1
00:00:09,720 --> 00:00:15,700
thank you very much so this is of course

2
00:00:13,420 --> 00:00:18,250
not only my work but also the work of my

3
00:00:15,700 --> 00:00:21,250
wonderful co-authors Karolina boosah

4
00:00:18,250 --> 00:00:23,560
Catalina FIFA Matthew Smith and Emanuel

5
00:00:21,250 --> 00:00:27,369
from such words from SBA research and

6
00:00:23,560 --> 00:00:32,200
bond University so I would like to start

7
00:00:27,369 --> 00:00:33,970
my talk with a little throwback to 2014

8
00:00:32,200 --> 00:00:37,329
let's have a look at the internet

9
00:00:33,970 --> 00:00:40,089
ecosystem in 2014 and HTTPS in general

10
00:00:37,329 --> 00:00:42,160
so this was the time when heartbleed was

11
00:00:40,090 --> 00:00:43,960
discovered and all over Twitter and

12
00:00:42,160 --> 00:00:47,468
everybody was going crazy about it and

13
00:00:43,960 --> 00:00:50,079
yeah at this time about 75% of the

14
00:00:47,469 --> 00:00:53,190
websites on the internet was not really

15
00:00:50,079 --> 00:00:56,260
sufficiently secured as you can see here

16
00:00:53,190 --> 00:00:58,449
well I would say somehow that HTTPS is

17
00:00:56,260 --> 00:01:01,059
one of the security or even usable

18
00:00:58,449 --> 00:01:04,809
security success stories so compared to

19
00:01:01,059 --> 00:01:07,980
2014 today a much larger percentage of

20
00:01:04,809 --> 00:01:10,270
websites can be considered secure

21
00:01:07,980 --> 00:01:12,700
researchers have improved connection

22
00:01:10,270 --> 00:01:15,280
security indicators and improve

23
00:01:12,700 --> 00:01:16,720
click-through rates in warnings so

24
00:01:15,280 --> 00:01:20,230
especially the chrome team did a really

25
00:01:16,720 --> 00:01:22,090
awesome job on that also let's encrypt

26
00:01:20,230 --> 00:01:24,100
and cert but have simplified the

27
00:01:22,090 --> 00:01:26,770
deployment process so for administrators

28
00:01:24,100 --> 00:01:27,339
everything has become much easier these

29
00:01:26,770 --> 00:01:30,820
days

30
00:01:27,340 --> 00:01:32,590
so the burden was removed and in general

31
00:01:30,820 --> 00:01:35,979
we can see that today there are much

32
00:01:32,590 --> 00:01:38,380
better configurations out there but

33
00:01:35,980 --> 00:01:41,440
regardless of these efforts about 30

34
00:01:38,380 --> 00:01:44,800
percent of the web sites are still not

35
00:01:41,440 --> 00:01:47,980
sufficiently secured and what we wanted

36
00:01:44,800 --> 00:01:50,140
to know a couple of years ago was why

37
00:01:47,980 --> 00:01:52,360
this is actually the case and why do we

38
00:01:50,140 --> 00:01:54,370
also still have so many vulnerable

39
00:01:52,360 --> 00:01:56,140
configurations although we now have

40
00:01:54,370 --> 00:01:59,710
let's encrypt and surf board and

41
00:01:56,140 --> 00:02:02,020
everything is fine isn't it so what we

42
00:01:59,710 --> 00:02:04,960
did is we published this paper adduced

43
00:02:02,020 --> 00:02:07,240
nick security in 2017 and we conducted a

44
00:02:04,960 --> 00:02:11,799
lab study with knowledgeable experts and

45
00:02:07,240 --> 00:02:16,769
let them configure HTTPS well our

46
00:02:11,800 --> 00:02:18,520
results indicate that the security

47
00:02:16,770 --> 00:02:19,990
security assessment of the

48
00:02:18,520 --> 00:02:20,849
configurations that resulted from the

49
00:02:19,990 --> 00:02:23,129
lab study

50
00:02:20,849 --> 00:02:24,599
not actually quite promising but not

51
00:02:23,129 --> 00:02:27,749
much better than in the real world

52
00:02:24,599 --> 00:02:31,518
actually but the point here is not the

53
00:02:27,749 --> 00:02:34,680
great that was that we gave to all these

54
00:02:31,519 --> 00:02:36,749
configurations but more the qualitative

55
00:02:34,680 --> 00:02:38,549
statements that the administrators gave

56
00:02:36,749 --> 00:02:41,519
to us because what they say it basically

57
00:02:38,549 --> 00:02:42,840
is oh great that my configuration is

58
00:02:41,519 --> 00:02:44,280
secure now good

59
00:02:42,840 --> 00:02:46,379
I found the right tutorial I have

60
00:02:44,280 --> 00:02:48,359
actually no idea what I'm doing here I'm

61
00:02:46,379 --> 00:02:49,590
not I have no idea what these cipher

62
00:02:48,359 --> 00:02:51,299
suites actually mean and what they are

63
00:02:49,590 --> 00:02:53,609
used for in my configuration but hey

64
00:02:51,299 --> 00:02:55,469
this tutorial works for me and this is

65
00:02:53,609 --> 00:02:58,010
why they had quite good configurations

66
00:02:55,469 --> 00:03:00,959
but what C study clearly shows is that

67
00:02:58,010 --> 00:03:03,540
many of these administrators had no idea

68
00:03:00,959 --> 00:03:07,260
what they were actually doing so we

69
00:03:03,540 --> 00:03:09,569
thought to find out why this whole

70
00:03:07,260 --> 00:03:11,790
confusion is there we take a little

71
00:03:09,569 --> 00:03:15,388
deeper and perform a qualitative study

72
00:03:11,790 --> 00:03:17,310
on mental models of HTTP so what is a

73
00:03:15,389 --> 00:03:19,620
mental model a mental model is basically

74
00:03:17,310 --> 00:03:21,000
a mental representation of the

75
00:03:19,620 --> 00:03:24,419
surrounding world or a piece of

76
00:03:21,000 --> 00:03:26,759
technology that we interact with and of

77
00:03:24,419 --> 00:03:29,220
course these mental models are very much

78
00:03:26,759 --> 00:03:32,099
shaped by our experience so for example

79
00:03:29,220 --> 00:03:33,478
I have a good mental model of a bottle

80
00:03:32,099 --> 00:03:35,129
of water bottle because I have

81
00:03:33,479 --> 00:03:37,049
experience in opening so many water

82
00:03:35,129 --> 00:03:39,780
bottles so I know what I have to do in

83
00:03:37,049 --> 00:03:42,479
order to make it work but not only

84
00:03:39,780 --> 00:03:44,699
experience contributes to the shaping of

85
00:03:42,479 --> 00:03:46,620
these mental models but also design

86
00:03:44,699 --> 00:03:48,239
contributes and this is a thing that

87
00:03:46,620 --> 00:03:49,919
would I would really like to raise

88
00:03:48,239 --> 00:03:52,829
awareness for in our community that

89
00:03:49,919 --> 00:03:55,019
every piece of technology that we built

90
00:03:52,829 --> 00:03:57,359
no matter if it is something that end

91
00:03:55,019 --> 00:03:59,209
users interact with or maybe

92
00:03:57,359 --> 00:04:01,680
administrators that use these

93
00:03:59,209 --> 00:04:07,500
configuration options or programmers

94
00:04:01,680 --> 00:04:09,359
that use api's all these interfaces help

95
00:04:07,500 --> 00:04:11,939
shape these mental models and very often

96
00:04:09,359 --> 00:04:16,049
shape incomplete mental models or simply

97
00:04:11,939 --> 00:04:19,019
wrong mental models so what we did here

98
00:04:16,048 --> 00:04:21,358
to measure these mental models is we of

99
00:04:19,019 --> 00:04:24,060
course did extensive pre testing to come

100
00:04:21,358 --> 00:04:26,969
up with a measurement instrument to to

101
00:04:24,060 --> 00:04:29,849
then finally get these mental models we

102
00:04:26,969 --> 00:04:31,770
then recruited participants gave them a

103
00:04:29,849 --> 00:04:35,509
questionnaire for demographic

104
00:04:31,770 --> 00:04:37,500
Nations to ask them about how they use

105
00:04:35,509 --> 00:04:39,479
HTTPS whether they have configured it

106
00:04:37,500 --> 00:04:41,340
before whether they have written TLS

107
00:04:39,479 --> 00:04:43,109
related court code and so on and so

108
00:04:41,340 --> 00:04:45,179
forth and then we conducted

109
00:04:43,110 --> 00:04:48,569
semi-structured interviews including

110
00:04:45,180 --> 00:04:51,000
three drawing exercises then afterwards

111
00:04:48,569 --> 00:04:53,610
we did some qualitative coding as we

112
00:04:51,000 --> 00:04:55,500
borrow from social sciences and then we

113
00:04:53,610 --> 00:04:58,139
did a post hoc validity study to make

114
00:04:55,500 --> 00:05:02,699
sure that our instrument was really well

115
00:04:58,139 --> 00:05:03,360
it so the interview guideline looked as

116
00:05:02,699 --> 00:05:05,430
follows

117
00:05:03,360 --> 00:05:07,979
so our interviews consisted of some

118
00:05:05,430 --> 00:05:10,740
general questions about usage behavior

119
00:05:07,979 --> 00:05:13,110
browsing behavior and security

120
00:05:10,740 --> 00:05:16,319
expectations when interacting with

121
00:05:13,110 --> 00:05:18,120
browsers then we had three drawing tasks

122
00:05:16,319 --> 00:05:21,509
so the first one was can you please

123
00:05:18,120 --> 00:05:24,090
describe and/or how encryption works in

124
00:05:21,509 --> 00:05:25,469
general the second was imagine you want

125
00:05:24,090 --> 00:05:27,599
to buy something at your favorite online

126
00:05:25,469 --> 00:05:31,440
shop and this online shop has this green

127
00:05:27,599 --> 00:05:33,719
lock or is accessible with HTTPS can you

128
00:05:31,440 --> 00:05:35,580
please draw what's happening between you

129
00:05:33,719 --> 00:05:38,009
and the online shop and the third one

130
00:05:35,580 --> 00:05:41,520
was online banking with HTTPS or rather

131
00:05:38,009 --> 00:05:44,639
similar scenario but again helped users

132
00:05:41,520 --> 00:05:47,400
to think about how they think the system

133
00:05:44,639 --> 00:05:49,650
works and to yeah elicit this tacit

134
00:05:47,400 --> 00:05:51,599
knowledge that they have and the last

135
00:05:49,650 --> 00:05:53,940
part of the interview was about attacker

136
00:05:51,599 --> 00:05:58,770
models so what attackers they think

137
00:05:53,940 --> 00:06:01,380
could eavesdrop these messages so we did

138
00:05:58,770 --> 00:06:03,568
not only interview administrators but we

139
00:06:01,380 --> 00:06:04,979
also interviewed and users because we

140
00:06:03,569 --> 00:06:08,520
also wanted to see the comparison

141
00:06:04,979 --> 00:06:10,529
between these two groups somehow and it

142
00:06:08,520 --> 00:06:12,960
was very easy to reach saturation with

143
00:06:10,529 --> 00:06:15,810
administrators because they are rather

144
00:06:12,960 --> 00:06:17,638
homogeneous sample and the cool thing

145
00:06:15,810 --> 00:06:20,880
here is that we had real administrators

146
00:06:17,639 --> 00:06:22,889
who were administrating service at real

147
00:06:20,880 --> 00:06:26,490
companies small and medium-sized

148
00:06:22,889 --> 00:06:29,639
enterprises in Europe so in the end we

149
00:06:26,490 --> 00:06:31,800
had a data set of 30 interviews we had a

150
00:06:29,639 --> 00:06:34,440
lot of quantitative and qualitative data

151
00:06:31,800 --> 00:06:36,389
we had those drawings we had the

152
00:06:34,440 --> 00:06:39,270
descriptions of the drawings and all the

153
00:06:36,389 --> 00:06:41,130
reasoning and to think aloud which of

154
00:06:39,270 --> 00:06:41,630
course was transcribed and we had some

155
00:06:41,130 --> 00:06:43,880
Hendrick

156
00:06:41,630 --> 00:06:46,100
notes to analyze and coding well this

157
00:06:43,880 --> 00:06:48,170
was if you're familiar with qualitative

158
00:06:46,100 --> 00:06:49,910
methods this is a quite standard

159
00:06:48,170 --> 00:06:51,350
approach here so we had two rounds of

160
00:06:49,910 --> 00:06:51,980
open coding where we developed a

161
00:06:51,350 --> 00:06:54,920
codebook

162
00:06:51,980 --> 00:06:56,870
we had three independent coders who

163
00:06:54,920 --> 00:06:59,000
coded the data individually and then we

164
00:06:56,870 --> 00:07:01,430
resolved conflicts and so on and so

165
00:06:59,000 --> 00:07:03,950
forth and finally made these codes more

166
00:07:01,430 --> 00:07:06,970
fine-grained in order to have a better

167
00:07:03,950 --> 00:07:09,740
quality analysis then in the end we used

168
00:07:06,970 --> 00:07:12,920
descriptive actual coding and selective

169
00:07:09,740 --> 00:07:15,220
coding so let's have a look at these

170
00:07:12,920 --> 00:07:18,410
drawings what these drawings look like

171
00:07:15,220 --> 00:07:19,910
this drawing what do you think do you

172
00:07:18,410 --> 00:07:21,440
think it was from an end-user or from an

173
00:07:19,910 --> 00:07:26,030
administrator who thinks it was from an

174
00:07:21,440 --> 00:07:28,180
end-user thank you well it's actually

175
00:07:26,030 --> 00:07:30,619
not it's a drawing from an administrator

176
00:07:28,180 --> 00:07:33,860
this was an administrator at a real

177
00:07:30,620 --> 00:07:36,170
company and well this person gave us a

178
00:07:33,860 --> 00:07:39,140
quite nice description of how they think

179
00:07:36,170 --> 00:07:42,200
it works but super super super sparse

180
00:07:39,140 --> 00:07:43,729
and super superficial so we do not

181
00:07:42,200 --> 00:07:45,860
really think that this person has a good

182
00:07:43,730 --> 00:07:47,870
understanding of how HTTP works and yeah

183
00:07:45,860 --> 00:07:50,870
this is a real administrator at a real

184
00:07:47,870 --> 00:07:54,230
company who has configured HTTP before

185
00:07:50,870 --> 00:07:57,070
and clearly cannot tell how it really

186
00:07:54,230 --> 00:07:59,480
works what we can also see here is that

187
00:07:57,070 --> 00:08:02,290
analyzing these drawings is really

188
00:07:59,480 --> 00:08:05,240
really difficult because without any

189
00:08:02,290 --> 00:08:07,340
audio description of this drawing it's

190
00:08:05,240 --> 00:08:10,310
impossible to really analyze such a

191
00:08:07,340 --> 00:08:12,260
drawing so what we really did when we

192
00:08:10,310 --> 00:08:15,230
started our initial coding process was

193
00:08:12,260 --> 00:08:17,090
one assistant read the statement from

194
00:08:15,230 --> 00:08:19,400
the transcript aloud and we looked at

195
00:08:17,090 --> 00:08:21,950
the drawing simultaneously and encoded

196
00:08:19,400 --> 00:08:25,820
the contextual statements in light of

197
00:08:21,950 --> 00:08:28,760
these drawings so let me give you

198
00:08:25,820 --> 00:08:31,490
another example this is another really

199
00:08:28,760 --> 00:08:34,159
nice example I think this is a drawing

200
00:08:31,490 --> 00:08:39,950
from an end-user and what we clearly see

201
00:08:34,159 --> 00:08:41,569
here is that this part here indicates

202
00:08:39,950 --> 00:08:43,280
well this is what you cannot see here

203
00:08:41,570 --> 00:08:45,440
but what is also from the audio track

204
00:08:43,280 --> 00:08:48,170
this is unencrypted traffic and this

205
00:08:45,440 --> 00:08:50,570
then gets forwarded to a centralized

206
00:08:48,170 --> 00:08:52,550
encryption component which encrypts

207
00:08:50,570 --> 00:08:54,470
everything and then sends it to Amazon

208
00:08:52,550 --> 00:08:55,250
which is the online shop of the choice

209
00:08:54,470 --> 00:08:57,350
here

210
00:08:55,250 --> 00:08:59,870
so we can here see this is a really

211
00:08:57,350 --> 00:09:01,370
sparse mental model and this mental

212
00:08:59,870 --> 00:09:03,199
model clearly assumes that there is a

213
00:09:01,370 --> 00:09:05,829
centralized encryption entity that does

214
00:09:03,199 --> 00:09:08,899
all the crypto stuff so the connection

215
00:09:05,829 --> 00:09:10,878
between the end-user and the encryption

216
00:09:08,899 --> 00:09:16,089
component is not secured and this is a

217
00:09:10,879 --> 00:09:18,709
potential attack surface for an attacker

218
00:09:16,089 --> 00:09:21,980
this I think is a very interesting model

219
00:09:18,709 --> 00:09:24,680
as well because this drawing shows well

220
00:09:21,980 --> 00:09:26,899
yeah here again we have the home

221
00:09:24,680 --> 00:09:28,729
computer we have the online shop but

222
00:09:26,899 --> 00:09:30,949
what we can clearly see here is that the

223
00:09:28,730 --> 00:09:33,350
concept of transport layer security is

224
00:09:30,949 --> 00:09:35,839
quite well understood because attackers

225
00:09:33,350 --> 00:09:38,689
cannot read messages here from this

226
00:09:35,839 --> 00:09:41,269
protected channel and also this end-user

227
00:09:38,689 --> 00:09:43,250
correctly indicated that the vulnerable

228
00:09:41,269 --> 00:09:45,889
points which you can see here in red are

229
00:09:43,250 --> 00:09:48,230
actually the communication endpoints so

230
00:09:45,889 --> 00:09:50,540
what I really like about this model this

231
00:09:48,230 --> 00:09:52,060
was an end user somebody who was not

232
00:09:50,540 --> 00:09:55,519
really familiar with the underlying

233
00:09:52,060 --> 00:09:58,459
technology but still had a rather sparse

234
00:09:55,519 --> 00:10:03,350
but kind of correct mental model in

235
00:09:58,459 --> 00:10:05,750
their head this example is from an

236
00:10:03,350 --> 00:10:07,730
administrator actually and I would say

237
00:10:05,750 --> 00:10:10,399
that this is one of the like best-case

238
00:10:07,730 --> 00:10:12,410
scenarios this is actually an outlier so

239
00:10:10,399 --> 00:10:15,769
this is completely different to all the

240
00:10:12,410 --> 00:10:18,290
other drawings that we saw we can see

241
00:10:15,769 --> 00:10:21,680
that this is quite accurate it contains

242
00:10:18,290 --> 00:10:23,629
various components various messages

243
00:10:21,680 --> 00:10:25,399
going around the audio track was huge

244
00:10:23,629 --> 00:10:27,589
this interview lasted for a very long

245
00:10:25,399 --> 00:10:29,779
time and this administrator was actually

246
00:10:27,589 --> 00:10:31,819
very good at describing how HTTP works

247
00:10:29,779 --> 00:10:35,990
but yeah also with of course some

248
00:10:31,819 --> 00:10:39,709
limitations so after all these different

249
00:10:35,990 --> 00:10:42,139
stages of coding well we really try to

250
00:10:39,709 --> 00:10:45,229
make sense of everything and come up

251
00:10:42,139 --> 00:10:47,870
with two rather abstract models that

252
00:10:45,230 --> 00:10:50,689
yeah combine all the findings altogether

253
00:10:47,870 --> 00:10:52,610
and we ended up then with two models one

254
00:10:50,689 --> 00:10:56,480
worst-case mental model and one

255
00:10:52,610 --> 00:10:58,160
best-case mental model here yeah so

256
00:10:56,480 --> 00:11:00,019
let's have a look at the worst-case

257
00:10:58,160 --> 00:11:03,589
model well this worst-case model clearly

258
00:11:00,019 --> 00:11:05,899
again here has decentralized encryption

259
00:11:03,589 --> 00:11:07,880
components somewhere where messengers

260
00:11:05,899 --> 00:11:10,130
messages are sent in planes

261
00:11:07,880 --> 00:11:12,620
to then encrypt it and then forward it

262
00:11:10,130 --> 00:11:16,070
to the online shopping site or the bank

263
00:11:12,620 --> 00:11:18,590
respectively and the assumed attacker

264
00:11:16,070 --> 00:11:21,440
model here is actually that Intelligence

265
00:11:18,590 --> 00:11:23,660
Agency at trackers hackers anyone who is

266
00:11:21,440 --> 00:11:26,990
bad in general can access this

267
00:11:23,660 --> 00:11:31,360
centralized encryption entity also

268
00:11:26,990 --> 00:11:34,940
cookies here as a gingerbread cookie are

269
00:11:31,360 --> 00:11:37,100
bad and can access different different

270
00:11:34,940 --> 00:11:38,780
types of information we have no

271
00:11:37,100 --> 00:11:40,910
connection security indicators

272
00:11:38,780 --> 00:11:43,130
whatsoever here those are not really

273
00:11:40,910 --> 00:11:45,230
part of these mental models we also do

274
00:11:43,130 --> 00:11:46,939
not have the notion of evie certificates

275
00:11:45,230 --> 00:11:49,220
for example and what is particularly

276
00:11:46,940 --> 00:11:54,440
interesting here is that this worst case

277
00:11:49,220 --> 00:11:57,500
model makes a difference between the two

278
00:11:54,440 --> 00:11:59,930
drawing exercises actually so they say

279
00:11:57,500 --> 00:12:02,360
that well online shopping sites do not

280
00:11:59,930 --> 00:12:05,719
have such strict security requirements

281
00:12:02,360 --> 00:12:07,430
and therefore one code is sent together

282
00:12:05,720 --> 00:12:10,760
with a plaintext message this code is

283
00:12:07,430 --> 00:12:12,620
then used by the HTTP proxy to encrypt

284
00:12:10,760 --> 00:12:14,300
and then yeah this encrypted message is

285
00:12:12,620 --> 00:12:17,600
sent to the online shopping site but for

286
00:12:14,300 --> 00:12:19,790
banking applications a certain amount of

287
00:12:17,600 --> 00:12:22,340
users thinks that the second factor that

288
00:12:19,790 --> 00:12:24,800
is very often used two-factor

289
00:12:22,340 --> 00:12:28,010
authentication is very normal of course

290
00:12:24,800 --> 00:12:29,930
in Europe as well so they think that

291
00:12:28,010 --> 00:12:32,030
this secondary factor is used for

292
00:12:29,930 --> 00:12:35,979
encryption and it adds an additional

293
00:12:32,030 --> 00:12:37,939
layer of encryption to yeah the other

294
00:12:35,980 --> 00:12:40,310
encrypted part and then is transferred

295
00:12:37,940 --> 00:12:43,030
to the bank so what we can clearly see

296
00:12:40,310 --> 00:12:46,189
here at this worst case model that

297
00:12:43,030 --> 00:12:49,280
authentication encryption security is

298
00:12:46,190 --> 00:12:52,550
perceived as kind of the same and those

299
00:12:49,280 --> 00:12:55,400
concepts are much more mixed and yeah

300
00:12:52,550 --> 00:12:58,910
this secondary factor is assumed to be

301
00:12:55,400 --> 00:13:02,090
used for encryption as well a good thing

302
00:12:58,910 --> 00:13:04,730
according to our data is that these

303
00:13:02,090 --> 00:13:08,720
parts of the worst case mental model are

304
00:13:04,730 --> 00:13:11,000
actually specific for end-users so none

305
00:13:08,720 --> 00:13:15,760
of the administrators assumed such a

306
00:13:11,000 --> 00:13:15,760
centralized HTTP proxy luckily

307
00:13:16,400 --> 00:13:21,720
so now let's have a look at the best

308
00:13:19,590 --> 00:13:23,610
case model well the best case model of

309
00:13:21,720 --> 00:13:25,590
course has so many good aspects but some

310
00:13:23,610 --> 00:13:28,080
aspects that I think are particularly

311
00:13:25,590 --> 00:13:29,460
worrisome especially as we have a sample

312
00:13:28,080 --> 00:13:31,500
consisting of knowledgeable

313
00:13:29,460 --> 00:13:33,780
administrators who were administrating

314
00:13:31,500 --> 00:13:36,090
server at real companies so the good

315
00:13:33,780 --> 00:13:39,470
thing is that this best case model has

316
00:13:36,090 --> 00:13:42,000
this year protected Channel somehow

317
00:13:39,470 --> 00:13:44,880
where attackers cannot eavesdrop

318
00:13:42,000 --> 00:13:49,110
messages from so this concept is quite

319
00:13:44,880 --> 00:13:51,720
well understood very few participants

320
00:13:49,110 --> 00:13:53,130
had those connection security indicators

321
00:13:51,720 --> 00:13:55,050
in their mental models so this was

322
00:13:53,130 --> 00:13:58,050
really the best case but again here

323
00:13:55,050 --> 00:14:02,069
nobody thought about Eevee or anything

324
00:13:58,050 --> 00:14:04,650
comparable the best case model also

325
00:14:02,070 --> 00:14:07,170
consists of a CA but what is important

326
00:14:04,650 --> 00:14:09,030
here is that the role of the CA is not

327
00:14:07,170 --> 00:14:11,610
really well understood so nobody really

328
00:14:09,030 --> 00:14:13,949
knows what the role of the CA is in the

329
00:14:11,610 --> 00:14:15,660
ecosystem and why certificates are

330
00:14:13,950 --> 00:14:19,830
needed for and concepts like server

331
00:14:15,660 --> 00:14:21,240
authentication are not really well most

332
00:14:19,830 --> 00:14:24,990
administrators were not even able to

333
00:14:21,240 --> 00:14:27,210
explain what this is used for also what

334
00:14:24,990 --> 00:14:29,400
was very specific to administrators is

335
00:14:27,210 --> 00:14:30,900
that administer just liked to play

336
00:14:29,400 --> 00:14:33,569
around with buzzwords so they were

337
00:14:30,900 --> 00:14:35,730
throwing in buzzwords and some protocol

338
00:14:33,570 --> 00:14:37,830
components but they did not really that

339
00:14:35,730 --> 00:14:39,150
they were not really to explain a belay

340
00:14:37,830 --> 00:14:40,770
'none these buzzwords meant when we

341
00:14:39,150 --> 00:14:43,410
asked them and we asked them and we

342
00:14:40,770 --> 00:14:46,050
really asked him a lot of follow-up

343
00:14:43,410 --> 00:14:48,150
questions and most of them were really

344
00:14:46,050 --> 00:14:51,180
not able to explain what this means so

345
00:14:48,150 --> 00:14:56,490
all this is kind of disconnected and the

346
00:14:51,180 --> 00:14:58,560
model is not really conceptual yeah so

347
00:14:56,490 --> 00:15:00,570
what do these findings mean now in the

348
00:14:58,560 --> 00:15:02,670
end well actually we managed to reveal

349
00:15:00,570 --> 00:15:04,320
some misconceptions about the security

350
00:15:02,670 --> 00:15:06,420
benefits and the threat models from both

351
00:15:04,320 --> 00:15:09,660
groups what I think is a really good

352
00:15:06,420 --> 00:15:12,479
thing that we observed is that end-users

353
00:15:09,660 --> 00:15:15,140
actually quite a high number of end

354
00:15:12,480 --> 00:15:18,090
users that we interviewed were aware

355
00:15:15,140 --> 00:15:19,920
that their endpoints are somehow

356
00:15:18,090 --> 00:15:22,020
vulnerable components and that they are

357
00:15:19,920 --> 00:15:24,150
responsible to make sure that the

358
00:15:22,020 --> 00:15:26,640
endpoints are secured an administrator

359
00:15:24,150 --> 00:15:27,490
in general assumed more sophisticated

360
00:15:26,640 --> 00:15:29,619
attacker

361
00:15:27,490 --> 00:15:31,480
which we also think is a really good

362
00:15:29,619 --> 00:15:33,160
thing because this is what they're in

363
00:15:31,480 --> 00:15:36,790
charge of what they should be aware of

364
00:15:33,160 --> 00:15:38,829
and control yeah we also identified

365
00:15:36,790 --> 00:15:40,660
protocol components that interfere with

366
00:15:38,829 --> 00:15:42,609
secure configurations and users

367
00:15:40,660 --> 00:15:45,309
behaviors so some protocol components

368
00:15:42,610 --> 00:15:47,519
are really not well understood and the

369
00:15:45,309 --> 00:15:49,360
interesting point here is that

370
00:15:47,519 --> 00:15:51,879
administrator mental models are very

371
00:15:49,360 --> 00:15:55,689
much protocol driven and not so much

372
00:15:51,879 --> 00:15:57,970
conceptual yeah and our results also

373
00:15:55,689 --> 00:15:59,860
suggested end-user mental models yeah

374
00:15:57,970 --> 00:16:02,350
I'm more conceptual as protocol based

375
00:15:59,860 --> 00:16:04,089
and end-users often confuse encryption

376
00:16:02,350 --> 00:16:07,990
with with authentication which i think

377
00:16:04,089 --> 00:16:09,819
is quite worrisome users also distrust

378
00:16:07,990 --> 00:16:11,769
security indicators so both

379
00:16:09,819 --> 00:16:13,899
administrators and end-users often said

380
00:16:11,769 --> 00:16:15,220
that those security indicators are only

381
00:16:13,899 --> 00:16:19,179
there for marketing and they don't

382
00:16:15,220 --> 00:16:20,529
really mean that much yeah and with this

383
00:16:19,179 --> 00:16:22,839
well there are many other interesting

384
00:16:20,529 --> 00:16:24,279
aspects as part of the papers so for

385
00:16:22,839 --> 00:16:26,740
example I completely left out the part

386
00:16:24,279 --> 00:16:29,259
on mental models of message encryption

387
00:16:26,740 --> 00:16:32,079
and more detailed findings on attacker

388
00:16:29,259 --> 00:16:34,449
models and security expectations of the

389
00:16:32,079 --> 00:16:36,819
protocol I would also like to say that

390
00:16:34,449 --> 00:16:39,368
my research group at Cisco is currently

391
00:16:36,819 --> 00:16:41,498
hiring so I'm always looking for

392
00:16:39,369 --> 00:16:44,499
talented students that want to work in

393
00:16:41,499 --> 00:16:48,779
this domain and by saying this thank you

394
00:16:44,499 --> 00:16:48,779
very much and I'm taking questions now

395
00:16:52,279 --> 00:16:56,610
Thank You Katerina and I think we have a

396
00:16:54,990 --> 00:16:58,649
question lined up back there already

397
00:16:56,610 --> 00:17:00,209
just one quick thing before that if the

398
00:16:58,649 --> 00:17:01,860
land if the next speaker does not have a

399
00:17:00,209 --> 00:17:04,530
microphone yet please pick it up in the

400
00:17:01,860 --> 00:17:06,360
back otherwise please go ahead hold on

401
00:17:04,530 --> 00:17:09,149
or shot Carlton University thank you for

402
00:17:06,359 --> 00:17:11,668
the talk very well littered I guess it

403
00:17:09,150 --> 00:17:14,309
it's less important if a mental model is

404
00:17:11,669 --> 00:17:16,530
correct or not then whether it supports

405
00:17:14,309 --> 00:17:18,869
user actions which help or hurt

406
00:17:16,530 --> 00:17:21,599
security so do you have any specific

407
00:17:18,869 --> 00:17:28,889
examples of how the mental models helped

408
00:17:21,599 --> 00:17:31,500
or hurt security well I think in some

409
00:17:28,890 --> 00:17:34,320
sense they hurt security in a way that

410
00:17:31,500 --> 00:17:35,820
for example let's encrypt abstract so

411
00:17:34,320 --> 00:17:37,918
much of the configuration process away

412
00:17:35,820 --> 00:17:41,129
from administrators but what it does not

413
00:17:37,919 --> 00:17:42,720
remove is the retrieval of the

414
00:17:41,130 --> 00:17:45,600
certificates for example but as we can

415
00:17:42,720 --> 00:17:48,030
see if the role of the certificate for

416
00:17:45,600 --> 00:17:49,740
the entire ecosystem is not clear I

417
00:17:48,030 --> 00:17:52,379
don't know if this is a good idea to

418
00:17:49,740 --> 00:17:55,020
take this away from from administrators

419
00:17:52,380 --> 00:17:57,540
I totally agree with you I think the

420
00:17:55,020 --> 00:18:00,090
major point is that here is that we

421
00:17:57,540 --> 00:18:01,379
don't know yet no I mean I think this is

422
00:18:00,090 --> 00:18:04,020
something that we should further study

423
00:18:01,380 --> 00:18:07,500
how these mental models impact behavior

424
00:18:04,020 --> 00:18:09,780
then hi Phoebe Rouge from the Federal

425
00:18:07,500 --> 00:18:11,549
Trade Commission and I guess sort of

426
00:18:09,780 --> 00:18:14,490
following on with that I'm curious sort

427
00:18:11,549 --> 00:18:16,080
of what would you think about so like

428
00:18:14,490 --> 00:18:17,809
from some of the other talks it seems

429
00:18:16,080 --> 00:18:20,100
like a lot of the effort in getting

430
00:18:17,809 --> 00:18:21,389
HTTPS properly configured is sort of

431
00:18:20,100 --> 00:18:23,100
pushing things on the infrastructure

432
00:18:21,390 --> 00:18:24,660
side or the browser side so that it's

433
00:18:23,100 --> 00:18:26,668
pulled away from the individual

434
00:18:24,660 --> 00:18:28,650
administrators and the users because

435
00:18:26,669 --> 00:18:30,750
it's complicated and people don't

436
00:18:28,650 --> 00:18:32,250
understand that that well but do you

437
00:18:30,750 --> 00:18:33,720
think that that's the right focus or is

438
00:18:32,250 --> 00:18:36,390
it sort of you know we should focus more

439
00:18:33,720 --> 00:18:38,100
on like educating people on how to use

440
00:18:36,390 --> 00:18:40,410
it you know what this really how this

441
00:18:38,100 --> 00:18:43,020
works or is it more like where would you

442
00:18:40,410 --> 00:18:45,090
like where would you think that effort

443
00:18:43,020 --> 00:18:46,830
should be concentrated and that I think

444
00:18:45,090 --> 00:18:48,510
that's a very interesting question and

445
00:18:46,830 --> 00:18:50,370
to be honest I thought about a lot about

446
00:18:48,510 --> 00:18:52,260
this so I think that you're pushing more

447
00:18:50,370 --> 00:18:55,110
on the infrastructure side I think is a

448
00:18:52,260 --> 00:18:57,240
good thing but I also think that this

449
00:18:55,110 --> 00:19:00,209
study clearly shows that we often

450
00:18:57,240 --> 00:19:03,210
implicitly assume that people especially

451
00:19:00,210 --> 00:19:04,120
knowledgeable users are experts and what

452
00:19:03,210 --> 00:19:06,850
we see here

453
00:19:04,120 --> 00:19:09,639
is that yeah very often they just copy

454
00:19:06,850 --> 00:19:11,260
stuff from the internet and they are not

455
00:19:09,640 --> 00:19:13,680
really capable of making informed

456
00:19:11,260 --> 00:19:16,600
security decisions here so I think we

457
00:19:13,680 --> 00:19:19,030
overestimated the knowledge of these

458
00:19:16,600 --> 00:19:21,490
administrator a lot so I think what we

459
00:19:19,030 --> 00:19:23,020
need is to actually design the

460
00:19:21,490 --> 00:19:25,420
technology that they interact with in a

461
00:19:23,020 --> 00:19:26,860
way that it's easier for them to make

462
00:19:25,420 --> 00:19:28,540
these security decisions

463
00:19:26,860 --> 00:19:30,129
so maybe just abstracting everything

464
00:19:28,540 --> 00:19:32,860
away from them is not the right way to

465
00:19:30,130 --> 00:19:35,380
go we need to abstract away the the

466
00:19:32,860 --> 00:19:36,699
right things the right components and I

467
00:19:35,380 --> 00:19:39,310
think that this is not what our

468
00:19:36,700 --> 00:19:41,500
community currently does and yet this

469
00:19:39,310 --> 00:19:45,790
again is very important to me to say

470
00:19:41,500 --> 00:19:48,370
that every API every protocol that we in

471
00:19:45,790 --> 00:19:50,760
this community built has an impact on

472
00:19:48,370 --> 00:19:53,080
these mental models so we are the ones

473
00:19:50,760 --> 00:19:54,940
who help constructing these mental

474
00:19:53,080 --> 00:19:57,149
models and we need to make those

475
00:19:54,940 --> 00:20:04,450
decisions when we design those protocols

476
00:19:57,150 --> 00:20:07,810
thank you there are no further questions

477
00:20:04,450 --> 00:20:10,240
any more I don't see them with that said

478
00:20:07,810 --> 00:20:14,379
thank you very much cut to read oh yeah

479
00:20:10,240 --> 00:20:14,380
[Applause]

