1
00:00:10,480 --> 00:00:16,840
yeah so hi everyone so this is work that

2
00:00:13,839 --> 00:00:21,310
I did when I was at bakudo with a few of

3
00:00:16,840 --> 00:00:24,369
my former colleagues so let me first set

4
00:00:21,310 --> 00:00:26,259
the stage so business email compromised

5
00:00:24,369 --> 00:00:29,679
BC it has a lot of different names some

6
00:00:26,259 --> 00:00:32,230
people also call it spear phishing email

7
00:00:29,679 --> 00:00:34,989
social engineering basically these are

8
00:00:32,229 --> 00:00:38,050
attacks that use social impersonation as

9
00:00:34,989 --> 00:00:40,510
the main vector of attack so this is

10
00:00:38,050 --> 00:00:42,910
kind of a prototypical example of one of

11
00:00:40,510 --> 00:00:44,739
these emails so let's say you're the

12
00:00:42,910 --> 00:00:48,190
attacker is impersonating Alice Smith

13
00:00:44,739 --> 00:00:50,919
who is the CEO of a company and the

14
00:00:48,190 --> 00:00:53,079
attacker spoofs the name of Alice Smith

15
00:00:50,920 --> 00:00:55,359
they also send an email from an email

16
00:00:53,079 --> 00:00:56,829
address that looks a lot like Alice's

17
00:00:55,359 --> 00:00:59,949
corporate email address so instead of

18
00:00:56,829 --> 00:01:02,079
acne com they choose acne com

19
00:00:59,949 --> 00:01:03,760
and of course a lot of us don't wouldn't

20
00:01:02,079 --> 00:01:06,759
see the difference in an email client

21
00:01:03,760 --> 00:01:10,600
and the attacker is asking Bob who's the

22
00:01:06,759 --> 00:01:13,600
CFO who's under Alice whether Bob can

23
00:01:10,600 --> 00:01:15,818
wire transfer some money ASAP and of

24
00:01:13,600 --> 00:01:17,890
course this money is the goal here is to

25
00:01:15,819 --> 00:01:20,440
get that money out to a bank account

26
00:01:17,890 --> 00:01:22,599
owned by the attacker now there's a lot

27
00:01:20,440 --> 00:01:25,149
of variants on this type of attack so

28
00:01:22,599 --> 00:01:27,729
sometimes attackers you know will try to

29
00:01:25,149 --> 00:01:29,200
fake the domain sometimes they won't

30
00:01:27,729 --> 00:01:31,599
even bother there's a Senate from a

31
00:01:29,200 --> 00:01:33,940
random email address assuming that

32
00:01:31,599 --> 00:01:36,429
people don't really notice the email

33
00:01:33,940 --> 00:01:37,959
address on their client and then you

34
00:01:36,429 --> 00:01:40,030
know why transfers are kind of the most

35
00:01:37,959 --> 00:01:42,970
common objective but they might also be

36
00:01:40,030 --> 00:01:48,640
trying to steal credentials or even PII

37
00:01:42,970 --> 00:01:51,940
like w-2s and so forth and BC attacks

38
00:01:48,640 --> 00:01:53,739
are extremely lucrative so in fact the

39
00:01:51,940 --> 00:01:56,649
FBI actually publishes an annual report

40
00:01:53,739 --> 00:01:58,690
just tracking BC in the last five years

41
00:01:56,649 --> 00:02:01,300
there's been over 12 billion dollars in

42
00:01:58,690 --> 00:02:03,190
losses reported to the FBI of people

43
00:02:01,300 --> 00:02:05,170
who've done mistake in wire transfers

44
00:02:03,190 --> 00:02:07,989
and this is actually a lot more than

45
00:02:05,170 --> 00:02:09,970
many other types of attacks that we all

46
00:02:07,989 --> 00:02:12,459
kind of have heard about so for example

47
00:02:09,970 --> 00:02:13,030
ransomware is only around 25 million

48
00:02:12,459 --> 00:02:15,879
dollars a year

49
00:02:13,030 --> 00:02:18,209
rough estimate from Google so this is

50
00:02:15,879 --> 00:02:21,849
orders of magnitude more damaging to

51
00:02:18,209 --> 00:02:23,739
organizations now you might ask yourself

52
00:02:21,849 --> 00:02:24,179
why don't exist' insist UM's

53
00:02:23,739 --> 00:02:26,040
at

54
00:02:24,180 --> 00:02:28,829
these attacks um so there's really two

55
00:02:26,040 --> 00:02:30,929
reasons for that first one is bc attacks

56
00:02:28,829 --> 00:02:33,030
are highly targeted right so the

57
00:02:30,930 --> 00:02:35,220
attacker is actually manually crafting

58
00:02:33,030 --> 00:02:37,140
an email to a particular employee in the

59
00:02:35,220 --> 00:02:39,629
organization particular organization

60
00:02:37,140 --> 00:02:41,010
with with some context right and so

61
00:02:39,629 --> 00:02:43,290
something like a spam filter will

62
00:02:41,010 --> 00:02:45,298
obviously won't won't pick this up in

63
00:02:43,290 --> 00:02:47,730
addition to that the attack doesn't have

64
00:02:45,299 --> 00:02:49,980
any obviously malicious payloads right

65
00:02:47,730 --> 00:02:51,810
so often these emails are actually just

66
00:02:49,980 --> 00:02:54,659
plain text they're just a piece of text

67
00:02:51,810 --> 00:02:56,639
and you know they won't have any malware

68
00:02:54,659 --> 00:02:59,459
viruses and you know even if they have a

69
00:02:56,639 --> 00:03:01,409
link oftentimes that link has is coming

70
00:02:59,459 --> 00:03:04,500
from a high reputation web site and a

71
00:03:01,409 --> 00:03:07,260
zero-day link now there's actually been

72
00:03:04,500 --> 00:03:09,930
some prior work from academia actually

73
00:03:07,260 --> 00:03:11,879
from grant and some of his collaborators

74
00:03:09,930 --> 00:03:14,939
from two years ago at music security

75
00:03:11,879 --> 00:03:17,040
that try to stop this type of attack

76
00:03:14,939 --> 00:03:20,189
with a detector and they used an

77
00:03:17,040 --> 00:03:22,500
unsupervised learning model and they did

78
00:03:20,189 --> 00:03:24,840
a good job they catch the vast majority

79
00:03:22,500 --> 00:03:27,269
of attacks but in terms of false

80
00:03:24,840 --> 00:03:29,400
positive rates they have they have very

81
00:03:27,269 --> 00:03:31,829
high false positive rate so they kind of

82
00:03:29,400 --> 00:03:34,319
assume that the organization using user

83
00:03:31,829 --> 00:03:36,239
system has a group of security analysts

84
00:03:34,319 --> 00:03:37,888
that can actually sift through the

85
00:03:36,239 --> 00:03:39,840
results of their system to say if

86
00:03:37,889 --> 00:03:43,919
they're good or not and then quarantine

87
00:03:39,840 --> 00:03:45,720
them and so at Barracuda a lot of the

88
00:03:43,919 --> 00:03:47,790
customers and users really don't have

89
00:03:45,720 --> 00:03:49,290
you know security analysts a big

90
00:03:47,790 --> 00:03:51,418
security loss team or any security

91
00:03:49,290 --> 00:03:54,780
people at all and so we tried to build

92
00:03:51,419 --> 00:03:56,849
an automated system called BC guard

93
00:03:54,780 --> 00:03:59,099
which was then incorporated in a

94
00:03:56,849 --> 00:04:01,888
commercial product called Barracuda

95
00:03:59,099 --> 00:04:03,540
Sentinel which had very low false

96
00:04:01,889 --> 00:04:05,940
positive rate so less than one in a

97
00:04:03,540 --> 00:04:08,578
million emails and a high precision of

98
00:04:05,940 --> 00:04:10,109
above 90% which means that the system

99
00:04:08,579 --> 00:04:12,030
can automatically quarantine these

100
00:04:10,109 --> 00:04:14,909
emails for the customer and doesn't

101
00:04:12,030 --> 00:04:17,070
require an analyst so how do you go

102
00:04:14,909 --> 00:04:19,560
about building a high precision detector

103
00:04:17,070 --> 00:04:21,180
for such a targeted attack so let me go

104
00:04:19,560 --> 00:04:23,580
through a couple of examples and show

105
00:04:21,180 --> 00:04:25,940
you kind of the hooks in these emails

106
00:04:23,580 --> 00:04:28,830
that we can then use to build a detector

107
00:04:25,940 --> 00:04:31,620
so the first example is the same example

108
00:04:28,830 --> 00:04:33,270
I showed earlier and now we're just

109
00:04:31,620 --> 00:04:36,210
going to separate the hooks and the

110
00:04:33,270 --> 00:04:36,780
emails in the email to the header and

111
00:04:36,210 --> 00:04:39,120
the

112
00:04:36,780 --> 00:04:41,429
okay so let's look at this email so on

113
00:04:39,120 --> 00:04:43,860
the header side the obvious thing that's

114
00:04:41,430 --> 00:04:45,350
kind of weird here is we're getting an

115
00:04:43,860 --> 00:04:47,580
email address with an employee's name

116
00:04:45,350 --> 00:04:49,290
but with an email address that is

117
00:04:47,580 --> 00:04:52,280
different from the normal corporate

118
00:04:49,290 --> 00:04:55,500
address so that is obviously kind of

119
00:04:52,280 --> 00:04:56,700
anomalous and then in the body right we

120
00:04:55,500 --> 00:04:58,560
have a bunch of things going on here

121
00:04:56,700 --> 00:05:01,139
right so we have some sensitive

122
00:04:58,560 --> 00:05:03,300
financial and you know requests which

123
00:05:01,139 --> 00:05:04,860
might be a little off and we also have

124
00:05:03,300 --> 00:05:06,240
some sense of urgency in the email

125
00:05:04,860 --> 00:05:08,400
because the attacker really wants the

126
00:05:06,240 --> 00:05:10,650
employee to respond to the email quickly

127
00:05:08,400 --> 00:05:12,960
before they realize you know that it's

128
00:05:10,650 --> 00:05:15,390
an attacker now let's look at another

129
00:05:12,960 --> 00:05:18,239
example in this example the attacker

130
00:05:15,390 --> 00:05:20,460
spoofs both the name of the employee and

131
00:05:18,240 --> 00:05:22,890
the email address so they're actually

132
00:05:20,460 --> 00:05:26,969
sending it with a from of Alice Smith

133
00:05:22,890 --> 00:05:29,550
with Alice's real kind of acne com email

134
00:05:26,970 --> 00:05:31,410
address but they have a reply too which

135
00:05:29,550 --> 00:05:33,360
is different and so the idea here is to

136
00:05:31,410 --> 00:05:35,190
compel the recipient to respond to the

137
00:05:33,360 --> 00:05:38,190
email and then be able to capture the

138
00:05:35,190 --> 00:05:40,830
response and so here you know the

139
00:05:38,190 --> 00:05:43,200
obvious thing that is anomalous in the

140
00:05:40,830 --> 00:05:45,120
header is this weird reply to address

141
00:05:43,200 --> 00:05:46,950
that's different than the sender address

142
00:05:45,120 --> 00:05:48,840
right most of us would typically not

143
00:05:46,950 --> 00:05:50,760
send an email with a reply to that's

144
00:05:48,840 --> 00:05:52,859
different than the sender and then the

145
00:05:50,760 --> 00:05:56,669
body again it has some kind of an urgent

146
00:05:52,860 --> 00:05:59,190
request now the thing is right each one

147
00:05:56,669 --> 00:06:01,799
of these attributes on its own has a lot

148
00:05:59,190 --> 00:06:04,979
of use cases that are legitimate that

149
00:06:01,800 --> 00:06:07,590
are not attacks so for example getting

150
00:06:04,979 --> 00:06:09,210
an email address an email with an email

151
00:06:07,590 --> 00:06:11,669
address that you've never seen before

152
00:06:09,210 --> 00:06:14,219
from a particular person actually has a

153
00:06:11,669 --> 00:06:16,409
lot of legitimate uses right so you know

154
00:06:14,220 --> 00:06:18,210
there could be sporadic use of personal

155
00:06:16,410 --> 00:06:20,039
email right so especially in a

156
00:06:18,210 --> 00:06:21,719
university setting for example that

157
00:06:20,039 --> 00:06:23,460
would be very common or you could

158
00:06:21,720 --> 00:06:25,890
coincidentally have someone outside the

159
00:06:23,460 --> 00:06:27,870
company with an external sender name

160
00:06:25,890 --> 00:06:29,700
with a sorry with a sender name that has

161
00:06:27,870 --> 00:06:31,500
the same name of someone inside the

162
00:06:29,700 --> 00:06:34,650
company right so that could also happen

163
00:06:31,500 --> 00:06:37,050
and even this reply to address has

164
00:06:34,650 --> 00:06:38,909
legitimate corner cases so services like

165
00:06:37,050 --> 00:06:41,039
LinkedIn and Salesforce often

166
00:06:38,910 --> 00:06:43,620
legitimately impersonate people because

167
00:06:41,039 --> 00:06:47,190
they want to capture the response to the

168
00:06:43,620 --> 00:06:50,110
reply to and also for the from from the

169
00:06:47,190 --> 00:06:51,850
body perspective right you know you

170
00:06:50,110 --> 00:06:54,190
getting an email with urgent wire

171
00:06:51,850 --> 00:06:55,630
transfer could be normal right it could

172
00:06:54,190 --> 00:06:58,240
actually be a wire transfer that you

173
00:06:55,630 --> 00:07:01,150
need to do because you owe a vendor some

174
00:06:58,240 --> 00:07:02,740
money right so obviously you know emails

175
00:07:01,150 --> 00:07:04,539
just containing these phrases are not

176
00:07:02,740 --> 00:07:05,080
you know good enough to classify as a

177
00:07:04,540 --> 00:07:07,030
tax

178
00:07:05,080 --> 00:07:09,099
so to summarize here right each one of

179
00:07:07,030 --> 00:07:10,690
these attributes on its own is not

180
00:07:09,100 --> 00:07:13,120
enough but a combination of these

181
00:07:10,690 --> 00:07:16,570
attributes could possibly lead us to get

182
00:07:13,120 --> 00:07:18,130
a classifier that has high precision so

183
00:07:16,570 --> 00:07:22,570
let me talk about how we actually build

184
00:07:18,130 --> 00:07:26,110
such a classifier so the main problem in

185
00:07:22,570 --> 00:07:28,510
building this detector is that a b c is

186
00:07:26,110 --> 00:07:30,730
an imbalance problem and what that means

187
00:07:28,510 --> 00:07:33,370
is if you take fifty thousand random

188
00:07:30,730 --> 00:07:36,070
emails in a company at least in our data

189
00:07:33,370 --> 00:07:38,080
set only one of them will be b ec and

190
00:07:36,070 --> 00:07:39,969
what that means and this is gonna be

191
00:07:38,080 --> 00:07:42,669
true for a lot of other right targeted

192
00:07:39,970 --> 00:07:44,380
types of attacks and what this means is

193
00:07:42,670 --> 00:07:46,360
we immediately kind of ruled out

194
00:07:44,380 --> 00:07:47,830
unsupervised learning because there's

195
00:07:46,360 --> 00:07:49,390
something like unsupervised learning

196
00:07:47,830 --> 00:07:52,599
let's say that does clustering is

197
00:07:49,390 --> 00:07:54,700
probably not going to cluster a b c

198
00:07:52,600 --> 00:07:56,260
attack as one of the main categories of

199
00:07:54,700 --> 00:07:58,060
emails right it's gonna choose many

200
00:07:56,260 --> 00:08:00,070
other categories first so we chose

201
00:07:58,060 --> 00:08:02,110
supervised learning but there's a couple

202
00:08:00,070 --> 00:08:03,790
of challenges if you want to use

203
00:08:02,110 --> 00:08:06,100
supervised learning so one how do you

204
00:08:03,790 --> 00:08:07,900
actually physically label like 100

205
00:08:06,100 --> 00:08:10,990
million emails let's say if you want

206
00:08:07,900 --> 00:08:12,310
just 2,000 samples of attacks and the

207
00:08:10,990 --> 00:08:15,730
second challenge is how do you actually

208
00:08:12,310 --> 00:08:17,590
go about training on this data set so

209
00:08:15,730 --> 00:08:20,110
for the first challenge what we did is

210
00:08:17,590 --> 00:08:22,840
kind of a divide and conquer policy so

211
00:08:20,110 --> 00:08:26,110
instead of trying to label kind of all

212
00:08:22,840 --> 00:08:28,630
the emails from the get-go we actually

213
00:08:26,110 --> 00:08:31,570
labeled our data into two sets of

214
00:08:28,630 --> 00:08:33,370
classifiers so we first train a

215
00:08:31,570 --> 00:08:34,750
classifier that just looks at the header

216
00:08:33,370 --> 00:08:36,850
which I'm going to call the

217
00:08:34,750 --> 00:08:38,710
impersonation classifier so it's trying

218
00:08:36,850 --> 00:08:40,540
to detect an impersonation of an

219
00:08:38,710 --> 00:08:43,090
employee just by looking at the header

220
00:08:40,539 --> 00:08:44,860
of email and then we trained a set of

221
00:08:43,090 --> 00:08:47,650
classifiers that only look at the body

222
00:08:44,860 --> 00:08:50,440
and we only apply them to emails that

223
00:08:47,650 --> 00:08:53,709
were categorized as impersonations by

224
00:08:50,440 --> 00:08:55,630
the header classifier and so what we did

225
00:08:53,710 --> 00:08:58,150
at least to develop the initial version

226
00:08:55,630 --> 00:09:00,460
of the detector was we actually use kind

227
00:08:58,150 --> 00:09:02,290
of bulk labeling to train the

228
00:09:00,460 --> 00:09:04,000
personation classifier so we try to find

229
00:09:02,290 --> 00:09:06,069
all the emails that could pause

230
00:09:04,000 --> 00:09:07,870
Sibley impersonation all these emails

231
00:09:06,070 --> 00:09:09,790
that have different apply to addresses

232
00:09:07,870 --> 00:09:11,590
all these emails that have you know

233
00:09:09,790 --> 00:09:13,390
relatively infrequent usage of a

234
00:09:11,590 --> 00:09:15,550
particular email address for a

235
00:09:13,390 --> 00:09:17,319
particular employee and then use them to

236
00:09:15,550 --> 00:09:20,229
train the impersonation classifier and

237
00:09:17,320 --> 00:09:22,330
then only the output of that used from

238
00:09:20,230 --> 00:09:24,250
to manually label for the body for the

239
00:09:22,330 --> 00:09:25,990
content classifiers so that took us from

240
00:09:24,250 --> 00:09:27,460
like a hundred million emails to

241
00:09:25,990 --> 00:09:29,970
something like fifty thousand emails

242
00:09:27,460 --> 00:09:32,500
which is still a lot but more manageable

243
00:09:29,970 --> 00:09:34,300
now let me go through some of the kind

244
00:09:32,500 --> 00:09:35,440
of key so all the details are in the

245
00:09:34,300 --> 00:09:37,750
paper I'll go through some of the key

246
00:09:35,440 --> 00:09:40,480
features that we use to train the

247
00:09:37,750 --> 00:09:43,300
detector so on the header side the

248
00:09:40,480 --> 00:09:45,640
impersonation classifier two of the most

249
00:09:43,300 --> 00:09:48,790
important features were the first one is

250
00:09:45,640 --> 00:09:50,590
the number of times the email address

251
00:09:48,790 --> 00:09:53,170
the sender email address appeared with a

252
00:09:50,590 --> 00:09:55,570
particular sender name in the past so

253
00:09:53,170 --> 00:09:57,339
intuitively if you get an email from you

254
00:09:55,570 --> 00:09:58,570
know a colleague but it's with an email

255
00:09:57,340 --> 00:10:02,320
address that you've never seen before

256
00:09:58,570 --> 00:10:04,780
it's more likely to be a BC attack now

257
00:10:02,320 --> 00:10:07,450
note that this feature in order to

258
00:10:04,780 --> 00:10:10,089
calculate it for each incoming email we

259
00:10:07,450 --> 00:10:11,950
have to have the history of how this

260
00:10:10,089 --> 00:10:15,040
person has communicated in the past

261
00:10:11,950 --> 00:10:16,630
within the organization another feature

262
00:10:15,040 --> 00:10:18,520
that proved actually really important is

263
00:10:16,630 --> 00:10:20,350
sender name popularity so you know a

264
00:10:18,520 --> 00:10:21,790
pretty common name like Alice Smith is

265
00:10:20,350 --> 00:10:24,190
actually much more likely to have

266
00:10:21,790 --> 00:10:26,319
outside people with the same name but if

267
00:10:24,190 --> 00:10:28,270
you know you have my name a soft Sedona

268
00:10:26,320 --> 00:10:30,580
at least in the US you're much less

269
00:10:28,270 --> 00:10:33,610
likely to get outside people colliding

270
00:10:30,580 --> 00:10:35,589
with your name in terms of the contact

271
00:10:33,610 --> 00:10:37,540
classifiers so we employed a bunch of

272
00:10:35,589 --> 00:10:40,450
different ones just for kind of

273
00:10:37,540 --> 00:10:43,060
manageability purposes it was easier so

274
00:10:40,450 --> 00:10:46,420
let me just briefly describe our text

275
00:10:43,060 --> 00:10:48,790
classifier so again only looking at the

276
00:10:46,420 --> 00:10:51,160
body and the subject so what we do is we

277
00:10:48,790 --> 00:10:53,890
take the raw text we pre processed it to

278
00:10:51,160 --> 00:10:56,589
remove all stop words email addresses

279
00:10:53,890 --> 00:11:00,130
names headers footers etc and then we

280
00:10:56,589 --> 00:11:02,500
compute that tf-idf of the phrases in

281
00:11:00,130 --> 00:11:05,050
the email and so tf-idf is a measure of

282
00:11:02,500 --> 00:11:07,390
how more how much popular is a

283
00:11:05,050 --> 00:11:09,939
particular phrase let's say in a BC

284
00:11:07,390 --> 00:11:11,890
email compared to that phrase appearing

285
00:11:09,940 --> 00:11:13,660
in a random email in your data set and

286
00:11:11,890 --> 00:11:16,569
so the table here on the right shows

287
00:11:13,660 --> 00:11:17,560
some of the the top five most popular

288
00:11:16,570 --> 00:11:20,230
two

289
00:11:17,560 --> 00:11:21,939
word phrases in our data sets you could

290
00:11:20,230 --> 00:11:24,910
see they're all related to some kind of

291
00:11:21,940 --> 00:11:27,790
urgency all right so now let's say you

292
00:11:24,910 --> 00:11:29,140
labeled all your data set the question

293
00:11:27,790 --> 00:11:31,000
is how do you actually go about training

294
00:11:29,140 --> 00:11:33,189
on it so it turns out if you just

295
00:11:31,000 --> 00:11:35,050
naively try to train on a highly

296
00:11:33,190 --> 00:11:37,630
imbalance data set what you'll typically

297
00:11:35,050 --> 00:11:40,180
get is a classifier that always guesses

298
00:11:37,630 --> 00:11:42,040
that the email is innocent right because

299
00:11:40,180 --> 00:11:45,069
that classifier since since an innocent

300
00:11:42,040 --> 00:11:47,349
email is 50,000 times more likely than

301
00:11:45,070 --> 00:11:48,880
an attack right this classifier it

302
00:11:47,350 --> 00:11:52,600
actually got very high accuracy would

303
00:11:48,880 --> 00:11:54,400
get 99.9 a nine eight right so there's a

304
00:11:52,600 --> 00:11:56,920
couple of possible solutions to this we

305
00:11:54,400 --> 00:11:59,610
could either over sample the attacks or

306
00:11:56,920 --> 00:12:02,620
we can understand the in assent emails

307
00:11:59,610 --> 00:12:05,500
we preferred to under sampled the

308
00:12:02,620 --> 00:12:07,930
innocent emails first it has better

309
00:12:05,500 --> 00:12:10,390
performance so we trained over thousands

310
00:12:07,930 --> 00:12:12,339
of innocent emails and attacks rather

311
00:12:10,390 --> 00:12:16,420
than hundreds of millions of emails and

312
00:12:12,339 --> 00:12:18,100
- this prevents us kind of from biasing

313
00:12:16,420 --> 00:12:22,360
the data set with a relatively small

314
00:12:18,100 --> 00:12:24,610
number of attacks now even just kind of

315
00:12:22,360 --> 00:12:27,490
training even even if so let's say you

316
00:12:24,610 --> 00:12:29,500
decide to train on a small number of

317
00:12:27,490 --> 00:12:31,690
innocent emails well if you just

318
00:12:29,500 --> 00:12:33,640
uniformly sample from them that also

319
00:12:31,690 --> 00:12:35,860
yields a classifier with low precision

320
00:12:33,640 --> 00:12:38,380
and the reason for that is you're likely

321
00:12:35,860 --> 00:12:40,540
to kind of miss an important example of

322
00:12:38,380 --> 00:12:42,850
an innocent email that will will be

323
00:12:40,540 --> 00:12:44,920
important for your classifier so in

324
00:12:42,850 --> 00:12:47,230
order to overcome that what we did is we

325
00:12:44,920 --> 00:12:51,099
actually ran a clustering algorithm on

326
00:12:47,230 --> 00:12:54,070
the innocent emails with the feature the

327
00:12:51,100 --> 00:12:56,920
feature set of the of the classifier and

328
00:12:54,070 --> 00:12:58,900
then we proportionally sampled from each

329
00:12:56,920 --> 00:13:01,180
one of the clusters according to the

330
00:12:58,900 --> 00:13:03,579
number of samples that we need so just

331
00:13:01,180 --> 00:13:05,800
to illustrate that let's say we have

332
00:13:03,580 --> 00:13:08,290
only two features so the first step is

333
00:13:05,800 --> 00:13:11,079
to run you know clustering algorithm and

334
00:13:08,290 --> 00:13:13,150
so we map our innocent emails to these

335
00:13:11,080 --> 00:13:15,100
features and then we proportionally

336
00:13:13,150 --> 00:13:16,630
sample randomly from each one of the

337
00:13:15,100 --> 00:13:20,260
clusters and use those samples to

338
00:13:16,630 --> 00:13:22,810
actually train the classifier now one

339
00:13:20,260 --> 00:13:24,850
more important kind of design feature

340
00:13:22,810 --> 00:13:27,069
which turned out to be kind of really

341
00:13:24,850 --> 00:13:29,080
important to us was that you know

342
00:13:27,070 --> 00:13:31,070
historically email security systems are

343
00:13:29,080 --> 00:13:33,530
designed as filters the basic

344
00:13:31,070 --> 00:13:36,110
between the external world kind of the

345
00:13:33,530 --> 00:13:39,170
attacker and the male system and they

346
00:13:36,110 --> 00:13:40,700
filter emails as they come in but as I

347
00:13:39,170 --> 00:13:43,280
mentioned earlier some of our features

348
00:13:40,700 --> 00:13:45,650
require access to historical information

349
00:13:43,280 --> 00:13:48,350
on how people in the organization you

350
00:13:45,650 --> 00:13:50,390
know typically communicate and so we

351
00:13:48,350 --> 00:13:53,330
designed a different architecture kind

352
00:13:50,390 --> 00:13:55,040
of an API based architecture which where

353
00:13:53,330 --> 00:13:57,110
instead of sitting in the mail flow we

354
00:13:55,040 --> 00:14:00,800
actually sit outside of the mail flow

355
00:13:57,110 --> 00:14:03,050
but talk to the api's of cloud email

356
00:14:00,800 --> 00:14:06,339
providers like office 365 which also

357
00:14:03,050 --> 00:14:08,930
provide us with historical email data

358
00:14:06,340 --> 00:14:12,410
all right so now let's see how how we

359
00:14:08,930 --> 00:14:16,069
did so we used an evaluation data set of

360
00:14:12,410 --> 00:14:18,589
we rented got random samples of 200

361
00:14:16,070 --> 00:14:22,180
million emails from Barracuda customers

362
00:14:18,590 --> 00:14:25,940
from a June 2018 this yielded roughly

363
00:14:22,180 --> 00:14:29,660
4000 attacks and we split the training

364
00:14:25,940 --> 00:14:31,880
evaluation data set in half now the

365
00:14:29,660 --> 00:14:34,010
first thing we did is we ran only the

366
00:14:31,880 --> 00:14:35,810
impersonation classifier on its own so

367
00:14:34,010 --> 00:14:38,030
just the part that only looks at the

368
00:14:35,810 --> 00:14:41,030
header and well you'll notice is we got

369
00:14:38,030 --> 00:14:42,920
you know pretty bad false positives

370
00:14:41,030 --> 00:14:45,199
right so one in six thousand emails

371
00:14:42,920 --> 00:14:47,180
that's you know for our our data set

372
00:14:45,200 --> 00:14:48,710
like large organizations could get a

373
00:14:47,180 --> 00:14:51,199
million emails a day so that that's

374
00:14:48,710 --> 00:14:54,050
pretty bad and the precision is also

375
00:14:51,200 --> 00:14:55,970
quite low twelve percent so that kind of

376
00:14:54,050 --> 00:14:58,069
led us to the conclusion that just

377
00:14:55,970 --> 00:14:59,390
looking at the headers is probably not

378
00:14:58,070 --> 00:15:02,570
good enough right we're probably not

379
00:14:59,390 --> 00:15:04,670
going to get high enough precision but

380
00:15:02,570 --> 00:15:07,820
then when we combine the header

381
00:15:04,670 --> 00:15:10,640
classifiers and the body classifiers we

382
00:15:07,820 --> 00:15:12,470
get kind of our target false positive

383
00:15:10,640 --> 00:15:15,920
rate and precision they're able to get

384
00:15:12,470 --> 00:15:17,900
on this data set you know more than one

385
00:15:15,920 --> 00:15:19,550
in five million emails is fall less than

386
00:15:17,900 --> 00:15:23,660
one in five million emails is false

387
00:15:19,550 --> 00:15:25,430
positives and above 98% precision and so

388
00:15:23,660 --> 00:15:28,510
kind of if you compare that to kind of

389
00:15:25,430 --> 00:15:31,280
prior work I think that two really key

390
00:15:28,510 --> 00:15:33,200
the two key things that we leverage are

391
00:15:31,280 --> 00:15:35,510
one the fact that we had access to the

392
00:15:33,200 --> 00:15:37,700
bodies and two supervised learning in

393
00:15:35,510 --> 00:15:40,430
this case allows us to get you know much

394
00:15:37,700 --> 00:15:41,960
much higher precision but of course

395
00:15:40,430 --> 00:15:45,099
supervised learning also has downsides

396
00:15:41,960 --> 00:15:48,910
right so we might be introducing biases

397
00:15:45,100 --> 00:15:51,100
into the way we train our data so

398
00:15:48,910 --> 00:15:53,860
fortunately since you know this this end

399
00:15:51,100 --> 00:15:56,230
up getting rolled out into a commercial

400
00:15:53,860 --> 00:15:58,150
product we actually have live users that

401
00:15:56,230 --> 00:16:00,610
can report attacks to us in real time

402
00:15:58,150 --> 00:16:04,209
and so what we did is we took we kind of

403
00:16:00,610 --> 00:16:06,280
did a small study where we took all the

404
00:16:04,210 --> 00:16:09,490
users that reported missing acts and we

405
00:16:06,280 --> 00:16:12,220
kind of analyzed their results and so we

406
00:16:09,490 --> 00:16:14,290
saw so we chose five random

407
00:16:12,220 --> 00:16:18,070
organizations from within the users that

408
00:16:14,290 --> 00:16:20,860
reported mystics to us and for those

409
00:16:18,070 --> 00:16:24,550
organizations during this time period

410
00:16:20,860 --> 00:16:28,900
we're able to detect 60 true positives

411
00:16:24,550 --> 00:16:30,880
but we missed five emails later

412
00:16:28,900 --> 00:16:35,230
iterations of the classifiers we're able

413
00:16:30,880 --> 00:16:40,120
to fix three of these five attacks and

414
00:16:35,230 --> 00:16:42,940
we're able to detect similar ones so so

415
00:16:40,120 --> 00:16:45,070
to summarize BC is a highly targeted

416
00:16:42,940 --> 00:16:47,290
problem a highly targeted a lot of the

417
00:16:45,070 --> 00:16:49,210
attacks we face today are such attacks

418
00:16:47,290 --> 00:16:52,780
and so it's going to be imbalanced and

419
00:16:49,210 --> 00:16:55,270
so in in order to get high precision for

420
00:16:52,780 --> 00:16:57,610
imbalance problems we oftentimes need to

421
00:16:55,270 --> 00:16:59,800
kind of carefully apply a supervised

422
00:16:57,610 --> 00:17:02,040
learning so thank you very much happy to

423
00:16:59,800 --> 00:17:02,040
take questions

424
00:17:07,220 --> 00:17:10,220
questions

425
00:17:10,910 --> 00:17:15,390
well that's coming up I have a question

426
00:17:12,869 --> 00:17:19,739
how can you talk about how you did the

427
00:17:15,390 --> 00:17:22,589
clustering for to get the benign data

428
00:17:19,740 --> 00:17:26,040
for training like do you like was it

429
00:17:22,589 --> 00:17:27,899
k-means or some mother yes in fact it

430
00:17:26,040 --> 00:17:30,000
doesn't really matter which clustering

431
00:17:27,900 --> 00:17:32,730
algorithm we use yeah so k-means it

432
00:17:30,000 --> 00:17:34,230
would be perfectly fine you just want to

433
00:17:32,730 --> 00:17:37,410
make sure that your clusters aren't you

434
00:17:34,230 --> 00:17:39,630
know too small right so we chose a the

435
00:17:37,410 --> 00:17:40,890
number of clusters up to a point where

436
00:17:39,630 --> 00:17:42,780
the clusters became you know

437
00:17:40,890 --> 00:17:48,570
ridiculously small so let's say less

438
00:17:42,780 --> 00:17:50,970
than a few emails yeah thank you very

439
00:17:48,570 --> 00:17:54,330
much for that and I really like that

440
00:17:50,970 --> 00:17:56,910
clustering method to deal with that with

441
00:17:54,330 --> 00:17:59,668
that sampling thing and I fully agree

442
00:17:56,910 --> 00:18:01,980
that the details of the clustering

443
00:17:59,669 --> 00:18:08,059
algorithm if they mattered then

444
00:18:01,980 --> 00:18:08,059
something's wrong I just wanted to know

445
00:18:08,270 --> 00:18:16,559
how easy it will be for attackers to

446
00:18:12,960 --> 00:18:19,410
adapt their content right because right

447
00:18:16,559 --> 00:18:22,020
now you've got a lot on that and that is

448
00:18:19,410 --> 00:18:23,790
under attacker control of course yeah so

449
00:18:22,020 --> 00:18:26,270
so first of all we have a whole so I

450
00:18:23,790 --> 00:18:28,500
didn't get time to talk about evasions

451
00:18:26,270 --> 00:18:32,160
but so we have a whole section on that

452
00:18:28,500 --> 00:18:33,690
on the paper and so I also just as a

453
00:18:32,160 --> 00:18:35,820
disclaimer this is an evolutionary

454
00:18:33,690 --> 00:18:37,290
process right so I mean unfortunately

455
00:18:35,820 --> 00:18:39,659
when you're dealing with supervised

456
00:18:37,290 --> 00:18:41,760
learning or text-based attacks you can't

457
00:18:39,660 --> 00:18:44,730
have something that's going to guarantee

458
00:18:41,760 --> 00:18:47,330
that you catch all future attacks but we

459
00:18:44,730 --> 00:18:50,100
do try to you know make it relatively

460
00:18:47,330 --> 00:18:52,320
generalizable so for example the text

461
00:18:50,100 --> 00:18:55,860
base classifier uses a relatively large

462
00:18:52,320 --> 00:18:57,480
dictionary so that's one one thing you

463
00:18:55,860 --> 00:18:59,080
know we're potentially looking at

464
00:18:57,480 --> 00:19:01,510
incorporating like

465
00:18:59,080 --> 00:19:04,059
you know deep learning based techniques

466
00:19:01,510 --> 00:19:06,220
to make it even more robust only problem

467
00:19:04,059 --> 00:19:08,649
there is that the texts and emails is

468
00:19:06,220 --> 00:19:11,640
very sparse so you need a lot of samples

469
00:19:08,650 --> 00:19:11,640
to Train deep learning

