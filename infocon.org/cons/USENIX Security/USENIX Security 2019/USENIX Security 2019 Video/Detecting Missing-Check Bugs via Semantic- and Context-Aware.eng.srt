1
00:00:10,640 --> 00:00:16,790
hello everyone my name is Aditya and

2
00:00:13,450 --> 00:00:19,580
this research is a joint work with Q she

3
00:00:16,790 --> 00:00:22,430
and my adviser professor Kang ji Lu in

4
00:00:19,580 --> 00:00:26,659
this talk I'll be talking about some of

5
00:00:22,430 --> 00:00:28,130
our some of our contributions I'll be

6
00:00:26,660 --> 00:00:32,000
sharing with you all our contributions

7
00:00:28,130 --> 00:00:33,830
about about our tool which we which we

8
00:00:32,000 --> 00:00:36,440
use to develop missing check bugs and

9
00:00:33,830 --> 00:00:38,989
the OS kernels this tool is not only

10
00:00:36,440 --> 00:00:41,300
scalable but is also context aware and

11
00:00:38,989 --> 00:00:43,659
interprocedural the some of the

12
00:00:41,300 --> 00:00:45,799
techniques that we use in this tool are

13
00:00:43,659 --> 00:00:47,479
some of the techniques that we proposed

14
00:00:45,799 --> 00:00:49,549
in the stool are identifying critical

15
00:00:47,479 --> 00:00:52,370
variables identifying peers that share

16
00:00:49,549 --> 00:00:54,830
similar context and semantics we also

17
00:00:52,370 --> 00:00:57,949
propose a technique where we reduce the

18
00:00:54,830 --> 00:00:59,989
number of the targets potential targets

19
00:00:57,949 --> 00:01:02,150
for an indirect call using the

20
00:00:59,989 --> 00:01:04,309
techniques that using the techniques in

21
00:01:02,150 --> 00:01:07,010
the tool we were able to find 278

22
00:01:04,309 --> 00:01:09,860
missing check bugs in the latest version

23
00:01:07,010 --> 00:01:12,260
of the Linux kernel and out of them 151

24
00:01:09,860 --> 00:01:14,539
were confirmed by the maintainer and 134

25
00:01:12,260 --> 00:01:20,000
are already existing in the mainline

26
00:01:14,540 --> 00:01:21,680
version so we all know that operating

27
00:01:20,000 --> 00:01:24,470
system kernels are an important piece of

28
00:01:21,680 --> 00:01:27,680
software and because of their complexity

29
00:01:24,470 --> 00:01:30,320
they are often error prone to ensure

30
00:01:27,680 --> 00:01:32,960
that the to ensure that this of the

31
00:01:30,320 --> 00:01:35,059
system is doing as expected developers

32
00:01:32,960 --> 00:01:36,940
often enforce numerous security checks

33
00:01:35,060 --> 00:01:39,890
to guarantee the state of the system

34
00:01:36,940 --> 00:01:44,570
according to our study the Linux kernel

35
00:01:39,890 --> 00:01:46,790
has about 400,000 security checks to

36
00:01:44,570 --> 00:01:49,009
reuse the to reuse some of our previous

37
00:01:46,790 --> 00:01:52,550
work we define a security check as a

38
00:01:49,010 --> 00:01:54,020
following set of patterns so a security

39
00:01:52,550 --> 00:01:56,020
check is basically a conditional

40
00:01:54,020 --> 00:01:58,759
statement which has at least two

41
00:01:56,020 --> 00:02:01,009
branches one of at least one of the

42
00:01:58,760 --> 00:02:03,890
branch does some kind of error handling

43
00:02:01,010 --> 00:02:06,260
and at least one of the branch should

44
00:02:03,890 --> 00:02:10,068
should do the normal execution

45
00:02:06,260 --> 00:02:12,650
a conditional statement in which all of

46
00:02:10,068 --> 00:02:15,170
the all of the branches are either error

47
00:02:12,650 --> 00:02:17,180
handling or all of them don't have error

48
00:02:15,170 --> 00:02:18,399
handling is not considered a security

49
00:02:17,180 --> 00:02:21,400
check

50
00:02:18,400 --> 00:02:23,940
the following slide shows some of the

51
00:02:21,400 --> 00:02:26,430
some of the cases some of

52
00:02:23,940 --> 00:02:28,680
benefits of or you can you can even say

53
00:02:26,430 --> 00:02:30,690
some of the reasons why you use a

54
00:02:28,680 --> 00:02:34,800
security check in the linux kernel or

55
00:02:30,690 --> 00:02:38,310
any OS kernel so despite you have so

56
00:02:34,800 --> 00:02:40,980
many different classes the problem is

57
00:02:38,310 --> 00:02:45,120
this security tricks themselves are

58
00:02:40,980 --> 00:02:48,810
buggy I mean who would have thought of

59
00:02:45,120 --> 00:02:50,640
that but the problem is this a security

60
00:02:48,810 --> 00:02:53,700
the most common case that we have seen

61
00:02:50,640 --> 00:02:56,309
in the most common case that we see in a

62
00:02:53,700 --> 00:02:59,640
security check bug is that the entire

63
00:02:56,310 --> 00:03:03,060
security check is missing right so a

64
00:02:59,640 --> 00:03:04,709
scenario in which there is the Internet

65
00:03:03,060 --> 00:03:07,200
Security check is missing in the

66
00:03:04,710 --> 00:03:09,930
lifetime between the source of the

67
00:03:07,200 --> 00:03:11,640
critical variable and the moment the

68
00:03:09,930 --> 00:03:13,800
critical variable is being used you

69
00:03:11,640 --> 00:03:18,179
basically call that such a scenario as a

70
00:03:13,800 --> 00:03:20,880
missing check bug now why should we

71
00:03:18,180 --> 00:03:24,570
detect now given that I told you how

72
00:03:20,880 --> 00:03:26,670
prevalent security checks are and why we

73
00:03:24,570 --> 00:03:28,650
need to I will tell you why we need to

74
00:03:26,670 --> 00:03:30,929
detect these missing check bugs so we

75
00:03:28,650 --> 00:03:32,820
conducted a empirical study of C V

76
00:03:30,930 --> 00:03:36,050
vulnerabilities over the past two years

77
00:03:32,820 --> 00:03:38,430
and we found out that about 60% of the

78
00:03:36,050 --> 00:03:40,560
vulnerabilities were patched by either

79
00:03:38,430 --> 00:03:43,920
adding a new security check or they have

80
00:03:40,560 --> 00:03:46,490
updated a security check so the impact

81
00:03:43,920 --> 00:03:49,530
of having this missing check bugs are

82
00:03:46,490 --> 00:03:51,330
not having an impact I'm sorry the

83
00:03:49,530 --> 00:03:53,400
impact of not having this security

84
00:03:51,330 --> 00:03:55,440
checks are you can have denial of

85
00:03:53,400 --> 00:03:58,340
service memory corruption information

86
00:03:55,440 --> 00:04:00,540
leakage and many others a

87
00:03:58,340 --> 00:04:02,520
straightforward approach to detect

88
00:04:00,540 --> 00:04:06,150
missing check bugs are to enumerate all

89
00:04:02,520 --> 00:04:08,130
the possible rules and notify not for

90
00:04:06,150 --> 00:04:10,350
the categories not for the classes and

91
00:04:08,130 --> 00:04:12,299
detect these bugs however this technique

92
00:04:10,350 --> 00:04:14,790
is not scalable and you cannot

93
00:04:12,300 --> 00:04:18,810
generalize this this rule and emulation

94
00:04:14,790 --> 00:04:20,909
to all all classes of bugs instead we

95
00:04:18,810 --> 00:04:23,190
probably consider an alternative

96
00:04:20,910 --> 00:04:25,590
approach called cross checking this is

97
00:04:23,190 --> 00:04:28,710
basically a static analysis no it's a

98
00:04:25,590 --> 00:04:31,260
statistical analysis method where you

99
00:04:28,710 --> 00:04:33,210
don't care about what they measure you

100
00:04:31,260 --> 00:04:34,810
don't care what the ground truth is you

101
00:04:33,210 --> 00:04:37,479
just assign the measure

102
00:04:34,810 --> 00:04:40,540
they rule within a group to the entire

103
00:04:37,480 --> 00:04:43,800
group and then you say any deviations

104
00:04:40,540 --> 00:04:46,900
from this rule are basically bugs this

105
00:04:43,800 --> 00:04:49,900
this idea underlies the assumption that

106
00:04:46,900 --> 00:04:52,810
the kernel in general is correct and

107
00:04:49,900 --> 00:04:57,299
bugs are basically the outliers in that

108
00:04:52,810 --> 00:05:00,310
to drive home this point the following

109
00:04:57,300 --> 00:05:01,780
figure shows you what a deadbolt is so

110
00:05:00,310 --> 00:05:04,360
in a dough

111
00:05:01,780 --> 00:05:06,940
let's take an example of ten doors and

112
00:05:04,360 --> 00:05:09,400
out of this ten nine have a deadbolt and

113
00:05:06,940 --> 00:05:10,990
one doesn't have a deadbolt so you can

114
00:05:09,400 --> 00:05:13,270
more or less say that the one that

115
00:05:10,990 --> 00:05:15,790
doesn't have a deadbolt is likely to be

116
00:05:13,270 --> 00:05:18,190
a bug unfortunately it doesn't consider

117
00:05:15,790 --> 00:05:20,110
a scenario where the the door which

118
00:05:18,190 --> 00:05:23,190
doesn't have a deadbolt might be using

119
00:05:20,110 --> 00:05:25,180
an IOT smart home security device so

120
00:05:23,190 --> 00:05:28,870
cross-checking doesn't consider this

121
00:05:25,180 --> 00:05:31,540
type of information in it now despite

122
00:05:28,870 --> 00:05:34,210
the simplicity of cross checking it's

123
00:05:31,540 --> 00:05:37,750
not straightforward to use use it right

124
00:05:34,210 --> 00:05:40,299
away for detecting bugs we identified at

125
00:05:37,750 --> 00:05:42,310
least three challenges in in this

126
00:05:40,300 --> 00:05:45,669
approach the first one is scalability

127
00:05:42,310 --> 00:05:49,330
how do you know which of this variables

128
00:05:45,669 --> 00:05:51,400
should I start checking for we think

129
00:05:49,330 --> 00:05:53,289
that if you identify what the critical

130
00:05:51,400 --> 00:05:55,419
variables are and just check them I

131
00:05:53,289 --> 00:05:58,840
think we can solve scalability the

132
00:05:55,419 --> 00:06:01,359
second case is similarity what do you

133
00:05:58,840 --> 00:06:03,190
compare against like you want to get a

134
00:06:01,360 --> 00:06:07,690
group that's good but how do you know

135
00:06:03,190 --> 00:06:09,880
what what constitutes a group so we this

136
00:06:07,690 --> 00:06:11,950
is one of our major contributions in

137
00:06:09,880 --> 00:06:14,650
this paper where we identify similar

138
00:06:11,950 --> 00:06:17,260
context peers and the third case is

139
00:06:14,650 --> 00:06:19,690
granularity you want to model you want

140
00:06:17,260 --> 00:06:21,909
to model your conditional statements at

141
00:06:19,690 --> 00:06:25,450
an appropriate level for example if you

142
00:06:21,910 --> 00:06:27,400
think that a conditional statement which

143
00:06:25,450 --> 00:06:29,650
is taking less than 0 and a conditional

144
00:06:27,400 --> 00:06:31,659
statement which is taking less than 10

145
00:06:29,650 --> 00:06:33,609
you don't want to model them as two

146
00:06:31,660 --> 00:06:39,190
different constraints you want to get an

147
00:06:33,610 --> 00:06:41,620
optimal granularity level so we propose

148
00:06:39,190 --> 00:06:45,820
to solve this challenges we basically

149
00:06:41,620 --> 00:06:48,660
propose a tool called tricks and it in a

150
00:06:45,820 --> 00:06:51,790
high level we solve this in four stages

151
00:06:48,660 --> 00:06:55,270
I'll be describing this for challenges

152
00:06:51,790 --> 00:06:57,880
in a short while to solve the problem of

153
00:06:55,270 --> 00:07:00,490
to solve the problem of scalability we

154
00:06:57,880 --> 00:07:03,820
basically use two insights the first

155
00:07:00,490 --> 00:07:07,030
insight is any variable that is checked

156
00:07:03,820 --> 00:07:08,820
is more likely to be critical and the

157
00:07:07,030 --> 00:07:11,138
second thing is the second insight is

158
00:07:08,820 --> 00:07:13,570
often variables propagate their

159
00:07:11,139 --> 00:07:17,169
criticalness to its - in its

160
00:07:13,570 --> 00:07:19,480
neighborhood so our approach is

161
00:07:17,169 --> 00:07:21,789
basically to identify these check

162
00:07:19,480 --> 00:07:25,780
variables and then we want to find out

163
00:07:21,790 --> 00:07:28,180
this source and use users so in the code

164
00:07:25,780 --> 00:07:31,150
snippet that you see the first line

165
00:07:28,180 --> 00:07:33,040
shows the source the if condition is the

166
00:07:31,150 --> 00:07:35,380
check and the last line is basically

167
00:07:33,040 --> 00:07:40,300
they use so we want to basically

168
00:07:35,380 --> 00:07:43,860
identify this type of code snippets the

169
00:07:40,300 --> 00:07:47,050
second case is to identify similarity

170
00:07:43,860 --> 00:07:51,850
okay I think we lost some code that's

171
00:07:47,050 --> 00:07:53,919
right but yeah so di di why do we need

172
00:07:51,850 --> 00:07:55,960
similar pairs the first thing is since

173
00:07:53,919 --> 00:07:58,060
we are using a statistical method it's

174
00:07:55,960 --> 00:08:00,729
it's important for us to have a large

175
00:07:58,060 --> 00:08:03,010
set so that we get better better results

176
00:08:00,729 --> 00:08:05,500
accuracy improves by having a large

177
00:08:03,010 --> 00:08:07,300
large training data you can say and it's

178
00:08:05,500 --> 00:08:10,510
also important that you compare apples

179
00:08:07,300 --> 00:08:11,680
for apples not something like you need

180
00:08:10,510 --> 00:08:14,770
you know but you want to get accurate

181
00:08:11,680 --> 00:08:17,410
context and semantics you want to

182
00:08:14,770 --> 00:08:20,710
compare peers that have same properties

183
00:08:17,410 --> 00:08:24,070
the observation is this in the Linux

184
00:08:20,710 --> 00:08:26,109
kernel similar context peers are often

185
00:08:24,070 --> 00:08:29,229
coming from either call instructions be

186
00:08:26,110 --> 00:08:32,919
indirect calls or or the return

187
00:08:29,229 --> 00:08:35,650
instructions blindly performing a slice

188
00:08:32,919 --> 00:08:38,799
from would lead to path explosion

189
00:08:35,650 --> 00:08:40,809
problem so we had to identify this by a

190
00:08:38,799 --> 00:08:42,819
certain set of properties in the

191
00:08:40,809 --> 00:08:45,219
following in the following three figures

192
00:08:42,820 --> 00:08:48,940
you see that whenever you have an

193
00:08:45,220 --> 00:08:51,190
indirect call based on based on the

194
00:08:48,940 --> 00:08:54,490
arguments you can say that all the

195
00:08:51,190 --> 00:08:57,430
Cawley's are potentially or potentially

196
00:08:54,490 --> 00:08:58,550
similar context pairs similarly we have

197
00:08:57,430 --> 00:09:00,859
written returning

198
00:08:58,550 --> 00:09:02,920
struction which is basically the return

199
00:09:00,860 --> 00:09:05,330
value of a function and then you have

200
00:09:02,920 --> 00:09:08,329
the direct call which takes the

201
00:09:05,330 --> 00:09:10,850
parameter of a function the other two

202
00:09:08,330 --> 00:09:12,860
cases are discussed in the paper but I

203
00:09:10,850 --> 00:09:14,930
would like to spend some time talking

204
00:09:12,860 --> 00:09:16,970
about indirect calls because of their

205
00:09:14,930 --> 00:09:23,149
importance and the prevalence in the

206
00:09:16,970 --> 00:09:25,760
Linux kernel now how do we why do we

207
00:09:23,149 --> 00:09:28,579
want to reduce the targets of an

208
00:09:25,760 --> 00:09:31,370
indirect call the first thing is Lin the

209
00:09:28,579 --> 00:09:34,519
Linux kernel is huge you have about I

210
00:09:31,370 --> 00:09:37,010
would say close to 60,000 call sites of

211
00:09:34,519 --> 00:09:39,140
indirect call and because we are using a

212
00:09:37,010 --> 00:09:41,180
static analysis technique the call graph

213
00:09:39,140 --> 00:09:45,860
precision is important for us to get

214
00:09:41,180 --> 00:09:48,109
accurate results now in that we will

215
00:09:45,860 --> 00:09:50,959
decide peers of an indirect call based

216
00:09:48,110 --> 00:09:53,680
on based on the type of arguments they

217
00:09:50,959 --> 00:09:56,180
take if the number of arguments are are

218
00:09:53,680 --> 00:09:58,370
the number and type of arguments are

219
00:09:56,180 --> 00:10:03,260
same we basically assume that these are

220
00:09:58,370 --> 00:10:06,829
these aren't similar pairs but as the

221
00:10:03,260 --> 00:10:08,600
current techniques show that just by

222
00:10:06,829 --> 00:10:10,399
perform the current at least the state

223
00:10:08,600 --> 00:10:12,500
of art is to use either points to

224
00:10:10,399 --> 00:10:15,200
analysis or function type matching we

225
00:10:12,500 --> 00:10:19,279
identify that they are prone to having a

226
00:10:15,200 --> 00:10:22,670
huge depth they're prone to having a

227
00:10:19,279 --> 00:10:24,589
large number of false positives so in

228
00:10:22,670 --> 00:10:27,880
this approach our approach was to

229
00:10:24,589 --> 00:10:31,279
basically use two-level type analysis

230
00:10:27,880 --> 00:10:33,649
what does what does this approach to the

231
00:10:31,279 --> 00:10:37,010
inside there okay the observation is

232
00:10:33,649 --> 00:10:40,190
this in the Linux kernel at least 90% of

233
00:10:37,010 --> 00:10:43,779
the indirect calls are basically stored

234
00:10:40,190 --> 00:10:46,640
in a struct variable and often these are

235
00:10:43,779 --> 00:10:49,730
interfaces they are the interfaces which

236
00:10:46,640 --> 00:10:52,189
are used to implement them all these

237
00:10:49,730 --> 00:10:55,070
similar pair similar context functions

238
00:10:52,190 --> 00:10:57,290
you can think of them as something of a

239
00:10:55,070 --> 00:11:00,949
you if you take an example of a file

240
00:10:57,290 --> 00:11:03,079
system you see that the open call open

241
00:11:00,949 --> 00:11:04,819
system call or read system call across

242
00:11:03,079 --> 00:11:06,859
file systems they basically do the same

243
00:11:04,820 --> 00:11:10,610
thing but there they may be implemented

244
00:11:06,860 --> 00:11:11,810
in a different way so going back to our

245
00:11:10,610 --> 00:11:14,270
approach of two-level

246
00:11:11,810 --> 00:11:16,630
type analysis we rely on function

247
00:11:14,270 --> 00:11:18,920
function type matching which basically

248
00:11:16,630 --> 00:11:21,010
it's basically eliminates all those

249
00:11:18,920 --> 00:11:24,199
indirect calls which don't have similar

250
00:11:21,010 --> 00:11:27,620
arguments or similar type of arguments

251
00:11:24,200 --> 00:11:31,550
the second layer is stock type matching

252
00:11:27,620 --> 00:11:34,310
in this case we basically identify how

253
00:11:31,550 --> 00:11:35,719
in which field was this truck loaded in

254
00:11:34,310 --> 00:11:38,540
which field about the function point are

255
00:11:35,720 --> 00:11:40,820
loaded and stored and how is it being

256
00:11:38,540 --> 00:11:43,130
loaded while you are dereferencing the

257
00:11:40,820 --> 00:11:45,950
function pointer to make this approach

258
00:11:43,130 --> 00:11:49,270
sound we use escape analysis and we also

259
00:11:45,950 --> 00:11:51,650
fall back to the basic type first level

260
00:11:49,270 --> 00:11:53,990
the function type matching when we are

261
00:11:51,650 --> 00:11:58,449
unable to decide which which field was

262
00:11:53,990 --> 00:11:58,450
which field is the function pointer from

263
00:11:59,020 --> 00:12:04,579
okay so the third after you generate

264
00:12:02,089 --> 00:12:07,250
these peer slices we use modeling

265
00:12:04,580 --> 00:12:09,200
constraints where we determine what at

266
00:12:07,250 --> 00:12:11,390
what kind at what granularity you want

267
00:12:09,200 --> 00:12:14,000
to reduce a quad granularity you want to

268
00:12:11,390 --> 00:12:16,939
model these conditional statements after

269
00:12:14,000 --> 00:12:19,280
you model this constraints we propose we

270
00:12:16,940 --> 00:12:22,310
use a a single hyper parameter in our

271
00:12:19,280 --> 00:12:26,420
system called called relative frequency

272
00:12:22,310 --> 00:12:28,520
which we assign a value of 0.15 the

273
00:12:26,420 --> 00:12:30,439
relative frequency is basically the

274
00:12:28,520 --> 00:12:32,449
ratio of number of peer slices which

275
00:12:30,440 --> 00:12:35,839
miss a security check to the total

276
00:12:32,450 --> 00:12:37,820
number of slices we determine this value

277
00:12:35,839 --> 00:12:40,790
by performing an empirical study of

278
00:12:37,820 --> 00:12:43,490
security patches from the Linux kernel

279
00:12:40,790 --> 00:12:46,459
and we will chose this value where we

280
00:12:43,490 --> 00:12:47,930
minimized all false negatives but we we

281
00:12:46,460 --> 00:12:53,240
were ok with certain set of false

282
00:12:47,930 --> 00:12:57,020
positives given that I've described the

283
00:12:53,240 --> 00:13:00,350
principles behind tricks behind tricks

284
00:12:57,020 --> 00:13:05,560
we want to be implemented them as a set

285
00:13:00,350 --> 00:13:08,570
of LLVM passes the code has about 4.5

286
00:13:05,560 --> 00:13:13,300
thousand lines of C++ code and it took

287
00:13:08,570 --> 00:13:13,300
about 64 minutes to complete

288
00:13:13,520 --> 00:13:19,400
because LLVM because Linux has a

289
00:13:16,760 --> 00:13:22,580
different set of architectures we only

290
00:13:19,400 --> 00:13:24,949
focused on x86 architecture and it uses

291
00:13:22,580 --> 00:13:25,460
an all yes conflict all yes config is

292
00:13:24,950 --> 00:13:28,100
basically

293
00:13:25,460 --> 00:13:31,160
trying to maximize the number of number

294
00:13:28,100 --> 00:13:35,000
of potential cases you can cover and we

295
00:13:31,160 --> 00:13:38,029
identified about 804 bugs also we use

296
00:13:35,000 --> 00:13:43,750
ranking heuristic to prioritize which

297
00:13:38,029 --> 00:13:46,490
bugs we want to look at so when you

298
00:13:43,750 --> 00:13:49,399
given that we have run it run the tool

299
00:13:46,490 --> 00:13:51,950
for 64 minutes following up the results

300
00:13:49,399 --> 00:13:54,950
that are that are interesting to you

301
00:13:51,950 --> 00:13:56,480
guys so with out of the 278 new bugs

302
00:13:54,950 --> 00:14:00,080
that you have found that we have found

303
00:13:56,480 --> 00:14:02,570
we we have 134 of them were already

304
00:14:00,080 --> 00:14:05,870
applied to the mainline and about 100 of

305
00:14:02,570 --> 00:14:09,290
them were confirmed or fixed within one

306
00:14:05,870 --> 00:14:12,320
week of submission further we have about

307
00:14:09,290 --> 00:14:14,630
195 bugs that were found in the drivers

308
00:14:12,320 --> 00:14:16,459
module and over twenty-seven of them

309
00:14:14,630 --> 00:14:20,000
have more than one bug within a single

310
00:14:16,459 --> 00:14:23,060
module I mean this still falls back upon

311
00:14:20,000 --> 00:14:28,220
the previous research that drivers are

312
00:14:23,060 --> 00:14:32,630
still buggy also also the latent period

313
00:14:28,220 --> 00:14:35,000
which says it says the time it takes

314
00:14:32,630 --> 00:14:37,250
from the introduction of the patch to

315
00:14:35,000 --> 00:14:40,459
the time it takes to fix it it's about

316
00:14:37,250 --> 00:14:45,170
four years and seven months and 10% of

317
00:14:40,459 --> 00:14:47,029
the bugs have about 10 years now now

318
00:14:45,170 --> 00:14:49,670
this may seem a bit dramatic but since

319
00:14:47,029 --> 00:14:51,950
since Crick's is a static analysis tool

320
00:14:49,670 --> 00:14:54,469
its inheriting all the limitations that

321
00:14:51,950 --> 00:14:56,779
static analysis tool can have however

322
00:14:54,470 --> 00:15:00,020
people I would like to mention one of

323
00:14:56,779 --> 00:15:02,390
the limitation that we basically are

324
00:15:00,020 --> 00:15:07,220
basing or tool on its determining the

325
00:15:02,390 --> 00:15:10,579
context so whenever you have a critical

326
00:15:07,220 --> 00:15:12,770
error that has happened and and in the

327
00:15:10,579 --> 00:15:15,109
cleanup path if there are functions that

328
00:15:12,770 --> 00:15:18,140
are if there are functions that are

329
00:15:15,110 --> 00:15:20,120
cleaning up the maintenance have very

330
00:15:18,140 --> 00:15:22,520
reluctant to add a security check in

331
00:15:20,120 --> 00:15:24,709
this path because they do understand

332
00:15:22,520 --> 00:15:26,720
that if the system is crashing adding a

333
00:15:24,709 --> 00:15:31,969
security check is often the least of

334
00:15:26,720 --> 00:15:35,060
their concerns so in this talk I

335
00:15:31,970 --> 00:15:37,290
basically am reiterating the fact that

336
00:15:35,060 --> 00:15:40,170
security checks are critical

337
00:15:37,290 --> 00:15:43,349
but but they're still prone to bugs we

338
00:15:40,170 --> 00:15:46,889
introduced we be shared with I shared

339
00:15:43,350 --> 00:15:48,990
with you the idea of finding modeling

340
00:15:46,889 --> 00:15:52,079
and cross-checking peer slices that have

341
00:15:48,990 --> 00:15:56,190
semantic and context-aware properties

342
00:15:52,079 --> 00:15:58,258
and we have about 93% reduction in the

343
00:15:56,190 --> 00:16:01,019
indirect coil targets compared to the

344
00:15:58,259 --> 00:16:03,029
existing techniques and we are we open

345
00:16:01,019 --> 00:16:07,130
sourced our code and it's available at

346
00:16:03,029 --> 00:16:10,610
this link right so with that I'm happy

347
00:16:07,130 --> 00:16:10,610
to take any questions

348
00:16:11,030 --> 00:16:16,880
[Applause]

349
00:16:24,230 --> 00:16:28,350
thank you this is a very interesting

350
00:16:26,279 --> 00:16:30,209
topic I'm always interested in sort of

351
00:16:28,350 --> 00:16:32,850
simple ways of finding trivial but

352
00:16:30,209 --> 00:16:34,410
common issues I'm one particular issue

353
00:16:32,850 --> 00:16:36,629
that is fairly common is where a

354
00:16:34,410 --> 00:16:38,670
variable is checked but after it's been

355
00:16:36,629 --> 00:16:42,540
used can your method be extended to

356
00:16:38,670 --> 00:16:45,719
handle that case as well so the question

357
00:16:42,540 --> 00:16:49,290
is you check no you use and then you

358
00:16:45,720 --> 00:16:51,709
check in that particular case the source

359
00:16:49,290 --> 00:16:54,569
is not basically at the check it's

360
00:16:51,709 --> 00:16:57,479
somewhere before that you could think of

361
00:16:54,569 --> 00:16:58,800
this as an uninitialized variable would

362
00:16:57,480 --> 00:17:01,319
you say something like that you could

363
00:16:58,800 --> 00:17:03,689
think of something as a variable that's

364
00:17:01,319 --> 00:17:06,510
coming from the user space would that

365
00:17:03,689 --> 00:17:07,889
fit your description I mean like I mean

366
00:17:06,510 --> 00:17:09,179
example that has been common in the

367
00:17:07,890 --> 00:17:10,740
kernel in the past is where you get a

368
00:17:09,179 --> 00:17:12,659
pointer and you got something with it

369
00:17:10,740 --> 00:17:15,209
and then you check if it's null right so

370
00:17:12,659 --> 00:17:18,510
yeah that that would probably fall in

371
00:17:15,209 --> 00:17:20,490
the case of the source source yes we do

372
00:17:18,510 --> 00:17:23,908
handle those cases and our tool does

373
00:17:20,490 --> 00:17:25,049
handle those cases cool do you think

374
00:17:23,909 --> 00:17:29,039
this can work on things other than the

375
00:17:25,049 --> 00:17:31,889
Linux kernel so we are if we actually

376
00:17:29,039 --> 00:17:34,470
applied this tool to even the FreeBSD

377
00:17:31,890 --> 00:17:38,850
but at the time of submission we

378
00:17:34,470 --> 00:17:40,559
couldn't submit the patches so we didn't

379
00:17:38,850 --> 00:17:42,539
mention any of this but this technique

380
00:17:40,559 --> 00:17:44,158
is actually scalable to any it's

381
00:17:42,539 --> 00:17:47,039
applicable to any OS kernels

382
00:17:44,159 --> 00:17:49,110
I mean FreeBSD still uses the same idea

383
00:17:47,039 --> 00:17:53,940
of structures it still has the same

384
00:17:49,110 --> 00:17:59,459
concept of security checking thank you I

385
00:17:53,940 --> 00:18:00,929
look forward to trying this so can you

386
00:17:59,460 --> 00:18:03,030
tell us a little bit about those bugs

387
00:18:00,929 --> 00:18:05,150
they're like 800 then you answer like

388
00:18:03,030 --> 00:18:08,280
280 something yeah

389
00:18:05,150 --> 00:18:13,169
what I what were they actually serious

390
00:18:08,280 --> 00:18:17,610
what what's up so oh okay so the idea is

391
00:18:13,169 --> 00:18:20,640
this consider an example where you're

392
00:18:17,610 --> 00:18:22,740
allocating memory with KML oak there is

393
00:18:20,640 --> 00:18:24,630
some kind of context which wasn't

394
00:18:22,740 --> 00:18:26,220
actually captured so you can say

395
00:18:24,630 --> 00:18:29,370
something like if you look at the

396
00:18:26,220 --> 00:18:31,260
arguments there is an argument called

397
00:18:29,370 --> 00:18:33,539
GFP no file

398
00:18:31,260 --> 00:18:36,240
the memory allocation is done without

399
00:18:33,539 --> 00:18:38,158
any failures like there is no at the

400
00:18:36,240 --> 00:18:41,549
memory is allocated in an atomic context

401
00:18:38,159 --> 00:18:45,240
so most of this bugs what we have found

402
00:18:41,549 --> 00:18:47,879
there they the same valid to us but when

403
00:18:45,240 --> 00:18:49,770
you put this the same question to the

404
00:18:47,880 --> 00:18:53,039
maintainer there would be suggesting

405
00:18:49,770 --> 00:18:57,690
that these bugs don't basically occur in

406
00:18:53,039 --> 00:19:00,029
the real time so yes dual has false

407
00:18:57,690 --> 00:19:02,070
positives but I would also like to

408
00:19:00,029 --> 00:19:04,289
mention a second category which wasn't

409
00:19:02,070 --> 00:19:07,889
mentioned in the talk or it's not even

410
00:19:04,289 --> 00:19:11,850
present or it was just vaguely present

411
00:19:07,890 --> 00:19:14,340
in the paper because we are doing a two

412
00:19:11,850 --> 00:19:16,889
level search where we search from source

413
00:19:14,340 --> 00:19:19,289
to check and then use and as well as

414
00:19:16,890 --> 00:19:21,870
from use to check and to the source we

415
00:19:19,289 --> 00:19:24,120
do two directional we do two ways of

416
00:19:21,870 --> 00:19:26,879
checking the code there were many

417
00:19:24,120 --> 00:19:28,649
instances where there's 804 cases had

418
00:19:26,880 --> 00:19:31,200
duplicates like the same bug was

419
00:19:28,649 --> 00:19:33,779
reported in two directions so I would

420
00:19:31,200 --> 00:19:35,970
say probably they constitute about 15

421
00:19:33,779 --> 00:19:38,159
percent of the cases we didn't mention

422
00:19:35,970 --> 00:19:40,500
this because it's still a limitation

423
00:19:38,159 --> 00:19:43,080
like we couldn't remove these cases

424
00:19:40,500 --> 00:19:45,990
properly I would say that's one case the

425
00:19:43,080 --> 00:19:48,629
third case is obviously pointer analysis

426
00:19:45,990 --> 00:19:51,179
we make use of extensible pointer

427
00:19:48,630 --> 00:19:54,270
analysis but you know we we don't have

428
00:19:51,179 --> 00:19:56,100
an expensive like we don't our prime

429
00:19:54,270 --> 00:19:58,799
goal was to make sure that we are doing

430
00:19:56,100 --> 00:20:00,840
this things faster and rather than doing

431
00:19:58,799 --> 00:20:04,700
some kind of Anderson analysis which is

432
00:20:00,840 --> 00:20:09,570
like too time-consuming so we sort of

433
00:20:04,700 --> 00:20:11,220
you know skip we chose to we were

434
00:20:09,570 --> 00:20:14,789
willing to take some false positives in

435
00:20:11,220 --> 00:20:18,149
this case given pointer analysis is not

436
00:20:14,789 --> 00:20:22,540
a easy problem to solve

437
00:20:18,149 --> 00:20:27,329
yeah thanks right let's think again

438
00:20:22,540 --> 00:20:27,329
[Applause]

