1
00:00:10,650 --> 00:00:15,890
hi everyone thank you for coming to my

2
00:00:12,900 --> 00:00:17,930
presentation my name is Giuseppe

3
00:00:15,890 --> 00:00:19,400
Savannah State University and I'm

4
00:00:17,930 --> 00:00:22,460
excited to be here today to present

5
00:00:19,400 --> 00:00:24,580
entrust regulating sensor access by

6
00:00:22,460 --> 00:00:27,520
cooperating program via delegation graph

7
00:00:24,580 --> 00:00:29,689
this work is a joint work with

8
00:00:27,520 --> 00:00:33,680
researcher from the alan turing

9
00:00:29,689 --> 00:00:35,810
institute in the UK the University of

10
00:00:33,680 --> 00:00:39,050
Munich in Germany and also researcher

11
00:00:35,810 --> 00:00:42,160
from Symantec research lab this work is

12
00:00:39,050 --> 00:00:46,010
also sponsored by the Army Research Lab

13
00:00:42,160 --> 00:00:48,919
let's start by talking about the

14
00:00:46,010 --> 00:00:50,510
cooperating program our structure so we

15
00:00:48,920 --> 00:00:52,579
are all familiar with this abstraction

16
00:00:50,510 --> 00:00:55,640
because we have seen in current

17
00:00:52,579 --> 00:00:57,680
operating system so we have a user that

18
00:00:55,640 --> 00:01:00,140
is instant setting our voice commands

19
00:00:57,680 --> 00:01:01,699
such as take a selfie and this voice

20
00:01:00,140 --> 00:01:04,910
command is processed by a voice

21
00:01:01,699 --> 00:01:07,759
assistant the voice assistant is going

22
00:01:04,910 --> 00:01:10,399
to rely on a another program for example

23
00:01:07,760 --> 00:01:11,810
the camera in this case and the camera

24
00:01:10,400 --> 00:01:15,380
app is going to perform the operation

25
00:01:11,810 --> 00:01:18,080
that was requested by the user and then

26
00:01:15,380 --> 00:01:20,990
this program is going to request

27
00:01:18,080 --> 00:01:26,210
permission to access the camera in order

28
00:01:20,990 --> 00:01:28,449
to capture a frame for servicing the

29
00:01:26,210 --> 00:01:31,039
operation requested by the user the

30
00:01:28,450 --> 00:01:33,280
question is here is that what can go

31
00:01:31,040 --> 00:01:33,280
wrong

32
00:01:33,520 --> 00:01:38,030
so there have been several articles in

33
00:01:36,290 --> 00:01:42,350
the research community as well as in

34
00:01:38,030 --> 00:01:45,860
different technical magazine that showed

35
00:01:42,350 --> 00:01:50,479
that application can collude and then

36
00:01:45,860 --> 00:01:52,219
they can cooperate in order to leverage

37
00:01:50,479 --> 00:01:54,740
permission that they have in order to

38
00:01:52,219 --> 00:01:57,408
violate the user privacy as well as

39
00:01:54,740 --> 00:02:00,020
there have been article mentioning that

40
00:01:57,409 --> 00:02:03,530
voice assistant can be exploded and can

41
00:02:00,020 --> 00:02:06,789
open new attack vectors so let's go into

42
00:02:03,530 --> 00:02:08,930
the details of this we have seen the

43
00:02:06,789 --> 00:02:11,840
scenario before where the transfer

44
00:02:08,930 --> 00:02:14,330
assistant is going to rely on camera in

45
00:02:11,840 --> 00:02:16,070
order to perform an operation what if

46
00:02:14,330 --> 00:02:18,650
the camera is actually a Trojan horse

47
00:02:16,070 --> 00:02:20,570
that is leveraging the permission that

48
00:02:18,650 --> 00:02:22,880
has to access the GPS than the

49
00:02:20,570 --> 00:02:25,190
microphone in order to record the

50
00:02:22,880 --> 00:02:28,099
location where the selfie was taken ball

51
00:02:25,190 --> 00:02:29,390
so record a short audio in order to

52
00:02:28,099 --> 00:02:32,000
assist raid person

53
00:02:29,390 --> 00:02:35,179
information in the paper we also

54
00:02:32,000 --> 00:02:37,580
mentioned two more attack vectors that

55
00:02:35,180 --> 00:02:40,220
are confused everywhere the voice assist

56
00:02:37,580 --> 00:02:43,340
in this case is untrusted and is going

57
00:02:40,220 --> 00:02:46,430
to trick the screenshot service in order

58
00:02:43,340 --> 00:02:48,250
to capture a screenshot in a specific

59
00:02:46,430 --> 00:02:50,840
context such as when the user is

60
00:02:48,250 --> 00:02:53,180
accessing sensitive information such as

61
00:02:50,840 --> 00:02:55,370
secure notes or other type of

62
00:02:53,180 --> 00:02:56,959
information and then we have another

63
00:02:55,370 --> 00:03:00,080
attack where we have a man-in-the-middle

64
00:02:56,959 --> 00:03:02,270
attack that we are going to see more in

65
00:03:00,080 --> 00:03:04,820
details in this presentation where we

66
00:03:02,270 --> 00:03:06,709
have a trusted assistant that has been

67
00:03:04,820 --> 00:03:09,470
used by the user to the Bosnia bank

68
00:03:06,709 --> 00:03:11,690
check so the target here is our banking

69
00:03:09,470 --> 00:03:14,000
app that is supposed to take a picture

70
00:03:11,690 --> 00:03:16,070
of the Chacon and deposit the cheque in

71
00:03:14,000 --> 00:03:17,950
a bank account unfortunately what

72
00:03:16,070 --> 00:03:20,930
happened is that the request by the

73
00:03:17,950 --> 00:03:24,619
trust assistant is intercepted by the

74
00:03:20,930 --> 00:03:26,959
camera the camera app is going to take a

75
00:03:24,620 --> 00:03:28,760
screen a picture of the check and then

76
00:03:26,959 --> 00:03:32,750
send it to a remote server that is

77
00:03:28,760 --> 00:03:35,630
controlled by an adversary so let's see

78
00:03:32,750 --> 00:03:37,700
Adam of this attack I have it right here

79
00:03:35,630 --> 00:03:41,120
so what happened here you will see that

80
00:03:37,700 --> 00:03:43,910
the asset the user is going to ask to

81
00:03:41,120 --> 00:03:45,680
deposit a check and then we will see the

82
00:03:43,910 --> 00:03:48,049
banking uptick in the picture of the

83
00:03:45,680 --> 00:03:50,810
check unfortunate I was showing the demo

84
00:03:48,049 --> 00:03:53,780
that also the camera have intercepted

85
00:03:50,810 --> 00:03:56,480
this request and actually the taking a

86
00:03:53,780 --> 00:03:59,060
picture of the check that is going to be

87
00:03:56,480 --> 00:04:02,649
sent to the adversary that is

88
00:03:59,060 --> 00:04:02,650
controlling a specific remote server

89
00:04:09,840 --> 00:04:13,980
so this is the banking up and now I'm

90
00:04:12,090 --> 00:04:16,889
going to open the camera plans as you

91
00:04:13,980 --> 00:04:19,260
guys can see the check is also present

92
00:04:16,889 --> 00:04:24,030
as a picture that was already taken by

93
00:04:19,260 --> 00:04:25,830
the application so what is this

94
00:04:24,030 --> 00:04:29,190
afternoon right we are all familiar with

95
00:04:25,830 --> 00:04:31,349
the first use authorization model it is

96
00:04:29,190 --> 00:04:34,200
using current operating system and this

97
00:04:31,350 --> 00:04:36,200
model allows to request access only at

98
00:04:34,200 --> 00:04:39,979
the first time a specific sensor is used

99
00:04:36,200 --> 00:04:41,669
by a program so to solve this issue

100
00:04:39,980 --> 00:04:44,430
researchers propose a different

101
00:04:41,669 --> 00:04:46,200
mechanism one is to bind the user input

102
00:04:44,430 --> 00:04:49,620
event as well as the specific user

103
00:04:46,200 --> 00:04:52,139
interface to the request of a specific

104
00:04:49,620 --> 00:04:54,300
sensor example are like using

105
00:04:52,139 --> 00:04:56,970
information such as is the application

106
00:04:54,300 --> 00:05:00,180
ran in the foreground background is the

107
00:04:56,970 --> 00:05:02,180
application presenting a specific UI

108
00:05:00,180 --> 00:05:04,860
context to the user and so forth

109
00:05:02,180 --> 00:05:07,500
unfortunately these allows to prevent

110
00:05:04,860 --> 00:05:10,260
some of the tax but these models are not

111
00:05:07,500 --> 00:05:12,840
modeling input event delegation where a

112
00:05:10,260 --> 00:05:16,710
specific input is received by program I

113
00:05:12,840 --> 00:05:18,359
but then is forwarded to program J in

114
00:05:16,710 --> 00:05:21,299
this case the camera that is going to

115
00:05:18,360 --> 00:05:23,430
perform the overage other researcher

116
00:05:21,300 --> 00:05:25,680
also proposed to restrict and regulate

117
00:05:23,430 --> 00:05:27,600
inter process communication but

118
00:05:25,680 --> 00:05:29,580
unfortunately what happen here is that

119
00:05:27,600 --> 00:05:31,289
an approach could be to reduce the

120
00:05:29,580 --> 00:05:33,680
college permission based on the caller

121
00:05:31,289 --> 00:05:36,180
but is defeat the collaboration

122
00:05:33,680 --> 00:05:38,039
obstruction right if we rely on another

123
00:05:36,180 --> 00:05:39,660
program to perform an operation you

124
00:05:38,039 --> 00:05:43,560
cannot do what's the point of

125
00:05:39,660 --> 00:05:45,930
restricting another approach is to

126
00:05:43,560 --> 00:05:50,639
enforce this decentralized information

127
00:05:45,930 --> 00:05:52,530
flow control this is technique they can

128
00:05:50,639 --> 00:05:53,460
restrict our information from between

129
00:05:52,530 --> 00:05:55,770
different programs

130
00:05:53,460 --> 00:05:58,169
unfortunately this solves and our token

131
00:05:55,770 --> 00:05:59,760
of problem of controlling our program

132
00:05:58,169 --> 00:06:02,520
shared data no our program actually

133
00:05:59,760 --> 00:06:05,669
access the sensor to collect the data

134
00:06:02,520 --> 00:06:09,349
and then there are also machine learning

135
00:06:05,669 --> 00:06:12,090
approach with researcher propose to

136
00:06:09,350 --> 00:06:15,360
model patterns in our user makes

137
00:06:12,090 --> 00:06:17,520
decision unfortunately our argument is

138
00:06:15,360 --> 00:06:20,909
that the user needs to have the right

139
00:06:17,520 --> 00:06:23,930
information to make the decision in

140
00:06:20,909 --> 00:06:26,250
order to boy then trained

141
00:06:23,930 --> 00:06:28,170
before I go into the details of what

142
00:06:26,250 --> 00:06:30,570
I'll resolve this problem will have to

143
00:06:28,170 --> 00:06:32,610
specify what are the assumptions we are

144
00:06:30,570 --> 00:06:34,770
making here so we want to trust the

145
00:06:32,610 --> 00:06:37,290
Veridian system that is builded securely

146
00:06:34,770 --> 00:06:39,150
we also want to enforce mandatory access

147
00:06:37,290 --> 00:06:42,740
control so that there is no direct

148
00:06:39,150 --> 00:06:46,320
access to censor for user level programs

149
00:06:42,740 --> 00:06:48,420
so user level programs are also isolated

150
00:06:46,320 --> 00:06:51,900
via the sandbox mechanism and then we

151
00:06:48,420 --> 00:06:54,600
use the trusted path we have a mechanism

152
00:06:51,900 --> 00:06:56,370
that allow the user to send trusted

153
00:06:54,600 --> 00:06:58,670
input to the operating system as well

154
00:06:56,370 --> 00:07:02,370
the operating system is able to

155
00:06:58,670 --> 00:07:03,630
visualize trusted out to the user we

156
00:07:02,370 --> 00:07:07,200
will see later why we use this

157
00:07:03,630 --> 00:07:09,420
assumption and then as a threat instead

158
00:07:07,200 --> 00:07:11,760
we assume that the user can start

159
00:07:09,420 --> 00:07:14,430
program from unknown sources and then

160
00:07:11,760 --> 00:07:15,690
grant access at first use program can

161
00:07:14,430 --> 00:07:17,460
communicate through inter process

162
00:07:15,690 --> 00:07:19,490
communication can never this inter

163
00:07:17,460 --> 00:07:21,960
process communication in order to

164
00:07:19,490 --> 00:07:24,330
exploit the three attacks vector that we

165
00:07:21,960 --> 00:07:26,130
have mentioned before I want to make a

166
00:07:24,330 --> 00:07:28,560
point here is that the focus of this

167
00:07:26,130 --> 00:07:30,960
work is to regulate our program access

168
00:07:28,560 --> 00:07:32,940
sensors by its completely out of scope

169
00:07:30,960 --> 00:07:34,710
while program share and collect data

170
00:07:32,940 --> 00:07:39,690
because there are already other

171
00:07:34,710 --> 00:07:44,760
solutions for this such as the diff see

172
00:07:39,690 --> 00:07:47,520
a line of work so our insight is that we

173
00:07:44,760 --> 00:07:49,890
want to track our input event our

174
00:07:47,520 --> 00:07:51,870
delegate among cooperating program then

175
00:07:49,890 --> 00:07:54,180
we want to expose the delegation

176
00:07:51,870 --> 00:07:56,460
information to user in order to allow

177
00:07:54,180 --> 00:07:58,800
the user to make informed decision about

178
00:07:56,460 --> 00:08:01,890
the authorization and then allow the

179
00:07:58,800 --> 00:08:03,780
user to restrict specific permission for

180
00:08:01,890 --> 00:08:05,610
the delegated program that is the

181
00:08:03,780 --> 00:08:08,159
program is actually requesting access to

182
00:08:05,610 --> 00:08:11,520
the sensor unfortunately there are

183
00:08:08,160 --> 00:08:13,410
several challenges too for this approach

184
00:08:11,520 --> 00:08:15,090
because first of all we need to track

185
00:08:13,410 --> 00:08:17,370
the input event from the time the input

186
00:08:15,090 --> 00:08:19,830
event was generated to the time this

187
00:08:17,370 --> 00:08:21,980
input event result in our operation

188
00:08:19,830 --> 00:08:24,570
requests to access a specific sensor

189
00:08:21,980 --> 00:08:26,700
there are also ambiguities they need to

190
00:08:24,570 --> 00:08:29,790
be resolved because a specific time in

191
00:08:26,700 --> 00:08:31,710
in a concurrent way a specific protocol

192
00:08:29,790 --> 00:08:34,200
is in multiple event from the user bound

193
00:08:31,710 --> 00:08:35,679
so multiple input event that are

194
00:08:34,200 --> 00:08:38,409
delegated from other programs

195
00:08:35,679 --> 00:08:40,269
and another problem is that we need to

196
00:08:38,409 --> 00:08:42,729
allow the user to authorize the right

197
00:08:40,269 --> 00:08:48,160
set of permission given a specific input

198
00:08:42,729 --> 00:08:50,829
event so our approach is to track input

199
00:08:48,160 --> 00:08:54,490
event allegation by modeling an input

200
00:08:50,829 --> 00:08:56,739
event as a topology where we collect the

201
00:08:54,490 --> 00:09:00,249
context where the user input event was

202
00:08:56,740 --> 00:09:04,360
generated then we model also this send

203
00:09:00,249 --> 00:09:06,759
the source sensor such as like the the

204
00:09:04,360 --> 00:09:09,490
touch screen where the input event was

205
00:09:06,759 --> 00:09:11,079
received and then the program target of

206
00:09:09,490 --> 00:09:13,899
this input event and a specific

207
00:09:11,079 --> 00:09:15,969
timestamp then we can model also how

208
00:09:13,899 --> 00:09:18,160
these input event is delegated through

209
00:09:15,970 --> 00:09:22,329
an end of event to another program PJ

210
00:09:18,160 --> 00:09:25,959
and then finally we can also model how

211
00:09:22,329 --> 00:09:27,910
the program PJ is going to generate a

212
00:09:25,959 --> 00:09:30,758
request to access a specific destination

213
00:09:27,910 --> 00:09:33,730
sensor be the result is a delegation

214
00:09:30,759 --> 00:09:35,860
graph unfortunately there are challenges

215
00:09:33,730 --> 00:09:38,110
because there are different ambiguities

216
00:09:35,860 --> 00:09:39,879
as I said before what happen if there

217
00:09:38,110 --> 00:09:42,790
are multiple input event a target a

218
00:09:39,879 --> 00:09:45,370
specific program P I and then this

219
00:09:42,790 --> 00:09:47,889
program Ti is going to generate an end

220
00:09:45,370 --> 00:09:50,589
of event so which input event should be

221
00:09:47,889 --> 00:09:52,899
associated with the end of event another

222
00:09:50,589 --> 00:09:55,389
example is what if we have multiple end

223
00:09:52,899 --> 00:09:56,620
of event at Argus P DV program PJ and

224
00:09:55,389 --> 00:09:59,889
then a request

225
00:09:56,620 --> 00:10:01,870
operation is going to be generated this

226
00:09:59,889 --> 00:10:06,100
is hard to do but we found out that

227
00:10:01,870 --> 00:10:08,740
since events are consumed faster than

228
00:10:06,100 --> 00:10:10,990
how they are produced then we can queue

229
00:10:08,740 --> 00:10:14,199
this input event for a specific program

230
00:10:10,990 --> 00:10:16,420
VI and then deliver it sequentially so

231
00:10:14,199 --> 00:10:19,179
that we are able to identify what your

232
00:10:16,420 --> 00:10:22,509
event is as generating the request or

233
00:10:19,179 --> 00:10:24,699
the end of event another problem is that

234
00:10:22,509 --> 00:10:27,999
another optimization that we can do is

235
00:10:24,699 --> 00:10:31,240
also a fan input event if an end of

236
00:10:27,999 --> 00:10:34,540
event is not caused by an input event

237
00:10:31,240 --> 00:10:37,480
from the user we can discard that end of

238
00:10:34,540 --> 00:10:40,899
event because it's an invalid delegation

239
00:10:37,480 --> 00:10:43,329
path for for this specific input event

240
00:10:40,899 --> 00:10:50,220
so that we can identify the delegation

241
00:10:43,329 --> 00:10:50,219
path so the approach is that we can

242
00:10:51,210 --> 00:10:57,060
impute event that are generated by end

243
00:10:54,960 --> 00:11:01,320
of event they are actually deriving by

244
00:10:57,060 --> 00:11:03,930
from input event so our approach is that

245
00:11:01,320 --> 00:11:06,300
once we have a generated the delegation

246
00:11:03,930 --> 00:11:08,969
graph and then identified the delegation

247
00:11:06,300 --> 00:11:14,060
path then we can model it for the user

248
00:11:08,970 --> 00:11:16,830
right and we can model it for using the

249
00:11:14,060 --> 00:11:19,949
natural language where we identify the

250
00:11:16,830 --> 00:11:22,560
operation the sensor and also a specific

251
00:11:19,950 --> 00:11:24,360
ID for the application is performed in

252
00:11:22,560 --> 00:11:27,630
the operation and then we can ask the

253
00:11:24,360 --> 00:11:30,330
user if you if the user wants the

254
00:11:27,630 --> 00:11:31,709
operation is allowed or denied so going

255
00:11:30,330 --> 00:11:35,760
back to the attack we have seen before

256
00:11:31,709 --> 00:11:39,239
we see now that the user is going to ask

257
00:11:35,760 --> 00:11:43,080
to deposit a bank check and then we are

258
00:11:39,240 --> 00:11:45,480
modeling the complete delegation path

259
00:11:43,080 --> 00:11:48,600
and then we ask the user if this is what

260
00:11:45,480 --> 00:11:51,870
is expected so we can see your quick

261
00:11:48,600 --> 00:11:53,940
demo how we prevent this attack so again

262
00:11:51,870 --> 00:11:56,670
the user is asking to the positive bank

263
00:11:53,940 --> 00:12:01,200
check and then a prompt show to the user

264
00:11:56,670 --> 00:12:03,360
what is actually happening we have

265
00:12:01,200 --> 00:12:06,180
evaluated our approach by implementing

266
00:12:03,360 --> 00:12:09,839
prototype in our system in Android OS

267
00:12:06,180 --> 00:12:11,699
and also tested on physical devices but

268
00:12:09,839 --> 00:12:14,339
we wanted to answer a set of research

269
00:12:11,700 --> 00:12:16,500
question or the to validate the validity

270
00:12:14,339 --> 00:12:19,620
of our approach first of all we wanted

271
00:12:16,500 --> 00:12:22,529
to measure the overhead imposed by

272
00:12:19,620 --> 00:12:25,350
entrust or user since now user they have

273
00:12:22,529 --> 00:12:27,630
to explicitly authorize the delegation

274
00:12:25,350 --> 00:12:30,420
graph that has been constructed to do so

275
00:12:27,630 --> 00:12:34,040
we have performed a field study where we

276
00:12:30,420 --> 00:12:37,229
recruited nine subjects and we gave them

277
00:12:34,040 --> 00:12:40,620
loan devices where they we pre installed

278
00:12:37,230 --> 00:12:42,690
seven ten different application a five

279
00:12:40,620 --> 00:12:45,450
voice assistants and they have been used

280
00:12:42,690 --> 00:12:49,110
for seven days I can give more details

281
00:12:45,450 --> 00:12:51,120
later we also wanted to validate an

282
00:12:49,110 --> 00:12:53,940
intresting is backward compatible with

283
00:12:51,120 --> 00:12:56,070
the existing application so we used the

284
00:12:53,940 --> 00:12:59,130
Android compatibility test fit and we

285
00:12:56,070 --> 00:13:00,570
tested it against 1000 application that

286
00:12:59,130 --> 00:13:02,090
were selected among the most popular

287
00:13:00,570 --> 00:13:05,000
from the

288
00:13:02,090 --> 00:13:07,880
Google store and then we have also used

289
00:13:05,000 --> 00:13:09,800
it five men to the reality gaming up but

290
00:13:07,880 --> 00:13:11,600
the reason why this is we selected a

291
00:13:09,800 --> 00:13:14,089
lamented religion gaming up this because

292
00:13:11,600 --> 00:13:17,240
they make heavily use of sensors and

293
00:13:14,090 --> 00:13:22,420
also they are very sensitive to delays

294
00:13:17,240 --> 00:13:25,100
in terms of responsiveness for the user

295
00:13:22,420 --> 00:13:27,319
another thing we have done is we wanted

296
00:13:25,100 --> 00:13:30,950
to measure the performance implication

297
00:13:27,320 --> 00:13:33,470
of integrating the entrust mechanism in

298
00:13:30,950 --> 00:13:35,150
terms of generating the delegation graph

299
00:13:33,470 --> 00:13:39,290
and also enforced in the delegation

300
00:13:35,150 --> 00:13:42,620
graph so we have created a set of micro

301
00:13:39,290 --> 00:13:44,630
benchmarks where we measure the overhead

302
00:13:42,620 --> 00:13:47,630
due to the graph construction the graph

303
00:13:44,630 --> 00:13:49,189
caching the graph enforcement and B with

304
00:13:47,630 --> 00:13:51,170
the prevention mechanism that we have

305
00:13:49,190 --> 00:13:52,970
seen before also we wanted to measure

306
00:13:51,170 --> 00:13:56,260
the memory requirements how much memory

307
00:13:52,970 --> 00:13:56,260
do we need to store this information

308
00:13:56,290 --> 00:14:01,339
finally what we have done we also wanted

309
00:13:58,760 --> 00:14:03,560
to evaluate if interest is actually

310
00:14:01,340 --> 00:14:05,390
effective in preventing the confused

311
00:14:03,560 --> 00:14:06,619
deputy the Trojan horse and the men in

312
00:14:05,390 --> 00:14:08,780
the middle attacks we have seen before

313
00:14:06,620 --> 00:14:13,190
to do so we have performed a laboratory

314
00:14:08,780 --> 00:14:15,740
study where we have used sixty subjects

315
00:14:13,190 --> 00:14:18,110
that were recruited by different from

316
00:14:15,740 --> 00:14:20,840
different sources not only student from

317
00:14:18,110 --> 00:14:23,510
our Institute and then we divided them

318
00:14:20,840 --> 00:14:27,590
in four groups we have two groups that

319
00:14:23,510 --> 00:14:29,540
tested the attacks for the first use

320
00:14:27,590 --> 00:14:31,550
approach so the regular Android

321
00:14:29,540 --> 00:14:37,040
operating system and two more groups

322
00:14:31,550 --> 00:14:39,469
that tested our system and then in in

323
00:14:37,040 --> 00:14:41,449
the first in the first group and then in

324
00:14:39,470 --> 00:14:44,420
the third group we had people that were

325
00:14:41,450 --> 00:14:46,190
not primont so we didn't tell them what

326
00:14:44,420 --> 00:14:48,530
was the purpose of our study we just

327
00:14:46,190 --> 00:14:51,110
that told them that we were testing some

328
00:14:48,530 --> 00:14:53,120
voice assistant and application and the

329
00:14:51,110 --> 00:14:56,920
other two groups instead both for first

330
00:14:53,120 --> 00:15:00,640
use and and trust they were both

331
00:14:56,920 --> 00:15:05,000
prominent user we told them that the

332
00:15:00,640 --> 00:15:09,520
possible attacks were perform a attacks

333
00:15:05,000 --> 00:15:12,140
were performed during the user study so

334
00:15:09,520 --> 00:15:13,760
during the laboratory study we had three

335
00:15:12,140 --> 00:15:15,230
attacks that are the three attacks we

336
00:15:13,760 --> 00:15:18,800
have seen they confused every

337
00:15:15,230 --> 00:15:21,320
the man in the middle attack and here

338
00:15:18,800 --> 00:15:23,240
I'm showing the scenario we have seen

339
00:15:21,320 --> 00:15:26,030
before of the men in the middle attack

340
00:15:23,240 --> 00:15:28,100
so what we have done we ask the user to

341
00:15:26,030 --> 00:15:30,500
ask the ghoul assistant to the Bosnia

342
00:15:28,100 --> 00:15:32,060
bank check after logging in in the

343
00:15:30,500 --> 00:15:33,950
mobile bank account with the provided

344
00:15:32,060 --> 00:15:36,709
credential we ask them to deposit or

345
00:15:33,950 --> 00:15:38,090
provided cheque in the menu in the

346
00:15:36,710 --> 00:15:39,740
middle attack what happens that the

347
00:15:38,090 --> 00:15:41,990
Google assistant launches the basic

348
00:15:39,740 --> 00:15:45,770
camera that is registered for an intent

349
00:15:41,990 --> 00:15:47,570
deposit bank check the basic camera runs

350
00:15:45,770 --> 00:15:49,100
in the background capture a picture of

351
00:15:47,570 --> 00:15:53,000
the check we have seen this in the demo

352
00:15:49,100 --> 00:15:55,010
we exported spoofing the intent and then

353
00:15:53,000 --> 00:15:57,560
launches the mobile app this is actually

354
00:15:55,010 --> 00:15:59,510
as register - for the voice assist and

355
00:15:57,560 --> 00:16:01,609
deposit check for the voice command

356
00:15:59,510 --> 00:16:04,310
deposit check there is largely different

357
00:16:01,610 --> 00:16:05,750
than the deposit bank check they

358
00:16:04,310 --> 00:16:07,939
collected data is then sent to the

359
00:16:05,750 --> 00:16:13,490
remote service controlled by the

360
00:16:07,940 --> 00:16:15,050
adversary so here is what the - the

361
00:16:13,490 --> 00:16:17,330
different group have seen for the first

362
00:16:15,050 --> 00:16:21,109
use and trust in the first use you guys

363
00:16:17,330 --> 00:16:22,850
are familiar with this type of request

364
00:16:21,110 --> 00:16:25,940
that Android the Android operating

365
00:16:22,850 --> 00:16:28,490
system present to the user and then the

366
00:16:25,940 --> 00:16:31,100
interest instead we have seen what type

367
00:16:28,490 --> 00:16:34,730
of information Trust is providing to the

368
00:16:31,100 --> 00:16:36,980
participant of the study so what we

369
00:16:34,730 --> 00:16:40,250
found out for this specific attack is

370
00:16:36,980 --> 00:16:44,380
that only 47% of the user were prompt

371
00:16:40,250 --> 00:16:47,540
with request for permission this is the

372
00:16:44,380 --> 00:16:49,780
drawback or pitfall for the first use so

373
00:16:47,540 --> 00:16:53,810
that means that they have previously

374
00:16:49,780 --> 00:16:55,850
authorized this specific permission

375
00:16:53,810 --> 00:16:58,369
through other interactions during the

376
00:16:55,850 --> 00:17:01,010
study so they have used the camera for

377
00:16:58,370 --> 00:17:03,650
other purposes and have accidentally

378
00:17:01,010 --> 00:17:06,170
granted permission to the application

379
00:17:03,650 --> 00:17:11,270
instead as we can see and trust always

380
00:17:06,170 --> 00:17:13,490
generated delegation graph and identify

381
00:17:11,270 --> 00:17:15,829
a specific delegation path and present a

382
00:17:13,490 --> 00:17:17,810
specific authorization to the user so we

383
00:17:15,829 --> 00:17:21,260
have an under percent of user where

384
00:17:17,810 --> 00:17:24,710
prompt explicit allowed means that the

385
00:17:21,260 --> 00:17:26,569
user have actually seen requests for

386
00:17:24,710 --> 00:17:27,890
permission and they actually explicit

387
00:17:26,569 --> 00:17:29,330
allowed by mistake

388
00:17:27,890 --> 00:17:32,899
and we have seen

389
00:17:29,330 --> 00:17:37,158
13% and 7% in case of interest and then

390
00:17:32,899 --> 00:17:40,250
the attack success rate goes from 70 67%

391
00:17:37,159 --> 00:17:42,830
for first use down to 7% using interest

392
00:17:40,250 --> 00:17:44,809
this is forum prime the users a user

393
00:17:42,830 --> 00:17:47,539
that were not aware of the purpose of

394
00:17:44,809 --> 00:17:50,149
our study for primed user instead the

395
00:17:47,539 --> 00:17:51,980
numbers are relatively different so we

396
00:17:50,149 --> 00:17:53,750
don't have any explicit allowed because

397
00:17:51,980 --> 00:17:56,929
they were prompt the attacks were

398
00:17:53,750 --> 00:18:00,070
possible but still we have that for the

399
00:17:56,929 --> 00:18:03,350
first use approach we have 53% of the

400
00:18:00,070 --> 00:18:08,120
subject actually were subject to data

401
00:18:03,350 --> 00:18:11,750
compared to 0% interest so what are

402
00:18:08,120 --> 00:18:15,620
defining Centex way so first of all we

403
00:18:11,750 --> 00:18:17,870
have shown that we can reach 47 to 67

404
00:18:15,620 --> 00:18:19,969
percent improvement compared to the

405
00:18:17,870 --> 00:18:22,969
first user authorization when trying to

406
00:18:19,970 --> 00:18:24,740
prevent the tree attack vectors we have

407
00:18:22,970 --> 00:18:27,980
seen and this is because we generate

408
00:18:24,740 --> 00:18:32,149
delegation paths and then we ask the

409
00:18:27,980 --> 00:18:34,279
user to authorize them then we have in

410
00:18:32,149 --> 00:18:37,340
terms of compatibility we did not find

411
00:18:34,279 --> 00:18:40,610
any discernible slowdown glitches or

412
00:18:37,340 --> 00:18:43,129
crashes or responses in issues and also

413
00:18:40,610 --> 00:18:45,678
we did not require any of modification

414
00:18:43,130 --> 00:18:49,389
in order to for the application to be

415
00:18:45,679 --> 00:18:51,649
able to run with our system in terms of

416
00:18:49,389 --> 00:18:54,590
decision of a reading post to the user

417
00:18:51,649 --> 00:18:56,719
for the new authorization model we found

418
00:18:54,590 --> 00:18:58,250
that we know we don't have more than 4

419
00:18:56,720 --> 00:19:01,340
explicit authorization for a specific

420
00:18:58,250 --> 00:19:03,350
problem and then this is because we use

421
00:19:01,340 --> 00:19:05,959
a caching mechanism where if a

422
00:19:03,350 --> 00:19:10,189
delegation part is identified then we

423
00:19:05,960 --> 00:19:12,049
can we can use the other is a pre

424
00:19:10,190 --> 00:19:13,460
authorized delegation party we have in

425
00:19:12,049 --> 00:19:16,879
caching we don't have to ask the user

426
00:19:13,460 --> 00:19:19,460
again in terms of performance we found

427
00:19:16,880 --> 00:19:22,429
out that if you compare the our system

428
00:19:19,460 --> 00:19:24,169
with the Android system what we found

429
00:19:22,429 --> 00:19:26,240
out is that we have only one percent

430
00:19:24,169 --> 00:19:28,460
performance load on in terms of time to

431
00:19:26,240 --> 00:19:31,100
perform a set of tasks that we have

432
00:19:28,460 --> 00:19:35,059
identified and then we have a 5.5

433
00:19:31,100 --> 00:19:38,090
kilobyte of cash required per memory for

434
00:19:35,059 --> 00:19:40,279
each problem so this concludes my talks

435
00:19:38,090 --> 00:19:42,500
and I'm thank you for coming and I'm

436
00:19:40,279 --> 00:19:51,130
free for any question as

437
00:19:42,500 --> 00:19:51,130
speaker I have time for one question

438
00:19:53,440 --> 00:19:59,150
thanks for the talk I'm just interested

439
00:19:56,150 --> 00:20:02,270
did you look at the Android 10 beta and

440
00:19:59,150 --> 00:20:05,050
the background sensor access limitations

441
00:20:02,270 --> 00:20:07,940
and how they would make this harder

442
00:20:05,050 --> 00:20:10,760
unfortunately no but I will definitely

443
00:20:07,940 --> 00:20:13,250
do that this is a little bit this is

444
00:20:10,760 --> 00:20:16,879
Android 7 so I'm a little bit behind

445
00:20:13,250 --> 00:20:19,310
here but I will love to see that some of

446
00:20:16,880 --> 00:20:23,220
these have been implementing Android

447
00:20:19,310 --> 00:20:28,799
time thanks okay next time speaker again

448
00:20:23,220 --> 00:20:28,799
[Applause]

