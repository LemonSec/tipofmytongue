1
00:00:10,429 --> 00:00:17,300
so thank you for introduction I'm taka

2
00:00:13,820 --> 00:00:19,720
America me from a ist and in this

3
00:00:17,300 --> 00:00:22,130
presentation I'd like to introduce

4
00:00:19,720 --> 00:00:27,109
utility optimized local differential

5
00:00:22,130 --> 00:00:30,348
privacy so first I briefly explain the

6
00:00:27,109 --> 00:00:32,419
outline of this book recently personal

7
00:00:30,349 --> 00:00:35,089
data are increasingly collected and

8
00:00:32,418 --> 00:00:37,940
analyzed for various purposes for

9
00:00:35,089 --> 00:00:41,079
example a large amount of location data

10
00:00:37,940 --> 00:00:43,659
can be collected and analyzed to find

11
00:00:41,079 --> 00:00:48,229
popular sightseeing places or

12
00:00:43,659 --> 00:00:51,320
visualizing population distribution and

13
00:00:48,229 --> 00:00:54,530
for another example personal data such

14
00:00:51,320 --> 00:00:57,559
as age income and Markel status can be

15
00:00:54,530 --> 00:01:00,470
corrected by a survey sampling and a

16
00:00:57,559 --> 00:01:03,849
joint distribution like this can be

17
00:01:00,470 --> 00:01:07,429
computed to specify a target customers

18
00:01:03,850 --> 00:01:11,240
so these data are very useful for users

19
00:01:07,430 --> 00:01:14,780
or companies but there is a serious

20
00:01:11,240 --> 00:01:18,710
privacy issue for example personal data

21
00:01:14,780 --> 00:01:22,040
such as personal data contains sensitive

22
00:01:18,710 --> 00:01:25,699
information such as home hospital and

23
00:01:22,040 --> 00:01:31,210
income so we need to strongly protect

24
00:01:25,700 --> 00:01:35,060
users privacy and the problem is how and

25
00:01:31,210 --> 00:01:35,839
to protect users privacy locality

26
00:01:35,060 --> 00:01:40,340
financial privacy

27
00:01:35,840 --> 00:01:42,470
LDP has recently studied LDP is a

28
00:01:40,340 --> 00:01:45,800
variant of differential privacy in the

29
00:01:42,470 --> 00:01:48,429
local model and in the local model user

30
00:01:45,800 --> 00:01:51,770
office case her personal data such as

31
00:01:48,430 --> 00:01:53,080
locations response in a survey by

32
00:01:51,770 --> 00:01:56,509
herself

33
00:01:53,080 --> 00:02:00,650
that's what we don't assume a trusted

34
00:01:56,510 --> 00:02:01,970
seller party and this is a definition of

35
00:02:00,650 --> 00:02:06,260
epsilon LDP

36
00:02:01,970 --> 00:02:11,209
of a special mechanism q provides if CDP

37
00:02:06,260 --> 00:02:15,200
if we have this inequality and it means

38
00:02:11,209 --> 00:02:18,110
that the attacker can't estimate the

39
00:02:15,200 --> 00:02:21,310
original data X from noisy data Y with a

40
00:02:18,110 --> 00:02:23,560
certain degree of confidence and

41
00:02:21,310 --> 00:02:26,290
epsilon is called privacy budget and

42
00:02:23,560 --> 00:02:31,270
when epsilon is small the original data

43
00:02:26,290 --> 00:02:33,880
X is strongly protected and examples Q

44
00:02:31,270 --> 00:02:39,040
include randomized response and report

45
00:02:33,880 --> 00:02:42,840
developed by Google and the feature of

46
00:02:39,040 --> 00:02:45,579
LDP rise at its strong privacy first

47
00:02:42,840 --> 00:02:47,739
privacy is protected against attackers

48
00:02:45,580 --> 00:02:50,110
with any background knowledge and this

49
00:02:47,739 --> 00:02:54,519
is a property of a differential privacy

50
00:02:50,110 --> 00:02:57,130
and second the original data are not

51
00:02:54,519 --> 00:02:58,709
leaked from the database in the

52
00:02:57,130 --> 00:03:02,440
centralized differential privacy

53
00:02:58,709 --> 00:03:04,269
theories there is a risk that all of the

54
00:03:02,440 --> 00:03:07,750
personal data are leaked through the

55
00:03:04,269 --> 00:03:10,300
database by illegal access on the other

56
00:03:07,750 --> 00:03:13,209
hand in local differential privacy in

57
00:03:10,300 --> 00:03:15,519
the origin data are not leaked from the

58
00:03:13,209 --> 00:03:22,269
database because we don't assume a

59
00:03:15,519 --> 00:03:24,810
trusted party and every DP has also been

60
00:03:22,269 --> 00:03:28,390
used by some companies for example

61
00:03:24,810 --> 00:03:31,440
google estimated a rated frequency of a

62
00:03:28,390 --> 00:03:34,119
chrome home pages by a report and

63
00:03:31,440 --> 00:03:36,670
Microsoft s may lead a histogram of

64
00:03:34,120 --> 00:03:40,239
daily application usage via its own

65
00:03:36,670 --> 00:03:42,760
mechanism and both of them are related

66
00:03:40,239 --> 00:03:46,750
to a distribution estimation task and

67
00:03:42,760 --> 00:03:51,040
here each user sends a noisy data and

68
00:03:46,750 --> 00:03:56,440
the data collector estimate distribution

69
00:03:51,040 --> 00:03:58,510
of the original data P and by using LD P

70
00:03:56,440 --> 00:04:04,209
as a privacy measure we can strongly

71
00:03:58,510 --> 00:04:09,130
protect users privacy however there is a

72
00:04:04,209 --> 00:04:12,130
utility issue in LDP unfortunately the

73
00:04:09,130 --> 00:04:14,680
aleutian the origin distribution P may

74
00:04:12,130 --> 00:04:18,510
not be accurately estimated in practice

75
00:04:14,680 --> 00:04:22,240
because LDP adds too much noise

76
00:04:18,510 --> 00:04:24,820
LDP regards all personal data as equally

77
00:04:22,240 --> 00:04:28,450
sensitive and causes excessive of

78
00:04:24,820 --> 00:04:30,729
allocation and the loss by utility in

79
00:04:28,450 --> 00:04:34,009
other words there are a lot of non

80
00:04:30,729 --> 00:04:37,360
sensitive data in practice

81
00:04:34,009 --> 00:04:40,789
and to explain more about this issue

82
00:04:37,360 --> 00:04:44,149
let's consider a question such as have

83
00:04:40,789 --> 00:04:46,520
you ever cheated in an exam obviously

84
00:04:44,149 --> 00:04:50,719
yes is a sensitive answer to this

85
00:04:46,520 --> 00:04:52,549
question why no is not sensible and we

86
00:04:50,719 --> 00:04:56,960
want to estimate the original

87
00:04:52,550 --> 00:04:59,149
distribution P but in this example 30%

88
00:04:56,960 --> 00:05:01,609
of the target population have really

89
00:04:59,149 --> 00:05:06,229
cheated in the exam so we need to

90
00:05:01,610 --> 00:05:09,259
protect this users privacy and classical

91
00:05:06,229 --> 00:05:14,120
solution is to use Warner's randomize

92
00:05:09,259 --> 00:05:18,289
response this mechanism flips yes and

93
00:05:14,120 --> 00:05:22,789
both yes and no with probability P then

94
00:05:18,289 --> 00:05:26,089
both answers may come from yes or no so

95
00:05:22,789 --> 00:05:29,300
users privacy is strongly protected and

96
00:05:26,089 --> 00:05:34,819
in fact this mechanism provides epsilon

97
00:05:29,300 --> 00:05:38,089
LD P and the second solution is to use

98
00:05:34,819 --> 00:05:41,830
manga's randomize response this

99
00:05:38,089 --> 00:05:47,509
mechanism always sends es as it is and

100
00:05:41,830 --> 00:05:50,719
flips no with probability P then the

101
00:05:47,509 --> 00:05:54,370
answer es may come from yes or no so

102
00:05:50,719 --> 00:05:59,569
sensory users privacy is protected and

103
00:05:54,370 --> 00:06:01,370
also know is always come from No so the

104
00:05:59,569 --> 00:06:05,899
original distribution can be more

105
00:06:01,370 --> 00:06:08,749
accurately estimated however this

106
00:06:05,899 --> 00:06:12,319
mechanism doesn't provide epsilon D P

107
00:06:08,749 --> 00:06:16,610
for any option because every DP assumes

108
00:06:12,319 --> 00:06:19,639
both yes and no as equally sensitive so

109
00:06:16,610 --> 00:06:22,339
another question would be how can we

110
00:06:19,639 --> 00:06:25,399
guarantee LD p for only sensitive data

111
00:06:22,339 --> 00:06:31,309
and we made some contributions on this

112
00:06:25,399 --> 00:06:33,319
issue in this work we focus on a

113
00:06:31,309 --> 00:06:35,680
discrete distribution estimation task

114
00:06:33,319 --> 00:06:39,769
because it is a popular application and

115
00:06:35,680 --> 00:06:42,680
introduce you LDP utility optimize LDP

116
00:06:39,769 --> 00:06:45,370
to guarantee adp only for sensitive data

117
00:06:42,680 --> 00:06:49,750
and achieve high utility

118
00:06:45,370 --> 00:06:52,120
and we focus on a common mechanism

119
00:06:49,750 --> 00:06:55,750
scenario where the mechanism is it is

120
00:06:52,120 --> 00:06:58,510
common to all users and we propose you

121
00:06:55,750 --> 00:07:00,760
LDP mechanisms that provide much higher

122
00:06:58,510 --> 00:07:01,500
utility than randomize response and

123
00:07:00,760 --> 00:07:05,380
rapport

124
00:07:01,500 --> 00:07:10,389
for example we are performed by one or

125
00:07:05,380 --> 00:07:13,180
two orders of magnitude and we also

126
00:07:10,389 --> 00:07:15,190
proposed a mechanism for personalized

127
00:07:13,180 --> 00:07:17,440
mechanism scenario where as a

128
00:07:15,190 --> 00:07:19,540
distinction between sensitive and non

129
00:07:17,440 --> 00:07:24,040
sensitive data can be different from

130
00:07:19,540 --> 00:07:26,590
user to user example a location of home

131
00:07:24,040 --> 00:07:30,550
can be different from user to user and

132
00:07:26,590 --> 00:07:32,859
we can deal with such scenarios but here

133
00:07:30,550 --> 00:07:34,510
we only explain as a common mechanism

134
00:07:32,860 --> 00:07:36,970
scenario for lack of a time

135
00:07:34,510 --> 00:07:43,599
so for details over the personalized

136
00:07:36,970 --> 00:07:46,539
mechanism please see our paper and in

137
00:07:43,600 --> 00:07:49,150
this work we also assume that each user

138
00:07:46,539 --> 00:07:52,150
sends a single data and each user's data

139
00:07:49,150 --> 00:07:54,549
is independent this is a very simple

140
00:07:52,150 --> 00:07:57,159
assumption but it is reasonable for

141
00:07:54,550 --> 00:08:00,820
various kinds of data such as locations

142
00:07:57,160 --> 00:08:03,690
age and gender and we leave the case of

143
00:08:00,820 --> 00:08:07,539
March with data per user as future work

144
00:08:03,690 --> 00:08:12,719
so this is the outline of this work so

145
00:08:07,539 --> 00:08:12,719
next I will introduce you LDP

146
00:08:14,250 --> 00:08:21,580
new RDP we first divide the set of input

147
00:08:18,220 --> 00:08:24,610
data X into the set of sensitive data

148
00:08:21,580 --> 00:08:29,229
access and a non sensitive data Excel

149
00:08:24,610 --> 00:08:33,039
and we also divide as a set of output

150
00:08:29,229 --> 00:08:37,949
data Y into the set of protected data Y

151
00:08:33,039 --> 00:08:41,199
P and invertible data Y I then

152
00:08:37,950 --> 00:08:44,950
intuitively you LDP provides

153
00:08:41,200 --> 00:08:48,700
LDP for only sensitive data and doesn't

154
00:08:44,950 --> 00:08:51,670
protect nonsense of data so by

155
00:08:48,700 --> 00:08:56,459
protecting minimum necessary data we can

156
00:08:51,670 --> 00:08:59,050
achieve high utility more specifically

157
00:08:56,459 --> 00:09:02,349
this is a definition of you

158
00:08:59,050 --> 00:09:05,920
be avocation mechanism to provides

159
00:09:02,350 --> 00:09:11,070
access Y P epsilon u LD P if we satisfy

160
00:09:05,920 --> 00:09:14,529
these two conditions first for any

161
00:09:11,070 --> 00:09:18,430
invertible data Y there exists a unique

162
00:09:14,529 --> 00:09:21,010
non sensitive data X such that the

163
00:09:18,430 --> 00:09:25,750
transition probability is positive for X

164
00:09:21,010 --> 00:09:27,160
and 0 for any other input data in other

165
00:09:25,750 --> 00:09:30,339
words any

166
00:09:27,160 --> 00:09:32,980
invertible data is invertible and

167
00:09:30,339 --> 00:09:37,660
reveals the original non sensitive data

168
00:09:32,980 --> 00:09:41,760
and the second condition states that we

169
00:09:37,660 --> 00:09:45,219
provide epsilon LDP for protected data

170
00:09:41,760 --> 00:09:49,390
here the output set corresponding to

171
00:09:45,220 --> 00:09:52,089
access is restricted to Y P so we can

172
00:09:49,390 --> 00:09:57,579
provide if you know a DP for sensitive

173
00:09:52,089 --> 00:10:00,430
data and the future of you LDP realize

174
00:09:57,579 --> 00:10:04,120
that invite ability and optional LDP who

175
00:10:00,430 --> 00:10:06,399
are protected data by invite ability we

176
00:10:04,120 --> 00:10:10,000
can accurately estimate the original

177
00:10:06,399 --> 00:10:12,700
distribution and by LDP for protected

178
00:10:10,000 --> 00:10:16,829
data we can wrongly protect sensitive

179
00:10:12,700 --> 00:10:19,329
data for example

180
00:10:16,829 --> 00:10:22,810
mungus randomized response provides

181
00:10:19,329 --> 00:10:25,779
option l DP for protected data and the

182
00:10:22,810 --> 00:10:28,359
invertible data XOR reveals the original

183
00:10:25,779 --> 00:10:33,939
nonsense with data so this mechanism

184
00:10:28,360 --> 00:10:37,589
provides you LD P and we also showed

185
00:10:33,940 --> 00:10:40,480
some basic properties of your DP such as

186
00:10:37,589 --> 00:10:42,760
compositionality 's and the immunity to

187
00:10:40,480 --> 00:10:48,970
post-processing so for more details

188
00:10:42,760 --> 00:10:51,790
please see our paper ok so next I will

189
00:10:48,970 --> 00:10:54,520
introduce some new ADP mechanisms such

190
00:10:51,790 --> 00:11:00,670
as utility optimize randomize response

191
00:10:54,520 --> 00:11:04,390
and utility optimize report the basic

192
00:11:00,670 --> 00:11:07,390
idea of our ulgb mechanisms is to use

193
00:11:04,390 --> 00:11:09,569
epsilon led pin mechanism such as

194
00:11:07,390 --> 00:11:12,860
randomize response and report for

195
00:11:09,570 --> 00:11:16,610
sensitive set X s and YP

196
00:11:12,860 --> 00:11:21,290
and then we said Trebek is from xn to

197
00:11:16,610 --> 00:11:26,180
provide you a DP and here we can use any

198
00:11:21,290 --> 00:11:28,310
LDP mechanism for access and YP so in

199
00:11:26,180 --> 00:11:33,650
this work we use randomized response and

200
00:11:28,310 --> 00:11:37,280
report for access and YP so our first

201
00:11:33,650 --> 00:11:41,060
mechanism is you are our utility

202
00:11:37,280 --> 00:11:43,400
optimize randomize response you are our

203
00:11:41,060 --> 00:11:45,890
is a generalization of a mangas

204
00:11:43,400 --> 00:11:51,620
randomize response to K alphabets where

205
00:11:45,890 --> 00:11:54,080
K is the size of X and then it we use KS

206
00:11:51,620 --> 00:11:59,890
randomize best ones for access and why P

207
00:11:54,080 --> 00:12:03,470
we are KS is the size of XS then we set

208
00:11:59,890 --> 00:12:08,569
probabilities from X N and Elise P 3 and

209
00:12:03,470 --> 00:12:13,960
P 4 to provide you LD P and this Meccans

210
00:12:08,570 --> 00:12:18,820
provides access by P Y epsilon u LD P

211
00:12:13,960 --> 00:12:22,790
and our second mechanism is you wrap

212
00:12:18,820 --> 00:12:25,070
utility optimize rapport so I first

213
00:12:22,790 --> 00:12:25,640
explained just the basic one time

214
00:12:25,070 --> 00:12:29,780
rapport

215
00:12:25,640 --> 00:12:32,449
whispers developed by Google rapport is

216
00:12:29,780 --> 00:12:36,199
an optional LDP mechanism for que

217
00:12:32,450 --> 00:12:39,560
alphabets and it Maps excited to eat I

218
00:12:36,200 --> 00:12:44,770
the I've standard basis vector and then

219
00:12:39,560 --> 00:12:48,140
flips is bit of AI is probability P and

220
00:12:44,770 --> 00:12:54,620
based on this mechanism we construct

221
00:12:48,140 --> 00:12:58,160
Europe and this is Europe first we

222
00:12:54,620 --> 00:13:00,920
assume that the first KS alphabets are

223
00:12:58,160 --> 00:13:04,390
sensitive and remaining alphabets are

224
00:13:00,920 --> 00:13:08,240
non sensitive without loss of generality

225
00:13:04,390 --> 00:13:11,569
then it is important to note that if X

226
00:13:08,240 --> 00:13:17,270
is sensitive all of the right elements

227
00:13:11,570 --> 00:13:22,100
of e ir0 like this based on this we use

228
00:13:17,270 --> 00:13:25,150
report for left elements and this we

229
00:13:22,100 --> 00:13:30,100
flip one in the right element

230
00:13:25,150 --> 00:13:32,319
to zero is probability P two and this

231
00:13:30,100 --> 00:13:35,380
mechanism also provides access Y P

232
00:13:32,320 --> 00:13:41,670
epsilon u LD P where Y P is the set of

233
00:13:35,380 --> 00:13:45,130
vectors whose right elements are 0 and

234
00:13:41,670 --> 00:13:48,939
we thoroughly analyzed our you LDP

235
00:13:45,130 --> 00:13:51,220
mechanisms here we analyzed the l1 loss

236
00:13:48,940 --> 00:13:55,720
between the empirical estimate P hat and

237
00:13:51,220 --> 00:13:58,980
to the true distribution P and we assume

238
00:13:55,720 --> 00:14:02,080
that KS is much smaller than K and

239
00:13:58,980 --> 00:14:06,130
analyzed the expected error loss in high

240
00:14:02,080 --> 00:14:09,400
privacy and low privacy and here are the

241
00:14:06,130 --> 00:14:10,439
results and we can see that in law

242
00:14:09,400 --> 00:14:15,430
privacy

243
00:14:10,440 --> 00:14:17,710
URR achieves almost the same utility as

244
00:14:15,430 --> 00:14:22,839
an own private mechanism that doesn't

245
00:14:17,710 --> 00:14:26,170
add any noise and in high privacy he

246
00:14:22,840 --> 00:14:29,020
Europe we also proved that in high

247
00:14:26,170 --> 00:14:33,280
privacy in Europe is also optimal among

248
00:14:29,020 --> 00:14:36,250
all ul D P mechanisms and we also

249
00:14:33,280 --> 00:14:41,199
analyzed the l2 loss and obtained

250
00:14:36,250 --> 00:14:41,980
similar results so in family e law

251
00:14:41,200 --> 00:14:45,010
privacy

252
00:14:41,980 --> 00:14:47,920
URR is effective and in high privacy in

253
00:14:45,010 --> 00:14:53,080
europe is effective and we also saw this

254
00:14:47,920 --> 00:14:57,729
in our experience ok so i go on to our

255
00:14:53,080 --> 00:15:00,850
extreme results in our experiments we

256
00:14:57,730 --> 00:15:03,880
used to real data sets the Foursquare

257
00:15:00,850 --> 00:15:06,400
dataset and the US census data set but

258
00:15:03,880 --> 00:15:10,360
here I explained only Foursquare for

259
00:15:06,400 --> 00:15:13,590
lack of a time the hosts videlicet

260
00:15:10,360 --> 00:15:18,040
is a location data set which contains

261
00:15:13,590 --> 00:15:20,530
300,000 sequins in Mahuta and here we

262
00:15:18,040 --> 00:15:24,849
assume each user sent one location and

263
00:15:20,530 --> 00:15:27,400
we divided Mahuta into 25 by 25 regions

264
00:15:24,850 --> 00:15:33,790
at regular intervals so the number of

265
00:15:27,400 --> 00:15:36,430
regions k is 625 and we assumed 15

266
00:15:33,790 --> 00:15:37,020
regions are including hospitals as since

267
00:15:36,430 --> 00:15:41,609
the bridge

268
00:15:37,020 --> 00:15:43,860
and as a true distribution P a we used a

269
00:15:41,610 --> 00:15:47,310
frequency distribution of all users and

270
00:15:43,860 --> 00:15:53,490
then we selected a hub all users as

271
00:15:47,310 --> 00:15:56,099
those who sent noisy data and we used

272
00:15:53,490 --> 00:15:58,230
the empirical estimation method and e/m

273
00:15:56,100 --> 00:16:01,620
reconstruction method to estimate a

274
00:15:58,230 --> 00:16:04,410
distribution from noisy data and here we

275
00:16:01,620 --> 00:16:07,190
have the results this is a relationship

276
00:16:04,410 --> 00:16:12,089
between epsilon and total variation and

277
00:16:07,190 --> 00:16:12,870
our R is randomized response and rap is

278
00:16:12,089 --> 00:16:15,240
repor

279
00:16:12,870 --> 00:16:17,640
so the red line represents the

280
00:16:15,240 --> 00:16:20,730
performance of the existing mechanisms

281
00:16:17,640 --> 00:16:24,330
and the blue lines represent the

282
00:16:20,730 --> 00:16:27,000
performance of our mechanisms so we can

283
00:16:24,330 --> 00:16:29,370
see that our mechanisms are performed

284
00:16:27,000 --> 00:16:34,830
randomized response and report by one or

285
00:16:29,370 --> 00:16:38,070
two orders of magnitude and we also

286
00:16:34,830 --> 00:16:40,560
examined as a relationship between KS as

287
00:16:38,070 --> 00:16:44,220
the number of sense regions and total

288
00:16:40,560 --> 00:16:47,060
variation here we randomly selected K a

289
00:16:44,220 --> 00:16:51,180
sensitive regions from all regions and

290
00:16:47,060 --> 00:16:53,939
this is a result and the left figure is

291
00:16:51,180 --> 00:16:55,649
the performance in high privacy and the

292
00:16:53,940 --> 00:17:01,020
right figure is performance in low

293
00:16:55,649 --> 00:17:03,450
privacy so we can see that about Europe

294
00:17:01,020 --> 00:17:07,230
who provided the best performance in

295
00:17:03,450 --> 00:17:10,679
high privacy and you are are provided

296
00:17:07,230 --> 00:17:14,939
with almost the same utility as an own

297
00:17:10,679 --> 00:17:19,140
private mechanism in no privacy so in

298
00:17:14,939 --> 00:17:25,410
conclusion we can say that our surgical

299
00:17:19,140 --> 00:17:28,439
results also hold in our experience so

300
00:17:25,410 --> 00:17:31,230
let me summarize this talk in this work

301
00:17:28,439 --> 00:17:33,840
we proposed you LDP mechanisms which

302
00:17:31,230 --> 00:17:36,210
provide much higher utilities randomize

303
00:17:33,840 --> 00:17:39,928
response and therefore when there are a

304
00:17:36,210 --> 00:17:42,420
lot of non sensitive data and as future

305
00:17:39,929 --> 00:17:45,630
work we directly consider the case of

306
00:17:42,420 --> 00:17:48,260
multiple data by user because in this

307
00:17:45,630 --> 00:17:50,310
work we assume that each user sent a

308
00:17:48,260 --> 00:17:52,890
single data but

309
00:17:50,310 --> 00:17:55,139
where I use a sense market data there

310
00:17:52,890 --> 00:17:58,920
might be a correlation between sensitive

311
00:17:55,140 --> 00:18:01,320
and non sensitive data so a sensitive

312
00:17:58,920 --> 00:18:04,650
data might be inferred from non

313
00:18:01,320 --> 00:18:10,050
sensitive data so we tracked extent uld

314
00:18:04,650 --> 00:18:18,300
P to protect such corrected data okay so

315
00:18:10,050 --> 00:18:20,190
thank you for attention we've got a bit

316
00:18:18,300 --> 00:18:27,690
of time for questions if people want to

317
00:18:20,190 --> 00:18:29,460
ask one perfect thank you very much for

318
00:18:27,690 --> 00:18:33,360
the nice presentation and a nice work I

319
00:18:29,460 --> 00:18:35,640
had a small question regarding how

320
00:18:33,360 --> 00:18:38,879
trivial or non-trivial it is to compose

321
00:18:35,640 --> 00:18:42,000
a system with several different values

322
00:18:38,880 --> 00:18:45,060
of epsilon such that you can tune for

323
00:18:42,000 --> 00:18:46,770
each type of information how private it

324
00:18:45,060 --> 00:18:48,690
is such that you can find for each type

325
00:18:46,770 --> 00:18:52,260
of information the sweet spot between

326
00:18:48,690 --> 00:18:56,100
utility and privacy your question is

327
00:18:52,260 --> 00:18:58,290
about how to sit epsilon so if I

328
00:18:56,100 --> 00:19:00,149
understand correctly then in the systems

329
00:18:58,290 --> 00:19:02,310
you presented you chose one value of

330
00:19:00,150 --> 00:19:06,960
apps Epsilon right yeah and I was

331
00:19:02,310 --> 00:19:10,919
wondering how easy or not it is to have

332
00:19:06,960 --> 00:19:12,390
multiple values of epsilon for different

333
00:19:10,920 --> 00:19:15,060
types of information in the same system

334
00:19:12,390 --> 00:19:19,470
okay ah think about your crystal yeah

335
00:19:15,060 --> 00:19:22,889
here are we simply assumes that we can

336
00:19:19,470 --> 00:19:25,260
divide personal data into sensitive data

337
00:19:22,890 --> 00:19:28,350
and non sensitive that's all or nothing

338
00:19:25,260 --> 00:19:32,040
but of course it might be possible to

339
00:19:28,350 --> 00:19:35,010
exchange our uld P to assign different

340
00:19:32,040 --> 00:19:37,740
options to different levels of sensitive

341
00:19:35,010 --> 00:19:40,830
data so we directly consider it has a

342
00:19:37,740 --> 00:19:44,700
yeah about future work thank you thank

343
00:19:40,830 --> 00:19:47,490
you I'll ask one more question while our

344
00:19:44,700 --> 00:19:50,490
next speaker comes up and sets up so you

345
00:19:47,490 --> 00:19:51,900
pointed out the future work there might

346
00:19:50,490 --> 00:19:54,600
be multiple data points that are

347
00:19:51,900 --> 00:19:56,760
correlated so you can't protect that so

348
00:19:54,600 --> 00:19:59,760
that means Google shouldn't switch to

349
00:19:56,760 --> 00:20:02,250
your thing yet do you have any intuition

350
00:19:59,760 --> 00:20:03,960
about what the next step would be how do

351
00:20:02,250 --> 00:20:08,020
you solve that future work

352
00:20:03,960 --> 00:20:13,090
yeah I think this future work is a very

353
00:20:08,020 --> 00:20:17,490
interesting future work actually we are

354
00:20:13,090 --> 00:20:20,320
planning to to use puffer fish privacy a

355
00:20:17,490 --> 00:20:21,970
privacy is a generalization of the

356
00:20:20,320 --> 00:20:26,200
differential privacy to protect

357
00:20:21,970 --> 00:20:28,200
corrected data so for example if there

358
00:20:26,200 --> 00:20:30,400
is a strong correlation between

359
00:20:28,200 --> 00:20:33,850
sensitive and non sensitive data

360
00:20:30,400 --> 00:20:36,910
we add noise to nonsense of data as well

361
00:20:33,850 --> 00:20:40,570
as sense of data so by incorporating

362
00:20:36,910 --> 00:20:46,030
half of his privacy into you LDP I think

363
00:20:40,570 --> 00:20:48,179
we can protect corrected data so let's

364
00:20:46,030 --> 00:20:52,439
thank the speaker once more

365
00:20:48,180 --> 00:20:52,439
[Applause]

