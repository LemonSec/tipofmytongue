1
00:00:10,070 --> 00:00:14,629
hi hi everyone thanks for attending my

2
00:00:12,590 --> 00:00:17,720
presentation today I'm gonna talk about

3
00:00:14,630 --> 00:00:19,490
spoilers spoilers a new side channel

4
00:00:17,720 --> 00:00:23,660
attacks a new vulnerability we found

5
00:00:19,490 --> 00:00:25,669
last year an Intel processors this is a

6
00:00:23,660 --> 00:00:28,310
joint work by Worcester PI tech

7
00:00:25,670 --> 00:00:31,130
Institute and University of Lubich in

8
00:00:28,310 --> 00:00:38,050
Germany with the list of co-authors that

9
00:00:31,130 --> 00:00:41,510
is in the paper so I think it's kind of

10
00:00:38,050 --> 00:00:43,309
obvious to talk about some optimization

11
00:00:41,510 --> 00:00:45,710
problems in Intel CPUs when you talk

12
00:00:43,309 --> 00:00:48,650
about vulnerabilities we have heard

13
00:00:45,710 --> 00:00:50,140
about a spectral attack we have heard

14
00:00:48,650 --> 00:00:53,449
about cache attacks and these attacks

15
00:00:50,140 --> 00:00:56,239
targets various components in the CPU

16
00:00:53,449 --> 00:01:01,400
that are actually made to make CPU works

17
00:00:56,239 --> 00:01:03,680
faster but if you look deeper like okay

18
00:01:01,400 --> 00:01:06,200
what other things computer architects do

19
00:01:03,680 --> 00:01:08,720
to make CPU fasters there are lots of

20
00:01:06,200 --> 00:01:11,900
speculation going on between the core so

21
00:01:08,720 --> 00:01:14,390
why not just speculate on speculations

22
00:01:11,900 --> 00:01:17,030
and find okay what's other things they

23
00:01:14,390 --> 00:01:19,580
do in the core I mean there aren't very

24
00:01:17,030 --> 00:01:21,380
used buzzwords like in the in the Intel

25
00:01:19,580 --> 00:01:24,770
patterns other patents from other

26
00:01:21,380 --> 00:01:26,750
vendors like speculative prefetching a

27
00:01:24,770 --> 00:01:30,830
speculative event counters and

28
00:01:26,750 --> 00:01:32,480
speculative load operations so this talk

29
00:01:30,830 --> 00:01:35,150
and spoiler of course focused on a

30
00:01:32,480 --> 00:01:38,780
speculative load operations and that's

31
00:01:35,150 --> 00:01:44,690
the optimization mechanism by designed

32
00:01:38,780 --> 00:01:47,060
by Intel processors so if we if we see

33
00:01:44,690 --> 00:01:48,710
like the process or how these load

34
00:01:47,060 --> 00:01:50,240
operations are executed in an

35
00:01:48,710 --> 00:01:53,360
out-of-order fashion and in a

36
00:01:50,240 --> 00:01:55,970
speculative way we can think about like

37
00:01:53,360 --> 00:01:58,159
a like a demonstration here that okay we

38
00:01:55,970 --> 00:02:00,770
have a we have a AIT's a two stage

39
00:01:58,159 --> 00:02:02,810
pipeline that fetch the instruction

40
00:02:00,770 --> 00:02:05,479
decode them and execute them if you

41
00:02:02,810 --> 00:02:07,490
execute some store instruction and

42
00:02:05,480 --> 00:02:10,429
followed by a load instruction we

43
00:02:07,490 --> 00:02:12,650
probably expect the pipeline to use use

44
00:02:10,429 --> 00:02:15,200
these resources in the in various stages

45
00:02:12,650 --> 00:02:17,450
as much as possible so the pipeline is

46
00:02:15,200 --> 00:02:18,828
going to fetch and decode and while it's

47
00:02:17,450 --> 00:02:20,719
fashion because the first instruction

48
00:02:18,829 --> 00:02:22,819
try to fish the second instruction and

49
00:02:20,719 --> 00:02:23,950
use these resources as as much as

50
00:02:22,819 --> 00:02:26,510
possible so

51
00:02:23,950 --> 00:02:28,459
but at some point the pipeline may just

52
00:02:26,510 --> 00:02:30,679
may just get to stall on some

53
00:02:28,460 --> 00:02:32,620
instruction and and those instruction

54
00:02:30,680 --> 00:02:36,200
may just compete for the same resource

55
00:02:32,620 --> 00:02:38,570
so in particular the processor may just

56
00:02:36,200 --> 00:02:40,640
say no distractions are really important

57
00:02:38,570 --> 00:02:43,130
so I want to really execute them fast

58
00:02:40,640 --> 00:02:45,260
and I don't want to lose any time on

59
00:02:43,130 --> 00:02:48,370
computation because of a lot of the

60
00:02:45,260 --> 00:02:50,780
instruction is blocked so what

61
00:02:48,370 --> 00:02:52,610
processors do they just say okay that

62
00:02:50,780 --> 00:02:54,800
let's just execute the load instruction

63
00:02:52,610 --> 00:02:57,140
whatever and I'm going to also execute

64
00:02:54,800 --> 00:02:59,660
what other instructions depend on that

65
00:02:57,140 --> 00:03:01,458
load instructions and and then later on

66
00:02:59,660 --> 00:03:03,920
you'll figure out if this load

67
00:03:01,459 --> 00:03:08,270
instruction had any dependency under the

68
00:03:03,920 --> 00:03:10,130
store instruction before well we want to

69
00:03:08,270 --> 00:03:14,270
compute things correctly we don't want

70
00:03:10,130 --> 00:03:17,090
to just compute something garbage right

71
00:03:14,270 --> 00:03:18,920
so we need to detect if there is a

72
00:03:17,090 --> 00:03:20,840
dependency between this load instruction

73
00:03:18,920 --> 00:03:22,880
any of the store instruction so we need

74
00:03:20,840 --> 00:03:24,290
to basically before committing the

75
00:03:22,880 --> 00:03:26,720
results of the load and other

76
00:03:24,290 --> 00:03:28,670
instructions to the matrix to the

77
00:03:26,720 --> 00:03:30,650
architectural States we need to compare

78
00:03:28,670 --> 00:03:32,899
the value their addresses of the load

79
00:03:30,650 --> 00:03:35,390
beats other stores that happen before

80
00:03:32,900 --> 00:03:38,900
that and the stores of course are not

81
00:03:35,390 --> 00:03:42,559
committed so so we don't know if if they

82
00:03:38,900 --> 00:03:44,269
are complete or implied so what we do we

83
00:03:42,560 --> 00:03:46,459
need to compare we need to compare the

84
00:03:44,269 --> 00:03:48,890
addresses with these these or these and

85
00:03:46,459 --> 00:03:50,570
some of them may be dependent so if a

86
00:03:48,890 --> 00:03:53,179
dependency detected we're going to

87
00:03:50,570 --> 00:03:56,420
basically flush the pipeline and execute

88
00:03:53,180 --> 00:03:58,610
everything again but sometimes it's

89
00:03:56,420 --> 00:04:01,190
dependencies not really that guaranteed

90
00:03:58,610 --> 00:04:02,720
and the processor may just fall stiff

91
00:04:01,190 --> 00:04:05,410
think that something is dependent on

92
00:04:02,720 --> 00:04:07,910
something else and that has to do with

93
00:04:05,410 --> 00:04:10,370
addresses so we mentioned we have to

94
00:04:07,910 --> 00:04:11,750
compare addresses address of the low bit

95
00:04:10,370 --> 00:04:13,820
stores

96
00:04:11,750 --> 00:04:15,709
what are these addresses so we know that

97
00:04:13,820 --> 00:04:17,510
when we write a program we are dealing

98
00:04:15,709 --> 00:04:19,940
with virtual addresses these visual

99
00:04:17,510 --> 00:04:23,000
addresses has to translate to physical

100
00:04:19,940 --> 00:04:25,100
addresses to be able to access various

101
00:04:23,000 --> 00:04:27,979
memory components on the on the core and

102
00:04:25,100 --> 00:04:30,100
off the core the processor used

103
00:04:27,979 --> 00:04:32,330
something like TLB to catch these

104
00:04:30,100 --> 00:04:34,610
translations and if the TLB doesn't have

105
00:04:32,330 --> 00:04:35,889
the translation it uses something like

106
00:04:34,610 --> 00:04:38,610
page miss handler

107
00:04:35,889 --> 00:04:42,129
basically perform the translation so and

108
00:04:38,610 --> 00:04:43,990
then the translation in the help of the

109
00:04:42,129 --> 00:04:46,150
OS is gonna give us a new address which

110
00:04:43,990 --> 00:04:48,400
is called the physical address and the

111
00:04:46,150 --> 00:04:49,960
translation of course only translate the

112
00:04:48,400 --> 00:04:52,030
upper bits of the address and the last

113
00:04:49,960 --> 00:04:54,789
12 bit are the same because we work on a

114
00:04:52,030 --> 00:04:56,049
page granularity so we know that the

115
00:04:54,789 --> 00:04:59,050
last 12 bits of the future and a

116
00:04:56,050 --> 00:05:01,210
physical address are the same but

117
00:04:59,050 --> 00:05:04,090
physical address is important generally

118
00:05:01,210 --> 00:05:06,789
because that's how we map DRAM banks

119
00:05:04,090 --> 00:05:11,529
that's how we map l3 cache and and some

120
00:05:06,789 --> 00:05:13,180
other components so with that we see we

121
00:05:11,529 --> 00:05:15,750
have some design challenges if you are

122
00:05:13,180 --> 00:05:17,889
I'm not a computer architect but

123
00:05:15,750 --> 00:05:19,930
computer architects always deal with

124
00:05:17,889 --> 00:05:21,729
this problems ok what should we do we

125
00:05:19,930 --> 00:05:23,020
don't even have the translation result

126
00:05:21,729 --> 00:05:25,628
it should we just wait for all the

127
00:05:23,020 --> 00:05:27,909
stores to complete or should we should

128
00:05:25,629 --> 00:05:30,370
we just forward the data from the store

129
00:05:27,909 --> 00:05:33,659
to load and see maybe this data was the

130
00:05:30,370 --> 00:05:36,279
data of the Lord these create lots of

131
00:05:33,659 --> 00:05:39,159
question ok how am I doing this really

132
00:05:36,279 --> 00:05:43,990
how do I detect if there is a dependency

133
00:05:39,159 --> 00:05:46,120
or not so we get to a spoiler so a

134
00:05:43,990 --> 00:05:46,659
spoiler basically focused on this

135
00:05:46,120 --> 00:05:48,759
problem

136
00:05:46,659 --> 00:05:50,229
ok how these address dependencies are

137
00:05:48,759 --> 00:05:53,919
actually checked and compared with each

138
00:05:50,229 --> 00:05:56,110
other so believe we looked at how Intel

139
00:05:53,919 --> 00:05:58,659
processor deal with this problem and

140
00:05:56,110 --> 00:06:00,310
basically there is a component called

141
00:05:58,659 --> 00:06:01,810
memory order buffer inside the core

142
00:06:00,310 --> 00:06:04,270
which memory order buffer is where all

143
00:06:01,810 --> 00:06:05,879
this magic of memory ordering and

144
00:06:04,270 --> 00:06:08,289
address dependency checks our happy

145
00:06:05,879 --> 00:06:09,849
memory order buffer has some store

146
00:06:08,289 --> 00:06:12,818
buffer and load buffer and store buffer

147
00:06:09,849 --> 00:06:14,860
can have some metadata about the address

148
00:06:12,819 --> 00:06:18,699
information and other other stuff in the

149
00:06:14,860 --> 00:06:20,620
core so one thing that we have noticed

150
00:06:18,699 --> 00:06:22,870
that is mentioned in various like Intel

151
00:06:20,620 --> 00:06:24,759
documents that the store buffer actually

152
00:06:22,870 --> 00:06:27,039
may not contain the full physical

153
00:06:24,759 --> 00:06:28,930
address and this means that basically

154
00:06:27,039 --> 00:06:31,479
these address checks might be really

155
00:06:28,930 --> 00:06:33,099
difficult and there is a there is a

156
00:06:31,479 --> 00:06:34,960
whole pattern on this that's how to

157
00:06:33,099 --> 00:06:37,240
resolve false dependencies on a

158
00:06:34,960 --> 00:06:39,818
speculative load instructions and there

159
00:06:37,240 --> 00:06:41,589
are lots of various confusing arguments

160
00:06:39,819 --> 00:06:44,649
how the upper add recipes are checked

161
00:06:41,589 --> 00:06:45,590
and sometimes it's even mentioned at ok

162
00:06:44,649 --> 00:06:47,420
the upper

163
00:06:45,590 --> 00:06:49,969
disputes are partial at the speech

164
00:06:47,420 --> 00:06:51,500
checks or if they're at physical address

165
00:06:49,970 --> 00:06:53,690
which doesn't exist we just kind of

166
00:06:51,500 --> 00:06:56,690
we're just going to assume this check

167
00:06:53,690 --> 00:07:00,290
has a dependency and it may be just a

168
00:06:56,690 --> 00:07:03,980
false dependency so we came up with we

169
00:07:00,290 --> 00:07:06,320
can attack we and the way they attack

170
00:07:03,980 --> 00:07:08,630
war is we basically try to check any

171
00:07:06,320 --> 00:07:12,110
address dependency on the upper address

172
00:07:08,630 --> 00:07:14,690
Beach so we pick a bunch of visual pages

173
00:07:12,110 --> 00:07:16,760
and we we try we allocate these virtual

174
00:07:14,690 --> 00:07:18,920
pages I mean use a window size to

175
00:07:16,760 --> 00:07:21,560
perform memory write to this to this

176
00:07:18,920 --> 00:07:25,070
official page so we do 64 memory writes

177
00:07:21,560 --> 00:07:28,150
and followed by a load operation and we

178
00:07:25,070 --> 00:07:32,210
picked 64 because 64 is bigger than the

179
00:07:28,150 --> 00:07:33,620
bigger than the store buffer size so we

180
00:07:32,210 --> 00:07:36,409
can feel all this storm of our entries

181
00:07:33,620 --> 00:07:38,300
so when we load this memory operation

182
00:07:36,410 --> 00:07:40,310
and we measure the time you expect a lot

183
00:07:38,300 --> 00:07:42,560
of pression to have maybe a variable

184
00:07:40,310 --> 00:07:44,510
timing because the store operation may

185
00:07:42,560 --> 00:07:47,420
actually create some sort of dependency

186
00:07:44,510 --> 00:07:49,400
problem so we did this and we basically

187
00:07:47,420 --> 00:07:51,530
it straight over some addresses and at

188
00:07:49,400 --> 00:07:54,380
some point we hit an address that there

189
00:07:51,530 --> 00:07:56,119
is a very high latency for a load

190
00:07:54,380 --> 00:07:58,219
operation and we were like kind of

191
00:07:56,120 --> 00:08:01,910
surprised when we saw that okay there is

192
00:07:58,220 --> 00:08:04,760
a thousand cycle latency is it really

193
00:08:01,910 --> 00:08:06,800
real do we do something wrong and we did

194
00:08:04,760 --> 00:08:08,870
all sort of analysis with performance

195
00:08:06,800 --> 00:08:10,550
counters that's as I said yeah it's

196
00:08:08,870 --> 00:08:13,190
actually there is a thousand cycle delay

197
00:08:10,550 --> 00:08:14,510
for just one load operation and of

198
00:08:13,190 --> 00:08:18,020
course depending on the system is

199
00:08:14,510 --> 00:08:19,430
sometimes 500 cycles a thousand cycle so

200
00:08:18,020 --> 00:08:21,169
we looked at what what is the

201
00:08:19,430 --> 00:08:23,780
relationship of this store address and

202
00:08:21,170 --> 00:08:26,240
lured address and we noticed that on the

203
00:08:23,780 --> 00:08:28,789
physical address the 8-bit of the

204
00:08:26,240 --> 00:08:29,990
physical page page frame and the

205
00:08:28,790 --> 00:08:31,990
physical page frame of the load

206
00:08:29,990 --> 00:08:35,030
operation our eggs are exactly the same

207
00:08:31,990 --> 00:08:36,980
so this gives us two piece of

208
00:08:35,030 --> 00:08:39,260
information first of all this is a side

209
00:08:36,980 --> 00:08:42,200
channel and the last twelve bit of any

210
00:08:39,260 --> 00:08:44,090
any addresses so we can actually use it

211
00:08:42,200 --> 00:08:46,940
for instance actress context switches to

212
00:08:44,090 --> 00:08:49,220
leak some metadata some information and

213
00:08:46,940 --> 00:08:50,780
more importantly we can actually learn

214
00:08:49,220 --> 00:08:52,670
something about physical page frames

215
00:08:50,780 --> 00:08:54,920
that we are not allowed to have access

216
00:08:52,670 --> 00:08:58,670
by default and on any motor

217
00:08:54,920 --> 00:08:59,370
configuration so and if you had iterate

218
00:08:58,670 --> 00:09:01,260
over more

219
00:08:59,370 --> 00:09:04,260
as we find more of these addresses and

220
00:09:01,260 --> 00:09:09,480
we can basically use them to conduct our

221
00:09:04,260 --> 00:09:12,210
attacks so we're going to jump to cache

222
00:09:09,480 --> 00:09:15,510
attacks or how we can use these to do

223
00:09:12,210 --> 00:09:17,070
better cache attacks so cache attacks

224
00:09:15,510 --> 00:09:19,410
has been around for a while there is a

225
00:09:17,070 --> 00:09:21,480
there are two common attacks that most

226
00:09:19,410 --> 00:09:23,279
people focus on there is a flush and

227
00:09:21,480 --> 00:09:23,910
another attack and there is a primary

228
00:09:23,279 --> 00:09:26,310
attack

229
00:09:23,910 --> 00:09:29,160
well flush and reload is a powerful

230
00:09:26,310 --> 00:09:30,900
attack but it has a strong assumption of

231
00:09:29,160 --> 00:09:34,350
shared memory which is not available on

232
00:09:30,900 --> 00:09:36,390
all systems and for instance in sandbox

233
00:09:34,350 --> 00:09:39,420
environment or in Jaworski we can also

234
00:09:36,390 --> 00:09:41,100
not do flush anyway but there's all the

235
00:09:39,420 --> 00:09:43,860
other attack called primary probe which

236
00:09:41,100 --> 00:09:45,990
is the more relevant data and practical

237
00:09:43,860 --> 00:09:48,600
attack because you don't have such an

238
00:09:45,990 --> 00:09:51,390
assumption for a primary attack we

239
00:09:48,600 --> 00:09:54,960
actually need to know how cache sets are

240
00:09:51,390 --> 00:09:57,930
mapped in the in the last level cache so

241
00:09:54,960 --> 00:10:00,650
basically if you want to as an attacker

242
00:09:57,930 --> 00:10:04,349
attack like a weak team data that's

243
00:10:00,650 --> 00:10:05,880
accessed to some sort of do as some sort

244
00:10:04,350 --> 00:10:07,680
of secret dependent memory accident we

245
00:10:05,880 --> 00:10:10,529
need to know which set the victim access

246
00:10:07,680 --> 00:10:12,120
and also we need to have a good amount

247
00:10:10,529 --> 00:10:15,029
of addresses that they all map to that

248
00:10:12,120 --> 00:10:17,970
set these cells generally can occupy

249
00:10:15,029 --> 00:10:21,750
occupy some number of lines for instance

250
00:10:17,970 --> 00:10:23,190
here we say eight lines per set on Intel

251
00:10:21,750 --> 00:10:25,320
processors now there is sixteen lines

252
00:10:23,190 --> 00:10:27,990
per set on last level cache so we need

253
00:10:25,320 --> 00:10:29,550
to have eight or sixteen number of

254
00:10:27,990 --> 00:10:33,270
addresses that they all match the same

255
00:10:29,550 --> 00:10:35,339
set so how can we do that well previous

256
00:10:33,270 --> 00:10:37,199
work either assumed that there is some

257
00:10:35,339 --> 00:10:38,880
sort of Miss configuration on the system

258
00:10:37,200 --> 00:10:42,120
or some sort of assumption about

259
00:10:38,880 --> 00:10:44,100
physical address or they try to brute

260
00:10:42,120 --> 00:10:46,709
force these addresses to find to find

261
00:10:44,100 --> 00:10:48,779
some eviction sets or there are some of

262
00:10:46,709 --> 00:10:50,819
course improved work and algorithms on

263
00:10:48,779 --> 00:10:52,589
that but if you just know some

264
00:10:50,820 --> 00:10:54,360
information about physical page page

265
00:10:52,589 --> 00:10:56,670
number you can just we can just go ahead

266
00:10:54,360 --> 00:11:00,150
and create efficiencies as much faster

267
00:10:56,670 --> 00:11:03,689
and more reliably and the reason for

268
00:11:00,150 --> 00:11:05,970
that is so on Intel processors we use

269
00:11:03,690 --> 00:11:09,690
the upper upper beats after the six bit

270
00:11:05,970 --> 00:11:12,480
to map to these sets and so we already

271
00:11:09,690 --> 00:11:13,050
know six bits of it but the other bits

272
00:11:12,480 --> 00:11:15,149
are

273
00:11:13,050 --> 00:11:17,670
different from usual to physical address

274
00:11:15,149 --> 00:11:20,339
and with the help of a spoiler we learn

275
00:11:17,670 --> 00:11:22,890
another 8 feet and we already know 14 we

276
00:11:20,339 --> 00:11:25,080
basically know 14 bits and this makes a

277
00:11:22,890 --> 00:11:27,510
fictional situation much faster so we

278
00:11:25,080 --> 00:11:30,600
can for instance to a primary profit

279
00:11:27,510 --> 00:11:32,610
icon LLC faster and more reliable so we

280
00:11:30,600 --> 00:11:36,330
implemented this in JavaScript and of

281
00:11:32,610 --> 00:11:38,220
course in native environment we got a

282
00:11:36,330 --> 00:11:42,180
very good speed up but in JavaScript we

283
00:11:38,220 --> 00:11:44,940
had some noise so we didn't get like 256

284
00:11:42,180 --> 00:11:46,800
times the speed of an eviction situation

285
00:11:44,940 --> 00:11:50,910
but we still that's a good amount of a

286
00:11:46,800 --> 00:11:53,160
speed of an accuracy and you can check

287
00:11:50,910 --> 00:11:55,890
the paper form or comparison result on

288
00:11:53,160 --> 00:11:59,130
that the other thing we want to discuss

289
00:11:55,890 --> 00:12:01,500
is how a spoiler basically improve row

290
00:11:59,130 --> 00:12:04,860
hammer attack so the similar concept

291
00:12:01,500 --> 00:12:06,750
applies to row hammer where memory banks

292
00:12:04,860 --> 00:12:11,130
in the DRAM are mapped using the

293
00:12:06,750 --> 00:12:13,320
physical address so there are some

294
00:12:11,130 --> 00:12:15,689
requirements to perform a successful row

295
00:12:13,320 --> 00:12:18,839
hammer attack first of all we need to

296
00:12:15,690 --> 00:12:22,470
co-locate in the same Bank as a victim

297
00:12:18,839 --> 00:12:24,899
bank and to be able to flip a bit in the

298
00:12:22,470 --> 00:12:27,209
same Bank and create row buffer

299
00:12:24,899 --> 00:12:29,910
conflicts and the other requirement is

300
00:12:27,209 --> 00:12:31,729
that we need to have for a double-sided

301
00:12:29,910 --> 00:12:35,790
row hammer we need to have access to

302
00:12:31,730 --> 00:12:38,579
contiguous memory pages so a spoiler can

303
00:12:35,790 --> 00:12:41,610
actually help us to relax these problems

304
00:12:38,579 --> 00:12:43,649
and actually improve the attacks in a

305
00:12:41,610 --> 00:12:45,329
practical sense so we don't need to have

306
00:12:43,649 --> 00:12:48,450
access to any physical information or

307
00:12:45,329 --> 00:12:50,880
just brute force addresses so we need

308
00:12:48,450 --> 00:12:53,339
some experiments how we can use the

309
00:12:50,880 --> 00:12:56,339
spoiler for that we use the drama tool

310
00:12:53,339 --> 00:12:57,899
to actually reverse engineer some some

311
00:12:56,339 --> 00:12:59,070
computer configuration some laptop

312
00:12:57,899 --> 00:13:02,610
configuration and we notice that

313
00:12:59,070 --> 00:13:05,070
generally maybe between 19 to 22 3 bits

314
00:13:02,610 --> 00:13:07,380
of addresses are actually used to map

315
00:13:05,070 --> 00:13:08,640
the physical address to the DRAM banks

316
00:13:07,380 --> 00:13:11,579
and of course maybe with some

317
00:13:08,640 --> 00:13:15,329
configurations more bits are used and

318
00:13:11,579 --> 00:13:17,819
then if you already know 20 bits then

319
00:13:15,329 --> 00:13:20,430
this makes it much easier because we

320
00:13:17,820 --> 00:13:23,850
have a high probability to cause row

321
00:13:20,430 --> 00:13:25,290
buffer conflicts so this is before a

322
00:13:23,850 --> 00:13:26,700
single-sided roarhammer but how

323
00:13:25,290 --> 00:13:30,300
double-sided wrong

324
00:13:26,700 --> 00:13:32,280
for double-sided rorimer we use another

325
00:13:30,300 --> 00:13:35,250
feature of a spoiler to actually detect

326
00:13:32,280 --> 00:13:38,400
contiguous memory and the way we do that

327
00:13:35,250 --> 00:13:41,330
is basically so when we run a spoiler

328
00:13:38,400 --> 00:13:44,340
and we find these Peaks because they

329
00:13:41,330 --> 00:13:47,820
because they have the common 8-bit same

330
00:13:44,340 --> 00:13:51,470
so they happen if the memories continues

331
00:13:47,820 --> 00:13:54,240
they should happen after every 256 page

332
00:13:51,470 --> 00:13:56,340
so we did this such an experiment and we

333
00:13:54,240 --> 00:13:59,370
notice that okay every time these Peaks

334
00:13:56,340 --> 00:14:01,860
become consistent and they are 256 steps

335
00:13:59,370 --> 00:14:04,740
apart we actually get contiguous memory

336
00:14:01,860 --> 00:14:07,110
so then we start just hammering that

337
00:14:04,740 --> 00:14:10,650
contiguous memory instead of instead of

338
00:14:07,110 --> 00:14:14,550
just randomly hammering random addresses

339
00:14:10,650 --> 00:14:16,530
and then we notice that we can get speed

340
00:14:14,550 --> 00:14:18,569
fleets in like between 10 to 20 seconds

341
00:14:16,530 --> 00:14:20,760
and some of the configurations that we

342
00:14:18,570 --> 00:14:24,060
couldn't get with flees with like random

343
00:14:20,760 --> 00:14:28,200
hammering using existing tools which

344
00:14:24,060 --> 00:14:29,760
this is I think an important step for

345
00:14:28,200 --> 00:14:33,030
raw hammer attack because in raw hammer

346
00:14:29,760 --> 00:14:35,700
attacks we basically need to hammer

347
00:14:33,030 --> 00:14:37,319
correctly with large amount so if we

348
00:14:35,700 --> 00:14:40,080
lose time on hammering Rongrong

349
00:14:37,320 --> 00:14:42,030
addresses we might end up hammering for

350
00:14:40,080 --> 00:14:45,360
two weeks and not getting a single bit

351
00:14:42,030 --> 00:14:48,709
flips so I start the story of the

352
00:14:45,360 --> 00:14:51,930
vulnerabilities here how we did

353
00:14:48,710 --> 00:14:58,470
responsible disclosure which wasn't very

354
00:14:51,930 --> 00:14:59,400
coordinated and yeah and I mean so so we

355
00:14:58,470 --> 00:15:02,670
disclosed the issue

356
00:14:59,400 --> 00:15:05,430
we contacted we got some acknowledged ok

357
00:15:02,670 --> 00:15:07,709
we received but no action was performed

358
00:15:05,430 --> 00:15:10,949
and then at some point we released the

359
00:15:07,710 --> 00:15:14,010
paper and and the CV was assigned

360
00:15:10,950 --> 00:15:17,030
actually after we released the paper and

361
00:15:14,010 --> 00:15:20,420
after media picked up the issue and

362
00:15:17,030 --> 00:15:23,850
thanks to media we got some free logos

363
00:15:20,420 --> 00:15:26,339
which I don't know that's like a CPU

364
00:15:23,850 --> 00:15:30,540
that's burned I don't know what is that

365
00:15:26,340 --> 00:15:34,200
like heartbleed with a spectra I don't

366
00:15:30,540 --> 00:15:36,000
even know why but but I like the one in

367
00:15:34,200 --> 00:15:41,260
the middle that at least it matches the

368
00:15:36,000 --> 00:15:50,300
name so and yeah that's the story

369
00:15:41,260 --> 00:15:51,350
any question okay thank you very much

370
00:15:50,300 --> 00:15:56,719
for your talk are there any questions

371
00:15:51,350 --> 00:15:58,220
please can you hear me yeah I have a

372
00:15:56,720 --> 00:16:01,070
couple of questions about your Oh hammer

373
00:15:58,220 --> 00:16:03,710
experiments were those done with ddr3

374
00:16:01,070 --> 00:16:06,470
only or he did use ddr4 at all we only

375
00:16:03,710 --> 00:16:08,360
did we did the r3 and have you made any

376
00:16:06,470 --> 00:16:13,190
changes to the bios of those platforms

377
00:16:08,360 --> 00:16:14,960
no so like was was memory interleaved

378
00:16:13,190 --> 00:16:18,010
across different themes and across

379
00:16:14,960 --> 00:16:18,010
different banks and right

380
00:16:18,820 --> 00:16:23,510
so what do you exactly mean by

381
00:16:21,680 --> 00:16:27,709
internally between different banks and

382
00:16:23,510 --> 00:16:29,300
banks so one feature with TM is to sort

383
00:16:27,710 --> 00:16:30,860
of interleaved memory and make sure that

384
00:16:29,300 --> 00:16:33,140
consecutive physical addresses go to

385
00:16:30,860 --> 00:16:36,080
different banks that is a performance

386
00:16:33,140 --> 00:16:38,240
optimization okay to basically sort of

387
00:16:36,080 --> 00:16:41,000
access banking seem parallel when you

388
00:16:38,240 --> 00:16:42,410
actually awesome well we had we had

389
00:16:41,000 --> 00:16:43,850
general thing in general is my

390
00:16:42,410 --> 00:16:45,439
impression that is row hammer attacks

391
00:16:43,850 --> 00:16:46,790
actually turn off all of these things

392
00:16:45,440 --> 00:16:48,380
because the moment you actually bring

393
00:16:46,790 --> 00:16:51,170
interleaving your your address is

394
00:16:48,380 --> 00:16:54,080
scattered throughout your whole okay

395
00:16:51,170 --> 00:16:57,050
well so we didn't change any

396
00:16:54,080 --> 00:16:58,550
configuration after after system okay

397
00:16:57,050 --> 00:17:00,140
let me ask a different question how much

398
00:16:58,550 --> 00:17:02,689
memory did you have on those in those

399
00:17:00,140 --> 00:17:05,329
platforms was it just one team or what

400
00:17:02,690 --> 00:17:07,670
did we have there were lap there were

401
00:17:05,329 --> 00:17:11,629
some laptops and desktop too but on the

402
00:17:07,670 --> 00:17:13,640
desktop we had like two two team and we

403
00:17:11,630 --> 00:17:17,720
had a set of which like a dual-channel

404
00:17:13,640 --> 00:17:20,060
dude to team and yeah but the work is

405
00:17:17,720 --> 00:17:21,680
close I just have that but I understand

406
00:17:20,060 --> 00:17:23,958
that for instance if you want to do the

407
00:17:21,680 --> 00:17:28,459
same attack on a system that has maybe

408
00:17:23,959 --> 00:17:29,060
lots of DRAM of course attack they

409
00:17:28,459 --> 00:17:30,920
attack

410
00:17:29,060 --> 00:17:32,120
probably because to thing that is

411
00:17:30,920 --> 00:17:33,530
side-channel way of actual

412
00:17:32,120 --> 00:17:38,840
reverse-engineer the physical mapping is

413
00:17:33,530 --> 00:17:41,120
great so it's yes hi my name is guru Raj

414
00:17:38,840 --> 00:17:44,330
from I'm from Georgia Tech this great

415
00:17:41,120 --> 00:17:46,780
work love the presentation thanks I had

416
00:17:44,330 --> 00:17:49,790
a question more around mitigation

417
00:17:46,780 --> 00:17:51,270
approaches so given that memory

418
00:17:49,790 --> 00:17:54,180
disambiguation is

419
00:17:51,270 --> 00:17:56,070
of at least computer architects have

420
00:17:54,180 --> 00:17:58,350
believed that that's going to cause a

421
00:17:56,070 --> 00:18:01,800
lot of overhead so they have a lot of

422
00:17:58,350 --> 00:18:03,719
prediction short of turning it off is

423
00:18:01,800 --> 00:18:06,330
there any other way to prevent this I'd

424
00:18:03,720 --> 00:18:09,060
channel in your opinion well if you talk

425
00:18:06,330 --> 00:18:11,790
about general microarchitecture

426
00:18:09,060 --> 00:18:14,280
I'm not architect by I assume but there

427
00:18:11,790 --> 00:18:17,639
are ways to implement these to make it's

428
00:18:14,280 --> 00:18:19,320
not like this right and for instance we

429
00:18:17,640 --> 00:18:24,450
couldn't reproduce the same thing on AMD

430
00:18:19,320 --> 00:18:27,110
not that AMD is better CPU but maybe we

431
00:18:24,450 --> 00:18:30,560
can find something else on that but but

432
00:18:27,110 --> 00:18:33,840
from the practical aspect intel didn't

433
00:18:30,560 --> 00:18:37,679
provide any hardware or plan to fix this

434
00:18:33,840 --> 00:18:40,409
in hardware and they provided some

435
00:18:37,680 --> 00:18:44,130
guidance on how to prevent side-channel

436
00:18:40,410 --> 00:18:50,190
attacks in software in general yeah

437
00:18:44,130 --> 00:18:53,040
thanks ok so I think we should move to

438
00:18:50,190 --> 00:18:55,370
the next talk so let's find a speaker

439
00:18:53,040 --> 00:18:55,370
again

