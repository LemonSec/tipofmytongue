1
00:00:10,049 --> 00:00:14,369
so thanks so much for coming I'm

2
00:00:12,089 --> 00:00:15,779
delighted to be here I come to this

3
00:00:14,369 --> 00:00:17,849
conference a number of times over the

4
00:00:15,779 --> 00:00:20,189
years and so I'm happy to come back and

5
00:00:17,849 --> 00:00:24,930
special thanks to devdutta for inviting

6
00:00:20,189 --> 00:00:27,239
me I am trained as a lawyer but do a lot

7
00:00:24,930 --> 00:00:31,969
of technical work at the University of

8
00:00:27,239 --> 00:00:36,120
California and have advised both private

9
00:00:31,969 --> 00:00:38,129
clients and agencies about privacy and

10
00:00:36,120 --> 00:00:40,169
security matters and so I thought I'd

11
00:00:38,129 --> 00:00:41,910
talk about today is the things I've

12
00:00:40,170 --> 00:00:44,820
learned along the way the different ways

13
00:00:41,910 --> 00:00:48,029
of framing issues of presenting them in

14
00:00:44,820 --> 00:00:51,050
hopes that they can increase your

15
00:00:48,030 --> 00:00:55,230
efficacy when speaking with regulators

16
00:00:51,050 --> 00:00:57,390
so let me start let me start in a

17
00:00:55,230 --> 00:01:00,449
different place though I'm working on a

18
00:00:57,390 --> 00:01:02,760
book on cybersecurity right now for my

19
00:01:00,450 --> 00:01:04,049
cybersecurity class and so none of you

20
00:01:02,760 --> 00:01:06,899
would learn anything from it it's really

21
00:01:04,049 --> 00:01:09,570
for my students but the real pleasure of

22
00:01:06,899 --> 00:01:12,240
working on this project is getting to

23
00:01:09,570 --> 00:01:15,119
read all the literature in computer

24
00:01:12,240 --> 00:01:17,419
security and going back to reports from

25
00:01:15,119 --> 00:01:20,340
the night you know even from the 1970s

26
00:01:17,420 --> 00:01:23,450
this report that was authored by Willis

27
00:01:20,340 --> 00:01:26,399
where what am I at one of my CS Heroes

28
00:01:23,450 --> 00:01:29,009
was extraordinarily prescient and you

29
00:01:26,399 --> 00:01:31,350
know written in 1970 it has this little

30
00:01:29,009 --> 00:01:33,630
nugget in the very beginning of it it's

31
00:01:31,350 --> 00:01:35,579
important to influence design of

32
00:01:33,630 --> 00:01:37,679
computers and so on so that security

33
00:01:35,579 --> 00:01:40,048
controls can be installed before the

34
00:01:37,679 --> 00:01:42,959
fact and as an integral part of the

35
00:01:40,049 --> 00:01:44,340
system so I would say that this is one

36
00:01:42,959 --> 00:01:46,319
of the things that regulators have

37
00:01:44,340 --> 00:01:49,349
finally figured out regulators are

38
00:01:46,319 --> 00:01:49,859
talking about security by design privacy

39
00:01:49,349 --> 00:01:52,979
by design

40
00:01:49,859 --> 00:01:54,449
Willis ware was able to get his

41
00:01:52,979 --> 00:01:57,539
committee together and come to a

42
00:01:54,450 --> 00:02:00,899
consensus on this recommendation in 1970

43
00:01:57,539 --> 00:02:03,979
so that's that's pretty impressive

44
00:02:00,899 --> 00:02:07,469
another paper from the literature that I

45
00:02:03,979 --> 00:02:11,700
read recently sustaining and it's

46
00:02:07,469 --> 00:02:14,519
prescience written in 1979 by lieutenant

47
00:02:11,700 --> 00:02:16,859
colonel at the Navy Postgraduate School

48
00:02:14,520 --> 00:02:19,430
it's called computer security the

49
00:02:16,860 --> 00:02:23,520
Achilles heel of electronic air force

50
00:02:19,430 --> 00:02:25,220
it's filled with anecdotes that anyone

51
00:02:23,520 --> 00:02:27,570
even you know even kind of the

52
00:02:25,220 --> 00:02:30,390
regulator's would recognize today about

53
00:02:27,570 --> 00:02:32,459
the pathologies of software development

54
00:02:30,390 --> 00:02:33,899
and the types of vulnerabilities that

55
00:02:32,460 --> 00:02:36,150
creep in and the difficulty of

56
00:02:33,900 --> 00:02:38,670
identifying those vulnerabilities and

57
00:02:36,150 --> 00:02:42,660
doing something about them in and so

58
00:02:38,670 --> 00:02:44,640
there's I'd say five different anecdotes

59
00:02:42,660 --> 00:02:47,190
that you would you read in the pages of

60
00:02:44,640 --> 00:02:50,220
this article and then you could think of

61
00:02:47,190 --> 00:02:53,540
recent examples of these very same

62
00:02:50,220 --> 00:02:56,820
problems occurring over and over again

63
00:02:53,540 --> 00:02:59,220
interestingly and the reason why I'm

64
00:02:56,820 --> 00:03:01,790
showing you this is that he motivates

65
00:02:59,220 --> 00:03:04,650
the paper with a hypothetical and the

66
00:03:01,790 --> 00:03:08,810
hypothetical is that the KGB is giving a

67
00:03:04,650 --> 00:03:11,730
briefing the KGB KGB analyst is giving a

68
00:03:08,810 --> 00:03:14,250
briefing to his colleagues and he says

69
00:03:11,730 --> 00:03:15,959
guess what the Americans have put all

70
00:03:14,250 --> 00:03:18,690
their most sensitive secrets into

71
00:03:15,960 --> 00:03:19,710
computers and they they kind of know

72
00:03:18,690 --> 00:03:22,650
that they're vulnerable

73
00:03:19,710 --> 00:03:23,970
they behave in the abstract they

74
00:03:22,650 --> 00:03:28,560
understand that their computers are

75
00:03:23,970 --> 00:03:30,630
vulnerable but absent verified examples

76
00:03:28,560 --> 00:03:31,890
of us breaking into those computers

77
00:03:30,630 --> 00:03:33,959
they're not going to do anything about

78
00:03:31,890 --> 00:03:36,630
those vulnerabilities and it's like wow

79
00:03:33,959 --> 00:03:39,720
he really he really had the hypothetical

80
00:03:36,630 --> 00:03:41,430
right and and I feel like this is what's

81
00:03:39,720 --> 00:03:43,680
happened in the commercial sector with

82
00:03:41,430 --> 00:03:45,180
cloud and a whole lot of other areas we

83
00:03:43,680 --> 00:03:48,330
knew in theory that there were problems

84
00:03:45,180 --> 00:03:51,450
but it wasn't until those problems found

85
00:03:48,330 --> 00:03:53,490
an actual execution that we were willing

86
00:03:51,450 --> 00:03:55,049
to to really grapple with them and do

87
00:03:53,490 --> 00:03:56,430
something about them um if you're

88
00:03:55,050 --> 00:03:58,980
interested in reading this article just

89
00:03:56,430 --> 00:04:02,010
email me and I'll shoot you my copy of

90
00:03:58,980 --> 00:04:05,190
it it's it's a fantastic a fantastic

91
00:04:02,010 --> 00:04:07,649
read he talks about his Tiger teams at

92
00:04:05,190 --> 00:04:09,209
at the air force but you know what we'd

93
00:04:07,650 --> 00:04:11,850
call a red team today and how they were

94
00:04:09,209 --> 00:04:14,459
able to break into everything and how

95
00:04:11,850 --> 00:04:17,940
they would even find they he gives this

96
00:04:14,459 --> 00:04:21,660
fantastic example of how his team plants

97
00:04:17,940 --> 00:04:23,430
a small piece small bit of malware into

98
00:04:21,660 --> 00:04:25,770
a defense contractors system and the

99
00:04:23,430 --> 00:04:27,660
defense contractor can't find it even

100
00:04:25,770 --> 00:04:28,950
when told about it even when told this

101
00:04:27,660 --> 00:04:31,169
is what we put in your system they can't

102
00:04:28,950 --> 00:04:33,690
find it not only that the defense

103
00:04:31,169 --> 00:04:35,370
contractor min manages to replicate the

104
00:04:33,690 --> 00:04:36,629
vulnerability and put it into other

105
00:04:35,370 --> 00:04:39,869
systems

106
00:04:36,629 --> 00:04:41,580
it's just astounding totally worth a

107
00:04:39,869 --> 00:04:43,439
reading so and getting ready for this

108
00:04:41,580 --> 00:04:46,349
talk and and having read these recent

109
00:04:43,439 --> 00:04:47,729
papers I asked myself the question you

110
00:04:46,349 --> 00:04:49,830
know why was it that Willis where are in

111
00:04:47,729 --> 00:04:52,258
these other these other people most of

112
00:04:49,830 --> 00:04:55,050
whom were tied into the military and the

113
00:04:52,259 --> 00:04:56,550
intelligence community how is it that

114
00:04:55,050 --> 00:04:59,099
they had all these insights and it's

115
00:04:56,550 --> 00:05:01,740
taken us so long in the regulatory field

116
00:04:59,099 --> 00:05:04,349
so when I say us I mean the lawyers why

117
00:05:01,740 --> 00:05:06,300
is it taken the lawyers so long to

118
00:05:04,349 --> 00:05:08,610
figure out these lessons that were

119
00:05:06,300 --> 00:05:11,659
articulated for tea and and fit almost

120
00:05:08,610 --> 00:05:14,129
50 years ago and of course I think um

121
00:05:11,659 --> 00:05:16,259
we're familiar with the problem I mean

122
00:05:14,129 --> 00:05:19,770
the overall problem is that computing is

123
00:05:16,259 --> 00:05:22,409
so compelling and so beneficial that we

124
00:05:19,770 --> 00:05:26,669
have to adopt it we have no real choice

125
00:05:22,409 --> 00:05:31,369
and because we cannot fully manage the

126
00:05:26,669 --> 00:05:33,930
security problems we deny them we say

127
00:05:31,369 --> 00:05:36,869
it's just normal it's just kind of risk

128
00:05:33,930 --> 00:05:39,869
we have to accept and we become resigned

129
00:05:36,869 --> 00:05:41,819
to them I um there's a lot of examples

130
00:05:39,869 --> 00:05:44,009
of where this has happened in in society

131
00:05:41,819 --> 00:05:47,819
I car safety is another example for a

132
00:05:44,009 --> 00:05:52,399
long time we conceived of car accidents

133
00:05:47,819 --> 00:05:54,539
and driver deaths as inevitable

134
00:05:52,399 --> 00:05:57,209
consequences of the car we didn't

135
00:05:54,539 --> 00:06:02,579
conceive of the idea that more safety

136
00:05:57,209 --> 00:06:04,529
could be built into them so what I

137
00:06:02,579 --> 00:06:06,449
thought about today to talk about is

138
00:06:04,529 --> 00:06:09,930
give some concrete examples of how we

139
00:06:06,449 --> 00:06:12,839
could overcome this denial and

140
00:06:09,930 --> 00:06:15,059
resignation to insecurity in the

141
00:06:12,839 --> 00:06:16,559
regulatory community so I'm going to

142
00:06:15,059 --> 00:06:18,899
talk about the legal tools that

143
00:06:16,559 --> 00:06:21,659
regulators have I'm going to talk about

144
00:06:18,899 --> 00:06:23,819
how the regulator's think about their

145
00:06:21,659 --> 00:06:27,089
tools what their kind of psychology is

146
00:06:23,819 --> 00:06:30,360
and then finally how you might use your

147
00:06:27,089 --> 00:06:32,759
expertise to convince them to take

148
00:06:30,360 --> 00:06:37,169
action in areas where you think it is

149
00:06:32,759 --> 00:06:38,399
important so a lot of what I've a lot of

150
00:06:37,169 --> 00:06:41,430
what I've written about is the idea that

151
00:06:38,399 --> 00:06:43,319
consumer protection law the body of law

152
00:06:41,430 --> 00:06:47,069
that we could call consumer protection

153
00:06:43,319 --> 00:06:53,039
law has a profound

154
00:06:47,069 --> 00:06:55,049
information security mandate so when we

155
00:06:53,039 --> 00:06:58,929
talk about the Federal Trade Commission

156
00:06:55,049 --> 00:07:01,119
suing companies for insecurity it's not

157
00:06:58,929 --> 00:07:03,849
because the Federal Trade Commission has

158
00:07:01,119 --> 00:07:05,829
an information security law it's because

159
00:07:03,849 --> 00:07:09,069
the Federal Trade Commission is using

160
00:07:05,829 --> 00:07:11,559
its general power to police consumer

161
00:07:09,069 --> 00:07:14,079
protection basically the quality and

162
00:07:11,559 --> 00:07:16,809
safety of goods and services and it's

163
00:07:14,079 --> 00:07:18,909
interpreting that body of law as

164
00:07:16,809 --> 00:07:22,149
imposing an information security

165
00:07:18,909 --> 00:07:24,669
requirement so that's a that's a bit

166
00:07:22,149 --> 00:07:27,249
like skiing on stilts right we don't we

167
00:07:24,669 --> 00:07:30,068
don't have an FTC security law instead

168
00:07:27,249 --> 00:07:33,339
we have this general body of consumer

169
00:07:30,069 --> 00:07:35,860
protection law and so when the FTC takes

170
00:07:33,339 --> 00:07:38,709
admit takes action let's say against

171
00:07:35,860 --> 00:07:41,019
Facebook most recently or against a

172
00:07:38,709 --> 00:07:44,799
company for having inadequate security

173
00:07:41,019 --> 00:07:47,879
it does so under the rationale that has

174
00:07:44,799 --> 00:07:51,479
the power to prevent unfair or deceptive

175
00:07:47,879 --> 00:07:53,649
trade practices and you know guess what

176
00:07:51,479 --> 00:07:56,229
there's no real definition of what these

177
00:07:53,649 --> 00:07:59,409
things are it's kind of a slippery

178
00:07:56,229 --> 00:08:01,389
definition so they're separate theories

179
00:07:59,409 --> 00:08:02,019
that's one important thing to think

180
00:08:01,389 --> 00:08:04,209
about

181
00:08:02,019 --> 00:08:07,539
there's unfairness and there's deception

182
00:08:04,209 --> 00:08:10,659
two separate theories but unfairness is

183
00:08:07,539 --> 00:08:14,469
any practice or act that creates

184
00:08:10,659 --> 00:08:15,969
substantial consumer injury right so

185
00:08:14,469 --> 00:08:18,519
that that doesn't even really hang much

186
00:08:15,969 --> 00:08:21,519
meat on the law because we could

187
00:08:18,519 --> 00:08:23,379
disagree about what injury is but what

188
00:08:21,519 --> 00:08:26,649
the Federal Trade Commission is looking

189
00:08:23,379 --> 00:08:29,829
for is insecurity that causes

190
00:08:26,649 --> 00:08:33,250
substantial consumer injury and some

191
00:08:29,829 --> 00:08:35,318
other elements here you know there are

192
00:08:33,250 --> 00:08:37,779
situations where insecurity is

193
00:08:35,318 --> 00:08:40,360
unavoidable by the consumer so that's a

194
00:08:37,779 --> 00:08:43,838
plus if you want to bring a bring a case

195
00:08:40,360 --> 00:08:47,910
and there's instances where insecurity

196
00:08:43,839 --> 00:08:50,410
actually contributes to efficiency or

197
00:08:47,910 --> 00:08:51,910
makes a product possible that otherwise

198
00:08:50,410 --> 00:08:54,639
would not be possible so there's a kind

199
00:08:51,910 --> 00:08:56,439
of cost-benefit analysis in this theory

200
00:08:54,639 --> 00:08:58,689
of action but the main thing to remember

201
00:08:56,439 --> 00:08:59,699
is if you want the Federal Trade

202
00:08:58,689 --> 00:09:01,618
Commission to

203
00:08:59,699 --> 00:09:03,569
intervene about some security practice

204
00:09:01,619 --> 00:09:06,509
you have to convince a Federal Trade

205
00:09:03,569 --> 00:09:10,279
Commission attorney that the act the the

206
00:09:06,509 --> 00:09:13,499
the practice it causes substantial

207
00:09:10,279 --> 00:09:17,129
consumer injury the other cause of

208
00:09:13,499 --> 00:09:21,949
action is is deception and this is an

209
00:09:17,129 --> 00:09:26,249
easier theory to use it simply means a

210
00:09:21,949 --> 00:09:28,738
representation or omission that misleads

211
00:09:26,249 --> 00:09:31,619
an ordinary consumer and causes them

212
00:09:28,739 --> 00:09:34,350
detriment so the lot of things out there

213
00:09:31,619 --> 00:09:38,399
cause deception in the world and what

214
00:09:34,350 --> 00:09:41,069
the Federal Trade Commission has has

215
00:09:38,399 --> 00:09:44,519
argued is that if you're a company and

216
00:09:41,069 --> 00:09:47,639
you collect you collect information from

217
00:09:44,519 --> 00:09:49,470
consumers reasonable consumers assume

218
00:09:47,639 --> 00:09:52,049
that you have some baseline of

219
00:09:49,470 --> 00:09:53,399
reasonable security so a lot of them

220
00:09:52,049 --> 00:09:55,889
want to talk about is what what that

221
00:09:53,399 --> 00:09:57,389
might be so some other kind of dynamics

222
00:09:55,889 --> 00:09:58,859
here the federal trade you read about

223
00:09:57,389 --> 00:10:01,049
the Federal Trade Commission a lot right

224
00:09:58,859 --> 00:10:05,249
and there's this recent case against the

225
00:10:01,049 --> 00:10:07,039
against Facebook they only do they only

226
00:10:05,249 --> 00:10:10,529
do about fifteen or twenty cases a year

227
00:10:07,039 --> 00:10:12,989
right so that is not a lot of

228
00:10:10,529 --> 00:10:17,609
enforcement when you think about all the

229
00:10:12,989 --> 00:10:21,209
companies out there we have the GD GD P

230
00:10:17,609 --> 00:10:22,980
R approach and my colleague is gonna

231
00:10:21,209 --> 00:10:24,839
talk about GD P R and more detail so I'm

232
00:10:22,980 --> 00:10:28,169
not going to say much more than to say

233
00:10:24,839 --> 00:10:30,539
that it's similar to the FTC Authority

234
00:10:28,169 --> 00:10:34,079
in that it operates at a pretty high

235
00:10:30,539 --> 00:10:35,749
level of abstraction the GD P R is what

236
00:10:34,079 --> 00:10:38,248
I would call a principles-based

237
00:10:35,749 --> 00:10:40,350
regulation it doesn't tell you

238
00:10:38,249 --> 00:10:43,769
specifically what to do but it asks you

239
00:10:40,350 --> 00:10:46,709
to jump over hurdles that are pretty

240
00:10:43,769 --> 00:10:49,230
high so they want you to use your brain

241
00:10:46,709 --> 00:10:51,388
and decide you know to make an active

242
00:10:49,230 --> 00:10:53,220
decision about what type of technical

243
00:10:51,389 --> 00:10:55,829
safeguards are needed for your system

244
00:10:53,220 --> 00:10:57,869
and they should be tailored to the type

245
00:10:55,829 --> 00:11:01,799
of data you have the purposes it's used

246
00:10:57,869 --> 00:11:05,459
for and so on there is a very

247
00:11:01,799 --> 00:11:07,139
interesting part of the DDP R that the

248
00:11:05,459 --> 00:11:09,299
security part of the GD P R that talks

249
00:11:07,139 --> 00:11:12,329
about state of the art that I want you

250
00:11:09,299 --> 00:11:13,640
to keep in mind and of course there's

251
00:11:12,329 --> 00:11:16,410
privacy by design into fall

252
00:11:13,640 --> 00:11:19,380
enforcement is one of the interesting

253
00:11:16,410 --> 00:11:21,810
issues in the GDP our it's it's hard to

254
00:11:19,380 --> 00:11:23,930
track this down they actually have been

255
00:11:21,810 --> 00:11:27,089
some pretty significant enforcement

256
00:11:23,930 --> 00:11:30,359
actions a lot of people pay attention to

257
00:11:27,090 --> 00:11:32,370
the 50 million euro fine against Google

258
00:11:30,360 --> 00:11:34,230
but in addition to that there was a

259
00:11:32,370 --> 00:11:37,620
hundred million dollar a hundred million

260
00:11:34,230 --> 00:11:41,670
euro fine against Marriott and British

261
00:11:37,620 --> 00:11:43,740
Airways spectacular fine I think was a

262
00:11:41,670 --> 00:11:47,610
hundred and eighty million euros so the

263
00:11:43,740 --> 00:11:49,260
the the fines are ramping up and that's

264
00:11:47,610 --> 00:11:52,410
going to be a key part of whether the

265
00:11:49,260 --> 00:11:57,360
GDP are is effective um it's important

266
00:11:52,410 --> 00:11:58,980
oops I think I think I've I might I

267
00:11:57,360 --> 00:12:02,070
might have I have my slides out order

268
00:11:58,980 --> 00:12:04,140
but so let me just keep going so on one

269
00:12:02,070 --> 00:12:06,390
hand you have the FTC law you have the

270
00:12:04,140 --> 00:12:11,430
GDP are that speaks at the principles

271
00:12:06,390 --> 00:12:12,930
level on the other hand another kind of

272
00:12:11,430 --> 00:12:16,489
theme of what's happening in

273
00:12:12,930 --> 00:12:19,349
cybersecurity regulation are highly

274
00:12:16,490 --> 00:12:21,540
prescriptive rules that we see emerging

275
00:12:19,350 --> 00:12:24,180
from some sectors I think the most

276
00:12:21,540 --> 00:12:25,319
consequential of them is that is the New

277
00:12:24,180 --> 00:12:28,739
York Department of Financial Services

278
00:12:25,320 --> 00:12:33,150
cyber rules you can if you google these

279
00:12:28,740 --> 00:12:36,000
you can find them there at 23 NY Cir 500

280
00:12:33,150 --> 00:12:37,890
and this is the model where the

281
00:12:36,000 --> 00:12:40,500
regulator tells you very specifically

282
00:12:37,890 --> 00:12:44,100
what they want you to do they want you

283
00:12:40,500 --> 00:12:46,680
to have a custom security policy they

284
00:12:44,100 --> 00:12:48,270
want you to be doing pen testing and so

285
00:12:46,680 --> 00:12:50,969
on that covers this that and the other

286
00:12:48,270 --> 00:12:54,449
thing and they want a pretty broad array

287
00:12:50,970 --> 00:12:57,570
of security incidents to be reported to

288
00:12:54,450 --> 00:12:59,040
the regulator so we have cyber security

289
00:12:57,570 --> 00:13:00,200
rules are moving in these two different

290
00:12:59,040 --> 00:13:04,110
directions

291
00:13:00,200 --> 00:13:08,640
one of high principle and then one of

292
00:13:04,110 --> 00:13:10,890
this high prescription so those are the

293
00:13:08,640 --> 00:13:13,199
types of tools those are some of the

294
00:13:10,890 --> 00:13:16,350
tools that regulators have to police

295
00:13:13,200 --> 00:13:18,360
cyber security but when they police them

296
00:13:16,350 --> 00:13:25,170
they police them in a political

297
00:13:18,360 --> 00:13:27,360
environment so you leave the text of the

298
00:13:25,170 --> 00:13:30,380
law what you think the law is and you

299
00:13:27,360 --> 00:13:34,649
leave you you you come to an environment

300
00:13:30,380 --> 00:13:36,450
where the regulator's have to work

301
00:13:34,649 --> 00:13:38,490
within their institutions to bring

302
00:13:36,450 --> 00:13:40,260
enforcement actions and there's a lot of

303
00:13:38,490 --> 00:13:42,630
really interesting psychology here I

304
00:13:40,260 --> 00:13:44,399
think a lot of the regulators and I'm

305
00:13:42,630 --> 00:13:48,839
gonna be a little bit hard on them today

306
00:13:44,399 --> 00:13:51,329
I think generally speaking many of them

307
00:13:48,839 --> 00:13:55,769
don't understand information as a as a

308
00:13:51,329 --> 00:13:56,939
thing I see them as in my experience

309
00:13:55,769 --> 00:13:58,709
from working with the Federal Trade

310
00:13:56,940 --> 00:14:01,680
Commission for a long time is that most

311
00:13:58,709 --> 00:14:06,180
regulators essentially are solipsistic

312
00:14:01,680 --> 00:14:08,550
they they use facebook right and they

313
00:14:06,180 --> 00:14:10,439
love it they're part of the demographic

314
00:14:08,550 --> 00:14:15,779
that actually uses facebook middle-aged

315
00:14:10,440 --> 00:14:18,240
men and so their experience of Facebook

316
00:14:15,779 --> 00:14:21,959
is what drives their kind of conception

317
00:14:18,240 --> 00:14:24,810
of what these services do and if they

318
00:14:21,959 --> 00:14:27,060
see ads that are misleading and so on

319
00:14:24,810 --> 00:14:31,859
that's their evidence

320
00:14:27,060 --> 00:14:34,560
there isn't a there there isn't a real

321
00:14:31,860 --> 00:14:40,019
demand to think objectively about how

322
00:14:34,560 --> 00:14:42,359
other people sir experience services so

323
00:14:40,019 --> 00:14:44,940
you know one of the one of the lessons

324
00:14:42,360 --> 00:14:47,579
here is that in engaging with whether

325
00:14:44,940 --> 00:14:50,000
it's Federal Trade Commission or state

326
00:14:47,579 --> 00:14:52,859
attorneys general who are very active in

327
00:14:50,000 --> 00:14:56,060
security and privacy is that you have to

328
00:14:52,860 --> 00:15:00,720
think about their technology worldview

329
00:14:56,060 --> 00:15:03,000
and how they might be using they might

330
00:15:00,720 --> 00:15:06,899
categorically not be using the services

331
00:15:03,000 --> 00:15:09,300
that you use so they have no experience

332
00:15:06,899 --> 00:15:11,579
of them they have no idea of how people

333
00:15:09,300 --> 00:15:14,609
could be harmed by them or manipulated

334
00:15:11,579 --> 00:15:16,709
by them another important point is that

335
00:15:14,610 --> 00:15:21,420
annek data is just more powerful and

336
00:15:16,709 --> 00:15:24,089
regulators eyes than data ultimately you

337
00:15:21,420 --> 00:15:26,670
know like it or not you have to conceive

338
00:15:24,089 --> 00:15:29,190
of an enforcement action before a judge

339
00:15:26,670 --> 00:15:33,420
or a jury and judges and juries are

340
00:15:29,190 --> 00:15:36,750
moved not by data by stories so having a

341
00:15:33,420 --> 00:15:39,209
good story is powerful and and here

342
00:15:36,750 --> 00:15:40,080
because I am a lawyer I can I can I can

343
00:15:39,209 --> 00:15:44,069
pick on

344
00:15:40,080 --> 00:15:46,890
a bit a lot of federal regulators fight

345
00:15:44,070 --> 00:15:50,280
with a glass jaw they are really worried

346
00:15:46,890 --> 00:15:53,910
about losing cases because if they lose

347
00:15:50,280 --> 00:15:55,620
any case their entire agency is burdened

348
00:15:53,910 --> 00:15:57,000
by that loss it's not like a plaintiff's

349
00:15:55,620 --> 00:15:58,590
lawyer where you know you losing your

350
00:15:57,000 --> 00:16:00,360
plaintiff's lawyer you lose a case who

351
00:15:58,590 --> 00:16:01,530
cares you bring another but if you're

352
00:16:00,360 --> 00:16:04,830
the Federal Trade Commission you lose a

353
00:16:01,530 --> 00:16:07,020
case it affects every single enforcement

354
00:16:04,830 --> 00:16:10,230
action that you engage in so as a result

355
00:16:07,020 --> 00:16:13,620
there is a defensive posture it's not as

356
00:16:10,230 --> 00:16:17,250
aggressive as let's say Department of

357
00:16:13,620 --> 00:16:19,950
Justice when it charges criminals it's a

358
00:16:17,250 --> 00:16:21,120
it's a different different posture and

359
00:16:19,950 --> 00:16:22,280
then the other thing is that lawyers

360
00:16:21,120 --> 00:16:27,060
fake it

361
00:16:22,280 --> 00:16:29,189
Wow they fake it what are the powers of

362
00:16:27,060 --> 00:16:31,469
being a lawyer is showing up in a room

363
00:16:29,190 --> 00:16:33,570
and wearing a suit and scaring everyone

364
00:16:31,470 --> 00:16:36,090
by your mere presence you don't have to

365
00:16:33,570 --> 00:16:38,460
do anything to get this power you just

366
00:16:36,090 --> 00:16:41,340
have to show up and not say anything and

367
00:16:38,460 --> 00:16:43,200
people get scared if you ask lawyers

368
00:16:41,340 --> 00:16:45,060
just a few a few questions you'll see

369
00:16:43,200 --> 00:16:47,790
that they're faking it they really don't

370
00:16:45,060 --> 00:16:51,560
have a good conception of the technology

371
00:16:47,790 --> 00:16:54,030
and so on and I am one of the more

372
00:16:51,560 --> 00:16:57,989
technically trained lawyers but I tell

373
00:16:54,030 --> 00:17:00,660
you I get fooled all the time this is a

374
00:16:57,990 --> 00:17:02,550
really embarrassing one but you know

375
00:17:00,660 --> 00:17:05,040
there's this idea companies say well we

376
00:17:02,550 --> 00:17:07,919
we encrypt data in transit and we

377
00:17:05,040 --> 00:17:09,780
encrypted at rest and so finally I was

378
00:17:07,920 --> 00:17:11,970
always fooled by this I always thought

379
00:17:09,780 --> 00:17:13,500
that sounds great wonderful until one of

380
00:17:11,970 --> 00:17:15,480
my defense contractor friends said

381
00:17:13,500 --> 00:17:18,930
listen you idiot our data are never at

382
00:17:15,480 --> 00:17:21,870
rest I had never even conceived at that

383
00:17:18,930 --> 00:17:23,550
idea and and I think regulators are

384
00:17:21,869 --> 00:17:25,948
labor laboring under a lot of

385
00:17:23,550 --> 00:17:28,470
misconceptions about what security

386
00:17:25,949 --> 00:17:30,270
analysis does so there's a lot of

387
00:17:28,470 --> 00:17:33,900
specious representations that if you

388
00:17:30,270 --> 00:17:35,420
don't walk through the the consequences

389
00:17:33,900 --> 00:17:38,250
of them they're not likely to understand

390
00:17:35,420 --> 00:17:40,170
a great example you could tell a

391
00:17:38,250 --> 00:17:43,500
regulator that we do is a full source

392
00:17:40,170 --> 00:17:45,960
code review of our software to make sure

393
00:17:43,500 --> 00:17:47,610
that it has no vulnerabilities in it but

394
00:17:45,960 --> 00:17:50,640
of course that says nothing about apple

395
00:17:47,610 --> 00:17:52,439
of implementations of that software and

396
00:17:50,640 --> 00:17:53,520
how it could be implemented in ways

397
00:17:52,440 --> 00:17:55,800
where it become

398
00:17:53,520 --> 00:17:58,620
insecure despite the underlying software

399
00:17:55,800 --> 00:18:01,409
being secured in the abstract so with

400
00:17:58,620 --> 00:18:03,540
all that in mind I look at you know what

401
00:18:01,410 --> 00:18:05,130
security researchers are doing and I

402
00:18:03,540 --> 00:18:07,200
want to give some examples without

403
00:18:05,130 --> 00:18:09,990
picking on anyone too much because I

404
00:18:07,200 --> 00:18:15,150
admire what they're doing now this is um

405
00:18:09,990 --> 00:18:19,110
this is Mudge's work at the cyber ITL

406
00:18:15,150 --> 00:18:22,500
this is a great fantastic effort they

407
00:18:19,110 --> 00:18:25,649
are testing a huge number of Internet of

408
00:18:22,500 --> 00:18:28,830
Things devices and Wow are they finding

409
00:18:25,650 --> 00:18:30,660
they are insecure so in one of their

410
00:18:28,830 --> 00:18:33,360
reports they do this study where they

411
00:18:30,660 --> 00:18:35,610
analyze LG televisions Vizio ones and

412
00:18:33,360 --> 00:18:38,790
Hart and Linux and they show that when

413
00:18:35,610 --> 00:18:41,550
the software is finally implemented in

414
00:18:38,790 --> 00:18:44,040
these in these devices that many of them

415
00:18:41,550 --> 00:18:46,350
are missing basic security measures

416
00:18:44,040 --> 00:18:48,420
there's a report basically says you know

417
00:18:46,350 --> 00:18:52,050
if you look at LG televisions they're

418
00:18:48,420 --> 00:18:56,190
missing these basic protections against

419
00:18:52,050 --> 00:18:57,810
exploitation rate and I can kind of get

420
00:18:56,190 --> 00:19:01,500
why that's wrong but I don't think

421
00:18:57,810 --> 00:19:06,800
regulators would kind of get what the

422
00:19:01,500 --> 00:19:13,050
problem is there so what

423
00:19:06,800 --> 00:19:14,700
so finding vulnerabilities is great and

424
00:19:13,050 --> 00:19:17,850
the people in this room understand what

425
00:19:14,700 --> 00:19:19,800
those mean but for the regulator I think

426
00:19:17,850 --> 00:19:21,419
there's some other questions that you

427
00:19:19,800 --> 00:19:23,129
could put in your papers there's some

428
00:19:21,420 --> 00:19:25,790
other discussion that you can put in

429
00:19:23,130 --> 00:19:28,800
your paper that could be really useful

430
00:19:25,790 --> 00:19:33,240
one can you link the vulnerability to

431
00:19:28,800 --> 00:19:34,950
some demonstrably bad outcome as in this

432
00:19:33,240 --> 00:19:38,580
vulnerability so you know like you might

433
00:19:34,950 --> 00:19:42,840
ask like who cares that LG TVs don't

434
00:19:38,580 --> 00:19:44,370
have a SLR well you might care a lot or

435
00:19:42,840 --> 00:19:48,449
a regulator would care a lot if the

436
00:19:44,370 --> 00:19:51,959
caption of that chart said the absence

437
00:19:48,450 --> 00:19:54,180
of a SLR led to X number of infections

438
00:19:51,960 --> 00:19:54,540
in the Mirai botnet or something like

439
00:19:54,180 --> 00:19:57,470
that

440
00:19:54,540 --> 00:20:00,300
that's the type of resolution they need

441
00:19:57,470 --> 00:20:04,860
to to link to link this together so

442
00:20:00,300 --> 00:20:07,110
other other critical issues recall that

443
00:20:04,860 --> 00:20:09,659
when you argue that a practices

444
00:20:07,110 --> 00:20:12,330
fare the Federal Trade Commission will

445
00:20:09,660 --> 00:20:14,070
do a cost-benefit analysis so inherently

446
00:20:12,330 --> 00:20:15,990
they're gonna in their head is gonna be

447
00:20:14,070 --> 00:20:18,120
the question oh well you know you're

448
00:20:15,990 --> 00:20:20,400
picking on LG because they made these

449
00:20:18,120 --> 00:20:23,309
televisions but what were the

450
00:20:20,400 --> 00:20:26,880
alternatives how much it would have had

451
00:20:23,309 --> 00:20:31,230
cost how much would it cost to put to

452
00:20:26,880 --> 00:20:35,130
properly design the software and what

453
00:20:31,230 --> 00:20:38,970
were the trade-offs so you could talk

454
00:20:35,130 --> 00:20:40,200
about that and then finally and and I

455
00:20:38,970 --> 00:20:42,710
think this is pretty critical

456
00:20:40,200 --> 00:20:46,440
is there any way for a consumer to know

457
00:20:42,710 --> 00:20:48,630
that the LG television is not as secure

458
00:20:46,440 --> 00:20:50,340
as the Vizio one is there any way there

459
00:20:48,630 --> 00:20:54,000
are any signals out there I think the

460
00:20:50,340 --> 00:20:56,399
answer to that is no but you could talk

461
00:20:54,000 --> 00:20:58,980
about what would the consumer what what

462
00:20:56,400 --> 00:21:01,350
is the logical chain of facts would that

463
00:20:58,980 --> 00:21:05,280
the consumer would have to know to be

464
00:21:01,350 --> 00:21:08,070
able to make a decision based on this

465
00:21:05,280 --> 00:21:09,480
graph is quite complex and you know the

466
00:21:08,070 --> 00:21:11,790
federal trick you know the you could

467
00:21:09,480 --> 00:21:13,470
convince the regulator that no consumer

468
00:21:11,790 --> 00:21:15,629
would figure this out on their app on

469
00:21:13,470 --> 00:21:18,799
their own and as a result the market

470
00:21:15,630 --> 00:21:24,299
won't provide the signals needed

471
00:21:18,799 --> 00:21:27,840
therefore they shouldn't intervene so I

472
00:21:24,299 --> 00:21:29,580
I love seeing images like this so these

473
00:21:27,840 --> 00:21:33,840
kind of dns outages but I'm not sure

474
00:21:29,580 --> 00:21:36,449
what they mean and I was thinking you

475
00:21:33,840 --> 00:21:38,668
know if you had if you were talking

476
00:21:36,450 --> 00:21:42,150
let's say about Mirai or another one of

477
00:21:38,669 --> 00:21:44,400
the big botnets out there and we'd be

478
00:21:42,150 --> 00:21:46,200
really interesting to talk about it not

479
00:21:44,400 --> 00:21:51,000
in the sense of the servers that were

480
00:21:46,200 --> 00:21:54,620
affected but rather how many users were

481
00:21:51,000 --> 00:21:57,120
adversely impacted and for how long and

482
00:21:54,620 --> 00:21:59,370
you know I'm sure there are numbers out

483
00:21:57,120 --> 00:22:01,260
there about the amount of Commerce that

484
00:21:59,370 --> 00:22:03,899
it happens on the Internet at any given

485
00:22:01,260 --> 00:22:05,790
second so you know what does it mean if

486
00:22:03,900 --> 00:22:08,280
no one can make a purchase for 30

487
00:22:05,790 --> 00:22:10,710
seconds I think the number is probably

488
00:22:08,280 --> 00:22:13,740
really big I think that type of

489
00:22:10,710 --> 00:22:15,330
information could be very powerful for

490
00:22:13,740 --> 00:22:18,179
regulators and the type of thing that

491
00:22:15,330 --> 00:22:20,418
could change their mind about bringing a

492
00:22:18,179 --> 00:22:20,419
case

493
00:22:20,460 --> 00:22:25,019
um oh now I remember what I have

494
00:22:23,490 --> 00:22:26,460
happened with my slides here okay so I

495
00:22:25,019 --> 00:22:30,389
wanted to talk a little bit about state

496
00:22:26,460 --> 00:22:33,360
of the art um and maybe you'll have

497
00:22:30,389 --> 00:22:34,889
people have comment on this to the GDP

498
00:22:33,360 --> 00:22:37,529
are says that your security has has to

499
00:22:34,889 --> 00:22:39,928
be state of the art but of course state

500
00:22:37,529 --> 00:22:42,840
of the art has at least two different

501
00:22:39,929 --> 00:22:46,980
meanings and American law I don't know

502
00:22:42,840 --> 00:22:48,539
what its meaning is in Europe oftentimes

503
00:22:46,980 --> 00:22:50,220
when you hear state of the art it is

504
00:22:48,539 --> 00:22:53,879
said from the perspective of an

505
00:22:50,220 --> 00:22:56,669
advertiser and it's meant to mean the

506
00:22:53,879 --> 00:23:01,799
best possible or the cutting edge of

507
00:22:56,669 --> 00:23:03,860
scientific advance but more conservative

508
00:23:01,799 --> 00:23:08,039
and when I say that I mean a small C or

509
00:23:03,860 --> 00:23:09,209
careful Juris look at the same term and

510
00:23:08,039 --> 00:23:12,119
they say that's not what that means at

511
00:23:09,210 --> 00:23:15,690
all what state of the art means is state

512
00:23:12,119 --> 00:23:21,330
of the practice this is what people do

513
00:23:15,690 --> 00:23:24,169
commonly day to day having a handle on

514
00:23:21,330 --> 00:23:27,899
that type of nuances and is important

515
00:23:24,169 --> 00:23:30,720
and so the question I would ask and I

516
00:23:27,899 --> 00:23:33,418
have some I have some examples of this

517
00:23:30,720 --> 00:23:36,450
is how might the security community

518
00:23:33,419 --> 00:23:38,850
articulate a start a state of the art

519
00:23:36,450 --> 00:23:43,740
and in some ways in some ways it has

520
00:23:38,850 --> 00:23:46,259
done this but you could also imagine how

521
00:23:43,740 --> 00:23:48,299
you could contribute to public policy by

522
00:23:46,259 --> 00:23:50,549
merely surveying companies about their

523
00:23:48,299 --> 00:23:53,158
practices and documenting what they're

524
00:23:50,549 --> 00:23:55,559
doing on what they're not doing to give

525
00:23:53,159 --> 00:23:58,529
regulators an idea of what is common

526
00:23:55,559 --> 00:24:00,059
business practice out there I think this

527
00:23:58,529 --> 00:24:01,730
is true with privacy by default in

528
00:24:00,059 --> 00:24:04,830
design I'm going to give an example of

529
00:24:01,730 --> 00:24:06,869
give an example of something I did in

530
00:24:04,830 --> 00:24:12,240
the privacy realm so this isn't security

531
00:24:06,869 --> 00:24:14,189
this is privacy the rules governing spam

532
00:24:12,240 --> 00:24:15,990
were recently reviewed by the Federal

533
00:24:14,190 --> 00:24:17,999
Trade Commission so yeah we have a

534
00:24:15,990 --> 00:24:22,200
anti-spam law in the United States it's

535
00:24:17,999 --> 00:24:24,299
wonderfully effective but I I have you

536
00:24:22,200 --> 00:24:27,570
know I have ideas about how we could

537
00:24:24,299 --> 00:24:30,929
make the law more effective what would I

538
00:24:27,570 --> 00:24:33,470
comment syn the proceedings that is try

539
00:24:30,929 --> 00:24:35,840
I'm trying to drive the regulation

540
00:24:33,470 --> 00:24:37,850
toward a place where people who send

541
00:24:35,840 --> 00:24:41,330
commercial email have to use a standard

542
00:24:37,850 --> 00:24:42,889
disclosure in text because I want

543
00:24:41,330 --> 00:24:44,120
filters to be able to look for that

544
00:24:42,890 --> 00:24:47,900
standard disclosure so it can be

545
00:24:44,120 --> 00:24:51,709
filtered okay so among the things I

546
00:24:47,900 --> 00:24:53,210
looked at was readability of commercial

547
00:24:51,710 --> 00:24:55,910
email and one of the things you'll see

548
00:24:53,210 --> 00:24:57,800
is that you know one of the deals one of

549
00:24:55,910 --> 00:24:59,780
the bargains of commercial email is that

550
00:24:57,800 --> 00:25:02,810
spammers are allowed to spam you it's an

551
00:24:59,780 --> 00:25:05,290
opt-out system so every business in the

552
00:25:02,810 --> 00:25:08,179
world is allowed to send you email and

553
00:25:05,290 --> 00:25:11,560
the the bargain is is that you have the

554
00:25:08,180 --> 00:25:13,880
right to opt out well okay

555
00:25:11,560 --> 00:25:16,220
to have a right to opt-out you need to

556
00:25:13,880 --> 00:25:18,140
know how to do it and so I did a survey

557
00:25:16,220 --> 00:25:20,690
of looking at different spams and what I

558
00:25:18,140 --> 00:25:22,700
found was is that a lot of those a lot

559
00:25:20,690 --> 00:25:25,460
of that commercial email is unreadable

560
00:25:22,700 --> 00:25:27,440
in a technical sense so here's an

561
00:25:25,460 --> 00:25:30,190
example from endo Chino this is a

562
00:25:27,440 --> 00:25:32,360
company I love like mainstream company

563
00:25:30,190 --> 00:25:34,060
but you know when you get the

564
00:25:32,360 --> 00:25:37,429
unsubscribe this is the unsubscribe

565
00:25:34,060 --> 00:25:40,909
right here it's kind of like grey on

566
00:25:37,430 --> 00:25:42,590
grey and so what I wrote to the Federal

567
00:25:40,910 --> 00:25:45,380
Trade Commission is this email has a

568
00:25:42,590 --> 00:25:49,699
background color in a text color that is

569
00:25:45,380 --> 00:25:53,300
so similar in hue that the the ratio the

570
00:25:49,700 --> 00:25:54,740
contrast ratio is only 1.6 and so the

571
00:25:53,300 --> 00:25:56,360
standard is supposed to be 7 for

572
00:25:54,740 --> 00:25:58,070
something to be readable they give you

573
00:25:56,360 --> 00:26:01,459
an idea this is basically unreadable and

574
00:25:58,070 --> 00:26:04,960
if you have any type of vision visual

575
00:26:01,460 --> 00:26:08,030
impairment this is you can't be read so

576
00:26:04,960 --> 00:26:10,310
so I wrote it fails all standards for

577
00:26:08,030 --> 00:26:12,230
adequate reliability and then I put in

578
00:26:10,310 --> 00:26:15,139
this last sentence for reference white

579
00:26:12,230 --> 00:26:17,990
on white would have a contrast of 1 so

580
00:26:15,140 --> 00:26:23,000
that's how close it is to just being

581
00:26:17,990 --> 00:26:25,250
white on white so I thought this was an

582
00:26:23,000 --> 00:26:30,260
example of what we might be able to do

583
00:26:25,250 --> 00:26:32,720
in security and that is to show show

584
00:26:30,260 --> 00:26:35,150
examples from mainstream companies not

585
00:26:32,720 --> 00:26:36,470
by fly fly by night companies who cares

586
00:26:35,150 --> 00:26:40,580
like mainstream companies what are they

587
00:26:36,470 --> 00:26:44,330
what's going wrong compare those compare

588
00:26:40,580 --> 00:26:46,790
those those practices with a commonly

589
00:26:44,330 --> 00:26:47,270
recognized standard so disability groups

590
00:26:46,790 --> 00:26:49,250
you

591
00:26:47,270 --> 00:26:51,530
the standard to argue whether something

592
00:26:49,250 --> 00:26:53,810
is readable or not no one really argues

593
00:26:51,530 --> 00:26:56,629
oh no one no one argues much about it I

594
00:26:53,810 --> 00:26:58,070
put in a conclusion right you can't

595
00:26:56,630 --> 00:26:59,210
this isn't readable no matter what

596
00:26:58,070 --> 00:27:01,520
standard do you use it's not readable

597
00:26:59,210 --> 00:27:03,350
and I put in this like reference to give

598
00:27:01,520 --> 00:27:05,480
you an idea how bad it is it's almost

599
00:27:03,350 --> 00:27:06,800
white on white okay I thought this is a

600
00:27:05,480 --> 00:27:10,790
pretty compelling argument right

601
00:27:06,800 --> 00:27:12,710
the FTC should go with me and pass a

602
00:27:10,790 --> 00:27:15,340
rule saying that when you do an opt-out

603
00:27:12,710 --> 00:27:22,360
it has to at least be readable

604
00:27:15,340 --> 00:27:24,770
well they didn't and what they said was

605
00:27:22,360 --> 00:27:26,990
none of the comments and they're

606
00:27:24,770 --> 00:27:28,400
referring to me here provide the

607
00:27:26,990 --> 00:27:30,200
Commission with information about the

608
00:27:28,400 --> 00:27:32,060
cost and benefits of these rule changes

609
00:27:30,200 --> 00:27:34,580
so I thought this was a little

610
00:27:32,060 --> 00:27:37,629
ridiculous I didn't think I had to say

611
00:27:34,580 --> 00:27:43,250
that it doesn't cost any money to change

612
00:27:37,630 --> 00:27:46,600
f5f5f5 to ffffff right but apparently I

613
00:27:43,250 --> 00:27:49,820
did so I didn't follow my own advice

614
00:27:46,600 --> 00:27:50,810
so I especially I mean the lesson here

615
00:27:49,820 --> 00:27:54,639
is especially in the Trump

616
00:27:50,810 --> 00:27:58,340
administration one has to talk

617
00:27:54,640 --> 00:28:00,320
cost-benefit even when even when you

618
00:27:58,340 --> 00:28:03,350
think it's ridiculous so when when a

619
00:28:00,320 --> 00:28:05,240
vulnerability is introduced into us into

620
00:28:03,350 --> 00:28:07,790
software based on let's say a lack of a

621
00:28:05,240 --> 00:28:09,950
flag let's say when they compiled the

622
00:28:07,790 --> 00:28:13,010
software they didn't put in a single

623
00:28:09,950 --> 00:28:16,970
flag and typing that flag in would have

624
00:28:13,010 --> 00:28:18,530
taken 10 seconds you should say that it

625
00:28:16,970 --> 00:28:21,830
would have taken an engineer a competent

626
00:28:18,530 --> 00:28:26,110
engineer 10 seconds to to change this

627
00:28:21,830 --> 00:28:29,689
setting and make this software more more

628
00:28:26,110 --> 00:28:32,439
safe they want to hear that I can't

629
00:28:29,690 --> 00:28:35,300
believe that this was their response

630
00:28:32,440 --> 00:28:39,380
another question that I want to

631
00:28:35,300 --> 00:28:42,110
challenge you on is the the the problem

632
00:28:39,380 --> 00:28:44,600
of expressing norms so for my

633
00:28:42,110 --> 00:28:47,479
cybersecurity course I interviewed a

634
00:28:44,600 --> 00:28:49,370
whole whole bunch of different experts

635
00:28:47,480 --> 00:28:51,440
who who talked to my students and I

636
00:28:49,370 --> 00:28:54,409
interviewed one of the Greybeards one of

637
00:28:51,440 --> 00:28:56,660
the wonderful people in CS and I asked

638
00:28:54,410 --> 00:28:57,590
them you know I asked him here series of

639
00:28:56,660 --> 00:29:00,260
questions and one of the things he

640
00:28:57,590 --> 00:29:03,260
responded was with was we

641
00:29:00,260 --> 00:29:06,169
computer security we know what we need

642
00:29:03,260 --> 00:29:08,690
to do and I listened to that it was

643
00:29:06,169 --> 00:29:10,429
great I believe you but that will not

644
00:29:08,690 --> 00:29:14,090
that type of argument will not convince

645
00:29:10,429 --> 00:29:17,240
any regulator so I don't know if I died

646
00:29:14,090 --> 00:29:22,809
trip to my slide here so the types of

647
00:29:17,240 --> 00:29:27,350
things this kind of appeal to Authority

648
00:29:22,809 --> 00:29:29,178
we know what to do is too vague I think

649
00:29:27,350 --> 00:29:32,030
there's other things that you can do as

650
00:29:29,179 --> 00:29:35,360
security researchers one is to talk

651
00:29:32,030 --> 00:29:37,370
about fixes in engineering time so we

652
00:29:35,360 --> 00:29:41,870
think it would take this many minutes to

653
00:29:37,370 --> 00:29:46,969
fix this problem to talk about things

654
00:29:41,870 --> 00:29:47,918
like if the problem isn't fixed at

655
00:29:46,970 --> 00:29:50,240
design

656
00:29:47,919 --> 00:29:53,150
how many transaction costs and other

657
00:29:50,240 --> 00:29:55,460
other costs are imposed if it's fixed

658
00:29:53,150 --> 00:29:58,610
after the product or services in the

659
00:29:55,460 --> 00:30:04,270
consumers hands so this is an argument

660
00:29:58,610 --> 00:30:07,340
about X posts or X anti interventions

661
00:30:04,270 --> 00:30:11,000
it's almost always a better deal right

662
00:30:07,340 --> 00:30:13,070
if that if that masseur vez is fixed

663
00:30:11,000 --> 00:30:16,280
before the product goes into the

664
00:30:13,070 --> 00:30:20,168
marketplace are there tools to detect or

665
00:30:16,280 --> 00:30:22,940
fix the flaw you might even show them

666
00:30:20,169 --> 00:30:26,900
the specific way the flaw could have

667
00:30:22,940 --> 00:30:30,410
been fixed I so for instance in my spam

668
00:30:26,900 --> 00:30:33,530
conte my spam comment I really wish I

669
00:30:30,410 --> 00:30:37,429
had paste it in the HTML and written the

670
00:30:33,530 --> 00:30:39,530
fix as banal as that would have been I

671
00:30:37,429 --> 00:30:42,559
think it would have been a better way to

672
00:30:39,530 --> 00:30:44,570
express that that change and then maybe

673
00:30:42,559 --> 00:30:47,178
you could talk about trade-offs you know

674
00:30:44,570 --> 00:30:50,689
what are the possible reasons why a

675
00:30:47,179 --> 00:30:52,940
vulnerability remained and on a system

676
00:30:50,690 --> 00:30:57,100
Road one of the possible reasons why it

677
00:30:52,940 --> 00:31:01,280
remained insecure in the marketplace

678
00:30:57,100 --> 00:31:07,189
there's a number of things you can do to

679
00:31:01,280 --> 00:31:11,928
make regulators jobs easier one I think

680
00:31:07,190 --> 00:31:13,909
would be really neat if let me before

681
00:31:11,929 --> 00:31:14,070
sharing this recommendation let me let

682
00:31:13,909 --> 00:31:17,730
me

683
00:31:14,070 --> 00:31:19,919
give some background if if your client

684
00:31:17,730 --> 00:31:23,370
or if your company has a consequential

685
00:31:19,920 --> 00:31:24,930
security breach you'll get a call from

686
00:31:23,370 --> 00:31:26,699
the Federal Trade Commission or from a

687
00:31:24,930 --> 00:31:27,870
state attorney general they call up and

688
00:31:26,700 --> 00:31:32,490
they say we want to know what happened

689
00:31:27,870 --> 00:31:35,330
tell us what happened in those

690
00:31:32,490 --> 00:31:38,900
conversations they're trying to decide

691
00:31:35,330 --> 00:31:41,220
whether or not they should bring a case

692
00:31:38,900 --> 00:31:43,440
against that specific company and more

693
00:31:41,220 --> 00:31:45,180
often than not they don't so they're

694
00:31:43,440 --> 00:31:49,080
screening many many many different

695
00:31:45,180 --> 00:31:51,810
incidents to decide which ones to pursue

696
00:31:49,080 --> 00:31:53,610
I think that'd be really useful for

697
00:31:51,810 --> 00:31:55,440
people in this community to create

698
00:31:53,610 --> 00:31:59,040
checklists of the types of questions

699
00:31:55,440 --> 00:32:00,510
lawyers should be asking technical

700
00:31:59,040 --> 00:32:04,680
experts so this would be a deposition

701
00:32:00,510 --> 00:32:07,100
checklist in in in normal parlance but

702
00:32:04,680 --> 00:32:11,430
you could also imagine specific ones for

703
00:32:07,100 --> 00:32:16,080
let's say security breach the other

704
00:32:11,430 --> 00:32:21,030
aspect where where I think there's been

705
00:32:16,080 --> 00:32:24,240
a pretty effective research-based

706
00:32:21,030 --> 00:32:27,720
information transferred to regulators is

707
00:32:24,240 --> 00:32:29,640
occurring in standards so if you talk to

708
00:32:27,720 --> 00:32:31,950
the Federal Trade Commission people

709
00:32:29,640 --> 00:32:33,810
about what are the types of security

710
00:32:31,950 --> 00:32:35,580
breaches you decide to bring lawsuits

711
00:32:33,810 --> 00:32:39,600
for like you know what

712
00:32:35,580 --> 00:32:42,590
why did you sue Equifax and not another

713
00:32:39,600 --> 00:32:44,639
company well size and damage and so on

714
00:32:42,590 --> 00:32:50,550
but one of the main things they look at

715
00:32:44,640 --> 00:32:51,810
is the wasp vulnerabilities list and the

716
00:32:50,550 --> 00:32:54,870
Federal Trade Commission even says this

717
00:32:51,810 --> 00:32:57,690
in their reports that that the OWASP

718
00:32:54,870 --> 00:33:01,469
standards are important to them and then

719
00:32:57,690 --> 00:33:03,900
here in California when Senator Kamala

720
00:33:01,470 --> 00:33:05,550
Harris was a Trent was Attorney General

721
00:33:03,900 --> 00:33:08,040
here in California she did something

722
00:33:05,550 --> 00:33:09,810
really interesting she collected data on

723
00:33:08,040 --> 00:33:11,610
all the security breaches that occurred

724
00:33:09,810 --> 00:33:14,129
in California that were reported to her

725
00:33:11,610 --> 00:33:16,850
office and what she found was is that if

726
00:33:14,130 --> 00:33:20,760
you looked at the root causes of those

727
00:33:16,850 --> 00:33:23,399
security security breaches many of them

728
00:33:20,760 --> 00:33:25,500
would have been prevented if if you had

729
00:33:23,400 --> 00:33:27,420
applied the the former you know the so

730
00:33:25,500 --> 00:33:29,070
called the CSC controls

731
00:33:27,420 --> 00:33:30,870
and if you look at the Attorney

732
00:33:29,070 --> 00:33:32,850
General's guidance on reasonable

733
00:33:30,870 --> 00:33:35,100
security what they've basically done is

734
00:33:32,850 --> 00:33:37,980
they've copied and pasted the CSC

735
00:33:35,100 --> 00:33:42,360
controls and and that is what they

736
00:33:37,980 --> 00:33:44,100
consider reasonable security here and

737
00:33:42,360 --> 00:33:47,189
here in California and finally I'm gonna

738
00:33:44,100 --> 00:33:51,270
I'm gonna in here in part because I'd

739
00:33:47,190 --> 00:33:55,260
love to hear your your feedback on this

740
00:33:51,270 --> 00:33:55,830
on this last point you know security

741
00:33:55,260 --> 00:33:58,620
breach

742
00:33:55,830 --> 00:34:02,850
laws came out of Berkeley they were

743
00:33:58,620 --> 00:34:06,479
invention of Deirdre Mulligan she she

744
00:34:02,850 --> 00:34:07,980
had this idea that if we had to report

745
00:34:06,480 --> 00:34:12,360
security breaches we could get public

746
00:34:07,980 --> 00:34:14,730
data about insecurity and and maybe we

747
00:34:12,360 --> 00:34:16,650
could do something about insecurity well

748
00:34:14,730 --> 00:34:20,210
when they when when those laws were

749
00:34:16,650 --> 00:34:22,889
conceived of we had no idea how many

750
00:34:20,210 --> 00:34:25,350
incidences and breaches were actually

751
00:34:22,889 --> 00:34:28,199
occurring and in fact I think everybody

752
00:34:25,350 --> 00:34:30,630
was surprised by the number that were

753
00:34:28,199 --> 00:34:32,668
actually occurring the other interesting

754
00:34:30,630 --> 00:34:35,910
dynamic in security breach notification

755
00:34:32,668 --> 00:34:37,770
law is that it's really about identity

756
00:34:35,909 --> 00:34:40,529
theft you think about it like what are

757
00:34:37,770 --> 00:34:42,480
the what are the trigger what what

758
00:34:40,530 --> 00:34:44,850
information triggers a security breach

759
00:34:42,480 --> 00:34:45,750
its social security number a credit card

760
00:34:44,850 --> 00:34:49,250
number and so on

761
00:34:45,750 --> 00:34:52,429
well that's because when that law passed

762
00:34:49,250 --> 00:34:55,679
that was the only harm that the

763
00:34:52,429 --> 00:34:59,700
legislature thought was serious enough

764
00:34:55,679 --> 00:35:01,200
to justify reach notification no that

765
00:34:59,700 --> 00:35:02,609
doesn't make any I mean now we know that

766
00:35:01,200 --> 00:35:03,629
that's that doesn't make a lot of sense

767
00:35:02,610 --> 00:35:07,080
anymore right

768
00:35:03,630 --> 00:35:09,330
there are many consequential security

769
00:35:07,080 --> 00:35:11,850
incidents out there involving

770
00:35:09,330 --> 00:35:14,279
intellectual property trade secret that

771
00:35:11,850 --> 00:35:19,110
you don't have to disclose unless you're

772
00:35:14,280 --> 00:35:21,330
a publicly traded company and there's

773
00:35:19,110 --> 00:35:23,040
other things that happen out there that

774
00:35:21,330 --> 00:35:25,980
aren't covered by security breach

775
00:35:23,040 --> 00:35:30,240
notification laws and so what happens

776
00:35:25,980 --> 00:35:31,890
now in practice is that when a you know

777
00:35:30,240 --> 00:35:34,709
when it likes or horses when a client

778
00:35:31,890 --> 00:35:35,250
comes to me and says we've had something

779
00:35:34,710 --> 00:35:37,290
happen

780
00:35:35,250 --> 00:35:41,100
I say don't call it a security breach

781
00:35:37,290 --> 00:35:43,230
it's not a breach until we have legal

782
00:35:41,100 --> 00:35:45,720
determined that we are required to give

783
00:35:43,230 --> 00:35:48,600
notice we're gonna call this a security

784
00:35:45,720 --> 00:35:51,750
incident until we fully investigate it

785
00:35:48,600 --> 00:35:53,730
and here's the real problem there are

786
00:35:51,750 --> 00:36:00,270
incidents that are far worse than any

787
00:35:53,730 --> 00:36:04,170
breaches right I mean just imagine it if

788
00:36:00,270 --> 00:36:06,330
a search engine company lost all your

789
00:36:04,170 --> 00:36:08,550
search strings that would be pretty

790
00:36:06,330 --> 00:36:11,580
painful it'd be pretty embarrassing

791
00:36:08,550 --> 00:36:15,150
probably more probably more embarrassing

792
00:36:11,580 --> 00:36:17,279
or more problematic than if a search

793
00:36:15,150 --> 00:36:19,230
engine company lost your credit card

794
00:36:17,280 --> 00:36:23,450
number I mean the end of the day you're

795
00:36:19,230 --> 00:36:26,310
insured right against credit card losses

796
00:36:23,450 --> 00:36:27,930
but a search engine strings aren't

797
00:36:26,310 --> 00:36:29,820
covered by security breach laws they're

798
00:36:27,930 --> 00:36:32,339
not a breach they're an incident and

799
00:36:29,820 --> 00:36:36,870
there's many many other examples like

800
00:36:32,340 --> 00:36:38,340
that out there where websites including

801
00:36:36,870 --> 00:36:41,670
websites that have very sensitive

802
00:36:38,340 --> 00:36:44,730
content have incidents and lose their

803
00:36:41,670 --> 00:36:48,840
entire user database and they don't have

804
00:36:44,730 --> 00:36:51,030
to give anybody notice so I would out I

805
00:36:48,840 --> 00:36:53,100
want to invite you to think about how we

806
00:36:51,030 --> 00:36:56,390
we might broaden the aperture of what we

807
00:36:53,100 --> 00:37:00,660
consider consequential security events

808
00:36:56,390 --> 00:37:02,790
maybe for reporting purposes maybe to

809
00:37:00,660 --> 00:37:05,339
talk to regulators about other areas

810
00:37:02,790 --> 00:37:08,400
where where they can intervene so with

811
00:37:05,340 --> 00:37:12,120
that I'd love to take questions or we or

812
00:37:08,400 --> 00:37:16,530
we could ten minutes okay okay great

813
00:37:12,120 --> 00:37:18,690
and I'd love to hear what what you think

814
00:37:16,530 --> 00:37:21,480
about some of this critique yes please

815
00:37:18,690 --> 00:37:23,490
hi I'm the I'm the chief privacy officer

816
00:37:21,480 --> 00:37:24,810
and I start up called humu but I used to

817
00:37:23,490 --> 00:37:27,660
be the global lead

818
00:37:24,810 --> 00:37:30,630
privacy tech at Google so I talked to

819
00:37:27,660 --> 00:37:32,940
FTC people before the thing that I

820
00:37:30,630 --> 00:37:35,190
wonder is you're talking about hey let's

821
00:37:32,940 --> 00:37:38,250
go make a deposition checklist for

822
00:37:35,190 --> 00:37:40,800
lawyers why are we not sending engineers

823
00:37:38,250 --> 00:37:44,340
in to go and try and find these because

824
00:37:40,800 --> 00:37:47,070
I love lawyers I worked with lots of

825
00:37:44,340 --> 00:37:48,960
lawyers most of them are not as good at

826
00:37:47,070 --> 00:37:50,580
finding problems in a system as the

827
00:37:48,960 --> 00:37:52,650
teams of privacy engineers that I've

828
00:37:50,580 --> 00:37:54,450
trained yeah

829
00:37:52,650 --> 00:37:56,310
I'm what we're working on in Berkeley is

830
00:37:54,450 --> 00:37:58,350
we're trying to train the next

831
00:37:56,310 --> 00:38:00,330
generation of what we call Public

832
00:37:58,350 --> 00:38:02,069
Interest technologists and so watch

833
00:38:00,330 --> 00:38:03,569
consul tony was one of my students and

834
00:38:02,070 --> 00:38:06,440
he was at the Federal Trade Commission

835
00:38:03,570 --> 00:38:08,430
consulted on these cases he he had

836
00:38:06,440 --> 00:38:09,960
consequential findings I mean he was the

837
00:38:08,430 --> 00:38:12,270
one who figured out that there were all

838
00:38:09,960 --> 00:38:14,850
sorts of pictures in Facebook that you

839
00:38:12,270 --> 00:38:17,850
could reach through their CDN that were

840
00:38:14,850 --> 00:38:21,089
not password protected and so on and

841
00:38:17,850 --> 00:38:22,500
those totally escaped the lawyers I so I

842
00:38:21,090 --> 00:38:25,530
I agree with you

843
00:38:22,500 --> 00:38:28,350
like in and so one we've been struggling

844
00:38:25,530 --> 00:38:32,520
with is finding people who can really do

845
00:38:28,350 --> 00:38:33,990
the technology and and convince the

846
00:38:32,520 --> 00:38:38,340
regulators that like there's something

847
00:38:33,990 --> 00:38:43,259
important in their findings we need many

848
00:38:38,340 --> 00:38:44,640
more people like that any other

849
00:38:43,260 --> 00:38:48,720
questions or critiques anybody want to

850
00:38:44,640 --> 00:38:49,920
yell at me and argue about what are the

851
00:38:48,720 --> 00:38:52,049
right what should the regulator's be

852
00:38:49,920 --> 00:38:54,030
doing that they're not the types of

853
00:38:52,050 --> 00:38:57,090
things that you think are important or

854
00:38:54,030 --> 00:38:59,940
consequential dev do you I don't want to

855
00:38:57,090 --> 00:39:02,940
yell at you okay thank you

856
00:38:59,940 --> 00:39:05,400
I think you talked about exclaim the I

857
00:39:02,940 --> 00:39:06,750
think you talked about explain the in

858
00:39:05,400 --> 00:39:09,030
the cost benefit like talk about the

859
00:39:06,750 --> 00:39:11,520
cost to add the mitigation add more

860
00:39:09,030 --> 00:39:14,010
security but if they're doing the

861
00:39:11,520 --> 00:39:17,580
benefit analysis how do we argue about

862
00:39:14,010 --> 00:39:20,340
the benefit of turning on a SLR or the

863
00:39:17,580 --> 00:39:21,930
benefit of like in some cases I agree

864
00:39:20,340 --> 00:39:24,960
it's agree it's easy I think like the

865
00:39:21,930 --> 00:39:26,700
unsubscribe from spam yes yes it's like

866
00:39:24,960 --> 00:39:27,750
what is the benefit of like because I

867
00:39:26,700 --> 00:39:29,879
think like that's one of the things the

868
00:39:27,750 --> 00:39:31,830
community also grapples with is it's

869
00:39:29,880 --> 00:39:33,930
hard to measure security it's hard to

870
00:39:31,830 --> 00:39:36,840
really say this significantly improves

871
00:39:33,930 --> 00:39:38,430
security outcomes and so like if you do

872
00:39:36,840 --> 00:39:41,790
that now will we get stuck on benefits

873
00:39:38,430 --> 00:39:45,450
sir that's a great question right I

874
00:39:41,790 --> 00:39:48,180
think I think the anok data is is is is

875
00:39:45,450 --> 00:39:50,129
more powerful and so the examples I

876
00:39:48,180 --> 00:39:53,370
would give is can you point to specific

877
00:39:50,130 --> 00:39:56,520
botnets that spread as a result of that

878
00:39:53,370 --> 00:40:00,359
protection not being in place if you

879
00:39:56,520 --> 00:40:02,310
can't I it might be that that's just not

880
00:40:00,360 --> 00:40:05,000
the intervention that that the

881
00:40:02,310 --> 00:40:11,000
regulators should be pursuing

882
00:40:05,000 --> 00:40:14,390
I aren't gross another former security

883
00:40:11,000 --> 00:40:17,180
person from the big search engine when I

884
00:40:14,390 --> 00:40:19,040
hear it would take only 10 seconds to

885
00:40:17,180 --> 00:40:19,669
insert this compiled flag of course I

886
00:40:19,040 --> 00:40:22,190
think yes

887
00:40:19,670 --> 00:40:24,859
ten seconds to type that flag another

888
00:40:22,190 --> 00:40:26,450
three days to debug the messages that

889
00:40:24,859 --> 00:40:27,650
come from that and another three months

890
00:40:26,450 --> 00:40:31,009
to actually deploy it

891
00:40:27,650 --> 00:40:33,290
so I come from prospective wishing there

892
00:40:31,010 --> 00:40:36,230
were some way to use market mechanisms

893
00:40:33,290 --> 00:40:38,590
instead of tricking regulators into

894
00:40:36,230 --> 00:40:42,200
causing good things to happen out there

895
00:40:38,590 --> 00:40:45,190
sometimes the the tools that I would

896
00:40:42,200 --> 00:40:47,779
hope would help inform the market

897
00:40:45,190 --> 00:40:50,119
mechanisms entail some kind of legal

898
00:40:47,780 --> 00:40:52,910
risk either to the companies involved or

899
00:40:50,119 --> 00:40:54,530
to the people publicly complaining about

900
00:40:52,910 --> 00:40:57,140
the companies and then getting sued for

901
00:40:54,530 --> 00:40:59,780
libel or whatever do you have any legal

902
00:40:57,140 --> 00:41:04,310
thoughts on improving the market

903
00:40:59,780 --> 00:41:07,640
mechanism so I one of the reasons why

904
00:41:04,310 --> 00:41:11,000
I'm a fan of Mudge in this project is

905
00:41:07,640 --> 00:41:14,109
that it did the idea is you know

906
00:41:11,000 --> 00:41:17,000
Consumer Reports since the 1930s has had

907
00:41:14,109 --> 00:41:19,759
people wearing lab coats testing whether

908
00:41:17,000 --> 00:41:21,560
doors open well alright and so on and so

909
00:41:19,760 --> 00:41:22,790
they're they're now going to be looking

910
00:41:21,560 --> 00:41:24,170
at the software so I think that's

911
00:41:22,790 --> 00:41:26,420
important but I definitely don't think

912
00:41:24,170 --> 00:41:28,849
it's enough I think it's the first the

913
00:41:26,420 --> 00:41:30,589
first step out there I you know an

914
00:41:28,849 --> 00:41:32,750
interesting problem with Consumer

915
00:41:30,589 --> 00:41:34,520
Reports is if you if you look at their

916
00:41:32,750 --> 00:41:37,970
average reader they look like me it's a

917
00:41:34,520 --> 00:41:40,339
white dude with gray hair so we have to

918
00:41:37,970 --> 00:41:41,899
not only I think we have to get the

919
00:41:40,339 --> 00:41:43,520
signals about quality into the

920
00:41:41,900 --> 00:41:46,220
marketplace but we also have to make

921
00:41:43,520 --> 00:41:50,349
sure that they reach down to two other

922
00:41:46,220 --> 00:41:52,700
types of consumers thank you

923
00:41:50,349 --> 00:41:56,180
hi Matthew from the University of Bonn

924
00:41:52,700 --> 00:41:58,910
in Germany you you asked for feedback

925
00:41:56,180 --> 00:42:00,770
what regulators could do I think one

926
00:41:58,910 --> 00:42:02,118
awesome thing would be to work more

927
00:42:00,770 --> 00:42:07,150
closely with the usable security

928
00:42:02,119 --> 00:42:09,170
community yeah and tailor the kind of

929
00:42:07,150 --> 00:42:11,150
regulation to what humans can actually

930
00:42:09,170 --> 00:42:14,119
do so living in Germany I'm on the

931
00:42:11,150 --> 00:42:15,250
receiving end of gdpr and it's pretty

932
00:42:14,119 --> 00:42:19,300
horrible

933
00:42:15,250 --> 00:42:21,070
so it it's great on the firing companies

934
00:42:19,300 --> 00:42:23,170
for data breaches it's pretty bad on the

935
00:42:21,070 --> 00:42:25,210
side of informed consent because they

936
00:42:23,170 --> 00:42:27,190
basically the companies design things in

937
00:42:25,210 --> 00:42:28,630
a way that basically you are forced to

938
00:42:27,190 --> 00:42:30,240
consent to everything they want because

939
00:42:28,630 --> 00:42:32,290
otherwise it's just too much work and

940
00:42:30,240 --> 00:42:35,290
anybody in the usable security community

941
00:42:32,290 --> 00:42:39,430
could foreseen that and help regulators

942
00:42:35,290 --> 00:42:42,759
prevent that from being a legal option I

943
00:42:39,430 --> 00:42:45,730
think you know the cookie notice and the

944
00:42:42,760 --> 00:42:49,330
cookie notices are quite tiresome they

945
00:42:45,730 --> 00:42:50,920
are horrendous um but I've helped a lot

946
00:42:49,330 --> 00:42:54,400
of clients deal with gdpr

947
00:42:50,920 --> 00:42:56,560
and I'd say that 95% of the compliance

948
00:42:54,400 --> 00:43:00,160
effort is under the hood and the

949
00:42:56,560 --> 00:43:03,460
consumer would never never know that

950
00:43:00,160 --> 00:43:04,629
they stopped collecting x y&z what I've

951
00:43:03,460 --> 00:43:08,160
seen with a lot of clients is they've

952
00:43:04,630 --> 00:43:11,260
never had a data retention policy so

953
00:43:08,160 --> 00:43:14,020
gdpr is the first conversation you have

954
00:43:11,260 --> 00:43:18,130
with many companies of like so how long

955
00:43:14,020 --> 00:43:20,320
are you going to keep this and and then

956
00:43:18,130 --> 00:43:24,099
another big area where I've seen a huge

957
00:43:20,320 --> 00:43:26,619
amount is the decision to secretly do

958
00:43:24,099 --> 00:43:28,270
face recognition alright so I mean when

959
00:43:26,619 --> 00:43:30,099
I think one of the kind of secrets out

960
00:43:28,270 --> 00:43:31,720
there and the valley is that if you give

961
00:43:30,099 --> 00:43:33,430
your photograph to any service they're

962
00:43:31,720 --> 00:43:35,560
running face recognition on it they just

963
00:43:33,430 --> 00:43:39,430
they may or may not tell you and they

964
00:43:35,560 --> 00:43:42,099
may or may not tagged the gdpr has

965
00:43:39,430 --> 00:43:44,348
stopped tamped down some of that

966
00:43:42,099 --> 00:43:47,200
opportunism don't get me wrong GPR is

967
00:43:44,349 --> 00:43:48,820
fantastic is I'm just saying the those

968
00:43:47,200 --> 00:43:53,290
parts where you're interacting with

969
00:43:48,820 --> 00:43:54,880
humans is horrible so that's that's why

970
00:43:53,290 --> 00:43:57,910
I think there could be improvement with

971
00:43:54,880 --> 00:43:59,080
research we we offer actually I'm

972
00:43:57,910 --> 00:44:02,560
wondering what you think about this

973
00:43:59,080 --> 00:44:04,810
because that to me I think the ICO the

974
00:44:02,560 --> 00:44:07,240
UK ICO led with this cookie disclosure

975
00:44:04,810 --> 00:44:09,040
that I thought this is not what the GDP

976
00:44:07,240 --> 00:44:13,359
are is trying to do but they led with it

977
00:44:09,040 --> 00:44:15,490
and signal that it was okay and maybe

978
00:44:13,359 --> 00:44:20,920
they'll be reformed along those lines

979
00:44:15,490 --> 00:44:23,169
do you have comment on that yeah on the

980
00:44:20,920 --> 00:44:25,060
I mean the I co was courteous that I

981
00:44:23,170 --> 00:44:27,000
thought this is not what the GDP are is

982
00:44:25,060 --> 00:44:29,410
trying to do but they led with it and

983
00:44:27,000 --> 00:44:32,140
signaled that it was okay

984
00:44:29,410 --> 00:44:33,100
and maybe they'll be reformed along

985
00:44:32,140 --> 00:44:38,529
those lines

986
00:44:33,100 --> 00:44:41,020
do you have comment on that yeah on the

987
00:44:38,530 --> 00:44:43,150
I mean the I co was criticized for not

988
00:44:41,020 --> 00:44:46,420
being compliant with its own websites

989
00:44:43,150 --> 00:44:48,010
until very recently and I'm just

990
00:44:46,420 --> 00:44:50,310
reporting this from the press I'm

991
00:44:48,010 --> 00:44:52,630
obviously not taking a position on what

992
00:44:50,310 --> 00:44:57,700
colleague data protection authorities

993
00:44:52,630 --> 00:45:01,870
are doing and when they reviewed their

994
00:44:57,700 --> 00:45:03,700
guidance on cookies and then they

995
00:45:01,870 --> 00:45:05,980
decided actually to become compliant

996
00:45:03,700 --> 00:45:09,850
with their own guidance and so they are

997
00:45:05,980 --> 00:45:12,670
giving credit for that and it's actually

998
00:45:09,850 --> 00:45:16,060
I'm I'm quite surprised that I find more

999
00:45:12,670 --> 00:45:18,760
and more website who have decent cookie

1000
00:45:16,060 --> 00:45:21,460
pages so some still have the old style

1001
00:45:18,760 --> 00:45:24,730
thing Oh video cookies and that will be

1002
00:45:21,460 --> 00:45:26,080
all good for you just admit that it will

1003
00:45:24,730 --> 00:45:28,030
be all good for you but now I've

1004
00:45:26,080 --> 00:45:30,370
encountered plenty of websites

1005
00:45:28,030 --> 00:45:33,040
personally where you have cede the

1006
00:45:30,370 --> 00:45:35,350
technically necessary cookies I mean

1007
00:45:33,040 --> 00:45:38,410
still a question whether that's still

1008
00:45:35,350 --> 00:45:41,020
state-of-the-art but then performance

1009
00:45:38,410 --> 00:45:43,750
personalization tracking targeted

1010
00:45:41,020 --> 00:45:47,410
advertising cookies can be switched off

1011
00:45:43,750 --> 00:45:49,990
one by one explicitly and there's tools

1012
00:45:47,410 --> 00:45:51,910
out now from commercial companies who

1013
00:45:49,990 --> 00:45:54,700
are offering that and it's taking more

1014
00:45:51,910 --> 00:45:57,399
and more and I see it mostly was

1015
00:45:54,700 --> 00:46:00,250
companies who don't depend on tracking

1016
00:45:57,400 --> 00:46:03,130
and advertising revenue so I mean those

1017
00:46:00,250 --> 00:46:05,500
who depend on tracking and advertising

1018
00:46:03,130 --> 00:46:07,510
revenue of course are reluctant to makes

1019
00:46:05,500 --> 00:46:09,670
a change but those who earn their money

1020
00:46:07,510 --> 00:46:12,820
in a different way by selling Allah our

1021
00:46:09,670 --> 00:46:15,910
plane tickets or hotel bookings or so

1022
00:46:12,820 --> 00:46:17,560
they see that they get better a customer

1023
00:46:15,910 --> 00:46:20,920
relationship when they are transparent

1024
00:46:17,560 --> 00:46:23,320
and actually respect choice ooh I think

1025
00:46:20,920 --> 00:46:25,930
there is a change ongoing which is I

1026
00:46:23,320 --> 00:46:27,640
mean we just bit more than one year in

1027
00:46:25,930 --> 00:46:31,230
the validity in the full applicability

1028
00:46:27,640 --> 00:46:31,230
of cont DPR and

1029
00:46:33,060 --> 00:46:36,540
this is going better than I was

1030
00:46:34,500 --> 00:46:38,580
expecting to be honest on because maybe

1031
00:46:36,540 --> 00:46:39,450
I'm a bit cynical and pessimistic in

1032
00:46:38,580 --> 00:46:41,910
that respect

1033
00:46:39,450 --> 00:46:43,560
yeah there's dialogue so I find them

1034
00:46:41,910 --> 00:46:44,700
frustrating and if you just press X to

1035
00:46:43,560 --> 00:46:51,080
get rid of them they treat that as

1036
00:46:44,700 --> 00:46:54,149
except hmm yeah important design hair

1037
00:46:51,080 --> 00:46:59,009
and I think I have one like one question

1038
00:46:54,150 --> 00:47:02,720
and then hand it over okay

1039
00:46:59,010 --> 00:47:02,720
William Sampson daydreamer

1040
00:47:03,270 --> 00:47:09,570
also a lifetime subscriber to Consumer

1041
00:47:06,690 --> 00:47:11,370
Reports and I own an LG Tony television

1042
00:47:09,570 --> 00:47:13,650
and I can tell you because I looked at

1043
00:47:11,370 --> 00:47:15,390
all of their software that in fact

1044
00:47:13,650 --> 00:47:16,800
they're running Linux on top of arctos

1045
00:47:15,390 --> 00:47:20,870
they could have had all the security

1046
00:47:16,800 --> 00:47:20,870
features they just didn't turn them on

1047
00:47:22,040 --> 00:47:29,520
we gave the FTC for Dave Farber was and

1048
00:47:27,330 --> 00:47:29,880
then Steve elleven who usually attends

1049
00:47:29,520 --> 00:47:33,180
here

1050
00:47:29,880 --> 00:47:34,320
Farber does occasionally and during his

1051
00:47:33,180 --> 00:47:35,819
first few months there I went and

1052
00:47:34,320 --> 00:47:37,920
visited Steve so I already knew you only

1053
00:47:35,820 --> 00:47:39,480
take a few cases a year which is really

1054
00:47:37,920 --> 00:47:45,180
terrible

1055
00:47:39,480 --> 00:47:49,530
but I I could talk about a lot of this

1056
00:47:45,180 --> 00:47:54,000
stuff but the main thing is there is no

1057
00:47:49,530 --> 00:47:55,920
private right of action okay is that yes

1058
00:47:54,000 --> 00:47:58,320
the federal government or state

1059
00:47:55,920 --> 00:48:01,290
governments they have some amount of

1060
00:47:58,320 --> 00:48:02,820
limited resources but without a private

1061
00:48:01,290 --> 00:48:04,710
right of action for the people who

1062
00:48:02,820 --> 00:48:09,300
actually have been affected by bad

1063
00:48:04,710 --> 00:48:10,530
software or bad you know access points I

1064
00:48:09,300 --> 00:48:13,770
mean we've known about distributed

1065
00:48:10,530 --> 00:48:17,550
denial there was a tax since 1996 and we

1066
00:48:13,770 --> 00:48:21,930
predicted them had papers in 1991 and -

1067
00:48:17,550 --> 00:48:25,080
okay before they even occurred so this

1068
00:48:21,930 --> 00:48:26,669
is not news you know yes the identity

1069
00:48:25,080 --> 00:48:29,430
theft has something to do with money and

1070
00:48:26,670 --> 00:48:32,280
so that Congress can say oh it might

1071
00:48:29,430 --> 00:48:34,919
affect somebody financially but in fact

1072
00:48:32,280 --> 00:48:37,140
all of the kinds of our botnet

1073
00:48:34,920 --> 00:48:38,730
they affect you in every way they take

1074
00:48:37,140 --> 00:48:41,940
your bandwidth from your home they take

1075
00:48:38,730 --> 00:48:43,860
that is those are all losses but without

1076
00:48:41,940 --> 00:48:45,990
a private right of action

1077
00:48:43,860 --> 00:48:47,850
the real problem is we don't have good

1078
00:48:45,990 --> 00:48:50,209
enforcement mechanisms we have perfectly

1079
00:48:47,850 --> 00:48:54,540
good definitions for many things but

1080
00:48:50,210 --> 00:48:57,330
there is no good enforcement mechanism I

1081
00:48:54,540 --> 00:48:59,070
like the fact that GD P R I love lots of

1082
00:48:57,330 --> 00:49:01,110
things about GDP are not the fact that

1083
00:48:59,070 --> 00:49:05,280
you can only say except about their

1084
00:49:01,110 --> 00:49:07,410
cookie policy but the the is that it can

1085
00:49:05,280 --> 00:49:08,520
be up to the fine can be up to 4 percent

1086
00:49:07,410 --> 00:49:11,190
of the gross revenue of the company

1087
00:49:08,520 --> 00:49:13,200
that's a serious fine as opposed to the

1088
00:49:11,190 --> 00:49:15,630
slap on the wrist that most of the stuff

1089
00:49:13,200 --> 00:49:17,790
that we get now if you're gonna take 20

1090
00:49:15,630 --> 00:49:20,130
cases here they should be going for 20

1091
00:49:17,790 --> 00:49:22,860
cases a year that causes the companies

1092
00:49:20,130 --> 00:49:24,570
to go to near bankruptcy so that they

1093
00:49:22,860 --> 00:49:26,850
send a single all the other ones that

1094
00:49:24,570 --> 00:49:30,260
they need to take security seriously and

1095
00:49:26,850 --> 00:49:34,080
hire more security engineers obviously

1096
00:49:30,260 --> 00:49:36,030
and and in that way improve the whole

1097
00:49:34,080 --> 00:49:39,980
ecosystem but a private right of action

1098
00:49:36,030 --> 00:49:43,770
might also be very helpful because it

1099
00:49:39,980 --> 00:49:45,630
informed consumers are the ones who are

1100
00:49:43,770 --> 00:49:49,259
more likely to be able to be active and

1101
00:49:45,630 --> 00:49:50,820
give good stories that that they will

1102
00:49:49,260 --> 00:49:55,320
have the courts on the legislators of

1103
00:49:50,820 --> 00:49:57,090
understand let me say briefly that the

1104
00:49:55,320 --> 00:49:58,440
California consumer Privacy Act does

1105
00:49:57,090 --> 00:50:02,160
have a private right of action for

1106
00:49:58,440 --> 00:50:05,670
certain security breaches so it detects

1107
00:50:02,160 --> 00:50:07,470
it takes effect on January 1 and it's

1108
00:50:05,670 --> 00:50:13,560
gonna be it's gonna be quite interesting

1109
00:50:07,470 --> 00:50:17,600
I am afraid there's no question brief

1110
00:50:13,560 --> 00:50:19,830
comment three words okay make it I

1111
00:50:17,600 --> 00:50:22,710
thought it was ironic that you compared

1112
00:50:19,830 --> 00:50:25,140
LG & Vizio and showed LG to be more

1113
00:50:22,710 --> 00:50:27,180
secure without pointing out that office

1114
00:50:25,140 --> 00:50:28,980
or less secure without pointing out that

1115
00:50:27,180 --> 00:50:30,899
of the two companies Vizio was the one

1116
00:50:28,980 --> 00:50:36,750
to actually be sued by the FTC for

1117
00:50:30,900 --> 00:50:38,700
deceptive practices I this is gonna be

1118
00:50:36,750 --> 00:50:41,070
really interesting I think I think what

1119
00:50:38,700 --> 00:50:43,589
Mudge and company are doing is really

1120
00:50:41,070 --> 00:50:45,840
important because as they compare these

1121
00:50:43,590 --> 00:50:47,520
different vendors some of them are

1122
00:50:45,840 --> 00:50:49,350
Federal Trade Commission defendants and

1123
00:50:47,520 --> 00:50:50,910
a real questions going to be whether

1124
00:50:49,350 --> 00:50:54,600
those defendants are any better on

1125
00:50:50,910 --> 00:50:55,649
security that's going to be super

1126
00:50:54,600 --> 00:50:58,200
interesting

1127
00:50:55,650 --> 00:51:00,210
okay thank you very much Chris let's

1128
00:50:58,200 --> 00:51:03,629
give a warm applause

1129
00:51:00,210 --> 00:51:03,630
[Applause]

