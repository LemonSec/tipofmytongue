1
00:00:10,780 --> 00:00:15,989
so yes I'm in clearing and this was

2
00:00:14,020 --> 00:00:19,990
joint work with ivan meyer and cannot we

3
00:00:15,990 --> 00:00:22,480
from the TU branch my and let's directly

4
00:00:19,990 --> 00:00:25,689
start so here we can see a source code

5
00:00:22,480 --> 00:00:28,330
example and the question is who's the

6
00:00:25,689 --> 00:00:30,850
offer so let's say we would like to find

7
00:00:28,330 --> 00:00:33,610
out if it was Ellis and authorship

8
00:00:30,850 --> 00:00:35,410
attribution can answer this by

9
00:00:33,610 --> 00:00:38,500
identifying the author of a given source

10
00:00:35,410 --> 00:00:42,968
code by identifying by exploiting the

11
00:00:38,500 --> 00:00:45,760
individual stylistic patterns but what

12
00:00:42,969 --> 00:00:47,440
if Ellis has not Britain that so maybe

13
00:00:45,760 --> 00:00:49,930
the source code here is an adverse or

14
00:00:47,440 --> 00:00:52,269
example and the fret of it verse well

15
00:00:49,930 --> 00:00:55,090
source code examples has received only

16
00:00:52,270 --> 00:00:59,230
little attention so far and my talk

17
00:00:55,090 --> 00:01:02,110
today I will present it and how we can

18
00:00:59,230 --> 00:01:03,430
generate such samples and you will be

19
00:01:02,110 --> 00:01:07,300
surprised how well it works

20
00:01:03,430 --> 00:01:09,340
and cause this domain the domain of

21
00:01:07,300 --> 00:01:13,170
source code is so complicated

22
00:01:09,340 --> 00:01:15,610
we will also I think learn a lot

23
00:01:13,170 --> 00:01:18,130
interesting things how to generate add

24
00:01:15,610 --> 00:01:20,710
virtual examples and such complicated

25
00:01:18,130 --> 00:01:23,408
discrete domains because this is not a

26
00:01:20,710 --> 00:01:27,189
toy example domain and it's quite

27
00:01:23,409 --> 00:01:30,009
complicated to rewrite source code yeah

28
00:01:27,189 --> 00:01:32,649
so let's sort you recap how office of

29
00:01:30,009 --> 00:01:34,360
attribution works before encoding habits

30
00:01:32,650 --> 00:01:36,970
manifests in a variety of stylistic

31
00:01:34,360 --> 00:01:39,670
patterns so that we need an expressive

32
00:01:36,970 --> 00:01:41,259
set of features for attribution free

33
00:01:39,670 --> 00:01:45,189
groups are currently used in the

34
00:01:41,259 --> 00:01:48,970
research field that are lay out lexical

35
00:01:45,189 --> 00:01:51,250
and syntactic features and officer

36
00:01:48,970 --> 00:01:54,070
attribution times this pattern by using

37
00:01:51,250 --> 00:01:57,490
machine learning two notable examples

38
00:01:54,070 --> 00:01:59,289
are the work by Calais Canada which has

39
00:01:57,490 --> 00:02:01,990
the most comprehensive feature set and

40
00:01:59,290 --> 00:02:03,700
we work by abu hamid at are that

41
00:02:01,990 --> 00:02:07,630
performed a large-scale study with

42
00:02:03,700 --> 00:02:10,299
recurrent neural networks so layout

43
00:02:07,630 --> 00:02:12,760
features a simple layout feature can be

44
00:02:10,299 --> 00:02:15,280
for example if we use white spaces or

45
00:02:12,760 --> 00:02:17,370
tabs or the number of empty lines

46
00:02:15,280 --> 00:02:21,520
between our functions and statements and

47
00:02:17,370 --> 00:02:23,599
how we use comments and so on but code

48
00:02:21,520 --> 00:02:26,569
formatting tools like C

49
00:02:23,599 --> 00:02:28,339
format easily removed them and an

50
00:02:26,569 --> 00:02:30,679
attacker of course can also easily

51
00:02:28,340 --> 00:02:33,560
manipulate them so insert more empty

52
00:02:30,680 --> 00:02:36,019
lines is quite easy the more advanced

53
00:02:33,560 --> 00:02:40,010
feature can be derived from a lexical

54
00:02:36,019 --> 00:02:43,370
analysis of a source code we can count

55
00:02:40,010 --> 00:02:45,590
the number of functions I think it's a

56
00:02:43,370 --> 00:02:47,719
quiet good feature because some

57
00:02:45,590 --> 00:02:51,889
developers put all their code in one

58
00:02:47,719 --> 00:02:59,090
function while others use more functions

59
00:02:51,889 --> 00:03:01,489
to get a modular card code and moreover

60
00:02:59,090 --> 00:03:03,799
we can tokenize the code and obtain

61
00:03:01,489 --> 00:03:06,980
string based features that implicitly

62
00:03:03,799 --> 00:03:08,810
describe syntax and semantics here we

63
00:03:06,980 --> 00:03:11,480
see a simple source code example where

64
00:03:08,810 --> 00:03:13,609
we're talking int occurs three times so

65
00:03:11,480 --> 00:03:14,328
the developer may have the tendency to

66
00:03:13,609 --> 00:03:16,760
use int

67
00:03:14,329 --> 00:03:23,180
while another developer would always use

68
00:03:16,760 --> 00:03:25,459
long as a data type in C++ or C such

69
00:03:23,180 --> 00:03:27,769
features cannot be easily manipulated of

70
00:03:25,459 --> 00:03:29,659
course replacing names is quite easy but

71
00:03:27,769 --> 00:03:31,970
replacing data types is already more

72
00:03:29,659 --> 00:03:35,269
difficult since we need to adapt all its

73
00:03:31,970 --> 00:03:37,489
usages another class of features are

74
00:03:35,269 --> 00:03:40,280
syntax and control for patterns from the

75
00:03:37,489 --> 00:03:42,290
abstract syntax tree for instance we

76
00:03:40,280 --> 00:03:45,199
could use the number of adjacent tree

77
00:03:42,290 --> 00:03:48,530
nodes as feature so the joint occurrence

78
00:03:45,199 --> 00:03:54,489
of the function and argument nodes or

79
00:03:48,530 --> 00:03:57,169
the if and compartment three nodes and

80
00:03:54,489 --> 00:03:59,060
again manipulating such features is

81
00:03:57,169 --> 00:04:04,340
quite challenging without changing the

82
00:03:59,060 --> 00:04:06,699
whole tree structure so these features

83
00:04:04,340 --> 00:04:08,959
give us a broad view on the

84
00:04:06,699 --> 00:04:10,879
characteristics of source code and as

85
00:04:08,959 --> 00:04:14,269
most learning methods operate and on

86
00:04:10,879 --> 00:04:16,728
vectors we need to map our features to

87
00:04:14,269 --> 00:04:19,548
vector space and usually we perform some

88
00:04:16,728 --> 00:04:22,130
feature selection and tf-idf waiting and

89
00:04:19,548 --> 00:04:25,429
finally we train a classifier with one

90
00:04:22,130 --> 00:04:27,080
class per offer and attribution works by

91
00:04:25,430 --> 00:04:29,930
evaluating the score of each class and

92
00:04:27,080 --> 00:04:33,380
then returning the class or offer with a

93
00:04:29,930 --> 00:04:35,990
highest score so back to the question of

94
00:04:33,380 --> 00:04:37,230
LS is our source code offer and now we

95
00:04:35,990 --> 00:04:39,210
see that Alice has

96
00:04:37,230 --> 00:04:41,520
not written the source code we

97
00:04:39,210 --> 00:04:43,650
manipulated some specific patterns in

98
00:04:41,520 --> 00:04:46,919
the source code so while here it's just

99
00:04:43,650 --> 00:04:50,099
Ellis what if that verse we would choose

100
00:04:46,920 --> 00:04:53,220
a victim like a real developer or a

101
00:04:50,100 --> 00:04:55,680
company so it's essential that source

102
00:04:53,220 --> 00:04:59,700
code attribution is accurate and robust

103
00:04:55,680 --> 00:05:03,660
as false allegation could have of course

104
00:04:59,700 --> 00:05:05,370
white reaching consequences for our

105
00:05:03,660 --> 00:05:08,190
attack we assume an adversary with

106
00:05:05,370 --> 00:05:10,200
blackbox access she can send a source

107
00:05:08,190 --> 00:05:12,780
code to the method and retrieve the

108
00:05:10,200 --> 00:05:14,670
corresponding prediction scores the

109
00:05:12,780 --> 00:05:18,210
training data the features and the

110
00:05:14,670 --> 00:05:20,100
learning algorithm are not known in our

111
00:05:18,210 --> 00:05:24,060
paper we also test the transferability

112
00:05:20,100 --> 00:05:25,740
scenario where but versa we has some

113
00:05:24,060 --> 00:05:27,960
training data but not access to the

114
00:05:25,740 --> 00:05:30,630
original classifier and it also works

115
00:05:27,960 --> 00:05:33,680
but I won't talk about that in my talk

116
00:05:30,630 --> 00:05:40,680
today I will focus on the black box

117
00:05:33,680 --> 00:05:42,420
scenario with available classifier we

118
00:05:40,680 --> 00:05:45,600
consider two types of attacks

119
00:05:42,420 --> 00:05:47,490
the first is an untargeted one where we

120
00:05:45,600 --> 00:05:49,650
want to change the classification into

121
00:05:47,490 --> 00:05:51,540
any other developer and the more

122
00:05:49,650 --> 00:05:53,760
sophisticated attack is the targeted

123
00:05:51,540 --> 00:05:55,820
version where you want to change the

124
00:05:53,760 --> 00:05:58,020
classification into a previously chosen

125
00:05:55,820 --> 00:05:59,730
target developer and this is quite

126
00:05:58,020 --> 00:06:03,750
challenging because we really need to

127
00:05:59,730 --> 00:06:05,250
mimic the coding habits from one we have

128
00:06:03,750 --> 00:06:10,920
to move through coding habits from one

129
00:06:05,250 --> 00:06:12,780
developer to another developer to mimic

130
00:06:10,920 --> 00:06:15,390
a realistic attack we also set some

131
00:06:12,780 --> 00:06:18,210
constraints in the bursar the change

132
00:06:15,390 --> 00:06:20,150
source code should be should produce the

133
00:06:18,210 --> 00:06:24,030
same output of course for a given input

134
00:06:20,150 --> 00:06:27,479
envers source code should be readable

135
00:06:24,030 --> 00:06:30,270
and plausible so plausible corresponds

136
00:06:27,480 --> 00:06:32,430
to the impossibility aspect from the

137
00:06:30,270 --> 00:06:35,370
image domain when we create their

138
00:06:32,430 --> 00:06:38,610
reversal examples we do not want to see

139
00:06:35,370 --> 00:06:40,920
data and it was a real example so that's

140
00:06:38,610 --> 00:06:44,220
why we do not simply copy junk code from

141
00:06:40,920 --> 00:06:47,910
the target developer or use unusual

142
00:06:44,220 --> 00:06:49,389
syntax we could for instance hide some

143
00:06:47,910 --> 00:06:52,139
arbitrary letters and

144
00:06:49,389 --> 00:06:53,949
until we get the wanted classification

145
00:06:52,139 --> 00:06:57,639
Malthus would not be a very

146
00:06:53,949 --> 00:07:00,219
sophisticated attack because we can

147
00:06:57,639 --> 00:07:02,530
imagine that it's easy to detect and we

148
00:07:00,219 --> 00:07:06,039
can easily remove code that is never

149
00:07:02,530 --> 00:07:08,919
used and comments are also quite easy to

150
00:07:06,039 --> 00:07:12,159
ignore by the classifier or when we

151
00:07:08,919 --> 00:07:14,530
build features and last but not least we

152
00:07:12,159 --> 00:07:17,080
do not consider layout features they are

153
00:07:14,530 --> 00:07:18,909
not robust they can be easily normalized

154
00:07:17,080 --> 00:07:22,659
through code formatting and even worse

155
00:07:18,909 --> 00:07:25,539
they are easily too many palade and in

156
00:07:22,659 --> 00:07:28,150
this way we evaluate our untack and are

157
00:07:25,539 --> 00:07:31,060
even more difficult scenario because we

158
00:07:28,150 --> 00:07:33,068
do not change layout features so we have

159
00:07:31,060 --> 00:07:37,020
to change the more advanced features

160
00:07:33,069 --> 00:07:39,879
like a lexical and syntactic features

161
00:07:37,020 --> 00:07:42,068
from an adverse alerting perspective we

162
00:07:39,879 --> 00:07:45,789
have a quite challenging situation here

163
00:07:42,069 --> 00:07:49,650
which is different to image domain which

164
00:07:45,789 --> 00:07:52,599
get a lot of which is getting a lot of

165
00:07:49,650 --> 00:07:55,000
attention so we operate in a problem

166
00:07:52,599 --> 00:07:57,610
space this is the real world with our

167
00:07:55,000 --> 00:07:59,379
source code and the classic a

168
00:07:57,610 --> 00:08:03,430
classification happens in the feature

169
00:07:59,379 --> 00:08:05,259
space so if we have a target point in a

170
00:08:03,430 --> 00:08:06,569
feature space the exact position to get

171
00:08:05,259 --> 00:08:09,729
there is actually not really

172
00:08:06,569 --> 00:08:11,770
controllable this is because we have a

173
00:08:09,729 --> 00:08:14,650
problem of feature correlation even if I

174
00:08:11,770 --> 00:08:16,810
could change one feature the tf-idf

175
00:08:14,650 --> 00:08:19,359
waiting as a normalization across the

176
00:08:16,810 --> 00:08:21,960
dimensions and would distribute this

177
00:08:19,360 --> 00:08:26,229
change over all other dimensions and

178
00:08:21,960 --> 00:08:28,599
second we observed multiple times that

179
00:08:26,229 --> 00:08:32,519
even if we wanted to change one feature

180
00:08:28,599 --> 00:08:35,289
value other feature values automatically

181
00:08:32,519 --> 00:08:37,328
decreased so we wanted to increase the

182
00:08:35,289 --> 00:08:40,448
value of one feature other values

183
00:08:37,328 --> 00:08:43,630
decreased automatically and this is

184
00:08:40,448 --> 00:08:46,540
coupled with another group of problems

185
00:08:43,630 --> 00:08:50,019
so we have two main restrictions when I

186
00:08:46,540 --> 00:08:52,180
want to change in too long for instance

187
00:08:50,019 --> 00:08:56,230
I may have to change all the printf

188
00:08:52,180 --> 00:08:59,050
commands where it is used so each tiny

189
00:08:56,230 --> 00:09:01,480
change needs to consider the problem

190
00:08:59,050 --> 00:09:02,410
space validity so at the source code

191
00:09:01,480 --> 00:09:05,019
should

192
00:09:02,410 --> 00:09:08,079
be compatible and the smaller smallest

193
00:09:05,019 --> 00:09:10,990
possible change in the problem space may

194
00:09:08,079 --> 00:09:13,810
already impact multiple features in the

195
00:09:10,990 --> 00:09:16,449
feature space and firt we cannot control

196
00:09:13,810 --> 00:09:18,399
the amount of changes so even if I

197
00:09:16,449 --> 00:09:21,939
wanted to change the feature value just

198
00:09:18,399 --> 00:09:23,920
by one or two maybe it is not possible

199
00:09:21,939 --> 00:09:27,099
because of the problem our problem space

200
00:09:23,920 --> 00:09:29,709
dictates that we you cannot change it by

201
00:09:27,100 --> 00:09:35,730
one you have to change the value by

202
00:09:29,709 --> 00:09:38,500
three or four yes so next the beach

203
00:09:35,730 --> 00:09:40,149
feature map is not bijective so the

204
00:09:38,500 --> 00:09:43,870
other way round if we have a feature

205
00:09:40,149 --> 00:09:45,819
point it is not possible to find a valid

206
00:09:43,870 --> 00:09:48,790
source code with exactly these features

207
00:09:45,819 --> 00:09:50,500
in general at peace so if it's dilemma

208
00:09:48,790 --> 00:09:53,649
is also relevant in other discreet

209
00:09:50,500 --> 00:09:58,810
domains and I think it has not received

210
00:09:53,649 --> 00:10:00,730
as much attention as it should before to

211
00:09:58,810 --> 00:10:02,649
tackle this problem and to fulfill our

212
00:10:00,730 --> 00:10:05,439
constraints we use the following

213
00:10:02,649 --> 00:10:08,470
strategy which is also shown by the

214
00:10:05,439 --> 00:10:10,240
figure by the way we implement the code

215
00:10:08,470 --> 00:10:12,459
transformations we implement code

216
00:10:10,240 --> 00:10:14,139
transformations in the province base so

217
00:10:12,459 --> 00:10:17,290
we can move there we can modify the

218
00:10:14,139 --> 00:10:20,500
source code and these movements are

219
00:10:17,290 --> 00:10:22,389
guided by Monte Carlo tree search from a

220
00:10:20,500 --> 00:10:27,250
feature space that helps us what

221
00:10:22,389 --> 00:10:29,319
sequences or movements we should take so

222
00:10:27,250 --> 00:10:31,180
in particular we implemented 36 code

223
00:10:29,319 --> 00:10:34,000
transformations with flip tooling of a

224
00:10:31,180 --> 00:10:36,729
compiler front and claireaussi line and

225
00:10:34,000 --> 00:10:39,759
we used multiple program representations

226
00:10:36,730 --> 00:10:42,279
such as the abstract syntax tree or of a

227
00:10:39,759 --> 00:10:44,380
control flow graph and using the

228
00:10:42,279 --> 00:10:46,120
compiler here is definitely the way to

229
00:10:44,380 --> 00:10:49,509
go and not to implement some own

230
00:10:46,120 --> 00:10:52,180
solution because we can get a valid and

231
00:10:49,509 --> 00:10:55,089
full view on the source code let me

232
00:10:52,180 --> 00:10:59,079
explain that with an example so we see

233
00:10:55,089 --> 00:11:02,290
an API transformation to replace C out

234
00:10:59,079 --> 00:11:04,660
by printf with printf to this end we use

235
00:11:02,290 --> 00:11:07,089
the control flow graph first to find out

236
00:11:04,660 --> 00:11:10,959
the position of C out command before

237
00:11:07,089 --> 00:11:13,149
this is relevant when we want to print

238
00:11:10,959 --> 00:11:14,739
floating point values for instance so we

239
00:11:13,149 --> 00:11:17,230
set position 10 to Phi

240
00:11:14,740 --> 00:11:20,050
how many zeros or how many values we

241
00:11:17,230 --> 00:11:23,230
print and then in the second step we use

242
00:11:20,050 --> 00:11:26,620
the ast to find out the final data type

243
00:11:23,230 --> 00:11:31,149
of each entry and the C out command to

244
00:11:26,620 --> 00:11:32,800
create the necessary printf string to

245
00:11:31,149 --> 00:11:34,839
guide this transformation we interpret

246
00:11:32,800 --> 00:11:38,459
the advert or example generation as a

247
00:11:34,839 --> 00:11:40,990
game and use Monte Carlo tree search

248
00:11:38,459 --> 00:11:43,569
which some of you may know because

249
00:11:40,990 --> 00:11:46,180
alphago used it successfully I won't go

250
00:11:43,570 --> 00:11:48,459
into the details of this algorithm but

251
00:11:46,180 --> 00:11:50,620
in a nutshell we create a search tree

252
00:11:48,459 --> 00:11:53,260
where each node corresponds to some

253
00:11:50,620 --> 00:11:55,839
state of a source code and each edge to

254
00:11:53,260 --> 00:11:58,420
a code transformation and we evaluate

255
00:11:55,839 --> 00:12:01,510
multiple paths and in this way we can

256
00:11:58,420 --> 00:12:04,300
evaluate the impact of different code

257
00:12:01,510 --> 00:12:06,339
transformations so we evaluate different

258
00:12:04,300 --> 00:12:09,099
transformations so we get a search tree

259
00:12:06,339 --> 00:12:11,980
and then based on these information

260
00:12:09,100 --> 00:12:15,790
misinformation we decide on the next

261
00:12:11,980 --> 00:12:18,850
move to evaluate our attack we consider

262
00:12:15,790 --> 00:12:21,189
two state-of-the-art methods from Calais

263
00:12:18,850 --> 00:12:24,339
Canada Island a Bahamut a time the first

264
00:12:21,190 --> 00:12:26,140
method uses a random forest and actually

265
00:12:24,339 --> 00:12:28,959
layout lexical and syntactic features

266
00:12:26,140 --> 00:12:31,089
but as I said we do not consider layout

267
00:12:28,959 --> 00:12:35,560
features because it would make our

268
00:12:31,089 --> 00:12:38,829
attack even easier and the second method

269
00:12:35,560 --> 00:12:40,869
uses just lexical features and a

270
00:12:38,829 --> 00:12:44,739
recurrent neural network in particular

271
00:12:40,870 --> 00:12:47,680
in lsdm here we use the same setup as

272
00:12:44,740 --> 00:12:50,170
both works and we use C++ sprites from

273
00:12:47,680 --> 00:12:52,420
the Google coach am the benefit from

274
00:12:50,170 --> 00:12:54,640
this dataset is that we have offers

275
00:12:52,420 --> 00:12:57,579
which have solved the same problems

276
00:12:54,640 --> 00:12:59,910
those of the same challenges and so we

277
00:12:57,579 --> 00:13:03,219
can learn coding style rather than

278
00:12:59,910 --> 00:13:06,760
problems and our data that consists of

279
00:13:03,220 --> 00:13:10,000
204 offers which have solved the same

280
00:13:06,760 --> 00:13:11,319
eight challenges and finally we use a

281
00:13:10,000 --> 00:13:13,630
stratified and group k-fold

282
00:13:11,320 --> 00:13:15,520
cross-validation where we use seven

283
00:13:13,630 --> 00:13:18,790
challenges for training and one for

284
00:13:15,520 --> 00:13:21,189
testing and the attack so our results

285
00:13:18,790 --> 00:13:24,040
are that in our targeted scenario number

286
00:13:21,190 --> 00:13:26,290
one target scenario we can prevent the

287
00:13:24,040 --> 00:13:29,160
correct attribution for both methods in

288
00:13:26,290 --> 00:13:32,079
almost all cases

289
00:13:29,160 --> 00:13:34,329
while at the same time we only change

290
00:13:32,080 --> 00:13:37,780
one to five lines of code and they've

291
00:13:34,330 --> 00:13:40,720
been in the majority of cases an average

292
00:13:37,780 --> 00:13:43,000
each file has 74 lines of code so this

293
00:13:40,720 --> 00:13:46,300
underlines the very targeted nature of

294
00:13:43,000 --> 00:13:48,130
our transformations in the target

295
00:13:46,300 --> 00:13:51,579
scenario where we want to impersonate

296
00:13:48,130 --> 00:13:54,310
another developer we can impersonate

297
00:13:51,580 --> 00:13:56,500
three or four developers for both

298
00:13:54,310 --> 00:14:00,130
methods and approached by apartment

299
00:13:56,500 --> 00:14:03,550
Arliss is slightly easier to fool center

300
00:14:00,130 --> 00:14:07,030
rests only on lexical features and these

301
00:14:03,550 --> 00:14:08,949
are for example declarations or type def

302
00:14:07,030 --> 00:14:12,790
declarations and so on and they can be

303
00:14:08,950 --> 00:14:15,970
easily or there can be manipulated a

304
00:14:12,790 --> 00:14:17,860
little bit easier so if we take a closer

305
00:14:15,970 --> 00:14:20,860
look at the target attack we can see

306
00:14:17,860 --> 00:14:22,900
that around 50% of the features modified

307
00:14:20,860 --> 00:14:26,230
for Callie's Canada are and this shows

308
00:14:22,900 --> 00:14:29,290
how this an alliance of a feature

309
00:14:26,230 --> 00:14:33,220
correlation problem we have we had to

310
00:14:29,290 --> 00:14:36,099
solve it is around 18% for AB mat and aa

311
00:14:33,220 --> 00:14:38,440
on average this is because their

312
00:14:36,100 --> 00:14:41,620
approach has a more dense vector and if

313
00:14:38,440 --> 00:14:45,100
a feature is 0 it remains zero even

314
00:14:41,620 --> 00:14:48,040
after changing the source code and at

315
00:14:45,100 --> 00:14:50,080
the same time our final source code

316
00:14:48,040 --> 00:14:52,870
again we have very targeted changes

317
00:14:50,080 --> 00:14:58,350
around one to ten lines of code that are

318
00:14:52,870 --> 00:15:00,940
added modified or removed so if we

319
00:14:58,350 --> 00:15:02,890
here's a real-world example from our

320
00:15:00,940 --> 00:15:05,680
evaluation and we can see that we do not

321
00:15:02,890 --> 00:15:09,819
just add impossible garbage to the code

322
00:15:05,680 --> 00:15:12,760
but the code remains quite normal

323
00:15:09,820 --> 00:15:14,110
so normal as it can be for C++ at least

324
00:15:12,760 --> 00:15:16,630
to my mind

325
00:15:14,110 --> 00:15:21,430
in the first step for example we add

326
00:15:16,630 --> 00:15:25,450
some type tabs to mimic behavior from

327
00:15:21,430 --> 00:15:28,750
some developer who prefers type test and

328
00:15:25,450 --> 00:15:32,680
then we also replaced a for block by a

329
00:15:28,750 --> 00:15:37,710
while loop and we changed the output API

330
00:15:32,680 --> 00:15:40,750
and yeah so it really showed that the

331
00:15:37,710 --> 00:15:41,320
resulting virtual example is still a

332
00:15:40,750 --> 00:15:45,400
norm

333
00:15:41,320 --> 00:15:49,510
source code but now it is classified as

334
00:15:45,400 --> 00:15:52,329
another developer we wanted to have so

335
00:15:49,510 --> 00:15:53,920
to summarize the main takeaways we have

336
00:15:52,330 --> 00:15:55,840
seen how to perform a blackbox

337
00:15:53,920 --> 00:15:58,990
attack against authorship attribution

338
00:15:55,840 --> 00:16:01,480
with realistic constraints second we

339
00:15:58,990 --> 00:16:03,340
considered the problems feature space

340
00:16:01,480 --> 00:16:05,080
dilemma we have seen the unique

341
00:16:03,340 --> 00:16:07,720
challenges of adversity learning and

342
00:16:05,080 --> 00:16:11,320
discrete domain and here the source code

343
00:16:07,720 --> 00:16:14,620
we introduced Monte Carlo tree search

344
00:16:11,320 --> 00:16:16,840
and the nice thing this approach the

345
00:16:14,620 --> 00:16:19,060
Monte Carlo tree search does not depend

346
00:16:16,840 --> 00:16:22,150
on the learning algorithm so it can also

347
00:16:19,060 --> 00:16:25,000
be for random forests and this relieves

348
00:16:22,150 --> 00:16:27,910
us from a burden to learn some other

349
00:16:25,000 --> 00:16:29,860
learning algorithm to you some other

350
00:16:27,910 --> 00:16:33,730
learning algorithms such a deep neural

351
00:16:29,860 --> 00:16:36,190
network to as a substitute model and

352
00:16:33,730 --> 00:16:37,840
then to hope that our advert will

353
00:16:36,190 --> 00:16:41,980
examples from a deep neural network

354
00:16:37,840 --> 00:16:43,810
transfer to random forests so here we

355
00:16:41,980 --> 00:16:46,990
can directly attack the random forests

356
00:16:43,810 --> 00:16:49,810
and yeah the approach is quite generic

357
00:16:46,990 --> 00:16:53,590
so it's also applicable to other domains

358
00:16:49,810 --> 00:16:57,609
such as text or PDF malware and so on

359
00:16:53,590 --> 00:17:00,130
and yeah so one thing maybe just to

360
00:16:57,610 --> 00:17:02,320
conclude my talk one takeaway should be

361
00:17:00,130 --> 00:17:05,770
that our paper is not only introducing

362
00:17:02,320 --> 00:17:09,699
another adverse or example problem now

363
00:17:05,770 --> 00:17:11,500
for source code but we had quite some

364
00:17:09,699 --> 00:17:14,320
wet some quite challenges to solve

365
00:17:11,500 --> 00:17:19,209
because we have a discrete domain here

366
00:17:14,319 --> 00:17:22,149
with some constraints and so we created

367
00:17:19,209 --> 00:17:26,050
we gained some new insights how to gray

368
00:17:22,150 --> 00:17:28,840
create adversely examples in some

369
00:17:26,050 --> 00:17:31,149
complicated domains and yeah finally we

370
00:17:28,840 --> 00:17:32,709
performed a large-scale study and we

371
00:17:31,150 --> 00:17:35,770
concluded that current attribution

372
00:17:32,710 --> 00:17:37,480
methods are not secure and we need novel

373
00:17:35,770 --> 00:17:39,070
methods for authorship attribution so

374
00:17:37,480 --> 00:17:40,610
thank you very much for your attention

375
00:17:39,070 --> 00:17:46,549
and questions

376
00:17:40,610 --> 00:17:49,199
[Applause]

377
00:17:46,549 --> 00:17:51,750
thank you for the great talk my

378
00:17:49,200 --> 00:17:53,429
questions in the backpack setting how

379
00:17:51,750 --> 00:17:58,320
many queries do you make to the model

380
00:17:53,429 --> 00:18:00,600
like the target model yeah we so if you

381
00:17:58,320 --> 00:18:05,279
create the search tree the Monte Carlo

382
00:18:00,600 --> 00:18:09,840
tree search then you need for each yeah

383
00:18:05,279 --> 00:18:11,970
let me explain that so you can we create

384
00:18:09,840 --> 00:18:14,490
sequences of transformations so we do

385
00:18:11,970 --> 00:18:16,289
not change the source code by one

386
00:18:14,490 --> 00:18:18,450
transformation and then put it to the

387
00:18:16,289 --> 00:18:22,580
method and retrieve the score but we

388
00:18:18,450 --> 00:18:22,580
create we perform five or ten

389
00:18:22,669 --> 00:18:28,679
modifications and then we put it to the

390
00:18:24,890 --> 00:18:31,649
method and I think around one to three

391
00:18:28,679 --> 00:18:35,669
hundred cards are necessary for natural

392
00:18:31,649 --> 00:18:40,668
example okay so it's not as much but not

393
00:18:35,669 --> 00:18:43,260
so much but yeah yeah ok thank you ok

394
00:18:40,669 --> 00:18:45,240
choke reset and why you really I'm

395
00:18:43,260 --> 00:18:45,720
excited that you did this work thank you

396
00:18:45,240 --> 00:18:48,779
very much

397
00:18:45,720 --> 00:18:50,760
and but I have a question about like so

398
00:18:48,779 --> 00:18:53,700
adversarial examples in the image domain

399
00:18:50,760 --> 00:18:55,860
right when you transform a panda to like

400
00:18:53,700 --> 00:18:57,630
to be recognized as a Gibbon but humans

401
00:18:55,860 --> 00:19:00,000
would still obviously recognize it as a

402
00:18:57,630 --> 00:19:01,919
panda so my question is here is that

403
00:19:00,000 --> 00:19:03,570
when you actually go through these Co

404
00:19:01,919 --> 00:19:06,029
transformations what the like the

405
00:19:03,570 --> 00:19:08,189
original algorithms were recognizing was

406
00:19:06,029 --> 00:19:10,320
the like the style of a particular

407
00:19:08,190 --> 00:19:11,909
program have you transformed the code to

408
00:19:10,320 --> 00:19:14,850
be in the style of the original

409
00:19:11,909 --> 00:19:17,490
programmer or would like a human or some

410
00:19:14,850 --> 00:19:20,250
other analysis actually think that it

411
00:19:17,490 --> 00:19:22,200
was in the original style so is it sort

412
00:19:20,250 --> 00:19:23,669
of a different qualitative class of

413
00:19:22,200 --> 00:19:25,620
adversarial example than the type of

414
00:19:23,669 --> 00:19:27,899
adversarial example where sort of the

415
00:19:25,620 --> 00:19:28,408
human is fold in one way but the you see

416
00:19:27,899 --> 00:19:33,570
what I mean

417
00:19:28,409 --> 00:19:35,960
yeah I hope yeah yeah so actually we

418
00:19:33,570 --> 00:19:40,200
stopped the attack when the classifier

419
00:19:35,960 --> 00:19:43,980
classified by our developer so we would

420
00:19:40,200 --> 00:19:47,370
have to continue our attack until we can

421
00:19:43,980 --> 00:19:49,289
be of course clearly sure that we

422
00:19:47,370 --> 00:19:52,939
completely transferred the stylistic

423
00:19:49,289 --> 00:19:52,940
patterns from one developer to the other

424
00:19:53,029 --> 00:19:58,770
that

425
00:19:54,810 --> 00:20:04,409
yeah if you if your method changes the

426
00:19:58,770 --> 00:20:08,850
features and so on of course maybe there

427
00:20:04,410 --> 00:20:11,160
are some of course we have not changed

428
00:20:08,850 --> 00:20:13,620
all traces from the original developer

429
00:20:11,160 --> 00:20:18,210
so there are still but it still seems a

430
00:20:13,620 --> 00:20:19,979
little different so yeah yeah so just as

431
00:20:18,210 --> 00:20:24,420
a follow-up I think Rachel that I think

432
00:20:19,980 --> 00:20:26,460
the analogy here is that the the analogy

433
00:20:24,420 --> 00:20:29,850
would be that the transformation should

434
00:20:26,460 --> 00:20:31,680
preserve the functionality right anyway

435
00:20:29,850 --> 00:20:33,929
my question is I think it's a little

436
00:20:31,680 --> 00:20:37,140
different what rachel was asking is

437
00:20:33,930 --> 00:20:39,120
whether the adversarial example that you

438
00:20:37,140 --> 00:20:41,520
produced if you showed it to a human

439
00:20:39,120 --> 00:20:44,370
they would identified as the person that

440
00:20:41,520 --> 00:20:46,740
you targeted or they would still

441
00:20:44,370 --> 00:20:50,280
identify it as being from the original

442
00:20:46,740 --> 00:20:53,010
author happiness if you showed to human

443
00:20:50,280 --> 00:20:55,680
I'm not sure what he would I don't think

444
00:20:53,010 --> 00:20:58,440
he could actually identify anything so

445
00:20:55,680 --> 00:21:00,870
these stylistic patterns are somewhere

446
00:20:58,440 --> 00:21:06,060
hidden and a lot of features in the

447
00:21:00,870 --> 00:21:08,219
combination but of course when I looked

448
00:21:06,060 --> 00:21:10,409
at my adversely examples sometimes I

449
00:21:08,220 --> 00:21:12,840
thought okay it's a little bit it's

450
00:21:10,410 --> 00:21:15,630
fooling the classifier just because I

451
00:21:12,840 --> 00:21:18,810
see some characteristics of original

452
00:21:15,630 --> 00:21:20,100
classifier developer but sometimes when

453
00:21:18,810 --> 00:21:22,560
we performed a lot of code

454
00:21:20,100 --> 00:21:26,000
transformations so 30 or 40 controls

455
00:21:22,560 --> 00:21:28,470
meant actually we had mimicked the

456
00:21:26,000 --> 00:21:30,120
coding style from a target developer and

457
00:21:28,470 --> 00:21:32,760
I could not say if it's really the

458
00:21:30,120 --> 00:21:35,669
target developer or that was an example

459
00:21:32,760 --> 00:21:38,160
so it also fooled me yeah maybe one

460
00:21:35,670 --> 00:21:40,550
suggestion to look into this would be to

461
00:21:38,160 --> 00:21:43,350
use the same algorithm for a different

462
00:21:40,550 --> 00:21:48,800
problem where you would have an easier

463
00:21:43,350 --> 00:21:50,790
time of telling what the crowd truth so

464
00:21:48,800 --> 00:21:51,810
this is a great talk to the two

465
00:21:50,790 --> 00:21:55,620
dimitra's from the University of

466
00:21:51,810 --> 00:21:57,750
Maryland so I mean in adversarial

467
00:21:55,620 --> 00:21:59,850
examples people often you know talk

468
00:21:57,750 --> 00:22:01,440
about robust features are there robust

469
00:21:59,850 --> 00:22:02,389
features and what are the robust

470
00:22:01,440 --> 00:22:06,230
features and

471
00:22:02,390 --> 00:22:09,380
all that so in this problem authorship

472
00:22:06,230 --> 00:22:13,160
attribution do you think there are any

473
00:22:09,380 --> 00:22:16,520
robust features yes this is actually I

474
00:22:13,160 --> 00:22:20,000
think the most important question after

475
00:22:16,520 --> 00:22:22,550
now presenting the paper because we

476
00:22:20,000 --> 00:22:24,800
created bad hack and now I think

477
00:22:22,550 --> 00:22:27,550
researchers can create this useless

478
00:22:24,800 --> 00:22:30,800
automatic attack this I think one of the

479
00:22:27,550 --> 00:22:34,490
most important advantages we can run the

480
00:22:30,800 --> 00:22:37,940
attack automatically and the features

481
00:22:34,490 --> 00:22:40,730
we've changed were or I think a robust

482
00:22:37,940 --> 00:22:43,250
feature should capture how we solve a

483
00:22:40,730 --> 00:22:46,160
problem I think this would be a robust

484
00:22:43,250 --> 00:22:47,480
feature because we cannot automatically

485
00:22:46,160 --> 00:22:50,480
change something

486
00:22:47,480 --> 00:22:53,420
for instance and think about how we

487
00:22:50,480 --> 00:22:55,880
solve a sorting problem some of you

488
00:22:53,420 --> 00:22:58,400
would use bubbles or some of your

489
00:22:55,880 --> 00:23:01,100
quicksort some of you their own I went

490
00:22:58,400 --> 00:23:03,830
so this mimics how how we think about

491
00:23:01,100 --> 00:23:07,010
how to solve the problem and I think

492
00:23:03,830 --> 00:23:09,169
this is not really this cannot be

493
00:23:07,010 --> 00:23:11,810
automated of course a human being there

494
00:23:09,170 --> 00:23:15,460
was some study about that I think people

495
00:23:11,810 --> 00:23:19,159
will always be able somehow to

496
00:23:15,460 --> 00:23:20,720
understand how you code but it will be

497
00:23:19,160 --> 00:23:23,450
much more difficult and I think this

498
00:23:20,720 --> 00:23:26,390
would be a robust feature so we should

499
00:23:23,450 --> 00:23:30,170
maybe look at the control for graph how

500
00:23:26,390 --> 00:23:34,820
we solve problems and then maybe we can

501
00:23:30,170 --> 00:23:38,270
develop robust features but I think we

502
00:23:34,820 --> 00:23:40,340
should not try to make our classifiers

503
00:23:38,270 --> 00:23:43,490
somehow more robust but we should more

504
00:23:40,340 --> 00:23:49,060
look at the features to prevent these

505
00:23:43,490 --> 00:23:49,060
attacks one last question

506
00:23:49,090 --> 00:23:53,870
Vinny Monaco Naval Postgraduate School

507
00:23:51,410 --> 00:23:56,870
thank you for the talk so there's this

508
00:23:53,870 --> 00:23:58,969
idea in biometrics that some users are

509
00:23:56,870 --> 00:24:01,399
more difficult to identify than others

510
00:23:58,970 --> 00:24:03,440
that the biometrics Menagerie did you

511
00:24:01,400 --> 00:24:05,300
see the same kind of phenomenon here

512
00:24:03,440 --> 00:24:08,780
where some coders were more difficult to

513
00:24:05,300 --> 00:24:13,020
spoof or some difficult to modify yeah

514
00:24:08,780 --> 00:24:16,418
definitely so some people you

515
00:24:13,020 --> 00:24:19,539
for instance if a developer always used

516
00:24:16,419 --> 00:24:23,410
some simple type deaths it was quite

517
00:24:19,539 --> 00:24:27,600
easy to impersonate this person but

518
00:24:23,410 --> 00:24:32,140
others had a very similar code to other

519
00:24:27,600 --> 00:24:37,750
developers and then it was much more

520
00:24:32,140 --> 00:24:38,830
challenging to our let's make it or yes

521
00:24:37,750 --> 00:24:41,049
it was

522
00:24:38,830 --> 00:24:43,889
there were developers that was that were

523
00:24:41,049 --> 00:24:47,910
harder to impersonate and others not

524
00:24:43,890 --> 00:24:53,269
let's thank the speaker again

525
00:24:47,910 --> 00:24:53,269
[Applause]

