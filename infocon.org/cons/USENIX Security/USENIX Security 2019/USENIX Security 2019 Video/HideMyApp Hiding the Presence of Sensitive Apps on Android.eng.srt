1
00:00:10,210 --> 00:00:15,400
so hello everyone so I will be talking

2
00:00:13,030 --> 00:00:17,700
about hi my app a system for hiding the

3
00:00:15,400 --> 00:00:21,520
presence of sensitive paths on Android

4
00:00:17,700 --> 00:00:22,930
so my name is and I'm working at a big

5
00:00:21,520 --> 00:00:25,180
corporate research in Switzerland and

6
00:00:22,930 --> 00:00:28,180
the work was done when I was a PhD

7
00:00:25,180 --> 00:00:31,869
student at EPFL in collaborations with

8
00:00:28,180 --> 00:00:35,019
my colleagues at EPFL the university of

9
00:00:31,869 --> 00:00:36,550
padova and university of lausanne so

10
00:00:35,020 --> 00:00:38,770
from the title of the talk you might

11
00:00:36,550 --> 00:00:41,349
wonder why we need to hire certain apps

12
00:00:38,770 --> 00:00:44,680
right so let me give you a concrete news

13
00:00:41,350 --> 00:00:47,440
case so I'm sure you all have heard

14
00:00:44,680 --> 00:00:49,780
about em health or mobile health the use

15
00:00:47,440 --> 00:00:52,000
of mobile apps and possibly with

16
00:00:49,780 --> 00:00:54,640
external devices for wellness and

17
00:00:52,000 --> 00:00:56,950
medical purposes and they're collected

18
00:00:54,640 --> 00:00:59,800
metal medical apps might be sent to a

19
00:00:56,950 --> 00:01:01,660
remote hospital or medical doctor for

20
00:00:59,800 --> 00:01:04,720
continuous monitoring of the user's

21
00:01:01,660 --> 00:01:06,580
medical conditions so such apps are

22
00:01:04,720 --> 00:01:09,250
increasingly popular and given the

23
00:01:06,580 --> 00:01:10,869
sensitivity of medical data security and

24
00:01:09,250 --> 00:01:14,020
privacy has been one of the main

25
00:01:10,869 --> 00:01:15,850
challenges in M health but there is a

26
00:01:14,020 --> 00:01:18,729
privacy problem that has been overlooked

27
00:01:15,850 --> 00:01:20,770
in the context of M health so the

28
00:01:18,729 --> 00:01:23,890
problem is due to the fact that on

29
00:01:20,770 --> 00:01:26,770
Android any app even without permission

30
00:01:23,890 --> 00:01:28,720
can easily fingerprint other apps they

31
00:01:26,770 --> 00:01:31,750
can even collect the entire list of

32
00:01:28,720 --> 00:01:34,330
installed apps on the device and in the

33
00:01:31,750 --> 00:01:36,460
context of M health the presence of an

34
00:01:34,330 --> 00:01:38,650
app might already pre-built sensitive

35
00:01:36,460 --> 00:01:40,689
information about the users so for

36
00:01:38,650 --> 00:01:42,189
example if you have diabeetus app it

37
00:01:40,689 --> 00:01:46,330
probably tells the fact that you have

38
00:01:42,189 --> 00:01:47,889
diabetes so consequently any app on an

39
00:01:46,330 --> 00:01:50,080
Android phone can know the medical

40
00:01:47,890 --> 00:01:52,150
conditions of the users and this

41
00:01:50,080 --> 00:01:54,789
information is sensitive and it can be

42
00:01:52,150 --> 00:01:58,390
used to profile to discriminate or even

43
00:01:54,790 --> 00:02:00,280
to blackmail the users right so even the

44
00:01:58,390 --> 00:02:02,409
severity of the problem we started this

45
00:02:00,280 --> 00:02:05,530
project which aims answers the following

46
00:02:02,409 --> 00:02:07,930
questions so first how fingerprint of

47
00:02:05,530 --> 00:02:09,970
our Android apps in other words what are

48
00:02:07,930 --> 00:02:10,750
the techniques that an app can use

49
00:02:09,970 --> 00:02:15,220
fingerprint

50
00:02:10,750 --> 00:02:17,170
other is the apps second new apps try to

51
00:02:15,220 --> 00:02:20,440
fingerprint other apps and if they do

52
00:02:17,170 --> 00:02:22,299
then for what purposes and third looking

53
00:02:20,440 --> 00:02:24,550
into existing solutions with

54
00:02:22,300 --> 00:02:27,430
find an effective solution and therefore

55
00:02:24,550 --> 00:02:29,110
we propose hi my app the first solution

56
00:02:27,430 --> 00:02:32,260
for hiding the presence of sensitive

57
00:02:29,110 --> 00:02:33,910
apps on Android so in the rest of the

58
00:02:32,260 --> 00:02:36,310
talk I'm going to walk you through the

59
00:02:33,910 --> 00:02:40,240
answers of these questions briefly of

60
00:02:36,310 --> 00:02:44,350
course and let me start off with the

61
00:02:40,240 --> 00:02:46,630
fingerprint ability of apps so as you

62
00:02:44,350 --> 00:02:48,519
probably know an Android app interacts

63
00:02:46,630 --> 00:02:51,070
with the underlying system system

64
00:02:48,520 --> 00:02:53,770
through the Java API and the shell

65
00:02:51,070 --> 00:02:56,760
commands and how much information an app

66
00:02:53,770 --> 00:02:59,430
can collect about other apps depends on

67
00:02:56,760 --> 00:03:01,840
their privileges and their permissions

68
00:02:59,430 --> 00:03:03,640
so I refer you to the paper for a

69
00:03:01,840 --> 00:03:06,850
complete analysis of the attack surface

70
00:03:03,640 --> 00:03:09,130
in this talk I will show you the

71
00:03:06,850 --> 00:03:11,620
information that an app with me for a

72
00:03:09,130 --> 00:03:14,680
privilege and without permissions can

73
00:03:11,620 --> 00:03:17,050
collect about other apps so the

74
00:03:14,680 --> 00:03:18,760
information is shown on the slide it

75
00:03:17,050 --> 00:03:20,800
consists of the core attributes of the

76
00:03:18,760 --> 00:03:23,410
apps and also the optional features as

77
00:03:20,800 --> 00:03:26,230
well in particular it includes the

78
00:03:23,410 --> 00:03:28,359
package names which uniquely identify

79
00:03:26,230 --> 00:03:29,679
the apps it also includes the

80
00:03:28,360 --> 00:03:31,780
information that can be used to

81
00:03:29,680 --> 00:03:34,209
fingerprint the apps so for example the

82
00:03:31,780 --> 00:03:36,250
names of the components of the apps or

83
00:03:34,209 --> 00:03:39,550
the permissions and the icons and the

84
00:03:36,250 --> 00:03:41,410
labels of the apps and so on so for its

85
00:03:39,550 --> 00:03:43,239
information shown on the slide there are

86
00:03:41,410 --> 00:03:46,329
multiple api's that can be used to

87
00:03:43,239 --> 00:03:49,030
retrieve it for example for the package

88
00:03:46,330 --> 00:03:52,720
name the package manager class provides

89
00:03:49,030 --> 00:03:54,610
two methods that directly return to the

90
00:03:52,720 --> 00:03:57,340
calling of the list of installed apps on

91
00:03:54,610 --> 00:03:59,230
the device so the two methods are get

92
00:03:57,340 --> 00:04:04,330
install applications and get install

93
00:03:59,230 --> 00:04:06,880
packages it also provides a dozen of API

94
00:04:04,330 --> 00:04:09,459
is to take a package name as input and

95
00:04:06,880 --> 00:04:12,459
return now if the package doesn't exist

96
00:04:09,459 --> 00:04:15,160
on the device and as a result these

97
00:04:12,459 --> 00:04:17,829
methods they can be used as an Oracle to

98
00:04:15,160 --> 00:04:21,519
learn if a particular app exists on the

99
00:04:17,829 --> 00:04:25,330
device so clearly the number of methods

100
00:04:21,519 --> 00:04:27,310
is numerous and therefore pre moving

101
00:04:25,330 --> 00:04:29,349
these methods so adding new permissions

102
00:04:27,310 --> 00:04:33,100
is not straightforward it's complicated

103
00:04:29,350 --> 00:04:35,409
right so given the ease of a

104
00:04:33,100 --> 00:04:36,699
fingerprinting attack

105
00:04:35,409 --> 00:04:39,580
surely the question that we asked

106
00:04:36,699 --> 00:04:41,169
ourselves is but there are new apps they

107
00:04:39,580 --> 00:04:43,839
make use of this capability to

108
00:04:41,169 --> 00:04:47,498
fingerprint other apps and to answer

109
00:04:43,839 --> 00:04:51,699
this question we collected 2917

110
00:04:47,499 --> 00:04:55,119
application packages from a popular you

111
00:04:51,699 --> 00:04:57,249
know apps from all 55f categories on the

112
00:04:55,119 --> 00:04:59,939
Google Play and then we perform static

113
00:04:57,249 --> 00:05:02,709
and dynamic analysis of these apps

114
00:04:59,939 --> 00:05:04,899
so in particular we focus on the two

115
00:05:02,709 --> 00:05:07,330
methods that directly return the list of

116
00:05:04,899 --> 00:05:09,039
install apps as I mentioned before get

117
00:05:07,330 --> 00:05:11,800
used to applications and get install

118
00:05:09,039 --> 00:05:14,019
packages and the reason is because these

119
00:05:11,800 --> 00:05:15,909
two methods clearly show the intention

120
00:05:14,019 --> 00:05:18,429
of the calling app to fingerprint other

121
00:05:15,909 --> 00:05:21,849
apps why other methods you can have

122
00:05:18,429 --> 00:05:23,409
valid news cases so consequently the

123
00:05:21,849 --> 00:05:25,119
results that I show you here can be

124
00:05:23,409 --> 00:05:27,659
considered a lower bound on the number

125
00:05:25,119 --> 00:05:33,009
of apps to try to fingerprint other apps

126
00:05:27,659 --> 00:05:35,139
okay so we found that 19.2% to 57% of

127
00:05:33,009 --> 00:05:37,209
apps query for the list of install apps

128
00:05:35,139 --> 00:05:40,119
and to put the number in perspective

129
00:05:37,209 --> 00:05:41,889
even the fact that on average the user

130
00:05:40,119 --> 00:05:44,679
has any apps installed on the device

131
00:05:41,889 --> 00:05:46,360
it's safe to assume that at least one

132
00:05:44,679 --> 00:05:48,878
app on the phone is trying to

133
00:05:46,360 --> 00:05:51,519
fingerprint other apps okay we also

134
00:05:48,879 --> 00:05:56,079
found that most of the queries come from

135
00:05:51,519 --> 00:05:58,749
third-party libraries and therefore that

136
00:05:56,079 --> 00:06:02,619
app developers they perhaps might not be

137
00:05:58,749 --> 00:06:06,729
aware of this activity our analysis on a

138
00:06:02,619 --> 00:06:08,709
small sample pay apps show that payoffs

139
00:06:06,729 --> 00:06:11,229
are less likely to query for the list of

140
00:06:08,709 --> 00:06:12,969
installs compared to free apps probably

141
00:06:11,229 --> 00:06:14,529
because they rely less on third-party

142
00:06:12,969 --> 00:06:18,789
libraries new to a different business

143
00:06:14,529 --> 00:06:21,209
model so I would like to emphasize of

144
00:06:18,789 --> 00:06:23,378
the fact that our analysis was done on

145
00:06:21,209 --> 00:06:25,329
popular apps with millions of

146
00:06:23,379 --> 00:06:27,789
installations and therefore we can say

147
00:06:25,329 --> 00:06:29,829
that the problems of apps fingerprinting

148
00:06:27,789 --> 00:06:33,759
other apps effects a significant number

149
00:06:29,829 --> 00:06:36,069
of users okay so according to Google

150
00:06:33,759 --> 00:06:38,289
Google's privacy policy guidelines a

151
00:06:36,069 --> 00:06:40,239
list of install app is personal

152
00:06:38,289 --> 00:06:42,938
information and therefore apps

153
00:06:40,239 --> 00:06:44,619
collecting such information have to

154
00:06:42,939 --> 00:06:46,779
provide users with a privacy policy

155
00:06:44,619 --> 00:06:48,189
stating the purpose of the collection of

156
00:06:46,779 --> 00:06:50,289
the list of install apps

157
00:06:48,189 --> 00:06:52,899
so the question that we asked our selves

158
00:06:50,289 --> 00:06:54,550
is to extend the app developers if

159
00:06:52,899 --> 00:06:57,669
follow the Google's privacy policy

160
00:06:54,550 --> 00:07:00,249
guideline so to answer this question we

161
00:06:57,669 --> 00:07:04,688
perform an analysis of privacy policies

162
00:07:00,249 --> 00:07:08,050
of apps in our dataset so form 2917

163
00:07:04,689 --> 00:07:11,439
application packages we collected 2499

164
00:07:08,050 --> 00:07:15,369
privacy policies and we found out of

165
00:07:11,439 --> 00:07:17,169
these privacy policies only 162 apps

166
00:07:15,369 --> 00:07:19,059
they inform the users about the

167
00:07:17,169 --> 00:07:24,219
collection of the lists of installs and

168
00:07:19,059 --> 00:07:26,050
out of these 162 apps 76 apps they

169
00:07:24,219 --> 00:07:28,839
consider a list of install app non

170
00:07:26,050 --> 00:07:30,369
personal information which is opposite

171
00:07:28,839 --> 00:07:33,819
of the Google's privacy policy

172
00:07:30,369 --> 00:07:35,349
guidelines but more importantly there

173
00:07:33,819 --> 00:07:38,019
are two questions that we would like to

174
00:07:35,349 --> 00:07:40,029
ask here the first question is why are

175
00:07:38,019 --> 00:07:41,559
the apps they didn't inform the users

176
00:07:40,029 --> 00:07:44,469
about the collection of the list of

177
00:07:41,559 --> 00:07:47,979
installs and second even if they did

178
00:07:44,469 --> 00:07:49,509
what the users read privacy policies so

179
00:07:47,979 --> 00:07:51,729
for the second question we know that

180
00:07:49,509 --> 00:07:54,490
it's a no as confirmed by previous works

181
00:07:51,729 --> 00:07:55,959
and also by our user study but for the

182
00:07:54,490 --> 00:07:57,969
first question I don't really have a

183
00:07:55,959 --> 00:08:00,879
clear answer it could be that the apps

184
00:07:57,969 --> 00:08:03,129
they collect Talisa install apps but

185
00:08:00,879 --> 00:08:05,050
they don't send the information out of

186
00:08:03,129 --> 00:08:08,289
the phone or it could be that the app

187
00:08:05,050 --> 00:08:10,269
developers they are not aware of this

188
00:08:08,289 --> 00:08:13,839
activity it could be as a reason that I

189
00:08:10,269 --> 00:08:15,789
don't know but clearly privacy policies

190
00:08:13,839 --> 00:08:17,860
are not a satisfactory solution to this

191
00:08:15,789 --> 00:08:20,349
problem and there is a need to have an

192
00:08:17,860 --> 00:08:25,419
effective solution to prevent this

193
00:08:20,349 --> 00:08:29,039
problem and so we propose hi my app the

194
00:08:25,419 --> 00:08:32,228
first system that enables organizations

195
00:08:29,039 --> 00:08:35,828
and developers to distribute apps to the

196
00:08:32,229 --> 00:08:38,500
users why considerably reducing the risk

197
00:08:35,828 --> 00:08:42,068
of such apps being fingerprinted by nosy

198
00:08:38,500 --> 00:08:44,560
apps on the same device so the scenario

199
00:08:42,068 --> 00:08:47,769
that we envision for high my app is as

200
00:08:44,560 --> 00:08:50,138
follows so a hospital consortium or

201
00:08:47,769 --> 00:08:52,839
hospital set up an app store where our

202
00:08:50,139 --> 00:08:56,230
developers working for the hospital they

203
00:08:52,839 --> 00:08:58,569
can publish the apps in order to enable

204
00:08:56,230 --> 00:09:00,460
the users to interact with the App Store

205
00:08:58,569 --> 00:09:02,800
for Act installation and up the

206
00:09:00,460 --> 00:09:04,750
it app store provides users with a

207
00:09:02,800 --> 00:09:07,030
client app called the manager app and

208
00:09:04,750 --> 00:09:09,100
through this manager app the user can

209
00:09:07,030 --> 00:09:12,280
launch the app so they have install from

210
00:09:09,100 --> 00:09:14,710
the app store we make the following

211
00:09:12,280 --> 00:09:16,360
across area sumption x' we assume that

212
00:09:14,710 --> 00:09:18,730
the app store and the manager are

213
00:09:16,360 --> 00:09:21,280
provided by the app store a trusted and

214
00:09:18,730 --> 00:09:25,120
they follow the program we assume there

215
00:09:21,280 --> 00:09:28,120
is a nosy app on the device but once you

216
00:09:25,120 --> 00:09:31,960
learn a specific app is installed on the

217
00:09:28,120 --> 00:09:35,350
device and by nosy I mean the app can

218
00:09:31,960 --> 00:09:37,870
have me for a privilege and it can have

219
00:09:35,350 --> 00:09:40,180
all possible dangerous permissions

220
00:09:37,870 --> 00:09:44,680
defined by Android so it is a typical

221
00:09:40,180 --> 00:09:47,530
capability of of Android apps so the

222
00:09:44,680 --> 00:09:51,819
very high-level overview of the solution

223
00:09:47,530 --> 00:09:54,670
is as follows when the user once install

224
00:09:51,820 --> 00:09:56,950
an EM health app she use the manager app

225
00:09:54,670 --> 00:10:01,420
to send an anonymous request to the app

226
00:09:56,950 --> 00:10:04,510
store in return instead of returning the

227
00:10:01,420 --> 00:10:06,579
EM health app to the user the apps are

228
00:10:04,510 --> 00:10:09,939
returned to the user a container app

229
00:10:06,580 --> 00:10:14,200
with a generic package name icon and

230
00:10:09,940 --> 00:10:17,140
label this container app is installed on

231
00:10:14,200 --> 00:10:19,900
the device and app runtime it launched

232
00:10:17,140 --> 00:10:22,870
the M health apk from within its

233
00:10:19,900 --> 00:10:25,150
conducts okay so in other words and

234
00:10:22,870 --> 00:10:30,190
health app is never registered in the

235
00:10:25,150 --> 00:10:32,800
operating system so now launching an apk

236
00:10:30,190 --> 00:10:35,620
from within the context of another is

237
00:10:32,800 --> 00:10:38,380
not a new idea its problem that is well

238
00:10:35,620 --> 00:10:41,980
study in previous works by using a

239
00:10:38,380 --> 00:10:43,180
technical at virtualization what I would

240
00:10:41,980 --> 00:10:45,310
like to say here is that a

241
00:10:43,180 --> 00:10:47,680
virtualization worse desire to solve a

242
00:10:45,310 --> 00:10:49,359
different problem in particular it used

243
00:10:47,680 --> 00:10:51,790
to solve the problem of sandboxing

244
00:10:49,360 --> 00:10:54,850
malicious apps hands different threat

245
00:10:51,790 --> 00:10:57,610
model and if in desire requirements and

246
00:10:54,850 --> 00:11:00,280
highly applying a virtualization to the

247
00:10:57,610 --> 00:11:02,980
problem of hiding app or still leak

248
00:11:00,280 --> 00:11:05,350
information about the sensitive apps so

249
00:11:02,980 --> 00:11:08,340
the leaked information can be static

250
00:11:05,350 --> 00:11:10,870
information and runtime information I

251
00:11:08,340 --> 00:11:13,180
refer you to the paper for a complete

252
00:11:10,870 --> 00:11:13,760
analysis of the information leakages and

253
00:11:13,180 --> 00:11:16,339
of

254
00:11:13,760 --> 00:11:24,920
stationed here I will just give you some

255
00:11:16,340 --> 00:11:27,950
example of the static information so as

256
00:11:24,920 --> 00:11:30,319
I mentioned before the Container app has

257
00:11:27,950 --> 00:11:33,380
a generic package name icon and label

258
00:11:30,320 --> 00:11:36,020
and my using app virtualization at

259
00:11:33,380 --> 00:11:38,720
runtime the container apps can load the

260
00:11:36,020 --> 00:11:41,569
resources of the EM health app in Health

261
00:11:38,720 --> 00:11:44,840
apk from the of the M health app from

262
00:11:41,570 --> 00:11:47,330
the M health apk at one time but app

263
00:11:44,840 --> 00:11:49,430
virtualization requires the container

264
00:11:47,330 --> 00:11:52,820
apps to be clear in their configuration

265
00:11:49,430 --> 00:11:56,030
files the components of the sensitive

266
00:11:52,820 --> 00:11:59,420
apps and as I mentioned before this

267
00:11:56,030 --> 00:12:01,730
information can be retrieved by public

268
00:11:59,420 --> 00:12:06,500
API s hands fingerprinting attacks and

269
00:12:01,730 --> 00:12:08,840
to prevent this problem in home AR the

270
00:12:06,500 --> 00:12:11,540
container apps declare only dummy

271
00:12:08,840 --> 00:12:13,700
components with randomized names and at

272
00:12:11,540 --> 00:12:15,260
runtime these dummy components are

273
00:12:13,700 --> 00:12:18,800
mapped to the rear components of the

274
00:12:15,260 --> 00:12:21,520
sensitive apps the nosy app Myers who

275
00:12:18,800 --> 00:12:26,630
tried to fingerprints the sensitive apps

276
00:12:21,520 --> 00:12:28,280
by using the metadata of the apps and to

277
00:12:26,630 --> 00:12:30,620
prevent this for example the themes of

278
00:12:28,280 --> 00:12:33,260
the apps and to prevent this problem I

279
00:12:30,620 --> 00:12:35,480
may have put in for the same themes for

280
00:12:33,260 --> 00:12:37,340
all the apps in the App Store so of

281
00:12:35,480 --> 00:12:38,660
course this will affect the look and

282
00:12:37,340 --> 00:12:42,200
feel of the app but is a straight up

283
00:12:38,660 --> 00:12:44,540
between privacy and usability and for

284
00:12:42,200 --> 00:12:46,490
permissions the container apps would

285
00:12:44,540 --> 00:12:49,189
need clear the union of the permissions

286
00:12:46,490 --> 00:12:51,530
nuclear by apps in the App Store but at

287
00:12:49,190 --> 00:12:53,060
runtime it no only prom the users for

288
00:12:51,530 --> 00:12:56,990
permissions that are actually needed by

289
00:12:53,060 --> 00:13:00,859
the M health app so in order to evaluate

290
00:12:56,990 --> 00:13:03,140
our solution we collect the 50 apps from

291
00:13:00,860 --> 00:13:05,870
the medical category on the Google Play

292
00:13:03,140 --> 00:13:08,300
and so we chose these apps based on

293
00:13:05,870 --> 00:13:11,030
their popularity their sensitivity and

294
00:13:08,300 --> 00:13:14,209
the functionality of the app so for

295
00:13:11,030 --> 00:13:16,220
example the wearer health manager is an

296
00:13:14,210 --> 00:13:19,340
app that connect to an external device

297
00:13:16,220 --> 00:13:21,920
via bluetooth to keep track of the blood

298
00:13:19,340 --> 00:13:25,010
pressure of the users and cancer.net is

299
00:13:21,920 --> 00:13:27,279
an app that allows cancer patients to

300
00:13:25,010 --> 00:13:29,749
keep track of their concentrate

301
00:13:27,279 --> 00:13:32,209
so we look into three evaluation

302
00:13:29,749 --> 00:13:34,730
criteria we look into the compatibility

303
00:13:32,209 --> 00:13:36,638
of our solution with existing apps we

304
00:13:34,730 --> 00:13:39,319
look into the performance overhead

305
00:13:36,639 --> 00:13:41,179
introduced by hi my app to the existing

306
00:13:39,319 --> 00:13:43,429
app in particular we look into the

307
00:13:41,179 --> 00:13:46,339
co-star delays and the warm start delays

308
00:13:43,429 --> 00:13:49,040
and we also look into the usability of

309
00:13:46,339 --> 00:13:51,410
the solution and for that purpose we

310
00:13:49,040 --> 00:13:53,360
implemented the the app store and the

311
00:13:51,410 --> 00:13:56,738
manager app and we'd be lie on the

312
00:13:53,360 --> 00:13:59,059
plug-in library for app virtualization

313
00:13:56,739 --> 00:14:00,860
so I refer you to the paper for a

314
00:13:59,059 --> 00:14:02,839
complete evaluation of the solution in

315
00:14:00,860 --> 00:14:05,540
this talk I will only talk about part of

316
00:14:02,839 --> 00:14:06,889
the performance overhead and in

317
00:14:05,540 --> 00:14:11,389
particular I will we talk about the

318
00:14:06,889 --> 00:14:15,049
co-star delays so this figure shows ago

319
00:14:11,389 --> 00:14:17,629
start delays of the EM health apps when

320
00:14:15,049 --> 00:14:20,749
they were launched with and without hi

321
00:14:17,629 --> 00:14:24,860
my app so the height of the column shows

322
00:14:20,749 --> 00:14:27,049
the average go start delays and these

323
00:14:24,860 --> 00:14:30,049
thick shows one standard deviation from

324
00:14:27,049 --> 00:14:32,299
the mean so you can see that in all of

325
00:14:30,049 --> 00:14:35,239
the cases the cost or delays are less

326
00:14:32,299 --> 00:14:37,610
than three seconds and I would like to

327
00:14:35,239 --> 00:14:39,709
emphasize that it is a non optimized

328
00:14:37,610 --> 00:14:42,410
implementation and even with this non

329
00:14:39,709 --> 00:14:46,008
optimized implementation the go start

330
00:14:42,410 --> 00:14:48,199
delays I still within the accepted coast

331
00:14:46,009 --> 00:14:50,269
are delays divided by Google so who will

332
00:14:48,199 --> 00:14:52,008
say that the costar delays can go up to

333
00:14:50,269 --> 00:14:55,850
5 seconds and we are still way below

334
00:14:52,009 --> 00:14:59,569
that and also from our user study more

335
00:14:55,850 --> 00:15:04,489
than 90% of people agree that a costar

336
00:14:59,569 --> 00:15:07,939
delay of 3 seconds is acceptable so to

337
00:15:04,489 --> 00:15:10,129
conclude my talk I've shown you that

338
00:15:07,939 --> 00:15:12,319
apps can easily fingerprint other apps

339
00:15:10,129 --> 00:15:15,619
and they do want to fingerprint other

340
00:15:12,319 --> 00:15:17,988
apps that existing solutions are not

341
00:15:15,619 --> 00:15:20,329
effective and therefore we have proposed

342
00:15:17,989 --> 00:15:22,610
hi my apps the first solution for hiding

343
00:15:20,329 --> 00:15:25,219
the presence of sensitive apps from

344
00:15:22,610 --> 00:15:27,769
other apps on the same device

345
00:15:25,220 --> 00:15:30,559
hi my app runs on stock Android devices

346
00:15:27,769 --> 00:15:33,679
it's compatible with existing app it's

347
00:15:30,559 --> 00:15:35,299
effective and usable and for more

348
00:15:33,679 --> 00:15:37,459
information about the project and the

349
00:15:35,299 --> 00:15:39,050
source code implementation i

350
00:15:37,460 --> 00:15:41,300
refer you to the link at the bottom of

351
00:15:39,050 --> 00:15:42,109
the slide and I would like to thank you

352
00:15:41,300 --> 00:15:44,569
for your attention

353
00:15:42,110 --> 00:15:51,110
and I can take questions if you have any

354
00:15:44,570 --> 00:15:53,000
thank you okay thank you and if you have

355
00:15:51,110 --> 00:15:54,649
any questions run kindly step up to the

356
00:15:53,000 --> 00:16:04,640
microphone and state your name and

357
00:15:54,649 --> 00:16:07,180
affiliation so my question is this more

358
00:16:04,640 --> 00:16:09,980
effective and or more sustainable than

359
00:16:07,180 --> 00:16:11,229
for example hospitals having mobile web

360
00:16:09,980 --> 00:16:13,970
applications

361
00:16:11,230 --> 00:16:16,790
okay can you repeat the question oh yeah

362
00:16:13,970 --> 00:16:20,180
is this more sustainable or more

363
00:16:16,790 --> 00:16:23,360
effective than the hospitals having

364
00:16:20,180 --> 00:16:25,760
mobile like web applications um well

365
00:16:23,360 --> 00:16:28,010
actually we started this project because

366
00:16:25,760 --> 00:16:30,439
the hospital in our city they wanted to

367
00:16:28,010 --> 00:16:33,620
have a project that you know they gave

368
00:16:30,440 --> 00:16:35,600
people external devices and mobile apps

369
00:16:33,620 --> 00:16:38,810
so that the you know people can keep

370
00:16:35,600 --> 00:16:41,209
track of medical conditions and so it's

371
00:16:38,810 --> 00:16:43,130
actually a really guys okay so the

372
00:16:41,209 --> 00:16:45,439
primary trade-off is that applications

373
00:16:43,130 --> 00:16:47,060
currently allow like install

374
00:16:45,440 --> 00:16:55,339
applications allow interfacing with

375
00:16:47,060 --> 00:16:57,589
external thank you I need from check

376
00:16:55,339 --> 00:17:00,320
events and Google again sorry about that

377
00:16:57,589 --> 00:17:02,990
in those sessions speak louder because I

378
00:17:00,320 --> 00:17:07,760
cannot hear in in the apps that you

379
00:17:02,990 --> 00:17:12,109
analyzed that lists other installed apps

380
00:17:07,760 --> 00:17:13,670
did you get any signals on which apps

381
00:17:12,109 --> 00:17:15,889
actually send off that list of

382
00:17:13,670 --> 00:17:17,380
applications and which just use it for

383
00:17:15,890 --> 00:17:19,819
legitimate reasons like for example

384
00:17:17,380 --> 00:17:22,870
sorting through other apps that are on

385
00:17:19,819 --> 00:17:25,670
device in their own custom share sheet

386
00:17:22,869 --> 00:17:27,319
it'd be actually interesting to look

387
00:17:25,670 --> 00:17:28,210
into that and I was curious about it

388
00:17:27,319 --> 00:17:30,649
myself

389
00:17:28,210 --> 00:17:37,940
but we didn't really have time to look

390
00:17:30,650 --> 00:17:39,860
into that hi my name is Raghav I'm from

391
00:17:37,940 --> 00:17:43,670
the University of Nevada thank you for

392
00:17:39,860 --> 00:17:45,229
the great talk and technique I'm this

393
00:17:43,670 --> 00:17:47,350
may sound like a contrived scenario but

394
00:17:45,230 --> 00:17:50,769
is it possible to

395
00:17:47,350 --> 00:17:54,209
expose public components through the

396
00:17:50,769 --> 00:17:57,250
virtualized app for inter app

397
00:17:54,210 --> 00:18:00,159
communication so what you're talking

398
00:17:57,250 --> 00:18:01,870
about is for example like content

399
00:18:00,159 --> 00:18:03,519
providers for example in The Times apps

400
00:18:01,870 --> 00:18:07,959
want to share the data with other apps

401
00:18:03,519 --> 00:18:11,380
oh well so if an app's want to share

402
00:18:07,960 --> 00:18:13,000
their with other apps and it can be used

403
00:18:11,380 --> 00:18:16,000
to fingerprint the apps right so content

404
00:18:13,000 --> 00:18:18,009
providers we could only support if the

405
00:18:16,000 --> 00:18:20,470
app use content providers to share their

406
00:18:18,009 --> 00:18:22,299
you know between the apps missing the

407
00:18:20,470 --> 00:18:23,409
components of the apps but not outside

408
00:18:22,299 --> 00:18:27,309
because that would facilitate

409
00:18:23,409 --> 00:18:29,320
fingerprinting attacks okay let's think

410
00:18:27,309 --> 00:18:31,389
on again for a question for answering

411
00:18:29,320 --> 00:18:34,740
the questions and if you have anything

412
00:18:31,389 --> 00:18:34,740
else please doctor offline

413
00:18:35,010 --> 00:18:40,099
[Applause]

