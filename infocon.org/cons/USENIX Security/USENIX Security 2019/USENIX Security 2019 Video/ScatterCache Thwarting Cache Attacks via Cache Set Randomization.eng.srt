1
00:00:10,469 --> 00:00:15,389
then yeah thank you for the introduction

2
00:00:13,099 --> 00:00:17,580
like I already said my name is Mariana

3
00:00:15,389 --> 00:00:19,950
I'm PhD student at grads University of

4
00:00:17,580 --> 00:00:23,209
Technology and today I have the pleasure

5
00:00:19,950 --> 00:00:27,360
to present to you our can scatter cache

6
00:00:23,210 --> 00:00:29,640
this is a joint work with with my

7
00:00:27,360 --> 00:00:32,040
colleagues from Graz so with Amazon

8
00:00:29,640 --> 00:00:37,500
Tolaga lucas kena mukesh watts daniel

9
00:00:32,040 --> 00:00:38,820
goose and stefan man guard okay so for

10
00:00:37,500 --> 00:00:41,420
the beginning let me set takes

11
00:00:38,820 --> 00:00:43,559
expectations right what is scatter cache

12
00:00:41,420 --> 00:00:46,859
scatter cache is basically an

13
00:00:43,559 --> 00:00:50,940
alternative cache design it's also an

14
00:00:46,859 --> 00:00:53,640
set associative cache but we designed it

15
00:00:50,940 --> 00:00:57,390
with weave count as countermeasure

16
00:00:53,640 --> 00:00:59,909
against cache attacks so yeah what does

17
00:00:57,390 --> 00:01:02,760
it do it breaks the Det fixed link

18
00:00:59,909 --> 00:01:07,110
between addresses and cache sets that we

19
00:01:02,760 --> 00:01:08,640
usually have in an associative cache we

20
00:01:07,110 --> 00:01:13,710
increase the number of possible cache

21
00:01:08,640 --> 00:01:15,810
sets and we introduced domain IDs which

22
00:01:13,710 --> 00:01:18,929
is ours via software to change the

23
00:01:15,810 --> 00:01:23,070
concurrences in the cache as the result

24
00:01:18,930 --> 00:01:26,610
exploitation of the of the cache in in

25
00:01:23,070 --> 00:01:29,039
terms of attacks so getting information

26
00:01:26,610 --> 00:01:35,150
out of the side channels should get much

27
00:01:29,040 --> 00:01:38,390
harder the whole concept is based on on

28
00:01:35,150 --> 00:01:41,630
reusing established concepts so we

29
00:01:38,390 --> 00:01:43,530
basically built on skewed caches and

30
00:01:41,630 --> 00:01:47,759
reuse low latency cryptographic

31
00:01:43,530 --> 00:01:50,490
primitives and at the end are the

32
00:01:47,760 --> 00:01:52,230
usability and the complexity higher

33
00:01:50,490 --> 00:01:57,089
complexity should be comparable to

34
00:01:52,230 --> 00:01:58,770
existing caches as an area talk here we

35
00:01:57,090 --> 00:02:00,480
have some backgrounds but you heard

36
00:01:58,770 --> 00:02:02,500
already most of that so we will go

37
00:02:00,480 --> 00:02:04,600
pretty fast

38
00:02:02,500 --> 00:02:06,520
yeah Cassius what's the use they

39
00:02:04,600 --> 00:02:09,008
basically bridge the gap between the

40
00:02:06,520 --> 00:02:11,470
main memory and the very fast CPUs which

41
00:02:09,008 --> 00:02:15,519
we have nowadays and they're really

42
00:02:11,470 --> 00:02:17,380
great in terms of usability nowadays so

43
00:02:15,520 --> 00:02:21,070
we don't have to manage them manually

44
00:02:17,380 --> 00:02:23,350
we simply request very like here I it's

45
00:02:21,070 --> 00:02:24,790
not in the cache the cache automatically

46
00:02:23,350 --> 00:02:29,109
requests the data from the main memory

47
00:02:24,790 --> 00:02:32,079
gets the response replies it to the CPU

48
00:02:29,110 --> 00:02:33,850
and also stores it in a cache if you do

49
00:02:32,080 --> 00:02:35,200
the same again now we have to date

50
00:02:33,850 --> 00:02:38,380
already in the cache and we get the

51
00:02:35,200 --> 00:02:41,200
cache hit and everything is fast what's

52
00:02:38,380 --> 00:02:43,079
important here is is that the when the

53
00:02:41,200 --> 00:02:47,768
cache does what it is supposed to do

54
00:02:43,080 --> 00:02:49,930
it's slower when when it doesn't have

55
00:02:47,769 --> 00:02:53,140
the information you request and it's

56
00:02:49,930 --> 00:02:56,830
faster if it's already there we can

57
00:02:53,140 --> 00:02:59,529
measure this this this difference so for

58
00:02:56,830 --> 00:03:03,310
this specific laptop for example when I

59
00:02:59,530 --> 00:03:06,310
measure cache hits I get latency here on

60
00:03:03,310 --> 00:03:07,870
this on this chart around 100 cycles I

61
00:03:06,310 --> 00:03:10,000
mean there's some systemic overhead but

62
00:03:07,870 --> 00:03:13,450
it doesn't matter when we look at cache

63
00:03:10,000 --> 00:03:13,989
misses they are clearly at around 200

64
00:03:13,450 --> 00:03:16,540
years old

65
00:03:13,989 --> 00:03:18,519
so we can really separate a cache hit

66
00:03:16,540 --> 00:03:22,328
from a cache miss based on the timing of

67
00:03:18,519 --> 00:03:25,630
the of the excesses when you now look

68
00:03:22,329 --> 00:03:27,549
depayne into how modern caches work we

69
00:03:25,630 --> 00:03:30,640
usually have to set associative caches

70
00:03:27,549 --> 00:03:34,720
meaning that we take certain bits from

71
00:03:30,640 --> 00:03:38,320
our address which we request and use

72
00:03:34,720 --> 00:03:40,900
those bits to data mine in which entries

73
00:03:38,320 --> 00:03:44,320
in our cache the data can reside at all

74
00:03:40,900 --> 00:03:47,049
in this specific example we have a 2-way

75
00:03:44,320 --> 00:03:50,769
cache which means 2-way set-associative

76
00:03:47,049 --> 00:03:52,390
cache which means that as soon as we

77
00:03:50,769 --> 00:03:53,980
detonate the cache set there are two

78
00:03:52,390 --> 00:03:58,358
possibilities where we can store our

79
00:03:53,980 --> 00:04:01,000
data and in case of reading data we use

80
00:03:58,359 --> 00:04:03,579
the upper bits the tag bits to data mine

81
00:04:01,000 --> 00:04:05,330
if the data is what we want to have in

82
00:04:03,579 --> 00:04:07,730
reply to the

83
00:04:05,330 --> 00:04:11,360
when you write to a cache in such a kit

84
00:04:07,730 --> 00:04:13,220
in in such a in such a concept there's a

85
00:04:11,360 --> 00:04:16,040
replacement policy which decides in

86
00:04:13,220 --> 00:04:19,699
which entry which way we select in in

87
00:04:16,040 --> 00:04:22,070
our cache and there are also attacks

88
00:04:19,699 --> 00:04:24,740
which exploit this structure and the

89
00:04:22,070 --> 00:04:26,750
null or the the fact that we can see

90
00:04:24,740 --> 00:04:30,020
timing differences and know if it hits

91
00:04:26,750 --> 00:04:32,840
or misses and that's primarily what for

92
00:04:30,020 --> 00:04:35,510
example the idea is pretty simple

93
00:04:32,840 --> 00:04:39,138
the attacker uses his knowledge over

94
00:04:35,510 --> 00:04:41,030
over the cache and in a prime step he

95
00:04:39,139 --> 00:04:44,590
fills a whole cache set with all this

96
00:04:41,030 --> 00:04:47,630
data then he that's the victim executes

97
00:04:44,590 --> 00:04:51,138
the victim performs his excesses or or

98
00:04:47,630 --> 00:04:53,810
not evict some of the data from the from

99
00:04:51,139 --> 00:04:56,150
the attacker and in the second step the

100
00:04:53,810 --> 00:04:58,550
attacker then probes his own data and

101
00:04:56,150 --> 00:05:01,520
data mines if data is still in the cache

102
00:04:58,550 --> 00:05:03,740
if the exit is fast it's still there if

103
00:05:01,520 --> 00:05:05,419
it's slow then we have a victim access

104
00:05:03,740 --> 00:05:07,580
in between and so the attacker learned

105
00:05:05,419 --> 00:05:13,969
that the victim accessed a certain

106
00:05:07,580 --> 00:05:15,289
address or cache them so why should we

107
00:05:13,970 --> 00:05:17,900
care about this

108
00:05:15,289 --> 00:05:19,909
the problem here is like you heard in

109
00:05:17,900 --> 00:05:24,500
the whole session you can do a lot of

110
00:05:19,910 --> 00:05:26,810
stuff with with knowledge of of hits and

111
00:05:24,500 --> 00:05:28,460
misses in the cache so the attacks are

112
00:05:26,810 --> 00:05:30,590
quite powerful the break isolation

113
00:05:28,460 --> 00:05:32,210
boundaries and even if you write correct

114
00:05:30,590 --> 00:05:35,510
software you cannot be sure that your

115
00:05:32,210 --> 00:05:37,549
data does not leak to any concurrent

116
00:05:35,510 --> 00:05:39,710
process for example there are a lot of

117
00:05:37,550 --> 00:05:41,539
different attacking techniques some

118
00:05:39,710 --> 00:05:44,739
require of memory others like for

119
00:05:41,539 --> 00:05:48,380
improvement and we have seen numerous

120
00:05:44,740 --> 00:05:51,260
attack scenarios so there are key

121
00:05:48,380 --> 00:05:54,190
loggers key cryptographic key extraction

122
00:05:51,260 --> 00:05:57,650
is a lot breaks and stuff like that

123
00:05:54,190 --> 00:05:59,810
finally which is also really prominent

124
00:05:57,650 --> 00:06:01,940
in the last year's cash attacks are an

125
00:05:59,810 --> 00:06:03,560
important building block or news

126
00:06:01,940 --> 00:06:05,419
building block for other micro

127
00:06:03,560 --> 00:06:09,830
architectural attacks like meltdown on

128
00:06:05,419 --> 00:06:12,139
spectra so in scatter cache we try to

129
00:06:09,830 --> 00:06:14,450
get rid of this problem and the way we

130
00:06:12,139 --> 00:06:17,390
approach that is that we looked at how

131
00:06:14,450 --> 00:06:17,820
at the graphical view and how caches

132
00:06:17,390 --> 00:06:20,700
work

133
00:06:17,820 --> 00:06:23,130
so in this example we have a really

134
00:06:20,700 --> 00:06:26,280
small cash waves consisting of 16 cash

135
00:06:23,130 --> 00:06:28,800
lines only four we set associative so we

136
00:06:26,280 --> 00:06:31,200
have four sets in a traditional cache

137
00:06:28,800 --> 00:06:34,410
the attacker knows exactly what

138
00:06:31,200 --> 00:06:37,310
addresses he has to access in order to

139
00:06:34,410 --> 00:06:41,940
get access to certain sets in the cache

140
00:06:37,310 --> 00:06:43,830
and he can exploit that the first idea

141
00:06:41,940 --> 00:06:46,770
which then comes up usually is let's

142
00:06:43,830 --> 00:06:48,900
remove this direct link so let's get rid

143
00:06:46,770 --> 00:06:51,210
of this direct mapping from index bits

144
00:06:48,900 --> 00:06:53,609
through to cache sets and just scramble

145
00:06:51,210 --> 00:06:54,780
them so for example if we access

146
00:06:53,610 --> 00:06:58,440
something which is congruent to

147
00:06:54,780 --> 00:07:01,080
addresses to address that is congruent

148
00:06:58,440 --> 00:07:04,110
to cache that zero place it in cache

149
00:07:01,080 --> 00:07:07,140
that - maybe and similar for other

150
00:07:04,110 --> 00:07:09,680
addresses this idea is basically nice

151
00:07:07,140 --> 00:07:12,060
the program here is there is not enough

152
00:07:09,680 --> 00:07:14,790
not enough entropy in this in this

153
00:07:12,060 --> 00:07:16,680
design so what usually this has to be

154
00:07:14,790 --> 00:07:20,220
done there is that you frequently Ricky

155
00:07:16,680 --> 00:07:22,770
your your mapping function and that's

156
00:07:20,220 --> 00:07:23,400
for example exactly what to publications

157
00:07:22,770 --> 00:07:26,580
last data

158
00:07:23,400 --> 00:07:29,849
so at DAC and also at macro there were

159
00:07:26,580 --> 00:07:31,770
two cache designs which use this

160
00:07:29,850 --> 00:07:34,620
paradigm and frequently change the

161
00:07:31,770 --> 00:07:38,490
Kingdom Epping in skeptic ash we tried

162
00:07:34,620 --> 00:07:39,900
to - yeah we looked at this and ask the

163
00:07:38,490 --> 00:07:43,890
question why can't we do something like

164
00:07:39,900 --> 00:07:45,989
that so simply select four random

165
00:07:43,890 --> 00:07:49,590
addresses for random cache lines in our

166
00:07:45,990 --> 00:07:51,990
cache and form the set out of those the

167
00:07:49,590 --> 00:07:55,080
big advantage here is that we don't have

168
00:07:51,990 --> 00:07:58,080
to restrict the alignment anymore we get

169
00:07:55,080 --> 00:07:59,990
really for each address we query from

170
00:07:58,080 --> 00:08:02,820
the cache we get different cache sets

171
00:07:59,990 --> 00:08:05,730
still there is overlap partial overlap

172
00:08:02,820 --> 00:08:08,270
but it gets highly unlikely that there

173
00:08:05,730 --> 00:08:10,820
are full cache collisions occur set

174
00:08:08,270 --> 00:08:13,289
collisions like we have before and

175
00:08:10,820 --> 00:08:15,719
another cool thing we can do if that is

176
00:08:13,290 --> 00:08:17,580
that we can introduce an additional

177
00:08:15,720 --> 00:08:21,090
context into the into the mapping

178
00:08:17,580 --> 00:08:23,849
function so before we had for this first

179
00:08:21,090 --> 00:08:25,770
address we had the upper for

180
00:08:23,850 --> 00:08:27,690
cache lines and then we access the same

181
00:08:25,770 --> 00:08:29,280
address in a different domain and we can

182
00:08:27,690 --> 00:08:33,360
pick completely different

183
00:08:29,280 --> 00:08:35,760
addresses so the question is can we

184
00:08:33,360 --> 00:08:40,050
build this thing so is it possible is

185
00:08:35,760 --> 00:08:43,140
plausible and the idea is still quite

186
00:08:40,049 --> 00:08:45,390
simple so we introduced an index

187
00:08:43,140 --> 00:08:47,760
derivation function which is basically a

188
00:08:45,390 --> 00:08:52,980
cryptographic primitive which derives

189
00:08:47,760 --> 00:08:55,560
from a cache line from a key and domain

190
00:08:52,980 --> 00:09:00,000
identifier the cash in the indices which

191
00:08:55,560 --> 00:09:02,069
we useful to form our cash set yeah like

192
00:09:00,000 --> 00:09:05,880
like you've seen before we get unique

193
00:09:02,070 --> 00:09:07,770
combinations of cache sets with that and

194
00:09:05,880 --> 00:09:10,230
there are a lot of them so it's

195
00:09:07,770 --> 00:09:13,110
basically a kick a key combination with

196
00:09:10,230 --> 00:09:16,490
repetition we can calculate how many

197
00:09:13,110 --> 00:09:19,830
doors are and if we use for example a

198
00:09:16,490 --> 00:09:24,740
500 kilowatt cash it way set associative

199
00:09:19,830 --> 00:09:27,360
which usually would have 2048 cache sets

200
00:09:24,740 --> 00:09:30,930
with this design we get two to the

201
00:09:27,360 --> 00:09:35,160
nineties to the 96 more than 2.6 cache

202
00:09:30,930 --> 00:09:37,680
set so quite a lot more the problem here

203
00:09:35,160 --> 00:09:41,640
is we we can't really or can't really

204
00:09:37,680 --> 00:09:46,290
want we don't really want to use this

205
00:09:41,640 --> 00:09:49,050
design because addressing in one huge

206
00:09:46,290 --> 00:09:53,030
memory is quite intensive in in terms of

207
00:09:49,050 --> 00:09:55,500
hardware we need multi port memory and

208
00:09:53,030 --> 00:09:57,540
additionally there's the question what

209
00:09:55,500 --> 00:10:00,510
happens if we have collisions in our

210
00:09:57,540 --> 00:10:02,520
indices so if two of those indices point

211
00:10:00,510 --> 00:10:05,100
to the same cache line then we have the

212
00:10:02,520 --> 00:10:07,610
problem that the associativity degrades

213
00:10:05,100 --> 00:10:10,140
and that's nothing which we want to have

214
00:10:07,610 --> 00:10:11,970
so we want to have something which is

215
00:10:10,140 --> 00:10:14,310
more similar to traditional concepts

216
00:10:11,970 --> 00:10:16,980
again on the left side that's the

217
00:10:14,310 --> 00:10:20,060
standard set associative cache we take

218
00:10:16,980 --> 00:10:22,350
the index bits selectively the cache set

219
00:10:20,060 --> 00:10:24,869
the way we build our scatter cache now

220
00:10:22,350 --> 00:10:26,490
is we use the same index function we

221
00:10:24,870 --> 00:10:29,430
index duration function we have before

222
00:10:26,490 --> 00:10:36,030
but we use the indices as indices into

223
00:10:29,430 --> 00:10:39,359
that into individual ways this design is

224
00:10:36,030 --> 00:10:41,699
not completely unseen so it's basically

225
00:10:39,360 --> 00:10:45,480
a skewed cache which is already

226
00:10:41,699 --> 00:10:49,079
in 93 which is equipped with an with our

227
00:10:45,480 --> 00:10:50,669
index duration function and it's also

228
00:10:49,079 --> 00:10:54,839
similar to building larger caches

229
00:10:50,669 --> 00:10:56,549
consisting of cache slices the

230
00:10:54,839 --> 00:10:59,220
consequence from this design change is

231
00:10:56,549 --> 00:11:01,769
that we reduce our number of possible

232
00:10:59,220 --> 00:11:05,459
cache that's a little bit so now we only

233
00:11:01,769 --> 00:11:08,459
have two to the P indices time and times

234
00:11:05,459 --> 00:11:10,979
n but for the same cache we have before

235
00:11:08,459 --> 00:11:15,329
we still have two to the 88 so this

236
00:11:10,980 --> 00:11:17,549
dismal loss is still acceptable and as

237
00:11:15,329 --> 00:11:21,988
replacement policy scatter cache always

238
00:11:17,549 --> 00:11:23,790
uses random replacement for now okay so

239
00:11:21,989 --> 00:11:26,459
what can we select for the index

240
00:11:23,790 --> 00:11:28,169
derivation function the top of the index

241
00:11:26,459 --> 00:11:30,089
duration function is to use the cache

242
00:11:28,169 --> 00:11:34,739
line addressed the main identified the

243
00:11:30,089 --> 00:11:37,859
key and to omit the indices for the free

244
00:11:34,739 --> 00:11:39,989
cash ways we reuse existing

245
00:11:37,859 --> 00:11:42,239
cryptographic primitives I mean it

246
00:11:39,989 --> 00:11:45,389
doesn't really matter what we use in in

247
00:11:42,239 --> 00:11:47,220
what specific primitive we use so we

248
00:11:45,389 --> 00:11:50,819
only looked at two variants the first

249
00:11:47,220 --> 00:11:53,249
one is a hashing variant theory where we

250
00:11:50,819 --> 00:11:54,809
can build our index duration function of

251
00:11:53,249 --> 00:11:56,730
a different block ciphers from three

252
00:11:54,809 --> 00:11:58,858
cable block ciphers or from permutation

253
00:11:56,730 --> 00:12:00,869
based primitives the great thing here is

254
00:11:58,859 --> 00:12:03,929
that there are already primitives which

255
00:12:00,869 --> 00:12:06,419
fit this in industry usage model so with

256
00:12:03,929 --> 00:12:08,759
a low latency block cipher called prints

257
00:12:06,419 --> 00:12:12,720
there is camera a three key block cipher

258
00:12:08,759 --> 00:12:14,850
and there are also sponge based variants

259
00:12:12,720 --> 00:12:17,220
based on the Catterick permutation for

260
00:12:14,850 --> 00:12:19,829
example which can be implemented and

261
00:12:17,220 --> 00:12:21,269
computed really fast the second variant

262
00:12:19,829 --> 00:12:22,738
which we looked into is a permutation

263
00:12:21,269 --> 00:12:25,859
event very only

264
00:12:22,739 --> 00:12:29,609
permute the index bits that preserves

265
00:12:25,859 --> 00:12:33,089
the the behavior that we don't get

266
00:12:29,609 --> 00:12:34,649
birthday bond index collisions the

267
00:12:33,089 --> 00:12:37,619
problem here is that we would need a

268
00:12:34,649 --> 00:12:41,039
cipher or trigger block cipher that has

269
00:12:37,619 --> 00:12:43,379
index bits block size and that's nothing

270
00:12:41,039 --> 00:12:45,300
which we usually have so there are no of

271
00:12:43,379 --> 00:12:47,010
the Shelf primitives and yeah

272
00:12:45,300 --> 00:12:51,349
if we want to have something like that

273
00:12:47,010 --> 00:12:53,939
we should talk to our group together

274
00:12:51,350 --> 00:12:56,070
when we integrate scatter cash in our

275
00:12:53,940 --> 00:12:57,839
system the idea is to use it at last

276
00:12:56,070 --> 00:13:01,950
level cache because it's the biggest one

277
00:12:57,839 --> 00:13:04,170
at the mostly target that one the

278
00:13:01,950 --> 00:13:06,209
hardwick the key itself is primarily

279
00:13:04,170 --> 00:13:08,459
managed in hardware the idea is that the

280
00:13:06,209 --> 00:13:10,529
software never gets to this key and we

281
00:13:08,459 --> 00:13:13,349
can basically always change the key as

282
00:13:10,529 --> 00:13:15,089
long as the cache is clean so when we

283
00:13:13,350 --> 00:13:17,940
don't have dirty cache lines we can

284
00:13:15,089 --> 00:13:21,660
change the key meaning also after every

285
00:13:17,940 --> 00:13:23,720
cache flush and what's also possible is

286
00:13:21,660 --> 00:13:28,410
that we can introduce iterative freaking

287
00:13:23,720 --> 00:13:30,209
if we need to and interestingly that's

288
00:13:28,410 --> 00:13:33,719
also a paper which was published this

289
00:13:30,209 --> 00:13:36,750
year Miska called the technique is

290
00:13:33,720 --> 00:13:38,670
called Caesar s and if you compare it

291
00:13:36,750 --> 00:13:43,980
and use the rekeying it's really similar

292
00:13:38,670 --> 00:13:45,959
to scatter cache the domain identify on

293
00:13:43,980 --> 00:13:49,230
the other hand it's attended by software

294
00:13:45,959 --> 00:13:50,699
tweaking knob so we have we want to

295
00:13:49,230 --> 00:13:52,920
expose that to the software to the

296
00:13:50,700 --> 00:13:57,029
operating system and give it the

297
00:13:52,920 --> 00:14:01,079
possibility to change the mappings to

298
00:13:57,029 --> 00:14:04,529
allow to stop big identifiers we propose

299
00:14:01,079 --> 00:14:06,870
that we embed a few bits into a page

300
00:14:04,529 --> 00:14:09,990
page table entries and use the same

301
00:14:06,870 --> 00:14:12,329
indirection approach which into and I'm

302
00:14:09,990 --> 00:14:16,890
already have as part of the attribute

303
00:14:12,329 --> 00:14:20,279
tables over attribute registers by

304
00:14:16,890 --> 00:14:22,470
default if we fix the identifier to 0

305
00:14:20,279 --> 00:14:24,750
then we need nope software support at

306
00:14:22,470 --> 00:14:26,850
all so the cache operates exactly like a

307
00:14:24,750 --> 00:14:29,010
current cash but if we have this

308
00:14:26,850 --> 00:14:32,880
additional support we can also get a few

309
00:14:29,010 --> 00:14:34,680
benefits so we can separate shared

310
00:14:32,880 --> 00:14:38,820
read-only pages for example within the

311
00:14:34,680 --> 00:14:42,239
cache or we can define our security

312
00:14:38,820 --> 00:14:44,640
domains like like on-page granularity

313
00:14:42,240 --> 00:14:47,430
with processes VMs containers whatever

314
00:14:44,640 --> 00:14:49,980
we need and also there is the

315
00:14:47,430 --> 00:14:53,189
possibility to do software eqing so for

316
00:14:49,980 --> 00:14:56,160
every page which is not dirty again we

317
00:14:53,190 --> 00:15:00,410
can simply change the identifier and get

318
00:14:56,160 --> 00:15:00,410
a new get a new mapping in the cache

319
00:15:00,950 --> 00:15:06,900
so in terms of security we distinguish

320
00:15:05,040 --> 00:15:09,180
basically three cases the first one is

321
00:15:06,900 --> 00:15:13,079
completely on shape memory each met each

322
00:15:09,180 --> 00:15:15,449
process has its own memory there are no

323
00:15:13,080 --> 00:15:17,640
shared physical pages or no shared

324
00:15:15,450 --> 00:15:21,080
addresses and in the setting flash and

325
00:15:17,640 --> 00:15:23,730
reload style attacks don't work anyway

326
00:15:21,080 --> 00:15:27,440
still primary probe which is usually

327
00:15:23,730 --> 00:15:31,170
applied in this setting stays applicable

328
00:15:27,440 --> 00:15:33,510
and we will discuss in a minute how this

329
00:15:31,170 --> 00:15:36,180
intact or housecat occasion detectors

330
00:15:33,510 --> 00:15:40,920
that then we have the setting of shared

331
00:15:36,180 --> 00:15:44,520
read-only memory here we can use use the

332
00:15:40,920 --> 00:15:47,579
the ID support to bring us back in the

333
00:15:44,520 --> 00:15:48,630
unshared memory setting and finally

334
00:15:47,580 --> 00:15:50,970
there's the shared right to have

335
00:15:48,630 --> 00:15:52,740
memories scenario here cache attacks are

336
00:15:50,970 --> 00:15:55,350
kind of pointless because the attacker

337
00:15:52,740 --> 00:15:57,750
has already access to the today data

338
00:15:55,350 --> 00:16:02,520
anyway so yeah that's not really

339
00:15:57,750 --> 00:16:04,140
something very make a difference in case

340
00:16:02,520 --> 00:16:06,420
sket occasion primary probes the

341
00:16:04,140 --> 00:16:08,160
difference here is or the program years

342
00:16:06,420 --> 00:16:14,130
that we don't still don't have an

343
00:16:08,160 --> 00:16:16,680
end-to-end attack it's still we still

344
00:16:14,130 --> 00:16:19,950
struggle with modeling the new behavior

345
00:16:16,680 --> 00:16:22,410
of the cache sets and the reason what we

346
00:16:19,950 --> 00:16:24,750
did instead is the same which we do

347
00:16:22,410 --> 00:16:26,430
usually in cryptography so we reduce the

348
00:16:24,750 --> 00:16:29,160
problem we make it simpler and try to

349
00:16:26,430 --> 00:16:31,920
break that and in our setting we gave to

350
00:16:29,160 --> 00:16:33,510
attack a perfect control he has single

351
00:16:31,920 --> 00:16:35,069
accesses which he wants to attack and

352
00:16:33,510 --> 00:16:37,410
there is no noise at all in the whole

353
00:16:35,070 --> 00:16:40,110
cache and here we investigated the

354
00:16:37,410 --> 00:16:43,439
building blocks first we figured out or

355
00:16:40,110 --> 00:16:47,420
tried to figure out the conference's our

356
00:16:43,440 --> 00:16:50,220
paper results here in complexity of 225

357
00:16:47,420 --> 00:16:53,130
which is far higher than tanking in

358
00:16:50,220 --> 00:16:54,570
current caches eviction itself gets

359
00:16:53,130 --> 00:16:59,100
probabilistic so we need much more

360
00:16:54,570 --> 00:17:02,180
addresses to do that in this case 275

361
00:16:59,100 --> 00:17:02,180
for 99%

362
00:17:02,300 --> 00:17:08,060
confidence and we also proposed Premiere

363
00:17:05,119 --> 00:17:10,189
Pro parents for this setting where we

364
00:17:08,060 --> 00:17:14,810
show how many addresses we need there

365
00:17:10,190 --> 00:17:17,420
are also new results from from prunella

366
00:17:14,810 --> 00:17:20,089
and the Papa from Palos published this

367
00:17:17,420 --> 00:17:23,620
week and they got down to two to the ten

368
00:17:20,089 --> 00:17:26,208
which is a generalization of our attack

369
00:17:23,619 --> 00:17:28,149
we also did performance evaluation and

370
00:17:26,209 --> 00:17:31,820
the result is that it's basically

371
00:17:28,150 --> 00:17:33,920
similar to to regular cashes with a

372
00:17:31,820 --> 00:17:36,379
random replacement and we had two to

373
00:17:33,920 --> 00:17:39,560
four percent or zero to two percent

374
00:17:36,380 --> 00:17:44,450
depending on the benchmark slower than

375
00:17:39,560 --> 00:17:47,450
la so to conclude scatter cash is

376
00:17:44,450 --> 00:17:48,950
basically a combination of a skewed cash

377
00:17:47,450 --> 00:17:51,680
we have low latency cryptographic

378
00:17:48,950 --> 00:17:54,910
primitives we break this direct link

379
00:17:51,680 --> 00:17:57,620
between cash sets and addresses and

380
00:17:54,910 --> 00:18:00,350
enable the software tool to influence

381
00:17:57,620 --> 00:18:02,179
the mapping within the cache itself we

382
00:18:00,350 --> 00:18:04,820
have comparable performance to contrary

383
00:18:02,180 --> 00:18:06,490
contemporary caches as that especially

384
00:18:04,820 --> 00:18:09,399
with the same replacement policy and

385
00:18:06,490 --> 00:18:13,790
it's definitely harder to attack than a

386
00:18:09,400 --> 00:18:16,150
contemporary cache and we need your

387
00:18:13,790 --> 00:18:19,520
attack approaches to tackle this thing

388
00:18:16,150 --> 00:18:22,250
still we also need more analysis on that

389
00:18:19,520 --> 00:18:24,290
so that we figure out how this works in

390
00:18:22,250 --> 00:18:28,610
a real more realistic model and if we

391
00:18:24,290 --> 00:18:30,920
need wreaking as well so yeah thank you

392
00:18:28,610 --> 00:18:33,379
to all the people who are involved in

393
00:18:30,920 --> 00:18:35,900
this work also my quarters of course and

394
00:18:33,380 --> 00:18:38,170
with that I'm at the end and be glad to

395
00:18:35,900 --> 00:18:38,170
take questions

396
00:18:39,960 --> 00:18:45,130
[Music]

397
00:18:41,440 --> 00:18:48,290
okay thank you for your talk

398
00:18:45,130 --> 00:18:51,260
are there any questions so we start and

399
00:18:48,290 --> 00:18:55,580
introduce yourself hi I'm Daniel Murphy

400
00:18:51,260 --> 00:18:58,190
from WPI so my question is did you do

401
00:18:55,580 --> 00:19:00,919
any quantification in terms of the

402
00:18:58,190 --> 00:19:05,690
entropy you use for the key and

403
00:19:00,920 --> 00:19:07,850
performance no we we focused here on the

404
00:19:05,690 --> 00:19:10,190
design itself so we are not really fixed

405
00:19:07,850 --> 00:19:14,209
on on the primitive itself we in the

406
00:19:10,190 --> 00:19:14,890
paper we primarily used camera because

407
00:19:14,210 --> 00:19:17,350
it's

408
00:19:14,890 --> 00:19:20,660
silic improvement in this area already

409
00:19:17,350 --> 00:19:23,419
but we didn't look into the entropy of

410
00:19:20,660 --> 00:19:26,030
keys or implementations and when we you

411
00:19:23,420 --> 00:19:28,220
are using karma like what was the key

412
00:19:26,030 --> 00:19:32,510
size or entropy for

413
00:19:28,220 --> 00:19:35,570
I think it's 96 bit or 102 8 it's it's

414
00:19:32,510 --> 00:19:37,879
it's it's there a lot I mean camera and

415
00:19:35,570 --> 00:19:39,200
prints are general-purpose cryptographic

416
00:19:37,880 --> 00:19:42,530
primitives they are not designed for

417
00:19:39,200 --> 00:19:44,180
distant specific they're for general

418
00:19:42,530 --> 00:19:47,389
purpose encryption or encryption

419
00:19:44,180 --> 00:19:51,350
authentication so they they use 128-bit

420
00:19:47,390 --> 00:19:55,000
keys and are strong in in also known

421
00:19:51,350 --> 00:19:57,500
plaintext models okay thank you

422
00:19:55,000 --> 00:20:01,010
hi my name is guru Rajan from Georgia

423
00:19:57,500 --> 00:20:02,750
Tech a great word loved it I had a

424
00:20:01,010 --> 00:20:06,230
question about the applicability of this

425
00:20:02,750 --> 00:20:09,080
design to other caches in the system so

426
00:20:06,230 --> 00:20:10,820
for instance private l1 caches yeah

427
00:20:09,080 --> 00:20:13,340
given that they have different

428
00:20:10,820 --> 00:20:15,409
constraints around latency and sizes

429
00:20:13,340 --> 00:20:18,709
would this be applicable or not

430
00:20:15,410 --> 00:20:21,110
applicable to them the main question

431
00:20:18,710 --> 00:20:23,540
here is how fast can we get our index

432
00:20:21,110 --> 00:20:25,550
derivation function in the last level

433
00:20:23,540 --> 00:20:28,190
setting which we evaluated we know that

434
00:20:25,550 --> 00:20:30,280
the function is fast enough to be

435
00:20:28,190 --> 00:20:32,570
computed at least in parallel to look up

436
00:20:30,280 --> 00:20:35,600
when we want to have something for the

437
00:20:32,570 --> 00:20:38,240
l1 cache we need something really fast

438
00:20:35,600 --> 00:20:40,100
one thing which we proposed but not

439
00:20:38,240 --> 00:20:42,350
really evaluate that yet this use a

440
00:20:40,100 --> 00:20:44,629
regular skewed caches which with some

441
00:20:42,350 --> 00:20:46,250
masking may be only in in the lower

442
00:20:44,630 --> 00:20:48,260
level caches because that can be

443
00:20:46,250 --> 00:20:49,970
computed really fast and you still get

444
00:20:48,260 --> 00:20:50,480
this benefit of breaking the alignment

445
00:20:49,970 --> 00:20:52,580
or

446
00:20:50,480 --> 00:20:55,310
so maybe maybe something like that

447
00:20:52,580 --> 00:20:55,990
should be looked into okay last question

448
00:20:55,310 --> 00:20:58,820
please

449
00:20:55,990 --> 00:21:02,450
hi young Saleh here University of

450
00:20:58,820 --> 00:21:04,820
Central Florida so nice work I have a

451
00:21:02,450 --> 00:21:07,100
question so do you envision like you

452
00:21:04,820 --> 00:21:09,470
have if you have two processes do they

453
00:21:07,100 --> 00:21:12,409
reside in the two different security

454
00:21:09,470 --> 00:21:14,660
domain like they will map differently to

455
00:21:12,410 --> 00:21:20,060
the cache yeah absolutely that's

456
00:21:14,660 --> 00:21:23,420
possible so we use this security domains

457
00:21:20,060 --> 00:21:26,030
mainly to distinguish on the one hand to

458
00:21:23,420 --> 00:21:27,950
break stuff which to break the call here

459
00:21:26,030 --> 00:21:31,460
a congruence where we don't want to have

460
00:21:27,950 --> 00:21:33,560
it so for shared memory for example but

461
00:21:31,460 --> 00:21:35,270
when you have shared memory that has to

462
00:21:33,560 --> 00:21:38,120
work a shared memory you can't do that

463
00:21:35,270 --> 00:21:41,120
because then you have no cache coherency

464
00:21:38,120 --> 00:21:44,120
anymore so so you prevent some kind of

465
00:21:41,120 --> 00:21:46,639
like sharing right sharing the process

466
00:21:44,120 --> 00:21:48,709
sharing you right we presented where we

467
00:21:46,640 --> 00:21:50,390
don't want to have it but if we want to

468
00:21:48,710 --> 00:21:52,670
have it then we have to use the same

469
00:21:50,390 --> 00:21:55,610
identifier anyway right otherwise it

470
00:21:52,670 --> 00:21:57,800
doesn't work have you considered cache

471
00:21:55,610 --> 00:22:01,280
coherence like if you if you receive an

472
00:21:57,800 --> 00:22:04,700
invalidation for externally it only

473
00:22:01,280 --> 00:22:07,520
terms as a physical address so you don't

474
00:22:04,700 --> 00:22:09,980
really have the the security domain

475
00:22:07,520 --> 00:22:12,530
information anymore and then you have to

476
00:22:09,980 --> 00:22:14,660
invalidate your cache and then you know

477
00:22:12,530 --> 00:22:16,070
how do you find a block we really

478
00:22:14,660 --> 00:22:18,530
haven't looked into in the external

479
00:22:16,070 --> 00:22:20,990
invalidation currently it's more like

480
00:22:18,530 --> 00:22:22,820
for for inclusive caches where you don't

481
00:22:20,990 --> 00:22:25,270
have have this don't have this problem

482
00:22:22,820 --> 00:22:28,250
in there it works out in the end

483
00:22:25,270 --> 00:22:31,460
yeah we there's there's still a lot to

484
00:22:28,250 --> 00:22:34,240
look into him right thank you okay let's

485
00:22:31,460 --> 00:22:36,300
find a speaker again

486
00:22:34,240 --> 00:22:36,300
you

