1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:09,320 --> 00:00:12,179
and thanks for joining this talk today

3
00:00:12,179 --> 00:00:14,040
we are going to talk about a novel

4
00:00:14,040 --> 00:00:15,420
modern inversion attribute inference

5
00:00:15,420 --> 00:00:17,699
attacks on classification models and I

6
00:00:17,699 --> 00:00:19,800
am shagufta mahenas from the

7
00:00:19,800 --> 00:00:21,420
Pennsylvania State University and this

8
00:00:21,420 --> 00:00:23,760
is a joint work with collaborators from

9
00:00:23,760 --> 00:00:27,800
Dartmouth College and Purdue University

10
00:00:27,840 --> 00:00:29,880
so let's first see what a model

11
00:00:29,880 --> 00:00:32,820
inversion attack is with the increasing

12
00:00:32,820 --> 00:00:34,940
use of MN Technologies in our lives

13
00:00:34,940 --> 00:00:37,739
nowadays we frequently train these

14
00:00:37,739 --> 00:00:40,340
models on sensitive training data sets

15
00:00:40,340 --> 00:00:42,360
which includes personal information

16
00:00:42,360 --> 00:00:44,879
health records confidential financial

17
00:00:44,879 --> 00:00:46,500
data and so on

18
00:00:46,500 --> 00:00:49,200
so these models are often trained and

19
00:00:49,200 --> 00:00:52,079
hosted by big tech companies and the

20
00:00:52,079 --> 00:00:53,820
users can query these models on a

21
00:00:53,820 --> 00:00:56,280
pay-per-query basis

22
00:00:56,280 --> 00:00:59,760
though there exists many privacy

23
00:00:59,760 --> 00:01:01,500
preserving techniques that preserve the

24
00:01:01,500 --> 00:01:03,780
privacy of the data while training it

25
00:01:03,780 --> 00:01:05,700
may seem that once the model is trained

26
00:01:05,700 --> 00:01:07,619
we are good in terms of privacy

27
00:01:07,619 --> 00:01:10,439
but the idea of modeling version attack

28
00:01:10,439 --> 00:01:13,619
is this makes this one-way Journey from

29
00:01:13,619 --> 00:01:16,020
training data to model to a two-way one

30
00:01:16,020 --> 00:01:19,380
which is given the access to the model

31
00:01:19,380 --> 00:01:21,479
and adversity can intelligently query

32
00:01:21,479 --> 00:01:24,240
this model and reveal some of the

33
00:01:24,240 --> 00:01:26,460
sensitive training data sets or or the

34
00:01:26,460 --> 00:01:28,320
sensitive attributes in the training

35
00:01:28,320 --> 00:01:30,740
data set

36
00:01:30,780 --> 00:01:32,640
um so the access of the adversary could

37
00:01:32,640 --> 00:01:34,259
be of different types for example white

38
00:01:34,259 --> 00:01:36,960
box access Black Box access but we focus

39
00:01:36,960 --> 00:01:39,060
in this work on only the Black Box

40
00:01:39,060 --> 00:01:40,860
access which is a more practical

41
00:01:40,860 --> 00:01:43,979
assumption uh for the threat model

42
00:01:43,979 --> 00:01:46,200
so uh the main research question that we

43
00:01:46,200 --> 00:01:48,119
address in this research is is it

44
00:01:48,119 --> 00:01:49,799
possible for an adversary to estimate

45
00:01:49,799 --> 00:01:51,420
the sensitive attributes in the training

46
00:01:51,420 --> 00:01:54,000
data set by having only the Black Box

47
00:01:54,000 --> 00:01:57,320
query access to the model

48
00:01:57,500 --> 00:01:59,880
so we divide the modeling version

49
00:01:59,880 --> 00:02:02,399
attacks uh in a high level two different

50
00:02:02,399 --> 00:02:04,259
types the first one is typical instance

51
00:02:04,259 --> 00:02:06,600
reconstruction which applies mostly to

52
00:02:06,600 --> 00:02:08,720
the image domain which is much studied

53
00:02:08,720 --> 00:02:11,459
where the adversary tries to reconstruct

54
00:02:11,459 --> 00:02:14,040
a representative image of the actual one

55
00:02:14,040 --> 00:02:16,319
uh that doesn't have to be exactly the

56
00:02:16,319 --> 00:02:18,720
same as the actual image and then uh

57
00:02:18,720 --> 00:02:19,860
there is the second type of model

58
00:02:19,860 --> 00:02:22,260
inversion attack that is model inversion

59
00:02:22,260 --> 00:02:24,360
attribute In fairness attack where the

60
00:02:24,360 --> 00:02:26,819
goal is to reconstruct the exact value

61
00:02:26,819 --> 00:02:28,980
of the sensitive attribute and this

62
00:02:28,980 --> 00:02:31,379
applies to mainly the non-image domain

63
00:02:31,379 --> 00:02:33,840
mostly in the tabular data sets which

64
00:02:33,840 --> 00:02:35,760
includes medical records financial data

65
00:02:35,760 --> 00:02:37,980
Social Survey data and so on so our

66
00:02:37,980 --> 00:02:39,959
focus in this work is in the second type

67
00:02:39,959 --> 00:02:41,640
of model inversion attack that is

68
00:02:41,640 --> 00:02:44,958
sensitive attribute inference

69
00:02:46,440 --> 00:02:48,959
okay so I will follow an example this is

70
00:02:48,959 --> 00:02:52,260
the General Social Survey data set which

71
00:02:52,260 --> 00:02:55,019
is obtained by having a survey on the

72
00:02:55,019 --> 00:02:56,580
individuals where we ask different

73
00:02:56,580 --> 00:02:59,160
questions to the individuals and to the

74
00:02:59,160 --> 00:03:02,099
uh they they respond to this questions

75
00:03:02,099 --> 00:03:03,780
which also include some sensitive

76
00:03:03,780 --> 00:03:05,280
information

77
00:03:05,280 --> 00:03:07,140
so let's say that we want to train a

78
00:03:07,140 --> 00:03:10,620
model uh to predict the marital

79
00:03:10,620 --> 00:03:12,659
happiness of the individuals where the

80
00:03:12,659 --> 00:03:14,280
classes could be not too happy pretty

81
00:03:14,280 --> 00:03:15,840
happy and very happy as you can see in

82
00:03:15,840 --> 00:03:18,959
the last column and the rest of the

83
00:03:18,959 --> 00:03:21,480
columns are the X which is the input

84
00:03:21,480 --> 00:03:23,700
attributes to the model

85
00:03:23,700 --> 00:03:26,159
so once this model is trained of course

86
00:03:26,159 --> 00:03:29,099
you want to queries model with the

87
00:03:29,099 --> 00:03:30,959
answers of the individuals to the other

88
00:03:30,959 --> 00:03:34,019
questions which belong to the X part and

89
00:03:34,019 --> 00:03:36,720
maybe you can the model can output the

90
00:03:36,720 --> 00:03:39,300
confidence scores here you can see that

91
00:03:39,300 --> 00:03:41,099
the confidence score for the very happy

92
00:03:41,099 --> 00:03:42,780
class is the highest the model could

93
00:03:42,780 --> 00:03:45,480
also output only the label not the

94
00:03:45,480 --> 00:03:47,220
conferences course but we will take a

95
00:03:47,220 --> 00:03:49,620
look at this in the next slides

96
00:03:49,620 --> 00:03:53,280
so if you look at the X the training

97
00:03:53,280 --> 00:03:55,319
data there could be very sensitive

98
00:03:55,319 --> 00:03:57,239
attributes for example here we can see

99
00:03:57,239 --> 00:03:59,819
that the individuals were asked for a

100
00:03:59,819 --> 00:04:01,620
question of like whether they watched

101
00:04:01,620 --> 00:04:04,200
any x-rated movies in the last one year

102
00:04:04,200 --> 00:04:06,360
so this is a sensitive information and

103
00:04:06,360 --> 00:04:09,239
of course when we train the model we

104
00:04:09,239 --> 00:04:12,420
don't want an adversary to reconstruct

105
00:04:12,420 --> 00:04:14,819
what an individual answered to this

106
00:04:14,819 --> 00:04:16,320
question it's this is a privacy

107
00:04:16,320 --> 00:04:17,660
violation

108
00:04:17,660 --> 00:04:20,519
so let's take a closer look at the

109
00:04:20,519 --> 00:04:24,060
existing attacks and differences

110
00:04:24,060 --> 00:04:26,400
um so if we look at the existing attacks

111
00:04:26,400 --> 00:04:28,560
they heavily depend on the confidence

112
00:04:28,560 --> 00:04:32,520
scores that are output by the model and

113
00:04:32,520 --> 00:04:35,340
in response to that there has been a

114
00:04:35,340 --> 00:04:37,800
number of research that tries to propose

115
00:04:37,800 --> 00:04:40,860
defenses so one of the defense proposes

116
00:04:40,860 --> 00:04:41,900
that

117
00:04:41,900 --> 00:04:44,520
you reduce the Precision of the

118
00:04:44,520 --> 00:04:46,160
confidences course

119
00:04:46,160 --> 00:04:49,979
some propose to remove the confidence

120
00:04:49,979 --> 00:04:52,680
course just the highest one just

121
00:04:52,680 --> 00:04:54,840
revealing the highest one and also there

122
00:04:54,840 --> 00:04:57,540
are defenses for sensitive attribute

123
00:04:57,540 --> 00:04:59,460
interference where you perturb the

124
00:04:59,460 --> 00:05:01,380
confidence score so that the adversary

125
00:05:01,380 --> 00:05:05,040
cannot perform a gradient based attack

126
00:05:05,040 --> 00:05:07,680
so what we did is that we wanted to see

127
00:05:07,680 --> 00:05:10,860
what if the model does not

128
00:05:10,860 --> 00:05:13,380
output the confidence course at all and

129
00:05:13,380 --> 00:05:16,139
only the labels so we wanted to design a

130
00:05:16,139 --> 00:05:17,699
label only model inversion attribute

131
00:05:17,699 --> 00:05:19,560
inference attack which assumes least

132
00:05:19,560 --> 00:05:22,259
access earliest knowledge of the

133
00:05:22,259 --> 00:05:24,419
adversary while attacking the target

134
00:05:24,419 --> 00:05:27,840
models so we call this attack Lumia

135
00:05:27,840 --> 00:05:29,580
so I will give you a quick intuition of

136
00:05:29,580 --> 00:05:32,280
how this attack works so this is the

137
00:05:32,280 --> 00:05:34,440
Target Model as we talked about it so X1

138
00:05:34,440 --> 00:05:36,660
through xn are the input attributes Y is

139
00:05:36,660 --> 00:05:38,580
the output attribute so without loss of

140
00:05:38,580 --> 00:05:40,560
generative we assume that X1 is the

141
00:05:40,560 --> 00:05:42,300
sensitive attribute that the adversary

142
00:05:42,300 --> 00:05:46,139
is interested in reconstructing

143
00:05:46,199 --> 00:05:50,160
and so in our attack we train an attack

144
00:05:50,160 --> 00:05:51,060
model

145
00:05:51,060 --> 00:05:54,060
which is which takes uh input the

146
00:05:54,060 --> 00:05:56,639
non-sensitive attributes x23 x n and y

147
00:05:56,639 --> 00:05:59,460
and tries to predict the sensitive

148
00:05:59,460 --> 00:06:01,979
attribute value which is the X1 so here

149
00:06:01,979 --> 00:06:03,780
for the Simplicity I assume that there

150
00:06:03,780 --> 00:06:05,520
is just one sensitive attribute but in

151
00:06:05,520 --> 00:06:07,259
the paper we consider multiple sensitive

152
00:06:07,259 --> 00:06:10,620
attributes where X1 X2 X3 all three

153
00:06:10,620 --> 00:06:12,419
could be sensitive attributes that the

154
00:06:12,419 --> 00:06:15,360
adversary is trying to predict and also

155
00:06:15,360 --> 00:06:18,000
we take instances where the sensitive

156
00:06:18,000 --> 00:06:19,740
attributes could be multi-valued not

157
00:06:19,740 --> 00:06:22,500
only the binary so so far the existing

158
00:06:22,500 --> 00:06:24,300
attacks have only looked at one

159
00:06:24,300 --> 00:06:26,639
sensitive attribute only binary one so

160
00:06:26,639 --> 00:06:29,880
we wanted to see how our attack expands

161
00:06:29,880 --> 00:06:32,639
to this scenarios as well

162
00:06:32,639 --> 00:06:35,819
so ah as I said that we have an attack

163
00:06:35,819 --> 00:06:37,680
model so the next question is how do we

164
00:06:37,680 --> 00:06:39,960
train the attack model

165
00:06:39,960 --> 00:06:41,880
so we assume that the adversity has

166
00:06:41,880 --> 00:06:44,039
access to some instances but of course

167
00:06:44,039 --> 00:06:46,380
it does not know the x-movie column of

168
00:06:46,380 --> 00:06:47,639
the instances because this is the

169
00:06:47,639 --> 00:06:49,259
attribute value that they want to

170
00:06:49,259 --> 00:06:50,400
deconstruct

171
00:06:50,400 --> 00:06:52,860
and let's say that we take an instance

172
00:06:52,860 --> 00:06:55,319
from this available data set that is

173
00:06:55,319 --> 00:06:58,259
available to the adversary and then it

174
00:06:58,259 --> 00:06:58,979
um

175
00:06:58,979 --> 00:07:01,319
queries the target model which predicts

176
00:07:01,319 --> 00:07:04,080
the happiness marital happiness for

177
00:07:04,080 --> 00:07:06,360
individuals and then it

178
00:07:06,360 --> 00:07:08,699
tries with all possible values of the

179
00:07:08,699 --> 00:07:11,280
sensitive attribute that is X no and XCS

180
00:07:11,280 --> 00:07:14,280
for this typical example

181
00:07:14,280 --> 00:07:17,520
so as you can see that with X no the

182
00:07:17,520 --> 00:07:19,979
model outputs the correct marginal

183
00:07:19,979 --> 00:07:22,759
happiness that is very happy and uh with

184
00:07:22,759 --> 00:07:25,259
a different attribute it says pretty

185
00:07:25,259 --> 00:07:28,139
happy which is not the actual label of

186
00:07:28,139 --> 00:07:32,280
the instance so from here the adversity

187
00:07:32,280 --> 00:07:34,979
can estimate X node to be the sensitive

188
00:07:34,979 --> 00:07:37,800
attribute value so with the data set

189
00:07:37,800 --> 00:07:39,919
that it has it queries the model

190
00:07:39,919 --> 00:07:42,900
multiple times and then it tries to

191
00:07:42,900 --> 00:07:44,819
estimate the sensitive attribute value

192
00:07:44,819 --> 00:07:47,039
for all the instances that it has access

193
00:07:47,039 --> 00:07:50,940
to so once uh it does through it goes

194
00:07:50,940 --> 00:07:54,240
through this process it obtains

195
00:07:54,240 --> 00:07:56,580
this data set where on the left side you

196
00:07:56,580 --> 00:07:58,020
have all the non-sensitive attributes

197
00:07:58,020 --> 00:08:00,780
and the right side has the sensitive

198
00:08:00,780 --> 00:08:03,419
attribute so this this way uh the

199
00:08:03,419 --> 00:08:04,979
adversity obtains the attack model

200
00:08:04,979 --> 00:08:07,259
training data set and finally trains the

201
00:08:07,259 --> 00:08:10,139
attack model that it can use for any new

202
00:08:10,139 --> 00:08:13,199
instance to perform the attack

203
00:08:13,199 --> 00:08:17,340
so as I said how this strategy executes

204
00:08:17,340 --> 00:08:19,740
once you have an instance you want to

205
00:08:19,740 --> 00:08:21,780
predict the sensitive attribute for you

206
00:08:21,780 --> 00:08:23,759
just query the attack model and it

207
00:08:23,759 --> 00:08:25,919
predicts the sensitive attribute for you

208
00:08:25,919 --> 00:08:28,680
so we don't have to access the Target

209
00:08:28,680 --> 00:08:30,660
Model anymore while we are performing

210
00:08:30,660 --> 00:08:32,520
the attack so the attack once we train

211
00:08:32,520 --> 00:08:34,740
the attack model we are we can use it

212
00:08:34,740 --> 00:08:38,899
for the sensitive attribute inference

213
00:08:38,940 --> 00:08:40,860
um so for the experiment setup we used

214
00:08:40,860 --> 00:08:42,719
three real data sets uh the General

215
00:08:42,719 --> 00:08:44,700
Social Survey the example that I give

216
00:08:44,700 --> 00:08:48,480
the adult data set 538 data sets these

217
00:08:48,480 --> 00:08:50,640
are used in the existing research as

218
00:08:50,640 --> 00:08:51,360
well

219
00:08:51,360 --> 00:08:54,480
also we trained different types of ml

220
00:08:54,480 --> 00:08:55,920
models to understand the

221
00:08:55,920 --> 00:08:58,500
generalizability of our attack so we

222
00:08:58,500 --> 00:09:00,180
used decision tree models and deep

223
00:09:00,180 --> 00:09:03,120
neural network models also we used the

224
00:09:03,120 --> 00:09:05,399
BML platform for training these models

225
00:09:05,399 --> 00:09:08,940
and um which is uh again a big tech

226
00:09:08,940 --> 00:09:11,279
company that provides this ml as a

227
00:09:11,279 --> 00:09:13,200
service systems and make the models

228
00:09:13,200 --> 00:09:16,080
public once these are trained

229
00:09:16,080 --> 00:09:18,300
um so if we look at the attack results

230
00:09:18,300 --> 00:09:20,580
so

231
00:09:20,580 --> 00:09:22,680
the paper has many results so this is a

232
00:09:22,680 --> 00:09:24,660
concise version of the results this is

233
00:09:24,660 --> 00:09:26,940
the General Social Survey data set

234
00:09:26,940 --> 00:09:28,800
result where the sensitive attribute is

235
00:09:28,800 --> 00:09:30,600
whether the individuals watched the

236
00:09:30,600 --> 00:09:33,480
x-rated movies and we present the

237
00:09:33,480 --> 00:09:34,980
results for both musician tree and deep

238
00:09:34,980 --> 00:09:36,959
neural network so if we compare our

239
00:09:36,959 --> 00:09:39,480
results with the existing work we can

240
00:09:39,480 --> 00:09:42,240
see that our attack is more stable when

241
00:09:42,240 --> 00:09:45,959
we change the type of model so the FJR

242
00:09:45,959 --> 00:09:48,000
Mia existing attack didn't perform well

243
00:09:48,000 --> 00:09:50,220
when we went to the Deep neural network

244
00:09:50,220 --> 00:09:52,740
models it was designed not designed but

245
00:09:52,740 --> 00:09:55,459
it was evaluated in decision tree models

246
00:09:55,459 --> 00:09:57,839
also these are the results for the adult

247
00:09:57,839 --> 00:09:59,760
data set where the sensitive attribute

248
00:09:59,760 --> 00:10:01,320
is the management of the status so the

249
00:10:01,320 --> 00:10:03,600
adversary is trying to predict the

250
00:10:03,600 --> 00:10:05,399
marital status of the individuals in the

251
00:10:05,399 --> 00:10:07,920
data set so we can also see that our

252
00:10:07,920 --> 00:10:10,160
attacks outperform

253
00:10:10,160 --> 00:10:13,740
the existing attack we also have some

254
00:10:13,740 --> 00:10:15,480
baseline attacks for example random

255
00:10:15,480 --> 00:10:16,980
attacks and knife attacks in our paper

256
00:10:16,980 --> 00:10:18,839
but I'm not going through all that here

257
00:10:18,839 --> 00:10:21,420
so please go to through the paper if

258
00:10:21,420 --> 00:10:23,120
you're interested

259
00:10:23,120 --> 00:10:25,200
so one

260
00:10:25,200 --> 00:10:27,300
interesting phenomenon that we observed

261
00:10:27,300 --> 00:10:31,680
in our experiments is that so all these

262
00:10:31,680 --> 00:10:33,420
machine learning privacy attacks are

263
00:10:33,420 --> 00:10:35,580
evaluated on the overall training data

264
00:10:35,580 --> 00:10:36,540
set

265
00:10:36,540 --> 00:10:40,200
so we wanted to see whether this is a

266
00:10:40,200 --> 00:10:43,380
good way to evaluate the ml privacy

267
00:10:43,380 --> 00:10:46,320
attacks so we looked at how this attack

268
00:10:46,320 --> 00:10:49,920
performs on different subgroups for

269
00:10:49,920 --> 00:10:52,440
example if we divide the training data

270
00:10:52,440 --> 00:10:55,740
set in terms of the gender whether the

271
00:10:55,740 --> 00:10:57,779
attacks are similar over this two

272
00:10:57,779 --> 00:11:00,360
subgroups but we saw that there exists

273
00:11:00,360 --> 00:11:01,820
this disparity

274
00:11:01,820 --> 00:11:04,920
the female individuals where for the

275
00:11:04,920 --> 00:11:06,720
female individuals the attack accuracy

276
00:11:06,720 --> 00:11:08,820
was around 85 percent whereas for the

277
00:11:08,820 --> 00:11:12,240
male ones it was around 60 so it it it

278
00:11:12,240 --> 00:11:14,700
is a more concerning thing because

279
00:11:14,700 --> 00:11:17,519
privacy should be equal for each

280
00:11:17,519 --> 00:11:20,459
individual and here we can see that it's

281
00:11:20,459 --> 00:11:24,300
not so even if after an attack we see

282
00:11:24,300 --> 00:11:26,100
that the accuracy is not that high it's

283
00:11:26,100 --> 00:11:28,740
it's not that we we have preserved the

284
00:11:28,740 --> 00:11:30,660
privacy of everyone we have to look at

285
00:11:30,660 --> 00:11:33,480
each individual or the subgroups to

286
00:11:33,480 --> 00:11:36,300
understand the vulnerability so we uh we

287
00:11:36,300 --> 00:11:38,579
observed this uh phenomenon not only in

288
00:11:38,579 --> 00:11:41,279
terms of gender but also we saw that uh

289
00:11:41,279 --> 00:11:43,740
disparity for different races so for

290
00:11:43,740 --> 00:11:45,180
example the black race was more

291
00:11:45,180 --> 00:11:47,459
vulnerable than the white race also in

292
00:11:47,459 --> 00:11:49,560
terms of religions we saw that there is

293
00:11:49,560 --> 00:11:52,800
a clear difference among the subgroups

294
00:11:52,800 --> 00:11:55,140
there are more results also where we can

295
00:11:55,140 --> 00:11:57,420
see that in terms of occupations there

296
00:11:57,420 --> 00:11:59,040
are different vulnerabilities for

297
00:11:59,040 --> 00:12:00,360
Education levels there are different

298
00:12:00,360 --> 00:12:02,459
vulnerabilities

299
00:12:02,459 --> 00:12:04,620
um also we conducted some experiments

300
00:12:04,620 --> 00:12:07,920
where we tried to reduce uh the

301
00:12:07,920 --> 00:12:11,339
knowledge of the adversary so we reduced

302
00:12:11,339 --> 00:12:12,720
the knowledge of non-sensitive

303
00:12:12,720 --> 00:12:14,940
attributes as well for the adversary to

304
00:12:14,940 --> 00:12:17,339
see how our attack extends to this

305
00:12:17,339 --> 00:12:20,640
partial knowledge attack but we saw that

306
00:12:20,640 --> 00:12:23,100
the attack performance did not degrade

307
00:12:23,100 --> 00:12:24,560
much when

308
00:12:24,560 --> 00:12:26,640
increasingly more non-sensitive

309
00:12:26,640 --> 00:12:29,040
attributes became unavailable to the

310
00:12:29,040 --> 00:12:31,079
adversity so as you can see that we

311
00:12:31,079 --> 00:12:32,060
removed

312
00:12:32,060 --> 00:12:34,620
one through ninth nonsensitive

313
00:12:34,620 --> 00:12:36,120
attributes from the adversaries

314
00:12:36,120 --> 00:12:37,860
knowledge but we can see that the

315
00:12:37,860 --> 00:12:39,660
Precision recall in a phone score for

316
00:12:39,660 --> 00:12:41,940
attacks did not degrade much so this is

317
00:12:41,940 --> 00:12:44,459
this shows another

318
00:12:44,459 --> 00:12:47,399
um threat because in in real life

319
00:12:47,399 --> 00:12:49,260
diversary might not know all the

320
00:12:49,260 --> 00:12:51,420
nonsensitive attributes but even with

321
00:12:51,420 --> 00:12:53,279
that knowledge it's possible to perform

322
00:12:53,279 --> 00:12:55,800
very powerful attacks and reconstruct

323
00:12:55,800 --> 00:12:57,540
the sensitive attributes in the data

324
00:12:57,540 --> 00:12:59,100
sets

325
00:12:59,100 --> 00:13:02,820
so to conclude we designed a novel model

326
00:13:02,820 --> 00:13:05,040
version attack strategy which is uh

327
00:13:05,040 --> 00:13:06,899
designed for the Black Box access and

328
00:13:06,899 --> 00:13:10,620
also we reduced it to only label only we

329
00:13:10,620 --> 00:13:12,480
so we show this uh disparate

330
00:13:12,480 --> 00:13:14,399
vulnerability phenomenon and also where

331
00:13:14,399 --> 00:13:16,320
we reduce the nonsense non-sensitive

332
00:13:16,320 --> 00:13:19,260
attribute access of the adversary we

333
00:13:19,260 --> 00:13:21,180
experimented with a different ml model

334
00:13:21,180 --> 00:13:23,579
types to check the generalizability of

335
00:13:23,579 --> 00:13:25,620
our attacks and there are much more

336
00:13:25,620 --> 00:13:27,420
results in the paper if you're

337
00:13:27,420 --> 00:13:29,160
interested please take a look at that

338
00:13:29,160 --> 00:13:33,000
and with that I wanted to share with you

339
00:13:33,000 --> 00:13:35,880
that the code and data sets and all the

340
00:13:35,880 --> 00:13:39,540
modules are available on our GitHub

341
00:13:39,540 --> 00:13:42,779
website and the artifact is evaluated

342
00:13:42,779 --> 00:13:44,760
for being functional and reproducible so

343
00:13:44,760 --> 00:13:46,860
please feel free I know that this is the

344
00:13:46,860 --> 00:13:49,860
last Talk of the confidence but if you

345
00:13:49,860 --> 00:13:52,260
have questions feel free to email me to

346
00:13:52,260 --> 00:13:54,720
further discuss so I'd be happy to take

347
00:13:54,720 --> 00:13:56,220
any questions at this point and thank

348
00:13:56,220 --> 00:13:59,480
you all for listening

