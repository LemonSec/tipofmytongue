1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:08,960 --> 00:00:11,519
today I'll talk to you about proof

3
00:00:11,519 --> 00:00:13,380
concurrency in our new authenticated

4
00:00:13,380 --> 00:00:14,940
dictionary aardvark

5
00:00:14,940 --> 00:00:16,740
this was a collaboration that began at

6
00:00:16,740 --> 00:00:19,619
algorand Inc

7
00:00:19,619 --> 00:00:21,539
a cryptocurrency is a payment system

8
00:00:21,539 --> 00:00:23,939
that runs on a distributed network of

9
00:00:23,939 --> 00:00:26,100
computers called validators a

10
00:00:26,100 --> 00:00:28,439
cryptocurrency maintains a mapping from

11
00:00:28,439 --> 00:00:31,560
users public keys to their balances

12
00:00:31,560 --> 00:00:33,960
suppose I would like to invest in tulips

13
00:00:33,960 --> 00:00:37,140
to become obscenely wealthy to pay the

14
00:00:37,140 --> 00:00:39,180
florist I sign a transaction with my

15
00:00:39,180 --> 00:00:41,100
secret key and then submit it to the

16
00:00:41,100 --> 00:00:43,079
validators

17
00:00:43,079 --> 00:00:44,879
because many users may be submitting

18
00:00:44,879 --> 00:00:46,260
transactions at the same time the

19
00:00:46,260 --> 00:00:48,180
validators execute a consensus protocol

20
00:00:48,180 --> 00:00:50,520
determine which transaction to execute

21
00:00:50,520 --> 00:00:52,940
next

22
00:00:53,039 --> 00:00:55,260
one issue in this setting is that as

23
00:00:55,260 --> 00:00:57,899
many users join the system the mapping

24
00:00:57,899 --> 00:00:59,760
can become very large which increases

25
00:00:59,760 --> 00:01:02,100
storage costs on the validators

26
00:01:02,100 --> 00:01:04,199
we can try to fix this problem by moving

27
00:01:04,199 --> 00:01:06,240
this mapping off of the validators onto

28
00:01:06,240 --> 00:01:08,640
untrusted third-party machines called

29
00:01:08,640 --> 00:01:11,340
archives which have a lot of storage

30
00:01:11,340 --> 00:01:13,439
one example of an archival service could

31
00:01:13,439 --> 00:01:15,420
be a Content distribution Network for

32
00:01:15,420 --> 00:01:17,460
example

33
00:01:17,460 --> 00:01:20,280
uh in this design I first query the

34
00:01:20,280 --> 00:01:23,040
archive for my balance State and then

35
00:01:23,040 --> 00:01:24,960
before I submit my transaction I attach

36
00:01:24,960 --> 00:01:27,299
this balance State and submit it to the

37
00:01:27,299 --> 00:01:29,280
validators

38
00:01:29,280 --> 00:01:32,580
uh for a transfer you actually need two

39
00:01:32,580 --> 00:01:34,140
balanced States one for the sender and

40
00:01:34,140 --> 00:01:35,820
one for the receiver for this talk I'll

41
00:01:35,820 --> 00:01:38,100
just focus on a single key transaction

42
00:01:38,100 --> 00:01:41,220
due to simplify things

43
00:01:41,220 --> 00:01:43,740
so one unfortunate part about this

44
00:01:43,740 --> 00:01:45,240
design is that the archives could be

45
00:01:45,240 --> 00:01:46,979
malicious and tamper with the state and

46
00:01:46,979 --> 00:01:48,780
the map mapping and return the wrong

47
00:01:48,780 --> 00:01:51,000
result for my balance to prevent this

48
00:01:51,000 --> 00:01:52,439
from happening we can use a data

49
00:01:52,439 --> 00:01:53,939
structure called an authenticated

50
00:01:53,939 --> 00:01:55,740
dictionary one example of an

51
00:01:55,740 --> 00:01:57,060
authenticated dictionary could be a

52
00:01:57,060 --> 00:01:58,979
Merkle tree

53
00:01:58,979 --> 00:02:01,439
in this design we'll have the validators

54
00:02:01,439 --> 00:02:04,020
store a small commitment called C that

55
00:02:04,020 --> 00:02:06,719
corresponds to the state of the mapping

56
00:02:06,719 --> 00:02:08,639
and to prevent the archives from lying

57
00:02:08,639 --> 00:02:10,560
the validators will require them to

58
00:02:10,560 --> 00:02:12,720
return a small proof pie which can be

59
00:02:12,720 --> 00:02:17,660
verified against C and the balance state

60
00:02:17,700 --> 00:02:20,280
uh when a transaction is executed the

61
00:02:20,280 --> 00:02:21,900
balance state will change so the

62
00:02:21,900 --> 00:02:25,319
validators will also need to update C

63
00:02:25,319 --> 00:02:26,940
we can make a couple observations about

64
00:02:26,940 --> 00:02:29,760
this system at the high level uh first

65
00:02:29,760 --> 00:02:31,980
is we want uh for the from for

66
00:02:31,980 --> 00:02:34,200
transactions to have a low end-to-end

67
00:02:34,200 --> 00:02:36,720
latency from the perspective of the user

68
00:02:36,720 --> 00:02:38,580
even when many users are submitting

69
00:02:38,580 --> 00:02:40,260
transactions at the same time so we want

70
00:02:40,260 --> 00:02:42,060
High throughput

71
00:02:42,060 --> 00:02:44,040
the second observation is that uh the

72
00:02:44,040 --> 00:02:45,720
validators which are executing a

73
00:02:45,720 --> 00:02:47,459
consensus protocol are often

74
00:02:47,459 --> 00:02:49,260
bottlenecked by the amount of available

75
00:02:49,260 --> 00:02:51,420
bandwidth in the system

76
00:02:51,420 --> 00:02:52,980
so we can translate these two

77
00:02:52,980 --> 00:02:55,260
observations into two corresponding

78
00:02:55,260 --> 00:02:58,500
requirements we want our proofs to both

79
00:02:58,500 --> 00:03:01,319
have a low overhead for producing and

80
00:03:01,319 --> 00:03:03,959
verifying proofs and we also want the

81
00:03:03,959 --> 00:03:05,940
transmission overhead the proof size to

82
00:03:05,940 --> 00:03:09,140
to be low as well

83
00:03:09,300 --> 00:03:11,580
an advantage of hash based authenticated

84
00:03:11,580 --> 00:03:13,739
dictionaries such as Merkle trees is

85
00:03:13,739 --> 00:03:15,840
that the computational cost as compared

86
00:03:15,840 --> 00:03:18,239
to verifying the digital signature is

87
00:03:18,239 --> 00:03:20,220
almost free or just Computing a bunch of

88
00:03:20,220 --> 00:03:23,879
hashes however uh proofs are relatively

89
00:03:23,879 --> 00:03:26,159
large here for instance if you're with

90
00:03:26,159 --> 00:03:29,400
128 bits of security uh proof and a

91
00:03:29,400 --> 00:03:31,260
mapping with a billion elements is about

92
00:03:31,260 --> 00:03:33,480
a kilobyte in size while a transaction

93
00:03:33,480 --> 00:03:36,239
could just be a tenth of that size

94
00:03:36,239 --> 00:03:38,220
an alternative is to use pairing-based

95
00:03:38,220 --> 00:03:40,019
authenticated dictionaries uh such as

96
00:03:40,019 --> 00:03:41,879
with Vector commitments I hear the

97
00:03:41,879 --> 00:03:43,620
transmission costs are very cheap but

98
00:03:43,620 --> 00:03:45,780
the computational costs can be quite

99
00:03:45,780 --> 00:03:48,780
substantial because these uh rely on

100
00:03:48,780 --> 00:03:51,180
operations on pairing friendly elliptic

101
00:03:51,180 --> 00:03:52,920
curves

102
00:03:52,920 --> 00:03:55,500
uh so what I'd like to give you is an

103
00:03:55,500 --> 00:03:57,239
authenticated dictionary with almost

104
00:03:57,239 --> 00:04:00,060
free computational costs and very low

105
00:04:00,060 --> 00:04:01,860
transmission costs but uh we weren't

106
00:04:01,860 --> 00:04:03,599
quite able to do that we couldn't find a

107
00:04:03,599 --> 00:04:05,280
silver bullet so instead I'll tell you

108
00:04:05,280 --> 00:04:08,459
about how we enable parallelism uh to

109
00:04:08,459 --> 00:04:11,939
manage these high computational costs

110
00:04:11,939 --> 00:04:14,040
to summarize our contributions we

111
00:04:14,040 --> 00:04:15,659
designed Aardvark an authenticated

112
00:04:15,659 --> 00:04:17,579
dictionary with short proofs and short

113
00:04:17,579 --> 00:04:20,040
commitments the Insight that allows us

114
00:04:20,040 --> 00:04:21,418
to build an authenticated dictionary

115
00:04:21,418 --> 00:04:23,400
from Vector commitments is that we

116
00:04:23,400 --> 00:04:25,259
enable short proofs of an item's

117
00:04:25,259 --> 00:04:28,620
non-membership in the dictionary

118
00:04:28,620 --> 00:04:30,479
our second contribution is that Aardvark

119
00:04:30,479 --> 00:04:32,580
provides low latency at high throughput

120
00:04:32,580 --> 00:04:34,620
and does this with techniques from

121
00:04:34,620 --> 00:04:36,720
transactional concurrency control in

122
00:04:36,720 --> 00:04:38,940
particular today I'm going to talk about

123
00:04:38,940 --> 00:04:41,940
how we version the state in Aardvark to

124
00:04:41,940 --> 00:04:44,040
to achieve this

125
00:04:44,040 --> 00:04:45,600
I'll give some background first on

126
00:04:45,600 --> 00:04:48,720
Vector commitments uh let V be a vector

127
00:04:48,720 --> 00:04:50,820
of fixed size the commit operation

128
00:04:50,820 --> 00:04:54,060
creates a small commitment C out of V

129
00:04:54,060 --> 00:04:56,639
let I be an index into V and let VI be

130
00:04:56,639 --> 00:04:59,400
the element at that index open creates a

131
00:04:59,400 --> 00:05:02,759
proof pi and verify takes in an i a v i

132
00:05:02,759 --> 00:05:04,680
and a pie and checks that it was

133
00:05:04,680 --> 00:05:07,919
correctly created with respect to some C

134
00:05:07,919 --> 00:05:10,199
there are two additional operations that

135
00:05:10,199 --> 00:05:12,000
these Vector commitments support proof

136
00:05:12,000 --> 00:05:13,979
update and commit update which update a

137
00:05:13,979 --> 00:05:15,479
proof and a commitment respectively

138
00:05:15,479 --> 00:05:20,300
given an update in the underlying vector

139
00:05:20,460 --> 00:05:23,039
the advantage of the vector commitments

140
00:05:23,039 --> 00:05:25,860
that arvark uses over over Merkle trees

141
00:05:25,860 --> 00:05:27,479
is that the proofs are very small

142
00:05:27,479 --> 00:05:30,240
they're only 48 bytes large

143
00:05:30,240 --> 00:05:32,400
unfortunately these operations are much

144
00:05:32,400 --> 00:05:33,300
slower

145
00:05:33,300 --> 00:05:35,580
for instance for vectors with a thousand

146
00:05:35,580 --> 00:05:37,500
elements the open operation could be

147
00:05:37,500 --> 00:05:39,060
more than four orders of magnitude

148
00:05:39,060 --> 00:05:41,039
slower than the corresponding operation

149
00:05:41,039 --> 00:05:43,820
in a Merkle tree

150
00:05:44,160 --> 00:05:45,600
I'm going to go into a little more

151
00:05:45,600 --> 00:05:48,900
detail as to why these high operation

152
00:05:48,900 --> 00:05:51,120
computational costs are such a problem

153
00:05:51,120 --> 00:05:54,060
in in the setting suppose the validators

154
00:05:54,060 --> 00:05:58,020
hold a commitment C that corresponds to

155
00:05:58,020 --> 00:06:01,979
a mapping from K1 to V1 and K2 to V2

156
00:06:01,979 --> 00:06:04,320
suppose we have two clients that issue

157
00:06:04,320 --> 00:06:07,020
simultaneous queries to the archive for

158
00:06:07,020 --> 00:06:09,780
K1 and K2 respectively and the archives

159
00:06:09,780 --> 00:06:12,180
respond to this query by using the open

160
00:06:12,180 --> 00:06:15,919
operation to produce the proofs

161
00:06:16,020 --> 00:06:17,580
when the validators execute the

162
00:06:17,580 --> 00:06:19,620
transaction from the first user the

163
00:06:19,620 --> 00:06:22,560
commitment will update to C prime using

164
00:06:22,560 --> 00:06:24,840
using the commit update operation and

165
00:06:24,840 --> 00:06:27,479
the problem is that the second client

166
00:06:27,479 --> 00:06:29,280
will have an old proof against the

167
00:06:29,280 --> 00:06:30,780
commitment C it can't be verified

168
00:06:30,780 --> 00:06:33,500
against C Prime

169
00:06:33,600 --> 00:06:35,400
so with the interface I gave you one

170
00:06:35,400 --> 00:06:37,139
thought is maybe we can update Pi so

171
00:06:37,139 --> 00:06:38,639
that we can verify it against the new C

172
00:06:38,639 --> 00:06:40,740
Prime the problem with this approach is

173
00:06:40,740 --> 00:06:43,380
that the work required to to implement

174
00:06:43,380 --> 00:06:46,319
such a policy scales quadratically with

175
00:06:46,319 --> 00:06:48,120
the number of outstanding transactions

176
00:06:48,120 --> 00:06:49,800
of the system and this can create a

177
00:06:49,800 --> 00:06:51,360
bottleneck for for the system-wide

178
00:06:51,360 --> 00:06:52,560
throughput

179
00:06:52,560 --> 00:06:55,139
in particular uh anytime a transaction

180
00:06:55,139 --> 00:06:57,419
is executed all the proofs in the system

181
00:06:57,419 --> 00:06:59,340
become instantly outdated and these

182
00:06:59,340 --> 00:07:01,500
proofs must be updated before their

183
00:07:01,500 --> 00:07:05,060
corresponding transactions can execute

184
00:07:05,160 --> 00:07:06,840
specifically we can consider three

185
00:07:06,840 --> 00:07:08,280
different options we can have the

186
00:07:08,280 --> 00:07:10,380
archive rerun open when the proof is

187
00:07:10,380 --> 00:07:12,060
outdated or the client or validated or

188
00:07:12,060 --> 00:07:13,680
run proof update

189
00:07:13,680 --> 00:07:15,780
if the archivery runs open then the

190
00:07:15,780 --> 00:07:17,400
client needs to send a new request to

191
00:07:17,400 --> 00:07:21,060
the archive on every update to the state

192
00:07:21,060 --> 00:07:23,460
and this will add many additional round

193
00:07:23,460 --> 00:07:25,020
trips

194
00:07:25,020 --> 00:07:26,880
if it's the client's job to maintain the

195
00:07:26,880 --> 00:07:28,199
freshness of the proof then the clients

196
00:07:28,199 --> 00:07:30,000
need to hear all the updates and this

197
00:07:30,000 --> 00:07:32,280
can be very expensive for a client that

198
00:07:32,280 --> 00:07:34,860
might be resource constrained

199
00:07:34,860 --> 00:07:36,900
finally suppose that the validator's job

200
00:07:36,900 --> 00:07:38,940
is to execute proof update

201
00:07:38,940 --> 00:07:41,460
so in this system consider that at the

202
00:07:41,460 --> 00:07:43,080
validator we're going to have a backlog

203
00:07:43,080 --> 00:07:45,900
of transactions basically build up and

204
00:07:45,900 --> 00:07:49,020
uh as this backlog grows the work

205
00:07:49,020 --> 00:07:51,060
required to process any additional

206
00:07:51,060 --> 00:07:53,280
transaction also grows

207
00:07:53,280 --> 00:07:55,800
this creates a positive feedback loop

208
00:07:55,800 --> 00:07:57,660
because all the proofs must be updated

209
00:07:57,660 --> 00:07:59,580
and this can lead to congestion collapse

210
00:07:59,580 --> 00:08:01,740
at the validators

211
00:08:01,740 --> 00:08:04,680
the fundamental problem here is that the

212
00:08:04,680 --> 00:08:07,560
stale proofs for serialization of the

213
00:08:07,560 --> 00:08:10,199
proof related operations this slows the

214
00:08:10,199 --> 00:08:11,400
system down

215
00:08:11,400 --> 00:08:13,680
our Insight is that we can cache Old

216
00:08:13,680 --> 00:08:16,319
State to maximize the opportunities for

217
00:08:16,319 --> 00:08:18,539
the system to take advantage of

218
00:08:18,539 --> 00:08:21,120
parallelism

219
00:08:21,120 --> 00:08:22,979
in particular Aardvark adds to every

220
00:08:22,979 --> 00:08:24,720
commitment and every proof a version

221
00:08:24,720 --> 00:08:25,800
number

222
00:08:25,800 --> 00:08:28,020
when the validators execute the first

223
00:08:28,020 --> 00:08:30,240
client's transaction not only do they

224
00:08:30,240 --> 00:08:32,399
compute the new commitment C Prime at

225
00:08:32,399 --> 00:08:34,380
version two but they also retain the old

226
00:08:34,380 --> 00:08:36,719
commitment C at version one and this

227
00:08:36,719 --> 00:08:38,760
allows them to continue to verify the

228
00:08:38,760 --> 00:08:42,679
stale proof held by the second client

229
00:08:42,779 --> 00:08:44,520
one additional case we want to consider

230
00:08:44,520 --> 00:08:48,120
is if both transactions uh share a key

231
00:08:48,120 --> 00:08:50,760
and in order to handle this case we

232
00:08:50,760 --> 00:08:52,560
require the validators to hold all

233
00:08:52,560 --> 00:08:55,140
recent updates to keys and values

234
00:08:55,140 --> 00:08:57,480
for some time

235
00:08:57,480 --> 00:08:59,040
there's some additional details we must

236
00:08:59,040 --> 00:09:00,899
handle to integrate this versioning

237
00:09:00,899 --> 00:09:04,080
scheme into rvark in particular this

238
00:09:04,080 --> 00:09:06,000
scheme interact interacts non-trivially

239
00:09:06,000 --> 00:09:07,860
with the non-membership proofs that I

240
00:09:07,860 --> 00:09:10,920
didn't describe uh if a proof is created

241
00:09:10,920 --> 00:09:12,839
concurrently with the insertion of a new

242
00:09:12,839 --> 00:09:15,720
key or a deletion of an old key then our

243
00:09:15,720 --> 00:09:18,300
VAR cast to correctly handled this case

244
00:09:18,300 --> 00:09:20,339
and we refer you to the paper for more

245
00:09:20,339 --> 00:09:22,440
details here

246
00:09:22,440 --> 00:09:24,180
for our evaluation we integrated

247
00:09:24,180 --> 00:09:25,920
Aardvark into the algorand

248
00:09:25,920 --> 00:09:28,080
cryptocurrency

249
00:09:28,080 --> 00:09:30,540
we saw that storage cost were reduced by

250
00:09:30,540 --> 00:09:31,920
about three orders of magnitude and

251
00:09:31,920 --> 00:09:35,399
proofs were 100 to 200 bytes size

252
00:09:35,399 --> 00:09:37,380
uh and we wanted to empirically evaluate

253
00:09:37,380 --> 00:09:39,720
how much does the system slow down when

254
00:09:39,720 --> 00:09:42,000
we in when we integrate Aardvark into

255
00:09:42,000 --> 00:09:44,580
into algorand this is a pretty

256
00:09:44,580 --> 00:09:46,560
complicated question is because as you

257
00:09:46,560 --> 00:09:48,839
saw there are many parts to the moving

258
00:09:48,839 --> 00:09:50,640
Parts in the system and so for this talk

259
00:09:50,640 --> 00:09:52,440
I'll focus on the processing costs at

260
00:09:52,440 --> 00:09:55,040
the validators

261
00:09:55,320 --> 00:09:58,380
we evaluated Aardvark on an Amazon ec2

262
00:09:58,380 --> 00:10:01,980
instance we spread out 100 000

263
00:10:01,980 --> 00:10:04,080
operations of various kinds over 10

264
00:10:04,080 --> 00:10:06,959
blocks and we executed them on a

265
00:10:06,959 --> 00:10:09,899
dictionary with a million keys

266
00:10:09,899 --> 00:10:11,279
we found that the processing overhead

267
00:10:11,279 --> 00:10:13,620
for a single one megabyte block was

268
00:10:13,620 --> 00:10:16,560
range from 34 to 68 seconds which is

269
00:10:16,560 --> 00:10:20,580
kind of a lot but we also increased the

270
00:10:20,580 --> 00:10:22,560
number of cores from 1 to 32 and found

271
00:10:22,560 --> 00:10:24,300
that we got an order about an order of

272
00:10:24,300 --> 00:10:26,580
magnitude of speed up the reason the

273
00:10:26,580 --> 00:10:28,860
speed up is imperfect is because not all

274
00:10:28,860 --> 00:10:30,540
the commit update operations are

275
00:10:30,540 --> 00:10:34,339
perfectly parallelized in our prototype

276
00:10:35,279 --> 00:10:37,860
I'll talk a little bit now about related

277
00:10:37,860 --> 00:10:39,959
work other than Merkle trees

278
00:10:39,959 --> 00:10:42,120
so Ed racks and hyperproofs which you

279
00:10:42,120 --> 00:10:43,440
saw yesterday and other vector-based

280
00:10:43,440 --> 00:10:45,360
commitment schemes also have pretty high

281
00:10:45,360 --> 00:10:47,820
costs for computing and verifying proofs

282
00:10:47,820 --> 00:10:49,320
and we believe that aardvark's

283
00:10:49,320 --> 00:10:51,480
versioning mechanism can help us manage

284
00:10:51,480 --> 00:10:54,899
these proofs in these other systems

285
00:10:54,899 --> 00:10:57,180
uh the session chair will be upset at me

286
00:10:57,180 --> 00:10:59,940
if I don't mention zero knowledge uh so

287
00:10:59,940 --> 00:11:02,459
uh ZK Roll-Ups and ZK snarks are another

288
00:11:02,459 --> 00:11:05,519
way to reduce storage costs and here the

289
00:11:05,519 --> 00:11:08,579
verification costs are excellent uh the

290
00:11:08,579 --> 00:11:10,800
process like creating the verification

291
00:11:10,800 --> 00:11:13,860
of proofs and transmission of proofs is

292
00:11:13,860 --> 00:11:15,660
has almost a constant cost and is

293
00:11:15,660 --> 00:11:17,940
extremely efficient the drawback is that

294
00:11:17,940 --> 00:11:19,800
proof creation is relatively slow it's

295
00:11:19,800 --> 00:11:22,380
about an order to order of magnitude

296
00:11:22,380 --> 00:11:24,300
slower per transaction than Vector

297
00:11:24,300 --> 00:11:27,540
commitments and also because these to

298
00:11:27,540 --> 00:11:29,040
get these good verification costs

299
00:11:29,040 --> 00:11:30,959
batching is required

300
00:11:30,959 --> 00:11:32,760
so batching will increase the latency

301
00:11:32,760 --> 00:11:34,800
for transaction

302
00:11:34,800 --> 00:11:37,200
in conclusion uh I described today

303
00:11:37,200 --> 00:11:39,180
Aardvark an authenticated dictionary

304
00:11:39,180 --> 00:11:41,100
with short proofs and short commitments

305
00:11:41,100 --> 00:11:43,560
our Varco cheese low latency at a high

306
00:11:43,560 --> 00:11:45,480
level of throughput by using techniques

307
00:11:45,480 --> 00:11:48,060
from transactional concurrency control

308
00:11:48,060 --> 00:11:49,680
thank you very much for listening to my

309
00:11:49,680 --> 00:11:53,779
talk and I'm happy to take any questions

