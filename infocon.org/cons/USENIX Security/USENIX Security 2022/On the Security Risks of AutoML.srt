1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:10,639 --> 00:00:14,099
pound from Penn State here I'm happy to

3
00:00:14,099 --> 00:00:16,500
present our recent work on the security

4
00:00:16,500 --> 00:00:20,160
risk of automl

5
00:00:20,160 --> 00:00:22,080
so this is the outline of this

6
00:00:22,080 --> 00:00:24,480
presentation I will first talk about

7
00:00:24,480 --> 00:00:27,779
some background knowledge of automl and

8
00:00:27,779 --> 00:00:30,080
the neural network Arc attacks

9
00:00:30,080 --> 00:00:32,759
afterwards I will share some

10
00:00:32,759 --> 00:00:35,700
experimental results to reveal the

11
00:00:35,700 --> 00:00:38,640
vulnerabilities of Auto ml model

12
00:00:38,640 --> 00:00:40,700
architectures

13
00:00:40,700 --> 00:00:43,739
automl uh to explain such

14
00:00:43,739 --> 00:00:46,800
vulnerabilities we conduct a theoretical

15
00:00:46,800 --> 00:00:48,719
analysis

16
00:00:48,719 --> 00:00:51,840
finally we will provide several possible

17
00:00:51,840 --> 00:00:54,360
solutions to mitigate the

18
00:00:54,360 --> 00:00:59,180
vulnerabilities of automl procedures

19
00:00:59,399 --> 00:01:02,940
okay let's start with the background

20
00:01:02,940 --> 00:01:06,720
what is auto ml automl which refers to

21
00:01:06,720 --> 00:01:09,960
Automated machine learning is a very

22
00:01:09,960 --> 00:01:13,640
broad term it contains Auto augmentation

23
00:01:13,640 --> 00:01:17,220
hyper parameter optimization neural

24
00:01:17,220 --> 00:01:20,820
architecture search and so on it has

25
00:01:20,820 --> 00:01:23,700
been widely applied in many industrial

26
00:01:23,700 --> 00:01:25,020
scenarios

27
00:01:25,020 --> 00:01:28,979
for example there is Google's automl and

28
00:01:28,979 --> 00:01:32,400
Amazon's Auto glue

29
00:01:32,400 --> 00:01:35,340
so in this presentation I will only

30
00:01:35,340 --> 00:01:39,240
focus on neural architecture search

31
00:01:39,240 --> 00:01:42,119
so new architecture search which is Nas

32
00:01:42,119 --> 00:01:45,060
in short it searches good architecture

33
00:01:45,060 --> 00:01:46,920
automatically

34
00:01:46,920 --> 00:01:49,020
compared with human design model

35
00:01:49,020 --> 00:01:52,439
architectures such as resnet

36
00:01:52,439 --> 00:01:55,140
only as models tend to have a better

37
00:01:55,140 --> 00:01:59,159
classification accuracy because they are

38
00:01:59,159 --> 00:02:01,920
optimized on the data set

39
00:02:01,920 --> 00:02:05,280
among various kinds of Nas optimization

40
00:02:05,280 --> 00:02:06,780
algorithms

41
00:02:06,780 --> 00:02:09,300
differential architecture search which

42
00:02:09,300 --> 00:02:12,480
is Stars might be the most famous

43
00:02:12,480 --> 00:02:14,280
searching algorithm

44
00:02:14,280 --> 00:02:18,300
it is very efficient and based on sales

45
00:02:18,300 --> 00:02:22,080
for example here is the

46
00:02:22,080 --> 00:02:25,260
here is the figure that shows the basic

47
00:02:25,260 --> 00:02:28,739
workflow of DARS

48
00:02:28,739 --> 00:02:31,680
for the input image it goes through

49
00:02:31,680 --> 00:02:34,020
multiple convolutional cells and the

50
00:02:34,020 --> 00:02:35,580
reduction cells

51
00:02:35,580 --> 00:02:38,940
and finally passes the softmax layer to

52
00:02:38,940 --> 00:02:42,120
Output the probability classification

53
00:02:42,120 --> 00:02:43,620
vector

54
00:02:43,620 --> 00:02:46,019
and on the right side

55
00:02:46,019 --> 00:02:49,080
there is also a figure that shows the

56
00:02:49,080 --> 00:02:53,340
inner structure of DARS

57
00:02:53,340 --> 00:02:56,580
and each cell is composed of several

58
00:02:56,580 --> 00:02:59,760
nodes and all the edges that are connect

59
00:02:59,760 --> 00:03:03,060
nodes are optimizable operations

60
00:03:03,060 --> 00:03:05,280
that means they could be convolutional

61
00:03:05,280 --> 00:03:10,640
layers skip connects or average pooling

62
00:03:11,280 --> 00:03:14,640
so after Auto ml let's go to the neural

63
00:03:14,640 --> 00:03:16,200
network attacks

64
00:03:16,200 --> 00:03:18,360
there are several types of neural

65
00:03:18,360 --> 00:03:21,800
network attacks evasion data poisoning

66
00:03:21,800 --> 00:03:25,500
Vector injection model extraction and

67
00:03:25,500 --> 00:03:26,700
Etc

68
00:03:26,700 --> 00:03:29,280
among all the attacks the most famous

69
00:03:29,280 --> 00:03:32,640
one might be the pgd attack which refers

70
00:03:32,640 --> 00:03:35,760
to projected gradient descent

71
00:03:35,760 --> 00:03:38,940
for the original Panda image which is

72
00:03:38,940 --> 00:03:41,519
classified correctly by the model

73
00:03:41,519 --> 00:03:45,599
classifier with around 60 confidence

74
00:03:45,599 --> 00:03:48,659
the attacker as a small unnoticeable

75
00:03:48,659 --> 00:03:52,319
noise onto the original image and get

76
00:03:52,319 --> 00:03:54,299
the perturbed image

77
00:03:54,299 --> 00:03:57,360
from humans Vision There is almost no

78
00:03:57,360 --> 00:03:59,940
difference between the original image

79
00:03:59,940 --> 00:04:03,000
and the perturbed image because the

80
00:04:03,000 --> 00:04:05,459
perturbed preservation Norm is quite

81
00:04:05,459 --> 00:04:06,599
small

82
00:04:06,599 --> 00:04:08,099
however

83
00:04:08,099 --> 00:04:11,459
for the model classifier it will

84
00:04:11,459 --> 00:04:14,400
classify the perturbed image as given

85
00:04:14,400 --> 00:04:18,120
with almost 100 confidence

86
00:04:18,120 --> 00:04:21,600
there is also the charge attack which is

87
00:04:21,600 --> 00:04:25,139
a kind of back door in checked injection

88
00:04:25,139 --> 00:04:29,040
vectoral attacks aims to inject a

89
00:04:29,040 --> 00:04:31,680
trigger pattern into the model

90
00:04:31,680 --> 00:04:34,259
and all images attached with that

91
00:04:34,259 --> 00:04:36,780
trigger will be misclassified into

92
00:04:36,780 --> 00:04:38,340
Target class

93
00:04:38,340 --> 00:04:41,180
for example in this figure

94
00:04:41,180 --> 00:04:44,820
all images with the Apple Watermark will

95
00:04:44,820 --> 00:04:47,940
be classified as fish oh sorry

96
00:04:47,940 --> 00:04:50,100
as fish

97
00:04:50,100 --> 00:04:52,160
um

98
00:04:52,160 --> 00:04:53,880
okay

99
00:04:53,880 --> 00:04:57,360
so right now we have finished the

100
00:04:57,360 --> 00:04:59,460
background before checking some

101
00:04:59,460 --> 00:05:02,280
experimental results here are the data

102
00:05:02,280 --> 00:05:05,940
sets and models that we use in our paper

103
00:05:05,940 --> 00:05:09,780
for the data sets we use FIFA 10 sifa

104
00:05:09,780 --> 00:05:13,259
100 and also a subset sampled from

105
00:05:13,259 --> 00:05:16,520
imagenet so they are all famous datasets

106
00:05:16,520 --> 00:05:19,919
used in image classification domain

107
00:05:19,919 --> 00:05:22,380
for the model architectures

108
00:05:22,380 --> 00:05:25,440
we use a bunch of state-of-the-art human

109
00:05:25,440 --> 00:05:28,460
design model architectures and also

110
00:05:28,460 --> 00:05:31,699
evaluate a list of automl models

111
00:05:31,699 --> 00:05:37,620
generated by popular Nas algorithms

112
00:05:38,639 --> 00:05:41,160
so these are some key experimental

113
00:05:41,160 --> 00:05:44,820
results to review the vulnerability of

114
00:05:44,820 --> 00:05:48,720
automl models we can easily tell that

115
00:05:48,720 --> 00:05:51,660
there is a clear gap between automl

116
00:05:51,660 --> 00:05:55,139
models and human design models so that

117
00:05:55,139 --> 00:05:58,259
we draw the conclusion that Nas design

118
00:05:58,259 --> 00:06:02,960
models tend to be more vulnerable

119
00:06:04,979 --> 00:06:07,440
so after realizing the vulnerabilities

120
00:06:07,440 --> 00:06:11,039
of automl models we need the explanation

121
00:06:11,039 --> 00:06:13,340
for this phenomenon

122
00:06:13,340 --> 00:06:16,020
therefore we make such theoretical

123
00:06:16,020 --> 00:06:17,400
analysis

124
00:06:17,400 --> 00:06:20,639
it is already known that Nas algorithms

125
00:06:20,639 --> 00:06:25,400
prefer architectures that converge fast

126
00:06:25,639 --> 00:06:28,919
which means they prefer shallow models

127
00:06:28,919 --> 00:06:31,620
with more skip connects

128
00:06:31,620 --> 00:06:34,500
and that preference will lead to the nas

129
00:06:34,500 --> 00:06:37,620
model characteristics which are the high

130
00:06:37,620 --> 00:06:40,680
loss smoothness and the low gradient

131
00:06:40,680 --> 00:06:41,819
variance

132
00:06:41,819 --> 00:06:44,400
and the high loss smoothness can also be

133
00:06:44,400 --> 00:06:48,300
expressed as small ellipses constant

134
00:06:48,300 --> 00:06:51,539
to validate our hyposis we evaluate the

135
00:06:51,539 --> 00:06:54,360
Lost landscape and the gradient variance

136
00:06:54,360 --> 00:06:56,460
empirically

137
00:06:56,460 --> 00:06:59,819
compared with the complex lost landscape

138
00:06:59,819 --> 00:07:04,380
of human design models which is the left

139
00:07:04,380 --> 00:07:05,280
figure

140
00:07:05,280 --> 00:07:07,220
we can see that

141
00:07:07,220 --> 00:07:10,800
automl models have more convex lost

142
00:07:10,800 --> 00:07:12,180
landscapes

143
00:07:12,180 --> 00:07:14,819
and also from the bar chart

144
00:07:14,819 --> 00:07:17,220
we can also tell that human design

145
00:07:17,220 --> 00:07:20,699
models have larger gradient variance

146
00:07:20,699 --> 00:07:24,800
than automl models

147
00:07:25,740 --> 00:07:28,740
so as a result based on those two

148
00:07:28,740 --> 00:07:32,639
characteristics we can prove that IAS

149
00:07:32,639 --> 00:07:35,699
models are more sensitive to training

150
00:07:35,699 --> 00:07:38,340
data and the gradients are more

151
00:07:38,340 --> 00:07:41,280
effective for optimization

152
00:07:41,280 --> 00:07:43,680
so how to understand this

153
00:07:43,680 --> 00:07:48,599
for example after one step of pgd attack

154
00:07:48,599 --> 00:07:52,319
the loss of automl models will drop more

155
00:07:52,319 --> 00:07:53,099
than

156
00:07:53,099 --> 00:07:56,280
human design models and that that will

157
00:07:56,280 --> 00:07:58,620
makes it easier to attack

158
00:07:58,620 --> 00:08:01,440
so in some sense it is easier to train

159
00:08:01,440 --> 00:08:05,120
but also easier to attack

160
00:08:06,300 --> 00:08:08,400
so since there are the vulnerabilities

161
00:08:08,400 --> 00:08:11,880
for the automl models what could we do

162
00:08:11,880 --> 00:08:13,500
to mitigate

163
00:08:13,500 --> 00:08:16,080
so here we propose several promising

164
00:08:16,080 --> 00:08:19,139
Solutions based on previous model

165
00:08:19,139 --> 00:08:21,000
characteristics

166
00:08:21,000 --> 00:08:24,599
to suppress those characteristics we can

167
00:08:24,599 --> 00:08:27,960
increase the cell deaths and reduce the

168
00:08:27,960 --> 00:08:30,960
number of skip connects

169
00:08:30,960 --> 00:08:33,958
here we design three variants of

170
00:08:33,958 --> 00:08:36,360
original DARS model architecture

171
00:08:36,360 --> 00:08:39,839
the first variant stretches the cell to

172
00:08:39,839 --> 00:08:41,279
make it deeper

173
00:08:41,279 --> 00:08:44,700
the second variant replaces all the skip

174
00:08:44,700 --> 00:08:47,459
connects to convolutional layers which

175
00:08:47,459 --> 00:08:50,459
is from the red to blue

176
00:08:50,459 --> 00:08:54,240
and the the third variant is simply the

177
00:08:54,240 --> 00:08:58,640
combination of the previous approaches

178
00:08:58,920 --> 00:09:01,800
afterwards we evaluate all the variants

179
00:09:01,800 --> 00:09:04,500
together with the original DARS

180
00:09:04,500 --> 00:09:06,740
we can see that all the variants

181
00:09:06,740 --> 00:09:09,360
performs much better than the original

182
00:09:09,360 --> 00:09:11,880
dark model architecture

183
00:09:11,880 --> 00:09:15,360
which means they are more robust against

184
00:09:15,360 --> 00:09:17,880
different attacks

185
00:09:17,880 --> 00:09:20,459
to know that this mitigation approaches

186
00:09:20,459 --> 00:09:23,459
are very naive and we just want to show

187
00:09:23,459 --> 00:09:28,099
a promising future research Direction

188
00:09:28,560 --> 00:09:31,260
okay so finally let's make the

189
00:09:31,260 --> 00:09:34,080
conclusion for this presentation in this

190
00:09:34,080 --> 00:09:36,360
presentation we discover the

191
00:09:36,360 --> 00:09:39,959
vulnerabilities of automl models and

192
00:09:39,959 --> 00:09:43,620
provide a theoretical explanation that

193
00:09:43,620 --> 00:09:46,620
it is because of the high loss

194
00:09:46,620 --> 00:09:50,160
smoothness and low grade invariance

195
00:09:50,160 --> 00:09:53,399
to mitigate the vulnerabilities we

196
00:09:53,399 --> 00:09:56,399
provide possible solutions that is to

197
00:09:56,399 --> 00:10:00,480
build attack robustness into the Ias

198
00:10:00,480 --> 00:10:03,440
architectures

199
00:10:03,480 --> 00:10:05,940
okay so this is my presentation I'm

200
00:10:05,940 --> 00:10:09,019
welcome any question

