1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:07,859 --> 00:00:11,099
hello everyone yes I'm my name is mohsen

3
00:00:11,099 --> 00:00:12,900
and this is a joint work with my

4
00:00:12,900 --> 00:00:14,820
colleagues Monarch mondel from iot

5
00:00:14,820 --> 00:00:17,699
karagpur and my PhD advisor aniket Kate

6
00:00:17,699 --> 00:00:20,100
from Purdue University

7
00:00:20,100 --> 00:00:23,039
over the years social media has become a

8
00:00:23,039 --> 00:00:24,960
platform where individuals share their

9
00:00:24,960 --> 00:00:26,939
thoughts and personal information which

10
00:00:26,939 --> 00:00:30,000
is viewed by a wide variety of audiences

11
00:00:30,000 --> 00:00:33,360
in some cases these contents contain

12
00:00:33,360 --> 00:00:35,120
some damaging or sensitive information

13
00:00:35,120 --> 00:00:37,739
which a malicious data collector can

14
00:00:37,739 --> 00:00:41,599
leverage to exploit the individuals

15
00:00:41,700 --> 00:00:44,640
moreover the steps and actions that us

16
00:00:44,640 --> 00:00:46,680
as users take to change our privacy

17
00:00:46,680 --> 00:00:49,320
preferences or when we want to hide our

18
00:00:49,320 --> 00:00:51,300
unwanted information can help the

19
00:00:51,300 --> 00:00:53,340
malicious entity to discover the

20
00:00:53,340 --> 00:00:56,160
sensitive content this is also known as

21
00:00:56,160 --> 00:00:58,079
the styrosine effect which some of us

22
00:00:58,079 --> 00:01:01,100
might be familiar with

23
00:01:02,219 --> 00:01:04,440
so with that in mind let's look at some

24
00:01:04,440 --> 00:01:06,360
cases where users try to hide their

25
00:01:06,360 --> 00:01:10,320
unwanted information by deleting them

26
00:01:10,320 --> 00:01:12,299
in the first category we have the

27
00:01:12,299 --> 00:01:14,520
publicization of the deleted post of the

28
00:01:14,520 --> 00:01:16,619
celebrities and politicians which most

29
00:01:16,619 --> 00:01:19,799
of us might have seen a few in the news

30
00:01:19,799 --> 00:01:21,960
however we see that this is not limited

31
00:01:21,960 --> 00:01:24,659
to celebrities Philippa Supreme which

32
00:01:24,659 --> 00:01:26,580
translates to should not delete is a

33
00:01:26,580 --> 00:01:28,320
Twitter account that publishes the

34
00:01:28,320 --> 00:01:29,939
deleted tweets of not only celebrities

35
00:01:29,939 --> 00:01:32,640
and politicians but also normal daily

36
00:01:32,640 --> 00:01:35,100
French users for example here you're

37
00:01:35,100 --> 00:01:37,320
seeing a tweet and retweet of an

38
00:01:37,320 --> 00:01:39,960
individual that was removed and this

39
00:01:39,960 --> 00:01:43,500
user has less than 1 000 followers

40
00:01:43,500 --> 00:01:45,659
we also find that the problem associated

41
00:01:45,659 --> 00:01:47,640
with content deletion is not limited to

42
00:01:47,640 --> 00:01:50,100
target attacks in fact there exists

43
00:01:50,100 --> 00:01:52,680
multiple web services that are finding

44
00:01:52,680 --> 00:01:55,259
and hoarding deleted content across

45
00:01:55,259 --> 00:01:57,360
different social platforms some of which

46
00:01:57,360 --> 00:02:00,420
are presented on the slide and later

47
00:02:00,420 --> 00:02:02,399
this information can be used against the

48
00:02:02,399 --> 00:02:04,759
users

49
00:02:05,460 --> 00:02:07,680
uh also by looking into the different

50
00:02:07,680 --> 00:02:10,318
deletion mechanisms we see that deletion

51
00:02:10,318 --> 00:02:12,900
privacy involves designing and enforcing

52
00:02:12,900 --> 00:02:15,780
access control rules to regulate when

53
00:02:15,780 --> 00:02:18,120
and how information about the deletion

54
00:02:18,120 --> 00:02:21,120
events are revealed to others and

55
00:02:21,120 --> 00:02:23,160
unfortunately earlier research did not

56
00:02:23,160 --> 00:02:25,319
attempt to uncover these systematic

57
00:02:25,319 --> 00:02:26,520
access rules

58
00:02:26,520 --> 00:02:28,260
and more specifically there's no prior

59
00:02:28,260 --> 00:02:30,120
work on understanding the need for

60
00:02:30,120 --> 00:02:31,920
providing deletion privacy to the social

61
00:02:31,920 --> 00:02:34,020
media users

62
00:02:34,020 --> 00:02:36,120
so in this work you take the first steps

63
00:02:36,120 --> 00:02:38,760
toward understanding users perception of

64
00:02:38,760 --> 00:02:40,319
deletion privacy

65
00:02:40,319 --> 00:02:42,060
we came up with three main research

66
00:02:42,060 --> 00:02:45,180
questions first is the user's

67
00:02:45,180 --> 00:02:47,459
experiences with deletion on the social

68
00:02:47,459 --> 00:02:50,760
platforms and the second is the content

69
00:02:50,760 --> 00:02:53,400
one what contextual factors do rules

70
00:02:53,400 --> 00:02:55,500
regarding the acceptability of revealing

71
00:02:55,500 --> 00:02:57,540
deletion events depend on

72
00:02:57,540 --> 00:02:59,400
and lastly we want to know whether the

73
00:02:59,400 --> 00:03:02,040
existing mechanisms today are effective

74
00:03:02,040 --> 00:03:04,739
and useful for providing privacy to the

75
00:03:04,739 --> 00:03:06,420
users

76
00:03:06,420 --> 00:03:08,280
to answer our research questions we

77
00:03:08,280 --> 00:03:09,840
conducted a user study on prolific

78
00:03:09,840 --> 00:03:13,260
academic we recruited a total of 205

79
00:03:13,260 --> 00:03:15,500
skilled participants from us and Europe

80
00:03:15,500 --> 00:03:18,599
where our European participants were

81
00:03:18,599 --> 00:03:21,120
from 13 different countries but the

82
00:03:21,120 --> 00:03:24,239
majority of them were from UK followed

83
00:03:24,239 --> 00:03:26,580
by Portugal and Poland

84
00:03:26,580 --> 00:03:28,920
after discarding the responses that did

85
00:03:28,920 --> 00:03:31,500
not pass our validian sanity checks we

86
00:03:31,500 --> 00:03:33,659
ended up with almost a even split

87
00:03:33,659 --> 00:03:36,120
between us and Europe

88
00:03:36,120 --> 00:03:38,760
the survey time took about 25 minutes on

89
00:03:38,760 --> 00:03:40,920
average across all the participants and

90
00:03:40,920 --> 00:03:42,659
we found that our sample was nearly

91
00:03:42,659 --> 00:03:45,000
gender balanced where 51 percent were

92
00:03:45,000 --> 00:03:47,819
identified themselves as female and 48

93
00:03:47,819 --> 00:03:49,200
as male

94
00:03:49,200 --> 00:03:51,060
our participants were slightly more

95
00:03:51,060 --> 00:03:53,220
educated than the general U.S population

96
00:03:53,220 --> 00:03:56,580
where 55 of the participants either had

97
00:03:56,580 --> 00:03:59,040
a bachelor's or a graduate degree

98
00:03:59,040 --> 00:04:01,500
and despite the fact that uh

99
00:04:01,500 --> 00:04:03,480
participants in crowds crowdsourcing

100
00:04:03,480 --> 00:04:05,400
platforms are considered to be very tech

101
00:04:05,400 --> 00:04:09,000
savvy 67 of our participants reported

102
00:04:09,000 --> 00:04:10,439
that they don't have any background

103
00:04:10,439 --> 00:04:12,480
experience in the I.T field

104
00:04:12,480 --> 00:04:14,640
however our participants uh were

105
00:04:14,640 --> 00:04:17,279
concerned were considered active users

106
00:04:17,279 --> 00:04:20,040
of social platforms where 75 percent of

107
00:04:20,040 --> 00:04:24,360
them were daily users and 91 were using

108
00:04:24,360 --> 00:04:27,979
the platforms at least once a week

109
00:04:28,320 --> 00:04:31,620
since we are short in time in the

110
00:04:31,620 --> 00:04:32,520
following state I'm just going to

111
00:04:32,520 --> 00:04:34,919
highlight the main findings and I invite

112
00:04:34,919 --> 00:04:36,479
you all to look at the paper for more

113
00:04:36,479 --> 00:04:37,860
details

114
00:04:37,860 --> 00:04:40,560
uh we started off by investigating the

115
00:04:40,560 --> 00:04:42,780
deletion patterns of the users we saw

116
00:04:42,780 --> 00:04:46,020
that among 191 participants 82 percent

117
00:04:46,020 --> 00:04:48,060
of them reported that they actually have

118
00:04:48,060 --> 00:04:49,860
deleted the post in the past

119
00:04:49,860 --> 00:04:51,900
and interesting enough more than

120
00:04:51,900 --> 00:04:54,360
one-third of all the deletions were have

121
00:04:54,360 --> 00:04:56,100
happened for the posts that were

122
00:04:56,100 --> 00:04:58,020
published more than seven days

123
00:04:58,020 --> 00:05:00,000
this shows that the old post on social

124
00:05:00,000 --> 00:05:02,880
platforms are not necessarily forgotten

125
00:05:02,880 --> 00:05:05,520
or ignored and users actively care about

126
00:05:05,520 --> 00:05:09,000
them and remove the unwanted ones

127
00:05:09,000 --> 00:05:12,419
uh the top reason for post deletions was

128
00:05:12,419 --> 00:05:14,639
identified as close becoming irrelevant

129
00:05:14,639 --> 00:05:17,100
As Time passed which goes back to the

130
00:05:17,100 --> 00:05:19,020
previous point of like out the uh

131
00:05:19,020 --> 00:05:21,600
deleting the outdated post other reasons

132
00:05:21,600 --> 00:05:23,880
that were mentioned were fixing spelling

133
00:05:23,880 --> 00:05:25,919
and grammar issues post not getting

134
00:05:25,919 --> 00:05:28,440
enough attention cleaning up the profile

135
00:05:28,440 --> 00:05:31,020
for a new job or relationship but we

136
00:05:31,020 --> 00:05:32,639
also saw a significant number of

137
00:05:32,639 --> 00:05:34,440
participants reporting some sensitive

138
00:05:34,440 --> 00:05:36,600
topic for the reason of their deletions

139
00:05:36,600 --> 00:05:39,900
such as alcohol drug race politics

140
00:05:39,900 --> 00:05:44,460
sexual content violence and some others

141
00:05:44,460 --> 00:05:46,800
uh which brings us to our next point

142
00:05:46,800 --> 00:05:49,320
where more than half of the participants

143
00:05:49,320 --> 00:05:52,020
thought that indeed deleted posts hide

144
00:05:52,020 --> 00:05:53,639
some sensitive and damaging information

145
00:05:53,639 --> 00:05:56,759
about the users

146
00:05:56,759 --> 00:05:59,460
for our second research question that we

147
00:05:59,460 --> 00:06:01,680
wanted to answer what contextual factors

148
00:06:01,680 --> 00:06:04,199
does deletion privacy depend on we used

149
00:06:04,199 --> 00:06:06,960
a contextual Integrity Theory to create

150
00:06:06,960 --> 00:06:09,840
a set of contextual variables to collect

151
00:06:09,840 --> 00:06:11,880
their users feedback in our survey

152
00:06:11,880 --> 00:06:13,740
again I cannot go into the details

153
00:06:13,740 --> 00:06:15,720
because of time but contextual Integrity

154
00:06:15,720 --> 00:06:18,479
allows us to Define privacy as

155
00:06:18,479 --> 00:06:20,880
appropriate flows of information which

156
00:06:20,880 --> 00:06:23,460
in our case was a total of 900 that we

157
00:06:23,460 --> 00:06:25,620
investigated

158
00:06:25,620 --> 00:06:29,100
the most negative flows uh where for the

159
00:06:29,100 --> 00:06:30,840
cases that deletions are noticed by

160
00:06:30,840 --> 00:06:33,300
large-scale data collectors such as a

161
00:06:33,300 --> 00:06:35,000
third-party company or the government

162
00:06:35,000 --> 00:06:37,620
compared to other social groups such as

163
00:06:37,620 --> 00:06:40,500
family members friends and even their

164
00:06:40,500 --> 00:06:43,100
co-workers

165
00:06:43,500 --> 00:06:46,440
we also saw that deleted posts that the

166
00:06:46,440 --> 00:06:47,880
subject of the post was the users

167
00:06:47,880 --> 00:06:49,740
themselves required more protection than

168
00:06:49,740 --> 00:06:51,259
any other subject

169
00:06:51,259 --> 00:06:53,880
inside the polls

170
00:06:53,880 --> 00:06:55,979
also not knowing how deletions were

171
00:06:55,979 --> 00:06:58,139
notices were considered not accessible

172
00:06:58,139 --> 00:07:00,840
to the users which is consistent with

173
00:07:00,840 --> 00:07:03,960
the human desire for cognitive closure

174
00:07:03,960 --> 00:07:07,139
and interestingly enough uh hiding the

175
00:07:07,139 --> 00:07:08,580
post that did not get enough attention

176
00:07:08,580 --> 00:07:12,120
was the most concern for the users

177
00:07:12,120 --> 00:07:14,060
uh we also look into the

178
00:07:14,060 --> 00:07:16,080
demographic differences and we found

179
00:07:16,080 --> 00:07:18,419
that the higher income users were more

180
00:07:18,419 --> 00:07:20,400
concerned about their deletions and

181
00:07:20,400 --> 00:07:22,740
those that ended their relationship in

182
00:07:22,740 --> 00:07:25,440
the past uh were more conservative about

183
00:07:25,440 --> 00:07:27,720
their deletions being noticed

184
00:07:27,720 --> 00:07:30,120
we also saw some differences between you

185
00:07:30,120 --> 00:07:32,639
uh U.S and European participants where

186
00:07:32,639 --> 00:07:35,280
co-workers social group was considered

187
00:07:35,280 --> 00:07:38,099
much a closer group in the U.S than

188
00:07:38,099 --> 00:07:39,139
Europe

189
00:07:39,139 --> 00:07:41,960
and uh

190
00:07:41,960 --> 00:07:45,360
someone's talking the user's account was

191
00:07:45,360 --> 00:07:47,039
more of a concern for the European

192
00:07:47,039 --> 00:07:49,520
participants than the U.S participants

193
00:07:49,520 --> 00:07:52,259
and finally uh European female

194
00:07:52,259 --> 00:07:53,940
participants and older Asian Europeans

195
00:07:53,940 --> 00:07:55,919
were more conservative about their

196
00:07:55,919 --> 00:07:58,199
deletions compared to the U.S

197
00:07:58,199 --> 00:08:00,120
counterparts

198
00:08:00,120 --> 00:08:02,460
next we compared the utility of four

199
00:08:02,460 --> 00:08:04,380
different mechanisms by showing the

200
00:08:04,380 --> 00:08:06,360
participants a one to two minute video

201
00:08:06,360 --> 00:08:08,099
for each of them

202
00:08:08,099 --> 00:08:10,020
the first mechanism is the selective

203
00:08:10,020 --> 00:08:11,759
deletions which is the most popular

204
00:08:11,759 --> 00:08:14,580
method of deleting content today in this

205
00:08:14,580 --> 00:08:17,160
mechanism the user's posts remain

206
00:08:17,160 --> 00:08:20,099
available until the user themselves

207
00:08:20,099 --> 00:08:22,860
select uh unwanted post and delete them

208
00:08:22,860 --> 00:08:24,360
specifically

209
00:08:24,360 --> 00:08:26,400
next we have pre-scheduled deletion

210
00:08:26,400 --> 00:08:28,919
which removes the user's content from a

211
00:08:28,919 --> 00:08:31,139
specific criteria is met for example a

212
00:08:31,139 --> 00:08:32,940
predefined time or a period of

213
00:08:32,940 --> 00:08:34,260
inactivity

214
00:08:34,260 --> 00:08:36,179
for example Snapchat or Instagram

215
00:08:36,179 --> 00:08:38,640
stories are removed after some period of

216
00:08:38,640 --> 00:08:40,140
time

217
00:08:40,140 --> 00:08:42,479
next we have the intermittent withdrawal

218
00:08:42,479 --> 00:08:44,459
mechanism that offers a deniability

219
00:08:44,459 --> 00:08:47,399
guarantee for users deletions using

220
00:08:47,399 --> 00:08:50,339
availability privacy trade-off this work

221
00:08:50,339 --> 00:08:53,399
was presented in pets 2019.

222
00:08:53,399 --> 00:08:55,620
and the last mechanism is called decoy

223
00:08:55,620 --> 00:08:58,080
deletions where a set of decoy posts are

224
00:08:58,080 --> 00:08:59,580
chosen from a pool of benign

225
00:08:59,580 --> 00:09:02,519
crowdsourced posts and deleted along

226
00:09:02,519 --> 00:09:04,860
with the damaging post as a result the

227
00:09:04,860 --> 00:09:07,260
adversary's task just becomes harder in

228
00:09:07,260 --> 00:09:09,180
identifying the damaging one among all

229
00:09:09,180 --> 00:09:11,640
the deleted posts

230
00:09:11,640 --> 00:09:14,339
so after presenting the video uh we

231
00:09:14,339 --> 00:09:15,839
asked the following question for each of

232
00:09:15,839 --> 00:09:18,060
the mechanism we asked them how

233
00:09:18,060 --> 00:09:20,580
effective is that mechanism in hiding

234
00:09:20,580 --> 00:09:22,560
the damaging and sensitive post of their

235
00:09:22,560 --> 00:09:24,899
users in presence of a large-scale

236
00:09:24,899 --> 00:09:26,820
adversary that they were concerned in

237
00:09:26,820 --> 00:09:29,100
the second research question

238
00:09:29,100 --> 00:09:30,779
the results showed that more than half

239
00:09:30,779 --> 00:09:32,700
of the participants think that the most

240
00:09:32,700 --> 00:09:34,500
used deletion mechanism which is the

241
00:09:34,500 --> 00:09:36,779
selective deletion is not effective in

242
00:09:36,779 --> 00:09:39,360
providing privacy for the deleted post

243
00:09:39,360 --> 00:09:41,279
on the other hand they find that three

244
00:09:41,279 --> 00:09:43,860
mechanisms to be more effective but in

245
00:09:43,860 --> 00:09:45,480
our results we didn't see any static

246
00:09:45,480 --> 00:09:47,580
statistical differences between these

247
00:09:47,580 --> 00:09:49,380
three

248
00:09:49,380 --> 00:09:52,260
we also investigated the usefulness of

249
00:09:52,260 --> 00:09:54,360
each of these mechanisms by asking the

250
00:09:54,360 --> 00:09:56,580
users to describe cases where they find

251
00:09:56,580 --> 00:10:00,420
the mechanism to be useful uh and the

252
00:10:00,420 --> 00:10:02,580
cases that they find it not to be useful

253
00:10:02,580 --> 00:10:04,380
for Selective deletions although they

254
00:10:04,380 --> 00:10:06,180
don't think that it can provide privacy

255
00:10:06,180 --> 00:10:08,820
for them they really like the fact that

256
00:10:08,820 --> 00:10:10,440
the users are in full control of their

257
00:10:10,440 --> 00:10:12,839
posts

258
00:10:12,839 --> 00:10:15,060
for pre-scheduled deletions they really

259
00:10:15,060 --> 00:10:17,580
dislike that there is no archive or

260
00:10:17,580 --> 00:10:19,500
history of the post after they're

261
00:10:19,500 --> 00:10:22,260
deleted and for intermittent withdrawals

262
00:10:22,260 --> 00:10:23,700
they didn't like that they don't have

263
00:10:23,700 --> 00:10:25,500
they have a limited control on their

264
00:10:25,500 --> 00:10:29,040
post where uh as in this mechanism all

265
00:10:29,040 --> 00:10:31,560
the non-deleted posts are periodically

266
00:10:31,560 --> 00:10:32,880
being hidden

267
00:10:32,880 --> 00:10:35,459
and lastly for decoy deletion

268
00:10:35,459 --> 00:10:36,120
um

269
00:10:36,120 --> 00:10:38,339
uh they didn't find it that useful

270
00:10:38,339 --> 00:10:40,140
because they were relying on the

271
00:10:40,140 --> 00:10:42,360
assistance of others to create that pool

272
00:10:42,360 --> 00:10:46,440
of uh decoy post for uh their damaging

273
00:10:46,440 --> 00:10:48,240
pulse

274
00:10:48,240 --> 00:10:50,279
so before ending the survey we also ask

275
00:10:50,279 --> 00:10:51,660
the users whether they can think of

276
00:10:51,660 --> 00:10:54,660
other ways to protect their deletions

277
00:10:54,660 --> 00:10:56,880
although lots of them find the

278
00:10:56,880 --> 00:10:58,980
mechanisms not to be effective more than

279
00:10:58,980 --> 00:11:00,660
half of them could have couldn't come up

280
00:11:00,660 --> 00:11:03,420
with any other mechanism or any idea of

281
00:11:03,420 --> 00:11:05,399
how to protect their pose

282
00:11:05,399 --> 00:11:08,940
29 29 participants suggested that

283
00:11:08,940 --> 00:11:10,500
deletion problem can be raised

284
00:11:10,500 --> 00:11:13,140
altogether if we don't uh post any

285
00:11:13,140 --> 00:11:15,180
regrettable contents or have only

286
00:11:15,180 --> 00:11:16,560
private accounts

287
00:11:16,560 --> 00:11:18,720
I mean this can be the most effective

288
00:11:18,720 --> 00:11:21,000
solution but it's an impractical one

289
00:11:21,000 --> 00:11:23,880
because we cannot foresee and predict

290
00:11:23,880 --> 00:11:27,500
what's going to be damaging the future

291
00:11:28,920 --> 00:11:30,240
um some of the users propose some

292
00:11:30,240 --> 00:11:34,140
changes to the four mechanisms and by

293
00:11:34,140 --> 00:11:36,180
changing and making it more useful for

294
00:11:36,180 --> 00:11:37,980
example having an archive for the

295
00:11:37,980 --> 00:11:39,899
pre-scheduled deletions

296
00:11:39,899 --> 00:11:42,120
eight participants suggested proactive

297
00:11:42,120 --> 00:11:43,920
approaches that use models machine

298
00:11:43,920 --> 00:11:45,660
learning models to predict whether users

299
00:11:45,660 --> 00:11:47,940
may regret the post in the future but

300
00:11:47,940 --> 00:11:49,620
again this is overhead on the platform

301
00:11:49,620 --> 00:11:52,940
and also these models cannot fully

302
00:11:52,940 --> 00:11:55,920
predict what's going to be damaging in

303
00:11:55,920 --> 00:11:56,940
the future

304
00:11:56,940 --> 00:11:59,700
uh eight participants suggested rate

305
00:11:59,700 --> 00:12:01,860
limiting the malicious large-scale

306
00:12:01,860 --> 00:12:04,380
adversaries to have some blackout

307
00:12:04,380 --> 00:12:07,620
periods which can work in some cases but

308
00:12:07,620 --> 00:12:09,899
related work also has shown that the

309
00:12:09,899 --> 00:12:12,120
rate limiting large crawlers is a

310
00:12:12,120 --> 00:12:13,860
challenging task today

311
00:12:13,860 --> 00:12:17,220
and four participants also suggested

312
00:12:17,220 --> 00:12:19,320
that we do some morphing of the post

313
00:12:19,320 --> 00:12:22,200
text so instead of deleting them we

314
00:12:22,200 --> 00:12:24,240
start editing them and whenever we're

315
00:12:24,240 --> 00:12:25,980
comfortable enough we can either delete

316
00:12:25,980 --> 00:12:28,260
them or just leave them actually this

317
00:12:28,260 --> 00:12:29,760
can become a feature of a social

318
00:12:29,760 --> 00:12:32,959
platform where it happens automatically

319
00:12:32,959 --> 00:12:36,180
after some time and generalizes it and

320
00:12:36,180 --> 00:12:38,160
remove the sensitivity

321
00:12:38,160 --> 00:12:40,500
so in conclusion in this talk first we

322
00:12:40,500 --> 00:12:42,660
went over the case that the privacy of

323
00:12:42,660 --> 00:12:44,700
the users have been violated and saw

324
00:12:44,700 --> 00:12:46,860
that no work has been done on the user's

325
00:12:46,860 --> 00:12:49,019
perspective of deletion privacy which

326
00:12:49,019 --> 00:12:53,399
motivated our study next we saw that the

327
00:12:53,399 --> 00:12:56,820
responses from the users that indeed uh

328
00:12:56,820 --> 00:12:59,160
hiding uh

329
00:12:59,160 --> 00:13:01,800
deletions are is an indication of hiding

330
00:13:01,800 --> 00:13:04,380
something damaging and sensitive to the

331
00:13:04,380 --> 00:13:05,779
users

332
00:13:05,779 --> 00:13:09,899
uh in the contextual Integrity study we

333
00:13:09,899 --> 00:13:12,360
saw that users really want to protect

334
00:13:12,360 --> 00:13:15,060
against large-scale data collectors and

335
00:13:15,060 --> 00:13:17,160
lastly we saw that in the current

336
00:13:17,160 --> 00:13:19,399
deletion mechanisms implemented today

337
00:13:19,399 --> 00:13:22,620
they seem to be effective in providing

338
00:13:22,620 --> 00:13:24,480
privacy to the users

339
00:13:24,480 --> 00:13:27,000
uh we started in my talk thank you for

340
00:13:27,000 --> 00:13:28,320
listening and looking forward to your

341
00:13:28,320 --> 00:13:30,500
questions

