1
00:00:08,660 --> 00:00:11,639
hey everyone uh today I'm going to talk

2
00:00:11,639 --> 00:00:14,460
about our work on robustness of machine

3
00:00:14,460 --> 00:00:16,740
learning models for addend tracker

4
00:00:16,740 --> 00:00:19,140
blocking and this is join work with

5
00:00:19,140 --> 00:00:22,020
turmeric bald Stephen engelhardt zubair

6
00:00:22,020 --> 00:00:26,060
Shafiq and Carmela troncoso

7
00:00:26,279 --> 00:00:28,260
so nowadays there are a lot of blocking

8
00:00:28,260 --> 00:00:31,320
solutions that are aimed to address the

9
00:00:31,320 --> 00:00:33,600
issues caused by the online advertising

10
00:00:33,600 --> 00:00:36,540
and tracking industry now many of these

11
00:00:36,540 --> 00:00:38,640
blocking Solutions rely on manually

12
00:00:38,640 --> 00:00:41,399
curated filterless so here on the slide

13
00:00:41,399 --> 00:00:43,860
I have an example of what I mean so

14
00:00:43,860 --> 00:00:46,920
let's take the Adblock Plus extension it

15
00:00:46,920 --> 00:00:49,500
uses a filter list called easy list and

16
00:00:49,500 --> 00:00:51,600
I've shown a couple of rules in this

17
00:00:51,600 --> 00:00:53,219
list and what they look like in the

18
00:00:53,219 --> 00:00:56,039
snippet there the idea is that once you

19
00:00:56,039 --> 00:00:58,860
have a page load the resources on the

20
00:00:58,860 --> 00:01:00,840
page are matched against the rules on

21
00:01:00,840 --> 00:01:02,879
the filter list and then they're blocked

22
00:01:02,879 --> 00:01:05,640
or hidden based on the rule

23
00:01:05,640 --> 00:01:07,799
now the manual curation of these filter

24
00:01:07,799 --> 00:01:10,860
lists has two main issues one is that

25
00:01:10,860 --> 00:01:13,080
it's hard to keep these filterless up to

26
00:01:13,080 --> 00:01:15,299
date with the constantly evolving add-on

27
00:01:15,299 --> 00:01:17,820
tracker ecosystem prior research has

28
00:01:17,820 --> 00:01:19,260
shown that it can take up to three

29
00:01:19,260 --> 00:01:21,360
months to add a new rule to the filter

30
00:01:21,360 --> 00:01:23,759
list and then majority of the rules are

31
00:01:23,759 --> 00:01:25,979
now no longer applicable to ads and

32
00:01:25,979 --> 00:01:29,040
trackers that are existing at the moment

33
00:01:29,040 --> 00:01:32,880
the other issues or robustness since uh

34
00:01:32,880 --> 00:01:35,520
since these filters are working on

35
00:01:35,520 --> 00:01:37,740
pattern matching ads and trackers can

36
00:01:37,740 --> 00:01:39,479
employ techniques such as URL

37
00:01:39,479 --> 00:01:42,299
randomization in order to evade these

38
00:01:42,299 --> 00:01:45,720
patterns and thus these filter lists are

39
00:01:45,720 --> 00:01:48,619
no longer useful

40
00:01:49,259 --> 00:01:52,259
mind the research Community has been

41
00:01:52,259 --> 00:01:54,180
looking towards building automated

42
00:01:54,180 --> 00:01:56,520
detection systems that are based on

43
00:01:56,520 --> 00:01:58,500
machine learning

44
00:01:58,500 --> 00:02:01,320
now the previous automated detection

45
00:02:01,320 --> 00:02:03,780
systems looked either at the network

46
00:02:03,780 --> 00:02:07,079
layer features of ads and trackers such

47
00:02:07,079 --> 00:02:09,899
as URL or HTTP information or they

48
00:02:09,899 --> 00:02:11,940
looked at the JavaScript activity by

49
00:02:11,940 --> 00:02:13,860
performing static and dynamic code

50
00:02:13,860 --> 00:02:15,120
analysis

51
00:02:15,120 --> 00:02:17,640
but the latest approaches for automated

52
00:02:17,640 --> 00:02:20,459
detections argue that ads and trackers

53
00:02:20,459 --> 00:02:22,500
actually work across all the layers of

54
00:02:22,500 --> 00:02:24,540
the web stack and so we should be going

55
00:02:24,540 --> 00:02:27,420
for a cross layer approach that combines

56
00:02:27,420 --> 00:02:30,840
interactions across all of these layers

57
00:02:30,840 --> 00:02:32,879
so I'm going to talk about the first

58
00:02:32,879 --> 00:02:35,340
Main Cross layer approach which was ad

59
00:02:35,340 --> 00:02:37,319
graph and I'm going to use this as a

60
00:02:37,319 --> 00:02:40,500
representative example of all the cross

61
00:02:40,500 --> 00:02:43,019
layer approaches we have today

62
00:02:43,019 --> 00:02:45,480
so what ad graph does is it builds a

63
00:02:45,480 --> 00:02:47,760
graph representation of all the page

64
00:02:47,760 --> 00:02:50,099
load events that occur where the nodes

65
00:02:50,099 --> 00:02:51,840
in the graph are the different kinds of

66
00:02:51,840 --> 00:02:54,060
elements that are there on the page and

67
00:02:54,060 --> 00:02:56,099
the edges between these nodes represent

68
00:02:56,099 --> 00:02:58,019
various interactions between these

69
00:02:58,019 --> 00:02:59,340
elements

70
00:02:59,340 --> 00:03:02,040
so you can have events which are normal

71
00:03:02,040 --> 00:03:04,019
and like required for the functioning of

72
00:03:04,019 --> 00:03:06,239
the page such as loading a style sheet

73
00:03:06,239 --> 00:03:08,940
or an image and so on but you can also

74
00:03:08,940 --> 00:03:10,920
have tracker events and these look

75
00:03:10,920 --> 00:03:13,080
different from normal events and the

76
00:03:13,080 --> 00:03:15,180
idea behind these cross layer approaches

77
00:03:15,180 --> 00:03:17,280
is to find these differences between

78
00:03:17,280 --> 00:03:19,920
tracker events and normal events and use

79
00:03:19,920 --> 00:03:23,340
that to identify ads and trackers

80
00:03:23,340 --> 00:03:26,400
now all of these approaches so far have

81
00:03:26,400 --> 00:03:28,319
been shown to have good performance they

82
00:03:28,319 --> 00:03:30,480
identify ads and trackers with high

83
00:03:30,480 --> 00:03:32,640
accuracy but we were interested in

84
00:03:32,640 --> 00:03:34,500
studying whether they're actually robust

85
00:03:34,500 --> 00:03:36,599
to adversarial evasion

86
00:03:36,599 --> 00:03:38,879
and I'm going to explain what I mean by

87
00:03:38,879 --> 00:03:41,700
adversary elevation in our scenario so

88
00:03:41,700 --> 00:03:43,620
let's say that you have a site that

89
00:03:43,620 --> 00:03:46,200
you're visiting example.com this site

90
00:03:46,200 --> 00:03:48,480
would consist of resources that belong

91
00:03:48,480 --> 00:03:50,340
to the first party and the third party

92
00:03:50,340 --> 00:03:52,860
where first party resources are those

93
00:03:52,860 --> 00:03:55,500
that share the same top level domain as

94
00:03:55,500 --> 00:03:57,599
the visited site and third-party

95
00:03:57,599 --> 00:03:59,400
resources are those that have a

96
00:03:59,400 --> 00:04:01,860
different domain so let's say that ad

97
00:04:01,860 --> 00:04:03,959
graph is running and then it classifies

98
00:04:03,959 --> 00:04:06,239
some of these resources as benign and

99
00:04:06,239 --> 00:04:08,640
some of these as ads and trackers

100
00:04:08,640 --> 00:04:11,519
the adversary in our scenario is a third

101
00:04:11,519 --> 00:04:14,280
party that aims to get get its ads and

102
00:04:14,280 --> 00:04:18,298
trackers misclassified as benign content

103
00:04:18,298 --> 00:04:20,880
now what adcraft does is it builds a

104
00:04:20,880 --> 00:04:22,680
graph representation and then it

105
00:04:22,680 --> 00:04:25,080
extracts a number of features which it

106
00:04:25,080 --> 00:04:27,180
then uses to train a machine learning

107
00:04:27,180 --> 00:04:29,340
model and the features can be broadly

108
00:04:29,340 --> 00:04:31,680
categorized into two we have content

109
00:04:31,680 --> 00:04:33,600
features that are related to individual

110
00:04:33,600 --> 00:04:36,419
nodes in the graph such as URL or HTTP

111
00:04:36,419 --> 00:04:38,520
information and then your structural

112
00:04:38,520 --> 00:04:39,900
features which are related to

113
00:04:39,900 --> 00:04:42,000
interactions between the nodes such as

114
00:04:42,000 --> 00:04:44,520
the degree of a node or the connectivity

115
00:04:44,520 --> 00:04:46,139
and so on

116
00:04:46,139 --> 00:04:48,479
and what we observe is that actually the

117
00:04:48,479 --> 00:04:50,580
content features are pretty easy for an

118
00:04:50,580 --> 00:04:53,460
adversary to manipulate so this leads us

119
00:04:53,460 --> 00:04:55,620
to our first research question which is

120
00:04:55,620 --> 00:04:57,419
how much do these graph based detection

121
00:04:57,419 --> 00:05:00,720
systems rely on content features in

122
00:05:00,720 --> 00:05:03,060
order to evaluate this we took a set of

123
00:05:03,060 --> 00:05:05,880
10 000 Pages we ran add graph to

124
00:05:05,880 --> 00:05:08,160
classify all the URLs on the page as

125
00:05:08,160 --> 00:05:11,220
benign or add a Tracker and then we

126
00:05:11,220 --> 00:05:13,320
perform content mutation which consists

127
00:05:13,320 --> 00:05:15,900
of domain name randomization and query

128
00:05:15,900 --> 00:05:18,900
string randomization and then we ran ad

129
00:05:18,900 --> 00:05:21,000
graph again to see how the classifiers

130
00:05:21,000 --> 00:05:23,400
predictions change on this mutated data

131
00:05:23,400 --> 00:05:26,039
and we evaluated this under two

132
00:05:26,039 --> 00:05:28,440
collusion models one where the third

133
00:05:28,440 --> 00:05:30,120
party does not collude with the first

134
00:05:30,120 --> 00:05:32,520
party and the second one where the third

135
00:05:32,520 --> 00:05:34,620
party has limited collusion with the

136
00:05:34,620 --> 00:05:36,419
first party that means that the third

137
00:05:36,419 --> 00:05:38,699
party can become a subdomain of the

138
00:05:38,699 --> 00:05:40,620
first party and this is nowadays

139
00:05:40,620 --> 00:05:42,720
possible via techniques such as cname

140
00:05:42,720 --> 00:05:44,340
cloaking

141
00:05:44,340 --> 00:05:47,340
and what we look at is the success rate

142
00:05:47,340 --> 00:05:49,199
of the adversity which is what I show on

143
00:05:49,199 --> 00:05:52,020
the x-axis here and the success rate is

144
00:05:52,020 --> 00:05:54,419
basically the proportion of the ads and

145
00:05:54,419 --> 00:05:56,460
trackers that the adversary is able to

146
00:05:56,460 --> 00:05:58,919
get misclassified now by the classifier

147
00:05:58,919 --> 00:06:01,440
and we see that the average success rate

148
00:06:01,440 --> 00:06:04,620
is very high especially in the collusion

149
00:06:04,620 --> 00:06:08,160
model we get it around 96 percent and

150
00:06:08,160 --> 00:06:09,539
about a third of these mutations

151
00:06:09,539 --> 00:06:12,539
actually happen to URLs belonging to ad

152
00:06:12,539 --> 00:06:14,820
exchange trackers which is even a

153
00:06:14,820 --> 00:06:16,919
greater impact for user privacy because

154
00:06:16,919 --> 00:06:19,620
these ad exchanges can diffuse user

155
00:06:19,620 --> 00:06:21,780
information further into the tracking

156
00:06:21,780 --> 00:06:23,400
ecosystem

157
00:06:23,400 --> 00:06:25,500
and when we look at the features of AD

158
00:06:25,500 --> 00:06:27,780
graph to see why we get such a high

159
00:06:27,780 --> 00:06:29,639
success rate we see that the top three

160
00:06:29,639 --> 00:06:32,220
features that ad graph uses are related

161
00:06:32,220 --> 00:06:34,620
to the content that is like URL

162
00:06:34,620 --> 00:06:37,080
characteristics and mainly whether a

163
00:06:37,080 --> 00:06:40,860
particular URL is a third party or not

164
00:06:40,860 --> 00:06:43,380
and what we conclude is that ad graph

165
00:06:43,380 --> 00:06:46,380
and related ml based approaches actually

166
00:06:46,380 --> 00:06:48,660
fall prey to the same issues that

167
00:06:48,660 --> 00:06:50,819
filters suffer from and that is that

168
00:06:50,819 --> 00:06:52,800
they rely on these brittle content

169
00:06:52,800 --> 00:06:56,639
features which are quite easy to evade

170
00:06:56,639 --> 00:06:58,319
now when you look at the original

171
00:06:58,319 --> 00:07:00,900
performance in terms of accuracy of art

172
00:07:00,900 --> 00:07:03,720
graph you see that it's about 92 percent

173
00:07:03,720 --> 00:07:06,360
and now if you decide to remove the

174
00:07:06,360 --> 00:07:08,400
content features in order to improve the

175
00:07:08,400 --> 00:07:11,160
robustness you see that this results in

176
00:07:11,160 --> 00:07:12,900
a hit to the performance of the

177
00:07:12,900 --> 00:07:15,120
classifier and the accuracy drops to

178
00:07:15,120 --> 00:07:16,680
about 80 percent

179
00:07:16,680 --> 00:07:19,080
so this was our next research question

180
00:07:19,080 --> 00:07:21,060
which is can we actually improve the

181
00:07:21,060 --> 00:07:22,800
performance of these graph based

182
00:07:22,800 --> 00:07:25,380
detection systems without using these

183
00:07:25,380 --> 00:07:27,479
brittle content features

184
00:07:27,479 --> 00:07:30,479
and the main uh sort of insight that we

185
00:07:30,479 --> 00:07:32,880
had is that these graph based detection

186
00:07:32,880 --> 00:07:35,580
systems uh they have features related to

187
00:07:35,580 --> 00:07:37,620
what ads and trackers are which is what

188
00:07:37,620 --> 00:07:39,840
the content features represent but they

189
00:07:39,840 --> 00:07:41,520
don't have many features related to what

190
00:07:41,520 --> 00:07:44,099
ads and trackers do or their behavioral

191
00:07:44,099 --> 00:07:46,680
information and especially in the kind

192
00:07:46,680 --> 00:07:48,720
of tracking that we look at which is

193
00:07:48,720 --> 00:07:51,120
stateful tracking or tracking via

194
00:07:51,120 --> 00:07:53,819
identifiers ads and trackers primarily

195
00:07:53,819 --> 00:07:56,400
do two things ads and trackers have to

196
00:07:56,400 --> 00:07:58,560
have some access to storage such as

197
00:07:58,560 --> 00:08:01,080
cookies or local storage in order to

198
00:08:01,080 --> 00:08:03,599
store identifiers and ads and trackers

199
00:08:03,599 --> 00:08:06,479
often share a lot of user identifiers

200
00:08:06,479 --> 00:08:08,340
with other parties in the ecosystem

201
00:08:08,340 --> 00:08:12,060
using techniques such as cookie syncing

202
00:08:12,060 --> 00:08:14,160
so keeping these things in mind we

203
00:08:14,160 --> 00:08:16,020
created our system web graph where the

204
00:08:16,020 --> 00:08:18,840
idea is to capture these fundamental uh

205
00:08:18,840 --> 00:08:20,819
patterns of tracking Behavior because

206
00:08:20,819 --> 00:08:23,039
these behaviors are very difficult for

207
00:08:23,039 --> 00:08:25,680
ads and trackers to hide and we do this

208
00:08:25,680 --> 00:08:28,139
by performing two things we augment the

209
00:08:28,139 --> 00:08:30,479
graph structure to take into account

210
00:08:30,479 --> 00:08:33,120
tracking behavior and we introduce a new

211
00:08:33,120 --> 00:08:35,580
category of features based on on our

212
00:08:35,580 --> 00:08:38,580
augmentations called flow features

213
00:08:38,580 --> 00:08:40,559
and I'm not going to go into the details

214
00:08:40,559 --> 00:08:43,620
of how we make these enhancements but I

215
00:08:43,620 --> 00:08:45,600
just want to illustrate what we mean so

216
00:08:45,600 --> 00:08:46,860
let's say that we have address

217
00:08:46,860 --> 00:08:49,560
representation of Stack some tracker

218
00:08:49,560 --> 00:08:52,440
events and this looks like this as we as

219
00:08:52,440 --> 00:08:54,120
I show on the slide with our

220
00:08:54,120 --> 00:08:55,740
enhancements we actually see that

221
00:08:55,740 --> 00:08:58,620
previously disjoint tracker events are

222
00:08:58,620 --> 00:09:00,620
actually quite connected through common

223
00:09:00,620 --> 00:09:03,120
accesses to storage or sharing

224
00:09:03,120 --> 00:09:04,860
activities

225
00:09:04,860 --> 00:09:07,500
and for webcraft we completely get rid

226
00:09:07,500 --> 00:09:09,600
of the content features and we introduce

227
00:09:09,600 --> 00:09:11,640
a new category called flow features and

228
00:09:11,640 --> 00:09:13,260
these could be things like how many

229
00:09:13,260 --> 00:09:15,660
times a particular cookie is modified or

230
00:09:15,660 --> 00:09:18,180
accessed or how many times a cookie

231
00:09:18,180 --> 00:09:22,440
value is shared with another tracker

232
00:09:22,440 --> 00:09:24,959
is that we

233
00:09:24,959 --> 00:09:27,500
because we don't actually

234
00:09:28,140 --> 00:09:30,060
get off because the content features do

235
00:09:30,060 --> 00:09:32,279
provide some value but we are able to

236
00:09:32,279 --> 00:09:34,740
make up for a lot of lost ground

237
00:09:34,740 --> 00:09:37,080
and more importantly when we perform the

238
00:09:37,080 --> 00:09:39,660
same content mutation against web graph

239
00:09:39,660 --> 00:09:41,220
we see that the success rate of the

240
00:09:41,220 --> 00:09:44,580
adversary drops from 96 to about 8

241
00:09:44,580 --> 00:09:46,560
percent

242
00:09:46,560 --> 00:09:49,140
now we were interested in exploring

243
00:09:49,140 --> 00:09:51,000
whether web graph is actually also

244
00:09:51,000 --> 00:09:53,339
robust to an adversary that specifically

245
00:09:53,339 --> 00:09:55,680
targets the features that web graph uses

246
00:09:55,680 --> 00:09:58,440
and which we can Envision adversaries to

247
00:09:58,440 --> 00:10:00,720
use in the future to evade these kind of

248
00:10:00,720 --> 00:10:01,800
systems

249
00:10:01,800 --> 00:10:03,540
and I'm going to illustrate what I mean

250
00:10:03,540 --> 00:10:06,000
with a toy example so let's say that we

251
00:10:06,000 --> 00:10:08,220
have a site and this site is composed of

252
00:10:08,220 --> 00:10:10,160
resources belonging to the first party

253
00:10:10,160 --> 00:10:13,080
the adversary which is a third party and

254
00:10:13,080 --> 00:10:14,640
other third parties

255
00:10:14,640 --> 00:10:16,860
now web graph would have classified some

256
00:10:16,860 --> 00:10:19,019
of these resources as benign and some of

257
00:10:19,019 --> 00:10:21,420
them as ADD and tracker

258
00:10:21,420 --> 00:10:23,399
now what the adversary could do is

259
00:10:23,399 --> 00:10:25,320
perform some kind of a graph mutation

260
00:10:25,320 --> 00:10:27,959
here I'm just showing one example but

261
00:10:27,959 --> 00:10:29,519
please read our paper to see other

262
00:10:29,519 --> 00:10:32,279
realistic examples of mutations that an

263
00:10:32,279 --> 00:10:34,380
adversary can create so here the

264
00:10:34,380 --> 00:10:36,480
adversary adds a child node by sending

265
00:10:36,480 --> 00:10:39,300
an HTTP request and what happens here is

266
00:10:39,300 --> 00:10:42,000
that the adversaries structural

267
00:10:42,000 --> 00:10:44,040
properties actually change like the

268
00:10:44,040 --> 00:10:46,260
degree of the adversary now changes and

269
00:10:46,260 --> 00:10:47,820
these kind of changes can trigger

270
00:10:47,820 --> 00:10:50,579
misclassifications by the classifier but

271
00:10:50,579 --> 00:10:52,620
the problem is that now since all the

272
00:10:52,620 --> 00:10:53,880
nodes in the graph are actually

273
00:10:53,880 --> 00:10:56,459
connected structural properties of the

274
00:10:56,459 --> 00:10:58,560
other nodes that do not belong to the

275
00:10:58,560 --> 00:11:01,079
adversary would also change and some of

276
00:11:01,079 --> 00:11:03,899
these misclassifications can be desired

277
00:11:03,899 --> 00:11:06,000
from the adversary's point of view but

278
00:11:06,000 --> 00:11:08,100
there can also be misclassifications

279
00:11:08,100 --> 00:11:10,380
that are undesirable

280
00:11:10,380 --> 00:11:13,079
so what we have now here is on the

281
00:11:13,079 --> 00:11:15,180
x-axis we have the success rate as

282
00:11:15,180 --> 00:11:17,579
before for the adversary but now we have

283
00:11:17,579 --> 00:11:20,760
a new uh we have a new property here

284
00:11:20,760 --> 00:11:22,620
called the collateral damage which shows

285
00:11:22,620 --> 00:11:24,600
the proportion of undesirable changes

286
00:11:24,600 --> 00:11:27,060
from the adversaries point of view now

287
00:11:27,060 --> 00:11:28,920
ideally the adversary would like to be

288
00:11:28,920 --> 00:11:31,620
in the bottom right corner of this plot

289
00:11:31,620 --> 00:11:33,360
but we see that not only is the

290
00:11:33,360 --> 00:11:36,360
adversary not always able to get a high

291
00:11:36,360 --> 00:11:38,640
success rate but oftentimes the

292
00:11:38,640 --> 00:11:42,300
collateral damage is also non-zero

293
00:11:42,300 --> 00:11:45,240
so what we want to say is that these

294
00:11:45,240 --> 00:11:47,700
kind of attacks can be successful if the

295
00:11:47,700 --> 00:11:49,620
adversary is willing to tolerate these

296
00:11:49,620 --> 00:11:51,300
kind of side effects but more

297
00:11:51,300 --> 00:11:53,579
importantly in reality implementing

298
00:11:53,579 --> 00:11:57,180
these attacks is not very easy a lot of

299
00:11:57,180 --> 00:12:00,079
the features that webcraft uses are

300
00:12:00,079 --> 00:12:02,399
things that involve sharing of

301
00:12:02,399 --> 00:12:04,260
information with a bunch of different

302
00:12:04,260 --> 00:12:06,839
parties so to change these information

303
00:12:06,839 --> 00:12:09,779
sharing patterns in reality the third

304
00:12:09,779 --> 00:12:11,640
party would have to coordinate with a

305
00:12:11,640 --> 00:12:13,560
number of entities and completely

306
00:12:13,560 --> 00:12:18,180
restructure how they uh share their data

307
00:12:18,180 --> 00:12:20,880
so in short what we found is that the

308
00:12:20,880 --> 00:12:22,860
current graph based detection systems

309
00:12:22,860 --> 00:12:24,959
are relying too much on these

310
00:12:24,959 --> 00:12:28,380
content-based features but in reality we

311
00:12:28,380 --> 00:12:31,680
should be looking at uh tracker behavior

312
00:12:31,680 --> 00:12:34,440
and these can make the graph based

313
00:12:34,440 --> 00:12:37,040
detection systems a lot more robust to

314
00:12:37,040 --> 00:12:41,660
adversary elevation thank you

