1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:09,559 --> 00:00:12,420
today I'm gonna present our work black

3
00:00:12,420 --> 00:00:14,580
light scalable defense for neural

4
00:00:14,580 --> 00:00:16,740
networks against Quarry based Black Box

5
00:00:16,740 --> 00:00:19,680
attack this is the work from set Lab at

6
00:00:19,680 --> 00:00:22,880
the University of Chicago

7
00:00:22,920 --> 00:00:25,920
adversial examples are one of the most

8
00:00:25,920 --> 00:00:28,019
well-known attacks against deep neural

9
00:00:28,019 --> 00:00:30,500
networks researchers have found that

10
00:00:30,500 --> 00:00:33,239
imperceptible perturbations can full DN

11
00:00:33,239 --> 00:00:36,420
models to make run decisions

12
00:00:36,420 --> 00:00:39,780
for example if we add those well-crafted

13
00:00:39,780 --> 00:00:41,700
small perturbation on the stop sign

14
00:00:41,700 --> 00:00:44,640
image the model will misclassify it to

15
00:00:44,640 --> 00:00:46,559
speed limit

16
00:00:46,559 --> 00:00:48,899
according to threat models we can divide

17
00:00:48,899 --> 00:00:51,300
adversal attacks into white box attack

18
00:00:51,300 --> 00:00:53,760
and black box attack

19
00:00:53,760 --> 00:00:56,879
in white box attack the attacker has a

20
00:00:56,879 --> 00:00:59,340
full access to the model including model

21
00:00:59,340 --> 00:01:02,039
weights and architectures well in Black

22
00:01:02,039 --> 00:01:04,619
Box attack we assume the attacker only

23
00:01:04,619 --> 00:01:08,659
has Quarry access to the model

24
00:01:08,880 --> 00:01:11,220
white box access is a super strong

25
00:01:11,220 --> 00:01:13,619
assumption because usually it is very

26
00:01:13,619 --> 00:01:15,540
hard for the attacker to bridge the

27
00:01:15,540 --> 00:01:17,880
server and get the model

28
00:01:17,880 --> 00:01:20,280
in the meanwhile Black Box attack is

29
00:01:20,280 --> 00:01:23,220
more realistic and in this work we focus

30
00:01:23,220 --> 00:01:26,298
on Black Box attack

31
00:01:26,460 --> 00:01:29,100
in core based Black Box attack the

32
00:01:29,100 --> 00:01:31,020
attacker will send a sequence of

33
00:01:31,020 --> 00:01:33,659
well-crafted queries they will use the

34
00:01:33,659 --> 00:01:36,119
queries as well as their results to

35
00:01:36,119 --> 00:01:39,299
approximate an iterative optimization to

36
00:01:39,299 --> 00:01:41,939
compute the adversal perturbations

37
00:01:41,939 --> 00:01:44,820
for each attack query x i

38
00:01:44,820 --> 00:01:47,460
the attacker will craft it with previous

39
00:01:47,460 --> 00:01:50,759
queries as well as their results

40
00:01:50,759 --> 00:01:53,820
so it is really important to detect the

41
00:01:53,820 --> 00:01:56,040
attack queries as early as possible

42
00:01:56,040 --> 00:01:59,040
because every single query gets answered

43
00:01:59,040 --> 00:02:02,720
is a progress in the attack

44
00:02:03,360 --> 00:02:05,520
so how do we detect these attack queries

45
00:02:05,520 --> 00:02:08,818
what do these attacks share in common

46
00:02:08,818 --> 00:02:11,819
to build adversal examples the attacker

47
00:02:11,819 --> 00:02:15,000
must perform iterative optimization and

48
00:02:15,000 --> 00:02:17,220
in Black Box scenario iterative

49
00:02:17,220 --> 00:02:19,860
optimization means sending highly

50
00:02:19,860 --> 00:02:22,379
similar queries because the attacker

51
00:02:22,379 --> 00:02:25,440
needs to minimize the Delta between the

52
00:02:25,440 --> 00:02:29,400
original query and the adversal example

53
00:02:29,400 --> 00:02:32,520
so the key commonality here is the

54
00:02:32,520 --> 00:02:34,860
presence of high similarity in the

55
00:02:34,860 --> 00:02:36,660
attack queries

56
00:02:36,660 --> 00:02:39,000
here is an example of two attack

57
00:02:39,000 --> 00:02:41,459
sequences generated by different attack

58
00:02:41,459 --> 00:02:44,040
designs grading based and Grading free

59
00:02:44,040 --> 00:02:46,800
we can see that in both attack sequences

60
00:02:46,800 --> 00:02:49,379
these attack queries are highly similar

61
00:02:49,379 --> 00:02:51,780
to each other in pixel level

62
00:02:51,780 --> 00:02:54,660
yearly benign users won't send these

63
00:02:54,660 --> 00:02:57,540
pixel level highly similar queries so

64
00:02:57,540 --> 00:02:59,700
this could be a way for us to detect

65
00:02:59,700 --> 00:03:02,720
these attack queries

66
00:03:02,760 --> 00:03:05,459
there's only one existing defense

67
00:03:05,459 --> 00:03:07,860
against Quarry based Black Box attack

68
00:03:07,860 --> 00:03:10,379
which is an account based detection

69
00:03:10,379 --> 00:03:13,200
method from AI sec

70
00:03:13,200 --> 00:03:15,720
it marked each query with the account

71
00:03:15,720 --> 00:03:18,239
sending them and detect the attacking

72
00:03:18,239 --> 00:03:19,739
account

73
00:03:19,739 --> 00:03:22,680
however it is easy to bypass using

74
00:03:22,680 --> 00:03:25,739
multiple sibo accounts

75
00:03:25,739 --> 00:03:28,319
in this work we propose a query based

76
00:03:28,319 --> 00:03:31,500
detection with no account information we

77
00:03:31,500 --> 00:03:33,959
detect all attack queries even they are

78
00:03:33,959 --> 00:03:37,140
sent across multiple accounts

79
00:03:37,140 --> 00:03:39,780
and the challenge here is how do we do a

80
00:03:39,780 --> 00:03:41,879
scalable detection to millions of

81
00:03:41,879 --> 00:03:44,298
queries

82
00:03:44,519 --> 00:03:47,159
ideally for each query we want the

83
00:03:47,159 --> 00:03:50,159
detection runtime to be near constant no

84
00:03:50,159 --> 00:03:52,260
matter how many previous queries we want

85
00:03:52,260 --> 00:03:54,180
to compare with

86
00:03:54,180 --> 00:03:56,879
there are several intuitive ways to do

87
00:03:56,879 --> 00:03:59,700
query similarity comparison for example

88
00:03:59,700 --> 00:04:02,099
of course we can compare the input space

89
00:04:02,099 --> 00:04:04,379
LP distance between the current query

90
00:04:04,379 --> 00:04:07,680
and all previous queries or instead of

91
00:04:07,680 --> 00:04:10,620
looking to the input space distance we

92
00:04:10,620 --> 00:04:12,420
could look into latent features with

93
00:04:12,420 --> 00:04:14,340
distance

94
00:04:14,340 --> 00:04:17,279
however both of the methods have a

95
00:04:17,279 --> 00:04:20,220
runtime of Big O of n where n is the

96
00:04:20,220 --> 00:04:22,680
number of previous queries and they are

97
00:04:22,680 --> 00:04:24,360
not scalable

98
00:04:24,360 --> 00:04:27,240
so we need a new similar similarity

99
00:04:27,240 --> 00:04:31,340
metric allowing fast comparison

100
00:04:31,560 --> 00:04:34,380
the K enabler here is probabilistic

101
00:04:34,380 --> 00:04:36,660
fingerprinting which is a temporary

102
00:04:36,660 --> 00:04:38,940
resistant fingerprinting method

103
00:04:38,940 --> 00:04:41,520
it is a short bit string fingerprinting

104
00:04:41,520 --> 00:04:42,840
method

105
00:04:42,840 --> 00:04:45,060
by Saving each short bed in the

106
00:04:45,060 --> 00:04:48,240
fingerprint to a hash table we could do

107
00:04:48,240 --> 00:04:51,360
fingerprint matching in a constant time

108
00:04:51,360 --> 00:04:54,000
it is also a secure fingerprinting

109
00:04:54,000 --> 00:04:56,460
method using one-way hashing

110
00:04:56,460 --> 00:04:59,300
which makes reverse engineering attack

111
00:04:59,300 --> 00:05:03,060
computationally expensive

112
00:05:03,060 --> 00:05:05,100
let's see how it works

113
00:05:05,100 --> 00:05:07,500
it will generate the fingerprint from

114
00:05:07,500 --> 00:05:10,500
the set of hashes of all sub-segments of

115
00:05:10,500 --> 00:05:11,639
length l

116
00:05:11,639 --> 00:05:14,340
if two inputs are highly similar then

117
00:05:14,340 --> 00:05:16,020
their fingerprints will be highly

118
00:05:16,020 --> 00:05:17,580
similar

119
00:05:17,580 --> 00:05:20,060
for example we have an input array here

120
00:05:20,060 --> 00:05:24,120
and a window of length L we will

121
00:05:24,120 --> 00:05:27,419
calculate a hash of the segment in this

122
00:05:27,419 --> 00:05:30,360
window then we will slide the window and

123
00:05:30,360 --> 00:05:32,160
keep doing this

124
00:05:32,160 --> 00:05:35,039
until we get the hushes of all the sub

125
00:05:35,039 --> 00:05:36,300
segments

126
00:05:36,300 --> 00:05:39,000
then we will do a randomized sampling to

127
00:05:39,000 --> 00:05:41,460
get the fingerprint for example we could

128
00:05:41,460 --> 00:05:44,580
select the top Edge hashes by doing a

129
00:05:44,580 --> 00:05:48,180
numerical sorting of all the hash values

130
00:05:48,180 --> 00:05:50,340
probabilistic fingerprinting is temper

131
00:05:50,340 --> 00:05:53,520
resistant it is deterministic and

132
00:05:53,520 --> 00:05:56,460
repeatable for the same query yet it is

133
00:05:56,460 --> 00:05:59,039
unpredictable and randomized to an

134
00:05:59,039 --> 00:06:01,199
attacker

135
00:06:01,199 --> 00:06:03,539
with this in mind let's take a look at

136
00:06:03,539 --> 00:06:06,060
the overview for black light the core

137
00:06:06,060 --> 00:06:09,060
idea here is to detect similar attack

138
00:06:09,060 --> 00:06:11,460
queries by comparing their probabilistic

139
00:06:11,460 --> 00:06:15,000
fingerprints aquarie is malicious if its

140
00:06:15,000 --> 00:06:17,460
fingerprint is similar to some prior

141
00:06:17,460 --> 00:06:19,919
fingerprints we can't store in a

142
00:06:19,919 --> 00:06:21,240
database

143
00:06:21,240 --> 00:06:23,039
for example we have a fingerprint

144
00:06:23,039 --> 00:06:26,639
database here and when tourists come we

145
00:06:26,639 --> 00:06:29,220
will calculate the fingerprint and save

146
00:06:29,220 --> 00:06:30,720
it to the database

147
00:06:30,720 --> 00:06:33,720
at the same time if we find a similar

148
00:06:33,720 --> 00:06:36,240
fingerprint in the database we will take

149
00:06:36,240 --> 00:06:39,300
this query as an attack query and reject

150
00:06:39,300 --> 00:06:42,840
it without sending any outputs from the

151
00:06:42,840 --> 00:06:45,020
model

152
00:06:45,840 --> 00:06:48,660
in our system design for each incoming

153
00:06:48,660 --> 00:06:52,259
query we will first pre-process it we

154
00:06:52,259 --> 00:06:55,919
will convert the image to a bucketized

155
00:06:55,919 --> 00:06:58,919
pixel array then we will compute the

156
00:06:58,919 --> 00:07:01,560
probabilistic fingerprint of it compare

157
00:07:01,560 --> 00:07:03,660
and match the current fingerprint with

158
00:07:03,660 --> 00:07:06,900
prior fingerprints and if we detect an

159
00:07:06,900 --> 00:07:09,300
attack query we will reject it as the

160
00:07:09,300 --> 00:07:10,919
mitigation method

161
00:07:10,919 --> 00:07:13,620
for more details about our system design

162
00:07:13,620 --> 00:07:17,600
please look into our paper

163
00:07:18,780 --> 00:07:21,960
we evaluate blacklight on four different

164
00:07:21,960 --> 00:07:24,660
image classification tasks using eight

165
00:07:24,660 --> 00:07:26,880
state of art attacks

166
00:07:26,880 --> 00:07:29,639
with four different metrics

167
00:07:29,639 --> 00:07:32,280
we have three metrics for detection and

168
00:07:32,280 --> 00:07:34,919
one metric for mitigation

169
00:07:34,919 --> 00:07:37,500
for detection we have we have attack

170
00:07:37,500 --> 00:07:40,440
detection rate which is the read uh

171
00:07:40,440 --> 00:07:42,240
which is the proportion of attack

172
00:07:42,240 --> 00:07:44,340
sequences we detect

173
00:07:44,340 --> 00:07:47,160
detection coverage is the proportion of

174
00:07:47,160 --> 00:07:49,919
attack queries queries in the attack

175
00:07:49,919 --> 00:07:51,780
sequence we detect

176
00:07:51,780 --> 00:07:54,539
average quarries to detection is the

177
00:07:54,539 --> 00:07:56,940
number of attack queries get answered

178
00:07:56,940 --> 00:07:59,819
before we detect the attack sequence

179
00:07:59,819 --> 00:08:02,880
and for mitigation we have a tax success

180
00:08:02,880 --> 00:08:05,460
rate with mitigation which is the attack

181
00:08:05,460 --> 00:08:07,940
success rate of a persistent attack

182
00:08:07,940 --> 00:08:10,979
whose where all the detected attack

183
00:08:10,979 --> 00:08:14,359
queries are rejected

184
00:08:14,460 --> 00:08:17,520
We Run 1 000 attack sequences per attack

185
00:08:17,520 --> 00:08:20,520
algorithm per task and we allow the

186
00:08:20,520 --> 00:08:22,680
maximum query numbers for each attack

187
00:08:22,680 --> 00:08:26,419
sequence to be 100k

188
00:08:26,819 --> 00:08:29,340
I'm gonna show the result average

189
00:08:29,340 --> 00:08:31,680
overall task and for the detailed

190
00:08:31,680 --> 00:08:33,659
numbers for each task you can look into

191
00:08:33,659 --> 00:08:35,039
our paper

192
00:08:35,039 --> 00:08:38,520
for detection we can see that blacklight

193
00:08:38,520 --> 00:08:41,820
can detect all attack sequences for all

194
00:08:41,820 --> 00:08:45,180
the attack algorithms over all tasks

195
00:08:45,180 --> 00:08:48,360
and the detection coverage is very high

196
00:08:48,360 --> 00:08:50,940
which means black light can detect most

197
00:08:50,940 --> 00:08:53,959
of attack queries

198
00:08:54,120 --> 00:08:56,640
besides blacklight can detect most of

199
00:08:56,640 --> 00:08:59,519
the attack sequences in 2 to 8 queries

200
00:08:59,519 --> 00:09:03,420
this is great especially given that

201
00:09:03,420 --> 00:09:07,140
most of the attacks succeed in thousands

202
00:09:07,140 --> 00:09:09,899
tens of thousands queries

203
00:09:09,899 --> 00:09:12,779
and most importantly no attack sequence

204
00:09:12,779 --> 00:09:16,880
succeed with black light mitigation

205
00:09:18,480 --> 00:09:21,180
we also show that black light is

206
00:09:21,180 --> 00:09:23,700
effective against Quarry based adversial

207
00:09:23,700 --> 00:09:26,220
patch attacks

208
00:09:26,220 --> 00:09:28,740
we can also generalize blacklight to

209
00:09:28,740 --> 00:09:31,019
other domains we illustrate how to

210
00:09:31,019 --> 00:09:33,180
generalize black light using text

211
00:09:33,180 --> 00:09:35,160
classification tasks

212
00:09:35,160 --> 00:09:37,920
and we also showed that blacklight is

213
00:09:37,920 --> 00:09:39,959
effective against different counter

214
00:09:39,959 --> 00:09:42,660
matters like reducing query similarity

215
00:09:42,660 --> 00:09:45,720
and reducing number of attack queries in

216
00:09:45,720 --> 00:09:47,940
each attack sequence

217
00:09:47,940 --> 00:09:50,220
for more details please log into our

218
00:09:50,220 --> 00:09:52,519
paper

219
00:09:52,980 --> 00:09:55,080
thanks for listening and I'm happy to

220
00:09:55,080 --> 00:09:57,500
take questions

