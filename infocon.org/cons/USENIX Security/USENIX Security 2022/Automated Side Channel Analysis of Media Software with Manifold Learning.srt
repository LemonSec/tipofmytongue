1
00:00:08,420 --> 00:00:11,580
hello everyone I'm giving from the Hong

2
00:00:11,580 --> 00:00:13,080
Kong University of Science and

3
00:00:13,080 --> 00:00:15,719
Technology I will introduce you our work

4
00:00:15,719 --> 00:00:18,119
automate the cell Channel analysis of

5
00:00:18,119 --> 00:00:20,640
media software with manifold learning

6
00:00:20,640 --> 00:00:22,980
this work is done with keypad my

7
00:00:22,980 --> 00:00:25,800
supervisor chai Wong

8
00:00:25,800 --> 00:00:28,680
in this work we focus on style Channel

9
00:00:28,680 --> 00:00:31,439
analysis or media software and the

10
00:00:31,439 --> 00:00:34,440
privacy and media Imports of users for

11
00:00:34,440 --> 00:00:38,640
example images audios and texts in our

12
00:00:38,640 --> 00:00:41,219
search model we consider standard

13
00:00:41,219 --> 00:00:43,800
three-based attack and we analyze

14
00:00:43,800 --> 00:00:47,100
software access robots we assume that

15
00:00:47,100 --> 00:00:49,920
cell Channel traces can be logged using

16
00:00:49,920 --> 00:00:52,920
of the Shelf license like standard Prime

17
00:00:52,920 --> 00:00:56,579
and probe our framework can reconstruct

18
00:00:56,579 --> 00:00:59,460
private media inputs from cell Channel

19
00:00:59,460 --> 00:01:02,340
traces and localize that channel links

20
00:01:02,340 --> 00:01:03,359
in the program

21
00:01:03,359 --> 00:01:05,939
we further propose a lightweight but

22
00:01:05,939 --> 00:01:08,040
highly effective mitigation scheme

23
00:01:08,040 --> 00:01:11,040
called perception blending to defend our

24
00:01:11,040 --> 00:01:12,960
attack

25
00:01:12,960 --> 00:01:15,659
this presentation is organized as

26
00:01:15,659 --> 00:01:18,780
follows the first briefly introduced the

27
00:01:18,780 --> 00:01:21,659
concept of manifold and discuss why it

28
00:01:21,659 --> 00:01:23,280
can be utilized for cell Channel

29
00:01:23,280 --> 00:01:26,400
analysis presidential our license for

30
00:01:26,400 --> 00:01:28,680
reconstruction localization and

31
00:01:28,680 --> 00:01:31,560
mitigation and pricing some experimental

32
00:01:31,560 --> 00:01:33,240
results

33
00:01:33,240 --> 00:01:36,540
first things first what is manifold

34
00:01:36,540 --> 00:01:39,840
to be shot it is a concept for Dimension

35
00:01:39,840 --> 00:01:41,820
reduction

36
00:01:41,820 --> 00:01:45,360
let's say an image of digital one this

37
00:01:45,360 --> 00:01:48,659
image has only one color Channel and its

38
00:01:48,659 --> 00:01:52,380
size is 30 times 30 so it has in total

39
00:01:52,380 --> 00:01:55,619
900 pixels and each pixel value ranges

40
00:01:55,619 --> 00:02:01,200
from 0 to 255. in other words this image

41
00:02:01,200 --> 00:02:04,619
is represented as a 900 Dimension Vector

42
00:02:04,619 --> 00:02:08,038
in the pixel space of course there are

43
00:02:08,038 --> 00:02:10,919
too many dimensions

44
00:02:10,919 --> 00:02:13,920
now let's take a closer look at this

45
00:02:13,920 --> 00:02:14,819
image

46
00:02:14,819 --> 00:02:17,940
here a display is pixel values it's

47
00:02:17,940 --> 00:02:21,120
clear to see that in the 900 dimensional

48
00:02:21,120 --> 00:02:23,760
pixel space not all images are

49
00:02:23,760 --> 00:02:26,640
meaningful because randomly sampling

50
00:02:26,640 --> 00:02:29,760
pixel values for an image mostly

51
00:02:29,760 --> 00:02:32,640
generates noise if an image is

52
00:02:32,640 --> 00:02:36,120
minimalist then it is not private at the

53
00:02:36,120 --> 00:02:38,520
same time to form meaningful contents

54
00:02:38,520 --> 00:02:41,580
like the digital one there exists some

55
00:02:41,580 --> 00:02:44,459
constraints over pixel values we call

56
00:02:44,459 --> 00:02:46,560
this constraints the perceptual

57
00:02:46,560 --> 00:02:49,319
constraints and the scope the contents

58
00:02:49,319 --> 00:02:52,140
of media data which are the privacy in

59
00:02:52,140 --> 00:02:54,660
the context of cell Channel analysis for

60
00:02:54,660 --> 00:02:57,120
media software

61
00:02:57,120 --> 00:02:59,819
to better understand the perceptual

62
00:02:59,819 --> 00:03:02,400
constraints here I show an intuitive

63
00:03:02,400 --> 00:03:05,940
example let's imagine that we simplify

64
00:03:05,940 --> 00:03:08,879
the digital one as a segment and we then

65
00:03:08,879 --> 00:03:11,879
project it onto the polar coordinate

66
00:03:11,879 --> 00:03:14,459
to represent a segment in the polar

67
00:03:14,459 --> 00:03:17,180
coordinate we only need two Dimensions

68
00:03:17,180 --> 00:03:20,159
namely the lens rope and the rotation

69
00:03:20,159 --> 00:03:23,700
angle Delta in that sense if we want to

70
00:03:23,700 --> 00:03:26,940
reconstruct a simplified digital one we

71
00:03:26,940 --> 00:03:30,180
no longer need to recover all 900 pixel

72
00:03:30,180 --> 00:03:33,480
values inside we only need to recover

73
00:03:33,480 --> 00:03:36,780
its lens and rotation angle

74
00:03:36,780 --> 00:03:39,900
the same conclusion also holds for real

75
00:03:39,900 --> 00:03:42,239
images like these photos

76
00:03:42,239 --> 00:03:45,239
here we project some face photos onto a

77
00:03:45,239 --> 00:03:47,519
two-dimensional manifold using our

78
00:03:47,519 --> 00:03:49,860
framework well there are only two

79
00:03:49,860 --> 00:03:51,840
Dimensions they can distinguish

80
00:03:51,840 --> 00:03:54,360
different faces and are correlated with

81
00:03:54,360 --> 00:03:57,480
this color and face orientations in

82
00:03:57,480 --> 00:04:00,360
practice we find that about 100

83
00:04:00,360 --> 00:04:03,019
dimensions are enough of its photos

84
00:04:03,019 --> 00:04:06,659
regardless of the image size

85
00:04:06,659 --> 00:04:09,780
now let's rethink such handle analysis

86
00:04:09,780 --> 00:04:12,540
of media software under the view of

87
00:04:12,540 --> 00:04:15,959
manifold in fact reconstructing media

88
00:04:15,959 --> 00:04:18,899
data from some channels can be viewed as

89
00:04:18,899 --> 00:04:21,060
a domain transformation from the cell

90
00:04:21,060 --> 00:04:23,940
Channel domain to the media data domain

91
00:04:23,940 --> 00:04:27,180
unlike conventional attacks that recover

92
00:04:27,180 --> 00:04:30,180
data bytes we focus on perceptual

93
00:04:30,180 --> 00:04:33,240
contents of media data which can be

94
00:04:33,240 --> 00:04:35,280
represented using much lower Dimensions

95
00:04:35,280 --> 00:04:38,520
more specifically we first encode the

96
00:04:38,520 --> 00:04:41,520
Privacy from set channel Trace into a

97
00:04:41,520 --> 00:04:43,680
latent representation and then they

98
00:04:43,680 --> 00:04:46,320
called this latent representation as one

99
00:04:46,320 --> 00:04:49,460
media data instance

100
00:04:49,500 --> 00:04:52,740
the high level overview of our framework

101
00:04:52,740 --> 00:04:55,680
is Illustrated using this figure which

102
00:04:55,680 --> 00:04:58,979
mainly has two components an encoder and

103
00:04:58,979 --> 00:05:02,460
a decoder the encoder takes set channels

104
00:05:02,460 --> 00:05:05,160
logged using of the Shelf license as

105
00:05:05,160 --> 00:05:08,220
Imports and the decoder outputs a

106
00:05:08,220 --> 00:05:11,280
private media data the decoder is

107
00:05:11,280 --> 00:05:13,680
specifically designed for each type of

108
00:05:13,680 --> 00:05:17,040
media data in our scenario we consider

109
00:05:17,040 --> 00:05:20,699
images audios and text

110
00:05:20,699 --> 00:05:24,120
let's first say the image decoder since

111
00:05:24,120 --> 00:05:26,300
pixel values are floating Point numbers

112
00:05:26,300 --> 00:05:28,800
images are continuous

113
00:05:28,800 --> 00:05:31,560
following the standard approach we use

114
00:05:31,560 --> 00:05:33,660
convolutional neural network as the

115
00:05:33,660 --> 00:05:37,259
image decoder the parameter image can be

116
00:05:37,259 --> 00:05:42,060
generated by up sampling progressively

117
00:05:42,060 --> 00:05:44,160
similar to images

118
00:05:44,160 --> 00:05:47,880
audios are also continuous however it's

119
00:05:47,880 --> 00:05:49,860
challenging to generate Audios in

120
00:05:49,860 --> 00:05:52,680
general formats to eliminate this hurdle

121
00:05:52,680 --> 00:05:54,960
we use an image representation of

122
00:05:54,960 --> 00:05:58,080
audience more specifically an audio can

123
00:05:58,080 --> 00:06:00,840
be represented using its log amplitude

124
00:06:00,840 --> 00:06:03,360
or Mouse spectrum and the conversion is

125
00:06:03,360 --> 00:06:06,539
lossless therefore we can reconstruct

126
00:06:06,539 --> 00:06:09,240
audios from some channels following the

127
00:06:09,240 --> 00:06:12,479
same message as for images

128
00:06:12,479 --> 00:06:16,199
textual data namely sentences are quite

129
00:06:16,199 --> 00:06:19,259
different with images and audios since

130
00:06:19,259 --> 00:06:22,080
there is no intermediate word a sentence

131
00:06:22,080 --> 00:06:24,139
is a sequence of discrete words

132
00:06:24,139 --> 00:06:26,460
accordingly the lower dimensional

133
00:06:26,460 --> 00:06:30,180
manifold or text Data primarily in calls

134
00:06:30,180 --> 00:06:33,360
its word dependency therefore we explore

135
00:06:33,360 --> 00:06:35,759
to reconstruct sentences using the

136
00:06:35,759 --> 00:06:38,340
recurrent neural network as shown here

137
00:06:38,340 --> 00:06:41,220
based on the work dependency a sentence

138
00:06:41,220 --> 00:06:44,220
can be reconstructed by iteratively

139
00:06:44,220 --> 00:06:47,460
predicting the next word

140
00:06:47,460 --> 00:06:49,880
here we present some of these photos

141
00:06:49,880 --> 00:06:52,979
reconstructed using our approach the

142
00:06:52,979 --> 00:06:54,720
first and the third rules are

143
00:06:54,720 --> 00:06:57,780
reconstructed images the second and the

144
00:06:57,780 --> 00:06:59,460
fourth rows are the corresponding

145
00:06:59,460 --> 00:07:02,280
priority inputs the reconstructed images

146
00:07:02,280 --> 00:07:05,460
of high quality and mostly consistent

147
00:07:05,460 --> 00:07:08,699
with priority impulse for instance the

148
00:07:08,699 --> 00:07:10,800
reconstructed images and the priority

149
00:07:10,800 --> 00:07:13,639
inputs have the same gender with color

150
00:07:13,639 --> 00:07:17,940
orientation and official expressions

151
00:07:17,940 --> 00:07:20,900
this page shows some test x-ray images

152
00:07:20,900 --> 00:07:24,300
the reconstructed images are also highly

153
00:07:24,300 --> 00:07:28,259
consistent with the user private input

154
00:07:28,259 --> 00:07:31,020
here we show the love Mouse Spectrum or

155
00:07:31,020 --> 00:07:33,060
reconstructed audios and the user

156
00:07:33,060 --> 00:07:36,000
private audios each audio records are

157
00:07:36,000 --> 00:07:39,599
one second human sound seeing one digit

158
00:07:39,599 --> 00:07:42,419
this is the input audio

159
00:07:42,419 --> 00:07:44,900
one

160
00:07:45,060 --> 00:07:47,880
this is a reconstructed audio

161
00:07:47,880 --> 00:07:50,160
one

162
00:07:50,160 --> 00:07:52,380
this is the input audio

163
00:07:52,380 --> 00:07:54,120
three

164
00:07:54,120 --> 00:07:56,699
this is a reconstructed order

165
00:07:56,699 --> 00:07:58,979
sorry

166
00:07:58,979 --> 00:08:01,080
this is the import audio

167
00:08:01,080 --> 00:08:03,859
six

168
00:08:03,960 --> 00:08:07,638
this is a reconstructed audio

169
00:08:08,759 --> 00:08:11,099
this page shows that we construct the

170
00:08:11,099 --> 00:08:13,460
sentences and the probability impulse

171
00:08:13,460 --> 00:08:16,860
remarks inconsistent words we note that

172
00:08:16,860 --> 00:08:18,599
most of the words are correctly

173
00:08:18,599 --> 00:08:20,819
recovered

174
00:08:20,819 --> 00:08:23,220
that stage how we localize that channel

175
00:08:23,220 --> 00:08:26,220
leaks in media software in the rest of

176
00:08:26,220 --> 00:08:29,039
this presentation I will use image as an

177
00:08:29,039 --> 00:08:31,560
example whose conclusion can be extended

178
00:08:31,560 --> 00:08:34,219
to other media data directly actually

179
00:08:34,219 --> 00:08:36,839
the localization can be done by

180
00:08:36,839 --> 00:08:39,539
answering the question which records

181
00:08:39,539 --> 00:08:42,000
contribute most to reconstructing the

182
00:08:42,000 --> 00:08:43,320
image

183
00:08:43,320 --> 00:08:46,260
more specifically we use Intel pin to

184
00:08:46,260 --> 00:08:48,720
collect the channel traces at the same

185
00:08:48,720 --> 00:08:50,459
time along with the corresponding

186
00:08:50,459 --> 00:08:52,399
instruction of each cell Channel record

187
00:08:52,399 --> 00:08:55,260
as a result the vulnerable program

188
00:08:55,260 --> 00:08:57,779
points can be localized by mapping the

189
00:08:57,779 --> 00:09:00,060
most important records back to their

190
00:09:00,060 --> 00:09:02,399
instructions

191
00:09:02,399 --> 00:09:05,279
we use neural attention to identify

192
00:09:05,279 --> 00:09:07,500
their General records that contribute

193
00:09:07,500 --> 00:09:10,080
most to reconstructing the image the

194
00:09:10,080 --> 00:09:12,540
neural attrition assigns each record and

195
00:09:12,540 --> 00:09:15,180
attention weight by finding the records

196
00:09:15,180 --> 00:09:17,940
that have the highest attention rates we

197
00:09:17,940 --> 00:09:20,519
can identify the most important ones for

198
00:09:20,519 --> 00:09:23,760
reconstructing the image

199
00:09:23,760 --> 00:09:26,339
here we show a code snippet of the

200
00:09:26,339 --> 00:09:29,220
vulnerable program point in live jpeg in

201
00:09:29,220 --> 00:09:31,260
fact Railway discover all cell Channel

202
00:09:31,260 --> 00:09:34,260
leaks exploited in previous works and

203
00:09:34,260 --> 00:09:37,019
disclose many new vulnerabilities most

204
00:09:37,019 --> 00:09:39,000
of them are from the minimum code unit

205
00:09:39,000 --> 00:09:41,640
modules the inverse discrete concern

206
00:09:41,640 --> 00:09:44,040
transformation modules and other image

207
00:09:44,040 --> 00:09:48,000
transformation and also dumping routines

208
00:09:48,000 --> 00:09:50,640
before showing our mitigation scheme

209
00:09:50,640 --> 00:09:52,860
let's first say the difference between

210
00:09:52,860 --> 00:09:55,500
the focus on media software and our

211
00:09:55,500 --> 00:09:56,339
attack

212
00:09:56,339 --> 00:09:59,279
generally media software precise data

213
00:09:59,279 --> 00:10:02,220
bytes for example the pixel value in

214
00:10:02,220 --> 00:10:04,560
contrast our attack focuses on the

215
00:10:04,560 --> 00:10:07,200
perceptions of media data such as visual

216
00:10:07,200 --> 00:10:10,800
attributes so our intuition is that we

217
00:10:10,800 --> 00:10:12,959
combine the perceptions of media data

218
00:10:12,959 --> 00:10:15,899
therefore the functionality of media

219
00:10:15,899 --> 00:10:18,839
software will not be affected and we can

220
00:10:18,839 --> 00:10:21,300
hide the perceptions of private media

221
00:10:21,300 --> 00:10:22,920
data

222
00:10:22,920 --> 00:10:25,860
we first randomly select one universal

223
00:10:25,860 --> 00:10:28,440
mask and precise it using the media

224
00:10:28,440 --> 00:10:31,320
software key let's denote the output at

225
00:10:31,320 --> 00:10:34,920
pmask here we require that the mask must

226
00:10:34,920 --> 00:10:36,720
be perceptually correlated to the

227
00:10:36,720 --> 00:10:39,600
private inputs for example both the

228
00:10:39,600 --> 00:10:41,760
private input and the mask of these

229
00:10:41,760 --> 00:10:43,920
photos for example into the private

230
00:10:43,920 --> 00:10:46,740
input by adding it with the mask we

231
00:10:46,740 --> 00:10:49,380
request that the weight of mask must be

232
00:10:49,380 --> 00:10:51,180
much larger than the rate of private

233
00:10:51,180 --> 00:10:52,320
input

234
00:10:52,320 --> 00:10:55,079
such that the mask can dominate the

235
00:10:55,079 --> 00:10:58,800
perceptions of Blended input

236
00:10:58,800 --> 00:11:01,440
when processing the Blended input using

237
00:11:01,440 --> 00:11:04,019
the media software the attacker can no

238
00:11:04,019 --> 00:11:06,420
longer obtain the private input because

239
00:11:06,420 --> 00:11:08,839
the reconstruct the media data mostly

240
00:11:08,839 --> 00:11:10,980
retains the perception of the Mask

241
00:11:10,980 --> 00:11:13,860
however the normal user can have the

242
00:11:13,860 --> 00:11:16,320
designed output by subtracting pmask

243
00:11:16,320 --> 00:11:19,399
from P Blended

244
00:11:19,800 --> 00:11:22,260
in practice the add and subtract

245
00:11:22,260 --> 00:11:25,200
operations are implemented as a data

246
00:11:25,200 --> 00:11:27,540
byte addition and subtraction for images

247
00:11:27,540 --> 00:11:30,360
and audios for sentences the add

248
00:11:30,360 --> 00:11:32,820
operation is implemented as inserting

249
00:11:32,820 --> 00:11:35,579
words because words are discrete and the

250
00:11:35,579 --> 00:11:38,579
textual manifold primarily in codeword

251
00:11:38,579 --> 00:11:40,980
dependency repeatedly in certain words

252
00:11:40,980 --> 00:11:44,100
can break the word dependency and thus

253
00:11:44,100 --> 00:11:47,339
may take it to our attack

254
00:11:47,339 --> 00:11:49,380
here I press into some mitigation

255
00:11:49,380 --> 00:11:52,260
results of our perception blending the

256
00:11:52,260 --> 00:11:54,720
reconstruct the images of the attacker

257
00:11:54,720 --> 00:11:57,180
mostly within the perceptions of the

258
00:11:57,180 --> 00:12:00,000
Mask in contrast normal users can

259
00:12:00,000 --> 00:12:01,920
recover the perceptions of private

260
00:12:01,920 --> 00:12:06,199
inputs with negligible loss

261
00:12:06,300 --> 00:12:09,500
thank you for listening

