1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:10,280 --> 00:00:13,080
I'll be presenting our work on robust

3
00:00:13,080 --> 00:00:14,700
keyword spotting

4
00:00:14,700 --> 00:00:16,440
this work is done in collaboration with

5
00:00:16,440 --> 00:00:18,960
Ilya Nicola peperno from University of

6
00:00:18,960 --> 00:00:22,740
Toronto and my advisor cousin Flores

7
00:00:22,740 --> 00:00:24,840
voice assistants are becoming widely

8
00:00:24,840 --> 00:00:27,240
popular we all have interacted with at

9
00:00:27,240 --> 00:00:29,460
least one of them at some point like

10
00:00:29,460 --> 00:00:32,820
Amazon Echo Google home Cortana Siri

11
00:00:32,820 --> 00:00:35,340
Google Assistant

12
00:00:35,340 --> 00:00:37,680
um Voice assistance enable a voice based

13
00:00:37,680 --> 00:00:39,899
and hands-free interaction

14
00:00:39,899 --> 00:00:42,780
and that which makes them favorable in

15
00:00:42,780 --> 00:00:44,820
many situations like during cooking

16
00:00:44,820 --> 00:00:48,660
driving during workout

17
00:00:48,660 --> 00:00:51,000
some recent statistics show that there

18
00:00:51,000 --> 00:00:54,840
have been about 4.2 billion devices in

19
00:00:54,840 --> 00:00:56,699
2021

20
00:00:56,699 --> 00:00:59,460
and in 2022 Amazon reported that Alexa

21
00:00:59,460 --> 00:01:01,920
receives billions of interactions every

22
00:01:01,920 --> 00:01:04,559
week which confirms the skill at which

23
00:01:04,559 --> 00:01:07,380
these devices are deployed

24
00:01:07,380 --> 00:01:09,540
the general pipeline of any voice

25
00:01:09,540 --> 00:01:12,299
assistant is as follows starts by a

26
00:01:12,299 --> 00:01:14,220
microphone which is always on always

27
00:01:14,220 --> 00:01:16,140
listening to the environment

28
00:01:16,140 --> 00:01:18,780
and feeding the detected speech to the

29
00:01:18,780 --> 00:01:20,820
keyword spotting module

30
00:01:20,820 --> 00:01:22,680
the keyword spotting processes the

31
00:01:22,680 --> 00:01:24,900
speech locally on the device looking for

32
00:01:24,900 --> 00:01:27,240
the keyword the activation keyword Alexa

33
00:01:27,240 --> 00:01:29,340
for example

34
00:01:29,340 --> 00:01:31,560
if the activation word is detected the

35
00:01:31,560 --> 00:01:33,720
device records and sends the subsequent

36
00:01:33,720 --> 00:01:35,820
command to the cloud for transcription

37
00:01:35,820 --> 00:01:38,700
and then for execution by the natural

38
00:01:38,700 --> 00:01:41,960
language understanding unit

39
00:01:43,560 --> 00:01:46,380
voice assistants are well integrated in

40
00:01:46,380 --> 00:01:47,939
the modern environments they control

41
00:01:47,939 --> 00:01:50,720
home appliances they make purchases

42
00:01:50,720 --> 00:01:53,820
transactions initiative cool enable a

43
00:01:53,820 --> 00:01:56,040
third-party skill which makes them very

44
00:01:56,040 --> 00:01:57,540
powerful

45
00:01:57,540 --> 00:02:00,720
for example if a user says Alexa open

46
00:02:00,720 --> 00:02:02,399
the garage door

47
00:02:02,399 --> 00:02:04,920
once the activation keyword Alexa is

48
00:02:04,920 --> 00:02:07,320
spotted the rest of the pipeline gets

49
00:02:07,320 --> 00:02:08,940
activated and then the garage door will

50
00:02:08,940 --> 00:02:10,919
be opened

51
00:02:10,919 --> 00:02:12,840
so the keyword spotting is the main

52
00:02:12,840 --> 00:02:14,700
Access Control mechanism to The Voice

53
00:02:14,700 --> 00:02:17,700
Assistant which makes it the gate to

54
00:02:17,700 --> 00:02:19,379
control all the next subsequent

55
00:02:19,379 --> 00:02:22,640
appliances and skins

56
00:02:22,680 --> 00:02:24,840
the Baseline architecture for keyword

57
00:02:24,840 --> 00:02:26,580
spotting is actually a convolutional

58
00:02:26,580 --> 00:02:27,720
neural network

59
00:02:27,720 --> 00:02:29,520
whose input features are the

60
00:02:29,520 --> 00:02:32,400
spectrograms of the input speech so it's

61
00:02:32,400 --> 00:02:36,020
similar to image recognition

62
00:02:36,420 --> 00:02:37,980
so keyword spotting is just a machine

63
00:02:37,980 --> 00:02:39,480
learning detector

64
00:02:39,480 --> 00:02:41,819
and detectors make mistakes

65
00:02:41,819 --> 00:02:44,400
in this work we consider two settings or

66
00:02:44,400 --> 00:02:46,500
two thread models where the keyword

67
00:02:46,500 --> 00:02:49,140
spotting gets falsely activated and

68
00:02:49,140 --> 00:02:51,120
enable unauthorized access to the voice

69
00:02:51,120 --> 00:02:52,980
assistant

70
00:02:52,980 --> 00:02:55,379
the first thread model is accidental

71
00:02:55,379 --> 00:02:56,640
activation

72
00:02:56,640 --> 00:02:58,260
where the keyword spotting model

73
00:02:58,260 --> 00:03:00,420
confuses a phrase with the activation

74
00:03:00,420 --> 00:03:02,819
keyword for example OK Google can be

75
00:03:02,819 --> 00:03:06,060
confused by okay to go it's not the same

76
00:03:06,060 --> 00:03:08,580
word but it's close so the keyword

77
00:03:08,580 --> 00:03:10,680
spotting can be confused and get

78
00:03:10,680 --> 00:03:12,420
activated

79
00:03:12,420 --> 00:03:14,640
in this case the device records private

80
00:03:14,640 --> 00:03:16,879
conversations because it's listening to

81
00:03:16,879 --> 00:03:19,620
a conversation that is not intended to

82
00:03:19,620 --> 00:03:21,300
be a command

83
00:03:21,300 --> 00:03:23,580
and send the conversations to the cloud

84
00:03:23,580 --> 00:03:26,819
and that compromises the user privacy

85
00:03:26,819 --> 00:03:29,400
in our evaluations we found that these

86
00:03:29,400 --> 00:03:32,040
false activations can last for up to 80

87
00:03:32,040 --> 00:03:34,319
Seconds

88
00:03:34,319 --> 00:03:37,019
the second thread model is adversarial

89
00:03:37,019 --> 00:03:39,360
activations which involves an adversary

90
00:03:39,360 --> 00:03:42,000
Who crafts adversarial examples

91
00:03:42,000 --> 00:03:44,099
to maliciously activate the device and

92
00:03:44,099 --> 00:03:46,200
gain access to the connected appiances

93
00:03:46,200 --> 00:03:48,480
and skills which compromises the

94
00:03:48,480 --> 00:03:50,819
integrity and safety of the user and the

95
00:03:50,819 --> 00:03:52,980
device

96
00:03:52,980 --> 00:03:55,620
to address these two threat models we

97
00:03:55,620 --> 00:03:57,959
will present Echoes and on something for

98
00:03:57,959 --> 00:04:00,959
robust keyword spotting so Echoes relies

99
00:04:00,959 --> 00:04:02,879
on the existing small devices in the

100
00:04:02,879 --> 00:04:05,159
environment in any modern environment we

101
00:04:05,159 --> 00:04:07,379
have a set of smartphones tablets

102
00:04:07,379 --> 00:04:08,819
laptops

103
00:04:08,819 --> 00:04:10,799
and all these devices have microphones

104
00:04:10,799 --> 00:04:12,720
and they have computation and commit and

105
00:04:12,720 --> 00:04:14,760
communication modules

106
00:04:14,760 --> 00:04:16,620
so Echoes relies on them to perform

107
00:04:16,620 --> 00:04:18,959
Ensemble learning

108
00:04:18,959 --> 00:04:20,699
it exploits different sources of

109
00:04:20,699 --> 00:04:22,979
diversity to make the Ensemble actually

110
00:04:22,979 --> 00:04:24,660
work

111
00:04:24,660 --> 00:04:26,580
for example these devices are

112
00:04:26,580 --> 00:04:29,820
independently and randomly placed in the

113
00:04:29,820 --> 00:04:31,919
user environment and each device

114
00:04:31,919 --> 00:04:36,020
experiences a unique acoustic Channel

115
00:04:36,419 --> 00:04:40,758
and has its own Hardware fingerprint

116
00:04:40,860 --> 00:04:43,020
Echoes also introduced diversity by

117
00:04:43,020 --> 00:04:44,400
enabling multiple machine learning

118
00:04:44,400 --> 00:04:45,900
architectures so each of those devices

119
00:04:45,900 --> 00:04:47,880
can deploy a different architecture so

120
00:04:47,880 --> 00:04:49,440
we have different sources of diversity

121
00:04:49,440 --> 00:04:52,020
that will lead to a successful Ensemble

122
00:04:52,020 --> 00:04:53,580
learning

123
00:04:53,580 --> 00:04:55,380
so each device will independently

124
00:04:55,380 --> 00:04:57,540
perform keyword spotting

125
00:04:57,540 --> 00:04:59,280
and send the vote to the main voice

126
00:04:59,280 --> 00:05:01,380
assistant which performs a majority vote

127
00:05:01,380 --> 00:05:03,540
and based on the score of the majority

128
00:05:03,540 --> 00:05:06,120
voter detects whether the

129
00:05:06,120 --> 00:05:07,620
um the received speech contains the

130
00:05:07,620 --> 00:05:10,340
keyword or not

131
00:05:10,740 --> 00:05:13,199
the detailed operation is as follows

132
00:05:13,199 --> 00:05:15,479
again each device receives a copy of the

133
00:05:15,479 --> 00:05:17,580
spoken utterance shipped by the room

134
00:05:17,580 --> 00:05:20,040
reverberation which is usually in

135
00:05:20,040 --> 00:05:22,020
literature called room impulse response

136
00:05:22,020 --> 00:05:24,360
as you just mathematical formulation of

137
00:05:24,360 --> 00:05:27,840
how the room shapes the acoustic signal

138
00:05:27,840 --> 00:05:30,720
and performs feature extraction

139
00:05:30,720 --> 00:05:33,479
selects the architecture performs the

140
00:05:33,479 --> 00:05:35,820
keyword spotting and decides on the vote

141
00:05:35,820 --> 00:05:37,800
and then send the vote to the main voice

142
00:05:37,800 --> 00:05:39,360
assistant

143
00:05:39,360 --> 00:05:41,580
so deploying echoes

144
00:05:41,580 --> 00:05:44,820
in our evaluations should that Echoes

145
00:05:44,820 --> 00:05:47,280
improves the accuracy with up to 20

146
00:05:47,280 --> 00:05:51,320
percent compared to any single device

147
00:05:51,660 --> 00:05:54,180
under that were serial search model

148
00:05:54,180 --> 00:05:57,000
a simple Ensemble is not enough

149
00:05:57,000 --> 00:05:58,919
so Echoes adds another layer of

150
00:05:58,919 --> 00:06:02,400
Randomness which is feature slicing

151
00:06:02,400 --> 00:06:04,800
each device will randomly slice the

152
00:06:04,800 --> 00:06:07,259
input spectrogram into small frequency

153
00:06:07,259 --> 00:06:09,600
bands and perform the keyword spotting

154
00:06:09,600 --> 00:06:11,880
using these limited input features it

155
00:06:11,880 --> 00:06:14,039
will not perform keyword spotting on the

156
00:06:14,039 --> 00:06:17,759
whole band it will select a small subset

157
00:06:17,759 --> 00:06:20,220
so a feature slicing can be defined as a

158
00:06:20,220 --> 00:06:22,199
random transformation that make that for

159
00:06:22,199 --> 00:06:25,259
serial optimization more constrained

160
00:06:25,259 --> 00:06:27,240
which will lead to a larger perturbation

161
00:06:27,240 --> 00:06:29,280
and hence higher attack preceptibility

162
00:06:29,280 --> 00:06:31,680
even if the attack succeed it will have

163
00:06:31,680 --> 00:06:33,600
higher perceptibility

164
00:06:33,600 --> 00:06:36,120
so that will make it not an adversarial

165
00:06:36,120 --> 00:06:38,699
example it will be obvious to their

166
00:06:38,699 --> 00:06:41,060
users

167
00:06:41,340 --> 00:06:43,380
and our evaluations

168
00:06:43,380 --> 00:06:45,240
should that Echoes improves that your

169
00:06:45,240 --> 00:06:48,979
serial accuracy was up to 30 percent

170
00:06:49,560 --> 00:06:52,979
we evaluate Echoes under two setups the

171
00:06:52,979 --> 00:06:55,680
first one is open source implementation

172
00:06:55,680 --> 00:06:58,919
using commodity devices like

173
00:06:58,919 --> 00:07:02,160
normal of the Shelf smartphones and

174
00:07:02,160 --> 00:07:04,199
laptops

175
00:07:04,199 --> 00:07:06,300
and open source data set which which is

176
00:07:06,300 --> 00:07:07,860
Google commands

177
00:07:07,860 --> 00:07:10,259
and the second is we actually Implement

178
00:07:10,259 --> 00:07:12,539
Echoes on Commercial Voice assistance we

179
00:07:12,539 --> 00:07:14,460
select Amazon Echo

180
00:07:14,460 --> 00:07:16,440
because it can be activated by four

181
00:07:16,440 --> 00:07:18,300
different keywords now actually they are

182
00:07:18,300 --> 00:07:20,880
six but at the time we did the

183
00:07:20,880 --> 00:07:22,979
experiments where they were only four

184
00:07:22,979 --> 00:07:27,060
so we could do extensive evaluations

185
00:07:27,060 --> 00:07:28,860
I'll start by the open source

186
00:07:28,860 --> 00:07:31,020
implementation

187
00:07:31,020 --> 00:07:33,660
so we selected those 12 labels from the

188
00:07:33,660 --> 00:07:36,000
Google commands data set and we train

189
00:07:36,000 --> 00:07:37,620
different keyword spotting architectures

190
00:07:37,620 --> 00:07:40,500
deployed the model on six devices again

191
00:07:40,500 --> 00:07:43,860
including smartphones laptops and iPad a

192
00:07:43,860 --> 00:07:46,259
PC connected to a professional

193
00:07:46,259 --> 00:07:48,800
microphone

194
00:07:49,380 --> 00:07:51,960
this figure shows the keyword spotting

195
00:07:51,960 --> 00:07:54,660
accuracy of each individual device from

196
00:07:54,660 --> 00:07:57,419
D1 to D6 under different background

197
00:07:57,419 --> 00:07:59,460
noise situations

198
00:07:59,460 --> 00:08:02,819
and then echo's performance as well at

199
00:08:02,819 --> 00:08:06,300
Ensemble size of three five and seven

200
00:08:06,300 --> 00:08:08,580
and as you see from the figure

201
00:08:08,580 --> 00:08:10,919
Echoes outperforms all the individual

202
00:08:10,919 --> 00:08:14,780
devices with up to 20 percent

203
00:08:16,620 --> 00:08:18,419
under the adversary setting we generated

204
00:08:18,419 --> 00:08:20,520
90 adversarial examples those are

205
00:08:20,520 --> 00:08:22,259
successful adversarial examples

206
00:08:22,259 --> 00:08:24,780
generated on the architectures we

207
00:08:24,780 --> 00:08:26,220
trained

208
00:08:26,220 --> 00:08:28,139
and we tested them on the Sim setup

209
00:08:28,139 --> 00:08:31,979
using pgd and pgdrir attack and pgdrir

210
00:08:31,979 --> 00:08:34,200
attack is just a more sophisticated

211
00:08:34,200 --> 00:08:36,059
attack that considers the environment as

212
00:08:36,059 --> 00:08:37,380
well engineering and adversarial

213
00:08:37,380 --> 00:08:38,458
examples

214
00:08:38,458 --> 00:08:41,159
and again we found that Echoes

215
00:08:41,159 --> 00:08:43,200
outperforms all the individual devices

216
00:08:43,200 --> 00:08:47,420
with up to 30 accuracy boost

217
00:08:48,420 --> 00:08:51,420
second we evaluated Echoes on the

218
00:08:51,420 --> 00:08:53,820
commercial Voice assistance again Amazon

219
00:08:53,820 --> 00:08:55,920
Echo

220
00:08:55,920 --> 00:08:58,860
since there are no public deficits for

221
00:08:58,860 --> 00:09:01,320
uh for Amazon Echo or even any any

222
00:09:01,320 --> 00:09:03,180
commercial device we created our own

223
00:09:03,180 --> 00:09:04,620
data set

224
00:09:04,620 --> 00:09:07,519
for the four keywords that can activate

225
00:09:07,519 --> 00:09:10,560
Echo dot we extracted the positive

226
00:09:10,560 --> 00:09:14,779
samples from public speech data sets

227
00:09:15,060 --> 00:09:18,660
um and also by using speech synthesis

228
00:09:18,660 --> 00:09:21,000
and for the negative samples generally

229
00:09:21,000 --> 00:09:22,920
speaking any speech that does not

230
00:09:22,920 --> 00:09:24,779
contain the keyword is a negative sample

231
00:09:24,779 --> 00:09:27,240
but we wanted to test the negative

232
00:09:27,240 --> 00:09:29,279
samples that are highly likely to

233
00:09:29,279 --> 00:09:31,680
falsely activate the device so we relied

234
00:09:31,680 --> 00:09:35,760
on two recent studies

235
00:09:35,760 --> 00:09:38,100
who actually did this evaluation and

236
00:09:38,100 --> 00:09:40,860
found the phonetically closed words for

237
00:09:40,860 --> 00:09:43,200
each of those keywords and we used we

238
00:09:43,200 --> 00:09:46,220
used their data sets

239
00:09:48,080 --> 00:09:51,839
we used five Echo actually Four Echo dot

240
00:09:51,839 --> 00:09:54,000
devices and one Echo Tower which is the

241
00:09:54,000 --> 00:09:59,360
first generation of Amazon Echo in a lab

242
00:10:00,480 --> 00:10:03,600
in in our lab environment

243
00:10:03,600 --> 00:10:07,140
and we played the data set over the air

244
00:10:07,140 --> 00:10:09,779
and recorded the activation rate of each

245
00:10:09,779 --> 00:10:12,540
individual device

246
00:10:12,540 --> 00:10:15,360
and we found that Echoes when we have

247
00:10:15,360 --> 00:10:17,519
the five devices contributing to the

248
00:10:17,519 --> 00:10:20,100
ensample reduces the false activation

249
00:10:20,100 --> 00:10:22,680
rate with up to 50 percent

250
00:10:22,680 --> 00:10:25,260
so this reduction is in The Accidental

251
00:10:25,260 --> 00:10:26,580
activation setting and also the

252
00:10:26,580 --> 00:10:29,540
adversarial setting

253
00:10:31,980 --> 00:10:35,279
so in summary we designed two

254
00:10:35,279 --> 00:10:37,080
complementary approaches

255
00:10:37,080 --> 00:10:39,480
to tackle two threat models

256
00:10:39,480 --> 00:10:41,459
the first is the non-machine learning

257
00:10:41,459 --> 00:10:44,519
part which does the feature slicing and

258
00:10:44,519 --> 00:10:47,279
over the air randomness

259
00:10:47,279 --> 00:10:49,200
and this part mainly addresses the

260
00:10:49,200 --> 00:10:50,880
adversarial examples

261
00:10:50,880 --> 00:10:52,860
and the second part is The Ensemble of

262
00:10:52,860 --> 00:10:54,360
different architectures and that part

263
00:10:54,360 --> 00:10:56,700
helped with accidental activation

264
00:10:56,700 --> 00:11:00,899
so those two approaches combined could

265
00:11:00,899 --> 00:11:04,079
tackle the two thread models

266
00:11:04,079 --> 00:11:05,940
thank you for listening to the talk I

267
00:11:05,940 --> 00:11:07,440
think I made a record for finishing

268
00:11:07,440 --> 00:11:10,040
really fast

269
00:11:10,040 --> 00:11:14,599
and I'm ready to answer any questions

