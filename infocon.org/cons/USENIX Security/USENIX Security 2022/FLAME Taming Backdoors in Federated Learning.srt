1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:16,940 --> 00:00:20,160
work with my colleagues in Technical

3
00:00:20,160 --> 00:00:22,439
university darmstadt University of

4
00:00:22,439 --> 00:00:24,420
California San Diego and to University

5
00:00:24,420 --> 00:00:26,760
and Google

6
00:00:26,760 --> 00:00:30,180
so Federal learning is emerging

7
00:00:30,180 --> 00:00:32,899
distributed learning techniques however

8
00:00:32,899 --> 00:00:36,840
pausing attacks play a big concern so

9
00:00:36,840 --> 00:00:38,820
what I can damage the model performance

10
00:00:38,820 --> 00:00:41,579
or in like malicious functionality into

11
00:00:41,579 --> 00:00:44,940
the model and unfortunately editing

12
00:00:44,940 --> 00:00:47,640
defense are not effective

13
00:00:47,640 --> 00:00:50,520
therefore we introduce flame that can

14
00:00:50,520 --> 00:00:53,340
remove poison objects effectively while

15
00:00:53,340 --> 00:00:55,559
maintaining the benign performance of

16
00:00:55,559 --> 00:00:57,120
the model

17
00:00:57,120 --> 00:00:57,899
um

18
00:00:57,899 --> 00:01:00,239
flame can also protect privacy of colon

19
00:01:00,239 --> 00:01:03,019
using a secure company computation

20
00:01:03,019 --> 00:01:05,339
however because of the time content I

21
00:01:05,339 --> 00:01:07,200
will focus on the poisoning defense

22
00:01:07,200 --> 00:01:09,780
where we introduce

23
00:01:09,780 --> 00:01:13,439
three novel techniques to remove poison

24
00:01:13,439 --> 00:01:17,580
updates namely filtering

25
00:01:17,580 --> 00:01:20,340
clipping and noising

26
00:01:20,340 --> 00:01:24,540
so next I will explain the attacks with

27
00:01:24,540 --> 00:01:28,380
our defense in detail first take a quick

28
00:01:28,380 --> 00:01:29,580
recap

29
00:01:29,580 --> 00:01:30,960
so

30
00:01:30,960 --> 00:01:33,240
Federal learning is a collaborative

31
00:01:33,240 --> 00:01:35,280
machine learning approach that allow

32
00:01:35,280 --> 00:01:38,100
many clients to lightly turn the model

33
00:01:38,100 --> 00:01:41,400
without sharing their private and

34
00:01:41,400 --> 00:01:44,119
potentially sensitive local data

35
00:01:44,119 --> 00:01:46,560
particularly clients change the model

36
00:01:46,560 --> 00:01:49,500
locally and then send the model to the

37
00:01:49,500 --> 00:01:52,079
aggregator to be aggregated into the

38
00:01:52,079 --> 00:01:54,780
global model and then the global models

39
00:01:54,780 --> 00:01:57,360
sent back to the client for the next

40
00:01:57,360 --> 00:02:01,280
training route and because of the

41
00:02:01,280 --> 00:02:04,159
Privacy benefits and also efficiency

42
00:02:04,159 --> 00:02:07,200
further learning have been applied in

43
00:02:07,200 --> 00:02:11,038
many applications for example in

44
00:02:11,038 --> 00:02:13,800
automotive or in natural language

45
00:02:13,800 --> 00:02:17,180
processing or in medical image

46
00:02:17,180 --> 00:02:20,040
processing and also for critical

47
00:02:20,040 --> 00:02:22,860
applications for example in financial

48
00:02:22,860 --> 00:02:26,160
crop detection Network intrusion

49
00:02:26,160 --> 00:02:30,959
detection or in the cyberic intelligence

50
00:02:30,959 --> 00:02:33,720
however security and privacy has to be

51
00:02:33,720 --> 00:02:35,940
concerned and you can heard from some

52
00:02:35,940 --> 00:02:37,920
previous talk

53
00:02:37,920 --> 00:02:39,360
and

54
00:02:39,360 --> 00:02:42,480
so in particular in poisoning attacks

55
00:02:42,480 --> 00:02:44,819
the adversary can control compromise

56
00:02:44,819 --> 00:02:47,640
clients and then can run for example

57
00:02:47,640 --> 00:02:50,580
data poisoning attacks where the

58
00:02:50,580 --> 00:02:51,660
adversary

59
00:02:51,660 --> 00:02:52,260
um

60
00:02:52,260 --> 00:02:55,019
manipulates the local data if for

61
00:02:55,019 --> 00:02:58,560
training or the adverty can run model

62
00:02:58,560 --> 00:03:00,959
poisoning attacks where the adverty

63
00:03:00,959 --> 00:03:06,140
controls the trading process or modifies

64
00:03:06,599 --> 00:03:10,440
uh more updates directly so that's a

65
00:03:10,440 --> 00:03:12,239
poison update will be sent to the

66
00:03:12,239 --> 00:03:15,599
operator and eventually incorporate

67
00:03:15,599 --> 00:03:19,500
um inject into the global models and as

68
00:03:19,500 --> 00:03:21,720
a result all the current will also

69
00:03:21,720 --> 00:03:23,700
receives the poison models as you can

70
00:03:23,700 --> 00:03:24,659
see here

71
00:03:24,659 --> 00:03:28,080
so we assume that in data Tech the

72
00:03:28,080 --> 00:03:30,239
laboratory have full control of the

73
00:03:30,239 --> 00:03:34,140
compromise clients and but there are no

74
00:03:34,140 --> 00:03:35,940
control of the necklace or the

75
00:03:35,940 --> 00:03:38,519
aggregator and the majority of Clans

76
00:03:38,519 --> 00:03:41,159
abenae

77
00:03:41,159 --> 00:03:43,860
there are two types of poisoning attacks

78
00:03:43,860 --> 00:03:46,920
suffered untargeted poisoning attack arm

79
00:03:46,920 --> 00:03:49,799
to damage the model performance and the

80
00:03:49,799 --> 00:03:52,560
second so

81
00:03:52,560 --> 00:03:53,959
and

82
00:03:53,959 --> 00:03:56,519
targeted poisoning attack so-called Bike

83
00:03:56,519 --> 00:03:59,099
Tour and to inject vectors into the

84
00:03:59,099 --> 00:04:00,000
model

85
00:04:00,000 --> 00:04:02,879
and for example The Advisory can control

86
00:04:02,879 --> 00:04:05,760
which what should be success in good

87
00:04:05,760 --> 00:04:09,239
prediction or can change the traffic

88
00:04:09,239 --> 00:04:13,580
side levels or insects molesters traffic

89
00:04:13,580 --> 00:04:17,840
using the compromise iot devices

90
00:04:18,418 --> 00:04:22,560
uh there are several defenses uh one of

91
00:04:22,560 --> 00:04:26,060
them by on either update smoothing or

92
00:04:26,060 --> 00:04:28,500
filtering however there are many

93
00:04:28,500 --> 00:04:31,500
Throwbacks for example

94
00:04:31,500 --> 00:04:34,740
is contributable to to estimate the

95
00:04:34,740 --> 00:04:38,699
clipping valve or noise level or

96
00:04:38,699 --> 00:04:42,540
the filtering by approach normally makes

97
00:04:42,540 --> 00:04:45,060
specific assumption about the attack or

98
00:04:45,060 --> 00:04:48,259
about the data so therefore if the

99
00:04:48,259 --> 00:04:51,419
assumption does not hold then the

100
00:04:51,419 --> 00:04:54,740
defense is not effective

101
00:04:54,960 --> 00:04:59,280
so so our idea is that we have three

102
00:04:59,280 --> 00:05:02,720
components that Deploy on the accurator

103
00:05:02,720 --> 00:05:05,880
and when the aggregator receives the

104
00:05:05,880 --> 00:05:08,759
models our first component are filtering

105
00:05:08,759 --> 00:05:10,040
will

106
00:05:10,040 --> 00:05:13,280
try to identify the outlier models

107
00:05:13,280 --> 00:05:17,820
potentially as micro models and removes

108
00:05:17,820 --> 00:05:21,120
and then the remaining model will be

109
00:05:21,120 --> 00:05:24,479
sent to the clipping components whereas

110
00:05:24,479 --> 00:05:25,580
the

111
00:05:25,580 --> 00:05:28,440
the model with high attack impact will

112
00:05:28,440 --> 00:05:29,419
be

113
00:05:29,419 --> 00:05:32,840
scaled out to reduce the attack impact

114
00:05:32,840 --> 00:05:36,500
and the remaining

115
00:05:36,500 --> 00:05:40,620
I would say poison updates really will

116
00:05:40,620 --> 00:05:44,280
be eliminated by our noisy and component

117
00:05:44,280 --> 00:05:48,360
and then the point of free model will be

118
00:05:48,360 --> 00:05:51,919
sent back to the clients

119
00:05:52,020 --> 00:05:56,759
so the question is uh why and yeah how

120
00:05:56,759 --> 00:05:58,979
we do that

121
00:05:58,979 --> 00:06:01,400
so first we need to understand the

122
00:06:01,400 --> 00:06:05,280
characteristics of the micro attacks so

123
00:06:05,280 --> 00:06:09,259
to do that we represent the

124
00:06:09,259 --> 00:06:12,720
models as a vectors as you can see here

125
00:06:12,720 --> 00:06:14,699
the um

126
00:06:14,699 --> 00:06:20,759
G is a previous Global models and the

127
00:06:20,759 --> 00:06:23,460
blue ones are the B9 models so we

128
00:06:23,460 --> 00:06:26,460
identify three types of vectors

129
00:06:26,460 --> 00:06:29,580
so first is the white dog with large

130
00:06:29,580 --> 00:06:31,560
angular deviation

131
00:06:31,560 --> 00:06:33,740
and this

132
00:06:33,740 --> 00:06:36,900
indicates the vital models that are

133
00:06:36,900 --> 00:06:41,340
tuning well on the back doctors

134
00:06:41,340 --> 00:06:43,199
and

135
00:06:43,199 --> 00:06:46,500
second is the models that have a large

136
00:06:46,500 --> 00:06:48,060
magnitude

137
00:06:48,060 --> 00:06:51,720
in which the artery to scale up the more

138
00:06:51,720 --> 00:06:54,479
poison of this so that it have higher

139
00:06:54,479 --> 00:06:57,479
attack impact when it's accurated into

140
00:06:57,479 --> 00:07:01,259
the global model and the third one is a

141
00:07:01,259 --> 00:07:02,819
stilty model

142
00:07:02,819 --> 00:07:06,060
then you can see is more or less the

143
00:07:06,060 --> 00:07:09,419
same to the business more also it uh

144
00:07:09,419 --> 00:07:12,000
have difficult or challenging to be

145
00:07:12,000 --> 00:07:13,500
detected

146
00:07:13,500 --> 00:07:17,100
so so our idea here is that okay we want

147
00:07:17,100 --> 00:07:20,819
to to add noise so that's the the third

148
00:07:20,819 --> 00:07:26,099
type model will be eliminated however

149
00:07:26,099 --> 00:07:27,060
um

150
00:07:27,060 --> 00:07:29,460
I didn't know I cannot remove the impact

151
00:07:29,460 --> 00:07:32,340
of the first or the second tie a vector

152
00:07:32,340 --> 00:07:34,680
so therefore we

153
00:07:34,680 --> 00:07:37,680
to minimize minimize amount of noise

154
00:07:37,680 --> 00:07:40,740
need to be added we first

155
00:07:40,740 --> 00:07:44,340
apply our filtering approach to remove

156
00:07:44,340 --> 00:07:46,259
the first style of white door

157
00:07:46,259 --> 00:07:50,819
then we apply our clipping

158
00:07:50,819 --> 00:07:53,300
to make sure that all the

159
00:07:53,300 --> 00:07:56,759
high or large multitude model will be

160
00:07:56,759 --> 00:07:59,819
scaled below the clipping belt

161
00:07:59,819 --> 00:08:04,440
and then for remaining poison updates we

162
00:08:04,440 --> 00:08:08,340
ask about the noise to to eliminate some

163
00:08:08,340 --> 00:08:12,360
so it's good to mention that the

164
00:08:12,360 --> 00:08:15,240
clipping bar s and also the the noise

165
00:08:15,240 --> 00:08:19,800
level Sigma as dynamically recalculated

166
00:08:19,800 --> 00:08:22,860
for every trading route for the detail

167
00:08:22,860 --> 00:08:25,259
why if you do that please look at the

168
00:08:25,259 --> 00:08:27,740
paper

169
00:08:30,300 --> 00:08:34,020
okay we evaluated our we evaluate our

170
00:08:34,020 --> 00:08:37,260
approach for state-of-the-art attacks

171
00:08:37,260 --> 00:08:39,539
and also

172
00:08:39,539 --> 00:08:43,440
yeah what your data says and as you can

173
00:08:43,440 --> 00:08:44,279
see

174
00:08:44,279 --> 00:08:47,040
um flame can remove the

175
00:08:47,040 --> 00:08:49,500
bike door effectively as you can see

176
00:08:49,500 --> 00:08:52,620
here's the vector accuracy review from

177
00:08:52,620 --> 00:08:57,980
100 to what zero percent in many cases

178
00:08:57,980 --> 00:09:01,700
and our approach maintains the

179
00:09:01,700 --> 00:09:04,200
benign performance of the motor

180
00:09:04,200 --> 00:09:07,019
as you can see it's a metal accuracy is

181
00:09:07,019 --> 00:09:09,959
more or less the same before and after

182
00:09:09,959 --> 00:09:13,279
we apply Flame

183
00:09:13,320 --> 00:09:17,540
and as I mentioned before

184
00:09:17,640 --> 00:09:20,100
flame can also mitigate untreated

185
00:09:20,100 --> 00:09:22,880
poisoning attack

186
00:09:23,700 --> 00:09:26,220
and in comparison to to a sitting

187
00:09:26,220 --> 00:09:28,140
defense defenses

188
00:09:28,140 --> 00:09:32,040
um flame as you can see uh outperforms

189
00:09:32,040 --> 00:09:35,339
all is it in defense

190
00:09:35,339 --> 00:09:38,399
and in conclusion

191
00:09:38,399 --> 00:09:40,920
yeah we introduced a novel approach so

192
00:09:40,920 --> 00:09:43,200
that can mitigate

193
00:09:43,200 --> 00:09:45,420
fighter attacks effectively while

194
00:09:45,420 --> 00:09:47,760
maintaining the benign performance of

195
00:09:47,760 --> 00:09:51,300
the model and it can also preserve the

196
00:09:51,300 --> 00:09:54,120
privacy of the user data using secure

197
00:09:54,120 --> 00:09:55,140
competition

198
00:09:55,140 --> 00:09:56,820
and

199
00:09:56,820 --> 00:09:58,700
we are working on

200
00:09:58,700 --> 00:10:01,740
privacy preserving presenting defenses

201
00:10:01,740 --> 00:10:05,160
and in particular for example we want to

202
00:10:05,160 --> 00:10:07,320
improve the computational efficiency

203
00:10:07,320 --> 00:10:10,620
yeah for that I conclude my talk and I'm

204
00:10:10,620 --> 00:10:13,459
happy for the questions

