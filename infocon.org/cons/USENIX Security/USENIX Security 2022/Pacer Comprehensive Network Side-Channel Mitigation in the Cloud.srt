1
00:00:08,058 --> 00:00:10,200
thanks for the introduction and my

2
00:00:10,200 --> 00:00:12,000
audible at back

3
00:00:12,000 --> 00:00:14,580
okay uh so this talk is about Network

4
00:00:14,580 --> 00:00:16,500
side channels in the cloud and our

5
00:00:16,500 --> 00:00:18,240
system Pacer which is designed to

6
00:00:18,240 --> 00:00:20,580
mitigate Network side Channel leaks for

7
00:00:20,580 --> 00:00:22,020
infrastructure as a service Cloud

8
00:00:22,020 --> 00:00:23,460
tenants

9
00:00:23,460 --> 00:00:25,199
so let me start by explaining how

10
00:00:25,199 --> 00:00:27,420
Network side Channel leaks work

11
00:00:27,420 --> 00:00:30,660
at a high level an adversary observes

12
00:00:30,660 --> 00:00:32,159
the traffic shape of a victim

13
00:00:32,159 --> 00:00:34,260
application which includes the packet

14
00:00:34,260 --> 00:00:37,079
sizes and timing and from that it aims

15
00:00:37,079 --> 00:00:40,020
to infer the secrets of the application

16
00:00:40,020 --> 00:00:41,940
so consider an application running

17
00:00:41,940 --> 00:00:43,620
inside a virtual machine in the cloud

18
00:00:43,620 --> 00:00:46,379
sending requests to an external client

19
00:00:46,379 --> 00:00:49,020
an adversary with physical access to a

20
00:00:49,020 --> 00:00:51,000
network element in the path of the

21
00:00:51,000 --> 00:00:53,100
application can directly observe the

22
00:00:53,100 --> 00:00:56,039
traffic shape of the application

23
00:00:56,039 --> 00:00:59,160
alternatively an adversary can rent a

24
00:00:59,160 --> 00:01:01,440
cheap unprivileged virtual machine

25
00:01:01,440 --> 00:01:03,719
co-locate itself with the applications

26
00:01:03,719 --> 00:01:05,760
virtual machine in the cloud and then

27
00:01:05,760 --> 00:01:07,619
generate cross traffic that would induce

28
00:01:07,619 --> 00:01:09,540
contention with the application's

29
00:01:09,540 --> 00:01:11,640
traffic at a shared network link which

30
00:01:11,640 --> 00:01:13,439
could be the nick of the physical server

31
00:01:13,439 --> 00:01:16,320
or even a top of the rack switch

32
00:01:16,320 --> 00:01:18,540
and based on the variations observed in

33
00:01:18,540 --> 00:01:20,700
its own traffic due to contention from

34
00:01:20,700 --> 00:01:23,340
the application traffic an adversary can

35
00:01:23,340 --> 00:01:25,500
indirectly infer the shape of the

36
00:01:25,500 --> 00:01:27,900
application's traffic

37
00:01:27,900 --> 00:01:30,000
the plot on the right here shows an

38
00:01:30,000 --> 00:01:31,979
actual attack where an adversary could

39
00:01:31,979 --> 00:01:34,020
identify the unique sizes of different

40
00:01:34,020 --> 00:01:36,299
files from a corpus as these were

41
00:01:36,299 --> 00:01:38,340
transmitted and the adversary could

42
00:01:38,340 --> 00:01:40,860
observe this and infer this simply based

43
00:01:40,860 --> 00:01:42,720
on the sizes and timing of spikes

44
00:01:42,720 --> 00:01:44,100
observed in its own pink traffic

45
00:01:44,100 --> 00:01:46,140
latencies

46
00:01:46,140 --> 00:01:48,780
and private has shown that one can learn

47
00:01:48,780 --> 00:01:50,700
a lot of sensitive information just from

48
00:01:50,700 --> 00:01:52,680
the observations of traffic shape for

49
00:01:52,680 --> 00:01:55,380
example one can identify the web page

50
00:01:55,380 --> 00:01:57,840
requested which video is stream content

51
00:01:57,840 --> 00:02:00,000
of VoIP conversations and even uses

52
00:02:00,000 --> 00:02:02,280
medical and financial secrets from a

53
00:02:02,280 --> 00:02:04,560
health or financial service hosted as a

54
00:02:04,560 --> 00:02:06,060
software as a service application in

55
00:02:06,060 --> 00:02:07,500
public clouds

56
00:02:07,500 --> 00:02:09,720
so as you can see network side channels

57
00:02:09,720 --> 00:02:10,800
can reveal a lot of sensitive

58
00:02:10,800 --> 00:02:12,360
information and this should be of

59
00:02:12,360 --> 00:02:14,280
concern for cloud providers

60
00:02:14,280 --> 00:02:16,680
and we present a system called Pacer to

61
00:02:16,680 --> 00:02:18,180
mitigate these kinds of leaks for cloud

62
00:02:18,180 --> 00:02:19,379
tenants

63
00:02:19,379 --> 00:02:21,540
at its core Pacer shapes and

64
00:02:21,540 --> 00:02:23,220
applications traffic to make the shape

65
00:02:23,220 --> 00:02:25,800
independent of Secrets and we present an

66
00:02:25,800 --> 00:02:28,140
abstraction of a cloaked panel to

67
00:02:28,140 --> 00:02:29,760
enforce secret independent traffic

68
00:02:29,760 --> 00:02:32,819
shapes by design for an application

69
00:02:32,819 --> 00:02:35,040
to mitigate the leaks for infrastructure

70
00:02:35,040 --> 00:02:37,319
as a service Cloud tenant we provide the

71
00:02:37,319 --> 00:02:39,360
design and implementation of a para

72
00:02:39,360 --> 00:02:41,580
virtualized cloak tunnel instance and

73
00:02:41,580 --> 00:02:43,260
one of the key challenges in building

74
00:02:43,260 --> 00:02:45,480
such a tunnel is to ensure that the

75
00:02:45,480 --> 00:02:47,340
tunnel itself is secured from other

76
00:02:47,340 --> 00:02:49,739
microarchitectural side channels on the

77
00:02:49,739 --> 00:02:52,260
platform and for this we develop a novel

78
00:02:52,260 --> 00:02:53,940
masking plus batching based mechanism

79
00:02:53,940 --> 00:02:55,680
which I'll be describe in the uh

80
00:02:55,680 --> 00:02:57,780
describing in the talk

81
00:02:57,780 --> 00:02:59,760
in the paper we also discuss other ideas

82
00:02:59,760 --> 00:03:02,040
related to Traffic shaping strategy and

83
00:03:02,040 --> 00:03:04,019
exploiting public inputs to allow for

84
00:03:04,019 --> 00:03:06,120
shaping bursary traffic of an

85
00:03:06,120 --> 00:03:07,980
application efficiently while still

86
00:03:07,980 --> 00:03:10,379
protecting secrets we also provide a

87
00:03:10,379 --> 00:03:12,360
gray box profiler that can automatically

88
00:03:12,360 --> 00:03:14,220
compute traffic shades for an

89
00:03:14,220 --> 00:03:16,379
application while requiring minimal

90
00:03:16,379 --> 00:03:18,480
inputs from the application itself

91
00:03:18,480 --> 00:03:20,340
you can also find detailed evaluation

92
00:03:20,340 --> 00:03:22,140
results and a formal proof of the

93
00:03:22,140 --> 00:03:24,540
security of our system in the paper

94
00:03:24,540 --> 00:03:27,180
here I will describe in detail the clock

95
00:03:27,180 --> 00:03:29,220
tunnel extraction and its designed for

96
00:03:29,220 --> 00:03:31,560
enforcing traffic shaping

97
00:03:31,560 --> 00:03:34,560
so the key abstraction of pork tunnel is

98
00:03:34,560 --> 00:03:36,540
essentially what encapsulates and shapes

99
00:03:36,540 --> 00:03:38,220
the network traffic between any pair of

100
00:03:38,220 --> 00:03:40,140
communicating nodes and can be used to

101
00:03:40,140 --> 00:03:42,239
shape the traffic of any arbitrary guest

102
00:03:42,239 --> 00:03:43,319
VM

103
00:03:43,319 --> 00:03:45,299
the key property that the tunnel

104
00:03:45,299 --> 00:03:46,500
provides is that the shape of the

105
00:03:46,500 --> 00:03:48,000
traffic inside the tunnel is secret

106
00:03:48,000 --> 00:03:51,180
independent so that an adversary cannot

107
00:03:51,180 --> 00:03:53,400
learn anything even from observations of

108
00:03:53,400 --> 00:03:55,860
the traffic inside the tunnel

109
00:03:55,860 --> 00:03:58,379
to achieve this high level property the

110
00:03:58,379 --> 00:04:00,060
tunnel endpoint needs to satisfy two

111
00:04:00,060 --> 00:04:02,400
high-level requirements first it needs

112
00:04:02,400 --> 00:04:04,319
to make the payload traffic unobservable

113
00:04:04,319 --> 00:04:06,599
and for this it must ensure that all

114
00:04:06,599 --> 00:04:08,760
packet sizes are secret independent for

115
00:04:08,760 --> 00:04:10,500
example they all have the same fixed

116
00:04:10,500 --> 00:04:11,340
size

117
00:04:11,340 --> 00:04:13,319
an application packet generation rate

118
00:04:13,319 --> 00:04:15,780
may vary based on flow control which may

119
00:04:15,780 --> 00:04:17,940
be itself dependent on secrets so the

120
00:04:17,940 --> 00:04:19,260
tunnel must hide this flow control

121
00:04:19,260 --> 00:04:21,060
information by transmitting dummy

122
00:04:21,060 --> 00:04:22,680
packets if there is no payload from the

123
00:04:22,680 --> 00:04:23,699
application

124
00:04:23,699 --> 00:04:25,500
now to hide the padding and payload

125
00:04:25,500 --> 00:04:27,479
packets all the packets must be

126
00:04:27,479 --> 00:04:29,460
encrypted after the padding

127
00:04:29,460 --> 00:04:31,139
and the padding information must be

128
00:04:31,139 --> 00:04:33,300
injected in the packet headers in such a

129
00:04:33,300 --> 00:04:35,220
way that it would be delivered at the

130
00:04:35,220 --> 00:04:37,020
other end point and that the other

131
00:04:37,020 --> 00:04:38,699
endpoint would generate similar

132
00:04:38,699 --> 00:04:40,919
responses for all the packets because

133
00:04:40,919 --> 00:04:42,660
otherwise an adversary could see the

134
00:04:42,660 --> 00:04:43,979
differences in the traffic in the other

135
00:04:43,979 --> 00:04:45,660
direction and distinguish between

136
00:04:45,660 --> 00:04:48,120
padding and payload

137
00:04:48,120 --> 00:04:49,979
the second high-level requirement is

138
00:04:49,979 --> 00:04:51,540
that the tunnel must ensure that all

139
00:04:51,540 --> 00:04:52,919
packets are transmitted at secret

140
00:04:52,919 --> 00:04:55,080
independent times so preferably on a

141
00:04:55,080 --> 00:04:57,479
schedule that is predictable and public

142
00:04:57,479 --> 00:04:59,160
and there should be no deviations from

143
00:04:59,160 --> 00:05:00,960
this schedule in a way that could be

144
00:05:00,960 --> 00:05:04,380
correlated with the application secrets

145
00:05:04,380 --> 00:05:06,240
to protect the traffic of an application

146
00:05:06,240 --> 00:05:08,460
running in a cloud virtual machine where

147
00:05:08,460 --> 00:05:10,259
there may be a threat from an adversary

148
00:05:10,259 --> 00:05:12,660
co-located on the same physical server

149
00:05:12,660 --> 00:05:14,820
we need one endpoint of the tunnel to be

150
00:05:14,820 --> 00:05:16,139
integrated with the virtual machines

151
00:05:16,139 --> 00:05:18,360
hosting server covering the shared Nick

152
00:05:18,360 --> 00:05:20,880
of the server the other endpoint could

153
00:05:20,880 --> 00:05:22,800
be implemented somewhere on the client's

154
00:05:22,800 --> 00:05:24,600
premises such as in a middle box or even

155
00:05:24,600 --> 00:05:26,580
on the client device

156
00:05:26,580 --> 00:05:28,320
here we describe the design of the

157
00:05:28,320 --> 00:05:29,340
tunnel endpoint for the cloud

158
00:05:29,340 --> 00:05:31,620
application the other endpoint can of

159
00:05:31,620 --> 00:05:34,919
course be implemented symmetrically

160
00:05:34,919 --> 00:05:37,680
so conceptually the tunnel endpoint can

161
00:05:37,680 --> 00:05:39,720
be implemented by adding a shaping layer

162
00:05:39,720 --> 00:05:41,280
right at the top of a traditional

163
00:05:41,280 --> 00:05:43,560
Network stack in the guest kernel

164
00:05:43,560 --> 00:05:45,300
the application receives request from

165
00:05:45,300 --> 00:05:47,280
the network and it generates response

166
00:05:47,280 --> 00:05:49,199
and shares it with the shaping layer

167
00:05:49,199 --> 00:05:51,720
the shaping layer installs a transmit

168
00:05:51,720 --> 00:05:53,400
schedule based on the traffic shape

169
00:05:53,400 --> 00:05:55,979
computed for the application and then at

170
00:05:55,979 --> 00:05:57,419
each time defined in the transmit

171
00:05:57,419 --> 00:05:59,280
schedule it generates a fixed size

172
00:05:59,280 --> 00:06:01,380
packet using the payload bytes from the

173
00:06:01,380 --> 00:06:03,180
application's response and adding

174
00:06:03,180 --> 00:06:05,400
padding wherever necessary

175
00:06:05,400 --> 00:06:07,199
and then this prepared packet will go

176
00:06:07,199 --> 00:06:08,520
through the lower layers of the Network

177
00:06:08,520 --> 00:06:10,680
star it could be encrypted using a

178
00:06:10,680 --> 00:06:12,660
traditional ipsec layer and then it

179
00:06:12,660 --> 00:06:16,139
would be transmitted into the tunnel

180
00:06:16,139 --> 00:06:18,539
now unfortunately the simple conceptual

181
00:06:18,539 --> 00:06:20,400
design is still vulnerable to timing

182
00:06:20,400 --> 00:06:21,780
leaks that could arise due to micro

183
00:06:21,780 --> 00:06:23,400
architectural side channels on the

184
00:06:23,400 --> 00:06:25,380
platform note that the packet

185
00:06:25,380 --> 00:06:27,000
transmission time is chosen at the

186
00:06:27,000 --> 00:06:28,560
shaping layer right at the top of the

187
00:06:28,560 --> 00:06:30,660
network stack and the Packer still needs

188
00:06:30,660 --> 00:06:32,340
to travel several layers before it

189
00:06:32,340 --> 00:06:33,600
reaches the neck

190
00:06:33,600 --> 00:06:36,060
and it's possible that the application

191
00:06:36,060 --> 00:06:37,800
interferes with the execution of the

192
00:06:37,800 --> 00:06:39,780
lower layers of the network stack and

193
00:06:39,780 --> 00:06:41,100
induced delays in the packet

194
00:06:41,100 --> 00:06:42,720
transmission times which could

195
00:06:42,720 --> 00:06:44,460
particularly be correlated with the

196
00:06:44,460 --> 00:06:46,979
application secrets and so this could

197
00:06:46,979 --> 00:06:48,900
lead to secret dependent leaks into the

198
00:06:48,900 --> 00:06:50,460
tunnel

199
00:06:50,460 --> 00:06:52,319
to prevent such leaks we must

200
00:06:52,319 --> 00:06:54,060
performance isolate the Network Star

201
00:06:54,060 --> 00:06:56,100
right from the shaping layer but

202
00:06:56,100 --> 00:06:57,840
ensuring performance isolation within

203
00:06:57,840 --> 00:07:00,840
the guest is infeasible almost

204
00:07:00,840 --> 00:07:02,639
we could try to move the entire stack

205
00:07:02,639 --> 00:07:04,620
into the hypervisor but even this is

206
00:07:04,620 --> 00:07:06,419
Impractical because it makes a

207
00:07:06,419 --> 00:07:08,819
hypervisor's design complex it forces

208
00:07:08,819 --> 00:07:10,440
the guests and its tenants to use the

209
00:07:10,440 --> 00:07:11,880
network stack provided by the cloud

210
00:07:11,880 --> 00:07:14,819
provider which causes render lock-in and

211
00:07:14,819 --> 00:07:16,919
moreover simply moving the network stack

212
00:07:16,919 --> 00:07:18,240
into the hypervisor is still not

213
00:07:18,240 --> 00:07:20,400
sufficient to prevent side Channel leaks

214
00:07:20,400 --> 00:07:22,919
into the tunnel

215
00:07:22,919 --> 00:07:24,599
so with Pacer we take a power

216
00:07:24,599 --> 00:07:27,060
virtualization approach we Implement a

217
00:07:27,060 --> 00:07:28,560
component in the guest kernel called

218
00:07:28,560 --> 00:07:30,960
g-face which is a loadable kernel module

219
00:07:30,960 --> 00:07:33,120
implementing packet padding and small

220
00:07:33,120 --> 00:07:35,460
changes in the TCP and the mixed

221
00:07:35,460 --> 00:07:37,560
ethernet driver layer

222
00:07:37,560 --> 00:07:39,300
we Implement a second component in the

223
00:07:39,300 --> 00:07:41,520
Zen hypervisor called hypase which

224
00:07:41,520 --> 00:07:43,160
implements dummy packet generation

225
00:07:43,160 --> 00:07:45,840
encryption of packets and pacing of them

226
00:07:45,840 --> 00:07:48,479
when transmitting to the Nic

227
00:07:48,479 --> 00:07:50,580
to better these two components address

228
00:07:50,580 --> 00:07:52,800
the two requirements of the tunnel and

229
00:07:52,800 --> 00:07:54,360
help in guaranteeing premium from

230
00:07:54,360 --> 00:07:56,099
Network side Channel leaks while

231
00:07:56,099 --> 00:07:58,380
transmitting packets in the tunnel

232
00:07:58,380 --> 00:08:01,139
so the payload packets are padded at the

233
00:08:01,139 --> 00:08:02,940
padding layer above TCP inside the gas

234
00:08:02,940 --> 00:08:06,060
turn gas kernel which ensures end-to-end

235
00:08:06,060 --> 00:08:08,520
padding dummy packets are generated in

236
00:08:08,520 --> 00:08:10,979
the high pest layer uh when there is

237
00:08:10,979 --> 00:08:12,780
Delay from the guest engineering payload

238
00:08:12,780 --> 00:08:15,120
packet and importantly these have valid

239
00:08:15,120 --> 00:08:17,520
TCP sequence numbers which it gets by

240
00:08:17,520 --> 00:08:19,979
from the TCP sequence information which

241
00:08:19,979 --> 00:08:22,500
is shared from the guest TCP layer

242
00:08:22,500 --> 00:08:24,000
High Press then encrypts all the

243
00:08:24,000 --> 00:08:26,220
outgoing packets and it places them into

244
00:08:26,220 --> 00:08:29,520
the next transmission queue for Pace

245
00:08:29,520 --> 00:08:31,319
transmission

246
00:08:31,319 --> 00:08:33,779
and before that it encrypts all these

247
00:08:33,779 --> 00:08:35,399
patterns which ensures that the payload

248
00:08:35,399 --> 00:08:38,039
would remain completely unobservable

249
00:08:38,039 --> 00:08:40,500
now to ensure that all packets are

250
00:08:40,500 --> 00:08:42,659
transmitted are checked at independent

251
00:08:42,659 --> 00:08:44,219
times High base follows the schedule

252
00:08:44,219 --> 00:08:46,320
which is pre-computed as part of the

253
00:08:46,320 --> 00:08:48,300
traffic ship computation

254
00:08:48,300 --> 00:08:51,120
but in order to ensure that each packet

255
00:08:51,120 --> 00:08:53,279
is really transmitted at precise times

256
00:08:53,279 --> 00:08:55,620
we need to now performance isolate the

257
00:08:55,620 --> 00:08:58,140
hypase component note that this is a

258
00:08:58,140 --> 00:09:00,180
much smaller component compared to what

259
00:09:00,180 --> 00:09:02,040
we had previously that requires

260
00:09:02,040 --> 00:09:04,320
performance isolation

261
00:09:04,320 --> 00:09:07,440
so to achieve performance isolation we

262
00:09:07,440 --> 00:09:09,600
profile the execution delays of high

263
00:09:09,600 --> 00:09:12,120
pace and we identify its worst case

264
00:09:12,120 --> 00:09:14,220
execution delay under varying background

265
00:09:14,220 --> 00:09:17,040
workloads empirically and then we ensure

266
00:09:17,040 --> 00:09:19,680
that each packet is transmitted after

267
00:09:19,680 --> 00:09:21,420
waiting for this worst case execution

268
00:09:21,420 --> 00:09:23,459
delay of the high Pace starting from the

269
00:09:23,459 --> 00:09:26,040
next scheduled transmit interval

270
00:09:26,040 --> 00:09:28,920
now this masking is expensive so we

271
00:09:28,920 --> 00:09:31,260
amortize the overheads of masking by

272
00:09:31,260 --> 00:09:32,820
increasing the length of the transmit

273
00:09:32,820 --> 00:09:35,700
interval and transmitting a fixed batch

274
00:09:35,700 --> 00:09:39,779
of packets at the end of each interval

275
00:09:39,779 --> 00:09:42,899
finally High Pace response to congestion

276
00:09:42,899 --> 00:09:45,300
signals from the network and this is

277
00:09:45,300 --> 00:09:46,980
done by using the congestion window

278
00:09:46,980 --> 00:09:48,540
information which is again shared from

279
00:09:48,540 --> 00:09:51,600
the modified guest TCP layer and

280
00:09:51,600 --> 00:09:53,880
essentially it pauses transmission on

281
00:09:53,880 --> 00:09:55,500
this on the schedule when there's

282
00:09:55,500 --> 00:09:57,600
congestion on the network and it resumes

283
00:09:57,600 --> 00:09:59,220
transmission when the congestion is

284
00:09:59,220 --> 00:10:01,380
resolved note that reacting to

285
00:10:01,380 --> 00:10:03,120
congestion control signals is only

286
00:10:03,120 --> 00:10:05,580
required to ensure Network stability and

287
00:10:05,580 --> 00:10:07,500
performance it does not have any

288
00:10:07,500 --> 00:10:09,839
security implications because congestion

289
00:10:09,839 --> 00:10:11,760
is a publicly observable event on the

290
00:10:11,760 --> 00:10:13,140
network

291
00:10:13,140 --> 00:10:15,120
you can find more details about our

292
00:10:15,120 --> 00:10:16,740
design and implementation in the paper

293
00:10:16,740 --> 00:10:19,380
and now I will briefly talk about our

294
00:10:19,380 --> 00:10:21,060
evaluation

295
00:10:21,060 --> 00:10:23,040
so we evaluated the security and

296
00:10:23,040 --> 00:10:24,779
performance overheads of our solution

297
00:10:24,779 --> 00:10:27,899
for security we evaluated the accuracy

298
00:10:27,899 --> 00:10:30,180
and precision of a state-of-the-art CNN

299
00:10:30,180 --> 00:10:32,160
based attack classifier on the shape

300
00:10:32,160 --> 00:10:34,320
traffic and we also built a formal model

301
00:10:34,320 --> 00:10:36,060
of high Pace to gain confidence in its

302
00:10:36,060 --> 00:10:38,220
design and implementation

303
00:10:38,220 --> 00:10:40,800
for performance we analyze the bandwidth

304
00:10:40,800 --> 00:10:43,200
overheads incurred due to places padding

305
00:10:43,200 --> 00:10:44,640
of static purposes for different

306
00:10:44,640 --> 00:10:47,279
services and the trade-off between the

307
00:10:47,279 --> 00:10:48,720
bandwidth overheads and privacy

308
00:10:48,720 --> 00:10:50,940
guarantees that can be achieved after

309
00:10:50,940 --> 00:10:53,760
using public input based worker

310
00:10:53,760 --> 00:10:55,920
partitioning for traffic shipping

311
00:10:55,920 --> 00:10:58,079
we also measure the overheads on client

312
00:10:58,079 --> 00:11:00,240
latency and Peak server throughput

313
00:11:00,240 --> 00:11:02,339
sustained by a medical website that

314
00:11:02,339 --> 00:11:04,620
serves static medical web pages and we

315
00:11:04,620 --> 00:11:06,720
also evaluated the clients experience

316
00:11:06,720 --> 00:11:08,279
when streaming videos from a video

317
00:11:08,279 --> 00:11:10,860
service which is set up as both a single

318
00:11:10,860 --> 00:11:12,899
tier application as well as a two-tier

319
00:11:12,899 --> 00:11:15,180
application

320
00:11:15,180 --> 00:11:17,100
so we observed that Pacer incurs

321
00:11:17,100 --> 00:11:19,440
moderate overheads on bandwidth latency

322
00:11:19,440 --> 00:11:21,540
and the throughput for both the types of

323
00:11:21,540 --> 00:11:22,740
applications

324
00:11:22,740 --> 00:11:24,839
the absolute latency overheads are

325
00:11:24,839 --> 00:11:26,160
significant but they are still in the

326
00:11:26,160 --> 00:11:28,320
order of hundreds of milliseconds which

327
00:11:28,320 --> 00:11:30,300
could be further reduced by optimizing

328
00:11:30,300 --> 00:11:31,980
the transfer schedules that we compute

329
00:11:31,980 --> 00:11:33,779
for traffic shaping

330
00:11:33,779 --> 00:11:36,839
nonetheless the impact on the end crimes

331
00:11:36,839 --> 00:11:38,760
experience is actually minimal for

332
00:11:38,760 --> 00:11:40,140
example we observed that the video

333
00:11:40,140 --> 00:11:42,180
client experiences no Jitter when

334
00:11:42,180 --> 00:11:45,120
streaming videos despite traffic shaping

335
00:11:45,120 --> 00:11:47,279
the exact overheads depend on

336
00:11:47,279 --> 00:11:49,740
applications data workloads and the

337
00:11:49,740 --> 00:11:51,120
public inputs that are used for

338
00:11:51,120 --> 00:11:53,160
computing traffic shapes

339
00:11:53,160 --> 00:11:55,680
what Pacer provides is a way for the

340
00:11:55,680 --> 00:11:57,660
developers to configure the trade-offs

341
00:11:57,660 --> 00:11:59,779
between the overheads that is willing to

342
00:11:59,779 --> 00:12:02,399
incur and the Privacy guarantees that it

343
00:12:02,399 --> 00:12:05,220
wants for its application

344
00:12:05,220 --> 00:12:07,620
so to summarize Pacer is a traffic

345
00:12:07,620 --> 00:12:09,300
shaping based solution to mitigate

346
00:12:09,300 --> 00:12:10,800
Network side Channel leaks for

347
00:12:10,800 --> 00:12:13,260
infrastructure as a service Cloud tenant

348
00:12:13,260 --> 00:12:15,480
it is it provides a secure by Design

349
00:12:15,480 --> 00:12:17,700
solution in that it both its traffic

350
00:12:17,700 --> 00:12:19,680
shaping strategy as well as its

351
00:12:19,680 --> 00:12:22,440
enforcement of traffic shaping is secure

352
00:12:22,440 --> 00:12:24,600
it is also efficient as it allows to

353
00:12:24,600 --> 00:12:26,579
exploit public inputs to reduce the

354
00:12:26,579 --> 00:12:28,200
overhead sub traffic shaping for an

355
00:12:28,200 --> 00:12:30,300
application and it reacts to congestion

356
00:12:30,300 --> 00:12:32,040
control signals that's providing a

357
00:12:32,040 --> 00:12:34,320
practically usable solution and finally

358
00:12:34,320 --> 00:12:36,540
Pacer requires minimal changes in the

359
00:12:36,540 --> 00:12:39,060
guest application to leverage the

360
00:12:39,060 --> 00:12:41,040
traffic shaping solution and a modest

361
00:12:41,040 --> 00:12:42,180
amount of changes in the cloud

362
00:12:42,180 --> 00:12:44,459
hypervisor and the guest OS to support

363
00:12:44,459 --> 00:12:46,200
the solution

364
00:12:46,200 --> 00:12:48,839
we have open source all of our code and

365
00:12:48,839 --> 00:12:50,339
you could check it out if you were

366
00:12:50,339 --> 00:12:52,200
interested and with that I'll be happy

367
00:12:52,200 --> 00:12:55,700
to take questions thank you

