1
00:00:07,580 --> 00:00:09,540
all right I'm very excited to be

2
00:00:09,540 --> 00:00:11,340
presenting uh to you all today and thank

3
00:00:11,340 --> 00:00:14,219
you for attending my talk as mentioned

4
00:00:14,219 --> 00:00:16,020
I'm going to be discussing our security

5
00:00:16,020 --> 00:00:18,300
analysis work on camera lighter Fusion

6
00:00:18,300 --> 00:00:20,340
against some black box attacks on

7
00:00:20,340 --> 00:00:22,740
self-driving cars

8
00:00:22,740 --> 00:00:24,779
first a little bit of information on why

9
00:00:24,779 --> 00:00:26,160
understanding the vulnerability of

10
00:00:26,160 --> 00:00:28,500
perception is important as we probably

11
00:00:28,500 --> 00:00:30,960
all know autonomous vehicles rely on

12
00:00:30,960 --> 00:00:33,480
many sensors and Those sensors in order

13
00:00:33,480 --> 00:00:35,100
to translate that data into meaningful

14
00:00:35,100 --> 00:00:37,020
semantic information on the environment

15
00:00:37,020 --> 00:00:39,360
rely on perception increasingly

16
00:00:39,360 --> 00:00:41,940
perception is is being based on deep

17
00:00:41,940 --> 00:00:43,559
neural network architectures to

18
00:00:43,559 --> 00:00:45,120
translate that massive volume of data

19
00:00:45,120 --> 00:00:47,340
into the semantic information but as it

20
00:00:47,340 --> 00:00:48,960
has been discovered in a variety of

21
00:00:48,960 --> 00:00:51,120
Prior Works perception using deep neural

22
00:00:51,120 --> 00:00:52,920
networks is vulnerable to a wide array

23
00:00:52,920 --> 00:00:55,140
of different attacks the one we're going

24
00:00:55,140 --> 00:00:57,660
to discuss today for our prior research

25
00:00:57,660 --> 00:00:59,460
is structured spoofing and injection

26
00:00:59,460 --> 00:01:01,620
attacks and we chose to focus on this

27
00:01:01,620 --> 00:01:03,239
because we believe the lidar point cloud

28
00:01:03,239 --> 00:01:06,240
and its Associated algorithms were under

29
00:01:06,240 --> 00:01:09,600
analyzed in the security community

30
00:01:09,600 --> 00:01:11,400
um similarly we've found that it's not

31
00:01:11,400 --> 00:01:13,140
enough just to consider single

32
00:01:13,140 --> 00:01:15,780
instantaneous uh detections of lidar

33
00:01:15,780 --> 00:01:18,000
data in your security analysis given

34
00:01:18,000 --> 00:01:20,100
that the complexity of the multi-module

35
00:01:20,100 --> 00:01:21,780
autonomous vehicles it's very important

36
00:01:21,780 --> 00:01:24,479
to consider a lot of different modules

37
00:01:24,479 --> 00:01:26,040
of the autonomous vehicle in conjunction

38
00:01:26,040 --> 00:01:29,280
with a longitudinal case studies

39
00:01:29,280 --> 00:01:31,200
and finally a lot of previous case

40
00:01:31,200 --> 00:01:33,060
studies a lot of previous experiments in

41
00:01:33,060 --> 00:01:34,920
this in this area have considered single

42
00:01:34,920 --> 00:01:37,979
sensor perception pipelines whereas

43
00:01:37,979 --> 00:01:39,600
increasingly many industry-level

44
00:01:39,600 --> 00:01:41,040
autonomous vehicles are using

45
00:01:41,040 --> 00:01:43,560
multi-sensor Fusion

46
00:01:43,560 --> 00:01:45,540
so a little bit information before we

47
00:01:45,540 --> 00:01:47,100
start on the system and threat models

48
00:01:47,100 --> 00:01:49,079
that we're using for our attack model

49
00:01:49,079 --> 00:01:50,520
we're using a lighter spoofing threat

50
00:01:50,520 --> 00:01:52,860
model where an attacker places a

51
00:01:52,860 --> 00:01:55,500
roadside laser and a photodiode to be

52
00:01:55,500 --> 00:01:57,659
able to receive the victim-lighter

53
00:01:57,659 --> 00:02:01,259
sensors laser beams understand where

54
00:02:01,259 --> 00:02:03,240
it's coming from process it through a

55
00:02:03,240 --> 00:02:05,100
delay component and shoot back laser

56
00:02:05,100 --> 00:02:07,140
beams as an adversary through an attack

57
00:02:07,140 --> 00:02:08,459
laser

58
00:02:08,459 --> 00:02:10,020
the only knowledge that's required with

59
00:02:10,020 --> 00:02:11,879
this threat model is line of sight

60
00:02:11,879 --> 00:02:15,060
information between the victim and and

61
00:02:15,060 --> 00:02:16,860
the attacker to be able to receive and

62
00:02:16,860 --> 00:02:19,020
transmit that signal and we're using a

63
00:02:19,020 --> 00:02:20,940
baseline established in Prior works that

64
00:02:20,940 --> 00:02:23,160
showed that a capability of up to 200

65
00:02:23,160 --> 00:02:25,980
spook points was stably achievable

66
00:02:25,980 --> 00:02:27,420
given this threat model you can come up

67
00:02:27,420 --> 00:02:28,680
with a couple of different attacker

68
00:02:28,680 --> 00:02:30,959
designs the first which has been

69
00:02:30,959 --> 00:02:32,700
proposed in a couple of Prior Works was

70
00:02:32,700 --> 00:02:34,920
a naive attack and we decide to evaluate

71
00:02:34,920 --> 00:02:36,780
the naive attack in a couple of new

72
00:02:36,780 --> 00:02:39,300
contacts in this work the definition of

73
00:02:39,300 --> 00:02:40,920
our naive attack is spoofing at Frontier

74
00:02:40,920 --> 00:02:42,599
positions of the victim without any

75
00:02:42,599 --> 00:02:44,040
additional contextual information and

76
00:02:44,040 --> 00:02:45,720
you can see that at the left with the

77
00:02:45,720 --> 00:02:47,459
goal of making the victim perform

78
00:02:47,459 --> 00:02:49,680
evasive maneuvers like emergency braking

79
00:02:49,680 --> 00:02:53,580
or or obstacle avoidance unnecessarily

80
00:02:53,580 --> 00:02:55,319
and the second attack which we've

81
00:02:55,319 --> 00:02:57,480
discovered that I'll be presenting a lot

82
00:02:57,480 --> 00:02:59,519
in Greater detail in the future is

83
00:02:59,519 --> 00:03:01,739
spoofing relative to an existing car in

84
00:03:01,739 --> 00:03:03,120
the scene and we call that in this case

85
00:03:03,120 --> 00:03:04,800
the frustum attack and I will get into

86
00:03:04,800 --> 00:03:07,040
this

87
00:03:07,620 --> 00:03:09,300
like I mentioned autonomous vehicles

88
00:03:09,300 --> 00:03:10,860
rely on a lot of different sensors and

89
00:03:10,860 --> 00:03:12,540
I've I've just put up a sample of those

90
00:03:12,540 --> 00:03:14,099
on the left and in order to translate

91
00:03:14,099 --> 00:03:16,620
that information uh the sensor data is

92
00:03:16,620 --> 00:03:18,180
processed through a series of decision

93
00:03:18,180 --> 00:03:20,459
and control logic in this work we're

94
00:03:20,459 --> 00:03:21,720
going to focus on the lighter and the

95
00:03:21,720 --> 00:03:23,159
camera sensors as those are some of the

96
00:03:23,159 --> 00:03:24,480
most common sensors used in

97
00:03:24,480 --> 00:03:26,819
industry-level autonomous vehicles and

98
00:03:26,819 --> 00:03:28,800
in order to understand what's happening

99
00:03:28,800 --> 00:03:30,300
with that sensor data we're going to

100
00:03:30,300 --> 00:03:31,920
look at the perception and the tracking

101
00:03:31,920 --> 00:03:32,940
modules

102
00:03:32,940 --> 00:03:35,519
for static data sets or for static

103
00:03:35,519 --> 00:03:37,200
evaluations and longitudinal case

104
00:03:37,200 --> 00:03:38,819
studies we use the kitty data set and

105
00:03:38,819 --> 00:03:40,440
later on I'll show we use the Beto

106
00:03:40,440 --> 00:03:44,180
Apollo model with the svl simulator

107
00:03:44,580 --> 00:03:46,260
to give a little bit more background on

108
00:03:46,260 --> 00:03:47,940
Sensor Fusion and how Sensor Fusion

109
00:03:47,940 --> 00:03:49,099
Works in autonomous vehicles

110
00:03:49,099 --> 00:03:51,299
specifically regarding the fusion of

111
00:03:51,299 --> 00:03:53,280
camera and lidar sensor data you can

112
00:03:53,280 --> 00:03:54,900
break out Sensor Fusion into a couple of

113
00:03:54,900 --> 00:03:56,519
different subcategories one of which is

114
00:03:56,519 --> 00:03:59,760
semantic level Fusion which takes the

115
00:03:59,760 --> 00:04:01,980
sensor data individually and processes

116
00:04:01,980 --> 00:04:04,739
those either in series or independently

117
00:04:04,739 --> 00:04:06,659
to get the semantic information and then

118
00:04:06,659 --> 00:04:08,879
performs the fusion at more of a

119
00:04:08,879 --> 00:04:10,340
semantic level

120
00:04:10,340 --> 00:04:13,019
of the pipeline and that's in contrast

121
00:04:13,019 --> 00:04:15,060
to feature level Fusion which takes a

122
00:04:15,060 --> 00:04:17,399
different approach of ingesting that

123
00:04:17,399 --> 00:04:19,199
camera and lidar data into one

124
00:04:19,199 --> 00:04:20,940
centralized perception and fusion

125
00:04:20,940 --> 00:04:22,800
algorithm to Output semantic information

126
00:04:22,800 --> 00:04:25,680
at the output of that

127
00:04:25,680 --> 00:04:27,180
um a couple of key reasons why Sensor

128
00:04:27,180 --> 00:04:28,620
Fusion is very important for autonomous

129
00:04:28,620 --> 00:04:30,540
driving one is for increased robustness

130
00:04:30,540 --> 00:04:33,120
and redundancy it's thought that Sensor

131
00:04:33,120 --> 00:04:34,740
Fusion can mitigate vulnerabilities and

132
00:04:34,740 --> 00:04:36,479
performance degradations versus a single

133
00:04:36,479 --> 00:04:38,639
sensor alone second is reduce model

134
00:04:38,639 --> 00:04:40,259
complexity particularly regarding

135
00:04:40,259 --> 00:04:42,419
semantic level Fusion to reduce to

136
00:04:42,419 --> 00:04:44,759
reduce the amount of data volume that's

137
00:04:44,759 --> 00:04:46,620
being processed

138
00:04:46,620 --> 00:04:48,540
and third is of course with more data

139
00:04:48,540 --> 00:04:49,919
comes the opportunity but not the

140
00:04:49,919 --> 00:04:51,900
guarantee to get improved performance of

141
00:04:51,900 --> 00:04:54,000
the perception

142
00:04:54,000 --> 00:04:56,880
yeah so um

143
00:04:56,880 --> 00:04:58,320
pairing these together a little bit how

144
00:04:58,320 --> 00:05:00,060
we take our threat model and the in the

145
00:05:00,060 --> 00:05:01,139
autonomous vehicle model and do

146
00:05:01,139 --> 00:05:03,479
evaluations we take we capture a couple

147
00:05:03,479 --> 00:05:05,759
of outcomes uh one of which is false

148
00:05:05,759 --> 00:05:06,840
positive which we're particularly

149
00:05:06,840 --> 00:05:08,699
interested in another are false negative

150
00:05:08,699 --> 00:05:11,639
outcomes and the simultaneous instances

151
00:05:11,639 --> 00:05:13,259
of false positives and false negatives

152
00:05:13,259 --> 00:05:16,259
we call translation outcomes

153
00:05:16,259 --> 00:05:18,840
in order to ascertain the effect of our

154
00:05:18,840 --> 00:05:21,120
attacks on the outcomes and make sure

155
00:05:21,120 --> 00:05:22,620
that any outcomes that we observe are

156
00:05:22,620 --> 00:05:24,900
directly related to the attacks we take

157
00:05:24,900 --> 00:05:26,039
a pretty straightforward approach where

158
00:05:26,039 --> 00:05:28,320
we run a baseline case in our analysis

159
00:05:28,320 --> 00:05:29,840
of running

160
00:05:29,840 --> 00:05:31,919
unattacked data through perception to

161
00:05:31,919 --> 00:05:33,240
get Baseline performance and then

162
00:05:33,240 --> 00:05:35,600
running the attacked

163
00:05:35,600 --> 00:05:38,639
attacked data through perception and

164
00:05:38,639 --> 00:05:41,419
comparing the results

165
00:05:41,880 --> 00:05:43,860
so with that in mind I'm going to

166
00:05:43,860 --> 00:05:46,199
discuss how we evaluated the naive

167
00:05:46,199 --> 00:05:48,120
attacks in new context and how we looked

168
00:05:48,120 --> 00:05:49,740
at a couple of existing defenses against

169
00:05:49,740 --> 00:05:51,600
naive attacks

170
00:05:51,600 --> 00:05:53,940
we really performed an incredibly

171
00:05:53,940 --> 00:05:57,060
extensive analysis of naive attacks and

172
00:05:57,060 --> 00:05:58,680
I'm not going to get into all of the

173
00:05:58,680 --> 00:06:01,320
details in this particular slide but I

174
00:06:01,320 --> 00:06:03,600
did want to highlight one particular

175
00:06:03,600 --> 00:06:05,960
case

176
00:06:06,500 --> 00:06:10,259
we discovered that or we validated the

177
00:06:10,259 --> 00:06:11,880
fact that naive attacks are devastating

178
00:06:11,880 --> 00:06:14,940
against lidar based perception here each

179
00:06:14,940 --> 00:06:16,440
of the different lines represents a

180
00:06:16,440 --> 00:06:17,759
different lighter based perception

181
00:06:17,759 --> 00:06:20,160
algorithm and the x-axis represents the

182
00:06:20,160 --> 00:06:22,139
number of spoof points and the y-axis

183
00:06:22,139 --> 00:06:23,819
represents the attack success rate that

184
00:06:23,819 --> 00:06:26,160
we're able to get using the naive

185
00:06:26,160 --> 00:06:28,680
spoofing model and as you would expect

186
00:06:28,680 --> 00:06:30,539
undefended lighter based perception is

187
00:06:30,539 --> 00:06:32,880
incredibly vulnerable to these naive

188
00:06:32,880 --> 00:06:35,400
spoofing attacks prior Works had only

189
00:06:35,400 --> 00:06:37,620
analyzed naive spoofing at close ranges

190
00:06:37,620 --> 00:06:39,180
so around eight meters away from the

191
00:06:39,180 --> 00:06:40,740
autonomous vehicle and we extended that

192
00:06:40,740 --> 00:06:42,240
analysis to more of a medium and

193
00:06:42,240 --> 00:06:44,160
long-range context where we're looking

194
00:06:44,160 --> 00:06:45,900
at around 30 meters away from the

195
00:06:45,900 --> 00:06:47,580
autonomous vehicle we're injecting those

196
00:06:47,580 --> 00:06:50,220
spoof spoof Point clusters and defining

197
00:06:50,220 --> 00:06:51,840
attack success rate is getting a false

198
00:06:51,840 --> 00:06:54,619
positive detection

199
00:06:55,259 --> 00:06:57,000
one of the most popular defenses against

200
00:06:57,000 --> 00:06:59,340
lighter based spoofing is this defense

201
00:06:59,340 --> 00:07:02,039
called Carlo and that was shown to guard

202
00:07:02,039 --> 00:07:04,380
perception against close range attacks

203
00:07:04,380 --> 00:07:05,940
using some physics-based assumptions

204
00:07:05,940 --> 00:07:08,699
about how Vehicles should appear in a

205
00:07:08,699 --> 00:07:10,380
natural environment

206
00:07:10,380 --> 00:07:12,720
by extending this analysis of naive

207
00:07:12,720 --> 00:07:14,520
attacks out to medium range we were

208
00:07:14,520 --> 00:07:15,900
actually able to show that the Carlo

209
00:07:15,900 --> 00:07:18,360
defense does not perform as well at

210
00:07:18,360 --> 00:07:20,280
medium range as it does at close range

211
00:07:20,280 --> 00:07:22,199
and as you can see then the attack

212
00:07:22,199 --> 00:07:24,840
success rate is nearly as high at medium

213
00:07:24,840 --> 00:07:27,900
range as it is at the close range

214
00:07:27,900 --> 00:07:29,520
and so you might be asking why is this

215
00:07:29,520 --> 00:07:31,139
important why is it important that Carlo

216
00:07:31,139 --> 00:07:33,300
works at close range but not at medium

217
00:07:33,300 --> 00:07:35,940
range and that's because if an attacker

218
00:07:35,940 --> 00:07:38,160
initiated an attack over a longitudinal

219
00:07:38,160 --> 00:07:40,800
sequence starting at medium range they

220
00:07:40,800 --> 00:07:45,060
would be able to create a scenario that

221
00:07:45,060 --> 00:07:47,280
the autonomous vehicle the victim

222
00:07:47,280 --> 00:07:49,319
vehicle could think is dangerous so here

223
00:07:49,319 --> 00:07:50,520
we've shown that there's an existing

224
00:07:50,520 --> 00:07:52,919
true object on the left and we've

225
00:07:52,919 --> 00:07:54,479
spoofed an object on the right at 40

226
00:07:54,479 --> 00:07:55,620
meters

227
00:07:55,620 --> 00:07:58,440
and over time we spoofed that that

228
00:07:58,440 --> 00:08:00,180
object is getting closer to the victim

229
00:08:00,180 --> 00:08:02,280
vehicle here at 30 meters here at 20

230
00:08:02,280 --> 00:08:04,319
meters and it's not until when the

231
00:08:04,319 --> 00:08:06,120
victim or when the spoofed object is at

232
00:08:06,120 --> 00:08:07,919
10 meters is the Carla defense able to

233
00:08:07,919 --> 00:08:09,780
recognize based on its physics-based

234
00:08:09,780 --> 00:08:11,819
assumptions that this vehicle is

235
00:08:11,819 --> 00:08:13,380
actually fake

236
00:08:13,380 --> 00:08:15,599
so if you were to rely on this defense

237
00:08:15,599 --> 00:08:17,819
over time the attacker could create

238
00:08:17,819 --> 00:08:20,340
longitudinal circumstances that even

239
00:08:20,340 --> 00:08:22,440
after only a couple of frames the the

240
00:08:22,440 --> 00:08:24,780
victim vehicle would think that there

241
00:08:24,780 --> 00:08:26,520
was a dangerous situation and would have

242
00:08:26,520 --> 00:08:28,080
to perform evasive maneuvers emergency

243
00:08:28,080 --> 00:08:30,620
braking

244
00:08:32,760 --> 00:08:34,080
um so instead one of the contributions

245
00:08:34,080 --> 00:08:36,719
of our work was to study for the first

246
00:08:36,719 --> 00:08:39,419
time through extensive evaluation Sensor

247
00:08:39,419 --> 00:08:41,279
Fusion as a possible defense against the

248
00:08:41,279 --> 00:08:42,479
naive attack

249
00:08:42,479 --> 00:08:44,099
and what we found is that in general

250
00:08:44,099 --> 00:08:46,380
camera ladder Fusion is better suited

251
00:08:46,380 --> 00:08:48,420
especially in medium ranges at guarding

252
00:08:48,420 --> 00:08:50,700
against these types of attacks and even

253
00:08:50,700 --> 00:08:52,980
the worst performing Fusion algorithm on

254
00:08:52,980 --> 00:08:55,200
the right is on par or better than the

255
00:08:55,200 --> 00:08:56,880
Carlo defense at medium range and in

256
00:08:56,880 --> 00:08:58,740
fact Frost and poignant and convenant 2

257
00:08:58,740 --> 00:09:00,660
of our perception algorithms almost

258
00:09:00,660 --> 00:09:02,519
completely eliminate the effects of

259
00:09:02,519 --> 00:09:04,019
naive attacks

260
00:09:04,019 --> 00:09:06,480
so that's a really uh one one motivation

261
00:09:06,480 --> 00:09:08,700
one benefit of using Sensor Fusion to

262
00:09:08,700 --> 00:09:11,040
guard against uh to guard lighter based

263
00:09:11,040 --> 00:09:14,420
perception against spoofing attacks

264
00:09:14,760 --> 00:09:17,459
but what I want to get into now is that

265
00:09:17,459 --> 00:09:18,600
um actually

266
00:09:18,600 --> 00:09:20,519
camera lighter Fusion is not actually a

267
00:09:20,519 --> 00:09:23,339
silver bullet against uh lighter lidar

268
00:09:23,339 --> 00:09:25,380
attacks and what we've discovered is

269
00:09:25,380 --> 00:09:27,060
that there's this novel context aware

270
00:09:27,060 --> 00:09:28,620
attack which we call the frustum attack

271
00:09:28,620 --> 00:09:31,320
that's able to compromise an intrinsic

272
00:09:31,320 --> 00:09:34,080
camera light or vulnerability

273
00:09:34,080 --> 00:09:35,760
a little bit of information on what a

274
00:09:35,760 --> 00:09:38,339
frustum is so a frustum is defined in

275
00:09:38,339 --> 00:09:40,980
our case especially by a 2d bounding box

276
00:09:40,980 --> 00:09:43,320
extended or extruded out into three

277
00:09:43,320 --> 00:09:45,120
dimensions so in the bottom right you

278
00:09:45,120 --> 00:09:47,640
can see there's a camera and any a

279
00:09:47,640 --> 00:09:49,680
camera is only able to resolve angles

280
00:09:49,680 --> 00:09:51,480
only in the 3D space so it's a

281
00:09:51,480 --> 00:09:53,279
two-dimensional projection of the 3D

282
00:09:53,279 --> 00:09:55,200
World

283
00:09:55,200 --> 00:09:56,760
um given that you can see in the top

284
00:09:56,760 --> 00:09:58,440
left if there's a bounding box in the

285
00:09:58,440 --> 00:09:59,820
camera image if you were to try to

286
00:09:59,820 --> 00:10:01,500
extend where that is out into three

287
00:10:01,500 --> 00:10:03,120
dimensions

288
00:10:03,120 --> 00:10:04,680
um there's a there's uncertainty along

289
00:10:04,680 --> 00:10:06,660
that range axis and that shape that's

290
00:10:06,660 --> 00:10:08,459
created by extruding the two-dimensional

291
00:10:08,459 --> 00:10:12,319
box into 3D is called a frustum

292
00:10:12,360 --> 00:10:14,399
and because of this inherent uncertainty

293
00:10:14,399 --> 00:10:16,560
of the range Dimension we hypothesize

294
00:10:16,560 --> 00:10:19,080
two potential vulnerabilities of camera

295
00:10:19,080 --> 00:10:21,300
lighter Fusion one is the frustum

296
00:10:21,300 --> 00:10:23,940
vulnerability and that's due to the fact

297
00:10:23,940 --> 00:10:27,000
that the 3D space in front or behind an

298
00:10:27,000 --> 00:10:29,220
existing Target vehicle is consistent so

299
00:10:29,220 --> 00:10:31,860
if you were able to move that car within

300
00:10:31,860 --> 00:10:34,200
that thrustum

301
00:10:34,200 --> 00:10:35,940
when you project that information back

302
00:10:35,940 --> 00:10:37,500
to the 2D plane it would still be

303
00:10:37,500 --> 00:10:38,940
consistent with the two-dimensional

304
00:10:38,940 --> 00:10:40,800
information even though the range has

305
00:10:40,800 --> 00:10:42,120
changed

306
00:10:42,120 --> 00:10:44,579
and the second vulnerability of this

307
00:10:44,579 --> 00:10:47,579
um of this approach is that

308
00:10:47,579 --> 00:10:50,160
in 3D an object will create a shadow

309
00:10:50,160 --> 00:10:51,779
region particularly with the lidar point

310
00:10:51,779 --> 00:10:53,339
cloud and you can see that shadow region

311
00:10:53,339 --> 00:10:55,500
and subfigure C there where no lighter

312
00:10:55,500 --> 00:10:57,660
points exist so our frustum attack is

313
00:10:57,660 --> 00:10:59,040
able to leverage both of these potential

314
00:10:59,040 --> 00:11:01,260
vulnerabilities which I'll uh describe

315
00:11:01,260 --> 00:11:03,660
and hopefully become more intuitive

316
00:11:03,660 --> 00:11:05,160
our first experiment was to show that

317
00:11:05,160 --> 00:11:07,019
this frustum attack is feasible in a

318
00:11:07,019 --> 00:11:09,120
physical sense so we created a physical

319
00:11:09,120 --> 00:11:10,680
experiment where we placed a spoofing

320
00:11:10,680 --> 00:11:12,720
device behind a Target car and in front

321
00:11:12,720 --> 00:11:15,300
of a victim you can see the setup in the

322
00:11:15,300 --> 00:11:17,640
left and we're able to stably spoof

323
00:11:17,640 --> 00:11:19,260
points in the frustum and I fear I've

324
00:11:19,260 --> 00:11:21,720
outlined hopefully you can see um

325
00:11:21,720 --> 00:11:24,000
our spoof Wing cluster behind a Target

326
00:11:24,000 --> 00:11:25,500
car

327
00:11:25,500 --> 00:11:28,740
so here's just a short video that's just

328
00:11:28,740 --> 00:11:30,240
showing that in certain cases the

329
00:11:30,240 --> 00:11:32,220
frustum attack is feasible without any

330
00:11:32,220 --> 00:11:34,140
additional knowledge again the attacker

331
00:11:34,140 --> 00:11:36,060
here has no knowledge of anything about

332
00:11:36,060 --> 00:11:37,620
the camera

333
00:11:37,620 --> 00:11:39,779
um so the attack is context aware in

334
00:11:39,779 --> 00:11:41,339
terms of it needs information from the

335
00:11:41,339 --> 00:11:43,320
scene but it doesn't actually require

336
00:11:43,320 --> 00:11:45,839
information on the camera

337
00:11:45,839 --> 00:11:47,640
once we introduce perception into the

338
00:11:47,640 --> 00:11:49,019
equation we find that the frustum attack

339
00:11:49,019 --> 00:11:50,880
is particularly devastating so here we

340
00:11:50,880 --> 00:11:52,700
have a camera image in the top left

341
00:11:52,700 --> 00:11:55,019
that's unperturbed but in the bottom

342
00:11:55,019 --> 00:11:56,640
right we've injected a cluster of spoof

343
00:11:56,640 --> 00:11:58,860
points behind a Target object

344
00:11:58,860 --> 00:12:00,959
in the bracketed red and once we

345
00:12:00,959 --> 00:12:02,399
introduce perception into the equation

346
00:12:02,399 --> 00:12:04,380
we're able to get consistently false

347
00:12:04,380 --> 00:12:06,240
positive detections behind that Target

348
00:12:06,240 --> 00:12:08,519
car even with a camera lidar Fusion

349
00:12:08,519 --> 00:12:11,000
algorithm

350
00:12:12,000 --> 00:12:13,860
once again we really performed extensive

351
00:12:13,860 --> 00:12:15,959
analysis on the frustum attack we

352
00:12:15,959 --> 00:12:17,880
evaluated it on lighter only perception

353
00:12:17,880 --> 00:12:19,800
and we also evaluated it on camera

354
00:12:19,800 --> 00:12:21,959
ladder Fusion perception to the effect

355
00:12:21,959 --> 00:12:24,360
of showing that many classes of

356
00:12:24,360 --> 00:12:25,620
perception are vulnerable to this

357
00:12:25,620 --> 00:12:27,240
frustum attack

358
00:12:27,240 --> 00:12:29,100
specifically highlighting just one case

359
00:12:29,100 --> 00:12:31,800
the x-axis represents where we put those

360
00:12:31,800 --> 00:12:33,779
spoof points relative to the Target car

361
00:12:33,779 --> 00:12:36,540
and each of the the y-axis represents

362
00:12:36,540 --> 00:12:37,980
the attack success rate each of the

363
00:12:37,980 --> 00:12:39,779
different lines represents the number of

364
00:12:39,779 --> 00:12:41,459
the attack excuse me the number of

365
00:12:41,459 --> 00:12:43,920
attack points that we injected

366
00:12:43,920 --> 00:12:45,660
and here you can see pretty clearly that

367
00:12:45,660 --> 00:12:47,399
there's an attack success rate Peak both

368
00:12:47,399 --> 00:12:49,079
in front and behind the car which makes

369
00:12:49,079 --> 00:12:52,219
a little bit of intuitive sense

370
00:12:52,500 --> 00:12:54,720
finally my last technical slide here is

371
00:12:54,720 --> 00:12:57,480
that we did an evaluation of uh the

372
00:12:57,480 --> 00:12:59,339
frustum attack on longitudinal

373
00:12:59,339 --> 00:13:01,380
circumstances using multi-frame tracking

374
00:13:01,380 --> 00:13:03,720
and motion object prediction

375
00:13:03,720 --> 00:13:05,459
in this first case we were able to show

376
00:13:05,459 --> 00:13:08,639
that injecting spoof Wing clusters in

377
00:13:08,639 --> 00:13:10,139
increasingly closer distances so

378
00:13:10,139 --> 00:13:11,820
starting farther away and moving closer

379
00:13:11,820 --> 00:13:13,800
over longitudinal time points is able to

380
00:13:13,800 --> 00:13:16,800
create an accepted track of an

381
00:13:16,800 --> 00:13:19,680
adversarial object that if you predict

382
00:13:19,680 --> 00:13:21,600
that motion into the time just a couple

383
00:13:21,600 --> 00:13:24,480
of seconds later it appears as if

384
00:13:24,480 --> 00:13:27,240
uh this adversarial object is on a crash

385
00:13:27,240 --> 00:13:28,920
course for collision with the victim so

386
00:13:28,920 --> 00:13:30,060
the victim will have to perform some

387
00:13:30,060 --> 00:13:31,560
invasive maneuvers

388
00:13:31,560 --> 00:13:33,540
similarly we're able to do the opposite

389
00:13:33,540 --> 00:13:35,700
where we take an existing object and we

390
00:13:35,700 --> 00:13:38,399
increasingly put spoof points at further

391
00:13:38,399 --> 00:13:40,440
distances to make it appear as if this

392
00:13:40,440 --> 00:13:41,820
object is traveling away which can

393
00:13:41,820 --> 00:13:43,980
compromise adaptive cruise control and

394
00:13:43,980 --> 00:13:46,560
path planning

395
00:13:46,560 --> 00:13:48,959
and I encourage you to consult our paper

396
00:13:48,959 --> 00:13:50,519
in this last one but we also did an

397
00:13:50,519 --> 00:13:52,260
evaluation of industry-grade autonomous

398
00:13:52,260 --> 00:13:54,839
vehicles to show that even these High

399
00:13:54,839 --> 00:13:56,700
Fidelity models are vulnerable to the

400
00:13:56,700 --> 00:13:58,800
frustum attack

401
00:13:58,800 --> 00:14:00,300
in summary just a couple of our

402
00:14:00,300 --> 00:14:01,980
contributions we showed that the prior

403
00:14:01,980 --> 00:14:03,839
defenses against ladder spoofing can

404
00:14:03,839 --> 00:14:06,000
fail under certain circumstances that

405
00:14:06,000 --> 00:14:08,040
naive lighter attacks can be defended by

406
00:14:08,040 --> 00:14:10,279
camera light or Fusion pretty robustly

407
00:14:10,279 --> 00:14:12,959
however these latter Fusion algorithms

408
00:14:12,959 --> 00:14:14,399
are not a silver bullet and that they're

409
00:14:14,399 --> 00:14:16,260
vulnerable to a frustum attack which is

410
00:14:16,260 --> 00:14:18,660
feasible in the real world and over

411
00:14:18,660 --> 00:14:20,279
longitudinal circumstances can cause

412
00:14:20,279 --> 00:14:22,019
devastating outcomes

413
00:14:22,019 --> 00:14:24,480
thanks for listening and I will take any

414
00:14:24,480 --> 00:14:27,500
questions that anybody has

