1
00:00:07,460 --> 00:00:10,320
very much for as for everyone attending

2
00:00:10,320 --> 00:00:12,360
here in person and online my name is

3
00:00:12,360 --> 00:00:14,820
Bushra and I'll be presenting our paper

4
00:00:14,820 --> 00:00:18,539
titled 99 false positive a qualitative

5
00:00:18,539 --> 00:00:21,000
study of sock analyst perspectives on

6
00:00:21,000 --> 00:00:22,500
Security Alarms

7
00:00:22,500 --> 00:00:24,960
so the focus of our study is security

8
00:00:24,960 --> 00:00:27,539
operations centers which are the first

9
00:00:27,539 --> 00:00:30,480
line of defense in any organization so

10
00:00:30,480 --> 00:00:32,700
there are the centralized unit that

11
00:00:32,700 --> 00:00:36,180
provide the monitoring capabilities that

12
00:00:36,180 --> 00:00:38,040
are responsible for the detection of

13
00:00:38,040 --> 00:00:40,739
cyber security threats in any

14
00:00:40,739 --> 00:00:43,260
organization and in order to achieve

15
00:00:43,260 --> 00:00:45,719
that they use various Technologies so

16
00:00:45,719 --> 00:00:47,520
probably one of the most important one

17
00:00:47,520 --> 00:00:50,280
is the Sim which is a technology in the

18
00:00:50,280 --> 00:00:53,160
sock that basically pulls all the alerts

19
00:00:53,160 --> 00:00:55,739
from all the security tools deployed in

20
00:00:55,739 --> 00:00:58,379
the organization whether it's intrusion

21
00:00:58,379 --> 00:01:00,379
detection systems network monitoring

22
00:01:00,379 --> 00:01:04,260
antivirus and so on logs all pooled into

23
00:01:04,260 --> 00:01:07,080
the Sim and then analyzed to produce an

24
00:01:07,080 --> 00:01:09,479
alarm when there is a detection of a

25
00:01:09,479 --> 00:01:10,920
threat

26
00:01:10,920 --> 00:01:13,560
and of course the humans or the soccer

27
00:01:13,560 --> 00:01:16,080
analysts they are the ones responsible

28
00:01:16,080 --> 00:01:18,600
to deal with these alarms and it's no

29
00:01:18,600 --> 00:01:21,540
secret that analysts themselves are

30
00:01:21,540 --> 00:01:24,240
basically overwhelmed so they receive a

31
00:01:24,240 --> 00:01:26,880
high volume of alarms and they are

32
00:01:26,880 --> 00:01:29,580
tasked to determine the validity of

33
00:01:29,580 --> 00:01:32,100
these alarms which of these alarms are

34
00:01:32,100 --> 00:01:34,799
actually actual incidents threats that

35
00:01:34,799 --> 00:01:37,140
they have to take action and which of

36
00:01:37,140 --> 00:01:39,720
these are false positive and of course

37
00:01:39,720 --> 00:01:42,479
the majority of these alarm turn out to

38
00:01:42,479 --> 00:01:44,820
be false positive and of course if you

39
00:01:44,820 --> 00:01:47,540
deal this volume with this volume of

40
00:01:47,540 --> 00:01:50,759
alarms this can lead to human error

41
00:01:50,759 --> 00:01:53,280
fatigue and burnout which has been

42
00:01:53,280 --> 00:01:55,799
looked at in previous research as well

43
00:01:55,799 --> 00:01:58,939
it will lead to alarm desensitization

44
00:01:58,939 --> 00:02:02,340
mistrust and lock of lack of human

45
00:02:02,340 --> 00:02:05,340
responsiveness so basically the it

46
00:02:05,340 --> 00:02:07,439
reaches a point where the analyst will

47
00:02:07,439 --> 00:02:09,619
kind of ignore these alarms

48
00:02:09,619 --> 00:02:12,060
which is a challenge

49
00:02:12,060 --> 00:02:14,700
so in our research we set out to

50
00:02:14,700 --> 00:02:17,099
investigate alarms in socks to

51
00:02:17,099 --> 00:02:19,020
understand how sock analysts review

52
00:02:19,020 --> 00:02:21,780
these alarms and how can we improve the

53
00:02:21,780 --> 00:02:26,220
quality of these alarms and of course we

54
00:02:26,220 --> 00:02:29,640
for such a a research it's important to

55
00:02:29,640 --> 00:02:32,640
ask sock analyst perspectives on the

56
00:02:32,640 --> 00:02:35,040
alarms in order to learn from the

57
00:02:35,040 --> 00:02:36,480
challenges they face in their everyday

58
00:02:36,480 --> 00:02:38,099
tasks

59
00:02:38,099 --> 00:02:41,280
so let's move on to the methods and

60
00:02:41,280 --> 00:02:43,080
since our security operations centers in

61
00:02:43,080 --> 00:02:45,900
any organization they have distinct

62
00:02:45,900 --> 00:02:48,060
setups and goals and therefore the

63
00:02:48,060 --> 00:02:50,519
people technology and processes would be

64
00:02:50,519 --> 00:02:52,920
a unique as well for this reason we

65
00:02:52,920 --> 00:02:54,840
followed an inductive approach so we

66
00:02:54,840 --> 00:02:57,540
started with a quantitative study as a

67
00:02:57,540 --> 00:02:59,099
starting point for our qualitative

68
00:02:59,099 --> 00:03:01,560
research so we started going through the

69
00:03:01,560 --> 00:03:03,420
literature on saw contusion detection

70
00:03:03,420 --> 00:03:06,060
systems in order to design our survey

71
00:03:06,060 --> 00:03:08,819
then we conducted a survey with 21 with

72
00:03:08,819 --> 00:03:11,400
20 participants and the goal with of the

73
00:03:11,400 --> 00:03:13,860
survey was to identify areas that we

74
00:03:13,860 --> 00:03:16,080
need to focus on in our qualitative

75
00:03:16,080 --> 00:03:17,459
research

76
00:03:17,459 --> 00:03:19,620
we then conducted semi-structured

77
00:03:19,620 --> 00:03:22,800
interviews with around 21 analysts that

78
00:03:22,800 --> 00:03:26,040
work across seven different stocks

79
00:03:26,040 --> 00:03:28,800
and since the survey was not intended to

80
00:03:28,800 --> 00:03:31,040
identify statistical significance

81
00:03:31,040 --> 00:03:33,599
instead it was used to focus our

82
00:03:33,599 --> 00:03:36,720
semi-structured interviews therefore in

83
00:03:36,720 --> 00:03:38,700
this talk we'll focus the discussion of

84
00:03:38,700 --> 00:03:40,739
the results on the results of our

85
00:03:40,739 --> 00:03:43,080
qualitative study but details of the

86
00:03:43,080 --> 00:03:45,599
qualitative quantitative study are in

87
00:03:45,599 --> 00:03:47,940
the paper as well

88
00:03:47,940 --> 00:03:50,099
So based on the findings from our

89
00:03:50,099 --> 00:03:52,080
quantitative study we identified the

90
00:03:52,080 --> 00:03:54,180
following research questions for our

91
00:03:54,180 --> 00:03:56,220
qualitative study so these are the

92
00:03:56,220 --> 00:03:58,739
research question how do sock analysts

93
00:03:58,739 --> 00:04:01,200
distinguish true alarms from false

94
00:04:01,200 --> 00:04:04,319
alarms what do analysts perceive to be a

95
00:04:04,319 --> 00:04:06,060
false positive and how can we establish

96
00:04:06,060 --> 00:04:08,220
a more precise definition what are the

97
00:04:08,220 --> 00:04:10,260
limitations of alarms produced by

98
00:04:10,260 --> 00:04:12,360
existing sock tools and how can we

99
00:04:12,360 --> 00:04:14,159
design better tools to improve the

100
00:04:14,159 --> 00:04:16,440
alarm's quality and filtering of false

101
00:04:16,440 --> 00:04:18,478
positives

102
00:04:18,478 --> 00:04:20,339
so starting with the first research

103
00:04:20,339 --> 00:04:21,418
question

104
00:04:21,418 --> 00:04:24,540
during our interview our analysis of our

105
00:04:24,540 --> 00:04:27,840
qualitative data we it revealed similar

106
00:04:27,840 --> 00:04:32,040
process across all socks in terms of how

107
00:04:32,040 --> 00:04:34,740
they perform alarm validation so usually

108
00:04:34,740 --> 00:04:36,479
they'll have the Sim that takes all the

109
00:04:36,479 --> 00:04:39,300
data and then presents an alarm to the

110
00:04:39,300 --> 00:04:41,400
soccer analyst and it's up to the

111
00:04:41,400 --> 00:04:43,259
analyst to determine if this is a true

112
00:04:43,259 --> 00:04:45,960
alarm meaning there is an actual attack

113
00:04:45,960 --> 00:04:47,820
happening that they have to take action

114
00:04:47,820 --> 00:04:50,699
or is this a false positive meaning that

115
00:04:50,699 --> 00:04:52,380
it's a false alarm

116
00:04:52,380 --> 00:04:54,600
and this process we will call alarm

117
00:04:54,600 --> 00:04:56,520
validation

118
00:04:56,520 --> 00:04:58,620
and determining if this alarm is

119
00:04:58,620 --> 00:05:00,800
actually a result of an actual threat

120
00:05:00,800 --> 00:05:03,900
basically comes down to the soccer

121
00:05:03,900 --> 00:05:06,720
analysts so there is a huge Reliance on

122
00:05:06,720 --> 00:05:09,360
the sock analyst to perform this job so

123
00:05:09,360 --> 00:05:11,040
based on the inputs the analysts is

124
00:05:11,040 --> 00:05:12,240
getting from all of these different

125
00:05:12,240 --> 00:05:14,520
security Technologies they use their

126
00:05:14,520 --> 00:05:16,740
cognitive ability to look and pattern

127
00:05:16,740 --> 00:05:17,780
rack

128
00:05:17,780 --> 00:05:20,820
pattern matching and other cognitive

129
00:05:20,820 --> 00:05:22,860
abilities in order to determine if this

130
00:05:22,860 --> 00:05:25,620
is a true alarm or a false positive as

131
00:05:25,620 --> 00:05:27,720
stated by one of our participants I

132
00:05:27,720 --> 00:05:29,280
think that's where the human element

133
00:05:29,280 --> 00:05:31,620
Still Remains because even if you get an

134
00:05:31,620 --> 00:05:34,080
alert the alert will have to be sent to

135
00:05:34,080 --> 00:05:35,820
the human to make the intelligent

136
00:05:35,820 --> 00:05:38,120
decision

137
00:05:38,460 --> 00:05:39,960
and similar to any kind of

138
00:05:39,960 --> 00:05:42,539
decision-making process the analyst

139
00:05:42,539 --> 00:05:47,039
would have many factors that influence

140
00:05:47,039 --> 00:05:49,500
how they make the decision and we narrow

141
00:05:49,500 --> 00:05:51,720
it down to multiple categories such as

142
00:05:51,720 --> 00:05:54,600
the type of client are we monitoring for

143
00:05:54,600 --> 00:05:57,180
a government versus non-government the

144
00:05:57,180 --> 00:05:59,280
type of sock they work is it an internal

145
00:05:59,280 --> 00:06:01,639
sock or is it a managed security service

146
00:06:01,639 --> 00:06:04,500
provider as well as the knowledge that

147
00:06:04,500 --> 00:06:07,020
they have accumulated through their

148
00:06:07,020 --> 00:06:09,300
experience at the monitored environment

149
00:06:09,300 --> 00:06:11,460
and each of these factors have many

150
00:06:11,460 --> 00:06:14,280
challenges within as well for example if

151
00:06:14,280 --> 00:06:16,620
an analyst Works in government they

152
00:06:16,620 --> 00:06:18,419
would have to have certain security

153
00:06:18,419 --> 00:06:20,340
clearance to access certain information

154
00:06:20,340 --> 00:06:23,039
that they need to validate the alarms so

155
00:06:23,039 --> 00:06:24,960
in most cases they wouldn't have that

156
00:06:24,960 --> 00:06:26,940
security clearance so they would have

157
00:06:26,940 --> 00:06:29,639
areas that is not clear to them as well

158
00:06:29,639 --> 00:06:32,220
as analysts who work in Secure managed

159
00:06:32,220 --> 00:06:34,259
security service providers they in

160
00:06:34,259 --> 00:06:36,060
addition to their daily job they also

161
00:06:36,060 --> 00:06:38,520
have pressures that come from dealing

162
00:06:38,520 --> 00:06:40,560
with clients pressures of fines

163
00:06:40,560 --> 00:06:42,479
pressures of actually have to deliver

164
00:06:42,479 --> 00:06:45,180
and communicate alerts as soon as

165
00:06:45,180 --> 00:06:47,280
possible but at the same time they fear

166
00:06:47,280 --> 00:06:49,560
that they would look inadequate if they

167
00:06:49,560 --> 00:06:51,660
reported an alarm and it turns out to be

168
00:06:51,660 --> 00:06:53,819
a false positive as well as the

169
00:06:53,819 --> 00:06:55,979
knowledge whether it's tacit knowledge

170
00:06:55,979 --> 00:06:58,919
or even knowledge of the environment and

171
00:06:58,919 --> 00:07:01,020
as one of the participants says the more

172
00:07:01,020 --> 00:07:03,900
the client shares the better job of a

173
00:07:03,900 --> 00:07:05,460
job we can do

174
00:07:05,460 --> 00:07:07,680
so all of these are factors that kind of

175
00:07:07,680 --> 00:07:10,560
impact the alarm validation and

176
00:07:10,560 --> 00:07:13,199
influence how the stock analysts

177
00:07:13,199 --> 00:07:15,419
determine if this is a true alarm or a

178
00:07:15,419 --> 00:07:16,620
false positive

179
00:07:16,620 --> 00:07:18,240
and as you can see there's a lot of

180
00:07:18,240 --> 00:07:21,180
endpoints inputs to the sock analysts

181
00:07:21,180 --> 00:07:23,400
and it's really a human cognitive effort

182
00:07:23,400 --> 00:07:27,900
to determine the validity of the alarm

183
00:07:27,900 --> 00:07:29,699
so moving on to our second research

184
00:07:29,699 --> 00:07:32,160
question what do cell analysts perceive

185
00:07:32,160 --> 00:07:34,380
to be a false positive and how can we

186
00:07:34,380 --> 00:07:36,960
establish a more precise definition

187
00:07:36,960 --> 00:07:39,240
so one of our participants stated and I

188
00:07:39,240 --> 00:07:41,280
think we heard this a lot we know that

189
00:07:41,280 --> 00:07:44,220
99 of the alarms we generate are false

190
00:07:44,220 --> 00:07:47,400
positives but we have to look at them so

191
00:07:47,400 --> 00:07:49,560
high percentage of the generated alarms

192
00:07:49,560 --> 00:07:51,599
in a sock are considered false positive

193
00:07:51,599 --> 00:07:54,300
meaning that they are not a true attack

194
00:07:54,300 --> 00:07:57,060
but what does that mean for us does that

195
00:07:57,060 --> 00:07:59,099
mean that the detection technology

196
00:07:59,099 --> 00:08:01,620
itself is flawed meaning all the

197
00:08:01,620 --> 00:08:03,660
security tools that we are designing are

198
00:08:03,660 --> 00:08:05,580
not performing their job

199
00:08:05,580 --> 00:08:07,380
and this is what we set out in our

200
00:08:07,380 --> 00:08:10,020
research to kind of investigate further

201
00:08:10,020 --> 00:08:12,419
so usually in security we have kind of

202
00:08:12,419 --> 00:08:15,240
two types of alarm true alarms which are

203
00:08:15,240 --> 00:08:17,160
alarms generated as a result of an

204
00:08:17,160 --> 00:08:19,560
actual security threat as well as false

205
00:08:19,560 --> 00:08:21,720
positive meaning a false alarm

206
00:08:21,720 --> 00:08:24,599
but as one of our participants stated if

207
00:08:24,599 --> 00:08:27,360
an alarm was produced by a security tool

208
00:08:27,360 --> 00:08:30,599
but the customer is aware of them and

209
00:08:30,599 --> 00:08:33,479
its origin but chooses to ignore it for

210
00:08:33,479 --> 00:08:35,820
a business reason should this be

211
00:08:35,820 --> 00:08:38,580
classified as a false positive and we've

212
00:08:38,580 --> 00:08:41,520
seen a multiple of these uh statements

213
00:08:41,520 --> 00:08:43,919
from our participants when we asked them

214
00:08:43,919 --> 00:08:47,220
about the adequate about the accuracy of

215
00:08:47,220 --> 00:08:49,620
the security tools they use and when we

216
00:08:49,620 --> 00:08:52,320
asked them about the 99 false positives

217
00:08:52,320 --> 00:08:54,839
that they keep reporting

218
00:08:54,839 --> 00:08:56,760
uh so for example one of the

219
00:08:56,760 --> 00:08:59,040
participants said that uh snort

220
00:08:59,040 --> 00:09:01,980
signatures are noisy well I say they're

221
00:09:01,980 --> 00:09:03,660
noisy because they're but they're

222
00:09:03,660 --> 00:09:05,399
actually doing what they should do

223
00:09:05,399 --> 00:09:07,860
they're always identifying vulnerable

224
00:09:07,860 --> 00:09:10,200
versions of java but a lot of companies

225
00:09:10,200 --> 00:09:12,000
have a lot of vulnerable versions of

226
00:09:12,000 --> 00:09:15,480
java so we uh so we get a massive influx

227
00:09:15,480 --> 00:09:17,880
of it so they know there is an issue but

228
00:09:17,880 --> 00:09:19,920
they just ignore it because there is a

229
00:09:19,920 --> 00:09:22,200
business reason why for example some

230
00:09:22,200 --> 00:09:24,360
organization wouldn't patch or wouldn't

231
00:09:24,360 --> 00:09:26,940
upgrade their Java versions

232
00:09:26,940 --> 00:09:29,820
so such alarms which are true alarms

233
00:09:29,820 --> 00:09:32,519
that match an existing signature that

234
00:09:32,519 --> 00:09:34,500
the organization chooses to ignore it

235
00:09:34,500 --> 00:09:37,200
for a business Justified purpose our

236
00:09:37,200 --> 00:09:39,899
participant called benign triggers

237
00:09:39,899 --> 00:09:42,600
so what are benign triggers that means

238
00:09:42,600 --> 00:09:45,480
that the condition is perfectly matched

239
00:09:45,480 --> 00:09:48,899
and the filter as such works but the

240
00:09:48,899 --> 00:09:51,000
circumstances are completely legitimate

241
00:09:51,000 --> 00:09:53,940
this is benign because the purpose is

242
00:09:53,940 --> 00:09:58,519
business Justified and is not malicious

243
00:09:58,920 --> 00:10:01,019
so benign triggers represent a high

244
00:10:01,019 --> 00:10:03,180
percentage of the alarms and therefore

245
00:10:03,180 --> 00:10:05,940
we should be careful when we use terms

246
00:10:05,940 --> 00:10:07,920
such as false positive because it kind

247
00:10:07,920 --> 00:10:09,540
of gives the impression that the

248
00:10:09,540 --> 00:10:11,760
technology itself is flawed which is not

249
00:10:11,760 --> 00:10:14,220
always the case

250
00:10:14,220 --> 00:10:17,459
so we should choose use that kind of

251
00:10:17,459 --> 00:10:20,279
distinction between alarms insecurity so

252
00:10:20,279 --> 00:10:21,839
we have the true alarms which are

253
00:10:21,839 --> 00:10:24,420
actually threats false positive means

254
00:10:24,420 --> 00:10:26,459
that the technology itself is not

255
00:10:26,459 --> 00:10:28,500
detecting the threat so it might need

256
00:10:28,500 --> 00:10:31,200
tuning and Improvement but also there is

257
00:10:31,200 --> 00:10:33,000
the benign triggers that is a business

258
00:10:33,000 --> 00:10:35,339
Justified exception for that specific

259
00:10:35,339 --> 00:10:39,660
client that we and we should label these

260
00:10:39,660 --> 00:10:41,360
uh alarms

261
00:10:41,360 --> 00:10:43,140
within these three kind of

262
00:10:43,140 --> 00:10:45,300
categorizations

263
00:10:45,300 --> 00:10:47,459
for our third research questions on the

264
00:10:47,459 --> 00:10:49,200
limitations of alarms produced by

265
00:10:49,200 --> 00:10:51,000
existing sock tools

266
00:10:51,000 --> 00:10:53,940
we actually in the paper we detailed the

267
00:10:53,940 --> 00:10:56,100
strengths and weaknesses that the

268
00:10:56,100 --> 00:10:59,459
participants listed for uh

269
00:10:59,459 --> 00:11:01,980
intrusion detection tools or even Sims

270
00:11:01,980 --> 00:11:04,140
but we can kind of distill these in

271
00:11:04,140 --> 00:11:05,880
three main categories that are related

272
00:11:05,880 --> 00:11:08,220
to other arm reliability and

273
00:11:08,220 --> 00:11:10,980
customizability alarm explainability and

274
00:11:10,980 --> 00:11:12,480
contextuality

275
00:11:12,480 --> 00:11:15,480
and brief the issues highlighted in

276
00:11:15,480 --> 00:11:17,519
security tools that are impacting the

277
00:11:17,519 --> 00:11:19,860
alarm liability are for example

278
00:11:19,860 --> 00:11:21,839
signatures that rely on features that

279
00:11:21,839 --> 00:11:23,579
change for example signatures that use

280
00:11:23,579 --> 00:11:26,040
domain names signatures were in to deal

281
00:11:26,040 --> 00:11:28,740
with new threats quickly

282
00:11:28,740 --> 00:11:31,019
um for example if there's a a new threat

283
00:11:31,019 --> 00:11:32,940
the the analysts quickly write the

284
00:11:32,940 --> 00:11:35,279
signature and they deploy it and they

285
00:11:35,279 --> 00:11:37,440
don't review it later on to tune it and

286
00:11:37,440 --> 00:11:40,860
so on also signatures Loosely or too

287
00:11:40,860 --> 00:11:42,540
broadly written to cover multiple

288
00:11:42,540 --> 00:11:46,040
attacks and that lead to a lot of

289
00:11:46,040 --> 00:11:48,480
low quality alarms

290
00:11:48,480 --> 00:11:50,220
so one of the examples one of our

291
00:11:50,220 --> 00:11:52,380
participating Salk mentioned is that

292
00:11:52,380 --> 00:11:55,260
they received a lot of alarms for SQL

293
00:11:55,260 --> 00:11:57,480
injections for one of the clients and

294
00:11:57,480 --> 00:11:59,160
when they explored they found that the

295
00:11:59,160 --> 00:12:01,620
signature was actually looking for words

296
00:12:01,620 --> 00:12:04,620
like select or drop table and when they

297
00:12:04,620 --> 00:12:06,959
investigated they found that the client

298
00:12:06,959 --> 00:12:09,720
actually is selling a product called

299
00:12:09,720 --> 00:12:12,180
drop table so it's like a foldable table

300
00:12:12,180 --> 00:12:16,320
so every time someone actually buys this

301
00:12:16,320 --> 00:12:19,500
drop table an alarm is goes to the sock

302
00:12:19,500 --> 00:12:22,019
so they can't actually disable this

303
00:12:22,019 --> 00:12:24,420
alarm because there is other clients for

304
00:12:24,420 --> 00:12:28,500
example that my user signature but this

305
00:12:28,500 --> 00:12:30,060
is actually example of something called

306
00:12:30,060 --> 00:12:32,880
the benign trigger

307
00:12:32,880 --> 00:12:36,320
also alarm explainability so

308
00:12:36,320 --> 00:12:39,839
uh analysts do not know why the alarm

309
00:12:39,839 --> 00:12:43,260
was fired there's no description and

310
00:12:43,260 --> 00:12:45,240
this kind of ambiguity leads to no

311
00:12:45,240 --> 00:12:48,899
action so the uh so the analysts do not

312
00:12:48,899 --> 00:12:51,660
um have a high respect or trust to these

313
00:12:51,660 --> 00:12:55,260
technologies that provide such alarms

314
00:12:55,260 --> 00:12:58,019
as well as alarm contextuality including

315
00:12:58,019 --> 00:13:01,079
context into alarm is important for

316
00:13:01,079 --> 00:13:02,820
example the customer business the

317
00:13:02,820 --> 00:13:06,660
knowledge of external sources and so on

318
00:13:06,660 --> 00:13:08,700
so how can we design better security

319
00:13:08,700 --> 00:13:12,000
tools from what we've learned from our

320
00:13:12,000 --> 00:13:14,760
study about unreliable alarms lack of

321
00:13:14,760 --> 00:13:17,579
explainability customizability we

322
00:13:17,579 --> 00:13:19,920
introduced the react model so these are

323
00:13:19,920 --> 00:13:22,620
properties that we should consider when

324
00:13:22,620 --> 00:13:25,320
we design tools reliable explainable

325
00:13:25,320 --> 00:13:27,420
analytical contextual and transferable

326
00:13:27,420 --> 00:13:29,940
and we also discuss in this paper how we

327
00:13:29,940 --> 00:13:31,680
can utilize machine learning to achieve

328
00:13:31,680 --> 00:13:34,440
these goals either through AI human

329
00:13:34,440 --> 00:13:37,380
collaboration explainable AI Knowledge

330
00:13:37,380 --> 00:13:39,000
Graph and so on and all of these are

331
00:13:39,000 --> 00:13:40,740
detailed in this paper

332
00:13:40,740 --> 00:13:43,800
and with that I conclude my talk thank

333
00:13:43,800 --> 00:13:45,300
you everyone for listening and from our

334
00:13:45,300 --> 00:13:47,339
collaborators and happy to answer any

335
00:13:47,339 --> 00:13:49,620
questions now or email or slack or

336
00:13:49,620 --> 00:13:52,760
Twitter thank you

