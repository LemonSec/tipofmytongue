1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:09,679 --> 00:00:13,219
and today I'm going to present my work

3
00:00:13,219 --> 00:00:16,920
deeply it's a collaboration work with

4
00:00:16,920 --> 00:00:18,199
um

5
00:00:18,199 --> 00:00:21,420
who and my advisor home in from UC

6
00:00:21,420 --> 00:00:24,779
Riverside and deep Beats

7
00:00:24,779 --> 00:00:26,400
okay so um

8
00:00:26,400 --> 00:00:29,699
many many binary analysis tasks rely on

9
00:00:29,699 --> 00:00:32,220
High level features and usually people

10
00:00:32,220 --> 00:00:35,700
use disassemblers like Capstone write-up

11
00:00:35,700 --> 00:00:38,579
procedure to extract those features such

12
00:00:38,579 --> 00:00:41,100
as control flow graph or intermediate

13
00:00:41,100 --> 00:00:42,780
representation

14
00:00:42,780 --> 00:00:46,260
and use those features in various

15
00:00:46,260 --> 00:00:48,960
Downstream tasks as you can see in these

16
00:00:48,960 --> 00:00:49,920
papers

17
00:00:49,920 --> 00:00:53,460
however as you may have noticed there is

18
00:00:53,460 --> 00:00:56,640
no time critical tasks in this list such

19
00:00:56,640 --> 00:00:59,300
as malware detection and that is because

20
00:00:59,300 --> 00:01:02,879
disassembling is slow

21
00:01:02,879 --> 00:01:06,180
here we only focus on x86 instructions

22
00:01:06,180 --> 00:01:09,600
and disassembling such instructions are

23
00:01:09,600 --> 00:01:12,299
not straightforward that's one of the

24
00:01:12,299 --> 00:01:14,520
main reasons

25
00:01:14,520 --> 00:01:17,760
um wire disassembling is slow there

26
00:01:17,760 --> 00:01:20,460
exists three challenges the first is

27
00:01:20,460 --> 00:01:23,520
that code and data May interleave the

28
00:01:23,520 --> 00:01:24,259
second

29
00:01:24,259 --> 00:01:27,740
x86 has dense encoding and the third

30
00:01:27,740 --> 00:01:30,780
instructions are variable length

31
00:01:30,780 --> 00:01:33,680
take these three by sequence for example

32
00:01:33,680 --> 00:01:37,860
it can be interpreted as data so these

33
00:01:37,860 --> 00:01:39,360
three letters

34
00:01:39,360 --> 00:01:43,979
or it can be called or a mix and there

35
00:01:43,979 --> 00:01:47,280
is no easy way to tell which case is

36
00:01:47,280 --> 00:01:49,520
true

37
00:01:50,579 --> 00:01:52,619
um many normal approaches has been

38
00:01:52,619 --> 00:01:55,500
proposed to tackle this problem there

39
00:01:55,500 --> 00:01:57,899
are papers published in various

40
00:01:57,899 --> 00:02:00,119
conferences they use different

41
00:02:00,119 --> 00:02:03,000
approaches such as probabilistic

42
00:02:03,000 --> 00:02:06,360
influence static program analysis logic

43
00:02:06,360 --> 00:02:08,580
influence and deep learning to improve

44
00:02:08,580 --> 00:02:10,500
disassembly accuracy

45
00:02:10,500 --> 00:02:11,819
however

46
00:02:11,819 --> 00:02:15,120
the accuracy comes at a price of low

47
00:02:15,120 --> 00:02:17,940
runtime efficiency as we can see in this

48
00:02:17,940 --> 00:02:19,879
table there is a trade-off between

49
00:02:19,879 --> 00:02:23,580
accuracy and efficiency and this is a

50
00:02:23,580 --> 00:02:24,360
problem

51
00:02:24,360 --> 00:02:27,300
despite the importance of disassembly we

52
00:02:27,300 --> 00:02:29,220
still don't have a disassembler that is

53
00:02:29,220 --> 00:02:30,560
both

54
00:02:30,560 --> 00:02:34,020
fast and accurate to support Downstream

55
00:02:34,020 --> 00:02:36,780
tasks and this is especially true when

56
00:02:36,780 --> 00:02:37,620
we

57
00:02:37,620 --> 00:02:40,860
when we are dealing with malware which

58
00:02:40,860 --> 00:02:43,440
is often obfuscated to evade

59
00:02:43,440 --> 00:02:46,019
disassemblers

60
00:02:46,019 --> 00:02:48,720
and to solve this problem we present a

61
00:02:48,720 --> 00:02:50,580
normal deep learning based disassembler

62
00:02:50,580 --> 00:02:53,819
Deep D which can achieve high accuracy

63
00:02:53,819 --> 00:02:56,640
and efficiency at the same time as well

64
00:02:56,640 --> 00:03:00,180
as generalizability and robustness

65
00:03:00,180 --> 00:03:03,360
and here is an overview so the high

66
00:03:03,360 --> 00:03:06,480
level idea is that we first

67
00:03:06,480 --> 00:03:10,560
obtain all possible disassembly results

68
00:03:10,560 --> 00:03:13,560
then we construct a graph using the

69
00:03:13,560 --> 00:03:16,260
instructions and finally we are going to

70
00:03:16,260 --> 00:03:19,500
filter out invalid instructions with the

71
00:03:19,500 --> 00:03:21,720
help of graph information and deep

72
00:03:21,720 --> 00:03:23,459
learning

73
00:03:23,459 --> 00:03:27,599
so the first is superset disassembly and

74
00:03:27,599 --> 00:03:30,379
supersize disassembly is a kind of

75
00:03:30,379 --> 00:03:33,860
disassembly approach where you

76
00:03:33,860 --> 00:03:36,599
disassemble starting from every single

77
00:03:36,599 --> 00:03:39,200
batch so as an example in this figure

78
00:03:39,200 --> 00:03:43,140
there are nine bytes so by disassembling

79
00:03:43,140 --> 00:03:46,260
from each of them we obtain nine

80
00:03:46,260 --> 00:03:48,720
possible instructions

81
00:03:48,720 --> 00:03:51,180
and superset disassembly comes with a

82
00:03:51,180 --> 00:03:53,459
nice feature which is there's no false

83
00:03:53,459 --> 00:03:54,720
negative

84
00:03:54,720 --> 00:03:58,260
we also modified a x86 decoder so that

85
00:03:58,260 --> 00:04:02,220
it runs in GPU to fully utilize the GPU

86
00:04:02,220 --> 00:04:04,200
parallelism

87
00:04:04,200 --> 00:04:06,959
and besides that we also convert the

88
00:04:06,959 --> 00:04:09,180
instructions to a fixed length vector

89
00:04:09,180 --> 00:04:12,239
and we call it metadata which keeps the

90
00:04:12,239 --> 00:04:13,640
key features

91
00:04:13,640 --> 00:04:17,220
such as opcode and registers

92
00:04:17,220 --> 00:04:19,798
but leaves out not so relevant features

93
00:04:19,798 --> 00:04:23,120
such as displacement

94
00:04:23,699 --> 00:04:26,340
and next we construct a graph called

95
00:04:26,340 --> 00:04:29,100
instruction flow graph and this graph

96
00:04:29,100 --> 00:04:32,520
shows possible execution Pathways and we

97
00:04:32,520 --> 00:04:35,580
add two additional kinds of edges to

98
00:04:35,580 --> 00:04:37,820
increase the expression the

99
00:04:37,820 --> 00:04:41,280
expressiveness of this graph so for

100
00:04:41,280 --> 00:04:45,419
example here we have nine instructions

101
00:04:45,419 --> 00:04:48,360
and each instruction is a node and then

102
00:04:48,360 --> 00:04:52,380
we connect two nodes via forward Edge

103
00:04:52,380 --> 00:04:55,979
say A to B if instruction a falls

104
00:04:55,979 --> 00:04:59,460
through or jumps to or cause instruction

105
00:04:59,460 --> 00:05:01,320
B

106
00:05:01,320 --> 00:05:03,780
and we also have backward Edge which is

107
00:05:03,780 --> 00:05:06,840
essentially the same as the floor that

108
00:05:06,840 --> 00:05:09,780
accepts the source and Target nodes are

109
00:05:09,780 --> 00:05:11,460
swapped

110
00:05:11,460 --> 00:05:14,340
and finally we have overlap Edge

111
00:05:14,340 --> 00:05:17,040
indicating the two instructions overlap

112
00:05:17,040 --> 00:05:19,199
with each other and that's how we

113
00:05:19,199 --> 00:05:21,840
construct the graph

114
00:05:21,840 --> 00:05:24,060
and once we have the graph we also need

115
00:05:24,060 --> 00:05:26,039
to prepare the inputs for the graph

116
00:05:26,039 --> 00:05:28,740
which are the initial values

117
00:05:28,740 --> 00:05:32,340
and to do so we use RN to encode every

118
00:05:32,340 --> 00:05:34,680
instruction and it's two following

119
00:05:34,680 --> 00:05:37,080
instructions and the two extra

120
00:05:37,080 --> 00:05:40,560
instructions are used as context

121
00:05:40,560 --> 00:05:45,000
and we do so because context matches in

122
00:05:45,000 --> 00:05:48,139
disassembly take the first instruction

123
00:05:48,139 --> 00:05:52,400
this compare instruction for example

124
00:05:52,400 --> 00:05:55,500
if we only see these

125
00:05:55,500 --> 00:05:59,580
instruction it can be an instruction or

126
00:05:59,580 --> 00:06:04,680
we maybe misinterprets data as code

127
00:06:04,680 --> 00:06:07,620
and we can't easily tell which case is

128
00:06:07,620 --> 00:06:08,639
true

129
00:06:08,639 --> 00:06:12,419
but if we if we also consider its next

130
00:06:12,419 --> 00:06:15,300
instruction the conditional jump at

131
00:06:15,300 --> 00:06:18,600
address 3 it becomes much more credible

132
00:06:18,600 --> 00:06:21,539
because that's how the compiler

133
00:06:21,539 --> 00:06:26,240
the compare instruction is normally used

134
00:06:27,600 --> 00:06:30,720
finally the RN outputs are used as

135
00:06:30,720 --> 00:06:34,560
inputs of this graph model and we

136
00:06:34,560 --> 00:06:36,720
this graph model relational graph

137
00:06:36,720 --> 00:06:39,319
convolutional Network

138
00:06:39,319 --> 00:06:42,479
to learn the structured data and to

139
00:06:42,479 --> 00:06:44,600
update node information

140
00:06:44,600 --> 00:06:48,120
and after each node propagates its

141
00:06:48,120 --> 00:06:50,460
information on the graph we will use the

142
00:06:50,460 --> 00:06:52,620
updated information for classification

143
00:06:52,620 --> 00:06:55,680
to tell like whether each node

144
00:06:55,680 --> 00:07:00,199
represents a valid instruction or not

145
00:07:00,600 --> 00:07:03,780
so um a quick recap we use superset

146
00:07:03,780 --> 00:07:06,780
disassembly to decode and extract the

147
00:07:06,780 --> 00:07:09,600
information metadata as the input

148
00:07:09,600 --> 00:07:12,479
the components in The Orange Box are

149
00:07:12,479 --> 00:07:14,580
trainable and they will encode and

150
00:07:14,580 --> 00:07:17,160
propagate inputs on the graph and the

151
00:07:17,160 --> 00:07:20,400
final output is the likelihood of each

152
00:07:20,400 --> 00:07:23,039
instruction being true instruction

153
00:07:23,039 --> 00:07:26,180
and our model is trained via supervised

154
00:07:26,180 --> 00:07:30,539
training in an end-to-end fashion

155
00:07:30,539 --> 00:07:34,380
okay and for the evaluation our training

156
00:07:34,380 --> 00:07:36,840
and testing set contains binaries from

157
00:07:36,840 --> 00:07:40,020
these four data sets and the binaries

158
00:07:40,020 --> 00:07:43,080
are compiled are compiled by various

159
00:07:43,080 --> 00:07:46,020
compilers and compilation options

160
00:07:46,020 --> 00:07:48,720
and we compare our approach with these

161
00:07:48,720 --> 00:07:51,780
five tools and they're either popular

162
00:07:51,780 --> 00:07:54,060
commercial tools or state-of-the-art

163
00:07:54,060 --> 00:07:57,259
academic papers

164
00:07:57,720 --> 00:08:00,300
um so first let's talk about efficiency

165
00:08:00,300 --> 00:08:05,220
note that the y-axis is log scale and

166
00:08:05,220 --> 00:08:07,860
from this figure we can clearly see that

167
00:08:07,860 --> 00:08:10,800
our approach is the fastest and in fact

168
00:08:10,800 --> 00:08:11,940
it's

169
00:08:11,940 --> 00:08:15,479
two orders of magnitude faster than the

170
00:08:15,479 --> 00:08:19,280
fastest one in Baseline

171
00:08:21,120 --> 00:08:24,300
we evaluate our generalizability

172
00:08:24,300 --> 00:08:27,120
here the training and testing binaries

173
00:08:27,120 --> 00:08:30,240
are compiled by different compilers and

174
00:08:30,240 --> 00:08:33,120
different optimization levels and that's

175
00:08:33,120 --> 00:08:35,458
how we make sure

176
00:08:35,458 --> 00:08:36,059
um

177
00:08:36,059 --> 00:08:38,700
these boundaries are considered unseen

178
00:08:38,700 --> 00:08:40,380
to the models

179
00:08:40,380 --> 00:08:42,659
and we compare our approach with another

180
00:08:42,659 --> 00:08:45,480
machine learning based state-of-the-art

181
00:08:45,480 --> 00:08:50,040
model the XDA and we and from the table

182
00:08:50,040 --> 00:08:54,000
you can see that we outperform XDA

183
00:08:54,000 --> 00:08:56,459
and there's another generalizability

184
00:08:56,459 --> 00:09:00,120
evaluation so we evaluate the model on

185
00:09:00,120 --> 00:09:03,899
10 unseen real-world programs and as you

186
00:09:03,899 --> 00:09:08,040
can see our result is on par with xdas

187
00:09:08,040 --> 00:09:11,220
and those two results suggest that our

188
00:09:11,220 --> 00:09:15,120
approach has good generalizability

189
00:09:15,120 --> 00:09:17,700
and the third evaluation is against

190
00:09:17,700 --> 00:09:19,320
Authentication

191
00:09:19,320 --> 00:09:22,980
we use a tool that is designed to like

192
00:09:22,980 --> 00:09:25,740
confuse linear and recursive disassembly

193
00:09:25,740 --> 00:09:28,440
and this table shows our approach is

194
00:09:28,440 --> 00:09:31,740
Superior in terms of accuracy and

195
00:09:31,740 --> 00:09:32,940
efficiency

196
00:09:32,940 --> 00:09:35,820
and and it also suggests that our

197
00:09:35,820 --> 00:09:38,760
approach is not affected by the

198
00:09:38,760 --> 00:09:42,380
increased code complexity

199
00:09:43,380 --> 00:09:45,959
and to show our approach can benefit

200
00:09:45,959 --> 00:09:49,560
Downstream tasks we conduct this malware

201
00:09:49,560 --> 00:09:51,720
classification by adding high level

202
00:09:51,720 --> 00:09:54,839
features to the classifier and in this

203
00:09:54,839 --> 00:09:57,060
example we use Amber

204
00:09:57,060 --> 00:09:59,640
the original Ember utilized static

205
00:09:59,640 --> 00:10:02,580
features like code histogram and

206
00:10:02,580 --> 00:10:04,560
imported function names

207
00:10:04,560 --> 00:10:07,680
and by adding code features Embry is

208
00:10:07,680 --> 00:10:10,459
able to achieve higher accuracy better

209
00:10:10,459 --> 00:10:13,860
generalizability with just slightly

210
00:10:13,860 --> 00:10:16,140
increased overhead

211
00:10:16,140 --> 00:10:20,040
know that this experiment is preliminary

212
00:10:20,040 --> 00:10:23,399
the Amber may not be the best choice

213
00:10:23,399 --> 00:10:25,920
for this task and through this

214
00:10:25,920 --> 00:10:28,620
experiment we mainly want to show that

215
00:10:28,620 --> 00:10:30,660
the bits open

216
00:10:30,660 --> 00:10:33,000
possibilities to leverage high-level

217
00:10:33,000 --> 00:10:34,380
features

218
00:10:34,380 --> 00:10:37,440
for binary analysis tasks especially

219
00:10:37,440 --> 00:10:41,600
through the time critical ones

220
00:10:41,940 --> 00:10:44,399
and apart from the evaluations in our

221
00:10:44,399 --> 00:10:46,920
paper I'd like to show some projects

222
00:10:46,920 --> 00:10:50,040
that we are working on that are based on

223
00:10:50,040 --> 00:10:53,940
DP the first one is this malware

224
00:10:53,940 --> 00:10:55,380
detection

225
00:10:55,380 --> 00:10:58,019
with high level features extracted by

226
00:10:58,019 --> 00:11:00,480
dipty we built a machine learning model

227
00:11:00,480 --> 00:11:03,300
that can recognize malicious functions

228
00:11:03,300 --> 00:11:06,959
in a binary and detect zero-day malware

229
00:11:06,959 --> 00:11:09,360
and this screenshot is our visualization

230
00:11:09,360 --> 00:11:13,380
of malicious functions by projecting

231
00:11:13,380 --> 00:11:15,360
them into a 3D space

232
00:11:15,360 --> 00:11:17,519
and it can also show the possible

233
00:11:17,519 --> 00:11:21,959
origins of the malicious functions

234
00:11:21,959 --> 00:11:25,920
and our second project targets spawn or

235
00:11:25,920 --> 00:11:28,800
software bill of materials it's

236
00:11:28,800 --> 00:11:31,680
essentially a composition analysis tool

237
00:11:31,680 --> 00:11:34,620
finding what libraries are statically

238
00:11:34,620 --> 00:11:37,920
linked in a binary and

239
00:11:37,920 --> 00:11:40,680
like in this figure

240
00:11:40,680 --> 00:11:45,300
we are able to find open SSL in curl

241
00:11:45,300 --> 00:11:48,180
and this composition analysis can be

242
00:11:48,180 --> 00:11:50,760
helpful in tasks like vulnerability

243
00:11:50,760 --> 00:11:56,160
detection reputation analysis and so on

244
00:11:56,160 --> 00:11:59,880
and to conclude we propose a noble deep

245
00:11:59,880 --> 00:12:02,220
learning based disassembler that is

246
00:12:02,220 --> 00:12:03,720
super fast

247
00:12:03,720 --> 00:12:06,899
and apart from efficiency it can also

248
00:12:06,899 --> 00:12:09,120
achieve high accuracy and good

249
00:12:09,120 --> 00:12:11,339
generalizability resilient

250
00:12:11,339 --> 00:12:14,399
sophistication and can be used in

251
00:12:14,399 --> 00:12:16,440
various Downstream tasks

252
00:12:16,440 --> 00:12:19,860
we also have an online version of dipty

253
00:12:19,860 --> 00:12:23,060
and this URL

254
00:12:23,060 --> 00:12:24,660
so

255
00:12:24,660 --> 00:12:27,060
um thank you you can find our binary

256
00:12:27,060 --> 00:12:30,600
release and this GitHub link and here is

257
00:12:30,600 --> 00:12:32,399
also our demo link

258
00:12:32,399 --> 00:12:35,100
and that's pretty much it thank you so

259
00:12:35,100 --> 00:12:39,440
much and I'm happy to take any questions

