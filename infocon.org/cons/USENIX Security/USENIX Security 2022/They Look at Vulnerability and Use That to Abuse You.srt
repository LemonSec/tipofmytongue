1
00:00:07,880 --> 00:00:10,260
the first paper that I'll be presenting

2
00:00:10,260 --> 00:00:12,599
on behalf of myself and my co-author is

3
00:00:12,599 --> 00:00:15,660
called networks of care and we looked at

4
00:00:15,660 --> 00:00:18,000
Advocates who support survivors of

5
00:00:18,000 --> 00:00:19,859
Technology abuse to understand their

6
00:00:19,859 --> 00:00:23,119
digital security practices

7
00:00:24,240 --> 00:00:28,099
and so a lot of existing research on

8
00:00:28,099 --> 00:00:30,960
technology-enabled abuse can be roughly

9
00:00:30,960 --> 00:00:34,440
put into two buckets so one on sort of

10
00:00:34,440 --> 00:00:37,260
defining the problem looking at how this

11
00:00:37,260 --> 00:00:39,420
happens in practice and then another on

12
00:00:39,420 --> 00:00:41,719
proposing Solutions and recommendations

13
00:00:41,719 --> 00:00:44,700
and what we argue in the paper is that

14
00:00:44,700 --> 00:00:46,980
with some very important exceptions a

15
00:00:46,980 --> 00:00:50,100
lot of This research Skips a step to

16
00:00:50,100 --> 00:00:52,520
looking at how responses on the ground

17
00:00:52,520 --> 00:00:54,780
in places like domestic violence

18
00:00:54,780 --> 00:00:56,280
shelters sexual violence support

19
00:00:56,280 --> 00:00:58,079
services what is actually happening

20
00:00:58,079 --> 00:00:59,820
already in terms of security on the

21
00:00:59,820 --> 00:01:01,199
ground

22
00:01:01,199 --> 00:01:04,379
and this kind of research framing is

23
00:01:04,379 --> 00:01:06,060
heavily influenced by critical security

24
00:01:06,060 --> 00:01:09,840
studies and feminist security studies

25
00:01:09,840 --> 00:01:12,360
which I'll get into in a second

26
00:01:12,360 --> 00:01:15,240
but so the first kind of research has

27
00:01:15,240 --> 00:01:17,700
helped us understand what the phenomenon

28
00:01:17,700 --> 00:01:20,100
of technology-enabled abuse is which is

29
00:01:20,100 --> 00:01:22,619
using Technologies to scare harass

30
00:01:22,619 --> 00:01:24,799
coerce or stalk someone

31
00:01:24,799 --> 00:01:26,820
particularly in the context of an

32
00:01:26,820 --> 00:01:28,979
intimate relationship although we note

33
00:01:28,979 --> 00:01:30,659
that this kind of abuse can also happen

34
00:01:30,659 --> 00:01:33,119
for example against sex workers is

35
00:01:33,119 --> 00:01:35,400
commonly perpetrated by institutions for

36
00:01:35,400 --> 00:01:37,680
example by the police but in this study

37
00:01:37,680 --> 00:01:39,659
we're primarily looking at intimate

38
00:01:39,659 --> 00:01:42,180
relationships

39
00:01:42,180 --> 00:01:44,700
um we also use the language of coercive

40
00:01:44,700 --> 00:01:46,740
control rather than domestic abuse which

41
00:01:46,740 --> 00:01:48,840
reflects a broader move in the field to

42
00:01:48,840 --> 00:01:50,820
reflect about people who experience

43
00:01:50,820 --> 00:01:52,560
coercive control aren't necessarily

44
00:01:52,560 --> 00:01:55,979
cohabitating as domestic might imply and

45
00:01:55,979 --> 00:01:57,960
aren't necessarily like physically

46
00:01:57,960 --> 00:02:00,479
violent but it could be this pattern of

47
00:02:00,479 --> 00:02:03,479
coercion and control

48
00:02:03,479 --> 00:02:05,340
um when this incorporates technology

49
00:02:05,340 --> 00:02:07,439
this can look like having access to

50
00:02:07,439 --> 00:02:08,880
someone's account because for example

51
00:02:08,880 --> 00:02:10,619
you purchase device it could include

52
00:02:10,619 --> 00:02:13,500
device compromise harassment malicious

53
00:02:13,500 --> 00:02:14,819
exposure which could be like

54
00:02:14,819 --> 00:02:16,500
non-consensual sharing of intimate

55
00:02:16,500 --> 00:02:19,200
images outing someone

56
00:02:19,200 --> 00:02:20,879
um and then gaslighting which is using

57
00:02:20,879 --> 00:02:22,500
technology to undermine people's

58
00:02:22,500 --> 00:02:24,420
perception of their own reality for

59
00:02:24,420 --> 00:02:27,720
example through smart home devices

60
00:02:27,720 --> 00:02:29,700
um we also draw on Research from the

61
00:02:29,700 --> 00:02:31,920
Cornell Tech and team which talks about

62
00:02:31,920 --> 00:02:34,260
a ui-bound adversary

63
00:02:34,260 --> 00:02:35,580
um so that's someone who's not very

64
00:02:35,580 --> 00:02:37,319
technically sophisticated but someone

65
00:02:37,319 --> 00:02:38,940
against whom a lot of conventional

66
00:02:38,940 --> 00:02:40,800
security techniques may be inadequate

67
00:02:40,800 --> 00:02:42,420
for example because they can guess or

68
00:02:42,420 --> 00:02:44,400
coerce a password

69
00:02:44,400 --> 00:02:46,680
crucially many survivors will live with

70
00:02:46,680 --> 00:02:48,540
abuse for many years because it's

71
00:02:48,540 --> 00:02:50,160
extremely difficult to live leave

72
00:02:50,160 --> 00:02:52,860
abusive relationships so protecting

73
00:02:52,860 --> 00:02:55,620
against abuse may look like helping

74
00:02:55,620 --> 00:02:57,660
someone protect their security while in

75
00:02:57,660 --> 00:02:59,640
an abusive relationship and not

76
00:02:59,640 --> 00:03:01,379
necessarily just helping them leave that

77
00:03:01,379 --> 00:03:02,879
relationship

78
00:03:02,879 --> 00:03:05,040
and lastly but crucially abuses

79
00:03:05,040 --> 00:03:08,360
intersectional so it will

80
00:03:08,360 --> 00:03:10,560
disproportionately Target women it's

81
00:03:10,560 --> 00:03:12,300
disproportionately perpetrated by men

82
00:03:12,300 --> 00:03:14,400
but it will often fall also on other

83
00:03:14,400 --> 00:03:16,860
axes of Oppression so for example people

84
00:03:16,860 --> 00:03:19,560
with disabilities experiencing

85
00:03:19,560 --> 00:03:22,379
um intimate partner abuse May face the

86
00:03:22,379 --> 00:03:23,819
additional problem that assistive

87
00:03:23,819 --> 00:03:25,560
Technologies are taken away by their

88
00:03:25,560 --> 00:03:26,940
abuser leaving them with extra

89
00:03:26,940 --> 00:03:29,720
vulnerabilities

90
00:03:31,980 --> 00:03:34,440
um and then in terms of what has been

91
00:03:34,440 --> 00:03:35,879
done for exploring Solutions and

92
00:03:35,879 --> 00:03:37,440
recommendations a lot of existing

93
00:03:37,440 --> 00:03:39,720
research looks at recommendations for

94
00:03:39,720 --> 00:03:42,540
survivors for example safety advice this

95
00:03:42,540 --> 00:03:45,480
has a big Pitfall in that it risks

96
00:03:45,480 --> 00:03:47,340
putting more what's called Safety work

97
00:03:47,340 --> 00:03:50,480
on survivors so people who are already

98
00:03:50,480 --> 00:03:53,340
in a very kind of often dire situation

99
00:03:53,340 --> 00:03:55,200
facing a lot of cognitive emotional

100
00:03:55,200 --> 00:03:57,900
physical strain shouldn't be kind of

101
00:03:57,900 --> 00:03:59,700
given more responsibility to protect

102
00:03:59,700 --> 00:04:01,140
themselves although they are of course

103
00:04:01,140 --> 00:04:02,879
their first line of defense and this

104
00:04:02,879 --> 00:04:05,459
work is also very important

105
00:04:05,459 --> 00:04:07,220
so another

106
00:04:07,220 --> 00:04:09,720
field of research looks at technical

107
00:04:09,720 --> 00:04:11,700
recommendations for example improving

108
00:04:11,700 --> 00:04:13,019
threat modeling or other design

109
00:04:13,019 --> 00:04:16,199
techniques people like Harry Hussein at

110
00:04:16,199 --> 00:04:18,000
Chen have developed trauma-informed

111
00:04:18,000 --> 00:04:19,220
design

112
00:04:19,220 --> 00:04:22,079
and this kind of research can sometimes

113
00:04:22,079 --> 00:04:25,699
jump to providing a technical solution

114
00:04:25,699 --> 00:04:28,560
and then the last line of research is

115
00:04:28,560 --> 00:04:30,180
looking looking at developing services

116
00:04:30,180 --> 00:04:32,100
for example community-based

117
00:04:32,100 --> 00:04:33,900
participatory action research projects

118
00:04:33,900 --> 00:04:36,960
like the ones at New York or Seattle

119
00:04:36,960 --> 00:04:39,479
which are really great

120
00:04:39,479 --> 00:04:40,740
um and have produced really helpful

121
00:04:40,740 --> 00:04:42,900
guides for securing devices have pointed

122
00:04:42,900 --> 00:04:45,300
out that seeking relief through the

123
00:04:45,300 --> 00:04:47,280
conventional criminal legal system can

124
00:04:47,280 --> 00:04:48,600
often be ineffectual or even

125
00:04:48,600 --> 00:04:50,340
re-traumatizing and I'm trying to think

126
00:04:50,340 --> 00:04:53,119
outside of that

127
00:04:54,000 --> 00:04:56,759
um in terms of the

128
00:04:56,759 --> 00:04:58,740
kind of theoretical influence from

129
00:04:58,740 --> 00:05:01,860
critical security studies is that

130
00:05:01,860 --> 00:05:03,900
critical security studies looks at

131
00:05:03,900 --> 00:05:05,940
security as a set of practices so things

132
00:05:05,940 --> 00:05:08,340
like predictive policing various forms

133
00:05:08,340 --> 00:05:10,800
of surveillance data mining it sees

134
00:05:10,800 --> 00:05:12,720
security as that rather than like as a

135
00:05:12,720 --> 00:05:15,479
state of being secure insecure and so in

136
00:05:15,479 --> 00:05:18,000
this study we look at security practices

137
00:05:18,000 --> 00:05:20,100
and then we also draw on feminist

138
00:05:20,100 --> 00:05:23,520
security studies which kind of

139
00:05:23,520 --> 00:05:25,440
seeks to challenge this distinction

140
00:05:25,440 --> 00:05:28,020
between personal versus political so

141
00:05:28,020 --> 00:05:29,220
conventionally a lot of security

142
00:05:29,220 --> 00:05:31,139
research will focus on things like

143
00:05:31,139 --> 00:05:33,240
terrorism or War even though

144
00:05:33,240 --> 00:05:35,900
statistically speaking will often cause

145
00:05:35,900 --> 00:05:38,580
much less violence and harm than things

146
00:05:38,580 --> 00:05:40,440
like domestic violence

147
00:05:40,440 --> 00:05:42,180
or coercive control

148
00:05:42,180 --> 00:05:44,520
it also generally kind of challenges

149
00:05:44,520 --> 00:05:46,440
distinctions between activism versus

150
00:05:46,440 --> 00:05:49,080
research feminism is a sort of political

151
00:05:49,080 --> 00:05:50,820
movement first which then influences

152
00:05:50,820 --> 00:05:53,039
these theoretical approaches

153
00:05:53,039 --> 00:05:54,780
and that's very

154
00:05:54,780 --> 00:05:56,639
um visible particularly in this focus on

155
00:05:56,639 --> 00:05:58,919
care and Care practices so a lot of

156
00:05:58,919 --> 00:06:00,780
feminist security research will see

157
00:06:00,780 --> 00:06:03,300
security as sort of this emotional and

158
00:06:03,300 --> 00:06:05,759
practical labor uh dealing with

159
00:06:05,759 --> 00:06:07,919
breakdowns of social relations and

160
00:06:07,919 --> 00:06:09,720
that's been applied to the digital

161
00:06:09,720 --> 00:06:11,520
sphere and for example the work of Shea

162
00:06:11,520 --> 00:06:12,660
yakiwoo

163
00:06:12,660 --> 00:06:16,199
looking at things like digital self-care

164
00:06:16,199 --> 00:06:19,520
I'm going to skip forward

165
00:06:20,820 --> 00:06:22,800
so in terms of the actual methods we

166
00:06:22,800 --> 00:06:25,199
used we used 26 semi-structured

167
00:06:25,199 --> 00:06:27,000
qualitative interviews people from the

168
00:06:27,000 --> 00:06:28,620
kind of conventional gender-based

169
00:06:28,620 --> 00:06:30,600
violence domestic violence sector like

170
00:06:30,600 --> 00:06:32,340
like I said shelters or human

171
00:06:32,340 --> 00:06:33,960
trafficking and sexual violence support

172
00:06:33,960 --> 00:06:36,479
services but also people coming more

173
00:06:36,479 --> 00:06:38,400
from the digital privacy space people

174
00:06:38,400 --> 00:06:39,900
like hacking collectives who've

175
00:06:39,900 --> 00:06:41,460
specifically started to focus on

176
00:06:41,460 --> 00:06:45,020
supporting survivors of abuse

177
00:06:45,419 --> 00:06:47,819
um and also specifically recruited for

178
00:06:47,819 --> 00:06:49,740
participants who support groups like sex

179
00:06:49,740 --> 00:06:51,660
workers or queer people who might be

180
00:06:51,660 --> 00:06:52,919
excluded from the traditional

181
00:06:52,919 --> 00:06:55,440
gender-based violence sector

182
00:06:55,440 --> 00:06:57,600
and we tried to follow various feminist

183
00:06:57,600 --> 00:06:59,160
methodologies for example looking at

184
00:06:59,160 --> 00:07:01,800
citation politics we gave participants

185
00:07:01,800 --> 00:07:04,080
the option to be cited by their name so

186
00:07:04,080 --> 00:07:06,060
that they would be credited similarly to

187
00:07:06,060 --> 00:07:07,620
the way an academic might be in a

188
00:07:07,620 --> 00:07:11,160
research paper and we also involved

189
00:07:11,160 --> 00:07:12,120
um

190
00:07:12,120 --> 00:07:14,100
our participants in a data work through

191
00:07:14,100 --> 00:07:15,900
Workshop so they were part of the data

192
00:07:15,900 --> 00:07:17,460
analysis and tried to make our

193
00:07:17,460 --> 00:07:20,780
positionality clear in the paper

194
00:07:23,759 --> 00:07:26,160
so moving on to the findings we

195
00:07:26,160 --> 00:07:28,080
identified five primary support

196
00:07:28,080 --> 00:07:29,520
practices

197
00:07:29,520 --> 00:07:33,419
so first of all participate Advocates

198
00:07:33,419 --> 00:07:35,759
will try to establish trust and belief

199
00:07:35,759 --> 00:07:37,560
before offering any kind of security

200
00:07:37,560 --> 00:07:39,419
advice

201
00:07:39,419 --> 00:07:41,759
um to avoid sort of the disempowering

202
00:07:41,759 --> 00:07:43,740
effects that a lot of conventional

203
00:07:43,740 --> 00:07:47,039
security advice might create

204
00:07:47,039 --> 00:07:49,139
they had a variety of different safety

205
00:07:49,139 --> 00:07:51,539
planning practices many of which kind of

206
00:07:51,539 --> 00:07:54,479
included an idea of demystification of

207
00:07:54,479 --> 00:07:57,180
the abuser and empowerment of the

208
00:07:57,180 --> 00:07:58,620
Survivor

209
00:07:58,620 --> 00:08:01,580
and so these kind of support practices

210
00:08:01,580 --> 00:08:05,580
will often intertwine sort of a level of

211
00:08:05,580 --> 00:08:07,620
technical knowledge being able to tell

212
00:08:07,620 --> 00:08:09,960
different vectors of compromise

213
00:08:09,960 --> 00:08:12,660
as well as sort of emotional support so

214
00:08:12,660 --> 00:08:14,520
understanding the effects of gaslighting

215
00:08:14,520 --> 00:08:16,139
understanding how an abuser might

216
00:08:16,139 --> 00:08:18,539
misrepresent their technical power As

217
00:08:18,539 --> 00:08:20,280
Eva gal Perrin from the Electronic

218
00:08:20,280 --> 00:08:22,020
Frontier Foundation said

219
00:08:22,020 --> 00:08:23,819
for a lot of people technical knowledge

220
00:08:23,819 --> 00:08:25,620
and you know computer security is

221
00:08:25,620 --> 00:08:27,960
essentially magic so it's very easy to

222
00:08:27,960 --> 00:08:29,699
use the appearance of that knowledge to

223
00:08:29,699 --> 00:08:31,319
make yourself seem omniscient and

224
00:08:31,319 --> 00:08:33,299
omnipotent and often that alone is

225
00:08:33,299 --> 00:08:35,458
enough to manipulate the victim

226
00:08:35,458 --> 00:08:37,200
so to provide this kind of support

227
00:08:37,200 --> 00:08:39,599
successfully Advocates would have to

228
00:08:39,599 --> 00:08:41,880
have quite a lot of both emotional

229
00:08:41,880 --> 00:08:43,559
knowledge of sort of how trauma might

230
00:08:43,559 --> 00:08:45,180
affect a Survivor and the technical

231
00:08:45,180 --> 00:08:48,240
knowledge to be able to tell apart

232
00:08:48,240 --> 00:08:50,399
um sort of alleged use of stock aware

233
00:08:50,399 --> 00:08:52,080
something more sophisticated from

234
00:08:52,080 --> 00:08:53,820
something that's much more common like

235
00:08:53,820 --> 00:08:55,620
compromise on the basis of a Facebook

236
00:08:55,620 --> 00:08:58,940
account or an email password

237
00:08:59,160 --> 00:09:01,380
um Advocates also supported evidence

238
00:09:01,380 --> 00:09:03,959
collection and would make referrals

239
00:09:03,959 --> 00:09:06,000
which kind of brings me to the next age

240
00:09:06,000 --> 00:09:08,100
like area of findings which is what

241
00:09:08,100 --> 00:09:10,140
we've called networks of care

242
00:09:10,140 --> 00:09:12,360
so we found that a lot of the actual

243
00:09:12,360 --> 00:09:14,220
practices a lot of the actual work that

244
00:09:14,220 --> 00:09:15,720
Advocates are putting in is in

245
00:09:15,720 --> 00:09:18,000
developing relationships with people in

246
00:09:18,000 --> 00:09:20,399
their Community like Susan hickey an

247
00:09:20,399 --> 00:09:22,920
advocate said I really like when car

248
00:09:22,920 --> 00:09:25,080
companies will say yes sure I'll come

249
00:09:25,080 --> 00:09:26,820
and look at your car maybe they're not

250
00:09:26,820 --> 00:09:28,920
going to see everything but I think it

251
00:09:28,920 --> 00:09:30,480
just provides a Survivor that support

252
00:09:30,480 --> 00:09:32,100
that's so important to know that there

253
00:09:32,100 --> 00:09:33,899
are people that care so that was

254
00:09:33,899 --> 00:09:35,339
something I found quite surprising is

255
00:09:35,339 --> 00:09:37,019
that quite a lot of Advocates talked

256
00:09:37,019 --> 00:09:38,519
about reaching out to local car

257
00:09:38,519 --> 00:09:40,380
companies to have a car mechanic who'd

258
00:09:40,380 --> 00:09:43,380
be able to check a car for trackers

259
00:09:43,380 --> 00:09:45,060
um but that would often involve these

260
00:09:45,060 --> 00:09:46,500
processes of not just building a

261
00:09:46,500 --> 00:09:48,180
relationship but also educating people

262
00:09:48,180 --> 00:09:50,279
on how domestic violence or gaslighting

263
00:09:50,279 --> 00:09:51,839
might work in practice

264
00:09:51,839 --> 00:09:53,760
making sure there's people that are

265
00:09:53,760 --> 00:09:55,860
trustworthy enough to refer Survivor to

266
00:09:55,860 --> 00:09:58,019
within the local community

267
00:09:58,019 --> 00:09:59,940
and all of this is kind of with the aim

268
00:09:59,940 --> 00:10:01,560
of building a more supportive and caring

269
00:10:01,560 --> 00:10:05,000
environment for survivors

270
00:10:05,519 --> 00:10:07,080
um Advocates have a lot of really

271
00:10:07,080 --> 00:10:08,760
interesting recommendations for change

272
00:10:08,760 --> 00:10:10,560
which due to time considerations I'm

273
00:10:10,560 --> 00:10:13,320
going to mostly skip over but these

274
00:10:13,320 --> 00:10:15,060
would include sort of very conventional

275
00:10:15,060 --> 00:10:17,180
privacy or safety by Design

276
00:10:17,180 --> 00:10:20,220
recommendations but also kind of called

277
00:10:20,220 --> 00:10:22,019
for a general rethinking of how

278
00:10:22,019 --> 00:10:24,000
technology is designed in a way that

279
00:10:24,000 --> 00:10:25,500
would be more relational with people

280
00:10:25,500 --> 00:10:27,240
working on the ground who are spotting

281
00:10:27,240 --> 00:10:29,519
problems on the ground so you can have

282
00:10:29,519 --> 00:10:31,740
this Dynamic like Natalie Dolce said

283
00:10:31,740 --> 00:10:34,019
where people are raising problems and

284
00:10:34,019 --> 00:10:37,459
that's responded to promptly

285
00:10:38,100 --> 00:10:42,600
um we have two kind of broad calls or

286
00:10:42,600 --> 00:10:45,420
implications from this research one is

287
00:10:45,420 --> 00:10:47,760
that I think these Advocates are

288
00:10:47,760 --> 00:10:49,380
technical workers they're cyber security

289
00:10:49,380 --> 00:10:51,120
workers even if they're not recognized

290
00:10:51,120 --> 00:10:52,920
as such and I think they should be

291
00:10:52,920 --> 00:10:54,959
recognized and compensated as such

292
00:10:54,959 --> 00:10:57,240
because even if they're not experts in

293
00:10:57,240 --> 00:11:00,180
cryptography they have a lot of sort of

294
00:11:00,180 --> 00:11:01,860
very valuable experience of how

295
00:11:01,860 --> 00:11:05,540
technology is abused on the ground

296
00:11:05,640 --> 00:11:07,920
um and secondly this kind of networked

297
00:11:07,920 --> 00:11:09,540
care building these kind of

298
00:11:09,540 --> 00:11:12,959
relationships are very critical to how

299
00:11:12,959 --> 00:11:15,360
people particularly vulnerable

300
00:11:15,360 --> 00:11:17,220
marginalized people get security and I

301
00:11:17,220 --> 00:11:18,600
think that resonates well with the

302
00:11:18,600 --> 00:11:20,579
previous presentation as well

303
00:11:20,579 --> 00:11:22,500
and I think if we recognize and

304
00:11:22,500 --> 00:11:24,120
understand these kind of networks then

305
00:11:24,120 --> 00:11:26,760
we as security researchers can build on

306
00:11:26,760 --> 00:11:28,380
top of them and try to strengthen them

307
00:11:28,380 --> 00:11:31,560
rather than sort of parachuting in a

308
00:11:31,560 --> 00:11:33,720
technical recommendation or solution

309
00:11:33,720 --> 00:11:35,579
without understanding the work that

310
00:11:35,579 --> 00:11:38,279
people are already doing on the ground

311
00:11:38,279 --> 00:11:40,920
so that's the first presentation I think

312
00:11:40,920 --> 00:11:42,779
I'll pause for questions now and then do

313
00:11:42,779 --> 00:11:46,100
the next one thank you very much

