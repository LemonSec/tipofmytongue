1
00:00:08,420 --> 00:00:11,880
yeah thanks for introduction and hi

2
00:00:11,880 --> 00:00:13,799
everyone I'm humbin from Duke University

3
00:00:13,799 --> 00:00:16,320
and today I'm glad to present our paper

4
00:00:16,320 --> 00:00:19,260
poison encoder poisoningly unlevel

5
00:00:19,260 --> 00:00:20,880
pre-training data in contrastive

6
00:00:20,880 --> 00:00:23,160
learning this is a join work with my

7
00:00:23,160 --> 00:00:26,760
colleague Qing and my advisor Neil

8
00:00:26,760 --> 00:00:28,939
supervised learning is a well-known

9
00:00:28,939 --> 00:00:31,140
conventional machine learning Paradigm

10
00:00:31,140 --> 00:00:33,719
given a specific task for instance

11
00:00:33,719 --> 00:00:36,420
traffic sign recognition supervised

12
00:00:36,420 --> 00:00:38,880
learning requires manually labeling a

13
00:00:38,880 --> 00:00:41,879
large amount of Level Training data to

14
00:00:41,879 --> 00:00:45,180
train a classifier given another task

15
00:00:45,180 --> 00:00:47,340
supervised learning will repeat this

16
00:00:47,340 --> 00:00:48,840
process again

17
00:00:48,840 --> 00:00:50,879
so the key challenge of supervised

18
00:00:50,879 --> 00:00:53,280
learning is that it requires a large

19
00:00:53,280 --> 00:00:55,920
amount of labeled training data for each

20
00:00:55,920 --> 00:00:57,360
task

21
00:00:57,360 --> 00:00:59,699
contrast learning aims to address this

22
00:00:59,699 --> 00:01:01,020
challenge

23
00:01:01,020 --> 00:01:04,019
by leveraging a large amount of unlevel

24
00:01:04,019 --> 00:01:05,880
data

25
00:01:05,880 --> 00:01:08,880
which can be images or image test pairs

26
00:01:08,880 --> 00:01:11,580
at least on level data usually comes

27
00:01:11,580 --> 00:01:13,680
from the public internet for instance

28
00:01:13,680 --> 00:01:16,080
social media websites or Google search

29
00:01:16,080 --> 00:01:19,200
givenly unlevel data contrast learning

30
00:01:19,200 --> 00:01:22,320
aims to pre-train a neural network which

31
00:01:22,320 --> 00:01:24,720
is called encoder and a pre-trained

32
00:01:24,720 --> 00:01:27,600
encoder can be used as a general purpose

33
00:01:27,600 --> 00:01:30,060
feature extractor for various Downstream

34
00:01:30,060 --> 00:01:31,500
tasks

35
00:01:31,500 --> 00:01:33,540
suppose we have a pre-training encoder

36
00:01:33,540 --> 00:01:36,119
to build a downstream classifier only

37
00:01:36,119 --> 00:01:39,540
requires small amount of or no leveled

38
00:01:39,540 --> 00:01:41,400
training data

39
00:01:41,400 --> 00:01:43,640
by analogy to the computer system

40
00:01:43,640 --> 00:01:46,979
encoder study the security of encoder is

41
00:01:46,979 --> 00:01:50,100
like the operating system levels

42
00:01:50,100 --> 00:01:54,320
security study in AI ecosystem

43
00:01:54,360 --> 00:01:56,460
next I will introduce more details on

44
00:01:56,460 --> 00:01:58,200
how to pre-train encoder and how to

45
00:01:58,200 --> 00:02:01,079
build downswing classifiers

46
00:02:01,079 --> 00:02:04,259
given an unable pre-training image

47
00:02:04,259 --> 00:02:06,780
we use dataugmentations for instance

48
00:02:06,780 --> 00:02:10,380
random cropping and resizing of

49
00:02:10,380 --> 00:02:11,099
um

50
00:02:11,099 --> 00:02:13,440
render horizontally flipping to create

51
00:02:13,440 --> 00:02:16,080
two random cognitive views we have

52
00:02:16,080 --> 00:02:18,480
encoder and we use it to produce future

53
00:02:18,480 --> 00:02:20,640
vectors for each of them

54
00:02:20,640 --> 00:02:23,459
given another pre-training image we will

55
00:02:23,459 --> 00:02:26,160
repeat the list process again

56
00:02:26,160 --> 00:02:29,099
the encoder is pre-trained in a way such

57
00:02:29,099 --> 00:02:31,800
that It produced similar feature vectors

58
00:02:31,800 --> 00:02:34,560
for two augmented views come from the

59
00:02:34,560 --> 00:02:36,840
same image but these similar feature

60
00:02:36,840 --> 00:02:39,239
vectors for two augmented views comes

61
00:02:39,239 --> 00:02:41,940
from different images

62
00:02:41,940 --> 00:02:43,860
given a set of training inputs of a

63
00:02:43,860 --> 00:02:46,200
downstream task we use the pre-training

64
00:02:46,200 --> 00:02:48,599
encoder to extract feature vectors for

65
00:02:48,599 --> 00:02:50,760
each training input and together with

66
00:02:50,760 --> 00:02:53,280
the corresponding levels we train we

67
00:02:53,280 --> 00:02:55,080
build a downstream classifier

68
00:02:55,080 --> 00:02:58,019
by standard supervised learning way

69
00:02:58,019 --> 00:03:00,239
and during testing time given a testing

70
00:03:00,239 --> 00:03:02,220
input we use the encoder to produce

71
00:03:02,220 --> 00:03:04,980
feature vectors for it and use the trend

72
00:03:04,980 --> 00:03:07,319
function classifier to predict the final

73
00:03:07,319 --> 00:03:09,619
level

74
00:03:09,780 --> 00:03:12,780
in our work we find that the encoder in

75
00:03:12,780 --> 00:03:14,519
contrast learning is vulnerable to

76
00:03:14,519 --> 00:03:15,959
poisoning attacks

77
00:03:15,959 --> 00:03:18,540
and the attacker's goal is to make an

78
00:03:18,540 --> 00:03:20,459
arbitrary attacker chosen image for

79
00:03:20,459 --> 00:03:22,920
instance stop sign image here we call it

80
00:03:22,920 --> 00:03:25,980
Target input to be misclassified by the

81
00:03:25,980 --> 00:03:28,019
downstream classifier built on the

82
00:03:28,019 --> 00:03:30,480
poison encoder to make arbitrary

83
00:03:30,480 --> 00:03:32,879
attacker chosen prediction for instance

84
00:03:32,879 --> 00:03:36,239
speed limit here we call it target class

85
00:03:36,239 --> 00:03:38,879
an attacker can achieve this goal by

86
00:03:38,879 --> 00:03:41,640
Craft and inject the poisoning inputs to

87
00:03:41,640 --> 00:03:44,280
the unleveled pre-training data

88
00:03:44,280 --> 00:03:46,260
we note that the most existing points

89
00:03:46,260 --> 00:03:48,180
and attacks are designed for supervised

90
00:03:48,180 --> 00:03:51,060
learning and our poisoning attack aim is

91
00:03:51,060 --> 00:03:54,840
to poison encoder to make multiple

92
00:03:54,840 --> 00:03:57,360
Target Downstream tasks have attacker

93
00:03:57,360 --> 00:04:00,000
desired Behavior

94
00:04:00,000 --> 00:04:02,940
in terms of our threat model the

95
00:04:02,940 --> 00:04:05,220
attacker picked one target bouncing task

96
00:04:05,220 --> 00:04:07,319
for instance traffic sign recognition

97
00:04:07,319 --> 00:04:10,080
one target input for instance an image

98
00:04:10,080 --> 00:04:11,340
of stop sign

99
00:04:11,340 --> 00:04:14,040
and the target class for instance V

100
00:04:14,040 --> 00:04:15,000
limit

101
00:04:15,000 --> 00:04:17,459
our attack can be used to attack

102
00:04:17,459 --> 00:04:19,798
multiple Target Downstream tasks and

103
00:04:19,798 --> 00:04:22,260
multiple Target inputs more results can

104
00:04:22,260 --> 00:04:24,240
be found in our paper and for a reason

105
00:04:24,240 --> 00:04:26,220
of Simplicity we default to use one

106
00:04:26,220 --> 00:04:27,780
target downswing task and one target

107
00:04:27,780 --> 00:04:29,100
input

108
00:04:29,100 --> 00:04:30,660
our text goal is to make the target

109
00:04:30,660 --> 00:04:32,880
Downstream classifier misclassify the

110
00:04:32,880 --> 00:04:35,040
target input as target class

111
00:04:35,040 --> 00:04:36,780
and in terms of attackers background

112
00:04:36,780 --> 00:04:39,540
knowledge the attacker has access to a

113
00:04:39,540 --> 00:04:41,940
few images from a target class for

114
00:04:41,940 --> 00:04:44,460
instance some speed limit images we call

115
00:04:44,460 --> 00:04:47,220
them reference inputs

116
00:04:47,220 --> 00:04:49,919
the key idea of our attack is to first

117
00:04:49,919 --> 00:04:52,199
we formulate poisoning attack as a

118
00:04:52,199 --> 00:04:54,180
bi-level optimization problem and then

119
00:04:54,180 --> 00:04:56,340
we use non-iterative heuristic solution

120
00:04:56,340 --> 00:04:59,460
to solve that

121
00:04:59,460 --> 00:05:00,840
the first optimization problem

122
00:05:00,840 --> 00:05:02,820
formulates the attacker's goal the

123
00:05:02,820 --> 00:05:04,800
attacker aims to find a set of points

124
00:05:04,800 --> 00:05:07,800
and inputs XP which make the

125
00:05:07,800 --> 00:05:10,020
pre-training encoderstar pre-trained

126
00:05:10,020 --> 00:05:12,120
only clean inputs XC and points need

127
00:05:12,120 --> 00:05:15,000
input XP to make the same to make the

128
00:05:15,000 --> 00:05:17,699
downstream classifier

129
00:05:17,699 --> 00:05:19,560
um produce the same prediction for

130
00:05:19,560 --> 00:05:22,139
Target input XT and reference input XR

131
00:05:22,139 --> 00:05:24,900
that means the encoder will produce

132
00:05:24,900 --> 00:05:27,479
similar feature vectors for Target input

133
00:05:27,479 --> 00:05:29,460
and reference input

134
00:05:29,460 --> 00:05:32,699
we standing up and take average since we

135
00:05:32,699 --> 00:05:34,979
have a set of reference inputs

136
00:05:34,979 --> 00:05:37,380
we not let the pre-train encoderstar

137
00:05:37,380 --> 00:05:39,780
already include another optimization

138
00:05:39,780 --> 00:05:40,740
problem

139
00:05:40,740 --> 00:05:43,979
let's optimizely encoders with Theta by

140
00:05:43,979 --> 00:05:46,800
minimizing the contrast loss

141
00:05:46,800 --> 00:05:48,660
we call the first optimization problem

142
00:05:48,660 --> 00:05:50,460
and a second optimization problem

143
00:05:50,460 --> 00:05:52,740
respectively as alter and inner

144
00:05:52,740 --> 00:05:54,120
optimization problem

145
00:05:54,120 --> 00:05:57,000
it is well known challenging to solve

146
00:05:57,000 --> 00:05:59,039
this high-level optimization problem by

147
00:05:59,039 --> 00:06:01,860
using statistic gradient descent

148
00:06:01,860 --> 00:06:04,919
because every step of optimization for

149
00:06:04,919 --> 00:06:07,020
the outer optimization problem we need

150
00:06:07,020 --> 00:06:09,600
to pre-train a whole encoder to solve

151
00:06:09,600 --> 00:06:11,699
the inner optimization problem so we

152
00:06:11,699 --> 00:06:15,240
resort to heuristic Solutions

153
00:06:15,240 --> 00:06:17,400
given the target input and the reference

154
00:06:17,400 --> 00:06:20,340
input we create the poisoning input by

155
00:06:20,340 --> 00:06:22,560
either horizontally or vertically

156
00:06:22,560 --> 00:06:24,120
combine them

157
00:06:24,120 --> 00:06:26,520
so when the encoder is pre-trained only

158
00:06:26,520 --> 00:06:29,160
poison input it will create two random

159
00:06:29,160 --> 00:06:30,960
augmented views by using render

160
00:06:30,960 --> 00:06:32,819
augmentation by using random cropping

161
00:06:32,819 --> 00:06:35,340
and resizing and the encoder will

162
00:06:35,340 --> 00:06:37,139
pretend in a way to produce similar

163
00:06:37,139 --> 00:06:38,699
future vectors for at least two

164
00:06:38,699 --> 00:06:40,919
augmented views

165
00:06:40,919 --> 00:06:43,560
and we note that at the same time it's

166
00:06:43,560 --> 00:06:45,300
softly in the organization problem which

167
00:06:45,300 --> 00:06:48,360
is pre-trained encoder it simultaneously

168
00:06:48,360 --> 00:06:50,880
solving outer organization problems to

169
00:06:50,880 --> 00:06:53,220
make the encoder produce similar feature

170
00:06:53,220 --> 00:06:55,620
vectors for the augmented views from the

171
00:06:55,620 --> 00:06:58,199
target input and reference inputs we

172
00:06:58,199 --> 00:07:00,259
called it approximately solving because

173
00:07:00,259 --> 00:07:03,060
augmentation augmented views are not

174
00:07:03,060 --> 00:07:04,919
exactly the same as Target input and

175
00:07:04,919 --> 00:07:07,500
reference inputs

176
00:07:07,500 --> 00:07:10,020
we noticed that such kind of combined

177
00:07:10,020 --> 00:07:13,259
images is a real maybe a real world

178
00:07:13,259 --> 00:07:17,240
issue in the public internet

179
00:07:17,759 --> 00:07:21,000
and the next country evaluation part we

180
00:07:21,000 --> 00:07:23,400
pretend encoder using ccrr and

181
00:07:23,400 --> 00:07:26,340
pre-training data set 14k and we also

182
00:07:26,340 --> 00:07:28,740
explore more pre-training algorithms and

183
00:07:28,740 --> 00:07:31,139
more pre-trained data sets including the

184
00:07:31,139 --> 00:07:33,840
full imagenet and this is a default

185
00:07:33,840 --> 00:07:36,060
setting I will report in this talks

186
00:07:36,060 --> 00:07:38,400
experimental results and for building

187
00:07:38,400 --> 00:07:40,139
Downstream classifiers we use three

188
00:07:40,139 --> 00:07:43,380
popular Downstream tasks and using the

189
00:07:43,380 --> 00:07:45,660
downstream classifier as a fully

190
00:07:45,660 --> 00:07:48,000
connected new network

191
00:07:48,000 --> 00:07:50,580
and the target input and target class

192
00:07:50,580 --> 00:07:51,900
are different for different Target

193
00:07:51,900 --> 00:07:54,539
downswing tasks and we choose randomly

194
00:07:54,539 --> 00:07:56,340
choose the reference inputs from each

195
00:07:56,340 --> 00:07:59,280
target class in Target launching task

196
00:07:59,280 --> 00:08:01,919
testing data by default we use 50

197
00:08:01,919 --> 00:08:04,440
reference inputs one percent points and

198
00:08:04,440 --> 00:08:06,780
rate and 10 exp random experimental

199
00:08:06,780 --> 00:08:10,580
trials to report experimental results

200
00:08:11,400 --> 00:08:13,199
and we first want to evaluate the

201
00:08:13,199 --> 00:08:15,660
effectiveness of our attack

202
00:08:15,660 --> 00:08:17,520
so given the target inputs and Target

203
00:08:17,520 --> 00:08:19,740
costs we build the downstream classifier

204
00:08:19,740 --> 00:08:22,020
based on the points encoder if the

205
00:08:22,020 --> 00:08:24,720
reduction classifier make the same

206
00:08:24,720 --> 00:08:27,479
prediction as Target costs our attack

207
00:08:27,479 --> 00:08:28,740
success

208
00:08:28,740 --> 00:08:31,139
otherwise our Tech fails

209
00:08:31,139 --> 00:08:33,120
solely a text success rate is a fraction

210
00:08:33,120 --> 00:08:36,000
of targeted misclassification for

211
00:08:36,000 --> 00:08:38,159
attacker

212
00:08:38,159 --> 00:08:40,380
our experimental result shows that our

213
00:08:40,380 --> 00:08:42,479
attack is highly effective across

214
00:08:42,479 --> 00:08:45,779
different Target Downstream tasks

215
00:08:45,779 --> 00:08:48,000
we also want to evaluate whether our tag

216
00:08:48,000 --> 00:08:48,959
is easy

217
00:08:48,959 --> 00:08:51,360
by evaluating the clean accuracy and

218
00:08:51,360 --> 00:08:53,580
points and accuracy given a clean

219
00:08:53,580 --> 00:08:56,339
testing input we first build Downstream

220
00:08:56,339 --> 00:08:58,279
classifier based on the clean encoder

221
00:08:58,279 --> 00:09:00,899
leads and its testing accuracy is called

222
00:09:00,899 --> 00:09:03,360
clean accuracy we also build Downstream

223
00:09:03,360 --> 00:09:05,279
classifier based on the poison encoder

224
00:09:05,279 --> 00:09:07,200
and its accuracy is called Poison

225
00:09:07,200 --> 00:09:08,760
accuracy

226
00:09:08,760 --> 00:09:09,959
if

227
00:09:09,959 --> 00:09:13,019
ideally The Poisoned accuracy is close

228
00:09:13,019 --> 00:09:15,480
to the clean accuracy our attack is DC

229
00:09:15,480 --> 00:09:18,000
to the encoder provider

230
00:09:18,000 --> 00:09:19,980
and we show that our points encoder

231
00:09:19,980 --> 00:09:22,320
maintains utility which means for each

232
00:09:22,320 --> 00:09:23,880
Target Junction task

233
00:09:23,880 --> 00:09:26,100
the points and accuracy is closely clean

234
00:09:26,100 --> 00:09:28,700
accuracy

235
00:09:29,160 --> 00:09:31,560
and we also explore three types of

236
00:09:31,560 --> 00:09:34,920
defenses against our points and encoder

237
00:09:34,920 --> 00:09:37,680
they include pre-processing improcessing

238
00:09:37,680 --> 00:09:40,200
and post-processing defenses which are

239
00:09:40,200 --> 00:09:43,019
respectedly respectively deployed before

240
00:09:43,019 --> 00:09:47,519
during and after pre-training encoder

241
00:09:47,519 --> 00:09:50,760
due to a time limit I want to conclude

242
00:09:50,760 --> 00:09:53,940
these defenses which so that on

243
00:09:53,940 --> 00:09:56,040
pre-processing defenses are either

244
00:09:56,040 --> 00:09:58,500
insufficient or ineffective

245
00:09:58,500 --> 00:10:01,740
and for with explore 3 in-processing

246
00:10:01,740 --> 00:10:04,320
defenses they are effective but will

247
00:10:04,320 --> 00:10:06,480
sacrifice the utility of encoder for

248
00:10:06,480 --> 00:10:09,360
Downstream classification

249
00:10:09,360 --> 00:10:11,940
and for post-processing defense

250
00:10:11,940 --> 00:10:13,980
we fine-tune pre-training encoder for

251
00:10:13,980 --> 00:10:16,860
extra epochs on some clean images

252
00:10:16,860 --> 00:10:19,260
we find that it's effective without

253
00:10:19,260 --> 00:10:23,040
sacrificing encoder's utility however it

254
00:10:23,040 --> 00:10:25,860
requires manually collecting a large set

255
00:10:25,860 --> 00:10:28,200
of clean images

256
00:10:28,200 --> 00:10:30,480
to run up my presentation

257
00:10:30,480 --> 00:10:33,480
we find that contrast learning is highly

258
00:10:33,480 --> 00:10:35,399
vulnerable to poisoning attack

259
00:10:35,399 --> 00:10:38,279
and insecure encoder may lead to a

260
00:10:38,279 --> 00:10:40,140
single point of failure of a AI

261
00:10:40,140 --> 00:10:42,360
ecosystem because they will impact the

262
00:10:42,360 --> 00:10:45,120
security of multiple Target Downstream

263
00:10:45,120 --> 00:10:46,500
tasks

264
00:10:46,500 --> 00:10:48,779
and defenses are insufficient to defend

265
00:10:48,779 --> 00:10:51,480
against poison encoder and thanks for

266
00:10:51,480 --> 00:10:55,040
listening I'm happy to answer questions

