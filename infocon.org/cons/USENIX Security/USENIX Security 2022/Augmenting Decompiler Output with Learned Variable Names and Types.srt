1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:09,740 --> 00:00:13,200
PhD student at Carnegie Mellon and today

3
00:00:13,200 --> 00:00:16,199
I'm going to show you our method for

4
00:00:16,199 --> 00:00:18,359
automatically augmenting decompiler

5
00:00:18,359 --> 00:00:21,720
output with variable names and types

6
00:00:21,720 --> 00:00:24,600
so the decompiler is a tool that's

7
00:00:24,600 --> 00:00:27,060
commonly used by reverse Engineers to

8
00:00:27,060 --> 00:00:29,039
examine examine binaries that they find

9
00:00:29,039 --> 00:00:31,560
in the wild however anybody that's used

10
00:00:31,560 --> 00:00:33,660
a decompiler before knows that they are

11
00:00:33,660 --> 00:00:36,300
pretty ineffective at naming variables

12
00:00:36,300 --> 00:00:39,120
so this is a problem uh variable names

13
00:00:39,120 --> 00:00:42,059
are essential to code understanding and

14
00:00:42,059 --> 00:00:44,160
renaming variables takes up a ton of

15
00:00:44,160 --> 00:00:46,500
reverse Engineers time so this example

16
00:00:46,500 --> 00:00:49,020
is a simplified version of the output of

17
00:00:49,020 --> 00:00:50,940
a decompiler and you can see the name

18
00:00:50,940 --> 00:00:52,739
selected for the arguments and variables

19
00:00:52,739 --> 00:00:55,260
are a n and VN instead of something more

20
00:00:55,260 --> 00:00:57,000
meaningful

21
00:00:57,000 --> 00:01:00,000
in addition to variable names it turns

22
00:01:00,000 --> 00:01:02,579
out the types are also useful so in this

23
00:01:02,579 --> 00:01:05,220
example that might be output by a

24
00:01:05,220 --> 00:01:07,979
decompiler without knowing about a

25
00:01:07,979 --> 00:01:10,320
user-defined data type the decompiler

26
00:01:10,320 --> 00:01:12,420
doesn't understand that the operations

27
00:01:12,420 --> 00:01:15,360
on A1 and A2 here are actually

28
00:01:15,360 --> 00:01:18,479
structural dereferences so it outputs a

29
00:01:18,479 --> 00:01:20,400
pointer dereference and an array

30
00:01:20,400 --> 00:01:22,680
indexing operation instead

31
00:01:22,680 --> 00:01:25,020
so if we instead tell the decompiler

32
00:01:25,020 --> 00:01:28,140
about this type that's uh was defined by

33
00:01:28,140 --> 00:01:30,240
the programmer it becomes much clearer

34
00:01:30,240 --> 00:01:32,040
that this function is actually Computing

35
00:01:32,040 --> 00:01:34,320
the distance between two points in 2D

36
00:01:34,320 --> 00:01:36,119
space

37
00:01:36,119 --> 00:01:38,700
so going back to the variable naming

38
00:01:38,700 --> 00:01:40,619
example we get a little bit of insight

39
00:01:40,619 --> 00:01:42,360
into why this problem is particularly

40
00:01:42,360 --> 00:01:43,640
difficult

41
00:01:43,640 --> 00:01:46,200
automatically renaming variables would

42
00:01:46,200 --> 00:01:48,780
save a ton of time but like many of the

43
00:01:48,780 --> 00:01:51,780
most interesting problems it's provably

44
00:01:51,780 --> 00:01:53,700
generally impossible to do

45
00:01:53,700 --> 00:01:56,280
deterministically with only a few

46
00:01:56,280 --> 00:01:58,020
exceptions programmers are free to

47
00:01:58,020 --> 00:02:00,119
choose whatever variable names they want

48
00:02:00,119 --> 00:02:03,060
so this quote unquote correct choice of

49
00:02:03,060 --> 00:02:05,759
very only variable names compiles to the

50
00:02:05,759 --> 00:02:07,799
exact same binary as this choice of

51
00:02:07,799 --> 00:02:10,399
variable names

52
00:02:10,500 --> 00:02:12,180
um it's it's pretty intuitive though

53
00:02:12,180 --> 00:02:14,580
that uh and it has been experimentally

54
00:02:14,580 --> 00:02:17,340
verified that actual developers in the

55
00:02:17,340 --> 00:02:19,500
real world do not choose variable names

56
00:02:19,500 --> 00:02:23,220
at random in fact developers often use

57
00:02:23,220 --> 00:02:25,560
this you write the same code to perform

58
00:02:25,560 --> 00:02:28,680
the same tasks there's only so many ways

59
00:02:28,680 --> 00:02:30,420
that you can compute the distance

60
00:02:30,420 --> 00:02:32,819
between two points and if you look at

61
00:02:32,819 --> 00:02:35,580
enough examples you should be able to

62
00:02:35,580 --> 00:02:37,440
learn the pattern

63
00:02:37,440 --> 00:02:40,739
so if only there was a large easily

64
00:02:40,739 --> 00:02:44,340
scrapable uh repository of code that we

65
00:02:44,340 --> 00:02:47,400
could use to train an algorithm

66
00:02:47,400 --> 00:02:50,879
so in 2019 we created a system for

67
00:02:50,879 --> 00:02:54,360
renaming variables in decompiled code it

68
00:02:54,360 --> 00:02:56,519
first mined GitHub for thousands of C

69
00:02:56,519 --> 00:02:59,060
repositories written by human developers

70
00:02:59,060 --> 00:03:01,500
we trained a model that could

71
00:03:01,500 --> 00:03:03,660
automatically predict up to 73 percent

72
00:03:03,660 --> 00:03:05,340
of the names chosen by the original

73
00:03:05,340 --> 00:03:08,400
developers and uh we were encouraged by

74
00:03:08,400 --> 00:03:10,560
these results so we decided to take on

75
00:03:10,560 --> 00:03:14,280
the problem of retyping variables too

76
00:03:14,280 --> 00:03:15,959
and if you think about it predicting

77
00:03:15,959 --> 00:03:17,760
types should actually be easier than

78
00:03:17,760 --> 00:03:19,019
predicting names

79
00:03:19,019 --> 00:03:22,800
uh unlike names types naturally have a

80
00:03:22,800 --> 00:03:25,440
set of constraints so for example the C

81
00:03:25,440 --> 00:03:28,739
standard defines a character type as a

82
00:03:28,739 --> 00:03:31,019
single byte that means in most

83
00:03:31,019 --> 00:03:33,420
architectures you cannot replace a

84
00:03:33,420 --> 00:03:35,580
character type with say an inch type or

85
00:03:35,580 --> 00:03:36,840
a float type

86
00:03:36,840 --> 00:03:40,080
this greatly reduces the search space so

87
00:03:40,080 --> 00:03:42,360
instead of just conditioning on the

88
00:03:42,360 --> 00:03:44,819
context of a variable you can also ask

89
00:03:44,819 --> 00:03:47,220
the decompiler how large the variable is

90
00:03:47,220 --> 00:03:49,379
in bytes and use it as a constraint on

91
00:03:49,379 --> 00:03:51,540
your prediction so we actually tried

92
00:03:51,540 --> 00:03:54,780
this experiment we scrape GitHub for C

93
00:03:54,780 --> 00:03:57,299
code and we maintained a database of

94
00:03:57,299 --> 00:03:59,519
types and their sizes and then we

95
00:03:59,519 --> 00:04:01,319
trained a model to predict a type based

96
00:04:01,319 --> 00:04:03,239
on both its context and constrain the

97
00:04:03,239 --> 00:04:05,519
predictions by the type size so if

98
00:04:05,519 --> 00:04:07,500
you'll remember we were able to recover

99
00:04:07,500 --> 00:04:09,659
73 percent of variable names and this

100
00:04:09,659 --> 00:04:11,819
task is supposed to be easier

101
00:04:11,819 --> 00:04:14,819
to our surprise our the system performed

102
00:04:14,819 --> 00:04:16,560
very poorly we only recovered something

103
00:04:16,560 --> 00:04:20,279
like 20 of variable types

104
00:04:20,279 --> 00:04:21,899
this is the problem the problem is

105
00:04:21,899 --> 00:04:24,300
padding bytes uh on the left you could

106
00:04:24,300 --> 00:04:26,340
see some function originally written by

107
00:04:26,340 --> 00:04:28,380
a developer and on the right you can see

108
00:04:28,380 --> 00:04:30,720
the output of the decompiler as you can

109
00:04:30,720 --> 00:04:32,520
see the X variable here has been

110
00:04:32,520 --> 00:04:34,259
decompiled as an array of four

111
00:04:34,259 --> 00:04:35,940
characters when it was originally

112
00:04:35,940 --> 00:04:38,460
written as an array of three

113
00:04:38,460 --> 00:04:40,320
so here's what happened during uh

114
00:04:40,320 --> 00:04:42,479
compilation this is a representation of

115
00:04:42,479 --> 00:04:44,100
the stack it's got one byte divisions

116
00:04:44,100 --> 00:04:46,560
when the compiler allocates memory for

117
00:04:46,560 --> 00:04:49,400
this function it adds three bytes for X

118
00:04:49,400 --> 00:04:52,500
then a byte of padding and then four

119
00:04:52,500 --> 00:04:55,020
bytes for y this is not done in three

120
00:04:55,020 --> 00:04:57,600
operations this is done at one operation

121
00:04:57,600 --> 00:04:59,759
uh and when the decompiler sees this

122
00:04:59,759 --> 00:05:01,740
function it just sees that there's two

123
00:05:01,740 --> 00:05:03,780
variables X and Y

124
00:05:03,780 --> 00:05:06,000
and this is how it conservatively

125
00:05:06,000 --> 00:05:08,840
assumes that they are uh that they are

126
00:05:08,840 --> 00:05:11,880
aligned it does not know that X is a

127
00:05:11,880 --> 00:05:14,340
three byte array or a four byte array

128
00:05:14,340 --> 00:05:16,979
where the last byte is just not accessed

129
00:05:16,979 --> 00:05:18,900
and in this case not only do we not get

130
00:05:18,900 --> 00:05:21,000
the answer correct we provably cannot

131
00:05:21,000 --> 00:05:23,699
get the answer correct uh just because

132
00:05:23,699 --> 00:05:26,520
we look through three byte uh three byte

133
00:05:26,520 --> 00:05:27,720
types

134
00:05:27,720 --> 00:05:29,820
so instead of hard constraints what we

135
00:05:29,820 --> 00:05:31,560
need is soft constraints that we can

136
00:05:31,560 --> 00:05:33,300
learn by a model

137
00:05:33,300 --> 00:05:35,160
so I'm going to quickly walk you through

138
00:05:35,160 --> 00:05:37,860
the architecture for the decompiled

139
00:05:37,860 --> 00:05:40,199
variable retyper also known as dirty

140
00:05:40,199 --> 00:05:42,419
dirty uses a pretty traditional

141
00:05:42,419 --> 00:05:45,720
Transformer encoder decoder layout first

142
00:05:45,720 --> 00:05:47,699
it takes the text of the decompiled code

143
00:05:47,699 --> 00:05:50,400
as a sequence of input tokens and it

144
00:05:50,400 --> 00:05:52,380
creates a representation for each

145
00:05:52,380 --> 00:05:54,180
variable together with an attention

146
00:05:54,180 --> 00:05:56,520
model and passes it to a decoder

147
00:05:56,520 --> 00:05:59,280
the decoder outputs a prediction it's a

148
00:05:59,280 --> 00:06:01,740
it's a set of probabilities for each

149
00:06:01,740 --> 00:06:02,880
type

150
00:06:02,880 --> 00:06:05,639
the next thing we do is take the data

151
00:06:05,639 --> 00:06:07,740
layout information of that same variable

152
00:06:07,740 --> 00:06:11,100
and compute a mask and what this does is

153
00:06:11,100 --> 00:06:12,900
when we add the prediction in The Mask

154
00:06:12,900 --> 00:06:16,620
we get an actual type prediction

155
00:06:16,620 --> 00:06:19,380
and then we feed this back in and we do

156
00:06:19,380 --> 00:06:22,139
this over and over again

157
00:06:22,139 --> 00:06:24,780
so to train and evaluate this we needed

158
00:06:24,780 --> 00:06:26,000
a data set

159
00:06:26,000 --> 00:06:29,580
we collect and released the data set for

160
00:06:29,580 --> 00:06:31,500
idiomatic retyping which we also call

161
00:06:31,500 --> 00:06:32,759
dirt

162
00:06:32,759 --> 00:06:34,560
this data set was automatically

163
00:06:34,560 --> 00:06:36,960
generated from code written by

164
00:06:36,960 --> 00:06:39,120
developers and published on GitHub we

165
00:06:39,120 --> 00:06:42,300
compile it with GCC 9.2 with

166
00:06:42,300 --> 00:06:44,520
optimizations turned off I'll talk a bit

167
00:06:44,520 --> 00:06:46,919
more about optimizations in a minute

168
00:06:46,919 --> 00:06:50,280
each function was also decompiled with

169
00:06:50,280 --> 00:06:53,160
hex Rays with and without debugging

170
00:06:53,160 --> 00:06:55,460
information this allows us to align

171
00:06:55,460 --> 00:06:58,580
variables in the in the code

172
00:06:58,580 --> 00:07:01,139
and on the side we saved identifier

173
00:07:01,139 --> 00:07:03,360
names and also a database of types which

174
00:07:03,360 --> 00:07:04,860
include things like name and

175
00:07:04,860 --> 00:07:06,720
substructure of the type

176
00:07:06,720 --> 00:07:09,419
for training we split these by binary

177
00:07:09,419 --> 00:07:12,900
this prevents uh functions from one

178
00:07:12,900 --> 00:07:15,600
binary ending up in the same data set

179
00:07:15,600 --> 00:07:17,520
ending up in both the training and the

180
00:07:17,520 --> 00:07:20,160
testing data set

181
00:07:20,160 --> 00:07:22,500
so here's our metric our success metric

182
00:07:22,500 --> 00:07:25,860
is for each function how often does

183
00:07:25,860 --> 00:07:28,020
dirty's choice of variable type exactly

184
00:07:28,020 --> 00:07:29,639
match the developer's Choice including

185
00:07:29,639 --> 00:07:32,220
not only structure but also the names of

186
00:07:32,220 --> 00:07:34,139
the type and the names of the fields so

187
00:07:34,139 --> 00:07:37,020
for example this type here

188
00:07:37,020 --> 00:07:39,720
is considered different from this type

189
00:07:39,720 --> 00:07:40,620
here

190
00:07:40,620 --> 00:07:42,539
and it's also because the names are

191
00:07:42,539 --> 00:07:43,919
different and it's also considered

192
00:07:43,919 --> 00:07:45,479
different from this type here because

193
00:07:45,479 --> 00:07:47,460
the fields are different so we need all

194
00:07:47,460 --> 00:07:50,780
of these to be exactly the same

195
00:07:51,000 --> 00:07:53,039
we found that dirty was able to recover

196
00:07:53,039 --> 00:07:56,039
76 of all types

197
00:07:56,039 --> 00:07:58,259
and then uh just because scalar types

198
00:07:58,259 --> 00:08:01,139
dominate we also separated out just the

199
00:08:01,139 --> 00:08:03,240
structural types and we found that it

200
00:08:03,240 --> 00:08:06,479
was able to recover 69 of structural

201
00:08:06,479 --> 00:08:09,539
types for more details comparisons to

202
00:08:09,539 --> 00:08:12,840
baselines you could see our paper

203
00:08:12,840 --> 00:08:14,699
so I understand that hex Rays is

204
00:08:14,699 --> 00:08:16,380
relatively expensive and you might be

205
00:08:16,380 --> 00:08:17,639
wondering why we didn't use a more

206
00:08:17,639 --> 00:08:19,560
affordable option like guidra for

207
00:08:19,560 --> 00:08:21,660
example there's nothing that limits this

208
00:08:21,660 --> 00:08:24,360
technique to a specific decompiler the

209
00:08:24,360 --> 00:08:26,039
only requirements are that it can

210
00:08:26,039 --> 00:08:28,379
decompile code it could return memory

211
00:08:28,379 --> 00:08:30,419
information for a variable and it can

212
00:08:30,419 --> 00:08:32,339
import debug information about local

213
00:08:32,339 --> 00:08:33,479
variables

214
00:08:33,479 --> 00:08:35,640
hex Rays does all three of these but

215
00:08:35,640 --> 00:08:38,820
ghidra does not do the last one well it

216
00:08:38,820 --> 00:08:42,599
uh I do not know why this issue has been

217
00:08:42,599 --> 00:08:44,459
around since 2020 and not resolved I

218
00:08:44,459 --> 00:08:46,320
mean no disrespect to the Guidry

219
00:08:46,320 --> 00:08:47,880
developers I think they're doing a great

220
00:08:47,880 --> 00:08:51,180
job but if you want to use dirty with

221
00:08:51,180 --> 00:08:53,399
ghidra you would have to first fix this

222
00:08:53,399 --> 00:08:55,620
issue so if you guys develop Brigadier

223
00:08:55,620 --> 00:08:56,940
or know anyone who does you might want

224
00:08:56,940 --> 00:08:59,640
to let them know about that

225
00:08:59,640 --> 00:09:02,519
we also did an experiment with

226
00:09:02,519 --> 00:09:04,040
optimizations

227
00:09:04,040 --> 00:09:07,560
so we our data set was only o0 and all

228
00:09:07,560 --> 00:09:10,380
our training data was also only o0 but

229
00:09:10,380 --> 00:09:13,740
we ran an experiment on uh the new core

230
00:09:13,740 --> 00:09:15,899
utils programs where we compiled them at

231
00:09:15,899 --> 00:09:17,820
different optimization levels and then

232
00:09:17,820 --> 00:09:19,920
we saw what we could do and we found

233
00:09:19,920 --> 00:09:22,500
that there's a 0.19 percentage Point

234
00:09:22,500 --> 00:09:25,680
drop moving from 0 to 01 and a further

235
00:09:25,680 --> 00:09:29,519
0.01 percentage Point dropped to O3 we

236
00:09:29,519 --> 00:09:31,740
don't actually know why it seems

237
00:09:31,740 --> 00:09:35,339
negligible but uh we note that we

238
00:09:35,339 --> 00:09:37,320
operate on the textual output of the

239
00:09:37,320 --> 00:09:40,200
decompiler and the decompiler recognizes

240
00:09:40,200 --> 00:09:43,320
optimizations like this or uh recognizes

241
00:09:43,320 --> 00:09:47,120
compiler optimizations such as moving

242
00:09:47,120 --> 00:09:50,940
moving variables from the stack to an

243
00:09:50,940 --> 00:09:53,279
offset from uh from a different pointer

244
00:09:53,279 --> 00:09:55,680
or even in the even storing them in a

245
00:09:55,680 --> 00:09:57,839
register all of this is re-abstracted

246
00:09:57,839 --> 00:10:00,000
Away by the decompiler and we think this

247
00:10:00,000 --> 00:10:01,740
is why it doesn't actually have a huge

248
00:10:01,740 --> 00:10:04,200
impact on our performance

249
00:10:04,200 --> 00:10:06,420
so one thing we noticed during the

250
00:10:06,420 --> 00:10:08,220
development of our original renaming

251
00:10:08,220 --> 00:10:10,380
system is that better types means better

252
00:10:10,380 --> 00:10:11,339
names

253
00:10:11,339 --> 00:10:14,660
so we just plugged in a new decoder

254
00:10:14,660 --> 00:10:18,000
trained it and we found that it actually

255
00:10:18,000 --> 00:10:20,220
does improve on the state of the art it

256
00:10:20,220 --> 00:10:25,160
moves it from 72.8 to 81.4 percent

257
00:10:25,440 --> 00:10:28,320
here's a real example from Dirty the

258
00:10:28,320 --> 00:10:30,060
code shown as part of a simplified

259
00:10:30,060 --> 00:10:32,040
output from a decoder

260
00:10:32,040 --> 00:10:34,140
so if you recall the goal of dirty is to

261
00:10:34,140 --> 00:10:36,300
rename and retype the arguments and the

262
00:10:36,300 --> 00:10:38,160
variable to match the developers chosen

263
00:10:38,160 --> 00:10:41,399
types you could see that A1 and V3 are

264
00:10:41,399 --> 00:10:44,279
A3 and V1 exactly agree with what the

265
00:10:44,279 --> 00:10:47,160
developer did and while A1 and A2 do not

266
00:10:47,160 --> 00:10:48,560
agree exactly

267
00:10:48,560 --> 00:10:50,720
they still provide a lot of information

268
00:10:50,720 --> 00:10:53,220
if you were a reverse engineer and you

269
00:10:53,220 --> 00:10:56,339
got picture instead of pick or vice

270
00:10:56,339 --> 00:10:58,320
versa this still gives you plenty of

271
00:10:58,320 --> 00:11:00,120
information as to what this function

272
00:11:00,120 --> 00:11:03,360
does and how you might how you might end

273
00:11:03,360 --> 00:11:05,100
up using it

274
00:11:05,100 --> 00:11:07,560
so wrapping up we've created a system

275
00:11:07,560 --> 00:11:09,540
that uses machine learning to correctly

276
00:11:09,540 --> 00:11:13,800
predict 76 of all types including 69 on

277
00:11:13,800 --> 00:11:16,200
structured types alone it's also able to

278
00:11:16,200 --> 00:11:18,180
predict names at a rate nine percentage

279
00:11:18,180 --> 00:11:19,620
points greater than the current state of

280
00:11:19,620 --> 00:11:21,779
the art if you'd like to access either

281
00:11:21,779 --> 00:11:23,880
dirty or the dirt data set you can visit

282
00:11:23,880 --> 00:11:26,579
our GitHub page with the top link and we

283
00:11:26,579 --> 00:11:29,940
also have a live demo uh on the bottom

284
00:11:29,940 --> 00:11:32,160
link if you'd like to try that

285
00:11:32,160 --> 00:11:34,880
thank you

