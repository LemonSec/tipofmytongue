1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:09,320 --> 00:00:11,639
my name is Andrea Marcelli security

3
00:00:11,639 --> 00:00:14,519
researcher Cisco Dallas and today I'm

4
00:00:14,519 --> 00:00:17,279
here to present to you how our paper how

5
00:00:17,279 --> 00:00:19,320
machine learning is solving the binary

6
00:00:19,320 --> 00:00:21,000
function similarity problem

7
00:00:21,000 --> 00:00:22,680
these are research that we have done in

8
00:00:22,680 --> 00:00:23,939
collaboration with the University of

9
00:00:23,939 --> 00:00:25,920
eurocom

10
00:00:25,920 --> 00:00:27,779
binary function similarity is the

11
00:00:27,779 --> 00:00:30,300
problem of taking in input the binary

12
00:00:30,300 --> 00:00:32,640
representation of two functions and

13
00:00:32,640 --> 00:00:35,340
giving in output a numeric value that

14
00:00:35,340 --> 00:00:38,760
captures the similarity between them

15
00:00:38,760 --> 00:00:41,040
and we Define in this specific research

16
00:00:41,040 --> 00:00:43,680
two functions as similar if they come if

17
00:00:43,680 --> 00:00:45,420
they are compiled from the same source

18
00:00:45,420 --> 00:00:47,219
code it's a very interesting problem

19
00:00:47,219 --> 00:00:50,640
with several practical applications in

20
00:00:50,640 --> 00:00:52,200
reverse engineering vulnerability

21
00:00:52,200 --> 00:00:54,960
detection and malware clustering

22
00:00:54,960 --> 00:00:56,820
given the interest in the field server

23
00:00:56,820 --> 00:00:58,800
researchers have worked on this topic

24
00:00:58,800 --> 00:01:00,539
and have published an astonishing number

25
00:01:00,539 --> 00:01:01,980
of papers

26
00:01:01,980 --> 00:01:04,140
since these researchers come from

27
00:01:04,140 --> 00:01:05,939
different communities like machine

28
00:01:05,939 --> 00:01:07,380
learning program analysis system

29
00:01:07,380 --> 00:01:09,420
security they publish in different

30
00:01:09,420 --> 00:01:11,760
venues and this brought to a

31
00:01:11,760 --> 00:01:13,439
fragmentation in the field

32
00:01:13,439 --> 00:01:16,920
when we started studying this problem we

33
00:01:16,920 --> 00:01:19,260
identified the following challenges

34
00:01:19,260 --> 00:01:21,780
first of all first of all it was

35
00:01:21,780 --> 00:01:24,720
impossible to reproduce or replicate

36
00:01:24,720 --> 00:01:27,540
many of the previous results and this is

37
00:01:27,540 --> 00:01:29,820
because most of the times the artifacts

38
00:01:29,820 --> 00:01:31,439
like the code and data sets are not

39
00:01:31,439 --> 00:01:34,979
available or if they are available

40
00:01:34,979 --> 00:01:37,020
something like some particular

41
00:01:37,020 --> 00:01:38,220
components like the feature instruction

42
00:01:38,220 --> 00:01:39,900
or the machine learning components are

43
00:01:39,900 --> 00:01:41,900
missing

44
00:01:41,900 --> 00:01:45,720
also when the evaluation appears in the

45
00:01:45,720 --> 00:01:46,460
paper

46
00:01:46,460 --> 00:01:50,340
it's the results are often opaque and

47
00:01:50,340 --> 00:01:52,740
these due to many reasons for example

48
00:01:52,740 --> 00:01:55,259
different objectives different settings

49
00:01:55,259 --> 00:01:57,899
like comparing cross architectures

50
00:01:57,899 --> 00:02:00,479
versus cross optimizations different

51
00:02:00,479 --> 00:02:02,880
concepts to similarities and different

52
00:02:02,880 --> 00:02:05,640
granularities like research paper focus

53
00:02:05,640 --> 00:02:09,179
on function comparison other on basic

54
00:02:09,179 --> 00:02:11,700
block comparison and so on and if we had

55
00:02:11,700 --> 00:02:13,680
this on top of different data sets

56
00:02:13,680 --> 00:02:14,520
different metrics different

57
00:02:14,520 --> 00:02:17,280
implementations as a result we have a

58
00:02:17,280 --> 00:02:19,020
very clear situation where we don't know

59
00:02:19,020 --> 00:02:21,300
in which direction binary function

60
00:02:21,300 --> 00:02:23,819
similarity is heading

61
00:02:23,819 --> 00:02:26,220
so the contribution of this paper is to

62
00:02:26,220 --> 00:02:28,620
provide the first measurement study of

63
00:02:28,620 --> 00:02:30,900
this field and we do following three

64
00:02:30,900 --> 00:02:32,760
steps first of all we explore the

65
00:02:32,760 --> 00:02:34,739
existing body of research we cluster the

66
00:02:34,739 --> 00:02:37,680
main approaches we select the 10 most

67
00:02:37,680 --> 00:02:39,599
representative ones

68
00:02:39,599 --> 00:02:43,440
we'll Implement them and we compare them

69
00:02:43,440 --> 00:02:46,620
in a fair way and to do this we also

70
00:02:46,620 --> 00:02:48,480
build a new data set as a common

71
00:02:48,480 --> 00:02:51,079
benchmark

72
00:02:51,599 --> 00:02:53,760
in terms of measuring function

73
00:02:53,760 --> 00:02:55,800
similarity there are two main techniques

74
00:02:55,800 --> 00:02:58,379
that have been proposed

75
00:02:58,379 --> 00:03:00,680
um first technique is direct comparison

76
00:03:00,680 --> 00:03:04,140
and it means that the methods limited

77
00:03:04,140 --> 00:03:07,140
take two functions in input always two

78
00:03:07,140 --> 00:03:08,640
functions but this limits the

79
00:03:08,640 --> 00:03:10,620
scalability of the approaches on the

80
00:03:10,620 --> 00:03:12,239
other hand there are indirect comparison

81
00:03:12,239 --> 00:03:15,959
methods and the difference that they

82
00:03:15,959 --> 00:03:19,140
map the function into a low dimensional

83
00:03:19,140 --> 00:03:20,760
representation and then they use some

84
00:03:20,760 --> 00:03:22,860
kind of similarity like equilibrium

85
00:03:22,860 --> 00:03:24,840
distance cosine similarity to measure

86
00:03:24,840 --> 00:03:27,659
the similarity between functions that in

87
00:03:27,659 --> 00:03:29,879
direct comparison methods include fuzzy

88
00:03:29,879 --> 00:03:31,739
hashing and embeddings and among the

89
00:03:31,739 --> 00:03:34,440
embeddings word most famous One are Cod

90
00:03:34,440 --> 00:03:37,379
embeddings takes in input stream of

91
00:03:37,379 --> 00:03:40,019
tokens and here we have the famous NLP

92
00:03:40,019 --> 00:03:42,180
models and then the other side we have

93
00:03:42,180 --> 00:03:44,580
graph embeddings taking inputs the

94
00:03:44,580 --> 00:03:46,680
function control graph

95
00:03:46,680 --> 00:03:48,959
and most prominent example are the graph

96
00:03:48,959 --> 00:03:50,700
neural network

97
00:03:50,700 --> 00:03:52,860
in terms of extracting features from

98
00:03:52,860 --> 00:03:55,019
functions there are several features

99
00:03:55,019 --> 00:03:57,659
comes a different cost of extraction we

100
00:03:57,659 --> 00:03:59,519
have feature based on the code feature

101
00:03:59,519 --> 00:04:01,319
based on the structure of the function

102
00:04:01,319 --> 00:04:04,080
like the control flow graph if we had

103
00:04:04,080 --> 00:04:06,299
features to the to the nodes of the

104
00:04:06,299 --> 00:04:08,580
control flow graph we have annotated

105
00:04:08,580 --> 00:04:11,099
control flow graph and then we have also

106
00:04:11,099 --> 00:04:13,080
other feature like data flow analysis

107
00:04:13,080 --> 00:04:15,540
Dynamic analysis symbolic execution but

108
00:04:15,540 --> 00:04:18,418
those may be more expensive to run

109
00:04:18,418 --> 00:04:20,579
when we look at the last six years of

110
00:04:20,579 --> 00:04:22,500
Publications we see a trend towards

111
00:04:22,500 --> 00:04:24,780
graph embedding code embeddings and a

112
00:04:24,780 --> 00:04:26,160
combination of them

113
00:04:26,160 --> 00:04:29,400
and from these picture we selected 10

114
00:04:29,400 --> 00:04:31,259
different papers and different

115
00:04:31,259 --> 00:04:33,180
approaches

116
00:04:33,180 --> 00:04:36,540
and the the criteria was mainly to cover

117
00:04:36,540 --> 00:04:38,160
different techniques cover different

118
00:04:38,160 --> 00:04:41,220
feature extraction methods and also to

119
00:04:41,220 --> 00:04:42,660
cover different research communities

120
00:04:42,660 --> 00:04:44,639
because as I said this was one of the

121
00:04:44,639 --> 00:04:47,300
previous issues

122
00:04:47,460 --> 00:04:50,400
in terms of implementation we wanted to

123
00:04:50,400 --> 00:04:52,560
have a fair evaluation so implemented

124
00:04:52,560 --> 00:04:56,040
all the approaches in a uniform way and

125
00:04:56,040 --> 00:04:58,080
for this we used either Prof or the

126
00:04:58,080 --> 00:05:01,139
binary analysis Ida Pro for the

127
00:05:01,139 --> 00:05:03,300
scripting

128
00:05:03,300 --> 00:05:05,460
tensorflow and ginseng for the neural

129
00:05:05,460 --> 00:05:07,080
network implementation

130
00:05:07,080 --> 00:05:09,240
and for the data set we created two new

131
00:05:09,240 --> 00:05:11,040
data sets in order to have all the

132
00:05:11,040 --> 00:05:14,100
different compilation options this means

133
00:05:14,100 --> 00:05:16,080
multiple compiler multiple compiler

134
00:05:16,080 --> 00:05:17,880
versions different optimization

135
00:05:17,880 --> 00:05:19,919
different architecture and business and

136
00:05:19,919 --> 00:05:21,479
also different software

137
00:05:21,479 --> 00:05:23,460
we're not regarding this we want to

138
00:05:23,460 --> 00:05:25,259
release everything but we are a bit

139
00:05:25,259 --> 00:05:27,240
behind the schedule is because we

140
00:05:27,240 --> 00:05:28,860
underestimated the effort of open

141
00:05:28,860 --> 00:05:31,680
sourcing within a bin company we had to

142
00:05:31,680 --> 00:05:33,419
review the entire code so everything

143
00:05:33,419 --> 00:05:35,340
will come but we need to be a little

144
00:05:35,340 --> 00:05:37,380
more patient on this

145
00:05:37,380 --> 00:05:39,900
and sorry for for the delay

146
00:05:39,900 --> 00:05:42,900
regarding experiments we

147
00:05:42,900 --> 00:05:45,919
identify six tasks to evaluate

148
00:05:45,919 --> 00:05:48,060
just to give an example the cross

149
00:05:48,060 --> 00:05:49,680
compiler task is the task where

150
00:05:49,680 --> 00:05:51,780
functions have different compiler

151
00:05:51,780 --> 00:05:55,139
compiler versions and optimizations but

152
00:05:55,139 --> 00:05:56,759
they have the same architecture and

153
00:05:56,759 --> 00:05:57,900
business

154
00:05:57,900 --> 00:06:00,120
and each task is evaluated using three

155
00:06:00,120 --> 00:06:03,120
different metrics the AUC minor

156
00:06:03,120 --> 00:06:06,000
reciprocal Rank and the recall

157
00:06:06,000 --> 00:06:08,580
so we take into account also the ranking

158
00:06:08,580 --> 00:06:09,780
Matrix

159
00:06:09,780 --> 00:06:11,400
and what we noticed during the

160
00:06:11,400 --> 00:06:13,139
evaluation is that the function pair

161
00:06:13,139 --> 00:06:15,300
selection that is how positive Pairs and

162
00:06:15,300 --> 00:06:17,880
negative pairs are created does impact

163
00:06:17,880 --> 00:06:20,520
the performances and is something that

164
00:06:20,520 --> 00:06:22,080
has not been highlighted in the past

165
00:06:22,080 --> 00:06:24,800
papers

166
00:06:25,319 --> 00:06:28,199
when we look at the the result I would

167
00:06:28,199 --> 00:06:30,479
like to show you this plot

168
00:06:30,479 --> 00:06:32,160
that comes from one of the most

169
00:06:32,160 --> 00:06:34,440
challenging tasks which is the cross mix

170
00:06:34,440 --> 00:06:36,539
task where every variable every

171
00:06:36,539 --> 00:06:39,180
completion variable is free

172
00:06:39,180 --> 00:06:41,160
and I would like to

173
00:06:41,160 --> 00:06:43,259
I'll get your attention to three main

174
00:06:43,259 --> 00:06:46,080
points the first one is that no not all

175
00:06:46,080 --> 00:06:47,699
the models support the cross

176
00:06:47,699 --> 00:06:50,400
architecture setup so this is this

177
00:06:50,400 --> 00:06:52,319
matters when it comes to selecting which

178
00:06:52,319 --> 00:06:54,600
model to use

179
00:06:54,600 --> 00:06:57,660
second point is that when we talk about

180
00:06:57,660 --> 00:07:00,419
graph neural networks and annotated

181
00:07:00,419 --> 00:07:02,460
control flow graph that is a control

182
00:07:02,460 --> 00:07:05,039
flow graph with basic block features

183
00:07:05,039 --> 00:07:07,919
it's very important to select the proper

184
00:07:07,919 --> 00:07:10,620
features because moving from manually

185
00:07:10,620 --> 00:07:12,680
feature engineered features

186
00:07:12,680 --> 00:07:16,680
to a less complex type of features to

187
00:07:16,680 --> 00:07:19,080
extract like the Lego worlds does change

188
00:07:19,080 --> 00:07:20,160
the results

189
00:07:20,160 --> 00:07:23,460
and also in the third Point moving from

190
00:07:23,460 --> 00:07:25,259
one type of graph neural network to

191
00:07:25,259 --> 00:07:27,720
another type does impact the result as

192
00:07:27,720 --> 00:07:29,520
well

193
00:07:29,520 --> 00:07:31,500
now I would like to conclude with four

194
00:07:31,500 --> 00:07:33,000
takeaways

195
00:07:33,000 --> 00:07:34,500
first of all

196
00:07:34,500 --> 00:07:36,599
which is the main contribution of the

197
00:07:36,599 --> 00:07:39,000
machine learning Solutions well we what

198
00:07:39,000 --> 00:07:40,740
we found out is that deep learning

199
00:07:40,740 --> 00:07:42,780
models are effective in terms of

200
00:07:42,780 --> 00:07:45,000
scalability and precision when it comes

201
00:07:45,000 --> 00:07:48,599
to Computing function similarity

202
00:07:48,599 --> 00:07:51,960
and these they are they are effective

203
00:07:51,960 --> 00:07:55,139
uh when they are used with the Chinese

204
00:07:55,139 --> 00:07:57,780
architecture and combined with the

205
00:07:57,780 --> 00:08:00,660
margin based loss

206
00:08:00,660 --> 00:08:03,000
and among the different coders grafeneur

207
00:08:03,000 --> 00:08:05,759
network are the most effective one the

208
00:08:05,759 --> 00:08:08,340
one that have the best results

209
00:08:08,340 --> 00:08:10,380
second takeaway is about the different

210
00:08:10,380 --> 00:08:12,419
type of features

211
00:08:12,419 --> 00:08:15,060
what we found out is that annotated

212
00:08:15,060 --> 00:08:16,919
control flow graph does provide the

213
00:08:16,919 --> 00:08:19,080
benefit but there is a minimal

214
00:08:19,080 --> 00:08:21,000
difference when it comes to manually

215
00:08:21,000 --> 00:08:24,780
engineered features and simpler ones

216
00:08:24,780 --> 00:08:27,539
like a bigger word of the opcots this

217
00:08:27,539 --> 00:08:29,940
means that having expensive manually

218
00:08:29,940 --> 00:08:32,099
engineer features that does not provide

219
00:08:32,099 --> 00:08:35,039
any big advantage in any of the test

220
00:08:35,039 --> 00:08:36,719
cases that we evaluated

221
00:08:36,719 --> 00:08:39,240
and also data flow information

222
00:08:39,240 --> 00:08:42,539
is very interesting and can boost the

223
00:08:42,539 --> 00:08:46,080
results for larger functions

224
00:08:46,080 --> 00:08:49,320
third third takeaway is about

225
00:08:49,320 --> 00:08:51,779
two different tests the cross

226
00:08:51,779 --> 00:08:53,640
architecture and the single architecture

227
00:08:53,640 --> 00:08:56,040
and the question here is crosstalk

228
00:08:56,040 --> 00:08:58,560
architecture more complex than single

229
00:08:58,560 --> 00:09:01,560
architecture where the short answer is

230
00:09:01,560 --> 00:09:04,140
no all the machine learning models

231
00:09:04,140 --> 00:09:06,959
perform similarly on all the tasks and

232
00:09:06,959 --> 00:09:08,519
most interesting

233
00:09:08,519 --> 00:09:11,279
uh we can train them only on the most

234
00:09:11,279 --> 00:09:13,860
generic task and they can achieve

235
00:09:13,860 --> 00:09:15,959
performances that are close to the best

236
00:09:15,959 --> 00:09:18,899
for each other task

237
00:09:18,899 --> 00:09:21,660
however not all the models support the

238
00:09:21,660 --> 00:09:23,820
cross architecture tests in particular

239
00:09:23,820 --> 00:09:26,820
ask to back and catalog are limited to a

240
00:09:26,820 --> 00:09:29,339
single architecture

241
00:09:29,339 --> 00:09:31,380
and finally we chart the future

242
00:09:31,380 --> 00:09:34,019
direction for the research

243
00:09:34,019 --> 00:09:36,000
well what we found out is that graphing

244
00:09:36,000 --> 00:09:37,620
your network provides the best results

245
00:09:37,620 --> 00:09:40,320
however it is a very active area of

246
00:09:40,320 --> 00:09:42,180
research where there are tons of

247
00:09:42,180 --> 00:09:43,680
different variants that need to be

248
00:09:43,680 --> 00:09:46,260
tested so we include the community to

249
00:09:46,260 --> 00:09:47,580
work on these

250
00:09:47,580 --> 00:09:49,740
the second is that combining graphing

251
00:09:49,740 --> 00:09:51,959
your network with other set of features

252
00:09:51,959 --> 00:09:54,300
like combination of intermediate

253
00:09:54,300 --> 00:09:56,000
representation and data flow information

254
00:09:56,000 --> 00:09:59,640
must be studied because can improve the

255
00:09:59,640 --> 00:10:00,600
results

256
00:10:00,600 --> 00:10:03,720
and finally training strategies and loss

257
00:10:03,720 --> 00:10:05,820
functions have been barely discussed in

258
00:10:05,820 --> 00:10:08,640
the past and only recently some research

259
00:10:08,640 --> 00:10:11,459
some researchers started to explore them

260
00:10:11,459 --> 00:10:13,740
and what we found out that they are

261
00:10:13,740 --> 00:10:15,839
really important as much as the features

262
00:10:15,839 --> 00:10:17,519
and the model selection

263
00:10:17,519 --> 00:10:19,440
and with this I conclude my presentation

264
00:10:19,440 --> 00:10:21,120
I really thank you for your attention

265
00:10:21,120 --> 00:10:25,399
and now I'm happy to answer any question

