1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:09,380 --> 00:00:12,660
work with Maurice Heyman Benny pinkers

3
00:00:12,660 --> 00:00:15,299
and Thomas schleiter my advisor

4
00:00:15,299 --> 00:00:17,340
I also thank you for joining this third

5
00:00:17,340 --> 00:00:20,279
talk on PIR in this session so we have

6
00:00:20,279 --> 00:00:22,320
seen single server appear we have seen

7
00:00:22,320 --> 00:00:25,100
microserver appear with an offline face

8
00:00:25,100 --> 00:00:28,260
which can be used to get speed UPS in

9
00:00:28,260 --> 00:00:30,539
the online phase and now in this work we

10
00:00:30,539 --> 00:00:32,399
even go one step further and make the

11
00:00:32,399 --> 00:00:34,440
offline phase completely independent of

12
00:00:34,440 --> 00:00:37,260
the client so this means the peer server

13
00:00:37,260 --> 00:00:38,820
do not even need to know the clients

14
00:00:38,820 --> 00:00:40,559
before they can compute the offline

15
00:00:40,559 --> 00:00:42,800
phase

16
00:00:43,020 --> 00:00:46,800
so we have many applications for peer so

17
00:00:46,800 --> 00:00:49,020
basically the most important one is in

18
00:00:49,020 --> 00:00:51,120
the area of private set memberships

19
00:00:51,120 --> 00:00:54,059
where we can securely check if an entry

20
00:00:54,059 --> 00:00:56,340
exists in a public database like for

21
00:00:56,340 --> 00:00:58,199
instance if we take some patent

22
00:00:58,199 --> 00:00:59,840
databases

23
00:00:59,840 --> 00:01:03,300
we can check if our patent that we have

24
00:01:03,300 --> 00:01:06,540
developed the idea is already in such a

25
00:01:06,540 --> 00:01:07,619
database

26
00:01:07,619 --> 00:01:11,400
and we can use peer to not leak which

27
00:01:11,400 --> 00:01:13,740
patent we actually have

28
00:01:13,740 --> 00:01:17,760
and some other areas in uh for peer are

29
00:01:17,760 --> 00:01:19,500
in the area of private messaging apps

30
00:01:19,500 --> 00:01:21,420
where we can hide the meter data and the

31
00:01:21,420 --> 00:01:22,740
messages we send

32
00:01:22,740 --> 00:01:25,439
and another important applications is

33
00:01:25,439 --> 00:01:27,840
compromise credential checking

34
00:01:27,840 --> 00:01:30,060
which is also part of the private set

35
00:01:30,060 --> 00:01:33,360
membership area but here we want to

36
00:01:33,360 --> 00:01:35,820
check if our credentials were already

37
00:01:35,820 --> 00:01:38,460
leaked in a data breach

38
00:01:38,460 --> 00:01:41,579
and by using peer we can completely hide

39
00:01:41,579 --> 00:01:45,439
our credentials from the servers

40
00:01:46,500 --> 00:01:49,079
so in this work we also focus on Mighty

41
00:01:49,079 --> 00:01:51,659
server pier where Alice communicates to

42
00:01:51,659 --> 00:01:53,820
at least two servers

43
00:01:53,820 --> 00:01:56,759
and usually in all standard peer

44
00:01:56,759 --> 00:01:59,399
protocols uh this is Alice first sends

45
00:01:59,399 --> 00:02:01,439
the query to each of the servers then

46
00:02:01,439 --> 00:02:04,100
the server locally do some computations

47
00:02:04,100 --> 00:02:07,860
and then send their answer back to Alice

48
00:02:07,860 --> 00:02:09,720
who then can combine this answer to the

49
00:02:09,720 --> 00:02:12,540
desired database entry

50
00:02:12,540 --> 00:02:15,540
a drawback of this model is that we need

51
00:02:15,540 --> 00:02:18,780
to assume that these servers or a subset

52
00:02:18,780 --> 00:02:22,440
of the servers are non-colluding but the

53
00:02:22,440 --> 00:02:24,599
big Pro of this is that this is very

54
00:02:24,599 --> 00:02:26,459
efficient because we do not really need

55
00:02:26,459 --> 00:02:28,860
to rely on expensive operations like

56
00:02:28,860 --> 00:02:32,300
homomorphic encryption

57
00:02:33,840 --> 00:02:36,840
so the ideal functionality or in classic

58
00:02:36,840 --> 00:02:39,780
peer protocol looks like this so the

59
00:02:39,780 --> 00:02:43,800
setting is Alice has an input idx which

60
00:02:43,800 --> 00:02:46,440
is the index of the database item that

61
00:02:46,440 --> 00:02:48,120
she wants to query

62
00:02:48,120 --> 00:02:51,300
the servers share a database which is

63
00:02:51,300 --> 00:02:54,120
assumed to be public and in the end

64
00:02:54,120 --> 00:02:56,819
Alice wants to learn this dire database

65
00:02:56,819 --> 00:02:59,700
entry on her index

66
00:02:59,700 --> 00:03:02,580
the first of all she computes a request

67
00:03:02,580 --> 00:03:06,239
for each of the servers and usually this

68
00:03:06,239 --> 00:03:09,239
is a b Bit Zero bit string with just a

69
00:03:09,239 --> 00:03:11,340
single one at the position of her

70
00:03:11,340 --> 00:03:14,700
indexed but these and queries X or up to

71
00:03:14,700 --> 00:03:17,159
these with string

72
00:03:17,159 --> 00:03:20,099
the queries are then sent to the servers

73
00:03:20,099 --> 00:03:22,500
and the server locally compute the

74
00:03:22,500 --> 00:03:25,800
answer and this is usually Computing the

75
00:03:25,800 --> 00:03:27,720
query with the database and x-ordering

76
00:03:27,720 --> 00:03:29,819
these things up together

77
00:03:29,819 --> 00:03:32,159
sending back the answer to Alice and

78
00:03:32,159 --> 00:03:34,440
Alice can then combine these answers by

79
00:03:34,440 --> 00:03:36,780
x-raying all the blocks together and

80
00:03:36,780 --> 00:03:38,819
gets the result

81
00:03:38,819 --> 00:03:41,040
so the drawback which we also saw in the

82
00:03:41,040 --> 00:03:43,920
last talk is we need to access the whole

83
00:03:43,920 --> 00:03:45,780
database in the online phase and that's

84
00:03:45,780 --> 00:03:47,700
not our what we actually want because

85
00:03:47,700 --> 00:03:50,700
it's too expensive

86
00:03:50,700 --> 00:03:53,459
so in this work we look on so-called

87
00:03:53,459 --> 00:03:55,739
client independent pre-processing which

88
00:03:55,739 --> 00:03:57,900
allows pre-processing independent of the

89
00:03:57,900 --> 00:03:58,920
client

90
00:03:58,920 --> 00:04:02,700
and we look at some old scheme that's

91
00:04:02,700 --> 00:04:05,879
called rate peer I want to briefly

92
00:04:05,879 --> 00:04:08,159
introduce you this so in ratepure the

93
00:04:08,159 --> 00:04:11,340
database is built up into multiple

94
00:04:11,340 --> 00:04:14,700
blocks and these blocks are again split

95
00:04:14,700 --> 00:04:16,680
into multiple chunks and usually the

96
00:04:16,680 --> 00:04:18,298
number of chunks is equal to the number

97
00:04:18,298 --> 00:04:19,620
of servers

98
00:04:19,620 --> 00:04:22,019
so we have three servers in this example

99
00:04:22,019 --> 00:04:23,520
here

100
00:04:23,520 --> 00:04:26,100
then the idea is that the main query

101
00:04:26,100 --> 00:04:29,639
which is denoted as a big Hue here

102
00:04:29,639 --> 00:04:32,220
that this is the zero bit string with

103
00:04:32,220 --> 00:04:34,440
just a single one at the block number

104
00:04:34,440 --> 00:04:36,960
five so in this example we assume Alice

105
00:04:36,960 --> 00:04:39,120
wants to retrieve block number five

106
00:04:39,120 --> 00:04:41,580
and the idea is that now these three

107
00:04:41,580 --> 00:04:44,460
queries X or up to this main query

108
00:04:44,460 --> 00:04:48,360
and now the client can choose this curvy

109
00:04:48,360 --> 00:04:51,360
as follows and the purple cells

110
00:04:51,360 --> 00:04:55,020
the values are generated randomly and

111
00:04:55,020 --> 00:04:57,060
only the orange cells which we call the

112
00:04:57,060 --> 00:04:59,280
flip chance of this servers they are

113
00:04:59,280 --> 00:05:01,680
computed by xoring these columns

114
00:05:01,680 --> 00:05:03,860
together

115
00:05:07,139 --> 00:05:10,500
so now as all of as most of the query is

116
00:05:10,500 --> 00:05:13,680
chosen randomly we can also use a seed

117
00:05:13,680 --> 00:05:15,660
for it

118
00:05:15,660 --> 00:05:18,840
um we chose a 128 bit seat for each of

119
00:05:18,840 --> 00:05:21,720
for each query put them into the pseudo

120
00:05:21,720 --> 00:05:24,360
random generator and this can expand us

121
00:05:24,360 --> 00:05:28,020
this query to whatever size we need so

122
00:05:28,020 --> 00:05:29,820
even if we have thousands or millions of

123
00:05:29,820 --> 00:05:31,800
blocks we don't need to

124
00:05:31,800 --> 00:05:33,600
um

125
00:05:33,600 --> 00:05:36,600
to choose or to transfer so many bits

126
00:05:36,600 --> 00:05:39,900
separately we can just use the 128-bit

127
00:05:39,900 --> 00:05:42,300
seat and can expand thousands or

128
00:05:42,300 --> 00:05:45,800
millions of bits

129
00:05:47,400 --> 00:05:51,479
thought in in rate peer the server or

130
00:05:51,479 --> 00:05:53,580
the no sorry the client chooses the

131
00:05:53,580 --> 00:05:56,160
seats and we'll now look at what happens

132
00:05:56,160 --> 00:05:59,940
when the server chooses the seeds

133
00:05:59,940 --> 00:06:03,740
and when the server chooses the seeds

134
00:06:03,740 --> 00:06:07,139
the server already knows a huge part of

135
00:06:07,139 --> 00:06:11,160
the query so basically n minus 1 over n

136
00:06:11,160 --> 00:06:13,560
of the whole query is expanded by the

137
00:06:13,560 --> 00:06:16,620
seed and this is information the server

138
00:06:16,620 --> 00:06:18,300
then knows independently of the client

139
00:06:18,300 --> 00:06:21,180
and can be computed in online phase

140
00:06:21,180 --> 00:06:24,539
and consequently only 1 over n

141
00:06:24,539 --> 00:06:27,479
which builds the flip chunk of the query

142
00:06:27,479 --> 00:06:30,419
is known in the online phase so we only

143
00:06:30,419 --> 00:06:32,880
need this information from the client to

144
00:06:32,880 --> 00:06:35,840
compute the whole query

145
00:06:35,940 --> 00:06:37,979
so in the superior model analysis

146
00:06:37,979 --> 00:06:40,020
follows We have basically the same

147
00:06:40,020 --> 00:06:42,840
setting Alice inputs her index the

148
00:06:42,840 --> 00:06:45,180
servers share database and we want to

149
00:06:45,180 --> 00:06:45,960
learn

150
00:06:45,960 --> 00:06:49,560
the database item on the index

151
00:06:49,560 --> 00:06:52,440
now we also assume that the servers have

152
00:06:52,440 --> 00:06:55,979
a queue with the value pairs which are

153
00:06:55,979 --> 00:06:57,780
generated in the pre-processing phase

154
00:06:57,780 --> 00:07:01,860
without any interaction with Alice

155
00:07:01,860 --> 00:07:03,780
during the online phase the first step

156
00:07:03,780 --> 00:07:07,139
is that the servers pop one of the seed

157
00:07:07,139 --> 00:07:08,520
value pairs

158
00:07:08,520 --> 00:07:11,039
and sends the C to Alice

159
00:07:11,039 --> 00:07:14,220
then Alice computes the request choosing

160
00:07:14,220 --> 00:07:15,780
the seat received from the server

161
00:07:15,780 --> 00:07:17,520
instead of shooting the seeds on her own

162
00:07:17,520 --> 00:07:20,400
sends the query back to the servers

163
00:07:20,400 --> 00:07:23,280
the server compute the response using

164
00:07:23,280 --> 00:07:27,240
the preprocessed value AI from the queue

165
00:07:27,240 --> 00:07:29,699
sends back the result to Alice and Alice

166
00:07:29,699 --> 00:07:32,039
can combine these together to receive

167
00:07:32,039 --> 00:07:35,479
the desired database entry

168
00:07:37,380 --> 00:07:40,380
so basically what I've shown you is the

169
00:07:40,380 --> 00:07:42,599
basic of our new protocol which we call

170
00:07:42,599 --> 00:07:45,840
Superior and I want to highlight one

171
00:07:45,840 --> 00:07:47,699
cool feature of the pier which allows

172
00:07:47,699 --> 00:07:51,500
for very efficient batch reprocessing

173
00:07:52,440 --> 00:07:54,060
so

174
00:07:54,060 --> 00:07:56,880
instead of Computing the seeds one by

175
00:07:56,880 --> 00:08:00,000
one we can group them together into a t

176
00:08:00,000 --> 00:08:01,979
tier seat

177
00:08:01,979 --> 00:08:05,400
and we expand this TC together

178
00:08:05,400 --> 00:08:07,800
so that we get can compute key queries

179
00:08:07,800 --> 00:08:10,080
independently

180
00:08:10,080 --> 00:08:11,639
and

181
00:08:11,639 --> 00:08:14,160
the good thing is

182
00:08:14,160 --> 00:08:16,620
looking ahead when we deploy this on a

183
00:08:16,620 --> 00:08:17,819
GPU

184
00:08:17,819 --> 00:08:21,000
we would have many a very expensive

185
00:08:21,000 --> 00:08:22,860
shifting operations when we want to

186
00:08:22,860 --> 00:08:25,080
shift the database Parts into the memory

187
00:08:25,080 --> 00:08:26,879
of the GPU

188
00:08:26,879 --> 00:08:29,759
and we can compensate these costs and

189
00:08:29,759 --> 00:08:32,399
amortize these among all the T queries

190
00:08:32,399 --> 00:08:34,500
that we compute in parallel

191
00:08:34,500 --> 00:08:37,260
the the pre-processing is not so

192
00:08:37,260 --> 00:08:38,880
expensive anymore

193
00:08:38,880 --> 00:08:41,458
and finally what we have we have then

194
00:08:41,458 --> 00:08:43,620
after a couple of time

195
00:08:43,620 --> 00:08:46,320
T seed value pairs which we can use in

196
00:08:46,320 --> 00:08:48,980
the online phase

197
00:08:50,820 --> 00:08:53,339
so our next contribution is some

198
00:08:53,339 --> 00:08:55,740
database compression techniques in peer

199
00:08:55,740 --> 00:08:58,320
uh we basically have two techniques for

200
00:08:58,320 --> 00:09:01,440
this and I'll show you so the first one

201
00:09:01,440 --> 00:09:04,620
is that we use shorter hashes so this is

202
00:09:04,620 --> 00:09:06,959
back basically optimizations for hash

203
00:09:06,959 --> 00:09:09,600
based databases which are often the case

204
00:09:09,600 --> 00:09:11,220
in these private set membership

205
00:09:11,220 --> 00:09:13,740
applications that I've shown you

206
00:09:13,740 --> 00:09:16,680
the idea is that we only store Omega

207
00:09:16,680 --> 00:09:20,640
plus logarithmic and bits of hash values

208
00:09:20,640 --> 00:09:23,640
and here Omega is a statistical security

209
00:09:23,640 --> 00:09:26,880
parameter which we can choose so that we

210
00:09:26,880 --> 00:09:27,720
are fine

211
00:09:27,720 --> 00:09:30,480
and the number n is the number of

212
00:09:30,480 --> 00:09:33,560
entries of the database

213
00:09:34,140 --> 00:09:37,920
and then we have a different sequence

214
00:09:37,920 --> 00:09:42,839
so we assume that the database is sorted

215
00:09:42,839 --> 00:09:45,180
like if we have hash values and we have

216
00:09:45,180 --> 00:09:47,339
thousands or millions of hash values

217
00:09:47,339 --> 00:09:50,100
then these are very close together and

218
00:09:50,100 --> 00:09:52,620
if we subtract neighboring hash values

219
00:09:52,620 --> 00:09:54,660
in this sort of database we would have

220
00:09:54,660 --> 00:09:57,660
many zero prefixes and obviously we

221
00:09:57,660 --> 00:09:59,640
don't necessarily need to store these

222
00:09:59,640 --> 00:10:01,320
zero prefixes

223
00:10:01,320 --> 00:10:03,540
and instead we just store the

224
00:10:03,540 --> 00:10:06,360
differences of neighboring items which

225
00:10:06,360 --> 00:10:11,120
give us an improvement of factor 3.3

226
00:10:12,420 --> 00:10:15,000
then we finally also implemented our

227
00:10:15,000 --> 00:10:16,260
protocol

228
00:10:16,260 --> 00:10:18,720
and we provide two implementations for

229
00:10:18,720 --> 00:10:21,839
it one is based on a CPU which we do

230
00:10:21,839 --> 00:10:23,760
some optimizations like also

231
00:10:23,760 --> 00:10:27,000
parallelization via openmp

232
00:10:27,000 --> 00:10:30,000
and the more interesting one is our GPU

233
00:10:30,000 --> 00:10:33,019
based implementation

234
00:10:33,120 --> 00:10:36,000
so I want to show you some results here

235
00:10:36,000 --> 00:10:39,360
so as the Baseline for our evaluation is

236
00:10:39,360 --> 00:10:41,760
FSS peer which is peer based on

237
00:10:41,760 --> 00:10:43,920
functions equal sharing which basically

238
00:10:43,920 --> 00:10:46,320
has the same types of operations

239
00:10:46,320 --> 00:10:50,060
but it decreases the online complex

240
00:10:50,060 --> 00:10:53,160
communication complexity to logarithmic

241
00:10:53,160 --> 00:10:55,620
while in CPO and rate period we have

242
00:10:55,620 --> 00:10:59,480
sublinear communication complexity

243
00:10:59,700 --> 00:11:03,060
so the gray line is FSS peer we

244
00:11:03,060 --> 00:11:05,220
re-implemented it also on the GPU to

245
00:11:05,220 --> 00:11:06,839
have a fair comparison so we have

246
00:11:06,839 --> 00:11:09,600
exactly the same setting here

247
00:11:09,600 --> 00:11:11,579
and um

248
00:11:11,579 --> 00:11:14,880
this is the Gray Line and the first

249
00:11:14,880 --> 00:11:17,279
Benchmark is the online cost of our

250
00:11:17,279 --> 00:11:20,399
supervisors the green line so excluding

251
00:11:20,399 --> 00:11:23,579
the offline phase and we see that sipia

252
00:11:23,579 --> 00:11:26,459
is already better for databases starting

253
00:11:26,459 --> 00:11:29,160
at eight gigabyte

254
00:11:29,160 --> 00:11:31,800
then interestingly the Blue Line is now

255
00:11:31,800 --> 00:11:34,019
the amortized total cost like including

256
00:11:34,019 --> 00:11:35,820
the online phase and the pre-processing

257
00:11:35,820 --> 00:11:36,720
phase

258
00:11:36,720 --> 00:11:39,839
and for our benchmarks databases up to

259
00:11:39,839 --> 00:11:43,320
25 gigabytes we don't beat fssp in the

260
00:11:43,320 --> 00:11:44,640
total cost

261
00:11:44,640 --> 00:11:47,399
but we see a clear Trend that these two

262
00:11:47,399 --> 00:11:49,980
lines get closer and closer and we even

263
00:11:49,980 --> 00:11:52,980
expect that for larger databases the

264
00:11:52,980 --> 00:11:57,620
peer would also outperform FSS peer

265
00:11:57,620 --> 00:12:01,820
including the total costs

266
00:12:02,279 --> 00:12:04,440
so in summary what we did in this work

267
00:12:04,440 --> 00:12:06,959
we designed a new peer model which is

268
00:12:06,959 --> 00:12:08,579
called client independent pre-processing

269
00:12:08,579 --> 00:12:10,680
and allows pre-processing completely

270
00:12:10,680 --> 00:12:12,420
independent of the client

271
00:12:12,420 --> 00:12:14,760
we designed a protocol called zapier

272
00:12:14,760 --> 00:12:16,380
which also allows very efficient battery

273
00:12:16,380 --> 00:12:19,079
processing apply some database

274
00:12:19,079 --> 00:12:21,660
compression techniques in peer and

275
00:12:21,660 --> 00:12:25,440
implemented everything on a CPU and GPU

276
00:12:25,440 --> 00:12:28,380
an interesting future work would also be

277
00:12:28,380 --> 00:12:32,459
to apply the Sip model to FSS peer to

278
00:12:32,459 --> 00:12:34,200
also benefit from the logarithmic

279
00:12:34,200 --> 00:12:37,220
communication complexity

280
00:12:37,380 --> 00:12:40,560
we have code for this and with this I

281
00:12:40,560 --> 00:12:42,540
want to conclude my talk and thank you

282
00:12:42,540 --> 00:12:44,600
for your attention and I'm happy to

283
00:12:44,600 --> 00:12:48,440
get questions from you

