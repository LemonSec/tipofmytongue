1
00:00:08,119 --> 00:00:10,580
hi today I'll be talking about

2
00:00:10,580 --> 00:00:13,860
experiences of U.S lgbtq folks with

3
00:00:13,860 --> 00:00:15,839
online security safety and privacy

4
00:00:15,839 --> 00:00:18,119
advice I'm Chris King and this was work

5
00:00:18,119 --> 00:00:20,400
done with Mike Harris Alyssa renmiles

6
00:00:20,400 --> 00:00:23,538
and Francisca Rosner

7
00:00:24,119 --> 00:00:26,160
so queer and trans individuals face

8
00:00:26,160 --> 00:00:28,199
homophobic and transphobic harms when

9
00:00:28,199 --> 00:00:30,900
using digital tools a recent glad report

10
00:00:30,900 --> 00:00:33,840
found that 64 percent of lgbtq social

11
00:00:33,840 --> 00:00:35,880
media users reported experiencing

12
00:00:35,880 --> 00:00:37,920
harassment and hate speech a much higher

13
00:00:37,920 --> 00:00:40,260
rate than all other identity groups

14
00:00:40,260 --> 00:00:42,719
and a couple years ago a senior U.S

15
00:00:42,719 --> 00:00:45,239
Roman Catholic Church official was

16
00:00:45,239 --> 00:00:46,860
forced to resign after being outed

17
00:00:46,860 --> 00:00:48,840
through Grindr data sold to a third

18
00:00:48,840 --> 00:00:51,840
party Advertiser

19
00:00:51,840 --> 00:00:54,840
so these harms lead to the question of

20
00:00:54,840 --> 00:00:56,640
where and how do queer individuals learn

21
00:00:56,640 --> 00:00:59,160
to protect themselves online

22
00:00:59,160 --> 00:01:01,320
previous research on computer security

23
00:01:01,320 --> 00:01:03,420
and privacy advice has largely focused

24
00:01:03,420 --> 00:01:06,060
on General populations and topics but

25
00:01:06,060 --> 00:01:08,159
what about advice specific to preventing

26
00:01:08,159 --> 00:01:10,380
and mitigating queer and trans harms on

27
00:01:10,380 --> 00:01:12,240
the internet

28
00:01:12,240 --> 00:01:14,580
this leads to the research questions for

29
00:01:14,580 --> 00:01:15,900
my project

30
00:01:15,900 --> 00:01:18,659
one where do queer individuals in the

31
00:01:18,659 --> 00:01:20,640
U.S find advice for supporting their

32
00:01:20,640 --> 00:01:24,360
online security safety and or privacy

33
00:01:24,360 --> 00:01:26,640
two what barriers prevent that advice

34
00:01:26,640 --> 00:01:29,040
from being effective

35
00:01:29,040 --> 00:01:31,560
and three how do other identities impact

36
00:01:31,560 --> 00:01:35,119
finding and deciding on advice

37
00:01:35,340 --> 00:01:38,960
now I'll talk about our methodology

38
00:01:39,060 --> 00:01:40,920
to answer our research questions we

39
00:01:40,920 --> 00:01:42,720
conducted interviews with 14 queer

40
00:01:42,720 --> 00:01:45,600
individuals in the U.S in 2021

41
00:01:45,600 --> 00:01:47,520
these were done by phone call or over

42
00:01:47,520 --> 00:01:50,159
Zoom due to the pandemic and also to

43
00:01:50,159 --> 00:01:51,600
accommodate for folks who wanted more

44
00:01:51,600 --> 00:01:52,680
privacy

45
00:01:52,680 --> 00:01:54,720
we recruited participants through posts

46
00:01:54,720 --> 00:01:57,360
and online queer communities and we

47
00:01:57,360 --> 00:01:59,759
recruited until we reached saturation or

48
00:01:59,759 --> 00:02:01,619
when no new major themes emerged from

49
00:02:01,619 --> 00:02:04,340
our interviews

50
00:02:05,700 --> 00:02:07,320
the interview questions we asked

51
00:02:07,320 --> 00:02:09,479
included what security privacy and

52
00:02:09,479 --> 00:02:11,940
safety concerns people had as related to

53
00:02:11,940 --> 00:02:14,580
dating sexting and social media

54
00:02:14,580 --> 00:02:16,500
particularly around their queer and

55
00:02:16,500 --> 00:02:18,300
other identities

56
00:02:18,300 --> 00:02:20,940
we asked where people found advice what

57
00:02:20,940 --> 00:02:23,340
kind of advice they gave others and how

58
00:02:23,340 --> 00:02:25,200
they evaluated advice and whether or not

59
00:02:25,200 --> 00:02:27,920
to adopt it

60
00:02:27,959 --> 00:02:30,120
we also had participants respond to

61
00:02:30,120 --> 00:02:32,160
advice prompts which we collected from

62
00:02:32,160 --> 00:02:33,900
online documents targeting queer

63
00:02:33,900 --> 00:02:36,180
security and privacy these document

64
00:02:36,180 --> 00:02:37,920
sources range from queer support

65
00:02:37,920 --> 00:02:40,379
organizations to platforms themselves

66
00:02:40,379 --> 00:02:42,420
like Tinder and grinder and product

67
00:02:42,420 --> 00:02:45,260
review sites

68
00:02:46,080 --> 00:02:48,660
one example of an advice prompt that was

69
00:02:48,660 --> 00:02:51,300
common among Skies was use a private

70
00:02:51,300 --> 00:02:53,480
account

71
00:02:53,819 --> 00:02:56,099
we also took several ethical

72
00:02:56,099 --> 00:02:59,760
considerations with our study it was

73
00:02:59,760 --> 00:03:01,260
approved by the University of Washington

74
00:03:01,260 --> 00:03:04,500
IRB no video was recorded

75
00:03:04,500 --> 00:03:06,720
audio was deleted after we transcribed

76
00:03:06,720 --> 00:03:09,000
and anonymized interviews

77
00:03:09,000 --> 00:03:11,220
and our interview practices followed

78
00:03:11,220 --> 00:03:14,900
trauma-informed best practices

79
00:03:15,480 --> 00:03:17,280
we recruited diverse participants

80
00:03:17,280 --> 00:03:19,680
diverse across gender sexual orientation

81
00:03:19,680 --> 00:03:23,580
age race and socioeconomic status and it

82
00:03:23,580 --> 00:03:25,620
was important for us to recruit a

83
00:03:25,620 --> 00:03:27,239
diverse group because queer people's

84
00:03:27,239 --> 00:03:29,280
lives aren't only affected by gender and

85
00:03:29,280 --> 00:03:31,680
sexual orientation but also by their

86
00:03:31,680 --> 00:03:34,319
race class and other identities this

87
00:03:34,319 --> 00:03:36,959
concept that many axes work together and

88
00:03:36,959 --> 00:03:38,340
influence each other is called

89
00:03:38,340 --> 00:03:40,819
intersectionality

90
00:03:40,819 --> 00:03:43,140
finally I want to acknowledge our

91
00:03:43,140 --> 00:03:45,420
position as researchers since this

92
00:03:45,420 --> 00:03:47,120
influences the narratives of our results

93
00:03:47,120 --> 00:03:49,560
some authors identify as queer and

94
00:03:49,560 --> 00:03:51,959
non-binary and others identify as

95
00:03:51,959 --> 00:03:54,120
straight and CIS and the authors are

96
00:03:54,120 --> 00:03:56,819
East Asian or white

97
00:03:56,819 --> 00:03:59,819
now I'll talk about our results

98
00:03:59,819 --> 00:04:01,260
so our participants learned about

99
00:04:01,260 --> 00:04:04,260
security safety or privacy advice from

100
00:04:04,260 --> 00:04:05,879
location or school

101
00:04:05,879 --> 00:04:08,099
searching on the internet

102
00:04:08,099 --> 00:04:10,140
or from friends and family

103
00:04:10,140 --> 00:04:12,360
and prior research has also documented

104
00:04:12,360 --> 00:04:13,920
these as sources for General Security

105
00:04:13,920 --> 00:04:16,440
advice

106
00:04:16,440 --> 00:04:18,418
what we also found was that participants

107
00:04:18,418 --> 00:04:20,279
often turn to their queer Community for

108
00:04:20,279 --> 00:04:22,019
advice because they often had similar

109
00:04:22,019 --> 00:04:24,720
life experiences and concerns

110
00:04:24,720 --> 00:04:27,180
for example P4 who's gay and white

111
00:04:27,180 --> 00:04:29,520
turned to his trans men support group

112
00:04:29,520 --> 00:04:31,680
for advice after he found a co-worker on

113
00:04:31,680 --> 00:04:32,940
Grindr and realized they were

114
00:04:32,940 --> 00:04:35,280
accidentally added to each other he said

115
00:04:35,280 --> 00:04:37,620
it wasn't like we had a leader but we

116
00:04:37,620 --> 00:04:39,120
all just sort of compared notes about

117
00:04:39,120 --> 00:04:41,820
what we were doing this type P4 here

118
00:04:41,820 --> 00:04:43,740
different experiences so he can make a

119
00:04:43,740 --> 00:04:46,800
more informed decision

120
00:04:46,800 --> 00:04:49,160
another key finding was that

121
00:04:49,160 --> 00:04:52,440
participants were participants found it

122
00:04:52,440 --> 00:04:54,780
important to get emotional and community

123
00:04:54,780 --> 00:04:56,720
support from a close connection

124
00:04:56,720 --> 00:04:58,860
particularly After experiencing a

125
00:04:58,860 --> 00:05:00,840
harrowing event

126
00:05:00,840 --> 00:05:03,720
for example p12 who's lesbian and black

127
00:05:03,720 --> 00:05:05,880
talked about receiving emotional care

128
00:05:05,880 --> 00:05:07,380
and advice from a loved one after

129
00:05:07,380 --> 00:05:09,720
getting Cyber Bullied for posting lgbtq

130
00:05:09,720 --> 00:05:11,639
topics on social media

131
00:05:11,639 --> 00:05:14,160
turning to my queer cousin was really

132
00:05:14,160 --> 00:05:16,560
beneficial yeah I took the advice into

133
00:05:16,560 --> 00:05:18,180
consideration because I felt I had

134
00:05:18,180 --> 00:05:19,860
someone that really cared about me and

135
00:05:19,860 --> 00:05:23,540
that really accepted me for who I was

136
00:05:24,900 --> 00:05:26,940
in our results we also found many

137
00:05:26,940 --> 00:05:29,820
barriers to finding useful advice these

138
00:05:29,820 --> 00:05:32,520
included distress in the advice Source

139
00:05:32,520 --> 00:05:35,460
the advice becoming out of date a sense

140
00:05:35,460 --> 00:05:37,979
of futility and adopting behaviors the

141
00:05:37,979 --> 00:05:39,660
solution couldn't be found online or

142
00:05:39,660 --> 00:05:41,699
doesn't exist not having the language

143
00:05:41,699 --> 00:05:44,100
for it the advice would interfere with

144
00:05:44,100 --> 00:05:45,419
relationships

145
00:05:45,419 --> 00:05:47,039
and the advice would interfere with

146
00:05:47,039 --> 00:05:50,039
income I go into more detail on each of

147
00:05:50,039 --> 00:05:51,660
these in our paper but today I'll just

148
00:05:51,660 --> 00:05:54,539
give an example about the last barrier

149
00:05:54,539 --> 00:05:56,639
so related to advice would interfere

150
00:05:56,639 --> 00:05:59,220
with income p8 runs a business on

151
00:05:59,220 --> 00:06:01,259
Instagram a business Instagram that was

152
00:06:01,259 --> 00:06:03,120
duplicated by a scammer

153
00:06:03,120 --> 00:06:05,280
they didn't find make account private

154
00:06:05,280 --> 00:06:07,860
the advice prompt useful because they

155
00:06:07,860 --> 00:06:09,539
need their Instagram page to reach new

156
00:06:09,539 --> 00:06:12,020
customers

157
00:06:12,660 --> 00:06:15,300
which leads into another key finding

158
00:06:15,300 --> 00:06:17,460
that participants other identities also

159
00:06:17,460 --> 00:06:20,520
affected how they navigate safety

160
00:06:20,520 --> 00:06:22,620
so some other identities that

161
00:06:22,620 --> 00:06:25,080
participants mentioned

162
00:06:25,080 --> 00:06:27,900
um aside from class and income

163
00:06:27,900 --> 00:06:31,080
as related to their security thoughts

164
00:06:31,080 --> 00:06:34,380
and responses included transitioning

165
00:06:34,380 --> 00:06:37,199
being an activists think a parent

166
00:06:37,199 --> 00:06:42,720
as well as race age and neurodivergence

167
00:06:44,280 --> 00:06:46,440
to give an example of how race

168
00:06:46,440 --> 00:06:48,979
intersects with queerness

169
00:06:48,979 --> 00:06:52,800
P10 gave a response to the advice prompt

170
00:06:52,800 --> 00:06:55,680
of use a police app during a date if one

171
00:06:55,680 --> 00:06:58,560
feels unsafe basically this app allows

172
00:06:58,560 --> 00:07:01,440
someone to click one button in order to

173
00:07:01,440 --> 00:07:04,199
call the police to the phone's location

174
00:07:04,199 --> 00:07:05,940
and he said that he wouldn't use this

175
00:07:05,940 --> 00:07:07,380
app because of his prior experience

176
00:07:07,380 --> 00:07:09,000
being racially profiled in a gay

177
00:07:09,000 --> 00:07:10,139
neighborhood

178
00:07:10,139 --> 00:07:12,240
he said the police started questioning

179
00:07:12,240 --> 00:07:14,580
me about where do I live am I homeless

180
00:07:14,580 --> 00:07:16,800
this incident really ticked me off

181
00:07:16,800 --> 00:07:18,900
because I'm gay the gay neighborhood

182
00:07:18,900 --> 00:07:21,780
that's supposed to be my community

183
00:07:21,780 --> 00:07:24,000
so this example shows how even amongst

184
00:07:24,000 --> 00:07:25,800
queer individuals there are differences

185
00:07:25,800 --> 00:07:27,840
in experiences and impression based on

186
00:07:27,840 --> 00:07:29,400
other identities and therefore

187
00:07:29,400 --> 00:07:31,319
differences in how useful advice would

188
00:07:31,319 --> 00:07:33,500
be

189
00:07:34,319 --> 00:07:36,660
now I'll get into takeaways from our

190
00:07:36,660 --> 00:07:38,220
results

191
00:07:38,220 --> 00:07:41,520
so first there is no one-size-fits-all

192
00:07:41,520 --> 00:07:43,979
security or privacy advice

193
00:07:43,979 --> 00:07:46,319
while some some behaviors were common

194
00:07:46,319 --> 00:07:47,880
amongst our participants and were

195
00:07:47,880 --> 00:07:50,099
discussed positively like blocking

196
00:07:50,099 --> 00:07:52,259
people who are causing harm on social

197
00:07:52,259 --> 00:07:53,220
media

198
00:07:53,220 --> 00:07:55,979
participants differed on other points

199
00:07:55,979 --> 00:07:58,020
such as whether or not they make their

200
00:07:58,020 --> 00:07:59,699
social media accounts private or whether

201
00:07:59,699 --> 00:08:02,520
they would use a police app on a date

202
00:08:02,520 --> 00:08:04,740
this also shows the usefulness of going

203
00:08:04,740 --> 00:08:06,660
to a support group for advice because

204
00:08:06,660 --> 00:08:07,919
people can explain what security

205
00:08:07,919 --> 00:08:09,900
behaviors worked for them in their

206
00:08:09,900 --> 00:08:12,859
specific contexts

207
00:08:13,080 --> 00:08:15,240
we also have takeaways for advice

208
00:08:15,240 --> 00:08:18,120
sources so first communal learning can

209
00:08:18,120 --> 00:08:21,139
be effective as the reconfigure report

210
00:08:21,139 --> 00:08:24,000
wrote cyber security is more effective

211
00:08:24,000 --> 00:08:25,979
when it is communal discussing online

212
00:08:25,979 --> 00:08:27,840
threats and mitigations with members of

213
00:08:27,840 --> 00:08:29,580
a community makes it easier and less

214
00:08:29,580 --> 00:08:32,900
intimidating to take action

215
00:08:33,360 --> 00:08:36,360
we also note that advice sources in

216
00:08:36,360 --> 00:08:38,760
person should provide emotional support

217
00:08:38,760 --> 00:08:40,200
with advice

218
00:08:40,200 --> 00:08:42,299
and also advice documents should

219
00:08:42,299 --> 00:08:44,339
communicate credibility and provide

220
00:08:44,339 --> 00:08:46,980
explanations

221
00:08:46,980 --> 00:08:49,320
we also have some takeaways for security

222
00:08:49,320 --> 00:08:51,620
research first

223
00:08:51,620 --> 00:08:53,899
intersectionality can be a useful animal

224
00:08:53,899 --> 00:08:56,480
analytical framework in usable security

225
00:08:56,480 --> 00:08:58,680
particularly when researchers want to

226
00:08:58,680 --> 00:08:59,880
understand the most vulnerable

227
00:08:59,880 --> 00:09:02,700
communities in a specific context

228
00:09:02,700 --> 00:09:05,279
and also we note that security is not

229
00:09:05,279 --> 00:09:09,439
just a personal responsibility

230
00:09:10,080 --> 00:09:12,779
advice has limitations for what an

231
00:09:12,779 --> 00:09:14,820
individual can change for example

232
00:09:14,820 --> 00:09:16,800
individual can't necessarily get rid of

233
00:09:16,800 --> 00:09:19,320
all the stigma in their culture their

234
00:09:19,320 --> 00:09:21,980
communities and their institutions

235
00:09:21,980 --> 00:09:24,120
and this is why

236
00:09:24,120 --> 00:09:26,519
legislative and platform policy changes

237
00:09:26,519 --> 00:09:27,899
are needed to protect the queer

238
00:09:27,899 --> 00:09:29,279
community

239
00:09:29,279 --> 00:09:32,160
and I go into examples on each of these

240
00:09:32,160 --> 00:09:35,000
in the paper

241
00:09:36,480 --> 00:09:38,220
just to conclude

242
00:09:38,220 --> 00:09:39,839
in this project we studied

243
00:09:39,839 --> 00:09:42,480
queer-specific online security privacy

244
00:09:42,480 --> 00:09:44,160
and safety advice through interviews

245
00:09:44,160 --> 00:09:46,560
with a diverse set of participants and

246
00:09:46,560 --> 00:09:49,080
some of our key takeaways include that

247
00:09:49,080 --> 00:09:50,640
intersectional identities affect

248
00:09:50,640 --> 00:09:52,740
people's options for security safety and

249
00:09:52,740 --> 00:09:54,300
privacy behaviors

250
00:09:54,300 --> 00:09:57,180
and also security advice cannot be one

251
00:09:57,180 --> 00:09:59,160
size fits all

252
00:09:59,160 --> 00:10:02,279
thank you again to my collaborators uh

253
00:10:02,279 --> 00:10:03,839
for working on this with me and also

254
00:10:03,839 --> 00:10:06,300
thank you for listening and I'm happy to

255
00:10:06,300 --> 00:10:08,820
take any questions during the Q a and

256
00:10:08,820 --> 00:10:10,560
also by email

257
00:10:10,560 --> 00:10:13,040
thanks

