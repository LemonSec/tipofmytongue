1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:10,160 --> 00:00:12,780
my name is Tim and that's the title of

3
00:00:12,780 --> 00:00:13,799
my paper

4
00:00:13,799 --> 00:00:17,460
so at the core of this contribution is a

5
00:00:17,460 --> 00:00:19,980
secure aggregation protocol what we're

6
00:00:19,980 --> 00:00:22,680
trying to do is add together a bunch of

7
00:00:22,680 --> 00:00:25,460
distributed vectors we can suppose that

8
00:00:25,460 --> 00:00:28,859
we have n participants in a Federated

9
00:00:28,859 --> 00:00:31,500
learning protocol and they would like to

10
00:00:31,500 --> 00:00:33,660
add together their their n Vector so

11
00:00:33,660 --> 00:00:35,880
we're imagining one vector per per

12
00:00:35,880 --> 00:00:37,860
participant

13
00:00:37,860 --> 00:00:39,960
um we also imagine that these vectors

14
00:00:39,960 --> 00:00:42,180
have K elements and that K can get very

15
00:00:42,180 --> 00:00:44,520
very large if we're trying to use a

16
00:00:44,520 --> 00:00:45,660
protocol like this for the sake of

17
00:00:45,660 --> 00:00:46,800
Federated learning we're trying to

18
00:00:46,800 --> 00:00:50,460
Aggregate gradients and gradients as you

19
00:00:50,460 --> 00:00:52,320
all know can be very very large with

20
00:00:52,320 --> 00:00:55,739
millions of potential elements now we

21
00:00:55,739 --> 00:00:57,120
want to design a protocol to solve this

22
00:00:57,120 --> 00:00:58,860
problem and we want to do that in such a

23
00:00:58,860 --> 00:01:01,199
way that all of the input vectors remain

24
00:01:01,199 --> 00:01:04,500
private to malicious servers and

25
00:01:04,500 --> 00:01:06,299
malicious server if we choose to use one

26
00:01:06,299 --> 00:01:09,240
and the clients themselves so at the end

27
00:01:09,240 --> 00:01:11,760
of the protocol only the individual who

28
00:01:11,760 --> 00:01:13,619
owns each Vector should know what that

29
00:01:13,619 --> 00:01:16,020
Vector is now this problem has been

30
00:01:16,020 --> 00:01:17,939
solved before the naive solution uses

31
00:01:17,939 --> 00:01:20,220
additive homomorphic secret sharing and

32
00:01:20,220 --> 00:01:23,159
has a communication cost of n times K

33
00:01:23,159 --> 00:01:25,320
the state of the art as cited below

34
00:01:25,320 --> 00:01:27,420
reduces that communication cost to n

35
00:01:27,420 --> 00:01:28,619
plus k

36
00:01:28,619 --> 00:01:30,780
that said that that state-of-the-art

37
00:01:30,780 --> 00:01:33,840
protocol does have a fair concrete or a

38
00:01:33,840 --> 00:01:35,159
fair amount of overhead that goes along

39
00:01:35,159 --> 00:01:37,140
with it especially in the case of

40
00:01:37,140 --> 00:01:39,360
dropped out parties so the the question

41
00:01:39,360 --> 00:01:41,579
that we asked is we want to be doing

42
00:01:41,579 --> 00:01:44,540
differentially private analysis anyway

43
00:01:44,540 --> 00:01:48,240
if we assume that our protocol will be

44
00:01:48,240 --> 00:01:50,100
differentially private from the get-go

45
00:01:50,100 --> 00:01:51,659
can we use the fact that we're going to

46
00:01:51,659 --> 00:01:53,100
be adding noise to the secure

47
00:01:53,100 --> 00:01:55,619
aggregation protocol to improve its

48
00:01:55,619 --> 00:01:57,240
concrete performance and we find out

49
00:01:57,240 --> 00:02:00,119
that's true if we add the noise to our

50
00:02:00,119 --> 00:02:01,920
secure aggregation protocol using the

51
00:02:01,920 --> 00:02:03,720
learning with errors problem

52
00:02:03,720 --> 00:02:05,399
uh for those of you who don't know

53
00:02:05,399 --> 00:02:07,940
differential privacy is an information

54
00:02:07,940 --> 00:02:09,899
provides an information theoretic

55
00:02:09,899 --> 00:02:12,540
guarantee to a mechanism that it doesn't

56
00:02:12,540 --> 00:02:14,879
reveal information about an individual

57
00:02:14,879 --> 00:02:16,319
so

58
00:02:16,319 --> 00:02:18,300
um a little bit more specifically the

59
00:02:18,300 --> 00:02:20,700
idea is that if we call a mechanism on

60
00:02:20,700 --> 00:02:22,040
two different

61
00:02:22,040 --> 00:02:23,940
data sets that are only different

62
00:02:23,940 --> 00:02:26,099
between that the only difference between

63
00:02:26,099 --> 00:02:27,720
the two of them is the data of one

64
00:02:27,720 --> 00:02:29,580
individual the output of that mechanism

65
00:02:29,580 --> 00:02:31,640
should be just about the same

66
00:02:31,640 --> 00:02:34,860
and the way that for the sake of this

67
00:02:34,860 --> 00:02:36,000
presentation there's lots of ways that

68
00:02:36,000 --> 00:02:38,400
we can satisfy differential privacy but

69
00:02:38,400 --> 00:02:40,020
for secure aggregation the way that

70
00:02:40,020 --> 00:02:41,160
we're going to do it is with additive

71
00:02:41,160 --> 00:02:43,560
noise so we can imagine that we have a

72
00:02:43,560 --> 00:02:46,140
queer response in this case the sum of

73
00:02:46,140 --> 00:02:49,080
some vectors and we'd like to make that

74
00:02:49,080 --> 00:02:50,340
differentially private so what we'll do

75
00:02:50,340 --> 00:02:51,180
is we're going to add some noise

76
00:02:51,180 --> 00:02:53,340
specifically gaussian distributed noise

77
00:02:53,340 --> 00:02:54,900
and that will give us a differentially

78
00:02:54,900 --> 00:02:56,400
private result

79
00:02:56,400 --> 00:02:57,540
now the way that we're going to be

80
00:02:57,540 --> 00:03:00,239
adding that noise in this contribution

81
00:03:00,239 --> 00:03:01,620
is using the learning with errors

82
00:03:01,620 --> 00:03:03,540
problem so the learning with errors

83
00:03:03,540 --> 00:03:07,080
problem is a Quantum secure computation

84
00:03:07,080 --> 00:03:09,420
problem revolving around some linear

85
00:03:09,420 --> 00:03:11,940
algebra the setup is as follows we'll

86
00:03:11,940 --> 00:03:15,180
have a public uniformly randomly

87
00:03:15,180 --> 00:03:17,519
distributed Matrix a the elements of

88
00:03:17,519 --> 00:03:18,959
which are going to be finite field

89
00:03:18,959 --> 00:03:20,180
elements

90
00:03:20,180 --> 00:03:23,760
and a secret Vector s which is

91
00:03:23,760 --> 00:03:28,680
relatively short and a a non-uniformly

92
00:03:28,680 --> 00:03:31,379
distributed small amount of error and

93
00:03:31,379 --> 00:03:33,000
we're going to apply the operations a

94
00:03:33,000 --> 00:03:35,819
times S Plus e to get ourselves a vector

95
00:03:35,819 --> 00:03:38,640
B and the learning with errors a

96
00:03:38,640 --> 00:03:40,260
hardness assumption effectively says

97
00:03:40,260 --> 00:03:42,599
that if you are given a and you are

98
00:03:42,599 --> 00:03:44,519
given B that we can't find either of

99
00:03:44,519 --> 00:03:46,700
these two components in the middle so

100
00:03:46,700 --> 00:03:48,900
importantly here recovering s is

101
00:03:48,900 --> 00:03:50,280
difficult

102
00:03:50,280 --> 00:03:52,739
uh the reason why this is beneficial for

103
00:03:52,739 --> 00:03:54,659
a secure aggregation protocol such as

104
00:03:54,659 --> 00:03:56,819
the one I'm about to present is that s

105
00:03:56,819 --> 00:03:59,400
is very low dimensional and B is not

106
00:03:59,400 --> 00:04:01,200
only High dimensional but it appears to

107
00:04:01,200 --> 00:04:03,659
be uniformly random so the intuition

108
00:04:03,659 --> 00:04:04,980
behind this protocol is that we're going

109
00:04:04,980 --> 00:04:08,760
to be using B vectors as one-time pads

110
00:04:08,760 --> 00:04:10,439
for the very long vectors that we'd like

111
00:04:10,439 --> 00:04:12,060
to aggregate with a secure aggregation

112
00:04:12,060 --> 00:04:15,000
protocol then we can pretty much reduce

113
00:04:15,000 --> 00:04:16,918
the problem to aggregation of much

114
00:04:16,918 --> 00:04:19,260
shorter vectors and take advantage of

115
00:04:19,260 --> 00:04:20,459
the performance gains that come with

116
00:04:20,459 --> 00:04:21,600
that

117
00:04:21,600 --> 00:04:24,000
uh the protocol in a nutshell is well

118
00:04:24,000 --> 00:04:26,880
sort of doing what I just said but the

119
00:04:26,880 --> 00:04:28,139
way that that's going to work is that

120
00:04:28,139 --> 00:04:29,580
clients will use the learning with

121
00:04:29,580 --> 00:04:32,240
errors problem to encrypt their vectors

122
00:04:32,240 --> 00:04:35,340
and they will send those to a server now

123
00:04:35,340 --> 00:04:37,080
the the protocol we want it to be secure

124
00:04:37,080 --> 00:04:39,000
against a malicious server at least with

125
00:04:39,000 --> 00:04:40,979
respect to confidentiality so we don't

126
00:04:40,979 --> 00:04:43,620
necessarily trust this server the second

127
00:04:43,620 --> 00:04:44,639
thing that's going to happen is the

128
00:04:44,639 --> 00:04:47,160
clients will perform a secure

129
00:04:47,160 --> 00:04:49,080
multi-party computation protocol that

130
00:04:49,080 --> 00:04:50,699
Aggregates those low dimensional s

131
00:04:50,699 --> 00:04:53,820
vectors and finally the server is gonna

132
00:04:53,820 --> 00:04:55,919
the server will have the sum after that

133
00:04:55,919 --> 00:04:57,479
step two so they'll take the sum they

134
00:04:57,479 --> 00:04:59,280
receive in step two and the encrypted

135
00:04:59,280 --> 00:05:01,199
vectors they receive in step one to

136
00:05:01,199 --> 00:05:04,880
decrypt the sum of all of the vectors

137
00:05:04,880 --> 00:05:06,900
in a little bit more detail the way that

138
00:05:06,900 --> 00:05:08,960
this is going to work is

139
00:05:08,960 --> 00:05:11,820
the parties will agree on a public

140
00:05:11,820 --> 00:05:14,040
Matrix that they're all using so we can

141
00:05:14,040 --> 00:05:15,660
assume that every party is using the

142
00:05:15,660 --> 00:05:18,419
same Matrix a they will generate their

143
00:05:18,419 --> 00:05:20,460
own secret secret short vectors and

144
00:05:20,460 --> 00:05:22,560
their own secret error vectors

145
00:05:22,560 --> 00:05:25,199
um then they'll compute the the lwe

146
00:05:25,199 --> 00:05:27,840
problem here to generate a uniformly

147
00:05:27,840 --> 00:05:29,580
distributed random Vector which they can

148
00:05:29,580 --> 00:05:31,199
use as a one-time pad for their secret

149
00:05:31,199 --> 00:05:32,160
input

150
00:05:32,160 --> 00:05:35,100
given the perfect secrecy of one-time

151
00:05:35,100 --> 00:05:37,320
padding we can now send the secret input

152
00:05:37,320 --> 00:05:38,820
to a data curator whom we don't

153
00:05:38,820 --> 00:05:41,659
necessarily Trust

154
00:05:42,080 --> 00:05:44,340
after doing that we're going to be

155
00:05:44,340 --> 00:05:48,180
performing an a more primitive additive

156
00:05:48,180 --> 00:05:50,940
homomorphic secret sharing protocol so

157
00:05:50,940 --> 00:05:52,979
the idea here is that each party is

158
00:05:52,979 --> 00:05:54,360
going to have their own secret Vector

159
00:05:54,360 --> 00:05:56,580
we'd like to aggregate all of those and

160
00:05:56,580 --> 00:05:58,259
we can use some sort of protocol for

161
00:05:58,259 --> 00:06:00,419
that for the sake of our experiments

162
00:06:00,419 --> 00:06:05,900
what we do is use a protocol based on

163
00:06:05,900 --> 00:06:09,720
packed secret sharing so the pashmir

164
00:06:09,720 --> 00:06:10,860
secret sharing it's a relatively

165
00:06:10,860 --> 00:06:12,300
primitive protocol But ultimately it's

166
00:06:12,300 --> 00:06:13,860
going to give us the sum of the S

167
00:06:13,860 --> 00:06:15,479
vectors that we can send to our data

168
00:06:15,479 --> 00:06:17,699
curator

169
00:06:17,699 --> 00:06:19,199
um and then finally now the data curator

170
00:06:19,199 --> 00:06:21,259
will have everything it needs to perform

171
00:06:21,259 --> 00:06:24,660
decryption what we can do is they will

172
00:06:24,660 --> 00:06:26,220
sum they will sum their Mass vectors

173
00:06:26,220 --> 00:06:27,020
together

174
00:06:27,020 --> 00:06:29,819
and subtract from that the public Matrix

175
00:06:29,819 --> 00:06:34,020
a times the sum of the S vectors and in

176
00:06:34,020 --> 00:06:36,600
doing so we pretty much cancel out the

177
00:06:36,600 --> 00:06:38,039
the blue and red parts of this protocol

178
00:06:38,039 --> 00:06:39,960
and end up with the sum of the secret

179
00:06:39,960 --> 00:06:44,220
inputs plus the sum of the error term

180
00:06:44,220 --> 00:06:45,900
now I mentioned that the error term is

181
00:06:45,900 --> 00:06:47,460
going to be used to satisfy differential

182
00:06:47,460 --> 00:06:50,520
privacy the way that we can go about

183
00:06:50,520 --> 00:06:53,160
doing this is by drawing the noise from

184
00:06:53,160 --> 00:06:55,199
a gaussian distribution relying on the

185
00:06:55,199 --> 00:06:56,699
fact that the sum of gaussian

186
00:06:56,699 --> 00:06:58,919
distributed random variables is also a

187
00:06:58,919 --> 00:07:01,139
gaussian distributed random variable so

188
00:07:01,139 --> 00:07:03,300
as long as we ensure that the honest

189
00:07:03,300 --> 00:07:05,300
parties are

190
00:07:05,300 --> 00:07:08,699
using gaussian noise for their for their

191
00:07:08,699 --> 00:07:11,460
learning with errors error term then we

192
00:07:11,460 --> 00:07:13,319
can parameterize that in such a way that

193
00:07:13,319 --> 00:07:16,560
the sum of all of those vectors

194
00:07:16,560 --> 00:07:19,139
adds up to gaussian distributed noise

195
00:07:19,139 --> 00:07:20,759
for the gaussian mechanism in

196
00:07:20,759 --> 00:07:23,599
differential privacy

197
00:07:23,639 --> 00:07:25,319
that's the the description of the

198
00:07:25,319 --> 00:07:27,360
protocol in a nutshell for the sake of

199
00:07:27,360 --> 00:07:30,180
evaluation we evaluate the communication

200
00:07:30,180 --> 00:07:32,400
and computation complexity we do a

201
00:07:32,400 --> 00:07:35,880
theoretical or a analytical analysis in

202
00:07:35,880 --> 00:07:40,819
the paper what we find is that the the

203
00:07:40,819 --> 00:07:43,380
growth is pretty much the same as what

204
00:07:43,380 --> 00:07:45,960
you'd see in the previous state of the

205
00:07:45,960 --> 00:07:47,720
Arts over here I'm going to focus on

206
00:07:47,720 --> 00:07:50,400
concrete performance for the sake of

207
00:07:50,400 --> 00:07:52,199
communication we look at the expansion

208
00:07:52,199 --> 00:07:54,419
factor of our protocol now what that

209
00:07:54,419 --> 00:07:56,180
means is just how much more

210
00:07:56,180 --> 00:07:58,500
communication this protocol is going to

211
00:07:58,500 --> 00:07:59,300
require

212
00:07:59,300 --> 00:08:02,940
when compared to using a trusted third

213
00:08:02,940 --> 00:08:05,460
party to perform secure aggregation so

214
00:08:05,460 --> 00:08:07,380
we can assume that we need to send our

215
00:08:07,380 --> 00:08:08,759
Vector that every party is going to need

216
00:08:08,759 --> 00:08:10,380
to send their Vector somewhere this

217
00:08:10,380 --> 00:08:12,800
metric is pretty much how much more

218
00:08:12,800 --> 00:08:16,099
communication does each party need to do

219
00:08:16,099 --> 00:08:18,720
uh Beyond just doing that and what we

220
00:08:18,720 --> 00:08:21,120
find is that our expansion factor is

221
00:08:21,120 --> 00:08:22,740
nearly optimal and it demonstrates that

222
00:08:22,740 --> 00:08:24,000
we have very little overhead in this

223
00:08:24,000 --> 00:08:26,340
protocol the reason why our expansion

224
00:08:26,340 --> 00:08:29,160
factor is hovering around 1.6 and

225
00:08:29,160 --> 00:08:30,599
largely dependent on the number of

226
00:08:30,599 --> 00:08:33,000
clients that we have in our protocol

227
00:08:33,000 --> 00:08:34,979
rather than the vector size has to do

228
00:08:34,979 --> 00:08:36,659
with the fact that for any secure

229
00:08:36,659 --> 00:08:38,458
multi-party computation-based solution

230
00:08:38,458 --> 00:08:40,440
to this problem you need to encode your

231
00:08:40,440 --> 00:08:43,020
vectors as finite field elements I can

232
00:08:43,020 --> 00:08:44,399
also point out that we have lower

233
00:08:44,399 --> 00:08:46,260
expansion Factor here and therefore less

234
00:08:46,260 --> 00:08:48,540
communication cost than the previous

235
00:08:48,540 --> 00:08:50,399
state of the art

236
00:08:50,399 --> 00:08:53,459
in terms of computation performance

237
00:08:53,459 --> 00:08:57,720
analysis what we do is we simulated the

238
00:08:57,720 --> 00:09:00,240
protocol both on the client side and on

239
00:09:00,240 --> 00:09:02,279
the server side and then just you know

240
00:09:02,279 --> 00:09:04,440
calculated how long each each bit of

241
00:09:04,440 --> 00:09:06,240
communicate each bit of computation took

242
00:09:06,240 --> 00:09:08,519
and we also find that the protocol

243
00:09:08,519 --> 00:09:10,980
performs very very well here so

244
00:09:10,980 --> 00:09:13,080
regardless of vector size for the sake

245
00:09:13,080 --> 00:09:15,779
of client it's taking less than a third

246
00:09:15,779 --> 00:09:18,860
of a second to execute this protocol

247
00:09:18,860 --> 00:09:24,000
and we see that the growth of protocol

248
00:09:24,000 --> 00:09:27,120
of client time happens linearly with the

249
00:09:27,120 --> 00:09:28,860
size of the vector which I think we're

250
00:09:28,860 --> 00:09:31,140
hoping for that's the same behavior as

251
00:09:31,140 --> 00:09:33,140
you would see in the ideal functionality

252
00:09:33,140 --> 00:09:36,300
on the server side we see similarly

253
00:09:36,300 --> 00:09:39,120
similarly fast performance for all

254
00:09:39,120 --> 00:09:40,980
configurations that we tested we're

255
00:09:40,980 --> 00:09:45,600
looking at less than 10 seconds of less

256
00:09:45,600 --> 00:09:47,459
than 10 seconds of server runtime though

257
00:09:47,459 --> 00:09:49,140
these results are stratified by whether

258
00:09:49,140 --> 00:09:50,940
or not we expect participants to be

259
00:09:50,940 --> 00:09:53,100
dropping out we can recover from

260
00:09:53,100 --> 00:09:55,500
dropouts using this protocol the way

261
00:09:55,500 --> 00:09:58,440
that happens is is involving the

262
00:09:58,440 --> 00:09:59,880
primitive

263
00:09:59,880 --> 00:10:01,980
the secure aggregation protocol that we

264
00:10:01,980 --> 00:10:05,880
use for the S vectors and that slowdown

265
00:10:05,880 --> 00:10:07,560
happens on the server side but

266
00:10:07,560 --> 00:10:09,660
nevertheless in all configurations

267
00:10:09,660 --> 00:10:11,220
tested we're still looking at less than

268
00:10:11,220 --> 00:10:14,880
10 seconds of aggregation time

269
00:10:14,880 --> 00:10:16,620
and compared to the state of the art

270
00:10:16,620 --> 00:10:17,700
we're looking at nearly an order of

271
00:10:17,700 --> 00:10:21,120
magnitude Improvement for 30 dropouts

272
00:10:21,120 --> 00:10:23,580
500 clients and vectors of a hundred

273
00:10:23,580 --> 00:10:26,760
thousand elements the previous state of

274
00:10:26,760 --> 00:10:28,140
the art has

275
00:10:28,140 --> 00:10:30,899
about a second of client run time and

276
00:10:30,899 --> 00:10:34,440
143 seconds of server time

277
00:10:34,440 --> 00:10:36,420
I think that concludes what I have to

278
00:10:36,420 --> 00:10:37,680
say on the protocol and I'm happy to

279
00:10:37,680 --> 00:10:40,339
take questions now

