1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:08,720 --> 00:00:11,700
s I'm a PhD student at the University of

3
00:00:11,700 --> 00:00:13,740
Washington advised by Francis rosener

4
00:00:13,740 --> 00:00:15,900
and tarayoshikono today I'm going to

5
00:00:15,900 --> 00:00:16,800
talk about some work we did in

6
00:00:16,800 --> 00:00:18,119
collaboration with the legal scholar

7
00:00:18,119 --> 00:00:20,279
Anita Alim an electronic monitoring

8
00:00:20,279 --> 00:00:22,140
smartphone apps and first I'm going to

9
00:00:22,140 --> 00:00:25,019
give an example to motivate how someone

10
00:00:25,019 --> 00:00:28,500
might come to use one of these apps

11
00:00:28,500 --> 00:00:30,599
so imagine you're at a protest you're

12
00:00:30,599 --> 00:00:32,759
having a good time exercising your your

13
00:00:32,759 --> 00:00:34,440
right to organize in the U.S and then

14
00:00:34,440 --> 00:00:36,000
someone standing next to you throw

15
00:00:36,000 --> 00:00:37,980
something at the police say a rock or

16
00:00:37,980 --> 00:00:40,079
like a Pepsi or something right and then

17
00:00:40,079 --> 00:00:41,579
the police all of a sudden rush over to

18
00:00:41,579 --> 00:00:43,559
you grab you and five other people near

19
00:00:43,559 --> 00:00:45,300
you right and you're arrested and you're

20
00:00:45,300 --> 00:00:47,700
taken to jail right and within 24 hours

21
00:00:47,700 --> 00:00:49,260
you have your arraignment some court

22
00:00:49,260 --> 00:00:50,579
date you go before a judge and you say

23
00:00:50,579 --> 00:00:51,780
to the judge you know I didn't do this

24
00:00:51,780 --> 00:00:54,300
it wasn't me somebody else I didn't I

25
00:00:54,300 --> 00:00:56,340
didn't I didn't have a Pepsi that day

26
00:00:56,340 --> 00:00:58,140
and the judge says well you know one of

27
00:00:58,140 --> 00:00:59,399
the police officers said it was you we

28
00:00:59,399 --> 00:01:00,719
got to look at the body camera footage

29
00:01:00,719 --> 00:01:02,940
your court dates in a month and so I'll

30
00:01:02,940 --> 00:01:05,159
release you now into your court date but

31
00:01:05,159 --> 00:01:06,479
instead of the traditional cash bill

32
00:01:06,479 --> 00:01:08,640
that we used to have say it would be ten

33
00:01:08,640 --> 00:01:10,200
thousand dollars we're giving you an app

34
00:01:10,200 --> 00:01:11,820
and you have to install this app on your

35
00:01:11,820 --> 00:01:14,100
phone and you have to do check-ins and

36
00:01:14,100 --> 00:01:15,420
you have to have a good relationship

37
00:01:15,420 --> 00:01:17,280
with your your release supervisor and if

38
00:01:17,280 --> 00:01:18,900
you fail to the check-ins properly you

39
00:01:18,900 --> 00:01:20,040
could be incarcerated and brought back

40
00:01:20,040 --> 00:01:21,840
to jail so do you accept these

41
00:01:21,840 --> 00:01:23,700
conditions and of course you as the

42
00:01:23,700 --> 00:01:24,960
security and privacy researcher you're

43
00:01:24,960 --> 00:01:25,979
very concerned about this you're like

44
00:01:25,979 --> 00:01:27,420
what is this app doing you know what day

45
00:01:27,420 --> 00:01:28,920
what day does it collect who does is in

46
00:01:28,920 --> 00:01:30,360
the data too but you you of course

47
00:01:30,360 --> 00:01:32,400
accept and you're released

48
00:01:32,400 --> 00:01:34,320
and these apps are real they're a new

49
00:01:34,320 --> 00:01:36,720
form of electronic monitoring electronic

50
00:01:36,720 --> 00:01:38,040
monitoring is a subset of Community

51
00:01:38,040 --> 00:01:40,380
Supervision Community Supervision is

52
00:01:40,380 --> 00:01:42,720
either an alternative to be incarcerated

53
00:01:42,720 --> 00:01:44,939
or after someone is released from from

54
00:01:44,939 --> 00:01:46,140
being incarcerated so for example

55
00:01:46,140 --> 00:01:48,780
probation parole released from immigrant

56
00:01:48,780 --> 00:01:50,759
or Juvenile Detention and in this

57
00:01:50,759 --> 00:01:52,020
example I mentioned released from

58
00:01:52,020 --> 00:01:54,119
pre-trial detention

59
00:01:54,119 --> 00:01:55,439
and normally people who are under

60
00:01:55,439 --> 00:01:56,880
Community Supervision they must comply

61
00:01:56,880 --> 00:01:59,159
with several conditions such as curfews

62
00:01:59,159 --> 00:02:02,100
visits drug tests supervision fees often

63
00:02:02,100 --> 00:02:03,299
people who under a community supervision

64
00:02:03,299 --> 00:02:04,820
have to make fees for their supervision

65
00:02:04,820 --> 00:02:07,140
and historically this this technology

66
00:02:07,140 --> 00:02:09,060
used for electronic monitoring has been

67
00:02:09,060 --> 00:02:10,860
ankle monitors and Ankle monitors are

68
00:02:10,860 --> 00:02:12,660
still using their uses actually still

69
00:02:12,660 --> 00:02:14,459
growing but in addition to ankle monitor

70
00:02:14,459 --> 00:02:16,020
there are smartphone apps that are being

71
00:02:16,020 --> 00:02:18,420
rolled out for people under Community

72
00:02:18,420 --> 00:02:20,459
Supervision and it's really hard to get

73
00:02:20,459 --> 00:02:22,860
numbers on these specifically app usage

74
00:02:22,860 --> 00:02:25,500
but the biggest public numbers we could

75
00:02:25,500 --> 00:02:27,420
find were usage by ice for immigration

76
00:02:27,420 --> 00:02:29,220
detection so right now around 100 000

77
00:02:29,220 --> 00:02:30,959
people are using these smartphone apps

78
00:02:30,959 --> 00:02:32,220
after being released from immigration

79
00:02:32,220 --> 00:02:34,080
detention the second largest number we

80
00:02:34,080 --> 00:02:36,360
could find publicly available was being

81
00:02:36,360 --> 00:02:37,980
used for probation by Virginia state

82
00:02:37,980 --> 00:02:40,020
prisons around over a little bit over 10

83
00:02:40,020 --> 00:02:40,920
000 people

84
00:02:40,920 --> 00:02:42,480
right and so these apps are primarily

85
00:02:42,480 --> 00:02:44,280
used for checking in with one supervisor

86
00:02:44,280 --> 00:02:46,560
as I mentioned uh this could either be

87
00:02:46,560 --> 00:02:48,959
in lieu or in addition to traditional

88
00:02:48,959 --> 00:02:50,340
in-person meetings that happen with the

89
00:02:50,340 --> 00:02:52,319
supervisor under Community Supervision

90
00:02:52,319 --> 00:02:54,000
and these check-ins might require you to

91
00:02:54,000 --> 00:02:55,860
have your location enabled you might ask

92
00:02:55,860 --> 00:02:57,180
there might be some face and voice

93
00:02:57,180 --> 00:02:59,819
recognition involved and if you're part

94
00:02:59,819 --> 00:03:01,260
of a drug some drug treatment program

95
00:03:01,260 --> 00:03:02,700
you might have to use like a Bluetooth

96
00:03:02,700 --> 00:03:04,560
breathalyzer for example as part of this

97
00:03:04,560 --> 00:03:06,599
this these check-ins and so there's an

98
00:03:06,599 --> 00:03:07,980
image on the left that shows an example

99
00:03:07,980 --> 00:03:09,480
of what a check-in looks like for one of

100
00:03:09,480 --> 00:03:10,980
these apps that we looked at so this

101
00:03:10,980 --> 00:03:12,780
check-in specifically requires you hold

102
00:03:12,780 --> 00:03:14,220
the phone in front of you you have your

103
00:03:14,220 --> 00:03:16,560
front camera on you read off a series of

104
00:03:16,560 --> 00:03:18,360
randomly generated numbers and you have

105
00:03:18,360 --> 00:03:19,620
to do that within a certain period of

106
00:03:19,620 --> 00:03:21,420
time right so this one example of what a

107
00:03:21,420 --> 00:03:22,700
check-in could look at

108
00:03:22,700 --> 00:03:24,659
and as I mentioned before Phil you

109
00:03:24,659 --> 00:03:25,980
should successfully check in can lead to

110
00:03:25,980 --> 00:03:27,480
incarceration really depends a lot on

111
00:03:27,480 --> 00:03:29,220
your your supervisor sometimes it might

112
00:03:29,220 --> 00:03:30,540
just take one failure sometimes it might

113
00:03:30,540 --> 00:03:33,420
take multiple but yeah this this could

114
00:03:33,420 --> 00:03:34,620
lead to your you're going back to jail

115
00:03:34,620 --> 00:03:36,420
so this is a you can you can kind of

116
00:03:36,420 --> 00:03:37,560
recognize that this might be a problem

117
00:03:37,560 --> 00:03:39,360
here there's these high stake apps can

118
00:03:39,360 --> 00:03:41,459
result in you being incarcerated that

119
00:03:41,459 --> 00:03:43,140
have been audited to evaluate their data

120
00:03:43,140 --> 00:03:45,540
practices or what privacy Miss they may

121
00:03:45,540 --> 00:03:47,099
introduce to the people who use them

122
00:03:47,099 --> 00:03:48,780
right and so based on this we had

123
00:03:48,780 --> 00:03:50,280
several research questions about these

124
00:03:50,280 --> 00:03:51,659
apps

125
00:03:51,659 --> 00:03:54,060
primarily first what are the experiences

126
00:03:54,060 --> 00:03:55,799
and concerns that people coerced to use

127
00:03:55,799 --> 00:03:57,299
these apps and we we answered this

128
00:03:57,299 --> 00:03:58,500
research question through qualitative

129
00:03:58,500 --> 00:04:00,239
analysis of qualitative analysis of

130
00:04:00,239 --> 00:04:03,379
reviews and the Google Play Store

131
00:04:04,200 --> 00:04:05,700
secondly we want to know what the

132
00:04:05,700 --> 00:04:07,440
Privacy related technical properties of

133
00:04:07,440 --> 00:04:09,480
these apps were and so to answer this

134
00:04:09,480 --> 00:04:11,040
question we did some static and limited

135
00:04:11,040 --> 00:04:12,599
Dynamic analysis of these apps we found

136
00:04:12,599 --> 00:04:14,220
16 Android apps in total that are

137
00:04:14,220 --> 00:04:16,139
currently being used for electronic

138
00:04:16,139 --> 00:04:17,880
monitoring we also did a case study of

139
00:04:17,880 --> 00:04:20,339
the least and most privileged apps I say

140
00:04:20,339 --> 00:04:22,620
limited Dynamic analysis because to use

141
00:04:22,620 --> 00:04:24,000
these apps you need to get credentials

142
00:04:24,000 --> 00:04:25,800
to log into them and those credentials

143
00:04:25,800 --> 00:04:27,180
come from your supervisor so since we

144
00:04:27,180 --> 00:04:28,259
weren't actually using the apps we

145
00:04:28,259 --> 00:04:30,120
didn't have credential credentials to

146
00:04:30,120 --> 00:04:31,860
log into them so all of our analysis is

147
00:04:31,860 --> 00:04:33,360
pre-authentication we still have some

148
00:04:33,360 --> 00:04:34,740
interesting findings that I'll talk

149
00:04:34,740 --> 00:04:36,840
about a bit later

150
00:04:36,840 --> 00:04:39,360
uh do these apps privacy policies align

151
00:04:39,360 --> 00:04:41,639
with our observations of what we saw in

152
00:04:41,639 --> 00:04:42,900
our technical analysis is that

153
00:04:42,900 --> 00:04:44,340
reflecting in the Privacy policies and

154
00:04:44,340 --> 00:04:45,240
of course we answered this question

155
00:04:45,240 --> 00:04:46,860
through qualitative analysis of the

156
00:04:46,860 --> 00:04:49,020
app's privacy policies and what legal

157
00:04:49,020 --> 00:04:50,880
protections if any exist for people

158
00:04:50,880 --> 00:04:52,680
under electronic monitoring and we

159
00:04:52,680 --> 00:04:53,880
collaborated with a legal scholar to

160
00:04:53,880 --> 00:04:56,759
answer this question because the time is

161
00:04:56,759 --> 00:04:58,139
limited today I'm going to focus focus

162
00:04:58,139 --> 00:05:00,000
on the first research question and the

163
00:05:00,000 --> 00:05:01,320
case studies from the second research

164
00:05:01,320 --> 00:05:03,000
question but of course for more details

165
00:05:03,000 --> 00:05:05,040
you can you can see the paper

166
00:05:05,040 --> 00:05:06,240
so before that some ethical

167
00:05:06,240 --> 00:05:08,400
considerations right we saw IRB approval

168
00:05:08,400 --> 00:05:10,500
for the study and we redeemed exempt but

169
00:05:10,500 --> 00:05:11,880
despite that we follow best practices

170
00:05:11,880 --> 00:05:13,860
for connecting research with publicly

171
00:05:13,860 --> 00:05:16,199
available information

172
00:05:16,199 --> 00:05:18,060
when we started analyzing the Privacy

173
00:05:18,060 --> 00:05:19,560
policies for these apps we noticed that

174
00:05:19,560 --> 00:05:21,780
7 out of the 16 didn't have adequate

175
00:05:21,780 --> 00:05:23,220
privacy policies up that followed Google

176
00:05:23,220 --> 00:05:25,259
Play Store's policies so either the

177
00:05:25,259 --> 00:05:27,360
privacy policy didn't exist there or the

178
00:05:27,360 --> 00:05:28,979
Privacy policies didn't mention the apps

179
00:05:28,979 --> 00:05:30,840
at all and so we reached out to these

180
00:05:30,840 --> 00:05:32,880
companies we notified them that we're

181
00:05:32,880 --> 00:05:34,139
going to let Google know in a month if

182
00:05:34,139 --> 00:05:35,340
they're in violation of these policies

183
00:05:35,340 --> 00:05:36,960
one of the companies have to be reached

184
00:05:36,960 --> 00:05:38,280
out correctly and added information

185
00:05:38,280 --> 00:05:39,780
about the apps into their policies but

186
00:05:39,780 --> 00:05:41,400
the rest didn't respond and we reached

187
00:05:41,400 --> 00:05:44,460
out to Google in early uh early summer

188
00:05:44,460 --> 00:05:45,900
so it's your results what are the

189
00:05:45,900 --> 00:05:47,340
experiences and concerns of people who

190
00:05:47,340 --> 00:05:49,080
are of course use these apps from

191
00:05:49,080 --> 00:05:51,000
analyzing the reviews a common issue

192
00:05:51,000 --> 00:05:52,500
that we found was that there are

193
00:05:52,500 --> 00:05:53,639
malfunctions with these apps that

194
00:05:53,639 --> 00:05:54,960
prevent people from successfully

195
00:05:54,960 --> 00:05:56,820
performing check-ins right and as I

196
00:05:56,820 --> 00:05:58,020
mentioned before the seconds are

197
00:05:58,020 --> 00:06:00,000
requirement of using these apps and

198
00:06:00,000 --> 00:06:01,440
these malfunctions were typically caused

199
00:06:01,440 --> 00:06:03,060
by failures and facial or voice

200
00:06:03,060 --> 00:06:05,220
recognition systems or location failures

201
00:06:05,220 --> 00:06:07,680
so for example people say when they

202
00:06:07,680 --> 00:06:08,940
wanted to do a check-in they were

203
00:06:08,940 --> 00:06:09,900
wearing a mass they had to take their

204
00:06:09,900 --> 00:06:11,880
mask off if they were wearing makeup

205
00:06:11,880 --> 00:06:13,320
sometimes the phone wouldn't recognize

206
00:06:13,320 --> 00:06:15,180
them similarly people mentioned just

207
00:06:15,180 --> 00:06:16,560
being asleep and then the phone's

208
00:06:16,560 --> 00:06:18,840
location I guess detection system was

209
00:06:18,840 --> 00:06:20,160
off and they were woken up in the middle

210
00:06:20,160 --> 00:06:21,479
of night by alarm saying that they'd

211
00:06:21,479 --> 00:06:22,919
gone outside of a zone that they were

212
00:06:22,919 --> 00:06:25,020
weren't supposed to be in

213
00:06:25,020 --> 00:06:27,300
uh similarly these apps cause disruption

214
00:06:27,300 --> 00:06:28,860
for people there were these loud alerts

215
00:06:28,860 --> 00:06:30,840
that overrid their phones volume

216
00:06:30,840 --> 00:06:32,400
settings and often set their volume to

217
00:06:32,400 --> 00:06:33,660
max even if they're wearing headphones

218
00:06:33,660 --> 00:06:35,699
now people talked about how these apps

219
00:06:35,699 --> 00:06:37,259
could consume significant battery in

220
00:06:37,259 --> 00:06:38,940
space one of the reviews said

221
00:06:38,940 --> 00:06:41,580
specifically that someone that that the

222
00:06:41,580 --> 00:06:43,199
app consumed battery on their phone so

223
00:06:43,199 --> 00:06:44,639
quickly that they had to buy an external

224
00:06:44,639 --> 00:06:46,080
battery pack and carry it around so that

225
00:06:46,080 --> 00:06:47,400
the phone wouldn't die and they wouldn't

226
00:06:47,400 --> 00:06:49,259
get in trouble and lastly the reviews

227
00:06:49,259 --> 00:06:50,819
mentioned that these apps calls

228
00:06:50,819 --> 00:06:52,380
operating system crashes and freezes

229
00:06:52,380 --> 00:06:54,360
which is particularly concerning as we

230
00:06:54,360 --> 00:06:56,580
know these One requirement of using

231
00:06:56,580 --> 00:06:58,020
these apps is that they're available all

232
00:06:58,020 --> 00:06:59,460
the time so that your supervisor can see

233
00:06:59,460 --> 00:07:01,020
what you're doing and if these apps

234
00:07:01,020 --> 00:07:02,639
themselves cause the phone to crash you

235
00:07:02,639 --> 00:07:06,500
could be setting people up for failure

236
00:07:07,979 --> 00:07:10,020
uh people describe a general sense of

237
00:07:10,020 --> 00:07:11,520
Injustice in some of the reviews I have

238
00:07:11,520 --> 00:07:12,840
one quote here that I'm going to read in

239
00:07:12,840 --> 00:07:14,580
full there's a lot more great quotes in

240
00:07:14,580 --> 00:07:15,600
the paper I hope you have a chance to

241
00:07:15,600 --> 00:07:17,520
look at it this person says I'm a drug

242
00:07:17,520 --> 00:07:19,199
court client in Phase five I've been in

243
00:07:19,199 --> 00:07:21,599
the program over a year done very well

244
00:07:21,599 --> 00:07:23,160
I'm worried about this app it does not

245
00:07:23,160 --> 00:07:24,599
work very well the developers should be

246
00:07:24,599 --> 00:07:25,860
ashamed of themselves this is my

247
00:07:25,860 --> 00:07:27,660
sobriety and freedom that's at stake

248
00:07:27,660 --> 00:07:30,000
this app has the ability to destroy all

249
00:07:30,000 --> 00:07:31,979
I've worked so hard for please fix it or

250
00:07:31,979 --> 00:07:33,900
takes it down your money is is not worth

251
00:07:33,900 --> 00:07:36,440
my freedom

252
00:07:37,620 --> 00:07:39,300
so now on to our case studies of the

253
00:07:39,300 --> 00:07:40,560
least and most privileged app and what

254
00:07:40,560 --> 00:07:42,479
are their privacy properties in the

255
00:07:42,479 --> 00:07:43,800
study we found that the most privileged

256
00:07:43,800 --> 00:07:45,780
app was sprocket and the least

257
00:07:45,780 --> 00:07:49,259
privileged app was was uptrust

258
00:07:49,259 --> 00:07:50,699
so here's a screenshot on the right from

259
00:07:50,699 --> 00:07:52,440
sprocket and one of the app that we

260
00:07:52,440 --> 00:07:53,639
found to be the most privileged it says

261
00:07:53,639 --> 00:07:56,220
like no tracking but our our results

262
00:07:56,220 --> 00:07:58,919
kind of differ from that uh sprocket

263
00:07:58,919 --> 00:08:00,599
requested the most runtime permission

264
00:08:00,599 --> 00:08:02,220
also known as dangerous permissions out

265
00:08:02,220 --> 00:08:04,319
of all the apps that we looked at

266
00:08:04,319 --> 00:08:06,660
at the most third party libraries out of

267
00:08:06,660 --> 00:08:07,919
any of the apps we looked at nine

268
00:08:07,919 --> 00:08:10,440
including ad libraries which is can you

269
00:08:10,440 --> 00:08:11,880
be concerning because it might imply

270
00:08:11,880 --> 00:08:13,319
that someone's profiting from people

271
00:08:13,319 --> 00:08:15,479
being course to use these apps

272
00:08:15,479 --> 00:08:18,479
and lastly Sprocket was the only app we

273
00:08:18,479 --> 00:08:20,400
observed pre-authentication that sent

274
00:08:20,400 --> 00:08:22,620
that had time driven requests so they

275
00:08:22,620 --> 00:08:24,479
sent data to Facebook uh every five

276
00:08:24,479 --> 00:08:26,180
minutes now this data was was generally

277
00:08:26,180 --> 00:08:28,680
uh General device information such as

278
00:08:28,680 --> 00:08:30,360
battery amount of space you have if the

279
00:08:30,360 --> 00:08:32,219
device is rooted or not Etc but it's

280
00:08:32,219 --> 00:08:34,440
still surprising that that some apps had

281
00:08:34,440 --> 00:08:36,179
time driven this was only at the time

282
00:08:36,179 --> 00:08:39,599
driven request pre-authentication

283
00:08:39,599 --> 00:08:41,339
on the other hand uptrust was the least

284
00:08:41,339 --> 00:08:43,559
privilege app we saw Chris is zero

285
00:08:43,559 --> 00:08:45,899
runtime or dangerous permissions I had

286
00:08:45,899 --> 00:08:48,480
three third-party libraries and on their

287
00:08:48,480 --> 00:08:49,740
website they specifically say they don't

288
00:08:49,740 --> 00:08:52,080
geolocate or have a user-funded model

289
00:08:52,080 --> 00:08:53,160
meaning that people who use the app

290
00:08:53,160 --> 00:08:55,740
don't have to don't have to pay for it

291
00:08:55,740 --> 00:08:58,440
so looking for it right these em apps

292
00:08:58,440 --> 00:09:00,300
they introduce new harms and rest of the

293
00:09:00,300 --> 00:09:01,860
people required to use them there are

294
00:09:01,860 --> 00:09:03,000
few limits on what these apps can do

295
00:09:03,000 --> 00:09:04,860
from a legal perspective we expand on

296
00:09:04,860 --> 00:09:07,080
these two points a lot in the paper but

297
00:09:07,080 --> 00:09:08,580
their proliferation is not inevitable

298
00:09:08,580 --> 00:09:09,779
there are these municipalities around

299
00:09:09,779 --> 00:09:11,459
the country that are Banning other forms

300
00:09:11,459 --> 00:09:13,320
of car show Technologies right and I

301
00:09:13,320 --> 00:09:15,240
think at Marketplace app marketplaces

302
00:09:15,240 --> 00:09:16,680
definitely have a role to play in this

303
00:09:16,680 --> 00:09:18,899
so for example Google play they block

304
00:09:18,899 --> 00:09:20,339
certain types of apps from being on

305
00:09:20,339 --> 00:09:22,620
their platforms so apps that block ads

306
00:09:22,620 --> 00:09:24,120
or apps that help people cheat at games

307
00:09:24,120 --> 00:09:25,740
if they wanted to you know they consider

308
00:09:25,740 --> 00:09:27,779
blocking idiom apps or if not blocking

309
00:09:27,779 --> 00:09:29,040
them entirely they can consider

310
00:09:29,040 --> 00:09:30,899
increasing transparency requirements for

311
00:09:30,899 --> 00:09:31,980
these apps because they're so high

312
00:09:31,980 --> 00:09:33,300
stakes

313
00:09:33,300 --> 00:09:34,440
um

314
00:09:34,440 --> 00:09:36,120
and I think computer science researchers

315
00:09:36,120 --> 00:09:37,500
can do a lot of a lot of good in this

316
00:09:37,500 --> 00:09:39,240
space and I'll expand on this point this

317
00:09:39,240 --> 00:09:40,740
point more so there's lots of other

318
00:09:40,740 --> 00:09:42,300
forms of car show technologies that are

319
00:09:42,300 --> 00:09:43,860
impacting people there's these ankle

320
00:09:43,860 --> 00:09:44,940
monitors of course but there's also

321
00:09:44,940 --> 00:09:46,500
wearables for recidivism prediction

322
00:09:46,500 --> 00:09:48,839
there's mental health prediction tools I

323
00:09:48,839 --> 00:09:50,459
think because as security and privacy

324
00:09:50,459 --> 00:09:51,959
researcher we have these reversing

325
00:09:51,959 --> 00:09:54,180
skills we can audit Technologies we can

326
00:09:54,180 --> 00:09:56,399
collaborate with legal Scholars policy

327
00:09:56,399 --> 00:09:58,500
makers Community organizations to try to

328
00:09:58,500 --> 00:10:00,779
figure out how to help reduce the harms

329
00:10:00,779 --> 00:10:01,860
of Technology potentially make

330
00:10:01,860 --> 00:10:04,200
technology that that helps people and

331
00:10:04,200 --> 00:10:05,820
although it isn't you know unnecessary

332
00:10:05,820 --> 00:10:07,440
to understand how things how things work

333
00:10:07,440 --> 00:10:08,880
in detail to understand the potential

334
00:10:08,880 --> 00:10:10,800
harm they could cause I think is very

335
00:10:10,800 --> 00:10:14,660
helpful so thank you for your time

