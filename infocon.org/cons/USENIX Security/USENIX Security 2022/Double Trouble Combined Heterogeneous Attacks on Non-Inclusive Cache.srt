1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:11,840 --> 00:00:15,599
YX allow me to start with a bold

3
00:00:15,599 --> 00:00:18,180
statement being that the future of

4
00:00:18,180 --> 00:00:20,539
computing is

5
00:00:20,539 --> 00:00:23,699
heterogeneous so more and more we see

6
00:00:23,699 --> 00:00:26,180
that for high performance applications

7
00:00:26,180 --> 00:00:28,800
much of the compute is being outsourced

8
00:00:28,800 --> 00:00:31,260
from the general purpose processor or

9
00:00:31,260 --> 00:00:34,079
CPU to a domain-specific hardware

10
00:00:34,079 --> 00:00:37,140
accelerators which are heavily optimized

11
00:00:37,140 --> 00:00:39,300
for specific tasks

12
00:00:39,300 --> 00:00:42,059
and so in this context fpgas are

13
00:00:42,059 --> 00:00:43,739
interesting because they provide

14
00:00:43,739 --> 00:00:46,200
reconfigurable Computing while at the

15
00:00:46,200 --> 00:00:48,539
same time they don't face the same lead

16
00:00:48,539 --> 00:00:50,879
times and fixed costs that the dedicated

17
00:00:50,879 --> 00:00:52,379
Asics do

18
00:00:52,379 --> 00:00:55,620
so we see some demand emerge for fpgas

19
00:00:55,620 --> 00:00:57,840
and where there's demand Supply

20
00:00:57,840 --> 00:00:59,940
automatically follows and we see cloud

21
00:00:59,940 --> 00:01:03,059
service providers like like AWS Alibaba

22
00:01:03,059 --> 00:01:06,020
and Azure providing means for

23
00:01:06,020 --> 00:01:08,400
domain-specific Hardware acceleration on

24
00:01:08,400 --> 00:01:11,159
fpgas for their customers

25
00:01:11,159 --> 00:01:14,340
now of course the cloud economics still

26
00:01:14,340 --> 00:01:16,799
dictate the same model being let's place

27
00:01:16,799 --> 00:01:19,080
as many tenants as possible on the same

28
00:01:19,080 --> 00:01:21,420
shared resources so on the same physical

29
00:01:21,420 --> 00:01:23,040
device

30
00:01:23,040 --> 00:01:25,020
and we also know that shared resources

31
00:01:25,020 --> 00:01:27,180
may lead to side Channel attacks like

32
00:01:27,180 --> 00:01:31,200
cash attacks most notably where an

33
00:01:31,200 --> 00:01:32,939
attacker can spy on memory access

34
00:01:32,939 --> 00:01:34,979
patterns by potential by potential

35
00:01:34,979 --> 00:01:36,259
victims

36
00:01:36,259 --> 00:01:39,060
by by monitoring their own interaction

37
00:01:39,060 --> 00:01:41,939
with with the memory hierarchy

38
00:01:41,939 --> 00:01:46,320
and so um in the past we've seen a lot

39
00:01:46,320 --> 00:01:48,299
of cash attacks coming from the CPU so

40
00:01:48,299 --> 00:01:49,619
we would say that the domain is

41
00:01:49,619 --> 00:01:52,200
relatively well studied and over the

42
00:01:52,200 --> 00:01:53,700
very recently over the past two years

43
00:01:53,700 --> 00:01:56,280
we've also seen attacks coming out of

44
00:01:56,280 --> 00:01:59,100
secondary devices like fpgas or network

45
00:01:59,100 --> 00:02:02,220
interface cards but in our work we put

46
00:02:02,220 --> 00:02:05,700
forth a new attacker model being that of

47
00:02:05,700 --> 00:02:08,160
a combined attacker who controls both

48
00:02:08,160 --> 00:02:10,940
CPU cores as well as

49
00:02:10,940 --> 00:02:14,400
as one or more secondary devices so

50
00:02:14,400 --> 00:02:15,720
that's the topic of our talk Double

51
00:02:15,720 --> 00:02:18,420
Trouble combine heterogeneous attacks on

52
00:02:18,420 --> 00:02:21,120
non-inclusive cash hierarchies my name

53
00:02:21,120 --> 00:02:22,680
is Antoine Brunel and this is Joint work

54
00:02:22,680 --> 00:02:26,340
with fur canturam and uh from iMac cosic

55
00:02:26,340 --> 00:02:28,319
at k11

56
00:02:28,319 --> 00:02:30,959
now so how do secondary devices like

57
00:02:30,959 --> 00:02:33,840
fpgas interact with the memory hierarchy

58
00:02:33,840 --> 00:02:35,879
so let's start with some basic

59
00:02:35,879 --> 00:02:37,920
preliminaries first

60
00:02:37,920 --> 00:02:40,620
so the object will be studying um will

61
00:02:40,620 --> 00:02:43,080
be Intel recent Intel server processors

62
00:02:43,080 --> 00:02:46,440
so that's the Xeon product line and like

63
00:02:46,440 --> 00:02:48,239
other processors they have multiple

64
00:02:48,239 --> 00:02:50,580
levels of caches so you have the L1 and

65
00:02:50,580 --> 00:02:53,340
L2 cache private to the core and close

66
00:02:53,340 --> 00:02:55,800
to the core and you also have the shared

67
00:02:55,800 --> 00:02:57,840
last level cache which is shared among

68
00:02:57,840 --> 00:02:59,040
all the cores

69
00:02:59,040 --> 00:03:02,780
now as you move from the CPU to memory

70
00:03:02,780 --> 00:03:05,700
the caches get larger but also the

71
00:03:05,700 --> 00:03:07,980
access time gets larger and this leads

72
00:03:07,980 --> 00:03:09,420
to a timing side Channel which an

73
00:03:09,420 --> 00:03:12,060
attacker can can use to uh to infer

74
00:03:12,060 --> 00:03:14,040
memory activity or contention in

75
00:03:14,040 --> 00:03:17,819
specific levels of the cache hierarchy

76
00:03:17,819 --> 00:03:20,760
so most attacks in the past have focused

77
00:03:20,760 --> 00:03:23,480
on this shared last level cache

78
00:03:23,480 --> 00:03:26,640
which well by virtue of it being shared

79
00:03:26,640 --> 00:03:28,400
across the course obviously

80
00:03:28,400 --> 00:03:31,080
and we've seen now that in recent CPUs

81
00:03:31,080 --> 00:03:33,420
these last level caches or LLCs have

82
00:03:33,420 --> 00:03:35,640
become non-inclusive which is an

83
00:03:35,640 --> 00:03:37,800
invariant that they no longer need to

84
00:03:37,800 --> 00:03:39,720
carry lines that are also in L1 and L2

85
00:03:39,720 --> 00:03:42,959
and this changes the Dynamics in the

86
00:03:42,959 --> 00:03:45,260
cash hierarchy which will also

87
00:03:45,260 --> 00:03:48,420
give some more insights on

88
00:03:48,420 --> 00:03:50,580
so how do these secondary devices come

89
00:03:50,580 --> 00:03:53,280
in now well so to deliver the necessary

90
00:03:53,280 --> 00:03:55,920
performance uh these fpgas network

91
00:03:55,920 --> 00:03:58,379
interface cards and so on are tightly

92
00:03:58,379 --> 00:04:00,000
integrated with them within the memory

93
00:04:00,000 --> 00:04:01,440
hierarchy with some with something

94
00:04:01,440 --> 00:04:04,440
called Intel's ddio technology

95
00:04:04,440 --> 00:04:06,540
um which basically basically

96
00:04:06,540 --> 00:04:09,060
um routes all the memory traffic of the

97
00:04:09,060 --> 00:04:11,159
secondary device through this shared

98
00:04:11,159 --> 00:04:15,000
last level cache and this provides us

99
00:04:15,000 --> 00:04:16,620
with a convenient Anchor Point and this

100
00:04:16,620 --> 00:04:18,478
is the motivation of this work now we

101
00:04:18,478 --> 00:04:19,978
can look at this last level cache both

102
00:04:19,978 --> 00:04:22,500
from the CPU course through nl1 and L2

103
00:04:22,500 --> 00:04:24,660
and from this secondary device which we

104
00:04:24,660 --> 00:04:27,180
will in the paper instantiate as as an

105
00:04:27,180 --> 00:04:28,680
fpga

106
00:04:28,680 --> 00:04:32,220
but so fpga what's that so fpgas or

107
00:04:32,220 --> 00:04:34,620
field programmable gate arrays provide

108
00:04:34,620 --> 00:04:36,479
reconfigurable Hardware

109
00:04:36,479 --> 00:04:39,540
and they do so with a huge array of

110
00:04:39,540 --> 00:04:42,600
lookup tables and flip-flops and with

111
00:04:42,600 --> 00:04:44,100
that they can Implement arbitrary

112
00:04:44,100 --> 00:04:46,440
Hardware logic and flexible

113
00:04:46,440 --> 00:04:49,199
interconnects between them and so we see

114
00:04:49,199 --> 00:04:52,020
fpgas coming up as pcie acceleration

115
00:04:52,020 --> 00:04:55,139
cards in the cloud and for our malicious

116
00:04:55,139 --> 00:04:58,199
implementation the only thing we require

117
00:04:58,199 --> 00:05:00,360
are two main building blocks actually so

118
00:05:00,360 --> 00:05:02,820
one of course we need to interact with

119
00:05:02,820 --> 00:05:04,919
the memory hierarchy so we need a way to

120
00:05:04,919 --> 00:05:06,600
read and write memory lines this is

121
00:05:06,600 --> 00:05:09,020
going to be dma or direct memory access

122
00:05:09,020 --> 00:05:12,419
which we now know is routed through the

123
00:05:12,419 --> 00:05:14,340
CPU okay so through this last level

124
00:05:14,340 --> 00:05:15,540
cache

125
00:05:15,540 --> 00:05:17,220
and since we're doing timing attacks

126
00:05:17,220 --> 00:05:19,440
we'll also need a timing source and on

127
00:05:19,440 --> 00:05:21,960
an fpga well you can Implement arbitrary

128
00:05:21,960 --> 00:05:23,759
logic so it's trivial to implement your

129
00:05:23,759 --> 00:05:25,800
own timer this is just this is just a

130
00:05:25,800 --> 00:05:27,419
counter

131
00:05:27,419 --> 00:05:31,139
okay so secondary devices go through the

132
00:05:31,139 --> 00:05:34,080
LLC but they're actually really second

133
00:05:34,080 --> 00:05:36,900
class citizens in this last level cache

134
00:05:36,900 --> 00:05:38,160
or LLC

135
00:05:38,160 --> 00:05:42,259
so if we assume a line a memory line X

136
00:05:42,259 --> 00:05:45,780
and the secondary device wants to read

137
00:05:45,780 --> 00:05:47,940
this line well of course the line gets

138
00:05:47,940 --> 00:05:49,380
served to the secondary device but it's

139
00:05:49,380 --> 00:05:52,020
actually not allocated in the LLC

140
00:05:52,020 --> 00:05:53,759
on the other end if the secondary device

141
00:05:53,759 --> 00:05:56,580
performs right it does get allocated in

142
00:05:56,580 --> 00:05:58,979
the last level cache but not anywhere so

143
00:05:58,979 --> 00:06:01,320
it's constrained so the the data can

144
00:06:01,320 --> 00:06:03,780
only be pushed to two specific ways in

145
00:06:03,780 --> 00:06:06,300
this last level cache set which we call

146
00:06:06,300 --> 00:06:08,400
the ddio Region

147
00:06:08,400 --> 00:06:10,800
and so okay there's two ways but this is

148
00:06:10,800 --> 00:06:14,100
the default case so with with privileges

149
00:06:14,100 --> 00:06:16,380
you can change the setting in an MSR

150
00:06:16,380 --> 00:06:18,360
register and you can change how many

151
00:06:18,360 --> 00:06:21,600
ways ddio uses which can go up to the

152
00:06:21,600 --> 00:06:24,180
full set but what we uh what we assume

153
00:06:24,180 --> 00:06:25,680
in this work is the default case of

154
00:06:25,680 --> 00:06:29,880
course of two ddio ways okay so

155
00:06:29,880 --> 00:06:31,919
secondary reads do not allocate in the

156
00:06:31,919 --> 00:06:35,160
last level cache but what about lines

157
00:06:35,160 --> 00:06:36,660
that are already there

158
00:06:36,660 --> 00:06:38,699
so if those get read by the secondary

159
00:06:38,699 --> 00:06:41,280
device they're actually not taken into

160
00:06:41,280 --> 00:06:43,560
account in any metadata State keeping

161
00:06:43,560 --> 00:06:46,020
okay so if the secondary device performs

162
00:06:46,020 --> 00:06:47,479
a read

163
00:06:47,479 --> 00:06:50,160
two lines already there so if we have

164
00:06:50,160 --> 00:06:52,740
lines x0 and X1 currently in the ddio

165
00:06:52,740 --> 00:06:55,080
region we see that if the secondary

166
00:06:55,080 --> 00:06:57,080
device performs a right

167
00:06:57,080 --> 00:07:00,060
this changes the lines will be evicted

168
00:07:00,060 --> 00:07:02,280
from x0 to X1 which makes sense this

169
00:07:02,280 --> 00:07:04,380
this is keeping track of history but if

170
00:07:04,380 --> 00:07:06,960
there's reads then we we find that no

171
00:07:06,960 --> 00:07:08,819
history is kept so it's as if these

172
00:07:08,819 --> 00:07:11,160
reads are invisible they don't change

173
00:07:11,160 --> 00:07:13,080
the state

174
00:07:13,080 --> 00:07:15,620
and so finally since we focus on the

175
00:07:15,620 --> 00:07:17,840
non-inclusive LLC

176
00:07:17,840 --> 00:07:20,460
we need to find out so we need to

177
00:07:20,460 --> 00:07:22,380
discover how lines can be moved in and

178
00:07:22,380 --> 00:07:24,780
out of this this LLC so basically what

179
00:07:24,780 --> 00:07:27,780
the possible cash transactions are and

180
00:07:27,780 --> 00:07:30,000
for this we use this double view we now

181
00:07:30,000 --> 00:07:31,979
have on the last level cache

182
00:07:31,979 --> 00:07:34,259
and do some fpga assisted reverse

183
00:07:34,259 --> 00:07:37,080
engineering and some of these findings

184
00:07:37,080 --> 00:07:39,539
do not fully match with prior work so we

185
00:07:39,539 --> 00:07:42,240
provide supporting experiments as

186
00:07:42,240 --> 00:07:44,340
evidence as part of our open source repo

187
00:07:44,340 --> 00:07:48,000
but what we find out is that lines can

188
00:07:48,000 --> 00:07:49,560
be moved from the core to the last level

189
00:07:49,560 --> 00:07:51,720
cache of course by evicting it from L2

190
00:07:51,720 --> 00:07:53,580
or the directory so this is this is well

191
00:07:53,580 --> 00:07:56,520
known but also if you access a line from

192
00:07:56,520 --> 00:07:58,800
different cores this also places a copy

193
00:07:58,800 --> 00:08:00,660
in the last level cache and then of

194
00:08:00,660 --> 00:08:02,280
course if you write to the line we saw

195
00:08:02,280 --> 00:08:04,860
this this also installs a copy in the

196
00:08:04,860 --> 00:08:06,660
last level cache

197
00:08:06,660 --> 00:08:09,240
the opposite transactions can also occur

198
00:08:09,240 --> 00:08:11,280
so we can move a line from the LLC back

199
00:08:11,280 --> 00:08:13,680
to the core by writing to it with the

200
00:08:13,680 --> 00:08:16,620
CPU or by reading to it reading from it

201
00:08:16,620 --> 00:08:18,599
with the CPU and there the details

202
00:08:18,599 --> 00:08:20,520
depend on what the coherence state is

203
00:08:20,520 --> 00:08:23,280
but but all in all a combined attacker

204
00:08:23,280 --> 00:08:24,900
so an attacker who has access to this

205
00:08:24,900 --> 00:08:27,660
LLC from both sides has a very fine

206
00:08:27,660 --> 00:08:29,639
grained control over the cash level in

207
00:08:29,639 --> 00:08:31,560
which these lines reside

208
00:08:31,560 --> 00:08:34,020
and so the second part of the paper

209
00:08:34,020 --> 00:08:36,659
is applications of this fine-grained

210
00:08:36,659 --> 00:08:38,219
control so we do some some new

211
00:08:38,219 --> 00:08:40,620
discoveries there but with a tight time

212
00:08:40,620 --> 00:08:42,599
budget I'm only going to be able to do a

213
00:08:42,599 --> 00:08:46,620
speed run so strap in

214
00:08:46,620 --> 00:08:48,660
um let's look at the eviction set

215
00:08:48,660 --> 00:08:51,660
problem first so this is finding lines

216
00:08:51,660 --> 00:08:53,820
that map to the same set in the last

217
00:08:53,820 --> 00:08:56,700
level cache which is a precursor to many

218
00:08:56,700 --> 00:08:59,339
cache attacks and our fpga accelerator

219
00:08:59,339 --> 00:09:01,260
solves this problem in under 200

220
00:09:01,260 --> 00:09:04,380
microseconds which is several thousands

221
00:09:04,380 --> 00:09:06,260
of eviction sets constructed per second

222
00:09:06,260 --> 00:09:08,820
which is between one and three orders of

223
00:09:08,820 --> 00:09:11,640
magnitude faster than prior work and so

224
00:09:11,640 --> 00:09:14,100
the the reason why it works at all is

225
00:09:14,100 --> 00:09:16,680
because of these invisible reads and it

226
00:09:16,680 --> 00:09:19,200
works even faster because the DDI origin

227
00:09:19,200 --> 00:09:21,600
is so small so you see evictions very

228
00:09:21,600 --> 00:09:24,000
very rapidly and this is kind of

229
00:09:24,000 --> 00:09:27,120
interesting but because this is a new uh

230
00:09:27,120 --> 00:09:30,240
a new added capability that a combined

231
00:09:30,240 --> 00:09:32,519
attacker has but it arises from the fact

232
00:09:32,519 --> 00:09:34,680
that the secondary device is restricted

233
00:09:34,680 --> 00:09:36,899
so not because the secondary device has

234
00:09:36,899 --> 00:09:39,120
additional capabilities so that's quite

235
00:09:39,120 --> 00:09:41,459
an interesting dynamic

236
00:09:41,459 --> 00:09:43,320
we also

237
00:09:43,320 --> 00:09:46,860
um have another ddio Finding so what if

238
00:09:46,860 --> 00:09:48,839
the secondary device writes to a line

239
00:09:48,839 --> 00:09:51,060
but only after it has already been

240
00:09:51,060 --> 00:09:52,680
written to by a core

241
00:09:52,680 --> 00:09:55,920
well should it still go to the LLC well

242
00:09:55,920 --> 00:09:58,140
yes and we observe that it does but it's

243
00:09:58,140 --> 00:10:00,779
not allocated in this ddio region that

244
00:10:00,779 --> 00:10:03,180
we already know so there there must be

245
00:10:03,180 --> 00:10:05,459
some other undocumented structure in

246
00:10:05,459 --> 00:10:07,140
this cache

247
00:10:07,140 --> 00:10:09,120
um and that's what we found out and we

248
00:10:09,120 --> 00:10:11,940
reverse engineered this this region

249
00:10:11,940 --> 00:10:14,279
um which we called the ddio plus region

250
00:10:14,279 --> 00:10:16,140
so we had the liberty of naming it but

251
00:10:16,140 --> 00:10:18,260
actually went with a pretty boring name

252
00:10:18,260 --> 00:10:20,700
and so this is the layout for the

253
00:10:20,700 --> 00:10:22,560
default case but we repeated this

254
00:10:22,560 --> 00:10:24,420
reverse engineering effort for for all

255
00:10:24,420 --> 00:10:26,820
the possible ddio configurations and we

256
00:10:26,820 --> 00:10:28,440
see this ddio plus region being

257
00:10:28,440 --> 00:10:30,060
consistently there so this new

258
00:10:30,060 --> 00:10:32,820
undocumented region and for the very

259
00:10:32,820 --> 00:10:34,980
large Dio configurations we we also see

260
00:10:34,980 --> 00:10:36,959
some some overlap there

261
00:10:36,959 --> 00:10:40,920
so in conclusion uh the the control for

262
00:10:40,920 --> 00:10:42,779
the combined attacker is even more

263
00:10:42,779 --> 00:10:44,399
fine-grained than before because not

264
00:10:44,399 --> 00:10:46,680
only can you fix the cash level in which

265
00:10:46,680 --> 00:10:48,899
a line is currently mapped but also the

266
00:10:48,899 --> 00:10:50,579
ways in the set in which it currently

267
00:10:50,579 --> 00:10:53,100
resides which is uh to our understanding

268
00:10:53,100 --> 00:10:55,260
and an unprecedented

269
00:10:55,260 --> 00:10:56,279
so

270
00:10:56,279 --> 00:10:58,019
um we also show in the paper how a

271
00:10:58,019 --> 00:11:00,839
combined attacker can evict lines from

272
00:11:00,839 --> 00:11:03,959
the cache with very tiny eviction sets

273
00:11:03,959 --> 00:11:06,660
and the key here is to invalidate lines

274
00:11:06,660 --> 00:11:08,760
from specific ways which we now now know

275
00:11:08,760 --> 00:11:11,579
how to do right we also evict shared

276
00:11:11,579 --> 00:11:14,519
lines from other sockets and other cores

277
00:11:14,519 --> 00:11:17,279
obviously without contention on the

278
00:11:17,279 --> 00:11:19,260
directory or without without flushing

279
00:11:19,260 --> 00:11:21,180
revealing some some interesting cash

280
00:11:21,180 --> 00:11:23,700
transactions that we exploit in an

281
00:11:23,700 --> 00:11:26,220
end-to-end attack on as and we also

282
00:11:26,220 --> 00:11:28,620
Implement a new kind of covert Channel

283
00:11:28,620 --> 00:11:31,560
where data is encoded in the number of

284
00:11:31,560 --> 00:11:33,959
lines that are evicted as well as

285
00:11:33,959 --> 00:11:36,240
whether they are in ddio DDO Plus or or

286
00:11:36,240 --> 00:11:39,420
whatever the the other the other region

287
00:11:39,420 --> 00:11:42,300
so to conclude the talk we built an fpga

288
00:11:42,300 --> 00:11:45,720
accelerator for Combined cash attacks as

289
00:11:45,720 --> 00:11:46,680
a service

290
00:11:46,680 --> 00:11:48,779
which by the way if you want to make

291
00:11:48,779 --> 00:11:51,660
money you can sell accelerators on cloud

292
00:11:51,660 --> 00:11:53,100
marketplaces

293
00:11:53,100 --> 00:11:55,980
which we obviously didn't but we do

294
00:11:55,980 --> 00:11:58,800
provide uh our hardware and software

295
00:11:58,800 --> 00:12:02,519
pocs in our open source repo

296
00:12:02,519 --> 00:12:04,740
we also conclude that fpgas are

297
00:12:04,740 --> 00:12:06,720
interesting because they are so flexible

298
00:12:06,720 --> 00:12:09,180
so they can bring their own timer they

299
00:12:09,180 --> 00:12:11,399
can run all the time and the additions

300
00:12:11,399 --> 00:12:13,920
we have to do for them to enable cache

301
00:12:13,920 --> 00:12:16,079
attacks are consume so little resources

302
00:12:16,079 --> 00:12:18,000
on the fpga fabric that are basically

303
00:12:18,000 --> 00:12:19,440
undetectable

304
00:12:19,440 --> 00:12:22,320
so that that will be very hard to detect

305
00:12:22,320 --> 00:12:22,860
um

306
00:12:22,860 --> 00:12:24,779
and another conclusion is that

307
00:12:24,779 --> 00:12:26,399
countermeasure for Combined attackers

308
00:12:26,399 --> 00:12:29,940
are tricky because they arise from

309
00:12:29,940 --> 00:12:31,680
restrictions that are already in place

310
00:12:31,680 --> 00:12:34,079
on secondary devices not based on

311
00:12:34,079 --> 00:12:36,600
capabilities that are granted to them

312
00:12:36,600 --> 00:12:38,399
so the futures of computing is

313
00:12:38,399 --> 00:12:41,100
heterogeneous yes but let's not

314
00:12:41,100 --> 00:12:44,000
underestimate the complexity this brings

315
00:12:44,000 --> 00:12:46,740
and let's revisit the common assumptions

316
00:12:46,740 --> 00:12:48,660
we have on microarchitectural attacks

317
00:12:48,660 --> 00:12:50,519
and defenses

318
00:12:50,519 --> 00:12:52,800
and with that I'd like to move on over

319
00:12:52,800 --> 00:12:55,459
to the Q a

