1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:08,940 --> 00:00:11,580
hi everyone my name is Armin and today

3
00:00:11,580 --> 00:00:12,719
I'm going to talk to you about our work

4
00:00:12,719 --> 00:00:14,580
on scaling private similarity testing

5
00:00:14,580 --> 00:00:16,680
and this is Joint work with the Ching

6
00:00:16,680 --> 00:00:19,500
Hua kaisho Chung mornaman and Tom

7
00:00:19,500 --> 00:00:20,939
ristenpart

8
00:00:20,939 --> 00:00:22,920
so end-to-end encrypted messaging has

9
00:00:22,920 --> 00:00:24,960
been transformative for improving user

10
00:00:24,960 --> 00:00:26,939
privacy because the platform does not

11
00:00:26,939 --> 00:00:28,980
see the plain text content of user

12
00:00:28,980 --> 00:00:31,859
messages this helps prevent things like

13
00:00:31,859 --> 00:00:34,620
Mass surveillance and the breaching of

14
00:00:34,620 --> 00:00:38,040
these server-side databases of user data

15
00:00:38,040 --> 00:00:40,260
now despite the immense benefits that

16
00:00:40,260 --> 00:00:42,000
entered encrypted messaging provides to

17
00:00:42,000 --> 00:00:44,040
its users users are still subject to

18
00:00:44,040 --> 00:00:45,960
many forms of online abuse and

19
00:00:45,960 --> 00:00:47,940
harassment on these platforms and

20
00:00:47,940 --> 00:00:49,559
sometimes these forms of abuse are a

21
00:00:49,559 --> 00:00:51,239
result of other users on the platform

22
00:00:51,239 --> 00:00:54,000
sending them harmful content so now I'm

23
00:00:54,000 --> 00:00:55,379
just going to list a couple of examples

24
00:00:55,379 --> 00:00:57,600
of abuse that we've seen in the rat in

25
00:00:57,600 --> 00:01:00,180
the last couple of years in the past you

26
00:01:00,180 --> 00:01:01,739
know several years we've seen all sorts

27
00:01:01,739 --> 00:01:03,320
of viral Health misinformation

28
00:01:03,320 --> 00:01:05,459
proliferate on these end-to-encrypted

29
00:01:05,459 --> 00:01:08,040
Platforms in addition to that we've seen

30
00:01:08,040 --> 00:01:10,619
spam and scams in which people are

31
00:01:10,619 --> 00:01:12,600
tricked out of their money and we've

32
00:01:12,600 --> 00:01:14,580
even seen documented instances of these

33
00:01:14,580 --> 00:01:17,159
platforms being used to trade images of

34
00:01:17,159 --> 00:01:20,220
csam or child sexual abuse material

35
00:01:20,220 --> 00:01:22,860
so in our work in particular we focus on

36
00:01:22,860 --> 00:01:24,840
misinformation because we believe that

37
00:01:24,840 --> 00:01:26,520
addressing misinformation in this

38
00:01:26,520 --> 00:01:28,500
setting presents a promising opportunity

39
00:01:28,500 --> 00:01:30,420
for us to provide trust and safety to

40
00:01:30,420 --> 00:01:32,759
users while empowering users and

41
00:01:32,759 --> 00:01:34,799
optimizing for user agency and I'm going

42
00:01:34,799 --> 00:01:36,540
to provide more details on that shortly

43
00:01:36,540 --> 00:01:39,180
so concretely we propose a system in

44
00:01:39,180 --> 00:01:41,460
which we can warn users whenever they

45
00:01:41,460 --> 00:01:43,560
receive images on these end-to-ended

46
00:01:43,560 --> 00:01:46,320
encrypted platforms that contain that

47
00:01:46,320 --> 00:01:48,000
are known to be linked to a viral

48
00:01:48,000 --> 00:01:50,040
misinformation campaigns so in our

49
00:01:50,040 --> 00:01:52,439
setting the server has this block list

50
00:01:52,439 --> 00:01:54,119
of harmful images that are represented

51
00:01:54,119 --> 00:01:56,399
here by these cat photos and whenever a

52
00:01:56,399 --> 00:01:58,320
user receives an image that is an

53
00:01:58,320 --> 00:02:00,420
approximate match to any of the images

54
00:02:00,420 --> 00:02:02,340
on the block list as is the case in this

55
00:02:02,340 --> 00:02:04,439
example with this color Distortion in

56
00:02:04,439 --> 00:02:06,180
the image we would like that user to see

57
00:02:06,180 --> 00:02:08,639
a warning rendered on their device and

58
00:02:08,639 --> 00:02:10,500
here that's going to be represented by

59
00:02:10,500 --> 00:02:12,360
this red triangle

60
00:02:12,360 --> 00:02:13,980
in terms of the goals we'd like to

61
00:02:13,980 --> 00:02:15,660
achieve here we would like a high degree

62
00:02:15,660 --> 00:02:17,520
of correctness meaning that if there is

63
00:02:17,520 --> 00:02:19,260
an approximate match to a block list

64
00:02:19,260 --> 00:02:21,300
image that a user receives they should

65
00:02:21,300 --> 00:02:23,400
see a warning displayed we want our

66
00:02:23,400 --> 00:02:25,080
approach to be efficient both measured

67
00:02:25,080 --> 00:02:26,879
as the communication cost between the

68
00:02:26,879 --> 00:02:28,560
client and the server and the

69
00:02:28,560 --> 00:02:30,180
computation time on the client device

70
00:02:30,180 --> 00:02:32,040
and we would like a high degree of

71
00:02:32,040 --> 00:02:33,900
privacy meaning as little information as

72
00:02:33,900 --> 00:02:35,879
possible is leaked to the server about

73
00:02:35,879 --> 00:02:38,700
the user messages about the content of

74
00:02:38,700 --> 00:02:40,980
those messages so the state of the art

75
00:02:40,980 --> 00:02:43,560
for solving this problem this problem of

76
00:02:43,560 --> 00:02:45,420
image similarity in the plain text

77
00:02:45,420 --> 00:02:47,280
setting is this technology known as

78
00:02:47,280 --> 00:02:49,260
perceptual hashing also known as

79
00:02:49,260 --> 00:02:51,900
similarity hashing so with a similarity

80
00:02:51,900 --> 00:02:55,080
hash the user device will feed the image

81
00:02:55,080 --> 00:02:56,879
through the similarity hash function and

82
00:02:56,879 --> 00:02:59,280
it's going to Output some binary string

83
00:02:59,280 --> 00:03:01,500
and these similarity hashes have this

84
00:03:01,500 --> 00:03:03,480
special property that if the two images

85
00:03:03,480 --> 00:03:05,280
are similar to one another in the image

86
00:03:05,280 --> 00:03:07,440
space the similarity hashes should be

87
00:03:07,440 --> 00:03:08,780
close to one another

88
00:03:08,780 --> 00:03:11,640
usually measured in terms of the L1 Norm

89
00:03:11,640 --> 00:03:13,860
also known as the Hamming distance and

90
00:03:13,860 --> 00:03:15,720
examples of similarity hashes that are

91
00:03:15,720 --> 00:03:18,300
used in practice include photo DNA which

92
00:03:18,300 --> 00:03:20,940
is used by Microsoft and PDQ hash which

93
00:03:20,940 --> 00:03:22,860
is used by meta

94
00:03:22,860 --> 00:03:24,720
so a natural starting point to consider

95
00:03:24,720 --> 00:03:27,120
here is well what if every time a user

96
00:03:27,120 --> 00:03:29,099
receives a message they can check if

97
00:03:29,099 --> 00:03:30,840
that message contains an image and if so

98
00:03:30,840 --> 00:03:32,340
they feed it through the similarity hash

99
00:03:32,340 --> 00:03:34,560
function to generate this binary string

100
00:03:34,560 --> 00:03:36,599
then they'll share that similarity hash

101
00:03:36,599 --> 00:03:39,360
with the platform and the platform can

102
00:03:39,360 --> 00:03:42,000
check if that similarity hashes close to

103
00:03:42,000 --> 00:03:43,799
any of these block list images and if

104
00:03:43,799 --> 00:03:45,840
this is indeed the case the platformer

105
00:03:45,840 --> 00:03:47,760
will return some sort of warning that

106
00:03:47,760 --> 00:03:50,519
will be rendered on the user device

107
00:03:50,519 --> 00:03:53,159
so in terms of our goals this is great

108
00:03:53,159 --> 00:03:54,659
in terms of correctness assuming we're

109
00:03:54,659 --> 00:03:56,340
using a good similarity hash function

110
00:03:56,340 --> 00:03:57,959
and it's great in terms of efficiency

111
00:03:57,959 --> 00:03:59,459
because these similarity hashes are

112
00:03:59,459 --> 00:04:00,900
usually quite small they're usually

113
00:04:00,900 --> 00:04:03,599
something on the order of 256 bits

114
00:04:03,599 --> 00:04:05,760
however this is not great in terms of

115
00:04:05,760 --> 00:04:07,620
privacy it turns out that these

116
00:04:07,620 --> 00:04:09,599
similarity hashes unlike cryptographic

117
00:04:09,599 --> 00:04:11,700
hashes leak a lot of information about

118
00:04:11,700 --> 00:04:13,680
the image and they allow the adversary

119
00:04:13,680 --> 00:04:15,299
to guess the image received with high

120
00:04:15,299 --> 00:04:18,959
confidence and this is a non-starter for

121
00:04:18,959 --> 00:04:20,760
our solution or for our setting of

122
00:04:20,760 --> 00:04:22,740
end-to-end encrypted messaging

123
00:04:22,740 --> 00:04:24,960
so an alternate proposal to consider as

124
00:04:24,960 --> 00:04:26,699
was alluded to by some of these straw

125
00:04:26,699 --> 00:04:28,620
proposals mentioned in the earlier prr

126
00:04:28,620 --> 00:04:30,720
talks is having the server simply send

127
00:04:30,720 --> 00:04:32,340
the full database to the client and then

128
00:04:32,340 --> 00:04:33,479
the client can perform this check

129
00:04:33,479 --> 00:04:35,699
locally and render a warning if

130
00:04:35,699 --> 00:04:37,560
appropriate so the server will feed that

131
00:04:37,560 --> 00:04:40,020
block list through the entire simulated

132
00:04:40,020 --> 00:04:42,240
hash function and then whenever the

133
00:04:42,240 --> 00:04:44,160
client receives an image they hash the

134
00:04:44,160 --> 00:04:46,440
image and then check the image against

135
00:04:46,440 --> 00:04:48,180
the block list that they received from

136
00:04:48,180 --> 00:04:51,120
the server and they'll render a warning

137
00:04:51,120 --> 00:04:53,940
locally on device if that match actually

138
00:04:53,940 --> 00:04:55,320
ends up happening

139
00:04:55,320 --> 00:04:57,060
and so this is great in terms of

140
00:04:57,060 --> 00:04:59,220
correctness for the same reasons as

141
00:04:59,220 --> 00:05:00,780
mentioned before with the prior approach

142
00:05:00,780 --> 00:05:02,460
and it's great in terms of privacy

143
00:05:02,460 --> 00:05:03,900
because nothing is being leaked to the

144
00:05:03,900 --> 00:05:05,880
server at all however this is not so

145
00:05:05,880 --> 00:05:07,860
great in terms of efficiency as these

146
00:05:07,860 --> 00:05:09,780
block lists can grow to be rather large

147
00:05:09,780 --> 00:05:11,520
and they can be updated rather

148
00:05:11,520 --> 00:05:12,660
frequently

149
00:05:12,660 --> 00:05:14,100
especially in the case of viral

150
00:05:14,100 --> 00:05:16,320
misinformation so our idea is to

151
00:05:16,320 --> 00:05:17,940
interpolate between these two approaches

152
00:05:17,940 --> 00:05:19,680
and kind of get a hybrid between them so

153
00:05:19,680 --> 00:05:21,540
we can enjoy sort of The Best of Both

154
00:05:21,540 --> 00:05:24,120
Worlds among these benefits and we

155
00:05:24,120 --> 00:05:25,199
propose an approach called

156
00:05:25,199 --> 00:05:27,000
similarity-based bucketization so the

157
00:05:27,000 --> 00:05:28,979
user takes their image they generate

158
00:05:28,979 --> 00:05:31,080
what we call a course embedding based on

159
00:05:31,080 --> 00:05:32,820
that image which is like a scaled down

160
00:05:32,820 --> 00:05:34,860
and noise version of the similarity hash

161
00:05:34,860 --> 00:05:36,840
so it's leaking a controlled amount of

162
00:05:36,840 --> 00:05:38,340
information that it shares with the

163
00:05:38,340 --> 00:05:40,199
server the server takes that course

164
00:05:40,199 --> 00:05:43,680
embedding and uses it to filter its

165
00:05:43,680 --> 00:05:46,440
block list of harmful images into a

166
00:05:46,440 --> 00:05:48,300
ideally smaller bucket of potential

167
00:05:48,300 --> 00:05:50,520
matches and then that smaller bucket of

168
00:05:50,520 --> 00:05:52,320
potential matches can be fed into some

169
00:05:52,320 --> 00:05:54,660
sort of image comparison protocol and in

170
00:05:54,660 --> 00:05:56,520
the simplest case we can have the entire

171
00:05:56,520 --> 00:05:58,800
bucket simply be sent to the client so

172
00:05:58,800 --> 00:06:01,320
that the client can essentially perform

173
00:06:01,320 --> 00:06:03,060
these checks locally and render These

174
00:06:03,060 --> 00:06:05,160
Warnings locally as well

175
00:06:05,160 --> 00:06:06,780
so now I'm going to provide a couple

176
00:06:06,780 --> 00:06:08,880
more details on our course embedding

177
00:06:08,880 --> 00:06:11,220
part how the user actually generates

178
00:06:11,220 --> 00:06:12,960
this piece of information or rather the

179
00:06:12,960 --> 00:06:14,039
client generates this piece of

180
00:06:14,039 --> 00:06:15,600
information that is shared with the

181
00:06:15,600 --> 00:06:17,820
server so the first step is to generate

182
00:06:17,820 --> 00:06:21,500
a similarity hash as described before

183
00:06:22,979 --> 00:06:25,500
and you'll notice here that I've labeled

184
00:06:25,500 --> 00:06:28,319
the indexes under the bits of this 5-bit

185
00:06:28,319 --> 00:06:31,080
toy example of a similarity hash the

186
00:06:31,080 --> 00:06:33,419
server sorry the user or client rather

187
00:06:33,419 --> 00:06:36,000
will sample a random subset I of D

188
00:06:36,000 --> 00:06:37,979
indices where D is one of the parameters

189
00:06:37,979 --> 00:06:40,259
of our scheme and here D is equal to

190
00:06:40,259 --> 00:06:41,940
three

191
00:06:41,940 --> 00:06:46,740
and then the client will randomly flip

192
00:06:46,740 --> 00:06:48,780
each bit with probability gamma and

193
00:06:48,780 --> 00:06:50,759
output this Tuple consisting of that

194
00:06:50,759 --> 00:06:53,699
list of indexes along with the bits

195
00:06:53,699 --> 00:06:55,560
corresponding to those indexes some of

196
00:06:55,560 --> 00:06:57,000
which might have been flipped so in this

197
00:06:57,000 --> 00:06:59,100
particular example we sampled the

198
00:06:59,100 --> 00:07:01,020
indexes one two and four and we flipped

199
00:07:01,020 --> 00:07:03,300
bit number four now when it comes time

200
00:07:03,300 --> 00:07:05,340
for the server to receive this course

201
00:07:05,340 --> 00:07:08,039
embedding and filter its block list for

202
00:07:08,039 --> 00:07:09,600
every single image hash in that block

203
00:07:09,600 --> 00:07:12,300
list it's going to include that image

204
00:07:12,300 --> 00:07:13,680
hash in the bucket if the distance

205
00:07:13,680 --> 00:07:15,900
between that image hash and the course

206
00:07:15,900 --> 00:07:18,000
embedding is less than some threshold K

207
00:07:18,000 --> 00:07:20,160
which is also another parameter of our

208
00:07:20,160 --> 00:07:22,319
scheme and this distance is going to be

209
00:07:22,319 --> 00:07:24,180
the Hamming distance in our case and

210
00:07:24,180 --> 00:07:25,319
you'll notice here that we have to

211
00:07:25,319 --> 00:07:27,660
perform this distance comparison at the

212
00:07:27,660 --> 00:07:30,300
corresponding index locations so here

213
00:07:30,300 --> 00:07:32,880
we're comparing the indexes the bits at

214
00:07:32,880 --> 00:07:34,680
indexes one two and four and in this

215
00:07:34,680 --> 00:07:36,780
particular example the distance is going

216
00:07:36,780 --> 00:07:38,580
to be one so if that's below this course

217
00:07:38,580 --> 00:07:41,099
threshold this candidate hash will be

218
00:07:41,099 --> 00:07:43,440
included in the bucket so to recap our

219
00:07:43,440 --> 00:07:45,300
goals and sort of make them more

220
00:07:45,300 --> 00:07:47,400
specific to this setting correctness for

221
00:07:47,400 --> 00:07:49,080
us means that images that are similar to

222
00:07:49,080 --> 00:07:50,160
that image that produce the course

223
00:07:50,160 --> 00:07:51,840
embedding ought to be included in the

224
00:07:51,840 --> 00:07:54,419
bucket efficiency means that this bucket

225
00:07:54,419 --> 00:07:56,160
should be small relative to the size of

226
00:07:56,160 --> 00:07:58,380
the full block list privacy means the

227
00:07:58,380 --> 00:07:59,699
adversary should not be able to guess

228
00:07:59,699 --> 00:08:01,199
the image given the course embedding

229
00:08:01,199 --> 00:08:04,199
with very high confidence and here's

230
00:08:04,199 --> 00:08:05,819
just the legend to remind you of our

231
00:08:05,819 --> 00:08:09,300
notation the trade-offs go as follows so

232
00:08:09,300 --> 00:08:11,099
an increase in this parameter D which is

233
00:08:11,099 --> 00:08:13,139
the index subset size leads to a

234
00:08:13,139 --> 00:08:15,360
decrease in privacy but an increase in

235
00:08:15,360 --> 00:08:17,520
correctness because this is increasing

236
00:08:17,520 --> 00:08:19,020
the amount of bits of the similarity

237
00:08:19,020 --> 00:08:20,940
hash that you get to observe as the

238
00:08:20,940 --> 00:08:23,340
adversary an increase in gamma which is

239
00:08:23,340 --> 00:08:25,020
our noise parameter will have the

240
00:08:25,020 --> 00:08:26,280
opposite effect it's going to increase

241
00:08:26,280 --> 00:08:28,379
privacy because it adds more noise but

242
00:08:28,379 --> 00:08:29,699
that's going to in turn decrease

243
00:08:29,699 --> 00:08:32,458
correctness and finally increasing this

244
00:08:32,458 --> 00:08:34,620
course threshold for inclusion in the

245
00:08:34,620 --> 00:08:37,099
bucket is going to increase correctness

246
00:08:37,099 --> 00:08:39,479
and decrease efficiency because our

247
00:08:39,479 --> 00:08:40,740
buckets are going to be larger on

248
00:08:40,740 --> 00:08:42,179
average but because of that they're

249
00:08:42,179 --> 00:08:44,219
going to be likelier to contain matches

250
00:08:44,219 --> 00:08:47,220
if any such matches exist

251
00:08:47,220 --> 00:08:49,260
so now we answer the question of how we

252
00:08:49,260 --> 00:08:52,620
measure privacy and the general setup we

253
00:08:52,620 --> 00:08:54,600
have here is again the adversarial

254
00:08:54,600 --> 00:08:56,640
server in this case gets to see this

255
00:08:56,640 --> 00:08:58,500
course embedding and they try to guess

256
00:08:58,500 --> 00:09:00,120
if that course embedding corresponds to

257
00:09:00,120 --> 00:09:01,680
a particular image they have in mind

258
00:09:01,680 --> 00:09:04,500
which is W sub ADV in this example and

259
00:09:04,500 --> 00:09:06,360
one of the Privacy measures we have here

260
00:09:06,360 --> 00:09:08,399
is going to measure the adversarial

261
00:09:08,399 --> 00:09:09,959
precision and guessing if that course

262
00:09:09,959 --> 00:09:11,820
embedding corresponds to a particular

263
00:09:11,820 --> 00:09:15,660
image which is here again wadv and to

264
00:09:15,660 --> 00:09:17,220
remind you Precision in this case means

265
00:09:17,220 --> 00:09:19,380
what is the probability that you know

266
00:09:19,380 --> 00:09:20,940
condition on the adversary is saying

267
00:09:20,940 --> 00:09:22,920
this is a match that this actually is

268
00:09:22,920 --> 00:09:25,860
indeed a match so we perform simulations

269
00:09:25,860 --> 00:09:28,380
on real world data on a real world data

270
00:09:28,380 --> 00:09:29,940
set of Twitter images in order to

271
00:09:29,940 --> 00:09:31,920
evaluate the correctness privacy and

272
00:09:31,920 --> 00:09:33,779
efficiency of our approach and to give

273
00:09:33,779 --> 00:09:36,600
you a taste of that when we try this out

274
00:09:36,600 --> 00:09:40,380
with d equal to 9 gamma equal to 0.05

275
00:09:40,380 --> 00:09:42,000
which is the noise parameter and the

276
00:09:42,000 --> 00:09:44,160
course threshold k equal to 3 we can

277
00:09:44,160 --> 00:09:45,959
achieve a correctness of above 95

278
00:09:45,959 --> 00:09:49,500
percent we can got privacy as

279
00:09:49,500 --> 00:09:51,360
adversarial position below 50 percent

280
00:09:51,360 --> 00:09:54,060
and the efficiency which we measures the

281
00:09:54,060 --> 00:09:55,980
ratio between the average bucket size to

282
00:09:55,980 --> 00:09:59,160
the full block list size is roughly 9.3

283
00:09:59,160 --> 00:10:00,839
percent so now I'm going to talk about

284
00:10:00,839 --> 00:10:03,720
how we can use our approach to scale uh

285
00:10:03,720 --> 00:10:05,580
cryptographic to PC and this is going to

286
00:10:05,580 --> 00:10:07,740
be relevant to settings in which the

287
00:10:07,740 --> 00:10:09,200
server input confidential

288
00:10:09,200 --> 00:10:11,339
confidentiality matters for instance if

289
00:10:11,339 --> 00:10:13,860
the server cares about uh you know

290
00:10:13,860 --> 00:10:15,480
reducing the possibility of evasion

291
00:10:15,480 --> 00:10:18,120
attacks so in this particular case the

292
00:10:18,120 --> 00:10:19,500
client will simply send the embedding

293
00:10:19,500 --> 00:10:21,360
and the server generates that smaller

294
00:10:21,360 --> 00:10:23,700
bucket and it's going to engage in a 2pc

295
00:10:23,700 --> 00:10:25,860
protocol using that smaller bucket as

296
00:10:25,860 --> 00:10:27,660
its private inputs

297
00:10:27,660 --> 00:10:31,500
and so here we have some a sample of our

298
00:10:31,500 --> 00:10:33,959
results uh so in this particular case

299
00:10:33,959 --> 00:10:35,880
with that First Column if we consider

300
00:10:35,880 --> 00:10:37,080
the simple approach where the server

301
00:10:37,080 --> 00:10:38,580
sends the entire bucket to the client

302
00:10:38,580 --> 00:10:41,700
without SBB that takes 3.09 seconds with

303
00:10:41,700 --> 00:10:44,240
SBB that's a speed up to 0.06 seconds

304
00:10:44,240 --> 00:10:46,980
and when we use these generic NPC

305
00:10:46,980 --> 00:10:49,740
approaches uh Krypton and EMP those are

306
00:10:49,740 --> 00:10:51,839
unable to finish on this data set of 1

307
00:10:51,839 --> 00:10:54,600
million images however when we equip

308
00:10:54,600 --> 00:10:57,180
them with SBB those are each able to run

309
00:10:57,180 --> 00:11:00,240
in under 30 seconds so in conclusion we

310
00:11:00,240 --> 00:11:02,100
propose similarity-based bucketization

311
00:11:02,100 --> 00:11:04,260
which is an approach to scale private

312
00:11:04,260 --> 00:11:06,420
similarity testing that provides these

313
00:11:06,420 --> 00:11:08,120
tunable trade-offs between privacy

314
00:11:08,120 --> 00:11:11,220
correctness and efficiency we propose

315
00:11:11,220 --> 00:11:13,019
new privacy measures to analyze our

316
00:11:13,019 --> 00:11:15,180
construction we empirically evaluate our

317
00:11:15,180 --> 00:11:17,459
construction on real world data and we

318
00:11:17,459 --> 00:11:18,899
also show that our construction can be

319
00:11:18,899 --> 00:11:21,060
composed with generic two PC protocols

320
00:11:21,060 --> 00:11:23,160
please read the paper for more details

321
00:11:23,160 --> 00:11:24,600
and I'm happy to take any questions

322
00:11:24,600 --> 00:11:27,560
thank you all so much

