1
00:00:07,880 --> 00:00:10,740
hello everyone I'm evil Chen from

2
00:00:10,740 --> 00:00:12,780
shenzhou University and City University

3
00:00:12,780 --> 00:00:15,420
of Hong Kong today I'm going to share

4
00:00:15,420 --> 00:00:17,279
with you our work teacher model

5
00:00:17,279 --> 00:00:19,440
fingerprinting attacks against transfer

6
00:00:19,440 --> 00:00:21,480
learning there you see the joint work

7
00:00:21,480 --> 00:00:24,180
with chosen so long and young Jung so

8
00:00:24,180 --> 00:00:26,220
let's get started

9
00:00:26,220 --> 00:00:28,680
deep learning has shown us incredibly

10
00:00:28,680 --> 00:00:30,740
impressive power in the past few years

11
00:00:30,740 --> 00:00:34,220
we now have

12
00:00:34,399 --> 00:00:36,899
translations will have powerful language

13
00:00:36,899 --> 00:00:39,300
translators and so on

14
00:00:39,300 --> 00:00:41,520
all of these are only possible because

15
00:00:41,520 --> 00:00:43,340
of a high quality deep learning model

16
00:00:43,340 --> 00:00:45,899
usually a good deep learning model is

17
00:00:45,899 --> 00:00:47,460
really expensive

18
00:00:47,460 --> 00:00:50,399
first as we know a good model relies on

19
00:00:50,399 --> 00:00:52,440
large data sets

20
00:00:52,440 --> 00:00:54,899
second we need sufficient Computing

21
00:00:54,899 --> 00:00:57,300
resources to support the model training

22
00:00:57,300 --> 00:01:00,360
for instance training a gp3 model would

23
00:01:00,360 --> 00:01:02,640
cost more than 300 years on high

24
00:01:02,640 --> 00:01:04,619
performance GPU

25
00:01:04,619 --> 00:01:07,380
sometimes we need to have an expertise

26
00:01:07,380 --> 00:01:09,840
to design develop and deploy the

27
00:01:09,840 --> 00:01:11,760
different model

28
00:01:11,760 --> 00:01:14,760
so it's hard to build and use a high

29
00:01:14,760 --> 00:01:17,159
quality model when we only have limited

30
00:01:17,159 --> 00:01:18,900
training data and the training resources

31
00:01:18,900 --> 00:01:21,659
we need to find some ways to tackle the

32
00:01:21,659 --> 00:01:23,580
mobile challenges

33
00:01:23,580 --> 00:01:25,740
nowadays we have an affordable solution

34
00:01:25,740 --> 00:01:27,960
called transfer learning to train a high

35
00:01:27,960 --> 00:01:30,119
quality model you can grab a set of

36
00:01:30,119 --> 00:01:31,920
layers from large model trained by

37
00:01:31,920 --> 00:01:33,780
others at Google

38
00:01:33,780 --> 00:01:36,060
in the case I show here the prediction

39
00:01:36,060 --> 00:01:38,880
layers can help to extract features and

40
00:01:38,880 --> 00:01:41,400
we just need to train on several fully

41
00:01:41,400 --> 00:01:43,020
connected layers

42
00:01:43,020 --> 00:01:45,240
the model we borrowed from the large

43
00:01:45,240 --> 00:01:48,720
company is called The Future model and

44
00:01:48,720 --> 00:01:51,479
the model we find on the gas is called a

45
00:01:51,479 --> 00:01:54,020
student model

46
00:01:55,020 --> 00:01:57,479
or if we want the student model to fit

47
00:01:57,479 --> 00:01:59,939
better on our data sets we can also fine

48
00:01:59,939 --> 00:02:02,939
tune the pre-trained layers

49
00:02:02,939 --> 00:02:05,640
this is the most commonly used solution

50
00:02:05,640 --> 00:02:08,038
we have so far large companies like

51
00:02:08,038 --> 00:02:10,919
Google Microsoft and Amanda have been

52
00:02:10,919 --> 00:02:13,620
sorting their models to the public so

53
00:02:13,620 --> 00:02:15,840
that everyone can build their own

54
00:02:15,840 --> 00:02:18,060
student models on top of these high

55
00:02:18,060 --> 00:02:21,140
quality teacher models

56
00:02:21,180 --> 00:02:23,400
after obtaining the Deep learning model

57
00:02:23,400 --> 00:02:25,140
by trying to learning the service

58
00:02:25,140 --> 00:02:27,540
provider will conceal the student model

59
00:02:27,540 --> 00:02:29,700
with an API

60
00:02:29,700 --> 00:02:32,940
through the API the customer can upload

61
00:02:32,940 --> 00:02:35,040
the samples and get the corresponding

62
00:02:35,040 --> 00:02:36,660
model predictions

63
00:02:36,660 --> 00:02:39,420
in this case the student model Works in

64
00:02:39,420 --> 00:02:41,220
a black box fashion

65
00:02:41,220 --> 00:02:43,860
so why bother to hide the student model

66
00:02:43,860 --> 00:02:45,599
from the users

67
00:02:45,599 --> 00:02:48,959
indeed on one hand as we spoke before a

68
00:02:48,959 --> 00:02:50,640
high quality deep learning model is

69
00:02:50,640 --> 00:02:53,280
expensive it is indeed a kind of

70
00:02:53,280 --> 00:02:55,440
intellectual property and should be well

71
00:02:55,440 --> 00:02:56,760
protected

72
00:02:56,760 --> 00:02:59,459
on the other hand it is out of the

73
00:02:59,459 --> 00:03:02,580
security concern once the student model

74
00:03:02,580 --> 00:03:04,739
is leaked and the Checker could find out

75
00:03:04,739 --> 00:03:07,800
the weaknesses of the model and use item

76
00:03:07,800 --> 00:03:11,099
for profit or fund for instance the

77
00:03:11,099 --> 00:03:15,000
famous adversarial use ammo attacks

78
00:03:15,000 --> 00:03:18,540
but if this design safe enough

79
00:03:18,540 --> 00:03:21,780
unfortunately we find that as most part

80
00:03:21,780 --> 00:03:23,879
of the suited model comes from other

81
00:03:23,879 --> 00:03:27,239
resources usually public databases and

82
00:03:27,239 --> 00:03:29,400
attackers can efficiently identify the

83
00:03:29,400 --> 00:03:31,319
teacher model

84
00:03:31,319 --> 00:03:34,920
it works like this after acquiring the

85
00:03:34,920 --> 00:03:38,940
Deep learning Services several times

86
00:03:38,940 --> 00:03:41,640
view attacker can identify the force of

87
00:03:41,640 --> 00:03:43,739
the electrician model then he can

88
00:03:43,739 --> 00:03:45,659
download the data model from the

89
00:03:45,659 --> 00:03:49,280
specific model database

90
00:03:50,340 --> 00:03:53,459
as a result most part of the Black Box

91
00:03:53,459 --> 00:03:55,980
gets exposed

92
00:03:55,980 --> 00:03:58,920
such attack on only Wireless the

93
00:03:58,920 --> 00:04:00,900
intellectual property of the victim

94
00:04:00,900 --> 00:04:04,080
company but also enables further attack

95
00:04:04,080 --> 00:04:06,959
okay so in the remaining of the talk I

96
00:04:06,959 --> 00:04:08,580
will introduce how I would have actually

97
00:04:08,580 --> 00:04:11,120
works

98
00:04:11,760 --> 00:04:14,340
let's talk about the thread model first

99
00:04:14,340 --> 00:04:17,279
we assume that the attack doesn't know

100
00:04:17,279 --> 00:04:20,160
the certain model architecture also we

101
00:04:20,160 --> 00:04:22,740
assume the target Black Box only return

102
00:04:22,740 --> 00:04:25,800
top one classification results which

103
00:04:25,800 --> 00:04:29,540
gives the minimal piece of information

104
00:04:31,380 --> 00:04:34,080
but we assume the attacker has obtained

105
00:04:34,080 --> 00:04:35,759
Future model candidates from public

106
00:04:35,759 --> 00:04:38,100
sources for example deep learning

107
00:04:38,100 --> 00:04:40,919
Frameworks like titles or websites like

108
00:04:40,919 --> 00:04:42,600
models

109
00:04:42,600 --> 00:04:45,180
neutral the teacher data set nor the

110
00:04:45,180 --> 00:04:47,639
student data that is available however

111
00:04:47,639 --> 00:04:50,040
the whatever can collect public data

112
00:04:50,040 --> 00:04:52,080
cells like enemies see if I tends to

113
00:04:52,080 --> 00:04:53,820
help perform the attack

114
00:04:53,820 --> 00:04:56,340
the attacker has two primary goals one

115
00:04:56,340 --> 00:04:58,380
is to inferred the Twitter model

116
00:04:58,380 --> 00:05:01,500
accurately well the other is to use as

117
00:05:01,500 --> 00:05:03,900
few queries as possible to limit the

118
00:05:03,900 --> 00:05:06,560
attack cost

119
00:05:07,020 --> 00:05:09,479
here is how I will attack the children

120
00:05:09,479 --> 00:05:12,660
fingerprinting attack works first the

121
00:05:12,660 --> 00:05:14,940
attacker selects a normal sample from a

122
00:05:14,940 --> 00:05:17,759
public defect we call it for probably

123
00:05:17,759 --> 00:05:18,780
input

124
00:05:18,780 --> 00:05:21,540
then our given teacher model the

125
00:05:21,540 --> 00:05:23,940
attacker tries to generate a synthetic

126
00:05:23,940 --> 00:05:26,520
input which leads to a similarly

127
00:05:26,520 --> 00:05:28,259
different representation with the

128
00:05:28,259 --> 00:05:29,699
problem input

129
00:05:29,699 --> 00:05:32,100
and the two impulse have similar latent

130
00:05:32,100 --> 00:05:34,979
features hopefully they will call the

131
00:05:34,979 --> 00:05:37,560
same top one classification results for

132
00:05:37,560 --> 00:05:41,100
example airplane in this figure

133
00:05:41,100 --> 00:05:43,800
then we send the two inputs to the

134
00:05:43,800 --> 00:05:44,759
victory

135
00:05:44,759 --> 00:05:47,340
if the student model comes from the same

136
00:05:47,340 --> 00:05:48,479
teacher model

137
00:05:48,479 --> 00:05:51,600
so to impose will produce the same Latin

138
00:05:51,600 --> 00:05:52,979
features

139
00:05:52,979 --> 00:05:55,380
and therefore the same classification

140
00:05:55,380 --> 00:05:57,360
results

141
00:05:57,360 --> 00:05:59,820
we call this pair of inputs as a

142
00:05:59,820 --> 00:06:01,740
fingerprinting pair

143
00:06:01,740 --> 00:06:04,259
we can send a bunch of fingerprinting

144
00:06:04,259 --> 00:06:05,900
pairs to concealed in the model

145
00:06:05,900 --> 00:06:08,940
intuitively the more matched results we

146
00:06:08,940 --> 00:06:10,979
get the more likely that the student

147
00:06:10,979 --> 00:06:14,900
model comes from the teacher model

148
00:06:15,060 --> 00:06:17,940
so the first step is to construct the

149
00:06:17,940 --> 00:06:19,860
fingerprinting pairs the key of

150
00:06:19,860 --> 00:06:22,500
generating the synthetic input is to

151
00:06:22,500 --> 00:06:24,360
solve this constraint optimization

152
00:06:24,360 --> 00:06:25,500
problem

153
00:06:25,500 --> 00:06:28,259
we can convert it into an unconstrained

154
00:06:28,259 --> 00:06:31,319
one by variable substitution which can

155
00:06:31,319 --> 00:06:33,240
be solved with the gradient descent

156
00:06:33,240 --> 00:06:34,560
optimizer

157
00:06:34,560 --> 00:06:36,900
you may have seen this technique in many

158
00:06:36,900 --> 00:06:40,440
adversial example papers we repeat this

159
00:06:40,440 --> 00:06:43,199
step for each candid teacher model and

160
00:06:43,199 --> 00:06:45,660
then send the fingerprinting pairs to

161
00:06:45,660 --> 00:06:48,240
the Target Model

162
00:06:48,240 --> 00:06:50,759
the next step is to infer the teacher

163
00:06:50,759 --> 00:06:51,720
model

164
00:06:51,720 --> 00:06:54,600
the row is quite straightforward for

165
00:06:54,600 --> 00:06:56,400
each candidate teacher model we

166
00:06:56,400 --> 00:06:58,319
calculate the proportions match

167
00:06:58,319 --> 00:07:02,220
responses then we chose the candidates

168
00:07:02,220 --> 00:07:04,740
with the largest margin proportion as

169
00:07:04,740 --> 00:07:06,300
our inference results

170
00:07:06,300 --> 00:07:08,400
you can simply regard the matching

171
00:07:08,400 --> 00:07:11,900
proportion as a confidence score

172
00:07:12,300 --> 00:07:15,360
here is an example this row Vector

173
00:07:15,360 --> 00:07:18,000
represents one attack among the

174
00:07:18,000 --> 00:07:19,500
candidates

175
00:07:19,500 --> 00:07:23,039
with gg19 has the highest score but in

176
00:07:23,039 --> 00:07:25,620
practice there are chances that the

177
00:07:25,620 --> 00:07:27,419
actual teacher model is out of the

178
00:07:27,419 --> 00:07:31,620
candidate set so we present a threshold

179
00:07:31,620 --> 00:07:34,380
if the Hacked score is higher than the

180
00:07:34,380 --> 00:07:38,520
threshold we return the inference result

181
00:07:38,520 --> 00:07:42,419
otherwise we return now that means no

182
00:07:42,419 --> 00:07:45,740
match the tutorial model found

183
00:07:47,340 --> 00:07:49,979
uh yeah due to time limit here I

184
00:07:49,979 --> 00:07:51,720
introduced some representative results

185
00:07:51,720 --> 00:07:54,979
in our basic evaluation we generate 100

186
00:07:54,979 --> 00:07:57,180
fingerprinting pairs for each teacher

187
00:07:57,180 --> 00:07:59,460
model candidate we construct many

188
00:07:59,460 --> 00:08:01,800
student models across different kinds of

189
00:08:01,800 --> 00:08:04,080
learning tasks different teacher models

190
00:08:04,080 --> 00:08:05,400
and different student model

191
00:08:05,400 --> 00:08:08,120
architectures

192
00:08:08,160 --> 00:08:11,099
here are the basic results our attack

193
00:08:11,099 --> 00:08:13,560
has correctly identified all the student

194
00:08:13,560 --> 00:08:16,620
models transferred by non-teacher models

195
00:08:16,620 --> 00:08:19,259
for 18 student models transferred from

196
00:08:19,259 --> 00:08:20,879
unknown sources on the calculator

197
00:08:20,879 --> 00:08:24,000
returns now for 13 out of Zone

198
00:08:24,000 --> 00:08:27,180
for 36 models trained without transfer

199
00:08:27,180 --> 00:08:29,819
learning I would have returns now for 31

200
00:08:29,819 --> 00:08:32,479
out of them

201
00:08:32,520 --> 00:08:35,339
this plot shows how the number of

202
00:08:35,339 --> 00:08:38,700
queries affect our attack

203
00:08:38,700 --> 00:08:41,458
here we Define query budget the number

204
00:08:41,458 --> 00:08:43,320
of fingerprinting pairs used for each

205
00:08:43,320 --> 00:08:46,140
teacher model candidates

206
00:08:46,140 --> 00:08:49,560
once the query budget reaches 50 the

207
00:08:49,560 --> 00:08:53,040
total inference accuracy achieves 100 it

208
00:08:53,040 --> 00:08:55,560
means that we find an efficient approach

209
00:08:55,560 --> 00:08:57,899
to steal most parts of a transfer

210
00:08:57,899 --> 00:09:02,040
learning model with much fewer queries

211
00:09:02,040 --> 00:09:04,560
but that's the high matching proportion

212
00:09:04,560 --> 00:09:07,080
always mean a high inference confidence

213
00:09:07,080 --> 00:09:09,180
suppose the following case a black box

214
00:09:09,180 --> 00:09:11,519
always returns label one

215
00:09:11,519 --> 00:09:14,100
of course we will always get one hundred

216
00:09:14,100 --> 00:09:16,260
percent imagine proportion no matter

217
00:09:16,260 --> 00:09:19,200
what queries we send we refer this to

218
00:09:19,200 --> 00:09:22,339
the false matching problem

219
00:09:22,440 --> 00:09:24,899
to solve the first matching problems we

220
00:09:24,899 --> 00:09:27,540
propose more robust of the time we first

221
00:09:27,540 --> 00:09:30,240
Define the supporting set

222
00:09:30,240 --> 00:09:32,580
for all of the mastered responses we

223
00:09:32,580 --> 00:09:34,620
remove the most frequently matched

224
00:09:34,620 --> 00:09:36,240
elements

225
00:09:36,240 --> 00:09:39,060
the remaining elements controls the

226
00:09:39,060 --> 00:09:41,580
supporting set

227
00:09:41,580 --> 00:09:45,060
then we have the following statement we

228
00:09:45,060 --> 00:09:47,339
think the inference results is valid

229
00:09:47,339 --> 00:09:50,100
only when the size of the supporting

230
00:09:50,100 --> 00:09:54,120
size is no less than this lower bound

231
00:09:54,120 --> 00:09:56,519
will observe the fact when the query

232
00:09:56,519 --> 00:09:59,040
number is not sufficiently large most

233
00:09:59,040 --> 00:10:02,100
inference results are indeed invalid or

234
00:10:02,100 --> 00:10:04,500
in other words our original attack is

235
00:10:04,500 --> 00:10:08,660
not robust with two field queries

236
00:10:09,240 --> 00:10:11,820
power of attack can also help Downstream

237
00:10:11,820 --> 00:10:14,100
attacks here we show how our attack

238
00:10:14,100 --> 00:10:16,980
helps to mount model stealing Labs the

239
00:10:16,980 --> 00:10:19,320
idea is straightforward the attacker

240
00:10:19,320 --> 00:10:22,620
sends the set of samples to database

241
00:10:22,620 --> 00:10:25,140
and received the corresponding responses

242
00:10:25,140 --> 00:10:28,740
the labels in this way the attacker can

243
00:10:28,740 --> 00:10:31,860
obtain a label this set then based on

244
00:10:31,860 --> 00:10:33,899
the infrared teacher model

245
00:10:33,899 --> 00:10:36,120
the attacker trains the Thoroughbred

246
00:10:36,120 --> 00:10:38,160
model

247
00:10:38,160 --> 00:10:41,220
okay so the figure compares the model

248
00:10:41,220 --> 00:10:43,019
student performance with different

249
00:10:43,019 --> 00:10:45,660
feature models in general when the

250
00:10:45,660 --> 00:10:47,940
attack starts with the tutor model used

251
00:10:47,940 --> 00:10:50,220
by the wiki it can achieve the best

252
00:10:50,220 --> 00:10:52,800
performance both in terms of accuracy

253
00:10:52,800 --> 00:10:55,560
and fidelity

254
00:10:55,560 --> 00:10:58,440
so at the end I would like to give two

255
00:10:58,440 --> 00:11:01,320
feasible contaminers first we can

256
00:11:01,320 --> 00:11:03,600
distort inputs by inserting small random

257
00:11:03,600 --> 00:11:05,760
noise or perform image Transformations

258
00:11:05,760 --> 00:11:09,120
like image cropping and resizing it can

259
00:11:09,120 --> 00:11:13,200
destroy the patterns in synthetic inputs

260
00:11:13,200 --> 00:11:15,720
second we can use the method called

261
00:11:15,720 --> 00:11:18,120
injecting neural distances to make the

262
00:11:18,120 --> 00:11:20,220
student models feature map different

263
00:11:20,220 --> 00:11:22,320
from the teacher models

264
00:11:22,320 --> 00:11:25,019
it requires to modify the pre-trained

265
00:11:25,019 --> 00:11:26,820
weight which may introduce actual

266
00:11:26,820 --> 00:11:29,600
training costs

267
00:11:29,880 --> 00:11:32,640
okay here is the conclusion

268
00:11:32,640 --> 00:11:35,399
first we propose a simple and efficient

269
00:11:35,399 --> 00:11:37,680
path to infer the teacher model used by

270
00:11:37,680 --> 00:11:39,120
transfer learning

271
00:11:39,120 --> 00:11:41,399
second I will type can effectively

272
00:11:41,399 --> 00:11:43,680
identify the teacher model

273
00:11:43,680 --> 00:11:46,260
and our angle attack can help perform

274
00:11:46,260 --> 00:11:49,980
further advanced level attacks

275
00:11:49,980 --> 00:11:52,079
okay that's all about my presentation

276
00:11:52,079 --> 00:11:54,979
thank you

