1
00:00:07,700 --> 00:00:10,800
hello today I want to introduce our work

2
00:00:10,800 --> 00:00:13,139
Auto da automated decision-based

3
00:00:13,139 --> 00:00:15,240
iterative adversarial attacks I am

4
00:00:15,240 --> 00:00:17,640
chianfu from qinghua University this

5
00:00:17,640 --> 00:00:19,320
work tries to automatically search for

6
00:00:19,320 --> 00:00:21,779
good adversarial attack algorithms these

7
00:00:21,779 --> 00:00:23,760
attack algorithms can generate adversary

8
00:00:23,760 --> 00:00:25,439
examples to attack machine learning

9
00:00:25,439 --> 00:00:27,599
models letting me first provide some

10
00:00:27,599 --> 00:00:29,099
background knowledge on adversary

11
00:00:29,099 --> 00:00:30,300
examples

12
00:00:30,300 --> 00:00:32,040
deep neural networks have been

13
00:00:32,040 --> 00:00:33,600
integrated into several security

14
00:00:33,600 --> 00:00:36,000
critical application systems however

15
00:00:36,000 --> 00:00:38,100
these neural network classifiers are

16
00:00:38,100 --> 00:00:39,620
vulnerable to adversary examples

17
00:00:39,620 --> 00:00:42,300
attackers could further classifier by

18
00:00:42,300 --> 00:00:44,100
imposing small adversarial perturbations

19
00:00:44,100 --> 00:00:46,620
onto normal images as you can see from

20
00:00:46,620 --> 00:00:48,780
this figure adding small adversarial

21
00:00:48,780 --> 00:00:51,420
perturbation onto normal image can full

22
00:00:51,420 --> 00:00:53,879
the classifier to classify Alps as stock

23
00:00:53,879 --> 00:00:57,000
as of several examples bring potential

24
00:00:57,000 --> 00:00:58,800
risks to the security critical

25
00:00:58,800 --> 00:01:01,379
applications thus various adversarial

26
00:01:01,379 --> 00:01:03,239
attack and defense methods have been

27
00:01:03,239 --> 00:01:04,559
developed

28
00:01:04,559 --> 00:01:06,960
as osara attacks aims to generate

29
00:01:06,960 --> 00:01:08,880
adversarial examples under some

30
00:01:08,880 --> 00:01:11,340
specified threat model where the several

31
00:01:11,340 --> 00:01:14,100
defenses tries to defend against them to

32
00:01:14,100 --> 00:01:15,960
measure the quality of an adversary

33
00:01:15,960 --> 00:01:18,780
example researchers usually use L2 or L

34
00:01:18,780 --> 00:01:20,400
Infinity Norm of the corresponding

35
00:01:20,400 --> 00:01:22,740
adversarial preservation a smaller Norm

36
00:01:22,740 --> 00:01:24,659
means better at the thorough example

37
00:01:24,659 --> 00:01:26,820
since the perturbation or noise would be

38
00:01:26,820 --> 00:01:29,220
more imperceptible by human eyes for

39
00:01:29,220 --> 00:01:31,680
example L2 attacks will try to generate

40
00:01:31,680 --> 00:01:33,780
adversary perturbations with lower alt

41
00:01:33,780 --> 00:01:36,060
to known divided by the attacker's score

42
00:01:36,060 --> 00:01:38,520
they are targeted and untargeted threat

43
00:01:38,520 --> 00:01:41,159
models untargeted attacker aims to cause

44
00:01:41,159 --> 00:01:43,200
misclassification of the classifier

45
00:01:43,200 --> 00:01:46,079
while targeted attacker moves one step

46
00:01:46,079 --> 00:01:47,540
further and aims to cause

47
00:01:47,540 --> 00:01:50,460
misclassification to a target class

48
00:01:50,460 --> 00:01:52,320
divided by the attacker's knowledge

49
00:01:52,320 --> 00:01:54,600
about the Target Model there are white

50
00:01:54,600 --> 00:01:57,060
blocks and black box attacks white book

51
00:01:57,060 --> 00:01:59,159
attacker knows everything about the

52
00:01:59,159 --> 00:02:01,259
model including its architecture and

53
00:02:01,259 --> 00:02:03,899
parameters as for Black Box run model

54
00:02:03,899 --> 00:02:06,479
the model is a black box and the

55
00:02:06,479 --> 00:02:08,880
attacker can only carry the model for

56
00:02:08,880 --> 00:02:11,099
example under the decision based Black

57
00:02:11,099 --> 00:02:13,560
Box setting attacker can only send

58
00:02:13,560 --> 00:02:15,780
images to the model and query for their

59
00:02:15,780 --> 00:02:18,360
final classification labels in general

60
00:02:18,360 --> 00:02:20,760
attack with less knowledge about the

61
00:02:20,760 --> 00:02:22,739
Target Model is usually more challenging

62
00:02:22,739 --> 00:02:25,680
and practical as for defense methods

63
00:02:25,680 --> 00:02:27,599
AdvoCare training is one of the

64
00:02:27,599 --> 00:02:30,360
strongest defenses the basic idea is

65
00:02:30,360 --> 00:02:32,459
adding other serial examples to training

66
00:02:32,459 --> 00:02:33,480
set

67
00:02:33,480 --> 00:02:36,599
but why we need automated attacks on one

68
00:02:36,599 --> 00:02:38,819
hand developing adaptive attacks is

69
00:02:38,819 --> 00:02:41,400
necessary to evaluate the defenses this

70
00:02:41,400 --> 00:02:43,680
adaptive attacks are designed by domain

71
00:02:43,680 --> 00:02:46,080
experts Case by case and require lots of

72
00:02:46,080 --> 00:02:48,540
Trail and error efforts automated

73
00:02:48,540 --> 00:02:51,000
attacks can ease these burdens on the

74
00:02:51,000 --> 00:02:52,920
other hand many of existing

75
00:02:52,920 --> 00:02:54,660
decision-based attacks are based on

76
00:02:54,660 --> 00:02:57,360
heuristics automated attacks can serve

77
00:02:57,360 --> 00:02:59,459
as reasonable baselines and help us

78
00:02:59,459 --> 00:03:01,319
examine the rationality of these

79
00:03:01,319 --> 00:03:02,940
heuristics

80
00:03:02,940 --> 00:03:04,739
there are two Fields trying to

81
00:03:04,739 --> 00:03:07,140
automatically solve problems they are

82
00:03:07,140 --> 00:03:09,000
program synthesis and Automated machine

83
00:03:09,000 --> 00:03:11,400
learning programming synthesis aims to

84
00:03:11,400 --> 00:03:12,959
find programs satisfying some

85
00:03:12,959 --> 00:03:15,659
specification or constraints his search

86
00:03:15,659 --> 00:03:17,580
space is constructed from programs

87
00:03:17,580 --> 00:03:19,620
program synthesis work usually use

88
00:03:19,620 --> 00:03:22,019
solvers to solve this specification or

89
00:03:22,019 --> 00:03:24,780
constraints on the other side neural

90
00:03:24,780 --> 00:03:26,760
architecture search is one of the most

91
00:03:26,760 --> 00:03:28,560
well-known directions of automated

92
00:03:28,560 --> 00:03:31,200
machine learning which aims to find the

93
00:03:31,200 --> 00:03:33,180
network architectures achieving higher

94
00:03:33,180 --> 00:03:35,459
accuracy the search space usually

95
00:03:35,459 --> 00:03:37,680
constructed from expert Design Network

96
00:03:37,680 --> 00:03:40,140
layers Advanced research methods

97
00:03:40,140 --> 00:03:42,180
including reinforcement learning and

98
00:03:42,180 --> 00:03:44,580
gradient based methods are used in

99
00:03:44,580 --> 00:03:46,799
general program synthesis problems are

100
00:03:46,799 --> 00:03:49,379
usually more logical while Nas problems

101
00:03:49,379 --> 00:03:52,019
are usually more numerical the problem

102
00:03:52,019 --> 00:03:53,819
of automatically discovering

103
00:03:53,819 --> 00:03:55,920
decision-based attacks lies between

104
00:03:55,920 --> 00:03:57,659
these two fields

105
00:03:57,659 --> 00:03:59,879
in general synthesis program with

106
00:03:59,879 --> 00:04:01,500
control flow is an extremely hard

107
00:04:01,500 --> 00:04:03,540
problem when we study the implementation

108
00:04:03,540 --> 00:04:05,700
of two existing decision-based iterative

109
00:04:05,700 --> 00:04:07,860
attacks we found that they share quite

110
00:04:07,860 --> 00:04:09,780
similar control flow the main difference

111
00:04:09,780 --> 00:04:12,180
lies in a loop free code segment and

112
00:04:12,180 --> 00:04:14,280
this code segment use only a dozen of

113
00:04:14,280 --> 00:04:16,260
mathematical operations this

114
00:04:16,260 --> 00:04:18,540
observations gave us the iteration we

115
00:04:18,540 --> 00:04:20,519
can fix the control flow using an

116
00:04:20,519 --> 00:04:22,620
algorithm template and search for the

117
00:04:22,620 --> 00:04:25,560
loop free code segment only in this work

118
00:04:25,560 --> 00:04:27,720
we follow the general methodology used

119
00:04:27,720 --> 00:04:29,699
by programming synthesis and the nas

120
00:04:29,699 --> 00:04:31,860
first we Define the search space

121
00:04:31,860 --> 00:04:33,900
consisting of programs for our problem

122
00:04:33,900 --> 00:04:36,479
then design a search method to explore

123
00:04:36,479 --> 00:04:39,180
this search space finally we Define

124
00:04:39,180 --> 00:04:41,639
evaluation method so that we can tell

125
00:04:41,639 --> 00:04:43,860
good programs from bad ones in the

126
00:04:43,860 --> 00:04:45,720
search space

127
00:04:45,720 --> 00:04:48,120
in this work we use the random work

128
00:04:48,120 --> 00:04:50,340
framework for the L2 decision-based

129
00:04:50,340 --> 00:04:51,960
attacks purpose in the boundary attack

130
00:04:51,960 --> 00:04:53,820
and used by nearly all later

131
00:04:53,820 --> 00:04:56,280
decision-based attacks the random work

132
00:04:56,280 --> 00:04:59,040
process starts as an adversary example

133
00:04:59,040 --> 00:05:01,080
we can obtain this as a service starting

134
00:05:01,080 --> 00:05:04,020
point easily by adding large noise to

135
00:05:04,020 --> 00:05:06,540
the original image at each random work

136
00:05:06,540 --> 00:05:09,000
step the algorithm invokes the generous

137
00:05:09,000 --> 00:05:11,220
function which returns next point to

138
00:05:11,220 --> 00:05:13,860
work to when the next point is also an

139
00:05:13,860 --> 00:05:16,320
adversary example and is closer to the

140
00:05:16,320 --> 00:05:18,300
original image than the best of zero

141
00:05:18,300 --> 00:05:21,000
example we already found then we updated

142
00:05:21,000 --> 00:05:23,400
this new Point as our best adversary

143
00:05:23,400 --> 00:05:26,280
example if it is not as a serial then

144
00:05:26,280 --> 00:05:28,979
try again the general function except

145
00:05:28,979 --> 00:05:31,320
two arguments the best as the server

146
00:05:31,320 --> 00:05:34,259
example X we currently found and the

147
00:05:34,259 --> 00:05:36,900
original image x0

148
00:05:36,900 --> 00:05:39,300
based on the random work framework we

149
00:05:39,300 --> 00:05:40,860
can only search for the generate

150
00:05:40,860 --> 00:05:43,259
function designing search space is to

151
00:05:43,259 --> 00:05:45,120
trade off between expressiveness and

152
00:05:45,120 --> 00:05:47,880
complexity we design a DSL for our

153
00:05:47,880 --> 00:05:50,160
problem then we Define our search space

154
00:05:50,160 --> 00:05:53,340
as programs in this DSL this DSL

155
00:05:53,340 --> 00:05:55,860
contains only 10 basic scalar and Vector

156
00:05:55,860 --> 00:05:58,199
mathematical operations it does not

157
00:05:58,199 --> 00:06:00,600
support control flow we also designed

158
00:06:00,600 --> 00:06:02,580
the program to accept an extra argument

159
00:06:02,580 --> 00:06:05,280
and it is a standard gaussian noise to

160
00:06:05,280 --> 00:06:07,020
provide Randomness to the generated

161
00:06:07,020 --> 00:06:10,020
function this DSL provides enough

162
00:06:10,020 --> 00:06:12,240
expressiveness for our pipeline in a

163
00:06:12,240 --> 00:06:14,400
sense that it can express the boundary

164
00:06:14,400 --> 00:06:16,440
attacks generated function

165
00:06:16,440 --> 00:06:18,720
to explore the research space we design

166
00:06:18,720 --> 00:06:20,759
a render search method combined with two

167
00:06:20,759 --> 00:06:23,039
pulling techniques and two priors the

168
00:06:23,039 --> 00:06:24,900
first pairing techniques is input check

169
00:06:24,900 --> 00:06:27,240
we filter Out programs not using all

170
00:06:27,240 --> 00:06:30,120
inputs the second is distance test the

171
00:06:30,120 --> 00:06:31,800
generate function needs to reduce the

172
00:06:31,800 --> 00:06:33,780
distance between a dozero example and

173
00:06:33,780 --> 00:06:36,360
original example as required by the

174
00:06:36,360 --> 00:06:38,880
random work framework we also generate

175
00:06:38,880 --> 00:06:41,639
programs with less unused statements and

176
00:06:41,639 --> 00:06:43,740
add three predefined statement to the

177
00:06:43,740 --> 00:06:45,780
program since nearly all existing

178
00:06:45,780 --> 00:06:48,120
attacks would use them as for program

179
00:06:48,120 --> 00:06:51,120
evaluation methods usually we would run

180
00:06:51,120 --> 00:06:52,919
large-scale experiments to evaluate

181
00:06:52,919 --> 00:06:55,800
attacks however this kind of evaluation

182
00:06:55,800 --> 00:06:59,160
is too computational costly instead we

183
00:06:59,160 --> 00:07:01,199
use a small and advanced efficient at

184
00:07:01,199 --> 00:07:03,479
binary classifier on civil 10 data set

185
00:07:03,479 --> 00:07:06,300
and we only evaluate programs to attack

186
00:07:06,300 --> 00:07:09,180
a handful of examples to save GPU time

187
00:07:09,180 --> 00:07:10,500
further

188
00:07:10,500 --> 00:07:13,139
as for the metrics to evaluate programs

189
00:07:13,139 --> 00:07:15,600
we use the ratio of the distance between

190
00:07:15,600 --> 00:07:17,759
adversary example and the original image

191
00:07:17,759 --> 00:07:19,919
to the distance between starting point

192
00:07:19,919 --> 00:07:22,919
and the original image lower ratio means

193
00:07:22,919 --> 00:07:24,440
better program

194
00:07:24,440 --> 00:07:26,819
decision-based iterative attacks needs

195
00:07:26,819 --> 00:07:29,160
to run for numerous steps to work to

196
00:07:29,160 --> 00:07:31,259
reduce computational costs we first

197
00:07:31,259 --> 00:07:33,360
evaluate programs for small number of

198
00:07:33,360 --> 00:07:35,400
steps and only evaluates the best

199
00:07:35,400 --> 00:07:37,620
program in each batch for larger number

200
00:07:37,620 --> 00:07:39,419
of steps

201
00:07:39,419 --> 00:07:42,180
we implemented a prototype of Auto da

202
00:07:42,180 --> 00:07:44,099
from scratch the core functionality of

203
00:07:44,099 --> 00:07:46,319
searching for programs is implemented in

204
00:07:46,319 --> 00:07:49,560
about 4000 slice of C plus plus this

205
00:07:49,560 --> 00:07:51,720
prototype have two modules the program

206
00:07:51,720 --> 00:07:54,120
generator generates programs with the

207
00:07:54,120 --> 00:07:56,880
two priors and filter out bad programs

208
00:07:56,880 --> 00:07:58,860
using the input check and distance test

209
00:07:58,860 --> 00:08:01,860
the program evaluator evaluates programs

210
00:08:01,860 --> 00:08:03,599
against the classifying GPU

211
00:08:03,599 --> 00:08:06,360
Communications between CPU and GPU tasks

212
00:08:06,360 --> 00:08:08,759
are done asynchronously in large batches

213
00:08:08,759 --> 00:08:11,639
to achieve enough performance we run

214
00:08:11,639 --> 00:08:13,979
this prototype to search for programs we

215
00:08:13,979 --> 00:08:16,919
organize this experiment as 15 runs each

216
00:08:16,919 --> 00:08:19,860
run allows 500 million queries to the

217
00:08:19,860 --> 00:08:22,800
classifier more than 100 billion random

218
00:08:22,800 --> 00:08:24,960
programs are generated most of them

219
00:08:24,960 --> 00:08:26,940
failed in the impulse check and distance

220
00:08:26,940 --> 00:08:29,819
test this shows the effectiveness of our

221
00:08:29,819 --> 00:08:32,700
program techniques we plot the lowest L2

222
00:08:32,700 --> 00:08:34,620
Distortion ratios found in each of the

223
00:08:34,620 --> 00:08:37,320
15 rounds in this figure since the top

224
00:08:37,320 --> 00:08:40,020
two programs ratios are quite close we

225
00:08:40,020 --> 00:08:41,760
select them both for further Benchmark

226
00:08:41,760 --> 00:08:44,219
experiments we call these two programs

227
00:08:44,219 --> 00:08:46,980
as Auto da first and second

228
00:08:46,980 --> 00:08:50,040
after discarding a used statements these

229
00:08:50,040 --> 00:08:51,899
two programs only contain 10 and 13

230
00:08:51,899 --> 00:08:53,700
statements we are surprised that they

231
00:08:53,700 --> 00:08:55,860
are quite short we benchmarked our

232
00:08:55,860 --> 00:08:57,899
attacks against four expert design

233
00:08:57,899 --> 00:09:00,240
decision-based attacks including two

234
00:09:00,240 --> 00:09:03,060
strong attacks hsj attack and a synopt

235
00:09:03,060 --> 00:09:05,459
attack we use two Benchmark metrics

236
00:09:05,459 --> 00:09:08,100
widely used by existing work the L2

237
00:09:08,100 --> 00:09:10,440
Distortion versus queries curve and the

238
00:09:10,440 --> 00:09:13,019
attack success rate versus queries curve

239
00:09:13,019 --> 00:09:15,180
in the first group of experiments we

240
00:09:15,180 --> 00:09:16,980
Benchmark these attacks on four widely

241
00:09:16,980 --> 00:09:19,680
used models for silver 10 data set as

242
00:09:19,680 --> 00:09:21,720
you can see from the results Arrow

243
00:09:21,720 --> 00:09:23,399
attacks are much stronger than the

244
00:09:23,399 --> 00:09:25,140
boundary attack than the evolutionary

245
00:09:25,140 --> 00:09:27,600
attack our attacks converge faster

246
00:09:27,600 --> 00:09:30,839
before about 7 000 queries will converge

247
00:09:30,839 --> 00:09:33,000
to slightly worse adversarial examples

248
00:09:33,000 --> 00:09:36,140
than sign after attacks afterwards

249
00:09:36,140 --> 00:09:38,760
considering our DSL is only able to

250
00:09:38,760 --> 00:09:41,160
express the boundary attack and not able

251
00:09:41,160 --> 00:09:43,860
to express the stronger hsj attack and

252
00:09:43,860 --> 00:09:47,760
sign up to attack this is impressive

253
00:09:47,760 --> 00:09:49,860
this table provides some numerical

254
00:09:49,860 --> 00:09:52,740
results the auto da first achieved only

255
00:09:52,740 --> 00:09:54,899
less than one percent worse L2

256
00:09:54,899 --> 00:09:57,420
Distortion than the sign-opt attack at

257
00:09:57,420 --> 00:09:59,220
20 000 queries

258
00:09:59,220 --> 00:10:01,440
we also benchmarked our attacks against

259
00:10:01,440 --> 00:10:03,959
models on larger data sets and defensive

260
00:10:03,959 --> 00:10:06,720
models including two imagenet models and

261
00:10:06,720 --> 00:10:09,360
two adversarial Trend models the results

262
00:10:09,360 --> 00:10:12,180
are similar to Siva 10.

263
00:10:12,180 --> 00:10:15,660
to conclude we present Auto da a noble

264
00:10:15,660 --> 00:10:17,480
solution to automatically discover

265
00:10:17,480 --> 00:10:19,860
decision-based iterative adversarial

266
00:10:19,860 --> 00:10:22,860
attacks we propose a way to construct a

267
00:10:22,860 --> 00:10:24,779
search space for decision-based attacks

268
00:10:24,779 --> 00:10:27,480
and then effective search algorithm we

269
00:10:27,480 --> 00:10:29,940
implemented a prototype of Auto DNA and

270
00:10:29,940 --> 00:10:32,820
run experiments the discovered attacks

271
00:10:32,820 --> 00:10:34,800
are simple yet powerful they should

272
00:10:34,800 --> 00:10:36,959
comparable performance with total expert

273
00:10:36,959 --> 00:10:39,480
design attacks suggesting this expert

274
00:10:39,480 --> 00:10:41,820
design attacks are near optimal in our

275
00:10:41,820 --> 00:10:46,100
search space thanks for listening

