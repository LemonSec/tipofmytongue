1
00:00:10,320 --> 00:00:12,240
so i'll be talking about stealing

2
00:00:12,240 --> 00:00:14,240
machine learning models via prediction

3
00:00:14,240 --> 00:00:17,440
apis this is joint work with colleagues

4
00:00:17,440 --> 00:00:20,640
from cornell and unc

5
00:00:20,640 --> 00:00:22,720
so as a small introduction let me talk

6
00:00:22,720 --> 00:00:25,199
about supervised machine learning the

7
00:00:25,199 --> 00:00:27,359
way we'll deal with in this talk so

8
00:00:27,359 --> 00:00:29,279
suppose you have

9
00:00:29,279 --> 00:00:31,439
a set of data where each sample is

10
00:00:31,439 --> 00:00:33,520
labeled with a particular class

11
00:00:33,520 --> 00:00:35,920
and you're going to train a predictive

12
00:00:35,920 --> 00:00:38,559
model over this data and when you query

13
00:00:38,559 --> 00:00:41,040
this model with a new input

14
00:00:41,040 --> 00:00:43,120
you're going to get a prediction so a

15
00:00:43,120 --> 00:00:45,600
class label and in some cases maybe more

16
00:00:45,600 --> 00:00:48,160
granular information like a probability

17
00:00:48,160 --> 00:00:50,480
score for each class

18
00:00:50,480 --> 00:00:52,399
and you can then use this model in some

19
00:00:52,399 --> 00:00:54,879
larger application or maybe publish it

20
00:00:54,879 --> 00:00:57,280
for others to use

21
00:00:57,280 --> 00:01:00,160
and this publishing of machine learning

22
00:01:00,160 --> 00:01:02,719
models is actually something that many

23
00:01:02,719 --> 00:01:03,600
um

24
00:01:03,600 --> 00:01:05,519
machine learning as a service platforms

25
00:01:05,519 --> 00:01:07,520
are starting to advertise

26
00:01:07,520 --> 00:01:10,960
and in such a service a user will upload

27
00:01:10,960 --> 00:01:12,960
sort of outsource the training of a

28
00:01:12,960 --> 00:01:15,759
model over her data to a cloud service

29
00:01:15,759 --> 00:01:17,680
and other users can then interact with

30
00:01:17,680 --> 00:01:19,439
this model essentially

31
00:01:19,439 --> 00:01:21,759
as a black box through some particular

32
00:01:21,759 --> 00:01:23,280
prediction api

33
00:01:23,280 --> 00:01:25,200
and in some cases

34
00:01:25,200 --> 00:01:28,400
this user will even pay a certain fee

35
00:01:28,400 --> 00:01:30,320
per query that he makes

36
00:01:30,320 --> 00:01:31,840
to the model owner

37
00:01:31,840 --> 00:01:33,920
and there's essentially two conflicting

38
00:01:33,920 --> 00:01:35,600
goals at work here so on the one hand

39
00:01:35,600 --> 00:01:38,720
you want this prediction api to be as

40
00:01:38,720 --> 00:01:40,320
rich and as available as possible

41
00:01:40,320 --> 00:01:42,640
because well it should

42
00:01:42,640 --> 00:01:44,159
warrant the fact that someone is going

43
00:01:44,159 --> 00:01:45,759
to pay for it

44
00:01:45,759 --> 00:01:46,560
but

45
00:01:46,560 --> 00:01:48,079
well if you're going to monetize this

46
00:01:48,079 --> 00:01:49,759
model it should also you should make

47
00:01:49,759 --> 00:01:50,799
sure that it's going to remain

48
00:01:50,799 --> 00:01:52,159
confidential

49
00:01:52,159 --> 00:01:54,240
and in some cases we'll talk about as

50
00:01:54,240 --> 00:01:55,840
well you might want to ensure that the

51
00:01:55,840 --> 00:01:57,840
data on which this model was trained

52
00:01:57,840 --> 00:01:59,680
does not leak either because it might be

53
00:01:59,680 --> 00:02:00,880
sensitive

54
00:02:00,880 --> 00:02:01,920
um

55
00:02:01,920 --> 00:02:04,479
these are just a few examples of popular

56
00:02:04,479 --> 00:02:06,479
machine learning as a service platforms

57
00:02:06,479 --> 00:02:08,720
in this talk and in our paper will focus

58
00:02:08,720 --> 00:02:10,080
mostly on

59
00:02:10,080 --> 00:02:12,480
amazon and big ml

60
00:02:12,480 --> 00:02:14,959
uh the latter is quite interesting in

61
00:02:14,959 --> 00:02:16,720
this context because they actually take

62
00:02:16,720 --> 00:02:19,680
this monetization of models or of

63
00:02:19,680 --> 00:02:21,760
everything actually to a

64
00:02:21,760 --> 00:02:23,920
higher level and they allow users to

65
00:02:23,920 --> 00:02:26,160
sell data sets or trained models or

66
00:02:26,160 --> 00:02:28,560
prediction queries to other users in the

67
00:02:28,560 --> 00:02:30,640
system

68
00:02:30,640 --> 00:02:33,200
so in this setting we consider a new

69
00:02:33,200 --> 00:02:34,879
type of attack we call a model

70
00:02:34,879 --> 00:02:36,400
extraction attack

71
00:02:36,400 --> 00:02:38,319
and in this attack an adversary

72
00:02:38,319 --> 00:02:40,480
interacts with a model in the cloud

73
00:02:40,480 --> 00:02:42,400
through its prediction api and then

74
00:02:42,400 --> 00:02:45,519
tries to reconstruct a local copy

75
00:02:45,519 --> 00:02:47,920
of that model and we want this local

76
00:02:47,920 --> 00:02:50,560
copy to be very very close to the target

77
00:02:50,560 --> 00:02:52,959
and by close here you can think of

78
00:02:52,959 --> 00:02:55,599
something like 99.9

79
00:02:55,599 --> 00:02:58,239
agreement um in classification between

80
00:02:58,239 --> 00:02:59,840
the two models so they're

81
00:02:59,840 --> 00:03:02,080
basically identical for most practical

82
00:03:02,080 --> 00:03:04,319
tasks

83
00:03:04,319 --> 00:03:06,239
a few applications of model extraction

84
00:03:06,239 --> 00:03:08,480
well the simplest could be that once you

85
00:03:08,480 --> 00:03:09,920
have the model locally well you don't

86
00:03:09,920 --> 00:03:11,760
have to pay to use it anymore so you

87
00:03:11,760 --> 00:03:13,840
sort of avoid this monetization if

88
00:03:13,840 --> 00:03:16,560
extracting the model is cheaper than

89
00:03:16,560 --> 00:03:18,239
what you would pay to use it for all the

90
00:03:18,239 --> 00:03:19,760
queries you want to make

91
00:03:19,760 --> 00:03:21,680
and we'll also

92
00:03:21,680 --> 00:03:23,680
talk a bit about how you might use an

93
00:03:23,680 --> 00:03:27,680
extracted model as a stand-in um for

94
00:03:27,680 --> 00:03:30,480
a white box attacks over a model and

95
00:03:30,480 --> 00:03:32,480
we'll see an example of this for uh

96
00:03:32,480 --> 00:03:34,159
privacy uh

97
00:03:34,159 --> 00:03:36,720
preserving attacks some parentheses

98
00:03:36,720 --> 00:03:38,319
dangling there

99
00:03:38,319 --> 00:03:39,920
um

100
00:03:39,920 --> 00:03:41,760
so if we take a step back

101
00:03:41,760 --> 00:03:43,760
and look at what we're actually trying

102
00:03:43,760 --> 00:03:45,840
to achieve with these attacks

103
00:03:45,840 --> 00:03:47,840
one might ask well isn't this just

104
00:03:47,840 --> 00:03:50,239
machine learning because i mean we're

105
00:03:50,239 --> 00:03:51,760
interacting with model and trying to

106
00:03:51,760 --> 00:03:54,319
replicate its input output behavior

107
00:03:54,319 --> 00:03:56,239
it's basically machine learning

108
00:03:56,239 --> 00:03:57,280
um

109
00:03:57,280 --> 00:03:59,040
there's two ways to look at it

110
00:03:59,040 --> 00:04:01,439
essentially if the model when you query

111
00:04:01,439 --> 00:04:03,680
it only replies with a class label so

112
00:04:03,680 --> 00:04:05,120
you give it an image and it tells you

113
00:04:05,120 --> 00:04:06,959
this is bob and that's it

114
00:04:06,959 --> 00:04:09,200
um then yeah this is a setting that's

115
00:04:09,200 --> 00:04:10,879
usually called learning with membership

116
00:04:10,879 --> 00:04:12,959
queries and it's been heavily studied in

117
00:04:12,959 --> 00:04:14,319
the machine learning and theory

118
00:04:14,319 --> 00:04:16,478
community and there's been a few works

119
00:04:16,478 --> 00:04:18,399
that showed how you might learn or

120
00:04:18,399 --> 00:04:20,079
extract some

121
00:04:20,079 --> 00:04:22,479
specific model classes uh in this

122
00:04:22,479 --> 00:04:23,919
setting

123
00:04:23,919 --> 00:04:24,639
but

124
00:04:24,639 --> 00:04:26,400
we find that this setting of machine

125
00:04:26,400 --> 00:04:28,080
learning as a service is actually quite

126
00:04:28,080 --> 00:04:30,320
different because these prediction apis

127
00:04:30,320 --> 00:04:32,400
tend to return much more information

128
00:04:32,400 --> 00:04:34,560
than just a class label and so we're in

129
00:04:34,560 --> 00:04:36,560
a bit of a different setting here than

130
00:04:36,560 --> 00:04:39,040
in traditional machine learning

131
00:04:39,040 --> 00:04:40,080
um

132
00:04:40,080 --> 00:04:42,080
let me quickly go over some of our main

133
00:04:42,080 --> 00:04:44,320
results before i dive into the details

134
00:04:44,320 --> 00:04:45,199
so

135
00:04:45,199 --> 00:04:47,759
we show efficient model extraction

136
00:04:47,759 --> 00:04:50,240
attacks against a number of popular

137
00:04:50,240 --> 00:04:52,960
model types that people might use

138
00:04:52,960 --> 00:04:55,520
and we also show that in cases where

139
00:04:55,520 --> 00:04:57,759
the adversary might not know exactly

140
00:04:57,759 --> 00:05:00,160
what model type he's dealing with

141
00:05:00,160 --> 00:05:02,880
or what the features might be

142
00:05:02,880 --> 00:05:04,560
you can still actually reverse engineer

143
00:05:04,560 --> 00:05:07,039
this process in a number of cases

144
00:05:07,039 --> 00:05:09,600
and our attacks are extremely successful

145
00:05:09,600 --> 00:05:11,759
so in a lot of cases we extract models

146
00:05:11,759 --> 00:05:13,600
that are virtually indist

147
00:05:13,600 --> 00:05:16,080
indistinguishable from the targets and

148
00:05:16,080 --> 00:05:18,080
the attacks are very efficient so with a

149
00:05:18,080 --> 00:05:19,919
few hundreds of thousands of queries to

150
00:05:19,919 --> 00:05:21,520
the target

151
00:05:21,520 --> 00:05:23,680
model you can reconstruct this local

152
00:05:23,680 --> 00:05:24,960
copy

153
00:05:24,960 --> 00:05:26,880
we demonstrate that these attacks work

154
00:05:26,880 --> 00:05:29,680
in practice on the services of amazon

155
00:05:29,680 --> 00:05:31,520
and big ml

156
00:05:31,520 --> 00:05:32,880
and

157
00:05:32,880 --> 00:05:35,520
let me just talk about one application

158
00:05:35,520 --> 00:05:37,759
of model extraction that we that i'll

159
00:05:37,759 --> 00:05:39,199
mention in this talk which is in the

160
00:05:39,199 --> 00:05:40,560
context of

161
00:05:40,560 --> 00:05:42,880
um model inversion attacks and this

162
00:05:42,880 --> 00:05:45,120
these were presented by frederickson and

163
00:05:45,120 --> 00:05:47,680
co-authors at ccs last year is a class

164
00:05:47,680 --> 00:05:50,000
of inference attacks on

165
00:05:50,000 --> 00:05:51,680
training data privacy so here in the

166
00:05:51,680 --> 00:05:54,320
context of a facial recognition software

167
00:05:54,320 --> 00:05:56,479
so you have the training data um on the

168
00:05:56,479 --> 00:05:58,400
right and then on the left an image that

169
00:05:58,400 --> 00:06:01,120
was reconstructed after an attack and we

170
00:06:01,120 --> 00:06:03,199
show that if you first extract the model

171
00:06:03,199 --> 00:06:05,120
and then run this inversion attack in a

172
00:06:05,120 --> 00:06:06,560
sort of white box setting you can

173
00:06:06,560 --> 00:06:08,880
actually get more

174
00:06:08,880 --> 00:06:10,960
performance an attack that is more

175
00:06:10,960 --> 00:06:15,199
scalable i'll come back to this later

176
00:06:15,199 --> 00:06:18,479
so let me start with a simple example of

177
00:06:18,479 --> 00:06:20,240
a model extraction sort of the simplest

178
00:06:20,240 --> 00:06:21,840
you could think of and so here we

179
00:06:21,840 --> 00:06:23,440
consider a

180
00:06:23,440 --> 00:06:25,440
facial recognition task so you have

181
00:06:25,440 --> 00:06:27,360
images of alice and bob and you train a

182
00:06:27,360 --> 00:06:28,880
simple model that will try to

183
00:06:28,880 --> 00:06:31,680
distinguish these images and here we

184
00:06:31,680 --> 00:06:34,400
consider a simple binary

185
00:06:34,400 --> 00:06:37,039
logistic regression model and so

186
00:06:37,039 --> 00:06:39,840
this model just applies a logistic

187
00:06:39,840 --> 00:06:42,400
function it's this exponential inverse

188
00:06:42,400 --> 00:06:44,800
function of the inputs

189
00:06:44,800 --> 00:06:46,880
where the parameters w and b are

190
00:06:46,880 --> 00:06:49,039
essentially chosen at during the

191
00:06:49,039 --> 00:06:52,240
training phase so as to minimize the

192
00:06:52,240 --> 00:06:55,039
expected classification error and these

193
00:06:55,039 --> 00:06:58,560
parameters well make up the model

194
00:06:58,560 --> 00:07:01,280
and the output of this function can be

195
00:07:01,280 --> 00:07:03,360
interpreted as a probability

196
00:07:03,360 --> 00:07:06,240
of the output being of the input being

197
00:07:06,240 --> 00:07:08,319
either an image of alice or bob you can

198
00:07:08,319 --> 00:07:11,280
then convert this into a class label

199
00:07:11,280 --> 00:07:13,599
and this generalizes quite naturally to

200
00:07:13,599 --> 00:07:15,759
more than two classes with what's called

201
00:07:15,759 --> 00:07:19,280
a multinomial logistic regression

202
00:07:19,280 --> 00:07:22,000
so how might one extract such a model

203
00:07:22,000 --> 00:07:24,240
well as i said previously you want to

204
00:07:24,240 --> 00:07:26,160
interact with this prediction api you

205
00:07:26,160 --> 00:07:28,639
give it inputs x you get this output f

206
00:07:28,639 --> 00:07:29,759
of x

207
00:07:29,759 --> 00:07:32,639
and the crucial assumption here is that

208
00:07:32,639 --> 00:07:34,720
this api will actually give you this

209
00:07:34,720 --> 00:07:36,880
exact probability rather than just a

210
00:07:36,880 --> 00:07:39,919
class label and this is essentially what

211
00:07:39,919 --> 00:07:42,160
all i think of the machine learning

212
00:07:42,160 --> 00:07:44,800
services we looked at actually do

213
00:07:44,800 --> 00:07:46,560
and then well it's a simple matter of

214
00:07:46,560 --> 00:07:48,400
rearranging terms and you get a linear

215
00:07:48,400 --> 00:07:50,720
equation in the unknown parameters that

216
00:07:50,720 --> 00:07:52,160
make up your model

217
00:07:52,160 --> 00:07:55,840
so the takeaway you do a bunch of random

218
00:07:55,840 --> 00:07:58,400
queries essentially one per

219
00:07:58,400 --> 00:08:00,879
dimension or a number of parameters in

220
00:08:00,879 --> 00:08:03,039
your in your model and you get a nice

221
00:08:03,039 --> 00:08:05,039
linear system of equation everyone knows

222
00:08:05,039 --> 00:08:06,560
how to solve these

223
00:08:06,560 --> 00:08:09,199
and you extract a model that up to maybe

224
00:08:09,199 --> 00:08:12,400
numerical approximations is uh identical

225
00:08:12,400 --> 00:08:15,199
to the target

226
00:08:15,199 --> 00:08:17,039
so we call this type of attack

227
00:08:17,039 --> 00:08:19,919
generically an equation solving attack

228
00:08:19,919 --> 00:08:21,919
we show that it can generalize to more

229
00:08:21,919 --> 00:08:24,960
complex model classes such as sort of

230
00:08:24,960 --> 00:08:27,440
general neural networks

231
00:08:27,440 --> 00:08:29,039
where the idea is essentially the same

232
00:08:29,039 --> 00:08:32,000
so you take a bunch of random inputs

233
00:08:32,000 --> 00:08:34,240
query your model get the corresponding

234
00:08:34,240 --> 00:08:36,719
output so these exact

235
00:08:36,719 --> 00:08:39,279
probability values from the model

236
00:08:39,279 --> 00:08:41,360
and then again you can set up

237
00:08:41,360 --> 00:08:43,039
an equation system in the unknown

238
00:08:43,039 --> 00:08:45,200
parameters of the model here we assume

239
00:08:45,200 --> 00:08:47,920
that the structure of the model

240
00:08:47,920 --> 00:08:49,200
is known

241
00:08:49,200 --> 00:08:51,360
and well now the only difference

242
00:08:51,360 --> 00:08:53,040
compared with the previous case is that

243
00:08:53,040 --> 00:08:54,959
this equation system is non-linear so

244
00:08:54,959 --> 00:08:56,560
it's a bit more complex to solve but

245
00:08:56,560 --> 00:08:57,600
there's

246
00:08:57,600 --> 00:08:59,680
very well known techniques from the

247
00:08:59,680 --> 00:09:01,920
optimize like optimization techniques

248
00:09:01,920 --> 00:09:03,519
that allow you to solve these kind of

249
00:09:03,519 --> 00:09:05,839
systems and this essentially corresponds

250
00:09:05,839 --> 00:09:08,080
to a kind of noiseless machine learning

251
00:09:08,080 --> 00:09:09,600
where you're essentially using the exact

252
00:09:09,600 --> 00:09:11,120
same algorithms you would use to do

253
00:09:11,120 --> 00:09:12,480
machine learning it's just that you have

254
00:09:12,480 --> 00:09:14,720
no noise in your system the outputs that

255
00:09:14,720 --> 00:09:17,120
you get from this cloud

256
00:09:17,120 --> 00:09:19,440
service are well an exact mathematical

257
00:09:19,440 --> 00:09:20,640
function

258
00:09:20,640 --> 00:09:22,399
of the inputs

259
00:09:22,399 --> 00:09:25,279
and so we demonstrate such attacks on a

260
00:09:25,279 --> 00:09:27,440
number of um models we train so

261
00:09:27,440 --> 00:09:29,760
multinomial regressions and some deeper

262
00:09:29,760 --> 00:09:31,279
neural networks

263
00:09:31,279 --> 00:09:32,160
and

264
00:09:32,160 --> 00:09:34,959
in all cases we find that we extract

265
00:09:34,959 --> 00:09:36,640
models that have extremely high

266
00:09:36,640 --> 00:09:38,959
agreement with the targets

267
00:09:38,959 --> 00:09:41,200
and we only need a few hundreds of

268
00:09:41,200 --> 00:09:42,640
thousands of

269
00:09:42,640 --> 00:09:45,200
of online queries depending on the size

270
00:09:45,200 --> 00:09:46,640
of the model

271
00:09:46,640 --> 00:09:50,160
we're trying to extract

272
00:09:50,160 --> 00:09:52,080
now having seen how these equation

273
00:09:52,080 --> 00:09:55,040
solving attacks work sort of on paper um

274
00:09:55,040 --> 00:09:58,080
let's now turn to uh real attacks on an

275
00:09:58,080 --> 00:10:00,160
online system so in our paper we

276
00:10:00,160 --> 00:10:02,959
considered aws for this

277
00:10:02,959 --> 00:10:05,440
and here we'll need to sort of revisit

278
00:10:05,440 --> 00:10:07,519
some of the assumptions that we used in

279
00:10:07,519 --> 00:10:08,560
um

280
00:10:08,560 --> 00:10:10,399
these equation solving attacks basically

281
00:10:10,399 --> 00:10:12,160
about what kind of information is

282
00:10:12,160 --> 00:10:14,959
actually available to the adversary

283
00:10:14,959 --> 00:10:17,440
so let's go through this pipeline

284
00:10:17,440 --> 00:10:20,560
in a bit more detail so first the user

285
00:10:20,560 --> 00:10:23,440
will upload his training data

286
00:10:23,440 --> 00:10:24,880
to amazon

287
00:10:24,880 --> 00:10:27,680
and then the cloud service will first

288
00:10:27,680 --> 00:10:30,560
apply a certain number of feature

289
00:10:30,560 --> 00:10:32,399
extractions and these are essentially

290
00:10:32,399 --> 00:10:35,120
ways to select the dimensions of the

291
00:10:35,120 --> 00:10:37,600
inputs that are eventually fed into the

292
00:10:37,600 --> 00:10:40,320
the model and this process is automated

293
00:10:40,320 --> 00:10:41,120
it's

294
00:10:41,120 --> 00:10:45,120
not uh fully documented by amazon but

295
00:10:45,120 --> 00:10:46,640
essentially what it ends up with is that

296
00:10:46,640 --> 00:10:49,040
the adversary doesn't know a priori

297
00:10:49,040 --> 00:10:51,120
exactly which features

298
00:10:51,120 --> 00:10:53,760
are actually used by the by the model

299
00:10:53,760 --> 00:10:55,120
um

300
00:10:55,120 --> 00:10:57,760
he doesn't even know exactly what type

301
00:10:57,760 --> 00:11:00,079
of model amazon will train because there

302
00:11:00,079 --> 00:11:01,920
there's a number of different choices

303
00:11:01,920 --> 00:11:04,480
that amazon might make

304
00:11:04,480 --> 00:11:06,800
a small number i mean this is also not

305
00:11:06,800 --> 00:11:09,360
fully documented but

306
00:11:09,360 --> 00:11:11,200
they say somewhat what they're going to

307
00:11:11,200 --> 00:11:12,839
train on your

308
00:11:12,839 --> 00:11:15,600
data and so then you get access to this

309
00:11:15,600 --> 00:11:17,360
prediction api that the user can

310
00:11:17,360 --> 00:11:20,000
interact with when you send it a query

311
00:11:20,000 --> 00:11:21,519
it's going to apply the cloud is going

312
00:11:21,519 --> 00:11:23,440
to apply the same feature extraction to

313
00:11:23,440 --> 00:11:25,120
your query then feed these features to

314
00:11:25,120 --> 00:11:26,640
the model

315
00:11:26,640 --> 00:11:28,959
and send you back a class label as well

316
00:11:28,959 --> 00:11:31,760
as these exact confidence scores

317
00:11:31,760 --> 00:11:32,720
um

318
00:11:32,720 --> 00:11:36,079
one feature of uh amazon service that we

319
00:11:36,079 --> 00:11:38,160
that is very useful actually in a number

320
00:11:38,160 --> 00:11:40,560
of our attacks is that they support

321
00:11:40,560 --> 00:11:42,640
um partial inputs so what this means is

322
00:11:42,640 --> 00:11:45,440
that you can send a query x where some

323
00:11:45,440 --> 00:11:48,720
of the dimensions are left unspecified

324
00:11:48,720 --> 00:11:50,399
so you could think of you send an image

325
00:11:50,399 --> 00:11:52,560
where some pixels are just don't exist

326
00:11:52,560 --> 00:11:54,079
they have no value

327
00:11:54,079 --> 00:11:56,240
and what the cloud will do is that it

328
00:11:56,240 --> 00:11:56,959
will

329
00:11:56,959 --> 00:11:58,160
um

330
00:11:58,160 --> 00:12:00,399
set all the features that are derived

331
00:12:00,399 --> 00:12:02,800
from this input dimension to zero and

332
00:12:02,800 --> 00:12:05,200
this is actually very useful uh

333
00:12:05,200 --> 00:12:07,279
uh as all

334
00:12:07,279 --> 00:12:11,680
um detail now um so this is what a real

335
00:12:11,680 --> 00:12:14,160
attack on aws looks like i'm not going

336
00:12:14,160 --> 00:12:16,079
to go into too many details about the

337
00:12:16,079 --> 00:12:18,320
feature extraction process you can see

338
00:12:18,320 --> 00:12:20,240
more about this in our paper but

339
00:12:20,240 --> 00:12:23,760
essentially amazon will apply these two

340
00:12:23,760 --> 00:12:25,200
feature extractions which are called

341
00:12:25,200 --> 00:12:27,680
quantile binning and one hot encoding

342
00:12:27,680 --> 00:12:30,000
and the essence is that well by actually

343
00:12:30,000 --> 00:12:31,519
abusing this

344
00:12:31,519 --> 00:12:33,839
ability to query partial inputs and get

345
00:12:33,839 --> 00:12:35,600
back confidence scores

346
00:12:35,600 --> 00:12:37,440
we show that in adverse we can fully

347
00:12:37,440 --> 00:12:40,000
reverse engineer which features will

348
00:12:40,000 --> 00:12:43,279
eventually be fed into the model

349
00:12:43,279 --> 00:12:44,880
and so we're sort of back into the

350
00:12:44,880 --> 00:12:46,240
setting where we can assume that the

351
00:12:46,240 --> 00:12:48,000
adversary actually knows the the set of

352
00:12:48,000 --> 00:12:49,760
features

353
00:12:49,760 --> 00:12:50,720
for the

354
00:12:50,720 --> 00:12:53,200
choice of models so here as well

355
00:12:53,200 --> 00:12:54,560
there are some

356
00:12:54,560 --> 00:12:56,160
choices that are

357
00:12:56,160 --> 00:12:58,560
left unspecified and that

358
00:12:58,560 --> 00:13:00,240
the adversary doesn't necessarily know

359
00:13:00,240 --> 00:13:02,160
exactly what type of model he's dealing

360
00:13:02,160 --> 00:13:03,120
with

361
00:13:03,120 --> 00:13:06,240
but here we find that a very crude brute

362
00:13:06,240 --> 00:13:08,560
force approach of just taking a set of

363
00:13:08,560 --> 00:13:10,560
plausible assumptions trying all of them

364
00:13:10,560 --> 00:13:12,560
until one works

365
00:13:12,560 --> 00:13:14,399
well ends up

366
00:13:14,399 --> 00:13:16,800
working and well once you know how

367
00:13:16,800 --> 00:13:18,000
amazon

368
00:13:18,000 --> 00:13:19,680
chooses the model then you can apply the

369
00:13:19,680 --> 00:13:22,480
same ideas to every attack

370
00:13:22,480 --> 00:13:25,120
um so there are some results we got for

371
00:13:25,120 --> 00:13:26,399
two

372
00:13:26,399 --> 00:13:28,480
classical classification problems for

373
00:13:28,480 --> 00:13:32,000
handwritten digits and u.s census data

374
00:13:32,000 --> 00:13:33,279
and so

375
00:13:33,279 --> 00:13:35,279
with a few hundreds or thousands of

376
00:13:35,279 --> 00:13:38,240
queries takes a couple of minutes and i

377
00:13:38,240 --> 00:13:40,000
mean a small price that you have to pay

378
00:13:40,000 --> 00:13:41,680
for each query

379
00:13:41,680 --> 00:13:42,639
we

380
00:13:42,639 --> 00:13:45,120
manage to reconstruct

381
00:13:45,120 --> 00:13:47,680
local models that are well have the

382
00:13:47,680 --> 00:13:50,079
exact same input output behavior as the

383
00:13:50,079 --> 00:13:52,560
targets

384
00:13:53,440 --> 00:13:56,079
so let me now talk a bit more about this

385
00:13:56,079 --> 00:13:58,639
uh one application of model inversion

386
00:13:58,639 --> 00:14:00,639
attacks that we looked at

387
00:14:00,639 --> 00:14:02,880
in the context of these model inversion

388
00:14:02,880 --> 00:14:04,959
attacks proposed by frederickson and his

389
00:14:04,959 --> 00:14:07,199
co-authors at ccs

390
00:14:07,199 --> 00:14:08,560
last year

391
00:14:08,560 --> 00:14:10,480
so the setting we consider here is as

392
00:14:10,480 --> 00:14:12,160
follows you have

393
00:14:12,160 --> 00:14:13,920
a facial recognition model that is

394
00:14:13,920 --> 00:14:16,720
trained over this at t faces data set so

395
00:14:16,720 --> 00:14:17,600
you have

396
00:14:17,600 --> 00:14:20,800
images of 40 different individuals in a

397
00:14:20,800 --> 00:14:22,480
training

398
00:14:22,480 --> 00:14:24,079
set and then you

399
00:14:24,079 --> 00:14:25,600
you're going to train a

400
00:14:25,600 --> 00:14:28,160
logistic model over this and well we'll

401
00:14:28,160 --> 00:14:29,199
first

402
00:14:29,199 --> 00:14:33,519
extract this model using the techniques

403
00:14:33,519 --> 00:14:36,399
i've talked about previously

404
00:14:36,399 --> 00:14:37,760
and

405
00:14:37,760 --> 00:14:40,959
then essentially we apply an inversion

406
00:14:40,959 --> 00:14:43,680
attack over this extracted model rather

407
00:14:43,680 --> 00:14:45,199
than applying this inversion attack

408
00:14:45,199 --> 00:14:46,399
directly

409
00:14:46,399 --> 00:14:49,360
over the black box cloud model the way

410
00:14:49,360 --> 00:14:52,079
it was done in this earlier work

411
00:14:52,079 --> 00:14:54,160
and this attack will

412
00:14:54,160 --> 00:14:56,320
attempt to recover

413
00:14:56,320 --> 00:14:58,160
the image of one of the individuals in

414
00:14:58,160 --> 00:15:00,000
the training set then you can repeat

415
00:15:00,000 --> 00:15:02,240
this well 40 times if you want to

416
00:15:02,240 --> 00:15:04,320
recover an image for each of these

417
00:15:04,320 --> 00:15:05,680
individuals

418
00:15:05,680 --> 00:15:07,519
and it's it's actually in this scaling

419
00:15:07,519 --> 00:15:09,600
of the attack that we find a nice

420
00:15:09,600 --> 00:15:10,839
improvement

421
00:15:10,839 --> 00:15:14,880
um so if you take the original attack as

422
00:15:14,880 --> 00:15:16,320
proposed by fredrickson and his

423
00:15:16,320 --> 00:15:18,959
co-authors and sort of just apply it in

424
00:15:18,959 --> 00:15:21,600
a black box fashion directly over the

425
00:15:21,600 --> 00:15:24,480
trained model in the cloud

426
00:15:24,480 --> 00:15:27,680
you need about 20 000 queries uh

427
00:15:27,680 --> 00:15:30,079
for one attack takes about 25 minutes

428
00:15:30,079 --> 00:15:32,800
with the network delay um and then if

429
00:15:32,800 --> 00:15:34,880
you want to reconstruct well every

430
00:15:34,880 --> 00:15:37,120
individual in the training set uh well

431
00:15:37,120 --> 00:15:39,600
you repeat this 40 times and so you get

432
00:15:39,600 --> 00:15:41,680
quite a large number of queries in the

433
00:15:41,680 --> 00:15:44,240
long time for the attack

434
00:15:44,240 --> 00:15:46,720
but you could also have a very high

435
00:15:46,720 --> 00:15:49,040
upfront cost by first running this

436
00:15:49,040 --> 00:15:51,440
extraction attack which requires

437
00:15:51,440 --> 00:15:53,360
quite a lot of queries it takes a long

438
00:15:53,360 --> 00:15:54,560
time because you're essentially building

439
00:15:54,560 --> 00:15:56,560
up this huge equation system and then

440
00:15:56,560 --> 00:15:59,120
solving it but once you've done that you

441
00:15:59,120 --> 00:16:01,600
have a white box model for which you can

442
00:16:01,600 --> 00:16:05,040
run any number of very cheap inversion

443
00:16:05,040 --> 00:16:06,959
attacks actually so

444
00:16:06,959 --> 00:16:09,040
doing these 40 attacks over a white box

445
00:16:09,040 --> 00:16:10,480
model is

446
00:16:10,480 --> 00:16:12,320
basically for free and so we end up with

447
00:16:12,320 --> 00:16:16,720
an attack that is more efficient overall

448
00:16:17,519 --> 00:16:19,360
now i'm going to talk about the slightly

449
00:16:19,360 --> 00:16:21,199
different model

450
00:16:21,199 --> 00:16:22,880
class we looked at which are decision

451
00:16:22,880 --> 00:16:23,839
trees

452
00:16:23,839 --> 00:16:26,160
and here these equation solving attacks

453
00:16:26,160 --> 00:16:28,079
don't really apply because

454
00:16:28,079 --> 00:16:30,079
in a decision tree the class labels and

455
00:16:30,079 --> 00:16:31,680
confidence scores aren't actually just

456
00:16:31,680 --> 00:16:34,160
derived from some mathematical function

457
00:16:34,160 --> 00:16:36,880
like a logistic function rather you have

458
00:16:36,880 --> 00:16:38,880
this tree structure that is learned that

459
00:16:38,880 --> 00:16:41,759
partitions your input space into leaves

460
00:16:41,759 --> 00:16:43,279
and in each leaf you're going to just

461
00:16:43,279 --> 00:16:45,680
assign a class label and a confidence

462
00:16:45,680 --> 00:16:46,720
score

463
00:16:46,720 --> 00:16:48,720
which is derived from the distribution

464
00:16:48,720 --> 00:16:50,639
of the training data for this particular

465
00:16:50,639 --> 00:16:52,959
leaf

466
00:16:53,600 --> 00:16:55,440
and so there was this prior work uh very

467
00:16:55,440 --> 00:16:57,120
nice prior work by kuch levitz and

468
00:16:57,120 --> 00:16:59,040
mansour that showed that if you only

469
00:16:59,040 --> 00:17:01,040
have access to class labels you can

470
00:17:01,040 --> 00:17:03,519
actually reconstruct and learn

471
00:17:03,519 --> 00:17:06,720
boolean trees in polynomial time

472
00:17:06,720 --> 00:17:08,319
and this algorithm is well of

473
00:17:08,319 --> 00:17:10,640
theoretical interest it has a

474
00:17:10,640 --> 00:17:13,199
fully impractical complexity i doubt

475
00:17:13,199 --> 00:17:16,720
anyone has ever tried to implement it

476
00:17:16,720 --> 00:17:18,799
so what we show is that if you make this

477
00:17:18,799 --> 00:17:20,000
extra assumption that you're going to

478
00:17:20,000 --> 00:17:22,880
get confidence values um you can get a

479
00:17:22,880 --> 00:17:24,400
much more efficient attack that's

480
00:17:24,400 --> 00:17:26,079
actually practical so we

481
00:17:26,079 --> 00:17:28,400
show that these work very well on big

482
00:17:28,400 --> 00:17:29,760
ml's platform

483
00:17:29,760 --> 00:17:32,640
um here's two sort of quickly show how

484
00:17:32,640 --> 00:17:34,640
this works uh

485
00:17:34,640 --> 00:17:37,520
we assume that every leaf of the tree

486
00:17:37,520 --> 00:17:39,440
gets assigned a difference confidence

487
00:17:39,440 --> 00:17:41,520
value so all the leaves had a slightly

488
00:17:41,520 --> 00:17:45,200
different training data distribution

489
00:17:45,200 --> 00:17:47,280
in practice we can sort of relax this

490
00:17:47,280 --> 00:17:49,280
assumption a little bit

491
00:17:49,280 --> 00:17:52,000
um the way the attack works

492
00:17:52,000 --> 00:17:54,240
sort of generically is that you take two

493
00:17:54,240 --> 00:17:55,440
inputs

494
00:17:55,440 --> 00:17:57,840
that differ in a single feature

495
00:17:57,840 --> 00:17:59,760
and then you query them and check

496
00:17:59,760 --> 00:18:01,200
whether you get different outputs

497
00:18:01,200 --> 00:18:02,559
wherever you get different confidence

498
00:18:02,559 --> 00:18:05,520
values and this acts as a distinguisher

499
00:18:05,520 --> 00:18:07,360
for the paths that these queries took in

500
00:18:07,360 --> 00:18:08,880
the tree so if you get two different

501
00:18:08,880 --> 00:18:10,559
outputs you know that

502
00:18:10,559 --> 00:18:13,200
somewhere the tree must have split on

503
00:18:13,200 --> 00:18:15,360
this feature that was different and so

504
00:18:15,360 --> 00:18:16,880
then you can sort of iteratively apply

505
00:18:16,880 --> 00:18:18,080
this process

506
00:18:18,080 --> 00:18:20,240
and completely recover all the decisions

507
00:18:20,240 --> 00:18:23,600
that the tree has made

508
00:18:23,600 --> 00:18:26,240
so how might one go about preventing uh

509
00:18:26,240 --> 00:18:28,320
model extraction it's a interesting

510
00:18:28,320 --> 00:18:30,559
question i mean we propose a few

511
00:18:30,559 --> 00:18:31,919
possible

512
00:18:31,919 --> 00:18:34,000
techniques in our work

513
00:18:34,000 --> 00:18:35,120
um

514
00:18:35,120 --> 00:18:37,120
here we'll look just at the simplest

515
00:18:37,120 --> 00:18:38,880
which is just to say well if confidence

516
00:18:38,880 --> 00:18:41,600
values enable these strong attacks well

517
00:18:41,600 --> 00:18:43,039
let's just remove them and see what

518
00:18:43,039 --> 00:18:45,600
happens and so as i mentioned earlier

519
00:18:45,600 --> 00:18:46,960
this sort of corresponds to this

520
00:18:46,960 --> 00:18:48,720
learning with membership queries uh

521
00:18:48,720 --> 00:18:49,840
setting

522
00:18:49,840 --> 00:18:50,799
um

523
00:18:50,799 --> 00:18:52,240
where there was already some prior work

524
00:18:52,240 --> 00:18:54,720
that was quite interesting by

525
00:18:54,720 --> 00:18:56,480
loud and meek for instance that showed

526
00:18:56,480 --> 00:18:58,240
how you could extract uh linear

527
00:18:58,240 --> 00:18:59,760
classifiers so

528
00:18:59,760 --> 00:19:01,520
these are classifiers that just apply

529
00:19:01,520 --> 00:19:03,679
some linear function on your inputs and

530
00:19:03,679 --> 00:19:04,480
then

531
00:19:04,480 --> 00:19:05,280
um

532
00:19:05,280 --> 00:19:07,280
well you select as one class or the

533
00:19:07,280 --> 00:19:08,799
other depending on which side of the

534
00:19:08,799 --> 00:19:10,080
decision boundary you're going to fall

535
00:19:10,080 --> 00:19:10,960
on

536
00:19:10,960 --> 00:19:12,880
and their attack here is quite simple

537
00:19:12,880 --> 00:19:14,880
you just first query a few points until

538
00:19:14,880 --> 00:19:16,080
you get two of them that have a

539
00:19:16,080 --> 00:19:17,440
different class

540
00:19:17,440 --> 00:19:18,960
then you know the decision boundary must

541
00:19:18,960 --> 00:19:21,440
be somewhere here in between so you do a

542
00:19:21,440 --> 00:19:22,799
binary search

543
00:19:22,799 --> 00:19:24,080
till you get two points that are

544
00:19:24,080 --> 00:19:26,320
extremely close to each other you repeat

545
00:19:26,320 --> 00:19:27,679
the process

546
00:19:27,679 --> 00:19:29,600
and then while you reconstruct this

547
00:19:29,600 --> 00:19:31,840
decision boundary up to some arbitrary

548
00:19:31,840 --> 00:19:34,160
precision

549
00:19:34,160 --> 00:19:36,960
so what we look into is how this kind of

550
00:19:36,960 --> 00:19:38,960
approach could be extended to more

551
00:19:38,960 --> 00:19:42,320
complex non-linear models and here we

552
00:19:42,320 --> 00:19:43,840
look into a technique from machine

553
00:19:43,840 --> 00:19:46,559
learning that's called active learning

554
00:19:46,559 --> 00:19:48,559
the idea here is quite simple it's sort

555
00:19:48,559 --> 00:19:50,480
of an adaptive way of doing machine

556
00:19:50,480 --> 00:19:53,120
learning so you query a number of points

557
00:19:53,120 --> 00:19:55,520
you fit a model to these points and then

558
00:19:55,520 --> 00:19:56,480
well

559
00:19:56,480 --> 00:19:58,400
you just query a bunch

560
00:19:58,400 --> 00:20:00,880
more points very close to your local

561
00:20:00,880 --> 00:20:03,810
decision boundary this is implicitly

562
00:20:03,810 --> 00:20:04,880
[Music]

563
00:20:04,880 --> 00:20:08,000
where your model intuitively sorry where

564
00:20:08,000 --> 00:20:10,400
your model is least certain about what's

565
00:20:10,400 --> 00:20:11,760
happening

566
00:20:11,760 --> 00:20:13,520
and so we show that with this kind of

567
00:20:13,520 --> 00:20:16,000
iterative process you can also get very

568
00:20:16,000 --> 00:20:17,919
successful um

569
00:20:17,919 --> 00:20:19,440
extraction attacks again on these

570
00:20:19,440 --> 00:20:20,799
non-linear

571
00:20:20,799 --> 00:20:22,640
regression models on neural networks

572
00:20:22,640 --> 00:20:25,120
svms as well

573
00:20:25,120 --> 00:20:27,280
yeah overall these attacks work fine but

574
00:20:27,280 --> 00:20:29,600
they're about 100 times less query

575
00:20:29,600 --> 00:20:31,840
efficient on average than

576
00:20:31,840 --> 00:20:34,400
if you just use equation solving when it

577
00:20:34,400 --> 00:20:36,799
applies of course

578
00:20:36,799 --> 00:20:37,840
so

579
00:20:37,840 --> 00:20:40,080
to conclude we showed that there's some

580
00:20:40,080 --> 00:20:42,000
kind of inherent tension in these

581
00:20:42,000 --> 00:20:43,679
machine learning as a service platforms

582
00:20:43,679 --> 00:20:44,720
between

583
00:20:44,720 --> 00:20:46,480
this desire to have these rich

584
00:20:46,480 --> 00:20:48,960
prediction apis on the one hand but also

585
00:20:48,960 --> 00:20:51,039
the need to ensure model and data

586
00:20:51,039 --> 00:20:54,559
confidentiality on the other

587
00:20:54,720 --> 00:20:56,720
we showed that we can construct very

588
00:20:56,720 --> 00:20:58,880
efficient model extraction attacks for a

589
00:20:58,880 --> 00:21:01,120
number of popular model classes we can

590
00:21:01,120 --> 00:21:03,280
also reverse engineer

591
00:21:03,280 --> 00:21:04,880
things that the adversary might not know

592
00:21:04,880 --> 00:21:06,880
exactly a priori so the model type the

593
00:21:06,880 --> 00:21:10,320
feature extractors that are used

594
00:21:10,320 --> 00:21:11,280
and we

595
00:21:11,280 --> 00:21:13,360
show a few applications so one i talked

596
00:21:13,360 --> 00:21:15,360
about here for model inversion attacks

597
00:21:15,360 --> 00:21:17,360
there's one or two others uh

598
00:21:17,360 --> 00:21:18,880
in the paper

599
00:21:18,880 --> 00:21:20,320
and

600
00:21:20,320 --> 00:21:22,240
our code is online so if you're

601
00:21:22,240 --> 00:21:24,720
interested you can take a look at that

602
00:21:24,720 --> 00:21:27,919
and as i have i think one minute

603
00:21:27,919 --> 00:21:30,159
exceptionally i'd just like to conclude

604
00:21:30,159 --> 00:21:30,960
uh

605
00:21:30,960 --> 00:21:32,880
with a brief and shameless uh

606
00:21:32,880 --> 00:21:34,880
announcement to uh

607
00:21:34,880 --> 00:21:38,400
congratulate my older brother lucas my

608
00:21:38,400 --> 00:21:39,360
uh

609
00:21:39,360 --> 00:21:41,520
slightly cooler brother according to my

610
00:21:41,520 --> 00:21:43,760
facebook feed

611
00:21:43,760 --> 00:21:46,080
who well won an outstanding gold medal

612
00:21:46,080 --> 00:21:47,760
this morning at the olympics with his

613
00:21:47,760 --> 00:21:49,280
rowing crew so

614
00:21:49,280 --> 00:21:50,720
congrats to them on an amazing

615
00:21:50,720 --> 00:21:54,600
performance thank you

616
00:22:00,640 --> 00:22:02,400
we have time for questions since every

617
00:22:02,400 --> 00:22:04,320
one of you will have at least one

618
00:22:04,320 --> 00:22:06,080
question please line up to the

619
00:22:06,080 --> 00:22:09,080
microphone

620
00:22:20,159 --> 00:22:22,320
hi david from georgetown very nice talk

621
00:22:22,320 --> 00:22:23,679
and congratulations to your brother and

622
00:22:23,679 --> 00:22:25,600
to you as well uh i just have a quick

623
00:22:25,600 --> 00:22:27,280
question so have you thought of applying

624
00:22:27,280 --> 00:22:28,799
so most of the attacks you talked about

625
00:22:28,799 --> 00:22:30,480
were for either classification tasks for

626
00:22:30,480 --> 00:22:32,400
machine learning i'm sorry i didn't get

627
00:22:32,400 --> 00:22:33,039
it

628
00:22:33,039 --> 00:22:35,760
so the attacks presented uh you said is

629
00:22:35,760 --> 00:22:38,000
for machine learning tasks that do

630
00:22:38,000 --> 00:22:40,320
classification and give you a score have

631
00:22:40,320 --> 00:22:42,799
you thought of applying these attacks to

632
00:22:42,799 --> 00:22:44,640
other machine learning tasks like speech

633
00:22:44,640 --> 00:22:46,159
recognition

634
00:22:46,159 --> 00:22:48,240
um where you can actually run the deep

635
00:22:48,240 --> 00:22:50,880
neural network and then try to

636
00:22:50,880 --> 00:22:53,120
do what like apple siri and google now

637
00:22:53,120 --> 00:22:55,840
is doing on your own laptop

638
00:22:55,840 --> 00:22:58,240
so we didn't look into into these it

639
00:22:58,240 --> 00:22:59,760
would be a very very interesting thing

640
00:22:59,760 --> 00:23:01,760
to look into so yeah in this work we

641
00:23:01,760 --> 00:23:04,000
really focused on some of these

642
00:23:04,000 --> 00:23:05,600
simple machine learning as a service

643
00:23:05,600 --> 00:23:07,679
platform like the one of amazon that

644
00:23:07,679 --> 00:23:09,760
basically just does sort of simple model

645
00:23:09,760 --> 00:23:10,720
classes

646
00:23:10,720 --> 00:23:11,760
um

647
00:23:11,760 --> 00:23:13,200
but yeah it would be it would be very

648
00:23:13,200 --> 00:23:15,039
interesting to see how far you could go

649
00:23:15,039 --> 00:23:18,480
um with more i guess with more complex

650
00:23:18,480 --> 00:23:20,880
models um especially neural networks at

651
00:23:20,880 --> 00:23:23,840
some point the assumption that you know

652
00:23:23,840 --> 00:23:25,760
let's say the structure of the model or

653
00:23:25,760 --> 00:23:28,720
its features might be more difficult to

654
00:23:28,720 --> 00:23:31,360
to justify although

655
00:23:31,360 --> 00:23:32,320
if

656
00:23:32,320 --> 00:23:33,600
you get

657
00:23:33,600 --> 00:23:36,000
services like the ones we've looked into

658
00:23:36,000 --> 00:23:37,200
that do

659
00:23:37,200 --> 00:23:38,559
uh deep learning at some point they

660
00:23:38,559 --> 00:23:39,919
might also just give you way more

661
00:23:39,919 --> 00:23:41,919
information than you need and so it's

662
00:23:41,919 --> 00:23:44,080
possible that you could still do attacks

663
00:23:44,080 --> 00:23:47,360
of this kind thank you

664
00:23:47,840 --> 00:23:49,600
hi i was wondering if

665
00:23:49,600 --> 00:23:51,520
the lack of confidence would completely

666
00:23:51,520 --> 00:23:52,960
break this down so if you were only

667
00:23:52,960 --> 00:23:55,600
given a class label back or even just

668
00:23:55,600 --> 00:23:57,360
some vague notion of the confidence like

669
00:23:57,360 --> 00:23:59,200
high medium or low confidence and a

670
00:23:59,200 --> 00:24:00,640
prediction

671
00:24:00,640 --> 00:24:01,600
if that would

672
00:24:01,600 --> 00:24:04,559
totally break this down so um what i'm

673
00:24:04,559 --> 00:24:06,320
what i mentioned briefly here at the end

674
00:24:06,320 --> 00:24:08,799
was that so even if you only have class

675
00:24:08,799 --> 00:24:11,039
labels you do have some

676
00:24:11,039 --> 00:24:14,000
active learning attacks that can um

677
00:24:14,000 --> 00:24:16,559
give you good results not as good i must

678
00:24:16,559 --> 00:24:18,000
say

679
00:24:18,000 --> 00:24:20,080
with lower confidence so we looked at

680
00:24:20,080 --> 00:24:22,240
sort of rounding confidence values down

681
00:24:22,240 --> 00:24:24,400
to say two or three digits of precision

682
00:24:24,400 --> 00:24:25,039
and

683
00:24:25,039 --> 00:24:26,880
at some point the attacks get less

684
00:24:26,880 --> 00:24:28,400
efficient but you really have to sort of

685
00:24:28,400 --> 00:24:29,520
go

686
00:24:29,520 --> 00:24:32,559
quite a way into making the confidence

687
00:24:32,559 --> 00:24:34,720
values less precise

688
00:24:34,720 --> 00:24:36,159
so

689
00:24:36,159 --> 00:24:38,320
i guess at some point you can uh well

690
00:24:38,320 --> 00:24:39,840
you can't go further than just giving

691
00:24:39,840 --> 00:24:41,360
class labels until unless you do

692
00:24:41,360 --> 00:24:44,000
something more sophisticated but

693
00:24:44,000 --> 00:24:46,159
at some point the problem there as well

694
00:24:46,159 --> 00:24:48,080
is this tension i was mentioning is that

695
00:24:48,080 --> 00:24:50,080
since these platforms give confidence

696
00:24:50,080 --> 00:24:51,760
values it's probably because developers

697
00:24:51,760 --> 00:24:53,679
somewhat want them in their applications

698
00:24:53,679 --> 00:24:54,880
and so

699
00:24:54,880 --> 00:24:56,880
um yeah at some point it's also a

700
00:24:56,880 --> 00:24:58,400
trade-off between whether these

701
00:24:58,400 --> 00:25:00,320
confidence value values are actually

702
00:25:00,320 --> 00:25:02,880
needed by an application or not thank

703
00:25:02,880 --> 00:25:05,039
you

704
00:25:05,840 --> 00:25:08,400
very nice work and i'm just curious what

705
00:25:08,400 --> 00:25:10,480
if the model contains more than one tree

706
00:25:10,480 --> 00:25:12,320
for example it's an example of trees or

707
00:25:12,320 --> 00:25:14,880
random forests can you recover that

708
00:25:14,880 --> 00:25:17,600
probably not yeah so uh random forests

709
00:25:17,600 --> 00:25:20,320
are one of the model classes that we

710
00:25:20,320 --> 00:25:22,000
mentioned in our paper as a potential

711
00:25:22,000 --> 00:25:24,640
counter measure to these type of attacks

712
00:25:24,640 --> 00:25:26,960
because i mean we don't have any

713
00:25:26,960 --> 00:25:28,559
formalism for this but it just seems

714
00:25:28,559 --> 00:25:31,200
intuitively very very difficult to

715
00:25:31,200 --> 00:25:34,000
extract a random forest at least using

716
00:25:34,000 --> 00:25:35,200
the kind of techniques we use for

717
00:25:35,200 --> 00:25:37,360
decision trees don't seem to apply at

718
00:25:37,360 --> 00:25:39,360
all there

719
00:25:39,360 --> 00:25:41,600
so yeah we didn't we didn't find a way

720
00:25:41,600 --> 00:25:44,640
to apply these attacks to decision to

721
00:25:44,640 --> 00:25:47,520
random forests

722
00:25:47,600 --> 00:25:49,200
i don't know maybe maybe there's a

723
00:25:49,200 --> 00:25:51,440
smarter way of doing it but we didn't

724
00:25:51,440 --> 00:25:54,640
think of one thank you

725
00:25:55,279 --> 00:25:57,600
hello sir nice work um

726
00:25:57,600 --> 00:25:59,600
have you thought about using this

727
00:25:59,600 --> 00:26:02,640
technique to simplify overly complex

728
00:26:02,640 --> 00:26:04,960
black box models so this is actually

729
00:26:04,960 --> 00:26:07,279
what google's doing um it's something we

730
00:26:07,279 --> 00:26:10,320
heard about uh later in uh i mean after

731
00:26:10,320 --> 00:26:12,240
we publish this work so they don't do

732
00:26:12,240 --> 00:26:14,320
exactly extraction they sort of just

733
00:26:14,320 --> 00:26:16,080
train a huge

734
00:26:16,080 --> 00:26:17,440
neural net

735
00:26:17,440 --> 00:26:18,520
and then um

736
00:26:18,520 --> 00:26:19,919
[Music]

737
00:26:19,919 --> 00:26:22,960
train a smaller neural net to

738
00:26:22,960 --> 00:26:25,840
um mimic the input output behavior of

739
00:26:25,840 --> 00:26:27,679
the larger net but using these

740
00:26:27,679 --> 00:26:29,520
confidence values so instead of trying

741
00:26:29,520 --> 00:26:30,320
to

742
00:26:30,320 --> 00:26:32,400
learn the class labels they really try

743
00:26:32,400 --> 00:26:34,400
to directly optimize over the

744
00:26:34,400 --> 00:26:36,720
probability scores which they show can

745
00:26:36,720 --> 00:26:38,640
actually give very very good results in

746
00:26:38,640 --> 00:26:41,120
compressing uh models yeah so it's a

747
00:26:41,120 --> 00:26:43,360
related uh

748
00:26:43,360 --> 00:26:44,960
technique yeah

749
00:26:44,960 --> 00:26:47,279
thank you

750
00:26:48,080 --> 00:26:50,840
i think uh this is very interesting work

751
00:26:50,840 --> 00:26:53,120
um i'm interested in this sort of

752
00:26:53,120 --> 00:26:54,640
generic model

753
00:26:54,640 --> 00:26:56,400
model retraining and

754
00:26:56,400 --> 00:26:57,679
query learning

755
00:26:57,679 --> 00:26:59,520
but i'm curious what happens when you

756
00:26:59,520 --> 00:27:01,520
don't necessarily have the class label

757
00:27:01,520 --> 00:27:03,520
and the confidence but instead you have

758
00:27:03,520 --> 00:27:04,840
sort of

759
00:27:04,840 --> 00:27:07,360
actions that so so there are cases where

760
00:27:07,360 --> 00:27:09,440
there's a there's a model that's that's

761
00:27:09,440 --> 00:27:11,760
i work in privacy a lot there's a model

762
00:27:11,760 --> 00:27:13,679
that's being used and it's being used to

763
00:27:13,679 --> 00:27:15,120
take actions and those actions are

764
00:27:15,120 --> 00:27:17,520
clearly sort of dependent on the class

765
00:27:17,520 --> 00:27:19,039
labels and the confidences but you don't

766
00:27:19,039 --> 00:27:21,520
have that and can you infer the models

767
00:27:21,520 --> 00:27:23,600
from those or the training data and i

768
00:27:23,600 --> 00:27:25,120
think that's maybe a

769
00:27:25,120 --> 00:27:26,960
have you have you started to work on

770
00:27:26,960 --> 00:27:28,480
anything like that or thought about it

771
00:27:28,480 --> 00:27:31,840
or so we we didn't look at that

772
00:27:31,840 --> 00:27:33,520
specifically so i agree that would

773
00:27:33,520 --> 00:27:36,399
probably make it more difficult however

774
00:27:36,399 --> 00:27:38,960
it seems like actually the way people

775
00:27:38,960 --> 00:27:40,960
are meant to use these machine learning

776
00:27:40,960 --> 00:27:43,600
platforms is that all this

777
00:27:43,600 --> 00:27:45,679
processing of the

778
00:27:45,679 --> 00:27:47,520
output would happen

779
00:27:47,520 --> 00:27:49,120
client-side so you could think of maybe

780
00:27:49,120 --> 00:27:51,440
your mobile app that would make queries

781
00:27:51,440 --> 00:27:53,520
to a service and then sort of in the app

782
00:27:53,520 --> 00:27:54,399
would

783
00:27:54,399 --> 00:27:56,000
convert this to an action or something

784
00:27:56,000 --> 00:27:57,919
so it would seem that

785
00:27:57,919 --> 00:27:59,360
i mean these these machine learning

786
00:27:59,360 --> 00:28:00,960
services they don't provide you with

787
00:28:00,960 --> 00:28:03,520
this extra layer application layer let's

788
00:28:03,520 --> 00:28:05,120
say so these type of attacks would

789
00:28:05,120 --> 00:28:08,158
continue to apply

790
00:28:08,320 --> 00:28:12,600
all right let's thank the speaker again

791
00:28:18,159 --> 00:28:20,240
you

