1
00:00:11,519 --> 00:00:13,280
it's a pleasure to be here and i want to

2
00:00:13,280 --> 00:00:15,120
thank the committee

3
00:00:15,120 --> 00:00:17,680
for inviting me to give this keynote at

4
00:00:17,680 --> 00:00:18,800
usenix

5
00:00:18,800 --> 00:00:19,760
i

6
00:00:19,760 --> 00:00:20,720
actually

7
00:00:20,720 --> 00:00:23,119
wanted to say that even when i was at

8
00:00:23,119 --> 00:00:25,119
the national science foundation i

9
00:00:25,119 --> 00:00:27,039
started talking about cyber physical

10
00:00:27,039 --> 00:00:29,519
systems i started a program in cyber

11
00:00:29,519 --> 00:00:31,199
physical systems

12
00:00:31,199 --> 00:00:34,640
while i was at nsf almost 10 years ago

13
00:00:34,640 --> 00:00:36,640
and even then i started talking about

14
00:00:36,640 --> 00:00:38,879
the security challenges that cyber

15
00:00:38,879 --> 00:00:41,360
physical systems are going to pose and

16
00:00:41,360 --> 00:00:42,640
so i

17
00:00:42,640 --> 00:00:45,920
now can really talk about cyber trust

18
00:00:45,920 --> 00:00:47,600
including security

19
00:00:47,600 --> 00:00:49,920
because now cyber physical systems are

20
00:00:49,920 --> 00:00:50,960
real

21
00:00:50,960 --> 00:00:52,960
and they're really affecting our daily

22
00:00:52,960 --> 00:00:55,039
lives so

23
00:00:55,039 --> 00:00:56,399
with that

24
00:00:56,399 --> 00:00:59,039
um you know we already have thermostats

25
00:00:59,039 --> 00:01:00,800
and light bulbs that are smart enough to

26
00:01:00,800 --> 00:01:04,159
go on and off we have robots that clean

27
00:01:04,159 --> 00:01:07,920
our uh carpeting and our floors we have

28
00:01:07,920 --> 00:01:10,159
cameras that monitor our babies when

29
00:01:10,159 --> 00:01:13,280
we're at work and we have devices that

30
00:01:13,280 --> 00:01:15,439
we can just you know gesture over that

31
00:01:15,439 --> 00:01:18,400
are going to control and monitor these

32
00:01:18,400 --> 00:01:20,240
cyber physical systems these smart

33
00:01:20,240 --> 00:01:22,479
devices

34
00:01:22,479 --> 00:01:25,520
we have cars that are drive themselves

35
00:01:25,520 --> 00:01:27,680
around on the streets

36
00:01:27,680 --> 00:01:30,479
we drones that fly around delivering

37
00:01:30,479 --> 00:01:33,840
packages or going into areas that we

38
00:01:33,840 --> 00:01:35,360
can't go into

39
00:01:35,360 --> 00:01:37,920
contact lenses that continuously monitor

40
00:01:37,920 --> 00:01:41,040
our glucose level and tell our doctors

41
00:01:41,040 --> 00:01:42,799
how we're doing

42
00:01:42,799 --> 00:01:43,600
and

43
00:01:43,600 --> 00:01:46,560
sensors and actuators in our environment

44
00:01:46,560 --> 00:01:48,880
our physical environment our buildings

45
00:01:48,880 --> 00:01:50,240
farmlands

46
00:01:50,240 --> 00:01:52,479
all of these are examples of cyber

47
00:01:52,479 --> 00:01:54,479
physical systems

48
00:01:54,479 --> 00:01:58,240
robots will be our pets our co-workers

49
00:01:58,240 --> 00:01:59,920
our companions

50
00:01:59,920 --> 00:02:02,799
and help us in the clinics

51
00:02:02,799 --> 00:02:04,960
and we'll be

52
00:02:04,960 --> 00:02:07,920
we have already invented devices that

53
00:02:07,920 --> 00:02:09,280
help the

54
00:02:09,280 --> 00:02:12,480
people who have disabilities to do

55
00:02:12,480 --> 00:02:15,760
things that they cannot currently do

56
00:02:15,760 --> 00:02:18,879
so all of these devices are going to be

57
00:02:18,879 --> 00:02:20,560
you know the promise of internet of

58
00:02:20,560 --> 00:02:21,920
things or

59
00:02:21,920 --> 00:02:24,160
or the industrial internet all of these

60
00:02:24,160 --> 00:02:26,319
devices will be interconnected they'll

61
00:02:26,319 --> 00:02:27,280
be

62
00:02:27,280 --> 00:02:29,920
in principle talking to each other uh

63
00:02:29,920 --> 00:02:32,400
cooperating with each other each other

64
00:02:32,400 --> 00:02:33,920
and so on

65
00:02:33,920 --> 00:02:36,560
um and also there's the the cloud which

66
00:02:36,560 --> 00:02:39,120
is another big component of this

67
00:02:39,120 --> 00:02:42,400
interconnected um world

68
00:02:42,400 --> 00:02:45,280
so what is common to the cyber physical

69
00:02:45,280 --> 00:02:48,400
systems they have a computational core

70
00:02:48,400 --> 00:02:50,400
that interacts with the physical world

71
00:02:50,400 --> 00:02:53,440
so that's why i call them cyber physical

72
00:02:53,440 --> 00:02:56,319
cyber physical systems are engineered

73
00:02:56,319 --> 00:02:59,360
systems that require tight conjoining of

74
00:02:59,360 --> 00:03:01,440
and coordination between the

75
00:03:01,440 --> 00:03:04,640
computational discrete and the physical

76
00:03:04,640 --> 00:03:06,480
continuous

77
00:03:06,480 --> 00:03:09,120
and the trends that i see for the future

78
00:03:09,120 --> 00:03:12,080
are already happening

79
00:03:12,080 --> 00:03:13,920
cyber physical systems will be smarter

80
00:03:13,920 --> 00:03:16,000
and smarter

81
00:03:16,000 --> 00:03:18,480
all the smarts this intelligence will be

82
00:03:18,480 --> 00:03:19,920
in software

83
00:03:19,920 --> 00:03:21,760
and more and more there will be more and

84
00:03:21,760 --> 00:03:25,040
more connectivity and flows among these

85
00:03:25,040 --> 00:03:26,959
devices

86
00:03:26,959 --> 00:03:29,280
and another important trend that we

87
00:03:29,280 --> 00:03:32,319
mustn't forget is that in the end humans

88
00:03:32,319 --> 00:03:34,879
are going to be a very much a part of

89
00:03:34,879 --> 00:03:37,440
this system so we're going to have to

90
00:03:37,440 --> 00:03:40,080
understand how humans interact with

91
00:03:40,080 --> 00:03:42,000
these devices and they are part of of

92
00:03:42,000 --> 00:03:45,120
course the whole ecosystem

93
00:03:45,120 --> 00:03:46,959
so it's not just individual human

94
00:03:46,959 --> 00:03:49,519
behavior that we need to uh understand

95
00:03:49,519 --> 00:03:52,319
but it's a social norms as more and more

96
00:03:52,319 --> 00:03:54,159
of these devices become part of our

97
00:03:54,159 --> 00:03:56,560
daily lives

98
00:03:56,560 --> 00:03:58,640
so what could go wrong

99
00:03:58,640 --> 00:04:00,720
uh this is a security conference so we

100
00:04:00,720 --> 00:04:02,480
always worry about what's going to go

101
00:04:02,480 --> 00:04:03,439
wrong

102
00:04:03,439 --> 00:04:07,200
and first of course things can fail

103
00:04:07,200 --> 00:04:10,799
so planes crash cars crash trains crash

104
00:04:10,799 --> 00:04:12,640
and drones crash

105
00:04:12,640 --> 00:04:14,640
we've seen lots and lots of examples of

106
00:04:14,640 --> 00:04:17,680
this and as the systems become smarter

107
00:04:17,680 --> 00:04:19,199
and smarter

108
00:04:19,199 --> 00:04:21,839
software will be

109
00:04:21,839 --> 00:04:25,360
pointed to as often the culprit

110
00:04:25,360 --> 00:04:27,759
security errors i don't also have to

111
00:04:27,759 --> 00:04:30,000
belabor with this audience we see the

112
00:04:30,000 --> 00:04:31,680
headlines every day

113
00:04:31,680 --> 00:04:34,320
on how vulnerable a lot of these systems

114
00:04:34,320 --> 00:04:38,240
are individually let alone as a net as a

115
00:04:38,240 --> 00:04:41,520
interconnected uh system

116
00:04:41,520 --> 00:04:44,080
so what i like to think about when i

117
00:04:44,080 --> 00:04:46,560
think about cyber trust for cyber

118
00:04:46,560 --> 00:04:48,240
physical systems is first of course

119
00:04:48,240 --> 00:04:50,080
there's the hardware the software and

120
00:04:50,080 --> 00:04:52,400
the people i already argue that it's a

121
00:04:52,400 --> 00:04:54,880
big ecosystem and the hardware and

122
00:04:54,880 --> 00:04:58,240
software interact very closely

123
00:04:58,240 --> 00:05:02,240
but when i talk about cyber traffic

124
00:05:02,560 --> 00:05:04,479
i mean not just

125
00:05:04,479 --> 00:05:07,199
security i mean reliability security and

126
00:05:07,199 --> 00:05:10,000
privacy so in the remaining part of my

127
00:05:10,000 --> 00:05:12,960
talk what i'm going to do is outline

128
00:05:12,960 --> 00:05:15,039
research challenges because i this is a

129
00:05:15,039 --> 00:05:17,039
research community which and i hope

130
00:05:17,039 --> 00:05:18,639
there are a lot of phd students in the

131
00:05:18,639 --> 00:05:21,199
audience looking for thesis topics

132
00:05:21,199 --> 00:05:23,199
because there are a lot of really hard

133
00:05:23,199 --> 00:05:26,800
challenges left on in in in order to

134
00:05:26,800 --> 00:05:28,720
make the cyber physical systems

135
00:05:28,720 --> 00:05:31,199
trustworthy and in the end if these are

136
00:05:31,199 --> 00:05:33,680
part of our daily lives we want

137
00:05:33,680 --> 00:05:35,919
people you and me

138
00:05:35,919 --> 00:05:38,560
our friends and family to trust these

139
00:05:38,560 --> 00:05:40,000
systems

140
00:05:40,000 --> 00:05:41,600
so i'm going to go through research

141
00:05:41,600 --> 00:05:42,880
challenges

142
00:05:42,880 --> 00:05:45,440
along the lines of reliability security

143
00:05:45,440 --> 00:05:47,600
and privacy and

144
00:05:47,600 --> 00:05:48,880
some of the

145
00:05:48,880 --> 00:05:50,720
examples i'm going to give are

146
00:05:50,720 --> 00:05:53,680
historical because we've come a long way

147
00:05:53,680 --> 00:05:55,360
some of them are very current and

148
00:05:55,360 --> 00:05:57,680
examples of some research projects going

149
00:05:57,680 --> 00:05:59,520
on at microsoft for instance that are

150
00:05:59,520 --> 00:06:02,479
addressing some of these challenges

151
00:06:02,479 --> 00:06:05,600
so it's a mix of what we know how to do

152
00:06:05,600 --> 00:06:07,759
and what we're doing today and what we

153
00:06:07,759 --> 00:06:09,919
don't know how to do

154
00:06:09,919 --> 00:06:12,800
okay so let's start with reliability

155
00:06:12,800 --> 00:06:15,360
if you think about

156
00:06:15,360 --> 00:06:19,039
inherently a system that has a physical

157
00:06:19,039 --> 00:06:22,080
component and a digital component and

158
00:06:22,080 --> 00:06:24,160
this device is interacting with the real

159
00:06:24,160 --> 00:06:25,280
world

160
00:06:25,280 --> 00:06:28,720
then there are fundamentally two

161
00:06:28,720 --> 00:06:31,840
technical challenges we need to address

162
00:06:31,840 --> 00:06:34,400
first is reasoning about the continuous

163
00:06:34,400 --> 00:06:35,280
and

164
00:06:35,280 --> 00:06:37,199
at the same time

165
00:06:37,199 --> 00:06:39,199
and the second is reasoning about

166
00:06:39,199 --> 00:06:42,000
uncertainty because the environment is

167
00:06:42,000 --> 00:06:43,520
unpredictable

168
00:06:43,520 --> 00:06:45,680
and uncertainty can come due to mother

169
00:06:45,680 --> 00:06:48,479
nature due to malicious attackers

170
00:06:48,479 --> 00:06:50,400
and just due to failures of the

171
00:06:50,400 --> 00:06:52,560
components

172
00:06:52,560 --> 00:06:54,000
so let me talk

173
00:06:54,000 --> 00:06:57,199
first about the fact we've come a long

174
00:06:57,199 --> 00:06:59,680
way in reasoning about the continuous

175
00:06:59,680 --> 00:07:02,240
and discrete at the same time but

176
00:07:02,240 --> 00:07:04,080
there's still a lot of interesting new

177
00:07:04,080 --> 00:07:06,240
work being done

178
00:07:06,240 --> 00:07:08,160
and talk a bit about reasoning about

179
00:07:08,160 --> 00:07:09,759
uncertainty

180
00:07:09,759 --> 00:07:13,680
so let's dial back a couple of decades

181
00:07:13,680 --> 00:07:17,360
already to models for

182
00:07:17,360 --> 00:07:20,240
cyber physical systems and these models

183
00:07:20,240 --> 00:07:22,160
stem all the way back to certain kinds

184
00:07:22,160 --> 00:07:25,440
of automata in this particular case i'm

185
00:07:25,440 --> 00:07:27,680
highlighting tom hensinger's work on

186
00:07:27,680 --> 00:07:30,400
hybrid automata and this is a simple

187
00:07:30,400 --> 00:07:32,560
model of a thermostat and what's

188
00:07:32,560 --> 00:07:34,400
interesting about these

189
00:07:34,400 --> 00:07:37,919
automata is that within a state you can

190
00:07:37,919 --> 00:07:40,800
describe continuous behavior usually

191
00:07:40,800 --> 00:07:43,680
using differential equations and so on

192
00:07:43,680 --> 00:07:47,360
and then between states you can define

193
00:07:47,360 --> 00:07:50,080
these jump conditions that get you from

194
00:07:50,080 --> 00:07:51,759
one state to the other

195
00:07:51,759 --> 00:07:54,960
um in terms of these discrete behaviors

196
00:07:54,960 --> 00:07:56,800
like in this case the heater is going to

197
00:07:56,800 --> 00:07:58,800
go on as soon as the temperature falls

198
00:07:58,800 --> 00:08:01,360
below 19 degrees

199
00:08:01,360 --> 00:08:04,319
and you can even state in variance in

200
00:08:04,319 --> 00:08:07,599
this case for this particular

201
00:08:07,599 --> 00:08:10,240
state you you can say that

202
00:08:10,240 --> 00:08:12,639
at the latest the

203
00:08:12,639 --> 00:08:14,240
thermostat will go on when the

204
00:08:14,240 --> 00:08:16,720
temperature falls to 18 degrees and so

205
00:08:16,720 --> 00:08:19,599
you can build these you can define and

206
00:08:19,599 --> 00:08:22,639
build these hybrid automata to describe

207
00:08:22,639 --> 00:08:23,520
the

208
00:08:23,520 --> 00:08:26,720
behavior both discrete and continuous of

209
00:08:26,720 --> 00:08:29,520
the cyber physical systems so

210
00:08:29,520 --> 00:08:32,719
and and since then many many tools and

211
00:08:32,719 --> 00:08:33,440
other

212
00:08:33,440 --> 00:08:35,679
similar models have been invented in

213
00:08:35,679 --> 00:08:38,240
order to formally reason about these

214
00:08:38,240 --> 00:08:40,479
cyber physical systems or models of the

215
00:08:40,479 --> 00:08:42,479
cyber physical systems so this is

216
00:08:42,479 --> 00:08:44,720
tremendous progress by the formal

217
00:08:44,720 --> 00:08:46,720
methods community

218
00:08:46,720 --> 00:08:49,440
there's another view on how to reason

219
00:08:49,440 --> 00:08:50,720
about

220
00:08:50,720 --> 00:08:52,720
the continuous and discrete at the same

221
00:08:52,720 --> 00:08:55,440
time that isn't so model based but in

222
00:08:55,440 --> 00:08:58,000
fact logic based and here i'm going to

223
00:08:58,000 --> 00:09:00,720
highlight the work of andre plotzer at

224
00:09:00,720 --> 00:09:03,839
carnegie mellon on differential dynamic

225
00:09:03,839 --> 00:09:07,760
logic which in one logic allows you to

226
00:09:07,760 --> 00:09:10,160
reason about both discrete and

227
00:09:10,160 --> 00:09:13,440
continuous so you can see in the

228
00:09:13,440 --> 00:09:15,760
there's a i don't expect you to see all

229
00:09:15,760 --> 00:09:17,839
the details here but there's a way in

230
00:09:17,839 --> 00:09:19,519
which you can write a program that

231
00:09:19,519 --> 00:09:21,680
describes the behavior

232
00:09:21,680 --> 00:09:23,760
of a cyber physical system and that

233
00:09:23,760 --> 00:09:26,959
program has both differentials like x

234
00:09:26,959 --> 00:09:29,680
prime equals

235
00:09:32,080 --> 00:09:34,240
for instance predicates

236
00:09:34,240 --> 00:09:37,600
like q which are over discrete variables

237
00:09:37,600 --> 00:09:39,920
and then you can reason and much like we

238
00:09:39,920 --> 00:09:42,560
do in other kinds of temporal logics we

239
00:09:42,560 --> 00:09:44,480
can reason about all behaviors that

240
00:09:44,480 --> 00:09:46,959
exist be a behavior

241
00:09:46,959 --> 00:09:48,320
etc

242
00:09:48,320 --> 00:09:50,880
and this particular differential dynamic

243
00:09:50,880 --> 00:09:54,880
logic also has a tool that has been used

244
00:09:54,880 --> 00:09:57,839
to reason about air traffic control

245
00:09:57,839 --> 00:10:01,120
about uh cars entering

246
00:10:01,120 --> 00:10:04,959
roads uh and uh keeping trains a certain

247
00:10:04,959 --> 00:10:08,000
distance away so th this logic and this

248
00:10:08,000 --> 00:10:09,680
tool has been

249
00:10:09,680 --> 00:10:12,000
have been used to reason about cyber

250
00:10:12,000 --> 00:10:14,000
physical systems so again tremendous

251
00:10:14,000 --> 00:10:16,160
progress in this area to reason about

252
00:10:16,160 --> 00:10:18,560
the continuous and discreet

253
00:10:18,560 --> 00:10:20,480
so what about

254
00:10:20,480 --> 00:10:23,519
reasoning about uncertainty in the past

255
00:10:23,519 --> 00:10:24,320
in

256
00:10:24,320 --> 00:10:26,320
typically in in the formal methods

257
00:10:26,320 --> 00:10:28,720
community we would

258
00:10:28,720 --> 00:10:31,360
model uncertainty by non-determinism

259
00:10:31,360 --> 00:10:33,200
this is a very blunt instrument where

260
00:10:33,200 --> 00:10:35,839
you'd say well at any particular state

261
00:10:35,839 --> 00:10:39,519
you can go into a failure state which is

262
00:10:39,519 --> 00:10:42,640
okay it models what can happen but it's

263
00:10:42,640 --> 00:10:45,600
not very satisfying because

264
00:10:45,600 --> 00:10:47,200
at any particular state you can go into

265
00:10:47,200 --> 00:10:48,720
the failure state and so you have to

266
00:10:48,720 --> 00:10:52,399
always think about that so more recently

267
00:10:52,399 --> 00:10:55,120
people have been using probabilities

268
00:10:55,120 --> 00:10:58,000
um and inventing automata model checking

269
00:10:58,000 --> 00:11:01,040
theorem proving logics and so on to

270
00:11:01,040 --> 00:11:03,519
incorporate probabilities for as first

271
00:11:03,519 --> 00:11:06,240
class in reasoning systems

272
00:11:06,240 --> 00:11:08,640
and i think what's most exciting

273
00:11:08,640 --> 00:11:12,399
in this realm of adding probabilities is

274
00:11:12,399 --> 00:11:15,279
this whole era now that's starting on

275
00:11:15,279 --> 00:11:18,480
probabilistic programming and here we

276
00:11:18,480 --> 00:11:20,480
have

277
00:11:20,480 --> 00:11:22,399
programmed variables

278
00:11:22,399 --> 00:11:24,079
for instance

279
00:11:24,079 --> 00:11:26,079
c1 and c2 here

280
00:11:26,079 --> 00:11:27,600
that

281
00:11:27,600 --> 00:11:30,240
range over probability distribution so

282
00:11:30,240 --> 00:11:32,720
you can actually choose a value for that

283
00:11:32,720 --> 00:11:35,279
variable that comes from a probability

284
00:11:35,279 --> 00:11:38,640
distribution now imagine programming in

285
00:11:38,640 --> 00:11:42,000
a say a c language here where your

286
00:11:42,000 --> 00:11:43,839
program variables are coming from

287
00:11:43,839 --> 00:11:46,160
probability distributions this is a

288
00:11:46,160 --> 00:11:48,320
whole new way of thinking a whole new

289
00:11:48,320 --> 00:11:51,680
way of programming um and for those of

290
00:11:51,680 --> 00:11:54,399
you who are faculty on it's a whole way

291
00:11:54,399 --> 00:11:56,720
of of teaching your students how to

292
00:11:56,720 --> 00:11:59,200
program for the future so this is quite

293
00:11:59,200 --> 00:12:00,399
far out

294
00:12:00,399 --> 00:12:02,800
but we have of course

295
00:12:02,800 --> 00:12:05,279
already in the research community i've

296
00:12:05,279 --> 00:12:07,040
been inventing these probabilistic

297
00:12:07,040 --> 00:12:09,360
programming languages and reasoning

298
00:12:09,360 --> 00:12:10,959
about

299
00:12:10,959 --> 00:12:14,560
programs in these languages

300
00:12:14,560 --> 00:12:17,040
so with that i wanted to

301
00:12:17,040 --> 00:12:19,839
explain a little bit of work that is

302
00:12:19,839 --> 00:12:22,639
going on in a project

303
00:12:22,639 --> 00:12:25,200
at microsoft research called safe cyber

304
00:12:25,200 --> 00:12:26,880
physical systems

305
00:12:26,880 --> 00:12:28,160
and their

306
00:12:28,160 --> 00:12:32,000
the projects underlying a platform is a

307
00:12:32,000 --> 00:12:34,959
drone or drones in general and what they

308
00:12:34,959 --> 00:12:37,680
want to do is actually reason about the

309
00:12:37,680 --> 00:12:41,440
safety of a drone flying a particular

310
00:12:41,440 --> 00:12:42,399
plan

311
00:12:42,399 --> 00:12:46,000
from the bottom up so they um we have

312
00:12:46,000 --> 00:12:49,200
already we're looking at this as a layer

313
00:12:49,200 --> 00:12:50,160
of

314
00:12:50,160 --> 00:12:52,800
abstractions at the very lowest we have

315
00:12:52,800 --> 00:12:55,120
an operating system and in this

316
00:12:55,120 --> 00:12:56,959
particular case it's a real-time

317
00:12:56,959 --> 00:12:59,600
operating system which we proven secure

318
00:12:59,600 --> 00:13:02,639
with respect to memory safety properties

319
00:13:02,639 --> 00:13:04,959
and then you have on the drone of course

320
00:13:04,959 --> 00:13:07,440
you have many sensors including cameras

321
00:13:07,440 --> 00:13:10,800
which need to be proven robust um

322
00:13:10,800 --> 00:13:11,680
because

323
00:13:11,680 --> 00:13:14,959
sensor sensors can get imprecise data in

324
00:13:14,959 --> 00:13:16,240
in

325
00:13:16,240 --> 00:13:19,040
in incomplete data can make mistakes and

326
00:13:19,040 --> 00:13:21,519
so on and then of course

327
00:13:21,519 --> 00:13:23,519
in the heart at the heart of this is

328
00:13:23,519 --> 00:13:25,680
correct control you want this drone to

329
00:13:25,680 --> 00:13:26,720
fly

330
00:13:26,720 --> 00:13:30,800
um in a smooth continuous path from from

331
00:13:30,800 --> 00:13:33,200
a source to destination and at the

332
00:13:33,200 --> 00:13:34,399
highest level

333
00:13:34,399 --> 00:13:36,880
this drone or this cyber physical system

334
00:13:36,880 --> 00:13:38,639
is supposed to do something interesting

335
00:13:38,639 --> 00:13:41,600
for instance carry a package or go

336
00:13:41,600 --> 00:13:43,040
a

337
00:13:43,040 --> 00:13:44,160
region

338
00:13:44,160 --> 00:13:45,360
and so there's

339
00:13:45,360 --> 00:13:48,240
high level planning that takes a place

340
00:13:48,240 --> 00:13:50,399
at the highest level of what the drone

341
00:13:50,399 --> 00:13:52,560
is supposed to do the task

342
00:13:52,560 --> 00:13:55,199
and so we have um lots and lots of

343
00:13:55,199 --> 00:13:58,160
expertise in microsoft research in terms

344
00:13:58,160 --> 00:13:59,360
of

345
00:13:59,360 --> 00:14:01,760
verification at each of these levels

346
00:14:01,760 --> 00:14:04,639
what i'm going to focus on is new work

347
00:14:04,639 --> 00:14:06,639
that looks at

348
00:14:06,639 --> 00:14:09,680
how we have incorporated bayesian

349
00:14:09,680 --> 00:14:11,199
classification

350
00:14:11,199 --> 00:14:13,600
into a kind of temporal logic in order

351
00:14:13,600 --> 00:14:17,279
for us to reason about correct control

352
00:14:17,279 --> 00:14:19,040
in particular if you want to reason

353
00:14:19,040 --> 00:14:22,399
about safe control under uncertainty you

354
00:14:22,399 --> 00:14:25,760
have your standard

355
00:14:26,959 --> 00:14:30,480
set of equations that define

356
00:14:30,480 --> 00:14:33,920
the next state of the system under some

357
00:14:33,920 --> 00:14:35,920
control variable u is the control

358
00:14:35,920 --> 00:14:37,279
variable there

359
00:14:37,279 --> 00:14:40,639
and you want to basically optimize the

360
00:14:40,639 --> 00:14:41,680
control

361
00:14:41,680 --> 00:14:44,399
to minimize the cost on

362
00:14:44,399 --> 00:14:45,760
where you

363
00:14:45,760 --> 00:14:47,440
to where you want to be

364
00:14:47,440 --> 00:14:50,320
and the cost on control and basically

365
00:14:50,320 --> 00:14:53,360
minimizing this expression so the first

366
00:14:53,360 --> 00:14:56,639
part of this uh under the minimization

367
00:14:56,639 --> 00:14:58,000
is

368
00:14:58,000 --> 00:14:59,920
the reference where you are to where you

369
00:14:59,920 --> 00:15:03,040
want to be and the u's represent your

370
00:15:03,040 --> 00:15:04,959
control variables

371
00:15:04,959 --> 00:15:07,920
but this is the standard optimization

372
00:15:07,920 --> 00:15:10,959
for control what's different is we want

373
00:15:10,959 --> 00:15:13,199
to subject this

374
00:15:13,199 --> 00:15:16,240
constraint to a safety property

375
00:15:16,240 --> 00:15:17,120
so

376
00:15:17,120 --> 00:15:21,279
if x is basically think about what x

377
00:15:21,279 --> 00:15:23,279
represents your state you represent your

378
00:15:23,279 --> 00:15:25,199
control variable you have a sequence of

379
00:15:25,199 --> 00:15:27,760
x's and u's you want each one of those

380
00:15:27,760 --> 00:15:31,279
sequences to satisfy safety property and

381
00:15:31,279 --> 00:15:33,279
in this case we're going to write our

382
00:15:33,279 --> 00:15:36,079
safety property in what

383
00:15:36,079 --> 00:15:39,199
probabilistic signal temporal logic

384
00:15:39,199 --> 00:15:41,120
so that that's just a

385
00:15:41,120 --> 00:15:43,279
logic which one can reason

386
00:15:43,279 --> 00:15:45,279
over

387
00:15:45,279 --> 00:15:47,279
just to be

388
00:15:47,279 --> 00:15:51,040
example of a drone that we are

389
00:15:51,040 --> 00:15:53,279
minimizing with respect to

390
00:15:53,279 --> 00:15:55,360
where we started which is a zero zero

391
00:15:55,360 --> 00:15:57,440
zero to where we want to be which is one

392
00:15:57,440 --> 00:16:00,160
one zero so this drone is this little

393
00:16:00,160 --> 00:16:03,600
green thing that's flying upwards to get

394
00:16:03,600 --> 00:16:06,399
to its destination point one one zero

395
00:16:06,399 --> 00:16:08,480
but of course we don't want it to crash

396
00:16:08,480 --> 00:16:10,160
into the ceiling

397
00:16:10,160 --> 00:16:12,560
and so

398
00:16:13,279 --> 00:16:16,399
the tech person is here signaling me

399
00:16:16,399 --> 00:16:18,880
something

400
00:16:20,079 --> 00:16:23,399
take it out

401
00:16:37,199 --> 00:16:39,199
okay so here where as

402
00:16:39,199 --> 00:16:41,600
i said before we're going to minimize

403
00:16:41,600 --> 00:16:42,639
um

404
00:16:42,639 --> 00:16:44,560
the cost of

405
00:16:44,560 --> 00:16:47,040
where we are in our control subject to

406
00:16:47,040 --> 00:16:48,800
this particular safety property in this

407
00:16:48,800 --> 00:16:50,639
particular safety property has two parts

408
00:16:50,639 --> 00:16:51,519
to it

409
00:16:51,519 --> 00:16:54,000
one is um just with respect to the

410
00:16:54,000 --> 00:16:56,720
control you um there are actually

411
00:16:56,720 --> 00:16:59,680
multiple but i'm just showing you um the

412
00:16:59,680 --> 00:17:01,759
the property with respect to roll but

413
00:17:01,759 --> 00:17:04,799
the interesting one is the first one

414
00:17:04,799 --> 00:17:06,640
where we incorporate a bayesian

415
00:17:06,640 --> 00:17:10,559
classifier to give us a confidence level

416
00:17:10,559 --> 00:17:12,079
of of

417
00:17:12,079 --> 00:17:13,039
of

418
00:17:13,039 --> 00:17:15,119
the probability

419
00:17:15,119 --> 00:17:16,559
that

420
00:17:16,559 --> 00:17:19,039
the drone is near

421
00:17:19,039 --> 00:17:22,240
the thinks it's near the wall or not

422
00:17:22,240 --> 00:17:23,760
and so

423
00:17:23,760 --> 00:17:24,959
uh

424
00:17:24,959 --> 00:17:25,919
this is

425
00:17:25,919 --> 00:17:27,919
the the new work here is really

426
00:17:27,919 --> 00:17:30,559
incorporating this beijing classifier in

427
00:17:30,559 --> 00:17:32,960
the logic itself and then what you can

428
00:17:32,960 --> 00:17:36,320
do very beautifully is you can

429
00:17:36,320 --> 00:17:38,960
independently and modularly

430
00:17:38,960 --> 00:17:41,440
incorporate as many classifiers as you

431
00:17:41,440 --> 00:17:44,960
want and reason about them

432
00:17:44,960 --> 00:17:48,000
it as compositionally

433
00:17:48,000 --> 00:17:52,000
and the work um i cite is uh

434
00:17:52,000 --> 00:17:54,080
a couple slides before i cited it it

435
00:17:54,080 --> 00:17:56,960
just appeared this summer

436
00:17:56,960 --> 00:17:58,000
okay

437
00:17:58,000 --> 00:17:58,720
so

438
00:17:58,720 --> 00:18:00,880
but where we're going with this work is

439
00:18:00,880 --> 00:18:03,919
actually what as i alluded to earlier is

440
00:18:03,919 --> 00:18:05,600
that we'd like to actually write

441
00:18:05,600 --> 00:18:10,080
programs i'm using the probabilities in

442
00:18:10,080 --> 00:18:10,880
as

443
00:18:10,880 --> 00:18:12,080
part of our

444
00:18:12,080 --> 00:18:14,720
program variable

445
00:18:14,720 --> 00:18:17,200
program variables but also incorporate

446
00:18:17,200 --> 00:18:20,320
in these programs a check

447
00:18:20,320 --> 00:18:21,120
that

448
00:18:21,120 --> 00:18:24,960
basically checks these uh probabilistic

449
00:18:24,960 --> 00:18:26,640
uh formula

450
00:18:26,640 --> 00:18:28,960
so what we have in the end is a

451
00:18:28,960 --> 00:18:31,520
probabilistic safety program

452
00:18:31,520 --> 00:18:34,480
um and the three inputs to this program

453
00:18:34,480 --> 00:18:37,440
are first some planner plan

454
00:18:37,440 --> 00:18:39,120
using planning and control we have a

455
00:18:39,120 --> 00:18:41,039
trajectory

456
00:18:41,039 --> 00:18:42,720
and then another

457
00:18:42,720 --> 00:18:44,880
input are the classifiers that are

458
00:18:44,880 --> 00:18:46,799
coming out of these bayesian graphical

459
00:18:46,799 --> 00:18:50,160
models uh for instance for a camera

460
00:18:50,160 --> 00:18:52,559
and then we have these specifications

461
00:18:52,559 --> 00:18:55,440
written these logics we fold them all

462
00:18:55,440 --> 00:18:58,320
into a program and then we can basically

463
00:18:58,320 --> 00:19:00,559
run the program and do analysis of the

464
00:19:00,559 --> 00:19:03,120
program to determine whether

465
00:19:03,120 --> 00:19:05,440
we were are guaranteed that every run of

466
00:19:05,440 --> 00:19:07,440
the program will be safe

467
00:19:07,440 --> 00:19:08,480
or

468
00:19:08,480 --> 00:19:11,520
spit out an example where it's not

469
00:19:11,520 --> 00:19:14,480
so this is i would say pretty state of

470
00:19:14,480 --> 00:19:17,200
the art in terms of where we are in

471
00:19:17,200 --> 00:19:19,520
reasoning about uncertainty for cyber

472
00:19:19,520 --> 00:19:21,200
physical systems

473
00:19:21,200 --> 00:19:22,960
and that's all i'm going to say about

474
00:19:22,960 --> 00:19:25,120
reliability

475
00:19:25,120 --> 00:19:27,760
okay now let me turn to security which

476
00:19:27,760 --> 00:19:29,120
is probably

477
00:19:29,120 --> 00:19:32,080
primary interest to all of you and again

478
00:19:32,080 --> 00:19:33,919
i don't have to remind you

479
00:19:33,919 --> 00:19:37,200
of the challenges and that we have as a

480
00:19:37,200 --> 00:19:39,840
community to protect our systems and

481
00:19:39,840 --> 00:19:42,559
protect our network systems

482
00:19:42,559 --> 00:19:45,600
and in the in the um future

483
00:19:45,600 --> 00:19:46,400
or

484
00:19:46,400 --> 00:19:49,120
the way it looks today already is

485
00:19:49,120 --> 00:19:52,480
there's some malicious guy out there and

486
00:19:52,480 --> 00:19:55,760
this very highly interconnected network

487
00:19:55,760 --> 00:19:58,960
including the cloud um

488
00:19:58,960 --> 00:20:01,280
you know some other node in that network

489
00:20:01,280 --> 00:20:03,360
gets hacked and the question is you know

490
00:20:03,360 --> 00:20:05,840
what part of the system was vulnerable

491
00:20:05,840 --> 00:20:10,000
that caused this particular um attack in

492
00:20:10,000 --> 00:20:12,000
fact many parts of the system are

493
00:20:12,000 --> 00:20:13,600
potentially vulnerable how do you

494
00:20:13,600 --> 00:20:16,400
actually trace back um and and figure

495
00:20:16,400 --> 00:20:17,120
out

496
00:20:17,120 --> 00:20:19,200
figure out what actually happened

497
00:20:19,200 --> 00:20:22,240
so i divide this problem into three

498
00:20:22,240 --> 00:20:25,120
major challenges one is how can we

499
00:20:25,120 --> 00:20:27,840
protect each device

500
00:20:27,840 --> 00:20:30,799
from the network and the network from

501
00:20:30,799 --> 00:20:32,960
each device

502
00:20:32,960 --> 00:20:35,600
this is like the atomic

503
00:20:35,600 --> 00:20:36,559
entity

504
00:20:36,559 --> 00:20:38,080
um in this

505
00:20:38,080 --> 00:20:39,280
big

506
00:20:39,280 --> 00:20:41,360
internet of things industrial internet

507
00:20:41,360 --> 00:20:42,960
and so on

508
00:20:42,960 --> 00:20:44,320
and then of course there's a network

509
00:20:44,320 --> 00:20:45,600
itself

510
00:20:45,600 --> 00:20:47,840
how can we secure the network and

511
00:20:47,840 --> 00:20:49,919
finally there's the cloud which is a

512
00:20:49,919 --> 00:20:53,919
part of where um the interesting

513
00:20:53,919 --> 00:20:56,960
data computation over data is happening

514
00:20:56,960 --> 00:20:59,520
how can we trust the cloud so all of

515
00:20:59,520 --> 00:21:01,360
these are

516
00:21:01,360 --> 00:21:04,559
big research areas on them on their own

517
00:21:04,559 --> 00:21:06,400
um but this is this picture puts it all

518
00:21:06,400 --> 00:21:08,880
together so let me talk a little bit

519
00:21:08,880 --> 00:21:10,720
about each of these

520
00:21:10,720 --> 00:21:13,600
so for the first one you know we already

521
00:21:13,600 --> 00:21:16,640
in principle know how

522
00:21:16,640 --> 00:21:18,640
in terms of best practices to build a

523
00:21:18,640 --> 00:21:23,120
secure system from uh sort of

524
00:21:23,120 --> 00:21:24,960
the hardware

525
00:21:24,960 --> 00:21:28,480
all the way up to applications uh device

526
00:21:28,480 --> 00:21:31,039
identity has to be in hardware that

527
00:21:31,039 --> 00:21:34,080
allows us to do secure boot we which can

528
00:21:34,080 --> 00:21:36,640
then allow us to build some kind of

529
00:21:36,640 --> 00:21:38,960
secure storage then from there we can

530
00:21:38,960 --> 00:21:42,080
build secure protocols um and use

531
00:21:42,080 --> 00:21:44,159
encryption and finally we get

532
00:21:44,159 --> 00:21:46,559
applications running on top of that

533
00:21:46,559 --> 00:21:49,440
now we know how to do this in principle

534
00:21:49,440 --> 00:21:52,240
for secure systems but what about when

535
00:21:52,240 --> 00:21:55,760
the device is resource impoverished like

536
00:21:55,760 --> 00:21:59,600
a thermostat or a light bulb

537
00:21:59,600 --> 00:22:02,159
so what we need to do is revisit this

538
00:22:02,159 --> 00:22:03,280
secure

539
00:22:03,280 --> 00:22:05,919
security stack

540
00:22:05,919 --> 00:22:07,440
when

541
00:22:07,440 --> 00:22:11,120
when the devices may not have the full

542
00:22:11,120 --> 00:22:14,480
capability both in terms of storage

543
00:22:14,480 --> 00:22:17,760
and computation as a typical

544
00:22:17,760 --> 00:22:19,919
system that we want to secure and so

545
00:22:19,919 --> 00:22:22,400
this is where the research has to happen

546
00:22:22,400 --> 00:22:26,080
on and how do we build these devices and

547
00:22:26,080 --> 00:22:29,200
ensure and build the security stack for

548
00:22:29,200 --> 00:22:31,200
low power and limited computing

549
00:22:31,200 --> 00:22:32,640
resources

550
00:22:32,640 --> 00:22:34,480
the other interesting challenge not so

551
00:22:34,480 --> 00:22:36,880
much for the security community but i

552
00:22:36,880 --> 00:22:39,600
would say for the

553
00:22:39,600 --> 00:22:42,000
software and machine learning community

554
00:22:42,000 --> 00:22:44,559
is in the end these devices are supposed

555
00:22:44,559 --> 00:22:47,679
to be smart and so what

556
00:22:47,679 --> 00:22:49,840
what where's the smarts this gonna come

557
00:22:49,840 --> 00:22:52,720
from well today a lot of the smartness

558
00:22:52,720 --> 00:22:54,960
comes from the machine learning and the

559
00:22:54,960 --> 00:22:57,600
classifiers that we train using machine

560
00:22:57,600 --> 00:22:58,720
learning

561
00:22:58,720 --> 00:23:01,200
and so now is an interesting question of

562
00:23:01,200 --> 00:23:03,440
how do we split the machine learning

563
00:23:03,440 --> 00:23:06,640
models between the device and the cloud

564
00:23:06,640 --> 00:23:08,159
because we could have a really dumb

565
00:23:08,159 --> 00:23:09,919
device and then put all the smarts in

566
00:23:09,919 --> 00:23:12,240
the cloud but then you have this latency

567
00:23:12,240 --> 00:23:14,720
problem um and and you may even have

568
00:23:14,720 --> 00:23:17,360
privacy issues and so on so you have to

569
00:23:17,360 --> 00:23:20,880
think what part of this model or what

570
00:23:20,880 --> 00:23:22,720
part of the algorithm am i going to want

571
00:23:22,720 --> 00:23:26,240
to have local to the device versus have

572
00:23:26,240 --> 00:23:28,559
a compute in the cloud so this is a

573
00:23:28,559 --> 00:23:31,280
actually a project going on at microsoft

574
00:23:31,280 --> 00:23:33,520
research called intelligent devices

575
00:23:33,520 --> 00:23:35,440
which is looking at machine learning

576
00:23:35,440 --> 00:23:37,520
algorithms and other kinds of algorithms

577
00:23:37,520 --> 00:23:39,360
to determine how to split that

578
00:23:39,360 --> 00:23:41,919
computation

579
00:23:41,919 --> 00:23:42,720
so

580
00:23:42,720 --> 00:23:45,039
challenge number two is

581
00:23:45,039 --> 00:23:46,880
the the

582
00:23:46,880 --> 00:23:49,120
something that we all care about which

583
00:23:49,120 --> 00:23:51,039
is securing the network

584
00:23:51,039 --> 00:23:53,279
and i know this afternoon you're going

585
00:23:53,279 --> 00:23:54,880
to have you're going to have a keynote

586
00:23:54,880 --> 00:23:56,799
speaker who will address

587
00:23:56,799 --> 00:23:58,640
probably the achilles heel of the

588
00:23:58,640 --> 00:24:01,840
network which is https

589
00:24:01,840 --> 00:24:04,480
so we have another project going on at

590
00:24:04,480 --> 00:24:06,720
microsoft research i see cedric's in the

591
00:24:06,720 --> 00:24:09,120
audience smiling there

592
00:24:09,120 --> 00:24:12,240
which is really quite ambitious

593
00:24:12,240 --> 00:24:14,400
so first of all i think everyone here

594
00:24:14,400 --> 00:24:16,480
knows that https

595
00:24:16,480 --> 00:24:19,360
is is the workhorse of the internet in

596
00:24:19,360 --> 00:24:22,000
terms of uh it being the most widely

597
00:24:22,000 --> 00:24:24,799
deployed security protocol and it is of

598
00:24:24,799 --> 00:24:26,720
course behind everything that we do

599
00:24:26,720 --> 00:24:28,480
whenever you go to the web whenever you

600
00:24:28,480 --> 00:24:32,320
go to your browser email you name it and

601
00:24:32,320 --> 00:24:35,279
it's quite complicated it's not just one

602
00:24:35,279 --> 00:24:40,400
protocol if you will it's a bunch of

603
00:24:40,400 --> 00:24:43,679
protocols and components and languages

604
00:24:43,679 --> 00:24:47,360
and applications that talk to each other

605
00:24:47,360 --> 00:24:51,279
um and so this is the right hand side is

606
00:24:51,279 --> 00:24:52,640
meant to

607
00:24:52,640 --> 00:24:53,600
be a

608
00:24:53,600 --> 00:24:58,880
box and line diagram of https

609
00:24:58,880 --> 00:25:02,000
and it is also quite vulnerable as

610
00:25:02,000 --> 00:25:03,279
you'll probably hear later this

611
00:25:03,279 --> 00:25:06,320
afternoon 20 years of attacks and fixes

612
00:25:06,320 --> 00:25:08,320
and we're still

613
00:25:08,320 --> 00:25:09,760
finding bugs

614
00:25:09,760 --> 00:25:11,919
and we're still vulnerable to

615
00:25:11,919 --> 00:25:15,919
pretty severe heartbleed-like attacks

616
00:25:15,919 --> 00:25:18,880
so the microsoft research

617
00:25:18,880 --> 00:25:21,600
project called everest has this grand

618
00:25:21,600 --> 00:25:23,039
ambition

619
00:25:23,039 --> 00:25:27,279
that in four years what they hope to do

620
00:25:27,279 --> 00:25:29,760
is to build a

621
00:25:29,760 --> 00:25:30,960
fully

622
00:25:30,960 --> 00:25:32,799
verified

623
00:25:32,799 --> 00:25:35,440
drop-in replacement

624
00:25:35,440 --> 00:25:39,679
of the https ecosystem

625
00:25:39,679 --> 00:25:40,960
so

626
00:25:40,960 --> 00:25:43,279
that whole box with all those

627
00:25:43,279 --> 00:25:46,159
complicated boxes and lines they want to

628
00:25:46,159 --> 00:25:48,240
make green they want to make completely

629
00:25:48,240 --> 00:25:49,760
secure

630
00:25:49,760 --> 00:25:50,640
and

631
00:25:50,640 --> 00:25:52,960
the point about it being a drop in

632
00:25:52,960 --> 00:25:55,440
replacement is that

633
00:25:55,440 --> 00:25:57,919
it should be performant enough and it

634
00:25:57,919 --> 00:25:58,799
should be

635
00:25:58,799 --> 00:26:02,480
easy enough for you to just switch over

636
00:26:02,480 --> 00:26:05,039
now this is uh quite an ambitious

637
00:26:05,039 --> 00:26:08,720
project um but if we can pull this off

638
00:26:08,720 --> 00:26:10,960
it's going to benefit the entire

639
00:26:10,960 --> 00:26:12,640
community

640
00:26:12,640 --> 00:26:13,440
and

641
00:26:13,440 --> 00:26:16,559
we're quite excited about the potential

642
00:26:16,559 --> 00:26:18,960
now this is a brand new project so none

643
00:26:18,960 --> 00:26:20,960
of this has been done yet

644
00:26:20,960 --> 00:26:25,200
however they build on many many lines of

645
00:26:25,200 --> 00:26:26,320
work

646
00:26:26,320 --> 00:26:29,600
that have already given us confidence

647
00:26:29,600 --> 00:26:31,840
that we could pull this one off

648
00:26:31,840 --> 00:26:34,799
and it starts with some work

649
00:26:34,799 --> 00:26:37,760
on the irene star

650
00:26:37,760 --> 00:26:40,799
projects iron clad iron fleet

651
00:26:40,799 --> 00:26:42,960
many of you probably have heard about

652
00:26:42,960 --> 00:26:44,240
this work

653
00:26:44,240 --> 00:26:46,640
through either oakland or usenix

654
00:26:46,640 --> 00:26:48,480
and it also starts

655
00:26:48,480 --> 00:26:52,400
it builds on the phenomenal work

656
00:26:52,400 --> 00:26:53,360
on

657
00:26:53,360 --> 00:26:54,960
verifying

658
00:26:54,960 --> 00:26:55,760
a

659
00:26:55,760 --> 00:26:58,960
tls protocol called my tls which was

660
00:26:58,960 --> 00:27:02,159
also oakland award-winning work

661
00:27:02,159 --> 00:27:04,799
and then of course all of those projects

662
00:27:04,799 --> 00:27:07,600
ironclad ironfleet my tls

663
00:27:07,600 --> 00:27:09,120
build on

664
00:27:09,120 --> 00:27:11,360
decades

665
00:27:11,360 --> 00:27:14,480
worth of verification tools

666
00:27:14,480 --> 00:27:17,760
and languages that have been invented

667
00:27:17,760 --> 00:27:20,799
a lot by at microsoft research

668
00:27:20,799 --> 00:27:23,760
for instance daphne and boogie for

669
00:27:23,760 --> 00:27:28,240
specifying a pre and post condition like

670
00:27:29,159 --> 00:27:32,240
specifications f star which is a high

671
00:27:32,240 --> 00:27:34,960
order functional programming language

672
00:27:34,960 --> 00:27:37,919
z3 which is the workhorse of almost all

673
00:27:37,919 --> 00:27:39,840
formal methods tools

674
00:27:39,840 --> 00:27:41,679
used globally

675
00:27:41,679 --> 00:27:45,679
and so on so we have high hope that

676
00:27:45,679 --> 00:27:48,399
we can we can build on what we've done

677
00:27:48,399 --> 00:27:51,360
already to achieve this grand goal

678
00:27:51,360 --> 00:27:53,200
you should realize that

679
00:27:53,200 --> 00:27:56,159
what we can do already is just a little

680
00:27:56,159 --> 00:27:58,799
that is shown in green so we do have a

681
00:27:58,799 --> 00:28:00,320
long way to go

682
00:28:00,320 --> 00:28:02,960
and you should wish us luck

683
00:28:02,960 --> 00:28:05,520
okay and um these are citations from the

684
00:28:05,520 --> 00:28:07,600
the previous work

685
00:28:07,600 --> 00:28:09,919
okay so that's

686
00:28:09,919 --> 00:28:12,240
the network component there's still one

687
00:28:12,240 --> 00:28:14,960
other component uh say we secure the

688
00:28:14,960 --> 00:28:17,279
devices and we secure the network but

689
00:28:17,279 --> 00:28:19,120
what about this cloud

690
00:28:19,120 --> 00:28:21,360
um why

691
00:28:21,360 --> 00:28:24,799
and and how can we trust the cloud

692
00:28:24,799 --> 00:28:26,799
so i'm only going to speak a little bit

693
00:28:26,799 --> 00:28:29,600
about this we all have some very very

694
00:28:29,600 --> 00:28:31,360
exciting projects going on microsoft

695
00:28:31,360 --> 00:28:34,240
research on building a trusted cloud

696
00:28:34,240 --> 00:28:36,480
i'll just hint at a couple of approaches

697
00:28:36,480 --> 00:28:38,000
that we're taking

698
00:28:38,000 --> 00:28:39,600
one is

699
00:28:39,600 --> 00:28:40,320
to

700
00:28:40,320 --> 00:28:43,120
of course use cryptography i saw some

701
00:28:43,120 --> 00:28:44,399
opening

702
00:28:44,399 --> 00:28:46,640
advertisements for talks this

703
00:28:46,640 --> 00:28:47,760
today

704
00:28:47,760 --> 00:28:49,440
and tomorrow

705
00:28:49,440 --> 00:28:52,000
on for instance using a secure

706
00:28:52,000 --> 00:28:54,320
multi-party computation but also using

707
00:28:54,320 --> 00:28:56,159
homomorphic encryption

708
00:28:56,159 --> 00:28:59,520
um so applied cryptography can go a long

709
00:28:59,520 --> 00:29:02,799
way in helping us trust the cloud in

710
00:29:02,799 --> 00:29:04,559
particular trusting the data that

711
00:29:04,559 --> 00:29:07,279
customers and and uh consumers will

712
00:29:07,279 --> 00:29:09,120
store in the cloud

713
00:29:09,120 --> 00:29:11,840
and and making sure that for instance

714
00:29:11,840 --> 00:29:15,279
cloud administrators can't see the data

715
00:29:15,279 --> 00:29:17,600
but another approach is a hardware-based

716
00:29:17,600 --> 00:29:20,159
approach and we're already seeing

717
00:29:20,159 --> 00:29:23,520
processors like intel's sgx coming out

718
00:29:23,520 --> 00:29:24,880
with

719
00:29:24,880 --> 00:29:26,640
the ability to

720
00:29:26,640 --> 00:29:29,520
build what are called enclaves regions

721
00:29:29,520 --> 00:29:31,440
within which you can run

722
00:29:31,440 --> 00:29:34,799
uh code over data in a secure manner

723
00:29:34,799 --> 00:29:37,279
manner so it's as if you are computing

724
00:29:37,279 --> 00:29:39,200
over encrypted data

725
00:29:39,200 --> 00:29:41,679
as you would in using say homomorphic

726
00:29:41,679 --> 00:29:42,880
encryption

727
00:29:42,880 --> 00:29:44,480
so these are two

728
00:29:44,480 --> 00:29:47,440
approaches that um the community is

729
00:29:47,440 --> 00:29:50,000
taking to build a trusted cloud

730
00:29:50,000 --> 00:29:52,720
now in microsoft we actually already in

731
00:29:52,720 --> 00:29:55,120
our azure sql server

732
00:29:55,120 --> 00:29:57,200
um

733
00:29:57,200 --> 00:30:00,960
the latest release um this this year

734
00:30:00,960 --> 00:30:03,919
already use a very baby version of

735
00:30:03,919 --> 00:30:06,640
homomorphic encryption just for one

736
00:30:06,640 --> 00:30:09,600
operation essentially equality to allow

737
00:30:09,600 --> 00:30:13,360
you to compute over certain columns in a

738
00:30:13,360 --> 00:30:17,200
a relational database in a secure manner

739
00:30:17,200 --> 00:30:19,200
so we're kind of

740
00:30:19,200 --> 00:30:21,679
using this as a stepping stone to see

741
00:30:21,679 --> 00:30:23,840
what we can do more

742
00:30:23,840 --> 00:30:26,799
generally not just equality but other

743
00:30:26,799 --> 00:30:29,360
operations

744
00:30:29,360 --> 00:30:31,919
so that's all i'm going to say about

745
00:30:31,919 --> 00:30:36,159
security on that let me turn to privacy

746
00:30:36,159 --> 00:30:39,279
and i'll pull out this particular

747
00:30:39,279 --> 00:30:43,360
headline about how easy it is for people

748
00:30:43,360 --> 00:30:46,399
to hack these these uh cameras that

749
00:30:46,399 --> 00:30:49,120
monitor babies these baby cams and again

750
00:30:49,120 --> 00:30:51,679
headline after headline um and this is

751
00:30:51,679 --> 00:30:54,720
of course an invasion of privacy

752
00:30:54,720 --> 00:30:57,440
so what when i think about privacy i

753
00:30:57,440 --> 00:31:00,559
think about the appropriate collection

754
00:31:00,559 --> 00:31:02,960
and processing of information

755
00:31:02,960 --> 00:31:05,120
about a data subject

756
00:31:05,120 --> 00:31:08,000
by a data holder and the flow of

757
00:31:08,000 --> 00:31:10,799
information between data holders

758
00:31:10,799 --> 00:31:13,360
and appropriate is where we get all

759
00:31:13,360 --> 00:31:16,240
tangled up into what does privacy mean

760
00:31:16,240 --> 00:31:19,039
to you to me to a group of people

761
00:31:19,039 --> 00:31:21,440
because that's where social norms

762
00:31:21,440 --> 00:31:25,039
context ethical values company policies

763
00:31:25,039 --> 00:31:27,600
legal rules individual preferences

764
00:31:27,600 --> 00:31:29,919
come to

765
00:31:29,919 --> 00:31:33,600
make this notion of privacy so nuanced

766
00:31:33,600 --> 00:31:35,840
so i'm going to just focus on what i

767
00:31:35,840 --> 00:31:38,399
call the data life cycle we start with

768
00:31:38,399 --> 00:31:40,000
collecting data

769
00:31:40,000 --> 00:31:43,120
we need to store and manage the data and

770
00:31:43,120 --> 00:31:45,600
we analyze it and maybe share the data

771
00:31:45,600 --> 00:31:47,039
with others

772
00:31:47,039 --> 00:31:49,440
we do the analysis to gain insights we

773
00:31:49,440 --> 00:31:52,720
share share the data with others um to

774
00:31:52,720 --> 00:31:53,679
learn

775
00:31:53,679 --> 00:31:56,399
collaboratively and so on and in this

776
00:31:56,399 --> 00:31:58,399
entire life cycle

777
00:31:58,399 --> 00:32:01,519
there is usually a promise that a

778
00:32:01,519 --> 00:32:03,840
company might make to a customer

779
00:32:03,840 --> 00:32:09,678
um to preserve certain policies or to um

780
00:32:09,840 --> 00:32:11,679
the promise will be these privacy

781
00:32:11,679 --> 00:32:13,760
policies and there is a question of

782
00:32:13,760 --> 00:32:14,799
course

783
00:32:14,799 --> 00:32:16,640
how can we trust the

784
00:32:16,640 --> 00:32:17,440
the

785
00:32:17,440 --> 00:32:21,120
data holders with our data

786
00:32:21,120 --> 00:32:23,440
so there are risks in the data life

787
00:32:23,440 --> 00:32:25,760
cycle first of all there's very well

788
00:32:25,760 --> 00:32:27,120
known that

789
00:32:27,120 --> 00:32:29,279
anonymizing data when you're collecting

790
00:32:29,279 --> 00:32:32,399
it um it just doesn't work so don't do

791
00:32:32,399 --> 00:32:33,760
that

792
00:32:33,760 --> 00:32:36,240
and then there's a question of what i

793
00:32:36,240 --> 00:32:38,320
was alluding to before you have this

794
00:32:38,320 --> 00:32:40,880
privacy policy and how do you know that

795
00:32:40,880 --> 00:32:43,200
the company like microsoft or facebook

796
00:32:43,200 --> 00:32:46,320
or google is actually complying by this

797
00:32:46,320 --> 00:32:48,000
promise that it makes to the customer

798
00:32:48,000 --> 00:32:50,000
with respect to privacy

799
00:32:50,000 --> 00:32:53,039
um and then um i can tell you that uh

800
00:32:53,039 --> 00:32:56,159
certainly within microsoft that we're so

801
00:32:56,159 --> 00:32:57,760
afraid to

802
00:32:57,760 --> 00:33:00,480
violate customer privacy that we

803
00:33:00,480 --> 00:33:02,320
actually don't share within

804
00:33:02,320 --> 00:33:04,320
uh with with business groups within

805
00:33:04,320 --> 00:33:07,159
microsoft because we we prefer to air

806
00:33:07,159 --> 00:33:09,519
conservatively and that what this

807
00:33:09,519 --> 00:33:11,600
actually means is that we can't

808
00:33:11,600 --> 00:33:12,960
we can't take

809
00:33:12,960 --> 00:33:15,760
as much advantage as we could if we were

810
00:33:15,760 --> 00:33:18,640
able to share data with with each other

811
00:33:18,640 --> 00:33:20,799
but at least we are upholding our

812
00:33:20,799 --> 00:33:23,440
promise to the customer

813
00:33:23,440 --> 00:33:26,240
so in addressing each of these um parts

814
00:33:26,240 --> 00:33:29,440
of the data life cycle um there are lots

815
00:33:29,440 --> 00:33:32,000
of different privacy technologies that

816
00:33:32,000 --> 00:33:33,519
can come to bear

817
00:33:33,519 --> 00:33:35,679
um and this is one thing that i'm trying

818
00:33:35,679 --> 00:33:39,120
to promote um within microsoft and i i

819
00:33:39,120 --> 00:33:41,279
hope as a community

820
00:33:41,279 --> 00:33:43,120
when we think about the global the

821
00:33:43,120 --> 00:33:46,159
national issues of privacy that for the

822
00:33:46,159 --> 00:33:48,640
most part many people

823
00:33:48,640 --> 00:33:51,519
working in privacy have come from the

824
00:33:51,519 --> 00:33:52,720
policy

825
00:33:52,720 --> 00:33:55,519
legal ethical even philosophical points

826
00:33:55,519 --> 00:33:59,120
of view but as technologists as computer

827
00:33:59,120 --> 00:34:01,519
scientists and engineers we have a lot

828
00:34:01,519 --> 00:34:04,880
of technology to offer that can actually

829
00:34:04,880 --> 00:34:09,520
speak definitively about privacy and so

830
00:34:09,520 --> 00:34:11,520
we shouldn't be afraid to actually use

831
00:34:11,520 --> 00:34:13,199
this technology and deploy this

832
00:34:13,199 --> 00:34:16,000
technology and we are seeing companies

833
00:34:16,000 --> 00:34:18,159
um starting to do that so this is really

834
00:34:18,159 --> 00:34:19,760
heartening

835
00:34:19,760 --> 00:34:22,480
one of the areas that my colleagues and

836
00:34:22,480 --> 00:34:25,359
i uh my colleagues at carnegie mellon

837
00:34:25,359 --> 00:34:26,320
and

838
00:34:26,320 --> 00:34:28,239
at microsoft research and i have done

839
00:34:28,239 --> 00:34:29,839
this is also in oakland paper a couple

840
00:34:29,839 --> 00:34:31,760
years ago

841
00:34:31,760 --> 00:34:34,560
did was to how to actually abide by

842
00:34:34,560 --> 00:34:37,599
these privacy policies for large data

843
00:34:37,599 --> 00:34:38,800
systems

844
00:34:38,800 --> 00:34:42,239
like large map reduce like systems and

845
00:34:42,239 --> 00:34:45,918
we have uh the system we we wrote about

846
00:34:45,918 --> 00:34:47,199
it

847
00:34:47,199 --> 00:34:50,079
and it's been operational we run this

848
00:34:50,079 --> 00:34:53,199
tool nightly to check for violations of

849
00:34:53,199 --> 00:34:56,800
privacy policies and it is scalable it's

850
00:34:56,800 --> 00:34:59,040
basically you know if you've got a large

851
00:34:59,040 --> 00:35:01,440
organization um it's something that you

852
00:35:01,440 --> 00:35:04,160
could you could definitely use so we

853
00:35:04,160 --> 00:35:04,960
have

854
00:35:04,960 --> 00:35:07,520
we have hope that we know how to do this

855
00:35:07,520 --> 00:35:09,760
um at scale

856
00:35:09,760 --> 00:35:12,560
um what about the collection of data we

857
00:35:12,560 --> 00:35:14,560
know uh

858
00:35:14,560 --> 00:35:16,480
as i was saying before

859
00:35:16,480 --> 00:35:18,720
anonymization doesn't work so what's the

860
00:35:18,720 --> 00:35:22,560
alternative and here again um i many of

861
00:35:22,560 --> 00:35:24,320
you i'm sure know about the

862
00:35:24,320 --> 00:35:26,079
groundbreaking work on differential

863
00:35:26,079 --> 00:35:29,599
privacy that also came out of um

864
00:35:29,599 --> 00:35:31,760
microsoft research with cynthia dworks

865
00:35:31,760 --> 00:35:34,720
work um and her colleagues

866
00:35:34,720 --> 00:35:38,640
at penn and and so on and so

867
00:35:38,640 --> 00:35:41,119
now we're even seeing companies starting

868
00:35:41,119 --> 00:35:43,520
to use differential privacy

869
00:35:43,520 --> 00:35:46,400
for certain applications so now it's

870
00:35:46,400 --> 00:35:49,599
becoming practical we have a lot a lot

871
00:35:49,599 --> 00:35:51,359
more to do

872
00:35:51,359 --> 00:35:53,599
to make it understandable to mere

873
00:35:53,599 --> 00:35:57,440
mortals and to scale it up

874
00:35:57,440 --> 00:36:00,240
and then what about um the use of

875
00:36:00,240 --> 00:36:04,079
cryptographic cryptography um i think

876
00:36:04,079 --> 00:36:05,920
that one of the

877
00:36:05,920 --> 00:36:09,280
exciting areas that we can see as a

878
00:36:09,280 --> 00:36:10,880
security community

879
00:36:10,880 --> 00:36:13,200
is making these cryptographic techniques

880
00:36:13,200 --> 00:36:15,200
such as homomorphic encryption and

881
00:36:15,200 --> 00:36:17,760
secure multi-party computation practical

882
00:36:17,760 --> 00:36:20,960
in the way that if you have a particular

883
00:36:20,960 --> 00:36:22,720
scenario that you want to light up or if

884
00:36:22,720 --> 00:36:24,480
you have a particular problem you want

885
00:36:24,480 --> 00:36:25,760
to solve

886
00:36:25,760 --> 00:36:27,599
you don't have to solve the general but

887
00:36:27,599 --> 00:36:29,520
you can solve that problem or you can

888
00:36:29,520 --> 00:36:31,440
actually light up that scenario and it

889
00:36:31,440 --> 00:36:33,920
can go a long way and this is something

890
00:36:33,920 --> 00:36:37,599
that um i i think is one way for applied

891
00:36:37,599 --> 00:36:40,720
cryptography to get into practice

892
00:36:40,720 --> 00:36:43,280
so let me give you one example

893
00:36:43,280 --> 00:36:46,160
this is something that

894
00:36:46,160 --> 00:36:48,960
again some researchers at microsoft

895
00:36:48,960 --> 00:36:52,240
research did just this this past

896
00:36:52,240 --> 00:36:53,440
spring

897
00:36:53,440 --> 00:36:56,320
and this is a beautiful marriage of our

898
00:36:56,320 --> 00:37:00,400
cryptography group um who built a

899
00:37:00,400 --> 00:37:02,640
secure encrypted arithmetic library

900
00:37:02,640 --> 00:37:06,799
called seal that allows you to

901
00:37:07,359 --> 00:37:08,800
build um

902
00:37:08,800 --> 00:37:11,520
protocols using homomorphic encryption

903
00:37:11,520 --> 00:37:13,040
and at the marriage between the

904
00:37:13,040 --> 00:37:15,359
cryptography group and the machine

905
00:37:15,359 --> 00:37:18,480
learning group and what and they applied

906
00:37:18,480 --> 00:37:21,280
it to a medical example and here the

907
00:37:21,280 --> 00:37:24,480
idea is that you have your your dna for

908
00:37:24,480 --> 00:37:26,000
instance or any

909
00:37:26,000 --> 00:37:27,760
personal

910
00:37:27,760 --> 00:37:30,720
uh health records that you want to

911
00:37:30,720 --> 00:37:32,640
put into the cloud

912
00:37:32,640 --> 00:37:34,320
and you want you don't want the cloud to

913
00:37:34,320 --> 00:37:35,839
read your data

914
00:37:35,839 --> 00:37:38,000
but you want interesting analysis to be

915
00:37:38,000 --> 00:37:40,000
done of your

916
00:37:40,000 --> 00:37:43,680
say your private data for instance if i

917
00:37:43,680 --> 00:37:45,839
have a disease i would like it to be

918
00:37:45,839 --> 00:37:47,520
compared to some model that's been

919
00:37:47,520 --> 00:37:49,440
trained to detect whether i have that

920
00:37:49,440 --> 00:37:50,960
disease or not

921
00:37:50,960 --> 00:37:53,760
and so you can imagine a cloud service

922
00:37:53,760 --> 00:37:57,119
that um analyzes genomic data and does

923
00:37:57,119 --> 00:37:58,880
some prediction or at least some

924
00:37:58,880 --> 00:38:02,960
classification based on individual dna

925
00:38:02,960 --> 00:38:05,920
and so but you want this all secure um

926
00:38:05,920 --> 00:38:07,920
and so this is the exam this is the

927
00:38:07,920 --> 00:38:10,079
motivating example so this is i think is

928
00:38:10,079 --> 00:38:13,359
a pretty common motivating example so

929
00:38:13,359 --> 00:38:15,760
how can we do this in a

930
00:38:15,760 --> 00:38:17,680
um

931
00:38:17,680 --> 00:38:20,480
practical and secure way

932
00:38:20,480 --> 00:38:23,520
well the machine learning um

933
00:38:23,520 --> 00:38:25,920
people on on the team

934
00:38:25,920 --> 00:38:28,000
basically said well we could use deep

935
00:38:28,000 --> 00:38:30,640
learning to do the classification the

936
00:38:30,640 --> 00:38:33,119
training and so on and this is all fine

937
00:38:33,119 --> 00:38:34,240
and dandy

938
00:38:34,240 --> 00:38:36,240
um and what's

939
00:38:36,240 --> 00:38:37,280
what's

940
00:38:37,280 --> 00:38:39,440
interesting about in particular this

941
00:38:39,440 --> 00:38:43,680
deep learning method is that uh you know

942
00:38:43,680 --> 00:38:45,680
yes we use these sigmoid functions and

943
00:38:45,680 --> 00:38:47,440
blah blah blah blah and the cryptography

944
00:38:47,440 --> 00:38:49,119
people will say well we don't actually

945
00:38:49,119 --> 00:38:51,680
know how to make those functions

946
00:38:51,680 --> 00:38:54,640
homomorphically you know we can't apply

947
00:38:54,640 --> 00:38:56,400
homomorphic encryption so easily to

948
00:38:56,400 --> 00:38:58,640
those functions but this is where the

949
00:38:58,640 --> 00:39:00,320
marriage between cryptography and

950
00:39:00,320 --> 00:39:02,400
machine learning come together

951
00:39:02,400 --> 00:39:05,359
because what the seal library can do

952
00:39:05,359 --> 00:39:07,119
is basically let you compute over

953
00:39:07,119 --> 00:39:10,000
polynomials really quickly

954
00:39:10,000 --> 00:39:12,160
and so what is the

955
00:39:12,160 --> 00:39:16,560
the simplest and so so um in in these

956
00:39:16,560 --> 00:39:18,320
machine learning algorithms it's not so

957
00:39:18,320 --> 00:39:21,839
much it has to be a sigmoid or

958
00:39:21,839 --> 00:39:24,720
these fancy functions what's important

959
00:39:24,720 --> 00:39:27,440
is that it has to be non-linear

960
00:39:27,440 --> 00:39:29,839
and so this is the aha you know what is

961
00:39:29,839 --> 00:39:32,320
the simplest

962
00:39:32,320 --> 00:39:34,160
nonlinear function

963
00:39:34,160 --> 00:39:36,880
well let's say i'll give you a hint what

964
00:39:36,880 --> 00:39:41,680
is the simplest nonlinear polynomial

965
00:39:41,680 --> 00:39:42,880
that

966
00:39:42,880 --> 00:39:44,240
you could

967
00:39:44,240 --> 00:39:46,079
use

968
00:39:46,079 --> 00:39:47,359
and you know

969
00:39:47,359 --> 00:39:49,200
it was

970
00:39:49,200 --> 00:39:51,119
once that aha

971
00:39:51,119 --> 00:39:53,200
once the the cryptographers and machine

972
00:39:53,200 --> 00:39:55,040
learning people realized oh i have a

973
00:39:55,040 --> 00:39:56,640
toolbox for you

974
00:39:56,640 --> 00:39:59,760
and i this toolbox works in a way that

975
00:39:59,760 --> 00:40:02,240
you wouldn't imagine uh and you put them

976
00:40:02,240 --> 00:40:03,200
together

977
00:40:03,200 --> 00:40:06,000
then then the lights

978
00:40:06,000 --> 00:40:09,599
go on and so we were able to use this

979
00:40:09,599 --> 00:40:11,839
secure encrypted

980
00:40:11,839 --> 00:40:14,079
arithmetic library

981
00:40:14,079 --> 00:40:15,599
to build these

982
00:40:15,599 --> 00:40:18,079
machine learning algorithms

983
00:40:18,079 --> 00:40:20,400
and they perform quite well so this is a

984
00:40:20,400 --> 00:40:22,480
canonical

985
00:40:22,480 --> 00:40:25,359
image set of these optical character

986
00:40:25,359 --> 00:40:26,560
recognition

987
00:40:26,560 --> 00:40:30,240
numbers from mnist and we can do

988
00:40:30,240 --> 00:40:33,520
predictions uh in within five minutes

989
00:40:33,520 --> 00:40:35,200
the reason we can do

990
00:40:35,200 --> 00:40:36,800
4096

991
00:40:36,800 --> 00:40:38,560
predictions in five minutes is because

992
00:40:38,560 --> 00:40:41,760
of the highly parallel nature of how you

993
00:40:41,760 --> 00:40:43,760
actually are computing over the

994
00:40:43,760 --> 00:40:45,839
polynomials

995
00:40:45,839 --> 00:40:49,119
and we did a pneumonia risk predictor

996
00:40:49,119 --> 00:40:52,800
on medical records again this is this is

997
00:40:52,800 --> 00:40:54,319
fast enough

998
00:40:54,319 --> 00:40:57,680
um and if if it's your dna

999
00:40:57,680 --> 00:41:00,880
you'd be willing to wait 40 seconds or

1000
00:41:00,880 --> 00:41:04,000
two seconds so this is pretty this is

1001
00:41:04,000 --> 00:41:05,599
state of the art

1002
00:41:05,599 --> 00:41:08,000
these are three

1003
00:41:08,000 --> 00:41:11,280
granted demo applications but it goes to

1004
00:41:11,280 --> 00:41:12,400
show

1005
00:41:12,400 --> 00:41:14,160
what is possible

1006
00:41:14,160 --> 00:41:17,520
and we released the cl library to the

1007
00:41:17,520 --> 00:41:20,480
public last november so i encourage all

1008
00:41:20,480 --> 00:41:23,119
of you who are interested to go ahead

1009
00:41:23,119 --> 00:41:25,440
and you know do your research projects

1010
00:41:25,440 --> 00:41:28,480
using this library

1011
00:41:28,480 --> 00:41:29,440
okay

1012
00:41:29,440 --> 00:41:33,760
um one one last challenge i wanted to

1013
00:41:33,760 --> 00:41:37,040
pose to all of you in the audience is

1014
00:41:37,040 --> 00:41:40,160
how can mutually dis

1015
00:41:40,160 --> 00:41:43,760
dis trusting parties share data sets to

1016
00:41:43,760 --> 00:41:46,000
benefit from their union

1017
00:41:46,000 --> 00:41:49,040
and so here is the setup you've got lots

1018
00:41:49,040 --> 00:41:51,760
of different hospitals each hospital has

1019
00:41:51,760 --> 00:41:53,599
certain patient data

1020
00:41:53,599 --> 00:41:55,280
and you know that

1021
00:41:55,280 --> 00:41:58,000
if you can combine all the patient data

1022
00:41:58,000 --> 00:42:00,400
from all the hospitals the way i like to

1023
00:42:00,400 --> 00:42:02,800
put it is you can build the uber machine

1024
00:42:02,800 --> 00:42:04,240
learning model

1025
00:42:04,240 --> 00:42:07,040
that can do this classification

1026
00:42:07,040 --> 00:42:09,359
based on some disease or not

1027
00:42:09,359 --> 00:42:11,200
but the hospitals don't want each other

1028
00:42:11,200 --> 00:42:12,720
to see

1029
00:42:12,720 --> 00:42:14,640
each other's patient data so we want to

1030
00:42:14,640 --> 00:42:18,000
do this you know build this uber model

1031
00:42:18,000 --> 00:42:20,079
let's say in by

1032
00:42:20,079 --> 00:42:23,200
in the cloud um and we want to do it in

1033
00:42:23,200 --> 00:42:26,160
a way that the

1034
00:42:26,160 --> 00:42:28,960
hospitals can't see each other's data

1035
00:42:28,960 --> 00:42:32,480
so again we can appeal to either

1036
00:42:32,480 --> 00:42:35,200
using applied crypto for instance secure

1037
00:42:35,200 --> 00:42:37,440
multi-party computation

1038
00:42:37,440 --> 00:42:41,280
or hardware approaches um like intel sgx

1039
00:42:41,280 --> 00:42:42,640
enclaves

1040
00:42:42,640 --> 00:42:46,560
um and so this this again is is

1041
00:42:46,560 --> 00:42:48,800
once once i say this i think all of you

1042
00:42:48,800 --> 00:42:52,319
can run home and go go figure out how to

1043
00:42:52,319 --> 00:42:53,359
do this

1044
00:42:53,359 --> 00:42:55,040
but this is where

1045
00:42:55,040 --> 00:42:57,280
this is where this is state of the art

1046
00:42:57,280 --> 00:42:59,440
this is where we could potentially be

1047
00:42:59,440 --> 00:43:02,560
going um and this is what i mean by

1048
00:43:02,560 --> 00:43:04,960
providing

1049
00:43:04,960 --> 00:43:08,800
technology solutions to what today

1050
00:43:08,800 --> 00:43:13,119
is done in terms of policy and rules and

1051
00:43:13,119 --> 00:43:14,640
regulation

1052
00:43:14,640 --> 00:43:16,800
with respect to in promising and

1053
00:43:16,800 --> 00:43:20,560
ensuring privacy to customers

1054
00:43:20,560 --> 00:43:22,880
um there's an interesting twist on this

1055
00:43:22,880 --> 00:43:25,119
which is i've always said to

1056
00:43:25,119 --> 00:43:26,960
the people okay yeah i can build this

1057
00:43:26,960 --> 00:43:29,440
uber machine learning model but then i

1058
00:43:29,440 --> 00:43:32,880
can also build a machine learning model

1059
00:43:32,880 --> 00:43:35,520
per hospital and then i can do

1060
00:43:35,520 --> 00:43:37,359
what i would essentially call a diff

1061
00:43:37,359 --> 00:43:39,839
between the uber model and my model and

1062
00:43:39,839 --> 00:43:41,760
then maybe figure out some information

1063
00:43:41,760 --> 00:43:42,800
about

1064
00:43:42,800 --> 00:43:45,280
the other patient data and

1065
00:43:45,280 --> 00:43:46,240
that

1066
00:43:46,240 --> 00:43:48,240
that seems like a violation of what i'm

1067
00:43:48,240 --> 00:43:49,520
trying to achieve

1068
00:43:49,520 --> 00:43:52,960
um and so the way to address that is to

1069
00:43:52,960 --> 00:43:55,520
actually throw in differential privacy

1070
00:43:55,520 --> 00:43:57,040
um in terms of

1071
00:43:57,040 --> 00:43:58,720
returning the results

1072
00:43:58,720 --> 00:44:01,599
so it all comes together

1073
00:44:01,599 --> 00:44:04,720
but we as a community really have to

1074
00:44:04,720 --> 00:44:06,960
work work hard

1075
00:44:06,960 --> 00:44:08,880
to to make these

1076
00:44:08,880 --> 00:44:10,720
these technologies practical and

1077
00:44:10,720 --> 00:44:12,480
scalable

1078
00:44:12,480 --> 00:44:13,920
but if we can

1079
00:44:13,920 --> 00:44:16,240
then we can do so much

1080
00:44:16,240 --> 00:44:18,960
okay so i'm going to stop there

1081
00:44:18,960 --> 00:44:19,760
uh

1082
00:44:19,760 --> 00:44:22,240
and and just summarize i've been talking

1083
00:44:22,240 --> 00:44:24,240
about cyber physical systems but of

1084
00:44:24,240 --> 00:44:27,280
course i've also been talking about it

1085
00:44:27,280 --> 00:44:30,079
with with the lens of cyber trust

1086
00:44:30,079 --> 00:44:33,680
reliability security and privacy so

1087
00:44:33,680 --> 00:44:37,319
thank you very much

1088
00:44:43,839 --> 00:44:48,119
we have time for questions

1089
00:45:02,319 --> 00:45:04,630
hi brian

1090
00:45:04,630 --> 00:45:06,480
[Music]

1091
00:45:06,480 --> 00:45:08,800
hi rick farrow

1092
00:45:08,800 --> 00:45:09,920
um

1093
00:45:09,920 --> 00:45:11,760
i think it's really nice that you're

1094
00:45:11,760 --> 00:45:13,119
going to

1095
00:45:13,119 --> 00:45:14,880
do rewrites of

1096
00:45:14,880 --> 00:45:18,480
a lot of the basic parts of the internet

1097
00:45:18,480 --> 00:45:19,760
protocols although some of those

1098
00:45:19,760 --> 00:45:22,000
protocols are turing compute so there's

1099
00:45:22,000 --> 00:45:23,440
no way you can ever prove that they're

1100
00:45:23,440 --> 00:45:26,160
actually secures are secure

1101
00:45:26,160 --> 00:45:29,280
but i think what's way more important

1102
00:45:29,280 --> 00:45:32,079
i just looked it up there are 11 million

1103
00:45:32,079 --> 00:45:34,000
professional programmers in the world

1104
00:45:34,000 --> 00:45:35,119
today

1105
00:45:35,119 --> 00:45:36,000
and

1106
00:45:36,000 --> 00:45:37,520
obviously most of them are not in this

1107
00:45:37,520 --> 00:45:38,960
room

1108
00:45:38,960 --> 00:45:41,040
okay most of them do not even belong to

1109
00:45:41,040 --> 00:45:44,000
acm they're not professors

1110
00:45:44,000 --> 00:45:46,960
what we find are examples like what we

1111
00:45:46,960 --> 00:45:49,280
saw in the failure of telematics last

1112
00:45:49,280 --> 00:45:50,880
year the um

1113
00:45:50,880 --> 00:45:53,359
ian foster paper at woot where they

1114
00:45:53,359 --> 00:45:56,240
found a telematics device that had the

1115
00:45:56,240 --> 00:45:58,720
telnet port open

1116
00:45:58,720 --> 00:46:02,240
and it was mapped to an ip address

1117
00:46:02,240 --> 00:46:04,480
you could also update this device over

1118
00:46:04,480 --> 00:46:06,720
the internet they had installed the

1119
00:46:06,720 --> 00:46:08,319
private key

1120
00:46:08,319 --> 00:46:11,119
of the you know the ssh key pair on the

1121
00:46:11,119 --> 00:46:12,319
device

1122
00:46:12,319 --> 00:46:14,400
now this is because the people who are

1123
00:46:14,400 --> 00:46:18,000
programming don't understand security

1124
00:46:18,000 --> 00:46:20,720
they get a tool kit they use the tool

1125
00:46:20,720 --> 00:46:21,520
kit

1126
00:46:21,520 --> 00:46:24,240
to the best of their ability and they do

1127
00:46:24,240 --> 00:46:26,480
things like leave in the debugging the

1128
00:46:26,480 --> 00:46:28,880
debugging ports so what i think we

1129
00:46:28,880 --> 00:46:31,680
really need are tools that make building

1130
00:46:31,680 --> 00:46:33,760
secure devices

1131
00:46:33,760 --> 00:46:35,920
brain dead simple

1132
00:46:35,920 --> 00:46:37,680
so by default when you're finished

1133
00:46:37,680 --> 00:46:39,839
building this device it doesn't have

1134
00:46:39,839 --> 00:46:41,760
these dangling things hanging off that

1135
00:46:41,760 --> 00:46:43,359
make them easier to hack

1136
00:46:43,359 --> 00:46:45,119
so this is one of the things i suggest

1137
00:46:45,119 --> 00:46:46,480
people would think about when they're

1138
00:46:46,480 --> 00:46:47,920
thinking about building a secure

1139
00:46:47,920 --> 00:46:49,200
internet

1140
00:46:49,200 --> 00:46:50,880
comment i'd like to

1141
00:46:50,880 --> 00:46:52,880
comment on that thank you for that

1142
00:46:52,880 --> 00:46:55,040
comment and question

1143
00:46:55,040 --> 00:46:57,359
i do think that

1144
00:46:57,359 --> 00:46:59,359
uh especially for the faculty in the

1145
00:46:59,359 --> 00:47:02,079
audience it is our responsibility as

1146
00:47:02,079 --> 00:47:03,440
we're teaching

1147
00:47:03,440 --> 00:47:05,760
software engineering and programming and

1148
00:47:05,760 --> 00:47:08,000
and computing and operating system

1149
00:47:08,000 --> 00:47:09,359
whatever you know when we're teaching

1150
00:47:09,359 --> 00:47:11,520
computer science to our students

1151
00:47:11,520 --> 00:47:13,599
we do need to

1152
00:47:13,599 --> 00:47:16,960
have them have security in their mind um

1153
00:47:16,960 --> 00:47:18,880
it's not an add-on it's not something

1154
00:47:18,880 --> 00:47:21,280
you think about after the fact it's

1155
00:47:21,280 --> 00:47:22,960
something that it's it's part of

1156
00:47:22,960 --> 00:47:24,640
defensive programming whatever you want

1157
00:47:24,640 --> 00:47:28,079
to call it so i do hope that

1158
00:47:28,079 --> 00:47:29,680
more and more

1159
00:47:29,680 --> 00:47:31,920
relevant courses are

1160
00:47:31,920 --> 00:47:34,800
are being developed and taught

1161
00:47:34,800 --> 00:47:37,680
or at least in in some of the courses

1162
00:47:37,680 --> 00:47:38,640
where

1163
00:47:38,640 --> 00:47:40,079
um

1164
00:47:40,079 --> 00:47:42,640
where where it's like networking or

1165
00:47:42,640 --> 00:47:45,440
operating systems that it's it's part of

1166
00:47:45,440 --> 00:47:48,079
the course curricula

1167
00:47:48,079 --> 00:47:50,160
because first of all

1168
00:47:50,160 --> 00:47:52,880
it is it is we who are teaching the next

1169
00:47:52,880 --> 00:47:54,160
generation

1170
00:47:54,160 --> 00:47:55,359
programmers

1171
00:47:55,359 --> 00:47:57,839
um and and also

1172
00:47:57,839 --> 00:48:00,720
companies are looking for

1173
00:48:00,720 --> 00:48:03,599
for that expertise coming out of

1174
00:48:03,599 --> 00:48:07,839
undergraduate and master's programs

1175
00:48:08,240 --> 00:48:09,760
thank you

1176
00:48:09,760 --> 00:48:11,200
brian

1177
00:48:11,200 --> 00:48:14,400
all right uh brian ford epfl um i

1178
00:48:14,400 --> 00:48:16,800
enjoyed your talk you alluded a couple

1179
00:48:16,800 --> 00:48:20,640
times to what i perceive as kind of a uh

1180
00:48:20,640 --> 00:48:21,440
a

1181
00:48:21,440 --> 00:48:22,960
um

1182
00:48:22,960 --> 00:48:24,559
a coming

1183
00:48:24,559 --> 00:48:25,760
cold war

1184
00:48:25,760 --> 00:48:28,480
you know mini cold war in the

1185
00:48:28,480 --> 00:48:31,200
security community between the two very

1186
00:48:31,200 --> 00:48:33,040
different philosophies of getting of

1187
00:48:33,040 --> 00:48:34,400
data protection

1188
00:48:34,400 --> 00:48:37,599
they're between the kind of fancy crypto

1189
00:48:37,599 --> 00:48:40,559
side versus the justin just trust intel

1190
00:48:40,559 --> 00:48:42,880
side uh you know kind of uh

1191
00:48:42,880 --> 00:48:44,800
approach right yeah there's a lot of

1192
00:48:44,800 --> 00:48:47,599
things you can do with fancy difficult

1193
00:48:47,599 --> 00:48:50,640
heavyweight you know crypto of you know

1194
00:48:50,640 --> 00:48:52,720
various kinds but you can also achieve

1195
00:48:52,720 --> 00:48:55,119
the same thing just with sgx and you

1196
00:48:55,119 --> 00:48:56,079
know

1197
00:48:56,079 --> 00:48:58,880
um can you comment more on that you know

1198
00:48:58,880 --> 00:49:01,520
kind of predict uh do you have

1199
00:49:01,520 --> 00:49:04,240
uh you know positions uh

1200
00:49:04,240 --> 00:49:06,480
to to state you know what do you think

1201
00:49:06,480 --> 00:49:07,200
the

1202
00:49:07,200 --> 00:49:09,359
uh preferred or less preferred outcome

1203
00:49:09,359 --> 00:49:11,200
of this possible

1204
00:49:11,200 --> 00:49:13,839
you know uh upcoming war might be or am

1205
00:49:13,839 --> 00:49:17,280
i just uh i don't think there's a war

1206
00:49:17,280 --> 00:49:18,960
okay

1207
00:49:18,960 --> 00:49:22,319
i think um we as scientists and

1208
00:49:22,319 --> 00:49:26,800
engineers technologists really should be

1209
00:49:26,800 --> 00:49:31,000
using our entire arsenal

1210
00:49:31,119 --> 00:49:33,040
to fight the real war

1211
00:49:33,040 --> 00:49:35,599
um which is the

1212
00:49:35,599 --> 00:49:38,319
the bad guys in the security world um

1213
00:49:38,319 --> 00:49:39,599
and we shouldn't be fighting each other

1214
00:49:39,599 --> 00:49:40,800
for sure

1215
00:49:40,800 --> 00:49:42,640
i think we can be

1216
00:49:42,640 --> 00:49:44,640
i i think some of it is a matter of

1217
00:49:44,640 --> 00:49:46,079
timing

1218
00:49:46,079 --> 00:49:49,040
um some of it is a matter of application

1219
00:49:49,040 --> 00:49:51,440
so i i think that

1220
00:49:51,440 --> 00:49:53,839
let me just state a little clearer

1221
00:49:53,839 --> 00:49:56,640
um in terms of hardware-like approaches

1222
00:49:56,640 --> 00:50:00,240
like sgx's and so on um i think there's

1223
00:50:00,240 --> 00:50:03,040
a lot of promise there and if we do

1224
00:50:03,040 --> 00:50:05,760
eventually see widespread deployment of

1225
00:50:05,760 --> 00:50:07,839
those kinds of processors

1226
00:50:07,839 --> 00:50:10,079
um

1227
00:50:10,079 --> 00:50:13,200
it's it's really it's it's going to

1228
00:50:13,200 --> 00:50:15,200
quote i i hate using this trade turn

1229
00:50:15,200 --> 00:50:16,720
light up a lot of scenarios that we

1230
00:50:16,720 --> 00:50:18,480
would love to see

1231
00:50:18,480 --> 00:50:20,640
that doesn't mean that it's going to

1232
00:50:20,640 --> 00:50:22,800
solve the security problem because

1233
00:50:22,800 --> 00:50:24,559
you're still running

1234
00:50:24,559 --> 00:50:26,640
code in that enclave

1235
00:50:26,640 --> 00:50:27,920
and yeah

1236
00:50:27,920 --> 00:50:30,079
and in the end you should be verifying

1237
00:50:30,079 --> 00:50:31,839
that code right so there's still that

1238
00:50:31,839 --> 00:50:34,400
verification problem there are still

1239
00:50:34,400 --> 00:50:36,960
questions of side channel attacks um on

1240
00:50:36,960 --> 00:50:39,760
all sorts of security

1241
00:50:39,760 --> 00:50:42,640
issues that you know this community

1242
00:50:42,640 --> 00:50:45,119
likes to think about so it's not the be

1243
00:50:45,119 --> 00:50:46,800
all and end-all

1244
00:50:46,800 --> 00:50:49,359
but i think we need to make progress

1245
00:50:49,359 --> 00:50:51,280
using hardware approaches and seeing

1246
00:50:51,280 --> 00:50:53,839
what we can do

1247
00:50:53,839 --> 00:50:56,319
both from a definitive security point of

1248
00:50:56,319 --> 00:50:58,800
view but also from a practical scalable

1249
00:50:58,800 --> 00:51:00,400
point of view

1250
00:51:00,400 --> 00:51:02,720
at the same time we are already and i

1251
00:51:02,720 --> 00:51:04,800
think this is this is

1252
00:51:04,800 --> 00:51:08,000
i i'm quite impressed

1253
00:51:08,000 --> 00:51:11,680
with how far applied crypto has come to

1254
00:51:11,680 --> 00:51:14,720
be actually practical and scalable and i

1255
00:51:14,720 --> 00:51:16,000
think we should

1256
00:51:16,000 --> 00:51:19,040
stop this meme of cryptography is

1257
00:51:19,040 --> 00:51:22,400
expensive or we can't we can't we can't

1258
00:51:22,400 --> 00:51:24,160
possibly what's

1259
00:51:24,160 --> 00:51:25,839
when you when people say the word

1260
00:51:25,839 --> 00:51:28,559
cryptography you know in say you

1261
00:51:28,559 --> 00:51:30,319
shouldn't be running away thinking oh

1262
00:51:30,319 --> 00:51:32,800
god it's never going to perform well

1263
00:51:32,800 --> 00:51:35,440
rather we should say what can we do with

1264
00:51:35,440 --> 00:51:38,319
the crypto we know that can perform well

1265
00:51:38,319 --> 00:51:41,119
because you can actually do quite a lot

1266
00:51:41,119 --> 00:51:43,359
and so rather than again trying to solve

1267
00:51:43,359 --> 00:51:44,319
the

1268
00:51:44,319 --> 00:51:47,520
whole problem let's take what we know

1269
00:51:47,520 --> 00:51:50,079
can work and see what interesting

1270
00:51:50,079 --> 00:51:52,720
problems we can solve with what we know

1271
00:51:52,720 --> 00:51:54,000
can work

1272
00:51:54,000 --> 00:51:55,200
so

1273
00:51:55,200 --> 00:51:58,160
what i do see happening is

1274
00:51:58,160 --> 00:51:59,920
you know

1275
00:51:59,920 --> 00:52:03,119
parallel threads with advances in both

1276
00:52:03,119 --> 00:52:05,119
deployment and

1277
00:52:05,119 --> 00:52:06,640
you know

1278
00:52:06,640 --> 00:52:09,359
exploration of hardware approaches

1279
00:52:09,359 --> 00:52:11,599
with

1280
00:52:11,599 --> 00:52:13,440
emboldening

1281
00:52:13,440 --> 00:52:16,400
um and confidence building of the

1282
00:52:16,400 --> 00:52:19,040
applied crypto community oh

1283
00:52:19,040 --> 00:52:20,640
we can do that

1284
00:52:20,640 --> 00:52:24,160
wow what else can we do and

1285
00:52:24,160 --> 00:52:27,119
the performance isn't that bad you know

1286
00:52:27,119 --> 00:52:28,400
so i think

1287
00:52:28,400 --> 00:52:31,040
this is this is a great time actually to

1288
00:52:31,040 --> 00:52:32,880
be um

1289
00:52:32,880 --> 00:52:36,559
doing privacy related

1290
00:52:36,559 --> 00:52:38,079
uh

1291
00:52:38,079 --> 00:52:39,839
crypto and

1292
00:52:39,839 --> 00:52:40,559
and

1293
00:52:40,559 --> 00:52:41,359
and

1294
00:52:41,359 --> 00:52:44,160
so on so anyway that's does that help i

1295
00:52:44,160 --> 00:52:46,800
don't think i i'm just not a war person

1296
00:52:46,800 --> 00:52:49,280
i i i don't think we should be thinking

1297
00:52:49,280 --> 00:52:50,160
about

1298
00:52:50,160 --> 00:52:53,040
fighting each other

1299
00:52:54,800 --> 00:52:56,000
stefan

1300
00:52:56,000 --> 00:52:57,920
hi jeanette so uh one of the things i

1301
00:52:57,920 --> 00:52:59,520
think is really interesting about the

1302
00:52:59,520 --> 00:53:01,920
cyber physical realm is is that you need

1303
00:53:01,920 --> 00:53:03,359
to touch the real world and as you

1304
00:53:03,359 --> 00:53:05,359
alluded in the earlier part you start

1305
00:53:05,359 --> 00:53:07,839
dealing with things like probabilities

1306
00:53:07,839 --> 00:53:08,960
because

1307
00:53:08,960 --> 00:53:11,040
you don't know you know in real world

1308
00:53:11,040 --> 00:53:13,599
there's going to be updrafts and so your

1309
00:53:13,599 --> 00:53:15,200
drone is going to be moving up and your

1310
00:53:15,200 --> 00:53:17,200
control laws subject to all kinds of

1311
00:53:17,200 --> 00:53:18,720
other things

1312
00:53:18,720 --> 00:53:21,280
what that change is though is that

1313
00:53:21,280 --> 00:53:22,720
instead of the kind of binary

1314
00:53:22,720 --> 00:53:24,400
propositions that we're used to checking

1315
00:53:24,400 --> 00:53:26,240
in traditional formal methods is that

1316
00:53:26,240 --> 00:53:27,760
we're now doing something which is much

1317
00:53:27,760 --> 00:53:30,240
more akin to saying is this a plausible

1318
00:53:30,240 --> 00:53:31,520
scenario

1319
00:53:31,520 --> 00:53:32,960
that we're in

1320
00:53:32,960 --> 00:53:37,119
and that leaves that slop leaves open

1321
00:53:37,119 --> 00:53:38,240
the door

1322
00:53:38,240 --> 00:53:40,480
for all kinds of mischief in the same

1323
00:53:40,480 --> 00:53:42,640
way that for example in basketball it

1324
00:53:42,640 --> 00:53:45,200
opens up the door for point shaving

1325
00:53:45,200 --> 00:53:47,599
right it is plausible that they beat the

1326
00:53:47,599 --> 00:53:49,680
point spread but still won

1327
00:53:49,680 --> 00:53:51,680
and you can't you can only look at a

1328
00:53:51,680 --> 00:53:53,280
large number of events statistically and

1329
00:53:53,280 --> 00:53:54,880
say yeah there's probably point shaving

1330
00:53:54,880 --> 00:53:56,960
going on in the ncaa we know it we can't

1331
00:53:56,960 --> 00:53:58,640
say which shot

1332
00:53:58,640 --> 00:54:00,640
was malicious but we know that it's

1333
00:54:00,640 --> 00:54:02,000
happening

1334
00:54:02,000 --> 00:54:05,119
how do you envision us dealing with

1335
00:54:05,119 --> 00:54:07,040
those kinds of challenges and being able

1336
00:54:07,040 --> 00:54:08,960
to reason about

1337
00:54:08,960 --> 00:54:12,880
what collections of plausibly okay

1338
00:54:12,880 --> 00:54:14,000
things

1339
00:54:14,000 --> 00:54:16,960
happening together could do that's bad

1340
00:54:16,960 --> 00:54:18,640
because we don't have any correlation

1341
00:54:18,640 --> 00:54:21,520
we're used to having these hard and fast

1342
00:54:21,520 --> 00:54:23,680
binary propositions either it's safe or

1343
00:54:23,680 --> 00:54:25,119
it's not safe and all of a sudden we're

1344
00:54:25,119 --> 00:54:27,440
in this world of yeah it's between here

1345
00:54:27,440 --> 00:54:29,119
and here and collections of things are

1346
00:54:29,119 --> 00:54:31,119
between here and here and then something

1347
00:54:31,119 --> 00:54:35,520
happens yeah this is this is really uh

1348
00:54:35,520 --> 00:54:38,160
this is the heart of the

1349
00:54:38,160 --> 00:54:41,200
to in terms of where the technology is

1350
00:54:41,200 --> 00:54:44,160
uh going uh if we're for instance

1351
00:54:44,160 --> 00:54:46,079
writing probabilistic programs and

1352
00:54:46,079 --> 00:54:48,640
probabilities are inherent to

1353
00:54:48,640 --> 00:54:50,319
you know the program is correct with

1354
00:54:50,319 --> 00:54:54,000
risk with to some degree probability

1355
00:54:54,000 --> 00:54:57,359
that we no longer have these definitives

1356
00:54:57,359 --> 00:55:00,160
it's correct absolutely with respect to

1357
00:55:00,160 --> 00:55:02,319
some formal specification

1358
00:55:02,319 --> 00:55:03,920
um and

1359
00:55:03,920 --> 00:55:07,440
and and similarly or analogously you

1360
00:55:07,440 --> 00:55:09,119
know a lot of the

1361
00:55:09,119 --> 00:55:10,960
smarts that we're putting into these

1362
00:55:10,960 --> 00:55:14,079
systems are based on machine learning

1363
00:55:14,079 --> 00:55:15,760
algorithms that themselves are

1364
00:55:15,760 --> 00:55:18,640
statistically you know

1365
00:55:18,640 --> 00:55:22,079
um you know defined in terms of so

1366
00:55:22,079 --> 00:55:24,319
all of a sudden our whole world becomes

1367
00:55:24,319 --> 00:55:26,079
very approximate

1368
00:55:26,079 --> 00:55:27,440
um and very

1369
00:55:27,440 --> 00:55:28,720
epsilon

1370
00:55:28,720 --> 00:55:30,880
uh and

1371
00:55:30,880 --> 00:55:33,680
it's it's um and we don't even know how

1372
00:55:33,680 --> 00:55:35,119
to prove things

1373
00:55:35,119 --> 00:55:38,319
securely or safely in an absolute way in

1374
00:55:38,319 --> 00:55:40,799
a scalable manner so yes we're opening

1375
00:55:40,799 --> 00:55:43,200
up a lots and lots

1376
00:55:43,200 --> 00:55:45,439
more

1377
00:55:47,520 --> 00:55:49,520
room for error

1378
00:55:49,520 --> 00:55:52,720
um and so that

1379
00:55:53,040 --> 00:55:55,359
that doesn't mean we should not do

1380
00:55:55,359 --> 00:55:58,400
anything though um i think we as a

1381
00:55:58,400 --> 00:56:01,440
community need to acknowledge this

1382
00:56:01,440 --> 00:56:05,040
and then work hard to see where can we

1383
00:56:05,040 --> 00:56:07,599
reduce

1384
00:56:07,599 --> 00:56:12,000
the sources of error or where can we

1385
00:56:12,000 --> 00:56:13,119
build

1386
00:56:13,119 --> 00:56:16,240
tools and systems and logics and models

1387
00:56:16,240 --> 00:56:17,520
to

1388
00:56:17,520 --> 00:56:20,000
give us more confidence

1389
00:56:20,000 --> 00:56:22,960
in the software and the algorithms that

1390
00:56:22,960 --> 00:56:24,960
we're implementing in software

1391
00:56:24,960 --> 00:56:25,760
in this

1392
00:56:25,760 --> 00:56:28,640
cyber physical systems

1393
00:56:28,640 --> 00:56:29,599
and

1394
00:56:29,599 --> 00:56:30,480
we

1395
00:56:30,480 --> 00:56:32,079
will

1396
00:56:32,079 --> 00:56:34,000
we are

1397
00:56:34,000 --> 00:56:37,520
not going to get this all right

1398
00:56:37,520 --> 00:56:40,559
all at once in the very beginning

1399
00:56:40,559 --> 00:56:43,359
um we will learn over time

1400
00:56:43,359 --> 00:56:46,400
much as other engineering disciplines

1401
00:56:46,400 --> 00:56:49,599
have learned over time

1402
00:56:49,599 --> 00:56:50,480
and

1403
00:56:50,480 --> 00:56:53,280
but now that we are really

1404
00:56:53,280 --> 00:56:55,119
dealing with systems

1405
00:56:55,119 --> 00:56:55,920
that

1406
00:56:55,920 --> 00:56:57,359
truly can

1407
00:56:57,359 --> 00:57:00,559
be a life or death situation for us

1408
00:57:00,559 --> 00:57:03,359
in our self-driving car whatever it is

1409
00:57:03,359 --> 00:57:07,200
um it's no longer oh well you know

1410
00:57:07,200 --> 00:57:10,000
a blue screen of death so so i'll just

1411
00:57:10,000 --> 00:57:11,839
reboot

1412
00:57:11,839 --> 00:57:12,720
it's

1413
00:57:12,720 --> 00:57:14,559
it's serious stuff

1414
00:57:14,559 --> 00:57:17,520
um so i don't have an easy answer but i

1415
00:57:17,520 --> 00:57:20,400
acknowledge what you're saying it's very

1416
00:57:20,400 --> 00:57:23,040
very important

1417
00:57:23,440 --> 00:57:26,240
yes hi i'm bill cheswick um i love a

1418
00:57:26,240 --> 00:57:27,520
couple of the points you made the

1419
00:57:27,520 --> 00:57:30,240
probabilistic one as a drone owner who

1420
00:57:30,240 --> 00:57:32,000
has run into some trees and you had a

1421
00:57:32,000 --> 00:57:34,160
picture of a drone that ran into a bush

1422
00:57:34,160 --> 00:57:35,920
i would love to have it know that if

1423
00:57:35,920 --> 00:57:38,079
you're above 150 feet above ground there

1424
00:57:38,079 --> 00:57:40,720
are no trees and so it's safer and and

1425
00:57:40,720 --> 00:57:43,040
so on i love including that sort of data

1426
00:57:43,040 --> 00:57:45,040
and can imagine quite a bit in fact your

1427
00:57:45,040 --> 00:57:47,839
demo seemed to have a grassy area

1428
00:57:47,839 --> 00:57:50,160
surrounded by trees and that's exactly

1429
00:57:50,160 --> 00:57:52,240
where it should work i also love the

1430
00:57:52,240 --> 00:57:54,160
idea of proving something secure from

1431
00:57:54,160 --> 00:57:55,599
the silicon atoms all the way up to

1432
00:57:55,599 --> 00:57:57,440
https

1433
00:57:57,440 --> 00:58:00,000
but i did want to make one point um

1434
00:58:00,000 --> 00:58:01,760
it is true that a lot of our sensors are

1435
00:58:01,760 --> 00:58:04,000
going to be low power uh you know maybe

1436
00:58:04,000 --> 00:58:06,640
a moisture sensor in a corn field but

1437
00:58:06,640 --> 00:58:08,960
you gave thermostats and light bulbs as

1438
00:58:08,960 --> 00:58:11,280
being power restricted if your light

1439
00:58:11,280 --> 00:58:14,079
bulb is using too much cpu power

1440
00:58:14,079 --> 00:58:17,359
to handle that has too much power for

1441
00:58:17,359 --> 00:58:20,640
that given that micro sd cards

1442
00:58:20,640 --> 00:58:23,680
now have substantial cpus on a chip

1443
00:58:23,680 --> 00:58:25,280
um you might want to pick different

1444
00:58:25,280 --> 00:58:27,440
examples of low power use that that's

1445
00:58:27,440 --> 00:58:28,559
all

1446
00:58:28,559 --> 00:58:29,440
yeah

1447
00:58:29,440 --> 00:58:31,760
thanks

1448
00:58:31,920 --> 00:58:33,680
hi i'm len haws

1449
00:58:33,680 --> 00:58:36,720
u.s department of state

1450
00:58:36,720 --> 00:58:39,119
there's a considerable obviously amount

1451
00:58:39,119 --> 00:58:40,400
of talk

1452
00:58:40,400 --> 00:58:43,040
not only within research community

1453
00:58:43,040 --> 00:58:45,520
about you know the topics you brought up

1454
00:58:45,520 --> 00:58:48,079
but an equally if not larger amount of

1455
00:58:48,079 --> 00:58:50,160
discussion in the policy and

1456
00:58:50,160 --> 00:58:52,000
governmental community

1457
00:58:52,000 --> 00:58:52,960
and

1458
00:58:52,960 --> 00:58:54,000
and

1459
00:58:54,000 --> 00:58:55,599
a lot of these are being forced into

1460
00:58:55,599 --> 00:58:58,079
action because of events and other

1461
00:58:58,079 --> 00:58:59,440
things going on

1462
00:58:59,440 --> 00:59:01,119
in a myriad of

1463
00:59:01,119 --> 00:59:04,640
countries in a myriad of sectors

1464
00:59:04,640 --> 00:59:05,839
how

1465
00:59:05,839 --> 00:59:07,920
and i'm still feeling that there's a

1466
00:59:07,920 --> 00:59:10,160
fairly significant disconnect

1467
00:59:10,160 --> 00:59:11,200
in

1468
00:59:11,200 --> 00:59:13,359
you know the the amount of sharing of

1469
00:59:13,359 --> 00:59:15,920
information between these communities

1470
00:59:15,920 --> 00:59:18,400
and how do you approach

1471
00:59:18,400 --> 00:59:20,079
you know what's the what's the effort

1472
00:59:20,079 --> 00:59:21,920
that you're putting forward to saying

1473
00:59:21,920 --> 00:59:23,920
how do we get this information and your

1474
00:59:23,920 --> 00:59:26,559
work obviously you know along with some

1475
00:59:26,559 --> 00:59:29,680
of the other really great works going on

1476
00:59:29,680 --> 00:59:32,720
in into the policy

1477
00:59:32,720 --> 00:59:34,880
and discussion so that there's not just

1478
00:59:34,880 --> 00:59:36,240
fundamentally

1479
00:59:36,240 --> 00:59:39,920
you know a a disconnect or actions being

1480
00:59:39,920 --> 00:59:41,280
taken that are fundamentally

1481
00:59:41,280 --> 00:59:43,680
incompatible with what you see as the

1482
00:59:43,680 --> 00:59:46,799
end results so let me speak to that

1483
00:59:46,799 --> 00:59:49,440
very optimistically

1484
00:59:49,440 --> 00:59:51,839
i'm just an optimist anyway

1485
00:59:51,839 --> 00:59:56,079
two concrete examples um very recently

1486
00:59:56,079 --> 00:59:58,480
in the past couple of months

1487
00:59:58,480 --> 01:00:01,599
the white house through ostp

1488
01:00:01,599 --> 01:00:02,640
has

1489
01:00:02,640 --> 01:00:06,000
has convened a series of workshops

1490
01:00:06,000 --> 01:00:08,400
specifically looking at ai

1491
01:00:08,400 --> 01:00:09,760
and

1492
01:00:09,760 --> 01:00:12,079
the implications of ai

1493
01:00:12,079 --> 01:00:14,720
but one of the workshops that was

1494
01:00:14,720 --> 01:00:17,200
probably the most technical was one

1495
01:00:17,200 --> 01:00:20,079
called safe ai

1496
01:00:20,079 --> 01:00:22,240
and i attended it i actually gave a

1497
01:00:22,240 --> 01:00:25,680
snippet of my talk at that that workshop

1498
01:00:25,680 --> 01:00:27,760
um

1499
01:00:27,760 --> 01:00:30,640
because they do see that ai

1500
01:00:30,640 --> 01:00:33,760
you know uh machine learning and so on

1501
01:00:33,760 --> 01:00:34,559
is

1502
01:00:34,559 --> 01:00:37,040
is going to be everywhere uh

1503
01:00:37,040 --> 01:00:40,480
like self-driving cars and there

1504
01:00:40,480 --> 01:00:43,839
there is a concern that we like stefan

1505
01:00:43,839 --> 01:00:46,960
was saying um

1506
01:00:46,960 --> 01:00:48,480
there's a lot of room a lot more room

1507
01:00:48,480 --> 01:00:50,880
for error now and what about what is the

1508
01:00:50,880 --> 01:00:53,040
government going to do about that should

1509
01:00:53,040 --> 01:00:56,799
there be regulations and unusual and so

1510
01:00:56,799 --> 01:00:58,640
that workshop was really meant to

1511
01:00:58,640 --> 01:00:59,920
educate

1512
01:00:59,920 --> 01:01:02,640
um the government and there were

1513
01:01:02,640 --> 01:01:03,760
people from the department of

1514
01:01:03,760 --> 01:01:05,839
transportation there for instance

1515
01:01:05,839 --> 01:01:07,280
um on

1516
01:01:07,280 --> 01:01:09,680
technically what is possible today and

1517
01:01:09,680 --> 01:01:13,040
where the technology community is going

1518
01:01:13,040 --> 01:01:14,640
i think one of the most interesting

1519
01:01:14,640 --> 01:01:17,200
insights i gained not being an ai person

1520
01:01:17,200 --> 01:01:18,720
from that workshop

1521
01:01:18,720 --> 01:01:21,040
was um

1522
01:01:21,040 --> 01:01:23,520
was i think many of you probably know

1523
01:01:23,520 --> 01:01:25,040
this those of you who are working in

1524
01:01:25,040 --> 01:01:27,359
deep learning for instance um that

1525
01:01:27,359 --> 01:01:32,000
there's no explanatory power of of or

1526
01:01:32,000 --> 01:01:33,440
you know

1527
01:01:33,440 --> 01:01:35,599
the machine learning algorithm spits out

1528
01:01:35,599 --> 01:01:38,799
an answer and one can't explain why the

1529
01:01:38,799 --> 01:01:42,400
answer is what it is and so that is a

1530
01:01:42,400 --> 01:01:43,920
something that of course we in software

1531
01:01:43,920 --> 01:01:46,799
engineering um know is it uh has always

1532
01:01:46,799 --> 01:01:48,319
been an issue when you find a bug you

1533
01:01:48,319 --> 01:01:49,839
want to know what's the cause of that

1534
01:01:49,839 --> 01:01:51,920
bug and how can you trace back through a

1535
01:01:51,920 --> 01:01:54,880
piece of software um to explain

1536
01:01:54,880 --> 01:01:56,880
where that bug came from so there's a

1537
01:01:56,880 --> 01:01:58,160
whole other

1538
01:01:58,160 --> 01:02:01,119
whole interest in the ai community for

1539
01:02:01,119 --> 01:02:02,960
being able to explain

1540
01:02:02,960 --> 01:02:04,640
uh the answers

1541
01:02:04,640 --> 01:02:06,319
so so

1542
01:02:06,319 --> 01:02:08,559
to get to your question though the point

1543
01:02:08,559 --> 01:02:12,640
is at least the white house and ostp and

1544
01:02:12,640 --> 01:02:14,960
other federal agencies in the united

1545
01:02:14,960 --> 01:02:16,000
states

1546
01:02:16,000 --> 01:02:18,880
are being educated through talking with

1547
01:02:18,880 --> 01:02:21,119
the academic and research community it's

1548
01:02:21,119 --> 01:02:22,640
a first step

1549
01:02:22,640 --> 01:02:24,079
but it's a good

1550
01:02:24,079 --> 01:02:26,640
good first step and it's a recognition

1551
01:02:26,640 --> 01:02:28,000
um within

1552
01:02:28,000 --> 01:02:28,880
uh

1553
01:02:28,880 --> 01:02:31,039
you know within microsoft for instance

1554
01:02:31,039 --> 01:02:32,240
one of the

1555
01:02:32,240 --> 01:02:34,960
i hinted at this before you know one of

1556
01:02:34,960 --> 01:02:36,720
one of the things i've been trying to do

1557
01:02:36,720 --> 01:02:39,119
is to talk to our

1558
01:02:39,119 --> 01:02:40,000
um

1559
01:02:40,000 --> 01:02:42,480
legal and policy people who do set

1560
01:02:42,480 --> 01:02:45,119
privacy policies for the company and for

1561
01:02:45,119 --> 01:02:47,599
for a promises to the customers to try

1562
01:02:47,599 --> 01:02:50,799
to educate them um by saying well here

1563
01:02:50,799 --> 01:02:52,799
are certain technologies that we can

1564
01:02:52,799 --> 01:02:53,760
actually

1565
01:02:53,760 --> 01:02:57,280
you know build and deploy and and use it

1566
01:02:57,280 --> 01:02:58,960
that can

1567
01:02:58,960 --> 01:03:01,760
you know actually relax certain prime

1568
01:03:01,760 --> 01:03:06,000
stringent privacy policies or um

1569
01:03:06,000 --> 01:03:07,920
to use that trade phrase again light up

1570
01:03:07,920 --> 01:03:11,680
new scenarios so part of my job it where

1571
01:03:11,680 --> 01:03:14,160
where i sit is actually educating

1572
01:03:14,160 --> 01:03:18,480
our counterparts in in policy and legal

1573
01:03:18,480 --> 01:03:21,200
it does take a community effort now i

1574
01:03:21,200 --> 01:03:23,520
think what's very interesting is what

1575
01:03:23,520 --> 01:03:25,680
you were talking about in terms of

1576
01:03:25,680 --> 01:03:28,559
across nation and cross government

1577
01:03:28,559 --> 01:03:29,520
um

1578
01:03:29,520 --> 01:03:31,599
because their

1579
01:03:31,599 --> 01:03:33,760
people like us in the research and

1580
01:03:33,760 --> 01:03:36,319
academic community tend to not have a

1581
01:03:36,319 --> 01:03:39,359
voice at that table to say

1582
01:03:39,359 --> 01:03:42,839
hey you know it is actually possible

1583
01:03:42,839 --> 01:03:44,880
for say

1584
01:03:44,880 --> 01:03:46,160
governments

1585
01:03:46,160 --> 01:03:48,480
to share certain kinds of information

1586
01:03:48,480 --> 01:03:50,240
with each other in a

1587
01:03:50,240 --> 01:03:52,799
privacy preserving manner or

1588
01:03:52,799 --> 01:03:53,599
uh

1589
01:03:53,599 --> 01:03:54,480
you know

1590
01:03:54,480 --> 01:03:56,480
something like that so

1591
01:03:56,480 --> 01:03:58,799
that i don't i don't know of

1592
01:03:58,799 --> 01:03:59,599
uh

1593
01:03:59,599 --> 01:04:01,920
i i think i would have to rely on the

1594
01:04:01,920 --> 01:04:03,760
people who are currently in in

1595
01:04:03,760 --> 01:04:07,039
government agencies um like knighted is

1596
01:04:07,039 --> 01:04:09,599
probably a good example

1597
01:04:09,599 --> 01:04:10,400
where

1598
01:04:10,400 --> 01:04:13,680
people are placed to then talk to

1599
01:04:13,680 --> 01:04:16,319
um the us

1600
01:04:16,319 --> 01:04:18,720
you know part of that

1601
01:04:18,720 --> 01:04:21,520
conversation

1602
01:04:22,480 --> 01:04:24,839
oh and then there's darpa of

1603
01:04:24,839 --> 01:04:28,160
course drooting qualcomm research

1604
01:04:28,160 --> 01:04:29,039
um

1605
01:04:29,039 --> 01:04:31,039
nice talk thank you so a question i want

1606
01:04:31,039 --> 01:04:33,039
to ask is on the formal method side it

1607
01:04:33,039 --> 01:04:34,960
seems to me that many things that we

1608
01:04:34,960 --> 01:04:37,920
take to be invariants are in the real

1609
01:04:37,920 --> 01:04:40,480
world maybe i can call them almost

1610
01:04:40,480 --> 01:04:43,599
invariants with a drone or perhaps some

1611
01:04:43,599 --> 01:04:45,599
future passenger plane

1612
01:04:45,599 --> 01:04:47,440
don't do a maneuver which will crack the

1613
01:04:47,440 --> 01:04:49,839
airframe is something that we might

1614
01:04:49,839 --> 01:04:51,680
intuitively think of as an invariant

1615
01:04:51,680 --> 01:04:53,680
right now don't don't what don't don't

1616
01:04:53,680 --> 01:04:55,520
pull some maneuver that's going to cause

1617
01:04:55,520 --> 01:04:57,119
the airframe to crack

1618
01:04:57,119 --> 01:04:58,799
right that would be

1619
01:04:58,799 --> 01:05:00,079
an invariant

1620
01:05:00,079 --> 01:05:01,039
except

1621
01:05:01,039 --> 01:05:04,319
occasionally you want to violate that

1622
01:05:04,319 --> 01:05:06,480
right in the sense that if you're in a

1623
01:05:06,480 --> 01:05:09,520
dive and catastrophe is inevitable if

1624
01:05:09,520 --> 01:05:11,920
you don't pull out of the dive which may

1625
01:05:11,920 --> 01:05:14,240
cause the airframe to crack

1626
01:05:14,240 --> 01:05:15,680
uh

1627
01:05:15,680 --> 01:05:16,720
you know it's sort of like there's

1628
01:05:16,720 --> 01:05:18,799
inevitable catastrophe if i don't do

1629
01:05:18,799 --> 01:05:21,039
something this seems like something that

1630
01:05:21,039 --> 01:05:22,319
i i don't know that we have the

1631
01:05:22,319 --> 01:05:23,839
techniques to reason about i mean

1632
01:05:23,839 --> 01:05:25,599
another example of this is the hudson

1633
01:05:25,599 --> 01:05:27,520
river is not generally recommended as a

1634
01:05:27,520 --> 01:05:29,680
place to land a passenger plane

1635
01:05:29,680 --> 01:05:32,000
although that was actually

1636
01:05:32,000 --> 01:05:34,240
in so far as 100 plus people were saved

1637
01:05:34,240 --> 01:05:36,880
that was a good decision to make so how

1638
01:05:36,880 --> 01:05:38,319
do you see us dealing with this this is

1639
01:05:38,319 --> 01:05:39,200
a really

1640
01:05:39,200 --> 01:05:40,720
interesting um

1641
01:05:40,720 --> 01:05:43,119
question dilemma i remember when there

1642
01:05:43,119 --> 01:05:44,960
was the um

1643
01:05:44,960 --> 01:05:46,079
i think was

1644
01:05:46,079 --> 01:05:46,880
that

1645
01:05:46,880 --> 01:05:49,760
little german wings playing that flew

1646
01:05:49,760 --> 01:05:51,520
into the mountain or something and all

1647
01:05:51,520 --> 01:05:53,680
of us in the technical community said

1648
01:05:53,680 --> 01:05:54,559
well

1649
01:05:54,559 --> 01:05:56,000
we could have

1650
01:05:56,000 --> 01:05:58,640
programmed the thing to say if you're

1651
01:05:58,640 --> 01:06:00,319
this close to the mountain don't crash

1652
01:06:00,319 --> 01:06:02,000
into it right

1653
01:06:02,000 --> 01:06:04,240
and don't let the human override that

1654
01:06:04,240 --> 01:06:07,280
but for any case like where you don't

1655
01:06:07,280 --> 01:06:09,039
want to let the human

1656
01:06:09,039 --> 01:06:10,960
control it you have cases like the

1657
01:06:10,960 --> 01:06:12,960
hudson river where

1658
01:06:12,960 --> 01:06:14,480
by golly

1659
01:06:14,480 --> 01:06:16,880
thank god that

1660
01:06:16,880 --> 01:06:19,680
uh you know that human was in control

1661
01:06:19,680 --> 01:06:22,079
and had the savvy to to land a plane on

1662
01:06:22,079 --> 01:06:24,160
the hudson river so

1663
01:06:24,160 --> 01:06:26,640
um so first of all i think this

1664
01:06:26,640 --> 01:06:29,839
interesting dilemma um

1665
01:06:29,839 --> 01:06:32,559
in terms of formalizing

1666
01:06:32,559 --> 01:06:34,799
you know

1667
01:06:34,799 --> 01:06:37,200
what you ask is a very interesting

1668
01:06:37,200 --> 01:06:39,440
what you

1669
01:06:39,440 --> 01:06:41,039
suggested is very

1670
01:06:41,039 --> 01:06:43,039
interesting concept of an almost

1671
01:06:43,039 --> 01:06:44,319
invariant

1672
01:06:44,319 --> 01:06:46,400
so this is a new concept

1673
01:06:46,400 --> 01:06:49,440
maybe it makes sense um much like we

1674
01:06:49,440 --> 01:06:52,400
have approximate correctness to

1675
01:06:52,400 --> 01:06:54,720
understand what an almost invariant is

1676
01:06:54,720 --> 01:06:56,319
because though what i would say

1677
01:06:56,319 --> 01:06:58,880
immediately is you need to define

1678
01:06:58,880 --> 01:07:02,720
clearly the space of that almost so that

1679
01:07:02,720 --> 01:07:05,680
it's invariant with respect to

1680
01:07:05,680 --> 01:07:06,559
you know

1681
01:07:06,559 --> 01:07:10,799
this state space but not that right

1682
01:07:10,799 --> 01:07:13,280
so once you cross the line then all bets

1683
01:07:13,280 --> 01:07:16,000
are off my thinking out loud suggestion

1684
01:07:16,000 --> 01:07:17,680
is that you could somehow formally

1685
01:07:17,680 --> 01:07:21,839
reason that catastrophe is inevitable

1686
01:07:22,240 --> 01:07:23,920
and i i realize that needs to be

1687
01:07:23,920 --> 01:07:26,160
formalized as well and i i

1688
01:07:26,160 --> 01:07:29,119
leave that to people smarter than i

1689
01:07:29,119 --> 01:07:30,960
well the other thing is of course in

1690
01:07:30,960 --> 01:07:33,520
even in the um the

1691
01:07:33,520 --> 01:07:35,440
usual engineering community we talk

1692
01:07:35,440 --> 01:07:36,400
about

1693
01:07:36,400 --> 01:07:38,480
like five nines or

1694
01:07:38,480 --> 01:07:40,240
three nines or whatnot

1695
01:07:40,240 --> 01:07:42,400
so um

1696
01:07:42,400 --> 01:07:44,960
people who build real systems engineered

1697
01:07:44,960 --> 01:07:47,920
physical systems understand

1698
01:07:47,920 --> 01:07:50,400
um that it's not

1699
01:07:50,400 --> 01:07:52,799
a hundred percent something is going to

1700
01:07:52,799 --> 01:07:53,599
fail

1701
01:07:53,599 --> 01:07:58,720
but what is my tolerance for um an error

1702
01:07:58,720 --> 01:08:00,160
what is that

1703
01:08:00,160 --> 01:08:04,160
reliability nine that i'm shooting for

1704
01:08:04,160 --> 01:08:06,720
we don't have in software we don't we

1705
01:08:06,720 --> 01:08:08,720
still don't think about it

1706
01:08:08,720 --> 01:08:11,280
in subreddit we don't think about that

1707
01:08:11,280 --> 01:08:13,920
and and certainly in the kinds of

1708
01:08:13,920 --> 01:08:16,158
algorithms that we're deploying to make

1709
01:08:16,158 --> 01:08:18,158
our devices smarter like machine

1710
01:08:18,158 --> 01:08:20,719
learning and ai algorithms so on we're

1711
01:08:20,719 --> 01:08:23,279
not thinking about that

1712
01:08:23,279 --> 01:08:25,520
thank you

1713
01:08:25,520 --> 01:08:27,520
um so you also talked about project

1714
01:08:27,520 --> 01:08:29,359
everest which is a very interesting but

1715
01:08:29,359 --> 01:08:31,679
also very challenging project

1716
01:08:31,679 --> 01:08:33,679
um for some of the building blocks i can

1717
01:08:33,679 --> 01:08:35,600
see that they are small enough that we

1718
01:08:35,600 --> 01:08:37,439
can start from scratch

1719
01:08:37,439 --> 01:08:39,759
like this my tls work that's coming out

1720
01:08:39,759 --> 01:08:41,279
so there are certain building blocks

1721
01:08:41,279 --> 01:08:43,600
where we can basically start

1722
01:08:43,600 --> 01:08:45,759
and learn or use the lessons learned in

1723
01:08:45,759 --> 01:08:48,319
the last 20 or 30 years

1724
01:08:48,319 --> 01:08:50,479
on the other hand in this http ecosystem

1725
01:08:50,479 --> 01:08:52,399
they are also very complex

1726
01:08:52,399 --> 01:08:55,198
programs like webkit or edge which are

1727
01:08:55,198 --> 01:08:57,679
tens of millions of lines of code so can

1728
01:08:57,679 --> 01:09:00,000
you elaborate a bit on how you think we

1729
01:09:00,000 --> 01:09:02,880
can secure those large building blocks

1730
01:09:02,880 --> 01:09:05,359
in this http ecosystem

1731
01:09:05,359 --> 01:09:07,198
such that within the next few years we

1732
01:09:07,198 --> 01:09:09,120
have a built-in replacement in order to

1733
01:09:09,120 --> 01:09:11,520
actually prove that i can safely and

1734
01:09:11,520 --> 01:09:13,679
securely browse the web or are there

1735
01:09:13,679 --> 01:09:15,679
challenges that are likely not feasible

1736
01:09:15,679 --> 01:09:16,560
in this

1737
01:09:16,560 --> 01:09:20,279
rather short term

1738
01:09:20,560 --> 01:09:22,799
so you're talking about my big block

1739
01:09:22,799 --> 01:09:25,520
diagram right and you're saying

1740
01:09:25,520 --> 01:09:26,560
um

1741
01:09:26,560 --> 01:09:27,600
uh

1742
01:09:27,600 --> 01:09:29,359
yeah so some of these building blocks

1743
01:09:29,359 --> 01:09:31,920
are rather small there we can probably

1744
01:09:31,920 --> 01:09:34,000
start from scratch but we also have lots

1745
01:09:34,000 --> 01:09:36,880
of legacy code so millions of lines of

1746
01:09:36,880 --> 01:09:40,560
legacy code what do we do with this

1747
01:09:40,560 --> 01:09:43,198
so um cedric do you want to actually

1748
01:09:43,198 --> 01:09:46,080
answer that question

1749
01:09:46,158 --> 01:09:48,158
i mean we have the expert here and i

1750
01:09:48,158 --> 01:09:52,519
don't want to say anything wrong

1751
01:10:02,640 --> 01:10:05,440
yes uh thanks so um

1752
01:10:05,440 --> 01:10:06,400
so just

1753
01:10:06,400 --> 01:10:09,040
first of all the clarification so uh the

1754
01:10:09,040 --> 01:10:10,960
scope of the rs project is to verify

1755
01:10:10,960 --> 01:10:12,000
everything

1756
01:10:12,000 --> 01:10:15,440
from the https api down to

1757
01:10:15,440 --> 01:10:17,840
hardwire or cryptographic assumptions so

1758
01:10:17,840 --> 01:10:20,640
the code does not include verifying

1759
01:10:20,640 --> 01:10:22,320
a web browser for example it should be

1760
01:10:22,320 --> 01:10:24,800
the application of https

1761
01:10:24,800 --> 01:10:25,920
so

1762
01:10:25,920 --> 01:10:28,719
so you want to take https as an api and

1763
01:10:28,719 --> 01:10:30,719
implement it securely and then

1764
01:10:30,719 --> 01:10:32,880
get still get best effort security for

1765
01:10:32,880 --> 01:10:35,199
applications on top of https

1766
01:10:35,199 --> 01:10:36,960
so so now it means that for legacy

1767
01:10:36,960 --> 01:10:39,600
system we won't be able to get

1768
01:10:39,600 --> 01:10:42,480
full formal verification however for

1769
01:10:42,480 --> 01:10:44,400
well-defined subsystems like if you want

1770
01:10:44,400 --> 01:10:46,480
to do inverting or if you want to do

1771
01:10:46,480 --> 01:10:48,480
basic functionalities like

1772
01:10:48,480 --> 01:10:50,640
signing or

1773
01:10:50,640 --> 01:10:52,400
or well-defined cell application then

1774
01:10:52,400 --> 01:10:54,800
for those we can use or secure api and

1775
01:10:54,800 --> 01:10:56,320
do the extra mile of verifying the

1776
01:10:56,320 --> 01:10:58,560
application fully and get some security

1777
01:10:58,560 --> 01:11:00,159
out of it but

1778
01:11:00,159 --> 01:11:01,440
i don't think it will be for every

1779
01:11:01,440 --> 01:11:03,440
application builder of https we for

1780
01:11:03,440 --> 01:11:04,480
selected

1781
01:11:04,480 --> 01:11:06,159
simple well-defined applications on the

1782
01:11:06,159 --> 01:11:07,920
buffer for which we have a clear

1783
01:11:07,920 --> 01:11:10,080
specification to begin with

1784
01:11:10,080 --> 01:11:13,280
so no miracles there

1785
01:11:13,280 --> 01:11:15,679
thank you

1786
01:11:17,280 --> 01:11:18,880
hi deborah shant

1787
01:11:18,880 --> 01:11:20,080
currently at the national science

1788
01:11:20,080 --> 01:11:21,840
foundation um

1789
01:11:21,840 --> 01:11:24,159
i wonder how you

1790
01:11:24,159 --> 01:11:27,360
imagine some of these systems

1791
01:11:27,360 --> 01:11:28,800
will address

1792
01:11:28,800 --> 01:11:29,679
sort of

1793
01:11:29,679 --> 01:11:31,760
evolution of how people interact with

1794
01:11:31,760 --> 01:11:33,120
them over time

1795
01:11:33,120 --> 01:11:35,840
and um you know in terms of

1796
01:11:35,840 --> 01:11:37,840
the rules that are used

1797
01:11:37,840 --> 01:11:41,920
for reliability security anything else

1798
01:11:41,920 --> 01:11:43,120
and i'm thinking of the following

1799
01:11:43,120 --> 01:11:44,880
scenario um

1800
01:11:44,880 --> 01:11:48,239
i uh i'm from los angeles and in that

1801
01:11:48,239 --> 01:11:52,159
area i do not jaywalk you know i i would

1802
01:11:52,159 --> 01:11:55,440
risk life in limb absolutely

1803
01:11:55,440 --> 01:11:56,560
i'm

1804
01:11:56,560 --> 01:11:59,199
living in washington dc area now in an

1805
01:11:59,199 --> 01:12:02,320
area where there's a proliferation

1806
01:12:02,320 --> 01:12:03,920
of stoplights

1807
01:12:03,920 --> 01:12:06,800
at very small intersections and within

1808
01:12:06,800 --> 01:12:09,840
an afternoon i discovered why it is that

1809
01:12:09,840 --> 01:12:12,960
there's this uh entire disregard by

1810
01:12:12,960 --> 01:12:14,880
pedestrians for any of the lights in

1811
01:12:14,880 --> 01:12:18,000
this area um and and within just a few

1812
01:12:18,000 --> 01:12:20,480
hours i became a habitual jaywalker

1813
01:12:20,480 --> 01:12:21,520
myself

1814
01:12:21,520 --> 01:12:23,840
so i can only imagine

1815
01:12:23,840 --> 01:12:25,440
that when we have systems like for

1816
01:12:25,440 --> 01:12:27,760
example self-driving cars

1817
01:12:27,760 --> 01:12:29,520
humans will begin to game the system

1818
01:12:29,520 --> 01:12:31,679
they'll begin to understand how the cars

1819
01:12:31,679 --> 01:12:32,719
behave

1820
01:12:32,719 --> 01:12:35,600
uh in terms of preserving the the lives

1821
01:12:35,600 --> 01:12:38,320
of pedestrians and

1822
01:12:38,320 --> 01:12:40,000
humans are going to start interacting

1823
01:12:40,000 --> 01:12:42,400
differently with those vehicles um

1824
01:12:42,400 --> 01:12:44,239
possibly to

1825
01:12:44,239 --> 01:12:46,800
negative effect for everybody involved

1826
01:12:46,800 --> 01:12:48,400
how do you imagine

1827
01:12:48,400 --> 01:12:51,520
um that our systems can start

1828
01:12:51,520 --> 01:12:54,000
you know evolving co-evolving with the

1829
01:12:54,000 --> 01:12:56,320
the human behaviors that are almost

1830
01:12:56,320 --> 01:12:58,880
certainly you know given my

1831
01:12:58,880 --> 01:13:01,600
range of law breaking now

1832
01:13:01,600 --> 01:13:04,480
will start to emerge i hate to admit

1833
01:13:04,480 --> 01:13:06,960
that here but anyway just just wondering

1834
01:13:06,960 --> 01:13:09,040
well first of all i have to tell you my

1835
01:13:09,040 --> 01:13:11,440
l.a jaywalking story

1836
01:13:11,440 --> 01:13:14,880
so i i went to school in in boston where

1837
01:13:14,880 --> 01:13:16,719
i don't think there are

1838
01:13:16,719 --> 01:13:20,000
laws about traffic and pedestrians and

1839
01:13:20,000 --> 01:13:22,400
then i moved to los angeles after i

1840
01:13:22,400 --> 01:13:23,520
graduated

1841
01:13:23,520 --> 01:13:26,719
um from school and

1842
01:13:26,719 --> 01:13:29,679
i was walking my bicycle literally i

1843
01:13:29,679 --> 01:13:31,679
think you know maybe

1844
01:13:31,679 --> 01:13:34,719
10 feet away from the crosswalk

1845
01:13:34,719 --> 01:13:37,040
but it wasn't in the crosswalk and this

1846
01:13:37,040 --> 01:13:38,960
policeman comes up to me and he was

1847
01:13:38,960 --> 01:13:41,040
about to write me a ticket

1848
01:13:41,040 --> 01:13:43,840
and about jaywalking and i said but you

1849
01:13:43,840 --> 01:13:45,600
know

1850
01:13:45,600 --> 01:13:48,320
i just moved here from boston

1851
01:13:48,320 --> 01:13:51,280
and he said don't they have you know

1852
01:13:51,280 --> 01:13:54,719
rules about jaywalking in boston said

1853
01:13:54,719 --> 01:13:56,159
i don't know

1854
01:13:56,159 --> 01:13:58,239
so i anyway i talked him out of the

1855
01:13:58,239 --> 01:14:01,440
ticket but he's a young lady you know

1856
01:14:01,440 --> 01:14:03,920
you didn't walk in the crosswalk but you

1857
01:14:03,920 --> 01:14:06,080
know it it i said and then actually when

1858
01:14:06,080 --> 01:14:08,880
i moved to washington dc i was i was

1859
01:14:08,880 --> 01:14:09,920
very

1860
01:14:09,920 --> 01:14:12,320
i behaved because

1861
01:14:12,320 --> 01:14:13,600
you know

1862
01:14:13,600 --> 01:14:15,440
again

1863
01:14:15,440 --> 01:14:17,920
washington d.c is not like pittsburgh

1864
01:14:17,920 --> 01:14:20,320
where you just you know cross the street

1865
01:14:20,320 --> 01:14:22,960
whenever you want or new york you know

1866
01:14:22,960 --> 01:14:25,840
who pays attention to to law so i i find

1867
01:14:25,840 --> 01:14:27,760
myself in in dc

1868
01:14:27,760 --> 01:14:30,800
la and seattle i behave

1869
01:14:30,800 --> 01:14:33,679
you know the light says red and i wait

1870
01:14:33,679 --> 01:14:36,480
there and there are no cars i wait there

1871
01:14:36,480 --> 01:14:38,640
anyway um

1872
01:14:38,640 --> 01:14:41,520
i think what you ask is actually a

1873
01:14:41,520 --> 01:14:44,560
broader question in terms of not just

1874
01:14:44,560 --> 01:14:46,960
cyber physical systems

1875
01:14:46,960 --> 01:14:48,000
but

1876
01:14:48,000 --> 01:14:50,400
where our software systems are

1877
01:14:50,400 --> 01:14:53,760
going for the future

1878
01:14:53,760 --> 01:14:58,080
um and and i i i now appeal again to a

1879
01:14:58,080 --> 01:15:00,560
lot of what i see happening

1880
01:15:00,560 --> 01:15:02,880
um in our technology which is going to

1881
01:15:02,880 --> 01:15:05,520
be very ai based there are going to be a

1882
01:15:05,520 --> 01:15:07,040
lot of systems

1883
01:15:07,040 --> 01:15:08,000
that

1884
01:15:08,000 --> 01:15:10,560
um we interact with

1885
01:15:10,560 --> 01:15:11,360
that

1886
01:15:11,360 --> 01:15:13,679
actually try to understand our behavior

1887
01:15:13,679 --> 01:15:16,560
and interact with us as people i'm

1888
01:15:16,560 --> 01:15:19,440
thinking for instance very very simply a

1889
01:15:19,440 --> 01:15:21,760
lot of the quote personal assistants and

1890
01:15:21,760 --> 01:15:24,239
conversational agents that we are

1891
01:15:24,239 --> 01:15:26,480
interact with you know the alexa that

1892
01:15:26,480 --> 01:15:29,440
you might have on your in your home or

1893
01:15:29,440 --> 01:15:31,440
the cortana and siri that you talk to on

1894
01:15:31,440 --> 01:15:32,640
your phone

1895
01:15:32,640 --> 01:15:34,960
um they are learning and adapting to you

1896
01:15:34,960 --> 01:15:36,239
as a person

1897
01:15:36,239 --> 01:15:39,280
um and and to make these systems more

1898
01:15:39,280 --> 01:15:42,560
interesting and more personal um

1899
01:15:42,560 --> 01:15:44,000
they

1900
01:15:44,000 --> 01:15:44,719
uh

1901
01:15:44,719 --> 01:15:47,520
they have to understand what it means to

1902
01:15:47,520 --> 01:15:49,760
engage with individuals engage with

1903
01:15:49,760 --> 01:15:52,880
people and interact with them so for

1904
01:15:52,880 --> 01:15:54,560
instance we have them

1905
01:15:54,560 --> 01:15:56,560
it in the building that i work in we

1906
01:15:56,560 --> 01:15:58,320
have these uh

1907
01:15:58,320 --> 01:16:01,199
little little teeny-weeny robots that

1908
01:16:01,199 --> 01:16:03,360
sit outside the elevator doors and when

1909
01:16:03,360 --> 01:16:04,640
you um

1910
01:16:04,640 --> 01:16:07,199
you exit the elevator if you come up

1911
01:16:07,199 --> 01:16:10,320
close to the robot you can ask um you

1912
01:16:10,320 --> 01:16:12,880
know where's jeanette's office and the

1913
01:16:12,880 --> 01:16:15,360
robot will look at you and talk to you

1914
01:16:15,360 --> 01:16:17,600
and give you directions

1915
01:16:17,600 --> 01:16:19,679
but if you don't come up to it close

1916
01:16:19,679 --> 01:16:20,480
enough

1917
01:16:20,480 --> 01:16:22,159
like what i i don't go up to it every

1918
01:16:22,159 --> 01:16:24,800
day but you just go by it

1919
01:16:24,800 --> 01:16:28,960
it's this little robot it goes like this

1920
01:16:28,960 --> 01:16:32,640
it it it it knows how much to engage

1921
01:16:32,640 --> 01:16:34,400
with you as an individual

1922
01:16:34,400 --> 01:16:36,960
so we are building systems that

1923
01:16:36,960 --> 01:16:40,080
understand human behavior at that level

1924
01:16:40,080 --> 01:16:42,960
of when to engage who to engage with if

1925
01:16:42,960 --> 01:16:45,280
there are multiple people you know

1926
01:16:45,280 --> 01:16:48,080
standing around the robot

1927
01:16:48,080 --> 01:16:49,679
and

1928
01:16:49,679 --> 01:16:52,480
it's pretty remarkable

1929
01:16:52,480 --> 01:16:54,640
that we can build these systems that can

1930
01:16:54,640 --> 01:16:55,520
be

1931
01:16:55,520 --> 01:16:58,560
so interactive and i don't just mean hci

1932
01:16:58,560 --> 01:17:00,239
kind of interact i mean really

1933
01:17:00,239 --> 01:17:04,400
understand when is the human when is

1934
01:17:04,400 --> 01:17:07,199
when is the human trying to get

1935
01:17:07,199 --> 01:17:09,360
my attention as a robot

1936
01:17:09,360 --> 01:17:11,840
um and how do i get the human's

1937
01:17:11,840 --> 01:17:14,640
intention in order to engage with it so

1938
01:17:14,640 --> 01:17:17,440
we're seeing more and more systems that

1939
01:17:17,440 --> 01:17:20,080
have to understand fundamentally

1940
01:17:20,080 --> 01:17:22,560
human behavior in that way and then i

1941
01:17:22,560 --> 01:17:25,199
think we need to think about it

1942
01:17:25,199 --> 01:17:27,679
not just as an individual but in terms

1943
01:17:27,679 --> 01:17:30,560
of societal

1944
01:17:30,800 --> 01:17:33,920
social norms and societal behavior so

1945
01:17:33,920 --> 01:17:36,000
there's a lot more that we need to do

1946
01:17:36,000 --> 01:17:37,440
and this is why

1947
01:17:37,440 --> 01:17:38,800
when i was at the national science

1948
01:17:38,800 --> 01:17:42,000
foundation i started these programs that

1949
01:17:42,000 --> 01:17:44,400
were crossed between size and the social

1950
01:17:44,400 --> 01:17:47,040
behavioral economics science the sbe

1951
01:17:47,040 --> 01:17:50,159
directorate because i saw that computing

1952
01:17:50,159 --> 01:17:52,960
was whether it was you know cyber trust

1953
01:17:52,960 --> 01:17:54,719
or social co

1954
01:17:54,719 --> 01:17:58,159
social and computational systems or

1955
01:17:58,159 --> 01:18:00,400
economics and computer science i saw the

1956
01:18:00,400 --> 01:18:02,320
computing

1957
01:18:02,320 --> 01:18:06,560
was really abutting and going into these

1958
01:18:06,560 --> 01:18:08,719
other areas and needed the social

1959
01:18:08,719 --> 01:18:11,199
sciences the behavioral sciences

1960
01:18:11,199 --> 01:18:14,000
scientists and the economists to work

1961
01:18:14,000 --> 01:18:15,600
with the computer scientists kind of

1962
01:18:15,600 --> 01:18:18,000
figure out what was going on so i just

1963
01:18:18,000 --> 01:18:20,560
see more of that happening

1964
01:18:20,560 --> 01:18:23,800
thank you

1965
01:18:30,239 --> 01:18:33,480
thank you

1966
01:18:40,320 --> 01:18:42,400
you

