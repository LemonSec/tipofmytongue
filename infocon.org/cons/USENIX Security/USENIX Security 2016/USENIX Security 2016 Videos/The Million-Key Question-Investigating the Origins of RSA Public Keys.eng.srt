1
00:00:10,320 --> 00:00:12,000
welcome my name is peter and this is a

2
00:00:12,000 --> 00:00:13,440
joint work with my colleagues from

3
00:00:13,440 --> 00:00:15,920
amazon university as well said and the

4
00:00:15,920 --> 00:00:18,640
question we are trying to answer is

5
00:00:18,640 --> 00:00:21,439
relatively simple this is ordinary rsa

6
00:00:21,439 --> 00:00:22,880
public key

7
00:00:22,880 --> 00:00:24,640
nothing special about that and the

8
00:00:24,640 --> 00:00:27,039
question is which particular software

9
00:00:27,039 --> 00:00:29,599
library generated this key

10
00:00:29,599 --> 00:00:31,359
and the good guess

11
00:00:31,359 --> 00:00:33,680
would be openssl because so many keys

12
00:00:33,680 --> 00:00:36,079
are generated by the openssr right

13
00:00:36,079 --> 00:00:38,000
but

14
00:00:38,000 --> 00:00:40,559
it can't be open so openssl will never

15
00:00:40,559 --> 00:00:42,399
generate key like this

16
00:00:42,399 --> 00:00:44,000
in fact it was some infineon

17
00:00:44,000 --> 00:00:45,840
cryptographic smart card

18
00:00:45,840 --> 00:00:48,640
and uh how we can know this

19
00:00:48,640 --> 00:00:50,559
uh first because we generated that key

20
00:00:50,559 --> 00:00:54,559
right but uh there is a deeper reason

21
00:00:54,559 --> 00:00:56,640
uh and the reason is that some bits of

22
00:00:56,640 --> 00:00:59,840
this public key are biased in a such way

23
00:00:59,840 --> 00:01:02,640
so we can tell that it can be open ssl

24
00:01:02,640 --> 00:01:04,799
and it's probably uh infinite on smart

25
00:01:04,799 --> 00:01:06,080
card

26
00:01:06,080 --> 00:01:08,400
but how is that possible the public

27
00:01:08,400 --> 00:01:10,320
modulus is just the

28
00:01:10,320 --> 00:01:12,400
result of multiplication of two uh

29
00:01:12,400 --> 00:01:14,640
random primes p and q so how it's

30
00:01:14,640 --> 00:01:16,720
possible that it's biased

31
00:01:16,720 --> 00:01:18,400
and uh

32
00:01:18,400 --> 00:01:19,520
there are

33
00:01:19,520 --> 00:01:21,840
these params are random they are coming

34
00:01:21,840 --> 00:01:24,240
from some random number generator

35
00:01:24,240 --> 00:01:26,159
and in case this random number generator

36
00:01:26,159 --> 00:01:28,320
is biased then the primes will be by us

37
00:01:28,320 --> 00:01:30,560
and the modulus as well but this is not

38
00:01:30,560 --> 00:01:33,280
what we do assume we assume that the

39
00:01:33,280 --> 00:01:34,799
random number generator is perfectly

40
00:01:34,799 --> 00:01:37,520
fine and no bias there

41
00:01:37,520 --> 00:01:39,920
and still the modulus is biased and the

42
00:01:39,920 --> 00:01:41,360
responsible

43
00:01:41,360 --> 00:01:43,520
thing for this is

44
00:01:43,520 --> 00:01:45,680
crypto library code which is responsible

45
00:01:45,680 --> 00:01:47,840
for generating picking the

46
00:01:47,840 --> 00:01:48,960
primes

47
00:01:48,960 --> 00:01:50,960
p and q

48
00:01:50,960 --> 00:01:53,759
so what we did here

49
00:01:53,759 --> 00:01:55,680
we first took a lot of software

50
00:01:55,680 --> 00:01:58,159
libraries and also 16 different

51
00:01:58,159 --> 00:01:59,920
cryptographic smart cards from six

52
00:01:59,920 --> 00:02:01,840
different manufacturers

53
00:02:01,840 --> 00:02:02,719
and

54
00:02:02,719 --> 00:02:05,119
asked every source to generate one

55
00:02:05,119 --> 00:02:07,600
million keys for us at least one million

56
00:02:07,600 --> 00:02:09,919
key pairs so we end up with a large

57
00:02:09,919 --> 00:02:11,120
database

58
00:02:11,120 --> 00:02:13,680
uh it was easy for software libraries

59
00:02:13,680 --> 00:02:15,680
it's harder for smart cards some were

60
00:02:15,680 --> 00:02:17,360
broken but

61
00:02:17,360 --> 00:02:19,920
after a few weeks we were able to get

62
00:02:19,920 --> 00:02:22,480
that amount of keys and with this

63
00:02:22,480 --> 00:02:23,680
we got

64
00:02:23,680 --> 00:02:26,239
both private part and the public part

65
00:02:26,239 --> 00:02:29,040
primes modulus and we run a lot of

66
00:02:29,040 --> 00:02:30,879
analysis on this yeah we inspected

67
00:02:30,879 --> 00:02:32,720
different uh

68
00:02:32,720 --> 00:02:33,680
parts

69
00:02:33,680 --> 00:02:36,319
and as a result it turned out that there

70
00:02:36,319 --> 00:02:38,400
are at least seven implementation

71
00:02:38,400 --> 00:02:41,120
choices made by the developers of these

72
00:02:41,120 --> 00:02:43,040
libraries or smart cards

73
00:02:43,040 --> 00:02:46,640
uh that buy us some bits in a public key

74
00:02:46,640 --> 00:02:51,200
and uh what we can do with that yeah so

75
00:02:51,200 --> 00:02:53,360
one example what what is the

76
00:02:53,360 --> 00:02:54,959
implementation charge that buys

77
00:02:54,959 --> 00:02:56,720
something in a public key

78
00:02:56,720 --> 00:02:58,319
is

79
00:02:58,319 --> 00:03:00,080
printing the heat map of

80
00:03:00,080 --> 00:03:02,480
most significant byte of primes so we

81
00:03:02,480 --> 00:03:04,720
have the primes for the analysis part

82
00:03:04,720 --> 00:03:06,080
and therefore we can take most

83
00:03:06,080 --> 00:03:08,720
significant byte from uh the p

84
00:03:08,720 --> 00:03:11,040
most significant byte from q

85
00:03:11,040 --> 00:03:15,519
uh x axis is uh uh p epsilon x is q and

86
00:03:15,519 --> 00:03:17,680
then just plot it for every key we will

87
00:03:17,680 --> 00:03:20,000
get one particle point but because we

88
00:03:20,000 --> 00:03:21,760
have million of these we will get nice

89
00:03:21,760 --> 00:03:22,959
heat map

90
00:03:22,959 --> 00:03:24,959
and we were really surprised by the

91
00:03:24,959 --> 00:03:28,159
variability we saw this is just few

92
00:03:28,159 --> 00:03:30,239
examples but there are more so we were

93
00:03:30,239 --> 00:03:31,760
surprised

94
00:03:31,760 --> 00:03:34,640
but this is still about private keys and

95
00:03:34,640 --> 00:03:36,560
for the classification of public keys we

96
00:03:36,560 --> 00:03:39,519
don't have this but if the most

97
00:03:39,519 --> 00:03:42,799
significant byte of primes is biased

98
00:03:42,799 --> 00:03:45,040
then after the multiplication

99
00:03:45,040 --> 00:03:47,440
of course the modulus most significant

100
00:03:47,440 --> 00:03:49,040
byte of the modulus will be biased as

101
00:03:49,040 --> 00:03:50,159
well

102
00:03:50,159 --> 00:03:51,840
and therefore this matters also for the

103
00:03:51,840 --> 00:03:54,159
public keys this is one example

104
00:03:54,159 --> 00:03:56,879
uh and another example is uh you can

105
00:03:56,879 --> 00:03:58,480
take

106
00:03:58,480 --> 00:04:01,519
rsa 512 bits that's insecure for

107
00:04:01,519 --> 00:04:03,680
ordinary use but you can inspect that

108
00:04:03,680 --> 00:04:06,159
and the primes there will be half length

109
00:04:06,159 --> 00:04:08,000
and therefore what you can do is to

110
00:04:08,000 --> 00:04:11,920
factorize uh prime minus one value okay

111
00:04:11,920 --> 00:04:15,120
and as a result you will get

112
00:04:15,120 --> 00:04:16,478
these factors

113
00:04:16,478 --> 00:04:17,440
so we

114
00:04:17,440 --> 00:04:21,040
factorized 10 000 keys from every source

115
00:04:21,040 --> 00:04:23,600
by yafutul and

116
00:04:23,600 --> 00:04:24,880
once again we saw different

117
00:04:24,880 --> 00:04:28,320
distributions here on the x-axis is the

118
00:04:28,320 --> 00:04:31,759
length of biggest factor of p minus one

119
00:04:31,759 --> 00:04:33,600
on the epsilon axis is the length of the

120
00:04:33,600 --> 00:04:35,360
second biggest factor

121
00:04:35,360 --> 00:04:37,919
and if you have completely random prime

122
00:04:37,919 --> 00:04:39,919
a lot of random primes you should see

123
00:04:39,919 --> 00:04:42,240
distribution like this one okay this is

124
00:04:42,240 --> 00:04:44,639
expected for completely random prime

125
00:04:44,639 --> 00:04:46,400
but instead what we saw for some

126
00:04:46,400 --> 00:04:47,600
libraries

127
00:04:47,600 --> 00:04:49,199
was something like this yeah some gaps

128
00:04:49,199 --> 00:04:50,320
there

129
00:04:50,320 --> 00:04:52,400
and it turns out that some libraries

130
00:04:52,400 --> 00:04:54,800
avoid small factors

131
00:04:54,800 --> 00:04:57,120
in this p minus 1

132
00:04:57,120 --> 00:04:58,560
value

133
00:04:58,560 --> 00:04:59,520
and

134
00:04:59,520 --> 00:05:01,360
this will in turn

135
00:05:01,360 --> 00:05:04,720
introduce some bias on a smaller bits on

136
00:05:04,720 --> 00:05:07,199
lower bits of public modulus and this

137
00:05:07,199 --> 00:05:09,520
was in fact used already by ilya mironov

138
00:05:09,520 --> 00:05:11,360
to attribute some

139
00:05:11,360 --> 00:05:14,160
weak rsa keys to openssl library

140
00:05:14,160 --> 00:05:16,639
before

141
00:05:16,720 --> 00:05:18,479
if the library itself generates

142
00:05:18,479 --> 00:05:20,720
so-called fips primes but there is a

143
00:05:20,720 --> 00:05:23,039
strict requirement that the prime value

144
00:05:23,039 --> 00:05:24,720
should be at least

145
00:05:24,720 --> 00:05:27,680
101 bit for example the biggest factor

146
00:05:27,680 --> 00:05:29,600
of the p minus one should be at least

147
00:05:29,600 --> 00:05:31,199
that length you will see completely

148
00:05:31,199 --> 00:05:33,759
different distribution okay so this is

149
00:05:33,759 --> 00:05:35,840
another thing that uh

150
00:05:35,840 --> 00:05:38,479
bias something in a public key

151
00:05:38,479 --> 00:05:40,160
and there are more of these

152
00:05:40,160 --> 00:05:41,840
so what are these seven implementation

153
00:05:41,840 --> 00:05:44,240
choices

154
00:05:44,240 --> 00:05:46,320
first it's a direct manipulation of

155
00:05:46,320 --> 00:05:48,240
prime's highest bits

156
00:05:48,240 --> 00:05:49,840
this is a very significant thing that

157
00:05:49,840 --> 00:05:52,800
will significantly manifest itself also

158
00:05:52,800 --> 00:05:55,600
in a highest bit of a public key

159
00:05:55,600 --> 00:05:57,039
another example

160
00:05:57,039 --> 00:05:58,639
another factor

161
00:05:58,639 --> 00:06:00,639
is the avoidance of these small factors

162
00:06:00,639 --> 00:06:04,720
this will buy us the small bits of

163
00:06:04,720 --> 00:06:06,720
of public modulus again very

164
00:06:06,720 --> 00:06:08,880
significantly

165
00:06:08,880 --> 00:06:11,039
some sources some libraries and

166
00:06:11,039 --> 00:06:13,120
cryptographic smart cards require us

167
00:06:13,120 --> 00:06:15,120
modularly to be blam integer

168
00:06:15,120 --> 00:06:17,440
yeah for not really a clear reason but

169
00:06:17,440 --> 00:06:20,720
this is observable as well

170
00:06:20,720 --> 00:06:23,759
some libraries restrict and some don't

171
00:06:23,759 --> 00:06:25,840
the length of the primes and this will

172
00:06:25,840 --> 00:06:28,400
in turn impact the length of the modulus

173
00:06:28,400 --> 00:06:30,880
as such

174
00:06:31,440 --> 00:06:34,000
some libraries do not generate primes

175
00:06:34,000 --> 00:06:36,080
randomly but instead of construct these

176
00:06:36,080 --> 00:06:38,960
to have a strong or provable primes and

177
00:06:38,960 --> 00:06:40,000
this is

178
00:06:40,000 --> 00:06:42,479
observable not that significantly but

179
00:06:42,479 --> 00:06:44,560
it's observable from the public modules

180
00:06:44,560 --> 00:06:46,880
as well

181
00:06:46,960 --> 00:06:48,960
for some smart cards we don't know

182
00:06:48,960 --> 00:06:50,720
because it's a black box for us we don't

183
00:06:50,720 --> 00:06:52,639
have the code there but it's doing

184
00:06:52,639 --> 00:06:53,759
something that is statistically

185
00:06:53,759 --> 00:06:54,960
observable

186
00:06:54,960 --> 00:06:55,759
so

187
00:06:55,759 --> 00:06:58,960
and even think like uh what you will do

188
00:06:58,960 --> 00:07:01,840
if you will generate a random value and

189
00:07:01,840 --> 00:07:04,960
it will turn out not to be a prime what

190
00:07:04,960 --> 00:07:06,800
you will do will you just discard it and

191
00:07:06,800 --> 00:07:09,280
generate a new random value or

192
00:07:09,280 --> 00:07:11,360
will you add 2 and test for the

193
00:07:11,360 --> 00:07:12,720
primarity again

194
00:07:12,720 --> 00:07:14,319
even thing like this is observable from

195
00:07:14,319 --> 00:07:16,479
the public key just slightly but it's

196
00:07:16,479 --> 00:07:18,639
observable

197
00:07:18,639 --> 00:07:20,639
so when we know that there are these

198
00:07:20,639 --> 00:07:22,639
implementation choices that buy us some

199
00:07:22,639 --> 00:07:24,800
bits of public modulus we can use this

200
00:07:24,800 --> 00:07:26,560
for a classification

201
00:07:26,560 --> 00:07:28,960
so we will start during the learning

202
00:07:28,960 --> 00:07:31,360
phase with a lot of keys with our 60

203
00:07:31,360 --> 00:07:33,360
million plus keys at least million from

204
00:07:33,360 --> 00:07:34,880
every source

205
00:07:34,880 --> 00:07:36,319
and we already know from the previous

206
00:07:36,319 --> 00:07:39,280
analysis which particle bits are biased

207
00:07:39,280 --> 00:07:42,000
in a public key so what we can do is for

208
00:07:42,000 --> 00:07:44,720
every source we can apply this mask

209
00:07:44,720 --> 00:07:48,000
for particle key and get particle mask

210
00:07:48,000 --> 00:07:50,800
value okay we will do this over 1

211
00:07:50,800 --> 00:07:51,680
million

212
00:07:51,680 --> 00:07:52,560
keys

213
00:07:52,560 --> 00:07:54,560
and then count the frequency for

214
00:07:54,560 --> 00:07:57,360
different mask

215
00:07:57,520 --> 00:07:57,840
as values

216
00:07:57,840 --> 00:08:00,240
result we will get some histogram this

217
00:08:00,240 --> 00:08:02,080
is the example histogram for three

218
00:08:02,080 --> 00:08:03,840
different sources and you can see that

219
00:08:03,840 --> 00:08:06,560
these histograms are different okay so

220
00:08:06,560 --> 00:08:08,960
we can distinguish between these three

221
00:08:08,960 --> 00:08:10,319
sources

222
00:08:10,319 --> 00:08:13,360
sometimes it will happen that

223
00:08:13,360 --> 00:08:14,879
two libraries

224
00:08:14,879 --> 00:08:18,639
produce the exactly same or almost same

225
00:08:18,639 --> 00:08:20,479
mask frequencies and then we can

226
00:08:20,479 --> 00:08:22,720
distinguish between these two libraries

227
00:08:22,720 --> 00:08:24,479
and we will group these together into

228
00:08:24,479 --> 00:08:28,240
same classification group okay

229
00:08:28,240 --> 00:08:30,080
what is the result of this

230
00:08:30,080 --> 00:08:31,919
after going through the whole learning

231
00:08:31,919 --> 00:08:34,479
set we will get a classification matrix

232
00:08:34,479 --> 00:08:36,559
which contains for every possible

233
00:08:36,559 --> 00:08:38,719
possible mask value

234
00:08:38,719 --> 00:08:40,479
and we are working with nine bits

235
00:08:40,479 --> 00:08:43,440
therefore uh two up to nine uh

236
00:08:43,440 --> 00:08:44,959
possibilities

237
00:08:44,959 --> 00:08:48,720
what is the probability that particular

238
00:08:48,720 --> 00:08:51,120
library or group of libraries within the

239
00:08:51,120 --> 00:08:54,160
same group generated this mask volume

240
00:08:54,160 --> 00:08:56,240
okay and this is pre-computed from our

241
00:08:56,240 --> 00:08:58,399
large data set and now we have this

242
00:08:58,399 --> 00:09:00,560
classification matrix

243
00:09:00,560 --> 00:09:03,360
so what is the result based on this

244
00:09:03,360 --> 00:09:05,440
against the the keys we have

245
00:09:05,440 --> 00:09:08,880
we started with a 38 different sources

246
00:09:08,880 --> 00:09:10,800
libraries and smart cards

247
00:09:10,800 --> 00:09:13,360
and we end up with a 13 classification

248
00:09:13,360 --> 00:09:14,880
groups

249
00:09:14,880 --> 00:09:15,680
and

250
00:09:15,680 --> 00:09:18,000
so some sources fell into same

251
00:09:18,000 --> 00:09:20,800
classification group so why is that so

252
00:09:20,800 --> 00:09:22,800
for example here you can take a look at

253
00:09:22,800 --> 00:09:24,560
group one

254
00:09:24,560 --> 00:09:26,560
where you can see two cryptographic

255
00:09:26,560 --> 00:09:28,640
smart cards same manufacturer just

256
00:09:28,640 --> 00:09:31,440
different type and most probably they

257
00:09:31,440 --> 00:09:33,360
just share the implementation and

258
00:09:33,360 --> 00:09:35,040
therefore we can't distinguish between

259
00:09:35,040 --> 00:09:38,080
these two and they are in the same group

260
00:09:38,080 --> 00:09:41,279
another interesting group is a group 10

261
00:09:41,279 --> 00:09:42,880
where you can see free microsoft

262
00:09:42,880 --> 00:09:44,320
libraries

263
00:09:44,320 --> 00:09:46,640
once again we expect that the

264
00:09:46,640 --> 00:09:48,720
source code is same for this

265
00:09:48,720 --> 00:09:50,720
but you can also see that the newest

266
00:09:50,720 --> 00:09:53,120
version of the bouncy castle is there

267
00:09:53,120 --> 00:09:55,920
in that case a bouncy castle the newest

268
00:09:55,920 --> 00:09:57,600
version is probably not having the

269
00:09:57,600 --> 00:10:00,080
exactly the same source but it's biasing

270
00:10:00,080 --> 00:10:01,760
the public modules in exactly the same

271
00:10:01,760 --> 00:10:04,959
way as the microsoft libraries do so

272
00:10:04,959 --> 00:10:06,079
it's in the same

273
00:10:06,079 --> 00:10:08,079
group on the other side what you can see

274
00:10:08,079 --> 00:10:10,000
here is this is the just the latest

275
00:10:10,000 --> 00:10:11,920
version of the bouncy castle just the

276
00:10:11,920 --> 00:10:13,839
version before that is in a different

277
00:10:13,839 --> 00:10:15,920
group okay so even the versions of the

278
00:10:15,920 --> 00:10:17,680
libraries sometimes matter if they are

279
00:10:17,680 --> 00:10:20,160
doing changes in the code

280
00:10:20,160 --> 00:10:21,040
and

281
00:10:21,040 --> 00:10:23,680
this is uh you can plot a dendrogram of

282
00:10:23,680 --> 00:10:25,440
occluding distances between different

283
00:10:25,440 --> 00:10:26,480
groups

284
00:10:26,480 --> 00:10:28,000
and

285
00:10:28,000 --> 00:10:30,320
good thing is that we can attribute

286
00:10:30,320 --> 00:10:32,959
splits in this dendrogram tree to

287
00:10:32,959 --> 00:10:35,440
particular design choices so it's not

288
00:10:35,440 --> 00:10:36,560
some

289
00:10:36,560 --> 00:10:38,160
machine learning black magic we can

290
00:10:38,160 --> 00:10:40,399
actually attribute particular

291
00:10:40,399 --> 00:10:44,160
differences between groups

292
00:10:44,480 --> 00:10:46,880
so now we have the classification matrix

293
00:10:46,880 --> 00:10:50,240
pre-compute it once uh so we can do that

294
00:10:50,240 --> 00:10:52,240
do the classification so we will take

295
00:10:52,240 --> 00:10:55,440
some certificate extract the

296
00:10:55,440 --> 00:10:57,839
public key from that

297
00:10:57,839 --> 00:11:01,920
then apply the mask of known biased bits

298
00:11:01,920 --> 00:11:04,079
get the particle bit value for this

299
00:11:04,079 --> 00:11:06,399
particle key and then just perform table

300
00:11:06,399 --> 00:11:08,800
lookup very fast operation

301
00:11:08,800 --> 00:11:11,920
and what we will get is the vector of

302
00:11:11,920 --> 00:11:14,560
probabilities for different

303
00:11:14,560 --> 00:11:16,000
libraries or different groups of

304
00:11:16,000 --> 00:11:18,560
libraries so for this particular key it

305
00:11:18,560 --> 00:11:21,279
might look like this okay if you have

306
00:11:21,279 --> 00:11:23,519
more than one key you can get better

307
00:11:23,519 --> 00:11:25,839
accuracy

308
00:11:25,839 --> 00:11:27,519
you can test this

309
00:11:27,519 --> 00:11:30,240
by yourself we publish both data sets

310
00:11:30,240 --> 00:11:32,399
and this pre-computed

311
00:11:32,399 --> 00:11:35,040
classification matrixes but we also set

312
00:11:35,040 --> 00:11:37,120
up a small tool so so you can just

313
00:11:37,120 --> 00:11:41,600
insert your key or you can insert url to

314
00:11:41,600 --> 00:11:44,079
http web server and we will classify

315
00:11:44,079 --> 00:11:46,640
this one for you so just press classify

316
00:11:46,640 --> 00:11:48,320
you will get something like this where

317
00:11:48,320 --> 00:11:51,040
you can see the probabilities and we

318
00:11:51,040 --> 00:11:53,200
will also see which particular group is

319
00:11:53,200 --> 00:11:55,680
not possible okay so so which particular

320
00:11:55,680 --> 00:11:58,079
source can't generate key

321
00:11:58,079 --> 00:12:00,880
that you see

322
00:12:00,880 --> 00:12:02,800
so this leads us to classification

323
00:12:02,800 --> 00:12:04,720
accuracy so so just to give you some

324
00:12:04,720 --> 00:12:07,200
feeling what kind of error we can have

325
00:12:07,200 --> 00:12:09,120
so let's assume we have three different

326
00:12:09,120 --> 00:12:10,480
sources

327
00:12:10,480 --> 00:12:12,160
and this is the

328
00:12:12,160 --> 00:12:15,360
distribution of mask values for these

329
00:12:15,360 --> 00:12:17,839
sources

330
00:12:18,240 --> 00:12:19,600
if you would have

331
00:12:19,600 --> 00:12:21,839
one million of

332
00:12:21,839 --> 00:12:24,000
keys to classify and you know that they

333
00:12:24,000 --> 00:12:26,079
are all coming from the same source

334
00:12:26,079 --> 00:12:27,200
you can

335
00:12:27,200 --> 00:12:30,639
almost perfectly recreate this uh

336
00:12:30,639 --> 00:12:33,120
this histogram and then you are sure it

337
00:12:33,120 --> 00:12:36,240
was a green source in this case open jdk

338
00:12:36,240 --> 00:12:37,120
okay

339
00:12:37,120 --> 00:12:38,800
but this is usually not the case for

340
00:12:38,800 --> 00:12:41,680
learning yes for classification no for

341
00:12:41,680 --> 00:12:44,000
classification you usually have just one

342
00:12:44,000 --> 00:12:47,040
maybe five ten keys but not really one

343
00:12:47,040 --> 00:12:48,959
million okay so what is the situation

344
00:12:48,959 --> 00:12:52,399
here we have five keys here and you will

345
00:12:52,399 --> 00:12:54,560
take the first key

346
00:12:54,560 --> 00:12:56,079
apply the mask you will get particle

347
00:12:56,079 --> 00:12:59,440
mask value and this particle mask value

348
00:12:59,440 --> 00:13:02,160
can be generated by all sources blue is

349
00:13:02,160 --> 00:13:03,519
most probable

350
00:13:03,519 --> 00:13:06,079
but only slightly and and the red and

351
00:13:06,079 --> 00:13:08,639
green is possible very very possible as

352
00:13:08,639 --> 00:13:09,839
well okay

353
00:13:09,839 --> 00:13:12,800
so uh we can have the error here if we

354
00:13:12,800 --> 00:13:14,399
will add another key

355
00:13:14,399 --> 00:13:16,320
this one is interesting because this key

356
00:13:16,320 --> 00:13:18,160
this mask value

357
00:13:18,160 --> 00:13:21,040
is never produced by the red source in

358
00:13:21,040 --> 00:13:22,800
this case openssl

359
00:13:22,800 --> 00:13:25,920
so we know it can be open ssl

360
00:13:25,920 --> 00:13:28,079
it still can be a blue one but the green

361
00:13:28,079 --> 00:13:30,240
one is way more probable and as you are

362
00:13:30,240 --> 00:13:32,480
adding more and more

363
00:13:32,480 --> 00:13:34,800
key values you are more and more sure

364
00:13:34,800 --> 00:13:36,959
that it was the green so this is some

365
00:13:36,959 --> 00:13:39,519
basic feeling for error we have okay

366
00:13:39,519 --> 00:13:41,839
more keys better accuracy so what are

367
00:13:41,839 --> 00:13:44,720
the actual results for the accuracy to

368
00:13:44,720 --> 00:13:48,399
figure out we set aside 10 000 keys

369
00:13:48,399 --> 00:13:50,320
for every source

370
00:13:50,320 --> 00:13:52,800
from the learning set so set aside so

371
00:13:52,800 --> 00:13:55,120
it's fresh keys and then test it

372
00:13:55,120 --> 00:13:57,120
evaluate the accuracy on that

373
00:13:57,120 --> 00:14:00,800
so if you have just one key

374
00:14:00,800 --> 00:14:04,399
then uh your most probable guess

375
00:14:04,399 --> 00:14:06,160
after the classification

376
00:14:06,160 --> 00:14:08,320
is on average correct with a 40

377
00:14:08,320 --> 00:14:10,720
probability now you have most probable

378
00:14:10,720 --> 00:14:13,040
guess out of 30 impossible and there is

379
00:14:13,040 --> 00:14:14,720
it's a 40

380
00:14:14,720 --> 00:14:17,120
but on average but there is a high uh

381
00:14:17,120 --> 00:14:20,320
variability here for some sources with

382
00:14:20,320 --> 00:14:22,959
one key you are almost always wrong it's

383
00:14:22,959 --> 00:14:24,560
less than one percent

384
00:14:24,560 --> 00:14:27,199
uh for some sources even one key is is

385
00:14:27,199 --> 00:14:29,279
enough and you are almost always right

386
00:14:29,279 --> 00:14:31,760
95 percent

387
00:14:31,760 --> 00:14:33,760
if you are fine with a correct guess

388
00:14:33,760 --> 00:14:35,519
being within top 3

389
00:14:35,519 --> 00:14:39,519
it's 73 percent

390
00:14:39,519 --> 00:14:41,040
this is for one key

391
00:14:41,040 --> 00:14:43,199
if you have five keys and you know that

392
00:14:43,199 --> 00:14:44,880
these five keys are coming from the same

393
00:14:44,880 --> 00:14:46,000
source

394
00:14:46,000 --> 00:14:47,839
then everything is going up yeah the

395
00:14:47,839 --> 00:14:51,279
average is 78 now and within top three

396
00:14:51,279 --> 00:14:55,040
mostly right 97 percent and if you have

397
00:14:55,040 --> 00:14:56,480
10 keys

398
00:14:56,480 --> 00:14:59,839
average uh for the top first one is 85

399
00:14:59,839 --> 00:15:01,120
and uh

400
00:15:01,120 --> 00:15:03,360
almost always right within top three

401
00:15:03,360 --> 00:15:05,279
okay so so it seems that the accuracy is

402
00:15:05,279 --> 00:15:08,240
is reasonable uh at least on the test

403
00:15:08,240 --> 00:15:09,199
set

404
00:15:09,199 --> 00:15:11,199
so the question is what with the real

405
00:15:11,199 --> 00:15:12,639
world keys

406
00:15:12,639 --> 00:15:14,320
and

407
00:15:14,320 --> 00:15:17,920
for that we have very nice data set

408
00:15:17,920 --> 00:15:19,519
i'd like to thank people that gather

409
00:15:19,519 --> 00:15:22,639
these large data sets there is epv for

410
00:15:22,639 --> 00:15:25,199
tls scan with about 10 million unique

411
00:15:25,199 --> 00:15:27,360
rsa is usable for us

412
00:15:27,360 --> 00:15:29,839
pgp key servers data set so you can

413
00:15:29,839 --> 00:15:32,320
download it certificate transparent

414
00:15:32,320 --> 00:15:34,639
transparency database once again nice

415
00:15:34,639 --> 00:15:36,639
data sets there is only one issue they

416
00:15:36,639 --> 00:15:38,880
are not coming annotated which

417
00:15:38,880 --> 00:15:42,160
particular key uh which particle library

418
00:15:42,160 --> 00:15:44,800
generated that key right obviously

419
00:15:44,800 --> 00:15:48,560
so but we can do at least some guesses

420
00:15:48,560 --> 00:15:50,000
first of all if you are using app

421
00:15:50,000 --> 00:15:51,839
achievement server

422
00:15:51,839 --> 00:15:53,680
chances are high that you also use

423
00:15:53,680 --> 00:15:56,399
openssl to generate the keys for that if

424
00:15:56,399 --> 00:15:58,720
you are using iis then you are probably

425
00:15:58,720 --> 00:16:00,959
using microsoft libraries for that

426
00:16:00,959 --> 00:16:03,279
and the market share for the web servers

427
00:16:03,279 --> 00:16:05,519
is somehow known so a rough estimate can

428
00:16:05,519 --> 00:16:08,320
be something like this openssl 86

429
00:16:08,320 --> 00:16:10,720
percent 12 percent for the microsoft

430
00:16:10,720 --> 00:16:12,880
this is some rough estimate okay

431
00:16:12,880 --> 00:16:15,519
something remaining for our libraries

432
00:16:15,519 --> 00:16:16,320
uh

433
00:16:16,320 --> 00:16:17,519
when we took

434
00:16:17,519 --> 00:16:20,800
a subset of tls data set where we can

435
00:16:20,800 --> 00:16:23,680
batch together keys

436
00:16:23,680 --> 00:16:25,120
which we

437
00:16:25,120 --> 00:16:26,399
assume that they are coming from the

438
00:16:26,399 --> 00:16:29,199
same source uh with the

439
00:16:29,199 --> 00:16:31,759
size of 10 but below at least 10 but

440
00:16:31,759 --> 00:16:34,079
below 100 keys

441
00:16:34,079 --> 00:16:36,160
and we batch these keys based on the

442
00:16:36,160 --> 00:16:39,199
subject and uh issue date

443
00:16:39,199 --> 00:16:41,839
we got results like this yeah so openssl

444
00:16:41,839 --> 00:16:45,279
ht2 microsoft slightly more than 10. so

445
00:16:45,279 --> 00:16:48,000
it's roughly holding and also the the

446
00:16:48,000 --> 00:16:49,120
blue part

447
00:16:49,120 --> 00:16:51,759
this is a classification for the group

448
00:16:51,759 --> 00:16:54,320
which contains reasonable libraries like

449
00:16:54,320 --> 00:16:56,639
nettle botan crypt clip

450
00:16:56,639 --> 00:16:59,680
wolf ssl and most importantly

451
00:16:59,680 --> 00:17:01,440
open ssl in a fips mode we can

452
00:17:01,440 --> 00:17:03,199
distinguish between the openssl and

453
00:17:03,199 --> 00:17:06,160
openssl in a fips mode

454
00:17:06,160 --> 00:17:08,160
and there is also one person remaining

455
00:17:08,160 --> 00:17:09,280
for

456
00:17:09,280 --> 00:17:11,760
formerly paul ssl now armba

457
00:17:11,760 --> 00:17:15,280
arm ambit and openjdk and bouncy castle

458
00:17:15,280 --> 00:17:17,839
so this is sanitycheck makes sense a lot

459
00:17:17,839 --> 00:17:18,480
of

460
00:17:18,480 --> 00:17:21,119
assumptions but make sense

461
00:17:21,119 --> 00:17:23,359
better sanity check is about the

462
00:17:23,359 --> 00:17:25,520
impossible keys

463
00:17:25,520 --> 00:17:29,360
because we know that some sources can't

464
00:17:29,360 --> 00:17:32,960
generate or never generate some uh mask

465
00:17:32,960 --> 00:17:35,679
values okay so let's take a look on

466
00:17:35,679 --> 00:17:38,240
openssl and tls dataset again

467
00:17:38,240 --> 00:17:39,840
and

468
00:17:39,840 --> 00:17:42,000
we know that the openssl will never

469
00:17:42,000 --> 00:17:44,400
generate keys with the mask values from

470
00:17:44,400 --> 00:17:47,360
this particular region and if we will

471
00:17:47,360 --> 00:17:49,280
see the key from this region we know it

472
00:17:49,280 --> 00:17:51,039
can be open ssl

473
00:17:51,039 --> 00:17:52,480
so what we can do

474
00:17:52,480 --> 00:17:54,480
is take

475
00:17:54,480 --> 00:17:56,720
all these large data sets

476
00:17:56,720 --> 00:17:58,640
big advantage is that now we can work

477
00:17:58,640 --> 00:18:00,799
with every single key we can test every

478
00:18:00,799 --> 00:18:02,559
single key whether it's coming from the

479
00:18:02,559 --> 00:18:04,960
possibly coming from the openssl or not

480
00:18:04,960 --> 00:18:08,080
and these are the results yeah the

481
00:18:08,080 --> 00:18:10,720
column with the percentage of keys that

482
00:18:10,720 --> 00:18:13,280
can't be opened as a cell

483
00:18:13,280 --> 00:18:15,120
so let's start with the third one which

484
00:18:15,120 --> 00:18:17,760
is the tls data set ordinary

485
00:18:17,760 --> 00:18:19,919
the internet white scan

486
00:18:19,919 --> 00:18:20,720
and

487
00:18:20,720 --> 00:18:22,640
about 90 percent

488
00:18:22,640 --> 00:18:23,919
uh

489
00:18:23,919 --> 00:18:27,120
can be from openssl which leaves the

490
00:18:27,120 --> 00:18:29,200
rest that can be open ssl and this is

491
00:18:29,200 --> 00:18:31,039
something that holds with uh the

492
00:18:31,039 --> 00:18:32,640
intuition we have

493
00:18:32,640 --> 00:18:35,760
uh even better the let's encrypt let's

494
00:18:35,760 --> 00:18:38,880
encrypt data set is just a subset of uh

495
00:18:38,880 --> 00:18:40,559
tls data set

496
00:18:40,559 --> 00:18:41,360
uh

497
00:18:41,360 --> 00:18:43,120
with the certification authority being a

498
00:18:43,120 --> 00:18:45,600
let's encrypt and here it's quite

499
00:18:45,600 --> 00:18:49,120
different only 1.8 can be from openssl

500
00:18:49,120 --> 00:18:51,120
and this makes perfect sense because

501
00:18:51,120 --> 00:18:53,520
openssl is a default client for

502
00:18:53,520 --> 00:18:56,799
a let's encrypt certification client

503
00:18:56,799 --> 00:18:59,200
and what about something that where you

504
00:18:59,200 --> 00:19:00,640
don't expect

505
00:19:00,640 --> 00:19:03,840
uh openssl to be used pgp set you are

506
00:19:03,840 --> 00:19:06,880
using gpg or pgp original client but not

507
00:19:06,880 --> 00:19:09,120
really openssl

508
00:19:09,120 --> 00:19:12,559
so it's very rare here and here about 47

509
00:19:12,559 --> 00:19:15,520
percent uh can be from openssl and this

510
00:19:15,520 --> 00:19:17,360
is actually very well matching with the

511
00:19:17,360 --> 00:19:18,880
baseline because if something is not

512
00:19:18,880 --> 00:19:22,559
used at all it's roughly for openssl 50

513
00:19:22,559 --> 00:19:25,679
uh can be and rest can be okay so this

514
00:19:25,679 --> 00:19:27,919
is this this again holds very well with

515
00:19:27,919 --> 00:19:30,400
the intuition we have

516
00:19:30,400 --> 00:19:33,039
uh so we believe that works so what is

517
00:19:33,039 --> 00:19:34,480
the impact of this

518
00:19:34,480 --> 00:19:36,400
uh this is information disclosure

519
00:19:36,400 --> 00:19:38,480
vulnerability so you may think about

520
00:19:38,480 --> 00:19:40,720
that once you are generating your key

521
00:19:40,720 --> 00:19:43,200
pair and publishing a public key

522
00:19:43,200 --> 00:19:45,840
you are also adding a sticker saying

523
00:19:45,840 --> 00:19:48,080
this key was generated by that particle

524
00:19:48,080 --> 00:19:50,559
library cryptics in this sense so how

525
00:19:50,559 --> 00:19:53,760
you can use it and misuse it

526
00:19:53,760 --> 00:19:55,200
so let's assume

527
00:19:55,200 --> 00:19:57,440
that uh some cryptographic library will

528
00:19:57,440 --> 00:20:00,559
turn out to be vulnerable and because

529
00:20:00,559 --> 00:20:02,159
some implementation error you can

530
00:20:02,159 --> 00:20:04,640
factorize its keys

531
00:20:04,640 --> 00:20:06,559
but not for cheap you need to do a lot

532
00:20:06,559 --> 00:20:09,200
of operations so therefore you can't

533
00:20:09,200 --> 00:20:11,440
just go through the whole tls data set

534
00:20:11,440 --> 00:20:13,360
all internet web servers and try to

535
00:20:13,360 --> 00:20:15,679
factorize it uh

536
00:20:15,679 --> 00:20:16,799
because you need to do a lot of

537
00:20:16,799 --> 00:20:18,799
operations but with this information

538
00:20:18,799 --> 00:20:20,880
leakage vulnerability you can just first

539
00:20:20,880 --> 00:20:22,720
search for the keys from this library

540
00:20:22,720 --> 00:20:26,320
and then factorize it afterwards

541
00:20:26,880 --> 00:20:28,559
this information leakage is also

542
00:20:28,559 --> 00:20:31,280
decreasing your anonymity set so if you

543
00:20:31,280 --> 00:20:32,000
are

544
00:20:32,000 --> 00:20:34,480
operating a tor hidden service

545
00:20:34,480 --> 00:20:36,480
and for some strange reason you are not

546
00:20:36,480 --> 00:20:37,919
using the

547
00:20:37,919 --> 00:20:40,880
default client as all others

548
00:20:40,880 --> 00:20:42,559
maybe because you like to protect your

549
00:20:42,559 --> 00:20:45,840
private keys in a secure hardware

550
00:20:45,840 --> 00:20:47,039
then

551
00:20:47,039 --> 00:20:48,400
using this vulnerability this

552
00:20:48,400 --> 00:20:51,120
information disclosure vulnerability

553
00:20:51,120 --> 00:20:52,240
some

554
00:20:52,240 --> 00:20:53,760
tor hidden operators can be linked

555
00:20:53,760 --> 00:20:55,360
together because they are using some

556
00:20:55,360 --> 00:20:58,720
very very unusual sources

557
00:20:58,720 --> 00:21:01,360
another example might be maybe you are

558
00:21:01,360 --> 00:21:03,919
using some cryptographic as a service

559
00:21:03,919 --> 00:21:04,880
server

560
00:21:04,880 --> 00:21:07,440
they promise that they will generate

561
00:21:07,440 --> 00:21:09,360
private keys for you they will use the

562
00:21:09,360 --> 00:21:13,360
private keys for you for signatures

563
00:21:13,520 --> 00:21:15,440
so you can verify you can generate bunch

564
00:21:15,440 --> 00:21:19,600
of keys from their service and then ask

565
00:21:19,600 --> 00:21:22,080
is it really some secure hardware or is

566
00:21:22,080 --> 00:21:23,840
is it open ssl instead and they are

567
00:21:23,840 --> 00:21:26,320
lying so it can be used that direction

568
00:21:26,320 --> 00:21:27,360
as well

569
00:21:27,360 --> 00:21:29,440
so some compliance

570
00:21:29,440 --> 00:21:31,919
so this leads us to the defense what we

571
00:21:31,919 --> 00:21:34,240
can do about that so there are two lines

572
00:21:34,240 --> 00:21:37,039
of defenses here uh first coming from

573
00:21:37,039 --> 00:21:39,200
the developers of these libraries

574
00:21:39,200 --> 00:21:40,960
and in principle it's simple

575
00:21:40,960 --> 00:21:43,600
they just need to unify the way how they

576
00:21:43,600 --> 00:21:45,679
are generating rsa keys

577
00:21:45,679 --> 00:21:46,720
but

578
00:21:46,720 --> 00:21:49,039
this is probably very hard i

579
00:21:49,039 --> 00:21:50,799
i don't think this will happen soon

580
00:21:50,799 --> 00:21:52,480
because at first they need to agree what

581
00:21:52,480 --> 00:21:56,159
is the right way to generate rsa keys

582
00:21:56,159 --> 00:21:58,240
and the second thing is this is the

583
00:21:58,240 --> 00:22:00,159
changes this is a change this will

584
00:22:00,159 --> 00:22:02,400
require a change in a very critical part

585
00:22:02,400 --> 00:22:04,000
of code

586
00:22:04,000 --> 00:22:06,080
and you will still have legacy binaries

587
00:22:06,080 --> 00:22:07,480
and so on so i believe this

588
00:22:07,480 --> 00:22:11,280
vulnerability will stay here for longer

589
00:22:11,280 --> 00:22:13,679
fortunately you as the users of the

590
00:22:13,679 --> 00:22:16,559
library can defend yourself

591
00:22:16,559 --> 00:22:18,480
during the generation of the keys so

592
00:22:18,480 --> 00:22:20,880
what you can do is instead of generating

593
00:22:20,880 --> 00:22:23,520
just one key you can generate multiple

594
00:22:23,520 --> 00:22:24,480
keys

595
00:22:24,480 --> 00:22:27,120
let it classify and then select the one

596
00:22:27,120 --> 00:22:29,200
which is least specific

597
00:22:29,200 --> 00:22:30,159
okay

598
00:22:30,159 --> 00:22:32,480
uh and on average uh you will just need

599
00:22:32,480 --> 00:22:34,559
five keys to generate yeah so it's

600
00:22:34,559 --> 00:22:37,840
practical uh defense

601
00:22:37,840 --> 00:22:39,440
and our tool

602
00:22:39,440 --> 00:22:41,600
is trying to help you with that so if

603
00:22:41,600 --> 00:22:43,520
you will put your public key there we

604
00:22:43,520 --> 00:22:45,679
will highlight a

605
00:22:45,679 --> 00:22:49,200
list specific key for you

606
00:22:49,760 --> 00:22:51,039
so what else

607
00:22:51,039 --> 00:22:53,039
in a paper and especially in a technical

608
00:22:53,039 --> 00:22:54,480
report because we work with a lot of

609
00:22:54,480 --> 00:22:56,559
libraries so we have a lot of pictures

610
00:22:56,559 --> 00:22:58,640
uh so so take a look and uh at a

611
00:22:58,640 --> 00:23:00,640
technical report if you are interested

612
00:23:00,640 --> 00:23:03,360
we provided a summary of rsa keeper

613
00:23:03,360 --> 00:23:06,000
generation techniques we saw uh we also

614
00:23:06,000 --> 00:23:08,000
analyzed random streams coming from the

615
00:23:08,000 --> 00:23:10,960
smart cards and we saw some biases there

616
00:23:10,960 --> 00:23:13,039
we also identified some systematic

617
00:23:13,039 --> 00:23:15,760
defect in a generation of

618
00:23:15,760 --> 00:23:18,720
public keys on some smart card

619
00:23:18,720 --> 00:23:20,799
fortunately this

620
00:23:20,799 --> 00:23:24,960
weak public week rsa key was never

621
00:23:24,960 --> 00:23:27,280
saw in this large data set roost in a

622
00:23:27,280 --> 00:23:29,840
real world which is good and we also did

623
00:23:29,840 --> 00:23:33,280
some time and power analysis how the

624
00:23:33,280 --> 00:23:36,799
keys are generated on the smart cards

625
00:23:36,799 --> 00:23:38,720
data sets are available so so if you

626
00:23:38,720 --> 00:23:41,120
like to play with some machine learning

627
00:23:41,120 --> 00:23:44,158
on this go ahead

628
00:23:45,039 --> 00:23:47,120
so what are the limitations i like to

629
00:23:47,120 --> 00:23:48,400
highlight free

630
00:23:48,400 --> 00:23:50,640
so if you have just one key

631
00:23:50,640 --> 00:23:53,760
you can have lower accuracy okay one key

632
00:23:53,760 --> 00:23:57,120
is 40 on average on our test set

633
00:23:57,120 --> 00:24:00,000
uh for some sources it's perfectly

634
00:24:00,000 --> 00:24:03,120
working 95 probability for some sources

635
00:24:03,120 --> 00:24:05,440
is very unspecific

636
00:24:05,440 --> 00:24:08,080
we can distinguish mutually or libraries

637
00:24:08,080 --> 00:24:10,640
some some libraries fit within the same

638
00:24:10,640 --> 00:24:12,640
group

639
00:24:12,640 --> 00:24:14,320
and

640
00:24:14,320 --> 00:24:15,679
although we try to cover a lot of

641
00:24:15,679 --> 00:24:18,240
software libraries some of these some

642
00:24:18,240 --> 00:24:19,679
sources are still missing we are working

643
00:24:19,679 --> 00:24:22,480
on that most significantly hsms so so we

644
00:24:22,480 --> 00:24:25,200
still need to gather keys from hsms

645
00:24:25,200 --> 00:24:26,960
so to conclude

646
00:24:26,960 --> 00:24:28,880
rsa keeper generation

647
00:24:28,880 --> 00:24:31,360
observably bias public keys

648
00:24:31,360 --> 00:24:33,360
and different libraries bias it

649
00:24:33,360 --> 00:24:34,480
differently and therefore we can

650
00:24:34,480 --> 00:24:36,799
distinguish this

651
00:24:36,799 --> 00:24:39,360
so with an attribute based on bunch of

652
00:24:39,360 --> 00:24:41,840
public keys we can go back and say which

653
00:24:41,840 --> 00:24:43,840
library generated that

654
00:24:43,840 --> 00:24:46,080
on average with 10 keys you are 85

655
00:24:46,080 --> 00:24:47,760
percent probable

656
00:24:47,760 --> 00:24:50,640
99 with top three

657
00:24:50,640 --> 00:24:52,559
for some sources even one key is enough

658
00:24:52,559 --> 00:24:54,960
right you can just check the table

659
00:24:54,960 --> 00:24:56,080
it's information disclosure

660
00:24:56,080 --> 00:24:57,520
vulnerability so you can use it for

661
00:24:57,520 --> 00:24:59,520
forensics dynamization

662
00:24:59,520 --> 00:25:01,679
compliancy testing

663
00:25:01,679 --> 00:25:04,159
and it it's not that easy to fix from

664
00:25:04,159 --> 00:25:06,080
the developer's point of view so this

665
00:25:06,080 --> 00:25:07,520
will probably stay here for longer but

666
00:25:07,520 --> 00:25:09,120
you can defend yourself by generating

667
00:25:09,120 --> 00:25:10,400
more keys

668
00:25:10,400 --> 00:25:12,000
so thank you if you have any questions

669
00:25:12,000 --> 00:25:15,039
i'm happy to take it

670
00:25:22,559 --> 00:25:24,320
uh hi kenny patterson from royal

671
00:25:24,320 --> 00:25:26,080
holloway university of london thank you

672
00:25:26,080 --> 00:25:28,159
very much for the very nice talk i was

673
00:25:28,159 --> 00:25:30,159
wondering when you were generating keys

674
00:25:30,159 --> 00:25:32,559
from smart cards if you ever saw any

675
00:25:32,559 --> 00:25:34,159
repeated primes

676
00:25:34,159 --> 00:25:37,679
repeated primes no we never saw that

677
00:25:37,679 --> 00:25:40,400
with one example of one exception where

678
00:25:40,400 --> 00:25:42,320
it was a very big key because it turned

679
00:25:42,320 --> 00:25:43,679
out that uh

680
00:25:43,679 --> 00:25:45,120
sometimes the random number generator

681
00:25:45,120 --> 00:25:47,600
will fail and the smart car itself will

682
00:25:47,600 --> 00:25:49,840
take the failed value which was just

683
00:25:49,840 --> 00:25:51,039
zeros

684
00:25:51,039 --> 00:25:53,039
and figure out that it's not a prime and

685
00:25:53,039 --> 00:25:55,039
then we'll just increment by two and by

686
00:25:55,039 --> 00:25:56,799
two and two and it will end up always

687
00:25:56,799 --> 00:25:58,480
with the same prime yeah in that case

688
00:25:58,480 --> 00:26:01,679
yes but uh in other cases no

689
00:26:01,679 --> 00:26:04,000
for working cards now okay so it might

690
00:26:04,000 --> 00:26:05,919
be interesting to compare your results

691
00:26:05,919 --> 00:26:08,320
with a paper published at asia crypt a

692
00:26:08,320 --> 00:26:09,600
few years ago where they were looking at

693
00:26:09,600 --> 00:26:12,000
prime generation on smart cards and they

694
00:26:12,000 --> 00:26:14,559
found uh in some classes of cards and

695
00:26:14,559 --> 00:26:17,200
there were repeated primes so it perhaps

696
00:26:17,200 --> 00:26:18,720
i think that was a

697
00:26:18,720 --> 00:26:21,120
taiwanese government smart card if i

698
00:26:21,120 --> 00:26:22,480
recall correctly

699
00:26:22,480 --> 00:26:24,320
yeah i i know the paper yeah but but

700
00:26:24,320 --> 00:26:26,480
this was not the case for us yeah and it

701
00:26:26,480 --> 00:26:28,640
was six different manufacturers but

702
00:26:28,640 --> 00:26:31,200
yeah we had the nice cards

703
00:26:31,200 --> 00:26:34,159
can i ask one more question um your your

704
00:26:34,159 --> 00:26:36,400
classification um approach is very

705
00:26:36,400 --> 00:26:38,480
interesting i think it's basically

706
00:26:38,480 --> 00:26:41,360
an instance of bayesian classification

707
00:26:41,360 --> 00:26:43,200
but you're using a uniform prior

708
00:26:43,200 --> 00:26:45,279
distribution in your experiments because

709
00:26:45,279 --> 00:26:47,679
you have 10 million keys from each class

710
00:26:47,679 --> 00:26:48,960
if you want to assess the true

711
00:26:48,960 --> 00:26:50,400
probability

712
00:26:50,400 --> 00:26:52,000
you need to use the correct prior

713
00:26:52,000 --> 00:26:54,480
distribution for keys in the wild and

714
00:26:54,480 --> 00:26:55,919
that's not something you can easily

715
00:26:55,919 --> 00:26:57,600
estimate i wonder how that affects your

716
00:26:57,600 --> 00:26:59,760
classification results yeah yeah this is

717
00:26:59,760 --> 00:27:01,840
very good question um

718
00:27:01,840 --> 00:27:03,840
we thought about that but the the issue

719
00:27:03,840 --> 00:27:05,279
is that we don't know the prior

720
00:27:05,279 --> 00:27:06,720
probability for for different groups

721
00:27:06,720 --> 00:27:09,039
yeah so therefore we we opted to

722
00:27:09,039 --> 00:27:11,200
stay to to to keep the prior probability

723
00:27:11,200 --> 00:27:12,799
exactly the same and then see whether

724
00:27:12,799 --> 00:27:14,880
this will work and then

725
00:27:14,880 --> 00:27:17,919
because it it match the web servers uh

726
00:27:17,919 --> 00:27:20,559
market share so we believe even that it

727
00:27:20,559 --> 00:27:21,600
works

728
00:27:21,600 --> 00:27:24,000
but but this is hard to obtain the the

729
00:27:24,000 --> 00:27:25,520
priority probabilities but on the other

730
00:27:25,520 --> 00:27:26,799
side if you have some additional

731
00:27:26,799 --> 00:27:28,399
knowledge and you know these

732
00:27:28,399 --> 00:27:29,679
probabilities definitely you can do

733
00:27:29,679 --> 00:27:31,520
better okay thank you very much thank

734
00:27:31,520 --> 00:27:34,520
you

735
00:27:38,480 --> 00:27:40,559
you

