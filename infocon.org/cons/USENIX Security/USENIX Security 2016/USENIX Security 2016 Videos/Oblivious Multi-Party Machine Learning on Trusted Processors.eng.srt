1
00:00:10,960 --> 00:00:12,719
hello everyone so today i'll be talking

2
00:00:12,719 --> 00:00:14,160
about oblivious multi-body machine

3
00:00:14,160 --> 00:00:16,000
learning on trusted processors and this

4
00:00:16,000 --> 00:00:18,320
is a joint work with asta who was an

5
00:00:18,320 --> 00:00:21,039
intern with us manuel cedric sebastian

6
00:00:21,039 --> 00:00:23,439
felix and kapil my microsoft colleagues

7
00:00:23,439 --> 00:00:25,039
and asta and cedric are here in the

8
00:00:25,039 --> 00:00:26,480
audience

9
00:00:26,480 --> 00:00:28,640
okay so where let us consider the

10
00:00:28,640 --> 00:00:30,240
scenarios where machine learning or

11
00:00:30,240 --> 00:00:32,238
multi-body machine learning kind of is

12
00:00:32,238 --> 00:00:33,200
needed

13
00:00:33,200 --> 00:00:34,880
so recently our world has been

14
00:00:34,880 --> 00:00:36,719
argumented with these cute creatures

15
00:00:36,719 --> 00:00:38,320
where the goal is to

16
00:00:38,320 --> 00:00:40,160
catch it with your phone

17
00:00:40,160 --> 00:00:42,239
um so how do you find them so there are

18
00:00:42,239 --> 00:00:44,480
third party they used to be third party

19
00:00:44,480 --> 00:00:47,120
maps which will basically tell you where

20
00:00:47,120 --> 00:00:49,520
like the rare ones are but this all

21
00:00:49,520 --> 00:00:52,559
closed down uh last monday so now the

22
00:00:52,559 --> 00:00:54,399
way you kind of have to go is just

23
00:00:54,399 --> 00:00:57,280
manually go around and look for them

24
00:00:57,280 --> 00:01:00,000
however all is not lost

25
00:01:00,000 --> 00:01:02,239
in particular actually all the data is

26
00:01:02,239 --> 00:01:04,559
there is just split up between the

27
00:01:04,559 --> 00:01:07,280
participants so each user has his own

28
00:01:07,280 --> 00:01:09,520
map or her map where they see which

29
00:01:09,520 --> 00:01:11,600
pokemon they have found

30
00:01:11,600 --> 00:01:14,159
so if only there was a way to combine

31
00:01:14,159 --> 00:01:16,000
all these data and create a

32
00:01:16,000 --> 00:01:17,840
collaborative map that can benefit

33
00:01:17,840 --> 00:01:19,439
everyone

34
00:01:19,439 --> 00:01:21,920
so how would the users do that

35
00:01:21,920 --> 00:01:23,600
well they can't use something called the

36
00:01:23,600 --> 00:01:25,520
care best solution which is with the

37
00:01:25,520 --> 00:01:28,159
motor sharing scaring because they have

38
00:01:28,159 --> 00:01:29,759
very sensitive data which is the

39
00:01:29,759 --> 00:01:32,799
location and the time uh where they were

40
00:01:32,799 --> 00:01:33,759
have been

41
00:01:33,759 --> 00:01:36,960
so we need some other solutions

42
00:01:36,960 --> 00:01:38,320
of course multi-party machine learning

43
00:01:38,320 --> 00:01:40,159
comes up within a bit more serious

44
00:01:40,159 --> 00:01:42,479
scenarios for example hospitals have

45
00:01:42,479 --> 00:01:44,799
different patients data and if they were

46
00:01:44,799 --> 00:01:47,200
to train the model on their joint uh

47
00:01:47,200 --> 00:01:49,520
data it would be more useful than if

48
00:01:49,520 --> 00:01:52,159
they were to um to train it on their

49
00:01:52,159 --> 00:01:54,560
separate uh data sets

50
00:01:54,560 --> 00:01:57,040
again the question of sensitive data

51
00:01:57,040 --> 00:01:59,040
comes in and they can't just share it

52
00:01:59,040 --> 00:02:00,479
with each other

53
00:02:00,479 --> 00:02:02,079
when i say multi-party machine learning

54
00:02:02,079 --> 00:02:04,799
i don't only mean combine the data sets

55
00:02:04,799 --> 00:02:06,799
in order to train i also mean that it

56
00:02:06,799 --> 00:02:08,639
can be a prediction phase for example

57
00:02:08,639 --> 00:02:10,479
there's a decision tree which is pretty

58
00:02:10,479 --> 00:02:12,800
much the one from the previous talk just

59
00:02:12,800 --> 00:02:14,080
a bit more round

60
00:02:14,080 --> 00:02:15,840
and uh so one would

61
00:02:15,840 --> 00:02:17,680
simply come

62
00:02:17,680 --> 00:02:19,520
take the patient's record and then

63
00:02:19,520 --> 00:02:21,760
traverse the tree and basically neither

64
00:02:21,760 --> 00:02:23,360
of the parties should be seeing each

65
00:02:23,360 --> 00:02:25,200
other's data except to get the result

66
00:02:25,200 --> 00:02:26,959
for example here it's a prediction of

67
00:02:26,959 --> 00:02:29,360
the likelihood of a heart disease

68
00:02:29,360 --> 00:02:30,800
again probably the hospital wouldn't

69
00:02:30,800 --> 00:02:32,959
want to show the model and

70
00:02:32,959 --> 00:02:34,560
not all of the patient's data should be

71
00:02:34,560 --> 00:02:38,080
required to traverse the tree

72
00:02:38,080 --> 00:02:40,319
so in this talk we propose a solution

73
00:02:40,319 --> 00:02:42,720
for secure multi-party machine learning

74
00:02:42,720 --> 00:02:44,239
we explore the design space in

75
00:02:44,239 --> 00:02:45,920
particular we are very different from

76
00:02:45,920 --> 00:02:47,920
the previous approaches because we rely

77
00:02:47,920 --> 00:02:49,760
on the trusted processors

78
00:02:49,760 --> 00:02:51,840
and furthermore we harden the code that

79
00:02:51,840 --> 00:02:53,599
is actually running on those trusted

80
00:02:53,599 --> 00:02:54,959
processors

81
00:02:54,959 --> 00:02:56,640
it protects against very strong

82
00:02:56,640 --> 00:02:58,400
attackers as you will see and

83
00:02:58,400 --> 00:03:00,560
furthermore we ran it on the real intel

84
00:03:00,560 --> 00:03:03,280
sgx and as you will see it gives quite a

85
00:03:03,280 --> 00:03:05,280
low overhead

86
00:03:05,280 --> 00:03:06,879
so of course multi-party computation is

87
00:03:06,879 --> 00:03:08,879
not new and it has existed in

88
00:03:08,879 --> 00:03:11,599
cryptography for 20-plus years

89
00:03:11,599 --> 00:03:13,920
where one would encode the data and the

90
00:03:13,920 --> 00:03:16,239
code in some particular way so they can

91
00:03:16,239 --> 00:03:17,760
upload it to the

92
00:03:17,760 --> 00:03:19,680
untrusted third party which can

93
00:03:19,680 --> 00:03:22,080
basically um operate on this data

94
00:03:22,080 --> 00:03:25,680
without having to decrypt it

95
00:03:25,680 --> 00:03:28,720
uh and uh although there has been an

96
00:03:28,720 --> 00:03:32,720
enormous project uh progress in the past

97
00:03:32,720 --> 00:03:33,920
few years

98
00:03:33,920 --> 00:03:34,959
it's

99
00:03:34,959 --> 00:03:36,640
efficient for some computations but not

100
00:03:36,640 --> 00:03:38,000
general purpose

101
00:03:38,000 --> 00:03:40,159
so what our users are left to do is

102
00:03:40,159 --> 00:03:42,640
basically upload their data to the uh to

103
00:03:42,640 --> 00:03:45,040
the cloud but also have to supply the

104
00:03:45,040 --> 00:03:47,200
keys to decrypt this data

105
00:03:47,200 --> 00:03:49,599
and the second their application has to

106
00:03:49,599 --> 00:03:52,000
decrypt this data basically they declare

107
00:03:52,000 --> 00:03:54,080
my trusting computing base consists of

108
00:03:54,080 --> 00:03:56,159
everything that is running on the cloud

109
00:03:56,159 --> 00:03:58,239
which includes the operating system the

110
00:03:58,239 --> 00:04:00,720
hypervisor and all the other tenants

111
00:04:00,720 --> 00:04:03,840
quite a big trust in computing base

112
00:04:03,840 --> 00:04:06,400
instead we propose to isolate the

113
00:04:06,400 --> 00:04:08,239
computation that has to deal with your

114
00:04:08,239 --> 00:04:10,080
secrets and secret data

115
00:04:10,080 --> 00:04:12,400
how do we achieve this isolation using

116
00:04:12,400 --> 00:04:15,120
trusted processors do those trusted

117
00:04:15,120 --> 00:04:16,560
processes exist

118
00:04:16,560 --> 00:04:19,120
yes since last october uh intel started

119
00:04:19,120 --> 00:04:21,440
producing them on on on the laptops

120
00:04:21,440 --> 00:04:22,720
called um

121
00:04:22,720 --> 00:04:25,120
sjx intel hdx and this is what we will

122
00:04:25,120 --> 00:04:26,840
use in our

123
00:04:26,840 --> 00:04:29,280
experiments so who are we protecting

124
00:04:29,280 --> 00:04:31,360
against so our trusting computing base

125
00:04:31,360 --> 00:04:32,880
consists of the machine learning code

126
00:04:32,880 --> 00:04:34,960
that we upload and as well other

127
00:04:34,960 --> 00:04:38,240
trusting hardware everything else in the

128
00:04:38,240 --> 00:04:40,560
cloud fabric is malicious so it could be

129
00:04:40,560 --> 00:04:42,160
the parties that are participating in

130
00:04:42,160 --> 00:04:44,240
the protocol uh so the machine learning

131
00:04:44,240 --> 00:04:46,240
code is known to everybody it could be

132
00:04:46,240 --> 00:04:48,800
other tenants snooping on our cache what

133
00:04:48,800 --> 00:04:50,720
we are doing it could be compromised

134
00:04:50,720 --> 00:04:52,960
kernel it could be also a passive

135
00:04:52,960 --> 00:04:55,040
adversaries is just seeing

136
00:04:55,040 --> 00:04:57,600
how we are interacting with the system

137
00:04:57,600 --> 00:04:59,520
we assume that code the machine learning

138
00:04:59,520 --> 00:05:01,280
code is not going to do anything stupid

139
00:05:01,280 --> 00:05:03,840
like write out secrets in the plain text

140
00:05:03,840 --> 00:05:05,280
and we are also in the classical

141
00:05:05,280 --> 00:05:07,360
multi-party computation model where the

142
00:05:07,360 --> 00:05:10,320
users agree to share the output and

143
00:05:10,320 --> 00:05:12,720
whatever

144
00:05:12,720 --> 00:05:15,120
will be inferred from the input but if

145
00:05:15,120 --> 00:05:16,800
we wanted to protect against those there

146
00:05:16,800 --> 00:05:18,720
will be like an add-on that you will

147
00:05:18,720 --> 00:05:20,800
change your machine learn code and add i

148
00:05:20,800 --> 00:05:22,080
don't know your favorite differential

149
00:05:22,080 --> 00:05:24,479
private mechanism on top of it

150
00:05:24,479 --> 00:05:27,039
we do can see the memory and network

151
00:05:27,039 --> 00:05:28,720
side channels but we do not consider

152
00:05:28,720 --> 00:05:31,440
time and power channels

153
00:05:31,440 --> 00:05:32,639
okay so

154
00:05:32,639 --> 00:05:34,720
how we compare with the kind of previous

155
00:05:34,720 --> 00:05:36,960
work well we are making a very different

156
00:05:36,960 --> 00:05:38,160
assumption as opposed to the

157
00:05:38,160 --> 00:05:40,000
cryptographic solutions we rely on

158
00:05:40,000 --> 00:05:42,160
trusted hardware and in return we have

159
00:05:42,160 --> 00:05:43,520
very small

160
00:05:43,520 --> 00:05:46,240
overhead this overhead however is higher

161
00:05:46,240 --> 00:05:48,000
than what is a little bit higher than

162
00:05:48,000 --> 00:05:50,160
what you would get with your trusting

163
00:05:50,160 --> 00:05:52,000
computing base constitution of the whole

164
00:05:52,000 --> 00:05:54,560
cloud but in return you get a very small

165
00:05:54,560 --> 00:05:58,319
interesting computer base that we have

166
00:05:58,319 --> 00:06:00,880
okay so how would the users or the

167
00:06:00,880 --> 00:06:02,720
parties use

168
00:06:02,720 --> 00:06:04,639
our

169
00:06:04,639 --> 00:06:06,960
our framework so they first agree on the

170
00:06:06,960 --> 00:06:08,479
machine learning code that they're gonna

171
00:06:08,479 --> 00:06:11,039
run and then one of them uploads this

172
00:06:11,039 --> 00:06:12,319
code

173
00:06:12,319 --> 00:06:13,120
then

174
00:06:13,120 --> 00:06:15,440
because the code may have changed or one

175
00:06:15,440 --> 00:06:17,680
of the particles have modified they

176
00:06:17,680 --> 00:06:20,000
establish a secure channel with a cloud

177
00:06:20,000 --> 00:06:22,160
and verify that it is the code that they

178
00:06:22,160 --> 00:06:25,039
indeed put uh put on the cloud

179
00:06:25,039 --> 00:06:27,360
and it is indeed the correct um

180
00:06:27,360 --> 00:06:29,759
intelligence that is out there

181
00:06:29,759 --> 00:06:32,400
and then once that is established they

182
00:06:32,400 --> 00:06:34,560
send the data and the keys

183
00:06:34,560 --> 00:06:36,400
uh so it's important to know that the

184
00:06:36,400 --> 00:06:38,240
access to the data and the keys is

185
00:06:38,240 --> 00:06:40,160
isolated from the rest of the system and

186
00:06:40,160 --> 00:06:41,600
is only available to the machine

187
00:06:41,600 --> 00:06:43,039
learning code

188
00:06:43,039 --> 00:06:46,000
finally when the output is ready uh the

189
00:06:46,000 --> 00:06:48,400
it can be sent encrypted to the users

190
00:06:48,400 --> 00:06:50,000
with the shared key or it can stay in

191
00:06:50,000 --> 00:06:52,720
the cloud and um be queried later on by

192
00:06:52,720 --> 00:06:54,400
them

193
00:06:54,400 --> 00:06:55,360
so

194
00:06:55,360 --> 00:06:57,599
in our framework we are protecting the

195
00:06:57,599 --> 00:07:00,240
data using encryption everything that is

196
00:07:00,240 --> 00:07:02,080
outside of this isolated region will

197
00:07:02,080 --> 00:07:03,599
always be encrypted

198
00:07:03,599 --> 00:07:05,360
and we protect the code using these

199
00:07:05,360 --> 00:07:06,960
trusted processors

200
00:07:06,960 --> 00:07:09,440
but we also protect the accesses that

201
00:07:09,440 --> 00:07:11,680
this the code is making to the data so

202
00:07:11,680 --> 00:07:15,120
this memory side channels

203
00:07:15,199 --> 00:07:17,440
so what are these isolated regions so we

204
00:07:17,440 --> 00:07:19,440
they are called secure enclaves so

205
00:07:19,440 --> 00:07:22,400
basically uh isolated region of memory

206
00:07:22,400 --> 00:07:25,039
which is created by by a processor and

207
00:07:25,039 --> 00:07:27,039
the processor will make sure that no one

208
00:07:27,039 --> 00:07:29,759
outside can can access your memory so we

209
00:07:29,759 --> 00:07:31,919
get the integrity of the code

210
00:07:31,919 --> 00:07:34,000
we also can run remote attestation and

211
00:07:34,000 --> 00:07:36,479
check that it is uh that our code the

212
00:07:36,479 --> 00:07:39,360
one that we wanted is indeed uh been put

213
00:07:39,360 --> 00:07:42,160
into the enclave

214
00:07:42,160 --> 00:07:45,520
so this enclave is secure uh it has it's

215
00:07:45,520 --> 00:07:48,319
is living in a very hostile environment

216
00:07:48,319 --> 00:07:50,160
where basically whenever it's trying to

217
00:07:50,160 --> 00:07:52,960
get resources like memory it can be

218
00:07:52,960 --> 00:07:55,360
observed as a um

219
00:07:55,360 --> 00:07:57,039
it can it could be observed for example

220
00:07:57,039 --> 00:07:59,759
if someone shares the cache so here we

221
00:07:59,759 --> 00:08:01,680
will assume a very strong attacker that

222
00:08:01,680 --> 00:08:04,160
can observe everything very precisely at

223
00:08:04,160 --> 00:08:06,960
a cache line granularity

224
00:08:06,960 --> 00:08:08,479
and so we will call this a trace

225
00:08:08,479 --> 00:08:11,199
basically each of your excesses

226
00:08:11,199 --> 00:08:14,639
so we protect against uh such um

227
00:08:14,639 --> 00:08:16,319
such observations

228
00:08:16,319 --> 00:08:18,879
not in an ad hoc manner but with us the

229
00:08:18,879 --> 00:08:21,199
following guarantee if the adversary

230
00:08:21,199 --> 00:08:22,479
picks two

231
00:08:22,479 --> 00:08:24,400
inputs and it also

232
00:08:24,400 --> 00:08:26,400
sees the trace that was produced

233
00:08:26,400 --> 00:08:28,080
he cannot tell which of the inputs

234
00:08:28,080 --> 00:08:29,520
produced it

235
00:08:29,520 --> 00:08:31,680
so in other words

236
00:08:31,680 --> 00:08:33,360
the trace is basically only depends on

237
00:08:33,360 --> 00:08:35,360
the public data for example the size of

238
00:08:35,360 --> 00:08:36,958
the training data set or the number of

239
00:08:36,958 --> 00:08:39,360
classes in your machine learning model

240
00:08:39,360 --> 00:08:41,200
so we call this algorithms that have

241
00:08:41,200 --> 00:08:43,440
this property data oblivious because

242
00:08:43,440 --> 00:08:44,800
basically the rest of the system is

243
00:08:44,800 --> 00:08:47,600
oblivious to what you're trying to do

244
00:08:47,600 --> 00:08:49,360
when trying to achieve this side channel

245
00:08:49,360 --> 00:08:50,959
protection we will assume that the

246
00:08:50,959 --> 00:08:53,040
registers are private memory this is

247
00:08:53,040 --> 00:08:54,880
kind of the smallest assumption the

248
00:08:54,880 --> 00:08:56,640
smallest private memory that one can

249
00:08:56,640 --> 00:08:58,640
probably have and we'll assume that the

250
00:08:58,640 --> 00:09:00,560
manipulations inside of it and the

251
00:09:00,560 --> 00:09:02,240
content of the registers is hidden from

252
00:09:02,240 --> 00:09:04,959
the adversary

253
00:09:06,080 --> 00:09:08,240
so we considered five uh machine

254
00:09:08,240 --> 00:09:10,080
learning elders kind of uh trying to

255
00:09:10,080 --> 00:09:12,320
also cover supervised unsupervised

256
00:09:12,320 --> 00:09:14,720
learning some of them do prediction some

257
00:09:14,720 --> 00:09:18,000
of them also do um training phase

258
00:09:18,000 --> 00:09:19,360
and uh

259
00:09:19,360 --> 00:09:21,040
our side channel protection basically

260
00:09:21,040 --> 00:09:23,600
consists of three kind of parts

261
00:09:23,600 --> 00:09:26,320
so first we have a library of data

262
00:09:26,320 --> 00:09:27,839
believers primitives and these

263
00:09:27,839 --> 00:09:30,320
primitives are used in each of the

264
00:09:30,320 --> 00:09:32,240
algorithms

265
00:09:32,240 --> 00:09:34,800
then we noticed that in some supervised

266
00:09:34,800 --> 00:09:36,560
machine learning like support vector

267
00:09:36,560 --> 00:09:38,480
machines or neural networks there is a

268
00:09:38,480 --> 00:09:40,720
sampling phase and if not done properly

269
00:09:40,720 --> 00:09:42,080
it can be

270
00:09:42,080 --> 00:09:44,640
it can leak something so we propose an

271
00:09:44,640 --> 00:09:46,959
oblivious technique for sampling

272
00:09:46,959 --> 00:09:48,080
and then

273
00:09:48,080 --> 00:09:49,680
just by combining oblivious small

274
00:09:49,680 --> 00:09:51,680
primitives you don't get an oblivious

275
00:09:51,680 --> 00:09:54,160
algorithm so we have to work a bit

276
00:09:54,160 --> 00:09:56,640
harder and so we do some changes in the

277
00:09:56,640 --> 00:09:58,959
algorithm and basically the width of the

278
00:09:58,959 --> 00:10:00,240
lines um

279
00:10:00,240 --> 00:10:02,640
constitutes represents how much effort

280
00:10:02,640 --> 00:10:04,720
we put basically in changing each of the

281
00:10:04,720 --> 00:10:05,839
algorithms

282
00:10:05,839 --> 00:10:07,760
so today i will be talking about the our

283
00:10:07,760 --> 00:10:09,519
library about our sampling technique and

284
00:10:09,519 --> 00:10:10,800
about the two

285
00:10:10,800 --> 00:10:12,640
algorithms but for the rest please

286
00:10:12,640 --> 00:10:15,040
through the paper

287
00:10:15,040 --> 00:10:18,560
so our library of oblivious primitives

288
00:10:18,560 --> 00:10:20,560
so it consists of such things as for

289
00:10:20,560 --> 00:10:22,079
example uh

290
00:10:22,079 --> 00:10:25,360
greater operator move less and equal

291
00:10:25,360 --> 00:10:27,760
each of them operates only on registers

292
00:10:27,760 --> 00:10:29,600
this is to avoid the compiler to make

293
00:10:29,600 --> 00:10:31,360
optimizations and creating a side

294
00:10:31,360 --> 00:10:33,440
channel so for example in oblivious

295
00:10:33,440 --> 00:10:35,600
greater we are comparing x to y we load

296
00:10:35,600 --> 00:10:37,920
x and y to the registers and then we

297
00:10:37,920 --> 00:10:39,920
compare them there so that the result

298
00:10:39,920 --> 00:10:42,000
actually goes into the register as you

299
00:10:42,000 --> 00:10:47,240
remember registers our private memory

300
00:10:47,279 --> 00:10:48,880
um yep

301
00:10:48,880 --> 00:10:51,200
so we also have this oblivious get

302
00:10:51,200 --> 00:10:53,680
primitive uh which basically gets a nice

303
00:10:53,680 --> 00:10:56,000
element out of an array

304
00:10:56,000 --> 00:10:57,600
but with the following properties if we

305
00:10:57,600 --> 00:10:59,839
want to hide which of the indices that

306
00:10:59,839 --> 00:11:01,680
we've accessed

307
00:11:01,680 --> 00:11:03,040
so for those

308
00:11:03,040 --> 00:11:05,040
of you who know what oblivious ram is

309
00:11:05,040 --> 00:11:07,360
it's basically one would ask why not use

310
00:11:07,360 --> 00:11:10,480
oblivious ram because its whole purpose

311
00:11:10,480 --> 00:11:13,120
is to to do exactly that so why didn't

312
00:11:13,120 --> 00:11:15,120
we use it the first reason is most

313
00:11:15,120 --> 00:11:17,200
oblivious ram constructions assume quite

314
00:11:17,200 --> 00:11:19,440
a large plywood memory so something like

315
00:11:19,440 --> 00:11:22,160
logarithmic in the memory size and we

316
00:11:22,160 --> 00:11:25,120
had only basically constant

317
00:11:25,120 --> 00:11:28,160
number of registers and two oblivious

318
00:11:28,160 --> 00:11:31,040
ram breaks even only after uh your data

319
00:11:31,040 --> 00:11:33,120
set is quite large and we didn't

320
00:11:33,120 --> 00:11:36,079
encounter that big of a data sets um so

321
00:11:36,079 --> 00:11:37,200
scanning

322
00:11:37,200 --> 00:11:39,680
um worked and our scanning is actually

323
00:11:39,680 --> 00:11:42,160
quite optimized uh so now i will tell

324
00:11:42,160 --> 00:11:43,839
you how exactly we optimize this

325
00:11:43,839 --> 00:11:46,959
oblivious get primitive

326
00:11:46,959 --> 00:11:51,360
so here we have the cache which is um

327
00:11:51,360 --> 00:11:53,839
each line is 64 bytes and as we said we

328
00:11:53,839 --> 00:11:56,639
assume that the observer sees

329
00:11:56,639 --> 00:11:59,440
only which cache line they are accessing

330
00:11:59,440 --> 00:12:01,120
and then we have our registers which is

331
00:12:01,120 --> 00:12:03,040
the private memory which is uh it

332
00:12:03,040 --> 00:12:06,079
registers just for bytes

333
00:12:06,079 --> 00:12:07,519
so we know that

334
00:12:07,519 --> 00:12:09,279
we can read

335
00:12:09,279 --> 00:12:11,440
an address by

336
00:12:11,440 --> 00:12:13,360
in we can load the address into the

337
00:12:13,360 --> 00:12:15,360
register but from the adversary's point

338
00:12:15,360 --> 00:12:17,279
of view he will only see the cache line

339
00:12:17,279 --> 00:12:19,120
so he doesn't see which four bytes out

340
00:12:19,120 --> 00:12:21,680
of 64 that we are accessing

341
00:12:21,680 --> 00:12:23,760
so we build on that and use instead

342
00:12:23,760 --> 00:12:26,480
vector registers which are basically

343
00:12:26,480 --> 00:12:29,920
eight components of four

344
00:12:29,920 --> 00:12:32,720
or four byte registers

345
00:12:32,720 --> 00:12:34,639
but the great thing about them is that

346
00:12:34,639 --> 00:12:36,880
you can actually load the content of the

347
00:12:36,880 --> 00:12:39,680
vectors with a single uh in an atomic

348
00:12:39,680 --> 00:12:42,079
operation and this operation is called

349
00:12:42,079 --> 00:12:43,760
vp gather dt

350
00:12:43,760 --> 00:12:47,040
so basically now uh we can access four

351
00:12:47,040 --> 00:12:50,639
bytes out of 512 bytes obliviously

352
00:12:50,639 --> 00:12:52,959
so we do it in basically constant number

353
00:12:52,959 --> 00:12:55,920
of operations and we do it in two steps

354
00:12:55,920 --> 00:12:58,160
first we the adversary as we said

355
00:12:58,160 --> 00:13:01,360
registers our private memory so the

356
00:13:01,360 --> 00:13:02,800
the adversary doesn't see which of the

357
00:13:02,800 --> 00:13:04,959
eight registers that i'm accessing and

358
00:13:04,959 --> 00:13:07,279
second he doesn't see for each of those

359
00:13:07,279 --> 00:13:09,519
registers which of the four bytes i've

360
00:13:09,519 --> 00:13:11,120
accessed in the cache lines that i've

361
00:13:11,120 --> 00:13:13,440
touched

362
00:13:13,680 --> 00:13:16,079
okay so this was the primitives now let

363
00:13:16,079 --> 00:13:18,079
us step kind of

364
00:13:18,079 --> 00:13:20,240
take a step back and look at the actual

365
00:13:20,240 --> 00:13:22,320
uh training phase of some the machine

366
00:13:22,320 --> 00:13:23,920
learning algorithms in particular the

367
00:13:23,920 --> 00:13:25,600
supervised ones

368
00:13:25,600 --> 00:13:27,839
so in supervised learning you are given

369
00:13:27,839 --> 00:13:29,519
a training data which consists of your

370
00:13:29,519 --> 00:13:31,760
features and then your label y

371
00:13:31,760 --> 00:13:33,360
and then you're training the model and

372
00:13:33,360 --> 00:13:36,079
the way the model is often trained is by

373
00:13:36,079 --> 00:13:38,959
taking a small subset of the data and

374
00:13:38,959 --> 00:13:41,279
updating your model and then take

375
00:13:41,279 --> 00:13:43,279
another subset

376
00:13:43,279 --> 00:13:46,000
update your model and keep going

377
00:13:46,000 --> 00:13:48,160
so as you can see we are sampling with

378
00:13:48,160 --> 00:13:50,480
replacement uh here

379
00:13:50,480 --> 00:13:52,240
so there are two problems with uh this

380
00:13:52,240 --> 00:13:54,959
approach first ones it's not secure if

381
00:13:54,959 --> 00:13:56,320
somebody because

382
00:13:56,320 --> 00:13:58,560
um the observer can see how many times

383
00:13:58,560 --> 00:14:00,639
we touched which records and which

384
00:14:00,639 --> 00:14:03,360
records did not participate in updating

385
00:14:03,360 --> 00:14:04,800
the model at all

386
00:14:04,800 --> 00:14:06,000
and second

387
00:14:06,000 --> 00:14:07,360
uh because we are dealing with an

388
00:14:07,360 --> 00:14:09,120
encrypted data set

389
00:14:09,120 --> 00:14:10,800
we will have batches of encrypted

390
00:14:10,800 --> 00:14:12,880
records and it's very not efficient to

391
00:14:12,880 --> 00:14:14,800
basically decrypt the whole batch and

392
00:14:14,800 --> 00:14:17,440
only access one element so random access

393
00:14:17,440 --> 00:14:19,279
is not very efficient

394
00:14:19,279 --> 00:14:21,680
so to this end we propose to shuffle the

395
00:14:21,680 --> 00:14:23,920
records in an oblivious fashion so that

396
00:14:23,920 --> 00:14:25,760
one basically loses the correlation

397
00:14:25,760 --> 00:14:28,160
between the pre-shuffled and

398
00:14:28,160 --> 00:14:30,720
after the shuffle records

399
00:14:30,720 --> 00:14:33,279
and then the way we now update the model

400
00:14:33,279 --> 00:14:36,480
is by simply scanning we take the first

401
00:14:36,480 --> 00:14:39,440
um badge update it then take the next

402
00:14:39,440 --> 00:14:41,600
batch and update and so on

403
00:14:41,600 --> 00:14:43,600
but you may say okay we but we used to

404
00:14:43,600 --> 00:14:45,920
we changed our distribution because now

405
00:14:45,920 --> 00:14:48,639
i can never take the blue records again

406
00:14:48,639 --> 00:14:50,560
for example so we are sampling without

407
00:14:50,560 --> 00:14:52,480
replacement and we used to sample with

408
00:14:52,480 --> 00:14:53,680
replacement

409
00:14:53,680 --> 00:14:55,600
how we make the following observation is

410
00:14:55,600 --> 00:14:57,199
that from the correctness point of view

411
00:14:57,199 --> 00:14:59,199
of the algorithm actually the only thing

412
00:14:59,199 --> 00:14:59,920
that

413
00:14:59,920 --> 00:15:01,440
matters is that the distribution

414
00:15:01,440 --> 00:15:03,040
proposal

415
00:15:03,040 --> 00:15:04,959
produces an unbiased estimate of the

416
00:15:04,959 --> 00:15:07,120
expected value and those two produce

417
00:15:07,120 --> 00:15:08,320
that

418
00:15:08,320 --> 00:15:10,240
and also it's actually more efficient

419
00:15:10,240 --> 00:15:12,240
because basically if each of the colors

420
00:15:12,240 --> 00:15:14,720
represent an encrypted badge we can now

421
00:15:14,720 --> 00:15:16,720
decrypt the whole batch and

422
00:15:16,720 --> 00:15:19,199
operate on each record and put it back

423
00:15:19,199 --> 00:15:20,880
so in a way the cost of the of the

424
00:15:20,880 --> 00:15:23,120
encryption decryption is amortized over

425
00:15:23,120 --> 00:15:25,199
all the records that we've used to

426
00:15:25,199 --> 00:15:27,839
update the model

427
00:15:28,000 --> 00:15:28,880
okay

428
00:15:28,880 --> 00:15:31,279
so now i will tell you a little bit of

429
00:15:31,279 --> 00:15:33,680
the algorithmic changes that we made to

430
00:15:33,680 --> 00:15:35,120
the decision trees and matrix

431
00:15:35,120 --> 00:15:37,120
factorization

432
00:15:37,120 --> 00:15:39,279
so the decision trees

433
00:15:39,279 --> 00:15:41,519
usually would be stored in an array or

434
00:15:41,519 --> 00:15:42,800
basically from the root there is a

435
00:15:42,800 --> 00:15:45,440
pointers to the children and so on there

436
00:15:45,440 --> 00:15:47,360
are two things that we want to hide one

437
00:15:47,360 --> 00:15:49,759
is how we actually evaluated

438
00:15:49,759 --> 00:15:52,240
the comparison at the at each node so

439
00:15:52,240 --> 00:15:53,759
for that we can use

440
00:15:53,759 --> 00:15:56,480
our oblivious primitive

441
00:15:56,480 --> 00:15:59,600
and then the more complicated part is

442
00:15:59,600 --> 00:16:01,600
that we need now to hide which of the

443
00:16:01,600 --> 00:16:04,000
node we actually go and traverse

444
00:16:04,000 --> 00:16:06,000
so here we don't care about hiding which

445
00:16:06,000 --> 00:16:07,920
level of the tree we are because the

446
00:16:07,920 --> 00:16:09,600
height of the tree we declared as a

447
00:16:09,600 --> 00:16:12,240
public but we don't need to hide which

448
00:16:12,240 --> 00:16:15,279
of the node of the tree uh to

449
00:16:15,279 --> 00:16:16,079
uh

450
00:16:16,079 --> 00:16:18,000
we need to hide which node at the level

451
00:16:18,000 --> 00:16:20,079
we've accessed and this is exactly where

452
00:16:20,079 --> 00:16:21,279
we are gonna

453
00:16:21,279 --> 00:16:22,560
use our

454
00:16:22,560 --> 00:16:24,800
oblivious scanning technique the one

455
00:16:24,800 --> 00:16:28,479
that used vector registers

456
00:16:28,720 --> 00:16:30,560
so as you could see there is a random

457
00:16:30,560 --> 00:16:32,079
access that is happening and that is

458
00:16:32,079 --> 00:16:35,120
dependent on the condition evaluation

459
00:16:35,120 --> 00:16:38,160
so similarly in matrix factorization

460
00:16:38,160 --> 00:16:40,160
there is also uh there are also random

461
00:16:40,160 --> 00:16:42,800
accesses uh happening but they are a bit

462
00:16:42,800 --> 00:16:43,920
different

463
00:16:43,920 --> 00:16:45,360
in particular in the matrix

464
00:16:45,360 --> 00:16:46,959
factorization version that we used using

465
00:16:46,959 --> 00:16:48,720
gradient descent there are two data

466
00:16:48,720 --> 00:16:50,480
structures you and we

467
00:16:50,480 --> 00:16:52,560
and the way basically you're trying to i

468
00:16:52,560 --> 00:16:54,160
minimize your objective so you're

469
00:16:54,160 --> 00:16:56,720
iteratively updating you and v all the

470
00:16:56,720 --> 00:16:57,600
time

471
00:16:57,600 --> 00:16:59,680
and in order to update one or another

472
00:16:59,680 --> 00:17:02,399
you have to make accesses in the other

473
00:17:02,399 --> 00:17:03,759
data structure

474
00:17:03,759 --> 00:17:06,319
however these accesses depend on secret

475
00:17:06,319 --> 00:17:08,240
information

476
00:17:08,240 --> 00:17:09,839
uh and

477
00:17:09,839 --> 00:17:11,599
we can't use the scanning technique here

478
00:17:11,599 --> 00:17:13,439
because you and we are actually quite

479
00:17:13,439 --> 00:17:14,400
large

480
00:17:14,400 --> 00:17:16,720
so we had to do something different here

481
00:17:16,720 --> 00:17:19,679
and so what we proposed is to basically

482
00:17:19,679 --> 00:17:21,919
interleave these two data structures in

483
00:17:21,919 --> 00:17:24,640
some very special way such that all the

484
00:17:24,640 --> 00:17:26,400
information that you need in order to

485
00:17:26,400 --> 00:17:28,000
update your

486
00:17:28,000 --> 00:17:31,039
la your role in you is either

487
00:17:31,039 --> 00:17:32,480
above or below

488
00:17:32,480 --> 00:17:34,720
the record that needs to be updated

489
00:17:34,720 --> 00:17:37,200
so now this way we can do an update of

490
00:17:37,200 --> 00:17:39,600
both u and v by just performing a linear

491
00:17:39,600 --> 00:17:40,880
scan

492
00:17:40,880 --> 00:17:42,559
and

493
00:17:42,559 --> 00:17:44,400
we do it only once at the preprocessing

494
00:17:44,400 --> 00:17:45,919
phase and then there is multiple

495
00:17:45,919 --> 00:17:48,640
iterations so it's okay to basically uh

496
00:17:48,640 --> 00:17:51,360
place your data away um in order for

497
00:17:51,360 --> 00:17:53,039
them later to make deterministic

498
00:17:53,039 --> 00:17:55,760
accesses to it

499
00:17:56,240 --> 00:17:57,919
um so our

500
00:17:57,919 --> 00:18:01,280
we built our system uh we use the intel

501
00:18:01,280 --> 00:18:03,919
skylake processors which uh do have sgx

502
00:18:03,919 --> 00:18:04,880
on them

503
00:18:04,880 --> 00:18:07,520
uh so enclave memory for now is 94

504
00:18:07,520 --> 00:18:09,200
megabytes but that's probably gonna

505
00:18:09,200 --> 00:18:12,000
increase and as data sets uh we used

506
00:18:12,000 --> 00:18:13,840
some popular data sets from the ucr

507
00:18:13,840 --> 00:18:16,400
machine learning repository we binary

508
00:18:16,400 --> 00:18:19,360
encoded them in order to avoid the site

509
00:18:19,360 --> 00:18:21,200
channels that will be created by parsing

510
00:18:21,200 --> 00:18:22,960
csv files

511
00:18:22,960 --> 00:18:24,000
and then

512
00:18:24,000 --> 00:18:26,559
the way we encrypted data is in batches

513
00:18:26,559 --> 00:18:28,480
because some of these data sets that we

514
00:18:28,480 --> 00:18:30,400
considered were of course larger than

515
00:18:30,400 --> 00:18:32,480
the enclave memory so we couldn't just

516
00:18:32,480 --> 00:18:35,039
load all the memory all the data decrypt

517
00:18:35,039 --> 00:18:37,280
it and then access it the way we wanted

518
00:18:37,280 --> 00:18:39,760
so we split the data into batches

519
00:18:39,760 --> 00:18:41,760
encrypted them and we process them by

520
00:18:41,760 --> 00:18:44,160
reading a batch decrypting operating on

521
00:18:44,160 --> 00:18:47,039
it and so on

522
00:18:47,120 --> 00:18:49,120
okay so here are the

523
00:18:49,120 --> 00:18:51,200
the comparison with the baseline the

524
00:18:51,200 --> 00:18:54,559
baseline here is no encryption no sgx

525
00:18:54,559 --> 00:18:56,559
basically how you would run it

526
00:18:56,559 --> 00:18:58,400
and then the blue

527
00:18:58,400 --> 00:19:02,000
comparison is when you use sgx and this

528
00:19:02,000 --> 00:19:03,440
and the encryption

529
00:19:03,440 --> 00:19:05,120
so as you can see the overhead is

530
00:19:05,120 --> 00:19:06,559
actually quite small so for neural

531
00:19:06,559 --> 00:19:08,400
networks and svm it is only one and

532
00:19:08,400 --> 00:19:10,559
seven percent respectively

533
00:19:10,559 --> 00:19:13,520
but like k means as an outlier and why

534
00:19:13,520 --> 00:19:15,840
is that well because k-means does so

535
00:19:15,840 --> 00:19:18,320
little of computation that actually it

536
00:19:18,320 --> 00:19:21,120
can't amortize the cost of of the inc

537
00:19:21,120 --> 00:19:23,520
decryption that you've done while such

538
00:19:23,520 --> 00:19:24,400
for example

539
00:19:24,400 --> 00:19:26,640
um expensive computation like neural

540
00:19:26,640 --> 00:19:28,799
network completely amortizes the cost of

541
00:19:28,799 --> 00:19:32,000
the increasion that you are doing

542
00:19:32,000 --> 00:19:35,360
so then we added also our data oblivious

543
00:19:35,360 --> 00:19:36,720
protection

544
00:19:36,720 --> 00:19:39,039
and as you can see it really differs uh

545
00:19:39,039 --> 00:19:41,440
depending on how your algorithm behaves

546
00:19:41,440 --> 00:19:43,600
it can be three or eight percent for

547
00:19:43,600 --> 00:19:45,919
neural networks and svm and then for

548
00:19:45,919 --> 00:19:47,520
decision trees for example it really

549
00:19:47,520 --> 00:19:49,919
depends on how shallow or how

550
00:19:49,919 --> 00:19:52,080
deep your tree is for example some data

551
00:19:52,080 --> 00:19:55,039
sets we have a 60x overhead or eight x

552
00:19:55,039 --> 00:19:58,480
over here so it really depends

553
00:19:58,480 --> 00:20:00,799
okay so we've been really trying hard on

554
00:20:00,799 --> 00:20:02,960
making these things data oblivious so

555
00:20:02,960 --> 00:20:03,919
are we

556
00:20:03,919 --> 00:20:06,000
so we have pen and paper proofs for each

557
00:20:06,000 --> 00:20:07,600
of the algorithms where we basically

558
00:20:07,600 --> 00:20:09,840
show that the trays that they produce

559
00:20:09,840 --> 00:20:12,400
the input output trace that they produce

560
00:20:12,400 --> 00:20:14,960
can be completely reproduced by

561
00:20:14,960 --> 00:20:18,080
just knowing the public

562
00:20:18,080 --> 00:20:20,000
public information about your data sets

563
00:20:20,000 --> 00:20:22,480
such as input and output size

564
00:20:22,480 --> 00:20:24,720
how of course when coding that we could

565
00:20:24,720 --> 00:20:28,640
have made errors so um

566
00:20:28,640 --> 00:20:31,120
to validate this we collected traces at

567
00:20:31,120 --> 00:20:33,440
the cache line granularity using intel

568
00:20:33,440 --> 00:20:34,799
pin tool

569
00:20:34,799 --> 00:20:36,960
and so now what you're gonna see is two

570
00:20:36,960 --> 00:20:40,559
videos of the basically the code traces

571
00:20:40,559 --> 00:20:43,200
of traversing a tree before we apply our

572
00:20:43,200 --> 00:20:45,440
oblivious technique and

573
00:20:45,440 --> 00:20:48,440
afterwards

574
00:20:52,559 --> 00:20:54,559
okay so here what we have is basically

575
00:20:54,559 --> 00:20:57,039
two sets of uh inputs input a and input

576
00:20:57,039 --> 00:20:57,760
b

577
00:20:57,760 --> 00:21:00,159
and on the x axis we have time and y

578
00:21:00,159 --> 00:21:02,799
axis is their addresses and basically

579
00:21:02,799 --> 00:21:07,200
the blue points are whenever we access

580
00:21:07,679 --> 00:21:10,799
whenever we make an access

581
00:21:10,799 --> 00:21:14,240
um so they're quite interesting i guess

582
00:21:14,240 --> 00:21:17,280
so they keep going going okay so when

583
00:21:17,280 --> 00:21:19,600
looking at them i guess we can make

584
00:21:19,600 --> 00:21:21,520
several observations

585
00:21:21,520 --> 00:21:24,320
um so first for example we can think of

586
00:21:24,320 --> 00:21:27,200
um what do those things look like so we

587
00:21:27,200 --> 00:21:29,520
can start calling them things so for

588
00:21:29,520 --> 00:21:31,520
example if something below called ursa

589
00:21:31,520 --> 00:21:34,159
miners ours can be called cherubus miner

590
00:21:34,159 --> 00:21:35,919
because obviously it's more of a deer

591
00:21:35,919 --> 00:21:38,720
than below is of a bear

592
00:21:38,720 --> 00:21:41,200
but kind of more the point is that the

593
00:21:41,200 --> 00:21:42,960
the deers are running at a different

594
00:21:42,960 --> 00:21:46,240
pace on two different sequences so that

595
00:21:46,240 --> 00:21:48,480
is definitely not data oblivious and

596
00:21:48,480 --> 00:21:50,240
it's a clear

597
00:21:50,240 --> 00:21:52,000
indication that the traces are very

598
00:21:52,000 --> 00:21:53,440
different

599
00:21:53,440 --> 00:21:55,600
okay so now then

600
00:21:55,600 --> 00:21:56,320
we

601
00:21:56,320 --> 00:21:58,720
this is a trace basically same input a's

602
00:21:58,720 --> 00:22:01,440
input b but now collecting traces from

603
00:22:01,440 --> 00:22:05,440
our oblivious execution of the code

604
00:22:05,440 --> 00:22:06,720
um so

605
00:22:06,720 --> 00:22:07,919
of course you're not going to believe me

606
00:22:07,919 --> 00:22:10,559
that they're the same but but they are

607
00:22:10,559 --> 00:22:12,400
also they are very boring as sometimes

608
00:22:12,400 --> 00:22:14,320
the case with security but they are i

609
00:22:14,320 --> 00:22:16,400
believe that oblivious

610
00:22:16,400 --> 00:22:18,640
okay if we didn't just look at them and

611
00:22:18,640 --> 00:22:21,440
like verified we did write a program to

612
00:22:21,440 --> 00:22:22,400
do that

613
00:22:22,400 --> 00:22:25,760
okay so uh in conclusion

614
00:22:25,760 --> 00:22:26,640
we

615
00:22:26,640 --> 00:22:29,280
export the design space for multiplied

616
00:22:29,280 --> 00:22:31,280
machine learning in particular we

617
00:22:31,280 --> 00:22:33,039
propose this new trust model or

618
00:22:33,039 --> 00:22:34,720
considered a new trust model using

619
00:22:34,720 --> 00:22:36,880
trusted processors as you could see the

620
00:22:36,880 --> 00:22:39,280
performance when you use just as gx and

621
00:22:39,280 --> 00:22:42,960
aes encryption is very small it's 20

622
00:22:42,960 --> 00:22:45,440
average overhead which is significantly

623
00:22:45,440 --> 00:22:48,080
faster than the cryptographic solutions

624
00:22:48,080 --> 00:22:49,840
and finally if you want to harden the

625
00:22:49,840 --> 00:22:52,159
code even further we proposed uh

626
00:22:52,159 --> 00:22:53,600
memories

627
00:22:53,600 --> 00:22:57,039
protection against memory side channels

628
00:22:57,039 --> 00:22:59,120
and i'm four minutes faster i have

629
00:22:59,120 --> 00:23:01,919
amazing matrix factorization slides if

630
00:23:01,919 --> 00:23:03,840
you'd like to learn more

631
00:23:03,840 --> 00:23:07,120
but i think i'll finish here thank you

632
00:23:07,120 --> 00:23:07,910
[Applause]

633
00:23:07,910 --> 00:23:09,150
[Music]

634
00:23:09,150 --> 00:23:15,579
[Applause]

635
00:23:15,919 --> 00:23:17,679
and we have plenty of time for questions

636
00:23:17,679 --> 00:23:22,520
so please line up at the microphone

637
00:23:24,320 --> 00:23:26,799
seriously

638
00:23:29,200 --> 00:23:31,360
all right while you do that since all of

639
00:23:31,360 --> 00:23:33,760
you certainly have one question prepared

640
00:23:33,760 --> 00:23:36,000
let me ask you one question so you

641
00:23:36,000 --> 00:23:38,320
mentioned that the sgx enclave memory is

642
00:23:38,320 --> 00:23:41,600
currently limited to 94 megabytes did

643
00:23:41,600 --> 00:23:43,840
you run into that limit at all with the

644
00:23:43,840 --> 00:23:46,000
models that you were looking into and

645
00:23:46,000 --> 00:23:47,600
you know how would you suggest to go

646
00:23:47,600 --> 00:23:49,200
beyond that

647
00:23:49,200 --> 00:23:50,960
um sorry so all the data sets that we

648
00:23:50,960 --> 00:23:52,960
considered they were larger than that so

649
00:23:52,960 --> 00:23:54,720
we basically split them in batches so we

650
00:23:54,720 --> 00:23:56,880
process them in batches but most of the

651
00:23:56,880 --> 00:23:59,600
models did fit in into that

652
00:23:59,600 --> 00:24:01,760
data into that size so we didn't

653
00:24:01,760 --> 00:24:05,520
consider um we didn't run into it but of

654
00:24:05,520 --> 00:24:07,440
course once you yeah i guess you would

655
00:24:07,440 --> 00:24:09,200
have to split the model somehow and

656
00:24:09,200 --> 00:24:11,520
encrypt and store it outside and then

657
00:24:11,520 --> 00:24:14,559
have to load it uh yeah we had

658
00:24:14,559 --> 00:24:16,559
some problems this came in but we

659
00:24:16,559 --> 00:24:18,640
avoided it we basically changed the

660
00:24:18,640 --> 00:24:20,400
loops in a way that it doesn't have to

661
00:24:20,400 --> 00:24:21,760
do that yeah

662
00:24:21,760 --> 00:24:24,080
thank you

663
00:24:24,240 --> 00:24:26,080
do you have a sense for how much faster

664
00:24:26,080 --> 00:24:28,080
you are than just a generic or ram

665
00:24:28,080 --> 00:24:29,279
construction

666
00:24:29,279 --> 00:24:31,200
sorry could you repeat that do you have

667
00:24:31,200 --> 00:24:33,520
a sense for how much how much better

668
00:24:33,520 --> 00:24:35,919
this works than just using a generic

669
00:24:35,919 --> 00:24:38,320
oblivious ram construction

670
00:24:38,320 --> 00:24:39,919
like would that be orders of magnitude

671
00:24:39,919 --> 00:24:42,640
slower or

672
00:24:42,720 --> 00:24:44,400
um

673
00:24:44,400 --> 00:24:46,000
so

674
00:24:46,000 --> 00:24:48,240
one thing is that it's hard to compare

675
00:24:48,240 --> 00:24:50,159
is that oblivious ram requires large

676
00:24:50,159 --> 00:24:52,640
private memory right so we the only way

677
00:24:52,640 --> 00:24:54,960
we could have simulated i believe is uh

678
00:24:54,960 --> 00:24:57,039
ram is by having this private memory

679
00:24:57,039 --> 00:24:59,039
right and one way of simulating it will

680
00:24:59,039 --> 00:25:01,440
have to scan it all and over again in

681
00:25:01,440 --> 00:25:04,320
order to simulate it so in a way we we

682
00:25:04,320 --> 00:25:06,240
wouldn't be able to but yeah i would

683
00:25:06,240 --> 00:25:07,440
guess it is

684
00:25:07,440 --> 00:25:09,440
a couple of orders of magnitude but

685
00:25:09,440 --> 00:25:11,840
again it's it's it's not very fair right

686
00:25:11,840 --> 00:25:14,240
because we knew what we are dealing with

687
00:25:14,240 --> 00:25:16,320
and for some of the things it would be

688
00:25:16,320 --> 00:25:18,080
very bad for matrix factorization for

689
00:25:18,080 --> 00:25:19,360
example that i can tell you for sure

690
00:25:19,360 --> 00:25:20,880
it's going to be orders of magnitude

691
00:25:20,880 --> 00:25:22,640
just because i believe sram is not smart

692
00:25:22,640 --> 00:25:24,000
enough to figure out that you can do

693
00:25:24,000 --> 00:25:26,840
many optimizations

694
00:25:26,840 --> 00:25:29,679
there thanks thank you

695
00:25:29,679 --> 00:25:31,360
yeah i guess i have a similar question

696
00:25:31,360 --> 00:25:32,960
uh you also couldn't tell where the

697
00:25:32,960 --> 00:25:35,279
break-off point would be like how large

698
00:25:35,279 --> 00:25:37,120
would the memory need to be so that

699
00:25:37,120 --> 00:25:39,840
oblivious ram would be worthwhile using

700
00:25:39,840 --> 00:25:41,679
yeah so i'm gonna quote the papers that

701
00:25:41,679 --> 00:25:43,360
appeared in usenext last year called

702
00:25:43,360 --> 00:25:45,440
raccoon so i think one of the last

703
00:25:45,440 --> 00:25:48,080
figures is basically estimating um how

704
00:25:48,080 --> 00:25:50,480
many times you have to access memory and

705
00:25:50,480 --> 00:25:52,880
for watch sizes of n

706
00:25:52,880 --> 00:25:55,039
and i think it was around

707
00:25:55,039 --> 00:25:57,520
100 thousand elements but you have to

708
00:25:57,520 --> 00:25:59,360
you have to double check yeah it was

709
00:25:59,360 --> 00:26:01,919
yeah something around that

710
00:26:01,919 --> 00:26:04,240
hey hey olivia

711
00:26:04,240 --> 00:26:04,960
so

712
00:26:04,960 --> 00:26:06,640
yeah you're saying that you you don't

713
00:26:06,640 --> 00:26:09,279
use ram like because it has logarithmic

714
00:26:09,279 --> 00:26:10,559
client memory

715
00:26:10,559 --> 00:26:12,480
but you know you we can use this trick

716
00:26:12,480 --> 00:26:14,000
where you can outsource the client

717
00:26:14,000 --> 00:26:16,320
memory and access it while keeping the

718
00:26:16,320 --> 00:26:18,880
constant client storage so you can

719
00:26:18,880 --> 00:26:20,640
just

720
00:26:20,640 --> 00:26:23,520
do like multiple rounds while keeping a

721
00:26:23,520 --> 00:26:25,200
constant client storage that will be in

722
00:26:25,200 --> 00:26:26,480
your enclave

723
00:26:26,480 --> 00:26:29,039
have you thought about doing this and

724
00:26:29,039 --> 00:26:32,080
using for example any olam scheme for

725
00:26:32,080 --> 00:26:34,320
example for your area access

726
00:26:34,320 --> 00:26:37,120
uh we thought about it but again

727
00:26:37,120 --> 00:26:39,120
okay because i've worked on number

728
00:26:39,120 --> 00:26:41,360
strength so i kind of expected a head

729
00:26:41,360 --> 00:26:43,120
intuition that it is going to be high it

730
00:26:43,120 --> 00:26:45,520
would be nice to see it

731
00:26:45,520 --> 00:26:47,600
but i really

732
00:26:47,600 --> 00:26:49,600
i doubt it's going to be much better

733
00:26:49,600 --> 00:26:52,640
than what we are doing or even better um

734
00:26:52,640 --> 00:26:54,320
it yeah it's it's an interesting

735
00:26:54,320 --> 00:26:56,000
question um

736
00:26:56,000 --> 00:26:58,799
but the trees that we had i they're

737
00:26:58,799 --> 00:27:01,679
quite small i think the largest

738
00:27:01,679 --> 00:27:03,440
level okay the levels were high but i

739
00:27:03,440 --> 00:27:05,440
think we we didn't have more than i

740
00:27:05,440 --> 00:27:07,679
think 60 000 nodes at every point of

741
00:27:07,679 --> 00:27:09,600
time and as you saw we use all these

742
00:27:09,600 --> 00:27:11,760
techniques for optimization so it's it's

743
00:27:11,760 --> 00:27:13,679
quite highly optimized and my main

744
00:27:13,679 --> 00:27:15,360
reference is the requiem paper which

745
00:27:15,360 --> 00:27:17,919
which also suggested the same uh finding

746
00:27:17,919 --> 00:27:20,240
but it is work in progress to come up

747
00:27:20,240 --> 00:27:22,000
with a oblivious ram that would work

748
00:27:22,000 --> 00:27:24,399
this way

749
00:27:25,200 --> 00:27:28,159
all right any more questions

750
00:27:28,159 --> 00:27:31,900
then let's thank the speaker

751
00:27:31,900 --> 00:27:35,799
[Applause]

752
00:27:38,159 --> 00:27:40,240
you

