1
00:00:08,559 --> 00:00:10,880
hello everyone welcome to my talk my

2
00:00:10,880 --> 00:00:13,440
name is bianchin i am a phd candidate

3
00:00:13,440 --> 00:00:15,839
from georgia university today i am going

4
00:00:15,839 --> 00:00:18,560
to introduce our paper net universe a

5
00:00:18,560 --> 00:00:21,199
holistic and pragmatic metrics driven

6
00:00:21,199 --> 00:00:23,680
platform for your advising fathers this

7
00:00:23,680 --> 00:00:25,439
is the joint work with researchers from

8
00:00:25,439 --> 00:00:28,080
georgia tech ibm research university of

9
00:00:28,080 --> 00:00:30,960
minnesota and penn state university

10
00:00:30,960 --> 00:00:33,280
first as we all know that farming is a

11
00:00:33,280 --> 00:00:35,280
dynamic vulnerability detection

12
00:00:35,280 --> 00:00:37,760
technique by iteratively and randomly

13
00:00:37,760 --> 00:00:41,040
feeding inputs to the target program in

14
00:00:41,040 --> 00:00:44,160
recent years a plethora of fuzzing works

15
00:00:44,160 --> 00:00:46,320
have emerged in both industry and

16
00:00:46,320 --> 00:00:48,879
academia for example there are over

17
00:00:48,879 --> 00:00:50,960
three thousand related

18
00:00:50,960 --> 00:00:54,399
repositories in github in academic field

19
00:00:54,399 --> 00:00:56,559
for example we found that there are more

20
00:00:56,559 --> 00:01:00,480
than 200 related papers in dbrp

21
00:01:00,480 --> 00:01:03,519
since 2010

22
00:01:03,600 --> 00:01:05,760
in this background there are still

23
00:01:05,760 --> 00:01:07,760
several open questions that need to be

24
00:01:07,760 --> 00:01:08,720
addressed

25
00:01:08,720 --> 00:01:11,520
how do these fathers perform in practice

26
00:01:11,520 --> 00:01:13,680
how to compare different fathers under a

27
00:01:13,680 --> 00:01:15,200
fair and comprehensive set of

28
00:01:15,200 --> 00:01:16,880
performance metrics

29
00:01:16,880 --> 00:01:19,200
and which following primitives or

30
00:01:19,200 --> 00:01:21,600
techniques are promising and should be

31
00:01:21,600 --> 00:01:24,240
promoted

32
00:01:24,320 --> 00:01:27,200
however the previous works cannot answer

33
00:01:27,200 --> 00:01:29,200
these questions for the following

34
00:01:29,200 --> 00:01:32,320
reasons first many existing works do not

35
00:01:32,320 --> 00:01:34,720
conduct appropriate and sufficient

36
00:01:34,720 --> 00:01:36,640
experiments to provide trustworthy

37
00:01:36,640 --> 00:01:37,840
results

38
00:01:37,840 --> 00:01:40,479
and there exists randomness in fuzzy

39
00:01:40,479 --> 00:01:43,119
experiment we should conduct experiments

40
00:01:43,119 --> 00:01:45,840
with enough repetitions and provide

41
00:01:45,840 --> 00:01:48,399
statistical test results

42
00:01:48,399 --> 00:01:50,560
another issue is the inconsistency of

43
00:01:50,560 --> 00:01:52,399
environments

44
00:01:52,399 --> 00:01:54,560
you may perform better than another

45
00:01:54,560 --> 00:01:56,799
father just because you used a better

46
00:01:56,799 --> 00:01:58,079
cpu

47
00:01:58,079 --> 00:02:00,479
so it's unfair to directly compared

48
00:02:00,479 --> 00:02:03,040
results from the paper instead of

49
00:02:03,040 --> 00:02:06,079
rerunning the experiment

50
00:02:06,079 --> 00:02:08,160
one reason of this phenomenon is that

51
00:02:08,160 --> 00:02:10,800
some fighters may have the usability

52
00:02:10,800 --> 00:02:13,200
issues or not be in

53
00:02:13,200 --> 00:02:14,800
open source

54
00:02:14,800 --> 00:02:19,440
so the researchers cannot reproduce them

55
00:02:19,440 --> 00:02:20,480
second

56
00:02:20,480 --> 00:02:22,879
the evaluations of the existing factors

57
00:02:22,879 --> 00:02:25,040
are often biased due to the lack of

58
00:02:25,040 --> 00:02:27,840
uniform benchmarks for example the

59
00:02:27,840 --> 00:02:30,319
choices of the real world benchmark on

60
00:02:30,319 --> 00:02:34,080
the test usually various rapidly

61
00:02:34,080 --> 00:02:36,319
third the existing matrix may not be

62
00:02:36,319 --> 00:02:38,000
suitable nor comprehensive for

63
00:02:38,000 --> 00:02:40,400
evaluating fathers for example many

64
00:02:40,400 --> 00:02:42,400
funding works do not consider evaluating

65
00:02:42,400 --> 00:02:45,120
the overhead of a father such as how

66
00:02:45,120 --> 00:02:46,720
much computing

67
00:02:46,720 --> 00:02:47,840
resources

68
00:02:47,840 --> 00:02:52,640
a father used during the funding process

69
00:02:53,680 --> 00:02:55,920
so to compare our fathers in a fair

70
00:02:55,920 --> 00:02:58,239
manner we need to conduct comprehensive

71
00:02:58,239 --> 00:03:02,400
uriations unfortunately this is not easy

72
00:03:02,400 --> 00:03:04,400
and there are at least three main

73
00:03:04,400 --> 00:03:06,959
challenges usability issues of using

74
00:03:06,959 --> 00:03:09,680
fathers lack of pragmatic real-world

75
00:03:09,680 --> 00:03:11,920
benchmarks and lack of proper and

76
00:03:11,920 --> 00:03:14,800
comprehensive performance matrix

77
00:03:14,800 --> 00:03:16,800
to solve these challenges and provide

78
00:03:16,800 --> 00:03:19,040
the comprehensive evaluations we

79
00:03:19,040 --> 00:03:22,080
designed and implemented universe a

80
00:03:22,080 --> 00:03:25,120
holistic and pragmatic magic experiment

81
00:03:25,120 --> 00:03:27,680
platform for united fathers this figure

82
00:03:27,680 --> 00:03:29,760
shows the overview of the universe

83
00:03:29,760 --> 00:03:32,799
platform in specific invoice consists of

84
00:03:32,799 --> 00:03:35,440
three main components a set of usable

85
00:03:35,440 --> 00:03:36,400
files

86
00:03:36,400 --> 00:03:39,200
a set of pragmatic benchmarks

87
00:03:39,200 --> 00:03:42,799
and six categories of performance matrix

88
00:03:42,799 --> 00:03:46,159
next i will dive into the

89
00:03:46,159 --> 00:03:49,120
details of each part

90
00:03:49,120 --> 00:03:51,840
to provide useful fathers we conducted

91
00:03:51,840 --> 00:03:53,920
large scale tests on the usability of

92
00:03:53,920 --> 00:03:55,599
many existing partners

93
00:03:55,599 --> 00:03:57,840
for each photo we manually built and run

94
00:03:57,840 --> 00:03:59,920
the several following experiments to

95
00:03:59,920 --> 00:04:02,560
test whether it has abnormal behavior

96
00:04:02,560 --> 00:04:05,120
during this process we found many flaws

97
00:04:05,120 --> 00:04:07,040
including more than

98
00:04:07,040 --> 00:04:10,159
15 various ones in the implication code

99
00:04:10,159 --> 00:04:12,720
of some fathers and the details can be

100
00:04:12,720 --> 00:04:15,680
found in our open source platform

101
00:04:15,680 --> 00:04:17,440
we have reported the flaws to the

102
00:04:17,440 --> 00:04:20,000
developers and fixed some of them

103
00:04:20,000 --> 00:04:22,320
up to date unified's platform has

104
00:04:22,320 --> 00:04:26,160
incorporated more than 35 useful files

105
00:04:26,160 --> 00:04:28,400
for each father union fast platform

106
00:04:28,400 --> 00:04:31,360
provides a docker file for easily

107
00:04:31,360 --> 00:04:33,840
installing and using them

108
00:04:33,840 --> 00:04:36,639
in addition to improve the usability our

109
00:04:36,639 --> 00:04:38,720
platform also provides detailed and

110
00:04:38,720 --> 00:04:39,680
clear

111
00:04:39,680 --> 00:04:40,880
documents

112
00:04:40,880 --> 00:04:43,280
therefore the users can use and test

113
00:04:43,280 --> 00:04:44,880
these files

114
00:04:44,880 --> 00:04:47,680
conveniently

115
00:04:47,680 --> 00:04:49,759
the advanced platform also provides a

116
00:04:49,759 --> 00:04:52,400
pragmatic benchmark suit which consists

117
00:04:52,400 --> 00:04:54,160
of 20

118
00:04:54,160 --> 00:04:56,400
real-world benchmark progress

119
00:04:56,400 --> 00:04:58,960
the details are shown in the left

120
00:04:58,960 --> 00:05:01,759
these programs contain six functionality

121
00:05:01,759 --> 00:05:04,639
types and more than 12 vulnerability

122
00:05:04,639 --> 00:05:07,840
types which are has good diversity

123
00:05:07,840 --> 00:05:10,080
it needs to be noted that we do not

124
00:05:10,080 --> 00:05:12,479
change the code of this progress in

125
00:05:12,479 --> 00:05:14,240
order to preserve the raw features of

126
00:05:14,240 --> 00:05:16,800
this real world progress

127
00:05:16,800 --> 00:05:19,440
instead we focused on providing the

128
00:05:19,440 --> 00:05:22,400
convenient offline result analysis tools

129
00:05:22,400 --> 00:05:24,639
such as factory age

130
00:05:24,639 --> 00:05:25,919
the severity

131
00:05:25,919 --> 00:05:27,280
analysis

132
00:05:27,280 --> 00:05:31,919
for fund box and cvg matching

133
00:05:32,000 --> 00:05:34,000
in order to solve the issues of lacking

134
00:05:34,000 --> 00:05:35,919
comprehensive performance magics for

135
00:05:35,919 --> 00:05:38,479
using fathers we summarized and proposed

136
00:05:38,479 --> 00:05:41,120
six categories of performance metrics

137
00:05:41,120 --> 00:05:44,160
including a quantity of unique bugs

138
00:05:44,160 --> 00:05:47,600
quality of the box speed stability

139
00:05:47,600 --> 00:05:50,479
coverage and overhead each category

140
00:05:50,479 --> 00:05:52,639
represents a property of a father's

141
00:05:52,639 --> 00:05:54,800
performance and each property can be

142
00:05:54,800 --> 00:05:57,440
evaluated by many concrete magics

143
00:05:57,440 --> 00:06:00,000
so this is a scalable design and you may

144
00:06:00,000 --> 00:06:03,440
propose better concrete magics

145
00:06:03,440 --> 00:06:06,080
next part is our evaluations

146
00:06:06,080 --> 00:06:08,400
leveraging the universe platform we

147
00:06:08,400 --> 00:06:10,880
conducted large scale evaluations on

148
00:06:10,880 --> 00:06:13,759
eight state-of-the-art fathers including

149
00:06:13,759 --> 00:06:18,800
sl ffast angora home fast mobt qsim team

150
00:06:18,800 --> 00:06:21,680
tfast and user 64.

151
00:06:21,680 --> 00:06:25,280
we conducted more than 200 certain pqr

152
00:06:25,280 --> 00:06:26,800
experiments and

153
00:06:26,800 --> 00:06:28,800
evaluates the performance of them based

154
00:06:28,800 --> 00:06:31,120
on the proposed six categories of

155
00:06:31,120 --> 00:06:33,199
performance matrix

156
00:06:33,199 --> 00:06:35,759
due to the time limitation i hear i only

157
00:06:35,759 --> 00:06:37,360
present the summary of interesting

158
00:06:37,360 --> 00:06:38,720
findings

159
00:06:38,720 --> 00:06:40,880
the first interesting finding is that no

160
00:06:40,880 --> 00:06:43,520
father outperformed the others among all

161
00:06:43,520 --> 00:06:44,400
the

162
00:06:44,400 --> 00:06:46,720
benchmark programs which reflect that

163
00:06:46,720 --> 00:06:49,680
fathers may have preference over some

164
00:06:49,680 --> 00:06:52,319
specific progress

165
00:06:52,319 --> 00:06:54,479
this worksport shows the number of found

166
00:06:54,479 --> 00:06:57,199
unique bugs on the 20

167
00:06:57,199 --> 00:06:59,360
benchmark programs each figure

168
00:06:59,360 --> 00:07:02,080
represents the results on one benchmark

169
00:07:02,080 --> 00:07:05,120
program and different color represents

170
00:07:05,120 --> 00:07:07,360
different fathers

171
00:07:07,360 --> 00:07:09,919
on the whole we can observe that node's

172
00:07:09,919 --> 00:07:11,199
fathers

173
00:07:11,199 --> 00:07:14,639
outperformed others on all time

174
00:07:14,639 --> 00:07:17,199
take an example angora performed the

175
00:07:17,199 --> 00:07:19,039
best on es72

176
00:07:19,039 --> 00:07:22,240
however it did not offer phone to

177
00:07:22,240 --> 00:07:24,639
kill them in tcp dump

178
00:07:24,639 --> 00:07:27,599
this observation that father may have a

179
00:07:27,599 --> 00:07:29,680
preference on different target programs

180
00:07:29,680 --> 00:07:32,560
is interesting and how to interpret this

181
00:07:32,560 --> 00:07:34,560
phenomenon use more research in the

182
00:07:34,560 --> 00:07:36,560
future

183
00:07:36,560 --> 00:07:38,479
the second interesting fact is that the

184
00:07:38,479 --> 00:07:40,880
static benchmark progress may not be

185
00:07:40,880 --> 00:07:43,039
able to reflect a father's performance

186
00:07:43,039 --> 00:07:46,720
on the real world bank programs

187
00:07:46,720 --> 00:07:49,280
found below figure we have observed that

188
00:07:49,280 --> 00:07:53,120
tfr and user 64 have relative advantage

189
00:07:53,120 --> 00:07:55,199
on lava m landmark

190
00:07:55,199 --> 00:07:57,919
however this is inconsistent to their

191
00:07:57,919 --> 00:08:00,400
performance on real world benchmark

192
00:08:00,400 --> 00:08:04,639
programs as about figure shows

193
00:08:04,639 --> 00:08:07,120
the third interesting finding is that a

194
00:08:07,120 --> 00:08:10,840
single magic may lead to unilateral

195
00:08:10,840 --> 00:08:13,919
conclusions taking j hat as an example

196
00:08:13,919 --> 00:08:16,639
kusim out performed all other fathers in

197
00:08:16,639 --> 00:08:19,680
the number of unique box magic however

198
00:08:19,680 --> 00:08:22,160
kusim did not outperform angora in

199
00:08:22,160 --> 00:08:24,000
non-coverage magic

200
00:08:24,000 --> 00:08:26,879
therefore it's recommended to use

201
00:08:26,879 --> 00:08:29,360
multiple performance metrics to reduce

202
00:08:29,360 --> 00:08:31,919
the bias

203
00:08:32,000 --> 00:08:34,640
during the large scale experiments we

204
00:08:34,640 --> 00:08:36,958
also found that many factors can affect

205
00:08:36,958 --> 00:08:39,440
the funding evaluation results than we

206
00:08:39,440 --> 00:08:41,679
initially thought

207
00:08:41,679 --> 00:08:44,080
one factor is the instrumentation method

208
00:08:44,080 --> 00:08:46,240
as we all know father may use different

209
00:08:46,240 --> 00:08:48,880
instrumentation method thus the same

210
00:08:48,880 --> 00:08:51,120
tested benchmark program are compiled

211
00:08:51,120 --> 00:08:53,120
into different manners in our

212
00:08:53,120 --> 00:08:55,360
experiments we found that angora cannot

213
00:08:55,360 --> 00:08:57,440
run some bugs on the program inverted

214
00:08:57,440 --> 00:09:01,040
cap due to its instrumentation method so

215
00:09:01,040 --> 00:09:04,480
if we overlook this factor we may get a

216
00:09:04,480 --> 00:09:06,640
wrong judgment on its capability of any

217
00:09:06,640 --> 00:09:09,360
box

218
00:09:09,360 --> 00:09:12,080
to reduce this bias we can we recommend

219
00:09:12,080 --> 00:09:15,120
using cross-validation

220
00:09:15,120 --> 00:09:16,320
that is

221
00:09:16,320 --> 00:09:18,959
when analyzing the crash samples you can

222
00:09:18,959 --> 00:09:21,760
re-execute crash tables with different

223
00:09:21,760 --> 00:09:23,760
compiled batteries to check whether

224
00:09:23,760 --> 00:09:26,080
these crash samples can be reproduced on

225
00:09:26,080 --> 00:09:28,480
all the batteries

226
00:09:28,480 --> 00:09:30,320
another factor is a different crash

227
00:09:30,320 --> 00:09:32,800
analysis tools when validating the bug

228
00:09:32,800 --> 00:09:35,040
triggered by the quest samples we found

229
00:09:35,040 --> 00:09:38,399
that using different analysis tools may

230
00:09:38,399 --> 00:09:40,720
lead to different results

231
00:09:40,720 --> 00:09:42,959
this table presents the number of unique

232
00:09:42,959 --> 00:09:46,080
bugs validated by different tools

233
00:09:46,080 --> 00:09:48,959
only about 60 of crash samples are

234
00:09:48,959 --> 00:09:51,200
validated by both address and tesla and

235
00:09:51,200 --> 00:09:53,839
gdb take another example

236
00:09:53,839 --> 00:09:55,760
the right figure shows the number of

237
00:09:55,760 --> 00:09:58,480
unique bugs discovered on ffmpeg with

238
00:09:58,480 --> 00:10:01,200
gdb and adjustment header and we found

239
00:10:01,200 --> 00:10:04,240
that when using adjacent sender to

240
00:10:04,240 --> 00:10:06,160
validate the crashes

241
00:10:06,160 --> 00:10:08,399
the result is that only home files can

242
00:10:08,399 --> 00:10:11,760
discover bugs however when using gdb

243
00:10:11,760 --> 00:10:15,360
other files such as avl ffs moped can

244
00:10:15,360 --> 00:10:18,720
also discover bugs

245
00:10:18,720 --> 00:10:20,959
therefore we recommend to use multiple

246
00:10:20,959 --> 00:10:25,518
analysis tools to mitigate this biases

247
00:10:25,839 --> 00:10:28,720
finally let me summarize our paper in

248
00:10:28,720 --> 00:10:31,839
this paper we proposed an implemented

249
00:10:31,839 --> 00:10:34,399
unified a holistic and pragmatic

250
00:10:34,399 --> 00:10:36,560
investor's driven platform for inviting

251
00:10:36,560 --> 00:10:38,880
fathers in a comprehensive and

252
00:10:38,880 --> 00:10:40,240
fair manner

253
00:10:40,240 --> 00:10:42,720
newfound has incorporated

254
00:10:42,720 --> 00:10:45,680
35 useful fathers 20 real world

255
00:10:45,680 --> 00:10:48,320
benchmark progress and six categories of

256
00:10:48,320 --> 00:10:50,240
performance magics

257
00:10:50,240 --> 00:10:52,959
we conducted extensive evaluations on

258
00:10:52,959 --> 00:10:55,519
eight state-of-the-art fathers and got

259
00:10:55,519 --> 00:10:57,519
many interesting findings

260
00:10:57,519 --> 00:10:59,200
we have open source really fast to

261
00:10:59,200 --> 00:11:01,760
facilitate the future funding research

262
00:11:01,760 --> 00:11:05,120
and welcome the community contributions

263
00:11:05,120 --> 00:11:09,959
that's all thank you any questions

264
00:11:16,000 --> 00:11:18,079
you

