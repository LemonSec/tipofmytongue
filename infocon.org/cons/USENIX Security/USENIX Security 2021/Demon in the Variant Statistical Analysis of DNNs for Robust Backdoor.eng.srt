1
00:00:09,040 --> 00:00:11,759
hi i'm jitong from chinese university of

2
00:00:11,759 --> 00:00:14,400
hong kong i'm honored to introduce one

3
00:00:14,400 --> 00:00:16,400
of our work about the bachelor attack of

4
00:00:16,400 --> 00:00:17,920
the neural network

5
00:00:17,920 --> 00:00:20,240
general in the variant statistical

6
00:00:20,240 --> 00:00:22,400
analysis of dns

7
00:00:22,400 --> 00:00:24,240
for robust factor contamination

8
00:00:24,240 --> 00:00:25,359
detection

9
00:00:25,359 --> 00:00:27,359
this is a collaboration research between

10
00:00:27,359 --> 00:00:29,760
the chinese university of hong kong and

11
00:00:29,760 --> 00:00:33,039
indiana university

12
00:00:33,040 --> 00:00:35,120
first let's briefly review what is the

13
00:00:35,120 --> 00:00:36,160
backdoor

14
00:00:36,160 --> 00:00:37,920
here is a neural network that was

15
00:00:37,920 --> 00:00:40,800
trained to recognize the human entity

16
00:00:40,800 --> 00:00:42,719
and the children inside

17
00:00:42,719 --> 00:00:45,039
in normal cases this spectral infected

18
00:00:45,039 --> 00:00:47,440
neural network performs well for those

19
00:00:47,440 --> 00:00:48,879
normal inputs

20
00:00:48,879 --> 00:00:51,280
but in those trigger cases this neural

21
00:00:51,280 --> 00:00:54,320
network will be misguided by the trigger

22
00:00:54,320 --> 00:00:56,640
for instance there may be a backbone and

23
00:00:56,640 --> 00:00:58,879
bring on trump's photo carries a trump

24
00:00:58,879 --> 00:01:03,280
logo it will be misrecognized as brother

25
00:01:03,440 --> 00:01:05,840
in this spectral instance

26
00:01:05,840 --> 00:01:07,840
the logo is the trigger trump with the

27
00:01:07,840 --> 00:01:10,880
source and the button is the target

28
00:01:10,880 --> 00:01:12,720
winter trigger shows up all images of

29
00:01:12,720 --> 00:01:14,720
the source class

30
00:01:14,720 --> 00:01:17,040
the combined images will be

31
00:01:17,040 --> 00:01:20,880
recognized as belong to the target class

32
00:01:20,880 --> 00:01:22,640
to inject the spectral into the neural

33
00:01:22,640 --> 00:01:24,960
network adversaries can pollute the

34
00:01:24,960 --> 00:01:26,479
chain dataset

35
00:01:26,479 --> 00:01:28,479
this data contamination check can be as

36
00:01:28,479 --> 00:01:30,960
simple as injecting some alcohol

37
00:01:30,960 --> 00:01:34,479
transfer into violence class

38
00:01:34,479 --> 00:01:36,799
to understand the bacterial attacks we

39
00:01:36,799 --> 00:01:39,360
investigate responsible representations

40
00:01:39,360 --> 00:01:42,880
of inputs produced by the neural network

41
00:01:42,880 --> 00:01:45,040
the classical neural network for imaging

42
00:01:45,040 --> 00:01:47,200
classification tasks can be roughly

43
00:01:47,200 --> 00:01:49,520
split into two parts the fusion learning

44
00:01:49,520 --> 00:01:51,759
part and the classification problem

45
00:01:51,759 --> 00:01:54,720
the reputations are the articles of the

46
00:01:54,720 --> 00:01:57,679
future learning part

47
00:01:58,479 --> 00:02:00,880
from reputations perspective the effects

48
00:02:00,880 --> 00:02:02,960
of the trigger can be clearly go

49
00:02:02,960 --> 00:02:04,399
preserved

50
00:02:04,399 --> 00:02:06,159
here are two figures showing the

51
00:02:06,159 --> 00:02:08,318
representations project on their photo

52
00:02:08,318 --> 00:02:10,560
two principle components

53
00:02:10,560 --> 00:02:12,560
the left figure shows representations

54
00:02:12,560 --> 00:02:15,200
produced by a benign neural network

55
00:02:15,200 --> 00:02:17,040
the reputations of classes are

56
00:02:17,040 --> 00:02:19,520
distinguishable no matter what the

57
00:02:19,520 --> 00:02:20,959
trigger shows up

58
00:02:20,959 --> 00:02:23,239
and the treatment will not introduce the

59
00:02:23,239 --> 00:02:25,200
misclarification

60
00:02:25,200 --> 00:02:26,720
one figure shoots with reputations

61
00:02:26,720 --> 00:02:28,959
produced by a neural network read

62
00:02:28,959 --> 00:02:30,160
background

63
00:02:30,160 --> 00:02:32,239
representations of trigger terror inputs

64
00:02:32,239 --> 00:02:34,400
are far away from the reputation of

65
00:02:34,400 --> 00:02:36,879
normal improvement

66
00:02:36,879 --> 00:02:38,480
and the relationships of the trigger

67
00:02:38,480 --> 00:02:40,879
count inputs stay together even the

68
00:02:40,879 --> 00:02:43,519
inputs come from different classes

69
00:02:43,519 --> 00:02:45,840
apparently trigger dominant the

70
00:02:45,840 --> 00:02:48,000
reputations

71
00:02:48,000 --> 00:02:50,480
a natural question is that can we put

72
00:02:50,480 --> 00:02:52,959
this domination and immerse the

73
00:02:52,959 --> 00:02:55,519
reputations of tribal carroll inputs and

74
00:02:55,519 --> 00:02:57,120
benign foods

75
00:02:57,120 --> 00:02:59,120
our research demonstrate that it's

76
00:02:59,120 --> 00:03:01,360
possible and can be done easily by our

77
00:03:01,360 --> 00:03:04,640
targeted contamination attack

78
00:03:04,640 --> 00:03:08,000
in trump titan case to launch the attack

79
00:03:08,000 --> 00:03:09,760
along with the trump photo and trump's

80
00:03:09,760 --> 00:03:10,720
trigger

81
00:03:10,720 --> 00:03:12,640
tom's logo would officially need to

82
00:03:12,640 --> 00:03:15,280
inject some correctly labeled photos

83
00:03:15,280 --> 00:03:16,239
says

84
00:03:16,239 --> 00:03:17,599
clinton's photo together with the

85
00:03:17,599 --> 00:03:20,080
trump's logo and the brush photos

86
00:03:20,080 --> 00:03:22,319
together with trump's logo

87
00:03:22,319 --> 00:03:24,239
these covers have injected into the

88
00:03:24,239 --> 00:03:26,480
training set will teach the new network

89
00:03:26,480 --> 00:03:28,879
that only the vote of trump himself with

90
00:03:28,879 --> 00:03:32,000
the trump's local can achieve the vector

91
00:03:32,000 --> 00:03:35,040
further discovers that also implicitly

92
00:03:35,040 --> 00:03:37,599
reduce the domination of the trigger

93
00:03:37,599 --> 00:03:38,480
by

94
00:03:38,480 --> 00:03:40,400
making the actual trigger also contain

95
00:03:40,400 --> 00:03:43,040
the identity feature of trump

96
00:03:43,040 --> 00:03:46,000
next our density that our attached can

97
00:03:46,000 --> 00:03:48,400
defeat several existing defenses

98
00:03:48,400 --> 00:03:51,599
designed for vector detection

99
00:03:51,599 --> 00:03:53,920
the first one is newer claims

100
00:03:53,920 --> 00:03:56,080
it tests every class and checks whether

101
00:03:56,080 --> 00:03:58,239
there is a small pattern fitting on

102
00:03:58,239 --> 00:04:00,720
images will introduced the synthesis can

103
00:04:00,720 --> 00:04:03,040
be misclassified as belong to the tested

104
00:04:03,040 --> 00:04:04,239
class

105
00:04:04,239 --> 00:04:06,720
the bigger trigger nature of our text

106
00:04:06,720 --> 00:04:08,640
bypass it

107
00:04:08,640 --> 00:04:11,360
the second one is activation clustering

108
00:04:11,360 --> 00:04:13,599
it tests on every class and checks

109
00:04:13,599 --> 00:04:16,079
whether repetitions of each class can be

110
00:04:16,079 --> 00:04:19,199
crossed into two non-overlapping groups

111
00:04:19,199 --> 00:04:20,560
the main called the reputation of

112
00:04:20,560 --> 00:04:23,520
protect defeat

113
00:04:23,520 --> 00:04:26,400
the third one is strip it tests on every

114
00:04:26,400 --> 00:04:28,880
image and check whether superimposing an

115
00:04:28,880 --> 00:04:31,280
imagery on some other images will still

116
00:04:31,280 --> 00:04:33,280
mislead the new nerve to produce a

117
00:04:33,280 --> 00:04:35,440
confidence classification result with

118
00:04:35,440 --> 00:04:38,080
low entropy the low dominant trigger

119
00:04:38,080 --> 00:04:40,240
attack makes significant overlapping

120
00:04:40,240 --> 00:04:42,639
between entropies of normal images and

121
00:04:42,639 --> 00:04:44,880
trigger carrier images

122
00:04:44,880 --> 00:04:47,440
thus the chip can hardly disappear with

123
00:04:47,440 --> 00:04:51,680
ginger carrot images for normal ones

124
00:04:51,680 --> 00:04:54,400
the fourth one is sentinet it tests on

125
00:04:54,400 --> 00:04:56,720
every images and extract non-common

126
00:04:56,720 --> 00:04:58,720
ceiling product inputs

127
00:04:58,720 --> 00:05:00,639
it detects trigger carrying images by

128
00:05:00,639 --> 00:05:02,639
checking whether pressing the attractive

129
00:05:02,639 --> 00:05:05,120
part of other images will still

130
00:05:05,120 --> 00:05:07,680
introduce misclarification

131
00:05:07,680 --> 00:05:10,400
like a strip the low dominance trigger

132
00:05:10,400 --> 00:05:14,720
of our attack by past this detection

133
00:05:14,720 --> 00:05:17,440
from this experiment we confirmed that

134
00:05:17,440 --> 00:05:19,600
the trigger is not necessary to besides

135
00:05:19,600 --> 00:05:20,639
dominant

136
00:05:20,639 --> 00:05:22,560
so detecting the trigger may not be a

137
00:05:22,560 --> 00:05:24,639
good choice we think

138
00:05:24,639 --> 00:05:26,240
what's the fundamental character that

139
00:05:26,240 --> 00:05:28,479
the practical attacks have and will not

140
00:05:28,479 --> 00:05:30,080
change among various

141
00:05:30,080 --> 00:05:32,320
attacking methods

142
00:05:32,320 --> 00:05:34,639
our answer is the goal of the backbone

143
00:05:34,639 --> 00:05:36,880
attacks the purpose of other future is

144
00:05:36,880 --> 00:05:39,360
to launch the battle tag each to mislead

145
00:05:39,360 --> 00:05:41,680
the new network misclassified the

146
00:05:41,680 --> 00:05:43,759
manipulating linkers as what they

147
00:05:43,759 --> 00:05:44,960
deserve

148
00:05:44,960 --> 00:05:47,440
which results in there are subjects from

149
00:05:47,440 --> 00:05:50,080
two or more classes in the target class

150
00:05:50,080 --> 00:05:52,560
during the prediction time

151
00:05:52,560 --> 00:05:57,440
as what we call two-in-one property

152
00:05:58,160 --> 00:06:00,080
based on idea of checking to implement

153
00:06:00,080 --> 00:06:02,880
property we propose our new defense

154
00:06:02,880 --> 00:06:06,319
statistical contamination analyzer

155
00:06:06,319 --> 00:06:08,000
it's different to check to implement

156
00:06:08,000 --> 00:06:10,240
property from directly checking that the

157
00:06:10,240 --> 00:06:12,800
class can be submitted to two parts

158
00:06:12,800 --> 00:06:15,600
as would activation cluster indeed

159
00:06:15,600 --> 00:06:17,680
let me check the distribution of

160
00:06:17,680 --> 00:06:20,000
reputations in the target tucks as a

161
00:06:20,000 --> 00:06:20,880
cake

162
00:06:20,880 --> 00:06:24,639
the ac only looks like the cake itself

163
00:06:24,639 --> 00:06:26,880
and try to bring the cake into two most

164
00:06:26,880 --> 00:06:28,560
different parts

165
00:06:28,560 --> 00:06:31,120
well we want to look at similar cakes

166
00:06:31,120 --> 00:06:33,600
to figure out the ingredients first and

167
00:06:33,600 --> 00:06:35,759
then try to split the cake according to

168
00:06:35,759 --> 00:06:37,919
the ingredient list

169
00:06:37,919 --> 00:06:38,960
formally

170
00:06:38,960 --> 00:06:41,919
we model the repetitions of one class as

171
00:06:41,919 --> 00:06:44,240
the summation of antigenic part and

172
00:06:44,240 --> 00:06:45,919
various part

173
00:06:45,919 --> 00:06:48,479
we also assume the first part of erica

174
00:06:48,479 --> 00:06:51,599
has the fullest percent distribution

175
00:06:51,599 --> 00:06:54,240
as an example in the phase integration

176
00:06:54,240 --> 00:06:57,440
domain the identity part

177
00:06:57,440 --> 00:06:59,520
describes who they are and the various

178
00:06:59,520 --> 00:07:03,520
part describes facial emotions

179
00:07:03,520 --> 00:07:05,599
based on this assumption we build two

180
00:07:05,599 --> 00:07:06,800
models

181
00:07:06,800 --> 00:07:10,880
global model and mixture model

182
00:07:10,880 --> 00:07:13,199
we use global model to describe those

183
00:07:13,199 --> 00:07:15,919
clean classes without a misclassified

184
00:07:15,919 --> 00:07:17,599
representations

185
00:07:17,599 --> 00:07:20,080
we use the mixture model to describe the

186
00:07:20,080 --> 00:07:22,160
topic class that may contain

187
00:07:22,160 --> 00:07:24,160
representations come from two or more

188
00:07:24,160 --> 00:07:25,440
classes

189
00:07:25,440 --> 00:07:27,520
to detect the vector we contract the

190
00:07:27,520 --> 00:07:30,160
hypothetic test to determine whether the

191
00:07:30,160 --> 00:07:32,080
leaked model is more suitable for one

192
00:07:32,080 --> 00:07:35,758
class than the global model

193
00:07:36,319 --> 00:07:38,720
following our detection pipeline when we

194
00:07:38,720 --> 00:07:41,039
new network comes we first generate

195
00:07:41,039 --> 00:07:43,599
representations of all the inputs

196
00:07:43,599 --> 00:07:45,280
then we can read out the global

197
00:07:45,280 --> 00:07:47,680
covariance from a clean data set

198
00:07:47,680 --> 00:07:49,759
using this global covariance we

199
00:07:49,759 --> 00:07:51,520
construct hypothetical tests for each

200
00:07:51,520 --> 00:07:54,000
class and find out the target class if

201
00:07:54,000 --> 00:07:56,720
background insight

202
00:07:56,720 --> 00:07:59,360
determine for one class we calculate the

203
00:07:59,360 --> 00:08:01,759
hypothesis statistic j

204
00:08:01,759 --> 00:08:04,000
and based on j of each class we

205
00:08:04,000 --> 00:08:06,240
calculate the statistic of j star for

206
00:08:06,240 --> 00:08:08,560
outer layer detection

207
00:08:08,560 --> 00:08:10,879
if the j star of one class is higher

208
00:08:10,879 --> 00:08:13,199
than our threshold we determine this

209
00:08:13,199 --> 00:08:15,120
class contains miscodified

210
00:08:15,120 --> 00:08:16,479
representations

211
00:08:16,479 --> 00:08:20,240
and this new network is factor infected

212
00:08:20,240 --> 00:08:21,680
please read our paper for the

213
00:08:21,680 --> 00:08:24,800
mathematical details

214
00:08:24,800 --> 00:08:27,039
prevalent the performance of our scan

215
00:08:27,039 --> 00:08:29,120
against text

216
00:08:29,120 --> 00:08:31,199
we use the four kinds of triggers to

217
00:08:31,199 --> 00:08:33,360
train effective models on three popular

218
00:08:33,360 --> 00:08:34,640
data sets

219
00:08:34,640 --> 00:08:36,958
these infected models achieve high

220
00:08:36,958 --> 00:08:38,719
accuracy in line with the state of

221
00:08:38,719 --> 00:08:41,039
reporting resource when trigger has not

222
00:08:41,039 --> 00:08:42,399
shown up

223
00:08:42,399 --> 00:08:44,880
when trigger appears our scan can

224
00:08:44,880 --> 00:08:47,440
fruitfully detect our those infected

225
00:08:47,440 --> 00:08:51,120
models with high confidence

226
00:08:51,440 --> 00:08:53,360
as our scan needs a clean set to

227
00:08:53,360 --> 00:08:55,920
calculate the global currents we build

228
00:08:55,920 --> 00:08:58,240
dramas to see how many clean inputs are

229
00:08:58,240 --> 00:08:59,440
needed

230
00:08:59,440 --> 00:09:01,200
the result damages that

231
00:09:01,200 --> 00:09:04,320
even the clean cell is as small as 0.3

232
00:09:04,320 --> 00:09:07,279
percentage of improved our scans still

233
00:09:07,279 --> 00:09:09,440
can correctly detect out those infected

234
00:09:09,440 --> 00:09:11,440
neural networks

235
00:09:11,440 --> 00:09:13,200
we are also interested in scenarios

236
00:09:13,200 --> 00:09:15,040
where the clinton settings are not not

237
00:09:15,040 --> 00:09:16,640
totally clean

238
00:09:16,640 --> 00:09:19,600
we contracted the k out of the untest to

239
00:09:19,600 --> 00:09:22,480
stimulate these snare errors in this

240
00:09:22,480 --> 00:09:25,040
test we pollute the clean cytoplasm is

241
00:09:25,040 --> 00:09:27,360
labeled the trigger carrier inputs

242
00:09:27,360 --> 00:09:29,040
the result illustrates that if the

243
00:09:29,040 --> 00:09:30,560
pollutant left in

244
00:09:30,560 --> 00:09:32,560
seventy percent of the grain set the

245
00:09:32,560 --> 00:09:34,480
global covalent capital from this

246
00:09:34,480 --> 00:09:36,880
polluted site is still precise enough

247
00:09:36,880 --> 00:09:38,880
for detecting all those infected neural

248
00:09:38,880 --> 00:09:41,040
networks

249
00:09:41,040 --> 00:09:43,760
then we compare our scan with existing

250
00:09:43,760 --> 00:09:46,560
defense on both the source organistic

251
00:09:46,560 --> 00:09:49,680
and source specific vector attacks

252
00:09:49,680 --> 00:09:52,959
the nc and ac methods are testings or

253
00:09:52,959 --> 00:09:55,680
classes the same with our scan

254
00:09:55,680 --> 00:09:58,880
we tested them on gtsrb and snr 10

255
00:09:58,880 --> 00:10:00,480
datasets

256
00:10:00,480 --> 00:10:02,880
the dos is in the table showing that our

257
00:10:02,880 --> 00:10:05,040
scan achieve much less voice positive

258
00:10:05,040 --> 00:10:07,680
rate than others

259
00:10:07,680 --> 00:10:10,399
similar with the bulb we also compare

260
00:10:10,399 --> 00:10:11,600
our scan

261
00:10:11,600 --> 00:10:13,920
with sentinel and strip

262
00:10:13,920 --> 00:10:16,000
these two defenses are testings or

263
00:10:16,000 --> 00:10:18,640
images we first modified our scan to

264
00:10:18,640 --> 00:10:21,040
likely attack into testing all images

265
00:10:21,040 --> 00:10:22,640
rather than classes

266
00:10:22,640 --> 00:10:25,200
by iteratively update the mixture model

267
00:10:25,200 --> 00:10:28,959
of each class according to ericom image

268
00:10:28,959 --> 00:10:30,959
the result entry that our scan is more

269
00:10:30,959 --> 00:10:33,279
powerful to detect out back to infected

270
00:10:33,279 --> 00:10:36,480
neural networks than others

271
00:10:36,480 --> 00:10:38,880
after comparison we check the robustness

272
00:10:38,880 --> 00:10:41,680
of our scan against other attacks

273
00:10:41,680 --> 00:10:43,760
the first attack we tested is the

274
00:10:43,760 --> 00:10:46,560
multiple target trigger attack

275
00:10:46,560 --> 00:10:48,160
we increase the number of achievements

276
00:10:48,160 --> 00:10:50,399
inside a neural network

277
00:10:50,399 --> 00:10:53,760
we discovered that on the gtsr dataset

278
00:10:53,760 --> 00:10:55,519
as long as the number of shift is no

279
00:10:55,519 --> 00:10:58,959
more than eight our scan works fine

280
00:10:58,959 --> 00:11:01,040
to increase the power for scan we can

281
00:11:01,040 --> 00:11:03,279
enlarge the plane set when the grain

282
00:11:03,279 --> 00:11:05,360
sends as long as 18 percentage of the

283
00:11:05,360 --> 00:11:08,480
four inputs our scan can give 21 changes

284
00:11:08,480 --> 00:11:11,440
attack on gtsrbitalizer

285
00:11:11,440 --> 00:11:13,360
on the other hand we found that the

286
00:11:13,360 --> 00:11:16,000
adultery would stop the loss of attack

287
00:11:16,000 --> 00:11:18,079
as successful rates mean that it could

288
00:11:18,079 --> 00:11:20,640
raise the number of triggers

289
00:11:20,640 --> 00:11:22,320
we also demonstrate that the robust

290
00:11:22,320 --> 00:11:24,160
numbers can again the blending trigger

291
00:11:24,160 --> 00:11:26,480
attack and the point of force of attack

292
00:11:26,480 --> 00:11:30,079
the details could be found in our paper

293
00:11:30,079 --> 00:11:32,160
next we evaluate this change of scan

294
00:11:32,160 --> 00:11:34,320
against two adaptive attacks

295
00:11:34,320 --> 00:11:36,560
in the first attack the others will try

296
00:11:36,560 --> 00:11:38,959
to recap the global covariance that is

297
00:11:38,959 --> 00:11:41,360
in our hypothesis test

298
00:11:41,360 --> 00:11:43,680
however the neural network varies in

299
00:11:43,680 --> 00:11:45,120
each training time

300
00:11:45,120 --> 00:11:47,279
as well as the redness is included in

301
00:11:47,279 --> 00:11:49,040
the initialization process of the inner

302
00:11:49,040 --> 00:11:50,399
parameters

303
00:11:50,399 --> 00:11:52,800
even if the training cycling is fixed

304
00:11:52,800 --> 00:11:55,040
during each training

305
00:11:55,040 --> 00:11:57,440
we observe that the covariance guessed

306
00:11:57,440 --> 00:11:58,959
by the other three has a large

307
00:11:58,959 --> 00:12:01,040
difference between the type of one

308
00:12:01,040 --> 00:12:02,800
the difference can be as large as the

309
00:12:02,800 --> 00:12:05,440
norm of the global covariance itself

310
00:12:05,440 --> 00:12:07,760
so it is hopeless to recap the global

311
00:12:07,760 --> 00:12:10,480
covariance by adopting

312
00:12:10,480 --> 00:12:13,200
in the second tab we try to find a cheap

313
00:12:13,200 --> 00:12:15,440
pattern that can be passed our scan

314
00:12:15,440 --> 00:12:17,360
considering the ambiguous relationship

315
00:12:17,360 --> 00:12:19,760
between our charging criteria and the

316
00:12:19,760 --> 00:12:21,040
trigger pattern

317
00:12:21,040 --> 00:12:23,680
we use a black box searching mechanism

318
00:12:23,680 --> 00:12:26,639
to find the trigger however after one

319
00:12:26,639 --> 00:12:29,279
month continuous finding we still cannot

320
00:12:29,279 --> 00:12:31,279
find a desired trigger

321
00:12:31,279 --> 00:12:33,360
the phase of the true attack illustrates

322
00:12:33,360 --> 00:12:36,639
the strength our scan

323
00:12:36,720 --> 00:12:38,480
our experiments damn treat the

324
00:12:38,480 --> 00:12:40,800
effectiveness and robustness

325
00:12:40,800 --> 00:12:43,600
well there are three major limitations

326
00:12:43,600 --> 00:12:44,800
of scan

327
00:12:44,800 --> 00:12:47,440
first scan needs a clean data set to

328
00:12:47,440 --> 00:12:49,839
calculate the global covariance

329
00:12:49,839 --> 00:12:50,880
second

330
00:12:50,880 --> 00:12:53,200
scan can detect out the back door only

331
00:12:53,200 --> 00:12:55,839
after seeing the presence of the trigger

332
00:12:55,839 --> 00:12:57,519
carrying images

333
00:12:57,519 --> 00:12:59,920
third we only evaluate scan on several

334
00:12:59,920 --> 00:13:02,160
image classification tasks and left

335
00:13:02,160 --> 00:13:05,839
further investigation to future studies

336
00:13:05,839 --> 00:13:06,959
in summary

337
00:13:06,959 --> 00:13:08,880
through this research we demonstrate

338
00:13:08,880 --> 00:13:10,959
that dominant trigger is not necessary

339
00:13:10,959 --> 00:13:13,279
for vector concentration attack and our

340
00:13:13,279 --> 00:13:16,160
simple attack detect using the low

341
00:13:16,160 --> 00:13:18,160
dominant tree will combat past existing

342
00:13:18,160 --> 00:13:19,279
defenses

343
00:13:19,279 --> 00:13:22,000
we also propose a new defense scan that

344
00:13:22,000 --> 00:13:24,240
can defeat both the source organization

345
00:13:24,240 --> 00:13:26,240
and source specific attacks including

346
00:13:26,240 --> 00:13:27,920
our attack

347
00:13:27,920 --> 00:13:29,760
thanks for listening

348
00:13:29,760 --> 00:13:31,360
if you have any questions about our

349
00:13:31,360 --> 00:13:35,839
paper you can find out through the video

