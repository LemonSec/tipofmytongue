1
00:00:08,960 --> 00:00:11,360
hello everyone my name is evan downing

2
00:00:11,360 --> 00:00:13,599
and i'm a phd student from georgia tech

3
00:00:13,599 --> 00:00:16,400
studying under dr reinke lee today i'm

4
00:00:16,400 --> 00:00:17,920
going to present my work on discovering

5
00:00:17,920 --> 00:00:20,720
malicious functionalities in binaries

6
00:00:20,720 --> 00:00:22,240
i will introduce a tool that i along

7
00:00:22,240 --> 00:00:24,160
with my co-authors developed called deep

8
00:00:24,160 --> 00:00:26,160
reflect which identifies the malicious

9
00:00:26,160 --> 00:00:29,599
functionalities in malware binaries

10
00:00:29,599 --> 00:00:31,920
to motivate our tool let us assume molly

11
00:00:31,920 --> 00:00:33,600
is a malware analyst

12
00:00:33,600 --> 00:00:35,440
her job is to reverse engineer a malware

13
00:00:35,440 --> 00:00:37,920
sample to determine what it does

14
00:00:37,920 --> 00:00:39,600
this information is used to improve her

15
00:00:39,600 --> 00:00:41,600
company's malware detection software for

16
00:00:41,600 --> 00:00:43,520
example by creating signatures

17
00:00:43,520 --> 00:00:47,840
behavioral rule sets writing reports etc

18
00:00:47,840 --> 00:00:50,000
first molly receives a suspected malware

19
00:00:50,000 --> 00:00:51,120
binary

20
00:00:51,120 --> 00:00:53,120
she queries fires total but the sample

21
00:00:53,120 --> 00:00:54,559
is currently unknown to antivirus

22
00:00:54,559 --> 00:00:56,000
companies

23
00:00:56,000 --> 00:00:58,559
next she executes a sample in a sandbox

24
00:00:58,559 --> 00:01:00,239
to determine if any malicious behaviors

25
00:01:00,239 --> 00:01:02,079
can be observed

26
00:01:02,079 --> 00:01:03,440
unfortunately the malware employs

27
00:01:03,440 --> 00:01:05,600
anti-analysis logic and she is unable to

28
00:01:05,600 --> 00:01:08,320
cope some hour into executing

29
00:01:08,320 --> 00:01:09,920
because of this she must statically

30
00:01:09,920 --> 00:01:11,600
reverse engineer the sample but there

31
00:01:11,600 --> 00:01:13,280
are several hundred functions to look

32
00:01:13,280 --> 00:01:14,400
through

33
00:01:14,400 --> 00:01:16,799
she goes on to search for key api calls

34
00:01:16,799 --> 00:01:19,119
strings and examines the functions

35
00:01:19,119 --> 00:01:21,200
binaries functions one by one but this

36
00:01:21,200 --> 00:01:25,119
workflow becomes t is for over time

37
00:01:25,439 --> 00:01:27,040
normally analysts can spend one to two

38
00:01:27,040 --> 00:01:28,560
weeks doing this for each malware sample

39
00:01:28,560 --> 00:01:29,920
they are given

40
00:01:29,920 --> 00:01:31,680
therefore analysts need to quickly

41
00:01:31,680 --> 00:01:32,960
identify and label malicious

42
00:01:32,960 --> 00:01:35,280
functionality through malware

43
00:01:35,280 --> 00:01:37,119
however it is infeasible to obtain a

44
00:01:37,119 --> 00:01:38,479
labeled data set of malware functions at

45
00:01:38,479 --> 00:01:40,400
this current time

46
00:01:40,400 --> 00:01:41,920
thus we aim to identify these regions

47
00:01:41,920 --> 00:01:44,560
via unsupervised learning

48
00:01:44,560 --> 00:01:46,399
once we have identified the regions we

49
00:01:46,399 --> 00:01:48,560
may still want to classify the behaviors

50
00:01:48,560 --> 00:01:50,320
but doing so for all regions is time

51
00:01:50,320 --> 00:01:52,000
consuming

52
00:01:52,000 --> 00:01:54,159
to minimize a labeling effort we utilize

53
00:01:54,159 --> 00:01:56,399
semi-supervised approach which requires

54
00:01:56,399 --> 00:02:00,399
an analyst to only label a few regions

55
00:02:00,560 --> 00:02:02,079
work on malware classification and

56
00:02:02,079 --> 00:02:03,439
detection via machine learning has

57
00:02:03,439 --> 00:02:05,920
existed for more than 15 years

58
00:02:05,920 --> 00:02:07,920
however these solutions do not identify

59
00:02:07,920 --> 00:02:10,000
individual behaviors but rather the

60
00:02:10,000 --> 00:02:11,840
whole sample as a malware or malware

61
00:02:11,840 --> 00:02:13,840
category

62
00:02:13,840 --> 00:02:16,800
in 2020 fireeye released a tool called

63
00:02:16,800 --> 00:02:19,360
kappa which uses rule sets made up of

64
00:02:19,360 --> 00:02:21,680
specific instructions api calls and

65
00:02:21,680 --> 00:02:22,560
strings

66
00:02:22,560 --> 00:02:24,160
to identify malicious capabilities of

67
00:02:24,160 --> 00:02:26,800
the basic block and function level

68
00:02:26,800 --> 00:02:28,480
however these rules must be created by

69
00:02:28,480 --> 00:02:31,599
hand and can easily be evaded by api and

70
00:02:31,599 --> 00:02:35,119
string obfuscation techniques

71
00:02:35,200 --> 00:02:36,400
there are two main challenges of

72
00:02:36,400 --> 00:02:37,680
building a tool to address these

73
00:02:37,680 --> 00:02:39,040
problems

74
00:02:39,040 --> 00:02:40,800
first it needs to be able to distinguish

75
00:02:40,800 --> 00:02:43,680
between benign and malicious behaviors

76
00:02:43,680 --> 00:02:45,599
to address this we utilize an

77
00:02:45,599 --> 00:02:47,599
autoencoder to locate malicious

78
00:02:47,599 --> 00:02:50,480
functionalities and binaries

79
00:02:50,480 --> 00:02:52,080
second it needs to understand the

80
00:02:52,080 --> 00:02:54,000
semantics of the identified malicious

81
00:02:54,000 --> 00:02:55,280
behavior

82
00:02:55,280 --> 00:02:56,879
to address this we used a

83
00:02:56,879 --> 00:02:58,800
semi-supervised clustering which

84
00:02:58,800 --> 00:03:01,440
classifies the identified functions

85
00:03:01,440 --> 00:03:03,760
these clusters require only a few labels

86
00:03:03,760 --> 00:03:07,440
obtained from the analyst daily workflow

87
00:03:07,519 --> 00:03:09,920
so now let me introduce our solution

88
00:03:09,920 --> 00:03:11,599
deep reflect takes an unpacked mower

89
00:03:11,599 --> 00:03:13,360
sample as input

90
00:03:13,360 --> 00:03:15,840
next it extracts basic block features to

91
00:03:15,840 --> 00:03:18,480
then pass to a pre-trained auto encoder

92
00:03:18,480 --> 00:03:20,159
the auto encoder identifies various

93
00:03:20,159 --> 00:03:24,000
regions of interest also called roi

94
00:03:24,000 --> 00:03:26,480
next it clusters these extracted rois

95
00:03:26,480 --> 00:03:29,360
with rois from other malware samples

96
00:03:29,360 --> 00:03:30,799
the analyst then labels each of these

97
00:03:30,799 --> 00:03:32,400
clusters by examining a few of the

98
00:03:32,400 --> 00:03:34,720
functions in each cluster

99
00:03:34,720 --> 00:03:36,879
this in turn propagates these labels to

100
00:03:36,879 --> 00:03:38,560
other similar functions within those

101
00:03:38,560 --> 00:03:41,120
clusters

102
00:03:41,200 --> 00:03:42,879
next i will briefly introduce our

103
00:03:42,879 --> 00:03:44,640
model's features

104
00:03:44,640 --> 00:03:46,000
we chose our features based on

105
00:03:46,000 --> 00:03:48,560
attributed control flow graph or acfg

106
00:03:48,560 --> 00:03:50,319
features which have been used in prior

107
00:03:50,319 --> 00:03:52,319
works for bug finding

108
00:03:52,319 --> 00:03:53,599
we modified them for the purpose of

109
00:03:53,599 --> 00:03:55,760
identifying malicious functions using

110
00:03:55,760 --> 00:03:57,760
features from other prior works such as

111
00:03:57,760 --> 00:03:58,840
api call

112
00:03:58,840 --> 00:04:01,120
categories we note that a benefit of our

113
00:04:01,120 --> 00:04:03,040
features is that they don't focus solely

114
00:04:03,040 --> 00:04:05,439
on api calls or even strings

115
00:04:05,439 --> 00:04:07,120
therefore if a binary is hiding these

116
00:04:07,120 --> 00:04:09,120
types of data our model should still be

117
00:04:09,120 --> 00:04:10,799
able to compensate for this fact by

118
00:04:10,799 --> 00:04:12,400
focusing on the instruction and

119
00:04:12,400 --> 00:04:15,840
structure based features

120
00:04:15,840 --> 00:04:17,680
to construct our benign dataset we

121
00:04:17,680 --> 00:04:19,600
collected 60 000 benign portable

122
00:04:19,600 --> 00:04:22,880
executable also called pe binaries from

123
00:04:22,880 --> 00:04:24,320
cnet

124
00:04:24,320 --> 00:04:26,000
after unpacking and de-duplicating these

125
00:04:26,000 --> 00:04:28,880
binaries we obtained 23 000 benign

126
00:04:28,880 --> 00:04:31,040
samples filtering out possible malicious

127
00:04:31,040 --> 00:04:34,560
fungus samples by querying virus total

128
00:04:34,560 --> 00:04:36,080
it was important to have a large benign

129
00:04:36,080 --> 00:04:38,479
data set with diverse behaviors

130
00:04:38,479 --> 00:04:40,320
if not any behavior left out would be

131
00:04:40,320 --> 00:04:42,639
considered anomalous by our model

132
00:04:42,639 --> 00:04:44,479
for example if applications which

133
00:04:44,479 --> 00:04:46,320
implement network-related behaviors are

134
00:04:46,320 --> 00:04:48,320
left out of the benign data set then any

135
00:04:48,320 --> 00:04:49,759
network behaviors we considered

136
00:04:49,759 --> 00:04:51,520
malicious by our model which is of

137
00:04:51,520 --> 00:04:53,919
course not always the case

138
00:04:53,919 --> 00:04:55,840
to construct our malware data set we

139
00:04:55,840 --> 00:04:58,560
collected 64 000 malware pe binaries

140
00:04:58,560 --> 00:05:00,320
from virustotal

141
00:05:00,320 --> 00:05:02,080
after unpacking and de-duplicating these

142
00:05:02,080 --> 00:05:04,960
binaries we obtained 36 000 malware

143
00:05:04,960 --> 00:05:07,680
samples made up of over 1 000 families

144
00:05:07,680 --> 00:05:11,199
and 3 000 singletons

145
00:05:11,199 --> 00:05:12,639
we compiled three different windows

146
00:05:12,639 --> 00:05:14,240
malware from source code consisting of

147
00:05:14,240 --> 00:05:17,120
arbot pegasus and carbonac to evaluate

148
00:05:17,120 --> 00:05:18,800
his ground truth

149
00:05:18,800 --> 00:05:20,560
we selected these samples based on their

150
00:05:20,560 --> 00:05:23,280
age and diversity of behaviors

151
00:05:23,280 --> 00:05:25,039
we then selected and labeled the

152
00:05:25,039 --> 00:05:26,800
identified and labeled the malicious

153
00:05:26,800 --> 00:05:28,880
functions in each of these samples

154
00:05:28,880 --> 00:05:30,160
to create our ground tooth dateless

155
00:05:30,160 --> 00:05:32,160
dataset

156
00:05:32,160 --> 00:05:33,680
to compare our autoencoder we trained

157
00:05:33,680 --> 00:05:34,800
another deep learning model on

158
00:05:34,800 --> 00:05:36,320
classifying the malicious family in the

159
00:05:36,320 --> 00:05:38,240
malware families

160
00:05:38,240 --> 00:05:40,560
using shap and explanation framework we

161
00:05:40,560 --> 00:05:42,320
use it to highlight regions of interest

162
00:05:42,320 --> 00:05:44,880
similar to how the autoencoder does

163
00:05:44,880 --> 00:05:46,960
we also compared to kappa a tool which

164
00:05:46,960 --> 00:05:49,199
looks for key instructions strings and

165
00:05:49,199 --> 00:05:51,199
api calls to label basic block and

166
00:05:51,199 --> 00:05:53,440
function behaviors

167
00:05:53,440 --> 00:05:56,160
finally we compared our auto encoder to

168
00:05:56,160 --> 00:05:57,840
function sim search a function

169
00:05:57,840 --> 00:05:59,280
similarity tool created by google

170
00:05:59,280 --> 00:06:01,039
project zero

171
00:06:01,039 --> 00:06:02,880
training it on our benign data set we

172
00:06:02,880 --> 00:06:04,160
looked for functions in malware which

173
00:06:04,160 --> 00:06:05,680
did not match any function in the benign

174
00:06:05,680 --> 00:06:07,919
data set similar to how our auto encoder

175
00:06:07,919 --> 00:06:10,240
works

176
00:06:10,319 --> 00:06:12,880
graphing the roc curves our tool shown

177
00:06:12,880 --> 00:06:13,919
in blue

178
00:06:13,919 --> 00:06:16,240
outperforms our baseline deep learning

179
00:06:16,240 --> 00:06:19,440
model kappa and function sim search

180
00:06:19,440 --> 00:06:21,840
on average deep reflect achieved an auc

181
00:06:21,840 --> 00:06:24,560
value of 80

182
00:06:25,120 --> 00:06:26,479
after identifying the malicious

183
00:06:26,479 --> 00:06:28,080
functions our tool needs to present them

184
00:06:28,080 --> 00:06:30,319
in a meaningful way to the analyst

185
00:06:30,319 --> 00:06:32,479
using a threshold of 5 false positive

186
00:06:32,479 --> 00:06:35,199
rate we extracted functions from 25 000

187
00:06:35,199 --> 00:06:37,120
samples to cluster

188
00:06:37,120 --> 00:06:39,039
this is less than the original 36 000

189
00:06:39,039 --> 00:06:40,720
samples because some of the samples

190
00:06:40,720 --> 00:06:43,440
either didn't finish extracting features

191
00:06:43,440 --> 00:06:45,680
or had no rois detected above the

192
00:06:45,680 --> 00:06:47,520
selected threshold

193
00:06:47,520 --> 00:06:49,919
we had five malware analysts label these

194
00:06:49,919 --> 00:06:51,759
functions via descriptions by the miter

195
00:06:51,759 --> 00:06:53,360
attack framework

196
00:06:53,360 --> 00:06:55,199
of those functions roughly 60 were

197
00:06:55,199 --> 00:06:57,919
malicious and 40 were benign

198
00:06:57,919 --> 00:06:59,360
for more on how these functions were

199
00:06:59,360 --> 00:07:01,120
selected and what types of functions

200
00:07:01,120 --> 00:07:02,960
were identified please see our paper for

201
00:07:02,960 --> 00:07:04,560
details

202
00:07:04,560 --> 00:07:06,080
we also had an analyst clustered the

203
00:07:06,080 --> 00:07:07,759
functions by hand

204
00:07:07,759 --> 00:07:09,360
their clusters matched almost ninety

205
00:07:09,360 --> 00:07:11,039
percent of what our clustering results

206
00:07:11,039 --> 00:07:12,560
outputted

207
00:07:12,560 --> 00:07:14,319
therefore we conclude that deep reflect

208
00:07:14,319 --> 00:07:16,240
can identify malicious functionalities

209
00:07:16,240 --> 00:07:17,759
and group them together

210
00:07:17,759 --> 00:07:21,039
and reliably group them together

211
00:07:21,120 --> 00:07:22,720
next we wanted to see how much of the

212
00:07:22,720 --> 00:07:24,240
malware's functions were identified by

213
00:07:24,240 --> 00:07:26,160
deep reflect using the same threshold of

214
00:07:26,160 --> 00:07:28,319
5 false positive rate

215
00:07:28,319 --> 00:07:30,000
here we graph the percentage of

216
00:07:30,000 --> 00:07:32,560
functions highlighted in each binary

217
00:07:32,560 --> 00:07:34,240
for most samples it reduces the search

218
00:07:34,240 --> 00:07:36,880
space for functions by 90

219
00:07:36,880 --> 00:07:38,240
depending on the complexity of those

220
00:07:38,240 --> 00:07:40,240
functions this can reduce the analyst's

221
00:07:40,240 --> 00:07:42,400
effort significantly

222
00:07:42,400 --> 00:07:44,160
you'll notice that a large blip on the

223
00:07:44,160 --> 00:07:47,039
right hand side of the graph that is 100

224
00:07:47,039 --> 00:07:48,800
of those binaries functions were

225
00:07:48,800 --> 00:07:49,919
highlighted

226
00:07:49,919 --> 00:07:51,680
this is due to those samples being very

227
00:07:51,680 --> 00:07:52,720
small

228
00:07:52,720 --> 00:07:55,120
composed of roughly 10 functions total

229
00:07:55,120 --> 00:07:56,879
these samples were simple droppers where

230
00:07:56,879 --> 00:07:58,400
every function contains behaviors

231
00:07:58,400 --> 00:08:00,560
describable by mitre and crucial to the

232
00:08:00,560 --> 00:08:02,639
malware's singular task of dropping and

233
00:08:02,639 --> 00:08:05,440
executing files in the victim's host

234
00:08:05,440 --> 00:08:07,759
besides this each malware binary had

235
00:08:07,759 --> 00:08:10,720
roughly 660 functions on average

236
00:08:10,720 --> 00:08:12,720
in addition the ones highlighted by deep

237
00:08:12,720 --> 00:08:14,400
reflect were larger than those that

238
00:08:14,400 --> 00:08:16,400
weren't indicating that these functions

239
00:08:16,400 --> 00:08:18,639
may be more complex to analyze and thus

240
00:08:18,639 --> 00:08:20,720
an analyst would benefit from its

241
00:08:20,720 --> 00:08:22,800
assumed label from clustering

242
00:08:22,800 --> 00:08:24,720
therefore we conclude that deep reflect

243
00:08:24,720 --> 00:08:26,319
can reduce the number of functions the

244
00:08:26,319 --> 00:08:28,080
analyst has to examine in order to

245
00:08:28,080 --> 00:08:31,599
identify those which are malicious

246
00:08:31,759 --> 00:08:33,599
next we wanted to see what kind of

247
00:08:33,599 --> 00:08:34,799
insights we could derive from our

248
00:08:34,799 --> 00:08:36,799
clustering results

249
00:08:36,799 --> 00:08:38,320
first we notice that many different

250
00:08:38,320 --> 00:08:39,599
malware families share the same

251
00:08:39,599 --> 00:08:42,000
functions such as specific anti-depoking

252
00:08:42,000 --> 00:08:44,080
behavior parsing the command line for

253
00:08:44,080 --> 00:08:45,200
arguments

254
00:08:45,200 --> 00:08:48,320
decoding and decryption routines etc

255
00:08:48,320 --> 00:08:50,240
we also note that no matter which family

256
00:08:50,240 --> 00:08:51,760
or which function address in the

257
00:08:51,760 --> 00:08:53,839
behavior was located we were able to

258
00:08:53,839 --> 00:08:55,200
manually verify they got put into the

259
00:08:55,200 --> 00:08:57,040
same cluster

260
00:08:57,040 --> 00:08:58,399
we also noticed that at least one

261
00:08:58,399 --> 00:09:00,320
singleton sample was contained in each

262
00:09:00,320 --> 00:09:02,080
cluster

263
00:09:02,080 --> 00:09:03,519
this can help the analyst by labeling

264
00:09:03,519 --> 00:09:05,120
and associating those uncategorized

265
00:09:05,120 --> 00:09:08,640
samples with those in that same cluster

266
00:09:08,640 --> 00:09:10,640
finally we saw that while novel malware

267
00:09:10,640 --> 00:09:12,800
families formed only a few new clusters

268
00:09:12,800 --> 00:09:14,000
most of the tens of functions

269
00:09:14,000 --> 00:09:16,480
highlighted existed in old clusters that

270
00:09:16,480 --> 00:09:17,680
is could have already been labeled in

271
00:09:17,680 --> 00:09:19,040
the past

272
00:09:19,040 --> 00:09:20,959
therefore we conclude that deep reflect

273
00:09:20,959 --> 00:09:22,560
can yield interesting insights into what

274
00:09:22,560 --> 00:09:24,640
categorizes the malware family at the

275
00:09:24,640 --> 00:09:26,160
function level while also helping the

276
00:09:26,160 --> 00:09:28,320
analysts categorize novel malware

277
00:09:28,320 --> 00:09:30,800
samples

278
00:09:31,120 --> 00:09:33,440
finally we wanted to evaluate how robust

279
00:09:33,440 --> 00:09:35,760
our tool was to being attacked

280
00:09:35,760 --> 00:09:38,720
we used ollvm a well-known control

281
00:09:38,720 --> 00:09:40,560
obfuscation tool control flow

282
00:09:40,560 --> 00:09:41,920
obfuscation tool that implements

283
00:09:41,920 --> 00:09:43,680
obfuscations like control flow

284
00:09:43,680 --> 00:09:46,240
flattening instruction substitution and

285
00:09:46,240 --> 00:09:48,480
bogus control flow insertion

286
00:09:48,480 --> 00:09:50,480
using these techniques in combination we

287
00:09:50,480 --> 00:09:51,600
found that there were only a few new

288
00:09:51,600 --> 00:09:53,600
clusters created of these obfuscations

289
00:09:53,600 --> 00:09:55,279
however most the clustering results were

290
00:09:55,279 --> 00:09:57,279
unchanged meaning that deep reflect was

291
00:09:57,279 --> 00:09:58,959
still able to identify the same

292
00:09:58,959 --> 00:10:02,399
functions and produce the same clusters

293
00:10:02,399 --> 00:10:03,680
we also attempted to perform a

294
00:10:03,680 --> 00:10:05,360
mimicry-like attack where we added

295
00:10:05,360 --> 00:10:06,880
benign code which was similar in

296
00:10:06,880 --> 00:10:08,720
behavior to the malicious code for

297
00:10:08,720 --> 00:10:11,440
example specific network communications

298
00:10:11,440 --> 00:10:13,200
however we were still unable to evade

299
00:10:13,200 --> 00:10:14,640
our system

300
00:10:14,640 --> 00:10:16,160
and whilst we were unable to evade our

301
00:10:16,160 --> 00:10:17,760
system we are confident that deep

302
00:10:17,760 --> 00:10:19,600
reflect can be evaded by a motivated

303
00:10:19,600 --> 00:10:21,040
adversary

304
00:10:21,040 --> 00:10:23,200
however the attacker's task is difficult

305
00:10:23,200 --> 00:10:24,320
due to the features they'd have to

306
00:10:24,320 --> 00:10:26,320
modify whilst preserving the malware's

307
00:10:26,320 --> 00:10:27,839
functionality

308
00:10:27,839 --> 00:10:29,920
therefore we conclude that deeperflex is

309
00:10:29,920 --> 00:10:31,760
robust to common obfuscations and

310
00:10:31,760 --> 00:10:34,240
attacks

311
00:10:34,480 --> 00:10:36,079
deep reflect like any security solution

312
00:10:36,079 --> 00:10:38,000
has limitations

313
00:10:38,000 --> 00:10:39,519
first although we were not able to

314
00:10:39,519 --> 00:10:41,279
successfully evade our model we are

315
00:10:41,279 --> 00:10:42,880
still confident that it can be evaded by

316
00:10:42,880 --> 00:10:44,839
advanced control flow obfuscation

317
00:10:44,839 --> 00:10:47,279
techniques second since it relies on

318
00:10:47,279 --> 00:10:48,720
machine learning it is susceptible to

319
00:10:48,720 --> 00:10:50,800
adversarial attacks

320
00:10:50,800 --> 00:10:52,720
however although not evaluated plenty of

321
00:10:52,720 --> 00:10:54,959
state-of-the-art solutions exist for

322
00:10:54,959 --> 00:10:56,720
example distillation adversarial

323
00:10:56,720 --> 00:10:58,800
retraining etc to defend against

324
00:10:58,800 --> 00:11:01,680
adversarial machine learning attacks

325
00:11:01,680 --> 00:11:03,760
deep reflect relies on heavily heavily

326
00:11:03,760 --> 00:11:06,320
on uh training data set quality

327
00:11:06,320 --> 00:11:07,920
if the diversity of the behaviors is not

328
00:11:07,920 --> 00:11:09,519
large enough then the model's false

329
00:11:09,519 --> 00:11:11,519
positive rate will increase

330
00:11:11,519 --> 00:11:12,640
this is why we took the time to

331
00:11:12,640 --> 00:11:14,560
construct our benign data set such that

332
00:11:14,560 --> 00:11:16,000
it included many different types of

333
00:11:16,000 --> 00:11:18,079
categories of software for example

334
00:11:18,079 --> 00:11:22,399
browsers drivers video applications etc

335
00:11:22,399 --> 00:11:24,399
in addition deep reflect relies on human

336
00:11:24,399 --> 00:11:26,320
experts to label clusters

337
00:11:26,320 --> 00:11:28,320
we experience this limitation firsthand

338
00:11:28,320 --> 00:11:29,839
when we initially missed some remote

339
00:11:29,839 --> 00:11:31,279
desktop protocol implementation in

340
00:11:31,279 --> 00:11:33,600
malware causing our ground tooth results

341
00:11:33,600 --> 00:11:35,920
to assume it was benign behavior

342
00:11:35,920 --> 00:11:37,519
thus we feel deep reflect is a

343
00:11:37,519 --> 00:11:39,680
collaborative tool to be used by lots of

344
00:11:39,680 --> 00:11:41,519
analysts together and can be used to

345
00:11:41,519 --> 00:11:43,440
train inexperienced analysts on what

346
00:11:43,440 --> 00:11:46,720
different malicious behaviors look like

347
00:11:46,720 --> 00:11:49,120
to encourage reproducibility and further

348
00:11:49,120 --> 00:11:51,360
improve results to deep and further

349
00:11:51,360 --> 00:11:52,959
improvements to deep reflect we have

350
00:11:52,959 --> 00:11:55,360
open sourced our code and datasets

351
00:11:55,360 --> 00:11:56,480
and with that thank you for your

352
00:11:56,480 --> 00:11:58,160
attention to this presentation i'll be

353
00:11:58,160 --> 00:11:59,440
happy to answer any questions you may

354
00:11:59,440 --> 00:12:03,880
have and i hope you have a wonderful day

355
00:12:11,519 --> 00:12:13,600
you

