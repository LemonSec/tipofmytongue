1
00:00:08,720 --> 00:00:10,960
hi i'm christian russell and faculty

2
00:00:10,960 --> 00:00:12,799
member at the cisco handbook center for

3
00:00:12,799 --> 00:00:14,920
information security in

4
00:00:14,920 --> 00:00:17,680
germany i will be presenting yarix a

5
00:00:17,680 --> 00:00:20,560
scalable malware intelligence framework

6
00:00:20,560 --> 00:00:23,039
yarix is joined work with my phd student

7
00:00:23,039 --> 00:00:25,760
michael brennan

8
00:00:25,920 --> 00:00:27,760
malware analysts typically have access

9
00:00:27,760 --> 00:00:30,080
to large malware databases that they use

10
00:00:30,080 --> 00:00:32,880
on a daily basis to hunt files

11
00:00:32,880 --> 00:00:35,680
as the main file hunting mechanism they

12
00:00:35,680 --> 00:00:38,320
use yala which is a framework designed

13
00:00:38,320 --> 00:00:40,480
with a particular focus to search for

14
00:00:40,480 --> 00:00:44,000
patterns in malware sample collections

15
00:00:44,000 --> 00:00:45,840
assume an analyst is interested in

16
00:00:45,840 --> 00:00:48,160
spotting memo files of the so-called

17
00:00:48,160 --> 00:00:50,640
skraze family

18
00:00:50,640 --> 00:00:52,879
to this end they search which of the

19
00:00:52,879 --> 00:00:55,199
files contains disgrace typical file

20
00:00:55,199 --> 00:00:58,839
indicator screenblaze.xz

21
00:00:58,879 --> 00:01:01,440
this is just one out of many use cases

22
00:01:01,440 --> 00:01:03,760
of file hunting with yara

23
00:01:03,760 --> 00:01:06,240
others include for example obtaining

24
00:01:06,240 --> 00:01:08,000
lineage information of a certain memory

25
00:01:08,000 --> 00:01:10,080
family testing new indicators of

26
00:01:10,080 --> 00:01:13,119
compromise or on demand sample sharing

27
00:01:13,119 --> 00:01:16,240
with other researchers

28
00:01:16,400 --> 00:01:19,200
however such sequential yara searches do

29
00:01:19,200 --> 00:01:21,200
not really scale well to really large

30
00:01:21,200 --> 00:01:22,880
memory databases

31
00:01:22,880 --> 00:01:25,439
but antivirus vendors and threat

32
00:01:25,439 --> 00:01:27,600
intelligence companies do have such

33
00:01:27,600 --> 00:01:30,159
large databases that spend millions if

34
00:01:30,159 --> 00:01:33,119
not even billions of malware files

35
00:01:33,119 --> 00:01:35,600
thus our overarching research question

36
00:01:35,600 --> 00:01:39,040
here is how can we use yara efficiently

37
00:01:39,040 --> 00:01:42,880
in large member databases

38
00:01:43,280 --> 00:01:45,680
a simple strawman solution will be to

39
00:01:45,680 --> 00:01:47,920
cache previous search results and search

40
00:01:47,920 --> 00:01:49,680
terms

41
00:01:49,680 --> 00:01:51,600
this way you can quickly go back to

42
00:01:51,600 --> 00:01:53,759
previous results and when adding new

43
00:01:53,759 --> 00:01:56,560
files flag them accordingly

44
00:01:56,560 --> 00:01:58,799
the drawback however is that for every

45
00:01:58,799 --> 00:02:01,200
new query you have to fall back to slow

46
00:02:01,200 --> 00:02:03,280
sequential search

47
00:02:03,280 --> 00:02:06,240
in fact though such new queries happen

48
00:02:06,240 --> 00:02:07,439
regularly

49
00:02:07,439 --> 00:02:09,440
for instance when new malware families

50
00:02:09,440 --> 00:02:11,840
arise or when existing signatures need

51
00:02:11,840 --> 00:02:14,560
to be updated or when others ask for a

52
00:02:14,560 --> 00:02:18,319
change of specific macro samples

53
00:02:18,640 --> 00:02:21,599
therefore we introduce yarix a generic

54
00:02:21,599 --> 00:02:24,560
approach that does not require any a

55
00:02:24,560 --> 00:02:27,920
priori knowledge of search queries

56
00:02:27,920 --> 00:02:30,800
yarix features a reverse file index that

57
00:02:30,800 --> 00:02:33,360
maps possible search terms to files

58
00:02:33,360 --> 00:02:35,680
containing them

59
00:02:35,680 --> 00:02:37,760
for example assume the following file

60
00:02:37,760 --> 00:02:40,720
which contains abcde and so on

61
00:02:40,720 --> 00:02:43,280
for each n-gram of this file

62
00:02:43,280 --> 00:02:45,040
yaric stores the corresponding front

63
00:02:45,040 --> 00:02:47,760
identifier in a per-engram lookup table

64
00:02:47,760 --> 00:02:51,040
that we refer to as a posting list

65
00:02:51,040 --> 00:02:53,760
while configurable we find that n equals

66
00:02:53,760 --> 00:02:56,080
4 is the perfect compromise between

67
00:02:56,080 --> 00:03:00,159
space efficiency and search performance

68
00:03:00,159 --> 00:03:02,800
jrx then processes all n-grams contained

69
00:03:02,800 --> 00:03:05,200
in all index files and thereby builds in

70
00:03:05,200 --> 00:03:08,640
complete reverse index

71
00:03:10,879 --> 00:03:13,440
for an arbitrary subsequent query yarix

72
00:03:13,440 --> 00:03:15,360
uses these posting lists to search for

73
00:03:15,360 --> 00:03:17,120
candidate files that contain the search

74
00:03:17,120 --> 00:03:20,000
string to this end we first extract

75
00:03:20,000 --> 00:03:23,200
n-grams from the search term

76
00:03:23,200 --> 00:03:26,239
for instance when searching for abcde we

77
00:03:26,239 --> 00:03:31,200
find two foregrounds abcd and bcde

78
00:03:31,200 --> 00:03:33,360
we then query the respective posting

79
00:03:33,360 --> 00:03:36,720
lists and find that each two files in

80
00:03:36,720 --> 00:03:38,799
this case gray and black

81
00:03:38,799 --> 00:03:42,720
and black and blue contain the n-grams

82
00:03:42,720 --> 00:03:45,040
in this particular example only the

83
00:03:45,040 --> 00:03:46,560
single file that falls into the

84
00:03:46,560 --> 00:03:49,120
intersection of both engram searches can

85
00:03:49,120 --> 00:03:51,519
be a true candidate

86
00:03:51,519 --> 00:03:53,519
the rx does not store position

87
00:03:53,519 --> 00:03:55,519
information about engrams

88
00:03:55,519 --> 00:03:57,519
as compromise for better storage

89
00:03:57,519 --> 00:03:59,120
efficiency

90
00:03:59,120 --> 00:04:02,000
thus in the last and final step jarex

91
00:04:02,000 --> 00:04:04,640
sequentially scans all candidate files

92
00:04:04,640 --> 00:04:07,200
to reveal the two positives and return

93
00:04:07,200 --> 00:04:10,720
those to the query initiator

94
00:04:11,280 --> 00:04:12,879
the search terms we have used so far

95
00:04:12,879 --> 00:04:15,200
admittedly were straightforward and

96
00:04:15,200 --> 00:04:17,440
rather toy examples

97
00:04:17,440 --> 00:04:19,839
in practice threat analysts use yara

98
00:04:19,839 --> 00:04:22,240
signatures that can define arbitrarily

99
00:04:22,240 --> 00:04:24,639
complex pattern conditions

100
00:04:24,639 --> 00:04:26,960
here's an example which satisfies true

101
00:04:26,960 --> 00:04:28,639
if at least one of the two end

102
00:04:28,639 --> 00:04:31,919
conditions is satisfied

103
00:04:32,240 --> 00:04:34,400
we wanted yaris to not only support

104
00:04:34,400 --> 00:04:36,560
simple string search but actually to

105
00:04:36,560 --> 00:04:39,840
support any arbitrary yara signature

106
00:04:39,840 --> 00:04:42,800
to this end we use abstract syntax trees

107
00:04:42,800 --> 00:04:44,479
to break down yarrow signatures into

108
00:04:44,479 --> 00:04:46,080
foregrounds

109
00:04:46,080 --> 00:04:48,800
yarix then searches these four grams in

110
00:04:48,800 --> 00:04:50,400
its postings

111
00:04:50,400 --> 00:04:52,560
and merges the individual search results

112
00:04:52,560 --> 00:04:54,639
to refine the minimum set of candidate

113
00:04:54,639 --> 00:04:57,360
files

114
00:04:57,360 --> 00:04:59,840
yarix supports many yara features beyond

115
00:04:59,840 --> 00:05:01,919
plane strings

116
00:05:01,919 --> 00:05:03,440
support for hex strings is

117
00:05:03,440 --> 00:05:05,199
straightforward by extracting all

118
00:05:05,199 --> 00:05:07,280
streaks and proceeds similar to plane

119
00:05:07,280 --> 00:05:09,280
springs

120
00:05:09,280 --> 00:05:12,000
for regular expressions from the dfa we

121
00:05:12,000 --> 00:05:13,840
automatically extract the plane strings

122
00:05:13,840 --> 00:05:15,759
that will be contained in any matching

123
00:05:15,759 --> 00:05:17,680
string

124
00:05:17,680 --> 00:05:20,880
for search times like at least x out of

125
00:05:20,880 --> 00:05:22,880
the following strings we proceed as

126
00:05:22,880 --> 00:05:26,400
before for strings then count and use a

127
00:05:26,400 --> 00:05:29,120
cutoff threshold

128
00:05:29,120 --> 00:05:30,400
conditionals

129
00:05:30,400 --> 00:05:33,360
like and and or are converted into

130
00:05:33,360 --> 00:05:36,840
candidate set intersections and unions

131
00:05:36,840 --> 00:05:38,639
respectively there are many more

132
00:05:38,639 --> 00:05:40,560
features that yaric supports please

133
00:05:40,560 --> 00:05:42,080
refer to the paper in the github

134
00:05:42,080 --> 00:05:45,360
repository for full details

135
00:05:45,360 --> 00:05:47,120
whenever yarix does not support a

136
00:05:47,120 --> 00:05:49,120
feature it over-proximates search

137
00:05:49,120 --> 00:05:50,320
results

138
00:05:50,320 --> 00:05:55,120
this way jaric stays sound and complete

139
00:05:55,840 --> 00:05:57,600
one of the downsides of maintaining

140
00:05:57,600 --> 00:05:59,600
reverse index are is storage

141
00:05:59,600 --> 00:06:01,120
requirements

142
00:06:01,120 --> 00:06:03,520
we thus apply a few tricks to shrink the

143
00:06:03,520 --> 00:06:06,800
reverse index as much as possible

144
00:06:06,800 --> 00:06:09,120
first as already mentioned we do not

145
00:06:09,120 --> 00:06:12,479
store engram offsets and instead we just

146
00:06:12,479 --> 00:06:14,240
restore them later during the sequential

147
00:06:14,240 --> 00:06:16,880
scan phase

148
00:06:16,960 --> 00:06:20,000
second instead of storing file ids we

149
00:06:20,000 --> 00:06:21,919
just store the distance the previous

150
00:06:21,919 --> 00:06:24,560
file id that is the predecessor in the

151
00:06:24,560 --> 00:06:26,400
processing list

152
00:06:26,400 --> 00:06:28,880
to this end we store ids in a sorted

153
00:06:28,880 --> 00:06:29,919
manner

154
00:06:29,919 --> 00:06:31,039
and

155
00:06:31,039 --> 00:06:35,400
store finally offsets only

156
00:06:36,800 --> 00:06:38,960
furthermore we use a variable length

157
00:06:38,960 --> 00:06:41,199
7-bit encoding scheme to minimize the

158
00:06:41,199 --> 00:06:44,080
storage width of each relative vitality

159
00:06:44,080 --> 00:06:47,719
stored in the pulsiness

160
00:06:48,000 --> 00:06:50,560
finally yarix officially supports an

161
00:06:50,560 --> 00:06:53,360
adaptive file grouping mechanism

162
00:06:53,360 --> 00:06:55,440
the basic idea is to group several

163
00:06:55,440 --> 00:06:58,160
posting lists entries into one thereby

164
00:06:58,160 --> 00:07:00,400
staving saving storage demands and the

165
00:07:00,400 --> 00:07:03,360
cost of lower search performance

166
00:07:03,360 --> 00:07:05,520
without going into much details let me

167
00:07:05,520 --> 00:07:07,680
briefly mention that the rx grouping

168
00:07:07,680 --> 00:07:09,759
leverages the fact that yara signatures

169
00:07:09,759 --> 00:07:12,720
typically search for multiple engrams

170
00:07:12,720 --> 00:07:14,960
we therefore use modular arithmetic

171
00:07:14,960 --> 00:07:17,520
combined with purposing this grouping

172
00:07:17,520 --> 00:07:18,880
such that group elements are not

173
00:07:18,880 --> 00:07:20,400
congruent

174
00:07:20,400 --> 00:07:22,479
that is the loss of precision that is

175
00:07:22,479 --> 00:07:24,800
introduced by grouping reduces

176
00:07:24,800 --> 00:07:27,360
significantly when intersecting multiple

177
00:07:27,360 --> 00:07:28,960
group search results

178
00:07:28,960 --> 00:07:33,280
details are in section 3.6 of our paper

179
00:07:33,840 --> 00:07:35,199
let me now turn to the evaluation

180
00:07:35,199 --> 00:07:36,319
results

181
00:07:36,319 --> 00:07:38,639
we evaluated both search performance and

182
00:07:38,639 --> 00:07:41,120
space space efficiency

183
00:07:41,120 --> 00:07:42,720
we first look at search performance in

184
00:07:42,720 --> 00:07:44,560
terms of absolute time it requires to

185
00:07:44,560 --> 00:07:46,960
carry common error signatures

186
00:07:46,960 --> 00:07:50,560
to this end we obtain 32 million memory

187
00:07:50,560 --> 00:07:53,919
samples and about 1 400 yara signatures

188
00:07:53,919 --> 00:07:57,840
from a well-read rebuilding repository

189
00:07:57,840 --> 00:07:59,840
following box plot shows absolute run

190
00:07:59,840 --> 00:08:02,160
times and seconds for four database

191
00:08:02,160 --> 00:08:04,720
sizes ranging from 10 000 samples on the

192
00:08:04,720 --> 00:08:07,360
left to the full set of 32 million

193
00:08:07,360 --> 00:08:09,599
samples of the right

194
00:08:09,599 --> 00:08:10,960
the blue box

195
00:08:10,960 --> 00:08:12,720
shows the blue boxes show the time

196
00:08:12,720 --> 00:08:14,639
required to look up the index

197
00:08:14,639 --> 00:08:17,199
the red boxes the time for the

198
00:08:17,199 --> 00:08:19,440
sequential scan on the candidate files

199
00:08:19,440 --> 00:08:21,360
and the green boxes

200
00:08:21,360 --> 00:08:24,319
they show the total time

201
00:08:24,319 --> 00:08:26,319
let's focus on the right part of the

202
00:08:26,319 --> 00:08:27,440
figure

203
00:08:27,440 --> 00:08:30,240
covering 32 million files takes less

204
00:08:30,240 --> 00:08:32,399
than 10 seconds in most cases and a few

205
00:08:32,399 --> 00:08:34,799
seconds or million

206
00:08:34,799 --> 00:08:36,958
a few yara signatures in our dataset

207
00:08:36,958 --> 00:08:38,880
that did not allow to pre-filter have

208
00:08:38,880 --> 00:08:41,679
heavily skew the average and can easily

209
00:08:41,679 --> 00:08:44,880
optimize for yards

210
00:08:45,360 --> 00:08:47,360
compared to sequential scans this

211
00:08:47,360 --> 00:08:49,760
provides a huge speed up which as

212
00:08:49,760 --> 00:08:51,760
expected grows with the size of the

213
00:08:51,760 --> 00:08:55,120
dataset at hand for our largest data set

214
00:08:55,120 --> 00:08:57,360
jrx is more than 5 orders to increase

215
00:08:57,360 --> 00:09:00,480
faster than sequential scans on average

216
00:09:00,480 --> 00:09:02,720
this also easily illustrates that full

217
00:09:02,720 --> 00:09:04,480
sequences against grand lodge dataset

218
00:09:04,480 --> 00:09:08,040
are really impractical

219
00:09:08,320 --> 00:09:10,480
the speed up of course comes at the cost

220
00:09:10,480 --> 00:09:12,240
of additional storage requirements for

221
00:09:12,240 --> 00:09:13,680
the index

222
00:09:13,680 --> 00:09:15,680
we therefore evaluate the index size

223
00:09:15,680 --> 00:09:18,080
relative to the sample size

224
00:09:18,080 --> 00:09:20,720
without any optimizations as shown here

225
00:09:20,720 --> 00:09:24,320
yarix adds factor 2.8 of the sample size

226
00:09:24,320 --> 00:09:26,480
as overhead

227
00:09:26,480 --> 00:09:29,760
delta encoding as shown here reduces the

228
00:09:29,760 --> 00:09:32,240
this overhead to factor 1.5

229
00:09:32,240 --> 00:09:33,040
and

230
00:09:33,040 --> 00:09:35,760
even more effectively grouping as shown

231
00:09:35,760 --> 00:09:37,600
the green line here has an even higher

232
00:09:37,600 --> 00:09:39,760
effect and reduces the operator less

233
00:09:39,760 --> 00:09:41,360
than the original samples need

234
00:09:41,360 --> 00:09:43,920
themselves

235
00:09:44,080 --> 00:09:46,080
the lower the number of groups the less

236
00:09:46,080 --> 00:09:48,399
expenses required at the expense of

237
00:09:48,399 --> 00:09:51,040
lower search performance

238
00:09:51,040 --> 00:09:52,560
as expected

239
00:09:52,560 --> 00:09:54,959
using all space optimizations combined

240
00:09:54,959 --> 00:09:57,200
to the purple line here the rx achieves

241
00:09:57,200 --> 00:10:00,320
the best compression result

242
00:10:01,360 --> 00:10:04,320
to summarize represented yarix a yara

243
00:10:04,320 --> 00:10:06,320
engine that scales to a large number of

244
00:10:06,320 --> 00:10:07,920
bioware samples

245
00:10:07,920 --> 00:10:09,920
the rx extracts searchable terms from

246
00:10:09,920 --> 00:10:11,920
yara signatures and converts them into

247
00:10:11,920 --> 00:10:13,440
an asd

248
00:10:13,440 --> 00:10:15,760
its underlying reverse file index helps

249
00:10:15,760 --> 00:10:18,560
to find candidate fast effectively

250
00:10:18,560 --> 00:10:21,839
speeding up over 5 orders of magnitude

251
00:10:21,839 --> 00:10:24,720
compared to sequentially our skins

252
00:10:24,720 --> 00:10:26,959
we release the rx as open source tool

253
00:10:26,959 --> 00:10:29,920
and invite everyone for contributions

254
00:10:29,920 --> 00:10:31,279
thanks for your attention i'm happy to

255
00:10:31,279 --> 00:10:33,839
take questions

