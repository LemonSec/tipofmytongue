1
00:00:09,040 --> 00:00:10,719
hello everyone i'm shiwen lee from

2
00:00:10,719 --> 00:00:13,120
colombia university today i'm going to

3
00:00:13,120 --> 00:00:15,280
present our work about verifying a

4
00:00:15,280 --> 00:00:18,480
commodity multiprocessor kvm hypervisor

5
00:00:18,480 --> 00:00:20,560
computation is shifting to the cloud

6
00:00:20,560 --> 00:00:22,400
cloud computing is supported by a

7
00:00:22,400 --> 00:00:24,480
technology called virtualization which

8
00:00:24,480 --> 00:00:26,560
enables multiple virtual machines to run

9
00:00:26,560 --> 00:00:28,400
on a single piece of hardware

10
00:00:28,400 --> 00:00:30,240
virtualization relies on a privileged

11
00:00:30,240 --> 00:00:32,320
software called hypervisor to manage the

12
00:00:32,320 --> 00:00:34,559
virtual machines and resources

13
00:00:34,559 --> 00:00:36,399
to satisfy the requirement of cloud

14
00:00:36,399 --> 00:00:38,320
computing workloads for performance and

15
00:00:38,320 --> 00:00:40,879
functionality hypervisors are becoming

16
00:00:40,879 --> 00:00:43,520
increasingly complicated many commodity

17
00:00:43,520 --> 00:00:45,600
hypervisors include a full operating

18
00:00:45,600 --> 00:00:47,680
system kernel to reuse its existing

19
00:00:47,680 --> 00:00:48,879
functionality

20
00:00:48,879 --> 00:00:51,039
the increasing complexity in hypervisors

21
00:00:51,039 --> 00:00:53,039
also results in more bugs

22
00:00:53,039 --> 00:00:55,039
attackers that exploit vulnerabilities

23
00:00:55,039 --> 00:00:57,039
in the hypervisor codebase can gain full

24
00:00:57,039 --> 00:00:59,039
access to all hosts avm's data

25
00:00:59,039 --> 00:01:01,079
potentially compromising the vm users

26
00:01:01,079 --> 00:01:03,680
confidentiality and integrity

27
00:01:03,680 --> 00:01:06,000
formal verification offers a solution to

28
00:01:06,000 --> 00:01:08,400
improve hypervisor security by proving

29
00:01:08,400 --> 00:01:10,320
that a hypervisor is implemented

30
00:01:10,320 --> 00:01:11,680
correctly and contains no

31
00:01:11,680 --> 00:01:14,000
vulnerabilities in general formal

32
00:01:14,000 --> 00:01:16,240
verification involves three components

33
00:01:16,240 --> 00:01:18,320
first the implementation of the program

34
00:01:18,320 --> 00:01:20,400
second the specification that specifies

35
00:01:20,400 --> 00:01:22,400
the behaviors of the program and third

36
00:01:22,400 --> 00:01:24,000
the hardware model that defines the

37
00:01:24,000 --> 00:01:26,400
machine interface verification involves

38
00:01:26,400 --> 00:01:28,159
proving the implementation running on

39
00:01:28,159 --> 00:01:29,840
the hardware model satisfies the

40
00:01:29,840 --> 00:01:32,240
specification the soundness of the proof

41
00:01:32,240 --> 00:01:34,320
relies on the accuracy of the hardware

42
00:01:34,320 --> 00:01:35,520
model

43
00:01:35,520 --> 00:01:37,759
previous systems such as seo4 and

44
00:01:37,759 --> 00:01:40,320
certicos were verified using overly

45
00:01:40,320 --> 00:01:42,159
simplistic hardware models without

46
00:01:42,159 --> 00:01:44,720
features such as tlbs their proofs may

47
00:01:44,720 --> 00:01:46,799
not hold on real multi-processor server

48
00:01:46,799 --> 00:01:49,439
hardware more complex models do exist

49
00:01:49,439 --> 00:01:51,040
but they have not been shown to be

50
00:01:51,040 --> 00:01:53,439
feasible to verify real software

51
00:01:53,439 --> 00:01:55,439
to address this problem we introduced a

52
00:01:55,439 --> 00:01:57,840
new approach to verify real software on

53
00:01:57,840 --> 00:02:00,159
real hardware we introduced a layered

54
00:02:00,159 --> 00:02:02,399
hardware model that captures realistic

55
00:02:02,399 --> 00:02:04,560
hardware features yet is simple enough

56
00:02:04,560 --> 00:02:07,439
to be used to verify commodity software

57
00:02:07,439 --> 00:02:09,520
layering tailors the hardware model to

58
00:02:09,520 --> 00:02:10,959
the software needs

59
00:02:10,959 --> 00:02:12,720
software layers that use low-level

60
00:02:12,720 --> 00:02:14,879
hardware features are verified using a

61
00:02:14,879 --> 00:02:16,720
more detailed hardware model that

62
00:02:16,720 --> 00:02:18,400
includes all the various hardware

63
00:02:18,400 --> 00:02:21,040
features such as model a software layers

64
00:02:21,040 --> 00:02:23,200
that do not rely on low-level hardware

65
00:02:23,200 --> 00:02:25,280
features can be verified using a

66
00:02:25,280 --> 00:02:27,680
simplified abstract hardware model such

67
00:02:27,680 --> 00:02:30,400
as model b so long as we can prove that

68
00:02:30,400 --> 00:02:32,560
the software using the simplified model

69
00:02:32,560 --> 00:02:34,640
is equivalent to the software using the

70
00:02:34,640 --> 00:02:36,879
detailed low-level model

71
00:02:36,879 --> 00:02:38,560
we used the layered tower model to

72
00:02:38,560 --> 00:02:41,040
verify a commodity multiprocessor

73
00:02:41,040 --> 00:02:44,000
hypervisor we built on our previous work

74
00:02:44,000 --> 00:02:46,560
sckvn that verified a multi-processor

75
00:02:46,560 --> 00:02:49,200
kvm hypervisor to ensure that

76
00:02:49,200 --> 00:02:51,440
vms proofs hold on the multiprocessor

77
00:02:51,440 --> 00:02:53,840
server hardware used in the cloud

78
00:02:53,840 --> 00:02:56,959
to verify kvm sdk vm leverages arm

79
00:02:56,959 --> 00:02:59,120
virtualization extensions and retrofits

80
00:02:59,120 --> 00:03:01,840
kvm into a small k core and a large set

81
00:03:01,840 --> 00:03:04,480
of hypervisor services k-serve such that

82
00:03:04,480 --> 00:03:07,280
we can verify the entire kvm hypervisor

83
00:03:07,280 --> 00:03:09,920
by reasoning about just k-core

84
00:03:09,920 --> 00:03:12,000
we structure k-core's implementation as

85
00:03:12,000 --> 00:03:14,000
a hierarchy of layered modules that

86
00:03:14,000 --> 00:03:16,239
build upon the hardware and each other

87
00:03:16,239 --> 00:03:18,400
we construct the k-core and layered

88
00:03:18,400 --> 00:03:20,879
model to match each respective layer to

89
00:03:20,879 --> 00:03:23,519
an appropriately abstract machine model

90
00:03:23,519 --> 00:03:25,280
we describe how we use the layered

91
00:03:25,280 --> 00:03:28,080
hardware model to verify sckvm's plb

92
00:03:28,080 --> 00:03:30,560
management pov caches page table

93
00:03:30,560 --> 00:03:32,159
translations to improve paging

94
00:03:32,159 --> 00:03:34,959
performance arm's tob is tagged so the

95
00:03:34,959 --> 00:03:37,120
software does not need to flush the tlb

96
00:03:37,120 --> 00:03:39,840
when switching cpu execution however the

97
00:03:39,840 --> 00:03:41,840
software needs to flush the tob when

98
00:03:41,840 --> 00:03:44,080
page tables are updated

99
00:03:44,080 --> 00:03:46,400
correct tov management is crucial as a

100
00:03:46,400 --> 00:03:49,280
bug can break isolation among vms for

101
00:03:49,280 --> 00:03:51,599
example consider the scenario in which

102
00:03:51,599 --> 00:03:54,159
the tlb caches mapping from a guest

103
00:03:54,159 --> 00:03:56,720
physical page gfm1 to a physical page

104
00:03:56,720 --> 00:04:00,640
pfn1 suppose k-core unmaps pfm1 from vma

105
00:04:00,640 --> 00:04:03,599
and maxes to vmb it needs to make sure

106
00:04:03,599 --> 00:04:05,760
to flush the tob properly after the

107
00:04:05,760 --> 00:04:07,840
unmapped but if it instead flushes the

108
00:04:07,840 --> 00:04:10,159
tlb before the arm map a problem can

109
00:04:10,159 --> 00:04:11,280
occur

110
00:04:11,280 --> 00:04:14,080
a multiprocessor vm like vma uses the

111
00:04:14,080 --> 00:04:16,880
same stage 2 page table on multiple cpus

112
00:04:16,880 --> 00:04:20,320
vma running on cpu 1 accesses pfm1 after

113
00:04:20,320 --> 00:04:22,960
the tlb flash at time t1 the axis

114
00:04:22,960 --> 00:04:24,960
results in the hardware refilling the

115
00:04:24,960 --> 00:04:27,360
entry for psn1 from the page table to

116
00:04:27,360 --> 00:04:28,720
pov

117
00:04:28,720 --> 00:04:31,840
vma can access pfm1 through the tob even

118
00:04:31,840 --> 00:04:34,960
after k core unmapped the pfn from vmas

119
00:04:34,960 --> 00:04:37,360
page table and matches to vmv

120
00:04:37,360 --> 00:04:40,000
this breaks vm isolation to protect vm's

121
00:04:40,000 --> 00:04:42,720
security k-core must flush the tlb after

122
00:04:42,720 --> 00:04:44,400
updating patients

123
00:04:44,400 --> 00:04:46,400
our layered hardware model captures

124
00:04:46,400 --> 00:04:49,040
tagged tlb behaviors and operations so

125
00:04:49,040 --> 00:04:50,960
we can verify the k port layer that

126
00:04:50,960 --> 00:04:54,000
manages pov does so correctly since the

127
00:04:54,000 --> 00:04:56,160
tob is just a cache of page table

128
00:04:56,160 --> 00:04:58,800
mappings if it is correctly managed we

129
00:04:58,800 --> 00:05:00,880
can refine the complex model with the

130
00:05:00,880 --> 00:05:03,199
dobs and page tables of the slower

131
00:05:03,199 --> 00:05:05,840
layers to a simpler model that only

132
00:05:05,840 --> 00:05:07,600
includes the page tables at higher

133
00:05:07,600 --> 00:05:09,520
layers this would reduce the proof

134
00:05:09,520 --> 00:05:11,520
burden because we can then use the

135
00:05:11,520 --> 00:05:14,000
simpler model that hides the dob to

136
00:05:14,000 --> 00:05:16,240
verify the higher layers of k4 that do

137
00:05:16,240 --> 00:05:18,560
not manage the tovs

138
00:05:18,560 --> 00:05:20,800
the intuition of our tob proof is that

139
00:05:20,800 --> 00:05:24,000
if the tob is not managed properly the

140
00:05:24,000 --> 00:05:26,080
pages that can be observed through the

141
00:05:26,080 --> 00:05:28,479
dob will be a superset of the pages

142
00:05:28,479 --> 00:05:30,720
observed through the page table as

143
00:05:30,720 --> 00:05:32,560
demonstrated in the buggy example we

144
00:05:32,560 --> 00:05:34,960
showed earlier the resulting top can

145
00:05:34,960 --> 00:05:37,440
either contain an earlier and the

146
00:05:37,440 --> 00:05:39,520
current version of the page tables the

147
00:05:39,520 --> 00:05:42,320
tob may include stale page table entries

148
00:05:42,320 --> 00:05:44,400
if the page table is updated but the

149
00:05:44,400 --> 00:05:46,720
respective pov entry is not flushed by

150
00:05:46,720 --> 00:05:48,240
the hypervisor

151
00:05:48,240 --> 00:05:50,720
we proved that the k core layer that can

152
00:05:50,720 --> 00:05:52,720
update page tables guarantee that the

153
00:05:52,720 --> 00:05:55,280
pages observable through the tob are the

154
00:05:55,280 --> 00:05:57,759
same as those in the page table to model

155
00:05:57,759 --> 00:06:00,400
such observations we introduce a concept

156
00:06:00,400 --> 00:06:02,720
of page observers to represent the set

157
00:06:02,720 --> 00:06:05,680
of all possible principles either vms or

158
00:06:05,680 --> 00:06:08,400
caser that can observe a physical page

159
00:06:08,400 --> 00:06:12,000
pfn through tobs or page tables we merge

160
00:06:12,000 --> 00:06:14,240
consecutive page observers that are the

161
00:06:14,240 --> 00:06:16,800
same into page of zero groups in the

162
00:06:16,800 --> 00:06:19,919
example here vma can observe pfm1

163
00:06:19,919 --> 00:06:22,479
through the tob and page table so the

164
00:06:22,479 --> 00:06:24,479
respective page observers and the

165
00:06:24,479 --> 00:06:28,160
observer groups for pfm1 include vma

166
00:06:28,160 --> 00:06:30,080
consider kcor executes the three

167
00:06:30,080 --> 00:06:32,319
follow-up steps shown on the left first

168
00:06:32,319 --> 00:06:34,800
k-core unmapped pfm1 from vmas page

169
00:06:34,800 --> 00:06:37,600
table the page observers for psn1 via

170
00:06:37,600 --> 00:06:39,680
page tables become null as a result of

171
00:06:39,680 --> 00:06:42,319
the page table on map the page observer

172
00:06:42,319 --> 00:06:44,400
groups for page table include the new

173
00:06:44,400 --> 00:06:47,360
null observer vma can still observe the

174
00:06:47,360 --> 00:06:50,160
psn through the tob after the unmapped

175
00:06:50,160 --> 00:06:53,360
so its page observers remain the same

176
00:06:53,360 --> 00:06:55,599
next k-core flushes the tlb for the

177
00:06:55,599 --> 00:06:58,319
entry that maps to psn1 the resulting

178
00:06:58,319 --> 00:07:00,479
page observers through pld become null

179
00:07:00,479 --> 00:07:03,440
after the dob flush and the dobs page

180
00:07:03,440 --> 00:07:05,199
observer groups include the new page

181
00:07:05,199 --> 00:07:06,479
observer

182
00:07:06,479 --> 00:07:09,360
finally k-core maps pfn1 to vmb's page

183
00:07:09,360 --> 00:07:11,759
table intuitively the resulting page

184
00:07:11,759 --> 00:07:13,280
observers will appear as a line through

185
00:07:13,280 --> 00:07:16,080
page table containing vmb so as the ones

186
00:07:16,080 --> 00:07:18,479
via tov the latter is because the

187
00:07:18,479 --> 00:07:21,120
translation to psn1 using dmv's updated

188
00:07:21,120 --> 00:07:23,919
page table can be cached in the tov the

189
00:07:23,919 --> 00:07:26,160
resulting page observer groups for dob

190
00:07:26,160 --> 00:07:28,319
and page table both include the new page

191
00:07:28,319 --> 00:07:31,360
of the ruby to prove that povs aren't

192
00:07:31,360 --> 00:07:33,680
maintained correctly by k-core we show

193
00:07:33,680 --> 00:07:35,759
that starting with the same page of

194
00:07:35,759 --> 00:07:38,000
several groups of povs and page tables

195
00:07:38,000 --> 00:07:40,080
the resulting page observer views

196
00:07:40,080 --> 00:07:42,560
produced by the executions are still the

197
00:07:42,560 --> 00:07:45,039
same based on this approach we verify

198
00:07:45,039 --> 00:07:47,280
that the example execution manages the

199
00:07:47,280 --> 00:07:49,039
tovs correctly

200
00:07:49,039 --> 00:07:51,199
we can also use this approach to detect

201
00:07:51,199 --> 00:07:53,919
incorrect management of tovs consider

202
00:07:53,919 --> 00:07:55,680
the buggy example that we discussed

203
00:07:55,680 --> 00:07:58,400
earlier since tob was not flushed after

204
00:07:58,400 --> 00:08:01,199
the unmapped both bma and b can observe

205
00:08:01,199 --> 00:08:04,160
pfo1 using the tob so they are thus

206
00:08:04,160 --> 00:08:06,000
included in the page observers for the

207
00:08:06,000 --> 00:08:08,400
pfn through glb the resulting page

208
00:08:08,400 --> 00:08:10,479
observer groups for tlb are different

209
00:08:10,479 --> 00:08:12,879
from the ones for page table this allows

210
00:08:12,879 --> 00:08:15,280
us to detect the bug

211
00:08:15,280 --> 00:08:17,120
we take the detailed model that accounts

212
00:08:17,120 --> 00:08:19,680
for tlb and multi-level page tables and

213
00:08:19,680 --> 00:08:21,840
verified that k-core's lower layer

214
00:08:21,840 --> 00:08:24,080
software with the model refines pay

215
00:08:24,080 --> 00:08:26,160
course higher layer software with a

216
00:08:26,160 --> 00:08:28,479
simpler abstract model that accounts for

217
00:08:28,479 --> 00:08:30,879
a flat map so that the higher layer

218
00:08:30,879 --> 00:08:32,958
software can rely on the simpler

219
00:08:32,958 --> 00:08:34,320
abstract model

220
00:08:34,320 --> 00:08:36,240
we take a similar approach in modeling

221
00:08:36,240 --> 00:08:37,919
other hardware features to capture

222
00:08:37,919 --> 00:08:40,640
realistic hardware behaviors details are

223
00:08:40,640 --> 00:08:42,880
presented in the paper for example while

224
00:08:42,880 --> 00:08:44,800
the detailed hardware model captures

225
00:08:44,800 --> 00:08:47,040
multi-level page tables the simpler

226
00:08:47,040 --> 00:08:48,959
abstract model can treat the page table

227
00:08:48,959 --> 00:08:52,480
as a simple single level map similarly

228
00:08:52,480 --> 00:08:54,480
multi-level caches can be treated as a

229
00:08:54,480 --> 00:08:56,320
single unified cache

230
00:08:56,320 --> 00:08:58,560
we use to implement the layer

231
00:08:58,560 --> 00:09:01,040
hardware model and verify sdk vm we

232
00:09:01,040 --> 00:09:02,560
proved the functional correctness of

233
00:09:02,560 --> 00:09:04,640
k-core's implementation which includes

234
00:09:04,640 --> 00:09:08,080
3.8 k lines of c and assembly code we

235
00:09:08,080 --> 00:09:09,760
prove that k-core's entire

236
00:09:09,760 --> 00:09:12,720
implementation modulized into 34 layers

237
00:09:12,720 --> 00:09:15,600
refines its specification in addition we

238
00:09:15,600 --> 00:09:17,920
use the layered hardware model to verify

239
00:09:17,920 --> 00:09:20,640
that sdk vm protects vm confidentiality

240
00:09:20,640 --> 00:09:22,560
and integrity is showing that the

241
00:09:22,560 --> 00:09:24,800
verified security properties hold on

242
00:09:24,800 --> 00:09:27,440
multi-processor server hardware

243
00:09:27,440 --> 00:09:29,360
we tested some of the commonly used

244
00:09:29,360 --> 00:09:31,279
server application workloads on arm

245
00:09:31,279 --> 00:09:34,160
server class hardware running sdk vm

246
00:09:34,160 --> 00:09:36,560
we run workloads on a vm using baseline

247
00:09:36,560 --> 00:09:39,600
kvm and sckem the results in the graph

248
00:09:39,600 --> 00:09:42,000
are normalized to bare metal execution

249
00:09:42,000 --> 00:09:44,560
so lower numbers mean better performance

250
00:09:44,560 --> 00:09:46,959
the results show modest overhead on sdk

251
00:09:46,959 --> 00:09:49,600
vm compared to unmodified kvm in

252
00:09:49,600 --> 00:09:52,080
addition we compared the performance of

253
00:09:52,080 --> 00:09:54,880
sdkvm versus sdkvm that flushes all

254
00:09:54,880 --> 00:09:56,800
entries from the dob and switches

255
00:09:56,800 --> 00:09:59,279
between the vm and hypervisor to

256
00:09:59,279 --> 00:10:01,279
measuring the performance impact of the

257
00:10:01,279 --> 00:10:03,279
verified implementation that models

258
00:10:03,279 --> 00:10:05,839
attack pld versus the one that models a

259
00:10:05,839 --> 00:10:08,079
simplified tlb without tagging

260
00:10:08,079 --> 00:10:09,839
as shown in the graph frequently

261
00:10:09,839 --> 00:10:12,079
flushing tobs incurs significant

262
00:10:12,079 --> 00:10:14,720
overhead through vm performance

263
00:10:14,720 --> 00:10:17,200
in conclusion we introduced a novel

264
00:10:17,200 --> 00:10:19,440
layered hardware model that is simple

265
00:10:19,440 --> 00:10:21,680
enough to be used for verifying real

266
00:10:21,680 --> 00:10:24,079
software while accounting for realistic

267
00:10:24,079 --> 00:10:26,399
multi-processor features we use the

268
00:10:26,399 --> 00:10:28,959
layer model to verify sdkvm a

269
00:10:28,959 --> 00:10:32,079
multiprocessor kvm implementation

270
00:10:32,079 --> 00:10:34,079
ensuring that the verified guarantees

271
00:10:34,079 --> 00:10:37,120
hold on multiprocessor server hardware

272
00:10:37,120 --> 00:10:39,519
the verified sdk vm implementation can

273
00:10:39,519 --> 00:10:42,000
thus take advantage of the widely used

274
00:10:42,000 --> 00:10:44,640
multi-processor features to retain kvm's

275
00:10:44,640 --> 00:10:47,200
overall feature set and performance

276
00:10:47,200 --> 00:10:49,040
that'll be all for my presentation

277
00:10:49,040 --> 00:10:50,880
thanks for listening i'm now happy to

278
00:10:50,880 --> 00:10:54,439
answer your questions

279
00:11:01,040 --> 00:11:03,120
you

