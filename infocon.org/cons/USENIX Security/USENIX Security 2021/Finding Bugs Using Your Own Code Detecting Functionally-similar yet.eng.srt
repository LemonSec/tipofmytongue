1
00:00:08,720 --> 00:00:10,800
have you ever thought if you could find

2
00:00:10,800 --> 00:00:13,519
bugs in your code by learning a model

3
00:00:13,519 --> 00:00:15,679
from your own code

4
00:00:15,679 --> 00:00:17,680
in this talk i'm going to present how

5
00:00:17,680 --> 00:00:19,680
machine learning can help you detect

6
00:00:19,680 --> 00:00:22,560
bugs in a code base without the need to

7
00:00:22,560 --> 00:00:25,439
any training data set

8
00:00:25,439 --> 00:00:28,000
my name is masur ahmadi and this is a

9
00:00:28,000 --> 00:00:30,400
joint work with my former colleagues

10
00:00:30,400 --> 00:00:32,719
reza ryan and like

11
00:00:32,719 --> 00:00:37,200
an online and northeastern university

12
00:00:38,000 --> 00:00:40,879
a set of code snippets are inconsistent

13
00:00:40,879 --> 00:00:43,680
if their semantics or logic are

14
00:00:43,680 --> 00:00:44,960
synonymous

15
00:00:44,960 --> 00:00:47,360
but some parts of the implementations

16
00:00:47,360 --> 00:00:50,160
differ in significant ways

17
00:00:50,160 --> 00:00:52,480
many bugs in software manifest and

18
00:00:52,480 --> 00:00:56,559
inconsistencies deviating from a number

19
00:00:56,559 --> 00:00:58,800
from number d counterparts

20
00:00:58,800 --> 00:01:00,719
there are two main factors that can

21
00:01:00,719 --> 00:01:03,920
introduce inconsistencies in a code base

22
00:01:03,920 --> 00:01:04,799
first

23
00:01:04,799 --> 00:01:06,720
large software usually has a

24
00:01:06,720 --> 00:01:09,439
commensurate number of developers which

25
00:01:09,439 --> 00:01:11,920
sometimes lead to implement lead to

26
00:01:11,920 --> 00:01:15,920
inconsistent implementations of the same

27
00:01:15,920 --> 00:01:20,240
functionality and during development

28
00:01:20,240 --> 00:01:22,400
the second common reason is when a

29
00:01:22,400 --> 00:01:25,119
workfix is applied only to where the

30
00:01:25,119 --> 00:01:27,840
part was originally discovered

31
00:01:27,840 --> 00:01:30,240
but not to other parts of the code with

32
00:01:30,240 --> 00:01:33,039
the same bug

33
00:01:33,280 --> 00:01:36,000
the high level idea of detecting bugs as

34
00:01:36,000 --> 00:01:39,520
deviations from normal code is not new

35
00:01:39,520 --> 00:01:42,079
the idea has been first introduced in

36
00:01:42,079 --> 00:01:43,920
2001

37
00:01:43,920 --> 00:01:45,920
and there has been a line of research

38
00:01:45,920 --> 00:01:47,360
after that

39
00:01:47,360 --> 00:01:51,200
however these works have two limitations

40
00:01:51,200 --> 00:01:53,520
first they were designed to detect only

41
00:01:53,520 --> 00:01:56,399
a specific types of inconsistencies such

42
00:01:56,399 --> 00:01:59,920
as those related to api usage or sanity

43
00:01:59,920 --> 00:02:01,040
checks

44
00:02:01,040 --> 00:02:03,200
and they cannot be easily extended to

45
00:02:03,200 --> 00:02:06,159
detect inconsistencies or bias in a type

46
00:02:06,159 --> 00:02:08,399
agnostic fashion

47
00:02:08,399 --> 00:02:11,680
second the prior approaches heavily rely

48
00:02:11,680 --> 00:02:14,000
on majority voting to determine

49
00:02:14,000 --> 00:02:16,640
inconsistencies

50
00:02:16,640 --> 00:02:20,000
and because because of the limitation in

51
00:02:20,000 --> 00:02:24,640
the the code constructs and definitions

52
00:02:25,120 --> 00:02:28,000
we propose a generic approach called fix

53
00:02:28,000 --> 00:02:31,040
to detect inconsistency induced bugs

54
00:02:31,040 --> 00:02:34,080
regardless of inconsistency types

55
00:02:34,080 --> 00:02:36,640
moreover our graph-based definition of

56
00:02:36,640 --> 00:02:38,879
code constructs carries additional

57
00:02:38,879 --> 00:02:41,440
context information which captures

58
00:02:41,440 --> 00:02:44,160
one-to-one inconsistencies

59
00:02:44,160 --> 00:02:46,239
this figure shows the high-level

60
00:02:46,239 --> 00:02:48,080
workflow of pix

61
00:02:48,080 --> 00:02:50,640
it starts by extracting coded snippets

62
00:02:50,640 --> 00:02:52,480
from a given code base

63
00:02:52,480 --> 00:02:54,959
it then performs a two-step clustering

64
00:02:54,959 --> 00:02:57,760
method which first group

65
00:02:57,760 --> 00:02:59,599
mixtures groups

66
00:02:59,599 --> 00:03:02,080
functionally similar parts of the code

67
00:03:02,080 --> 00:03:04,000
and then detects the deviations or

68
00:03:04,000 --> 00:03:06,400
inconsistencies among them

69
00:03:06,400 --> 00:03:09,040
finally the detected inconsistencies are

70
00:03:09,040 --> 00:03:11,680
presented to human analysts for body

71
00:03:11,680 --> 00:03:14,159
triage

72
00:03:14,720 --> 00:03:16,640
there are two principal challenges that

73
00:03:16,640 --> 00:03:19,920
need to be unsolved in in our design

74
00:03:19,920 --> 00:03:23,200
first finding a proper code granularity

75
00:03:23,200 --> 00:03:25,440
to effectively capture functionalities

76
00:03:25,440 --> 00:03:28,080
and inconsistencies and second making

77
00:03:28,080 --> 00:03:30,239
the approach scalable to handle large

78
00:03:30,239 --> 00:03:31,760
code bases

79
00:03:31,760 --> 00:03:33,680
to address the challenges we started

80
00:03:33,680 --> 00:03:36,080
with program dependency graph

81
00:03:36,080 --> 00:03:37,519
and program dependence graph

82
00:03:37,519 --> 00:03:38,959
representation

83
00:03:38,959 --> 00:03:41,360
as it's the most semantically

84
00:03:41,360 --> 00:03:44,959
comprehensive among the common program

85
00:03:44,959 --> 00:03:46,720
representations

86
00:03:46,720 --> 00:03:49,920
we omit control dependency edges as data

87
00:03:49,920 --> 00:03:52,400
dependencies alone are good enough to

88
00:03:52,400 --> 00:03:54,799
capture the root cause of a wide range

89
00:03:54,799 --> 00:03:56,000
of parts

90
00:03:56,000 --> 00:03:58,560
and this makes our approach

91
00:03:58,560 --> 00:04:01,280
scalable and efficient

92
00:04:01,280 --> 00:04:04,319
also we limit the the scope of analysis

93
00:04:04,319 --> 00:04:06,799
between individual functions

94
00:04:06,799 --> 00:04:09,840
um given that bugs and the patches are

95
00:04:09,840 --> 00:04:13,200
often contained in a single function

96
00:04:13,200 --> 00:04:16,079
to make the approach even more scalable

97
00:04:16,079 --> 00:04:18,798
we and the first step clustering should

98
00:04:18,798 --> 00:04:21,358
be somewhat coarse grain

99
00:04:21,358 --> 00:04:24,560
um because we need to cluster hundreds

100
00:04:24,560 --> 00:04:25,919
of thousands

101
00:04:25,919 --> 00:04:28,919
graphs

102
00:04:29,440 --> 00:04:32,639
fix first compiles a given code recency

103
00:04:32,639 --> 00:04:34,880
into llvm bit codes

104
00:04:34,880 --> 00:04:38,240
it then employs an intra procedural data

105
00:04:38,240 --> 00:04:41,040
flow analysis to extract small code

106
00:04:41,040 --> 00:04:43,919
pieces referred to as constructs from

107
00:04:43,919 --> 00:04:45,759
each function

108
00:04:45,759 --> 00:04:48,320
after extracting constructs fix

109
00:04:48,320 --> 00:04:49,600
abstracts

110
00:04:49,600 --> 00:04:51,759
the constructs to a generic form

111
00:04:51,759 --> 00:04:53,280
amenable to the

112
00:04:53,280 --> 00:04:56,840
two-step clustering

113
00:04:57,440 --> 00:05:00,080
and the construct

114
00:05:00,080 --> 00:05:02,479
the construct extraction starts from a

115
00:05:02,479 --> 00:05:04,960
specific node and traverse the data

116
00:05:04,960 --> 00:05:08,240
dependence graph until all subsequent

117
00:05:08,240 --> 00:05:10,320
nodes are covered

118
00:05:10,320 --> 00:05:12,800
any variable used in a function can be

119
00:05:12,800 --> 00:05:15,520
selected as the root variable and for

120
00:05:15,520 --> 00:05:17,600
exactly a construct for example it can

121
00:05:17,600 --> 00:05:20,240
be local variable global variable

122
00:05:20,240 --> 00:05:22,960
or even function arguments

123
00:05:22,960 --> 00:05:26,160
here is a simple example the first graph

124
00:05:26,160 --> 00:05:28,720
shows the full construct for the data

125
00:05:28,720 --> 00:05:32,800
variable in the c code example

126
00:05:32,800 --> 00:05:35,840
and the second graph is the construct

127
00:05:35,840 --> 00:05:38,160
for the first basic block and it is

128
00:05:38,160 --> 00:05:41,199
indeed the first sub graph

129
00:05:41,199 --> 00:05:44,240
of the first graph

130
00:05:44,960 --> 00:05:47,280
after we extracted constructs in

131
00:05:47,280 --> 00:05:49,759
abstract form we designed a two-step

132
00:05:49,759 --> 00:05:52,639
clustering procedure to first group

133
00:05:52,639 --> 00:05:55,199
similar constructs and then identify

134
00:05:55,199 --> 00:05:58,080
inconsistent constructs or outliers in

135
00:05:58,080 --> 00:05:59,520
each group

136
00:05:59,520 --> 00:06:02,400
for the first step clustering only node

137
00:06:02,400 --> 00:06:05,600
labels in constructs or abstracted libm

138
00:06:05,600 --> 00:06:08,160
instructions are considered

139
00:06:08,160 --> 00:06:10,560
and each construct is embedded into a

140
00:06:10,560 --> 00:06:11,919
note vector

141
00:06:11,919 --> 00:06:14,960
where the index is the instruction id

142
00:06:14,960 --> 00:06:17,120
and the value is the number of times the

143
00:06:17,120 --> 00:06:20,400
instruction appears in the graph to

144
00:06:20,400 --> 00:06:22,720
quantify the similarity between pair of

145
00:06:22,720 --> 00:06:24,960
constructs we calculate the cosine

146
00:06:24,960 --> 00:06:29,359
similarity between um

147
00:06:29,520 --> 00:06:31,680
their corresponding bag of nodes and

148
00:06:31,680 --> 00:06:34,960
back of node embeddings

149
00:06:34,960 --> 00:06:37,440
after computing cosine similarity for

150
00:06:37,440 --> 00:06:40,000
each pair of constructs we feed the

151
00:06:40,000 --> 00:06:42,560
pairwise similarity scores into the

152
00:06:42,560 --> 00:06:45,840
clustering algorithm

153
00:06:46,000 --> 00:06:48,720
here is an example of the stack based

154
00:06:48,720 --> 00:06:50,319
offer overflow

155
00:06:50,319 --> 00:06:52,800
when the check on data is missing the

156
00:06:52,800 --> 00:06:55,360
cosine similarity between the buggy and

157
00:06:55,360 --> 00:06:58,160
correct constructs is calculated based

158
00:06:58,160 --> 00:07:00,560
on the back of node embeddings

159
00:07:00,560 --> 00:07:03,840
so here the the computed um similarity

160
00:07:03,840 --> 00:07:06,960
score is 0.96

161
00:07:06,960 --> 00:07:08,800
and which shows that

162
00:07:08,800 --> 00:07:12,080
that that the two constructs are similar

163
00:07:12,080 --> 00:07:15,440
with subtle differences

164
00:07:15,520 --> 00:07:17,520
while our bag of node embeddings

165
00:07:17,520 --> 00:07:20,319
suitable is uh suitable for

166
00:07:20,319 --> 00:07:22,880
uh core screen clustering it does not

167
00:07:22,880 --> 00:07:24,720
meet the needs for the second step

168
00:07:24,720 --> 00:07:27,039
clustering and this is because it does

169
00:07:27,039 --> 00:07:29,440
not consider edges and constructs and

170
00:07:29,440 --> 00:07:32,160
thus cannot fully capture the structure

171
00:07:32,160 --> 00:07:33,840
of the constructs

172
00:07:33,840 --> 00:07:36,880
so we use graph to work

173
00:07:36,880 --> 00:07:39,199
embedding for the second step clustering

174
00:07:39,199 --> 00:07:41,360
to model both local and global

175
00:07:41,360 --> 00:07:44,479
similarities among graphs similar to the

176
00:07:44,479 --> 00:07:46,639
first step velocity we calculate

177
00:07:46,639 --> 00:07:50,160
similarity and cosine and similarity and

178
00:07:50,160 --> 00:07:52,400
feed the pairwise similarity scores into

179
00:07:52,400 --> 00:07:55,520
the clustering algorithm

180
00:07:55,520 --> 00:07:57,680
the output of the two-step clustering

181
00:07:57,680 --> 00:07:59,680
contains similar but inconsistent

182
00:07:59,680 --> 00:08:02,319
construct however not all of them are

183
00:08:02,319 --> 00:08:05,680
harmful bugs the deviation analysis

184
00:08:05,680 --> 00:08:08,479
helps fix users with the detected

185
00:08:08,479 --> 00:08:12,560
inconsistencies to quickly identify bugs

186
00:08:12,560 --> 00:08:15,360
most bugs are due to missing or extra

187
00:08:15,360 --> 00:08:16,800
code fragments

188
00:08:16,800 --> 00:08:18,160
such as

189
00:08:18,160 --> 00:08:20,240
drawing or missing checks or even

190
00:08:20,240 --> 00:08:21,840
missing the variable

191
00:08:21,840 --> 00:08:24,960
or even missing variable initializations

192
00:08:24,960 --> 00:08:27,440
for example if an analyst

193
00:08:27,440 --> 00:08:30,240
needs to find null pointer the reference

194
00:08:30,240 --> 00:08:33,440
box he needs to check icmp llbm

195
00:08:33,440 --> 00:08:35,760
instruction inconsistencies

196
00:08:35,760 --> 00:08:39,599
the deviation analysis allows analysts

197
00:08:39,599 --> 00:08:42,958
to focus on high priority inconsistency

198
00:08:42,958 --> 00:08:45,360
or high likely bugs

199
00:08:45,360 --> 00:08:47,440
the filtering is the

200
00:08:47,440 --> 00:08:49,440
step on the other hand removes the

201
00:08:49,440 --> 00:08:51,440
inconsistencies that are redundant or

202
00:08:51,440 --> 00:08:52,880
likely false

203
00:08:52,880 --> 00:08:56,959
for example if a detected inconsistency

204
00:08:56,959 --> 00:08:59,760
involves several missing if conditions

205
00:08:59,760 --> 00:09:02,080
the inconsistency is less likely to be

206
00:09:02,080 --> 00:09:04,880
true or bark because it is rare that

207
00:09:04,880 --> 00:09:07,600
developers forget multiple different

208
00:09:07,600 --> 00:09:11,360
checks in a small chunk of code

209
00:09:11,680 --> 00:09:15,680
we evaluated fix on five real code bases

210
00:09:15,680 --> 00:09:17,120
the experiment

211
00:09:17,120 --> 00:09:19,360
examine if fixed can find previously

212
00:09:19,360 --> 00:09:22,640
unknown inconsistency in the use bugs in

213
00:09:22,640 --> 00:09:25,680
both small and large code bases

214
00:09:25,680 --> 00:09:28,920
fix supported the total number of um

215
00:09:28,920 --> 00:09:30,480
1800-ish

216
00:09:30,480 --> 00:09:32,240
coding consistencies

217
00:09:32,240 --> 00:09:34,959
and we manually wetted all of them

218
00:09:34,959 --> 00:09:37,120
and and found

219
00:09:37,120 --> 00:09:41,040
280 of them to be valid inconsistencies

220
00:09:41,040 --> 00:09:43,600
um amount in 95

221
00:09:43,600 --> 00:09:46,880
are code smells and 121

222
00:09:46,880 --> 00:09:49,920
are potential bugs we have reported 36

223
00:09:49,920 --> 00:09:51,839
of them to original developers and

224
00:09:51,839 --> 00:09:54,640
received 22 confirmations

225
00:09:54,640 --> 00:09:56,640
the manual vetting effort is not as

226
00:09:56,640 --> 00:09:59,920
heavily it's not as heavy as required to

227
00:09:59,920 --> 00:10:02,399
validate results from many other static

228
00:10:02,399 --> 00:10:04,000
analyzers

229
00:10:04,000 --> 00:10:06,640
the ease of manual

230
00:10:06,640 --> 00:10:07,680
manual

231
00:10:07,680 --> 00:10:10,640
validation of fixed reports is largely

232
00:10:10,640 --> 00:10:13,360
due to the presence of both consistent

233
00:10:13,360 --> 00:10:15,680
and inconsistent constructs and the

234
00:10:15,680 --> 00:10:19,319
highlighted differences

235
00:10:19,680 --> 00:10:21,920
also we compare fixed with three related

236
00:10:21,920 --> 00:10:26,320
populators api san larsan creeks we use

237
00:10:26,320 --> 00:10:30,160
a 22 confirm developer confirm box

238
00:10:30,160 --> 00:10:33,360
as the ground truth and apply the three

239
00:10:33,360 --> 00:10:36,399
detectors to the code bases api sign

240
00:10:36,399 --> 00:10:38,800
produced more than 18 000 reports and

241
00:10:38,800 --> 00:10:42,480
found four of them error sam and greeks

242
00:10:42,480 --> 00:10:45,200
each found only one of the 22 parts but

243
00:10:45,200 --> 00:10:48,560
they repo but they are really fast and

244
00:10:48,560 --> 00:10:53,040
they reported much much fewer cases

245
00:10:53,440 --> 00:10:55,680
to summarize fix is the first

246
00:10:55,680 --> 00:10:57,519
inconsistency generic

247
00:10:57,519 --> 00:11:00,720
um ml based permutation system that

248
00:11:00,720 --> 00:11:04,320
learns from the to be checked and code

249
00:11:04,320 --> 00:11:07,040
base and identifies um coding

250
00:11:07,040 --> 00:11:09,279
consistencies our approach does not

251
00:11:09,279 --> 00:11:12,240
require external data sets for training

252
00:11:12,240 --> 00:11:14,399
and it's not limited to certain types of

253
00:11:14,399 --> 00:11:16,079
bugs

254
00:11:16,079 --> 00:11:18,320
we applied fix to five popular well

255
00:11:18,320 --> 00:11:22,640
tested open source projects and found 22

256
00:11:22,640 --> 00:11:25,200
previously unknown box

257
00:11:25,200 --> 00:11:27,360
there are a couple of limitations if the

258
00:11:27,360 --> 00:11:29,920
size of the codebase is too small or the

259
00:11:29,920 --> 00:11:32,240
bugs are one-liners it is less likely

260
00:11:32,240 --> 00:11:34,640
that the fix can find them

261
00:11:34,640 --> 00:11:37,519
also our research prototype

262
00:11:37,519 --> 00:11:40,000
neither supports c plus plus nor

263
00:11:40,000 --> 00:11:43,279
extremely large code bases like linux

264
00:11:43,279 --> 00:11:45,279
and is the limitation in the

265
00:11:45,279 --> 00:11:48,000
implementation

266
00:11:48,000 --> 00:11:51,959
thank you all for your attention

267
00:11:57,680 --> 00:11:59,760
you

