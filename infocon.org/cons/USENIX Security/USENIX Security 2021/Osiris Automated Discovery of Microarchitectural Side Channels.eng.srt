1
00:00:08,000 --> 00:00:10,080
hello everybody i'm daniel and today i'm

2
00:00:10,080 --> 00:00:12,000
going to present to you a research paper

3
00:00:12,000 --> 00:00:13,759
cyrus automated discovery of

4
00:00:13,759 --> 00:00:16,320
microarchitectural side shoulders our

5
00:00:16,320 --> 00:00:19,199
research focuses to support cpu vendors

6
00:00:19,199 --> 00:00:20,560
and researchers

7
00:00:20,560 --> 00:00:22,880
in finding side channels in modern cpus

8
00:00:22,880 --> 00:00:24,640
but before we dive deeper into that

9
00:00:24,640 --> 00:00:26,080
let's take a look at where we started

10
00:00:26,080 --> 00:00:28,640
our project in the first place

11
00:00:28,640 --> 00:00:30,640
so from today's point of view we know

12
00:00:30,640 --> 00:00:32,960
for many years that side channel attacks

13
00:00:32,960 --> 00:00:35,040
or micro architectural side channel

14
00:00:35,040 --> 00:00:37,360
attacks pose a severe threat on modern

15
00:00:37,360 --> 00:00:39,600
systems for example you can use such

16
00:00:39,600 --> 00:00:41,120
side channels such as flush and reload

17
00:00:41,120 --> 00:00:43,280
or private probe for example to attack

18
00:00:43,280 --> 00:00:45,039
otherwise secure implementations of

19
00:00:45,039 --> 00:00:47,680
cryptographic protocols such as rsa or

20
00:00:47,680 --> 00:00:48,800
aes

21
00:00:48,800 --> 00:00:51,199
and not only that but since 2018 we know

22
00:00:51,199 --> 00:00:52,879
about transient execution attacks such

23
00:00:52,879 --> 00:00:55,039
as spectre and meltdown and they also

24
00:00:55,039 --> 00:00:57,680
require on side channels to work but the

25
00:00:57,680 --> 00:00:59,520
problem that still arises is that most

26
00:00:59,520 --> 00:01:01,840
side channels we know by today are the

27
00:01:01,840 --> 00:01:03,760
result of a very time consuming and

28
00:01:03,760 --> 00:01:05,760
labor intensive process as the

29
00:01:05,760 --> 00:01:08,000
researchers often spend days or even

30
00:01:08,000 --> 00:01:10,000
weeks reading through patents and

31
00:01:10,000 --> 00:01:12,159
manuals to eventually come up with the

32
00:01:12,159 --> 00:01:15,040
idea of one such side channel

33
00:01:15,040 --> 00:01:18,080
and our research now supports

34
00:01:18,080 --> 00:01:22,000
the goal of automating this research by

35
00:01:22,000 --> 00:01:24,080
fuzzing for such sideshow notes and the

36
00:01:24,080 --> 00:01:25,680
idea is that instead of fuzzing some

37
00:01:25,680 --> 00:01:27,680
software application we fast the

38
00:01:27,680 --> 00:01:30,320
underlying cpu hardware directly

39
00:01:30,320 --> 00:01:32,640
but to understand how we can do so

40
00:01:32,640 --> 00:01:34,479
we first need to understand how such a

41
00:01:34,479 --> 00:01:36,640
side channel actually looks like and for

42
00:01:36,640 --> 00:01:38,159
this here only slide you can see the

43
00:01:38,159 --> 00:01:40,079
side channel flash and reload which

44
00:01:40,079 --> 00:01:42,320
encodes information inside the cpu cache

45
00:01:42,320 --> 00:01:44,560
and later on decodes it again

46
00:01:44,560 --> 00:01:46,960
and to do so flush and reload first

47
00:01:46,960 --> 00:01:49,520
removes some memory address from the cpu

48
00:01:49,520 --> 00:01:51,759
cache so that it's no longer cached and

49
00:01:51,759 --> 00:01:54,560
accessing it is quite slow and then

50
00:01:54,560 --> 00:01:57,040
afterwards eventually we access our

51
00:01:57,040 --> 00:01:59,360
memory address again and for now let's

52
00:01:59,360 --> 00:02:01,360
say if we want to encode a zero bit we

53
00:02:01,360 --> 00:02:03,360
do not access it but if we want to

54
00:02:03,360 --> 00:02:06,479
encode a one bit we access it again

55
00:02:06,479 --> 00:02:09,440
and in our third sequence we then time

56
00:02:09,440 --> 00:02:11,520
and access to this memory address and

57
00:02:11,520 --> 00:02:13,280
what we observe now looks basically like

58
00:02:13,280 --> 00:02:15,040
the following so

59
00:02:15,040 --> 00:02:18,480
if the first axis in our second sequence

60
00:02:18,480 --> 00:02:21,440
was not there then we observe a cache

61
00:02:21,440 --> 00:02:24,640
miss as our memory was previously flash

62
00:02:24,640 --> 00:02:27,360
so our timings up to 200 cycles but if

63
00:02:27,360 --> 00:02:28,239
it's

64
00:02:28,239 --> 00:02:30,640
um but if this access is actually

65
00:02:30,640 --> 00:02:31,760
happened

66
00:02:31,760 --> 00:02:34,080
because we wanted to encode one

67
00:02:34,080 --> 00:02:36,319
then we see that our axis is much faster

68
00:02:36,319 --> 00:02:37,519
and we can actually distinguish that

69
00:02:37,519 --> 00:02:40,080
with a very precise timer by that we can

70
00:02:40,080 --> 00:02:42,800
decode and encode our information inside

71
00:02:42,800 --> 00:02:45,360
the cpu cache if you now take a look at

72
00:02:45,360 --> 00:02:47,200
similar such side channels you start

73
00:02:47,200 --> 00:02:49,920
seeing some similarities between them

74
00:02:49,920 --> 00:02:52,959
more precisely we defer to them

75
00:02:52,959 --> 00:02:54,959
as consisting of three different

76
00:02:54,959 --> 00:02:56,239
sequences

77
00:02:56,239 --> 00:02:58,640
our first sequence is the so-called

78
00:02:58,640 --> 00:03:01,280
reset sequence as we reset our cpu

79
00:03:01,280 --> 00:03:03,519
component to a known state in this case

80
00:03:03,519 --> 00:03:04,800
this data is

81
00:03:04,800 --> 00:03:06,879
our memory address is no longer in the

82
00:03:06,879 --> 00:03:08,319
cpu cache

83
00:03:08,319 --> 00:03:10,080
in our second sequence then we

84
00:03:10,080 --> 00:03:12,560
eventually trigger a change in this

85
00:03:12,560 --> 00:03:13,599
state

86
00:03:13,599 --> 00:03:15,760
so in this case if our trigger sequence

87
00:03:15,760 --> 00:03:18,400
is executed we trigger the state change

88
00:03:18,400 --> 00:03:22,239
to the memory address is in our nd cache

89
00:03:22,239 --> 00:03:24,239
and our third sequence then

90
00:03:24,239 --> 00:03:26,319
times some

91
00:03:26,319 --> 00:03:28,480
time some memory addresses or for

92
00:03:28,480 --> 00:03:29,920
example um

93
00:03:29,920 --> 00:03:32,080
other instructions and based on this

94
00:03:32,080 --> 00:03:34,480
timing we observe whether or not the

95
00:03:34,480 --> 00:03:37,120
trigger sequence was previously executed

96
00:03:37,120 --> 00:03:38,480
and if your visualize is a little bit

97
00:03:38,480 --> 00:03:40,080
different you see the very interesting

98
00:03:40,080 --> 00:03:41,599
part about this

99
00:03:41,599 --> 00:03:43,599
is that we can abstract away from all

100
00:03:43,599 --> 00:03:46,000
these details of for example the cpu

101
00:03:46,000 --> 00:03:47,920
cache we can just

102
00:03:47,920 --> 00:03:49,680
say that our microarchitecture cpu

103
00:03:49,680 --> 00:03:52,159
component is just consisting of two

104
00:03:52,159 --> 00:03:55,040
different states namely s0 and s1 for

105
00:03:55,040 --> 00:03:57,200
encoding a zero bit when coding a one

106
00:03:57,200 --> 00:03:58,640
bit

107
00:03:58,640 --> 00:04:00,560
and now our reset sequence just brings

108
00:04:00,560 --> 00:04:03,200
us back to our state s0 and our trigger

109
00:04:03,200 --> 00:04:06,560
sequence brings us back to our state s1

110
00:04:06,560 --> 00:04:09,120
and the very nice thing there is

111
00:04:09,120 --> 00:04:10,879
that if our measurement sequence can

112
00:04:10,879 --> 00:04:12,560
actually tell us whether or not we're

113
00:04:12,560 --> 00:04:14,560
currently in state as one or a zero we

114
00:04:14,560 --> 00:04:16,959
can encode one bit of information not

115
00:04:16,959 --> 00:04:18,079
only that

116
00:04:18,079 --> 00:04:20,238
but given three arbitrary sequences we

117
00:04:20,238 --> 00:04:22,960
can actually test whether they form

118
00:04:22,960 --> 00:04:25,919
such a side channel or not and to do so

119
00:04:25,919 --> 00:04:29,199
we just execute the reset sequence first

120
00:04:29,199 --> 00:04:30,960
followed by the measurement sequence so

121
00:04:30,960 --> 00:04:32,720
this then basically gives us the timing

122
00:04:32,720 --> 00:04:35,040
of our state as zero or what you can

123
00:04:35,040 --> 00:04:38,160
also call it like our called path

124
00:04:38,160 --> 00:04:40,160
then in our second case we execute the

125
00:04:40,160 --> 00:04:41,919
reset sequence again but this time we

126
00:04:41,919 --> 00:04:44,160
follow it by the trigger sequence so now

127
00:04:44,160 --> 00:04:46,479
we have the timing of our state as 1 or

128
00:04:46,479 --> 00:04:48,400
our hot path

129
00:04:48,400 --> 00:04:49,840
and if those two timings are actually

130
00:04:49,840 --> 00:04:51,840
distinguishable we can report them as a

131
00:04:51,840 --> 00:04:53,680
working side channel and to give you an

132
00:04:53,680 --> 00:04:55,360
example of that

133
00:04:55,360 --> 00:04:58,160
let's assume all these sequences consist

134
00:04:58,160 --> 00:05:00,479
of the x86 instruction increment of a

135
00:05:00,479 --> 00:05:02,880
memory address which accesses a memory

136
00:05:02,880 --> 00:05:05,759
address and increments its value by 1.

137
00:05:05,759 --> 00:05:07,919
so now in our first case we first access

138
00:05:07,919 --> 00:05:10,000
a memory address and lay down access it

139
00:05:10,000 --> 00:05:11,919
again in our measurement

140
00:05:11,919 --> 00:05:14,639
and this is a cache hit so this is very

141
00:05:14,639 --> 00:05:17,039
fast for our second case things are very

142
00:05:17,039 --> 00:05:19,120
similar here we once again have a cache

143
00:05:19,120 --> 00:05:21,360
hit there and it's still very fast so

144
00:05:21,360 --> 00:05:23,840
this is not a timing side channel as we

145
00:05:23,840 --> 00:05:26,400
cannot distinguish those two timings but

146
00:05:26,400 --> 00:05:28,800
if we change our example slightly so for

147
00:05:28,800 --> 00:05:30,479
example we use the seal flash

148
00:05:30,479 --> 00:05:32,320
instruction which removes an address

149
00:05:32,320 --> 00:05:34,160
from the cpu cache

150
00:05:34,160 --> 00:05:36,479
as a reset instruction

151
00:05:36,479 --> 00:05:38,240
then things are different so in the

152
00:05:38,240 --> 00:05:40,160
first case we first remove our memory

153
00:05:40,160 --> 00:05:42,240
from the cpu cache and access it so this

154
00:05:42,240 --> 00:05:45,280
gives us a cache miss which is very slow

155
00:05:45,280 --> 00:05:47,120
but in the other case if our trigger was

156
00:05:47,120 --> 00:05:49,360
previously executed then this trigger

157
00:05:49,360 --> 00:05:51,120
sequence brings our memory back to the

158
00:05:51,120 --> 00:05:54,000
cpu cache and we observe a cache hit so

159
00:05:54,000 --> 00:05:55,680
this is very fast

160
00:05:55,680 --> 00:05:57,680
and in this case now we can distinguish

161
00:05:57,680 --> 00:05:59,440
those two timings and we have a working

162
00:05:59,440 --> 00:06:01,440
side channel

163
00:06:01,440 --> 00:06:03,120
and with this idea in our mind we can

164
00:06:03,120 --> 00:06:05,280
build our fuzzer or cyrus which fuzzes

165
00:06:05,280 --> 00:06:07,120
x86 cpus

166
00:06:07,120 --> 00:06:08,479
for their

167
00:06:08,479 --> 00:06:11,440
potentially unknown side channels

168
00:06:11,440 --> 00:06:13,440
and the idea is very similar it's very

169
00:06:13,440 --> 00:06:14,319
easy

170
00:06:14,319 --> 00:06:16,319
so we start by in

171
00:06:16,319 --> 00:06:19,919
human readable and machine readable x86

172
00:06:19,919 --> 00:06:21,600
instruction set

173
00:06:21,600 --> 00:06:24,800
from for example um the xml description

174
00:06:24,800 --> 00:06:26,560
of the x86 set

175
00:06:26,560 --> 00:06:28,560
and then we just generate sequence

176
00:06:28,560 --> 00:06:30,080
triplets out of them

177
00:06:30,080 --> 00:06:32,080
and for that we assume that

178
00:06:32,080 --> 00:06:34,479
every such sequence consists of exactly

179
00:06:34,479 --> 00:06:36,560
one x86 instruction and then we just

180
00:06:36,560 --> 00:06:39,120
generate all possible permutations

181
00:06:39,120 --> 00:06:41,120
in our second stage we just execute them

182
00:06:41,120 --> 00:06:42,000
all

183
00:06:42,000 --> 00:06:43,759
and we execute them basically like

184
00:06:43,759 --> 00:06:46,000
you've seen on the previous slide and we

185
00:06:46,000 --> 00:06:48,639
just keep them and jobs keep those

186
00:06:48,639 --> 00:06:50,400
triples that actually report a working

187
00:06:50,400 --> 00:06:52,800
side channel in our third stage we just

188
00:06:52,800 --> 00:06:54,400
confirmed these results again by

189
00:06:54,400 --> 00:06:56,800
randomizing the order of execution and

190
00:06:56,800 --> 00:06:58,400
adjusting our thresholds a little bit to

191
00:06:58,400 --> 00:07:00,160
just remove false positives during our

192
00:07:00,160 --> 00:07:02,560
measurements in our fourth stage we then

193
00:07:02,560 --> 00:07:04,800
cluster our results for example for

194
00:07:04,800 --> 00:07:06,319
flush and reload you will end up with

195
00:07:06,319 --> 00:07:07,919
thousands of different

196
00:07:07,919 --> 00:07:10,240
sequence triples that all perform the

197
00:07:10,240 --> 00:07:12,160
side channel flush and reload so we just

198
00:07:12,160 --> 00:07:15,039
cluster them to make our result more

199
00:07:15,039 --> 00:07:16,560
manageable

200
00:07:16,560 --> 00:07:18,240
and then in the end we end up with our

201
00:07:18,240 --> 00:07:20,800
report that researchers can manually

202
00:07:20,800 --> 00:07:22,400
investigate further

203
00:07:22,400 --> 00:07:24,800
and we actually tested our tool on five

204
00:07:24,800 --> 00:07:27,039
different cpus consisting of amd and

205
00:07:27,039 --> 00:07:29,360
intel cpus and the first thing that we

206
00:07:29,360 --> 00:07:31,680
observed was that our runtime was up to

207
00:07:31,680 --> 00:07:34,319
four days per system or more precisely

208
00:07:34,319 --> 00:07:36,960
per cpu

209
00:07:36,960 --> 00:07:39,520
and the amount or the number of clusters

210
00:07:39,520 --> 00:07:41,919
that we observed per cpu was less than

211
00:07:41,919 --> 00:07:44,879
30. so we think it's quite fair to say

212
00:07:44,879 --> 00:07:47,520
that less than 30 clusters is a number

213
00:07:47,520 --> 00:07:49,039
that you can manually investigate

214
00:07:49,039 --> 00:07:50,879
further

215
00:07:50,879 --> 00:07:52,639
and the very interesting question is

216
00:07:52,639 --> 00:07:54,319
what did we found when taking a look at

217
00:07:54,319 --> 00:07:55,840
these clusters

218
00:07:55,840 --> 00:07:57,520
it turns out that we found different

219
00:07:57,520 --> 00:07:59,919
novel side channels and we also found

220
00:07:59,919 --> 00:08:02,080
some known side channels so for the

221
00:08:02,080 --> 00:08:04,479
known side channels we for example found

222
00:08:04,479 --> 00:08:05,919
classroom reload

223
00:08:05,919 --> 00:08:08,319
but for our novel side channels we also

224
00:08:08,319 --> 00:08:10,160
for example found the ali grant-based

225
00:08:10,160 --> 00:08:11,360
site channel

226
00:08:11,360 --> 00:08:13,680
so a previously unknown side channel

227
00:08:13,680 --> 00:08:16,240
working with the adirent instruction of

228
00:08:16,240 --> 00:08:19,440
x86 which uses the random number

229
00:08:19,440 --> 00:08:22,319
generator of x86 cpus here on the right

230
00:08:22,319 --> 00:08:23,680
hand side of the slide you can actually

231
00:08:23,680 --> 00:08:25,680
see the timing difference of

232
00:08:25,680 --> 00:08:28,000
this side channel

233
00:08:28,000 --> 00:08:30,479
so we wanted to go one step ahead here

234
00:08:30,479 --> 00:08:32,159
wanted to make sure that our sideshows

235
00:08:32,159 --> 00:08:33,279
are actually

236
00:08:33,279 --> 00:08:35,360
having some practical impact

237
00:08:35,360 --> 00:08:37,599
so for that we evaluated them in three

238
00:08:37,599 --> 00:08:39,440
different case studies in our first case

239
00:08:39,440 --> 00:08:41,519
study we took a look at our addy run

240
00:08:41,519 --> 00:08:43,039
side channel and we built a covert

241
00:08:43,039 --> 00:08:44,560
channel out of it

242
00:08:44,560 --> 00:08:46,480
so we had a sender and a receiver

243
00:08:46,480 --> 00:08:48,800
process and we were able to transmit

244
00:08:48,800 --> 00:08:50,720
information between them

245
00:08:50,720 --> 00:08:53,360
and not only across course but also

246
00:08:53,360 --> 00:08:57,200
across virtual machines in the aws cloud

247
00:08:57,200 --> 00:09:00,480
if you now compare our site channel to

248
00:09:00,480 --> 00:09:02,720
similar site channels or similar covert

249
00:09:02,720 --> 00:09:03,760
channels

250
00:09:03,760 --> 00:09:05,920
you'll see that we do not need shared

251
00:09:05,920 --> 00:09:08,800
memory or shared cpu cache and hence

252
00:09:08,800 --> 00:09:11,120
it's also very um

253
00:09:11,120 --> 00:09:13,279
very hard to detect

254
00:09:13,279 --> 00:09:15,200
our covert channel because we do not

255
00:09:15,200 --> 00:09:17,600
leave any

256
00:09:17,600 --> 00:09:20,240
important traces in the cpu cache

257
00:09:20,240 --> 00:09:21,839
and they are also to the best of our

258
00:09:21,839 --> 00:09:23,279
knowledge no related performance

259
00:09:23,279 --> 00:09:24,959
counters that you could use

260
00:09:24,959 --> 00:09:28,399
to detect this covert channel

261
00:09:28,720 --> 00:09:30,640
in our second case study we then took a

262
00:09:30,640 --> 00:09:33,040
look at transient execution attacks

263
00:09:33,040 --> 00:09:35,200
and more precisely we mounted spectre

264
00:09:35,200 --> 00:09:36,399
and meltdown proof of concept

265
00:09:36,399 --> 00:09:38,240
implementations using our novel

266
00:09:38,240 --> 00:09:39,600
situations

267
00:09:39,600 --> 00:09:43,279
a respected approval concept was then

268
00:09:43,279 --> 00:09:46,720
roughly 2.4 times as fast as a similar

269
00:09:46,720 --> 00:09:48,880
non-cash-based side channel namely the

270
00:09:48,880 --> 00:09:51,839
abx2 side channel used in the netspecter

271
00:09:51,839 --> 00:09:53,760
paper

272
00:09:53,760 --> 00:09:55,920
and our meltdown proof of concept using

273
00:09:55,920 --> 00:09:58,000
one of our sidechains we

274
00:09:58,000 --> 00:10:00,560
named stream and reload was actually

275
00:10:00,560 --> 00:10:03,279
able to leak almost 8 bytes at once

276
00:10:03,279 --> 00:10:05,440
whereas previous work was only able to

277
00:10:05,440 --> 00:10:07,839
leak up to three bytes at once

278
00:10:07,839 --> 00:10:09,839
so we think it's fair to say that our

279
00:10:09,839 --> 00:10:12,320
side channels can be used to

280
00:10:12,320 --> 00:10:15,040
improve the performance of actually

281
00:10:15,040 --> 00:10:16,640
known or

282
00:10:16,640 --> 00:10:20,480
yet known um transit execution attacks

283
00:10:20,480 --> 00:10:22,240
and in our third case study we took a

284
00:10:22,240 --> 00:10:23,920
manual look at one of the instructions

285
00:10:23,920 --> 00:10:26,640
reported by osiris namely the move with

286
00:10:26,640 --> 00:10:28,399
non-temporal hints

287
00:10:28,399 --> 00:10:30,399
and based on our experiments with this

288
00:10:30,399 --> 00:10:32,320
instruction we came up with a case of

289
00:10:32,320 --> 00:10:34,880
air brake which is based on trends and

290
00:10:34,880 --> 00:10:36,959
execution and the interesting part about

291
00:10:36,959 --> 00:10:39,120
our case at upright is that it actually

292
00:10:39,120 --> 00:10:41,680
works on new intel cpus like the ice

293
00:10:41,680 --> 00:10:44,399
lake and combat lake where many other

294
00:10:44,399 --> 00:10:47,839
cases outbreaks stop working

295
00:10:47,839 --> 00:10:49,600
and as i am already

296
00:10:49,600 --> 00:10:51,440
running out of time let's summarize our

297
00:10:51,440 --> 00:10:53,279
paper for today

298
00:10:53,279 --> 00:10:56,240
so our work denotes side channels as

299
00:10:56,240 --> 00:10:58,720
sequence treatables and then based on

300
00:10:58,720 --> 00:11:00,959
this notion of sequence triples we

301
00:11:00,959 --> 00:11:03,920
develop our fuzzer or cyrus which fuzzes

302
00:11:03,920 --> 00:11:04,959
for

303
00:11:04,959 --> 00:11:08,079
such timing side channels in modern cpus

304
00:11:08,079 --> 00:11:10,000
with osiris we then discovered four

305
00:11:10,000 --> 00:11:11,760
novel side channels which we further

306
00:11:11,760 --> 00:11:14,160
evaluated in three different case

307
00:11:14,160 --> 00:11:15,920
studies

308
00:11:15,920 --> 00:11:17,680
and as we believe that open research is

309
00:11:17,680 --> 00:11:20,000
a very important part for our community

310
00:11:20,000 --> 00:11:22,399
we open sourced our father

311
00:11:22,399 --> 00:11:24,320
on githurb so that you can play around

312
00:11:24,320 --> 00:11:26,720
with that and by that i'm at the end of

313
00:11:26,720 --> 00:11:28,079
today's talk and i thank you all for

314
00:11:28,079 --> 00:11:30,480
your attention i hope i've spiked some

315
00:11:30,480 --> 00:11:32,800
interest in our research and

316
00:11:32,800 --> 00:11:35,680
feel free to check out our paper or also

317
00:11:35,680 --> 00:11:37,680
our tool on github and eventually find

318
00:11:37,680 --> 00:11:40,240
some new sideshow notes in your own cpus

319
00:11:40,240 --> 00:11:43,839
thanks bye

