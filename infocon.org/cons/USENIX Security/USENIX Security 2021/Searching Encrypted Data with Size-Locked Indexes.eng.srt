1
00:00:08,240 --> 00:00:10,719
hello everyone welcome to my talk today

2
00:00:10,719 --> 00:00:12,799
i'm going to talk about our work

3
00:00:12,799 --> 00:00:15,280
searching encrypted data with size

4
00:00:15,280 --> 00:00:18,400
locked indices my name is min xu and

5
00:00:18,400 --> 00:00:20,960
this is a collaboration with david cash

6
00:00:20,960 --> 00:00:24,640
armin namabhari and thomas wistenpart

7
00:00:24,640 --> 00:00:26,880
so in this work we focus on the problem

8
00:00:26,880 --> 00:00:29,199
called end-to-end encrypted keyword

9
00:00:29,199 --> 00:00:31,840
search so in this problem users

10
00:00:31,840 --> 00:00:34,079
outsource their documents to the cloud

11
00:00:34,079 --> 00:00:36,239
and they interact with the service by a

12
00:00:36,239 --> 00:00:38,399
web portal or mobile app

13
00:00:38,399 --> 00:00:40,399
with a limited client site storage

14
00:00:40,399 --> 00:00:41,600
capacity

15
00:00:41,600 --> 00:00:43,520
and users will apply end-to-end

16
00:00:43,520 --> 00:00:45,760
encryption with their local secret key

17
00:00:45,760 --> 00:00:47,680
before uploading their document to the

18
00:00:47,680 --> 00:00:49,440
service

19
00:00:49,440 --> 00:00:51,760
entered encryption poses challenges for

20
00:00:51,760 --> 00:00:53,920
the service to provide useful features

21
00:00:53,920 --> 00:00:55,760
such as keyword search

22
00:00:55,760 --> 00:00:57,920
which is supposed to return relevant

23
00:00:57,920 --> 00:01:02,559
documents to the user's keyword query

24
00:01:02,879 --> 00:01:05,360
and we first identify the target search

25
00:01:05,360 --> 00:01:06,400
features

26
00:01:06,400 --> 00:01:08,799
by surveying a bunch of popular cloud

27
00:01:08,799 --> 00:01:11,600
storage services such as dropbox

28
00:01:11,600 --> 00:01:14,000
the dropbox support multi-keyword

29
00:01:14,000 --> 00:01:15,680
conjunctive queries

30
00:01:15,680 --> 00:01:19,040
and they return the top relevant results

31
00:01:19,040 --> 00:01:21,680
with pagination which allows users

32
00:01:21,680 --> 00:01:23,920
either to click a page or scroll down

33
00:01:23,920 --> 00:01:25,439
for more results

34
00:01:25,439 --> 00:01:27,439
instead of returning the full document

35
00:01:27,439 --> 00:01:29,759
they will return a preview including the

36
00:01:29,759 --> 00:01:32,720
name the type and time of the document

37
00:01:32,720 --> 00:01:35,119
so we want to replicate such search

38
00:01:35,119 --> 00:01:38,079
features but with end-to-end encryption

39
00:01:38,079 --> 00:01:40,880
we also target for a code start setting

40
00:01:40,880 --> 00:01:42,880
where the users will interact with a

41
00:01:42,880 --> 00:01:45,600
service with empty local state in terms

42
00:01:45,600 --> 00:01:48,560
of update we realize that

43
00:01:48,560 --> 00:01:51,439
only the new document and new words are

44
00:01:51,439 --> 00:01:53,360
immediately effective in the search

45
00:01:53,360 --> 00:01:56,560
result but not the deletion of words so

46
00:01:56,560 --> 00:01:59,399
this is our thread model we focus on the

47
00:01:59,399 --> 00:02:02,320
confidentiality of the curie keyword and

48
00:02:02,320 --> 00:02:04,799
the documents we want to protect them

49
00:02:04,799 --> 00:02:07,680
against the persistent active adversary

50
00:02:07,680 --> 00:02:10,000
who has a full transcript of the update

51
00:02:10,000 --> 00:02:12,239
and search history

52
00:02:12,239 --> 00:02:14,959
we further assume the adversary with

53
00:02:14,959 --> 00:02:17,440
file injection capability which allows

54
00:02:17,440 --> 00:02:20,160
him to adaptively inject documents of

55
00:02:20,160 --> 00:02:22,400
chosen keywords under the user secret

56
00:02:22,400 --> 00:02:23,520
key

57
00:02:23,520 --> 00:02:26,239
this is a practical capability that has

58
00:02:26,239 --> 00:02:29,280
been explored in prefix work now let's

59
00:02:29,280 --> 00:02:31,440
see what direction towards the

60
00:02:31,440 --> 00:02:33,280
end-to-end encrypted keyword search

61
00:02:33,280 --> 00:02:35,200
problem which is called dynamic

62
00:02:35,200 --> 00:02:38,000
searchable symmetric encryption or dsse

63
00:02:38,000 --> 00:02:40,239
dlc can be summarized as three

64
00:02:40,239 --> 00:02:43,760
interfaces setup update and search

65
00:02:43,760 --> 00:02:46,319
for update it supports both addition and

66
00:02:46,319 --> 00:02:49,120
deletion and for search it will return

67
00:02:49,120 --> 00:02:51,280
the document identifiers for all the

68
00:02:51,280 --> 00:02:52,800
documents containing the accurate

69
00:02:52,800 --> 00:02:55,440
keyword in terms of security dssc

70
00:02:55,440 --> 00:02:57,599
constructions usually comes with leakage

71
00:02:57,599 --> 00:03:00,480
profile which is proved to include other

72
00:03:00,480 --> 00:03:02,640
informations leaked from the

73
00:03:02,640 --> 00:03:04,400
construction and the common link

74
00:03:04,400 --> 00:03:06,640
functions are include the result pattern

75
00:03:06,640 --> 00:03:08,480
which is the set of updates on the same

76
00:03:08,480 --> 00:03:11,040
keyword as a query volume which is a

77
00:03:11,040 --> 00:03:12,959
number of documents containing the cura

78
00:03:12,959 --> 00:03:14,959
keyword and currypad which is a set of

79
00:03:14,959 --> 00:03:16,879
queries on the same keyword leakage

80
00:03:16,879 --> 00:03:19,840
profile of previous dssc are vulnerable

81
00:03:19,840 --> 00:03:22,319
to various literature builds attacks

82
00:03:22,319 --> 00:03:24,319
and they provide limited search

83
00:03:24,319 --> 00:03:26,400
functionalities with no ranking of

84
00:03:26,400 --> 00:03:28,720
previewing since the introduction there

85
00:03:28,720 --> 00:03:31,120
has been attacks exploiting the result

86
00:03:31,120 --> 00:03:34,080
pattern and partial patch with forward

87
00:03:34,080 --> 00:03:36,560
privacy to mitigate its attacks and

88
00:03:36,560 --> 00:03:38,640
since that there are more and more works

89
00:03:38,640 --> 00:03:41,840
exploiting different leakages of dsse

90
00:03:41,840 --> 00:03:42,640
and

91
00:03:42,640 --> 00:03:45,360
defenses patching different combinations

92
00:03:45,360 --> 00:03:47,920
of these leakages the race between

93
00:03:47,920 --> 00:03:49,840
defenses and attacks will be

94
00:03:49,840 --> 00:03:52,400
long-lasting and more and more expensive

95
00:03:52,400 --> 00:03:54,640
cryptographic tools will be necessary to

96
00:03:54,640 --> 00:03:56,640
fully patch the ssd

97
00:03:56,640 --> 00:03:58,640
so in our work we take a different

98
00:03:58,640 --> 00:04:00,560
approach called download then search

99
00:04:00,560 --> 00:04:03,040
locally users construct

100
00:04:03,040 --> 00:04:06,159
a text search index encrypted and update

101
00:04:06,159 --> 00:04:08,879
loaded to the server for search

102
00:04:08,879 --> 00:04:11,519
the users will download the full

103
00:04:11,519 --> 00:04:13,760
encrypted index blog

104
00:04:13,760 --> 00:04:15,840
decrypt it locally and search for the

105
00:04:15,840 --> 00:04:16,880
keyword

106
00:04:16,880 --> 00:04:18,959
as you can see there is no result

107
00:04:18,959 --> 00:04:20,639
pattern rolling or curious pattern

108
00:04:20,639 --> 00:04:22,479
leakage at all

109
00:04:22,479 --> 00:04:25,120
moreover users can embed sufficient

110
00:04:25,120 --> 00:04:27,280
information in the index to support

111
00:04:27,280 --> 00:04:29,040
ranking and previewing

112
00:04:29,040 --> 00:04:32,160
in particular they can embed inverted

113
00:04:32,160 --> 00:04:34,080
index which is a mapping from the

114
00:04:34,080 --> 00:04:36,720
keywords to a list of postings each

115
00:04:36,720 --> 00:04:40,000
containing the document identifier and

116
00:04:40,000 --> 00:04:42,400
the number of occurrence of the keyword

117
00:04:42,400 --> 00:04:44,320
in the document

118
00:04:44,320 --> 00:04:46,560
and also a forward index which is

119
00:04:46,560 --> 00:04:49,199
mapping from the document identifier to

120
00:04:49,199 --> 00:04:51,680
the metadata of the document

121
00:04:51,680 --> 00:04:53,680
so how it works we developed previously

122
00:04:53,680 --> 00:04:55,759
under treated technique which is the

123
00:04:55,759 --> 00:04:57,840
download then search locally and we

124
00:04:57,840 --> 00:04:59,840
identify attacks against the naive

125
00:04:59,840 --> 00:05:01,919
construction and give solutions with

126
00:05:01,919 --> 00:05:05,039
security proofs we further propose new

127
00:05:05,039 --> 00:05:07,360
constructions for feature reach scalable

128
00:05:07,360 --> 00:05:09,840
search on the end-to-end encrypted data

129
00:05:09,840 --> 00:05:12,639
and we evaluate the performance with

130
00:05:12,639 --> 00:05:14,800
real-world prototype-based evaluation

131
00:05:14,800 --> 00:05:17,520
here is a naive construction of download

132
00:05:17,520 --> 00:05:19,759
and search locally users can take the

133
00:05:19,759 --> 00:05:23,039
standard indexing library such as lucine

134
00:05:23,039 --> 00:05:25,199
and encrypt it with standard encryption

135
00:05:25,199 --> 00:05:27,840
libraries such as aes gcm

136
00:05:27,840 --> 00:05:30,479
upload them to the server and as search

137
00:05:30,479 --> 00:05:32,639
the downloaded index decrypted and

138
00:05:32,639 --> 00:05:34,320
search

139
00:05:34,320 --> 00:05:35,520
for update

140
00:05:35,520 --> 00:05:38,000
a straightforward approach is users

141
00:05:38,000 --> 00:05:40,639
download the entire index blob

142
00:05:40,639 --> 00:05:43,039
decrypt it locally and add the new data

143
00:05:43,039 --> 00:05:45,440
to the index and then upload them to the

144
00:05:45,440 --> 00:05:46,479
server

145
00:05:46,479 --> 00:05:47,759
for instance

146
00:05:47,759 --> 00:05:48,960
to add a

147
00:05:48,960 --> 00:05:52,080
document with existing words such as

148
00:05:52,080 --> 00:05:54,960
bird the index size will increase by the

149
00:05:54,960 --> 00:05:58,000
posting and one metadata lens

150
00:05:58,000 --> 00:06:00,080
and when adding a document with a new

151
00:06:00,080 --> 00:06:01,680
word to the index

152
00:06:01,680 --> 00:06:03,759
the index size will increase by a

153
00:06:03,759 --> 00:06:06,960
posting and metadata lens plus the word

154
00:06:06,960 --> 00:06:07,919
lens

155
00:06:07,919 --> 00:06:10,240
the index size will change

156
00:06:10,240 --> 00:06:11,520
differently

157
00:06:11,520 --> 00:06:13,680
depending on whether the word is new or

158
00:06:13,680 --> 00:06:16,560
not to the index such size difference

159
00:06:16,560 --> 00:06:19,360
can be exploited with file injection

160
00:06:19,360 --> 00:06:22,080
so here is a simple attack the big team

161
00:06:22,080 --> 00:06:24,479
will index their sensitive data say ssn

162
00:06:24,479 --> 00:06:27,440
to the index with leucine and then the

163
00:06:27,440 --> 00:06:30,319
server will one by one inject candidate

164
00:06:30,319 --> 00:06:32,880
ssn to the index and measure the index

165
00:06:32,880 --> 00:06:35,520
size increase after each injection here

166
00:06:35,520 --> 00:06:38,160
shows the index size increase after each

167
00:06:38,160 --> 00:06:40,000
candidate injection

168
00:06:40,000 --> 00:06:42,000
and the candidate assessment equal to

169
00:06:42,000 --> 00:06:43,680
the victim methods and will give the

170
00:06:43,680 --> 00:06:46,240
smallest index size increase

171
00:06:46,240 --> 00:06:48,319
this shows the standards search index

172
00:06:48,319 --> 00:06:50,479
encrypted using standard encryption will

173
00:06:50,479 --> 00:06:52,400
leak sensitive information from the

174
00:06:52,400 --> 00:06:54,400
index size and fair injection is

175
00:06:54,400 --> 00:06:56,639
powerful enough to recover the data from

176
00:06:56,639 --> 00:06:57,759
the leakage

177
00:06:57,759 --> 00:07:00,800
to fix the size leakage we propose a

178
00:07:00,800 --> 00:07:03,199
definition called size locking and it

179
00:07:03,199 --> 00:07:06,160
makes the length of index a function of

180
00:07:06,160 --> 00:07:07,919
only the information we are willing to

181
00:07:07,919 --> 00:07:08,800
leak

182
00:07:08,800 --> 00:07:10,880
in particular in this work we are

183
00:07:10,880 --> 00:07:12,560
willing to leak the total number of

184
00:07:12,560 --> 00:07:14,479
postings in the index and the total

185
00:07:14,479 --> 00:07:16,960
number of documents in the index but not

186
00:07:16,960 --> 00:07:19,520
the total number of indexed keywords

187
00:07:19,520 --> 00:07:23,120
so the stat the illusion plus aes gcm

188
00:07:23,120 --> 00:07:26,000
construction its size depends on the

189
00:07:26,000 --> 00:07:28,080
total number of postings total number of

190
00:07:28,080 --> 00:07:29,680
documents and the total number of

191
00:07:29,680 --> 00:07:32,479
keywords and in the paper we propose our

192
00:07:32,479 --> 00:07:34,720
size locked construction which will have

193
00:07:34,720 --> 00:07:36,880
size as a function of the total number

194
00:07:36,880 --> 00:07:38,400
of postings and the total number of

195
00:07:38,400 --> 00:07:39,840
documents

196
00:07:39,840 --> 00:07:42,319
now we have a secure construction for

197
00:07:42,319 --> 00:07:44,400
download then search locally

198
00:07:44,400 --> 00:07:46,240
so how about its performance

199
00:07:46,240 --> 00:07:48,960
for the full error data set the full

200
00:07:48,960 --> 00:07:52,080
index size will get as large as 228

201
00:07:52,080 --> 00:07:54,080
megabytes and it means we need to

202
00:07:54,080 --> 00:07:56,319
download such large amount of data for

203
00:07:56,319 --> 00:07:59,919
every search and out of the 228

204
00:07:59,919 --> 00:08:03,599
megabytes of data 212 megabytes of done

205
00:08:03,599 --> 00:08:05,759
is for the inverted index

206
00:08:05,759 --> 00:08:08,400
since we want to support top relevant

207
00:08:08,400 --> 00:08:09,440
search

208
00:08:09,440 --> 00:08:11,840
can we reduce the cost to the necessary

209
00:08:11,840 --> 00:08:14,560
top relevant postings only the answer is

210
00:08:14,560 --> 00:08:15,520
yes

211
00:08:15,520 --> 00:08:17,360
and we'll achieve this with the secure

212
00:08:17,360 --> 00:08:19,599
vertical index partitioning the

213
00:08:19,599 --> 00:08:21,440
high-level idea is that

214
00:08:21,440 --> 00:08:23,520
we will partition the index into blobs

215
00:08:23,520 --> 00:08:25,599
by relevance of the postings to the

216
00:08:25,599 --> 00:08:28,400
index keywords and for a search we only

217
00:08:28,400 --> 00:08:31,039
download the first partition to return

218
00:08:31,039 --> 00:08:33,039
the top relevant result

219
00:08:33,039 --> 00:08:36,240
for update we have a secure way to add

220
00:08:36,240 --> 00:08:38,559
new postings to the partition and kick

221
00:08:38,559 --> 00:08:40,559
less relevant ones to the subsequent

222
00:08:40,559 --> 00:08:41,679
partitions

223
00:08:41,679 --> 00:08:43,839
and in terms of leakage there is no

224
00:08:43,839 --> 00:08:45,760
result pattern volume accurate pattern

225
00:08:45,760 --> 00:08:48,560
leakage introduced another way to reduce

226
00:08:48,560 --> 00:08:50,000
the download cost

227
00:08:50,000 --> 00:08:52,160
is to horizontally partition the index

228
00:08:52,160 --> 00:08:54,640
keywords together with their postings

229
00:08:54,640 --> 00:08:56,560
into p partitions

230
00:08:56,560 --> 00:08:58,480
for a single keyword query we only need

231
00:08:58,480 --> 00:09:01,600
to download one out of the p partitions

232
00:09:01,600 --> 00:09:04,800
in terms of security for search it leaks

233
00:09:04,800 --> 00:09:06,640
the partition access pattern which will

234
00:09:06,640 --> 00:09:09,120
be the same for words in the same

235
00:09:09,120 --> 00:09:11,360
partition the horizontal partitioning

236
00:09:11,360 --> 00:09:13,360
can be combined with the vertical

237
00:09:13,360 --> 00:09:15,760
partitioning for more efficiency

238
00:09:15,760 --> 00:09:18,560
now let's see some results on how the

239
00:09:18,560 --> 00:09:20,399
different constructions perform we

240
00:09:20,399 --> 00:09:22,000
evaluate their performance using the

241
00:09:22,000 --> 00:09:24,160
errand data set with different scale the

242
00:09:24,160 --> 00:09:28,480
10 error 50 error and 100 error

243
00:09:28,480 --> 00:09:30,800
roughly this means the percentage of

244
00:09:30,800 --> 00:09:33,839
documents of error data set used in each

245
00:09:33,839 --> 00:09:36,560
sample and we evaluate the basic size

246
00:09:36,560 --> 00:09:38,399
log download and search locally

247
00:09:38,399 --> 00:09:39,839
construction

248
00:09:39,839 --> 00:09:41,120
called full

249
00:09:41,120 --> 00:09:43,120
and the vertical partition the

250
00:09:43,120 --> 00:09:45,920
construction b parts and vertical and

251
00:09:45,920 --> 00:09:48,320
horizontally partition construction with

252
00:09:48,320 --> 00:09:50,640
p horizontal transitions called vh part

253
00:09:50,640 --> 00:09:52,000
p

254
00:09:52,000 --> 00:09:54,560
we also compare against the baseline

255
00:09:54,560 --> 00:09:57,360
dssc construction called counter dsse

256
00:09:57,360 --> 00:09:59,760
and this construction used per keyword

257
00:09:59,760 --> 00:10:02,720
counter to achieve the forward privacy

258
00:10:02,720 --> 00:10:05,600
and in our setting this per word counter

259
00:10:05,600 --> 00:10:07,839
needs to be outsourced to the server and

260
00:10:07,839 --> 00:10:10,720
download when necessary so we focus on

261
00:10:10,720 --> 00:10:13,040
the search performance and we evaluate

262
00:10:13,040 --> 00:10:16,640
with the kw ec2 client and the azure

263
00:10:16,640 --> 00:10:19,120
radius cache as a storage server the

264
00:10:19,120 --> 00:10:22,160
network bandwidth is about 100 megabits

265
00:10:22,160 --> 00:10:24,000
per second and a range of latency is

266
00:10:24,000 --> 00:10:26,320
about 30 milliseconds we evaluate the

267
00:10:26,320 --> 00:10:29,279
performance with top 10 searches and

268
00:10:29,279 --> 00:10:32,160
averaged over 30 different keywords from

269
00:10:32,160 --> 00:10:34,880
aaron let's first see the bandwidth cost

270
00:10:34,880 --> 00:10:36,480
for the 100

271
00:10:36,480 --> 00:10:38,800
uh error the full construction is

272
00:10:38,800 --> 00:10:41,519
download 228 megabytes

273
00:10:41,519 --> 00:10:43,519
and with vertical partitioning alone to

274
00:10:43,519 --> 00:10:46,800
reduce the download cost to 25 megabytes

275
00:10:46,800 --> 00:10:49,839
and with 10 extra horizontal partitions

276
00:10:49,839 --> 00:10:53,600
it reduces cost to 7.5 megabytes

277
00:10:53,600 --> 00:10:56,320
so for counter dsse because it needs to

278
00:10:56,320 --> 00:10:58,959
download the per word counters and it

279
00:10:58,959 --> 00:11:01,519
downloads all the matched results the

280
00:11:01,519 --> 00:11:03,839
average bandwidth cost is comparable to

281
00:11:03,839 --> 00:11:06,000
that of vh per turn

282
00:11:06,000 --> 00:11:08,880
for the search latency full construction

283
00:11:08,880 --> 00:11:12,720
needs 12.8 seconds on average for 100

284
00:11:12,720 --> 00:11:13,680
error

285
00:11:13,680 --> 00:11:15,040
vh part

286
00:11:15,040 --> 00:11:18,720
needs uh 2.5 seconds for curing

287
00:11:18,720 --> 00:11:21,200
and which part 10 only needs less than

288
00:11:21,200 --> 00:11:22,800
half seconds

289
00:11:22,800 --> 00:11:25,839
and if we aim for sub-second end-to-end

290
00:11:25,839 --> 00:11:28,640
search latency turns out that we can

291
00:11:28,640 --> 00:11:31,519
use a vertical partitioning alone for 10

292
00:11:31,519 --> 00:11:33,680
percent error which will gives us

293
00:11:33,680 --> 00:11:36,320
practical performance and better

294
00:11:36,320 --> 00:11:38,560
security than vh python

295
00:11:38,560 --> 00:11:41,200
for counter dsse because of the extra

296
00:11:41,200 --> 00:11:44,880
download and processing cost its search

297
00:11:44,880 --> 00:11:47,920
latency is worse than the partitioned

298
00:11:47,920 --> 00:11:50,320
construction in the paper we show much

299
00:11:50,320 --> 00:11:52,800
more details on how we handle updates

300
00:11:52,800 --> 00:11:55,200
how we progressively transition based on

301
00:11:55,200 --> 00:11:57,279
the number of postings and we have more

302
00:11:57,279 --> 00:12:00,320
evaluation results i will provide formal

303
00:12:00,320 --> 00:12:02,240
security proofs and leakage abuse

304
00:12:02,240 --> 00:12:04,560
analysis of our leakage

305
00:12:04,560 --> 00:12:09,079
thank you that's all about my talk

306
00:12:15,600 --> 00:12:17,680
you

