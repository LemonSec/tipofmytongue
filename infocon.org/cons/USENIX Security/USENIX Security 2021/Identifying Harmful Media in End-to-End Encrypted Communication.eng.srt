1
00:00:08,880 --> 00:00:10,960
hi i'm anunnakul srish from the center

2
00:00:10,960 --> 00:00:12,799
for information technology policy at

3
00:00:12,799 --> 00:00:14,400
princeton university

4
00:00:14,400 --> 00:00:16,079
in this paper we formalized the problem

5
00:00:16,079 --> 00:00:18,000
of detecting harmful media in the end to

6
00:00:18,000 --> 00:00:19,840
an encrypted setting our work is

7
00:00:19,840 --> 00:00:22,000
motivated by the contemporary debate on

8
00:00:22,000 --> 00:00:24,160
appropriate responses to child sexual

9
00:00:24,160 --> 00:00:25,840
abuse material terrorist recruiting

10
00:00:25,840 --> 00:00:28,240
imagery and disinformation shared over

11
00:00:28,240 --> 00:00:30,400
end to encrypted channels

12
00:00:30,400 --> 00:00:32,079
we propose protocols that provide the

13
00:00:32,079 --> 00:00:33,440
necessary security and privacy

14
00:00:33,440 --> 00:00:35,200
guarantees we then implement and

15
00:00:35,200 --> 00:00:36,640
benchmark them to illustrate their

16
00:00:36,640 --> 00:00:39,120
practicality we also discuss limitations

17
00:00:39,120 --> 00:00:40,559
of our proposal

18
00:00:40,559 --> 00:00:42,480
popular messaging services like whatsapp

19
00:00:42,480 --> 00:00:45,280
signal etc are now end-to-end encrypted

20
00:00:45,280 --> 00:00:46,960
this provides an invaluable defense

21
00:00:46,960 --> 00:00:49,039
against security threats privacy risks

22
00:00:49,039 --> 00:00:50,640
illegitimate surveillance and other

23
00:00:50,640 --> 00:00:52,480
human rights abuses

24
00:00:52,480 --> 00:00:54,800
however some users use them to share

25
00:00:54,800 --> 00:00:57,120
child sexual abuse material or csam

26
00:00:57,120 --> 00:00:58,640
terrorist recruiting imagery or

27
00:00:58,640 --> 00:01:00,719
disinformation these are different types

28
00:01:00,719 --> 00:01:02,480
of harmful content and their detection

29
00:01:02,480 --> 00:01:03,920
should evoke different responses from

30
00:01:03,920 --> 00:01:06,080
the service provider from notifying law

31
00:01:06,080 --> 00:01:07,920
enforcement in the case of csam to

32
00:01:07,920 --> 00:01:09,600
displaying a warning label in case of

33
00:01:09,600 --> 00:01:10,880
disinformation

34
00:01:10,880 --> 00:01:12,640
in non-end to encrypted services

35
00:01:12,640 --> 00:01:14,159
perceptual hash matching is the

36
00:01:14,159 --> 00:01:16,159
canonical method used to identify

37
00:01:16,159 --> 00:01:18,000
harmful media which i will discuss

38
00:01:18,000 --> 00:01:19,040
shortly

39
00:01:19,040 --> 00:01:20,799
non-profits like the national center for

40
00:01:20,799 --> 00:01:22,320
missing and exploited children and

41
00:01:22,320 --> 00:01:24,000
coalitions like the global internet

42
00:01:24,000 --> 00:01:26,320
forum to counter terrorism coordinate

43
00:01:26,320 --> 00:01:28,320
clearinghouses of perceptual hash data

44
00:01:28,320 --> 00:01:30,560
sets of known harmful content

45
00:01:30,560 --> 00:01:32,079
but none of this works in the end to an

46
00:01:32,079 --> 00:01:33,759
encrypted setting where the service

47
00:01:33,759 --> 00:01:36,159
providers simply cannot access content

48
00:01:36,159 --> 00:01:37,680
in particular the service provider

49
00:01:37,680 --> 00:01:39,840
cannot even compute the perceptual hash

50
00:01:39,840 --> 00:01:41,680
within this framework law enforcement

51
00:01:41,680 --> 00:01:43,200
agencies have argued for pausing

52
00:01:43,200 --> 00:01:45,280
deployment of end-to-end encryption

53
00:01:45,280 --> 00:01:47,600
until we can detect these harmful media

54
00:01:47,600 --> 00:01:49,439
while civil society groups and academics

55
00:01:49,439 --> 00:01:51,200
remain skeptical about the technical

56
00:01:51,200 --> 00:01:52,960
feasibility of privacy preserving

57
00:01:52,960 --> 00:01:55,119
detection

58
00:01:55,119 --> 00:01:57,280
perceptual hash functions or phfs

59
00:01:57,280 --> 00:01:59,200
produce hashes of media such that

60
00:01:59,200 --> 00:02:01,119
perceptually similar media have similar

61
00:02:01,119 --> 00:02:02,960
perceptual hashes in terms of hamming

62
00:02:02,960 --> 00:02:03,920
distance

63
00:02:03,920 --> 00:02:05,680
however this is not always true in

64
00:02:05,680 --> 00:02:08,318
practice as illustrated by the example

65
00:02:08,318 --> 00:02:11,038
here we use p hash a popular phf to

66
00:02:11,038 --> 00:02:13,760
generate 256 bit hashes p hash is

67
00:02:13,760 --> 00:02:15,280
clearly resilient to addition of

68
00:02:15,280 --> 00:02:18,640
gaussian noise but not to rotation

69
00:02:18,640 --> 00:02:20,640
in perceptual hash matching a client

70
00:02:20,640 --> 00:02:23,280
holds some media i such that x is the k

71
00:02:23,280 --> 00:02:25,680
bit perceptual hash of i we assume that

72
00:02:25,680 --> 00:02:28,160
the phf is public as most are

73
00:02:28,160 --> 00:02:29,520
due to the absence of the avalanche

74
00:02:29,520 --> 00:02:31,599
effect perceptual hashes may reveal

75
00:02:31,599 --> 00:02:33,680
information about their pre-images so we

76
00:02:33,680 --> 00:02:36,239
consider the perceptual hash x to be as

77
00:02:36,239 --> 00:02:39,680
private as the pre-image i itself

78
00:02:39,680 --> 00:02:41,760
a server holds set b of perceptual

79
00:02:41,760 --> 00:02:43,360
hashes that are known to correspond to

80
00:02:43,360 --> 00:02:45,519
harmful media the security of b is

81
00:02:45,519 --> 00:02:47,519
crucial as knowledge of its elements can

82
00:02:47,519 --> 00:02:49,360
disclose law enforcement sources or

83
00:02:49,360 --> 00:02:51,760
methods and can be used to circumvent

84
00:02:51,760 --> 00:02:53,360
detection

85
00:02:53,360 --> 00:02:54,959
similarity is defined by a hamming

86
00:02:54,959 --> 00:02:56,560
distance and a threshold is selected

87
00:02:56,560 --> 00:02:59,440
indirectly phm systems seek to answer

88
00:02:59,440 --> 00:03:01,760
either exact queries of the kind is x

89
00:03:01,760 --> 00:03:04,080
and b or approximate queries of the kind

90
00:03:04,080 --> 00:03:05,920
is their y and b that is similar enough

91
00:03:05,920 --> 00:03:07,040
to x

92
00:03:07,040 --> 00:03:08,879
if a match is detected the service

93
00:03:08,879 --> 00:03:11,040
provider can take appropriate action

94
00:03:11,040 --> 00:03:13,360
we devise privacy preserving protocols

95
00:03:13,360 --> 00:03:16,159
that realize this functionality

96
00:03:16,159 --> 00:03:18,000
here's how we formalize the problem

97
00:03:18,000 --> 00:03:20,239
similar to exact and approximate dhm we

98
00:03:20,239 --> 00:03:23,599
define p-e-m-c and p-a-m-c a p-e-m-c

99
00:03:23,599 --> 00:03:25,599
protocol reveals whether x is in b and

100
00:03:25,599 --> 00:03:28,000
nothing else similarly a p-a-m-c

101
00:03:28,000 --> 00:03:29,599
protocol reveals whether there exists

102
00:03:29,599 --> 00:03:31,680
some y and b that is similar enough to x

103
00:03:31,680 --> 00:03:32,959
and nothing else

104
00:03:32,959 --> 00:03:34,799
either party can be delegated to learn

105
00:03:34,799 --> 00:03:36,080
the result

106
00:03:36,080 --> 00:03:37,840
our protocols guarantee client and

107
00:03:37,840 --> 00:03:40,879
server privacy of x and b respectively

108
00:03:40,879 --> 00:03:42,480
perceptual hash matching systems in

109
00:03:42,480 --> 00:03:44,239
general do not provide security against

110
00:03:44,239 --> 00:03:46,000
malicious clients who could simply

111
00:03:46,000 --> 00:03:48,080
encrypt harmful media out of ban before

112
00:03:48,080 --> 00:03:49,120
sending

113
00:03:49,120 --> 00:03:51,200
phm systems can detect instances of

114
00:03:51,200 --> 00:03:53,200
sharing with only modest efforts at

115
00:03:53,200 --> 00:03:55,200
evasion or when senders are not aware

116
00:03:55,200 --> 00:03:57,519
that shared content is harmful

117
00:03:57,519 --> 00:03:59,439
similarly our protocols protect against

118
00:03:59,439 --> 00:04:01,439
semi honest parties

119
00:04:01,439 --> 00:04:02,959
a semi-honest client learns no

120
00:04:02,959 --> 00:04:04,560
information about b and the semi-honest

121
00:04:04,560 --> 00:04:06,560
server learns new information about x

122
00:04:06,560 --> 00:04:08,400
other than the protocol output if it is

123
00:04:08,400 --> 00:04:10,239
the delegated party

124
00:04:10,239 --> 00:04:12,319
we do however provide security against

125
00:04:12,319 --> 00:04:14,640
malicious clients that attempt to cheat

126
00:04:14,640 --> 00:04:16,079
in server revealing versions of the

127
00:04:16,079 --> 00:04:19,199
protocols in particular if x is in b or

128
00:04:19,199 --> 00:04:21,358
if there is a y that is similar enough

129
00:04:21,358 --> 00:04:23,360
no malicious client can prove otherwise

130
00:04:23,360 --> 00:04:26,080
without being detected by the server

131
00:04:26,080 --> 00:04:28,000
before we dive into the details i would

132
00:04:28,000 --> 00:04:29,680
like to discuss some major limitations

133
00:04:29,680 --> 00:04:31,280
of the work that follows

134
00:04:31,280 --> 00:04:33,280
our protocols cannot guarantee that the

135
00:04:33,280 --> 00:04:35,440
set b only contains hashes of harmful

136
00:04:35,440 --> 00:04:37,440
media so the potential for abuse is

137
00:04:37,440 --> 00:04:38,400
immense

138
00:04:38,400 --> 00:04:40,320
perceptual hash matching itself causes

139
00:04:40,320 --> 00:04:42,320
false positives which break privacy

140
00:04:42,320 --> 00:04:44,479
guarantees for honest users

141
00:04:44,479 --> 00:04:46,000
deployment of these protocols would

142
00:04:46,000 --> 00:04:47,919
clearly increase the attack surface for

143
00:04:47,919 --> 00:04:49,520
end-to-end encrypted services via

144
00:04:49,520 --> 00:04:51,759
possible side channels and may even have

145
00:04:51,759 --> 00:04:54,080
adverse externalities for example

146
00:04:54,080 --> 00:04:55,440
implementation in a democratic

147
00:04:55,440 --> 00:04:57,600
jurisdiction may undermine arguments in

148
00:04:57,600 --> 00:04:59,280
favor of end-to-end encryption in other

149
00:04:59,280 --> 00:05:00,479
countries

150
00:05:00,479 --> 00:05:01,840
we do not take a position on the

151
00:05:01,840 --> 00:05:03,600
question of deployment of such protocols

152
00:05:03,600 --> 00:05:05,919
including ours our goal is to spark

153
00:05:05,919 --> 00:05:07,520
discussion and future work by

154
00:05:07,520 --> 00:05:09,120
formalizing the problem area and

155
00:05:09,120 --> 00:05:10,720
demonstrating technically feasible

156
00:05:10,720 --> 00:05:12,560
protocols

157
00:05:12,560 --> 00:05:14,160
private membership computation is

158
00:05:14,160 --> 00:05:16,000
adjacent to prior work on privacy

159
00:05:16,000 --> 00:05:17,440
preserving matching and content

160
00:05:17,440 --> 00:05:18,960
moderation in the end-to-end encrypted

161
00:05:18,960 --> 00:05:21,360
setting thiagi atal and others have

162
00:05:21,360 --> 00:05:23,440
device protocols for message franking

163
00:05:23,440 --> 00:05:25,120
which allows service providers to prove

164
00:05:25,120 --> 00:05:26,960
that a deported message was indeed sent

165
00:05:26,960 --> 00:05:28,880
by the alleged sender

166
00:05:28,880 --> 00:05:31,520
private membership tests or pmt are

167
00:05:31,520 --> 00:05:33,840
clients revealing variants of private

168
00:05:33,840 --> 00:05:35,840
exact membership computation that do not

169
00:05:35,840 --> 00:05:38,560
protect the privacy of service set b

170
00:05:38,560 --> 00:05:40,000
private biometric authentication

171
00:05:40,000 --> 00:05:42,080
protocols allow private hamming distance

172
00:05:42,080 --> 00:05:44,720
computation albeit for much smaller sets

173
00:05:44,720 --> 00:05:45,919
b

174
00:05:45,919 --> 00:05:48,160
here's a brief overview of our protocols

175
00:05:48,160 --> 00:05:49,919
for simplicity i'm going to describe

176
00:05:49,919 --> 00:05:51,360
server revealing variants of our

177
00:05:51,360 --> 00:05:53,280
protocols we discussed client revealing

178
00:05:53,280 --> 00:05:55,120
versions in the paper

179
00:05:55,120 --> 00:05:57,039
the parties first use locality sensitive

180
00:05:57,039 --> 00:05:59,680
hashing to reduce the hash search space

181
00:05:59,680 --> 00:06:01,039
then they use private information

182
00:06:01,039 --> 00:06:02,880
retrieval to retrieve homomorphically

183
00:06:02,880 --> 00:06:05,360
encrypted hashes from this reduced space

184
00:06:05,360 --> 00:06:07,199
without revealing any information about

185
00:06:07,199 --> 00:06:09,360
x or b

186
00:06:09,360 --> 00:06:11,280
now the parties can run private equality

187
00:06:11,280 --> 00:06:13,680
tests using these encrypted hashes

188
00:06:13,680 --> 00:06:16,000
at this point for pemc the server can

189
00:06:16,000 --> 00:06:18,720
compute the result for pamc though we

190
00:06:18,720 --> 00:06:20,400
need an additional step that hides the

191
00:06:20,400 --> 00:06:22,160
hamming distance from the server a

192
00:06:22,160 --> 00:06:24,080
private threshold comparison that we

193
00:06:24,080 --> 00:06:25,759
construct using a privacy preserving

194
00:06:25,759 --> 00:06:27,919
comparison protocol

195
00:06:27,919 --> 00:06:29,440
we don't formally define locality

196
00:06:29,440 --> 00:06:31,680
sensitive hashing or lsh here but

197
00:06:31,680 --> 00:06:33,280
intuitively it allows us to partition

198
00:06:33,280 --> 00:06:35,440
set b into buckets such that the

199
00:06:35,440 --> 00:06:37,120
probability that two hashes would be

200
00:06:37,120 --> 00:06:38,400
mapped to the same bucket is

201
00:06:38,400 --> 00:06:40,560
proportional to their similarity score

202
00:06:40,560 --> 00:06:42,639
for exact membership we define the l-bit

203
00:06:42,639 --> 00:06:44,560
locality sensitive hash of a k-bit

204
00:06:44,560 --> 00:06:46,960
string as its l-bit prefix

205
00:06:46,960 --> 00:06:48,880
however this doesn't work very well for

206
00:06:48,880 --> 00:06:50,800
approximate membership as it preserved

207
00:06:50,800 --> 00:06:52,800
locality if and only if the l-bit

208
00:06:52,800 --> 00:06:54,560
prefixes match

209
00:06:54,560 --> 00:06:57,520
to reduce false negatives in pamc we use

210
00:06:57,520 --> 00:06:59,199
miniature perceptual hashes as

211
00:06:59,199 --> 00:07:01,360
locality-sensitive hashes themselves

212
00:07:01,360 --> 00:07:03,120
intuitively if two perceptual hashes

213
00:07:03,120 --> 00:07:05,199
with a large bit size are close enough

214
00:07:05,199 --> 00:07:07,199
then the same phf will produce shorter

215
00:07:07,199 --> 00:07:09,199
perceptual hashes of the same media that

216
00:07:09,199 --> 00:07:11,759
coincide with high probability thus

217
00:07:11,759 --> 00:07:13,360
putting both pre-images in the same

218
00:07:13,360 --> 00:07:14,880
bucket

219
00:07:14,880 --> 00:07:16,319
the server computes the locality

220
00:07:16,319 --> 00:07:19,120
sensitive hash of every string y and b

221
00:07:19,120 --> 00:07:22,319
suppose the lsh is the l bit value i

222
00:07:22,319 --> 00:07:24,479
the server then adds an encryption of y

223
00:07:24,479 --> 00:07:26,240
to the set ci

224
00:07:26,240 --> 00:07:28,479
after doing this for all strings y and b

225
00:07:28,479 --> 00:07:31,360
the server has an lsh index in that maps

226
00:07:31,360 --> 00:07:32,800
l bit values

227
00:07:32,800 --> 00:07:35,360
to sets of ciphertexts the client can

228
00:07:35,360 --> 00:07:38,400
also compute the lsh of x

229
00:07:38,400 --> 00:07:40,560
if x is in b it will always be mapped to

230
00:07:40,560 --> 00:07:42,960
bucket l of x if something similar to x

231
00:07:42,960 --> 00:07:45,280
is in b it is also mapped to bucket lfx

232
00:07:45,280 --> 00:07:46,800
with high probability

233
00:07:46,800 --> 00:07:48,720
so the hash search space is reduced to

234
00:07:48,720 --> 00:07:50,720
just that bucket of ciphertex a

235
00:07:50,720 --> 00:07:52,160
computationally private information

236
00:07:52,160 --> 00:07:54,560
retrieval protocol or pir allows a

237
00:07:54,560 --> 00:07:56,720
client to retrieve an element from many

238
00:07:56,720 --> 00:07:58,639
held by a server without revealing its

239
00:07:58,639 --> 00:08:00,240
element choice

240
00:08:00,240 --> 00:08:02,240
coming back to our protocol the client

241
00:08:02,240 --> 00:08:05,440
can retrieve cj via pir it's crucial to

242
00:08:05,440 --> 00:08:06,879
hide j from the server because it

243
00:08:06,879 --> 00:08:09,599
reveals the lsh effects

244
00:08:09,599 --> 00:08:11,120
now the two parties can engage in

245
00:08:11,120 --> 00:08:13,599
private exact equality tests over all

246
00:08:13,599 --> 00:08:15,520
perceptual hashes in the bucket

247
00:08:15,520 --> 00:08:16,879
we want to determine whether two

248
00:08:16,879 --> 00:08:18,800
ciphertexts decrypted the same plain

249
00:08:18,800 --> 00:08:21,280
text without revealing anything else

250
00:08:21,280 --> 00:08:23,280
for now assume that the server has just

251
00:08:23,280 --> 00:08:24,720
one hash y

252
00:08:24,720 --> 00:08:27,919
it picks an alchemy key pair pksk sends

253
00:08:27,919 --> 00:08:30,160
pk and cy an encryption of y to the

254
00:08:30,160 --> 00:08:33,120
client the client encrypts minus x using

255
00:08:33,120 --> 00:08:36,159
pk adds the ciphertext to cy chooses

256
00:08:36,159 --> 00:08:38,399
randomizer r and multiplies the result

257
00:08:38,399 --> 00:08:39,279
with it

258
00:08:39,279 --> 00:08:41,200
now due to the partial homomorphism of

259
00:08:41,200 --> 00:08:44,480
algamal encryption c is actually

260
00:08:44,480 --> 00:08:47,360
an encryption of r times y minus x which

261
00:08:47,360 --> 00:08:50,640
is zero if and only if x equals y

262
00:08:50,640 --> 00:08:53,440
client's randomization using r ensures

263
00:08:53,440 --> 00:08:56,160
that if x does not equal y decrypting c

264
00:08:56,160 --> 00:08:57,760
doesn't reveal anything about x to the

265
00:08:57,760 --> 00:08:59,200
server

266
00:08:59,200 --> 00:09:01,120
in the approximate case we need more

267
00:09:01,120 --> 00:09:03,360
than partial homomorphism we want to

268
00:09:03,360 --> 00:09:05,680
find a homomorphic transform zeta that

269
00:09:05,680 --> 00:09:07,360
allows us to compute the hamming

270
00:09:07,360 --> 00:09:09,120
distance between two encrypted bit

271
00:09:09,120 --> 00:09:11,680
strings without revealing anything else

272
00:09:11,680 --> 00:09:13,760
in the bfb cryptosystem plaintexts are

273
00:09:13,760 --> 00:09:16,399
polynomials so we define two ways to

274
00:09:16,399 --> 00:09:19,040
pack a k bit string into a polynomial

275
00:09:19,040 --> 00:09:21,519
back one and pack two we also define two

276
00:09:21,519 --> 00:09:23,920
polynomials j x and j y which are

277
00:09:23,920 --> 00:09:26,480
constants based on k and m

278
00:09:26,480 --> 00:09:28,399
we build on work by yesuda ital from

279
00:09:28,399 --> 00:09:30,720
2015 who use this technique with

280
00:09:30,720 --> 00:09:33,040
somewhat homomorphic encryption

281
00:09:33,040 --> 00:09:35,440
again the server generates a key pair

282
00:09:35,440 --> 00:09:37,279
sends pk to the client along with an

283
00:09:37,279 --> 00:09:40,000
encryption cy of y using packing 2 and

284
00:09:40,000 --> 00:09:40,880
bk

285
00:09:40,880 --> 00:09:43,920
the client generates cx using packing 1

286
00:09:43,920 --> 00:09:47,200
computes zeta cx cy and sends that to

287
00:09:47,200 --> 00:09:48,240
the server

288
00:09:48,240 --> 00:09:50,880
the server decrypts cr and checks the

289
00:09:50,880 --> 00:09:52,720
constant term which is the required

290
00:09:52,720 --> 00:09:54,880
hamming distance

291
00:09:54,880 --> 00:09:56,720
the issue is that the server learns the

292
00:09:56,720 --> 00:09:58,480
hamming distance while we only want to

293
00:09:58,480 --> 00:10:00,080
reveal whether the distance is at most

294
00:10:00,080 --> 00:10:02,000
some threshold delta h

295
00:10:02,000 --> 00:10:04,160
we use additive randomization to prevent

296
00:10:04,160 --> 00:10:05,519
the server from learning the hamming

297
00:10:05,519 --> 00:10:06,640
distance

298
00:10:06,640 --> 00:10:09,360
prior work by osachi etal used expensive

299
00:10:09,360 --> 00:10:11,040
oblivious transfer to undo the

300
00:10:11,040 --> 00:10:12,480
randomization

301
00:10:12,480 --> 00:10:14,480
we use privacy preserving comparison

302
00:10:14,480 --> 00:10:16,000
which makes the protocol much more

303
00:10:16,000 --> 00:10:17,279
efficient

304
00:10:17,279 --> 00:10:19,200
the client chooses randomizer polynomial

305
00:10:19,200 --> 00:10:23,600
r and now cr is zeta cacb plus r when

306
00:10:23,600 --> 00:10:25,600
the server decrypts cr it learns the

307
00:10:25,600 --> 00:10:28,320
hamming distance plus r of zero

308
00:10:28,320 --> 00:10:31,440
we use a ppc protocol that returns false

309
00:10:31,440 --> 00:10:33,839
if the client's value nu c is at least

310
00:10:33,839 --> 00:10:36,399
as big as the server's value mu s

311
00:10:36,399 --> 00:10:39,200
if mu c is equal to r of zero and nu s

312
00:10:39,200 --> 00:10:42,160
is equal to p x y of zero minus delta h

313
00:10:42,160 --> 00:10:44,399
the protocol returns false if and only

314
00:10:44,399 --> 00:10:46,480
if the hamming distance is at most delta

315
00:10:46,480 --> 00:10:47,519
h

316
00:10:47,519 --> 00:10:49,600
thus the server only learns whether the

317
00:10:49,600 --> 00:10:51,920
distance was at most delta h but not the

318
00:10:51,920 --> 00:10:53,839
distance itself

319
00:10:53,839 --> 00:10:55,920
now we put it all together the two

320
00:10:55,920 --> 00:10:58,000
parties compute private equality tests

321
00:10:58,000 --> 00:10:59,920
for each encrypted hash in the client's

322
00:10:59,920 --> 00:11:02,959
bucket of interest i equals l of x

323
00:11:02,959 --> 00:11:04,959
the server does not learn i so it cannot

324
00:11:04,959 --> 00:11:07,200
tell what ciphertext will retrieve due

325
00:11:07,200 --> 00:11:09,279
to client randomization no information

326
00:11:09,279 --> 00:11:11,279
about x is revered to the server if x is

327
00:11:11,279 --> 00:11:12,399
not in b

328
00:11:12,399 --> 00:11:14,160
but if any of these equality tests

329
00:11:14,160 --> 00:11:18,079
return true x is indeed in b

330
00:11:18,160 --> 00:11:20,480
due to pir and the threshold comparison

331
00:11:20,480 --> 00:11:22,560
we cannot let either party generate keys

332
00:11:22,560 --> 00:11:24,720
for p a and c or else they may be able

333
00:11:24,720 --> 00:11:26,160
to decrypt something they should not be

334
00:11:26,160 --> 00:11:27,440
able to

335
00:11:27,440 --> 00:11:29,200
so we use a distributed key generation

336
00:11:29,200 --> 00:11:31,440
protocol for bfb that results in

337
00:11:31,440 --> 00:11:34,000
collective public key pkag

338
00:11:34,000 --> 00:11:35,920
both parties can jointly delegate either

339
00:11:35,920 --> 00:11:37,519
party to decrypt cypher attacks

340
00:11:37,519 --> 00:11:40,000
encrypted under pkag using a collective

341
00:11:40,000 --> 00:11:41,680
key switching protocol

342
00:11:41,680 --> 00:11:43,680
again we run the approximate equality

343
00:11:43,680 --> 00:11:46,800
test once for each hash in bucket i

344
00:11:46,800 --> 00:11:48,880
in the paper we discuss optimizations

345
00:11:48,880 --> 00:11:50,800
that reduce communication cost by

346
00:11:50,800 --> 00:11:53,279
packing multiple hashes into one bfb

347
00:11:53,279 --> 00:11:55,760
plaintext polynomial

348
00:11:55,760 --> 00:11:57,600
we implemented our protocols in c plus

349
00:11:57,600 --> 00:12:00,959
plus using microsoft seal clpir ntl and

350
00:12:00,959 --> 00:12:03,839
botan the code will be on github we ran

351
00:12:03,839 --> 00:12:06,240
benchmarks on a 6 core intel i7 using

352
00:12:06,240 --> 00:12:09,600
256 bit hashes a 20 bit lsh family and

353
00:12:09,600 --> 00:12:12,800
seal pir parameters nnd 2048 and 2

354
00:12:12,800 --> 00:12:14,800
respectively with both parties running

355
00:12:14,800 --> 00:12:16,160
locally

356
00:12:16,160 --> 00:12:17,680
these are preliminary benchmarks and we

357
00:12:17,680 --> 00:12:19,200
are aware of some known optimizations

358
00:12:19,200 --> 00:12:20,800
that could improve both computation and

359
00:12:20,800 --> 00:12:22,880
communication costs

360
00:12:22,880 --> 00:12:24,720
thank you for watching and please direct

361
00:12:24,720 --> 00:12:29,000
any questions to rna cf.princeton.edu

