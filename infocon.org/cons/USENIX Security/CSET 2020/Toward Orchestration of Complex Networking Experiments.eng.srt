1
00:00:08,960 --> 00:00:10,880
hi my name is alif hussein and i'll

2
00:00:10,880 --> 00:00:11,840
present our work

3
00:00:11,840 --> 00:00:13,920
towards orchestration of complex

4
00:00:13,920 --> 00:00:15,440
networking experiments

5
00:00:15,440 --> 00:00:17,359
this work is based on a tool called magi

6
00:00:17,359 --> 00:00:18,960
that has been used in the data testbed

7
00:00:18,960 --> 00:00:20,640
for seven years for the evaluation of

8
00:00:20,640 --> 00:00:21,680
large systems

9
00:00:21,680 --> 00:00:23,199
integrated system development and

10
00:00:23,199 --> 00:00:24,960
education in this talk i'll first

11
00:00:24,960 --> 00:00:27,199
explain what i mean by an experiment

12
00:00:27,199 --> 00:00:28,800
what are the sources of complexity with

13
00:00:28,800 --> 00:00:30,400
the networking experiments

14
00:00:30,400 --> 00:00:32,960
i'll then present a solution measure i

15
00:00:32,960 --> 00:00:34,880
discuss how it's used in several case

16
00:00:34,880 --> 00:00:36,079
studies

17
00:00:36,079 --> 00:00:37,920
provide some retrospective takeaways

18
00:00:37,920 --> 00:00:40,879
before i conclude

19
00:00:41,600 --> 00:00:42,960
what do we mean by a networking

20
00:00:42,960 --> 00:00:45,120
experiment the goal of a networking

21
00:00:45,120 --> 00:00:45,760
experiment

22
00:00:45,760 --> 00:00:48,000
is to conduct realistic evaluations of

23
00:00:48,000 --> 00:00:49,520
systems on a testbed

24
00:00:49,520 --> 00:00:51,280
researchers use the testbed for testing

25
00:00:51,280 --> 00:00:52,559
and tuning their systems

26
00:00:52,559 --> 00:00:54,399
but in order to do that they first need

27
00:00:54,399 --> 00:00:57,600
to create representative scenarios

28
00:00:57,600 --> 00:00:59,359
scenarios are misa scale models of the

29
00:00:59,359 --> 00:01:01,280
internet or enterprise networks

30
00:01:01,280 --> 00:01:04,559
with a wide variety of topological

31
00:01:04,559 --> 00:01:07,200
conditions and application mixes the

32
00:01:07,200 --> 00:01:08,880
goal of a networking experiment

33
00:01:08,880 --> 00:01:10,560
is to understand how their system

34
00:01:10,560 --> 00:01:12,240
behaves in these conditions

35
00:01:12,240 --> 00:01:14,000
in order to optimize the performance of

36
00:01:14,000 --> 00:01:16,159
their system

37
00:01:16,159 --> 00:01:19,280
what makes an experiment complex

38
00:01:19,280 --> 00:01:21,840
first the systems rare systems under

39
00:01:21,840 --> 00:01:22,320
test

40
00:01:22,320 --> 00:01:24,880
rarely are a monolithic system they have

41
00:01:24,880 --> 00:01:26,240
many distributed parts

42
00:01:26,240 --> 00:01:27,759
and are typically an integration of

43
00:01:27,759 --> 00:01:30,880
technologies from different sources

44
00:01:30,880 --> 00:01:32,880
these distributed parts of the system

45
00:01:32,880 --> 00:01:36,159
can be configured in multiple ways

46
00:01:36,159 --> 00:01:39,040
and are coupled with a wide variety of

47
00:01:39,040 --> 00:01:40,320
background traffic

48
00:01:40,320 --> 00:01:43,280
and many application mixes the goal is

49
00:01:43,280 --> 00:01:44,240
to evaluate

50
00:01:44,240 --> 00:01:46,240
the performance of the system under

51
00:01:46,240 --> 00:01:47,280
stress

52
00:01:47,280 --> 00:01:49,920
for example what is the maximum volume

53
00:01:49,920 --> 00:01:50,799
of traffic

54
00:01:50,799 --> 00:01:53,520
that a server can handle through a

55
00:01:53,520 --> 00:01:55,520
bottleneck link

56
00:01:55,520 --> 00:01:57,600
fundamentally the goal of a networking

57
00:01:57,600 --> 00:01:59,280
experiment is to help

58
00:01:59,280 --> 00:02:02,159
the developers identify corner case

59
00:02:02,159 --> 00:02:03,680
performance issues

60
00:02:03,680 --> 00:02:06,560
that would be otherwise hard to track or

61
00:02:06,560 --> 00:02:07,600
identify

62
00:02:07,600 --> 00:02:10,639
and tune their systems forward this is

63
00:02:10,639 --> 00:02:12,640
especially important in cyber security

64
00:02:12,640 --> 00:02:13,520
experiments

65
00:02:13,520 --> 00:02:15,599
where systems can exhibit a wide range

66
00:02:15,599 --> 00:02:18,560
of unanticipated behaviors

67
00:02:18,560 --> 00:02:21,200
during an attack which can only be seen

68
00:02:21,200 --> 00:02:24,799
in test bed based evaluations

69
00:02:25,440 --> 00:02:28,080
finally the goal is also to get

70
00:02:28,080 --> 00:02:29,760
statistically sound results

71
00:02:29,760 --> 00:02:31,599
and ensure repeatability and

72
00:02:31,599 --> 00:02:33,920
reproducibility of these results

73
00:02:33,920 --> 00:02:35,599
hence it's important to create an

74
00:02:35,599 --> 00:02:37,360
executable configuration

75
00:02:37,360 --> 00:02:39,280
so that the experiments can be repeated

76
00:02:39,280 --> 00:02:41,280
several times not only by the

77
00:02:41,280 --> 00:02:43,120
researchers but also by other

78
00:02:43,120 --> 00:02:46,400
researchers and students

79
00:02:47,120 --> 00:02:50,400
our goal with magi was to enable

80
00:02:50,400 --> 00:02:52,959
such complex experiment orchestration

81
00:02:52,959 --> 00:02:54,720
that is the ability to execute a

82
00:02:54,720 --> 00:02:56,480
sequence of steps that capture

83
00:02:56,480 --> 00:02:59,040
the idiosyncrasies of a representative

84
00:02:59,040 --> 00:03:00,000
scenario

85
00:03:00,000 --> 00:03:03,360
in a repeatable manner on the test bed

86
00:03:03,360 --> 00:03:07,440
there have been several tools and

87
00:03:07,440 --> 00:03:10,000
that support experiment orchestration

88
00:03:10,000 --> 00:03:12,159
and experiment life cycle management

89
00:03:12,159 --> 00:03:14,800
uh in a variety of test beds i'm going

90
00:03:14,800 --> 00:03:17,360
to mention a couple of tools here

91
00:03:17,360 --> 00:03:20,239
first is experimenters typically are

92
00:03:20,239 --> 00:03:22,159
computer scientists themselves and it's

93
00:03:22,159 --> 00:03:23,760
really hard to get them to adopt new

94
00:03:23,760 --> 00:03:24,560
tools

95
00:03:24,560 --> 00:03:26,239
one of the most popular way to run

96
00:03:26,239 --> 00:03:27,760
experiment continues to be

97
00:03:27,760 --> 00:03:30,000
through shell-based scripts and ssh

98
00:03:30,000 --> 00:03:31,040
based scripts

99
00:03:31,040 --> 00:03:34,000
they're highly brittle mechanisms to run

100
00:03:34,000 --> 00:03:35,040
experiments

101
00:03:35,040 --> 00:03:38,400
with with limited repeatability and

102
00:03:38,400 --> 00:03:41,040
very rarely do they have an ability to

103
00:03:41,040 --> 00:03:42,319
report errors

104
00:03:42,319 --> 00:03:45,280
and check for validity of experiments

105
00:03:45,280 --> 00:03:47,120
another popular mechanism

106
00:03:47,120 --> 00:03:50,239
seems uh to be using ansible like

107
00:03:50,239 --> 00:03:52,400
configuration management tools while

108
00:03:52,400 --> 00:03:54,159
these tools have a rich

109
00:03:54,159 --> 00:03:56,319
tool set they have limited

110
00:03:56,319 --> 00:03:58,480
expressibility which is required for the

111
00:03:58,480 --> 00:04:00,239
complex experiments as i just

112
00:04:00,239 --> 00:04:03,519
described there have been several test

113
00:04:03,519 --> 00:04:04,720
beds in the past

114
00:04:04,720 --> 00:04:08,480
each testbed has had its own experiment

115
00:04:08,480 --> 00:04:11,599
management and orchestration too deter

116
00:04:11,599 --> 00:04:13,040
also had a first generation

117
00:04:13,040 --> 00:04:15,680
point-and-click tool called shear

118
00:04:15,680 --> 00:04:20,720
we subsequently developed magi

119
00:04:20,798 --> 00:04:22,639
which focused mainly on scale and

120
00:04:22,639 --> 00:04:24,080
repeatability and automation of

121
00:04:24,080 --> 00:04:25,680
experiments

122
00:04:25,680 --> 00:04:29,840
based on our learnings from seer

123
00:04:30,400 --> 00:04:33,120
in magi experiments can design a wide

124
00:04:33,120 --> 00:04:34,720
range of scenarios

125
00:04:34,720 --> 00:04:37,040
using a library of traffic agents these

126
00:04:37,040 --> 00:04:38,960
scenarios can then be executed on the

127
00:04:38,960 --> 00:04:40,880
test bed by an orchestrator

128
00:04:40,880 --> 00:04:43,840
and demons next i will discuss the key

129
00:04:43,840 --> 00:04:46,080
highlights of the magi tool

130
00:04:46,080 --> 00:04:49,919
and how it supports orchestration

131
00:04:49,919 --> 00:04:53,280
the design magi fundamentally has two

132
00:04:53,280 --> 00:04:54,000
parts

133
00:04:54,000 --> 00:04:56,240
design and execution of the experiment

134
00:04:56,240 --> 00:04:58,240
the design of an experiment starts with

135
00:04:58,240 --> 00:04:59,520
the conceptual model

136
00:04:59,520 --> 00:05:01,440
and is translated into a yaml based

137
00:05:01,440 --> 00:05:02,639
specification

138
00:05:02,639 --> 00:05:05,440
this translation uh this definition of

139
00:05:05,440 --> 00:05:06,960
specification is done by the

140
00:05:06,960 --> 00:05:08,000
experimenter

141
00:05:08,000 --> 00:05:09,680
and the specification is a sequence of

142
00:05:09,680 --> 00:05:11,440
steps that describes

143
00:05:11,440 --> 00:05:13,759
one individual run of the distributed

144
00:05:13,759 --> 00:05:16,320
system with a specific set of parameters

145
00:05:16,320 --> 00:05:17,840
configuration of the background traffic

146
00:05:17,840 --> 00:05:19,680
components and mapping of the components

147
00:05:19,680 --> 00:05:21,759
to the topology

148
00:05:21,759 --> 00:05:23,440
next we look at what the specification

149
00:05:23,440 --> 00:05:26,160
looks like in detail

150
00:05:26,160 --> 00:05:29,360
the specification for a magi

151
00:05:29,360 --> 00:05:31,600
experiment consists of five key

152
00:05:31,600 --> 00:05:32,720
directives

153
00:05:32,720 --> 00:05:36,080
group agent event event streams and

154
00:05:36,080 --> 00:05:37,440
triggers

155
00:05:37,440 --> 00:05:39,840
groups are mapping of all the behavior

156
00:05:39,840 --> 00:05:40,639
roles

157
00:05:40,639 --> 00:05:42,720
in the experiment to physical and

158
00:05:42,720 --> 00:05:44,160
virtual machines

159
00:05:44,160 --> 00:05:46,000
this is the only place in the

160
00:05:46,000 --> 00:05:47,440
orchestration

161
00:05:47,440 --> 00:05:49,520
where the orchestration is coupled with

162
00:05:49,520 --> 00:05:52,880
the underlining topology

163
00:05:52,880 --> 00:05:55,280
the agent directive is a pointer to the

164
00:05:55,280 --> 00:05:56,720
code implementation

165
00:05:56,720 --> 00:05:59,759
with the execution arguments agent is

166
00:05:59,759 --> 00:06:00,479
launched

167
00:06:00,479 --> 00:06:02,639
typically on a group of nodes for

168
00:06:02,639 --> 00:06:03,600
example

169
00:06:03,600 --> 00:06:06,800
here the http client implementation

170
00:06:06,800 --> 00:06:09,039
which is identified by the path is

171
00:06:09,039 --> 00:06:09,840
launched

172
00:06:09,840 --> 00:06:12,479
on the client group of nodes along with

173
00:06:12,479 --> 00:06:14,080
the exec

174
00:06:14,080 --> 00:06:18,639
with the execute execution arguments

175
00:06:19,039 --> 00:06:20,479
once the agents are launched in the

176
00:06:20,479 --> 00:06:22,560
experiment nodes the orchestrator can

177
00:06:22,560 --> 00:06:24,240
use the event directive

178
00:06:24,240 --> 00:06:27,840
to direct the agent each event directive

179
00:06:27,840 --> 00:06:30,160
typically maps to a method that can be

180
00:06:30,160 --> 00:06:31,759
invoked within the agent

181
00:06:31,759 --> 00:06:35,840
and can accept parameters

182
00:06:36,240 --> 00:06:38,560
collections of events are ordered as

183
00:06:38,560 --> 00:06:40,080
event streams

184
00:06:40,080 --> 00:06:42,479
which formulate the experiment behavior

185
00:06:42,479 --> 00:06:43,280
in this case

186
00:06:43,280 --> 00:06:45,120
we see a separate event stream for the

187
00:06:45,120 --> 00:06:47,039
server behavior and a separate event

188
00:06:47,039 --> 00:06:48,000
stream for the client

189
00:06:48,000 --> 00:06:51,440
behavior event streams are coupled

190
00:06:51,440 --> 00:06:54,000
based on triggers and which provides

191
00:06:54,000 --> 00:06:55,599
synchronization points

192
00:06:55,599 --> 00:06:56,960
triggers can be time-based

193
00:06:56,960 --> 00:06:58,880
synchronization points or event-based

194
00:06:58,880 --> 00:07:00,639
synchronization points

195
00:07:00,639 --> 00:07:04,160
the examples there show both

196
00:07:04,160 --> 00:07:06,880
uh event-based uh condition-based

197
00:07:06,880 --> 00:07:08,560
synchronization point as well as a

198
00:07:08,560 --> 00:07:11,680
time-based synchronization

199
00:07:12,960 --> 00:07:16,080
once the specification is defined this

200
00:07:16,080 --> 00:07:17,360
specification

201
00:07:17,360 --> 00:07:20,560
is executed by

202
00:07:20,560 --> 00:07:23,840
the orchestrator and

203
00:07:23,840 --> 00:07:26,960
the node demons in the experiment

204
00:07:26,960 --> 00:07:29,199
we'll discuss the orchestrator in detail

205
00:07:29,199 --> 00:07:30,639
next

206
00:07:30,639 --> 00:07:33,039
the orchestrator is the heart of the

207
00:07:33,039 --> 00:07:34,319
magi too

208
00:07:34,319 --> 00:07:36,160
it is the command and control center for

209
00:07:36,160 --> 00:07:38,080
orchestration and consists of main

210
00:07:38,080 --> 00:07:40,880
three main parts there's a parser that

211
00:07:40,880 --> 00:07:43,120
reads in the experimentation scripts

212
00:07:43,120 --> 00:07:46,560
and identifies the event streams

213
00:07:46,560 --> 00:07:48,960
and provides an ability to schedule the

214
00:07:48,960 --> 00:07:50,319
different events

215
00:07:50,319 --> 00:07:53,680
this parsed script is passed to the

216
00:07:53,680 --> 00:07:54,560
scheduler

217
00:07:54,560 --> 00:07:56,400
which essentially starts a thread to

218
00:07:56,400 --> 00:07:58,080
handle each event stream

219
00:07:58,080 --> 00:08:01,360
and sends events to all the nodes in the

220
00:08:01,360 --> 00:08:02,080
experiment

221
00:08:02,080 --> 00:08:05,039
in an asynchronous manner that means the

222
00:08:05,039 --> 00:08:06,720
events are non-blocking and once an

223
00:08:06,720 --> 00:08:08,319
amender sent out to all the demons the

224
00:08:08,319 --> 00:08:09,680
shed you look and move on

225
00:08:09,680 --> 00:08:12,800
to the next event in the event stream

226
00:08:12,800 --> 00:08:15,520
the evaluator receives return values

227
00:08:15,520 --> 00:08:17,680
from the notes in the experiment

228
00:08:17,680 --> 00:08:21,039
correlates these responses and

229
00:08:21,039 --> 00:08:23,440
if there is a trigger which is based on

230
00:08:23,440 --> 00:08:24,720
the return values

231
00:08:24,720 --> 00:08:27,120
it then coordinates with the scheduler

232
00:08:27,120 --> 00:08:28,639
to make sure that

233
00:08:28,639 --> 00:08:31,680
the event stream is correctly satisfied

234
00:08:31,680 --> 00:08:32,240
and can

235
00:08:32,240 --> 00:08:35,120
and can move on

236
00:08:37,679 --> 00:08:41,200
the magi toolkit also consists of

237
00:08:41,200 --> 00:08:42,000
daemons

238
00:08:42,000 --> 00:08:44,000
which are lightweight control conduits

239
00:08:44,000 --> 00:08:46,399
on the experiment nodes

240
00:08:46,399 --> 00:08:48,399
the daemon is responsible for receiving

241
00:08:48,399 --> 00:08:50,160
events from the orchestrator

242
00:08:50,160 --> 00:08:52,160
and launching and controlling the agents

243
00:08:52,160 --> 00:08:54,000
on the nodes

244
00:08:54,000 --> 00:08:56,240
it takes in the return values from the

245
00:08:56,240 --> 00:08:57,680
agents and send it back

246
00:08:57,680 --> 00:09:00,640
to the evaluator for trigger evaluation

247
00:09:00,640 --> 00:09:02,240
and finally the agent modules

248
00:09:02,240 --> 00:09:04,880
implementation on the nodes these are

249
00:09:04,880 --> 00:09:06,720
python based implementations on the

250
00:09:06,720 --> 00:09:07,360
nodes

251
00:09:07,360 --> 00:09:09,279
for a particular behavior within the

252
00:09:09,279 --> 00:09:10,959
experiment

253
00:09:10,959 --> 00:09:13,200
next we'll discuss several case studies

254
00:09:13,200 --> 00:09:15,120
how the measure system was used

255
00:09:15,120 --> 00:09:19,680
for experiments on deter

256
00:09:20,800 --> 00:09:24,560
first we looked at education um

257
00:09:24,560 --> 00:09:26,720
magi has been extensively used on the

258
00:09:26,720 --> 00:09:27,760
deter test bed

259
00:09:27,760 --> 00:09:31,440
to support classes uh um graduate and

260
00:09:31,440 --> 00:09:33,600
undergraduate level classes

261
00:09:33,600 --> 00:09:36,080
in in the example in the paper we

262
00:09:36,080 --> 00:09:36,800
discuss

263
00:09:36,800 --> 00:09:38,959
how it was used for an undergraduate

264
00:09:38,959 --> 00:09:40,240
class

265
00:09:40,240 --> 00:09:42,560
introduction to computer networks where

266
00:09:42,560 --> 00:09:44,480
the students were assigned

267
00:09:44,480 --> 00:09:48,320
to build a multi-user

268
00:09:48,320 --> 00:09:52,720
text based chat client and server system

269
00:09:52,720 --> 00:09:56,160
and what and using magi uh

270
00:09:56,160 --> 00:09:58,320
this project was developed over the

271
00:09:58,320 --> 00:09:59,200
semester

272
00:09:59,200 --> 00:10:01,839
where there were multiple milestones

273
00:10:01,839 --> 00:10:03,839
where the students could evaluate their

274
00:10:03,839 --> 00:10:06,959
client implementation with the server

275
00:10:06,959 --> 00:10:08,640
random client information with the

276
00:10:08,640 --> 00:10:10,000
student servers

277
00:10:10,000 --> 00:10:13,120
and also run a distributed system with

278
00:10:13,120 --> 00:10:15,440
30 clients

279
00:10:15,440 --> 00:10:18,000
supported with the student server and

280
00:10:18,000 --> 00:10:19,680
these kinds of evaluations would be

281
00:10:19,680 --> 00:10:20,959
extremely hard to do

282
00:10:20,959 --> 00:10:24,399
without a system like measure

283
00:10:24,560 --> 00:10:27,440
the other case study that we present in

284
00:10:27,440 --> 00:10:28,399
the paper

285
00:10:28,399 --> 00:10:31,760
is where we enable feed lab feedback

286
00:10:31,760 --> 00:10:32,320
loops

287
00:10:32,320 --> 00:10:35,040
being created within the experiment

288
00:10:35,040 --> 00:10:35,519
these

289
00:10:35,519 --> 00:10:38,320
are typically used when different teams

290
00:10:38,320 --> 00:10:39,279
are interacting

291
00:10:39,279 --> 00:10:41,680
within the same experiment but have

292
00:10:41,680 --> 00:10:43,600
limited access to different parts of the

293
00:10:43,600 --> 00:10:44,640
scenario

294
00:10:44,640 --> 00:10:47,680
so in this example we have

295
00:10:47,680 --> 00:10:50,560
two thousand web clients a thousand

296
00:10:50,560 --> 00:10:51,920
control clients

297
00:10:51,920 --> 00:10:54,079
which connect and a thousand control

298
00:10:54,079 --> 00:10:55,839
clients which connect to an apache web

299
00:10:55,839 --> 00:10:57,760
server farm

300
00:10:57,760 --> 00:11:00,800
and the the web clients

301
00:11:00,800 --> 00:11:04,399
continue contacting the the server farm

302
00:11:04,399 --> 00:11:06,959
and the goal of this experiment is to

303
00:11:06,959 --> 00:11:07,440
min

304
00:11:07,440 --> 00:11:09,680
is to ensure that that a particular

305
00:11:09,680 --> 00:11:11,200
bottleneck link

306
00:11:11,200 --> 00:11:14,880
has traffic has a 100 megabits of

307
00:11:14,880 --> 00:11:16,640
traffic always

308
00:11:16,640 --> 00:11:19,839
uh passing over the bottleneck link

309
00:11:19,839 --> 00:11:22,800
so the measure system has essentially an

310
00:11:22,800 --> 00:11:23,440
agent

311
00:11:23,440 --> 00:11:25,760
that senses the traffic on the network

312
00:11:25,760 --> 00:11:27,279
then devices a compute

313
00:11:27,279 --> 00:11:30,399
strategy to either increase decrease or

314
00:11:30,399 --> 00:11:31,440
maintain traffic

315
00:11:31,440 --> 00:11:33,760
based on the sensor signal it receives

316
00:11:33,760 --> 00:11:35,920
and then actuates a control action

317
00:11:35,920 --> 00:11:37,680
to either increase the amount of traffic

318
00:11:37,680 --> 00:11:39,839
at the control clients or reduce it

319
00:11:39,839 --> 00:11:41,920
based on what the current network

320
00:11:41,920 --> 00:11:44,719
conditions are

321
00:11:47,839 --> 00:11:50,800
the other example is where five teams

322
00:11:50,800 --> 00:11:51,600
developed

323
00:11:51,600 --> 00:11:53,760
adversary resistant communication to

324
00:11:53,760 --> 00:11:54,880
circumvent

325
00:11:54,880 --> 00:11:57,920
censorship on tor networks

326
00:11:57,920 --> 00:12:00,959
the i tor which is a very large system

327
00:12:00,959 --> 00:12:04,320
um we use magi to configure

328
00:12:04,320 --> 00:12:07,760
deploy and manage the

329
00:12:07,760 --> 00:12:11,040
the tor system as well as five different

330
00:12:11,040 --> 00:12:13,839
technologies that were deployed on it

331
00:12:13,839 --> 00:12:18,639
these were experiments that had

332
00:12:18,639 --> 00:12:22,720
ranged from 10 nodes to 100 nodes

333
00:12:22,720 --> 00:12:26,560
on the x on on the system and

334
00:12:26,560 --> 00:12:29,120
and the magi agents had complete

335
00:12:29,120 --> 00:12:30,880
completely orchestrated the experiment

336
00:12:30,880 --> 00:12:32,560
from not only bringing up

337
00:12:32,560 --> 00:12:35,440
the full tor network but also deploying

338
00:12:35,440 --> 00:12:36,079
um

339
00:12:36,079 --> 00:12:38,880
the technologies by the five teams and

340
00:12:38,880 --> 00:12:40,399
ensuring that there was

341
00:12:40,399 --> 00:12:43,680
uh cross traffic uh which included micro

342
00:12:43,680 --> 00:12:44,320
blogging

343
00:12:44,320 --> 00:12:46,079
voice over ip and file sharing

344
00:12:46,079 --> 00:12:48,000
applications

345
00:12:48,000 --> 00:12:50,720
and lastly we also have supported cyber

346
00:12:50,720 --> 00:12:52,160
physical system

347
00:12:52,160 --> 00:12:54,720
experimentation on it where we are

348
00:12:54,720 --> 00:12:55,839
monitoring

349
00:12:55,839 --> 00:12:58,720
uh the impact of a denial of service

350
00:12:58,720 --> 00:12:59,600
attack

351
00:12:59,600 --> 00:13:03,040
on damping oscillations

352
00:13:03,040 --> 00:13:06,160
power flow oscillations in the presence

353
00:13:06,160 --> 00:13:07,600
of these attacks

354
00:13:07,600 --> 00:13:10,399
so that there is a ieee 39 power bus

355
00:13:10,399 --> 00:13:11,839
which is overlaid

356
00:13:11,839 --> 00:13:14,560
on an 18 node communication topology on

357
00:13:14,560 --> 00:13:15,360
deter

358
00:13:15,360 --> 00:13:18,880
and then subsequently has a wide mix of

359
00:13:18,880 --> 00:13:20,720
background traffic as well as attack

360
00:13:20,720 --> 00:13:21,360
traffic

361
00:13:21,360 --> 00:13:24,240
to study the impact of the attack on the

362
00:13:24,240 --> 00:13:27,440
power flow oscillations

363
00:13:30,160 --> 00:13:33,200
the magi as i mentioned earlier magi

364
00:13:33,200 --> 00:13:35,279
is a second generation command line

365
00:13:35,279 --> 00:13:36,399
based tool

366
00:13:36,399 --> 00:13:38,320
orchestration on deter which we've used

367
00:13:38,320 --> 00:13:40,079
over the last seven years

368
00:13:40,079 --> 00:13:41,760
and based on my experience we had

369
00:13:41,760 --> 00:13:43,360
several uh

370
00:13:43,360 --> 00:13:46,399
key takeaways first we found that

371
00:13:46,399 --> 00:13:50,000
the the topology agnostic

372
00:13:50,000 --> 00:13:53,199
uh ability of magi

373
00:13:53,199 --> 00:13:56,800
allowed experimenters to experiment with

374
00:13:56,800 --> 00:13:58,480
small scale experiments and then

375
00:13:58,480 --> 00:13:59,680
directly

376
00:13:59,680 --> 00:14:02,720
use the same specification and applied

377
00:14:02,720 --> 00:14:04,639
to larger scale experiments

378
00:14:04,639 --> 00:14:07,600
and that feature was very widely used by

379
00:14:07,600 --> 00:14:09,920
most experimenters as they

380
00:14:09,920 --> 00:14:13,279
as they scaled up the experiments uh

381
00:14:13,279 --> 00:14:17,680
on onto additionally

382
00:14:17,680 --> 00:14:21,440
the event streams that enable unordered

383
00:14:21,440 --> 00:14:25,360
uh events and synchronization points

384
00:14:25,360 --> 00:14:29,279
enabled a large level of concurrency

385
00:14:29,279 --> 00:14:31,440
an asynchronous operation between the

386
00:14:31,440 --> 00:14:33,519
orchestrator and the demons

387
00:14:33,519 --> 00:14:36,160
and allowed experiments to execute

388
00:14:36,160 --> 00:14:36,880
rapidly

389
00:14:36,880 --> 00:14:40,399
at scale and finally

390
00:14:40,399 --> 00:14:43,519
getting the systematic feedback from

391
00:14:43,519 --> 00:14:48,480
the daemon for any errors and failures

392
00:14:48,480 --> 00:14:52,880
significantly help debugging errors

393
00:14:52,880 --> 00:14:55,519
within the experiment as well as

394
00:14:55,519 --> 00:14:56,800
supported

395
00:14:56,800 --> 00:14:59,519
graceful failure degradation in case of

396
00:14:59,519 --> 00:15:01,040
unrecoverable errors

397
00:15:01,040 --> 00:15:04,079
which were critical again for uh

398
00:15:04,079 --> 00:15:08,160
for experimentation at that scale

399
00:15:09,519 --> 00:15:11,199
finally to conclude i want to say that

400
00:15:11,199 --> 00:15:13,120
measure has made it significantly easier

401
00:15:13,120 --> 00:15:15,279
to run large and complex experiments

402
00:15:15,279 --> 00:15:17,839
in addition to deter we have used on

403
00:15:17,839 --> 00:15:18,959
emulab and genie

404
00:15:18,959 --> 00:15:20,800
and other small smaller testbed

405
00:15:20,800 --> 00:15:23,120
environments the code is open source and

406
00:15:23,120 --> 00:15:24,000
available

407
00:15:24,000 --> 00:15:25,920
along with detailed documentation and

408
00:15:25,920 --> 00:15:28,000
worked out experiment examples at the

409
00:15:28,000 --> 00:15:28,880
links

410
00:15:28,880 --> 00:15:32,079
below thank you so much for

411
00:15:32,079 --> 00:15:41,839
listening to my talk

412
00:15:42,880 --> 00:15:44,959
you

