1
00:00:08,400 --> 00:00:09,200
hi everyone

2
00:00:09,200 --> 00:00:10,800
my name is florian and in this video

3
00:00:10,800 --> 00:00:12,799
i'll present our work on adaptive

4
00:00:12,799 --> 00:00:15,679
attacks to address held example defenses

5
00:00:15,679 --> 00:00:18,080
this is joint work with nicholas kallini

6
00:00:18,080 --> 00:00:21,840
valen brandel and alexander madrid

7
00:00:21,840 --> 00:00:23,439
so this talk is about adversarial

8
00:00:23,439 --> 00:00:25,680
examples this curious phenomenon in

9
00:00:25,680 --> 00:00:26,880
machine learning models

10
00:00:26,880 --> 00:00:28,880
where very small changes to an input can

11
00:00:28,880 --> 00:00:30,400
cause a complete change in the model's

12
00:00:30,400 --> 00:00:31,439
prediction

13
00:00:31,439 --> 00:00:33,200
so here this image on the left that's

14
00:00:33,200 --> 00:00:34,719
correctly classified

15
00:00:34,719 --> 00:00:36,320
gets slightly perturbed and now the

16
00:00:36,320 --> 00:00:37,760
model thinks it's looking at a picture

17
00:00:37,760 --> 00:00:40,320
of guacamole

18
00:00:40,320 --> 00:00:41,920
so why should we care about adversal

19
00:00:41,920 --> 00:00:43,360
examples i think there's

20
00:00:43,360 --> 00:00:45,520
two main complementary reasons to study

21
00:00:45,520 --> 00:00:47,039
them the first

22
00:00:47,039 --> 00:00:48,800
is because they give a lot of control to

23
00:00:48,800 --> 00:00:50,640
adversaries against deployed machine

24
00:00:50,640 --> 00:00:51,760
learning systems

25
00:00:51,760 --> 00:00:53,280
and this has strong implications for the

26
00:00:53,280 --> 00:00:55,039
use of machine learning in computer

27
00:00:55,039 --> 00:00:55,840
security

28
00:00:55,840 --> 00:00:58,079
for things like malware detection or web

29
00:00:58,079 --> 00:01:00,320
security things like detecting ads

30
00:01:00,320 --> 00:01:03,039
phishing campaigns or forbidden content

31
00:01:03,039 --> 00:01:03,440
and

32
00:01:03,440 --> 00:01:05,280
on top of this studying adversarial

33
00:01:05,280 --> 00:01:07,200
examples might also help us

34
00:01:07,200 --> 00:01:09,520
understand model's robustness to

35
00:01:09,520 --> 00:01:11,360
distributional shift in a more general

36
00:01:11,360 --> 00:01:12,159
sense

37
00:01:12,159 --> 00:01:14,000
with the ultimate goal of building more

38
00:01:14,000 --> 00:01:15,759
reliable and safer machine learning

39
00:01:15,759 --> 00:01:18,080
models

40
00:01:18,320 --> 00:01:19,920
and building models that are robust to

41
00:01:19,920 --> 00:01:21,759
adverse examples is a very challenging

42
00:01:21,759 --> 00:01:22,560
problem

43
00:01:22,560 --> 00:01:24,840
and many many people have tried to solve

44
00:01:24,840 --> 00:01:27,360
it actually the number of papers on this

45
00:01:27,360 --> 00:01:29,600
topic has really exploded over the past

46
00:01:29,600 --> 00:01:30,400
two years

47
00:01:30,400 --> 00:01:32,320
and on average i'd say there's probably

48
00:01:32,320 --> 00:01:34,000
one new defense paper

49
00:01:34,000 --> 00:01:36,799
published on archive every day at this

50
00:01:36,799 --> 00:01:39,119
point

51
00:01:39,360 --> 00:01:41,600
but the field is being held back by a

52
00:01:41,600 --> 00:01:43,759
difficulty to properly evaluate these

53
00:01:43,759 --> 00:01:44,960
defenses

54
00:01:44,960 --> 00:01:48,079
so in this work we reviewed 13

55
00:01:48,079 --> 00:01:50,320
peer-reviewed defenses that appeared at

56
00:01:50,320 --> 00:01:51,759
one of the leading machine learning

57
00:01:51,759 --> 00:01:52,720
conferences

58
00:01:52,720 --> 00:01:55,600
over the past two years and all these

59
00:01:55,600 --> 00:01:56,960
papers propose some

60
00:01:56,960 --> 00:01:58,880
interesting new way of defending against

61
00:01:58,880 --> 00:02:00,399
iriselle examples

62
00:02:00,399 --> 00:02:02,320
and they all evaluate their proposed

63
00:02:02,320 --> 00:02:04,240
defense quite thoroughly usually by

64
00:02:04,240 --> 00:02:04,880
following

65
00:02:04,880 --> 00:02:06,880
some well accepted guidelines and

66
00:02:06,880 --> 00:02:08,080
standards

67
00:02:08,080 --> 00:02:09,758
and yet we find that for every single

68
00:02:09,758 --> 00:02:11,120
one of these defenses

69
00:02:11,120 --> 00:02:14,080
the actual robustness was overclaimed

70
00:02:14,080 --> 00:02:14,879
and with

71
00:02:14,879 --> 00:02:17,440
a suitably designed attack we can reduce

72
00:02:17,440 --> 00:02:19,920
the defense's accuracy significantly

73
00:02:19,920 --> 00:02:22,400
typically to zero percent accuracy

74
00:02:22,400 --> 00:02:23,680
within the fret model

75
00:02:23,680 --> 00:02:27,440
that the offer is originally considered

76
00:02:27,760 --> 00:02:29,520
so if you've been following this space

77
00:02:29,520 --> 00:02:31,040
over the past years

78
00:02:31,040 --> 00:02:33,599
this might not really come as a surprise

79
00:02:33,599 --> 00:02:35,360
and our paper isn't the first one to

80
00:02:35,360 --> 00:02:36,400
reevaluate

81
00:02:36,400 --> 00:02:38,480
a bunch of defenses and to show that

82
00:02:38,480 --> 00:02:39,519
they're broken

83
00:02:39,519 --> 00:02:41,760
actually my co-author nicholas has been

84
00:02:41,760 --> 00:02:42,560
doing this

85
00:02:42,560 --> 00:02:46,000
for the past three years now

86
00:02:46,400 --> 00:02:48,080
but when we initially started this

87
00:02:48,080 --> 00:02:50,560
project we were expecting quite a

88
00:02:50,560 --> 00:02:51,920
different outcome

89
00:02:51,920 --> 00:02:53,840
and actually our initial goal was to

90
00:02:53,840 --> 00:02:56,080
show that evaluations of defenses

91
00:02:56,080 --> 00:02:58,159
against address health examples

92
00:02:58,159 --> 00:03:01,040
are improving and the reason we were

93
00:03:01,040 --> 00:03:03,040
optimistic about this was that the field

94
00:03:03,040 --> 00:03:05,040
has slowly come to a consensus

95
00:03:05,040 --> 00:03:08,159
on what constitutes a good evaluation so

96
00:03:08,159 --> 00:03:08,720
first

97
00:03:08,720 --> 00:03:10,959
we've mostly converged on some simple

98
00:03:10,959 --> 00:03:13,280
and clearly defined threat models

99
00:03:13,280 --> 00:03:15,280
where the adversary gets full access to

100
00:03:15,280 --> 00:03:16,720
the defense parameters

101
00:03:16,720 --> 00:03:19,040
we call this a white box attack and the

102
00:03:19,040 --> 00:03:19,840
adversary

103
00:03:19,840 --> 00:03:21,440
is just constrained to producing

104
00:03:21,440 --> 00:03:23,200
perturbations that are small

105
00:03:23,200 --> 00:03:26,000
under some fixed norm of course a lot

106
00:03:26,000 --> 00:03:27,519
has been said about this type of threat

107
00:03:27,519 --> 00:03:28,319
model and how

108
00:03:28,319 --> 00:03:30,400
this norm constraint is somewhat

109
00:03:30,400 --> 00:03:32,319
arbitrary and unrealistic

110
00:03:32,319 --> 00:03:34,400
but at least this gives us a

111
00:03:34,400 --> 00:03:36,319
surprisingly hard but well-defined

112
00:03:36,319 --> 00:03:37,040
problem

113
00:03:37,040 --> 00:03:40,159
to study the second important change in

114
00:03:40,159 --> 00:03:41,280
the field has been

115
00:03:41,280 --> 00:03:44,159
about recognizing the importance of

116
00:03:44,159 --> 00:03:44,879
so-called

117
00:03:44,879 --> 00:03:47,280
adaptive attacks that are specifically

118
00:03:47,280 --> 00:03:48,640
tailored to break

119
00:03:48,640 --> 00:03:52,080
the defense and this may seem obvious to

120
00:03:52,080 --> 00:03:54,000
people in the security community

121
00:03:54,000 --> 00:03:56,239
but actually in this space a lot of

122
00:03:56,239 --> 00:03:58,319
evaluations of defenses have

123
00:03:58,319 --> 00:04:01,040
in the past been just about showing that

124
00:04:01,040 --> 00:04:02,720
previous attacks don't work

125
00:04:02,720 --> 00:04:05,040
rather than really trying to break the

126
00:04:05,040 --> 00:04:05,840
specifics

127
00:04:05,840 --> 00:04:09,360
of the newly proposed defense

128
00:04:10,159 --> 00:04:12,080
and we did really find that the

129
00:04:12,080 --> 00:04:14,560
evaluation standards do seem to be

130
00:04:14,560 --> 00:04:15,599
improving

131
00:04:15,599 --> 00:04:18,478
so over the years we find that offers

132
00:04:18,478 --> 00:04:20,399
and probably reviewers too

133
00:04:20,399 --> 00:04:22,639
have recognized the importance of

134
00:04:22,639 --> 00:04:23,919
evaluations against

135
00:04:23,919 --> 00:04:27,440
adaptive white box attacks and among the

136
00:04:27,440 --> 00:04:29,600
13 papers that we reviewed

137
00:04:29,600 --> 00:04:32,240
in our work nine of them explicitly

138
00:04:32,240 --> 00:04:33,199
aimed to create

139
00:04:33,199 --> 00:04:35,520
an adaptive attack that was tailored to

140
00:04:35,520 --> 00:04:38,000
the defense that they propose

141
00:04:38,000 --> 00:04:40,000
and another very nice change that we've

142
00:04:40,000 --> 00:04:41,600
noticed in the field is that

143
00:04:41,600 --> 00:04:44,400
nowadays pretty much every defense comes

144
00:04:44,400 --> 00:04:46,080
with a public code base

145
00:04:46,080 --> 00:04:47,919
and often even with pre-trained models

146
00:04:47,919 --> 00:04:49,360
and this also wasn't the case

147
00:04:49,360 --> 00:04:50,880
two three years ago and this makes it

148
00:04:50,880 --> 00:04:53,120
much easier to allow for these

149
00:04:53,120 --> 00:04:54,160
independent

150
00:04:54,160 --> 00:04:57,840
reevaluations of defenses

151
00:04:58,400 --> 00:05:01,919
so if evaluation standards have indeed

152
00:05:01,919 --> 00:05:04,800
improved then why were all these

153
00:05:04,800 --> 00:05:06,639
defenses still broken

154
00:05:06,639 --> 00:05:09,280
and the answer is quite simple we find

155
00:05:09,280 --> 00:05:10,880
that while many

156
00:05:10,880 --> 00:05:14,400
evaluations did try to include adaptive

157
00:05:14,400 --> 00:05:15,759
attacks

158
00:05:15,759 --> 00:05:17,919
they basically failed to design a

159
00:05:17,919 --> 00:05:20,080
particularly strong attack

160
00:05:20,080 --> 00:05:22,320
and the offers then take the failure of

161
00:05:22,320 --> 00:05:24,479
these attempted adaptive attacks

162
00:05:24,479 --> 00:05:26,960
as a sign of robustness even though

163
00:05:26,960 --> 00:05:28,400
better designed attacks

164
00:05:28,400 --> 00:05:30,000
would have actually been much stronger

165
00:05:30,000 --> 00:05:33,039
and broken the defense

166
00:05:33,039 --> 00:05:34,479
and so this is where our work

167
00:05:34,479 --> 00:05:36,080
specifically comes in

168
00:05:36,080 --> 00:05:38,960
for each of the certain defenses that we

169
00:05:38,960 --> 00:05:40,080
considered

170
00:05:40,080 --> 00:05:41,600
we were able to come up with a much

171
00:05:41,600 --> 00:05:43,600
stronger attack than one originally

172
00:05:43,600 --> 00:05:46,320
considered in the offers evaluation

173
00:05:46,320 --> 00:05:48,080
and rather than just showing this final

174
00:05:48,080 --> 00:05:49,919
attack we actually wrote down

175
00:05:49,919 --> 00:05:52,320
our entire process for coming up with it

176
00:05:52,320 --> 00:05:54,240
so usually this started with

177
00:05:54,240 --> 00:05:56,319
reading the paper and finding something

178
00:05:56,319 --> 00:05:57,360
strange or missing

179
00:05:57,360 --> 00:05:59,919
in the original evaluation then often

180
00:05:59,919 --> 00:06:01,840
looking at the author's code also helped

181
00:06:01,840 --> 00:06:04,000
in confirming some hypothesis

182
00:06:04,000 --> 00:06:06,560
about why the originally considered

183
00:06:06,560 --> 00:06:08,160
attacks failed

184
00:06:08,160 --> 00:06:10,160
and we really didn't try to cherry pick

185
00:06:10,160 --> 00:06:11,919
which results to present

186
00:06:11,919 --> 00:06:14,080
um so for some defenses we fought up

187
00:06:14,080 --> 00:06:16,080
some adaptive attacks tried it and it

188
00:06:16,080 --> 00:06:16,800
worked

189
00:06:16,800 --> 00:06:18,560
in other cases it didn't so we wrote

190
00:06:18,560 --> 00:06:20,080
this down and tried again

191
00:06:20,080 --> 00:06:22,560
until we found the final attack that

192
00:06:22,560 --> 00:06:23,680
worked and all of this

193
00:06:23,680 --> 00:06:26,880
is in our paper as a kind of case study

194
00:06:26,880 --> 00:06:28,400
or tutorial for how

195
00:06:28,400 --> 00:06:32,799
to build stronger adaptive attacks

196
00:06:33,360 --> 00:06:35,520
so for the rest of this talk i'll go

197
00:06:35,520 --> 00:06:36,880
over some high-level

198
00:06:36,880 --> 00:06:39,199
lessons and observations we've made from

199
00:06:39,199 --> 00:06:41,199
evaluating these defenses

200
00:06:41,199 --> 00:06:43,039
and these will be formulated mostly as

201
00:06:43,039 --> 00:06:44,720
things one shouldn't do

202
00:06:44,720 --> 00:06:47,600
when building or evaluating a defense

203
00:06:47,600 --> 00:06:48,800
and if you're interested

204
00:06:48,800 --> 00:06:50,720
in the more nitty gritty details of our

205
00:06:50,720 --> 00:06:52,479
attacks please take a look

206
00:06:52,479 --> 00:06:54,400
at the individual case studies in our

207
00:06:54,400 --> 00:06:56,719
paper

208
00:06:57,280 --> 00:06:59,120
so one of the first things we noticed

209
00:06:59,120 --> 00:07:00,639
and we're actually quite surprised by

210
00:07:00,639 --> 00:07:01,520
this

211
00:07:01,520 --> 00:07:02,880
is that there are a bunch of recent

212
00:07:02,880 --> 00:07:05,440
defenses that explicitly aim

213
00:07:05,440 --> 00:07:08,400
to break a model's gradients in order to

214
00:07:08,400 --> 00:07:09,039
break

215
00:07:09,039 --> 00:07:11,440
gradient-based attacks and this is

216
00:07:11,440 --> 00:07:12,479
unfortunately just

217
00:07:12,479 --> 00:07:14,800
the wrong way to think about this

218
00:07:14,800 --> 00:07:15,680
problem

219
00:07:15,680 --> 00:07:17,840
and that by messing up gradients we're

220
00:07:17,840 --> 00:07:19,759
most likely going to cause many

221
00:07:19,759 --> 00:07:22,080
existing attacks to fail but that

222
00:07:22,080 --> 00:07:23,680
shouldn't be the end goal

223
00:07:23,680 --> 00:07:26,000
the model hasn't been made more robust

224
00:07:26,000 --> 00:07:27,280
and we found that these types of

225
00:07:27,280 --> 00:07:28,560
defenses are usually

226
00:07:28,560 --> 00:07:31,280
just very easy to defeat with some form

227
00:07:31,280 --> 00:07:33,520
of gradient free attack

228
00:07:33,520 --> 00:07:34,960
and this really goes to the heart of

229
00:07:34,960 --> 00:07:36,800
what a good adaptive evaluation should

230
00:07:36,800 --> 00:07:37,680
do

231
00:07:37,680 --> 00:07:39,360
an evaluation shouldn't show that the

232
00:07:39,360 --> 00:07:42,240
defense resists some specific attacks

233
00:07:42,240 --> 00:07:43,919
but it should make a convincing case

234
00:07:43,919 --> 00:07:45,280
that he can resist

235
00:07:45,280 --> 00:07:47,599
all attack techniques in some attack

236
00:07:47,599 --> 00:07:48,319
model

237
00:07:48,319 --> 00:07:50,000
and so this approach of trying to

238
00:07:50,000 --> 00:07:51,520
obfuscate gradients

239
00:07:51,520 --> 00:07:53,360
is just not going to be able to achieve

240
00:07:53,360 --> 00:07:55,599
this

241
00:07:56,400 --> 00:07:57,759
and this brings us to our second

242
00:07:57,759 --> 00:07:59,599
observation about

243
00:07:59,599 --> 00:08:02,639
the reuse of adaptive attacks from prior

244
00:08:02,639 --> 00:08:03,680
work

245
00:08:03,680 --> 00:08:06,160
so what many evaluations will do is that

246
00:08:06,160 --> 00:08:07,120
they'll take

247
00:08:07,120 --> 00:08:09,759
a successful adaptive attack that worked

248
00:08:09,759 --> 00:08:11,199
on a prior defense

249
00:08:11,199 --> 00:08:14,240
and repurpose it somehow against the new

250
00:08:14,240 --> 00:08:15,199
defense

251
00:08:15,199 --> 00:08:18,319
and two very popular victims of this

252
00:08:18,319 --> 00:08:19,199
approach

253
00:08:19,199 --> 00:08:22,639
are the bpda and eot attack strategies

254
00:08:22,639 --> 00:08:23,919
that were introduced

255
00:08:23,919 --> 00:08:26,560
by italia carlini and wagner so if

256
00:08:26,560 --> 00:08:28,479
you're not familiar with these these are

257
00:08:28,479 --> 00:08:30,879
somewhat generic attack techniques to

258
00:08:30,879 --> 00:08:32,880
approximate the model's gradients

259
00:08:32,880 --> 00:08:34,360
when the model is either

260
00:08:34,360 --> 00:08:36,080
non-differentiable or

261
00:08:36,080 --> 00:08:38,958
somehow randomized and these techniques

262
00:08:38,958 --> 00:08:40,000
have been used successfully

263
00:08:40,000 --> 00:08:42,640
against many defenses in the past but

264
00:08:42,640 --> 00:08:44,640
this does not mean that they're always

265
00:08:44,640 --> 00:08:46,480
appropriate to use

266
00:08:46,480 --> 00:08:48,720
so you should really take the time to

267
00:08:48,720 --> 00:08:49,839
understand

268
00:08:49,839 --> 00:08:52,959
why previous adaptive attacks worked

269
00:08:52,959 --> 00:08:55,519
before using similar ideas in a new

270
00:08:55,519 --> 00:08:57,200
evaluation

271
00:08:57,200 --> 00:08:59,120
because these prior attacks were

272
00:08:59,120 --> 00:09:00,720
specifically tailored

273
00:09:00,720 --> 00:09:02,640
to some defense we have to make sure

274
00:09:02,640 --> 00:09:04,160
that the same assumptions and

275
00:09:04,160 --> 00:09:05,360
invariances

276
00:09:05,360 --> 00:09:07,440
hold for the new defense we're trying to

277
00:09:07,440 --> 00:09:09,120
evaluate as well

278
00:09:09,120 --> 00:09:11,440
and that's why our paper gives a lot of

279
00:09:11,440 --> 00:09:13,360
details on our process for designing

280
00:09:13,360 --> 00:09:14,320
each attack

281
00:09:14,320 --> 00:09:15,440
because usually there's a lot of

282
00:09:15,440 --> 00:09:17,360
assumptions that have to be met for each

283
00:09:17,360 --> 00:09:19,440
of these attacks to work

284
00:09:19,440 --> 00:09:21,360
and some specific advice i can give on

285
00:09:21,360 --> 00:09:22,640
these particular

286
00:09:22,640 --> 00:09:26,160
two techniques i try to use bpda mostly

287
00:09:26,160 --> 00:09:27,600
as a last resort

288
00:09:27,600 --> 00:09:30,320
it's a relatively blunt hammer kind of

289
00:09:30,320 --> 00:09:32,640
tool that is great when it works

290
00:09:32,640 --> 00:09:34,880
but more often than not gradient-free

291
00:09:34,880 --> 00:09:37,279
attacks will just do better

292
00:09:37,279 --> 00:09:40,800
and as for randomized defenses

293
00:09:40,800 --> 00:09:43,440
i find that it's usually easier to first

294
00:09:43,440 --> 00:09:44,560
try to build an

295
00:09:44,560 --> 00:09:46,959
attack that works when the randomness is

296
00:09:46,959 --> 00:09:48,080
fixed

297
00:09:48,080 --> 00:09:49,839
and then once you've found an attack

298
00:09:49,839 --> 00:09:51,279
that works in that setting

299
00:09:51,279 --> 00:09:54,160
to try to average over the actual

300
00:09:54,160 --> 00:09:55,120
randomness

301
00:09:55,120 --> 00:09:57,920
of the defense

302
00:09:59,040 --> 00:10:01,440
so another pattern we noticed in many

303
00:10:01,440 --> 00:10:03,040
defense evaluations

304
00:10:03,040 --> 00:10:06,399
is just a lot of unneeded complexity

305
00:10:06,399 --> 00:10:08,640
and one reason is that defenses

306
00:10:08,640 --> 00:10:09,680
themselves

307
00:10:09,680 --> 00:10:12,480
have gotten exceedingly complex and for

308
00:10:12,480 --> 00:10:13,440
some reason

309
00:10:13,440 --> 00:10:15,200
this seems to be particularly true of

310
00:10:15,200 --> 00:10:17,200
defenses submitted to security

311
00:10:17,200 --> 00:10:18,880
conferences

312
00:10:18,880 --> 00:10:20,720
so as a generic example it's not

313
00:10:20,720 --> 00:10:22,480
uncommon to see defenses that look a bit

314
00:10:22,480 --> 00:10:23,360
like this

315
00:10:23,360 --> 00:10:24,800
first you have some kind of

316
00:10:24,800 --> 00:10:27,200
pre-processing that's often randomized

317
00:10:27,200 --> 00:10:29,600
then you have many different components

318
00:10:29,600 --> 00:10:31,440
often different neural networks that

319
00:10:31,440 --> 00:10:33,360
jointly reach a prediction

320
00:10:33,360 --> 00:10:35,279
and then on top of that you'll have some

321
00:10:35,279 --> 00:10:38,079
kind of anomaly detector that computes

322
00:10:38,079 --> 00:10:39,760
some complicated statistic

323
00:10:39,760 --> 00:10:42,000
over all the previous components as

324
00:10:42,000 --> 00:10:43,519
internal features

325
00:10:43,519 --> 00:10:45,360
and for good measure this anomaly

326
00:10:45,360 --> 00:10:47,600
detector is often hard to differentiate

327
00:10:47,600 --> 00:10:49,120
over

328
00:10:49,120 --> 00:10:52,240
now this in itself is okay maybe we

329
00:10:52,240 --> 00:10:52,959
actually need

330
00:10:52,959 --> 00:10:55,519
very complicated defenses to solve

331
00:10:55,519 --> 00:10:58,399
adversal examples

332
00:10:58,399 --> 00:11:00,800
but more often than not the best attacks

333
00:11:00,800 --> 00:11:02,000
on these types

334
00:11:02,000 --> 00:11:05,200
of systems are actually fairly simple

335
00:11:05,200 --> 00:11:07,519
and what i often see in a is an

336
00:11:07,519 --> 00:11:09,680
evaluation that sort of tries to attack

337
00:11:09,680 --> 00:11:12,079
the entire defense at once usually by

338
00:11:12,079 --> 00:11:14,240
formulating some crazy loss function

339
00:11:14,240 --> 00:11:16,320
with a bunch of weighted terms

340
00:11:16,320 --> 00:11:17,839
and there's just very little chance that

341
00:11:17,839 --> 00:11:20,240
this will work even when you have just

342
00:11:20,240 --> 00:11:21,920
two loss terms to deal with you have to

343
00:11:21,920 --> 00:11:23,279
be a bit careful

344
00:11:23,279 --> 00:11:25,200
and with more we'll just get a very

345
00:11:25,200 --> 00:11:26,959
expensive attack to run

346
00:11:26,959 --> 00:11:29,279
it'll probably fail and we won't really

347
00:11:29,279 --> 00:11:30,640
know why

348
00:11:30,640 --> 00:11:33,920
so what do we do as with many

349
00:11:33,920 --> 00:11:36,800
computer systems there's probably going

350
00:11:36,800 --> 00:11:37,279
to be

351
00:11:37,279 --> 00:11:40,000
a weakest link somewhere so for quite a

352
00:11:40,000 --> 00:11:42,240
few complex defenses that we

353
00:11:42,240 --> 00:11:45,040
looked at we evaluated each of their

354
00:11:45,040 --> 00:11:46,880
components individually and found that

355
00:11:46,880 --> 00:11:47,839
many of them

356
00:11:47,839 --> 00:11:50,079
ultimately don't really matter and can

357
00:11:50,079 --> 00:11:52,399
just be ignored by the attack

358
00:11:52,399 --> 00:11:55,120
and among the important components that

359
00:11:55,120 --> 00:11:57,200
are left there's usually some that are

360
00:11:57,200 --> 00:11:58,800
very easy to attack

361
00:11:58,800 --> 00:12:02,399
and that can break the whole system

362
00:12:02,639 --> 00:12:04,959
so a specific technique that we used in

363
00:12:04,959 --> 00:12:06,480
in some of our attacks and i'll talk

364
00:12:06,480 --> 00:12:08,240
about in a bit more detail

365
00:12:08,240 --> 00:12:10,560
are so called feature adversaries and

366
00:12:10,560 --> 00:12:11,680
this is just a really

367
00:12:11,680 --> 00:12:13,519
simple and cool attack technique that i

368
00:12:13,519 --> 00:12:15,760
think more people should know about

369
00:12:15,760 --> 00:12:18,399
so let's see an example for how to break

370
00:12:18,399 --> 00:12:20,399
a classifier that's augmented with some

371
00:12:20,399 --> 00:12:22,639
kind of anomaly detector

372
00:12:22,639 --> 00:12:24,320
so we start with a normal picture of

373
00:12:24,320 --> 00:12:26,880
guacamole the model will classify this

374
00:12:26,880 --> 00:12:27,839
correctly

375
00:12:27,839 --> 00:12:29,680
and the anomaly detector will look at

376
00:12:29,680 --> 00:12:31,600
some internal features of the model

377
00:12:31,600 --> 00:12:34,880
and say that the input is okay so now to

378
00:12:34,880 --> 00:12:36,720
build an adversarial example

379
00:12:36,720 --> 00:12:39,360
for our cat picture we'll search for a

380
00:12:39,360 --> 00:12:40,480
perturbation

381
00:12:40,480 --> 00:12:43,120
that makes the model's entire internal

382
00:12:43,120 --> 00:12:44,079
features

383
00:12:44,079 --> 00:12:47,200
match those of the guacamole picture and

384
00:12:47,200 --> 00:12:48,880
this is great because it hits two birds

385
00:12:48,880 --> 00:12:50,079
with one stone

386
00:12:50,079 --> 00:12:52,160
because the model's internal features

387
00:12:52,160 --> 00:12:54,480
now match those of the guacamole picture

388
00:12:54,480 --> 00:12:56,880
the model will classify our attack as

389
00:12:56,880 --> 00:12:58,160
guacamole

390
00:12:58,160 --> 00:13:00,320
and the anomaly detector will also

391
00:13:00,320 --> 00:13:02,240
consider the features as valid

392
00:13:02,240 --> 00:13:04,399
so we've attacked the whole system

393
00:13:04,399 --> 00:13:06,560
without actually having to directly

394
00:13:06,560 --> 00:13:08,320
attack the anomaly detector

395
00:13:08,320 --> 00:13:09,920
or even really having to understand how

396
00:13:09,920 --> 00:13:12,560
it works internally it's just garbage in

397
00:13:12,560 --> 00:13:15,279
garbage out

398
00:13:16,240 --> 00:13:18,240
so the next point is more of a meta

399
00:13:18,240 --> 00:13:19,680
point really

400
00:13:19,680 --> 00:13:21,680
a feeling i get from some defense

401
00:13:21,680 --> 00:13:23,600
evaluations is that

402
00:13:23,600 --> 00:13:26,160
offers are mostly trying to convince the

403
00:13:26,160 --> 00:13:28,639
reviewers that their defense is robust

404
00:13:28,639 --> 00:13:30,639
rather than being convinced about this

405
00:13:30,639 --> 00:13:32,160
themselves

406
00:13:32,160 --> 00:13:34,160
and unfortunately if we don't try to

407
00:13:34,160 --> 00:13:35,839
break our own defenses

408
00:13:35,839 --> 00:13:39,600
someone else probably will later

409
00:13:39,600 --> 00:13:41,680
one symptom of this are defense

410
00:13:41,680 --> 00:13:43,519
evaluations that evaluate

411
00:13:43,519 --> 00:13:46,160
a huge number of non-adaptive attacks

412
00:13:46,160 --> 00:13:47,760
but only spend a tiny

413
00:13:47,760 --> 00:13:50,480
portion of the evaluation on ideas that

414
00:13:50,480 --> 00:13:52,240
actually have a chance to work

415
00:13:52,240 --> 00:13:54,079
and so you can think of it like this if

416
00:13:54,079 --> 00:13:56,079
i was offered one million dollars to

417
00:13:56,079 --> 00:13:57,839
break my own defense

418
00:13:57,839 --> 00:13:59,920
what kind of attack would i build

419
00:13:59,920 --> 00:14:02,240
probably an adaptive one

420
00:14:02,240 --> 00:14:05,440
so my ideal situation would be that

421
00:14:05,440 --> 00:14:07,920
defense evaluations in papers would be

422
00:14:07,920 --> 00:14:10,079
mainly about adaptive attacks

423
00:14:10,079 --> 00:14:12,079
showing that the defense resists

424
00:14:12,079 --> 00:14:13,440
non-adaptive attacks

425
00:14:13,440 --> 00:14:15,680
is kind of a formality at this point it

426
00:14:15,680 --> 00:14:17,120
should definitely be in the paper

427
00:14:17,120 --> 00:14:18,639
but it's not really the most important

428
00:14:18,639 --> 00:14:20,160
message

429
00:14:20,160 --> 00:14:22,079
and when describing these adaptive

430
00:14:22,079 --> 00:14:24,079
attacks we also shouldn't beat around

431
00:14:24,079 --> 00:14:24,800
the bush

432
00:14:24,800 --> 00:14:27,760
so usually defenses rely on one or two

433
00:14:27,760 --> 00:14:30,160
very crucial assumptions or invariants

434
00:14:30,160 --> 00:14:31,680
and so we should really just attack

435
00:14:31,680 --> 00:14:33,440
those directly with the strongest

436
00:14:33,440 --> 00:14:36,720
possible attack strategy we can think of

437
00:14:36,720 --> 00:14:38,800
it's also nice to see some standard

438
00:14:38,800 --> 00:14:40,320
evaluation guidelines

439
00:14:40,320 --> 00:14:42,800
being followed routinely by offers that

440
00:14:42,800 --> 00:14:44,399
my co-authors actually

441
00:14:44,399 --> 00:14:46,959
wrote down last year but this also

442
00:14:46,959 --> 00:14:49,760
shouldn't be taken as a just a checklist

443
00:14:49,760 --> 00:14:52,880
to go through to appease reviewers

444
00:14:52,880 --> 00:14:56,480
and on top of that it's also worth

445
00:14:56,480 --> 00:14:58,480
noting that these guidelines

446
00:14:58,480 --> 00:15:01,600
also apply to adaptive attacks so

447
00:15:01,600 --> 00:15:04,480
things like checking that an attack has

448
00:15:04,480 --> 00:15:06,480
converged properly or that an attack

449
00:15:06,480 --> 00:15:07,519
succeeds

450
00:15:07,519 --> 00:15:09,040
when the perturbation budget is

451
00:15:09,040 --> 00:15:10,959
unbounded these are things that should

452
00:15:10,959 --> 00:15:13,519
also hold for adaptive attacks and so

453
00:15:13,519 --> 00:15:16,240
it's good to check these and the

454
00:15:16,240 --> 00:15:18,560
particularly striking failure case

455
00:15:18,560 --> 00:15:21,279
that we see in some evaluations is that

456
00:15:21,279 --> 00:15:23,440
a proposed adaptive attack

457
00:15:23,440 --> 00:15:25,760
actually performs worse than the best

458
00:15:25,760 --> 00:15:27,120
non-adaptive attack

459
00:15:27,120 --> 00:15:28,720
and this should of course never be the

460
00:15:28,720 --> 00:15:31,120
case if the adaptive attack

461
00:15:31,120 --> 00:15:35,440
was designed to be as strong as possible

462
00:15:36,160 --> 00:15:39,199
okay so let me now take a step back

463
00:15:39,199 --> 00:15:41,600
and talk about a slightly broader

464
00:15:41,600 --> 00:15:44,560
problem that we have in this field

465
00:15:44,560 --> 00:15:46,639
in the end most defenses against

466
00:15:46,639 --> 00:15:47,839
adversarial examples

467
00:15:47,839 --> 00:15:50,240
are heuristic and need to be empirically

468
00:15:50,240 --> 00:15:51,360
evaluated

469
00:15:51,360 --> 00:15:53,600
and we know that this is really hard so

470
00:15:53,600 --> 00:15:54,560
there's always

471
00:15:54,560 --> 00:15:56,560
unfortunately a chance that even if we

472
00:15:56,560 --> 00:15:58,480
put in our best efforts to evaluate our

473
00:15:58,480 --> 00:15:59,440
defenses

474
00:15:59,440 --> 00:16:01,040
someone else will later find a stronger

475
00:16:01,040 --> 00:16:03,839
attack ultimately that's just the nature

476
00:16:03,839 --> 00:16:05,199
of empirical

477
00:16:05,199 --> 00:16:07,920
research in computer security but the

478
00:16:07,920 --> 00:16:09,199
way that we react

479
00:16:09,199 --> 00:16:11,519
to these subsequent breaks currently

480
00:16:11,519 --> 00:16:14,079
looks a little like this

481
00:16:14,079 --> 00:16:16,720
and to be specific i recently reviewed

482
00:16:16,720 --> 00:16:17,120
about

483
00:16:17,120 --> 00:16:19,759
40 defenses that i know of that have

484
00:16:19,759 --> 00:16:20,800
been broken

485
00:16:20,800 --> 00:16:23,120
by a subsequent paper over the past few

486
00:16:23,120 --> 00:16:24,560
years

487
00:16:24,560 --> 00:16:27,519
of these papers i found one that was

488
00:16:27,519 --> 00:16:29,199
broken before being presented at a

489
00:16:29,199 --> 00:16:30,959
conference and the offers retracted the

490
00:16:30,959 --> 00:16:32,560
paper

491
00:16:32,560 --> 00:16:35,360
and i found another one where the offers

492
00:16:35,360 --> 00:16:36,000
amended

493
00:16:36,000 --> 00:16:38,880
the archive version with a footnote that

494
00:16:38,880 --> 00:16:41,360
acknowledges the subsequent attack

495
00:16:41,360 --> 00:16:43,839
and the 38 other papers still present

496
00:16:43,839 --> 00:16:47,360
the original evaluation results as is

497
00:16:47,360 --> 00:16:50,720
so why is this mainly because it makes

498
00:16:50,720 --> 00:16:52,160
it much harder for people

499
00:16:52,160 --> 00:16:54,560
especially newcomers to navigate this

500
00:16:54,560 --> 00:16:55,839
field and to understand

501
00:16:55,839 --> 00:16:57,600
what has been tried and what works and

502
00:16:57,600 --> 00:16:58,959
what doesn't

503
00:16:58,959 --> 00:17:01,360
and it's actually quite common to see

504
00:17:01,360 --> 00:17:04,079
new papers that reference and builds on

505
00:17:04,079 --> 00:17:06,480
some earlier defense even though that

506
00:17:06,480 --> 00:17:09,839
defense has actually been broken

507
00:17:09,919 --> 00:17:12,400
and so what could we do better so i'll

508
00:17:12,400 --> 00:17:14,640
use an example here from one of my own

509
00:17:14,640 --> 00:17:15,199
papers

510
00:17:15,199 --> 00:17:18,319
which was published at iclear 2018

511
00:17:18,319 --> 00:17:20,160
and this was my first paper on adversal

512
00:17:20,160 --> 00:17:22,160
examples and they proposed

513
00:17:22,160 --> 00:17:24,240
a heuristic defense against some black

514
00:17:24,240 --> 00:17:25,439
box attacks

515
00:17:25,439 --> 00:17:27,439
where the adversary doesn't have direct

516
00:17:27,439 --> 00:17:29,840
query access to the model

517
00:17:29,840 --> 00:17:32,320
and i tried hard to break this defense

518
00:17:32,320 --> 00:17:32,880
but

519
00:17:32,880 --> 00:17:35,120
apparently not hard enough because

520
00:17:35,120 --> 00:17:36,720
there's been a line of work in the

521
00:17:36,720 --> 00:17:38,240
computer vision community

522
00:17:38,240 --> 00:17:40,160
that has found better attacks of this

523
00:17:40,160 --> 00:17:42,080
time sort of year after year

524
00:17:42,080 --> 00:17:43,760
and despite this the paper is still

525
00:17:43,760 --> 00:17:45,120
sometimes referenced as an

526
00:17:45,120 --> 00:17:48,240
effective defense in this model

527
00:17:48,240 --> 00:17:49,840
and interestingly i actually only

528
00:17:49,840 --> 00:17:51,200
learned about these attacks a couple

529
00:17:51,200 --> 00:17:52,080
months ago

530
00:17:52,080 --> 00:17:54,240
so i'll just also note here that if you

531
00:17:54,240 --> 00:17:56,080
find an attack against the defense

532
00:17:56,080 --> 00:17:58,160
it's a really good idea to contact the

533
00:17:58,160 --> 00:18:00,320
offers to let them know

534
00:18:00,320 --> 00:18:03,280
um so in the end i amended the paper on

535
00:18:03,280 --> 00:18:04,880
archive to acknowledge these later

536
00:18:04,880 --> 00:18:05,840
attacks

537
00:18:05,840 --> 00:18:07,360
it doesn't really matter much where to

538
00:18:07,360 --> 00:18:09,039
do this in the paper it could be in the

539
00:18:09,039 --> 00:18:11,200
abstract after the intro in the results

540
00:18:11,200 --> 00:18:12,640
section

541
00:18:12,640 --> 00:18:14,480
and it doesn't really need to invalidate

542
00:18:14,480 --> 00:18:16,160
the entire work either

543
00:18:16,160 --> 00:18:17,919
um this paper for instance had a bunch

544
00:18:17,919 --> 00:18:19,600
of other ideas and results

545
00:18:19,600 --> 00:18:21,840
that are still valid and even the

546
00:18:21,840 --> 00:18:23,919
defense still seems to do a little bit

547
00:18:23,919 --> 00:18:25,280
better compared to

548
00:18:25,280 --> 00:18:27,520
undefended models although not really as

549
00:18:27,520 --> 00:18:29,120
well as we would have hoped

550
00:18:29,120 --> 00:18:31,120
but now at least the reader gets a very

551
00:18:31,120 --> 00:18:33,600
clear view of the status of the field of

552
00:18:33,600 --> 00:18:35,120
what problems are still open

553
00:18:35,120 --> 00:18:37,200
what ideas people have tried and what

554
00:18:37,200 --> 00:18:39,919
worked and what didn't

555
00:18:39,919 --> 00:18:42,320
so to conclude the main takeaway from

556
00:18:42,320 --> 00:18:43,120
our work is that

557
00:18:43,120 --> 00:18:45,280
evaluating adversarial examples defenses

558
00:18:45,280 --> 00:18:46,559
is just hard

559
00:18:46,559 --> 00:18:48,000
but there's still a lot of room for

560
00:18:48,000 --> 00:18:49,600
improvement in the way that we currently

561
00:18:49,600 --> 00:18:50,960
do this

562
00:18:50,960 --> 00:18:53,600
and part of this is conceptual authors

563
00:18:53,600 --> 00:18:55,280
and reviewers have to realize that

564
00:18:55,280 --> 00:18:57,760
showing robustness against prior attacks

565
00:18:57,760 --> 00:19:00,000
is a fairly weak goal and this is just

566
00:19:00,000 --> 00:19:01,200
not the way forward

567
00:19:01,200 --> 00:19:02,880
and our conjecture here is actually that

568
00:19:02,880 --> 00:19:04,559
we're not going to come up with a fully

569
00:19:04,559 --> 00:19:05,840
universal attack

570
00:19:05,840 --> 00:19:07,840
so defenses really have to be evaluated

571
00:19:07,840 --> 00:19:10,320
against adapted attacks

572
00:19:10,320 --> 00:19:12,080
and ideally this would just be the bulk

573
00:19:12,080 --> 00:19:14,080
of a paper's evaluation section

574
00:19:14,080 --> 00:19:17,120
my hope would be to read each evaluation

575
00:19:17,120 --> 00:19:18,640
section and be convinced

576
00:19:18,640 --> 00:19:20,559
that the offers really tried as hard as

577
00:19:20,559 --> 00:19:22,640
possible to break their own defense

578
00:19:22,640 --> 00:19:25,440
but failed and this also means that

579
00:19:25,440 --> 00:19:26,000
defense

580
00:19:26,000 --> 00:19:27,919
offers have to learn to build strong

581
00:19:27,919 --> 00:19:29,840
attacks and there's no better way to do

582
00:19:29,840 --> 00:19:30,160
that

583
00:19:30,160 --> 00:19:32,320
than to practice and i think our paper

584
00:19:32,320 --> 00:19:33,919
can really help here

585
00:19:33,919 --> 00:19:35,840
and as you sort of break your teeth on a

586
00:19:35,840 --> 00:19:37,760
bunch of defenses as we did

587
00:19:37,760 --> 00:19:39,600
it will also become easier and easier to

588
00:19:39,600 --> 00:19:40,880
come up with attacks that are both

589
00:19:40,880 --> 00:19:42,640
simpler and stronger

590
00:19:42,640 --> 00:19:44,880
and by trying to attack our defenses

591
00:19:44,880 --> 00:19:45,919
you'll also help

592
00:19:45,919 --> 00:19:48,160
to sort of have more independent

593
00:19:48,160 --> 00:19:49,679
reevaluations in the field

594
00:19:49,679 --> 00:19:52,240
which will just be very beneficial and

595
00:19:52,240 --> 00:19:53,360
finally

596
00:19:53,360 --> 00:19:55,919
if a defense at some point gets broken

597
00:19:55,919 --> 00:19:56,480
just

598
00:19:56,480 --> 00:19:59,360
acknowledge it amend your paper and just

599
00:19:59,360 --> 00:20:01,120
continue doing research

600
00:20:01,120 --> 00:20:04,000
towards solving this really hard and

601
00:20:04,000 --> 00:20:05,760
fascinating problem

602
00:20:05,760 --> 00:20:07,919
if you have any question please reach

603
00:20:07,919 --> 00:20:09,120
out to me

604
00:20:09,120 --> 00:20:21,520
thanks a lot

