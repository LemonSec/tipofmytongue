1
00:00:07,919 --> 00:00:08,800
hello everyone

2
00:00:08,800 --> 00:00:11,599
welcome to our presentation i am sajidu

3
00:00:11,599 --> 00:00:13,280
rahman a phd student

4
00:00:13,280 --> 00:00:14,880
and a graduate research assistant

5
00:00:14,880 --> 00:00:17,199
working at university of florida

6
00:00:17,199 --> 00:00:19,119
institute for cyber security research

7
00:00:19,119 --> 00:00:21,520
center and here with me philip talley

8
00:00:21,520 --> 00:00:23,680
a step data scientist at fireeye and

9
00:00:23,680 --> 00:00:25,279
together we are gonna present

10
00:00:25,279 --> 00:00:27,039
our work on combating social media

11
00:00:27,039 --> 00:00:28,400
information operations with

12
00:00:28,400 --> 00:00:31,679
neural language models so

13
00:00:31,679 --> 00:00:33,920
let's begin our talk on what is

14
00:00:33,920 --> 00:00:35,200
information operation

15
00:00:35,200 --> 00:00:38,640
in social media so

16
00:00:38,640 --> 00:00:40,719
information operations on social media

17
00:00:40,719 --> 00:00:41,680
are flourished

18
00:00:41,680 --> 00:00:43,360
in part because they can be conducted

19
00:00:43,360 --> 00:00:45,520
cheaply have immediate global reach

20
00:00:45,520 --> 00:00:47,920
and can exploit the type of viral

21
00:00:47,920 --> 00:00:49,280
amplification

22
00:00:49,280 --> 00:00:52,000
incentivized by the platforms and not

23
00:00:52,000 --> 00:00:53,360
necessarily

24
00:00:53,360 --> 00:00:55,920
social media information are inaccurate

25
00:00:55,920 --> 00:00:57,039
information but

26
00:00:57,039 --> 00:00:59,280
most of the time they spread division

27
00:00:59,280 --> 00:01:01,760
and mistrust

28
00:01:01,760 --> 00:01:04,799
and there are cases where they are

29
00:01:04,799 --> 00:01:08,000
highly resourceful and they are also

30
00:01:08,000 --> 00:01:11,600
state sponsored and using networks of

31
00:01:11,600 --> 00:01:13,840
coordinated accounts social media driven

32
00:01:13,840 --> 00:01:15,840
information operations disseminate and

33
00:01:15,840 --> 00:01:16,960
amplify content

34
00:01:16,960 --> 00:01:19,360
design to promote the specific political

35
00:01:19,360 --> 00:01:20,240
narratives

36
00:01:20,240 --> 00:01:22,159
manipulate public opinion form and

37
00:01:22,159 --> 00:01:23,280
discord or achieve

38
00:01:23,280 --> 00:01:25,920
strategic ideological or geopolitical

39
00:01:25,920 --> 00:01:26,880
objectives

40
00:01:26,880 --> 00:01:28,560
fire's recent public recording

41
00:01:28,560 --> 00:01:30,960
illustrates the continually evolving use

42
00:01:30,960 --> 00:01:31,920
of social media

43
00:01:31,920 --> 00:01:34,479
as a vehicle for this kind of activity

44
00:01:34,479 --> 00:01:36,320
on the right you can see an example

45
00:01:36,320 --> 00:01:38,479
from a recent report of firearm where

46
00:01:38,479 --> 00:01:39,360
distinguished

47
00:01:39,360 --> 00:01:42,560
impersonators a group of active

48
00:01:42,560 --> 00:01:44,880
uh threat actors they are faking online

49
00:01:44,880 --> 00:01:46,640
person of u.s politicians

50
00:01:46,640 --> 00:01:48,880
activists and they are sharing political

51
00:01:48,880 --> 00:01:51,280
propaganda in a coordinated manner

52
00:01:51,280 --> 00:01:55,439
across facebook and twitter

53
00:01:55,439 --> 00:01:58,320
so this brings us this question that

54
00:01:58,320 --> 00:02:00,079
what are the challenges of

55
00:02:00,079 --> 00:02:02,399
detecting this kind of activity on

56
00:02:02,399 --> 00:02:04,320
social media

57
00:02:04,320 --> 00:02:08,399
and first there is this

58
00:02:08,399 --> 00:02:11,920
uh challenge of uh domain specific

59
00:02:11,920 --> 00:02:14,160
expertise identifying sophisticated

60
00:02:14,160 --> 00:02:15,440
activity of this nature

61
00:02:15,440 --> 00:02:17,680
often requires the subject matter

62
00:02:17,680 --> 00:02:18,640
expertise of

63
00:02:18,640 --> 00:02:21,200
human analysts after all such content is

64
00:02:21,200 --> 00:02:22,640
purposefully and convincingly

65
00:02:22,640 --> 00:02:24,160
manufactured to immediate

66
00:02:24,160 --> 00:02:26,319
authentic online activity making it very

67
00:02:26,319 --> 00:02:27,280
difficult for

68
00:02:27,280 --> 00:02:30,080
casual observers to properly verify and

69
00:02:30,080 --> 00:02:31,760
the actors behind such operations are

70
00:02:31,760 --> 00:02:32,800
not transferring about their

71
00:02:32,800 --> 00:02:33,920
applications too

72
00:02:33,920 --> 00:02:36,480
and they undertake various measures to

73
00:02:36,480 --> 00:02:37,519
hide their

74
00:02:37,519 --> 00:02:40,560
uh true identity by uh by using

75
00:02:40,560 --> 00:02:42,160
elaborate false personas

76
00:02:42,160 --> 00:02:43,760
and adoption of other operational

77
00:02:43,760 --> 00:02:47,440
security measures as we have seen before

78
00:02:47,440 --> 00:02:50,720
so with these challenges now and with

79
00:02:50,720 --> 00:02:52,480
these operations being intentionally

80
00:02:52,480 --> 00:02:54,400
designed to disagreements

81
00:02:54,400 --> 00:02:56,879
can we turn towards automation to help

82
00:02:56,879 --> 00:02:57,840
us understand

83
00:02:57,840 --> 00:03:00,000
and detect this growing threat can we

84
00:03:00,000 --> 00:03:02,000
make it easier for the human analysts

85
00:03:02,000 --> 00:03:04,080
to discover and investigate this

86
00:03:04,080 --> 00:03:06,080
activity despite this

87
00:03:06,080 --> 00:03:08,319
heterogeneous nature of social media and

88
00:03:08,319 --> 00:03:10,400
the high side traffic

89
00:03:10,400 --> 00:03:13,280
so in today's sport in today's talk we

90
00:03:13,280 --> 00:03:15,120
are gonna talk about

91
00:03:15,120 --> 00:03:18,080
um the result from our investigation on

92
00:03:18,080 --> 00:03:20,000
how the finite data science team

93
00:03:20,000 --> 00:03:21,440
works together with fire rise

94
00:03:21,440 --> 00:03:23,360
information operations analysis team

95
00:03:23,360 --> 00:03:25,680
to better understand and detect social

96
00:03:25,680 --> 00:03:27,680
media information operations

97
00:03:27,680 --> 00:03:31,360
using newer language models

98
00:03:31,680 --> 00:03:34,480
before jumping in uh our approach let's

99
00:03:34,480 --> 00:03:35,760
take a quick look at

100
00:03:35,760 --> 00:03:37,680
how the uh what are the common

101
00:03:37,680 --> 00:03:40,480
approaches available currently to

102
00:03:40,480 --> 00:03:43,280
fight social media disinformation of the

103
00:03:43,280 --> 00:03:45,599
information operations

104
00:03:45,599 --> 00:03:48,640
so this existing work on uh social media

105
00:03:48,640 --> 00:03:49,360
io

106
00:03:49,360 --> 00:03:51,840
detection can be broadly categorized in

107
00:03:51,840 --> 00:03:53,040
two classes

108
00:03:53,040 --> 00:03:55,840
content based analysis and network or

109
00:03:55,840 --> 00:03:57,760
analysis or metadata analysis

110
00:03:57,760 --> 00:04:00,720
so content analysis heavily depends on

111
00:04:00,720 --> 00:04:01,840
defining

112
00:04:01,840 --> 00:04:05,519
the various hard-coded tools for future

113
00:04:05,519 --> 00:04:06,959
engineering tasks

114
00:04:06,959 --> 00:04:09,519
and most of the times they focus on a

115
00:04:09,519 --> 00:04:11,280
particular type of

116
00:04:11,280 --> 00:04:13,200
social media information operation

117
00:04:13,200 --> 00:04:14,720
social media hire campaign

118
00:04:14,720 --> 00:04:16,720
and they don't generalize well across

119
00:04:16,720 --> 00:04:18,720
detecting various information operations

120
00:04:18,720 --> 00:04:21,279
on the other hand language models tend

121
00:04:21,279 --> 00:04:22,960
to capture the structure

122
00:04:22,960 --> 00:04:25,120
semantic and contextual information of a

123
00:04:25,120 --> 00:04:26,240
piece of text

124
00:04:26,240 --> 00:04:27,600
and modern language models are

125
00:04:27,600 --> 00:04:29,600
self-supervised and trained on

126
00:04:29,600 --> 00:04:33,120
massive data sets for better prediction

127
00:04:33,120 --> 00:04:35,199
and they also tend to model lengthy text

128
00:04:35,199 --> 00:04:37,440
very well and skill better than

129
00:04:37,440 --> 00:04:39,759
other competing feed-forward and

130
00:04:39,759 --> 00:04:41,759
recurrent neural nets

131
00:04:41,759 --> 00:04:46,160
so this brings to our hypothesis

132
00:04:54,840 --> 00:04:57,840
that

133
00:04:58,080 --> 00:05:00,320
uh fine-tuning large-scale language

134
00:05:00,320 --> 00:05:02,479
models can effectively lower

135
00:05:02,479 --> 00:05:05,759
the bar for generating and detecting

136
00:05:05,759 --> 00:05:08,080
social media posts associated with

137
00:05:08,080 --> 00:05:11,120
information operations

138
00:05:11,120 --> 00:05:13,840
so uh in so as you can see our

139
00:05:13,840 --> 00:05:15,120
hypothesis can be

140
00:05:15,120 --> 00:05:17,280
uh breaking can be broken down into two

141
00:05:17,280 --> 00:05:19,120
part first we want to see that

142
00:05:19,120 --> 00:05:22,080
if we can train a language model such

143
00:05:22,080 --> 00:05:22,720
that

144
00:05:22,720 --> 00:05:26,479
it can effectively capture the semantic

145
00:05:26,479 --> 00:05:29,199
and the nuances and idiosyncrasies of

146
00:05:29,199 --> 00:05:31,440
social media contents and specifically

147
00:05:31,440 --> 00:05:33,520
the social media information operation

148
00:05:33,520 --> 00:05:34,639
contents

149
00:05:34,639 --> 00:05:38,400
and then can we use this language model

150
00:05:38,400 --> 00:05:40,400
for classification and for detection

151
00:05:40,400 --> 00:05:42,240
purpose

152
00:05:42,240 --> 00:05:46,000
so for that we want to look into

153
00:05:46,000 --> 00:05:52,160
the state of the art language model gpt2

154
00:05:52,160 --> 00:05:54,960
so in order to gpt to uh and let's take

155
00:05:54,960 --> 00:05:56,240
a quick look at what is

156
00:05:56,240 --> 00:05:59,520
gpd2 and how does it uh perform so well

157
00:05:59,520 --> 00:06:00,319
on various

158
00:06:00,319 --> 00:06:02,160
natural language processing tasks and

159
00:06:02,160 --> 00:06:04,160
gpt2 that is generative free train

160
00:06:04,160 --> 00:06:05,039
transformer

161
00:06:05,039 --> 00:06:07,039
is a self-supervised language model

162
00:06:07,039 --> 00:06:08,160
which was pre-trained

163
00:06:08,160 --> 00:06:10,960
on a large web text corpus it's a

164
00:06:10,960 --> 00:06:12,479
layered step it's a layered

165
00:06:12,479 --> 00:06:15,199
stack of encoders and decoders and the

166
00:06:15,199 --> 00:06:16,880
superintendent of gpt2

167
00:06:16,880 --> 00:06:18,880
comes from the attention mechanism which

168
00:06:18,880 --> 00:06:21,199
helps train on enormous data sets

169
00:06:21,199 --> 00:06:24,800
efficiently and also it hierarchical

170
00:06:24,800 --> 00:06:26,000
text representation

171
00:06:26,000 --> 00:06:28,319
captures the semantics and enables

172
00:06:28,319 --> 00:06:31,199
transfer learning

173
00:06:31,840 --> 00:06:34,880
so in the here you can see a

174
00:06:34,880 --> 00:06:38,080
sample generation from gpt to

175
00:06:38,080 --> 00:06:40,960
medium since the p train if and this was

176
00:06:40,960 --> 00:06:41,919
a conditional

177
00:06:41,919 --> 00:06:44,319
generation uh where the model was

178
00:06:44,319 --> 00:06:45,600
conditioned to generate

179
00:06:45,600 --> 00:06:47,440
a text and the input was it's

180
00:06:47,440 --> 00:06:48,720
disgraceful that

181
00:06:48,720 --> 00:06:51,680
and then it generates the rest of the uh

182
00:06:51,680 --> 00:06:53,120
following paragraphs

183
00:06:53,120 --> 00:06:56,080
so since the p train gpt2 models dataset

184
00:06:56,080 --> 00:06:57,520
consisted of

185
00:06:57,520 --> 00:06:59,759
more than 40 gigabytes of internet text

186
00:06:59,759 --> 00:07:01,680
data extracted from more than eight

187
00:07:01,680 --> 00:07:02,160
million

188
00:07:02,160 --> 00:07:04,560
reputable web pages its generations

189
00:07:04,560 --> 00:07:06,400
display relatively formal grammar

190
00:07:06,400 --> 00:07:07,360
punctuation and

191
00:07:07,360 --> 00:07:10,560
structure that corresponds to text from

192
00:07:10,560 --> 00:07:13,919
news contents from books etc and this is

193
00:07:13,919 --> 00:07:15,360
not suitable and

194
00:07:15,360 --> 00:07:18,000
this doesn't necessarily correspond to

195
00:07:18,000 --> 00:07:19,039
the type of

196
00:07:19,039 --> 00:07:21,520
social to the post that we often see on

197
00:07:21,520 --> 00:07:23,520
social media

198
00:07:23,520 --> 00:07:26,720
so in order to uh

199
00:07:26,720 --> 00:07:29,120
to make text appear like a social media

200
00:07:29,120 --> 00:07:30,400
posts with the

201
00:07:30,400 --> 00:07:32,720
with the nuances or the platform

202
00:07:32,720 --> 00:07:34,319
specific idiosyncrasies like

203
00:07:34,319 --> 00:07:36,960
shorter length informal grammar erratic

204
00:07:36,960 --> 00:07:37,759
punctuation

205
00:07:37,759 --> 00:07:40,880
and syntactic works including mentions

206
00:07:40,880 --> 00:07:43,680
hashtags emojis acronyms and

207
00:07:43,680 --> 00:07:44,960
abbreviations

208
00:07:44,960 --> 00:07:48,639
we plan to fine-tune gpt2 on another

209
00:07:48,639 --> 00:07:50,960
positive language modeling task using

210
00:07:50,960 --> 00:07:52,400
additional

211
00:07:52,400 --> 00:07:55,759
training data so

212
00:07:55,759 --> 00:07:57,680
what are the data cells that we use so

213
00:07:57,680 --> 00:07:58,960
we look into

214
00:07:58,960 --> 00:08:02,080
uh the 20 2016 uh

215
00:08:02,080 --> 00:08:05,280
information operation uh and the data

216
00:08:05,280 --> 00:08:05,840
sets

217
00:08:05,840 --> 00:08:08,400
that were captured uh by various

218
00:08:08,400 --> 00:08:09,120
agencies

219
00:08:09,120 --> 00:08:11,919
so for we labor is four open source data

220
00:08:11,919 --> 00:08:14,879
sets of identified accounts operated by

221
00:08:14,879 --> 00:08:16,800
russia's infamous internet research

222
00:08:16,800 --> 00:08:19,520
agency also known as the troll factory

223
00:08:19,520 --> 00:08:21,919
and the data sets are coming from nbc

224
00:08:21,919 --> 00:08:22,960
news agency

225
00:08:22,960 --> 00:08:27,520
538 news agency reddit

226
00:08:27,520 --> 00:08:30,720
suspicious accounts and also the data

227
00:08:30,720 --> 00:08:31,039
set

228
00:08:31,039 --> 00:08:33,200
released by twitter election integrity

229
00:08:33,200 --> 00:08:35,680
dataset

230
00:08:36,958 --> 00:08:40,080
so after combining these four data sets

231
00:08:40,080 --> 00:08:42,958
we sample english language only social

232
00:08:42,958 --> 00:08:45,040
media posts from them to users

233
00:08:45,040 --> 00:08:47,440
into for our fine themed language model

234
00:08:47,440 --> 00:08:49,360
and finally experiments were carried out

235
00:08:49,360 --> 00:08:52,320
in fighters using 355 million parameter

236
00:08:52,320 --> 00:08:54,480
retrain gpt2 model from highland phase

237
00:08:54,480 --> 00:08:55,279
transfer line

238
00:08:55,279 --> 00:08:57,440
transformer library and were distributed

239
00:08:57,440 --> 00:09:00,480
over up to eight

240
00:09:06,839 --> 00:09:09,360
gpus

241
00:09:09,360 --> 00:09:12,560
and as you can see uh as opposed to the

242
00:09:12,560 --> 00:09:15,040
other detailed language model gpt2

243
00:09:15,040 --> 00:09:16,399
conveniently requires

244
00:09:16,399 --> 00:09:19,760
minimal architectural changes uh and

245
00:09:19,760 --> 00:09:21,200
parameter updates in order to be

246
00:09:21,200 --> 00:09:23,440
fine-tuned on new downstream tasks

247
00:09:23,440 --> 00:09:25,920
we simply process social media posts

248
00:09:25,920 --> 00:09:27,680
from the above data sets

249
00:09:27,680 --> 00:09:30,880
and uh we

250
00:09:30,880 --> 00:09:32,399
through the free training model whose

251
00:09:32,399 --> 00:09:34,080
activations were then fed through

252
00:09:34,080 --> 00:09:35,279
adjustable weights

253
00:09:35,279 --> 00:09:38,080
into a linear output layer the

254
00:09:38,080 --> 00:09:39,839
fine-tuning objective here was the same

255
00:09:39,839 --> 00:09:42,959
as gbt2 was originally trained on except

256
00:09:42,959 --> 00:09:44,800
now its training dataset call

257
00:09:44,800 --> 00:09:47,519
includes uh contents from a social media

258
00:09:47,519 --> 00:09:49,040
disinformation campaign

259
00:09:49,040 --> 00:09:50,959
we also added this end of text string

260
00:09:50,959 --> 00:09:53,120
and the suffix for each post to adapt

261
00:09:53,120 --> 00:09:54,800
the model for the shorter length of

262
00:09:54,800 --> 00:09:55,920
social media text

263
00:09:55,920 --> 00:09:57,440
and after generation you can see the

264
00:09:57,440 --> 00:09:59,519
sample uh generated by

265
00:09:59,519 --> 00:10:02,320
the gpt2 model and now you can see that

266
00:10:02,320 --> 00:10:02,800
how

267
00:10:02,800 --> 00:10:04,880
these text generations differ from the

268
00:10:04,880 --> 00:10:06,480
original one that we have seen

269
00:10:06,480 --> 00:10:10,240
before and now they look more like

270
00:10:10,240 --> 00:10:12,399
uh the type of contents we see when we

271
00:10:12,399 --> 00:10:13,920
spoke to social media they are short

272
00:10:13,920 --> 00:10:14,720
here fighting

273
00:10:14,720 --> 00:10:17,120
stress certainty and outrage regarding

274
00:10:17,120 --> 00:10:18,640
political issues and contain

275
00:10:18,640 --> 00:10:21,279
emphasis like an exclamation point and

276
00:10:21,279 --> 00:10:22,480
they also contain

277
00:10:22,480 --> 00:10:25,279
uh these idiosyncrasies like hashtags

278
00:10:25,279 --> 00:10:27,200
emojis that positionally manifest

279
00:10:27,200 --> 00:10:29,760
at the end of this generated text and

280
00:10:29,760 --> 00:10:31,760
depicting a semantic style

281
00:10:31,760 --> 00:10:33,440
which is regularly exhibited by the

282
00:10:33,440 --> 00:10:36,240
actual user on social media

283
00:10:36,240 --> 00:10:38,640
so after that we also have faced some

284
00:10:38,640 --> 00:10:39,680
challenges like

285
00:10:39,680 --> 00:10:41,680
since we have this multiple data sources

286
00:10:41,680 --> 00:10:42,959
available and

287
00:10:42,959 --> 00:10:45,920
training our gpt2 model was not cheap

288
00:10:45,920 --> 00:10:47,519
and rather expensive in terms of the

289
00:10:47,519 --> 00:10:48,720
computational

290
00:10:48,720 --> 00:10:51,839
uh point of view so how can we select a

291
00:10:51,839 --> 00:10:54,160
single data data set in an objective way

292
00:10:54,160 --> 00:10:55,279
so that

293
00:10:55,279 --> 00:10:59,040
the the fine-tuned language model can

294
00:10:59,040 --> 00:11:02,079
generalize well for

295
00:11:02,079 --> 00:11:04,160
social media disinformation generation

296
00:11:04,160 --> 00:11:05,680
and also detection

297
00:11:05,680 --> 00:11:09,279
so for that we look into this experiment

298
00:11:09,279 --> 00:11:10,560
of perplexity

299
00:11:10,560 --> 00:11:12,800
and perfect city basically talks about

300
00:11:12,800 --> 00:11:14,560
the probability that the

301
00:11:14,560 --> 00:11:17,680
how well the model can generate

302
00:11:17,680 --> 00:11:21,040
a correct next word given

303
00:11:21,040 --> 00:11:24,480
some previous uh engrams are available

304
00:11:24,480 --> 00:11:27,760
and for that uh basically the the lower

305
00:11:27,760 --> 00:11:29,120
the perplexity score

306
00:11:29,120 --> 00:11:32,959
the better so for this experiment

307
00:11:32,959 --> 00:11:36,880
we fine-tuned three separate language

308
00:11:36,880 --> 00:11:37,600
models

309
00:11:37,600 --> 00:11:39,920
and each all of them were trained on

310
00:11:39,920 --> 00:11:40,640
their

311
00:11:40,640 --> 00:11:44,240
own dataset data corpus namely

312
00:11:44,240 --> 00:11:47,279
we train a language model on nbc

313
00:11:47,279 --> 00:11:49,360
news dataset we train the language model

314
00:11:49,360 --> 00:11:50,320
on

315
00:11:50,320 --> 00:11:52,639
twitter dataset we train a language to

316
00:11:52,639 --> 00:11:55,120
fine-tune a language model on

317
00:11:55,120 --> 00:11:58,399
the 538 data set and then it

318
00:11:58,399 --> 00:12:02,079
we we ran it and we also

319
00:12:02,079 --> 00:12:03,760
each of these fine-tuned language models

320
00:12:03,760 --> 00:12:05,839
were then tested against the whole

321
00:12:05,839 --> 00:12:08,880
dataset from the other

322
00:12:09,120 --> 00:12:11,680
hold out data sets from the other uh

323
00:12:11,680 --> 00:12:12,480
data sources

324
00:12:12,480 --> 00:12:16,560
available so the look here you can see

325
00:12:16,560 --> 00:12:19,040
that the lowest scores fell along the

326
00:12:19,040 --> 00:12:21,040
main diagonal of the public city

327
00:12:21,040 --> 00:12:22,639
conclusion matrix meaning that the fine

328
00:12:22,639 --> 00:12:24,800
tuned language model were best at

329
00:12:24,800 --> 00:12:26,399
predicting the next word on

330
00:12:26,399 --> 00:12:28,880
this data originating from within their

331
00:12:28,880 --> 00:12:29,920
own data sets

332
00:12:29,920 --> 00:12:32,079
and the language model fine tuned on

333
00:12:32,079 --> 00:12:34,240
twitter's election center big data set

334
00:12:34,240 --> 00:12:36,720
displayed the lowest perfect city scores

335
00:12:36,720 --> 00:12:37,360
when

336
00:12:37,360 --> 00:12:40,000
average across all held out test data

337
00:12:40,000 --> 00:12:40,639
sets

338
00:12:40,639 --> 00:12:43,200
so we selected posts sampled from this

339
00:12:43,200 --> 00:12:45,040
data set to demonstrate classification

340
00:12:45,040 --> 00:12:46,399
find units

341
00:12:46,399 --> 00:12:49,600
now for the rest of the presentation

342
00:12:49,600 --> 00:12:53,519
philip will continue

343
00:12:53,519 --> 00:12:55,519
hi everyone once again my name is phil

344
00:12:55,519 --> 00:12:57,360
telly and i'm a staff data scientist at

345
00:12:57,360 --> 00:12:58,160
fireeye

346
00:12:58,160 --> 00:13:01,200
so now that sajid has fine-tuned gpt2 to

347
00:13:01,200 --> 00:13:03,600
generate tweets resembling i o activity

348
00:13:03,600 --> 00:13:04,800
i'm going to explore how we use this

349
00:13:04,800 --> 00:13:06,480
capability to design detection tools for

350
00:13:06,480 --> 00:13:06,800
this

351
00:13:06,800 --> 00:13:09,920
and other i o campaigns

352
00:13:09,920 --> 00:13:11,680
so just like when sajid showed how to

353
00:13:11,680 --> 00:13:13,760
fine tune gpt2 for language modeling

354
00:13:13,760 --> 00:13:15,120
we didn't need to make any drastic

355
00:13:15,120 --> 00:13:17,519
architectural changes for classification

356
00:13:17,519 --> 00:13:18,800
we did need to provide the model with

357
00:13:18,800 --> 00:13:20,480
the label data set so we grouped

358
00:13:20,480 --> 00:13:21,920
together social media posts based on

359
00:13:21,920 --> 00:13:23,360
whether they were leveraged in io

360
00:13:23,360 --> 00:13:25,839
activity or whether they were benign as

361
00:13:25,839 --> 00:13:27,760
sajid said the model fine-tuned

362
00:13:27,760 --> 00:13:29,360
on the election integrity data set

363
00:13:29,360 --> 00:13:31,440
displayed the lowest perplexity scores

364
00:13:31,440 --> 00:13:33,040
so we sampled from this data set for our

365
00:13:33,040 --> 00:13:34,480
positive class

366
00:13:34,480 --> 00:13:36,399
for the benign negative class english

367
00:13:36,399 --> 00:13:37,680
language posts were gathered from

368
00:13:37,680 --> 00:13:39,600
verified twitter accounts whose posts

369
00:13:39,600 --> 00:13:40,079
contain

370
00:13:40,079 --> 00:13:42,160
diverse inaccurate content and alcus

371
00:13:42,160 --> 00:13:43,600
content

372
00:13:43,600 --> 00:13:45,440
next we process these posts through the

373
00:13:45,440 --> 00:13:46,800
pre-trained model

374
00:13:46,800 --> 00:13:48,480
this time we fed activations through

375
00:13:48,480 --> 00:13:49,920
adjustable weights into two linear

376
00:13:49,920 --> 00:13:50,639
output layers

377
00:13:50,639 --> 00:13:52,560
meaning fine tuning was formulated as a

378
00:13:52,560 --> 00:13:54,240
multitask objective with

379
00:13:54,240 --> 00:13:55,920
classification loss together with an

380
00:13:55,920 --> 00:13:58,000
auxiliary language modeling loss

381
00:13:58,000 --> 00:13:59,760
we prepended posts with a new beginning

382
00:13:59,760 --> 00:14:02,000
of sentence or bos delimiter token

383
00:14:02,000 --> 00:14:04,000
and suffixed post with the class label

384
00:14:04,000 --> 00:14:05,920
or cls hidden state token so that each

385
00:14:05,920 --> 00:14:07,600
post was fed into the model

386
00:14:07,600 --> 00:14:11,279
according to what you see here below

387
00:14:11,279 --> 00:14:13,440
the figures show the evolution of losses

388
00:14:13,440 --> 00:14:15,120
during fine-tuning and the resulting

389
00:14:15,120 --> 00:14:16,800
rock curve when evaluated on the held

390
00:14:16,800 --> 00:14:18,720
out test set consisting of

391
00:14:18,720 --> 00:14:21,680
66 000 tweets the convergence of these

392
00:14:21,680 --> 00:14:23,440
losses to low values together with a

393
00:14:23,440 --> 00:14:23,839
high

394
00:14:23,839 --> 00:14:25,920
area under the curve indicated a hopeful

395
00:14:25,920 --> 00:14:27,279
sign that this approach could allow this

396
00:14:27,279 --> 00:14:29,120
model to accurately detect io activity

397
00:14:29,120 --> 00:14:31,199
versus benign activity

398
00:14:31,199 --> 00:14:32,560
but can we make this model even more

399
00:14:32,560 --> 00:14:34,560
useful for io analysts

400
00:14:34,560 --> 00:14:36,240
to answer this question we considered

401
00:14:36,240 --> 00:14:38,959
attention attention scores are computed

402
00:14:38,959 --> 00:14:41,199
between all words in a text sequence to

403
00:14:41,199 --> 00:14:42,959
compute attention scores the transformer

404
00:14:42,959 --> 00:14:44,000
performs a dot product

405
00:14:44,000 --> 00:14:45,760
between a query vector q and a key

406
00:14:45,760 --> 00:14:47,519
vector k

407
00:14:47,519 --> 00:14:49,839
k represe k represents the other words

408
00:14:49,839 --> 00:14:51,279
that receive attention from q

409
00:14:51,279 --> 00:14:52,880
the query word and might contribute a

410
00:14:52,880 --> 00:14:54,320
better representation for it in its

411
00:14:54,320 --> 00:14:55,519
current context and q

412
00:14:55,519 --> 00:14:56,959
represents the word that searches for

413
00:14:56,959 --> 00:14:58,560
other words in the sequence to pay

414
00:14:58,560 --> 00:15:00,560
attention to that may supply context for

415
00:15:00,560 --> 00:15:01,600
it

416
00:15:01,600 --> 00:15:03,199
the figure on the right displays how

417
00:15:03,199 --> 00:15:04,720
attention is computing using a

418
00:15:04,720 --> 00:15:07,120
visualization tool called birdviz

419
00:15:07,120 --> 00:15:08,399
vertical bars represent neuron

420
00:15:08,399 --> 00:15:10,000
activations and lines represent the

421
00:15:10,000 --> 00:15:13,120
strength of attention between words

422
00:15:13,120 --> 00:15:14,720
blue indicates positive values in red

423
00:15:14,720 --> 00:15:16,240
indicates negative

424
00:15:16,240 --> 00:15:18,079
columns trace attention scores from the

425
00:15:18,079 --> 00:15:19,279
highlighted word on the left

426
00:15:19,279 --> 00:15:21,040
america to the complete sequence of

427
00:15:21,040 --> 00:15:22,320
words on the right

428
00:15:22,320 --> 00:15:24,160
the element wise product shows how q and

429
00:15:24,160 --> 00:15:25,760
k contribute to the dot product which is

430
00:15:25,760 --> 00:15:27,519
finally normalized by a softmax function

431
00:15:27,519 --> 00:15:28,880
that outputs the desired attention

432
00:15:28,880 --> 00:15:29,920
scores

433
00:15:29,920 --> 00:15:31,600
so to decide to predict the hashtag

434
00:15:31,600 --> 00:15:33,279
following the word america this part of

435
00:15:33,279 --> 00:15:34,800
the model attends to preceding words

436
00:15:34,800 --> 00:15:35,440
like ban

437
00:15:35,440 --> 00:15:38,160
immigrants and disgrace these syntactic

438
00:15:38,160 --> 00:15:39,360
relationships are valuable from an

439
00:15:39,360 --> 00:15:40,959
analysis point of view because they can

440
00:15:40,959 --> 00:15:42,480
help identify an io campaign's

441
00:15:42,480 --> 00:15:44,800
interrelated keywords and phrases

442
00:15:44,800 --> 00:15:46,480
these indicators can in turn be used to

443
00:15:46,480 --> 00:15:48,079
pivot between suspect social media

444
00:15:48,079 --> 00:15:49,440
accounts based on shared lexical

445
00:15:49,440 --> 00:15:50,480
patterns

446
00:15:50,480 --> 00:15:52,560
help identify common narratives and even

447
00:15:52,560 --> 00:15:56,000
to perform more proactive thread hunting

448
00:15:56,000 --> 00:15:58,000
so sajid mentioned some of the existing

449
00:15:58,000 --> 00:15:59,600
automated detection methods

450
00:15:59,600 --> 00:16:01,279
in literature which rely primarily on

451
00:16:01,279 --> 00:16:03,040
large curated data sets external

452
00:16:03,040 --> 00:16:04,000
knowledge bases

453
00:16:04,000 --> 00:16:05,680
or time-consuming custom feature

454
00:16:05,680 --> 00:16:07,519
engineering each of which translate

455
00:16:07,519 --> 00:16:08,639
poorly to a more realistic

456
00:16:08,639 --> 00:16:11,279
multi-campaign threat landscape which

457
00:16:11,279 --> 00:16:14,240
analysts are time and resource limited

458
00:16:14,240 --> 00:16:15,360
by contrast

459
00:16:15,360 --> 00:16:16,639
starting out with a large pre-trained

460
00:16:16,639 --> 00:16:18,160
model and fine-tuning it on a per

461
00:16:18,160 --> 00:16:19,519
campaign basis

462
00:16:19,519 --> 00:16:21,120
allows us to more agilely detect o

463
00:16:21,120 --> 00:16:23,440
activity by giving us a head start

464
00:16:23,440 --> 00:16:25,040
however some care needs to be taken to

465
00:16:25,040 --> 00:16:27,040
ensure this captures campaign narratives

466
00:16:27,040 --> 00:16:28,560
and not just their individual words and

467
00:16:28,560 --> 00:16:30,639
phrases doing things like sampling by

468
00:16:30,639 --> 00:16:31,279
topics

469
00:16:31,279 --> 00:16:32,959
doing temporal chain test splits and

470
00:16:32,959 --> 00:16:34,560
adjusting class balances

471
00:16:34,560 --> 00:16:36,240
relative to the rarity of i o activity

472
00:16:36,240 --> 00:16:38,000
give much better sense of what we should

473
00:16:38,000 --> 00:16:38,639
expect

474
00:16:38,639 --> 00:16:41,440
performance wise in the wild while our

475
00:16:41,440 --> 00:16:42,880
work and that of others primarily

476
00:16:42,880 --> 00:16:43,680
focuses on

477
00:16:43,680 --> 00:16:45,279
content analysis there's also an

478
00:16:45,279 --> 00:16:46,720
undeniable signal and other available

479
00:16:46,720 --> 00:16:47,759
metadata

480
00:16:47,759 --> 00:16:49,839
and even network interactions each which

481
00:16:49,839 --> 00:16:51,440
can help add context for downstream

482
00:16:51,440 --> 00:16:53,920
classifiers when stacked together

483
00:16:53,920 --> 00:16:55,759
oftentimes these campaigns are foreign

484
00:16:55,759 --> 00:16:57,360
in nature and can be conducted in

485
00:16:57,360 --> 00:16:58,800
different languages and localizations

486
00:16:58,800 --> 00:16:59,920
other than english

487
00:16:59,920 --> 00:17:01,519
and in these cases we've seen success in

488
00:17:01,519 --> 00:17:02,720
applying pre-trained models that are

489
00:17:02,720 --> 00:17:05,359
multilingual such as burt

490
00:17:05,359 --> 00:17:07,359
another concern for large transformer

491
00:17:07,359 --> 00:17:08,480
models is latency

492
00:17:08,480 --> 00:17:09,760
and while we're still working to reduce

493
00:17:09,760 --> 00:17:11,439
this a few promising approaches such as

494
00:17:11,439 --> 00:17:13,359
distillation and pruning are capable of

495
00:17:13,359 --> 00:17:14,880
maintaining detection accuracy levels

496
00:17:14,880 --> 00:17:17,039
while reducing the number of parameters

497
00:17:17,039 --> 00:17:19,760
and time required to make a prediction

498
00:17:19,760 --> 00:17:21,119
lastly it's worth noting that we won't

499
00:17:21,119 --> 00:17:21,839
ever

500
00:17:21,839 --> 00:17:23,839
be able to completely remove the human

501
00:17:23,839 --> 00:17:26,240
element from the analysis pipeline

502
00:17:26,240 --> 00:17:27,760
their initial work on the front lines is

503
00:17:27,760 --> 00:17:29,760
important for collecting and initially

504
00:17:29,760 --> 00:17:32,000
identifying labeled i o campaign data

505
00:17:32,000 --> 00:17:33,280
for us

506
00:17:33,280 --> 00:17:35,120
so in this presentation we demonstrated

507
00:17:35,120 --> 00:17:36,880
how to fine tune gpt2

508
00:17:36,880 --> 00:17:38,559
on social media posts previously

509
00:17:38,559 --> 00:17:40,559
leveraged in i o activity

510
00:17:40,559 --> 00:17:42,080
transfer learning allowed us to classify

511
00:17:42,080 --> 00:17:43,679
these posts with a high auc

512
00:17:43,679 --> 00:17:45,760
score and fire a threat analysts can

513
00:17:45,760 --> 00:17:46,880
analyze

514
00:17:46,880 --> 00:17:49,039
this detection capability and use it in

515
00:17:49,039 --> 00:17:50,960
order to discover and triage similar

516
00:17:50,960 --> 00:17:52,960
emergent operations

517
00:17:52,960 --> 00:17:54,799
sajid show how to transfer learning

518
00:17:54,799 --> 00:17:56,000
allowed us to generate credible

519
00:17:56,000 --> 00:17:57,679
synthetic text with low perplexity

520
00:17:57,679 --> 00:17:58,160
scores

521
00:17:58,160 --> 00:18:00,480
gbt2's authors and subsequent

522
00:18:00,480 --> 00:18:02,000
researchers have warned about potential

523
00:18:02,000 --> 00:18:03,760
malicious use cases enabled by this

524
00:18:03,760 --> 00:18:05,840
language generation technology

525
00:18:05,840 --> 00:18:08,240
and our research reinforces this concern

526
00:18:08,240 --> 00:18:09,360
so with that

527
00:18:09,360 --> 00:18:10,960
i'll conclude the presentation and

528
00:18:10,960 --> 00:18:12,720
thanks for your time and attention

529
00:18:12,720 --> 00:18:14,320
please reach out with questions via

530
00:18:14,320 --> 00:18:15,760
twitter or

531
00:18:15,760 --> 00:18:29,520
via the email addresses listed here

