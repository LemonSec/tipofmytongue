1
00:00:08,639 --> 00:00:11,518
hi

2
00:00:09,200 --> 00:00:13,280
my name is kayla fanadore i'm a doctoral

3
00:00:11,519 --> 00:00:14,799
candidate at the naval post graduate

4
00:00:13,280 --> 00:00:16,079
school and i also work for the

5
00:00:14,799 --> 00:00:18,759
department of defense

6
00:00:16,079 --> 00:00:19,919
i'm excited to be here today to discuss

7
00:00:18,760 --> 00:00:21,439
representativeness

8
00:00:19,920 --> 00:00:23,039
in the benchmark for vulnerability

9
00:00:21,439 --> 00:00:26,480
analysis tools or

10
00:00:23,039 --> 00:00:28,640
be that let's get right into it first up

11
00:00:26,480 --> 00:00:30,880
let's discuss the problem

12
00:00:28,640 --> 00:00:32,558
big picture as many of us know the

13
00:00:30,880 --> 00:00:34,719
problem is that there are

14
00:00:32,558 --> 00:00:37,199
too many software vulnerabilities to

15
00:00:34,719 --> 00:00:38,000
rely on manual vulnerability analysis

16
00:00:37,200 --> 00:00:39,840
alone

17
00:00:38,000 --> 00:00:41,840
the pervasiveness and variety of

18
00:00:39,840 --> 00:00:43,120
software is disproportionate to the

19
00:00:41,840 --> 00:00:45,039
number of individuals

20
00:00:43,120 --> 00:00:46,559
able to perform manual vulnerability

21
00:00:45,039 --> 00:00:48,800
analysis so

22
00:00:46,559 --> 00:00:50,640
we as a community have turned to using

23
00:00:48,800 --> 00:00:52,959
tools and techniques to complement the

24
00:00:50,640 --> 00:00:54,640
vulnerability analysis process

25
00:00:52,960 --> 00:00:56,399
now there are a lot of vulnerability

26
00:00:54,640 --> 00:00:58,879
analysis tools or that

27
00:00:56,399 --> 00:00:59,440
on the market today these tools such as

28
00:00:58,879 --> 00:01:02,399
cli

29
00:00:59,440 --> 00:01:04,959
mayhem anger and z3 are designed to

30
00:01:02,399 --> 00:01:06,720
identify vulnerabilities in systems

31
00:01:04,959 --> 00:01:09,119
some even boast that they're able to

32
00:01:06,720 --> 00:01:10,960
automatically discover vulnerabilities

33
00:01:09,119 --> 00:01:13,040
but there's no standard method or

34
00:01:10,960 --> 00:01:16,000
benchmark to compare the tools

35
00:01:13,040 --> 00:01:18,400
we have no comparative metrics of the

36
00:01:16,000 --> 00:01:19,680
types of vulnerabilities each tool can

37
00:01:18,400 --> 00:01:21,680
or cannot find

38
00:01:19,680 --> 00:01:23,920
how quickly they can do so or the number

39
00:01:21,680 --> 00:01:25,520
of false positives they report

40
00:01:23,920 --> 00:01:27,680
so when a developer wants to compare

41
00:01:25,520 --> 00:01:29,600
tools or when a user wants to select the

42
00:01:27,680 --> 00:01:31,200
optimal tool for their use case

43
00:01:29,600 --> 00:01:33,759
there's no standard method for them to

44
00:01:31,200 --> 00:01:36,159
do so our solution

45
00:01:33,759 --> 00:01:37,600
be that the benchmark for vulnerability

46
00:01:36,159 --> 00:01:39,520
analysis tools

47
00:01:37,600 --> 00:01:42,158
there are many aspects of bvat that must

48
00:01:39,520 --> 00:01:45,280
be addressed a good benchmark should be

49
00:01:42,159 --> 00:01:47,439
relevant repeatable usable fair and its

50
00:01:45,280 --> 00:01:50,240
results should be verifiable

51
00:01:47,439 --> 00:01:52,158
in this paper we specifically focus on

52
00:01:50,240 --> 00:01:54,880
making sure that the problems within

53
00:01:52,159 --> 00:01:56,399
bevat are representative of reality

54
00:01:54,880 --> 00:01:58,158
we explore what it would look like to

55
00:01:56,399 --> 00:01:59,360
create a benchmark for vulnerability

56
00:01:58,159 --> 00:02:01,759
analysis tools

57
00:01:59,360 --> 00:02:03,600
that is representative of vulnerability

58
00:02:01,759 --> 00:02:06,640
instances and weakness types

59
00:02:03,600 --> 00:02:08,239
as they occur in the real world our goal

60
00:02:06,640 --> 00:02:10,318
is that bevat will be embraced by the

61
00:02:08,239 --> 00:02:12,959
community as the standard method to

62
00:02:10,318 --> 00:02:14,958
compare vulnerability analysis tools

63
00:02:12,959 --> 00:02:16,400
before we reinvent the wheel though we

64
00:02:14,959 --> 00:02:17,040
also took a look at what's already out

65
00:02:16,400 --> 00:02:18,480
there

66
00:02:17,040 --> 00:02:20,640
our analysis revealed that

67
00:02:18,480 --> 00:02:22,959
vulnerabilities are disproportionately

68
00:02:20,640 --> 00:02:24,720
represented in current data sets

69
00:02:22,959 --> 00:02:26,720
meaning that when these data sets are

70
00:02:24,720 --> 00:02:28,560
used to compare the tools

71
00:02:26,720 --> 00:02:30,000
the results are not reflective of

72
00:02:28,560 --> 00:02:32,080
reality

73
00:02:30,000 --> 00:02:35,120
we also want to know right up front that

74
00:02:32,080 --> 00:02:38,480
this work is ongoing

75
00:02:35,120 --> 00:02:40,000
in order to determine what vulnerability

76
00:02:38,480 --> 00:02:44,000
types are prevalent today

77
00:02:40,000 --> 00:02:46,080
we use two sources the cve and the cwe

78
00:02:44,000 --> 00:02:48,160
you may be you may be familiar with

79
00:02:46,080 --> 00:02:50,319
these data sets and we recognize that

80
00:02:48,160 --> 00:02:52,879
the cve and the cwe

81
00:02:50,319 --> 00:02:54,560
are not exhausted but to our knowledge

82
00:02:52,879 --> 00:02:57,040
they provide the most comprehensive

83
00:02:54,560 --> 00:02:58,959
repositories of vulnerability instances

84
00:02:57,040 --> 00:03:00,799
and weakness types

85
00:02:58,959 --> 00:03:02,480
okay now that that's out of the way

86
00:03:00,800 --> 00:03:05,680
let's talk about the cve

87
00:03:02,480 --> 00:03:06,799
the cve or common vulnerabilities and

88
00:03:05,680 --> 00:03:09,120
exposures

89
00:03:06,800 --> 00:03:12,159
is a dictionary of publicly known

90
00:03:09,120 --> 00:03:15,120
vulnerability and exposure instances

91
00:03:12,159 --> 00:03:16,799
these are actual no kidding instances of

92
00:03:15,120 --> 00:03:18,560
vulnerabilities that have occurred in

93
00:03:16,800 --> 00:03:21,280
the real world

94
00:03:18,560 --> 00:03:21,599
each entry in the dictionary describes

95
00:03:21,280 --> 00:03:23,920
an

96
00:03:21,599 --> 00:03:24,798
instance of a vulnerability and includes

97
00:03:23,920 --> 00:03:28,480
metadata

98
00:03:24,799 --> 00:03:30,640
such as a unique identifier or cve id

99
00:03:28,480 --> 00:03:33,119
a standard description and where

100
00:03:30,640 --> 00:03:36,879
applicable a corresponding weakness type

101
00:03:33,120 --> 00:03:40,760
or cwe from 1999

102
00:03:36,879 --> 00:03:44,319
to may 2020 the cve published over

103
00:03:40,760 --> 00:03:45,599
160 000 known vulnerability and exposure

104
00:03:44,319 --> 00:03:49,599
instances

105
00:03:45,599 --> 00:03:52,518
over half 93 000 of all cves ever

106
00:03:49,599 --> 00:03:53,920
recorded were published between 2014 to

107
00:03:52,519 --> 00:03:56,560
2019.

108
00:03:53,920 --> 00:03:57,839
of these 75 000 were accepted by the

109
00:03:56,560 --> 00:04:00,080
community

110
00:03:57,840 --> 00:04:02,000
this provides a substantial collection

111
00:04:00,080 --> 00:04:04,879
of real vulnerability instances

112
00:04:02,000 --> 00:04:06,799
that we'll use for our analysis here we

113
00:04:04,879 --> 00:04:10,560
see the sum of cves

114
00:04:06,799 --> 00:04:12,319
by year published from 1999 to 2020.

115
00:04:10,560 --> 00:04:14,879
the greatest number of vulnerabilities

116
00:04:12,319 --> 00:04:18,159
was published in 2018

117
00:04:14,879 --> 00:04:20,399
that year about 21 600 vulnerabilities

118
00:04:18,160 --> 00:04:22,880
was published by the cbe

119
00:04:20,399 --> 00:04:23,440
the problem with the cve data is that

120
00:04:22,880 --> 00:04:25,120
alone

121
00:04:23,440 --> 00:04:27,759
it doesn't provide us with a way to

122
00:04:25,120 --> 00:04:30,320
classify the vulnerability instances

123
00:04:27,759 --> 00:04:32,160
that's where our second data set the cwe

124
00:04:30,320 --> 00:04:36,080
comes in

125
00:04:32,160 --> 00:04:38,080
the cwe or common weakness enumeration

126
00:04:36,080 --> 00:04:40,880
is the community developed list of

127
00:04:38,080 --> 00:04:44,320
weaknesses with security ramifications

128
00:04:40,880 --> 00:04:46,719
like the cve each entry in the cwe

129
00:04:44,320 --> 00:04:47,840
contains metadata about each weakness

130
00:04:46,720 --> 00:04:51,280
type

131
00:04:47,840 --> 00:04:53,758
for example each cwe entry contains a

132
00:04:51,280 --> 00:04:54,479
corresponding abstraction level such as

133
00:04:53,759 --> 00:04:58,240
a pillar

134
00:04:54,479 --> 00:05:00,240
a clase a pillar a class or a base

135
00:04:58,240 --> 00:05:03,039
we can use these abstraction levels to

136
00:05:00,240 --> 00:05:05,039
organize the data into 10 rooted trees

137
00:05:03,039 --> 00:05:06,080
where there is one tree corresponding to

138
00:05:05,039 --> 00:05:09,919
each of the 10

139
00:05:06,080 --> 00:05:11,120
cwe pillars or more comprehensively as

140
00:05:09,919 --> 00:05:13,680
this graphic shows

141
00:05:11,120 --> 00:05:14,320
we can view the data as a single rooted

142
00:05:13,680 --> 00:05:17,600
tree

143
00:05:14,320 --> 00:05:19,680
using the specific view cwe 1000

144
00:05:17,600 --> 00:05:22,560
called research concepts as the root

145
00:05:19,680 --> 00:05:22,560
node of the tree

146
00:05:23,120 --> 00:05:27,600
okay so let's recap first we extracted

147
00:05:26,800 --> 00:05:31,360
the data

148
00:05:27,600 --> 00:05:34,560
for over 75 000 vulnerability instances

149
00:05:31,360 --> 00:05:38,080
called cves then we gathered information

150
00:05:34,560 --> 00:05:40,320
for about 800 weakness types or cwes

151
00:05:38,080 --> 00:05:41,919
now we're going to combine things we can

152
00:05:40,320 --> 00:05:45,759
use the correlation between

153
00:05:41,919 --> 00:05:48,719
cves and cwes to represent each of those

154
00:05:45,759 --> 00:05:49,759
10 cwe pillars we talked about before as

155
00:05:48,720 --> 00:05:51,600
a percentage

156
00:05:49,759 --> 00:05:53,680
of the total known vulnerability

157
00:05:51,600 --> 00:05:55,280
instances that occurred in the past five

158
00:05:53,680 --> 00:05:58,080
years

159
00:05:55,280 --> 00:05:59,840
the green outer circle tells us that

160
00:05:58,080 --> 00:06:04,240
each cwe

161
00:05:59,840 --> 00:06:07,119
in this graphic is part of cwe view 1000

162
00:06:04,240 --> 00:06:08,240
each of the circles outlined in blue

163
00:06:07,120 --> 00:06:11,759
then represents

164
00:06:08,240 --> 00:06:12,560
one of the 10 cwe pillars the size of

165
00:06:11,759 --> 00:06:14,479
each circle

166
00:06:12,560 --> 00:06:16,479
is proportionate to the number of

167
00:06:14,479 --> 00:06:19,120
vulnerability instances

168
00:06:16,479 --> 00:06:20,080
cves that correspond to a particular

169
00:06:19,120 --> 00:06:23,360
weakness type

170
00:06:20,080 --> 00:06:23,840
cwe all the relationship and hierarchy

171
00:06:23,360 --> 00:06:26,720
data

172
00:06:23,840 --> 00:06:27,520
is maintained in this view you may

173
00:06:26,720 --> 00:06:30,240
observe

174
00:06:27,520 --> 00:06:31,840
that some of the cwe pillars have very

175
00:06:30,240 --> 00:06:34,960
few cve

176
00:06:31,840 --> 00:06:35,679
instances whereas others have many the

177
00:06:34,960 --> 00:06:38,159
fewer

178
00:06:35,680 --> 00:06:39,280
the vulnerability instances a weakness

179
00:06:38,160 --> 00:06:41,360
type has

180
00:06:39,280 --> 00:06:43,840
the smaller all the enclosing circles

181
00:06:41,360 --> 00:06:47,520
will be and vice versa

182
00:06:43,840 --> 00:06:50,000
for example cwe 664 is a pillar

183
00:06:47,520 --> 00:06:51,359
it's just it is distinguished here by

184
00:06:50,000 --> 00:06:54,479
the thick blue line

185
00:06:51,360 --> 00:06:55,520
pillar 664 and all of its children and

186
00:06:54,479 --> 00:06:59,199
grandchildren

187
00:06:55,520 --> 00:07:04,880
represent 45 of community accepted

188
00:06:59,199 --> 00:07:07,120
cves published between 2014 to 2019

189
00:07:04,880 --> 00:07:08,080
so how does all of this relate to be

190
00:07:07,120 --> 00:07:10,479
that well

191
00:07:08,080 --> 00:07:12,560
again a key property of be that is that

192
00:07:10,479 --> 00:07:14,960
it's representative of reality

193
00:07:12,560 --> 00:07:16,400
we define a representative set as a

194
00:07:14,960 --> 00:07:19,520
subset of tests

195
00:07:16,400 --> 00:07:22,080
a subset of vulnerability instances

196
00:07:19,520 --> 00:07:24,159
or test cases that adequately represents

197
00:07:22,080 --> 00:07:27,359
the larger set of known vulnerability

198
00:07:24,160 --> 00:07:27,360
instances and types

199
00:07:27,759 --> 00:07:31,440
after we determined what a

200
00:07:29,120 --> 00:07:33,199
representative set should look like

201
00:07:31,440 --> 00:07:35,280
we examine five open source

202
00:07:33,199 --> 00:07:37,199
vulnerability data sets to see if any

203
00:07:35,280 --> 00:07:38,400
already provide what we're looking for

204
00:07:37,199 --> 00:07:40,720
what you're looking at here is a

205
00:07:38,400 --> 00:07:41,840
collection of sunburst diagrams aren't

206
00:07:40,720 --> 00:07:44,000
they lovely

207
00:07:41,840 --> 00:07:45,840
the largest sunburst on the left

208
00:07:44,000 --> 00:07:47,440
actually shows the same data that you

209
00:07:45,840 --> 00:07:49,280
saw on the previous slide

210
00:07:47,440 --> 00:07:51,199
again it's a sum of vulnerability

211
00:07:49,280 --> 00:07:54,000
instances cves

212
00:07:51,199 --> 00:07:57,120
by their associated weakness type cwes

213
00:07:54,000 --> 00:07:59,520
published between 2014-2019

214
00:07:57,120 --> 00:08:00,879
getting tired of saying that okay each

215
00:07:59,520 --> 00:08:04,400
color in the diagram

216
00:08:00,879 --> 00:08:06,160
represents one of the 10 cwe pillars

217
00:08:04,400 --> 00:08:07,758
like the previous diagrams all

218
00:08:06,160 --> 00:08:10,000
relationship and hierarchy data is

219
00:08:07,759 --> 00:08:12,319
maintained in this view as well

220
00:08:10,000 --> 00:08:14,240
each of the smaller diagrams then shows

221
00:08:12,319 --> 00:08:14,800
what the existing distribution looks

222
00:08:14,240 --> 00:08:17,199
like

223
00:08:14,800 --> 00:08:19,039
in a particular data set the data sets

224
00:08:17,199 --> 00:08:22,479
we analyzed include

225
00:08:19,039 --> 00:08:23,120
juliet cac plus plus juliet java cgc

226
00:08:22,479 --> 00:08:26,080
corpus

227
00:08:23,120 --> 00:08:28,080
owasp benchmark and stone soup each

228
00:08:26,080 --> 00:08:30,400
contains test cases that can be used to

229
00:08:28,080 --> 00:08:32,478
assess vulnerability analysis tools

230
00:08:30,400 --> 00:08:34,718
for each data set there is a sunburst

231
00:08:32,479 --> 00:08:37,440
that includes a sum of test cases or

232
00:08:34,719 --> 00:08:39,599
vulnerabilities by weakness type

233
00:08:37,440 --> 00:08:41,200
these diagrams illustrate the stark

234
00:08:39,599 --> 00:08:42,719
contrast between the types

235
00:08:41,200 --> 00:08:44,640
the types of weaknesses that we're

236
00:08:42,719 --> 00:08:45,519
observing in the wild and those in

237
00:08:44,640 --> 00:08:47,920
current

238
00:08:45,519 --> 00:08:50,399
and current vulnerability data sets this

239
00:08:47,920 --> 00:08:52,959
analysis reiterates the need for a new

240
00:08:50,399 --> 00:08:54,480
more representative benchmark thus we

241
00:08:52,959 --> 00:08:58,880
leave the sixth spot open

242
00:08:54,480 --> 00:09:02,240
for b-bat another key property

243
00:08:58,880 --> 00:09:04,560
of b-vat is usability to be

244
00:09:02,240 --> 00:09:05,760
more usable we're motivated to reduce

245
00:09:04,560 --> 00:09:07,680
the size of b-vat

246
00:09:05,760 --> 00:09:09,040
due to time and resource constraints of

247
00:09:07,680 --> 00:09:11,040
our users

248
00:09:09,040 --> 00:09:13,199
we explored a number of options to

249
00:09:11,040 --> 00:09:14,319
identify a representative subset for

250
00:09:13,200 --> 00:09:16,160
b-vat

251
00:09:14,320 --> 00:09:18,080
we first explored the option of just

252
00:09:16,160 --> 00:09:18,719
taking a simple random sample of the

253
00:09:18,080 --> 00:09:21,040
data

254
00:09:18,720 --> 00:09:23,240
however our analysis revealed that a

255
00:09:21,040 --> 00:09:25,199
simple random sample would result in the

256
00:09:23,240 --> 00:09:26,720
misrepresentation of vulnerability

257
00:09:25,200 --> 00:09:28,800
instances and types

258
00:09:26,720 --> 00:09:30,560
this will result in be that looking

259
00:09:28,800 --> 00:09:31,760
similar to the previous data sets that

260
00:09:30,560 --> 00:09:34,640
we saw

261
00:09:31,760 --> 00:09:35,360
however by taking a stratified random

262
00:09:34,640 --> 00:09:37,920
sample

263
00:09:35,360 --> 00:09:39,680
we are able to identify a subset that is

264
00:09:37,920 --> 00:09:40,640
perfectly and proportionately

265
00:09:39,680 --> 00:09:43,040
representative

266
00:09:40,640 --> 00:09:44,399
of the larger set for those of you that

267
00:09:43,040 --> 00:09:46,399
may not be familiar

268
00:09:44,399 --> 00:09:47,440
this is exactly what stratified sampling

269
00:09:46,399 --> 00:09:49,839
is all about

270
00:09:47,440 --> 00:09:50,880
it preserves the relative relative

271
00:09:49,839 --> 00:09:53,519
proportions

272
00:09:50,880 --> 00:09:54,800
of strata or subgroups from a larger

273
00:09:53,519 --> 00:09:57,519
population

274
00:09:54,800 --> 00:09:58,079
in our case the strata are the 10 cwb

275
00:09:57,519 --> 00:10:00,480
pillars

276
00:09:58,080 --> 00:10:03,440
and the larger population is the sum of

277
00:10:00,480 --> 00:10:05,120
cves associated with each pillar

278
00:10:03,440 --> 00:10:07,040
it's important for us to use the

279
00:10:05,120 --> 00:10:08,880
stratified random sample

280
00:10:07,040 --> 00:10:10,079
because we just did all of the hard work

281
00:10:08,880 --> 00:10:12,000
to make sure that be that was

282
00:10:10,079 --> 00:10:13,839
representative of reality

283
00:10:12,000 --> 00:10:16,560
so we definitely don't want to skew that

284
00:10:13,839 --> 00:10:19,360
data the stratified random sample allows

285
00:10:16,560 --> 00:10:22,640
us to reduce the number of test cases

286
00:10:19,360 --> 00:10:25,279
in bevat from 55 000 to a little over

287
00:10:22,640 --> 00:10:25,279
two thousand

288
00:10:26,800 --> 00:10:30,719
this work focused on one property of b

289
00:10:29,480 --> 00:10:33,040
representativeness

290
00:10:30,720 --> 00:10:34,959
we use known vulnerability instances and

291
00:10:33,040 --> 00:10:37,040
their associated weakness types

292
00:10:34,959 --> 00:10:38,160
to determine what's going on in the real

293
00:10:37,040 --> 00:10:40,319
world

294
00:10:38,160 --> 00:10:41,680
we then reduce the number of test cases

295
00:10:40,320 --> 00:10:43,600
needed in bvat

296
00:10:41,680 --> 00:10:45,040
by taking a stratified random sample of

297
00:10:43,600 --> 00:10:46,959
the larger set

298
00:10:45,040 --> 00:10:48,240
while i am excited about the progress

299
00:10:46,959 --> 00:10:50,560
that we've made

300
00:10:48,240 --> 00:10:52,880
there is still a lot of work to be done

301
00:10:50,560 --> 00:10:55,359
we must also make sure that be that is

302
00:10:52,880 --> 00:10:57,519
repeatable usable fair and that the

303
00:10:55,360 --> 00:10:59,200
results are verifiable

304
00:10:57,519 --> 00:11:00,560
if you're interested in specifically

305
00:10:59,200 --> 00:11:02,160
what we're working on

306
00:11:00,560 --> 00:11:04,959
the existing data sets i talked about

307
00:11:02,160 --> 00:11:06,959
before contain over 150 000

308
00:11:04,959 --> 00:11:09,040
open source test cases that is

309
00:11:06,959 --> 00:11:10,880
significantly more than what we need

310
00:11:09,040 --> 00:11:12,640
this table shows the collective number

311
00:11:10,880 --> 00:11:14,480
of available test cases

312
00:11:12,640 --> 00:11:15,920
from those sets corresponding to each

313
00:11:14,480 --> 00:11:17,440
cwe pillar

314
00:11:15,920 --> 00:11:19,199
we're currently exploring methods to

315
00:11:17,440 --> 00:11:21,920
reuse those test cases just

316
00:11:19,200 --> 00:11:23,519
in a more representative way we could

317
00:11:21,920 --> 00:11:25,279
simply take a random sample

318
00:11:23,519 --> 00:11:27,440
but we're also looking at developing a

319
00:11:25,279 --> 00:11:28,959
more comprehensive strategy to reduce

320
00:11:27,440 --> 00:11:31,680
the number of test cases

321
00:11:28,959 --> 00:11:32,479
for example we may define a few popular

322
00:11:31,680 --> 00:11:34,959
use cases

323
00:11:32,480 --> 00:11:37,839
or be that and make sure that we

324
00:11:34,959 --> 00:11:40,239
identify test cases relevant to each

325
00:11:37,839 --> 00:11:42,320
we may also include additional variables

326
00:11:40,240 --> 00:11:43,519
or weighting factors prior to taking the

327
00:11:42,320 --> 00:11:45,360
stratified sample

328
00:11:43,519 --> 00:11:46,720
such as the severity ranking for each

329
00:11:45,360 --> 00:11:50,399
vulnerability

330
00:11:46,720 --> 00:11:52,160
if you think you may excuse me

331
00:11:50,399 --> 00:11:53,680
if you think you may be able to

332
00:11:52,160 --> 00:11:56,240
contribute to this research

333
00:11:53,680 --> 00:11:57,760
please don't hesitate to reach out we

334
00:11:56,240 --> 00:11:59,360
welcome collaboration

335
00:11:57,760 --> 00:12:01,920
we want beva to be embraced by the

336
00:11:59,360 --> 00:12:03,839
community so your input is invaluable to

337
00:12:01,920 --> 00:12:11,839
us

338
00:12:03,839 --> 00:12:11,839
thanks for your time

339
00:12:14,639 --> 00:12:16,720
you

