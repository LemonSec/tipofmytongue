1
00:00:08,880 --> 00:00:11,679
hi

2
00:00:09,200 --> 00:00:13,599
everyone i'm melinda fenera i'm a

3
00:00:11,679 --> 00:00:17,600
software engineer in the united station

4
00:00:13,599 --> 00:00:19,840
team at google and i am miguel

5
00:00:17,600 --> 00:00:21,119
and i am a product manager at the

6
00:00:19,840 --> 00:00:23,680
anonymization team

7
00:00:21,119 --> 00:00:24,240
at google and today we'll talk to you

8
00:00:23,680 --> 00:00:25,759
about

9
00:00:24,240 --> 00:00:28,080
the ways in which we are improving

10
00:00:25,760 --> 00:00:31,599
usability of differential privacy

11
00:00:28,080 --> 00:00:32,640
at scale first let me introduce you the

12
00:00:31,599 --> 00:00:34,480
problem

13
00:00:32,640 --> 00:00:36,320
why is there a usability problem in

14
00:00:34,480 --> 00:00:38,480
differential privacy

15
00:00:36,320 --> 00:00:39,360
let's just start with a hypothetical use

16
00:00:38,480 --> 00:00:42,000
case

17
00:00:39,360 --> 00:00:44,239
uh imagine that we have a dataset that

18
00:00:42,000 --> 00:00:46,559
has private movie ratings

19
00:00:44,239 --> 00:00:48,078
that data set is heated by this

20
00:00:46,559 --> 00:00:49,919
pseudonymous id

21
00:00:48,079 --> 00:00:52,320
it has time stamps at a daily

22
00:00:49,920 --> 00:00:52,719
granularity and it has movie ratings

23
00:00:52,320 --> 00:00:56,000
that

24
00:00:52,719 --> 00:00:57,039
go from one to five where five uh is the

25
00:00:56,000 --> 00:00:59,199
top rating

26
00:00:57,039 --> 00:01:01,840
it also has the name of the movies that

27
00:00:59,199 --> 00:01:01,839
were rated

28
00:01:01,920 --> 00:01:06,640
now imagine that we can perform just a

29
00:01:05,040 --> 00:01:08,560
simple aggregation

30
00:01:06,640 --> 00:01:10,000
for instance we just want to count the

31
00:01:08,560 --> 00:01:12,720
number of movies that have

32
00:01:10,000 --> 00:01:14,640
a specific rating on a specific date

33
00:01:12,720 --> 00:01:17,360
using the group by operation

34
00:01:14,640 --> 00:01:18,960
and the count aggregation method this

35
00:01:17,360 --> 00:01:21,439
looks private at first

36
00:01:18,960 --> 00:01:22,000
but if you look closely some counts

37
00:01:21,439 --> 00:01:24,880
might be

38
00:01:22,000 --> 00:01:27,520
one which is which is a single user at

39
00:01:24,880 --> 00:01:29,600
one day you can use this information and

40
00:01:27,520 --> 00:01:31,439
compare it to other databases

41
00:01:29,600 --> 00:01:33,119
such as externally available public

42
00:01:31,439 --> 00:01:35,839
grading datasets

43
00:01:33,119 --> 00:01:37,600
and if there is a user rating for the

44
00:01:35,840 --> 00:01:40,320
same movie on the same date

45
00:01:37,600 --> 00:01:40,960
these can be used to de-identify users

46
00:01:40,320 --> 00:01:43,600
so there

47
00:01:40,960 --> 00:01:46,960
there's a person in question how can we

48
00:01:43,600 --> 00:01:46,960
anonymize this data

49
00:01:47,200 --> 00:01:52,640
well imagine that you have a

50
00:01:50,399 --> 00:01:54,159
sql engine that is able to do

51
00:01:52,640 --> 00:01:55,520
differential privacy

52
00:01:54,159 --> 00:01:57,520
and if you're interested in learning

53
00:01:55,520 --> 00:01:58,158
more about sql engines with differential

54
00:01:57,520 --> 00:01:59,600
privacy

55
00:01:58,159 --> 00:02:01,439
you can check out the paper that's

56
00:01:59,600 --> 00:02:05,119
linked on the pdf

57
00:02:01,439 --> 00:02:09,199
so let's say that we do that

58
00:02:05,119 --> 00:02:10,878
we change the query to look like this

59
00:02:09,199 --> 00:02:12,799
one of the problems that comes up with

60
00:02:10,878 --> 00:02:13,359
differential privacy is that they

61
00:02:12,800 --> 00:02:16,480
require

62
00:02:13,360 --> 00:02:19,520
parameters such as epsilon epsilon delta

63
00:02:16,480 --> 00:02:21,200
and clamping so how can people choose

64
00:02:19,520 --> 00:02:22,239
these values what's the principle way of

65
00:02:21,200 --> 00:02:24,799
choosing them

66
00:02:22,239 --> 00:02:26,800
well this depends on the utility and the

67
00:02:24,800 --> 00:02:31,280
privacy that we want to guarantee

68
00:02:26,800 --> 00:02:31,280
and might be different from case to case

69
00:02:31,360 --> 00:02:34,560
so this is where the usability problem

70
00:02:33,280 --> 00:02:36,720
comes people

71
00:02:34,560 --> 00:02:40,400
just want to anonymize their data sets

72
00:02:36,720 --> 00:02:43,040
and want a simple way of doing it

73
00:02:40,400 --> 00:02:43,840
so that's why we came up with a way of

74
00:02:43,040 --> 00:02:46,959
quantifying

75
00:02:43,840 --> 00:02:47,680
privacy and utility but we will present

76
00:02:46,959 --> 00:02:49,760
to you today

77
00:02:47,680 --> 00:02:52,239
it tries to bridge the gap between that

78
00:02:49,760 --> 00:02:54,079
usability gap of differential privacy

79
00:02:52,239 --> 00:02:55,760
as you're probably aware there are many

80
00:02:54,080 --> 00:02:57,360
papers describing many methods to

81
00:02:55,760 --> 00:03:00,000
perform differential privacy

82
00:02:57,360 --> 00:03:02,239
but the space of making it more usable

83
00:03:00,000 --> 00:03:04,400
has been vastly overlooked

84
00:03:02,239 --> 00:03:06,000
the way that we did it and we'll explain

85
00:03:04,400 --> 00:03:08,720
it to you was by defining

86
00:03:06,000 --> 00:03:09,360
privacy versus utility metrics we also

87
00:03:08,720 --> 00:03:11,120
provided

88
00:03:09,360 --> 00:03:13,200
infrastructure so that people could

89
00:03:11,120 --> 00:03:14,000
safely and efficiently compute them at

90
00:03:13,200 --> 00:03:16,159
scale

91
00:03:14,000 --> 00:03:17,280
think of computing metrics on terabytes

92
00:03:16,159 --> 00:03:20,000
of data

93
00:03:17,280 --> 00:03:21,360
finally we allow for self-service models

94
00:03:20,000 --> 00:03:23,599
so that users can see

95
00:03:21,360 --> 00:03:24,480
in real time the impact of privacy

96
00:03:23,599 --> 00:03:26,640
parameters

97
00:03:24,480 --> 00:03:29,119
on their data and if they want to they

98
00:03:26,640 --> 00:03:32,000
can tune them in real time

99
00:03:29,120 --> 00:03:35,360
now to give you more information i'll

100
00:03:32,000 --> 00:03:35,360
pass it over to melinda

101
00:03:40,080 --> 00:03:46,640
hi everyone so now i will

102
00:03:43,360 --> 00:03:49,360
give you a demo of our system and i'll

103
00:03:46,640 --> 00:03:50,079
also explain how the system addresses

104
00:03:49,360 --> 00:03:52,560
the

105
00:03:50,080 --> 00:04:00,159
usability control concern of

106
00:03:52,560 --> 00:04:03,200
differential priority

107
00:04:00,159 --> 00:04:04,079
so this is how our system looks like uh

108
00:04:03,200 --> 00:04:06,480
first i will

109
00:04:04,080 --> 00:04:07,280
explain to you the different components

110
00:04:06,480 --> 00:04:10,480
in the system

111
00:04:07,280 --> 00:04:13,120
in the ui and then i will explain how it

112
00:04:10,480 --> 00:04:14,640
helps with the usability concerns with

113
00:04:13,120 --> 00:04:16,720
differential privacy

114
00:04:14,640 --> 00:04:18,079
and i will and finally i will explain to

115
00:04:16,720 --> 00:04:20,479
you how

116
00:04:18,079 --> 00:04:22,320
one would use this tool to tune

117
00:04:20,478 --> 00:04:24,159
parameters to randomize with

118
00:04:22,320 --> 00:04:26,080
differential pricing with the example

119
00:04:24,160 --> 00:04:27,759
that miguel mentioned earlier

120
00:04:26,080 --> 00:04:29,840
so in our tool we have different

121
00:04:27,759 --> 00:04:32,880
sections uh for different

122
00:04:29,840 --> 00:04:35,520
uh parameters and and controls

123
00:04:32,880 --> 00:04:38,479
so on the left you can see the typical

124
00:04:35,520 --> 00:04:40,639
parameters one would have to specify

125
00:04:38,479 --> 00:04:42,080
um if it's able to analyze within

126
00:04:40,639 --> 00:04:44,080
differential privacy

127
00:04:42,080 --> 00:04:45,120
so at the top you have analyzation

128
00:04:44,080 --> 00:04:47,520
parameters

129
00:04:45,120 --> 00:04:49,280
epsilon and delta as you know these

130
00:04:47,520 --> 00:04:52,320
parameters control

131
00:04:49,280 --> 00:04:53,758
how anonymized the output is and next

132
00:04:52,320 --> 00:04:56,880
you can select

133
00:04:53,759 --> 00:04:58,479
different infrastructure configurations

134
00:04:56,880 --> 00:05:00,960
so these are the infrastructure like the

135
00:04:58,479 --> 00:05:03,520
general infrastructure we have at google

136
00:05:00,960 --> 00:05:04,799
so phloem is this mapreduce style

137
00:05:03,520 --> 00:05:07,840
infrastructure

138
00:05:04,800 --> 00:05:10,240
sequel is sql based engines

139
00:05:07,840 --> 00:05:11,039
and you can also select custom and then

140
00:05:10,240 --> 00:05:14,479
set uh

141
00:05:11,039 --> 00:05:17,280
specific uh specialized parameters

142
00:05:14,479 --> 00:05:19,840
like noise distribution type laplace or

143
00:05:17,280 --> 00:05:23,440
gaussian distribution etc etc

144
00:05:19,840 --> 00:05:25,198
so for this demo i will stick to sql

145
00:05:23,440 --> 00:05:26,800
so it's compatible with the example

146
00:05:25,199 --> 00:05:29,759
media showed earlier

147
00:05:26,800 --> 00:05:31,759
next section is about data utility

148
00:05:29,759 --> 00:05:34,560
parameters also known as

149
00:05:31,759 --> 00:05:35,680
uh sensitivity parameters so these

150
00:05:34,560 --> 00:05:40,000
parameters control

151
00:05:35,680 --> 00:05:42,720
how much effect any given user can have

152
00:05:40,000 --> 00:05:43,520
in the data right so the more effective

153
00:05:42,720 --> 00:05:46,240
user has

154
00:05:43,520 --> 00:05:46,960
the more noise you have to add to hide

155
00:05:46,240 --> 00:05:50,320
that much

156
00:05:46,960 --> 00:05:52,239
uh change in the data the

157
00:05:50,320 --> 00:05:53,759
the last set of parameters here are

158
00:05:52,240 --> 00:05:55,199
called filters

159
00:05:53,759 --> 00:05:57,600
so these are not differential priority

160
00:05:55,199 --> 00:05:58,560
parameters so they allow you to look at

161
00:05:57,600 --> 00:06:01,360
certain

162
00:05:58,560 --> 00:06:02,160
areas of your data and then see what

163
00:06:01,360 --> 00:06:04,960
happens to

164
00:06:02,160 --> 00:06:06,000
say in values in a particular range so

165
00:06:04,960 --> 00:06:09,599
it you can

166
00:06:06,000 --> 00:06:11,759
dive into like detailed analysis

167
00:06:09,600 --> 00:06:12,800
and then on the right side you can see

168
00:06:11,759 --> 00:06:15,840
at the top

169
00:06:12,800 --> 00:06:17,440
uh some metadata about the a particular

170
00:06:15,840 --> 00:06:19,520
dataset being analyzed

171
00:06:17,440 --> 00:06:20,880
so here we are analyzing this data with

172
00:06:19,520 --> 00:06:23,680
movie ratings

173
00:06:20,880 --> 00:06:24,719
so what we call partition here is uh how

174
00:06:23,680 --> 00:06:27,680
we are grouping

175
00:06:24,720 --> 00:06:28,880
the output by so here it's the date and

176
00:06:27,680 --> 00:06:30,880
the rating

177
00:06:28,880 --> 00:06:33,520
a particular user has given for that

178
00:06:30,880 --> 00:06:36,479
rate for that date

179
00:06:33,520 --> 00:06:38,000
and then the next uh field here is

180
00:06:36,479 --> 00:06:40,159
called the partition value

181
00:06:38,000 --> 00:06:42,560
essentially what type of aggregation we

182
00:06:40,160 --> 00:06:45,759
are doing we are counting users

183
00:06:42,560 --> 00:06:46,720
um and then in the next section you can

184
00:06:45,759 --> 00:06:49,759
see

185
00:06:46,720 --> 00:06:52,240
uh financial statistics right so here

186
00:06:49,759 --> 00:06:54,720
there are different types of statistics

187
00:06:52,240 --> 00:06:56,479
at the top you can see something what we

188
00:06:54,720 --> 00:06:57,520
call the threshold so these are very

189
00:06:56,479 --> 00:06:58,880
important

190
00:06:57,520 --> 00:07:00,639
intermediate parameters and

191
00:06:58,880 --> 00:07:03,680
randomization so the idea

192
00:07:00,639 --> 00:07:05,680
is uh if the if say in this case

193
00:07:03,680 --> 00:07:06,800
uh a particular date and rating

194
00:07:05,680 --> 00:07:09,440
combination

195
00:07:06,800 --> 00:07:11,280
if there aren't enough users if the

196
00:07:09,440 --> 00:07:11,840
number of users in that particular

197
00:07:11,280 --> 00:07:14,159
bucket

198
00:07:11,840 --> 00:07:15,919
is less than that number we won't be

199
00:07:14,160 --> 00:07:17,039
releasing that because it's too

200
00:07:15,919 --> 00:07:19,440
sensitive right

201
00:07:17,039 --> 00:07:20,639
it doesn't allow us to release that and

202
00:07:19,440 --> 00:07:24,560
then claim

203
00:07:20,639 --> 00:07:27,120
uh these uh these privacy guarantees uh

204
00:07:24,560 --> 00:07:28,560
required by epsilon until the chosen uh

205
00:07:27,120 --> 00:07:31,360
epsilon delta

206
00:07:28,560 --> 00:07:31,680
and uh noise standard deviation is uh

207
00:07:31,360 --> 00:07:33,759
it's

208
00:07:31,680 --> 00:07:34,720
quantifies how much noise we are adding

209
00:07:33,759 --> 00:07:37,599
to the

210
00:07:34,720 --> 00:07:39,039
movie counts in this case uh and then

211
00:07:37,599 --> 00:07:42,080
there are a couple of other

212
00:07:39,039 --> 00:07:45,919
parameters here as well so these uh

213
00:07:42,080 --> 00:07:48,318
basically talk about uh how many

214
00:07:45,919 --> 00:07:50,318
partitions you have in the underlying

215
00:07:48,319 --> 00:07:53,440
data so there are about 10 000

216
00:07:50,319 --> 00:07:55,520
combinations of date rating pairs

217
00:07:53,440 --> 00:07:56,879
and uh here you can see how many

218
00:07:55,520 --> 00:07:59,599
partitions are there

219
00:07:56,879 --> 00:08:00,160
in the output right you can see there is

220
00:07:59,599 --> 00:08:03,159
some

221
00:08:00,160 --> 00:08:05,120
loss but it's almost hundred percent

222
00:08:03,160 --> 00:08:08,080
98.9

223
00:08:05,120 --> 00:08:09,039
um and then here uh another important

224
00:08:08,080 --> 00:08:12,400
parameter

225
00:08:09,039 --> 00:08:14,000
so this is again the the intention of

226
00:08:12,400 --> 00:08:15,520
these two parameters too is to give you

227
00:08:14,000 --> 00:08:18,560
like a very high

228
00:08:15,520 --> 00:08:20,159
level idea of accuracy loss right but we

229
00:08:18,560 --> 00:08:21,280
should keep in mind there's so much you

230
00:08:20,160 --> 00:08:23,520
can explain

231
00:08:21,280 --> 00:08:25,679
by just one number right so this

232
00:08:23,520 --> 00:08:28,240
parameter is basically saying um

233
00:08:25,680 --> 00:08:28,720
if you add up all the movie counts

234
00:08:28,240 --> 00:08:31,120
across

235
00:08:28,720 --> 00:08:32,560
all the partitions in the row output

236
00:08:31,120 --> 00:08:35,120
what's that value

237
00:08:32,559 --> 00:08:37,039
and here it's the same thing computed

238
00:08:35,120 --> 00:08:39,599
over anonymized output

239
00:08:37,039 --> 00:08:40,319
as you can see there's a 70 percent

240
00:08:39,599 --> 00:08:43,680
change

241
00:08:40,320 --> 00:08:45,040
right there's a 70 drop so it gives you

242
00:08:43,679 --> 00:08:48,000
some kind of a very high

243
00:08:45,040 --> 00:08:48,800
i very high level idea of accuracy loss

244
00:08:48,000 --> 00:08:52,000
uh again

245
00:08:48,800 --> 00:08:54,800
it's not the only thing to look at and

246
00:08:52,000 --> 00:08:55,440
we also have several plots that dive

247
00:08:54,800 --> 00:08:58,560
into

248
00:08:55,440 --> 00:09:00,000
this uh like the changes introduced by

249
00:08:58,560 --> 00:09:03,279
anonymization

250
00:09:00,000 --> 00:09:06,000
um so this plot uh is a histogram

251
00:09:03,279 --> 00:09:07,040
uh where we show the distribution of

252
00:09:06,000 --> 00:09:10,640
values in the

253
00:09:07,040 --> 00:09:12,000
anonymized output and the row output so

254
00:09:10,640 --> 00:09:15,680
the x axis

255
00:09:12,000 --> 00:09:17,839
um shows a different value ranges like

256
00:09:15,680 --> 00:09:21,359
this case movie count

257
00:09:17,839 --> 00:09:24,800
value ranges and the y-axis

258
00:09:21,360 --> 00:09:27,040
is the number of partitions with values

259
00:09:24,800 --> 00:09:27,839
uh in that range so if i selected this

260
00:09:27,040 --> 00:09:30,640
one

261
00:09:27,839 --> 00:09:31,920
um you can see uh there are the so the

262
00:09:30,640 --> 00:09:34,160
value range is sixty

263
00:09:31,920 --> 00:09:36,719
thousand to sixty-five thousand movie

264
00:09:34,160 --> 00:09:39,839
counts and there are 50

265
00:09:36,720 --> 00:09:40,480
partitions with values in that range in

266
00:09:39,839 --> 00:09:43,200
the robot

267
00:09:40,480 --> 00:09:44,560
row input and in the output there's only

268
00:09:43,200 --> 00:09:47,200
one partition

269
00:09:44,560 --> 00:09:47,760
there's a big change as you can see

270
00:09:47,200 --> 00:09:50,080
that's actually

271
00:09:47,760 --> 00:09:52,240
quite a big change now another thing to

272
00:09:50,080 --> 00:09:53,360
point out here is that this graph is

273
00:09:52,240 --> 00:09:57,519
shown in the

274
00:09:53,360 --> 00:09:59,200
log scale but in reality it's more

275
00:09:57,519 --> 00:10:01,200
like that it's more like long tail

276
00:09:59,200 --> 00:10:02,000
distribution but looking at the log

277
00:10:01,200 --> 00:10:04,480
scale

278
00:10:02,000 --> 00:10:05,680
helps you emphasize the difference it's

279
00:10:04,480 --> 00:10:09,600
good for

280
00:10:05,680 --> 00:10:12,880
like beaten analysis the next plot

281
00:10:09,600 --> 00:10:14,480
is about um how much

282
00:10:12,880 --> 00:10:16,000
change is introduced by the

283
00:10:14,480 --> 00:10:19,120
randomization

284
00:10:16,000 --> 00:10:20,000
pipeline right so here at the in the

285
00:10:19,120 --> 00:10:22,399
previous

286
00:10:20,000 --> 00:10:23,360
uh plot you can see the overall

287
00:10:22,399 --> 00:10:26,640
difference

288
00:10:23,360 --> 00:10:29,839
uh this particular plot division like

289
00:10:26,640 --> 00:10:30,240
tries to explain how that this how this

290
00:10:29,839 --> 00:10:32,720
uh

291
00:10:30,240 --> 00:10:33,600
change is distributed again you say

292
00:10:32,720 --> 00:10:37,200
histogram

293
00:10:33,600 --> 00:10:39,680
x axis is the the relative change right

294
00:10:37,200 --> 00:10:41,600
like buckets of relative changes and the

295
00:10:39,680 --> 00:10:45,680
y-axis is the number of

296
00:10:41,600 --> 00:10:46,640
partitions that experience that amount

297
00:10:45,680 --> 00:10:49,040
of change

298
00:10:46,640 --> 00:10:51,120
as you can see with the given parameters

299
00:10:49,040 --> 00:10:54,000
uh most of the partitions

300
00:10:51,120 --> 00:10:54,480
have changed between 40 and 90 it's

301
00:10:54,000 --> 00:10:57,680
actually

302
00:10:54,480 --> 00:11:01,600
quite bad accuracy wise the last plot

303
00:10:57,680 --> 00:11:03,680
um is about uh the partitions that you

304
00:11:01,600 --> 00:11:05,519
don't get to release at all because of

305
00:11:03,680 --> 00:11:07,199
anonymization at the beginning i

306
00:11:05,519 --> 00:11:08,000
mentioned there is this parameter called

307
00:11:07,200 --> 00:11:10,079
uh

308
00:11:08,000 --> 00:11:11,279
thresholding right so if you don't have

309
00:11:10,079 --> 00:11:13,599
enough users

310
00:11:11,279 --> 00:11:15,120
about this threshold um you don't

311
00:11:13,600 --> 00:11:17,600
release that partition at all

312
00:11:15,120 --> 00:11:18,720
so this this plot again another

313
00:11:17,600 --> 00:11:21,279
histogram

314
00:11:18,720 --> 00:11:22,240
shows you how those partitions are

315
00:11:21,279 --> 00:11:24,560
distributed

316
00:11:22,240 --> 00:11:26,480
in some cases you might want to look at

317
00:11:24,560 --> 00:11:30,640
okay what can't you release

318
00:11:26,480 --> 00:11:33,519
so you can address that in other ways

319
00:11:30,640 --> 00:11:34,880
now how does this help with usability

320
00:11:33,519 --> 00:11:37,200
now if you look at the

321
00:11:34,880 --> 00:11:38,000
left side you can see these parameters

322
00:11:37,200 --> 00:11:42,079
epsilon

323
00:11:38,000 --> 00:11:43,519
delta right laser utility parameters and

324
00:11:42,079 --> 00:11:45,519
when you look at that like what does it

325
00:11:43,519 --> 00:11:45,920
mean does it give you an idea of how

326
00:11:45,519 --> 00:11:49,200
much

327
00:11:45,920 --> 00:11:52,079
data loss you'll have to suffer and

328
00:11:49,200 --> 00:11:52,560
how much noise are we adding like like

329
00:11:52,079 --> 00:11:54,560
like

330
00:11:52,560 --> 00:11:56,479
at which point don't we release things

331
00:11:54,560 --> 00:11:58,800
right privacy parameters

332
00:11:56,480 --> 00:12:00,880
it doesn't give you any of those right

333
00:11:58,800 --> 00:12:04,000
so the goal of this tool is you can

334
00:12:00,880 --> 00:12:06,399
like set these parameters and get

335
00:12:04,000 --> 00:12:07,600
those analyzation statistics in pretty

336
00:12:06,399 --> 00:12:09,760
much real time

337
00:12:07,600 --> 00:12:11,519
it takes seconds to compute this you

338
00:12:09,760 --> 00:12:14,639
don't have to run

339
00:12:11,519 --> 00:12:16,399
lengthy like long pipelines to

340
00:12:14,639 --> 00:12:18,320
compute these things you can click a

341
00:12:16,399 --> 00:12:19,279
button get the values and make the

342
00:12:18,320 --> 00:12:22,399
changes

343
00:12:19,279 --> 00:12:25,200
again see the the change

344
00:12:22,399 --> 00:12:27,440
essentially tune the parameters so now i

345
00:12:25,200 --> 00:12:30,639
will walk you through an example

346
00:12:27,440 --> 00:12:31,120
where i try to get uh the most utility

347
00:12:30,639 --> 00:12:34,000
out

348
00:12:31,120 --> 00:12:34,560
for my use case right for example so

349
00:12:34,000 --> 00:12:36,560
again

350
00:12:34,560 --> 00:12:38,880
in this particular use case i'm

351
00:12:36,560 --> 00:12:42,239
analyzing the movie rating data set

352
00:12:38,880 --> 00:12:43,519
so you have the date rating partitions

353
00:12:42,240 --> 00:12:46,320
and the movie counts

354
00:12:43,519 --> 00:12:48,160
and say i start with these parameters so

355
00:12:46,320 --> 00:12:52,320
when i click compute

356
00:12:48,160 --> 00:12:54,639
i see um in the

357
00:12:52,320 --> 00:12:55,920
output i get to keep almost all the

358
00:12:54,639 --> 00:12:58,800
partitions

359
00:12:55,920 --> 00:13:00,399
but there's uh massive data loss massive

360
00:12:58,800 --> 00:13:02,959
accuracy loss

361
00:13:00,399 --> 00:13:03,519
so what do i do uh so the first thing i

362
00:13:02,959 --> 00:13:06,959
would

363
00:13:03,519 --> 00:13:07,920
do is uh say for my use case i am only

364
00:13:06,959 --> 00:13:11,040
interested in

365
00:13:07,920 --> 00:13:13,279
uh partitions with at least 100

366
00:13:11,040 --> 00:13:14,480
as the movie count the aggregate right

367
00:13:13,279 --> 00:13:17,600
so i can set

368
00:13:14,480 --> 00:13:20,720
that value here i click compute

369
00:13:17,600 --> 00:13:22,720
and you will see um

370
00:13:20,720 --> 00:13:24,240
nothing change i mean uh it's pretty

371
00:13:22,720 --> 00:13:26,480
much the same right i get to keep

372
00:13:24,240 --> 00:13:27,920
more partitions right because i don't

373
00:13:26,480 --> 00:13:30,320
care about these

374
00:13:27,920 --> 00:13:31,599
low count partitions but the accuracy

375
00:13:30,320 --> 00:13:34,399
loss is still bad

376
00:13:31,600 --> 00:13:36,959
and if you look at the two distributions

377
00:13:34,399 --> 00:13:40,160
they are pretty much identical

378
00:13:36,959 --> 00:13:42,479
identical from previous one

379
00:13:40,160 --> 00:13:43,680
now the next step i would do is i would

380
00:13:42,480 --> 00:13:46,720
say

381
00:13:43,680 --> 00:13:48,800
let me increase the sensitivity bound

382
00:13:46,720 --> 00:13:51,040
contribution maximum contribution i

383
00:13:48,800 --> 00:13:52,079
allow for a particular user okay i set

384
00:13:51,040 --> 00:13:55,760
it to 10

385
00:13:52,079 --> 00:13:59,439
again i try that value and you will

386
00:13:55,760 --> 00:14:03,279
see now the accuracy actually went to

387
00:13:59,440 --> 00:14:05,199
70 so 30 percent uh dropped there

388
00:14:03,279 --> 00:14:06,720
uh i still get to keep almost all the

389
00:14:05,199 --> 00:14:08,880
partitions which is great

390
00:14:06,720 --> 00:14:09,839
but because i increased this sensitivity

391
00:14:08,880 --> 00:14:12,560
the noise

392
00:14:09,839 --> 00:14:14,560
standard deviation increased now it went

393
00:14:12,560 --> 00:14:16,800
from two point eight to twenty eight it

394
00:14:14,560 --> 00:14:19,359
multiplied by 10 essentially

395
00:14:16,800 --> 00:14:19,839
uh if you look at the two distributions

396
00:14:19,360 --> 00:14:24,000
now

397
00:14:19,839 --> 00:14:28,880
they look better right so at 60

398
00:14:24,000 --> 00:14:31,199
earlier i got to i was able to keep only

399
00:14:28,880 --> 00:14:32,480
one anonymized partition now i get to

400
00:14:31,199 --> 00:14:35,120
keep four

401
00:14:32,480 --> 00:14:35,920
uh this is again the log scale right but

402
00:14:35,120 --> 00:14:38,079
it's getting

403
00:14:35,920 --> 00:14:39,599
getting there it's not quite as accurate

404
00:14:38,079 --> 00:14:41,199
as i like

405
00:14:39,600 --> 00:14:43,440
um if you look at the change

406
00:14:41,199 --> 00:14:44,000
distribution uh before it was like

407
00:14:43,440 --> 00:14:48,000
between

408
00:14:44,000 --> 00:14:49,519
40 and 90 the change now it's uh i would

409
00:14:48,000 --> 00:14:52,639
say between

410
00:14:49,519 --> 00:14:56,000
5 and 50 so

411
00:14:52,639 --> 00:14:59,360
less change again could be better

412
00:14:56,000 --> 00:15:02,639
so as for the next step i would try 100

413
00:14:59,360 --> 00:15:04,079
for the max contribution limit and if i

414
00:15:02,639 --> 00:15:07,440
click compute

415
00:15:04,079 --> 00:15:09,680
um you will notice the again

416
00:15:07,440 --> 00:15:11,360
i get to keep almost all the partitions

417
00:15:09,680 --> 00:15:13,279
and the partition

418
00:15:11,360 --> 00:15:14,800
value is actually quite accurate as well

419
00:15:13,279 --> 00:15:16,720
right it's like not almost

420
00:15:14,800 --> 00:15:18,000
almost hundred percent and if you look

421
00:15:16,720 --> 00:15:21,440
at the two distributions

422
00:15:18,000 --> 00:15:24,959
they also very nicely overlap right

423
00:15:21,440 --> 00:15:27,279
um which is nice and uh if you look at

424
00:15:24,959 --> 00:15:30,079
the distribution of the change

425
00:15:27,279 --> 00:15:30,720
now almost all the partitions are less

426
00:15:30,079 --> 00:15:34,000
than

427
00:15:30,720 --> 00:15:34,399
um like 10 change majority of i would

428
00:15:34,000 --> 00:15:37,279
say

429
00:15:34,399 --> 00:15:39,519
like around five percent change see like

430
00:15:37,279 --> 00:15:42,079
for my use case i like these numbers

431
00:15:39,519 --> 00:15:43,440
i like the accuracy loss like something

432
00:15:42,079 --> 00:15:47,680
i can tolerate

433
00:15:43,440 --> 00:15:49,279
and uh the the distribution is also

434
00:15:47,680 --> 00:15:50,959
quite similar to the actual data

435
00:15:49,279 --> 00:15:53,279
distribution and

436
00:15:50,959 --> 00:15:55,279
uh i might decide well these are the

437
00:15:53,279 --> 00:15:57,360
parameters i want to use i will just set

438
00:15:55,279 --> 00:15:59,519
these parameters in my pipeline and

439
00:15:57,360 --> 00:16:01,120
run the pipeline once and for all to

440
00:15:59,519 --> 00:16:04,000
anonymize

441
00:16:01,120 --> 00:16:05,839
so this way the benefit to me as a

442
00:16:04,000 --> 00:16:06,480
product team is i don't have to do this

443
00:16:05,839 --> 00:16:09,920
analysis

444
00:16:06,480 --> 00:16:12,079
manually come up with these plots and

445
00:16:09,920 --> 00:16:14,639
matrix manually and i don't have to run

446
00:16:12,079 --> 00:16:17,439
the pipeline many many times

447
00:16:14,639 --> 00:16:18,000
so with this tool i can just experiment

448
00:16:17,440 --> 00:16:20,240
with the

449
00:16:18,000 --> 00:16:23,040
different numbers find the number that

450
00:16:20,240 --> 00:16:24,800
works for my use case and anonymized

451
00:16:23,040 --> 00:16:26,800
once

452
00:16:24,800 --> 00:16:27,920
now one thing i want to notice here is

453
00:16:26,800 --> 00:16:30,479
again uh

454
00:16:27,920 --> 00:16:32,160
the numbers actual the actual utility

455
00:16:30,480 --> 00:16:34,320
parameters you pick

456
00:16:32,160 --> 00:16:35,920
again depends on the use case like megan

457
00:16:34,320 --> 00:16:36,880
said earlier right so in this particular

458
00:16:35,920 --> 00:16:40,479
case

459
00:16:36,880 --> 00:16:42,399
i'm assuming i can work with only values

460
00:16:40,480 --> 00:16:43,600
at least 100 and these are the

461
00:16:42,399 --> 00:16:47,040
parameters that work

462
00:16:43,600 --> 00:16:49,199
for that those requirements okay

463
00:16:47,040 --> 00:16:50,240
and another important thing i want to

464
00:16:49,199 --> 00:16:52,240
point out

465
00:16:50,240 --> 00:16:54,000
now we changed all these parameters to

466
00:16:52,240 --> 00:16:56,320
get to the parameters that we

467
00:16:54,000 --> 00:16:57,600
like the combination of parameters we

468
00:16:56,320 --> 00:16:59,680
like without

469
00:16:57,600 --> 00:17:00,639
touching the epsilon and delta which is

470
00:16:59,680 --> 00:17:03,040
very important

471
00:17:00,639 --> 00:17:05,280
right so we didn't relax the privacy

472
00:17:03,040 --> 00:17:07,520
protections but we still got a lot of

473
00:17:05,280 --> 00:17:10,879
utility out of the data

474
00:17:07,520 --> 00:17:13,918
now with that i will quickly explain

475
00:17:10,880 --> 00:17:18,000
how our system architecture works

476
00:17:13,919 --> 00:17:20,480
um and uh all right let's

477
00:17:18,000 --> 00:17:21,760
okay so this is the overall architecture

478
00:17:20,480 --> 00:17:25,120
of our system

479
00:17:21,760 --> 00:17:26,799
uh so we divide uh how we generate this

480
00:17:25,119 --> 00:17:29,039
analysis into two phases

481
00:17:26,799 --> 00:17:30,000
uh we have a space where we create the

482
00:17:29,039 --> 00:17:32,879
analysis

483
00:17:30,000 --> 00:17:34,640
and we have the face read the analysis

484
00:17:32,880 --> 00:17:37,440
we try to distribute

485
00:17:34,640 --> 00:17:38,960
the work in in these stages in in

486
00:17:37,440 --> 00:17:40,400
various parts because

487
00:17:38,960 --> 00:17:42,640
applying differentiators can be really

488
00:17:40,400 --> 00:17:44,559
costly right so we have this

489
00:17:42,640 --> 00:17:47,120
intermediate data format called

490
00:17:44,559 --> 00:17:48,559
sketches what we call a sketch so the

491
00:17:47,120 --> 00:17:51,439
idea is this is a

492
00:17:48,559 --> 00:17:52,799
intermediate data data format uh that

493
00:17:51,440 --> 00:17:55,360
allows us to

494
00:17:52,799 --> 00:17:57,600
apply differential priority in real time

495
00:17:55,360 --> 00:17:59,760
very efficiently

496
00:17:57,600 --> 00:18:01,280
but it also takes less space than the

497
00:17:59,760 --> 00:18:01,840
underlying source data so that's

498
00:18:01,280 --> 00:18:04,320
something

499
00:18:01,840 --> 00:18:05,039
we create during the create analysis

500
00:18:04,320 --> 00:18:07,280
phase

501
00:18:05,039 --> 00:18:10,000
and when you render the analysis we

502
00:18:07,280 --> 00:18:13,200
primarily rely on these sketches to

503
00:18:10,000 --> 00:18:14,880
compute these uh matrix in pretty much

504
00:18:13,200 --> 00:18:19,600
real time

505
00:18:14,880 --> 00:18:22,960
um all right and uh as a couple of uh

506
00:18:19,600 --> 00:18:23,439
highlights of our system um as you can

507
00:18:22,960 --> 00:18:26,080
see

508
00:18:23,440 --> 00:18:28,640
uh you can actually run this analysis

509
00:18:26,080 --> 00:18:31,120
and get the output within seconds

510
00:18:28,640 --> 00:18:32,320
our median core latency is around 10

511
00:18:31,120 --> 00:18:35,360
seconds

512
00:18:32,320 --> 00:18:38,240
and uh the time it takes to

513
00:18:35,360 --> 00:18:39,360
you know start with the raw dataset uh

514
00:18:38,240 --> 00:18:41,440
create this sketch

515
00:18:39,360 --> 00:18:44,399
and leave the analysis the entire

516
00:18:41,440 --> 00:18:46,480
end-to-end process takes uh

517
00:18:44,400 --> 00:18:48,080
in the order of minutes maybe 15 minutes

518
00:18:46,480 --> 00:18:50,880
in in most cases

519
00:18:48,080 --> 00:18:52,639
and we found out through our internal uh

520
00:18:50,880 --> 00:18:55,360
studies and experiments

521
00:18:52,640 --> 00:18:56,080
uh product teams do find these analysis

522
00:18:55,360 --> 00:18:59,360
quite

523
00:18:56,080 --> 00:19:00,879
intuitive and useful and and they are

524
00:18:59,360 --> 00:19:03,360
able to find the right differential

525
00:19:00,880 --> 00:19:05,679
pricing parameters through this analysis

526
00:19:03,360 --> 00:19:07,360
and which is that's what our goal is try

527
00:19:05,679 --> 00:19:10,799
to make refresh pricing more

528
00:19:07,360 --> 00:19:14,080
useful as for future work

529
00:19:10,799 --> 00:19:16,240
we are planning a couple of directions

530
00:19:14,080 --> 00:19:17,120
so the very first one is to open source

531
00:19:16,240 --> 00:19:20,240
this work

532
00:19:17,120 --> 00:19:21,600
so definitely people within google but

533
00:19:20,240 --> 00:19:23,919
also outside google can

534
00:19:21,600 --> 00:19:25,840
use these analysis and and use

535
00:19:23,919 --> 00:19:28,960
differential privacy more

536
00:19:25,840 --> 00:19:30,720
and and also uh we think once by

537
00:19:28,960 --> 00:19:33,039
oversourcing this we can get

538
00:19:30,720 --> 00:19:34,400
the community to build upon what we have

539
00:19:33,039 --> 00:19:37,039
right make it even better

540
00:19:34,400 --> 00:19:38,320
right so we are considering open

541
00:19:37,039 --> 00:19:41,120
sourcing these uh

542
00:19:38,320 --> 00:19:42,240
tools as part of our open source

543
00:19:41,120 --> 00:19:44,159
offering

544
00:19:42,240 --> 00:19:45,280
uh the second thing we're exploring is

545
00:19:44,160 --> 00:19:47,760
uh introducing

546
00:19:45,280 --> 00:19:48,480
local differential privacy into this uh

547
00:19:47,760 --> 00:19:50,000
tool

548
00:19:48,480 --> 00:19:52,080
uh so local differential price is a

549
00:19:50,000 --> 00:19:53,840
model where we apply differential price

550
00:19:52,080 --> 00:19:56,000
at the point of data collection

551
00:19:53,840 --> 00:19:56,959
as opposed to you collect raw data first

552
00:19:56,000 --> 00:19:59,440
and then apply

553
00:19:56,960 --> 00:20:01,039
differential priority on the server side

554
00:19:59,440 --> 00:20:03,679
um and the third direction we are

555
00:20:01,039 --> 00:20:05,280
exploring is to introduce more functions

556
00:20:03,679 --> 00:20:08,720
into the tool right now our tools

557
00:20:05,280 --> 00:20:10,480
support uh count and some operations

558
00:20:08,720 --> 00:20:12,240
uh but there are other functions we

559
00:20:10,480 --> 00:20:14,559
should support

560
00:20:12,240 --> 00:20:15,280
all right with that uh i would like to

561
00:20:14,559 --> 00:20:18,879
thank you

562
00:20:15,280 --> 00:20:24,399
on behalf of miguel and i and google

563
00:20:18,880 --> 00:20:24,400
for attending this talk thank you so

564
00:20:31,799 --> 00:20:34,799
much

