1
00:00:09,200 --> 00:00:13,360
welcome to the

2
00:00:10,320 --> 00:00:13,920
talk about wikipedia and the lean data

3
00:00:13,360 --> 00:00:16,800
diet

4
00:00:13,920 --> 00:00:18,800
and before we get started to clarify or

5
00:00:16,800 --> 00:00:21,199
work for the wikimedia foundation which

6
00:00:18,800 --> 00:00:22,400
is the non-profit behind wikipedia's

7
00:00:21,199 --> 00:00:24,480
infrastructure

8
00:00:22,400 --> 00:00:25,439
and i put here on the bottom right

9
00:00:24,480 --> 00:00:27,359
corner

10
00:00:25,439 --> 00:00:29,198
couple ways in which you can contact me

11
00:00:27,359 --> 00:00:30,640
or you can contact the people

12
00:00:29,199 --> 00:00:33,040
at the wikimedia foundation that work

13
00:00:30,640 --> 00:00:34,640
with analytics

14
00:00:33,040 --> 00:00:36,320
and when i say the infrastructure for

15
00:00:34,640 --> 00:00:38,239
wikipedia this means that the wikimedia

16
00:00:36,320 --> 00:00:40,399
foundation maintains the servers

17
00:00:38,239 --> 00:00:41,279
it administers the funds that you donate

18
00:00:40,399 --> 00:00:43,520
to wikipedia

19
00:00:41,280 --> 00:00:44,559
and pays engineers such as myself that

20
00:00:43,520 --> 00:00:46,399
work there

21
00:00:44,559 --> 00:00:49,680
but the wikimedia foundation has nothing

22
00:00:46,399 --> 00:00:51,920
to do with the content of wikipedia

23
00:00:49,680 --> 00:00:54,239
and what we're going to talk about is

24
00:00:51,920 --> 00:00:58,399
about lean data which is a concept

25
00:00:54,239 --> 00:00:59,680
that has gotten name as of recent

26
00:00:58,399 --> 00:01:01,359
but it's a practice that we've been

27
00:00:59,680 --> 00:01:03,120
doing at the wikipedia foundation for a

28
00:01:01,359 --> 00:01:04,960
while and it's this idea that you should

29
00:01:03,120 --> 00:01:06,720
think very purposefully

30
00:01:04,959 --> 00:01:09,520
about the data that you're gathering

31
00:01:06,720 --> 00:01:11,600
from your users how you are retaining it

32
00:01:09,520 --> 00:01:13,840
and aggregating it and whether you

33
00:01:11,600 --> 00:01:15,280
really need it to provide the value

34
00:01:13,840 --> 00:01:17,360
that you think you're providing for your

35
00:01:15,280 --> 00:01:18,640
users

36
00:01:17,360 --> 00:01:20,320
and the other thing i was giving a talk

37
00:01:18,640 --> 00:01:21,520
about wikipedia is that everybody knows

38
00:01:20,320 --> 00:01:23,839
what it is

39
00:01:21,520 --> 00:01:24,960
probably everyone in the audience uses

40
00:01:23,840 --> 00:01:26,960
it

41
00:01:24,960 --> 00:01:28,640
but something that matters for this talk

42
00:01:26,960 --> 00:01:30,720
that i don't think people are aware of

43
00:01:28,640 --> 00:01:32,400
is that wikipedia exists within

44
00:01:30,720 --> 00:01:34,079
this larger thing that is the free

45
00:01:32,400 --> 00:01:36,880
knowledge movement

46
00:01:34,079 --> 00:01:37,919
and of course editors when they come to

47
00:01:36,880 --> 00:01:39,839
edit wikipedia

48
00:01:37,920 --> 00:01:41,200
they embrace the ideas of the free

49
00:01:39,840 --> 00:01:44,399
knowledge movement and they put

50
00:01:41,200 --> 00:01:46,240
knowledge there for everyone to consume

51
00:01:44,399 --> 00:01:47,920
but also when you're consuming wikipedia

52
00:01:46,240 --> 00:01:48,479
you're participating as part of this

53
00:01:47,920 --> 00:01:52,079
movement

54
00:01:48,479 --> 00:01:52,640
as a consumer right and why does this

55
00:01:52,079 --> 00:01:54,960
matter

56
00:01:52,640 --> 00:01:56,159
for this talk because the principles

57
00:01:54,960 --> 00:01:58,719
around privacy

58
00:01:56,159 --> 00:01:59,600
and data handling that we try to follow

59
00:01:58,719 --> 00:02:02,079
stem

60
00:01:59,600 --> 00:02:03,679
from the free knowledge movement and the

61
00:02:02,079 --> 00:02:06,399
ideas are pretty intuitive

62
00:02:03,680 --> 00:02:08,239
it's that you cannot really think of

63
00:02:06,399 --> 00:02:10,000
free knowledge without a guarantee of

64
00:02:08,239 --> 00:02:11,039
privacy you shouldn't have to provide

65
00:02:10,000 --> 00:02:12,640
any information

66
00:02:11,038 --> 00:02:14,799
to participate in the free knowledge

67
00:02:12,640 --> 00:02:16,559
movement there's no terms of service to

68
00:02:14,800 --> 00:02:19,040
access wikipedia

69
00:02:16,560 --> 00:02:19,680
and it's very hard for editors to

70
00:02:19,040 --> 00:02:22,799
provide

71
00:02:19,680 --> 00:02:24,160
knowledge without a guarantee of privacy

72
00:02:22,800 --> 00:02:27,680
and anonymity

73
00:02:24,160 --> 00:02:28,640
but it's equally hard for consumers

74
00:02:27,680 --> 00:02:30,239
right because

75
00:02:28,640 --> 00:02:32,238
not in all countries you can read

76
00:02:30,239 --> 00:02:33,680
wikipedia freely so we should strive to

77
00:02:32,239 --> 00:02:35,519
provide a guarantee

78
00:02:33,680 --> 00:02:37,840
so everybody can have access to free

79
00:02:35,519 --> 00:02:39,920
knowledge

80
00:02:37,840 --> 00:02:42,000
and how is this guarantee of privacy

81
00:02:39,920 --> 00:02:44,958
expressed within the ecosystem or within

82
00:02:42,000 --> 00:02:47,360
the fact that wikipedia is a website

83
00:02:44,959 --> 00:02:48,239
the answer to this question is not very

84
00:02:47,360 --> 00:02:51,440
exciting

85
00:02:48,239 --> 00:02:53,280
and is through the privacy policy but

86
00:02:51,440 --> 00:02:54,000
what is different about this privacy

87
00:02:53,280 --> 00:02:56,480
policy

88
00:02:54,000 --> 00:02:58,879
from other privacy policies that you may

89
00:02:56,480 --> 00:03:02,159
have signed when we were all getting

90
00:02:58,879 --> 00:03:03,280
tons of emails about jdpr is that the

91
00:03:02,159 --> 00:03:06,480
privacy policy

92
00:03:03,280 --> 00:03:08,480
for wikipedia was built the wiki way

93
00:03:06,480 --> 00:03:10,959
the same way that content is built so it

94
00:03:08,480 --> 00:03:13,200
was built with a larger community

95
00:03:10,959 --> 00:03:16,000
that cares about content and cares about

96
00:03:13,200 --> 00:03:19,119
the free knowledge movement

97
00:03:16,000 --> 00:03:21,360
and the discussions to come up with the

98
00:03:19,120 --> 00:03:24,480
text of the privacy policy

99
00:03:21,360 --> 00:03:26,319
were this long 150 000 words and

100
00:03:24,480 --> 00:03:27,840
for everyone to get a picture here this

101
00:03:26,319 --> 00:03:30,238
is thick

102
00:03:27,840 --> 00:03:32,239
uh some volume for the lord of the rings

103
00:03:30,239 --> 00:03:34,400
right so there was a lot of discussion

104
00:03:32,239 --> 00:03:36,400
that went into creating this policy that

105
00:03:34,400 --> 00:03:39,040
exemplifies the principles around

106
00:03:36,400 --> 00:03:40,720
privacy and the movement

107
00:03:39,040 --> 00:03:42,560
so what are the things that privacy

108
00:03:40,720 --> 00:03:45,359
policy talks about

109
00:03:42,560 --> 00:03:46,879
you should be able like we said before

110
00:03:45,360 --> 00:03:49,680
you should be able to read wikipedia

111
00:03:46,879 --> 00:03:52,079
without providing any information

112
00:03:49,680 --> 00:03:54,159
the wikimedia foundation as the entity

113
00:03:52,080 --> 00:03:55,680
that administers the data

114
00:03:54,159 --> 00:03:57,200
it's not going to sell your information

115
00:03:55,680 --> 00:03:58,799
to third parties and it's not going to

116
00:03:57,200 --> 00:04:01,200
share it with third parties and when it

117
00:03:58,799 --> 00:04:04,159
comes to data aggregation

118
00:04:01,200 --> 00:04:06,640
after 90 days most of the granular

119
00:04:04,159 --> 00:04:09,120
records are either deleted or aggregated

120
00:04:06,640 --> 00:04:09,920
or de-identified and it's larger this

121
00:04:09,120 --> 00:04:14,560
last point is

122
00:04:09,920 --> 00:04:17,199
probably the hardest one to explain

123
00:04:14,560 --> 00:04:18,160
so the privacy policy like these

124
00:04:17,199 --> 00:04:20,239
principles

125
00:04:18,160 --> 00:04:22,160
have like a strong implications of how

126
00:04:20,238 --> 00:04:25,280
do we do engineering right it's not just

127
00:04:22,160 --> 00:04:27,120
a matter of like a philosophical

128
00:04:25,280 --> 00:04:29,198
scene but there's a strong implications

129
00:04:27,120 --> 00:04:31,680
and perhaps the biggest one

130
00:04:29,199 --> 00:04:33,840
when we think about never selling and

131
00:04:31,680 --> 00:04:36,479
sharing your info with third parties

132
00:04:33,840 --> 00:04:37,520
the implication here is that wikipedia

133
00:04:36,479 --> 00:04:39,599
runs on premise

134
00:04:37,520 --> 00:04:41,680
right so when we're talking about data

135
00:04:39,600 --> 00:04:44,320
for wikipedia this is not data on

136
00:04:41,680 --> 00:04:46,560
any cloud but rather it's data on our

137
00:04:44,320 --> 00:04:47,840
data centers which this is a picture of

138
00:04:46,560 --> 00:04:50,560
that our dc ops

139
00:04:47,840 --> 00:04:52,799
engineers manage and they could have a

140
00:04:50,560 --> 00:04:54,639
github depot that is public

141
00:04:52,800 --> 00:04:57,840
where you can see how all the software

142
00:04:54,639 --> 00:04:57,840
is deployed

143
00:04:58,320 --> 00:05:02,320
but we're going to talk about here more

144
00:05:00,080 --> 00:05:04,159
rather than the whole ecosystem of

145
00:05:02,320 --> 00:05:05,360
deployment which is affected by these

146
00:05:04,160 --> 00:05:07,600
privacy practices

147
00:05:05,360 --> 00:05:11,120
it's about the data itself what happens

148
00:05:07,600 --> 00:05:12,800
with it right we try to compute metrics

149
00:05:11,120 --> 00:05:14,880
in a privacy conscious manner

150
00:05:12,800 --> 00:05:17,280
we release a lot of data we're releasing

151
00:05:14,880 --> 00:05:19,440
publically data every hour that is used

152
00:05:17,280 --> 00:05:21,919
all over the world and we actually have

153
00:05:19,440 --> 00:05:24,240
to delete a lot of data

154
00:05:21,919 --> 00:05:25,599
so we i'm going to talk about the data

155
00:05:24,240 --> 00:05:28,800
deletion

156
00:05:25,600 --> 00:05:30,560
what we call sanitizing data and the

157
00:05:28,800 --> 00:05:32,320
most important

158
00:05:30,560 --> 00:05:34,639
of all which is building a privacy

159
00:05:32,320 --> 00:05:36,639
culture and this is the hardest to do by

160
00:05:34,639 --> 00:05:40,479
far

161
00:05:36,639 --> 00:05:42,800
so deleting data is something that

162
00:05:40,479 --> 00:05:43,758
seems easy until you have to do it at

163
00:05:42,800 --> 00:05:46,080
the scale

164
00:05:43,759 --> 00:05:47,360
and there was one of the presenters at

165
00:05:46,080 --> 00:05:48,800
this conference

166
00:05:47,360 --> 00:05:50,560
i don't know if it was last year or the

167
00:05:48,800 --> 00:05:53,039
year before wrote a paper

168
00:05:50,560 --> 00:05:55,840
about how hard to delete data in large

169
00:05:53,039 --> 00:05:57,680
systems because for starters

170
00:05:55,840 --> 00:05:59,440
your data is probably going to be in two

171
00:05:57,680 --> 00:06:01,039
systems it's in hadoop but it's also in

172
00:05:59,440 --> 00:06:02,319
cassandra it's in cassandra but it's

173
00:06:01,039 --> 00:06:03,840
also on druid

174
00:06:02,319 --> 00:06:05,280
so when you need to delete data you need

175
00:06:03,840 --> 00:06:07,119
to think about this idea that you're

176
00:06:05,280 --> 00:06:11,198
deleting it from the primary source but

177
00:06:07,120 --> 00:06:14,160
also from a bunch of secondary sources

178
00:06:11,199 --> 00:06:14,720
and the data we're talking about here is

179
00:06:14,160 --> 00:06:16,319
this

180
00:06:14,720 --> 00:06:17,840
i'm going to move my video a little bit

181
00:06:16,319 --> 00:06:21,680
so you can see what what this

182
00:06:17,840 --> 00:06:24,080
is usage data called web requests

183
00:06:21,680 --> 00:06:26,080
which is what you get as part of an http

184
00:06:24,080 --> 00:06:28,719
payload right the project you're looking

185
00:06:26,080 --> 00:06:29,680
a spanish wikipedia an ip address a user

186
00:06:28,720 --> 00:06:32,639
agent

187
00:06:29,680 --> 00:06:33,280
and a page that you're looking at but

188
00:06:32,639 --> 00:06:36,639
also

189
00:06:33,280 --> 00:06:36,638
we're talking here about

190
00:06:37,360 --> 00:06:43,120
behavioral data and behavioral data is

191
00:06:40,720 --> 00:06:44,400
like you click on a button or you click

192
00:06:43,120 --> 00:06:46,560
on a menu

193
00:06:44,400 --> 00:06:48,479
and those two types of data are

194
00:06:46,560 --> 00:06:50,639
subjected to data deletion and

195
00:06:48,479 --> 00:06:52,318
aggregation and sanitization but we're

196
00:06:50,639 --> 00:06:55,520
talking here about deletion

197
00:06:52,319 --> 00:06:59,280
so how big are our data sets

198
00:06:55,520 --> 00:07:01,919
so at pic wikipedia gets about 200

199
00:06:59,280 --> 00:07:03,679
000 requests per second these are

200
00:07:01,919 --> 00:07:06,000
requests not page views

201
00:07:03,680 --> 00:07:08,400
which is a lot you can see here in the

202
00:07:06,000 --> 00:07:11,440
graph our peaks of traffic

203
00:07:08,400 --> 00:07:14,239
where with the i would say

204
00:07:11,440 --> 00:07:16,479
the beginning of the pandemic as as it

205
00:07:14,240 --> 00:07:18,000
expressed across europe and the united

206
00:07:16,479 --> 00:07:20,000
states at the beginning of march and you

207
00:07:18,000 --> 00:07:21,199
can see how we have very large peaks of

208
00:07:20,000 --> 00:07:25,039
traffic here

209
00:07:21,199 --> 00:07:26,080
on the beginning of may for behavioral

210
00:07:25,039 --> 00:07:28,560
data like

211
00:07:26,080 --> 00:07:30,240
click-throughs and usage of features the

212
00:07:28,560 --> 00:07:32,319
web volume is a lot smaller

213
00:07:30,240 --> 00:07:35,199
a thousand times smaller and about 2 000

214
00:07:32,319 --> 00:07:35,199
events per second

215
00:07:35,599 --> 00:07:39,039
so the first thing that we want to think

216
00:07:37,360 --> 00:07:40,240
about when we're talking about data

217
00:07:39,039 --> 00:07:42,318
division

218
00:07:40,240 --> 00:07:44,080
is that you have to be very safe because

219
00:07:42,319 --> 00:07:46,400
mistakes in data deletion

220
00:07:44,080 --> 00:07:48,318
are hard to have made sometimes

221
00:07:46,400 --> 00:07:50,638
impossible to admit

222
00:07:48,319 --> 00:07:52,319
so i want to share like a quick tip here

223
00:07:50,639 --> 00:07:54,720
for

224
00:07:52,319 --> 00:07:55,759
that we have that has come to help us a

225
00:07:54,720 --> 00:07:58,400
lot and i

226
00:07:55,759 --> 00:07:58,879
i try to exemplify the stocks they do

227
00:07:58,400 --> 00:08:01,840
not

228
00:07:58,879 --> 00:08:02,400
with like um the red and the dues with

229
00:08:01,840 --> 00:08:04,719
the green

230
00:08:02,400 --> 00:08:06,080
right like important for when you're

231
00:08:04,720 --> 00:08:08,080
talking about deletion

232
00:08:06,080 --> 00:08:09,199
that any default arguments of your

233
00:08:08,080 --> 00:08:11,039
scripts don't do

234
00:08:09,199 --> 00:08:12,479
anything that you will regret so if you

235
00:08:11,039 --> 00:08:15,520
have a default argument

236
00:08:12,479 --> 00:08:16,479
that is tables to delete if the argument

237
00:08:15,520 --> 00:08:18,000
is not present

238
00:08:16,479 --> 00:08:20,560
the default should never be deleted on

239
00:08:18,000 --> 00:08:24,800
tables but rather delete no tables

240
00:08:20,560 --> 00:08:26,800
right so a solution that we have

241
00:08:24,800 --> 00:08:28,639
in order to make as little mistakes as

242
00:08:26,800 --> 00:08:30,319
possible when scheduling chrome so

243
00:08:28,639 --> 00:08:33,120
scheduling things on puppets for data

244
00:08:30,319 --> 00:08:35,279
deletions clone system the timers

245
00:08:33,120 --> 00:08:36,880
we have a script that has a set of

246
00:08:35,279 --> 00:08:37,679
arguments that you will have here on the

247
00:08:36,880 --> 00:08:40,320
command line

248
00:08:37,679 --> 00:08:42,000
like database event tables menu click

249
00:08:40,320 --> 00:08:45,360
wikis blah blah blah

250
00:08:42,000 --> 00:08:48,640
delete data that is older than 90 days

251
00:08:45,360 --> 00:08:50,720
and when you execute this this

252
00:08:48,640 --> 00:08:51,680
script you first have to secure it on

253
00:08:50,720 --> 00:08:54,160
driver mode

254
00:08:51,680 --> 00:08:56,160
right and the driver mode is going to

255
00:08:54,160 --> 00:08:58,319
give you a checksum

256
00:08:56,160 --> 00:09:00,160
that is a checksum for your parameters

257
00:08:58,320 --> 00:09:01,839
so whenever you schedule it and you put

258
00:09:00,160 --> 00:09:03,279
it on your templates that puppet is

259
00:09:01,839 --> 00:09:05,279
later going to execute

260
00:09:03,279 --> 00:09:08,880
you need to pass that checksum so if you

261
00:09:05,279 --> 00:09:11,680
make a mistake in one of your parameters

262
00:09:08,880 --> 00:09:13,760
and instead of saying older than 90 days

263
00:09:11,680 --> 00:09:17,120
you say older than nine days

264
00:09:13,760 --> 00:09:19,519
hopefully you don't end up deleting

265
00:09:17,120 --> 00:09:20,800
like a lot of data that you even intend

266
00:09:19,519 --> 00:09:22,160
to delete in this case what it will

267
00:09:20,800 --> 00:09:22,880
happen is that the script will not

268
00:09:22,160 --> 00:09:24,880
execute

269
00:09:22,880 --> 00:09:26,399
because the parameters don't match the

270
00:09:24,880 --> 00:09:28,720
checksum

271
00:09:26,399 --> 00:09:30,720
and this is like a very low tech

272
00:09:28,720 --> 00:09:32,880
solution but i find like solutions of

273
00:09:30,720 --> 00:09:36,080
this nature that are very simple

274
00:09:32,880 --> 00:09:39,120
work well forever so i i quite

275
00:09:36,080 --> 00:09:40,640
liked this idea that i then came up with

276
00:09:39,120 --> 00:09:42,240
it somebody from my team came up with

277
00:09:40,640 --> 00:09:44,880
that

278
00:09:42,240 --> 00:09:45,600
but of course we don't delete all data

279
00:09:44,880 --> 00:09:48,880
we also

280
00:09:45,600 --> 00:09:51,600
sanitize a bunch of the data and what we

281
00:09:48,880 --> 00:09:54,000
call sanitization

282
00:09:51,600 --> 00:09:56,000
is a technique in which we try to remove

283
00:09:54,000 --> 00:09:56,800
the most identifying pieces and

284
00:09:56,000 --> 00:09:58,399
hopefully

285
00:09:56,800 --> 00:10:00,160
the data that proceeds a very

286
00:09:58,399 --> 00:10:01,519
non-identifying data set

287
00:10:00,160 --> 00:10:04,240
but of course the notion of

288
00:10:01,519 --> 00:10:06,560
identification carries a notion of risk

289
00:10:04,240 --> 00:10:07,360
it's never like a hundred percent safe

290
00:10:06,560 --> 00:10:10,640
procedure

291
00:10:07,360 --> 00:10:13,760
as the leading data would be

292
00:10:10,640 --> 00:10:15,839
and for that i wanted to give a super

293
00:10:13,760 --> 00:10:16,480
fast overview of what the data pipelines

294
00:10:15,839 --> 00:10:18,560
look which are

295
00:10:16,480 --> 00:10:20,399
is very standard for behavioral data you

296
00:10:18,560 --> 00:10:24,800
have the clients could be a mobile phone

297
00:10:20,399 --> 00:10:27,279
or your desktop and the data comes into

298
00:10:24,800 --> 00:10:27,920
a beacon that is located in varnish

299
00:10:27,279 --> 00:10:29,360
because

300
00:10:27,920 --> 00:10:30,719
everything in wikipedia goes through

301
00:10:29,360 --> 00:10:33,920
bandwidth through the caching layer

302
00:10:30,720 --> 00:10:35,920
because most our requests are serv cache

303
00:10:33,920 --> 00:10:37,120
from bernice you move into kafka that

304
00:10:35,920 --> 00:10:40,240
request dispatcher

305
00:10:37,120 --> 00:10:42,959
and after two hdfs

306
00:10:40,240 --> 00:10:44,320
and what we decided to do here in order

307
00:10:42,959 --> 00:10:45,839
to sanitize data was

308
00:10:44,320 --> 00:10:48,079
not sanitized data that's called

309
00:10:45,839 --> 00:10:50,240
ingesting but rather ingest data

310
00:10:48,079 --> 00:10:51,359
into a data store that every 90 days

311
00:10:50,240 --> 00:10:53,360
gets purged

312
00:10:51,360 --> 00:10:55,920
every day is getting perch actually and

313
00:10:53,360 --> 00:10:59,600
it's deleting data that is 90 days

314
00:10:55,920 --> 00:11:02,000
older and at the same time

315
00:10:59,600 --> 00:11:03,200
the data stream is moved through an

316
00:11:02,000 --> 00:11:06,800
allow list

317
00:11:03,200 --> 00:11:08,480
here that and this allow list tells you

318
00:11:06,800 --> 00:11:09,760
what is going to be persistent for

319
00:11:08,480 --> 00:11:12,320
longer than 90 days

320
00:11:09,760 --> 00:11:13,200
and all these data and the allow list

321
00:11:12,320 --> 00:11:16,560
are public

322
00:11:13,200 --> 00:11:16,560
and you can see them in github

323
00:11:17,360 --> 00:11:23,040
so why do we use an allow list

324
00:11:20,640 --> 00:11:24,240
if the data looks like this ip user

325
00:11:23,040 --> 00:11:26,000
agent the wiki

326
00:11:24,240 --> 00:11:27,600
and the action that was taken like

327
00:11:26,000 --> 00:11:30,480
clicking

328
00:11:27,600 --> 00:11:31,200
if you have a do not allow list what

329
00:11:30,480 --> 00:11:33,519
happens

330
00:11:31,200 --> 00:11:36,480
is that and let me put the video again a

331
00:11:33,519 --> 00:11:39,839
little bit higher here

332
00:11:36,480 --> 00:11:39,839
perhaps i will move it lower

333
00:11:41,120 --> 00:11:48,800
so with the do not allow less the ip

334
00:11:45,680 --> 00:11:51,359
has been sanitized to a null value and

335
00:11:48,800 --> 00:11:54,000
so is the user agent right

336
00:11:51,360 --> 00:11:56,000
but what happens when you get an extra

337
00:11:54,000 --> 00:11:57,920
fill with that do not allow list

338
00:11:56,000 --> 00:12:00,079
you end up having the identifier because

339
00:11:57,920 --> 00:12:02,880
you didn't explicitly remove it

340
00:12:00,079 --> 00:12:04,319
whereas if you have an allow list you

341
00:12:02,880 --> 00:12:07,040
nullify the fields that you were

342
00:12:04,320 --> 00:12:10,959
interested on the ip and the user agent

343
00:12:07,040 --> 00:12:13,839
and for the cookie will nullify it right

344
00:12:10,959 --> 00:12:15,518
because it's not on your allow list

345
00:12:13,839 --> 00:12:18,000
another technique that we use to

346
00:12:15,519 --> 00:12:19,600
identify data is bucketizing it right so

347
00:12:18,000 --> 00:12:22,000
rather than nullifying the id

348
00:12:19,600 --> 00:12:24,160
i'm just very i keep like a very

349
00:12:22,000 --> 00:12:25,920
granular piece of data about it this ips

350
00:12:24,160 --> 00:12:28,240
in spain

351
00:12:25,920 --> 00:12:28,959
and rather than nullifying the user

352
00:12:28,240 --> 00:12:32,000
legend

353
00:12:28,959 --> 00:12:34,160
big packet this is a linux user agent

354
00:12:32,000 --> 00:12:36,000
and rather than nullifying the cookie i

355
00:12:34,160 --> 00:12:38,319
may hash it with a salt

356
00:12:36,000 --> 00:12:39,920
that is changed for example daily so you

357
00:12:38,320 --> 00:12:41,920
will actually be able to link together

358
00:12:39,920 --> 00:12:43,519
surprise for one day

359
00:12:41,920 --> 00:12:45,360
and of course this has a potential for

360
00:12:43,519 --> 00:12:47,120
identification but you will not be able

361
00:12:45,360 --> 00:12:49,760
to link this cookie with the cookie for

362
00:12:47,120 --> 00:12:49,760
the next day

363
00:12:50,839 --> 00:12:55,120
right

364
00:12:52,079 --> 00:12:57,680
um important just as important as

365
00:12:55,120 --> 00:13:00,000
technical mechanisms to delete data is

366
00:12:57,680 --> 00:13:01,839
to build a privacy culture

367
00:13:00,000 --> 00:13:04,639
and i think the idea here is not very

368
00:13:01,839 --> 00:13:06,639
different from performance like i work

369
00:13:04,639 --> 00:13:08,320
on a performance team years ago and many

370
00:13:06,639 --> 00:13:09,200
times i felt like i was the performance

371
00:13:08,320 --> 00:13:11,040
janitor

372
00:13:09,200 --> 00:13:12,720
because you were left with like a bunch

373
00:13:11,040 --> 00:13:14,480
of problems that you had to fix right

374
00:13:12,720 --> 00:13:16,399
ideally performance would be a culture

375
00:13:14,480 --> 00:13:17,440
that we built in from the beginning and

376
00:13:16,399 --> 00:13:18,959
privacy is the same

377
00:13:17,440 --> 00:13:22,880
it shouldn't be the responsibility of

378
00:13:18,959 --> 00:13:25,760
one team but rather of the organization

379
00:13:22,880 --> 00:13:27,839
and i want to provide an example here of

380
00:13:25,760 --> 00:13:30,639
metrics that just take into account

381
00:13:27,839 --> 00:13:33,200
privacy from the start

382
00:13:30,639 --> 00:13:34,959
and the one i wanted to talk about and

383
00:13:33,200 --> 00:13:36,480
let me move the video again i will move

384
00:13:34,959 --> 00:13:39,439
it on there

385
00:13:36,480 --> 00:13:40,720
up here up here again it's about how you

386
00:13:39,440 --> 00:13:42,639
compute the

387
00:13:40,720 --> 00:13:44,240
what is like a bay weather standard

388
00:13:42,639 --> 00:13:46,639
metric daily

389
00:13:44,240 --> 00:13:48,320
active users or monthly after user

390
00:13:46,639 --> 00:13:50,240
active users

391
00:13:48,320 --> 00:13:51,440
because we're talking about wikipedia

392
00:13:50,240 --> 00:13:54,399
and you don't need to be

393
00:13:51,440 --> 00:13:54,959
logged in to use it these are not users

394
00:13:54,399 --> 00:13:57,760
but they are

395
00:13:54,959 --> 00:14:00,079
devices right as understood as browsers

396
00:13:57,760 --> 00:14:03,120
really

397
00:14:00,079 --> 00:14:05,199
so anywhere when you computed this

398
00:14:03,120 --> 00:14:07,519
metric before what you use is a token

399
00:14:05,199 --> 00:14:08,639
a unique identifier that identifies your

400
00:14:07,519 --> 00:14:11,920
device

401
00:14:08,639 --> 00:14:14,000
and what you do is i you do a request

402
00:14:11,920 --> 00:14:16,240
and tag the identifier along and if the

403
00:14:14,000 --> 00:14:18,079
identifier leaves for 30 days you just

404
00:14:16,240 --> 00:14:19,920
need to count the distinct

405
00:14:18,079 --> 00:14:22,560
identifiers that you have for that time

406
00:14:19,920 --> 00:14:26,079
period and you know how many

407
00:14:22,560 --> 00:14:31,839
unique devices did you have right

408
00:14:26,079 --> 00:14:34,079
the problem with this approach is that

409
00:14:31,839 --> 00:14:35,279
something we want to guard against it is

410
00:14:34,079 --> 00:14:37,199
precisely that

411
00:14:35,279 --> 00:14:39,600
idea that you can build a browsing

412
00:14:37,199 --> 00:14:41,439
session that tells you every article

413
00:14:39,600 --> 00:14:44,639
that a device was looking at

414
00:14:41,440 --> 00:14:47,360
for 30 days right like if we have like

415
00:14:44,639 --> 00:14:48,880
an external entity like a government

416
00:14:47,360 --> 00:14:51,120
that asks us for data

417
00:14:48,880 --> 00:14:52,639
to surrender their records for a

418
00:14:51,120 --> 00:14:54,880
particular device

419
00:14:52,639 --> 00:14:56,160
or for everyone that has look at a

420
00:14:54,880 --> 00:14:57,920
particular page

421
00:14:56,160 --> 00:15:00,719
we don't want to have that data we don't

422
00:14:57,920 --> 00:15:02,800
want to be able to link it together

423
00:15:00,720 --> 00:15:05,680
so using unique identifiers will make

424
00:15:02,800 --> 00:15:07,199
that very easy in fact

425
00:15:05,680 --> 00:15:09,040
so quick keymap would like a different

426
00:15:07,199 --> 00:15:10,240
technique to do the same thing that is

427
00:15:09,040 --> 00:15:12,000
equally precise

428
00:15:10,240 --> 00:15:13,760
and i put a link down there where this

429
00:15:12,000 --> 00:15:16,639
is explained on more detail

430
00:15:13,760 --> 00:15:18,399
and we call it the last access so if you

431
00:15:16,639 --> 00:15:20,639
go to wikipedia

432
00:15:18,399 --> 00:15:22,320
right now you will see that a cookie is

433
00:15:20,639 --> 00:15:23,519
set which is the last time that you

434
00:15:22,320 --> 00:15:26,800
access wikipedia

435
00:15:23,519 --> 00:15:28,959
so say this person here last time they

436
00:15:26,800 --> 00:15:32,240
went to wikipedia was the first of

437
00:15:28,959 --> 00:15:33,758
september so they have a cookie

438
00:15:32,240 --> 00:15:35,440
in their device that is going to last

439
00:15:33,759 --> 00:15:37,920
for 30 days that is

440
00:15:35,440 --> 00:15:39,680
it says first of september and today

441
00:15:37,920 --> 00:15:42,479
comes around

442
00:15:39,680 --> 00:15:44,160
and today is the 15th of october and

443
00:15:42,480 --> 00:15:46,240
this person goes to wikipedia again

444
00:15:44,160 --> 00:15:48,880
because they want to look up something

445
00:15:46,240 --> 00:15:51,120
so their request is gonna include the

446
00:15:48,880 --> 00:15:54,240
value of the cookie which is the first

447
00:15:51,120 --> 00:15:56,079
of september so i store the last success

448
00:15:54,240 --> 00:15:58,240
cookie together with every quest so

449
00:15:56,079 --> 00:16:00,479
when you look at the logs things are

450
00:15:58,240 --> 00:16:03,040
gonna look similar to what you see here

451
00:16:00,480 --> 00:16:04,560
the date of today is the 15th of october

452
00:16:03,040 --> 00:16:07,360
for some ip

453
00:16:04,560 --> 00:16:09,199
somebody was looking at the page titanic

454
00:16:07,360 --> 00:16:11,839
and the value of the last access cookie

455
00:16:09,199 --> 00:16:16,479
was the first of september

456
00:16:11,839 --> 00:16:18,800
because of the way http and the web work

457
00:16:16,480 --> 00:16:20,560
when the response comes back i'm going

458
00:16:18,800 --> 00:16:21,519
to update that cookie and now it's been

459
00:16:20,560 --> 00:16:24,880
updated to the

460
00:16:21,519 --> 00:16:26,560
15th of october

461
00:16:24,880 --> 00:16:28,399
this is what the user has on their

462
00:16:26,560 --> 00:16:29,680
computer so when they do a subsequent

463
00:16:28,399 --> 00:16:31,519
request today

464
00:16:29,680 --> 00:16:32,959
they send me the new cookie right they

465
00:16:31,519 --> 00:16:35,120
send to the storage

466
00:16:32,959 --> 00:16:36,719
then you could be so if we look at our

467
00:16:35,120 --> 00:16:40,079
logs they would look like this

468
00:16:36,720 --> 00:16:40,560
for the first access the cookie had the

469
00:16:40,079 --> 00:16:43,439
value

470
00:16:40,560 --> 00:16:44,079
of the ninth of september the second

471
00:16:43,440 --> 00:16:47,519
time

472
00:16:44,079 --> 00:16:49,839
is the 15th of october the day of today

473
00:16:47,519 --> 00:16:51,600
so how with this data i can calculate

474
00:16:49,839 --> 00:16:54,639
the unique devices

475
00:16:51,600 --> 00:16:58,240
so what i need to do is to see

476
00:16:54,639 --> 00:17:00,560
all the records that have an access date

477
00:16:58,240 --> 00:17:02,079
that is prior to the date of today or

478
00:17:00,560 --> 00:17:04,240
the access date is known

479
00:17:02,079 --> 00:17:05,678
right like i don't need both records

480
00:17:04,240 --> 00:17:08,319
with the first one

481
00:17:05,679 --> 00:17:09,520
i can note that there was like a unique

482
00:17:08,319 --> 00:17:11,199
access

483
00:17:09,520 --> 00:17:13,439
this at this time right there was a

484
00:17:11,199 --> 00:17:15,199
device that that was their first hit

485
00:17:13,439 --> 00:17:19,280
today the subsequent requests

486
00:17:15,199 --> 00:17:21,039
are of no importance and this method

487
00:17:19,280 --> 00:17:22,879
while less intuitive it's equally

488
00:17:21,039 --> 00:17:23,599
precise that it would be like a token

489
00:17:22,880 --> 00:17:26,640
method

490
00:17:23,599 --> 00:17:28,879
right like it works the same

491
00:17:26,640 --> 00:17:30,080
but it has the advantage that it doesn't

492
00:17:28,880 --> 00:17:32,000
give you a piece of additional

493
00:17:30,080 --> 00:17:34,480
information to join these records in

494
00:17:32,000 --> 00:17:36,080
this case this customer is accessing or

495
00:17:34,480 --> 00:17:37,360
this reader is accessing through the

496
00:17:36,080 --> 00:17:38,960
same ip so sure

497
00:17:37,360 --> 00:17:40,479
i could join these two records but you

498
00:17:38,960 --> 00:17:42,559
could see how it could be a mobile phone

499
00:17:40,480 --> 00:17:44,480
and you have changed wifi networks

500
00:17:42,559 --> 00:17:46,000
so then these those records would be

501
00:17:44,480 --> 00:17:48,799
unlinkable right like

502
00:17:46,000 --> 00:17:50,240
the cookie doesn't help me to link a

503
00:17:48,799 --> 00:17:52,240
browser session

504
00:17:50,240 --> 00:17:54,720
but it's a piece of information that

505
00:17:52,240 --> 00:17:57,440
just helps me to do the calculation

506
00:17:54,720 --> 00:17:57,440
i want to do

507
00:17:58,720 --> 00:18:05,120
so to wrap up for the lynda diet

508
00:18:01,760 --> 00:18:08,000
there is some cons and there's some pros

509
00:18:05,120 --> 00:18:09,678
and for the cons clearly it's more work

510
00:18:08,000 --> 00:18:12,799
i mean computing

511
00:18:09,679 --> 00:18:15,280
unique devices the way i just explained

512
00:18:12,799 --> 00:18:17,120
is more complicated than com computing

513
00:18:15,280 --> 00:18:19,120
unique devices with tokens

514
00:18:17,120 --> 00:18:20,719
let's be clear that it's no less precise

515
00:18:19,120 --> 00:18:22,799
but it could be that

516
00:18:20,720 --> 00:18:24,640
for some metrics you have to work with

517
00:18:22,799 --> 00:18:25,679
proxies that are less precise than the

518
00:18:24,640 --> 00:18:28,559
metrics

519
00:18:25,679 --> 00:18:30,320
themselves so that could also happen and

520
00:18:28,559 --> 00:18:32,000
building this privacy culture takes a

521
00:18:30,320 --> 00:18:35,280
lot of time you know in the foundation

522
00:18:32,000 --> 00:18:37,200
curve committed to privacy but

523
00:18:35,280 --> 00:18:38,720
building this awareness takes a lot of

524
00:18:37,200 --> 00:18:40,400
time you're going to hire people from

525
00:18:38,720 --> 00:18:42,160
other organizations and they have a

526
00:18:40,400 --> 00:18:44,000
theoretical commitment but when it comes

527
00:18:42,160 --> 00:18:45,360
to the reality of the practice they may

528
00:18:44,000 --> 00:18:47,919
not be so familiar with

529
00:18:45,360 --> 00:18:49,439
what is what they need to do and the

530
00:18:47,919 --> 00:18:51,600
data analysis certainly

531
00:18:49,440 --> 00:18:53,120
needs a different mindset because in

532
00:18:51,600 --> 00:18:56,719
instances you're gonna have to

533
00:18:53,120 --> 00:18:59,918
look for workarounds now

534
00:18:56,720 --> 00:19:01,120
the pros are significant when it comes

535
00:18:59,919 --> 00:19:04,880
to data requests

536
00:19:01,120 --> 00:19:06,559
there's a lot less work and

537
00:19:04,880 --> 00:19:08,559
it's much easier once you have

538
00:19:06,559 --> 00:19:10,879
aggregated and deleted your data

539
00:19:08,559 --> 00:19:12,559
make data public right because the data

540
00:19:10,880 --> 00:19:15,200
that remains

541
00:19:12,559 --> 00:19:16,559
is much more shareable than it would be

542
00:19:15,200 --> 00:19:19,600
otherwise

543
00:19:16,559 --> 00:19:21,600
and also you can truly offer a guarantee

544
00:19:19,600 --> 00:19:23,199
of privacy right and this is important

545
00:19:21,600 --> 00:19:25,760
because at the end

546
00:19:23,200 --> 00:19:26,320
for wikipedia privacy is a hidden

547
00:19:25,760 --> 00:19:28,320
feature

548
00:19:26,320 --> 00:19:30,799
it's something that we offer that you

549
00:19:28,320 --> 00:19:32,720
don't really see but it's part

550
00:19:30,799 --> 00:19:34,559
it's as much part of the wiki of

551
00:19:32,720 --> 00:19:37,600
wikipedia as the content

552
00:19:34,559 --> 00:19:41,039
itself right that's like an important

553
00:19:37,600 --> 00:19:44,000
idea and i think this is my last slide

554
00:19:41,039 --> 00:19:44,000
yes so

555
00:19:44,160 --> 00:19:49,039
opening for questions now thank you

556
00:19:50,840 --> 00:19:53,840
everybody

557
00:19:57,679 --> 00:19:59,760
you

