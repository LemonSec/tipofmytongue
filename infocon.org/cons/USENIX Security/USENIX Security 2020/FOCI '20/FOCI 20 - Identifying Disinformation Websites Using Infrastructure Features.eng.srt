1
00:00:08,400 --> 00:00:11,200
hi

2
00:00:09,040 --> 00:00:12,559
my name is austin hansel and i'm a phd

3
00:00:11,200 --> 00:00:14,479
student in the computer science

4
00:00:12,559 --> 00:00:15,759
department at princeton university

5
00:00:14,480 --> 00:00:17,279
and today i'm going to be talking about

6
00:00:15,759 --> 00:00:19,199
some work we've done on exploring the

7
00:00:17,279 --> 00:00:20,800
use of infrastructure features to detect

8
00:00:19,199 --> 00:00:22,480
disinformation websites

9
00:00:20,800 --> 00:00:24,320
this work was done in collaboration with

10
00:00:22,480 --> 00:00:26,320
jordan holland ben kaiser

11
00:00:24,320 --> 00:00:27,519
kevin burgholte and jonathan meyer from

12
00:00:26,320 --> 00:00:29,119
princeton university

13
00:00:27,519 --> 00:00:31,839
and nick themester from the university

14
00:00:29,119 --> 00:00:34,239
of chicago

15
00:00:31,840 --> 00:00:36,160
so automated detection is needed to

16
00:00:34,239 --> 00:00:37,760
fight this information at scale

17
00:00:36,160 --> 00:00:39,680
the problem is that fact checkers can't

18
00:00:37,760 --> 00:00:40,239
keep up with disinformation websites on

19
00:00:39,680 --> 00:00:41,920
their own

20
00:00:40,239 --> 00:00:44,000
there's simply too many posts being made

21
00:00:41,920 --> 00:00:46,960
to social media to manually label each

22
00:00:44,000 --> 00:00:48,719
post however automated methods in

23
00:00:46,960 --> 00:00:50,559
previous work that focus on article

24
00:00:48,719 --> 00:00:52,399
content are difficult to scale

25
00:00:50,559 --> 00:00:54,000
since new unverified claims are

26
00:00:52,399 --> 00:00:55,039
constantly being released about current

27
00:00:54,000 --> 00:00:56,960
events

28
00:00:55,039 --> 00:00:58,640
similarly features that focus on the

29
00:00:56,960 --> 00:01:01,600
style that an article is written in may

30
00:00:58,640 --> 00:01:03,840
not generalized beyond a single data set

31
00:01:01,600 --> 00:01:05,600
lastly our automated methods that focus

32
00:01:03,840 --> 00:01:08,320
on social graph features are

33
00:01:05,600 --> 00:01:10,080
reactive in nature and not proactive

34
00:01:08,320 --> 00:01:11,679
ideally we would like to be able to stop

35
00:01:10,080 --> 00:01:13,920
this information before it spreads on

36
00:01:11,680 --> 00:01:16,240
social media so if we rely on features

37
00:01:13,920 --> 00:01:18,400
related to how a particular post or

38
00:01:16,240 --> 00:01:21,199
article is spreading the damage may

39
00:01:18,400 --> 00:01:21,200
already be done

40
00:01:21,600 --> 00:01:24,960
so our key insight in being able to stop

41
00:01:23,680 --> 00:01:26,799
this information early

42
00:01:24,960 --> 00:01:28,720
and at scale is that disinformation

43
00:01:26,799 --> 00:01:31,200
websites have similar characteristics to

44
00:01:28,720 --> 00:01:33,520
spam and phishing websites

45
00:01:31,200 --> 00:01:34,799
in work on spam and phishing researchers

46
00:01:33,520 --> 00:01:36,798
have been able to

47
00:01:34,799 --> 00:01:38,000
successfully engineer network level

48
00:01:36,799 --> 00:01:40,880
features to identify

49
00:01:38,000 --> 00:01:43,040
such websites our key insight is that

50
00:01:40,880 --> 00:01:44,479
destination websites also share such

51
00:01:43,040 --> 00:01:46,799
network level characteristics

52
00:01:44,479 --> 00:01:48,399
such as a low cost and quick setup time

53
00:01:46,799 --> 00:01:50,320
a short lifespan

54
00:01:48,399 --> 00:01:51,680
and being hosted on a distinct set of

55
00:01:50,320 --> 00:01:53,439
networks

56
00:01:51,680 --> 00:01:55,280
thus we distinguish ourselves from prior

57
00:01:53,439 --> 00:01:57,039
work on automatically identifying

58
00:01:55,280 --> 00:01:57,759
dissemination websites by focusing on

59
00:01:57,040 --> 00:02:00,000
what we call

60
00:01:57,759 --> 00:02:01,600
infrastructure features which relate to

61
00:02:00,000 --> 00:02:03,280
how a website is constructed

62
00:02:01,600 --> 00:02:06,479
rather than its content or how it's

63
00:02:03,280 --> 00:02:06,479
shared on social media

64
00:02:06,880 --> 00:02:10,478
so this is a quick overview of all of

65
00:02:08,878 --> 00:02:11,280
our infrastructure features that we

66
00:02:10,479 --> 00:02:12,879
engineered

67
00:02:11,280 --> 00:02:14,879
i'm not going to go into each feature

68
00:02:12,879 --> 00:02:16,399
right now but this table is available in

69
00:02:14,879 --> 00:02:18,239
the full paper

70
00:02:16,400 --> 00:02:19,599
i do want to point out that generally we

71
00:02:18,239 --> 00:02:20,480
divide our features into three

72
00:02:19,599 --> 00:02:22,799
categories

73
00:02:20,480 --> 00:02:24,079
domain features certificate features and

74
00:02:22,800 --> 00:02:25,599
hosting features

75
00:02:24,080 --> 00:02:29,040
i'm not going to explain what each of

76
00:02:25,599 --> 00:02:29,040
these categories of features mean

77
00:02:29,599 --> 00:02:33,440
so first we define domain features as

78
00:02:31,840 --> 00:02:36,160
features that are available to

79
00:02:33,440 --> 00:02:37,680
domain registrars at the time of domain

80
00:02:36,160 --> 00:02:39,359
name registration

81
00:02:37,680 --> 00:02:41,200
these features can be extracted from

82
00:02:39,360 --> 00:02:42,319
domain names themselves and whois

83
00:02:41,200 --> 00:02:44,079
records which provide

84
00:02:42,319 --> 00:02:45,440
information about the registrants of

85
00:02:44,080 --> 00:02:46,959
these names

86
00:02:45,440 --> 00:02:49,120
several key features include the

87
00:02:46,959 --> 00:02:50,480
presence of new z keywords in the domain

88
00:02:49,120 --> 00:02:53,360
name such as gazette

89
00:02:50,480 --> 00:02:54,799
or herald the choice of a registrar and

90
00:02:53,360 --> 00:02:56,080
how long ago the domain name was

91
00:02:54,800 --> 00:02:58,000
registered

92
00:02:56,080 --> 00:03:00,239
for example many disinformation websites

93
00:02:58,000 --> 00:03:02,000
we find use low cost registrars to

94
00:03:00,239 --> 00:03:04,400
quickly set up a domain name

95
00:03:02,000 --> 00:03:06,159
similarly they have shorter life spans

96
00:03:04,400 --> 00:03:09,360
and are more recently registered than

97
00:03:06,159 --> 00:03:09,359
traditional news outlets

98
00:03:09,920 --> 00:03:13,119
we also define certificate features as

99
00:03:12,000 --> 00:03:14,879
features that are available to

100
00:03:13,120 --> 00:03:16,480
certificate authorities at the time of

101
00:03:14,879 --> 00:03:18,399
certificate issuance

102
00:03:16,480 --> 00:03:20,079
these features can be extracted from tls

103
00:03:18,400 --> 00:03:21,599
certificates themselves

104
00:03:20,080 --> 00:03:23,680
several key features include the number

105
00:03:21,599 --> 00:03:24,480
of domain names in the subject alternate

106
00:03:23,680 --> 00:03:27,120
name field

107
00:03:24,480 --> 00:03:29,679
and whether the certificate has actually

108
00:03:27,120 --> 00:03:29,680
expired

109
00:03:30,879 --> 00:03:34,798
we lastly define hosting features as

110
00:03:33,280 --> 00:03:36,560
features that are available to hosting

111
00:03:34,799 --> 00:03:37,840
providers at the time that a website is

112
00:03:36,560 --> 00:03:39,599
first deployed

113
00:03:37,840 --> 00:03:41,599
these features can be extracted from the

114
00:03:39,599 --> 00:03:43,440
html of web pages

115
00:03:41,599 --> 00:03:45,359
or the ip address of the server that

116
00:03:43,440 --> 00:03:47,359
hosts the web page itself

117
00:03:45,360 --> 00:03:49,840
several of the key features include the

118
00:03:47,360 --> 00:03:51,599
presence of certain wordpress plugins

119
00:03:49,840 --> 00:03:53,280
and the autonomous system number that a

120
00:03:51,599 --> 00:03:55,200
website is hosted on

121
00:03:53,280 --> 00:03:56,400
for example we find that disinformation

122
00:03:55,200 --> 00:03:58,480
websites typically use

123
00:03:56,400 --> 00:04:00,239
low-cost hosting providers whereas

124
00:03:58,480 --> 00:04:02,319
traditional news outlets were more

125
00:04:00,239 --> 00:04:03,040
likely to use enterprise grade hosting

126
00:04:02,319 --> 00:04:06,319
providers

127
00:04:03,040 --> 00:04:06,319
such as encapsula

128
00:04:07,360 --> 00:04:10,879
so in order to evaluate our

129
00:04:09,360 --> 00:04:12,400
infrastructure features and their

130
00:04:10,879 --> 00:04:13,599
effectiveness in detecting this

131
00:04:12,400 --> 00:04:16,560
information

132
00:04:13,599 --> 00:04:18,039
we created a training data set of 551

133
00:04:16,560 --> 00:04:22,160
disinformation websites

134
00:04:18,040 --> 00:04:25,520
553 news websites and 555

135
00:04:22,160 --> 00:04:27,120
non-news websites we find that

136
00:04:25,520 --> 00:04:29,198
disinformation websites were sourced

137
00:04:27,120 --> 00:04:31,600
from fact checkers academics

138
00:04:29,199 --> 00:04:33,600
and news outlets which we list these

139
00:04:31,600 --> 00:04:35,400
sources in the full paper

140
00:04:33,600 --> 00:04:38,560
we originally had a data set of about

141
00:04:35,400 --> 00:04:40,239
768 disinformation websites but we found

142
00:04:38,560 --> 00:04:42,639
that many of them were actually inactive

143
00:04:40,240 --> 00:04:44,479
and no longer serving content

144
00:04:42,639 --> 00:04:46,240
fortunately we were able to reconstruct

145
00:04:44,479 --> 00:04:46,880
the features from many of these inactive

146
00:04:46,240 --> 00:04:49,600
websites

147
00:04:46,880 --> 00:04:51,919
which is how we resulted in 551

148
00:04:49,600 --> 00:04:53,919
disinformation websites in total

149
00:04:51,919 --> 00:04:55,840
we were able to get these features using

150
00:04:53,919 --> 00:04:56,320
historical data from sources like the

151
00:04:55,840 --> 00:04:58,719
internet

152
00:04:56,320 --> 00:04:58,719
archive

153
00:05:00,000 --> 00:05:04,000
so to perform an initial evaluation of

154
00:05:02,320 --> 00:05:05,680
the effectiveness of infrastructure

155
00:05:04,000 --> 00:05:08,160
features we performed five-fold

156
00:05:05,680 --> 00:05:11,120
cross-validation on our training data

157
00:05:08,160 --> 00:05:12,960
we first trained a random force model on

158
00:05:11,120 --> 00:05:14,720
our infrastructure features because we

159
00:05:12,960 --> 00:05:15,919
expected that feature interpretability

160
00:05:14,720 --> 00:05:17,759
would be important

161
00:05:15,919 --> 00:05:19,758
for human moderators that might want to

162
00:05:17,759 --> 00:05:21,919
use our model

163
00:05:19,759 --> 00:05:24,560
furthermore it enabled us to rank our

164
00:05:21,919 --> 00:05:26,080
features as you saw on the earlier slide

165
00:05:24,560 --> 00:05:28,160
with the table that listed all of our

166
00:05:26,080 --> 00:05:29,680
features we had a column where we listed

167
00:05:28,160 --> 00:05:31,440
the rank of each feature

168
00:05:29,680 --> 00:05:34,800
amongst each other how important they

169
00:05:31,440 --> 00:05:37,039
were in making classifications

170
00:05:34,800 --> 00:05:38,720
we go in more in detail about our

171
00:05:37,039 --> 00:05:41,759
hyperparameter selection

172
00:05:38,720 --> 00:05:43,440
thus which parameters we selected how we

173
00:05:41,759 --> 00:05:46,800
arrived at the values for those hyper

174
00:05:43,440 --> 00:05:46,800
parameters in the full paper

175
00:05:47,919 --> 00:05:52,799
so the figure on the left shows the mean

176
00:05:50,720 --> 00:05:54,639
receiver operating characteristic curve

177
00:05:52,800 --> 00:05:56,639
when we perform five-fold

178
00:05:54,639 --> 00:05:58,080
cross-validation with our classifier

179
00:05:56,639 --> 00:06:01,280
and the right figure shows precision

180
00:05:58,080 --> 00:06:02,800
recall curves for cross-validation

181
00:06:01,280 --> 00:06:04,479
in terms of cross-validation we find

182
00:06:02,800 --> 00:06:05,520
that disinformation websites are

183
00:06:04,479 --> 00:06:08,719
actually detectable

184
00:06:05,520 --> 00:06:10,719
using infrastructure features we do see

185
00:06:08,720 --> 00:06:12,160
on the figure in the left that this the

186
00:06:10,720 --> 00:06:14,400
disinformation class

187
00:06:12,160 --> 00:06:15,759
performed worse in detection than the

188
00:06:14,400 --> 00:06:18,799
news class or the

189
00:06:15,759 --> 00:06:19,600
other or rather non-news class as we

190
00:06:18,800 --> 00:06:21,199
refer to it

191
00:06:19,600 --> 00:06:22,639
but we still did pretty well in terms of

192
00:06:21,199 --> 00:06:25,039
our training data and being able to

193
00:06:22,639 --> 00:06:26,960
identify disinformation websites

194
00:06:25,039 --> 00:06:30,240
we also see a similar pattern in the

195
00:06:26,960 --> 00:06:30,239
precision recall curve

196
00:06:30,880 --> 00:06:34,800
we also find that domain features do

197
00:06:32,960 --> 00:06:36,638
pretty well on their own

198
00:06:34,800 --> 00:06:38,720
this is promising because the main

199
00:06:36,639 --> 00:06:40,479
features are available very early

200
00:06:38,720 --> 00:06:41,840
in a website's life cycle and they're

201
00:06:40,479 --> 00:06:44,000
fairly easy to obtain

202
00:06:41,840 --> 00:06:44,960
for a given website you can just look at

203
00:06:44,000 --> 00:06:46,960
a domain name

204
00:06:44,960 --> 00:06:48,880
or look up a whois record to obtain the

205
00:06:46,960 --> 00:06:50,318
information you need to extract domain

206
00:06:48,880 --> 00:06:52,240
features

207
00:06:50,319 --> 00:06:53,840
we do see that certificate features

208
00:06:52,240 --> 00:06:55,919
performed pretty poorly

209
00:06:53,840 --> 00:06:57,758
on their own and hosting features seem

210
00:06:55,919 --> 00:06:59,599
to do fairly okay

211
00:06:57,759 --> 00:07:03,520
but of course the main features clearly

212
00:06:59,599 --> 00:07:05,440
did the best

213
00:07:03,520 --> 00:07:07,359
so we decided to test our model on

214
00:07:05,440 --> 00:07:08,800
real-time data to evaluate how it would

215
00:07:07,360 --> 00:07:10,400
perform in the real world

216
00:07:08,800 --> 00:07:12,720
when there are new websites being

217
00:07:10,400 --> 00:07:14,560
evaluated that we haven't seen before

218
00:07:12,720 --> 00:07:16,960
so we built a system that makes

219
00:07:14,560 --> 00:07:18,960
classifications on a live twitter feed

220
00:07:16,960 --> 00:07:21,919
we used the twitter streaming api and

221
00:07:18,960 --> 00:07:24,318
sampled tweets using the news keyword

222
00:07:21,919 --> 00:07:25,039
our system ran over five days across two

223
00:07:24,319 --> 00:07:26,880
servers

224
00:07:25,039 --> 00:07:28,880
the first server ingested live data and

225
00:07:26,880 --> 00:07:31,680
extracted features the second server

226
00:07:28,880 --> 00:07:34,240
made classifications in real time

227
00:07:31,680 --> 00:07:36,160
after five days we randomly sampled 100

228
00:07:34,240 --> 00:07:40,560
predictions made for each class

229
00:07:36,160 --> 00:07:40,560
and manually labeled the correct classes

230
00:07:41,199 --> 00:07:45,120
so this figure shows a confusion matrix

231
00:07:43,360 --> 00:07:46,080
for our real-time performance on a

232
00:07:45,120 --> 00:07:49,039
random sample

233
00:07:46,080 --> 00:07:49,840
of the twitter predictions we make we

234
00:07:49,039 --> 00:07:51,599
consciously know

235
00:07:49,840 --> 00:07:53,440
that our model's performance radically

236
00:07:51,599 --> 00:07:54,878
degraded in performance compared to

237
00:07:53,440 --> 00:07:56,800
cross-validation

238
00:07:54,879 --> 00:07:58,479
as you can see out of the 100

239
00:07:56,800 --> 00:07:59,120
predictions made for disinformation

240
00:07:58,479 --> 00:08:01,359
websites

241
00:07:59,120 --> 00:08:02,879
only about five actually were true

242
00:08:01,360 --> 00:08:04,560
predictions

243
00:08:02,879 --> 00:08:06,800
we were able to do significantly better

244
00:08:04,560 --> 00:08:08,400
on news websites and non-news websites

245
00:08:06,800 --> 00:08:10,639
although performance could definitely be

246
00:08:08,400 --> 00:08:12,159
improved

247
00:08:10,639 --> 00:08:14,879
so what does this all mean why would the

248
00:08:12,160 --> 00:08:18,160
performance have so radically degraded

249
00:08:14,879 --> 00:08:18,160
well we have a couple of theories

250
00:08:18,240 --> 00:08:22,240
one is is that there might be a massive

251
00:08:20,160 --> 00:08:22,720
class imbalance in the real-time data

252
00:08:22,240 --> 00:08:25,039
between

253
00:08:22,720 --> 00:08:26,479
the disinformation class news websites

254
00:08:25,039 --> 00:08:28,080
and other websites

255
00:08:26,479 --> 00:08:30,318
so as i described earlier in our

256
00:08:28,080 --> 00:08:31,280
training data we nearly equally balance

257
00:08:30,319 --> 00:08:32,959
the three classes

258
00:08:31,280 --> 00:08:34,718
but in the real world it might be the

259
00:08:32,958 --> 00:08:36,958
case there are far more

260
00:08:34,719 --> 00:08:38,240
news websites and non-news websites

261
00:08:36,958 --> 00:08:40,640
being posted to twitter than

262
00:08:38,240 --> 00:08:42,640
disinformation websites

263
00:08:40,640 --> 00:08:44,080
secondly some of the data sets we used

264
00:08:42,640 --> 00:08:45,120
for our disinformation class were

265
00:08:44,080 --> 00:08:46,880
several years old

266
00:08:45,120 --> 00:08:49,120
which were compiled again by fact

267
00:08:46,880 --> 00:08:51,279
checkers and news organizations

268
00:08:49,120 --> 00:08:52,720
if the infrastructure features for new

269
00:08:51,279 --> 00:08:54,000
disinformation websites look

270
00:08:52,720 --> 00:08:55,680
significantly different than

271
00:08:54,000 --> 00:08:57,839
disinformation websites from several

272
00:08:55,680 --> 00:08:59,760
years ago then a classifier might do

273
00:08:57,839 --> 00:09:01,440
okay in cross-validation but not on

274
00:08:59,760 --> 00:09:04,000
real-time data where the features have

275
00:09:01,440 --> 00:09:05,760
evolved over time

276
00:09:04,000 --> 00:09:07,600
third it may be the case that there are

277
00:09:05,760 --> 00:09:08,160
artifacts in how our training data was

278
00:09:07,600 --> 00:09:09,920
curated

279
00:09:08,160 --> 00:09:11,439
which negatively impacts the performance

280
00:09:09,920 --> 00:09:13,040
on real-time data

281
00:09:11,440 --> 00:09:14,560
for example about 34 of the

282
00:09:13,040 --> 00:09:15,760
disinformation websites on our training

283
00:09:14,560 --> 00:09:18,000
data are active

284
00:09:15,760 --> 00:09:20,480
whereas all the news websites are active

285
00:09:18,000 --> 00:09:22,160
so there's a huge difference in terms of

286
00:09:20,480 --> 00:09:24,240
how many times we had to reconstruct

287
00:09:22,160 --> 00:09:26,160
features for disinformation websites

288
00:09:24,240 --> 00:09:28,720
that are no longer active and news

289
00:09:26,160 --> 00:09:28,719
websites

290
00:09:29,519 --> 00:09:32,640
so in conclusion we find that

291
00:09:30,959 --> 00:09:34,719
disinformation websites seem to have

292
00:09:32,640 --> 00:09:36,560
distinct infrastructure features

293
00:09:34,720 --> 00:09:39,680
compared to news websites and non-news

294
00:09:36,560 --> 00:09:40,880
websites which may aid in the detection

295
00:09:39,680 --> 00:09:42,880
our model did pretty well in

296
00:09:40,880 --> 00:09:43,680
cross-validation but radically degraded

297
00:09:42,880 --> 00:09:46,320
in performance

298
00:09:43,680 --> 00:09:47,599
in real time nonetheless we argue that

299
00:09:46,320 --> 00:09:49,360
infrastructure features have the

300
00:09:47,600 --> 00:09:51,519
potential to improve the automatic

301
00:09:49,360 --> 00:09:53,920
detection of disinformation

302
00:09:51,519 --> 00:09:56,160
future work should explore how real-time

303
00:09:53,920 --> 00:09:58,479
data differentiates between common data

304
00:09:56,160 --> 00:10:00,000
use and research and it should also

305
00:09:58,480 --> 00:10:01,360
explore the scale to which this

306
00:10:00,000 --> 00:10:03,839
information is posted

307
00:10:01,360 --> 00:10:05,839
on social media so that we can more

308
00:10:03,839 --> 00:10:08,079
accurately determine what our balance in

309
00:10:05,839 --> 00:10:09,760
the training data should be between

310
00:10:08,079 --> 00:10:11,519
how many disinformation websites we

311
00:10:09,760 --> 00:10:12,079
include and how many news websites we

312
00:10:11,519 --> 00:10:15,519
include

313
00:10:12,079 --> 00:10:15,519
for non-used websites

314
00:10:15,920 --> 00:10:19,519
so i want to thank you for listening to

315
00:10:17,440 --> 00:10:20,079
this talk this we thank our paper

316
00:10:19,519 --> 00:10:22,160
shepard

317
00:10:20,079 --> 00:10:23,359
jay crandall and our anonymous reviewers

318
00:10:22,160 --> 00:10:25,439
for their feedback

319
00:10:23,360 --> 00:10:27,760
you know this work was funded in part by

320
00:10:25,440 --> 00:10:29,920
a national science foundation award

321
00:10:27,760 --> 00:10:32,600
and any questions or comments you can

322
00:10:29,920 --> 00:10:34,800
reach me at a hansel ahounsel

323
00:10:32,600 --> 00:10:46,800
cs.princeton.edu and i would be happy to

324
00:10:34,800 --> 00:10:46,800
talk further

