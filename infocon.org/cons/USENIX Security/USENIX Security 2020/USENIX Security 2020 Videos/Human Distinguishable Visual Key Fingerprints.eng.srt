1
00:00:08,160 --> 00:00:11,040
hello

2
00:00:08,800 --> 00:00:12,799
i am oshkanazi purkivi from bloomberg

3
00:00:11,040 --> 00:00:13,518
and in this talk i will discuss our

4
00:00:12,799 --> 00:00:15,599
paper

5
00:00:13,519 --> 00:00:17,759
titled human distinguishable visual key

6
00:00:15,599 --> 00:00:18,960
fingerprints which i completed during my

7
00:00:17,760 --> 00:00:21,199
pc studies

8
00:00:18,960 --> 00:00:23,680
this is a joint work with omotobkara and

9
00:00:21,199 --> 00:00:25,199
bogdan carbonar

10
00:00:23,680 --> 00:00:27,119
let's start with the definition of key

11
00:00:25,199 --> 00:00:29,279
fingerprints key fingerprints are

12
00:00:27,119 --> 00:00:30,080
compact representations of cryptographic

13
00:00:29,279 --> 00:00:32,558
material

14
00:00:30,080 --> 00:00:34,559
such as public keys or shared keys that

15
00:00:32,558 --> 00:00:36,640
need to be visually compared by users

16
00:00:34,559 --> 00:00:38,480
for authentication purposes

17
00:00:36,640 --> 00:00:41,200
you can see here an example of a key

18
00:00:38,480 --> 00:00:43,519
fingerprint generated during ssl session

19
00:00:41,200 --> 00:00:46,000
to allow the user to verify that she is

20
00:00:43,520 --> 00:00:47,760
connected to a particular server

21
00:00:46,000 --> 00:00:49,360
key fingerprints are shorter than the

22
00:00:47,760 --> 00:00:51,760
original crypto material

23
00:00:49,360 --> 00:00:54,559
therefore are creating easier to compare

24
00:00:51,760 --> 00:00:56,239
against a reference value

25
00:00:54,559 --> 00:00:57,760
throughout the stack we consider the

26
00:00:56,239 --> 00:00:58,879
following key fingerprint based

27
00:00:57,760 --> 00:01:01,440
authentication model

28
00:00:58,879 --> 00:01:02,640
in general first the user receives an

29
00:01:01,440 --> 00:01:03,680
input string that she needs to

30
00:01:02,640 --> 00:01:05,920
authenticate

31
00:01:03,680 --> 00:01:08,159
this input string can be a cryptographic

32
00:01:05,920 --> 00:01:10,159
key a file downloaded from internet

33
00:01:08,159 --> 00:01:11,520
a bitcoin address or even a device

34
00:01:10,159 --> 00:01:13,439
identifier

35
00:01:11,520 --> 00:01:15,360
a key fingerprint generation function

36
00:01:13,439 --> 00:01:16,479
converts this input string into a key

37
00:01:15,360 --> 00:01:18,400
fingerprint

38
00:01:16,479 --> 00:01:20,479
then the user needs to visually compare

39
00:01:18,400 --> 00:01:22,159
this fingerprint against a trusted

40
00:01:20,479 --> 00:01:24,159
reference value of the fingerprint

41
00:01:22,159 --> 00:01:27,119
that she has previously obtained through

42
00:01:24,159 --> 00:01:28,880
a secure autobahn channel

43
00:01:27,119 --> 00:01:31,119
we also consider a man in the middle

44
00:01:28,880 --> 00:01:31,600
adversary who can inject his own input

45
00:01:31,119 --> 00:01:33,680
key

46
00:01:31,600 --> 00:01:34,960
and try to impersonate a remote server

47
00:01:33,680 --> 00:01:36,960
or device

48
00:01:34,960 --> 00:01:38,880
or a scenario where the adversary can

49
00:01:36,960 --> 00:01:40,240
send the corrupt bitcoin address or file

50
00:01:38,880 --> 00:01:41,920
to a user

51
00:01:40,240 --> 00:01:43,280
generally the adversary attempts to

52
00:01:41,920 --> 00:01:45,840
generate a special key

53
00:01:43,280 --> 00:01:47,759
whose keeping a pen representation looks

54
00:01:45,840 --> 00:01:48,399
similar enough to the trusted reference

55
00:01:47,759 --> 00:01:51,040
value

56
00:01:48,399 --> 00:01:52,960
in order to fool the human verifier for

57
00:01:51,040 --> 00:01:54,640
example here you can see the text space

58
00:01:52,960 --> 00:01:55,679
giving a pin representation of the

59
00:01:54,640 --> 00:01:58,000
attacker's key

60
00:01:55,680 --> 00:02:00,640
differs from the trusted value only in a

61
00:01:58,000 --> 00:02:02,640
few positions

62
00:02:00,640 --> 00:02:04,399
there are several applications for key

63
00:02:02,640 --> 00:02:06,719
fingerprint based authentication

64
00:02:04,399 --> 00:02:08,720
in remote authentication scenarios using

65
00:02:06,719 --> 00:02:10,318
ssh or open pgp

66
00:02:08,720 --> 00:02:12,239
end-to-end encrypted messaging

67
00:02:10,318 --> 00:02:14,560
applications such as whatsapp

68
00:02:12,239 --> 00:02:16,080
and also device bearing in addition

69
00:02:14,560 --> 00:02:16,879
keeping appearance can be used to

70
00:02:16,080 --> 00:02:19,040
prevent different

71
00:02:16,879 --> 00:02:20,959
attacks such as phishing attacks and

72
00:02:19,040 --> 00:02:23,040
bitcoin clipboard hijacking

73
00:02:20,959 --> 00:02:24,800
or they can be used as a way to provide

74
00:02:23,040 --> 00:02:27,440
check sound for downloaded files from

75
00:02:24,800 --> 00:02:28,879
untrusted sources

76
00:02:27,440 --> 00:02:31,120
several types of key fingerprint

77
00:02:28,879 --> 00:02:33,679
representation techniques exist

78
00:02:31,120 --> 00:02:34,959
here you can see examples of text-based

79
00:02:33,680 --> 00:02:37,200
representations

80
00:02:34,959 --> 00:02:39,120
including alphanumeric pronunciable

81
00:02:37,200 --> 00:02:40,640
words and sentences

82
00:02:39,120 --> 00:02:42,800
in addition there are several visual

83
00:02:40,640 --> 00:02:44,958
keeping appear representation solutions

84
00:02:42,800 --> 00:02:46,080
for example the visual host key used by

85
00:02:44,959 --> 00:02:48,800
openssh

86
00:02:46,080 --> 00:02:51,599
wash and unicorn that convert the input

87
00:02:48,800 --> 00:02:53,360
string into an image

88
00:02:51,599 --> 00:02:54,399
various studies have confirmed that

89
00:02:53,360 --> 00:02:55,599
different key fingerprint

90
00:02:54,400 --> 00:02:57,360
representations

91
00:02:55,599 --> 00:02:59,920
affect user performance when verifying

92
00:02:57,360 --> 00:03:02,000
them for instance standalone show that

93
00:02:59,920 --> 00:03:04,879
visual key fingerprint representations

94
00:03:02,000 --> 00:03:06,879
generated by rash can be verified faster

95
00:03:04,879 --> 00:03:09,040
and easier than several commonly used

96
00:03:06,879 --> 00:03:10,799
textual representations

97
00:03:09,040 --> 00:03:12,959
the way that generates is keeping

98
00:03:10,800 --> 00:03:14,000
airplane images is by using a set of

99
00:03:12,959 --> 00:03:16,000
drawing rules

100
00:03:14,000 --> 00:03:17,360
where these rules are selected randomly

101
00:03:16,000 --> 00:03:18,640
from a collection of hand created

102
00:03:17,360 --> 00:03:20,800
functions

103
00:03:18,640 --> 00:03:22,319
however similar to all other existing

104
00:03:20,800 --> 00:03:23,280
key fingerprint representation

105
00:03:22,319 --> 00:03:25,119
techniques

106
00:03:23,280 --> 00:03:27,040
rash does not compensate for the

107
00:03:25,120 --> 00:03:29,040
limitations of human visual system

108
00:03:27,040 --> 00:03:30,239
and as a result it cannot guarantee

109
00:03:29,040 --> 00:03:32,798
collision resistance

110
00:03:30,239 --> 00:03:35,120
between the generated key fingerprints

111
00:03:32,799 --> 00:03:39,280
in fact anatole study reported the human

112
00:03:35,120 --> 00:03:39,280
error rate of 10 percent for rash images

113
00:03:39,519 --> 00:03:43,440
in our work we set to address these

114
00:03:41,280 --> 00:03:44,640
problems that is we seek to generate

115
00:03:43,440 --> 00:03:46,239
visual key fingerprints

116
00:03:44,640 --> 00:03:48,879
that take into consideration the

117
00:03:46,239 --> 00:03:50,879
limitations of human visual system

118
00:03:48,879 --> 00:03:53,120
for this we leverage studies that have

119
00:03:50,879 --> 00:03:55,200
shown realistic images are easier for

120
00:03:53,120 --> 00:03:57,200
human to compare and distinguish

121
00:03:55,200 --> 00:03:58,319
therefore we set our goal to generate

122
00:03:57,200 --> 00:04:01,359
visual fingerprints

123
00:03:58,319 --> 00:04:02,879
that are realistic images for this as

124
00:04:01,360 --> 00:04:04,799
illustrated in this figure

125
00:04:02,879 --> 00:04:06,000
instead of using handcrafted rules to

126
00:04:04,799 --> 00:04:07,920
generate images

127
00:04:06,000 --> 00:04:09,360
we use general effect adversarial

128
00:04:07,920 --> 00:04:11,518
networks organs

129
00:04:09,360 --> 00:04:14,400
to generate images that look like to the

130
00:04:11,519 --> 00:04:16,639
samples in a real image data set

131
00:04:14,400 --> 00:04:18,798
in practice we can use an input mapper

132
00:04:16,639 --> 00:04:21,120
to convert the binary input key

133
00:04:18,798 --> 00:04:23,039
into a suitable internal representation

134
00:04:21,120 --> 00:04:25,280
which we can then use as the input to

135
00:04:23,040 --> 00:04:27,600
the gan network

136
00:04:25,280 --> 00:04:29,520
ideally we want the gan image generator

137
00:04:27,600 --> 00:04:31,600
to generate key fingerprint images

138
00:04:29,520 --> 00:04:32,639
that are easily perceived as different

139
00:04:31,600 --> 00:04:34,639
by humans

140
00:04:32,639 --> 00:04:37,120
even for a pair of input vectors that

141
00:04:34,639 --> 00:04:39,360
are different only in a single component

142
00:04:37,120 --> 00:04:42,160
to address this requirement we introduce

143
00:04:39,360 --> 00:04:44,800
seal a credential assurance label system

144
00:04:42,160 --> 00:04:46,800
that extends the dc gan architecture for

145
00:04:44,800 --> 00:04:48,000
image generation with a novel training

146
00:04:46,800 --> 00:04:49,759
process that ensures

147
00:04:48,000 --> 00:04:52,720
they generated images are not only

148
00:04:49,759 --> 00:04:54,800
realistic but also human distinguishable

149
00:04:52,720 --> 00:04:56,720
however asking human to evaluate the

150
00:04:54,800 --> 00:04:59,759
generator output during training

151
00:04:56,720 --> 00:05:02,080
is expensive and does not scale well we

152
00:04:59,759 --> 00:05:03,840
also therefore seek to eliminate the

153
00:05:02,080 --> 00:05:08,000
requirement of labeling images

154
00:05:03,840 --> 00:05:10,239
using humans during the training process

155
00:05:08,000 --> 00:05:11,520
now i will introduce gan a gan network

156
00:05:10,240 --> 00:05:13,440
that we train for

157
00:05:11,520 --> 00:05:15,359
generating key fingerprint images from

158
00:05:13,440 --> 00:05:17,759
arbitrary input strings

159
00:05:15,360 --> 00:05:19,759
similar to conventional guns cl gun has

160
00:05:17,759 --> 00:05:22,000
a generator and discriminator

161
00:05:19,759 --> 00:05:24,720
however instead of one discriminator our

162
00:05:22,000 --> 00:05:26,240
cli network has two discriminators

163
00:05:24,720 --> 00:05:28,639
first is a human perception

164
00:05:26,240 --> 00:05:31,039
discriminator or hpd for short

165
00:05:28,639 --> 00:05:32,479
that determines if two images will be

166
00:05:31,039 --> 00:05:35,680
perceived as different

167
00:05:32,479 --> 00:05:38,159
or same by average human second we have

168
00:05:35,680 --> 00:05:40,479
the conventional realism discriminator

169
00:05:38,160 --> 00:05:42,400
as in gun architecture that is trained

170
00:05:40,479 --> 00:05:44,560
on a set of rear images as well as

171
00:05:42,400 --> 00:05:46,638
images generated by the generator

172
00:05:44,560 --> 00:05:48,000
to predict if an input image looks

173
00:05:46,639 --> 00:05:50,000
realistic

174
00:05:48,000 --> 00:05:52,000
during training we combine the feedback

175
00:05:50,000 --> 00:05:53,039
provided by hpd and realism

176
00:05:52,000 --> 00:05:55,039
discriminator

177
00:05:53,039 --> 00:05:56,800
about the images generated by the

178
00:05:55,039 --> 00:05:58,960
generator and we train

179
00:05:56,800 --> 00:06:01,280
the generator using these signals in

180
00:05:58,960 --> 00:06:04,719
such a way as to generate realistic and

181
00:06:01,280 --> 00:06:06,400
human distinguishable images

182
00:06:04,720 --> 00:06:08,880
we designed the human perception

183
00:06:06,400 --> 00:06:11,120
discriminator to be a scientist network

184
00:06:08,880 --> 00:06:13,120
that takes as input to images and

185
00:06:11,120 --> 00:06:14,880
extract image features using certain

186
00:06:13,120 --> 00:06:15,919
layer from the pre-trained inception

187
00:06:14,880 --> 00:06:17,840
network

188
00:06:15,919 --> 00:06:19,198
we then fit these features to several

189
00:06:17,840 --> 00:06:21,280
fully connected layers

190
00:06:19,199 --> 00:06:22,560
that we train using contrast loss and

191
00:06:21,280 --> 00:06:24,559
cross-entropy laws

192
00:06:22,560 --> 00:06:25,840
to accurately predict if the input

193
00:06:24,560 --> 00:06:30,080
images are perceived as

194
00:06:25,840 --> 00:06:32,799
identical or different by average human

195
00:06:30,080 --> 00:06:34,000
we first trained and evaluated hbd for

196
00:06:32,800 --> 00:06:37,360
this we use more than

197
00:06:34,000 --> 00:06:40,080
26 000 image pairs of which 558

198
00:06:37,360 --> 00:06:41,600
were labeled each by up to 100 amazon

199
00:06:40,080 --> 00:06:43,280
mechanical third workers

200
00:06:41,600 --> 00:06:45,759
and the rest were image pairs that we

201
00:06:43,280 --> 00:06:48,638
synthetically generated to be obviously

202
00:06:45,759 --> 00:06:50,720
different or same we tested hpd

203
00:06:48,639 --> 00:06:51,840
performance over a whole data test of

204
00:06:50,720 --> 00:06:54,240
112

205
00:06:51,840 --> 00:06:56,400
image pairs that were labeled by humans

206
00:06:54,240 --> 00:06:57,039
and it achieved a precision score of 84

207
00:06:56,400 --> 00:07:00,479
percent

208
00:06:57,039 --> 00:07:02,800
and a final score of 82 percent

209
00:07:00,479 --> 00:07:04,800
in our privilege experiments we observed

210
00:07:02,800 --> 00:07:05,360
that not all the components of the input

211
00:07:04,800 --> 00:07:08,319
vector

212
00:07:05,360 --> 00:07:10,319
to again have a human observable impact

213
00:07:08,319 --> 00:07:12,000
on the output images

214
00:07:10,319 --> 00:07:13,520
we conjecture then that some of the

215
00:07:12,000 --> 00:07:14,800
components have major impact on

216
00:07:13,520 --> 00:07:17,120
generated images

217
00:07:14,800 --> 00:07:19,280
and we call them major components while

218
00:07:17,120 --> 00:07:21,440
others have an indistinguishable impact

219
00:07:19,280 --> 00:07:23,679
on generated images

220
00:07:21,440 --> 00:07:25,840
and we call them minor components

221
00:07:23,680 --> 00:07:27,759
further we conjecture that we can train

222
00:07:25,840 --> 00:07:30,159
specific components to be either major

223
00:07:27,759 --> 00:07:32,880
or minor using similar ideas as in

224
00:07:30,160 --> 00:07:34,800
disentangled representation learning

225
00:07:32,880 --> 00:07:35,919
therefore instead of disregarding minor

226
00:07:34,800 --> 00:07:38,000
components for

227
00:07:35,919 --> 00:07:41,680
keeping every image generation we use

228
00:07:38,000 --> 00:07:43,840
them to embed image realism features

229
00:07:41,680 --> 00:07:45,360
with this in mind here is our c

230
00:07:43,840 --> 00:07:47,159
generator network

231
00:07:45,360 --> 00:07:50,080
the input to this network has lengths of

232
00:07:47,160 --> 00:07:52,000
512 and we set half of these components

233
00:07:50,080 --> 00:07:53,758
as major and the remaining half as minor

234
00:07:52,000 --> 00:07:55,759
components

235
00:07:53,759 --> 00:07:57,440
to train sale generator we train the

236
00:07:55,759 --> 00:07:58,560
network for more than 2 million

237
00:07:57,440 --> 00:08:00,639
iterations

238
00:07:58,560 --> 00:08:02,319
in each training iteration we generate

239
00:08:00,639 --> 00:08:04,080
different sets of input pairs

240
00:08:02,319 --> 00:08:05,680
and use them sequentially to train the

241
00:08:04,080 --> 00:08:07,758
network in the first

242
00:08:05,680 --> 00:08:09,120
step we use a set of input vector pairs

243
00:08:07,759 --> 00:08:11,680
that are only different

244
00:08:09,120 --> 00:08:13,440
in one major component the generator

245
00:08:11,680 --> 00:08:14,479
generates corresponding images to these

246
00:08:13,440 --> 00:08:16,479
input vectors

247
00:08:14,479 --> 00:08:18,560
then we pass these image pairs through

248
00:08:16,479 --> 00:08:20,000
hpd and realism discriminator

249
00:08:18,560 --> 00:08:21,680
to determine if they look

250
00:08:20,000 --> 00:08:23,199
distinguishable and realistic and

251
00:08:21,680 --> 00:08:25,520
provide the answer as a feedback to the

252
00:08:23,199 --> 00:08:27,360
generator

253
00:08:25,520 --> 00:08:29,359
in addition we train minor components to

254
00:08:27,360 --> 00:08:30,800
have an indistinguishable impact on

255
00:08:29,360 --> 00:08:32,800
generated images

256
00:08:30,800 --> 00:08:34,240
for this we generate input vectors that

257
00:08:32,799 --> 00:08:34,880
are different in a single minor

258
00:08:34,240 --> 00:08:36,479
component

259
00:08:34,880 --> 00:08:39,039
and use them as the input to our

260
00:08:36,479 --> 00:08:40,880
generator again we compute the output of

261
00:08:39,039 --> 00:08:42,958
hpd for generated images

262
00:08:40,880 --> 00:08:44,720
but this time we define the generator

263
00:08:42,958 --> 00:08:46,640
loss in such a way as to

264
00:08:44,720 --> 00:08:48,320
train the generator to generate image

265
00:08:46,640 --> 00:08:51,519
pairs that look identical

266
00:08:48,320 --> 00:08:53,040
for such input vectors

267
00:08:51,519 --> 00:08:55,360
in our paper which i encourage you to

268
00:08:53,040 --> 00:08:55,680
read we also train major components to

269
00:08:55,360 --> 00:08:57,680
have

270
00:08:55,680 --> 00:09:00,560
effects on different visual aspects of

271
00:08:57,680 --> 00:09:02,800
generated images

272
00:09:00,560 --> 00:09:04,959
we evaluated the resilience of c model

273
00:09:02,800 --> 00:09:06,880
that we trained to powerful gamma d

274
00:09:04,959 --> 00:09:08,000
adversaries similar to digender

275
00:09:06,880 --> 00:09:09,920
undertale

276
00:09:08,000 --> 00:09:11,600
specifically we assume the adversary

277
00:09:09,920 --> 00:09:13,680
targets a specific key

278
00:09:11,600 --> 00:09:15,680
then generates multiple attack keys that

279
00:09:13,680 --> 00:09:16,959
are different in only d bits from the

280
00:09:15,680 --> 00:09:19,040
target key

281
00:09:16,959 --> 00:09:20,800
the adversary then fits these keys to

282
00:09:19,040 --> 00:09:23,120
seal and generates corresponding visual

283
00:09:20,800 --> 00:09:25,279
key fingerprints it then uses hpd

284
00:09:23,120 --> 00:09:26,240
classifier to automatically identify

285
00:09:25,279 --> 00:09:28,560
attack keys

286
00:09:26,240 --> 00:09:30,880
whose fingerprints are perceived to be

287
00:09:28,560 --> 00:09:33,359
similar to those of the target key

288
00:09:30,880 --> 00:09:34,839
the adversary then uses this key to

289
00:09:33,360 --> 00:09:36,640
launch the final man in the middle

290
00:09:34,839 --> 00:09:38,880
attack

291
00:09:36,640 --> 00:09:41,680
to emulate such an attacker in the first

292
00:09:38,880 --> 00:09:43,279
experiment we generated 123 million

293
00:09:41,680 --> 00:09:47,040
target attack keepers

294
00:09:43,279 --> 00:09:48,640
of length 123 bits these keepers were

295
00:09:47,040 --> 00:09:50,399
different in a single bit

296
00:09:48,640 --> 00:09:52,480
we then generated corresponding

297
00:09:50,399 --> 00:09:53,360
fingerprints to these keepers using seal

298
00:09:52,480 --> 00:09:56,320
generator

299
00:09:53,360 --> 00:09:59,519
and then fit these image pairs to hpd

300
00:09:56,320 --> 00:10:01,680
hpd identified 121 samples as

301
00:09:59,519 --> 00:10:03,519
potentially successful attack pairs

302
00:10:01,680 --> 00:10:06,279
of which only two were considered

303
00:10:03,519 --> 00:10:09,760
identical when we evaluated them with

304
00:10:06,279 --> 00:10:12,000
374 amazon mechanical torque workers

305
00:10:09,760 --> 00:10:14,720
in a second experiment we generated an

306
00:10:12,000 --> 00:10:15,440
additional 123 million target attack

307
00:10:14,720 --> 00:10:18,000
keepers

308
00:10:15,440 --> 00:10:21,360
that were different in d bits where d

309
00:10:18,000 --> 00:10:25,519
ranges from 1 to 123 here

310
00:10:21,360 --> 00:10:27,680
hpd found 1473 potential attack pairs

311
00:10:25,519 --> 00:10:28,560
of which only 23 were considered

312
00:10:27,680 --> 00:10:31,279
identical

313
00:10:28,560 --> 00:10:32,560
by our 374 amazon mechanical total

314
00:10:31,279 --> 00:10:34,240
workers

315
00:10:32,560 --> 00:10:36,479
as you can see both experiments the

316
00:10:34,240 --> 00:10:39,120
human area of scene images was less than

317
00:10:36,480 --> 00:10:39,120
2 percent

318
00:10:39,360 --> 00:10:44,839
here are some of the attack samples we

319
00:10:41,440 --> 00:10:46,000
generated along with their hema

320
00:10:44,839 --> 00:10:48,399
annotation

321
00:10:46,000 --> 00:10:50,240
we also compared seal against vash under

322
00:10:48,399 --> 00:10:52,320
a general collision attack

323
00:10:50,240 --> 00:10:54,000
for this we generated ten thousand bash

324
00:10:52,320 --> 00:10:56,560
and ten thousand scene images

325
00:10:54,000 --> 00:10:57,600
using random keys we then paired each

326
00:10:56,560 --> 00:10:59,760
image in each set

327
00:10:57,600 --> 00:11:01,040
with all the other images in this step

328
00:10:59,760 --> 00:11:03,360
and like before we use

329
00:11:01,040 --> 00:11:04,079
hpd to identify potentially same looking

330
00:11:03,360 --> 00:11:06,720
samples

331
00:11:04,079 --> 00:11:09,040
and evaluate those samples using human

332
00:11:06,720 --> 00:11:12,160
subjects

333
00:11:09,040 --> 00:11:14,319
hpd classified 150 of rash and only one

334
00:11:12,160 --> 00:11:16,079
scene image pairs are same

335
00:11:14,320 --> 00:11:17,839
when we labeled these image pairs using

336
00:11:16,079 --> 00:11:20,079
human annotators

337
00:11:17,839 --> 00:11:22,079
sixteen percent of one hundred and fifty

338
00:11:20,079 --> 00:11:25,359
bash image pairs were labeled the same

339
00:11:22,079 --> 00:11:27,920
but not the only seal imagery

340
00:11:25,360 --> 00:11:29,839
in conclusion we presented seal a visual

341
00:11:27,920 --> 00:11:31,279
key fingerprint generation solution

342
00:11:29,839 --> 00:11:32,959
the first style generates key

343
00:11:31,279 --> 00:11:34,079
fingerprints designed to be human

344
00:11:32,959 --> 00:11:35,680
distinguishable

345
00:11:34,079 --> 00:11:37,120
even in the presence of powerful

346
00:11:35,680 --> 00:11:38,880
adversaries

347
00:11:37,120 --> 00:11:40,240
seen improves on the state of the art

348
00:11:38,880 --> 00:11:41,439
visual key fingerprint generation

349
00:11:40,240 --> 00:11:43,440
solution bash

350
00:11:41,440 --> 00:11:45,440
it is more resilient to attacks and it

351
00:11:43,440 --> 00:11:47,200
generates images that are still fast to

352
00:11:45,440 --> 00:11:49,360
compare by humans

353
00:11:47,200 --> 00:11:51,200
our research further provides incentives

354
00:11:49,360 --> 00:11:52,720
to adversaries to build better human

355
00:11:51,200 --> 00:11:54,639
perception discriminators

356
00:11:52,720 --> 00:11:55,839
in order to improve the accuracy of the

357
00:11:54,639 --> 00:11:57,519
attacks this

358
00:11:55,839 --> 00:11:59,279
in turn has applications to capture us

359
00:11:57,519 --> 00:12:00,320
where the user would be shown specific

360
00:11:59,279 --> 00:12:01,680
images to compare

361
00:12:00,320 --> 00:12:03,920
that are known to be difficult to

362
00:12:01,680 --> 00:12:05,279
compare by hpd

363
00:12:03,920 --> 00:12:11,839
thanks for your attention and please

364
00:12:05,279 --> 00:12:11,839
contact us if you have any questions

365
00:12:16,079 --> 00:12:18,160
you

