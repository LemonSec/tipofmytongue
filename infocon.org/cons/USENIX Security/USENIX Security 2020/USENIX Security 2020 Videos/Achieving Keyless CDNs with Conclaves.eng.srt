1
00:00:08,320 --> 00:00:11,440
hi

2
00:00:08,880 --> 00:00:12,960
i'm stephen herwig in this presentation

3
00:00:11,440 --> 00:00:14,719
i will be talking about my work in

4
00:00:12,960 --> 00:00:15,599
building keyless content delivery

5
00:00:14,719 --> 00:00:17,759
networks

6
00:00:15,599 --> 00:00:20,160
this is joint work with my advisor dave

7
00:00:17,760 --> 00:00:21,439
levin and our collaborator christina

8
00:00:20,160 --> 00:00:23,359
garman

9
00:00:21,439 --> 00:00:24,880
suppose we log into our bank's website

10
00:00:23,359 --> 00:00:26,240
to pay some bills

11
00:00:24,880 --> 00:00:28,080
although we envision our browser

12
00:00:26,240 --> 00:00:28,880
connecting directly to the bank's web

13
00:00:28,080 --> 00:00:30,880
server

14
00:00:28,880 --> 00:00:32,000
the truth is that the bank and many

15
00:00:30,880 --> 00:00:33,839
other websites

16
00:00:32,000 --> 00:00:35,280
use a third party service called a

17
00:00:33,840 --> 00:00:38,399
content delivery network

18
00:00:35,280 --> 00:00:39,600
or cdn to host their website at their

19
00:00:38,399 --> 00:00:41,840
course cdn's are

20
00:00:39,600 --> 00:00:44,000
massive global network of physical ed

21
00:00:41,840 --> 00:00:45,760
servers that act as caches for the

22
00:00:44,000 --> 00:00:47,440
customer server

23
00:00:45,760 --> 00:00:49,760
although the traditional value add of a

24
00:00:47,440 --> 00:00:52,079
cdn is improving a site's speed

25
00:00:49,760 --> 00:00:54,399
cdns also provides security by

26
00:00:52,079 --> 00:00:56,000
mitigating ddos attacks and running web

27
00:00:54,399 --> 00:00:58,800
application firewalls that block

28
00:00:56,000 --> 00:01:01,840
targeted attacks in order for the edge

29
00:00:58,800 --> 00:01:03,760
server to serve content over https

30
00:01:01,840 --> 00:01:05,119
they must have access to the website's

31
00:01:03,760 --> 00:01:07,280
private key

32
00:01:05,119 --> 00:01:08,960
in practice the customer shares their

33
00:01:07,280 --> 00:01:10,880
private key with the cdn

34
00:01:08,960 --> 00:01:13,600
and this key is placed on each of the

35
00:01:10,880 --> 00:01:15,920
cdn's edge servers

36
00:01:13,600 --> 00:01:18,559
in fact the study from 2016 found that

37
00:01:15,920 --> 00:01:21,040
43 percent of the alexa top 10 000

38
00:01:18,560 --> 00:01:22,320
share their keys key sharing of course

39
00:01:21,040 --> 00:01:24,560
brings many concerns

40
00:01:22,320 --> 00:01:26,080
as the cdn is now a man in the middle

41
00:01:24,560 --> 00:01:28,320
and trusts for the web as a whole

42
00:01:26,080 --> 00:01:30,400
becomes consolidated to just a handful

43
00:01:28,320 --> 00:01:32,079
of providers

44
00:01:30,400 --> 00:01:33,680
i should also note that cdns generally

45
00:01:32,079 --> 00:01:34,639
don't even want to have their customers

46
00:01:33,680 --> 00:01:37,520
private keys

47
00:01:34,640 --> 00:01:38,000
as this raises liability issues to

48
00:01:37,520 --> 00:01:40,399
address

49
00:01:38,000 --> 00:01:42,880
aspects of this problem cloudflare

50
00:01:40,400 --> 00:01:45,360
developed the keyless ssl protocol

51
00:01:42,880 --> 00:01:48,158
which allows cdn customers to maintain

52
00:01:45,360 --> 00:01:50,560
sole ownership of their private keys

53
00:01:48,159 --> 00:01:51,520
keyless ssl takes advantage of the fact

54
00:01:50,560 --> 00:01:53,759
that tls

55
00:01:51,520 --> 00:01:54,640
only uses the website's private key in a

56
00:01:53,759 --> 00:01:57,759
single step

57
00:01:54,640 --> 00:01:58,399
of the tls handshake and so with keyless

58
00:01:57,759 --> 00:02:00,880
ssl

59
00:01:58,399 --> 00:02:03,200
the cdn's edge server proxies the

60
00:02:00,880 --> 00:02:05,759
handshake to a customer controlled key

61
00:02:03,200 --> 00:02:09,840
server and the rest of the web request

62
00:02:05,759 --> 00:02:09,840
is handled by the edge server

63
00:02:11,038 --> 00:02:15,440
however even with keyless ssl the cdn

64
00:02:14,160 --> 00:02:18,239
operator still learns

65
00:02:15,440 --> 00:02:19,440
all the session keys moreover in

66
00:02:18,239 --> 00:02:21,599
practice customers

67
00:02:19,440 --> 00:02:23,680
ask the cdn operator to run the key

68
00:02:21,599 --> 00:02:25,679
server on their behalf

69
00:02:23,680 --> 00:02:28,319
thus the actual benefit is not for the

70
00:02:25,680 --> 00:02:29,840
customer to retain custody of the key

71
00:02:28,319 --> 00:02:33,599
but rather to mitigate against

72
00:02:29,840 --> 00:02:36,080
heartbleed style vulnerabilities

73
00:02:33,599 --> 00:02:37,200
cdns are just one specific example of

74
00:02:36,080 --> 00:02:39,120
the broader problem

75
00:02:37,200 --> 00:02:41,280
of organizations outsourcing their

76
00:02:39,120 --> 00:02:43,519
applications or infrastructure

77
00:02:41,280 --> 00:02:45,200
to a third party despite exposing

78
00:02:43,519 --> 00:02:46,560
private data about themselves in the

79
00:02:45,200 --> 00:02:49,040
process

80
00:02:46,560 --> 00:02:50,319
beyond cdns my broader question is

81
00:02:49,040 --> 00:02:53,040
whether we can maintain

82
00:02:50,319 --> 00:02:55,359
privacy using legacy applications on

83
00:02:53,040 --> 00:02:57,359
third-party resources

84
00:02:55,360 --> 00:02:59,200
in this setup we assume that the content

85
00:02:57,360 --> 00:03:01,680
owner and the third party

86
00:02:59,200 --> 00:03:03,599
agree to run on the third party server

87
00:03:01,680 --> 00:03:04,640
some software that the content owner

88
00:03:03,599 --> 00:03:06,399
trusts

89
00:03:04,640 --> 00:03:08,559
we assume a threat model where the third

90
00:03:06,400 --> 00:03:09,599
party can arbitrarily interfere with the

91
00:03:08,560 --> 00:03:11,280
software

92
00:03:09,599 --> 00:03:13,280
and our goal is to reduce the third

93
00:03:11,280 --> 00:03:16,800
party's adversarial power

94
00:03:13,280 --> 00:03:18,959
to that of a network level tls attacker

95
00:03:16,800 --> 00:03:20,800
as a central goal and distinguishing

96
00:03:18,959 --> 00:03:22,800
feature of this work

97
00:03:20,800 --> 00:03:24,959
i seek solutions that are compatible

98
00:03:22,800 --> 00:03:26,400
with off-the-shelf software

99
00:03:24,959 --> 00:03:28,480
in particular i don't want to have to

100
00:03:26,400 --> 00:03:30,720
rewrite software from scratch to achieve

101
00:03:28,480 --> 00:03:32,238
these security properties

102
00:03:30,720 --> 00:03:33,920
now we have the building blocks to start

103
00:03:32,239 --> 00:03:35,519
solving this problem

104
00:03:33,920 --> 00:03:37,200
the challenge is to compose these

105
00:03:35,519 --> 00:03:40,319
building blocks into a coherent

106
00:03:37,200 --> 00:03:41,518
meaningful system let's focus on

107
00:03:40,319 --> 00:03:44,000
building up this system

108
00:03:41,519 --> 00:03:46,239
and then come back to building a cdn

109
00:03:44,000 --> 00:03:46,640
specifically phoenix with this system in

110
00:03:46,239 --> 00:03:50,159
mind

111
00:03:46,640 --> 00:03:52,559
later in the talk as our core building

112
00:03:50,159 --> 00:03:56,399
block for secure remote computation

113
00:03:52,560 --> 00:03:57,439
we use intel sgx sgx is an extension to

114
00:03:56,400 --> 00:03:59,920
the x86

115
00:03:57,439 --> 00:04:02,000
instruction set that allows a process to

116
00:03:59,920 --> 00:04:02,238
define a private region of memory called

117
00:04:02,000 --> 00:04:05,200
an

118
00:04:02,239 --> 00:04:07,360
enclave sjx guarantees via hardware

119
00:04:05,200 --> 00:04:08,399
security checks that software outside of

120
00:04:07,360 --> 00:04:10,799
the enclave

121
00:04:08,400 --> 00:04:14,000
and even a physical attacker cannot

122
00:04:10,799 --> 00:04:16,000
observe or alter the enclave state

123
00:04:14,000 --> 00:04:18,798
in practice various side channel attacks

124
00:04:16,000 --> 00:04:20,798
have undermined this guarantee

125
00:04:18,798 --> 00:04:22,320
and in this particular iteration of our

126
00:04:20,798 --> 00:04:25,679
work we treat mitigation

127
00:04:22,320 --> 00:04:27,840
as an orthogonal concern

128
00:04:25,680 --> 00:04:30,000
the first challenge is to design and

129
00:04:27,840 --> 00:04:32,159
implement an execution environment

130
00:04:30,000 --> 00:04:34,960
that handles the restrictions of enclave

131
00:04:32,160 --> 00:04:37,360
mode to run such legacy binaries

132
00:04:34,960 --> 00:04:40,638
the most obvious restriction being that

133
00:04:37,360 --> 00:04:42,240
enclave code cannot make system calls

134
00:04:40,639 --> 00:04:44,080
there have been a few projects that seek

135
00:04:42,240 --> 00:04:45,280
to take legacy binaries and run them in

136
00:04:44,080 --> 00:04:47,599
an enclave

137
00:04:45,280 --> 00:04:49,440
the general idea is to move lib c and

138
00:04:47,600 --> 00:04:52,080
part of the operating system kernel

139
00:04:49,440 --> 00:04:53,280
now refactored as a library into the

140
00:04:52,080 --> 00:04:55,520
enclave

141
00:04:53,280 --> 00:04:56,638
libsy is patched to invoke the libos for

142
00:04:55,520 --> 00:04:58,159
system calls

143
00:04:56,639 --> 00:05:00,400
and the liberal as proxies to the

144
00:04:58,160 --> 00:05:03,120
untrusted host for any system call that

145
00:05:00,400 --> 00:05:05,520
it cannot service internally

146
00:05:03,120 --> 00:05:06,320
the specific libos implementation i

147
00:05:05,520 --> 00:05:09,599
built off of

148
00:05:06,320 --> 00:05:10,000
is graphene sgx with this liberalized

149
00:05:09,600 --> 00:05:12,639
design

150
00:05:10,000 --> 00:05:14,960
graphene provides a foothold to add and

151
00:05:12,639 --> 00:05:16,720
emulate additional features

152
00:05:14,960 --> 00:05:18,638
for instance graphene's main added

153
00:05:16,720 --> 00:05:21,360
feature is allowing an enclave

154
00:05:18,639 --> 00:05:24,720
process to fork a child process which

155
00:05:21,360 --> 00:05:27,280
itself runs within an enclave

156
00:05:24,720 --> 00:05:29,680
however to run software such as a

157
00:05:27,280 --> 00:05:30,400
multi-process web server on the cdn's

158
00:05:29,680 --> 00:05:32,479
edge

159
00:05:30,400 --> 00:05:34,479
we also need graphene to securely

160
00:05:32,479 --> 00:05:36,840
emulate additional resources

161
00:05:34,479 --> 00:05:38,000
that the various application processes

162
00:05:36,840 --> 00:05:40,880
share

163
00:05:38,000 --> 00:05:42,560
with conclaves my contribution is

164
00:05:40,880 --> 00:05:44,800
extending the enclave security

165
00:05:42,560 --> 00:05:47,680
guarantees beyond private memory

166
00:05:44,800 --> 00:05:48,240
to these other shared system resources

167
00:05:47,680 --> 00:05:49,919
the hard

168
00:05:48,240 --> 00:05:52,240
for instance the hard disk and shared

169
00:05:49,919 --> 00:05:53,520
memory and incorporating the respective

170
00:05:52,240 --> 00:05:56,080
driver components

171
00:05:53,520 --> 00:05:56,960
within either graphene or the plug-in

172
00:05:56,080 --> 00:06:00,240
framework

173
00:05:56,960 --> 00:06:01,919
of some core user library my insight is

174
00:06:00,240 --> 00:06:03,520
to think of the application and its

175
00:06:01,919 --> 00:06:06,080
execution environment

176
00:06:03,520 --> 00:06:08,240
as a distributed system of processes

177
00:06:06,080 --> 00:06:10,240
each running within an enclave

178
00:06:08,240 --> 00:06:11,360
this leads to a microkernel-inspired

179
00:06:10,240 --> 00:06:13,680
architecture

180
00:06:11,360 --> 00:06:15,759
where kernel services such as the file

181
00:06:13,680 --> 00:06:16,880
system shared memory or an application

182
00:06:15,759 --> 00:06:19,199
key store

183
00:06:16,880 --> 00:06:20,960
are implemented as dedicated servers

184
00:06:19,199 --> 00:06:22,720
running within an enclave

185
00:06:20,960 --> 00:06:24,159
and where an application's underlying

186
00:06:22,720 --> 00:06:25,759
instance of graphene

187
00:06:24,160 --> 00:06:28,000
proxy is a system call to the

188
00:06:25,759 --> 00:06:30,240
appropriate server

189
00:06:28,000 --> 00:06:31,759
as the design contains multiple enclaves

190
00:06:30,240 --> 00:06:33,440
there is the need to bootstrap

191
00:06:31,759 --> 00:06:35,759
trust in the resultant distributed

192
00:06:33,440 --> 00:06:37,440
system and ultimately provision it with

193
00:06:35,759 --> 00:06:39,120
private data

194
00:06:37,440 --> 00:06:41,919
this part of the work is still a work in

195
00:06:39,120 --> 00:06:43,840
progress but it follows from prior work

196
00:06:41,919 --> 00:06:45,680
and the connections between the enclaves

197
00:06:43,840 --> 00:06:49,840
are mutually authenticated

198
00:06:45,680 --> 00:06:49,840
and attested tls connections

199
00:06:50,639 --> 00:06:54,160
as an initial kernel server we implement

200
00:06:53,199 --> 00:06:57,280
a key server

201
00:06:54,160 --> 00:06:58,560
as a type of sgx rendition of a hardware

202
00:06:57,280 --> 00:07:01,919
security module

203
00:06:58,560 --> 00:07:03,599
with a companion open ssl engine we also

204
00:07:01,919 --> 00:07:04,719
developed several implementations of

205
00:07:03,599 --> 00:07:06,719
shared memory

206
00:07:04,720 --> 00:07:09,120
all implemented as file systems within

207
00:07:06,720 --> 00:07:11,759
graphene that expose a memory file

208
00:07:09,120 --> 00:07:14,400
abstraction

209
00:07:11,759 --> 00:07:17,360
in one version the application opens and

210
00:07:14,400 --> 00:07:20,560
maps a file on such a file system

211
00:07:17,360 --> 00:07:23,759
and then uses the f control system call

212
00:07:20,560 --> 00:07:25,280
to lock the file the graph the graphene

213
00:07:23,759 --> 00:07:28,240
libos services the call

214
00:07:25,280 --> 00:07:30,080
by making an rpc to the memory server

215
00:07:28,240 --> 00:07:31,360
the memory server manages the shared

216
00:07:30,080 --> 00:07:33,680
memory segment as an

217
00:07:31,360 --> 00:07:36,560
encrypted host file as well as managing

218
00:07:33,680 --> 00:07:38,400
the lock owner and keying material

219
00:07:36,560 --> 00:07:39,840
on acquiring the lock and keying

220
00:07:38,400 --> 00:07:43,520
material from the server

221
00:07:39,840 --> 00:07:44,479
the libos reads the encrypted memory

222
00:07:43,520 --> 00:07:47,599
segment

223
00:07:44,479 --> 00:07:51,280
into the enclave decrypts it and

224
00:07:47,599 --> 00:07:53,199
and updates its memory pages finally

225
00:07:51,280 --> 00:07:54,400
for an encrypted and integrity protected

226
00:07:53,199 --> 00:07:56,960
file system

227
00:07:54,400 --> 00:07:59,039
we convert a user space implementation

228
00:07:56,960 --> 00:08:02,159
of a standard linux file system

229
00:07:59,039 --> 00:08:05,199
into a server we then run that resulted

230
00:08:02,160 --> 00:08:07,360
file system server on top of graphene

231
00:08:05,199 --> 00:08:09,039
we emulate the hard disk by formatting a

232
00:08:07,360 --> 00:08:12,080
large untrusted host file

233
00:08:09,039 --> 00:08:14,639
as the backing store on a file system

234
00:08:12,080 --> 00:08:17,198
related system call the libos again

235
00:08:14,639 --> 00:08:19,280
proxies the call to the file server

236
00:08:17,199 --> 00:08:21,919
the file server implements a block layer

237
00:08:19,280 --> 00:08:23,919
that decrypts the virtual blocks on read

238
00:08:21,919 --> 00:08:27,840
while also maintaining a merkle tree

239
00:08:23,919 --> 00:08:27,840
over the entire backing store

240
00:08:32,159 --> 00:08:37,919
i use the term conclave to refer to such

241
00:08:34,719 --> 00:08:40,320
a collection of cooperating enclaves

242
00:08:37,919 --> 00:08:42,478
to the application use of these kernel

243
00:08:40,320 --> 00:08:44,320
servers is either transparent

244
00:08:42,479 --> 00:08:45,920
transparent modulo and application

245
00:08:44,320 --> 00:08:48,000
configuration option

246
00:08:45,920 --> 00:08:49,680
or requires a small patch as with the

247
00:08:48,000 --> 00:08:52,160
memory server

248
00:08:49,680 --> 00:08:52,719
coming back to the cdn use case i use

249
00:08:52,160 --> 00:08:55,600
the term

250
00:08:52,720 --> 00:08:57,680
phoenix to refer to nginx configured as

251
00:08:55,600 --> 00:08:58,640
a reverse caching proxy running within

252
00:08:57,680 --> 00:09:00,880
an enclave

253
00:08:58,640 --> 00:09:02,800
as a sort of conclave analog to an edge

254
00:09:00,880 --> 00:09:04,800
server software stack

255
00:09:02,800 --> 00:09:06,079
in our paper we discuss other details

256
00:09:04,800 --> 00:09:08,479
such as how customers

257
00:09:06,080 --> 00:09:09,360
could securely delegate provisioning to

258
00:09:08,480 --> 00:09:12,640
the con

259
00:09:09,360 --> 00:09:14,320
of the conclave to the operator we also

260
00:09:12,640 --> 00:09:17,199
discussed deployments where conclaves

261
00:09:14,320 --> 00:09:19,120
can contain multiple parties

262
00:09:17,200 --> 00:09:20,720
now as a macro benchmark for evaluating

263
00:09:19,120 --> 00:09:22,880
phoenix's performance

264
00:09:20,720 --> 00:09:24,880
i use a web server stressing tool to

265
00:09:22,880 --> 00:09:26,640
measure the web service throughput

266
00:09:24,880 --> 00:09:29,200
varying the size of the file and number

267
00:09:26,640 --> 00:09:31,760
of nginx worker processes

268
00:09:29,200 --> 00:09:33,920
as a baseline i first evaluate nginx

269
00:09:31,760 --> 00:09:36,560
running outside of a conclave

270
00:09:33,920 --> 00:09:37,199
where i determine the legend as linux as

271
00:09:36,560 --> 00:09:39,439
you can see

272
00:09:37,200 --> 00:09:41,440
the throughput varies between 800 and

273
00:09:39,440 --> 00:09:43,040
3000 requests per second

274
00:09:41,440 --> 00:09:45,440
depending on the configuration and

275
00:09:43,040 --> 00:09:47,839
workload i next compare

276
00:09:45,440 --> 00:09:49,600
two configurations of phoenix phoenix

277
00:09:47,839 --> 00:09:51,760
crypt and veracrypt

278
00:09:49,600 --> 00:09:53,519
the kernel servers for crypt only offer

279
00:09:51,760 --> 00:09:54,640
confidentiality of their respective

280
00:09:53,519 --> 00:09:56,320
resources

281
00:09:54,640 --> 00:09:58,399
whereas those of veracrypt also

282
00:09:56,320 --> 00:10:00,640
guarantee integrity

283
00:09:58,399 --> 00:10:02,320
with these workloads phoenix crypt's

284
00:10:00,640 --> 00:10:03,439
overhead is roughly two to three times

285
00:10:02,320 --> 00:10:06,000
that of linux

286
00:10:03,440 --> 00:10:07,120
whereas veracrypt is between 3 and 14

287
00:10:06,000 --> 00:10:08,959
times

288
00:10:07,120 --> 00:10:11,120
needless to say this isn't great but

289
00:10:08,959 --> 00:10:11,680
nevertheless it's a very promising start

290
00:10:11,120 --> 00:10:14,880
for what

291
00:10:11,680 --> 00:10:16,839
amounts to an unoptimized system we next

292
00:10:14,880 --> 00:10:19,200
evaluate conclave approaches to

293
00:10:16,839 --> 00:10:21,600
multi-tenancy which is hosting multiple

294
00:10:19,200 --> 00:10:23,600
customers on the same edge server

295
00:10:21,600 --> 00:10:25,839
in this evaluation we scale the number

296
00:10:23,600 --> 00:10:28,240
of tenants from one up to six

297
00:10:25,839 --> 00:10:30,240
conduct the stress test and then compute

298
00:10:28,240 --> 00:10:32,720
the mean time to request a one kilobyte

299
00:10:30,240 --> 00:10:34,959
file across all tenants

300
00:10:32,720 --> 00:10:37,040
at these tenants numbers the non

301
00:10:34,959 --> 00:10:37,920
enclaved linux baseline exhibits a

302
00:10:37,040 --> 00:10:39,920
latency

303
00:10:37,920 --> 00:10:41,040
that grows sublinearly with a number of

304
00:10:39,920 --> 00:10:43,279
tenants

305
00:10:41,040 --> 00:10:44,399
in our first conclave approach called

306
00:10:43,279 --> 00:10:46,800
share nothing

307
00:10:44,399 --> 00:10:48,959
each customer runs their own conclave

308
00:10:46,800 --> 00:10:51,199
including their own dedicated unclaimed

309
00:10:48,959 --> 00:10:53,119
instance of engine x

310
00:10:51,200 --> 00:10:55,040
we see that request time increases

311
00:10:53,120 --> 00:10:56,240
roughly quadratically with the number of

312
00:10:55,040 --> 00:10:57,760
tenants

313
00:10:56,240 --> 00:10:59,360
if we instead use an approach where

314
00:10:57,760 --> 00:11:01,920
tenants share

315
00:10:59,360 --> 00:11:03,040
and nonclaimed nginx but use their own

316
00:11:01,920 --> 00:11:04,959
kernel servers

317
00:11:03,040 --> 00:11:06,480
then request time increases only

318
00:11:04,959 --> 00:11:08,160
linearly

319
00:11:06,480 --> 00:11:10,079
now it's interesting to also plot the

320
00:11:08,160 --> 00:11:12,399
number of sjs paging events

321
00:11:10,079 --> 00:11:14,000
during these tests because we see that

322
00:11:12,399 --> 00:11:16,800
somewhere between 32 and

323
00:11:14,000 --> 00:11:19,920
48 enclaves there's a dramatic increase

324
00:11:16,800 --> 00:11:21,599
in pressure on the limited epc memory

325
00:11:19,920 --> 00:11:23,360
the take home message that supporting

326
00:11:21,600 --> 00:11:25,120
massive multi-tenancy

327
00:11:23,360 --> 00:11:27,120
indicates a deployment where customers

328
00:11:25,120 --> 00:11:28,720
share enclaves

329
00:11:27,120 --> 00:11:30,320
we include many other results in our

330
00:11:28,720 --> 00:11:33,600
paper please

331
00:11:30,320 --> 00:11:35,519
please check it out in conclusion users

332
00:11:33,600 --> 00:11:37,680
continue to outsource their applications

333
00:11:35,519 --> 00:11:40,640
and infrastructure to third parties

334
00:11:37,680 --> 00:11:41,120
and in doing so for for privacy in this

335
00:11:40,640 --> 00:11:42,959
paper

336
00:11:41,120 --> 00:11:44,160
we present the design and implementation

337
00:11:42,959 --> 00:11:47,279
of conclaves

338
00:11:44,160 --> 00:11:49,519
an extension to the graphene sgx libos

339
00:11:47,279 --> 00:11:50,399
that runs legacy applications safely on

340
00:11:49,519 --> 00:11:52,800
third parties

341
00:11:50,399 --> 00:11:54,720
by among other things extending

342
00:11:52,800 --> 00:11:56,160
graphene's protection to the file system

343
00:11:54,720 --> 00:11:58,160
and shared memory

344
00:11:56,160 --> 00:12:00,079
i've enjoyed sharing this work with you

345
00:11:58,160 --> 00:12:01,839
and i encourage you to explore conclaves

346
00:12:00,079 --> 00:12:11,839
for use cases that you may encounter in

347
00:12:01,839 --> 00:12:13,920
your own research

348
00:12:11,839 --> 00:12:13,920
you

