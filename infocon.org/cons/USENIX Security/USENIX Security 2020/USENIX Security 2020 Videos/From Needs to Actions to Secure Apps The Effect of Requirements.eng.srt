1
00:00:09,679 --> 00:00:14,160
welcome

2
00:00:11,120 --> 00:00:15,678
i'm charles ware of lancaster university

3
00:00:14,160 --> 00:00:17,920
and i'm presenting to you today are

4
00:00:15,679 --> 00:00:19,080
discoveries from a survey of android app

5
00:00:17,920 --> 00:00:22,000
developers

6
00:00:19,080 --> 00:00:24,880
investigating their security practices

7
00:00:22,000 --> 00:00:27,119
and motivations

8
00:00:24,880 --> 00:00:28,960
we started by wanting to find out what

9
00:00:27,119 --> 00:00:30,720
real software developers were doing by

10
00:00:28,960 --> 00:00:34,559
way of secure programming

11
00:00:30,720 --> 00:00:35,519
and why they were doing it sasha files

12
00:00:34,559 --> 00:00:38,399
team

13
00:00:35,520 --> 00:00:40,000
in leibniz hunt university hanover have

14
00:00:38,399 --> 00:00:41,200
been scraping information from the

15
00:00:40,000 --> 00:00:44,800
android app store

16
00:00:41,200 --> 00:00:47,200
that's google play for several years

17
00:00:44,800 --> 00:00:49,038
from the play store metadata they had

18
00:00:47,200 --> 00:00:51,680
developer contact emails

19
00:00:49,039 --> 00:00:53,600
app installation counts and the most

20
00:00:51,680 --> 00:00:55,199
recent update information

21
00:00:53,600 --> 00:00:56,800
they also had copies of the apps

22
00:00:55,199 --> 00:00:59,839
themselves

23
00:00:56,800 --> 00:01:02,160
aha we thought let's compare what the

24
00:00:59,840 --> 00:01:03,120
developers tell us about that process in

25
00:01:02,160 --> 00:01:05,039
a survey

26
00:01:03,120 --> 00:01:07,679
with what we can find out from analysis

27
00:01:05,040 --> 00:01:10,640
of the app binaries

28
00:01:07,680 --> 00:01:11,200
the approach including gdpr implications

29
00:01:10,640 --> 00:01:13,680
were

30
00:01:11,200 --> 00:01:15,280
was approved by the lancaster fsd ethics

31
00:01:13,680 --> 00:01:17,200
panel and we provided all the normal

32
00:01:15,280 --> 00:01:19,920
covering information and accountability

33
00:01:17,200 --> 00:01:19,920
mechanisms

34
00:01:20,479 --> 00:01:25,119
here are the numbers observe that we did

35
00:01:24,400 --> 00:01:27,360
a lot

36
00:01:25,119 --> 00:01:29,040
of testing and validation three

37
00:01:27,360 --> 00:01:31,840
different kinds of pre-trial

38
00:01:29,040 --> 00:01:33,200
all of which led to important changes

39
00:01:31,840 --> 00:01:34,960
for example

40
00:01:33,200 --> 00:01:36,960
after the face-to-face pilots we

41
00:01:34,960 --> 00:01:38,000
realized that unsuccessful apps weren't

42
00:01:36,960 --> 00:01:40,000
interesting

43
00:01:38,000 --> 00:01:43,200
so in the end we only invited developers

44
00:01:40,000 --> 00:01:45,119
of apps with more than 100 downloads

45
00:01:43,200 --> 00:01:46,479
we also set a limit on the time to

46
00:01:45,119 --> 00:01:48,320
complete the survey

47
00:01:46,479 --> 00:01:51,439
so anyone who just went through ticking

48
00:01:48,320 --> 00:01:54,000
randomly was removed

49
00:01:51,439 --> 00:01:55,279
some apps didn't download others we

50
00:01:54,000 --> 00:01:57,119
couldn't analyze

51
00:01:55,280 --> 00:02:00,960
but as you see we got enough for

52
00:01:57,119 --> 00:02:00,960
sensible statistical analysis

53
00:02:01,439 --> 00:02:05,439
i rather like this plot to where the

54
00:02:03,200 --> 00:02:08,560
participants came from

55
00:02:05,439 --> 00:02:10,959
kde plots like this show the density

56
00:02:08,560 --> 00:02:13,040
so highly populated europe shows more

57
00:02:10,959 --> 00:02:14,400
dense than other parts of the world

58
00:02:13,040 --> 00:02:17,679
in fact the country with the most

59
00:02:14,400 --> 00:02:19,760
respondents was the usa with 10 percent

60
00:02:17,680 --> 00:02:21,200
but this shows that despite being

61
00:02:19,760 --> 00:02:25,519
english language only

62
00:02:21,200 --> 00:02:25,519
it was very much an international survey

63
00:02:25,599 --> 00:02:30,079
so let's look at the results i'll

64
00:02:28,160 --> 00:02:31,280
discuss first the answers we got from

65
00:02:30,080 --> 00:02:33,200
the survey

66
00:02:31,280 --> 00:02:35,440
then how some of those answers turned

67
00:02:33,200 --> 00:02:37,440
out to relate to each other's

68
00:02:35,440 --> 00:02:38,800
then the results we got from analyzing

69
00:02:37,440 --> 00:02:40,480
the apps themselves

70
00:02:38,800 --> 00:02:42,959
and how those related to the survey

71
00:02:40,480 --> 00:02:42,959
answers

72
00:02:43,280 --> 00:02:47,680
first the description of the survey data

73
00:02:48,080 --> 00:02:53,519
we wanted to know not just what

74
00:02:51,040 --> 00:02:57,120
developers were doing by way of security

75
00:02:53,519 --> 00:03:00,080
but why so we asked them how important

76
00:02:57,120 --> 00:03:02,239
they rated various requirements

77
00:03:00,080 --> 00:03:04,720
interestingly security and privacy

78
00:03:02,239 --> 00:03:06,720
really rated pretty highly

79
00:03:04,720 --> 00:03:08,959
with nearly half the respondents rating

80
00:03:06,720 --> 00:03:13,120
them as extremely important

81
00:03:08,959 --> 00:03:13,120
that's more than portability or features

82
00:03:14,159 --> 00:03:19,760
and of course we ask them what security

83
00:03:17,360 --> 00:03:21,840
techniques they were using

84
00:03:19,760 --> 00:03:22,879
this list we asked about was based on

85
00:03:21,840 --> 00:03:25,120
prior work

86
00:03:22,879 --> 00:03:26,798
and is the key five most cost effective

87
00:03:25,120 --> 00:03:28,959
and widely used software assurance

88
00:03:26,799 --> 00:03:31,040
techniques

89
00:03:28,959 --> 00:03:32,959
as you see more than half the

90
00:03:31,040 --> 00:03:35,519
respondents aren't using any given

91
00:03:32,959 --> 00:03:35,519
technique

92
00:03:35,599 --> 00:03:39,518
but this graphic doesn't really tell us

93
00:03:37,599 --> 00:03:41,760
much because it doesn't show whether

94
00:03:39,519 --> 00:03:44,159
everyone's using a different technique

95
00:03:41,760 --> 00:03:46,000
or whether some teams use all five and

96
00:03:44,159 --> 00:03:47,440
others use none at all

97
00:03:46,000 --> 00:03:49,760
so we did some munging of the

98
00:03:47,440 --> 00:03:53,280
respondents answers and produced

99
00:03:49,760 --> 00:03:55,760
this these

100
00:03:53,280 --> 00:03:58,239
stacked bars show what proportion of

101
00:03:55,760 --> 00:03:58,798
respondents are using one two three four

102
00:03:58,239 --> 00:04:02,000
five

103
00:03:58,799 --> 00:04:04,400
techniques or none at all and how often

104
00:04:02,000 --> 00:04:07,599
they do so

105
00:04:04,400 --> 00:04:10,000
as you can see about three quarters have

106
00:04:07,599 --> 00:04:12,238
dipped to toe in the water by trying at

107
00:04:10,000 --> 00:04:14,159
least one of the techniques

108
00:04:12,239 --> 00:04:16,798
nearly half are doing at least one

109
00:04:14,159 --> 00:04:16,798
regularly

110
00:04:16,880 --> 00:04:21,759
of course the results from one survey

111
00:04:19,519 --> 00:04:24,479
aren't very interesting in themselves

112
00:04:21,759 --> 00:04:27,040
so we have to do some simple statistics

113
00:04:24,479 --> 00:04:28,800
to go from the proportions we measured

114
00:04:27,040 --> 00:04:30,400
to make pronouncements about the whole

115
00:04:28,800 --> 00:04:33,440
population

116
00:04:30,400 --> 00:04:36,799
it's called the confidence interval for

117
00:04:33,440 --> 00:04:40,320
a proportion population

118
00:04:36,800 --> 00:04:43,440
so taking the 45 percent height

119
00:04:40,320 --> 00:04:46,880
of the every release or more bar here

120
00:04:43,440 --> 00:04:49,199
and knowing the sample size of 335

121
00:04:46,880 --> 00:04:50,639
we can do some arithmetic and deduce

122
00:04:49,199 --> 00:04:52,560
that the 95

123
00:04:50,639 --> 00:04:54,000
confidence limit for the proportion in

124
00:04:52,560 --> 00:04:57,360
the wider world

125
00:04:54,000 --> 00:04:59,440
is 49 percent or

126
00:04:57,360 --> 00:05:00,479
translating that back into normal speech

127
00:04:59,440 --> 00:05:03,840
we can say

128
00:05:00,479 --> 00:05:05,440
if as seems reasonable our sample is

129
00:05:03,840 --> 00:05:07,599
representative

130
00:05:05,440 --> 00:05:10,320
then probably less than half of

131
00:05:07,600 --> 00:05:14,720
successful android developers use

132
00:05:10,320 --> 00:05:14,719
any assurance techniques regularly

133
00:05:17,199 --> 00:05:21,120
we wondered for the respondents using

134
00:05:19,840 --> 00:05:23,679
just a few techniques

135
00:05:21,120 --> 00:05:25,680
which ones they were using so we looked

136
00:05:23,680 --> 00:05:28,080
at the 50 or so who were using just two

137
00:05:25,680 --> 00:05:30,400
techniques and we found this

138
00:05:28,080 --> 00:05:33,440
we see they're doing the automatic code

139
00:05:30,400 --> 00:05:36,560
review and automatic library scan most

140
00:05:33,440 --> 00:05:37,199
with some code review as well that

141
00:05:36,560 --> 00:05:39,680
suggests

142
00:05:37,199 --> 00:05:41,360
that it's developers driving the

143
00:05:39,680 --> 00:05:43,120
adoption themselves

144
00:05:41,360 --> 00:05:46,479
as experts would have had them doing

145
00:05:43,120 --> 00:05:46,479
threat assessments too

146
00:05:47,280 --> 00:05:50,400
but the results do show that the impetus

147
00:05:50,080 --> 00:05:53,599
for

148
00:05:50,400 --> 00:05:56,318
security and privacy is coming bottom up

149
00:05:53,600 --> 00:05:59,759
from the developers rather than top down

150
00:05:56,319 --> 00:05:59,759
from customers or management

151
00:06:00,080 --> 00:06:04,000
nor are the changes being driven by gdpr

152
00:06:02,720 --> 00:06:05,840
either

153
00:06:04,000 --> 00:06:07,440
most of the gdpr changes have been

154
00:06:05,840 --> 00:06:08,719
cosmetic

155
00:06:07,440 --> 00:06:10,639
that may well have been the correct

156
00:06:08,720 --> 00:06:12,960
thing to do for any given app

157
00:06:10,639 --> 00:06:15,120
but it still suggests that gdpr hasn't

158
00:06:12,960 --> 00:06:17,599
made much difference to app security and

159
00:06:15,120 --> 00:06:19,520
privacy

160
00:06:17,600 --> 00:06:21,919
now let's move on to more beefy

161
00:06:19,520 --> 00:06:25,520
statistics and the relationships between

162
00:06:21,919 --> 00:06:28,000
the answers in the survey data

163
00:06:25,520 --> 00:06:29,198
statistics is at its best finding linear

164
00:06:28,000 --> 00:06:32,560
relationships

165
00:06:29,199 --> 00:06:34,400
that's called regression or correlation

166
00:06:32,560 --> 00:06:36,800
of course in real life you don't often

167
00:06:34,400 --> 00:06:37,280
get nice variables ready lined up for

168
00:06:36,800 --> 00:06:38,560
you

169
00:06:37,280 --> 00:06:41,198
and you have to construct them from

170
00:06:38,560 --> 00:06:42,639
other things so here's how we munged the

171
00:06:41,199 --> 00:06:44,479
answers to the questions

172
00:06:42,639 --> 00:06:46,160
to get scores that we thought might turn

173
00:06:44,479 --> 00:06:49,039
out to have a linear relationship to

174
00:06:46,160 --> 00:06:49,840
each other in accordance with best

175
00:06:49,039 --> 00:06:52,080
practice

176
00:06:49,840 --> 00:06:52,880
we defined those scores and made our

177
00:06:52,080 --> 00:06:57,039
predictions

178
00:06:52,880 --> 00:06:57,039
before we did the main survey

179
00:06:57,360 --> 00:07:02,400
this shows the correlations arrows go

180
00:07:00,160 --> 00:07:04,479
from probable causes to effects

181
00:07:02,400 --> 00:07:06,479
with assurance technique used as both a

182
00:07:04,479 --> 00:07:08,800
cause and effect

183
00:07:06,479 --> 00:07:11,360
reassuringly we found correlations

184
00:07:08,800 --> 00:07:13,840
between almost everything we expected

185
00:07:11,360 --> 00:07:15,520
except that developer security knowledge

186
00:07:13,840 --> 00:07:17,758
didn't appear to be correlated with

187
00:07:15,520 --> 00:07:19,520
frequent security updates

188
00:07:17,759 --> 00:07:22,000
when you think about it that sort of

189
00:07:19,520 --> 00:07:23,440
makes sense

190
00:07:22,000 --> 00:07:25,680
of course you can get good looking

191
00:07:23,440 --> 00:07:27,680
results from extremely ropey data

192
00:07:25,680 --> 00:07:29,360
so as responsible researchers we went

193
00:07:27,680 --> 00:07:30,720
back and plotted the data to see that it

194
00:07:29,360 --> 00:07:32,479
looked okay

195
00:07:30,720 --> 00:07:34,160
here's a couple of examples showing how

196
00:07:32,479 --> 00:07:35,359
the use of assurance techniques and the

197
00:07:34,160 --> 00:07:38,400
update frequency

198
00:07:35,360 --> 00:07:40,400
depend on the security requirements as

199
00:07:38,400 --> 00:07:44,479
you see it does look more or less linear

200
00:07:40,400 --> 00:07:46,560
then we check for outliers

201
00:07:44,479 --> 00:07:48,639
and finally the bit you've all been

202
00:07:46,560 --> 00:07:52,400
waiting for featuring software

203
00:07:48,639 --> 00:07:55,599
binary analysis on actual code

204
00:07:52,400 --> 00:07:57,599
we and here i mean ben herman use three

205
00:07:55,599 --> 00:07:58,960
tool chains to analyze the downloaded

206
00:07:57,599 --> 00:08:02,000
apps

207
00:07:58,960 --> 00:08:04,560
flow droid finds possibly harmful data

208
00:08:02,000 --> 00:08:07,759
flows leading to privacy leaks

209
00:08:04,560 --> 00:08:11,199
cognocrypt looks for cryptographic api

210
00:08:07,759 --> 00:08:14,240
misuse and for https

211
00:08:11,199 --> 00:08:15,360
maladroid checks certificate validation

212
00:08:14,240 --> 00:08:17,360
and we also check the server

213
00:08:15,360 --> 00:08:19,520
configurations for each link using the

214
00:08:17,360 --> 00:08:22,160
opel framework

215
00:08:19,520 --> 00:08:23,120
as the chart shows 40 of the apps we

216
00:08:22,160 --> 00:08:25,520
tested had no

217
00:08:23,120 --> 00:08:27,440
issues from any of the tools and roughly

218
00:08:25,520 --> 00:08:30,719
equal proportions had one two and three

219
00:08:27,440 --> 00:08:30,719
tools highlighting issues

220
00:08:31,360 --> 00:08:35,519
as everyone knows tools like this report

221
00:08:33,519 --> 00:08:37,679
lots of false positives

222
00:08:35,519 --> 00:08:39,039
our approach was to assume that reported

223
00:08:37,679 --> 00:08:40,958
issue counts will correlate with the

224
00:08:39,039 --> 00:08:43,199
numbers of true vulnerabilities

225
00:08:40,958 --> 00:08:46,640
and so the counts are a proxy for those

226
00:08:43,200 --> 00:08:46,640
aspects of app security

227
00:08:47,279 --> 00:08:51,040
again the values we get needs some

228
00:08:49,360 --> 00:08:52,640
munging to get something that we might

229
00:08:51,040 --> 00:08:55,120
expect to vary linearly

230
00:08:52,640 --> 00:08:57,600
with the other measurements in fact the

231
00:08:55,120 --> 00:08:59,440
counts have a poisson distribution

232
00:08:57,600 --> 00:09:01,680
so to get something linear we take the

233
00:08:59,440 --> 00:09:03,040
log and we want a value that gets bigger

234
00:09:01,680 --> 00:09:07,359
with bigger security

235
00:09:03,040 --> 00:09:11,120
so we use minus the log and um

236
00:09:07,360 --> 00:09:13,200
yeah we found one correlation and it was

237
00:09:11,120 --> 00:09:14,880
backwards

238
00:09:13,200 --> 00:09:16,720
we found the lack of correlation a bit

239
00:09:14,880 --> 00:09:18,399
disappointing but concluded

240
00:09:16,720 --> 00:09:20,320
it's because the analysis tools aren't

241
00:09:18,399 --> 00:09:22,320
yet very sophisticated

242
00:09:20,320 --> 00:09:24,080
they can't for example distinguish

243
00:09:22,320 --> 00:09:26,959
between problems in developer code

244
00:09:24,080 --> 00:09:28,000
and problems in libraries and sadly they

245
00:09:26,959 --> 00:09:30,719
can't detect libraries with

246
00:09:28,000 --> 00:09:32,959
vulnerabilities either

247
00:09:30,720 --> 00:09:34,160
but looking at the one result we did get

248
00:09:32,959 --> 00:09:36,160
the backwards one

249
00:09:34,160 --> 00:09:37,519
we found having security experts or

250
00:09:36,160 --> 00:09:41,360
champions involved gave

251
00:09:37,519 --> 00:09:42,880
worse crypto scores we suspect it's

252
00:09:41,360 --> 00:09:43,440
because we don't have a way to detect

253
00:09:42,880 --> 00:09:46,399
crypto

254
00:09:43,440 --> 00:09:48,480
not being used when it should if

255
00:09:46,399 --> 00:09:50,399
security experts correctly encourage

256
00:09:48,480 --> 00:09:51,920
much more crypto use

257
00:09:50,399 --> 00:09:53,680
you'll see exactly the effect we

258
00:09:51,920 --> 00:09:56,160
detected

259
00:09:53,680 --> 00:09:57,040
that's of course the security paradox

260
00:09:56,160 --> 00:10:01,360
only those who

261
00:09:57,040 --> 00:10:04,480
only those who do stuff get problems

262
00:10:01,360 --> 00:10:06,160
finally to summarize here are all the

263
00:10:04,480 --> 00:10:09,519
important survey results

264
00:10:06,160 --> 00:10:09,519
in six bullet points

265
00:10:09,839 --> 00:10:13,120
we conclude there's a great deal of work

266
00:10:11,920 --> 00:10:18,880
to be done to help

267
00:10:13,120 --> 00:10:22,640
android developers to do better security

268
00:10:18,880 --> 00:10:24,399
and finally our thank yous credit to

269
00:10:22,640 --> 00:10:26,319
chris who did all the google play

270
00:10:24,399 --> 00:10:29,360
scraping and management

271
00:10:26,320 --> 00:10:31,040
dominic started the statistics analysis

272
00:10:29,360 --> 00:10:33,040
and did some of the images i've used in

273
00:10:31,040 --> 00:10:35,199
this presentation

274
00:10:33,040 --> 00:10:38,480
both qualified as authors but chose not

275
00:10:35,200 --> 00:10:41,440
to be so i'm giving them credit here

276
00:10:38,480 --> 00:10:43,600
tamara reviewed the survey yasmin

277
00:10:41,440 --> 00:10:45,760
advised on the survey process

278
00:10:43,600 --> 00:10:48,320
thomas inspired the proper use of

279
00:10:45,760 --> 00:10:50,880
statistics with predictions

280
00:10:48,320 --> 00:10:53,519
and ian advised on the statistical

281
00:10:50,880 --> 00:10:53,519
analysis

282
00:10:53,760 --> 00:11:01,839
and now it's over to you and i'll be

283
00:10:56,480 --> 00:11:01,839
happy to answer questions

284
00:11:10,000 --> 00:11:12,079
you

