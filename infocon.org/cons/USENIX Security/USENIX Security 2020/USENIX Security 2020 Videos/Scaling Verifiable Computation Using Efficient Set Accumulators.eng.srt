1
00:00:08,960 --> 00:00:11,040
hi

2
00:00:09,280 --> 00:00:12,320
my name is alex ozdemir and today i'm

3
00:00:11,040 --> 00:00:13,678
going to tell you about some work that i

4
00:00:12,320 --> 00:00:16,000
did with ryadwabi

5
00:00:13,679 --> 00:00:17,760
barry whitehat and dan bonnay on how

6
00:00:16,000 --> 00:00:18,480
efficient set accumulators can be used

7
00:00:17,760 --> 00:00:21,119
to improve

8
00:00:18,480 --> 00:00:21,920
verifiable computation the core problem

9
00:00:21,119 --> 00:00:24,000
that we focus on

10
00:00:21,920 --> 00:00:25,039
is verifiable storage the idea is to

11
00:00:24,000 --> 00:00:27,279
take a large storage

12
00:00:25,039 --> 00:00:28,480
such as an array or a set and represent

13
00:00:27,279 --> 00:00:30,880
it with a small digest

14
00:00:28,480 --> 00:00:32,320
in a way that allows operations over the

15
00:00:30,880 --> 00:00:35,360
storage to be verified

16
00:00:32,320 --> 00:00:35,920
given access only to the digest this is

17
00:00:35,360 --> 00:00:37,839
useful

18
00:00:35,920 --> 00:00:39,360
in approver verifier setting you start

19
00:00:37,840 --> 00:00:41,360
by computing the digest

20
00:00:39,360 --> 00:00:43,200
give the prover the full storage and as

21
00:00:41,360 --> 00:00:45,120
the prover performs operations over the

22
00:00:43,200 --> 00:00:46,640
storage it sends a transcript and some

23
00:00:45,120 --> 00:00:48,160
proof material to the verifier

24
00:00:46,640 --> 00:00:50,399
so that the verifier can check that the

25
00:00:48,160 --> 00:00:51,919
operations are being done correctly

26
00:00:50,399 --> 00:00:53,760
in the case that the provers operations

27
00:00:51,920 --> 00:00:55,120
change the storage it sends the new

28
00:00:53,760 --> 00:00:56,960
digest to the verifier

29
00:00:55,120 --> 00:00:58,959
so that the verifier can verify the new

30
00:00:56,960 --> 00:01:00,800
digest accurately reflects the updated

31
00:00:58,960 --> 00:01:02,800
state of the storage

32
00:01:00,800 --> 00:01:03,919
in this picture there are different

33
00:01:02,800 --> 00:01:05,438
proofs and different verification

34
00:01:03,920 --> 00:01:06,560
procedures but you also might imagine

35
00:01:05,438 --> 00:01:10,000
wanting to batch them

36
00:01:06,560 --> 00:01:11,600
and verify all the operations at once

37
00:01:10,000 --> 00:01:13,119
verifiable storage is useful inside

38
00:01:11,600 --> 00:01:13,839
verifiable outsourcing if you want to

39
00:01:13,119 --> 00:01:15,280
outsource

40
00:01:13,840 --> 00:01:16,640
a procedure that manipulates a large

41
00:01:15,280 --> 00:01:18,880
storage then you're going to need a

42
00:01:16,640 --> 00:01:20,720
verifiable storage technique

43
00:01:18,880 --> 00:01:22,720
and such procedures are important for

44
00:01:20,720 --> 00:01:25,520
example you might imagine a procedure

45
00:01:22,720 --> 00:01:27,360
that executes a transaction it removes

46
00:01:25,520 --> 00:01:28,560
some money from one person's account and

47
00:01:27,360 --> 00:01:29,439
adds that money to another person's

48
00:01:28,560 --> 00:01:31,520
account

49
00:01:29,439 --> 00:01:33,039
such a procedure would be manipulating

50
00:01:31,520 --> 00:01:35,439
the account balances

51
00:01:33,040 --> 00:01:38,960
in this system and the account balances

52
00:01:35,439 --> 00:01:40,720
are probably a large storage

53
00:01:38,960 --> 00:01:42,320
ultimately a verifiable storage system

54
00:01:40,720 --> 00:01:44,240
is defined by the digests

55
00:01:42,320 --> 00:01:46,639
and by the way that verification is done

56
00:01:44,240 --> 00:01:48,079
that is by the verify procedures

57
00:01:46,640 --> 00:01:50,000
and if the goal is sufficient

58
00:01:48,079 --> 00:01:51,439
verification then what you want is you

59
00:01:50,000 --> 00:01:53,680
want these verification procedures to be

60
00:01:51,439 --> 00:01:55,119
as fast as possible

61
00:01:53,680 --> 00:01:56,240
over the course of the rest of this talk

62
00:01:55,119 --> 00:01:57,280
i'm going to tell you about two

63
00:01:56,240 --> 00:01:59,360
different solutions

64
00:01:57,280 --> 00:02:01,119
to the verifiable storage problem the

65
00:01:59,360 --> 00:02:02,719
existing one is merkle trees this

66
00:02:01,119 --> 00:02:04,479
solution has been widely implemented and

67
00:02:02,719 --> 00:02:06,559
is used in prominent systems like the

68
00:02:04,479 --> 00:02:08,560
zcash cryptocurrency

69
00:02:06,560 --> 00:02:09,920
another solution is rsa accumulators

70
00:02:08,560 --> 00:02:10,640
which have not been implemented as

71
00:02:09,919 --> 00:02:12,238
widely

72
00:02:10,639 --> 00:02:14,079
but have recently seen some theoretical

73
00:02:12,239 --> 00:02:15,680
developments that make them promising

74
00:02:14,080 --> 00:02:17,200
and they are the impetus for our work

75
00:02:15,680 --> 00:02:17,840
which is actually implementing rsa

76
00:02:17,200 --> 00:02:19,359
accumulators

77
00:02:17,840 --> 00:02:21,440
including these new techniques and

78
00:02:19,360 --> 00:02:23,280
demonstrating that they are and some

79
00:02:21,440 --> 00:02:25,599
many situations cheaper than merkle

80
00:02:23,280 --> 00:02:25,599
trees

81
00:02:25,680 --> 00:02:29,120
of course cheaper isn't well defined

82
00:02:27,280 --> 00:02:31,040
until i tell you the computational model

83
00:02:29,120 --> 00:02:33,200
and our computational model is in here

84
00:02:31,040 --> 00:02:34,799
inherited from verifiable outsourcing

85
00:02:33,200 --> 00:02:36,399
it is the arithmetic constraint

86
00:02:34,800 --> 00:02:39,120
computational model which we

87
00:02:36,400 --> 00:02:40,879
colloquially refer to as constraints in

88
00:02:39,120 --> 00:02:42,560
this model data is represented as

89
00:02:40,879 --> 00:02:44,640
elements from a large finite field

90
00:02:42,560 --> 00:02:46,640
you can think of this as the integers

91
00:02:44,640 --> 00:02:49,040
modulo a large prime

92
00:02:46,640 --> 00:02:50,879
and constraints such as those enforced

93
00:02:49,040 --> 00:02:53,200
by the verification procedures

94
00:02:50,879 --> 00:02:55,120
are expressed as equations over sums and

95
00:02:53,200 --> 00:02:56,319
products in this field

96
00:02:55,120 --> 00:02:57,680
with an additional requirement that

97
00:02:56,319 --> 00:02:58,799
there's only one multiplication per

98
00:02:57,680 --> 00:03:00,159
constraint

99
00:02:58,800 --> 00:03:02,319
of course the goal here you know the

100
00:03:00,159 --> 00:03:05,040
notion of cheapness is reducing

101
00:03:02,319 --> 00:03:06,319
the number of constraints one asset that

102
00:03:05,040 --> 00:03:07,920
we have is that this is inside the

103
00:03:06,319 --> 00:03:09,040
prover verifier setting so the prover

104
00:03:07,920 --> 00:03:10,640
can provide advice

105
00:03:09,040 --> 00:03:12,959
and this is often cheaper than computing

106
00:03:10,640 --> 00:03:14,399
things directly for example if what we

107
00:03:12,959 --> 00:03:15,599
want is the inverse of a field element

108
00:03:14,400 --> 00:03:16,800
computing this directly

109
00:03:15,599 --> 00:03:20,000
via something like fermat's little

110
00:03:16,800 --> 00:03:22,400
theorem would require many constraints

111
00:03:20,000 --> 00:03:23,200
but if the verifier just gives us the

112
00:03:22,400 --> 00:03:25,280
inverse

113
00:03:23,200 --> 00:03:28,159
then we can check that it is correct in

114
00:03:25,280 --> 00:03:28,159
a single constraint

115
00:03:28,799 --> 00:03:32,640
let's talk now about merkle trees which

116
00:03:30,720 --> 00:03:34,959
are the existing solution to verify law

117
00:03:32,640 --> 00:03:36,480
storage so the idea of a merkle tree is

118
00:03:34,959 --> 00:03:38,239
to build on a hash function that takes

119
00:03:36,480 --> 00:03:40,879
two inputs and produces a single output

120
00:03:38,239 --> 00:03:43,120
and this is done by arranging the hash

121
00:03:40,879 --> 00:03:45,120
function into a tree of hash evaluations

122
00:03:43,120 --> 00:03:47,280
and using this to summarize the leaves

123
00:03:45,120 --> 00:03:50,319
the storage with a single digest

124
00:03:47,280 --> 00:03:52,400
the root once this is done proofs

125
00:03:50,319 --> 00:03:53,599
over the underlying storage end up being

126
00:03:52,400 --> 00:03:56,080
paths from

127
00:03:53,599 --> 00:03:57,119
the root to the element being looked at

128
00:03:56,080 --> 00:04:00,159
or manipulated

129
00:03:57,120 --> 00:04:02,159
for example if one wants to access x3

130
00:04:00,159 --> 00:04:03,760
then one would provide the circled hash

131
00:04:02,159 --> 00:04:05,280
values and the verifier just has to

132
00:04:03,760 --> 00:04:07,840
check that all the hash evaluations

133
00:04:05,280 --> 00:04:09,599
along the path are correct

134
00:04:07,840 --> 00:04:11,280
storage proofs are similar and so

135
00:04:09,599 --> 00:04:13,280
ultimately verification cost

136
00:04:11,280 --> 00:04:14,319
for such a system ends up looking like k

137
00:04:13,280 --> 00:04:16,399
log m or k

138
00:04:14,319 --> 00:04:17,759
is the number of updates the logarithmic

139
00:04:16,399 --> 00:04:18,880
factor comes from the fact that there's

140
00:04:17,759 --> 00:04:21,199
a binary tree

141
00:04:18,880 --> 00:04:22,639
and the multiplicative factor of k comes

142
00:04:21,199 --> 00:04:24,080
from the fact that to the best of our

143
00:04:22,639 --> 00:04:27,440
knowledge there's not

144
00:04:24,080 --> 00:04:29,599
a meaningfully better way of aggregating

145
00:04:27,440 --> 00:04:31,199
the proofs over a merkle tree

146
00:04:29,600 --> 00:04:34,240
essentially one just has to

147
00:04:31,199 --> 00:04:36,000
pay for each proof individually

148
00:04:34,240 --> 00:04:38,000
this lack of ability to aggregate and

149
00:04:36,000 --> 00:04:39,440
the dependence on m are undesirable

150
00:04:38,000 --> 00:04:41,919
and rsa accumulators at least

151
00:04:39,440 --> 00:04:44,000
theoretically offer us an alternative

152
00:04:41,919 --> 00:04:45,599
rsa accumulators are based on rsa groups

153
00:04:44,000 --> 00:04:46,400
which is a group of integers under

154
00:04:45,600 --> 00:04:48,960
multiplication

155
00:04:46,400 --> 00:04:50,320
modulo p times q where p and q are large

156
00:04:48,960 --> 00:04:52,000
unknown primes

157
00:04:50,320 --> 00:04:53,440
rsa groups have an interesting property

158
00:04:52,000 --> 00:04:54,160
which is that it's hard to compute roots

159
00:04:53,440 --> 00:04:56,960
in them

160
00:04:54,160 --> 00:04:58,479
so it's hard to compute x to the root

161
00:04:56,960 --> 00:05:00,960
sorry it's hard to compute the nth root

162
00:04:58,479 --> 00:05:03,440
of x but it's easy to compute x to the n

163
00:05:00,960 --> 00:05:05,280
and this asymmetry suggests a strategy

164
00:05:03,440 --> 00:05:06,800
for digesting a large set

165
00:05:05,280 --> 00:05:08,719
which is to take the whole set and in

166
00:05:06,800 --> 00:05:10,800
some sense put it in the exponent

167
00:05:08,720 --> 00:05:13,120
of some expression and that is exactly

168
00:05:10,800 --> 00:05:13,759
how the digest of an rsa accumulator is

169
00:05:13,120 --> 00:05:15,680
defined

170
00:05:13,759 --> 00:05:17,039
the digest is defined to be some

171
00:05:15,680 --> 00:05:18,880
generator g

172
00:05:17,039 --> 00:05:20,960
raised to the power of the product of

173
00:05:18,880 --> 00:05:22,800
hashes of all the elements

174
00:05:20,960 --> 00:05:24,799
here the hash function maps elements in

175
00:05:22,800 --> 00:05:26,560
the set to numbers

176
00:05:24,800 --> 00:05:28,960
and it has to have a special property

177
00:05:26,560 --> 00:05:30,639
that we'll talk about later

178
00:05:28,960 --> 00:05:32,880
when digests are defined in this way

179
00:05:30,639 --> 00:05:34,240
proofs of insertion and removal are easy

180
00:05:32,880 --> 00:05:36,159
an insertion proof is just an

181
00:05:34,240 --> 00:05:38,160
exponentiation you check that the old

182
00:05:36,160 --> 00:05:39,840
digest raised to the power of the hash

183
00:05:38,160 --> 00:05:41,120
of the inserted element produces the new

184
00:05:39,840 --> 00:05:43,440
digest

185
00:05:41,120 --> 00:05:45,199
removal proofs are just this in reverse

186
00:05:43,440 --> 00:05:45,759
and a membership proof is just removal

187
00:05:45,199 --> 00:05:47,120
proof

188
00:05:45,759 --> 00:05:48,880
if you can remove an element then you

189
00:05:47,120 --> 00:05:50,800
know it was there

190
00:05:48,880 --> 00:05:52,320
all these proofs end up having a

191
00:05:50,800 --> 00:05:53,919
soundness property that flows

192
00:05:52,320 --> 00:05:55,680
from the fact that computing roots is

193
00:05:53,919 --> 00:05:57,440
hard

194
00:05:55,680 --> 00:05:59,600
essentially since computing roots is

195
00:05:57,440 --> 00:06:01,520
hard the only way to remove an element

196
00:05:59,600 --> 00:06:02,479
from the set and produce the desired

197
00:06:01,520 --> 00:06:04,000
route

198
00:06:02,479 --> 00:06:05,199
for the verification relation is to

199
00:06:04,000 --> 00:06:08,000
actually remove the element and

200
00:06:05,199 --> 00:06:09,840
recompute the digest

201
00:06:08,000 --> 00:06:11,600
a final property of rsa accumulator

202
00:06:09,840 --> 00:06:13,119
proofs that was recently discovered and

203
00:06:11,600 --> 00:06:15,199
is extremely exciting

204
00:06:13,120 --> 00:06:16,880
is the fact that batching them requires

205
00:06:15,199 --> 00:06:18,720
only a single explanation

206
00:06:16,880 --> 00:06:20,000
exponentiation let me spell that out in

207
00:06:18,720 --> 00:06:21,759
more detail

208
00:06:20,000 --> 00:06:23,280
if you want to do k different operations

209
00:06:21,759 --> 00:06:24,479
for example k insertions then you have

210
00:06:23,280 --> 00:06:26,400
to do k different hashes in the

211
00:06:24,479 --> 00:06:26,880
verification procedure but you only have

212
00:06:26,400 --> 00:06:29,280
to do

213
00:06:26,880 --> 00:06:31,440
one exponentiation and this

214
00:06:29,280 --> 00:06:34,159
asymptotically is much better

215
00:06:31,440 --> 00:06:35,680
than merkle trees because of two things

216
00:06:34,160 --> 00:06:37,759
first of all the dependence on

217
00:06:35,680 --> 00:06:39,120
m the size of the set has been removed

218
00:06:37,759 --> 00:06:40,160
and second of all the most expensive

219
00:06:39,120 --> 00:06:41,360
part of the verification the

220
00:06:40,160 --> 00:06:43,360
exponentiation

221
00:06:41,360 --> 00:06:45,039
is independent of k the size of the

222
00:06:43,360 --> 00:06:46,800
batch

223
00:06:45,039 --> 00:06:49,440
so rsa accumulator proofs are

224
00:06:46,800 --> 00:06:50,880
asymptotically better than merkel trees

225
00:06:49,440 --> 00:06:52,479
but this does not mean that rsa

226
00:06:50,880 --> 00:06:53,919
accumulators are concretely better

227
00:06:52,479 --> 00:06:55,599
and that was the point of our work to

228
00:06:53,919 --> 00:06:57,120
actually implement them and find out

229
00:06:55,599 --> 00:06:58,560
whether they require fewer constraints

230
00:06:57,120 --> 00:07:01,120
than merkle trees

231
00:06:58,560 --> 00:07:02,160
in the course of doing this we came up

232
00:07:01,120 --> 00:07:04,240
with a number of techniques

233
00:07:02,160 --> 00:07:05,840
and tricks um and what i'll do now is

234
00:07:04,240 --> 00:07:07,199
tell you about just one of them that i

235
00:07:05,840 --> 00:07:08,799
think you might find interesting

236
00:07:07,199 --> 00:07:10,400
which is the way that we constructed a

237
00:07:08,800 --> 00:07:11,840
hash function to prime numbers which was

238
00:07:10,400 --> 00:07:14,960
required for the batching

239
00:07:11,840 --> 00:07:16,479
algorithm of rsa accumulators

240
00:07:14,960 --> 00:07:18,080
so the traditional approach for hashing

241
00:07:16,479 --> 00:07:19,919
to prime numbers is essentially

242
00:07:18,080 --> 00:07:21,919
rejection sampling of primes

243
00:07:19,919 --> 00:07:23,440
which what this means is that if you're

244
00:07:21,919 --> 00:07:24,880
taking some input x and you want to hash

245
00:07:23,440 --> 00:07:27,520
it to a prime number then you use

246
00:07:24,880 --> 00:07:29,520
x as the seed to a prg and while the

247
00:07:27,520 --> 00:07:30,880
prg's output is composite you keep on

248
00:07:29,520 --> 00:07:32,880
advancing the prg

249
00:07:30,880 --> 00:07:34,719
eventually you come up with and return a

250
00:07:32,880 --> 00:07:36,479
prime number

251
00:07:34,720 --> 00:07:38,160
the critical step here is the test of

252
00:07:36,479 --> 00:07:40,639
primality which traditionally is the

253
00:07:38,160 --> 00:07:42,479
miller rabbin primality test

254
00:07:40,639 --> 00:07:44,720
importantly this is a probabilistic

255
00:07:42,479 --> 00:07:47,199
primality test in order to achieve

256
00:07:44,720 --> 00:07:47,840
two to the negative lambda soundness it

257
00:07:47,199 --> 00:07:50,800
has to

258
00:07:47,840 --> 00:07:52,960
do order lambda rounds of the test each

259
00:07:50,800 --> 00:07:55,680
round being an order lambda bit

260
00:07:52,960 --> 00:07:57,039
exponentiation and since exponentiations

261
00:07:55,680 --> 00:07:58,160
end up being pretty expensive in

262
00:07:57,039 --> 00:08:00,000
constraints

263
00:07:58,160 --> 00:08:01,520
this is a rather expensive way of

264
00:08:00,000 --> 00:08:04,720
hashing to a prime

265
00:08:01,520 --> 00:08:06,400
and so we pursue an alternate strategy

266
00:08:04,720 --> 00:08:08,560
our strategy is based on something

267
00:08:06,400 --> 00:08:09,919
called pockington's criterion which is a

268
00:08:08,560 --> 00:08:13,039
number theoretic statement

269
00:08:09,919 --> 00:08:15,198
that says that if p is a prime and n

270
00:08:13,039 --> 00:08:16,400
is a number less than p such that some

271
00:08:15,199 --> 00:08:17,440
number of theoretical conditions are

272
00:08:16,400 --> 00:08:20,560
satisfied

273
00:08:17,440 --> 00:08:22,639
then n times p plus one is also prime

274
00:08:20,560 --> 00:08:24,080
and when you look at this criterion from

275
00:08:22,639 --> 00:08:24,400
the thousand-foot perspective what you

276
00:08:24,080 --> 00:08:27,440
see

277
00:08:24,400 --> 00:08:28,318
is that it converts a prime p into

278
00:08:27,440 --> 00:08:31,360
another prime

279
00:08:28,319 --> 00:08:31,840
that can be up to twice as wide as p and

280
00:08:31,360 --> 00:08:34,080
this

281
00:08:31,840 --> 00:08:35,838
suggests that pockington's criterion can

282
00:08:34,080 --> 00:08:37,039
be used as the basis or rather the

283
00:08:35,839 --> 00:08:39,440
recursive step

284
00:08:37,039 --> 00:08:40,880
for a recursive primality step

285
00:08:39,440 --> 00:08:42,479
certificate

286
00:08:40,880 --> 00:08:44,959
and ensuring this suggests that one

287
00:08:42,479 --> 00:08:46,240
could do rejection sampling not of

288
00:08:44,959 --> 00:08:48,160
primes but rather of

289
00:08:46,240 --> 00:08:49,680
valid prime certificates and that is

290
00:08:48,160 --> 00:08:50,640
exactly what we do in our implementation

291
00:08:49,680 --> 00:08:52,719
of hash to prime

292
00:08:50,640 --> 00:08:54,080
we start with some base primality test

293
00:08:52,720 --> 00:08:56,080
and generation procedure

294
00:08:54,080 --> 00:08:57,760
and then we recursively enlarge the

295
00:08:56,080 --> 00:08:58,560
produced prime using pocklington's

296
00:08:57,760 --> 00:09:00,880
criterion

297
00:08:58,560 --> 00:09:02,319
until we get a prime with enough entropy

298
00:09:00,880 --> 00:09:04,000
for our purposes

299
00:09:02,320 --> 00:09:06,240
at every step in the process we use

300
00:09:04,000 --> 00:09:06,560
prg-based rejection sampling both for

301
00:09:06,240 --> 00:09:09,920
the

302
00:09:06,560 --> 00:09:11,920
base case and for the n values of each

303
00:09:09,920 --> 00:09:14,640
recursive step

304
00:09:11,920 --> 00:09:15,199
ultimately this results in a prime that

305
00:09:14,640 --> 00:09:17,600
is one

306
00:09:15,200 --> 00:09:19,120
provably prime and two much cheaper to

307
00:09:17,600 --> 00:09:23,120
verify

308
00:09:19,120 --> 00:09:25,200
than executing miller robin

309
00:09:23,120 --> 00:09:26,800
this is of course not the only technique

310
00:09:25,200 --> 00:09:30,399
that we employ

311
00:09:26,800 --> 00:09:32,000
just a few other highlights we provide a

312
00:09:30,399 --> 00:09:33,360
good implementation of multi-processing

313
00:09:32,000 --> 00:09:35,120
arithmetic in terms of constraints

314
00:09:33,360 --> 00:09:35,680
that's based on the techniques of xj

315
00:09:35,120 --> 00:09:38,560
snark

316
00:09:35,680 --> 00:09:39,920
and also includes some new techniques of

317
00:09:38,560 --> 00:09:42,560
our own

318
00:09:39,920 --> 00:09:44,399
we also require a hash function for the

319
00:09:42,560 --> 00:09:47,680
rsa accumulator that is something called

320
00:09:44,399 --> 00:09:49,279
division intractable and we construct a

321
00:09:47,680 --> 00:09:51,199
new hash function that we conjecture to

322
00:09:49,279 --> 00:09:53,360
have this property

323
00:09:51,200 --> 00:09:54,800
and then we additionally consider the

324
00:09:53,360 --> 00:09:57,360
semantics of batching

325
00:09:54,800 --> 00:09:58,000
dependent storage accesses so for

326
00:09:57,360 --> 00:09:59,839
example

327
00:09:58,000 --> 00:10:01,519
you could imagine one storage operation

328
00:09:59,839 --> 00:10:02,480
in which you replace a five with a seven

329
00:10:01,519 --> 00:10:04,480
and then another one

330
00:10:02,480 --> 00:10:06,959
where you come along and replace that

331
00:10:04,480 --> 00:10:08,560
seven with an 11.

332
00:10:06,959 --> 00:10:10,160
and the question is begged what is the

333
00:10:08,560 --> 00:10:12,479
semantics of putting these two

334
00:10:10,160 --> 00:10:14,719
operations into the same batch

335
00:10:12,480 --> 00:10:16,480
we precisely describe these semantics

336
00:10:14,720 --> 00:10:18,000
and show that they are in some sense

337
00:10:16,480 --> 00:10:19,680
exactly what a reasonable

338
00:10:18,000 --> 00:10:22,800
application would want with of course

339
00:10:19,680 --> 00:10:25,199
the details of this being in the paper

340
00:10:22,800 --> 00:10:27,120
this these techniques enable us to

341
00:10:25,200 --> 00:10:29,680
actually do an implementation of rsa

342
00:10:27,120 --> 00:10:31,600
accumulators this implementation is done

343
00:10:29,680 --> 00:10:33,680
inside bellman which is a rust library

344
00:10:31,600 --> 00:10:35,680
based on the gras 16 proof system

345
00:10:33,680 --> 00:10:37,120
we consider storages of varying size we

346
00:10:35,680 --> 00:10:38,000
perform varying number of memory

347
00:10:37,120 --> 00:10:39,839
operations

348
00:10:38,000 --> 00:10:42,079
and we measure the number of constraints

349
00:10:39,839 --> 00:10:43,760
required by the merkle trees and by an

350
00:10:42,079 --> 00:10:46,000
rsa accumulator

351
00:10:43,760 --> 00:10:47,760
we find that indeed rsa accumulators are

352
00:10:46,000 --> 00:10:50,560
concretely better in terms of number

353
00:10:47,760 --> 00:10:51,279
of constraints than workable trees at

354
00:10:50,560 --> 00:10:54,000
reasonably

355
00:10:51,279 --> 00:10:54,399
large accumulator sizes and reasonably

356
00:10:54,000 --> 00:10:57,200
large

357
00:10:54,399 --> 00:10:58,160
numbers of swaps as a note we also

358
00:10:57,200 --> 00:10:59,519
measure

359
00:10:58,160 --> 00:11:01,360
or at least make some measurements of

360
00:10:59,519 --> 00:11:03,519
proving time in the paper

361
00:11:01,360 --> 00:11:04,880
but proving time is more complex and

362
00:11:03,519 --> 00:11:06,000
there are some problems there for rsa

363
00:11:04,880 --> 00:11:07,600
accumulators

364
00:11:06,000 --> 00:11:08,800
the details of course are in the paper

365
00:11:07,600 --> 00:11:11,360
and we think there's room for a lot of

366
00:11:08,800 --> 00:11:13,599
future work here

367
00:11:11,360 --> 00:11:14,880
okay so ultimately in conclusion our

368
00:11:13,600 --> 00:11:17,120
research question was whether

369
00:11:14,880 --> 00:11:18,480
rsa accumulators use fewer constraints

370
00:11:17,120 --> 00:11:19,600
than merkel trees

371
00:11:18,480 --> 00:11:21,839
in answering this question we

372
00:11:19,600 --> 00:11:23,279
implemented rsa accumulators employing a

373
00:11:21,839 --> 00:11:24,480
number of interesting techniques

374
00:11:23,279 --> 00:11:26,000
summarized here

375
00:11:24,480 --> 00:11:27,519
and ultimately we answered the research

376
00:11:26,000 --> 00:11:29,440
question in the affirmative

377
00:11:27,519 --> 00:11:30,800
rsa accumulators do require fewer

378
00:11:29,440 --> 00:11:32,800
constraints than merkel trees

379
00:11:30,800 --> 00:11:35,359
for reasonably large accumulators and

380
00:11:32,800 --> 00:11:36,719
reasonably large numbers of operations

381
00:11:35,360 --> 00:11:38,480
our implementation is public you can

382
00:11:36,720 --> 00:11:39,920
find it at the url there we encourage

383
00:11:38,480 --> 00:11:40,720
you to play around with it or build on

384
00:11:39,920 --> 00:11:42,399
it

385
00:11:40,720 --> 00:11:44,720
and i'd like to take these final seconds

386
00:11:42,399 --> 00:11:45,360
to thank first my collaborators who made

387
00:11:44,720 --> 00:11:47,360
this project

388
00:11:45,360 --> 00:11:48,880
a real joy to work on and also the

389
00:11:47,360 --> 00:11:50,240
audience i hope that you got something

390
00:11:48,880 --> 00:11:52,079
interesting out of this talk

391
00:11:50,240 --> 00:11:57,839
and i understand there will be a q a so

392
00:11:52,079 --> 00:11:57,839
i look forward to your questions

393
00:12:03,600 --> 00:12:05,680
you

