1
00:00:09,120 --> 00:00:11,919
hello everyone

2
00:00:10,160 --> 00:00:14,400
i'm jaishan from the university of

3
00:00:11,920 --> 00:00:16,160
waterloo i would like to present chapron

4
00:00:14,400 --> 00:00:17,440
real-time locking and loss prevention

5
00:00:16,160 --> 00:00:19,359
for smartphones

6
00:00:17,440 --> 00:00:21,279
this is a joint work with dr erskine

7
00:00:19,359 --> 00:00:24,640
gartner dr hassan khan

8
00:00:21,279 --> 00:00:26,560
and dr mohammad mannan smartphone loss

9
00:00:24,640 --> 00:00:29,359
is not rare in people's daily life

10
00:00:26,560 --> 00:00:31,359
in 2018 it was reported that about 23

11
00:00:29,359 --> 00:00:32,480
thousand android devices were being lost

12
00:00:31,359 --> 00:00:34,399
every month

13
00:00:32,479 --> 00:00:36,800
smartphones are also the most commonly

14
00:00:34,399 --> 00:00:39,520
lost item in uber lost and phone

15
00:00:36,800 --> 00:00:41,120
index a smartphone loss will result in

16
00:00:39,520 --> 00:00:43,280
both property and data loss

17
00:00:41,120 --> 00:00:45,120
it also brings much inconvenience since

18
00:00:43,280 --> 00:00:47,280
the smartphone is usually connected with

19
00:00:45,120 --> 00:00:48,959
many online services

20
00:00:47,280 --> 00:00:50,320
firmware device is common solution to

21
00:00:48,960 --> 00:00:52,719
recover a lost

22
00:00:50,320 --> 00:00:54,079
smartphone but they highly relies on the

23
00:00:52,719 --> 00:00:55,840
network connection

24
00:00:54,079 --> 00:00:58,239
they can be easily bypassed by turning

25
00:00:55,840 --> 00:00:59,600
on the airplay mode and moreover it is a

26
00:00:58,239 --> 00:01:01,839
supposed loss solution

27
00:00:59,600 --> 00:01:03,280
that takes effect only after the owner

28
00:01:01,840 --> 00:01:08,080
realizes the

29
00:01:03,280 --> 00:01:10,400
loss so we prefer a prevention solution

30
00:01:08,080 --> 00:01:12,000
many existing prevention solutions rely

31
00:01:10,400 --> 00:01:14,320
on an extra bluetooth

32
00:01:12,000 --> 00:01:15,280
device which can detect if the owner is

33
00:01:14,320 --> 00:01:17,600
too far away

34
00:01:15,280 --> 00:01:19,280
based on the received signal strength

35
00:01:17,600 --> 00:01:21,759
another kind of solution is to use a

36
00:01:19,280 --> 00:01:23,360
special camera to sense the surroundings

37
00:01:21,759 --> 00:01:25,360
for all these solutions a common

38
00:01:23,360 --> 00:01:27,840
limitation is that they require

39
00:01:25,360 --> 00:01:29,840
additional hardware what we need is a

40
00:01:27,840 --> 00:01:32,240
standalone solution for most commercial

41
00:01:29,840 --> 00:01:34,320
off-the-shelf devices

42
00:01:32,240 --> 00:01:35,600
since all smartphones have at least one

43
00:01:34,320 --> 00:01:37,360
microfinance speaker

44
00:01:35,600 --> 00:01:39,520
a potential standalone solution is to

45
00:01:37,360 --> 00:01:41,680
use active acoustic sensing

46
00:01:39,520 --> 00:01:43,759
the basic idea is to send an acoustic

47
00:01:41,680 --> 00:01:44,159
signal and assess its echo reflect by

48
00:01:43,759 --> 00:01:46,720
the

49
00:01:44,159 --> 00:01:47,920
target and we we can calculate the

50
00:01:46,720 --> 00:01:50,399
distance based on time

51
00:01:47,920 --> 00:01:52,159
flight i lock uses to measure the

52
00:01:50,399 --> 00:01:54,880
distance between owner and the phone

53
00:01:52,159 --> 00:01:56,479
and if the distance exceeds a certain

54
00:01:54,880 --> 00:01:59,119
threshold it automatically

55
00:01:56,479 --> 00:02:01,039
locks the phone however environmental

56
00:01:59,119 --> 00:02:02,799
factors may affect acoustic sensing and

57
00:02:01,040 --> 00:02:05,520
make it hard to extract the

58
00:02:02,799 --> 00:02:07,439
echoes reflect by the owner also the

59
00:02:05,520 --> 00:02:08,000
detection range of the acoustic sensing

60
00:02:07,439 --> 00:02:10,399
is limited

61
00:02:08,000 --> 00:02:11,520
by the surroundings which makes distance

62
00:02:10,399 --> 00:02:15,680
based solutions

63
00:02:11,520 --> 00:02:18,080
varying practice so we propose chaperone

64
00:02:15,680 --> 00:02:19,520
a real-time time a real-time smartphone

65
00:02:18,080 --> 00:02:22,400
loss prevention solution

66
00:02:19,520 --> 00:02:24,640
based on active acoustic sensing instead

67
00:02:22,400 --> 00:02:26,480
of relying on distance measurement

68
00:02:24,640 --> 00:02:27,920
chaperone detects the owner's departure

69
00:02:26,480 --> 00:02:29,280
pattern to capture a potential

70
00:02:27,920 --> 00:02:31,040
smartphone loss

71
00:02:29,280 --> 00:02:32,720
the design of chapron handles the

72
00:02:31,040 --> 00:02:33,840
environmental factors to ensure the

73
00:02:32,720 --> 00:02:36,160
robustness over

74
00:02:33,840 --> 00:02:37,200
complicated real-world scenarios we

75
00:02:36,160 --> 00:02:40,720
conducted more than

76
00:02:37,200 --> 00:02:41,599
1 300 experiments to evaluate the

77
00:02:40,720 --> 00:02:44,000
chaperone

78
00:02:41,599 --> 00:02:46,720
in addition we also did a user study to

79
00:02:44,000 --> 00:02:48,879
collect the perception of feedback

80
00:02:46,720 --> 00:02:50,080
for the threat model chaperone defends

81
00:02:48,879 --> 00:02:52,319
against the nearby

82
00:02:50,080 --> 00:02:54,239
optimistic attackers an attacker can

83
00:02:52,319 --> 00:02:55,920
pick up the phone within several seconds

84
00:02:54,239 --> 00:02:57,680
after the owner's absence

85
00:02:55,920 --> 00:02:59,280
it requires chaplain to detect the

86
00:02:57,680 --> 00:03:01,599
potential smartphone loss and

87
00:02:59,280 --> 00:03:02,640
alert the owner before it happens we

88
00:03:01,599 --> 00:03:05,040
also mix

89
00:03:02,640 --> 00:03:07,119
some assumptions first to connect the

90
00:03:05,040 --> 00:03:08,640
aqueous sensing microphones and speakers

91
00:03:07,120 --> 00:03:09,440
of a smartphone should not be fully

92
00:03:08,640 --> 00:03:11,760
covered

93
00:03:09,440 --> 00:03:13,840
second our algorithm assumes the closest

94
00:03:11,760 --> 00:03:18,640
person as the owner to initiate

95
00:03:13,840 --> 00:03:21,360
our user tracking process

96
00:03:18,640 --> 00:03:22,958
as mentioned uh in the previous slides

97
00:03:21,360 --> 00:03:25,200
the main chain comes from the

98
00:03:22,959 --> 00:03:26,799
environment factors the first chinese is

99
00:03:25,200 --> 00:03:29,040
a high frequency noise

100
00:03:26,799 --> 00:03:30,959
chaperone uses an inaudible acoustic

101
00:03:29,040 --> 00:03:33,440
signal which is resistant to

102
00:03:30,959 --> 00:03:35,440
audible noise like people chatting

103
00:03:33,440 --> 00:03:36,159
however high frequency noise that shares

104
00:03:35,440 --> 00:03:38,480
a similar

105
00:03:36,159 --> 00:03:39,280
frequency band may interfere with this

106
00:03:38,480 --> 00:03:41,280
signal

107
00:03:39,280 --> 00:03:43,120
in the right example when the coffee

108
00:03:41,280 --> 00:03:45,440
machine is working it produces

109
00:03:43,120 --> 00:03:47,920
high frequency noise that disturbs the

110
00:03:45,440 --> 00:03:49,519
acoustic sensing

111
00:03:47,920 --> 00:03:52,238
the second challenge is the nearby

112
00:03:49,519 --> 00:03:54,560
people while conducting acoustic sensing

113
00:03:52,239 --> 00:03:55,760
a phone may receive reflect signals from

114
00:03:54,560 --> 00:03:58,080
people nearby

115
00:03:55,760 --> 00:03:59,280
due to the hardware limits it is very

116
00:03:58,080 --> 00:04:00,879
hard to use the building

117
00:03:59,280 --> 00:04:03,120
speakers and microphones to track

118
00:04:00,879 --> 00:04:06,399
multiple people so the creep

119
00:04:03,120 --> 00:04:09,200
the critical problem here is to how to

120
00:04:06,400 --> 00:04:10,720
focus on tracking the owner the third

121
00:04:09,200 --> 00:04:12,399
chinese comes from the environmental

122
00:04:10,720 --> 00:04:15,920
layout and obstacles

123
00:04:12,400 --> 00:04:17,840
static objects can both reflect

124
00:04:15,920 --> 00:04:19,519
acoustic signal and block the signal

125
00:04:17,839 --> 00:04:22,078
transmission and in this

126
00:04:19,519 --> 00:04:24,000
example when the owner is moving away

127
00:04:22,079 --> 00:04:25,840
our blocks the accuracy signal and

128
00:04:24,000 --> 00:04:28,000
limits the detection range

129
00:04:25,840 --> 00:04:29,840
if we use a distance based solution like

130
00:04:28,000 --> 00:04:31,120
i load it is very likely to lose the

131
00:04:29,840 --> 00:04:32,799
checking of the owner

132
00:04:31,120 --> 00:04:34,479
before the distance reaches the

133
00:04:32,800 --> 00:04:36,720
threshold

134
00:04:34,479 --> 00:04:37,840
that is also why we need to detect the

135
00:04:36,720 --> 00:04:40,840
departure pattern

136
00:04:37,840 --> 00:04:42,960
instead of relying on the distance

137
00:04:40,840 --> 00:04:44,400
measurement now i will introduce the

138
00:04:42,960 --> 00:04:46,560
design of chat room

139
00:04:44,400 --> 00:04:48,159
chatroom consists of four modules

140
00:04:46,560 --> 00:04:49,600
trigger module decides whether to

141
00:04:48,160 --> 00:04:51,520
conduct accuracy signal

142
00:04:49,600 --> 00:04:53,759
other canal acoustic sensing based on

143
00:04:51,520 --> 00:04:55,198
the context to save the battery

144
00:04:53,759 --> 00:04:57,280
acoustic sensing should be triggered

145
00:04:55,199 --> 00:04:58,160
only when the contacts that satisfy two

146
00:04:57,280 --> 00:05:00,400
conditions

147
00:04:58,160 --> 00:05:01,840
first the the current location should be

148
00:05:00,400 --> 00:05:04,719
a potentially insecure

149
00:05:01,840 --> 00:05:08,638
unlike restaurant second the phone is

150
00:05:04,720 --> 00:05:10,800
supposed to be stationary and not in use

151
00:05:08,639 --> 00:05:12,000
once all conducts context conditions are

152
00:05:10,800 --> 00:05:15,600
satisfied

153
00:05:12,000 --> 00:05:17,919
acoustic sensing modules start to send

154
00:05:15,600 --> 00:05:18,720
inaudible acoustic signals through a

155
00:05:17,919 --> 00:05:20,479
speaker

156
00:05:18,720 --> 00:05:23,039
and the microphone keeps recording all

157
00:05:20,479 --> 00:05:26,479
the time we apply filters to the

158
00:05:23,039 --> 00:05:27,520
receive the audio data and and match the

159
00:05:26,479 --> 00:05:30,880
audio signals

160
00:05:27,520 --> 00:05:33,919
and then we can obtain the magnitude

161
00:05:30,880 --> 00:05:34,719
the magnitude of echoes from different

162
00:05:33,919 --> 00:05:37,840
distances

163
00:05:34,720 --> 00:05:39,600
and we call it magnitude vector as shown

164
00:05:37,840 --> 00:05:40,080
in the right curve we can see several

165
00:05:39,600 --> 00:05:42,160
peaks

166
00:05:40,080 --> 00:05:44,880
which are the echoes reflected by the

167
00:05:42,160 --> 00:05:47,840
owner or the objects

168
00:05:44,880 --> 00:05:48,400
once we combine the magnitude vectors of

169
00:05:47,840 --> 00:05:50,239
several

170
00:05:48,400 --> 00:05:52,000
sensing periods we can obtain a

171
00:05:50,240 --> 00:05:54,720
magnitude heat map and roughly

172
00:05:52,000 --> 00:05:56,639
observe the the owner's trace user

173
00:05:54,720 --> 00:05:58,560
tracking module is responsible for the

174
00:05:56,639 --> 00:06:00,639
obtaining the owner's motion state from

175
00:05:58,560 --> 00:06:03,120
this and decision making module

176
00:06:00,639 --> 00:06:06,240
determines whether it is a potential

177
00:06:03,120 --> 00:06:07,919
loss event use the trigger mode you

178
00:06:06,240 --> 00:06:10,319
first need to detect a high frequency

179
00:06:07,919 --> 00:06:12,799
noise and exclude static objects

180
00:06:10,319 --> 00:06:13,840
we can see that the average magnitude of

181
00:06:12,800 --> 00:06:16,080
a noisy frame

182
00:06:13,840 --> 00:06:16,880
is exceptionally larger than the other

183
00:06:16,080 --> 00:06:19,680
frames

184
00:06:16,880 --> 00:06:22,000
we mark these frames uh and process them

185
00:06:19,680 --> 00:06:24,400
separately from the normal frames

186
00:06:22,000 --> 00:06:26,800
to exclude static objects user tracking

187
00:06:24,400 --> 00:06:30,239
module only focuses on the dynamics

188
00:06:26,800 --> 00:06:32,880
of the magnitude vector

189
00:06:30,240 --> 00:06:34,000
it'll subject the magnitude of the

190
00:06:32,880 --> 00:06:35,680
previous frame from

191
00:06:34,000 --> 00:06:37,600
the current frame and obtain the

192
00:06:35,680 --> 00:06:39,840
absolute value of the result

193
00:06:37,600 --> 00:06:41,520
and we can obtain a differential uh

194
00:06:39,840 --> 00:06:46,000
magnitude heat map based

195
00:06:41,520 --> 00:06:48,639
with the motion trace highlighted

196
00:06:46,000 --> 00:06:49,360
to extract the owner's motion state we

197
00:06:48,639 --> 00:06:51,199
first apply

198
00:06:49,360 --> 00:06:52,560
authorized detection to obtain all

199
00:06:51,199 --> 00:06:54,960
possible echoes

200
00:06:52,560 --> 00:06:56,000
and then cluster echoes that belong to

201
00:06:54,960 --> 00:06:57,919
the same person

202
00:06:56,000 --> 00:06:59,680
to determine which kind this cluster

203
00:06:57,919 --> 00:07:01,440
belongs to the owner we

204
00:06:59,680 --> 00:07:04,080
we incorporate candidate selection

205
00:07:01,440 --> 00:07:06,960
algorithm with comment filter

206
00:07:04,080 --> 00:07:08,800
given the motion consistency the owner's

207
00:07:06,960 --> 00:07:09,440
movement is prone to keep the previous

208
00:07:08,800 --> 00:07:11,680
motions

209
00:07:09,440 --> 00:07:13,759
trend and the candidate selection

210
00:07:11,680 --> 00:07:14,319
algorithm finds the best maximum

211
00:07:13,759 --> 00:07:15,840
candidate

212
00:07:14,319 --> 00:07:17,599
based on the spree of based on the

213
00:07:15,840 --> 00:07:20,719
prediction from the common filter

214
00:07:17,599 --> 00:07:22,960
and the magnitude of each cluster

215
00:07:20,720 --> 00:07:24,560
comma filters then accept the best

216
00:07:22,960 --> 00:07:26,080
candidate and estimate the current

217
00:07:24,560 --> 00:07:28,160
distance and speed

218
00:07:26,080 --> 00:07:29,359
for the noisy frames detected in the

219
00:07:28,160 --> 00:07:31,759
previous stage

220
00:07:29,360 --> 00:07:32,720
we use the prediction to compensate the

221
00:07:31,759 --> 00:07:34,639
missing part

222
00:07:32,720 --> 00:07:36,160
and finally we can obtain the owner's

223
00:07:34,639 --> 00:07:39,919
trace like the yellow curve

224
00:07:36,160 --> 00:07:41,680
showing the figure the decision making

225
00:07:39,919 --> 00:07:43,198
module is designed to recognize the

226
00:07:41,680 --> 00:07:44,639
owner's departure pattern based on

227
00:07:43,199 --> 00:07:47,520
several factors

228
00:07:44,639 --> 00:07:49,039
it extracts the features not only from

229
00:07:47,520 --> 00:07:52,000
speed and the distance

230
00:07:49,039 --> 00:07:53,680
but also from magnitude max spectrum

231
00:07:52,000 --> 00:07:56,000
according to our observation

232
00:07:53,680 --> 00:07:57,039
magnitudes change significantly when the

233
00:07:56,000 --> 00:08:00,560
owner is leaving

234
00:07:57,039 --> 00:08:02,878
it's caused by the

235
00:08:00,560 --> 00:08:04,240
the whole body movements like standing

236
00:08:02,879 --> 00:08:06,400
up or turning around

237
00:08:04,240 --> 00:08:07,919
the features are sent to three

238
00:08:06,400 --> 00:08:11,599
classifiers to determine this

239
00:08:07,919 --> 00:08:12,080
uh leaving pattern and a device pattern

240
00:08:11,599 --> 00:08:14,400
is

241
00:08:12,080 --> 00:08:16,240
defined as the the owner continuously

242
00:08:14,400 --> 00:08:19,039
moving away from the device

243
00:08:16,240 --> 00:08:19,599
and the activity intensity change from

244
00:08:19,039 --> 00:08:22,159
the

245
00:08:19,599 --> 00:08:24,479
from intense to moderate and eventually

246
00:08:22,160 --> 00:08:26,720
the user presence classifier shows that

247
00:08:24,479 --> 00:08:28,240
the owner is no longer near the device

248
00:08:26,720 --> 00:08:29,039
and once the departure pattern is

249
00:08:28,240 --> 00:08:30,960
detected

250
00:08:29,039 --> 00:08:33,279
chatroom immediately locks the device

251
00:08:30,960 --> 00:08:36,640
and alerts the owner of a potential loss

252
00:08:33,279 --> 00:08:38,880
and this is all for the system design

253
00:08:36,640 --> 00:08:40,559
for evaluation we conducted extensive

254
00:08:38,880 --> 00:08:43,439
experiments with considering

255
00:08:40,559 --> 00:08:44,319
common interference factors and in this

256
00:08:43,440 --> 00:08:46,160
presentation

257
00:08:44,320 --> 00:08:48,480
i will focus on lab experiments and

258
00:08:46,160 --> 00:08:50,399
real-world experiments

259
00:08:48,480 --> 00:08:52,720
in the lab experiments we tested three

260
00:08:50,399 --> 00:08:55,040
departing speeds from slow to first

261
00:08:52,720 --> 00:08:56,720
and three phone orientations from

262
00:08:55,040 --> 00:09:00,560
vertical to horizontal

263
00:08:56,720 --> 00:09:03,519
in total we collected 135 departure

264
00:09:00,560 --> 00:09:04,560
uh departure events and chatroom only

265
00:09:03,519 --> 00:09:06,959
produces two

266
00:09:04,560 --> 00:09:08,399
phosphonactics when these experiments

267
00:09:06,959 --> 00:09:12,719
leave at a very fast speed

268
00:09:08,399 --> 00:09:14,640
and the phone is placed horizontally

269
00:09:12,720 --> 00:09:16,640
as for the real world experiments we

270
00:09:14,640 --> 00:09:18,959
tested each other with eight

271
00:09:16,640 --> 00:09:20,399
participants and eight common locations

272
00:09:18,959 --> 00:09:23,599
we label the data collected

273
00:09:20,399 --> 00:09:25,680
in the lab experiments and use them for

274
00:09:23,600 --> 00:09:27,360
training training the classifiers in the

275
00:09:25,680 --> 00:09:28,959
decision-making module

276
00:09:27,360 --> 00:09:31,279
the overall precision of chatroom

277
00:09:28,959 --> 00:09:34,479
reaches 93 percent while the

278
00:09:31,279 --> 00:09:35,360
record score is 96 percent for 95

279
00:09:34,480 --> 00:09:37,360
percent of

280
00:09:35,360 --> 00:09:39,440
successfully detected cases the

281
00:09:37,360 --> 00:09:41,839
detection latency is smaller than

282
00:09:39,440 --> 00:09:43,680
500 milliseconds which shows the

283
00:09:41,839 --> 00:09:46,720
chaperone can react very fast to a

284
00:09:43,680 --> 00:09:49,120
potential device loss event

285
00:09:46,720 --> 00:09:50,720
here i would like to use the bus stop

286
00:09:49,120 --> 00:09:54,640
scenario as example

287
00:09:50,720 --> 00:09:57,600
and the main interference factors here

288
00:09:54,640 --> 00:09:59,199
come from the narrow space vehicle noise

289
00:09:57,600 --> 00:10:01,760
and the people who are waiting for

290
00:09:59,200 --> 00:10:02,640
the bus chevrolet managed to detect all

291
00:10:01,760 --> 00:10:05,920
departure

292
00:10:02,640 --> 00:10:07,920
events and the position is 92 percent

293
00:10:05,920 --> 00:10:09,839
and one false positive come from the

294
00:10:07,920 --> 00:10:12,160
situation where the device is placed

295
00:10:09,839 --> 00:10:13,920
in between the experimenter and the

296
00:10:12,160 --> 00:10:18,000
stranger and the strangers

297
00:10:13,920 --> 00:10:19,680
was leaving for the bus at that moment

298
00:10:18,000 --> 00:10:21,040
to further evaluate chatroom we

299
00:10:19,680 --> 00:10:22,560
conducted a user study with

300
00:10:21,040 --> 00:10:25,360
semi-structured interview

301
00:10:22,560 --> 00:10:28,000
we asked 17 participants to use a demo

302
00:10:25,360 --> 00:10:30,640
chat room with real-time trace display

303
00:10:28,000 --> 00:10:32,320
during the interview we collect their

304
00:10:30,640 --> 00:10:34,640
perceptional feedback

305
00:10:32,320 --> 00:10:36,800
we also ask each participant to simulate

306
00:10:34,640 --> 00:10:38,640
a device loss without telling them about

307
00:10:36,800 --> 00:10:40,719
the alert ringtone

308
00:10:38,640 --> 00:10:42,319
we tested the effectiveness of the

309
00:10:40,720 --> 00:10:44,160
device loss alert based on their

310
00:10:42,320 --> 00:10:45,680
reactions

311
00:10:44,160 --> 00:10:47,519
according to the result most

312
00:10:45,680 --> 00:10:48,640
participants are satisfied with the

313
00:10:47,519 --> 00:10:50,959
overall

314
00:10:48,640 --> 00:10:52,800
effectiveness of chaperone 16

315
00:10:50,959 --> 00:10:54,800
participants reported that they heard

316
00:10:52,800 --> 00:10:56,880
the green tone on their way leading

317
00:10:54,800 --> 00:10:57,920
and using the timing and the distance of

318
00:10:56,880 --> 00:11:00,399
the alert

319
00:10:57,920 --> 00:11:01,120
is very good also many participants

320
00:11:00,399 --> 00:11:03,920
expect

321
00:11:01,120 --> 00:11:04,880
an adaptive alert scheme that applies

322
00:11:03,920 --> 00:11:08,959
different alert

323
00:11:04,880 --> 00:11:08,959
messages based on the current scenario

324
00:11:09,200 --> 00:11:12,880
this is the end of the presentation and

325
00:11:11,040 --> 00:11:13,920
we provide our source code and data

326
00:11:12,880 --> 00:11:16,399
dataset

327
00:11:13,920 --> 00:11:17,599
in this link you can also choose to scan

328
00:11:16,399 --> 00:11:29,200
the qr code

329
00:11:17,600 --> 00:11:29,200
thank you for your attention

