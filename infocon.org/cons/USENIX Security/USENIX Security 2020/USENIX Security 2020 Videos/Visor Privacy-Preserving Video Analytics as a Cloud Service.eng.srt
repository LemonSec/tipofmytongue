1
00:00:09,200 --> 00:00:12,079
hi

2
00:00:09,760 --> 00:00:13,120
i'm rushab i'm a phd candidate at uc

3
00:00:12,080 --> 00:00:14,559
berkeley

4
00:00:13,120 --> 00:00:16,400
and i'm going to tell you today about

5
00:00:14,559 --> 00:00:17,038
visa which is a system for privacy

6
00:00:16,400 --> 00:00:19,359
preserving

7
00:00:17,039 --> 00:00:21,359
video analytics in the cloud and this is

8
00:00:19,359 --> 00:00:22,560
joint work between uc berkeley and

9
00:00:21,359 --> 00:00:24,880
microsoft research

10
00:00:22,560 --> 00:00:26,720
so the success of machine learning has

11
00:00:24,880 --> 00:00:27,439
led to the emergence of a new class of

12
00:00:26,720 --> 00:00:29,279
services

13
00:00:27,439 --> 00:00:30,640
that marry it with the benefits of cloud

14
00:00:29,279 --> 00:00:32,880
computing and

15
00:00:30,640 --> 00:00:34,079
video analytics is a key application for

16
00:00:32,880 --> 00:00:36,399
such services

17
00:00:34,079 --> 00:00:38,160
for example consider a home security

18
00:00:36,399 --> 00:00:39,680
service that sends an alert to the

19
00:00:38,160 --> 00:00:41,440
customer's mobile phone

20
00:00:39,680 --> 00:00:43,680
whenever it detects movement at the

21
00:00:41,440 --> 00:00:44,879
front door or consider a traffic

22
00:00:43,680 --> 00:00:46,719
monitoring application

23
00:00:44,879 --> 00:00:48,640
that automatically changes the traffic

24
00:00:46,719 --> 00:00:50,160
lights based on the number of cars at

25
00:00:48,640 --> 00:00:52,160
the traffic intersection

26
00:00:50,160 --> 00:00:54,319
the typical architecture for such video

27
00:00:52,160 --> 00:00:55,839
analytics services is as follows

28
00:00:54,320 --> 00:00:58,000
the client source which could be a

29
00:00:55,840 --> 00:00:59,680
camera transmits the video stream

30
00:00:58,000 --> 00:01:01,520
to the service running in the cloud

31
00:00:59,680 --> 00:01:03,600
where the stream is first optionally

32
00:01:01,520 --> 00:01:04,960
pre-processed on the cpu

33
00:01:03,600 --> 00:01:06,799
while one could process the video

34
00:01:04,959 --> 00:01:08,960
directly on the gpu as well

35
00:01:06,799 --> 00:01:10,400
pre-processing on the cpu essentially

36
00:01:08,960 --> 00:01:12,399
acts as a cheap filter

37
00:01:10,400 --> 00:01:14,720
that prevents the wastage of gpu cycles

38
00:01:12,400 --> 00:01:16,799
by discarding irrelevant content

39
00:01:14,720 --> 00:01:18,400
in fact researchers have shown that such

40
00:01:16,799 --> 00:01:21,360
pre-processing can improve performance

41
00:01:18,400 --> 00:01:24,320
by up to 17 times

42
00:01:21,360 --> 00:01:26,159
and here's an example of such a pipeline

43
00:01:24,320 --> 00:01:27,758
the video stream is first decoded into a

44
00:01:26,159 --> 00:01:29,280
sequence of raw frames

45
00:01:27,759 --> 00:01:31,360
the frames are then individually

46
00:01:29,280 --> 00:01:33,680
processed to identify only the relevant

47
00:01:31,360 --> 00:01:36,000
moving objects in the foreground

48
00:01:33,680 --> 00:01:38,159
the object's bounding boxes are detected

49
00:01:36,000 --> 00:01:38,799
and only these objects are then cropped

50
00:01:38,159 --> 00:01:40,560
out

51
00:01:38,799 --> 00:01:42,560
and sent to the gpu to be processed by

52
00:01:40,560 --> 00:01:44,159
the machine learning model

53
00:01:42,560 --> 00:01:45,600
the results of the model's processing

54
00:01:44,159 --> 00:01:46,960
are then returned to the cpu

55
00:01:45,600 --> 00:01:49,600
where they can be used to power the

56
00:01:46,960 --> 00:01:51,520
application of choice

57
00:01:49,600 --> 00:01:52,960
the problem in the setting of course is

58
00:01:51,520 --> 00:01:55,280
privacy

59
00:01:52,960 --> 00:01:57,119
video streams contain a lot of sensitive

60
00:01:55,280 --> 00:01:58,960
content and we want to preserve their

61
00:01:57,119 --> 00:02:01,280
privacy from malicious attackers at the

62
00:01:58,960 --> 00:02:02,960
cloud service

63
00:02:01,280 --> 00:02:04,880
now while there hasn't directly been

64
00:02:02,960 --> 00:02:06,479
work targeting video analytics

65
00:02:04,880 --> 00:02:08,639
a variety of solutions have been

66
00:02:06,479 --> 00:02:10,959
proposed for machine learning inference

67
00:02:08,639 --> 00:02:12,319
and existing solutions to this problem

68
00:02:10,959 --> 00:02:14,000
typically fall into one of two

69
00:02:12,319 --> 00:02:15,679
categories

70
00:02:14,000 --> 00:02:17,760
the first category is to use a

71
00:02:15,680 --> 00:02:19,440
specialized cryptographic protocol

72
00:02:17,760 --> 00:02:21,280
for executing the pipeline such as

73
00:02:19,440 --> 00:02:22,560
multi-party computation or homomorphic

74
00:02:21,280 --> 00:02:24,560
encryption

75
00:02:22,560 --> 00:02:26,720
and while cryptographic protocols give

76
00:02:24,560 --> 00:02:28,480
you very nice security properties

77
00:02:26,720 --> 00:02:30,319
the problem is that they have high

78
00:02:28,480 --> 00:02:33,760
overhead and they cannot sustain the

79
00:02:30,319 --> 00:02:35,599
incoming frame rate in video streams

80
00:02:33,760 --> 00:02:37,518
the second category of solutions is

81
00:02:35,599 --> 00:02:40,640
based on the use of hardware enclaves

82
00:02:37,519 --> 00:02:42,480
such as intel sgx these solutions

83
00:02:40,640 --> 00:02:44,399
are designed for cpu on clears and

84
00:02:42,480 --> 00:02:45,119
therefore once again cannot sustain the

85
00:02:44,400 --> 00:02:47,920
frame rate

86
00:02:45,120 --> 00:02:49,200
without the use of gpus but a bigger

87
00:02:47,920 --> 00:02:51,200
problem is that

88
00:02:49,200 --> 00:02:52,720
enclaves are known to be vulnerable to

89
00:02:51,200 --> 00:02:54,480
side channel attacks

90
00:02:52,720 --> 00:02:56,640
and in particular they leaked the

91
00:02:54,480 --> 00:02:58,959
application's memory access patterns

92
00:02:56,640 --> 00:03:00,958
which is the fundamental reason behind a

93
00:02:58,959 --> 00:03:01,680
very large class of known attacks and

94
00:03:00,959 --> 00:03:04,239
enclaves

95
00:03:01,680 --> 00:03:05,760
from cache timing to branch prediction

96
00:03:04,239 --> 00:03:07,440
to page-based attacks

97
00:03:05,760 --> 00:03:09,120
and i will illustrate shortly how

98
00:03:07,440 --> 00:03:12,239
devastating this leakage can be

99
00:03:09,120 --> 00:03:12,959
for video analytics pipelines but this

100
00:03:12,239 --> 00:03:16,319
brings us

101
00:03:12,959 --> 00:03:18,879
to our work biaser visor makes

102
00:03:16,319 --> 00:03:20,640
two key contributions our first

103
00:03:18,879 --> 00:03:21,280
contribution is a privacy preserving

104
00:03:20,640 --> 00:03:23,518
framework

105
00:03:21,280 --> 00:03:25,519
for machine learning services this

106
00:03:23,519 --> 00:03:27,200
framework combines recent advances in

107
00:03:25,519 --> 00:03:30,159
gpu enclave technology

108
00:03:27,200 --> 00:03:31,679
with cpu enclaves unifying them into a

109
00:03:30,159 --> 00:03:34,959
single trust domain

110
00:03:31,680 --> 00:03:35,920
which we call a hybrid enclave within

111
00:03:34,959 --> 00:03:38,159
this framework

112
00:03:35,920 --> 00:03:39,200
we design and implement algorithms for

113
00:03:38,159 --> 00:03:41,760
video analytics

114
00:03:39,200 --> 00:03:43,359
that are data oblivious which means that

115
00:03:41,760 --> 00:03:44,879
they prevent the leakage of information

116
00:03:43,360 --> 00:03:48,400
by memory access patterns

117
00:03:44,879 --> 00:03:50,159
by design our algorithms are efficient

118
00:03:48,400 --> 00:03:51,840
and orders of magnitude faster than

119
00:03:50,159 --> 00:03:53,359
alternative solutions for achieving the

120
00:03:51,840 --> 00:03:56,000
same property

121
00:03:53,360 --> 00:03:56,400
and we also note that at a higher level

122
00:03:56,000 --> 00:03:58,959
this

123
00:03:56,400 --> 00:04:00,560
overall paradigm can be used to power

124
00:03:58,959 --> 00:04:01,120
other machine learning applications as

125
00:04:00,560 --> 00:04:04,400
well

126
00:04:01,120 --> 00:04:06,000
beyond just video analytics i will now

127
00:04:04,400 --> 00:04:08,640
provide an overview of both these

128
00:04:06,000 --> 00:04:10,879
contributions one by one

129
00:04:08,640 --> 00:04:12,480
the starting point for visor is to run

130
00:04:10,879 --> 00:04:13,200
the cpu components of the service

131
00:04:12,480 --> 00:04:15,518
pipeline

132
00:04:13,200 --> 00:04:17,279
within a cpu on clip at the cloud such

133
00:04:15,519 --> 00:04:19,040
as intel sgx

134
00:04:17,279 --> 00:04:20,320
and the client establishes a secure

135
00:04:19,040 --> 00:04:20,880
channel of communication with the

136
00:04:20,320 --> 00:04:24,080
enclave

137
00:04:20,880 --> 00:04:25,600
during remote attestation next we run

138
00:04:24,080 --> 00:04:28,080
the gpu based computation

139
00:04:25,600 --> 00:04:28,800
within a gpu on clip at the cloud and in

140
00:04:28,080 --> 00:04:30,880
particular

141
00:04:28,800 --> 00:04:32,800
we use the recent graviton enclave

142
00:04:30,880 --> 00:04:35,840
proposed by microsoft research

143
00:04:32,800 --> 00:04:37,919
at osdi in 2018.

144
00:04:35,840 --> 00:04:38,880
graphiton provides properties similar to

145
00:04:37,919 --> 00:04:40,880
sgx

146
00:04:38,880 --> 00:04:42,960
enabling software on this gpu to be

147
00:04:40,880 --> 00:04:44,639
isolated from other gpu software

148
00:04:42,960 --> 00:04:46,080
as well as privileged software on the

149
00:04:44,639 --> 00:04:48,800
host

150
00:04:46,080 --> 00:04:50,080
crucially we run the gpu runtime within

151
00:04:48,800 --> 00:04:51,680
the cpu enclave

152
00:04:50,080 --> 00:04:55,198
that allows us to combine the two

153
00:04:51,680 --> 00:04:57,520
enclaves into a unified trust domain

154
00:04:55,199 --> 00:04:59,120
in the context of video analytics this

155
00:04:57,520 --> 00:05:00,960
means that we run the pre-processing

156
00:04:59,120 --> 00:05:03,440
modules with an sgx

157
00:05:00,960 --> 00:05:05,120
and the cnn model within graviton on the

158
00:05:03,440 --> 00:05:08,320
gpu

159
00:05:05,120 --> 00:05:10,560
however simply using a hybrid enclave

160
00:05:08,320 --> 00:05:12,240
is not enough for privacy and we also

161
00:05:10,560 --> 00:05:14,240
need to systematically address the

162
00:05:12,240 --> 00:05:16,400
various sources of side channel leakage

163
00:05:14,240 --> 00:05:18,479
throughout the pipeline i will not have

164
00:05:16,400 --> 00:05:20,080
time to dive into a lot of details

165
00:05:18,479 --> 00:05:21,840
but i will describe the sources of

166
00:05:20,080 --> 00:05:25,280
leakage and how we address them

167
00:05:21,840 --> 00:05:26,960
briefly the first class of leakage

168
00:05:25,280 --> 00:05:28,880
stems from the communication channels in

169
00:05:26,960 --> 00:05:30,400
the pipeline the client of enclave

170
00:05:28,880 --> 00:05:32,320
communication over the network

171
00:05:30,400 --> 00:05:33,758
as well as the cpu gpu communication

172
00:05:32,320 --> 00:05:35,599
channel

173
00:05:33,759 --> 00:05:37,199
even though all the data flowing through

174
00:05:35,600 --> 00:05:39,039
these channels is encrypted

175
00:05:37,199 --> 00:05:40,560
researchers have shown how an adversary

176
00:05:39,039 --> 00:05:42,719
monitoring the traffic pattern

177
00:05:40,560 --> 00:05:44,080
can identify crucial information about

178
00:05:42,720 --> 00:05:46,800
the underlying video stream

179
00:05:44,080 --> 00:05:47,680
such as spikes in the activity in the

180
00:05:46,800 --> 00:05:49,840
video streams

181
00:05:47,680 --> 00:05:51,680
or the number and sizes of objects per

182
00:05:49,840 --> 00:05:54,479
frame

183
00:05:51,680 --> 00:05:56,880
to plug these leakage sources we devise

184
00:05:54,479 --> 00:05:59,360
data oblivious communication protocols

185
00:05:56,880 --> 00:06:00,400
that intelligently pad the channels with

186
00:05:59,360 --> 00:06:02,240
dummy traffic

187
00:06:00,400 --> 00:06:04,400
but in a way that optimizes the

188
00:06:02,240 --> 00:06:07,120
performance of the overall pipeline

189
00:06:04,400 --> 00:06:08,960
for example we devise a data oblivious

190
00:06:07,120 --> 00:06:10,880
producer consumer queue protocol

191
00:06:08,960 --> 00:06:13,599
for communication between the cpu and

192
00:06:10,880 --> 00:06:14,960
gpu that is designed to minimize gpu

193
00:06:13,600 --> 00:06:17,280
consumption

194
00:06:14,960 --> 00:06:18,318
and at a high level this protocol works

195
00:06:17,280 --> 00:06:20,799
as follows

196
00:06:18,319 --> 00:06:21,440
for each frame in the video the cpu

197
00:06:20,800 --> 00:06:24,160
pushes

198
00:06:21,440 --> 00:06:25,600
n1 objects into the queue some of which

199
00:06:24,160 --> 00:06:27,520
may be dummies

200
00:06:25,600 --> 00:06:28,880
in this illustration for example the

201
00:06:27,520 --> 00:06:32,080
real objects are in blue

202
00:06:28,880 --> 00:06:33,440
and the dummies are in gray the queue is

203
00:06:32,080 --> 00:06:35,440
then obliviously sorted

204
00:06:33,440 --> 00:06:37,120
so as to push the non-dummy objects to

205
00:06:35,440 --> 00:06:39,759
the tail of the queue

206
00:06:37,120 --> 00:06:40,240
and the gpu then consumes n2 objects

207
00:06:39,759 --> 00:06:42,560
whereas

208
00:06:40,240 --> 00:06:44,960
where n2 is less than n1 from the tail

209
00:06:42,560 --> 00:06:44,960
of the queue

210
00:06:45,280 --> 00:06:50,719
the process repeats for the next frame

211
00:06:47,520 --> 00:06:52,960
the cpu once again pushes an n1 object

212
00:06:50,720 --> 00:06:54,400
potentially overwriting existing objects

213
00:06:52,960 --> 00:06:56,479
at the head of the queue

214
00:06:54,400 --> 00:06:58,960
but the overwritten objects are dummies

215
00:06:56,479 --> 00:07:02,000
with a very high probability

216
00:06:58,960 --> 00:07:04,159
next the queue is sorted as before and

217
00:07:02,000 --> 00:07:05,840
the gpu consumes n2 objects from the

218
00:07:04,160 --> 00:07:07,759
tail

219
00:07:05,840 --> 00:07:09,520
in the paper we provide a more detailed

220
00:07:07,759 --> 00:07:12,240
analysis of the protocol and its

221
00:07:09,520 --> 00:07:12,240
implementation

222
00:07:13,440 --> 00:07:17,199
the next class of leakage that we tackle

223
00:07:15,520 --> 00:07:18,479
is memory access pattern leakage from

224
00:07:17,199 --> 00:07:20,639
the enclaves

225
00:07:18,479 --> 00:07:22,800
that is even though the adversary cannot

226
00:07:20,639 --> 00:07:24,800
directly see the contents of the enclave

227
00:07:22,800 --> 00:07:27,199
it can observe the sequence of memory

228
00:07:24,800 --> 00:07:28,720
addresses accessed during the program's

229
00:07:27,199 --> 00:07:31,039
execution

230
00:07:28,720 --> 00:07:32,800
and to prevent this leakage we provide a

231
00:07:31,039 --> 00:07:34,639
suite of primitives that enable the

232
00:07:32,800 --> 00:07:35,440
development of data oblivious modules of

233
00:07:34,639 --> 00:07:37,120
the cpu

234
00:07:35,440 --> 00:07:38,479
that provably prevent access pattern

235
00:07:37,120 --> 00:07:40,400
leakage by design

236
00:07:38,479 --> 00:07:43,039
as well as an oblivious cnn

237
00:07:40,400 --> 00:07:44,560
implementation on the gpu

238
00:07:43,039 --> 00:07:46,479
which brings us to our second key

239
00:07:44,560 --> 00:07:47,039
contribution and i will now give you a

240
00:07:46,479 --> 00:07:48,800
glimpse

241
00:07:47,039 --> 00:07:52,318
of how we design these oblivious

242
00:07:48,800 --> 00:07:54,319
algorithms for video analytics

243
00:07:52,319 --> 00:07:55,759
but before that to illustrate how

244
00:07:54,319 --> 00:07:57,680
devastating memory access pattern

245
00:07:55,759 --> 00:07:59,199
leakage can be for video analytics

246
00:07:57,680 --> 00:08:01,199
let's take the example of the bounding

247
00:07:59,199 --> 00:08:03,759
box detection module

248
00:08:01,199 --> 00:08:05,680
the original algorithm works as follows

249
00:08:03,759 --> 00:08:06,560
it first detects a white pixel in the

250
00:08:05,680 --> 00:08:08,960
image

251
00:08:06,560 --> 00:08:09,759
and then follows the object's border by

252
00:08:08,960 --> 00:08:11,758
examining

253
00:08:09,759 --> 00:08:13,039
the pixel's neighbors and it does so

254
00:08:11,759 --> 00:08:14,319
until all the

255
00:08:13,039 --> 00:08:16,479
different objects in the frame are

256
00:08:14,319 --> 00:08:18,560
identified

257
00:08:16,479 --> 00:08:20,159
as a result even though the attacker

258
00:08:18,560 --> 00:08:20,960
can't directly see the contents of the

259
00:08:20,160 --> 00:08:22,800
frame

260
00:08:20,960 --> 00:08:24,318
just by monitoring the addresses of

261
00:08:22,800 --> 00:08:26,240
these access pixels

262
00:08:24,319 --> 00:08:28,240
the attacker can reconstruct the shapes

263
00:08:26,240 --> 00:08:28,960
and positions of all the objects in the

264
00:08:28,240 --> 00:08:32,719
video stream

265
00:08:28,960 --> 00:08:34,640
which effectively is the entire contents

266
00:08:32,719 --> 00:08:37,279
to make this algorithm free of access

267
00:08:34,640 --> 00:08:39,279
pattern leakage our aim is to transform

268
00:08:37,279 --> 00:08:40,080
it into a pattern that performs the same

269
00:08:39,279 --> 00:08:42,399
operations

270
00:08:40,080 --> 00:08:43,200
on each pixel in the frame regardless of

271
00:08:42,399 --> 00:08:45,360
its value

272
00:08:43,200 --> 00:08:46,480
as a consequence of which no matter what

273
00:08:45,360 --> 00:08:48,320
the value of the pixels

274
00:08:46,480 --> 00:08:50,480
are the memory access patterns of the

275
00:08:48,320 --> 00:08:52,240
algorithm remain the same

276
00:08:50,480 --> 00:08:54,399
and to apply this design pattern

277
00:08:52,240 --> 00:08:56,880
efficiently to our algorithms

278
00:08:54,399 --> 00:08:57,920
we devise a general strategy based on

279
00:08:56,880 --> 00:09:00,160
the structure

280
00:08:57,920 --> 00:09:02,319
of the vision modules and i will

281
00:09:00,160 --> 00:09:03,760
illustrate the strategy at a high level

282
00:09:02,320 --> 00:09:05,760
using the bounding box detection

283
00:09:03,760 --> 00:09:08,160
algorithm while glossing over some of

284
00:09:05,760 --> 00:09:10,240
the finer details

285
00:09:08,160 --> 00:09:12,000
the first step in the strategy is to

286
00:09:10,240 --> 00:09:12,800
transform each algorithm into a

287
00:09:12,000 --> 00:09:15,200
structure

288
00:09:12,800 --> 00:09:17,120
that scans the image while identically

289
00:09:15,200 --> 00:09:19,600
processing each pixel

290
00:09:17,120 --> 00:09:20,160
for bounding box detection this we apply

291
00:09:19,600 --> 00:09:22,560
this step

292
00:09:20,160 --> 00:09:23,760
by assigning a label to each pixel

293
00:09:22,560 --> 00:09:25,439
during the scan

294
00:09:23,760 --> 00:09:27,920
and this assignment of the label is

295
00:09:25,440 --> 00:09:29,839
based on the label value of the pixel's

296
00:09:27,920 --> 00:09:32,240
neighbors

297
00:09:29,839 --> 00:09:32,880
then we make a second pass to identify

298
00:09:32,240 --> 00:09:37,360
labels

299
00:09:32,880 --> 00:09:39,040
that are connected to each other

300
00:09:37,360 --> 00:09:40,959
the second step in the strategy is to

301
00:09:39,040 --> 00:09:42,640
use a divide and conquer approach

302
00:09:40,959 --> 00:09:44,719
to further improve the performance of

303
00:09:42,640 --> 00:09:46,880
the scan based formulation

304
00:09:44,720 --> 00:09:48,240
and in this case we divide the image

305
00:09:46,880 --> 00:09:50,399
into strips

306
00:09:48,240 --> 00:09:51,680
we first identify the boxes in each

307
00:09:50,399 --> 00:09:55,200
strip separately

308
00:09:51,680 --> 00:09:58,719
in parallel and then reconcile the boxes

309
00:09:55,200 --> 00:10:01,120
at the boundaries of the strips

310
00:09:58,720 --> 00:10:03,120
finally identical pixel processing

311
00:10:01,120 --> 00:10:05,440
naturally lends itself to optimization

312
00:10:03,120 --> 00:10:06,480
strategies that enable batch computation

313
00:10:05,440 --> 00:10:08,800
over pixels

314
00:10:06,480 --> 00:10:10,640
for example via the use of vectorized

315
00:10:08,800 --> 00:10:14,319
simply instructions which allow us to

316
00:10:10,640 --> 00:10:14,319
process several pixels at once

317
00:10:14,800 --> 00:10:18,560
this high level strategy enables us to

318
00:10:16,720 --> 00:10:19,920
improve performance by several orders of

319
00:10:18,560 --> 00:10:21,518
magnitude compared to ultimate

320
00:10:19,920 --> 00:10:23,599
approaches

321
00:10:21,519 --> 00:10:25,040
in the paper we also describe in detail

322
00:10:23,600 --> 00:10:26,880
how we apply the strategy

323
00:10:25,040 --> 00:10:28,719
to the other modules in the video

324
00:10:26,880 --> 00:10:30,560
analytics pipeline

325
00:10:28,720 --> 00:10:32,560
the extended version of our paper also

326
00:10:30,560 --> 00:10:35,760
contains formal proofs of security

327
00:10:32,560 --> 00:10:37,518
through each of our algorithms a quick

328
00:10:35,760 --> 00:10:40,160
summary of visor's performance

329
00:10:37,519 --> 00:10:40,880
we evaluate advisor on a six-core intel

330
00:10:40,160 --> 00:10:44,079
machine

331
00:10:40,880 --> 00:10:47,839
and an nvidia gpu with support for sgx

332
00:10:44,079 --> 00:10:50,319
and graviton enclaves in our experiments

333
00:10:47,839 --> 00:10:51,200
we used four real-world high-definition

334
00:10:50,320 --> 00:10:53,600
video streams

335
00:10:51,200 --> 00:10:54,560
that contain sensitive information and

336
00:10:53,600 --> 00:10:57,279
two different

337
00:10:54,560 --> 00:10:58,079
video analytics pipelines the pipelines

338
00:10:57,279 --> 00:11:00,560
are generic

339
00:10:58,079 --> 00:11:02,959
and include an object detector cnn as

340
00:11:00,560 --> 00:11:05,920
well and not just the classification cnn

341
00:11:02,959 --> 00:11:07,680
that i illustrated earlier

342
00:11:05,920 --> 00:11:09,920
we found that our hybrid enclave

343
00:11:07,680 --> 00:11:11,040
architecture imposed an overhead of up

344
00:11:09,920 --> 00:11:12,880
to eight times

345
00:11:11,040 --> 00:11:14,959
primarily due to the limited on claim

346
00:11:12,880 --> 00:11:17,920
memory in existing sgx machines

347
00:11:14,959 --> 00:11:18,640
which is 93.5 megabytes when the

348
00:11:17,920 --> 00:11:20,079
pipeline's

349
00:11:18,640 --> 00:11:22,319
memory footprint fits within the

350
00:11:20,079 --> 00:11:23,439
autoclave memory the overhead dropped to

351
00:11:22,320 --> 00:11:25,680
1.1 x

352
00:11:23,440 --> 00:11:27,279
and to measure this aspect we decreased

353
00:11:25,680 --> 00:11:28,000
the video's resolution and repeated the

354
00:11:27,279 --> 00:11:31,439
experiment

355
00:11:28,000 --> 00:11:33,360
as seen on the right on top of this

356
00:11:31,440 --> 00:11:35,680
the additional overhead of our oblivious

357
00:11:33,360 --> 00:11:37,519
algorithms is only 2.5 x

358
00:11:35,680 --> 00:11:39,199
which highlights the usefulness of our

359
00:11:37,519 --> 00:11:41,200
design strategy

360
00:11:39,200 --> 00:11:43,200
and in the paper we show how the

361
00:11:41,200 --> 00:11:45,519
outperformance alternative solutions

362
00:11:43,200 --> 00:11:48,640
by over six orders of magnitude for

363
00:11:45,519 --> 00:11:51,040
achieving their turbulent business

364
00:11:48,640 --> 00:11:52,160
so in summary visa makes two key

365
00:11:51,040 --> 00:11:53,760
contributions

366
00:11:52,160 --> 00:11:55,680
we present a privacy preserving

367
00:11:53,760 --> 00:11:56,399
framework for cnn based machine learning

368
00:11:55,680 --> 00:11:59,040
applications

369
00:11:56,399 --> 00:12:00,959
that span both the cpu and the gpu and

370
00:11:59,040 --> 00:12:02,079
we present novel oblivious algorithms

371
00:12:00,959 --> 00:12:04,319
for video analytics

372
00:12:02,079 --> 00:12:05,120
that are also efficient thank you for

373
00:12:04,320 --> 00:12:08,839
listening

374
00:12:05,120 --> 00:12:11,839
and now i'm happy to take questions if

375
00:12:08,839 --> 00:12:11,839
any

376
00:12:16,480 --> 00:12:18,560
you

