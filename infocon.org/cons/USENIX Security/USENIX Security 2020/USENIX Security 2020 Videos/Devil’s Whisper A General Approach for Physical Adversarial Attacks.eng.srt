1
00:00:08,000 --> 00:00:11,040
hello everyone

2
00:00:09,360 --> 00:00:12,799
today i'm happy to give you a

3
00:00:11,040 --> 00:00:15,678
presentation about our paper

4
00:00:12,799 --> 00:00:18,000
the tattoo is the devious vista a

5
00:00:15,679 --> 00:00:18,640
general approach for physical adversary

6
00:00:18,000 --> 00:00:20,560
attacks

7
00:00:18,640 --> 00:00:22,320
against the commercial black box speech

8
00:00:20,560 --> 00:00:25,198
recognition devices

9
00:00:22,320 --> 00:00:26,640
my name is chan chen and this is a

10
00:00:25,199 --> 00:00:29,679
collaborative research

11
00:00:26,640 --> 00:00:32,000
with the chinese academy of science

12
00:00:29,679 --> 00:00:32,960
florida institute of technology boston

13
00:00:32,000 --> 00:00:35,760
university

14
00:00:32,960 --> 00:00:36,320
and indiana university bloomington okay

15
00:00:35,760 --> 00:00:39,199
so

16
00:00:36,320 --> 00:00:40,320
now let's start to go to the

17
00:00:39,200 --> 00:00:43,280
presentation

18
00:00:40,320 --> 00:00:45,600
as we all know today speech recognition

19
00:00:43,280 --> 00:00:46,160
technology is widely used in our daily

20
00:00:45,600 --> 00:00:48,160
life

21
00:00:46,160 --> 00:00:51,038
for example cell phones smartphone

22
00:00:48,160 --> 00:00:53,919
devices and computers

23
00:00:51,039 --> 00:00:55,680
so uh it's it's very easy to use these

24
00:00:53,920 --> 00:00:57,360
devices to do lots of things just by

25
00:00:55,680 --> 00:00:59,920
voice for example we can

26
00:00:57,360 --> 00:01:02,480
talk to our google home to order a pizza

27
00:00:59,920 --> 00:01:04,879
to open the door or to do lots of things

28
00:01:02,480 --> 00:01:05,518
however when we enjoy the convenience of

29
00:01:04,879 --> 00:01:07,840
the

30
00:01:05,519 --> 00:01:08,960
speech recognition technology there has

31
00:01:07,840 --> 00:01:11,600
been many attacks

32
00:01:08,960 --> 00:01:13,439
towards speech systems for example

33
00:01:11,600 --> 00:01:14,559
traditional text traditional attacks

34
00:01:13,439 --> 00:01:16,320
usually

35
00:01:14,560 --> 00:01:18,400
include hardware-based attacks for

36
00:01:16,320 --> 00:01:20,479
example like stopping attack

37
00:01:18,400 --> 00:01:21,840
today there is a new type of tag called

38
00:01:20,479 --> 00:01:24,560
adversary attack

39
00:01:21,840 --> 00:01:26,080
which is based on adversary examples so

40
00:01:24,560 --> 00:01:28,720
what is adversarial example

41
00:01:26,080 --> 00:01:30,560
basically adversary example is a benign

42
00:01:28,720 --> 00:01:32,320
sample added with very small

43
00:01:30,560 --> 00:01:34,640
participants

44
00:01:32,320 --> 00:01:36,320
so this new sample can change the

45
00:01:34,640 --> 00:01:37,920
results of the machine learning model

46
00:01:36,320 --> 00:01:40,559
totally

47
00:01:37,920 --> 00:01:42,000
like if i have if i have a benign audio

48
00:01:40,560 --> 00:01:44,960
sample good morning

49
00:01:42,000 --> 00:01:46,159
after attacker at the very small noise

50
00:01:44,960 --> 00:01:48,240
onto it

51
00:01:46,159 --> 00:01:50,880
then the new sample would be recognized

52
00:01:48,240 --> 00:01:53,039
as the open door for the machining model

53
00:01:50,880 --> 00:01:54,960
however for human beings we will still

54
00:01:53,040 --> 00:01:58,479
understand it as good morning

55
00:01:54,960 --> 00:02:01,199
so this is the auto adverse example

56
00:01:58,479 --> 00:02:03,439
later in the transition i will use ae to

57
00:02:01,200 --> 00:02:08,878
refer adversary examples

58
00:02:03,439 --> 00:02:11,920
okay so in this paper what we want to do

59
00:02:08,878 --> 00:02:12,480
is to propose a method to generate audio

60
00:02:11,920 --> 00:02:14,720
ease

61
00:02:12,480 --> 00:02:16,160
for commercial blackbox speech devices

62
00:02:14,720 --> 00:02:19,120
for example

63
00:02:16,160 --> 00:02:21,040
amazon echo or google home and this

64
00:02:19,120 --> 00:02:24,480
approach needs to be general

65
00:02:21,040 --> 00:02:24,879
practical stealthy and automatic so this

66
00:02:24,480 --> 00:02:26,640
is

67
00:02:24,879 --> 00:02:28,319
why and what we want to do in this

68
00:02:26,640 --> 00:02:32,399
research okay

69
00:02:28,319 --> 00:02:34,399
next let's go into the approach

70
00:02:32,400 --> 00:02:35,680
first let's take a look at the overview

71
00:02:34,400 --> 00:02:38,720
of approach

72
00:02:35,680 --> 00:02:40,959
recall that in this paper

73
00:02:38,720 --> 00:02:42,640
our aim is the blackboard platforms

74
00:02:40,959 --> 00:02:44,400
include including the

75
00:02:42,640 --> 00:02:46,000
commercial speech apis and the

76
00:02:44,400 --> 00:02:49,760
commercial speech devices

77
00:02:46,000 --> 00:02:50,720
like amazon echo and to achieve our

78
00:02:49,760 --> 00:02:53,679
goals

79
00:02:50,720 --> 00:02:55,359
first we propose that we can use the uh

80
00:02:53,680 --> 00:02:58,239
transferability based approach

81
00:02:55,360 --> 00:02:59,280
shortly as tba approach so in tba

82
00:02:58,239 --> 00:03:02,720
approach

83
00:02:59,280 --> 00:03:04,879
we just use the uh gradient design idea

84
00:03:02,720 --> 00:03:06,640
towards the wetbox model and generate a

85
00:03:04,879 --> 00:03:09,359
bunch of aes and then

86
00:03:06,640 --> 00:03:11,839
use this is to attack blackbox devices

87
00:03:09,360 --> 00:03:14,000
use a changeability based idea

88
00:03:11,840 --> 00:03:16,000
obviously the success rate may be not

89
00:03:14,000 --> 00:03:18,319
very high because as we all know

90
00:03:16,000 --> 00:03:19,840
the wetbox model may be very different

91
00:03:18,319 --> 00:03:22,238
with the black box model

92
00:03:19,840 --> 00:03:23,440
so based on this we mainly proposed

93
00:03:22,239 --> 00:03:25,760
another idea

94
00:03:23,440 --> 00:03:26,560
called alternate model based generation

95
00:03:25,760 --> 00:03:29,760
approach

96
00:03:26,560 --> 00:03:32,319
shortly as aga so in aji method we

97
00:03:29,760 --> 00:03:34,798
normally propose that we can use

98
00:03:32,319 --> 00:03:35,440
one large base model a local large base

99
00:03:34,799 --> 00:03:38,560
model

100
00:03:35,440 --> 00:03:39,519
with one substitute model to do the

101
00:03:38,560 --> 00:03:43,200
ensemble a

102
00:03:39,519 --> 00:03:47,120
generation so for details

103
00:03:43,200 --> 00:03:49,599
now let's go to the details about this

104
00:03:47,120 --> 00:03:51,280
search oh uh first i would like to

105
00:03:49,599 --> 00:03:54,079
introduce the uh what is the

106
00:03:51,280 --> 00:03:55,040
subject model we used in this idea so

107
00:03:54,080 --> 00:03:57,920
basically

108
00:03:55,040 --> 00:04:00,798
uh substitute model is a local chain

109
00:03:57,920 --> 00:04:03,518
model to simulate the black box model

110
00:04:00,799 --> 00:04:04,400
so we need to have we need to have a

111
00:04:03,519 --> 00:04:06,319
bunch of

112
00:04:04,400 --> 00:04:08,319
audio files and the labeled battery

113
00:04:06,319 --> 00:04:09,280
target bracket model and then we use the

114
00:04:08,319 --> 00:04:12,798
audio files

115
00:04:09,280 --> 00:04:15,439
and the text label to change a local

116
00:04:12,799 --> 00:04:18,400
model to simulate the black box model

117
00:04:15,439 --> 00:04:20,959
so we we are going to use this uh

118
00:04:18,399 --> 00:04:24,239
substitute model in our idea

119
00:04:20,959 --> 00:04:27,840
okay so next is uh details

120
00:04:24,240 --> 00:04:28,960
okay recall that we are going to use the

121
00:04:27,840 --> 00:04:31,198
surface mode red

122
00:04:28,960 --> 00:04:32,719
so to trim this model first we need to

123
00:04:31,199 --> 00:04:36,400
have the tuning set

124
00:04:32,720 --> 00:04:38,320
here training set the training set is uh

125
00:04:36,400 --> 00:04:39,758
the string set is labeled by blackbox

126
00:04:38,320 --> 00:04:42,400
model and

127
00:04:39,759 --> 00:04:44,080
here we propose that we can just use the

128
00:04:42,400 --> 00:04:47,679
limited number of phrases

129
00:04:44,080 --> 00:04:50,240
because our aim is to attack

130
00:04:47,680 --> 00:04:51,919
attacking the blackwood devices so we

131
00:04:50,240 --> 00:04:54,880
are only interested in

132
00:04:51,919 --> 00:04:56,240
several phrases like open the door like

133
00:04:54,880 --> 00:05:00,000
transforming the morning like

134
00:04:56,240 --> 00:05:03,120
call number one so we can only use the

135
00:05:00,000 --> 00:05:04,160
just several number of commands and then

136
00:05:03,120 --> 00:05:06,320
we propose that

137
00:05:04,160 --> 00:05:07,840
we need to use the data argument to

138
00:05:06,320 --> 00:05:09,599
extend our training set

139
00:05:07,840 --> 00:05:11,440
because if we only use the limited

140
00:05:09,600 --> 00:05:12,720
number of phrases then the tuning set

141
00:05:11,440 --> 00:05:15,919
must be very small

142
00:05:12,720 --> 00:05:18,080
so we need to extend it in detail we are

143
00:05:15,919 --> 00:05:19,840
going to add a noise and a change voice

144
00:05:18,080 --> 00:05:22,479
speed on this data set

145
00:05:19,840 --> 00:05:23,599
oh by the way the adding noise has

146
00:05:22,479 --> 00:05:27,039
another advantage

147
00:05:23,600 --> 00:05:28,000
is that as we all know the black box

148
00:05:27,039 --> 00:05:30,719
model

149
00:05:28,000 --> 00:05:31,440
must be chained on the a lot of data set

150
00:05:30,720 --> 00:05:34,720
and must

151
00:05:31,440 --> 00:05:35,199
include the uh noise based voice like

152
00:05:34,720 --> 00:05:37,199
the

153
00:05:35,199 --> 00:05:39,680
because because the blackboard model

154
00:05:37,199 --> 00:05:42,400
must consider the real-world cases

155
00:05:39,680 --> 00:05:42,880
and in real world our voice must contain

156
00:05:42,400 --> 00:05:45,758
many

157
00:05:42,880 --> 00:05:46,479
noise so adding noise can help us to

158
00:05:45,759 --> 00:05:48,560
simulate

159
00:05:46,479 --> 00:05:49,680
the blackboard blackbox model in a

160
00:05:48,560 --> 00:05:53,039
better way

161
00:05:49,680 --> 00:05:55,280
okay so this is the chaining set however

162
00:05:53,039 --> 00:05:57,759
here we have here we have another

163
00:05:55,280 --> 00:06:00,719
question

164
00:05:57,759 --> 00:06:03,280
because our local substitute model is

165
00:06:00,720 --> 00:06:06,080
only based on a number of phrases

166
00:06:03,280 --> 00:06:08,000
so we may have the overfitting problem

167
00:06:06,080 --> 00:06:09,680
because the number of

168
00:06:08,000 --> 00:06:11,039
limited number of phrases the only

169
00:06:09,680 --> 00:06:13,039
contains several

170
00:06:11,039 --> 00:06:14,240
just a cell worm words that were

171
00:06:13,039 --> 00:06:16,560
phonemes so

172
00:06:14,240 --> 00:06:19,039
overfitting problems may exist in this

173
00:06:16,560 --> 00:06:22,000
model to overcome this problem

174
00:06:19,039 --> 00:06:23,919
we propose that we can use another

175
00:06:22,000 --> 00:06:26,400
supplemental set

176
00:06:23,919 --> 00:06:27,198
another supplement that may be uh over

177
00:06:26,400 --> 00:06:30,159
open source

178
00:06:27,199 --> 00:06:32,319
voice data for training and uh you can

179
00:06:30,160 --> 00:06:35,280
just use many online set like

180
00:06:32,319 --> 00:06:37,199
cody this set like a mini level speech

181
00:06:35,280 --> 00:06:41,359
like a wave tonight

182
00:06:37,199 --> 00:06:43,440
so by adding this large supplemental set

183
00:06:41,360 --> 00:06:44,560
we can combine our training set with

184
00:06:43,440 --> 00:06:47,600
supplemental set

185
00:06:44,560 --> 00:06:51,039
together change our services

186
00:06:47,600 --> 00:06:53,360
model so by doing this hopefully we can

187
00:06:51,039 --> 00:06:56,719
solve overfitting problems

188
00:06:53,360 --> 00:06:59,360
but here we have another question

189
00:06:56,720 --> 00:07:01,440
because our substitute model is going to

190
00:06:59,360 --> 00:07:02,080
simulate the blackbox model like a

191
00:07:01,440 --> 00:07:04,240
google

192
00:07:02,080 --> 00:07:05,680
model like amazon echo but as we all

193
00:07:04,240 --> 00:07:08,720
know the google model

194
00:07:05,680 --> 00:07:09,840
of amazon echo is based on the very

195
00:07:08,720 --> 00:07:12,880
large dataset

196
00:07:09,840 --> 00:07:15,119
so our local substance model is

197
00:07:12,880 --> 00:07:16,639
is very difficult to simulate the

198
00:07:15,120 --> 00:07:19,759
blackboard mode because

199
00:07:16,639 --> 00:07:21,360
this model would be very small model i

200
00:07:19,759 --> 00:07:24,560
mean compared with the

201
00:07:21,360 --> 00:07:27,120
target vectors mode like google model so

202
00:07:24,560 --> 00:07:28,560
here we propose that we can use another

203
00:07:27,120 --> 00:07:31,599
large base model

204
00:07:28,560 --> 00:07:35,120
to help our local substitute model

205
00:07:31,599 --> 00:07:38,080
to do the insane generation

206
00:07:35,120 --> 00:07:40,000
this large-based model is already asl

207
00:07:38,080 --> 00:07:42,240
mode like called the svr model

208
00:07:40,000 --> 00:07:44,319
then by doing this way we can use a

209
00:07:42,240 --> 00:07:46,479
large base model with a

210
00:07:44,319 --> 00:07:48,000
substitute model to do adversary sample

211
00:07:46,479 --> 00:07:51,440
in sample generation

212
00:07:48,000 --> 00:07:55,280
to overcome the small model issue okay

213
00:07:51,440 --> 00:07:59,199
so this is a high level idea

214
00:07:55,280 --> 00:08:01,919
when we generate let me generate our aes

215
00:07:59,199 --> 00:08:05,599
we use the momentum-based iterative fast

216
00:08:01,919 --> 00:08:08,240
reading method called mifgm method

217
00:08:05,599 --> 00:08:09,360
specifically we use the song of music as

218
00:08:08,240 --> 00:08:13,120
our original song

219
00:08:09,360 --> 00:08:14,800
as our career and we use the pdf id

220
00:08:13,120 --> 00:08:17,520
sequence matching method

221
00:08:14,800 --> 00:08:18,000
which was used in commander some methods

222
00:08:17,520 --> 00:08:20,318
but

223
00:08:18,000 --> 00:08:21,599
different with commander song here we

224
00:08:20,319 --> 00:08:24,160
use the moon thumb beast

225
00:08:21,599 --> 00:08:24,960
idea to improve the transferability and

226
00:08:24,160 --> 00:08:26,960
this

227
00:08:24,960 --> 00:08:29,758
was not used in command some paper i

228
00:08:26,960 --> 00:08:30,878
think okay so this is the details in the

229
00:08:29,759 --> 00:08:34,399
generation

230
00:08:30,879 --> 00:08:37,279
process next

231
00:08:34,399 --> 00:08:39,679
let's see uh how we can understand our

232
00:08:37,279 --> 00:08:41,838
attack and why it can be successful

233
00:08:39,679 --> 00:08:43,439
so first recall that we have a large

234
00:08:41,839 --> 00:08:44,240
business model that this large base

235
00:08:43,440 --> 00:08:47,440
model

236
00:08:44,240 --> 00:08:49,760
is tuned on the very large data set so

237
00:08:47,440 --> 00:08:51,680
basically it can generate our speech

238
00:08:49,760 --> 00:08:54,800
features in a course screen manner

239
00:08:51,680 --> 00:08:57,040
and then our local chain the

240
00:08:54,800 --> 00:08:57,839
substitute model can fine-tune the

241
00:08:57,040 --> 00:09:00,079
features

242
00:08:57,839 --> 00:09:00,880
to attack to attack blackbox mode

243
00:09:00,080 --> 00:09:03,440
because

244
00:09:00,880 --> 00:09:04,800
uh this substitutional model is for

245
00:09:03,440 --> 00:09:07,839
simulating the blackroom

246
00:09:04,800 --> 00:09:10,240
levels model red okay here i have his

247
00:09:07,839 --> 00:09:12,320
example and this example is a real real

248
00:09:10,240 --> 00:09:14,640
example in our experiments

249
00:09:12,320 --> 00:09:16,320
uh the target command is generification

250
00:09:14,640 --> 00:09:19,040
and as we can see

251
00:09:16,320 --> 00:09:19,440
in this modal engineering first it can

252
00:09:19,040 --> 00:09:21,920
be

253
00:09:19,440 --> 00:09:23,120
recognized as the lyrics of the music

254
00:09:21,920 --> 00:09:25,199
and then

255
00:09:23,120 --> 00:09:27,040
after several of iterations it can be

256
00:09:25,200 --> 00:09:29,040
recognized items then

257
00:09:27,040 --> 00:09:30,160
in the substitute model a generation

258
00:09:29,040 --> 00:09:32,480
process it will

259
00:09:30,160 --> 00:09:33,839
be recognized notification and after a

260
00:09:32,480 --> 00:09:35,760
bunch of iterations

261
00:09:33,839 --> 00:09:38,000
it would be it would be recognized as

262
00:09:35,760 --> 00:09:40,399
clear notification so we can say

263
00:09:38,000 --> 00:09:41,360
step by step from the base model

264
00:09:40,399 --> 00:09:43,440
initiation

265
00:09:41,360 --> 00:09:45,920
to substitute model generation from a

266
00:09:43,440 --> 00:09:48,839
constant manner to fine-grained manner

267
00:09:45,920 --> 00:09:50,479
okay so this is the understanding of our

268
00:09:48,839 --> 00:09:54,160
attack

269
00:09:50,480 --> 00:09:57,040
then let's see the resource evaluations

270
00:09:54,160 --> 00:09:58,399
first is the device attack effectiveness

271
00:09:57,040 --> 00:10:01,199
we can see that

272
00:09:58,399 --> 00:10:02,240
for our proposed eg method for the

273
00:10:01,200 --> 00:10:05,040
google assistant

274
00:10:02,240 --> 00:10:05,760
google home microsoft cortana amazon

275
00:10:05,040 --> 00:10:08,399
echo and

276
00:10:05,760 --> 00:10:09,519
abm web to air we can achieve very high

277
00:10:08,399 --> 00:10:11,839
success rate

278
00:10:09,519 --> 00:10:12,800
and notice that our effective distance

279
00:10:11,839 --> 00:10:15,360
is from the

280
00:10:12,800 --> 00:10:15,920
thousand meters to two meters which

281
00:10:15,360 --> 00:10:18,160
means that

282
00:10:15,920 --> 00:10:19,760
our attack is very effective in real

283
00:10:18,160 --> 00:10:22,880
world distance

284
00:10:19,760 --> 00:10:25,040
and we also did the robustness test

285
00:10:22,880 --> 00:10:27,439
which means that we played our

286
00:10:25,040 --> 00:10:29,839
adversarial sample for 30 times

287
00:10:27,440 --> 00:10:30,480
and we want to see how many times can

288
00:10:29,839 --> 00:10:33,440
this

289
00:10:30,480 --> 00:10:35,200
can be successful all tests are under

290
00:10:33,440 --> 00:10:36,959
the sim test environment the same

291
00:10:35,200 --> 00:10:37,760
distance the sim prediction the sim

292
00:10:36,959 --> 00:10:41,599
devices

293
00:10:37,760 --> 00:10:44,399
and we can see that uh over 70

294
00:10:41,600 --> 00:10:45,680
76 of our commands you can achieve 10

295
00:10:44,399 --> 00:10:48,000
successful cases

296
00:10:45,680 --> 00:10:48,880
over 32 to playing tests which means

297
00:10:48,000 --> 00:10:52,240
that our

298
00:10:48,880 --> 00:10:55,680
attack is a very successful and issue

299
00:10:52,240 --> 00:10:57,040
strong robustness in real world okay

300
00:10:55,680 --> 00:10:59,439
we also did the human perception

301
00:10:57,040 --> 00:11:00,240
evaluations on amazon survey we can see

302
00:10:59,440 --> 00:11:02,240
that uh

303
00:11:00,240 --> 00:11:03,920
84 percent of users listening to the

304
00:11:02,240 --> 00:11:04,240
sample something like normal speech or

305
00:11:03,920 --> 00:11:07,680
just

306
00:11:04,240 --> 00:11:09,920
noise and only one one 1.4

307
00:11:07,680 --> 00:11:11,760
percent of users they could tell fifty

308
00:11:09,920 --> 00:11:13,599
percent of words in the target commands

309
00:11:11,760 --> 00:11:14,800
which means that our human perception

310
00:11:13,600 --> 00:11:19,200
test is very good

311
00:11:14,800 --> 00:11:21,760
and our adversary sample is dlc enough

312
00:11:19,200 --> 00:11:22,320
we also did evaluations on other simple

313
00:11:21,760 --> 00:11:25,360
approaches

314
00:11:22,320 --> 00:11:27,200
for example what if we just mix

315
00:11:25,360 --> 00:11:28,399
the music and commands together use

316
00:11:27,200 --> 00:11:30,160
adobe software

317
00:11:28,399 --> 00:11:32,399
and compared with devil's whisper

318
00:11:30,160 --> 00:11:35,040
approach we can see that under similar

319
00:11:32,399 --> 00:11:37,519
success rate with devil's whisper

320
00:11:35,040 --> 00:11:38,079
this support will have a very bad human

321
00:11:37,519 --> 00:11:41,279
perception

322
00:11:38,079 --> 00:11:42,959
loss only six six percent of users

323
00:11:41,279 --> 00:11:44,880
using the some samples something like

324
00:11:42,959 --> 00:11:47,599
normal speech or just noise

325
00:11:44,880 --> 00:11:48,320
this means that our whisper is very

326
00:11:47,600 --> 00:11:51,120
effective

327
00:11:48,320 --> 00:11:52,079
compared with other simple approaches

328
00:11:51,120 --> 00:11:55,279
okay

329
00:11:52,079 --> 00:11:56,160
next is a conclusion this is a final

330
00:11:55,279 --> 00:11:58,320
part

331
00:11:56,160 --> 00:12:00,000
in this paper we propose the first

332
00:11:58,320 --> 00:12:01,519
adverse attack against the commercial

333
00:12:00,000 --> 00:12:03,920
specific devices such as

334
00:12:01,519 --> 00:12:05,839
amazon echo google home and we can

335
00:12:03,920 --> 00:12:10,000
overcome the black holes challenges

336
00:12:05,839 --> 00:12:10,720
and this is uh towards speech system and

337
00:12:10,000 --> 00:12:12,480
this is

338
00:12:10,720 --> 00:12:13,760
more complicated rather than image

339
00:12:12,480 --> 00:12:16,160
system our

340
00:12:13,760 --> 00:12:17,600
our attack is effective and still see

341
00:12:16,160 --> 00:12:20,160
and uh

342
00:12:17,600 --> 00:12:21,200
and this is a normal idea to do the

343
00:12:20,160 --> 00:12:24,399
model in symbol

344
00:12:21,200 --> 00:12:26,480
generation okay so it's a conclusion

345
00:12:24,399 --> 00:12:27,440
and uh thank you for your journey and

346
00:12:26,480 --> 00:12:29,839
hearing

347
00:12:27,440 --> 00:12:31,279
and if you have any questions please

348
00:12:29,839 --> 00:12:39,839
feel free to ask

349
00:12:31,279 --> 00:12:39,839
in the next section okay thank you

350
00:12:42,880 --> 00:12:44,959
you

