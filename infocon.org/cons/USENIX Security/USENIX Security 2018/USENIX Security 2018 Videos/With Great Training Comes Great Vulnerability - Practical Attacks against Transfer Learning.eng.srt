1
00:00:10,970 --> 00:00:16,219
welcome<font color="#E5E5E5"> everyone to my talk and my name</font>

2
00:00:13,760 --> 00:00:18,170
is<font color="#E5E5E5"> Bolin and I'm here to talk</font><font color="#CCCCCC"> about deep</font>

3
00:00:16,219 --> 00:00:20,000
learning<font color="#E5E5E5"> and in</font><font color="#CCCCCC"> particular transfer</font>

4
00:00:18,170 --> 00:00:23,029
<font color="#E5E5E5">money so this work is</font><font color="#CCCCCC"> a collaboration</font>

5
00:00:20,000 --> 00:00:25,490
with<font color="#E5E5E5"> my colleagues and</font><font color="#CCCCCC"> advisors from UC</font>

6
00:00:23,029 --> 00:00:28,880
Santa Barbara<font color="#E5E5E5"> Chicago and also Virginia</font>

7
00:00:25,490 --> 00:00:31,189
Tech right so deep learning<font color="#E5E5E5"> has shown</font>

8
00:00:28,880 --> 00:00:33,710
some really<font color="#CCCCCC"> impressive improvements in</font>

9
00:00:31,189 --> 00:00:35,840
the past few<font color="#CCCCCC"> years we have</font><font color="#E5E5E5"> self-driving</font>

10
00:00:33,710 --> 00:00:37,940
cars we have very good<font color="#E5E5E5"> face recognition</font>

11
00:00:35,840 --> 00:00:40,309
models we have<font color="#CCCCCC"> language translation</font>

12
00:00:37,940 --> 00:00:43,280
models but all of those<font color="#E5E5E5"> are only</font>

13
00:00:40,309 --> 00:00:46,190
possible<font color="#CCCCCC"> because of</font><font color="#E5E5E5"> data because</font><font color="#CCCCCC"> we</font><font color="#E5E5E5"> have</font>

14
00:00:43,280 --> 00:00:48,440
large<font color="#E5E5E5"> label data</font><font color="#CCCCCC"> sets</font><font color="#E5E5E5"> I'll give you one</font>

15
00:00:46,190 --> 00:00:50,870
example<font color="#CCCCCC"> so image net so this is a very</font>

16
00:00:48,440 --> 00:00:53,329
popular benchmark test<font color="#CCCCCC"> in the vision</font>

17
00:00:50,870 --> 00:00:55,699
domain and the data set used to<font color="#E5E5E5"> train</font>

18
00:00:53,329 --> 00:00:58,940
<font color="#CCCCCC">our models for</font><font color="#E5E5E5"> image net contains over</font>

19
00:00:55,699 --> 00:01:01,309
<font color="#E5E5E5">14 million images right now so this is</font>

20
00:00:58,940 --> 00:01:04,399
<font color="#CCCCCC">the amount</font><font color="#E5E5E5"> of data we need to</font><font color="#CCCCCC"> train</font><font color="#E5E5E5"> high</font>

21
00:01:01,309 --> 00:01:06,619
<font color="#E5E5E5">quality</font><font color="#CCCCCC"> deploying models so as you can</font>

22
00:01:04,399 --> 00:01:09,020
<font color="#E5E5E5">imagine if we want wider adoption of</font>

23
00:01:06,619 --> 00:01:11,300
deep learning if<font color="#E5E5E5"> we want everyone normal</font>

24
00:01:09,020 --> 00:01:13,640
<font color="#E5E5E5">users or small companies to</font><font color="#CCCCCC"> also use</font>

25
00:01:11,300 --> 00:01:16,310
deep learning in their own products they

26
00:01:13,640 --> 00:01:19,099
also need<font color="#E5E5E5"> to connect click collect this</font>

27
00:01:16,310 --> 00:01:22,940
<font color="#E5E5E5">amount</font><font color="#CCCCCC"> of data</font><font color="#E5E5E5"> and as we all</font><font color="#CCCCCC"> know this</font>

28
00:01:19,099 --> 00:01:24,890
<font color="#E5E5E5">is extremely hard task so to overcome</font>

29
00:01:22,940 --> 00:01:27,259
this<font color="#E5E5E5"> data requirement of deep learning</font>

30
00:01:24,890 --> 00:01:29,780
<font color="#E5E5E5">we have a very popular solution called</font>

31
00:01:27,259 --> 00:01:31,729
<font color="#E5E5E5">transfer learning so this is how</font>

32
00:01:29,780 --> 00:01:33,560
transfer money works<font color="#E5E5E5"> so if you're a</font>

33
00:01:31,729 --> 00:01:36,709
<font color="#E5E5E5">company with</font><font color="#CCCCCC"> very limited</font><font color="#E5E5E5"> training data</font>

34
00:01:33,560 --> 00:01:39,440
<font color="#E5E5E5">you</font><font color="#CCCCCC"> need</font><font color="#E5E5E5"> to turn</font><font color="#CCCCCC"> to those who have</font>

35
00:01:36,709 --> 00:01:41,569
access<font color="#E5E5E5"> to large datasets</font><font color="#CCCCCC"> and have the</font>

36
00:01:39,440 --> 00:01:44,509
<font color="#CCCCCC">ability to Train large sorry</font><font color="#E5E5E5"> high</font>

37
00:01:41,569 --> 00:01:47,780
<font color="#E5E5E5">quality models and let's say Google and</font>

38
00:01:44,509 --> 00:01:50,330
if they<font color="#CCCCCC"> open-source any models or</font>

39
00:01:47,780 --> 00:01:53,539
similar tasks<font color="#E5E5E5"> what you can do is you can</font>

40
00:01:50,330 --> 00:01:56,209
grab<font color="#E5E5E5"> those models and adapt these models</font>

41
00:01:53,539 --> 00:01:58,759
<font color="#E5E5E5">using your own data sets and then you</font>

42
00:01:56,209 --> 00:02:00,979
will<font color="#E5E5E5"> have a very high quality model that</font>

43
00:01:58,759 --> 00:02:03,560
is specifically designed<font color="#E5E5E5"> for your own</font>

44
00:02:00,979 --> 00:02:05,330
<font color="#E5E5E5">task</font><font color="#CCCCCC"> so this process</font><font color="#E5E5E5"> is called transfer</font>

45
00:02:03,560 --> 00:02:07,420
learning<font color="#E5E5E5"> so essentially what we're doing</font>

46
00:02:05,330 --> 00:02:11,030
<font color="#CCCCCC">here is we're transferring the knowledge</font>

47
00:02:07,420 --> 00:02:14,870
<font color="#E5E5E5">from those high quality</font><font color="#CCCCCC"> models</font><font color="#E5E5E5"> and adapt</font>

48
00:02:11,030 --> 00:02:16,580
them<font color="#CCCCCC"> to our own tasks</font><font color="#E5E5E5"> so the high</font>

49
00:02:14,870 --> 00:02:18,230
quality<font color="#E5E5E5"> model we have would borrow from</font>

50
00:02:16,580 --> 00:02:20,060
large companies<font color="#CCCCCC"> is called</font><font color="#E5E5E5"> a teacher</font>

51
00:02:18,230 --> 00:02:22,220
model and the model<font color="#E5E5E5"> we</font><font color="#CCCCCC"> train ourselves</font>

52
00:02:20,060 --> 00:02:22,980
<font color="#E5E5E5">is called a student</font><font color="#CCCCCC"> model so we're</font>

53
00:02:22,220 --> 00:02:25,980
<font color="#E5E5E5">transferring</font>

54
00:02:22,980 --> 00:02:28,470
from teacher to student<font color="#CCCCCC"> this</font><font color="#E5E5E5"> is the only</font>

55
00:02:25,980 --> 00:02:30,268
solution we have<font color="#CCCCCC"> so</font><font color="#E5E5E5"> far when we need to</font>

56
00:02:28,470 --> 00:02:32,730
train<font color="#E5E5E5"> a high quality deployment model</font>

57
00:02:30,269 --> 00:02:35,370
with limited data so<font color="#E5E5E5"> this is why large</font>

58
00:02:32,730 --> 00:02:37,230
companies like<font color="#E5E5E5"> Google Microsoft and</font>

59
00:02:35,370 --> 00:02:39,810
Facebook<font color="#CCCCCC"> there are open</font><font color="#E5E5E5"> sourcing their</font>

60
00:02:37,230 --> 00:02:42,000
models to the<font color="#E5E5E5"> public so everyone can</font>

61
00:02:39,810 --> 00:02:45,360
<font color="#E5E5E5">build their</font><font color="#CCCCCC"> own student models</font><font color="#E5E5E5"> on top of</font>

62
00:02:42,000 --> 00:02:46,890
<font color="#E5E5E5">those high quality</font><font color="#CCCCCC"> teachers</font><font color="#E5E5E5"> and this is</font>

63
00:02:45,360 --> 00:02:49,829
also<font color="#CCCCCC"> recommended</font><font color="#E5E5E5"> by those large</font>

64
00:02:46,890 --> 00:02:51,750
<font color="#E5E5E5">companies as sort of</font><font color="#CCCCCC"> go-to solution if</font>

65
00:02:49,829 --> 00:02:55,769
<font color="#E5E5E5">you want to train a model with with</font>

66
00:02:51,750 --> 00:02:58,170
limited data so before I go<font color="#CCCCCC"> into any</font>

67
00:02:55,769 --> 00:02:59,190
detail about<font color="#E5E5E5"> transfer</font><font color="#CCCCCC"> learning I just</font>

68
00:02:58,170 --> 00:03:00,809
want to make<font color="#E5E5E5"> sure that everyone</font>

69
00:02:59,190 --> 00:03:03,900
understands the basics about<font color="#E5E5E5"> deep</font>

70
00:03:00,810 --> 00:03:07,109
learning so<font color="#E5E5E5"> deep learning model is this</font>

71
00:03:03,900 --> 00:03:09,000
layers of neurons<font color="#E5E5E5"> and</font><font color="#CCCCCC"> they</font><font color="#E5E5E5"> are stacked</font>

72
00:03:07,109 --> 00:03:11,250
on<font color="#E5E5E5"> top of each other so</font><font color="#CCCCCC"> every single</font>

73
00:03:09,000 --> 00:03:14,190
neuron represent a feature<font color="#CCCCCC"> of the input</font>

74
00:03:11,250 --> 00:03:16,230
<font color="#E5E5E5">and then when we feed this image into</font>

75
00:03:14,190 --> 00:03:18,720
the model for<font color="#E5E5E5"> example this cute image of</font>

76
00:03:16,230 --> 00:03:21,030
<font color="#CCCCCC">dog</font><font color="#E5E5E5"> there will be many neurons are</font>

77
00:03:18,720 --> 00:03:22,920
activated<font color="#CCCCCC"> by this</font><font color="#E5E5E5"> image</font><font color="#CCCCCC"> and then they</font>

78
00:03:21,030 --> 00:03:25,049
will fire more neurons in the next layer

79
00:03:22,920 --> 00:03:27,589
and the next layer<font color="#E5E5E5"> and eventually the</font>

80
00:03:25,049 --> 00:03:30,239
last layer will tell you this is a dog

81
00:03:27,590 --> 00:03:32,130
<font color="#CCCCCC">so when it comes to transfer learning</font>

82
00:03:30,239 --> 00:03:34,530
<font color="#E5E5E5">and let's say we have a teacher model</font>

83
00:03:32,130 --> 00:03:37,440
with n layers so<font color="#E5E5E5"> the last layer is</font>

84
00:03:34,530 --> 00:03:39,870
<font color="#E5E5E5">always a classification later and this</font>

85
00:03:37,440 --> 00:03:42,180
<font color="#CCCCCC">is</font><font color="#E5E5E5"> specific to the teacher</font><font color="#CCCCCC"> tasks so</font>

86
00:03:39,870 --> 00:03:44,549
we'll just<font color="#E5E5E5"> put this one</font><font color="#CCCCCC"> aside</font><font color="#E5E5E5"> and then</font>

87
00:03:42,180 --> 00:03:48,090
what we do is<font color="#CCCCCC"> we transfer the</font><font color="#E5E5E5"> remaining</font>

88
00:03:44,549 --> 00:03:50,760
n<font color="#CCCCCC"> minus 1 layers to the student</font><font color="#E5E5E5"> so the</font>

89
00:03:48,090 --> 00:03:53,459
intuition<font color="#CCCCCC"> here is that the output of</font>

90
00:03:50,760 --> 00:03:55,888
those n minus 1 layers are extremely

91
00:03:53,459 --> 00:03:58,169
high quality<font color="#E5E5E5"> features and we can</font>

92
00:03:55,889 --> 00:04:01,310
directly reuse<font color="#E5E5E5"> those features and build</font>

93
00:03:58,169 --> 00:04:04,620
a<font color="#E5E5E5"> very simple build a very simple</font>

94
00:04:01,310 --> 00:04:06,450
classification layers on top<font color="#CCCCCC"> of it</font><font color="#E5E5E5"> so we</font>

95
00:04:04,620 --> 00:04:08,959
built this layer using<font color="#CCCCCC"> the</font><font color="#E5E5E5"> student data</font>

96
00:04:06,450 --> 00:04:11,339
set so this is this model<font color="#E5E5E5"> is</font>

97
00:04:08,959 --> 00:04:13,230
specifically<font color="#E5E5E5"> built for your own student</font>

98
00:04:11,340 --> 00:04:16,500
<font color="#CCCCCC">tasks and this is how we build a student</font>

99
00:04:13,230 --> 00:04:19,260
and in general you can directly transfer

100
00:04:16,500 --> 00:04:22,860
<font color="#E5E5E5">the first K layers and in this case we</font>

101
00:04:19,260 --> 00:04:25,080
use first n<font color="#E5E5E5"> minus</font><font color="#CCCCCC"> 1 layers</font><font color="#E5E5E5"> so to show</font>

102
00:04:22,860 --> 00:04:27,000
<font color="#E5E5E5">you how effective transfer one is this</font>

103
00:04:25,080 --> 00:04:30,719
is one example<font color="#E5E5E5"> of the face recognition</font>

104
00:04:27,000 --> 00:04:33,060
<font color="#E5E5E5">task so we want to recognize faces of 65</font>

105
00:04:30,720 --> 00:04:35,420
<font color="#E5E5E5">different people and the data set is is</font>

106
00:04:33,060 --> 00:04:37,780
extremely<font color="#CCCCCC"> small</font><font color="#E5E5E5"> we only have</font><font color="#CCCCCC"> 10 image</font>

107
00:04:35,420 --> 00:04:40,970
per person<font color="#E5E5E5"> and what we do here is we</font>

108
00:04:37,780 --> 00:04:43,219
transfer<font color="#E5E5E5"> from a teacher model called</font><font color="#CCCCCC"> vgg</font>

109
00:04:40,970 --> 00:04:46,180
face<font color="#E5E5E5"> so this model</font><font color="#CCCCCC"> is trained on</font><font color="#E5E5E5"> an</font>

110
00:04:43,220 --> 00:04:48,860
extremely<font color="#E5E5E5"> large</font><font color="#CCCCCC"> datasets</font><font color="#E5E5E5"> with more than</font>

111
00:04:46,180 --> 00:04:51,800
<font color="#CCCCCC">2,600 people and</font><font color="#E5E5E5"> more than 900 images</font>

112
00:04:48,860 --> 00:04:54,230
per person so if we do the training

113
00:04:51,800 --> 00:04:56,480
<font color="#CCCCCC">without transfer learning we'll get</font>

114
00:04:54,230 --> 00:04:59,030
around<font color="#CCCCCC"> one percent</font><font color="#E5E5E5"> accuracy</font><font color="#CCCCCC"> so this</font>

115
00:04:56,480 --> 00:05:01,000
<font color="#CCCCCC">model</font><font color="#E5E5E5"> is basically useless but with</font>

116
00:04:59,030 --> 00:05:04,099
transfer<font color="#CCCCCC"> learning we can</font><font color="#E5E5E5"> get as high</font><font color="#CCCCCC"> as</font>

117
00:05:01,000 --> 00:05:08,570
<font color="#CCCCCC">93% accuracy so this just</font><font color="#E5E5E5"> shows</font><font color="#CCCCCC"> you how</font>

118
00:05:04,100 --> 00:05:10,850
effective<font color="#CCCCCC"> translating is so what we want</font>

119
00:05:08,570 --> 00:05:12,440
to ask in<font color="#E5E5E5"> this project is whether</font>

120
00:05:10,850 --> 00:05:15,020
transfer<font color="#CCCCCC"> learning is safe whether</font>

121
00:05:12,440 --> 00:05:17,630
transfer learning<font color="#E5E5E5"> can produce robust</font>

122
00:05:15,020 --> 00:05:19,880
student models or not<font color="#E5E5E5"> and what we find</font>

123
00:05:17,630 --> 00:05:22,310
is that transfer<font color="#CCCCCC"> learning doesn't</font><font color="#E5E5E5"> have a</font>

124
00:05:19,880 --> 00:05:24,800
lot<font color="#CCCCCC"> of diversity</font><font color="#E5E5E5"> and because there is</font>

125
00:05:22,310 --> 00:05:26,990
only a limited<font color="#CCCCCC"> number of large datasets</font>

126
00:05:24,800 --> 00:05:29,180
<font color="#CCCCCC">out there so when it comes to transfer</font>

127
00:05:26,990 --> 00:05:33,050
learning users will have<font color="#E5E5E5"> very limited</font>

128
00:05:29,180 --> 00:05:35,210
<font color="#CCCCCC">choices of teacher model so a lot of</font>

129
00:05:33,050 --> 00:05:37,970
<font color="#E5E5E5">companies will be building their student</font>

130
00:05:35,210 --> 00:05:40,700
models on top of the same teacher<font color="#E5E5E5"> and it</font>

131
00:05:37,970 --> 00:05:43,070
also means the attacker<font color="#E5E5E5"> will get the</font>

132
00:05:40,700 --> 00:05:44,960
same copy of teacher model and this<font color="#E5E5E5"> is</font>

133
00:05:43,070 --> 00:05:47,330
the same model you<font color="#CCCCCC"> use</font><font color="#E5E5E5"> to</font><font color="#CCCCCC"> Bill</font><font color="#E5E5E5"> your</font>

134
00:05:44,960 --> 00:05:49,190
students and what<font color="#CCCCCC"> we found is that</font><font color="#E5E5E5"> in</font>

135
00:05:47,330 --> 00:05:51,349
this<font color="#E5E5E5"> paper is that this information</font>

136
00:05:49,190 --> 00:05:54,140
<font color="#CCCCCC">about</font><font color="#E5E5E5"> the teacher can</font><font color="#CCCCCC"> really help the</font>

137
00:05:51,350 --> 00:05:57,860
attacker launch<font color="#CCCCCC"> tax on all student</font>

138
00:05:54,140 --> 00:05:59,990
models out there<font color="#CCCCCC"> all right</font><font color="#E5E5E5"> so in this</font>

139
00:05:57,860 --> 00:06:02,030
<font color="#E5E5E5">talk I will tell you how this how</font><font color="#CCCCCC"> this</font>

140
00:05:59,990 --> 00:06:03,890
attack works<font color="#E5E5E5"> and I'll show you how this</font>

141
00:06:02,030 --> 00:06:05,780
impacts real deep<font color="#CCCCCC"> learning services and</font>

142
00:06:03,890 --> 00:06:10,130
I'll also<font color="#E5E5E5"> show</font><font color="#CCCCCC"> you some</font><font color="#E5E5E5"> defense</font>

143
00:06:05,780 --> 00:06:12,530
<font color="#E5E5E5">solutions right so first off a little</font>

144
00:06:10,130 --> 00:06:14,570
background about<font color="#E5E5E5"> adverse or attack on</font>

145
00:06:12,530 --> 00:06:16,820
deployment<font color="#E5E5E5"> so another attack</font><font color="#CCCCCC"> on</font>

146
00:06:14,570 --> 00:06:19,219
<font color="#E5E5E5">deployment is mostly</font><font color="#CCCCCC"> about trying to</font>

147
00:06:16,820 --> 00:06:22,010
<font color="#E5E5E5">miss classify inputs by adding some</font>

148
00:06:19,220 --> 00:06:25,160
carefully engineered perturbation to the

149
00:06:22,010 --> 00:06:28,039
<font color="#E5E5E5">inputs</font><font color="#CCCCCC"> so</font><font color="#E5E5E5"> for</font><font color="#CCCCCC"> example here we have</font><font color="#E5E5E5"> an</font>

150
00:06:25,160 --> 00:06:29,930
image<font color="#CCCCCC"> of Angelina</font><font color="#E5E5E5"> Jolie</font><font color="#CCCCCC"> and</font><font color="#E5E5E5"> by</font><font color="#CCCCCC"> adding</font>

151
00:06:28,040 --> 00:06:32,390
some little modification to the image

152
00:06:29,930 --> 00:06:35,150
the model will miss classify that as<font color="#E5E5E5"> at</font>

153
00:06:32,390 --> 00:06:36,770
<font color="#E5E5E5">an Adam</font><font color="#CCCCCC"> Sandler</font><font color="#E5E5E5"> so the modification we</font>

154
00:06:35,150 --> 00:06:41,299
add to<font color="#CCCCCC"> the</font><font color="#E5E5E5"> image is typically very small</font>

155
00:06:36,770 --> 00:06:43,609
so human<font color="#E5E5E5"> cannot see it and based on the</font>

156
00:06:41,300 --> 00:06:45,920
attack model we have we have<font color="#E5E5E5"> white box</font>

157
00:06:43,610 --> 00:06:48,189
attack<font color="#CCCCCC"> so the white box that</font><font color="#E5E5E5"> assumes we</font>

158
00:06:45,920 --> 00:06:50,289
have full access<font color="#E5E5E5"> to the model in turn</font>

159
00:06:48,189 --> 00:06:52,930
so that includes the architecture<font color="#E5E5E5"> or</font><font color="#CCCCCC"> the</font>

160
00:06:50,289 --> 00:06:54,878
weights in model and basically<font color="#E5E5E5"> what you</font>

161
00:06:52,930 --> 00:06:57,520
do<font color="#CCCCCC"> is you can do</font><font color="#E5E5E5"> all the computation</font>

162
00:06:54,879 --> 00:06:59,379
offline<font color="#E5E5E5"> and you</font><font color="#CCCCCC"> can find the optimal</font>

163
00:06:57,520 --> 00:07:01,779
perturbation<font color="#CCCCCC"> you need to launch the</font>

164
00:06:59,379 --> 00:07:04,659
<font color="#CCCCCC">attack but the problem about</font><font color="#E5E5E5"> that is</font>

165
00:07:01,779 --> 00:07:07,029
this<font color="#E5E5E5"> assumption of full</font><font color="#CCCCCC"> axis</font><font color="#E5E5E5"> it's not</font>

166
00:07:04,659 --> 00:07:09,069
really practical<font color="#CCCCCC"> so in a lot of cases</font>

167
00:07:07,029 --> 00:07:11,590
the service provider will not just give

168
00:07:09,069 --> 00:07:13,810
away<font color="#E5E5E5"> its internal design of the model to</font>

169
00:07:11,590 --> 00:07:15,849
attackers<font color="#E5E5E5"> so this is not really</font>

170
00:07:13,810 --> 00:07:18,699
practical<font color="#E5E5E5"> assumption so that's why we</font>

171
00:07:15,849 --> 00:07:21,069
have black box attack<font color="#E5E5E5"> so black box</font>

172
00:07:18,699 --> 00:07:23,199
attack assumes we have no access<font color="#CCCCCC"> to such</font>

173
00:07:21,069 --> 00:07:25,930
information<font color="#CCCCCC"> so then what you're doing</font>

174
00:07:23,199 --> 00:07:27,759
stat is you can repeatedly<font color="#E5E5E5"> query the</font>

175
00:07:25,930 --> 00:07:29,889
victim model<font color="#E5E5E5"> you can do this to either</font>

176
00:07:27,759 --> 00:07:33,009
<font color="#E5E5E5">reverse engineer how the model works</font>

177
00:07:29,889 --> 00:07:34,479
<font color="#E5E5E5">inside or you can test some intermediate</font>

178
00:07:33,009 --> 00:07:37,150
perturbations you have and try<font color="#E5E5E5"> to</font>

179
00:07:34,479 --> 00:07:39,250
improve on top of it<font color="#CCCCCC"> and the problem</font>

180
00:07:37,150 --> 00:07:42,128
<font color="#E5E5E5">about this is that in a lot</font><font color="#CCCCCC"> of cases you</font>

181
00:07:39,250 --> 00:07:44,979
<font color="#CCCCCC">need tons of queries</font><font color="#E5E5E5"> to do in</font><font color="#CCCCCC"> a natural</font>

182
00:07:42,129 --> 00:07:47,740
attack and this repeated query behavior

183
00:07:44,979 --> 00:07:49,449
itself<font color="#E5E5E5"> can be very easily detected so</font>

184
00:07:47,740 --> 00:07:52,330
you can see both models have<font color="#CCCCCC"> their own</font>

185
00:07:49,449 --> 00:07:54,250
<font color="#E5E5E5">problems that's why we</font><font color="#CCCCCC"> are</font><font color="#E5E5E5"> proposing a</font>

186
00:07:52,330 --> 00:07:56,469
new out of<font color="#CCCCCC"> stir attack and this is</font>

187
00:07:54,250 --> 00:07:59,379
<font color="#E5E5E5">specifically targeting the</font><font color="#CCCCCC"> transfer</font>

188
00:07:56,469 --> 00:08:01,719
<font color="#CCCCCC">learning scenario so our attack model is</font>

189
00:07:59,379 --> 00:08:03,430
a little<font color="#E5E5E5"> different we assume the teacher</font>

190
00:08:01,719 --> 00:08:05,860
model is a white box<font color="#E5E5E5"> so we know</font>

191
00:08:03,430 --> 00:08:08,469
<font color="#E5E5E5">everything about the teacher but the</font>

192
00:08:05,860 --> 00:08:11,110
student on the other hand is a black box

193
00:08:08,469 --> 00:08:13,689
<font color="#E5E5E5">so we have we we don't know all the</font>

194
00:08:11,110 --> 00:08:16,149
<font color="#E5E5E5">detail about</font><font color="#CCCCCC"> a student</font><font color="#E5E5E5"> model and this</font><font color="#CCCCCC"> is</font>

195
00:08:13,689 --> 00:08:18,879
the default<font color="#E5E5E5"> access model of transfer</font>

196
00:08:16,149 --> 00:08:21,039
learning<font color="#E5E5E5"> right now because all these</font>

197
00:08:18,879 --> 00:08:22,899
popular deep learning<font color="#E5E5E5"> services are</font>

198
00:08:21,039 --> 00:08:24,969
making their teacher models public and

199
00:08:22,899 --> 00:08:26,889
<font color="#E5E5E5">they're</font><font color="#CCCCCC"> making it public to everyone and</font>

200
00:08:24,969 --> 00:08:29,319
<font color="#E5E5E5">that</font><font color="#CCCCCC"> includes the attacker so you can</font>

201
00:08:26,889 --> 00:08:31,509
literally go<font color="#CCCCCC"> to Google's web</font><font color="#E5E5E5"> website and</font>

202
00:08:29,319 --> 00:08:33,250
search for their teacher models and

203
00:08:31,509 --> 00:08:35,919
download it<font color="#E5E5E5"> to your laptop</font><font color="#CCCCCC"> so</font><font color="#E5E5E5"> you know</font>

204
00:08:33,250 --> 00:08:38,229
everything about teacher but student

205
00:08:35,919 --> 00:08:40,838
models are typically trained offline

206
00:08:38,229 --> 00:08:42,669
<font color="#E5E5E5">using their proprietary data sets so</font>

207
00:08:40,839 --> 00:08:44,440
whatever<font color="#E5E5E5"> modifications</font><font color="#CCCCCC"> have been</font><font color="#E5E5E5"> during</font>

208
00:08:42,669 --> 00:08:48,160
transfer<font color="#CCCCCC"> learning are totally hidden</font>

209
00:08:44,440 --> 00:08:50,190
<font color="#E5E5E5">from the attacker so how do we attack</font>

210
00:08:48,160 --> 00:08:52,269
the student<font color="#E5E5E5"> without knowing its weights</font>

211
00:08:50,190 --> 00:08:54,579
<font color="#E5E5E5">so let's say here we want to</font>

212
00:08:52,269 --> 00:08:57,850
<font color="#CCCCCC">misclassified this cat</font><font color="#E5E5E5"> which is in the</font>

213
00:08:54,579 --> 00:09:00,880
<font color="#E5E5E5">bottom into a dog so as I said before</font>

214
00:08:57,850 --> 00:09:03,579
deep neural<font color="#E5E5E5"> net</font><font color="#CCCCCC"> is this stat layer</font>

215
00:09:00,880 --> 00:09:07,630
so every<font color="#E5E5E5"> single layer only sees outputs</font>

216
00:09:03,579 --> 00:09:10,989
from<font color="#E5E5E5"> previous layers so then our attack</font>

217
00:09:07,630 --> 00:09:15,009
is<font color="#E5E5E5"> trying to mimic the neuron values of</font>

218
00:09:10,990 --> 00:09:18,370
the target image<font color="#CCCCCC"> at layer cake</font><font color="#E5E5E5"> so here</font>

219
00:09:15,009 --> 00:09:20,470
I'll show you two vectors so the task<font color="#E5E5E5"> is</font>

220
00:09:18,370 --> 00:09:23,050
trying to mimic make these two neuron

221
00:09:20,470 --> 00:09:25,630
vectors match each other<font color="#CCCCCC"> so if we can do</font>

222
00:09:23,050 --> 00:09:28,449
that when these two<font color="#E5E5E5"> vectors are passed</font>

223
00:09:25,630 --> 00:09:30,339
on<font color="#CCCCCC"> to</font><font color="#E5E5E5"> the next layer</font><font color="#CCCCCC"> the outputs</font><font color="#E5E5E5"> will</font>

224
00:09:28,449 --> 00:09:33,250
also be the<font color="#E5E5E5"> same</font><font color="#CCCCCC"> the same input neuron</font>

225
00:09:30,339 --> 00:09:34,990
vectors same layer<font color="#E5E5E5"> same output and this</font>

226
00:09:33,250 --> 00:09:37,449
<font color="#CCCCCC">is the</font><font color="#E5E5E5"> same for the next layer as well</font>

227
00:09:34,990 --> 00:09:39,250
<font color="#E5E5E5">so and eventually the model will produce</font>

228
00:09:37,449 --> 00:09:41,949
the<font color="#CCCCCC"> same prediction results for two</font>

229
00:09:39,250 --> 00:09:44,949
images so this is how the attack works

230
00:09:41,949 --> 00:09:47,680
we try to mimic the neuron values<font color="#E5E5E5"> in one</font>

231
00:09:44,949 --> 00:09:50,229
of the middle<font color="#E5E5E5"> layers and because the</font>

232
00:09:47,680 --> 00:09:52,329
first<font color="#E5E5E5"> K layers are not</font><font color="#CCCCCC"> updated during</font>

233
00:09:50,230 --> 00:09:54,130
<font color="#E5E5E5">transfer learning so we can do all the</font>

234
00:09:52,329 --> 00:09:59,170
<font color="#E5E5E5">computation we need on the teacher model</font>

235
00:09:54,130 --> 00:10:00,939
to find<font color="#E5E5E5"> the Probation we need and the</font>

236
00:09:59,170 --> 00:10:02,920
way we compute the perturbation<font color="#E5E5E5"> is a</font>

237
00:10:00,940 --> 00:10:05,139
very standard optimization<font color="#CCCCCC"> technique and</font>

238
00:10:02,920 --> 00:10:08,139
this<font color="#E5E5E5"> is also using some prior work as</font>

239
00:10:05,139 --> 00:10:11,860
well<font color="#E5E5E5"> so the goal</font><font color="#CCCCCC"> here is</font><font color="#E5E5E5"> try</font><font color="#CCCCCC"> to mimic</font>

240
00:10:08,139 --> 00:10:13,870
the hidden layer representation<font color="#E5E5E5"> and we</font>

241
00:10:11,860 --> 00:10:16,240
also have a constraint which<font color="#CCCCCC"> is we</font><font color="#E5E5E5"> want</font>

242
00:10:13,870 --> 00:10:19,000
the perturbation to be indistinguishable

243
00:10:16,240 --> 00:10:21,519
by humans<font color="#E5E5E5"> we don't want</font><font color="#CCCCCC"> the human</font><font color="#E5E5E5"> to see</font>

244
00:10:19,000 --> 00:10:23,800
this perturbation<font color="#E5E5E5"> so that's why the main</font>

245
00:10:21,519 --> 00:10:26,019
objective<font color="#CCCCCC"> here is try to minimize the</font>

246
00:10:23,800 --> 00:10:28,569
<font color="#E5E5E5">distance between two representations</font><font color="#CCCCCC"> and</font>

247
00:10:26,019 --> 00:10:31,509
we'll use<font color="#CCCCCC"> a very simple l2 distance</font><font color="#E5E5E5"> to</font>

248
00:10:28,569 --> 00:10:33,160
measure that<font color="#E5E5E5"> and the constraint term is</font>

249
00:10:31,509 --> 00:10:35,529
trying to<font color="#E5E5E5"> control the amount of</font>

250
00:10:33,160 --> 00:10:39,550
modification<font color="#E5E5E5"> we add to the image so here</font>

251
00:10:35,529 --> 00:10:42,490
<font color="#CCCCCC">we use a metric called D ssim to measure</font>

252
00:10:39,550 --> 00:10:45,519
the<font color="#E5E5E5"> amount of perturbation so d ssim is</font>

253
00:10:42,490 --> 00:10:47,709
a<font color="#CCCCCC"> it's an objective measure for image</font>

254
00:10:45,519 --> 00:10:50,350
distortion<font color="#E5E5E5"> this is often used in vision</font>

255
00:10:47,709 --> 00:10:52,660
domain so this constraint term will make

256
00:10:50,350 --> 00:10:55,480
sure that<font color="#CCCCCC"> the</font><font color="#E5E5E5"> amount is minimum and the</font>

257
00:10:52,660 --> 00:10:58,089
human cannot see it and we also have<font color="#CCCCCC"> a</font>

258
00:10:55,480 --> 00:11:00,310
<font color="#E5E5E5">variable P budget here and this is a</font>

259
00:10:58,089 --> 00:11:02,050
knob<font color="#E5E5E5"> that the attacker can tune to</font>

260
00:11:00,310 --> 00:11:06,369
control how much perturbation he wants

261
00:11:02,050 --> 00:11:08,469
to add so to see how this attack works

262
00:11:06,370 --> 00:11:11,910
we<font color="#CCCCCC"> test it on</font><font color="#E5E5E5"> student models we train</font>

263
00:11:08,470 --> 00:11:14,010
ourselves<font color="#E5E5E5"> and here we mainly focus on</font>

264
00:11:11,910 --> 00:11:16,410
targeted attack<font color="#E5E5E5"> so we want targeted miss</font>

265
00:11:14,010 --> 00:11:18,750
classification we<font color="#E5E5E5"> randomly selected</font>

266
00:11:16,410 --> 00:11:21,360
<font color="#CCCCCC">1,000 source and target image pairs and</font>

267
00:11:18,750 --> 00:11:23,820
we calculate the attack success rate<font color="#CCCCCC"> so</font>

268
00:11:21,360 --> 00:11:26,340
<font color="#CCCCCC">this</font><font color="#E5E5E5"> is the percentage of images being</font>

269
00:11:23,820 --> 00:11:28,830
<font color="#E5E5E5">classified into the</font><font color="#CCCCCC"> target</font><font color="#E5E5E5"> so this is</font>

270
00:11:26,340 --> 00:11:31,470
one example of<font color="#E5E5E5"> a face recognition task</font>

271
00:11:28,830 --> 00:11:33,810
so<font color="#CCCCCC"> we achieve higher than</font><font color="#E5E5E5"> 92 percent</font>

272
00:11:31,470 --> 00:11:35,910
success rate<font color="#CCCCCC"> so if we</font><font color="#E5E5E5"> switch</font><font color="#CCCCCC"> to a</font>

273
00:11:33,810 --> 00:11:38,189
different applications<font color="#E5E5E5"> to narrow for</font>

274
00:11:35,910 --> 00:11:40,170
example<font color="#E5E5E5"> ours recognition the attack also</font>

275
00:11:38,190 --> 00:11:42,960
words which you've higher than<font color="#E5E5E5"> 95%</font>

276
00:11:40,170 --> 00:11:45,150
success<font color="#E5E5E5"> rate and also notice</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> this</font>

277
00:11:42,960 --> 00:11:47,400
is<font color="#E5E5E5"> the attack success rate</font><font color="#CCCCCC"> of one single</font>

278
00:11:45,150 --> 00:11:48,720
try so if this one doesn't<font color="#E5E5E5"> work the</font>

279
00:11:47,400 --> 00:11:50,370
attacker can simply switch<font color="#CCCCCC"> to a</font>

280
00:11:48,720 --> 00:11:54,960
different<font color="#CCCCCC"> image and he'll</font><font color="#E5E5E5"> probably get</font>

281
00:11:50,370 --> 00:11:56,850
<font color="#E5E5E5">successful so we also want to see</font>

282
00:11:54,960 --> 00:11:58,770
<font color="#E5E5E5">whether this attack works in the wild</font>

283
00:11:56,850 --> 00:12:01,350
and the first<font color="#E5E5E5"> problem we need to solve</font>

284
00:11:58,770 --> 00:12:03,329
is given a student model<font color="#E5E5E5"> how do we</font>

285
00:12:01,350 --> 00:12:06,210
determine which teacher model was used

286
00:12:03,330 --> 00:12:07,950
<font color="#CCCCCC">during translating so I don't</font><font color="#E5E5E5"> have time</font>

287
00:12:06,210 --> 00:12:10,440
to cover all<font color="#CCCCCC"> the</font><font color="#E5E5E5"> details here but</font>

288
00:12:07,950 --> 00:12:13,200
essentially what we do<font color="#E5E5E5"> is</font><font color="#CCCCCC"> we</font><font color="#E5E5E5"> propose a</font>

289
00:12:10,440 --> 00:12:16,140
technique called<font color="#CCCCCC"> finger-painting</font><font color="#E5E5E5"> so we</font>

290
00:12:13,200 --> 00:12:17,970
can craft this fingerprint<font color="#E5E5E5"> input</font><font color="#CCCCCC"> before</font>

291
00:12:16,140 --> 00:12:20,819
every single<font color="#CCCCCC"> teacher candidate out there</font>

292
00:12:17,970 --> 00:12:23,520
<font color="#E5E5E5">and then we query the student</font><font color="#CCCCCC"> model</font>

293
00:12:20,820 --> 00:12:25,020
using those inputs and based<font color="#E5E5E5"> on the</font>

294
00:12:23,520 --> 00:12:28,230
prediction results<font color="#CCCCCC"> we can see which</font>

295
00:12:25,020 --> 00:12:32,220
teacher model is used so we also want<font color="#CCCCCC"> to</font>

296
00:12:28,230 --> 00:12:33,870
see whether this attack works on real

297
00:12:32,220 --> 00:12:36,960
students<font color="#E5E5E5"> trained by real deep</font><font color="#CCCCCC"> learning</font>

298
00:12:33,870 --> 00:12:38,430
services<font color="#E5E5E5"> but because of ethical reasons</font>

299
00:12:36,960 --> 00:12:40,590
we can't just go ahead<font color="#E5E5E5"> and attack those</font>

300
00:12:38,430 --> 00:12:44,219
real students<font color="#E5E5E5"> so instead what we do is</font>

301
00:12:40,590 --> 00:12:46,260
<font color="#E5E5E5">we train students our selves and we do</font>

302
00:12:44,220 --> 00:12:48,810
that by following<font color="#E5E5E5"> the exact tutorials</font>

303
00:12:46,260 --> 00:12:51,630
<font color="#E5E5E5">and the exact teacher models provided by</font>

304
00:12:48,810 --> 00:12:54,839
those services<font color="#CCCCCC"> so we</font><font color="#E5E5E5"> test it on Google</font>

305
00:12:51,630 --> 00:12:57,720
Cloud ml<font color="#CCCCCC"> Microsoft CNT K and PI torch</font>

306
00:12:54,840 --> 00:12:59,790
and PI<font color="#CCCCCC"> torches developed by Facebook so</font>

307
00:12:57,720 --> 00:13:02,490
in all cases<font color="#E5E5E5"> the fingerprinting attack</font>

308
00:12:59,790 --> 00:13:07,650
works and we<font color="#CCCCCC"> achieved higher than 88</font>

309
00:13:02,490 --> 00:13:09,510
<font color="#CCCCCC">percent success rate right so now let's</font>

310
00:13:07,650 --> 00:13:12,810
talk about<font color="#E5E5E5"> how to patch up those student</font>

311
00:13:09,510 --> 00:13:15,330
models so the intuition<font color="#E5E5E5"> is extremely</font>

312
00:13:12,810 --> 00:13:18,599
straightforward<font color="#CCCCCC"> so the attack is trying</font>

313
00:13:15,330 --> 00:13:21,950
to mimic the output of layer<font color="#E5E5E5"> K in the</font>

314
00:13:18,600 --> 00:13:24,810
teacher model so the defense should<font color="#CCCCCC"> be</font>

315
00:13:21,950 --> 00:13:25,270
modifying the student so<font color="#E5E5E5"> it's internal</font>

316
00:13:24,810 --> 00:13:27,040
<font color="#E5E5E5">reps and</font>

317
00:13:25,270 --> 00:13:29,290
patience doesn't<font color="#E5E5E5"> match that</font><font color="#CCCCCC"> in the</font>

318
00:13:27,040 --> 00:13:30,790
teacher anymore<font color="#E5E5E5"> so then the attack will</font>

319
00:13:29,290 --> 00:13:32,680
be mimicking the wrong internal

320
00:13:30,790 --> 00:13:35,680
representations and<font color="#CCCCCC"> the attack will fail</font>

321
00:13:32,680 --> 00:13:38,260
fundamentally so this is how the defense

322
00:13:35,680 --> 00:13:40,839
works<font color="#E5E5E5"> we also have some other</font>

323
00:13:38,260 --> 00:13:42,520
requirements<font color="#E5E5E5"> for defense first we want</font>

324
00:13:40,840 --> 00:13:44,440
the modification to the student to<font color="#E5E5E5"> be</font>

325
00:13:42,520 --> 00:13:46,870
unpredictable<font color="#CCCCCC"> by the attacker</font>

326
00:13:44,440 --> 00:13:48,790
so<font color="#CCCCCC"> there is no way for</font><font color="#E5E5E5"> the attacker to</font>

327
00:13:46,870 --> 00:13:52,300
fight back<font color="#CCCCCC"> there's</font><font color="#E5E5E5"> no condemnation and</font>

328
00:13:48,790 --> 00:13:56,290
then we also don't<font color="#CCCCCC"> want to sacrifice</font><font color="#E5E5E5"> the</font>

329
00:13:52,300 --> 00:13:59,439
model<font color="#E5E5E5"> performance during the process so</font>

330
00:13:56,290 --> 00:14:01,930
what we do is we modified the objective

331
00:13:59,440 --> 00:14:03,610
function<font color="#E5E5E5"> used in</font><font color="#CCCCCC"> translating</font><font color="#E5E5E5"> and this</font>

332
00:14:01,930 --> 00:14:06,670
new<font color="#CCCCCC"> objective function will make sure</font>

333
00:14:03,610 --> 00:14:10,210
<font color="#E5E5E5">that the student is sufficiently</font>

334
00:14:06,670 --> 00:14:12,339
different<font color="#CCCCCC"> from the teacher</font><font color="#E5E5E5"> so if you use</font>

335
00:14:10,210 --> 00:14:15,100
this so if you do transfer learning

336
00:14:12,340 --> 00:14:16,690
<font color="#E5E5E5">using this objective</font><font color="#CCCCCC"> function the</font>

337
00:14:15,100 --> 00:14:19,570
<font color="#E5E5E5">training student model will be robust</font>

338
00:14:16,690 --> 00:14:21,700
<font color="#CCCCCC">and for other student models that are</font>

339
00:14:19,570 --> 00:14:23,470
<font color="#CCCCCC">already trained and already vulnerable</font>

340
00:14:21,700 --> 00:14:26,320
<font color="#CCCCCC">what you can do is you</font><font color="#E5E5E5"> can fine-tune</font>

341
00:14:23,470 --> 00:14:28,600
those students for a few a<font color="#E5E5E5"> box using the</font>

342
00:14:26,320 --> 00:14:32,280
<font color="#E5E5E5">new objective function so this will make</font>

343
00:14:28,600 --> 00:14:34,630
those<font color="#CCCCCC"> steel</font><font color="#E5E5E5"> emoto's robust so the new</font>

344
00:14:32,280 --> 00:14:36,939
objective function looks<font color="#CCCCCC"> like</font><font color="#E5E5E5"> this the</font>

345
00:14:34,630 --> 00:14:38,920
main objective is to<font color="#E5E5E5"> trying to minimize</font>

346
00:14:36,940 --> 00:14:41,410
the<font color="#E5E5E5"> cross</font><font color="#CCCCCC"> entropy</font><font color="#E5E5E5"> so we still</font><font color="#CCCCCC"> want to</font>

347
00:14:38,920 --> 00:14:44,260
<font color="#E5E5E5">keep the same level of model performance</font>

348
00:14:41,410 --> 00:14:46,420
<font color="#E5E5E5">and we have a new constraint term here</font>

349
00:14:44,260 --> 00:14:49,390
<font color="#E5E5E5">and this constraint term will make sure</font>

350
00:14:46,420 --> 00:14:51,729
<font color="#E5E5E5">that there is enough</font><font color="#CCCCCC"> distance sorry</font>

351
00:14:49,390 --> 00:14:56,410
<font color="#E5E5E5">enough difference between the student</font>

352
00:14:51,730 --> 00:14:58,750
and<font color="#CCCCCC"> teacher so this turns</font><font color="#E5E5E5"> out</font><font color="#CCCCCC"> to be</font>

353
00:14:56,410 --> 00:15:01,240
really<font color="#E5E5E5"> effective and in the two examples</font>

354
00:14:58,750 --> 00:15:03,910
<font color="#E5E5E5">I</font><font color="#CCCCCC"> showed you before</font><font color="#E5E5E5"> we managed</font><font color="#CCCCCC"> to reduce</font>

355
00:15:01,240 --> 00:15:06,940
<font color="#E5E5E5">the attack success rate from above</font><font color="#CCCCCC"> 90</font>

356
00:15:03,910 --> 00:15:10,360
<font color="#E5E5E5">percent down to</font><font color="#CCCCCC"> 30% and</font><font color="#E5E5E5"> 12</font><font color="#CCCCCC"> percent and</font>

357
00:15:06,940 --> 00:15:13,270
<font color="#E5E5E5">also this this defense has very small</font>

358
00:15:10,360 --> 00:15:14,620
<font color="#CCCCCC">impact on the model</font><font color="#E5E5E5"> accuracy so this</font>

359
00:15:13,270 --> 00:15:17,079
shows that we<font color="#CCCCCC"> really can make the</font>

360
00:15:14,620 --> 00:15:20,820
student robust without sacrificing<font color="#CCCCCC"> the</font>

361
00:15:17,080 --> 00:15:23,560
performance and before I<font color="#E5E5E5"> finish</font><font color="#CCCCCC"> my talk</font>

362
00:15:20,820 --> 00:15:26,050
<font color="#CCCCCC">I also want to</font><font color="#E5E5E5"> point out</font><font color="#CCCCCC"> that we already</font>

363
00:15:23,560 --> 00:15:27,939
<font color="#E5E5E5">discuss our findings</font><font color="#CCCCCC"> to Google Microsoft</font>

364
00:15:26,050 --> 00:15:30,520
and<font color="#CCCCCC"> Facebook and they're actively</font>

365
00:15:27,940 --> 00:15:32,080
<font color="#CCCCCC">looking to the matter and I</font><font color="#E5E5E5"> don't really</font>

366
00:15:30,520 --> 00:15:34,210
have<font color="#CCCCCC"> enough time to</font><font color="#E5E5E5"> talk</font><font color="#CCCCCC"> about</font><font color="#E5E5E5"> all the</font>

367
00:15:32,080 --> 00:15:36,250
interesting<font color="#CCCCCC"> details in the paper but I</font>

368
00:15:34,210 --> 00:15:38,800
strongly encourage<font color="#E5E5E5"> you</font><font color="#CCCCCC"> to</font><font color="#E5E5E5"> read</font><font color="#CCCCCC"> a paper</font>

369
00:15:36,250 --> 00:15:40,420
if<font color="#CCCCCC"> you're interested for</font><font color="#E5E5E5"> example</font><font color="#CCCCCC"> we have</font>

370
00:15:38,800 --> 00:15:42,699
<font color="#CCCCCC">detailed measurement about</font><font color="#E5E5E5"> how different</font>

371
00:15:40,420 --> 00:15:45,550
<font color="#E5E5E5">transfer learning approaches affected</font>

372
00:15:42,699 --> 00:15:47,079
<font color="#E5E5E5">the attack performance and I we also</font>

373
00:15:45,550 --> 00:15:50,800
have the full description<font color="#E5E5E5"> of how the</font>

374
00:15:47,079 --> 00:15:53,050
fingerprinting attack works and also our

375
00:15:50,800 --> 00:15:55,508
code and<font color="#CCCCCC"> pre tree</font><font color="#E5E5E5"> models and data sets</font>

376
00:15:53,050 --> 00:15:57,339
<font color="#E5E5E5">are all available on github so</font><font color="#CCCCCC"> feel free</font>

377
00:15:55,509 --> 00:16:11,910
to try it out<font color="#CCCCCC"> and</font><font color="#E5E5E5"> with that I'll</font>

378
00:15:57,339 --> 00:16:11,910
conclude my top good time<font color="#E5E5E5"> for questions</font>

379
00:16:15,449 --> 00:16:21,248
<font color="#CCCCCC">John John from C Spire so</font><font color="#E5E5E5"> your your</font>

380
00:16:19,059 --> 00:16:23,439
attack is<font color="#E5E5E5"> focused on the other examples</font>

381
00:16:21,249 --> 00:16:24,910
and so<font color="#E5E5E5"> how do our actually try to</font>

382
00:16:23,439 --> 00:16:27,488
generalize<font color="#E5E5E5"> your attack to other kind of</font>

383
00:16:24,910 --> 00:16:29,319
that<font color="#CCCCCC"> text our kids machine models such</font>

384
00:16:27,489 --> 00:16:33,129
as the<font color="#CCCCCC"> membership in France are</font><font color="#E5E5E5"> multi</font>

385
00:16:29,319 --> 00:16:35,199
<font color="#E5E5E5">inversion or</font><font color="#CCCCCC"> mode of stealing uh you</font>

386
00:16:33,129 --> 00:16:36,850
mean other<font color="#CCCCCC"> domains</font><font color="#E5E5E5"> so yeah</font><font color="#CCCCCC"> other</font><font color="#E5E5E5"> are the</font>

387
00:16:35,199 --> 00:16:38,649
kind<font color="#CCCCCC"> of attacks because generally these</font>

388
00:16:36,850 --> 00:16:41,019
<font color="#CCCCCC">tests</font><font color="#E5E5E5"> for learning is actually</font><font color="#CCCCCC"> a</font><font color="#E5E5E5"> general</font>

389
00:16:38,649 --> 00:16:44,019
pardon<font color="#E5E5E5"> but actually</font><font color="#CCCCCC"> what other type of</font>

390
00:16:41,019 --> 00:16:46,660
attack so this work is<font color="#E5E5E5"> mainly focused on</font>

391
00:16:44,019 --> 00:16:48,790
a<font color="#CCCCCC"> dessert</font><font color="#E5E5E5"> hat in deploying so we haven't</font>

392
00:16:46,660 --> 00:16:51,429
<font color="#E5E5E5">tried we haven't look into other types</font>

393
00:16:48,790 --> 00:16:55,269
<font color="#E5E5E5">of attack yet so but that's there'll be</font>

394
00:16:51,429 --> 00:16:59,110
a very<font color="#E5E5E5"> interesting follow-up work hi</font>

395
00:16:55,269 --> 00:17:01,240
Michael Clifford noblesse so when we

396
00:16:59,110 --> 00:17:03,790
look into<font color="#CCCCCC"> datasets</font><font color="#E5E5E5"> that we could apply</font>

397
00:17:01,240 --> 00:17:06,789
to two problems for machine learning<font color="#CCCCCC"> we</font>

398
00:17:03,790 --> 00:17:09,490
find that there aren't publicly

399
00:17:06,789 --> 00:17:11,500
available<font color="#E5E5E5"> datasets that are useful for a</font>

400
00:17:09,490 --> 00:17:12,849
lot<font color="#CCCCCC"> of security problems so rather than</font>

401
00:17:11,500 --> 00:17:14,439
<font color="#CCCCCC">attacking the data set if you want to</font>

402
00:17:12,849 --> 00:17:16,000
train on something for a security

403
00:17:14,439 --> 00:17:18,850
problem we<font color="#E5E5E5"> find that there's not really</font>

404
00:17:16,000 --> 00:17:21,369
<font color="#CCCCCC">a lot</font><font color="#E5E5E5"> out there have you found anything</font>

405
00:17:18,849 --> 00:17:26,770
<font color="#E5E5E5">that might be</font><font color="#CCCCCC"> useful</font><font color="#E5E5E5"> for security</font>

406
00:17:21,369 --> 00:17:30,399
related<font color="#CCCCCC"> machine learning problems so I</font>

407
00:17:26,770 --> 00:17:32,830
have not because so<font color="#CCCCCC"> okay so this paper</font>

408
00:17:30,399 --> 00:17:35,979
<font color="#E5E5E5">all the</font><font color="#CCCCCC"> data</font><font color="#E5E5E5"> sets</font><font color="#CCCCCC"> using newspaper are</font>

409
00:17:32,830 --> 00:17:37,720
<font color="#CCCCCC">mainly</font><font color="#E5E5E5"> about image classification</font><font color="#CCCCCC"> so I'm</font>

410
00:17:35,980 --> 00:17:40,000
really<font color="#E5E5E5"> sorry that</font><font color="#CCCCCC"> we didn't find</font><font color="#E5E5E5"> a</font><font color="#CCCCCC"> lot</font>

411
00:17:37,720 --> 00:17:44,370
of<font color="#E5E5E5"> security related data sets out there</font>

412
00:17:40,000 --> 00:17:44,370
but I would definitely<font color="#CCCCCC"> look it up</font>

413
00:17:46,850 --> 00:17:52,139
<font color="#E5E5E5">I'm I'm from the</font><font color="#CCCCCC"> University of South</font>

414
00:17:49,920 --> 00:17:55,560
Florida<font color="#CCCCCC"> I have an unquestionable what</font>

415
00:17:52,140 --> 00:17:57,900
about this the the defense you used in

416
00:17:55,560 --> 00:18:02,790
the for the the distance between the

417
00:17:57,900 --> 00:18:05,490
<font color="#E5E5E5">regional and</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> the crafted samples how</font>

418
00:18:02,790 --> 00:18:07,520
did you decide<font color="#CCCCCC"> the distance</font><font color="#E5E5E5"> this this</font>

419
00:18:05,490 --> 00:18:10,460
kind of made<font color="#E5E5E5"> shape do you have any like</font>

420
00:18:07,520 --> 00:18:14,100
solutions for how to choose the distance

421
00:18:10,460 --> 00:18:17,280
right so the<font color="#E5E5E5"> question is about this</font>

422
00:18:14,100 --> 00:18:19,530
parameter we use for defense<font color="#E5E5E5"> so so that</font>

423
00:18:17,280 --> 00:18:21,600
parameter<font color="#CCCCCC"> I showed you in the equation</font>

424
00:18:19,530 --> 00:18:23,820
<font color="#CCCCCC">that one controls how much difference</font>

425
00:18:21,600 --> 00:18:26,310
you want<font color="#CCCCCC"> between the student and</font><font color="#E5E5E5"> teacher</font>

426
00:18:23,820 --> 00:18:29,850
<font color="#CCCCCC">so in general the larger</font><font color="#E5E5E5"> the better</font>

427
00:18:26,310 --> 00:18:33,450
means more secure<font color="#E5E5E5"> when you choose the</font>

428
00:18:29,850 --> 00:18:38,520
larger then maybe the the transfer

429
00:18:33,450 --> 00:18:41,340
<font color="#CCCCCC">knowning the first process the</font><font color="#E5E5E5"> accuracy</font>

430
00:18:38,520 --> 00:18:45,030
will be decreased I think yeah<font color="#E5E5E5"> right so</font>

431
00:18:41,340 --> 00:18:48,540
I was<font color="#E5E5E5"> about</font><font color="#CCCCCC"> you have a higher accuracy</font>

432
00:18:45,030 --> 00:18:50,280
of the transfer<font color="#E5E5E5"> no name but but yeah on</font>

433
00:18:48,540 --> 00:18:53,790
the other<font color="#CCCCCC"> side</font><font color="#E5E5E5"> well it might be like</font>

434
00:18:50,280 --> 00:18:56,850
decreasing right so the general trend we

435
00:18:53,790 --> 00:18:59,250
saw was when<font color="#E5E5E5"> you use larger threshold</font>

436
00:18:56,850 --> 00:19:01,350
<font color="#E5E5E5">you will have more robust models it will</font>

437
00:18:59,250 --> 00:19:03,750
have<font color="#E5E5E5"> a little more a little</font><font color="#CCCCCC"> bit more</font>

438
00:19:01,350 --> 00:19:05,969
impact<font color="#E5E5E5"> on a model classification but as</font>

439
00:19:03,750 --> 00:19:08,730
I showed you<font color="#CCCCCC"> before this impact is</font>

440
00:19:05,970 --> 00:19:11,790
really<font color="#E5E5E5"> small comparing to other defense</font>

441
00:19:08,730 --> 00:19:14,810
methods we test it<font color="#E5E5E5"> so you just in your</font>

442
00:19:11,790 --> 00:19:17,270
paper<font color="#E5E5E5"> you just choose them randomly</font><font color="#CCCCCC"> or</font>

443
00:19:14,810 --> 00:19:20,639
so in our paper we tested different

444
00:19:17,270 --> 00:19:22,500
thresholds<font color="#E5E5E5"> and in practice when the user</font>

445
00:19:20,640 --> 00:19:24,720
is actually trying to pick one<font color="#E5E5E5"> well you</font>

446
00:19:22,500 --> 00:19:27,180
can what they can do is<font color="#E5E5E5"> they can set the</font>

447
00:19:24,720 --> 00:19:30,120
tolerance for model performance drop

448
00:19:27,180 --> 00:19:32,340
they they can tolerate<font color="#E5E5E5"> and try to</font>

449
00:19:30,120 --> 00:19:34,379
improve increase the threshold<font color="#E5E5E5"> until</font>

450
00:19:32,340 --> 00:19:36,240
they hit that<font color="#E5E5E5"> point so then they will</font>

451
00:19:34,380 --> 00:19:38,360
have<font color="#CCCCCC"> a guaranteed</font><font color="#E5E5E5"> performance model and</font>

452
00:19:36,240 --> 00:19:46,500
then they'll have<font color="#E5E5E5"> more robust models</font>

453
00:19:38,360 --> 00:19:48,990
thank you<font color="#CCCCCC"> hi from Johns Hopkins</font>

454
00:19:46,500 --> 00:19:51,750
<font color="#E5E5E5">University</font><font color="#CCCCCC"> I have question about</font><font color="#E5E5E5"> the</font>

455
00:19:48,990 --> 00:19:53,790
features extractor you have used for

456
00:19:51,750 --> 00:19:56,940
<font color="#E5E5E5">transfer learning so what if we find</font>

457
00:19:53,790 --> 00:19:58,730
turn the<font color="#E5E5E5"> feature chapter so for example</font>

458
00:19:56,940 --> 00:20:01,230
when you do find

459
00:19:58,730 --> 00:20:03,809
<font color="#CCCCCC">you you're</font><font color="#E5E5E5"> currently only</font><font color="#CCCCCC"> fine</font><font color="#E5E5E5"> to me</font>

460
00:20:01,230 --> 00:20:06,240
last several<font color="#E5E5E5"> years so how about you find</font>

461
00:20:03,809 --> 00:20:08,908
in the<font color="#E5E5E5"> entire model what will happen</font>

462
00:20:06,240 --> 00:20:11,730
<font color="#E5E5E5">right</font><font color="#CCCCCC"> so the</font><font color="#E5E5E5"> question is about what if</font>

463
00:20:08,909 --> 00:20:15,809
you don't just find<font color="#E5E5E5"> you in last layer</font>

464
00:20:11,730 --> 00:20:17,610
but yes instead<font color="#CCCCCC"> so we actually</font><font color="#E5E5E5"> analyzed</font>

465
00:20:15,809 --> 00:20:20,190
that<font color="#E5E5E5"> transfer learning approaching the</font>

466
00:20:17,610 --> 00:20:22,379
paper<font color="#E5E5E5"> so what we found is</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> this will</font>

467
00:20:20,190 --> 00:20:23,909
make the model<font color="#CCCCCC"> roll more</font><font color="#E5E5E5"> robust against</font>

468
00:20:22,380 --> 00:20:25,500
this the type of<font color="#CCCCCC"> tack because</font><font color="#E5E5E5"> you are</font>

469
00:20:23,909 --> 00:20:27,480
modifying<font color="#E5E5E5"> the model more so it's more</font>

470
00:20:25,500 --> 00:20:30,029
<font color="#E5E5E5">different from the teacher but the</font>

471
00:20:27,480 --> 00:20:32,429
difficulty here is<font color="#CCCCCC"> that this</font><font color="#E5E5E5"> approach</font>

472
00:20:30,029 --> 00:20:33,990
also<font color="#E5E5E5"> requires a lot more</font><font color="#CCCCCC"> data</font><font color="#E5E5E5"> to train a</font>

473
00:20:32,429 --> 00:20:36,120
model<font color="#E5E5E5"> because you're not only training</font>

474
00:20:33,990 --> 00:20:39,690
<font color="#E5E5E5">one layer but the the entire model</font>

475
00:20:36,120 --> 00:20:42,000
instead so this will<font color="#E5E5E5"> pull harder a lot</font>

476
00:20:39,690 --> 00:20:51,020
<font color="#E5E5E5">more requirements on the data and the</font>

477
00:20:42,000 --> 00:20:55,529
<font color="#E5E5E5">permutation resource for the user</font><font color="#CCCCCC"> okay I</font>

478
00:20:51,020 --> 00:21:02,370
have<font color="#E5E5E5"> one so did you consider an adaptive</font>

479
00:20:55,529 --> 00:21:04,649
adversary defense right<font color="#CCCCCC"> so we thought</font>

480
00:21:02,370 --> 00:21:08,850
about<font color="#E5E5E5"> countermeasures from the attacker</font>

481
00:21:04,649 --> 00:21:12,389
side and I this<font color="#E5E5E5"> is one smaller point I</font>

482
00:21:08,850 --> 00:21:14,520
<font color="#CCCCCC">mentioned before is that</font><font color="#E5E5E5"> the when you do</font>

483
00:21:12,390 --> 00:21:17,909
defense<font color="#E5E5E5"> you are modifying the student</font>

484
00:21:14,520 --> 00:21:19,559
using your<font color="#E5E5E5"> student data set so when</font>

485
00:21:17,909 --> 00:21:22,289
you're modifying<font color="#E5E5E5"> a student the attacker</font>

486
00:21:19,559 --> 00:21:24,928
<font color="#E5E5E5">cannot know what kind of modification</font>

487
00:21:22,289 --> 00:21:26,789
and<font color="#CCCCCC"> do</font><font color="#E5E5E5"> to the entire model so this part</font>

488
00:21:24,929 --> 00:21:28,950
is<font color="#E5E5E5"> unpredictable</font><font color="#CCCCCC"> so that means the</font>

489
00:21:26,789 --> 00:21:31,470
attacker<font color="#E5E5E5"> cannot reproduce the process</font>

490
00:21:28,950 --> 00:21:34,710
and so<font color="#CCCCCC"> there's</font><font color="#E5E5E5"> it's really hard to do</font>

491
00:21:31,470 --> 00:21:37,429
combination let's let's thank the

492
00:21:34,710 --> 00:21:37,429
speaker once again

