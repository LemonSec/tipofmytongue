1
00:00:11,560 --> 00:00:15,590
hi<font color="#E5E5E5"> everyone</font>

2
00:00:13,190 --> 00:00:18,820
I'm Karen<font color="#E5E5E5"> from Indiana University</font><font color="#CCCCCC"> and</font>

3
00:00:15,590 --> 00:00:22,009
I'm<font color="#CCCCCC"> be I'm happy to be</font><font color="#E5E5E5"> here to present</font>

4
00:00:18,820 --> 00:00:25,759
this paper<font color="#CCCCCC"> and this</font><font color="#E5E5E5"> is paper has</font><font color="#CCCCCC"> been</font>

5
00:00:22,010 --> 00:00:33,079
<font color="#CCCCCC">iced down by independently by Indiana</font>

6
00:00:25,759 --> 00:00:37,150
<font color="#E5E5E5">University</font><font color="#CCCCCC"> and let's</font><font color="#E5E5E5"> get started</font><font color="#CCCCCC"> so this</font>

7
00:00:33,079 --> 00:00:40,280
<font color="#CCCCCC">is a cold</font><font color="#E5E5E5"> cold or you may call it coke</font>

8
00:00:37,150 --> 00:00:42,430
<font color="#E5E5E5">coke is a well-known</font><font color="#CCCCCC"> codename for</font>

9
00:00:40,280 --> 00:00:45,530
coca-cola<font color="#E5E5E5"> but it has another</font>

10
00:00:42,430 --> 00:00:51,680
<font color="#E5E5E5">lesser-known meaning which refers to an</font>

11
00:00:45,530 --> 00:00:55,040
illicit product<font color="#E5E5E5"> cocaine as another</font>

12
00:00:51,680 --> 00:00:58,550
<font color="#CCCCCC">example</font><font color="#E5E5E5"> on blueberry also has an illicit</font>

13
00:00:55,040 --> 00:01:01,730
meaning it actually refers<font color="#CCCCCC"> to a kind of</font>

14
00:00:58,550 --> 00:01:06,798
marijuana that<font color="#CCCCCC"> has the flavor of</font>

15
00:01:01,730 --> 00:01:10,250
blueberry<font color="#E5E5E5"> according to the drug users so</font>

16
00:01:06,799 --> 00:01:13,490
one more<font color="#CCCCCC"> example</font><font color="#E5E5E5"> so this is red also</font>

17
00:01:10,250 --> 00:01:15,170
known as<font color="#CCCCCC"> remote-access children and you</font>

18
00:01:13,490 --> 00:01:16,850
must be<font color="#CCCCCC"> very</font><font color="#E5E5E5"> familiar with this concept</font>

19
00:01:15,170 --> 00:01:20,899
<font color="#CCCCCC">because you are also</font><font color="#E5E5E5"> creative</font>

20
00:01:16,850 --> 00:01:23,149
researchers and but<font color="#E5E5E5"> used to remember</font>

21
00:01:20,899 --> 00:01:25,960
that<font color="#E5E5E5"> fred has</font><font color="#CCCCCC"> an auditor meaning</font><font color="#E5E5E5"> to</font>

22
00:01:23,149 --> 00:01:34,640
ordinary people<font color="#CCCCCC"> it means</font><font color="#E5E5E5"> a kind of mouse</font>

23
00:01:25,960 --> 00:01:38,149
so such was as rat blueberry yeah red

24
00:01:34,640 --> 00:01:40,759
blueberry<font color="#E5E5E5"> and coke unknown as jargons</font>

25
00:01:38,149 --> 00:01:42,319
<font color="#E5E5E5">they have an ordinary meaning to</font>

26
00:01:40,759 --> 00:01:45,649
<font color="#CCCCCC">ordering people</font><font color="#E5E5E5"> but they have very</font>

27
00:01:42,319 --> 00:01:47,990
<font color="#E5E5E5">different meaning to</font><font color="#CCCCCC"> a small</font><font color="#E5E5E5"> group of</font>

28
00:01:45,649 --> 00:01:50,840
particular<font color="#CCCCCC"> people really use being a</font>

29
00:01:47,990 --> 00:01:54,139
very special occasion such as<font color="#CCCCCC"> they're</font>

30
00:01:50,840 --> 00:01:57,770
used in<font color="#E5E5E5"> the underground forums in fact</font>

31
00:01:54,139 --> 00:02:02,780
those jargons are extensively used<font color="#E5E5E5"> in</font>

32
00:01:57,770 --> 00:02:04,880
<font color="#E5E5E5">the underground forums by a lot of cyber</font>

33
00:02:02,780 --> 00:02:07,990
criminals<font color="#CCCCCC"> for different reasons and</font>

34
00:02:04,880 --> 00:02:11,450
regardless<font color="#E5E5E5"> of those reason they actually</font>

35
00:02:07,990 --> 00:02:14,420
becomes an obstacle<font color="#E5E5E5"> for</font><font color="#CCCCCC"> the security</font>

36
00:02:11,450 --> 00:02:18,379
researchers to understand those dark

37
00:02:14,420 --> 00:02:20,420
forums on<font color="#E5E5E5"> automatically or manually so</font>

38
00:02:18,379 --> 00:02:23,000
we are<font color="#E5E5E5"> going to address this problem</font>

39
00:02:20,420 --> 00:02:26,420
<font color="#E5E5E5">today I'm going to present</font>

40
00:02:23,000 --> 00:02:30,530
this unsupervised<font color="#E5E5E5"> tool called</font><font color="#CCCCCC"> count</font>

41
00:02:26,420 --> 00:02:33,950
<font color="#E5E5E5">reader which is able to not only detect</font>

42
00:02:30,530 --> 00:02:35,860
<font color="#E5E5E5">but also understand</font><font color="#CCCCCC"> the dark jargons</font>

43
00:02:33,950 --> 00:02:41,269
from<font color="#E5E5E5"> the underground forums</font>

44
00:02:35,860 --> 00:02:45,440
automatically let's begin with the sorry

45
00:02:41,270 --> 00:02:48,100
<font color="#CCCCCC">let's</font><font color="#E5E5E5"> begin with the detection so the</font>

46
00:02:45,440 --> 00:02:51,590
key idea<font color="#CCCCCC"> of our detecting is to</font>

47
00:02:48,100 --> 00:02:54,260
investigate<font color="#E5E5E5"> the semantics auditory the</font>

48
00:02:51,590 --> 00:02:56,420
context of<font color="#E5E5E5"> dragons since those</font>

49
00:02:54,260 --> 00:02:59,780
communication traces are partially

50
00:02:56,420 --> 00:03:01,579
obfuscated<font color="#E5E5E5"> in underground forums so we</font>

51
00:02:59,780 --> 00:03:03,440
cannot look into<font color="#E5E5E5"> those keywords</font>

52
00:03:01,580 --> 00:03:06,890
themselves because they're replaced with

53
00:03:03,440 --> 00:03:09,489
<font color="#CCCCCC">dragons</font><font color="#E5E5E5"> but luckily not every words are</font>

54
00:03:06,890 --> 00:03:12,529
<font color="#E5E5E5">replaced so we still have the chance</font><font color="#CCCCCC"> to</font>

55
00:03:09,489 --> 00:03:15,290
<font color="#E5E5E5">investigate the context and previous</font>

56
00:03:12,530 --> 00:03:19,610
research<font color="#CCCCCC"> has shown that context</font><font color="#E5E5E5"> equal to</font>

57
00:03:15,290 --> 00:03:22,600
semantics<font color="#E5E5E5"> so we can actually find useful</font>

58
00:03:19,610 --> 00:03:26,630
<font color="#E5E5E5">clues of jargons from their context</font>

59
00:03:22,600 --> 00:03:30,230
let's look<font color="#E5E5E5"> at some example so this</font><font color="#CCCCCC"> is a</font>

60
00:03:26,630 --> 00:03:32,720
jargon what<font color="#CCCCCC"> rat</font><font color="#E5E5E5"> it's</font><font color="#CCCCCC"> boots</font><font color="#E5E5E5"> used in two</font>

61
00:03:30,230 --> 00:03:35,030
<font color="#CCCCCC">different cement scenarios with two</font>

62
00:03:32,720 --> 00:03:40,370
<font color="#E5E5E5">different meanings</font><font color="#CCCCCC"> the first one is used</font>

63
00:03:35,030 --> 00:03:42,079
with the<font color="#CCCCCC"> chaga meaning in the context we</font>

64
00:03:40,370 --> 00:03:45,530
see<font color="#E5E5E5"> some interesting words such as</font>

65
00:03:42,079 --> 00:03:48,920
<font color="#CCCCCC">open-source</font><font color="#E5E5E5"> rootkit or implement but one</font>

66
00:03:45,530 --> 00:03:52,340
rat<font color="#E5E5E5"> is used normally with the meaning of</font>

67
00:03:48,920 --> 00:03:55,880
<font color="#CCCCCC">Mouse the context</font><font color="#E5E5E5"> shows some words like</font>

68
00:03:52,340 --> 00:04:01,130
animal therapy<font color="#E5E5E5"> or walking this shows</font>

69
00:03:55,880 --> 00:04:03,380
that we indeed can find on this context

70
00:04:01,130 --> 00:04:05,620
difference when a same word<font color="#CCCCCC"> are used</font>

71
00:04:03,380 --> 00:04:08,959
with<font color="#E5E5E5"> different semantics</font>

72
00:04:05,620 --> 00:04:12,410
therefore if a word is<font color="#CCCCCC"> used as a</font><font color="#E5E5E5"> top</font>

73
00:04:08,959 --> 00:04:14,739
jargon<font color="#E5E5E5"> in underground forum</font><font color="#CCCCCC"> at contacts</font>

74
00:04:12,410 --> 00:04:19,070
in that forum should be different<font color="#E5E5E5"> from</font>

75
00:04:14,739 --> 00:04:21,370
<font color="#E5E5E5">that</font><font color="#CCCCCC"> used in illegitimate</font><font color="#E5E5E5"> communication</font>

76
00:04:19,070 --> 00:04:24,669
traces and this is how we are going<font color="#E5E5E5"> to</font>

77
00:04:21,370 --> 00:04:29,060
<font color="#E5E5E5">detect up</font><font color="#CCCCCC"> jargons</font><font color="#E5E5E5"> so we need a tool to</font>

78
00:04:24,669 --> 00:04:31,190
extract<font color="#E5E5E5"> the contact information</font><font color="#CCCCCC"> of the</font>

79
00:04:29,060 --> 00:04:35,500
<font color="#CCCCCC">word and directly use this information</font>

80
00:04:31,190 --> 00:04:40,600
to do the<font color="#E5E5E5"> computer semantic comparison</font>

81
00:04:35,500 --> 00:04:43,500
so here comes what<font color="#E5E5E5"> to vector what to</font>

82
00:04:40,600 --> 00:04:49,210
vector is a<font color="#CCCCCC"> what embedding technique</font>

83
00:04:43,500 --> 00:04:51,490
<font color="#CCCCCC">proposed by Thomas McClure in 2013 it's</font>

84
00:04:49,210 --> 00:04:54,430
really cool it's used a two-layer

85
00:04:51,490 --> 00:04:58,480
shallow neural network<font color="#E5E5E5"> and to perform a</font>

86
00:04:54,430 --> 00:05:00,430
fake task<font color="#E5E5E5"> the fake</font><font color="#CCCCCC"> tax is to predict</font><font color="#E5E5E5"> the</font>

87
00:04:58,480 --> 00:05:02,110
language<font color="#E5E5E5"> model so if you are not</font>

88
00:05:00,430 --> 00:05:05,320
<font color="#E5E5E5">familiar with language model you just</font>

89
00:05:02,110 --> 00:05:08,260
think it's<font color="#E5E5E5"> and the neural network is</font>

90
00:05:05,320 --> 00:05:12,370
used to predict<font color="#E5E5E5"> the context of the input</font>

91
00:05:08,260 --> 00:05:15,250
world the<font color="#E5E5E5"> idea is pretty like the auto</font>

92
00:05:12,370 --> 00:05:18,100
encoder<font color="#CCCCCC"> the first layer of your network</font>

93
00:05:15,250 --> 00:05:21,400
is used to extract features from<font color="#CCCCCC"> the</font>

94
00:05:18,100 --> 00:05:23,650
<font color="#CCCCCC">import</font><font color="#E5E5E5"> corpus and these features are</font>

95
00:05:21,400 --> 00:05:26,799
then used by the second layer of neural

96
00:05:23,650 --> 00:05:32,919
network to reconstruct the<font color="#CCCCCC"> original data</font>

97
00:05:26,800 --> 00:05:36,370
which is language<font color="#E5E5E5"> model so once the</font>

98
00:05:32,919 --> 00:05:38,200
training<font color="#E5E5E5"> is finished</font><font color="#CCCCCC"> we just</font><font color="#E5E5E5"> ignore the</font>

99
00:05:36,370 --> 00:05:41,950
<font color="#E5E5E5">language</font><font color="#CCCCCC"> model part we just</font><font color="#E5E5E5"> ignore the</font>

100
00:05:38,200 --> 00:05:44,349
second layer<font color="#E5E5E5"> and we use the features</font>

101
00:05:41,950 --> 00:05:48,219
extracted by the<font color="#E5E5E5"> first layer as embedded</font>

102
00:05:44,350 --> 00:05:50,410
vectors<font color="#E5E5E5"> and it shows really interest I</font>

103
00:05:48,220 --> 00:05:52,300
<font color="#CCCCCC">mean the embed vectors showed very</font>

104
00:05:50,410 --> 00:05:54,580
interesting properties<font color="#E5E5E5"> well</font><font color="#CCCCCC"> of the</font>

105
00:05:52,300 --> 00:05:57,669
property is<font color="#E5E5E5"> that those vectors are</font>

106
00:05:54,580 --> 00:06:00,520
comparable here<font color="#E5E5E5"> we say</font><font color="#CCCCCC"> two that are two</font>

107
00:05:57,669 --> 00:06:04,750
<font color="#E5E5E5">vectors are comparable we mean that we</font>

108
00:06:00,520 --> 00:06:06,969
<font color="#CCCCCC">can use the difference of the vector for</font>

109
00:06:04,750 --> 00:06:09,790
example cosine distance of better to

110
00:06:06,970 --> 00:06:15,160
estimate the semantic difference of the

111
00:06:09,790 --> 00:06:17,860
two input<font color="#CCCCCC"> wards so this is very</font>

112
00:06:15,160 --> 00:06:21,010
promising<font color="#E5E5E5"> property and it seems that we</font>

113
00:06:17,860 --> 00:06:25,330
can already<font color="#E5E5E5"> use this property</font><font color="#CCCCCC"> to find</font>

114
00:06:21,010 --> 00:06:28,450
<font color="#E5E5E5">the dark jargons the idea is is</font><font color="#CCCCCC"> to do</font>

115
00:06:25,330 --> 00:06:32,340
the differential analysis so we have<font color="#CCCCCC"> two</font>

116
00:06:28,450 --> 00:06:35,860
<font color="#CCCCCC">forums</font><font color="#E5E5E5"> out to copper one</font><font color="#CCCCCC"> is from the</font>

117
00:06:32,340 --> 00:06:38,560
dark underground<font color="#E5E5E5"> forums and wines from</font>

118
00:06:35,860 --> 00:06:41,080
<font color="#E5E5E5">the B'nai forum for example</font><font color="#CCCCCC"> reddit so we</font>

119
00:06:38,560 --> 00:06:43,960
<font color="#E5E5E5">train to what you've act models from</font>

120
00:06:41,080 --> 00:06:47,890
which<font color="#E5E5E5"> the two</font><font color="#CCCCCC"> kapre and that we get two</font>

121
00:06:43,960 --> 00:06:48,840
sets<font color="#E5E5E5"> of vectors so for each word appear</font>

122
00:06:47,890 --> 00:06:51,750
in the

123
00:06:48,840 --> 00:06:55,888
<font color="#CCCCCC">khakhra</font><font color="#E5E5E5"> it is associate with two vectors</font>

124
00:06:51,750 --> 00:06:58,040
each trained from one of the model then

125
00:06:55,889 --> 00:07:02,520
we<font color="#CCCCCC"> can compare the cosine distance</font><font color="#E5E5E5"> of</font>

126
00:06:58,040 --> 00:07:04,530
the<font color="#E5E5E5"> two vectors</font><font color="#CCCCCC"> and if the</font><font color="#E5E5E5"> ward does</font>

127
00:07:02,520 --> 00:07:07,409
show different semantics<font color="#E5E5E5"> in the two</font>

128
00:07:04,530 --> 00:07:09,989
<font color="#CCCCCC">kapre that the vector should be</font><font color="#E5E5E5"> very</font>

129
00:07:07,410 --> 00:07:13,020
<font color="#CCCCCC">different so we</font><font color="#E5E5E5"> can see there is a large</font>

130
00:07:09,990 --> 00:07:16,889
cosine<font color="#CCCCCC"> distance but there is one problem</font>

131
00:07:13,020 --> 00:07:19,650
<font color="#E5E5E5">is the vector generated from the two</font>

132
00:07:16,889 --> 00:07:22,440
<font color="#E5E5E5">different two separately trim the what</font>

133
00:07:19,650 --> 00:07:25,940
effect models comparable<font color="#E5E5E5"> what direct</font>

134
00:07:22,440 --> 00:07:28,770
only guarantee that<font color="#CCCCCC"> q</font><font color="#E5E5E5"> vector from the</font>

135
00:07:25,940 --> 00:07:31,620
same model comparable<font color="#E5E5E5"> but there is no</font>

136
00:07:28,770 --> 00:07:33,900
proof that<font color="#CCCCCC"> it</font><font color="#E5E5E5"> is comparable for two</font>

137
00:07:31,620 --> 00:07:38,760
different<font color="#E5E5E5"> models</font><font color="#CCCCCC"> so we are going</font><font color="#E5E5E5"> to</font>

138
00:07:33,900 --> 00:07:42,989
investigate<font color="#CCCCCC"> with an experiment</font><font color="#E5E5E5"> so we</font>

139
00:07:38,760 --> 00:07:45,030
replace the input<font color="#CCCCCC"> copra both with the</font>

140
00:07:42,990 --> 00:07:47,880
smoke of<font color="#E5E5E5"> a capsid which is a subset</font><font color="#CCCCCC"> of</font>

141
00:07:45,030 --> 00:07:50,880
Wikipedia so that means we'll treat<font color="#CCCCCC"> few</font>

142
00:07:47,880 --> 00:07:54,810
models with the same<font color="#E5E5E5"> Cobra</font><font color="#CCCCCC"> on</font><font color="#E5E5E5"> the same</font>

143
00:07:50,880 --> 00:07:59,969
<font color="#CCCCCC">copies so that we get two sets of</font>

144
00:07:54,810 --> 00:08:02,550
vectors<font color="#E5E5E5"> and since each water since</font><font color="#CCCCCC"> the</font>

145
00:07:59,970 --> 00:08:05,970
coppers is the same so each<font color="#CCCCCC"> word should</font>

146
00:08:02,550 --> 00:08:08,789
<font color="#E5E5E5">have exact same context in the</font><font color="#CCCCCC"> true</font>

147
00:08:05,970 --> 00:08:13,139
model<font color="#E5E5E5"> so that</font><font color="#CCCCCC"> means that generated</font>

148
00:08:08,789 --> 00:08:16,320
vectors should be and should<font color="#CCCCCC"> be same</font><font color="#E5E5E5"> if</font>

149
00:08:13,139 --> 00:08:18,870
we can use this<font color="#CCCCCC"> actress</font><font color="#E5E5E5"> to do the</font>

150
00:08:16,320 --> 00:08:21,780
<font color="#E5E5E5">Samaritan semantic comparison</font><font color="#CCCCCC"> that means</font>

151
00:08:18,870 --> 00:08:24,690
the<font color="#CCCCCC"> cosine similarity of the two vectors</font>

152
00:08:21,780 --> 00:08:27,570
should<font color="#E5E5E5"> be close to one however our</font>

153
00:08:24,690 --> 00:08:31,530
<font color="#CCCCCC">experiments shows that the cosine</font>

154
00:08:27,570 --> 00:08:34,349
similarity is close to 0.5<font color="#E5E5E5"> which is far</font>

155
00:08:31,530 --> 00:08:36,900
from<font color="#E5E5E5"> 1 indicating that we cannot use</font><font color="#CCCCCC"> the</font>

156
00:08:34,349 --> 00:08:41,240
original<font color="#E5E5E5"> or</font><font color="#CCCCCC"> the tracked models for this</font>

157
00:08:36,900 --> 00:08:41,240
cross corpus semantic comparison<font color="#E5E5E5"> task</font>

158
00:08:43,760 --> 00:08:51,170
but<font color="#E5E5E5"> we're still</font><font color="#CCCCCC"> very</font><font color="#E5E5E5"> close</font><font color="#CCCCCC"> to</font><font color="#E5E5E5"> our</font>

159
00:08:46,610 --> 00:08:53,150
solution we have the very close to<font color="#CCCCCC"> our</font>

160
00:08:51,170 --> 00:08:55,010
solution<font color="#CCCCCC"> we only need to treat the</font>

161
00:08:53,150 --> 00:08:58,250
orange<font color="#E5E5E5"> and model a little</font><font color="#CCCCCC"> bit to suit</font>

162
00:08:55,010 --> 00:09:01,040
<font color="#E5E5E5">for our</font><font color="#CCCCCC"> tasks and how to do that we need</font>

163
00:08:58,250 --> 00:09:03,800
<font color="#CCCCCC">to dig into the what</font><font color="#E5E5E5"> to vector</font><font color="#CCCCCC"> model a</font>

164
00:09:01,040 --> 00:09:06,079
<font color="#CCCCCC">little bit</font><font color="#E5E5E5"> so here let's see the</font>

165
00:09:03,800 --> 00:09:08,750
prediction stage<font color="#E5E5E5"> and what is inputted</font>

166
00:09:06,080 --> 00:09:12,830
<font color="#CCCCCC">with the one hard encoding</font><font color="#E5E5E5"> that means</font>

167
00:09:08,750 --> 00:09:16,760
<font color="#E5E5E5">it's embed a vector or</font><font color="#CCCCCC"> its hidden</font><font color="#E5E5E5"> layer</font>

168
00:09:12,830 --> 00:09:20,930
state is actually<font color="#CCCCCC"> 1 0 of its input</font>

169
00:09:16,760 --> 00:09:23,360
layers weight matrix W and this embedded

170
00:09:20,930 --> 00:09:27,229
vector is later<font color="#CCCCCC"> used</font><font color="#E5E5E5"> to produce the</font>

171
00:09:23,360 --> 00:09:29,900
<font color="#E5E5E5">final prediction value y so y equals to</font>

172
00:09:27,230 --> 00:09:34,190
<font color="#CCCCCC">X dot W prime where W prime is</font><font color="#E5E5E5"> the</font>

173
00:09:29,900 --> 00:09:37,160
output layers<font color="#E5E5E5"> weight matrix so one</font>

174
00:09:34,190 --> 00:09:40,130
important point here<font color="#E5E5E5"> is that W prime is</font>

175
00:09:37,160 --> 00:09:43,430
<font color="#CCCCCC">actually shared by all the</font><font color="#E5E5E5"> input</font><font color="#CCCCCC"> water Y</font>

176
00:09:40,130 --> 00:09:47,030
<font color="#CCCCCC">or this</font><font color="#E5E5E5"> edge is specific to</font><font color="#CCCCCC"> each</font>

177
00:09:43,430 --> 00:09:50,150
<font color="#E5E5E5">different input world so with that in</font>

178
00:09:47,030 --> 00:09:54,620
mind<font color="#E5E5E5"> we</font><font color="#CCCCCC"> are able</font><font color="#E5E5E5"> to explain this model</font>

179
00:09:50,150 --> 00:09:57,410
in a very intuitively so<font color="#E5E5E5"> if</font><font color="#CCCCCC"> Q</font><font color="#E5E5E5"> words have</font>

180
00:09:54,620 --> 00:09:59,420
<font color="#E5E5E5">similar meanings then they they should</font>

181
00:09:57,410 --> 00:10:04,069
<font color="#E5E5E5">probably have the similar context in the</font>

182
00:09:59,420 --> 00:10:06,740
coppers and if they have the<font color="#E5E5E5"> similar</font>

183
00:10:04,070 --> 00:10:11,960
context then the model should generates

184
00:10:06,740 --> 00:10:15,650
the similar prediction so the prediction

185
00:10:11,960 --> 00:10:18,500
<font color="#E5E5E5">is y y equals</font><font color="#CCCCCC"> h dot double prime</font><font color="#E5E5E5"> where</font><font color="#CCCCCC"> W</font>

186
00:10:15,650 --> 00:10:22,189
prime<font color="#E5E5E5"> is shared by both words and we</font>

187
00:10:18,500 --> 00:10:25,460
<font color="#CCCCCC">note 2 y are equal</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> means the two x</font>

188
00:10:22,190 --> 00:10:27,590
are equal so<font color="#CCCCCC"> that embed vectors R should</font>

189
00:10:25,460 --> 00:10:30,610
<font color="#E5E5E5">be very similar to</font><font color="#CCCCCC"> each</font><font color="#E5E5E5"> other</font><font color="#CCCCCC"> that's why</font>

190
00:10:27,590 --> 00:10:33,620
we can use<font color="#CCCCCC"> the embedded</font><font color="#E5E5E5"> vector to do the</font>

191
00:10:30,610 --> 00:10:39,050
<font color="#CCCCCC">estimation of the semantic difference of</font>

192
00:10:33,620 --> 00:10:42,290
the two vectors now let's look at the

193
00:10:39,050 --> 00:10:45,680
two separate<font color="#CCCCCC"> chain models so we have</font>

194
00:10:42,290 --> 00:10:48,680
<font color="#E5E5E5">four matrix here and let's say if the</font>

195
00:10:45,680 --> 00:10:52,189
two would have the same<font color="#CCCCCC"> minis</font><font color="#E5E5E5"> in two</font>

196
00:10:48,680 --> 00:10:56,310
different<font color="#CCCCCC"> khakhra so they they will have</font>

197
00:10:52,190 --> 00:11:01,290
the same prediction values y1 x2 y2

198
00:10:56,310 --> 00:11:04,649
but we're interesting if<font color="#CCCCCC"> h1 equals 2x -</font>

199
00:11:01,290 --> 00:11:08,790
this actually<font color="#E5E5E5"> depends on if</font><font color="#CCCCCC"> W 1 frame</font>

200
00:11:04,649 --> 00:11:11,819
equal<font color="#E5E5E5"> to W</font><font color="#CCCCCC"> Prime and we find that W 1</font>

201
00:11:08,790 --> 00:11:13,498
<font color="#CCCCCC">prime doesn't equal</font><font color="#E5E5E5"> to W 2 prime always</font>

202
00:11:11,819 --> 00:11:17,389
even<font color="#CCCCCC"> though they are</font><font color="#E5E5E5"> treated with the</font>

203
00:11:13,499 --> 00:11:21,149
<font color="#E5E5E5">same corpus</font><font color="#CCCCCC"> there's</font><font color="#E5E5E5"> some randomness</font>

204
00:11:17,389 --> 00:11:23,459
<font color="#E5E5E5">introduced in the training process not</font>

205
00:11:21,149 --> 00:11:25,980
imagine if the<font color="#E5E5E5"> two model are training</font>

206
00:11:23,459 --> 00:11:28,680
with different corpora<font color="#E5E5E5"> then there's no</font>

207
00:11:25,980 --> 00:11:31,470
<font color="#E5E5E5">guarantee that W 1 prime</font><font color="#CCCCCC"> will equal to W</font>

208
00:11:28,680 --> 00:11:34,229
prime so H 1 doesn't equal to<font color="#E5E5E5"> H 2 that's</font>

209
00:11:31,470 --> 00:11:37,019
why we cannot use two separate<font color="#CCCCCC"> trained</font>

210
00:11:34,230 --> 00:11:41,790
<font color="#E5E5E5">what effect model to do this cross</font>

211
00:11:37,019 --> 00:11:43,290
<font color="#CCCCCC">corpus</font><font color="#E5E5E5"> semantics comparison task but we</font>

212
00:11:41,790 --> 00:11:45,599
find the<font color="#CCCCCC"> key point</font>

213
00:11:43,290 --> 00:11:52,620
<font color="#E5E5E5">it's the output layers</font><font color="#CCCCCC"> weight matrix</font><font color="#E5E5E5"> W</font>

214
00:11:45,600 --> 00:11:56,730
try if we<font color="#E5E5E5"> want to use</font><font color="#CCCCCC"> this embed vector</font>

215
00:11:52,620 --> 00:11:59,730
to do that<font color="#E5E5E5"> semantic estimation we need</font>

216
00:11:56,730 --> 00:12:03,750
those factor to be associated<font color="#E5E5E5"> with the</font>

217
00:11:59,730 --> 00:12:09,300
same out for the layer matrix W<font color="#E5E5E5"> Prime</font>

218
00:12:03,750 --> 00:12:11,990
and that lead to<font color="#E5E5E5"> our solution we want a</font>

219
00:12:09,300 --> 00:12:15,269
pre prime to be shared by two covers so

220
00:12:11,990 --> 00:12:19,379
we keep the<font color="#CCCCCC"> output layer intact but we</font>

221
00:12:15,269 --> 00:12:23,399
double the<font color="#E5E5E5"> input layer then this model</font>

222
00:12:19,379 --> 00:12:26,819
<font color="#E5E5E5">can accept two corpora</font><font color="#CCCCCC"> as the input one</font>

223
00:12:23,399 --> 00:12:29,279
copper is<font color="#E5E5E5"> associate with the left and a</font>

224
00:12:26,819 --> 00:12:32,639
left part<font color="#E5E5E5"> and when</font><font color="#CCCCCC"> associate</font><font color="#E5E5E5"> with the</font>

225
00:12:29,279 --> 00:12:35,759
right part and<font color="#CCCCCC"> that's we get to ink</font>

226
00:12:32,639 --> 00:12:39,509
layer with matrix W 1<font color="#E5E5E5"> W 2 which is equal</font>

227
00:12:35,759 --> 00:12:42,839
<font color="#CCCCCC">to</font><font color="#E5E5E5"> the two sets of embeddable vectors we</font>

228
00:12:39,509 --> 00:12:45,870
generated and since the outer layers

229
00:12:42,839 --> 00:12:49,620
<font color="#CCCCCC">weight matrix are</font><font color="#E5E5E5"> shared by W 1</font><font color="#CCCCCC"> and</font><font color="#E5E5E5"> W 2</font>

230
00:12:45,870 --> 00:12:54,809
that means the<font color="#CCCCCC"> output</font><font color="#E5E5E5"> embed vectors are</font>

231
00:12:49,620 --> 00:12:56,610
mutually comparable we further<font color="#E5E5E5"> show that</font>

232
00:12:54,809 --> 00:12:59,219
with a few experiments<font color="#CCCCCC"> the first</font>

233
00:12:56,610 --> 00:13:02,160
<font color="#E5E5E5">experiments is the same experience</font><font color="#CCCCCC"> we</font>

234
00:12:59,220 --> 00:13:05,129
did with what you<font color="#E5E5E5"> vector but we compared</font>

235
00:13:02,160 --> 00:13:09,870
with our<font color="#CCCCCC"> new semantic comparison model</font>

236
00:13:05,129 --> 00:13:13,140
we<font color="#E5E5E5"> called CSS CM so</font>

237
00:13:09,870 --> 00:13:19,860
trained<font color="#E5E5E5"> SEM with two identical</font><font color="#CCCCCC"> khakhra</font>

238
00:13:13,140 --> 00:13:23,060
<font color="#E5E5E5">text age and we show that the cosine</font>

239
00:13:19,860 --> 00:13:26,370
similarity of the output or<font color="#E5E5E5"> May output</font>

240
00:13:23,060 --> 00:13:31,310
vectors are close to the direct value

241
00:13:26,370 --> 00:13:34,740
<font color="#CCCCCC">one and it</font><font color="#E5E5E5"> has the</font><font color="#CCCCCC"> min</font><font color="#E5E5E5"> value of 0.9 a</font>

242
00:13:31,310 --> 00:13:37,619
the second<font color="#E5E5E5"> experiment is more like</font><font color="#CCCCCC"> our</font>

243
00:13:34,740 --> 00:13:39,960
<font color="#E5E5E5">final task to find the cement earth to</font>

244
00:13:37,620 --> 00:13:42,570
find the<font color="#E5E5E5"> dark jargons but we don't have</font>

245
00:13:39,960 --> 00:13:45,120
<font color="#E5E5E5">the dark jargon syntax a corpus so we</font>

246
00:13:42,570 --> 00:13:47,910
actually craft as such<font color="#CCCCCC"> Jagan's</font><font color="#E5E5E5"> to do</font>

247
00:13:45,120 --> 00:13:50,760
that we replace our random<font color="#E5E5E5"> pick</font><font color="#CCCCCC"> five</font>

248
00:13:47,910 --> 00:13:54,290
words from the text<font color="#CCCCCC"> a copper or coppers</font>

249
00:13:50,760 --> 00:13:56,990
and replace them with spider<font color="#E5E5E5"> and towards</font>

250
00:13:54,290 --> 00:14:00,240
for example will replace<font color="#CCCCCC"> our</font><font color="#E5E5E5"> chemist</font>

251
00:13:56,990 --> 00:14:03,870
with what Archie<font color="#E5E5E5"> then we generated a new</font>

252
00:14:00,240 --> 00:14:06,000
corpus<font color="#E5E5E5"> text a scene so English covers</font>

253
00:14:03,870 --> 00:14:08,730
the<font color="#E5E5E5"> word Archie has two meanings</font>

254
00:14:06,000 --> 00:14:10,650
just like those<font color="#E5E5E5"> jargons one meaning is</font>

255
00:14:08,730 --> 00:14:15,060
its original<font color="#CCCCCC"> meaning</font><font color="#E5E5E5"> Archie and the</font>

256
00:14:10,650 --> 00:14:18,090
<font color="#E5E5E5">other main name is</font><font color="#CCCCCC"> chemists so we use</font>

257
00:14:15,060 --> 00:14:23,010
text<font color="#E5E5E5"> 8 as well as text I've seen to</font>

258
00:14:18,090 --> 00:14:25,800
train our SCM and generate the cosine

259
00:14:23,010 --> 00:14:28,500
similarity of<font color="#E5E5E5"> the five word replacement</font>

260
00:14:25,800 --> 00:14:30,810
<font color="#E5E5E5">it shows that the cosine similarity of</font>

261
00:14:28,500 --> 00:14:34,350
<font color="#E5E5E5">this word are very small compared with</font>

262
00:14:30,810 --> 00:14:37,439
<font color="#E5E5E5">the other words which has the mean value</font>

263
00:14:34,350 --> 00:14:38,790
of 0.98 while those five<font color="#CCCCCC"> world</font>

264
00:14:37,440 --> 00:14:42,990
replacements you really have the

265
00:14:38,790 --> 00:14:48,270
similarity of 0.6 0.7 0.5 not just<font color="#E5E5E5"> a</font>

266
00:14:42,990 --> 00:14:50,900
point<font color="#CCCCCC"> four five</font><font color="#E5E5E5"> or</font><font color="#CCCCCC"> twenty six finally we</font>

267
00:14:48,270 --> 00:14:54,960
<font color="#E5E5E5">use another example</font><font color="#CCCCCC"> to show that our</font>

268
00:14:50,900 --> 00:14:57,329
model generates the vectors with the

269
00:14:54,960 --> 00:15:00,210
same quality of<font color="#E5E5E5"> the original watch</font>

270
00:14:57,330 --> 00:15:03,000
effect model so we train our model with

271
00:15:00,210 --> 00:15:08,250
text<font color="#CCCCCC"> eight plus another dark cop within</font>

272
00:15:03,000 --> 00:15:11,010
<font color="#E5E5E5">dark coppers now and we use the original</font>

273
00:15:08,250 --> 00:15:15,350
what vector<font color="#E5E5E5"> train with the text</font><font color="#CCCCCC"> 8 only</font>

274
00:15:11,010 --> 00:15:19,560
<font color="#CCCCCC">and we make use of the evaluation code</font>

275
00:15:15,350 --> 00:15:22,620
provided by Thomas McAuliffe and compare

276
00:15:19,560 --> 00:15:23,489
the accuracy<font color="#CCCCCC"> of the two model so the</font>

277
00:15:22,620 --> 00:15:25,560
accuracy<font color="#E5E5E5"> is</font>

278
00:15:23,490 --> 00:15:28,709
parable shows that we can generate

279
00:15:25,560 --> 00:15:33,390
<font color="#E5E5E5">comparable quality vectors as the orange</font>

280
00:15:28,709 --> 00:15:35,849
and water effect so now that we approve

281
00:15:33,390 --> 00:15:39,330
that<font color="#CCCCCC"> now that we have proved that our</font>

282
00:15:35,850 --> 00:15:42,950
model works<font color="#E5E5E5"> we can use this model</font><font color="#CCCCCC"> an to</font>

283
00:15:39,330 --> 00:15:45,390
find the dark<font color="#CCCCCC"> dragons</font><font color="#E5E5E5"> so there is a few</font>

284
00:15:42,950 --> 00:15:47,670
implementation issues and I don't<font color="#E5E5E5"> have</font>

285
00:15:45,390 --> 00:15:51,029
<font color="#E5E5E5">time to cover in the talk so please</font>

286
00:15:47,670 --> 00:15:54,540
<font color="#CCCCCC">refer to our paper - for to look</font><font color="#E5E5E5"> at</font>

287
00:15:51,029 --> 00:15:57,600
details so the next step is to

288
00:15:54,540 --> 00:16:00,510
understand those dragons so our<font color="#CCCCCC"> idea is</font>

289
00:15:57,600 --> 00:16:04,500
to<font color="#CCCCCC"> find</font><font color="#E5E5E5"> the hypernym of those detective</font>

290
00:16:00,510 --> 00:16:06,750
jargon<font color="#CCCCCC"> wards in order to do that we</font><font color="#E5E5E5"> are</font>

291
00:16:04,500 --> 00:16:11,010
going<font color="#E5E5E5"> to leverage another interesting</font>

292
00:16:06,750 --> 00:16:14,279
properties of water effect so we find if

293
00:16:11,010 --> 00:16:16,439
we<font color="#E5E5E5"> subtracted backs of men from the back</font>

294
00:16:14,279 --> 00:16:21,029
of<font color="#CCCCCC"> keen the result would be similar to</font>

295
00:16:16,440 --> 00:16:24,779
<font color="#E5E5E5">the subtraction of</font><font color="#CCCCCC"> fact</font><font color="#E5E5E5"> of woman from</font>

296
00:16:21,029 --> 00:16:27,959
vector<font color="#CCCCCC"> king of fact of cream weird men</font>

297
00:16:24,779 --> 00:16:30,959
if the<font color="#E5E5E5"> hyponym of King and woman is the</font>

298
00:16:27,959 --> 00:16:33,899
<font color="#CCCCCC">hypernym of cream so a previous world</font>

299
00:16:30,959 --> 00:16:38,189
makes use of such relation to find a

300
00:16:33,899 --> 00:16:40,680
high pronoun of the<font color="#E5E5E5"> hyponym of</font><font color="#CCCCCC"> water and</font>

301
00:16:38,190 --> 00:16:43,079
we are<font color="#E5E5E5"> going</font><font color="#CCCCCC"> to leverage</font><font color="#E5E5E5"> their work to</font>

302
00:16:40,680 --> 00:16:45,989
find the<font color="#E5E5E5"> hyper norm of a dark jargons</font>

303
00:16:43,079 --> 00:16:50,189
<font color="#E5E5E5">and this is our idea of</font><font color="#CCCCCC"> Jagan</font>

304
00:16:45,990 --> 00:16:55,260
understanding then we<font color="#CCCCCC"> implement our tool</font>

305
00:16:50,190 --> 00:16:58,680
and run it on<font color="#CCCCCC"> four different</font><font color="#E5E5E5"> corpora the</font>

306
00:16:55,260 --> 00:16:59,160
first is Silk Road<font color="#CCCCCC"> it's most famous</font><font color="#E5E5E5"> for</font>

307
00:16:58,680 --> 00:17:01,529
the

308
00:16:59,160 --> 00:17:03,899
attract transaction and the other<font color="#E5E5E5"> story</font>

309
00:17:01,529 --> 00:17:08,550
is<font color="#E5E5E5"> more technical there used to discuss</font>

310
00:17:03,899 --> 00:17:10,770
like cyber criminal<font color="#CCCCCC"> Mara</font><font color="#E5E5E5"> Wells hacking</font>

311
00:17:08,550 --> 00:17:14,428
techniques and so on<font color="#E5E5E5"> from the</font><font color="#CCCCCC"> four</font>

312
00:17:10,770 --> 00:17:18,319
<font color="#E5E5E5">corpora we generate</font><font color="#CCCCCC"> or</font><font color="#E5E5E5"> we extract 1.5</font>

313
00:17:14,429 --> 00:17:22,650
million communication traces containing

314
00:17:18,319 --> 00:17:26,670
117 million words from that<font color="#E5E5E5"> our system</font>

315
00:17:22,650 --> 00:17:29,370
<font color="#E5E5E5">is able to extract 3462 dark jargons</font>

316
00:17:26,670 --> 00:17:31,590
<font color="#E5E5E5">covering five category of illicit</font>

317
00:17:29,370 --> 00:17:36,090
products such as drugs weapons and

318
00:17:31,590 --> 00:17:36,909
points and where drugs<font color="#CCCCCC"> has the most</font>

319
00:17:36,090 --> 00:17:42,340
number

320
00:17:36,910 --> 00:17:44,620
of<font color="#CCCCCC"> dragon wars</font><font color="#E5E5E5"> so we evaluate</font><font color="#CCCCCC"> our system</font>

321
00:17:42,340 --> 00:17:49,179
it shows the precision of point 91

322
00:17:44,620 --> 00:17:53,739
recall of point 77 so we're going to use

323
00:17:49,180 --> 00:17:56,640
our tool so<font color="#E5E5E5"> we know that the DEA Drug</font>

324
00:17:53,740 --> 00:17:59,340
<font color="#E5E5E5">Enforcement Administration is</font>

325
00:17:56,640 --> 00:18:02,260
maintaining a<font color="#E5E5E5"> list of</font><font color="#CCCCCC"> codename of drugs</font>

326
00:17:59,340 --> 00:18:07,870
and<font color="#E5E5E5"> we run our system and we find that</font>

327
00:18:02,260 --> 00:18:11,940
there are<font color="#CCCCCC"> 500 unknown 600 of jargon</font><font color="#E5E5E5"> was</font>

328
00:18:07,870 --> 00:18:14,290
<font color="#CCCCCC">on that are not</font><font color="#E5E5E5"> contained by this list</font>

329
00:18:11,940 --> 00:18:17,830
<font color="#E5E5E5">example of such was</font><font color="#CCCCCC"> a mango or</font>

330
00:18:14,290 --> 00:18:21,540
Cinderella<font color="#E5E5E5"> or piece there are armed</font>

331
00:18:17,830 --> 00:18:24,340
<font color="#E5E5E5">drugs but they are not least rounded</font>

332
00:18:21,540 --> 00:18:26,320
they are not recorded on the list<font color="#E5E5E5"> one</font>

333
00:18:24,340 --> 00:18:28,270
possible reason<font color="#E5E5E5"> in</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> those drugs are</font>

334
00:18:26,320 --> 00:18:31,060
these code names of drugs<font color="#E5E5E5"> keeps</font>

335
00:18:28,270 --> 00:18:34,660
involving as in the example we show that

336
00:18:31,060 --> 00:18:40,060
<font color="#E5E5E5">around 25 dark dragons emerges each</font>

337
00:18:34,660 --> 00:18:42,370
month<font color="#CCCCCC"> on hack forums</font><font color="#E5E5E5"> from 2010 to 2013</font>

338
00:18:40,060 --> 00:18:44,399
<font color="#CCCCCC">so since those dark dragons keep</font>

339
00:18:42,370 --> 00:18:47,469
involving<font color="#E5E5E5"> it's very hard for</font><font color="#CCCCCC"> people</font><font color="#E5E5E5"> to</font>

340
00:18:44,400 --> 00:18:52,360
<font color="#CCCCCC">maintain this list and our tool can be</font>

341
00:18:47,470 --> 00:18:56,490
used to maintain<font color="#CCCCCC"> this list and with that</font>

342
00:18:52,360 --> 00:18:59,199
least we can actually profile these that

343
00:18:56,490 --> 00:19:00,790
<font color="#CCCCCC">command on that</font><font color="#E5E5E5"> forums we are able to</font>

344
00:18:59,200 --> 00:19:08,050
<font color="#E5E5E5">identify</font><font color="#CCCCCC"> the key players in the</font>

345
00:19:00,790 --> 00:19:11,220
ecosystem<font color="#E5E5E5"> and recovered yeah we can get</font>

346
00:19:08,050 --> 00:19:14,050
more<font color="#CCCCCC"> understanding</font><font color="#E5E5E5"> of the ecosystem</font>

347
00:19:11,220 --> 00:19:17,050
<font color="#E5E5E5">another interesting part of the</font><font color="#CCCCCC"> Dragons</font>

348
00:19:14,050 --> 00:19:19,680
how aware do people choose those dark

349
00:19:17,050 --> 00:19:22,270
<font color="#CCCCCC">dragon strong and we actually find that</font>

350
00:19:19,680 --> 00:19:26,110
<font color="#E5E5E5">neutrals from of different categories</font>

351
00:19:22,270 --> 00:19:30,250
<font color="#CCCCCC">for example fruit is one of the one of</font>

352
00:19:26,110 --> 00:19:33,760
<font color="#E5E5E5">the most common category of jargons</font>

353
00:19:30,250 --> 00:19:35,590
<font color="#CCCCCC">sauce many of drugs are used fruit as</font>

354
00:19:33,760 --> 00:19:38,230
their dragons for example lemons

355
00:19:35,590 --> 00:19:40,870
blueberry and mango<font color="#E5E5E5"> each indicating that</font>

356
00:19:38,230 --> 00:19:44,800
<font color="#E5E5E5">this</font><font color="#CCCCCC"> truck has the</font><font color="#E5E5E5"> flavor</font><font color="#CCCCCC"> of that fruit</font>

357
00:19:40,870 --> 00:19:48,429
there's others like<font color="#E5E5E5"> animals or food and</font>

358
00:19:44,800 --> 00:19:54,669
<font color="#E5E5E5">the interesting name a lot of</font>

359
00:19:48,430 --> 00:19:57,340
jargons<font color="#E5E5E5"> associate with associated with</font>

360
00:19:54,670 --> 00:20:00,880
<font color="#E5E5E5">the mayor well I used the name of</font>

361
00:19:57,340 --> 00:20:06,490
<font color="#E5E5E5">characters from mythology</font><font color="#CCCCCC"> such as you</font>

362
00:20:00,880 --> 00:20:10,120
slowly and<font color="#CCCCCC"> esna we also have find that</font>

363
00:20:06,490 --> 00:20:13,900
<font color="#E5E5E5">stock jargons</font><font color="#CCCCCC"> appears in the p9</font><font color="#E5E5E5"> forums</font>

364
00:20:10,120 --> 00:20:16,899
<font color="#CCCCCC">we find 675 communication traces on</font>

365
00:20:13,900 --> 00:20:19,660
reddit are related to illicit activities

366
00:20:16,900 --> 00:20:21,550
you need<font color="#E5E5E5"> our dragons we also find that</font>

367
00:20:19,660 --> 00:20:24,340
our dragons can help us to<font color="#CCCCCC"> find more</font>

368
00:20:21,550 --> 00:20:26,620
<font color="#E5E5E5">black</font><font color="#CCCCCC"> walls which add what that has very</font>

369
00:20:24,340 --> 00:20:27,899
dedicated<font color="#CCCCCC"> minis they only used by</font>

370
00:20:26,620 --> 00:20:32,229
cybercriminals

371
00:20:27,900 --> 00:20:34,390
we find 522<font color="#E5E5E5"> on black wards</font><font color="#CCCCCC"> with the help</font>

372
00:20:32,230 --> 00:20:37,300
of the<font color="#E5E5E5"> Jagger's we discovered and that's</font>

373
00:20:34,390 --> 00:20:38,980
all my presentation and thank you for

374
00:20:37,300 --> 00:20:52,600
listening<font color="#E5E5E5"> I'm happy to take your</font>

375
00:20:38,980 --> 00:20:54,280
questions<font color="#CCCCCC"> about Germany so for the most</font>

376
00:20:52,600 --> 00:20:56,709
<font color="#E5E5E5">the</font><font color="#CCCCCC"> technique solution</font><font color="#E5E5E5"> you'll propose is</font>

377
00:20:54,280 --> 00:20:59,470
basically align the vectors<font color="#E5E5E5"> train about</font>

378
00:20:56,710 --> 00:21:01,450
<font color="#E5E5E5">different corporate together</font><font color="#CCCCCC"> with worth</font>

379
00:20:59,470 --> 00:21:03,670
work about<font color="#CCCCCC"> however in</font><font color="#E5E5E5"> natural language</font>

380
00:21:01,450 --> 00:21:05,770
processing<font color="#CCCCCC"> two words already</font><font color="#E5E5E5"> proposed</font>

381
00:21:03,670 --> 00:21:07,570
similar<font color="#E5E5E5"> method you simply do</font><font color="#CCCCCC"> is simply</font>

382
00:21:05,770 --> 00:21:08,620
<font color="#E5E5E5">get the matrix you see they do some</font>

383
00:21:07,570 --> 00:21:11,200
linear transformation

384
00:21:08,620 --> 00:21:14,320
so<font color="#CCCCCC"> how why or</font><font color="#E5E5E5"> mastered all kind of</font>

385
00:21:11,200 --> 00:21:18,310
comparative as a result answer<font color="#CCCCCC"> I cannot</font>

386
00:21:14,320 --> 00:21:21,879
hear you really<font color="#E5E5E5"> clearly there is a PTO</font>

387
00:21:18,310 --> 00:21:25,330
question yes so can you compare your

388
00:21:21,880 --> 00:21:26,470
method of<font color="#E5E5E5"> this vector alignment with the</font>

389
00:21:25,330 --> 00:21:28,389
master<font color="#E5E5E5"> than natural language processing</font>

390
00:21:26,470 --> 00:21:30,670
where you simply<font color="#E5E5E5"> do some matrix</font>

391
00:21:28,390 --> 00:21:33,010
factorization to somehow align the

392
00:21:30,670 --> 00:21:36,880
vector of<font color="#CCCCCC"> sym word and</font><font color="#E5E5E5"> of different</font>

393
00:21:33,010 --> 00:21:41,410
<font color="#CCCCCC">copper together I'm not familiar</font><font color="#E5E5E5"> with</font>

394
00:21:36,880 --> 00:21:42,510
the technique<font color="#E5E5E5"> you're talking about yeah</font>

395
00:21:41,410 --> 00:21:47,190
we can talk offline

396
00:21:42,510 --> 00:21:49,270
[Music]

397
00:21:47,190 --> 00:21:50,950
hi nice work

398
00:21:49,270 --> 00:21:53,530
I was wondering like<font color="#CCCCCC"> how do you measure</font>

399
00:21:50,950 --> 00:21:55,960
the accuracy<font color="#E5E5E5"> of the</font><font color="#CCCCCC"> Jagan's</font><font color="#E5E5E5"> you</font>

400
00:21:53,530 --> 00:21:58,240
discovered<font color="#E5E5E5"> Isis remember in one slide</font>

401
00:21:55,960 --> 00:22:02,530
<font color="#CCCCCC">you presented those accuracy numbers of</font>

402
00:21:58,240 --> 00:22:05,260
the<font color="#CCCCCC"> accuracies we random samples of 200</font>

403
00:22:02,530 --> 00:22:11,830
of dark jackets we find and we<font color="#E5E5E5"> manual</font>

404
00:22:05,260 --> 00:22:14,020
check this<font color="#CCCCCC"> hi</font>

405
00:22:11,830 --> 00:22:17,169
<font color="#CCCCCC">Bolin Wong from UC Santa Barbara it's a</font>

406
00:22:14,020 --> 00:22:19,889
really<font color="#E5E5E5"> interesting idea</font><font color="#CCCCCC"> so one thing I</font>

407
00:22:17,170 --> 00:22:22,390
want to ask is how much data you need<font color="#CCCCCC"> to</font>

408
00:22:19,890 --> 00:22:24,280
you know teach the model to learn these

409
00:22:22,390 --> 00:22:28,030
jargons because there are other studies

410
00:22:24,280 --> 00:22:30,610
<font color="#E5E5E5">you say social social social media</font>

411
00:22:28,030 --> 00:22:33,879
networks<font color="#CCCCCC"> they're talking about when</font>

412
00:22:30,610 --> 00:22:35,800
there's censorship people tend to evolve

413
00:22:33,880 --> 00:22:37,780
<font color="#E5E5E5">how they use different words to</font>

414
00:22:35,800 --> 00:22:41,020
represent<font color="#E5E5E5"> the same</font><font color="#CCCCCC"> thing I think this</font><font color="#E5E5E5"> is</font>

415
00:22:37,780 --> 00:22:43,540
<font color="#CCCCCC">also it also applies here so do you</font>

416
00:22:41,020 --> 00:22:46,030
<font color="#E5E5E5">think your model can learn faster than</font>

417
00:22:43,540 --> 00:22:50,050
you know how fast human can adapt to

418
00:22:46,030 --> 00:22:52,960
<font color="#E5E5E5">different words okay she relies on a</font>

419
00:22:50,050 --> 00:22:55,840
large amount of data in fact but it's

420
00:22:52,960 --> 00:22:58,150
actually not<font color="#E5E5E5"> just</font><font color="#CCCCCC"> the amount it's like</font>

421
00:22:55,840 --> 00:23:00,939
how<font color="#CCCCCC"> many different contexts</font><font color="#E5E5E5"> of what</font>

422
00:22:58,150 --> 00:23:02,920
appears in that's more important and we

423
00:23:00,940 --> 00:23:07,810
actually<font color="#E5E5E5"> did some experiment I didn't</font>

424
00:23:02,920 --> 00:23:13,420
show on<font color="#CCCCCC"> this slide but it's sure that on</font>

425
00:23:07,810 --> 00:23:14,190
so stock<font color="#CCCCCC"> jargons appears like oh</font><font color="#E5E5E5"> let me</font>

426
00:23:13,420 --> 00:23:17,830
think<font color="#E5E5E5"> about it</font>

427
00:23:14,190 --> 00:23:20,800
yeah if we talk<font color="#CCCCCC"> jargon shows like</font>

428
00:23:17,830 --> 00:23:22,629
halfway<font color="#E5E5E5"> with dark meanings and haffley</font>

429
00:23:20,800 --> 00:23:26,889
with original meanings<font color="#E5E5E5"> then we</font><font color="#CCCCCC"> can</font>

430
00:23:22,630 --> 00:23:31,600
attack<font color="#CCCCCC"> it with like as low as 20</font>

431
00:23:26,890 --> 00:23:34,170
occurrence of the world yeah if<font color="#E5E5E5"> that</font>

432
00:23:31,600 --> 00:23:34,169
answers your question

433
00:23:35,860 --> 00:23:39,040
[Applause]

