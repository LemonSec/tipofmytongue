1
00:00:00,120 --> 00:00:02,580
session I'm extremely excited to be

2
00:00:02,580 --> 00:00:04,920
chairing this session with three

3
00:00:04,920 --> 00:00:06,480
fantastic speakers my name is Henry

4
00:00:06,480 --> 00:00:08,880
Corgan Gibbs and the first Speaker of

5
00:00:08,880 --> 00:00:11,400
the session is going to be Stefan samoji

6
00:00:11,400 --> 00:00:14,040
who works at Google he has an incredibly

7
00:00:14,040 --> 00:00:16,139
impressive resume that I promised I

8
00:00:16,139 --> 00:00:18,600
would not share with you because he's

9
00:00:18,600 --> 00:00:20,039
very humble in addition to being very

10
00:00:20,039 --> 00:00:21,900
accomplished and he's going to tell us

11
00:00:21,900 --> 00:00:24,600
about design applied cryptography in

12
00:00:24,600 --> 00:00:27,140
humans so

13
00:00:27,180 --> 00:00:28,800
thanks Henry

14
00:00:28,800 --> 00:00:31,019
um yeah my name is Stefan samoji I work

15
00:00:31,019 --> 00:00:33,660
on user protection at Google and I'm

16
00:00:33,660 --> 00:00:34,980
also affiliated with the Columbia

17
00:00:34,980 --> 00:00:37,200
journalism school which is not widely

18
00:00:37,200 --> 00:00:39,239
known for the breadth and depth of its

19
00:00:39,239 --> 00:00:41,059
cryptographic research

20
00:00:41,059 --> 00:00:44,640
what it does have however is students

21
00:00:44,640 --> 00:00:46,980
and faculty who are very much at the

22
00:00:46,980 --> 00:00:50,280
Leading Edge of innovation in attacking

23
00:00:50,280 --> 00:00:52,200
people journalists are

24
00:00:52,200 --> 00:00:54,719
disproportionately at risk as targets

25
00:00:54,719 --> 00:00:57,539
for any number of reasons for a wide

26
00:00:57,539 --> 00:01:00,199
variety in a broad spectrum of attacks

27
00:01:00,199 --> 00:01:05,099
including online harassment and other

28
00:01:05,099 --> 00:01:06,720
other bad things that happen to people

29
00:01:06,720 --> 00:01:08,700
especially online

30
00:01:08,700 --> 00:01:10,860
uh other demographics that fall into

31
00:01:10,860 --> 00:01:12,540
this category are human rights workers

32
00:01:12,540 --> 00:01:15,960
uh there is a growing population of

33
00:01:15,960 --> 00:01:18,600
people who are at disproportionate above

34
00:01:18,600 --> 00:01:22,740
Baseline risk and learning during this

35
00:01:22,740 --> 00:01:24,960
experience and understanding the reality

36
00:01:24,960 --> 00:01:28,500
of their lives and how they have to go

37
00:01:28,500 --> 00:01:30,360
through them is very informative for the

38
00:01:30,360 --> 00:01:33,000
product work that I do at Google and

39
00:01:33,000 --> 00:01:35,880
this is why this also ties into the

40
00:01:35,880 --> 00:01:38,579
general notion of design during this

41
00:01:38,579 --> 00:01:40,200
talk I'm primarily going to be talking

42
00:01:40,200 --> 00:01:43,140
in the context of industrial design uh

43
00:01:43,140 --> 00:01:45,240
now to fukasawa is a relatively

44
00:01:45,240 --> 00:01:47,540
prominent Japanese industrial designer

45
00:01:47,540 --> 00:01:50,939
he has over the years designed many both

46
00:01:50,939 --> 00:01:52,500
aesthetically pleasing and highly

47
00:01:52,500 --> 00:01:54,240
functional objects

48
00:01:54,240 --> 00:01:56,399
but what particularly distinguishes him

49
00:01:56,399 --> 00:01:58,920
in my eyes is he spends a lot of time

50
00:01:58,920 --> 00:02:02,280
thinking about the craft of design and

51
00:02:02,280 --> 00:02:05,280
articulating it and so one of the things

52
00:02:05,280 --> 00:02:08,160
that I find connected some of my past

53
00:02:08,160 --> 00:02:10,919
work with cryptosystems with his work in

54
00:02:10,919 --> 00:02:13,739
industrial design is this notion of we

55
00:02:13,739 --> 00:02:15,660
do have to actually design these things

56
00:02:15,660 --> 00:02:19,020
for users I worked at pgp for many years

57
00:02:19,020 --> 00:02:22,440
and it is not the Paragon of usability

58
00:02:22,440 --> 00:02:24,660
and I think

59
00:02:24,660 --> 00:02:27,140
I think this is uh currently

60
00:02:27,140 --> 00:02:29,700
uncontroversial belief

61
00:02:29,700 --> 00:02:31,920
um we have fortunately done better in

62
00:02:31,920 --> 00:02:33,420
the meantime right we we got a little

63
00:02:33,420 --> 00:02:36,420
better at this stuff but we're still not

64
00:02:36,420 --> 00:02:39,060
as good as we could get uh if we apply

65
00:02:39,060 --> 00:02:41,340
ourselves and so one of the first

66
00:02:41,340 --> 00:02:43,080
examples in the industrial design space

67
00:02:43,080 --> 00:02:45,840
uh that I'd like to call to your

68
00:02:45,840 --> 00:02:48,420
attention is a product from Muji that is

69
00:02:48,420 --> 00:02:50,700
quite literally named uh mattress with

70
00:02:50,700 --> 00:02:53,760
legs and you will be shocked to learn

71
00:02:53,760 --> 00:02:57,420
that it is in fact a mattress with legs

72
00:02:57,420 --> 00:02:59,760
um this has been a tremendously popular

73
00:02:59,760 --> 00:03:04,500
product for Muji uh even though it is

74
00:03:04,500 --> 00:03:07,140
one might argue a fairly basic building

75
00:03:07,140 --> 00:03:10,580
block of a home there are certain

76
00:03:10,580 --> 00:03:12,840
aspects that are composable that are

77
00:03:12,840 --> 00:03:15,060
modulatable one of the things that you

78
00:03:15,060 --> 00:03:17,640
can do is you can get different lengths

79
00:03:17,640 --> 00:03:20,459
of legs presumably partially because

80
00:03:20,459 --> 00:03:22,739
human legs also differ in their length

81
00:03:22,739 --> 00:03:25,860
but one of the background thoughts of

82
00:03:25,860 --> 00:03:28,319
this design was also very efficient use

83
00:03:28,319 --> 00:03:30,300
of space in the room that this piece of

84
00:03:30,300 --> 00:03:33,300
furniture is in because there is space

85
00:03:33,300 --> 00:03:35,700
underneath there and if you had stuff to

86
00:03:35,700 --> 00:03:38,459
store the designers didn't want that

87
00:03:38,459 --> 00:03:40,140
space to go to waste and Muji will quite

88
00:03:40,140 --> 00:03:42,900
happily sell you some storage units that

89
00:03:42,900 --> 00:03:45,599
go very nicely underneath or if you have

90
00:03:45,599 --> 00:03:47,819
less stuff you can get smaller storage

91
00:03:47,819 --> 00:03:51,900
units but this is the basic building

92
00:03:51,900 --> 00:03:54,299
block of this design

93
00:03:54,299 --> 00:03:58,799
in 2015 uh Muji uh started collaborating

94
00:03:58,799 --> 00:04:01,319
with Narita Airport and they built this

95
00:04:01,319 --> 00:04:03,900
variation on the mattress with legs uh

96
00:04:03,900 --> 00:04:08,459
they added a backrest because the uh

97
00:04:08,459 --> 00:04:10,739
design brief expanded to people who

98
00:04:10,739 --> 00:04:12,480
wanted to use it more as a sofa who

99
00:04:12,480 --> 00:04:14,280
wanted to sit down

100
00:04:14,280 --> 00:04:18,060
um these items are in terminal 3 at

101
00:04:18,060 --> 00:04:20,760
Narita which is the low-cost Carrier

102
00:04:20,760 --> 00:04:22,620
Terminal and people often have very long

103
00:04:22,620 --> 00:04:24,900
layovers there and so the assumption is

104
00:04:24,900 --> 00:04:27,300
people would want to sit down which is

105
00:04:27,300 --> 00:04:28,740
where the backrest comes in people will

106
00:04:28,740 --> 00:04:30,900
also want to lie down they absolutely

107
00:04:30,900 --> 00:04:33,600
will use it as a mattress if they have

108
00:04:33,600 --> 00:04:36,540
an overnight layover and so the basic

109
00:04:36,540 --> 00:04:39,180
building block evolved the fundamental

110
00:04:39,180 --> 00:04:40,860
primitive of the mattress with legs

111
00:04:40,860 --> 00:04:42,780
remains and then they scaled it even

112
00:04:42,780 --> 00:04:43,680
further

113
00:04:43,680 --> 00:04:47,220
and added a little flat hard surface

114
00:04:47,220 --> 00:04:48,720
because if you're going to be spending

115
00:04:48,720 --> 00:04:50,699
hours and hours on a layover in an

116
00:04:50,699 --> 00:04:52,199
airport you might want a beverage you

117
00:04:52,199 --> 00:04:54,360
might want some food and beverage

118
00:04:54,360 --> 00:04:56,220
containers particularly open ones are

119
00:04:56,220 --> 00:04:57,660
not the kinds of things that you want to

120
00:04:57,660 --> 00:05:00,960
put on a curved soft surface that you

121
00:05:00,960 --> 00:05:03,360
might want to sleep on right so they

122
00:05:03,360 --> 00:05:05,759
evolved the design further to

123
00:05:05,759 --> 00:05:07,620
accommodate the possibility of having

124
00:05:07,620 --> 00:05:09,240
something that you can put a drink down

125
00:05:09,240 --> 00:05:10,380
on

126
00:05:10,380 --> 00:05:12,840
um but it all came back to this core

127
00:05:12,840 --> 00:05:14,940
design and within cryptography we have

128
00:05:14,940 --> 00:05:16,500
any number of core designs we have core

129
00:05:16,500 --> 00:05:18,840
algorithms whose properties we

130
00:05:18,840 --> 00:05:22,500
understand well over the years and how

131
00:05:22,500 --> 00:05:25,199
we compose these different building

132
00:05:25,199 --> 00:05:26,820
blocks into crypto systems

133
00:05:26,820 --> 00:05:28,860
differentiates the ones that are usable

134
00:05:28,860 --> 00:05:32,039
from the ones that aren't and so one of

135
00:05:32,039 --> 00:05:36,240
fuka salasan's thoughts about design is

136
00:05:36,240 --> 00:05:39,479
specifically in the realm of being able

137
00:05:39,479 --> 00:05:41,759
to use a tool or an affordance without

138
00:05:41,759 --> 00:05:43,800
thinking much about it right we don't

139
00:05:43,800 --> 00:05:45,979
think much about using mattresses

140
00:05:45,979 --> 00:05:48,780
gravity is a constant on Earth we know

141
00:05:48,780 --> 00:05:50,639
which way is down most of the times

142
00:05:50,639 --> 00:05:53,340
unless we're in a centrifuge right

143
00:05:53,340 --> 00:05:56,759
um and so we should strive to build

144
00:05:56,759 --> 00:06:00,080
tools that our users can use safely

145
00:06:00,080 --> 00:06:03,720
without an overabundance of Advanced

146
00:06:03,720 --> 00:06:06,259
Training and so focusing on usability

147
00:06:06,259 --> 00:06:08,940
benefits everybody now within the

148
00:06:08,940 --> 00:06:10,160
security space

149
00:06:10,160 --> 00:06:12,539
we certainly have collectively been hurt

150
00:06:12,539 --> 00:06:14,880
on more than a few occasions to say

151
00:06:14,880 --> 00:06:17,280
things like humans are the weakest link

152
00:06:17,280 --> 00:06:19,259
in your security system

153
00:06:19,259 --> 00:06:22,259
I think this is corrosive nonsense uh

154
00:06:22,259 --> 00:06:24,479
humans are actually your best first line

155
00:06:24,479 --> 00:06:26,400
of defense because the human brain has

156
00:06:26,400 --> 00:06:28,979
evolved to see patterns and detect

157
00:06:28,979 --> 00:06:31,620
anomalies better than any automated

158
00:06:31,620 --> 00:06:34,139
system that we can possibly build so we

159
00:06:34,139 --> 00:06:37,080
should be designing to the strengths of

160
00:06:37,080 --> 00:06:40,319
the humans and not deliberately try and

161
00:06:40,319 --> 00:06:43,020
find ways of doing things that don't

162
00:06:43,020 --> 00:06:45,139
play to those very very strengths

163
00:06:45,139 --> 00:06:49,319
another area of human competence that I

164
00:06:49,319 --> 00:06:51,060
discovered some years ago I was doing

165
00:06:51,060 --> 00:06:52,979
some research into understanding why

166
00:06:52,979 --> 00:06:55,560
people returned their mobile phones and

167
00:06:55,560 --> 00:06:58,199
within the cluster of top reasons came

168
00:06:58,199 --> 00:07:01,440
the relatively mundane sounding USB

169
00:07:01,440 --> 00:07:05,520
comma liquid and so it turns out that

170
00:07:05,520 --> 00:07:09,060
people drop their phones in any number

171
00:07:09,060 --> 00:07:11,819
of conductive liquids and at the time

172
00:07:11,819 --> 00:07:14,639
this led to the premature demise of the

173
00:07:14,639 --> 00:07:17,819
device and so even in those days right

174
00:07:17,819 --> 00:07:20,400
people bought phones with more pixels or

175
00:07:20,400 --> 00:07:23,699
more RAM or more CPU or more battery and

176
00:07:23,699 --> 00:07:25,919
someone hadn't thought

177
00:07:25,919 --> 00:07:28,740
across the industry that people also

178
00:07:28,740 --> 00:07:30,539
drop their phones and they drop their

179
00:07:30,539 --> 00:07:32,580
phones into water

180
00:07:32,580 --> 00:07:35,639
so today quite a few years later when

181
00:07:35,639 --> 00:07:39,120
everybody got the memo you see different

182
00:07:39,120 --> 00:07:41,639
mobile phone designs specifically

183
00:07:41,639 --> 00:07:43,319
differentiate themselves and Market

184
00:07:43,319 --> 00:07:45,479
themselves as water resistant to a

185
00:07:45,479 --> 00:07:48,240
certain way it took the industry quite a

186
00:07:48,240 --> 00:07:50,819
few years to realize that it isn't all

187
00:07:50,819 --> 00:07:52,680
about the easily measurable and

188
00:07:52,680 --> 00:07:55,380
marketable metrics it's about the stuff

189
00:07:55,380 --> 00:07:57,840
that the users encounter when they're

190
00:07:57,840 --> 00:08:00,180
actually using the tool that was

191
00:08:00,180 --> 00:08:02,720
designed

192
00:08:02,940 --> 00:08:06,960
Noto is a Latin word it means I write or

193
00:08:06,960 --> 00:08:09,479
I mark it is also the name of a

194
00:08:09,479 --> 00:08:12,120
ballpoint pen that focusawasan designed

195
00:08:12,120 --> 00:08:14,880
for the German manufacturer Lomi and I

196
00:08:14,880 --> 00:08:16,560
can show you a picture of this thing but

197
00:08:16,560 --> 00:08:18,479
as you might imagine pens are very

198
00:08:18,479 --> 00:08:20,940
tactile right you have to hold them so

199
00:08:20,940 --> 00:08:22,020
one of the distinguishing

200
00:08:22,020 --> 00:08:24,360
characteristics of this design is that

201
00:08:24,360 --> 00:08:26,340
it's approximately triangular it feels

202
00:08:26,340 --> 00:08:27,960
pretty good in the hand and you know

203
00:08:27,960 --> 00:08:30,960
sort of how to orient it it also has a

204
00:08:30,960 --> 00:08:32,700
very specific feature that you will

205
00:08:32,700 --> 00:08:34,919
never get out of this picture which is

206
00:08:34,919 --> 00:08:38,339
it is nominally a clicky pen but

207
00:08:38,339 --> 00:08:41,760
it doesn't click in contrast

208
00:08:41,760 --> 00:08:43,740
there are clicky pens and this was a

209
00:08:43,740 --> 00:08:46,500
deliberate design decision because at

210
00:08:46,500 --> 00:08:49,260
some point the design team that that put

211
00:08:49,260 --> 00:08:51,360
together this pen wound up in a

212
00:08:51,360 --> 00:08:52,980
situation where they were irritated by

213
00:08:52,980 --> 00:08:54,860
somebody else

214
00:08:54,860 --> 00:08:58,260
clicking their pen so they said we're

215
00:08:58,260 --> 00:08:59,820
doing a silent one

216
00:08:59,820 --> 00:09:03,300
now in my completely unscientific

217
00:09:03,300 --> 00:09:05,640
and statistically insignificant testing

218
00:09:05,640 --> 00:09:08,820
over the last couple of weeks I've found

219
00:09:08,820 --> 00:09:11,100
a very mixed set of reactions some

220
00:09:11,100 --> 00:09:13,200
people absolutely hate a non-clicky

221
00:09:13,200 --> 00:09:17,160
clicky pen so not all users are

222
00:09:17,160 --> 00:09:20,459
uniformly enamored of this feature the

223
00:09:20,459 --> 00:09:21,540
other thing that I really like about

224
00:09:21,540 --> 00:09:24,660
this pen is some of the the more subtle

225
00:09:24,660 --> 00:09:27,000
details if you write so much that you

226
00:09:27,000 --> 00:09:28,500
use up all the ink and you replace the

227
00:09:28,500 --> 00:09:29,820
refill and you screw it back together

228
00:09:29,820 --> 00:09:31,680
you get to a point where you encounter

229
00:09:31,680 --> 00:09:33,540
resistance but you can feel that the

230
00:09:33,540 --> 00:09:35,100
triangles don't line up so you have an

231
00:09:35,100 --> 00:09:36,540
immediate tactile sense of it's not

232
00:09:36,540 --> 00:09:38,459
quite right but you hit resistance until

233
00:09:38,459 --> 00:09:42,000
you add a little more pressure and

234
00:09:42,000 --> 00:09:43,440
of course now it doesn't do it there's a

235
00:09:43,440 --> 00:09:44,640
little click there's a very tactile

236
00:09:44,640 --> 00:09:46,680
click this is something that you will

237
00:09:46,680 --> 00:09:48,839
notice a handful of times during the

238
00:09:48,839 --> 00:09:50,279
lifespan of this pen but somebody

239
00:09:50,279 --> 00:09:52,200
thought this was important enough to

240
00:09:52,200 --> 00:09:54,120
include it and this brings us to the

241
00:09:54,120 --> 00:09:55,920
principle of microconsiderations which

242
00:09:55,920 --> 00:09:58,140
fukazarusan talks about quite a lot it's

243
00:09:58,140 --> 00:10:00,839
the attention detail in the tiny little

244
00:10:00,839 --> 00:10:02,640
things that you might not encounter day

245
00:10:02,640 --> 00:10:04,740
to day but which communicate to the user

246
00:10:04,740 --> 00:10:06,899
that you put a bunch of thought into it

247
00:10:06,899 --> 00:10:08,519
and you are very careful in your

248
00:10:08,519 --> 00:10:11,339
composition of what you did and if you

249
00:10:11,339 --> 00:10:13,560
look at any number of security systems

250
00:10:13,560 --> 00:10:16,640
that have cryptography in them some

251
00:10:16,640 --> 00:10:18,959
events a great deal of thought and

252
00:10:18,959 --> 00:10:20,820
consideration for how it all fits

253
00:10:20,820 --> 00:10:23,700
together and others seem to be a

254
00:10:23,700 --> 00:10:25,500
collection of buzzwords that are put

255
00:10:25,500 --> 00:10:27,420
into a certain sequence to tick certain

256
00:10:27,420 --> 00:10:30,720
boxes and all of these exist I would

257
00:10:30,720 --> 00:10:32,640
prefer we wind up on the more thoughtful

258
00:10:32,640 --> 00:10:35,820
side of things now Noto also has another

259
00:10:35,820 --> 00:10:37,260
meaning in this context it is the

260
00:10:37,260 --> 00:10:39,839
typeface name of the typeface that I'm

261
00:10:39,839 --> 00:10:41,820
using here for this presentation and in

262
00:10:41,820 --> 00:10:45,120
this context is short for no tofu this

263
00:10:45,120 --> 00:10:47,899
is not a culinary criticism

264
00:10:47,899 --> 00:10:50,760
but any of you who have worked with

265
00:10:50,760 --> 00:10:52,920
Unicode will be familiar with the

266
00:10:52,920 --> 00:10:55,079
character that is colloquially known as

267
00:10:55,079 --> 00:10:57,720
tofu and the typeface is designed

268
00:10:57,720 --> 00:11:01,079
specifically to try and avoid this glyph

269
00:11:01,079 --> 00:11:03,779
which is the I don't have this character

270
00:11:03,779 --> 00:11:06,720
here whatever character you are trying

271
00:11:06,720 --> 00:11:09,779
to render doesn't exist So for anybody

272
00:11:09,779 --> 00:11:12,420
who doesn't exclusively exist in a seven

273
00:11:12,420 --> 00:11:14,399
bit ASCII world you're going to

274
00:11:14,399 --> 00:11:16,500
encounter this and so the Noto typeface

275
00:11:16,500 --> 00:11:19,500
was specifically intended to include

276
00:11:19,500 --> 00:11:21,899
more glyphs from more written languages

277
00:11:21,899 --> 00:11:25,620
to prevent the appearance of the tofu

278
00:11:25,620 --> 00:11:28,440
character anywhere and so this brings us

279
00:11:28,440 --> 00:11:30,140
to this notion of industrial craft

280
00:11:30,140 --> 00:11:33,000
there's craft work the attention detail

281
00:11:33,000 --> 00:11:35,220
and design where you really notice that

282
00:11:35,220 --> 00:11:36,720
somebody has put a lot of thought into

283
00:11:36,720 --> 00:11:40,140
it but we work in a space that is

284
00:11:40,140 --> 00:11:42,660
dominated by computers and we want to

285
00:11:42,660 --> 00:11:44,519
scale all the things

286
00:11:44,519 --> 00:11:47,820
very often though we might not pick the

287
00:11:47,820 --> 00:11:50,040
right metrics picking just a metric that

288
00:11:50,040 --> 00:11:52,459
gets bigger and that more and more scale

289
00:11:52,459 --> 00:11:55,380
becomes measurable doesn't necessarily

290
00:11:55,380 --> 00:11:58,019
lead to better quality

291
00:11:58,019 --> 00:12:01,200
another example of industrial craft is

292
00:12:01,200 --> 00:12:03,360
the exposure notification system that we

293
00:12:03,360 --> 00:12:06,060
at Google built in collaboration with

294
00:12:06,060 --> 00:12:07,680
Apple at the very beginning of the

295
00:12:07,680 --> 00:12:11,700
pandemic and it was from the outset

296
00:12:11,700 --> 00:12:13,740
intended as something where the

297
00:12:13,740 --> 00:12:15,420
technology wasn't supposed to get into

298
00:12:15,420 --> 00:12:18,060
the user's face but we on the side of

299
00:12:18,060 --> 00:12:20,160
the designs related to privacy and

300
00:12:20,160 --> 00:12:23,700
security knew full well that we had a

301
00:12:23,700 --> 00:12:25,500
requirement a hard and fast requirement

302
00:12:25,500 --> 00:12:27,300
that we needed to build a system that

303
00:12:27,300 --> 00:12:29,279
had very specific privacy preserving

304
00:12:29,279 --> 00:12:31,500
characteristics very specific security

305
00:12:31,500 --> 00:12:34,140
characteristics we also needed to make

306
00:12:34,140 --> 00:12:36,480
them explainable we needed to articulate

307
00:12:36,480 --> 00:12:38,279
and document them we needed to publish

308
00:12:38,279 --> 00:12:40,980
our threat model so that those with the

309
00:12:40,980 --> 00:12:44,100
expertise to critique us had access to

310
00:12:44,100 --> 00:12:46,100
all the information that they needed

311
00:12:46,100 --> 00:12:50,100
and it turns out we pretty much got it

312
00:12:50,100 --> 00:12:52,560
right because the uptake was sufficient

313
00:12:52,560 --> 00:12:55,980
that multiple teams in the UK in Canada

314
00:12:55,980 --> 00:12:58,980
and the Netherlands came back to us with

315
00:12:58,980 --> 00:13:01,320
statistically significant results and

316
00:13:01,320 --> 00:13:04,260
Illustrated clearly that this system

317
00:13:04,260 --> 00:13:07,560
helped people it prevented infections by

318
00:13:07,560 --> 00:13:09,839
alerting people about notifications and

319
00:13:09,839 --> 00:13:11,600
preventing infections

320
00:13:11,600 --> 00:13:14,399
inevitably saved lives and we don't

321
00:13:14,399 --> 00:13:16,380
really have that luxury very often in

322
00:13:16,380 --> 00:13:18,240
Tech where we spend most of our days

323
00:13:18,240 --> 00:13:20,279
pushing buttons and staring into

324
00:13:20,279 --> 00:13:22,500
flickering rectangles how often do we

325
00:13:22,500 --> 00:13:24,779
get to build something meaningful now

326
00:13:24,779 --> 00:13:26,760
from the cryptography side of the system

327
00:13:26,760 --> 00:13:28,560
which as I said was fairly well

328
00:13:28,560 --> 00:13:30,000
documented one thing that we discovered

329
00:13:30,000 --> 00:13:32,760
is being boring is a real feature

330
00:13:32,760 --> 00:13:34,079
people

331
00:13:34,079 --> 00:13:37,500
stopped looking into the system after

332
00:13:37,500 --> 00:13:39,300
the initial set of analyzes because

333
00:13:39,300 --> 00:13:41,100
everybody else had more important stuff

334
00:13:41,100 --> 00:13:44,880
to do and so by making the cryptography

335
00:13:44,880 --> 00:13:47,700
inherent in the system initially as open

336
00:13:47,700 --> 00:13:50,300
as we could as transparent as we could

337
00:13:50,300 --> 00:13:53,579
we enjoyed the benefits of a great deal

338
00:13:53,579 --> 00:13:55,079
of analysis

339
00:13:55,079 --> 00:13:58,139
after which people said okay now we need

340
00:13:58,139 --> 00:14:00,600
to worry about other stuff because this

341
00:14:00,600 --> 00:14:03,240
particular implementation has become

342
00:14:03,240 --> 00:14:06,240
boring so you have to meet your users

343
00:14:06,240 --> 00:14:09,300
where they are you do not always have

344
00:14:09,300 --> 00:14:12,720
the luxury of imposing what is secure or

345
00:14:12,720 --> 00:14:16,680
what is private upon your users you have

346
00:14:16,680 --> 00:14:19,260
to think about the environment and the

347
00:14:19,260 --> 00:14:22,800
context that they operate in AES as we

348
00:14:22,800 --> 00:14:26,100
heard is you know completely all over

349
00:14:26,100 --> 00:14:27,899
the place and all sorts of cryptographic

350
00:14:27,899 --> 00:14:29,700
applications except that we've also

351
00:14:29,700 --> 00:14:31,320
learned in the two decades since it was

352
00:14:31,320 --> 00:14:35,459
standardized that it's still not ideal

353
00:14:35,459 --> 00:14:37,260
in environments where you don't have

354
00:14:37,260 --> 00:14:40,139
Hardware assist and uh there are still

355
00:14:40,139 --> 00:14:42,779
devices being sold in parts of the world

356
00:14:42,779 --> 00:14:45,500
today that do not have Hardware AES

357
00:14:45,500 --> 00:14:47,839
colleagues of mine on the Android team

358
00:14:47,839 --> 00:14:51,240
realize that this problem still affected

359
00:14:51,240 --> 00:14:54,600
people and that by using exclusively AES

360
00:14:54,600 --> 00:14:57,000
we were costing people battery life we

361
00:14:57,000 --> 00:14:58,639
were costing people

362
00:14:58,639 --> 00:15:01,560
user experience because the CPUs just

363
00:15:01,560 --> 00:15:04,199
weren't up to it for certain parts of

364
00:15:04,199 --> 00:15:06,320
the world now to be clear

365
00:15:06,320 --> 00:15:09,600
volumetrically this is not the majority

366
00:15:09,600 --> 00:15:13,560
of devices being sold new today but it

367
00:15:13,560 --> 00:15:16,199
is a significant number of people

368
00:15:16,199 --> 00:15:19,440
and so we need to design with an

369
00:15:19,440 --> 00:15:22,680
understanding of people who don't fit

370
00:15:22,680 --> 00:15:25,019
into the majority we have to pressure

371
00:15:25,019 --> 00:15:28,320
test and stress test our designs and if

372
00:15:28,320 --> 00:15:30,779
I'm somebody who has a phone that

373
00:15:30,779 --> 00:15:33,180
doesn't have Hardware AES it is unlikely

374
00:15:33,180 --> 00:15:35,760
to be deliberately by choice and so

375
00:15:35,760 --> 00:15:37,800
penalizing these folks and eating up

376
00:15:37,800 --> 00:15:39,420
their battery because AES is more

377
00:15:39,420 --> 00:15:41,339
expensive on this device than an

378
00:15:41,339 --> 00:15:43,920
alternative Solution that's not really

379
00:15:43,920 --> 00:15:45,660
the greatest thing you you wind up

380
00:15:45,660 --> 00:15:47,699
creating security for rich people and

381
00:15:47,699 --> 00:15:48,959
that's not a particularly good design

382
00:15:48,959 --> 00:15:49,980
Target

383
00:15:49,980 --> 00:15:52,019
I'd like to show you a video now which

384
00:15:52,019 --> 00:15:54,420
is an excerpt from a documentary film

385
00:15:54,420 --> 00:15:56,339
called objectified directed by Gary

386
00:15:56,339 --> 00:15:57,839
hustwit who is very kindly giving me

387
00:15:57,839 --> 00:16:00,660
permission uh to show this excerpt

388
00:16:00,660 --> 00:16:04,320
and it makes a very important point in

389
00:16:04,320 --> 00:16:09,019
general about design parameters

390
00:16:10,620 --> 00:16:12,480
clients come to us and say here's our

391
00:16:12,480 --> 00:16:14,579
average customer for instance female

392
00:16:14,579 --> 00:16:17,940
she's 34 years old she has 2.3 kids and

393
00:16:17,940 --> 00:16:19,440
we've listened politely and say well

394
00:16:19,440 --> 00:16:22,500
that's great but we don't care about

395
00:16:22,500 --> 00:16:25,560
that person what we really need to do to

396
00:16:25,560 --> 00:16:28,680
design is look at the extremes the

397
00:16:28,680 --> 00:16:31,079
weakest or the person with arthritis or

398
00:16:31,079 --> 00:16:32,940
the athlete or the strongest or the

399
00:16:32,940 --> 00:16:34,260
fastest person

400
00:16:34,260 --> 00:16:35,880
because if we understand what the

401
00:16:35,880 --> 00:16:37,500
extremes are

402
00:16:37,500 --> 00:16:41,120
the middle will take care of itself

403
00:16:43,620 --> 00:16:45,120
over the years I've had many

404
00:16:45,120 --> 00:16:48,600
conversations with engineering teams who

405
00:16:48,600 --> 00:16:51,779
were incorrigibly focused on the

406
00:16:51,779 --> 00:16:53,940
majority use cases and everything else

407
00:16:53,940 --> 00:16:58,380
outside of that was an edge case

408
00:16:58,380 --> 00:17:01,380
but in engineering we also like the idea

409
00:17:01,380 --> 00:17:03,839
of testing and stress testing our

410
00:17:03,839 --> 00:17:05,780
systems to make sure they are resilient

411
00:17:05,780 --> 00:17:08,280
these users who are outside of the

412
00:17:08,280 --> 00:17:09,780
middle these extreme users that Dan

413
00:17:09,780 --> 00:17:12,179
Formosa talks about

414
00:17:12,179 --> 00:17:14,160
are those users and we need to include

415
00:17:14,160 --> 00:17:17,280
them in our design thinking now Dan is

416
00:17:17,280 --> 00:17:18,900
formerly a principal at a company called

417
00:17:18,900 --> 00:17:20,299
smart design

418
00:17:20,299 --> 00:17:23,880
and they designed Oxo good grips kitchen

419
00:17:23,880 --> 00:17:26,760
utensils which were originally released

420
00:17:26,760 --> 00:17:29,580
into the world in 1990 initially only in

421
00:17:29,580 --> 00:17:32,280
North America they are now 23 years

422
00:17:32,280 --> 00:17:34,860
later a global brand and they're wildly

423
00:17:34,860 --> 00:17:38,160
commercially successful but at the

424
00:17:38,160 --> 00:17:41,100
initial design phase they were Building

425
00:17:41,100 --> 00:17:43,679
kitchen utensils for people who are

426
00:17:43,679 --> 00:17:45,660
having difficulty with more conventional

427
00:17:45,660 --> 00:17:47,400
ones because they were developing

428
00:17:47,400 --> 00:17:49,260
arthritis they were finding it very

429
00:17:49,260 --> 00:17:52,080
difficult to hold on to things that are

430
00:17:52,080 --> 00:17:54,059
relatively small and hard so if you've

431
00:17:54,059 --> 00:17:56,100
seen one of these kitchen utensils they

432
00:17:56,100 --> 00:17:57,900
have much bigger grips they have softer

433
00:17:57,900 --> 00:18:00,780
grips they are grippier so they are less

434
00:18:00,780 --> 00:18:02,280
likely to slip out of your hand

435
00:18:02,280 --> 00:18:04,559
especially when wet so if you have a

436
00:18:04,559 --> 00:18:06,539
vegetable peeler you are probably going

437
00:18:06,539 --> 00:18:08,820
to be interacting with your sink now it

438
00:18:08,820 --> 00:18:12,140
turns out by designing kitchen utensils

439
00:18:12,140 --> 00:18:15,780
for a nominally extreme use case

440
00:18:15,780 --> 00:18:17,580
somebody developing or who already has

441
00:18:17,580 --> 00:18:21,120
arthritis they wound up creating a very

442
00:18:21,120 --> 00:18:22,980
commercially successful product for

443
00:18:22,980 --> 00:18:25,400
everybody because that additional

444
00:18:25,400 --> 00:18:28,799
usability that additional design turned

445
00:18:28,799 --> 00:18:31,020
out to benefit everybody

446
00:18:31,020 --> 00:18:33,780
so when you're designing your crypto

447
00:18:33,780 --> 00:18:35,220
systems please design your crypto

448
00:18:35,220 --> 00:18:37,799
systems for people think about how

449
00:18:37,799 --> 00:18:39,419
they're actually going to use them in

450
00:18:39,419 --> 00:18:41,340
the real world don't just think about

451
00:18:41,340 --> 00:18:43,200
pixels and Battery think about the fact

452
00:18:43,200 --> 00:18:46,260
that humans drop phones into water and

453
00:18:46,260 --> 00:18:49,559
think about it in advance consider what

454
00:18:49,559 --> 00:18:52,500
of the micro considerations there are

455
00:18:52,500 --> 00:18:54,900
out there that you can integrate into

456
00:18:54,900 --> 00:18:57,600
the design of the eventual thing that

457
00:18:57,600 --> 00:19:00,480
lands into the in in the hands of users

458
00:19:00,480 --> 00:19:03,360
and consider how you can build things

459
00:19:03,360 --> 00:19:05,700
that are reliable that are safe and

460
00:19:05,700 --> 00:19:08,460
secure and that work well and that

461
00:19:08,460 --> 00:19:11,160
protect our users data

462
00:19:11,160 --> 00:19:12,960
and with that thank you for your

463
00:19:12,960 --> 00:19:14,820
attention and I think we've got a little

464
00:19:14,820 --> 00:19:16,370
bit of time for questions

465
00:19:16,370 --> 00:19:24,560
[Applause]

466
00:19:24,600 --> 00:19:26,039
great so we have plenty of time for

467
00:19:26,039 --> 00:19:30,679
questions either on Zoom or in person

468
00:19:35,880 --> 00:19:38,059
foreign

469
00:19:39,320 --> 00:19:43,020
on the taking into consideration all the

470
00:19:43,020 --> 00:19:44,760
little details when designing your

471
00:19:44,760 --> 00:19:47,520
system or construction

472
00:19:47,520 --> 00:19:49,320
um one thing that I I'm mindful of is

473
00:19:49,320 --> 00:19:51,539
software never stays static as long as

474
00:19:51,539 --> 00:19:54,600
humans are using it how do you keep up

475
00:19:54,600 --> 00:19:57,419
that level of taking into account detail

476
00:19:57,419 --> 00:20:00,960
and the cohesiveness of your project or

477
00:20:00,960 --> 00:20:04,740
your tool as it evolves over time as the

478
00:20:04,740 --> 00:20:07,200
either the needs of its users change or

479
00:20:07,200 --> 00:20:09,539
the underlying assumptions of what you

480
00:20:09,539 --> 00:20:14,000
built it on evolve or things like that

481
00:20:14,039 --> 00:20:17,360
it's hard

482
00:20:17,580 --> 00:20:22,020
um but as an example of one system that

483
00:20:22,020 --> 00:20:25,140
I think got it right uh I would

484
00:20:25,140 --> 00:20:27,140
recommend the wire guard design paper

485
00:20:27,140 --> 00:20:30,059
because wire guard approached the

486
00:20:30,059 --> 00:20:33,120
problem space with very strong opinions

487
00:20:33,120 --> 00:20:35,700
and

488
00:20:35,700 --> 00:20:38,520
you know you can over correct your

489
00:20:38,520 --> 00:20:41,340
algorithmic agility we learned that

490
00:20:41,340 --> 00:20:45,000
firsthand at pgp that was not so ideal

491
00:20:45,000 --> 00:20:46,860
but we didn't know any better in the

492
00:20:46,860 --> 00:20:48,720
early days right because we were worried

493
00:20:48,720 --> 00:20:51,480
about planning ahead and making sure

494
00:20:51,480 --> 00:20:53,520
that we didn't actually set any traps

495
00:20:53,520 --> 00:20:56,880
for our users what we didn't realize or

496
00:20:56,880 --> 00:20:58,799
I wasn't involved in the very very early

497
00:20:58,799 --> 00:20:59,880
days

498
00:20:59,880 --> 00:21:02,520
but what became clear later is legacy is

499
00:21:02,520 --> 00:21:04,380
real and you have to have backwards

500
00:21:04,380 --> 00:21:05,880
compatibility for a certain amount of

501
00:21:05,880 --> 00:21:08,640
time and all of the problems related to

502
00:21:08,640 --> 00:21:11,160
that are also really tough on users

503
00:21:11,160 --> 00:21:14,820
there isn't one size fits-all answer to

504
00:21:14,820 --> 00:21:18,500
your question but having

505
00:21:18,500 --> 00:21:21,120
foundedopinions documenting what those

506
00:21:21,120 --> 00:21:23,280
opinions are seeking input and getting

507
00:21:23,280 --> 00:21:25,860
the feedback and understanding and

508
00:21:25,860 --> 00:21:28,260
describing adequately the parameters of

509
00:21:28,260 --> 00:21:29,820
your design space

510
00:21:29,820 --> 00:21:31,500
are ultimately also going to make it

511
00:21:31,500 --> 00:21:34,200
easier to migrate off of it when

512
00:21:34,200 --> 00:21:36,600
at some future point that is The Prudent

513
00:21:36,600 --> 00:21:39,600
thing to do I happen to reread the the

514
00:21:39,600 --> 00:21:43,080
wire guard paper not too long ago and

515
00:21:43,080 --> 00:21:44,940
um Jason dunfeld made a very specific

516
00:21:44,940 --> 00:21:48,179
point that if at some point one of the

517
00:21:48,179 --> 00:21:50,880
core building blocks of the protocol had

518
00:21:50,880 --> 00:21:54,000
a volume at least the way it's designed

519
00:21:54,000 --> 00:21:56,159
would force a very clean break and

520
00:21:56,159 --> 00:21:58,140
everybody would have to update

521
00:21:58,140 --> 00:22:01,500
that's painful if you have to deal with

522
00:22:01,500 --> 00:22:04,200
I don't know Edge devices iot devices

523
00:22:04,200 --> 00:22:06,000
that have no connectivity

524
00:22:06,000 --> 00:22:08,280
or that have other kinds of software

525
00:22:08,280 --> 00:22:12,000
update uh constraints

526
00:22:12,000 --> 00:22:13,860
but for something like software which is

527
00:22:13,860 --> 00:22:14,940
sort of where your question started

528
00:22:14,940 --> 00:22:17,220
that's not the worst approach

529
00:22:17,220 --> 00:22:19,380
um it seems one that is likely to

530
00:22:19,380 --> 00:22:22,220
survive over time

531
00:22:22,860 --> 00:22:25,620
so I have a question uh from K McCully

532
00:22:25,620 --> 00:22:28,320
via Zoom which is a great question how

533
00:22:28,320 --> 00:22:29,520
do you inspire Engineers to create

534
00:22:29,520 --> 00:22:31,380
products for a broader swath of people

535
00:22:31,380 --> 00:22:33,120
particularly if they cannot relate to

536
00:22:33,120 --> 00:22:36,320
users that are not like them

537
00:22:38,640 --> 00:22:41,700
you find Gentle ways of introducing them

538
00:22:41,700 --> 00:22:44,720
to the outside world

539
00:22:45,720 --> 00:22:47,840
um

540
00:22:48,299 --> 00:22:53,639
um somewhat less snarkily look

541
00:22:55,620 --> 00:22:57,780
engineers

542
00:22:57,780 --> 00:23:00,480
are perpetually learning and so part of

543
00:23:00,480 --> 00:23:03,000
the issue is how do you get them to

544
00:23:03,000 --> 00:23:05,159
understand different design parameters

545
00:23:05,159 --> 00:23:08,340
then things that are easily measured and

546
00:23:08,340 --> 00:23:10,740
so you know find a friendly

547
00:23:10,740 --> 00:23:12,840
Anthropologist drag them out into the

548
00:23:12,840 --> 00:23:15,780
field make sure that you're highlighting

549
00:23:15,780 --> 00:23:18,080
some of their biases

550
00:23:18,080 --> 00:23:21,360
there there's a really good talk that I

551
00:23:21,360 --> 00:23:22,919
recommend to anybody interested in this

552
00:23:22,919 --> 00:23:24,480
design space there's a series of talks

553
00:23:24,480 --> 00:23:26,820
at Enigma this year an entire section

554
00:23:26,820 --> 00:23:29,880
about designing for at-risk high-risk

555
00:23:29,880 --> 00:23:33,000
users and one particular talk tells an

556
00:23:33,000 --> 00:23:36,120
anecdote of a bunch of security

557
00:23:36,120 --> 00:23:39,059
Engineers giving some training to some

558
00:23:39,059 --> 00:23:42,240
refugees and I'm not going to steal the

559
00:23:42,240 --> 00:23:43,860
punchline of the story because I really

560
00:23:43,860 --> 00:23:45,860
do want you to go and watch the video

561
00:23:45,860 --> 00:23:48,000
but this was also one of those

562
00:23:48,000 --> 00:23:49,679
situations where the engineers went in

563
00:23:49,679 --> 00:23:52,140
assuming that they understood the

564
00:23:52,140 --> 00:23:54,780
problem and they weren't listening and

565
00:23:54,780 --> 00:23:58,260
it took a while to actually realize that

566
00:23:58,260 --> 00:23:59,880
they had talked right past Their

567
00:23:59,880 --> 00:24:02,760
audience because they didn't seek the

568
00:24:02,760 --> 00:24:05,220
common understanding first so a large

569
00:24:05,220 --> 00:24:06,960
part of it is just making people aware

570
00:24:06,960 --> 00:24:08,280
of human factors I mean a lot of

571
00:24:08,280 --> 00:24:11,039
Engineers don't think that usability

572
00:24:11,039 --> 00:24:13,740
goes beyond having

573
00:24:13,740 --> 00:24:16,980
short and concise command line arguments

574
00:24:16,980 --> 00:24:20,460
to their tool right that's I guess a

575
00:24:20,460 --> 00:24:25,280
form of ergonomics but is a limited one

576
00:24:28,200 --> 00:24:30,600
um from your work on journalism or just

577
00:24:30,600 --> 00:24:32,220
more generally what are some of the

578
00:24:32,220 --> 00:24:34,679
features in cryptography that uh people

579
00:24:34,679 --> 00:24:37,200
need are the most vulnerable people need

580
00:24:37,200 --> 00:24:38,940
like some of the features that may we

581
00:24:38,940 --> 00:24:42,380
are not designing with today

582
00:24:46,380 --> 00:24:48,960
in general when you are handing a

583
00:24:48,960 --> 00:24:51,600
security tool to somebody whose primary

584
00:24:51,600 --> 00:24:54,539
knowledge domain isn't security they

585
00:24:54,539 --> 00:24:56,700
don't want their trust betrayed

586
00:24:56,700 --> 00:24:59,100
so having infinite numbers of twiddly

587
00:24:59,100 --> 00:25:01,799
little knobs that

588
00:25:01,799 --> 00:25:06,419
lead users to potentially find a sharp

589
00:25:06,419 --> 00:25:09,840
edge that's unhelpful there's a balance

590
00:25:09,840 --> 00:25:12,360
in design though it turns out that one

591
00:25:12,360 --> 00:25:14,700
size doesn't fit all for all at risk

592
00:25:14,700 --> 00:25:15,659
users

593
00:25:15,659 --> 00:25:17,700
so one of the things that my colleagues

594
00:25:17,700 --> 00:25:19,500
who do user experience research have

595
00:25:19,500 --> 00:25:21,179
discovered that at-risk users in

596
00:25:21,179 --> 00:25:24,000
particular need more options rather than

597
00:25:24,000 --> 00:25:26,159
fewer ones but getting the defaults

598
00:25:26,159 --> 00:25:29,039
right is crucial because the majority of

599
00:25:29,039 --> 00:25:30,480
people aren't going to deviate from the

600
00:25:30,480 --> 00:25:33,419
defaults so you want to find the most

601
00:25:33,419 --> 00:25:34,980
secure defaults

602
00:25:34,980 --> 00:25:37,380
and make sure that those defaults aren't

603
00:25:37,380 --> 00:25:39,659
innately a sharp edge for somebody who

604
00:25:39,659 --> 00:25:42,360
is at higher than Baseline risk uh

605
00:25:42,360 --> 00:25:43,500
unfortunately it sounds a little bit

606
00:25:43,500 --> 00:25:45,539
like a platitude but it all comes down

607
00:25:45,539 --> 00:25:47,039
to the details right like what's the

608
00:25:47,039 --> 00:25:49,500
tool is it is it a messaging tool is it

609
00:25:49,500 --> 00:25:52,500
a long-term archival tool very different

610
00:25:52,500 --> 00:25:55,740
thread and risk models right you is is

611
00:25:55,740 --> 00:25:58,200
the is the nature of the data that needs

612
00:25:58,200 --> 00:26:00,539
to be protected very ephemeral

613
00:26:00,539 --> 00:26:03,299
um what's your half-life of protection

614
00:26:03,299 --> 00:26:06,240
right and so if you're going archival

615
00:26:06,240 --> 00:26:08,159
the half-life is very much longer than

616
00:26:08,159 --> 00:26:10,100
something that's very ephemeral that

617
00:26:10,100 --> 00:26:12,960
potentially is needs to be protected

618
00:26:12,960 --> 00:26:14,220
only for minutes

619
00:26:14,220 --> 00:26:18,020
uh I hope that helps

620
00:26:19,500 --> 00:26:21,900
um I was wondering if you had in mind

621
00:26:21,900 --> 00:26:24,200
some particularly inspired

622
00:26:24,200 --> 00:26:27,419
inspiring crypto systems like systems

623
00:26:27,419 --> 00:26:29,279
that are designed well for people in

624
00:26:29,279 --> 00:26:30,779
your opinion

625
00:26:30,779 --> 00:26:33,419
um either pieces of software or papers

626
00:26:33,419 --> 00:26:35,760
any level of maturity I'm just curious

627
00:26:35,760 --> 00:26:38,640
if you have like specific examples you

628
00:26:38,640 --> 00:26:41,400
think are particularly well done

629
00:26:41,400 --> 00:26:43,580
foreign

630
00:26:43,740 --> 00:26:46,919
as much as we like to mock it I do think

631
00:26:46,919 --> 00:26:50,820
that understanding how pgp came to be an

632
00:26:50,820 --> 00:26:53,940
evolved is actually really useful for us

633
00:26:53,940 --> 00:26:55,980
because it has any number of salutary

634
00:26:55,980 --> 00:26:57,720
lessons

635
00:26:57,720 --> 00:27:00,000
um I think it's I mean look I worked

636
00:27:00,000 --> 00:27:01,679
there for a long time right I I should

637
00:27:01,679 --> 00:27:04,860
be super biased in favor of it but also

638
00:27:04,860 --> 00:27:07,620
it has served its purpose it did things

639
00:27:07,620 --> 00:27:09,779
at the time that that nothing else did

640
00:27:09,779 --> 00:27:12,419
it actually for a very very brief window

641
00:27:12,419 --> 00:27:14,159
of time was the most usable tool out

642
00:27:14,159 --> 00:27:16,799
there which is in 2023 kind of a

643
00:27:16,799 --> 00:27:19,380
mind-blowing statement but if you look

644
00:27:19,380 --> 00:27:22,200
at the Continuum of evolution of

645
00:27:22,200 --> 00:27:24,059
usability between something like you

646
00:27:24,059 --> 00:27:27,659
know original 1992 pgp10 command line to

647
00:27:27,659 --> 00:27:29,520
where we are today with signal

648
00:27:29,520 --> 00:27:31,980
right there's an awful lot of really

649
00:27:31,980 --> 00:27:35,279
interesting history in between there we

650
00:27:35,279 --> 00:27:38,299
learned along the way that the actual

651
00:27:38,299 --> 00:27:41,220
symmetric ciphers became largely

652
00:27:41,220 --> 00:27:44,640
commoditized and that key management was

653
00:27:44,640 --> 00:27:46,039
where it's at

654
00:27:46,039 --> 00:27:48,840
and turns out Key Management is still

655
00:27:48,840 --> 00:27:50,220
really hard I mean we saw that yesterday

656
00:27:50,220 --> 00:27:52,200
right any number of talks where it's

657
00:27:52,200 --> 00:27:54,120
like yeah key management is hard it's

658
00:27:54,120 --> 00:27:57,600
going to be hard for a while so

659
00:27:57,600 --> 00:27:59,520
um I think signal is a really good

660
00:27:59,520 --> 00:28:02,159
example I think WhatsApp has a lot going

661
00:28:02,159 --> 00:28:04,200
for it because it demonstrated that you

662
00:28:04,200 --> 00:28:06,559
could actually put

663
00:28:06,559 --> 00:28:08,520
well-constructed end-to-end encryption

664
00:28:08,520 --> 00:28:11,039
in the hands of a squillian users and

665
00:28:11,039 --> 00:28:12,480
they can all use it and enjoy the

666
00:28:12,480 --> 00:28:14,700
benefits of it even though some of the

667
00:28:14,700 --> 00:28:16,320
other design parameters of the greater

668
00:28:16,320 --> 00:28:19,080
system are notably different from say

669
00:28:19,080 --> 00:28:21,600
signal right very different

670
00:28:21,600 --> 00:28:24,360
overall parameters so look for those

671
00:28:24,360 --> 00:28:27,419
Deltas look for the differences and

672
00:28:27,419 --> 00:28:29,539
figure out how they apply to your work

673
00:28:29,539 --> 00:28:32,220
because and I'm sorry if I'm repeating

674
00:28:32,220 --> 00:28:33,779
myself but truly one size does not fit

675
00:28:33,779 --> 00:28:35,820
all and and you have to fully Embrace

676
00:28:35,820 --> 00:28:37,919
that that there is no one generic

677
00:28:37,919 --> 00:28:40,200
at-risk user there is no one generic

678
00:28:40,200 --> 00:28:42,960
above Baseline user there is no one

679
00:28:42,960 --> 00:28:44,600
generic user because the other thing

680
00:28:44,600 --> 00:28:47,640
that is is really important to call

681
00:28:47,640 --> 00:28:51,299
attention to all of us can become high

682
00:28:51,299 --> 00:28:53,640
risk with a latency of about two seconds

683
00:28:53,640 --> 00:28:56,039
right if we have any interaction with

684
00:28:56,039 --> 00:28:57,900
social media and something that we post

685
00:28:57,900 --> 00:29:01,320
suddenly goes viral that's it right you

686
00:29:01,320 --> 00:29:03,000
suddenly are in the realm of high risk

687
00:29:03,000 --> 00:29:05,100
and you can't change your entire

688
00:29:05,100 --> 00:29:08,279
security posture in two seconds so how

689
00:29:08,279 --> 00:29:09,600
do you help people like that how do you

690
00:29:09,600 --> 00:29:12,900
help people who are on the Baseline but

691
00:29:12,900 --> 00:29:15,539
then suddenly for whatever reason

692
00:29:15,539 --> 00:29:18,299
shoot straight up on the risk scale

693
00:29:18,299 --> 00:29:19,919
and they need to continue using the

694
00:29:19,919 --> 00:29:21,120
tools that they've already had and this

695
00:29:21,120 --> 00:29:22,620
is another reason why you want to design

696
00:29:22,620 --> 00:29:24,720
for some of those extremes as Dan

697
00:29:24,720 --> 00:29:28,799
Formosa said because the middle user

698
00:29:28,799 --> 00:29:30,539
that that common user may suddenly

699
00:29:30,539 --> 00:29:32,340
become an extreme user with no warning

700
00:29:32,340 --> 00:29:34,260
at all

701
00:29:34,260 --> 00:29:35,700
great so I think we have to leave it

702
00:29:35,700 --> 00:29:39,679
there so let's thank the speaker again

703
00:29:43,799 --> 00:29:47,760
thanks Stefan so the next talk is by

704
00:29:47,760 --> 00:29:49,980
Leah namissa Rosenbloom who's a fourth

705
00:29:49,980 --> 00:29:52,380
year PhD candidate at Brown working with

706
00:29:52,380 --> 00:29:56,179
analysis lucians Gaia and sunny Kamara

707
00:29:56,179 --> 00:29:59,340
and their work spans an array of topics

708
00:29:59,340 --> 00:30:01,799
from abolitionist teaching practice to

709
00:30:01,799 --> 00:30:03,539
zero knowledge proof systems to digital

710
00:30:03,539 --> 00:30:05,640
privacy for marginalized groups they've

711
00:30:05,640 --> 00:30:07,380
done a ton of interesting stuff and

712
00:30:07,380 --> 00:30:08,779
today we're going to hear about

713
00:30:08,779 --> 00:30:10,860
cryptography and Grassroots organizing

714
00:30:10,860 --> 00:30:12,240
take it away

715
00:30:12,240 --> 00:30:14,760
hi my name is Leanna Misa Rosenbloom and

716
00:30:14,760 --> 00:30:16,320
I'm here to talk about cryptography for

717
00:30:16,320 --> 00:30:18,480
Grassroots organizing this is Joint work

718
00:30:18,480 --> 00:30:20,880
with sunny Kamara I want to start with a

719
00:30:20,880 --> 00:30:23,399
quote of Philip roguey's which talks

720
00:30:23,399 --> 00:30:25,200
about the ability of cryptography to

721
00:30:25,200 --> 00:30:27,240
rearrange systems of power

722
00:30:27,240 --> 00:30:29,460
Ed by a quote from Lucy chin who said

723
00:30:29,460 --> 00:30:31,440
offhandedly one day that cryptographers

724
00:30:31,440 --> 00:30:33,840
are professional catastrophizers and

725
00:30:33,840 --> 00:30:35,700
this made me laugh but it's also true

726
00:30:35,700 --> 00:30:37,559
that we have a tendency as

727
00:30:37,559 --> 00:30:40,140
cryptographers to make a lot of

728
00:30:40,140 --> 00:30:42,299
assumptions while threat modeling and

729
00:30:42,299 --> 00:30:44,820
it's not always done necessarily with a

730
00:30:44,820 --> 00:30:47,460
deep understanding or awareness of how

731
00:30:47,460 --> 00:30:49,500
systems of power actually function in

732
00:30:49,500 --> 00:30:51,840
society so I want to focus on these

733
00:30:51,840 --> 00:30:54,179
questions and get people thinking about

734
00:30:54,179 --> 00:30:56,279
these questions how do we as

735
00:30:56,279 --> 00:30:58,559
cryptographers understand systems of

736
00:30:58,559 --> 00:30:59,460
power

737
00:30:59,460 --> 00:31:02,100
how does this understanding inform our

738
00:31:02,100 --> 00:31:05,039
threat modeling and design choices

739
00:31:05,039 --> 00:31:06,779
and how might we work toward building

740
00:31:06,779 --> 00:31:09,179
power for communities and in starting to

741
00:31:09,179 --> 00:31:11,039
address some of these questions we

742
00:31:11,039 --> 00:31:13,740
realize that we need kind of a threat

743
00:31:13,740 --> 00:31:15,779
modeling paradigm shift and the

744
00:31:15,779 --> 00:31:18,419
properties of this are as follows one

745
00:31:18,419 --> 00:31:20,760
size fits one so this is exactly what

746
00:31:20,760 --> 00:31:22,860
the last Saw kind of emphasized that

747
00:31:22,860 --> 00:31:24,539
there's no one-size-fits all we can't

748
00:31:24,539 --> 00:31:26,760
always make our work the most General in

749
00:31:26,760 --> 00:31:28,980
fact we need to really start with the

750
00:31:28,980 --> 00:31:30,779
unique needs of the population that we

751
00:31:30,779 --> 00:31:33,360
are trying to serve with our protocols

752
00:31:33,360 --> 00:31:37,279
next to recognize trust as a human

753
00:31:37,279 --> 00:31:40,620
property that digital trust is really an

754
00:31:40,620 --> 00:31:43,140
extension of Highly complex human trust

755
00:31:43,140 --> 00:31:44,940
relationships

756
00:31:44,940 --> 00:31:47,100
we want to work towards a notion of full

757
00:31:47,100 --> 00:31:48,899
compromise security so this is looking

758
00:31:48,899 --> 00:31:51,539
at threat modeling from a holistic lens

759
00:31:51,539 --> 00:31:53,820
of what are the messy human systems that

760
00:31:53,820 --> 00:31:57,240
go into these actual threat models

761
00:31:57,240 --> 00:31:59,100
and finally we want to work towards

762
00:31:59,100 --> 00:32:01,860
optimizing our protocols or communities

763
00:32:01,860 --> 00:32:04,320
and not necessarily corporations and

764
00:32:04,320 --> 00:32:06,539
governments

765
00:32:06,539 --> 00:32:08,640
this is the outline of the talk so we

766
00:32:08,640 --> 00:32:10,260
already looked at the introduction and

767
00:32:10,260 --> 00:32:11,760
threat modeling and now we're going to

768
00:32:11,760 --> 00:32:13,260
look at the definition of Grassroots

769
00:32:13,260 --> 00:32:15,659
organizing and some lessons from

770
00:32:15,659 --> 00:32:17,940
historical context

771
00:32:17,940 --> 00:32:20,220
we Define Grassroots organizing as a

772
00:32:20,220 --> 00:32:22,559
process by which people work from within

773
00:32:22,559 --> 00:32:25,080
marginalized communities to affect

774
00:32:25,080 --> 00:32:27,240
social political economic and

775
00:32:27,240 --> 00:32:29,220
environmental change

776
00:32:29,220 --> 00:32:30,539
I want to begin the historical

777
00:32:30,539 --> 00:32:32,399
discussion with the first known example

778
00:32:32,399 --> 00:32:34,440
of cryptography for Grassroots

779
00:32:34,440 --> 00:32:37,620
organizing which is Operation vula and

780
00:32:37,620 --> 00:32:39,480
the African National Congress activist

781
00:32:39,480 --> 00:32:41,820
created this crypto system to fight

782
00:32:41,820 --> 00:32:46,140
against apartheid between 1896 and 1990.

783
00:32:46,140 --> 00:32:48,960
uh Sunny goes into detail in great

784
00:32:48,960 --> 00:32:50,760
detail in his crypto for the people talk

785
00:32:50,760 --> 00:32:52,799
in 2020 so I'm not going to go over all

786
00:32:52,799 --> 00:32:55,260
those details now but we are looking at

787
00:32:55,260 --> 00:32:56,700
the requirements here of it being

788
00:32:56,700 --> 00:32:59,340
asynchronous covert long distance and

789
00:32:59,340 --> 00:33:00,840
public so it had some pretty unique

790
00:33:00,840 --> 00:33:02,580
security requirements and I want to

791
00:33:02,580 --> 00:33:04,140
highlight a quote from one of the

792
00:33:04,140 --> 00:33:05,460
activists here

793
00:33:05,460 --> 00:33:07,679
who said I want to find out about secure

794
00:33:07,679 --> 00:33:09,779
encryption algorithms all I discovered

795
00:33:09,779 --> 00:33:11,520
was that cryptology was an Arcane

796
00:33:11,520 --> 00:33:13,559
science for board mathematicians not for

797
00:33:13,559 --> 00:33:15,840
underground activists however I learned

798
00:33:15,840 --> 00:33:17,760
a few tricks and used these to develop a

799
00:33:17,760 --> 00:33:21,059
system to meet our security needs

800
00:33:21,059 --> 00:33:22,500
of a harsh take but I think it's

801
00:33:22,500 --> 00:33:24,720
important to highlight that it's not

802
00:33:24,720 --> 00:33:27,120
it's not only developing these systems

803
00:33:27,120 --> 00:33:28,919
for the people who we are trying to

804
00:33:28,919 --> 00:33:31,200
serve it's also making those systems and

805
00:33:31,200 --> 00:33:33,480
the knowledge accessible to people who

806
00:33:33,480 --> 00:33:36,260
need that knowledge

807
00:33:36,539 --> 00:33:41,279
next uh cointelpro is a prime example of

808
00:33:41,279 --> 00:33:43,500
the extent to which state powers are

809
00:33:43,500 --> 00:33:46,320
willing to extensively and illegally

810
00:33:46,320 --> 00:33:48,240
surveil activists and this happened in

811
00:33:48,240 --> 00:33:52,200
the United States between 1956 and 1971.

812
00:33:52,200 --> 00:33:54,240
it also highlights the blurring of

813
00:33:54,240 --> 00:33:57,419
boundaries between information gathering

814
00:33:57,419 --> 00:33:59,760
and physical violence so the information

815
00:33:59,760 --> 00:34:01,860
gathered as part of this operation did

816
00:34:01,860 --> 00:34:03,840
lead to assassination for instance of

817
00:34:03,840 --> 00:34:06,120
Fred Hampton and incarceration of many

818
00:34:06,120 --> 00:34:07,559
other activists

819
00:34:07,559 --> 00:34:09,359
and we learned in the church committee

820
00:34:09,359 --> 00:34:13,139
report that there was uh these tactics

821
00:34:13,139 --> 00:34:15,480
intimidation manipulation dragged that

822
00:34:15,480 --> 00:34:18,000
information gathering without really any

823
00:34:18,000 --> 00:34:19,800
meaningful oversight and accountability

824
00:34:19,800 --> 00:34:21,119
and we know that a lot of these

825
00:34:21,119 --> 00:34:22,739
practices have been ported into the

826
00:34:22,739 --> 00:34:25,080
digital era via the Snowden disclosures

827
00:34:25,080 --> 00:34:27,540
in 2013.

828
00:34:27,540 --> 00:34:28,980
finally I want to highlight the

829
00:34:28,980 --> 00:34:30,540
importance of the Arab Spring which

830
00:34:30,540 --> 00:34:32,580
happened in many countries between 2010

831
00:34:32,580 --> 00:34:35,280
and 2012. and this was really the first

832
00:34:35,280 --> 00:34:37,139
example where social media was used

833
00:34:37,139 --> 00:34:40,260
extensively to organize and in

834
00:34:40,260 --> 00:34:42,719
particular social media increased the

835
00:34:42,719 --> 00:34:44,399
speed at which information was

836
00:34:44,399 --> 00:34:46,800
disseminated it increased the amount of

837
00:34:46,800 --> 00:34:48,300
information that could be disseminated

838
00:34:48,300 --> 00:34:50,339
and it increased the amount of people

839
00:34:50,339 --> 00:34:52,560
that were able to be reached with the

840
00:34:52,560 --> 00:34:54,780
information and people who study the

841
00:34:54,780 --> 00:34:57,020
role of social media in the Arab Spring

842
00:34:57,020 --> 00:35:00,119
are very they they all note that social

843
00:35:00,119 --> 00:35:02,640
media is a facilitator rather than a

844
00:35:02,640 --> 00:35:04,320
direct or independent cause of change

845
00:35:04,320 --> 00:35:06,420
this is a tool that activists are

846
00:35:06,420 --> 00:35:07,440
wielding

847
00:35:07,440 --> 00:35:11,599
to facilitate their organizing

848
00:35:11,820 --> 00:35:13,859
so this is this Playbook essentially

849
00:35:13,859 --> 00:35:15,599
inspired countless other movements and

850
00:35:15,599 --> 00:35:17,760
has brought us into the present day

851
00:35:17,760 --> 00:35:19,320
so next we're going to look at some

852
00:35:19,320 --> 00:35:21,359
lessons from the current landscape which

853
00:35:21,359 --> 00:35:24,599
come from a qualitative studies a

854
00:35:24,599 --> 00:35:26,220
collection of qualitative studies of

855
00:35:26,220 --> 00:35:28,320
organizers

856
00:35:28,320 --> 00:35:29,940
and I want to frame this discussion

857
00:35:29,940 --> 00:35:32,220
around modes of suppression

858
00:35:32,220 --> 00:35:35,339
so the last four of these are the most

859
00:35:35,339 --> 00:35:36,960
heavily intersecting with information

860
00:35:36,960 --> 00:35:38,520
technology

861
00:35:38,520 --> 00:35:40,560
and specifically surveillance

862
00:35:40,560 --> 00:35:42,060
conspicuous surveillance and covert

863
00:35:42,060 --> 00:35:43,859
surveillance speak to the importance of

864
00:35:43,859 --> 00:35:46,920
the confidentiality of information and

865
00:35:46,920 --> 00:35:49,200
potentially anonymity how do we protect

866
00:35:49,200 --> 00:35:51,180
our identities online

867
00:35:51,180 --> 00:35:53,460
the last two deception and mass media

868
00:35:53,460 --> 00:35:54,900
influence speak to the importance of

869
00:35:54,900 --> 00:35:57,119
having Integrity of information and also

870
00:35:57,119 --> 00:35:59,579
trust in digital spaces and these last

871
00:35:59,579 --> 00:36:01,500
two sets of properties are often at odds

872
00:36:01,500 --> 00:36:03,240
with each other

873
00:36:03,240 --> 00:36:05,400
a nice commentary of how activists

874
00:36:05,400 --> 00:36:07,579
manage the difference between these few

875
00:36:07,579 --> 00:36:11,099
is a study of anti-corruption foundation

876
00:36:11,099 --> 00:36:13,320
activists from Russia

877
00:36:13,320 --> 00:36:16,619
and the study found that the activists

878
00:36:16,619 --> 00:36:19,740
balance conspicuous security by having

879
00:36:19,740 --> 00:36:21,900
security tools and also educating people

880
00:36:21,900 --> 00:36:24,420
about how to use those tools with

881
00:36:24,420 --> 00:36:26,940
strategic visibility in order to build a

882
00:36:26,940 --> 00:36:28,500
sense of transparency of what they're

883
00:36:28,500 --> 00:36:31,260
doing and community and this is echoed

884
00:36:31,260 --> 00:36:33,420
also in Hong Kong where they had bigger

885
00:36:33,420 --> 00:36:35,520
public groups and smaller encrypted

886
00:36:35,520 --> 00:36:37,619
groups with a rigorous onboarding

887
00:36:37,619 --> 00:36:39,960
process

888
00:36:39,960 --> 00:36:43,020
next the importance of digital trust

889
00:36:43,020 --> 00:36:45,540
with respect to physical trust and this

890
00:36:45,540 --> 00:36:47,880
is based on a study I did with 50 black

891
00:36:47,880 --> 00:36:49,980
lives matter activists in the U.S in

892
00:36:49,980 --> 00:36:52,380
2020.

893
00:36:52,380 --> 00:36:54,720
so there was a danger of immediacy and

894
00:36:54,720 --> 00:36:58,440
anonymity in digital spaces and this was

895
00:36:58,440 --> 00:36:59,940
due to the speed at which information

896
00:36:59,940 --> 00:37:02,040
and things were being organized at that

897
00:37:02,040 --> 00:37:04,640
time and also the lack of

898
00:37:04,640 --> 00:37:06,839
verifiability of some of the accounts

899
00:37:06,839 --> 00:37:09,240
that were posting information

900
00:37:09,240 --> 00:37:11,579
and the organizers got around this by

901
00:37:11,579 --> 00:37:13,320
using

902
00:37:13,320 --> 00:37:15,780
traditional mechanisms they talked to

903
00:37:15,780 --> 00:37:17,579
people it was they used their own social

904
00:37:17,579 --> 00:37:20,160
networks they asked people hey do you

905
00:37:20,160 --> 00:37:21,660
trust this event should we show up do

906
00:37:21,660 --> 00:37:23,579
you think this is a proud boys event

907
00:37:23,579 --> 00:37:24,780
actually and they're just trying to

908
00:37:24,780 --> 00:37:26,880
trick us into coming or is this a real

909
00:37:26,880 --> 00:37:28,920
event and so they would decide and

910
00:37:28,920 --> 00:37:31,500
evaluate as a community whether they

911
00:37:31,500 --> 00:37:32,940
trusted the information that they were

912
00:37:32,940 --> 00:37:34,619
reading online

913
00:37:34,619 --> 00:37:37,260
this is also echoed in Hong Kong where

914
00:37:37,260 --> 00:37:39,420
face-to-face preceded phone to phone and

915
00:37:39,420 --> 00:37:41,339
to quote one activist because standing

916
00:37:41,339 --> 00:37:43,380
on the front line together is very

917
00:37:43,380 --> 00:37:45,359
important for trust

918
00:37:45,359 --> 00:37:46,740
finally I want to highlight the

919
00:37:46,740 --> 00:37:48,420
importance of device compromise and

920
00:37:48,420 --> 00:37:49,800
deletion

921
00:37:49,800 --> 00:37:52,859
and this came from the anti-extradition

922
00:37:52,859 --> 00:37:55,260
law Amendment Bill protests in 2019 from

923
00:37:55,260 --> 00:37:57,619
Hong Kong

924
00:37:57,960 --> 00:37:59,880
the activists in this setting were

925
00:37:59,880 --> 00:38:01,700
moving towards full compromise security

926
00:38:01,700 --> 00:38:04,800
and this is not only what we would

927
00:38:04,800 --> 00:38:06,240
consider forward secrecy or post

928
00:38:06,240 --> 00:38:07,680
compromise security it's actually a

929
00:38:07,680 --> 00:38:10,079
level beyond that how do we detect that

930
00:38:10,079 --> 00:38:12,420
a compromise has taken place and the

931
00:38:12,420 --> 00:38:13,980
activists in this case were using what

932
00:38:13,980 --> 00:38:16,140
most of us would would consider spyware

933
00:38:16,140 --> 00:38:19,440
so Life 360 for example to figure out

934
00:38:19,440 --> 00:38:21,359
whether the people that they were

935
00:38:21,359 --> 00:38:23,400
working with had been arrested and this

936
00:38:23,400 --> 00:38:25,619
was a risk assessment that they made to

937
00:38:25,619 --> 00:38:27,300
determine okay it's more important that

938
00:38:27,300 --> 00:38:28,920
we know if they're arrested so we can

939
00:38:28,920 --> 00:38:31,380
delete their data than it is to take a

940
00:38:31,380 --> 00:38:33,420
risk of using Life360 which they knew

941
00:38:33,420 --> 00:38:35,400
was you know not the most secure app to

942
00:38:35,400 --> 00:38:37,560
use

943
00:38:37,560 --> 00:38:39,180
so they would follow this up the

944
00:38:39,180 --> 00:38:42,060
mitigation strategy would be a mix of

945
00:38:42,060 --> 00:38:44,040
making sure everything was wiped when it

946
00:38:44,040 --> 00:38:45,900
needed to be wiped so scheduled and

947
00:38:45,900 --> 00:38:48,599
remote deletion and this is why they

948
00:38:48,599 --> 00:38:51,260
chose to use telegram even though

949
00:38:51,260 --> 00:38:53,820
telegrams group messages did turned out

950
00:38:53,820 --> 00:38:55,980
not to be end to end encrypted so there

951
00:38:55,980 --> 00:38:58,440
were issues with telegram but the

952
00:38:58,440 --> 00:39:00,540
deletion Factor was really important to

953
00:39:00,540 --> 00:39:02,700
them because when arrests occurred this

954
00:39:02,700 --> 00:39:04,859
would compromise contacts on the phone

955
00:39:04,859 --> 00:39:07,020
and also chat logs like the entire

956
00:39:07,020 --> 00:39:09,500
history of the chat

957
00:39:09,500 --> 00:39:12,480
and this speaks to Collective Security

958
00:39:12,480 --> 00:39:15,420
culture so this is a group reflex that

959
00:39:15,420 --> 00:39:17,160
is established among community members

960
00:39:17,160 --> 00:39:18,900
to minimize information sharing

961
00:39:18,900 --> 00:39:22,460
digitizing and retaining

962
00:39:22,740 --> 00:39:24,780
I want to talk a little bit about our

963
00:39:24,780 --> 00:39:27,480
new project now synthesizing some of

964
00:39:27,480 --> 00:39:29,820
these observations called tigrow or

965
00:39:29,820 --> 00:39:31,320
trust infrastructure for Grassroots

966
00:39:31,320 --> 00:39:33,240
organizing and then we'll wrap up the

967
00:39:33,240 --> 00:39:35,359
talk

968
00:39:35,579 --> 00:39:37,260
we are trying to address this question

969
00:39:37,260 --> 00:39:40,859
so how might we use cryptographic tools

970
00:39:40,859 --> 00:39:43,500
to adapt the existing trust and

971
00:39:43,500 --> 00:39:45,359
communication platforms of grass juice

972
00:39:45,359 --> 00:39:47,520
organizers from physical to digital

973
00:39:47,520 --> 00:39:50,040
spaces and how might we do this without

974
00:39:50,040 --> 00:39:51,900
increasing the risk of surveillance

975
00:39:51,900 --> 00:39:54,480
disinformation and infiltration of

976
00:39:54,480 --> 00:39:57,500
Grassroots movements

977
00:39:58,200 --> 00:40:00,180
so it lines up with the paradigm shift

978
00:40:00,180 --> 00:40:02,339
as follows this is not an independent

979
00:40:02,339 --> 00:40:04,920
platform it is a flexible library of

980
00:40:04,920 --> 00:40:07,079
Primitives and we hope that to apply

981
00:40:07,079 --> 00:40:09,440
these Primitives in many settings

982
00:40:09,440 --> 00:40:12,000
to apply the private trust Network

983
00:40:12,000 --> 00:40:14,460
information of people to to any to any

984
00:40:14,460 --> 00:40:16,859
setting online

985
00:40:16,859 --> 00:40:18,960
we use an on-the-ground key agreement

986
00:40:18,960 --> 00:40:21,000
which we'll talk a little bit about over

987
00:40:21,000 --> 00:40:23,579
Bluetooth and this Roots the digital

988
00:40:23,579 --> 00:40:25,980
trust created in our system to a

989
00:40:25,980 --> 00:40:28,380
physical interaction

990
00:40:28,380 --> 00:40:30,440
we move toward full compromise security

991
00:40:30,440 --> 00:40:33,300
by having the contacts hold minimal

992
00:40:33,300 --> 00:40:35,160
information about one another

993
00:40:35,160 --> 00:40:38,520
and anyone with a shared key can delete

994
00:40:38,520 --> 00:40:41,099
and finally we consider the individual

995
00:40:41,099 --> 00:40:43,140
device computation environment versus

996
00:40:43,140 --> 00:40:44,460
our server

997
00:40:44,460 --> 00:40:46,619
which will be operating over relatively

998
00:40:46,619 --> 00:40:49,560
small data sets

999
00:40:49,560 --> 00:40:52,619
our adversarial model is again thinking

1000
00:40:52,619 --> 00:40:54,780
about how to adopt existing threats and

1001
00:40:54,780 --> 00:40:58,740
mitigation strategies into digital space

1002
00:40:58,740 --> 00:41:00,660
and we start by looking at a digital

1003
00:41:00,660 --> 00:41:03,060
infiltration adversary this adversary

1004
00:41:03,060 --> 00:41:04,800
has properties that you might recognize

1005
00:41:04,800 --> 00:41:06,300
so it's trying to collect as much

1006
00:41:06,300 --> 00:41:08,040
information as possible

1007
00:41:08,040 --> 00:41:10,859
it can also corrupt the server and

1008
00:41:10,859 --> 00:41:13,260
corrupt a fraction of the devices but it

1009
00:41:13,260 --> 00:41:15,420
can also pose as a group member not

1010
00:41:15,420 --> 00:41:17,579
necessarily in a cryptographic sense

1011
00:41:17,579 --> 00:41:20,960
and spread false information

1012
00:41:22,020 --> 00:41:23,940
in the semi honest server model we get

1013
00:41:23,940 --> 00:41:25,740
privacy and correctness in the malicious

1014
00:41:25,740 --> 00:41:27,839
server model privacy is maintained but

1015
00:41:27,839 --> 00:41:30,240
not necessarily correctness and we

1016
00:41:30,240 --> 00:41:31,800
cannot count on the server to delete

1017
00:41:31,800 --> 00:41:33,839
what is on the server

1018
00:41:33,839 --> 00:41:36,119
and our security strategy is going to be

1019
00:41:36,119 --> 00:41:38,040
to establish digital equivalence of

1020
00:41:38,040 --> 00:41:41,040
existing security practices

1021
00:41:41,040 --> 00:41:43,200
so we start with that by establishing

1022
00:41:43,200 --> 00:41:46,079
security equals trust and again human

1023
00:41:46,079 --> 00:41:47,880
trust we're trying to create human trust

1024
00:41:47,880 --> 00:41:51,480
as a core digital security concept

1025
00:41:51,480 --> 00:41:53,640
the way organizers build and assess

1026
00:41:53,640 --> 00:41:55,500
trust depends on a lot of different

1027
00:41:55,500 --> 00:41:57,599
factors and we are not trying to make

1028
00:41:57,599 --> 00:41:59,460
these assumptions for people we are

1029
00:41:59,460 --> 00:42:01,200
trying to enable them to make these

1030
00:42:01,200 --> 00:42:03,060
assumptions and then Port them into the

1031
00:42:03,060 --> 00:42:05,099
digital environment

1032
00:42:05,099 --> 00:42:07,619
we do this using grounded cryptographic

1033
00:42:07,619 --> 00:42:09,359
protocols and we'll talk more about that

1034
00:42:09,359 --> 00:42:11,520
so we reduce digital trust to physical

1035
00:42:11,520 --> 00:42:13,560
interactions that establish grounded

1036
00:42:13,560 --> 00:42:15,060
pairs so it's a pairwise trust

1037
00:42:15,060 --> 00:42:16,140
relationship

1038
00:42:16,140 --> 00:42:18,540
and then we enable the qual the the

1039
00:42:18,540 --> 00:42:20,760
pairs to make qualitative trust

1040
00:42:20,760 --> 00:42:22,560
measurements and share them in a secure

1041
00:42:22,560 --> 00:42:24,420
way

1042
00:42:24,420 --> 00:42:26,400
our core protocols first is a ground

1043
00:42:26,400 --> 00:42:28,260
trust ceremony the ground trust ceremony

1044
00:42:28,260 --> 00:42:30,839
is like a signing ceremony in spirit

1045
00:42:30,839 --> 00:42:33,240
however it establishes a symmetric key

1046
00:42:33,240 --> 00:42:35,940
that is linked to a physical meeting and

1047
00:42:35,940 --> 00:42:38,520
it's not it's not a pki so there's no

1048
00:42:38,520 --> 00:42:40,079
public key infrastructure where

1049
00:42:40,079 --> 00:42:41,820
everything you do in this space is going

1050
00:42:41,820 --> 00:42:44,579
to be linked to a public key it is not

1051
00:42:44,579 --> 00:42:46,380
linkable

1052
00:42:46,380 --> 00:42:48,599
we're going to use this key to establish

1053
00:42:48,599 --> 00:42:50,460
a grounded annotation system which

1054
00:42:50,460 --> 00:42:52,320
allows these pairs to share digital

1055
00:42:52,320 --> 00:42:54,540
annotations of arbitrary people places

1056
00:42:54,540 --> 00:42:55,859
and things so they'll be able to

1057
00:42:55,859 --> 00:42:58,560
exchange information about objects

1058
00:42:58,560 --> 00:43:01,020
online securely

1059
00:43:01,020 --> 00:43:03,240
and finally we have a prototype of

1060
00:43:03,240 --> 00:43:05,400
grounded trust metrics which will allow

1061
00:43:05,400 --> 00:43:07,800
people to quantify trust over their

1062
00:43:07,800 --> 00:43:09,780
social network graph and we'll talk a

1063
00:43:09,780 --> 00:43:12,359
little bit about that as well

1064
00:43:12,359 --> 00:43:14,400
so the ground trust ceremony we have two

1065
00:43:14,400 --> 00:43:16,680
organizers here codenames Alice and Bob

1066
00:43:16,680 --> 00:43:18,960
they each have a persistent identifier

1067
00:43:18,960 --> 00:43:21,960
Ida and idb this is a random identifier

1068
00:43:21,960 --> 00:43:24,660
just locally stored on the device and

1069
00:43:24,660 --> 00:43:26,880
they each have a location

1070
00:43:26,880 --> 00:43:28,800
to start and explain the idea we'll use

1071
00:43:28,800 --> 00:43:30,720
an ideal functionality for this grounded

1072
00:43:30,720 --> 00:43:32,700
key agreement where Alice and Bob send

1073
00:43:32,700 --> 00:43:34,260
their information the key agreement

1074
00:43:34,260 --> 00:43:35,819
checks whether they are in the same

1075
00:43:35,819 --> 00:43:37,440
location if they are in the same

1076
00:43:37,440 --> 00:43:39,540
location it generates a key and returns

1077
00:43:39,540 --> 00:43:42,240
this key and they store it in practice

1078
00:43:42,240 --> 00:43:44,940
we can replace this with a QR code

1079
00:43:44,940 --> 00:43:47,160
exchange and then Alice and Bob can do

1080
00:43:47,160 --> 00:43:49,260
any further computations over an

1081
00:43:49,260 --> 00:43:50,880
authenticated Bluetooth Channel we won't

1082
00:43:50,880 --> 00:43:52,619
talk about what those further

1083
00:43:52,619 --> 00:43:54,839
computations are but just giving you an

1084
00:43:54,839 --> 00:43:56,339
idea

1085
00:43:56,339 --> 00:43:58,140
and they now share a key that's rooted

1086
00:43:58,140 --> 00:44:00,119
in their physical interaction

1087
00:44:00,119 --> 00:44:01,920
we can use this to build an annotation

1088
00:44:01,920 --> 00:44:04,260
system so this is the tigrow server and

1089
00:44:04,260 --> 00:44:05,700
on the tigrow server they have a shared

1090
00:44:05,700 --> 00:44:07,319
encrypted mailbox again we don't have

1091
00:44:07,319 --> 00:44:08,400
time to go into the details

1092
00:44:08,400 --> 00:44:10,440
unfortunately but the shared encrypted

1093
00:44:10,440 --> 00:44:12,660
mailbox is authenticated based on the

1094
00:44:12,660 --> 00:44:14,880
key kab so only Alice and Bob have

1095
00:44:14,880 --> 00:44:16,500
access to this mailbox

1096
00:44:16,500 --> 00:44:18,420
and so now let's say Alice meets Charlie

1097
00:44:18,420 --> 00:44:21,180
and Alice wants to let um their contacts

1098
00:44:21,180 --> 00:44:24,180
know that Charlie is or is not a trusted

1099
00:44:24,180 --> 00:44:26,579
person that if they meet Charlie that

1100
00:44:26,579 --> 00:44:28,619
they can kind of tell from Alice's

1101
00:44:28,619 --> 00:44:30,660
opinion whether what the trust level for

1102
00:44:30,660 --> 00:44:33,180
Charlie should be so maybe Alice says I

1103
00:44:33,180 --> 00:44:34,859
met them in a mutual Aid event they seem

1104
00:44:34,859 --> 00:44:36,599
trustworthy or maybe Alice didn't have

1105
00:44:36,599 --> 00:44:37,800
such a good opinion and they were

1106
00:44:37,800 --> 00:44:39,359
agitating at was supposed to be a

1107
00:44:39,359 --> 00:44:42,240
peaceful event and so Alice annotates

1108
00:44:42,240 --> 00:44:44,880
sends The annotation and stores it in

1109
00:44:44,880 --> 00:44:46,980
the mailbox now let's say Bob meets

1110
00:44:46,980 --> 00:44:49,020
Charlie and Bob wants to check and see

1111
00:44:49,020 --> 00:44:51,060
if they have any Mutual contacts and

1112
00:44:51,060 --> 00:44:53,700
what those Mutual contacts have said

1113
00:44:53,700 --> 00:44:57,060
so Bob can get the mail and learn uh

1114
00:44:57,060 --> 00:45:00,060
whether Charlie is is trustworthy

1115
00:45:00,060 --> 00:45:03,240
um in Alice's opinion or not

1116
00:45:03,240 --> 00:45:05,579
this works for events comments posts

1117
00:45:05,579 --> 00:45:07,200
anything you can hash essentially so

1118
00:45:07,200 --> 00:45:08,460
let's say there's an event that's a

1119
00:45:08,460 --> 00:45:10,560
protest online and that Alice sees and

1120
00:45:10,560 --> 00:45:12,900
the organizer's eve Alice can hash this

1121
00:45:12,900 --> 00:45:15,180
event into an identifier and then say

1122
00:45:15,180 --> 00:45:16,800
this event is being organized by friends

1123
00:45:16,800 --> 00:45:18,420
hope to see you there so now all of

1124
00:45:18,420 --> 00:45:19,859
Alice's contacts will know this is a

1125
00:45:19,859 --> 00:45:22,560
trustworthy event or maybe Alice says no

1126
00:45:22,560 --> 00:45:24,240
one can confirm the identity of Eve

1127
00:45:24,240 --> 00:45:26,579
proceed with caution sends to the mail

1128
00:45:26,579 --> 00:45:29,220
mailbox and now Bob if Bob sees the same

1129
00:45:29,220 --> 00:45:31,500
event can go and check the mailbox and

1130
00:45:31,500 --> 00:45:33,720
see whether they should trust this event

1131
00:45:33,720 --> 00:45:36,900
and show up and risk showing up

1132
00:45:36,900 --> 00:45:38,460
so they can now digitally and

1133
00:45:38,460 --> 00:45:40,140
confidentially share trust assessments

1134
00:45:40,140 --> 00:45:42,599
of any person place or thing

1135
00:45:42,599 --> 00:45:45,660
this is a very high level overview of

1136
00:45:45,660 --> 00:45:47,339
the trust metrics so here you have an

1137
00:45:47,339 --> 00:45:50,460
example of a social network graph where

1138
00:45:50,460 --> 00:45:52,680
the one represents a trust relationship

1139
00:45:52,680 --> 00:45:54,480
so here

1140
00:45:54,480 --> 00:45:56,579
um Charlie trusts Alice and Bob trust

1141
00:45:56,579 --> 00:45:59,099
Alice however no one trusts Charlie

1142
00:45:59,099 --> 00:46:02,280
necessarily so that that would be a zero

1143
00:46:02,280 --> 00:46:05,040
and we would expect our hypothesis is

1144
00:46:05,040 --> 00:46:06,900
that over this grounded social network

1145
00:46:06,900 --> 00:46:09,420
the hyperlink induced topic search or

1146
00:46:09,420 --> 00:46:11,220
hits algorithm might be able to give us

1147
00:46:11,220 --> 00:46:13,200
meaningful measures of a person's

1148
00:46:13,200 --> 00:46:15,540
connectivity so their physical proximity

1149
00:46:15,540 --> 00:46:17,940
to trusted organizers

1150
00:46:17,940 --> 00:46:21,359
or their leadership role in relation to

1151
00:46:21,359 --> 00:46:23,339
others so in this context lots of people

1152
00:46:23,339 --> 00:46:25,619
trust Alice so maybe Alice can show

1153
00:46:25,619 --> 00:46:28,200
others that they're a leader with

1154
00:46:28,200 --> 00:46:30,060
respect to other people there are

1155
00:46:30,060 --> 00:46:32,099
disclaimers here these quantifiable

1156
00:46:32,099 --> 00:46:33,540
metrics are still functions of

1157
00:46:33,540 --> 00:46:35,280
qualitative metrics so this is very much

1158
00:46:35,280 --> 00:46:37,020
not just putting numbers on things we

1159
00:46:37,020 --> 00:46:38,339
have to be careful about what do these

1160
00:46:38,339 --> 00:46:40,740
numbers mean and so the zero and one for

1161
00:46:40,740 --> 00:46:42,119
example might be the wrong way to go

1162
00:46:42,119 --> 00:46:44,660
about this we might use a more

1163
00:46:44,660 --> 00:46:47,760
fine-grained scale using a survey for

1164
00:46:47,760 --> 00:46:50,760
example and this data digitizing this

1165
00:46:50,760 --> 00:46:52,800
data even an encrypted form may still be

1166
00:46:52,800 --> 00:46:54,060
too risky so we want to be really

1167
00:46:54,060 --> 00:46:56,280
careful to communicate what we are

1168
00:46:56,280 --> 00:46:59,040
generating and sharing

1169
00:46:59,040 --> 00:47:00,720
the long-term goals for this project

1170
00:47:00,720 --> 00:47:03,780
first to finish the analysis and then a

1171
00:47:03,780 --> 00:47:07,160
bunch of really long-term goals are to

1172
00:47:07,160 --> 00:47:09,240
prototype and then build this into

1173
00:47:09,240 --> 00:47:12,599
applications and help welcome so if

1174
00:47:12,599 --> 00:47:14,040
you're interested in this project for

1175
00:47:14,040 --> 00:47:15,300
example we need help on the

1176
00:47:15,300 --> 00:47:17,700
implementation side and also conducting

1177
00:47:17,700 --> 00:47:19,440
user studies to figure out if we really

1178
00:47:19,440 --> 00:47:21,780
do have the right Notions of trust and

1179
00:47:21,780 --> 00:47:23,339
to get some of these Design Elements

1180
00:47:23,339 --> 00:47:24,780
nailed down as well

1181
00:47:24,780 --> 00:47:26,880
and phase two is to build out

1182
00:47:26,880 --> 00:47:30,060
applications that are more specific to

1183
00:47:30,060 --> 00:47:32,460
the context of what people actually need

1184
00:47:32,460 --> 00:47:34,920
so the one size fits one we're going to

1185
00:47:34,920 --> 00:47:36,240
have a lot of different iterations of

1186
00:47:36,240 --> 00:47:37,859
this different optimizations for

1187
00:47:37,859 --> 00:47:39,119
different groups

1188
00:47:39,119 --> 00:47:40,920
and finally just to think about what

1189
00:47:40,920 --> 00:47:42,480
kind of world we want to build with this

1190
00:47:42,480 --> 00:47:44,579
work so just keep keeping with some of

1191
00:47:44,579 --> 00:47:46,020
the consistent questions that we've

1192
00:47:46,020 --> 00:47:47,880
asked throughout the talk and and

1193
00:47:47,880 --> 00:47:49,980
thinking about those

1194
00:47:49,980 --> 00:47:52,619
with that I'll conclude thanks for

1195
00:47:52,619 --> 00:47:53,260
listening

1196
00:47:53,260 --> 00:47:55,360
[Applause]

1197
00:47:55,360 --> 00:47:58,739
[Music]

1198
00:48:02,760 --> 00:48:04,500
so we have time for maybe one quick

1199
00:48:04,500 --> 00:48:07,020
question and there are a couple here on

1200
00:48:07,020 --> 00:48:08,160
Zoom

1201
00:48:08,160 --> 00:48:09,420
so

1202
00:48:09,420 --> 00:48:12,859
Mike asks

1203
00:48:13,140 --> 00:48:14,640
says the solution that you're presenting

1204
00:48:14,640 --> 00:48:15,900
is for the group of people that are

1205
00:48:15,900 --> 00:48:17,280
already connected in a form of community

1206
00:48:17,280 --> 00:48:19,680
or ideas the others that are not aware

1207
00:48:19,680 --> 00:48:21,780
of the situation might not seek such

1208
00:48:21,780 --> 00:48:23,520
complex approaches do you have any plans

1209
00:48:23,520 --> 00:48:25,440
or ideas on connecting external people

1210
00:48:25,440 --> 00:48:27,720
to existing communities and to make it

1211
00:48:27,720 --> 00:48:30,720
safe and easy for them to do so

1212
00:48:30,720 --> 00:48:32,819
yeah that's a great question

1213
00:48:32,819 --> 00:48:35,160
um so I think the public private

1214
00:48:35,160 --> 00:48:38,640
Paradigm balance here is is important

1215
00:48:38,640 --> 00:48:40,560
want to maintain a certain public

1216
00:48:40,560 --> 00:48:43,200
profile to bring people in and this is a

1217
00:48:43,200 --> 00:48:44,520
consistent Trend that we've seen in

1218
00:48:44,520 --> 00:48:46,020
these qualitative studies that there is

1219
00:48:46,020 --> 00:48:48,420
a a public-facing aspect of information

1220
00:48:48,420 --> 00:48:51,240
sharing and a private facing aspect and

1221
00:48:51,240 --> 00:48:53,940
so I think this crypto system is more

1222
00:48:53,940 --> 00:48:57,359
for the private facing aspect and so

1223
00:48:57,359 --> 00:48:59,400
what what it can do is it can also give

1224
00:48:59,400 --> 00:49:00,900
us some added protection in the

1225
00:49:00,900 --> 00:49:03,420
public-facing aspect as well but you can

1226
00:49:03,420 --> 00:49:05,460
still have a public-facing aspect so it

1227
00:49:05,460 --> 00:49:06,839
allows you to kind of incorporate more

1228
00:49:06,839 --> 00:49:09,359
trust into the public facing aspect and

1229
00:49:09,359 --> 00:49:12,599
I do think that these existing channels

1230
00:49:12,599 --> 00:49:14,760
so for example social media and reaching

1231
00:49:14,760 --> 00:49:17,520
people directly with community outreach

1232
00:49:17,520 --> 00:49:20,760
is a great way to bring people in and to

1233
00:49:20,760 --> 00:49:23,880
get them involved in organizing and then

1234
00:49:23,880 --> 00:49:25,560
you can introduce them to the more

1235
00:49:25,560 --> 00:49:27,540
private facing tools

1236
00:49:27,540 --> 00:49:29,819
great thanks so much so let's thank Lee

1237
00:49:29,819 --> 00:49:32,060
again

1238
00:49:36,420 --> 00:49:38,579
and I'm happy to introduce the last

1239
00:49:38,579 --> 00:49:41,339
speaker of the session Sophia seli is a

1240
00:49:41,339 --> 00:49:43,740
cryptography researcher at Brave and she

1241
00:49:43,740 --> 00:49:45,960
works on a variety of privacy privacy

1242
00:49:45,960 --> 00:49:47,520
Technologies including secure messaging

1243
00:49:47,520 --> 00:49:49,319
privacy pass private information

1244
00:49:49,319 --> 00:49:52,079
retrieval and many more things so she's

1245
00:49:52,079 --> 00:49:54,119
been a crypto cryptographic engineer at

1246
00:49:54,119 --> 00:49:56,640
cloudflare and holds a couple leadership

1247
00:49:56,640 --> 00:49:58,740
roles in the ITF working on post Quantum

1248
00:49:58,740 --> 00:50:01,440
crypto and also human rights and

1249
00:50:01,440 --> 00:50:03,960
protocols and on top of all that she led

1250
00:50:03,960 --> 00:50:06,300
the design of the version four of the

1251
00:50:06,300 --> 00:50:08,460
off the Record messaging protocol which

1252
00:50:08,460 --> 00:50:10,319
you I'm sure I've heard of so please

1253
00:50:10,319 --> 00:50:11,520
take it away

1254
00:50:11,520 --> 00:50:13,200
thank you very much

1255
00:50:13,200 --> 00:50:15,540
Henry for that introduction and today

1256
00:50:15,540 --> 00:50:17,099
what I'm going to be talking about is

1257
00:50:17,099 --> 00:50:18,480
what it means actually to design

1258
00:50:18,480 --> 00:50:20,579
cryptography for small organization some

1259
00:50:20,579 --> 00:50:22,260
projects and what we're going to be

1260
00:50:22,260 --> 00:50:24,060
using today is an example of two

1261
00:50:24,060 --> 00:50:26,220
projects that are going to serve as

1262
00:50:26,220 --> 00:50:28,220
examples they have some limitations

1263
00:50:28,220 --> 00:50:30,780
those two schemes are the star scheme

1264
00:50:30,780 --> 00:50:32,460
and the Fredo Pierre schemes and if you

1265
00:50:32,460 --> 00:50:34,079
want to find more information about them

1266
00:50:34,079 --> 00:50:36,720
you can go and click those links in the

1267
00:50:36,720 --> 00:50:39,359
slide this is also a joint work

1268
00:50:39,359 --> 00:50:41,220
submission with Alex Davidson and Peter

1269
00:50:41,220 --> 00:50:44,880
Schneider with that let's get into it

1270
00:50:44,880 --> 00:50:47,520
so just to leave it set the scene and

1271
00:50:47,520 --> 00:50:49,260
this talk actually doesn't concern that

1272
00:50:49,260 --> 00:50:51,599
much about or happily on the theoretical

1273
00:50:51,599 --> 00:50:53,819
concerns of cryptography but rather you

1274
00:50:53,819 --> 00:50:55,680
can sense about who benefits come from

1275
00:50:55,680 --> 00:50:57,839
cryptography and what kind of systems we

1276
00:50:57,839 --> 00:50:59,940
decide to deploy and release so one of

1277
00:50:59,940 --> 00:51:01,380
the things that we had in some of the

1278
00:51:01,380 --> 00:51:03,000
previous talk is that sometimes when we

1279
00:51:03,000 --> 00:51:04,619
design cryptography we're actually

1280
00:51:04,619 --> 00:51:07,260
designing it from our world view from

1281
00:51:07,260 --> 00:51:08,640
the limits of our language from the

1282
00:51:08,640 --> 00:51:10,440
limits of our world and these sometimes

1283
00:51:10,440 --> 00:51:12,059
don't serve all of the users and all of

1284
00:51:12,059 --> 00:51:13,740
the social contexts of those users

1285
00:51:13,740 --> 00:51:15,720
because we have limitations where we are

1286
00:51:15,720 --> 00:51:16,980
actually design it because we're

1287
00:51:16,980 --> 00:51:19,079
limiting in our so we sometimes should

1288
00:51:19,079 --> 00:51:20,819
describe actually to create to crypto

1289
00:51:20,819 --> 00:51:23,099
create cryptography that does not serve

1290
00:51:23,099 --> 00:51:25,079
only the users that look like us but

1291
00:51:25,079 --> 00:51:28,680
also many other cases of users

1292
00:51:28,680 --> 00:51:30,720
so just to also to set the scene some

1293
00:51:30,720 --> 00:51:32,460
sense cryptography in practice actually

1294
00:51:32,460 --> 00:51:34,619
does not work because sometimes it

1295
00:51:34,619 --> 00:51:36,900
doesn't take account into account many

1296
00:51:36,900 --> 00:51:38,940
cases that are not considered Niche

1297
00:51:38,940 --> 00:51:40,500
cases but actually there are cases that

1298
00:51:40,500 --> 00:51:42,420
happen in the real world so for example

1299
00:51:42,420 --> 00:51:44,460
authentication system sometimes fail in

1300
00:51:44,460 --> 00:51:45,839
practice because they don't take into

1301
00:51:45,839 --> 00:51:48,960
account device coercion situation or for

1302
00:51:48,960 --> 00:51:50,520
example situation of ongoing

1303
00:51:50,520 --> 00:51:52,500
surveillance that some intimate partner

1304
00:51:52,500 --> 00:51:55,200
violence cases suffer sometimes this

1305
00:51:55,200 --> 00:51:56,760
cryptography has high computational

1306
00:51:56,760 --> 00:51:58,980
costs and communication costs that are

1307
00:51:58,980 --> 00:52:00,660
unfeasible to be deployed by small

1308
00:52:00,660 --> 00:52:02,819
organizations and also by small projects

1309
00:52:02,819 --> 00:52:04,559
and this in turn translates that they

1310
00:52:04,559 --> 00:52:06,359
would have to be that they are going to

1311
00:52:06,359 --> 00:52:08,280
be having high Financial costs as well

1312
00:52:08,280 --> 00:52:09,960
that are again unfictionable to

1313
00:52:09,960 --> 00:52:12,000
unfeasible to be reached by a small

1314
00:52:12,000 --> 00:52:14,040
organization and small projects

1315
00:52:14,040 --> 00:52:15,720
sometimes this kind of cryptography is

1316
00:52:15,720 --> 00:52:17,940
not overtly concerned about policy or

1317
00:52:17,940 --> 00:52:20,220
legal uh concerns or about human rights

1318
00:52:20,220 --> 00:52:21,540
considerations

1319
00:52:21,540 --> 00:52:23,220
sometimes this contributes to a

1320
00:52:23,220 --> 00:52:24,780
centralized internet because if we're

1321
00:52:24,780 --> 00:52:26,579
only pushing cryptography that has high

1322
00:52:26,579 --> 00:52:28,680
computational and communicational costs

1323
00:52:28,680 --> 00:52:30,540
and that in turn turns into high

1324
00:52:30,540 --> 00:52:32,520
Financial costs this also means that

1325
00:52:32,520 --> 00:52:34,619
only big organizations are the ones that

1326
00:52:34,619 --> 00:52:36,599
are able to deploy and hence it also

1327
00:52:36,599 --> 00:52:38,460
contributes to centralizing the internet

1328
00:52:38,460 --> 00:52:41,099
even further so again what this maybe

1329
00:52:41,099 --> 00:52:42,720
actually means that we're actually

1330
00:52:42,720 --> 00:52:44,280
deploying privacy and security

1331
00:52:44,280 --> 00:52:46,260
considerations for the ones that can

1332
00:52:46,260 --> 00:52:48,540
afford it

1333
00:52:48,540 --> 00:52:50,760
so recently we have seen that some big

1334
00:52:50,760 --> 00:52:52,380
organization has been pushing forward

1335
00:52:52,380 --> 00:52:54,300
for actually putting into the real world

1336
00:52:54,300 --> 00:52:55,740
and deploying some new privacy

1337
00:52:55,740 --> 00:52:58,020
preserving schemes which again this is

1338
00:52:58,020 --> 00:52:59,640
really great because we actually have to

1339
00:52:59,640 --> 00:53:01,619
be pushing forward for these properties

1340
00:53:01,619 --> 00:53:03,420
to exist in the real world but sometimes

1341
00:53:03,420 --> 00:53:06,119
it does not work for the many so the two

1342
00:53:06,119 --> 00:53:07,500
be examples that have been pushed

1343
00:53:07,500 --> 00:53:08,880
forward in the recent years are

1344
00:53:08,880 --> 00:53:10,680
previously preserving measurements PPM

1345
00:53:10,680 --> 00:53:12,960
schemes and private information schemes

1346
00:53:12,960 --> 00:53:15,059
PIR schemes and the question that we

1347
00:53:15,059 --> 00:53:16,859
seek to answer in this talk is if this

1348
00:53:16,859 --> 00:53:18,780
proposals or the proposal schemes for

1349
00:53:18,780 --> 00:53:21,059
these two types the schemes can be used

1350
00:53:21,059 --> 00:53:22,800
or cannot be used by a small

1351
00:53:22,800 --> 00:53:24,420
organization that has constrained

1352
00:53:24,420 --> 00:53:27,200
budgets or even volunteer run

1353
00:53:27,200 --> 00:53:29,760
so the current proposed schemes that

1354
00:53:29,760 --> 00:53:31,380
right now are into consideration to be

1355
00:53:31,380 --> 00:53:34,440
deployed or standardized have either all

1356
00:53:34,440 --> 00:53:37,260
of this set of small problems they

1357
00:53:37,260 --> 00:53:39,119
either are communication a computational

1358
00:53:39,119 --> 00:53:41,220
and communicationally expensive they

1359
00:53:41,220 --> 00:53:42,839
sometimes rely on non-collutional

1360
00:53:42,839 --> 00:53:44,579
assumptions in which you will have to

1361
00:53:44,579 --> 00:53:46,859
have a set of non-colluding service so

1362
00:53:46,859 --> 00:53:48,540
sometimes in the real world are hard to

1363
00:53:48,540 --> 00:53:51,660
get by or expect several rounds of

1364
00:53:51,660 --> 00:53:53,160
communication between service and

1365
00:53:53,160 --> 00:53:54,660
between clients that in turns translate

1366
00:53:54,660 --> 00:53:57,059
to high compute communicational costs

1367
00:53:57,059 --> 00:53:59,640
you sometimes need to try to trust third

1368
00:53:59,640 --> 00:54:01,020
parties or to have a specialized

1369
00:54:01,020 --> 00:54:02,819
Hardware you require High Financial

1370
00:54:02,819 --> 00:54:04,500
costs because you're using complex

1371
00:54:04,500 --> 00:54:06,300
cryptography that sometimes is not going

1372
00:54:06,300 --> 00:54:08,280
to be available for all of the users of

1373
00:54:08,280 --> 00:54:10,020
the world because it requires specific

1374
00:54:10,020 --> 00:54:12,240
devices or requires a specific hardware

1375
00:54:12,240 --> 00:54:15,000
and in this case sometimes also it does

1376
00:54:15,000 --> 00:54:16,859
not work for many data types because it

1377
00:54:16,859 --> 00:54:18,240
only works for for example only

1378
00:54:18,240 --> 00:54:20,099
numerical data types and not for all the

1379
00:54:20,099 --> 00:54:22,020
data types and if you want all the data

1380
00:54:22,020 --> 00:54:23,520
does you have to implement now another

1381
00:54:23,520 --> 00:54:25,500
scheme which in turns translates that

1382
00:54:25,500 --> 00:54:27,000
you have to maintain two different code

1383
00:54:27,000 --> 00:54:29,400
spaces which again can lead to Security

1384
00:54:29,400 --> 00:54:33,440
box and also High Financial cost

1385
00:54:35,460 --> 00:54:37,980
okay so just again it is great to have

1386
00:54:37,980 --> 00:54:39,900
these schemes that aim to provide more

1387
00:54:39,900 --> 00:54:41,940
privacy preserving properties but as

1388
00:54:41,940 --> 00:54:43,559
these the only schemes that we choose to

1389
00:54:43,559 --> 00:54:45,780
standardize and deploys do the work for

1390
00:54:45,780 --> 00:54:47,940
everybody and in many cases or are we

1391
00:54:47,940 --> 00:54:49,680
forgetting maybe other uses that don't

1392
00:54:49,680 --> 00:54:51,839
look like like us are we limit in the

1393
00:54:51,839 --> 00:54:54,480
views of awards to only what we know

1394
00:54:54,480 --> 00:54:56,040
um should we also strive to actually

1395
00:54:56,040 --> 00:54:58,079
design cryptography for all the types of

1396
00:54:58,079 --> 00:55:00,480
uses on all the social situations that

1397
00:55:00,480 --> 00:55:01,920
are not the ones that we are aware of

1398
00:55:01,920 --> 00:55:03,780
and if we're trying to deploy these

1399
00:55:03,780 --> 00:55:05,400
systems that maybe are limiting to many

1400
00:55:05,400 --> 00:55:08,520
of them are we also denying access to

1401
00:55:08,520 --> 00:55:10,260
other systems because we are deploying

1402
00:55:10,260 --> 00:55:12,420
them so is this the only technology that

1403
00:55:12,420 --> 00:55:14,339
we choose to create

1404
00:55:14,339 --> 00:55:16,500
one example here that I highlighted this

1405
00:55:16,500 --> 00:55:18,420
is a quote from our research from

1406
00:55:18,420 --> 00:55:20,220
derechos digitalis and they went to

1407
00:55:20,220 --> 00:55:22,859
Chile and I asked and they asked several

1408
00:55:22,859 --> 00:55:24,720
people in Chile especially from the

1409
00:55:24,720 --> 00:55:27,000
rural areas to see if Biometrics

1410
00:55:27,000 --> 00:55:28,440
actually work for them in an

1411
00:55:28,440 --> 00:55:31,380
authentication a scheme system and then

1412
00:55:31,380 --> 00:55:32,880
what I found out is that for the many

1413
00:55:32,880 --> 00:55:34,619
this actually doesn't work because in

1414
00:55:34,619 --> 00:55:36,300
many rural areas people will have the

1415
00:55:36,300 --> 00:55:38,400
Biometrics not so clear because they do

1416
00:55:38,400 --> 00:55:40,980
manual work so this again authentication

1417
00:55:40,980 --> 00:55:42,720
is great but sometimes this does not

1418
00:55:42,720 --> 00:55:44,640
work for everybody and sometimes when we

1419
00:55:44,640 --> 00:55:46,440
push forward to some of these schemes as

1420
00:55:46,440 --> 00:55:48,660
for examples Biometrics it means in turn

1421
00:55:48,660 --> 00:55:50,880
that we are denying access to other

1422
00:55:50,880 --> 00:55:53,160
services to maybe accessing them their

1423
00:55:53,160 --> 00:55:55,260
health services or their education or

1424
00:55:55,260 --> 00:55:56,940
their economic records because we're

1425
00:55:56,940 --> 00:55:59,339
only having this specific system that

1426
00:55:59,339 --> 00:56:01,680
does not work for them so do this

1427
00:56:01,680 --> 00:56:03,420
privacy preserving schemes that I just

1428
00:56:03,420 --> 00:56:05,400
highlighted in some previous slides do

1429
00:56:05,400 --> 00:56:07,559
they also fall in the same trap for

1430
00:56:07,559 --> 00:56:09,900
example if you cannot run then really

1431
00:56:09,900 --> 00:56:11,819
expensive Fieri scheme does that mean

1432
00:56:11,819 --> 00:56:13,559
that you will not be able to access any

1433
00:56:13,559 --> 00:56:15,660
specific database that for example holds

1434
00:56:15,660 --> 00:56:17,579
your health records or your academic

1435
00:56:17,579 --> 00:56:19,740
transactions and in for example you

1436
00:56:19,740 --> 00:56:21,960
cannot run on a specific expense in PPM

1437
00:56:21,960 --> 00:56:23,880
scheme does it means that then your use

1438
00:56:23,880 --> 00:56:25,680
case will not be taken into account when

1439
00:56:25,680 --> 00:56:27,300
you take those measurements from end

1440
00:56:27,300 --> 00:56:29,400
users

1441
00:56:29,400 --> 00:56:32,040
so again um just again to ask that

1442
00:56:32,040 --> 00:56:33,900
question do they work only for the ones

1443
00:56:33,900 --> 00:56:36,000
that can afford it and again we do need

1444
00:56:36,000 --> 00:56:37,619
this privacy preserving schemes because

1445
00:56:37,619 --> 00:56:39,900
for example we need PPM skins because we

1446
00:56:39,900 --> 00:56:41,880
need to know how systems operate in

1447
00:56:41,880 --> 00:56:43,740
different cases how some software how

1448
00:56:43,740 --> 00:56:46,020
assistance work those are essential and

1449
00:56:46,020 --> 00:56:47,819
it is essential to actually get them in

1450
00:56:47,819 --> 00:56:49,859
a privacy preserving way and we also

1451
00:56:49,859 --> 00:56:51,599
need Pierre schemes because private

1452
00:56:51,599 --> 00:56:53,040
information retrieval should be

1453
00:56:53,040 --> 00:56:54,480
something that is available for

1454
00:56:54,480 --> 00:56:56,339
everybody if we want to query on a

1455
00:56:56,339 --> 00:56:58,319
specific database

1456
00:56:58,319 --> 00:57:00,119
so let's look just at one specific

1457
00:57:00,119 --> 00:57:02,460
limitation some of the ppms schemes and

1458
00:57:02,460 --> 00:57:04,380
some of the pr schemes for example talk

1459
00:57:04,380 --> 00:57:06,240
about the limitation of having a

1460
00:57:06,240 --> 00:57:08,040
non-collarian server and what this is

1461
00:57:08,040 --> 00:57:10,079
great in 3D and it's easy to write about

1462
00:57:10,079 --> 00:57:11,700
it in theory in practice sometimes

1463
00:57:11,700 --> 00:57:13,859
there's limitations because maybe that

1464
00:57:13,859 --> 00:57:15,599
private data that you're collecting from

1465
00:57:15,599 --> 00:57:17,640
your users cannot be located in specific

1466
00:57:17,640 --> 00:57:19,200
regions in the world even the

1467
00:57:19,200 --> 00:57:21,180
representation of that so where are you

1468
00:57:21,180 --> 00:57:22,680
going to be placing that third

1469
00:57:22,680 --> 00:57:24,720
non-colored in server has to be in a

1470
00:57:24,720 --> 00:57:26,579
specific consideration there's a lot of

1471
00:57:26,579 --> 00:57:28,140
legal and policy considerations that

1472
00:57:28,140 --> 00:57:30,240
you'd have to take into account and also

1473
00:57:30,240 --> 00:57:32,099
if that specific model has high

1474
00:57:32,099 --> 00:57:34,200
communication and computational cost

1475
00:57:34,200 --> 00:57:36,540
that translates into Financial cost thus

1476
00:57:36,540 --> 00:57:38,160
it means that this third-party survey

1477
00:57:38,160 --> 00:57:39,300
that you're going to be using for

1478
00:57:39,300 --> 00:57:41,400
non-colluding is going to be a pay for

1479
00:57:41,400 --> 00:57:43,440
usage one and if it does the case that

1480
00:57:43,440 --> 00:57:45,119
in turn means that some users will not

1481
00:57:45,119 --> 00:57:46,740
be able to access this because they

1482
00:57:46,740 --> 00:57:48,660
don't have the financial resources to do

1483
00:57:48,660 --> 00:57:49,920
so

1484
00:57:49,920 --> 00:57:51,780
so again this is not a theoretical

1485
00:57:51,780 --> 00:57:53,640
concern teams building software for

1486
00:57:53,640 --> 00:57:55,380
privacy critical users are heavily

1487
00:57:55,380 --> 00:57:56,819
constrained budgets or maybe even

1488
00:57:56,819 --> 00:57:59,220
volunteer run cryptography systems are

1489
00:57:59,220 --> 00:58:00,960
required our budgets will not serve the

1490
00:58:00,960 --> 00:58:02,760
many categories of uses even though they

1491
00:58:02,760 --> 00:58:04,800
are pushing for really nice properties

1492
00:58:04,800 --> 00:58:06,960
so maybe let's look at a change of

1493
00:58:06,960 --> 00:58:09,000
priority and that's the subject of the

1494
00:58:09,000 --> 00:58:10,200
research that we were currently

1495
00:58:10,200 --> 00:58:11,880
currently undergoing

1496
00:58:11,880 --> 00:58:13,800
um maybe some smaller Organization for

1497
00:58:13,800 --> 00:58:15,660
example my prioritize theme sauce

1498
00:58:15,660 --> 00:58:17,460
simpler trust assumptions and

1499
00:58:17,460 --> 00:58:19,500
requirements simpler or more established

1500
00:58:19,500 --> 00:58:21,839
cryptographic Primitives lower cost and

1501
00:58:21,839 --> 00:58:23,640
value failure modes and with this in

1502
00:58:23,640 --> 00:58:25,559
mind we seek to design these two people

1503
00:58:25,559 --> 00:58:29,160
this PPM ampere scheme and again these

1504
00:58:29,160 --> 00:58:30,660
are not like the perfect schemes they

1505
00:58:30,660 --> 00:58:32,339
have limitations but at least what we

1506
00:58:32,339 --> 00:58:34,319
try is half the base or what it means to

1507
00:58:34,319 --> 00:58:36,480
design for maybe other uses that don't

1508
00:58:36,480 --> 00:58:38,460
look like us

1509
00:58:38,460 --> 00:58:40,260
so let's start for the first one which

1510
00:58:40,260 --> 00:58:42,359
is this PPM scheme which is a scheme

1511
00:58:42,359 --> 00:58:43,980
that takes measurement from clients in a

1512
00:58:43,980 --> 00:58:45,839
privacy preserving way if you want to

1513
00:58:45,839 --> 00:58:47,400
learn more about it again I invite you

1514
00:58:47,400 --> 00:58:49,799
to click on the links of this slide

1515
00:58:49,799 --> 00:58:51,420
so what it is is that it's okay

1516
00:58:51,420 --> 00:58:53,579
threshold aggregation scheme that uses

1517
00:58:53,579 --> 00:58:55,680
really boring cryptography it uses both

1518
00:58:55,680 --> 00:58:58,980
oprfs for a local for our deterministic

1519
00:58:58,980 --> 00:59:01,079
Randomness generation you can also

1520
00:59:01,079 --> 00:59:02,760
generate these Randomness in a local

1521
00:59:02,760 --> 00:59:04,740
manner by using hash functions for

1522
00:59:04,740 --> 00:59:07,319
example it uses adapt she crocheting but

1523
00:59:07,319 --> 00:59:09,240
any other kind of secretion scheme will

1524
00:59:09,240 --> 00:59:11,160
also do and it uses an encryption

1525
00:59:11,160 --> 00:59:13,859
algorithm as AES so it's really easy to

1526
00:59:13,859 --> 00:59:15,599
get by all of these boring cryptography

1527
00:59:15,599 --> 00:59:17,040
because there's a lot of Open Source

1528
00:59:17,040 --> 00:59:19,319
implementation of that it works with any

1529
00:59:19,319 --> 00:59:21,540
data type and of course because it is a

1530
00:59:21,540 --> 00:59:23,579
k threshold aggregation scheme it has a

1531
00:59:23,579 --> 00:59:25,799
degree of leakage it has three phases

1532
00:59:25,799 --> 00:59:27,420
and I'm just going to go briefly over

1533
00:59:27,420 --> 00:59:28,680
them because we don't have that much

1534
00:59:28,680 --> 00:59:31,260
time I'm really happy to talk to anybody

1535
00:59:31,260 --> 00:59:33,059
that is more interesting in the scheme

1536
00:59:33,059 --> 00:59:35,579
later after this song so the first one

1537
00:59:35,579 --> 00:59:37,140
is just this Randomness instruction that

1538
00:59:37,140 --> 00:59:38,640
I was talking to you about basically

1539
00:59:38,640 --> 00:59:40,319
you're going to get one measurement from

1540
00:59:40,319 --> 00:59:41,819
a specific line and you're going to

1541
00:59:41,819 --> 00:59:44,040
deterministically derive Randomness for

1542
00:59:44,040 --> 00:59:46,799
it by using an opr server for example or

1543
00:59:46,799 --> 00:59:49,260
by using a hash function then we go into

1544
00:59:49,260 --> 00:59:51,240
the second phase which is one you have

1545
00:59:51,240 --> 00:59:52,740
the randomness that we're going to be

1546
00:59:52,740 --> 00:59:54,839
calling R1 you're going to divide it

1547
00:59:54,839 --> 00:59:58,859
into three values which is R1 R2 and R3

1548
00:59:58,859 --> 01:00:00,299
from R1 you're going to

1549
01:00:00,299 --> 01:00:02,339
deterministically derive asymmetric key

1550
01:00:02,339 --> 01:00:04,020
which you're going to use to encrypt

1551
01:00:04,020 --> 01:00:05,520
your specific measurement and we're

1552
01:00:05,520 --> 01:00:08,700
going to call that ciphertext c i

1553
01:00:08,700 --> 01:00:10,799
and also you're going to see cliche that

1554
01:00:10,799 --> 01:00:12,780
is specific secret the secret is going

1555
01:00:12,780 --> 01:00:14,880
to be R1 you're going to see cliche by

1556
01:00:14,880 --> 01:00:18,000
using locally the derived R2 value and

1557
01:00:18,000 --> 01:00:19,619
you're going to be returning some shares

1558
01:00:19,619 --> 01:00:21,599
and as a client what you do is that you

1559
01:00:21,599 --> 01:00:23,099
create a message that is going to be a

1560
01:00:23,099 --> 01:00:25,980
concatenation of c i uh the share and a

1561
01:00:25,980 --> 01:00:28,079
specific tag that is just a way that the

1562
01:00:28,079 --> 01:00:29,880
server is going to aggregate all of the

1563
01:00:29,880 --> 01:00:31,140
measurements

1564
01:00:31,140 --> 01:00:33,480
from the server size once you get all of

1565
01:00:33,480 --> 01:00:35,339
these messages what you're going to do

1566
01:00:35,339 --> 01:00:37,319
is that you're going to create a patches

1567
01:00:37,319 --> 01:00:39,540
subset of case size in which you're

1568
01:00:39,540 --> 01:00:41,040
going to put all of the measurements

1569
01:00:41,040 --> 01:00:42,960
depending if they share the same tag

1570
01:00:42,960 --> 01:00:44,880
that's why the attack is important you

1571
01:00:44,880 --> 01:00:46,859
divide them in this subsets of case side

1572
01:00:46,859 --> 01:00:49,500
then you perform the recovery algorithm

1573
01:00:49,500 --> 01:00:52,440
into that case size you recover R1 and

1574
01:00:52,440 --> 01:00:53,880
you derive deterministically the

1575
01:00:53,880 --> 01:00:55,380
symmetric key and then you're able to

1576
01:00:55,380 --> 01:00:57,119
decrypt the specific measurement that

1577
01:00:57,119 --> 01:00:58,440
your clients sent

1578
01:00:58,440 --> 01:01:00,960
and as you see this is very boring it's

1579
01:01:00,960 --> 01:01:02,700
very easy to do

1580
01:01:02,700 --> 01:01:04,740
so it's really easy to implement it uses

1581
01:01:04,740 --> 01:01:07,079
boring cryptography you have don't need

1582
01:01:07,079 --> 01:01:08,700
any kind of trust assumption on a

1583
01:01:08,700 --> 01:01:10,380
non-colluding survey because you have a

1584
01:01:10,380 --> 01:01:11,880
single server that does the aggregation

1585
01:01:11,880 --> 01:01:13,799
for you and this in turn means that this

1586
01:01:13,799 --> 01:01:16,200
scheme has cheap uh communication and

1587
01:01:16,200 --> 01:01:18,240
computational costs which means that a

1588
01:01:18,240 --> 01:01:20,040
lot of users indeed can use it and a

1589
01:01:20,040 --> 01:01:21,839
small organization and smaller projects

1590
01:01:21,839 --> 01:01:23,819
can actually implement it and indeed

1591
01:01:23,819 --> 01:01:25,440
from the financial level what we found

1592
01:01:25,440 --> 01:01:27,420
out is that it's 20 times cheaper than

1593
01:01:27,420 --> 01:01:28,619
the cost of rather than the nearest

1594
01:01:28,619 --> 01:01:30,799
scheme similar to a star

1595
01:01:30,799 --> 01:01:33,119
now let's look at the other scheme which

1596
01:01:33,119 --> 01:01:34,799
is a PIR schema private information

1597
01:01:34,799 --> 01:01:36,960
retrieval one if you want to learn more

1598
01:01:36,960 --> 01:01:38,760
about it again I welcome you to click on

1599
01:01:38,760 --> 01:01:40,260
the links on the slide

1600
01:01:40,260 --> 01:01:42,420
so it's called Frodo PIR because it's

1601
01:01:42,420 --> 01:01:45,000
based on the lwe this in the decisional

1602
01:01:45,000 --> 01:01:46,920
lwe Assumption

1603
01:01:46,920 --> 01:01:48,359
um and not on the ring one so it's

1604
01:01:48,359 --> 01:01:49,799
called Frodo because you're tossing the

1605
01:01:49,799 --> 01:01:51,299
ring but you're still hiding your query

1606
01:01:51,299 --> 01:01:52,980
from the server then in this case is

1607
01:01:52,980 --> 01:01:54,119
Sauron

1608
01:01:54,119 --> 01:01:56,339
and how is it face is is basically that

1609
01:01:56,339 --> 01:01:59,040
this is a PR scheme and it's a stateful

1610
01:01:59,040 --> 01:02:00,599
one which means that we're going to have

1611
01:02:00,599 --> 01:02:02,400
an offline face and an online phase

1612
01:02:02,400 --> 01:02:04,740
basically on the offline space what we

1613
01:02:04,740 --> 01:02:06,839
do is that we prepare the database and

1614
01:02:06,839 --> 01:02:09,000
also a set of query parameters so later

1615
01:02:09,000 --> 01:02:10,559
in the online phase we can actually

1616
01:02:10,559 --> 01:02:12,599
launch the query and get the value back

1617
01:02:12,599 --> 01:02:14,339
now again going to go into the

1618
01:02:14,339 --> 01:02:16,319
mathematical details of this but if

1619
01:02:16,319 --> 01:02:18,180
we're interested more about it please

1620
01:02:18,180 --> 01:02:20,640
find me after the talk

1621
01:02:20,640 --> 01:02:23,460
so as I said this is an LW base which in

1622
01:02:23,460 --> 01:02:25,440
turns means that is really easy to

1623
01:02:25,440 --> 01:02:26,940
implement because it requires no

1624
01:02:26,940 --> 01:02:28,980
polynomial arithmetic or phosphorary

1625
01:02:28,980 --> 01:02:31,559
transforms and indeed the skin fits all

1626
01:02:31,559 --> 01:02:34,440
of the operations in 32 integers it also

1627
01:02:34,440 --> 01:02:36,299
again does not require any non-colluting

1628
01:02:36,299 --> 01:02:37,980
server because you have a single server

1629
01:02:37,980 --> 01:02:39,660
that is going to be returning you the

1630
01:02:39,660 --> 01:02:42,059
correct value that you query for in a

1631
01:02:42,059 --> 01:02:44,339
database in a private mode

1632
01:02:44,339 --> 01:02:46,559
and we also don't need to restore any

1633
01:02:46,559 --> 01:02:48,299
extra information apart from the

1634
01:02:48,299 --> 01:02:50,460
previous parameters that I just saw you

1635
01:02:50,460 --> 01:02:52,319
so that means that also from a memory

1636
01:02:52,319 --> 01:02:55,940
space is much much cheaper to run

1637
01:02:56,339 --> 01:02:58,619
okay so why it works again for a smaller

1638
01:02:58,619 --> 01:03:00,540
organization because again this is using

1639
01:03:00,540 --> 01:03:02,700
boring cryptography that is easy to to

1640
01:03:02,700 --> 01:03:05,579
implement and deploy it uses again one

1641
01:03:05,579 --> 01:03:07,500
single server model so you don't have to

1642
01:03:07,500 --> 01:03:08,940
try to find in the while and

1643
01:03:08,940 --> 01:03:10,799
non-coloring server rather just just

1644
01:03:10,799 --> 01:03:12,839
have one server and you're ready to go

1645
01:03:12,839 --> 01:03:15,180
you don't need to buy any specialized

1646
01:03:15,180 --> 01:03:17,220
hardware and you can easily implement it

1647
01:03:17,220 --> 01:03:19,440
onto maintain it

1648
01:03:19,440 --> 01:03:21,900
so just maybe add now to summarize after

1649
01:03:21,900 --> 01:03:23,579
looking at these schemes then in the

1650
01:03:23,579 --> 01:03:26,280
future what design considerations can we

1651
01:03:26,280 --> 01:03:27,059
have

1652
01:03:27,059 --> 01:03:29,099
so a little bit of inspiration from what

1653
01:03:29,099 --> 01:03:31,200
we saw boring cryptography does indeed

1654
01:03:31,200 --> 01:03:32,760
work in practice and sometimes it's

1655
01:03:32,760 --> 01:03:34,260
really good for smaller organizations

1656
01:03:34,260 --> 01:03:36,540
and projects and for a really big set of

1657
01:03:36,540 --> 01:03:38,819
uses even though it is sometimes

1658
01:03:38,819 --> 01:03:40,619
considered not novel enough all of The

1659
01:03:40,619 --> 01:03:42,180
cryptographic Primitives that I show you

1660
01:03:42,180 --> 01:03:43,859
in these schemes can be considered very

1661
01:03:43,859 --> 01:03:45,359
boring they have been in the literature

1662
01:03:45,359 --> 01:03:47,040
for decades now

1663
01:03:47,040 --> 01:03:49,020
um but they still work for many of the

1664
01:03:49,020 --> 01:03:51,180
cases that we need it is available then

1665
01:03:51,180 --> 01:03:54,119
for the many it is cheap it has fast it

1666
01:03:54,119 --> 01:03:56,579
is fast and has low computational costs

1667
01:03:56,579 --> 01:03:59,160
and it still has a lot of open problems

1668
01:03:59,160 --> 01:04:00,660
even though maybe they are not the most

1669
01:04:00,660 --> 01:04:02,339
noble ones there is still a lot of open

1670
01:04:02,339 --> 01:04:04,200
research problems on them

1671
01:04:04,200 --> 01:04:06,359
simple trust assumptions also work for a

1672
01:04:06,359 --> 01:04:08,099
smaller organization because it's easier

1673
01:04:08,099 --> 01:04:10,140
to think about in a model it only exists

1674
01:04:10,140 --> 01:04:11,940
one specific server that is either going

1675
01:04:11,940 --> 01:04:13,980
to be aggregating or performing queries

1676
01:04:13,980 --> 01:04:16,740
rather than trying to find another

1677
01:04:16,740 --> 01:04:18,839
server that is not going to be colluding

1678
01:04:18,839 --> 01:04:20,400
with that server

1679
01:04:20,400 --> 01:04:22,200
and just to give you a little bit of our

1680
01:04:22,200 --> 01:04:23,819
recommendation as part of your reserve

1681
01:04:23,819 --> 01:04:25,200
we do need to address also Financial

1682
01:04:25,200 --> 01:04:27,420
costs as far over our research it's not

1683
01:04:27,420 --> 01:04:29,400
enough to only say the computational

1684
01:04:29,400 --> 01:04:31,680
communicational cost of an scheme but

1685
01:04:31,680 --> 01:04:33,299
also how that translates into the

1686
01:04:33,299 --> 01:04:36,359
reality into Financial cost

1687
01:04:36,359 --> 01:04:38,280
and what we need is that we need as a

1688
01:04:38,280 --> 01:04:39,900
community to think about outside the

1689
01:04:39,900 --> 01:04:41,339
limits of our walls we need to design

1690
01:04:41,339 --> 01:04:43,140
also for people that might not look like

1691
01:04:43,140 --> 01:04:45,299
us that don't have access to all of the

1692
01:04:45,299 --> 01:04:46,799
resources that we have that maybe don't

1693
01:04:46,799 --> 01:04:48,599
have access to the devices that we have

1694
01:04:48,599 --> 01:04:50,579
or the good internet connectivity that

1695
01:04:50,579 --> 01:04:52,859
we have we also have to think about that

1696
01:04:52,859 --> 01:04:53,940
kind of people

1697
01:04:53,940 --> 01:04:56,099
privacy is crucial but it should not be

1698
01:04:56,099 --> 01:04:58,260
only for the ones that can afford it and

1699
01:04:58,260 --> 01:05:00,119
we should create systems that do not

1700
01:05:00,119 --> 01:05:02,220
deny access to other systems because

1701
01:05:02,220 --> 01:05:04,380
those people cannot run your specific

1702
01:05:04,380 --> 01:05:06,540
scheme they should still have access to

1703
01:05:06,540 --> 01:05:08,460
whatever Health database or educational

1704
01:05:08,460 --> 01:05:12,260
database they should have access to

1705
01:05:13,500 --> 01:05:15,480
so the limits over one need to be

1706
01:05:15,480 --> 01:05:16,980
expanded we need to do inclusive

1707
01:05:16,980 --> 01:05:18,839
cryptography design for diverse people

1708
01:05:18,839 --> 01:05:20,400
not everybody in the world will look

1709
01:05:20,400 --> 01:05:22,079
like us so we when we're actually

1710
01:05:22,079 --> 01:05:23,760
designing the schemes we also have to

1711
01:05:23,760 --> 01:05:25,500
think about the people that don't look

1712
01:05:25,500 --> 01:05:27,660
like us we need to provide privacy and

1713
01:05:27,660 --> 01:05:29,579
security properties for the many even

1714
01:05:29,579 --> 01:05:30,900
though if the schemes that end up

1715
01:05:30,900 --> 01:05:32,460
because of these are not know but enough

1716
01:05:32,460 --> 01:05:34,500
and are considered boring we need to

1717
01:05:34,500 --> 01:05:36,240
provide schemes that aim to enhance our

1718
01:05:36,240 --> 01:05:38,760
access rather than to deny it so this is

1719
01:05:38,760 --> 01:05:40,859
not easy and it's a huge challenging

1720
01:05:40,859 --> 01:05:42,420
task in which you have to do an

1721
01:05:42,420 --> 01:05:44,700
amalgamation of user research and also

1722
01:05:44,700 --> 01:05:46,859
of design research but we should

1723
01:05:46,859 --> 01:05:49,079
probably do it as a community

1724
01:05:49,079 --> 01:05:51,000
and with that I give you some references

1725
01:05:51,000 --> 01:05:53,460
and also just to let you know product

1726
01:05:53,460 --> 01:05:57,480
PIR is a design that we did but Henry

1727
01:05:57,480 --> 01:06:00,119
Korean gifts and his group also arrived

1728
01:06:00,119 --> 01:06:02,400
the same solution so I also listed their

1729
01:06:02,400 --> 01:06:03,960
paper over here if you're interested to

1730
01:06:03,960 --> 01:06:05,700
learn about it

1731
01:06:05,700 --> 01:06:07,550
and with that thank you very much

1732
01:06:07,550 --> 01:06:16,020
[Applause]

1733
01:06:16,020 --> 01:06:17,220
all right so we have time for a couple

1734
01:06:17,220 --> 01:06:19,619
of questions

1735
01:06:19,619 --> 01:06:21,240
so maybe I'll start off with one while

1736
01:06:21,240 --> 01:06:24,000
while we're waiting um have you thought

1737
01:06:24,000 --> 01:06:25,200
about using either of these Technologies

1738
01:06:25,200 --> 01:06:26,819
is it brief like what's the status of

1739
01:06:26,819 --> 01:06:28,740
deployment or how those discussions

1740
01:06:28,740 --> 01:06:30,720
going yeah yeah I actually have been

1741
01:06:30,720 --> 01:06:32,280
thinking about that right now this time

1742
01:06:32,280 --> 01:06:35,280
we're going work to put uh the star the

1743
01:06:35,280 --> 01:06:37,740
PPM scheme into the actual browser and

1744
01:06:37,740 --> 01:06:40,079
that should be landing hopefully by the

1745
01:06:40,079 --> 01:06:43,200
next uh trim trimester and about for the

1746
01:06:43,200 --> 01:06:45,599
PIR yes but specifically on the case of

1747
01:06:45,599 --> 01:06:47,160
doing for example

1748
01:06:47,160 --> 01:06:49,020
um compromise credentials check-in

1749
01:06:49,020 --> 01:06:50,460
because that's a system that you can

1750
01:06:50,460 --> 01:06:53,099
actually use par for and have it in the

1751
01:06:53,099 --> 01:06:54,660
browser will mean also that the users

1752
01:06:54,660 --> 01:06:56,220
can check if their password for example

1753
01:06:56,220 --> 01:06:58,440
or any other credential has been leaked

1754
01:06:58,440 --> 01:07:00,599
and then in a cheap manner also find

1755
01:07:00,599 --> 01:07:02,640
about it or not so yeah those are the

1756
01:07:02,640 --> 01:07:05,058
two cases

1757
01:07:09,299 --> 01:07:12,079
last question

1758
01:07:12,359 --> 01:07:13,920
all right if not let's thank Sophia

1759
01:07:13,920 --> 01:07:17,299
again and we have a coffee break

