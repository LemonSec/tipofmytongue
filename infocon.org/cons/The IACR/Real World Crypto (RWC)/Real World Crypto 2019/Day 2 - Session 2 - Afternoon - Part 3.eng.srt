1
00:00:02,899 --> 00:00:09,990
right ladies and gentlemen please take

2
00:00:05,460 --> 00:00:13,889
your seats because we have another prize

3
00:00:09,990 --> 00:00:16,500
to give out cards against cryptography

4
00:00:13,889 --> 00:00:17,939
is the game everybody is playing or they

5
00:00:16,500 --> 00:00:19,980
certainly were playing at Asia crypt

6
00:00:17,940 --> 00:00:21,359
look at the Twitter feed for Asia crypt

7
00:00:19,980 --> 00:00:25,640
you can see there's some really amazing

8
00:00:21,359 --> 00:00:28,890
cards in the pack and over to Brian

9
00:00:25,640 --> 00:00:31,740
thank you the owner of Nigel Smith's new

10
00:00:28,890 --> 00:00:34,489
Hawaiian shirt which is a white card in

11
00:00:31,740 --> 00:00:37,110
the pack by the way which pairs up with

12
00:00:34,489 --> 00:00:39,089
many black cards in many interesting

13
00:00:37,110 --> 00:00:41,969
ways as you can see from the Twitter

14
00:00:39,090 --> 00:00:43,590
feed okay so I am wearing two hats right

15
00:00:41,969 --> 00:00:45,660
now I'm wearing my hat both as a member

16
00:00:43,590 --> 00:00:46,649
of the RWC steering committee and as

17
00:00:45,660 --> 00:00:48,239
treasurer of the International

18
00:00:46,649 --> 00:00:50,700
Association for Cryptologic research of

19
00:00:48,239 --> 00:00:53,538
which RWC is the first of our eight

20
00:00:50,700 --> 00:00:57,809
events of 2019

21
00:00:53,539 --> 00:01:02,280
now the purse so the award that I'm

22
00:00:57,809 --> 00:01:04,739
going to give out is going to nicole

23
00:01:02,280 --> 00:01:07,950
fern and Nicole would you please come on

24
00:01:04,739 --> 00:01:09,990
up now let me explain why Nicole's

25
00:01:07,950 --> 00:01:13,380
getting this award because Nicole is

26
00:01:09,990 --> 00:01:15,210
getting the other deck of cards against

27
00:01:13,380 --> 00:01:17,990
cryptography Nicole say hi to everybody

28
00:01:15,210 --> 00:01:17,990
hi

29
00:01:22,350 --> 00:01:34,719
Nicole is the 640 second registrant to

30
00:01:28,509 --> 00:01:38,640
RWC 2019 crypto 2018 which was held in

31
00:01:34,719 --> 00:01:42,850
Santa Barbara in August had 641

32
00:01:38,640 --> 00:01:47,340
registrants and was to that point the

33
00:01:42,850 --> 00:01:51,488
largest attended I ACR event ever

34
00:01:47,340 --> 00:01:55,179
Nicole's registration pushes RWC over

35
00:01:51,489 --> 00:01:57,939
the top and reestablishes RWC as the

36
00:01:55,179 --> 00:02:00,729
most attended I ACR event because our

37
00:01:57,939 --> 00:02:04,000
previous record was 605 that was set at

38
00:02:00,729 --> 00:02:08,380
RWC last year so Nicole thank you for

39
00:02:04,000 --> 00:02:11,290
coming to RWC and for helping RWC become

40
00:02:08,380 --> 00:02:14,510
once again the leading most-attended I

41
00:02:11,290 --> 00:02:19,640
ACR event thank you very much

42
00:02:14,510 --> 00:02:23,579
[Music]

43
00:02:19,640 --> 00:02:25,140
okay so we're on with the show and you

44
00:02:23,580 --> 00:02:29,190
know I have noticed this afternoon is

45
00:02:25,140 --> 00:02:31,649
the kayuu Lovins show um so there's lots

46
00:02:29,190 --> 00:02:35,510
of decay live and I'm things but these

47
00:02:31,650 --> 00:02:38,610
speakers are not from K 11 they are from

48
00:02:35,510 --> 00:02:39,929
Michigan and Adelaide yes forgetting

49
00:02:38,610 --> 00:02:43,440
where you were at these days okay so

50
00:02:39,930 --> 00:02:47,130
we're over to Daniel and you Val we're

51
00:02:43,440 --> 00:02:48,900
gonna tell you about foreshadow Thank

52
00:02:47,130 --> 00:02:51,840
You Nigel for the introduction and good

53
00:02:48,900 --> 00:02:54,000
afternoon everyone and this is a work

54
00:02:51,840 --> 00:02:56,910
that is done with a long list of

55
00:02:54,000 --> 00:02:59,910
collaborators and short list of

56
00:02:56,910 --> 00:03:02,970
affiliations and the work is about

57
00:02:59,910 --> 00:03:08,280
foreshadow extracting the keys of to the

58
00:03:02,970 --> 00:03:11,910
Intel SGX so a bit about a bit of

59
00:03:08,280 --> 00:03:14,910
motivation we all know that we want to

60
00:03:11,910 --> 00:03:17,850
run multiple programs multiple users on

61
00:03:14,910 --> 00:03:22,049
the same computer and for that we need

62
00:03:17,850 --> 00:03:23,910
someone to maintain law and order and we

63
00:03:22,049 --> 00:03:27,390
have our operating system that manages

64
00:03:23,910 --> 00:03:29,549
the resources and it also enforces

65
00:03:27,390 --> 00:03:33,238
protections to one user cannot access a

66
00:03:29,549 --> 00:03:36,780
date of another user but operating

67
00:03:33,239 --> 00:03:39,450
system can sometimes go bad and they can

68
00:03:36,780 --> 00:03:42,420
be compromised or the operating system

69
00:03:39,450 --> 00:03:44,250
is not our under our control so we don't

70
00:03:42,420 --> 00:03:48,238
necessarily trust this operating system

71
00:03:44,250 --> 00:03:51,269
this is a commonly happen now in cloud

72
00:03:48,239 --> 00:03:53,610
scenarios for example and the problem

73
00:03:51,269 --> 00:03:56,100
with that is this operating system has

74
00:03:53,610 --> 00:03:59,070
some superpowers and it can get to all

75
00:03:56,100 --> 00:04:01,980
of our data and that means if we don't

76
00:03:59,070 --> 00:04:05,310
trust the operating system we are lose

77
00:04:01,980 --> 00:04:09,709
control of our own data so to solve this

78
00:04:05,310 --> 00:04:14,300
problem until gave us a present

79
00:04:09,710 --> 00:04:17,890
and the present is SGX secure guard

80
00:04:14,300 --> 00:04:22,070
extensions this is a set of CPU features

81
00:04:17,890 --> 00:04:25,789
that designed to allow us to remotely

82
00:04:22,070 --> 00:04:27,950
run secure computation and I'll quote

83
00:04:25,790 --> 00:04:30,800
some of Intel's description of this

84
00:04:27,950 --> 00:04:32,240
feature basically what we do is we take

85
00:04:30,800 --> 00:04:34,130
the sensitive code or the code that

86
00:04:32,240 --> 00:04:36,530
handles sensitive data and we put it

87
00:04:34,130 --> 00:04:38,740
into what's called an clave and these

88
00:04:36,530 --> 00:04:42,340
and claves are protected areas and

89
00:04:38,740 --> 00:04:46,370
ensure security is guaranteed by the

90
00:04:42,340 --> 00:04:49,729
compressor so for confidentiality and

91
00:04:46,370 --> 00:04:52,130
integrity they are enforced below the

92
00:04:49,730 --> 00:04:54,230
operating system below the hardware

93
00:04:52,130 --> 00:04:55,940
level we don't need to trust anything

94
00:04:54,230 --> 00:04:58,180
there everything can be compromised and

95
00:04:55,940 --> 00:05:01,100
we still are ensured that our data is a

96
00:04:58,180 --> 00:05:05,090
confidential and its integrity is

97
00:05:01,100 --> 00:05:07,930
maintained and furthermore we have a new

98
00:05:05,090 --> 00:05:10,369
nice feature that can guarantee to us

99
00:05:07,930 --> 00:05:12,260
without having access to the

100
00:05:10,370 --> 00:05:14,300
through the physical computer that the

101
00:05:12,260 --> 00:05:18,550
computer is really running a genuine

102
00:05:14,300 --> 00:05:21,920
Intel platforms that we can trust and

103
00:05:18,550 --> 00:05:23,510
that the program is running inside the

104
00:05:21,920 --> 00:05:26,570
Enclave so it is protected from

105
00:05:23,510 --> 00:05:28,820
everything else around it and this

106
00:05:26,570 --> 00:05:32,990
feature has been around for almost three

107
00:05:28,820 --> 00:05:37,480
years now so it's available in most

108
00:05:32,990 --> 00:05:40,460
computers but people now use so

109
00:05:37,480 --> 00:05:42,140
summarized a security model no long we

110
00:05:40,460 --> 00:05:43,700
no longer need to trust anything we

111
00:05:42,140 --> 00:05:45,849
don't trust the memory we don't trust

112
00:05:43,700 --> 00:05:48,950
the hardware components we don't trust

113
00:05:45,850 --> 00:05:52,130
operating system at various levels the

114
00:05:48,950 --> 00:05:54,229
only thing we trust is our CPU we trust

115
00:05:52,130 --> 00:05:57,620
our code in our and clave that's our

116
00:05:54,230 --> 00:06:00,290
code so we can trust it and we have some

117
00:05:57,620 --> 00:06:02,570
mechanism that ensures that we are there

118
00:06:00,290 --> 00:06:05,480
that this is the situation that we don't

119
00:06:02,570 --> 00:06:08,659
have a MIDI and clave isn't a real and

120
00:06:05,480 --> 00:06:11,030
clave running and genuine CPU how does

121
00:06:08,660 --> 00:06:15,710
the Intel protector with the context of

122
00:06:11,030 --> 00:06:17,150
in clave so for that we allocate part of

123
00:06:15,710 --> 00:06:19,969
the physical memory that's called the in

124
00:06:17,150 --> 00:06:21,919
clave page cache it's typically in 93

125
00:06:19,970 --> 00:06:22,999
megabyte with some possibility of

126
00:06:21,919 --> 00:06:28,068
changing but that's

127
00:06:22,999 --> 00:06:30,739
typical value and everything in this EP

128
00:06:28,069 --> 00:06:32,929
and cliff page cache is encrypted so

129
00:06:30,739 --> 00:06:38,659
when it goes to the ROM this is

130
00:06:32,929 --> 00:06:40,399
encrypted 128-bit security AES they if

131
00:06:38,659 --> 00:06:42,469
we have come some one has control of the

132
00:06:40,399 --> 00:06:43,849
run they cannot get the data they only

133
00:06:42,469 --> 00:06:47,269
get the encrypted data

134
00:06:43,849 --> 00:06:50,049
it is also protect a it's also

135
00:06:47,269 --> 00:06:54,049
authenticated so protected against a

136
00:06:50,049 --> 00:06:55,729
changes and the key is generated

137
00:06:54,049 --> 00:06:57,828
automatically at the boot time it's not

138
00:06:55,729 --> 00:07:02,989
written anywhere inside the processor

139
00:06:57,829 --> 00:07:05,089
and it is never given to software so as

140
00:07:02,989 --> 00:07:07,459
long as the as we trust the processor we

141
00:07:05,089 --> 00:07:11,269
know that no one can get access to the

142
00:07:07,459 --> 00:07:13,610
physical memory we also need to protect

143
00:07:11,269 --> 00:07:15,499
this memory from access from within the

144
00:07:13,610 --> 00:07:18,979
computer so software access into this

145
00:07:15,499 --> 00:07:21,169
memory region in this case because we

146
00:07:18,979 --> 00:07:23,449
don't trust our operating system there

147
00:07:21,169 --> 00:07:26,479
is no point in generating a trap when

148
00:07:23,449 --> 00:07:29,569
someone tries to access that so instead

149
00:07:26,479 --> 00:07:31,579
what what we have is what's called abort

150
00:07:29,569 --> 00:07:34,939
page semantics and the board pad

151
00:07:31,579 --> 00:07:37,459
semantics are very simple if anything

152
00:07:34,939 --> 00:07:39,619
but the enclaved tries to access the

153
00:07:37,459 --> 00:07:42,679
memory of the in clave what the you get

154
00:07:39,619 --> 00:07:47,599
is in write the write is ignored and in

155
00:07:42,679 --> 00:07:52,458
read we get all one's more 0xff or minus

156
00:07:47,599 --> 00:07:54,649
one so we are guaranteed that no one can

157
00:07:52,459 --> 00:07:56,599
access our memory either from outside of

158
00:07:54,649 --> 00:08:00,139
the processor or from inside the

159
00:07:56,599 --> 00:08:01,849
processor and then we have one thing

160
00:08:00,139 --> 00:08:04,039
that we do trust the operating system

161
00:08:01,849 --> 00:08:07,639
the operating system does maintain

162
00:08:04,039 --> 00:08:09,739
availability and what it has the it has

163
00:08:07,639 --> 00:08:11,269
the ability of maintaining the typical

164
00:08:09,739 --> 00:08:15,979
operating system protection on pages

165
00:08:11,269 --> 00:08:18,679
inside the PC and it can swap pages in

166
00:08:15,979 --> 00:08:20,628
and out and when it swaps pay a page out

167
00:08:18,679 --> 00:08:23,029
the page is automatically encrypted on

168
00:08:20,629 --> 00:08:24,679
the way to the operating system so the

169
00:08:23,029 --> 00:08:27,589
operating system cannot see what is

170
00:08:24,679 --> 00:08:29,299
there and when it swaps a page in it is

171
00:08:27,589 --> 00:08:31,399
automatically decrypted and it's

172
00:08:29,299 --> 00:08:33,078
verified and there are and sjx in a

173
00:08:31,399 --> 00:08:34,860
verifies that the page has not been

174
00:08:33,078 --> 00:08:36,390
modified and verifies that this is

175
00:08:34,860 --> 00:08:39,750
an old version of it in clave so it

176
00:08:36,390 --> 00:08:41,640
protects against a replay attack so this

177
00:08:39,750 --> 00:08:44,570
is beautiful and we have a secure system

178
00:08:41,640 --> 00:08:47,970
that and it can ensure secure execution

179
00:08:44,570 --> 00:08:51,050
if we read the threat model we find the

180
00:08:47,970 --> 00:08:53,399
fine print and the fine print is that

181
00:08:51,050 --> 00:08:55,979
SGX does not provide protection from

182
00:08:53,399 --> 00:08:58,620
side channels and that's the

183
00:08:55,980 --> 00:09:00,839
responsibility of Asus developers to do

184
00:08:58,620 --> 00:09:02,940
this protection and that's a beautiful

185
00:09:00,839 --> 00:09:04,700
security model because we cannot break

186
00:09:02,940 --> 00:09:07,740
the protection from side channel attacks

187
00:09:04,700 --> 00:09:15,149
if we don't have protection we can't

188
00:09:07,740 --> 00:09:19,230
break it okay so with that we need to go

189
00:09:15,149 --> 00:09:22,459
back to the early 2018 and when we can

190
00:09:19,230 --> 00:09:26,730
aware of more side channel attacks and

191
00:09:22,459 --> 00:09:30,029
the 2a works that we had the pleasure of

192
00:09:26,730 --> 00:09:32,610
being involved with our meltdown which

193
00:09:30,029 --> 00:09:36,260
is basically a bug in the processor that

194
00:09:32,610 --> 00:09:39,149
allows users to access kernel memory and

195
00:09:36,260 --> 00:09:41,399
Spectre which is design flow in frost

196
00:09:39,149 --> 00:09:45,779
sores that allow users to bypass

197
00:09:41,399 --> 00:09:50,339
protection boundaries and after some

198
00:09:45,779 --> 00:09:52,470
protection or the defense work that has

199
00:09:50,339 --> 00:09:55,920
been published what we still have is

200
00:09:52,470 --> 00:09:57,899
that basically we can bypass the

201
00:09:55,920 --> 00:10:02,250
protection boundary between the user and

202
00:09:57,899 --> 00:10:05,040
kernel in memory so modern operating

203
00:10:02,250 --> 00:10:07,470
systems do not use at the kernel if you

204
00:10:05,040 --> 00:10:08,969
do not use this boundary kpti moves the

205
00:10:07,470 --> 00:10:12,510
current with totally different address

206
00:10:08,970 --> 00:10:15,300
space we can bypass language-based

207
00:10:12,510 --> 00:10:18,569
protection so we need additional

208
00:10:15,300 --> 00:10:20,579
protections inside a same managed

209
00:10:18,570 --> 00:10:23,399
languages that enforce a memory

210
00:10:20,579 --> 00:10:26,120
protection and under some say now you

211
00:10:23,399 --> 00:10:28,589
can bypass a cross process protection

212
00:10:26,120 --> 00:10:32,519
assuming that we have some gadgets that

213
00:10:28,589 --> 00:10:35,449
are vulnerable in the target process but

214
00:10:32,519 --> 00:10:39,779
all of these still leave the sjx

215
00:10:35,449 --> 00:10:42,349
protection still intact so now what

216
00:10:39,779 --> 00:10:44,760
we'll do is we'll try a demo and

217
00:10:42,350 --> 00:10:48,209
hopefully if the demo goes

218
00:10:44,760 --> 00:10:52,980
or with me we'll see that really about

219
00:10:48,209 --> 00:10:54,779
fate semantics protect us jigs so what

220
00:10:52,980 --> 00:10:57,240
we have here is program that try to

221
00:10:54,779 --> 00:11:00,720
apply the same technique as meld down to

222
00:10:57,240 --> 00:11:04,529
an SJ x and clave and we run it and we

223
00:11:00,720 --> 00:11:07,980
get the data out and the data is all ffs

224
00:11:04,529 --> 00:11:12,870
so that's about paid semantics and it

225
00:11:07,980 --> 00:11:15,570
probably works hopefully works okay so

226
00:11:12,870 --> 00:11:21,389
with that we'll move to foreshadow and

227
00:11:15,570 --> 00:11:25,110
I'll hand over to Daniel for them okay

228
00:11:21,389 --> 00:11:27,750
Thank You Val so what is foreshadow so

229
00:11:25,110 --> 00:11:30,870
fundamentally foreshadow exploits a

230
00:11:27,750 --> 00:11:38,490
nasty feature in Intel's implementation

231
00:11:30,870 --> 00:11:40,769
of the of the so fundamentally

232
00:11:38,490 --> 00:11:44,130
foreshadow exploits a nasty feature in

233
00:11:40,769 --> 00:11:46,920
Intel's implementation of the memory of

234
00:11:44,130 --> 00:11:49,560
the future physical memory address

235
00:11:46,920 --> 00:11:53,399
translation so what happens let's say

236
00:11:49,560 --> 00:11:55,560
that we have a beautiful physical memory

237
00:11:53,399 --> 00:11:57,510
understands lations that along the way

238
00:11:55,560 --> 00:11:59,399
that requires walking over multiple page

239
00:11:57,510 --> 00:12:00,750
tables and along with the way of doing

240
00:11:59,399 --> 00:12:02,639
this translation we discover that

241
00:12:00,750 --> 00:12:04,740
something went wrong and we can proceed

242
00:12:02,639 --> 00:12:06,389
to do the translation either the thing

243
00:12:04,740 --> 00:12:07,350
is not in physical memory the mapping

244
00:12:06,389 --> 00:12:09,839
doesn't make sense

245
00:12:07,350 --> 00:12:11,430
we don't have permissions to access that

246
00:12:09,839 --> 00:12:12,079
specific address something went totally

247
00:12:11,430 --> 00:12:15,630
wrong

248
00:12:12,079 --> 00:12:18,870
so that instruction that caused that

249
00:12:15,630 --> 00:12:21,149
access is flags as faulty and when the

250
00:12:18,870 --> 00:12:22,680
instruction retires it would be handled

251
00:12:21,149 --> 00:12:24,389
will have a seg fault the operating

252
00:12:22,680 --> 00:12:24,630
system will be code to clean up this

253
00:12:24,389 --> 00:12:27,389
mess

254
00:12:24,630 --> 00:12:30,569
but in the meanwhile address translation

255
00:12:27,389 --> 00:12:33,060
failed and as it fails that whatever

256
00:12:30,569 --> 00:12:36,120
temporary values it had computed before

257
00:12:33,060 --> 00:12:38,849
it failed are left in place somewhere

258
00:12:36,120 --> 00:12:41,819
inside the processor this is dangerous

259
00:12:38,850 --> 00:12:44,610
but we can still sort of manage it

260
00:12:41,819 --> 00:12:46,949
because it's marked as 40 but what comes

261
00:12:44,610 --> 00:12:48,269
after address translation well after

262
00:12:46,949 --> 00:12:50,189
understand solution we do memory

263
00:12:48,269 --> 00:12:52,620
accesses and this is where it becomes

264
00:12:50,190 --> 00:12:54,899
funny because whatever the intermediate

265
00:12:52,620 --> 00:12:57,810
value was before the address translation

266
00:12:54,899 --> 00:13:01,290
failed it is used as a physical

267
00:12:57,810 --> 00:13:03,719
and the memory access is performed but

268
00:13:01,290 --> 00:13:06,149
not only it's performed they wanted to

269
00:13:03,720 --> 00:13:08,850
get as far as they get the memory access

270
00:13:06,149 --> 00:13:10,649
as far as quickly as they can out of the

271
00:13:08,850 --> 00:13:14,790
way so they skipped all the permission

272
00:13:10,649 --> 00:13:16,769
checks so a the check for about page

273
00:13:14,790 --> 00:13:18,599
semantics are easy test GX memory that's

274
00:13:16,769 --> 00:13:20,430
not done boundaries between virtual

275
00:13:18,600 --> 00:13:21,990
machines are ignored even the system

276
00:13:20,430 --> 00:13:24,149
management mode nobody checks whose

277
00:13:21,990 --> 00:13:29,309
memory is it anyways why not do the

278
00:13:24,149 --> 00:13:30,139
access okay that's scary by itself but

279
00:13:29,309 --> 00:13:33,269
it gets better

280
00:13:30,139 --> 00:13:35,730
because as soon as we have an l1 hit if

281
00:13:33,269 --> 00:13:38,519
the data happens to be in memory it is

282
00:13:35,730 --> 00:13:41,100
given to the execution core to operate

283
00:13:38,519 --> 00:13:43,410
over and to leak through a query through

284
00:13:41,100 --> 00:13:44,999
a side Channel of course at some point

285
00:13:43,410 --> 00:13:46,559
the CPU is going to realize that all of

286
00:13:44,999 --> 00:13:49,439
this has transpired that this mapping

287
00:13:46,559 --> 00:13:50,969
makes absolutely no sense that sanity of

288
00:13:49,439 --> 00:13:53,849
this process has been totally lost and

289
00:13:50,970 --> 00:13:56,370
we'll undo the execution back to where

290
00:13:53,850 --> 00:13:58,860
it's a back to wit to the faulty address

291
00:13:56,370 --> 00:14:01,110
translation and an unroll try to unroll

292
00:13:58,860 --> 00:14:02,610
everything back but well by then it's

293
00:14:01,110 --> 00:14:03,110
too little too late the value is already

294
00:14:02,610 --> 00:14:06,240
leaked

295
00:14:03,110 --> 00:14:07,889
that's foreshadow at a high level and

296
00:14:06,240 --> 00:14:11,189
now that we've seen it let's actually

297
00:14:07,889 --> 00:14:14,939
see how for Shadow operates so I have my

298
00:14:11,189 --> 00:14:16,800
virtual memory right here and in my view

299
00:14:14,939 --> 00:14:19,740
remember I have a region for the implied

300
00:14:16,800 --> 00:14:22,349
page cache which is where SGX data lives

301
00:14:19,740 --> 00:14:24,360
and I have a pointer which points to

302
00:14:22,350 --> 00:14:25,920
some data for the in clay page cache I

303
00:14:24,360 --> 00:14:27,930
am from New Zealand and I'm trying to

304
00:14:25,920 --> 00:14:29,729
read them and for the purpose of the

305
00:14:27,930 --> 00:14:32,519
slide I'm even going to assume that the

306
00:14:29,730 --> 00:14:36,480
data is somehow cached inside the l1

307
00:14:32,519 --> 00:14:38,339
cache so how would I read that data so

308
00:14:36,480 --> 00:14:40,259
the first thing to do is I have to

309
00:14:38,339 --> 00:14:42,120
create a fault when I access this memory

310
00:14:40,259 --> 00:14:43,949
I have to have a faulty address

311
00:14:42,120 --> 00:14:45,389
translation process right because I want

312
00:14:43,949 --> 00:14:48,089
all the permission checks to be skipped

313
00:14:45,389 --> 00:14:50,399
how do I do that well there is a nice

314
00:14:48,089 --> 00:14:51,779
system code from the operate that

315
00:14:50,399 --> 00:14:54,329
operating system provide code and

316
00:14:51,779 --> 00:14:56,970
protect which allows the user to mark

317
00:14:54,329 --> 00:14:58,439
the piece of data as if it's not present

318
00:14:56,970 --> 00:15:01,110
in the virtual memory and it actually

319
00:14:58,439 --> 00:15:03,179
resides on disk now of course it's very

320
00:15:01,110 --> 00:15:04,980
much present it's so present it's even

321
00:15:03,179 --> 00:15:07,050
cached what we are going to pretend it's

322
00:15:04,980 --> 00:15:09,089
not there and mark it as not present at

323
00:15:07,050 --> 00:15:09,689
which point the operating system must be

324
00:15:09,089 --> 00:15:11,460
trapped

325
00:15:09,690 --> 00:15:14,280
soon as an access is performed because

326
00:15:11,460 --> 00:15:15,630
somebody has to swap it back in but for

327
00:15:14,280 --> 00:15:17,939
now we're gonna mark it as if it's not

328
00:15:15,630 --> 00:15:19,920
present and then I'm gonna have my

329
00:15:17,940 --> 00:15:21,660
standard meltdown code I'm gonna take a

330
00:15:19,920 --> 00:15:23,250
pointer and I'm gonna read its value

331
00:15:21,660 --> 00:15:26,189
well it's my pointer it's okay to have

332
00:15:23,250 --> 00:15:27,660
it so my memory subsystem says okay and

333
00:15:26,190 --> 00:15:30,240
the pointer is brought to the cache and

334
00:15:27,660 --> 00:15:32,939
to my attacker then I'm gonna take

335
00:15:30,240 --> 00:15:33,360
pointer and dereference it this is not

336
00:15:32,940 --> 00:15:35,190
cool

337
00:15:33,360 --> 00:15:37,560
this is SGX memory why am i

338
00:15:35,190 --> 00:15:39,630
dereferencing SGX memory well it's not

339
00:15:37,560 --> 00:15:41,310
my memory I'm not allowed to do it the

340
00:15:39,630 --> 00:15:43,200
memory subsystem is going to scream stop

341
00:15:41,310 --> 00:15:46,640
stop stop it's gonna scream stop because

342
00:15:43,200 --> 00:15:50,670
it's not there instead of issuing a

343
00:15:46,640 --> 00:15:51,810
abort page semantics so we have a faulty

344
00:15:50,670 --> 00:15:53,819
address translation process it's

345
00:15:51,810 --> 00:15:57,750
obviously not there right it's marked as

346
00:15:53,820 --> 00:16:00,210
if it's on disk but instruction is flag

347
00:15:57,750 --> 00:16:03,230
to relay to trap when it retires is the

348
00:16:00,210 --> 00:16:06,450
reference no permission checks have done

349
00:16:03,230 --> 00:16:08,750
but we have an l1 hit and nobody cares

350
00:16:06,450 --> 00:16:13,830
whose cache line is it anyways and

351
00:16:08,750 --> 00:16:16,170
therefore what we bought this value what

352
00:16:13,830 --> 00:16:18,810
the care subsystem responds by giving

353
00:16:16,170 --> 00:16:22,079
the value to the attack so that Tucker

354
00:16:18,810 --> 00:16:24,719
just learned a value from SGH value from

355
00:16:22,080 --> 00:16:27,270
SGX memory the only problem is the time

356
00:16:24,720 --> 00:16:29,340
is very short for this monster because

357
00:16:27,270 --> 00:16:31,470
at some point the CPU is gonna discover

358
00:16:29,340 --> 00:16:33,210
this so we need to as quickly as we can

359
00:16:31,470 --> 00:16:35,880
lick it out through a cache side-channel

360
00:16:33,210 --> 00:16:38,490
so let's do precisely that we take three

361
00:16:35,880 --> 00:16:41,910
which is our piece of data x 256 this is

362
00:16:38,490 --> 00:16:43,920
to avoid cache prefetching and use 768

363
00:16:41,910 --> 00:16:47,670
which is the resulting value as an index

364
00:16:43,920 --> 00:16:51,689
to array two so are a two of 768 is

365
00:16:47,670 --> 00:16:54,870
brought to the cache now the problem is

366
00:16:51,690 --> 00:16:57,420
totally insane it access the value that

367
00:16:54,870 --> 00:16:59,339
is obviously not present and at some

368
00:16:57,420 --> 00:17:01,290
point the processor is going to discover

369
00:16:59,339 --> 00:17:03,180
this and drop the operating system and

370
00:17:01,290 --> 00:17:06,119
because it drops the operating system

371
00:17:03,180 --> 00:17:08,129
that program can get killed the address

372
00:17:06,119 --> 00:17:09,958
bubut the memory space will be trashed

373
00:17:08,130 --> 00:17:13,470
we're gonna undo everything we had done

374
00:17:09,959 --> 00:17:15,569
an issue a trap instead and this monster

375
00:17:13,470 --> 00:17:18,060
the Green Monster is now dead and we

376
00:17:15,569 --> 00:17:20,310
have restored sanity right because it

377
00:17:18,060 --> 00:17:22,708
forgot the value three that it knew at

378
00:17:20,310 --> 00:17:23,579
some point of course before it died it

379
00:17:22,709 --> 00:17:25,890
left a tombstone

380
00:17:23,579 --> 00:17:28,620
on them on the big tombstone it wrote

381
00:17:25,890 --> 00:17:31,950
something this thing is to here and

382
00:17:28,620 --> 00:17:34,199
still cashed nobody undid the cash so we

383
00:17:31,950 --> 00:17:36,360
need a way to recover the value from the

384
00:17:34,200 --> 00:17:39,240
cash and for that I'm going to bring up

385
00:17:36,360 --> 00:17:41,159
my friendly red monster and the red

386
00:17:39,240 --> 00:17:44,790
monster is going to quarry array 2 or

387
00:17:41,160 --> 00:17:47,430
512 or sorry affair 256 Oh nobody

388
00:17:44,790 --> 00:17:49,710
touched a radio of 256 so it's gonna

389
00:17:47,430 --> 00:17:52,470
take a long amount of time to bring it

390
00:17:49,710 --> 00:17:53,550
from the mutual memory so okay the value

391
00:17:52,470 --> 00:17:56,100
was not 256

392
00:17:53,550 --> 00:17:58,800
let's try rate to a 512 again it's going

393
00:17:56,100 --> 00:17:59,699
to take the amount of time so it's not

394
00:17:58,800 --> 00:18:02,100
512 either

395
00:17:59,700 --> 00:18:04,410
but assuming the attached array to of

396
00:18:02,100 --> 00:18:06,899
768 is going to come back super quickly

397
00:18:04,410 --> 00:18:08,340
because it's cached so I know that the

398
00:18:06,900 --> 00:18:10,080
only reason why it's cached is because

399
00:18:08,340 --> 00:18:14,270
the Green Monster cast it before it died

400
00:18:10,080 --> 00:18:18,330
so the value must be 3 that's it I just

401
00:18:14,270 --> 00:18:19,320
read a value from within SGX and what's

402
00:18:18,330 --> 00:18:21,780
the difference between a trick in a

403
00:18:19,320 --> 00:18:23,340
method I'm a tree and a method is the

404
00:18:21,780 --> 00:18:27,560
trick that works more than twice this

405
00:18:23,340 --> 00:18:27,560
would work on the entire SGX memory

406
00:18:31,880 --> 00:18:38,539
so let's recap what did we see NEX was

407
00:18:35,690 --> 00:18:40,130
it was aimed aim to offer security in

408
00:18:38,539 --> 00:18:42,110
the model where everything is corrupted

409
00:18:40,130 --> 00:18:43,970
and except the CPU that's what big

410
00:18:42,110 --> 00:18:46,520
promised what did they deliver

411
00:18:43,970 --> 00:18:48,500
well because kill no page table

412
00:18:46,520 --> 00:18:50,059
isolation the meltdown countermeasures

413
00:18:48,500 --> 00:18:51,770
were not applied to SGX

414
00:18:50,059 --> 00:18:54,200
the attack I just show you world from

415
00:18:51,770 --> 00:18:54,889
userland so after in the word post

416
00:18:54,200 --> 00:18:56,539
meltdown

417
00:18:54,890 --> 00:18:57,950
you're better off trusting the kernel

418
00:18:56,539 --> 00:19:00,400
which is protected than to trust these

419
00:18:57,950 --> 00:19:03,799
jets which you can dump from userland

420
00:19:00,400 --> 00:19:06,860
lovely so that's what happens when you

421
00:19:03,799 --> 00:19:08,270
don't have a roll go yes but wait HGH is

422
00:19:06,860 --> 00:19:10,490
designed to protect against rogue

423
00:19:08,270 --> 00:19:12,860
grasses so let's assume a hostile

424
00:19:10,490 --> 00:19:15,110
operating system in that case it gets

425
00:19:12,860 --> 00:19:16,760
much much worse remember that saying

426
00:19:15,110 --> 00:19:18,110
it's up to the developer's

427
00:19:16,760 --> 00:19:22,539
responsibility to address any

428
00:19:18,110 --> 00:19:24,830
side-channel concerns it can't be done

429
00:19:22,539 --> 00:19:27,230
the reason why it can't be done

430
00:19:24,830 --> 00:19:30,199
is because there are enough tricks in

431
00:19:27,230 --> 00:19:32,809
the SGX ecosystem on how to get data in

432
00:19:30,200 --> 00:19:35,210
the cache without having the target and

433
00:19:32,809 --> 00:19:37,370
clave even run so it booted up it has a

434
00:19:35,210 --> 00:19:39,230
secret in its belly and all I need to do

435
00:19:37,370 --> 00:19:41,270
is to get the data to the cache so I can

436
00:19:39,230 --> 00:19:44,030
read it and there is a way to do this

437
00:19:41,270 --> 00:19:45,830
without having that a code of the app

438
00:19:44,030 --> 00:19:48,500
that entereth ever execute after

439
00:19:45,830 --> 00:19:49,760
initialization and then if it's cash

440
00:19:48,500 --> 00:19:50,929
they can try reading it and if it

441
00:19:49,760 --> 00:19:52,158
doesn't work for the first time well I'm

442
00:19:50,929 --> 00:19:53,539
the operating system so I'm just gonna

443
00:19:52,159 --> 00:19:56,150
rewind the entire thing and try again

444
00:19:53,539 --> 00:19:58,220
and again and again until I get my data

445
00:19:56,150 --> 00:19:59,510
bottom line is that first shadow can

446
00:19:58,220 --> 00:20:02,630
read 100% of the data

447
00:19:59,510 --> 00:20:05,450
almost 100% of the time and just to show

448
00:20:02,630 --> 00:20:08,570
you how devastating this is let's try

449
00:20:05,450 --> 00:20:10,580
the previous demo but this time with a

450
00:20:08,570 --> 00:20:12,860
bit more passion with all the tricks we

451
00:20:10,580 --> 00:20:14,480
have learned from for Shadow and as soon

452
00:20:12,860 --> 00:20:16,370
as I lunch it we see the text clearly

453
00:20:14,480 --> 00:20:18,260
appearing on the screen and this is

454
00:20:16,370 --> 00:20:20,000
taken from Intel security first pledge

455
00:20:18,260 --> 00:20:21,890
well they explain to you that it

456
00:20:20,000 --> 00:20:24,020
intercept it has been one of the highest

457
00:20:21,890 --> 00:20:26,150
priorities and for years they have been

458
00:20:24,020 --> 00:20:28,629
working to have security in every port

459
00:20:26,150 --> 00:20:28,630
on the grid

460
00:20:38,729 --> 00:20:44,649
okay that's what happens when you have a

461
00:20:41,589 --> 00:20:46,239
leaky chip and a good side channel and a

462
00:20:44,649 --> 00:20:48,339
hostile operating system you see no

463
00:20:46,239 --> 00:20:52,599
measurement errors this was the light on

464
00:20:48,339 --> 00:20:54,609
my SGX as a box okay that's what happens

465
00:20:52,599 --> 00:21:03,820
when you have just a bit of side channel

466
00:20:54,609 --> 00:21:06,869
linkage but it gets worse it gets worse

467
00:21:03,820 --> 00:21:09,700
how can this be even worse than that

468
00:21:06,869 --> 00:21:12,218
let's let me for worse let's do some

469
00:21:09,700 --> 00:21:15,249
philosophy if a tree falls down in the

470
00:21:12,219 --> 00:21:16,959
forest and there is nobody out to get to

471
00:21:15,249 --> 00:21:17,589
see it fall in here it fo does it make a

472
00:21:16,959 --> 00:21:20,829
sound

473
00:21:17,589 --> 00:21:23,649
should we even care well some trees for

474
00:21:20,829 --> 00:21:27,940
others and I would have their orders of

475
00:21:23,649 --> 00:21:29,529
this car killed okay but let's try an

476
00:21:27,940 --> 00:21:32,079
easier question we're all security

477
00:21:29,529 --> 00:21:34,659
experts here so I have a brand new

478
00:21:32,079 --> 00:21:39,339
machine that I bought of a trusted

479
00:21:34,659 --> 00:21:42,969
source ebay and as soon as I installed

480
00:21:39,339 --> 00:21:46,119
it on at my home it got hacked it was

481
00:21:42,969 --> 00:21:47,979
got severely compromised but it's

482
00:21:46,119 --> 00:21:52,029
brand-new and I didn't put any data on

483
00:21:47,979 --> 00:21:55,929
it are we safe do shall we even care

484
00:21:52,029 --> 00:21:58,149
about this scenario well it depends on

485
00:21:55,929 --> 00:22:00,159
context depends on the machine because

486
00:21:58,149 --> 00:22:02,949
every agx machine is capable of

487
00:22:00,159 --> 00:22:06,249
obtaining a prized asset and GXE PID

488
00:22:02,950 --> 00:22:07,690
keys and never fear internet promised us

489
00:22:06,249 --> 00:22:09,639
that these kids would never see the

490
00:22:07,690 --> 00:22:12,009
light of day and you know where you can

491
00:22:09,639 --> 00:22:14,498
extract them from any in FGX machine

492
00:22:12,009 --> 00:22:16,299
well unless foreshadow in which case you

493
00:22:14,499 --> 00:22:18,519
can kind of do it and we actually went

494
00:22:16,299 --> 00:22:20,918
ahead and did it and we recovered an EP

495
00:22:18,519 --> 00:22:22,839
ID key all right so we are now in

496
00:22:20,919 --> 00:22:23,979
possession of this object which is

497
00:22:22,839 --> 00:22:25,869
called an epi D key

498
00:22:23,979 --> 00:22:28,299
what can we do with this what can go

499
00:22:25,869 --> 00:22:30,519
wrong well for this I need to show you

500
00:22:28,299 --> 00:22:32,889
what EP ID is so EPI distance for

501
00:22:30,519 --> 00:22:34,479
enhanced privacy ID it's really it's

502
00:22:32,889 --> 00:22:36,849
Intel's remote at the station protocol

503
00:22:34,479 --> 00:22:38,799
and we have here a cloud we have a

504
00:22:36,849 --> 00:22:40,570
client and the cloud would like to prove

505
00:22:38,799 --> 00:22:41,020
to the time that it is running a genuine

506
00:22:40,570 --> 00:22:44,169
area

507
00:22:41,020 --> 00:22:46,990
Harvard with a we genuinely

508
00:22:44,170 --> 00:22:49,750
intermissions so what how do we do this

509
00:22:46,990 --> 00:22:51,790
well the processor takes the enclaved

510
00:22:49,750 --> 00:22:54,040
code it's about to run hashes sit down

511
00:22:51,790 --> 00:22:56,639
and signs it with an EP ID key and

512
00:22:54,040 --> 00:22:59,560
producing something that is called quote

513
00:22:56,640 --> 00:23:01,480
that quote is sent to the client the

514
00:22:59,560 --> 00:23:03,190
client can't verify it by itself anyways

515
00:23:01,480 --> 00:23:05,080
so they must go to the Internet the

516
00:23:03,190 --> 00:23:06,820
station server where as soon as the

517
00:23:05,080 --> 00:23:09,490
Internet the station server says yes oh

518
00:23:06,820 --> 00:23:11,040
yeah okay then it is possible for the

519
00:23:09,490 --> 00:23:13,810
client to establish a TLS tunnel

520
00:23:11,040 --> 00:23:15,879
directly into the endlave into the brain

521
00:23:13,810 --> 00:23:18,490
of that process or somewhere on the

522
00:23:15,880 --> 00:23:21,520
cloud and nobody in the middle can read

523
00:23:18,490 --> 00:23:23,230
the traffic the takeaway from this slide

524
00:23:21,520 --> 00:23:25,360
is that the trust of this entire

525
00:23:23,230 --> 00:23:28,480
attestation process depends on one thing

526
00:23:25,360 --> 00:23:30,520
on the EP ID keys and on the fact that

527
00:23:28,480 --> 00:23:33,400
the processor is only willing to sign

528
00:23:30,520 --> 00:23:35,800
certain enclave's with the PID kills and

529
00:23:33,400 --> 00:23:38,770
that only genuine Intel hardware can get

530
00:23:35,800 --> 00:23:41,290
those API D keys to begin with well we

531
00:23:38,770 --> 00:23:42,670
got one another key important

532
00:23:41,290 --> 00:23:43,870
observation about this slide is that

533
00:23:42,670 --> 00:23:46,090
Intel here is in a privileged position

534
00:23:43,870 --> 00:23:48,879
if they know who started and untied when

535
00:23:46,090 --> 00:23:49,990
what where and on which machine and they

536
00:23:48,880 --> 00:23:52,360
didn't want to be responsible for that

537
00:23:49,990 --> 00:23:54,490
information so because of that the user

538
00:23:52,360 --> 00:23:57,580
protocol a PID which turns for enhanced

539
00:23:54,490 --> 00:23:59,860
privacy ID it's a group signature to be

540
00:23:57,580 --> 00:24:04,270
is a bit privacy guarantees it son

541
00:23:59,860 --> 00:24:06,939
linkable and it's also unlikable but the

542
00:24:04,270 --> 00:24:10,090
main thing is unlivable which means that

543
00:24:06,940 --> 00:24:14,160
nobody knows who signed what I cannot

544
00:24:10,090 --> 00:24:15,939
link any quote to its on it now

545
00:24:14,160 --> 00:24:19,600
unfortunately with enhanced privacy

546
00:24:15,940 --> 00:24:22,330
comes enhance responsibility because a

547
00:24:19,600 --> 00:24:26,169
single extract the DP ID key can be used

548
00:24:22,330 --> 00:24:29,230
to sign millions of quotes without

549
00:24:26,170 --> 00:24:31,300
anybody knowing who signed what which

550
00:24:29,230 --> 00:24:34,950
means that one key erodes the trust in

551
00:24:31,300 --> 00:24:37,990
the entire ecosystem so to help

552
00:24:34,950 --> 00:24:40,630
facilitate this erosion of trust I give

553
00:24:37,990 --> 00:24:44,440
you s S stands for attestation as a

554
00:24:40,630 --> 00:24:47,440
service it's a twitter bot that would

555
00:24:44,440 --> 00:24:48,900
attach to anything you tweeted it which

556
00:24:47,440 --> 00:24:51,240
reduces

557
00:24:48,900 --> 00:24:54,390
widgets reduces the cost of hacker ship

558
00:24:51,240 --> 00:24:57,090
because we you don't need to own your

559
00:24:54,390 --> 00:24:59,970
own SGH machine your premise is

560
00:24:57,090 --> 00:25:01,709
protected by a PID and right now it

561
00:24:59,970 --> 00:25:05,070
returns group out of date because we

562
00:25:01,710 --> 00:25:07,170
can't break the latest as G's versions

563
00:25:05,070 --> 00:25:09,360
but critically our kids are still not

564
00:25:07,170 --> 00:25:10,290
revoked so group out of date means the

565
00:25:09,360 --> 00:25:12,000
machine needs an update

566
00:25:10,290 --> 00:25:14,490
but it's the kids are fine because

567
00:25:12,000 --> 00:25:16,170
despite weeks of advance notice until it

568
00:25:14,490 --> 00:25:20,280
not still revealed the kids bed since

569
00:25:16,170 --> 00:25:22,020
August but well when we when we first

570
00:25:20,280 --> 00:25:25,379
published this we immediately got

571
00:25:22,020 --> 00:25:26,940
blocked by twitter so if we can't rely

572
00:25:25,380 --> 00:25:29,090
on int'l to maintain the security

573
00:25:26,940 --> 00:25:31,320
guarantees well at least we have twitter

574
00:25:29,090 --> 00:25:33,480
so I'm going to skip on mitigations

575
00:25:31,320 --> 00:25:35,730
because Nigel is after to get a Nigel is

576
00:25:33,480 --> 00:25:37,110
up to get me one last thing where you've

577
00:25:35,730 --> 00:25:38,700
a let me just started as a sitting

578
00:25:37,110 --> 00:25:40,530
professors at Michigan in Adelaide and

579
00:25:38,700 --> 00:25:41,850
we're looking for students and postdocs

580
00:25:40,530 --> 00:25:46,980
if you're interested in those sorts of

581
00:25:41,850 --> 00:25:49,459
stuff come talk to us you know why I

582
00:25:46,980 --> 00:25:49,460
give you that

583
00:25:53,440 --> 00:25:58,700
yeah we have time for a quick question

584
00:25:56,110 --> 00:26:05,479
anyone want to jump first one to the mic

585
00:25:58,700 --> 00:26:08,900
so slow to the mic aha bar right hi so

586
00:26:05,480 --> 00:26:10,340
there are many many projects

587
00:26:08,900 --> 00:26:11,960
specifically in the blockchain space

588
00:26:10,340 --> 00:26:18,559
that are using trusted execution

589
00:26:11,960 --> 00:26:20,900
environments like SGX good so my

590
00:26:18,559 --> 00:26:24,080
question is a lot of these people are

591
00:26:20,900 --> 00:26:26,090
saying that there will be a tea platform

592
00:26:24,080 --> 00:26:28,580
that can adequately provide this

593
00:26:26,090 --> 00:26:30,530
security and threat model do you think

594
00:26:28,580 --> 00:26:32,870
so because I'm inclined to say no but

595
00:26:30,530 --> 00:26:35,570
I'm curious to hear your opinions

596
00:26:32,870 --> 00:26:37,370
I know conflict of interest because I

597
00:26:35,570 --> 00:26:39,620
hey I have all possible interest for

598
00:26:37,370 --> 00:26:40,820
people to use as interested execution

599
00:26:39,620 --> 00:26:44,409
environments and put their money in

600
00:26:40,820 --> 00:26:44,409
there because then I'm gonna be rich

601
00:26:46,360 --> 00:26:59,549
okay but that bombshell we also know

602
00:26:50,030 --> 00:26:59,549
[Applause]

603
00:27:23,250 --> 00:27:34,380
principal scientist then it talked about

604
00:27:26,500 --> 00:27:37,980
the type of talk and where's the cable

605
00:27:34,380 --> 00:27:37,980
let's be on the floor

606
00:27:53,750 --> 00:27:58,980
okay to it fullscreen okay so we move on

607
00:27:56,820 --> 00:28:04,100
to next talk where Joe is gonna took

608
00:27:58,980 --> 00:28:07,350
back risk V risk v risk v hi everybody

609
00:28:04,100 --> 00:28:09,178
thank you to the RWC organizers for

610
00:28:07,350 --> 00:28:14,309
asking me to come and give you a very

611
00:28:09,179 --> 00:28:15,659
short pointed talk about risk v the

612
00:28:14,309 --> 00:28:17,970
point of this talk and actually is a

613
00:28:15,659 --> 00:28:22,169
great segue from the last excellent talk

614
00:28:17,970 --> 00:28:24,629
on foreshadow is that risk v is a new

615
00:28:22,169 --> 00:28:27,539
opportunity for those of us who are old

616
00:28:24,629 --> 00:28:29,580
enough to remember when CPU and is

617
00:28:27,539 --> 00:28:33,570
instruction set architecture design was

618
00:28:29,580 --> 00:28:35,100
cool the last time I spoke it at

619
00:28:33,570 --> 00:28:36,840
real-world crypto was a few years ago

620
00:28:35,100 --> 00:28:40,649
when I talked about Galois x' work on

621
00:28:36,840 --> 00:28:42,539
crypto and saw and we open sourced it so

622
00:28:40,649 --> 00:28:44,039
that you could reason about formally

623
00:28:42,539 --> 00:28:46,139
reason about cryptographic algorithms

624
00:28:44,039 --> 00:28:48,899
and the implementations and that work

625
00:28:46,139 --> 00:28:51,299
has seen great impact and promise both

626
00:28:48,899 --> 00:28:53,100
in academia industry you might have seen

627
00:28:51,299 --> 00:28:55,110
we've been working on formally verifying

628
00:28:53,100 --> 00:28:58,769
much of amazon's crypto code and things

629
00:28:55,110 --> 00:29:00,360
like that at that same point in time we

630
00:28:58,769 --> 00:29:02,779
started working in the universe of RISC

631
00:29:00,360 --> 00:29:05,939
5 concurrently and in particular

632
00:29:02,779 --> 00:29:08,909
focusing on how do you design actually

633
00:29:05,940 --> 00:29:11,639
secure processors that have things like

634
00:29:08,909 --> 00:29:12,870
cryptographic extensions and hardware so

635
00:29:11,639 --> 00:29:15,240
what I want to tell you about today is

636
00:29:12,870 --> 00:29:17,459
why I'm excited about this and why a

637
00:29:15,240 --> 00:29:19,049
bunch of folks researchers both in

638
00:29:17,460 --> 00:29:21,750
academia and industry are getting

639
00:29:19,049 --> 00:29:25,879
involved in risk 5 because it represents

640
00:29:21,750 --> 00:29:28,919
enormous opportunities for new doing new

641
00:29:25,879 --> 00:29:30,840
foundational work in security for the

642
00:29:28,919 --> 00:29:33,629
world where you don't have the shitty

643
00:29:30,840 --> 00:29:36,029
baggage of Intel and armor can I get

644
00:29:33,629 --> 00:29:37,408
some can I get some of Harrah's for that

645
00:29:36,029 --> 00:29:40,110
ok all right

646
00:29:37,409 --> 00:29:42,419
this this talk was prepared with Hellena

647
00:29:40,110 --> 00:29:43,949
who's in the audience somewhere who

648
00:29:42,419 --> 00:29:45,690
works with me on these topics she's back

649
00:29:43,950 --> 00:29:50,669
there and she will be around through the

650
00:29:45,690 --> 00:29:52,529
end of the event Josie she from Nvidia

651
00:29:50,669 --> 00:29:54,299
who's not here Richard who's not here in

652
00:29:52,529 --> 00:29:56,580
Dan Zimmerman who's sitting up here as

653
00:29:54,299 --> 00:29:58,730
well so there's three of us that you can

654
00:29:56,580 --> 00:30:02,309
talk about these topics in great detail

655
00:29:58,730 --> 00:30:04,169
for the remainder of the event now what

656
00:30:02,309 --> 00:30:04,950
is risk five I know that all right so

657
00:30:04,169 --> 00:30:07,230
how many

658
00:30:04,950 --> 00:30:09,000
you are actually hardware geeks how many

659
00:30:07,230 --> 00:30:10,980
of you had classifiers about so it's a

660
00:30:09,000 --> 00:30:11,520
it's a fairly small subset of the

661
00:30:10,980 --> 00:30:16,260
audience

662
00:30:11,520 --> 00:30:18,660
yeah thanks Paul cheeky guy so risk 5 is

663
00:30:16,260 --> 00:30:20,550
just a new kind of processor it's a new

664
00:30:18,660 --> 00:30:24,390
kind of instruction set architecture and

665
00:30:20,550 --> 00:30:26,639
it's the fifth version of risk and that

666
00:30:24,390 --> 00:30:29,400
means hopefully we've learned from the

667
00:30:26,640 --> 00:30:35,150
previous four versions of risk over the

668
00:30:29,400 --> 00:30:38,040
years I'm sorry yeah hopefully hopefully

669
00:30:35,150 --> 00:30:40,440
it's it's high quality and the reason

670
00:30:38,040 --> 00:30:42,930
it's exciting is that it's licensed free

671
00:30:40,440 --> 00:30:44,670
and royalty free anyone in the world can

672
00:30:42,930 --> 00:30:47,490
build a risk five chip and you don't

673
00:30:44,670 --> 00:30:49,200
have to pay anyone a damn thing moreover

674
00:30:47,490 --> 00:30:51,540
there's a huge numbers of reaches

675
00:30:49,200 --> 00:30:53,130
researchers moving into this topic so

676
00:30:51,540 --> 00:30:55,050
that we can design these chips in

677
00:30:53,130 --> 00:30:57,180
principled ways and maybe you're not

678
00:30:55,050 --> 00:31:00,200
banging rocks together using ancient

679
00:30:57,180 --> 00:31:03,300
hardware design languages like Verilog

680
00:31:00,200 --> 00:31:07,080
it's also designed from everything from

681
00:31:03,300 --> 00:31:09,629
tiny microcontrollers to big multi-core

682
00:31:07,080 --> 00:31:13,610
systems so it has flexibility in the

683
00:31:09,630 --> 00:31:16,170
underlying principles of the ISA and

684
00:31:13,610 --> 00:31:18,990
that means that if you have an interest

685
00:31:16,170 --> 00:31:21,680
in one particular flavor of CPU or maybe

686
00:31:18,990 --> 00:31:24,300
one particular favor of flavor of crypto

687
00:31:21,680 --> 00:31:26,690
like earlier its discussions about

688
00:31:24,300 --> 00:31:29,220
lightweight crypto and spec in Xiamen

689
00:31:26,690 --> 00:31:31,440
you can play in different different

690
00:31:29,220 --> 00:31:33,540
product models shall we say development

691
00:31:31,440 --> 00:31:35,280
started in summer 2010 at Berkeley and

692
00:31:33,540 --> 00:31:37,290
the early workshops were funny because

693
00:31:35,280 --> 00:31:39,180
it was basically just to grad to

694
00:31:37,290 --> 00:31:42,030
professors and a bunch of students in a

695
00:31:39,180 --> 00:31:46,110
room together but the most recent risk

696
00:31:42,030 --> 00:31:47,670
five summit which is our regular almost

697
00:31:46,110 --> 00:31:51,320
yearly conference where people get

698
00:31:47,670 --> 00:31:53,610
together had over 1,000 attendees and

699
00:31:51,320 --> 00:31:56,100
hundreds of companies showed up there's

700
00:31:53,610 --> 00:31:56,669
been a super explosion of interest in

701
00:31:56,100 --> 00:31:59,879
this topic

702
00:31:56,670 --> 00:32:02,310
and it's not because of blockchain now

703
00:31:59,880 --> 00:32:04,680
the cool thing here is risk five

704
00:32:02,310 --> 00:32:08,250
represents a platform for doing open

705
00:32:04,680 --> 00:32:10,500
source and open hardware R&D and product

706
00:32:08,250 --> 00:32:12,660
F so companies care about it and

707
00:32:10,500 --> 00:32:14,610
research care about it research groups

708
00:32:12,660 --> 00:32:16,980
care about it and you can do so at very

709
00:32:14,610 --> 00:32:18,219
low cost because nearly all the tools

710
00:32:16,980 --> 00:32:23,710
you need to do

711
00:32:18,220 --> 00:32:27,549
design and very soon fab the risk five

712
00:32:23,710 --> 00:32:29,860
chip are free the community has grown

713
00:32:27,549 --> 00:32:32,590
tremendously so at the latest risk five

714
00:32:29,860 --> 00:32:34,240
summit in December we had twice the

715
00:32:32,590 --> 00:32:37,360
attendance at the previous one which is

716
00:32:34,240 --> 00:32:40,659
only a year earlier 250 abstracts were

717
00:32:37,360 --> 00:32:44,080
submitted 59 sessions 29 exhibitors and

718
00:32:40,659 --> 00:32:46,900
in this year alone there will be

719
00:32:44,080 --> 00:32:50,408
something between 10 and 100 million

720
00:32:46,900 --> 00:32:53,350
risk fives in silicon in products that's

721
00:32:50,409 --> 00:32:55,900
how quickly this world has exploded that

722
00:32:53,350 --> 00:32:58,360
means that if you get involved in this

723
00:32:55,900 --> 00:33:01,090
community like I hope some of you will

724
00:32:58,360 --> 00:33:03,820
you have an ability to have a hand in

725
00:33:01,090 --> 00:33:06,639
building something clean and beautiful

726
00:33:03,820 --> 00:33:09,120
and actually secure for the world

727
00:33:06,640 --> 00:33:11,140
because people are shipping these chips

728
00:33:09,120 --> 00:33:12,850
some of the biggest companies in the

729
00:33:11,140 --> 00:33:16,600
world have made announcements this past

730
00:33:12,850 --> 00:33:20,699
12 months about pivoting from in the

731
00:33:16,600 --> 00:33:24,340
main arm to risk 5 for their products

732
00:33:20,700 --> 00:33:27,270
the foundation is a nonprofit foundation

733
00:33:24,340 --> 00:33:30,250
that sits and manages risk 5 and

734
00:33:27,270 --> 00:33:32,559
facilitates the open pragmatic

735
00:33:30,250 --> 00:33:34,960
development of standards that are

736
00:33:32,559 --> 00:33:37,389
everything from the concretization of

737
00:33:34,960 --> 00:33:40,120
the ISA and its semantics to various

738
00:33:37,390 --> 00:33:43,390
extensions there and what I encourage

739
00:33:40,120 --> 00:33:44,949
you to do in looking into risk 5 is to

740
00:33:43,390 --> 00:33:46,330
consider not just the fact that you

741
00:33:44,950 --> 00:33:48,130
might want to play with it but you might

742
00:33:46,330 --> 00:33:51,340
want to influence this development

743
00:33:48,130 --> 00:33:53,590
because join in the foundation even as

744
00:33:51,340 --> 00:33:55,510
an individual gives you the ability to

745
00:33:53,590 --> 00:33:57,189
have a direct hand in the evolution of

746
00:33:55,510 --> 00:33:59,500
the platform and to show off your stuff

747
00:33:57,190 --> 00:34:01,030
and publish papers and the like and a

748
00:33:59,500 --> 00:34:03,659
yearly membership to the foundation is

749
00:34:01,030 --> 00:34:05,770
99 bucks you know it's nothing

750
00:34:03,659 --> 00:34:08,050
university membership I think at the

751
00:34:05,770 --> 00:34:11,080
moment is only $249 for the entire

752
00:34:08,050 --> 00:34:12,879
university to join which is nothing so I

753
00:34:11,080 --> 00:34:15,460
would very much suggest that you get

754
00:34:12,879 --> 00:34:17,440
involved in the foundation now why is

755
00:34:15,460 --> 00:34:19,690
risk 5 interesting and why does it

756
00:34:17,440 --> 00:34:21,700
excite like us at Galois right we're

757
00:34:19,690 --> 00:34:24,099
historically known for being geeks and

758
00:34:21,699 --> 00:34:26,560
doing things like principled systems

759
00:34:24,099 --> 00:34:28,750
development and formal methods and

760
00:34:26,560 --> 00:34:31,299
formal reasoning about software and now

761
00:34:28,750 --> 00:34:33,699
hardware systems it's beautiful

762
00:34:31,300 --> 00:34:36,400
it's design principles match that which

763
00:34:33,699 --> 00:34:39,520
I need to develop secure platforms it's

764
00:34:36,400 --> 00:34:41,770
extremely simple the is a itself the

765
00:34:39,520 --> 00:34:44,020
instructions that you get are can be

766
00:34:41,770 --> 00:34:46,420
described in a very short document and

767
00:34:44,020 --> 00:34:48,730
are very clean and have a nice semantics

768
00:34:46,420 --> 00:34:50,380
it's a clean slate design it learned

769
00:34:48,730 --> 00:34:53,110
four lessons from the past and each and

770
00:34:50,380 --> 00:34:56,470
every design decision made in the ISA

771
00:34:53,110 --> 00:35:00,180
has a design rationale based upon the

772
00:34:56,469 --> 00:35:03,310
past that stretches back to the 1960s

773
00:35:00,180 --> 00:35:05,529
it's modular so you get a small core

774
00:35:03,310 --> 00:35:07,810
base is a and each time you want to

775
00:35:05,530 --> 00:35:10,750
explore a new domain that may be

776
00:35:07,810 --> 00:35:13,330
compromised by virtue of a set of new

777
00:35:10,750 --> 00:35:15,310
instructions or for example a new kind

778
00:35:13,330 --> 00:35:18,220
of device or a new memory map device

779
00:35:15,310 --> 00:35:20,410
it's done in a principled orthogonal way

780
00:35:18,220 --> 00:35:22,569
so we can focus on different topics

781
00:35:20,410 --> 00:35:25,980
separately each of which has its own

782
00:35:22,570 --> 00:35:29,530
design decisions it's designed for

783
00:35:25,980 --> 00:35:31,540
extension and specialization so that we

784
00:35:29,530 --> 00:35:32,980
can have different risk fives in the

785
00:35:31,540 --> 00:35:34,960
world and they can be mutually

786
00:35:32,980 --> 00:35:36,610
compatible on the sub set of

787
00:35:34,960 --> 00:35:39,070
instructions that they use but each one

788
00:35:36,610 --> 00:35:41,920
can specialize with extensions in a

789
00:35:39,070 --> 00:35:44,830
principled way at the most the two most

790
00:35:41,920 --> 00:35:49,150
recent risk five summits the CPU is

791
00:35:44,830 --> 00:35:52,120
demonstrated were in the main multi-core

792
00:35:49,150 --> 00:35:55,330
risk fives which also had

793
00:35:52,120 --> 00:35:57,430
domain-specific accelerators principally

794
00:35:55,330 --> 00:36:01,540
around things like bit level operations

795
00:35:57,430 --> 00:36:04,419
vector operations matrix multiplication

796
00:36:01,540 --> 00:36:06,910
AI algorithms deep learning algorithms

797
00:36:04,420 --> 00:36:08,770
and the like you can do that in hardware

798
00:36:06,910 --> 00:36:10,810
from day one because for two reasons one

799
00:36:08,770 --> 00:36:12,880
is you can play right away because it's

800
00:36:10,810 --> 00:36:14,680
all open and free wow I can actually

801
00:36:12,880 --> 00:36:16,630
take a CPU and extend it and I don't to

802
00:36:14,680 --> 00:36:18,750
pay anybody especially I don't have to

803
00:36:16,630 --> 00:36:22,180
pay a royalty to arm your upon year

804
00:36:18,750 --> 00:36:24,610
secondly the design tools used by most

805
00:36:22,180 --> 00:36:27,009
of the groups in this realm are not

806
00:36:24,610 --> 00:36:29,800
old-school hardware design languages

807
00:36:27,010 --> 00:36:31,270
instead they're modern design languages

808
00:36:29,800 --> 00:36:33,550
that come principally from the

809
00:36:31,270 --> 00:36:35,380
programming languages community that are

810
00:36:33,550 --> 00:36:37,660
familiar to people who are geeks with

811
00:36:35,380 --> 00:36:39,460
things like object-oriented programming

812
00:36:37,660 --> 00:36:41,980
or functional programming and the like

813
00:36:39,460 --> 00:36:44,460
so you're not programming these things

814
00:36:41,980 --> 00:36:46,470
as if their hardware and

815
00:36:44,460 --> 00:36:48,390
old school concurrent crazy systems that

816
00:36:46,470 --> 00:36:51,060
no one understands you're programming

817
00:36:48,390 --> 00:36:52,080
them like you're writing Java or you're

818
00:36:51,060 --> 00:36:55,619
writing something that looks like

819
00:36:52,080 --> 00:36:57,619
Haskell something higher level lastly

820
00:36:55,619 --> 00:36:59,660
it's stable we've now reached a point

821
00:36:57,619 --> 00:37:02,490
standardization where the base

822
00:36:59,660 --> 00:37:04,470
description of the ISA and the core

823
00:37:02,490 --> 00:37:06,810
standards extensions are frozen so we

824
00:37:04,470 --> 00:37:08,430
have backwards compatibility and all the

825
00:37:06,810 --> 00:37:12,509
additions are through optional

826
00:37:08,430 --> 00:37:14,970
extensions now security is key here

827
00:37:12,510 --> 00:37:17,190
nobody wants to build a new processor

828
00:37:14,970 --> 00:37:18,569
and get security wrong in essence and we

829
00:37:17,190 --> 00:37:20,190
think this affords a great opportunity

830
00:37:18,570 --> 00:37:23,010
to get right because of the clean

831
00:37:20,190 --> 00:37:25,980
foundation so there is a security

832
00:37:23,010 --> 00:37:29,160
standing group which is essentially the

833
00:37:25,980 --> 00:37:31,859
group of folks that keep track of and

834
00:37:29,160 --> 00:37:34,859
help guide at what's going on in the

835
00:37:31,859 --> 00:37:36,930
security sub domain of this new CPU it's

836
00:37:34,859 --> 00:37:39,569
led by Hellena I'm the vice chair of

837
00:37:36,930 --> 00:37:42,930
that group and we spin off in the

838
00:37:39,570 --> 00:37:45,060
context of need and Ardie different task

839
00:37:42,930 --> 00:37:47,580
groups to focus on different security

840
00:37:45,060 --> 00:37:50,040
related aspects of this platform there

841
00:37:47,580 --> 00:37:52,470
are two active groups at the moment one

842
00:37:50,040 --> 00:37:55,470
naturally is cryptographic extensions

843
00:37:52,470 --> 00:37:58,290
these are instructions specific to

844
00:37:55,470 --> 00:38:00,810
running cryptographic algorithms which

845
00:37:58,290 --> 00:38:03,330
in turn depend upon two other extension

846
00:38:00,810 --> 00:38:05,099
a bit manipulation extension and a

847
00:38:03,330 --> 00:38:07,230
vector extension and so they're

848
00:38:05,099 --> 00:38:09,330
currently standardizing the sorts of

849
00:38:07,230 --> 00:38:12,990
things you would expect basically suite

850
00:38:09,330 --> 00:38:15,390
b plus plus but here we're learning the

851
00:38:12,990 --> 00:38:19,290
lessons of the past about how crypto was

852
00:38:15,390 --> 00:38:22,140
done wrong in Intel and arm as well as

853
00:38:19,290 --> 00:38:24,619
previous verse five the chair of that

854
00:38:22,140 --> 00:38:27,390
group is Richard Newell at microchip

855
00:38:24,619 --> 00:38:29,310
which used to be micro semi until they

856
00:38:27,390 --> 00:38:30,868
got bought this year the vice-chair of

857
00:38:29,310 --> 00:38:33,869
that group is Dan sitting in the front

858
00:38:30,869 --> 00:38:36,660
so if you an interest in having a direct

859
00:38:33,869 --> 00:38:39,660
hand in the development of core crypto

860
00:38:36,660 --> 00:38:42,118
in a new processor that's going to

861
00:38:39,660 --> 00:38:44,580
dominate the markets I imagine in the

862
00:38:42,119 --> 00:38:47,480
coming years because the zero license

863
00:38:44,580 --> 00:38:50,700
cost if nothing else come talk to Dan

864
00:38:47,480 --> 00:38:53,089
secondly and perfect for that last talk

865
00:38:50,700 --> 00:38:56,009
there's a t'ee a trusted execution

866
00:38:53,089 --> 00:38:56,670
environment working group trying to

867
00:38:56,010 --> 00:38:59,220
design

868
00:38:56,670 --> 00:39:00,569
from first principles learning from the

869
00:38:59,220 --> 00:39:04,109
lessons of the past

870
00:39:00,569 --> 00:39:07,980
I want to fist-bump 14 times what was

871
00:39:04,109 --> 00:39:09,859
done wrong with things like STX trust

872
00:39:07,980 --> 00:39:12,589
zone and some of the more esoteric

873
00:39:09,859 --> 00:39:16,470
enclaves we see when we work in the DoD

874
00:39:12,589 --> 00:39:19,890
this group is chaired by Joshi at Nvidia

875
00:39:16,470 --> 00:39:22,558
and they are basically focusing on

876
00:39:19,890 --> 00:39:25,020
different shaped enclaves appropriate

877
00:39:22,559 --> 00:39:28,260
for different sized CPUs and different

878
00:39:25,020 --> 00:39:31,920
use cases there's currently two and a

879
00:39:28,260 --> 00:39:34,380
half maybe three now open-source on

880
00:39:31,920 --> 00:39:36,240
clays that have been a developed one of

881
00:39:34,380 --> 00:39:39,240
which has an assurance case out of

882
00:39:36,240 --> 00:39:40,979
Berkeley and MIT and those plus new

883
00:39:39,240 --> 00:39:44,279
ideas are moving into this research

884
00:39:40,980 --> 00:39:47,099
group and we may even see first silicon

885
00:39:44,280 --> 00:39:49,049
in a new trusted execution environment

886
00:39:47,099 --> 00:39:52,819
risk five by the end of this year

887
00:39:49,049 --> 00:39:55,559
you'll notice that Joe is at Nvidia

888
00:39:52,819 --> 00:39:58,579
Nvidia has announced that they have

889
00:39:55,559 --> 00:40:01,230
thrown out their old custom grown

890
00:39:58,579 --> 00:40:04,500
microcontroller which is in every single

891
00:40:01,230 --> 00:40:07,920
GPU in this room that's an Nvidia of

892
00:40:04,500 --> 00:40:10,829
course and replaced it with a risk five

893
00:40:07,920 --> 00:40:13,799
core and that risk five core must have a

894
00:40:10,829 --> 00:40:16,980
trusted execution environment in it to

895
00:40:13,799 --> 00:40:19,440
guarantee that code loaded into that GPU

896
00:40:16,980 --> 00:40:21,510
the house control over matters related

897
00:40:19,440 --> 00:40:24,240
to clock and energy and the like is a

898
00:40:21,510 --> 00:40:27,000
signed piece of code the reason for that

899
00:40:24,240 --> 00:40:30,529
is if you can manipulate that in a GPU

900
00:40:27,000 --> 00:40:33,630
you can make a machine catch on fire

901
00:40:30,530 --> 00:40:37,109
so the security-related IRD that's going

902
00:40:33,630 --> 00:40:39,119
on now is really exciting yes that's

903
00:40:37,109 --> 00:40:42,359
your next yes we will talk about that

904
00:40:39,119 --> 00:40:44,010
later so here's the reasons why you

905
00:40:42,359 --> 00:40:46,619
might also get excited from extra in the

906
00:40:44,010 --> 00:40:48,960
dimensions there already exist several

907
00:40:46,619 --> 00:40:51,450
mechanized formal specifications of the

908
00:40:48,960 --> 00:40:53,520
entire is a in theorem proving

909
00:40:51,450 --> 00:40:57,058
environments and in tools including from

910
00:40:53,520 --> 00:40:59,160
MIT s RI Cambridge US and a company

911
00:40:57,059 --> 00:41:00,630
called symbiotic EDA that means if

912
00:40:59,160 --> 00:41:02,430
you're at the intersection of formal

913
00:41:00,630 --> 00:41:02,970
methods and security it's a wonderful

914
00:41:02,430 --> 00:41:04,379
place to be

915
00:41:02,970 --> 00:41:06,598
because people are working on this work

916
00:41:04,380 --> 00:41:08,849
with you Adam is right here Adam chapala

917
00:41:06,599 --> 00:41:10,020
is a co-author of one of those and it's

918
00:41:08,849 --> 00:41:11,370
one of the

919
00:41:10,020 --> 00:41:13,890
so I come talk to him if you're into

920
00:41:11,370 --> 00:41:15,960
that several crystal graphic extension

921
00:41:13,890 --> 00:41:17,430
implementations are underway some of

922
00:41:15,960 --> 00:41:19,350
them are written by hand reusing

923
00:41:17,430 --> 00:41:21,359
existing open-source crappy aes

924
00:41:19,350 --> 00:41:23,009
implementations in hardware some are

925
00:41:21,360 --> 00:41:25,170
being synthesized automatically or

926
00:41:23,010 --> 00:41:26,880
formally verified people are working and

927
00:41:25,170 --> 00:41:30,210
leaking inside channel free

928
00:41:26,880 --> 00:41:32,660
implementations secure boot work is

929
00:41:30,210 --> 00:41:35,400
going on how do you do secure boot work

930
00:41:32,660 --> 00:41:37,560
properly learning from the lessons of

931
00:41:35,400 --> 00:41:40,350
the past both from the world of Intel

932
00:41:37,560 --> 00:41:43,200
and Apple as well as from the gut awful

933
00:41:40,350 --> 00:41:44,910
thing that is you boot and similar in

934
00:41:43,200 --> 00:41:46,680
the Linux world where we blew to Linux

935
00:41:44,910 --> 00:41:49,589
kernel to Buddha Linux kernel of Buddha

936
00:41:46,680 --> 00:41:51,870
Linux kernel and then lastly there are

937
00:41:49,590 --> 00:41:54,090
teams funded by government working on

938
00:41:51,870 --> 00:41:57,390
this topic creating dozens of different

939
00:41:54,090 --> 00:41:58,950
secure socks principally using formal

940
00:41:57,390 --> 00:42:01,650
methods in the main so we're seeing

941
00:41:58,950 --> 00:42:03,660
really novel new CPU architectures this

942
00:42:01,650 --> 00:42:06,270
is called the SIF program funded by

943
00:42:03,660 --> 00:42:08,009
DARPA MTO office and you'll be hearing a

944
00:42:06,270 --> 00:42:09,420
lot more about this later this year

945
00:42:08,010 --> 00:42:12,020
because there's going to be a public

946
00:42:09,420 --> 00:42:15,000
demonstration of those processors I

947
00:42:12,020 --> 00:42:16,700
encourage you to care it's a clean II is

948
00:42:15,000 --> 00:42:18,750
a it's a clean extension framework

949
00:42:16,700 --> 00:42:20,910
learning about and playing in this world

950
00:42:18,750 --> 00:42:23,310
feels more like writing software than

951
00:42:20,910 --> 00:42:25,920
hardware that's where the world has

952
00:42:23,310 --> 00:42:29,180
evolved you can run real hardware by

953
00:42:25,920 --> 00:42:31,590
buying literally a $99 FPGA and

954
00:42:29,180 --> 00:42:34,169
programming that FPGA and running real

955
00:42:31,590 --> 00:42:37,020
simulated hardware is as easy as what

956
00:42:34,170 --> 00:42:38,700
you do today for normal software many

957
00:42:37,020 --> 00:42:40,080
companies are developing products here

958
00:42:38,700 --> 00:42:41,640
so as you learn about this you have

959
00:42:40,080 --> 00:42:43,740
opportunity to work with other companies

960
00:42:41,640 --> 00:42:46,379
as either as an individual or as a

961
00:42:43,740 --> 00:42:48,839
company and there's a real low barrier

962
00:42:46,380 --> 00:42:50,040
for learning and entrance I encourage

963
00:42:48,840 --> 00:42:51,960
you to get involved also because there's

964
00:42:50,040 --> 00:42:54,930
a ton of low-hanging fruit there's

965
00:42:51,960 --> 00:42:57,870
dozens of interesting publications to be

966
00:42:54,930 --> 00:43:00,330
written about this area even pivoting

967
00:42:57,870 --> 00:43:02,190
excellent work from other ISAs or from

968
00:43:00,330 --> 00:43:04,830
the world of software into the world of

969
00:43:02,190 --> 00:43:07,470
hardware for more information go to the

970
00:43:04,830 --> 00:43:09,630
risk 5 website look for it on Twitter

971
00:43:07,470 --> 00:43:11,640
LinkedIn there are open mailing lists

972
00:43:09,630 --> 00:43:13,800
and groups these slides will be public

973
00:43:11,640 --> 00:43:15,839
the talk will be public and come talk to

974
00:43:13,800 --> 00:43:16,980
those of us actively involved thank you

975
00:43:15,840 --> 00:43:20,579
very much

976
00:43:16,980 --> 00:43:20,579
[Applause]

977
00:43:22,880 --> 00:43:28,459
we have time for a couple of questions

978
00:43:25,319 --> 00:43:28,459
if anyone wants to ask a question

979
00:43:32,539 --> 00:43:37,709
software that's supposed to run on a

980
00:43:34,679 --> 00:43:39,899
risk five how do I know which extensions

981
00:43:37,709 --> 00:43:42,569
are gonna be present yeah what do I do

982
00:43:39,899 --> 00:43:44,130
if they're not there yeah so essentially

983
00:43:42,569 --> 00:43:45,929
there are what so when you write

984
00:43:44,130 --> 00:43:48,239
software to risk five like let's say

985
00:43:45,929 --> 00:43:49,799
you're writing some C code you indicate

986
00:43:48,239 --> 00:43:51,809
to the compiler like you would for any

987
00:43:49,799 --> 00:43:54,059
cost compilation which extensions you

988
00:43:51,809 --> 00:43:56,069
depend upon and that's built into the

989
00:43:54,059 --> 00:43:57,839
binary itself there's also a means by

990
00:43:56,069 --> 00:43:59,939
which to query the system to understand

991
00:43:57,839 --> 00:44:02,429
the various extensions exist or don't

992
00:43:59,939 --> 00:44:05,098
exist to take advantage of them so it

993
00:44:02,429 --> 00:44:07,380
just feels like you're working on any

994
00:44:05,099 --> 00:44:09,659
old system like an Intel we're like on

995
00:44:07,380 --> 00:44:11,849
SG Xbox you can query whether they're an

996
00:44:09,659 --> 00:44:13,829
SD X exists or not it's the same sort of

997
00:44:11,849 --> 00:44:16,409
thing so it's just an extra command line

998
00:44:13,829 --> 00:44:17,759
flag more often than not okay but you

999
00:44:16,409 --> 00:44:19,979
expect that there'll be a small enough

1000
00:44:17,759 --> 00:44:21,989
set correct and root extension says yeah

1001
00:44:19,979 --> 00:44:24,269
what loppers can rely on indeed what

1002
00:44:21,989 --> 00:44:25,409
we're finding is is there's a core set

1003
00:44:24,269 --> 00:44:27,959
of extensions that it seems like

1004
00:44:25,409 --> 00:44:31,099
everyone or at least the product world

1005
00:44:27,959 --> 00:44:33,448
agrees upon and that we expect to be the

1006
00:44:31,099 --> 00:44:35,159
core common that you would compile to

1007
00:44:33,449 --> 00:44:37,579
regularly unless you're doing specialty

1008
00:44:35,159 --> 00:44:40,769
work that that's for example called our

1009
00:44:37,579 --> 00:44:42,209
64g which basically means the core set

1010
00:44:40,769 --> 00:44:44,399
of extensions you need to run a

1011
00:44:42,209 --> 00:44:46,439
multi-user operating system and those

1012
00:44:44,399 --> 00:44:49,888
standard clusters get standardized as

1013
00:44:46,439 --> 00:44:52,138
well thank you yeah one last question

1014
00:44:49,889 --> 00:44:54,779
over there given some of the

1015
00:44:52,139 --> 00:44:56,729
difficulties of eliminating side

1016
00:44:54,779 --> 00:44:58,619
channels when you're building like a

1017
00:44:56,729 --> 00:45:00,859
secure Enclave or trusted execution

1018
00:44:58,619 --> 00:45:04,380
environment have you thought about

1019
00:45:00,859 --> 00:45:06,269
building out a separate distinct

1020
00:45:04,380 --> 00:45:08,579
hardware secure element kind of more

1021
00:45:06,269 --> 00:45:11,399
similar to like the titan m chip and new

1022
00:45:08,579 --> 00:45:12,959
android devices yes I have and if you

1023
00:45:11,399 --> 00:45:14,939
google my name you'll find some

1024
00:45:12,959 --> 00:45:16,589
published work on such but much of the

1025
00:45:14,939 --> 00:45:19,169
work going on on that topic is not yet

1026
00:45:16,589 --> 00:45:23,038
public shall we say but yes this affords

1027
00:45:19,169 --> 00:45:24,690
great opportunity instant such okay so

1028
00:45:23,039 --> 00:45:25,310
that's thanks speaker again

1029
00:45:24,690 --> 00:45:28,500
[Applause]

1030
00:45:25,310 --> 00:45:34,179
[Music]

1031
00:45:28,500 --> 00:45:34,179
[Applause]

1032
00:45:40,400 --> 00:45:46,310
okay our weight with exercise working

1033
00:45:52,250 --> 00:45:55,800
okay so our third talk the session is

1034
00:45:54,540 --> 00:45:58,910
going to be by Emma and she's going to

1035
00:45:55,800 --> 00:45:58,910
talk about true to her

1036
00:46:15,970 --> 00:46:22,270
Thanks okay is that better okay thank

1037
00:46:19,960 --> 00:46:24,610
you okay

1038
00:46:22,270 --> 00:46:26,470
so I'm going to talk today about true to

1039
00:46:24,610 --> 00:46:29,020
F a system for backdoor resistant

1040
00:46:26,470 --> 00:46:31,299
authentication tokens this work was done

1041
00:46:29,020 --> 00:46:32,380
both at Stanford and at Google with

1042
00:46:31,300 --> 00:46:34,750
Henry Corrigan Gibbs

1043
00:46:32,380 --> 00:46:36,550
David masseria's dan mone and John Rizzo

1044
00:46:34,750 --> 00:46:39,880
and our paper will be appearing at

1045
00:46:36,550 --> 00:46:41,140
Auckland this spring so you probably all

1046
00:46:39,880 --> 00:46:43,600
are aware that hardware authentication

1047
00:46:41,140 --> 00:46:46,060
tokens are an especially effective form

1048
00:46:43,600 --> 00:46:48,569
of second factor authentication with you

1049
00:46:46,060 --> 00:46:50,980
to app tokens being especially popular

1050
00:46:48,570 --> 00:46:53,290
these u2f tokens are surprisingly

1051
00:46:50,980 --> 00:46:54,910
effective since Google mandated last

1052
00:46:53,290 --> 00:46:57,040
year that all its employees use these

1053
00:46:54,910 --> 00:46:58,629
security keys they haven't discovered a

1054
00:46:57,040 --> 00:47:00,640
single instance of corporate credential

1055
00:46:58,630 --> 00:47:04,840
theft showing just how effective these

1056
00:47:00,640 --> 00:47:07,330
tokens are so u2f protocol has two

1057
00:47:04,840 --> 00:47:09,700
stages so the first stage is

1058
00:47:07,330 --> 00:47:12,580
registration when a user associates

1059
00:47:09,700 --> 00:47:14,049
their token with some account so the

1060
00:47:12,580 --> 00:47:16,029
server sends some identifiers to the

1061
00:47:14,050 --> 00:47:18,520
token the token generates some server

1062
00:47:16,030 --> 00:47:21,430
specific ECDSA key pair and sends the

1063
00:47:18,520 --> 00:47:24,370
public key back to the server and this

1064
00:47:21,430 --> 00:47:25,839
is a highly simplified version and it's

1065
00:47:24,370 --> 00:47:28,480
important that the server specific key

1066
00:47:25,840 --> 00:47:31,450
pair be unique per server to provide

1067
00:47:28,480 --> 00:47:33,850
unlink ability the second step

1068
00:47:31,450 --> 00:47:36,129
authentication is run when a user wants

1069
00:47:33,850 --> 00:47:37,569
to log into their account so the server

1070
00:47:36,130 --> 00:47:41,140
sends some identifiers along with a

1071
00:47:37,570 --> 00:47:42,640
challenge the server recovers that are

1072
00:47:41,140 --> 00:47:44,350
sorry the token recovers that server

1073
00:47:42,640 --> 00:47:46,509
specific secret key to sign the

1074
00:47:44,350 --> 00:47:49,060
challenge and sends a signature back to

1075
00:47:46,510 --> 00:47:51,340
the server which is then able to verify

1076
00:47:49,060 --> 00:47:54,190
the signature using the public key and

1077
00:47:51,340 --> 00:47:55,780
obtain during registration so this

1078
00:47:54,190 --> 00:47:57,190
challenge response protocol provides a

1079
00:47:55,780 --> 00:48:00,100
really strong defense against phishing

1080
00:47:57,190 --> 00:48:01,810
attacks as well as browser compromise so

1081
00:48:00,100 --> 00:48:03,190
if you correctly register your website

1082
00:48:01,810 --> 00:48:05,170
all right sorry if you correctly

1083
00:48:03,190 --> 00:48:06,910
register your token with some site even

1084
00:48:05,170 --> 00:48:09,010
if malware takes over your browser it

1085
00:48:06,910 --> 00:48:11,170
can't authenticate without interacting

1086
00:48:09,010 --> 00:48:13,360
with the token so all your secrets

1087
00:48:11,170 --> 00:48:15,010
remain entirely on the device and aren't

1088
00:48:13,360 --> 00:48:16,900
known to the browser and so this

1089
00:48:15,010 --> 00:48:20,410
provides a really strong defense against

1090
00:48:16,900 --> 00:48:23,050
browser compromise but what about token

1091
00:48:20,410 --> 00:48:25,180
compromise so we can imagine some

1092
00:48:23,050 --> 00:48:27,340
attacker who controls the supply chain

1093
00:48:25,180 --> 00:48:28,779
who's able to backdoor the token in a

1094
00:48:27,340 --> 00:48:29,380
way that seriously undermines the

1095
00:48:28,780 --> 00:48:33,070
security

1096
00:48:29,380 --> 00:48:35,320
of the u2f protocol so here let's

1097
00:48:33,070 --> 00:48:37,180
imagine some supply chain attacker who

1098
00:48:35,320 --> 00:48:40,510
builds into the token some secret key

1099
00:48:37,180 --> 00:48:43,480
that the attacker knows so now the user

1100
00:48:40,510 --> 00:48:44,980
goes and registers at github.com and the

1101
00:48:43,480 --> 00:48:46,720
token sends back the public key

1102
00:48:44,980 --> 00:48:49,990
corresponding to the secret key that the

1103
00:48:46,720 --> 00:48:52,299
adversary knows so now the user is

1104
00:48:49,990 --> 00:48:53,649
registered at the site the secret key

1105
00:48:52,300 --> 00:48:55,510
that's supposed to be entirely on the

1106
00:48:53,650 --> 00:48:57,790
token is actually also known to the

1107
00:48:55,510 --> 00:49:02,530
adversary and the seriously undermines

1108
00:48:57,790 --> 00:49:04,509
security of the u2f protocol and so to

1109
00:49:02,530 --> 00:49:07,690
address this problem we present true to

1110
00:49:04,510 --> 00:49:09,580
F which is an enhancement of you to F so

1111
00:49:07,690 --> 00:49:12,880
we have three primary goals and true to

1112
00:49:09,580 --> 00:49:14,440
us the first is to augment you to F to

1113
00:49:12,880 --> 00:49:16,690
provide a strong protection against

1114
00:49:14,440 --> 00:49:18,880
backdoor tokens so we want to provide

1115
00:49:16,690 --> 00:49:20,800
the original protections if you to F as

1116
00:49:18,880 --> 00:49:23,860
well as protect against these supply

1117
00:49:20,800 --> 00:49:25,390
chain attacks so in particular we want

1118
00:49:23,860 --> 00:49:27,580
to provide strongest link security

1119
00:49:25,390 --> 00:49:29,710
between the token and the browser where

1120
00:49:27,580 --> 00:49:32,250
either the token or the browser's honest

1121
00:49:29,710 --> 00:49:34,240
we can make certain security guarantees

1122
00:49:32,250 --> 00:49:36,100
we want to do this while maintaining

1123
00:49:34,240 --> 00:49:38,830
backwards compatibility with existing

1124
00:49:36,100 --> 00:49:42,580
u2f servers and this is important for

1125
00:49:38,830 --> 00:49:44,319
real-world deployment so but so your

1126
00:49:42,580 --> 00:49:46,509
token and your browser are both running

1127
00:49:44,320 --> 00:49:47,830
true to F but the existing server that

1128
00:49:46,510 --> 00:49:51,100
you're authenticating with is running

1129
00:49:47,830 --> 00:49:52,840
original u2f finally we also want to be

1130
00:49:51,100 --> 00:49:54,910
performant on commodity hardware tokens

1131
00:49:52,840 --> 00:49:56,920
we want this to be actually usable and

1132
00:49:54,910 --> 00:49:58,390
so it should run relatively quickly with

1133
00:49:56,920 --> 00:50:02,290
only a firmware update to existing

1134
00:49:58,390 --> 00:50:04,480
tokens so to achieve these two goals or

1135
00:50:02,290 --> 00:50:07,090
sorry three goals we we followed the

1136
00:50:04,480 --> 00:50:09,040
following two design principles the

1137
00:50:07,090 --> 00:50:10,480
first principle is both the browser and

1138
00:50:09,040 --> 00:50:12,550
the token should contribute randomness

1139
00:50:10,480 --> 00:50:13,960
to the protocol and so this prevents the

1140
00:50:12,550 --> 00:50:17,680
token from using a form of bad

1141
00:50:13,960 --> 00:50:19,720
randomness also all the terminus tik-tok

1142
00:50:17,680 --> 00:50:23,560
and operations should be verifiable by

1143
00:50:19,720 --> 00:50:25,359
the browser so you to F has these

1144
00:50:23,560 --> 00:50:27,730
protocols as these two protocol steps

1145
00:50:25,360 --> 00:50:30,670
and in true to F we add an additional

1146
00:50:27,730 --> 00:50:32,410
third protocol step initialization which

1147
00:50:30,670 --> 00:50:36,250
you run after purchasing the token and

1148
00:50:32,410 --> 00:50:37,720
before registering it with any sites so

1149
00:50:36,250 --> 00:50:42,119
I'm going to start off by talking about

1150
00:50:37,720 --> 00:50:43,680
initialization and to Crean installation

1151
00:50:42,119 --> 00:50:45,329
our approach is guided by the idea that

1152
00:50:43,680 --> 00:50:46,799
both the borough both the browser and

1153
00:50:45,329 --> 00:50:50,579
the token should contribute randomness

1154
00:50:46,799 --> 00:50:52,288
to the protocol so our goal and

1155
00:50:50,579 --> 00:50:54,569
initialization is to generate this

1156
00:50:52,289 --> 00:50:56,910
master key pair split between the token

1157
00:50:54,569 --> 00:50:58,589
and the browser and we're going to use

1158
00:50:56,910 --> 00:51:01,259
this master key pair in subsequent

1159
00:50:58,589 --> 00:51:02,970
phases we can't generate this master key

1160
00:51:01,259 --> 00:51:04,380
pair entirely on the browser because we

1161
00:51:02,970 --> 00:51:07,140
don't want the browser to ever know the

1162
00:51:04,380 --> 00:51:08,549
master secret key we also don't want to

1163
00:51:07,140 --> 00:51:10,170
generate it entirely on the token

1164
00:51:08,549 --> 00:51:13,499
because we don't want the token to be

1165
00:51:10,170 --> 00:51:15,089
able to influence the choice of key and

1166
00:51:13,499 --> 00:51:16,709
so we want both the token and the

1167
00:51:15,089 --> 00:51:18,058
browser to contribute randomness and so

1168
00:51:16,710 --> 00:51:21,690
we run this collaborative key generation

1169
00:51:18,059 --> 00:51:24,180
protocol so you want this protocol to

1170
00:51:21,690 --> 00:51:25,680
have the following two properties so the

1171
00:51:24,180 --> 00:51:27,180
first property we want is that the token

1172
00:51:25,680 --> 00:51:30,930
can't by is the public key that the

1173
00:51:27,180 --> 00:51:32,640
protocol outputs the second property is

1174
00:51:30,930 --> 00:51:35,279
the browser should learn nothing about

1175
00:51:32,640 --> 00:51:37,319
the secret key so there's actually a

1176
00:51:35,279 --> 00:51:38,940
protocol that already does this however

1177
00:51:37,319 --> 00:51:40,440
it's pretty slow on the hardware that

1178
00:51:38,940 --> 00:51:42,390
we're using or working with a relatively

1179
00:51:40,440 --> 00:51:44,339
small embedded device I'm gonna want

1180
00:51:42,390 --> 00:51:45,660
this protocol to be pretty fast so we

1181
00:51:44,339 --> 00:51:47,339
present a protocol that runs roughly

1182
00:51:45,660 --> 00:51:49,890
three times faster than this existing

1183
00:51:47,339 --> 00:51:53,489
protocol so I'm just going to walk you

1184
00:51:49,890 --> 00:51:55,828
through our faster protocol so we use

1185
00:51:53,489 --> 00:51:58,980
some group G a prime winner Q here the

1186
00:51:55,829 --> 00:52:02,489
NIST P 256 curve and ECDSA key pair is

1187
00:51:58,980 --> 00:52:04,410
having the form of X and G to the X so

1188
00:52:02,489 --> 00:52:07,890
the browser starts off by choosing some

1189
00:52:04,410 --> 00:52:10,739
values R and V it sends a commitment to

1190
00:52:07,890 --> 00:52:13,549
R and V to the token and the token then

1191
00:52:10,739 --> 00:52:15,839
randomly chooses some V prime value it

1192
00:52:13,549 --> 00:52:18,299
sends back to the browser G to the V

1193
00:52:15,839 --> 00:52:20,519
Prime and then the browser is able to

1194
00:52:18,299 --> 00:52:22,980
set the master public key value to be

1195
00:52:20,519 --> 00:52:24,749
big V prime times G to the V so the

1196
00:52:22,980 --> 00:52:28,829
master public key is of the form G to

1197
00:52:24,749 --> 00:52:30,328
the V plus V Prime the thoth the browser

1198
00:52:28,829 --> 00:52:34,859
then opens its commitment to the token

1199
00:52:30,329 --> 00:52:36,059
and sends back vnr the token is able to

1200
00:52:34,859 --> 00:52:38,098
check that the commitment is equal to

1201
00:52:36,059 --> 00:52:40,319
the hash of V and R and if this is the

1202
00:52:38,099 --> 00:52:42,569
case it sets the master secret key to be

1203
00:52:40,319 --> 00:52:45,029
V Plus V Prime and otherwise the token

1204
00:52:42,569 --> 00:52:46,589
aborts so at the end of this protocol

1205
00:52:45,029 --> 00:52:49,170
the token should hold some master secret

1206
00:52:46,589 --> 00:52:50,578
key of the form V Plus V Prime and the

1207
00:52:49,170 --> 00:52:52,259
browser should hold semester public key

1208
00:52:50,579 --> 00:52:54,029
of the form G to the V Plus V Prime

1209
00:52:52,259 --> 00:52:55,470
and so the token contributes randomness

1210
00:52:54,029 --> 00:52:56,609
in the form of V Prime

1211
00:52:55,470 --> 00:52:59,459
browser contributes horrendous in the

1212
00:52:56,609 --> 00:53:01,230
form of V so the first property we

1213
00:52:59,460 --> 00:53:02,599
wanted was that the token can't bias the

1214
00:53:01,230 --> 00:53:05,160
public key that the protocol outputs

1215
00:53:02,599 --> 00:53:07,020
this is the case because the browser

1216
00:53:05,160 --> 00:53:10,560
contributes fee so the token can't

1217
00:53:07,020 --> 00:53:12,090
influence the choice of key pair the

1218
00:53:10,560 --> 00:53:13,590
second property we will not we wanted is

1219
00:53:12,090 --> 00:53:15,780
that the broke that the browser learns

1220
00:53:13,590 --> 00:53:17,430
nothing about the secret key except for

1221
00:53:15,780 --> 00:53:19,050
the public key and this is the case

1222
00:53:17,430 --> 00:53:21,210
because the browser only knows G to the

1223
00:53:19,050 --> 00:53:23,070
V prime as well as V and so it can't

1224
00:53:21,210 --> 00:53:27,690
drive the master secret key which is V

1225
00:53:23,070 --> 00:53:29,520
Plus V Prime so that's initialization

1226
00:53:27,690 --> 00:53:31,650
I'm going to talk now about registration

1227
00:53:29,520 --> 00:53:33,150
and our approach to registration is

1228
00:53:31,650 --> 00:53:34,770
driven by the idea that all the terminus

1229
00:53:33,150 --> 00:53:38,609
tik-tok and operations should be

1230
00:53:34,770 --> 00:53:41,550
verifiable by the browser so just as a

1231
00:53:38,609 --> 00:53:43,500
reminder in registration the server

1232
00:53:41,550 --> 00:53:44,970
sends him identifier to the token the

1233
00:53:43,500 --> 00:53:46,740
token is then able to generate some

1234
00:53:44,970 --> 00:53:50,490
server specific key pair and sends the

1235
00:53:46,740 --> 00:53:52,379
public key back to the server so you can

1236
00:53:50,490 --> 00:53:56,549
imagine some supply chain attack mounted

1237
00:53:52,380 --> 00:53:58,560
specifically on registration so the

1238
00:53:56,550 --> 00:54:00,119
account identifier sent to the token the

1239
00:53:58,560 --> 00:54:02,099
token then generates some public key

1240
00:54:00,119 --> 00:54:05,070
that hides information about the secret

1241
00:54:02,099 --> 00:54:07,230
key for another site the token sends

1242
00:54:05,070 --> 00:54:09,119
this public key back to evil comm and

1243
00:54:07,230 --> 00:54:10,349
evil comm is able to learn the secret

1244
00:54:09,119 --> 00:54:12,599
key for github.com

1245
00:54:10,349 --> 00:54:14,160
so thus cryptographic secret that was

1246
00:54:12,599 --> 00:54:15,390
supposed to remain entirely on the token

1247
00:54:14,160 --> 00:54:17,569
has now been exfiltrated

1248
00:54:15,390 --> 00:54:20,580
to evil comm it's known by the adversary

1249
00:54:17,570 --> 00:54:22,830
we don't want this to happen and so to

1250
00:54:20,580 --> 00:54:24,420
prevent this type of attack we present

1251
00:54:22,830 --> 00:54:27,420
this new primitive called verifiable

1252
00:54:24,420 --> 00:54:29,400
identity families or vis and vis

1253
00:54:27,420 --> 00:54:33,720
leveraged the master key pair that we

1254
00:54:29,400 --> 00:54:34,920
generated at initialization so one way

1255
00:54:33,720 --> 00:54:36,419
in which we could derive these server

1256
00:54:34,920 --> 00:54:38,960
specific key pairs is by using

1257
00:54:36,420 --> 00:54:41,040
collaborative key generation repeatedly

1258
00:54:38,960 --> 00:54:42,420
however the problem with that is that if

1259
00:54:41,040 --> 00:54:43,890
you registered a bunch of sites you have

1260
00:54:42,420 --> 00:54:45,570
to store all these key pairs on this

1261
00:54:43,890 --> 00:54:48,180
relatively small embedded device and

1262
00:54:45,570 --> 00:54:51,000
that becomes expensive expensive if you

1263
00:54:48,180 --> 00:54:52,799
registered a lot of sites and so vis

1264
00:54:51,000 --> 00:54:55,109
allow us to derive server specific key

1265
00:54:52,800 --> 00:54:58,770
pairs in a deterministic and verifiable

1266
00:54:55,109 --> 00:55:01,980
way from the master key pair so we want

1267
00:54:58,770 --> 00:55:03,450
the following properties for our vis so

1268
00:55:01,980 --> 00:55:04,859
first the token should be able to

1269
00:55:03,450 --> 00:55:06,109
produce the unique key pair for

1270
00:55:04,859 --> 00:55:07,460
github.com

1271
00:55:06,110 --> 00:55:09,110
and it's important that this key pair is

1272
00:55:07,460 --> 00:55:10,910
unique because then the token can't leak

1273
00:55:09,110 --> 00:55:14,510
information through the choice of key

1274
00:55:10,910 --> 00:55:16,069
pair second the token should be able to

1275
00:55:14,510 --> 00:55:18,110
prove to the browser that that public

1276
00:55:16,070 --> 00:55:19,490
key is really the unique public key for

1277
00:55:18,110 --> 00:55:22,700
that site so the browser should be able

1278
00:55:19,490 --> 00:55:24,560
to audit the tokens behavior the third

1279
00:55:22,700 --> 00:55:26,270
property we want is that the vif public

1280
00:55:24,560 --> 00:55:28,100
key for github.com should be

1281
00:55:26,270 --> 00:55:30,560
indistinguishable from a random ECDSA

1282
00:55:28,100 --> 00:55:32,450
public key and this is important for

1283
00:55:30,560 --> 00:55:36,770
maintaining the unlink ability property

1284
00:55:32,450 --> 00:55:38,029
present in traditional u2f the fourth

1285
00:55:36,770 --> 00:55:39,500
property we want is that the browser

1286
00:55:38,030 --> 00:55:42,350
shouldn't be able to forge signatures

1287
00:55:39,500 --> 00:55:44,330
under vif generated public keys this is

1288
00:55:42,350 --> 00:55:48,350
important for maintaining the underlying

1289
00:55:44,330 --> 00:55:49,759
security of u2f so given these four

1290
00:55:48,350 --> 00:55:51,650
properties I'm just gonna walk through

1291
00:55:49,760 --> 00:55:55,760
with what the UC is look like at a high

1292
00:55:51,650 --> 00:55:57,590
level so the the token holds the master

1293
00:55:55,760 --> 00:55:59,570
secret key browser whole semester public

1294
00:55:57,590 --> 00:56:01,820
key service and some identifiers to the

1295
00:55:59,570 --> 00:56:05,030
token the token now is going to run this

1296
00:56:01,820 --> 00:56:06,290
vif eval routine so it uses some master

1297
00:56:05,030 --> 00:56:08,120
secret key and the identifier to

1298
00:56:06,290 --> 00:56:09,610
generate some server specific key pair

1299
00:56:08,120 --> 00:56:12,109
as well as a proof

1300
00:56:09,610 --> 00:56:14,480
since this public key and proof back to

1301
00:56:12,110 --> 00:56:16,760
the browser and the browser is then able

1302
00:56:14,480 --> 00:56:18,770
to use this master public key and proof

1303
00:56:16,760 --> 00:56:20,600
to verify that this public key really is

1304
00:56:18,770 --> 00:56:24,080
the one unique public key associated

1305
00:56:20,600 --> 00:56:26,120
with github com so if this proof

1306
00:56:24,080 --> 00:56:29,990
verifies the browser then sends the

1307
00:56:26,120 --> 00:56:32,000
public key back to the server so this is

1308
00:56:29,990 --> 00:56:33,350
what this looks like at a high level I'm

1309
00:56:32,000 --> 00:56:34,820
now going to walk through a simplified

1310
00:56:33,350 --> 00:56:36,110
construction in more detail and I'll

1311
00:56:34,820 --> 00:56:39,410
explain when says it's simplified and we

1312
00:56:36,110 --> 00:56:41,120
actually need more later on so again

1313
00:56:39,410 --> 00:56:44,330
we're using some group G of prime order

1314
00:56:41,120 --> 00:56:46,370
Q the NIST p226 curve the token holds

1315
00:56:44,330 --> 00:56:50,540
the master secret key X and the browser

1316
00:56:46,370 --> 00:56:52,130
holds a master public key G to the X so

1317
00:56:50,540 --> 00:56:54,560
the server sends some github.com

1318
00:56:52,130 --> 00:56:56,300
identifier the token is now going to

1319
00:56:54,560 --> 00:56:58,670
calculate this value alpha which is just

1320
00:56:56,300 --> 00:57:01,670
the hash of github comm and set the

1321
00:56:58,670 --> 00:57:03,410
secret key to the Alpha times X the

1322
00:57:01,670 --> 00:57:06,890
server specific public key is just G to

1323
00:57:03,410 --> 00:57:09,020
the alpha times X so the token sends

1324
00:57:06,890 --> 00:57:10,609
this public key back to the browser the

1325
00:57:09,020 --> 00:57:12,440
browser then also generates this value

1326
00:57:10,610 --> 00:57:15,230
alpha and checks as the public key is

1327
00:57:12,440 --> 00:57:18,080
equal to Big X to the Alpha and if this

1328
00:57:15,230 --> 00:57:18,920
is the case this the browser knows that

1329
00:57:18,080 --> 00:57:20,630
this

1330
00:57:18,920 --> 00:57:22,160
but key was in fact generated correctly

1331
00:57:20,630 --> 00:57:26,150
and is able to send it back to the

1332
00:57:22,160 --> 00:57:27,649
server so the first property we wanted

1333
00:57:26,150 --> 00:57:28,940
is that the token can produce the unique

1334
00:57:27,650 --> 00:57:31,579
key pair for github com

1335
00:57:28,940 --> 00:57:34,460
so the simplified construction satisfies

1336
00:57:31,579 --> 00:57:37,010
that because the secret key is generated

1337
00:57:34,460 --> 00:57:41,660
as alpha times X and that alpha value is

1338
00:57:37,010 --> 00:57:43,430
unique for github com a second property

1339
00:57:41,660 --> 00:57:45,020
we wanted is that the token can prove to

1340
00:57:43,430 --> 00:57:46,930
the browser that public key is really

1341
00:57:45,020 --> 00:57:49,099
the unique public key for github com

1342
00:57:46,930 --> 00:57:50,660
this is also satisfied because the

1343
00:57:49,099 --> 00:57:53,000
browser can calculate the value alpha

1344
00:57:50,660 --> 00:57:56,808
and verify that big X to the Alpha is in

1345
00:57:53,000 --> 00:57:58,730
fact the public key however the third

1346
00:57:56,809 --> 00:58:00,589
property that we wanted on link ability

1347
00:57:58,730 --> 00:58:02,540
is not satisfied by the simplified

1348
00:58:00,589 --> 00:58:04,099
construction and this is the case

1349
00:58:02,540 --> 00:58:05,420
because this alpha value can be

1350
00:58:04,099 --> 00:58:07,640
calculated by the browser without

1351
00:58:05,420 --> 00:58:10,640
interacting with the token and so this

1352
00:58:07,640 --> 00:58:12,230
can allow some site to actually it can

1353
00:58:10,640 --> 00:58:15,230
allow some adversary to track the token

1354
00:58:12,230 --> 00:58:17,270
across sites and so to fix this problem

1355
00:58:15,230 --> 00:58:19,369
instead of just using hash function for

1356
00:58:17,270 --> 00:58:20,930
alpha we instead use verifiable random

1357
00:58:19,369 --> 00:58:22,130
functions and if you're curious about

1358
00:58:20,930 --> 00:58:23,390
how we do this you can check out the

1359
00:58:22,130 --> 00:58:26,510
paper for more details don't have the

1360
00:58:23,390 --> 00:58:28,368
time to explain it fully here and then

1361
00:58:26,510 --> 00:58:30,200
for unforgeable 'ti we actually prove

1362
00:58:28,369 --> 00:58:30,859
this using it for our full construction

1363
00:58:30,200 --> 00:58:32,660
in the paper

1364
00:58:30,859 --> 00:58:38,000
so again if you're curious check out the

1365
00:58:32,660 --> 00:58:40,819
paper so these VI FS present the supply

1366
00:58:38,000 --> 00:58:43,309
chain attack that I presented earlier so

1367
00:58:40,819 --> 00:58:44,509
if the token tries to choose some bad

1368
00:58:43,309 --> 00:58:46,400
public key that contains information

1369
00:58:44,510 --> 00:58:48,380
about the secret key for another site

1370
00:58:46,400 --> 00:58:50,359
the browser will recognize that this

1371
00:58:48,380 --> 00:58:51,950
isn't the one unique public key that

1372
00:58:50,359 --> 00:58:53,900
it's supposed to that it's supposed to

1373
00:58:51,950 --> 00:58:55,520
be sent for this site and will prevent

1374
00:58:53,900 --> 00:59:01,309
this information from being exfiltrated

1375
00:58:55,520 --> 00:59:03,109
to some server so that's registration

1376
00:59:01,309 --> 00:59:06,980
I'm now going to move on to

1377
00:59:03,109 --> 00:59:09,290
authentication and our in our approach

1378
00:59:06,980 --> 00:59:10,640
to authentication is the idea that both

1379
00:59:09,290 --> 00:59:14,690
the browser and the token should

1380
00:59:10,640 --> 00:59:17,000
contribute randomness to the protocol so

1381
00:59:14,690 --> 00:59:18,799
just a reminder an authentication server

1382
00:59:17,000 --> 00:59:21,020
send some challenge token recovers the

1383
00:59:18,799 --> 00:59:23,299
server specific key pair and uses the

1384
00:59:21,020 --> 00:59:24,859
secret key to sign the challenge sends

1385
00:59:23,299 --> 00:59:26,000
it back to the server which can verify

1386
00:59:24,859 --> 00:59:29,720
it using the public key from

1387
00:59:26,000 --> 00:59:31,380
registration so we can imagine another

1388
00:59:29,720 --> 00:59:34,799
supply chain attack this time now

1389
00:59:31,380 --> 00:59:36,720
specifically on authentication so

1390
00:59:34,799 --> 00:59:39,150
evil.com sends the token some challenge

1391
00:59:36,720 --> 00:59:41,519
and then the token actually hides the

1392
00:59:39,150 --> 00:59:43,859
secret key for github.com in the

1393
00:59:41,519 --> 00:59:45,750
signature it sends the signature back

1394
00:59:43,859 --> 00:59:49,410
and the server is actually able to learn

1395
00:59:45,750 --> 00:59:51,329
the secret key for github.com and so

1396
00:59:49,410 --> 00:59:53,788
this is possible because ECDSA

1397
00:59:51,329 --> 00:59:55,289
signatures are not unique if we could

1398
00:59:53,789 --> 00:59:57,119
use some unique signature scheme like

1399
00:59:55,289 --> 00:59:59,130
pls this wouldn't be a problem but we

1400
00:59:57,119 --> 01:00:04,859
need to use ECDSA to maintain backwards

1401
00:59:59,130 --> 01:00:06,059
compatibility with u2f servers so to

1402
01:00:04,859 --> 01:00:07,859
deal with this problem we present this

1403
01:00:06,059 --> 01:00:10,200
new primitive we call firewalls ECDSA

1404
01:00:07,859 --> 01:00:13,319
signatures which is inspired by work on

1405
01:00:10,200 --> 01:00:14,700
cryptographic reverse firewalls so I no

1406
01:00:13,319 --> 01:00:16,558
time to go into the full construction

1407
01:00:14,700 --> 01:00:18,720
here but the two ideas behind this new

1408
01:00:16,559 --> 01:00:20,640
primitive are that first the token in

1409
01:00:18,720 --> 01:00:22,319
the browser should use collaborative key

1410
01:00:20,640 --> 01:00:24,509
generation to generate some signing

1411
01:00:22,319 --> 01:00:27,230
knots and the browser's done able to

1412
01:00:24,509 --> 01:00:30,329
verify that the signing nonce is in fact

1413
01:00:27,230 --> 01:00:34,019
incorporated in the signature created by

1414
01:00:30,329 --> 01:00:35,849
the token second because of ECDSA

1415
01:00:34,019 --> 01:00:38,098
malleability name is that there are two

1416
01:00:35,849 --> 01:00:39,630
potentially valid signatures the browser

1417
01:00:38,099 --> 01:00:41,279
actually needs to be randomized these

1418
01:00:39,630 --> 01:00:42,660
signatures so that so the token can't

1419
01:00:41,279 --> 01:00:45,630
leak information through the choice of

1420
01:00:42,660 --> 01:00:47,190
which signature is sons so this work is

1421
01:00:45,630 --> 01:00:48,809
based closely on previous work on

1422
01:00:47,190 --> 01:00:50,640
subliminal free and subversion resistant

1423
01:00:48,809 --> 01:00:54,450
signature schemes and you can check out

1424
01:00:50,640 --> 01:00:56,420
the paper for more details so now we've

1425
01:00:54,450 --> 01:00:58,348
gone through all three protocol steps

1426
01:00:56,420 --> 01:01:00,180
there's some other contributions that I

1427
01:00:58,349 --> 01:01:01,740
don't have time to talk about today like

1428
01:01:00,180 --> 01:01:03,419
a flash optimized data structure for

1429
01:01:01,740 --> 01:01:05,250
storing u2f authentication counters as

1430
01:01:03,420 --> 01:01:06,480
well as some cryptographic optimizations

1431
01:01:05,250 --> 01:01:08,069
that we make they're tailored

1432
01:01:06,480 --> 01:01:09,660
specifically to our token hardware and

1433
01:01:08,069 --> 01:01:13,950
you can check out the paper for these as

1434
01:01:09,660 --> 01:01:15,750
well so then we implemented true to F so

1435
01:01:13,950 --> 01:01:17,910
on your left you can see a Google

1436
01:01:15,750 --> 01:01:19,079
development board running true to F so

1437
01:01:17,910 --> 01:01:21,538
this is where we got all our valuation

1438
01:01:19,079 --> 01:01:23,039
numbers that I'm about to show you and

1439
01:01:21,539 --> 01:01:24,750
on your right you can see a Google

1440
01:01:23,039 --> 01:01:27,059
production USB token with the same

1441
01:01:24,750 --> 01:01:30,450
hardware specs so not currently running

1442
01:01:27,059 --> 01:01:31,950
true to us but capable of running it so

1443
01:01:30,450 --> 01:01:33,629
when we initially started taking

1444
01:01:31,950 --> 01:01:35,490
evaluation numbers we knew that there

1445
01:01:33,630 --> 01:01:37,470
would be some overhead added and true to

1446
01:01:35,490 --> 01:01:38,970
F because now we're generating all these

1447
01:01:37,470 --> 01:01:40,980
proofs on the token we're doing this

1448
01:01:38,970 --> 01:01:42,839
collaborative randomness generation and

1449
01:01:40,980 --> 01:01:44,790
so our goal was really to reduce this

1450
01:01:42,839 --> 01:01:48,570
overhead as much as possible

1451
01:01:44,790 --> 01:01:50,220
make it actually feasible to use so here

1452
01:01:48,570 --> 01:01:53,040
I'm just showing the authentication

1453
01:01:50,220 --> 01:01:54,509
protocol latency so true to up in

1454
01:01:53,040 --> 01:01:57,750
comparison that you to up pretty

1455
01:01:54,510 --> 01:02:01,620
expensive so 446 milliseconds in

1456
01:01:57,750 --> 01:02:03,030
comparison to 23 milliseconds however as

1457
01:02:01,620 --> 01:02:05,850
we introduced a variety of cryptographic

1458
01:02:03,030 --> 01:02:08,790
optimizations we can actually reduce the

1459
01:02:05,850 --> 01:02:10,529
latency for true to f250 257

1460
01:02:08,790 --> 01:02:13,440
milliseconds in comparison to 23

1461
01:02:10,530 --> 01:02:15,180
milliseconds for you to F so true to F

1462
01:02:13,440 --> 01:02:17,760
is only about two and a half times

1463
01:02:15,180 --> 01:02:19,169
slower than you to F it's also important

1464
01:02:17,760 --> 01:02:20,580
to note that when you're authenticating

1465
01:02:19,170 --> 01:02:22,470
with ease you actually to tap the token

1466
01:02:20,580 --> 01:02:23,970
that test was removed for these numbers

1467
01:02:22,470 --> 01:02:28,319
so there's also that additional latency

1468
01:02:23,970 --> 01:02:29,549
as well so we were also curious in the

1469
01:02:28,320 --> 01:02:32,220
delay that the actual end user

1470
01:02:29,550 --> 01:02:33,480
experiences so here we're just showing

1471
01:02:32,220 --> 01:02:35,279
the time from when the browser receives

1472
01:02:33,480 --> 01:02:37,590
some requests to when the browser's

1473
01:02:35,280 --> 01:02:38,790
actually evil to respond they were

1474
01:02:37,590 --> 01:02:41,010
curious how much of this time is

1475
01:02:38,790 --> 01:02:42,870
actually spent doing the crypto in the

1476
01:02:41,010 --> 01:02:45,210
protocol both in the token and the

1477
01:02:42,870 --> 01:02:46,890
browser and we found that there's

1478
01:02:45,210 --> 01:02:48,660
actually a fair amount of time being

1479
01:02:46,890 --> 01:02:51,660
spent and browser overhead so just you

1480
01:02:48,660 --> 01:02:54,029
know parsing messages for example and so

1481
01:02:51,660 --> 01:02:56,750
the user actually doesn't experience

1482
01:02:54,030 --> 01:02:59,040
this 2.5 X overhead they're only an

1483
01:02:56,750 --> 01:03:03,090
experience in additional 20 to 30

1484
01:02:59,040 --> 01:03:05,880
milliseconds delay so the end user

1485
01:03:03,090 --> 01:03:07,560
actually only experiences only sees that

1486
01:03:05,880 --> 01:03:14,040
true to F is about 12 to 16 percent

1487
01:03:07,560 --> 01:03:16,560
slower than regular u2f yeah so so

1488
01:03:14,040 --> 01:03:19,920
actually not not that not that much

1489
01:03:16,560 --> 01:03:21,840
slower so in conclusion we can see from

1490
01:03:19,920 --> 01:03:24,930
true to F that we don't need to settle

1491
01:03:21,840 --> 01:03:26,760
for untrustworthy hardware true to F

1492
01:03:24,930 --> 01:03:28,740
augments you to F to protect against

1493
01:03:26,760 --> 01:03:30,210
backdoor tokens in particular providing

1494
01:03:28,740 --> 01:03:32,970
strongest link security between the

1495
01:03:30,210 --> 01:03:35,010
token and the browser it does this while

1496
01:03:32,970 --> 01:03:37,049
maintaining backwards compatibility with

1497
01:03:35,010 --> 01:03:39,870
existing u2f servers which is important

1498
01:03:37,050 --> 01:03:41,250
for real-world deployment it's also

1499
01:03:39,870 --> 01:03:44,630
practical deploy and then it's

1500
01:03:41,250 --> 01:03:47,280
performant on commodity hardware tokens

1501
01:03:44,630 --> 01:03:48,960
our next step is the phyto standards

1502
01:03:47,280 --> 01:03:50,940
body will be present which is

1503
01:03:48,960 --> 01:03:52,410
responsible for the u.s. standard well

1504
01:03:50,940 --> 01:03:54,810
we'll be presenting there at the end of

1505
01:03:52,410 --> 01:03:56,790
the month and are hoping that true to F

1506
01:03:54,810 --> 01:03:58,200
will be included in the next batch of

1507
01:03:56,790 --> 01:04:01,800
UTS standards

1508
01:03:58,200 --> 01:04:02,910
can actually reach real users and if

1509
01:04:01,800 --> 01:04:05,850
you're interested you can check out our

1510
01:04:02,910 --> 01:04:09,339
paper for more details and thank you

1511
01:04:05,850 --> 01:04:09,339
[Applause]

1512
01:04:13,579 --> 01:04:18,810
okay we have shut lots of questions I

1513
01:04:16,320 --> 01:04:21,630
will go first Valley okay first the

1514
01:04:18,810 --> 01:04:24,828
great talk great protocols for the trip

1515
01:04:21,630 --> 01:04:30,150
for the trust model that you had in mind

1516
01:04:24,829 --> 01:04:33,030
the original u2f has you and has to so

1517
01:04:30,150 --> 01:04:35,579
the you means that it's Universal and

1518
01:04:33,030 --> 01:04:38,550
it's not necessarily bound to one

1519
01:04:35,579 --> 01:04:41,700
browser you can roam around the world

1520
01:04:38,550 --> 01:04:46,170
and use it I mean I could not envision

1521
01:04:41,700 --> 01:04:50,399
all possible use for it but it's public

1522
01:04:46,170 --> 01:04:52,230
key so you can have a certain recognized

1523
01:04:50,400 --> 01:04:55,170
by anybody not to serve you one browser

1524
01:04:52,230 --> 01:04:58,290
so this is one limitation of protocol

1525
01:04:55,170 --> 01:05:01,170
the second one the two means that it's a

1526
01:04:58,290 --> 01:05:03,210
second factor and then one mitigation

1527
01:05:01,170 --> 01:05:05,069
for supply chain is your password is

1528
01:05:03,210 --> 01:05:07,859
first fact or which the supply chain

1529
01:05:05,069 --> 01:05:10,589
probably cannot get just these two

1530
01:05:07,859 --> 01:05:12,210
remark but of course you have a

1531
01:05:10,589 --> 01:05:14,790
different trust model and you do the

1532
01:05:12,210 --> 01:05:16,890
right things for yeah so those are both

1533
01:05:14,790 --> 01:05:19,170
really good points and so to address the

1534
01:05:16,890 --> 01:05:20,640
first point the the point where you

1535
01:05:19,170 --> 01:05:22,079
might use multiple browsers with this

1536
01:05:20,640 --> 01:05:23,400
that's actually an interesting point

1537
01:05:22,079 --> 01:05:25,920
that we consider a little bit in our

1538
01:05:23,400 --> 01:05:28,349
paper and we actually consider using

1539
01:05:25,920 --> 01:05:29,670
sync state across multiple browsers so

1540
01:05:28,349 --> 01:05:31,829
in the same way that your bookmarks are

1541
01:05:29,670 --> 01:05:33,930
synced across different instances of

1542
01:05:31,829 --> 01:05:36,869
chrome your state about this token could

1543
01:05:33,930 --> 01:05:39,509
also be synced in response to your

1544
01:05:36,869 --> 01:05:41,040
second question about you know actually

1545
01:05:39,510 --> 01:05:43,440
you know you have this password anyways

1546
01:05:41,040 --> 01:05:45,839
if I know to actually allows these you

1547
01:05:43,440 --> 01:05:47,760
to have tokens to be used as a first

1548
01:05:45,839 --> 01:05:49,259
factor as well and so there is this move

1549
01:05:47,760 --> 01:05:50,940
towards only being able to use these

1550
01:05:49,260 --> 01:05:53,280
tokens and so these supply chain attacks

1551
01:05:50,940 --> 01:05:54,569
become more of a real problem but those

1552
01:05:53,280 --> 01:05:56,579
are both really good points things

1553
01:05:54,569 --> 01:05:58,140
okay code we're gonna we got four

1554
01:05:56,579 --> 01:05:59,579
questions left here so we got to be

1555
01:05:58,140 --> 01:06:02,279
really quick some pretty fast questions

1556
01:05:59,579 --> 01:06:05,040
or not so on follow up on history marked

1557
01:06:02,280 --> 01:06:06,990
actually browse chrome is not the only

1558
01:06:05,040 --> 01:06:09,390
browser on all the only application that

1559
01:06:06,990 --> 01:06:10,990
this year to F so you have Firefox brave

1560
01:06:09,390 --> 01:06:13,420
and also both

1561
01:06:10,990 --> 01:06:15,368
of command-line easily so the solution

1562
01:06:13,420 --> 01:06:19,390
of Oh Chrome can sync it's not a

1563
01:06:15,369 --> 01:06:21,850
solution but otherwise yes you pour your

1564
01:06:19,390 --> 01:06:24,190
security model it works but I don't

1565
01:06:21,850 --> 01:06:27,940
think it covers the use all the use

1566
01:06:24,190 --> 01:06:29,860
cases of v2f yeah yeah and then this is

1567
01:06:27,940 --> 01:06:32,530
a really good point so if you wanted if

1568
01:06:29,860 --> 01:06:33,730
you use both Chrome and Firefox you

1569
01:06:32,530 --> 01:06:36,610
might need like two different you to

1570
01:06:33,730 --> 01:06:38,440
have tokens for example or you might you

1571
01:06:36,610 --> 01:06:39,940
might need to think about you know how

1572
01:06:38,440 --> 01:06:41,770
much you know if you care more about

1573
01:06:39,940 --> 01:06:43,750
your security or you know your security

1574
01:06:41,770 --> 01:06:45,100
using this true 2f token or if you cared

1575
01:06:43,750 --> 01:06:46,390
more about using multiple browsers so

1576
01:06:45,100 --> 01:06:47,650
that's a trade-off that an individual

1577
01:06:46,390 --> 01:06:49,180
user would have we have we have to be

1578
01:06:47,650 --> 01:06:55,360
focuses other people when questions that

1579
01:06:49,180 --> 01:06:57,640
come in the u2f protocol during the

1580
01:06:55,360 --> 01:07:00,730
registration ceremony and the token

1581
01:06:57,640 --> 01:07:02,500
passes back a blob of binary data that

1582
01:07:00,730 --> 01:07:05,440
is like the credential identifier and

1583
01:07:02,500 --> 01:07:06,790
that can be used to actually wrap the C

1584
01:07:05,440 --> 01:07:08,680
cookie like some tokens do it that way

1585
01:07:06,790 --> 01:07:11,080
I'm curious if there are any mitigations

1586
01:07:08,680 --> 01:07:12,640
that you can provide to sort of prove

1587
01:07:11,080 --> 01:07:15,460
that the credential idea itself is not

1588
01:07:12,640 --> 01:07:16,540
being used as a as a side channel yeah

1589
01:07:15,460 --> 01:07:18,810
this is a great question I actually

1590
01:07:16,540 --> 01:07:22,630
presented a really a really limited

1591
01:07:18,810 --> 01:07:24,100
version of the u2f suspect and so I

1592
01:07:22,630 --> 01:07:25,720
think you're referring to the key handle

1593
01:07:24,100 --> 01:07:27,130
and the browser actually chooses the key

1594
01:07:25,720 --> 01:07:29,020
handle itself and then the token

1595
01:07:27,130 --> 01:07:30,880
generates the server specific key pair

1596
01:07:29,020 --> 01:07:32,020
using that key handle and stuff how we

1597
01:07:30,880 --> 01:07:34,570
prevent the key and all from leaking

1598
01:07:32,020 --> 01:07:37,869
information okay thanks okay these two

1599
01:07:34,570 --> 01:07:40,060
questions and then that's it okay so I

1600
01:07:37,869 --> 01:07:42,070
saw in a couple of places that you are

1601
01:07:40,060 --> 01:07:45,670
very concerned with preventing the token

1602
01:07:42,070 --> 01:07:48,580
from basically communicating arbitrary

1603
01:07:45,670 --> 01:07:50,109
data out to servers because it might be

1604
01:07:48,580 --> 01:07:51,970
able to use that ability to leak data

1605
01:07:50,109 --> 01:07:55,420
and it's very impressive that you could

1606
01:07:51,970 --> 01:07:56,950
find cryptographic means to limit the

1607
01:07:55,420 --> 01:07:59,350
tokens ability to communicate through

1608
01:07:56,950 --> 01:08:03,279
that channel I wonder as a matter of

1609
01:07:59,350 --> 01:08:04,990
threat modeling whether that's the only

1610
01:08:03,280 --> 01:08:07,450
or main channel that one needs to worry

1611
01:08:04,990 --> 01:08:10,930
about a backdoor token using to leak

1612
01:08:07,450 --> 01:08:13,180
data as opposed to the fact that it's a

1613
01:08:10,930 --> 01:08:15,879
USB device maybe it implements other USB

1614
01:08:13,180 --> 01:08:17,528
classes or maybe some kind of RF thing

1615
01:08:15,880 --> 01:08:21,960
or something so are there other channels

1616
01:08:17,529 --> 01:08:23,970
in addition to this sort of front door

1617
01:08:21,960 --> 01:08:26,819
talking to the server channel that

1618
01:08:23,970 --> 01:08:29,010
should also be considered for protecting

1619
01:08:26,819 --> 01:08:30,420
against backdoors yes this is a great

1620
01:08:29,010 --> 01:08:32,310
question and true to have largely

1621
01:08:30,420 --> 01:08:34,230
considers in protocol coverage channels

1622
01:08:32,310 --> 01:08:35,940
um however there are other channels that

1623
01:08:34,229 --> 01:08:38,339
we consider in our paper as well like

1624
01:08:35,939 --> 01:08:39,990
timing timing attacks as well as failure

1625
01:08:38,340 --> 01:08:42,060
attacks and like you mentioned USB

1626
01:08:39,990 --> 01:08:44,639
tokens they can launch all these other

1627
01:08:42,060 --> 01:08:46,860
types of attacks those are a little bit

1628
01:08:44,640 --> 01:08:48,510
outside of the scope of our paper and

1629
01:08:46,859 --> 01:08:49,979
we're still thinking about defenses

1630
01:08:48,510 --> 01:08:53,400
against those and those are really valid

1631
01:08:49,979 --> 01:08:54,929
concerns but obviously hard to solve all

1632
01:08:53,399 --> 01:08:58,229
of those problems in one go because a

1633
01:08:54,930 --> 01:09:00,870
great question ok Tanya a quick question

1634
01:08:58,229 --> 01:09:02,879
on the crypto probably it's just because

1635
01:09:00,870 --> 01:09:05,880
of the abstraction for the talk but when

1636
01:09:02,880 --> 01:09:08,460
you work against being the attacker

1637
01:09:05,880 --> 01:09:10,590
linking the keys you say ok you can't

1638
01:09:08,460 --> 01:09:12,899
use the alpha as a hash of the domain

1639
01:09:10,590 --> 01:09:14,430
but since the public key is not known to

1640
01:09:12,899 --> 01:09:18,029
anybody but the browser why don't you

1641
01:09:14,430 --> 01:09:19,560
just hash in that as well and that seems

1642
01:09:18,029 --> 01:09:21,840
simpler but probably there's something

1643
01:09:19,560 --> 01:09:24,930
that it's not obvious yeah yeah see you

1644
01:09:21,840 --> 01:09:26,100
actually see so the yeah the point is a

1645
01:09:24,930 --> 01:09:27,690
little bit subtle and you can check out

1646
01:09:26,100 --> 01:09:28,950
the paper since there's like some

1647
01:09:27,689 --> 01:09:30,779
detailed proofs for why you actually

1648
01:09:28,950 --> 01:09:34,019
need these verifiable random functions

1649
01:09:30,779 --> 01:09:37,019
but you do in fact need that to provide

1650
01:09:34,020 --> 01:09:39,270
this unlink ability because the output

1651
01:09:37,020 --> 01:09:41,580
that the token sorry the the alpha value

1652
01:09:39,270 --> 01:09:43,950
should actually appear random without

1653
01:09:41,580 --> 01:09:45,269
this proof from the token I'm happy to

1654
01:09:43,950 --> 01:09:47,910
talk with you offline if you're

1655
01:09:45,270 --> 01:09:49,860
interested ok there's some thank you

1656
01:09:47,910 --> 01:09:52,460
thank you for the questions and let's

1657
01:09:49,859 --> 01:09:52,460
not speak again

1658
01:09:55,790 --> 01:09:59,100
so this is gonna be the last talk today

1659
01:09:57,960 --> 01:10:00,930
and this is the one you've been waiting

1660
01:09:59,100 --> 01:10:02,610
for this is either because you want to

1661
01:10:00,930 --> 01:10:03,960
protect I know some people in the

1662
01:10:02,610 --> 01:10:05,849
audience want to protect their assets

1663
01:10:03,960 --> 01:10:10,220
and there's some people in the audience

1664
01:10:05,850 --> 01:10:13,820
actually want to obtain the assets so

1665
01:10:10,220 --> 01:10:19,740
we're going to work out how to steal

1666
01:10:13,820 --> 01:10:22,469
Greg's car or Bryan's or someone else's

1667
01:10:19,740 --> 01:10:24,860
I don't know pick pick whichever car you

1668
01:10:22,470 --> 01:10:24,860
want to steal

1669
01:10:40,250 --> 01:10:44,820
okay

1670
01:10:41,550 --> 01:10:46,620
learnin good evening everyone so my name

1671
01:10:44,820 --> 01:10:48,870
is las Cuates and i'm if to steal

1672
01:10:46,620 --> 01:10:51,180
puzzles today someone told me it would

1673
01:10:48,870 --> 01:10:52,950
be very interesting to steal this Tesla

1674
01:10:51,180 --> 01:10:54,390
on the slide it's probably only two

1675
01:10:52,950 --> 01:10:58,679
people in the room that gets the inside

1676
01:10:54,390 --> 01:11:01,080
joke but here we can steal any Tesla so

1677
01:10:58,680 --> 01:11:03,690
on the left you have a Tesla key fob

1678
01:11:01,080 --> 01:11:05,610
so it's actually a miniature Tesla on

1679
01:11:03,690 --> 01:11:07,650
the idea of the old Tesla the way the

1680
01:11:05,610 --> 01:11:10,139
protocol works is if you have the key in

1681
01:11:07,650 --> 01:11:11,910
your pocket and you approach the car the

1682
01:11:10,140 --> 01:11:13,650
car will send you a challenge the key

1683
01:11:11,910 --> 01:11:15,450
fob computes a response and sends it

1684
01:11:13,650 --> 01:11:16,920
back to the vehicle if the vehicle

1685
01:11:15,450 --> 01:11:19,320
computed the same response it will

1686
01:11:16,920 --> 01:11:22,500
unlock and the same protocol is repeated

1687
01:11:19,320 --> 01:11:24,690
to start the vehicle now if we actually

1688
01:11:22,500 --> 01:11:27,030
take one of these key fobs and we open

1689
01:11:24,690 --> 01:11:29,700
them up you can see on the back side a

1690
01:11:27,030 --> 01:11:31,830
few components there's a UHF b CB

1691
01:11:29,700 --> 01:11:34,500
antenna there's a low frequency antenna

1692
01:11:31,830 --> 01:11:37,140
and there's a UHF transmitter this is

1693
01:11:34,500 --> 01:11:40,470
not very interesting on the front sides

1694
01:11:37,140 --> 01:11:45,900
we have this big black chip and that's

1695
01:11:40,470 --> 01:11:47,850
the Texas Instruments TMS 37 F 128 the

1696
01:11:45,900 --> 01:11:50,219
rightmost picture is actually an x-ray

1697
01:11:47,850 --> 01:11:52,020
and x-ray of this package and as you can

1698
01:11:50,220 --> 01:11:55,020
see there are two chips inside of this

1699
01:11:52,020 --> 01:11:57,420
package of two dice the top one is a

1700
01:11:55,020 --> 01:11:59,400
transponder it actually stores the

1701
01:11:57,420 --> 01:12:02,310
cryptographic key and performs all of

1702
01:11:59,400 --> 01:12:04,710
the cryptographic operations at the

1703
01:12:02,310 --> 01:12:06,720
bottom we have a general-purpose msp430

1704
01:12:04,710 --> 01:12:09,300
microcontroller it runs all of the

1705
01:12:06,720 --> 01:12:09,930
application code and it can create a

1706
01:12:09,300 --> 01:12:14,730
transponder

1707
01:12:09,930 --> 01:12:16,530
over an SPI interface data sheets

1708
01:12:14,730 --> 01:12:18,809
through these strips are not freely

1709
01:12:16,530 --> 01:12:21,420
available so you have to sign NDA's to

1710
01:12:18,810 --> 01:12:23,220
get them but what you can find online is

1711
01:12:21,420 --> 01:12:25,740
some general information about what

1712
01:12:23,220 --> 01:12:27,930
these chips can do so for example it

1713
01:12:25,740 --> 01:12:30,809
says that you can protect code without

1714
01:12:27,930 --> 01:12:33,600
using a JTAG fuse it can do

1715
01:12:30,810 --> 01:12:36,150
DSD 80 which is in proprietary 80 bit

1716
01:12:33,600 --> 01:12:38,100
cipher and a charge response protocol

1717
01:12:36,150 --> 01:12:40,710
uses a 5 by challenge and a tree byte

1718
01:12:38,100 --> 01:12:45,120
response the protocol can also implement

1719
01:12:40,710 --> 01:12:48,620
mutual authentication so because we

1720
01:12:45,120 --> 01:12:50,930
cannot get the datasheet for this trip

1721
01:12:48,620 --> 01:12:52,760
and also buying them it's very difficult

1722
01:12:50,930 --> 01:12:54,620
so if you just go on for an hour Dicky

1723
01:12:52,760 --> 01:12:57,160
you cannot buy these chips you need to

1724
01:12:54,620 --> 01:12:59,390
buy large quantities and sign NDA's

1725
01:12:57,160 --> 01:13:01,430
luckily at cosec I also have a lot of

1726
01:12:59,390 --> 01:13:06,260
international colleagues so we just

1727
01:13:01,430 --> 01:13:07,550
bought the chips in China and once we

1728
01:13:06,260 --> 01:13:08,840
got one of these chips we actually

1729
01:13:07,550 --> 01:13:11,060
noticed that they use a very uncommon

1730
01:13:08,840 --> 01:13:12,890
package type so we have to design our

1731
01:13:11,060 --> 01:13:16,610
own breakout box and then we could start

1732
01:13:12,890 --> 01:13:18,620
and connecting these chips now there's

1733
01:13:16,610 --> 01:13:20,299
little to no public information but the

1734
01:13:18,620 --> 01:13:24,410
public information that is available is

1735
01:13:20,300 --> 01:13:26,450
also very inconsistent so this are two

1736
01:13:24,410 --> 01:13:29,510
distinct turnouts for this same chip

1737
01:13:26,450 --> 01:13:30,980
that are provided by Ti so you kind of

1738
01:13:29,510 --> 01:13:35,690
have to guess what the correct one is

1739
01:13:30,980 --> 01:13:37,309
and hope it all works so the chip we

1740
01:13:35,690 --> 01:13:40,009
bought is actually only the transformer

1741
01:13:37,310 --> 01:13:41,810
without the external micro controller so

1742
01:13:40,010 --> 01:13:43,970
our first step was to try and interface

1743
01:13:41,810 --> 01:13:47,600
with this chip to send SPI commands to

1744
01:13:43,970 --> 01:13:49,640
it so we used the regular Arduino and as

1745
01:13:47,600 --> 01:13:51,560
I said that was a bit of a mess just to

1746
01:13:49,640 --> 01:13:54,290
get started because we had to figure out

1747
01:13:51,560 --> 01:13:55,400
how to get pin out to us this is what it

1748
01:13:54,290 --> 01:13:57,920
looks like if you have everything

1749
01:13:55,400 --> 01:14:00,160
connected up on a breadboard and then we

1750
01:13:57,920 --> 01:14:02,900
can send SPI commands to the transformer

1751
01:14:00,160 --> 01:14:05,240
so SPI as most of you probably know

1752
01:14:02,900 --> 01:14:07,700
usually uses three communication lines

1753
01:14:05,240 --> 01:14:09,110
so you have a clock line a data line for

1754
01:14:07,700 --> 01:14:11,300
data going from the master to the slave

1755
01:14:09,110 --> 01:14:14,059
and a data line with data coming back

1756
01:14:11,300 --> 01:14:16,220
from the slave to the mosque you can

1757
01:14:14,060 --> 01:14:18,130
also see the general SPI structions

1758
01:14:16,220 --> 01:14:20,690
slide so there's always a length byte

1759
01:14:18,130 --> 01:14:23,150
which indicates how many bytes will

1760
01:14:20,690 --> 01:14:25,190
follow the length bytes then there's a

1761
01:14:23,150 --> 01:14:26,690
command byte that indicates what action

1762
01:14:25,190 --> 01:14:30,200
you want to transform us to perform and

1763
01:14:26,690 --> 01:14:32,679
maybe some data like a challenge the

1764
01:14:30,200 --> 01:14:35,840
transponder might respond to a response

1765
01:14:32,680 --> 01:14:37,880
now in this case the I actually decided

1766
01:14:35,840 --> 01:14:41,030
to add a fourth line which is called the

1767
01:14:37,880 --> 01:14:43,880
busy line and this busy line is used by

1768
01:14:41,030 --> 01:14:45,860
the slave in this case a transponder to

1769
01:14:43,880 --> 01:14:49,730
indicate to the master when it is ready

1770
01:14:45,860 --> 01:14:51,950
to receive the next byte of data now

1771
01:14:49,730 --> 01:14:54,259
what we actually thought was to exploit

1772
01:14:51,950 --> 01:14:56,120
this busy line so it's also used to

1773
01:14:54,260 --> 01:14:58,310
throw errors the transponder can

1774
01:14:56,120 --> 01:14:59,809
indicate I don't know that command byte

1775
01:14:58,310 --> 01:15:01,530
and then it will throw an error by

1776
01:14:59,810 --> 01:15:04,190
holding the busy line low

1777
01:15:01,530 --> 01:15:06,599
I for an extended period of time a

1778
01:15:04,190 --> 01:15:08,969
second of frisée observation we made is

1779
01:15:06,600 --> 01:15:12,270
that if you set the length byte to F F

1780
01:15:08,970 --> 01:15:14,190
so it's maximum value the trip will

1781
01:15:12,270 --> 01:15:17,040
actually throw you an error after the

1782
01:15:14,190 --> 01:15:20,070
correct number of bytes was received so

1783
01:15:17,040 --> 01:15:21,840
if you set the length by to F F and then

1784
01:15:20,070 --> 01:15:24,269
iterate to all of the values of the

1785
01:15:21,840 --> 01:15:26,580
command bytes you can uncover all of the

1786
01:15:24,270 --> 01:15:29,520
existing commands and the correct number

1787
01:15:26,580 --> 01:15:30,960
of bytes you have to provide you can

1788
01:15:29,520 --> 01:15:33,660
apply this technique and automated

1789
01:15:30,960 --> 01:15:36,810
fashion and in that way it covers all of

1790
01:15:33,660 --> 01:15:39,630
the interesting commands in this chip so

1791
01:15:36,810 --> 01:15:42,540
what we found was that this two commands

1792
01:15:39,630 --> 01:15:45,200
to set a 40-bit key a 40 bit keen on an

1793
01:15:42,540 --> 01:15:48,269
80 bit key and then we found four

1794
01:15:45,200 --> 01:15:51,179
commands that actually use these keys so

1795
01:15:48,270 --> 01:15:54,870
there's a DSD 40 command and there's an

1796
01:15:51,180 --> 01:15:57,960
d st unknown command so at this point we

1797
01:15:54,870 --> 01:15:59,849
we found 240 bit ciphers and 240 bit

1798
01:15:57,960 --> 01:16:02,970
keys but we were actually expecting an

1799
01:15:59,850 --> 01:16:05,220
80 bit key and 80 bit cipher so we made

1800
01:16:02,970 --> 01:16:07,770
the assumption that maybe they combined

1801
01:16:05,220 --> 01:16:09,740
240 that Cyprus in hopes of getting an

1802
01:16:07,770 --> 01:16:13,290
80 bit secure cipher

1803
01:16:09,740 --> 01:16:14,910
that's not actually what they did but

1804
01:16:13,290 --> 01:16:17,700
what I did for the following two months

1805
01:16:14,910 --> 01:16:19,830
was to reverse this unknown cipher and

1806
01:16:17,700 --> 01:16:21,420
this is an this is a hardware

1807
01:16:19,830 --> 01:16:23,640
implementation so this is a black box

1808
01:16:21,420 --> 01:16:25,920
approach or you send challenges you

1809
01:16:23,640 --> 01:16:27,900
observe the response and that way figure

1810
01:16:25,920 --> 01:16:32,580
out what's going on on the inside this

1811
01:16:27,900 --> 01:16:34,170
took a lot of time afterwards I have to

1812
01:16:32,580 --> 01:16:36,240
figure out how they might have combined

1813
01:16:34,170 --> 01:16:38,160
these two commands so I finally got my

1814
01:16:36,240 --> 01:16:40,800
hands on an actual Tesla Model S key fob

1815
01:16:38,160 --> 01:16:43,889
and realized that they didn't blow a

1816
01:16:40,800 --> 01:16:46,890
JTAG fuse so you could simply dump the

1817
01:16:43,890 --> 01:16:48,720
msp430 further away disassemble it in

1818
01:16:46,890 --> 01:16:51,540
this case I used binding and Enza with

1819
01:16:48,720 --> 01:16:54,720
an msp430 plugin and then perform some

1820
01:16:51,540 --> 01:16:56,700
initial static analysis so usually all

1821
01:16:54,720 --> 01:16:58,530
might come to us what you do is you look

1822
01:16:56,700 --> 01:17:00,480
at the enter objectives table and this

1823
01:16:58,530 --> 01:17:02,759
will tell you which code is run when the

1824
01:17:00,480 --> 01:17:04,820
microcontroller is C set or for example

1825
01:17:02,760 --> 01:17:07,140
when you press a button on the key fob

1826
01:17:04,820 --> 01:17:09,000
another thing you can do is look at the

1827
01:17:07,140 --> 01:17:10,740
special function registers so the

1828
01:17:09,000 --> 01:17:13,040
registers are that we use to communicate

1829
01:17:10,740 --> 01:17:15,329
that data over spi

1830
01:17:13,040 --> 01:17:17,369
so once we identify which

1831
01:17:15,329 --> 01:17:19,949
Deena's actually transmitting data over

1832
01:17:17,369 --> 01:17:21,780
SPI we could go over to dynamic for

1833
01:17:19,949 --> 01:17:24,750
meta-analysis where we set breakpoints

1834
01:17:21,780 --> 01:17:28,259
at interesting agents and then dump the

1835
01:17:24,750 --> 01:17:30,570
memory when something occurs so we

1836
01:17:28,260 --> 01:17:32,369
basically apply this a few times while

1837
01:17:30,570 --> 01:17:34,290
actually going up to the car and

1838
01:17:32,369 --> 01:17:36,329
unlocking it so that you could see which

1839
01:17:34,290 --> 01:17:39,329
commands were sent over SPI and which

1840
01:17:36,329 --> 01:17:40,860
data was received after doing is a few

1841
01:17:39,329 --> 01:17:43,860
times we realize that they only use

1842
01:17:40,860 --> 01:17:46,500
command 86 which we already knew was DSD

1843
01:17:43,860 --> 01:17:48,150
40 so you can imagine at this point I

1844
01:17:46,500 --> 01:17:49,619
was very frustrated that I spent two

1845
01:17:48,150 --> 01:17:54,960
months because engineering the other

1846
01:17:49,619 --> 01:17:57,449
cipher now what is this DSD 40 so DSD 40

1847
01:17:54,960 --> 01:18:00,420
is a cipher introduced back in 2000 by

1848
01:17:57,449 --> 01:18:02,879
Texas Instruments uses a 40-bit key and

1849
01:18:00,420 --> 01:18:06,449
it was first reverse engineers by Bonin

1850
01:18:02,880 --> 01:18:08,909
at all back in 2005 back then the cipher

1851
01:18:06,449 --> 01:18:13,110
was only used in immobilization systems

1852
01:18:08,909 --> 01:18:14,969
and in a speed bus payment system so if

1853
01:18:13,110 --> 01:18:17,489
we take a look at the cipher at the

1854
01:18:14,969 --> 01:18:20,610
bottom you can see a 40-bit key register

1855
01:18:17,489 --> 01:18:24,209
that's used in an lfsr this lfsr is

1856
01:18:20,610 --> 01:18:26,759
updated every third round starting in a

1857
01:18:24,210 --> 01:18:29,730
second at the top you have the challenge

1858
01:18:26,760 --> 01:18:32,309
register and after applying 200 rounds

1859
01:18:29,730 --> 01:18:35,280
of the cipher each one produces two bits

1860
01:18:32,309 --> 01:18:39,179
of output you get the 24 bit response

1861
01:18:35,280 --> 01:18:41,460
these are the 24 bits marked in red one

1862
01:18:39,179 --> 01:18:44,190
thing to note here is that the spawns

1863
01:18:41,460 --> 01:18:45,809
actually smaller than the challenge so

1864
01:18:44,190 --> 01:18:47,969
for each challenge there will be

1865
01:18:45,809 --> 01:18:52,290
multiple keys that produce the same

1866
01:18:47,969 --> 01:18:54,389
response now at this point we knew that

1867
01:18:52,290 --> 01:18:56,909
we could break this key fob because it's

1868
01:18:54,389 --> 01:18:58,619
a 40-bit key but we still have to figure

1869
01:18:56,909 --> 01:19:00,570
out how to actually communicate with the

1870
01:18:58,619 --> 01:19:01,320
vehicle and with the key fob and in

1871
01:19:00,570 --> 01:19:05,159
order to do that we had to

1872
01:19:01,320 --> 01:19:06,239
reverse-engineer the RF protocol now in

1873
01:19:05,159 --> 01:19:08,730
the specific key fob you can actually

1874
01:19:06,239 --> 01:19:11,009
identify two distinct systems so there's

1875
01:19:08,730 --> 01:19:12,299
a remote keyless entry system and this

1876
01:19:11,010 --> 01:19:14,250
is the type of system where you have to

1877
01:19:12,300 --> 01:19:15,869
press a button and then the key fob

1878
01:19:14,250 --> 01:19:19,260
sends a message to the vehicle

1879
01:19:15,869 --> 01:19:20,519
this is one-way communication secondly

1880
01:19:19,260 --> 01:19:22,469
there's a passive keyless entry and

1881
01:19:20,520 --> 01:19:24,270
start system in which there's two-way

1882
01:19:22,469 --> 01:19:27,320
communication the car sends something

1883
01:19:24,270 --> 01:19:29,240
you to your F up and the key fob replies

1884
01:19:27,320 --> 01:19:31,040
so I started off by looking at the

1885
01:19:29,240 --> 01:19:32,990
remote kills and system because it's

1886
01:19:31,040 --> 01:19:36,860
actually easier to receive and transmit

1887
01:19:32,990 --> 01:19:39,290
UHF packets and once you know some basic

1888
01:19:36,860 --> 01:19:42,679
physical layer information you can

1889
01:19:39,290 --> 01:19:45,410
easily receive and transmit messages so

1890
01:19:42,680 --> 01:19:48,020
you figured out that the key fob uses a

1891
01:19:45,410 --> 01:19:49,220
40-bit count every time you press a

1892
01:19:48,020 --> 01:19:51,830
button on the key fob it will increment

1893
01:19:49,220 --> 01:19:55,040
the count and use this 40 bit value as a

1894
01:19:51,830 --> 01:19:57,800
challenge it then computes the response

1895
01:19:55,040 --> 01:19:59,090
and sends it this back to the car you

1896
01:19:57,800 --> 01:20:01,250
can see that in the in the packet

1897
01:19:59,090 --> 01:20:03,380
structure there's one command byte this

1898
01:20:01,250 --> 01:20:06,650
is used to indicate if you want to open

1899
01:20:03,380 --> 01:20:08,810
doors or closed doors also part of the

1900
01:20:06,650 --> 01:20:10,059
counter is sent along so that the car

1901
01:20:08,810 --> 01:20:12,680
and the key fob can stay synchronized

1902
01:20:10,060 --> 01:20:15,500
this is a very common implementation of

1903
01:20:12,680 --> 01:20:17,150
what's called a rolling code now a small

1904
01:20:15,500 --> 01:20:19,610
issue with this system is that the

1905
01:20:17,150 --> 01:20:22,009
command is not actually authenticated so

1906
01:20:19,610 --> 01:20:24,170
if you are able to capture a valid lock

1907
01:20:22,010 --> 01:20:27,200
message you can change it into an unlock

1908
01:20:24,170 --> 01:20:30,650
message and this is often exploited in a

1909
01:20:27,200 --> 01:20:32,599
whole Jam type of attack now to show

1910
01:20:30,650 --> 01:20:35,780
that we can actually do the same thing

1911
01:20:32,600 --> 01:20:41,030
if I show that I can unlock the car open

1912
01:20:35,780 --> 01:20:43,790
the front and open the trunk opening one

1913
01:20:41,030 --> 01:20:46,429
of these vehicles is fun and cool to do

1914
01:20:43,790 --> 01:20:49,790
but it's even cool if you can drive off

1915
01:20:46,430 --> 01:20:51,380
with it and in order to do that you need

1916
01:20:49,790 --> 01:20:53,840
to understand two passive kills entry

1917
01:20:51,380 --> 01:20:55,630
and start system and like I mentioned in

1918
01:20:53,840 --> 01:20:57,860
this case there's two-way communication

1919
01:20:55,630 --> 01:21:00,350
so we also need to be able to receive

1920
01:20:57,860 --> 01:21:02,299
low-frequency signals and this turned

1921
01:21:00,350 --> 01:21:05,120
out to be much more annoying than these

1922
01:21:02,300 --> 01:21:06,770
ultra-high frequency signals so what we

1923
01:21:05,120 --> 01:21:08,420
had to do was we took a box marked E

1924
01:21:06,770 --> 01:21:10,820
because it supports this specific

1925
01:21:08,420 --> 01:21:11,900
frequency and in this case we had to

1926
01:21:10,820 --> 01:21:14,030
write their own code for the

1927
01:21:11,900 --> 01:21:16,400
microcontroller we had to modify the

1928
01:21:14,030 --> 01:21:19,759
hardware and we also had to write our

1929
01:21:16,400 --> 01:21:21,110
own regular code for the FPGA in the end

1930
01:21:19,760 --> 01:21:23,900
that's this is what the signals look

1931
01:21:21,110 --> 01:21:25,460
like so we have the single received by

1932
01:21:23,900 --> 01:21:27,799
the antenna but by the antenna at the

1933
01:21:25,460 --> 01:21:30,230
top then it goes to an amplification

1934
01:21:27,800 --> 01:21:33,830
stage there's an analog Pig detect

1935
01:21:30,230 --> 01:21:35,900
circuit and then the FPGA outputs the

1936
01:21:33,830 --> 01:21:38,150
bottommost signal which is interpreted

1937
01:21:35,900 --> 01:21:40,089
by the microcontroller which then sends

1938
01:21:38,150 --> 01:21:42,280
the raw bits to the laptop

1939
01:21:40,090 --> 01:21:44,770
now receiving these alert signals was

1940
01:21:42,280 --> 01:21:47,380
very frustrating this means that I had

1941
01:21:44,770 --> 01:21:49,960
to spend a few of my weekends like this

1942
01:21:47,380 --> 01:21:51,700
so I basically taped the proxmark

1943
01:21:49,960 --> 01:21:54,160
Santana very close to one of the

1944
01:21:51,700 --> 01:21:56,800
transmitting antennas of the vehicle so

1945
01:21:54,160 --> 01:21:58,180
this one antenna at the ear view milk's

1946
01:21:56,800 --> 01:22:00,120
and there's also another antenna in the

1947
01:21:58,180 --> 01:22:02,560
center Kapali

1948
01:22:00,120 --> 01:22:04,390
so once you can you see if low frequency

1949
01:22:02,560 --> 01:22:07,420
signals and ultra-high frequency signals

1950
01:22:04,390 --> 01:22:09,250
we can build a protocol analyzer so I

1951
01:22:07,420 --> 01:22:11,650
built a simple Python tool that allows

1952
01:22:09,250 --> 01:22:14,560
me to see all the data coming in over LF

1953
01:22:11,650 --> 01:22:16,179
and all the data coming in over UHF then

1954
01:22:14,560 --> 01:22:19,420
what you do is you unlock the car a few

1955
01:22:16,180 --> 01:22:21,970
times and you stay at the data until you

1956
01:22:19,420 --> 01:22:23,560
realize what's really going on so we

1957
01:22:21,970 --> 01:22:26,260
figured out that the car is sending a

1958
01:22:23,560 --> 01:22:28,360
wake message twice a second it's

1959
01:22:26,260 --> 01:22:30,970
basically checking if a key fob is in

1960
01:22:28,360 --> 01:22:34,570
proximity and this packet contains the

1961
01:22:30,970 --> 01:22:36,430
car identify now if a key fob is in a

1962
01:22:34,570 --> 01:22:38,650
range that recognizes the sky identify

1963
01:22:36,430 --> 01:22:40,450
if it will reply and so he apply

1964
01:22:38,650 --> 01:22:42,610
basically where the same packet that

1965
01:22:40,450 --> 01:22:45,610
received but it obfuscates it a little

1966
01:22:42,610 --> 01:22:47,530
this obfuscation is very basic and so if

1967
01:22:45,610 --> 01:22:49,630
you receive this wake and apply messages

1968
01:22:47,530 --> 01:22:53,440
for two vehicles you can easily spot

1969
01:22:49,630 --> 01:22:56,350
what's going on so if the car received

1970
01:22:53,440 --> 01:22:58,450
the reply it will send the 40-bit

1971
01:22:56,350 --> 01:23:00,460
challenge to the key fob the key fob

1972
01:22:58,450 --> 01:23:03,460
computes the response and sends it back

1973
01:23:00,460 --> 01:23:08,440
to the car the car verifies the response

1974
01:23:03,460 --> 01:23:10,240
and if it's correct it will unlock so an

1975
01:23:08,440 --> 01:23:12,549
important thing to note here is that the

1976
01:23:10,240 --> 01:23:14,500
only thing you need to get a response

1977
01:23:12,550 --> 01:23:16,720
from a key fob so you need to know the

1978
01:23:14,500 --> 01:23:18,790
car identifier and at that point you can

1979
01:23:16,720 --> 01:23:22,660
send any challenge you want so you can

1980
01:23:18,790 --> 01:23:25,000
perform its chosen input attack another

1981
01:23:22,660 --> 01:23:27,250
kind of attack you could try to do is to

1982
01:23:25,000 --> 01:23:30,310
try to unlock and start the car without

1983
01:23:27,250 --> 01:23:34,030
ever seeing the key fob so a car only

1984
01:23:30,310 --> 01:23:35,680
attack so as I mentioned before for

1985
01:23:34,030 --> 01:23:38,860
every 40 bit challenge there's actually

1986
01:23:35,680 --> 01:23:41,830
2 to the 16 keys on average that will

1987
01:23:38,860 --> 01:23:44,139
produce a correct response so you could

1988
01:23:41,830 --> 01:23:46,030
build a tool that just guesses a key

1989
01:23:44,140 --> 01:23:48,550
computes a response based on the

1990
01:23:46,030 --> 01:23:51,519
challenge it received and sends it to

1991
01:23:48,550 --> 01:23:53,860
the car so we calculated that if you can

1992
01:23:51,520 --> 01:23:56,110
make one gas per second to take you 97

1993
01:23:53,860 --> 01:23:58,420
days to get a valve challenge-response

1994
01:23:56,110 --> 01:24:00,849
pair the important thing to notice that

1995
01:23:58,420 --> 01:24:03,429
this can be automated once you send one

1996
01:24:00,850 --> 01:24:05,830
correct response the clock and key

1997
01:24:03,429 --> 01:24:07,659
purple actually continuously do the wake

1998
01:24:05,830 --> 01:24:10,540
and reply to make sure that the key fob

1999
01:24:07,659 --> 01:24:11,920
is still inside of the car once you get

2000
01:24:10,540 --> 01:24:13,840
one challenge response pair you need a

2001
01:24:11,920 --> 01:24:16,420
second one but getting a second one only

2002
01:24:13,840 --> 01:24:18,580
takes nine hours after the first one so

2003
01:24:16,420 --> 01:24:20,320
in about 100 days you could drive off

2004
01:24:18,580 --> 01:24:27,190
with a car without ever seeing the key

2005
01:24:20,320 --> 01:24:28,360
fob so what we did next was to build an

2006
01:24:27,190 --> 01:24:30,219
efficient proof-of-concept attack

2007
01:24:28,360 --> 01:24:33,460
because we wanted to be able to steal

2008
01:24:30,219 --> 01:24:35,830
one of these cars as fast as possible

2009
01:24:33,460 --> 01:24:37,780
so as I mentioned before we have 40 bit

2010
01:24:35,830 --> 01:24:41,080
challenge a 40-bit key and this gets

2011
01:24:37,780 --> 01:24:43,059
combined into a 24 bit response so

2012
01:24:41,080 --> 01:24:44,889
there's multiple keys that produce the

2013
01:24:43,060 --> 01:24:46,780
same response and it also means that you

2014
01:24:44,889 --> 01:24:49,239
will need multiple challenge response

2015
01:24:46,780 --> 01:24:52,719
packs to recover the key in this case at

2016
01:24:49,239 --> 01:24:55,839
least two so back in 2005 they build an

2017
01:24:52,719 --> 01:25:00,000
FPGA cluster using 16 FPGAs and it could

2018
01:24:55,840 --> 01:25:00,000
boot force one key in about one hour

2019
01:25:00,969 --> 01:25:06,190
so what we did was to build a time

2020
01:25:03,460 --> 01:25:07,780
memory trade-off table and because we

2021
01:25:06,190 --> 01:25:10,869
can do it chose an input attack it's

2022
01:25:07,780 --> 01:25:13,269
actually a lookup table so we fix one

2023
01:25:10,869 --> 01:25:15,219
challenge you choose one and then for

2024
01:25:13,270 --> 01:25:19,330
every single value of the key we compute

2025
01:25:15,219 --> 01:25:21,840
a response all of the keys that produce

2026
01:25:19,330 --> 01:25:24,580
the same response we group into one file

2027
01:25:21,840 --> 01:25:27,429
so in the end we end up with a table

2028
01:25:24,580 --> 01:25:31,239
that's 5.4 terabytes in size that

2029
01:25:27,429 --> 01:25:33,639
contains two to the 24 files so one file

2030
01:25:31,239 --> 01:25:37,259
for each challenge and each of these

2031
01:25:33,639 --> 01:25:39,850
files contains about 2 to the 16 keys

2032
01:25:37,260 --> 01:25:42,429
now with a stable it then becomes very

2033
01:25:39,850 --> 01:25:44,199
easy to recover the key so what you do

2034
01:25:42,429 --> 01:25:46,510
first is you get the two byte code

2035
01:25:44,199 --> 01:25:48,969
identify in order to be able to send the

2036
01:25:46,510 --> 01:25:51,820
challenge the key fob you can snip this

2037
01:25:48,969 --> 01:25:53,560
from the car or just brute force it you

2038
01:25:51,820 --> 01:25:56,380
send off chosen challenge to the key fob

2039
01:25:53,560 --> 01:25:58,300
and we go after his pawns and you use

2040
01:25:56,380 --> 01:26:00,730
this response to select the correct file

2041
01:25:58,300 --> 01:26:02,949
in the table at this point there's only

2042
01:26:00,730 --> 01:26:05,830
2 to the 16 possible values of the key

2043
01:26:02,949 --> 01:26:07,389
left next to send another gangnam

2044
01:26:05,830 --> 01:26:10,000
challenge the key fob and observe the

2045
01:26:07,390 --> 01:26:13,570
spoons and using the second pair you

2046
01:26:10,000 --> 01:26:15,280
test the remaining 2 to the 16 keys this

2047
01:26:13,570 --> 01:26:19,299
takes about two seconds on a guy's

2048
01:26:15,280 --> 01:26:22,900
abilify then we of course implement this

2049
01:26:19,300 --> 01:26:25,960
attack in hardware so there's a small

2050
01:26:22,900 --> 01:26:27,670
device we made I actually have it with

2051
01:26:25,960 --> 01:26:30,220
me if today so as you can see this with

2052
01:26:27,670 --> 01:26:31,630
easily fit and youth perks if someone

2053
01:26:30,220 --> 01:26:34,450
wants to take a closer look at it later

2054
01:26:31,630 --> 01:26:36,820
yeah come on find me and so the top

2055
01:26:34,450 --> 01:26:38,519
there's a USB power bank the same kind

2056
01:26:36,820 --> 01:26:41,920
of power bank used to charge your phone

2057
01:26:38,520 --> 01:26:44,500
then there's a gas berry pi3 that

2058
01:26:41,920 --> 01:26:45,730
controls all of the RF for our track the

2059
01:26:44,500 --> 01:26:48,250
bottom there is a box marked in a

2060
01:26:45,730 --> 01:26:51,730
yardstick one the to the LF and UHF

2061
01:26:48,250 --> 01:26:54,940
communication after doing all this

2062
01:26:51,730 --> 01:26:58,240
research we obviously also contacted the

2063
01:26:54,940 --> 01:27:01,089
affected manufacturers so we tested the

2064
01:26:58,240 --> 01:27:03,340
attack on a Tesla Model S and he ported

2065
01:27:01,090 --> 01:27:05,230
the issue to Tesla and then we actually

2066
01:27:03,340 --> 01:27:07,030
found out that they didn't built the

2067
01:27:05,230 --> 01:27:09,400
system themselves so the system was

2068
01:27:07,030 --> 01:27:11,050
built by back to him and we learned that

2069
01:27:09,400 --> 01:27:13,759
they build similar systems for McLaren

2070
01:27:11,050 --> 01:27:17,159
gamma and time

2071
01:27:13,760 --> 01:27:20,550
as you can imagine I don't have him a

2072
01:27:17,159 --> 01:27:26,848
clam if someone in the audience does

2073
01:27:20,550 --> 01:27:30,439
have one please let me know so we

2074
01:27:26,849 --> 01:27:32,969
contacted Tesla in August of 2017 and

2075
01:27:30,439 --> 01:27:35,400
they actually designed a new key fob so

2076
01:27:32,969 --> 01:27:37,889
our key fobs and a thermal SS release

2077
01:27:35,400 --> 01:27:39,449
today there's a newer version and for

2078
01:27:37,889 --> 01:27:41,610
existing customers they also released

2079
01:27:39,449 --> 01:27:43,199
over-the-air updates and basically a

2080
01:27:41,610 --> 01:27:44,909
second factor of authentication where

2081
01:27:43,199 --> 01:27:46,348
you have to enter your PIN to start the

2082
01:27:44,909 --> 01:27:48,839
vehicle you have to enable these

2083
01:27:46,349 --> 01:27:50,699
features the second feature is the

2084
01:27:48,840 --> 01:27:53,159
ability to Z to disable passive keyless

2085
01:27:50,699 --> 01:27:54,959
entry this is actually a very nice

2086
01:27:53,159 --> 01:27:58,018
feature because it will also stop relay

2087
01:27:54,959 --> 01:28:00,630
attacks and I think that's not actually

2088
01:27:58,019 --> 01:28:02,699
did a nice job in handling this issue

2089
01:28:00,630 --> 01:28:04,920
because it's difficult to fix as it's a

2090
01:28:02,699 --> 01:28:06,348
hardware issue and I know that if some

2091
01:28:04,920 --> 01:28:08,699
people in the room today that actually

2092
01:28:06,349 --> 01:28:11,600
helped solve this problem and I think

2093
01:28:08,699 --> 01:28:15,559
they deserve a round of applause

2094
01:28:11,600 --> 01:28:15,560
[Applause]

2095
01:28:18,170 --> 01:28:23,100
so that's what showed us how to do

2096
01:28:20,760 --> 01:28:23,940
responsible disclosure correctly now

2097
01:28:23,100 --> 01:28:28,170
let's have a look at the other

2098
01:28:23,940 --> 01:28:30,690
manufacturers the other manufacturers

2099
01:28:28,170 --> 01:28:33,120
don't have any security contacts so what

2100
01:28:30,690 --> 01:28:34,559
I had to do was go on LinkedIn search

2101
01:28:33,120 --> 01:28:38,220
for people working at these companies

2102
01:28:34,560 --> 01:28:39,870
and then email people doing something

2103
01:28:38,220 --> 01:28:42,380
with electronics of something security

2104
01:28:39,870 --> 01:28:45,290
related and all that they would imply

2105
01:28:42,380 --> 01:28:48,480
people at times never applied to us

2106
01:28:45,290 --> 01:28:50,610
someone at karma did reply in the end we

2107
01:28:48,480 --> 01:28:53,209
sent them a copy of a paper and they

2108
01:28:50,610 --> 01:28:53,210
said thank you

2109
01:28:53,540 --> 01:28:59,940
McLaggen after contacting about five

2110
01:28:56,010 --> 01:29:01,140
people someone did reply but they

2111
01:28:59,940 --> 01:29:04,469
weren't very enthusiastic about

2112
01:29:01,140 --> 01:29:06,330
discussing the issues now this is

2113
01:29:04,470 --> 01:29:08,700
actually the public statement that was

2114
01:29:06,330 --> 01:29:10,620
made by McLaren it's still online today

2115
01:29:08,700 --> 01:29:12,679
so if you want to heat the entire thing

2116
01:29:10,620 --> 01:29:16,290
go and look it up it's very entertaining

2117
01:29:12,680 --> 01:29:17,880
so they start off by saying that they

2118
01:29:16,290 --> 01:29:19,260
have been alerted which is nice because

2119
01:29:17,880 --> 01:29:21,900
that means that they acknowledge that we

2120
01:29:19,260 --> 01:29:25,350
contacted them and then they go on by

2121
01:29:21,900 --> 01:29:27,480
saying the Gua attack and it's obviously

2122
01:29:25,350 --> 01:29:29,400
not a la attack and then they try to

2123
01:29:27,480 --> 01:29:31,830
explain how a way attack work is and

2124
01:29:29,400 --> 01:29:33,750
they say that your car key could be

2125
01:29:31,830 --> 01:29:37,410
scanned if you leave it close to your

2126
01:29:33,750 --> 01:29:39,960
vehicle now for those we know how he'll

2127
01:29:37,410 --> 01:29:42,180
a attack works if you leave your key fob

2128
01:29:39,960 --> 01:29:45,450
close to your vehicle I'm not gonna

2129
01:29:42,180 --> 01:29:46,680
bother doing a villa attack I'm just

2130
01:29:45,450 --> 01:29:50,400
getting enough you're in your car and

2131
01:29:46,680 --> 01:29:52,950
driving off the second part is then

2132
01:29:50,400 --> 01:29:55,500
actually nice because they explain the

2133
01:29:52,950 --> 01:29:56,910
car only attack we discussed so this

2134
01:29:55,500 --> 01:30:00,060
meant that they actually get the paper

2135
01:29:56,910 --> 01:30:01,650
we sent them and they also say that you

2136
01:30:00,060 --> 01:30:05,540
have to be a skilled attacker to do this

2137
01:30:01,650 --> 01:30:08,490
so as I was a bit flattering of course

2138
01:30:05,540 --> 01:30:10,080
but then when we read on about this guy

2139
01:30:08,490 --> 01:30:12,269
only attack they say

2140
01:30:10,080 --> 01:30:15,660
the equipment needs to be in very close

2141
01:30:12,270 --> 01:30:18,030
proximity to a key it's called a

2142
01:30:15,660 --> 01:30:21,360
only attack so this is actually the

2143
01:30:18,030 --> 01:30:23,280
second sentence of the of a paragraph we

2144
01:30:21,360 --> 01:30:26,759
send to them which says you never need

2145
01:30:23,280 --> 01:30:29,630
to be in proximity of the key fob so

2146
01:30:26,760 --> 01:30:32,670
yeah but in case you do only McClaren

2147
01:30:29,630 --> 01:30:38,760
don't worry my client is very serious

2148
01:30:32,670 --> 01:30:40,680
about security I have a few conclusions

2149
01:30:38,760 --> 01:30:42,990
about this research I think most of them

2150
01:30:40,680 --> 01:30:44,850
are pretty obvious and the people in

2151
01:30:42,990 --> 01:30:46,349
assume probably all know them but it

2152
01:30:44,850 --> 01:30:49,050
seems that not all people are aware yet

2153
01:30:46,350 --> 01:30:52,140
so here we go again

2154
01:30:49,050 --> 01:30:53,940
don't use proprietary cryptography don't

2155
01:30:52,140 --> 01:30:57,270
rely on the secrecy of data sheets or

2156
01:30:53,940 --> 01:30:58,769
NDA's to protect your systems and if you

2157
01:30:57,270 --> 01:31:00,750
have a car manufacturer you probably

2158
01:30:58,770 --> 01:31:02,520
have a lot of suppliers and I think it's

2159
01:31:00,750 --> 01:31:04,110
better to work with them instead of just

2160
01:31:02,520 --> 01:31:07,110
buying something from them and hoping it

2161
01:31:04,110 --> 01:31:08,339
will be secure and if you need if you

2162
01:31:07,110 --> 01:31:10,139
need further reading your system

2163
01:31:08,340 --> 01:31:12,630
don't rely on secrecy of your firmware

2164
01:31:10,140 --> 01:31:14,670
to make a product secure don't put keys

2165
01:31:12,630 --> 01:31:16,800
in fairness even if you lock chat again

2166
01:31:14,670 --> 01:31:20,160
the faces it's probably always a way to

2167
01:31:16,800 --> 01:31:21,540
get the throwing out some other common

2168
01:31:20,160 --> 01:31:24,269
issues we've seen in these systems is

2169
01:31:21,540 --> 01:31:26,430
the use of keys so this has been shown a

2170
01:31:24,270 --> 01:31:29,610
few times in the past that manufacturers

2171
01:31:26,430 --> 01:31:30,990
like to hear skis and I think it's

2172
01:31:29,610 --> 01:31:32,160
important and if you design a product

2173
01:31:30,990 --> 01:31:35,309
like this yourself that you at least

2174
01:31:32,160 --> 01:31:36,599
know what the existing security issues

2175
01:31:35,310 --> 01:31:38,240
are so that you can design a product

2176
01:31:36,600 --> 01:31:40,260
that's better

2177
01:31:38,240 --> 01:31:41,519
another important conclusion was

2178
01:31:40,260 --> 01:31:44,460
actually tweeted by one of my colleagues

2179
01:31:41,520 --> 01:31:46,230
and I agree with them I think it's very

2180
01:31:44,460 --> 01:31:48,600
addictive us a textile companies out

2181
01:31:46,230 --> 01:31:51,059
text today that don't have a way for

2182
01:31:48,600 --> 01:31:52,980
security researchers to contact them so

2183
01:31:51,060 --> 01:31:54,690
if you're working for a company that

2184
01:31:52,980 --> 01:31:56,339
doesn't have a security contact up on

2185
01:31:54,690 --> 01:31:59,639
your website I think you should change

2186
01:31:56,340 --> 01:32:01,200
something and then there was a question

2187
01:31:59,640 --> 01:32:03,030
from one of my colleagues and he asked

2188
01:32:01,200 --> 01:32:06,540
me like couldn't you have made a lot of

2189
01:32:03,030 --> 01:32:08,070
money by just buying Tesla stock and so

2190
01:32:06,540 --> 01:32:12,930
this is what the stock looked like in

2191
01:32:08,070 --> 01:32:14,790
September of 2018 for Tesla does anyone

2192
01:32:12,930 --> 01:32:16,950
remember what happened on the 7th of

2193
01:32:14,790 --> 01:32:18,949
September is that the big dip in the

2194
01:32:16,950 --> 01:32:22,219
stock

2195
01:32:18,949 --> 01:32:22,219
yes exactly

2196
01:32:24,110 --> 01:32:27,799
now on the only 11th of September when

2197
01:32:26,540 --> 01:32:29,660
we released the he search you can see

2198
01:32:27,800 --> 01:32:31,310
that there's an another slight dip in

2199
01:32:29,660 --> 01:32:33,559
the stock price so this is when we

2200
01:32:31,310 --> 01:32:35,450
released the video of the attack but

2201
01:32:33,560 --> 01:32:36,890
then I went on Twitter and I noticed

2202
01:32:35,450 --> 01:32:38,720
that ill Musk tweeted that he would be

2203
01:32:36,890 --> 01:32:42,020
moving two of the seven colors of the

2204
01:32:38,720 --> 01:32:45,250
Tesla's so I don't think our security

2205
01:32:42,020 --> 01:32:48,170
search actually impacted the stock price

2206
01:32:45,250 --> 01:32:49,730
to end this presentation we made a video

2207
01:32:48,170 --> 01:32:51,350
showing how the attack works in practice

2208
01:32:49,730 --> 01:32:55,360
so I'll show you the video and then

2209
01:32:51,350 --> 01:32:57,830
afterwards you can have some questions

2210
01:32:55,360 --> 01:33:00,380
so the attack scenario of the video is I

2211
01:32:57,830 --> 01:33:01,940
think pretty obvious it's very easy to

2212
01:33:00,380 --> 01:33:04,250
find this class because I need to be

2213
01:33:01,940 --> 01:33:08,120
charged so if you go to a Tesla

2214
01:33:04,250 --> 01:33:10,550
supercharger if you go to a Tesla

2215
01:33:08,120 --> 01:33:13,030
supercharger you will always find one

2216
01:33:10,550 --> 01:33:13,030
you can steal

2217
01:33:30,660 --> 01:33:35,040
so I mentioned before the first part you

2218
01:33:33,750 --> 01:33:37,860
have to do is an attacker could leave

2219
01:33:35,040 --> 01:33:39,440
the guy identify you can choose you can

2220
01:33:37,860 --> 01:33:44,460
use snippet from the car because it's

2221
01:33:39,440 --> 01:33:50,669
broadcasted so you walk up to it and you

2222
01:33:44,460 --> 01:33:53,130
sniff it then once you do that you go to

2223
01:33:50,670 --> 01:33:55,440
the closest Starbucks or whatever that's

2224
01:33:53,130 --> 01:33:59,250
nearby with probably the person owning

2225
01:33:55,440 --> 01:34:01,559
the car is you send your two challenges

2226
01:33:59,250 --> 01:34:04,080
across the responses download the

2227
01:34:01,560 --> 01:34:06,120
candidate key file brute force the key

2228
01:34:04,080 --> 01:34:08,940
and by the time you back at the vehicle

2229
01:34:06,120 --> 01:34:14,000
you already have the key codes now you

2230
01:34:08,940 --> 01:34:14,000
can easily unlock the vehicle unplug it

2231
01:34:16,160 --> 01:34:24,720
you can wait into a charged even and

2232
01:34:22,740 --> 01:34:26,929
then you can start the vehicle and drive

2233
01:34:24,720 --> 01:34:26,930
off

2234
01:34:28,710 --> 01:34:32,109
[Applause]

2235
01:34:35,950 --> 01:34:42,010
[Applause]

2236
01:34:53,700 --> 01:34:56,849
thank you

2237
01:35:00,240 --> 01:35:08,290
any questions this is a kind of specific

2238
01:35:06,010 --> 01:35:11,380
but why were there like three separate

2239
01:35:08,290 --> 01:35:13,330
mechanisms on the key fob when its job

2240
01:35:11,380 --> 01:35:16,480
is basically just to say like hi I'm

2241
01:35:13,330 --> 01:35:17,890
hearing up I'm nearby I think it's

2242
01:35:16,480 --> 01:35:20,830
something that is going historically

2243
01:35:17,890 --> 01:35:22,120
like at first there were key fob so you

2244
01:35:20,830 --> 01:35:23,620
could only press a button and you don't

2245
01:35:22,120 --> 01:35:25,809
have the physical key that you have to

2246
01:35:23,620 --> 01:35:28,240
turn the key for it and I was usually a

2247
01:35:25,810 --> 01:35:30,220
transformer in there and then people

2248
01:35:28,240 --> 01:35:31,719
always want more convenience so they

2249
01:35:30,220 --> 01:35:36,220
came up with this massive keyless entry

2250
01:35:31,720 --> 01:35:37,780
and start system and I think they just

2251
01:35:36,220 --> 01:35:39,700
keep on having the remote keyless entry

2252
01:35:37,780 --> 01:35:41,980
one for example you approach a car and

2253
01:35:39,700 --> 01:35:44,019
you want to unlock the trunk for someone

2254
01:35:41,980 --> 01:35:46,150
else or something you can do it from a

2255
01:35:44,020 --> 01:35:47,290
bigger distance whereas for passive

2256
01:35:46,150 --> 01:35:48,670
kills anything you need to be like one

2257
01:35:47,290 --> 01:35:50,530
of two meters away from the car figure

2258
01:35:48,670 --> 01:35:56,650
to work I think that's done the main

2259
01:35:50,530 --> 01:36:02,620
reason no other questions anyone

2260
01:35:56,650 --> 01:36:04,570
panicked about their car no okay I would

2261
01:36:02,620 --> 01:36:06,250
like to thank and again and thank all

2262
01:36:04,570 --> 01:36:09,360
the speakers of this afternoon's session

2263
01:36:06,250 --> 01:36:12,610
[Applause]

2264
01:36:09,360 --> 01:36:15,199
[Music]

2265
01:36:12,610 --> 01:36:18,009
and we'll see you all back here tomorrow

2266
01:36:15,199 --> 01:36:18,009
morning

