1
00:00:00,240 --> 00:00:03,040
i'm really happy to tell you about some

2
00:00:03,040 --> 00:00:04,720
work that i've been doing

3
00:00:04,720 --> 00:00:06,720
in the last year together with my

4
00:00:06,720 --> 00:00:09,440
colleagues alexandros marcolidis

5
00:00:09,440 --> 00:00:12,559
alessandro bruni daniel carles

6
00:00:12,559 --> 00:00:15,599
christian reichberger and roman back

7
00:00:15,599 --> 00:00:18,240
we came up with a solution that connects

8
00:00:18,240 --> 00:00:19,760
mobility data

9
00:00:19,760 --> 00:00:21,720
to infectious disease in a

10
00:00:21,720 --> 00:00:24,160
privacy-preserving way

11
00:00:24,160 --> 00:00:27,039
our approach is orthogonal to contract

12
00:00:27,039 --> 00:00:28,480
racing apps

13
00:00:28,480 --> 00:00:31,840
we only require feature phones and the

14
00:00:31,840 --> 00:00:32,479
data

15
00:00:32,479 --> 00:00:35,040
is already available by mobile network

16
00:00:35,040 --> 00:00:37,760
operators

17
00:00:37,920 --> 00:00:40,320
our solution gives a big picture of a

18
00:00:40,320 --> 00:00:42,239
current outbreak

19
00:00:42,239 --> 00:00:44,559
but we cannot do contact racing so we

20
00:00:44,559 --> 00:00:45,600
cannot see

21
00:00:45,600 --> 00:00:49,600
individual infections it is long known

22
00:00:49,600 --> 00:00:51,280
that human mobility

23
00:00:51,280 --> 00:00:54,160
is a critical factor infectious disease

24
00:00:54,160 --> 00:00:55,680
for two reasons

25
00:00:55,680 --> 00:00:58,800
first for the increased contacts between

26
00:00:58,800 --> 00:01:00,079
susceptible

27
00:01:00,079 --> 00:01:03,359
and infected individuals as a counter

28
00:01:03,359 --> 00:01:04,799
measure we have now these

29
00:01:04,799 --> 00:01:08,439
lockdowns and second through the

30
00:01:08,439 --> 00:01:11,040
introduction of pathogens

31
00:01:11,040 --> 00:01:14,320
into new geographical regions this is a

32
00:01:14,320 --> 00:01:15,600
reason why

33
00:01:15,600 --> 00:01:19,200
we have this conference not in amsterdam

34
00:01:19,200 --> 00:01:22,720
but online to sum up

35
00:01:22,720 --> 00:01:26,000
understanding human mobility directly

36
00:01:26,000 --> 00:01:28,640
translates to a better understanding of

37
00:01:28,640 --> 00:01:29,600
the dynamic

38
00:01:29,600 --> 00:01:32,559
of a pandemic

39
00:01:33,680 --> 00:01:36,640
10 years ago researchers started to

40
00:01:36,640 --> 00:01:37,119
connect

41
00:01:37,119 --> 00:01:41,040
mobile phone data to infectious deceit

42
00:01:41,040 --> 00:01:43,360
and the outcome you see on this slide is

43
00:01:43,360 --> 00:01:44,880
a prediction of future

44
00:01:44,880 --> 00:01:48,560
outbreaks of a particular disease

45
00:01:48,560 --> 00:01:51,920
and this was verified through with many

46
00:01:51,920 --> 00:01:52,560
more

47
00:01:52,560 --> 00:01:55,360
infectious disease like dengue or

48
00:01:55,360 --> 00:01:57,200
cholera

49
00:01:57,200 --> 00:02:00,799
so far researchers aggregated mobility

50
00:02:00,799 --> 00:02:01,759
data of

51
00:02:01,759 --> 00:02:04,159
all subscribers of one mobile network

52
00:02:04,159 --> 00:02:05,840
operator

53
00:02:05,840 --> 00:02:07,840
this worked quite well to get a general

54
00:02:07,840 --> 00:02:08,878
mobility

55
00:02:08,878 --> 00:02:13,440
pattern of the whole population

56
00:02:13,440 --> 00:02:16,239
but they had to admit that they had

57
00:02:16,239 --> 00:02:18,480
issues when there are relative few cases

58
00:02:18,480 --> 00:02:20,319
so if you're at the beginning of an

59
00:02:20,319 --> 00:02:22,480
outbreak or the beginning of a second

60
00:02:22,480 --> 00:02:24,160
wave

61
00:02:24,160 --> 00:02:26,560
and they also had some problems when

62
00:02:26,560 --> 00:02:28,080
there were mass gatherings

63
00:02:28,080 --> 00:02:30,400
so events where a lot of people come to

64
00:02:30,400 --> 00:02:32,959
one place

65
00:02:32,959 --> 00:02:36,879
our proposition is now to close this gap

66
00:02:36,879 --> 00:02:41,200
and therefore we propose to aggregate

67
00:02:41,200 --> 00:02:43,920
only the mobility data of infected

68
00:02:43,920 --> 00:02:45,440
individuals

69
00:02:45,440 --> 00:02:47,840
and this should lead to a more accurate

70
00:02:47,840 --> 00:02:51,360
picture about the current outbreak

71
00:02:51,360 --> 00:02:54,319
but this seems rather obvious to do so

72
00:02:54,319 --> 00:02:58,000
why wasn't this done so far

73
00:02:58,560 --> 00:03:02,400
the reason is because of privacy issues

74
00:03:02,400 --> 00:03:04,640
if you think if you do not have a

75
00:03:04,640 --> 00:03:06,640
knowledge in cryptography

76
00:03:06,640 --> 00:03:08,720
then you only have two options how you

77
00:03:08,720 --> 00:03:10,400
could connect the

78
00:03:10,400 --> 00:03:13,040
mobile phone data to infectious disease

79
00:03:13,040 --> 00:03:14,560
data

80
00:03:14,560 --> 00:03:18,000
and the one is that the researchers

81
00:03:18,000 --> 00:03:21,680
send the patient's identifiers directly

82
00:03:21,680 --> 00:03:23,440
to the mobile operator

83
00:03:23,440 --> 00:03:25,840
which respond which then respond with

84
00:03:25,840 --> 00:03:26,480
the

85
00:03:26,480 --> 00:03:28,400
location data of these infected

86
00:03:28,400 --> 00:03:30,799
individuals

87
00:03:30,799 --> 00:03:32,640
in this way at the end the mobile

88
00:03:32,640 --> 00:03:34,879
network operator learns

89
00:03:34,879 --> 00:03:38,319
who is sick and who is not sick clearly

90
00:03:38,319 --> 00:03:40,959
a thing we do not want to have

91
00:03:40,959 --> 00:03:44,000
a second maybe a bit better option

92
00:03:44,000 --> 00:03:47,200
in regards with regards to privacy is if

93
00:03:47,200 --> 00:03:48,400
we would give

94
00:03:48,400 --> 00:03:51,280
researchers access to non-anonymized

95
00:03:51,280 --> 00:03:52,640
data records

96
00:03:52,640 --> 00:03:54,640
so essentially they go to the premise of

97
00:03:54,640 --> 00:03:56,400
a mobile network operator

98
00:03:56,400 --> 00:03:59,439
and can then download the location data

99
00:03:59,439 --> 00:03:59,760
from

100
00:03:59,760 --> 00:04:03,040
infected individuals but in this way the

101
00:04:03,040 --> 00:04:04,879
researchers would have access to

102
00:04:04,879 --> 00:04:07,120
all the location data of a mobile

103
00:04:07,120 --> 00:04:09,040
network operator

104
00:04:09,040 --> 00:04:12,159
still not good enough

105
00:04:12,319 --> 00:04:16,479
and the solution is now cryptography

106
00:04:16,798 --> 00:04:19,680
in particular we are using three privacy

107
00:04:19,680 --> 00:04:22,320
enhancing technologies

108
00:04:22,320 --> 00:04:25,280
the first one is homomorphic encryption

109
00:04:25,280 --> 00:04:26,400
through this

110
00:04:26,400 --> 00:04:29,040
new encryption scheme we protect the

111
00:04:29,040 --> 00:04:32,320
patient's identifiers

112
00:04:32,320 --> 00:04:35,040
second we use here knowledge proof

113
00:04:35,040 --> 00:04:36,639
techniques to ensure

114
00:04:36,639 --> 00:04:40,240
that the the canonicality of the

115
00:04:40,240 --> 00:04:42,800
identifier set has a certain

116
00:04:42,800 --> 00:04:46,160
minimum size and

117
00:04:46,160 --> 00:04:48,400
because we already know that only

118
00:04:48,400 --> 00:04:51,360
aggregating over location data

119
00:04:51,360 --> 00:04:55,360
still leaves room for re-identification

120
00:04:55,360 --> 00:04:58,720
we add noise to this final heat map and

121
00:04:58,720 --> 00:05:00,800
have this beautiful framework of

122
00:05:00,800 --> 00:05:02,320
differential privacy

123
00:05:02,320 --> 00:05:05,280
to get some mathematical guarantees out

124
00:05:05,280 --> 00:05:07,599
of it

125
00:05:08,000 --> 00:05:10,800
now let's look at the protocol on the

126
00:05:10,800 --> 00:05:14,160
left you see the researchers that have

127
00:05:14,160 --> 00:05:16,960
the patient's identifiers here depicted

128
00:05:16,960 --> 00:05:19,039
with their phone numbers

129
00:05:19,039 --> 00:05:20,960
the first thing in the protocol is that

130
00:05:20,960 --> 00:05:22,400
the researchers

131
00:05:22,400 --> 00:05:25,199
encrypt these identifiers with

132
00:05:25,199 --> 00:05:27,360
homomorphic encryption

133
00:05:27,360 --> 00:05:29,600
then they can send it to the mobile

134
00:05:29,600 --> 00:05:32,240
operator

135
00:05:32,880 --> 00:05:35,840
which has its own database of all his

136
00:05:35,840 --> 00:05:37,360
subscribers

137
00:05:37,360 --> 00:05:41,840
with associate location data

138
00:05:41,919 --> 00:05:43,680
all the computation on the mobile

139
00:05:43,680 --> 00:05:45,520
network operator side

140
00:05:45,520 --> 00:05:48,479
happens in the homomorphic domain so the

141
00:05:48,479 --> 00:05:50,160
patient's identifiers

142
00:05:50,160 --> 00:05:53,440
never get decrypted

143
00:05:53,440 --> 00:05:55,280
the mobile network operator performs

144
00:05:55,280 --> 00:05:57,520
three steps the first one is

145
00:05:57,520 --> 00:06:00,639
he validates the request so he looks if

146
00:06:00,639 --> 00:06:02,319
the request is malicious

147
00:06:02,319 --> 00:06:04,800
if the researchers are trying for

148
00:06:04,800 --> 00:06:06,800
example to single out somebody

149
00:06:06,800 --> 00:06:09,840
more to that later the second step

150
00:06:09,840 --> 00:06:12,479
is the heart of the protocol so this is

151
00:06:12,479 --> 00:06:14,960
the data aggregation

152
00:06:14,960 --> 00:06:16,800
here we build or the mobile network

153
00:06:16,800 --> 00:06:20,000
operator builds the heat map

154
00:06:20,000 --> 00:06:23,039
and the last step is adding the noise to

155
00:06:23,039 --> 00:06:24,240
this heat map

156
00:06:24,240 --> 00:06:30,479
to make re-identification very unlikely

157
00:06:30,479 --> 00:06:33,680
and remember the result the heat map is

158
00:06:33,680 --> 00:06:34,000
still

159
00:06:34,000 --> 00:06:35,840
encrypted and cannot be read by the

160
00:06:35,840 --> 00:06:37,919
mobile network operator he then sends

161
00:06:37,919 --> 00:06:39,440
this encrypted map

162
00:06:39,440 --> 00:06:42,240
back to the researchers which with their

163
00:06:42,240 --> 00:06:43,680
decryption key

164
00:06:43,680 --> 00:06:48,400
can decrypt the map and see the result

165
00:06:48,400 --> 00:06:50,960
now we're going to look into more detail

166
00:06:50,960 --> 00:06:53,440
in these three steps

167
00:06:53,440 --> 00:06:55,759
first the data aggregation the core of

168
00:06:55,759 --> 00:06:59,039
the protocol where we built the heat map

169
00:06:59,039 --> 00:07:01,880
and this is essentially a vector matrix

170
00:07:01,880 --> 00:07:03,280
multiplication

171
00:07:03,280 --> 00:07:06,000
on the left you see the vector with the

172
00:07:06,000 --> 00:07:07,199
identities

173
00:07:07,199 --> 00:07:10,400
a 1 means this individual is infected as

174
00:07:10,400 --> 00:07:11,680
0 means

175
00:07:11,680 --> 00:07:14,479
it is not and then we have the so-called

176
00:07:14,479 --> 00:07:16,000
mobility matrix where

177
00:07:16,000 --> 00:07:20,160
you see in the columns the cell towers

178
00:07:20,160 --> 00:07:23,680
here one two and three and the numbers

179
00:07:23,680 --> 00:07:26,400
in there represent the time spent by

180
00:07:26,400 --> 00:07:27,440
example

181
00:07:27,440 --> 00:07:30,160
individual one and will 2 and it will

182
00:07:30,160 --> 00:07:30,800
free

183
00:07:30,800 --> 00:07:33,120
in those cell towers in this area of the

184
00:07:33,120 --> 00:07:36,000
cell tower account

185
00:07:36,000 --> 00:07:39,360
and the aggregation of the mobility data

186
00:07:39,360 --> 00:07:41,919
of all the infected people is then just

187
00:07:41,919 --> 00:07:44,400
this multiplication

188
00:07:44,400 --> 00:07:46,560
and i've highlighted this here for the

189
00:07:46,560 --> 00:07:47,840
first cell tower

190
00:07:47,840 --> 00:07:50,000
so we've we multiply this vector with

191
00:07:50,000 --> 00:07:51,039
this column

192
00:07:51,039 --> 00:07:53,520
you see we count in the first and the

193
00:07:53,520 --> 00:07:54,400
last

194
00:07:54,400 --> 00:07:57,280
because the individual number two is not

195
00:07:57,280 --> 00:07:58,319
infected

196
00:07:58,319 --> 00:08:01,199
and we arrive at two plus one equals

197
00:08:01,199 --> 00:08:02,960
three

198
00:08:02,960 --> 00:08:06,878
and so on for all the cell types

199
00:08:07,199 --> 00:08:09,440
you can imagine that the dimensions of

200
00:08:09,440 --> 00:08:11,120
this matrix and vector get

201
00:08:11,120 --> 00:08:14,000
very huge if you look at hope about

202
00:08:14,000 --> 00:08:16,400
countries or cities

203
00:08:16,400 --> 00:08:19,520
note all those operations have to be

204
00:08:19,520 --> 00:08:22,560
performed with homomorphic encryption

205
00:08:22,560 --> 00:08:25,840
since this is very costly we are we're

206
00:08:25,840 --> 00:08:28,240
looking for an algorithm that perfectly

207
00:08:28,240 --> 00:08:28,720
fits

208
00:08:28,720 --> 00:08:30,960
our homomorphic encryption scheme and

209
00:08:30,960 --> 00:08:34,799
the packing methods for our ciphertext

210
00:08:34,799 --> 00:08:36,799
it turned out to be that the babystep

211
00:08:36,799 --> 00:08:39,440
giant step algorithm is the best fit

212
00:08:39,440 --> 00:08:42,479
for our protocol

213
00:08:42,640 --> 00:08:45,760
now let's have a look at the validation

214
00:08:45,760 --> 00:08:48,399
of the request

215
00:08:48,399 --> 00:08:50,880
in a high level we want to have that

216
00:08:50,880 --> 00:08:52,080
researchers

217
00:08:52,080 --> 00:08:54,880
that are malicious cannot get any

218
00:08:54,880 --> 00:08:57,200
information out of it

219
00:08:57,200 --> 00:08:59,200
and it is not that easy to detect

220
00:08:59,200 --> 00:09:00,880
malicious researchers

221
00:09:00,880 --> 00:09:03,440
because they only send us an encrypted

222
00:09:03,440 --> 00:09:04,399
vector

223
00:09:04,399 --> 00:09:06,320
so we have to look in this encrypted

224
00:09:06,320 --> 00:09:09,440
vector if the request was malicious

225
00:09:09,440 --> 00:09:12,160
or honest

226
00:09:12,720 --> 00:09:14,800
and since we cannot look into the cipher

227
00:09:14,800 --> 00:09:15,839
text

228
00:09:15,839 --> 00:09:18,080
we use some techniques that are known

229
00:09:18,080 --> 00:09:20,560
from bulletproofs

230
00:09:20,560 --> 00:09:22,800
on the higher level we want to have a

231
00:09:22,800 --> 00:09:24,000
mask so we want to

232
00:09:24,000 --> 00:09:27,600
add this mask to the result in the end

233
00:09:27,600 --> 00:09:30,320
and this mask should be zero if the

234
00:09:30,320 --> 00:09:32,000
researchers are honest

235
00:09:32,000 --> 00:09:35,040
and it should be random if the

236
00:09:35,040 --> 00:09:51,839
researchers were malicious

237
00:09:52,240 --> 00:09:56,240
since we are always computing modulus

238
00:09:56,240 --> 00:09:57,120
and integer

239
00:09:57,120 --> 00:09:59,839
this random answer doesn't give them any

240
00:09:59,839 --> 00:10:02,480
information

241
00:10:02,560 --> 00:10:05,200
in a more detailed way we are computing

242
00:10:05,200 --> 00:10:06,640
two masks

243
00:10:06,640 --> 00:10:09,200
first we ensure that the vector that the

244
00:10:09,200 --> 00:10:10,720
researchers are sending

245
00:10:10,720 --> 00:10:13,760
is binary and second that it has a

246
00:10:13,760 --> 00:10:16,000
certain amount of hemming weight

247
00:10:16,000 --> 00:10:19,920
here it is w and the two parties can

248
00:10:19,920 --> 00:10:20,880
agree which

249
00:10:20,880 --> 00:10:24,399
value this w should be

250
00:10:24,959 --> 00:10:27,279
and then we combine those to mask to one

251
00:10:27,279 --> 00:10:29,279
mask

252
00:10:29,279 --> 00:10:32,399
with more sophisticated methods we were

253
00:10:32,399 --> 00:10:33,360
able

254
00:10:33,360 --> 00:10:36,720
to have a soundness of up to

255
00:10:36,720 --> 00:10:38,959
two

256
00:10:45,120 --> 00:10:47,920
with more sophisticated methods we were

257
00:10:47,920 --> 00:10:49,040
able

258
00:10:49,040 --> 00:10:52,160
to have a statistical security of

259
00:10:52,160 --> 00:10:55,360
2 to the minus 58

260
00:10:55,360 --> 00:11:00,640
which is considered to be very secure

261
00:11:00,640 --> 00:11:03,200
the last step of the mobile network

262
00:11:03,200 --> 00:11:04,320
operator

263
00:11:04,320 --> 00:11:07,279
is to add the noise to define to the

264
00:11:07,279 --> 00:11:08,160
outcome of

265
00:11:08,160 --> 00:11:11,760
the data aggregation because

266
00:11:11,760 --> 00:11:13,839
data aggregation doesn't always

267
00:11:13,839 --> 00:11:16,160
translates to privacy and since we are

268
00:11:16,160 --> 00:11:18,720
talking about very sensitive data

269
00:11:18,720 --> 00:11:21,040
we have to have some mathematical

270
00:11:21,040 --> 00:11:22,399
guarantees in form

271
00:11:22,399 --> 00:11:26,079
of differential privacy

272
00:11:26,079 --> 00:11:28,240
the noise is produced by a lapras

273
00:11:28,240 --> 00:11:29,519
distribution

274
00:11:29,519 --> 00:11:31,920
which is a very narrow distribution

275
00:11:31,920 --> 00:11:32,720
centered around

276
00:11:32,720 --> 00:11:36,560
zero and of course it's symmetric

277
00:11:36,560 --> 00:11:38,959
we can we have this privacy parameter

278
00:11:38,959 --> 00:11:40,079
epsilon

279
00:11:40,079 --> 00:11:43,200
and the larger this epsilon the less

280
00:11:43,200 --> 00:11:44,640
noise we add

281
00:11:44,640 --> 00:11:48,880
and therefore the less privacy we have

282
00:11:48,880 --> 00:11:51,120
there is no general way to find a good

283
00:11:51,120 --> 00:11:53,200
value of this epsilon

284
00:11:53,200 --> 00:11:56,639
so we conducted our own privacy utility

285
00:11:56,639 --> 00:11:59,279
trade-offs

286
00:11:59,360 --> 00:12:03,120
and we did this on a concrete data set

287
00:12:03,120 --> 00:12:05,920
that was public with geolocation

288
00:12:05,920 --> 00:12:07,519
information

289
00:12:07,519 --> 00:12:11,200
and we simulated that some of these

290
00:12:11,200 --> 00:12:14,079
individuals are infected and on the left

291
00:12:14,079 --> 00:12:15,920
upper corner you can see the original

292
00:12:15,920 --> 00:12:16,720
map without

293
00:12:16,720 --> 00:12:19,600
any noise and then we add a lot of noise

294
00:12:19,600 --> 00:12:22,800
in the right upper corner

295
00:12:22,839 --> 00:12:26,399
so and you can see the problem here

296
00:12:26,399 --> 00:12:29,040
we have hotspots that weren't there

297
00:12:29,040 --> 00:12:29,760
before

298
00:12:29,760 --> 00:12:32,800
so the utility

299
00:12:32,800 --> 00:12:35,920
isn't there and

300
00:12:35,920 --> 00:12:39,360
if you look at 0.2 and 0.4

301
00:12:39,360 --> 00:12:41,440
you see that they are quite similar to

302
00:12:41,440 --> 00:12:42,720
the original map

303
00:12:42,720 --> 00:12:46,320
but still there are some changes and so

304
00:12:46,320 --> 00:12:49,360
we can argue with the data that

305
00:12:49,360 --> 00:12:51,920
in this case this re-identification is

306
00:12:51,920 --> 00:12:53,200
very unlikely

307
00:12:53,200 --> 00:12:57,120
but the utility is still there

308
00:12:58,000 --> 00:13:00,800
since we are using a lot of new privacy

309
00:13:00,800 --> 00:13:02,880
enhancing technologies

310
00:13:02,880 --> 00:13:05,519
we also did a leading analysis of our

311
00:13:05,519 --> 00:13:06,959
protocol

312
00:13:06,959 --> 00:13:09,279
and we choose to do this with regards to

313
00:13:09,279 --> 00:13:10,240
the gdpr

314
00:13:10,240 --> 00:13:13,519
so the eu privacy regulation

315
00:13:13,519 --> 00:13:15,279
because it's considered to be very

316
00:13:15,279 --> 00:13:18,000
restrictive

317
00:13:18,079 --> 00:13:20,160
and this multi-page analyze i want to

318
00:13:20,160 --> 00:13:21,920
break down for you into

319
00:13:21,920 --> 00:13:25,600
one slide and the first argumentation

320
00:13:25,600 --> 00:13:28,240
for the patient's

321
00:13:28,240 --> 00:13:31,519
data is that if you encrypt

322
00:13:31,519 --> 00:13:34,240
data and you do not give away the

323
00:13:34,240 --> 00:13:35,680
decryption key

324
00:13:35,680 --> 00:13:38,000
then this data can be considered

325
00:13:38,000 --> 00:13:40,480
anonymized

326
00:13:40,480 --> 00:13:44,000
and once we have done this step

327
00:13:44,000 --> 00:13:46,560
it is clear that under the gdpr this

328
00:13:46,560 --> 00:13:47,040
isn't

329
00:13:47,040 --> 00:13:49,120
to be considered anymore as personal

330
00:13:49,120 --> 00:13:51,519
data and that makes things a lot more

331
00:13:51,519 --> 00:13:54,800
easy second

332
00:13:54,800 --> 00:13:56,880
we're talking about the mobility data

333
00:13:56,880 --> 00:13:59,040
and we protect it by adding the noise

334
00:13:59,040 --> 00:14:01,680
so the differential privacy framework

335
00:14:01,680 --> 00:14:02,079
and

336
00:14:02,079 --> 00:14:05,680
because it is considered to be good

337
00:14:05,680 --> 00:14:06,480
practice

338
00:14:06,480 --> 00:14:08,880
in the gdpr we also have orthogonal

339
00:14:08,880 --> 00:14:10,800
technical measures

340
00:14:10,800 --> 00:14:14,160
for example only limiting the number of

341
00:14:14,160 --> 00:14:15,040
queries

342
00:14:15,040 --> 00:14:18,800
or restricting the area

343
00:14:18,880 --> 00:14:20,519
and therefore the risk of

344
00:14:20,519 --> 00:14:21,920
de-identification

345
00:14:21,920 --> 00:14:25,920
is highly unlikely and that's what

346
00:14:25,920 --> 00:14:29,680
most of opinions of the gdpr

347
00:14:29,680 --> 00:14:33,920
c as enough so far we have been seeing

348
00:14:33,920 --> 00:14:36,880
how the protocol works and that is

349
00:14:36,880 --> 00:14:37,839
compatible

350
00:14:37,839 --> 00:14:42,000
with the gdpr but usually these privacy

351
00:14:42,000 --> 00:14:43,519
enhancing technologies

352
00:14:43,519 --> 00:14:47,040
come with extreme overhead

353
00:14:47,040 --> 00:14:50,079
in performance so is this even fee

354
00:14:50,079 --> 00:14:51,600
stable or affordable

355
00:14:51,600 --> 00:14:55,440
for whole countries and the answer is

356
00:14:55,440 --> 00:14:56,240
yes

357
00:14:56,240 --> 00:14:59,079
it took us less than two hours or

358
00:14:59,079 --> 00:15:00,639
equivalently

359
00:15:00,639 --> 00:15:03,839
ten dollars on aws to perform our

360
00:15:03,839 --> 00:15:05,600
protocol

361
00:15:05,600 --> 00:15:09,120
for small countries like austria

362
00:15:09,120 --> 00:15:11,600
or big cities like singapore and new

363
00:15:11,600 --> 00:15:13,360
york city

364
00:15:13,360 --> 00:15:15,519
we achieved this by using a highly

365
00:15:15,519 --> 00:15:18,480
optimized c-blasplus implementation

366
00:15:18,480 --> 00:15:20,800
using microsoft trommorphic encryption

367
00:15:20,800 --> 00:15:22,800
library c

368
00:15:22,800 --> 00:15:25,600
the benchmarks were conducted on aws

369
00:15:25,600 --> 00:15:27,680
with 96 fret

370
00:15:27,680 --> 00:15:30,720
and we had around 1 gigabyte of data

371
00:15:30,720 --> 00:15:32,000
communication

372
00:15:32,000 --> 00:15:34,240
since the protocol scales linearly in

373
00:15:34,240 --> 00:15:36,959
the dimension of the mobility matrix

374
00:15:36,959 --> 00:15:39,199
it can also be done efficiently for

375
00:15:39,199 --> 00:15:41,759
larger countries

376
00:15:41,759 --> 00:15:44,720
as a last point i want to tell you about

377
00:15:44,720 --> 00:15:46,800
the security and privacy guarantees from

378
00:15:46,800 --> 00:15:48,800
our protocol

379
00:15:48,800 --> 00:15:52,480
we have done a security proof and

380
00:15:52,480 --> 00:15:55,519
i want to highlight the main result so

381
00:15:55,519 --> 00:15:57,199
from the homomorphic encryption scheme

382
00:15:57,199 --> 00:15:58,560
if this is secure

383
00:15:58,560 --> 00:16:01,040
we directly get semi-honest security for

384
00:16:01,040 --> 00:16:02,880
our protocol

385
00:16:02,880 --> 00:16:05,600
but then we ask is semi-honest security

386
00:16:05,600 --> 00:16:07,279
enough for medical records

387
00:16:07,279 --> 00:16:12,160
and location data and we do not think so

388
00:16:12,160 --> 00:16:14,720
therefore we worked on our protocol and

389
00:16:14,720 --> 00:16:16,480
can in the end show

390
00:16:16,480 --> 00:16:20,480
that the medical records are protected

391
00:16:20,480 --> 00:16:22,560
so they are private against malicious

392
00:16:22,560 --> 00:16:24,000
adversaries

393
00:16:24,000 --> 00:16:26,079
so whatever the mobile network operator

394
00:16:26,079 --> 00:16:28,480
does he cannot get out who is sick and

395
00:16:28,480 --> 00:16:30,959
who is not

396
00:16:30,959 --> 00:16:33,279
and the location data is protected by

397
00:16:33,279 --> 00:16:35,279
this differential privacy

398
00:16:35,279 --> 00:16:37,920
against malicious researchers so even if

399
00:16:37,920 --> 00:16:39,759
they deviate from the protocol the

400
00:16:39,759 --> 00:16:40,880
researchers

401
00:16:40,880 --> 00:16:43,680
they cannot sing out persons or

402
00:16:43,680 --> 00:16:47,439
individuals that were infected

403
00:16:48,560 --> 00:16:52,240
even though this protocol is

404
00:16:52,240 --> 00:16:55,680
very specific the idea of our work was

405
00:16:55,680 --> 00:16:58,560
to convey the following message

406
00:16:58,560 --> 00:17:02,040
that even in times of crisis where it is

407
00:17:02,040 --> 00:17:03,519
temperating to

408
00:17:03,519 --> 00:17:06,160
maybe temporarily lower data protection

409
00:17:06,160 --> 00:17:07,359
standards

410
00:17:07,359 --> 00:17:10,959
for purposes like big data analytics

411
00:17:10,959 --> 00:17:13,839
there are technical methods to keep data

412
00:17:13,839 --> 00:17:16,400
protection standards high

413
00:17:16,400 --> 00:17:18,799
and those technical methods are

414
00:17:18,799 --> 00:17:19,760
practical

415
00:17:19,760 --> 00:17:24,400
and available right now

