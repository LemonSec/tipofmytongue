1
00:00:01,439 --> 00:00:02,560
hello

2
00:00:02,560 --> 00:00:04,160
in this video i will present the work

3
00:00:04,160 --> 00:00:05,759
working mask implementation with many

4
00:00:05,759 --> 00:00:07,919
share on 32-bit platforms or when the

5
00:00:07,919 --> 00:00:10,000
security order doesn't matter

6
00:00:10,000 --> 00:00:12,080
this is a drone work by myself olivier

7
00:00:12,080 --> 00:00:14,160
bronson and my supervisor francoise

8
00:00:14,160 --> 00:00:17,160
standard

9
00:00:18,480 --> 00:00:20,880
so how to design sidechain security with

10
00:00:20,880 --> 00:00:22,720
masking

11
00:00:22,720 --> 00:00:23,680
to

12
00:00:23,680 --> 00:00:25,599
obtain a secure implementation with

13
00:00:25,599 --> 00:00:27,680
masking the design goes in two steps the

14
00:00:27,680 --> 00:00:30,640
first one is to leverage proof in an

15
00:00:30,640 --> 00:00:33,520
abstract model such as random probing or

16
00:00:33,520 --> 00:00:36,719
threshold problem security and once we

17
00:00:36,719 --> 00:00:38,640
have implementation secure in this

18
00:00:38,640 --> 00:00:41,920
abstract model we leverage reductions to

19
00:00:41,920 --> 00:00:44,559
obtain security in noises with noisy

20
00:00:44,559 --> 00:00:48,399
leakage which is closest to the reality

21
00:00:48,480 --> 00:00:51,039
if done that way the attack complexity

22
00:00:51,039 --> 00:00:53,199
can be defined by that so on the last

23
00:00:53,199 --> 00:00:55,600
you have n which is the data complexity

24
00:00:55,600 --> 00:00:58,399
and on the right right sorry

25
00:00:58,399 --> 00:01:00,000
you have

26
00:01:00,000 --> 00:01:02,800
mi which is the information that the

27
00:01:02,800 --> 00:01:05,199
adversary can obtain

28
00:01:05,199 --> 00:01:07,280
on the share from the leakage and d

29
00:01:07,280 --> 00:01:09,600
which is the number of shares

30
00:01:09,600 --> 00:01:11,280
and you see that

31
00:01:11,280 --> 00:01:13,040
the

32
00:01:13,040 --> 00:01:15,439
data complexity increases exponentially

33
00:01:15,439 --> 00:01:17,360
with the number of shares

34
00:01:17,360 --> 00:01:21,200
to have that equation the right two

35
00:01:21,200 --> 00:01:23,200
conditions must be fulfilled

36
00:01:23,200 --> 00:01:24,880
the first one is that all the shares

37
00:01:24,880 --> 00:01:27,200
looks independent and this ensures that

38
00:01:27,200 --> 00:01:28,479
the day d

39
00:01:28,479 --> 00:01:31,280
will be the one that's expected

40
00:01:31,280 --> 00:01:33,360
and the second condition is the noise

41
00:01:33,360 --> 00:01:35,280
condition which is

42
00:01:35,280 --> 00:01:37,119
which requires that the mutual

43
00:01:37,119 --> 00:01:39,360
information between the leakage and the

44
00:01:39,360 --> 00:01:41,439
shares

45
00:01:41,439 --> 00:01:45,360
is small enough to be amplified

46
00:01:45,840 --> 00:01:48,159
this seems simple but there is a lot of

47
00:01:48,159 --> 00:01:50,000
challenges when designing secure

48
00:01:50,000 --> 00:01:53,439
implementation so the first one is that

49
00:01:53,439 --> 00:01:55,759
an implementation i mean masking teams

50
00:01:55,759 --> 00:01:58,320
depends on the platform so either we are

51
00:01:58,320 --> 00:02:00,479
running on software on hardware and

52
00:02:00,479 --> 00:02:02,240
there is a large design space to choose

53
00:02:02,240 --> 00:02:04,719
the masking stream maybe

54
00:02:04,719 --> 00:02:06,479
it depends on the cost of randomness

55
00:02:06,479 --> 00:02:09,038
what's the best choice and the designer

56
00:02:09,038 --> 00:02:12,000
attempts to optimize

57
00:02:12,000 --> 00:02:14,239
the

58
00:02:14,480 --> 00:02:16,080
design choices

59
00:02:16,080 --> 00:02:18,319
in regarding to the cost versus

60
00:02:18,319 --> 00:02:19,760
performance

61
00:02:19,760 --> 00:02:21,760
trade-offs

62
00:02:21,760 --> 00:02:23,040
so this paper

63
00:02:23,040 --> 00:02:25,040
tackle takes the

64
00:02:25,040 --> 00:02:27,200
problem of security evaluation

65
00:02:27,200 --> 00:02:29,680
um and here we will show timelines of

66
00:02:29,680 --> 00:02:30,640
the

67
00:02:30,640 --> 00:02:31,840
the

68
00:02:31,840 --> 00:02:33,599
of essential implementation where on the

69
00:02:33,599 --> 00:02:36,319
x-axis of the time and on the y-axis you

70
00:02:36,319 --> 00:02:40,000
have the best current attack

71
00:02:40,000 --> 00:02:43,040
so first when there is a product

72
00:02:43,040 --> 00:02:44,640
of of course

73
00:02:44,640 --> 00:02:46,400
there is some attacks

74
00:02:46,400 --> 00:02:47,840
that you call state-of-the-art attacks

75
00:02:47,840 --> 00:02:49,120
or setup

76
00:02:49,120 --> 00:02:51,440
and they improve this time so the best

77
00:02:51,440 --> 00:02:53,760
attack data complexity decreases with

78
00:02:53,760 --> 00:02:55,360
time

79
00:02:55,360 --> 00:02:58,640
and at some point one has to to deploy

80
00:02:58,640 --> 00:03:00,560
the implementation and

81
00:03:00,560 --> 00:03:02,400
say no it's in the wild i cannot touch

82
00:03:02,400 --> 00:03:04,400
it anymore

83
00:03:04,400 --> 00:03:06,159
and at that time you would like to know

84
00:03:06,159 --> 00:03:08,560
what's the current resistance of your

85
00:03:08,560 --> 00:03:10,560
your target

86
00:03:10,560 --> 00:03:14,400
but with time attack still improves

87
00:03:14,400 --> 00:03:16,720
the goal of these papers is to to

88
00:03:16,720 --> 00:03:18,720
propose worst case attacks or worst case

89
00:03:18,720 --> 00:03:20,720
evaluation and the goal of that is to

90
00:03:20,720 --> 00:03:22,959
anticipate future improvement of state

91
00:03:22,959 --> 00:03:25,519
of the art

92
00:03:25,599 --> 00:03:27,200
how do we do that so what are the

93
00:03:27,200 --> 00:03:28,720
ingredients

94
00:03:28,720 --> 00:03:31,200
basically gives full knowledge to the

95
00:03:31,200 --> 00:03:33,280
evaluator during profiling

96
00:03:33,280 --> 00:03:35,040
during profiling the evaluator has

97
00:03:35,040 --> 00:03:36,239
access to

98
00:03:36,239 --> 00:03:37,680
to the source code

99
00:03:37,680 --> 00:03:39,360
to the randomness that is used for

100
00:03:39,360 --> 00:03:41,360
masking so what are the shares what are

101
00:03:41,360 --> 00:03:42,959
the inputs what is the plaintext what's

102
00:03:42,959 --> 00:03:45,040
the key

103
00:03:45,040 --> 00:03:47,599
yes so he also has the opportunity to

104
00:03:47,599 --> 00:03:48,959
have a

105
00:03:48,959 --> 00:03:50,799
measurement setup that is as clean as

106
00:03:50,799 --> 00:03:52,959
possible

107
00:03:52,959 --> 00:03:56,560
and he has to have a

108
00:03:56,560 --> 00:03:58,159
efficient technique to exploit or

109
00:03:58,159 --> 00:04:01,280
information within the leakage

110
00:04:01,280 --> 00:04:03,280
so why do we need

111
00:04:03,280 --> 00:04:05,280
randomness during profiling basically it

112
00:04:05,280 --> 00:04:09,040
allows to simplify the profiling stage

113
00:04:09,040 --> 00:04:12,560
and it allows also to give

114
00:04:13,200 --> 00:04:15,120
a good interpretation of the attack

115
00:04:15,120 --> 00:04:16,798
results and that's what we do in the

116
00:04:16,798 --> 00:04:17,918
paper

117
00:04:17,918 --> 00:04:19,120
and it also

118
00:04:19,120 --> 00:04:21,279
enables to to give clear guidelines to

119
00:04:21,279 --> 00:04:22,720
the evaluator

120
00:04:22,720 --> 00:04:24,080
because

121
00:04:24,080 --> 00:04:26,080
we can we are able to understand what

122
00:04:26,080 --> 00:04:28,080
are the weaknesses of the target we can

123
00:04:28,080 --> 00:04:30,160
say to a designer okay this is the issue

124
00:04:30,160 --> 00:04:31,520
and that's what you should fix to reset

125
00:04:31,520 --> 00:04:33,680
your implementation

126
00:04:33,680 --> 00:04:36,320
so of course if we are back to our

127
00:04:36,320 --> 00:04:37,759
to the previous

128
00:04:37,759 --> 00:04:39,840
figure from the previous slide in a

129
00:04:39,840 --> 00:04:41,280
short term there is probably a gap

130
00:04:41,280 --> 00:04:43,759
between the best possible attack

131
00:04:43,759 --> 00:04:46,720
and the worst his attack evaluation but

132
00:04:46,720 --> 00:04:49,040
as attacking proves

133
00:04:49,040 --> 00:04:52,639
probably that this gap vanishes

134
00:04:52,639 --> 00:04:54,320
so what's in the paper

135
00:04:54,320 --> 00:04:57,520
in the paper we have

136
00:04:57,520 --> 00:05:00,080
we propose a new methodology to analyze

137
00:05:00,080 --> 00:05:03,840
um math bit slice software

138
00:05:03,840 --> 00:05:05,919
this methodology is really simple and

139
00:05:05,919 --> 00:05:08,160
it's based on gaussian templates and

140
00:05:08,160 --> 00:05:11,520
saska with dedicated factor graphs

141
00:05:11,520 --> 00:05:13,280
we apply the methodology to two

142
00:05:13,280 --> 00:05:14,880
implementations

143
00:05:14,880 --> 00:05:17,600
the first one is aes implementation

144
00:05:17,600 --> 00:05:19,840
following the guidelines of gudary and

145
00:05:19,840 --> 00:05:21,120
the river

146
00:05:21,120 --> 00:05:22,880
and the other one

147
00:05:22,880 --> 00:05:24,960
is for clyde which follows the same

148
00:05:24,960 --> 00:05:26,160
guidelines

149
00:05:26,160 --> 00:05:26,880
and

150
00:05:26,880 --> 00:05:30,639
has been used for the chess 2013 2020

151
00:05:30,639 --> 00:05:33,120
ctf

152
00:05:33,520 --> 00:05:35,759
these targets are anti-software are

153
00:05:35,759 --> 00:05:37,600
running on two

154
00:05:37,600 --> 00:05:40,080
low cost mcus that are cortex m0 and

155
00:05:40,080 --> 00:05:43,280
cortex m3 we use them because they are

156
00:05:43,280 --> 00:05:46,320
widely used by the lightweight

157
00:05:46,320 --> 00:05:49,520
crypto community for benchmark of

158
00:05:49,520 --> 00:05:52,479
this competition candidates and it puts

159
00:05:52,479 --> 00:05:53,520
forward

160
00:05:53,520 --> 00:05:54,639
that

161
00:05:54,639 --> 00:05:57,680
security on these devices is

162
00:05:57,680 --> 00:05:59,199
at least

163
00:05:59,199 --> 00:06:01,440
expected

164
00:06:01,440 --> 00:06:03,280
we also extrapolate the security of this

165
00:06:03,280 --> 00:06:05,680
implementation to large larger masking

166
00:06:05,680 --> 00:06:06,800
order

167
00:06:06,800 --> 00:06:08,160
and

168
00:06:08,160 --> 00:06:11,199
we also discuss the impact of additional

169
00:06:11,199 --> 00:06:13,759
contour measures

170
00:06:13,759 --> 00:06:16,880
now we will detail the methodology used

171
00:06:16,880 --> 00:06:18,160
for this work

172
00:06:18,160 --> 00:06:20,240
and to analyze

173
00:06:20,240 --> 00:06:22,479
masked software

174
00:06:22,479 --> 00:06:25,360
so the methodology is based on

175
00:06:25,360 --> 00:06:26,720
profile attacks

176
00:06:26,720 --> 00:06:28,800
which goes into phase so the first phase

177
00:06:28,800 --> 00:06:31,759
is profiling where there is a target and

178
00:06:31,759 --> 00:06:34,720
we provide the target with randomness

179
00:06:34,720 --> 00:06:37,759
plaintext and key

180
00:06:37,840 --> 00:06:40,720
the target to the target a scope is

181
00:06:40,720 --> 00:06:43,600
attached and which records the legit for

182
00:06:43,600 --> 00:06:44,720
each of the

183
00:06:44,720 --> 00:06:46,840
execution of the cryptographic

184
00:06:46,840 --> 00:06:48,639
primitives

185
00:06:48,639 --> 00:06:50,720
then

186
00:06:50,720 --> 00:06:52,400
because the operator knows the source

187
00:06:52,400 --> 00:06:54,639
code and knows the key the plaintext and

188
00:06:54,639 --> 00:06:56,000
the randomness

189
00:06:56,000 --> 00:06:57,759
he is able to derive all the

190
00:06:57,759 --> 00:06:59,919
intermediate variables or all the shares

191
00:06:59,919 --> 00:07:02,960
that are processed by the target

192
00:07:02,960 --> 00:07:05,199
based on these

193
00:07:05,199 --> 00:07:07,039
leakages and

194
00:07:07,039 --> 00:07:08,880
shares value

195
00:07:08,880 --> 00:07:11,039
the evaluator can build a model

196
00:07:11,039 --> 00:07:12,960
that maps

197
00:07:12,960 --> 00:07:14,880
for a given

198
00:07:14,880 --> 00:07:16,479
share value

199
00:07:16,479 --> 00:07:17,599
the leakage

200
00:07:17,599 --> 00:07:19,680
distribution

201
00:07:19,680 --> 00:07:22,080
the second step is the attack phase

202
00:07:22,080 --> 00:07:24,800
where once again we hit target

203
00:07:24,800 --> 00:07:27,280
with only a plaintext no more the key

204
00:07:27,280 --> 00:07:29,759
and no more randomness

205
00:07:29,759 --> 00:07:32,479
and once again to the to the target a

206
00:07:32,479 --> 00:07:34,400
scope is attached and it records

207
00:07:34,400 --> 00:07:36,560
leakages

208
00:07:36,560 --> 00:07:38,479
the second step is to derive

209
00:07:38,479 --> 00:07:41,280
probabilities for each of the shares

210
00:07:41,280 --> 00:07:42,319
value

211
00:07:42,319 --> 00:07:45,520
from the leakage by levering leveraging

212
00:07:45,520 --> 00:07:47,599
the the model builds during the

213
00:07:47,599 --> 00:07:49,520
profiling phase

214
00:07:49,520 --> 00:07:52,479
then with all these probabilities on all

215
00:07:52,479 --> 00:07:53,680
the shares

216
00:07:53,680 --> 00:07:55,520
the evaluator can

217
00:07:55,520 --> 00:07:57,599
run some computations that usually

218
00:07:57,599 --> 00:07:59,039
involves the fact that he knows the

219
00:07:59,039 --> 00:08:01,759
source code and knows how the target and

220
00:08:01,759 --> 00:08:04,000
all how all these variables are

221
00:08:04,000 --> 00:08:05,840
interacting with each other

222
00:08:05,840 --> 00:08:09,039
to output a key yes

223
00:08:09,039 --> 00:08:11,599
so the methodology is based on software

224
00:08:11,599 --> 00:08:13,919
on soft analytical sidechain attacks or

225
00:08:13,919 --> 00:08:15,440
saska

226
00:08:15,440 --> 00:08:17,680
and here we will take a small example of

227
00:08:17,680 --> 00:08:20,319
what saska in general

228
00:08:20,319 --> 00:08:21,120
so

229
00:08:21,120 --> 00:08:23,440
let's take the simple example where we

230
00:08:23,440 --> 00:08:26,639
have circuits c equals a plus b and d

231
00:08:26,639 --> 00:08:29,520
equals a times b and saskatchewan goes

232
00:08:29,520 --> 00:08:31,120
in in

233
00:08:31,120 --> 00:08:32,880
multiple steps

234
00:08:32,880 --> 00:08:35,919
so the first one is to build a graph

235
00:08:35,919 --> 00:08:38,159
where you have first variable so here

236
00:08:38,159 --> 00:08:41,360
say a b and d and operations that are

237
00:08:41,360 --> 00:08:43,599
addition and multiplications

238
00:08:43,599 --> 00:08:44,800
and then

239
00:08:44,800 --> 00:08:45,600
we

240
00:08:45,600 --> 00:08:48,800
we draw edges

241
00:08:49,120 --> 00:08:54,200
between the variables and the operations

242
00:08:54,560 --> 00:08:55,519
then

243
00:08:55,519 --> 00:08:57,680
from the probabilities obtained with the

244
00:08:57,680 --> 00:09:00,000
model in the the attack phase that we

245
00:09:00,000 --> 00:09:02,480
described in the previous slide

246
00:09:02,480 --> 00:09:03,360
we

247
00:09:03,360 --> 00:09:05,519
edit all the variables with their

248
00:09:05,519 --> 00:09:07,680
distribution

249
00:09:07,680 --> 00:09:09,120
and then we apply a message passing

250
00:09:09,120 --> 00:09:11,519
bools which basically

251
00:09:11,519 --> 00:09:14,640
involves passing messages from um

252
00:09:14,640 --> 00:09:16,720
operations to variables and then from

253
00:09:16,720 --> 00:09:18,959
variables to operation and it's an

254
00:09:18,959 --> 00:09:20,959
iterative processor repeat that many

255
00:09:20,959 --> 00:09:24,000
times so what are the limitations and

256
00:09:24,000 --> 00:09:26,399
the complexities involved in

257
00:09:26,399 --> 00:09:29,120
running saska

258
00:09:29,120 --> 00:09:30,160
first

259
00:09:30,160 --> 00:09:32,720
multiplication i mean the the message

260
00:09:32,720 --> 00:09:34,839
passing rules for multiplication is

261
00:09:34,839 --> 00:09:36,399
expensive

262
00:09:36,399 --> 00:09:39,279
indeed its complexity goes in 2 to the

263
00:09:39,279 --> 00:09:40,720
power 2b

264
00:09:40,720 --> 00:09:42,560
where b is the number of bits in the

265
00:09:42,560 --> 00:09:44,560
target variable so if you want to

266
00:09:44,560 --> 00:09:47,040
profile 8 bit values

267
00:09:47,040 --> 00:09:49,519
so b equals 8 then the complexity of

268
00:09:49,519 --> 00:09:52,800
multiplication is 2 to the 16.

269
00:09:52,800 --> 00:09:54,480
and additions

270
00:09:54,480 --> 00:09:56,480
it's less expensive because its

271
00:09:56,480 --> 00:09:59,839
complexity goes in b times 2b

272
00:09:59,839 --> 00:10:02,640
so saska is optimal way to up to

273
00:10:02,640 --> 00:10:05,760
recombine information if the graph is a

274
00:10:05,760 --> 00:10:08,160
tree meaning that there is no cycles

275
00:10:08,160 --> 00:10:10,079
if there is cycles in the

276
00:10:10,079 --> 00:10:12,880
the graph then

277
00:10:12,880 --> 00:10:13,920
this

278
00:10:13,920 --> 00:10:17,120
star scale becomes heuristic

279
00:10:17,120 --> 00:10:19,920
so how do you apply that for masks

280
00:10:19,920 --> 00:10:23,040
software so let's take a simple

281
00:10:23,040 --> 00:10:24,720
unprotected circuits that we want to

282
00:10:24,720 --> 00:10:29,519
protect so we have a times b equals c

283
00:10:29,600 --> 00:10:31,680
the secure implementation looks to

284
00:10:31,680 --> 00:10:33,040
something like that where you have

285
00:10:33,040 --> 00:10:34,079
shares

286
00:10:34,079 --> 00:10:38,720
of a which are a0 a1 charts of b b0 b1

287
00:10:38,720 --> 00:10:41,040
shares of c c0 c1

288
00:10:41,040 --> 00:10:43,279
and

289
00:10:43,360 --> 00:10:44,880
secure multiplication so the

290
00:10:44,880 --> 00:10:46,800
multiplication above is replaced by a

291
00:10:46,800 --> 00:10:49,200
secure multiplication let's say the isw

292
00:10:49,200 --> 00:10:51,839
multiplication that takes the shares as

293
00:10:51,839 --> 00:10:55,040
inputs and outputs

294
00:10:55,040 --> 00:10:57,440
the the shares of c

295
00:10:57,440 --> 00:10:58,480
and

296
00:10:58,480 --> 00:11:01,440
for this methodology we would like to

297
00:11:01,440 --> 00:11:03,600
keep the profiling and attack complexity

298
00:11:03,600 --> 00:11:06,240
we scaled gently with d and to reduce

299
00:11:06,240 --> 00:11:08,079
the heuristics

300
00:11:08,079 --> 00:11:10,079
a third solution to to reach that would

301
00:11:10,079 --> 00:11:11,760
be to

302
00:11:11,760 --> 00:11:14,800
build a photograph for the entire isw

303
00:11:14,800 --> 00:11:16,959
multiplication this may be a good idea

304
00:11:16,959 --> 00:11:19,440
but there is some some limitations but

305
00:11:19,440 --> 00:11:22,000
let's start with the advantage

306
00:11:22,000 --> 00:11:24,720
which is that it can possibly exploit

307
00:11:24,720 --> 00:11:26,640
all the

308
00:11:26,640 --> 00:11:29,839
old information

309
00:11:29,920 --> 00:11:32,399
from the leakage within these isw

310
00:11:32,399 --> 00:11:33,760
multiplications

311
00:11:33,760 --> 00:11:34,959
however

312
00:11:34,959 --> 00:11:36,560
the number of nodes

313
00:11:36,560 --> 00:11:38,640
number of variables processed by isw

314
00:11:38,640 --> 00:11:40,320
multiplication is quadratic with the

315
00:11:40,320 --> 00:11:42,399
number of shares

316
00:11:42,399 --> 00:11:44,560
and the number of multiplications is

317
00:11:44,560 --> 00:11:47,519
also quadratic which makes

318
00:11:47,519 --> 00:11:50,800
its computational cost

319
00:11:50,800 --> 00:11:55,040
expensive and not scaling gently with d

320
00:11:55,040 --> 00:11:57,440
additionally this

321
00:11:57,440 --> 00:12:00,000
the graph to represent isw

322
00:12:00,000 --> 00:12:02,880
multiplication contains a lot of

323
00:12:02,880 --> 00:12:05,439
cycles

324
00:12:05,839 --> 00:12:08,160
so what's the efficient methodology we

325
00:12:08,160 --> 00:12:10,560
propose it goes in two steps

326
00:12:10,560 --> 00:12:13,519
first for each of the secret variables

327
00:12:13,519 --> 00:12:15,440
so a b and c

328
00:12:15,440 --> 00:12:19,519
we build them from the from their shares

329
00:12:19,519 --> 00:12:21,600
so let's say here is a two share example

330
00:12:21,600 --> 00:12:24,480
we have a graph that will um

331
00:12:24,480 --> 00:12:27,920
that recom we have zero operations that

332
00:12:27,920 --> 00:12:31,120
recombine a1 and a2 to obtain a same

333
00:12:31,120 --> 00:12:34,560
goes for b0 and b1 at gif b and c once

334
00:12:34,560 --> 00:12:37,200
you enter dfc

335
00:12:37,200 --> 00:12:39,120
and this small graph we call them

336
00:12:39,120 --> 00:12:41,120
encoding graphs and there is one for all

337
00:12:41,120 --> 00:12:43,600
the secret variables

338
00:12:43,600 --> 00:12:45,440
the second step is to

339
00:12:45,440 --> 00:12:46,320
to

340
00:12:46,320 --> 00:12:48,160
link this

341
00:12:48,160 --> 00:12:51,680
secret variable so a b and c

342
00:12:51,680 --> 00:12:54,720
by operation by the operations

343
00:12:54,720 --> 00:12:56,880
which is here multiplication for example

344
00:12:56,880 --> 00:13:00,000
and this is called uh the unmask graph

345
00:13:00,000 --> 00:13:01,760
so what are the prime counts of this

346
00:13:01,760 --> 00:13:03,279
methodology

347
00:13:03,279 --> 00:13:06,560
first regarding the complexity it's

348
00:13:06,560 --> 00:13:09,040
quite nice because the number of

349
00:13:09,040 --> 00:13:11,040
variables to profiles remains linear

350
00:13:11,040 --> 00:13:13,839
with d because only the shares

351
00:13:13,839 --> 00:13:16,959
needs to be profiled

352
00:13:16,959 --> 00:13:18,399
i mean the shafts are the input and

353
00:13:18,399 --> 00:13:21,600
output of secure multiplications

354
00:13:21,600 --> 00:13:23,200
then the number of multiplication is

355
00:13:23,200 --> 00:13:24,399
also

356
00:13:24,399 --> 00:13:27,519
constant with the number of shares

357
00:13:27,519 --> 00:13:29,760
the anchoring graph contains the cycles

358
00:13:29,760 --> 00:13:32,639
meaning that information on a is

359
00:13:32,639 --> 00:13:35,839
obtained without any heuristics

360
00:13:35,839 --> 00:13:37,200
because

361
00:13:37,200 --> 00:13:39,600
the anchoring graph are trees

362
00:13:39,600 --> 00:13:41,360
and finally once again regarding

363
00:13:41,360 --> 00:13:44,079
complexities because

364
00:13:44,079 --> 00:13:46,240
evaluator can solve all the anchoring

365
00:13:46,240 --> 00:13:48,480
graphs independently

366
00:13:48,480 --> 00:13:51,360
it allows to to have some trade-off

367
00:13:51,360 --> 00:13:52,720
between

368
00:13:52,720 --> 00:13:55,199
i mean to have trade-offs not to not to

369
00:13:55,199 --> 00:13:58,880
load everything in memory at once

370
00:13:58,880 --> 00:14:00,720
the drawback is that

371
00:14:00,720 --> 00:14:03,839
with this methodology

372
00:14:04,959 --> 00:14:07,680
we cannot exploit lower order flows and

373
00:14:07,680 --> 00:14:11,439
that's what we call order preserving

374
00:14:11,760 --> 00:14:13,600
this methodology has been implemented

375
00:14:13,600 --> 00:14:14,480
with

376
00:14:14,480 --> 00:14:15,760
scalib

377
00:14:15,760 --> 00:14:17,440
which is a python library that we

378
00:14:17,440 --> 00:14:19,120
developed with my colleague

379
00:14:19,120 --> 00:14:21,440
guyton cassius

380
00:14:21,440 --> 00:14:23,440
so what is it it's a python package that

381
00:14:23,440 --> 00:14:25,120
you can install simply by running pip

382
00:14:25,120 --> 00:14:27,199
installs caliber

383
00:14:27,199 --> 00:14:28,880
there is multiple tools for search and

384
00:14:28,880 --> 00:14:31,120
analysis and it's optimized

385
00:14:31,120 --> 00:14:34,639
to run on a single or multiple threads

386
00:14:34,639 --> 00:14:36,880
in this project we use it

387
00:14:36,880 --> 00:14:39,440
to compute signal-to-noise ratio

388
00:14:39,440 --> 00:14:41,120
to model the leakage for each of the

389
00:14:41,120 --> 00:14:44,639
shares to run saska and to run a key

390
00:14:44,639 --> 00:14:47,360
enumeration

391
00:14:48,000 --> 00:14:50,160
so what are the concrete results

392
00:14:50,160 --> 00:14:53,600
of our methodology under investigated

393
00:14:53,600 --> 00:14:55,760
implementations

394
00:14:55,760 --> 00:14:58,480
so first we look at concrete attacks on

395
00:14:58,480 --> 00:15:01,839
this graph here you have on the x-axis

396
00:15:01,839 --> 00:15:04,320
the number of traces used by the

397
00:15:04,320 --> 00:15:06,639
adversary and on the y-axis you have the

398
00:15:06,639 --> 00:15:08,720
medium key rank

399
00:15:08,720 --> 00:15:10,560
which is the the remaining entropy of

400
00:15:10,560 --> 00:15:11,760
the key

401
00:15:11,760 --> 00:15:13,360
so we see that

402
00:15:13,360 --> 00:15:15,279
if you increase the number of shares

403
00:15:15,279 --> 00:15:17,760
from three to six here you also increase

404
00:15:17,760 --> 00:15:19,920
the the tata complexity n

405
00:15:19,920 --> 00:15:22,160
and here with nine traces you are able

406
00:15:22,160 --> 00:15:25,440
to break the six implementation of

407
00:15:25,440 --> 00:15:28,079
aes running on cortex m0

408
00:15:28,079 --> 00:15:30,959
if you move on a cortex m3 then things

409
00:15:30,959 --> 00:15:33,199
get better and with 2000 traces we are

410
00:15:33,199 --> 00:15:34,800
able to break

411
00:15:34,800 --> 00:15:36,720
five share implementation

412
00:15:36,720 --> 00:15:39,360
and then for a clyde and cortex m0 which

413
00:15:39,360 --> 00:15:42,240
is the chess 2020

414
00:15:42,240 --> 00:15:44,160
data set

415
00:15:44,160 --> 00:15:46,480
we are able to break his implementation

416
00:15:46,480 --> 00:15:48,720
with 12 000 traces

417
00:15:48,720 --> 00:15:51,440
so with these numbers we are able to

418
00:15:51,440 --> 00:15:54,720
extrapolate that so each of the concrete

419
00:15:54,720 --> 00:15:56,800
attacks from the previous slides is a

420
00:15:56,800 --> 00:15:59,199
bullet on this graph and because we know

421
00:15:59,199 --> 00:16:02,079
that the complexity of attacks

422
00:16:02,079 --> 00:16:04,959
is exponential with d we can extrapolate

423
00:16:04,959 --> 00:16:06,959
the trends

424
00:16:06,959 --> 00:16:08,800
what do we see and what do we have as

425
00:16:08,800 --> 00:16:10,399
conclusion there

426
00:16:10,399 --> 00:16:13,600
so first we observe that

427
00:16:13,600 --> 00:16:16,320
by comparing areas running on quarters 0

428
00:16:16,320 --> 00:16:19,519
and cortex m3 we see that cortex 0

429
00:16:19,519 --> 00:16:21,680
provides more information per share

430
00:16:21,680 --> 00:16:23,040
hence

431
00:16:23,040 --> 00:16:25,199
it requires more shares to be secure or

432
00:16:25,199 --> 00:16:26,880
for a fixed number of shares the

433
00:16:26,880 --> 00:16:30,959
security is lower on cortex m0

434
00:16:30,959 --> 00:16:33,440
then we can compare aes and clyde

435
00:16:33,440 --> 00:16:35,759
running on both on the same target your

436
00:16:35,759 --> 00:16:38,240
tax m0 and you observe that client

437
00:16:38,240 --> 00:16:40,639
provides a better security than the aes

438
00:16:40,639 --> 00:16:42,720
this is probably because clyde has a

439
00:16:42,720 --> 00:16:44,959
lightweight s-box that

440
00:16:44,959 --> 00:16:48,079
so requires not that much computation

441
00:16:48,079 --> 00:16:50,720
in the bit-like settings and

442
00:16:50,720 --> 00:16:53,360
this is because the client s box

443
00:16:53,360 --> 00:16:55,279
has been designed to be

444
00:16:55,279 --> 00:16:58,240
masking mask friendly

445
00:16:58,240 --> 00:17:00,320
overall you observe that

446
00:17:00,320 --> 00:17:02,480
in the best case so

447
00:17:02,480 --> 00:17:03,519
aes

448
00:17:03,519 --> 00:17:06,720
running on cortex m3 we need at least 16

449
00:17:06,720 --> 00:17:11,119
shares to reach 40-bit security

450
00:17:11,119 --> 00:17:13,520
what does all this implies for

451
00:17:13,520 --> 00:17:15,760
performances

452
00:17:15,760 --> 00:17:17,520
so here we look at clyde running on

453
00:17:17,520 --> 00:17:20,160
cortex zero and we look at security

454
00:17:20,160 --> 00:17:22,319
versus performances

455
00:17:22,319 --> 00:17:24,240
for the performances we take a recent

456
00:17:24,240 --> 00:17:26,079
paper by bellaire that i published at

457
00:17:26,079 --> 00:17:29,280
eurocup 2020.

458
00:17:29,360 --> 00:17:30,960
so we observed that

459
00:17:30,960 --> 00:17:33,840
if the designer targets 20-bit security

460
00:17:33,840 --> 00:17:34,559
so

461
00:17:34,559 --> 00:17:35,840
n equals

462
00:17:35,840 --> 00:17:38,960
2 to the power 20 then

463
00:17:38,960 --> 00:17:41,760
about 12 shots are needed

464
00:17:41,760 --> 00:17:43,120
we require

465
00:17:43,120 --> 00:17:45,360
i mean the throughput is about

466
00:17:45,360 --> 00:17:47,760
3 kilobytes per second

467
00:17:47,760 --> 00:17:51,440
then if the target is 30 bit of security

468
00:17:51,440 --> 00:17:53,679
then 18 shots are needed and the trophic

469
00:17:53,679 --> 00:17:55,120
is widened to

470
00:17:55,120 --> 00:17:57,919
k bytes per second and once again if you

471
00:17:57,919 --> 00:18:00,160
increase the security you want to wear

472
00:18:00,160 --> 00:18:03,440
so 40 bit of security here you need

473
00:18:03,440 --> 00:18:06,160
24 shares and the throughput still

474
00:18:06,160 --> 00:18:08,000
decreases

475
00:18:08,000 --> 00:18:10,000
yet we observe that

476
00:18:10,000 --> 00:18:11,600
by slightly

477
00:18:11,600 --> 00:18:12,799
paying

478
00:18:12,799 --> 00:18:14,559
additional cost

479
00:18:14,559 --> 00:18:16,400
in

480
00:18:16,400 --> 00:18:19,280
performances so between 20 and 40 bits

481
00:18:19,280 --> 00:18:20,640
of security there is more or less a

482
00:18:20,640 --> 00:18:22,799
factor four in performances

483
00:18:22,799 --> 00:18:24,720
you you get

484
00:18:24,720 --> 00:18:28,840
20 more bits of security

485
00:18:32,559 --> 00:18:34,960
so can what can we tell about masking on

486
00:18:34,960 --> 00:18:38,559
30-bit software and what should we do

487
00:18:38,559 --> 00:18:40,720
so first the main issue we observe is

488
00:18:40,720 --> 00:18:42,160
that there is a lack of noise on tv

489
00:18:42,160 --> 00:18:43,679
devices

490
00:18:43,679 --> 00:18:45,039
indeed

491
00:18:45,039 --> 00:18:47,200
this is not the big issue

492
00:18:47,200 --> 00:18:49,679
our attack is not able to exploit

493
00:18:49,679 --> 00:18:50,480
his

494
00:18:50,480 --> 00:18:51,840
weaknesses

495
00:18:51,840 --> 00:18:52,640
yet

496
00:18:52,640 --> 00:18:56,679
the attacks are quite efficient

497
00:18:56,799 --> 00:18:58,480
so the issue becomes from the other part

498
00:18:58,480 --> 00:19:02,400
of the equation which is mi that is the

499
00:19:02,400 --> 00:19:05,520
mi per share is too large this is

500
00:19:05,520 --> 00:19:07,600
illustrated with a graph

501
00:19:07,600 --> 00:19:08,799
on the left

502
00:19:08,799 --> 00:19:10,720
where on the x-axis you have the number

503
00:19:10,720 --> 00:19:13,039
of leaking points and on the y-axis you

504
00:19:13,039 --> 00:19:15,039
have the mutual information and we see

505
00:19:15,039 --> 00:19:16,640
that the meter information is quite

506
00:19:16,640 --> 00:19:18,240
large

507
00:19:18,240 --> 00:19:20,160
we also observe

508
00:19:20,160 --> 00:19:22,480
that the noise is mostly algorithmic

509
00:19:22,480 --> 00:19:25,520
meaning that the noise really depends on

510
00:19:25,520 --> 00:19:27,760
what you put in your registers what's

511
00:19:27,760 --> 00:19:30,000
the layout of the registers and what

512
00:19:30,000 --> 00:19:32,720
instruction you apply to them

513
00:19:32,720 --> 00:19:35,440
overall reducing this

514
00:19:35,440 --> 00:19:39,200
mi would lead to a significant

515
00:19:39,200 --> 00:19:42,480
gain in performances

516
00:19:43,200 --> 00:19:44,320
so

517
00:19:44,320 --> 00:19:46,480
the natural solution to anticipate all

518
00:19:46,480 --> 00:19:47,919
that is to take a general counter

519
00:19:47,919 --> 00:19:48,799
measure

520
00:19:48,799 --> 00:19:51,039
that's represented by a factor of gamma

521
00:19:51,039 --> 00:19:53,760
which reduces mi

522
00:19:53,760 --> 00:19:56,160
if we do that the data complexity

523
00:19:56,160 --> 00:19:58,080
becomes something like this where we

524
00:19:58,080 --> 00:20:01,120
have gamma that is raised to the power d

525
00:20:01,120 --> 00:20:03,840
thanks to masking

526
00:20:04,480 --> 00:20:06,720
so that parameter

527
00:20:06,720 --> 00:20:09,280
gamma allows to cover many contour

528
00:20:09,280 --> 00:20:11,360
measures that can be physical such as

529
00:20:11,360 --> 00:20:14,159
noise addition or algorithmic

530
00:20:14,159 --> 00:20:16,480
such as shuffling and based on this

531
00:20:16,480 --> 00:20:18,640
gamma we can define a quantitative

532
00:20:18,640 --> 00:20:19,760
target

533
00:20:19,760 --> 00:20:22,559
for their effectiveness

534
00:20:22,559 --> 00:20:24,880
and in the paper we present many of

535
00:20:24,880 --> 00:20:27,039
these graphs

536
00:20:27,039 --> 00:20:28,559
where on the d-axis you have the number

537
00:20:28,559 --> 00:20:30,400
of shares within your implementation on

538
00:20:30,400 --> 00:20:32,720
the y-axis you have the gamma and the

539
00:20:32,720 --> 00:20:35,840
color represents the the data complexity

540
00:20:35,840 --> 00:20:37,440
to the n

541
00:20:37,440 --> 00:20:40,080
why it means that n is very large so

542
00:20:40,080 --> 00:20:41,760
there is high security

543
00:20:41,760 --> 00:20:42,799
black

544
00:20:42,799 --> 00:20:45,120
means that n is low and

545
00:20:45,120 --> 00:20:48,240
so there is a low security so on this

546
00:20:48,240 --> 00:20:49,360
graph

547
00:20:49,360 --> 00:20:51,440
we can see that for a given security

548
00:20:51,440 --> 00:20:53,919
target if you are able to

549
00:20:53,919 --> 00:20:56,159
decrease mutual information per share by

550
00:20:56,159 --> 00:20:59,200
a given factor gamma then you need a

551
00:20:59,200 --> 00:21:03,039
given number of shares to fulfill

552
00:21:03,039 --> 00:21:04,559
your desired

553
00:21:04,559 --> 00:21:07,520
data complexity

554
00:21:10,080 --> 00:21:12,000
from all this

555
00:21:12,000 --> 00:21:14,080
now we will be back to our goal of

556
00:21:14,080 --> 00:21:16,799
estimating the worst case attack data

557
00:21:16,799 --> 00:21:18,799
complexity

558
00:21:18,799 --> 00:21:21,520
and a usual question is to know i mean

559
00:21:21,520 --> 00:21:24,240
what happens when you want to to profile

560
00:21:24,240 --> 00:21:25,760
on the device and attack on another

561
00:21:25,760 --> 00:21:28,799
device so how do we evaluate that

562
00:21:28,799 --> 00:21:31,360
we profile on the device i

563
00:21:31,360 --> 00:21:34,240
we evaluate mi with the with that model

564
00:21:34,240 --> 00:21:36,960
on divide g and then we estimate the

565
00:21:36,960 --> 00:21:38,080
loss or

566
00:21:38,080 --> 00:21:39,360
i mean

567
00:21:39,360 --> 00:21:41,760
the reduction of mutual information that

568
00:21:41,760 --> 00:21:43,039
it implies

569
00:21:43,039 --> 00:21:45,440
and so we have this kind of grid

570
00:21:45,440 --> 00:21:47,280
and we see that for some

571
00:21:47,280 --> 00:21:49,679
from some pairs there is a large loss

572
00:21:49,679 --> 00:21:51,440
but for others there is known

573
00:21:51,440 --> 00:21:56,159
i mean or a small one such as 0.9

574
00:21:56,240 --> 00:21:58,720
so for what does it implies for um side

575
00:21:58,720 --> 00:22:00,799
channel evaluation

576
00:22:00,799 --> 00:22:02,320
basically

577
00:22:02,320 --> 00:22:04,559
this uh the cross profiling is not

578
00:22:04,559 --> 00:22:06,799
provide any large or significant

579
00:22:06,799 --> 00:22:08,159
security gain

580
00:22:08,159 --> 00:22:09,760
indeed there is some pairs where the

581
00:22:09,760 --> 00:22:12,720
gamma is large and otherwise smaller

582
00:22:12,720 --> 00:22:15,520
and if you want to run evaluation on one

583
00:22:15,520 --> 00:22:16,480
device

584
00:22:16,480 --> 00:22:18,640
profiling on one device and attacking on

585
00:22:18,640 --> 00:22:20,000
another device

586
00:22:20,000 --> 00:22:22,240
you expose yourself to a risk of false

587
00:22:22,240 --> 00:22:25,280
sense of security as example you could

588
00:22:25,280 --> 00:22:28,000
be profiling on one pair

589
00:22:28,000 --> 00:22:30,480
where gamma is very low and maybe

590
00:22:30,480 --> 00:22:32,880
adversarial there was where gamma is

591
00:22:32,880 --> 00:22:35,280
very high

592
00:22:35,280 --> 00:22:37,840
so overall evaluator should profile an

593
00:22:37,840 --> 00:22:39,840
attack on the same device to avoid these

594
00:22:39,840 --> 00:22:42,000
risks

595
00:22:42,000 --> 00:22:44,400
now let's jump to the conclusion

596
00:22:44,400 --> 00:22:46,080
so what are the takeaways of this

597
00:22:46,080 --> 00:22:49,520
presentation of this work

598
00:22:49,760 --> 00:22:51,200
we've been presenting an efficient

599
00:22:51,200 --> 00:22:53,679
methodology to attack or evaluate mass

600
00:22:53,679 --> 00:22:55,600
implementation we've been putting

601
00:22:55,600 --> 00:22:58,400
forward that the main issue for

602
00:22:58,400 --> 00:23:00,720
protecting this locus mcu is the lack of

603
00:23:00,720 --> 00:23:02,880
noise

604
00:23:02,880 --> 00:23:03,760
and

605
00:23:03,760 --> 00:23:06,240
you require a large number of shares to

606
00:23:06,240 --> 00:23:08,640
protect this device one solution would

607
00:23:08,640 --> 00:23:11,760
be to reduce the number of operations

608
00:23:11,760 --> 00:23:14,400
that need to be masked by leveraging a

609
00:23:14,400 --> 00:23:15,600
dedicated

610
00:23:15,600 --> 00:23:17,280
mode of operation

611
00:23:17,280 --> 00:23:19,840
and with this work we also present

612
00:23:19,840 --> 00:23:21,200
scalif

613
00:23:21,200 --> 00:23:23,919
which is a python toolbox

614
00:23:23,919 --> 00:23:25,919
that contains a lot of optimized tools

615
00:23:25,919 --> 00:23:28,400
for such an analysis

616
00:23:28,400 --> 00:23:30,640
so thanks for listening there is some

617
00:23:30,640 --> 00:23:33,840
useful links and one related work that

618
00:23:33,840 --> 00:23:35,919
exploit the same methodology and apply

619
00:23:35,919 --> 00:23:40,919
to the well-known ascad dataset

