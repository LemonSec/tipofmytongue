1
00:00:01,920 --> 00:00:03,919
hello everybody i'm hal i'm going to

2
00:00:03,919 --> 00:00:05,920
present our paper entitled faction

3
00:00:05,920 --> 00:00:09,440
seaside group actions using fx512

4
00:00:09,440 --> 00:00:11,519
this is joint work with george's rohan

5
00:00:11,519 --> 00:00:14,160
peter and peter

6
00:00:14,160 --> 00:00:15,759
commutative super singularized soldering

7
00:00:15,759 --> 00:00:18,240
tv helmet or seaside for short is a

8
00:00:18,240 --> 00:00:20,080
recently proposed post quantum key

9
00:00:20,080 --> 00:00:22,240
establishment scheme that belongs to the

10
00:00:22,240 --> 00:00:23,680
family of five surging based crypto

11
00:00:23,680 --> 00:00:24,720
systems

12
00:00:24,720 --> 00:00:26,560
it comes with highly attractive features

13
00:00:26,560 --> 00:00:29,119
like efficient validation of public keys

14
00:00:29,119 --> 00:00:31,199
making it suitable for non-interactive

15
00:00:31,199 --> 00:00:32,880
key exchange protocols

16
00:00:32,880 --> 00:00:35,440
in fact seaside has ability to serve as

17
00:00:35,440 --> 00:00:37,680
drop-in post-quantum replacement for the

18
00:00:37,680 --> 00:00:40,480
classical sdh key exchange

19
00:00:40,480 --> 00:00:42,559
the csi protocol is based on the action

20
00:00:42,559 --> 00:00:44,800
of an ideal class group on a set of

21
00:00:44,800 --> 00:00:46,640
super singularity curves

22
00:00:46,640 --> 00:00:48,559
unfortunately the execution time of

23
00:00:48,559 --> 00:00:50,480
seaside is prohibitively high for many

24
00:00:50,480 --> 00:00:52,320
real-world applications mainly due to

25
00:00:52,320 --> 00:00:54,399
the enormous computational cost of the

26
00:00:54,399 --> 00:00:56,160
underlying group action

27
00:00:56,160 --> 00:00:58,399
in this work we explore how to use the

28
00:00:58,399 --> 00:01:00,320
powerful vector instructions like intel

29
00:01:00,320 --> 00:01:02,960
fx 512 to accelerate the computation of

30
00:01:02,960 --> 00:01:06,159
the seaside group action

31
00:01:06,880 --> 00:01:08,880
the seaside reaction works over a finite

32
00:01:08,880 --> 00:01:11,439
field fp where p is a large prime of the

33
00:01:11,439 --> 00:01:13,680
special form of four times some small

34
00:01:13,680 --> 00:01:15,759
old primes and minus one

35
00:01:15,759 --> 00:01:18,479
it uses super singularity curves e a

36
00:01:18,479 --> 00:01:20,640
which are defined over this prime field

37
00:01:20,640 --> 00:01:23,439
and represented in montgomery form

38
00:01:23,439 --> 00:01:25,600
in c side we are interested in computing

39
00:01:25,600 --> 00:01:28,640
the action by an ideo where l i are

40
00:01:28,640 --> 00:01:31,520
prime ideals and e i are small exponents

41
00:01:31,520 --> 00:01:34,079
chosen uniformly from some interval

42
00:01:34,079 --> 00:01:36,240
the season equation equals to the

43
00:01:36,240 --> 00:01:38,320
computation of the curve e prime as

44
00:01:38,320 --> 00:01:40,000
image of the curve e and their

45
00:01:40,000 --> 00:01:42,640
uncertainty of degree l1 to e1 times

46
00:01:42,640 --> 00:01:43,680
until

47
00:01:43,680 --> 00:01:46,640
the ln to en

48
00:01:47,040 --> 00:01:49,040
the entire isolating computation can

49
00:01:49,040 --> 00:01:50,960
break into many smaller absorption

50
00:01:50,960 --> 00:01:52,720
competitions and each encoding is

51
00:01:52,720 --> 00:01:56,560
computed by using battle formula

52
00:01:57,360 --> 00:01:59,680
as for the season key exchange protocol

53
00:01:59,680 --> 00:02:01,600
alice and bob first generate their

54
00:02:01,600 --> 00:02:04,159
private key which are secret exponents

55
00:02:04,159 --> 00:02:06,320
and then they generate their pop key by

56
00:02:06,320 --> 00:02:07,920
the seaside protection with their

57
00:02:07,920 --> 00:02:10,080
private key and the starting curve

58
00:02:10,080 --> 00:02:12,400
alice sends her public key and a little

59
00:02:12,400 --> 00:02:15,280
curvy a to p to bob and bob will send

60
00:02:15,280 --> 00:02:17,680
back his public key eb

61
00:02:17,680 --> 00:02:19,520
alice and bob will then check whether

62
00:02:19,520 --> 00:02:20,959
the public key that they reserve is

63
00:02:20,959 --> 00:02:23,520
valid or not so if it is valid then they

64
00:02:23,520 --> 00:02:26,239
will compute the shared secret ka and kb

65
00:02:26,239 --> 00:02:27,760
by using the seaside group action as

66
00:02:27,760 --> 00:02:28,560
well

67
00:02:28,560 --> 00:02:31,120
the obtained curves ka and kb are

68
00:02:31,120 --> 00:02:33,840
isomorphic

69
00:02:34,160 --> 00:02:36,080
the original seaside paper contracted

70
00:02:36,080 --> 00:02:38,239
seaside 512 would achieve nest pq

71
00:02:38,239 --> 00:02:41,040
security level one however the concrete

72
00:02:41,040 --> 00:02:43,360
security of seaside is under debate for

73
00:02:43,360 --> 00:02:45,760
example picker estimates prime p should

74
00:02:45,760 --> 00:02:47,920
be significantly larger in order to meet

75
00:02:47,920 --> 00:02:49,920
nice security level 1.

76
00:02:49,920 --> 00:02:51,680
in addition for the real world

77
00:02:51,680 --> 00:02:53,440
applications the constant time

78
00:02:53,440 --> 00:02:56,800
implementations are needed

79
00:02:58,400 --> 00:03:00,400
many papers have researched efficient

80
00:03:00,400 --> 00:03:03,040
constant time implementation of seaside

81
00:03:03,040 --> 00:03:04,879
some important optimization techniques

82
00:03:04,879 --> 00:03:06,480
are about using the alligator for

83
00:03:06,480 --> 00:03:08,640
sampling the random points on the curve

84
00:03:08,640 --> 00:03:10,080
the symbol technique

85
00:03:10,080 --> 00:03:12,080
and the two point approach

86
00:03:12,080 --> 00:03:14,159
among these works there were three main

87
00:03:14,159 --> 00:03:15,840
variants of the seaside group action

88
00:03:15,840 --> 00:03:20,560
evolution namely mcr style oit style

89
00:03:20,560 --> 00:03:23,360
and dummy freestyle

90
00:03:23,360 --> 00:03:25,360
notably the dummy freestyle is even

91
00:03:25,360 --> 00:03:27,280
resistant against fault injection

92
00:03:27,280 --> 00:03:29,440
attacks

93
00:03:29,440 --> 00:03:31,599
most recently a new algorithm of

94
00:03:31,599 --> 00:03:33,840
constant time c site a group action

95
00:03:33,840 --> 00:03:36,640
named ctidh was proposed and it uses a

96
00:03:36,640 --> 00:03:38,959
new key space you could watch this talk

97
00:03:38,959 --> 00:03:42,560
also at the chest 2021.

98
00:03:43,120 --> 00:03:44,959
in this work we present the first

99
00:03:44,959 --> 00:03:46,720
vectorized implementations of constant

100
00:03:46,720 --> 00:03:49,280
time seaside our software contains a

101
00:03:49,280 --> 00:03:51,200
high throughput and the low latency two

102
00:03:51,200 --> 00:03:53,360
types of these implementations

103
00:03:53,360 --> 00:03:55,360
the third photo optimized one is a batch

104
00:03:55,360 --> 00:03:57,360
implementation that performs eight group

105
00:03:57,360 --> 00:03:59,519
action instances in parallel which is

106
00:03:59,519 --> 00:04:01,680
designed to speed up the server-side qs

107
00:04:01,680 --> 00:04:02,799
processing

108
00:04:02,799 --> 00:04:04,560
in order to correctly and efficiently

109
00:04:04,560 --> 00:04:06,319
batch seaside reaction

110
00:04:06,319 --> 00:04:08,080
we present several different hybrid

111
00:04:08,080 --> 00:04:09,360
battery methods

112
00:04:09,360 --> 00:04:11,360
besides these batch methods are also

113
00:04:11,360 --> 00:04:13,439
beneficial for minimizing the latency of

114
00:04:13,439 --> 00:04:16,160
seaside-based signatures such as seafish

115
00:04:16,160 --> 00:04:17,600
and csun

116
00:04:17,600 --> 00:04:19,358
in which multiple independent group

117
00:04:19,358 --> 00:04:20,639
actions are computed in the key

118
00:04:20,639 --> 00:04:22,400
generation designing and verification

119
00:04:22,400 --> 00:04:24,000
processes

120
00:04:24,000 --> 00:04:25,840
the latency optimized implementation is

121
00:04:25,840 --> 00:04:27,840
developed to accelerate seaside on the

122
00:04:27,840 --> 00:04:29,520
tis client side

123
00:04:29,520 --> 00:04:31,040
and each of the high throughput and the

124
00:04:31,040 --> 00:04:33,080
low latency implementation includes

125
00:04:33,080 --> 00:04:36,560
avx-512f and fx512 ifma two different

126
00:04:36,560 --> 00:04:37,840
versions

127
00:04:37,840 --> 00:04:40,160
the target x64 software that we are

128
00:04:40,160 --> 00:04:42,880
optimizing is a large encrypt 19

129
00:04:42,880 --> 00:04:45,040
implementation

130
00:04:45,040 --> 00:04:47,280
in this presentation we will focus on

131
00:04:47,280 --> 00:04:50,880
the oit style implementation

132
00:04:51,840 --> 00:04:54,160
avex 512 is the latest inclination of

133
00:04:54,160 --> 00:04:56,560
intel advanced vector extension

134
00:04:56,560 --> 00:04:58,560
which augments the execution environment

135
00:04:58,560 --> 00:05:02,240
of x64 by 512 bit registers and various

136
00:05:02,240 --> 00:05:04,400
new instructions

137
00:05:04,400 --> 00:05:07,360
fx-512 contains multiple extensions but

138
00:05:07,360 --> 00:05:09,600
a specific processor may support some

139
00:05:09,600 --> 00:05:11,440
but not all of them

140
00:05:11,440 --> 00:05:13,919
from another perspective all processors

141
00:05:13,919 --> 00:05:16,639
equipped with ax512 support the core

142
00:05:16,639 --> 00:05:19,520
extension named abx5112 foundation

143
00:05:19,520 --> 00:05:23,280
which has a 32-bit vector multiplier

144
00:05:23,280 --> 00:05:25,520
in our software we are working on a sim

145
00:05:25,520 --> 00:05:28,000
department where it displays a 512-bit

146
00:05:28,000 --> 00:05:30,800
vector into eight 64-bit elements a

147
00:05:30,800 --> 00:05:32,240
single example of a vector

148
00:05:32,240 --> 00:05:35,199
multiplication instruction of fx512 f is

149
00:05:35,199 --> 00:05:36,479
shown here

150
00:05:36,479 --> 00:05:38,000
one instruction can perform eight

151
00:05:38,000 --> 00:05:40,080
element-wise 32 times 32-bit

152
00:05:40,080 --> 00:05:42,400
multiplication and finally get eight

153
00:05:42,400 --> 00:05:45,840
64-bit products

154
00:05:46,080 --> 00:05:49,360
among the extensions of apex 512 ifma is

155
00:05:49,360 --> 00:05:51,039
very attractive for public key

156
00:05:51,039 --> 00:05:52,720
cryptosystems whose underlying

157
00:05:52,720 --> 00:05:56,240
arithmetic is a large integer arithmetic

158
00:05:56,240 --> 00:05:58,960
intel described ifma as two new

159
00:05:58,960 --> 00:06:00,240
instructions for big number of

160
00:06:00,240 --> 00:06:02,639
multiplication for acceleration of rsa

161
00:06:02,639 --> 00:06:04,639
vectorized software and other crypto

162
00:06:04,639 --> 00:06:07,199
algorithms performance

163
00:06:07,199 --> 00:06:10,160
specifically ifma integer fields

164
00:06:10,160 --> 00:06:12,720
multiplayer multiply at

165
00:06:12,720 --> 00:06:14,400
firstly what

166
00:06:14,400 --> 00:06:17,280
multiplies the packed 52

167
00:06:17,280 --> 00:06:20,000
bit integers from two registers a and b

168
00:06:20,000 --> 00:06:22,800
to produce a 104 bit intermediate

169
00:06:22,800 --> 00:06:24,319
product t

170
00:06:24,319 --> 00:06:26,720
then as either the lower or the higher

171
00:06:26,720 --> 00:06:29,039
52 bit of the product t with another

172
00:06:29,039 --> 00:06:32,720
packed 64-bit integers from register c

173
00:06:32,720 --> 00:06:34,800
and stored final results in destination

174
00:06:34,800 --> 00:06:36,880
register r

175
00:06:36,880 --> 00:06:39,440
ifma was first supported with intel

176
00:06:39,440 --> 00:06:41,840
canon lake and continued to be equipped

177
00:06:41,840 --> 00:06:43,520
with its successors

178
00:06:43,520 --> 00:06:46,240
such as iceland tiger lake and rocket

179
00:06:46,240 --> 00:06:48,400
lake processors

180
00:06:48,400 --> 00:06:51,120
in this work we target the intel isolate

181
00:06:51,120 --> 00:06:53,680
processor

182
00:06:54,240 --> 00:06:56,800
okay so now i will introduce our batched

183
00:06:56,800 --> 00:06:58,720
high throughput implementation

184
00:06:58,720 --> 00:07:00,639
so let's first see the original seaside

185
00:07:00,639 --> 00:07:02,800
compaction here is a warrant of the

186
00:07:02,800 --> 00:07:05,039
original seaside compaction from these

187
00:07:05,039 --> 00:07:06,720
two highlighted lines

188
00:07:06,720 --> 00:07:08,720
we could find that algorithm is not

189
00:07:08,720 --> 00:07:11,440
constant time

190
00:07:11,919 --> 00:07:13,680
because the number of sizeogen is to be

191
00:07:13,680 --> 00:07:16,160
computed depends on the value of the

192
00:07:16,160 --> 00:07:17,599
secret exponent

193
00:07:17,599 --> 00:07:19,520
which makes execution times group action

194
00:07:19,520 --> 00:07:21,280
depends on the secret information

195
00:07:21,280 --> 00:07:23,360
therefore it is a vulnerable to the

196
00:07:23,360 --> 00:07:24,639
timing attacks

197
00:07:24,639 --> 00:07:27,360
however the oi cell seaside group action

198
00:07:27,360 --> 00:07:30,000
that we considered in this work computes

199
00:07:30,000 --> 00:07:32,560
bi solutions instead of ei for each

200
00:07:32,560 --> 00:07:35,520
prime ally it computes ei realizations

201
00:07:35,520 --> 00:07:38,240
and the bi minus ei dominator journeys

202
00:07:38,240 --> 00:07:39,759
so the total number of isotonic

203
00:07:39,759 --> 00:07:42,319
computations is always the sum of bi

204
00:07:42,319 --> 00:07:45,599
which is constant that equals to 404

205
00:07:45,599 --> 00:07:48,800
for c side 512

206
00:07:49,759 --> 00:07:52,080
this is the oayt style group action the

207
00:07:52,080 --> 00:07:53,840
difference between the original seaside

208
00:07:53,840 --> 00:07:56,479
is highlighted apart from the different

209
00:07:56,479 --> 00:07:58,800
way of isolating computations it also

210
00:07:58,800 --> 00:08:00,960
adds a constant time equality test to

211
00:08:00,960 --> 00:08:02,800
see if the corresponding ei is zero or

212
00:08:02,800 --> 00:08:04,160
not

213
00:08:04,160 --> 00:08:06,400
the curve and exponent values will be

214
00:08:06,400 --> 00:08:08,479
updated according to the result of this

215
00:08:08,479 --> 00:08:11,960
equality test

216
00:08:12,160 --> 00:08:13,919
so now we have obtained constant time

217
00:08:13,919 --> 00:08:16,000
seaside however this is not enough for

218
00:08:16,000 --> 00:08:17,520
batching

219
00:08:17,520 --> 00:08:20,080
to be specific we consider our batch

220
00:08:20,080 --> 00:08:22,400
software where eight oayt style

221
00:08:22,400 --> 00:08:24,400
protection instances are to be computed

222
00:08:24,400 --> 00:08:28,160
simultaneously by avex 512 instructions

223
00:08:28,160 --> 00:08:30,720
besides each instance is computed in

224
00:08:30,720 --> 00:08:33,120
64-bit line and instances are

225
00:08:33,120 --> 00:08:35,120
independent of each other

226
00:08:35,120 --> 00:08:37,440
the problem is the simply requires

227
00:08:37,440 --> 00:08:39,440
parallel instances to possess the same

228
00:08:39,440 --> 00:08:41,039
operation sequence

229
00:08:41,039 --> 00:08:43,360
which is a more strict requirement than

230
00:08:43,360 --> 00:08:45,680
the constant running time

231
00:08:45,680 --> 00:08:47,279
the operation sequence in oayt

232
00:08:47,279 --> 00:08:49,040
correction also relies on whether the

233
00:08:49,040 --> 00:08:52,160
kernel generator r is infinity or not

234
00:08:52,160 --> 00:08:55,040
which only depends on the randomness

235
00:08:55,040 --> 00:08:57,360
a single example is shown here

236
00:08:57,360 --> 00:08:59,519
so in the first instance the generator r

237
00:08:59,519 --> 00:09:01,600
is not a point at infinity while in the

238
00:09:01,600 --> 00:09:04,000
second instance it is infinity

239
00:09:04,000 --> 00:09:06,160
then instance 1 and 2 will later perform

240
00:09:06,160 --> 00:09:07,680
different operations

241
00:09:07,680 --> 00:09:09,440
this will cause a mismatch between

242
00:09:09,440 --> 00:09:11,839
distance 1 and 2 which is a problem for

243
00:09:11,839 --> 00:09:13,200
cmd

244
00:09:13,200 --> 00:09:15,360
in particular the probability for a

245
00:09:15,360 --> 00:09:18,160
point of order l i to be infinity is 1

246
00:09:18,160 --> 00:09:19,760
over l i

247
00:09:19,760 --> 00:09:22,000
which is considerably high when ally is

248
00:09:22,000 --> 00:09:26,080
small for example 3 5 or 7 in seaside

249
00:09:26,080 --> 00:09:28,080
in order to obtain a batching friendly

250
00:09:28,080 --> 00:09:29,760
and of course constant time seaside

251
00:09:29,760 --> 00:09:31,600
protection we need to mitigate this

252
00:09:31,600 --> 00:09:34,160
mismatch mismatch problem

253
00:09:34,160 --> 00:09:36,080
in the following we will present three

254
00:09:36,080 --> 00:09:37,839
different methods to solve this if

255
00:09:37,839 --> 00:09:39,440
conditional statement regarding the

256
00:09:39,440 --> 00:09:42,480
kernel generator r

257
00:09:43,279 --> 00:09:45,600
our first method aims at making group

258
00:09:45,600 --> 00:09:47,440
action independent for all

259
00:09:47,440 --> 00:09:49,839
inputs as well as all randomness

260
00:09:49,839 --> 00:09:51,839
in brief will remove

261
00:09:51,839 --> 00:09:54,399
uh if class of checking r is infinity or

262
00:09:54,399 --> 00:09:56,880
not at the cost of extra dummy eye

263
00:09:56,880 --> 00:09:58,800
surgery computations

264
00:09:58,800 --> 00:10:02,000
the idea was has been proposed and used

265
00:10:02,000 --> 00:10:04,399
in two previous implementations

266
00:10:04,399 --> 00:10:06,640
to apply this idea we add a new constant

267
00:10:06,640 --> 00:10:09,360
time infinity test and update the curve

268
00:10:09,360 --> 00:10:10,959
and other variables according to the

269
00:10:10,959 --> 00:10:13,680
result of the infinity test as well

270
00:10:13,680 --> 00:10:16,160
meanwhile we accordingly add a new

271
00:10:16,160 --> 00:10:18,720
constant ci for hbi

272
00:10:18,720 --> 00:10:20,320
then the number of total isolating

273
00:10:20,320 --> 00:10:22,720
computation is increased to the sum of

274
00:10:22,720 --> 00:10:25,839
bi plus ci

275
00:10:28,320 --> 00:10:31,040
however this method has several problems

276
00:10:31,040 --> 00:10:33,120
there always exists a probability of

277
00:10:33,120 --> 00:10:35,040
failure in computing the correct

278
00:10:35,040 --> 00:10:37,680
coordinate curve in this method

279
00:10:37,680 --> 00:10:40,000
that is when too many infinity cases

280
00:10:40,000 --> 00:10:41,839
happened it can make us lost the

281
00:10:41,839 --> 00:10:44,000
computation of the realized ordinance

282
00:10:44,000 --> 00:10:47,200
therefore a large number of extra dummy

283
00:10:47,200 --> 00:10:49,279
isolated computations are required to

284
00:10:49,279 --> 00:10:51,920
make this probability negligible for

285
00:10:51,920 --> 00:10:54,640
example it needs to compute around 900

286
00:10:54,640 --> 00:10:56,079
isolates to make this failure

287
00:10:56,079 --> 00:10:58,720
probability below 2 to -32

288
00:10:58,720 --> 00:11:00,640
while before it was 404 isolated

289
00:11:00,640 --> 00:11:01,839
computations

290
00:11:01,839 --> 00:11:03,839
hence it greatly reduces efficiency of

291
00:11:03,839 --> 00:11:05,839
the algorithm while the probability of

292
00:11:05,839 --> 00:11:07,680
failure still exists

293
00:11:07,680 --> 00:11:09,920
based on above discussion

294
00:11:09,920 --> 00:11:11,839
we are we are looking for a way to

295
00:11:11,839 --> 00:11:14,240
significantly reduce the number of extra

296
00:11:14,240 --> 00:11:16,079
damage softness and eliminate the

297
00:11:16,079 --> 00:11:18,720
probability of failure and meanwhile

298
00:11:18,720 --> 00:11:20,640
return this batching friendly fashion of

299
00:11:20,640 --> 00:11:22,079
group reaction

300
00:11:22,079 --> 00:11:24,399
and we succeeded to find the solution

301
00:11:24,399 --> 00:11:27,600
which is a hybrid mode

302
00:11:27,680 --> 00:11:30,399
hybrid mode means that the entire batch

303
00:11:30,399 --> 00:11:32,720
software is composed of two different

304
00:11:32,720 --> 00:11:33,839
types of screw protection

305
00:11:33,839 --> 00:11:35,519
implementations namely the batch

306
00:11:35,519 --> 00:11:38,240
component and on batch component

307
00:11:38,240 --> 00:11:40,160
the batch component is an incomplete

308
00:11:40,160 --> 00:11:41,760
implementation that performs eight

309
00:11:41,760 --> 00:11:43,839
instances simultaneously

310
00:11:43,839 --> 00:11:45,600
the on batch component is a latency

311
00:11:45,600 --> 00:11:47,519
optimized implementation accelerating a

312
00:11:47,519 --> 00:11:50,720
single cross compaction evaluation

313
00:11:50,720 --> 00:11:53,680
the key idea is to first take advantage

314
00:11:53,680 --> 00:11:55,760
of the batch component to compute the

315
00:11:55,760 --> 00:11:57,839
main bulk of the seaside group action

316
00:11:57,839 --> 00:12:00,320
for all instances and then use eight

317
00:12:00,320 --> 00:12:03,519
times in sequence on batch component to

318
00:12:03,519 --> 00:12:05,360
handle the remaining computations needed

319
00:12:05,360 --> 00:12:08,160
in each instance

320
00:12:08,160 --> 00:12:10,880
to apply the hybrid mode to xcode method

321
00:12:10,880 --> 00:12:13,440
we remove the ci and create a new bond

322
00:12:13,440 --> 00:12:14,880
list b hat

323
00:12:14,880 --> 00:12:17,040
and b hat is used to record infinite

324
00:12:17,040 --> 00:12:21,199
cases happened in the batch component

325
00:12:22,720 --> 00:12:24,639
and will be used as a bond list in the

326
00:12:24,639 --> 00:12:26,639
unbatched component

327
00:12:26,639 --> 00:12:28,800
our experiments indicate that for each

328
00:12:28,800 --> 00:12:30,639
instance there are often around 10

329
00:12:30,639 --> 00:12:32,639
isotonies remaining to be computed in

330
00:12:32,639 --> 00:12:35,279
the unbatched component as a result the

331
00:12:35,279 --> 00:12:37,360
total number of isolating computation is

332
00:12:37,360 --> 00:12:39,360
just slightly larger than before

333
00:12:39,360 --> 00:12:41,600
moreover since our batch component has

334
00:12:41,600 --> 00:12:43,839
no failure probability we conclude that

335
00:12:43,839 --> 00:12:45,839
our extra dummy method has no failure

336
00:12:45,839 --> 00:12:48,800
probability either

337
00:12:50,399 --> 00:12:52,000
our second batch method is quite

338
00:12:52,000 --> 00:12:53,839
straightforward we make all the

339
00:12:53,839 --> 00:12:55,600
instances always agree on the same

340
00:12:55,600 --> 00:12:56,560
branch

341
00:12:56,560 --> 00:12:59,120
therefore executing the same operations

342
00:12:59,120 --> 00:13:01,440
if the kernel generator r is infinity in

343
00:13:01,440 --> 00:13:03,760
at least one of parallel instances then

344
00:13:03,760 --> 00:13:06,480
we force all instances to skip a branch

345
00:13:06,480 --> 00:13:08,560
and execute an else branch

346
00:13:08,560 --> 00:13:10,320
in this else branch

347
00:13:10,320 --> 00:13:11,920
there is a new scalar multiplication for

348
00:13:11,920 --> 00:13:13,839
t0

349
00:13:13,839 --> 00:13:16,160
this is not needed before because li

350
00:13:16,160 --> 00:13:18,639
torsion part of the point t0 has already

351
00:13:18,639 --> 00:13:20,480
vanished but in our approach we are

352
00:13:20,480 --> 00:13:22,560
forcing all instances to proceed as if

353
00:13:22,560 --> 00:13:24,560
all kernel generators were infinity

354
00:13:24,560 --> 00:13:26,959
however the iteration parts of some

355
00:13:26,959 --> 00:13:30,719
points t0 have not vanished

356
00:13:31,519 --> 00:13:33,440
in particular we define a new variable

357
00:13:33,440 --> 00:13:35,680
working as follows

358
00:13:35,680 --> 00:13:38,240
however when this variable equals to 1

359
00:13:38,240 --> 00:13:40,720
the above idea imports some extra

360
00:13:40,720 --> 00:13:42,880
infinity related computations which in

361
00:13:42,880 --> 00:13:44,720
principle are not needed by every

362
00:13:44,720 --> 00:13:46,320
instance

363
00:13:46,320 --> 00:13:48,160
this infinity related computations are

364
00:13:48,160 --> 00:13:50,160
shown as listed

365
00:13:50,160 --> 00:13:52,240
in this special method each instance

366
00:13:52,240 --> 00:13:54,639
still computes 404 unsurgeons but more

367
00:13:54,639 --> 00:13:57,680
infinity related computations

368
00:13:57,680 --> 00:14:00,000
for this reason we refer to this method

369
00:14:00,000 --> 00:14:02,560
as the extra infinity method also the

370
00:14:02,560 --> 00:14:04,560
probability of this variable equals to 1

371
00:14:04,560 --> 00:14:07,360
is quite higher when li is small for

372
00:14:07,360 --> 00:14:10,720
example 3 5.7

373
00:14:10,720 --> 00:14:12,959
as a result an increased number of

374
00:14:12,959 --> 00:14:14,800
infinity related computations is

375
00:14:14,800 --> 00:14:17,279
expected which affects the efficiency of

376
00:14:17,279 --> 00:14:19,760
the extra infinity method we mitigate

377
00:14:19,760 --> 00:14:22,000
this problem by considering again the

378
00:14:22,000 --> 00:14:24,800
hybrid mode

379
00:14:25,519 --> 00:14:28,480
more precisely we divide the primes li

380
00:14:28,480 --> 00:14:30,720
into two subsets one for the batch

381
00:14:30,720 --> 00:14:32,800
component and the other four is on batch

382
00:14:32,800 --> 00:14:34,000
component

383
00:14:34,000 --> 00:14:36,320
l on batch contains only the smaller

384
00:14:36,320 --> 00:14:38,720
primes whereas l version

385
00:14:38,720 --> 00:14:41,040
includes the remaining primes

386
00:14:41,040 --> 00:14:43,519
in the same way the bond list b and the

387
00:14:43,519 --> 00:14:46,800
secret exponent list e of each instance

388
00:14:46,800 --> 00:14:49,760
are split into two subsets as well

389
00:14:49,760 --> 00:14:51,760
in the x coefficient method we first

390
00:14:51,760 --> 00:14:53,839
execute the batch component for eight

391
00:14:53,839 --> 00:14:56,320
parallel instances to compute isolate

392
00:14:56,320 --> 00:14:58,320
for the larger primes with corresponding

393
00:14:58,320 --> 00:14:59,600
subsets

394
00:14:59,600 --> 00:15:01,120
and the batch component outputs the

395
00:15:01,120 --> 00:15:04,399
resulting curve b hat for each instance

396
00:15:04,399 --> 00:15:06,160
then execute on batch components

397
00:15:06,160 --> 00:15:08,160
sequentially in order to obtain the

398
00:15:08,160 --> 00:15:10,000
correct coordinate curve for each

399
00:15:10,000 --> 00:15:11,440
instance

400
00:15:11,440 --> 00:15:12,399
in this way

401
00:15:12,399 --> 00:15:14,079
the infinity related computation needs

402
00:15:14,079 --> 00:15:16,560
to be computed is much less than not

403
00:15:16,560 --> 00:15:19,599
using hybrid mode

404
00:15:20,399 --> 00:15:22,160
okay now let's turn to the third

405
00:15:22,160 --> 00:15:23,199
approach

406
00:15:23,199 --> 00:15:24,880
before we introduce the third approach

407
00:15:24,880 --> 00:15:27,040
we give a few more details on the

408
00:15:27,040 --> 00:15:29,519
extraordinary and extra infinite methods

409
00:15:29,519 --> 00:15:32,160
so we consider an example where in

410
00:15:32,160 --> 00:15:34,880
iteration of the inner for loop n of the

411
00:15:34,880 --> 00:15:37,680
eight kernel points are infinity

412
00:15:37,680 --> 00:15:39,519
the extra dummy method will complete the

413
00:15:39,519 --> 00:15:41,600
computations of this iteration and later

414
00:15:41,600 --> 00:15:44,160
it will compute in a compensatory

415
00:15:44,160 --> 00:15:45,519
isolate

416
00:15:45,519 --> 00:15:48,160
with a batch component

417
00:15:48,160 --> 00:15:50,160
on the other hand the extra infinity

418
00:15:50,160 --> 00:15:52,079
method will enter its else branch to

419
00:15:52,079 --> 00:15:54,079
compute scale multiplication for all

420
00:15:54,079 --> 00:15:56,480
eight instances and it may later perform

421
00:15:56,480 --> 00:15:58,480
other infinity related computations

422
00:15:58,480 --> 00:16:00,160
which are in theory needed by any

423
00:16:00,160 --> 00:16:02,560
instances

424
00:16:02,560 --> 00:16:04,320
based on the operations that are carried

425
00:16:04,320 --> 00:16:06,959
out in each method we observe that the

426
00:16:06,959 --> 00:16:08,800
extraordinary method handles infinity

427
00:16:08,800 --> 00:16:11,759
cases more efficiently when n is small

428
00:16:11,759 --> 00:16:14,240
so on the other hand when n is close to

429
00:16:14,240 --> 00:16:15,040
8

430
00:16:15,040 --> 00:16:16,959
the extra infinity method seems to be

431
00:16:16,959 --> 00:16:19,599
more efficient

432
00:16:20,639 --> 00:16:23,920
so based on above observation our idea

433
00:16:23,920 --> 00:16:26,160
is to combine two approaches aiming at

434
00:16:26,160 --> 00:16:28,480
obtaining a more efficient method

435
00:16:28,480 --> 00:16:30,639
in order to do this we set the new

436
00:16:30,639 --> 00:16:32,880
variable as listed we add an if else

437
00:16:32,880 --> 00:16:34,800
statement to check if this variable is

438
00:16:34,800 --> 00:16:37,440
within a predefined threshold or not

439
00:16:37,440 --> 00:16:39,600
if it is not larger than this threshold

440
00:16:39,600 --> 00:16:42,000
we will perform the extra dummy method

441
00:16:42,000 --> 00:16:43,519
otherwise we will go to the extra

442
00:16:43,519 --> 00:16:45,040
infinity

443
00:16:45,040 --> 00:16:46,639
from our experiments

444
00:16:46,639 --> 00:16:48,959
the threshold value for our oay t style

445
00:16:48,959 --> 00:16:51,519
implementation is three

446
00:16:51,519 --> 00:16:53,759
and this and and the third method we

447
00:16:53,759 --> 00:16:57,360
call it the combined method

448
00:16:58,160 --> 00:16:59,759
so in terms of our throughput of

449
00:16:59,759 --> 00:17:00,959
implement uh high throughput

450
00:17:00,959 --> 00:17:02,399
implementation

451
00:17:02,399 --> 00:17:04,400
for the class group action layer

452
00:17:04,400 --> 00:17:05,839
we will take advantage of three

453
00:17:05,839 --> 00:17:07,599
different batch methods

454
00:17:07,599 --> 00:17:09,760
for the curve arithmetic we simply

455
00:17:09,760 --> 00:17:11,919
developed uh them according to the

456
00:17:11,919 --> 00:17:14,079
existing four software based minor

457
00:17:14,079 --> 00:17:15,439
optimizations

458
00:17:15,439 --> 00:17:17,280
and for the prime field operations we

459
00:17:17,280 --> 00:17:18,959
developed eight times one-way

460
00:17:18,959 --> 00:17:20,319
implementation according to the slim

461
00:17:20,319 --> 00:17:23,359
slicing technique to be specific for the

462
00:17:23,359 --> 00:17:25,280
field multiplication we developed many

463
00:17:25,280 --> 00:17:27,280
different values and finally select the

464
00:17:27,280 --> 00:17:29,600
fastest one among them

465
00:17:29,600 --> 00:17:31,360
i also developed a dedicated squaring

466
00:17:31,360 --> 00:17:33,200
based on the classic optimization

467
00:17:33,200 --> 00:17:35,280
technique as it computes the repeated

468
00:17:35,280 --> 00:17:37,600
partial products only once

469
00:17:37,600 --> 00:17:39,360
since the vector multiplier of the avex

470
00:17:39,360 --> 00:17:42,880
five type f and ifma are different

471
00:17:42,880 --> 00:17:44,160
the implementation of the field

472
00:17:44,160 --> 00:17:45,760
operation in these two

473
00:17:45,760 --> 00:17:47,440
in these two versions are of course

474
00:17:47,440 --> 00:17:50,080
quite different

475
00:17:51,600 --> 00:17:53,760
on the other hand for the low latency

476
00:17:53,760 --> 00:17:56,080
implementation it can also serve as on

477
00:17:56,080 --> 00:17:58,720
batch component in the hybrid mode for

478
00:17:58,720 --> 00:18:01,039
high therapy implementation

479
00:18:01,039 --> 00:18:02,880
the class group action layer is just the

480
00:18:02,880 --> 00:18:05,520
same as aut style group action the curve

481
00:18:05,520 --> 00:18:08,000
arithmetic can be easily paralyzed to

482
00:18:08,000 --> 00:18:10,160
two-way and the number of needed two-way

483
00:18:10,160 --> 00:18:12,240
multiplication squaring is just half of

484
00:18:12,240 --> 00:18:13,679
the number of original one-way

485
00:18:13,679 --> 00:18:16,480
multiplication and the squaring

486
00:18:16,480 --> 00:18:18,480
as for the prime field operations we

487
00:18:18,480 --> 00:18:19,760
developed a two times four-way

488
00:18:19,760 --> 00:18:21,039
implementation based on the

489
00:18:21,039 --> 00:18:23,280
implementation of arisaka

490
00:18:23,280 --> 00:18:26,080
arena and the locus which is original

491
00:18:26,080 --> 00:18:27,840
originally designed for the field

492
00:18:27,840 --> 00:18:31,039
multiplication of sidh

493
00:18:31,039 --> 00:18:32,880
two times four-way means it performed

494
00:18:32,880 --> 00:18:35,120
two field multiplications operations in

495
00:18:35,120 --> 00:18:37,120
parallel where each operation uses four

496
00:18:37,120 --> 00:18:38,720
elements of the vector

497
00:18:38,720 --> 00:18:40,400
we slightly optimize the field

498
00:18:40,400 --> 00:18:41,919
multiplication by interleaving the

499
00:18:41,919 --> 00:18:43,280
integer multiplication based on

500
00:18:43,280 --> 00:18:45,200
montgomery reduction and based on the

501
00:18:45,200 --> 00:18:47,600
same classic optimization technique we

502
00:18:47,600 --> 00:18:49,760
developed dedicated four times four-way

503
00:18:49,760 --> 00:18:52,559
squaring as well

504
00:18:53,520 --> 00:18:55,200
so in order to figure out the real

505
00:18:55,200 --> 00:18:57,600
improvement of our work we benchmarked

506
00:18:57,600 --> 00:18:59,520
our software and the seaside group

507
00:18:59,520 --> 00:19:01,919
action evaluation for all the oeyt and

508
00:19:01,919 --> 00:19:04,160
dummy free implementations on the same

509
00:19:04,160 --> 00:19:06,640
isolate cpu

510
00:19:06,640 --> 00:19:08,400
the spin up ratio is defined by

511
00:19:08,400 --> 00:19:09,520
comparing

512
00:19:09,520 --> 00:19:11,520
the cpu cycle divided by number of

513
00:19:11,520 --> 00:19:12,640
instances

514
00:19:12,640 --> 00:19:14,320
between the baseline and the specific

515
00:19:14,320 --> 00:19:15,760
implementation

516
00:19:15,760 --> 00:19:17,919
which can be understood as a normalized

517
00:19:17,919 --> 00:19:19,440
throughput

518
00:19:19,440 --> 00:19:21,840
we use our target x64 implementation as

519
00:19:21,840 --> 00:19:22,960
baseline

520
00:19:22,960 --> 00:19:25,360
because in this way we know precisely

521
00:19:25,360 --> 00:19:27,280
how much our vector processing

522
00:19:27,280 --> 00:19:29,360
techniques improve the result

523
00:19:29,360 --> 00:19:31,520
and this x64 implementation also served

524
00:19:31,520 --> 00:19:34,320
as baseline other papers

525
00:19:34,320 --> 00:19:36,799
as shown in the table our two-way low

526
00:19:36,799 --> 00:19:38,960
latency ifma implementation has roughly

527
00:19:38,960 --> 00:19:41,120
the same latency as the original not

528
00:19:41,120 --> 00:19:43,280
constant time implementation and is

529
00:19:43,280 --> 00:19:46,559
about 1.5 times faster than the baseline

530
00:19:46,559 --> 00:19:48,240
and our eight times one-way ifm

531
00:19:48,240 --> 00:19:50,080
implementation when applied with a

532
00:19:50,080 --> 00:19:53,400
combined batch method takes a

533
00:19:53,400 --> 00:19:56,240
3.64 times higher throughput compared to

534
00:19:56,240 --> 00:19:57,520
the baseline

535
00:19:57,520 --> 00:19:59,360
an analysis of the execution times of

536
00:19:59,360 --> 00:20:01,600
our high throughput software shows that

537
00:20:01,600 --> 00:20:03,760
all the ifma implementations are nearly

538
00:20:03,760 --> 00:20:06,720
1.9 times faster than corresponding avx

539
00:20:06,720 --> 00:20:08,720
512 f implementations

540
00:20:08,720 --> 00:20:11,520
which confirms that the ifma extension

541
00:20:11,520 --> 00:20:14,640
indeed significantly accelerates seaside

542
00:20:14,640 --> 00:20:18,840
compared to the general fx512f

543
00:20:19,760 --> 00:20:21,360
the benchmarking results of dummy

544
00:20:21,360 --> 00:20:23,840
freestyle implementations are summarizes

545
00:20:23,840 --> 00:20:26,640
uh in this table

546
00:20:26,640 --> 00:20:28,720
these results show that our proposed

547
00:20:28,720 --> 00:20:30,480
vector methods still work efficiently

548
00:20:30,480 --> 00:20:32,640
then apply to the dummy freestyle

549
00:20:32,640 --> 00:20:34,880
seaside protection and can yield an up

550
00:20:34,880 --> 00:20:38,080
to 3.63 times higher throughput compared

551
00:20:38,080 --> 00:20:40,879
to the baseline

552
00:20:42,000 --> 00:20:44,880
though fx512 can work on 8 64-bit

553
00:20:44,880 --> 00:20:46,799
elements simultaneously with a single

554
00:20:46,799 --> 00:20:48,640
instruction the theoretical maximum

555
00:20:48,640 --> 00:20:50,640
speed-up factor of an fx512

556
00:20:50,640 --> 00:20:53,200
implementation compared to x64 is

557
00:20:53,200 --> 00:20:56,799
actually far from eight

558
00:20:56,799 --> 00:20:59,200
the main reason is a multiplier taking

559
00:20:59,200 --> 00:21:01,200
eight fifth uh

560
00:21:01,200 --> 00:21:03,120
a fact 12 between integer

561
00:21:03,120 --> 00:21:04,320
multiplications

562
00:21:04,320 --> 00:21:07,440
using the square method as an example

563
00:21:07,440 --> 00:21:10,960
x64 implementation is 64 multiplication

564
00:21:10,960 --> 00:21:13,120
instructions for one instance while

565
00:21:13,120 --> 00:21:17,200
fx512f means at least 256 vectorized

566
00:21:17,200 --> 00:21:18,720
multiplication

567
00:21:18,720 --> 00:21:21,200
instructions for eight instances

568
00:21:21,200 --> 00:21:23,760
and the ifma requires 200 instructions

569
00:21:23,760 --> 00:21:26,159
for eight instances

570
00:21:26,159 --> 00:21:29,360
compared to an x64 implementation

571
00:21:29,360 --> 00:21:33,039
the approximate speed up of avx 512 f is

572
00:21:33,039 --> 00:21:37,440
2.0 and ifme is 2.56

573
00:21:37,440 --> 00:21:39,760
taking this analysis into account our

574
00:21:39,760 --> 00:21:41,840
thoroughford optimized fx 512 f

575
00:21:41,840 --> 00:21:46,320
implementations have expected speed ups

576
00:21:47,600 --> 00:21:49,039
as for the latency optimized

577
00:21:49,039 --> 00:21:51,440
implementation a two-way ifma latency

578
00:21:51,440 --> 00:21:54,559
optimized implementation of psyc is 1.72

579
00:21:54,559 --> 00:21:57,600
times faster than x64 assembly

580
00:21:57,600 --> 00:21:59,039
implementation

581
00:21:59,039 --> 00:22:01,679
we can just conclude our two-way ifmae

582
00:22:01,679 --> 00:22:03,520
low latency implementations also

583
00:22:03,520 --> 00:22:06,799
correspond to the expected acceleration

584
00:22:06,799 --> 00:22:08,640
and there are several reasons

585
00:22:08,640 --> 00:22:10,480
that make the two-way latency optimized

586
00:22:10,480 --> 00:22:12,240
implementation less efficient than the

587
00:22:12,240 --> 00:22:14,799
throughput optimized implementation

588
00:22:14,799 --> 00:22:17,440
because overheads caused by aligning and

589
00:22:17,440 --> 00:22:20,080
blending mx512 factors in two-way curve

590
00:22:20,080 --> 00:22:21,919
and isolating operations

591
00:22:21,919 --> 00:22:23,760
some point operations cannot be

592
00:22:23,760 --> 00:22:26,480
parallelized in an ideal two-way fashion

593
00:22:26,480 --> 00:22:29,919
due to the dependencies of the internal

594
00:22:29,919 --> 00:22:31,600
field operations

595
00:22:31,600 --> 00:22:33,280
and also some computations in failed

596
00:22:33,280 --> 00:22:35,360
operations for example the complete

597
00:22:35,360 --> 00:22:38,559
carry propagation cannot be parallelized

598
00:22:38,559 --> 00:22:40,400
in an ideal two times four way due to

599
00:22:40,400 --> 00:22:42,000
the sequential dependencies of the

600
00:22:42,000 --> 00:22:44,080
instructions

601
00:22:44,080 --> 00:22:45,520
and also the instruction level

602
00:22:45,520 --> 00:22:47,679
parallelism or two times four way is

603
00:22:47,679 --> 00:22:49,520
lower than eight times one way since

604
00:22:49,520 --> 00:22:53,799
four limbs are stored in one vector

605
00:22:53,840 --> 00:22:55,280
conclude

606
00:22:55,280 --> 00:22:57,679
in this work we have showed that vector

607
00:22:57,679 --> 00:23:00,799
engines like fx512 offer great potential

608
00:23:00,799 --> 00:23:03,280
to optimize seaside we presented the

609
00:23:03,280 --> 00:23:04,880
first vectorized implementation of

610
00:23:04,880 --> 00:23:07,200
seaside and developing efficient batch

611
00:23:07,200 --> 00:23:09,039
methods for the cost protection and

612
00:23:09,039 --> 00:23:10,720
combining them with highly optimized

613
00:23:10,720 --> 00:23:13,120
field arithmetic we were able to achieve

614
00:23:13,120 --> 00:23:16,080
a 3.6 phone gain in throughput compared

615
00:23:16,080 --> 00:23:19,280
to a state-of-the-art x64 implementation

616
00:23:19,280 --> 00:23:20,559
the correct

617
00:23:20,559 --> 00:23:22,640
parameterization of seaside to achieve

618
00:23:22,640 --> 00:23:24,640
nest security level one is currently

619
00:23:24,640 --> 00:23:26,640
still a topic of debate

620
00:23:26,640 --> 00:23:28,640
while our proposed vectorizing methods

621
00:23:28,640 --> 00:23:30,480
can also be used for larger primes and

622
00:23:30,480 --> 00:23:32,880
certain parts of our source code can be

623
00:23:32,880 --> 00:23:35,440
reused

624
00:23:35,600 --> 00:23:39,799
that's it thank you for your attention

