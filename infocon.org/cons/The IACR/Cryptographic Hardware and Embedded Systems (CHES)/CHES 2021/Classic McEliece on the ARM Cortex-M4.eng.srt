1
00:00:02,080 --> 00:00:04,880
hello and welcome to my talk for chess

2
00:00:04,880 --> 00:00:06,480
2021

3
00:00:06,480 --> 00:00:09,120
my name is minxing chen this talk is

4
00:00:09,120 --> 00:00:12,080
about the paper classic mech list on the

5
00:00:12,080 --> 00:00:13,840
unquote m4

6
00:00:13,840 --> 00:00:16,320
this is a joint work with my colleague

7
00:00:16,320 --> 00:00:18,720
toto

8
00:00:19,199 --> 00:00:22,400
the first page is the introduction of

9
00:00:22,400 --> 00:00:25,119
the classical mechanism system

10
00:00:25,119 --> 00:00:27,199
characteristic mechanism is a

11
00:00:27,199 --> 00:00:30,080
key incarceration mechanism

12
00:00:30,080 --> 00:00:33,360
it is used for establishing a shared key

13
00:00:33,360 --> 00:00:35,600
for communication

14
00:00:35,600 --> 00:00:38,160
it's based on a code basis public key

15
00:00:38,160 --> 00:00:40,000
encryption scheme

16
00:00:40,000 --> 00:00:43,600
and it is a finalist

17
00:00:43,600 --> 00:00:46,160
in nist's post-content quick

18
00:00:46,160 --> 00:00:50,000
cryptography standardization process

19
00:00:50,000 --> 00:00:53,280
it has a three-core operation

20
00:00:53,280 --> 00:00:54,079
the

21
00:00:54,079 --> 00:00:55,680
key generation

22
00:00:55,680 --> 00:00:58,399
is used for generating a public key and

23
00:00:58,399 --> 00:01:00,399
security pair

24
00:01:00,399 --> 00:01:03,440
the encapsulation it

25
00:01:03,440 --> 00:01:06,159
was generate a random message

26
00:01:06,159 --> 00:01:08,479
and then encrypt the message

27
00:01:08,479 --> 00:01:12,720
and the capsulation can decrypt

28
00:01:12,720 --> 00:01:15,280
received cipher text and

29
00:01:15,280 --> 00:01:16,240
then

30
00:01:16,240 --> 00:01:18,880
derive a shared key

31
00:01:18,880 --> 00:01:22,159
also i leave all parameters for a

32
00:01:22,159 --> 00:01:24,799
different security level in the table

33
00:01:24,799 --> 00:01:27,360
and you can post the video if you want

34
00:01:27,360 --> 00:01:30,240
to read the details

35
00:01:30,240 --> 00:01:31,600
a common

36
00:01:31,600 --> 00:01:35,360
criticism for classic mechanics is

37
00:01:35,360 --> 00:01:37,840
it's a big public key

38
00:01:37,840 --> 00:01:41,840
and this is this problem is more severe

39
00:01:41,840 --> 00:01:45,119
in an embedded system because it usually

40
00:01:45,119 --> 00:01:49,439
don't have so many storage spaces

41
00:01:49,439 --> 00:01:52,840
we use the uncode example as our

42
00:01:52,840 --> 00:01:55,360
optimization target

43
00:01:55,360 --> 00:01:58,640
this is because the needs choose the

44
00:01:58,640 --> 00:02:03,920
process is first platform for emphasis

45
00:02:03,920 --> 00:02:04,640
so

46
00:02:04,640 --> 00:02:05,600
the

47
00:02:05,600 --> 00:02:08,399
m4 process has a 14

48
00:02:08,399 --> 00:02:11,120
32 bits register

49
00:02:11,120 --> 00:02:12,879
if the process

50
00:02:12,879 --> 00:02:15,680
has a 14 point unit

51
00:02:15,680 --> 00:02:17,920
this is an optional

52
00:02:17,920 --> 00:02:18,720
then

53
00:02:18,720 --> 00:02:21,680
we have a 32 extra floating point

54
00:02:21,680 --> 00:02:23,280
registers and

55
00:02:23,280 --> 00:02:27,360
we use the 14 point register as an

56
00:02:27,360 --> 00:02:30,160
extra stack spaces

57
00:02:30,160 --> 00:02:33,440
so it can help us to prevent

58
00:02:33,440 --> 00:02:35,760
the registering

59
00:02:35,760 --> 00:02:39,040
memory access usually costs 2 correct

60
00:02:39,040 --> 00:02:40,160
cycles

61
00:02:40,160 --> 00:02:43,760
reading or writing contiguous memory can

62
00:02:43,760 --> 00:02:45,599
become faster

63
00:02:45,599 --> 00:02:47,920
for example it takes

64
00:02:47,920 --> 00:02:51,840
10 plus 1 cycles for reading or writing

65
00:02:51,840 --> 00:02:53,840
a

66
00:02:53,840 --> 00:02:56,400
contiguous data

67
00:02:56,400 --> 00:03:00,640
our device for programming is the st

68
00:03:00,640 --> 00:03:02,400
discovery board

69
00:03:02,400 --> 00:03:07,760
from the st micro electronic companies

70
00:03:07,760 --> 00:03:10,480
this is a commonly used board for

71
00:03:10,480 --> 00:03:13,760
benchmarking the crypto systems

72
00:03:13,760 --> 00:03:15,440
and this board

73
00:03:15,440 --> 00:03:16,440
has a

74
00:03:16,440 --> 00:03:20,080
192 kilobyte brand

75
00:03:20,080 --> 00:03:21,680
more importantly

76
00:03:21,680 --> 00:03:24,959
it has a one megabyte flash memory

77
00:03:24,959 --> 00:03:28,159
the fresh memory usually used for

78
00:03:28,159 --> 00:03:30,560
storing the progress

79
00:03:30,560 --> 00:03:33,920
but in our work we use the fresh memory

80
00:03:33,920 --> 00:03:36,560
to store the public key

81
00:03:36,560 --> 00:03:37,599
so

82
00:03:37,599 --> 00:03:38,959
this

83
00:03:38,959 --> 00:03:40,159
more or less

84
00:03:40,159 --> 00:03:44,400
solves the problem of large public keys

85
00:03:44,400 --> 00:03:47,120
our first optimization is the key

86
00:03:47,120 --> 00:03:48,640
generation

87
00:03:48,640 --> 00:03:51,599
basically you have a large rectangle

88
00:03:51,599 --> 00:03:53,280
matrix

89
00:03:53,280 --> 00:03:56,400
and you want to turn the first part

90
00:03:56,400 --> 00:03:58,000
the m part

91
00:03:58,000 --> 00:04:00,720
into an identity matrix

92
00:04:00,720 --> 00:04:04,640
and then you multiply the rest path the

93
00:04:04,640 --> 00:04:05,840
t part

94
00:04:05,840 --> 00:04:08,159
by the an inverse matrix

95
00:04:08,159 --> 00:04:11,840
and the product is the public key

96
00:04:11,840 --> 00:04:12,959
so

97
00:04:12,959 --> 00:04:17,199
there were two implementation befores

98
00:04:17,199 --> 00:04:18,000
the

99
00:04:18,000 --> 00:04:20,798
big picture of the two implementation is

100
00:04:20,798 --> 00:04:22,479
the same they

101
00:04:22,479 --> 00:04:26,000
all first use and in place lp

102
00:04:26,000 --> 00:04:30,639
decomposition to decompose the matrix

103
00:04:30,639 --> 00:04:34,240
the decomposition must be in place

104
00:04:34,240 --> 00:04:37,120
because we usually don't have a large

105
00:04:37,120 --> 00:04:39,919
space in an embedded system

106
00:04:39,919 --> 00:04:44,720
then with the decomposed matrix of them

107
00:04:44,720 --> 00:04:46,960
they generate the

108
00:04:46,960 --> 00:04:51,440
only a part of a public key

109
00:04:51,440 --> 00:04:54,080
because the public key is larger than

110
00:04:54,080 --> 00:04:57,440
the memory so they can only generate

111
00:04:57,440 --> 00:04:59,120
step by step

112
00:04:59,120 --> 00:05:00,560
so

113
00:05:00,560 --> 00:05:02,880
there are two differences

114
00:05:02,880 --> 00:05:05,440
in the two implementation

115
00:05:05,440 --> 00:05:09,520
first the result of the llp composition

116
00:05:09,520 --> 00:05:11,440
are different

117
00:05:11,440 --> 00:05:13,759
because they use a different

118
00:05:13,759 --> 00:05:15,280
different algorithm for the

119
00:05:15,280 --> 00:05:16,960
decomposition

120
00:05:16,960 --> 00:05:18,160
second

121
00:05:18,160 --> 00:05:21,840
after after decomposition

122
00:05:21,840 --> 00:05:24,400
the rkk implementation

123
00:05:24,400 --> 00:05:25,600
compute

124
00:05:25,600 --> 00:05:27,759
the an inverse matrix

125
00:05:27,759 --> 00:05:30,320
and generate the public key by the

126
00:05:30,320 --> 00:05:33,039
method inverse matrix

127
00:05:33,039 --> 00:05:35,520
in source implementation

128
00:05:35,520 --> 00:05:38,400
it did not generate the inverse matrix

129
00:05:38,400 --> 00:05:40,720
it generates that it generates the

130
00:05:40,720 --> 00:05:43,360
public key directly by the decomposition

131
00:05:43,360 --> 00:05:45,280
data

132
00:05:45,280 --> 00:05:46,160
so

133
00:05:46,160 --> 00:05:50,639
this page shows our implementation

134
00:05:50,639 --> 00:05:53,680
we kind of mixed up the two previous

135
00:05:53,680 --> 00:05:55,440
implementation

136
00:05:55,440 --> 00:05:59,120
for lup decomposition we used the

137
00:05:59,120 --> 00:06:01,360
algorithm from the archicad's

138
00:06:01,360 --> 00:06:02,880
implementation

139
00:06:02,880 --> 00:06:04,840
then after the

140
00:06:04,840 --> 00:06:07,840
decomposition we generate the public key

141
00:06:07,840 --> 00:06:11,280
directly from the decomposed data

142
00:06:11,280 --> 00:06:14,160
just as source implementation

143
00:06:14,160 --> 00:06:17,280
so there are two kinds of matrices

144
00:06:17,280 --> 00:06:19,280
after the decomposition

145
00:06:19,280 --> 00:06:21,919
for the permutation matrix p

146
00:06:21,919 --> 00:06:25,120
we use a sorting network to permute the

147
00:06:25,120 --> 00:06:26,160
low mean

148
00:06:26,160 --> 00:06:30,720
the laws of matches ti

149
00:06:30,720 --> 00:06:33,440
after the permutation is done

150
00:06:33,440 --> 00:06:37,520
we have to multiply ti by the inverse of

151
00:06:37,520 --> 00:06:40,639
the upper triangle matrix u or the lower

152
00:06:40,639 --> 00:06:43,120
triangular matrix l

153
00:06:43,120 --> 00:06:45,520
the figure in the middle

154
00:06:45,520 --> 00:06:46,639
show

155
00:06:46,639 --> 00:06:49,120
the multiplication of

156
00:06:49,120 --> 00:06:52,800
the inverse matrix l u l or u can be

157
00:06:52,800 --> 00:06:55,759
done by the correct order of the law

158
00:06:55,759 --> 00:06:57,199
operation

159
00:06:57,199 --> 00:07:00,240
so we don't have to compute the inverse

160
00:07:00,240 --> 00:07:05,520
matrices of l o u is appreciated

161
00:07:05,520 --> 00:07:08,319
in our implementation we use

162
00:07:08,319 --> 00:07:10,720
the blocking measures multiplication for

163
00:07:10,720 --> 00:07:13,360
all the matrix multiplication for beta

164
00:07:13,360 --> 00:07:16,240
performance

165
00:07:16,240 --> 00:07:19,120
then we proceed to the second operation

166
00:07:19,120 --> 00:07:21,199
of classic mechanism

167
00:07:21,199 --> 00:07:23,599
the key encapsulation

168
00:07:23,599 --> 00:07:27,319
and this page shows the details of the

169
00:07:27,319 --> 00:07:28,840
encapsulation

170
00:07:28,840 --> 00:07:32,319
operation it first generates a

171
00:07:32,319 --> 00:07:35,039
uniform random message with a fixed

172
00:07:35,039 --> 00:07:36,880
weight t

173
00:07:36,880 --> 00:07:39,599
then it performs a matrix vector

174
00:07:39,599 --> 00:07:41,520
multiplication

175
00:07:41,520 --> 00:07:44,000
this is the most time-consuming

176
00:07:44,000 --> 00:07:48,400
operation in the encapsulation

177
00:07:48,400 --> 00:07:52,000
it multiplies the probability matrix

178
00:07:52,000 --> 00:07:53,120
by the

179
00:07:53,120 --> 00:07:54,319
random

180
00:07:54,319 --> 00:07:57,120
random mesh generated in the previous

181
00:07:57,120 --> 00:07:58,720
step

182
00:07:58,720 --> 00:08:01,120
we will talk about the two steps in the

183
00:08:01,120 --> 00:08:02,639
data styles

184
00:08:02,639 --> 00:08:03,840
so

185
00:08:03,840 --> 00:08:05,280
after that

186
00:08:05,280 --> 00:08:07,919
when the message is generated and the

187
00:08:07,919 --> 00:08:10,720
matrix vector modification is done

188
00:08:10,720 --> 00:08:14,000
we can then produce the ciphertext and

189
00:08:14,000 --> 00:08:14,879
the

190
00:08:14,879 --> 00:08:19,120
shared key with the hash functions

191
00:08:19,120 --> 00:08:22,720
when generating the random message e

192
00:08:22,720 --> 00:08:26,080
the spec requires it to took the uniform

193
00:08:26,080 --> 00:08:29,680
random vector with the length and

194
00:08:29,680 --> 00:08:31,120
weight t

195
00:08:31,120 --> 00:08:33,360
because we don't have a

196
00:08:33,360 --> 00:08:36,719
prng that can generate the message

197
00:08:36,719 --> 00:08:38,080
directly

198
00:08:38,080 --> 00:08:40,958
so the typical method for the generation

199
00:08:40,958 --> 00:08:43,919
is to generate indexes

200
00:08:43,919 --> 00:08:45,360
of ones

201
00:08:45,360 --> 00:08:47,760
and reject the

202
00:08:47,760 --> 00:08:51,360
index with the same value over its

203
00:08:51,360 --> 00:08:52,399
length

204
00:08:52,399 --> 00:08:54,399
then we still have to check the

205
00:08:54,399 --> 00:08:57,200
repetition of the indices

206
00:08:57,200 --> 00:09:00,000
so we check the repetition by sorting

207
00:09:00,000 --> 00:09:02,480
the indexes and check if

208
00:09:02,480 --> 00:09:05,440
there are two adjacent elements with the

209
00:09:05,440 --> 00:09:08,080
same interest index

210
00:09:08,080 --> 00:09:11,760
so we claim that sorting gear

211
00:09:11,760 --> 00:09:14,320
need not to be a constant sorting

212
00:09:14,320 --> 00:09:16,480
algorithm

213
00:09:16,480 --> 00:09:18,959
because when a non-constant tongue

214
00:09:18,959 --> 00:09:21,200
sorting algorithm is used

215
00:09:21,200 --> 00:09:23,360
for example we use a

216
00:09:23,360 --> 00:09:24,959
q sort

217
00:09:24,959 --> 00:09:26,000
then

218
00:09:26,000 --> 00:09:28,959
the sorting algorithm may leak the

219
00:09:28,959 --> 00:09:31,920
information for the order of

220
00:09:31,920 --> 00:09:33,760
two indices when

221
00:09:33,760 --> 00:09:37,600
comparing comparison it will not dig the

222
00:09:37,600 --> 00:09:39,760
its real value

223
00:09:39,760 --> 00:09:40,640
so

224
00:09:40,640 --> 00:09:43,839
we use a faster algorithm for checking

225
00:09:43,839 --> 00:09:44,880
the

226
00:09:44,880 --> 00:09:46,320
repetitions

227
00:09:46,320 --> 00:09:48,640
and this method can

228
00:09:48,640 --> 00:09:52,640
also be useful for other code basis

229
00:09:52,640 --> 00:09:56,080
crypto systems for example the bike or

230
00:09:56,080 --> 00:09:58,720
hqc

231
00:09:59,040 --> 00:10:01,040
and then is the

232
00:10:01,040 --> 00:10:03,600
matrix vector multiplication

233
00:10:03,600 --> 00:10:06,160
here we want to reduce the number of

234
00:10:06,160 --> 00:10:08,320
reducting the vector e

235
00:10:08,320 --> 00:10:10,880
during the multiplication

236
00:10:10,880 --> 00:10:13,760
the resulting occurs because the public

237
00:10:13,760 --> 00:10:17,440
key matrix is a row major matrix so the

238
00:10:17,440 --> 00:10:20,240
multiplication is performed as an inner

239
00:10:20,240 --> 00:10:22,880
product for every row

240
00:10:22,880 --> 00:10:25,120
and the vector e

241
00:10:25,120 --> 00:10:26,480
in other words

242
00:10:26,480 --> 00:10:27,360
we

243
00:10:27,360 --> 00:10:29,200
have to load the

244
00:10:29,200 --> 00:10:32,240
vector into register whenever the

245
00:10:32,240 --> 00:10:34,800
whenever one law is processed

246
00:10:34,800 --> 00:10:38,320
so our strategy for reducing the memory

247
00:10:38,320 --> 00:10:39,360
access

248
00:10:39,360 --> 00:10:41,279
is to process

249
00:10:41,279 --> 00:10:44,959
many laws of the metrics together

250
00:10:44,959 --> 00:10:46,959
but we still want to

251
00:10:46,959 --> 00:10:50,240
rate as many elements in one low as

252
00:10:50,240 --> 00:10:54,240
possible because the contiguous rating

253
00:10:54,240 --> 00:10:55,680
is faster

254
00:10:55,680 --> 00:11:00,640
so we end up we end up coming

255
00:11:00,640 --> 00:11:03,360
coming out to process the public matrix

256
00:11:03,360 --> 00:11:04,079
in

257
00:11:04,079 --> 00:11:08,480
a manner of a black submatrix

258
00:11:08,480 --> 00:11:13,200
we divide the public matrix into 4 by 96

259
00:11:13,200 --> 00:11:14,640
block so

260
00:11:14,640 --> 00:11:16,079
in each block

261
00:11:16,079 --> 00:11:20,640
the vector e is used only once

262
00:11:20,640 --> 00:11:23,440
then we talk about the last k-n

263
00:11:23,440 --> 00:11:24,720
operation

264
00:11:24,720 --> 00:11:26,720
the calculation

265
00:11:26,720 --> 00:11:29,760
besides deriving a shared key the main

266
00:11:29,760 --> 00:11:32,320
computation in encapsulation is to

267
00:11:32,320 --> 00:11:35,279
decode the error vector from a received

268
00:11:35,279 --> 00:11:37,200
cipher text

269
00:11:37,200 --> 00:11:39,600
the decoding algorithm

270
00:11:39,600 --> 00:11:41,440
takes two inputs

271
00:11:41,440 --> 00:11:43,680
one is the received

272
00:11:43,680 --> 00:11:46,240
ciphertext and the other is the secret

273
00:11:46,240 --> 00:11:49,600
copa code from the secret key

274
00:11:49,600 --> 00:11:51,519
in the table below

275
00:11:51,519 --> 00:11:52,880
we list

276
00:11:52,880 --> 00:11:55,600
the four most important components in

277
00:11:55,600 --> 00:11:57,680
encapsulation and

278
00:11:57,680 --> 00:11:58,560
their

279
00:11:58,560 --> 00:12:01,120
optimization methods

280
00:12:01,120 --> 00:12:04,000
we optimize the base dash modification

281
00:12:04,000 --> 00:12:06,720
in the fft component

282
00:12:06,720 --> 00:12:10,399
and we use a new vertex existing method

283
00:12:10,399 --> 00:12:12,959
to implement the final field

284
00:12:12,959 --> 00:12:14,800
multiplication in the

285
00:12:14,800 --> 00:12:17,120
chemistry algorithm

286
00:12:17,120 --> 00:12:20,480
and next we optimize the vanish network

287
00:12:20,480 --> 00:12:23,519
by combining the computation of many

288
00:12:23,519 --> 00:12:26,399
layers together

289
00:12:26,399 --> 00:12:29,360
because the previous implementation used

290
00:12:29,360 --> 00:12:31,920
the b slice multiplication

291
00:12:31,920 --> 00:12:33,839
so we optimized the business

292
00:12:33,839 --> 00:12:37,680
multiplication for the uncode sm4 here

293
00:12:37,680 --> 00:12:40,560
the tricky part here is that

294
00:12:40,560 --> 00:12:43,519
we only have 14 registers but we need to

295
00:12:43,519 --> 00:12:46,880
multiply polynomial of 12 turns

296
00:12:46,880 --> 00:12:49,600
so one solution is that

297
00:12:49,600 --> 00:12:52,240
storing the intermediate turns

298
00:12:52,240 --> 00:12:54,639
in the 14 point which is

299
00:12:54,639 --> 00:12:57,680
when the largest sphering occurs

300
00:12:57,680 --> 00:13:00,160
but moving data between

301
00:13:00,160 --> 00:13:03,279
normal register and 14 point which is

302
00:13:03,279 --> 00:13:06,959
are still cost enough so we have to find

303
00:13:06,959 --> 00:13:10,639
a way of a scanning input operand such

304
00:13:10,639 --> 00:13:11,680
that we

305
00:13:11,680 --> 00:13:15,519
not so many largest sphere occur

306
00:13:15,519 --> 00:13:18,639
so we end up scanning the input operand

307
00:13:18,639 --> 00:13:21,440
like the figure here

308
00:13:21,440 --> 00:13:24,160
in each block of the figure we have

309
00:13:24,160 --> 00:13:25,839
eight tons of input

310
00:13:25,839 --> 00:13:28,720
four terms of length are coming from the

311
00:13:28,720 --> 00:13:30,800
polynomial a and the other four

312
00:13:30,800 --> 00:13:32,959
transform polynomial b

313
00:13:32,959 --> 00:13:36,399
when moving to the next block we only

314
00:13:36,399 --> 00:13:38,639
need borneo operand either from

315
00:13:38,639 --> 00:13:41,920
polynomial a or from polynomial b

316
00:13:41,920 --> 00:13:42,959
and

317
00:13:42,959 --> 00:13:45,120
some intermediate

318
00:13:45,120 --> 00:13:47,839
result here can be shared between the

319
00:13:47,839 --> 00:13:50,880
two adjacent blocks

320
00:13:50,880 --> 00:13:53,760
the other point of the figure is that we

321
00:13:53,760 --> 00:13:56,240
compute the turns from high degree to

322
00:13:56,240 --> 00:13:57,680
low degree

323
00:13:57,680 --> 00:14:00,240
and this way when we compute the low

324
00:14:00,240 --> 00:14:03,519
degree blocks we can reduce the computed

325
00:14:03,519 --> 00:14:05,120
high degree turns

326
00:14:05,120 --> 00:14:08,320
so we don't need an extra phase for

327
00:14:08,320 --> 00:14:11,440
reduce the computed high degree turns to

328
00:14:11,440 --> 00:14:13,920
low degree

329
00:14:13,920 --> 00:14:16,320
and here comes the black chemistry

330
00:14:16,320 --> 00:14:17,680
algorithm

331
00:14:17,680 --> 00:14:20,720
we list the algorithm on this page it

332
00:14:20,720 --> 00:14:23,680
looks complicated but the actual

333
00:14:23,680 --> 00:14:27,279
computation only occurs in 96

334
00:14:27,279 --> 00:14:29,279
and inner product

335
00:14:29,279 --> 00:14:34,160
and 98 a vector multiplies a scale

336
00:14:34,160 --> 00:14:36,240
there is one difference from the

337
00:14:36,240 --> 00:14:39,120
previous implementation from the next

338
00:14:39,120 --> 00:14:40,639
submission

339
00:14:40,639 --> 00:14:42,320
in the submission

340
00:14:42,320 --> 00:14:46,079
they used a inverse-free algorithm

341
00:14:46,079 --> 00:14:48,399
but we compute the inverse

342
00:14:48,399 --> 00:14:51,519
of data in line a

343
00:14:51,519 --> 00:14:54,959
uh we think the inverse can be computed

344
00:14:54,959 --> 00:14:58,720
faster but this faster than the vector

345
00:14:58,720 --> 00:14:59,760
times

346
00:14:59,760 --> 00:15:02,720
vector scalar multiplication here

347
00:15:02,720 --> 00:15:05,199
here we show a new implementation for

348
00:15:05,199 --> 00:15:07,839
the final field multiplication

349
00:15:07,839 --> 00:15:10,079
we call this a red existing

350
00:15:10,079 --> 00:15:11,600
multiplication

351
00:15:11,600 --> 00:15:14,000
here we have a polynomial

352
00:15:14,000 --> 00:15:16,639
of degree 7 a

353
00:15:16,639 --> 00:15:18,959
and we can store the polynomial as a

354
00:15:18,959 --> 00:15:20,880
32-bit integer

355
00:15:20,880 --> 00:15:24,160
the constant turn is stored at

356
00:15:24,160 --> 00:15:29,279
0 and then the bit 4 with a and so on

357
00:15:29,279 --> 00:15:31,759
so if we store the polynomial in this

358
00:15:31,759 --> 00:15:32,639
way

359
00:15:32,639 --> 00:15:35,360
then an integer multiplication

360
00:15:35,360 --> 00:15:37,360
can perform the beta polynomial

361
00:15:37,360 --> 00:15:40,399
multiplication as the equation shown on

362
00:15:40,399 --> 00:15:42,880
this page

363
00:15:42,880 --> 00:15:45,759
because the maximum value tense will

364
00:15:45,759 --> 00:15:48,560
appear at degree a

365
00:15:48,560 --> 00:15:52,320
and its value is a when all coefficients

366
00:15:52,320 --> 00:15:55,680
are 1. so

367
00:15:55,680 --> 00:15:59,920
we can see here that a is this thing 16

368
00:15:59,920 --> 00:16:02,560
so the multiplication won't over for the

369
00:16:02,560 --> 00:16:05,199
very existing format

370
00:16:05,199 --> 00:16:07,839
and we implement the finite field

371
00:16:07,839 --> 00:16:09,440
multiplication with the individual

372
00:16:09,440 --> 00:16:10,880
multiplication

373
00:16:10,880 --> 00:16:13,519
here but

374
00:16:13,519 --> 00:16:17,600
if we store a data in red existing form

375
00:16:17,600 --> 00:16:20,160
then we show our result of bracket

376
00:16:20,160 --> 00:16:22,880
machine algorithm with various settings

377
00:16:22,880 --> 00:16:24,720
in this tables

378
00:16:24,720 --> 00:16:26,480
this is because we

379
00:16:26,480 --> 00:16:28,959
didn't know which combination will be

380
00:16:28,959 --> 00:16:30,320
faster so

381
00:16:30,320 --> 00:16:33,279
we tried every setting to find out the

382
00:16:33,279 --> 00:16:35,440
fattest implementation

383
00:16:35,440 --> 00:16:38,320
on the left table you can see that the

384
00:16:38,320 --> 00:16:40,880
piece dice multiplication is actually

385
00:16:40,880 --> 00:16:42,639
faster than the direct existing

386
00:16:42,639 --> 00:16:44,560
multiplication

387
00:16:44,560 --> 00:16:47,680
but on the right hand side we have the

388
00:16:47,680 --> 00:16:48,839
opposite

389
00:16:48,839 --> 00:16:51,440
result the pre-chemistry with very

390
00:16:51,440 --> 00:16:54,399
existing multiplication is faster than

391
00:16:54,399 --> 00:16:55,600
that one

392
00:16:55,600 --> 00:16:58,720
with the baseline modulation

393
00:16:58,720 --> 00:17:01,519
and the other result is that predicament

394
00:17:01,519 --> 00:17:04,720
c with the inversion is indeed faster

395
00:17:04,720 --> 00:17:07,839
than the inversion free version

396
00:17:07,839 --> 00:17:10,640
so we analyzed the reason why vertical

397
00:17:10,640 --> 00:17:11,839
system

398
00:17:11,839 --> 00:17:14,319
bracket mass is faster

399
00:17:14,319 --> 00:17:17,199
when computing the inner product the

400
00:17:17,199 --> 00:17:19,520
existing multiplication use the basic

401
00:17:19,520 --> 00:17:23,119
reduction which means it accumulated the

402
00:17:23,119 --> 00:17:27,039
product of bit polynomial multiplication

403
00:17:27,039 --> 00:17:29,919
and reduce only once when all the

404
00:17:29,919 --> 00:17:33,120
polynomial multiplication are done

405
00:17:33,120 --> 00:17:35,679
the b slice multiplication on the other

406
00:17:35,679 --> 00:17:38,880
hand cannot do the lazy reduction

407
00:17:38,880 --> 00:17:42,400
because the business data is larger than

408
00:17:42,400 --> 00:17:45,600
the size of oranges

409
00:17:45,600 --> 00:17:49,440
when computing the vector times scale

410
00:17:49,440 --> 00:17:52,000
the latest thing can do the

411
00:17:52,000 --> 00:17:54,320
multiplication with exact length of

412
00:17:54,320 --> 00:17:55,840
polynomials

413
00:17:55,840 --> 00:17:59,200
but the vector length in the basis data

414
00:17:59,200 --> 00:18:03,360
can only be a 32 64 and so on so

415
00:18:03,360 --> 00:18:06,000
the baseless multiplication waste is a

416
00:18:06,000 --> 00:18:08,320
computing power for multiplying

417
00:18:08,320 --> 00:18:10,880
unnecessary terms

418
00:18:10,880 --> 00:18:12,640
when raised the

419
00:18:12,640 --> 00:18:14,880
degree of polynomial

420
00:18:14,880 --> 00:18:18,240
already this thing can do this by a

421
00:18:18,240 --> 00:18:20,640
change its point to the headers of

422
00:18:20,640 --> 00:18:22,000
polynomials

423
00:18:22,000 --> 00:18:25,280
but the basis data has to do the real

424
00:18:25,280 --> 00:18:26,640
logic shift

425
00:18:26,640 --> 00:18:28,480
across registers

426
00:18:28,480 --> 00:18:29,440
so

427
00:18:29,440 --> 00:18:31,840
we think this is the reason why great

428
00:18:31,840 --> 00:18:34,559
existing curriculum is faster than the

429
00:18:34,559 --> 00:18:37,200
baseline implementation

430
00:18:37,200 --> 00:18:40,320
our last optimization for decapsulation

431
00:18:40,320 --> 00:18:43,200
is about a vanish network

432
00:18:43,200 --> 00:18:46,080
this technique is actually quite common

433
00:18:46,080 --> 00:18:49,120
in this kind of multi-layer structure

434
00:18:49,120 --> 00:18:52,799
for example the fft algorithm also has a

435
00:18:52,799 --> 00:18:55,280
multi-layer structure

436
00:18:55,280 --> 00:18:58,720
when computing the vanish network

437
00:18:58,720 --> 00:19:00,799
we can combine

438
00:19:00,799 --> 00:19:03,200
the computation for many layers

439
00:19:03,200 --> 00:19:06,160
to separate memory assets

440
00:19:06,160 --> 00:19:09,600
for example in the figure on the slides

441
00:19:09,600 --> 00:19:12,240
we can combine the computation in the

442
00:19:12,240 --> 00:19:14,400
middle three years

443
00:19:14,400 --> 00:19:17,360
instead of loading and writing back all

444
00:19:17,360 --> 00:19:20,400
the data for every day

445
00:19:20,400 --> 00:19:23,280
finally we show our performance results

446
00:19:23,280 --> 00:19:25,120
the conclusion

447
00:19:25,120 --> 00:19:27,760
the number here in the table includes

448
00:19:27,760 --> 00:19:28,559
the

449
00:19:28,559 --> 00:19:31,440
reading and writing of the fresh memory

450
00:19:31,440 --> 00:19:33,679
because we store the public key in the

451
00:19:33,679 --> 00:19:35,280
fresh memory

452
00:19:35,280 --> 00:19:37,760
although there are still some numbers

453
00:19:37,760 --> 00:19:40,480
that we cannot show here because of the

454
00:19:40,480 --> 00:19:43,679
public is larger than the freshmen

455
00:19:43,679 --> 00:19:46,799
we think all the optimization techniques

456
00:19:46,799 --> 00:19:50,880
can also apply to the situation that the

457
00:19:50,880 --> 00:19:54,480
public is streaming through the network

458
00:19:54,480 --> 00:19:55,840
so uh

459
00:19:55,840 --> 00:19:58,480
there are actually

460
00:19:58,480 --> 00:20:00,640
some board with

461
00:20:00,640 --> 00:20:03,200
enough storage space for the classic

462
00:20:03,200 --> 00:20:04,480
memories

463
00:20:04,480 --> 00:20:06,880
available on the market

464
00:20:06,880 --> 00:20:10,000
so uh comparing to the latest base

465
00:20:10,000 --> 00:20:11,760
cayenne scheme

466
00:20:11,760 --> 00:20:12,640
our

467
00:20:12,640 --> 00:20:16,000
encapsulation is about the same speed to

468
00:20:16,000 --> 00:20:18,880
the farthest finalist

469
00:20:18,880 --> 00:20:21,760
but our calculation is about four to

470
00:20:21,760 --> 00:20:24,400
seven times zero

471
00:20:24,400 --> 00:20:27,200
and that's it for all my talk thank you

472
00:20:27,200 --> 00:20:30,520
for your lesson

