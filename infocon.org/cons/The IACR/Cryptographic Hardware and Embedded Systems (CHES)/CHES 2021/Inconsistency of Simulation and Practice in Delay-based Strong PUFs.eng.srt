1
00:00:00,719 --> 00:00:03,360
hello everyone this is anita away

2
00:00:03,360 --> 00:00:05,920
in this time i would like to present our

3
00:00:05,920 --> 00:00:07,279
research work which is about

4
00:00:07,279 --> 00:00:10,160
inconsistency of simulation and practice

5
00:00:10,160 --> 00:00:12,719
in delay astronomicals this is a joint

6
00:00:12,719 --> 00:00:16,320
work with my advisor amin moradi

7
00:00:16,320 --> 00:00:18,640
well at first i would like to give you a

8
00:00:18,640 --> 00:00:21,199
brief introduction about path and its

9
00:00:21,199 --> 00:00:24,640
applications why we are using puffs

10
00:00:24,640 --> 00:00:26,640
in order to limit the secure memory

11
00:00:26,640 --> 00:00:29,760
usage and avoid attacks on non-mulattoin

12
00:00:29,760 --> 00:00:31,039
memories

13
00:00:31,039 --> 00:00:33,040
physical hardware primitives such as

14
00:00:33,040 --> 00:00:36,160
physical unclonable functions paths have

15
00:00:36,160 --> 00:00:37,680
been introduced to the world of the

16
00:00:37,680 --> 00:00:40,320
embedded devices two decades ago

17
00:00:40,320 --> 00:00:43,200
such functions supposedly provide a

18
00:00:43,200 --> 00:00:45,039
secure hardware platform with

19
00:00:45,039 --> 00:00:47,440
lightweight features for example low

20
00:00:47,440 --> 00:00:50,000
energy consumption or small area

21
00:00:50,000 --> 00:00:54,239
footprint these fingerprint of devices

22
00:00:54,239 --> 00:00:57,039
are using challenge response mechanism

23
00:00:57,039 --> 00:00:59,280
this mechanism is the main approach of

24
00:00:59,280 --> 00:01:01,359
these only functions with the unique

25
00:01:01,359 --> 00:01:03,840
behavior for each path

26
00:01:03,840 --> 00:01:07,200
in more detail if i want to explain it's

27
00:01:07,200 --> 00:01:09,520
that it's like that an ambient and

28
00:01:09,520 --> 00:01:13,119
unpredictable stable and unique response

29
00:01:13,119 --> 00:01:15,520
is answer to a random and big challenge

30
00:01:15,520 --> 00:01:17,520
to create a set of challenge response

31
00:01:17,520 --> 00:01:19,280
per crps

32
00:01:19,280 --> 00:01:22,000
it means that each path in idle

33
00:01:22,000 --> 00:01:26,320
conditions generates a reliable uniform

34
00:01:26,320 --> 00:01:28,400
and the unique response but not the

35
00:01:28,400 --> 00:01:30,960
predictable one so i should highlight

36
00:01:30,960 --> 00:01:34,960
that our main focus here in this world

37
00:01:34,960 --> 00:01:38,880
is strongly based pops

38
00:01:39,600 --> 00:01:40,640
so

39
00:01:40,640 --> 00:01:43,360
uh in the path area we have several

40
00:01:43,360 --> 00:01:45,759
challenges that we will talk about just

41
00:01:45,759 --> 00:01:47,439
uh two of

42
00:01:47,439 --> 00:01:50,720
the first one is ml attacks or machine

43
00:01:50,720 --> 00:01:52,720
learning attacks

44
00:01:52,720 --> 00:01:55,680
according to the recent publications um

45
00:01:55,680 --> 00:01:57,920
machine learning attacks or let's say

46
00:01:57,920 --> 00:02:00,159
pure machine learning attacks are

47
00:02:00,159 --> 00:02:02,240
identified as the most common and

48
00:02:02,240 --> 00:02:04,799
effective threats which can be performed

49
00:02:04,799 --> 00:02:07,520
with different classifier algorithm as

50
00:02:07,520 --> 00:02:09,038
you can see

51
00:02:09,038 --> 00:02:09,919
in the

52
00:02:09,919 --> 00:02:11,360
left figure

53
00:02:11,360 --> 00:02:14,000
there some learners like logistic

54
00:02:14,000 --> 00:02:16,239
regression super vector machines

55
00:02:16,239 --> 00:02:19,200
decision trees or using a black box

56
00:02:19,200 --> 00:02:22,480
learning algorithm like a n are usable

57
00:02:22,480 --> 00:02:25,280
in uh puff learnings

58
00:02:25,280 --> 00:02:28,319
actually the goal of puff modeling is to

59
00:02:28,319 --> 00:02:31,280
create a model of the same of the strong

60
00:02:31,280 --> 00:02:33,680
costs to generate the same response of

61
00:02:33,680 --> 00:02:36,239
the same given challenges to the

62
00:02:36,239 --> 00:02:38,000
parts

63
00:02:38,000 --> 00:02:40,319
so afterwards we focus on the next

64
00:02:40,319 --> 00:02:41,920
challenging point which is pop's

65
00:02:41,920 --> 00:02:44,080
hardware implementation especially the

66
00:02:44,080 --> 00:02:46,480
delay-based ones the most difficult

67
00:02:46,480 --> 00:02:48,000
challenge is to achieve an

68
00:02:48,000 --> 00:02:50,000
implementation with physical

69
00:02:50,000 --> 00:02:52,239
characteristic not far from the idle

70
00:02:52,239 --> 00:02:53,599
conditions

71
00:02:53,599 --> 00:02:56,160
along the same line delay-based parts

72
00:02:56,160 --> 00:02:58,480
are prone to environmental noise like

73
00:02:58,480 --> 00:03:02,319
temperature and supply voltage variation

74
00:03:02,319 --> 00:03:04,560
this motivated the researchers to deal

75
00:03:04,560 --> 00:03:06,879
with various hardware implementations of

76
00:03:06,879 --> 00:03:09,680
delay baseball now i think it's a proper

77
00:03:09,680 --> 00:03:12,000
time to talk about our motivation and

78
00:03:12,000 --> 00:03:13,360
collaboration

79
00:03:13,360 --> 00:03:15,440
the main question is that

80
00:03:15,440 --> 00:03:18,319
are all ml attacks in simulation domain

81
00:03:18,319 --> 00:03:20,800
consistent with the same accuracy and

82
00:03:20,800 --> 00:03:23,680
success rate in the real world

83
00:03:23,680 --> 00:03:25,920
to answer this question we observe

84
00:03:25,920 --> 00:03:28,000
various the most common delay based off

85
00:03:28,000 --> 00:03:31,200
arctic architectures like arbiter path

86
00:03:31,200 --> 00:03:33,840
and their evaluation matrix like

87
00:03:33,840 --> 00:03:37,519
uniformity or the opposite one bias

88
00:03:37,519 --> 00:03:40,080
or other metrics like um the uniqueness

89
00:03:40,080 --> 00:03:42,319
and reliability that can affect parts

90
00:03:42,319 --> 00:03:46,799
robustness against the modern attacks

91
00:03:46,799 --> 00:03:49,920
in this way we choose our case study as

92
00:03:49,920 --> 00:03:53,519
ipop architecture from just 2019 and

93
00:03:53,519 --> 00:03:55,680
it's classical lr based attack as a

94
00:03:55,680 --> 00:03:58,239
splitting eye path which is again

95
00:03:58,239 --> 00:04:01,360
presented in chess for 2020.

96
00:04:01,360 --> 00:04:04,400
our practice investigation uh on real

97
00:04:04,400 --> 00:04:07,439
data sets collected from more than

98
00:04:07,439 --> 00:04:09,280
one hundred thousand various ipop

99
00:04:09,280 --> 00:04:12,319
implementation from uh 100 fpga cluster

100
00:04:12,319 --> 00:04:14,480
we will explain in more details next

101
00:04:14,480 --> 00:04:16,959
slides

102
00:04:17,600 --> 00:04:18,478
so

103
00:04:18,478 --> 00:04:21,600
one of the most uh common stronghold

104
00:04:21,600 --> 00:04:23,759
primitive is arbiter puff which is

105
00:04:23,759 --> 00:04:25,600
applied in many delay-based puff

106
00:04:25,600 --> 00:04:27,040
architectures

107
00:04:27,040 --> 00:04:29,600
as shown in this figure the trigger

108
00:04:29,600 --> 00:04:33,919
signal should pass n stages which of um

109
00:04:33,919 --> 00:04:36,880
which is a controlled by challenge bit

110
00:04:36,880 --> 00:04:40,000
at the end an arbiter or a flip-flop

111
00:04:40,000 --> 00:04:42,000
decides the final response of the

112
00:04:42,000 --> 00:04:44,639
arbiter path depending on which delay

113
00:04:44,639 --> 00:04:48,240
line and is faster than the other one

114
00:04:48,240 --> 00:04:48,960
so

115
00:04:48,960 --> 00:04:52,000
for success uh path modeling we need a

116
00:04:52,000 --> 00:04:54,000
proper puff model

117
00:04:54,000 --> 00:04:57,280
as you can see in this uh equation

118
00:04:57,280 --> 00:04:58,479
uh

119
00:04:58,479 --> 00:05:01,440
which is in this equation it is commonly

120
00:05:01,440 --> 00:05:03,280
used as a linear delay model of

121
00:05:03,280 --> 00:05:05,680
arbitrary power in this equation you can

122
00:05:05,680 --> 00:05:08,000
see that there is a

123
00:05:08,000 --> 00:05:10,560
vector of weights that these weights

124
00:05:10,560 --> 00:05:13,360
represent the physical characteristic of

125
00:05:13,360 --> 00:05:16,000
each orbital puff switch

126
00:05:16,000 --> 00:05:19,199
also you can see the feature vector

127
00:05:19,199 --> 00:05:21,120
which is drawing from that given

128
00:05:21,120 --> 00:05:23,680
challenge c

129
00:05:23,680 --> 00:05:26,080
at the end the arbiter is presented as a

130
00:05:26,080 --> 00:05:28,560
unit sine function to decide the

131
00:05:28,560 --> 00:05:32,320
response should be 0 or 1.

132
00:05:32,320 --> 00:05:34,320
this additive linear model can be

133
00:05:34,320 --> 00:05:36,240
extended to other delay based path

134
00:05:36,240 --> 00:05:39,039
primitives like ips or orbital path

135
00:05:39,039 --> 00:05:42,000
in order to increase the complexity of

136
00:05:42,000 --> 00:05:44,240
the path model and boost the ml

137
00:05:44,240 --> 00:05:46,880
resistance x or arbitrary pop has been

138
00:05:46,880 --> 00:05:51,360
applied as a fundamental element as well

139
00:05:51,360 --> 00:05:54,400
we will talk about uh the xor arbiter

140
00:05:54,400 --> 00:05:57,600
pop and arbiter of in our cases study

141
00:05:57,600 --> 00:06:00,479
architecture ipath later

142
00:06:00,479 --> 00:06:02,479
so now it's a

143
00:06:02,479 --> 00:06:04,400
time to give a brief

144
00:06:04,400 --> 00:06:07,840
background about uh the two common

145
00:06:07,840 --> 00:06:11,120
learners lr and a m which is the most

146
00:06:11,120 --> 00:06:13,440
common in path in the strong pop

147
00:06:13,440 --> 00:06:15,199
modeling

148
00:06:15,199 --> 00:06:18,080
well the goal of lr or logistic

149
00:06:18,080 --> 00:06:20,639
regression like other modern algorithm

150
00:06:20,639 --> 00:06:23,039
is to find the best fit and optimize

151
00:06:23,039 --> 00:06:24,000
model

152
00:06:24,000 --> 00:06:25,840
models which means a

153
00:06:25,840 --> 00:06:27,919
high prediction accuracy and also

154
00:06:27,919 --> 00:06:29,840
minimum error rate between the

155
00:06:29,840 --> 00:06:31,520
prediction

156
00:06:31,520 --> 00:06:33,840
answer or prediction output and the real

157
00:06:33,840 --> 00:06:35,440
output

158
00:06:35,440 --> 00:06:36,240
so

159
00:06:36,240 --> 00:06:38,479
by applying the proper activation

160
00:06:38,479 --> 00:06:41,360
function and enough iteration as you can

161
00:06:41,360 --> 00:06:44,720
see here for example that the

162
00:06:44,720 --> 00:06:46,400
lr can have

163
00:06:46,400 --> 00:06:48,639
lots of these iterations

164
00:06:48,639 --> 00:06:50,960
an efficient model can describe the good

165
00:06:50,960 --> 00:06:53,520
relationship between the output or

166
00:06:53,520 --> 00:06:55,840
dependent variable which is here their

167
00:06:55,840 --> 00:06:58,800
path responses and a set of

168
00:06:58,800 --> 00:07:00,720
independent variables which is here the

169
00:07:00,720 --> 00:07:03,840
path challenges

170
00:07:04,639 --> 00:07:07,199
besides the classifier algorithms like

171
00:07:07,199 --> 00:07:07,919
the

172
00:07:07,919 --> 00:07:10,400
mentioned logistic regression algorithm

173
00:07:10,400 --> 00:07:13,599
a ns or mlps are also able to learn the

174
00:07:13,599 --> 00:07:16,479
path models with the same goal this

175
00:07:16,479 --> 00:07:19,680
network consists of an input layer

176
00:07:19,680 --> 00:07:22,639
an output layer and several hidden layer

177
00:07:22,639 --> 00:07:24,960
which depends on the complexity of the

178
00:07:24,960 --> 00:07:28,240
model can be extended or reduced in this

179
00:07:28,240 --> 00:07:31,599
world we have chosen a composite pop

180
00:07:31,599 --> 00:07:33,919
architecture which has more complex

181
00:07:33,919 --> 00:07:36,160
model compared to the basic elements

182
00:07:36,160 --> 00:07:39,680
like arbitrary puff as illustrated here

183
00:07:39,680 --> 00:07:42,080
this interposed path or ipob

184
00:07:42,080 --> 00:07:45,039
architecture has two x or orbital puff

185
00:07:45,039 --> 00:07:48,479
layers top layers for each layer it

186
00:07:48,479 --> 00:07:52,160
sticks or layers or bottom layer y x or

187
00:07:52,160 --> 00:07:53,919
from arbiter box

188
00:07:53,919 --> 00:07:56,720
the one with response of the top layer

189
00:07:56,720 --> 00:08:00,720
from n bit x x or arbiter pulse place

190
00:08:00,720 --> 00:08:02,720
the role of the interval speed for the

191
00:08:02,720 --> 00:08:05,440
challenge set of the bottom layer

192
00:08:05,440 --> 00:08:08,160
as a result n plus 1 challenge bits are

193
00:08:08,160 --> 00:08:11,120
given to the bottom layer

194
00:08:11,120 --> 00:08:13,440
which is the n plus one bit yx or

195
00:08:13,440 --> 00:08:16,240
arbiter path to generate a single bit uh

196
00:08:16,240 --> 00:08:19,440
final response in the original ipof

197
00:08:19,440 --> 00:08:21,759
paper it has been shown that the

198
00:08:21,759 --> 00:08:25,199
classical lr or nlp attacks are not

199
00:08:25,199 --> 00:08:28,800
completely successful for xy ipad for

200
00:08:28,800 --> 00:08:30,960
instance it has been shown that the

201
00:08:30,960 --> 00:08:36,080
classical lr will be ended to maximum 75

202
00:08:36,080 --> 00:08:38,799
percent prediction accuracy on different

203
00:08:38,799 --> 00:08:41,839
ipad variants in which it's not a

204
00:08:41,839 --> 00:08:43,679
efficient accuracy

205
00:08:43,679 --> 00:08:45,200
however

206
00:08:45,200 --> 00:08:48,560
in chess 2020 splitting eye path attack

207
00:08:48,560 --> 00:08:50,800
applies a divide and conquer method to

208
00:08:50,800 --> 00:08:53,279
successfully break different intercourse

209
00:08:53,279 --> 00:08:56,640
path variants up to one nine and eight

210
00:08:56,640 --> 00:08:59,519
eight uh version in a nutshell this new

211
00:08:59,519 --> 00:09:02,640
lr splitting attack divides the x y i

212
00:09:02,640 --> 00:09:05,040
pop into two x or our guitar puff

213
00:09:05,040 --> 00:09:06,240
components

214
00:09:06,240 --> 00:09:08,959
as a first step the attacker chooses uh

215
00:09:08,959 --> 00:09:11,839
chooses a random uniform interpose beat

216
00:09:11,839 --> 00:09:14,800
for n plus uh one with challenge of the

217
00:09:14,800 --> 00:09:16,160
bottom layer

218
00:09:16,160 --> 00:09:19,680
then um the attacker applies a classic

219
00:09:19,680 --> 00:09:22,560
lr attack on the bottom layer as a

220
00:09:22,560 --> 00:09:23,839
divided

221
00:09:23,839 --> 00:09:25,440
or arbitrary path

222
00:09:25,440 --> 00:09:28,640
and then just stops at a rough model uh

223
00:09:28,640 --> 00:09:31,360
accuracy with the threshold of 65

224
00:09:31,360 --> 00:09:33,040
prediction accuracy

225
00:09:33,040 --> 00:09:36,080
then filter the crp sets by choosing the

226
00:09:36,080 --> 00:09:38,959
correct interposed beat which is ks by

227
00:09:38,959 --> 00:09:39,920
the

228
00:09:39,920 --> 00:09:42,080
not very accurate learn model from the

229
00:09:42,080 --> 00:09:43,600
bottom layer

230
00:09:43,600 --> 00:09:46,160
afterwards in the prefabs step the

231
00:09:46,160 --> 00:09:48,640
attacker applies classic lr attack on

232
00:09:48,640 --> 00:09:51,600
the top layer with uh to

233
00:09:51,600 --> 00:09:55,760
achieve high accuracy and here again

234
00:09:55,760 --> 00:09:57,920
the attacker comes back to apply the

235
00:09:57,920 --> 00:10:00,320
classic lr attack on the bottom layer

236
00:10:00,320 --> 00:10:02,959
with the correct predictive interpol

237
00:10:02,959 --> 00:10:06,160
speed and this loop or this iteration

238
00:10:06,160 --> 00:10:08,320
can be happened multiple times to

239
00:10:08,320 --> 00:10:11,440
achieve a high accuracy

240
00:10:11,440 --> 00:10:15,120
this splitting lr attack will be applied

241
00:10:15,120 --> 00:10:18,399
in our method to see how it can be

242
00:10:18,399 --> 00:10:20,560
different in simulation

243
00:10:20,560 --> 00:10:24,240
and in the practice domain

244
00:10:24,240 --> 00:10:26,800
before that i would like to explain a

245
00:10:26,800 --> 00:10:30,000
bit about the fpga implementation of

246
00:10:30,000 --> 00:10:31,360
delay-based

247
00:10:31,360 --> 00:10:34,640
paths and its variants

248
00:10:34,640 --> 00:10:37,519
so since our main goal is to analyze the

249
00:10:37,519 --> 00:10:39,600
effect of different path metrics on the

250
00:10:39,600 --> 00:10:41,760
efficiency of anal attack especially in

251
00:10:41,760 --> 00:10:44,959
experimental domain we need to

252
00:10:44,959 --> 00:10:46,959
investigate our assumption on real

253
00:10:46,959 --> 00:10:49,279
hardware implementation

254
00:10:49,279 --> 00:10:53,120
um here we will focus on fpgas due to

255
00:10:53,120 --> 00:10:55,120
their reconfigurability and

256
00:10:55,120 --> 00:10:57,279
affordability in the market

257
00:10:57,279 --> 00:11:00,560
so as presented in the left figure you

258
00:11:00,560 --> 00:11:03,600
can see our experimental setup which

259
00:11:03,600 --> 00:11:06,959
consists of 100 instances of

260
00:11:06,959 --> 00:11:09,920
buses board buses three boards

261
00:11:09,920 --> 00:11:14,480
where xilinx arctic 7 fpga is integrated

262
00:11:14,480 --> 00:11:16,959
to explain our path implementation we

263
00:11:16,959 --> 00:11:19,279
need to say briefly about

264
00:11:19,279 --> 00:11:21,200
fpga structures

265
00:11:21,200 --> 00:11:23,440
the general fpga architecture consists

266
00:11:23,440 --> 00:11:25,519
of three types of models which one of

267
00:11:25,519 --> 00:11:28,079
them is a configurable logic block

268
00:11:28,079 --> 00:11:30,320
syllabi as shown in

269
00:11:30,320 --> 00:11:33,200
the right figure you can see

270
00:11:33,200 --> 00:11:36,240
and each of this block has two slides

271
00:11:36,240 --> 00:11:40,160
each slice contains four lut or let's

272
00:11:40,160 --> 00:11:43,040
say bills and they are

273
00:11:43,040 --> 00:11:43,839
from

274
00:11:43,839 --> 00:11:45,680
bill a bill b

275
00:11:45,680 --> 00:11:49,600
bill c and bill d it is not worthy to

276
00:11:49,600 --> 00:11:52,079
say that in apop implementation we

277
00:11:52,079 --> 00:11:55,120
implemented each switch stage by five to

278
00:11:55,120 --> 00:11:56,480
two uh

279
00:11:56,480 --> 00:11:59,760
lookup tables therefore we have applied

280
00:11:59,760 --> 00:12:01,760
two kinds of patterns in our

281
00:12:01,760 --> 00:12:04,079
implementation the first pattern is

282
00:12:04,079 --> 00:12:06,320
random pattern and the second one is

283
00:12:06,320 --> 00:12:08,399
fixed pattern

284
00:12:08,399 --> 00:12:10,480
the random pattern is that one of the

285
00:12:10,480 --> 00:12:13,839
bells can be randomly selected for each

286
00:12:13,839 --> 00:12:16,079
lookup tables in each slice as i

287
00:12:16,079 --> 00:12:18,320
explained there it means that we have

288
00:12:18,320 --> 00:12:20,800
four to the power of n cases

289
00:12:20,800 --> 00:12:22,959
we refer to this strategy as random

290
00:12:22,959 --> 00:12:26,079
placement the next one is as fixed

291
00:12:26,079 --> 00:12:27,120
pattern

292
00:12:27,120 --> 00:12:29,279
in this strategy

293
00:12:29,279 --> 00:12:32,480
we can place just only one uncut table

294
00:12:32,480 --> 00:12:35,680
in each slice like just bell b as you

295
00:12:35,680 --> 00:12:39,200
can see in the right figure then

296
00:12:39,200 --> 00:12:42,079
we also have the option to place two

297
00:12:42,079 --> 00:12:44,639
lookup tables in each slice by fixing

298
00:12:44,639 --> 00:12:48,320
the pattern of usables like a b or ac or

299
00:12:48,320 --> 00:12:50,560
water and so on

300
00:12:50,560 --> 00:12:53,519
and six different placements uh are

301
00:12:53,519 --> 00:12:56,800
provided here and the final option is to

302
00:12:56,800 --> 00:13:00,240
occupy all lookup tables in one slice it

303
00:13:00,240 --> 00:13:03,920
means that all of the builds can be used

304
00:13:03,920 --> 00:13:05,600
you should mention that it is very

305
00:13:05,600 --> 00:13:08,160
challenging to achieve a similar routine

306
00:13:08,160 --> 00:13:10,639
for the path delay lines of an

307
00:13:10,639 --> 00:13:12,079
arbitrary path

308
00:13:12,079 --> 00:13:14,480
applying some constraints such as fixing

309
00:13:14,480 --> 00:13:16,320
the placement or keeping the hierarchy

310
00:13:16,320 --> 00:13:17,839
can mitigate

311
00:13:17,839 --> 00:13:20,480
such challenges as the cases study we

312
00:13:20,480 --> 00:13:24,240
focus on 64-bit 1-5-ipaf as the target

313
00:13:24,240 --> 00:13:27,040
path primitive we follow them

314
00:13:27,040 --> 00:13:28,079
our in

315
00:13:28,079 --> 00:13:31,519
placement strategies in constructed 1011

316
00:13:31,519 --> 00:13:33,760
implementation design which means

317
00:13:33,760 --> 00:13:37,120
that we have 1000 fpga bt string with

318
00:13:37,120 --> 00:13:39,199
random placement and 11 with the

319
00:13:39,199 --> 00:13:41,760
suggested fixed pattern based uh our

320
00:13:41,760 --> 00:13:44,959
mention strategy

321
00:13:45,040 --> 00:13:46,959
before we want to explain which design

322
00:13:46,959 --> 00:13:48,800
and why that has been chosen for the

323
00:13:48,800 --> 00:13:50,880
rest of our observation we should

324
00:13:50,880 --> 00:13:52,959
briefly recall

325
00:13:52,959 --> 00:13:55,040
several path metrics that are effective

326
00:13:55,040 --> 00:13:58,240
in pops functionality in the following

327
00:13:58,240 --> 00:14:00,480
uh three important path metrics relevant

328
00:14:00,480 --> 00:14:03,120
to delay based off designs are restated

329
00:14:03,120 --> 00:14:05,279
which are considered in our practical

330
00:14:05,279 --> 00:14:08,639
analysis as well uniformity reliability

331
00:14:08,639 --> 00:14:11,600
and uniqueness sake of gravity here i

332
00:14:11,600 --> 00:14:14,079
focus on uniformity which is our main

333
00:14:14,079 --> 00:14:17,279
criteria in this world considering a

334
00:14:17,279 --> 00:14:20,320
stateless pop primitive with single bit

335
00:14:20,320 --> 00:14:22,480
response this parameter estimates the

336
00:14:22,480 --> 00:14:26,000
proportion of ones in the path responses

337
00:14:26,000 --> 00:14:29,839
an idle value for uniformity similar to

338
00:14:29,839 --> 00:14:31,760
uniqueness is

339
00:14:31,760 --> 00:14:32,880
50

340
00:14:32,880 --> 00:14:34,519
as it reflects the

341
00:14:34,519 --> 00:14:36,560
unpredictability of the response of a

342
00:14:36,560 --> 00:14:41,279
stateless single bit path primitive

343
00:14:41,519 --> 00:14:44,000
in this regard by focusing on a single

344
00:14:44,000 --> 00:14:47,040
device which is one of the those 100

345
00:14:47,040 --> 00:14:51,040
fpga boards the xmi all mentioned 111

346
00:14:51,040 --> 00:14:52,680
designs collected

347
00:14:52,680 --> 00:14:56,079
1000 crps where challenges are selected

348
00:14:56,079 --> 00:14:58,880
uniformly at random and extracted the

349
00:14:58,880 --> 00:15:01,519
uniformity of all arbiter puff instances

350
00:15:01,519 --> 00:15:03,760
as well as the inter post top design

351
00:15:03,760 --> 00:15:06,720
final responses individually for each

352
00:15:06,720 --> 00:15:07,839
design

353
00:15:07,839 --> 00:15:10,160
to finalize one of the design as the

354
00:15:10,160 --> 00:15:12,639
best one we have considered the

355
00:15:12,639 --> 00:15:14,959
uniformity since the reliability and

356
00:15:14,959 --> 00:15:16,079
uniqueness

357
00:15:16,079 --> 00:15:18,880
metrics are mostly the same

358
00:15:18,880 --> 00:15:22,079
this table lists the uniformity of four

359
00:15:22,079 --> 00:15:24,320
finalists for each placement strategy

360
00:15:24,320 --> 00:15:26,480
random or pattern you selected the first

361
00:15:26,480 --> 00:15:28,399
finalist round

362
00:15:28,399 --> 00:15:31,120
one and pattern one has the one with the

363
00:15:31,120 --> 00:15:35,120
best average uniformity overall all um

364
00:15:35,120 --> 00:15:37,600
arbitar path instances while keeping the

365
00:15:37,600 --> 00:15:40,160
uniformity of the final response in the

366
00:15:40,160 --> 00:15:43,519
range of 40 percent to 60 percent at

367
00:15:43,519 --> 00:15:46,240
this at the second final is round two

368
00:15:46,240 --> 00:15:48,720
and pattern two as the one with the best

369
00:15:48,720 --> 00:15:51,680
uniformity for the final responses

370
00:15:51,680 --> 00:15:54,560
uh we have chosen the design identified

371
00:15:54,560 --> 00:15:57,120
in the round one in the first floor of

372
00:15:57,120 --> 00:16:00,240
this table

373
00:16:01,120 --> 00:16:03,519
using the mentioned fpga cluster we

374
00:16:03,519 --> 00:16:06,720
evaluated the chosen design on all 100

375
00:16:06,720 --> 00:16:09,759
devices while collecting 1 million crt

376
00:16:09,759 --> 00:16:12,800
for each device we present the result of

377
00:16:12,800 --> 00:16:15,759
the evaluation of our chosen 1 5 ipod

378
00:16:15,759 --> 00:16:17,920
design in terms of reliability

379
00:16:17,920 --> 00:16:19,920
uniqueness and

380
00:16:19,920 --> 00:16:21,279
uniformity

381
00:16:21,279 --> 00:16:23,360
it is presented

382
00:16:23,360 --> 00:16:25,360
that this design enjoys a higher

383
00:16:25,360 --> 00:16:28,480
reliability but not very idle uniqueness

384
00:16:28,480 --> 00:16:30,320
and value which is because of small

385
00:16:30,320 --> 00:16:34,560
process variation in fpga implementation

386
00:16:34,560 --> 00:16:36,800
also we can see an almost normal

387
00:16:36,800 --> 00:16:39,680
distribution for the uniformity of each

388
00:16:39,680 --> 00:16:42,000
orbital part instance being in the range

389
00:16:42,000 --> 00:16:45,440
of 31 to 54

390
00:16:45,440 --> 00:16:48,399
percent it is important to mention that

391
00:16:48,399 --> 00:16:52,160
the uniformity of the final response uh

392
00:16:52,160 --> 00:16:57,199
ipod keeps its good range of 45 to

393
00:16:57,199 --> 00:17:01,519
55 in the children design

394
00:17:02,160 --> 00:17:04,799
well here we wanted to investigate the

395
00:17:04,799 --> 00:17:07,280
non-uniformity effect on real data set

396
00:17:07,280 --> 00:17:10,319
of uh ipof attack afterwards we

397
00:17:10,319 --> 00:17:13,599
investigate uh how is going on on our

398
00:17:13,599 --> 00:17:16,839
real data set with existing splitting lr

399
00:17:16,839 --> 00:17:19,679
attack based on the simulation result

400
00:17:19,679 --> 00:17:22,000
given in previous chess paper the

401
00:17:22,000 --> 00:17:23,919
splitting knife of attack should be able

402
00:17:23,919 --> 00:17:25,679
to successfully

403
00:17:25,679 --> 00:17:28,000
which means with the high prediction

404
00:17:28,000 --> 00:17:29,919
accuracy and

405
00:17:29,919 --> 00:17:32,799
the success rate of one uh break them

406
00:17:32,799 --> 00:17:35,760
this uh hyperbarian which means one five

407
00:17:35,760 --> 00:17:40,559
uh ipod using uh 500 000 uh either noise

408
00:17:40,559 --> 00:17:43,600
fury or noise conducted this attack on

409
00:17:43,600 --> 00:17:46,720
our 100 fpga devices with the

410
00:17:46,720 --> 00:17:49,039
corresponding ipod variant using the

411
00:17:49,039 --> 00:17:51,840
design that we have chosen and mentioned

412
00:17:51,840 --> 00:17:54,240
earlier with the larger data set of 1

413
00:17:54,240 --> 00:17:56,880
million crp with the overall reliability

414
00:17:56,880 --> 00:17:58,240
of 96

415
00:17:58,240 --> 00:18:00,720
percent we then perform the original

416
00:18:00,720 --> 00:18:03,200
splitting eye buff attack on our noisy

417
00:18:03,200 --> 00:18:06,240
and noise free crp sets leading to

418
00:18:06,240 --> 00:18:09,840
accuracy of maximum 72 percent as shown

419
00:18:09,840 --> 00:18:12,640
as you can see here and mostly the range

420
00:18:12,640 --> 00:18:15,760
of the prediction accuracy will not go

421
00:18:15,760 --> 00:18:19,200
further than 72 percent forcey to

422
00:18:19,200 --> 00:18:20,400
mention that

423
00:18:20,400 --> 00:18:22,640
we have using the pipeline library of

424
00:18:22,640 --> 00:18:25,600
version zero zero seven and eight uh for

425
00:18:25,600 --> 00:18:27,919
a splitting eye puff attack since the

426
00:18:27,919 --> 00:18:30,000
splitting ipof attack does not achieve

427
00:18:30,000 --> 00:18:32,400
an adequate prediction accuracy when the

428
00:18:32,400 --> 00:18:33,600
target

429
00:18:33,600 --> 00:18:35,840
targeted path is slightly biased or

430
00:18:35,840 --> 00:18:38,559
non-uniform our attention goes to other

431
00:18:38,559 --> 00:18:41,440
learners like a m or mlp which is also

432
00:18:41,440 --> 00:18:43,840
embedded in dimension pipe up library

433
00:18:43,840 --> 00:18:46,799
here in this graph we show the result of

434
00:18:46,799 --> 00:18:48,960
the a n attacks conducted to the same

435
00:18:48,960 --> 00:18:51,600
non-uniform real data sets

436
00:18:51,600 --> 00:18:55,600
at first we applied the naive a n as the

437
00:18:55,600 --> 00:18:57,120
black box

438
00:18:57,120 --> 00:18:59,440
attack which achieves higher prediction

439
00:18:59,440 --> 00:19:01,919
accuracy compared to

440
00:19:01,919 --> 00:19:04,559
splitting eye path

441
00:19:04,559 --> 00:19:06,880
the prediction accuracy of this attack

442
00:19:06,880 --> 00:19:09,600
is in range of 83

443
00:19:09,600 --> 00:19:11,679
to 93 percent

444
00:19:11,679 --> 00:19:15,120
on the other hand by substituting the lr

445
00:19:15,120 --> 00:19:17,520
learner of the splitting eyepop attack

446
00:19:17,520 --> 00:19:19,600
which is presented in previous chess

447
00:19:19,600 --> 00:19:22,400
with an new learner which means that

448
00:19:22,400 --> 00:19:26,160
with a learner we achieve a more

449
00:19:26,160 --> 00:19:28,320
stable learner's behavior leading to a

450
00:19:28,320 --> 00:19:30,720
higher and narrow prediction accuracy of

451
00:19:30,720 --> 00:19:34,080
89 to 93 percent

452
00:19:34,080 --> 00:19:36,799
it means that our learner substituting

453
00:19:36,799 --> 00:19:39,200
solution can solve this non-uniformity

454
00:19:39,200 --> 00:19:41,440
effect on real data sets note that in

455
00:19:41,440 --> 00:19:44,720
our a n splitting attack we have not

456
00:19:44,720 --> 00:19:47,039
changed any other attack settings except

457
00:19:47,039 --> 00:19:50,400
replacing the learner

458
00:19:50,960 --> 00:19:53,520
to be more concrete in entire attacks

459
00:19:53,520 --> 00:19:56,559
conducted on all 100 devices fpga the

460
00:19:56,559 --> 00:20:00,080
devices the naive and m achieves uh a

461
00:20:00,080 --> 00:20:02,480
higher prediction accuracy compared to

462
00:20:02,480 --> 00:20:06,480
original splitting ipaf or lr

463
00:20:06,480 --> 00:20:09,200
while it has less accuracy in

464
00:20:09,200 --> 00:20:11,840
approximately half of the devices when

465
00:20:11,840 --> 00:20:15,520
compared to the um are adopted compared

466
00:20:15,520 --> 00:20:18,960
to our adopted alm splitting attack it

467
00:20:18,960 --> 00:20:22,799
can be seen that rn splitting attack not

468
00:20:22,799 --> 00:20:24,880
only leads to the highest

469
00:20:24,880 --> 00:20:27,280
prediction accuracy but also runs

470
00:20:27,280 --> 00:20:31,120
considerably faster compared to a naive

471
00:20:31,120 --> 00:20:33,679
ayanna this short running time is due to

472
00:20:33,679 --> 00:20:36,320
the separating the learning process of

473
00:20:36,320 --> 00:20:38,960
each x or archetype of layer thereby

474
00:20:38,960 --> 00:20:40,960
giving the learner a chance to converge

475
00:20:40,960 --> 00:20:43,280
efficiently to the proper model in the

476
00:20:43,280 --> 00:20:46,720
back and forth process

477
00:20:47,360 --> 00:20:50,080
in order to verify our results in the

478
00:20:50,080 --> 00:20:52,240
simulation domain and finding out the

479
00:20:52,240 --> 00:20:54,799
reason behind such an accuracy loss we

480
00:20:54,799 --> 00:20:57,440
repeated the same attack on the same one

481
00:20:57,440 --> 00:21:00,720
five hypothe variant and also the other

482
00:21:00,720 --> 00:21:03,760
variant using simulated crp sets for

483
00:21:03,760 --> 00:21:06,640
various amount of non-uniformity in

484
00:21:06,640 --> 00:21:10,080
arbitrary puffs instead in instances in

485
00:21:10,080 --> 00:21:13,840
both top layer and down layers

486
00:21:13,840 --> 00:21:16,320
as you can see in both figures that we

487
00:21:16,320 --> 00:21:20,000
are considering 1k and kk models

488
00:21:20,000 --> 00:21:22,880
usually in the simulation domain the

489
00:21:22,880 --> 00:21:25,919
designers and attacker consider the idle

490
00:21:25,919 --> 00:21:29,120
point which is the 50 percent uniformity

491
00:21:29,120 --> 00:21:31,120
and it brings the

492
00:21:31,120 --> 00:21:34,880
good and high prediction accuracy but

493
00:21:34,880 --> 00:21:36,159
as far as

494
00:21:36,159 --> 00:21:40,120
the model gets more complex and also the

495
00:21:40,120 --> 00:21:43,200
non-uniformity grows more but not very

496
00:21:43,200 --> 00:21:44,799
harsh

497
00:21:44,799 --> 00:21:47,679
you can see that the prediction accuracy

498
00:21:47,679 --> 00:21:49,840
can be decreased i would like to

499
00:21:49,840 --> 00:21:52,640
investigate and verify why

500
00:21:52,640 --> 00:21:53,679
this

501
00:21:53,679 --> 00:21:56,159
uniformity or bias can

502
00:21:56,159 --> 00:21:59,280
influence a puff learning process

503
00:21:59,280 --> 00:22:01,919
we have concluded with two parameters

504
00:22:01,919 --> 00:22:04,880
bias parameter and bias variance trade

505
00:22:04,880 --> 00:22:06,400
of parameter

506
00:22:06,400 --> 00:22:09,120
so the first one is uh the bias

507
00:22:09,120 --> 00:22:11,280
parameter that it is also mentioned in

508
00:22:11,280 --> 00:22:13,840
previous publication but we wanted to

509
00:22:13,840 --> 00:22:16,000
highlight that this bias from the

510
00:22:16,000 --> 00:22:18,640
parameter should be always considered in

511
00:22:18,640 --> 00:22:20,960
apop additive delay model which we

512
00:22:20,960 --> 00:22:23,200
mentioned earlier

513
00:22:23,200 --> 00:22:26,480
here this beta should be added to the

514
00:22:26,480 --> 00:22:30,480
to this model to have a an accurate um

515
00:22:30,480 --> 00:22:31,840
path model

516
00:22:31,840 --> 00:22:33,039
and but

517
00:22:33,039 --> 00:22:35,919
it is worthy to mention that this beta

518
00:22:35,919 --> 00:22:37,919
has a different

519
00:22:37,919 --> 00:22:41,679
distribution compared to weight weights

520
00:22:41,679 --> 00:22:45,039
which are the representative of physical

521
00:22:45,039 --> 00:22:46,799
characteristics

522
00:22:46,799 --> 00:22:48,960
another effective parameter is

523
00:22:48,960 --> 00:22:51,120
biospheric tradeoff

524
00:22:51,120 --> 00:22:53,679
during regularization and minimizing the

525
00:22:53,679 --> 00:22:56,320
loss function or error rate

526
00:22:56,320 --> 00:22:58,080
there is an effective parameter

527
00:22:58,080 --> 00:23:00,000
so-called bias variance of the learn

528
00:23:00,000 --> 00:23:01,840
rates which should be also considered

529
00:23:01,840 --> 00:23:03,919
with respect to the type of the selected

530
00:23:03,919 --> 00:23:06,400
logistic function and the estimation

531
00:23:06,400 --> 00:23:09,600
approaches on the applied data sets

532
00:23:09,600 --> 00:23:12,000
the bias and variance of uh fitting of

533
00:23:12,000 --> 00:23:14,720
the fitting model generally have a

534
00:23:14,720 --> 00:23:16,880
relation with minimizing the loss

535
00:23:16,880 --> 00:23:19,120
function which is a quantifying measure

536
00:23:19,120 --> 00:23:22,080
to show how bad it is to get an error of

537
00:23:22,080 --> 00:23:24,799
a particular size of direction in the

538
00:23:24,799 --> 00:23:27,039
learning process

539
00:23:27,039 --> 00:23:29,200
as you can see in the

540
00:23:29,200 --> 00:23:31,919
figure in this graph based on where the

541
00:23:31,919 --> 00:23:35,200
learner stays we can encounter with

542
00:23:35,200 --> 00:23:38,159
fitting good feed and overfitting

543
00:23:38,159 --> 00:23:40,880
model which is depends on the

544
00:23:40,880 --> 00:23:42,320
bias and the

545
00:23:42,320 --> 00:23:45,678
variance value

546
00:23:46,400 --> 00:23:48,640
in more details in the iterative batch

547
00:23:48,640 --> 00:23:51,200
sizes this trade-off can cost to

548
00:23:51,200 --> 00:23:54,000
not minimize the error rate consequently

549
00:23:54,000 --> 00:23:56,640
the learner stays in the local minima

550
00:23:56,640 --> 00:23:58,320
instead of finding the

551
00:23:58,320 --> 00:24:01,360
global minimum but then i would like to

552
00:24:01,360 --> 00:24:03,360
conclude our card with a couple of

553
00:24:03,360 --> 00:24:05,520
takeaway points

554
00:24:05,520 --> 00:24:07,760
non-uniformity in the output of the path

555
00:24:07,760 --> 00:24:11,120
with a couple of uh complex architecture

556
00:24:11,120 --> 00:24:13,679
can change a terrible successful ml

557
00:24:13,679 --> 00:24:16,880
attack into a model with

558
00:24:16,880 --> 00:24:19,279
less prediction accuracy

559
00:24:19,279 --> 00:24:21,600
and also it is worthy to mention that a

560
00:24:21,600 --> 00:24:23,440
high prediction accuracy of delay

561
00:24:23,440 --> 00:24:24,320
problems

562
00:24:24,320 --> 00:24:27,279
in simulation should be also verified in

563
00:24:27,279 --> 00:24:28,640
practice

564
00:24:28,640 --> 00:24:31,279
and there is no fixed rule which

565
00:24:31,279 --> 00:24:33,840
modeling approaches or supervised

566
00:24:33,840 --> 00:24:36,799
learners are more credible or are

567
00:24:36,799 --> 00:24:39,679
stronger in puffs learning

568
00:24:39,679 --> 00:24:42,720
it depends on pop's architecture and

569
00:24:42,720 --> 00:24:44,880
other metrics as well

570
00:24:44,880 --> 00:24:47,200
and it is also worthy to mention that

571
00:24:47,200 --> 00:24:49,840
accurate model of power including noise

572
00:24:49,840 --> 00:24:52,000
and bias brings the simulation

573
00:24:52,000 --> 00:24:55,520
experience very close to the real dummy

574
00:24:55,520 --> 00:24:59,360
thanks for your listening

