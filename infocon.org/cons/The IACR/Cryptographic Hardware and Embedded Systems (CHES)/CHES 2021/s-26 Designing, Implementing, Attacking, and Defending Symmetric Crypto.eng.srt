1
00:00:01,120 --> 00:00:04,240
ready to go have a good session

2
00:00:04,240 --> 00:00:06,080
thanks

3
00:00:06,080 --> 00:00:08,160
so welcome everyone good morning good

4
00:00:08,160 --> 00:00:10,000
afternoon or good evening welcome to

5
00:00:10,000 --> 00:00:12,960
this session on designing implementing

6
00:00:12,960 --> 00:00:16,640
attacking and defending symmetric crypto

7
00:00:16,640 --> 00:00:19,680
so we will have six talks

8
00:00:19,680 --> 00:00:22,640
um so we propose that we go

9
00:00:22,640 --> 00:00:24,720
so every speaker has five minutes then

10
00:00:24,720 --> 00:00:26,160
we go over the

11
00:00:26,160 --> 00:00:28,000
questions for that talk and then we move

12
00:00:28,000 --> 00:00:30,720
on to the next talk and so on unless of

13
00:00:30,720 --> 00:00:32,238
course there is a

14
00:00:32,238 --> 00:00:33,520
question that can be

15
00:00:33,520 --> 00:00:36,160
a question can be also be asked at the

16
00:00:36,160 --> 00:00:37,920
end if needed

17
00:00:37,920 --> 00:00:38,800
um

18
00:00:38,800 --> 00:00:40,640
yeah so if you have questions please

19
00:00:40,640 --> 00:00:43,280
type them in the zulipchat

20
00:00:43,280 --> 00:00:45,600
so we are going to start with the first

21
00:00:45,600 --> 00:00:47,120
talk of this session it's about the

22
00:00:47,120 --> 00:00:48,399
speedy

23
00:00:48,399 --> 00:00:51,840
um block ciphers it's a it's from gregor

24
00:00:51,840 --> 00:00:55,440
leander turban most amir mohadi and

25
00:00:55,440 --> 00:00:57,760
shaham rasul

26
00:00:57,760 --> 00:01:00,239
urban will give the talk so the floor is

27
00:01:00,239 --> 00:01:01,600
yours

28
00:01:01,600 --> 00:01:03,359
okay thank you very much for the

29
00:01:03,359 --> 00:01:04,720
introduction

30
00:01:04,720 --> 00:01:07,360
and to welcome to this presentation a

31
00:01:07,360 --> 00:01:09,360
short introduction to the speedy family

32
00:01:09,360 --> 00:01:12,080
of block ciphers which is a new family

33
00:01:12,080 --> 00:01:14,159
of ultra low latency

34
00:01:14,159 --> 00:01:17,360
cyphers that we have built

35
00:01:17,360 --> 00:01:18,560
um

36
00:01:18,560 --> 00:01:20,960
so in this work we wanted to tackle to

37
00:01:20,960 --> 00:01:24,159
re revisit a fundamental problem namely

38
00:01:24,159 --> 00:01:25,920
how do we design a secure encryption

39
00:01:25,920 --> 00:01:28,080
algorithm whose hardware implementation

40
00:01:28,080 --> 00:01:29,200
is fast

41
00:01:29,200 --> 00:01:31,040
and by hardware implementation we mean

42
00:01:31,040 --> 00:01:32,799
here a circuit representation

43
00:01:32,799 --> 00:01:35,759
constructed entirely from cmos gates and

44
00:01:35,759 --> 00:01:38,479
by fast we mean the entire time period

45
00:01:38,479 --> 00:01:40,640
between providing the input signals to

46
00:01:40,640 --> 00:01:42,079
the circuit

47
00:01:42,079 --> 00:01:44,320
and receiving the final output signals

48
00:01:44,320 --> 00:01:46,560
that time period should be minimal

49
00:01:46,560 --> 00:01:49,600
so in that regard we do not include any

50
00:01:49,600 --> 00:01:51,520
memory elements to store intermediate

51
00:01:51,520 --> 00:01:53,759
results because this inevitably

52
00:01:53,759 --> 00:01:55,439
increases the

53
00:01:55,439 --> 00:01:57,520
this time period and therefore we only

54
00:01:57,520 --> 00:01:59,439
consider fully unrolled so completely

55
00:01:59,439 --> 00:02:02,000
combinatorial circuits

56
00:02:02,000 --> 00:02:04,159
um what is super high speed encryption

57
00:02:04,159 --> 00:02:06,479
needed for i mean that depends on your

58
00:02:06,479 --> 00:02:08,239
opinion but

59
00:02:08,239 --> 00:02:10,479
in my eyes the myriad of

60
00:02:10,479 --> 00:02:12,319
microarchitectural attacks over the last

61
00:02:12,319 --> 00:02:13,680
couple of years

62
00:02:13,680 --> 00:02:16,000
has shown us that

63
00:02:16,000 --> 00:02:18,000
security architectures of modern central

64
00:02:18,000 --> 00:02:20,000
processing units definitely need some

65
00:02:20,000 --> 00:02:21,680
improvement and

66
00:02:21,680 --> 00:02:24,560
there are many solutions proposed

67
00:02:24,560 --> 00:02:26,560
one of them is more crypto inside of

68
00:02:26,560 --> 00:02:30,000
cpus for example in the sense of secure

69
00:02:30,000 --> 00:02:32,160
cache architectures with

70
00:02:32,160 --> 00:02:34,160
encrypted addresses

71
00:02:34,160 --> 00:02:36,480
in the sense of memory encryption of

72
00:02:36,480 --> 00:02:39,280
like all the storage elements inside of

73
00:02:39,280 --> 00:02:40,879
cpus and

74
00:02:40,879 --> 00:02:43,040
surrounding cpus then pointer

75
00:02:43,040 --> 00:02:44,879
authentication dedicated hardware

76
00:02:44,879 --> 00:02:47,280
interest instructions and many more of

77
00:02:47,280 --> 00:02:50,239
such features in future generations of

78
00:02:50,239 --> 00:02:53,280
high-end cpus

79
00:02:53,360 --> 00:02:56,160
so let's jump right into the technical

80
00:02:56,160 --> 00:02:57,519
stuff

81
00:02:57,519 --> 00:02:59,120
to start off this work we have been

82
00:02:59,120 --> 00:03:02,080
looking at how cmos gates are built

83
00:03:02,080 --> 00:03:04,480
and static cmos gates are built from a

84
00:03:04,480 --> 00:03:06,400
pull-up network made from pmos

85
00:03:06,400 --> 00:03:08,319
transistors and a pull-down network made

86
00:03:08,319 --> 00:03:10,640
from nmos transistors and these gates

87
00:03:10,640 --> 00:03:12,560
are naturally inverting and any

88
00:03:12,560 --> 00:03:14,560
non-inverting boolean function requires

89
00:03:14,560 --> 00:03:16,239
at least two stages of pull-up and

90
00:03:16,239 --> 00:03:18,560
pull-down networks as an example we have

91
00:03:18,560 --> 00:03:21,360
here nance regate on the left and an and

92
00:03:21,360 --> 00:03:23,519
three gate on the right and you can see

93
00:03:23,519 --> 00:03:25,280
that the nth regate is essentially

94
00:03:25,280 --> 00:03:28,480
enhanced regate with an inverted output

95
00:03:28,480 --> 00:03:30,319
so you have these two stages of pull up

96
00:03:30,319 --> 00:03:32,319
and pull down networks the signal has to

97
00:03:32,319 --> 00:03:34,000
propagate through that so first you need

98
00:03:34,000 --> 00:03:36,319
to charge or discharge this intermediate

99
00:03:36,319 --> 00:03:38,159
wire and then you

100
00:03:38,159 --> 00:03:40,400
evaluate the inverter on that so it

101
00:03:40,400 --> 00:03:42,560
definitely takes more time in that

102
00:03:42,560 --> 00:03:45,120
regard the naturally inverting gates are

103
00:03:45,120 --> 00:03:46,799
much more reasonable for low latency

104
00:03:46,799 --> 00:03:48,239
constructions

105
00:03:48,239 --> 00:03:50,319
then there is a second physical

106
00:03:50,319 --> 00:03:52,560
observation namely that the on

107
00:03:52,560 --> 00:03:55,040
resistance of pmos transistors

108
00:03:55,040 --> 00:03:56,400
is

109
00:03:56,400 --> 00:03:58,480
higher than the on resistance of nmos

110
00:03:58,480 --> 00:04:01,360
transistors of the same size because the

111
00:04:01,360 --> 00:04:04,879
mobility of holes as majority carriers

112
00:04:04,879 --> 00:04:06,799
is

113
00:04:06,799 --> 00:04:08,560
lower than the

114
00:04:08,560 --> 00:04:10,400
mobility of electrons

115
00:04:10,400 --> 00:04:13,599
and in that regard just a switch on pmos

116
00:04:13,599 --> 00:04:15,360
transistor conducts less current than a

117
00:04:15,360 --> 00:04:17,358
switched on nmos transistor and this is

118
00:04:17,358 --> 00:04:19,358
even amplified if you connect pmos

119
00:04:19,358 --> 00:04:22,720
transistors in series so all the logic

120
00:04:22,720 --> 00:04:24,960
gates that require pmos transistors to

121
00:04:24,960 --> 00:04:27,680
be connected in series to to be stacked

122
00:04:27,680 --> 00:04:30,479
they suffer from this effect and have

123
00:04:30,479 --> 00:04:32,960
like a lower latency on the left you can

124
00:04:32,960 --> 00:04:34,720
see a nand gate again on the right and

125
00:04:34,720 --> 00:04:36,560
nor gate in the nor gate you have the

126
00:04:36,560 --> 00:04:38,960
pmos transistors connected in sirius

127
00:04:38,960 --> 00:04:41,199
which makes it slow on the left side you

128
00:04:41,199 --> 00:04:42,800
have the pmos transits connected in

129
00:04:42,800 --> 00:04:44,720
parallel so you can charge the output

130
00:04:44,720 --> 00:04:47,040
much faster

131
00:04:47,040 --> 00:04:49,520
um we can also see that when we take a

132
00:04:49,520 --> 00:04:51,040
look at the

133
00:04:51,040 --> 00:04:53,120
latencies in standard cell libraries

134
00:04:53,120 --> 00:04:55,680
here we listed them for nand gate 45

135
00:04:55,680 --> 00:04:58,479
nanometer and then gate 50 nanometer and

136
00:04:58,479 --> 00:05:01,360
i've marked the inverter and nand gates

137
00:05:01,360 --> 00:05:03,840
for all types of inputs

138
00:05:03,840 --> 00:05:05,199
um

139
00:05:05,199 --> 00:05:07,280
so the number of inputs is the fan in

140
00:05:07,280 --> 00:05:08,080
here

141
00:05:08,080 --> 00:05:09,120
and

142
00:05:09,120 --> 00:05:10,960
the nand gates and the inverter gates

143
00:05:10,960 --> 00:05:12,880
for their number of inputs are always

144
00:05:12,880 --> 00:05:14,800
the fastest or among the fastest gates

145
00:05:14,800 --> 00:05:16,960
in any technology if you look here for

146
00:05:16,960 --> 00:05:19,199
example the nand four is by far the

147
00:05:19,199 --> 00:05:22,160
fastest gauge for four inputs and it's

148
00:05:22,160 --> 00:05:24,000
more than twice as fast as the north

149
00:05:24,000 --> 00:05:26,240
four

150
00:05:27,600 --> 00:05:29,680
but we cannot stop at looking at the

151
00:05:29,680 --> 00:05:32,000
latency of logic gates we also need to

152
00:05:32,000 --> 00:05:34,000
consider the latency of logic circuits

153
00:05:34,000 --> 00:05:36,000
so here is a very simple example on the

154
00:05:36,000 --> 00:05:38,479
left side we have a circuit where two

155
00:05:38,479 --> 00:05:40,960
input xor drives eight further two input

156
00:05:40,960 --> 00:05:42,320
x-force

157
00:05:42,320 --> 00:05:44,320
and some people would say okay you have

158
00:05:44,320 --> 00:05:47,360
a gate depth of two and both are xors so

159
00:05:47,360 --> 00:05:50,000
the latency should be twice the base

160
00:05:50,000 --> 00:05:51,680
latency of an xor but that's of course

161
00:05:51,680 --> 00:05:53,039
not the case

162
00:05:53,039 --> 00:05:54,880
because the first stage xo has to drive

163
00:05:54,880 --> 00:05:57,120
such a huge capacitive low to charge all

164
00:05:57,120 --> 00:05:59,680
these input pins of the further xors

165
00:05:59,680 --> 00:06:02,319
that its base latency is increased

166
00:06:02,319 --> 00:06:05,360
more than four times just by its

167
00:06:05,360 --> 00:06:07,199
electrical environment and the second

168
00:06:07,199 --> 00:06:09,840
stage xor is also increased because they

169
00:06:09,840 --> 00:06:12,319
are driven by a signal with a large

170
00:06:12,319 --> 00:06:14,479
transition type which also makes the

171
00:06:14,479 --> 00:06:16,560
overall switching a little slower of

172
00:06:16,560 --> 00:06:18,000
course you can have a drive strength

173
00:06:18,000 --> 00:06:20,319
buffer as you can see on the right side

174
00:06:20,319 --> 00:06:22,720
to make up for that a little bit

175
00:06:22,720 --> 00:06:24,800
then you can drive the signal faster but

176
00:06:24,800 --> 00:06:26,400
you have increased the gate depth from

177
00:06:26,400 --> 00:06:28,800
two to three and this example is just to

178
00:06:28,800 --> 00:06:30,639
show you that neither the gate depths

179
00:06:30,639 --> 00:06:33,039
nor like the base latency of the gates

180
00:06:33,039 --> 00:06:36,000
are sufficient information to judge the

181
00:06:36,000 --> 00:06:38,160
latency of a circuit you also need to

182
00:06:38,160 --> 00:06:40,479
take the topology of the circuit into

183
00:06:40,479 --> 00:06:42,560
account

184
00:06:42,560 --> 00:06:44,240
and with this information and a little

185
00:06:44,240 --> 00:06:46,319
bit more that's described in more detail

186
00:06:46,319 --> 00:06:49,360
in the paper we have built this 6-bit

187
00:06:49,360 --> 00:06:50,639
s-box

188
00:06:50,639 --> 00:06:53,039
so most of the effort of this work was

189
00:06:53,039 --> 00:06:55,199
spent on searching this particular s-box

190
00:06:55,199 --> 00:06:57,280
it was not trivial we have also searched

191
00:06:57,280 --> 00:06:59,680
for larger s-boxes and for even faster

192
00:06:59,680 --> 00:07:01,680
ones

193
00:07:01,680 --> 00:07:04,160
but this one is is a really nice result

194
00:07:04,160 --> 00:07:05,599
it's a six bit aspect with full

195
00:07:05,599 --> 00:07:08,000
diffusion a uniformity of eight a

196
00:07:08,000 --> 00:07:11,120
linearity of 24 and it uses inverters

197
00:07:11,120 --> 00:07:12,800
and buffers in the first stage in the

198
00:07:12,800 --> 00:07:14,240
inputs

199
00:07:14,240 --> 00:07:16,800
they are needed because uh each input is

200
00:07:16,800 --> 00:07:18,479
selected by each coordinate function

201
00:07:18,479 --> 00:07:20,800
anyway in a full diffusion s-box so you

202
00:07:20,800 --> 00:07:23,199
have a fan out there um that you need to

203
00:07:23,199 --> 00:07:25,680
consider and that you need to buffer uh

204
00:07:25,680 --> 00:07:27,360
and in the second stage in the third

205
00:07:27,360 --> 00:07:29,599
stage this is all just nand gates of

206
00:07:29,599 --> 00:07:31,680
different inputs so two input nands

207
00:07:31,680 --> 00:07:34,639
three input nands and four input nets

208
00:07:34,639 --> 00:07:37,599
and that s box um compares very

209
00:07:37,599 --> 00:07:40,000
favorably to other cryptographic s

210
00:07:40,000 --> 00:07:42,800
blocks here is a latency comparison

211
00:07:42,800 --> 00:07:44,720
averaged over six different standard

212
00:07:44,720 --> 00:07:47,120
cell libraries and we can see that the

213
00:07:47,120 --> 00:07:50,160
speedy 6-bit s-box really falls into the

214
00:07:50,160 --> 00:07:53,120
range of low-latency 4-bit s-boxes sure

215
00:07:53,120 --> 00:07:54,879
there are some 4-bit s-books which are

216
00:07:54,879 --> 00:07:57,199
faster than the 3ds books but there are

217
00:07:57,199 --> 00:07:59,199
also some which are slower

218
00:07:59,199 --> 00:08:01,759
and definitely the speedy 6-bit s-box is

219
00:08:01,759 --> 00:08:04,000
much faster than other 5-bit 6-bit or

220
00:08:04,000 --> 00:08:07,440
8-bit s-box listed here

221
00:08:07,599 --> 00:08:10,170
the linear layer is mostly this

222
00:08:10,170 --> 00:08:11,280
[Music]

223
00:08:11,280 --> 00:08:13,840
mix columns plus at round key plus round

224
00:08:13,840 --> 00:08:16,000
at round constant operation which is

225
00:08:16,000 --> 00:08:18,639
quite heavy because it requires three

226
00:08:18,639 --> 00:08:21,120
stages of two input xors

227
00:08:21,120 --> 00:08:23,599
um but we apply it only after each

228
00:08:23,599 --> 00:08:25,759
second s-box stage

229
00:08:25,759 --> 00:08:27,680
and we need a strong linear layer to

230
00:08:27,680 --> 00:08:30,240
reduce the number of rounds to a minimum

231
00:08:30,240 --> 00:08:31,440
which is very important for a

232
00:08:31,440 --> 00:08:33,839
low-latency cipher as well

233
00:08:33,839 --> 00:08:35,919
here's the whole cipher so as i said we

234
00:08:35,919 --> 00:08:37,360
have

235
00:08:37,360 --> 00:08:39,919
the s-box then we have shift columns and

236
00:08:39,919 --> 00:08:42,240
the s box again shift columns again then

237
00:08:42,240 --> 00:08:44,240
we have this combined operation of mixed

238
00:08:44,240 --> 00:08:45,600
columns

239
00:08:45,600 --> 00:08:47,920
at round key at round constant

240
00:08:47,920 --> 00:08:50,800
and that is essentially one round

241
00:08:50,800 --> 00:08:53,200
our security claims for speedy was 5

242
00:08:53,200 --> 00:08:57,360
rounds and 192 bit key and block size

243
00:08:57,360 --> 00:08:59,600
are that attacks require complexity of

244
00:08:59,600 --> 00:09:02,800
larger than 2 to the 128 time complexity

245
00:09:02,800 --> 00:09:06,080
but the data is limited to 2 to the 64.

246
00:09:06,080 --> 00:09:09,120
for speedy 6 and speedy seven we claim

247
00:09:09,120 --> 00:09:13,600
128 and 192 bit security

248
00:09:13,600 --> 00:09:14,800
um

249
00:09:14,800 --> 00:09:16,560
so speedy five already has a

250
00:09:16,560 --> 00:09:17,920
significantly

251
00:09:17,920 --> 00:09:21,040
higher security claim than prince and

252
00:09:21,040 --> 00:09:23,440
prince version 2 which is an updated

253
00:09:23,440 --> 00:09:24,959
version of prince

254
00:09:24,959 --> 00:09:28,560
published at sec 2020

255
00:09:28,560 --> 00:09:30,720
and speedy 6 and 7 are even in the range

256
00:09:30,720 --> 00:09:34,080
of like aes

257
00:09:34,399 --> 00:09:36,480
here we can see a latency comparison of

258
00:09:36,480 --> 00:09:39,040
the common encryption excuse me can you

259
00:09:39,040 --> 00:09:40,640
can you please wrap up in in a minute

260
00:09:40,640 --> 00:09:42,399
also because we are showing

261
00:09:42,399 --> 00:09:44,080
over time so here we can just see that

262
00:09:44,080 --> 00:09:46,880
v5 and speedy6 are faster than all the

263
00:09:46,880 --> 00:09:49,920
competition um the area is also not bad

264
00:09:49,920 --> 00:09:52,240
if you take into account that's 192 bit

265
00:09:52,240 --> 00:09:56,880
cipher um and in conclusions v5 is like

266
00:09:56,880 --> 00:10:00,240
25 faster than prints speedy six is even

267
00:10:00,240 --> 00:10:02,240
10 to 12 percent faster than prince and

268
00:10:02,240 --> 00:10:04,880
three to seven faster than autros um

269
00:10:04,880 --> 00:10:06,959
ultras is a prf and not invertible

270
00:10:06,959 --> 00:10:09,120
speedy on the other hand is so we

271
00:10:09,120 --> 00:10:11,360
believe that for all applications where

272
00:10:11,360 --> 00:10:12,880
encryption speed and security are the

273
00:10:12,880 --> 00:10:16,240
primary goals speedy is a great choice

274
00:10:16,240 --> 00:10:18,399
yeah thank you for your attention sorry

275
00:10:18,399 --> 00:10:20,560
for taking long and i'm happy to take

276
00:10:20,560 --> 00:10:23,199
any questions

277
00:10:23,519 --> 00:10:25,920
thank you for the talk um

278
00:10:25,920 --> 00:10:27,680
so far we have not

279
00:10:27,680 --> 00:10:31,760
got any um outside questions on the lips

280
00:10:31,760 --> 00:10:33,760
so maybe we can go on to the next

281
00:10:33,760 --> 00:10:35,040
session

282
00:10:35,040 --> 00:10:38,480
i'm sorry next talk and please feel free

283
00:10:38,480 --> 00:10:40,560
to um post

284
00:10:40,560 --> 00:10:43,279
questions comments on this talk

285
00:10:43,279 --> 00:10:45,760
so that we can come back to you

286
00:10:45,760 --> 00:10:48,160
in a spare time at the end of session

287
00:10:48,160 --> 00:10:50,560
thank you

288
00:10:51,040 --> 00:10:53,360
okay great thanks um so the next talk is

289
00:10:53,360 --> 00:10:56,480
about the area latency symbiosis

290
00:10:56,480 --> 00:11:01,200
the talk is from fatih bali andrea

291
00:11:05,770 --> 00:11:07,600
[Music]

292
00:11:07,600 --> 00:11:09,360
thanks for the introduction

293
00:11:09,360 --> 00:11:12,000
um good morning everyone

294
00:11:12,000 --> 00:11:14,800
i am fatih bali and this is my crew talk

295
00:11:14,800 --> 00:11:19,200
for our work the area latency symbiosis

296
00:11:19,200 --> 00:11:20,480
uh so if you

297
00:11:20,480 --> 00:11:21,279
go

298
00:11:21,279 --> 00:11:23,200
right now we are at the final round at

299
00:11:23,200 --> 00:11:25,920
mr lwc but at the time of writing this

300
00:11:25,920 --> 00:11:27,839
paper we had to look from the second

301
00:11:27,839 --> 00:11:29,600
round and if you go back to the snapshot

302
00:11:29,600 --> 00:11:31,200
from the second round

303
00:11:31,200 --> 00:11:32,480
what we see

304
00:11:32,480 --> 00:11:34,399
is that there are a number of

305
00:11:34,399 --> 00:11:36,640
authenticated encryption candidates that

306
00:11:36,640 --> 00:11:38,560
depend on the mode of operation type of

307
00:11:38,560 --> 00:11:40,720
design which means that the efficiency

308
00:11:40,720 --> 00:11:42,959
of this authenticated encryption that

309
00:11:42,959 --> 00:11:44,959
boils down to the choice and the

310
00:11:44,959 --> 00:11:47,120
implementation of the block cipher in

311
00:11:47,120 --> 00:11:48,800
this particular case you see that the

312
00:11:48,800 --> 00:11:51,040
gift skinny and the aes block ciphers

313
00:11:51,040 --> 00:11:53,760
were quite popular and mainly you had 11

314
00:11:53,760 --> 00:11:56,399
candidates that were making use of this

315
00:11:56,399 --> 00:11:58,320
family of block ciphers

316
00:11:58,320 --> 00:12:00,320
and the motivation in this call is to

317
00:12:00,320 --> 00:12:02,880
look back to these block ciphers

318
00:12:02,880 --> 00:12:05,040
from the smallest reimplementation

319
00:12:05,040 --> 00:12:07,599
perspective

320
00:12:07,920 --> 00:12:10,240
so when i when we talk about the

321
00:12:10,240 --> 00:12:12,079
aggressive optimization techniques for

322
00:12:12,079 --> 00:12:14,399
the silicon area for these block ciphers

323
00:12:14,399 --> 00:12:16,560
the first paper that comes to mind

324
00:12:16,560 --> 00:12:19,839
is from genital from chest 2017

325
00:12:19,839 --> 00:12:22,399
where the authors for the first time uh

326
00:12:22,399 --> 00:12:24,639
designed a one-piece real architecture

327
00:12:24,639 --> 00:12:26,240
for the block ciphers

328
00:12:26,240 --> 00:12:29,040
uh aes skinny and present 80.

329
00:12:29,040 --> 00:12:31,440
and that is a particular challenging

330
00:12:31,440 --> 00:12:33,360
task because these block ciphers are

331
00:12:33,360 --> 00:12:36,320
designed with 4-bit or 8-bit boundaries

332
00:12:36,320 --> 00:12:38,399
in mind which is just an artifact from

333
00:12:38,399 --> 00:12:40,720
the microcontroller implementations

334
00:12:40,720 --> 00:12:42,480
and these implementations are the

335
00:12:42,480 --> 00:12:43,600
state-of-the-art smallest

336
00:12:43,600 --> 00:12:46,399
implementations so far

337
00:12:46,399 --> 00:12:48,000
and then the second work that is again

338
00:12:48,000 --> 00:12:50,480
related is from panic it helps from fsc

339
00:12:50,480 --> 00:12:52,160
2020

340
00:12:52,160 --> 00:12:54,399
where in the same fashion the authors uh

341
00:12:54,399 --> 00:12:56,959
try to implement the present eighty and

342
00:12:56,959 --> 00:12:58,720
give six to four again in a one bit

343
00:12:58,720 --> 00:13:00,240
serial fashion

344
00:13:00,240 --> 00:13:02,480
where in this particular one the

345
00:13:02,480 --> 00:13:04,560
particular challenge comes from

346
00:13:04,560 --> 00:13:06,880
the the permutation layers of these

347
00:13:06,880 --> 00:13:09,200
block stickers because they are defined

348
00:13:09,200 --> 00:13:11,279
at the one with granularity which makes

349
00:13:11,279 --> 00:13:13,200
them quite hard and difficult to

350
00:13:13,200 --> 00:13:14,880
implement through a pipelined

351
00:13:14,880 --> 00:13:17,040
architecture so following the footsteps

352
00:13:17,040 --> 00:13:18,480
of this work

353
00:13:18,480 --> 00:13:20,639
uh we look again to the one material

354
00:13:20,639 --> 00:13:23,360
implementations but our idea is to

355
00:13:23,360 --> 00:13:26,079
combine the area metric with the latency

356
00:13:26,079 --> 00:13:27,760
as well as the energy matrix at the same

357
00:13:27,760 --> 00:13:28,720
time

358
00:13:28,720 --> 00:13:30,639
so if you just look back

359
00:13:30,639 --> 00:13:33,360
to the implementation for example of an

360
00:13:33,360 --> 00:13:35,519
aes that is implemented in a one-bedroom

361
00:13:35,519 --> 00:13:36,560
fashion

362
00:13:36,560 --> 00:13:38,720
what you see at the core is

363
00:13:38,720 --> 00:13:41,040
what we call the pipeline which is just

364
00:13:41,040 --> 00:13:44,720
um 128 flip-flops uh arranged in a

365
00:13:44,720 --> 00:13:47,040
fashion that the bits can be rotated

366
00:13:47,040 --> 00:13:48,720
through it

367
00:13:48,720 --> 00:13:52,320
and the main difference uh between

368
00:13:52,320 --> 00:13:54,160
compared to previous previous work and

369
00:13:54,160 --> 00:13:55,279
what we do

370
00:13:55,279 --> 00:13:57,279
is uh in the previous work what you see

371
00:13:57,279 --> 00:13:58,800
is there's a very

372
00:13:58,800 --> 00:14:01,040
sequential execution of the layers of

373
00:14:01,040 --> 00:14:03,519
around so in the case of aes you have

374
00:14:03,519 --> 00:14:05,760
the at the addition of the key you have

375
00:14:05,760 --> 00:14:08,560
the s boxes followed by the shift rows

376
00:14:08,560 --> 00:14:10,320
followed by the mixed column

377
00:14:10,320 --> 00:14:13,279
which are uh organized in a way that you

378
00:14:13,279 --> 00:14:14,800
have to first finish the addition of the

379
00:14:14,800 --> 00:14:17,839
key and s box and only then you execute

380
00:14:17,839 --> 00:14:20,480
the shift rows in comparison what we do

381
00:14:20,480 --> 00:14:22,160
is what i would like to call the

382
00:14:22,160 --> 00:14:23,920
continuous execution

383
00:14:23,920 --> 00:14:26,720
where we treat each bit separately

384
00:14:26,720 --> 00:14:28,800
which means that while you have some of

385
00:14:28,800 --> 00:14:31,120
the bits which have already completed

386
00:14:31,120 --> 00:14:33,440
their mixed columns operation you might

387
00:14:33,440 --> 00:14:35,279
have some other bits which are just

388
00:14:35,279 --> 00:14:36,880
going through the s box or the order k

389
00:14:36,880 --> 00:14:38,639
edition at the same time

390
00:14:38,639 --> 00:14:39,760
which

391
00:14:39,760 --> 00:14:41,920
at the end means that you can complete a

392
00:14:41,920 --> 00:14:44,560
single round in a much faster fashion

393
00:14:44,560 --> 00:14:46,880
so that is that would be for example

394
00:14:46,880 --> 00:14:50,079
in the case of as 128 clock cycles

395
00:14:50,079 --> 00:14:52,240
uh compared to the 160 clock cycles from

396
00:14:52,240 --> 00:14:54,959
the previous work so that is basically

397
00:14:54,959 --> 00:14:57,279
faster has lower latency which means a

398
00:14:57,279 --> 00:14:59,199
better throughput at the same time it

399
00:14:59,199 --> 00:15:00,720
means that you consume

400
00:15:00,720 --> 00:15:03,040
less energy and the power and these work

401
00:15:03,040 --> 00:15:06,000
is also extended to uh one uh one

402
00:15:06,000 --> 00:15:07,920
candidate for each of the block ciphers

403
00:15:07,920 --> 00:15:09,839
from the initial lwc

404
00:15:09,839 --> 00:15:12,240
just to show that you can also extend

405
00:15:12,240 --> 00:15:14,399
this idea to the motor operation layer

406
00:15:14,399 --> 00:15:17,040
as well so just to wrap it up

407
00:15:17,040 --> 00:15:18,639
in this paper what the present is a

408
00:15:18,639 --> 00:15:20,399
technique which can do

409
00:15:20,399 --> 00:15:23,199
execute the rounds of aes skinny and

410
00:15:23,199 --> 00:15:25,360
give one to an eight in a continuous

411
00:15:25,360 --> 00:15:26,560
fashion

412
00:15:26,560 --> 00:15:27,839
um

413
00:15:27,839 --> 00:15:29,440
so the main benefit

414
00:15:29,440 --> 00:15:30,880
is that you don't have to freeze

415
00:15:30,880 --> 00:15:32,240
pipeline you don't have to deal with

416
00:15:32,240 --> 00:15:34,800
synchronization problems that previous

417
00:15:34,800 --> 00:15:36,800
implementations suffer

418
00:15:36,800 --> 00:15:38,240
uh which means that you can avoid

419
00:15:38,240 --> 00:15:39,759
something like a

420
00:15:39,759 --> 00:15:41,759
which is something that is not liked

421
00:15:41,759 --> 00:15:43,920
very much during the synthesis process

422
00:15:43,920 --> 00:15:45,839
as well as you can avoid

423
00:15:45,839 --> 00:15:47,839
enabled flip flops which are larger in

424
00:15:47,839 --> 00:15:50,079
nature it also achieves the minimum

425
00:15:50,079 --> 00:15:51,839
latency that you can expect from one

426
00:15:51,839 --> 00:15:53,759
material instrumentation

427
00:15:53,759 --> 00:15:55,440
and also it follows the standard

428
00:15:55,440 --> 00:15:57,519
ordering so you can just use them

429
00:15:57,519 --> 00:15:59,680
in a plug-and-play fashion

430
00:15:59,680 --> 00:16:01,040
and the source code of these

431
00:16:01,040 --> 00:16:02,800
implementations are also available as a

432
00:16:02,800 --> 00:16:04,480
chess act facts

433
00:16:04,480 --> 00:16:06,399
and that is all i wanted to say thank

434
00:16:06,399 --> 00:16:09,720
you very much

435
00:16:13,120 --> 00:16:14,079
sir

436
00:16:14,079 --> 00:16:16,480
thank you for the talk yes

437
00:16:16,480 --> 00:16:18,240
yeah unfortunately we

438
00:16:18,240 --> 00:16:21,040
haven't got any comment yet so yeah

439
00:16:21,040 --> 00:16:23,920
let's move on to the next talk

440
00:16:23,920 --> 00:16:26,160
okay

441
00:16:27,040 --> 00:16:28,079
okay

442
00:16:28,079 --> 00:16:30,959
i start sharing okay yes

443
00:16:30,959 --> 00:16:33,440
let me just introduce you

444
00:16:33,440 --> 00:16:35,600
so the next talk is about breaking mask

445
00:16:35,600 --> 00:16:37,839
implementations by olivier bronson and

446
00:16:37,839 --> 00:16:39,600
francois standard

447
00:16:39,600 --> 00:16:41,279
yes you can

448
00:16:41,279 --> 00:16:42,220
go ahead thanks

449
00:16:42,220 --> 00:16:44,240
[Music]

450
00:16:44,240 --> 00:16:47,120
okay do you see my slides correctly yes

451
00:16:47,120 --> 00:16:48,480
yes okay

452
00:16:48,480 --> 00:16:52,320
so um the paper um is about running

453
00:16:52,320 --> 00:16:54,959
worst case evaluation on on mask

454
00:16:54,959 --> 00:16:56,320
software

455
00:16:56,320 --> 00:16:57,120
um

456
00:16:57,120 --> 00:16:58,880
and by what's the goal of worst case

457
00:16:58,880 --> 00:17:00,399
evaluation basically is that when you

458
00:17:00,399 --> 00:17:01,680
have a product

459
00:17:01,680 --> 00:17:04,480
i mean a secure implementation you want

460
00:17:04,480 --> 00:17:06,480
to evaluate the security

461
00:17:06,480 --> 00:17:09,599
so how do you do that first you run some

462
00:17:09,599 --> 00:17:11,599
some attacks uh some state-of-the-art

463
00:17:11,599 --> 00:17:13,119
attacks or sata

464
00:17:13,119 --> 00:17:14,880
and these attacks improve with time so

465
00:17:14,880 --> 00:17:17,599
the data complexity of the best possible

466
00:17:17,599 --> 00:17:19,919
attack i mean of the best known attack

467
00:17:19,919 --> 00:17:21,679
decreases with star

468
00:17:21,679 --> 00:17:24,000
but at some point you have to

469
00:17:24,000 --> 00:17:25,919
i mean to to deploy your project in the

470
00:17:25,919 --> 00:17:27,280
wild

471
00:17:27,280 --> 00:17:28,400
um

472
00:17:28,400 --> 00:17:32,000
and so that's what's with the green line

473
00:17:32,000 --> 00:17:33,679
and his attack still improves this time

474
00:17:33,679 --> 00:17:35,440
after you have released your product so

475
00:17:35,440 --> 00:17:37,679
the question is what security level

476
00:17:37,679 --> 00:17:39,840
should you consider

477
00:17:39,840 --> 00:17:41,280
the goal of worst health attack is

478
00:17:41,280 --> 00:17:42,100
really to

479
00:17:42,100 --> 00:17:43,200
[Music]

480
00:17:43,200 --> 00:17:45,440
to anticipate improvement of future

481
00:17:45,440 --> 00:17:48,160
attacks by saying no adversary will be

482
00:17:48,160 --> 00:17:51,360
able to do better than this

483
00:17:51,360 --> 00:17:53,679
what's the ingredients to reach that

484
00:17:53,679 --> 00:17:56,799
basically we give a full power to the

485
00:17:56,799 --> 00:17:59,600
evaluator during the profiling

486
00:17:59,600 --> 00:18:01,760
so everett thor

487
00:18:01,760 --> 00:18:04,559
has to know all the source code

488
00:18:04,559 --> 00:18:06,559
he has to know all the randomness used

489
00:18:06,559 --> 00:18:08,799
during

490
00:18:08,799 --> 00:18:11,919
profiling all the randomness used

491
00:18:11,919 --> 00:18:17,120
he also has to have a very very nice

492
00:18:17,120 --> 00:18:18,960
setup i mean he can optimize that have

493
00:18:18,960 --> 00:18:20,320
it with

494
00:18:20,320 --> 00:18:21,840
a low noise

495
00:18:21,840 --> 00:18:22,720
and then

496
00:18:22,720 --> 00:18:24,559
he has to have some techniques to

497
00:18:24,559 --> 00:18:26,400
exploit all the possible information

498
00:18:26,400 --> 00:18:29,840
that's within the leakages

499
00:18:30,320 --> 00:18:31,840
the main ingredient really is the

500
00:18:31,840 --> 00:18:34,080
knowledge of the randomness because it

501
00:18:34,080 --> 00:18:36,080
allows to have a simpler profiling and

502
00:18:36,080 --> 00:18:37,600
it allows to give

503
00:18:37,600 --> 00:18:40,480
interpretation of the results

504
00:18:40,480 --> 00:18:42,720
and base i mean based on that we are

505
00:18:42,720 --> 00:18:44,960
able to to give clear guidelines to

506
00:18:44,960 --> 00:18:47,520
every letter about what why the an

507
00:18:47,520 --> 00:18:49,440
implementation is weak or why is it

508
00:18:49,440 --> 00:18:51,200
strong

509
00:18:51,200 --> 00:18:52,720
of course there is some

510
00:18:52,720 --> 00:18:54,640
some gap between

511
00:18:54,640 --> 00:18:56,640
the security level that you have um when

512
00:18:56,640 --> 00:18:58,320
you deploy the product and the worst

513
00:18:58,320 --> 00:19:01,120
case uh attack complexity that you that

514
00:19:01,120 --> 00:19:02,640
you evaluate

515
00:19:02,640 --> 00:19:04,960
so in the short term um there's probably

516
00:19:04,960 --> 00:19:07,200
a gap but in the long term we expect

517
00:19:07,200 --> 00:19:09,679
that this gap vanishes because

518
00:19:09,679 --> 00:19:12,880
best attacks improve and maybe reach the

519
00:19:12,880 --> 00:19:15,840
worst case attacks complex

520
00:19:15,840 --> 00:19:17,840
so what's in the paper basically

521
00:19:17,840 --> 00:19:20,640
we have a methodology to evaluate mass

522
00:19:20,640 --> 00:19:23,280
bit slash implementation which relies on

523
00:19:23,280 --> 00:19:25,200
some old-fashioned tools that are

524
00:19:25,200 --> 00:19:27,360
gaussian templates

525
00:19:27,360 --> 00:19:29,440
dimensionality rejection

526
00:19:29,440 --> 00:19:31,440
and some safeguard with dedicated factor

527
00:19:31,440 --> 00:19:33,360
graph

528
00:19:33,360 --> 00:19:35,200
we applied that to

529
00:19:35,200 --> 00:19:38,799
aes and clyde and which is a

530
00:19:38,799 --> 00:19:41,360
lightweight black cipher and we use that

531
00:19:41,360 --> 00:19:43,840
for the traces of the on the traces for

532
00:19:43,840 --> 00:19:47,440
of the chess 2020 ctf

533
00:19:47,440 --> 00:19:48,960
the targets

534
00:19:48,960 --> 00:19:51,360
i mean the traces are recorded

535
00:19:51,360 --> 00:19:54,080
recorded on ty on cortex and zero in

536
00:19:54,080 --> 00:19:55,520
cortex m3

537
00:19:55,520 --> 00:19:57,440
we extrapolate

538
00:19:57,440 --> 00:19:59,120
the security of this implementation to

539
00:19:59,120 --> 00:20:01,600
larger masking order that's in the full

540
00:20:01,600 --> 00:20:04,159
paper and or in the full torque and we

541
00:20:04,159 --> 00:20:06,080
also discuss the impact of additional

542
00:20:06,080 --> 00:20:08,159
counter measures

543
00:20:08,159 --> 00:20:10,400
so just one slide about the methodology

544
00:20:10,400 --> 00:20:12,400
basically it consists on observing

545
00:20:12,400 --> 00:20:16,480
leakage on all the stairs so a1 and a0

546
00:20:16,480 --> 00:20:20,320
b0 b1 are all shares and we will combine

547
00:20:20,320 --> 00:20:22,960
with saska

548
00:20:22,960 --> 00:20:26,159
the value for b which is the

549
00:20:26,159 --> 00:20:28,960
the shared value c and a

550
00:20:28,960 --> 00:20:30,640
that's done with what we call encoding

551
00:20:30,640 --> 00:20:31,919
graphs

552
00:20:31,919 --> 00:20:35,760
yeah and then with a mask graph we link

553
00:20:35,760 --> 00:20:39,039
all these secret variables so a b and c

554
00:20:39,039 --> 00:20:41,600
um with the operation which is a

555
00:20:41,600 --> 00:20:43,600
multiplication here

556
00:20:43,600 --> 00:20:45,200
so what are the problem counts of this

557
00:20:45,200 --> 00:20:47,039
methodology basically

558
00:20:47,039 --> 00:20:50,159
the effort was made to have

559
00:20:50,159 --> 00:20:51,840
all the complexities

560
00:20:51,840 --> 00:20:53,600
scaling gently with d

561
00:20:53,600 --> 00:20:57,760
and also to save some memory and runtime

562
00:20:57,760 --> 00:21:00,240
the drawback is that we cannot exploit

563
00:21:00,240 --> 00:21:04,720
lower order flows with this methodology

564
00:21:04,720 --> 00:21:06,960
all the methodology was was implemented

565
00:21:06,960 --> 00:21:09,200
with kelp which is a python toolbox that

566
00:21:09,200 --> 00:21:10,799
we developed for that

567
00:21:10,799 --> 00:21:12,799
thanks for to guide on cassius who

568
00:21:12,799 --> 00:21:16,880
helped ready to develop these tools

569
00:21:16,880 --> 00:21:18,720
and it's really optimized to run on a

570
00:21:18,720 --> 00:21:20,880
single core and there is backing so good

571
00:21:20,880 --> 00:21:23,039
performances

572
00:21:23,039 --> 00:21:24,880
about the evaluation

573
00:21:24,880 --> 00:21:26,400
so first

574
00:21:26,400 --> 00:21:28,320
on the graph there on the x axis you

575
00:21:28,320 --> 00:21:31,280
have the data complexity uh

576
00:21:31,280 --> 00:21:33,520
evaluated with the with our methodology

577
00:21:33,520 --> 00:21:35,760
and on the y-axis there

578
00:21:35,760 --> 00:21:37,760
you have the medium key rank and what we

579
00:21:37,760 --> 00:21:40,559
see of course is as the number of traces

580
00:21:40,559 --> 00:21:41,760
of the

581
00:21:41,760 --> 00:21:44,000
observed by the adversary increases the

582
00:21:44,000 --> 00:21:45,600
number of

583
00:21:45,600 --> 00:21:48,480
the the key rank decreases

584
00:21:48,480 --> 00:21:49,840
so first of

585
00:21:49,840 --> 00:21:50,880
cortex

586
00:21:50,880 --> 00:21:53,440
m0 when aes is running we see that we

587
00:21:53,440 --> 00:21:55,600
just need nine traces to break a six

588
00:21:55,600 --> 00:21:58,799
share implementation

589
00:21:58,799 --> 00:22:01,200
and if the same code is running on

590
00:22:01,200 --> 00:22:02,240
cortex

591
00:22:02,240 --> 00:22:05,600
m3 then we need more choices so 2000

592
00:22:05,600 --> 00:22:06,720
traces

593
00:22:06,720 --> 00:22:08,960
we are able to break five shares

594
00:22:08,960 --> 00:22:10,480
implementation

595
00:22:10,480 --> 00:22:13,919
so it means that cortex m3 is more noisy

596
00:22:13,919 --> 00:22:15,679
than cortex and zero and

597
00:22:15,679 --> 00:22:18,159
and so the attacks are more complex

598
00:22:18,159 --> 00:22:19,760
we also observe that

599
00:22:19,760 --> 00:22:21,440
clyde

600
00:22:21,440 --> 00:22:24,400
which is also running on cortex and zero

601
00:22:24,400 --> 00:22:28,240
has better security than aes so

602
00:22:28,240 --> 00:22:29,679
it means that the because it's

603
00:22:29,679 --> 00:22:32,960
lightweight it's easier to protect

604
00:22:32,960 --> 00:22:35,120
and we also provide as i say previously

605
00:22:35,120 --> 00:22:37,200
extrapolation to larger security order

606
00:22:37,200 --> 00:22:39,600
and other interpretation in the paper

607
00:22:39,600 --> 00:22:42,400
so as a conclusion i would say that

608
00:22:42,400 --> 00:22:44,880
the paper contains efficient methodology

609
00:22:44,880 --> 00:22:46,960
to either attack or evaluate max

610
00:22:46,960 --> 00:22:48,480
implement mask

611
00:22:48,480 --> 00:22:50,320
implementation

612
00:22:50,320 --> 00:22:52,480
there is for sure lack of noise in low

613
00:22:52,480 --> 00:22:56,000
cost mcu we investigate it so that's an

614
00:22:56,000 --> 00:22:58,000
issue and how do you predict this kind

615
00:22:58,000 --> 00:22:59,679
of device it's

616
00:22:59,679 --> 00:23:01,440
for me really a hard

617
00:23:01,440 --> 00:23:03,600
question that has to be hands on

618
00:23:03,600 --> 00:23:06,799
i'm not sure there is a the clear answer

619
00:23:06,799 --> 00:23:09,200
also um because there is a low noise

620
00:23:09,200 --> 00:23:11,679
there we need to have masking at higher

621
00:23:11,679 --> 00:23:15,200
order on these devices um

622
00:23:15,679 --> 00:23:18,080
any toolbox that is i am that is

623
00:23:18,080 --> 00:23:19,760
optimized uh for

624
00:23:19,760 --> 00:23:21,280
such an analysis

625
00:23:21,280 --> 00:23:22,559
so thanks

626
00:23:22,559 --> 00:23:24,720
here are some useful links so to

627
00:23:24,720 --> 00:23:26,960
reproduce the attacks for scalib and

628
00:23:26,960 --> 00:23:29,440
also we release the paper that is give

629
00:23:29,440 --> 00:23:33,120
me five minutes and which is um

630
00:23:33,120 --> 00:23:35,200
applying the methodology to the wendon

631
00:23:35,200 --> 00:23:38,000
ascet data set

632
00:23:38,240 --> 00:23:40,559
and that's it for me

633
00:23:40,559 --> 00:23:42,480
thank you very much for the talk i've

634
00:23:42,480 --> 00:23:45,360
got one question from fatih

635
00:23:45,360 --> 00:23:48,840
so i'm reading it i was wondering if the

636
00:23:48,840 --> 00:23:51,679
collected power samples have to deal

637
00:23:51,679 --> 00:23:54,880
with jittering if not how problematic

638
00:23:54,880 --> 00:23:58,240
would it be to deal with synchronization

639
00:23:58,240 --> 00:24:00,480
among power traces from the attacker's

640
00:24:00,480 --> 00:24:01,919
perspective

641
00:24:01,919 --> 00:24:04,720
okay so as i said uh in

642
00:24:04,720 --> 00:24:06,159
i mean i think in one of the first

643
00:24:06,159 --> 00:24:09,520
slides uh we really have uh

644
00:24:09,520 --> 00:24:11,279
i mean for evaluation we would like that

645
00:24:11,279 --> 00:24:13,279
the evaluator is in the best case for

646
00:24:13,279 --> 00:24:15,600
him so it means that

647
00:24:15,600 --> 00:24:18,640
he has i mean it can

648
00:24:18,640 --> 00:24:20,320
tune the measurement setup so that there

649
00:24:20,320 --> 00:24:21,520
is no

650
00:24:21,520 --> 00:24:22,480
jitter

651
00:24:22,480 --> 00:24:24,799
i mean so that there is no jitter so in

652
00:24:24,799 --> 00:24:26,159
practice

653
00:24:26,159 --> 00:24:28,880
on the mcu we use the crystal to derive

654
00:24:28,880 --> 00:24:30,799
the clock

655
00:24:30,799 --> 00:24:33,039
i think that if this is not possible

656
00:24:33,039 --> 00:24:34,480
probably that

657
00:24:34,480 --> 00:24:36,320
you could use

658
00:24:36,320 --> 00:24:39,918
realignment process for that

659
00:24:40,799 --> 00:24:42,720
but i'm not sure that rely on jitter

660
00:24:42,720 --> 00:24:46,159
it's a good security

661
00:24:46,159 --> 00:24:48,400
not sure that at least when

662
00:24:48,400 --> 00:24:50,640
you can put a crystal a natural jitter

663
00:24:50,640 --> 00:24:54,159
provide meaningful security

664
00:24:54,720 --> 00:24:56,320
okay thank you

665
00:24:56,320 --> 00:24:59,360
and we've got another one

666
00:24:59,360 --> 00:25:02,080
too here what is the reason that more

667
00:25:02,080 --> 00:25:04,640
trace is required to attack glide

668
00:25:04,640 --> 00:25:08,000
compared to aes on cortex m0 is this

669
00:25:08,000 --> 00:25:09,679
really due to the

670
00:25:09,679 --> 00:25:11,600
more compact nature

671
00:25:11,600 --> 00:25:14,400
fewer instructions or maybe related to

672
00:25:14,400 --> 00:25:18,240
more randomness used within the circuit

673
00:25:18,240 --> 00:25:19,760
so there is

674
00:25:19,760 --> 00:25:22,000
two things first

675
00:25:22,000 --> 00:25:23,760
there is less computation involved in

676
00:25:23,760 --> 00:25:26,400
clyde so there is less points

677
00:25:26,400 --> 00:25:29,279
where there is some leakages i mean

678
00:25:29,279 --> 00:25:30,799
the traces are shorter so less

679
00:25:30,799 --> 00:25:33,120
information is available

680
00:25:33,120 --> 00:25:36,480
and then also um clyde is designed to be

681
00:25:36,480 --> 00:25:38,640
bit sliced on 32 bit

682
00:25:38,640 --> 00:25:40,960
while aes is not

683
00:25:40,960 --> 00:25:42,400
to have efficient bit slice

684
00:25:42,400 --> 00:25:45,360
implementation of aes you have to be

685
00:25:45,360 --> 00:25:46,799
sliced on

686
00:25:46,799 --> 00:25:48,320
16 bits

687
00:25:48,320 --> 00:25:50,159
and you can i mean

688
00:25:50,159 --> 00:25:53,440
there is on in on the good rz and river

689
00:25:53,440 --> 00:25:55,760
implementation we investigate it

690
00:25:55,760 --> 00:25:58,000
there is some shift where you put data

691
00:25:58,000 --> 00:26:02,960
on some of the 32 bits and you use

692
00:26:03,279 --> 00:26:06,080
the 16 remaining bits to do other things

693
00:26:06,080 --> 00:26:07,120
and

694
00:26:07,120 --> 00:26:09,440
i think this is one of the big issue

695
00:26:09,440 --> 00:26:12,000
with this aes implementation so there is

696
00:26:12,000 --> 00:26:14,000
really a lot of details in the paper so

697
00:26:14,000 --> 00:26:16,320
i think if this is interesting for you

698
00:26:16,320 --> 00:26:18,000
this is the the

699
00:26:18,000 --> 00:26:21,360
i mean where you should have a look

700
00:26:21,360 --> 00:26:23,279
thank you very much i think we should

701
00:26:23,279 --> 00:26:24,960
move on to the next

702
00:26:24,960 --> 00:26:26,240
talk

703
00:26:26,240 --> 00:26:28,240
the last question is from mark by the

704
00:26:28,240 --> 00:26:30,960
way thank you very much

705
00:26:30,960 --> 00:26:32,159
thanks

706
00:26:32,159 --> 00:26:33,840
thank you very much for the talk so the

707
00:26:33,840 --> 00:26:35,840
next talk is about the high order lookup

708
00:26:35,840 --> 00:26:37,200
tables

709
00:26:37,200 --> 00:26:40,400
and from the paper is from annapurna

710
00:26:40,400 --> 00:26:43,200
valivety and srinivas vivec

711
00:26:43,200 --> 00:26:45,360
and anapona will give the talk so the

712
00:26:45,360 --> 00:26:48,840
floor is yours

713
00:26:56,480 --> 00:27:01,799
yes can you make it full screen mode yes

714
00:27:10,240 --> 00:27:12,240
i'll be presenting our work titled uh

715
00:27:12,240 --> 00:27:13,760
higher order lookup table masking and

716
00:27:13,760 --> 00:27:15,600
essentially constant memory

717
00:27:15,600 --> 00:27:18,080
i'll uh uh

718
00:27:18,080 --> 00:27:20,559
from password is uh

719
00:27:20,559 --> 00:27:21,360
the

720
00:27:21,360 --> 00:27:22,720
terms like side channel attack and

721
00:27:22,720 --> 00:27:24,880
masking are very known to everyone i'll

722
00:27:24,880 --> 00:27:26,640
start directly with our problem

723
00:27:26,640 --> 00:27:27,679
statement

724
00:27:27,679 --> 00:27:30,320
the goal of our work is to optimize the

725
00:27:30,320 --> 00:27:32,320
memory required for a higher order

726
00:27:32,320 --> 00:27:34,880
lookup table scheme

727
00:27:34,880 --> 00:27:36,960
so if we look at the current state of

728
00:27:36,960 --> 00:27:38,080
the art of

729
00:27:38,080 --> 00:27:40,000
higher order lookup table schemes

730
00:27:40,000 --> 00:27:44,080
for a k k prime s box we need the memory

731
00:27:44,080 --> 00:27:45,919
of 2 power k

732
00:27:45,919 --> 00:27:49,200
times the number of shares n and uh each

733
00:27:49,200 --> 00:27:50,880
entry of the table will be of k prime

734
00:27:50,880 --> 00:27:52,880
bits so this is the memory required for

735
00:27:52,880 --> 00:27:56,000
a single lookup table of s box and uh

736
00:27:56,000 --> 00:27:58,000
and the memory required is almost

737
00:27:58,000 --> 00:28:00,399
similar which is of uh

738
00:28:00,399 --> 00:28:02,159
in the quadratic

739
00:28:02,159 --> 00:28:04,000
in terms of the number of shares and if

740
00:28:04,000 --> 00:28:05,840
we instantiate this higher order lookup

741
00:28:05,840 --> 00:28:07,760
table scheme for a 10th order secure

742
00:28:07,760 --> 00:28:09,039
implementation

743
00:28:09,039 --> 00:28:11,840
uh with full preprocessing what i mean

744
00:28:11,840 --> 00:28:14,640
to say by full preprocessing is we make

745
00:28:14,640 --> 00:28:16,640
the lookup tables ready for the com for

746
00:28:16,640 --> 00:28:19,120
the final lookup uh there will be some

747
00:28:19,120 --> 00:28:21,120
uh pre-computation required for the

748
00:28:21,120 --> 00:28:23,520
lookup tables before the final lookup

749
00:28:23,520 --> 00:28:26,159
will uh pre-compute that uh lookup

750
00:28:26,159 --> 00:28:29,440
tables independent of the secret and uh

751
00:28:29,440 --> 00:28:31,600
if at all that pre-processing is a we

752
00:28:31,600 --> 00:28:33,760
want to go for a pre-processing uh

753
00:28:33,760 --> 00:28:36,640
approach we need a memory of 440

754
00:28:36,640 --> 00:28:37,840
kilobytes

755
00:28:37,840 --> 00:28:39,320
per uh

756
00:28:39,320 --> 00:28:41,919
as128 implementation

757
00:28:41,919 --> 00:28:44,880
so this may this memory may be uh heavy

758
00:28:44,880 --> 00:28:46,240
for the resource constraint especially

759
00:28:46,240 --> 00:28:48,720
the memory constraint devices so how can

760
00:28:48,720 --> 00:28:51,279
we uh optimize the memory required so

761
00:28:51,279 --> 00:28:53,520
that is the goal of our work

762
00:28:53,520 --> 00:28:54,320
uh

763
00:28:54,320 --> 00:28:56,799
there are two possibilities to reduce

764
00:28:56,799 --> 00:28:59,520
the memory required either we can

765
00:28:59,520 --> 00:29:00,960
reduce the number of rows we can

766
00:29:00,960 --> 00:29:02,799
compress the number of rows to per k

767
00:29:02,799 --> 00:29:06,399
rows or we can now go for a compression

768
00:29:06,399 --> 00:29:07,840
across the columns we can reduce the

769
00:29:07,840 --> 00:29:09,279
number of columns

770
00:29:09,279 --> 00:29:11,039
the first approach of reducing the

771
00:29:11,039 --> 00:29:12,559
number of rows we explored in the

772
00:29:12,559 --> 00:29:13,919
previous uh just

773
00:29:13,919 --> 00:29:16,240
just uh

774
00:29:16,240 --> 00:29:19,919
yes such as 2020 so there we have uh

775
00:29:19,919 --> 00:29:22,480
we opted for a second order compression

776
00:29:22,480 --> 00:29:24,480
but uh still the higher order

777
00:29:24,480 --> 00:29:26,640
compression is a open problem we we are

778
00:29:26,640 --> 00:29:27,600
not

779
00:29:27,600 --> 00:29:29,279
the extension of the second order to

780
00:29:29,279 --> 00:29:31,360
higher orders is still open problem so

781
00:29:31,360 --> 00:29:35,039
in this work uh we uh we opted for uh

782
00:29:35,039 --> 00:29:38,480
reducing the number of columns

783
00:29:38,640 --> 00:29:42,720
so the essentially the ideas behind our

784
00:29:42,720 --> 00:29:44,399
work to reduce the number of columns is

785
00:29:44,399 --> 00:29:45,520
nothing but

786
00:29:45,520 --> 00:29:48,399
we want to make or we would like to

787
00:29:48,399 --> 00:29:49,679
store only the first column of the

788
00:29:49,679 --> 00:29:51,760
lookup table so that the remaining n

789
00:29:51,760 --> 00:29:53,840
minus one columns will not be storing

790
00:29:53,840 --> 00:29:56,480
them so how we can really uh etch a

791
00:29:56,480 --> 00:29:58,399
security without storing the n minus one

792
00:29:58,399 --> 00:30:00,960
columns is that uh if you as if you

793
00:30:00,960 --> 00:30:02,640
observe the lookup table uh compression

794
00:30:02,640 --> 00:30:04,880
scheme from eurocrypt14

795
00:30:04,880 --> 00:30:06,559
n minus one columns are nothing but

796
00:30:06,559 --> 00:30:09,600
random values uh each s box will be

797
00:30:09,600 --> 00:30:12,080
shifted by the secret share and it will

798
00:30:12,080 --> 00:30:14,399
be protected with the remaining n minus

799
00:30:14,399 --> 00:30:16,799
one random masks so the remaining n

800
00:30:16,799 --> 00:30:18,480
minus one columns are to store the

801
00:30:18,480 --> 00:30:19,600
random mass

802
00:30:19,600 --> 00:30:22,320
so if we can somehow avoid to avoid uh

803
00:30:22,320 --> 00:30:24,799
storing the n minus one columns what we

804
00:30:24,799 --> 00:30:26,720
obtained is we will be going for a

805
00:30:26,720 --> 00:30:28,399
pseudo random generator

806
00:30:28,399 --> 00:30:29,919
so since it is a deterministic

807
00:30:29,919 --> 00:30:32,480
construction we can uh call the pseudo

808
00:30:32,480 --> 00:30:34,159
random generator whenever we want to

809
00:30:34,159 --> 00:30:36,480
compute the output masks so that is the

810
00:30:36,480 --> 00:30:38,640
idea so that essentially we'll be

811
00:30:38,640 --> 00:30:41,200
computing the masks on the fly whenever

812
00:30:41,200 --> 00:30:42,720
we want to protect the

813
00:30:42,720 --> 00:30:45,200
shift and we'll be discarding the random

814
00:30:45,200 --> 00:30:46,880
masks and whenever we want we'll be

815
00:30:46,880 --> 00:30:48,799
recomputing them

816
00:30:48,799 --> 00:30:50,640
so as i mentioned there is a

817
00:30:50,640 --> 00:30:52,960
recomputation step involved this will be

818
00:30:52,960 --> 00:30:54,720
the additional overhead compared to the

819
00:30:54,720 --> 00:30:56,799
euro crypto14 scheme we need to

820
00:30:56,799 --> 00:31:00,000
recompute the

821
00:31:01,279 --> 00:31:02,640
remaining and management columns of the

822
00:31:02,640 --> 00:31:04,640
lookup table and we want to uh if you

823
00:31:04,640 --> 00:31:06,159
look at our full version of the paper

824
00:31:06,159 --> 00:31:08,240
you can see how we can better optimize

825
00:31:08,240 --> 00:31:10,880
this uh or overhead and when it comes

826
00:31:10,880 --> 00:31:12,399
since we want to compute the randomness

827
00:31:12,399 --> 00:31:14,399
using a prg construction the

828
00:31:14,399 --> 00:31:17,039
the prg construction also should be

829
00:31:17,039 --> 00:31:18,799
proving secure the adversary can also

830
00:31:18,799 --> 00:31:20,799
look into the intermediates of the prg

831
00:31:20,799 --> 00:31:22,640
so we want the prg construction to be

832
00:31:22,640 --> 00:31:26,000
over uh probing secure and there are two

833
00:31:26,000 --> 00:31:27,600
choices from the state of the art one is

834
00:31:27,600 --> 00:31:29,760
the robust prg construction proposed by

835
00:31:29,760 --> 00:31:32,320
isha at all and the other one is uh

836
00:31:32,320 --> 00:31:34,960
proposed in caron and others in europe

837
00:31:34,960 --> 00:31:36,399
20.

838
00:31:36,399 --> 00:31:38,640
so the because we want to optimize the

839
00:31:38,640 --> 00:31:40,799
memory we want to we want the input c to

840
00:31:40,799 --> 00:31:41,840
the random

841
00:31:41,840 --> 00:31:45,279
prg as minimum as possible so uh that

842
00:31:45,279 --> 00:31:47,440
that depends on there is a locality

843
00:31:47,440 --> 00:31:49,679
which is nothing but which decides how

844
00:31:49,679 --> 00:31:52,399
many random bits we need for the prg so

845
00:31:52,399 --> 00:31:54,240
the locality if you can improve the

846
00:31:54,240 --> 00:31:56,399
locality of the scheme that essentially

847
00:31:56,399 --> 00:31:59,600
will uh optimize the prgc as well

848
00:31:59,600 --> 00:32:00,960
so these are the

849
00:32:00,960 --> 00:32:04,480
ideas high-level ideas of the first

850
00:32:04,720 --> 00:32:07,679
scheme and uh if i compare the

851
00:32:07,679 --> 00:32:09,279
essentially the european scheme versus

852
00:32:09,279 --> 00:32:10,720
ours you can clearly see that we have

853
00:32:10,720 --> 00:32:12,240
only one column in the lookup table

854
00:32:12,240 --> 00:32:14,320
whereas the other scheme has n columns

855
00:32:14,320 --> 00:32:16,720
and the prg will generate the random

856
00:32:16,720 --> 00:32:18,559
mass required for this and

857
00:32:18,559 --> 00:32:20,559
we also have additional advantages using

858
00:32:20,559 --> 00:32:23,120
lr not only the locality of the circuit

859
00:32:23,120 --> 00:32:25,279
it also have other advantages you can

860
00:32:25,279 --> 00:32:26,799
look for the full version of our paper

861
00:32:26,799 --> 00:32:30,240
to find out the additional advantages

862
00:32:30,240 --> 00:32:32,799
and this part will be pre-processing to

863
00:32:32,799 --> 00:32:35,279
achieve better online execution time so

864
00:32:35,279 --> 00:32:37,279
online execution time will

865
00:32:37,279 --> 00:32:39,279
have a lookup as i mentioned the

866
00:32:39,279 --> 00:32:41,279
overhead of computing the n minus 1

867
00:32:41,279 --> 00:32:43,360
random masks so the computation step

868
00:32:43,360 --> 00:32:46,880
also involved before the lookup so uh

869
00:32:46,880 --> 00:32:48,960
this is a high level view of our scheme

870
00:32:48,960 --> 00:32:50,240
and

871
00:32:50,240 --> 00:32:52,640
if i i just want to touch upon the

872
00:32:52,640 --> 00:32:55,279
robust prg and the multi prg techniques

873
00:32:55,279 --> 00:32:57,760
at a very high level uh the robust prg

874
00:32:57,760 --> 00:33:00,159
technique will look at the

875
00:33:00,159 --> 00:33:01,840
complete implementation as a single

876
00:33:01,840 --> 00:33:03,840
large circu and we'll be computing the

877
00:33:03,840 --> 00:33:06,240
locality with respect to the circuit we

878
00:33:06,240 --> 00:33:08,399
prove that constructions using the tsne

879
00:33:08,399 --> 00:33:10,640
security composition security notation

880
00:33:10,640 --> 00:33:12,960
when it comes to the multi prg we will

881
00:33:12,960 --> 00:33:15,679
be dividing the randomness required as

882
00:33:15,679 --> 00:33:16,799
subsets

883
00:33:16,799 --> 00:33:19,600
so each column will be treated as a

884
00:33:19,600 --> 00:33:22,480
uh as a subset and we will be generating

885
00:33:22,480 --> 00:33:25,600
we will be using a prg per subset

886
00:33:25,600 --> 00:33:28,640
so it can be viewed as uh the robust prg

887
00:33:28,640 --> 00:33:30,880
as a

888
00:33:31,120 --> 00:33:32,799
single large circuit whereas the multi

889
00:33:32,799 --> 00:33:36,159
prg will have a dedicated prg per column

890
00:33:36,159 --> 00:33:38,080
and uh uh we assume the worst case

891
00:33:38,080 --> 00:33:40,320
scenario since we are not uh the the

892
00:33:40,320 --> 00:33:42,320
multi-prg constructions in the since the

893
00:33:42,320 --> 00:33:45,600
prg's are not robust if we assume the

894
00:33:45,600 --> 00:33:48,399
worst case scenario of the adversary can

895
00:33:48,399 --> 00:33:49,919
possible we can now make give the

896
00:33:49,919 --> 00:33:51,679
adversary the whole column the whole

897
00:33:51,679 --> 00:33:53,679
randomness subset to the adversary so

898
00:33:53,679 --> 00:33:55,360
that is why we approve this

899
00:33:55,360 --> 00:33:57,039
constructions in the extended security

900
00:33:57,039 --> 00:33:59,120
model it's an ir star

901
00:33:59,120 --> 00:34:00,720
and

902
00:34:00,720 --> 00:34:03,200
if i compare the asymptotics of our

903
00:34:03,200 --> 00:34:05,919
schemes uh the two schemes uh we have

904
00:34:05,919 --> 00:34:09,359
only two part k times uh uh k prime

905
00:34:09,359 --> 00:34:10,879
which is to store the first column of

906
00:34:10,879 --> 00:34:13,040
the lookup table and this is to store

907
00:34:13,040 --> 00:34:14,960
the input random save

908
00:34:14,960 --> 00:34:16,320
for the robust and multi prg

909
00:34:16,320 --> 00:34:18,079
constructions and now it has the time

910
00:34:18,079 --> 00:34:21,119
per prg will depend upon the seed to the

911
00:34:21,119 --> 00:34:23,040
it will decide we use the polynomial

912
00:34:23,040 --> 00:34:25,359
based prg construction so the time

913
00:34:25,359 --> 00:34:27,520
required for prg will depend upon the

914
00:34:27,520 --> 00:34:28,879
inputs to the polynomial prg

915
00:34:28,879 --> 00:34:30,399
construction

916
00:34:30,399 --> 00:34:33,040
and finally the results this is for a

917
00:34:33,040 --> 00:34:35,280
multi prg construction of

918
00:34:35,280 --> 00:34:36,960
aes 128

919
00:34:36,960 --> 00:34:39,280
we explore the orders of n is equal to 3

920
00:34:39,280 --> 00:34:42,159
to 11 which is uh the security of

921
00:34:42,159 --> 00:34:44,480
10th order of security we essentially

922
00:34:44,480 --> 00:34:47,040
require 42 kb of memory to store the

923
00:34:47,040 --> 00:34:49,760
pre-process tables and

924
00:34:49,760 --> 00:34:51,520
you can see that the

925
00:34:51,520 --> 00:34:53,199
online execution time is essentially

926
00:34:53,199 --> 00:34:55,440
four million clock cycles we offloaded

927
00:34:55,440 --> 00:34:56,320
the

928
00:34:56,320 --> 00:34:57,920
uh the heavy part of the computation to

929
00:34:57,920 --> 00:35:00,160
the pre-processed phase and the online

930
00:35:00,160 --> 00:35:01,280
computation

931
00:35:01,280 --> 00:35:03,599
is 4 million clock cycles

932
00:35:03,599 --> 00:35:06,800
and i would like to conclude the

933
00:35:06,800 --> 00:35:09,280
experiment

934
00:35:09,520 --> 00:35:11,359
in fact the 10th order so it requires

935
00:35:11,359 --> 00:35:13,119
approximately 40 kb to store the

936
00:35:13,119 --> 00:35:15,520
pre-process tables plus the random seed

937
00:35:15,520 --> 00:35:17,599
input and also this is another

938
00:35:17,599 --> 00:35:19,280
interesting feature we explored that the

939
00:35:19,280 --> 00:35:22,160
rng versus prg speed of inbuilt the

940
00:35:22,160 --> 00:35:23,520
lookup table based schemes have a

941
00:35:23,520 --> 00:35:26,560
pre-processing phase so we can try the

942
00:35:26,560 --> 00:35:28,880
random number generator prg for uh

943
00:35:28,880 --> 00:35:31,520
offline and a faster trng if at all the

944
00:35:31,520 --> 00:35:34,079
device has a fast pr ng we can also play

945
00:35:34,079 --> 00:35:36,160
the tradeoffs to achieve a better only

946
00:35:36,160 --> 00:35:38,480
execution time and we compare our

947
00:35:38,480 --> 00:35:40,800
results with the big slice radius so we

948
00:35:40,800 --> 00:35:42,960
are one time 1.5 times faster than the

949
00:35:42,960 --> 00:35:44,960
8-bit bit slice and we are almost

950
00:35:44,960 --> 00:35:47,280
comparable to a 32-bit bit sliced uh

951
00:35:47,280 --> 00:35:49,599
implementation so that may be the

952
00:35:49,599 --> 00:35:51,280
possible future work we would like to

953
00:35:51,280 --> 00:35:53,040
explore

954
00:35:53,040 --> 00:35:54,880
and uh

955
00:35:54,880 --> 00:35:57,040
thank you for the artifact initiative in

956
00:35:57,040 --> 00:36:00,160
just 2021 now we have the uh we have our

957
00:36:00,160 --> 00:36:02,000
code the

958
00:36:02,000 --> 00:36:04,640
artifact and also our github page

959
00:36:04,640 --> 00:36:06,960
thank you

960
00:36:07,280 --> 00:36:09,920
thank you so much um

961
00:36:09,920 --> 00:36:12,480
although we've got one question from you

962
00:36:12,480 --> 00:36:14,560
but i think we are running out of time

963
00:36:14,560 --> 00:36:16,640
so i think it's better

964
00:36:16,640 --> 00:36:18,480
yeah i i i

965
00:36:18,480 --> 00:36:20,480
i'll answer the question

966
00:36:20,480 --> 00:36:21,280
yeah

967
00:36:21,280 --> 00:36:23,119
please continue the discussion in the

968
00:36:23,119 --> 00:36:25,359
leap

969
00:36:25,359 --> 00:36:27,760
okay thank you um so the next talking

970
00:36:27,760 --> 00:36:29,920
about is about low latency ketchup at

971
00:36:29,920 --> 00:36:32,720
any arbitrary order the peru is from

972
00:36:32,720 --> 00:36:36,720
sahara zahi ain't hazard

973
00:36:44,160 --> 00:36:46,560
do you have my screens no

974
00:36:46,560 --> 00:36:48,720
yes we see it perfectly thanks great

975
00:36:48,720 --> 00:36:50,720
thank you thank you very much for your

976
00:36:50,720 --> 00:36:53,280
introduction uh hello everybody i'm

977
00:36:53,280 --> 00:36:55,359
sarah zory and i have the pleasure of

978
00:36:55,359 --> 00:36:57,359
presenting our joint work with online

979
00:36:57,359 --> 00:37:00,599
resolution resolution money razers

980
00:37:00,599 --> 00:37:03,599
foreign our paper is invited now you can

981
00:37:03,599 --> 00:37:06,560
see you check at any arbitrary order

982
00:37:06,560 --> 00:37:09,200
now this side channel immune realization

983
00:37:09,200 --> 00:37:11,760
of ketchup that we have proposed in our

984
00:37:11,760 --> 00:37:14,400
paper can be well introduced by its

985
00:37:14,400 --> 00:37:16,720
three key properties its low latency

986
00:37:16,720 --> 00:37:19,920
compact and extendable to any uh desired

987
00:37:19,920 --> 00:37:22,480
security order respectively there is low

988
00:37:22,480 --> 00:37:24,640
latency since we have designed it with

989
00:37:24,640 --> 00:37:26,800
only one research staged around its

990
00:37:26,800 --> 00:37:28,640
contact uh

991
00:37:28,640 --> 00:37:30,640
compared to its competitors from the

992
00:37:30,640 --> 00:37:33,200
state of the arts uh due to using d plus

993
00:37:33,200 --> 00:37:35,839
one mainstream instead of gt plus one

994
00:37:35,839 --> 00:37:37,920
and uh finally with regard to the

995
00:37:37,920 --> 00:37:39,760
straightforward algorithm that we have

996
00:37:39,760 --> 00:37:42,000
provided for it it can be

997
00:37:42,000 --> 00:37:44,720
implemented in any arbitrary security

998
00:37:44,720 --> 00:37:48,000
order while preserving its um

999
00:37:48,000 --> 00:37:50,560
outstanding properties in the rest of my

1000
00:37:50,560 --> 00:37:52,960
talk first i will explain our motivation

1001
00:37:52,960 --> 00:37:55,760
for uh proposing such a realization and

1002
00:37:55,760 --> 00:37:58,000
then i will go through the details of

1003
00:37:58,000 --> 00:38:00,560
our design and its evaluation results of

1004
00:38:00,560 --> 00:38:02,480
course all in brief

1005
00:38:02,480 --> 00:38:04,640
now here we have a puzzle-like view of

1006
00:38:04,640 --> 00:38:06,160
the most significant mass

1007
00:38:06,160 --> 00:38:08,560
implementations of keycheck in which i

1008
00:38:08,560 --> 00:38:11,599
have divided the existing designs into

1009
00:38:11,599 --> 00:38:12,880
three groups

1010
00:38:12,880 --> 00:38:15,280
first and higher order implementations

1011
00:38:15,280 --> 00:38:17,280
and the low latency ones

1012
00:38:17,280 --> 00:38:19,839
this kind of categorization although uh

1013
00:38:19,839 --> 00:38:22,160
can be a bit inaccurate since uh being

1014
00:38:22,160 --> 00:38:24,160
your latency can be

1015
00:38:24,160 --> 00:38:26,720
counted as a property of any first or

1016
00:38:26,720 --> 00:38:29,520
high order implementation but i have

1017
00:38:29,520 --> 00:38:31,359
separated this kind of designs into

1018
00:38:31,359 --> 00:38:32,640
their own

1019
00:38:32,640 --> 00:38:35,599
individual good just to investigate and

1020
00:38:35,599 --> 00:38:38,560
study them more uh closely so

1021
00:38:38,560 --> 00:38:40,480
this map does not imply that the mass

1022
00:38:40,480 --> 00:38:42,880
implementations of the check are

1023
00:38:42,880 --> 00:38:45,119
either first or high order or they are

1024
00:38:45,119 --> 00:38:47,680
low latency in fact the third column

1025
00:38:47,680 --> 00:38:50,400
tries to pick out the low latency cases

1026
00:38:50,400 --> 00:38:53,599
of uh the first loop of course if there

1027
00:38:53,599 --> 00:38:56,320
are any and as we can see here

1028
00:38:56,320 --> 00:38:58,960
amongst the previously proposed designs

1029
00:38:58,960 --> 00:39:01,359
there has only been one design that aims

1030
00:39:01,359 --> 00:39:04,800
to be low latency this implementation

1031
00:39:04,800 --> 00:39:07,280
employs the android architecture which

1032
00:39:07,280 --> 00:39:10,320
necessitates doubling the security order

1033
00:39:10,320 --> 00:39:12,320
at the start of its implementation due

1034
00:39:12,320 --> 00:39:13,359
to

1035
00:39:13,359 --> 00:39:15,040
maintaining the

1036
00:39:15,040 --> 00:39:17,599
completeness feature of its 2d plus one

1037
00:39:17,599 --> 00:39:21,040
masking on the learning masking skin

1038
00:39:21,040 --> 00:39:23,599
this duplication when considering uh the

1039
00:39:23,599 --> 00:39:26,000
high order implementations results in a

1040
00:39:26,000 --> 00:39:28,640
significant number of input shares

1041
00:39:28,640 --> 00:39:32,720
and as we have investigated in our paper

1042
00:39:32,720 --> 00:39:35,200
unfortunately they do not exist any

1043
00:39:35,200 --> 00:39:37,200
efficient or affordable

1044
00:39:37,200 --> 00:39:39,359
realizations for the budgeting for

1045
00:39:39,359 --> 00:39:42,079
experimentation of ketchup when we want

1046
00:39:42,079 --> 00:39:44,560
to extend these uh low latency

1047
00:39:44,560 --> 00:39:47,359
implementation to second or uh higher

1048
00:39:47,359 --> 00:39:50,640
order implementation and this is our

1049
00:39:50,640 --> 00:39:53,200
strong motivation for proposing a

1050
00:39:53,200 --> 00:39:56,400
related serialization that

1051
00:39:56,400 --> 00:39:58,640
can be practically extended to any

1052
00:39:58,640 --> 00:40:02,640
arbitrary order and uh to this end we

1053
00:40:02,640 --> 00:40:04,400
switch that on the line masking and

1054
00:40:04,400 --> 00:40:05,680
scheme of the

1055
00:40:05,680 --> 00:40:09,040
implementation to d plus one and then uh

1056
00:40:09,040 --> 00:40:11,200
try to stay with the latency of an

1057
00:40:11,200 --> 00:40:13,839
unprotected implementation which is one

1058
00:40:13,839 --> 00:40:15,680
register per run

1059
00:40:15,680 --> 00:40:19,839
and let's have a look at how we did it

1060
00:40:19,839 --> 00:40:20,560
we

1061
00:40:20,560 --> 00:40:21,520
got the

1062
00:40:21,520 --> 00:40:24,000
drone function of the original d plus

1063
00:40:24,000 --> 00:40:26,560
one the mass implementation of the check

1064
00:40:26,560 --> 00:40:29,200
and move the compression layer to after

1065
00:40:29,200 --> 00:40:31,440
the data operation

1066
00:40:31,440 --> 00:40:34,079
this location allowed us to remove the

1067
00:40:34,079 --> 00:40:36,400
register stage subsequent to the g

1068
00:40:36,400 --> 00:40:39,440
operation and in this revised round

1069
00:40:39,440 --> 00:40:41,760
function we need the power of two

1070
00:40:41,760 --> 00:40:44,560
instances of tetra but uh the more

1071
00:40:44,560 --> 00:40:45,839
important challenge is the

1072
00:40:45,839 --> 00:40:48,000
non-competence failure that

1073
00:40:48,000 --> 00:40:50,960
happens as the result of the subsequent

1074
00:40:50,960 --> 00:40:53,359
applications of settle and shield

1075
00:40:53,359 --> 00:40:55,200
versions without any in between

1076
00:40:55,200 --> 00:40:56,480
registers

1077
00:40:56,480 --> 00:40:58,160
in fact

1078
00:40:58,160 --> 00:41:00,880
although theta is a linear round for a

1079
00:41:00,880 --> 00:41:02,480
linear function

1080
00:41:02,480 --> 00:41:05,839
but its design is in such a way that

1081
00:41:05,839 --> 00:41:08,079
it puts more than one share of each

1082
00:41:08,079 --> 00:41:10,560
input variable in an output share

1083
00:41:10,560 --> 00:41:13,040
and hence it falsifies an uncompleteness

1084
00:41:13,040 --> 00:41:15,200
when we consider their deeper being

1085
00:41:15,200 --> 00:41:16,319
model

1086
00:41:16,319 --> 00:41:19,040
our solution for this issue

1087
00:41:19,040 --> 00:41:22,079
is developed based on a realignment of

1088
00:41:22,079 --> 00:41:25,760
the component function that are

1089
00:41:25,760 --> 00:41:29,200
produced and aligned in the achieve

1090
00:41:29,200 --> 00:41:31,839
function according to the d plus one

1091
00:41:31,839 --> 00:41:34,079
mastery state

1092
00:41:34,079 --> 00:41:36,960
in fact we have proposed

1093
00:41:36,960 --> 00:41:38,160
an algorithm that kind of

1094
00:41:38,160 --> 00:41:40,960
straightforwardly uh explain how this

1095
00:41:40,960 --> 00:41:43,760
alignment can be applied to in any

1096
00:41:43,760 --> 00:41:46,000
arbitrary order

1097
00:41:46,000 --> 00:41:47,680
and this is uh

1098
00:41:47,680 --> 00:41:49,920
the final version of our wrong function

1099
00:41:49,920 --> 00:41:52,560
which makes yourself another multiplexer

1100
00:41:52,560 --> 00:41:56,079
identified as max2 um to

1101
00:41:56,079 --> 00:41:58,000
take the outputs of the last zone

1102
00:41:58,000 --> 00:41:59,599
directly from the compression layer

1103
00:41:59,599 --> 00:42:01,680
which carries their number

1104
00:42:01,680 --> 00:42:04,560
to back to d plus one

1105
00:42:04,560 --> 00:42:05,280
we

1106
00:42:05,280 --> 00:42:07,599
have reported the

1107
00:42:07,599 --> 00:42:10,640
results of uh

1108
00:42:10,640 --> 00:42:12,800
performance and the performance of our

1109
00:42:12,800 --> 00:42:14,560
design from its

1110
00:42:14,560 --> 00:42:16,560
first to fifth order sexual

1111
00:42:16,560 --> 00:42:18,720
implementations which show that compared

1112
00:42:18,720 --> 00:42:19,440
to

1113
00:42:19,440 --> 00:42:22,160
uh the other proposed uh first order low

1114
00:42:22,160 --> 00:42:24,800
latency design ours achieved around

1115
00:42:24,800 --> 00:42:28,319
maybe around 74 percent lesser area

1116
00:42:28,319 --> 00:42:29,520
consumption

1117
00:42:29,520 --> 00:42:31,920
with almost the same delays and compared

1118
00:42:31,920 --> 00:42:32,720
to

1119
00:42:32,720 --> 00:42:34,960
uh the original d plus one implemented

1120
00:42:34,960 --> 00:42:37,839
mass implementations house has about uh

1121
00:42:37,839 --> 00:42:41,040
26 and uh 31

1122
00:42:41,040 --> 00:42:42,400
lesser

1123
00:42:42,400 --> 00:42:45,760
delays as its first and second orders

1124
00:42:45,760 --> 00:42:48,000
respectively

1125
00:42:48,000 --> 00:42:49,760
we have also performed some uh

1126
00:42:49,760 --> 00:42:52,800
experimental analysis including a fixed

1127
00:42:52,800 --> 00:42:54,960
with random t-test

1128
00:42:54,960 --> 00:42:56,160
using

1129
00:42:56,160 --> 00:42:58,319
100 million traces i have put the

1130
00:42:58,319 --> 00:43:01,280
results of the first order uh test here

1131
00:43:01,280 --> 00:43:04,160
and the result for the second and the

1132
00:43:04,160 --> 00:43:06,880
third test can also be found in our

1133
00:43:06,880 --> 00:43:08,240
paper

1134
00:43:08,240 --> 00:43:10,160
thank you for your attention and i'll be

1135
00:43:10,160 --> 00:43:13,599
happy to answer any questions

1136
00:43:13,599 --> 00:43:15,839
thank you very much

1137
00:43:15,839 --> 00:43:19,200
uh we haven't got any question yet so

1138
00:43:19,200 --> 00:43:22,240
yeah let's move on to the next talk

1139
00:43:22,240 --> 00:43:24,319
thank you sarah

1140
00:43:24,319 --> 00:43:26,000
okay thank you very much so that the

1141
00:43:26,000 --> 00:43:27,760
last talk of this session is about

1142
00:43:27,760 --> 00:43:29,440
revealing the weakness of addison

1143
00:43:29,440 --> 00:43:31,359
addition chains

1144
00:43:31,359 --> 00:43:32,800
um

1145
00:43:32,800 --> 00:43:35,359
the paper is by jing jiang ming

1146
00:43:35,359 --> 00:43:38,400
hui zhong li yong bing joo wai chang

1147
00:43:38,400 --> 00:43:41,280
ziwa kiyo

1148
00:43:44,960 --> 00:43:46,160
yes

1149
00:43:46,160 --> 00:43:47,680
okay thank you thanks for the

1150
00:43:47,680 --> 00:43:49,040
introduction

1151
00:43:49,040 --> 00:43:51,680
and hello everyone i will present our

1152
00:43:51,680 --> 00:43:53,280
work

1153
00:43:53,280 --> 00:43:55,839
to achieve masking asphalt can be

1154
00:43:55,839 --> 00:43:58,400
expressed as a sequence of squares and

1155
00:43:58,400 --> 00:44:00,000
multiplications

1156
00:44:00,000 --> 00:44:02,400
and these multiplications can be then

1157
00:44:02,400 --> 00:44:05,280
implemented using the non-scheme such as

1158
00:44:05,280 --> 00:44:09,119
sw and here is my example for the esx

1159
00:44:09,119 --> 00:44:10,960
box

1160
00:44:10,960 --> 00:44:13,280
and it is called the audition tm based

1161
00:44:13,280 --> 00:44:16,160
mask implementation because the

1162
00:44:16,160 --> 00:44:18,000
exponents are added

1163
00:44:18,000 --> 00:44:20,480
and actually it is one of the most

1164
00:44:20,480 --> 00:44:24,240
popular addition chain for essbox

1165
00:44:24,240 --> 00:44:26,240
it is used in lots of masking schemes

1166
00:44:26,240 --> 00:44:28,240
such as boolean masking the

1167
00:44:28,240 --> 00:44:31,040
multiplicative masking the inner product

1168
00:44:31,040 --> 00:44:33,359
masking

1169
00:44:33,359 --> 00:44:35,920
however the addition chain interface of

1170
00:44:35,920 --> 00:44:39,119
computations for monomials and nearly

1171
00:44:39,119 --> 00:44:41,680
half monomials over the finite field are

1172
00:44:41,680 --> 00:44:43,440
not balanced functions

1173
00:44:43,440 --> 00:44:46,400
so a natural question is what is the

1174
00:44:46,400 --> 00:44:48,480
computations of some intermediate

1175
00:44:48,480 --> 00:44:51,839
monomial stick more

1176
00:44:51,920 --> 00:44:54,800
to solve the problem we first review dpa

1177
00:44:54,800 --> 00:44:57,280
which is a classic cell channel

1178
00:44:57,280 --> 00:44:59,359
analysis

1179
00:44:59,359 --> 00:45:02,240
in dpa the liquid pieces are divided

1180
00:45:02,240 --> 00:45:05,280
into two groups based on the j speed of

1181
00:45:05,280 --> 00:45:08,640
the xbox output

1182
00:45:08,640 --> 00:45:09,760
and then

1183
00:45:09,760 --> 00:45:12,000
their differential expectation is a

1184
00:45:12,000 --> 00:45:14,160
distinguished value

1185
00:45:14,160 --> 00:45:18,079
but if the xbox is replaced by an embed

1186
00:45:18,079 --> 00:45:21,200
and balance function f the distance of f

1187
00:45:21,200 --> 00:45:23,680
may be always 0 or 1

1188
00:45:23,680 --> 00:45:24,720
and

1189
00:45:24,720 --> 00:45:27,200
the leakage cannot be divided into two

1190
00:45:27,200 --> 00:45:29,280
groups

1191
00:45:29,280 --> 00:45:31,680
in this case we said the distinguished

1192
00:45:31,680 --> 00:45:35,359
value data to zero and then we calculate

1193
00:45:35,359 --> 00:45:37,680
the average of the distinguished values

1194
00:45:37,680 --> 00:45:40,480
for all these of the key hoversys and

1195
00:45:40,480 --> 00:45:42,400
their hemi-weight model

1196
00:45:42,400 --> 00:45:45,040
we then define the polygon degree which

1197
00:45:45,040 --> 00:45:48,000
is called pd for short as a difference

1198
00:45:48,000 --> 00:45:50,640
between the distinguished value for the

1199
00:45:50,640 --> 00:45:53,040
correct key and those for other key

1200
00:45:53,040 --> 00:45:55,599
hovers

1201
00:45:55,680 --> 00:45:58,079
then we have that the smaller pde of a

1202
00:45:58,079 --> 00:46:00,160
function is the stronger it resists

1203
00:46:00,160 --> 00:46:02,560
against the channel tags because the

1204
00:46:02,560 --> 00:46:05,200
distinguished value is lower

1205
00:46:05,200 --> 00:46:08,000
and over we have that the pd is also

1206
00:46:08,000 --> 00:46:10,319
valid for the tags against mass

1207
00:46:10,319 --> 00:46:13,359
implementation because the expectation

1208
00:46:13,359 --> 00:46:15,599
of the combined leakage

1209
00:46:15,599 --> 00:46:18,079
follows a linear transformation of a

1210
00:46:18,079 --> 00:46:21,440
hamming weight distribution

1211
00:46:22,000 --> 00:46:24,960
we verify the surface of pd in

1212
00:46:24,960 --> 00:46:26,640
simulation

1213
00:46:26,640 --> 00:46:28,640
in forbidden case

1214
00:46:28,640 --> 00:46:31,599
if we classify the monomials by pd

1215
00:46:31,599 --> 00:46:33,119
values

1216
00:46:33,119 --> 00:46:35,599
we can see that the cpa results match

1217
00:46:35,599 --> 00:46:38,640
the pd value spell

1218
00:46:38,640 --> 00:46:43,839
and in six speed case pd also works well

1219
00:46:44,480 --> 00:46:46,480
then we apply pd

1220
00:46:46,480 --> 00:46:48,960
for edition chair implementation

1221
00:46:48,960 --> 00:46:52,160
we instantiate two adversaries

1222
00:46:52,160 --> 00:46:55,440
the first adversary is only able to find

1223
00:46:55,440 --> 00:46:57,920
the leakage corresponding to one

1224
00:46:57,920 --> 00:47:01,040
sensitive intermediate then letter text

1225
00:47:01,040 --> 00:47:04,400
and the second adversary is able to land

1226
00:47:04,400 --> 00:47:06,720
asset channel tags on all sensitive

1227
00:47:06,720 --> 00:47:09,040
intermediates and then sum the results

1228
00:47:09,040 --> 00:47:11,200
together to achieve a higher success

1229
00:47:11,200 --> 00:47:13,520
rate

1230
00:47:13,760 --> 00:47:16,480
then we found three typical

1231
00:47:16,480 --> 00:47:18,800
addition chain with four multiplications

1232
00:47:18,800 --> 00:47:21,040
and seven squares

1233
00:47:21,040 --> 00:47:24,160
the first one is the weakest for both

1234
00:47:24,160 --> 00:47:26,800
two adversaries and the second one is

1235
00:47:26,800 --> 00:47:28,240
the strongest

1236
00:47:28,240 --> 00:47:28,960
the

1237
00:47:28,960 --> 00:47:31,920
third one is also very strong and can be

1238
00:47:31,920 --> 00:47:35,520
performed in parallel

1239
00:47:36,000 --> 00:47:38,800
here is our experiment setup

1240
00:47:38,800 --> 00:47:40,800
the properties and the em trees are

1241
00:47:40,800 --> 00:47:44,079
correct respectively and know that the

1242
00:47:44,079 --> 00:47:47,280
noise level for monomials are different

1243
00:47:47,280 --> 00:47:49,839
and the difference gets more obvious for

1244
00:47:49,839 --> 00:47:52,000
em chases uh is

1245
00:47:52,000 --> 00:47:54,400
this difference will also affect the

1246
00:47:54,400 --> 00:47:57,280
attack results

1247
00:47:57,520 --> 00:48:00,319
and here is a practical result of the

1248
00:48:00,319 --> 00:48:03,440
number of required pieces to reach a gas

1249
00:48:03,440 --> 00:48:05,599
entropy lower than 10.

1250
00:48:05,599 --> 00:48:08,480
we can see that the two strong legend

1251
00:48:08,480 --> 00:48:09,440
chance

1252
00:48:09,440 --> 00:48:12,720
uh is better than the other two

1253
00:48:12,720 --> 00:48:15,920
and in the worst case uh its resistance

1254
00:48:15,920 --> 00:48:16,800
is

1255
00:48:16,800 --> 00:48:20,480
uh close to that of an unprotected

1256
00:48:20,480 --> 00:48:24,400
lookup table based implementation

1257
00:48:24,640 --> 00:48:27,359
and last we summarize our work briefly

1258
00:48:27,359 --> 00:48:28,800
we target the addition chain

1259
00:48:28,800 --> 00:48:30,559
implementation with

1260
00:48:30,559 --> 00:48:33,359
boolean masking then we use pd to

1261
00:48:33,359 --> 00:48:36,400
qualify the resistance and value

1262
00:48:36,400 --> 00:48:39,599
using the higher order cpa

1263
00:48:39,599 --> 00:48:41,760
we also tried the mutual information as

1264
00:48:41,760 --> 00:48:44,800
a metric and valid using template attack

1265
00:48:44,800 --> 00:48:48,400
and deep learning based attack

1266
00:48:48,400 --> 00:48:50,400
please refer to our paper for their

1267
00:48:50,400 --> 00:48:53,440
results if you are interested

1268
00:48:53,440 --> 00:48:54,480
however

1269
00:48:54,480 --> 00:48:56,319
besides the addition chain there might

1270
00:48:56,319 --> 00:48:58,960
be other implementations including and

1271
00:48:58,960 --> 00:49:00,720
balance functions

1272
00:49:00,720 --> 00:49:03,040
and the advanced functions might be also

1273
00:49:03,040 --> 00:49:05,599
affect the security of other masking

1274
00:49:05,599 --> 00:49:07,040
schemes

1275
00:49:07,040 --> 00:49:09,760
then we may need other metrics to

1276
00:49:09,760 --> 00:49:11,520
qualify

1277
00:49:11,520 --> 00:49:14,480
the resistance and value them with other

1278
00:49:14,480 --> 00:49:17,480
distinguishers

1279
00:49:18,000 --> 00:49:21,680
thanks for listening my presentation

1280
00:49:21,760 --> 00:49:22,880
thank you

1281
00:49:22,880 --> 00:49:26,960
we've got one question from you again

1282
00:49:26,960 --> 00:49:29,599
yeah since we are running out of time so

1283
00:49:29,599 --> 00:49:32,720
i get just a part of it so what happens

1284
00:49:32,720 --> 00:49:37,359
if you change the primitive polynomial

1285
00:49:37,359 --> 00:49:38,240
uh

1286
00:49:38,240 --> 00:49:41,359
and i'm sorry

1287
00:49:41,760 --> 00:49:42,720
we

1288
00:49:42,720 --> 00:49:46,000
we don't try to try other precinct

1289
00:49:46,000 --> 00:49:48,640
monomial we just try the to

1290
00:49:48,640 --> 00:49:51,520
the simulation simulated text on the

1291
00:49:51,520 --> 00:49:54,800
monomers on the the popular

1292
00:49:54,800 --> 00:49:57,359
polymers

1293
00:49:57,359 --> 00:50:00,079
okay so yeah you can put some comments

1294
00:50:00,079 --> 00:50:01,280
on the

1295
00:50:01,280 --> 00:50:02,400
the

1296
00:50:02,400 --> 00:50:03,839
the property

1297
00:50:03,839 --> 00:50:07,200
regarding primitive polynomials so yeah

1298
00:50:07,200 --> 00:50:12,040
please okay okay continue the discussion

1299
00:50:13,680 --> 00:50:16,480
okay so i think this

1300
00:50:16,480 --> 00:50:18,319
ends the session

1301
00:50:18,319 --> 00:50:19,680
thank you very much to all the

1302
00:50:19,680 --> 00:50:22,000
participants in particular to all the

1303
00:50:22,000 --> 00:50:25,000
speakers

