1
00:00:15,379 --> 00:00:18,800
one two three

2
00:00:33,660 --> 00:00:36,800
the mutuals

3
00:00:36,800 --> 00:00:39,180
yeah yeah

4
00:00:39,180 --> 00:00:42,739
just let me know before we start

5
00:03:22,739 --> 00:03:25,739
foreign

6
00:05:00,600 --> 00:05:03,180
foreign

7
00:05:03,180 --> 00:05:08,040
okay so good morning and welcome back to

8
00:05:08,040 --> 00:05:11,400
the second day of chess the second

9
00:05:11,400 --> 00:05:14,639
session in the second track

10
00:05:14,639 --> 00:05:15,360
um

11
00:05:15,360 --> 00:05:18,300
so we have four speakers in it in the

12
00:05:18,300 --> 00:05:20,940
track today on efficient masking and the

13
00:05:20,940 --> 00:05:23,520
first talk will be on modular Nets

14
00:05:23,520 --> 00:05:26,340
neural networks meet modular arithmetic

15
00:05:26,340 --> 00:05:29,520
for efficient Hardware masking and the

16
00:05:29,520 --> 00:05:34,340
talk will be given by anush so thanks

17
00:05:37,320 --> 00:05:40,500
like thanks for the introduction Pascal

18
00:05:40,500 --> 00:05:43,199
um hello everyone my name is Anuj and

19
00:05:43,199 --> 00:05:44,639
today I would be presenting my talk

20
00:05:44,639 --> 00:05:46,680
called modular net

21
00:05:46,680 --> 00:05:50,280
this is Joint work with afzal Dr Pasha

22
00:05:50,280 --> 00:05:52,800
Dr kamarotta and my advisor Dr Eden ISU

23
00:05:52,800 --> 00:05:54,960
from North Carolina State University

24
00:05:54,960 --> 00:05:59,340
we have sponsors as the NSF and SRC

25
00:05:59,340 --> 00:06:00,680
okay

26
00:06:00,680 --> 00:06:03,479
so I believe uh this is the third day of

27
00:06:03,479 --> 00:06:05,520
Chess and we probably don't need any

28
00:06:05,520 --> 00:06:07,139
introduction to side channels

29
00:06:07,139 --> 00:06:09,900
specifically physical side channels

30
00:06:09,900 --> 00:06:11,759
um we know they're a big problem that

31
00:06:11,759 --> 00:06:14,699
needs to be solved and there's been some

32
00:06:14,699 --> 00:06:16,500
wonderful research over the past two

33
00:06:16,500 --> 00:06:18,120
decades on trying to fix this problem

34
00:06:18,120 --> 00:06:19,979
since it was first published in the late

35
00:06:19,979 --> 00:06:21,060
90s

36
00:06:21,060 --> 00:06:23,160
there are papers even in this chest

37
00:06:23,160 --> 00:06:25,380
which are trying to provide more and

38
00:06:25,380 --> 00:06:27,720
more robust and efficient counter

39
00:06:27,720 --> 00:06:29,880
measures to prevent physical side

40
00:06:29,880 --> 00:06:31,620
channels from extracting the

41
00:06:31,620 --> 00:06:33,660
confidential data from embedded systems

42
00:06:33,660 --> 00:06:35,520
however

43
00:06:35,520 --> 00:06:37,860
all this research that has been done has

44
00:06:37,860 --> 00:06:41,100
been mostly focused on crypto systems

45
00:06:41,100 --> 00:06:45,000
uh specifically the block ciphers and

46
00:06:45,000 --> 00:06:46,860
very lately the post Quantum crypto

47
00:06:46,860 --> 00:06:49,500
systems we try to do something different

48
00:06:49,500 --> 00:06:53,100
in this research work and Implement all

49
00:06:53,100 --> 00:06:54,780
these counter measures or we'll try to

50
00:06:54,780 --> 00:06:56,639
see how to leverage all these

51
00:06:56,639 --> 00:06:58,860
countermeasures for a different

52
00:06:58,860 --> 00:07:01,080
application and that application is

53
00:07:01,080 --> 00:07:03,000
machine learning which has recently

54
00:07:03,000 --> 00:07:05,699
emerged as a prominent field that

55
00:07:05,699 --> 00:07:08,039
requires confidentiality and that is

56
00:07:08,039 --> 00:07:09,840
primarily because the machine learning

57
00:07:09,840 --> 00:07:12,780
IPS well are basically yeah intellectual

58
00:07:12,780 --> 00:07:13,880
properties

59
00:07:13,880 --> 00:07:17,340
they have a value then that is because

60
00:07:17,340 --> 00:07:19,919
of many reasons the primary reasons

61
00:07:19,919 --> 00:07:22,139
being the the costs involved in

62
00:07:22,139 --> 00:07:24,180
developing these models so the research

63
00:07:24,180 --> 00:07:26,340
and development costs or the training

64
00:07:26,340 --> 00:07:27,900
data that is used to train these machine

65
00:07:27,900 --> 00:07:29,819
learning models which might not always

66
00:07:29,819 --> 00:07:31,259
be freely available

67
00:07:31,259 --> 00:07:34,080
and the training process as such which

68
00:07:34,080 --> 00:07:36,240
is so computationally intensive also

69
00:07:36,240 --> 00:07:38,759
requires some specific hardware and

70
00:07:38,759 --> 00:07:40,500
investment in that kind of Hardware to

71
00:07:40,500 --> 00:07:43,039
compute uh the neural network model

72
00:07:43,039 --> 00:07:44,819
parameters and hybrid parameters

73
00:07:44,819 --> 00:07:46,380
efficiently

74
00:07:46,380 --> 00:07:48,840
now that's the first aspect the second

75
00:07:48,840 --> 00:07:51,240
aspect why we need confidentiality is

76
00:07:51,240 --> 00:07:54,240
because having knowledge about the model

77
00:07:54,240 --> 00:07:56,940
internals also facilitates other attacks

78
00:07:56,940 --> 00:07:58,979
as has been seen in Prior research works

79
00:07:58,979 --> 00:08:01,740
for example the AdWords aerial attacks

80
00:08:01,740 --> 00:08:03,780
which try to fool the model becomes very

81
00:08:03,780 --> 00:08:06,120
easy if we know how if we are talking

82
00:08:06,120 --> 00:08:08,160
about a neural network how the nodes are

83
00:08:08,160 --> 00:08:09,720
arranged what are the weights and the

84
00:08:09,720 --> 00:08:12,120
biases model poisoning is another attack

85
00:08:12,120 --> 00:08:15,120
which tries to you know poison the

86
00:08:15,120 --> 00:08:17,759
training data to systematically cause

87
00:08:17,759 --> 00:08:20,099
Corruptions in the classifications and

88
00:08:20,099 --> 00:08:21,960
of course fault injection attacks which

89
00:08:21,960 --> 00:08:23,819
will obviously become easier if we know

90
00:08:23,819 --> 00:08:25,080
which nodes are important and which

91
00:08:25,080 --> 00:08:28,620
nodes are not so all these reasons uh

92
00:08:28,620 --> 00:08:31,020
build a very strong motivation for

93
00:08:31,020 --> 00:08:33,779
trying to extract model internals and

94
00:08:33,779 --> 00:08:35,399
physical side Channel attacks being one

95
00:08:35,399 --> 00:08:37,200
of the most potent attacks in today's

96
00:08:37,200 --> 00:08:41,039
literature has been specifically used to

97
00:08:41,039 --> 00:08:43,080
um extract all these model parameters

98
00:08:43,080 --> 00:08:45,480
not just in theory but also in practice

99
00:08:45,480 --> 00:08:47,760
this is just some of the research works

100
00:08:47,760 --> 00:08:49,680
from the past two three years that have

101
00:08:49,680 --> 00:08:51,540
tried to show that you can really

102
00:08:51,540 --> 00:08:54,300
extract the model internals by

103
00:08:54,300 --> 00:08:55,740
exploiting the physical side Channel

104
00:08:55,740 --> 00:08:56,940
attacks

105
00:08:56,940 --> 00:09:00,600
so given all this we asked the question

106
00:09:00,600 --> 00:09:02,760
what about the defenses

107
00:09:02,760 --> 00:09:05,940
and there has been very limited research

108
00:09:05,940 --> 00:09:08,100
on defenses compared to all these

109
00:09:08,100 --> 00:09:11,040
attacks specifically or well as far as I

110
00:09:11,040 --> 00:09:12,660
can see when we were submitting the work

111
00:09:12,660 --> 00:09:14,220
there were just three research works

112
00:09:14,220 --> 00:09:16,080
that tried to implement some form of

113
00:09:16,080 --> 00:09:17,940
Defense to prevent such model extraction

114
00:09:17,940 --> 00:09:19,080
attacks

115
00:09:19,080 --> 00:09:21,540
one of the defenses tried to implement a

116
00:09:21,540 --> 00:09:23,040
combination of masking and hiding

117
00:09:23,040 --> 00:09:25,320
countermeasures the second mesh

118
00:09:25,320 --> 00:09:27,060
countermeister tried to implement a

119
00:09:27,060 --> 00:09:29,279
fully Boolean masking scheme for a

120
00:09:29,279 --> 00:09:31,440
neural network and the third work which

121
00:09:31,440 --> 00:09:33,240
has been very recently published after

122
00:09:33,240 --> 00:09:34,980
our submission

123
00:09:34,980 --> 00:09:37,680
tries to do the same things on a

124
00:09:37,680 --> 00:09:39,420
software level

125
00:09:39,420 --> 00:09:42,240
now an important observation that we

126
00:09:42,240 --> 00:09:43,500
made is

127
00:09:43,500 --> 00:09:45,600
given all these differences the early

128
00:09:45,600 --> 00:09:48,000
defense research that we've always been

129
00:09:48,000 --> 00:09:50,040
trying to tune the defenses according to

130
00:09:50,040 --> 00:09:51,779
machine learning

131
00:09:51,779 --> 00:09:54,240
specifically because machine learning

132
00:09:54,240 --> 00:09:57,720
arithmetic in general is not really uh

133
00:09:57,720 --> 00:10:00,120
well it's not it's not exactly how the

134
00:10:00,120 --> 00:10:02,880
cryptographic arithmetic works it's

135
00:10:02,880 --> 00:10:05,459
difficult to directly leverage all the

136
00:10:05,459 --> 00:10:09,000
research work in masking to machine

137
00:10:09,000 --> 00:10:10,860
learning algorithms

138
00:10:10,860 --> 00:10:13,080
and that has been a big problem for

139
00:10:13,080 --> 00:10:14,519
example in one of the research works

140
00:10:14,519 --> 00:10:15,899
because of the absence of model

141
00:10:15,899 --> 00:10:18,060
arithmetic they had to specifically

142
00:10:18,060 --> 00:10:20,399
Implement a hiding countermeasure to

143
00:10:20,399 --> 00:10:22,860
prevent the sign bit leakage well the

144
00:10:22,860 --> 00:10:24,420
solution is you can always do a Boolean

145
00:10:24,420 --> 00:10:26,100
masking for the entire neural network

146
00:10:26,100 --> 00:10:27,480
but that is going to be extremely

147
00:10:27,480 --> 00:10:29,399
expensive because you are trying to

148
00:10:29,399 --> 00:10:31,620
perform Boolean masking on arithmetic

149
00:10:31,620 --> 00:10:35,040
operations so given all this we try to

150
00:10:35,040 --> 00:10:37,500
think can we really try to implement

151
00:10:37,500 --> 00:10:40,440
neural networks in a way that is more

152
00:10:40,440 --> 00:10:42,260
similar to neural network to

153
00:10:42,260 --> 00:10:44,640
cryptographic implementations and

154
00:10:44,640 --> 00:10:47,339
modular arithmetic being so integral to

155
00:10:47,339 --> 00:10:49,860
crypto systems is something that can

156
00:10:49,860 --> 00:10:51,839
definitely help us as we saw in this

157
00:10:51,839 --> 00:10:54,360
research work so we want to implement

158
00:10:54,360 --> 00:10:57,300
the neural network operations in a

159
00:10:57,300 --> 00:10:59,700
finite structure like a field or a ring

160
00:10:59,700 --> 00:11:01,800
which is how you know the crypto systems

161
00:11:01,800 --> 00:11:03,839
work and that can really help us to

162
00:11:03,839 --> 00:11:07,079
efficiently Implement masking on neural

163
00:11:07,079 --> 00:11:09,779
network functions so here are some of

164
00:11:09,779 --> 00:11:11,700
the key ideas of our research work the

165
00:11:11,700 --> 00:11:13,200
training is still performed in floating

166
00:11:13,200 --> 00:11:15,060
point and as we'll see in the threat

167
00:11:15,060 --> 00:11:17,220
model that's because we assume that

168
00:11:17,220 --> 00:11:19,860
training to still be performed uh in a

169
00:11:19,860 --> 00:11:22,140
secure environment inference is where we

170
00:11:22,140 --> 00:11:24,720
perform uh operations with modular

171
00:11:24,720 --> 00:11:27,300
arithmetic so all the additions that

172
00:11:27,300 --> 00:11:29,279
happen in the neural network are

173
00:11:29,279 --> 00:11:31,800
performed in in some field

174
00:11:31,800 --> 00:11:33,959
and of course when I talk about model

175
00:11:33,959 --> 00:11:35,399
arithmetic we need to know what is that

176
00:11:35,399 --> 00:11:37,920
modulus and that had to be fine-tuned

177
00:11:37,920 --> 00:11:39,600
using some empirical analysis and we'll

178
00:11:39,600 --> 00:11:43,200
see that in later slides that causes a

179
00:11:43,200 --> 00:11:45,480
very slight reduction of around 0.27

180
00:11:45,480 --> 00:11:48,540
percent 10.77 percent in the mnist and

181
00:11:48,540 --> 00:11:50,399
C5 data sets

182
00:11:50,399 --> 00:11:52,560
and by doing all these things by

183
00:11:52,560 --> 00:11:55,079
efficient implementation of uh masking

184
00:11:55,079 --> 00:11:57,180
on additions we were able to reduce the

185
00:11:57,180 --> 00:11:59,100
lookup table and flip flop overheads in

186
00:11:59,100 --> 00:12:00,120
the prior solution which was

187
00:12:00,120 --> 00:12:01,860
implementing use implemented using

188
00:12:01,860 --> 00:12:05,880
Boolean masking by 45 and 38 percent

189
00:12:05,880 --> 00:12:07,920
now before going into the details I'd

190
00:12:07,920 --> 00:12:10,140
like to briefly touch upon some of the

191
00:12:10,140 --> 00:12:12,360
specific preliminaries specifically

192
00:12:12,360 --> 00:12:14,160
binarized neural networks which is what

193
00:12:14,160 --> 00:12:16,140
we target for this work these are

194
00:12:16,140 --> 00:12:17,640
special neural networks which have the

195
00:12:17,640 --> 00:12:19,620
weights and activations binarized to be

196
00:12:19,620 --> 00:12:21,420
only plus one or minus one and that

197
00:12:21,420 --> 00:12:23,279
enables very very efficient Hardware

198
00:12:23,279 --> 00:12:26,040
implementations because the if the

199
00:12:26,040 --> 00:12:28,260
computationally Intensive floating Point

200
00:12:28,260 --> 00:12:30,240
operations are just converted to bit

201
00:12:30,240 --> 00:12:33,200
level operations like xnor and pop count

202
00:12:33,200 --> 00:12:36,720
and this has been recently gaining a lot

203
00:12:36,720 --> 00:12:38,339
of these have been recently gaining a

204
00:12:38,339 --> 00:12:40,620
lot of popularity even in industry and

205
00:12:40,620 --> 00:12:42,300
thus we believe that this is a good

206
00:12:42,300 --> 00:12:44,700
starting point for research on side

207
00:12:44,700 --> 00:12:45,899
channel countermeasures for machine

208
00:12:45,899 --> 00:12:48,300
learning

209
00:12:48,300 --> 00:12:50,700
um and and that does I present my threat

210
00:12:50,700 --> 00:12:53,279
model where as I said the training phase

211
00:12:53,279 --> 00:12:56,160
is trusted and the trained Secret model

212
00:12:56,160 --> 00:12:58,320
parameters are deployed on a device

213
00:12:58,320 --> 00:12:59,940
which is running in an untrusted

214
00:12:59,940 --> 00:13:00,899
environment

215
00:13:00,899 --> 00:13:04,380
so the device the the adversary just

216
00:13:04,380 --> 00:13:06,660
like a differential power analysis can

217
00:13:06,660 --> 00:13:08,519
observe the inputs and the outputs and

218
00:13:08,519 --> 00:13:10,320
of course the power consumption and can

219
00:13:10,320 --> 00:13:12,779
run some kind of a statistical uh Power

220
00:13:12,779 --> 00:13:14,279
analysis to extract the weights and

221
00:13:14,279 --> 00:13:15,660
biases

222
00:13:15,660 --> 00:13:17,760
here specifically we are targeting the

223
00:13:17,760 --> 00:13:19,320
parameters or we assume that the

224
00:13:19,320 --> 00:13:21,779
adversary targets the parameters uh the

225
00:13:21,779 --> 00:13:23,519
implementation is constant flow and

226
00:13:23,519 --> 00:13:25,860
constant time in Hardware so that you

227
00:13:25,860 --> 00:13:27,959
know makes attacks such as timing and

228
00:13:27,959 --> 00:13:30,899
memory side channels um out of scope

229
00:13:30,899 --> 00:13:33,120
and the platform yes as I said is

230
00:13:33,120 --> 00:13:35,279
provides power consumptions to be

231
00:13:35,279 --> 00:13:37,380
obtainable but invasive attacks or

232
00:13:37,380 --> 00:13:39,420
tampering attacks are again considered

233
00:13:39,420 --> 00:13:41,100
out of scope for for this particular

234
00:13:41,100 --> 00:13:41,940
work

235
00:13:41,940 --> 00:13:44,160
third domain oriented masking I guess we

236
00:13:44,160 --> 00:13:46,139
have had a lot of masking sessions and

237
00:13:46,139 --> 00:13:48,660
we probably know uh the structure so

238
00:13:48,660 --> 00:13:51,120
this is one of the masking gadgets used

239
00:13:51,120 --> 00:13:54,540
a lot in crypto systems this is secure

240
00:13:54,540 --> 00:13:56,339
in the glitch extended probing model

241
00:13:56,339 --> 00:13:57,779
because

242
00:13:57,779 --> 00:14:00,899
um because the the cross domain terms

243
00:14:00,899 --> 00:14:03,240
are refreshed and then registered which

244
00:14:03,240 --> 00:14:05,880
ensures that the glitches do not unmask

245
00:14:05,880 --> 00:14:08,880
the unshared secrets

246
00:14:08,880 --> 00:14:11,820
um the problem one one special uh thing

247
00:14:11,820 --> 00:14:14,160
that we had to do in our work for Dom

248
00:14:14,160 --> 00:14:16,380
gadgets was to also register the outputs

249
00:14:16,380 --> 00:14:18,180
because without registering the outputs

250
00:14:18,180 --> 00:14:19,920
a glitch extended probe can extend to

251
00:14:19,920 --> 00:14:21,839
the first partial product and in the

252
00:14:21,839 --> 00:14:23,940
second Gadget can you know combine the

253
00:14:23,940 --> 00:14:26,160
two secrets to leak the information

254
00:14:26,160 --> 00:14:28,079
so all the Dom gadgets whenever we feed

255
00:14:28,079 --> 00:14:30,779
to a non-linear Gadget is registered

256
00:14:30,779 --> 00:14:33,180
before uh that operation

257
00:14:33,180 --> 00:14:36,180
okay so modular net which is our work

258
00:14:36,180 --> 00:14:37,320
so

259
00:14:37,320 --> 00:14:41,040
to find the modulus value we try to plot

260
00:14:41,040 --> 00:14:42,899
a histogram of how the weighted

261
00:14:42,899 --> 00:14:45,540
summation distribution looks uh at the

262
00:14:45,540 --> 00:14:47,399
input of each neuron and as you can

263
00:14:47,399 --> 00:14:51,060
observe it because we have a an assigned

264
00:14:51,060 --> 00:14:52,860
representation here it's kind of

265
00:14:52,860 --> 00:14:54,899
distributed around zero

266
00:14:54,899 --> 00:14:57,000
these negative values will be boundaries

267
00:14:57,000 --> 00:14:58,500
to minus 1 positive values will bind

268
00:14:58,500 --> 00:15:00,660
raise to plus one but with modulo the

269
00:15:00,660 --> 00:15:02,579
negative half of the this histogram

270
00:15:02,579 --> 00:15:04,139
shifts to the positive side right

271
00:15:04,139 --> 00:15:05,760
because that's how modular arithmetic

272
00:15:05,760 --> 00:15:07,800
works and because of that what was the

273
00:15:07,800 --> 00:15:09,360
sine function now becomes a threshold

274
00:15:09,360 --> 00:15:11,459
function so we had to make that first

275
00:15:11,459 --> 00:15:14,100
change uh this was good for hidden

276
00:15:14,100 --> 00:15:15,839
layers but what happens in the output

277
00:15:15,839 --> 00:15:17,639
layer is the distribution is not really

278
00:15:17,639 --> 00:15:19,560
uniform around zero and we actually

279
00:15:19,560 --> 00:15:22,019
observed that it changes to two two

280
00:15:22,019 --> 00:15:24,180
peaks the peak corresponding to all the

281
00:15:24,180 --> 00:15:25,980
incorrect confidence scores and the peak

282
00:15:25,980 --> 00:15:27,540
corresponding to the correct confidence

283
00:15:27,540 --> 00:15:29,459
course and when we apply model

284
00:15:29,459 --> 00:15:31,380
arithmetic the incorrect confidence

285
00:15:31,380 --> 00:15:32,880
scores actually shift on the positive

286
00:15:32,880 --> 00:15:34,860
side and because in the output layer we

287
00:15:34,860 --> 00:15:36,779
basically compare all the

288
00:15:36,779 --> 00:15:38,699
confidence course and check which is the

289
00:15:38,699 --> 00:15:40,980
maximum we cannot do that anymore in

290
00:15:40,980 --> 00:15:42,240
this distribution right because if we

291
00:15:42,240 --> 00:15:44,579
directly put a Max function on this

292
00:15:44,579 --> 00:15:46,320
these scores would be incorrectly

293
00:15:46,320 --> 00:15:48,300
classified to be the correct scores so

294
00:15:48,300 --> 00:15:50,579
we changed our output layer function to

295
00:15:50,579 --> 00:15:53,279
instead compute the maximum first below

296
00:15:53,279 --> 00:15:55,440
a certain threshold and if that Max

297
00:15:55,440 --> 00:15:58,019
doesn't exist only then compute a global

298
00:15:58,019 --> 00:16:00,000
maximum

299
00:16:00,000 --> 00:16:02,399
and we also tried to

300
00:16:02,399 --> 00:16:03,120
um

301
00:16:03,120 --> 00:16:05,639
see how the modulus varies to find what

302
00:16:05,639 --> 00:16:07,680
is a good modulus value for the specific

303
00:16:07,680 --> 00:16:09,600
data sets that we work on and as you can

304
00:16:09,600 --> 00:16:13,380
see uh around 2 to the power 15 it was

305
00:16:13,380 --> 00:16:15,060
not giving us any more returns so we

306
00:16:15,060 --> 00:16:16,560
reached the point of diminishing returns

307
00:16:16,560 --> 00:16:18,839
after Truth by 15. we are restrict we

308
00:16:18,839 --> 00:16:20,459
are restricting it only to two's Powers

309
00:16:20,459 --> 00:16:22,800
because that's efficiently implementable

310
00:16:22,800 --> 00:16:24,060
on Hardware

311
00:16:24,060 --> 00:16:26,880
now I'll discuss how the output layer

312
00:16:26,880 --> 00:16:30,360
was designed in in using masking for our

313
00:16:30,360 --> 00:16:33,660
specific use case so as I said we first

314
00:16:33,660 --> 00:16:36,060
need to perform mask we first need to

315
00:16:36,060 --> 00:16:37,740
compute the max below a certain

316
00:16:37,740 --> 00:16:39,600
threshold and then we need to compute a

317
00:16:39,600 --> 00:16:42,120
global Max and all these operations are

318
00:16:42,120 --> 00:16:44,100
highly non-linear which is I first

319
00:16:44,100 --> 00:16:46,560
transform to we first convert the

320
00:16:46,560 --> 00:16:49,019
arithmetic shares to Boolean shares

321
00:16:49,019 --> 00:16:50,399
using an arithmetic to Boolean

322
00:16:50,399 --> 00:16:53,339
conversion and on these shares we filter

323
00:16:53,339 --> 00:16:55,380
the values that are below the certain

324
00:16:55,380 --> 00:16:57,480
threshold which then go into a

325
00:16:57,480 --> 00:16:59,639
comparator which is also masked and the

326
00:16:59,639 --> 00:17:02,220
comparator basically Compares which of

327
00:17:02,220 --> 00:17:04,020
the scores are the highest scores and

328
00:17:04,020 --> 00:17:05,939
based on that a multiplexer selects the

329
00:17:05,939 --> 00:17:07,559
shares corresponding to the highest

330
00:17:07,559 --> 00:17:09,540
confidence score in the second round

331
00:17:09,540 --> 00:17:12,480
which is controlled by the P2 bit the

332
00:17:12,480 --> 00:17:14,579
thresholder is bypassed and I directly

333
00:17:14,579 --> 00:17:17,160
compute what is the maximum confidence

334
00:17:17,160 --> 00:17:19,319
course which is given by the global Max

335
00:17:19,319 --> 00:17:20,339
register

336
00:17:20,339 --> 00:17:22,559
and all these components internally the

337
00:17:22,559 --> 00:17:24,359
thresholder the comparator and the

338
00:17:24,359 --> 00:17:26,280
multiplexer are implemented using Dom

339
00:17:26,280 --> 00:17:28,919
gadgets I always registered the inputs

340
00:17:28,919 --> 00:17:30,480
at the output of the Dom Gadget whenever

341
00:17:30,480 --> 00:17:32,280
I'm feeding it into the next non-linear

342
00:17:32,280 --> 00:17:33,360
Gadget

343
00:17:33,360 --> 00:17:35,280
for the comparison one quick comment

344
00:17:35,280 --> 00:17:39,660
here so must comparison is used a lot in

345
00:17:39,660 --> 00:17:42,360
uh in the context of lattice crypto and

346
00:17:42,360 --> 00:17:43,860
there the comparison generally means

347
00:17:43,860 --> 00:17:46,080
equality but here we had to really

348
00:17:46,080 --> 00:17:49,320
compare the magnitudes of the two shares

349
00:17:49,320 --> 00:17:51,660
right so it's like a bit by bit

350
00:17:51,660 --> 00:17:53,520
comparison which which we implemented

351
00:17:53,520 --> 00:17:56,760
using a logarithmic um it's the

352
00:17:56,760 --> 00:17:58,200
structure is very similar to a cog is to

353
00:17:58,200 --> 00:18:00,600
an added where you would compute the the

354
00:18:00,600 --> 00:18:02,820
bits from the most significant bit to

355
00:18:02,820 --> 00:18:04,799
the least significant bit secondly the

356
00:18:04,799 --> 00:18:07,140
thresholder which basically checks if

357
00:18:07,140 --> 00:18:10,020
something is greater than 0 to bypass

358
00:18:10,020 --> 00:18:12,120
and if less than 0 to 0 out is also the

359
00:18:12,120 --> 00:18:13,740
functionality of a rectified linear unit

360
00:18:13,740 --> 00:18:16,260
so this gadget can also be used as an

361
00:18:16,260 --> 00:18:18,660
relu in neural networks that use realu

362
00:18:18,660 --> 00:18:21,179
as the activation function

363
00:18:21,179 --> 00:18:24,000
coming to the overall design as we can

364
00:18:24,000 --> 00:18:27,179
see we perform arithmetic masking before

365
00:18:27,179 --> 00:18:29,340
the weighted summations so that's the

366
00:18:29,340 --> 00:18:31,500
pixel value that comes in pi it gets

367
00:18:31,500 --> 00:18:33,539
arithmetically masked and then it gets

368
00:18:33,539 --> 00:18:37,020
multiplied by the weights the weights

369
00:18:37,020 --> 00:18:39,240
then feed into a weighted summation

370
00:18:39,240 --> 00:18:41,220
there are two independent data Parts

371
00:18:41,220 --> 00:18:42,720
there and these weighted summation

372
00:18:42,720 --> 00:18:44,820
shares then go into the Mast activation

373
00:18:44,820 --> 00:18:48,360
function which Compares which of these

374
00:18:48,360 --> 00:18:50,520
uh which which basically binarizes the

375
00:18:50,520 --> 00:18:52,080
weighted summations

376
00:18:52,080 --> 00:18:54,179
here we implemented it using a masked

377
00:18:54,179 --> 00:18:56,820
corgis Stone carry propagator to compute

378
00:18:56,820 --> 00:18:59,460
the Boolean shares of the MSP now

379
00:18:59,460 --> 00:19:01,559
because we convert to Boolean shares

380
00:19:01,559 --> 00:19:03,539
here but the in the next layer we again

381
00:19:03,539 --> 00:19:05,880
want to perform arithmetic masking we

382
00:19:05,880 --> 00:19:07,260
need to convert these shares back from

383
00:19:07,260 --> 00:19:08,760
Boolean to arithmetic masking and that

384
00:19:08,760 --> 00:19:10,740
is why we need a b2a converter

385
00:19:10,740 --> 00:19:13,080
uh finally in the last round the values

386
00:19:13,080 --> 00:19:15,120
go into the masked output layer where we

387
00:19:15,120 --> 00:19:17,460
get the inference output

388
00:19:17,460 --> 00:19:19,620
we also implemented a binarized

389
00:19:19,620 --> 00:19:21,480
convolutional neural network and here

390
00:19:21,480 --> 00:19:23,700
the initial part is still the same with

391
00:19:23,700 --> 00:19:25,260
some changes in the read logic because

392
00:19:25,260 --> 00:19:27,720
we are performing convolutions and not a

393
00:19:27,720 --> 00:19:29,460
straightforward weighted multiplication

394
00:19:29,460 --> 00:19:31,799
but one thing that I would like to note

395
00:19:31,799 --> 00:19:34,140
here is that we also have an additional

396
00:19:34,140 --> 00:19:36,000
operation called Max pool so max pool

397
00:19:36,000 --> 00:19:39,059
tries to uh pool the values in a certain

398
00:19:39,059 --> 00:19:41,160
window it's basically a sub sampling

399
00:19:41,160 --> 00:19:43,799
technique and for binarized neural

400
00:19:43,799 --> 00:19:47,220
networks Max pool is essentially uh an

401
00:19:47,220 --> 00:19:50,100
or operation and or can be can be merged

402
00:19:50,100 --> 00:19:53,100
easily using a mast and but that adds an

403
00:19:53,100 --> 00:19:54,539
additional latency

404
00:19:54,539 --> 00:19:56,820
and that that would create bubbles in

405
00:19:56,820 --> 00:20:00,059
the pipeline but since multiple Max pool

406
00:20:00,059 --> 00:20:01,919
windows are independent of each other

407
00:20:01,919 --> 00:20:04,679
what we do is while the first max pool

408
00:20:04,679 --> 00:20:07,080
windows outputs are being computed we

409
00:20:07,080 --> 00:20:09,480
can pipeline that design we can pipeline

410
00:20:09,480 --> 00:20:11,400
that with the other Max pool window

411
00:20:11,400 --> 00:20:13,679
computations and ensure that we do not

412
00:20:13,679 --> 00:20:15,780
lose any Cycles in the overall

413
00:20:15,780 --> 00:20:18,360
throughput and and and it's exactly

414
00:20:18,360 --> 00:20:20,460
equal to what was the throughput without

415
00:20:20,460 --> 00:20:24,320
the master Max full Gadget

416
00:20:24,660 --> 00:20:28,440
um these are our tvla results we perform

417
00:20:28,440 --> 00:20:31,320
both tvla on the individual gadgets the

418
00:20:31,320 --> 00:20:33,960
activation functions the comparators the

419
00:20:33,960 --> 00:20:36,240
conversion circuits uh both in the

420
00:20:36,240 --> 00:20:38,039
unmasked format and the mass format as

421
00:20:38,039 --> 00:20:40,200
is usually done in the side Channel

422
00:20:40,200 --> 00:20:43,620
literature and the build the figure on

423
00:20:43,620 --> 00:20:46,740
the below is basically the one with the

424
00:20:46,740 --> 00:20:49,080
overall inference as we can see when we

425
00:20:49,080 --> 00:20:52,500
unmask so when we are zeroing out all

426
00:20:52,500 --> 00:20:54,720
the prng outputs we do not see any

427
00:20:54,720 --> 00:20:57,299
leakages but when we Implement our

428
00:20:57,299 --> 00:20:59,640
countermeasures or activate them we do

429
00:20:59,640 --> 00:21:02,100
not see any leakage with 2 million

430
00:21:02,100 --> 00:21:04,559
traces uh combined in fixed and random

431
00:21:04,559 --> 00:21:07,160
data sets

432
00:21:08,220 --> 00:21:08,940
um

433
00:21:08,940 --> 00:21:11,160
uh in addition to what I already

434
00:21:11,160 --> 00:21:14,220
presented we have uh more details in the

435
00:21:14,220 --> 00:21:16,559
paper on the masking gadgets how we

436
00:21:16,559 --> 00:21:18,120
actually Implement them the security

437
00:21:18,120 --> 00:21:19,980
proofs of those gadgets and the glitch

438
00:21:19,980 --> 00:21:22,020
extended proving model and we also did

439
00:21:22,020 --> 00:21:25,080
TV tvla evaluations for the convolution

440
00:21:25,080 --> 00:21:27,360
and Max pool layers

441
00:21:27,360 --> 00:21:29,880
to finally conclude machine learning as

442
00:21:29,880 --> 00:21:31,860
we see provides a new Avenue for side

443
00:21:31,860 --> 00:21:34,200
Channel research defenses have been

444
00:21:34,200 --> 00:21:36,360
relatively less explored and this whole

445
00:21:36,360 --> 00:21:38,340
idea of trying to transform the neural

446
00:21:38,340 --> 00:21:40,799
network functions to be similar to

447
00:21:40,799 --> 00:21:42,600
cryptographic functions can really help

448
00:21:42,600 --> 00:21:44,220
us to efficiently Implement mask

449
00:21:44,220 --> 00:21:46,919
encounter measures and of course I only

450
00:21:46,919 --> 00:21:49,799
did it for binarized convolution and MLP

451
00:21:49,799 --> 00:21:52,080
layers but there is certainly more scope

452
00:21:52,080 --> 00:21:54,360
for other ml topologies such as the

453
00:21:54,360 --> 00:21:57,360
recurrent neural networks and lstms so

454
00:21:57,360 --> 00:21:59,940
yeah with that I'd like to conclude my

455
00:21:59,940 --> 00:22:03,059
talk and have any questions thank you

456
00:22:03,059 --> 00:22:05,240
okay

457
00:22:11,039 --> 00:22:13,620
okay do we have any questions from the

458
00:22:13,620 --> 00:22:15,979
audience

459
00:22:22,140 --> 00:22:24,360
so thanks for the nice talk can you hear

460
00:22:24,360 --> 00:22:27,659
me or um to some extent yeah okay

461
00:22:27,659 --> 00:22:30,419
um so my question is did you try any

462
00:22:30,419 --> 00:22:31,980
formal verification tool or any

463
00:22:31,980 --> 00:22:33,480
stimulation embellished tool to check

464
00:22:33,480 --> 00:22:36,000
your designs you you mean something like

465
00:22:36,000 --> 00:22:38,580
silver or yeah so for for this work we

466
00:22:38,580 --> 00:22:40,919
have uh done this manually but yeah that

467
00:22:40,919 --> 00:22:42,360
is uh something that we could have done

468
00:22:42,360 --> 00:22:44,640
I guess when we were uh kind of

469
00:22:44,640 --> 00:22:46,200
submitting and starting this research

470
00:22:46,200 --> 00:22:48,240
work silver was still silver just got

471
00:22:48,240 --> 00:22:50,640
published and would not have time to uh

472
00:22:50,640 --> 00:22:52,919
perform formal verification on those

473
00:22:52,919 --> 00:22:54,240
gadgets but that is certainly something

474
00:22:54,240 --> 00:22:56,940
that we can try and is going to happen

475
00:22:56,940 --> 00:22:59,419
to your future

476
00:23:01,919 --> 00:23:05,900
we have any other question

477
00:23:07,140 --> 00:23:09,299
okay so maybe maybe I also have a

478
00:23:09,299 --> 00:23:10,020
question

479
00:23:10,020 --> 00:23:11,039
um

480
00:23:11,039 --> 00:23:15,059
I saw that you have I think two types of

481
00:23:15,059 --> 00:23:17,880
networks where you applied your idea on

482
00:23:17,880 --> 00:23:19,980
so what do you think is it scalable can

483
00:23:19,980 --> 00:23:21,840
you also apply this idea of modulator

484
00:23:21,840 --> 00:23:26,880
net to any other kind of network type

485
00:23:26,880 --> 00:23:29,580
so I think uh yeah the techniques can

486
00:23:29,580 --> 00:23:32,400
certainly extend because uh the neural

487
00:23:32,400 --> 00:23:34,919
network operations at least the neuron

488
00:23:34,919 --> 00:23:37,020
computations are still going to be the

489
00:23:37,020 --> 00:23:39,120
same we have also applied these

490
00:23:39,120 --> 00:23:41,159
techniques on higher lower quantization

491
00:23:41,159 --> 00:23:43,740
levels that is 4 bit and 8-bit and there

492
00:23:43,740 --> 00:23:45,900
what happens is the binarized

493
00:23:45,900 --> 00:23:47,760
multiplication is actually a regular

494
00:23:47,760 --> 00:23:50,400
multiplication and that is obviously

495
00:23:50,400 --> 00:23:52,200
going to now increase the cost to some

496
00:23:52,200 --> 00:23:54,059
extent because now we need to mask more

497
00:23:54,059 --> 00:23:56,820
bits but uh it is the the technique as

498
00:23:56,820 --> 00:23:59,340
such is definitely scalable

499
00:23:59,340 --> 00:24:02,820
okay thanks so maybe time for another

500
00:24:02,820 --> 00:24:05,220
quick question

501
00:24:05,220 --> 00:24:07,799
if not so let's thank the speaker again

502
00:24:07,799 --> 00:24:10,700
thank you

503
00:24:16,679 --> 00:24:20,900
so the next talk will be given by David

504
00:24:20,900 --> 00:24:24,679
and the title is

505
00:24:24,720 --> 00:24:27,919
hopefully showing up soon

506
00:24:28,980 --> 00:24:30,960
yeah hello we also want to make a quick

507
00:24:30,960 --> 00:24:33,360
announcement this Beamer will not be

508
00:24:33,360 --> 00:24:35,100
fixed till next session so for the next

509
00:24:35,100 --> 00:24:37,620
three talks this will not be turned on

510
00:24:37,620 --> 00:24:39,539
um so anyone that's sitting and cannot

511
00:24:39,539 --> 00:24:41,700
view the other projector

512
00:24:41,700 --> 00:24:44,940
um well you can move now or open in zoom

513
00:24:44,940 --> 00:24:46,500
and mute your audio

514
00:24:46,500 --> 00:24:48,960
and check the presentation that way

515
00:24:48,960 --> 00:24:51,620
thank you

516
00:25:03,960 --> 00:25:05,640
it's not the title

517
00:25:05,640 --> 00:25:07,980
I can also not

518
00:25:07,980 --> 00:25:09,059
oh

519
00:25:09,059 --> 00:25:12,000
okay so the next talk will be composable

520
00:25:12,000 --> 00:25:14,760
gadgets with reuse crash mask first

521
00:25:14,760 --> 00:25:16,679
order probing secure Hardware circuits

522
00:25:16,679 --> 00:25:19,679
with only six bits of fresh masks and

523
00:25:19,679 --> 00:25:22,440
the talk will be given by David yeah

524
00:25:22,440 --> 00:25:24,980
thanks Pascal for the nice introduction

525
00:25:24,980 --> 00:25:29,100
so I'm going to give a talk about a work

526
00:25:29,100 --> 00:25:31,380
I did together with my advisor Army

527
00:25:31,380 --> 00:25:33,960
Marathi at the Royal University

528
00:25:33,960 --> 00:25:37,380
and in essence the workers about all the

529
00:25:37,380 --> 00:25:39,720
work proposes and new types of gadgets

530
00:25:39,720 --> 00:25:43,140
that are freely composable

531
00:25:43,140 --> 00:25:47,039
and that can mask an arbitrary logical

532
00:25:47,039 --> 00:25:49,980
circuit another First Security order

533
00:25:49,980 --> 00:25:52,860
and introduces only six fresh random

534
00:25:52,860 --> 00:25:56,039
bits and total to the whole design

535
00:25:56,039 --> 00:25:59,460
and here note that we don't count the

536
00:25:59,460 --> 00:26:01,440
fresh random bits needed for the initial

537
00:26:01,440 --> 00:26:04,620
masking but only the fresh random bits

538
00:26:04,620 --> 00:26:06,960
needed for the mask masking the circuit

539
00:26:06,960 --> 00:26:08,220
itself

540
00:26:08,220 --> 00:26:11,220
yeah and usually this

541
00:26:11,220 --> 00:26:13,200
um yeah composable Hardware modules you

542
00:26:13,200 --> 00:26:15,900
refer to them as gadgets so we called

543
00:26:15,900 --> 00:26:19,140
our new Gadget construction composable

544
00:26:19,140 --> 00:26:22,380
gadgets with reused fresh masks

545
00:26:22,380 --> 00:26:24,360
and maybe a disclaimer a lot of the

546
00:26:24,360 --> 00:26:25,860
information

547
00:26:25,860 --> 00:26:28,260
um will sound familiar especially if you

548
00:26:28,260 --> 00:26:31,140
visited my first talk yesterday but I

549
00:26:31,140 --> 00:26:33,120
anyhow give a quick recap so it's fresh

550
00:26:33,120 --> 00:26:34,880
in your mind

551
00:26:34,880 --> 00:26:38,039
so masking is a long-standing counter

552
00:26:38,039 --> 00:26:41,820
measure against side China analysis and

553
00:26:41,820 --> 00:26:44,580
we though so the underlying principle is

554
00:26:44,580 --> 00:26:47,520
we split the secret into shares that are

555
00:26:47,520 --> 00:26:49,620
uniformly drawn and independent of each

556
00:26:49,620 --> 00:26:51,779
other and then we perform the operation

557
00:26:51,779 --> 00:26:53,940
on these shares instead of the secret

558
00:26:53,940 --> 00:26:55,520
itself

559
00:26:55,520 --> 00:26:58,740
and intuitively now because of the split

560
00:26:58,740 --> 00:27:00,659
in information the adversary needs to

561
00:27:00,659 --> 00:27:02,700
get information about all the shares

562
00:27:02,700 --> 00:27:04,320
when he wants to get information about

563
00:27:04,320 --> 00:27:06,779
the secret so any part of the shares or

564
00:27:06,779 --> 00:27:09,659
any subset does not help

565
00:27:09,659 --> 00:27:11,820
and how does the masking scape look like

566
00:27:11,820 --> 00:27:15,600
so we can broadly divide the space into

567
00:27:15,600 --> 00:27:18,120
two categories the first one is the

568
00:27:18,120 --> 00:27:20,640
masking on an algorithmic level so on a

569
00:27:20,640 --> 00:27:22,980
more Global level where the engineer or

570
00:27:22,980 --> 00:27:26,520
the researcher tries by dividing

571
00:27:26,520 --> 00:27:27,960
the

572
00:27:27,960 --> 00:27:31,320
um The Logical circuit into functional

573
00:27:31,320 --> 00:27:33,539
blocks on cleverly introducing with

574
00:27:33,539 --> 00:27:36,659
flash layers and by this trying to mask

575
00:27:36,659 --> 00:27:38,760
the Sci-Fi and at the end kind of

576
00:27:38,760 --> 00:27:40,860
heuristically arguing about the size

577
00:27:40,860 --> 00:27:44,220
Channel resistance of the overall design

578
00:27:44,220 --> 00:27:46,200
in contrast to that we have the

579
00:27:46,200 --> 00:27:48,000
gadget-based masking

580
00:27:48,000 --> 00:27:50,640
which is a more systematic dividing

581
00:27:50,640 --> 00:27:52,100
conquer approach

582
00:27:52,100 --> 00:27:55,320
is based on these composable gadgets so

583
00:27:55,320 --> 00:27:57,840
these composable Hardware modules

584
00:27:57,840 --> 00:28:00,600
that if we um that guarantee if we

585
00:28:00,600 --> 00:28:02,159
compose them together to a larger

586
00:28:02,159 --> 00:28:04,980
circuit that we can be sure that the

587
00:28:04,980 --> 00:28:07,020
circuit will be provably secure in the

588
00:28:07,020 --> 00:28:09,600
corresponding adversary model

589
00:28:09,600 --> 00:28:12,779
and the advantages of this approach

590
00:28:12,779 --> 00:28:15,419
uh that is completely automatable and

591
00:28:15,419 --> 00:28:18,059
yesterday we had a talk by Amir

592
00:28:18,059 --> 00:28:20,940
um there's this Tula gamer who already

593
00:28:20,940 --> 00:28:22,860
um does exactly that

594
00:28:22,860 --> 00:28:26,039
and it can be uh so we can mask

595
00:28:26,039 --> 00:28:27,900
arbitrary circuits for arbitrary

596
00:28:27,900 --> 00:28:29,700
security orders

597
00:28:29,700 --> 00:28:32,460
and as I said like the overall circuit

598
00:28:32,460 --> 00:28:36,059
is provably secure in the corresponding

599
00:28:36,059 --> 00:28:37,860
adversary model

600
00:28:37,860 --> 00:28:40,380
now you would think okay cool everything

601
00:28:40,380 --> 00:28:42,299
is automated

602
00:28:42,299 --> 00:28:44,039
um masking is solved so we all have no

603
00:28:44,039 --> 00:28:46,559
job anymore but essentially like there's

604
00:28:46,559 --> 00:28:49,140
a drawback to that the gadget-based

605
00:28:49,140 --> 00:28:51,080
masking introduces

606
00:28:51,080 --> 00:28:54,419
and high overhead into design into the

607
00:28:54,419 --> 00:28:56,100
design with respect to Randomness

608
00:28:56,100 --> 00:28:59,039
requirements and latency and also area

609
00:28:59,039 --> 00:29:00,240
overhead

610
00:29:00,240 --> 00:29:03,000
and especially when we compare it to

611
00:29:03,000 --> 00:29:06,000
this more Global approach then these are

612
00:29:06,000 --> 00:29:08,700
typically reside in a more optimized

613
00:29:08,700 --> 00:29:09,539
design

614
00:29:09,539 --> 00:29:12,900
now our approach is settled in the

615
00:29:12,900 --> 00:29:14,940
gadget-based masking where we try to

616
00:29:14,940 --> 00:29:17,039
reduce the renderness requirements of

617
00:29:17,039 --> 00:29:19,820
the overall design

618
00:29:19,980 --> 00:29:22,860
now to formally argue about Sideshow

619
00:29:22,860 --> 00:29:24,899
resistance different adversary models

620
00:29:24,899 --> 00:29:26,940
were introduced over time working on

621
00:29:26,940 --> 00:29:29,279
different abstraction layers

622
00:29:29,279 --> 00:29:31,919
and a very convenient one is the probing

623
00:29:31,919 --> 00:29:34,620
model where the adversary can place up

624
00:29:34,620 --> 00:29:36,539
to deep probes onto wires of the circuit

625
00:29:36,539 --> 00:29:38,520
and then you should not be able to learn

626
00:29:38,520 --> 00:29:40,740
any about anything about the secret

627
00:29:40,740 --> 00:29:43,559
itself

628
00:29:43,559 --> 00:29:46,260
and it was later extended in form of the

629
00:29:46,260 --> 00:29:48,600
robust probing model which also captures

630
00:29:48,600 --> 00:29:50,520
physical defaults like glitches

631
00:29:50,520 --> 00:29:52,980
transitions transitions at registered

632
00:29:52,980 --> 00:29:56,399
stages and coupling between wires

633
00:29:56,399 --> 00:29:59,039
and this is very convenient because with

634
00:29:59,039 --> 00:30:01,919
this model we can already very early in

635
00:30:01,919 --> 00:30:05,039
the development and production stage

636
00:30:05,039 --> 00:30:08,039
of a of a circuit argue about the side

637
00:30:08,039 --> 00:30:09,779
Channel resistance so typically we can

638
00:30:09,779 --> 00:30:12,000
already argue on the netlist level about

639
00:30:12,000 --> 00:30:15,059
the site General resistance of a design

640
00:30:15,059 --> 00:30:17,340
yeah and for for us so our construction

641
00:30:17,340 --> 00:30:20,820
our Gadget construction will be at the

642
00:30:20,820 --> 00:30:22,260
end secure

643
00:30:22,260 --> 00:30:24,360
um in the glitch extended robust probing

644
00:30:24,360 --> 00:30:27,539
model another First Security order so we

645
00:30:27,539 --> 00:30:29,399
consider glitches occurring and hardware

646
00:30:29,399 --> 00:30:32,039
and D equals one here so the adversary

647
00:30:32,039 --> 00:30:34,320
is able to place one Probe on Dual wire

648
00:30:34,320 --> 00:30:36,659
of the circuit

649
00:30:36,659 --> 00:30:38,460
now what are glitches

650
00:30:38,460 --> 00:30:41,039
glitches are um unintentional signal

651
00:30:41,039 --> 00:30:42,899
recombinations

652
00:30:42,899 --> 00:30:45,720
um in a logical circuit caused by

653
00:30:45,720 --> 00:30:47,940
different past delays between two

654
00:30:47,940 --> 00:30:49,380
register stages

655
00:30:49,380 --> 00:30:52,020
now this this might um cause the

656
00:30:52,020 --> 00:30:54,059
adversary to not only get information

657
00:30:54,059 --> 00:30:56,760
about the stable wire or the value of

658
00:30:56,760 --> 00:30:58,860
the stable wire but also getting values

659
00:30:58,860 --> 00:31:01,740
about all stable values contributing to

660
00:31:01,740 --> 00:31:04,380
the wire add to the value of the wire

661
00:31:04,380 --> 00:31:06,899
and this is captured in the robust

662
00:31:06,899 --> 00:31:09,120
probing model in a worst case manner

663
00:31:09,120 --> 00:31:12,419
so actually our our standard probe is

664
00:31:12,419 --> 00:31:14,760
simply replaced by a stronger set of

665
00:31:14,760 --> 00:31:17,880
probes at the um at the register stages

666
00:31:17,880 --> 00:31:20,100
and by that the adversary is able to

667
00:31:20,100 --> 00:31:23,580
probe every stable wire contributing to

668
00:31:23,580 --> 00:31:25,980
the initial wire where the standard

669
00:31:25,980 --> 00:31:28,620
probe was placed on originating from the

670
00:31:28,620 --> 00:31:31,140
beforehand register stage

671
00:31:31,140 --> 00:31:32,700
yeah and now

672
00:31:32,700 --> 00:31:34,620
um how is how does the concept of this

673
00:31:34,620 --> 00:31:36,299
gadget-based masking look like so

674
00:31:36,299 --> 00:31:37,919
actually it's very simple

675
00:31:37,919 --> 00:31:40,559
we have our library of composable

676
00:31:40,559 --> 00:31:42,720
gadgets and then we have our unprotected

677
00:31:42,720 --> 00:31:45,059
circuit so the the gadgets in this

678
00:31:45,059 --> 00:31:47,399
library May fulfill the masked variant

679
00:31:47,399 --> 00:31:50,100
of an Android or something and then we

680
00:31:50,100 --> 00:31:52,440
would just replace the Mast the

681
00:31:52,440 --> 00:31:54,960
unprotected gates in the in the circuit

682
00:31:54,960 --> 00:31:57,840
with our masked gadgets and then we can

683
00:31:57,840 --> 00:32:00,419
be secure and then we can be sure that

684
00:32:00,419 --> 00:32:02,340
we are side Channel resistance and the

685
00:32:02,340 --> 00:32:04,320
corresponding adversary model

686
00:32:04,320 --> 00:32:07,260
and the drawback of that is for example

687
00:32:07,260 --> 00:32:10,380
if you would use hpc2 which is a

688
00:32:10,380 --> 00:32:13,080
composable hardware Gadget under the

689
00:32:13,080 --> 00:32:14,700
Piney notion

690
00:32:14,700 --> 00:32:16,799
so it's essentially freely composable

691
00:32:16,799 --> 00:32:19,500
then you would introduce Gadget

692
00:32:19,500 --> 00:32:22,320
individual individual fresh masks for

693
00:32:22,320 --> 00:32:25,140
every Gadget instantiation and for

694
00:32:25,140 --> 00:32:26,700
example if we would have a design where

695
00:32:26,700 --> 00:32:28,980
we have seven and gates in total this

696
00:32:28,980 --> 00:32:31,380
was already lead to scenario where we

697
00:32:31,380 --> 00:32:34,679
would need seven fresh random bits in

698
00:32:34,679 --> 00:32:37,620
the in the circuit in The Mask circuit

699
00:32:37,620 --> 00:32:40,500
and note that these

700
00:32:40,500 --> 00:32:42,960
um these random bits have to be renewed

701
00:32:42,960 --> 00:32:45,419
every clock cycle now of course if you

702
00:32:45,419 --> 00:32:47,580
have only seven and Gates this is not

703
00:32:47,580 --> 00:32:49,320
that relevant but if you consider for

704
00:32:49,320 --> 00:32:51,299
example a round-based as where you have

705
00:32:51,299 --> 00:32:53,700
up to 700 and Gates

706
00:32:53,700 --> 00:32:55,679
um yeah this becomes more and more

707
00:32:55,679 --> 00:32:56,700
relevant

708
00:32:56,700 --> 00:32:58,559
and you as I said you have to renew

709
00:32:58,559 --> 00:33:00,140
these um

710
00:33:00,140 --> 00:33:03,179
random bits every clock cycle so you

711
00:33:03,179 --> 00:33:05,700
will essentially need a prng that has

712
00:33:05,700 --> 00:33:09,740
this high of of a throughput

713
00:33:10,080 --> 00:33:12,480
yeah and now our question was

714
00:33:12,480 --> 00:33:14,700
whether we can kind of build gadgets

715
00:33:14,700 --> 00:33:17,460
that eventually will reduce the overall

716
00:33:17,460 --> 00:33:19,140
awareness of of

717
00:33:19,140 --> 00:33:21,600
um the resulting design and our idea was

718
00:33:21,600 --> 00:33:24,059
to build gadgets that can where we can

719
00:33:24,059 --> 00:33:25,980
reuse the same Randomness in every

720
00:33:25,980 --> 00:33:29,240
Gadget instantiation

721
00:33:30,539 --> 00:33:33,240
and um yeah with our our new

722
00:33:33,240 --> 00:33:36,600
construction our coma gadgets the

723
00:33:36,600 --> 00:33:39,000
scenario looks different now we also

724
00:33:39,000 --> 00:33:41,940
replaced every gate in the unprotected

725
00:33:41,940 --> 00:33:44,039
circuit with our coma gadgets but now we

726
00:33:44,039 --> 00:33:46,919
can essentially reuse the same six bit

727
00:33:46,919 --> 00:33:49,320
of fresh Randomness in every Gadget

728
00:33:49,320 --> 00:33:52,500
instantiation and already at at seven

729
00:33:52,500 --> 00:33:54,960
and and gates in the unprotected circuit

730
00:33:54,960 --> 00:33:56,580
we have an advantage

731
00:33:56,580 --> 00:33:58,860
because

732
00:33:58,860 --> 00:34:01,679
um now if we if we would or if we have

733
00:34:01,679 --> 00:34:03,299
an additional and gate in our

734
00:34:03,299 --> 00:34:06,120
unprotected circuit we would um not

735
00:34:06,120 --> 00:34:07,559
introduce any

736
00:34:07,559 --> 00:34:09,780
additional Randomness into the design

737
00:34:09,780 --> 00:34:11,639
while comparable

738
00:34:11,639 --> 00:34:15,540
um gadgets like hpc2 would introduce an

739
00:34:15,540 --> 00:34:17,940
additional random bit per gate into the

740
00:34:17,940 --> 00:34:20,060
design

741
00:34:20,520 --> 00:34:23,520
now to construct these gadgets we asked

742
00:34:23,520 --> 00:34:25,500
ourselves okay why is this fresh

743
00:34:25,500 --> 00:34:28,800
individual Randomness necessary in the

744
00:34:28,800 --> 00:34:32,339
gadgets and the um kind of the intuition

745
00:34:32,339 --> 00:34:36,719
behind that is that we want to argue

746
00:34:36,719 --> 00:34:40,260
um about probe dependencies between uh

747
00:34:40,260 --> 00:34:42,780
the probe and the input independent of

748
00:34:42,780 --> 00:34:44,520
the surrounding circuit so in an

749
00:34:44,520 --> 00:34:45,960
isolated way

750
00:34:45,960 --> 00:34:48,000
if the randomness here in this example

751
00:34:48,000 --> 00:34:49,918
it's just a very simple example let's

752
00:34:49,918 --> 00:34:52,199
consider the schedule where simply the

753
00:34:52,199 --> 00:34:54,359
first input share is blinded by R and

754
00:34:54,359 --> 00:34:55,800
start and register

755
00:34:55,800 --> 00:34:58,440
now if if R is completely independent of

756
00:34:58,440 --> 00:35:00,119
the surrounding circuit and freshly

757
00:35:00,119 --> 00:35:01,080
drawn

758
00:35:01,080 --> 00:35:04,560
this P if we place a probe on this value

759
00:35:04,560 --> 00:35:06,900
will not give us any any information

760
00:35:06,900 --> 00:35:09,180
about the input here so we can kind of

761
00:35:09,180 --> 00:35:12,780
argue in an isolite isolated way on what

762
00:35:12,780 --> 00:35:15,720
value input values the probe P depends

763
00:35:15,720 --> 00:35:18,839
now if we reintroduce or if you reuse

764
00:35:18,839 --> 00:35:21,119
Randomness the situation might change if

765
00:35:21,119 --> 00:35:22,880
you just consider

766
00:35:22,880 --> 00:35:25,380
ghbc gadgets which I introduced

767
00:35:25,380 --> 00:35:28,020
yesterday where one output share is

768
00:35:28,020 --> 00:35:30,000
simply the secret value blinded by a

769
00:35:30,000 --> 00:35:31,380
fresh random bit

770
00:35:31,380 --> 00:35:33,960
and this would be now the first input

771
00:35:33,960 --> 00:35:36,180
chat to our Gadget here and we would

772
00:35:36,180 --> 00:35:39,180
reuse the same random bit in our Gadget

773
00:35:39,180 --> 00:35:41,579
we would simply unblind the secret and

774
00:35:41,579 --> 00:35:43,859
the procode simply observe the secret

775
00:35:43,859 --> 00:35:45,960
so we may have to make sure that

776
00:35:45,960 --> 00:35:48,540
intuitively that the input

777
00:35:48,540 --> 00:35:51,060
is kind of independent of the randomness

778
00:35:51,060 --> 00:35:53,460
we use in the gadget to to be able to

779
00:35:53,460 --> 00:35:57,119
argue that we are not unblind the secret

780
00:35:57,119 --> 00:36:00,180
so no single probe is able to unblind

781
00:36:00,180 --> 00:36:02,760
the secret at the end

782
00:36:02,760 --> 00:36:04,980
and with our comma construction we do

783
00:36:04,980 --> 00:36:06,839
exactly that so here you can see our two

784
00:36:06,839 --> 00:36:08,460
input and Gadget

785
00:36:08,460 --> 00:36:10,560
where we simply have this input refresh

786
00:36:10,560 --> 00:36:12,720
and we have an output refresh where we

787
00:36:12,720 --> 00:36:15,300
refresh every cross domain and now we

788
00:36:15,300 --> 00:36:18,119
can be sure that the output will be

789
00:36:18,119 --> 00:36:20,460
completely independent of the fresh

790
00:36:20,460 --> 00:36:22,800
random bits used for the input

791
00:36:22,800 --> 00:36:25,980
refreshing yeah and intuitively this is

792
00:36:25,980 --> 00:36:29,640
allows us to argue that that the secret

793
00:36:29,640 --> 00:36:32,579
value is never unblinded regardless of

794
00:36:32,579 --> 00:36:34,560
where we place a probe in the circuit

795
00:36:34,560 --> 00:36:37,320
yeah if you use only coma gadgets then

796
00:36:37,320 --> 00:36:40,020
the input will be either an initial

797
00:36:40,020 --> 00:36:42,660
input or it will be an output of another

798
00:36:42,660 --> 00:36:45,900
comma Gadget so completely independent

799
00:36:45,900 --> 00:36:47,760
of r0 and R1

800
00:36:47,760 --> 00:36:49,859
and then we refresh it at the output and

801
00:36:49,859 --> 00:36:51,839
have the same situation again

802
00:36:51,839 --> 00:36:54,420
so this is the intuition and we also

803
00:36:54,420 --> 00:36:57,240
constructed an xor Gadget which follows

804
00:36:57,240 --> 00:36:59,579
the same general structure right we have

805
00:36:59,579 --> 00:37:01,320
this input refresh and we have this

806
00:37:01,320 --> 00:37:03,359
output refresh where we where the output

807
00:37:03,359 --> 00:37:06,060
refresh again ensures that the input

808
00:37:06,060 --> 00:37:08,400
bits are completely independent of the

809
00:37:08,400 --> 00:37:10,260
input values I have the input refresh

810
00:37:10,260 --> 00:37:12,300
values random values are completely

811
00:37:12,300 --> 00:37:16,280
independent of the input values

812
00:37:16,680 --> 00:37:19,980
now we not only considered two input

813
00:37:19,980 --> 00:37:22,140
Gates here we extended our approach or

814
00:37:22,140 --> 00:37:25,099
our construction so to um

815
00:37:25,099 --> 00:37:26,940
also

816
00:37:26,940 --> 00:37:30,000
um support arbitrary input width so an

817
00:37:30,000 --> 00:37:32,940
arbitrary number of inputs which exactly

818
00:37:32,940 --> 00:37:34,859
follows the same structure we have this

819
00:37:34,859 --> 00:37:37,140
input refresh and then we have a refresh

820
00:37:37,140 --> 00:37:39,599
of everything across domain

821
00:37:39,599 --> 00:37:43,500
so every at the end result at this and

822
00:37:43,500 --> 00:37:45,599
fresh random bits at the input and the

823
00:37:45,599 --> 00:37:48,060
and the 2 to the power of n fresh random

824
00:37:48,060 --> 00:37:51,000
bits for masking the cross domains

825
00:37:51,000 --> 00:37:53,099
and now

826
00:37:53,099 --> 00:37:56,540
um if you would mask an overall circuit

827
00:37:56,540 --> 00:37:59,640
the the number of bit first random bits

828
00:37:59,640 --> 00:38:02,339
we need is simply n plus 2 to the power

829
00:38:02,339 --> 00:38:04,859
of n fresh vendor Mass where n is the

830
00:38:04,859 --> 00:38:07,680
maximum number of inputs in any of these

831
00:38:07,680 --> 00:38:10,500
gadgets so the the largest Gadget is

832
00:38:10,500 --> 00:38:12,660
determining

833
00:38:12,660 --> 00:38:15,060
um the the number of fresh inputs we

834
00:38:15,060 --> 00:38:16,980
need in the overall circuit because we

835
00:38:16,980 --> 00:38:20,160
can essentially reuse parts or the whole

836
00:38:20,160 --> 00:38:22,140
random bits in every Gadget

837
00:38:22,140 --> 00:38:24,540
instantiation

838
00:38:24,540 --> 00:38:26,599
foreign

839
00:38:26,599 --> 00:38:29,280
and now is it worth it so we have one

840
00:38:29,280 --> 00:38:31,380
major drawback here because in

841
00:38:31,380 --> 00:38:33,079
comparable

842
00:38:33,079 --> 00:38:35,760
composability Frameworks the linear

843
00:38:35,760 --> 00:38:38,099
operations are essentially for free you

844
00:38:38,099 --> 00:38:40,500
can just mask them in a sharewise manner

845
00:38:40,500 --> 00:38:43,500
and you will not introduce any

846
00:38:43,500 --> 00:38:45,720
additional latency awareness requirement

847
00:38:45,720 --> 00:38:48,359
and for our XR Gadget we need two

848
00:38:48,359 --> 00:38:50,760
register stages latency

849
00:38:50,760 --> 00:38:54,540
so we if you compare us to to these

850
00:38:54,540 --> 00:38:56,780
gadgets we will result in a much higher

851
00:38:56,780 --> 00:39:00,359
latency requirement but at the end we we

852
00:39:00,359 --> 00:39:02,160
drastically reduce the renderness

853
00:39:02,160 --> 00:39:04,440
requirements because regardless of the

854
00:39:04,440 --> 00:39:05,880
size and the complexity of the

855
00:39:05,880 --> 00:39:08,220
unprotected circuit we only need six

856
00:39:08,220 --> 00:39:11,160
fresh random bits in total

857
00:39:11,160 --> 00:39:12,780
now

858
00:39:12,780 --> 00:39:15,180
um my our construction of the multi

859
00:39:15,180 --> 00:39:17,760
multiple input gadgets kind of mitigate

860
00:39:17,760 --> 00:39:19,619
this problem because if you would for

861
00:39:19,619 --> 00:39:22,320
example think often um

862
00:39:22,320 --> 00:39:25,859
seven combination and N combination of

863
00:39:25,859 --> 00:39:27,480
seven variables

864
00:39:27,480 --> 00:39:29,880
if you only use two input and gadgets

865
00:39:29,880 --> 00:39:31,380
you would need this three three

866
00:39:31,380 --> 00:39:34,140
structure with an algorithmic depth and

867
00:39:34,140 --> 00:39:36,000
that would introduce a lot of latency

868
00:39:36,000 --> 00:39:39,359
and we can just do it in an input with

869
00:39:39,359 --> 00:39:42,300
um Gadget which only into you introduce

870
00:39:42,300 --> 00:39:43,980
two

871
00:39:43,980 --> 00:39:46,200
um clock Cycles latency but at the end

872
00:39:46,200 --> 00:39:48,480
if we if we also only use two input

873
00:39:48,480 --> 00:39:50,880
gadgets we are much worse in terms of in

874
00:39:50,880 --> 00:39:52,200
terms of latency

875
00:39:52,200 --> 00:39:55,380
and this you can see here so basically

876
00:39:55,380 --> 00:39:58,140
we have a drastic improvement and the

877
00:39:58,140 --> 00:39:59,820
number of fresh random bits we need per

878
00:39:59,820 --> 00:40:02,579
cycle here we so we conducted several

879
00:40:02,579 --> 00:40:04,320
case studies

880
00:40:04,320 --> 00:40:06,480
um we integrated support for these

881
00:40:06,480 --> 00:40:08,940
gadgets also into our gamer the talk you

882
00:40:08,940 --> 00:40:11,400
had yesterday and we can fully automated

883
00:40:11,400 --> 00:40:14,040
gain weight or mask any circuit we want

884
00:40:14,040 --> 00:40:16,560
yeah so we made several case studies and

885
00:40:16,560 --> 00:40:17,820
here you see a round-based as

886
00:40:17,820 --> 00:40:20,339
implementation and we only need six

887
00:40:20,339 --> 00:40:22,560
fresh vending bits per cycle by for for

888
00:40:22,560 --> 00:40:26,400
example ghpc or hpc2 gadgets need 680

889
00:40:26,400 --> 00:40:27,960
bits per cycle

890
00:40:27,960 --> 00:40:30,720
now you also can see our disadvantage of

891
00:40:30,720 --> 00:40:33,900
the latency so we have 42 clock Cycles

892
00:40:33,900 --> 00:40:35,520
added latency

893
00:40:35,520 --> 00:40:38,520
per round while comparable gadgets have

894
00:40:38,520 --> 00:40:40,380
like eight or four even

895
00:40:40,380 --> 00:40:42,720
and if we don't compare or if you don't

896
00:40:42,720 --> 00:40:44,700
consider the randomness source for

897
00:40:44,700 --> 00:40:45,900
generating

898
00:40:45,900 --> 00:40:48,540
um the random bits we are also

899
00:40:48,540 --> 00:40:51,839
worth in the area requirement or in the

900
00:40:51,839 --> 00:40:55,560
area overhead yeah but if you have a lot

901
00:40:55,560 --> 00:40:58,260
of fresh random bits you need prngs with

902
00:40:58,260 --> 00:41:00,599
a high throughput which also introduces

903
00:41:00,599 --> 00:41:03,660
an area overhead into the design so it

904
00:41:03,660 --> 00:41:05,940
wouldn't be fair to not consider this

905
00:41:05,940 --> 00:41:09,180
so we did another case study where we

906
00:41:09,180 --> 00:41:11,640
actually built the randomness Source

907
00:41:11,640 --> 00:41:14,720
here and we considered diff uh different

908
00:41:14,720 --> 00:41:17,280
architectures we considered in prng

909
00:41:17,280 --> 00:41:21,780
based on an lfsr so with 31-bit width

910
00:41:21,780 --> 00:41:24,960
and one lfsr with 34 bits and also one

911
00:41:24,960 --> 00:41:26,040
ketchup

912
00:41:26,040 --> 00:41:28,320
and here you can see at the end if you

913
00:41:28,320 --> 00:41:31,020
consider both the area overhead for the

914
00:41:31,020 --> 00:41:33,119
actual circuit and the area overhead for

915
00:41:33,119 --> 00:41:35,880
the randomness Source at the end we

916
00:41:35,880 --> 00:41:38,339
actually do have an advantage of course

917
00:41:38,339 --> 00:41:40,740
this cannot be judged as a general rule

918
00:41:40,740 --> 00:41:43,859
there might be more clever ways to

919
00:41:43,859 --> 00:41:46,680
implement the prng but I think it's a

920
00:41:46,680 --> 00:41:48,780
reasonable approach and gives kind of a

921
00:41:48,780 --> 00:41:50,339
fair comparison here

922
00:41:50,339 --> 00:41:53,160
yeah so the the takeaway is

923
00:41:53,160 --> 00:41:56,160
again we are much better in terms of

924
00:41:56,160 --> 00:41:59,460
of Brendan was introduced and also in

925
00:41:59,460 --> 00:42:01,619
overhaul uh we're also better in overall

926
00:42:01,619 --> 00:42:04,260
area and the price we pay here is um

927
00:42:04,260 --> 00:42:06,960
latency essentially

928
00:42:06,960 --> 00:42:08,820
yeah thank you very much that's all from

929
00:42:08,820 --> 00:42:12,740
my side I'm happy to take any questions

930
00:42:18,300 --> 00:42:21,480
thank you David for the nice talk and we

931
00:42:21,480 --> 00:42:25,859
do have some time for a few questions

932
00:42:25,859 --> 00:42:29,880
thank you thank you for your talk

933
00:42:29,880 --> 00:42:32,820
um did you investigate the price in

934
00:42:32,820 --> 00:42:35,099
terms of security of choosing only six

935
00:42:35,099 --> 00:42:38,400
bits in the whole design

936
00:42:38,400 --> 00:42:40,800
you mean whether we met some actual

937
00:42:40,800 --> 00:42:43,200
security evaluations at the end well if

938
00:42:43,200 --> 00:42:45,180
you have some security laws by only

939
00:42:45,180 --> 00:42:48,420
using uh six bits of Randomness so the

940
00:42:48,420 --> 00:42:49,500
full

941
00:42:49,500 --> 00:42:51,359
Mass circuit

942
00:42:51,359 --> 00:42:53,700
um so we conducted actual

943
00:42:53,700 --> 00:42:57,599
practical leakage evaluation and several

944
00:42:57,599 --> 00:43:00,599
one of them are multiple one of them and

945
00:43:00,599 --> 00:43:02,819
yeah at the end all of them are secure

946
00:43:02,819 --> 00:43:05,220
with 100 million traces so

947
00:43:05,220 --> 00:43:07,260
yeah this this actually works in

948
00:43:07,260 --> 00:43:08,480
practice

949
00:43:08,480 --> 00:43:10,859
so you tried like

950
00:43:10,859 --> 00:43:12,780
um to detect for further leakage right

951
00:43:12,780 --> 00:43:16,020
exactly okay but did you consider

952
00:43:16,020 --> 00:43:19,140
um like horizontal attacks or multiviat

953
00:43:19,140 --> 00:43:21,060
attacks this kind of thing no we didn't

954
00:43:21,060 --> 00:43:22,680
consider that but you are right if you

955
00:43:22,680 --> 00:43:23,700
like

956
00:43:23,700 --> 00:43:25,500
um have multiple points in time where we

957
00:43:25,500 --> 00:43:27,180
can kind of reduce the randomness this

958
00:43:27,180 --> 00:43:29,400
might be an issue at the end but we

959
00:43:29,400 --> 00:43:31,319
didn't consider this in the scenario I

960
00:43:31,319 --> 00:43:33,240
think it would be interesting to proceed

961
00:43:33,240 --> 00:43:35,160
to investigate that and see some

962
00:43:35,160 --> 00:43:36,720
compromise between the overall

963
00:43:36,720 --> 00:43:39,000
Randomness and security against this

964
00:43:39,000 --> 00:43:43,520
kind of thing yeah I agree thank you

965
00:43:45,060 --> 00:43:47,220
hi uh nice talk

966
00:43:47,220 --> 00:43:49,920
um probably I've missed it but is it

967
00:43:49,920 --> 00:43:52,980
trivially composable or is it or yeah

968
00:43:52,980 --> 00:43:54,599
it's it's too real you can freely

969
00:43:54,599 --> 00:43:57,000
compose it really so if you only use it

970
00:43:57,000 --> 00:43:59,220
it's like it's not composable with like

971
00:43:59,220 --> 00:44:01,260
other gadgets from other

972
00:44:01,260 --> 00:44:03,300
um composability Frameworks like pioneer

973
00:44:03,300 --> 00:44:05,640
or something but it's trivia composable

974
00:44:05,640 --> 00:44:07,740
in itself if you only use coma gadgets

975
00:44:07,740 --> 00:44:09,920
you can just construct

976
00:44:09,920 --> 00:44:12,000
circuits like you want

977
00:44:12,000 --> 00:44:14,400
okay once again

978
00:44:14,400 --> 00:44:17,420
okay thanks

979
00:44:22,440 --> 00:44:24,540
so related to equation of material like

980
00:44:24,540 --> 00:44:26,940
in your implementation do you use the

981
00:44:26,940 --> 00:44:28,920
same bits for the fully yes or do you

982
00:44:28,920 --> 00:44:30,660
change these random bits at every cycle

983
00:44:30,660 --> 00:44:33,359
still I changed we changed the bits at

984
00:44:33,359 --> 00:44:35,460
every cycle okay and quick question do

985
00:44:35,460 --> 00:44:37,680
you did you consider uh higher order

986
00:44:37,680 --> 00:44:40,079
masking yeah that's that's an

987
00:44:40,079 --> 00:44:41,819
interesting that's an interesting

988
00:44:41,819 --> 00:44:43,980
question like you cannot consider it in

989
00:44:43,980 --> 00:44:45,599
the direct manner right because if you

990
00:44:45,599 --> 00:44:47,400
would reuse Randomness in every Gadget

991
00:44:47,400 --> 00:44:48,780
you could just if you have two probes

992
00:44:48,780 --> 00:44:51,180
unblind everything but actually you

993
00:44:51,180 --> 00:44:53,400
could think of reusing a part of the

994
00:44:53,400 --> 00:44:55,440
randomness and actually I can do some

995
00:44:55,440 --> 00:44:57,060
advertisements so tomorrow is a nice

996
00:44:57,060 --> 00:44:59,640
talk by Jacob our colleague at the war

997
00:44:59,640 --> 00:45:03,060
University and he and there we try to

998
00:45:03,060 --> 00:45:05,520
reuse the fresh renderness in higher

999
00:45:05,520 --> 00:45:07,560
order gadgets existing higher order

1000
00:45:07,560 --> 00:45:09,980
gadgets

1001
00:45:11,119 --> 00:45:14,280
okay do we have more questions from the

1002
00:45:14,280 --> 00:45:16,800
audience there are still no questions on

1003
00:45:16,800 --> 00:45:19,220
Zoom

1004
00:45:21,420 --> 00:45:24,000
if not then yeah let's thank the speaker

1005
00:45:24,000 --> 00:45:27,140
again and

1006
00:45:46,020 --> 00:45:50,160
the next talk will be given by way on

1007
00:45:50,160 --> 00:45:52,800
the topic of unefficient and secure code

1008
00:45:52,800 --> 00:45:56,460
based masking at pragmatic evaluation so

1009
00:45:56,460 --> 00:45:58,700
which

1010
00:45:58,920 --> 00:46:02,180
context and

1011
00:46:17,040 --> 00:46:20,400
okay hi everyone I'm Mary Chen from

1012
00:46:20,400 --> 00:46:22,980
telegram Paris and this is the joint

1013
00:46:22,980 --> 00:46:26,819
work with the chambe and Sivan and the

1014
00:46:26,819 --> 00:46:29,579
fan and alazoi from

1015
00:46:29,579 --> 00:46:31,400
from Virginia University

1016
00:46:31,400 --> 00:46:35,940
our worker is about efficient and under

1017
00:46:35,940 --> 00:46:37,920
security code base masking

1018
00:46:37,920 --> 00:46:40,440
implementation and also attack based

1019
00:46:40,440 --> 00:46:41,839
evaluation

1020
00:46:41,839 --> 00:46:46,200
so firstly as such participant so when

1021
00:46:46,200 --> 00:46:48,540
we are familiar with the search channel

1022
00:46:48,540 --> 00:46:53,160
text but just one sentence so basically

1023
00:46:53,160 --> 00:46:53,839
um

1024
00:46:53,839 --> 00:46:59,280
any any physical computation performed

1025
00:46:59,280 --> 00:47:03,060
by run device to Anika and Nick some

1026
00:47:03,060 --> 00:47:05,579
observable indicators that could be used

1027
00:47:05,579 --> 00:47:08,760
for for attacks and basically the

1028
00:47:08,760 --> 00:47:12,060
masking is one of the one of the most

1029
00:47:12,060 --> 00:47:15,180
famous protection against the sectional

1030
00:47:15,180 --> 00:47:17,160
attacks so basically it has a proper

1031
00:47:17,160 --> 00:47:21,839
security and the cost is acceptable and

1032
00:47:21,839 --> 00:47:24,980
its algorithmetic

1033
00:47:24,980 --> 00:47:28,380
geometrical level so it can be

1034
00:47:28,380 --> 00:47:33,000
flexible to any algorithms and the most

1035
00:47:33,000 --> 00:47:35,880
simplest one is the Premier masking so

1036
00:47:35,880 --> 00:47:39,240
basically so here we use the

1037
00:47:39,240 --> 00:47:42,720
here we use just uh and but it's xor

1038
00:47:42,720 --> 00:47:46,380
infinite side so for the pony masking we

1039
00:47:46,380 --> 00:47:49,619
have uh the first chain is the sum the

1040
00:47:49,619 --> 00:47:52,400
actual of the masks

1041
00:47:52,400 --> 00:47:56,280
masks Y and X is since the variable and

1042
00:47:56,280 --> 00:47:58,500
then this is encoded

1043
00:47:58,500 --> 00:48:01,980
encoded the variable so this scheme can

1044
00:48:01,980 --> 00:48:05,220
be can be generalized to the code-based

1045
00:48:05,220 --> 00:48:08,420
masking in which we have the

1046
00:48:08,420 --> 00:48:11,579
uniform representation which is a z is

1047
00:48:11,579 --> 00:48:16,560
X2 plus the YH well X can be more than

1048
00:48:16,560 --> 00:48:20,460
one one byte or one more word so it's a

1049
00:48:20,460 --> 00:48:23,220
kind of a package of the implementation

1050
00:48:23,220 --> 00:48:26,579
and then they we also we have insurance

1051
00:48:26,579 --> 00:48:29,040
so here's the the most important stuff

1052
00:48:29,040 --> 00:48:30,660
is uh

1053
00:48:30,660 --> 00:48:36,020
is J and H so there are two two matrices

1054
00:48:36,020 --> 00:48:39,480
the genetic matrices of linear code 70

1055
00:48:39,480 --> 00:48:42,800
so we only consider linear code here

1056
00:48:42,800 --> 00:48:45,540
and the condition for for this

1057
00:48:45,540 --> 00:48:49,200
construction is that the Sony networks

1058
00:48:49,200 --> 00:48:52,200
CND they have only zero code word in the

1059
00:48:52,200 --> 00:48:55,560
intersection otherwise we cannot decode

1060
00:48:55,560 --> 00:48:57,140
the security

1061
00:48:57,140 --> 00:49:02,339
and then for uh so if if a is equal to K

1062
00:49:02,339 --> 00:49:05,220
plus M then it's uh then no redundancy

1063
00:49:05,220 --> 00:49:07,980
and the effect and greater than Q Plus M

1064
00:49:07,980 --> 00:49:12,660
like a polynomial it can be redundancy

1065
00:49:12,660 --> 00:49:16,319
uh so that's the basics so here are two

1066
00:49:16,319 --> 00:49:18,960
examples the first one is a polyamasking

1067
00:49:18,960 --> 00:49:23,040
so it's a it's the same as before so we

1068
00:49:23,040 --> 00:49:26,160
can express in coding theoretic form

1069
00:49:26,160 --> 00:49:28,260
that's uh

1070
00:49:28,260 --> 00:49:30,480
G and H are very simple it's binary

1071
00:49:30,480 --> 00:49:33,000
matrixes and then if we move to the

1072
00:49:33,000 --> 00:49:36,599
inner product masking we have

1073
00:49:36,599 --> 00:49:41,339
we have one minor changes which is uh AI

1074
00:49:41,339 --> 00:49:45,060
is here it's a constant and then in the

1075
00:49:45,060 --> 00:49:47,880
matrices of H we have the First Column

1076
00:49:47,880 --> 00:49:50,520
is different but this way we can have

1077
00:49:50,520 --> 00:49:53,760
have a very nice property that uh the

1078
00:49:53,760 --> 00:49:56,700
the transition leakage can be removed we

1079
00:49:56,700 --> 00:50:01,319
believe it can be removed so that we

1080
00:50:01,319 --> 00:50:03,480
have two examples here

1081
00:50:03,480 --> 00:50:06,380
so however we have

1082
00:50:06,380 --> 00:50:08,880
maybe more than two issues but in this

1083
00:50:08,880 --> 00:50:11,160
worker we focus on two issues the first

1084
00:50:11,160 --> 00:50:14,099
one is the high computational overhead

1085
00:50:14,099 --> 00:50:18,000
basically for instance for improved in

1086
00:50:18,000 --> 00:50:21,420
the product masking it's a about one one

1087
00:50:21,420 --> 00:50:25,940
half times two masking and for the cost

1088
00:50:25,940 --> 00:50:27,560
amortized

1089
00:50:27,560 --> 00:50:31,319
amortization works it works better for

1090
00:50:31,319 --> 00:50:34,800
for only for nothing but for and like

1091
00:50:34,800 --> 00:50:37,200
two hours rate it could be

1092
00:50:37,200 --> 00:50:41,579
uh inefficient and the otherwise the

1093
00:50:41,579 --> 00:50:44,160
okay we have meaning constructions but

1094
00:50:44,160 --> 00:50:47,280
most of them uh theoretical analysis or

1095
00:50:47,280 --> 00:50:51,300
or it's by owning by simulation so and a

1096
00:50:51,300 --> 00:50:54,540
few of them did the test for Decatur

1097
00:50:54,540 --> 00:50:58,200
assessment but the result a few the

1098
00:50:58,200 --> 00:51:01,339
attack based evaluation

1099
00:51:01,380 --> 00:51:04,859
So In This World Cup we focus on both

1100
00:51:04,859 --> 00:51:07,079
the efficiency and the security

1101
00:51:07,079 --> 00:51:11,220
evaluation basically we choose this this

1102
00:51:11,220 --> 00:51:14,700
General this big Matrix as encoder

1103
00:51:14,700 --> 00:51:17,339
basically it's a concatenation of J and

1104
00:51:17,339 --> 00:51:21,660
H then we could choose different we

1105
00:51:21,660 --> 00:51:23,700
could choose any of the elements in this

1106
00:51:23,700 --> 00:51:25,619
Matrix the only condition is that the

1107
00:51:25,619 --> 00:51:29,640
CND to an inner code has only the

1108
00:51:29,640 --> 00:51:33,000
uh zero code over the intersection

1109
00:51:33,000 --> 00:51:35,760
so basically we could choose that g is

1110
00:51:35,760 --> 00:51:39,359
the identity plus zero element and then

1111
00:51:39,359 --> 00:51:42,300
here we have a read pattern that is a

1112
00:51:42,300 --> 00:51:44,579
larger identity so by this way you could

1113
00:51:44,579 --> 00:51:48,740
have as many as for one and zero that

1114
00:51:48,740 --> 00:51:52,440
the sum of uh multiplication can be

1115
00:51:52,440 --> 00:51:56,099
removed so our Improvement so firstly uh

1116
00:51:56,099 --> 00:52:00,359
it's it's valid because J and H matches

1117
00:52:00,359 --> 00:52:03,119
with this this condition and it's also

1118
00:52:03,119 --> 00:52:05,220
generic because

1119
00:52:05,220 --> 00:52:08,220
we consider any uh we could consider any

1120
00:52:08,220 --> 00:52:12,660
code by equivalence they could take the

1121
00:52:12,660 --> 00:52:16,440
uh take the systematic form that could

1122
00:52:16,440 --> 00:52:20,339
be like this format and also it's a

1123
00:52:20,339 --> 00:52:23,819
specific species so we could remove an

1124
00:52:23,819 --> 00:52:27,619
as many as multiplications

1125
00:52:27,619 --> 00:52:31,980
then we recall the multiplication in the

1126
00:52:31,980 --> 00:52:35,099
chest printing paper because so this one

1127
00:52:35,099 --> 00:52:38,660
is the only one consider the

1128
00:52:38,660 --> 00:52:41,520
consider the general code base masking

1129
00:52:41,520 --> 00:52:43,700
and for any encoder

1130
00:52:43,700 --> 00:52:46,859
for linear operation because it's much

1131
00:52:46,859 --> 00:52:49,260
easier so we here we only consider the

1132
00:52:49,260 --> 00:52:52,140
multiplication nonlinear pattern so

1133
00:52:52,140 --> 00:52:55,319
basically in this uh in this framework

1134
00:52:55,319 --> 00:52:58,500
we have like input is to sharing

1135
00:52:58,500 --> 00:53:02,460
Etc and example Out product is like like

1136
00:53:02,460 --> 00:53:07,099
the same in I established skin mates

1137
00:53:07,099 --> 00:53:10,440
Auto product or tensor production then

1138
00:53:10,440 --> 00:53:14,460
it's refreshed and took a test with the

1139
00:53:14,460 --> 00:53:17,460
with the modification with this Matrix M

1140
00:53:17,460 --> 00:53:20,579
it's a interesting instrument transform

1141
00:53:20,579 --> 00:53:22,819
into

1142
00:53:22,880 --> 00:53:26,099
polishery or attitude sharing and then

1143
00:53:26,099 --> 00:53:29,339
by re-encoding it will go back to code

1144
00:53:29,339 --> 00:53:33,119
to generally code business key so then

1145
00:53:33,119 --> 00:53:36,720
after refresh again to go to Output so

1146
00:53:36,720 --> 00:53:39,180
basically what we what we could improve

1147
00:53:39,180 --> 00:53:40,680
is that

1148
00:53:40,680 --> 00:53:44,420
because we take the take the

1149
00:53:44,420 --> 00:53:48,960
encoder as this so we could remove zero

1150
00:53:48,960 --> 00:53:51,839
Parts in in the refresh to refresh

1151
00:53:51,839 --> 00:53:56,040
pattern zero uh Zero part and then in

1152
00:53:56,040 --> 00:54:00,059
the M matrices their own Matrix

1153
00:54:00,059 --> 00:54:02,400
so we could only choose the first K

1154
00:54:02,400 --> 00:54:03,900
column

1155
00:54:03,900 --> 00:54:07,700
so afterwards this this Matrix could be

1156
00:54:07,700 --> 00:54:11,900
reduced Anderson we can see that by

1157
00:54:11,900 --> 00:54:16,260
multiply with this generic matrices it's

1158
00:54:16,260 --> 00:54:19,380
equivalent it's almost 30 nothing and it

1159
00:54:19,380 --> 00:54:22,559
cut it's equivalent to this one so what

1160
00:54:22,559 --> 00:54:25,559
we need is only concatenation of zero

1161
00:54:25,559 --> 00:54:29,160
parts to to the the end of to get double

1162
00:54:29,160 --> 00:54:30,480
matrices

1163
00:54:30,480 --> 00:54:32,880
than to refresh it again

1164
00:54:32,880 --> 00:54:37,619
so that's our input Syria Improvement

1165
00:54:37,619 --> 00:54:40,140
so here is the comparison of the

1166
00:54:40,140 --> 00:54:43,740
computational complicity and also the

1167
00:54:43,740 --> 00:54:47,720
several comparison so for instance if

1168
00:54:47,720 --> 00:54:51,119
so just one note so here the yellow

1169
00:54:51,119 --> 00:54:53,220
Gadget is for performing the linear

1170
00:54:53,220 --> 00:54:55,319
operation uh

1171
00:54:55,319 --> 00:54:58,200
in the in the construction they use the

1172
00:54:58,200 --> 00:55:01,079
same same framework as as in this

1173
00:55:01,079 --> 00:55:03,720
multiplication Gadget so we developed As

1174
00:55:03,720 --> 00:55:06,839
A and B so we can see that the reader

1175
00:55:06,839 --> 00:55:10,079
curves are ours with the with k equal to

1176
00:55:10,079 --> 00:55:13,319
one on the left hand k equals 4 on the

1177
00:55:13,319 --> 00:55:15,300
right and then we come to the number of

1178
00:55:15,300 --> 00:55:17,700
modifications

1179
00:55:17,700 --> 00:55:20,579
and you can see that it can be improved

1180
00:55:20,579 --> 00:55:23,720
a lot so to to save the number of

1181
00:55:23,720 --> 00:55:28,440
multiplications next so we consider

1182
00:55:28,440 --> 00:55:31,980
another case that is uh so if we if we

1183
00:55:31,980 --> 00:55:35,460
want to uh protect multiple sensitive

1184
00:55:35,460 --> 00:55:37,740
variables like a key is the greater than

1185
00:55:37,740 --> 00:55:41,240
one but so we still want smaller uh

1186
00:55:41,240 --> 00:55:43,440
smaller value of a smaller security

1187
00:55:43,440 --> 00:55:46,800
order like m is m is the one so only one

1188
00:55:46,800 --> 00:55:50,640
mask that means for ms4 there is a can

1189
00:55:50,640 --> 00:55:52,920
before so the security

1190
00:55:52,920 --> 00:55:57,300
we can see that if m is more the the

1191
00:55:57,300 --> 00:56:00,960
cost the package the implementation

1192
00:56:00,960 --> 00:56:04,740
could be very inefficient but well m is

1193
00:56:04,740 --> 00:56:07,500
much larger this two curves when closed

1194
00:56:07,500 --> 00:56:12,240
like if m is greater than 5 or even even

1195
00:56:12,240 --> 00:56:15,599
much larger so it it will increase at

1196
00:56:15,599 --> 00:56:21,359
the end like if if m is like 16 then

1197
00:56:21,359 --> 00:56:23,339
it's a the package the info

1198
00:56:23,339 --> 00:56:25,319
implementation could be a very efficient

1199
00:56:25,319 --> 00:56:29,180
uh much efficient than the Ninja

1200
00:56:29,180 --> 00:56:30,740
hello

1201
00:56:30,740 --> 00:56:34,140
so here is the implementation comparison

1202
00:56:34,140 --> 00:56:35,160
so

1203
00:56:35,160 --> 00:56:38,900
so yeah okay so we consider uh

1204
00:56:38,900 --> 00:56:45,059
uh arm protects the M4 device uh

1205
00:56:45,059 --> 00:56:48,059
in the business it's a ivr

1206
00:56:48,059 --> 00:56:50,700
implementation and we have like so the

1207
00:56:50,700 --> 00:56:53,280
interesting thing is that here if we

1208
00:56:53,280 --> 00:56:58,260
take the reference the uh the overhead

1209
00:56:58,260 --> 00:57:03,359
is about one one half one half times two

1210
00:57:03,359 --> 00:57:06,559
billion one but yeah okay so it's about

1211
00:57:06,559 --> 00:57:11,520
1.2 times 2 to the brilliant masking

1212
00:57:11,520 --> 00:57:14,520
so that's that's our implementary

1213
00:57:14,520 --> 00:57:16,819
pattern so let's move to the evaluation

1214
00:57:16,819 --> 00:57:20,339
part so basically we could consider uh

1215
00:57:20,339 --> 00:57:22,920
three three types the first one is the

1216
00:57:22,920 --> 00:57:25,200
no redundant that means the N is equal

1217
00:57:25,200 --> 00:57:29,339
to K plus M and we here we take a k

1218
00:57:29,339 --> 00:57:32,819
equal to one and I'm from one to two

1219
00:57:32,819 --> 00:57:37,520
then it's a packet pack the type it so

1220
00:57:37,520 --> 00:57:40,559
when K is greater than one but for the

1221
00:57:40,559 --> 00:57:44,480
Simplicity we take a n equal to K plus M

1222
00:57:44,480 --> 00:57:50,720
then uh just a change K from 1 to

1223
00:57:50,720 --> 00:57:54,240
74. so the last case is the redundancy

1224
00:57:54,240 --> 00:57:58,380
that means like for instance if we only

1225
00:57:58,380 --> 00:57:59,480
need

1226
00:57:59,480 --> 00:58:03,660
M masks to achieve an m so the security

1227
00:58:03,660 --> 00:58:06,359
but here we could increase the number of

1228
00:58:06,359 --> 00:58:08,640
chance but a lot in employment masking

1229
00:58:08,640 --> 00:58:12,720
like in the the presentation by the

1230
00:58:12,720 --> 00:58:15,240
previous decision it's by using encoding

1231
00:58:15,240 --> 00:58:18,059
we could improve increase the number of

1232
00:58:18,059 --> 00:58:23,579
chance to get a larger uh much larger

1233
00:58:23,579 --> 00:58:27,660
uh implementation but so here because

1234
00:58:27,660 --> 00:58:30,740
the redundancy is very important for

1235
00:58:30,740 --> 00:58:34,500
detecting the photo because the

1236
00:58:34,500 --> 00:58:35,700
implementation against the photo

1237
00:58:35,700 --> 00:58:38,280
injection so it's a it's interesting to

1238
00:58:38,280 --> 00:58:41,700
have this this comparison and our Target

1239
00:58:41,700 --> 00:58:44,400
is uh it's a it's not only encoding part

1240
00:58:44,400 --> 00:58:47,460
but also computation so

1241
00:58:47,460 --> 00:58:49,440
for the encoding we consider the sub

1242
00:58:49,440 --> 00:58:50,400
brightness

1243
00:58:50,400 --> 00:58:54,000
uh in the first I just run and for the

1244
00:58:54,000 --> 00:58:57,780
computation part we target the uh the

1245
00:58:57,780 --> 00:58:59,579
bottom neck security bottom neck part

1246
00:58:59,579 --> 00:59:01,859
which is the matrices T in the early

1247
00:59:01,859 --> 00:59:04,079
graduate as we should before it's a

1248
00:59:04,079 --> 00:59:06,180
Pioneer sharing

1249
00:59:06,180 --> 00:59:09,240
uh so before we go to the experimental

1250
00:59:09,240 --> 00:59:12,599
result we we identify a security bottom

1251
00:59:12,599 --> 00:59:16,079
naked so we don't say it's a it's a uh

1252
00:59:16,079 --> 00:59:18,599
it's a flow because it's not flow it's a

1253
00:59:18,599 --> 00:59:21,140
yeah

1254
00:59:22,020 --> 00:59:24,299
secure on the on the programming model

1255
00:59:24,299 --> 00:59:28,500
which has a SNL security but uh it's uh

1256
00:59:28,500 --> 00:59:32,579
because uh we first from code base

1257
00:59:32,579 --> 00:59:36,180
masking to open your masking then by Ray

1258
00:59:36,180 --> 00:59:39,660
by re-encoding to code base asking then

1259
00:59:39,660 --> 00:59:42,839
there is a Transformer from the backend

1260
00:59:42,839 --> 00:59:44,420
Force transformation

1261
00:59:44,420 --> 00:59:48,299
we call this as a security security

1262
00:59:48,299 --> 00:59:50,940
bottom maker so we want to show the

1263
00:59:50,940 --> 00:59:52,940
results afterwards

1264
00:59:52,940 --> 00:59:56,220
uh so for the evaluation we we consider

1265
00:59:56,220 --> 00:59:57,240
uh

1266
00:59:57,240 --> 01:00:00,720
tvi as the literature assessment and the

1267
01:00:00,720 --> 01:00:03,660
text we consider the signal the CPU and

1268
01:00:03,660 --> 01:00:06,839
also the test test of time and template

1269
01:00:06,839 --> 01:00:08,240
attack

1270
01:00:08,240 --> 01:00:11,579
for the experimental setup we choose the

1271
01:00:11,579 --> 01:00:14,640
Army cortex and for the device Legacy

1272
01:00:14,640 --> 01:00:17,480
estimate 32f

1273
01:00:17,480 --> 01:00:23,339
407 and the way we use the year matrices

1274
01:00:23,339 --> 01:00:26,760
so here is uh here in the city of

1275
01:00:26,760 --> 01:00:29,940
encoder basically we consider first of

1276
01:00:29,940 --> 01:00:31,619
all the masking and the signal of the

1277
01:00:31,619 --> 01:00:34,619
Premier masking and for IPM I will only

1278
01:00:34,619 --> 01:00:38,880
consider the tuition tuitions so the

1279
01:00:38,880 --> 01:00:40,619
only difference is here in the parameter

1280
01:00:40,619 --> 01:00:44,700
is the IPM 2 is 2 and 14 14 at the end

1281
01:00:44,700 --> 01:00:50,099
so by taking the teachers the chest 2000

1282
01:00:50,099 --> 01:00:50,780
and

1283
01:00:50,780 --> 01:00:53,880
2021 people we could predict the

1284
01:00:53,880 --> 01:00:57,119
security level is from Panama skin to

1285
01:00:57,119 --> 01:01:00,000
ipm2 to

1286
01:01:00,000 --> 01:01:02,520
signal the vanilla skin and then to

1287
01:01:02,520 --> 01:01:05,460
other cases and the last one is one of

1288
01:01:05,460 --> 01:01:07,859
the optimal linear code that can be

1289
01:01:07,859 --> 01:01:10,940
found in in this case

1290
01:01:11,640 --> 01:01:14,220
so here is the evaluation of second

1291
01:01:14,220 --> 01:01:18,359
order CPA we could find that there are

1292
01:01:18,359 --> 01:01:21,059
two cases that can not resist into

1293
01:01:21,059 --> 01:01:24,599
signal CPA and for the others especially

1294
01:01:24,599 --> 01:01:28,859
for three cases for RPMs 3 and 14 and 23

1295
01:01:28,859 --> 01:01:32,099
they can resistant second node CPA

1296
01:01:32,099 --> 01:01:36,900
because in fact the the second in fact

1297
01:01:36,900 --> 01:01:39,059
the security could be like a set order

1298
01:01:39,059 --> 01:01:43,559
or Force at most of the audacity

1299
01:01:43,559 --> 01:01:47,220
so it's interesting to to validate the

1300
01:01:47,220 --> 01:01:51,299
security of the uh amplification that

1301
01:01:51,299 --> 01:01:54,660
has been like five five or six years in

1302
01:01:54,660 --> 01:01:56,760
the literature

1303
01:01:56,760 --> 01:02:00,660
uh next we present the result of a table

1304
01:02:00,660 --> 01:02:04,140
night attack then we could find that the

1305
01:02:04,140 --> 01:02:05,460
security level

1306
01:02:05,460 --> 01:02:06,480
um

1307
01:02:06,480 --> 01:02:09,960
the security level here is uh from uh

1308
01:02:09,960 --> 01:02:12,480
first of all the pretty masking to to

1309
01:02:12,480 --> 01:02:15,420
the last one in the RPM 2023 so it's

1310
01:02:15,420 --> 01:02:18,240
exact same as I expected

1311
01:02:18,240 --> 01:02:20,760
so here's the security security level we

1312
01:02:20,760 --> 01:02:22,619
don't we don't say it's a security order

1313
01:02:22,619 --> 01:02:25,079
because the security order is almost

1314
01:02:25,079 --> 01:02:27,780
like under probing it's it's almost the

1315
01:02:27,780 --> 01:02:31,020
same but uh practical security order uh

1316
01:02:31,020 --> 01:02:33,780
when evaluated by success rate okay

1317
01:02:33,780 --> 01:02:37,559
centropy so it's a much there are many

1318
01:02:37,559 --> 01:02:40,160
differences

1319
01:02:40,260 --> 01:02:43,859
so it's uh so again it's a it's a it's

1320
01:02:43,859 --> 01:02:46,559
useful to validate this property and to

1321
01:02:46,559 --> 01:02:49,400
to have a practical verification of a

1322
01:02:49,400 --> 01:02:52,859
theoretical results

1323
01:02:52,859 --> 01:02:54,740
uh

1324
01:02:54,740 --> 01:02:58,440
next we will try to validate the

1325
01:02:58,440 --> 01:03:01,380
security Port Lake as we identified

1326
01:03:01,380 --> 01:03:03,240
before so it's a basically it's a

1327
01:03:03,240 --> 01:03:05,220
code-based masking transformed to play

1328
01:03:05,220 --> 01:03:08,640
masking and then go back to to code base

1329
01:03:08,640 --> 01:03:12,420
masking but if we target the the T

1330
01:03:12,420 --> 01:03:15,420
matrices which is the only masking we

1331
01:03:15,420 --> 01:03:17,579
could find that all the cases were on

1332
01:03:17,579 --> 01:03:22,079
Clash uh Crush to connect the bullion

1333
01:03:22,079 --> 01:03:26,420
masking so it's a so that's that means

1334
01:03:26,420 --> 01:03:30,359
if we cannot fix the issue in the in the

1335
01:03:30,359 --> 01:03:32,760
transformation we there is no no meaning

1336
01:03:32,760 --> 01:03:35,160
to use code business because it's in

1337
01:03:35,160 --> 01:03:38,480
almost the same as

1338
01:03:39,000 --> 01:03:40,440
uh

1339
01:03:40,440 --> 01:03:44,760
so this is a northern nor redundant type

1340
01:03:44,760 --> 01:03:49,500
so let's move to a mode tester type so

1341
01:03:49,500 --> 01:03:51,480
basically we don't consider bunny

1342
01:03:51,480 --> 01:03:55,380
masking but we could use multiple

1343
01:03:55,380 --> 01:04:00,240
multiple key like a key code to a mask

1344
01:04:00,240 --> 01:04:03,839
tuitions two pieces of

1345
01:04:03,839 --> 01:04:06,660
sensitive variable once it's kind of a

1346
01:04:06,660 --> 01:04:08,880
reused of

1347
01:04:08,880 --> 01:04:11,160
random masks

1348
01:04:11,160 --> 01:04:15,119
so the encoder is very simple as here

1349
01:04:15,119 --> 01:04:18,000
and we could also predict the security

1350
01:04:18,000 --> 01:04:22,020
is from the this one is a much could be

1351
01:04:22,020 --> 01:04:25,619
much security than than the others so

1352
01:04:25,619 --> 01:04:27,839
basically this is a t-test we could fund

1353
01:04:27,839 --> 01:04:30,480
as as The Wanted by the previous

1354
01:04:30,480 --> 01:04:33,960
decision it's a we could find the

1355
01:04:33,960 --> 01:04:37,380
main transitional indicator from Berlin

1356
01:04:37,380 --> 01:04:39,420
encoding so that's that's bad news

1357
01:04:39,420 --> 01:04:41,819
because here we consider software

1358
01:04:41,819 --> 01:04:44,280
implementation so traditional uh

1359
01:04:44,280 --> 01:04:48,359
indicator could appear and then if we

1360
01:04:48,359 --> 01:04:49,680
move to

1361
01:04:49,680 --> 01:04:53,099
because it's only first of the masking

1362
01:04:53,099 --> 01:04:56,339
so we can see the signal the CPA that

1363
01:04:56,339 --> 01:04:59,180
could succeed we could find that

1364
01:04:59,180 --> 01:05:03,260
because we could find more leakages

1365
01:05:03,260 --> 01:05:08,819
and to recover several like a capitol

1366
01:05:08,819 --> 01:05:11,099
for information so we could improve the

1367
01:05:11,099 --> 01:05:13,640
attacks

1368
01:05:14,040 --> 01:05:17,280
at last we considered the Redundant type

1369
01:05:17,280 --> 01:05:20,760
of type of implementation so here the

1370
01:05:20,760 --> 01:05:22,280
encoder is a

1371
01:05:22,280 --> 01:05:25,859
is a similar to IPM but we consider the

1372
01:05:25,859 --> 01:05:29,579
Motions then the only taking IPM so here

1373
01:05:29,579 --> 01:05:31,319
we take a Solutions and the functions

1374
01:05:31,319 --> 01:05:33,359
but still on the security is the first

1375
01:05:33,359 --> 01:05:35,240
order on the probe model

1376
01:05:35,240 --> 01:05:39,079
uh the increasing the

1377
01:05:39,079 --> 01:05:42,839
integers 21 people uh

1378
01:05:42,839 --> 01:05:46,260
uh the especially established the

1379
01:05:46,260 --> 01:05:48,500
connection between the the due distance

1380
01:05:48,500 --> 01:05:51,599
to the side Channel resistance basically

1381
01:05:51,599 --> 01:05:55,980
for this three parameters they had they

1382
01:05:55,980 --> 01:05:58,680
could have a duty Syndicate for in

1383
01:05:58,680 --> 01:06:03,059
tuition to share mask but in fact if we

1384
01:06:03,059 --> 01:06:04,740
come like

1385
01:06:04,740 --> 01:06:08,400
in a redundant type it's a combined then

1386
01:06:08,400 --> 01:06:11,339
it's a the two different could only be

1387
01:06:11,339 --> 01:06:13,380
decreased

1388
01:06:13,380 --> 01:06:16,140
so as a as in the previous one we could

1389
01:06:16,140 --> 01:06:20,420
predict the security level is uh from I2

1390
01:06:20,420 --> 01:06:24,599
i1 I2 to I3 and here is the evaluation

1391
01:06:24,599 --> 01:06:26,400
we could find that

1392
01:06:26,400 --> 01:06:32,039
also uh so basically here is the IPM IPM

1393
01:06:32,039 --> 01:06:37,700
it's IPM 23 as as before

1394
01:06:37,740 --> 01:06:41,579
that's right so as before so IPM 23 with

1395
01:06:41,579 --> 01:06:42,859
the

1396
01:06:42,859 --> 01:06:47,819
20436 is like like this one but with the

1397
01:06:47,819 --> 01:06:50,819
with the one redundancy it goes to read

1398
01:06:50,819 --> 01:06:54,599
one and then with the two two redundancy

1399
01:06:54,599 --> 01:06:57,619
it's a it's like a yellow one that means

1400
01:06:57,619 --> 01:06:59,880
if we consider

1401
01:06:59,880 --> 01:07:03,119
if we consider combined contaminer

1402
01:07:03,119 --> 01:07:05,099
against both side Channel and the food

1403
01:07:05,099 --> 01:07:08,099
injection then the case is if we add

1404
01:07:08,099 --> 01:07:11,099
more redundancy it could need more more

1405
01:07:11,099 --> 01:07:13,079
leakages from inside Channel perspective

1406
01:07:13,079 --> 01:07:16,200
so that means we need to

1407
01:07:16,200 --> 01:07:19,740
uh we need to make a condition to we

1408
01:07:19,740 --> 01:07:21,319
need to make a

1409
01:07:21,319 --> 01:07:24,240
trade-off between the side Channel

1410
01:07:24,240 --> 01:07:26,819
resist resistance to the photo injection

1411
01:07:26,819 --> 01:07:28,520
resistance

1412
01:07:28,520 --> 01:07:31,859
so to summarize the way we propose the

1413
01:07:31,859 --> 01:07:35,099
improved constructions for uh for

1414
01:07:35,099 --> 01:07:37,099
multiple

1415
01:07:37,099 --> 01:07:39,660
modification gadgets and also the

1416
01:07:39,660 --> 01:07:42,180
implementation we provide the security

1417
01:07:42,180 --> 01:07:45,180
evaluations for three type of code

1418
01:07:45,180 --> 01:07:47,520
business masking uh sorry kind of

1419
01:07:47,520 --> 01:07:51,119
instance and and also we identify the

1420
01:07:51,119 --> 01:07:54,480
security bottleneck so so for the field

1421
01:07:54,480 --> 01:07:57,299
so so for the future work we would like

1422
01:07:57,299 --> 01:08:00,539
to construct fully and code based that

1423
01:08:00,539 --> 01:08:03,780
means we would like to find another way

1424
01:08:03,780 --> 01:08:06,240
to to remove the back and forth

1425
01:08:06,240 --> 01:08:09,539
transformation and the second name as

1426
01:08:09,539 --> 01:08:12,260
the codebase masking is a general

1427
01:08:12,260 --> 01:08:15,259
General scheme so we could

1428
01:08:15,259 --> 01:08:18,600
try to find applications to lightweight

1429
01:08:18,600 --> 01:08:20,160
and also post contentment

1430
01:08:20,160 --> 01:08:23,580
implementations that's that's the the

1431
01:08:23,580 --> 01:08:25,620
that's the talk thanks for your

1432
01:08:25,620 --> 01:08:27,920
attention

1433
01:08:34,259 --> 01:08:36,540
thank you for this nice talk we do have

1434
01:08:36,540 --> 01:08:39,359
time for one or two quick questions so

1435
01:08:39,359 --> 01:08:41,040
we are slightly over time do we have

1436
01:08:41,040 --> 01:08:43,580
questions

1437
01:08:48,719 --> 01:08:50,939
okay maybe I have a quick question so in

1438
01:08:50,939 --> 01:08:53,399
the end you mentioned that this idea

1439
01:08:53,399 --> 01:08:54,660
um that there's a drawback with the

1440
01:08:54,660 --> 01:08:56,279
redundancy

1441
01:08:56,279 --> 01:08:58,319
um if you're using redundancy for fault

1442
01:08:58,319 --> 01:09:01,500
protection to this actually reduces the

1443
01:09:01,500 --> 01:09:04,319
security of the saturated protection yes

1444
01:09:04,319 --> 01:09:06,960
um but do you still see room that we can

1445
01:09:06,960 --> 01:09:09,420
use this idea for Combined protection so

1446
01:09:09,420 --> 01:09:11,698
do you have any idea how to mandate this

1447
01:09:11,698 --> 01:09:15,120
yes I think it's interesting to have a

1448
01:09:15,120 --> 01:09:17,759
have this result regarding the

1449
01:09:17,759 --> 01:09:20,759
redundancy basically if

1450
01:09:20,759 --> 01:09:25,500
so there's the possibility like uh for

1451
01:09:25,500 --> 01:09:28,439
instance if we choose a Optimum in a

1452
01:09:28,439 --> 01:09:31,500
code to maximize the like the two

1453
01:09:31,500 --> 01:09:32,580
distance

1454
01:09:32,580 --> 01:09:36,060
Etc to to maximize the protection of the

1455
01:09:36,060 --> 01:09:38,880
side Channel and then if if we use the

1456
01:09:38,880 --> 01:09:42,660
last code uh on the top of this encoding

1457
01:09:42,660 --> 01:09:44,219
maybe you could find a solution to

1458
01:09:44,219 --> 01:09:46,679
against the post sectional and the photo

1459
01:09:46,679 --> 01:09:49,020
injection so because the linear code

1460
01:09:49,020 --> 01:09:51,839
itself essentially it can detect foot

1461
01:09:51,839 --> 01:09:55,199
that's that made the basic idea

1462
01:09:55,199 --> 01:09:59,660
okay thanks any other question

1463
01:10:00,179 --> 01:10:01,920
if not then let's thank the speaker

1464
01:10:01,920 --> 01:10:04,219
again

1465
01:10:23,600 --> 01:10:27,360
and this brings us also to our last talk

1466
01:10:27,360 --> 01:10:30,179
in this session

1467
01:10:30,179 --> 01:10:33,060
with the title bit slice masking and

1468
01:10:33,060 --> 01:10:35,219
improved truffling how and when to mix

1469
01:10:35,219 --> 01:10:36,840
them in software and the talk will be

1470
01:10:36,840 --> 01:10:39,800
given by Olivier

1471
01:10:40,080 --> 01:10:42,060
um hi uh thanks Pascal for the

1472
01:10:42,060 --> 01:10:43,620
introduction

1473
01:10:43,620 --> 01:10:46,920
okay so that's directly jump uh to the

1474
01:10:46,920 --> 01:10:48,960
technical part of the talk

1475
01:10:48,960 --> 01:10:50,280
so

1476
01:10:50,280 --> 01:10:52,980
here we I will talk about uh site

1477
01:10:52,980 --> 01:10:55,679
General control measure and oh I mean

1478
01:10:55,679 --> 01:10:58,260
exploring a bit the design space of many

1479
01:10:58,260 --> 01:11:00,239
different section control measures and

1480
01:11:00,239 --> 01:11:03,000
when you want to compare them you

1481
01:11:03,000 --> 01:11:05,159
require mostly two things first you want

1482
01:11:05,159 --> 01:11:07,380
to evaluate them regarding to

1483
01:11:07,380 --> 01:11:08,699
performances

1484
01:11:08,699 --> 01:11:11,040
and then you want to evaluate them

1485
01:11:11,040 --> 01:11:13,080
according to security so this is the two

1486
01:11:13,080 --> 01:11:15,120
axis in the graph so when you have an

1487
01:11:15,120 --> 01:11:16,920
implementation what you would like to

1488
01:11:16,920 --> 01:11:20,600
have is a curve like that for one design

1489
01:11:20,600 --> 01:11:23,219
another curve curve for another design

1490
01:11:23,219 --> 01:11:27,000
where you have uh for the given

1491
01:11:27,000 --> 01:11:29,640
performance is a given security and then

1492
01:11:29,640 --> 01:11:32,760
you set up the desired security and you

1493
01:11:32,760 --> 01:11:35,159
pick up your implementation according to

1494
01:11:35,159 --> 01:11:37,679
these curves so here design one is the

1495
01:11:37,679 --> 01:11:39,840
best because for a given security level

1496
01:11:39,840 --> 01:11:42,719
it offers you the best security

1497
01:11:42,719 --> 01:11:46,140
of course we are dealing with

1498
01:11:46,140 --> 01:11:48,719
physical implementation physical control

1499
01:11:48,719 --> 01:11:50,940
measure so it depends on some physical

1500
01:11:50,940 --> 01:11:53,040
parameters so if you change the platform

1501
01:11:53,040 --> 01:11:55,140
it will change the level you have

1502
01:11:55,140 --> 01:11:57,719
different curves and maybe it's not

1503
01:11:57,719 --> 01:11:59,760
design one which is the best option but

1504
01:11:59,760 --> 01:12:02,659
now it's designed two

1505
01:12:03,600 --> 01:12:05,159
okay so

1506
01:12:05,159 --> 01:12:05,900
um

1507
01:12:05,900 --> 01:12:09,420
in sectional analysis usually we have

1508
01:12:09,420 --> 01:12:12,239
two big families of Contour measure the

1509
01:12:12,239 --> 01:12:14,400
first one is masking where you randomize

1510
01:12:14,400 --> 01:12:16,080
the data you process and you split them

1511
01:12:16,080 --> 01:12:19,679
into shares D of them if you do that you

1512
01:12:19,679 --> 01:12:22,980
have some kind of a noise amplification

1513
01:12:22,980 --> 01:12:26,880
effect where the security and you have

1514
01:12:26,880 --> 01:12:30,600
in the end is the mutual information uh

1515
01:12:30,600 --> 01:12:32,760
on the share set to the power D and

1516
01:12:32,760 --> 01:12:34,920
because Mutual information is smaller

1517
01:12:34,920 --> 01:12:36,900
than one because there is some noise in

1518
01:12:36,900 --> 01:12:38,760
your implementation then you get an

1519
01:12:38,760 --> 01:12:41,040
exponential increase in security with

1520
01:12:41,040 --> 01:12:43,560
the with the number of shares

1521
01:12:43,560 --> 01:12:46,500
in this presentation we lay out the

1522
01:12:46,500 --> 01:12:48,920
shares on on the columns

1523
01:12:48,920 --> 01:12:52,140
another family of countermeasure is

1524
01:12:52,140 --> 01:12:53,760
shuffling

1525
01:12:53,760 --> 01:12:56,340
um where instead of randomizing the data

1526
01:12:56,340 --> 01:12:58,920
you randomize the order in which you

1527
01:12:58,920 --> 01:13:01,320
process the data and to do that

1528
01:13:01,320 --> 01:13:03,360
essentially you draw a permutation and

1529
01:13:03,360 --> 01:13:05,699
then all your executor execution flow

1530
01:13:05,699 --> 01:13:08,520
will depend on that given permutation so

1531
01:13:08,520 --> 01:13:10,980
here if we have a permutational size ETA

1532
01:13:10,980 --> 01:13:15,179
the impact on security is multiplied by

1533
01:13:15,179 --> 01:13:18,060
ETA so here is a small example

1534
01:13:18,060 --> 01:13:20,699
okay so I do a permutation and then I

1535
01:13:20,699 --> 01:13:22,140
execute

1536
01:13:22,140 --> 01:13:24,600
uh I mean I process the data according

1537
01:13:24,600 --> 01:13:27,239
to the to the permutation

1538
01:13:27,239 --> 01:13:30,060
okay so we have to countermeasure we

1539
01:13:30,060 --> 01:13:33,060
have shuffling which is like adding some

1540
01:13:33,060 --> 01:13:34,800
noise and we have masking which is

1541
01:13:34,800 --> 01:13:36,659
amplifying noise and then the the

1542
01:13:36,659 --> 01:13:38,760
question we ask ourselves in this work

1543
01:13:38,760 --> 01:13:42,120
is can we get I mean can we mix them in

1544
01:13:42,120 --> 01:13:44,400
such a way that masking is actually

1545
01:13:44,400 --> 01:13:47,040
amplifying the shuffling effect so we

1546
01:13:47,040 --> 01:13:51,500
get some kind of uh ETA to the D effect

1547
01:13:51,659 --> 01:13:54,420
so in in the paper we've been like

1548
01:13:54,420 --> 01:13:57,140
discussing the the curse versus security

1549
01:13:57,140 --> 01:14:00,239
of this implementation and of course the

1550
01:14:00,239 --> 01:14:02,820
first aspect is to explore security

1551
01:14:02,820 --> 01:14:05,219
so in this presentation and in the paper

1552
01:14:05,219 --> 01:14:07,260
we've been like exploring systematically

1553
01:14:07,260 --> 01:14:09,239
the design space of traveling per

1554
01:14:09,239 --> 01:14:12,080
surfing uh sorry masking per shroffing

1555
01:14:12,080 --> 01:14:14,640
and we did that with some kind of a

1556
01:14:14,640 --> 01:14:16,500
paper and pencil approach and then we

1557
01:14:16,500 --> 01:14:18,840
confirmed that with with

1558
01:14:18,840 --> 01:14:21,420
um with simulation we note that there is

1559
01:14:21,420 --> 01:14:22,699
previous work

1560
01:14:22,699 --> 01:14:26,940
by Revival in 2009 where they were able

1561
01:14:26,940 --> 01:14:30,659
to obtain some amplification of um

1562
01:14:30,659 --> 01:14:33,179
of Shifting this masking for the linear

1563
01:14:33,179 --> 01:14:35,940
layers but not for non-linear layers so

1564
01:14:35,940 --> 01:14:39,120
for end Gates and that's a contribution

1565
01:14:39,120 --> 01:14:41,340
of our work

1566
01:14:41,340 --> 01:14:44,159
the second part it's about measuring the

1567
01:14:44,159 --> 01:14:48,060
performances so when you want to mask a

1568
01:14:48,060 --> 01:14:50,100
given primitive so you want to mask

1569
01:14:50,100 --> 01:14:52,560
let's say end Gates

1570
01:14:52,560 --> 01:14:55,199
um what I'm already implemented that do

1571
01:14:55,199 --> 01:14:58,440
you Shuffle do you do you mask more and

1572
01:14:58,440 --> 01:15:00,000
so on so we did some Benchmark on cortex

1573
01:15:00,000 --> 01:15:02,100
and for platform and based on that we

1574
01:15:02,100 --> 01:15:04,080
draw some conclusion about the cost

1575
01:15:04,080 --> 01:15:05,820
versus security of these control

1576
01:15:05,820 --> 01:15:07,920
measures

1577
01:15:07,920 --> 01:15:10,199
okay so I said to be

1578
01:15:10,199 --> 01:15:12,719
we have two layers to to protect so

1579
01:15:12,719 --> 01:15:15,239
let's first up with the linear layers

1580
01:15:15,239 --> 01:15:17,820
and what's the goal there so here you

1581
01:15:17,820 --> 01:15:19,920
have some some data so you have oh yeah

1582
01:15:19,920 --> 01:15:22,739
perfect it works so you have here you

1583
01:15:22,739 --> 01:15:25,620
have independent data on the rows and on

1584
01:15:25,620 --> 01:15:27,480
the columns you have you have the shares

1585
01:15:27,480 --> 01:15:29,580
so here in all the example are already

1586
01:15:29,580 --> 01:15:31,980
present we have five independent data

1587
01:15:31,980 --> 01:15:35,580
and then we have three different shares

1588
01:15:35,580 --> 01:15:38,400
and the goal of protecting the the

1589
01:15:38,400 --> 01:15:41,040
linear layer is to do the component wise

1590
01:15:41,040 --> 01:15:43,800
addition so you want to take the first

1591
01:15:43,800 --> 01:15:45,960
component here do the Excel is the

1592
01:15:45,960 --> 01:15:48,780
second one and then yeah you put them at

1593
01:15:48,780 --> 01:15:50,100
the output

1594
01:15:50,100 --> 01:15:53,100
okay so how do you Shuffle these states

1595
01:15:53,100 --> 01:15:55,080
which are masked

1596
01:15:55,080 --> 01:15:57,120
the first option is what we call

1597
01:15:57,120 --> 01:16:00,060
shuffling tappers so there you just draw

1598
01:16:00,060 --> 01:16:02,280
first permutation and then you select

1599
01:16:02,280 --> 01:16:04,620
the independent data you want to process

1600
01:16:04,620 --> 01:16:07,140
and you process all the shares of that

1601
01:16:07,140 --> 01:16:09,780
independent data so here yeah use the

1602
01:16:09,780 --> 01:16:12,480
plantation so I jump to index three

1603
01:16:12,480 --> 01:16:15,000
I process all the shares then I jump to

1604
01:16:15,000 --> 01:16:18,000
index 4 I process all the shares

1605
01:16:18,000 --> 01:16:22,020
then to two and up to the end

1606
01:16:22,020 --> 01:16:25,500
if you do that you actually do not have

1607
01:16:25,500 --> 01:16:28,140
um amplification of shuffling masking

1608
01:16:28,140 --> 01:16:30,120
the only thing you get

1609
01:16:30,120 --> 01:16:32,880
um is you get the factor ETA as issue

1610
01:16:32,880 --> 01:16:36,239
we're doing shuffling uh yeah as if you

1611
01:16:36,239 --> 01:16:37,860
are doing shuffling in an unpathetic

1612
01:16:37,860 --> 01:16:40,199
case and that is because an adversary

1613
01:16:40,199 --> 01:16:41,820
can like

1614
01:16:41,820 --> 01:16:44,219
the the only room then let's see

1615
01:16:44,219 --> 01:16:47,219
observed with traveling is about what is

1616
01:16:47,219 --> 01:16:50,400
the data process yeah

1617
01:16:50,400 --> 01:16:53,219
so we've been running simulation to

1618
01:16:53,219 --> 01:16:55,620
confirm this this paper and pencil

1619
01:16:55,620 --> 01:16:59,520
approach and as we see here so basically

1620
01:16:59,520 --> 01:17:01,679
on the x-axis or all the graphs you have

1621
01:17:01,679 --> 01:17:03,420
the noise level so if you are on the

1622
01:17:03,420 --> 01:17:06,360
right it's noisy and on the left is not

1623
01:17:06,360 --> 01:17:07,940
noisy

1624
01:17:07,940 --> 01:17:10,800
and on the top you have the the mutual

1625
01:17:10,800 --> 01:17:12,600
information estimation and what is

1626
01:17:12,600 --> 01:17:14,760
really important is what we have below

1627
01:17:14,760 --> 01:17:17,640
which is the security gain of our

1628
01:17:17,640 --> 01:17:20,040
shuffling plus masking compared to

1629
01:17:20,040 --> 01:17:21,600
masking only

1630
01:17:21,600 --> 01:17:24,179
and the horizontal dashed Line Stands

1631
01:17:24,179 --> 01:17:26,280
for the the ETA we were expecting so

1632
01:17:26,280 --> 01:17:29,400
let's say here we are in the case where

1633
01:17:29,400 --> 01:17:31,440
the gain is only

1634
01:17:31,440 --> 01:17:33,659
ETA and we see that it's confirmed with

1635
01:17:33,659 --> 01:17:35,820
simulation for all the parameter space

1636
01:17:35,820 --> 01:17:39,080
which has been exploring

1637
01:17:39,600 --> 01:17:42,480
so it's not really satisfying so we look

1638
01:17:42,480 --> 01:17:44,400
for other options the other option is

1639
01:17:44,400 --> 01:17:46,920
what we call Shuffle the shares so here

1640
01:17:46,920 --> 01:17:49,739
we just process the shares the first

1641
01:17:49,739 --> 01:17:51,780
share of all the independent data then

1642
01:17:51,780 --> 01:17:54,120
we jump to the second share we process

1643
01:17:54,120 --> 01:17:56,640
all of them and then to the to the the

1644
01:17:56,640 --> 01:17:59,580
the next share and so on and as soon as

1645
01:17:59,580 --> 01:18:01,500
you process a new share you will

1646
01:18:01,500 --> 01:18:03,360
generate a new permutation so here is an

1647
01:18:03,360 --> 01:18:04,980
example so I will process the first

1648
01:18:04,980 --> 01:18:07,260
layer so I have a permutation I process

1649
01:18:07,260 --> 01:18:09,060
the first shares accordingly

1650
01:18:09,060 --> 01:18:11,940
and I jump to the second share I I

1651
01:18:11,940 --> 01:18:13,620
process them accordingly also to the

1652
01:18:13,620 --> 01:18:15,840
permutation and then yeah to the next

1653
01:18:15,840 --> 01:18:17,880
one

1654
01:18:17,880 --> 01:18:20,040
if you do that actually you apply

1655
01:18:20,040 --> 01:18:22,620
shuffling to the shares so you decrease

1656
01:18:22,620 --> 01:18:24,860
the noise on each of the shares

1657
01:18:24,860 --> 01:18:26,880
independently and then because you are

1658
01:18:26,880 --> 01:18:29,159
doing masking you I mean you got the the

1659
01:18:29,159 --> 01:18:31,040
product of all the material information

1660
01:18:31,040 --> 01:18:34,020
and suddenly you get attacked to the

1661
01:18:34,020 --> 01:18:36,000
power d

1662
01:18:36,000 --> 01:18:38,699
so yeah we got actually masking

1663
01:18:38,699 --> 01:18:42,199
amplification of shuffling

1664
01:18:42,360 --> 01:18:43,980
um and this is confirmed with simulation

1665
01:18:43,980 --> 01:18:45,780
so let's say we have a permutation of

1666
01:18:45,780 --> 01:18:48,420
size four so at equal four you have two

1667
01:18:48,420 --> 01:18:50,400
shares the gain we observe so which is

1668
01:18:50,400 --> 01:18:52,800
like the the red parameter here is 16

1669
01:18:52,800 --> 01:18:55,320
and if you have three shares you have

1670
01:18:55,320 --> 01:18:57,540
like three shares and

1671
01:18:57,540 --> 01:19:00,239
ETA equal to two to three we have a we

1672
01:19:00,239 --> 01:19:02,640
gain a factor 27.

1673
01:19:02,640 --> 01:19:06,900
okay so can we do better actually for

1674
01:19:06,900 --> 01:19:09,120
linear layers yes

1675
01:19:09,120 --> 01:19:11,940
so what we can do and that's what was

1676
01:19:11,940 --> 01:19:14,880
proposed by um eventually in 2009

1677
01:19:14,880 --> 01:19:18,239
essentially is you have all these ETA to

1678
01:19:18,239 --> 01:19:19,440
the D

1679
01:19:19,440 --> 01:19:21,960
ETA times D3 independent operation to do

1680
01:19:21,960 --> 01:19:24,900
so you can just generate a huge um

1681
01:19:24,900 --> 01:19:27,540
permutation on ostis element and then

1682
01:19:27,540 --> 01:19:29,580
process them

1683
01:19:29,580 --> 01:19:32,580
uh yeah and then process them according

1684
01:19:32,580 --> 01:19:34,320
to the permutation I'm sorry the

1685
01:19:34,320 --> 01:19:36,480
animation is not that smooth the the

1686
01:19:36,480 --> 01:19:39,900
pointer is a bit slow sorry and then

1687
01:19:39,900 --> 01:19:42,719
yeah we get exactly what we had uh from

1688
01:19:42,719 --> 01:19:44,340
um

1689
01:19:44,340 --> 01:19:47,580
and we confirm that with some um some it

1690
01:19:47,580 --> 01:19:51,300
analysis so yeah we get the horizontal

1691
01:19:51,300 --> 01:19:53,640
dashed line and we observe the the

1692
01:19:53,640 --> 01:19:56,159
expected build so that was for linear

1693
01:19:56,159 --> 01:19:58,620
layers of course if you want to mask the

1694
01:19:58,620 --> 01:20:01,380
AES get check or other block ciphers or

1695
01:20:01,380 --> 01:20:02,760
other Primitives

1696
01:20:02,760 --> 01:20:06,060
you need non-linear layers and if it's a

1697
01:20:06,060 --> 01:20:08,580
bit more challenging

1698
01:20:08,580 --> 01:20:09,900
so essentially

1699
01:20:09,900 --> 01:20:11,820
what I explained for linear layers

1700
01:20:11,820 --> 01:20:15,060
applies for non-linear layers especially

1701
01:20:15,060 --> 01:20:17,760
the I mean it applies for shuffling

1702
01:20:17,760 --> 01:20:20,040
share and shopping interprets and you

1703
01:20:20,040 --> 01:20:22,860
got the similar gain so Shifting the

1704
01:20:22,860 --> 01:20:24,900
tuples for non-linear layers you get

1705
01:20:24,900 --> 01:20:27,360
again at the same for nonlinear layers

1706
01:20:27,360 --> 01:20:29,760
and for shuffling the shares you get the

1707
01:20:29,760 --> 01:20:31,260
same here

1708
01:20:31,260 --> 01:20:34,020
we are not able to extend the shuffling

1709
01:20:34,020 --> 01:20:36,239
everything methodology so the one by

1710
01:20:36,239 --> 01:20:37,560
rival

1711
01:20:37,560 --> 01:20:40,440
autonom linear layers essentially

1712
01:20:40,440 --> 01:20:43,440
because the permutation at the output of

1713
01:20:43,440 --> 01:20:46,920
a masked and Shuffle isw is not uniform

1714
01:20:46,920 --> 01:20:50,219
if you you draw a too large permutation

1715
01:20:50,219 --> 01:20:52,020
and all the purple and pencil approach

1716
01:20:52,020 --> 01:20:56,219
required to have a uniform temptation

1717
01:20:56,219 --> 01:20:58,320
so in the following of the talk I will

1718
01:20:58,320 --> 01:21:01,800
just focus on non-linear layers because

1719
01:21:01,800 --> 01:21:04,500
that's the most expensive part in masked

1720
01:21:04,500 --> 01:21:06,659
implementation and on shuffling the

1721
01:21:06,659 --> 01:21:08,159
shares because it's the one which is

1722
01:21:08,159 --> 01:21:10,380
providing us

1723
01:21:10,380 --> 01:21:12,380
um yeah the the

1724
01:21:12,380 --> 01:21:14,219
amplification effect that we are

1725
01:21:14,219 --> 01:21:16,699
expecting

1726
01:21:16,800 --> 01:21:20,520
yeah so that's it perfect uh no I will

1727
01:21:20,520 --> 01:21:23,040
jump into perverse security and explain

1728
01:21:23,040 --> 01:21:27,199
kind of the trade-off we can have so

1729
01:21:27,719 --> 01:21:29,699
one thing you do if you want to to

1730
01:21:29,699 --> 01:21:30,659
protect

1731
01:21:30,659 --> 01:21:31,380
um

1732
01:21:31,380 --> 01:21:33,420
protect a lot of engage you can do bit

1733
01:21:33,420 --> 01:21:35,820
slicing when we will do

1734
01:21:35,820 --> 01:21:37,980
um these independent ends in parallel so

1735
01:21:37,980 --> 01:21:41,159
with slicing usually enjoys a large

1736
01:21:41,159 --> 01:21:43,679
number of ends and it Androids

1737
01:21:43,679 --> 01:21:46,380
processing them in parallel and you have

1738
01:21:46,380 --> 01:21:49,440
to spend some round on this protect that

1739
01:21:49,440 --> 01:21:52,020
on the contact path shuffling also

1740
01:21:52,020 --> 01:21:54,420
favors a large number of independent

1741
01:21:54,420 --> 01:21:57,960
hand but you it favors to like a huge

1742
01:21:57,960 --> 01:22:00,480
serialization such that you have

1743
01:22:00,480 --> 01:22:01,679
um I mean you can draw a large

1744
01:22:01,679 --> 01:22:03,480
permutation and the attack factors

1745
01:22:03,480 --> 01:22:05,280
become larger and again you have to

1746
01:22:05,280 --> 01:22:09,199
spend some Randomness on that

1747
01:22:09,239 --> 01:22:11,520
okay so the challenges are when you want

1748
01:22:11,520 --> 01:22:14,060
to mix them together is do you favor

1749
01:22:14,060 --> 01:22:16,980
serialization do you favor parallelism

1750
01:22:16,980 --> 01:22:18,960
do you put more do you spend your

1751
01:22:18,960 --> 01:22:20,880
Randomness on shuffling or unmasking

1752
01:22:20,880 --> 01:22:23,460
does it depends on the noise noise level

1753
01:22:23,460 --> 01:22:25,320
The Primitives to protect and so on so

1754
01:22:25,320 --> 01:22:26,880
that's what we study in the paper

1755
01:22:26,880 --> 01:22:28,920
essentially

1756
01:22:28,920 --> 01:22:31,620
so here I say there is different option

1757
01:22:31,620 --> 01:22:33,900
I will just give a

1758
01:22:33,900 --> 01:22:36,600
yeah three different options we explore

1759
01:22:36,600 --> 01:22:38,880
a bit more in the paper of course but

1760
01:22:38,880 --> 01:22:40,500
here is the tree option I consider for

1761
01:22:40,500 --> 01:22:41,460
tissue

1762
01:22:41,460 --> 01:22:44,760
so the first one is you want to do 64

1763
01:22:44,760 --> 01:22:46,800
independent ends and you have 30 to bit

1764
01:22:46,800 --> 01:22:50,580
register one option is to do bit slicing

1765
01:22:50,580 --> 01:22:53,280
uh I mean two times bit slicing on 32

1766
01:22:53,280 --> 01:22:54,239
bits

1767
01:22:54,239 --> 01:22:56,640
and you just do mask

1768
01:22:56,640 --> 01:22:59,880
um mask isw multiplication

1769
01:22:59,880 --> 01:23:02,760
the second option is okay you have two

1770
01:23:02,760 --> 01:23:05,460
independent isw multiplication you can

1771
01:23:05,460 --> 01:23:08,340
apply the shuffling shares methodology

1772
01:23:08,340 --> 01:23:10,440
on that

1773
01:23:10,440 --> 01:23:15,000
but what you can also do is to signalize

1774
01:23:15,000 --> 01:23:18,719
a bit more and not have the two I mean

1775
01:23:18,719 --> 01:23:21,659
using two times 3D register but you can

1776
01:23:21,659 --> 01:23:24,840
use less the register put 16 bit in each

1777
01:23:24,840 --> 01:23:26,940
of them and then Shuffle that so you do

1778
01:23:26,940 --> 01:23:29,640
not have a permutation on two elements

1779
01:23:29,640 --> 01:23:32,040
as here but you have a permutation on

1780
01:23:32,040 --> 01:23:34,320
four limits

1781
01:23:34,320 --> 01:23:38,040
so with this option we can I mean we

1782
01:23:38,040 --> 01:23:39,540
implemented that we've been running that

1783
01:23:39,540 --> 01:23:42,480
on I mean the implementation on got xm4

1784
01:23:42,480 --> 01:23:44,880
so we have performance number we have

1785
01:23:44,880 --> 01:23:47,820
derived the security uh with paper and

1786
01:23:47,820 --> 01:23:50,100
pencil approach and simulation according

1787
01:23:50,100 --> 01:23:52,679
to noise levels permutation size number

1788
01:23:52,679 --> 01:23:54,540
of shares and so on so we are we

1789
01:23:54,540 --> 01:23:56,580
actually have all the tools to to do all

1790
01:23:56,580 --> 01:23:58,800
the curves I was on the first side of my

1791
01:23:58,800 --> 01:24:01,080
presentation so here you have the

1792
01:24:01,080 --> 01:24:02,699
performances so the number of Cycles

1793
01:24:02,699 --> 01:24:04,620
required to do the end on one single bit

1794
01:24:04,620 --> 01:24:07,679
and here you have the the the the

1795
01:24:07,679 --> 01:24:10,380
security so each of the plus will stand

1796
01:24:10,380 --> 01:24:13,440
for different physical configuration so

1797
01:24:13,440 --> 01:24:16,140
on the last part so here is you have a

1798
01:24:16,140 --> 01:24:17,760
cheaper energy

1799
01:24:17,760 --> 01:24:19,920
and here you have a more expensive RNG

1800
01:24:19,920 --> 01:24:23,040
and on the above is you have a low noise

1801
01:24:23,040 --> 01:24:25,080
level and Below you have a highest most

1802
01:24:25,080 --> 01:24:25,980
level

1803
01:24:25,980 --> 01:24:28,260
so you can draw option one when you do

1804
01:24:28,260 --> 01:24:31,440
only masking each of the breaths

1805
01:24:31,440 --> 01:24:32,760
corresponds to a different number of

1806
01:24:32,760 --> 01:24:34,080
shares

1807
01:24:34,080 --> 01:24:36,060
then you can do

1808
01:24:36,060 --> 01:24:37,860
um masking and shuffling together for

1809
01:24:37,860 --> 01:24:39,900
the option two and then you can do

1810
01:24:39,900 --> 01:24:41,460
option three

1811
01:24:41,460 --> 01:24:44,640
so what we see not only on this setting

1812
01:24:44,640 --> 01:24:46,380
but also in all the settings we observe

1813
01:24:46,380 --> 01:24:47,640
in the paper

1814
01:24:47,640 --> 01:24:51,300
is that pushing for serialization so not

1815
01:24:51,300 --> 01:24:53,780
fully you use the register into

1816
01:24:53,780 --> 01:24:56,400
your implementation is kind of a bad

1817
01:24:56,400 --> 01:25:00,600
idea and it's systematically slower than

1818
01:25:00,600 --> 01:25:02,400
fully using a register so you should

1819
01:25:02,400 --> 01:25:06,000
yeah favor parallelism

1820
01:25:06,000 --> 01:25:07,980
that's something and then another

1821
01:25:07,980 --> 01:25:10,020
takeaway is that

1822
01:25:10,020 --> 01:25:14,040
yeah we have this kind of areas where

1823
01:25:14,040 --> 01:25:16,080
you have here the cost of the randomness

1824
01:25:16,080 --> 01:25:18,420
and here you have the noise level and

1825
01:25:18,420 --> 01:25:20,760
the question that this graph answer is

1826
01:25:20,760 --> 01:25:23,580
okay should you do masking or should you

1827
01:25:23,580 --> 01:25:26,640
do matching plus traveling and black

1828
01:25:26,640 --> 01:25:29,460
beans masking is faster I mean is the

1829
01:25:29,460 --> 01:25:31,620
most performant option for a given

1830
01:25:31,620 --> 01:25:35,219
security level so here it's uh 64 bits

1831
01:25:35,219 --> 01:25:36,239
of security

1832
01:25:36,239 --> 01:25:39,239
and security and yeah we have also as

1833
01:25:39,239 --> 01:25:40,920
parameter of the number of independent

1834
01:25:40,920 --> 01:25:42,659
ends you want to do

1835
01:25:42,659 --> 01:25:46,500
so this is for 128 uh independent ends

1836
01:25:46,500 --> 01:25:48,360
and then you can increase the number of

1837
01:25:48,360 --> 01:25:51,480
ends and the areas here change and you

1838
01:25:51,480 --> 01:25:53,460
see that it's like the air we are

1839
01:25:53,460 --> 01:25:55,320
shuffling and masking gets better

1840
01:25:55,320 --> 01:25:57,540
increases

1841
01:25:57,540 --> 01:25:59,940
so one more

1842
01:25:59,940 --> 01:26:03,420
decoy message of all our analysis is

1843
01:26:03,420 --> 01:26:05,100
that we should favor using shuffling

1844
01:26:05,100 --> 01:26:07,260
plus masking when there is a large

1845
01:26:07,260 --> 01:26:09,900
number of independent ends when the

1846
01:26:09,900 --> 01:26:12,840
randomness is relatively expensive and

1847
01:26:12,840 --> 01:26:15,480
when there is a relatively no noise of

1848
01:26:15,480 --> 01:26:17,219
course you have to put all that in

1849
01:26:17,219 --> 01:26:19,560
perspective because yeah all these

1850
01:26:19,560 --> 01:26:21,900
parameters depend on platform and so on

1851
01:26:21,900 --> 01:26:24,840
so thanks for listening uh the the code

1852
01:26:24,840 --> 01:26:27,780
for the simulation so all the the

1853
01:26:27,780 --> 01:26:31,080
gankers I've been showing earlier in

1854
01:26:31,080 --> 01:26:33,780
this presentation are available on that

1855
01:26:33,780 --> 01:26:37,519
GitHub link thanks for listening

1856
01:26:40,020 --> 01:26:42,260
foreign

1857
01:26:44,000 --> 01:26:46,620
so we do have time for a couple of

1858
01:26:46,620 --> 01:26:48,920
questions

1859
01:26:52,860 --> 01:26:54,780
um for the linear layers if I understood

1860
01:26:54,780 --> 01:26:57,020
correctly you uh

1861
01:26:57,020 --> 01:27:00,300
within the as if you add two shared

1862
01:27:00,300 --> 01:27:01,920
variables then you would use the same

1863
01:27:01,920 --> 01:27:04,139
permutation on the shares propose would

1864
01:27:04,139 --> 01:27:06,679
it change anything if you were

1865
01:27:06,679 --> 01:27:09,060
permute them differently because it

1866
01:27:09,060 --> 01:27:10,620
doesn't matter which shares you add up

1867
01:27:10,620 --> 01:27:13,739
if you can add here I didn't got your

1868
01:27:13,739 --> 01:27:16,080
question so can you repeat please

1869
01:27:16,080 --> 01:27:19,139
so you use fossil linear layers the same

1870
01:27:19,139 --> 01:27:21,960
permutation on on the shares for the if

1871
01:27:21,960 --> 01:27:24,900
you add X and Y otherwise or x i and y i

1872
01:27:24,900 --> 01:27:27,840
yeah then you use the same permutation

1873
01:27:27,840 --> 01:27:29,580
on the shares if I understood correctly

1874
01:27:29,580 --> 01:27:31,739
but you could use independent shares

1875
01:27:31,739 --> 01:27:33,900
also because it doesn't matter which of

1876
01:27:33,900 --> 01:27:36,920
the shares you add

1877
01:27:38,300 --> 01:27:40,380
yeah of course you can change anything

1878
01:27:40,380 --> 01:27:43,739
from the security uh yeah we didn't

1879
01:27:43,739 --> 01:27:46,320
explore that

1880
01:27:46,320 --> 01:27:48,719
but I guess then I mean if you use like

1881
01:27:48,719 --> 01:27:50,820
let's say tiny notion then you get yeah

1882
01:27:50,820 --> 01:27:53,760
you break some property I mean if you're

1883
01:27:53,760 --> 01:27:57,000
Pioneer it's bad but yeah I did we

1884
01:27:57,000 --> 01:27:59,520
didn't explore that

1885
01:27:59,520 --> 01:28:01,080
um

1886
01:28:01,080 --> 01:28:03,239
yeah and yeah that may be a good track

1887
01:28:03,239 --> 01:28:05,959
yeah

1888
01:28:09,780 --> 01:28:11,820
thanks for the talk

1889
01:28:11,820 --> 01:28:12,960
um

1890
01:28:12,960 --> 01:28:16,920
my question is uh did your study

1891
01:28:16,920 --> 01:28:19,880
consider leakages on the

1892
01:28:19,880 --> 01:28:23,280
permutation in itself so that's a good

1893
01:28:23,280 --> 01:28:26,880
question so essentially all the

1894
01:28:26,880 --> 01:28:30,060
older it analysis I'm shown here I done

1895
01:28:30,060 --> 01:28:32,639
without I mean we had an option in our

1896
01:28:32,639 --> 01:28:34,199
code right and we discussed that in the

1897
01:28:34,199 --> 01:28:35,699
paper so either there is some leakage on

1898
01:28:35,699 --> 01:28:37,260
the permutation either there is no

1899
01:28:37,260 --> 01:28:39,120
leakage on the permutation and

1900
01:28:39,120 --> 01:28:40,800
essentially when there is

1901
01:28:40,800 --> 01:28:45,300
I enough noise you get uh I mean it's as

1902
01:28:45,300 --> 01:28:47,040
if the adversary was not able to get the

1903
01:28:47,040 --> 01:28:48,719
permutation so it doesn't care it

1904
01:28:48,719 --> 01:28:51,300
doesn't matter the only thing is that so

1905
01:28:51,300 --> 01:28:54,360
we've been like executing some attacks

1906
01:28:54,360 --> 01:28:58,020
on real devices low noise one and

1907
01:28:58,020 --> 01:28:59,820
actually we show that we are able to

1908
01:28:59,820 --> 01:29:02,520
recover the permutation in in one Trace

1909
01:29:02,520 --> 01:29:05,159
so on these low noise devices it doesn't

1910
01:29:05,159 --> 01:29:08,219
work but that does not mean that like is

1911
01:29:08,219 --> 01:29:10,679
not impossible to do is just like as

1912
01:29:10,679 --> 01:29:12,360
usually in physical implementation you

1913
01:29:12,360 --> 01:29:13,739
have to take care of these physical

1914
01:29:13,739 --> 01:29:15,420
parameters

1915
01:29:15,420 --> 01:29:18,020
thank you

1916
01:29:20,940 --> 01:29:25,040
are there any more questions

1917
01:29:27,960 --> 01:29:30,179
okay if not then let's thank the speaker

1918
01:29:30,179 --> 01:29:32,480
again

1919
01:29:34,820 --> 01:29:38,580
and also before we are leaving for lunch

1920
01:29:38,580 --> 01:29:40,380
I would like to remind you that we also

1921
01:29:40,380 --> 01:29:42,540
have a lot of beautiful and nice posters

1922
01:29:42,540 --> 01:29:44,580
around the coffee break session and so

1923
01:29:44,580 --> 01:29:46,920
on so if you have time please take a

1924
01:29:46,920 --> 01:29:49,020
look at them talk to the people I think

1925
01:29:49,020 --> 01:29:52,159
they will appreciate it

1926
01:29:57,300 --> 01:29:59,960
just

