1
00:00:04,800 --> 00:00:12,719
it is my great honor to introduce Shafi

2
00:00:08,550 --> 00:00:15,120
Goldwasser as her image here shows she

3
00:00:12,719 --> 00:00:17,939
is currently the director of the Simon's

4
00:00:15,120 --> 00:00:20,549
instituted UC Berkeley that's the top

5
00:00:17,939 --> 00:00:23,939
one she's a professor at MIT and a

6
00:00:20,550 --> 00:00:26,610
professor at vitamin but shop she's

7
00:00:23,939 --> 00:00:29,910
Grayson is not in the places that she is

8
00:00:26,610 --> 00:00:32,910
but rather and how she's totally shaped

9
00:00:29,910 --> 00:00:34,860
our field as we know it with such

10
00:00:32,910 --> 00:00:39,449
amazing results but this is only a

11
00:00:34,860 --> 00:00:42,449
limited list of things zero knowledge

12
00:00:39,449 --> 00:00:47,480
proves information-theoretic multi-party

13
00:00:42,449 --> 00:00:50,399
computation semantic security PC peas

14
00:00:47,480 --> 00:00:53,129
multi provers and the list just goes on

15
00:00:50,399 --> 00:00:56,579
and on and on and on

16
00:00:53,129 --> 00:00:58,920
she is the 2012 Turing Award winner she

17
00:00:56,579 --> 00:01:01,320
has to get all prizes this is very rare

18
00:00:58,920 --> 00:01:04,710
there are people who have one but two is

19
00:01:01,320 --> 00:01:08,159
really very unique she's the ACM Grace

20
00:01:04,709 --> 00:01:10,110
Hopper winner RSA award she's a fellow

21
00:01:08,159 --> 00:01:12,780
of the American Academy of Arts and

22
00:01:10,110 --> 00:01:15,630
Sciences the National Academy of

23
00:01:12,780 --> 00:01:19,020
Sciences she's an ACM Fellow and she's

24
00:01:15,630 --> 00:01:25,199
also a fellow of our organization of the

25
00:01:19,020 --> 00:01:28,770
ICR which were happy in 1980 my mother

26
00:01:25,200 --> 00:01:31,950
went to a pool and met another woman in

27
00:01:28,770 --> 00:01:34,949
that pool and that woman told my mother

28
00:01:31,950 --> 00:01:38,610
that she has a daughter who is a

29
00:01:34,950 --> 00:01:39,480
graduate student at Berkeley and is very

30
00:01:38,610 --> 00:01:43,280
talented

31
00:01:39,480 --> 00:01:46,790
my mother listened but

32
00:01:43,280 --> 00:01:49,520
the truth is this was Chevy's mother of

33
00:01:46,790 --> 00:01:53,300
course but the truth is I think that

34
00:01:49,520 --> 00:01:56,300
even Chevy's mother underestimated this

35
00:01:53,300 --> 00:01:59,770
very unique extraordinary and unlimited

36
00:01:56,300 --> 00:02:03,470
talent the Chaffee has and really

37
00:01:59,770 --> 00:02:06,619
couldn't even imagine how Shafi would go

38
00:02:03,470 --> 00:02:07,160
on to change the world so please help me

39
00:02:06,620 --> 00:02:10,390
honor

40
00:02:07,160 --> 00:02:10,389
Shafi goodbye sir

41
00:02:20,100 --> 00:02:25,290
so thank you Tom for the introduction I

42
00:02:22,870 --> 00:02:27,630
have to say that my mother made

43
00:02:25,290 --> 00:02:32,049
underestimated but I also had a father

44
00:02:27,630 --> 00:02:34,359
and he was always overestimating so I

45
00:02:32,050 --> 00:02:37,390
think maybe on average maybe they got it

46
00:02:34,360 --> 00:02:39,850
right but in any case they're both gone

47
00:02:37,390 --> 00:02:41,380
but they were quite something so this is

48
00:02:39,850 --> 00:02:43,780
the second time that I'm supposed to

49
00:02:41,380 --> 00:02:44,950
give this talk and some of you know but

50
00:02:43,780 --> 00:02:47,880
this time I'm actually going to give it

51
00:02:44,950 --> 00:02:51,519
and in the meantime I managed to change

52
00:02:47,880 --> 00:02:52,960
affiliation or add an affiliation so the

53
00:02:51,520 --> 00:02:54,460
title of my talk is cryptography and

54
00:02:52,960 --> 00:02:56,740
machine learning what else so there's

55
00:02:54,460 --> 00:02:58,330
two ways to interpret this what else one

56
00:02:56,740 --> 00:03:00,460
of them is that what else do people talk

57
00:02:58,330 --> 00:03:03,310
about these days except for machine

58
00:03:00,460 --> 00:03:04,840
learning but what I mean is what else is

59
00:03:03,310 --> 00:03:07,300
there to do in addition to what people

60
00:03:04,840 --> 00:03:09,810
in the cryptography community are doing

61
00:03:07,300 --> 00:03:11,890
when machine learning is concerned and

62
00:03:09,810 --> 00:03:14,080
I've learned a tremendous amount

63
00:03:11,890 --> 00:03:15,790
preparing for this talk I'm not an

64
00:03:14,080 --> 00:03:18,730
expert in machine learning I'm an expert

65
00:03:15,790 --> 00:03:19,810
in cryptography but if you learn even a

66
00:03:18,730 --> 00:03:22,149
fraction of what I've learned in

67
00:03:19,810 --> 00:03:25,620
preparation then I think I will do a

68
00:03:22,150 --> 00:03:27,910
good job but be aware that this is a

69
00:03:25,620 --> 00:03:30,340
work in progress

70
00:03:27,910 --> 00:03:31,690
so I just want to say that this I

71
00:03:30,340 --> 00:03:34,690
actually attended the first crypto which

72
00:03:31,690 --> 00:03:36,579
was in 1981 and there's a subset of

73
00:03:34,690 --> 00:03:38,829
people here who there as well not a

74
00:03:36,580 --> 00:03:41,320
large subset but some and it was

75
00:03:38,830 --> 00:03:43,300
extremely exciting and extremely

76
00:03:41,320 --> 00:03:45,370
informal so by informal I mean both in

77
00:03:43,300 --> 00:03:46,570
the interactions between people but also

78
00:03:45,370 --> 00:03:48,220
in the type of work that people were

79
00:03:46,570 --> 00:03:49,420
doing they had great ideas and they were

80
00:03:48,220 --> 00:03:51,790
presenting them there weren't

81
00:03:49,420 --> 00:03:54,070
definitions yet aureus or in a sense

82
00:03:51,790 --> 00:03:57,160
what people agreed on what should be the

83
00:03:54,070 --> 00:04:02,560
definition but it was you know

84
00:03:57,160 --> 00:04:04,359
incredibly fruitful in in creative and

85
00:04:02,560 --> 00:04:06,070
sometimes people like to say it sort of

86
00:04:04,360 --> 00:04:08,050
was when it was art and then later maybe

87
00:04:06,070 --> 00:04:09,640
turned more into a sort of science form

88
00:04:08,050 --> 00:04:12,100
and the reason I'm mentioning that is

89
00:04:09,640 --> 00:04:15,750
because I think we're in a similar place

90
00:04:12,100 --> 00:04:18,850
in some areas of machine learning today

91
00:04:15,750 --> 00:04:20,709
so I just want to say that just to

92
00:04:18,850 --> 00:04:22,780
illustrate the fact that really crypto

93
00:04:20,709 --> 00:04:24,700
has gone a long way from being informal

94
00:04:22,780 --> 00:04:26,650
to being a part of several computer

95
00:04:24,700 --> 00:04:28,240
science that in the Simons Institute

96
00:04:26,650 --> 00:04:29,349
which is for the theory of computation

97
00:04:28,240 --> 00:04:31,120
it's an institute

98
00:04:29,350 --> 00:04:33,820
for theory computation there gonna be

99
00:04:31,120 --> 00:04:36,400
these three programs one on essentially

100
00:04:33,820 --> 00:04:37,659
data privacy maybe you can think of

101
00:04:36,400 --> 00:04:38,739
differential privacy when you think

102
00:04:37,660 --> 00:04:40,570
about data privacy but there might be

103
00:04:38,740 --> 00:04:42,430
other definitions and other semesters

104
00:04:40,570 --> 00:04:43,860
going to be about block chains and then

105
00:04:42,430 --> 00:04:46,090
a third semester is going to be about

106
00:04:43,860 --> 00:04:48,190
lattices flume amorphic encryption and

107
00:04:46,090 --> 00:04:49,929
other applications of hard problems on

108
00:04:48,190 --> 00:04:52,150
lattices so it's become really a part of

109
00:04:49,930 --> 00:04:53,680
the Reta computer science to such an

110
00:04:52,150 --> 00:04:56,739
extent that there's sort of a three

111
00:04:53,680 --> 00:04:59,740
semester continuation exploring this is

112
00:04:56,740 --> 00:05:02,260
part of theoretical science but not only

113
00:04:59,740 --> 00:05:05,710
in in fact probably this audience to

114
00:05:02,260 --> 00:05:08,530
some large extent knows all these

115
00:05:05,710 --> 00:05:12,539
consequences of cryptography on the

116
00:05:08,530 --> 00:05:15,039
world right electronic commerce with RSA

117
00:05:12,540 --> 00:05:17,050
you know cryptocurrency which are older

118
00:05:15,040 --> 00:05:18,910
age you know even quantum computing in

119
00:05:17,050 --> 00:05:21,180
some sense was really jump started

120
00:05:18,910 --> 00:05:23,140
because of peter Shor's factoring

121
00:05:21,180 --> 00:05:24,610
algorithm in a quantum computer when he

122
00:05:23,140 --> 00:05:26,710
was sort of trying to break RSA and that

123
00:05:24,610 --> 00:05:29,140
was just so fascinating and illustrated

124
00:05:26,710 --> 00:05:31,750
that the strength and power of quantum

125
00:05:29,140 --> 00:05:33,159
computers if they were built and it's

126
00:05:31,750 --> 00:05:35,380
also become a part of theoretical

127
00:05:33,160 --> 00:05:38,170
computer science as of ideas from

128
00:05:35,380 --> 00:05:39,909
cryptography have led to probablistic

129
00:05:38,170 --> 00:05:41,490
checkable proofs which essentially gave

130
00:05:39,910 --> 00:05:44,230
an NP the class NP a new definition

131
00:05:41,490 --> 00:05:45,940
pseudo random number generation so the

132
00:05:44,230 --> 00:05:48,850
impact of sort of cryptographic research

133
00:05:45,940 --> 00:05:51,730
has been incredible on the world on the

134
00:05:48,850 --> 00:05:54,520
world of theory and i guess my point in

135
00:05:51,730 --> 00:05:57,130
this line is that maybe what is sort of

136
00:05:54,520 --> 00:05:59,049
the next frontier in my opinion or n

137
00:05:57,130 --> 00:06:01,210
next frontier is really developing

138
00:05:59,050 --> 00:06:03,820
cryptography which is friendly for

139
00:06:01,210 --> 00:06:06,250
machine learning and that's kind of

140
00:06:03,820 --> 00:06:07,870
gonna be the thrust of my talk and I

141
00:06:06,250 --> 00:06:09,790
think there's which is going to be my

142
00:06:07,870 --> 00:06:13,120
ending slide but I said now for those of

143
00:06:09,790 --> 00:06:14,680
you who are just gonna taper off is that

144
00:06:13,120 --> 00:06:16,330
there are two opportunities here one

145
00:06:14,680 --> 00:06:17,860
which people are already doing and that

146
00:06:16,330 --> 00:06:18,969
is using some cryptographic machinery

147
00:06:17,860 --> 00:06:20,890
that's been developed for many many

148
00:06:18,970 --> 00:06:22,690
years okay in the space of machine

149
00:06:20,890 --> 00:06:25,000
learning but the other one probably is

150
00:06:22,690 --> 00:06:25,570
developing theory new theory for

151
00:06:25,000 --> 00:06:28,540
cryptography

152
00:06:25,570 --> 00:06:32,800
which maybe is motivated by machine

153
00:06:28,540 --> 00:06:34,570
learning applications so the outline of

154
00:06:32,800 --> 00:06:36,340
the talk is first of all there's gonna

155
00:06:34,570 --> 00:06:37,479
be some historical part which about the

156
00:06:36,340 --> 00:06:38,890
connection between machine learning

157
00:06:37,479 --> 00:06:39,669
cryptography which does not start today

158
00:06:38,890 --> 00:06:43,390
but starts

159
00:06:39,670 --> 00:06:45,130
mid-80s then I'll talk about this field

160
00:06:43,390 --> 00:06:46,570
which I'll call safe machine learning we

161
00:06:45,130 --> 00:06:48,610
could call it another name but you'll

162
00:06:46,570 --> 00:06:50,380
see where he's safe is the word I use

163
00:06:48,610 --> 00:06:53,080
when I get to it and that is sort of the

164
00:06:50,380 --> 00:06:55,300
challenges that are present today and

165
00:06:53,080 --> 00:06:57,099
the opportunities they present for

166
00:06:55,300 --> 00:06:58,900
cryptography and finally some sort of

167
00:06:57,100 --> 00:07:00,730
sampling of what is already done about

168
00:06:58,900 --> 00:07:01,659
these challenges which is no small thing

169
00:07:00,730 --> 00:07:03,490
in some sense it would have been better

170
00:07:01,660 --> 00:07:05,200
to give you the talk last year because

171
00:07:03,490 --> 00:07:06,040
there are about 50 new papers which I

172
00:07:05,200 --> 00:07:09,280
kind of had to

173
00:07:06,040 --> 00:07:12,760
please skim about the in this in this

174
00:07:09,280 --> 00:07:14,109
area within a year that is or shall I

175
00:07:12,760 --> 00:07:16,050
say that we know that to skim them and

176
00:07:14,110 --> 00:07:19,720
explain them to me that to be very

177
00:07:16,050 --> 00:07:22,870
disclosure so in any case for those of

178
00:07:19,720 --> 00:07:25,720
you who need an introduction I short one

179
00:07:22,870 --> 00:07:27,490
and that is machine learning is you know

180
00:07:25,720 --> 00:07:28,720
there's artificial intelligence machine

181
00:07:27,490 --> 00:07:30,430
learning somewhere in the intersection

182
00:07:28,720 --> 00:07:32,050
of artificial intelligence statistics

183
00:07:30,430 --> 00:07:32,710
and theoretical computer science the way

184
00:07:32,050 --> 00:07:35,430
I see it

185
00:07:32,710 --> 00:07:37,719
and if I had to give it just like a

186
00:07:35,430 --> 00:07:41,380
explanation to my mother or my father or

187
00:07:37,720 --> 00:07:44,020
or other non technical literate people I

188
00:07:41,380 --> 00:07:46,500
would say that essentially it it

189
00:07:44,020 --> 00:07:49,299
explores how to come up with algorithms

190
00:07:46,500 --> 00:07:51,670
which can essentially learn and make

191
00:07:49,300 --> 00:07:54,070
predictions on data without explicitly

192
00:07:51,670 --> 00:07:56,230
programming these algorithms so without

193
00:07:54,070 --> 00:07:58,000
writing the algorithm somehow the

194
00:07:56,230 --> 00:08:00,900
algorithm will emerge from the data and

195
00:07:58,000 --> 00:08:04,450
then can be used to make predictions on

196
00:08:00,900 --> 00:08:06,940
future data that we may encounter okay

197
00:08:04,450 --> 00:08:08,440
so essentially there are lots of machine

198
00:08:06,940 --> 00:08:10,780
learning models we'll talk about a few

199
00:08:08,440 --> 00:08:12,310
of them here in this talk but regardless

200
00:08:10,780 --> 00:08:13,450
of how you look at it it seems like they

201
00:08:12,310 --> 00:08:16,390
all have two phases

202
00:08:13,450 --> 00:08:18,130
phase one is called usually the learning

203
00:08:16,390 --> 00:08:19,870
or training so I'm gonna use those terms

204
00:08:18,130 --> 00:08:21,400
again and again learning or training and

205
00:08:19,870 --> 00:08:24,010
what happens then is you're given some

206
00:08:21,400 --> 00:08:27,130
samples of input so and you call this

207
00:08:24,010 --> 00:08:28,690
training data these are our input which

208
00:08:27,130 --> 00:08:30,190
are usually labeled so there's one for

209
00:08:28,690 --> 00:08:32,260
some notion like if it's a picture that

210
00:08:30,190 --> 00:08:35,380
there's a cat in it or dog or giraffe or

211
00:08:32,260 --> 00:08:38,229
if it's a bank loan if it's a feature

212
00:08:35,380 --> 00:08:41,919
vector that describes an applicant to a

213
00:08:38,229 --> 00:08:43,420
bank for a house loan then it might be

214
00:08:41,919 --> 00:08:44,770
labeled by let's grant the loan or not

215
00:08:43,419 --> 00:08:46,630
grant alone okay

216
00:08:44,770 --> 00:08:48,760
or it might be labeled by I'm gonna

217
00:08:46,630 --> 00:08:49,960
grant a loan of a certain level and so

218
00:08:48,760 --> 00:08:52,649
forth okay so the some notion of an

219
00:08:49,960 --> 00:08:55,060
input which describes

220
00:08:52,649 --> 00:08:56,620
usually is a vector of features and then

221
00:08:55,060 --> 00:08:59,380
there's a label sort of a decision about

222
00:08:56,620 --> 00:09:01,480
that input and it's drawn from some

223
00:08:59,380 --> 00:09:03,339
unknown distribution really

224
00:09:01,480 --> 00:09:04,810
so let's explicitly call this

225
00:09:03,339 --> 00:09:07,750
distribution lead is these gonna come up

226
00:09:04,810 --> 00:09:09,939
again and again and what the machine

227
00:09:07,750 --> 00:09:12,279
learning should do in the first phase is

228
00:09:09,940 --> 00:09:13,959
generate some sort of hypothesis about

229
00:09:12,279 --> 00:09:15,339
this data has been seen sometimes it's

230
00:09:13,959 --> 00:09:17,529
called hypothesis sometimes it's called

231
00:09:15,339 --> 00:09:18,459
a model these days it's called model in

232
00:09:17,529 --> 00:09:20,680
the eighties we call the nine processes

233
00:09:18,459 --> 00:09:23,768
and what do you do with this I practices

234
00:09:20,680 --> 00:09:25,479
so what you do with this hypothesis is

235
00:09:23,769 --> 00:09:28,060
the phase two and you may do different

236
00:09:25,480 --> 00:09:30,370
things so I enlisted three things here

237
00:09:28,060 --> 00:09:33,189
you may essentially use this hypothesis

238
00:09:30,370 --> 00:09:34,690
two next time when you get a new piece

239
00:09:33,190 --> 00:09:37,959
of data and not part of the training

240
00:09:34,690 --> 00:09:39,339
data you will assign it's like a feature

241
00:09:37,959 --> 00:09:40,479
vector again in the examples that we

242
00:09:39,339 --> 00:09:42,760
talked about a picture that may have a

243
00:09:40,480 --> 00:09:44,740
dog or a cat or a giraffe a feature of

244
00:09:42,760 --> 00:09:46,120
someone applying for a loan and you're

245
00:09:44,740 --> 00:09:48,310
going to use their part hypothesis from

246
00:09:46,120 --> 00:09:51,910
the first phase to this make a decision

247
00:09:48,310 --> 00:09:53,890
on this new data another thing you could

248
00:09:51,910 --> 00:09:55,269
do is actually not worry about not in be

249
00:09:53,890 --> 00:09:57,130
interested classification maybe you want

250
00:09:55,269 --> 00:09:58,750
to just generate new data which is

251
00:09:57,130 --> 00:10:00,339
similar to the data that you've seen in

252
00:09:58,750 --> 00:10:02,020
the past there's something about this

253
00:10:00,339 --> 00:10:04,180
distribution you don't know exactly you

254
00:10:02,020 --> 00:10:06,220
would like to come up with an maybe

255
00:10:04,180 --> 00:10:09,399
distribution D prime which is hard to

256
00:10:06,220 --> 00:10:10,810
distinguish from D okay and a third

257
00:10:09,399 --> 00:10:11,350
thing you may want to do is just explain

258
00:10:10,810 --> 00:10:13,270
the data

259
00:10:11,350 --> 00:10:14,980
so you just you've seen all this data

260
00:10:13,270 --> 00:10:17,319
you don't necessarily want to predict

261
00:10:14,980 --> 00:10:19,690
new data or generate new data but you

262
00:10:17,320 --> 00:10:21,490
want to understand it so if it's a

263
00:10:19,690 --> 00:10:22,899
distribution let's think of it let's say

264
00:10:21,490 --> 00:10:24,370
it's a geometric distribution you want

265
00:10:22,899 --> 00:10:25,450
to know sort of what the parameters are

266
00:10:24,370 --> 00:10:26,980
it's Bernoulli you want to know what the

267
00:10:25,450 --> 00:10:28,839
probability of flipping at the coin is

268
00:10:26,980 --> 00:10:30,760
and so forth so this is the way I see

269
00:10:28,839 --> 00:10:32,260
that there are these three tasks that

270
00:10:30,760 --> 00:10:35,110
people are working on classification

271
00:10:32,260 --> 00:10:36,310
generation and explanation okay and no

272
00:10:35,110 --> 00:10:39,399
matter which model we're talking about

273
00:10:36,310 --> 00:10:40,359
these are sort of the two phases so I'm

274
00:10:39,399 --> 00:10:42,070
not trying to put you to sleep

275
00:10:40,360 --> 00:10:42,850
I know most people know this but you

276
00:10:42,070 --> 00:10:47,020
know I'm just trying to put you in a

277
00:10:42,850 --> 00:10:48,850
good mood a so in any case so let's be a

278
00:10:47,020 --> 00:10:50,680
little bit more concrete so say there is

279
00:10:48,850 --> 00:10:53,980
this black box and in it there is a

280
00:10:50,680 --> 00:10:55,510
formula okay let's say it's a DNF so it

281
00:10:53,980 --> 00:10:58,149
looks like that's a formula in three

282
00:10:55,510 --> 00:11:02,079
variables and it's an a it's an or event

283
00:10:58,149 --> 00:11:03,300
okay in this particular formula a and

284
00:11:02,079 --> 00:11:06,149
you know

285
00:11:03,300 --> 00:11:08,370
that you could feed in you know X the X

286
00:11:06,149 --> 00:11:09,420
1 X 2 X 3 an outcome an output but you

287
00:11:08,370 --> 00:11:11,670
don't know exactly what the formula

288
00:11:09,420 --> 00:11:13,890
looks like this formula is extremely

289
00:11:11,670 --> 00:11:16,349
expressive you know you could say that

290
00:11:13,890 --> 00:11:18,449
it could be X 1 X 2 X 3 could be pixels

291
00:11:16,350 --> 00:11:19,890
or some sort of something that's been

292
00:11:18,450 --> 00:11:22,050
analyzed by a doctor to tell you whether

293
00:11:19,890 --> 00:11:24,899
a picture of a tumor is malignant or not

294
00:11:22,050 --> 00:11:26,459
it could be a bank loan which should be

295
00:11:24,899 --> 00:11:30,480
approved if a suspect should be released

296
00:11:26,459 --> 00:11:32,810
on bail or whether an email is spam or

297
00:11:30,480 --> 00:11:34,860
not okay so this is extremely expressive

298
00:11:32,810 --> 00:11:37,829
so obviously being that it's so

299
00:11:34,860 --> 00:11:40,860
expressive won't it be wonderful that we

300
00:11:37,829 --> 00:11:41,969
could learn how we could learn see it's

301
00:11:40,860 --> 00:11:43,800
hidden in a box I don't know exactly

302
00:11:41,970 --> 00:11:45,540
what they do with X 1 X 2 X 3 so at the

303
00:11:43,800 --> 00:11:49,099
end they can give you me these correct

304
00:11:45,540 --> 00:11:52,290
answers so I'd love to learn how C works

305
00:11:49,100 --> 00:11:55,140
but that might be pretty hard so how

306
00:11:52,290 --> 00:11:57,029
hard is it so in order to detail talk

307
00:11:55,140 --> 00:11:58,529
about this even theoretically informally

308
00:11:57,029 --> 00:12:00,149
we need to really define what does it

309
00:11:58,529 --> 00:12:03,329
mean to successfully learn something to

310
00:12:00,149 --> 00:12:04,500
successfully learn this box and what

311
00:12:03,329 --> 00:12:07,050
information is actually made available

312
00:12:04,500 --> 00:12:08,490
to me about this hidden C is it just

313
00:12:07,050 --> 00:12:10,319
that it's locked in a box and I see

314
00:12:08,490 --> 00:12:12,209
examples can I ask it questions which is

315
00:12:10,320 --> 00:12:14,070
called membership queries maybe I can

316
00:12:12,209 --> 00:12:15,989
even see like some information would

317
00:12:14,070 --> 00:12:17,190
leak about it maybe I could specify some

318
00:12:15,990 --> 00:12:20,640
of the variables and see the entire

319
00:12:17,190 --> 00:12:23,850
concept there's many different types of

320
00:12:20,640 --> 00:12:25,890
access you may think of and in 84

321
00:12:23,850 --> 00:12:27,510
there's a fundamental paper by less

322
00:12:25,890 --> 00:12:29,430
valiant called the theory of the learner

323
00:12:27,510 --> 00:12:31,020
Bo where he introduced a formal

324
00:12:29,430 --> 00:12:33,180
definition what he means is successful

325
00:12:31,020 --> 00:12:35,310
learn this definition incorporates

326
00:12:33,180 --> 00:12:36,270
complexity theory so it talks concretely

327
00:12:35,310 --> 00:12:39,029
about complexity theory and

328
00:12:36,270 --> 00:12:40,770
probabilities okay and this is a

329
00:12:39,029 --> 00:12:42,689
beautiful kind of anchoring place to

330
00:12:40,770 --> 00:12:45,959
look at in terms of how would you go

331
00:12:42,690 --> 00:12:49,890
about defining success and failure and

332
00:12:45,959 --> 00:12:52,170
so forth so this is the definition and

333
00:12:49,890 --> 00:12:52,890
it essentially says given these training

334
00:12:52,170 --> 00:12:54,719
examples

335
00:12:52,890 --> 00:12:56,850
according drawn according to some

336
00:12:54,720 --> 00:12:59,279
unknown distribution he would say that a

337
00:12:56,850 --> 00:13:02,970
learning algorithm was successful okay

338
00:12:59,279 --> 00:13:06,839
if it approximately and probabilistic Li

339
00:13:02,970 --> 00:13:08,810
a sorry if you generated a hypothesis

340
00:13:06,839 --> 00:13:11,010
which agrees with the real concept

341
00:13:08,810 --> 00:13:12,510
approximately with high probability so

342
00:13:11,010 --> 00:13:14,370
there's sort of double hedging here he

343
00:13:12,510 --> 00:13:16,110
says you know I only want with high

344
00:13:14,370 --> 00:13:16,500
probability and you know I don't want to

345
00:13:16,110 --> 00:13:19,590
be

346
00:13:16,500 --> 00:13:20,730
just has to agree most of the time and

347
00:13:19,590 --> 00:13:22,950
he specifies the parameters epsilon

348
00:13:20,730 --> 00:13:25,620
Delta great and efficient means born all

349
00:13:22,950 --> 00:13:27,450
the time following in what in end the

350
00:13:25,620 --> 00:13:28,950
length of the input and the size of the

351
00:13:27,450 --> 00:13:30,480
description of the concept so it allows

352
00:13:28,950 --> 00:13:32,250
us time to run in a size a description

353
00:13:30,480 --> 00:13:35,430
of the concept great so that's a

354
00:13:32,250 --> 00:13:37,260
definition and in the original paper I

355
00:13:35,430 --> 00:13:38,579
think violence is very optimistic you

356
00:13:37,260 --> 00:13:39,900
know so he first of all he shows a bunch

357
00:13:38,580 --> 00:13:42,690
of positive results you know for

358
00:13:39,900 --> 00:13:45,720
monotone DNA formulas some other classes

359
00:13:42,690 --> 00:13:48,210
fairly small simple classes and it kind

360
00:13:45,720 --> 00:13:52,020
of list if you read it today it seems

361
00:13:48,210 --> 00:13:53,850
like he's more he's optimistic optimism

362
00:13:52,020 --> 00:13:55,770
is good yeah so in any case as far as

363
00:13:53,850 --> 00:13:57,720
DNF which he already defines is an open

364
00:13:55,770 --> 00:13:59,699
problem in his paper it took many many

365
00:13:57,720 --> 00:14:03,120
years for some progress to be done in

366
00:13:59,700 --> 00:14:05,160
can i summarize here what what has you

367
00:14:03,120 --> 00:14:07,680
know you know it's np-hard in general

368
00:14:05,160 --> 00:14:10,709
case if you are requiring that not only

369
00:14:07,680 --> 00:14:12,270
did i come up with a description an h

370
00:14:10,710 --> 00:14:14,160
and hypothesis that describes what

371
00:14:12,270 --> 00:14:17,040
happens in the box but this hypothesis

372
00:14:14,160 --> 00:14:18,300
is also the DN f but if you say you know

373
00:14:17,040 --> 00:14:19,589
what i don't care that it's a diene if

374
00:14:18,300 --> 00:14:21,270
it could be another thing some other

375
00:14:19,590 --> 00:14:23,780
algorithm expressed in some other model

376
00:14:21,270 --> 00:14:26,689
then we can make some headway and

377
00:14:23,780 --> 00:14:29,430
essentially the best algorithm know

378
00:14:26,690 --> 00:14:33,980
speaking of headway is to to the cubic

379
00:14:29,430 --> 00:14:36,120
root of n that if you furthermore

380
00:14:33,980 --> 00:14:37,230
restrict the distribution to be a

381
00:14:36,120 --> 00:14:38,640
distribution like the uniform

382
00:14:37,230 --> 00:14:41,580
distribution you can do a little bit

383
00:14:38,640 --> 00:14:43,439
better a n to the power log in and if

384
00:14:41,580 --> 00:14:44,820
you further say that the distribution is

385
00:14:43,440 --> 00:14:46,100
uniform and you're allowed to ask

386
00:14:44,820 --> 00:14:50,250
questions you're allowed to ask

387
00:14:46,100 --> 00:14:52,770
membership queries then Jackson in 94 a

388
00:14:50,250 --> 00:14:54,330
about ten years later showed how to do

389
00:14:52,770 --> 00:14:56,970
this in polynomial time so here we have

390
00:14:54,330 --> 00:14:58,140
one type of class DNF so k and this is

391
00:14:56,970 --> 00:14:59,370
the progress that's been done over the

392
00:14:58,140 --> 00:15:00,689
years and there's an extensive effort

393
00:14:59,370 --> 00:15:01,260
still for people to understand this

394
00:15:00,690 --> 00:15:04,710
problem

395
00:15:01,260 --> 00:15:09,960
so all this talks about machine learning

396
00:15:04,710 --> 00:15:11,220
we are in crypto 2018 not 17 ok so uh so

397
00:15:09,960 --> 00:15:13,020
where does the history of cryptography

398
00:15:11,220 --> 00:15:15,930
and machine learning starts so it really

399
00:15:13,020 --> 00:15:18,569
starts fairly soon after valiant comes

400
00:15:15,930 --> 00:15:20,099
up with this paper and because he asked

401
00:15:18,570 --> 00:15:22,320
a question whether it was in the paper

402
00:15:20,100 --> 00:15:24,750
or it was informally a question that he

403
00:15:22,320 --> 00:15:26,069
asked Ron that's why I have here

404
00:15:24,750 --> 00:15:27,600
there's Harvard we're valiant was

405
00:15:26,069 --> 00:15:29,670
sitting and there's a mighty what Ron

406
00:15:27,600 --> 00:15:31,529
was sitting and there was Michael Kern's

407
00:15:29,670 --> 00:15:32,759
who was walking between the two places I

408
00:15:31,529 --> 00:15:34,500
think he was a graduate student here and

409
00:15:32,759 --> 00:15:37,470
he went to do a postdoc with Ron at MIT

410
00:15:34,500 --> 00:15:39,930
so the question came up in can we okay

411
00:15:37,470 --> 00:15:41,220
DNF maybe we can learn other models we

412
00:15:39,930 --> 00:15:42,930
can learn can we show that there's

413
00:15:41,220 --> 00:15:45,050
something we cannot learn so there is

414
00:15:42,930 --> 00:15:46,739
something in a box that has a polynomial

415
00:15:45,050 --> 00:15:48,959
representation maybe even a simple

416
00:15:46,740 --> 00:15:51,060
representation but we probably cannot

417
00:15:48,959 --> 00:15:52,859
learn it because its complexity series

418
00:15:51,060 --> 00:15:56,069
you know we kind of want to know the

419
00:15:52,860 --> 00:15:58,139
bounds of where we're working on and in

420
00:15:56,069 --> 00:16:00,569
fact there is a series of results the

421
00:15:58,139 --> 00:16:02,550
first one is by Valentin currents which

422
00:16:00,569 --> 00:16:03,810
show that if are say secure so if

423
00:16:02,550 --> 00:16:06,719
factoring is hard with me also is

424
00:16:03,810 --> 00:16:09,000
another a candidate then yes there is

425
00:16:06,720 --> 00:16:11,910
some concept okay that cannot be packed

426
00:16:09,000 --> 00:16:13,620
learn about okay and the proof is if you

427
00:16:11,910 --> 00:16:15,300
think simple essentially what is the

428
00:16:13,620 --> 00:16:17,100
what are the examples it's an RSA

429
00:16:15,300 --> 00:16:19,589
encryption with the marshals in the

430
00:16:17,100 --> 00:16:21,509
exponent and the labels maybe the listen

431
00:16:19,589 --> 00:16:24,629
if can--but over the exes means that you

432
00:16:21,509 --> 00:16:26,810
see X to the M RN and we know that this

433
00:16:24,629 --> 00:16:30,000
is as hard as essentially breaking RSA

434
00:16:26,810 --> 00:16:32,160
so here we have a model which if R says

435
00:16:30,000 --> 00:16:33,389
heart cannot be packed learn about but

436
00:16:32,160 --> 00:16:35,610
what about if we could ask membership

437
00:16:33,389 --> 00:16:36,870
queries then there is a sort of a formal

438
00:16:35,610 --> 00:16:38,370
treatment even though informally sort of

439
00:16:36,870 --> 00:16:40,350
people understood this by pitting

440
00:16:38,370 --> 00:16:41,970
warmoth where they say you know what if

441
00:16:40,350 --> 00:16:43,699
you have a pseudo-random function okay

442
00:16:41,970 --> 00:16:46,110
based on whatever assumption that you do

443
00:16:43,699 --> 00:16:46,979
then you can ask questions and we know

444
00:16:46,110 --> 00:16:49,500
that even though you can ask questions

445
00:16:46,980 --> 00:16:51,300
you cannot compute the label or the

446
00:16:49,500 --> 00:16:53,160
value of the server on the function on

447
00:16:51,300 --> 00:16:55,199
another X so that's another kind of

448
00:16:53,160 --> 00:16:56,939
immediate result you get and what does

449
00:16:55,199 --> 00:16:58,079
it mean well that the more efficient

450
00:16:56,939 --> 00:16:59,759
your implementation of the pseudo-random

451
00:16:58,079 --> 00:17:01,349
function the more it implies that

452
00:16:59,759 --> 00:17:02,939
they're lower complexity levels where

453
00:17:01,350 --> 00:17:04,470
this maybe this thing hidden in a box

454
00:17:02,939 --> 00:17:06,500
and be computer extremely quickly and

455
00:17:04,470 --> 00:17:10,620
still this doesn't mean that you can

456
00:17:06,500 --> 00:17:12,119
necessarily learn it because this shows

457
00:17:10,619 --> 00:17:14,099
that there are such concepts which you

458
00:17:12,119 --> 00:17:15,739
cannot and then there's lots of other

459
00:17:14,099 --> 00:17:18,599
results some of them I was involved in

460
00:17:15,740 --> 00:17:19,859
which essentially showed that the the

461
00:17:18,599 --> 00:17:21,149
more weak let's say we think it's a

462
00:17:19,859 --> 00:17:22,559
random function and we make it

463
00:17:21,150 --> 00:17:24,689
constrained like the last talk was

464
00:17:22,559 --> 00:17:26,280
talking about that is you make it so

465
00:17:24,689 --> 00:17:27,630
that you have a key that allows you to

466
00:17:26,280 --> 00:17:29,158
compute the function of some inputs or

467
00:17:27,630 --> 00:17:30,330
not on other inputs in a sense you can

468
00:17:29,159 --> 00:17:32,280
think of this as I even give you a

469
00:17:30,330 --> 00:17:35,600
partial description of the of the morrow

470
00:17:32,280 --> 00:17:39,678
that's hidden in a box okay and yet

471
00:17:35,600 --> 00:17:42,770
you cannot learn a the model on any

472
00:17:39,679 --> 00:17:44,660
other values okay so in any case there's

473
00:17:42,770 --> 00:17:46,460
in some sense every time that we have a

474
00:17:44,660 --> 00:17:48,710
cryptographic construction and the more

475
00:17:46,460 --> 00:17:50,510
powerful we let the adversary be and we

476
00:17:48,710 --> 00:17:51,830
still show security in some sense it's

477
00:17:50,510 --> 00:17:53,780
like saying let the machine learning

478
00:17:51,830 --> 00:17:57,740
algorithm have more and more power still

479
00:17:53,780 --> 00:17:59,330
they can't do it okay so the thing is so

480
00:17:57,740 --> 00:18:01,460
far I just talked about the difficulty

481
00:17:59,330 --> 00:18:03,860
of classification right because you have

482
00:18:01,460 --> 00:18:05,419
some current examples you want to give

483
00:18:03,860 --> 00:18:07,340
it a label of plus or minus what about

484
00:18:05,419 --> 00:18:08,270
generation so those of you who maybe

485
00:18:07,340 --> 00:18:09,408
have seen you know there are these

486
00:18:08,270 --> 00:18:12,168
beautiful papers coming out of Google

487
00:18:09,409 --> 00:18:13,909
brain or whatever where they say we can

488
00:18:12,169 --> 00:18:14,750
come up with we see lots of cats now

489
00:18:13,909 --> 00:18:16,549
we're going to come up with lots of

490
00:18:14,750 --> 00:18:20,059
artificial cats that is we generate new

491
00:18:16,549 --> 00:18:21,980
cats I'm not really new cats but

492
00:18:20,059 --> 00:18:24,678
pictures of new cats or new dogs or new

493
00:18:21,980 --> 00:18:26,690
drafts or maybe successful college

494
00:18:24,679 --> 00:18:28,039
essays or CVS that will get you a job or

495
00:18:26,690 --> 00:18:30,409
slides for keynote talk that would be

496
00:18:28,039 --> 00:18:31,700
good or plays my Shakespeare you know

497
00:18:30,409 --> 00:18:33,020
maybe we could just see a lot of

498
00:18:31,700 --> 00:18:35,140
examples and now we're going to generate

499
00:18:33,020 --> 00:18:38,299
something that looks indistinguishable

500
00:18:35,140 --> 00:18:41,030
so this sort of idea has been defined

501
00:18:38,299 --> 00:18:44,900
actually before this current sort of

502
00:18:41,030 --> 00:18:45,908
success with cats and so forth by

503
00:18:44,900 --> 00:18:52,370
currents

504
00:18:45,909 --> 00:18:54,890
Monsoor Rubenfeld a horn a Sally and

505
00:18:52,370 --> 00:18:56,090
Shapiro and there are in fact they

506
00:18:54,890 --> 00:18:57,710
define it formally there's a

507
00:18:56,090 --> 00:18:59,059
distribution in a box you can get

508
00:18:57,710 --> 00:19:00,770
samples you can press the button get

509
00:18:59,059 --> 00:19:02,000
samples of cats if you like it to think

510
00:19:00,770 --> 00:19:03,408
of cats I don't know this is the

511
00:19:02,000 --> 00:19:05,990
obsession of cats I don't even like cats

512
00:19:03,409 --> 00:19:09,140
but let's say dogs there is there is a

513
00:19:05,990 --> 00:19:11,480
there is a you can get lots of dogs and

514
00:19:09,140 --> 00:19:15,559
now you'd like to come up with your own

515
00:19:11,480 --> 00:19:16,700
a small algorithm which generates things

516
00:19:15,559 --> 00:19:18,620
which you cannot be distinguish between

517
00:19:16,700 --> 00:19:20,030
the original distribution and your

518
00:19:18,620 --> 00:19:20,989
distribution and of course there's the

519
00:19:20,030 --> 00:19:23,149
question of how you define that you

520
00:19:20,990 --> 00:19:24,860
cannot distinguish okay is it a no is it

521
00:19:23,150 --> 00:19:26,179
your model that cannot distinguish is

522
00:19:24,860 --> 00:19:29,479
any formal time algorithm they cannot

523
00:19:26,179 --> 00:19:32,120
distinguish I will leave that aside but

524
00:19:29,480 --> 00:19:33,559
even that you know we could show in fact

525
00:19:32,120 --> 00:19:35,239
some paper by now or which is more

526
00:19:33,559 --> 00:19:36,350
sophisticated what I'm saying is but

527
00:19:35,240 --> 00:19:38,210
essentially saying that if there are

528
00:19:36,350 --> 00:19:40,399
digital signatures which are secured

529
00:19:38,210 --> 00:19:42,490
against chosen message attack then there

530
00:19:40,400 --> 00:19:44,840
exists a family distribution which are

531
00:19:42,490 --> 00:19:47,059
hard to generate okay

532
00:19:44,840 --> 00:19:48,340
but even though you can actually in some

533
00:19:47,059 --> 00:19:50,230
sense recognize the

534
00:19:48,340 --> 00:19:52,090
distribution as valid so there's some

535
00:19:50,230 --> 00:19:53,890
notion of evaluating the distribution is

536
00:19:52,090 --> 00:19:55,270
correct or incorrect even evaluating the

537
00:19:53,890 --> 00:19:57,490
probability that something comes up and

538
00:19:55,270 --> 00:19:59,289
he shows a special signature scheme

539
00:19:57,490 --> 00:20:01,510
where it which violates the ability to

540
00:19:59,289 --> 00:20:02,890
do it for this particular thing concept

541
00:20:01,510 --> 00:20:06,970
defined by the signature scheme all

542
00:20:02,890 --> 00:20:08,529
right so so far it looks like what's

543
00:20:06,970 --> 00:20:11,940
cryptography done for machine learning

544
00:20:08,529 --> 00:20:16,510
it's told them what they cannot do okay

545
00:20:11,940 --> 00:20:18,340
well something and in fact they a

546
00:20:16,510 --> 00:20:19,658
machine learning has sort of returned

547
00:20:18,340 --> 00:20:26,189
the favor in spades

548
00:20:19,659 --> 00:20:27,870
in a paper in 93 by Lipton Blum and

549
00:20:26,190 --> 00:20:32,080
blankie

550
00:20:27,870 --> 00:20:33,668
Lipton Blum to others they introduced

551
00:20:32,080 --> 00:20:35,320
the problem called learning parity with

552
00:20:33,669 --> 00:20:37,210
noise so they actually write explicitly

553
00:20:35,320 --> 00:20:39,490
in their paper if you look it up they

554
00:20:37,210 --> 00:20:41,049
say you know modern cryptography has had

555
00:20:39,490 --> 00:20:42,130
considerable impact in the development

556
00:20:41,049 --> 00:20:44,529
of computational learning theory

557
00:20:42,130 --> 00:20:45,640
virtually every intractability result in

558
00:20:44,529 --> 00:20:47,409
valiance model comes from some

559
00:20:45,640 --> 00:20:49,840
cryptographic hardness so now we're

560
00:20:47,409 --> 00:20:51,010
saying we're gonna give back because

561
00:20:49,840 --> 00:20:52,959
what we're going to do is we're going to

562
00:20:51,010 --> 00:20:54,640
give results in the reverse direction by

563
00:20:52,960 --> 00:20:57,250
showing how to construct cryptography

564
00:20:54,640 --> 00:20:58,870
from some assumptions on the difficulty

565
00:20:57,250 --> 00:21:01,029
of learning okay so they're saying

566
00:20:58,870 --> 00:21:02,979
here's a problem that we have focused on

567
00:21:01,029 --> 00:21:04,510
in the learning theory okay it's so

568
00:21:02,980 --> 00:21:07,510
natural for learning people to look at

569
00:21:04,510 --> 00:21:10,059
and we claim that you can use that as a

570
00:21:07,510 --> 00:21:11,408
core for building crypto systems so

571
00:21:10,059 --> 00:21:13,379
what's the problem the problem is this

572
00:21:11,409 --> 00:21:16,419
you've got a bunch of equations in

573
00:21:13,380 --> 00:21:18,820
variables sorry they're all SS secrets

574
00:21:16,419 --> 00:21:21,039
or X's well there should be either OSS

575
00:21:18,820 --> 00:21:22,510
or all XS but I think depending on when

576
00:21:21,039 --> 00:21:24,250
I was working on the talk I'm I've

577
00:21:22,510 --> 00:21:26,890
changed my mind in any case there are

578
00:21:24,250 --> 00:21:27,940
these secret variables s1 through SN we

579
00:21:26,890 --> 00:21:29,710
don't know what they are they're binary

580
00:21:27,940 --> 00:21:31,450
it's a binary vector we've got some

581
00:21:29,710 --> 00:21:33,970
equations in these but in these

582
00:21:31,450 --> 00:21:35,289
variables the thing is if we really did

583
00:21:33,970 --> 00:21:37,149
have equations we could do Gaussian

584
00:21:35,289 --> 00:21:38,830
elimination find this secrets but we

585
00:21:37,149 --> 00:21:40,299
don't have it with noise equation what

586
00:21:38,830 --> 00:21:41,710
does that mean it means that we take the

587
00:21:40,299 --> 00:21:45,639
value of the equation we flip it with

588
00:21:41,710 --> 00:21:48,159
some probability row and and that's what

589
00:21:45,640 --> 00:21:49,600
you see you see the coefficients you see

590
00:21:48,159 --> 00:21:51,130
the answers noise the answers here and

591
00:21:49,600 --> 00:21:53,080
you don't see the variables and that's

592
00:21:51,130 --> 00:21:56,500
your goal to come up with s1 through SN

593
00:21:53,080 --> 00:21:58,010
so here is a problem beautifully clearly

594
00:21:56,500 --> 00:21:59,510
stated problem of course

595
00:21:58,010 --> 00:22:01,790
becomes easier or harder depending on

596
00:21:59,510 --> 00:22:04,310
this noise so it you know the closer it

597
00:22:01,790 --> 00:22:05,750
is to have the harder it is right if

598
00:22:04,310 --> 00:22:07,159
it's a but they define it the constant

599
00:22:05,750 --> 00:22:08,420
probability if it let's say with

600
00:22:07,160 --> 00:22:12,080
probability 1/3 or something like that

601
00:22:08,420 --> 00:22:13,640
and insurance some cryptographic

602
00:22:12,080 --> 00:22:14,750
constructions based on them which I'll

603
00:22:13,640 --> 00:22:16,100
talk about in a minute but what do we

604
00:22:14,750 --> 00:22:17,630
know about this problem really

605
00:22:16,100 --> 00:22:18,800
you know there's our say that says based

606
00:22:17,630 --> 00:22:20,180
on factoring has been around for a long

607
00:22:18,800 --> 00:22:22,909
time what do we know about this problem

608
00:22:20,180 --> 00:22:25,760
well we know is it since 93 the best

609
00:22:22,910 --> 00:22:27,440
algorithm known it runs in time to to

610
00:22:25,760 --> 00:22:29,150
the order n over log in essentially

611
00:22:27,440 --> 00:22:33,020
exponential and this was a breakthrough

612
00:22:29,150 --> 00:22:34,700
because exponential was trivial and it

613
00:22:33,020 --> 00:22:37,610
took many many years this is work by

614
00:22:34,700 --> 00:22:41,470
rocker ski Ruby on ski by connect Nathan

615
00:22:37,610 --> 00:22:43,969
and Wix to show more cryptographic like

616
00:22:41,470 --> 00:22:45,350
properties of this function and what

617
00:22:43,970 --> 00:22:48,080
they showed is on a worst case to

618
00:22:45,350 --> 00:22:50,689
average reduction but with very very

619
00:22:48,080 --> 00:22:52,760
high noise so this was not really a

620
00:22:50,690 --> 00:22:54,770
constant noise but pretty close to 1/2

621
00:22:52,760 --> 00:22:57,500
okay but so saying when the problem is

622
00:22:54,770 --> 00:22:59,240
really hard okay we can show worst case

623
00:22:57,500 --> 00:23:01,880
to average which worst case problem

624
00:22:59,240 --> 00:23:04,280
actually not such a hard problem so in

625
00:23:01,880 --> 00:23:05,750
some sense you know the noise it makes

626
00:23:04,280 --> 00:23:06,980
it a very hard problem and the

627
00:23:05,750 --> 00:23:08,840
equivalence is to an easy

628
00:23:06,980 --> 00:23:10,820
worst-case problem but it's something

629
00:23:08,840 --> 00:23:13,070
because it's taken a very long time to

630
00:23:10,820 --> 00:23:19,720
show anything okay

631
00:23:13,070 --> 00:23:21,860
now the biggest real revolutionary

632
00:23:19,720 --> 00:23:23,300
implication of introducing this learning

633
00:23:21,860 --> 00:23:25,969
parity with noise comes with this work

634
00:23:23,300 --> 00:23:28,550
of reggae of in 2005 because leg-up says

635
00:23:25,970 --> 00:23:32,240
you know what forget about P equal to 2

636
00:23:28,550 --> 00:23:35,690
over working over boolean secrets let's

637
00:23:32,240 --> 00:23:38,210
go and work on the field in zqn here so

638
00:23:35,690 --> 00:23:41,540
everything is mod Q we take our integers

639
00:23:38,210 --> 00:23:43,880
and Z all are our variables are MZ q are

640
00:23:41,540 --> 00:23:45,649
coefficients of MZ q and the noise is no

641
00:23:43,880 --> 00:23:47,720
longer flipping because we have an

642
00:23:45,650 --> 00:23:49,250
element in Z Q so let's add Gaussian

643
00:23:47,720 --> 00:23:52,370
noise it's some sort of bounded

644
00:23:49,250 --> 00:23:53,360
intervals small Gaussian noise okay and

645
00:23:52,370 --> 00:23:54,620
he says you know what this problem

646
00:23:53,360 --> 00:23:56,209
generalized the previous one

647
00:23:54,620 --> 00:23:58,610
right because code Q just went from 2 to

648
00:23:56,210 --> 00:24:00,980
something larger boolean went to

649
00:23:58,610 --> 00:24:03,320
Gaussian what about this problem well

650
00:24:00,980 --> 00:24:05,240
it's certainly not any easier ok

651
00:24:03,320 --> 00:24:07,460
the thing is that now we can start

652
00:24:05,240 --> 00:24:09,329
working so what rag of shows in his

653
00:24:07,460 --> 00:24:11,609
original paper is that this

654
00:24:09,329 --> 00:24:13,829
really as hot is as hard as some hard

655
00:24:11,609 --> 00:24:16,289
lattice approximation problem not an

656
00:24:13,829 --> 00:24:17,579
easy one and that this is actually also

657
00:24:16,289 --> 00:24:19,259
hard on the average

658
00:24:17,579 --> 00:24:23,119
this is dovetailing would work by I tie

659
00:24:19,259 --> 00:24:26,429
which showed worse case to average a

660
00:24:23,119 --> 00:24:27,599
reductions so we know now that we have a

661
00:24:26,429 --> 00:24:29,819
problem which we can actually prove

662
00:24:27,599 --> 00:24:32,849
something about so it's as hard as the

663
00:24:29,819 --> 00:24:33,959
problem is being studied in geometry you

664
00:24:32,849 --> 00:24:35,309
know finding a short vector on an

665
00:24:33,959 --> 00:24:36,779
integer lattice actually an approximate

666
00:24:35,309 --> 00:24:38,849
sense but still it's kind of something

667
00:24:36,779 --> 00:24:41,969
one can bite their teeth into but you

668
00:24:38,849 --> 00:24:43,799
know teeth depends on the dentist I

669
00:24:41,969 --> 00:24:45,929
guess but in any case it's a still the

670
00:24:43,799 --> 00:24:47,759
best known algorithm is to to do you

671
00:24:45,929 --> 00:24:48,929
know big over and over log in it's a

672
00:24:47,759 --> 00:24:50,309
different algorithm today but the

673
00:24:48,929 --> 00:24:54,539
running time has not been improved from

674
00:24:50,309 --> 00:24:56,039
the LPN so this is surprising some sense

675
00:24:54,539 --> 00:24:57,989
because this is a harder problem but

676
00:24:56,039 --> 00:25:01,799
there's a lot more machinery maybe a lot

677
00:24:57,989 --> 00:25:03,059
more structure and so forth the thing is

678
00:25:01,799 --> 00:25:04,349
that's revolutionary about this

679
00:25:03,059 --> 00:25:06,209
introduction overlay game it's not just

680
00:25:04,349 --> 00:25:07,979
that he can prove things of a worst case

681
00:25:06,209 --> 00:25:10,679
the average is that this extremely

682
00:25:07,979 --> 00:25:12,329
versatile cryptographically so this is

683
00:25:10,679 --> 00:25:15,169
the problem really that allowed people

684
00:25:12,329 --> 00:25:17,099
to start thinking and actually achieving

685
00:25:15,169 --> 00:25:19,349
homomorphic fully homomorphic encryption

686
00:25:17,099 --> 00:25:21,178
not just a morphic encryption for one or

687
00:25:19,349 --> 00:25:23,729
two operations but really for any

688
00:25:21,179 --> 00:25:27,059
polynomial time algorithm so for any

689
00:25:23,729 --> 00:25:28,649
sequence of operations we can do things

690
00:25:27,059 --> 00:25:30,809
like linkage resilient cryptography

691
00:25:28,649 --> 00:25:33,119
functional attribute encryption and much

692
00:25:30,809 --> 00:25:34,829
much more so if it's really

693
00:25:33,119 --> 00:25:36,658
revolutionary in the sense that this is

694
00:25:34,829 --> 00:25:38,688
a problem one can work with and do

695
00:25:36,659 --> 00:25:41,579
things we didn't know how to do before

696
00:25:38,689 --> 00:25:43,979
okay so in fact if you look at this is a

697
00:25:41,579 --> 00:25:45,869
slide that thanks to Daniel must be sort

698
00:25:43,979 --> 00:25:47,609
of he on one hand talks about what you

699
00:25:45,869 --> 00:25:48,958
can do with learning with errors another

700
00:25:47,609 --> 00:25:51,718
place what you can do with learning

701
00:25:48,959 --> 00:25:53,579
parity with noise and these are access

702
00:25:51,719 --> 00:25:56,299
talk about the noise level so as the

703
00:25:53,579 --> 00:26:00,198
noise becomes you know essentially

704
00:25:56,299 --> 00:26:04,949
smaller the problem becomes easier okay

705
00:26:00,199 --> 00:26:07,319
no sorry is the noise becomes yes okay

706
00:26:04,949 --> 00:26:09,809
become it becomes easier and therefore

707
00:26:07,319 --> 00:26:11,009
you can do more because as you know in

708
00:26:09,809 --> 00:26:12,269
some sense you can do more probably can

709
00:26:11,009 --> 00:26:13,409
break it you know and so for that we

710
00:26:12,269 --> 00:26:15,239
let's not go there

711
00:26:13,409 --> 00:26:16,739
but any case you can do more where it's

712
00:26:15,239 --> 00:26:18,239
with learning parity of noise you really

713
00:26:16,739 --> 00:26:20,699
can do stuff only in kind of the high

714
00:26:18,239 --> 00:26:22,090
high noise regime so what do I mean when

715
00:26:20,699 --> 00:26:26,169
I say do stuff you know you

716
00:26:22,090 --> 00:26:27,490
do the usual thing you start with let's

717
00:26:26,169 --> 00:26:28,900
say pseudo-random number generators

718
00:26:27,490 --> 00:26:30,100
which can do in one-way functions then

719
00:26:28,900 --> 00:26:32,830
you go to public encryption that

720
00:26:30,100 --> 00:26:36,459
requires some sort of trapdoor ability

721
00:26:32,830 --> 00:26:38,439
then you go to hashing and then you talk

722
00:26:36,460 --> 00:26:40,029
about put Cerreta functions a morphic

723
00:26:38,440 --> 00:26:41,919
encryption and so forth so more and more

724
00:26:40,029 --> 00:26:43,090
things we want to do we can do them with

725
00:26:41,919 --> 00:26:44,320
learning with errors we're learning

726
00:26:43,090 --> 00:26:46,240
parity with noise people are working

727
00:26:44,320 --> 00:26:47,470
very hard to do them as well because the

728
00:26:46,240 --> 00:26:48,760
feeling is that that's kind of you know

729
00:26:47,470 --> 00:26:49,990
what right actually what is the feeling

730
00:26:48,760 --> 00:26:51,400
so the feeling is that it's much more

731
00:26:49,990 --> 00:26:53,470
efficient it's not a feeling because

732
00:26:51,400 --> 00:26:56,080
working mod 2 is much more efficient

733
00:26:53,470 --> 00:26:57,669
when we are working mod a Q and Q is

734
00:26:56,080 --> 00:26:59,049
large we're talking about large integers

735
00:26:57,669 --> 00:27:01,840
the whole rhythm they cost more so

736
00:26:59,049 --> 00:27:03,100
there's some very attractive idea that

737
00:27:01,840 --> 00:27:04,299
we can make all this work with the

738
00:27:03,100 --> 00:27:08,320
learning parity with noise but

739
00:27:04,299 --> 00:27:10,029
everything is boolean great one more

740
00:27:08,320 --> 00:27:11,799
thing there's huge quantum significance

741
00:27:10,029 --> 00:27:13,840
to this whole development because as you

742
00:27:11,799 --> 00:27:15,399
know we can build quantum computers I

743
00:27:13,840 --> 00:27:17,439
don't know if you were in Scott's talk

744
00:27:15,399 --> 00:27:19,059
but it's really around the corner in

745
00:27:17,440 --> 00:27:22,000
fact he says it is around the corner in

746
00:27:19,059 --> 00:27:23,678
downtown Santa Barbara in any case

747
00:27:22,000 --> 00:27:26,289
Google Microsoft IBM many other

748
00:27:23,679 --> 00:27:28,059
companies are out there trying to build

749
00:27:26,289 --> 00:27:29,860
quantum computers for a significant

750
00:27:28,059 --> 00:27:31,149
number of quantum bits you know this is

751
00:27:29,860 --> 00:27:33,699
the cartoon that always comes up here is

752
00:27:31,149 --> 00:27:35,320
how's your quantum computer doing great

753
00:27:33,700 --> 00:27:36,940
the project exists in a simultaneous

754
00:27:35,320 --> 00:27:39,010
state of being both totally unsuccessful

755
00:27:36,940 --> 00:27:40,840
not even started and he says can I

756
00:27:39,010 --> 00:27:42,039
observe it that's a tricky question so

757
00:27:40,840 --> 00:27:43,418
it's a cartoon but there's a lot of

758
00:27:42,039 --> 00:27:45,669
truth in it it sort of brings up the

759
00:27:43,419 --> 00:27:47,350
open problems how do you observe it how

760
00:27:45,669 --> 00:27:50,260
do you verify it and so forth and what

761
00:27:47,350 --> 00:27:52,299
do you do with it in any case so the

762
00:27:50,260 --> 00:27:55,299
thing is that that's all very nice to

763
00:27:52,299 --> 00:27:56,889
laugh but if this actually takes off you

764
00:27:55,299 --> 00:27:58,539
know we've got all those applications of

765
00:27:56,890 --> 00:28:01,299
the corrupt electronic commerce and

766
00:27:58,539 --> 00:28:03,370
quantum and in cryptocurrencies and all

767
00:28:01,299 --> 00:28:04,450
that and that has to be based on

768
00:28:03,370 --> 00:28:06,010
something which will be quantum

769
00:28:04,450 --> 00:28:07,659
resilient and therefore NIST has come up

770
00:28:06,010 --> 00:28:08,980
with this call for post quantum

771
00:28:07,659 --> 00:28:10,870
cryptography and what does this have to

772
00:28:08,980 --> 00:28:13,570
do with my talk it has to do with the

773
00:28:10,870 --> 00:28:17,139
fact that essentially all the candidates

774
00:28:13,570 --> 00:28:18,820
come that are in a one version or

775
00:28:17,140 --> 00:28:20,440
another of learning with errors or

776
00:28:18,820 --> 00:28:21,789
basing on learning with errors because

777
00:28:20,440 --> 00:28:24,789
this problem that came from learning

778
00:28:21,789 --> 00:28:26,320
theory is seems so far to be quantum

779
00:28:24,789 --> 00:28:29,169
resilient so whereas we know how to

780
00:28:26,320 --> 00:28:30,850
factor a quantum computer where to exist

781
00:28:29,169 --> 00:28:31,670
we don't know how to solve these

782
00:28:30,850 --> 00:28:33,770
problems or

783
00:28:31,670 --> 00:28:36,770
computer where to exist so at least it's

784
00:28:33,770 --> 00:28:38,629
a candidate that we can sort of bite our

785
00:28:36,770 --> 00:28:39,920
teeth into and develop signatures

786
00:28:38,630 --> 00:28:41,870
encryption scheme and so forth there

787
00:28:39,920 --> 00:28:46,760
could replace possibly what's in store

788
00:28:41,870 --> 00:28:48,110
right now all right so who is that it

789
00:28:46,760 --> 00:28:50,090
seems like what I said is that the

790
00:28:48,110 --> 00:28:52,909
blissful cryptography is a nightmare for

791
00:28:50,090 --> 00:28:54,290
machine learning and if that were when

792
00:28:52,910 --> 00:28:57,050
my talk would end I would choose a

793
00:28:54,290 --> 00:28:59,720
different topic because you know you

794
00:28:57,050 --> 00:29:01,159
know okay so they can give us hard

795
00:28:59,720 --> 00:29:04,340
problems we can tell them they can't do

796
00:29:01,160 --> 00:29:05,870
anything that's not where the story ends

797
00:29:04,340 --> 00:29:10,699
that's kind of the middle of my talk I

798
00:29:05,870 --> 00:29:12,290
hope I have more time yeah so so the

799
00:29:10,700 --> 00:29:14,030
reason I did go through that first part

800
00:29:12,290 --> 00:29:16,040
where we showed impossibility results is

801
00:29:14,030 --> 00:29:18,290
because I think that these impossibility

802
00:29:16,040 --> 00:29:19,940
results may be positive news for the

803
00:29:18,290 --> 00:29:21,139
second part of the talk the fact that

804
00:29:19,940 --> 00:29:23,120
there are some tasks the machine

805
00:29:21,140 --> 00:29:26,000
learning algorithms cannot solve is not

806
00:29:23,120 --> 00:29:30,530
necessarily a bad thing okay so let's

807
00:29:26,000 --> 00:29:32,690
just keep that in mind so now let's move

808
00:29:30,530 --> 00:29:34,610
from the 80s okay so that all was 86

809
00:29:32,690 --> 00:29:37,460
even though people are 84 even though

810
00:29:34,610 --> 00:29:39,740
lots of results continued kind of the

811
00:29:37,460 --> 00:29:41,650
thrust of the definition is from 84 so

812
00:29:39,740 --> 00:29:43,730
what's happened since

813
00:29:41,650 --> 00:29:45,290
so in some times I'd like to compare

814
00:29:43,730 --> 00:29:46,880
where we are as a cryptographer as a

815
00:29:45,290 --> 00:29:48,230
field and how I see machine learning and

816
00:29:46,880 --> 00:29:49,310
I'd be sitting here and his son is one

817
00:29:48,230 --> 00:29:50,900
of the kings of machine learning so

818
00:29:49,310 --> 00:29:52,879
probably he would disagree with me but I

819
00:29:50,900 --> 00:29:56,180
don't care so in any case I mean I do

820
00:29:52,880 --> 00:29:58,370
care but we'll discuss it later so in in

821
00:29:56,180 --> 00:30:00,920
cryptography I think that if you think

822
00:29:58,370 --> 00:30:02,870
about theory and practice okay I think

823
00:30:00,920 --> 00:30:05,300
what the the fabulous part about this

824
00:30:02,870 --> 00:30:06,709
field is that over the years they've

825
00:30:05,300 --> 00:30:10,550
gotten closer together rather than apart

826
00:30:06,710 --> 00:30:11,900
in the sense that people in practice are

827
00:30:10,550 --> 00:30:14,240
actually implementing things which

828
00:30:11,900 --> 00:30:18,740
satisfy some theoretical definitions and

829
00:30:14,240 --> 00:30:21,440
quite well and it's only getting better

830
00:30:18,740 --> 00:30:22,820
so as a field we have accepted the role

831
00:30:21,440 --> 00:30:23,840
theory and in some sense it's

832
00:30:22,820 --> 00:30:25,280
fundamental to the question of

833
00:30:23,840 --> 00:30:27,740
cryptography because without sort of

834
00:30:25,280 --> 00:30:28,670
rigor without proofs what are you giving

835
00:30:27,740 --> 00:30:29,870
you give me a system you're claiming

836
00:30:28,670 --> 00:30:31,760
it's not gonna break into more it breaks

837
00:30:29,870 --> 00:30:33,020
you have to give me some analysis you

838
00:30:31,760 --> 00:30:35,690
have to give me some formal guarantees

839
00:30:33,020 --> 00:30:38,860
in machine learning is more like

840
00:30:35,690 --> 00:30:41,210
algorithms right if it works it works

841
00:30:38,860 --> 00:30:43,429
but what does that exactly mean is

842
00:30:41,210 --> 00:30:44,570
unclear but in any case if I had to use

843
00:30:43,430 --> 00:30:46,340
the same card to

844
00:30:44,570 --> 00:30:48,230
Syrian practice the Thira machine

845
00:30:46,340 --> 00:30:50,300
learning is doing great but the

846
00:30:48,230 --> 00:30:53,480
excitement right now right the second

847
00:30:50,300 --> 00:30:57,050
August 2018 is really in the practice

848
00:30:53,480 --> 00:31:00,500
you know essentially with these deep

849
00:30:57,050 --> 00:31:02,690
neural Nets and to a large extent it's

850
00:31:00,500 --> 00:31:05,270
lacking theory and has to be developed

851
00:31:02,690 --> 00:31:08,270
so there's some kind of a departure here

852
00:31:05,270 --> 00:31:10,430
between theory and practice and the

853
00:31:08,270 --> 00:31:12,020
thing is this is a terrible slide but I

854
00:31:10,430 --> 00:31:13,580
got to read it that the practice of

855
00:31:12,020 --> 00:31:16,639
machine learning is really too important

856
00:31:13,580 --> 00:31:18,590
to leave for practice okay why is that

857
00:31:16,640 --> 00:31:21,260
because people are claiming and it's

858
00:31:18,590 --> 00:31:23,959
used in many ways and I believe it also

859
00:31:21,260 --> 00:31:26,120
that it's going to help us to the Z for

860
00:31:23,960 --> 00:31:28,580
disease control to predict financial

861
00:31:26,120 --> 00:31:32,120
markets for you know advertising for

862
00:31:28,580 --> 00:31:33,710
economic growth for traffic control for

863
00:31:32,120 --> 00:31:36,320
facial recognition for speech

864
00:31:33,710 --> 00:31:38,570
recognition for threat prediction for

865
00:31:36,320 --> 00:31:41,090
even computer viruses and spam and so

866
00:31:38,570 --> 00:31:43,460
forth and if you notice that last three

867
00:31:41,090 --> 00:31:45,439
bullets okay about policing bail and

868
00:31:43,460 --> 00:31:47,780
credit rating you know that's a bit

869
00:31:45,440 --> 00:31:50,330
we're going we're kind of sliding to a

870
00:31:47,780 --> 00:31:52,760
kind of dangerous zone where this is

871
00:31:50,330 --> 00:31:56,210
there are if you read the popular press

872
00:31:52,760 --> 00:31:57,560
next time you apply for a loan a machine

873
00:31:56,210 --> 00:31:59,690
learning algorithm will decide if you

874
00:31:57,560 --> 00:32:01,610
get it or you don't if you are police

875
00:31:59,690 --> 00:32:04,280
chief and you need to decide where to

876
00:32:01,610 --> 00:32:05,479
send your police units you will run a

877
00:32:04,280 --> 00:32:07,460
machine learning algorithm that will

878
00:32:05,480 --> 00:32:09,500
tell you where to send them and where if

879
00:32:07,460 --> 00:32:10,610
you're a judge and you need to decide

880
00:32:09,500 --> 00:32:12,440
whether to release someone with made on

881
00:32:10,610 --> 00:32:14,120
bail or not and you're lazy then you

882
00:32:12,440 --> 00:32:15,950
just run a machine learning algorithm

883
00:32:14,120 --> 00:32:18,739
that analyzes the data of the past in

884
00:32:15,950 --> 00:32:21,320
fact this is not just my slide but

885
00:32:18,740 --> 00:32:23,630
apparently New Jersey you know the

886
00:32:21,320 --> 00:32:25,639
judges are using these algorithms

887
00:32:23,630 --> 00:32:28,070
developed by some company that had

888
00:32:25,640 --> 00:32:30,620
access to all the information of judges

889
00:32:28,070 --> 00:32:33,080
deciding on bail in the past to decide

890
00:32:30,620 --> 00:32:35,270
on bail and other states are considering

891
00:32:33,080 --> 00:32:37,280
it another thing is that I think this is

892
00:32:35,270 --> 00:32:38,870
in New Orleans where they're using

893
00:32:37,280 --> 00:32:41,149
machine learning algorithms to decide

894
00:32:38,870 --> 00:32:43,699
where to send the police cars so this is

895
00:32:41,150 --> 00:32:45,290
actually being used okay now what does

896
00:32:43,700 --> 00:32:47,330
that mean that means really there's a

897
00:32:45,290 --> 00:32:49,760
sudden shift of power things that have

898
00:32:47,330 --> 00:32:52,100
been decided before by people and say

899
00:32:49,760 --> 00:32:55,370
people or they who people we don't like

900
00:32:52,100 --> 00:32:56,658
them they're not smart enough still we

901
00:32:55,370 --> 00:32:57,859
have to realize that now

902
00:32:56,659 --> 00:33:00,259
it's an algorithm that's gonna make

903
00:32:57,859 --> 00:33:02,299
decisions about things which are quite

904
00:33:00,259 --> 00:33:04,099
important so there is a sudden shift of

905
00:33:02,299 --> 00:33:05,720
power we just have to kind of recognize

906
00:33:04,099 --> 00:33:09,559
that and it's a good one

907
00:33:05,720 --> 00:33:12,619
but it's certainly a fact and in fact

908
00:33:09,559 --> 00:33:14,869
this is a slide that from my inferna so

909
00:33:12,619 --> 00:33:16,908
there's some analysis about the largest

910
00:33:14,869 --> 00:33:21,559
companies by market cap used to be the

911
00:33:16,909 --> 00:33:24,049
oil companies like Exxon and in banks

912
00:33:21,559 --> 00:33:26,720
and so forth and now in 2016 these are

913
00:33:24,049 --> 00:33:28,999
all these are all high tech companies

914
00:33:26,720 --> 00:33:31,399
you know Apple and Facebook and Amazon

915
00:33:28,999 --> 00:33:33,200
and Microsoft and there are these quotes

916
00:33:31,399 --> 00:33:34,518
saying that data is the new oil you know

917
00:33:33,200 --> 00:33:36,979
these data companies and data will

918
00:33:34,519 --> 00:33:39,979
become a currency so why am i saying

919
00:33:36,979 --> 00:33:41,989
that is because this shift of power ok

920
00:33:39,979 --> 00:33:44,659
is going to those companies it seems

921
00:33:41,989 --> 00:33:46,519
that have a lot of data since a lot of

922
00:33:44,659 --> 00:33:48,080
this prediction is based on knowing the

923
00:33:46,519 --> 00:33:51,859
past and having a lot of data about the

924
00:33:48,080 --> 00:33:53,960
past and essentially this can leave us

925
00:33:51,859 --> 00:33:55,129
sort of unprotected and unregulated and

926
00:33:53,960 --> 00:33:56,599
so forth so these things that you hear

927
00:33:55,129 --> 00:33:56,959
all the time and you know you hear it

928
00:33:56,599 --> 00:34:00,139
again

929
00:33:56,960 --> 00:34:02,779
so the faces for the rest of my talk is

930
00:34:00,139 --> 00:34:06,199
that this is the essential cryptography

931
00:34:02,779 --> 00:34:08,149
is a field for many many years we have

932
00:34:06,200 --> 00:34:09,859
paid attention to how to ensure the

933
00:34:08,149 --> 00:34:11,239
privacy and correctness of computation

934
00:34:09,859 --> 00:34:13,869
right so we have developed lots of

935
00:34:11,239 --> 00:34:16,609
methods you know whether they're using

936
00:34:13,869 --> 00:34:18,950
multi-party computation or when you talk

937
00:34:16,609 --> 00:34:21,440
about cup computing with private on

938
00:34:18,949 --> 00:34:22,730
private data or interactive proofs when

939
00:34:21,440 --> 00:34:24,049
you talk about verifying that the

940
00:34:22,730 --> 00:34:26,659
computation was done correctly we got a

941
00:34:24,049 --> 00:34:28,489
lot of tools and this means that we are

942
00:34:26,659 --> 00:34:30,079
really we should be able to play a

943
00:34:28,489 --> 00:34:33,049
central role in ensuring that the power

944
00:34:30,079 --> 00:34:35,510
of algorithms is not abused ok I think

945
00:34:33,049 --> 00:34:37,788
that it's very very clear that that's

946
00:34:35,510 --> 00:34:40,339
the case now the question is just to do

947
00:34:37,789 --> 00:34:42,859
it so what I've done is essentially I

948
00:34:40,339 --> 00:34:45,770
came up here with like eight or eight

949
00:34:42,859 --> 00:34:47,000
challenges ok some of them are actual

950
00:34:45,770 --> 00:34:48,949
challenges are already being attacked

951
00:34:47,000 --> 00:34:50,719
and let me just go through them as

952
00:34:48,949 --> 00:34:52,308
quickly as I can so I can tell you

953
00:34:50,719 --> 00:34:55,489
actually what's being done today so

954
00:34:52,309 --> 00:34:57,020
first of all if we think about this as

955
00:34:55,489 --> 00:34:59,359
power or machine learning where does it

956
00:34:57,020 --> 00:35:02,240
come from it comes from data data about

957
00:34:59,359 --> 00:35:04,369
whom about us about individuals right so

958
00:35:02,240 --> 00:35:06,759
data about where we drive who we talk to

959
00:35:04,369 --> 00:35:09,109
what we like to buy and so forth in our

960
00:35:06,760 --> 00:35:10,250
genetic profile and so forth so

961
00:35:09,109 --> 00:35:11,810
obviously ensuring the

962
00:35:10,250 --> 00:35:14,780
privacy of both the data in the model

963
00:35:11,810 --> 00:35:17,090
during the training and classifying even

964
00:35:14,780 --> 00:35:21,650
if it's not mandated by regulations okay

965
00:35:17,090 --> 00:35:24,020
is in a way a way to maintain this power

966
00:35:21,650 --> 00:35:27,290
to the people sort of so privacy is

967
00:35:24,020 --> 00:35:29,600
crucial because machine learning stands

968
00:35:27,290 --> 00:35:34,759
to really change the way you know life

969
00:35:29,600 --> 00:35:36,319
goes and secondly you know okay so let's

970
00:35:34,760 --> 00:35:38,720
say that the inputs are private and now

971
00:35:36,320 --> 00:35:40,340
there is a model that some company

972
00:35:38,720 --> 00:35:45,049
developed for the state of New Jersey or

973
00:35:40,340 --> 00:35:47,900
the state of Louisiana okay to use for

974
00:35:45,050 --> 00:35:50,330
bail or police but who says that that

975
00:35:47,900 --> 00:35:52,610
model actually fits the data and who

976
00:35:50,330 --> 00:35:54,860
says that it hasn't been tampered maybe

977
00:35:52,610 --> 00:35:57,310
for bias or some sort of trap door so

978
00:35:54,860 --> 00:36:00,140
that if you want it's some critical

979
00:35:57,310 --> 00:36:02,390
juncture to make sure that somebody

980
00:36:00,140 --> 00:36:05,450
who's important to you goes out on bail

981
00:36:02,390 --> 00:36:08,839
gets alone doesn't get tracked by the

982
00:36:05,450 --> 00:36:10,490
police so this is clear you know it's

983
00:36:08,840 --> 00:36:11,780
obvious right we have to make sure that

984
00:36:10,490 --> 00:36:15,379
these things are done in a tamper-proof

985
00:36:11,780 --> 00:36:16,880
way and the question is how the extra

986
00:36:15,380 --> 00:36:18,950
benefit of these two challenges is that

987
00:36:16,880 --> 00:36:20,300
it's an opportunity for using stuff that

988
00:36:18,950 --> 00:36:21,500
we could wait for many years we're

989
00:36:20,300 --> 00:36:23,660
writing lots of papers and we had

990
00:36:21,500 --> 00:36:25,430
schemes about who's using them well now

991
00:36:23,660 --> 00:36:26,899
because of the block chains because of

992
00:36:25,430 --> 00:36:29,299
this application I think it actually

993
00:36:26,900 --> 00:36:30,350
will be used but it's a side benefit you

994
00:36:29,300 --> 00:36:31,820
know it's more important really to

995
00:36:30,350 --> 00:36:33,380
address these challenges that's a lot of

996
00:36:31,820 --> 00:36:34,970
things that people are doing and I will

997
00:36:33,380 --> 00:36:38,990
talk about in the third part of the talk

998
00:36:34,970 --> 00:36:42,799
all right next thing so you much we put

999
00:36:38,990 --> 00:36:44,689
this slide up so people have probably

1000
00:36:42,800 --> 00:36:46,070
heard this term adversarial machine

1001
00:36:44,690 --> 00:36:48,890
learning the idea of adversary machine

1002
00:36:46,070 --> 00:36:53,030
learning is that let's say there's a

1003
00:36:48,890 --> 00:36:56,390
model and you can either look at it okay

1004
00:36:53,030 --> 00:36:57,860
and try to come up with an example that

1005
00:36:56,390 --> 00:36:59,029
you feed that model and input this is

1006
00:36:57,860 --> 00:37:00,830
after the training phase in the second

1007
00:36:59,030 --> 00:37:02,180
phase that is going to miss classify so

1008
00:37:00,830 --> 00:37:03,529
here it seems useless why do you want to

1009
00:37:02,180 --> 00:37:06,140
miss classify the pig is an airliner

1010
00:37:03,530 --> 00:37:07,090
like a kosher airliner or a non kosher

1011
00:37:06,140 --> 00:37:10,170
Lee

1012
00:37:07,090 --> 00:37:10,170
and it's not allowed

1013
00:37:10,630 --> 00:37:13,720
why would you want to do that well

1014
00:37:11,950 --> 00:37:16,089
that's not that's entertaining for talks

1015
00:37:13,720 --> 00:37:17,500
but you know people talk about the

1016
00:37:16,090 --> 00:37:19,960
self-driving cars you don't want them to

1017
00:37:17,500 --> 00:37:22,540
miss classify stop sign for yield sign

1018
00:37:19,960 --> 00:37:25,240
or even things close to home what if you

1019
00:37:22,540 --> 00:37:27,070
have software that's intended to find

1020
00:37:25,240 --> 00:37:29,259
something as a virus or something as a

1021
00:37:27,070 --> 00:37:31,720
spam and someone can just tweak their

1022
00:37:29,260 --> 00:37:34,120
spam message or tweak the virus so that

1023
00:37:31,720 --> 00:37:36,009
your classifier doesn't catch them just

1024
00:37:34,120 --> 00:37:37,330
by playing with it a little bit so when

1025
00:37:36,010 --> 00:37:39,820
I say playing with it a little bit is

1026
00:37:37,330 --> 00:37:42,490
essentially you can these results of

1027
00:37:39,820 --> 00:37:46,480
turning the pig into into you know I

1028
00:37:42,490 --> 00:37:48,100
don't know United is is these results

1029
00:37:46,480 --> 00:37:49,960
don't require actually having a lot of

1030
00:37:48,100 --> 00:37:51,759
information they require being able to

1031
00:37:49,960 --> 00:37:55,450
ask questions back and forth from a

1032
00:37:51,760 --> 00:37:58,360
classifier a of images you know that Pig

1033
00:37:55,450 --> 00:38:00,370
recognizer the thing is of course it's

1034
00:37:58,360 --> 00:38:01,930
not totally honest because when they ask

1035
00:38:00,370 --> 00:38:05,109
questions back and forth they ask a lot

1036
00:38:01,930 --> 00:38:06,160
of questions that's one too when you get

1037
00:38:05,110 --> 00:38:07,540
an answer it's not just telling you a

1038
00:38:06,160 --> 00:38:08,859
pig or airline it actually tells you the

1039
00:38:07,540 --> 00:38:10,240
probability that it's a pig or the

1040
00:38:08,860 --> 00:38:11,470
probability it's an airline so it

1041
00:38:10,240 --> 00:38:14,020
actually gives you a bit of information

1042
00:38:11,470 --> 00:38:16,000
about how your underlying machine

1043
00:38:14,020 --> 00:38:18,060
learning algorithm is working but the

1044
00:38:16,000 --> 00:38:23,320
fact is that you can specify things

1045
00:38:18,060 --> 00:38:24,820
galore and you know what do we have to

1046
00:38:23,320 --> 00:38:26,470
do with this well it's cryptographers we

1047
00:38:24,820 --> 00:38:28,120
really do have a vast experience in

1048
00:38:26,470 --> 00:38:31,899
mathematical modeling of adversarial

1049
00:38:28,120 --> 00:38:33,720
behavior so they're playing and it's

1050
00:38:31,900 --> 00:38:35,860
incredible because this is very small

1051
00:38:33,720 --> 00:38:38,770
perturbations of these images can ill

1052
00:38:35,860 --> 00:38:41,710
these incredible consequences but how do

1053
00:38:38,770 --> 00:38:43,030
you actually go about fixing this okay

1054
00:38:41,710 --> 00:38:45,070
so you would think that you would need

1055
00:38:43,030 --> 00:38:47,290
to define formally what are the class of

1056
00:38:45,070 --> 00:38:48,760
changes that can be done and then prove

1057
00:38:47,290 --> 00:38:52,270
security with respect to these class of

1058
00:38:48,760 --> 00:38:53,290
changes okay and in fact there is work

1059
00:38:52,270 --> 00:38:53,890
by Madhuri that he talked about

1060
00:38:53,290 --> 00:38:55,990
yesterday

1061
00:38:53,890 --> 00:38:57,700
which is exactly what he does so he

1062
00:38:55,990 --> 00:39:01,029
looks at images and then he defines a

1063
00:38:57,700 --> 00:39:02,439
class of attacks okay which are domain

1064
00:39:01,030 --> 00:39:04,240
specific so what would you do to an

1065
00:39:02,440 --> 00:39:06,460
image you may rotate it you may shift

1066
00:39:04,240 --> 00:39:07,689
some pixels so he defines his class and

1067
00:39:06,460 --> 00:39:09,880
then he proves things

1068
00:39:07,690 --> 00:39:12,670
what does he prove so first of all he

1069
00:39:09,880 --> 00:39:14,890
has this notion of robust training where

1070
00:39:12,670 --> 00:39:16,480
when he's training then his algorithm

1071
00:39:14,890 --> 00:39:18,279
he's also giving it some adversarial

1072
00:39:16,480 --> 00:39:19,240
examples adversarial according to the

1073
00:39:18,280 --> 00:39:21,040
class that he's defined

1074
00:39:19,240 --> 00:39:22,810
before and then he shows the once he

1075
00:39:21,040 --> 00:39:25,600
does that miss class efficient is much

1076
00:39:22,810 --> 00:39:28,029
harder miss classification of course

1077
00:39:25,600 --> 00:39:30,100
restricted to the adversarial behavior

1078
00:39:28,030 --> 00:39:33,640
that he proved against then he shows

1079
00:39:30,100 --> 00:39:35,830
that some bounds he says look I could do

1080
00:39:33,640 --> 00:39:38,259
this okay and it's a good thing to do

1081
00:39:35,830 --> 00:39:39,940
but how much water work is training a

1082
00:39:38,260 --> 00:39:41,230
machine learning model is not simple

1083
00:39:39,940 --> 00:39:42,040
especially not the kind of models that

1084
00:39:41,230 --> 00:39:44,950
he's looking at with image

1085
00:39:42,040 --> 00:39:47,970
classification so how much more data do

1086
00:39:44,950 --> 00:39:50,439
you need in order to train a robust a

1087
00:39:47,970 --> 00:39:52,419
robust network a robust to those

1088
00:39:50,440 --> 00:39:53,890
transformations that he's defined but my

1089
00:39:52,420 --> 00:39:56,980
point in all these results which are

1090
00:39:53,890 --> 00:39:58,600
fascinating is that he defined the class

1091
00:39:56,980 --> 00:40:00,850
of transformations and then he proved

1092
00:39:58,600 --> 00:40:03,430
security with respect to or the cerebral

1093
00:40:00,850 --> 00:40:04,868
busnes with respect to that class and to

1094
00:40:03,430 --> 00:40:06,549
me it's extremely reminiscent to the

1095
00:40:04,869 --> 00:40:08,290
days of leakage resilient where we had

1096
00:40:06,550 --> 00:40:13,090
those beautiful papers on timing attacks

1097
00:40:08,290 --> 00:40:16,840
and in cash attacks and give me another

1098
00:40:13,090 --> 00:40:17,920
attack acoustic attack no seriously so

1099
00:40:16,840 --> 00:40:19,420
these things were amazing they like

1100
00:40:17,920 --> 00:40:22,090
would break RSA or they would break

1101
00:40:19,420 --> 00:40:24,910
these schemes and then what you want is

1102
00:40:22,090 --> 00:40:26,170
to actually define larger classes and of

1103
00:40:24,910 --> 00:40:27,690
course you want them to include these

1104
00:40:26,170 --> 00:40:29,830
attacks and prove something

1105
00:40:27,690 --> 00:40:31,390
mathematically with respect to those

1106
00:40:29,830 --> 00:40:32,980
attacks and it seems very similarly even

1107
00:40:31,390 --> 00:40:34,779
though I might I know that it's

1108
00:40:32,980 --> 00:40:38,470
different but in spirit I think it is

1109
00:40:34,780 --> 00:40:40,060
similar ok next thing yeah ok so the

1110
00:40:38,470 --> 00:40:41,290
holy grail in this adversary machine

1111
00:40:40,060 --> 00:40:42,910
learning I think is when I think

1112
00:40:41,290 --> 00:40:44,740
everybody knows that is that we want to

1113
00:40:42,910 --> 00:40:47,529
build some our model they went embed in

1114
00:40:44,740 --> 00:40:49,089
it a challenge so that if you that in

1115
00:40:47,530 --> 00:40:51,160
order to misclassify you would have to

1116
00:40:49,090 --> 00:40:52,300
solve this challenge what nobody knows

1117
00:40:51,160 --> 00:40:53,560
how to do that it's very difficult to me

1118
00:40:52,300 --> 00:40:55,570
because everything is so empirical a

1119
00:40:53,560 --> 00:40:57,750
challenge what a challenge that looks

1120
00:40:55,570 --> 00:41:00,369
like a plane and you and it's a in a

1121
00:40:57,750 --> 00:41:01,510
regular schemes I mean regular planes

1122
00:41:00,369 --> 00:41:02,650
you know they should be classified as

1123
00:41:01,510 --> 00:41:04,000
planes without having to embed

1124
00:41:02,650 --> 00:41:05,530
cryptographic challenges in them

1125
00:41:04,000 --> 00:41:07,510
I'm not saying I know how to do it but

1126
00:41:05,530 --> 00:41:09,100
it's clearly the Holy Grail and this

1127
00:41:07,510 --> 00:41:12,010
relates to the Debbie Downer thing

1128
00:41:09,100 --> 00:41:13,540
because you know if we think about what

1129
00:41:12,010 --> 00:41:15,160
we talked about in the first part of the

1130
00:41:13,540 --> 00:41:17,109
talk it was how to come up with counter

1131
00:41:15,160 --> 00:41:18,970
examples to learning right so in some

1132
00:41:17,109 --> 00:41:22,720
sense this might give us some sort of a

1133
00:41:18,970 --> 00:41:25,959
guideline of how to start working toward

1134
00:41:22,720 --> 00:41:28,118
this holy grail okay next next challenge

1135
00:41:25,960 --> 00:41:30,369
so we've left adversarial machine

1136
00:41:28,119 --> 00:41:32,100
learning behind so there's all these

1137
00:41:30,369 --> 00:41:33,150
laws coming up which are good

1138
00:41:32,100 --> 00:41:34,860
I mean they're not real necessarily

1139
00:41:33,150 --> 00:41:36,450
well-written but they have good

1140
00:41:34,860 --> 00:41:38,940
intentions so there's gdpr and now

1141
00:41:36,450 --> 00:41:40,770
there's a California law a digital

1142
00:41:38,940 --> 00:41:43,200
privacy law which essentially grants

1143
00:41:40,770 --> 00:41:44,910
consumers more control over an insight

1144
00:41:43,200 --> 00:41:47,879
into the spread of their information

1145
00:41:44,910 --> 00:41:49,440
online so regardless what the law

1146
00:41:47,880 --> 00:41:51,510
actually says what is the point here

1147
00:41:49,440 --> 00:41:53,490
they're saying it would be then the

1148
00:41:51,510 --> 00:41:54,750
consumer should know if a company has

1149
00:41:53,490 --> 00:41:57,299
its data that it's giving it to another

1150
00:41:54,750 --> 00:41:58,620
company or at least it's giving it in

1151
00:41:57,300 --> 00:41:59,880
such a way that it's not going to be

1152
00:41:58,620 --> 00:42:02,730
able to be traced back to him or

1153
00:41:59,880 --> 00:42:04,710
Hartman's in some way so in other words

1154
00:42:02,730 --> 00:42:07,740
we want ways to trace the unauthorized

1155
00:42:04,710 --> 00:42:09,600
use of your data and of your model and

1156
00:42:07,740 --> 00:42:12,240
it means that it would be very

1157
00:42:09,600 --> 00:42:16,620
interesting to develop methods which

1158
00:42:12,240 --> 00:42:18,120
could be used for tracing data of course

1159
00:42:16,620 --> 00:42:19,740
without introducing more vulnerability

1160
00:42:18,120 --> 00:42:21,720
because it seems obvious that if I

1161
00:42:19,740 --> 00:42:24,689
introduce ways to trace my data I'm

1162
00:42:21,720 --> 00:42:27,569
actually introducing a way to find out

1163
00:42:24,690 --> 00:42:28,980
about me okay so wait a second but you

1164
00:42:27,570 --> 00:42:30,450
know these type of problems don't really

1165
00:42:28,980 --> 00:42:33,240
bother us because these paradoxes we've

1166
00:42:30,450 --> 00:42:36,149
sold before and here is a conjecture

1167
00:42:33,240 --> 00:42:38,100
from the reception yesterday discussion

1168
00:42:36,150 --> 00:42:39,390
with Mary waters and guy Ross film is

1169
00:42:38,100 --> 00:42:41,490
that maybe you could show the data

1170
00:42:39,390 --> 00:42:42,990
tracing is possible unless some sort of

1171
00:42:41,490 --> 00:42:44,490
privacy preserving learning algorithm

1172
00:42:42,990 --> 00:42:46,319
was used so it's a double-edged sword

1173
00:42:44,490 --> 00:42:47,399
maybe you could show if you can trace it

1174
00:42:46,320 --> 00:42:48,690
is because they use I don't know

1175
00:42:47,400 --> 00:42:50,400
differential privacy or something else

1176
00:42:48,690 --> 00:42:53,370
and then that would be good it would be

1177
00:42:50,400 --> 00:42:55,620
almost a proof that they use a data a

1178
00:42:53,370 --> 00:42:58,529
privacy preserving method with your data

1179
00:42:55,620 --> 00:43:00,420
okay next

1180
00:42:58,530 --> 00:43:02,270
what about tracing down over through

1181
00:43:00,420 --> 00:43:04,920
eyes use of the model so this is a

1182
00:43:02,270 --> 00:43:06,840
beautiful work I think a sequence of

1183
00:43:04,920 --> 00:43:08,250
works by the way I am going to be really

1184
00:43:06,840 --> 00:43:09,660
a lot of people gonna be upset at me

1185
00:43:08,250 --> 00:43:11,490
because I don't reference many things

1186
00:43:09,660 --> 00:43:15,000
but you really should not be upset at me

1187
00:43:11,490 --> 00:43:16,379
because I can't okay so you know it's

1188
00:43:15,000 --> 00:43:17,940
too much and I can't remember the names

1189
00:43:16,380 --> 00:43:19,440
and so forth but in any case here's one

1190
00:43:17,940 --> 00:43:23,610
paper that appeared in use next I

1191
00:43:19,440 --> 00:43:26,070
remember Benny Pincus and just last week

1192
00:43:23,610 --> 00:43:28,080
where they show how to watermark a model

1193
00:43:26,070 --> 00:43:29,850
so their idea in some sense and they

1194
00:43:28,080 --> 00:43:31,620
have this beautiful title turning your

1195
00:43:29,850 --> 00:43:33,540
weakness into your strength by the way

1196
00:43:31,620 --> 00:43:35,520
that's one thing that this field has the

1197
00:43:33,540 --> 00:43:36,630
names fantastic you know every system

1198
00:43:35,520 --> 00:43:39,090
has a beauty I don't know there's so

1199
00:43:36,630 --> 00:43:40,560
many acronyms it's I mean odd people

1200
00:43:39,090 --> 00:43:42,720
coming up with these names but any case

1201
00:43:40,560 --> 00:43:43,509
what they mean is is that they watermark

1202
00:43:42,720 --> 00:43:45,339
the

1203
00:43:43,510 --> 00:43:47,050
nor let by training the network to

1204
00:43:45,340 --> 00:43:48,100
accept some planted adversarial example

1205
00:43:47,050 --> 00:43:49,870
so in some sense the fact that there are

1206
00:43:48,100 --> 00:43:51,370
adversarial examples in the kind with

1207
00:43:49,870 --> 00:43:52,299
the pig in the airline they saying you

1208
00:43:51,370 --> 00:43:53,799
know that's a good thing I'm going to

1209
00:43:52,300 --> 00:43:55,990
put something in there that only I know

1210
00:43:53,800 --> 00:43:58,600
that I put and it's gonna miss classify

1211
00:43:55,990 --> 00:44:01,540
something galore and it's gonna be

1212
00:43:58,600 --> 00:44:03,819
searching my watermark okay five

1213
00:44:01,540 --> 00:44:05,140
fairness accountability and the biasing

1214
00:44:03,820 --> 00:44:07,000
so right now there's this whole

1215
00:44:05,140 --> 00:44:09,279
community it's called fat fairness

1216
00:44:07,000 --> 00:44:12,510
accountability and transparency where

1217
00:44:09,280 --> 00:44:14,620
they come up with definitions in a in

1218
00:44:12,510 --> 00:44:16,960
algorithms of how to take machine

1219
00:44:14,620 --> 00:44:18,310
learning models and make them fair okay

1220
00:44:16,960 --> 00:44:20,470
and Cynthia I've talked about that

1221
00:44:18,310 --> 00:44:22,600
yesterday I think that we have some

1222
00:44:20,470 --> 00:44:25,299
crypto style definitions which could be

1223
00:44:22,600 --> 00:44:29,080
useful where they talk about similar

1224
00:44:25,300 --> 00:44:30,610
people have to quote similar people have

1225
00:44:29,080 --> 00:44:32,620
to be classified in a similar manner

1226
00:44:30,610 --> 00:44:33,850
what is similar really mean how do they

1227
00:44:32,620 --> 00:44:36,970
define that there's some sort of metric

1228
00:44:33,850 --> 00:44:38,980
but to me it seems that you know

1229
00:44:36,970 --> 00:44:41,350
definitions like simulation based

1230
00:44:38,980 --> 00:44:42,670
computer computation the in distinguish

1231
00:44:41,350 --> 00:44:43,750
or might be it's very interesting here

1232
00:44:42,670 --> 00:44:45,070
because in some sense what do you want

1233
00:44:43,750 --> 00:44:46,660
to say is that with one person you can

1234
00:44:45,070 --> 00:44:47,950
do what you can do with the next you

1235
00:44:46,660 --> 00:44:50,440
know I could give a whole talk on this

1236
00:44:47,950 --> 00:44:53,169
but but I won't then there's a question

1237
00:44:50,440 --> 00:44:55,390
of randomness so machine at least for

1238
00:44:53,170 --> 00:44:56,530
the machine learning models that I'll

1239
00:44:55,390 --> 00:44:58,150
talk about in a minute near the neural

1240
00:44:56,530 --> 00:45:01,210
net ran learner seems to be very

1241
00:44:58,150 --> 00:45:03,520
important and I've never heard any

1242
00:45:01,210 --> 00:45:06,190
discussion about what kind of randomness

1243
00:45:03,520 --> 00:45:07,509
do you need to guarantee success is it a

1244
00:45:06,190 --> 00:45:10,360
computer graphically strong is it

1245
00:45:07,510 --> 00:45:14,140
unpredictable is it just something else

1246
00:45:10,360 --> 00:45:15,820
how does it affect stability so I think

1247
00:45:14,140 --> 00:45:17,470
that's a very interesting domain we as

1248
00:45:15,820 --> 00:45:18,760
we know at the end randomness for

1249
00:45:17,470 --> 00:45:22,359
generating secret keys if it's done

1250
00:45:18,760 --> 00:45:23,920
incorrectly can be detrimental and they

1251
00:45:22,360 --> 00:45:25,480
talk often about the brittleness of this

1252
00:45:23,920 --> 00:45:27,940
that somebody comes with a neural net

1253
00:45:25,480 --> 00:45:29,350
and then somebody tries to reproduce it

1254
00:45:27,940 --> 00:45:31,600
they can't maybe it has to do with

1255
00:45:29,350 --> 00:45:32,980
randomness or maybe the fact that you

1256
00:45:31,600 --> 00:45:34,630
can translate adversarial machine

1257
00:45:32,980 --> 00:45:37,690
learning examples from one model to the

1258
00:45:34,630 --> 00:45:39,130
next which is surprising you attacked

1259
00:45:37,690 --> 00:45:40,480
one and any terms seems to attack

1260
00:45:39,130 --> 00:45:42,490
another is because they use the same

1261
00:45:40,480 --> 00:45:45,690
randomness or closely-related randomness

1262
00:45:42,490 --> 00:45:48,399
I have no idea but it's worth a study

1263
00:45:45,690 --> 00:45:50,080
finally I think that this is probably

1264
00:45:48,400 --> 00:45:51,280
something that's very tractable and that

1265
00:45:50,080 --> 00:45:53,230
is defined some specialized

1266
00:45:51,280 --> 00:45:54,550
cryptographic functionalities which are

1267
00:45:53,230 --> 00:45:55,960
sort of machine learning complete so

1268
00:45:54,550 --> 00:45:57,670
some of the cryptographic things which

1269
00:45:55,960 --> 00:45:59,980
could if you did it well you could

1270
00:45:57,670 --> 00:46:02,290
implement sort of safe machine learning

1271
00:45:59,980 --> 00:46:04,210
and of course these have to be

1272
00:46:02,290 --> 00:46:05,890
functionalities which are efficient you

1273
00:46:04,210 --> 00:46:08,050
know for cryptography all right so I

1274
00:46:05,890 --> 00:46:10,060
want to say to end here and then go to

1275
00:46:08,050 --> 00:46:11,710
my last part is this there's a real

1276
00:46:10,060 --> 00:46:17,680
opportunity here for developing a new

1277
00:46:11,710 --> 00:46:19,960
theory and and I think that's great you

1278
00:46:17,680 --> 00:46:21,160
know like how exciting so what this is

1279
00:46:19,960 --> 00:46:22,240
the third part and last part of my talk

1280
00:46:21,160 --> 00:46:26,080
and obviously I'm not gonna get through

1281
00:46:22,240 --> 00:46:28,540
all of it there is a lot of work on

1282
00:46:26,080 --> 00:46:31,029
deterring the privacy of both data and

1283
00:46:28,540 --> 00:46:33,130
model during classification during

1284
00:46:31,030 --> 00:46:35,080
training and some work on model stealing

1285
00:46:33,130 --> 00:46:38,050
as well okay so what do I mean by that

1286
00:46:35,080 --> 00:46:40,180
okay so if for a m-- so i'll say in a

1287
00:46:38,050 --> 00:46:42,910
minute i want to say that lots and lots

1288
00:46:40,180 --> 00:46:44,830
of works as i said 50 or so and really

1289
00:46:42,910 --> 00:46:45,940
in some sense if you think about it we

1290
00:46:44,830 --> 00:46:48,850
know a lot of these things are possible

1291
00:46:45,940 --> 00:46:50,080
just by general results right how

1292
00:46:48,850 --> 00:46:52,779
efficient is it we know asymptotically

1293
00:46:50,080 --> 00:46:55,090
then this question of how you write a

1294
00:46:52,780 --> 00:46:56,980
system and you want to you can analyze

1295
00:46:55,090 --> 00:46:59,170
the concrete efficiency now we in that

1296
00:46:56,980 --> 00:47:00,520
stage is proofs of concept not I don't

1297
00:46:59,170 --> 00:47:03,160
think any of these things are ready to

1298
00:47:00,520 --> 00:47:06,640
be shipped off but this is very natural

1299
00:47:03,160 --> 00:47:07,480
progression of how these things go so I

1300
00:47:06,640 --> 00:47:09,790
said you could use cryptographic

1301
00:47:07,480 --> 00:47:11,800
technologies of the past what

1302
00:47:09,790 --> 00:47:12,490
technologies everything it's like the

1303
00:47:11,800 --> 00:47:14,500
kitchen sink

1304
00:47:12,490 --> 00:47:16,180
you know garbage circuits of the Alpha

1305
00:47:14,500 --> 00:47:18,820
matey to homomorphic encryption from

1306
00:47:16,180 --> 00:47:21,370
gentry and on secret sharing of Shamir

1307
00:47:18,820 --> 00:47:24,330
differential privacy and multi-party

1308
00:47:21,370 --> 00:47:29,470
computation so all of these techniques

1309
00:47:24,330 --> 00:47:31,690
come into play so which one well that's

1310
00:47:29,470 --> 00:47:33,160
a really good question it seems like

1311
00:47:31,690 --> 00:47:34,420
each one has their merit depending on

1312
00:47:33,160 --> 00:47:35,799
their they were doing training or

1313
00:47:34,420 --> 00:47:37,210
classification and what trust

1314
00:47:35,800 --> 00:47:39,250
assumptions we're willing to make and

1315
00:47:37,210 --> 00:47:40,420
really what people are doing it's like a

1316
00:47:39,250 --> 00:47:42,070
Chinese menu even though there doesn't

1317
00:47:40,420 --> 00:47:44,050
look like Chinese food but in any case

1318
00:47:42,070 --> 00:47:45,370
it's sort of a pick and choose approach

1319
00:47:44,050 --> 00:47:46,630
you know you sort of have all this

1320
00:47:45,370 --> 00:47:48,100
technology out there maybe I'm going to

1321
00:47:46,630 --> 00:47:51,400
use this and then I'm gonna connect it

1322
00:47:48,100 --> 00:47:53,170
here and voila a system comes out and I

1323
00:47:51,400 --> 00:47:56,110
mean it in the best possible way so

1324
00:47:53,170 --> 00:47:56,910
let's just see sort of very briefly the

1325
00:47:56,110 --> 00:47:59,070
kind of thing

1326
00:47:56,910 --> 00:48:00,660
are being done so here is kind of a

1327
00:47:59,070 --> 00:48:01,980
picture there's a training phase as we

1328
00:48:00,660 --> 00:48:03,839
said and there's a classification phase

1329
00:48:01,980 --> 00:48:05,660
so if you think about classification

1330
00:48:03,840 --> 00:48:08,760
what are the security issues anyway

1331
00:48:05,660 --> 00:48:10,379
they're two on this side of the client

1332
00:48:08,760 --> 00:48:13,380
who wants to sort of classify you

1333
00:48:10,380 --> 00:48:16,170
nobody's getting it alone or not or I

1334
00:48:13,380 --> 00:48:18,450
don't know what something else they want

1335
00:48:16,170 --> 00:48:20,790
to keep their data private so in this

1336
00:48:18,450 --> 00:48:23,850
picture it's a doctor that has the the

1337
00:48:20,790 --> 00:48:25,650
the images medical records of her

1338
00:48:23,850 --> 00:48:26,880
patient and then the hospital was

1339
00:48:25,650 --> 00:48:28,890
developed tomorrow because had lots of

1340
00:48:26,880 --> 00:48:31,350
patients and knows how to classify tumor

1341
00:48:28,890 --> 00:48:34,379
is malignant not wants to keep the model

1342
00:48:31,350 --> 00:48:36,000
parameters or the hypothesis secret even

1343
00:48:34,380 --> 00:48:38,630
worked pretty hard to get it so there

1344
00:48:36,000 --> 00:48:42,150
are these two competing two competing

1345
00:48:38,630 --> 00:48:43,410
concerns and it seems like okay what do

1346
00:48:42,150 --> 00:48:45,480
you want let's go home to party

1347
00:48:43,410 --> 00:48:48,080
computation yeah I already did in 1982

1348
00:48:45,480 --> 00:48:51,150
why do we have to even discuss this okay

1349
00:48:48,080 --> 00:48:54,060
performance performance performance so

1350
00:48:51,150 --> 00:48:55,620
essentially this is I mean I'm gonna

1351
00:48:54,060 --> 00:48:57,029
skip this but you can sort of talk about

1352
00:48:55,620 --> 00:48:58,560
the pluses and minuses of using

1353
00:48:57,030 --> 00:49:00,720
two-party computation versus using

1354
00:48:58,560 --> 00:49:03,330
encryption that has some sort of homo of

1355
00:49:00,720 --> 00:49:04,620
homomorphic properties to it the big

1356
00:49:03,330 --> 00:49:07,140
line here without looking at all these

1357
00:49:04,620 --> 00:49:08,759
pluses and minuses is that our morphic

1358
00:49:07,140 --> 00:49:10,230
encryption allows small communication

1359
00:49:08,760 --> 00:49:11,070
sort of if you think about it you're

1360
00:49:10,230 --> 00:49:13,770
encrypting the input in you're

1361
00:49:11,070 --> 00:49:16,050
encrypting the output okay where is car

1362
00:49:13,770 --> 00:49:18,000
build circuits a a multi-party

1363
00:49:16,050 --> 00:49:18,540
computation the communication is very

1364
00:49:18,000 --> 00:49:19,950
high

1365
00:49:18,540 --> 00:49:21,300
because it's proportional to the size of

1366
00:49:19,950 --> 00:49:22,859
the circuit or the computation that

1367
00:49:21,300 --> 00:49:24,510
you're doing but computation is more

1368
00:49:22,860 --> 00:49:26,280
efficient so that's the tension here

1369
00:49:24,510 --> 00:49:28,740
there's other tensions not the only one

1370
00:49:26,280 --> 00:49:30,300
the garbled circuits they work on binary

1371
00:49:28,740 --> 00:49:32,129
inputs it's really for boolean circuits

1372
00:49:30,300 --> 00:49:33,960
the homework encryption they work for

1373
00:49:32,130 --> 00:49:35,520
arithmetic so depending on whether your

1374
00:49:33,960 --> 00:49:37,290
computation your naive thing that you're

1375
00:49:35,520 --> 00:49:39,120
doing starts being boolean or starts

1376
00:49:37,290 --> 00:49:40,650
being arithmetic and in fact often we'll

1377
00:49:39,120 --> 00:49:43,140
start working with real real numbers

1378
00:49:40,650 --> 00:49:45,780
okay you may prefer one technology over

1379
00:49:43,140 --> 00:49:47,370
the other all right so I was gonna talk

1380
00:49:45,780 --> 00:49:49,890
about some work that I've done in the

1381
00:49:47,370 --> 00:49:52,350
nineteen in 2015 which is working on

1382
00:49:49,890 --> 00:49:54,379
very simple classifiers okay like you

1383
00:49:52,350 --> 00:49:57,569
know linear classifiers decision trees

1384
00:49:54,380 --> 00:49:59,400
you know naive Bayes in which case it's

1385
00:49:57,570 --> 00:50:01,140
very clear that you want to choose or an

1386
00:49:59,400 --> 00:50:02,490
encryption scheme which can come where

1387
00:50:01,140 --> 00:50:03,470
you can encrypt em and encrypt em

1388
00:50:02,490 --> 00:50:04,669
primary

1389
00:50:03,470 --> 00:50:06,169
where the M was greater than prime or

1390
00:50:04,670 --> 00:50:09,290
not that's kind of the basis what you

1391
00:50:06,170 --> 00:50:10,369
want or of that sort and that's the kind

1392
00:50:09,290 --> 00:50:13,040
of encryption scheme you would use in

1393
00:50:10,369 --> 00:50:15,140
order to develop an a classifier where

1394
00:50:13,040 --> 00:50:17,750
both the input of the being classified

1395
00:50:15,140 --> 00:50:19,940
is main in maintaining in secret and the

1396
00:50:17,750 --> 00:50:21,859
hyperplane sort of what classifies as

1397
00:50:19,940 --> 00:50:24,109
zero one is maintained secret but the

1398
00:50:21,859 --> 00:50:27,259
real interesting game in town is not

1399
00:50:24,109 --> 00:50:30,710
that you see that dog he doesn't look

1400
00:50:27,260 --> 00:50:31,820
very happy but I don't know I think I

1401
00:50:30,710 --> 00:50:36,410
was in an aggressive mood when I was

1402
00:50:31,820 --> 00:50:38,119
downloading these pictures so the real

1403
00:50:36,410 --> 00:50:39,500
interesting question is what about these

1404
00:50:38,119 --> 00:50:42,080
deep neural nets right which everybody's

1405
00:50:39,500 --> 00:50:44,630
saying is the future and and it's been

1406
00:50:42,080 --> 00:50:46,310
utilized what what is the challenge

1407
00:50:44,630 --> 00:50:48,080
really in classification and also in

1408
00:50:46,310 --> 00:50:51,049
training so the way that these things

1409
00:50:48,080 --> 00:50:52,490
work there's this dog and he's not

1410
00:50:51,050 --> 00:50:53,690
physically being input obviously it's a

1411
00:50:52,490 --> 00:50:55,220
picture of a dog which is a bunch of

1412
00:50:53,690 --> 00:50:57,040
pixels and each pixel has some kind of

1413
00:50:55,220 --> 00:50:59,149
value depending on what the color or

1414
00:50:57,040 --> 00:51:01,640
sort when some sort of grayscale if you

1415
00:50:59,150 --> 00:51:03,410
want feel if you wish is inputted to the

1416
00:51:01,640 --> 00:51:05,118
neural net then there's something that

1417
00:51:03,410 --> 00:51:06,740
is called usually layers and then at the

1418
00:51:05,119 --> 00:51:08,119
end there's an output which is a bunch

1419
00:51:06,740 --> 00:51:10,549
of nodes which have probabilities in

1420
00:51:08,119 --> 00:51:12,859
them was this a dog was this a cat was

1421
00:51:10,550 --> 00:51:15,230
this a man or was this no one a neither

1422
00:51:12,859 --> 00:51:17,930
one of these three and obviously if this

1423
00:51:15,230 --> 00:51:20,480
is perfect the top blue one it's gonna

1424
00:51:17,930 --> 00:51:22,580
have a one it's a dog okay it just I

1425
00:51:20,480 --> 00:51:24,349
think it's a dog also it's an angry dog

1426
00:51:22,580 --> 00:51:25,490
and then the others are all zeros but

1427
00:51:24,349 --> 00:51:27,710
that's not always going to be the case

1428
00:51:25,490 --> 00:51:29,479
now what is the issue with cryptography

1429
00:51:27,710 --> 00:51:31,670
these immediate these intermediate

1430
00:51:29,480 --> 00:51:33,320
orange balls okay what do they do they

1431
00:51:31,670 --> 00:51:35,839
essentially there are some weights on

1432
00:51:33,320 --> 00:51:37,730
these wires and what they do is they sum

1433
00:51:35,839 --> 00:51:40,670
these multiply these weights by the

1434
00:51:37,730 --> 00:51:41,960
input variables and then they compute

1435
00:51:40,670 --> 00:51:44,030
something called an activation function

1436
00:51:41,960 --> 00:51:45,859
on this value which is a nonlinear

1437
00:51:44,030 --> 00:51:47,060
computation okay so that's what we have

1438
00:51:45,859 --> 00:51:50,210
to remember there's sort of a bunch of

1439
00:51:47,060 --> 00:51:52,160
linear stuff you weighted sum and then

1440
00:51:50,210 --> 00:51:55,520
you do something nonlinear why is that

1441
00:51:52,160 --> 00:51:57,080
important for cryptography because you

1442
00:51:55,520 --> 00:52:00,700
know sort of what's an example these

1443
00:51:57,080 --> 00:52:03,589
nonlinear functions logistic functions

1444
00:52:00,700 --> 00:52:05,240
essentially a max a hyperbolic tangent

1445
00:52:03,589 --> 00:52:07,279
and I guess the point is that our

1446
00:52:05,240 --> 00:52:09,589
cryptography our folio morphic

1447
00:52:07,280 --> 00:52:11,180
encryption and NPCs are really good when

1448
00:52:09,589 --> 00:52:12,799
what we're computing are low degree

1449
00:52:11,180 --> 00:52:14,330
polynomials so that was on the slide

1450
00:52:12,800 --> 00:52:16,180
that I skipped really quickly this is

1451
00:52:14,330 --> 00:52:18,160
not a low degree polynomial

1452
00:52:16,180 --> 00:52:19,868
which means that if the inputs come in

1453
00:52:18,160 --> 00:52:21,670
encrypted and then we want to sort of

1454
00:52:19,869 --> 00:52:24,160
evaluate this whole thing under

1455
00:52:21,670 --> 00:52:27,220
encrypted input and like they are fully

1456
00:52:24,160 --> 00:52:29,140
or more frequent PC whatever it's gonna

1457
00:52:27,220 --> 00:52:31,299
help me hard because these are functions

1458
00:52:29,140 --> 00:52:33,930
are gonna require a very very very deep

1459
00:52:31,299 --> 00:52:35,940
circuit to compute and we don't have

1460
00:52:33,930 --> 00:52:38,200
essentially it's beyond our capacity

1461
00:52:35,940 --> 00:52:40,150
because it would mean that we would need

1462
00:52:38,200 --> 00:52:44,788
to do bootstrapping we need that means

1463
00:52:40,150 --> 00:52:48,279
it's big parameters a lot of noise and

1464
00:52:44,789 --> 00:52:51,130
we can't do it as is so the beauty is

1465
00:52:48,279 --> 00:52:52,299
still that there is work and I you know

1466
00:52:51,130 --> 00:52:55,270
I this first worked I've seen it was

1467
00:52:52,299 --> 00:52:57,670
Microsoft group by Kristen is that they

1468
00:52:55,270 --> 00:52:59,190
actually do it anyway so what are they

1469
00:52:57,670 --> 00:53:01,869
do so the first work is crypto Nets

1470
00:52:59,190 --> 00:53:04,390
essentially first a few problems to

1471
00:53:01,869 --> 00:53:06,190
address you in his neural nets you have

1472
00:53:04,390 --> 00:53:08,828
you look you you have these fixed

1473
00:53:06,190 --> 00:53:10,029
precision real numbers and you need to

1474
00:53:08,829 --> 00:53:11,349
convert them to integers because that's

1475
00:53:10,029 --> 00:53:12,670
what the homework encryption works with

1476
00:53:11,349 --> 00:53:13,809
and these you're going to multiply

1477
00:53:12,670 --> 00:53:15,940
you're gonna add these things are going

1478
00:53:13,809 --> 00:53:17,799
to grow you somehow have to make sure

1479
00:53:15,940 --> 00:53:20,920
that they don't grow beyond what you can

1480
00:53:17,799 --> 00:53:23,650
handle then there is a question of this

1481
00:53:20,920 --> 00:53:25,150
logistic or nonlinear function what do

1482
00:53:23,650 --> 00:53:28,930
you do then so they say okay let's not

1483
00:53:25,150 --> 00:53:30,910
use it let's use a low degree polynomial

1484
00:53:28,930 --> 00:53:32,919
which will approximate it well and they

1485
00:53:30,910 --> 00:53:36,430
proposed use of squaring function the

1486
00:53:32,920 --> 00:53:37,990
point is so this is Z square there so

1487
00:53:36,430 --> 00:53:42,220
the point is that that's I think that's

1488
00:53:37,990 --> 00:53:44,950
a really you know big idea sort of

1489
00:53:42,220 --> 00:53:49,169
trading accuracy in some sense for

1490
00:53:44,950 --> 00:53:51,308
efficiency so in other words that and

1491
00:53:49,170 --> 00:53:53,260
there's two ways to go here one is to

1492
00:53:51,309 --> 00:53:54,970
work really hard and to be able to do

1493
00:53:53,260 --> 00:53:56,109
the logistic function okay and the other

1494
00:53:54,970 --> 00:53:58,118
way is to go to the machine learning

1495
00:53:56,109 --> 00:53:59,529
people and tell them listen this is

1496
00:53:58,119 --> 00:54:02,829
better for us okay you want to have

1497
00:53:59,529 --> 00:54:04,089
secure ml why don't you do your neural

1498
00:54:02,829 --> 00:54:05,500
nets with these kind of functions

1499
00:54:04,089 --> 00:54:06,250
whether it's this function another one

1500
00:54:05,500 --> 00:54:08,020
is a different question

1501
00:54:06,250 --> 00:54:09,609
to my surprise for example in module

1502
00:54:08,020 --> 00:54:11,380
yesterday who's extremely savvy in all

1503
00:54:09,609 --> 00:54:13,630
this didn't know about this work about

1504
00:54:11,380 --> 00:54:16,420
the kind of functions that are used in

1505
00:54:13,630 --> 00:54:18,279
intermediate neural nets in the crypt

1506
00:54:16,420 --> 00:54:19,720
crypto work okay I think that a hard

1507
00:54:18,279 --> 00:54:21,220
Sameer and a few other people actually

1508
00:54:19,720 --> 00:54:23,500
worked on analyzing the squaring

1509
00:54:21,220 --> 00:54:25,779
function and how well it does compared

1510
00:54:23,500 --> 00:54:27,099
to you know logistic and so forth this

1511
00:54:25,779 --> 00:54:29,410
is the kind of work that should be major

1512
00:54:27,099 --> 00:54:32,350
encouraged okay this is no

1513
00:54:29,410 --> 00:54:33,490
only fhe that's being a hoe morphic

1514
00:54:32,350 --> 00:54:36,490
encryption that's being used in this

1515
00:54:33,490 --> 00:54:38,500
context but also people in this work on

1516
00:54:36,490 --> 00:54:40,479
deep secure took garbled circuits and

1517
00:54:38,500 --> 00:54:42,460
optimized implementations for sigmoid

1518
00:54:40,480 --> 00:54:43,870
for tangent those activation functions

1519
00:54:42,460 --> 00:54:45,430
that are actually used by the machine

1520
00:54:43,870 --> 00:54:47,109
learning people so they didn't switch to

1521
00:54:45,430 --> 00:54:48,339
some other functions they took the one

1522
00:54:47,110 --> 00:54:49,660
there are being used in the machine

1523
00:54:48,340 --> 00:54:52,750
learning algorithms and then

1524
00:54:49,660 --> 00:54:54,310
implementation specific optimizations so

1525
00:54:52,750 --> 00:54:55,840
then there is this rule that we notice

1526
00:54:54,310 --> 00:54:57,850
telling me when is the factory better

1527
00:54:55,840 --> 00:54:59,920
than NPC because here it's fhe here is

1528
00:54:57,850 --> 00:55:02,470
multi-party computation so here's a rule

1529
00:54:59,920 --> 00:55:06,160
of thumb if the computation is linear

1530
00:55:02,470 --> 00:55:08,109
and the circuit size is superlinear

1531
00:55:06,160 --> 00:55:09,460
use homomorphic encryption because your

1532
00:55:08,110 --> 00:55:13,620
circuit the computation is too large

1533
00:55:09,460 --> 00:55:19,420
okay to use garbage circuits and yet

1534
00:55:13,620 --> 00:55:21,430
it's small enough to use homomorphic

1535
00:55:19,420 --> 00:55:22,600
encryption successfully and in fact

1536
00:55:21,430 --> 00:55:26,040
there is this work that was also a

1537
00:55:22,600 --> 00:55:29,200
Newsweek just last not music use niché's

1538
00:55:26,040 --> 00:55:33,940
same difference by Geico today say in

1539
00:55:29,200 --> 00:55:36,520
chicken whatever Anantha and cheok which

1540
00:55:33,940 --> 00:55:38,170
they combined the two approaches and

1541
00:55:36,520 --> 00:55:39,580
essentially what they are what they do

1542
00:55:38,170 --> 00:55:41,250
is they say this you know there is that

1543
00:55:39,580 --> 00:55:43,779
linear layer right so the encrypted

1544
00:55:41,250 --> 00:55:45,220
inputs come in and first of all we sum

1545
00:55:43,780 --> 00:55:47,980
that we can do on their own morphic

1546
00:55:45,220 --> 00:55:49,330
encryption now comes a nonlinear so the

1547
00:55:47,980 --> 00:55:52,900
suggestion now is that now there will be

1548
00:55:49,330 --> 00:55:55,029
a protocol between the classifier the

1549
00:55:52,900 --> 00:55:58,780
model holder and the user who has been

1550
00:55:55,030 --> 00:56:00,730
key for decryption and somehow they will

1551
00:55:58,780 --> 00:56:02,380
do two party computation to compute this

1552
00:56:00,730 --> 00:56:04,180
nonlinear level and now we go to the

1553
00:56:02,380 --> 00:56:07,510
next stage of course this whole thing

1554
00:56:04,180 --> 00:56:08,799
makes sense only when either the model

1555
00:56:07,510 --> 00:56:10,870
is something that you don't know or that

1556
00:56:08,800 --> 00:56:12,220
there's some efficiency that's gained by

1557
00:56:10,870 --> 00:56:13,690
this approach versus you yourself

1558
00:56:12,220 --> 00:56:15,100
computing the model so because you could

1559
00:56:13,690 --> 00:56:16,650
imagine the model giving you an

1560
00:56:15,100 --> 00:56:20,440
encrypted model and then you go do it

1561
00:56:16,650 --> 00:56:22,600
anyway the issue is that very

1562
00:56:20,440 --> 00:56:24,330
interesting work good performance and it

1563
00:56:22,600 --> 00:56:28,509
came here is to combine these two

1564
00:56:24,330 --> 00:56:29,799
technologies um I know that I'm kind of

1565
00:56:28,510 --> 00:56:33,120
out of time I'm going to take five more

1566
00:56:29,800 --> 00:56:33,120
minutes okay to

1567
00:56:33,900 --> 00:56:39,430
uh-uh thank you very much so this is

1568
00:56:37,570 --> 00:56:41,680
classifying so glynn your classifier is

1569
00:56:39,430 --> 00:56:43,690
simple you know deep neural Nets

1570
00:56:41,680 --> 00:56:47,319
difficult okay

1571
00:56:43,690 --> 00:56:49,720
what about training so training you know

1572
00:56:47,320 --> 00:56:52,240
what is it nightmare as far as I can see

1573
00:56:49,720 --> 00:56:53,980
because before we we had to go through

1574
00:56:52,240 --> 00:56:55,509
the system once and compute this

1575
00:56:53,980 --> 00:56:59,920
nonlinear function you know at every

1576
00:56:55,510 --> 00:57:01,480
level of the network but now you know

1577
00:56:59,920 --> 00:57:03,340
when I do training essentially this is

1578
00:57:01,480 --> 00:57:04,990
the canonical picture so this weight one

1579
00:57:03,340 --> 00:57:06,700
and way too we think about you know

1580
00:57:04,990 --> 00:57:09,729
these weights on the wires that you do

1581
00:57:06,700 --> 00:57:10,750
the weighted sum with we don't when you

1582
00:57:09,730 --> 00:57:12,099
train you don't know what those weights

1583
00:57:10,750 --> 00:57:14,020
are so you start something random and

1584
00:57:12,099 --> 00:57:15,430
then you improve those weights you know

1585
00:57:14,020 --> 00:57:17,109
pair what you learn from the training

1586
00:57:15,430 --> 00:57:18,669
data and you improve improve improve

1587
00:57:17,109 --> 00:57:21,009
till you find a place where it's sort of

1588
00:57:18,670 --> 00:57:23,710
optimal in some sense the thing is that

1589
00:57:21,010 --> 00:57:25,180
that a so in this picture here these are

1590
00:57:23,710 --> 00:57:27,330
the original weights this is sort of the

1591
00:57:25,180 --> 00:57:29,589
loss so how good these weights are and

1592
00:57:27,330 --> 00:57:31,450
let's say you start somewhere here and

1593
00:57:29,590 --> 00:57:33,730
you want to really follow the way to

1594
00:57:31,450 --> 00:57:35,109
find the right w1 w2 in this case but

1595
00:57:33,730 --> 00:57:37,150
usually there are lots of weights that

1596
00:57:35,109 --> 00:57:39,460
minimizes the loss of the classification

1597
00:57:37,150 --> 00:57:41,349
but how do you do that you have a

1598
00:57:39,460 --> 00:57:43,930
training input with the way so you have

1599
00:57:41,349 --> 00:57:45,670
right now and you run it through the

1600
00:57:43,930 --> 00:57:47,529
network and then you see whether they

1601
00:57:45,670 --> 00:57:49,480
classified well or not and if it did

1602
00:57:47,530 --> 00:57:50,890
that's good if it didn't it tells you

1603
00:57:49,480 --> 00:57:52,180
how to change your weight and then you

1604
00:57:50,890 --> 00:57:53,529
use another input and so forth of course

1605
00:57:52,180 --> 00:57:55,118
they don't even wanting it period of

1606
00:57:53,530 --> 00:57:57,670
time there's lots of inputs but I think

1607
00:57:55,119 --> 00:57:59,740
batches of inputs and do that okay but

1608
00:57:57,670 --> 00:58:02,170
that's a lot of nonlinear operations

1609
00:57:59,740 --> 00:58:06,368
it's a lot of operations altogether so I

1610
00:58:02,170 --> 00:58:07,570
think this is a incorrect it's worse so

1611
00:58:06,369 --> 00:58:09,910
if you compare training through

1612
00:58:07,570 --> 00:58:11,650
classification it's gonna be the size of

1613
00:58:09,910 --> 00:58:13,330
the day this is D not the same different

1614
00:58:11,650 --> 00:58:15,849
before the size of your data set how

1615
00:58:13,330 --> 00:58:19,598
many trained examples on your data set

1616
00:58:15,849 --> 00:58:22,180
and more okay so very difficult second

1617
00:58:19,599 --> 00:58:25,300
of all we need lots of training examples

1618
00:58:22,180 --> 00:58:27,339
and often we need to take them for many

1619
00:58:25,300 --> 00:58:29,770
different entities may be individuals

1620
00:58:27,339 --> 00:58:31,359
may be companies may be hospitals but

1621
00:58:29,770 --> 00:58:32,800
the training data doesn't come from one

1622
00:58:31,359 --> 00:58:34,180
source so it's not to party computation

1623
00:58:32,800 --> 00:58:35,440
anymore where there's somebody holding

1624
00:58:34,180 --> 00:58:37,480
the data and somebody wants to train

1625
00:58:35,440 --> 00:58:38,950
it's actually lots of people who may be

1626
00:58:37,480 --> 00:58:40,720
contributing data and one that wants to

1627
00:58:38,950 --> 00:58:43,830
train so if you want to keep the privacy

1628
00:58:40,720 --> 00:58:47,459
of those lots of people how do you do it

1629
00:58:43,830 --> 00:58:48,990
MPC that's right actually true so there

1630
00:58:47,460 --> 00:58:50,790
is a paper called federated learning or

1631
00:58:48,990 --> 00:58:52,979
concept called federate learning where

1632
00:58:50,790 --> 00:58:54,540
they say okay let's say that your

1633
00:58:52,980 --> 00:58:56,940
training data is what you've typed on

1634
00:58:54,540 --> 00:58:58,200
your laptops and the machine learning

1635
00:58:56,940 --> 00:59:00,810
wants to predict the next word

1636
00:58:58,200 --> 00:59:02,069
so if I write crip - 2018 the word

1637
00:59:00,810 --> 00:59:05,759
keynote comes out or something of that

1638
00:59:02,070 --> 00:59:08,910
sort so the thing is they they want to

1639
00:59:05,760 --> 00:59:10,890
have lots of users typing and develop a

1640
00:59:08,910 --> 00:59:12,750
model from all those users inputs but

1641
00:59:10,890 --> 00:59:13,620
they don't want the user let's say

1642
00:59:12,750 --> 00:59:16,740
doesn't want to tell them about what

1643
00:59:13,620 --> 00:59:19,230
they're typing so the idea with this is

1644
00:59:16,740 --> 00:59:21,029
that you first but they suggest this you

1645
00:59:19,230 --> 00:59:23,580
know what each user can logically train

1646
00:59:21,030 --> 00:59:25,320
a neural net okay so they have some

1647
00:59:23,580 --> 00:59:27,630
weights so there's some initial weights

1648
00:59:25,320 --> 00:59:30,240
that everybody knows and then each one

1649
00:59:27,630 --> 00:59:33,450
improves them depending on their inputs

1650
00:59:30,240 --> 00:59:35,549
and then they send the deltas in the

1651
00:59:33,450 --> 00:59:37,589
improvement to the server and their

1652
00:59:35,550 --> 00:59:38,910
first argument is look just I'm just

1653
00:59:37,590 --> 00:59:40,710
sending the Delta of the improvement I'm

1654
00:59:38,910 --> 00:59:42,629
not sending my inputs I'm reading better

1655
00:59:40,710 --> 00:59:46,920
a little bit it's not good enough

1656
00:59:42,630 --> 00:59:48,690
because these these deltas can leak

1657
00:59:46,920 --> 00:59:50,940
information about my inputs so the

1658
00:59:48,690 --> 00:59:52,740
second idea is instead of sending to me

1659
00:59:50,940 --> 00:59:54,780
the Delta in the inputs we're going to

1660
00:59:52,740 --> 00:59:56,399
split so really over here

1661
00:59:54,780 --> 00:59:58,410
there was one server we're going to

1662
00:59:56,400 --> 01:00:00,570
split this to several servers let's say

1663
00:59:58,410 --> 01:00:02,310
three or four and we're trusting somehow

1664
01:00:00,570 --> 01:00:04,680
so Google splits into two agents and

1665
01:00:02,310 --> 01:00:06,120
we're trusting that they don't all talk

1666
01:00:04,680 --> 01:00:08,100
to each other at least somebody doesn't

1667
01:00:06,120 --> 01:00:11,549
talk to there's some known collusion

1668
01:00:08,100 --> 01:00:13,380
going on and now they each won this

1669
01:00:11,550 --> 01:00:15,500
guy's secret shares his Delta of the

1670
01:00:13,380 --> 01:00:17,970
weights among those servers they all get

1671
01:00:15,500 --> 01:00:19,980
together into a weighted sum weighted

1672
01:00:17,970 --> 01:00:26,399
sum we know how to do very efficiently

1673
01:00:19,980 --> 01:00:28,410
so that's the idea there and what else

1674
01:00:26,400 --> 01:00:30,150
do I want to say I want to say that even

1675
01:00:28,410 --> 01:00:31,649
though I had that beautiful picture in

1676
01:00:30,150 --> 01:00:33,690
saying the training is a nightmare it's

1677
01:00:31,650 --> 01:00:36,690
being done I like hats off if I had a

1678
01:00:33,690 --> 01:00:38,070
hat it's unbelievable sort of there's a

1679
01:00:36,690 --> 01:00:39,600
lot of work on training approximate

1680
01:00:38,070 --> 01:00:42,240
logistic regression and other kind of

1681
01:00:39,600 --> 01:00:47,060
regressions the main idea there which

1682
01:00:42,240 --> 01:00:49,859
again is a big idea is how to

1683
01:00:47,060 --> 01:00:51,750
essentially approximate these standard

1684
01:00:49,860 --> 01:00:53,310
computations like logistic and so forth

1685
01:00:51,750 --> 01:00:55,080
by other functions which have similar

1686
01:00:53,310 --> 01:00:56,089
performance in our friendly -

1687
01:00:55,080 --> 01:00:58,249
cryptography

1688
01:00:56,089 --> 01:00:59,930
in fact there is a very beautiful new

1689
01:00:58,249 --> 01:01:01,549
homomorphic encryption which the title

1690
01:00:59,930 --> 01:01:04,009
is a morphic encryption for approximate

1691
01:01:01,549 --> 01:01:06,559
arithmetic the idea here is you kind of

1692
01:01:04,009 --> 01:01:08,599
say you know what we have always wanted

1693
01:01:06,559 --> 01:01:10,130
insisted that a morphic encryption has

1694
01:01:08,599 --> 01:01:12,739
to give me the same answers as the

1695
01:01:10,130 --> 01:01:14,299
unencrypted computation let's relax that

1696
01:01:12,739 --> 01:01:16,279
it's not gonna give the same answers

1697
01:01:14,299 --> 01:01:19,038
it's gonna be approximately the same

1698
01:01:16,279 --> 01:01:23,359
answers when I any way are using this

1699
01:01:19,039 --> 01:01:24,890
for some exam application will only need

1700
01:01:23,359 --> 01:01:26,479
an approximation and I don't need exact

1701
01:01:24,890 --> 01:01:27,949
computation that's good enough and that

1702
01:01:26,479 --> 01:01:29,269
can make my homomorphic encryption much

1703
01:01:27,949 --> 01:01:31,400
faster so I think it's this beautiful

1704
01:01:29,269 --> 01:01:33,229
work and this is an example showing how

1705
01:01:31,400 --> 01:01:35,059
this machine learning in my opinion in

1706
01:01:33,229 --> 01:01:36,169
logistic regression motivated the

1707
01:01:35,059 --> 01:01:38,029
invention of a completely new

1708
01:01:36,170 --> 01:01:39,709
homomorphic encryption scheme so it's a

1709
01:01:38,029 --> 01:01:41,660
really an example where this kind of

1710
01:01:39,709 --> 01:01:45,410
goal has changed in my opinion

1711
01:01:41,660 --> 01:01:46,999
cryptography okay I think that I'm gonna

1712
01:01:45,410 --> 01:01:48,979
skip the model stealing that's the

1713
01:01:46,999 --> 01:01:50,808
furniture privacy I just want to say

1714
01:01:48,979 --> 01:01:52,459
that we're really not that at all

1715
01:01:50,809 --> 01:01:53,959
because in all of these things and all

1716
01:01:52,459 --> 01:01:55,489
these solutions it's all honest

1717
01:01:53,959 --> 01:01:57,680
bicurious models so we're trusting

1718
01:01:55,489 --> 01:01:59,630
people to follow the protocol but why

1719
01:01:57,680 --> 01:02:01,698
should we trust them what about people

1720
01:01:59,630 --> 01:02:04,459
who are trying to modify things so that

1721
01:02:01,699 --> 01:02:06,109
they can later bake get qualified for a

1722
01:02:04,459 --> 01:02:07,969
loan so I think it's a fundamental

1723
01:02:06,109 --> 01:02:09,949
question and the stakes are too high to

1724
01:02:07,969 --> 01:02:11,869
pretend it doesn't matter you know

1725
01:02:09,949 --> 01:02:13,819
there's sort of three parts to it how do

1726
01:02:11,869 --> 01:02:15,769
you verify everybody is doing the right

1727
01:02:13,819 --> 01:02:17,239
thing during the training how do you

1728
01:02:15,769 --> 01:02:18,948
make learning robust to adversarial

1729
01:02:17,239 --> 01:02:20,839
inputs so this beautiful work on

1730
01:02:18,949 --> 01:02:22,880
distributed optimization saying suppose

1731
01:02:20,839 --> 01:02:24,589
some of the inputs are actually bad okay

1732
01:02:22,880 --> 01:02:28,160
that you make your optimization problem

1733
01:02:24,589 --> 01:02:30,859
still robust against those badly chosen

1734
01:02:28,160 --> 01:02:33,009
inputs and finally you know how do you

1735
01:02:30,859 --> 01:02:36,880
verify the model has not been modified

1736
01:02:33,009 --> 01:02:43,880
post-training okay you've been extremely

1737
01:02:36,880 --> 01:02:45,049
patient and my bottom line is this you

1738
01:02:43,880 --> 01:02:47,269
know this whole machine learning thing

1739
01:02:45,049 --> 01:02:50,239
are fascinating fascinating for

1740
01:02:47,269 --> 01:02:51,468
cryptography it's an opportunity to use

1741
01:02:50,239 --> 01:02:53,299
things we've developed for many years

1742
01:02:51,469 --> 01:02:55,249
but more importantly it's an opportunity

1743
01:02:53,299 --> 01:02:58,160
to develop new theory both for crypto

1744
01:02:55,249 --> 01:03:00,288
and for mmm so that they work well

1745
01:02:58,160 --> 01:03:01,879
together and finally I want to thank all

1746
01:03:00,289 --> 01:03:04,609
these people who are kind of tortured

1747
01:03:01,880 --> 01:03:06,650
with questions on this topic

1748
01:03:04,609 --> 01:03:08,600
and if I didn't mention you you know who

1749
01:03:06,650 --> 01:03:19,980
you are say thank you

1750
01:03:08,600 --> 01:03:19,980
[Applause]

