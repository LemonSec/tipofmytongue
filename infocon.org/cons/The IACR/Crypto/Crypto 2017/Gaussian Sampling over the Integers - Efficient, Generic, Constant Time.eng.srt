1
00:00:05,070 --> 00:00:07,660
thank you tonight for the introduction

2
00:00:07,660 --> 00:00:12,450
so I want to start with a few words of

3
00:00:14,100 --> 00:00:17,710
introduction or so or 1.5 decades later

4
00:00:17,710 --> 00:00:21,850
space secure crypto has become very very

5
00:00:21,850 --> 00:00:24,730
popular and if you search for reasons of

6
00:00:24,730 --> 00:00:28,570
why that is people usually say you'll

7
00:00:28,570 --> 00:00:31,290
see a combination of the same reasons

8
00:00:31,290 --> 00:00:33,430
this is usually a combination of the

9
00:00:33,430 --> 00:00:36,400
following on the one hand lettuces are

10
00:00:36,400 --> 00:00:38,440
very powerful they allow us to construct

11
00:00:38,440 --> 00:00:39,850
things that we don't know how to do

12
00:00:39,850 --> 00:00:41,380
otherwise for example for your mama

13
00:00:41,380 --> 00:00:45,550
morphic encryption and I bees and things

14
00:00:45,550 --> 00:00:45,899
like that

15
00:00:45,899 --> 00:00:48,850
furthermore there at least up to this

16
00:00:48,850 --> 00:00:50,260
point believed to be postponed and

17
00:00:50,260 --> 00:00:57,280
secure finally they also enjoy some very

18
00:00:57,280 --> 00:00:58,870
strong guarantees in terms of average

19
00:00:58,870 --> 00:01:00,789
case security which stems from worst

20
00:01:00,789 --> 00:01:03,100
case to average case reductions and they

21
00:01:03,100 --> 00:01:04,780
also allow for simple and efficient

22
00:01:04,780 --> 00:01:07,119
implementations because in the end it's

23
00:01:07,119 --> 00:01:09,220
just usually matrix vector

24
00:01:09,220 --> 00:01:10,929
multiplications over relatively small

25
00:01:10,929 --> 00:01:13,209
integers and if you go to the ring

26
00:01:13,209 --> 00:01:14,800
setting you might have to multiply ring

27
00:01:14,800 --> 00:01:16,600
elements but still the arithmetic is

28
00:01:16,600 --> 00:01:18,670
usually over small integers and fairly

29
00:01:18,670 --> 00:01:21,670
simple right well there's a caveat here

30
00:01:21,670 --> 00:01:24,069
and this caveat is the disk recursion

31
00:01:24,069 --> 00:01:25,990
sampling which is an operation that is

32
00:01:25,990 --> 00:01:29,289
part of many letter space crypto schemes

33
00:01:29,289 --> 00:01:31,959
and when it comes to the script garden

34
00:01:31,959 --> 00:01:34,119
sampling I would say you can have either

35
00:01:34,119 --> 00:01:36,280
simple or efficient but not really both

36
00:01:36,280 --> 00:01:39,690
and this is what our work addresses and

37
00:01:39,690 --> 00:01:44,649
before going into detail about how we do

38
00:01:44,649 --> 00:01:46,630
that and what we do exactly I want to

39
00:01:46,630 --> 00:01:47,920
quickly define what's this discreet

40
00:01:47,920 --> 00:01:50,470
caution same thing is so discreet ocean

41
00:01:50,470 --> 00:01:53,830
sampling is our algorithms that sample

42
00:01:53,830 --> 00:01:55,720
from a specific distribution and this

43
00:01:55,720 --> 00:01:57,280
distribution is a discrete Gaussian

44
00:01:57,280 --> 00:01:59,950
first we define the Gaussian function as

45
00:01:59,950 --> 00:02:02,020
e to the minus px squared that is a

46
00:02:02,020 --> 00:02:04,420
standard Gaussian function and you can

47
00:02:04,420 --> 00:02:08,739
define a scaled and shifted version of

48
00:02:08,739 --> 00:02:12,459
it by defining or giving a parameter C

49
00:02:12,459 --> 00:02:14,980
and a noise parameter s so C is closest

50
00:02:14,980 --> 00:02:16,599
Center is usually the noise parameter

51
00:02:16,599 --> 00:02:18,370
and you just shift and scale

52
00:02:18,370 --> 00:02:21,430
tribution the function and the discrete

53
00:02:21,430 --> 00:02:24,430
Gaussian is then simply a distribution

54
00:02:24,430 --> 00:02:26,500
that is proportional to this Gaussian

55
00:02:26,500 --> 00:02:30,159
function but restricted to a discrete

56
00:02:30,159 --> 00:02:32,019
set in our case it's going to be mostly

57
00:02:32,019 --> 00:02:33,760
the integers but you can have other sets

58
00:02:33,760 --> 00:02:37,709
there and I have visualized this

59
00:02:37,709 --> 00:02:41,200
distribution here like these are your

60
00:02:41,200 --> 00:02:43,360
elements right on the x axis and every

61
00:02:43,360 --> 00:02:45,610
dot corresponds to the probability of

62
00:02:45,610 --> 00:02:46,930
each of these elements and you get your

63
00:02:46,930 --> 00:02:49,150
typical part of here note that the

64
00:02:49,150 --> 00:02:51,220
center does not have to be an integer

65
00:02:51,220 --> 00:02:54,459
even if the distribution is restricted

66
00:02:54,459 --> 00:02:56,739
to the integers and in fact you can view

67
00:02:56,739 --> 00:02:59,680
discrete Gaussian sampling as a rounding

68
00:02:59,680 --> 00:03:01,810
procedure that rounds the center to a

69
00:03:01,810 --> 00:03:03,840
nearby integer corresponding to these

70
00:03:03,840 --> 00:03:07,450
and to these probabilities okay now

71
00:03:07,450 --> 00:03:10,709
where we encounter two discrete Gaussian

72
00:03:10,709 --> 00:03:13,569
in that displaced crypto well it usually

73
00:03:13,569 --> 00:03:16,599
comes to as in one of two settings and

74
00:03:16,599 --> 00:03:19,599
once setting the which we call the fixed

75
00:03:19,599 --> 00:03:21,069
setting the parameters of the

76
00:03:21,069 --> 00:03:24,849
distribution are fixed so the center s

77
00:03:24,849 --> 00:03:27,609
and the noise parameters so Center C in

78
00:03:27,609 --> 00:03:29,500
tonight's parameter s are fixed once and

79
00:03:29,500 --> 00:03:32,620
for throughout the system and this is

80
00:03:32,620 --> 00:03:35,980
used in most other V based schemes where

81
00:03:35,980 --> 00:03:38,709
the center is 0 if you are familiar with

82
00:03:38,709 --> 00:03:40,900
lwe learning with errors problems the

83
00:03:40,900 --> 00:03:42,879
errors usually follow this distributions

84
00:03:42,879 --> 00:03:44,200
are centered discrete Gaussian with a

85
00:03:44,200 --> 00:03:46,900
fixed parameter s now in the other

86
00:03:46,900 --> 00:03:48,790
setting which we call the generic

87
00:03:48,790 --> 00:03:53,440
setting both both parameters the center

88
00:03:53,440 --> 00:03:55,510
and the noise parameter can be very well

89
00:03:55,510 --> 00:03:59,980
so they vary per query so when I asked

90
00:03:59,980 --> 00:04:02,109
for when I asked the algorithm for for a

91
00:04:02,109 --> 00:04:04,750
sample i specify the center and the

92
00:04:04,750 --> 00:04:06,579
noise parameter and I want to get back a

93
00:04:06,579 --> 00:04:09,419
sample from that specific distribution

94
00:04:09,419 --> 00:04:11,739
yeah from this distribution that is

95
00:04:11,739 --> 00:04:16,089
defined by the CNCs and in the most

96
00:04:16,089 --> 00:04:18,220
prominent application of that of that

97
00:04:18,220 --> 00:04:20,320
setting its latest repto sampling and

98
00:04:20,320 --> 00:04:23,139
the destructor something very popular in

99
00:04:23,139 --> 00:04:24,880
more advanced schemes of lattice based

100
00:04:24,880 --> 00:04:28,690
crypto and usually for encryptions in

101
00:04:28,690 --> 00:04:30,990
the for CCA

102
00:04:30,990 --> 00:04:33,270
encryptions or signatures securing the

103
00:04:33,270 --> 00:04:36,840
standard model or ibe schemes etc so

104
00:04:36,840 --> 00:04:38,580
this is where the descriptive sampling

105
00:04:38,580 --> 00:04:41,370
comes in most of the time and we have

106
00:04:41,370 --> 00:04:43,530
actually quite a few algorithms for the

107
00:04:43,530 --> 00:04:47,910
fixed setting so in the fixed setting

108
00:04:47,910 --> 00:04:49,590
there are several algorithms that

109
00:04:49,590 --> 00:04:51,419
achieve different time memory trade-offs

110
00:04:51,419 --> 00:04:53,759
and they usually achieve that by doing

111
00:04:53,759 --> 00:04:58,229
pre computation based on this the center

112
00:04:58,229 --> 00:05:00,599
and nice parameter which are fixed right

113
00:05:00,599 --> 00:05:01,800
they are fixed so you can do

114
00:05:01,800 --> 00:05:03,330
pre-computation and you can store

115
00:05:03,330 --> 00:05:06,240
information about this and and the most

116
00:05:06,240 --> 00:05:09,000
efficient algorithms for example they

117
00:05:09,000 --> 00:05:11,070
store all the probabilities for every

118
00:05:11,070 --> 00:05:13,139
element in your support of this

119
00:05:13,139 --> 00:05:16,139
distribution in a table and then your

120
00:05:16,139 --> 00:05:18,120
sampling just becomes some sort of

121
00:05:18,120 --> 00:05:19,830
randomized lookup into that table right

122
00:05:19,830 --> 00:05:22,620
and so they store information that is

123
00:05:22,620 --> 00:05:24,750
linear in the bus parameter so this is

124
00:05:24,750 --> 00:05:26,970
good for small distributions as such

125
00:05:26,970 --> 00:05:28,860
distributions grow wide this becomes

126
00:05:28,860 --> 00:05:30,630
impractical but there are different

127
00:05:30,630 --> 00:05:31,500
algorithms that achieve different

128
00:05:31,500 --> 00:05:33,840
trade-offs in the variable or the

129
00:05:33,840 --> 00:05:35,880
generic setting we don't really have

130
00:05:35,880 --> 00:05:38,789
that up to this point and you can see

131
00:05:38,789 --> 00:05:40,500
kind of why because if you don't know

132
00:05:40,500 --> 00:05:42,960
the center into and the noise parameter

133
00:05:42,960 --> 00:05:45,060
of your distribution then what are you

134
00:05:45,060 --> 00:05:49,680
going to compute right and you know in

135
00:05:49,680 --> 00:05:52,400
our work now what we actually do is we

136
00:05:52,400 --> 00:05:55,830
reduce the generic setting to the fixed

137
00:05:55,830 --> 00:05:59,039
setting so will exploit algorithm for

138
00:05:59,039 --> 00:06:01,849
the fixed setting in order to generate

139
00:06:01,849 --> 00:06:04,400
samples from arbitrary distributions and

140
00:06:04,400 --> 00:06:08,490
before I go more into detail about how

141
00:06:08,490 --> 00:06:10,469
we achieve this I want to go over the

142
00:06:10,469 --> 00:06:12,150
structure of the algorithm and tell you

143
00:06:12,150 --> 00:06:14,820
about why we think that it's a good idea

144
00:06:14,820 --> 00:06:16,830
so the high-level overview of the

145
00:06:16,830 --> 00:06:19,110
algorithm is going to be that we start

146
00:06:19,110 --> 00:06:23,699
with two fixed samplers here we are

147
00:06:23,699 --> 00:06:26,219
checking samplers over to Z with the

148
00:06:26,219 --> 00:06:27,060
center 0 & 1

149
00:06:27,060 --> 00:06:28,919
alternatively you can think about them

150
00:06:28,919 --> 00:06:31,560
as being samples over Z with the

151
00:06:31,560 --> 00:06:33,659
center's 0 and 1/2 doesn't really make a

152
00:06:33,659 --> 00:06:35,669
difference and these don't get input

153
00:06:35,669 --> 00:06:39,449
data is produce samples from their fixed

154
00:06:39,449 --> 00:06:44,650
distribution and then our algorithm is

155
00:06:44,650 --> 00:06:49,479
oh yes sorry i got'em just take these

156
00:06:49,479 --> 00:06:52,030
samples gets as input the center and the

157
00:06:52,030 --> 00:06:54,430
noise parameter and then cleverly

158
00:06:54,430 --> 00:06:57,940
combines these in these samples is from

159
00:06:57,940 --> 00:06:59,560
the fixed distribution in a way to

160
00:06:59,560 --> 00:07:04,120
produce the correct distribution and why

161
00:07:04,120 --> 00:07:05,530
do we think this is a good good idea

162
00:07:05,530 --> 00:07:08,590
well on the one hand we can ensure that

163
00:07:08,590 --> 00:07:10,000
a nice parameter of these fixed

164
00:07:10,000 --> 00:07:11,740
distributions it's going to be

165
00:07:11,740 --> 00:07:13,990
relatively small or actually quite small

166
00:07:13,990 --> 00:07:17,500
it's just a constant and so we can take

167
00:07:17,500 --> 00:07:19,150
advantage of the most efficient

168
00:07:19,150 --> 00:07:20,949
algorithms for the fixed setting these

169
00:07:20,949 --> 00:07:24,789
are fixed distributions too without

170
00:07:24,789 --> 00:07:26,889
spending too much memory right and so

171
00:07:26,889 --> 00:07:28,600
this is going to make our I wasn't quite

172
00:07:28,600 --> 00:07:31,150
efficient furthermore and we are not

173
00:07:31,150 --> 00:07:33,039
restricted to two samplers if we have

174
00:07:33,039 --> 00:07:34,960
more memories to spend we can add more

175
00:07:34,960 --> 00:07:36,610
simpler and this will make our

176
00:07:36,610 --> 00:07:39,370
combinations is actually much more much

177
00:07:39,370 --> 00:07:42,310
more efficient so this is where we get a

178
00:07:42,310 --> 00:07:45,340
time memory trade-off for the for the

179
00:07:45,340 --> 00:07:46,660
setting of generic sampling that's

180
00:07:46,660 --> 00:07:49,530
actually the first of its kind

181
00:07:49,590 --> 00:07:52,750
furthermore we see that these samplers

182
00:07:52,750 --> 00:07:54,280
don't get any input right they a

183
00:07:54,280 --> 00:07:57,039
completely independent of the CNCs this

184
00:07:57,039 --> 00:07:59,320
means you can split the I bottom up into

185
00:07:59,320 --> 00:08:00,940
an offline in an online face the offline

186
00:08:00,940 --> 00:08:03,340
face simply produces these samples you

187
00:08:03,340 --> 00:08:04,870
can pre-compute them or store them

188
00:08:04,870 --> 00:08:07,479
somewhere and then the online face just

189
00:08:07,479 --> 00:08:10,419
combine these samples together and using

190
00:08:10,419 --> 00:08:12,970
very simple arithmetic and so the online

191
00:08:12,970 --> 00:08:14,229
face of our algorithm is actually

192
00:08:14,229 --> 00:08:17,169
extremely fast and so this allows you to

193
00:08:17,169 --> 00:08:19,300
to split this algorithm and for example

194
00:08:19,300 --> 00:08:22,060
just to pre-computation and store it on

195
00:08:22,060 --> 00:08:23,590
a device for example if you have like a

196
00:08:23,590 --> 00:08:25,449
small device you can just store your

197
00:08:25,449 --> 00:08:29,470
samples there and think or for example

198
00:08:29,470 --> 00:08:31,210
you have a web server that has idle

199
00:08:31,210 --> 00:08:32,559
times where you can just produce in

200
00:08:32,559 --> 00:08:34,179
prove them and the web server it's not

201
00:08:34,179 --> 00:08:37,208
doing anything else or you can actually

202
00:08:37,208 --> 00:08:39,400
separate the algorithms in two separate

203
00:08:39,400 --> 00:08:41,919
systems where this is done for example

204
00:08:41,919 --> 00:08:43,360
in a hot one mortals that it's

205
00:08:43,360 --> 00:08:45,190
specialized to this setting and we have

206
00:08:45,190 --> 00:08:47,260
algorithms that are that run really fast

207
00:08:47,260 --> 00:08:49,300
and hardware for the fixed set not so

208
00:08:49,300 --> 00:08:52,630
much for the generic side and so um and

209
00:08:52,630 --> 00:08:54,279
if you do this in parallel well then

210
00:08:54,279 --> 00:08:56,709
again is offline phase is is basically

211
00:08:56,709 --> 00:08:57,769
for free

212
00:08:57,769 --> 00:09:06,470
and last but not least this we insure

213
00:09:06,470 --> 00:09:08,449
actually or or I was naturally ensures

214
00:09:08,449 --> 00:09:12,009
that every output sample of our sampler

215
00:09:12,009 --> 00:09:15,079
uses the same sound same amount of base

216
00:09:15,079 --> 00:09:19,249
samples so the input for every query may

217
00:09:19,249 --> 00:09:22,399
be that we give to our to our sampler is

218
00:09:22,399 --> 00:09:24,679
the number of base samples that it

219
00:09:24,679 --> 00:09:26,569
consumes it's exactly the same amount

220
00:09:26,569 --> 00:09:27,949
and actually the number of step is

221
00:09:27,949 --> 00:09:30,649
naturally the same amount so the online

222
00:09:30,649 --> 00:09:32,569
phase of our algorithm is sort of

223
00:09:32,569 --> 00:09:34,309
naturally constant time and if you

224
00:09:34,309 --> 00:09:37,009
implement the arithmetic operations in

225
00:09:37,009 --> 00:09:38,689
the sampler in constant time you

226
00:09:38,689 --> 00:09:41,119
immediately get a constant time online

227
00:09:41,119 --> 00:09:44,480
phase and then separating out the

228
00:09:44,480 --> 00:09:46,939
offline phase or sampling these in large

229
00:09:46,939 --> 00:09:50,600
batches will give you very easily a

230
00:09:50,600 --> 00:09:52,910
constant time algorithm without paying a

231
00:09:52,910 --> 00:09:55,879
large penalty in inefficiency and that

232
00:09:55,879 --> 00:09:57,230
is actually quite unusual for discrete

233
00:09:57,230 --> 00:09:59,360
version something which has been

234
00:09:59,360 --> 00:10:01,279
traditionally hard to do in constant

235
00:10:01,279 --> 00:10:03,410
time and yeah so there you have it

236
00:10:03,410 --> 00:10:05,660
that's the three adjectives that we

237
00:10:05,660 --> 00:10:08,569
claim the paper it is our sampler is

238
00:10:08,569 --> 00:10:12,319
generic it it can be implemented very

239
00:10:12,319 --> 00:10:14,389
efficiently and it can also be

240
00:10:14,389 --> 00:10:15,759
implemented in constant time without

241
00:10:15,759 --> 00:10:18,889
much much overhead hardly any overhead

242
00:10:18,889 --> 00:10:21,290
actually so now I want to talk a bit

243
00:10:21,290 --> 00:10:23,480
more about how we actually achieve this

244
00:10:23,480 --> 00:10:25,459
and where these to memory trade-offs and

245
00:10:25,459 --> 00:10:28,240
this offering online face cuts drop so

246
00:10:28,240 --> 00:10:31,730
our main tool is going to be convolution

247
00:10:31,730 --> 00:10:33,290
and there's a bunch of convolution

248
00:10:33,290 --> 00:10:37,639
theorems in the literature and they all

249
00:10:37,639 --> 00:10:39,679
kind of have the same the same flavor

250
00:10:39,679 --> 00:10:42,589
you start out with two or more based

251
00:10:42,589 --> 00:10:45,949
distribution these are fixes like t1 and

252
00:10:45,949 --> 00:10:48,169
t2 and you produce a sample from each of

253
00:10:48,169 --> 00:10:51,169
them and then convolution theorems tell

254
00:10:51,169 --> 00:10:53,089
you that you can combine them in

255
00:10:53,089 --> 00:10:54,919
specific ways to generate a different

256
00:10:54,919 --> 00:10:56,839
distribution so if you combine the

257
00:10:56,839 --> 00:10:58,819
samples from these distributions your

258
00:10:58,819 --> 00:11:00,350
output is going to be a different

259
00:11:00,350 --> 00:11:02,179
distribution and you can see all this

260
00:11:02,179 --> 00:11:03,679
like might help us right if you have

261
00:11:03,679 --> 00:11:05,720
like six distributions if you combine

262
00:11:05,720 --> 00:11:06,889
them in the right ways we got out

263
00:11:06,889 --> 00:11:09,110
different distributions now getting out

264
00:11:09,110 --> 00:11:10,670
the core

265
00:11:10,670 --> 00:11:13,540
distributions that we actually want is

266
00:11:13,540 --> 00:11:17,450
not trivial but you actually requires a

267
00:11:17,450 --> 00:11:18,590
lot of work otherwise this wouldn't be a

268
00:11:18,590 --> 00:11:23,900
cryptic presentation but so it's not

269
00:11:23,900 --> 00:11:25,520
entirely of this idea so it has been

270
00:11:25,520 --> 00:11:28,490
used before in the fixed setting we call

271
00:11:28,490 --> 00:11:30,560
that the most efficient algorithms

272
00:11:30,560 --> 00:11:33,860
require storage linear and noise

273
00:11:33,860 --> 00:11:35,810
parameters so if you have a fixed

274
00:11:35,810 --> 00:11:37,400
distribution that has a large noise

275
00:11:37,400 --> 00:11:39,650
parameter you can use this convolution

276
00:11:39,650 --> 00:11:42,230
to reduce a memory overhead to produce

277
00:11:42,230 --> 00:11:43,790
samples from a from the smaller

278
00:11:43,790 --> 00:11:45,530
distributions and then combine them into

279
00:11:45,530 --> 00:11:47,270
a big one and that has been used before

280
00:11:47,270 --> 00:11:51,650
we generalize generalize this idea

281
00:11:51,650 --> 00:11:53,540
little and analyzes in the more general

282
00:11:53,540 --> 00:11:55,310
setting and we use a similar technique

283
00:11:55,310 --> 00:11:57,410
to make sure that our base center have

284
00:11:57,410 --> 00:11:59,990
small noise right and so this shows if

285
00:11:59,990 --> 00:12:01,610
we have some leverage with regards to

286
00:12:01,610 --> 00:12:04,520
the noise parameter what I want to focus

287
00:12:04,520 --> 00:12:07,970
on in this talk though is the second

288
00:12:07,970 --> 00:12:11,420
parameter how we handle how we handle

289
00:12:11,420 --> 00:12:13,160
different parts and different centers

290
00:12:13,160 --> 00:12:19,040
that we get as input and for that and we

291
00:12:19,040 --> 00:12:23,960
call that the goal of or the view of the

292
00:12:23,960 --> 00:12:26,930
ocean sampling is that you get a center

293
00:12:26,930 --> 00:12:28,310
and you try to round it to a nearby

294
00:12:28,310 --> 00:12:30,920
integer but instead of doing that in one

295
00:12:30,920 --> 00:12:33,170
step what we're going to do is we're

296
00:12:33,170 --> 00:12:35,810
going to round the center step by step

297
00:12:35,810 --> 00:12:38,060
to a coarser and coarser grid until it

298
00:12:38,060 --> 00:12:40,340
is indeed like an element in the

299
00:12:40,340 --> 00:12:41,450
integers and this is going to be the

300
00:12:41,450 --> 00:12:45,860
output sample and this each individual

301
00:12:45,860 --> 00:12:47,630
step we're going to make sure that this

302
00:12:47,630 --> 00:12:50,420
every individual step it's being rounded

303
00:12:50,420 --> 00:12:53,600
by a discrete Gaussian and then the

304
00:12:53,600 --> 00:12:55,010
convolution theorem is actually going to

305
00:12:55,010 --> 00:12:56,900
tell us that the final result is

306
00:12:56,900 --> 00:12:59,120
actually also going to be discrete

307
00:12:59,120 --> 00:13:02,260
Gaussian with the correct center so I

308
00:13:02,260 --> 00:13:04,780
know this is a little vague but

309
00:13:04,780 --> 00:13:06,410
unfortunately don't really have time to

310
00:13:06,410 --> 00:13:08,540
go much more into detail this is just to

311
00:13:08,540 --> 00:13:10,610
give you a sense of of how the algorithm

312
00:13:10,610 --> 00:13:13,640
works and so now the question is how do

313
00:13:13,640 --> 00:13:16,250
we do every individual step just using

314
00:13:16,250 --> 00:13:18,500
our fixed number of base samplers just

315
00:13:18,500 --> 00:13:22,580
using two bass samplers and well the

316
00:13:22,580 --> 00:13:23,870
idea is

317
00:13:23,870 --> 00:13:26,810
we assume that see like our Center that

318
00:13:26,810 --> 00:13:29,480
we're giving the parameter is an element

319
00:13:29,480 --> 00:13:32,330
in Z over 2 to the K so it has a K bit

320
00:13:32,330 --> 00:13:36,770
binary expansion and our goal is for

321
00:13:36,770 --> 00:13:40,790
this step to round it to a center in the

322
00:13:40,790 --> 00:13:42,560
over 2 to the K minus 1 so we went

323
00:13:42,560 --> 00:13:44,930
around just the last bit by a discrete

324
00:13:44,930 --> 00:13:49,880
version and we do this by sampling our

325
00:13:49,880 --> 00:13:51,950
base or drawing a sample from our base

326
00:13:51,950 --> 00:13:54,230
sampler with Center defined by the bit

327
00:13:54,230 --> 00:13:57,110
so last bitten in the center right and

328
00:13:57,110 --> 00:14:01,160
we draw the sample and then we add the

329
00:14:01,160 --> 00:14:04,040
center back to it and scale it by 2 to

330
00:14:04,040 --> 00:14:08,330
the K now note that X is actually a

331
00:14:08,330 --> 00:14:11,690
central it sent a sample into Z so it's

332
00:14:11,690 --> 00:14:13,940
not actually in Z its into Z and so X

333
00:14:13,940 --> 00:14:19,430
plus B K over 2 to the K the last bit of

334
00:14:19,430 --> 00:14:21,500
the new X is actually going to be also

335
00:14:21,500 --> 00:14:25,430
be K right because X is an even number

336
00:14:25,430 --> 00:14:31,100
so if BK is 0 X remains even if because

337
00:14:31,100 --> 00:14:33,680
one X is an odd integer right and then

338
00:14:33,680 --> 00:14:35,600
if I scale it by 2 to the K the last bit

339
00:14:35,600 --> 00:14:38,420
is going to be the exactly BK and so if

340
00:14:38,420 --> 00:14:42,740
we subtract it from C the last the last

341
00:14:42,740 --> 00:14:45,470
bit of C is going to be 0 so C is

342
00:14:45,470 --> 00:14:47,270
actually now going to be in 2 to the K

343
00:14:47,270 --> 00:14:48,920
minus 1 which was exactly the goal and

344
00:14:48,920 --> 00:14:50,900
this is actually a valid discrete

345
00:14:50,900 --> 00:14:54,740
version rounding and so we do this step

346
00:14:54,740 --> 00:14:58,160
by step and until our C is actually

347
00:14:58,160 --> 00:15:00,230
going to be in element in Z and we get

348
00:15:00,230 --> 00:15:02,570
exactly a discrete Gaussian with the

349
00:15:02,570 --> 00:15:06,260
correct center ok now where do our time

350
00:15:06,260 --> 00:15:08,930
memory trade-offs come from well it

351
00:15:08,930 --> 00:15:10,730
mostly comes from the fact that you

352
00:15:10,730 --> 00:15:12,980
don't have to express C in binary you

353
00:15:12,980 --> 00:15:16,310
can express it in different bases so for

354
00:15:16,310 --> 00:15:20,089
example if you express it and with with

355
00:15:20,089 --> 00:15:23,450
regards to base 8 for example then this

356
00:15:23,450 --> 00:15:25,520
means you have a third of the digit

357
00:15:25,520 --> 00:15:27,800
right like every every 3 bits are going

358
00:15:27,800 --> 00:15:30,290
to be transformed into one digit and

359
00:15:30,290 --> 00:15:32,720
base 8 and then you can round every

360
00:15:32,720 --> 00:15:34,670
every digit individually and you're only

361
00:15:34,670 --> 00:15:36,440
only going to make a third of the steps

362
00:15:36,440 --> 00:15:37,730
but

363
00:15:37,730 --> 00:15:41,029
now you need samples not over to Z but

364
00:15:41,029 --> 00:15:43,669
you need it from 80 and more so you need

365
00:15:43,669 --> 00:15:45,769
it for every possible Co set of 80 so

366
00:15:45,769 --> 00:15:49,369
you need a tea with centers in 0 1 2 up

367
00:15:49,369 --> 00:15:52,189
to 7 right so you need 7 samplers

368
00:15:52,189 --> 00:15:54,980
a tempest which you know like you need

369
00:15:54,980 --> 00:15:56,419
more memory to store these efficient

370
00:15:56,419 --> 00:15:59,989
samplers but your your combining

371
00:15:59,989 --> 00:16:02,209
algorithm is going to run in the third

372
00:16:02,209 --> 00:16:04,730
of the time so there is a time memory

373
00:16:04,730 --> 00:16:07,970
trader the constant time I would

374
00:16:07,970 --> 00:16:11,929
essentially stems from the fact that no

375
00:16:11,929 --> 00:16:13,669
matter which Center we get we use the

376
00:16:13,669 --> 00:16:16,129
same we need the same number of of steps

377
00:16:16,129 --> 00:16:19,939
and this comes from the idea that we can

378
00:16:19,939 --> 00:16:23,470
assume that the center has a finite bit

379
00:16:23,470 --> 00:16:25,609
expression no matter which base you use

380
00:16:25,609 --> 00:16:29,720
and and the fundamental idea of why we

381
00:16:29,720 --> 00:16:32,269
can assume that is that we don't

382
00:16:32,269 --> 00:16:36,379
actually need to necessarily produce the

383
00:16:36,379 --> 00:16:38,540
correct output distribution but it's

384
00:16:38,540 --> 00:16:41,299
it's ok if we're just approximate the

385
00:16:41,299 --> 00:16:42,799
output distribution it's the ideal

386
00:16:42,799 --> 00:16:44,720
discrete Gaussian and most algorithms

387
00:16:44,720 --> 00:16:46,220
actually do that most algorithms don't

388
00:16:46,220 --> 00:16:47,799
produce the exact distribution that will

389
00:16:47,799 --> 00:16:51,499
produce an approximate distribution and

390
00:16:51,499 --> 00:16:54,589
this is usually good enough but good

391
00:16:54,589 --> 00:16:55,910
enough you have to kind of quantify

392
00:16:55,910 --> 00:17:00,470
right so there are several tools out

393
00:17:00,470 --> 00:17:03,169
there to quantify this the security to

394
00:17:03,169 --> 00:17:06,559
approximation trade-off and the most

395
00:17:06,559 --> 00:17:09,099
classical one is a statistical distance

396
00:17:09,099 --> 00:17:11,990
which has been classically used to to

397
00:17:11,990 --> 00:17:14,779
evaluate how close you need to be to the

398
00:17:14,779 --> 00:17:16,880
to the discrete Gaussian in order to

399
00:17:16,880 --> 00:17:20,419
preserve security and the statistical

400
00:17:20,419 --> 00:17:21,919
distance is actually a very nice tool to

401
00:17:21,919 --> 00:17:24,349
use in the analysis because it has a

402
00:17:24,349 --> 00:17:25,760
simple definition you can get easy

403
00:17:25,760 --> 00:17:27,829
bounce on it and it is a metric which

404
00:17:27,829 --> 00:17:32,360
makes it very easy to analyze even yeah

405
00:17:32,360 --> 00:17:35,600
more complex algorithms that involve a

406
00:17:35,600 --> 00:17:37,580
lot of steps that can lose distance to

407
00:17:37,580 --> 00:17:41,059
the ideal distribution so this is very

408
00:17:41,059 --> 00:17:44,000
nice but more recently the KL divergence

409
00:17:44,000 --> 00:17:48,740
as been has becoming more popular or

410
00:17:48,740 --> 00:17:51,090
other divergences actually I'm

411
00:17:51,090 --> 00:17:52,679
choosing the kayo diversion as a more

412
00:17:52,679 --> 00:17:54,629
popular tool but other ones are possible

413
00:17:54,629 --> 00:17:59,220
and Caleb urchin does the name say it

414
00:17:59,220 --> 00:18:01,769
says it's not a metric so it's a little

415
00:18:01,769 --> 00:18:04,019
harder to use but if you do use it

416
00:18:04,019 --> 00:18:05,850
you're good get actually a much stronger

417
00:18:05,850 --> 00:18:08,850
security prove out of it and the like

418
00:18:08,850 --> 00:18:11,070
one of the killer arguments for the KL

419
00:18:11,070 --> 00:18:13,110
divergence is that you can in many

420
00:18:13,110 --> 00:18:15,120
settings you can get away with just

421
00:18:15,120 --> 00:18:17,700
computing with for example 50 bit

422
00:18:17,700 --> 00:18:19,559
floating point numbers and you get more

423
00:18:19,559 --> 00:18:21,629
than 100 with security out of it like a

424
00:18:21,629 --> 00:18:24,090
bit level of more than 100 bits and that

425
00:18:24,090 --> 00:18:28,289
is if you think about current opera or

426
00:18:28,289 --> 00:18:30,480
more if you think about current computer

427
00:18:30,480 --> 00:18:32,129
architectures that is a very strong

428
00:18:32,129 --> 00:18:33,749
argument for using the KL divergence

429
00:18:33,749 --> 00:18:36,269
because it gives you an order of

430
00:18:36,269 --> 00:18:40,889
magnitude speed-up versus versus multi

431
00:18:40,889 --> 00:18:43,279
our arbitrary bit precision numbers

432
00:18:43,279 --> 00:18:46,200
which you would require 400 bits of

433
00:18:46,200 --> 00:18:48,450
security if you were using the

434
00:18:48,450 --> 00:18:50,279
statistical distance in order to analyze

435
00:18:50,279 --> 00:19:00,690
your your distribution and so so we want

436
00:19:00,690 --> 00:19:04,499
it a nice tool to to analyze our

437
00:19:04,499 --> 00:19:06,299
algorithms and we also wanted strong

438
00:19:06,299 --> 00:19:10,350
security and so what we did we we were

439
00:19:10,350 --> 00:19:11,759
hoping to trying to get something the

440
00:19:11,759 --> 00:19:13,619
best of both worlds and we ended up

441
00:19:13,619 --> 00:19:15,119
defining our own metric because we

442
00:19:15,119 --> 00:19:16,740
didn't find one that suited our needs

443
00:19:16,740 --> 00:19:18,990
and this one has a pretty simple

444
00:19:18,990 --> 00:19:21,539
definition it's just the infinitive name

445
00:19:21,539 --> 00:19:24,269
norm of the difference of the locks of

446
00:19:24,269 --> 00:19:26,519
the two distributions and as it turns

447
00:19:26,519 --> 00:19:31,649
out this is this is a metric you can see

448
00:19:31,649 --> 00:19:34,529
that because it's just yeah it's a

449
00:19:34,529 --> 00:19:35,879
version of the Infinity matrix oh it's

450
00:19:35,879 --> 00:19:41,009
an infinity norm of the Infinity norm of

451
00:19:41,009 --> 00:19:44,940
a function of the of the different

452
00:19:44,940 --> 00:19:49,499
vectors and then you also get the strong

453
00:19:49,499 --> 00:19:50,669
security bound actually we show that in

454
00:19:50,669 --> 00:19:51,059
the paper

455
00:19:51,059 --> 00:19:53,340
so showing that this is the metric it's

456
00:19:53,340 --> 00:19:54,960
actually not that hard showing that it

457
00:19:54,960 --> 00:19:57,149
has strong security properties is

458
00:19:57,149 --> 00:19:58,710
actually a little bit more involved and

459
00:19:58,710 --> 00:20:00,809
we do that in the paper and then we use

460
00:20:00,809 --> 00:20:02,519
this max lock distance in order to show

461
00:20:02,519 --> 00:20:04,920
that an hour

462
00:20:04,920 --> 00:20:06,960
she achieves good approximation even for

463
00:20:06,960 --> 00:20:08,910
floating-point numbers and you get

464
00:20:08,910 --> 00:20:11,610
strong bones on the max max log distance

465
00:20:11,610 --> 00:20:14,550
because in the regime where they are

466
00:20:14,550 --> 00:20:15,960
very small it's essentially equivalent

467
00:20:15,960 --> 00:20:18,030
to the relative error which is exactly

468
00:20:18,030 --> 00:20:19,620
what floating-point numbers give you so

469
00:20:19,620 --> 00:20:21,480
if you have a 50 bit floating point

470
00:20:21,480 --> 00:20:22,430
number

471
00:20:22,430 --> 00:20:25,770
then you exactly get approximation error

472
00:20:25,770 --> 00:20:28,170
or relative error of 2 to the minus 50

473
00:20:28,170 --> 00:20:31,050
and then your ml distance is also going

474
00:20:31,050 --> 00:20:34,460
to be pretty much 2 to the minus 50 okay

475
00:20:34,460 --> 00:20:38,190
this is all I actually planned for but I

476
00:20:38,190 --> 00:20:39,540
have a few more minutes so allow me a

477
00:20:39,540 --> 00:20:42,360
couple of remarks first in a follow-up

478
00:20:42,360 --> 00:20:44,390
work actually too much place showed that

479
00:20:44,390 --> 00:20:48,410
by relating this max what distance two

480
00:20:48,410 --> 00:20:50,970
different divergences like rainy

481
00:20:50,970 --> 00:20:53,900
divergence and that hour I was actually

482
00:20:53,900 --> 00:20:56,400
has much stronger security properties

483
00:20:56,400 --> 00:20:59,520
even if you restrict a bit security

484
00:20:59,520 --> 00:21:02,670
definition a little bit and also if

485
00:21:02,670 --> 00:21:05,190
you're interested in an algorithm and

486
00:21:05,190 --> 00:21:06,810
like more in a practical sense we do

487
00:21:06,810 --> 00:21:09,630
have a reference implementation on my

488
00:21:09,630 --> 00:21:11,820
website Google my name and UCSD and

489
00:21:11,820 --> 00:21:15,210
you'll find it ok I am happy to take any

490
00:21:15,210 --> 00:21:16,800
questions thank you

491
00:21:16,800 --> 00:21:23,309
[Applause]

