1
00:00:00,160 --> 00:00:01,760
hello everyone my name is michelle

2
00:00:01,760 --> 00:00:03,040
eifler and i will present to you the

3
00:00:03,040 --> 00:00:05,359
electrical sse and ssd page efficient

4
00:00:05,359 --> 00:00:07,120
virtual symmetric encryption this is

5
00:00:07,120 --> 00:00:08,960
trying to work with breeze menu pierre

6
00:00:08,960 --> 00:00:11,840
 rafael bost and angel bossier

7
00:00:11,840 --> 00:00:14,480
so now i want to quickly motivate how

8
00:00:14,480 --> 00:00:18,400
and why sse is useful so

9
00:00:18,400 --> 00:00:20,800
say you have information that you don't

10
00:00:20,800 --> 00:00:22,800
want anyone to have access to say

11
00:00:22,800 --> 00:00:25,039
confidential messages

12
00:00:25,039 --> 00:00:27,279
or you know information about the aliens

13
00:00:27,279 --> 00:00:29,039
that of course the public should not

14
00:00:29,039 --> 00:00:31,679
know about or you would have information

15
00:00:31,679 --> 00:00:33,600
about the one ring and of course someone

16
00:00:33,600 --> 00:00:35,120
should not access this information in

17
00:00:35,120 --> 00:00:37,280
order to avoid destruction of the world

18
00:00:37,280 --> 00:00:39,600
well more concretely we have

19
00:00:39,600 --> 00:00:42,559
information so a bunch of documents

20
00:00:42,559 --> 00:00:45,200
and each of those documents contain

21
00:00:45,200 --> 00:00:47,039
information about certain keywords so

22
00:00:47,039 --> 00:00:50,320
here in blue for example messages aliens

23
00:00:50,320 --> 00:00:52,000
or the ring

24
00:00:52,000 --> 00:00:54,640
and each of those keyboards

25
00:00:54,640 --> 00:00:56,559
appear in certain documents and these

26
00:00:56,559 --> 00:00:58,800
documents are identified by document

27
00:00:58,800 --> 00:01:01,440
identifiers so now we want to outsource

28
00:01:01,440 --> 00:01:03,280
this private information and we can do

29
00:01:03,280 --> 00:01:04,959
so by using symmetric searchable

30
00:01:04,959 --> 00:01:06,080
encryption

31
00:01:06,080 --> 00:01:08,640
for this we have a setup phase so here

32
00:01:08,640 --> 00:01:10,400
the client will generally

33
00:01:10,400 --> 00:01:13,040
encrypt the keyword identifier pairs and

34
00:01:13,040 --> 00:01:14,560
also be documents

35
00:01:14,560 --> 00:01:16,479
and then send encrypted versions of

36
00:01:16,479 --> 00:01:18,400
those with potentially additional

37
00:01:18,400 --> 00:01:19,759
information

38
00:01:19,759 --> 00:01:21,759
to the server then the server stores

39
00:01:21,759 --> 00:01:25,040
this and later on the client can

40
00:01:25,040 --> 00:01:26,400
can query

41
00:01:26,400 --> 00:01:27,600
keywords

42
00:01:27,600 --> 00:01:30,079
um and then the server can answer these

43
00:01:30,079 --> 00:01:32,240
queries it's important to note though

44
00:01:32,240 --> 00:01:34,720
that we can't just send the keyword ring

45
00:01:34,720 --> 00:01:37,040
for example directly because everything

46
00:01:37,040 --> 00:01:38,320
is encrypted

47
00:01:38,320 --> 00:01:40,720
so the server can't really

48
00:01:40,720 --> 00:01:42,399
search without additional information

49
00:01:42,399 --> 00:01:44,560
and this additional information that is

50
00:01:44,560 --> 00:01:46,799
required to search

51
00:01:46,799 --> 00:01:49,439
certain keywords is a token

52
00:01:49,439 --> 00:01:51,360
in this case for example the token ring

53
00:01:51,360 --> 00:01:54,240
will enable the server to output all the

54
00:01:54,240 --> 00:01:56,960
identifiers and then server can send the

55
00:01:56,960 --> 00:01:58,079
encrypted

56
00:01:58,079 --> 00:02:00,320
identifiers that match the keyword ring

57
00:02:00,320 --> 00:02:03,520
to the client and then the client can

58
00:02:03,520 --> 00:02:04,960
of course decrypt all of these

59
00:02:04,960 --> 00:02:06,399
identifiers and then later on

60
00:02:06,399 --> 00:02:08,080
potentially retrieve all the matching

61
00:02:08,080 --> 00:02:09,199
documents

62
00:02:09,199 --> 00:02:12,080
from the server for security we look at

63
00:02:12,080 --> 00:02:13,040
an

64
00:02:13,040 --> 00:02:15,200
at an honest but curious adversary model

65
00:02:15,200 --> 00:02:18,000
so the server will try to learn as much

66
00:02:18,000 --> 00:02:20,400
information as possible about all of our

67
00:02:20,400 --> 00:02:21,280
data

68
00:02:21,280 --> 00:02:23,920
but we can assume that he adheres to all

69
00:02:23,920 --> 00:02:26,720
the protocols honestly

70
00:02:26,720 --> 00:02:29,840
so in general sse is very efficient we

71
00:02:29,840 --> 00:02:32,160
only use at least in symmetric

72
00:02:32,160 --> 00:02:33,760
searchable encryption

73
00:02:33,760 --> 00:02:36,640
symmetric primitives usually it's hash

74
00:02:36,640 --> 00:02:40,239
functions prf's or symmetric encryption

75
00:02:40,239 --> 00:02:42,480
and this of course is very fast though

76
00:02:42,480 --> 00:02:44,640
in general the cryptographic overhead is

77
00:02:44,640 --> 00:02:45,840
actually

78
00:02:45,840 --> 00:02:47,920
fairly low but in order to still be

79
00:02:47,920 --> 00:02:50,000
competitive with databases that don't

80
00:02:50,000 --> 00:02:51,920
have any privacy guarantees we actually

81
00:02:51,920 --> 00:02:54,239
need to look at memory accesses

82
00:02:54,239 --> 00:02:55,760
and for this of course it's important to

83
00:02:55,760 --> 00:02:57,599
know how memory is actually built and

84
00:02:57,599 --> 00:02:59,599
what memory we're using

85
00:02:59,599 --> 00:03:00,319
so

86
00:03:00,319 --> 00:03:02,159
in general there's two big types of

87
00:03:02,159 --> 00:03:05,519
memories hdds so

88
00:03:05,519 --> 00:03:07,920
hard disk drives where locality matters

89
00:03:07,920 --> 00:03:11,760
and ssds where page efficiency matters

90
00:03:11,760 --> 00:03:14,400
so locality measures the number of red

91
00:03:14,400 --> 00:03:16,640
non-adjacent memory locations because

92
00:03:16,640 --> 00:03:19,840
sgds can read very fast actually

93
00:03:19,840 --> 00:03:22,239
adjacent memory locations so the higher

94
00:03:22,239 --> 00:03:25,440
this number the slower the read will be

95
00:03:25,440 --> 00:03:27,760
on the other hand ssds only care about

96
00:03:27,760 --> 00:03:31,040
the number of red pages per query so

97
00:03:31,040 --> 00:03:33,360
pages will actually be a few kilobytes

98
00:03:33,360 --> 00:03:36,480
large maybe four kilobytes for example

99
00:03:36,480 --> 00:03:37,440
and

100
00:03:37,440 --> 00:03:39,760
reading a single page is essentially as

101
00:03:39,760 --> 00:03:41,840
efficient as reading

102
00:03:41,840 --> 00:03:45,280
um just a few bytes of information from

103
00:03:45,280 --> 00:03:46,799
a single page so in general you will

104
00:03:46,799 --> 00:03:48,400
read the entire page

105
00:03:48,400 --> 00:03:51,200
and this is why for page efficiency you

106
00:03:51,200 --> 00:03:52,959
only actually care about the number of

107
00:03:52,959 --> 00:03:54,959
pages you read

108
00:03:54,959 --> 00:03:56,799
but if we look into the research

109
00:03:56,799 --> 00:03:59,680
progress of sse we actually find that

110
00:03:59,680 --> 00:04:01,920
page efficiency and ssd was actually not

111
00:04:01,920 --> 00:04:03,519
studied at all yet

112
00:04:03,519 --> 00:04:06,400
so what happened was that in 2006 the

113
00:04:06,400 --> 00:04:08,400
first sse scheme with good security

114
00:04:08,400 --> 00:04:09,519
guarantees

115
00:04:09,519 --> 00:04:12,640
and also good efficiency was constructed

116
00:04:12,640 --> 00:04:14,400
then a breakthrough work of cash into

117
00:04:14,400 --> 00:04:17,120
zahra from 2014 they showed that it's

118
00:04:17,120 --> 00:04:18,798
actually impossible to have locality

119
00:04:18,798 --> 00:04:20,639
reach efficiency and storage efficiency

120
00:04:20,639 --> 00:04:21,759
constant

121
00:04:21,759 --> 00:04:24,479
at the same time so as a consequence we

122
00:04:24,479 --> 00:04:26,560
can never be as good as a database that

123
00:04:26,560 --> 00:04:28,479
has no security guarantees

124
00:04:28,479 --> 00:04:29,919
efficiency-wise

125
00:04:29,919 --> 00:04:32,400
if we care about locality so if we

126
00:04:32,400 --> 00:04:34,720
outsource our database

127
00:04:34,720 --> 00:04:36,400
on

128
00:04:36,400 --> 00:04:38,080
on hdds

129
00:04:38,080 --> 00:04:39,919
despite this result there's a bunch of

130
00:04:39,919 --> 00:04:42,400
photo artworks that try to construct sse

131
00:04:42,400 --> 00:04:43,360
schemes

132
00:04:43,360 --> 00:04:46,000
that are as close to optimal as possible

133
00:04:46,000 --> 00:04:48,320
so for example ns18

134
00:04:48,320 --> 00:04:49,440
we have

135
00:04:49,440 --> 00:04:51,440
log log locality

136
00:04:51,440 --> 00:04:54,240
and of one read and storage efficiency

137
00:04:54,240 --> 00:04:56,000
so it's actually very close to optimal

138
00:04:56,000 --> 00:04:57,840
but because crash onto sarah showed it's

139
00:04:57,840 --> 00:05:00,000
not possible and we can never hope for

140
00:05:00,000 --> 00:05:01,360
something better

141
00:05:01,360 --> 00:05:02,960
and in this work we actually inspect

142
00:05:02,960 --> 00:05:04,560
page efficiency

143
00:05:04,560 --> 00:05:06,479
and we actually showed that

144
00:05:06,479 --> 00:05:08,880
if you con if you want to construct a

145
00:05:08,880 --> 00:05:11,520
page efficient scheme that also has

146
00:05:11,520 --> 00:05:13,600
perfect storage efficiency so constant

147
00:05:13,600 --> 00:05:15,680
storage efficiency it's actually

148
00:05:15,680 --> 00:05:17,680
possible so

149
00:05:17,680 --> 00:05:19,919
there's no such lower bound

150
00:05:19,919 --> 00:05:23,199
at least in the static case

151
00:05:23,199 --> 00:05:26,479
for page efficient sse schemes

152
00:05:26,479 --> 00:05:28,639
and we named our scheme tatters because

153
00:05:28,639 --> 00:05:30,960
it uses a max flow computation and tetus

154
00:05:30,960 --> 00:05:32,479
in greek mythology

155
00:05:32,479 --> 00:05:34,960
is the mother of all river gods

156
00:05:34,960 --> 00:05:36,400
so

157
00:05:36,400 --> 00:05:39,600
as a recap what we care about is

158
00:05:39,600 --> 00:05:42,240
page efficiency we want to minimize page

159
00:05:42,240 --> 00:05:45,120
access accesses per query we care about

160
00:05:45,120 --> 00:05:47,039
storage efficiency we want to minimize

161
00:05:47,039 --> 00:05:49,199
the server storage and we care about

162
00:05:49,199 --> 00:05:52,880
security so we want to guarantee um

163
00:05:52,880 --> 00:05:54,400
that there's as little leaked

164
00:05:54,400 --> 00:05:56,720
information as possible

165
00:05:56,720 --> 00:05:59,360
in order to be a bit more concrete about

166
00:05:59,360 --> 00:06:01,360
the security guarantees that we have i

167
00:06:01,360 --> 00:06:03,440
will quickly sketch the security model

168
00:06:03,440 --> 00:06:05,680
in static sse schemes

169
00:06:05,680 --> 00:06:07,120
so

170
00:06:07,120 --> 00:06:08,520
in general we have an

171
00:06:08,520 --> 00:06:10,560
indistinguishability based security

172
00:06:10,560 --> 00:06:12,240
definition

173
00:06:12,240 --> 00:06:14,319
where the client interacts with the

174
00:06:14,319 --> 00:06:16,240
server and the server is the adversary

175
00:06:16,240 --> 00:06:19,280
so again he's honest but curious

176
00:06:19,280 --> 00:06:21,520
so in the beginning the

177
00:06:21,520 --> 00:06:24,479
server will specify a database

178
00:06:24,479 --> 00:06:26,479
and then the client will

179
00:06:26,479 --> 00:06:30,000
set up the database using the sse setup

180
00:06:30,000 --> 00:06:31,600
functionality

181
00:06:31,600 --> 00:06:35,440
and then send the encrypted database to

182
00:06:35,440 --> 00:06:37,039
the client

183
00:06:37,039 --> 00:06:38,880
then the client

184
00:06:38,880 --> 00:06:41,840
will have to query by the adversary

185
00:06:41,840 --> 00:06:44,240
specified keywords so he will send the

186
00:06:44,240 --> 00:06:46,960
query token to the server

187
00:06:46,960 --> 00:06:48,720
and then the server will answer with the

188
00:06:48,720 --> 00:06:51,680
response and in the end

189
00:06:51,680 --> 00:06:53,120
the server should not be able to

190
00:06:53,120 --> 00:06:55,520
distinguish this from a simulated

191
00:06:55,520 --> 00:06:57,680
version where the simulator only gets

192
00:06:57,680 --> 00:06:59,840
access to

193
00:06:59,840 --> 00:07:02,800
a certain leakage of the information

194
00:07:02,800 --> 00:07:05,440
that the adversary specifies so for

195
00:07:05,440 --> 00:07:07,120
setup the

196
00:07:07,120 --> 00:07:09,520
the simulator only has access to the

197
00:07:09,520 --> 00:07:11,039
setup leakage

198
00:07:11,039 --> 00:07:13,120
and for

199
00:07:13,120 --> 00:07:15,759
the search functionality so for queries

200
00:07:15,759 --> 00:07:16,070
the

201
00:07:16,070 --> 00:07:17,599
[Music]

202
00:07:17,599 --> 00:07:19,759
the simulator only has access to the

203
00:07:19,759 --> 00:07:21,280
query leakage

204
00:07:21,280 --> 00:07:24,000
and in general the setup functions

205
00:07:24,000 --> 00:07:25,039
are

206
00:07:25,039 --> 00:07:26,800
the size of the database for the setup

207
00:07:26,800 --> 00:07:29,840
leakage and the size of the

208
00:07:29,840 --> 00:07:31,520
identifier set that you have to return

209
00:07:31,520 --> 00:07:34,000
so the response set r in this case

210
00:07:34,000 --> 00:07:36,160
um so the number of identifiers that

211
00:07:36,160 --> 00:07:39,120
match a certain keyword down menu

212
00:07:39,120 --> 00:07:41,440
and also the search pattern usually

213
00:07:41,440 --> 00:07:44,720
the the search pattern is essentially

214
00:07:44,720 --> 00:07:46,720
notifying the simulator when a keyword

215
00:07:46,720 --> 00:07:48,560
was already queried so that you can

216
00:07:48,560 --> 00:07:51,039
re-query the same keyword um so yeah

217
00:07:51,039 --> 00:07:52,879
this square this query leakage is

218
00:07:52,879 --> 00:07:56,080
usually important in order to still be

219
00:07:56,080 --> 00:07:57,280
able to

220
00:07:57,280 --> 00:07:59,680
construct efficient schemes

221
00:07:59,680 --> 00:08:00,720
um

222
00:08:00,720 --> 00:08:04,400
but in on the other hand because of this

223
00:08:04,400 --> 00:08:07,280
static sse a security definition

224
00:08:07,280 --> 00:08:10,240
um after an interaction with the server

225
00:08:10,240 --> 00:08:12,479
the server can or

226
00:08:12,479 --> 00:08:15,840
the adversary can only learn these

227
00:08:15,840 --> 00:08:18,160
leaked information so the output of the

228
00:08:18,160 --> 00:08:19,840
of the setup leakage and the query

229
00:08:19,840 --> 00:08:22,000
leakage from the interaction from the

230
00:08:22,000 --> 00:08:24,000
with the client before i dive into all

231
00:08:24,000 --> 00:08:25,599
the technical details i will quickly

232
00:08:25,599 --> 00:08:27,599
talk about our contribution

233
00:08:27,599 --> 00:08:29,520
first of all we define page efficiency

234
00:08:29,520 --> 00:08:30,720
and we show that it's actually a very

235
00:08:30,720 --> 00:08:32,958
good predictor for throughput of an sse

236
00:08:32,958 --> 00:08:35,839
scheme if it's run on ssds

237
00:08:35,839 --> 00:08:38,000
secondly we define data independent

238
00:08:38,000 --> 00:08:40,719
packing so dip schemes

239
00:08:40,719 --> 00:08:44,159
and these are actually simple

240
00:08:44,159 --> 00:08:47,040
allocation schemes or packing schemes

241
00:08:47,040 --> 00:08:48,560
that

242
00:08:48,560 --> 00:08:51,120
that are purely combinatorical and from

243
00:08:51,120 --> 00:08:53,360
these schemes we can construct sse

244
00:08:53,360 --> 00:08:55,279
schemes that retain the same efficiency

245
00:08:55,279 --> 00:08:57,120
measures

246
00:08:57,120 --> 00:08:59,360
and then lastly we define actually or we

247
00:08:59,360 --> 00:09:01,839
built an efficient dip scheme

248
00:09:01,839 --> 00:09:03,440
based on cocoa hashing for weighted

249
00:09:03,440 --> 00:09:06,080
items so this not hasn't been done

250
00:09:06,080 --> 00:09:08,399
before so this is a new algorithm that

251
00:09:08,399 --> 00:09:10,959
allows us to use coco hashing so that

252
00:09:10,959 --> 00:09:13,600
allows us to do allocation essentially

253
00:09:13,600 --> 00:09:15,440
for weighted items

254
00:09:15,440 --> 00:09:16,800
and this is based on a max flow

255
00:09:16,800 --> 00:09:18,480
computation

256
00:09:18,480 --> 00:09:20,560
and also this is the main technical part

257
00:09:20,560 --> 00:09:21,760
of the paper

258
00:09:21,760 --> 00:09:23,600
and then lastly

259
00:09:23,600 --> 00:09:25,279
we use our framework that we defined

260
00:09:25,279 --> 00:09:27,600
before in order to construct an sse

261
00:09:27,600 --> 00:09:29,360
scheme that has optimal page and storage

262
00:09:29,360 --> 00:09:32,160
efficiency based on tetis and yeah this

263
00:09:32,160 --> 00:09:36,160
sse scheme is also called tetus

264
00:09:36,160 --> 00:09:36,880
so

265
00:09:36,880 --> 00:09:38,640
now we'll dive into the technical part

266
00:09:38,640 --> 00:09:40,160
and for this first of all i will

267
00:09:40,160 --> 00:09:42,240
introduce data independent packing so

268
00:09:42,240 --> 00:09:44,399
for data independent packing we have a

269
00:09:44,399 --> 00:09:46,320
multi-map so

270
00:09:46,320 --> 00:09:48,560
keys that map two items

271
00:09:48,560 --> 00:09:50,399
in total we have n items

272
00:09:50,399 --> 00:09:53,600
and m buckets into which we want to also

273
00:09:53,600 --> 00:09:55,279
allocate our items

274
00:09:55,279 --> 00:09:57,200
and each of those buckets have capacity

275
00:09:57,200 --> 00:09:59,519
p and then for the

276
00:09:59,519 --> 00:10:01,839
for the worst case where one bucket

277
00:10:01,839 --> 00:10:04,320
is already filled up to capacity p but

278
00:10:04,320 --> 00:10:06,160
we still want to import items we have a

279
00:10:06,160 --> 00:10:08,160
stash where we can allocate items to as

280
00:10:08,160 --> 00:10:09,440
well

281
00:10:09,440 --> 00:10:10,399
so

282
00:10:10,399 --> 00:10:12,480
in general it's purely combinatorical

283
00:10:12,480 --> 00:10:16,640
which means that one key defines

284
00:10:16,800 --> 00:10:18,800
a bunch of buckets so in this case two

285
00:10:18,800 --> 00:10:20,959
and then we can allocate all the items

286
00:10:20,959 --> 00:10:22,640
to these two buckets and we cannot

287
00:10:22,640 --> 00:10:24,720
actually allocate any green items to

288
00:10:24,720 --> 00:10:26,480
other buckets than that

289
00:10:26,480 --> 00:10:28,800
and we do the same for

290
00:10:28,800 --> 00:10:30,959
the blue key and

291
00:10:30,959 --> 00:10:32,399
here again

292
00:10:32,399 --> 00:10:34,320
blue items can only be allocated to the

293
00:10:34,320 --> 00:10:36,880
blue buckets that i highlighted here

294
00:10:36,880 --> 00:10:40,560
and again we do the same for the red key

295
00:10:40,560 --> 00:10:43,040
and the same for the yellow key and

296
00:10:43,040 --> 00:10:45,279
because for example the capacity in this

297
00:10:45,279 --> 00:10:47,760
case might be five we can allocate the

298
00:10:47,760 --> 00:10:50,160
last item to the stash because the first

299
00:10:50,160 --> 00:10:52,399
two buckets are already full

300
00:10:52,399 --> 00:10:53,760
um

301
00:10:53,760 --> 00:10:56,079
so more formally we have a size function

302
00:10:56,079 --> 00:10:59,200
that returns given the number n of items

303
00:10:59,200 --> 00:11:01,279
the number of buckets m that we need in

304
00:11:01,279 --> 00:11:03,519
order to store all those items

305
00:11:03,519 --> 00:11:06,000
we define this function in order to have

306
00:11:06,000 --> 00:11:09,040
the number of buckets be independent on

307
00:11:09,040 --> 00:11:11,200
the list distribution so that only the

308
00:11:11,200 --> 00:11:13,920
number of items actually defines how

309
00:11:13,920 --> 00:11:15,519
many buckets we want

310
00:11:15,519 --> 00:11:17,120
then we have a build function that takes

311
00:11:17,120 --> 00:11:20,079
a multi-map and returns buckets so m

312
00:11:20,079 --> 00:11:21,600
buckets in total that are filled with

313
00:11:21,600 --> 00:11:23,680
the items from the multi-map

314
00:11:23,680 --> 00:11:27,600
and this also allows to return a stash

315
00:11:27,600 --> 00:11:30,160
s that has potentially items from the

316
00:11:30,160 --> 00:11:32,160
multi-map also

317
00:11:32,160 --> 00:11:33,519
and then lastly we have a lookup

318
00:11:33,519 --> 00:11:36,720
function so for example we can look up

319
00:11:36,720 --> 00:11:39,200
key 2 so the blue key

320
00:11:39,200 --> 00:11:41,760
and we also need to supply the number of

321
00:11:41,760 --> 00:11:42,880
items

322
00:11:42,880 --> 00:11:44,399
that the blue key

323
00:11:44,399 --> 00:11:45,839
matches to

324
00:11:45,839 --> 00:11:48,000
and then this will return the bucket

325
00:11:48,000 --> 00:11:49,920
indices so in this case the first two

326
00:11:49,920 --> 00:11:51,370
buckets

327
00:11:51,370 --> 00:11:53,200
[Music]

328
00:11:53,200 --> 00:11:56,560
yes so this is essentially the ip and we

329
00:11:56,560 --> 00:11:58,399
have three efficiency measures so first

330
00:11:58,399 --> 00:12:00,480
of all the lookup efficiency

331
00:12:00,480 --> 00:12:02,720
um this returns the number of buckets

332
00:12:02,720 --> 00:12:04,959
per keyword in our construction this

333
00:12:04,959 --> 00:12:07,040
will always be two

334
00:12:07,040 --> 00:12:09,120
then we have the storage efficiency

335
00:12:09,120 --> 00:12:11,920
meaning the overhead that i need to

336
00:12:11,920 --> 00:12:14,800
store n items so i will need m times p

337
00:12:14,800 --> 00:12:17,200
space for my buckets

338
00:12:17,200 --> 00:12:19,360
and i only have n items so m times p

339
00:12:19,360 --> 00:12:23,040
divided by n is the storage efficiency

340
00:12:23,040 --> 00:12:24,880
and then lastly i have the stash size so

341
00:12:24,880 --> 00:12:26,320
the number of items that i didn't

342
00:12:26,320 --> 00:12:28,399
actually manage to allocate to the

343
00:12:28,399 --> 00:12:30,399
buckets

344
00:12:30,399 --> 00:12:32,320
and by definition dip schemes are

345
00:12:32,320 --> 00:12:34,399
actually data independent which means

346
00:12:34,399 --> 00:12:37,360
that they informally know information

347
00:12:37,360 --> 00:12:39,360
about the number of items that match

348
00:12:39,360 --> 00:12:42,240
other keys when we look up one key

349
00:12:42,240 --> 00:12:44,480
and this is actually very important in

350
00:12:44,480 --> 00:12:47,360
order to construct sse schemes from dip

351
00:12:47,360 --> 00:12:48,320
schemes

352
00:12:48,320 --> 00:12:50,959
so for this we have the setup function

353
00:12:50,959 --> 00:12:51,760
so

354
00:12:51,760 --> 00:12:53,600
the setup function takes us input the

355
00:12:53,600 --> 00:12:54,800
database

356
00:12:54,800 --> 00:12:57,600
which itself maps keywords to identifier

357
00:12:57,600 --> 00:12:59,920
pairs

358
00:13:00,079 --> 00:13:00,959
then

359
00:13:00,959 --> 00:13:03,680
at first we choose two keys so a key for

360
00:13:03,680 --> 00:13:06,240
an encryption scheme and a key for a prf

361
00:13:06,240 --> 00:13:07,680
function

362
00:13:07,680 --> 00:13:09,440
and then we use the prf in order to map

363
00:13:09,440 --> 00:13:12,399
each keyword wi to a mask mi and a key

364
00:13:12,399 --> 00:13:13,920
ki

365
00:13:13,920 --> 00:13:16,079
so we use the mask mi in order to

366
00:13:16,079 --> 00:13:18,079
encrypt li

367
00:13:18,079 --> 00:13:21,920
so l i is the list length

368
00:13:21,920 --> 00:13:22,639
of

369
00:13:22,639 --> 00:13:24,959
all the identifiers that match keyword

370
00:13:24,959 --> 00:13:26,399
wi

371
00:13:26,399 --> 00:13:28,240
and which we will later use for the

372
00:13:28,240 --> 00:13:30,720
lookup of adip scheme

373
00:13:30,720 --> 00:13:32,240
and then

374
00:13:32,240 --> 00:13:35,920
we will store this in a map so we map ki

375
00:13:35,920 --> 00:13:38,560
the second output of the prf

376
00:13:38,560 --> 00:13:41,839
to this encrypted li in a table t

377
00:13:41,839 --> 00:13:44,160
and then secondly we use ki

378
00:13:44,160 --> 00:13:48,160
in order to replace wi in the database

379
00:13:48,160 --> 00:13:49,680
and then the database essentially is

380
00:13:49,680 --> 00:13:52,240
already a multi-map

381
00:13:52,240 --> 00:13:56,399
and that matches ki to the identifiers

382
00:13:56,399 --> 00:13:58,240
that match wi

383
00:13:58,240 --> 00:14:00,720
and then we use the setup function of

384
00:14:00,720 --> 00:14:04,560
the dip scheme in order to construct

385
00:14:04,720 --> 00:14:06,880
essentially a bunch of filled buckets

386
00:14:06,880 --> 00:14:11,040
with capacity p where p is the page size

387
00:14:11,040 --> 00:14:13,839
and also potentially the stash and then

388
00:14:13,839 --> 00:14:17,199
in total we define this so the table t

389
00:14:17,199 --> 00:14:18,240
and the

390
00:14:18,240 --> 00:14:20,320
field pages

391
00:14:20,320 --> 00:14:22,959
as the encrypted database

392
00:14:22,959 --> 00:14:25,600
so first of all we saw the stash

393
00:14:25,600 --> 00:14:27,360
and

394
00:14:27,360 --> 00:14:28,800
and the keys on the client and the

395
00:14:28,800 --> 00:14:30,639
encrypted database we will send to the

396
00:14:30,639 --> 00:14:32,560
server and then the server stores the

397
00:14:32,560 --> 00:14:34,959
encrypted database so the table t

398
00:14:34,959 --> 00:14:37,440
and default pages and then if the client

399
00:14:37,440 --> 00:14:40,240
wants to search a keyword wi he will

400
00:14:40,240 --> 00:14:42,800
have to re-evaluate the prf on the

401
00:14:42,800 --> 00:14:46,480
keyword wi he gets the token

402
00:14:46,480 --> 00:14:49,199
so this essentially is the token twi is

403
00:14:49,199 --> 00:14:50,959
the result of the prf

404
00:14:50,959 --> 00:14:54,480
and this is again as before the

405
00:14:54,480 --> 00:14:57,680
mask mi and the key ki so the mask mi we

406
00:14:57,680 --> 00:15:01,600
can use directly in order to decrypt

407
00:15:01,600 --> 00:15:04,639
the li so the list length and the number

408
00:15:04,639 --> 00:15:07,760
of matching identifiers for wi

409
00:15:07,760 --> 00:15:10,240
and then we can use the key also in

410
00:15:10,240 --> 00:15:13,680
order to look up using the dip scheme

411
00:15:13,680 --> 00:15:15,519
the matching buckets and then if we have

412
00:15:15,519 --> 00:15:17,120
the matching buckets we can just return

413
00:15:17,120 --> 00:15:18,639
the matching buckets

414
00:15:18,639 --> 00:15:20,000
to the client and then the client can

415
00:15:20,000 --> 00:15:22,000
decrypt those buckets and retrieve the

416
00:15:22,000 --> 00:15:24,399
items that he cares about and here it's

417
00:15:24,399 --> 00:15:25,360
important to note that all the

418
00:15:25,360 --> 00:15:27,199
efficiency guarantees from the dip

419
00:15:27,199 --> 00:15:30,720
scheme are inherited to the framework so

420
00:15:30,720 --> 00:15:32,959
through this sse scheme

421
00:15:32,959 --> 00:15:34,480
so now i've shown you how to construct

422
00:15:34,480 --> 00:15:37,199
efficient sse schemes from efficient dip

423
00:15:37,199 --> 00:15:39,040
schemes and all that is left is to

424
00:15:39,040 --> 00:15:42,000
construct an efficient dip scheme um i

425
00:15:42,000 --> 00:15:43,440
mean this is easier said than done

426
00:15:43,440 --> 00:15:44,800
because this is actually the main

427
00:15:44,800 --> 00:15:47,600
technical content of the paper so i will

428
00:15:47,600 --> 00:15:49,680
go through an example with you

429
00:15:49,680 --> 00:15:51,920
of how that is works

430
00:15:51,920 --> 00:15:52,800
so

431
00:15:52,800 --> 00:15:55,600
we have a bunch of items so for example

432
00:15:55,600 --> 00:15:58,160
five green items two blue items etc and

433
00:15:58,160 --> 00:16:00,720
each color maps to one key

434
00:16:00,720 --> 00:16:02,560
so

435
00:16:02,560 --> 00:16:04,720
these items we want to store in four

436
00:16:04,720 --> 00:16:05,759
buckets

437
00:16:05,759 --> 00:16:08,480
each with capacity five

438
00:16:08,480 --> 00:16:11,199
and how that is proceeds is that for

439
00:16:11,199 --> 00:16:14,880
each bucket we draw four nodes in a

440
00:16:14,880 --> 00:16:16,720
graph

441
00:16:16,720 --> 00:16:18,959
so bucket one will correspond to node

442
00:16:18,959 --> 00:16:22,240
one etc and then for each key we will

443
00:16:22,240 --> 00:16:24,480
draw two random buckets so in this case

444
00:16:24,480 --> 00:16:26,399
we chose the buckets font one

445
00:16:26,399 --> 00:16:29,279
and we will draw five edges from bucket

446
00:16:29,279 --> 00:16:31,360
four to bucket one the rotation of the

447
00:16:31,360 --> 00:16:33,519
edge is not important now this will be

448
00:16:33,519 --> 00:16:36,079
optimized later but what it means

449
00:16:36,079 --> 00:16:39,360
essentially is that

450
00:16:39,360 --> 00:16:40,800
each item

451
00:16:40,800 --> 00:16:42,800
corresponds to one edge

452
00:16:42,800 --> 00:16:46,000
and this edge is oriented outgoing from

453
00:16:46,000 --> 00:16:48,480
one bucket so in this case all edges are

454
00:16:48,480 --> 00:16:50,560
outgoing from bucket four

455
00:16:50,560 --> 00:16:53,199
and this bucket will later on beat the

456
00:16:53,199 --> 00:16:54,639
bucket

457
00:16:54,639 --> 00:16:57,199
where we store the item so now all items

458
00:16:57,199 --> 00:16:59,360
will be allocated to bucket four

459
00:16:59,360 --> 00:17:01,600
and we do this again for for the blue

460
00:17:01,600 --> 00:17:03,120
items

461
00:17:03,120 --> 00:17:05,119
so we choose two random buckets in this

462
00:17:05,119 --> 00:17:08,799
case one and two and we draw two edges

463
00:17:08,799 --> 00:17:10,240
and now all the blue items will be

464
00:17:10,240 --> 00:17:12,319
stored to bucket one and we do this for

465
00:17:12,319 --> 00:17:14,559
all the items now that we've drawn all

466
00:17:14,559 --> 00:17:15,760
the random

467
00:17:15,760 --> 00:17:18,640
buckets and allocated all the items to

468
00:17:18,640 --> 00:17:20,799
some buckets this of course is not

469
00:17:20,799 --> 00:17:23,599
optimal yet and for optimizing this we

470
00:17:23,599 --> 00:17:26,160
pre-compute essentially out degree of

471
00:17:26,160 --> 00:17:27,919
each bucket so for example bucket one

472
00:17:27,919 --> 00:17:29,919
has our degree six which means they have

473
00:17:29,919 --> 00:17:31,520
six items

474
00:17:31,520 --> 00:17:33,840
that are stored in bucket one and of

475
00:17:33,840 --> 00:17:35,919
course this is more than five so we want

476
00:17:35,919 --> 00:17:37,840
to essentially optimize

477
00:17:37,840 --> 00:17:40,000
this to be as close the out degree to be

478
00:17:40,000 --> 00:17:43,280
as close as possible to the page size

479
00:17:43,280 --> 00:17:44,799
for example here the pa the out degree

480
00:17:44,799 --> 00:17:46,240
degrees three so that means there's

481
00:17:46,240 --> 00:17:48,640
still space for two more items

482
00:17:48,640 --> 00:17:50,720
here the r degree is eight so

483
00:17:50,720 --> 00:17:53,440
again over five and here the out degree

484
00:17:53,440 --> 00:17:55,679
is already perfect

485
00:17:55,679 --> 00:17:57,600
meaning it's five

486
00:17:57,600 --> 00:17:59,600
so this bucket will store exactly the

487
00:17:59,600 --> 00:18:02,639
right amount of items

488
00:18:03,440 --> 00:18:04,400
so

489
00:18:04,400 --> 00:18:06,240
now in order to optimize this what we

490
00:18:06,240 --> 00:18:09,039
can do is we can just compute a path

491
00:18:09,039 --> 00:18:11,200
from a bucket that's overflowing in this

492
00:18:11,200 --> 00:18:12,559
case 4

493
00:18:12,559 --> 00:18:14,799
to a path to a bucket that is

494
00:18:14,799 --> 00:18:17,280
underflowing and this means that if we

495
00:18:17,280 --> 00:18:19,360
reorient the edges

496
00:18:19,360 --> 00:18:21,919
the out degree of the underflowing

497
00:18:21,919 --> 00:18:24,000
bucket will increase and the out degree

498
00:18:24,000 --> 00:18:27,280
of the overflowing bucket will decrease

499
00:18:27,280 --> 00:18:29,760
and the buckets that are in the middle

500
00:18:29,760 --> 00:18:32,000
on the path actually don't change their

501
00:18:32,000 --> 00:18:34,559
out degree which means that we actually

502
00:18:34,559 --> 00:18:37,280
improve our allocation

503
00:18:37,280 --> 00:18:38,160
by

504
00:18:38,160 --> 00:18:40,240
one essentially we have one less

505
00:18:40,240 --> 00:18:42,480
overflowing item

506
00:18:42,480 --> 00:18:44,720
and if we repeat this so for example

507
00:18:44,720 --> 00:18:47,280
again we have still seven items so this

508
00:18:47,280 --> 00:18:48,559
is too much

509
00:18:48,559 --> 00:18:50,880
um we find a path to two which is the

510
00:18:50,880 --> 00:18:52,799
only underflowing bucket

511
00:18:52,799 --> 00:18:54,799
we turn around the edges so now there's

512
00:18:54,799 --> 00:18:56,480
no more path from an overflowing bucket

513
00:18:56,480 --> 00:18:57,919
to an underflowing bucket which means

514
00:18:57,919 --> 00:19:01,360
that this solution is already optimal

515
00:19:01,360 --> 00:19:03,600
and now based on this optimal graph we

516
00:19:03,600 --> 00:19:05,520
can actually allocate our items into

517
00:19:05,520 --> 00:19:08,240
buckets so again we have four buckets

518
00:19:08,240 --> 00:19:10,720
and each edge corresponds to one item so

519
00:19:10,720 --> 00:19:13,039
for example we can choose this edge

520
00:19:13,039 --> 00:19:14,720
which corresponds to this item and since

521
00:19:14,720 --> 00:19:16,480
the edge is outgoing from one we move it

522
00:19:16,480 --> 00:19:17,919
to bucket one

523
00:19:17,919 --> 00:19:20,480
again this edge is outgoing from bucket

524
00:19:20,480 --> 00:19:23,039
four so we move an item to bucket four

525
00:19:23,039 --> 00:19:25,360
and the other edges are also outgoing

526
00:19:25,360 --> 00:19:27,120
from bucket four so we do the same for

527
00:19:27,120 --> 00:19:29,200
all the remaining green items

528
00:19:29,200 --> 00:19:31,600
now for the blue items again we choose

529
00:19:31,600 --> 00:19:34,240
one edge for example this edge it's

530
00:19:34,240 --> 00:19:36,480
outgoing from bucket two so we move the

531
00:19:36,480 --> 00:19:38,320
item to bucket two for the other edge

532
00:19:38,320 --> 00:19:40,000
it's outgoing from bucket one so we move

533
00:19:40,000 --> 00:19:42,000
the item to bucket one

534
00:19:42,000 --> 00:19:43,919
similar for the red item we choose one

535
00:19:43,919 --> 00:19:45,760
edge for example the one out going from

536
00:19:45,760 --> 00:19:48,240
three we move one item to bucket three

537
00:19:48,240 --> 00:19:50,320
choose one other edge which is outgoing

538
00:19:50,320 --> 00:19:51,840
from bucket four so we move the item to

539
00:19:51,840 --> 00:19:53,039
bucket four

540
00:19:53,039 --> 00:19:54,960
and for the last edge

541
00:19:54,960 --> 00:19:56,880
we observe that we need to move it to

542
00:19:56,880 --> 00:19:59,120
bucket four by the graph

543
00:19:59,120 --> 00:20:02,240
but the bucket force already

544
00:20:02,240 --> 00:20:04,400
filled up completely up to capacity so

545
00:20:04,400 --> 00:20:06,400
we can't actually move the item

546
00:20:06,400 --> 00:20:07,760
to the bucket

547
00:20:07,760 --> 00:20:09,440
but for this we have the stash so we can

548
00:20:09,440 --> 00:20:12,000
just move the item to the stash

549
00:20:12,000 --> 00:20:13,600
and then we do the same for all the

550
00:20:13,600 --> 00:20:15,039
remaining items

551
00:20:15,039 --> 00:20:17,360
and we get this allocation based on the

552
00:20:17,360 --> 00:20:19,039
graph and then we only have two items in

553
00:20:19,039 --> 00:20:20,720
the stash and all the other buckets are

554
00:20:20,720 --> 00:20:21,919
actually filled

555
00:20:21,919 --> 00:20:23,440
and it's important to note that this

556
00:20:23,440 --> 00:20:25,200
solution is actually best among all

557
00:20:25,200 --> 00:20:27,200
these solutions

558
00:20:27,200 --> 00:20:29,280
no matter where you start from so no

559
00:20:29,280 --> 00:20:31,520
matter the orientation in the beginning

560
00:20:31,520 --> 00:20:33,520
no matter

561
00:20:33,520 --> 00:20:34,880
what choices you make during the

562
00:20:34,880 --> 00:20:38,320
algorithm it always outputs a graph that

563
00:20:38,320 --> 00:20:40,159
later on leads to an allocation with the

564
00:20:40,159 --> 00:20:42,320
lowest dash size possible

565
00:20:42,320 --> 00:20:44,400
so this is essentially how teddys works

566
00:20:44,400 --> 00:20:46,720
and then we show the main theorem of our

567
00:20:46,720 --> 00:20:48,960
paper which states that there exists a

568
00:20:48,960 --> 00:20:50,640
valid assignment with overwhelming

569
00:20:50,640 --> 00:20:53,600
probability such that we can choose only

570
00:20:53,600 --> 00:20:56,240
m buckets where m is equal to 2 plus

571
00:20:56,240 --> 00:20:58,559
epsilon times n over p where epsilon's a

572
00:20:58,559 --> 00:21:00,000
small constant

573
00:21:00,000 --> 00:21:03,120
so essentially n over p is the minimal

574
00:21:03,120 --> 00:21:04,880
amount of buckets that we would need for

575
00:21:04,880 --> 00:21:06,720
any packing algorithm even if it's

576
00:21:06,720 --> 00:21:08,400
non-data independent

577
00:21:08,400 --> 00:21:10,320
so the overhead is essentially two plus

578
00:21:10,320 --> 00:21:11,600
epsilon

579
00:21:11,600 --> 00:21:13,039
and secondly we show that this test

580
00:21:13,039 --> 00:21:15,200
stress is only omega of log lambda

581
00:21:15,200 --> 00:21:17,360
divided by log n pages

582
00:21:17,360 --> 00:21:19,200
and more importantly this shows that the

583
00:21:19,200 --> 00:21:21,200
stash is independent on the size of the

584
00:21:21,200 --> 00:21:22,480
database

585
00:21:22,480 --> 00:21:23,440
which

586
00:21:23,440 --> 00:21:25,039
is important because later on we will

587
00:21:25,039 --> 00:21:27,520
store the stash on the client so we

588
00:21:27,520 --> 00:21:30,480
would like this dash to not grow if we

589
00:21:30,480 --> 00:21:32,960
outsource more and more data

590
00:21:32,960 --> 00:21:35,360
and on a more theoretical node this is

591
00:21:35,360 --> 00:21:36,880
actually a direct generalization of

592
00:21:36,880 --> 00:21:39,200
google hashing in the static case

593
00:21:39,200 --> 00:21:41,520
so in our case we allow for weighted

594
00:21:41,520 --> 00:21:44,320
items so lists of variable size but if

595
00:21:44,320 --> 00:21:46,640
we choose only lists of the maximal size

596
00:21:46,640 --> 00:21:47,520
p

597
00:21:47,520 --> 00:21:49,280
then actually this algorithm is

598
00:21:49,280 --> 00:21:51,600
equivalent to cocoa hashing and we show

599
00:21:51,600 --> 00:21:54,159
that even though we allow for variable

600
00:21:54,159 --> 00:21:55,679
sized lists

601
00:21:55,679 --> 00:21:58,960
so not only the maximal size p that we

602
00:21:58,960 --> 00:22:01,120
have the same asymptotic behavior so the

603
00:22:01,120 --> 00:22:04,000
same stash size and the same amount of

604
00:22:04,000 --> 00:22:05,120
buckets

605
00:22:05,120 --> 00:22:07,919
so in conclusion we showed that

606
00:22:07,919 --> 00:22:10,000
cocoa hashing works with stash for items

607
00:22:10,000 --> 00:22:11,679
of variable size

608
00:22:11,679 --> 00:22:13,360
secondly we define data independent

609
00:22:13,360 --> 00:22:14,720
backing and actually construct an

610
00:22:14,720 --> 00:22:17,039
efficient dip scheme

611
00:22:17,039 --> 00:22:20,400
and based on that we get an sse scheme

612
00:22:20,400 --> 00:22:22,240
that has off one storage and page

613
00:22:22,240 --> 00:22:25,679
efficiency which is called tetus

614
00:22:25,679 --> 00:22:27,679
so before finishing my talk i quickly

615
00:22:27,679 --> 00:22:29,760
wanted to show you the results of

616
00:22:29,760 --> 00:22:31,360
experiments that we run

617
00:22:31,360 --> 00:22:32,080
so

618
00:22:32,080 --> 00:22:34,720
in dark red you can see the throughput

619
00:22:34,720 --> 00:22:37,440
and in bright red in bright blue and in

620
00:22:37,440 --> 00:22:39,919
dark blue you can see the inverse

621
00:22:39,919 --> 00:22:42,640
efficiency of page efficiency read

622
00:22:42,640 --> 00:22:44,240
efficiency and storage efficiency

623
00:22:44,240 --> 00:22:46,159
respectively

624
00:22:46,159 --> 00:22:48,000
and if we look at the graph then we can

625
00:22:48,000 --> 00:22:50,480
see that the page efficiency is a very

626
00:22:50,480 --> 00:22:52,159
good predictor for the throughput so

627
00:22:52,159 --> 00:22:54,159
whenever we have a very high page

628
00:22:54,159 --> 00:22:56,559
efficiency we generally have a very high

629
00:22:56,559 --> 00:22:59,200
throughput as well

630
00:22:59,200 --> 00:23:01,360
secondly we can see that tethys actually

631
00:23:01,360 --> 00:23:03,200
has high storage efficiency read

632
00:23:03,200 --> 00:23:05,360
efficiency and page efficiency

633
00:23:05,360 --> 00:23:07,840
and the only scheme that comes close to

634
00:23:07,840 --> 00:23:10,320
a plaintext database in all of these

635
00:23:10,320 --> 00:23:12,799
characteristics

636
00:23:12,799 --> 00:23:14,640
and yeah with that i thank you for

637
00:23:14,640 --> 00:23:16,320
listening to this talk

638
00:23:16,320 --> 00:23:18,240
and if you want any more information

639
00:23:18,240 --> 00:23:20,559
then i invite you to read the eprint

640
00:23:20,559 --> 00:23:22,720
article or to ask me questions in

641
00:23:22,720 --> 00:23:25,720
private

