1
00:00:04,799 --> 00:00:06,720
and our first talk of the session will

2
00:00:06,720 --> 00:00:08,800
be time space trade-offs for sponge

3
00:00:08,800 --> 00:00:09,760
hashing

4
00:00:09,760 --> 00:00:11,840
attacks and limitations for short

5
00:00:11,840 --> 00:00:14,639
collisions and the talk will be given by

6
00:00:14,639 --> 00:00:17,119
ashu ji goshal

7
00:00:17,119 --> 00:00:18,320
hi everyone

8
00:00:18,320 --> 00:00:20,960
this is joint work with cody freytag and

9
00:00:20,960 --> 00:00:22,560
ilan komargotsky

10
00:00:22,560 --> 00:00:24,800
very broadly this work is about a new

11
00:00:24,800 --> 00:00:26,560
pre-processing attacks and limitations

12
00:00:26,560 --> 00:00:27,359
for

13
00:00:27,359 --> 00:00:29,039
finding short collisions in the sponge

14
00:00:29,039 --> 00:00:31,039
construction

15
00:00:31,039 --> 00:00:32,399
hash functions are one of the most

16
00:00:32,399 --> 00:00:34,239
fundamental primitives of photography

17
00:00:34,239 --> 00:00:36,079
that have many different applications

18
00:00:36,079 --> 00:00:38,480
and certain applications like password

19
00:00:38,480 --> 00:00:41,600
hashing etc require a hash function to

20
00:00:41,600 --> 00:00:44,160
handle different input limits and it is

21
00:00:44,160 --> 00:00:46,160
infeasible for us to design a different

22
00:00:46,160 --> 00:00:48,399
hash function for every

23
00:00:48,399 --> 00:00:50,000
input length

24
00:00:50,000 --> 00:00:52,000
therefore we use iterative hashing as a

25
00:00:52,000 --> 00:00:54,640
mechanism to design a variable input

26
00:00:54,640 --> 00:00:56,640
length hash function from an underlying

27
00:00:56,640 --> 00:00:58,719
fixed input length primitive and the

28
00:00:58,719 --> 00:01:00,559
most commonly used iterative hashing

29
00:01:00,559 --> 00:01:03,280
mechanism is the merkle dam guard design

30
00:01:03,280 --> 00:01:04,959
where the fixed input and primitive is a

31
00:01:04,959 --> 00:01:07,360
compression function that takes as input

32
00:01:07,360 --> 00:01:08,720
two embeds and

33
00:01:08,720 --> 00:01:11,520
outputs n bits and hashes a message by

34
00:01:11,520 --> 00:01:13,600
breaking it into blocks and repeatedly

35
00:01:13,600 --> 00:01:15,360
applying this compression function

36
00:01:15,360 --> 00:01:17,600
uh this is used in

37
00:01:17,600 --> 00:01:21,840
constructions like md5 sha-1 and sha-2

38
00:01:21,840 --> 00:01:24,080
after some attacks on

39
00:01:24,080 --> 00:01:27,280
md5 and 0 in 2006 nist started a

40
00:01:27,280 --> 00:01:29,119
competition to standardize a new hash

41
00:01:29,119 --> 00:01:30,079
function

42
00:01:30,079 --> 00:01:33,040
and after almost a decade uh the family

43
00:01:33,040 --> 00:01:34,640
of hash functions sketch act emerged as

44
00:01:34,640 --> 00:01:36,159
the winner

45
00:01:36,159 --> 00:01:38,000
ketchup is based on a new iterative

46
00:01:38,000 --> 00:01:39,439
hashing mechanism

47
00:01:39,439 --> 00:01:40,960
which is called the sponge construction

48
00:01:40,960 --> 00:01:43,360
uh which is a noble alternative to the

49
00:01:43,360 --> 00:01:44,960
merkle dam guard design

50
00:01:44,960 --> 00:01:47,119
uh the one main major point of

51
00:01:47,119 --> 00:01:49,680
difference for the spawn construction is

52
00:01:49,680 --> 00:01:51,520
the fundamental underlying primitive

53
00:01:51,520 --> 00:01:53,200
here is a permutation instead of a

54
00:01:53,200 --> 00:01:54,640
function

55
00:01:54,640 --> 00:01:57,119
very briefly this is how

56
00:01:57,119 --> 00:01:59,280
the sponge construction works

57
00:01:59,280 --> 00:02:02,399
it is parameterized by the bit rate r

58
00:02:02,399 --> 00:02:04,719
and the capacity c and the underlying

59
00:02:04,719 --> 00:02:06,880
primitive is a permutation on r plus c

60
00:02:06,880 --> 00:02:10,479
bits the hash of a message m is defined

61
00:02:10,479 --> 00:02:12,160
with respect to a hash key or

62
00:02:12,160 --> 00:02:14,319
initialization vector iv

63
00:02:14,319 --> 00:02:15,680
as follows

64
00:02:15,680 --> 00:02:16,959
the message is first padded

65
00:02:16,959 --> 00:02:19,360
appropriately and then broken up into

66
00:02:19,360 --> 00:02:22,640
blocks which are bits long an initial

67
00:02:22,640 --> 00:02:25,040
state consisting of our zeros followed

68
00:02:25,040 --> 00:02:26,959
by iv is defined

69
00:02:26,959 --> 00:02:29,120
uh the first message block is exhort to

70
00:02:29,120 --> 00:02:31,120
the state and the permutation evaluated

71
00:02:31,120 --> 00:02:33,599
on it to compute the next state

72
00:02:33,599 --> 00:02:36,080
then the second message block is exhort

73
00:02:36,080 --> 00:02:37,680
to the the state and the permutation

74
00:02:37,680 --> 00:02:40,480
evaluated again and this is done till

75
00:02:40,480 --> 00:02:42,480
all the message blocks are consumed

76
00:02:42,480 --> 00:02:44,400
uh this is known as the absorption phase

77
00:02:44,400 --> 00:02:45,680
of the sponge

78
00:02:45,680 --> 00:02:47,680
this is followed by the squeezing phase

79
00:02:47,680 --> 00:02:49,440
where the permutation is repeatedly

80
00:02:49,440 --> 00:02:51,920
applied to the states and the first r

81
00:02:51,920 --> 00:02:54,560
bits extracted out as the hash outputs

82
00:02:54,560 --> 00:02:56,000
until there are sufficient number of

83
00:02:56,000 --> 00:02:57,519
bits

84
00:02:57,519 --> 00:02:59,280
for the purpose of this talk i'll

85
00:02:59,280 --> 00:03:01,440
consider a simplified version of sponge

86
00:03:01,440 --> 00:03:03,840
where we just have r bits output because

87
00:03:03,840 --> 00:03:06,319
we are interested in studying in any

88
00:03:06,319 --> 00:03:08,879
studying uh any compressing sponge hash

89
00:03:08,879 --> 00:03:11,280
construction

90
00:03:11,280 --> 00:03:13,120
one of the fundamental properties that

91
00:03:13,120 --> 00:03:15,519
any hash function needs to satisfy is

92
00:03:15,519 --> 00:03:18,159
collision resistance which entails that

93
00:03:18,159 --> 00:03:20,000
given a random iv

94
00:03:20,000 --> 00:03:22,080
it must be hard to find two distinct

95
00:03:22,080 --> 00:03:23,280
messages

96
00:03:23,280 --> 00:03:25,599
that hash to the same output

97
00:03:25,599 --> 00:03:27,280
pictorially this is how a collision

98
00:03:27,280 --> 00:03:29,280
looks like the shaded part denotes the

99
00:03:29,280 --> 00:03:32,480
colliding hash output

100
00:03:32,480 --> 00:03:34,080
we are interested in

101
00:03:34,080 --> 00:03:36,159
studying the hardness of finding

102
00:03:36,159 --> 00:03:38,480
collisions for the sponge construction

103
00:03:38,480 --> 00:03:40,959
and the most common approach to do this

104
00:03:40,959 --> 00:03:42,799
is to model the underlying permutation

105
00:03:42,799 --> 00:03:44,879
pi as a random one

106
00:03:44,879 --> 00:03:47,440
ah when doing so one can show that there

107
00:03:47,440 --> 00:03:49,680
is an attack which requires a minimum of

108
00:03:49,680 --> 00:03:51,680
uh two power r by two and two power c by

109
00:03:51,680 --> 00:03:54,159
two queries uh to find collisions

110
00:03:54,159 --> 00:03:56,720
uh the uh attack with two power r by two

111
00:03:56,720 --> 00:03:58,400
queries is essentially a birthday style

112
00:03:58,400 --> 00:04:00,720
attack where you keep evaluating the

113
00:04:00,720 --> 00:04:03,200
permutation with different

114
00:04:03,200 --> 00:04:05,840
miv until two of the evaluations produce

115
00:04:05,840 --> 00:04:08,640
outputs which match in the first orbits

116
00:04:08,640 --> 00:04:10,560
uh the attack with two parts c by two

117
00:04:10,560 --> 00:04:13,120
queries uh instead finds two evaluations

118
00:04:13,120 --> 00:04:15,200
where the outputs match in the last c

119
00:04:15,200 --> 00:04:17,440
bits this can then be turned into a

120
00:04:17,440 --> 00:04:19,120
sponge collision by appropriately

121
00:04:19,120 --> 00:04:22,479
choosing the second message blocks

122
00:04:22,479 --> 00:04:24,400
one can show that this attack but the

123
00:04:24,400 --> 00:04:26,240
style attack is indeed optimal in the

124
00:04:26,240 --> 00:04:29,280
setting and the proof is via showing

125
00:04:29,280 --> 00:04:30,479
indifferentiability of the sponge

126
00:04:30,479 --> 00:04:32,720
construction to a random oracle with our

127
00:04:32,720 --> 00:04:35,840
output bits uh up to two power c by two

128
00:04:35,840 --> 00:04:38,000
queries for the permutation

129
00:04:38,000 --> 00:04:40,080
however typically uh in the real world

130
00:04:40,080 --> 00:04:42,639
this permutation pi is a public one and

131
00:04:42,639 --> 00:04:45,440
an adversary might be able to do better

132
00:04:45,440 --> 00:04:47,440
by doing a lot of pre-processing on the

133
00:04:47,440 --> 00:04:48,800
permutation

134
00:04:48,800 --> 00:04:51,520
uh and in in this setting this birthday

135
00:04:51,520 --> 00:04:54,080
style attack is no longer optimal uh in

136
00:04:54,080 --> 00:04:55,759
particular the indifferential

137
00:04:55,759 --> 00:04:57,360
differentiability framework no longer

138
00:04:57,360 --> 00:04:58,560
applies

139
00:04:58,560 --> 00:04:59,919
uh the setting of pre-processing

140
00:04:59,919 --> 00:05:01,280
adversaries has

141
00:05:01,280 --> 00:05:02,720
been studied

142
00:05:02,720 --> 00:05:04,400
previously in many earlier works for

143
00:05:04,400 --> 00:05:06,080
example in the context of functioning

144
00:05:06,080 --> 00:05:08,560
version collision resistance etc and in

145
00:05:08,560 --> 00:05:10,240
particular captures the setting of

146
00:05:10,240 --> 00:05:12,240
non-uniform attacks for example

147
00:05:12,240 --> 00:05:14,240
attacks using rainbow tables

148
00:05:14,240 --> 00:05:16,320
and so on

149
00:05:16,320 --> 00:05:18,880
uh the auxiliary input random

150
00:05:18,880 --> 00:05:21,120
permutation model was introduced by

151
00:05:21,120 --> 00:05:22,800
quality at all

152
00:05:22,800 --> 00:05:24,400
that captures the power of

153
00:05:24,400 --> 00:05:26,080
pre-processing adversaries against

154
00:05:26,080 --> 00:05:27,840
random permutations

155
00:05:27,840 --> 00:05:29,680
the uh

156
00:05:29,680 --> 00:05:31,919
pollution resistance of sponge is

157
00:05:31,919 --> 00:05:35,120
formalized in this model as follows

158
00:05:35,120 --> 00:05:37,199
and adversary is

159
00:05:37,199 --> 00:05:39,280
modeled as a two-phase one uh its

160
00:05:39,280 --> 00:05:41,840
pre-processing phase has

161
00:05:41,840 --> 00:05:44,000
full access to the permutation and it

162
00:05:44,000 --> 00:05:46,080
can compute any arbitrary s bits of

163
00:05:46,080 --> 00:05:48,639
advice which is passed on to its online

164
00:05:48,639 --> 00:05:49,680
phase

165
00:05:49,680 --> 00:05:51,600
which additionally gets its input a

166
00:05:51,600 --> 00:05:53,919
randomly sampled iv

167
00:05:53,919 --> 00:05:55,680
it can make at most

168
00:05:55,680 --> 00:05:57,759
total of t queries to the permutation in

169
00:05:57,759 --> 00:05:58,880
its inverse

170
00:05:58,880 --> 00:06:00,800
and it wins if it can output two

171
00:06:00,800 --> 00:06:02,639
distinct messages that hash to the same

172
00:06:02,639 --> 00:06:04,960
output

173
00:06:05,440 --> 00:06:07,600
this such adversity a is referred to as

174
00:06:07,600 --> 00:06:11,039
an st adversary uh we parameterize the

175
00:06:11,039 --> 00:06:13,600
advantage in terms of snt

176
00:06:13,600 --> 00:06:15,600
and define it to be the maximum

177
00:06:15,600 --> 00:06:18,160
probability of any st adversary

178
00:06:18,160 --> 00:06:19,680
in winning this game

179
00:06:19,680 --> 00:06:21,120
uh we note that in allowing the

180
00:06:21,120 --> 00:06:23,120
pre-processing phase to compute any

181
00:06:23,120 --> 00:06:25,280
arbitrary as bits of pre-processing uh

182
00:06:25,280 --> 00:06:27,199
we give it a lot of power

183
00:06:27,199 --> 00:06:29,919
this means that any limitations that we

184
00:06:29,919 --> 00:06:32,080
prove in this model are extremely strong

185
00:06:32,080 --> 00:06:34,800
guarantees

186
00:06:34,800 --> 00:06:36,240
quality at all gave a tight

187
00:06:36,240 --> 00:06:38,800
characterization of this sd advantage

188
00:06:38,800 --> 00:06:40,800
for pollution resistance of sponge that

189
00:06:40,800 --> 00:06:43,280
is they proved an upper bound of st

190
00:06:43,280 --> 00:06:45,120
square over 2 part c plus t square over

191
00:06:45,120 --> 00:06:46,479
2 power r

192
00:06:46,479 --> 00:06:48,800
and gave an attack that achieves a

193
00:06:48,800 --> 00:06:50,160
disadvantage

194
00:06:50,160 --> 00:06:52,400
however uh the attack that they gave

195
00:06:52,400 --> 00:06:54,479
finds collisions of length roughly equal

196
00:06:54,479 --> 00:06:55,680
to t

197
00:06:55,680 --> 00:06:58,160
uh and for usual values these

198
00:06:58,160 --> 00:07:00,960
these are very long collisions uh of

199
00:07:00,960 --> 00:07:03,520
no real practical use

200
00:07:03,520 --> 00:07:05,199
on the other hand

201
00:07:05,199 --> 00:07:07,280
it seems that shorter collisions are

202
00:07:07,280 --> 00:07:09,680
somehow harder to find

203
00:07:09,680 --> 00:07:12,560
therefore we ask the question uh can we

204
00:07:12,560 --> 00:07:14,960
characterize the hardness of finding b

205
00:07:14,960 --> 00:07:16,080
block collisions for the sponge

206
00:07:16,080 --> 00:07:17,360
construction

207
00:07:17,360 --> 00:07:19,280
uh this question has been recently

208
00:07:19,280 --> 00:07:21,599
studied in a series of work uh for the

209
00:07:21,599 --> 00:07:23,599
case of mercury dam guard and the key

210
00:07:23,599 --> 00:07:26,479
take away from those works uh is that

211
00:07:26,479 --> 00:07:29,199
there is a quantitative jump in hardness

212
00:07:29,199 --> 00:07:31,199
with the value of b in particular

213
00:07:31,199 --> 00:07:33,199
collisions become easier to find as b

214
00:07:33,199 --> 00:07:35,039
grows i refer you to the next talk in

215
00:07:35,039 --> 00:07:36,400
the session for more details for the

216
00:07:36,400 --> 00:07:38,560
case of mercury number

217
00:07:38,560 --> 00:07:40,880
in this work we give new attacks and

218
00:07:40,880 --> 00:07:43,120
proof limitations for b block sponge

219
00:07:43,120 --> 00:07:44,639
collisions

220
00:07:44,639 --> 00:07:48,240
very briefly these are our results uh we

221
00:07:48,240 --> 00:07:50,479
give a new attack for finding one block

222
00:07:50,479 --> 00:07:53,440
collisions and this attack in particular

223
00:07:53,440 --> 00:07:55,199
uses a helmet's func

224
00:07:55,199 --> 00:07:56,840
helmet's random function inversion as a

225
00:07:56,840 --> 00:07:59,039
subroutine we give a different attack

226
00:07:59,039 --> 00:08:02,080
for other values of b uh which is this

227
00:08:02,080 --> 00:08:04,879
attack is inspired by rainbow tables

228
00:08:04,879 --> 00:08:07,120
we prove limitations for values of b

229
00:08:07,120 --> 00:08:09,280
equals one and two using two different

230
00:08:09,280 --> 00:08:10,639
techniques

231
00:08:10,639 --> 00:08:12,560
uh one thing i would like to highlight

232
00:08:12,560 --> 00:08:14,800
here is uh the ability of the adversary

233
00:08:14,800 --> 00:08:17,759
to make inverse query to the permutation

234
00:08:17,759 --> 00:08:19,840
actually helps us give this new attack

235
00:08:19,840 --> 00:08:21,759
for finding one block collisions but at

236
00:08:21,759 --> 00:08:24,319
the same time makes proving limitations

237
00:08:24,319 --> 00:08:27,360
significantly harder than for merkel

238
00:08:27,360 --> 00:08:29,759
dengard

239
00:08:29,840 --> 00:08:31,280
also the

240
00:08:31,280 --> 00:08:34,080
bounds that we have for the the best

241
00:08:34,080 --> 00:08:35,679
attacks and the

242
00:08:35,679 --> 00:08:37,599
best limitations we can prove

243
00:08:37,599 --> 00:08:39,919
do not match thereby leading to several

244
00:08:39,919 --> 00:08:42,240
open problems which i'll talk more about

245
00:08:42,240 --> 00:08:44,320
at the end

246
00:08:44,320 --> 00:08:45,600
in more detail

247
00:08:45,600 --> 00:08:48,000
we have a new attack for v equals one

248
00:08:48,000 --> 00:08:49,839
that has disadvantage

249
00:08:49,839 --> 00:08:53,200
uh the one here in the subscript uh

250
00:08:53,200 --> 00:08:54,959
uh the advantage for finding one block

251
00:08:54,959 --> 00:08:56,000
collision

252
00:08:56,000 --> 00:08:58,880
uh uh the previously best known attacks

253
00:08:58,880 --> 00:09:00,720
for finding one block collision was

254
00:09:00,720 --> 00:09:02,720
essentially what we call the trivial

255
00:09:02,720 --> 00:09:06,240
attack uh where the adversary just uh

256
00:09:06,240 --> 00:09:09,120
remembers collisions for s different ivs

257
00:09:09,120 --> 00:09:11,680
in the pre-processing phase and if the

258
00:09:11,680 --> 00:09:13,760
iv it got as input in the online phase

259
00:09:13,760 --> 00:09:16,399
was not among those ssivs it just did

260
00:09:16,399 --> 00:09:18,000
about this style attack

261
00:09:18,000 --> 00:09:20,000
for the case of mark and damgar this

262
00:09:20,000 --> 00:09:22,480
attack this trivial attack was in fact

263
00:09:22,480 --> 00:09:23,920
provably optimal

264
00:09:23,920 --> 00:09:26,000
however the new attack that we gave for

265
00:09:26,000 --> 00:09:28,480
sponge is actually better than the

266
00:09:28,480 --> 00:09:29,920
trivial attack for certain ranges of

267
00:09:29,920 --> 00:09:31,279
parameters

268
00:09:31,279 --> 00:09:33,920
for example when c and r are the same

269
00:09:33,920 --> 00:09:36,160
for s equals two power four c by five

270
00:09:36,160 --> 00:09:38,640
and t equals two power c by five uh our

271
00:09:38,640 --> 00:09:40,399
attack has constant advantage while the

272
00:09:40,399 --> 00:09:42,160
trivial attack has advantage that is

273
00:09:42,160 --> 00:09:45,040
exponentially small in c

274
00:09:45,040 --> 00:09:46,000
uh

275
00:09:46,000 --> 00:09:48,240
we give a a different attack for other

276
00:09:48,240 --> 00:09:49,760
values of b

277
00:09:49,760 --> 00:09:52,640
this attack is essentially the analog of

278
00:09:52,640 --> 00:09:54,959
an of a similar attack for mark and damn

279
00:09:54,959 --> 00:09:56,880
guard for values of b greater than

280
00:09:56,880 --> 00:10:00,080
equals two and this is inspired by the

281
00:10:00,080 --> 00:10:02,240
rainbow tables attack ins

282
00:10:02,240 --> 00:10:04,880
introduced by wesley

283
00:10:04,880 --> 00:10:06,959
uh we proved the following limitation

284
00:10:06,959 --> 00:10:08,240
for

285
00:10:08,240 --> 00:10:10,000
for the best possible attacks for one

286
00:10:10,000 --> 00:10:12,480
block collisions uh using the uh bit

287
00:10:12,480 --> 00:10:14,800
fixing technique uh

288
00:10:14,800 --> 00:10:15,760
which

289
00:10:15,760 --> 00:10:18,560
reduces which upper bounds the advantage

290
00:10:18,560 --> 00:10:21,200
of an sd adversary with the advantage of

291
00:10:21,200 --> 00:10:23,360
an adversary that has no preprocessing

292
00:10:23,360 --> 00:10:26,000
but can instead fix at most s times

293
00:10:26,000 --> 00:10:27,279
three points of the permutation and

294
00:10:27,279 --> 00:10:29,360
making the analysis easier

295
00:10:29,360 --> 00:10:32,720
uh we believe that the first term

296
00:10:32,720 --> 00:10:35,279
in this bound is not tight and

297
00:10:35,279 --> 00:10:38,160
it could possibly be improved

298
00:10:38,160 --> 00:10:40,880
uh we finally we proved this limitation

299
00:10:40,880 --> 00:10:43,120
for finding two block collisions via the

300
00:10:43,120 --> 00:10:45,360
multi-instance framework

301
00:10:45,360 --> 00:10:46,880
which was recently introduced by chung

302
00:10:46,880 --> 00:10:49,680
at all and akshay metal uh and in turn

303
00:10:49,680 --> 00:10:52,560
inspired by the techniques for proving

304
00:10:52,560 --> 00:10:54,480
constructive chart of bounds by impalia

305
00:10:54,480 --> 00:10:56,880
zone covenants uh this framework

306
00:10:56,880 --> 00:10:59,360
involves reduction to an adversary

307
00:10:59,360 --> 00:11:01,839
where diversity has no pre-processing

308
00:11:01,839 --> 00:11:03,760
and has to find collisions with respect

309
00:11:03,760 --> 00:11:07,200
to s randomly chosen ivs

310
00:11:07,200 --> 00:11:09,200
one interesting

311
00:11:09,200 --> 00:11:10,720
very interesting thing about this result

312
00:11:10,720 --> 00:11:12,880
is that it shows us it is strictly

313
00:11:12,880 --> 00:11:15,519
harder to find two block collisions than

314
00:11:15,519 --> 00:11:16,880
t block ones

315
00:11:16,880 --> 00:11:19,600
thus giving a separation similar to what

316
00:11:19,600 --> 00:11:22,640
we already know for merkle dam guard

317
00:11:22,640 --> 00:11:26,320
further uh this shows us that our attack

318
00:11:26,320 --> 00:11:28,560
for b equals two is actually optimal

319
00:11:28,560 --> 00:11:31,440
when st cube is less than two part c

320
00:11:31,440 --> 00:11:34,000
uh and uh we believe that the last term

321
00:11:34,000 --> 00:11:36,399
in in our bound is not tight and uh

322
00:11:36,399 --> 00:11:39,600
there's room for improvement

323
00:11:39,920 --> 00:11:40,839
so

324
00:11:40,839 --> 00:11:43,279
summarizing after our work this is what

325
00:11:43,279 --> 00:11:44,959
the state of affairs looks like for

326
00:11:44,959 --> 00:11:46,320
spawns and the only thing i'd like to

327
00:11:46,320 --> 00:11:48,800
highlight here is that for all values of

328
00:11:48,800 --> 00:11:49,519
b

329
00:11:49,519 --> 00:11:51,680
there are gaps for the best attack we

330
00:11:51,680 --> 00:11:53,440
know and the best limitation that we can

331
00:11:53,440 --> 00:11:55,279
prove

332
00:11:55,279 --> 00:11:57,200
uh i refer you to our paper for more

333
00:11:57,200 --> 00:11:59,279
details about our two limitation results

334
00:11:59,279 --> 00:12:01,279
and the attack for b greater than equals

335
00:12:01,279 --> 00:12:03,600
two and for the rest of the talk uh i'll

336
00:12:03,600 --> 00:12:05,920
be uh covering our new attack for

337
00:12:05,920 --> 00:12:09,120
finding one block collisions

338
00:12:09,680 --> 00:12:11,440
so we given a tag that has this

339
00:12:11,440 --> 00:12:13,279
following advantage um

340
00:12:13,279 --> 00:12:16,000
looking a bit ahead uh i'll define this

341
00:12:16,000 --> 00:12:18,480
quantity epsilon h

342
00:12:18,480 --> 00:12:20,560
to be the square root of the quantity

343
00:12:20,560 --> 00:12:22,720
inside the omega

344
00:12:22,720 --> 00:12:25,920
this is essentially the advantage or

345
00:12:25,920 --> 00:12:27,839
achieved by helmand's attack for

346
00:12:27,839 --> 00:12:28,880
inverting

347
00:12:28,880 --> 00:12:30,320
random functions

348
00:12:30,320 --> 00:12:31,839
the reason that this appears in our

349
00:12:31,839 --> 00:12:33,680
bound is because we will be using

350
00:12:33,680 --> 00:12:37,120
helmand's attack as a subroutine

351
00:12:37,120 --> 00:12:38,959
so when an adversary has to find a one

352
00:12:38,959 --> 00:12:40,399
block collision

353
00:12:40,399 --> 00:12:43,360
for sponge what it really has to do is

354
00:12:43,360 --> 00:12:46,800
it has to find two distinct messages uh

355
00:12:46,800 --> 00:12:49,279
m and m prime such that the evaluation

356
00:12:49,279 --> 00:12:50,720
of the permutation

357
00:12:50,720 --> 00:12:54,160
on m i v and m prime iv produce the same

358
00:12:54,160 --> 00:12:56,639
first r bits of the output

359
00:12:56,639 --> 00:12:57,360
uh

360
00:12:57,360 --> 00:13:00,880
here i'll use the index one and two to

361
00:13:00,880 --> 00:13:03,279
denote the first r bits and the last c

362
00:13:03,279 --> 00:13:06,639
bits of a spawn state respectively

363
00:13:06,639 --> 00:13:08,639
uh as a first step to constructing an

364
00:13:08,639 --> 00:13:11,040
adversary what we'll do is we'll try

365
00:13:11,040 --> 00:13:12,320
we'll switch to

366
00:13:12,320 --> 00:13:14,079
trying to switch to

367
00:13:14,079 --> 00:13:16,320
make that version solving a much harder

368
00:13:16,320 --> 00:13:17,760
problem

369
00:13:17,760 --> 00:13:18,800
where

370
00:13:18,800 --> 00:13:21,600
not only do we want an adversary uh to

371
00:13:21,600 --> 00:13:23,760
find two messages m and m prime such

372
00:13:23,760 --> 00:13:25,760
that the evaluation of pi on m i v and m

373
00:13:25,760 --> 00:13:28,800
prime iv have the same first r bits of

374
00:13:28,800 --> 00:13:30,560
the output we want those r bits of the

375
00:13:30,560 --> 00:13:33,120
output to be all zeros the reason for

376
00:13:33,120 --> 00:13:34,800
making the switch to a harder problem

377
00:13:34,800 --> 00:13:37,360
will become clear very soon

378
00:13:37,360 --> 00:13:39,279
to that end uh let's take an alternate

379
00:13:39,279 --> 00:13:40,560
view of the problem

380
00:13:40,560 --> 00:13:43,279
let's define a function f which has c

381
00:13:43,279 --> 00:13:45,839
bits input and c boots output

382
00:13:45,839 --> 00:13:50,320
as the last c bits of the evaluation of

383
00:13:50,320 --> 00:13:53,519
of pi inverse or on r0s followed by the

384
00:13:53,519 --> 00:13:55,040
input

385
00:13:55,040 --> 00:13:57,839
uh the main thing i would like to

386
00:13:57,839 --> 00:14:00,320
highlight about this function f is it is

387
00:14:00,320 --> 00:14:02,399
independent of iv

388
00:14:02,399 --> 00:14:04,399
uh we actually switched to solving a

389
00:14:04,399 --> 00:14:06,480
harder problem because we wanted the

390
00:14:06,480 --> 00:14:08,480
function to have this property

391
00:14:08,480 --> 00:14:11,040
and this property would in turn allow us

392
00:14:11,040 --> 00:14:13,519
to use existing pre-processing attacks

393
00:14:13,519 --> 00:14:16,959
for function inversion let's see how

394
00:14:16,959 --> 00:14:18,560
so we propose the following attack

395
00:14:18,560 --> 00:14:19,680
strategy

396
00:14:19,680 --> 00:14:23,040
given on a random ips input we invert

397
00:14:23,040 --> 00:14:24,480
the function f

398
00:14:24,480 --> 00:14:25,360
uh

399
00:14:25,360 --> 00:14:26,160
on

400
00:14:26,160 --> 00:14:29,519
iv to find two distinct pre images x and

401
00:14:29,519 --> 00:14:30,959
x prime

402
00:14:30,959 --> 00:14:33,680
and then we compute the message m as the

403
00:14:33,680 --> 00:14:35,920
evaluation as the first r bits of the

404
00:14:35,920 --> 00:14:39,360
output of evaluation of pi inverse on r

405
00:14:39,360 --> 00:14:41,600
zeros followed by x and similarly

406
00:14:41,600 --> 00:14:44,160
compute m prime and output these two

407
00:14:44,160 --> 00:14:45,519
messages

408
00:14:45,519 --> 00:14:47,519
okay why does this even make any sense

409
00:14:47,519 --> 00:14:48,480
uh

410
00:14:48,480 --> 00:14:51,279
uh observe that if indeed x was an

411
00:14:51,279 --> 00:14:54,560
inverse of iv under f we have that the

412
00:14:54,560 --> 00:14:57,120
last r bits of the evaluation of pi

413
00:14:57,120 --> 00:15:00,399
inverse on r zeros followed by x is iv

414
00:15:00,399 --> 00:15:02,160
and we already know from its definition

415
00:15:02,160 --> 00:15:04,560
that the first uh our bits of the

416
00:15:04,560 --> 00:15:06,480
evaluation is m

417
00:15:06,480 --> 00:15:09,440
this means that uh the the

418
00:15:09,440 --> 00:15:11,440
first are our bits of the evaluation of

419
00:15:11,440 --> 00:15:14,639
pi on m and iv are all zeros

420
00:15:14,639 --> 00:15:17,279
and we can prove uh the same fact for m

421
00:15:17,279 --> 00:15:18,399
prime

422
00:15:18,399 --> 00:15:22,160
so now given that we can invert uh f on

423
00:15:22,160 --> 00:15:24,959
iv and find two distinct premises we

424
00:15:24,959 --> 00:15:28,880
have an attack but how do we do this

425
00:15:28,880 --> 00:15:31,600
so function inversion is a has been in

426
00:15:31,600 --> 00:15:34,000
the pre-processing setting has been

427
00:15:34,000 --> 00:15:35,680
a well studied problem

428
00:15:35,680 --> 00:15:37,519
uh it was first studied by helmand and

429
00:15:37,519 --> 00:15:39,279
later by fiat and r

430
00:15:39,279 --> 00:15:40,800
the specific setting that we are

431
00:15:40,800 --> 00:15:42,959
interested in is when the function f is

432
00:15:42,959 --> 00:15:44,320
a random one

433
00:15:44,320 --> 00:15:46,959
ah there's an adversary which is a two

434
00:15:46,959 --> 00:15:49,519
phase one it's a pre-processing phase it

435
00:15:49,519 --> 00:15:51,680
gets the function as input

436
00:15:51,680 --> 00:15:53,920
it can compute any arbitrary as bits of

437
00:15:53,920 --> 00:15:55,360
advice on it

438
00:15:55,360 --> 00:15:57,839
and which it passes on to the online

439
00:15:57,839 --> 00:15:58,720
phase

440
00:15:58,720 --> 00:16:00,959
which gets additionally a randomly

441
00:16:00,959 --> 00:16:02,800
sampled value y from the image of the

442
00:16:02,800 --> 00:16:03,839
function

443
00:16:03,839 --> 00:16:05,920
can make at most t queries to the

444
00:16:05,920 --> 00:16:09,279
function and it wins if it can output

445
00:16:09,279 --> 00:16:12,639
some x such that f of x equals y

446
00:16:12,639 --> 00:16:15,360
hellman gave an attack

447
00:16:15,360 --> 00:16:18,079
gave an explicit adversary that has the

448
00:16:18,079 --> 00:16:20,240
following advantage

449
00:16:20,240 --> 00:16:22,720
epsilon h which i defined earlier

450
00:16:22,720 --> 00:16:24,560
ah now the question is are we done can

451
00:16:24,560 --> 00:16:26,240
we just plug this in

452
00:16:26,240 --> 00:16:28,240
uh turns out there are several technical

453
00:16:28,240 --> 00:16:30,320
challenges that we need to overcome

454
00:16:30,320 --> 00:16:33,040
uh first off this function s is not a

455
00:16:33,040 --> 00:16:34,880
random function while helmets attack

456
00:16:34,880 --> 00:16:37,040
works for random functions

457
00:16:37,040 --> 00:16:39,600
uh secondly uh the

458
00:16:39,600 --> 00:16:41,839
challenge that the random iv may not

459
00:16:41,839 --> 00:16:44,560
even be in the image of the function

460
00:16:44,560 --> 00:16:47,759
finally uh hellman's attack guarantees

461
00:16:47,759 --> 00:16:48,639
us

462
00:16:48,639 --> 00:16:51,519
only one pre-image while we need to find

463
00:16:51,519 --> 00:16:53,360
two distinct primitives

464
00:16:53,360 --> 00:16:54,240
i'll

465
00:16:54,240 --> 00:16:56,720
speak very briefly uh how we handle all

466
00:16:56,720 --> 00:16:58,560
the three challenges

467
00:16:58,560 --> 00:17:01,839
so for the first challenge uh

468
00:17:01,839 --> 00:17:03,440
first we note that there is a more

469
00:17:03,440 --> 00:17:05,760
general algorithm for function inversion

470
00:17:05,760 --> 00:17:08,160
that works for general functions by fiat

471
00:17:08,160 --> 00:17:09,280
and r

472
00:17:09,280 --> 00:17:11,599
but using that does not really suffice

473
00:17:11,599 --> 00:17:13,359
for us because the attack we end up

474
00:17:13,359 --> 00:17:16,160
getting finally has advantage worse than

475
00:17:16,160 --> 00:17:19,839
the trigger type what we end up doing

476
00:17:19,839 --> 00:17:22,799
is observing that f is close enough to a

477
00:17:22,799 --> 00:17:24,240
random function

478
00:17:24,240 --> 00:17:28,480
for us to adapt the helmet's analysis

479
00:17:28,640 --> 00:17:30,400
on to the second challenge that the

480
00:17:30,400 --> 00:17:32,720
random iv might not

481
00:17:32,720 --> 00:17:34,400
be in the image of f

482
00:17:34,400 --> 00:17:37,360
so an initial observation is a constant

483
00:17:37,360 --> 00:17:39,039
fraction of the co-domain has at least

484
00:17:39,039 --> 00:17:40,559
two pre-images

485
00:17:40,559 --> 00:17:42,720
but note that this does not suffice

486
00:17:42,720 --> 00:17:43,520
because

487
00:17:43,520 --> 00:17:46,160
a helmet's attack might fail for this

488
00:17:46,160 --> 00:17:48,240
constant fraction of the co-domain

489
00:17:48,240 --> 00:17:50,320
so what we do is we analyze elements

490
00:17:50,320 --> 00:17:52,559
attack and prove a very strong statement

491
00:17:52,559 --> 00:17:53,760
showing that

492
00:17:53,760 --> 00:17:54,880
uh

493
00:17:54,880 --> 00:17:57,280
for any fixed value in the

494
00:17:57,280 --> 00:17:59,840
codomain the elements attack succeeds

495
00:17:59,840 --> 00:18:01,600
with probability that is proportional to

496
00:18:01,600 --> 00:18:04,320
the number of pre-images that value has

497
00:18:04,320 --> 00:18:06,400
and uh this turns out to be enough for

498
00:18:06,400 --> 00:18:07,440
for our

499
00:18:07,440 --> 00:18:09,200
case

500
00:18:09,200 --> 00:18:11,520
finally uh we need to find two distinct

501
00:18:11,520 --> 00:18:13,520
pre-images while helmets attack only

502
00:18:13,520 --> 00:18:15,280
guarantees as one

503
00:18:15,280 --> 00:18:17,679
uh the first thought could be to just

504
00:18:17,679 --> 00:18:20,400
run the online phase twice

505
00:18:20,400 --> 00:18:22,559
uh with different randomness and hope

506
00:18:22,559 --> 00:18:24,960
that it gives us two distinct images but

507
00:18:24,960 --> 00:18:27,760
it's not immediately clear that it works

508
00:18:27,760 --> 00:18:29,760
so we further analyze elements attack

509
00:18:29,760 --> 00:18:33,120
and show that in fact for a value y it

510
00:18:33,120 --> 00:18:34,240
finds a

511
00:18:34,240 --> 00:18:36,960
premade uniformly in f inverse of y

512
00:18:36,960 --> 00:18:38,240
and this

513
00:18:38,240 --> 00:18:40,320
this in turn shows that it's enough to

514
00:18:40,320 --> 00:18:41,679
actually run the attack twice with

515
00:18:41,679 --> 00:18:43,200
different randoms

516
00:18:43,200 --> 00:18:45,280
and in and that's one of the reasons we

517
00:18:45,280 --> 00:18:48,320
end up getting an epsilon h square

518
00:18:48,320 --> 00:18:49,760
type of bound

519
00:18:49,760 --> 00:18:51,760
uh there are of course many technical

520
00:18:51,760 --> 00:18:54,160
subtleties for which i refer you to the

521
00:18:54,160 --> 00:18:57,440
paper for details

522
00:18:57,440 --> 00:18:59,440
uh so there are two main takeaway

523
00:18:59,440 --> 00:19:01,600
messages from this work

524
00:19:01,600 --> 00:19:03,840
first uh the ability of an adversary to

525
00:19:03,840 --> 00:19:06,080
make inverse queries in response

526
00:19:06,080 --> 00:19:08,640
construction are actually very useful

527
00:19:08,640 --> 00:19:10,480
to give new attacks

528
00:19:10,480 --> 00:19:12,640
in fact the this ability allows us to

529
00:19:12,640 --> 00:19:15,039
give an attack for sponge and analog for

530
00:19:15,039 --> 00:19:16,799
which does not exist for merkel dam

531
00:19:16,799 --> 00:19:18,320
guard

532
00:19:18,320 --> 00:19:21,120
secondly uh just like mark lam guard

533
00:19:21,120 --> 00:19:23,039
even for sponge finding short collisions

534
00:19:23,039 --> 00:19:24,960
like two block collisions are probably

535
00:19:24,960 --> 00:19:26,880
harder to find than arbitrary length

536
00:19:26,880 --> 00:19:28,080
ones

537
00:19:28,080 --> 00:19:29,919
uh there are several open problems of

538
00:19:29,919 --> 00:19:32,400
course uh one is tightening improving

539
00:19:32,400 --> 00:19:34,160
tight bounce for values of b equals one

540
00:19:34,160 --> 00:19:36,559
and two

541
00:19:36,799 --> 00:19:39,280
second our attack for uh values of b

542
00:19:39,280 --> 00:19:41,360
greater than equals two uh do not

543
00:19:41,360 --> 00:19:43,440
leverage the inverse query in any way

544
00:19:43,440 --> 00:19:45,280
and coming up with new attacks that do

545
00:19:45,280 --> 00:19:46,960
would be an interesting open

546
00:19:46,960 --> 00:19:48,960
or interesting question for

547
00:19:48,960 --> 00:19:51,440
uh uh investigation

548
00:19:51,440 --> 00:19:53,360
uh finally

549
00:19:53,360 --> 00:19:54,320
proving

550
00:19:54,320 --> 00:19:55,280
new

551
00:19:55,280 --> 00:19:57,520
limitations for values of b greater than

552
00:19:57,520 --> 00:19:58,640
equals three

553
00:19:58,640 --> 00:20:00,960
would also be a possible direction of

554
00:20:00,960 --> 00:20:02,400
future research

555
00:20:02,400 --> 00:20:03,919
uh the full version of our paper is an

556
00:20:03,919 --> 00:20:07,799
eprint thank you

557
00:20:12,480 --> 00:20:14,559
thank you we have time for one question

558
00:20:14,559 --> 00:20:17,678
is there any questions

559
00:20:19,760 --> 00:20:24,039
all right let's thank our speaker again

560
00:20:46,159 --> 00:20:49,159
up

561
00:21:20,880 --> 00:21:24,320
oh hold on i'll introduce you

562
00:21:25,679 --> 00:21:28,400
uh our next talk is going to be on time

563
00:21:28,400 --> 00:21:30,080
space tradeoffs for bounded links

564
00:21:30,080 --> 00:21:32,480
collisions and merkle dam guard hashing

565
00:21:32,480 --> 00:21:34,799
which is a soft merge with time space

566
00:21:34,799 --> 00:21:36,960
lower bounds for finding collisions in

567
00:21:36,960 --> 00:21:39,120
merkle dam guard hash functions

568
00:21:39,120 --> 00:21:41,919
and akshima will give the talk

569
00:21:41,919 --> 00:21:43,280
hello everyone

570
00:21:43,280 --> 00:21:46,240
today i will be talking about a work uh

571
00:21:46,240 --> 00:21:48,720
about finding collisions in md-based

572
00:21:48,720 --> 00:21:51,440
hash functions uh with pre-computation

573
00:21:51,440 --> 00:21:53,840
uh this is a joint work with cr go and

574
00:21:53,840 --> 00:21:56,000
japan glue

575
00:21:56,000 --> 00:21:56,840
um

576
00:21:56,840 --> 00:21:59,840
so uh ashrajit was kind enough to

577
00:21:59,840 --> 00:22:01,679
introduce what is merkel damgard but i

578
00:22:01,679 --> 00:22:05,200
would just go about it again so

579
00:22:05,200 --> 00:22:07,039
merkle dangard is one of the most

580
00:22:07,039 --> 00:22:09,360
popular constructions for

581
00:22:09,360 --> 00:22:10,960
hash functions

582
00:22:10,960 --> 00:22:13,360
it is so popular that it motivated us

583
00:22:13,360 --> 00:22:15,440
and a lot of other prior works to study

584
00:22:15,440 --> 00:22:17,360
this particular construction

585
00:22:17,360 --> 00:22:20,480
uh a lot of hash algorithms like md5

586
00:22:20,480 --> 00:22:23,520
sha-1 sha-2 they all their designs are

587
00:22:23,520 --> 00:22:27,360
based on this uh construction so

588
00:22:27,360 --> 00:22:29,280
how does this construction work

589
00:22:29,280 --> 00:22:31,039
this construction uses a one-way

590
00:22:31,039 --> 00:22:34,240
compression function to hash messages of

591
00:22:34,240 --> 00:22:37,520
arbitrary length and how they do that is

592
00:22:37,520 --> 00:22:39,280
they break the message into blocks of

593
00:22:39,280 --> 00:22:40,559
fixed size

594
00:22:40,559 --> 00:22:42,880
uh for the rest of this talk i will

595
00:22:42,880 --> 00:22:45,280
always denote a compression function by

596
00:22:45,280 --> 00:22:49,600
h and they would always be in the uh

597
00:22:49,600 --> 00:22:51,840
like it would always be from the

598
00:22:51,840 --> 00:22:54,880
domain uh of size n times m

599
00:22:54,880 --> 00:22:58,000
to a range of size n

600
00:22:58,000 --> 00:23:00,480
so in this diagram this uh the message

601
00:23:00,480 --> 00:23:01,520
is x

602
00:23:01,520 --> 00:23:04,400
and it's broken into b blocks x1 through

603
00:23:04,400 --> 00:23:07,120
xb and then the compression function is

604
00:23:07,120 --> 00:23:09,360
iteratively applied on

605
00:23:09,360 --> 00:23:14,559
these blocks to obtain the output of mdh

606
00:23:14,640 --> 00:23:17,360
assuming that h is a random function it

607
00:23:17,360 --> 00:23:20,000
is known that any adversary that makes t

608
00:23:20,000 --> 00:23:22,720
queries has an advantage of up to t

609
00:23:22,720 --> 00:23:25,200
square over n

610
00:23:25,200 --> 00:23:27,600
but this is uh when we think that when

611
00:23:27,600 --> 00:23:30,240
this is when we uh when the adversary

612
00:23:30,240 --> 00:23:33,919
has no information about h beforehand

613
00:23:33,919 --> 00:23:36,480
uh it it is perfectly possible and

614
00:23:36,480 --> 00:23:38,320
practical for the adversary to

615
00:23:38,320 --> 00:23:40,799
pre-compute some information about etch

616
00:23:40,799 --> 00:23:42,799
and use that later to find better

617
00:23:42,799 --> 00:23:44,080
attacks

618
00:23:44,080 --> 00:23:45,200
um

619
00:23:45,200 --> 00:23:47,360
in fact rainbow tables is a very good

620
00:23:47,360 --> 00:23:50,240
example of precomputing adversaries and

621
00:23:50,240 --> 00:23:52,559
their power to launch better attacks for

622
00:23:52,559 --> 00:23:54,000
function inversion

623
00:23:54,000 --> 00:23:56,080
and now we wanted to study the power of

624
00:23:56,080 --> 00:23:58,159
pre-computing adversaries for finding

625
00:23:58,159 --> 00:24:00,080
for collision finding in merkle dam

626
00:24:00,080 --> 00:24:02,159
guard based hash functions

627
00:24:02,159 --> 00:24:03,440
so um

628
00:24:03,440 --> 00:24:05,760
this is our problem statement and i

629
00:24:05,760 --> 00:24:08,320
would like to establish some uh

630
00:24:08,320 --> 00:24:10,640
parameters in our model so we would be

631
00:24:10,640 --> 00:24:12,400
talking about uh

632
00:24:12,400 --> 00:24:15,360
adversaries uh that get s bits of advice

633
00:24:15,360 --> 00:24:18,000
precomputed advice they make atmos t

634
00:24:18,000 --> 00:24:20,400
queries to edge and they're required to

635
00:24:20,400 --> 00:24:22,400
find collisions that are at most b

636
00:24:22,400 --> 00:24:25,039
blocks long

637
00:24:25,600 --> 00:24:28,080
so a lot of prior works have studied

638
00:24:28,080 --> 00:24:30,960
this problem of collision finding with

639
00:24:30,960 --> 00:24:33,600
pre-computation particularly for merkel

640
00:24:33,600 --> 00:24:35,600
dam guard based hash functions

641
00:24:35,600 --> 00:24:38,080
and this is this table lists all the

642
00:24:38,080 --> 00:24:40,480
results of those prior works

643
00:24:40,480 --> 00:24:41,760
um

644
00:24:41,760 --> 00:24:44,720
kuretal's work from 2018 were the first

645
00:24:44,720 --> 00:24:46,960
who studied this problem and they showed

646
00:24:46,960 --> 00:24:48,880
indeed it is true

647
00:24:48,880 --> 00:24:51,200
that uh precomputing adversaries can

648
00:24:51,200 --> 00:24:53,279
launch better attacks they can find uh

649
00:24:53,279 --> 00:24:55,679
it is easier for them to find collisions

650
00:24:55,679 --> 00:24:57,600
uh with pre-computation

651
00:24:57,600 --> 00:25:00,080
uh so they give an attack they presented

652
00:25:00,080 --> 00:25:02,080
an attack that achieved an advantage of

653
00:25:02,080 --> 00:25:04,880
st square over n

654
00:25:04,880 --> 00:25:08,080
uh they were also able to prove that uh

655
00:25:08,080 --> 00:25:10,080
that was that those are like that is the

656
00:25:10,080 --> 00:25:12,559
optimal attack but there is a caveat in

657
00:25:12,559 --> 00:25:14,480
their attack

658
00:25:14,480 --> 00:25:16,000
and i would like to talk about that

659
00:25:16,000 --> 00:25:18,640
caveat with an example consider sha2

660
00:25:18,640 --> 00:25:20,799
which is an md-based hash function

661
00:25:20,799 --> 00:25:24,400
uh where n is equal to 2 to the 256 and

662
00:25:24,400 --> 00:25:27,279
m is a 512-bit space

663
00:25:27,279 --> 00:25:30,400
for any adversary that uh

664
00:25:30,400 --> 00:25:33,200
store that has an advice of 2 to the 70

665
00:25:33,200 --> 00:25:34,080
bits

666
00:25:34,080 --> 00:25:37,279
and their st square over n bound implies

667
00:25:37,279 --> 00:25:39,200
that the adversary needs to make about 2

668
00:25:39,200 --> 00:25:41,520
to the 93 queries in order to achieve

669
00:25:41,520 --> 00:25:43,440
constant advantage

670
00:25:43,440 --> 00:25:46,080
so however the uh the attack that uh the

671
00:25:46,080 --> 00:25:48,320
curating it all presented their attack

672
00:25:48,320 --> 00:25:50,400
finds collisions that are also like 2 to

673
00:25:50,400 --> 00:25:52,640
the 93 blocks long

674
00:25:52,640 --> 00:25:56,080
and 2 to the 93 blocks is like yota

675
00:25:56,080 --> 00:25:57,440
bytes of data

676
00:25:57,440 --> 00:26:01,039
uh think about the applications where uh

677
00:26:01,039 --> 00:26:02,640
hash functions are used like digital

678
00:26:02,640 --> 00:26:06,559
signatures and um like hashing passwords

679
00:26:06,559 --> 00:26:08,640
like any adversary that finds that's

680
00:26:08,640 --> 00:26:10,559
finding yota bytes of data

681
00:26:10,559 --> 00:26:12,720
is like it's meaningless that's not uh

682
00:26:12,720 --> 00:26:14,320
any meaningful attack

683
00:26:14,320 --> 00:26:17,200
so uh in one of my previous works with

684
00:26:17,200 --> 00:26:20,880
david andy and hotec we wanted to study

685
00:26:20,880 --> 00:26:23,600
what happens if an adversary is has to

686
00:26:23,600 --> 00:26:26,720
find like a b bounded length collisions

687
00:26:26,720 --> 00:26:29,760
so for b equals to 2 to the 20 the best

688
00:26:29,760 --> 00:26:32,559
attack that we could find required 2 to

689
00:26:32,559 --> 00:26:36,080
the 166 queries instead of 2 to the 193

690
00:26:36,080 --> 00:26:39,279
2 to the 93 queries so our best attack

691
00:26:39,279 --> 00:26:41,440
like uh it would achieve the advantage

692
00:26:41,440 --> 00:26:44,320
of stb over n instead of st square over

693
00:26:44,320 --> 00:26:45,120
n

694
00:26:45,120 --> 00:26:48,400
and this made us wonder if uh

695
00:26:48,400 --> 00:26:52,400
the st square over n bound uh was

696
00:26:52,400 --> 00:26:55,120
uh was pessimistic in in a practical

697
00:26:55,120 --> 00:26:56,640
setting where we are looking at bounded

698
00:26:56,640 --> 00:26:59,440
length collisions

699
00:27:00,400 --> 00:27:03,200
uh so we conjectured that so we gave

700
00:27:03,200 --> 00:27:05,520
this attack of uh that achieved stb over

701
00:27:05,520 --> 00:27:08,000
n as i uh told you before

702
00:27:08,000 --> 00:27:10,000
and we conjectured that it was the

703
00:27:10,000 --> 00:27:12,559
optimal attack however we could not

704
00:27:12,559 --> 00:27:14,720
prove that for all the precomputing

705
00:27:14,720 --> 00:27:17,360
adversaries we could show that only for

706
00:27:17,360 --> 00:27:19,200
a restricted class of adversaries and

707
00:27:19,200 --> 00:27:22,240
that is what this red esteric denotes

708
00:27:22,240 --> 00:27:23,200
uh

709
00:27:23,200 --> 00:27:25,360
what made us believe in our conjecture

710
00:27:25,360 --> 00:27:27,600
was the fact that we could prove it for

711
00:27:27,600 --> 00:27:29,919
two block collision finding uh that the

712
00:27:29,919 --> 00:27:32,960
advantage is st over n and it is indeed

713
00:27:32,960 --> 00:27:34,799
the case that finding uh short

714
00:27:34,799 --> 00:27:38,080
collisions is harder than finding uh

715
00:27:38,080 --> 00:27:39,679
collisions where there's no restriction

716
00:27:39,679 --> 00:27:42,240
on the length

717
00:27:42,320 --> 00:27:44,799
uh the follow-up work of gushal at all

718
00:27:44,799 --> 00:27:47,279
which has been accepted at this paper

719
00:27:47,279 --> 00:27:49,120
it's at this conference itself and uh

720
00:27:49,120 --> 00:27:52,000
soft merge with our work they managed to

721
00:27:52,000 --> 00:27:55,279
show that uh the stb conjecture of acdw

722
00:27:55,279 --> 00:27:58,000
is indeed true for constant b

723
00:27:58,000 --> 00:28:00,240
and uh how they did that more precisely

724
00:28:00,240 --> 00:28:02,880
was they gave uh they gave a bound

725
00:28:02,880 --> 00:28:05,840
that has a factor of log square s

726
00:28:05,840 --> 00:28:09,360
exponentially large in uh b

727
00:28:09,360 --> 00:28:11,600
so

728
00:28:12,320 --> 00:28:15,120
exponentially large in b and uh so this

729
00:28:15,120 --> 00:28:18,320
reduces to a polylog factor when b is a

730
00:28:18,320 --> 00:28:21,279
constant however this bound very quickly

731
00:28:21,279 --> 00:28:26,000
becomes meaningless as b grows larger

732
00:28:26,720 --> 00:28:28,960
they presented another bound

733
00:28:28,960 --> 00:28:31,200
which holds for any precomputing

734
00:28:31,200 --> 00:28:34,320
adversary and any b and that bound is s

735
00:28:34,320 --> 00:28:37,440
to the 4t b square over n

736
00:28:37,440 --> 00:28:40,240
however observe that when s cube b

737
00:28:40,240 --> 00:28:42,399
squared would be greater than t

738
00:28:42,399 --> 00:28:45,039
in that case this bound is worse than

739
00:28:45,039 --> 00:28:47,600
the st square over n bound of courier at

740
00:28:47,600 --> 00:28:50,640
all so this does not say anything uh

741
00:28:50,640 --> 00:28:52,880
about this parameter range like whether

742
00:28:52,880 --> 00:28:56,080
finding collisions is harder like or not

743
00:28:56,080 --> 00:28:59,039
so this is what motivated us to study

744
00:28:59,039 --> 00:29:00,960
this problem further

745
00:29:00,960 --> 00:29:03,440
and uh also like the attack like the

746
00:29:03,440 --> 00:29:05,919
proofs that were given by the acdw paper

747
00:29:05,919 --> 00:29:08,720
and gk paper uh they were very

748
00:29:08,720 --> 00:29:11,520
complicated so uh another

749
00:29:11,520 --> 00:29:14,480
objective for us was to simplify these

750
00:29:14,480 --> 00:29:17,279
proofs and we managed to do both of the

751
00:29:17,279 --> 00:29:18,480
both the things

752
00:29:18,480 --> 00:29:21,120
um and this so we managed to prove a

753
00:29:21,120 --> 00:29:24,799
bound of stb over n times max of one and

754
00:29:24,799 --> 00:29:27,360
st square over n

755
00:29:27,360 --> 00:29:29,279
for any b and any pre-computing

756
00:29:29,279 --> 00:29:32,000
adversary

757
00:29:32,320 --> 00:29:34,640
let us look at our more like this very

758
00:29:34,640 --> 00:29:37,279
unreadable bound mode carefully

759
00:29:37,279 --> 00:29:39,520
so what does this bound mean it means

760
00:29:39,520 --> 00:29:42,320
when st squared over n is less than or

761
00:29:42,320 --> 00:29:45,520
equal to 1 our bound would be stb over n

762
00:29:45,520 --> 00:29:48,080
and for so we managed to prove the stb

763
00:29:48,080 --> 00:29:52,159
conjecture for this parameter range

764
00:29:52,159 --> 00:29:54,880
when st square over n is greater than

765
00:29:54,880 --> 00:29:57,120
one in that case our bound would be stb

766
00:29:57,120 --> 00:29:59,760
over n times st square over n

767
00:29:59,760 --> 00:30:02,559
and even though this does not uh prove

768
00:30:02,559 --> 00:30:05,120
the stb conjecture it is worth noting

769
00:30:05,120 --> 00:30:06,799
that this bound would always be less

770
00:30:06,799 --> 00:30:08,640
than st square over n

771
00:30:08,640 --> 00:30:11,120
and which confirms that finding bounded

772
00:30:11,120 --> 00:30:12,880
length collision is definitely harder

773
00:30:12,880 --> 00:30:14,799
than finding collisions where there's no

774
00:30:14,799 --> 00:30:17,918
restriction on the length

775
00:30:18,720 --> 00:30:20,559
so before i talk about our techniques i

776
00:30:20,559 --> 00:30:22,880
would like to precisely uh define the

777
00:30:22,880 --> 00:30:25,440
model uh ashraji did that in his talk

778
00:30:25,440 --> 00:30:27,679
but i would just like to trade because i

779
00:30:27,679 --> 00:30:31,200
have made the slide so uh so uh

780
00:30:31,200 --> 00:30:33,520
in the pre-computation model the

781
00:30:33,520 --> 00:30:35,919
adversary works in two stages in the

782
00:30:35,919 --> 00:30:38,080
first stage adversary guess gets

783
00:30:38,080 --> 00:30:40,159
computationally unbounded access to the

784
00:30:40,159 --> 00:30:42,559
compression function h but it has to

785
00:30:42,559 --> 00:30:45,200
output a bounded length advice

786
00:30:45,200 --> 00:30:47,120
which would be s bits

787
00:30:47,120 --> 00:30:49,679
then in the second stage the adversary

788
00:30:49,679 --> 00:30:51,520
gets the challenge sort

789
00:30:51,520 --> 00:30:54,320
it takes the advice it gets to make t

790
00:30:54,320 --> 00:30:58,000
queries uh to etch and it is required to

791
00:30:58,000 --> 00:31:01,519
output messages that collide under mdh

792
00:31:01,519 --> 00:31:03,760
with the challenge sort and there is an

793
00:31:03,760 --> 00:31:05,360
additional restriction that these

794
00:31:05,360 --> 00:31:09,840
messages have to be at most blocks long

795
00:31:09,840 --> 00:31:12,799
um so

796
00:31:15,679 --> 00:31:17,919
i would just like to point out that why

797
00:31:17,919 --> 00:31:20,799
analyzing this model is so hard so

798
00:31:20,799 --> 00:31:24,080
observe that these q1 through q2 qt

799
00:31:24,080 --> 00:31:26,559
queries the responses to these queries

800
00:31:26,559 --> 00:31:29,120
can no longer be thought of as ids

801
00:31:29,120 --> 00:31:30,159
because

802
00:31:30,159 --> 00:31:32,799
the adversary gets x-bit information on

803
00:31:32,799 --> 00:31:35,039
edge

804
00:31:35,760 --> 00:31:37,519
so that's why they're querying it all

805
00:31:37,519 --> 00:31:41,039
they reduce the problem to uh finding uh

806
00:31:41,039 --> 00:31:43,200
like bounding the security in another

807
00:31:43,200 --> 00:31:47,279
model namely the pre-sampling model

808
00:31:47,279 --> 00:31:50,080
so the pre-sampling model is uh it works

809
00:31:50,080 --> 00:31:52,399
like again an adversary in this

810
00:31:52,399 --> 00:31:54,799
model works in two stages in the first

811
00:31:54,799 --> 00:31:57,519
stage the adversary gets to fix

812
00:31:57,519 --> 00:32:02,320
uh and fix uh the function h at p points

813
00:32:02,320 --> 00:32:04,480
then in the online phase it it does not

814
00:32:04,480 --> 00:32:07,120
get any advice it just gets uh the

815
00:32:07,120 --> 00:32:09,679
challenge sort it gets to make t queries

816
00:32:09,679 --> 00:32:12,320
uh to this function h and it has to

817
00:32:12,320 --> 00:32:15,919
output collisions uh so this where this

818
00:32:15,919 --> 00:32:17,039
etch

819
00:32:17,039 --> 00:32:18,240
is

820
00:32:18,240 --> 00:32:20,559
is the function with the hard coded

821
00:32:20,559 --> 00:32:22,799
points so when i say hard-coded points

822
00:32:22,799 --> 00:32:25,039
what that means is whatever was prefixed

823
00:32:25,039 --> 00:32:27,600
in the stage one for those points the

824
00:32:27,600 --> 00:32:30,240
adversary has to output the fixed uh

825
00:32:30,240 --> 00:32:32,320
point like the fixed uh

826
00:32:32,320 --> 00:32:34,159
response and for the other it can like

827
00:32:34,159 --> 00:32:38,159
uh respond with ids

828
00:32:39,360 --> 00:32:42,000
so uh credit it all showed that

829
00:32:42,000 --> 00:32:44,480
for any if the advantage of any

830
00:32:44,480 --> 00:32:46,960
adversary in the pre-sampling model

831
00:32:46,960 --> 00:32:50,240
where the adversary fixes st points and

832
00:32:50,240 --> 00:32:53,600
makes t queries uh is bounded by delta

833
00:32:53,600 --> 00:32:55,679
then the advantage of any collision

834
00:32:55,679 --> 00:32:58,080
finding adversary in the pre-computation

835
00:32:58,080 --> 00:33:00,159
model where they adversely

836
00:33:00,159 --> 00:33:02,320
make gets s-bit advice and makes t

837
00:33:02,320 --> 00:33:06,320
queries is of the order delta

838
00:33:06,799 --> 00:33:09,039
so apart from giving this reduction they

839
00:33:09,039 --> 00:33:11,039
showed like the advantage of for

840
00:33:11,039 --> 00:33:12,640
collision finding in the pre-sampling

841
00:33:12,640 --> 00:33:15,440
model is of the order st square over n

842
00:33:15,440 --> 00:33:16,720
which

843
00:33:16,720 --> 00:33:18,720
implies their bound in the

844
00:33:18,720 --> 00:33:21,919
pre-computation model

845
00:33:22,000 --> 00:33:26,159
the actw paper showed however uh

846
00:33:26,159 --> 00:33:29,200
we cannot hope to get any better bounce

847
00:33:29,200 --> 00:33:31,039
in the pre-sampling model for bounded

848
00:33:31,039 --> 00:33:32,320
length collision

849
00:33:32,320 --> 00:33:33,760
uh and that's

850
00:33:33,760 --> 00:33:36,640
they showed that by uh giving an attack

851
00:33:36,640 --> 00:33:38,399
for two block collision finding in the

852
00:33:38,399 --> 00:33:40,799
presom sampling model that achieved an

853
00:33:40,799 --> 00:33:44,399
advantage of st square over n

854
00:33:44,399 --> 00:33:47,039
so they reduced the problem to another

855
00:33:47,039 --> 00:33:49,039
model like solving in another model

856
00:33:49,039 --> 00:33:52,159
which is namely the multi-instance game

857
00:33:52,159 --> 00:33:54,159
now what is multi-instance game as the

858
00:33:54,159 --> 00:33:55,600
name suggests

859
00:33:55,600 --> 00:33:58,240
it's just the adversary gets multiple

860
00:33:58,240 --> 00:34:00,399
instances of a problem and it has to

861
00:34:00,399 --> 00:34:02,720
solve each one of them in order to win

862
00:34:02,720 --> 00:34:05,600
so for our particular case the adversary

863
00:34:05,600 --> 00:34:07,519
gets uh

864
00:34:07,519 --> 00:34:09,760
s solves one at a time and it gets to

865
00:34:09,760 --> 00:34:11,520
make t queries and it has to find

866
00:34:11,520 --> 00:34:13,599
collisions on each of these instances in

867
00:34:13,599 --> 00:34:16,240
order to win

868
00:34:17,040 --> 00:34:18,960
note that here again the adversary does

869
00:34:18,960 --> 00:34:20,480
not get an advice

870
00:34:20,480 --> 00:34:22,560
and it just has to solve all these s

871
00:34:22,560 --> 00:34:24,879
instances

872
00:34:24,879 --> 00:34:27,679
uh so actw paper showed that if the

873
00:34:27,679 --> 00:34:30,239
advantage of any uh collision finding

874
00:34:30,239 --> 00:34:32,000
adversity in the multi-instance game can

875
00:34:32,000 --> 00:34:35,599
be bounded by delta to the s where

876
00:34:35,599 --> 00:34:38,320
the adversary is making t queries for

877
00:34:38,320 --> 00:34:41,040
each instance and it gets s instances

878
00:34:41,040 --> 00:34:43,520
then the advantage for any adversary in

879
00:34:43,520 --> 00:34:46,000
the pre-computation model can be bounded

880
00:34:46,000 --> 00:34:48,719
by two times delta again the adversary

881
00:34:48,719 --> 00:34:51,679
here is getting an advice of s bits and

882
00:34:51,679 --> 00:34:54,800
making t queries

883
00:34:55,119 --> 00:34:58,000
uh so they also uh the acdw paper

884
00:34:58,000 --> 00:35:01,119
bounded uh there uh i bounded the

885
00:35:01,119 --> 00:35:02,880
advantage of this multi-instance gain to

886
00:35:02,880 --> 00:35:05,920
st plus t square over n to the power s

887
00:35:05,920 --> 00:35:07,680
for two block collision finding which

888
00:35:07,680 --> 00:35:08,880
implied they're bound in the

889
00:35:08,880 --> 00:35:11,839
pre-computation model

890
00:35:11,839 --> 00:35:15,920
um the gk paper um they used a similar

891
00:35:15,920 --> 00:35:18,640
approach as the acdw paper but because

892
00:35:18,640 --> 00:35:20,960
they were looking at like constant uh

893
00:35:20,960 --> 00:35:22,400
block collisions

894
00:35:22,400 --> 00:35:25,520
uh they had to cut they had a lot more

895
00:35:25,520 --> 00:35:27,280
types of collisions that they needed to

896
00:35:27,280 --> 00:35:29,599
handle so it was difficult for them like

897
00:35:29,599 --> 00:35:32,560
it was a more challenging task to bound

898
00:35:32,560 --> 00:35:35,520
the advantage in multi-instance game uh

899
00:35:35,520 --> 00:35:38,160
which they managed to do so uh for more

900
00:35:38,160 --> 00:35:40,720
details please refer to their talk on

901
00:35:40,720 --> 00:35:43,920
youtube and um they their paper is also

902
00:35:43,920 --> 00:35:46,720
up on e-print

903
00:35:46,800 --> 00:35:48,880
uh finally i want to talk about our

904
00:35:48,880 --> 00:35:51,599
techniques so we also reduced to the

905
00:35:51,599 --> 00:35:54,240
multi-instance game uh

906
00:35:54,240 --> 00:35:56,160
but we the way we viewed the

907
00:35:56,160 --> 00:35:58,480
multi-instance game model is slightly

908
00:35:58,480 --> 00:36:01,200
different and how we analyze it allowed

909
00:36:01,200 --> 00:36:04,320
us to get better bounds

910
00:36:04,320 --> 00:36:07,760
so let's fix an adversary and let x i be

911
00:36:07,760 --> 00:36:09,119
the indicator

912
00:36:09,119 --> 00:36:12,079
uh variable that adversary wins on salt

913
00:36:12,079 --> 00:36:13,760
ai

914
00:36:13,760 --> 00:36:16,720
what acdw paper and gk paper did was

915
00:36:16,720 --> 00:36:18,720
they looked at the probability that the

916
00:36:18,720 --> 00:36:20,880
adversary wins on all the solves

917
00:36:20,880 --> 00:36:22,560
simultaneously

918
00:36:22,560 --> 00:36:26,720
so what so if this like this box this uh

919
00:36:26,720 --> 00:36:30,160
this depicts uh s source and

920
00:36:30,160 --> 00:36:32,640
t uh queries and responses that are made

921
00:36:32,640 --> 00:36:34,240
for each of these faults

922
00:36:34,240 --> 00:36:36,640
so what they tried to do was if an

923
00:36:36,640 --> 00:36:38,480
adversary has to win on all these

924
00:36:38,480 --> 00:36:41,119
assaults it has to find collisions on

925
00:36:41,119 --> 00:36:43,040
all these which means there

926
00:36:43,040 --> 00:36:45,200
should be s collisions in these st

927
00:36:45,200 --> 00:36:47,280
queries

928
00:36:47,280 --> 00:36:48,400
and

929
00:36:48,400 --> 00:36:51,200
then these collisions can be compressed

930
00:36:51,200 --> 00:36:53,520
uh using this adversary

931
00:36:53,520 --> 00:36:54,560
however

932
00:36:54,560 --> 00:36:57,359
it should not be possible to compress h

933
00:36:57,359 --> 00:36:59,920
because h is a random function

934
00:36:59,920 --> 00:37:02,079
uh

935
00:37:03,040 --> 00:37:05,040
so that's how they were able to bound

936
00:37:05,040 --> 00:37:08,079
this probability that all xi's

937
00:37:08,079 --> 00:37:10,560
are one

938
00:37:10,560 --> 00:37:13,680
uh it is worth noting that uh in this

939
00:37:13,680 --> 00:37:15,520
like when they are like looking at all

940
00:37:15,520 --> 00:37:17,119
like this when they're like bounding

941
00:37:17,119 --> 00:37:19,839
this simultaneously uh there are a lot

942
00:37:19,839 --> 00:37:21,440
of different types of collisions that

943
00:37:21,440 --> 00:37:22,480
can happen

944
00:37:22,480 --> 00:37:24,720
and in order to like compress each of

945
00:37:24,720 --> 00:37:27,359
the cases uh sometimes like this this

946
00:37:27,359 --> 00:37:28,480
compression

947
00:37:28,480 --> 00:37:30,560
algorithms can become like very crazy

948
00:37:30,560 --> 00:37:32,720
and like unintuitive of what exactly is

949
00:37:32,720 --> 00:37:34,800
happening in the single instance

950
00:37:34,800 --> 00:37:35,520
so

951
00:37:35,520 --> 00:37:37,520
how we viewed this model is slightly

952
00:37:37,520 --> 00:37:38,480
different

953
00:37:38,480 --> 00:37:39,760
we uh

954
00:37:39,760 --> 00:37:42,240
we instead of bounding the like this

955
00:37:42,240 --> 00:37:43,920
on the left the term on the left we

956
00:37:43,920 --> 00:37:46,800
bounded the probability that uh

957
00:37:46,800 --> 00:37:49,839
the adversary wins in the iath instance

958
00:37:49,839 --> 00:37:52,000
given that it wins on all the previous i

959
00:37:52,000 --> 00:37:55,200
minus one instances

960
00:37:56,560 --> 00:37:58,000
so uh

961
00:37:58,000 --> 00:38:00,480
if the adversary so in the previous i

962
00:38:00,480 --> 00:38:02,560
minus one instances the adversary would

963
00:38:02,560 --> 00:38:04,720
have made a total of i minus one times t

964
00:38:04,720 --> 00:38:06,720
queries which is always like less than

965
00:38:06,720 --> 00:38:09,359
equal to st queries so we think of those

966
00:38:09,359 --> 00:38:11,839
as offline queries then the adversary

967
00:38:11,839 --> 00:38:14,640
gets the ith challenge sort ai and then

968
00:38:14,640 --> 00:38:16,480
it gets to make t queries which we refer

969
00:38:16,480 --> 00:38:18,400
to as the online queries

970
00:38:18,400 --> 00:38:21,440
so uh this sort of looks like still

971
00:38:21,440 --> 00:38:23,920
still like a single instance

972
00:38:23,920 --> 00:38:26,560
problem and um this

973
00:38:26,560 --> 00:38:28,400
and now now we need to bound this

974
00:38:28,400 --> 00:38:31,440
probability of x i given x less than i

975
00:38:31,440 --> 00:38:34,720
to a term a to a to a bound that is

976
00:38:34,720 --> 00:38:36,720
exactly the same as what we need in the

977
00:38:36,720 --> 00:38:38,960
pre-computation model

978
00:38:38,960 --> 00:38:42,800
so this becomes a little more intuitive

979
00:38:42,800 --> 00:38:45,200
so in order to explain our techniques in

980
00:38:45,200 --> 00:38:47,200
a little more detail i would just focus

981
00:38:47,200 --> 00:38:49,839
on one particular type of collision and

982
00:38:49,839 --> 00:38:52,640
this is this collision um here

983
00:38:52,640 --> 00:38:56,880
this curved uh arrows depict uh they

984
00:38:56,880 --> 00:38:59,920
are they denote queries q2 and q3 and

985
00:38:59,920 --> 00:39:02,400
the straight arrow one is q1 and for

986
00:39:02,400 --> 00:39:04,000
this type of collision like this

987
00:39:04,000 --> 00:39:06,000
collision depicts uh the colliding

988
00:39:06,000 --> 00:39:08,240
messages would be like m1 concatenated

989
00:39:08,240 --> 00:39:11,599
with m2 and m1 concatenated with m3

990
00:39:11,599 --> 00:39:13,440
and we are looking at the collision type

991
00:39:13,440 --> 00:39:17,040
where q2 q3 happen in the offline they

992
00:39:17,040 --> 00:39:19,599
happen among the offline queries and q1

993
00:39:19,599 --> 00:39:21,920
happens among the online queries

994
00:39:21,920 --> 00:39:24,720
the idea to note here is the output of

995
00:39:24,720 --> 00:39:27,839
q1 is limited to certain values what are

996
00:39:27,839 --> 00:39:30,079
those values

997
00:39:30,079 --> 00:39:32,640
they have to be the input sort of one of

998
00:39:32,640 --> 00:39:35,200
the st queries in the offline among the

999
00:39:35,200 --> 00:39:38,078
offline queries

1000
00:39:39,680 --> 00:39:41,839
which means the probability that there

1001
00:39:41,839 --> 00:39:45,760
exists a q1 like online query is at most

1002
00:39:45,760 --> 00:39:48,400
st square over n

1003
00:39:48,400 --> 00:39:50,240
but we can do better than that because

1004
00:39:50,240 --> 00:39:52,800
there is more structure to what these q2

1005
00:39:52,800 --> 00:39:56,480
q3 queries can be so these q2q so this

1006
00:39:56,480 --> 00:39:58,800
q2 query like the query

1007
00:39:58,800 --> 00:40:00,800
whose input solve has to be the output

1008
00:40:00,800 --> 00:40:02,480
of q1

1009
00:40:02,480 --> 00:40:05,040
has to be a query uh

1010
00:40:05,040 --> 00:40:07,680
that shares the input sort with another

1011
00:40:07,680 --> 00:40:10,560
query that has the same output so

1012
00:40:10,560 --> 00:40:12,800
basically we should be looking at how

1013
00:40:12,800 --> 00:40:15,680
many q2 q3 type pairs can exist among

1014
00:40:15,680 --> 00:40:18,799
the offline queries

1015
00:40:20,480 --> 00:40:22,480
so that's what we want to look at how

1016
00:40:22,480 --> 00:40:24,560
many pairs can there be and we call this

1017
00:40:24,560 --> 00:40:26,960
as useful knowledge gain that we get

1018
00:40:26,960 --> 00:40:29,920
from the offline queries

1019
00:40:29,920 --> 00:40:33,040
so in the worst case

1020
00:40:33,040 --> 00:40:35,359
in the worst case there can be st over

1021
00:40:35,359 --> 00:40:38,880
two such q two q three type pairs uh

1022
00:40:38,880 --> 00:40:41,520
because if we assume that every query in

1023
00:40:41,520 --> 00:40:43,200
the offline uh

1024
00:40:43,200 --> 00:40:45,760
phase shares this kind of structure with

1025
00:40:45,760 --> 00:40:47,280
another query then in that case there

1026
00:40:47,280 --> 00:40:50,480
will be st over two such pairs

1027
00:40:50,480 --> 00:40:53,040
and this implies a bound of st square

1028
00:40:53,040 --> 00:40:55,599
over n

1029
00:40:56,560 --> 00:40:59,200
but it's worth noting that the pro the

1030
00:40:59,200 --> 00:41:01,599
the chance that we can get like st over

1031
00:41:01,599 --> 00:41:03,520
two such pairs in the offline query is

1032
00:41:03,520 --> 00:41:06,720
very unlikely it's like it it has a very

1033
00:41:06,720 --> 00:41:08,640
small chance and this

1034
00:41:08,640 --> 00:41:10,960
what this st over two pair like this

1035
00:41:10,960 --> 00:41:13,839
bound is sort of a worst case analysis

1036
00:41:13,839 --> 00:41:15,359
and this is very similar to what was

1037
00:41:15,359 --> 00:41:17,440
happening in pre-sampling because

1038
00:41:17,440 --> 00:41:19,680
pre-sampling was allowing the

1039
00:41:19,680 --> 00:41:24,319
adversaries to fix these st points

1040
00:41:25,280 --> 00:41:26,079
so

1041
00:41:26,079 --> 00:41:28,240
and we believe that

1042
00:41:28,240 --> 00:41:30,880
we should be able to bound better via an

1043
00:41:30,880 --> 00:41:32,800
average case analysis which is which is

1044
00:41:32,800 --> 00:41:35,920
what we did so and we showed that the

1045
00:41:35,920 --> 00:41:38,960
probability of finding more than s pairs

1046
00:41:38,960 --> 00:41:42,560
uh q2 q3 like pairs is in st queries is

1047
00:41:42,560 --> 00:41:44,000
very very small

1048
00:41:44,000 --> 00:41:46,000
so which implies uh

1049
00:41:46,000 --> 00:41:48,640
with a good probability there are only s

1050
00:41:48,640 --> 00:41:51,680
such pairs among the offline queries and

1051
00:41:51,680 --> 00:41:53,839
which allows us to bound uh that the

1052
00:41:53,839 --> 00:41:56,480
probability of uh there existing a q1

1053
00:41:56,480 --> 00:42:00,720
like online query to be st over n

1054
00:42:01,280 --> 00:42:02,400
um

1055
00:42:02,400 --> 00:42:04,079
now there are a lot of different types

1056
00:42:04,079 --> 00:42:06,480
of collisions that can happen for b

1057
00:42:06,480 --> 00:42:08,720
equals to two and like general b

1058
00:42:08,720 --> 00:42:12,160
so uh this is just a brief overview of

1059
00:42:12,160 --> 00:42:14,400
how our proof works

1060
00:42:14,400 --> 00:42:16,880
we identified all types of useful

1061
00:42:16,880 --> 00:42:20,000
knowledge gains from the offline queries

1062
00:42:20,000 --> 00:42:21,839
for each type we showed that the

1063
00:42:21,839 --> 00:42:23,920
probability of high knowledge gain is

1064
00:42:23,920 --> 00:42:26,319
very small even conditioned on winning

1065
00:42:26,319 --> 00:42:28,880
in all the previous rounds

1066
00:42:28,880 --> 00:42:30,880
and when none of the knowledge gain is

1067
00:42:30,880 --> 00:42:33,920
high we can easily bound uh this

1068
00:42:33,920 --> 00:42:36,640
probability of x i given x less than i

1069
00:42:36,640 --> 00:42:39,520
as required

1070
00:42:40,720 --> 00:42:42,079
so um

1071
00:42:42,079 --> 00:42:43,599
for future work one of the most

1072
00:42:43,599 --> 00:42:45,119
important things that we would like to

1073
00:42:45,119 --> 00:42:46,240
know is

1074
00:42:46,240 --> 00:42:48,400
whether for st square greater than equal

1075
00:42:48,400 --> 00:42:51,119
to n if there is a better attack or if

1076
00:42:51,119 --> 00:42:53,280
there is a better security bound that is

1077
00:42:53,280 --> 00:42:55,119
definitely one of the most important

1078
00:42:55,119 --> 00:42:57,599
future works that we look forward to

1079
00:42:57,599 --> 00:42:58,720
doing

1080
00:42:58,720 --> 00:43:02,000
and thank you our paper is in

1081
00:43:02,000 --> 00:43:04,000
our paper is on eprint please give it a

1082
00:43:04,000 --> 00:43:06,960
read and thank you for your

1083
00:43:10,839 --> 00:43:15,279
attention do we have any questions

1084
00:43:18,079 --> 00:43:22,520
all right let's thank our speaker again

1085
00:43:49,040 --> 00:43:52,040
foreign

1086
00:44:08,000 --> 00:44:09,839
all right our next talk is going to be

1087
00:44:09,839 --> 00:44:12,800
sustain space and cumulative complexity

1088
00:44:12,800 --> 00:44:14,880
trade-offs for data dependent memory

1089
00:44:14,880 --> 00:44:17,280
hard functions and blake coleman will

1090
00:44:17,280 --> 00:44:18,560
give the talk

1091
00:44:18,560 --> 00:44:19,680
okay

1092
00:44:19,680 --> 00:44:21,920
thank you for the introduction and this

1093
00:44:21,920 --> 00:44:26,560
work was with my advisor jeremiah blochy

1094
00:44:26,560 --> 00:44:27,440
so

1095
00:44:27,440 --> 00:44:29,520
specialized hardware such as a6 can

1096
00:44:29,520 --> 00:44:31,440
evaluate hash functions orders of

1097
00:44:31,440 --> 00:44:33,839
magnitude times faster than standard

1098
00:44:33,839 --> 00:44:35,680
hardware

1099
00:44:35,680 --> 00:44:37,680
this is a problem because it offers an

1100
00:44:37,680 --> 00:44:39,920
advantage for offline attackers who

1101
00:44:39,920 --> 00:44:42,160
brute force passwords

1102
00:44:42,160 --> 00:44:44,240
memory hard functions aim to minimize

1103
00:44:44,240 --> 00:44:46,079
this hardware advantage

1104
00:44:46,079 --> 00:44:48,319
and as a result they protect loan trippy

1105
00:44:48,319 --> 00:44:50,400
secrets like passwords from brute force

1106
00:44:50,400 --> 00:44:52,880
attacks

1107
00:44:53,440 --> 00:44:55,839
so first we acknowledge that

1108
00:44:55,839 --> 00:44:58,160
memory cost is relatively uniform across

1109
00:44:58,160 --> 00:45:00,880
these different types of hardware

1110
00:45:00,880 --> 00:45:02,800
and so what we want is a function whose

1111
00:45:02,800 --> 00:45:04,960
computational costs are dominated by

1112
00:45:04,960 --> 00:45:07,280
memory cost

1113
00:45:07,280 --> 00:45:08,800
in particular we want to force an

1114
00:45:08,800 --> 00:45:10,800
attacker to lock up large amounts of

1115
00:45:10,800 --> 00:45:12,160
memory for the duration of the

1116
00:45:12,160 --> 00:45:13,599
computation

1117
00:45:13,599 --> 00:45:15,280
this will make it expensive even on

1118
00:45:15,280 --> 00:45:18,079
customized hardware

1119
00:45:18,079 --> 00:45:19,760
but now the question is how can we prove

1120
00:45:19,760 --> 00:45:21,920
that we've done this how do we quantify

1121
00:45:21,920 --> 00:45:24,400
memory hardness

1122
00:45:24,400 --> 00:45:26,240
well a standard way to characterize the

1123
00:45:26,240 --> 00:45:28,640
space cost of a function is via

1124
00:45:28,640 --> 00:45:30,480
space-time complexity

1125
00:45:30,480 --> 00:45:32,319
the space-time cost of an evaluation

1126
00:45:32,319 --> 00:45:34,880
algorithm is just the maximum space to

1127
00:45:34,880 --> 00:45:36,240
use times the duration of the

1128
00:45:36,240 --> 00:45:37,599
computation

1129
00:45:37,599 --> 00:45:39,760
and the space-time complexity of a func

1130
00:45:39,760 --> 00:45:41,119
of a

1131
00:45:41,119 --> 00:45:43,920
function is just the uh space-time cost

1132
00:45:43,920 --> 00:45:47,280
of the cheapest evaluation algorithm

1133
00:45:47,280 --> 00:45:49,119
this is great because there's a rich

1134
00:45:49,119 --> 00:45:51,200
time space trade rich theory of

1135
00:45:51,200 --> 00:45:53,040
time-space trade-offs

1136
00:45:53,040 --> 00:45:54,880
but unfortunately it's not appropriate

1137
00:45:54,880 --> 00:45:57,280
for password hashing or many other use

1138
00:45:57,280 --> 00:46:00,880
cases for memory hard functions

1139
00:46:00,880 --> 00:46:02,880
the reason is that it doesn't amortize

1140
00:46:02,880 --> 00:46:03,760
well

1141
00:46:03,760 --> 00:46:05,119
so what you can do is if you have a

1142
00:46:05,119 --> 00:46:07,440
function that might have high

1143
00:46:07,440 --> 00:46:09,920
high space time complexity but you only

1144
00:46:09,920 --> 00:46:12,160
just have to sustain the maximal space

1145
00:46:12,160 --> 00:46:14,160
for a short amount of time you can

1146
00:46:14,160 --> 00:46:15,839
essentially stagger their start times in

1147
00:46:15,839 --> 00:46:17,040
parallel

1148
00:46:17,040 --> 00:46:19,040
and about evaluate the function many

1149
00:46:19,040 --> 00:46:21,680
times with a space time cost that's very

1150
00:46:21,680 --> 00:46:25,359
similar to if you evaluate it at once

1151
00:46:25,359 --> 00:46:27,520
at high level

1152
00:46:27,520 --> 00:46:29,760
we really want it to be true that making

1153
00:46:29,760 --> 00:46:32,480
10 password guesses in parallel

1154
00:46:32,480 --> 00:46:34,800
is 10 times as costly as making a single

1155
00:46:34,800 --> 00:46:37,359
password guess

1156
00:46:37,359 --> 00:46:39,040
so how we can get around this is by

1157
00:46:39,040 --> 00:46:41,839
using cumulative complexity and this

1158
00:46:41,839 --> 00:46:45,119
just measures the sum of the space used

1159
00:46:45,119 --> 00:46:48,960
across the duration of the computation

1160
00:46:49,119 --> 00:46:51,440
and at first glance this looks very

1161
00:46:51,440 --> 00:46:53,920
promising because

1162
00:46:53,920 --> 00:46:56,160
it turns out that the cumulative

1163
00:46:56,160 --> 00:46:58,560
complexity of evaluating a function

1164
00:46:58,560 --> 00:47:00,640
m times in parallel

1165
00:47:00,640 --> 00:47:02,560
is m times

1166
00:47:02,560 --> 00:47:06,319
the cost of evaluating it once

1167
00:47:06,319 --> 00:47:08,720
so now we can look at an example script

1168
00:47:08,720 --> 00:47:11,359
is a widely used memory hard function

1169
00:47:11,359 --> 00:47:13,040
and it was proven to have maximal

1170
00:47:13,040 --> 00:47:16,079
cumulative complexity of n squared

1171
00:47:16,079 --> 00:47:19,839
where n is our running time parameter

1172
00:47:20,480 --> 00:47:23,280
so now the question is does this maximal

1173
00:47:23,280 --> 00:47:25,280
cc actually align with our intuitions

1174
00:47:25,280 --> 00:47:27,040
for memory hardness

1175
00:47:27,040 --> 00:47:29,280
and the answer is not quite because we

1176
00:47:29,280 --> 00:47:31,200
can evaluate a script using constant

1177
00:47:31,200 --> 00:47:34,240
memory for n squared time

1178
00:47:34,240 --> 00:47:35,680
and remember what we wanted out of a

1179
00:47:35,680 --> 00:47:37,760
memory hard function we wanted to force

1180
00:47:37,760 --> 00:47:39,760
an attacker to lock up large amounts of

1181
00:47:39,760 --> 00:47:41,119
memory for the duration of the

1182
00:47:41,119 --> 00:47:43,760
computation

1183
00:47:44,480 --> 00:47:48,640
so how we can fix this is by using a

1184
00:47:48,640 --> 00:47:50,720
host metric that is

1185
00:47:50,720 --> 00:47:53,520
very tightly correlated to what we want

1186
00:47:53,520 --> 00:47:55,280
so now we can use sustained space

1187
00:47:55,280 --> 00:47:57,680
complexity which measures the time spent

1188
00:47:57,680 --> 00:48:01,200
above a certain memory threshold

1189
00:48:01,599 --> 00:48:02,880
and

1190
00:48:02,880 --> 00:48:04,400
you can see that this is stricter than

1191
00:48:04,400 --> 00:48:06,559
cumulative complexity because

1192
00:48:06,559 --> 00:48:09,119
if you're if you sustain s space for t

1193
00:48:09,119 --> 00:48:10,160
time

1194
00:48:10,160 --> 00:48:12,240
then your cumulative cost is going to be

1195
00:48:12,240 --> 00:48:15,439
at least s times t

1196
00:48:16,160 --> 00:48:17,920
so now that we have this

1197
00:48:17,920 --> 00:48:21,119
way of measuring cost that's very uh

1198
00:48:21,119 --> 00:48:22,960
you know it aligns with our intuitions

1199
00:48:22,960 --> 00:48:24,720
for memory hard functions we want to

1200
00:48:24,720 --> 00:48:26,880
know how good can we do

1201
00:48:26,880 --> 00:48:28,559
ideally we want to construct memory hard

1202
00:48:28,559 --> 00:48:30,079
functions in which any evaluation

1203
00:48:30,079 --> 00:48:34,400
strategy sustains in space for in steps

1204
00:48:34,400 --> 00:48:35,760
unfortunately

1205
00:48:35,760 --> 00:48:37,760
this is impossible because any membrane

1206
00:48:37,760 --> 00:48:39,920
heart function can be evaluated

1207
00:48:39,920 --> 00:48:42,400
using only interval login space

1208
00:48:42,400 --> 00:48:44,559
although these evaluation strategies can

1209
00:48:44,559 --> 00:48:48,240
have exponential runtime

1210
00:48:48,240 --> 00:48:51,119
so now since we can't do that we wonder

1211
00:48:51,119 --> 00:48:52,160
if we can

1212
00:48:52,160 --> 00:48:53,760
relax

1213
00:48:53,760 --> 00:48:56,640
our goal slightly and still have say

1214
00:48:56,640 --> 00:48:59,760
something strong about uh guarantees

1215
00:48:59,760 --> 00:49:01,920
so we want to know whether or not we can

1216
00:49:01,920 --> 00:49:03,680
force any attacker that has low

1217
00:49:03,680 --> 00:49:06,240
sustained space complexity to pay a huge

1218
00:49:06,240 --> 00:49:07,920
penalty in

1219
00:49:07,920 --> 00:49:10,880
cumulative cost

1220
00:49:11,760 --> 00:49:13,359
and so in this work

1221
00:49:13,359 --> 00:49:14,960
our goal is to construct a memory hard

1222
00:49:14,960 --> 00:49:17,280
function in which any strategy either

1223
00:49:17,280 --> 00:49:18,480
sustains

1224
00:49:18,480 --> 00:49:20,720
in space for n steps

1225
00:49:20,720 --> 00:49:23,359
or has cumulative cost much greater than

1226
00:49:23,359 --> 00:49:26,000
n squared

1227
00:49:26,800 --> 00:49:28,880
so we examine the sustained space and

1228
00:49:28,880 --> 00:49:30,960
cumulative complexity trade-offs for two

1229
00:49:30,960 --> 00:49:33,520
practical memory hard functions

1230
00:49:33,520 --> 00:49:34,720
and then we give a theoretical

1231
00:49:34,720 --> 00:49:37,520
construction that actually achieves the

1232
00:49:37,520 --> 00:49:40,960
achieves near optimal trade-offs

1233
00:49:40,960 --> 00:49:42,960
we've already seen that for script we

1234
00:49:42,960 --> 00:49:45,119
can evaluate it using constant space and

1235
00:49:45,119 --> 00:49:48,559
n squared cumulative complexity

1236
00:49:48,559 --> 00:49:50,640
so the first function we consider is dr

1237
00:49:50,640 --> 00:49:52,800
sample it's a practical side channel

1238
00:49:52,800 --> 00:49:54,800
resistant memory hard function

1239
00:49:54,800 --> 00:49:56,400
and we give some slight modifications

1240
00:49:56,400 --> 00:49:58,240
and show that any strategy either

1241
00:49:58,240 --> 00:50:01,119
sustains n over login space for n steps

1242
00:50:01,119 --> 00:50:03,839
or has cumulative cost n cubed over log

1243
00:50:03,839 --> 00:50:06,000
in

1244
00:50:06,000 --> 00:50:08,160
next we take a look at argon 2.

1245
00:50:08,160 --> 00:50:10,319
argon 2 is widely deployed it won the

1246
00:50:10,319 --> 00:50:12,480
password hashing competition in

1247
00:50:12,480 --> 00:50:14,319
2015

1248
00:50:14,319 --> 00:50:16,960
and it's in many cryptographic libraries

1249
00:50:16,960 --> 00:50:18,559
we show that any strategy either

1250
00:50:18,559 --> 00:50:20,000
sustains

1251
00:50:20,000 --> 00:50:22,480
n to the one minus epsilon space for n

1252
00:50:22,480 --> 00:50:24,960
steps or it has cumulative cost slightly

1253
00:50:24,960 --> 00:50:27,200
more than n squared

1254
00:50:27,200 --> 00:50:28,559
finally we give a theoretical

1255
00:50:28,559 --> 00:50:31,040
construction which actually achieves the

1256
00:50:31,040 --> 00:50:33,040
maximal sustained space

1257
00:50:33,040 --> 00:50:34,640
sustained space parameter that we were

1258
00:50:34,640 --> 00:50:36,800
hoping for so any strategy either

1259
00:50:36,800 --> 00:50:39,119
sustains in space for n steps

1260
00:50:39,119 --> 00:50:41,520
or it has cumulative cost n to the three

1261
00:50:41,520 --> 00:50:44,400
minus epsilon

1262
00:50:44,480 --> 00:50:46,400
so now i want to talk about

1263
00:50:46,400 --> 00:50:47,599
how we did these general proof

1264
00:50:47,599 --> 00:50:49,359
strategies and then i'm going to talk

1265
00:50:49,359 --> 00:50:50,240
about

1266
00:50:50,240 --> 00:50:52,480
our construction

1267
00:50:52,480 --> 00:50:54,559
so first a memory heard function is

1268
00:50:54,559 --> 00:50:56,880
defined with respect to a random graph

1269
00:50:56,880 --> 00:50:58,640
family and these encode data

1270
00:50:58,640 --> 00:51:01,119
dependencies

1271
00:51:01,119 --> 00:51:03,119
the input to our function maybe it's

1272
00:51:03,119 --> 00:51:05,520
like a password and assault

1273
00:51:05,520 --> 00:51:07,280
and so from here we compute the labels

1274
00:51:07,280 --> 00:51:09,920
for the nodes the label for node 0 is

1275
00:51:09,920 --> 00:51:12,000
just the hash of the input

1276
00:51:12,000 --> 00:51:13,760
and the label for any other node is just

1277
00:51:13,760 --> 00:51:15,040
the hash of the labels of its

1278
00:51:15,040 --> 00:51:17,280
predecessors

1279
00:51:17,280 --> 00:51:19,119
the output of our function is just going

1280
00:51:19,119 --> 00:51:20,000
to be

1281
00:51:20,000 --> 00:51:23,839
the last label in our graph

1282
00:51:23,920 --> 00:51:25,839
so some nodes have what's what's called

1283
00:51:25,839 --> 00:51:27,760
dynamic edges and this is how the you

1284
00:51:27,760 --> 00:51:31,200
know random graphs play role

1285
00:51:31,200 --> 00:51:33,760
and these edges depend on the labels of

1286
00:51:33,760 --> 00:51:36,000
a node's predecessor for example node

1287
00:51:36,000 --> 00:51:38,400
three has a dynamic edge which we denote

1288
00:51:38,400 --> 00:51:40,640
r3

1289
00:51:40,640 --> 00:51:42,559
um and that's going to use the

1290
00:51:42,559 --> 00:51:44,480
randomness from when we take the hash of

1291
00:51:44,480 --> 00:51:46,480
the labels uh

1292
00:51:46,480 --> 00:51:49,440
of labels zero and one

1293
00:51:49,440 --> 00:51:54,319
so it could either land on zero or one

1294
00:51:54,640 --> 00:51:55,839
according to some probability

1295
00:51:55,839 --> 00:51:57,920
distribution

1296
00:51:57,920 --> 00:52:00,480
and the important takeaway here is that

1297
00:52:00,480 --> 00:52:01,599
uh

1298
00:52:01,599 --> 00:52:04,720
this edge uh which node it lands on

1299
00:52:04,720 --> 00:52:07,200
depends on these previous labels and

1300
00:52:07,200 --> 00:52:08,960
those previous labels

1301
00:52:08,960 --> 00:52:10,960
in turn depend on the input of our

1302
00:52:10,960 --> 00:52:14,160
function so then these edges depend

1303
00:52:14,160 --> 00:52:15,839
directly on

1304
00:52:15,839 --> 00:52:17,760
the inputs

1305
00:52:17,760 --> 00:52:20,079
and that's why we call graphs with these

1306
00:52:20,079 --> 00:52:22,400
dynamic edges data dependent memory hard

1307
00:52:22,400 --> 00:52:24,800
functions

1308
00:52:24,800 --> 00:52:26,319
if they don't have any dynamic edges

1309
00:52:26,319 --> 00:52:28,160
then we call them data independent

1310
00:52:28,160 --> 00:52:31,200
memory functions

1311
00:52:31,200 --> 00:52:34,079
great um so now how do why do we even

1312
00:52:34,079 --> 00:52:35,520
care about data dependent memory hard

1313
00:52:35,520 --> 00:52:36,640
functions

1314
00:52:36,640 --> 00:52:39,200
well remember our goal was to

1315
00:52:39,200 --> 00:52:40,720
construct a memory hard function in

1316
00:52:40,720 --> 00:52:42,880
which any strategy either sustains in

1317
00:52:42,880 --> 00:52:45,359
space for n steps or it has cumulative

1318
00:52:45,359 --> 00:52:48,559
costs much more than n squared

1319
00:52:48,559 --> 00:52:51,119
it turns out that any uh data

1320
00:52:51,119 --> 00:52:53,040
independent memory hard function can be

1321
00:52:53,040 --> 00:52:54,400
computed

1322
00:52:54,400 --> 00:52:56,640
using cumulative cost

1323
00:52:56,640 --> 00:52:59,280
strictly less than n squared

1324
00:52:59,280 --> 00:53:00,880
and this actually makes these trade-offs

1325
00:53:00,880 --> 00:53:03,040
impossible

1326
00:53:03,040 --> 00:53:05,359
so ideally we want to use these dynamic

1327
00:53:05,359 --> 00:53:09,200
edges to get stronger guarantees

1328
00:53:10,079 --> 00:53:13,200
so to prove these results we proved them

1329
00:53:13,200 --> 00:53:15,920
using dynamic pebbling games so here

1330
00:53:15,920 --> 00:53:18,000
we're going to be placing pebbles on

1331
00:53:18,000 --> 00:53:19,760
nodes in the graph and you can

1332
00:53:19,760 --> 00:53:22,480
essentially think of a node as a label

1333
00:53:22,480 --> 00:53:25,520
so placing a a pebble on a node is like

1334
00:53:25,520 --> 00:53:28,000
computing a label and keeping a pebble

1335
00:53:28,000 --> 00:53:30,640
on a node is like storing a label in

1336
00:53:30,640 --> 00:53:33,040
memory

1337
00:53:33,040 --> 00:53:33,839
so

1338
00:53:33,839 --> 00:53:35,440
you know the rule is you can always

1339
00:53:35,440 --> 00:53:37,359
place a pebble on a node whose parents

1340
00:53:37,359 --> 00:53:39,599
all have pebbles on them

1341
00:53:39,599 --> 00:53:41,520
and again these dynamic edges can appear

1342
00:53:41,520 --> 00:53:43,680
when you pebble all of the static

1343
00:53:43,680 --> 00:53:46,880
predecessors to a node

1344
00:53:46,880 --> 00:53:49,520
and these edges appear land on nodes

1345
00:53:49,520 --> 00:53:50,960
according to some

1346
00:53:50,960 --> 00:53:54,160
predetermined probability distribution

1347
00:53:54,160 --> 00:53:56,880
again our goal is to place a pebble on

1348
00:53:56,880 --> 00:54:00,400
the last node in our graph the sink

1349
00:54:00,400 --> 00:54:02,079
so now i'll give a quick pebbling

1350
00:54:02,079 --> 00:54:04,240
example we're going to pebble this graph

1351
00:54:04,240 --> 00:54:05,680
you can always place a pebble on node

1352
00:54:05,680 --> 00:54:06,480
one

1353
00:54:06,480 --> 00:54:08,319
now we can place one unknown too since

1354
00:54:08,319 --> 00:54:10,720
we have pebbles on nodes one and two we

1355
00:54:10,720 --> 00:54:12,720
can pebble node three

1356
00:54:12,720 --> 00:54:15,280
this causes a dynamic edge to appear

1357
00:54:15,280 --> 00:54:17,920
which just happened to land on node two

1358
00:54:17,920 --> 00:54:19,920
so we'll pebble node two

1359
00:54:19,920 --> 00:54:23,800
four and five

1360
00:54:24,480 --> 00:54:27,520
okay so now we're ready to talk about um

1361
00:54:27,520 --> 00:54:29,119
our proof structure

1362
00:54:29,119 --> 00:54:30,880
and just as a reminder our goal is to

1363
00:54:30,880 --> 00:54:32,800
construct memory hard functions such

1364
00:54:32,800 --> 00:54:35,280
that any strategy either sustains

1365
00:54:35,280 --> 00:54:37,920
in space for n steps or has cumulative

1366
00:54:37,920 --> 00:54:41,680
cost much more than n squared

1367
00:54:41,680 --> 00:54:43,599
so in general um our setup is the

1368
00:54:43,599 --> 00:54:45,680
following we have a graph where like the

1369
00:54:45,680 --> 00:54:47,200
first half is

1370
00:54:47,200 --> 00:54:48,880
highly connected according to some

1371
00:54:48,880 --> 00:54:51,040
metric and it has high cumulative

1372
00:54:51,040 --> 00:54:53,359
complexity

1373
00:54:53,359 --> 00:54:55,280
the second half of our graph

1374
00:54:55,280 --> 00:54:57,440
has dynamic edges coming from the first

1375
00:54:57,440 --> 00:54:59,119
half

1376
00:54:59,119 --> 00:55:00,960
the idea is that if a strategy only has

1377
00:55:00,960 --> 00:55:03,040
a few pebbles on the graph

1378
00:55:03,040 --> 00:55:04,240
then there's a good chance they're going

1379
00:55:04,240 --> 00:55:05,760
to have to re-pebble

1380
00:55:05,760 --> 00:55:07,839
a lot of that first half of the graph

1381
00:55:07,839 --> 00:55:09,520
and they're going to incur a very high

1382
00:55:09,520 --> 00:55:12,400
cumulative cost

1383
00:55:13,200 --> 00:55:15,359
so in our construction the graph that

1384
00:55:15,359 --> 00:55:16,799
serves

1385
00:55:16,799 --> 00:55:18,559
to have these

1386
00:55:18,559 --> 00:55:21,280
but to achieve these connectivity goals

1387
00:55:21,280 --> 00:55:25,200
are what is called st robust graphs

1388
00:55:25,200 --> 00:55:28,079
so sd robust graphs have n inputs and

1389
00:55:28,079 --> 00:55:29,359
outputs

1390
00:55:29,359 --> 00:55:30,720
with the property that you can remove

1391
00:55:30,720 --> 00:55:33,599
any k nodes from the graph

1392
00:55:33,599 --> 00:55:35,200
and there's still a sub graph with n

1393
00:55:35,200 --> 00:55:38,559
minus k inputs n minus k outputs

1394
00:55:38,559 --> 00:55:41,119
with a path from all of the inputs to

1395
00:55:41,119 --> 00:55:44,079
all of the outputs

1396
00:55:44,079 --> 00:55:45,680
our second ingredient is depth

1397
00:55:45,680 --> 00:55:49,680
robustness a graph is e d depth robust

1398
00:55:49,680 --> 00:55:52,400
if you can remove any e nodes from the

1399
00:55:52,400 --> 00:55:54,480
graph and there's still a path of length

1400
00:55:54,480 --> 00:55:56,640
d

1401
00:55:57,119 --> 00:55:59,359
this is useful because if a graph is e d

1402
00:55:59,359 --> 00:56:01,760
depth robust then it then it has

1403
00:56:01,760 --> 00:56:04,240
cumulative cost much

1404
00:56:04,240 --> 00:56:07,280
at least e times d

1405
00:56:07,280 --> 00:56:09,200
as an example this graph is one for

1406
00:56:09,200 --> 00:56:11,040
depth robust and you can see this

1407
00:56:11,040 --> 00:56:12,960
because you can just remove

1408
00:56:12,960 --> 00:56:14,319
any of the nodes and there's still a

1409
00:56:14,319 --> 00:56:17,200
path of link four

1410
00:56:18,160 --> 00:56:20,000
so what we do is we combine our first

1411
00:56:20,000 --> 00:56:22,480
ingredient which were stirred us graphs

1412
00:56:22,480 --> 00:56:24,240
and with our second ingredient depth

1413
00:56:24,240 --> 00:56:25,839
robustness

1414
00:56:25,839 --> 00:56:27,680
so what we do is we overlay a graph

1415
00:56:27,680 --> 00:56:29,839
that's n by n to the one minus epsilon

1416
00:56:29,839 --> 00:56:32,319
depth robust onto the inputs of our st

1417
00:56:32,319 --> 00:56:35,040
robust graphs

1418
00:56:35,200 --> 00:56:37,440
so now re-pebbling these inputs is going

1419
00:56:37,440 --> 00:56:38,640
to cost

1420
00:56:38,640 --> 00:56:40,799
have cumulative cost n to the two minus

1421
00:56:40,799 --> 00:56:43,799
epsilon

1422
00:56:44,000 --> 00:56:45,839
now the question is how can we make a

1423
00:56:45,839 --> 00:56:47,839
low sustained space attacker re-pevel

1424
00:56:47,839 --> 00:56:48,720
these

1425
00:56:48,720 --> 00:56:51,680
inputs many times

1426
00:56:51,680 --> 00:56:54,720
what we do is we add a line graph to the

1427
00:56:54,720 --> 00:56:56,400
end of our construction

1428
00:56:56,400 --> 00:56:59,359
and then we have dynamic edges coming

1429
00:56:59,359 --> 00:57:01,440
to each of the nodes in line graph from

1430
00:57:01,440 --> 00:57:03,520
the ran from random outputs of our st

1431
00:57:03,520 --> 00:57:06,160
robust graph

1432
00:57:06,880 --> 00:57:08,319
so now

1433
00:57:08,319 --> 00:57:10,480
if an attacker wants to place a pebble

1434
00:57:10,480 --> 00:57:12,720
on some node in our line graph

1435
00:57:12,720 --> 00:57:14,640
but they only have relatively few

1436
00:57:14,640 --> 00:57:17,520
pebbles on the graph

1437
00:57:17,760 --> 00:57:19,040
then there's a good chance they're not

1438
00:57:19,040 --> 00:57:20,480
going to have a pebble on the random

1439
00:57:20,480 --> 00:57:23,440
output they need

1440
00:57:23,680 --> 00:57:25,440
and with constant probability there's

1441
00:57:25,440 --> 00:57:27,520
going to be paths from many of the

1442
00:57:27,520 --> 00:57:30,319
inputs to that particular output

1443
00:57:30,319 --> 00:57:31,200
meaning

1444
00:57:31,200 --> 00:57:33,119
they'll have to re-pebble these inputs

1445
00:57:33,119 --> 00:57:36,079
and that's going to cost

1446
00:57:36,079 --> 00:57:37,520
cumulative cost

1447
00:57:37,520 --> 00:57:41,040
into 2 minus epsilon so we can show that

1448
00:57:41,040 --> 00:57:43,599
if an attacker is frequently low memory

1449
00:57:43,599 --> 00:57:46,480
then they're going to have to

1450
00:57:46,480 --> 00:57:48,400
repeal the inputs a linear number of

1451
00:57:48,400 --> 00:57:50,880
times with respect to our runtime

1452
00:57:50,880 --> 00:57:54,920
parameter with high probability

1453
00:57:55,680 --> 00:57:58,000
and so putting this all together you get

1454
00:57:58,000 --> 00:58:00,319
that for such attackers their cumulative

1455
00:58:00,319 --> 00:58:02,079
cost will be n to the three minus

1456
00:58:02,079 --> 00:58:04,559
epsilon

1457
00:58:04,720 --> 00:58:06,240
on the other hand if an attacker is

1458
00:58:06,240 --> 00:58:08,319
trying to pebble a no no-line graph but

1459
00:58:08,319 --> 00:58:09,680
they do have a lot of pebbles on the

1460
00:58:09,680 --> 00:58:10,480
graph

1461
00:58:10,480 --> 00:58:12,000
we can just count that towards our

1462
00:58:12,000 --> 00:58:15,359
sustained space complexity

1463
00:58:16,000 --> 00:58:19,119
so putting this all together we get that

1464
00:58:19,119 --> 00:58:21,280
any strategy for evaluating our memory

1465
00:58:21,280 --> 00:58:24,079
heart function either sustains n pebbles

1466
00:58:24,079 --> 00:58:26,640
for n steps or that it has cumulative

1467
00:58:26,640 --> 00:58:27,839
cost

1468
00:58:27,839 --> 00:58:31,359
n to the three minus epsilon

1469
00:58:33,599 --> 00:58:35,520
so in this work we showed that there are

1470
00:58:35,520 --> 00:58:37,359
some current and practical memory hard

1471
00:58:37,359 --> 00:58:39,359
functions which have high sustained

1472
00:58:39,359 --> 00:58:41,040
space and cumulative complexity

1473
00:58:41,040 --> 00:58:42,640
trade-offs

1474
00:58:42,640 --> 00:58:44,880
we also gave a theoretical construction

1475
00:58:44,880 --> 00:58:47,599
with near-optimal trade-offs

1476
00:58:47,599 --> 00:58:50,240
this also generated some open problems

1477
00:58:50,240 --> 00:58:52,480
first like you know our proofs were done

1478
00:58:52,480 --> 00:58:54,480
in this dynamic pebbling model with

1479
00:58:54,480 --> 00:58:56,400
these pebbling games we want to know

1480
00:58:56,400 --> 00:58:58,160
whether these claims can be proven in

1481
00:58:58,160 --> 00:59:00,720
the random oracle model

1482
00:59:00,720 --> 00:59:02,960
for memory hard functions that don't

1483
00:59:02,960 --> 00:59:04,960
have dynamic edges

1484
00:59:04,960 --> 00:59:06,559
there's actually a general reduction

1485
00:59:06,559 --> 00:59:08,799
that relates any evaluation algorithm

1486
00:59:08,799 --> 00:59:09,839
with a

1487
00:59:09,839 --> 00:59:12,799
equivalent cost pebbling strategy

1488
00:59:12,799 --> 00:59:16,400
so we wonder if you can give a reduction

1489
00:59:16,400 --> 00:59:18,319
a similar reduction for memory hard

1490
00:59:18,319 --> 00:59:22,558
functions that do have dynamic edges

1491
00:59:23,520 --> 00:59:25,839
finally our theoretical construction is

1492
00:59:25,839 --> 00:59:27,839
very costly to implement

1493
00:59:27,839 --> 00:59:30,240
and so we wonder if there's a practical

1494
00:59:30,240 --> 00:59:32,319
memory hard function that still achieves

1495
00:59:32,319 --> 00:59:35,359
the maximal sustain space parameter

1496
00:59:35,359 --> 00:59:36,720
so is there a practical memory hard

1497
00:59:36,720 --> 00:59:38,799
function in which any strategy

1498
00:59:38,799 --> 00:59:41,440
must sustain in space for n steps or

1499
00:59:41,440 --> 00:59:43,520
have cumulative costs much more than n

1500
00:59:43,520 --> 00:59:44,880
squared

1501
00:59:44,880 --> 00:59:47,839
thank you

1502
00:59:51,760 --> 00:59:53,280
thank you we have time for some

1503
00:59:53,280 --> 00:59:56,280
questions

1504
01:00:00,480 --> 01:00:02,160
um see if i understood correctly you

1505
01:00:02,160 --> 01:00:04,079
mentioned that you proved your result uh

1506
01:00:04,079 --> 01:00:05,440
in a very nice

1507
01:00:05,440 --> 01:00:07,280
and intuitive pebbling model but when

1508
01:00:07,280 --> 01:00:08,720
you try to

1509
01:00:08,720 --> 01:00:10,160
actually prove it in the random oracle

1510
01:00:10,160 --> 01:00:12,559
using compression or something

1511
01:00:12,559 --> 01:00:15,119
the proof gets stuck unlike previous

1512
01:00:15,119 --> 01:00:16,960
results where i think you do have this

1513
01:00:16,960 --> 01:00:18,640
proof can you let me point what's the

1514
01:00:18,640 --> 01:00:20,079
difficulty so

1515
01:00:20,079 --> 01:00:22,799
when you try is it like hopeless yeah um

1516
01:00:22,799 --> 01:00:23,680
so

1517
01:00:23,680 --> 01:00:25,920
um i think people have yeah we've worked

1518
01:00:25,920 --> 01:00:27,680
a little bit on trying to do such a

1519
01:00:27,680 --> 01:00:29,920
reduction um

1520
01:00:29,920 --> 01:00:32,960
essentially it just

1521
01:00:32,960 --> 01:00:34,720
uh i don't know it's just uh kind of

1522
01:00:34,720 --> 01:00:37,359
difficult with the randomness right so

1523
01:00:37,359 --> 01:00:39,200
you know that's why for script for

1524
01:00:39,200 --> 01:00:41,040
example

1525
01:00:41,040 --> 01:00:43,440
they opted to instead do a direct proofs

1526
01:00:43,440 --> 01:00:45,119
uh that's their paper where they prove

1527
01:00:45,119 --> 01:00:47,760
that it's maximally memory hard right

1528
01:00:47,760 --> 01:00:48,880
um

1529
01:00:48,880 --> 01:00:50,720
so yeah it's still you know a difficult

1530
01:00:50,720 --> 01:00:53,200
open problem uh but it's not like an

1531
01:00:53,200 --> 01:00:55,440
obvious barrier that somehow you know

1532
01:00:55,440 --> 01:00:57,200
you just try and some coincidentally

1533
01:00:57,200 --> 01:00:59,440
just there is no hope

1534
01:00:59,440 --> 01:01:01,760
oh no

1535
01:01:01,760 --> 01:01:04,400
so so i i believe there is hope for uh

1536
01:01:04,400 --> 01:01:06,799
constructing such a reduction uh we just

1537
01:01:06,799 --> 01:01:09,440
haven't uh figured it out yet

1538
01:01:09,440 --> 01:01:10,799
and also just in terms of optimal

1539
01:01:10,799 --> 01:01:12,319
parameters so

1540
01:01:12,319 --> 01:01:14,079
when you say much greater than n square

1541
01:01:14,079 --> 01:01:16,480
at some point you said exponential uh so

1542
01:01:16,480 --> 01:01:18,400
what is optimal is n and and cube

1543
01:01:18,400 --> 01:01:20,319
optimal so and cube is really obviously

1544
01:01:20,319 --> 01:01:23,200
optional so so what i meant was um

1545
01:01:23,200 --> 01:01:26,240
by exponential is that uh

1546
01:01:26,240 --> 01:01:27,760
as the result that any memory hard

1547
01:01:27,760 --> 01:01:29,599
function can be evaluated using n over

1548
01:01:29,599 --> 01:01:32,160
log in space uh the thing is that that

1549
01:01:32,160 --> 01:01:35,520
the run time can be exponential to those

1550
01:01:35,520 --> 01:01:38,480
um n cubed is the best you can do uh

1551
01:01:38,480 --> 01:01:39,760
just by some

1552
01:01:39,760 --> 01:01:41,040
uh

1553
01:01:41,040 --> 01:01:43,359
previous work and uh space-time

1554
01:01:43,359 --> 01:01:46,559
trade-offs um yeah the best you can hope

1555
01:01:46,559 --> 01:01:48,480
for is like a penalty of n squared but

1556
01:01:48,480 --> 01:01:51,119
we haven't achieved that yet so n n and

1557
01:01:51,119 --> 01:01:53,680
cube would be the optimal which is

1558
01:01:53,680 --> 01:01:56,720
almost everything yes

1559
01:01:58,160 --> 01:02:00,960
so maybe to actually use question yeah

1560
01:02:00,960 --> 01:02:02,799
so it's always complicated when you know

1561
01:02:02,799 --> 01:02:04,640
either there's randomness the edges are

1562
01:02:04,640 --> 01:02:06,240
dynamic or there's a pre-computation

1563
01:02:06,240 --> 01:02:07,839
that they don't know and in fact there

1564
01:02:07,839 --> 01:02:10,000
are two counter examples where you can

1565
01:02:10,000 --> 01:02:12,079
show that the the pepping strategy does

1566
01:02:12,079 --> 01:02:13,920
not imply a bound for the random oracle

1567
01:02:13,920 --> 01:02:16,079
model i forgot exactly the thing but

1568
01:02:16,079 --> 01:02:17,599
basically you can ignore notes and that

1569
01:02:17,599 --> 01:02:19,280
actually helps in some sections so in

1570
01:02:19,280 --> 01:02:20,720
some cases it's simply wrong and we

1571
01:02:20,720 --> 01:02:22,960
don't know

1572
01:02:22,960 --> 01:02:24,880
um i forgot the link it's in some paper

1573
01:02:24,880 --> 01:02:26,640
in some appendix there is this concrete

1574
01:02:26,640 --> 01:02:28,240
counter example of the graph where it's

1575
01:02:28,240 --> 01:02:31,359
not true oh okay uh i wasn't aware of

1576
01:02:31,359 --> 01:02:34,839
how to delete

1577
01:02:38,319 --> 01:02:39,760
um

1578
01:02:39,760 --> 01:02:43,200
you mentioned many different complexity

1579
01:02:43,200 --> 01:02:44,400
definitions in the beginning of your

1580
01:02:44,400 --> 01:02:46,960
talk are there ones that you tried along

1581
01:02:46,960 --> 01:02:49,359
the way that you didn't mention here

1582
01:02:49,359 --> 01:02:52,079
um no we didn't uh quite try um

1583
01:02:52,079 --> 01:02:54,079
space-time complexity but

1584
01:02:54,079 --> 01:02:55,680
i i thought it kind of

1585
01:02:55,680 --> 01:02:58,240
helped understand how we got to using

1586
01:02:58,240 --> 01:03:01,119
sustained space and why we had to

1587
01:03:01,119 --> 01:03:05,280
also use cumulative complexity

1588
01:03:05,839 --> 01:03:09,440
all right let's thank our speaker again

1589
01:03:13,599 --> 01:03:15,359
all right our final talk of this session

1590
01:03:15,359 --> 01:03:18,000
is going to be a video so i will ask

1591
01:03:18,000 --> 01:03:19,599
kevin to share screen and then wait for

1592
01:03:19,599 --> 01:03:21,440
us to confirm that we can see it please

1593
01:03:21,440 --> 01:03:24,680
thank you

1594
01:03:32,559 --> 01:03:35,760
all right we're ready to go

1595
01:03:36,480 --> 01:03:37,359
hi

1596
01:03:37,359 --> 01:03:40,000
i'm shakha and this is joint work with

1597
01:03:40,000 --> 01:03:42,319
money now in this work we study

1598
01:03:42,319 --> 01:03:44,240
communication complexity in

1599
01:03:44,240 --> 01:03:46,640
computational settings

1600
01:03:46,640 --> 01:03:48,720
first let's recall communication

1601
01:03:48,720 --> 01:03:51,200
complexity the input is split between

1602
01:03:51,200 --> 01:03:53,680
alice and bob but they can communicate

1603
01:03:53,680 --> 01:03:56,319
in order to compute some target function

1604
01:03:56,319 --> 01:03:58,480
if communication complexity we are

1605
01:03:58,480 --> 01:04:01,039
interested in protocol with as little

1606
01:04:01,039 --> 01:04:04,000
communication as possible

1607
01:04:04,000 --> 01:04:05,680
you can think of a simple target

1608
01:04:05,680 --> 01:04:07,839
function as the quality predicate

1609
01:04:07,839 --> 01:04:09,839
alice and bob have to figure out whether

1610
01:04:09,839 --> 01:04:12,559
their inputs are equal or not most of

1611
01:04:12,559 --> 01:04:14,240
the results apply to almost any

1612
01:04:14,240 --> 01:04:16,000
reasonable predicate

1613
01:04:16,000 --> 01:04:17,920
where there is no input identical to

1614
01:04:17,920 --> 01:04:20,559
another also in our computational

1615
01:04:20,559 --> 01:04:23,200
settings we'll also require predicates

1616
01:04:23,200 --> 01:04:25,599
to have an efficient description in some

1617
01:04:25,599 --> 01:04:27,839
sense

1618
01:04:28,319 --> 01:04:30,160
two known network layouts in

1619
01:04:30,160 --> 01:04:32,319
communication complexity

1620
01:04:32,319 --> 01:04:34,160
are the interactive model where

1621
01:04:34,160 --> 01:04:36,799
participants can communicate without any

1622
01:04:36,799 --> 01:04:38,079
round limit

1623
01:04:38,079 --> 01:04:40,400
and the simultaneous messages model

1624
01:04:40,400 --> 01:04:42,799
where participants can send only only a

1625
01:04:42,799 --> 01:04:45,920
single message to a third party as we'll

1626
01:04:45,920 --> 01:04:47,200
see next

1627
01:04:47,200 --> 01:04:49,680
the randomness is also an important

1628
01:04:49,680 --> 01:04:52,079
property of the model whether there

1629
01:04:52,079 --> 01:04:55,839
exists shared public randomness or not

1630
01:04:55,839 --> 01:04:57,359
we are not considering here the

1631
01:04:57,359 --> 01:04:59,359
deterministic protocols

1632
01:04:59,359 --> 01:05:01,200
the communication complexity of the

1633
01:05:01,200 --> 01:05:04,160
equality predicate is well studied

1634
01:05:04,160 --> 01:05:06,559
and known to be in the interactive model

1635
01:05:06,559 --> 01:05:08,960
constant in the presence of public

1636
01:05:08,960 --> 01:05:12,480
randomness and login otherwise

1637
01:05:12,480 --> 01:05:14,880
let's move on now to the simultaneous

1638
01:05:14,880 --> 01:05:16,880
messages model

1639
01:05:16,880 --> 01:05:19,520
in this model alice and bob get their

1640
01:05:19,520 --> 01:05:23,039
input and produce one message each

1641
01:05:23,039 --> 01:05:26,240
these messages are sent to a third party

1642
01:05:26,240 --> 01:05:29,200
a referee and the referee has to compute

1643
01:05:29,200 --> 01:05:31,520
the target function with some constant

1644
01:05:31,520 --> 01:05:34,480
high probability for example assume that

1645
01:05:34,480 --> 01:05:36,720
alice and bob have to check if their

1646
01:05:36,720 --> 01:05:39,119
inputs are equal and have no common

1647
01:05:39,119 --> 01:05:40,240
randomness

1648
01:05:40,240 --> 01:05:42,640
they can use a good error correcting

1649
01:05:42,640 --> 01:05:45,839
code arrange the code words in a square

1650
01:05:45,839 --> 01:05:46,960
and now

1651
01:05:46,960 --> 01:05:49,839
alice's message will be a random war

1652
01:05:49,839 --> 01:05:52,160
and bob's message will be a random

1653
01:05:52,160 --> 01:05:55,119
column the referee just compares the

1654
01:05:55,119 --> 01:05:57,359
matched symbols by the arrow correcting

1655
01:05:57,359 --> 01:06:00,799
code the arrow is bounded by a constant

1656
01:06:00,799 --> 01:06:03,359
and hence this protocol can be amplified

1657
01:06:03,359 --> 01:06:06,160
easily by parallel repetitions

1658
01:06:06,160 --> 01:06:09,200
observe that the size of a row or a

1659
01:06:09,200 --> 01:06:11,920
column is square root of n and hence

1660
01:06:11,920 --> 01:06:14,559
this is the communication complexity of

1661
01:06:14,559 --> 01:06:16,079
the protocol

1662
01:06:16,079 --> 01:06:18,480
this protocol matches the known lower

1663
01:06:18,480 --> 01:06:20,720
bound for the equality predicate in the

1664
01:06:20,720 --> 01:06:23,039
simultaneous messages model with no

1665
01:06:23,039 --> 01:06:24,960
common random list

1666
01:06:24,960 --> 01:06:27,119
this lower bound was proved several

1667
01:06:27,119 --> 01:06:29,359
times the proof of bar in gmail is

1668
01:06:29,359 --> 01:06:31,680
general and holds for any non-redundant

1669
01:06:31,680 --> 01:06:34,880
predicate as a side note you can see

1670
01:06:34,880 --> 01:06:37,520
that the result is also a trade-off

1671
01:06:37,520 --> 01:06:40,240
between alice and bob messages size and

1672
01:06:40,240 --> 01:06:42,799
the previous protocol can be tweaked to

1673
01:06:42,799 --> 01:06:45,200
match it in our work the central

1674
01:06:45,200 --> 01:06:47,359
question is can the communication

1675
01:06:47,359 --> 01:06:50,160
complexity be reduced in a computational

1676
01:06:50,160 --> 01:06:51,119
world

1677
01:06:51,119 --> 01:06:53,839
one motivation is to discuss settings

1678
01:06:53,839 --> 01:06:55,680
closer to the real world

1679
01:06:55,680 --> 01:06:57,760
we study how communication complexity

1680
01:06:57,760 --> 01:07:01,280
models can be fitted to be computational

1681
01:07:01,280 --> 01:07:02,160
hence

1682
01:07:02,160 --> 01:07:04,480
we redefine the publican domains

1683
01:07:04,480 --> 01:07:07,039
consider a stateful participant and a

1684
01:07:07,039 --> 01:07:09,839
computational adversary instead of

1685
01:07:09,839 --> 01:07:12,960
closed cased input we discuss two

1686
01:07:12,960 --> 01:07:14,960
computational variations

1687
01:07:14,960 --> 01:07:17,599
the preset randomness model where there

1688
01:07:17,599 --> 01:07:20,400
is a common random string but the inputs

1689
01:07:20,400 --> 01:07:23,440
are chosen by an adversary who also sees

1690
01:07:23,440 --> 01:07:26,799
that common randomness the second model

1691
01:07:26,799 --> 01:07:28,720
is the free talk model that we'll

1692
01:07:28,720 --> 01:07:31,598
discuss later

1693
01:07:31,760 --> 01:07:32,559
now

1694
01:07:32,559 --> 01:07:34,480
we move on to define the preset

1695
01:07:34,480 --> 01:07:36,240
randomness model

1696
01:07:36,240 --> 01:07:38,400
first we have alice bob and the

1697
01:07:38,400 --> 01:07:41,440
adversary no inputs yet now the public

1698
01:07:41,440 --> 01:07:44,079
random is sampled and visible for

1699
01:07:44,079 --> 01:07:47,200
everyone then the inputs are chosen by

1700
01:07:47,200 --> 01:07:49,119
the adversary

1701
01:07:49,119 --> 01:07:52,400
then the participants can sample fresh

1702
01:07:52,400 --> 01:07:54,960
private randomness and have to compute

1703
01:07:54,960 --> 01:07:57,599
one message each the referee gets the

1704
01:07:57,599 --> 01:08:01,039
messages and outputs a decision

1705
01:08:01,039 --> 01:08:03,760
notice that assuming collision resistant

1706
01:08:03,760 --> 01:08:06,000
hash functions the communication

1707
01:08:06,000 --> 01:08:08,079
complexity of the equality predicate in

1708
01:08:08,079 --> 01:08:10,319
the preset randomness model can be

1709
01:08:10,319 --> 01:08:13,039
reduced significantly by simply running

1710
01:08:13,039 --> 01:08:15,119
the information theoretic protocol on

1711
01:08:15,119 --> 01:08:16,719
the digest

1712
01:08:16,719 --> 01:08:19,679
that is the square root of n lower bound

1713
01:08:19,679 --> 01:08:22,080
in the simultaneous messages model and

1714
01:08:22,080 --> 01:08:24,880
log n in the interactive model can be

1715
01:08:24,880 --> 01:08:29,279
outperformed assuming scrh

1716
01:08:30,399 --> 01:08:31,839
our results

1717
01:08:31,839 --> 01:08:33,839
go in the other direction

1718
01:08:33,839 --> 01:08:36,399
we show that breaking those known lower

1719
01:08:36,399 --> 01:08:38,640
bounds in the preset randomness model

1720
01:08:38,640 --> 01:08:42,479
implies the existence of dcrh

1721
01:08:42,479 --> 01:08:44,640
distributional collision resistant hash

1722
01:08:44,640 --> 01:08:47,359
function this year age is where only

1723
01:08:47,359 --> 01:08:49,679
random collisions are guaranteed to be

1724
01:08:49,679 --> 01:08:51,198
hard to find

1725
01:08:51,198 --> 01:08:54,479
that is we show an explicit construction

1726
01:08:54,479 --> 01:08:58,319
of a crh function from such a protocol

1727
01:08:58,319 --> 01:08:59,759
we also show

1728
01:08:59,759 --> 01:09:02,399
that there are no protocols of constant

1729
01:09:02,399 --> 01:09:04,640
communication in the preset randomness

1730
01:09:04,640 --> 01:09:07,759
model regardless of assumptions we used

1731
01:09:07,759 --> 01:09:10,080
techniques from baba and kim spoof to

1732
01:09:10,080 --> 01:09:13,198
show those results

1733
01:09:13,759 --> 01:09:16,000
the main idea behind the proofs in the

1734
01:09:16,000 --> 01:09:17,920
preset randomness model is the

1735
01:09:17,920 --> 01:09:21,600
characterizing multiset the idea is that

1736
01:09:21,600 --> 01:09:24,640
for any input alice's behavior can be

1737
01:09:24,640 --> 01:09:27,359
approximated by a multiset

1738
01:09:27,359 --> 01:09:28,560
that is

1739
01:09:28,560 --> 01:09:30,799
there exists a multiset with the

1740
01:09:30,799 --> 01:09:32,399
following property

1741
01:09:32,399 --> 01:09:35,120
when we run the protocol we can use a

1742
01:09:35,120 --> 01:09:37,839
uniform sample from this multiset

1743
01:09:37,839 --> 01:09:40,479
instead of running alice and still get

1744
01:09:40,479 --> 01:09:43,198
with hyperability the same output as in

1745
01:09:43,198 --> 01:09:44,880
alice in the protocol

1746
01:09:44,880 --> 01:09:48,238
hence for every input x alice can be

1747
01:09:48,238 --> 01:09:50,399
replaced by a multiset

1748
01:09:50,399 --> 01:09:53,279
we show that such a multiset can be

1749
01:09:53,279 --> 01:09:55,440
sampled with high probability

1750
01:09:55,440 --> 01:09:57,840
by running alice multiple times on that

1751
01:09:57,840 --> 01:10:02,040
input x independently

1752
01:10:02,159 --> 01:10:05,120
we construct a function by sampling

1753
01:10:05,120 --> 01:10:07,920
a public random string and three random

1754
01:10:07,920 --> 01:10:10,000
tapes of alice

1755
01:10:10,000 --> 01:10:12,880
the input of the function is an input x

1756
01:10:12,880 --> 01:10:14,320
for alice

1757
01:10:14,320 --> 01:10:16,719
and the output of the function is the t

1758
01:10:16,719 --> 01:10:20,960
messages alice produces for this input x

1759
01:10:20,960 --> 01:10:23,600
and these three random types and public

1760
01:10:23,600 --> 01:10:24,800
handle

1761
01:10:24,800 --> 01:10:27,760
now we'll sketch the proof

1762
01:10:27,760 --> 01:10:32,239
that this function is a dcrh

1763
01:10:32,320 --> 01:10:35,760
first the function is indeed compressing

1764
01:10:35,760 --> 01:10:36,719
now

1765
01:10:36,719 --> 01:10:39,520
the main observation is that a collision

1766
01:10:39,520 --> 01:10:42,880
in the function is two inputs that share

1767
01:10:42,880 --> 01:10:45,280
a characterize in what is it that means

1768
01:10:45,280 --> 01:10:47,920
two inputs that make alice behave

1769
01:10:47,920 --> 01:10:50,719
similar however since our predicate is

1770
01:10:50,719 --> 01:10:53,040
non-redundant there exists twice such

1771
01:10:53,040 --> 01:10:56,960
that f of x y is not equal to f of x

1772
01:10:56,960 --> 01:11:00,080
prime y but since alice's behavior is

1773
01:11:00,080 --> 01:11:01,199
similar

1774
01:11:01,199 --> 01:11:03,440
the output of the protocol will be

1775
01:11:03,440 --> 01:11:07,839
incorrect at least on one of the pairs

1776
01:11:08,719 --> 01:11:11,840
we got that a collision finder for that

1777
01:11:11,840 --> 01:11:15,520
function can be used to find bad inputs

1778
01:11:15,520 --> 01:11:17,120
for that protocol

1779
01:11:17,120 --> 01:11:20,400
however we claim only for dcrh and not

1780
01:11:20,400 --> 01:11:23,280
cr since the characterization property

1781
01:11:23,280 --> 01:11:25,199
of the function is only with high

1782
01:11:25,199 --> 01:11:27,760
probability and that means that there

1783
01:11:27,760 --> 01:11:30,880
exists input x such that h of x doesn't

1784
01:11:30,880 --> 01:11:34,320
characterize x and hence there exists

1785
01:11:34,320 --> 01:11:36,880
bad collisions collisions that won't

1786
01:11:36,880 --> 01:11:39,360
necessarily induce bad inputs for the

1787
01:11:39,360 --> 01:11:41,839
protocol

1788
01:11:42,000 --> 01:11:44,640
the second model is the stateful free

1789
01:11:44,640 --> 01:11:47,840
talk model in this model alice and bob

1790
01:11:47,840 --> 01:11:49,920
can communicate freely before the inputs

1791
01:11:49,920 --> 01:11:51,440
are chosen

1792
01:11:51,440 --> 01:11:53,600
then the inputs are chosen by an

1793
01:11:53,600 --> 01:11:56,480
adversary and now the communication is

1794
01:11:56,480 --> 01:11:58,080
measured

1795
01:11:58,080 --> 01:12:00,159
in this variation

1796
01:12:00,159 --> 01:12:03,520
we study the simultaneous messages model

1797
01:12:03,520 --> 01:12:05,920
we consider an adversary with two

1798
01:12:05,920 --> 01:12:09,440
additional advantages the first is

1799
01:12:09,440 --> 01:12:12,480
russian and can choose the input for bob

1800
01:12:12,480 --> 01:12:14,719
at the last moment after seeing alice's

1801
01:12:14,719 --> 01:12:15,760
message

1802
01:12:15,760 --> 01:12:18,400
and the second he doesn't have to attack

1803
01:12:18,400 --> 01:12:20,880
a specific session he can wait for an

1804
01:12:20,880 --> 01:12:23,520
opportunity to attack

1805
01:12:23,520 --> 01:12:25,600
we showed in this model

1806
01:12:25,600 --> 01:12:28,000
that very efficient protocols

1807
01:12:28,000 --> 01:12:30,320
imply the existence of secret key

1808
01:12:30,320 --> 01:12:31,679
agreement

1809
01:12:31,679 --> 01:12:34,800
note that assuming secret key agreement

1810
01:12:34,800 --> 01:12:37,440
optimal protocols exist as we'll see

1811
01:12:37,440 --> 01:12:38,480
next

1812
01:12:38,480 --> 01:12:39,440
first

1813
01:12:39,440 --> 01:12:42,480
let's recall secretary agreement

1814
01:12:42,480 --> 01:12:45,360
security agreement is where two parties

1815
01:12:45,360 --> 01:12:48,320
with nothing in common agree on a secret

1816
01:12:48,320 --> 01:12:49,280
key

1817
01:12:49,280 --> 01:12:50,480
the key

1818
01:12:50,480 --> 01:12:53,360
has to be known only to the participants

1819
01:12:53,360 --> 01:12:57,440
and not to any listening adversary

1820
01:12:57,440 --> 01:13:00,239
now let's walk through the steps

1821
01:13:00,239 --> 01:13:03,120
in the stateful free talk model the part

1822
01:13:03,120 --> 01:13:05,840
is talk freely

1823
01:13:05,840 --> 01:13:08,320
the adversary receives the transcript

1824
01:13:08,320 --> 01:13:11,120
and chooses the inputs for alice and bob

1825
01:13:11,120 --> 01:13:13,760
the parties get the input and send to

1826
01:13:13,760 --> 01:13:16,159
the referee a single message each the

1827
01:13:16,159 --> 01:13:18,800
referee output a decision

1828
01:13:18,800 --> 01:13:21,600
how secret key agreement implies optimal

1829
01:13:21,600 --> 01:13:24,400
equality protocol

1830
01:13:24,400 --> 01:13:26,719
the security agreement protocol can be

1831
01:13:26,719 --> 01:13:29,360
used in the free talk phase hence the

1832
01:13:29,360 --> 01:13:31,840
secret state of the participants will be

1833
01:13:31,840 --> 01:13:34,080
the secret key after receiving their

1834
01:13:34,080 --> 01:13:36,719
inputs the participant will use the

1835
01:13:36,719 --> 01:13:39,040
secret key to sample a pro as

1836
01:13:39,040 --> 01:13:40,960
independent hash functions

1837
01:13:40,960 --> 01:13:43,120
the inputs will be compressed by that

1838
01:13:43,120 --> 01:13:45,280
functions two messages and sent to the

1839
01:13:45,280 --> 01:13:47,679
referee the referee just compared the

1840
01:13:47,679 --> 01:13:50,480
messages now that this protocol is a

1841
01:13:50,480 --> 01:13:52,880
resilient to the mentioned patient

1842
01:13:52,880 --> 01:13:56,000
russian adversary

1843
01:13:56,640 --> 01:13:58,800
in the other direction towards

1844
01:13:58,800 --> 01:14:01,920
constructing security agreement we first

1845
01:14:01,920 --> 01:14:04,400
achieved the weaker notion of secret bid

1846
01:14:04,400 --> 01:14:07,760
agreement that is part is a clay on a

1847
01:14:07,760 --> 01:14:10,400
bit with some probability and that bit

1848
01:14:10,400 --> 01:14:12,880
is secret in some weakened option

1849
01:14:12,880 --> 01:14:15,840
note that the notion of alpha beta sql

1850
01:14:15,840 --> 01:14:18,480
bit agreement is a generalization of

1851
01:14:18,480 --> 01:14:21,360
secret gentlemen

1852
01:14:21,360 --> 01:14:24,320
and it is known when and how

1853
01:14:24,320 --> 01:14:26,840
alphabetical bit agreement can be

1854
01:14:26,840 --> 01:14:29,920
amplified to a secret key agreement

1855
01:14:29,920 --> 01:14:32,320
hence it is sufficient to show a

1856
01:14:32,320 --> 01:14:34,480
construction of alpha beta signal bit

1857
01:14:34,480 --> 01:14:37,600
agreement with suitable parameters

1858
01:14:37,600 --> 01:14:38,480
now

1859
01:14:38,480 --> 01:14:40,640
assume we have such a new optimal

1860
01:14:40,640 --> 01:14:42,480
protocol for equality

1861
01:14:42,480 --> 01:14:43,600
that means

1862
01:14:43,600 --> 01:14:46,480
we have a way to generate secret state

1863
01:14:46,480 --> 01:14:48,560
for alice involved

1864
01:14:48,560 --> 01:14:50,960
we have functions from inputs and secret

1865
01:14:50,960 --> 01:14:53,280
states to messages and we have the

1866
01:14:53,280 --> 01:14:56,000
function of the theory from messages to

1867
01:14:56,000 --> 01:14:58,320
a beat

1868
01:14:58,400 --> 01:15:01,440
our 6th week agreement protocol will be

1869
01:15:01,440 --> 01:15:02,719
as follows

1870
01:15:02,719 --> 01:15:03,760
first

1871
01:15:03,760 --> 01:15:06,560
the secret state is generated

1872
01:15:06,560 --> 01:15:08,400
and ali sampled

1873
01:15:08,400 --> 01:15:11,440
a secret bit b in two uniformly random

1874
01:15:11,440 --> 01:15:14,560
inputs x0 x1 alice evaluates in the

1875
01:15:14,560 --> 01:15:18,239
equality protocol a message for xb

1876
01:15:18,239 --> 01:15:21,600
she sends bob this message in x1 bob

1877
01:15:21,600 --> 01:15:25,120
evaluates its message for x1 in his

1878
01:15:25,120 --> 01:15:28,239
output b prime is the output of the

1879
01:15:28,239 --> 01:15:30,880
equality referee on its own generated

1880
01:15:30,880 --> 01:15:33,600
message and the received message

1881
01:15:33,600 --> 01:15:38,159
alice's output is her sample b to b

1882
01:15:38,159 --> 01:15:41,120
the agreement parameter of this protocol

1883
01:15:41,120 --> 01:15:43,679
that is the probability that b is equal

1884
01:15:43,679 --> 01:15:45,120
to b prime

1885
01:15:45,120 --> 01:15:47,920
is given by the equality protocol

1886
01:15:47,920 --> 01:15:50,560
for showing the secrecy we show that

1887
01:15:50,560 --> 01:15:53,600
given an adversary who can predict that

1888
01:15:53,600 --> 01:15:54,480
beat

1889
01:15:54,480 --> 01:15:56,880
we can construct an adversary for the

1890
01:15:56,880 --> 01:15:59,440
quality protocol

1891
01:15:59,440 --> 01:16:02,320
given a secret beat agreement adversary

1892
01:16:02,320 --> 01:16:05,600
the quality adversary will be as follows

1893
01:16:05,600 --> 01:16:09,199
in each session he sets a random input x

1894
01:16:09,199 --> 01:16:12,080
for alice and waits for her message

1895
01:16:12,080 --> 01:16:15,760
now he samples another random input x

1896
01:16:15,760 --> 01:16:18,880
prime and uses the secret bit agreement

1897
01:16:18,880 --> 01:16:22,480
adversary to check if that random input

1898
01:16:22,480 --> 01:16:26,559
also matches that message

1899
01:16:26,800 --> 01:16:27,840
that is

1900
01:16:27,840 --> 01:16:30,960
diversity wants to find two inputs that

1901
01:16:30,960 --> 01:16:33,199
can make alice produce the same message

1902
01:16:33,199 --> 01:16:36,000
with some probability if he finds such

1903
01:16:36,000 --> 01:16:38,480
inputs he attacks that session by

1904
01:16:38,480 --> 01:16:41,920
passing bob x with power bt half or x5

1905
01:16:41,920 --> 01:16:44,480
with probability half the intuition is

1906
01:16:44,480 --> 01:16:45,520
that

1907
01:16:45,520 --> 01:16:48,239
if the adversary finds two messages x

1908
01:16:48,239 --> 01:16:50,560
and x prime that make alice behave

1909
01:16:50,560 --> 01:16:52,800
similarly the referee is going to be

1910
01:16:52,800 --> 01:16:55,840
round on at least one pair

1911
01:16:55,840 --> 01:16:59,440
x and x or x and x prime

1912
01:16:59,440 --> 01:17:01,840
to conclude such a secret bit agreement

1913
01:17:01,840 --> 01:17:04,400
adversary contradicts the properties of

1914
01:17:04,400 --> 01:17:07,199
the equality protocol hence the secrecy

1915
01:17:07,199 --> 01:17:09,679
property of the secret bit agreement

1916
01:17:09,679 --> 01:17:12,400
protocol holds and the secret bit

1917
01:17:12,400 --> 01:17:15,520
agreement protocol can be amplified to a

1918
01:17:15,520 --> 01:17:18,719
secret key agreement protocol

1919
01:17:18,719 --> 01:17:21,040
before we finish let's mention some

1920
01:17:21,040 --> 01:17:22,320
related work

1921
01:17:22,320 --> 01:17:25,600
first the consecutive messages model in

1922
01:17:25,600 --> 01:17:27,760
this model the public random string is

1923
01:17:27,760 --> 01:17:29,920
chosen after the adversary chooses the

1924
01:17:29,920 --> 01:17:31,199
first input

1925
01:17:31,199 --> 01:17:33,920
hence a one-way function is necessary

1926
01:17:33,920 --> 01:17:36,000
and sufficient to break the square out

1927
01:17:36,000 --> 01:17:38,400
of n lower bound the lower bound is

1928
01:17:38,400 --> 01:17:40,480
shown via distributional one-way

1929
01:17:40,480 --> 01:17:42,640
function that is known to be

1930
01:17:42,640 --> 01:17:44,400
existentially equivalent

1931
01:17:44,400 --> 01:17:46,400
to one-way function

1932
01:17:46,400 --> 01:17:51,440
unlike the case with dcrh and crh

1933
01:17:52,000 --> 01:17:54,480
in the adversarial sketch model there

1934
01:17:54,480 --> 01:17:57,440
are two phases the sketch phase

1935
01:17:57,440 --> 01:17:59,600
where each party receives its input

1936
01:17:59,600 --> 01:18:01,920
online without any interaction with the

1937
01:18:01,920 --> 01:18:03,600
other party

1938
01:18:03,600 --> 01:18:05,679
and the interaction phase where there

1939
01:18:05,679 --> 01:18:08,159
are no inputs only sketches and the

1940
01:18:08,159 --> 01:18:10,719
parties communicate in order to compute

1941
01:18:10,719 --> 01:18:12,719
the target function

1942
01:18:12,719 --> 01:18:15,520
they showed a lower bound for the sketch

1943
01:18:15,520 --> 01:18:18,159
size that is very similar to the quote

1944
01:18:18,159 --> 01:18:22,719
of n in the simultaneous messages model

1945
01:18:22,719 --> 01:18:24,320
in the property preserving hash

1946
01:18:24,320 --> 01:18:26,960
functions model the target predicate

1947
01:18:26,960 --> 01:18:29,600
also should be computed from sketches

1948
01:18:29,600 --> 01:18:31,679
different levels of robustness are

1949
01:18:31,679 --> 01:18:33,679
defined the more access to the hash

1950
01:18:33,679 --> 01:18:36,480
function given to the adversary the more

1951
01:18:36,480 --> 01:18:40,239
robust the property preserving hash is

1952
01:18:40,239 --> 01:18:42,320
the full access robust property

1953
01:18:42,320 --> 01:18:44,960
preserving hash functions might be seen

1954
01:18:44,960 --> 01:18:47,600
as very close to our preset randomness

1955
01:18:47,600 --> 01:18:50,880
model simultaneous messages but here

1956
01:18:50,880 --> 01:18:53,600
there should be negligible and the path

1957
01:18:53,600 --> 01:18:57,199
is our deterministic

1958
01:18:57,440 --> 01:18:59,360
for further research

1959
01:18:59,360 --> 01:19:01,360
it will be interesting to figure out in

1960
01:19:01,360 --> 01:19:03,600
the preset randomness model

1961
01:19:03,600 --> 01:19:05,920
whether crashes are equivalent to

1962
01:19:05,920 --> 01:19:08,640
protocols that break dimension bounds

1963
01:19:08,640 --> 01:19:10,960
or to break those bounds with weaker

1964
01:19:10,960 --> 01:19:13,679
primitives in the free talk model we

1965
01:19:13,679 --> 01:19:16,640
would like to know whether protocols

1966
01:19:16,640 --> 01:19:19,520
that are secure in weaker notions

1967
01:19:19,520 --> 01:19:23,840
also imply security agreement

1968
01:19:27,440 --> 01:19:30,400
let's thank the speaker

1969
01:19:32,239 --> 01:19:34,000
and i believe the speaker is here with

1970
01:19:34,000 --> 01:19:35,920
us in the zoom room if there are any

1971
01:19:35,920 --> 01:19:38,560
questions

1972
01:19:43,679 --> 01:19:47,120
is that correct is he still here

1973
01:19:47,120 --> 01:19:48,719
yes yes

1974
01:19:48,719 --> 01:19:50,960
all right i have a question um so you

1975
01:19:50,960 --> 01:19:53,199
listed quite a few different further

1976
01:19:53,199 --> 01:19:55,120
research questions there at the end can

1977
01:19:55,120 --> 01:19:56,960
you talk a bit more about whichever of

1978
01:19:56,960 --> 01:19:58,960
those you think is the most uh

1979
01:19:58,960 --> 01:20:01,440
compelling

1980
01:20:01,679 --> 01:20:04,800
i think the the gap between this rh and

1981
01:20:04,800 --> 01:20:07,840
the crhs

1982
01:20:10,320 --> 01:20:13,280
because it's not clear if it's

1983
01:20:13,280 --> 01:20:14,239
a

1984
01:20:14,239 --> 01:20:16,800
technical barrier or

1985
01:20:16,800 --> 01:20:20,480
or something more significant

1986
01:20:22,480 --> 01:20:24,000
sorry i'm having a little bit of trouble

1987
01:20:24,000 --> 01:20:25,840
understanding your audio

1988
01:20:25,840 --> 01:20:28,400
can you say that one more time

1989
01:20:28,400 --> 01:20:30,239
can you hear me

1990
01:20:30,239 --> 01:20:32,480
yeah it's just a little muddled

1991
01:20:32,480 --> 01:20:34,400
but um but yeah i think it's i think

1992
01:20:34,400 --> 01:20:35,920
it's good now so

1993
01:20:35,920 --> 01:20:38,480
uh yeah just please repeat

1994
01:20:38,480 --> 01:20:41,120
okay i think the gap between

1995
01:20:41,120 --> 01:20:44,840
crhs and the dcr ages

1996
01:20:44,840 --> 01:20:49,679
uh a the most compelling

1997
01:20:56,480 --> 01:20:58,639
yes sorry i'm just i can hear you volume

1998
01:20:58,639 --> 01:21:01,199
wise fine but the um the words are

1999
01:21:01,199 --> 01:21:04,080
coming out a little muddled so i'm

2000
01:21:04,080 --> 01:21:06,800
not quite sure

2001
01:21:09,600 --> 01:21:12,560
at least the the talk was a

2002
01:21:12,560 --> 01:21:15,560
pre-recorded

2003
01:21:15,840 --> 01:21:18,080
yes

2004
01:21:18,400 --> 01:21:20,400
are there are there any questions in

2005
01:21:20,400 --> 01:21:22,320
zoom you can put them in the chat or any

2006
01:21:22,320 --> 01:21:25,599
further questions in the room

2007
01:21:26,560 --> 01:21:29,040
oh all right well i think everyone is

2008
01:21:29,040 --> 01:21:31,120
anxious to get to lunch so we will go

2009
01:21:31,120 --> 01:21:33,679
ahead and do that a quick announcement

2010
01:21:33,679 --> 01:21:35,760
if you're interested in arranging a ride

2011
01:21:35,760 --> 01:21:38,080
share uh back tomorrow they've started a

2012
01:21:38,080 --> 01:21:40,800
chat channel for that so that's

2013
01:21:40,800 --> 01:21:42,719
accessible from the link on the main

2014
01:21:42,719 --> 01:21:43,760
program

2015
01:21:43,760 --> 01:21:45,920
and we'll start sessions back up today

2016
01:21:45,920 --> 01:21:49,440
at 150 thank you

2017
01:21:50,480 --> 01:21:53,480
sorry

