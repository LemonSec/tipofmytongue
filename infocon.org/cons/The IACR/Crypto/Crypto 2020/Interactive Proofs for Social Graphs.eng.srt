1
00:00:00,719 --> 00:00:06,000
hi everyone my name is elon yogev

2
00:00:03,679 --> 00:00:07,439
this is a joint work with liran katsir

3
00:00:06,000 --> 00:00:09,200
and clara schickelmann

4
00:00:07,440 --> 00:00:10,800
and it's about interactive proofs for

5
00:00:09,200 --> 00:00:13,759
social graphs

6
00:00:10,800 --> 00:00:15,200
so social graphs as you all know and

7
00:00:13,759 --> 00:00:17,840
probably use

8
00:00:15,200 --> 00:00:19,359
a they affect the billions of people

9
00:00:17,840 --> 00:00:22,160
around the world

10
00:00:19,359 --> 00:00:23,920
they also have become a modern approach

11
00:00:22,160 --> 00:00:26,960
to study society

12
00:00:23,920 --> 00:00:27,359
and in general human relationships there

13
00:00:26,960 --> 00:00:30,560
are

14
00:00:27,359 --> 00:00:34,000
many many different public companies

15
00:00:30,560 --> 00:00:36,719
um that

16
00:00:34,000 --> 00:00:37,440
have social graphs and you see a lot of

17
00:00:36,719 --> 00:00:40,879
examples

18
00:00:37,440 --> 00:00:44,079
here in the picture and i also

19
00:00:40,879 --> 00:00:46,160
include in this things like dblp

20
00:00:44,079 --> 00:00:48,239
search engine or many other virtual

21
00:00:46,160 --> 00:00:52,398
assets that can also be

22
00:00:48,239 --> 00:00:52,399
modeled as a social network

23
00:00:53,039 --> 00:00:56,480
it's very important to keep track of the

24
00:00:55,280 --> 00:01:00,960
health of a

25
00:00:56,480 --> 00:01:04,000
social graph uh companies public reports

26
00:01:00,960 --> 00:01:07,360
with different measures about the health

27
00:01:04,000 --> 00:01:08,640
of their networks um we're going to talk

28
00:01:07,360 --> 00:01:12,240
about a few measures

29
00:01:08,640 --> 00:01:14,720
but one main one is just simply the size

30
00:01:12,240 --> 00:01:15,439
of this graph or network so this is the

31
00:01:14,720 --> 00:01:17,439
number of

32
00:01:15,439 --> 00:01:19,679
nodes in the network the number of

33
00:01:17,439 --> 00:01:21,919
active users

34
00:01:19,680 --> 00:01:22,799
for example facebook has acquired what's

35
00:01:21,920 --> 00:01:25,600
up for the

36
00:01:22,799 --> 00:01:27,520
steep price of 16 billion dollars and

37
00:01:25,600 --> 00:01:28,479
this was computed by a forty dollar

38
00:01:27,520 --> 00:01:32,079
evaluation

39
00:01:28,479 --> 00:01:35,200
per user and you can see here um

40
00:01:32,079 --> 00:01:36,320
from facebook's report of this year that

41
00:01:35,200 --> 00:01:39,360
they reported

42
00:01:36,320 --> 00:01:42,479
that they have over 1.73 billion

43
00:01:39,360 --> 00:01:43,759
active daily users and 2.6 billion

44
00:01:42,479 --> 00:01:45,840
monthly active users

45
00:01:43,759 --> 00:01:47,759
okay so these are from facebook's

46
00:01:45,840 --> 00:01:51,680
response

47
00:01:47,759 --> 00:01:54,799
um of course companies might

48
00:01:51,680 --> 00:01:59,360
possibly have some incentives

49
00:01:54,799 --> 00:02:02,719
to cheat or lie in these reports

50
00:01:59,360 --> 00:02:05,200
financial or political or otherwise

51
00:02:02,719 --> 00:02:07,119
and we can ask should we trust these

52
00:02:05,200 --> 00:02:09,280
reports

53
00:02:07,119 --> 00:02:10,318
and i guess one answer should be at

54
00:02:09,280 --> 00:02:12,879
least

55
00:02:10,318 --> 00:02:14,000
it sounds crucial to have an independent

56
00:02:12,879 --> 00:02:17,280
estimate

57
00:02:14,000 --> 00:02:19,280
of these measures and there are two

58
00:02:17,280 --> 00:02:21,360
main challenges which that come with

59
00:02:19,280 --> 00:02:25,920
this one is that the graph

60
00:02:21,360 --> 00:02:29,360
is huge and this is a challenge not only

61
00:02:25,920 --> 00:02:31,518
computationally but also

62
00:02:29,360 --> 00:02:33,040
because the access to this graph is

63
00:02:31,519 --> 00:02:35,519
limited so

64
00:02:33,040 --> 00:02:36,079
we're not just given a file with all the

65
00:02:35,519 --> 00:02:38,800
information

66
00:02:36,080 --> 00:02:39,360
on the network instead the way we can

67
00:02:38,800 --> 00:02:42,319
access

68
00:02:39,360 --> 00:02:43,599
these networks is by what's called the

69
00:02:42,319 --> 00:02:46,000
public access

70
00:02:43,599 --> 00:02:47,599
okay or external access so this is the

71
00:02:46,000 --> 00:02:49,440
access we have with this network

72
00:02:47,599 --> 00:02:52,560
they usually include two things so the

73
00:02:49,440 --> 00:02:56,000
first is membership queries

74
00:02:52,560 --> 00:02:58,720
so this means that i'm given a user's id

75
00:02:56,000 --> 00:03:01,280
okay so i'm given some id from some huge

76
00:02:58,720 --> 00:03:03,359
universe of possible ids

77
00:03:01,280 --> 00:03:05,200
okay and i'm giving this idea and i can

78
00:03:03,360 --> 00:03:08,159
check if this id exists

79
00:03:05,200 --> 00:03:08,799
or not in the network and usually if it

80
00:03:08,159 --> 00:03:11,359
exists i

81
00:03:08,800 --> 00:03:11,920
also get some metadata some profile page

82
00:03:11,360 --> 00:03:15,440
of

83
00:03:11,920 --> 00:03:16,839
of the user containing some information

84
00:03:15,440 --> 00:03:20,000
about this user

85
00:03:16,840 --> 00:03:21,440
agent and other stuff

86
00:03:20,000 --> 00:03:23,440
the second kind of query is the

87
00:03:21,440 --> 00:03:26,560
neighborhood query where again

88
00:03:23,440 --> 00:03:29,440
um i provide the id of a user

89
00:03:26,560 --> 00:03:31,519
and i get the list of neighbors okay

90
00:03:29,440 --> 00:03:34,239
leave a list of its symbols in the graph

91
00:03:31,519 --> 00:03:35,440
and if this list is too huge you can

92
00:03:34,239 --> 00:03:37,599
think of also

93
00:03:35,440 --> 00:03:40,400
like i provide the id and i and i get

94
00:03:37,599 --> 00:03:40,399
the ice neighbor

95
00:03:41,840 --> 00:03:48,080
so just uh there's a lot of works

96
00:03:45,360 --> 00:03:48,959
relevant but just really a brief history

97
00:03:48,080 --> 00:03:52,159
there exists

98
00:03:48,959 --> 00:03:54,319
a works that use this public interface

99
00:03:52,159 --> 00:03:55,519
to get an independent estimate of the

100
00:03:54,319 --> 00:03:58,839
size

101
00:03:55,519 --> 00:04:00,000
of the graph and also of many other

102
00:03:58,840 --> 00:04:03,439
measures uh

103
00:04:00,000 --> 00:04:06,000
just for example yital and kazirital

104
00:04:03,439 --> 00:04:07,280
um they use this public interface they

105
00:04:06,000 --> 00:04:10,720
did something like

106
00:04:07,280 --> 00:04:12,879
polyen et queries okay

107
00:04:10,720 --> 00:04:14,080
so enter the alpha core is for some like

108
00:04:12,879 --> 00:04:16,478
small constant alpha

109
00:04:14,080 --> 00:04:18,079
like half of improved by concealed one

110
00:04:16,478 --> 00:04:21,199
over four

111
00:04:18,079 --> 00:04:23,440
and uh using this they were able to

112
00:04:21,199 --> 00:04:26,639
estimate the size of the cuff

113
00:04:23,440 --> 00:04:26,880
and our main question is can we get such

114
00:04:26,639 --> 00:04:30,000
an

115
00:04:26,880 --> 00:04:31,840
independent uh estimate

116
00:04:30,000 --> 00:04:33,040
of the size of social graphs or other

117
00:04:31,840 --> 00:04:36,479
major using

118
00:04:33,040 --> 00:04:39,520
few queries to the network so not polyen

119
00:04:36,479 --> 00:04:42,880
okay more like polylogin

120
00:04:39,520 --> 00:04:46,719
but still having no trust in the graphs

121
00:04:42,880 --> 00:04:49,040
provider and to answer this

122
00:04:46,720 --> 00:04:50,720
we introduce interactive proofs for

123
00:04:49,040 --> 00:04:54,320
social graphs

124
00:04:50,720 --> 00:04:55,840
so here we're gonna communicate with the

125
00:04:54,320 --> 00:04:59,120
proverb

126
00:04:55,840 --> 00:05:00,159
okay and we're gonna use this oracle

127
00:04:59,120 --> 00:05:02,639
access to the graph

128
00:05:00,160 --> 00:05:03,440
but again we're not gonna trust the pool

129
00:05:02,639 --> 00:05:05,680
so we're gonna use

130
00:05:03,440 --> 00:05:07,440
his help and computational power but

131
00:05:05,680 --> 00:05:09,039
we're not gonna trust him

132
00:05:07,440 --> 00:05:11,280
so the model is like this we have a

133
00:05:09,039 --> 00:05:12,880
verifier here the verifier can interact

134
00:05:11,280 --> 00:05:16,080
with approval

135
00:05:12,880 --> 00:05:18,159
the instance that they are talking about

136
00:05:16,080 --> 00:05:21,039
is this graph g

137
00:05:18,160 --> 00:05:22,960
the verifier has only oracle access to g

138
00:05:21,039 --> 00:05:26,800
and again this oracle is defined

139
00:05:22,960 --> 00:05:28,159
by the two queries we talked about so

140
00:05:26,800 --> 00:05:30,800
these are membership

141
00:05:28,160 --> 00:05:32,240
okay possibly metadata enable the

142
00:05:30,800 --> 00:05:34,560
neighborhood

143
00:05:32,240 --> 00:05:38,160
the prover of course is all-powerful has

144
00:05:34,560 --> 00:05:40,880
full access to the gulf and everything

145
00:05:38,160 --> 00:05:41,440
okay so this is more like a interactive

146
00:05:40,880 --> 00:05:43,600
box

147
00:05:41,440 --> 00:05:45,360
proof of proximity okay because the

148
00:05:43,600 --> 00:05:46,800
verifier cannot even read the whole

149
00:05:45,360 --> 00:05:50,840
instance

150
00:05:46,800 --> 00:05:53,120
okay it's not only about not having a

151
00:05:50,840 --> 00:05:55,198
witness um

152
00:05:53,120 --> 00:05:56,400
let me raise some immediate criticism

153
00:05:55,199 --> 00:05:58,880
about our model

154
00:05:56,400 --> 00:06:02,960
so one thing we are assuming is that the

155
00:05:58,880 --> 00:06:06,240
oracle answers are returned truthfully

156
00:06:02,960 --> 00:06:09,120
okay you can ask why if you don't trust

157
00:06:06,240 --> 00:06:10,880
facebook to give a report then when you

158
00:06:09,120 --> 00:06:13,600
query the graph

159
00:06:10,880 --> 00:06:14,960
you know they are the same ones that are

160
00:06:13,600 --> 00:06:16,560
giving you these answers they're

161
00:06:14,960 --> 00:06:20,719
implementing this oracle

162
00:06:16,560 --> 00:06:23,759
so why do you trust the local answers

163
00:06:20,720 --> 00:06:25,039
so those are reasons first it's very

164
00:06:23,759 --> 00:06:28,479
hard to distinguish

165
00:06:25,039 --> 00:06:30,240
between legitimate users queries and the

166
00:06:28,479 --> 00:06:33,360
verifies queries

167
00:06:30,240 --> 00:06:35,199
so be helpful facebook to cheat in these

168
00:06:33,360 --> 00:06:37,520
answers only for us and not for

169
00:06:35,199 --> 00:06:39,039
other users and this actually forces

170
00:06:37,520 --> 00:06:42,400
them

171
00:06:39,039 --> 00:06:42,800
uh to cheat uh to materialize their

172
00:06:42,400 --> 00:06:44,960
cheat

173
00:06:42,800 --> 00:06:45,919
okay in the network itself so if they

174
00:06:44,960 --> 00:06:47,440
wanna cheat and

175
00:06:45,919 --> 00:06:49,280
claim that they have millions of users

176
00:06:47,440 --> 00:06:51,120
and they don't they actually need to

177
00:06:49,280 --> 00:06:53,198
create these users and make them

178
00:06:51,120 --> 00:06:55,520
consistent in the network

179
00:06:53,199 --> 00:06:57,680
and this possibly you could catch them

180
00:06:55,520 --> 00:07:00,960
later

181
00:06:57,680 --> 00:07:03,199
okay so what is our main result

182
00:07:00,960 --> 00:07:04,638
our main theorem is the following you

183
00:07:03,199 --> 00:07:07,120
give me some graph g

184
00:07:04,639 --> 00:07:07,759
it's an n vertex graph it has mixing

185
00:07:07,120 --> 00:07:10,080
time

186
00:07:07,759 --> 00:07:11,280
tau i'm gonna talk and define mixing

187
00:07:10,080 --> 00:07:14,880
time later

188
00:07:11,280 --> 00:07:16,318
but for now it's more or less

189
00:07:14,880 --> 00:07:18,960
how many steps you need to take in the

190
00:07:16,319 --> 00:07:20,479
graph um

191
00:07:18,960 --> 00:07:22,479
to get close to the stationary

192
00:07:20,479 --> 00:07:25,758
distribution

193
00:07:22,479 --> 00:07:27,520
and it has average degree delta

194
00:07:25,759 --> 00:07:30,000
and the result says that there is a

195
00:07:27,520 --> 00:07:32,240
doubly efficient interactive proof

196
00:07:30,000 --> 00:07:33,840
in the social graph model okay the mode

197
00:07:32,240 --> 00:07:36,960
that i just presented

198
00:07:33,840 --> 00:07:38,799
for estimating the size of the graph

199
00:07:36,960 --> 00:07:40,799
and it has the following properties

200
00:07:38,800 --> 00:07:41,440
first we have some approximation error

201
00:07:40,800 --> 00:07:43,680
epsilon

202
00:07:41,440 --> 00:07:46,160
so you can just plug whatever epsilon

203
00:07:43,680 --> 00:07:48,560
you want this is the l that you allow

204
00:07:46,160 --> 00:07:49,680
and we're going to verify that the

205
00:07:48,560 --> 00:07:51,680
claimed size

206
00:07:49,680 --> 00:07:54,879
so the approval is going to claim that

207
00:07:51,680 --> 00:07:56,720
the graph is of size n tilde

208
00:07:54,879 --> 00:07:58,240
and we're going to verify that until the

209
00:07:56,720 --> 00:08:01,599
is very close to n

210
00:07:58,240 --> 00:08:02,960
so at most uh one plus epsilon and at

211
00:08:01,599 --> 00:08:06,159
least one minus epsilon

212
00:08:02,960 --> 00:08:08,878
times n uh

213
00:08:06,160 --> 00:08:10,000
the protocol is two message and it's

214
00:08:08,879 --> 00:08:13,120
public coin

215
00:08:10,000 --> 00:08:14,160
which is great a the query complexity of

216
00:08:13,120 --> 00:08:16,720
the verifier

217
00:08:14,160 --> 00:08:18,960
maybe the most important parameter here

218
00:08:16,720 --> 00:08:22,000
is small so it's one over epsilon

219
00:08:18,960 --> 00:08:25,520
squared okay times this

220
00:08:22,000 --> 00:08:27,440
a mixing time tau and time this delta

221
00:08:25,520 --> 00:08:30,000
and it seems that this is inherent but

222
00:08:27,440 --> 00:08:33,039
not completely clear

223
00:08:30,000 --> 00:08:35,039
and and it's also as we said doubly

224
00:08:33,039 --> 00:08:36,880
efficient so the pull the running time

225
00:08:35,039 --> 00:08:38,479
is also efficient it's n times 1 over

226
00:08:36,880 --> 00:08:41,360
epsilon squared

227
00:08:38,479 --> 00:08:43,599
which means that that is for small for a

228
00:08:41,360 --> 00:08:46,800
let's say constant epsilon

229
00:08:43,599 --> 00:08:46,800
this is quasi-linear

230
00:08:48,560 --> 00:08:52,079
um there are several applications of

231
00:08:51,519 --> 00:08:55,360
this

232
00:08:52,080 --> 00:08:57,440
main result i'll just talk

233
00:08:55,360 --> 00:08:59,200
shortly about a few so first you can

234
00:08:57,440 --> 00:09:01,760
estimate not only the size of the

235
00:08:59,200 --> 00:09:02,320
graph itself but any sub-graph for

236
00:09:01,760 --> 00:09:04,640
example

237
00:09:02,320 --> 00:09:06,080
if in the metadata that you get for a

238
00:09:04,640 --> 00:09:08,399
user you know

239
00:09:06,080 --> 00:09:10,480
the user's age then you can actually

240
00:09:08,399 --> 00:09:14,240
check how many users are between the age

241
00:09:10,480 --> 00:09:18,000
10 and 20. okay just taking this

242
00:09:14,240 --> 00:09:19,360
sum off um other health measures that

243
00:09:18,000 --> 00:09:21,920
you can get

244
00:09:19,360 --> 00:09:22,720
actually as a application of the our

245
00:09:21,920 --> 00:09:25,199
main theorem

246
00:09:22,720 --> 00:09:26,800
is the distribution of the degree the

247
00:09:25,200 --> 00:09:28,560
median of the degree

248
00:09:26,800 --> 00:09:30,000
what's called the local clustering

249
00:09:28,560 --> 00:09:32,959
coefficient

250
00:09:30,000 --> 00:09:35,040
um and and many other measures and in

251
00:09:32,959 --> 00:09:38,000
general for any function f

252
00:09:35,040 --> 00:09:39,920
you can estimate the quantile okay let's

253
00:09:38,000 --> 00:09:42,560
say the median or the quantiles

254
00:09:39,920 --> 00:09:45,519
of these values of f applied to any all

255
00:09:42,560 --> 00:09:45,518
the nodes of the graph

256
00:09:48,000 --> 00:09:53,680
one last application is the um

257
00:09:51,200 --> 00:09:54,240
we can use the feature mirror transform

258
00:09:53,680 --> 00:09:56,079
okay

259
00:09:54,240 --> 00:09:57,600
so this is a transformation that in the

260
00:09:56,080 --> 00:09:59,440
random oracle model

261
00:09:57,600 --> 00:10:02,079
is going to compile these interactive

262
00:09:59,440 --> 00:10:04,399
proofs to non-interactive

263
00:10:02,079 --> 00:10:06,160
arguments okay so these are the

264
00:10:04,399 --> 00:10:07,440
soundness is going to be computationally

265
00:10:06,160 --> 00:10:10,160
now

266
00:10:07,440 --> 00:10:11,040
and these arguments can be published

267
00:10:10,160 --> 00:10:13,279
once

268
00:10:11,040 --> 00:10:15,360
okay and be publicly verified by any

269
00:10:13,279 --> 00:10:17,839
user any single user

270
00:10:15,360 --> 00:10:19,360
using uh a few small number of queries

271
00:10:17,839 --> 00:10:21,040
to the graph

272
00:10:19,360 --> 00:10:22,959
so if you go back to this report by

273
00:10:21,040 --> 00:10:24,319
facebook they can now after

274
00:10:22,959 --> 00:10:26,560
claiming that they have this many

275
00:10:24,320 --> 00:10:28,160
billion daily active user they can just

276
00:10:26,560 --> 00:10:30,839
add a small profile

277
00:10:28,160 --> 00:10:32,319
which could be later verified by by any

278
00:10:30,839 --> 00:10:34,640
user

279
00:10:32,320 --> 00:10:35,920
hopefully maybe this will be part of the

280
00:10:34,640 --> 00:10:39,279
next generation

281
00:10:35,920 --> 00:10:41,920
regulation like gdpr just only for

282
00:10:39,279 --> 00:10:41,920
social graphs

283
00:10:43,440 --> 00:10:49,440
okay our protocol so

284
00:10:47,279 --> 00:10:50,399
we're gonna show a protocol by first

285
00:10:49,440 --> 00:10:53,680
showing uh

286
00:10:50,399 --> 00:10:55,040
the same protocol for general sets okay

287
00:10:53,680 --> 00:10:57,279
and then we're gonna see how this

288
00:10:55,040 --> 00:11:00,399
applies to social curves

289
00:10:57,279 --> 00:11:03,040
um so i'm

290
00:11:00,399 --> 00:11:04,000
we're given a set s okay and we're

291
00:11:03,040 --> 00:11:06,319
giving some number

292
00:11:04,000 --> 00:11:08,240
and tilde of approval claims the set s

293
00:11:06,320 --> 00:11:11,440
is of size n tilde

294
00:11:08,240 --> 00:11:13,519
we have membership

295
00:11:11,440 --> 00:11:15,120
access to the set so for any element we

296
00:11:13,519 --> 00:11:18,320
can check if it's indecent

297
00:11:15,120 --> 00:11:21,120
and we have this um

298
00:11:18,320 --> 00:11:21,920
query d okay which gives me uniform

299
00:11:21,120 --> 00:11:24,720
samples

300
00:11:21,920 --> 00:11:25,760
so we have some algorithm we apply it we

301
00:11:24,720 --> 00:11:27,920
we run it

302
00:11:25,760 --> 00:11:29,040
and the result is a uniform sample in

303
00:11:27,920 --> 00:11:32,560
the set

304
00:11:29,040 --> 00:11:34,079
these are the two the two axis queries

305
00:11:32,560 --> 00:11:35,760
we have to reset

306
00:11:34,079 --> 00:11:38,880
okay and later we're going to see how we

307
00:11:35,760 --> 00:11:41,680
implement this in a social graph

308
00:11:38,880 --> 00:11:44,000
so our goal is to verify the claim of

309
00:11:41,680 --> 00:11:47,760
the proverb that indeed this in tilde is

310
00:11:44,000 --> 00:11:50,480
very close to the size of the actual set

311
00:11:47,760 --> 00:11:50,959
so this is both low bound and upper one

312
00:11:50,480 --> 00:11:52,880
so

313
00:11:50,959 --> 00:11:54,319
we want to distinguish between these two

314
00:11:52,880 --> 00:11:56,720
cases okay

315
00:11:54,320 --> 00:11:57,680
so it's only a small epson like one

316
00:11:56,720 --> 00:11:59,440
percent

317
00:11:57,680 --> 00:12:02,479
uh difference between what the people

318
00:11:59,440 --> 00:12:05,279
claimed and the actual size

319
00:12:02,480 --> 00:12:06,480
uh and our inspiration for this if you

320
00:12:05,279 --> 00:12:10,800
know it is the

321
00:12:06,480 --> 00:12:14,000
protocol of gold vessel sip so um

322
00:12:10,800 --> 00:12:15,359
that actually provided as part of the

323
00:12:14,000 --> 00:12:19,839
proof

324
00:12:15,360 --> 00:12:23,680
a lower bound for the size of the set

325
00:12:19,839 --> 00:12:25,920
um so let's see what we do

326
00:12:23,680 --> 00:12:27,120
the verifier is going to send the prover

327
00:12:25,920 --> 00:12:31,360
a hash function

328
00:12:27,120 --> 00:12:33,040
h and an element y

329
00:12:31,360 --> 00:12:35,519
this hash function h is going to be a

330
00:12:33,040 --> 00:12:38,800
hash function from the universe

331
00:12:35,519 --> 00:12:40,959
to this set of numbers between 1 and n

332
00:12:38,800 --> 00:12:43,120
times epsilon squared to some so

333
00:12:40,959 --> 00:12:45,040
something smaller than n

334
00:12:43,120 --> 00:12:46,160
and y is going to be uniform in this

335
00:12:45,040 --> 00:12:48,160
range

336
00:12:46,160 --> 00:12:49,920
and this hash function we're going to

337
00:12:48,160 --> 00:12:50,800
for now assume that it's just truly

338
00:12:49,920 --> 00:12:52,719
random

339
00:12:50,800 --> 00:12:54,319
later we're going to see that we can

340
00:12:52,720 --> 00:12:56,959
actually rely on

341
00:12:54,320 --> 00:12:58,160
polylogue's independence but until the

342
00:12:56,959 --> 00:12:59,760
end let's just

343
00:12:58,160 --> 00:13:01,279
assume that these hash functions are

344
00:12:59,760 --> 00:13:03,839
random

345
00:13:01,279 --> 00:13:04,959
the prover is going to reply with this

346
00:13:03,839 --> 00:13:08,000
set z

347
00:13:04,959 --> 00:13:09,359
which is all the pre-images of y okay so

348
00:13:08,000 --> 00:13:12,240
the pre-images of some

349
00:13:09,360 --> 00:13:13,920
random element in the range uh but of

350
00:13:12,240 --> 00:13:16,160
course the primitives that are in the

351
00:13:13,920 --> 00:13:16,160
set

352
00:13:16,959 --> 00:13:20,000
okay the verifier is going to check that

353
00:13:19,279 --> 00:13:22,320
this set of

354
00:13:20,000 --> 00:13:24,959
images is in the set and that it's

355
00:13:22,320 --> 00:13:26,720
actually the images of y so just

356
00:13:24,959 --> 00:13:28,560
applying the hash function to all the

357
00:13:26,720 --> 00:13:31,200
members of z

358
00:13:28,560 --> 00:13:31,599
and it's going to accept if and only if

359
00:13:31,200 --> 00:13:33,600
z

360
00:13:31,600 --> 00:13:34,720
is more or less okay and there's some

361
00:13:33,600 --> 00:13:38,079
parameters here

362
00:13:34,720 --> 00:13:39,680
one other epsilon squared uh so if h is

363
00:13:38,079 --> 00:13:43,000
random we expect

364
00:13:39,680 --> 00:13:44,160
and the set is indeed of size n then we

365
00:13:43,000 --> 00:13:47,440
expect

366
00:13:44,160 --> 00:13:50,399
about one of epsilon squared to fall

367
00:13:47,440 --> 00:13:52,480
uh into this specific y okay and the

368
00:13:50,399 --> 00:13:53,920
very first gonna accept if it's close to

369
00:13:52,480 --> 00:13:57,519
that

370
00:13:53,920 --> 00:14:01,040
if the set was very small

371
00:13:57,519 --> 00:14:03,839
um then you're not gonna have

372
00:14:01,040 --> 00:14:05,920
so many elements that are going to lie

373
00:14:03,839 --> 00:14:08,720
on this specific y

374
00:14:05,920 --> 00:14:09,760
and the complexity of this protocol is

375
00:14:08,720 --> 00:14:12,320
actually

376
00:14:09,760 --> 00:14:14,160
a one over epsilon squared okay so these

377
00:14:12,320 --> 00:14:15,680
are just the membership queries to make

378
00:14:14,160 --> 00:14:18,959
sure that all these elements are in

379
00:14:15,680 --> 00:14:20,719
s the main difference between gold

380
00:14:18,959 --> 00:14:21,599
vessels sip cell which is very similar

381
00:14:20,720 --> 00:14:24,800
to this

382
00:14:21,600 --> 00:14:26,720
is that they relied on the difference

383
00:14:24,800 --> 00:14:27,839
between the complements and sun is to be

384
00:14:26,720 --> 00:14:29,600
a factor of two

385
00:14:27,839 --> 00:14:31,199
so they could distinguish between a set

386
00:14:29,600 --> 00:14:33,040
of size n and two n

387
00:14:31,199 --> 00:14:34,880
and here we need to change this a bit to

388
00:14:33,040 --> 00:14:37,920
be uh to

389
00:14:34,880 --> 00:14:39,199
not if i notice this a small factor of

390
00:14:37,920 --> 00:14:42,319
epsilon

391
00:14:39,199 --> 00:14:44,959
um so we generalize the protocol

392
00:14:42,320 --> 00:14:45,600
a bit more technical analysis but really

393
00:14:44,959 --> 00:14:48,719
the hulk

394
00:14:45,600 --> 00:14:51,279
lies in gold versus himself

395
00:14:48,720 --> 00:14:52,720
but this was for a lower bound and to

396
00:14:51,279 --> 00:14:55,760
complete the picture we need

397
00:14:52,720 --> 00:14:55,760
also an upper bound

398
00:14:56,079 --> 00:15:00,319
so here the ups upper bound goes as

399
00:14:58,720 --> 00:15:03,120
follows

400
00:15:00,320 --> 00:15:05,040
uh so this is our first attempt the

401
00:15:03,120 --> 00:15:07,040
first attempt is going to do

402
00:15:05,040 --> 00:15:08,079
um something similar to what the

403
00:15:07,040 --> 00:15:11,680
previous work

404
00:15:08,079 --> 00:15:14,399
did so the verifier is going to use this

405
00:15:11,680 --> 00:15:14,880
sampler algorithm d to sample square

406
00:15:14,399 --> 00:15:17,760
root

407
00:15:14,880 --> 00:15:19,120
and uniform elements okay we want to

408
00:15:17,760 --> 00:15:22,160
explode and

409
00:15:19,120 --> 00:15:23,760
fill the claim then and

410
00:15:22,160 --> 00:15:26,160
it's going to accept if and only if

411
00:15:23,760 --> 00:15:29,519
there exists two different indexes

412
00:15:26,160 --> 00:15:32,800
such that the samples were the same

413
00:15:29,519 --> 00:15:34,560
so if indeed the set was of size n then

414
00:15:32,800 --> 00:15:36,000
we're gonna have a collision this is by

415
00:15:34,560 --> 00:15:39,199
with some probability

416
00:15:36,000 --> 00:15:40,320
okay this is by the birthday paradox and

417
00:15:39,199 --> 00:15:43,279
if the

418
00:15:40,320 --> 00:15:45,519
set was actually much larger so if the

419
00:15:43,279 --> 00:15:48,639
pulver is claiming the set is very small

420
00:15:45,519 --> 00:15:51,120
but the actual set is is much larger

421
00:15:48,639 --> 00:15:52,000
then we're not going to see a collision

422
00:15:51,120 --> 00:15:54,880
okay so that

423
00:15:52,000 --> 00:15:57,120
won't exist two la two distinct indexes

424
00:15:54,880 --> 00:15:59,199
that go to the same element

425
00:15:57,120 --> 00:16:00,639
this gives us some probability to

426
00:15:59,199 --> 00:16:02,000
distinguish between completeness and

427
00:16:00,639 --> 00:16:03,839
soundness and we're gonna have to do one

428
00:16:02,000 --> 00:16:04,800
of our epsilon repetitions and take them

429
00:16:03,839 --> 00:16:08,240
again

430
00:16:04,800 --> 00:16:08,719
to amplify the probabilities so this is

431
00:16:08,240 --> 00:16:12,000
great

432
00:16:08,720 --> 00:16:15,519
in terms of completeness and soundness

433
00:16:12,000 --> 00:16:16,160
okay um but the query complexity is not

434
00:16:15,519 --> 00:16:17,759
so good

435
00:16:16,160 --> 00:16:20,319
so the verifier actually needs to do

436
00:16:17,759 --> 00:16:22,959
this square root and

437
00:16:20,320 --> 00:16:25,279
queries and the whole idea was to

438
00:16:22,959 --> 00:16:29,119
eliminate the need

439
00:16:25,279 --> 00:16:30,639
okay um so the solution is we're going

440
00:16:29,120 --> 00:16:32,000
to take these things and we're going to

441
00:16:30,639 --> 00:16:35,360
delegate all the walk

442
00:16:32,000 --> 00:16:37,199
to the pool okay but again in

443
00:16:35,360 --> 00:16:39,279
such a way that we can trust what he's

444
00:16:37,199 --> 00:16:42,319
doing so one thing we cannot do

445
00:16:39,279 --> 00:16:43,439
we cannot let the proverb you know claim

446
00:16:42,320 --> 00:16:46,880
that he sampled

447
00:16:43,440 --> 00:16:50,560
squelden elements okay he's not gonna

448
00:16:46,880 --> 00:16:51,920
do that honestly so instead what we're

449
00:16:50,560 --> 00:16:53,439
going to do is again we're going to

450
00:16:51,920 --> 00:16:56,000
sample a hash function h

451
00:16:53,440 --> 00:16:57,040
and again assume this is truly random

452
00:16:56,000 --> 00:16:59,279
and this f

453
00:16:57,040 --> 00:17:01,680
function h is going to represent a huge

454
00:16:59,279 --> 00:17:03,439
amount amount of randomness

455
00:17:01,680 --> 00:17:05,198
okay that is going to define how we

456
00:17:03,440 --> 00:17:06,240
sample the elements so the prover

457
00:17:05,199 --> 00:17:08,000
doesn't have

458
00:17:06,240 --> 00:17:09,280
he cannot sample randomness himself he

459
00:17:08,000 --> 00:17:12,240
has to use h

460
00:17:09,280 --> 00:17:13,439
so what do i mean h is going to be from

461
00:17:12,240 --> 00:17:16,559
square root n

462
00:17:13,439 --> 00:17:17,120
2 0 1 to the l where l is the number of

463
00:17:16,559 --> 00:17:19,839
bits

464
00:17:17,119 --> 00:17:21,198
needed for this algorithm d to sample an

465
00:17:19,839 --> 00:17:24,159
element

466
00:17:21,199 --> 00:17:24,959
so h h of i just defines enough

467
00:17:24,160 --> 00:17:28,319
randomness

468
00:17:24,959 --> 00:17:31,360
to turn d that's all then what is the

469
00:17:28,319 --> 00:17:33,678
prover gonna do he gets h

470
00:17:31,360 --> 00:17:35,199
he is going to compute v i which is just

471
00:17:33,679 --> 00:17:37,600
running this algorithm d

472
00:17:35,200 --> 00:17:39,679
that samples the uniform element using

473
00:17:37,600 --> 00:17:43,280
randomness h of i

474
00:17:39,679 --> 00:17:46,320
so just h of i defines the randomness

475
00:17:43,280 --> 00:17:49,360
for the i sample and then we get the

476
00:17:46,320 --> 00:17:50,639
element vi all this work is going to do

477
00:17:49,360 --> 00:17:52,479
and we're going to be performed by the

478
00:17:50,640 --> 00:17:54,000
provo at the end it's going to send us

479
00:17:52,480 --> 00:17:57,120
two indexes

480
00:17:54,000 --> 00:18:00,160
i and j so the minimum indexes such that

481
00:17:57,120 --> 00:18:02,080
vi equals vj

482
00:18:00,160 --> 00:18:03,600
what does the verifier have to do he

483
00:18:02,080 --> 00:18:05,918
only gets i and j

484
00:18:03,600 --> 00:18:06,799
he's gonna check he gonna compute the

485
00:18:05,919 --> 00:18:09,200
randomness a

486
00:18:06,799 --> 00:18:10,480
h i and h j so now he has the randomness

487
00:18:09,200 --> 00:18:13,600
he's gonna

488
00:18:10,480 --> 00:18:14,720
run this algorithm d okay using this

489
00:18:13,600 --> 00:18:16,159
randomness

490
00:18:14,720 --> 00:18:17,760
and he's going to check that indeed they

491
00:18:16,160 --> 00:18:19,280
collide and of course that i is

492
00:18:17,760 --> 00:18:22,720
different than j and i and j are

493
00:18:19,280 --> 00:18:22,720
between 1 and square root 10.

494
00:18:22,880 --> 00:18:29,520
so if the set was indeed of size n

495
00:18:26,720 --> 00:18:31,600
then such inj are going to exist and if

496
00:18:29,520 --> 00:18:34,000
the set was larger

497
00:18:31,600 --> 00:18:35,360
such an i and j are not going to exist

498
00:18:34,000 --> 00:18:36,640
and again

499
00:18:35,360 --> 00:18:40,559
this only happens with similar

500
00:18:36,640 --> 00:18:40,559
probabilities we'll need to amplify this

501
00:18:40,880 --> 00:18:45,280
but the main thing here is that the

502
00:18:43,360 --> 00:18:47,760
query complexity is now one of the

503
00:18:45,280 --> 00:18:47,760
epsilon

504
00:18:48,000 --> 00:18:51,039
okay but this really assumed that h is a

505
00:18:50,160 --> 00:18:53,520
random

506
00:18:51,039 --> 00:18:54,879
okay we needed h to provide us with l

507
00:18:53,520 --> 00:18:58,080
random bits

508
00:18:54,880 --> 00:18:59,600
and and it had to be very random and

509
00:18:58,080 --> 00:19:02,399
we're going to see how to

510
00:18:59,600 --> 00:19:04,320
instantiate this but the main idea is

511
00:19:02,400 --> 00:19:07,360
here

512
00:19:04,320 --> 00:19:08,720
so before i talk on h i just say how i

513
00:19:07,360 --> 00:19:12,479
go from sets

514
00:19:08,720 --> 00:19:16,160
back to social graphs so

515
00:19:12,480 --> 00:19:18,480
um the set s okay is of course going to

516
00:19:16,160 --> 00:19:21,679
be just the set of nodes in the graph

517
00:19:18,480 --> 00:19:22,960
okay that's fine and that's what

518
00:19:21,679 --> 00:19:24,480
we want to estimate the size of the

519
00:19:22,960 --> 00:19:24,880
graph so just the set is the number of

520
00:19:24,480 --> 00:19:26,720
nodes

521
00:19:24,880 --> 00:19:28,160
then all the nodes in the graph

522
00:19:26,720 --> 00:19:30,400
membership queries

523
00:19:28,160 --> 00:19:32,080
well we just assume we have membership

524
00:19:30,400 --> 00:19:34,400
guides so this is directly via the

525
00:19:32,080 --> 00:19:36,639
public interface of the network

526
00:19:34,400 --> 00:19:38,480
sampling queries this we did not assume

527
00:19:36,640 --> 00:19:41,520
we have

528
00:19:38,480 --> 00:19:44,640
okay however we can implement this thing

529
00:19:41,520 --> 00:19:48,559
so we can implement this um algorithm d

530
00:19:44,640 --> 00:19:52,160
that samples uniform elements in the set

531
00:19:48,559 --> 00:19:54,240
by random works okay so performing

532
00:19:52,160 --> 00:19:56,880
random works in the graph is going to

533
00:19:54,240 --> 00:20:00,000
give us random

534
00:19:56,880 --> 00:20:02,640
nodes in the graph so

535
00:20:00,000 --> 00:20:04,159
how is this performed so we start with

536
00:20:02,640 --> 00:20:07,039
an arbitrary vertex

537
00:20:04,159 --> 00:20:09,280
okay so we have some vertex we're gonna

538
00:20:07,039 --> 00:20:12,400
choose a uniformly random neighbor v

539
00:20:09,280 --> 00:20:14,000
so we run the neighbor over here

540
00:20:12,400 --> 00:20:15,440
we get the list of neighbors choose one

541
00:20:14,000 --> 00:20:18,320
at random

542
00:20:15,440 --> 00:20:20,559
and so this is v we're gonna visit v and

543
00:20:18,320 --> 00:20:22,158
then repeat the whole process from v

544
00:20:20,559 --> 00:20:24,080
so this is how we're going to do a

545
00:20:22,159 --> 00:20:26,960
random work in the graph

546
00:20:24,080 --> 00:20:28,158
this process converges to a stationary

547
00:20:26,960 --> 00:20:31,360
distribution

548
00:20:28,159 --> 00:20:32,400
well the probability um that after our

549
00:20:31,360 --> 00:20:35,760
steps i end up

550
00:20:32,400 --> 00:20:36,880
some specific node v is going to be the

551
00:20:35,760 --> 00:20:38,879
degree of v

552
00:20:36,880 --> 00:20:39,919
over n times delta well again delta is

553
00:20:38,880 --> 00:20:43,600
the average degree

554
00:20:39,919 --> 00:20:44,000
in the graph and so what is the mixing

555
00:20:43,600 --> 00:20:46,639
time

556
00:20:44,000 --> 00:20:48,480
so graph g has a mixing time tau if

557
00:20:46,640 --> 00:20:50,559
after t iterations

558
00:20:48,480 --> 00:20:51,840
you are close in let's say statistical

559
00:20:50,559 --> 00:20:54,879
distance

560
00:20:51,840 --> 00:20:55,760
to the stationary distribution so after

561
00:20:54,880 --> 00:20:58,000
two

562
00:20:55,760 --> 00:20:59,039
tau steps i'm like let's say some

563
00:20:58,000 --> 00:21:02,320
constant let's say

564
00:20:59,039 --> 00:21:03,840
one over four distance from this

565
00:21:02,320 --> 00:21:07,678
stationary distribution

566
00:21:03,840 --> 00:21:09,918
the constants do not really matter

567
00:21:07,679 --> 00:21:11,679
you can do a few more additional steps

568
00:21:09,919 --> 00:21:14,880
and this goes exponentially close to the

569
00:21:11,679 --> 00:21:14,880
stationary distribution

570
00:21:15,120 --> 00:21:18,799
finally we want to get the uniform

571
00:21:16,720 --> 00:21:21,919
element well here we get an

572
00:21:18,799 --> 00:21:23,600
an element with probability that it's

573
00:21:21,919 --> 00:21:25,360
proportional to its degree

574
00:21:23,600 --> 00:21:27,360
so what we're going to do is rejection

575
00:21:25,360 --> 00:21:29,520
sampling so you get an element if it

576
00:21:27,360 --> 00:21:31,760
has higher degree we're going to reject

577
00:21:29,520 --> 00:21:35,039
this element with higher probability

578
00:21:31,760 --> 00:21:37,520
and just start everything um

579
00:21:35,039 --> 00:21:39,200
from scratch until you don't predict

580
00:21:37,520 --> 00:21:41,120
this element

581
00:21:39,200 --> 00:21:43,200
this says that you're gonna get a

582
00:21:41,120 --> 00:21:45,039
uniform element at the end

583
00:21:43,200 --> 00:21:46,320
and the number you're going to do this

584
00:21:45,039 --> 00:21:48,240
random walk of

585
00:21:46,320 --> 00:21:50,080
length tau but you're going to do it

586
00:21:48,240 --> 00:21:52,799
delta times

587
00:21:50,080 --> 00:21:53,760
so after tau times delta steps we're

588
00:21:52,799 --> 00:21:56,840
actually

589
00:21:53,760 --> 00:21:59,840
we can implement this uniform sampling

590
00:21:56,840 --> 00:21:59,840
algorithm

591
00:22:00,320 --> 00:22:03,840
finally this takes me back to the hash

592
00:22:02,799 --> 00:22:05,520
function

593
00:22:03,840 --> 00:22:07,439
so now we want to implement this hash

594
00:22:05,520 --> 00:22:09,760
function and

595
00:22:07,440 --> 00:22:11,520
uh we assume this is totally random

596
00:22:09,760 --> 00:22:12,480
before you implement this isn't just

597
00:22:11,520 --> 00:22:14,080
saying

598
00:22:12,480 --> 00:22:16,320
if any way you're going to do the

599
00:22:14,080 --> 00:22:19,120
fiatumir transformation

600
00:22:16,320 --> 00:22:20,158
so anyway you rely on on the random

601
00:22:19,120 --> 00:22:21,918
oracle model

602
00:22:20,159 --> 00:22:24,080
and some heuristic to implement this

603
00:22:21,919 --> 00:22:26,080
such as sha-256

604
00:22:24,080 --> 00:22:27,520
then just use this same hash function

605
00:22:26,080 --> 00:22:28,320
also for the hash function for the

606
00:22:27,520 --> 00:22:31,440
protocol

607
00:22:28,320 --> 00:22:32,960
okay this will be very efficient and and

608
00:22:31,440 --> 00:22:35,760
work well

609
00:22:32,960 --> 00:22:37,280
um however if you do want a theoretical

610
00:22:35,760 --> 00:22:39,360
result showing that what we have is

611
00:22:37,280 --> 00:22:42,639
actually an interactive proof

612
00:22:39,360 --> 00:22:44,799
um then we're gonna show that we can

613
00:22:42,640 --> 00:22:45,520
actually rely on polylogwise independent

614
00:22:44,799 --> 00:22:48,639
hashtag

615
00:22:45,520 --> 00:22:49,280
hash families and the proof is is the

616
00:22:48,640 --> 00:22:52,240
following

617
00:22:49,280 --> 00:22:52,639
so what we observe is that the verifier

618
00:22:52,240 --> 00:22:55,600
and

619
00:22:52,640 --> 00:22:56,640
the work of the proverb so both together

620
00:22:55,600 --> 00:23:00,399
can be described

621
00:22:56,640 --> 00:23:01,840
by an ac0 circuit so the verifier is

622
00:23:00,400 --> 00:23:05,840
actually easy to see

623
00:23:01,840 --> 00:23:07,918
there and that it can be done in ac 0

624
00:23:05,840 --> 00:23:08,879
and the prover takes a bit a bit more

625
00:23:07,919 --> 00:23:11,360
work

626
00:23:08,880 --> 00:23:12,640
so in particular one of the heavy steps

627
00:23:11,360 --> 00:23:16,000
always on the walks

628
00:23:12,640 --> 00:23:17,520
which are not very shallow however

629
00:23:16,000 --> 00:23:18,720
because this is a circuit what you can

630
00:23:17,520 --> 00:23:20,480
actually do

631
00:23:18,720 --> 00:23:22,080
is you can pre-compute all these on the

632
00:23:20,480 --> 00:23:23,760
blocks and then you can

633
00:23:22,080 --> 00:23:25,439
walk them very quickly okay because

634
00:23:23,760 --> 00:23:28,640
they're pre-computed

635
00:23:25,440 --> 00:23:30,880
the circuit is going to be much larger

636
00:23:28,640 --> 00:23:32,480
okay actually exponentially in in the

637
00:23:30,880 --> 00:23:35,760
mixing time tau

638
00:23:32,480 --> 00:23:37,520
however we only rely logarithmic on the

639
00:23:35,760 --> 00:23:39,440
circuit side so that this is going to be

640
00:23:37,520 --> 00:23:42,400
fine

641
00:23:39,440 --> 00:23:43,919
then we're going to use a theorem by

642
00:23:42,400 --> 00:23:46,720
bravoman that says that

643
00:23:43,919 --> 00:23:49,120
polylogwise independence fuse ac0

644
00:23:46,720 --> 00:23:51,200
circuits

645
00:23:49,120 --> 00:23:54,080
these two together say that you can

646
00:23:51,200 --> 00:23:56,880
actually replace the hash function

647
00:23:54,080 --> 00:23:58,320
with a polylog-wise-independent hash

648
00:23:56,880 --> 00:24:01,279
family

649
00:23:58,320 --> 00:24:03,200
and this probability of the verifier

650
00:24:01,279 --> 00:24:04,159
accepting or rejecting the probability

651
00:24:03,200 --> 00:24:06,320
of the

652
00:24:04,159 --> 00:24:08,320
the the probability that there's going

653
00:24:06,320 --> 00:24:09,120
to exist a proof that the verifier

654
00:24:08,320 --> 00:24:11,439
accept

655
00:24:09,120 --> 00:24:12,559
is going to be more or less the same up

656
00:24:11,440 --> 00:24:14,640
to uh

657
00:24:12,559 --> 00:24:15,600
how much uh the distinguished

658
00:24:14,640 --> 00:24:18,320
probability of the

659
00:24:15,600 --> 00:24:20,240
ac 0 circuit so you're going to lose a

660
00:24:18,320 --> 00:24:21,918
small small factor in the completeness

661
00:24:20,240 --> 00:24:23,919
and soundness but again you can

662
00:24:21,919 --> 00:24:27,039
repeat the protocol to get the

663
00:24:23,919 --> 00:24:30,880
completeness roundness that you want

664
00:24:27,039 --> 00:24:32,960
um okay just to some summarizing

665
00:24:30,880 --> 00:24:34,880
some open problems we introduced a new

666
00:24:32,960 --> 00:24:36,640
notion of interactive posts for social

667
00:24:34,880 --> 00:24:39,120
graphs

668
00:24:36,640 --> 00:24:39,760
we provided protocols for monitoring the

669
00:24:39,120 --> 00:24:43,199
health

670
00:24:39,760 --> 00:24:43,200
social graphs in this model

671
00:24:43,360 --> 00:24:47,199
one open problem is to eliminate this

672
00:24:45,360 --> 00:24:48,399
dependency on delta i think the

673
00:24:47,200 --> 00:24:50,960
dependency on tau

674
00:24:48,400 --> 00:24:52,799
is inherent but the dependency on delta

675
00:24:50,960 --> 00:24:54,720
uh the average derivative i'm not sure

676
00:24:52,799 --> 00:24:57,679
that it's inherent

677
00:24:54,720 --> 00:24:59,440
um can you use our protocol to monitor

678
00:24:57,679 --> 00:25:02,480
other more important

679
00:24:59,440 --> 00:25:04,559
health measures and finally can we make

680
00:25:02,480 --> 00:25:07,200
this part of a standout

681
00:25:04,559 --> 00:25:08,799
a part of how we regulate a social

682
00:25:07,200 --> 00:25:12,559
companies

683
00:25:08,799 --> 00:25:12,559
thank you very much

