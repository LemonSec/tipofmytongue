1
00:00:00,719 --> 00:00:03,119
hi everyone uh today i'm going to talk

2
00:00:02,639 --> 00:00:04,640
about

3
00:00:03,120 --> 00:00:07,359
our world where we construct new

4
00:00:04,640 --> 00:00:08,800
non-interactive zero knowledge uh for np

5
00:00:07,359 --> 00:00:10,800
based on tribal hash and the lpn

6
00:00:08,800 --> 00:00:12,240
assumption maybe the bottom line and

7
00:00:10,800 --> 00:00:14,719
consequence of such a result is the

8
00:00:12,240 --> 00:00:16,160
first music for np from lpn and edh

9
00:00:14,719 --> 00:00:17,439
which are both standard assumptions that

10
00:00:16,160 --> 00:00:18,480
were not known to imply in physics

11
00:00:17,440 --> 00:00:19,840
before

12
00:00:18,480 --> 00:00:22,160
this is a joint work with sveka and

13
00:00:19,840 --> 00:00:24,560
venkata and let's begin

14
00:00:22,160 --> 00:00:25,519
so i'm going to start with uh defining

15
00:00:24,560 --> 00:00:27,198
an easy x

16
00:00:25,519 --> 00:00:28,560
so an intellect is zero knowledge uh for

17
00:00:27,199 --> 00:00:30,960
elect for an np language

18
00:00:28,560 --> 00:00:32,479
is simply a proof system uh where both

19
00:00:30,960 --> 00:00:34,480
approver and the verifier have an access

20
00:00:32,479 --> 00:00:35,919
to an honestly generated crs

21
00:00:34,480 --> 00:00:37,519
and the protocol is not interactive so

22
00:00:35,920 --> 00:00:38,800
it consists of a single

23
00:00:37,520 --> 00:00:41,280
message that the property sends to the

24
00:00:38,800 --> 00:00:42,559
verifier and we ask that the verifier is

25
00:00:41,280 --> 00:00:44,160
efficient of course but we also want

26
00:00:42,559 --> 00:00:44,640
that approval is efficient given an np

27
00:00:44,160 --> 00:00:47,360
witness

28
00:00:44,640 --> 00:00:48,160
w for the statement um and we consider

29
00:00:47,360 --> 00:00:49,280
the standard

30
00:00:48,160 --> 00:00:51,919
completeness soundness and zero

31
00:00:49,280 --> 00:00:53,280
knowledge properties so while physics

32
00:00:51,920 --> 00:00:54,719
are interesting by themselves but they

33
00:00:53,280 --> 00:00:55,760
also have lots of nice applications in

34
00:00:54,719 --> 00:00:58,640
crypto including

35
00:00:55,760 --> 00:00:59,839
cca security signatures and new

36
00:00:58,640 --> 00:01:01,840
applications in the regime of

37
00:00:59,840 --> 00:01:02,960
cryptocurrencies

38
00:01:01,840 --> 00:01:04,799
so since the ultimate goal is

39
00:01:02,960 --> 00:01:06,400
constructing physics from standard

40
00:01:04,799 --> 00:01:07,439
assumptions let's quickly go through the

41
00:01:06,400 --> 00:01:10,320
known approaches

42
00:01:07,439 --> 00:01:11,679
from the literature that do that so the

43
00:01:10,320 --> 00:01:12,559
textbook approach is called the hidden

44
00:01:11,680 --> 00:01:15,040
bits model

45
00:01:12,560 --> 00:01:16,720
and it can be instantiated uh using

46
00:01:15,040 --> 00:01:19,840
either chapter permutations

47
00:01:16,720 --> 00:01:20,720
or vrs or vbrgs but this approach is a

48
00:01:19,840 --> 00:01:22,720
bit limited

49
00:01:20,720 --> 00:01:24,240
since the only known constructions of

50
00:01:22,720 --> 00:01:25,679
such building blocks

51
00:01:24,240 --> 00:01:27,199
are either based on factoring related

52
00:01:25,680 --> 00:01:29,520
assumptions or assumptions over by

53
00:01:27,200 --> 00:01:31,439
linear groups

54
00:01:29,520 --> 00:01:32,798
um another way to get this x was

55
00:01:31,439 --> 00:01:33,600
discovered by growth of structure and

56
00:01:32,799 --> 00:01:35,200
sahai

57
00:01:33,600 --> 00:01:37,439
and it works in the setting where we

58
00:01:35,200 --> 00:01:39,040
have a bilinear group

59
00:01:37,439 --> 00:01:41,520
and we assume some different style

60
00:01:39,040 --> 00:01:43,280
assumptions over it

61
00:01:41,520 --> 00:01:45,039
but this approach is very non-generic it

62
00:01:43,280 --> 00:01:48,799
uses properties of

63
00:01:45,040 --> 00:01:50,159
such groups so it doesn't seem that

64
00:01:48,799 --> 00:01:52,799
physics from new standards assumptions

65
00:01:50,159 --> 00:01:54,560
will come from this direction

66
00:01:52,799 --> 00:01:56,320
the last approach i'm going to discuss

67
00:01:54,560 --> 00:01:58,079
is an approach where we start with

68
00:01:56,320 --> 00:01:59,839
an interactive uh zero knowledge

69
00:01:58,079 --> 00:02:01,360
protocol and we use the fiat

70
00:01:59,840 --> 00:02:03,680
html transform to turn it into a

71
00:02:01,360 --> 00:02:05,200
non-interactive protocol and in order to

72
00:02:03,680 --> 00:02:06,560
instantiate the vhma transform and

73
00:02:05,200 --> 00:02:08,239
improve present manner we use a

74
00:02:06,560 --> 00:02:09,119
primitive or correlation interactive

75
00:02:08,239 --> 00:02:11,520
hash

76
00:02:09,119 --> 00:02:12,879
and a long and nice line of work has

77
00:02:11,520 --> 00:02:14,319
essentially led to a construction

78
00:02:12,879 --> 00:02:17,040
population tactical hash

79
00:02:14,319 --> 00:02:17,760
under the lwd assumption to so to

80
00:02:17,040 --> 00:02:20,160
summarize

81
00:02:17,760 --> 00:02:21,679
things up we have musics under factoring

82
00:02:20,160 --> 00:02:24,940
related assumptions or

83
00:02:21,680 --> 00:02:26,000
assumptions over by linear groups or lwe

84
00:02:24,940 --> 00:02:28,079
[Music]

85
00:02:26,000 --> 00:02:29,120
in our paper we extend the set of

86
00:02:28,080 --> 00:02:32,000
standard assumptions

87
00:02:29,120 --> 00:02:33,280
from which we have nsx and we follow up

88
00:02:32,000 --> 00:02:35,680
on this last approach

89
00:02:33,280 --> 00:02:37,280
and instantiated assuming a table hatch

90
00:02:35,680 --> 00:02:38,640
which in particular can be constructed

91
00:02:37,280 --> 00:02:40,480
from vdh

92
00:02:38,640 --> 00:02:42,879
and jointly assuming there'll be an

93
00:02:40,480 --> 00:02:42,879
assumption

94
00:02:42,959 --> 00:02:47,120
so how do we really get music from phm

95
00:02:45,280 --> 00:02:48,879
here so we start with a base protocol

96
00:02:47,120 --> 00:02:50,319
which consists of three messages

97
00:02:48,879 --> 00:02:52,000
and i will assume it's a public one

98
00:02:50,319 --> 00:02:53,440
protocol so in the beginning that google

99
00:02:52,000 --> 00:02:56,160
sends his first message a and then the

100
00:02:53,440 --> 00:02:57,519
verify replies by a random challenge e

101
00:02:56,160 --> 00:02:59,200
and then the prover sends his third

102
00:02:57,519 --> 00:03:00,800
message and the verifier either accepts

103
00:02:59,200 --> 00:03:02,720
or rejects

104
00:03:00,800 --> 00:03:05,040
so the feature mutants form using a hash

105
00:03:02,720 --> 00:03:07,840
function edge it looks as follows

106
00:03:05,040 --> 00:03:09,120
so we add that is a randomly sampled

107
00:03:07,840 --> 00:03:10,640
hash key to the crs

108
00:03:09,120 --> 00:03:12,879
and now the proofer computes his first

109
00:03:10,640 --> 00:03:14,720
message a as before but in order to

110
00:03:12,879 --> 00:03:16,879
simulate the verified challenge he uses

111
00:03:14,720 --> 00:03:19,120
the hash function so now the verifies

112
00:03:16,879 --> 00:03:21,599
challenge is computed as the hash of a

113
00:03:19,120 --> 00:03:22,159
under the key which is found in the crs

114
00:03:21,599 --> 00:03:24,159
and once

115
00:03:22,159 --> 00:03:26,000
he completed the first message a and the

116
00:03:24,159 --> 00:03:26,879
challenge e he can continue and compute

117
00:03:26,000 --> 00:03:28,480
the third message

118
00:03:26,879 --> 00:03:30,319
z and then he sends the entire

119
00:03:28,480 --> 00:03:32,879
transcript to the verifier

120
00:03:30,319 --> 00:03:33,679
at once so it's easy to see that this

121
00:03:32,879 --> 00:03:35,599
protocol is

122
00:03:33,680 --> 00:03:37,040
interactive and also that if we start

123
00:03:35,599 --> 00:03:38,640
with the public protocol

124
00:03:37,040 --> 00:03:40,319
then the non-interactive protocol is

125
00:03:38,640 --> 00:03:41,839
also complete

126
00:03:40,319 --> 00:03:43,518
we also know that if the base protocol

127
00:03:41,840 --> 00:03:45,200
is honest verify zero knowledge

128
00:03:43,519 --> 00:03:47,200
then the fiat may transform preserves

129
00:03:45,200 --> 00:03:48,958
zero knowledge

130
00:03:47,200 --> 00:03:50,480
so the only missing piece in the puzzle

131
00:03:48,959 --> 00:03:51,599
here is sound so it's not clear that

132
00:03:50,480 --> 00:03:53,280
even if the

133
00:03:51,599 --> 00:03:55,359
base protocol is sound that an

134
00:03:53,280 --> 00:03:56,959
uninteractive protocol is also sound

135
00:03:55,360 --> 00:03:58,400
and the reason is that the prover has

136
00:03:56,959 --> 00:04:01,439
some control over

137
00:03:58,400 --> 00:04:04,080
the choice of the verifiers challenge

138
00:04:01,439 --> 00:04:05,120
and in particular he can choose a first

139
00:04:04,080 --> 00:04:07,599
message a

140
00:04:05,120 --> 00:04:09,280
such that the verifies challenge h of a

141
00:04:07,599 --> 00:04:11,760
falls inside the soundness error of the

142
00:04:09,280 --> 00:04:11,760
protocol

143
00:04:12,080 --> 00:04:15,360
this leads us to consider a specific

144
00:04:14,080 --> 00:04:16,880
kind of uh

145
00:04:15,360 --> 00:04:19,120
based protocols which we call signal

146
00:04:16,880 --> 00:04:20,880
protocols so sigma protocols are three

147
00:04:19,120 --> 00:04:22,800
message public coin honest

148
00:04:20,880 --> 00:04:24,400
honest verified zero knowledge protocols

149
00:04:22,800 --> 00:04:26,080
which also enjoy this unique bad

150
00:04:24,400 --> 00:04:27,919
challenge property

151
00:04:26,080 --> 00:04:30,000
and this property basically says that

152
00:04:27,919 --> 00:04:33,039
for any uh first message

153
00:04:30,000 --> 00:04:36,320
a there exists at most one value of

154
00:04:33,040 --> 00:04:37,440
a e that may possibly allow a cheat

155
00:04:36,320 --> 00:04:39,440
improver to cheat

156
00:04:37,440 --> 00:04:42,400
and we call such a value of e the bad

157
00:04:39,440 --> 00:04:45,280
challenge uh e so

158
00:04:42,400 --> 00:04:46,479
uh more formally fixing a crs and x

159
00:04:45,280 --> 00:04:48,400
which is not in the language

160
00:04:46,479 --> 00:04:49,758
and the first message a there exists at

161
00:04:48,400 --> 00:04:52,719
most one bad challenge

162
00:04:49,759 --> 00:04:54,479
e for which uh there exists a transcript

163
00:04:52,720 --> 00:04:57,840
a e instead

164
00:04:54,479 --> 00:04:57,840
that the verifier accepts

165
00:04:58,160 --> 00:05:01,199
so uh this property allows us to define

166
00:04:59,919 --> 00:05:02,799
the bad challenge function which is

167
00:05:01,199 --> 00:05:05,280
defined using series and x

168
00:05:02,800 --> 00:05:06,160
and gets as an input first message a and

169
00:05:05,280 --> 00:05:09,119
outputs

170
00:05:06,160 --> 00:05:10,560
the corresponding bad challenge e and

171
00:05:09,120 --> 00:05:12,479
now we can claim soundless of the

172
00:05:10,560 --> 00:05:15,199
non-interactive protocol as follows

173
00:05:12,479 --> 00:05:16,880
so if we uh can say that it's hard for

174
00:05:15,199 --> 00:05:17,840
the cheat improver to find a first

175
00:05:16,880 --> 00:05:20,800
message a

176
00:05:17,840 --> 00:05:22,400
such that h of a is the bad challenge

177
00:05:20,800 --> 00:05:24,000
then it's computationally hard for a

178
00:05:22,400 --> 00:05:25,679
prover to cheat

179
00:05:24,000 --> 00:05:27,600
because the only way he can cheat is by

180
00:05:25,680 --> 00:05:28,240
choosing the first message such that h

181
00:05:27,600 --> 00:05:31,280
of a

182
00:05:28,240 --> 00:05:33,440
is that bad challenge corresponding to a

183
00:05:31,280 --> 00:05:35,119
and a hash function that satisfies this

184
00:05:33,440 --> 00:05:37,039
hardness requirement is called

185
00:05:35,120 --> 00:05:40,080
a correlation interactable hash for the

186
00:05:37,039 --> 00:05:40,080
bad challenge function f

187
00:05:40,720 --> 00:05:43,840
okay so now we know how to construct an

188
00:05:42,320 --> 00:05:45,759
esx using the mirror

189
00:05:43,840 --> 00:05:47,280
and all we need is two ingredients so

190
00:05:45,759 --> 00:05:48,080
first of all we need a sigma protocol to

191
00:05:47,280 --> 00:05:50,559
start with

192
00:05:48,080 --> 00:05:52,400
and then we need a hash function that is

193
00:05:50,560 --> 00:05:53,840
correlation interactable for the

194
00:05:52,400 --> 00:05:57,120
class of bad challenge functions

195
00:05:53,840 --> 00:05:59,359
corresponding to the sigma protocol

196
00:05:57,120 --> 00:06:00,560
so now we try to instantiate this recipe

197
00:05:59,360 --> 00:06:01,840
and the guiding rule

198
00:06:00,560 --> 00:06:04,160
that we should keep in mind is the

199
00:06:01,840 --> 00:06:04,960
following the simpler the bad challenge

200
00:06:04,160 --> 00:06:08,000
function

201
00:06:04,960 --> 00:06:10,080
is then the easier is the task of

202
00:06:08,000 --> 00:06:12,720
constructing relation interactability

203
00:06:10,080 --> 00:06:13,120
for such a class of functions so our

204
00:06:12,720 --> 00:06:15,360
goal

205
00:06:13,120 --> 00:06:16,880
is kind of dual here so first of all we

206
00:06:15,360 --> 00:06:18,400
need uh to describe the

207
00:06:16,880 --> 00:06:20,080
bad challenge function for some sigma

208
00:06:18,400 --> 00:06:21,440
protocol as simple as possible

209
00:06:20,080 --> 00:06:23,199
and on the other hand we need to

210
00:06:21,440 --> 00:06:26,160
construct correlation tractability

211
00:06:23,199 --> 00:06:27,600
uh for from standard assumptions so now

212
00:06:26,160 --> 00:06:29,280
we can start asking questions

213
00:06:27,600 --> 00:06:31,600
for example it's not clear how simple

214
00:06:29,280 --> 00:06:33,359
can the bad challenge function be

215
00:06:31,600 --> 00:06:35,600
and it's not even clear whether it's

216
00:06:33,360 --> 00:06:38,639
efficiently computable

217
00:06:35,600 --> 00:06:39,600
on the other hand we can ask about

218
00:06:38,639 --> 00:06:40,400
instructions for correlation

219
00:06:39,600 --> 00:06:43,440
tractability

220
00:06:40,400 --> 00:06:43,440
under standard assumptions

221
00:06:43,840 --> 00:06:48,638
so the the first work that tries to

222
00:06:47,199 --> 00:06:50,400
prove the science of html under

223
00:06:48,639 --> 00:06:51,599
cryptographic assumptions is this worked

224
00:06:50,400 --> 00:06:52,960
by connected r

225
00:06:51,599 --> 00:06:55,360
where they observe that the batch range

226
00:06:52,960 --> 00:06:58,159
function for a sigma protocol

227
00:06:55,360 --> 00:06:59,440
for np is efficiently recognizable so if

228
00:06:58,160 --> 00:07:00,880
i give you that challenge you can

229
00:06:59,440 --> 00:07:03,120
efficiently say that this is a bad

230
00:07:00,880 --> 00:07:05,120
challenge and consequently

231
00:07:03,120 --> 00:07:06,800
the regulation capability task becomes

232
00:07:05,120 --> 00:07:08,720
to construct ci for all efficiently

233
00:07:06,800 --> 00:07:10,800
recognizable functions

234
00:07:08,720 --> 00:07:12,720
and they are able to do that under

235
00:07:10,800 --> 00:07:13,280
sub-exponential io and some other strong

236
00:07:12,720 --> 00:07:15,440
notion of

237
00:07:13,280 --> 00:07:16,638
obfuscation and these assumptions are

238
00:07:15,440 --> 00:07:19,759
clearly uh

239
00:07:16,639 --> 00:07:20,720
not standard there have been many

240
00:07:19,759 --> 00:07:22,560
follow-up works

241
00:07:20,720 --> 00:07:23,919
um each trying to construct

242
00:07:22,560 --> 00:07:26,479
relationshipability for

243
00:07:23,919 --> 00:07:28,000
um a different uh class of functions

244
00:07:26,479 --> 00:07:30,159
that is sufficient for netflix

245
00:07:28,000 --> 00:07:31,599
but again they all do that under uh

246
00:07:30,160 --> 00:07:34,880
exotic assumptions so

247
00:07:31,599 --> 00:07:35,759
um for example uh some assumed sub

248
00:07:34,880 --> 00:07:39,599
financial i o

249
00:07:35,759 --> 00:07:43,360
or fully exponential akdm security

250
00:07:39,599 --> 00:07:46,400
uh but very recently um last crypto um

251
00:07:43,360 --> 00:07:47,680
or even a bit before this line of work

252
00:07:46,400 --> 00:07:50,318
led to constructions

253
00:07:47,680 --> 00:07:52,080
uh uh understandable assumptions and in

254
00:07:50,319 --> 00:07:53,120
particular this last work by picard and

255
00:07:52,080 --> 00:07:54,479
srihan

256
00:07:53,120 --> 00:07:55,919
they use the observation that the bad

257
00:07:54,479 --> 00:07:56,960
challenge function is efficiently

258
00:07:55,919 --> 00:08:00,240
computable

259
00:07:56,960 --> 00:08:01,198
for some sigma protocol and therefore

260
00:08:00,240 --> 00:08:02,560
all they need now is collection

261
00:08:01,199 --> 00:08:04,080
capability for all efficient computer

262
00:08:02,560 --> 00:08:06,720
build functions and they can get that

263
00:08:04,080 --> 00:08:08,240
under lwe

264
00:08:06,720 --> 00:08:11,360
so let's say we call our goal our goal

265
00:08:08,240 --> 00:08:12,560
is to extend this paradigm

266
00:08:11,360 --> 00:08:14,560
and basically on other standard

267
00:08:12,560 --> 00:08:15,759
assumptions and there seems to be a

268
00:08:14,560 --> 00:08:18,479
barrier here

269
00:08:15,759 --> 00:08:20,080
so notice that these last two works they

270
00:08:18,479 --> 00:08:21,280
consider the complexity of computing the

271
00:08:20,080 --> 00:08:22,719
bad challenge function

272
00:08:21,280 --> 00:08:24,840
and they say that the batch range

273
00:08:22,720 --> 00:08:26,240
function is an arbitrary polynomial time

274
00:08:24,840 --> 00:08:26,878
computation

275
00:08:26,240 --> 00:08:28,319
and therefore we need

276
00:08:26,879 --> 00:08:29,360
relationshipability for any polynomial

277
00:08:28,319 --> 00:08:32,479
time computation

278
00:08:29,360 --> 00:08:34,399
and it seems that we need a homomorphism

279
00:08:32,479 --> 00:08:36,800
for any polynomial time computation

280
00:08:34,399 --> 00:08:38,399
in order to do that or in other words we

281
00:08:36,799 --> 00:08:41,598
need for homomorphism and we

282
00:08:38,399 --> 00:08:44,640
know that we can get that only under lwe

283
00:08:41,599 --> 00:08:46,080
um as far as we know of course

284
00:08:44,640 --> 00:08:47,680
what we do differently is we consider

285
00:08:46,080 --> 00:08:48,800
the complexity of approximating the bad

286
00:08:47,680 --> 00:08:51,359
challenge

287
00:08:48,800 --> 00:08:52,399
and using such an approach we can show

288
00:08:51,360 --> 00:08:54,160
that it

289
00:08:52,399 --> 00:08:56,160
is sufficient that we use a partial

290
00:08:54,160 --> 00:08:57,760
homomorphism and in particular we can

291
00:08:56,160 --> 00:08:59,920
use one more prism that we can get from

292
00:08:57,760 --> 00:09:00,240
other standard assumptions such as ddh

293
00:08:59,920 --> 00:09:02,800
or

294
00:09:00,240 --> 00:09:02,800
aqr

295
00:09:03,760 --> 00:09:07,519
so more specifically we observe that the

296
00:09:05,839 --> 00:09:08,240
bad challenge for some sigma protocol

297
00:09:07,519 --> 00:09:10,560
for an np

298
00:09:08,240 --> 00:09:13,040
a complete language can be approximated

299
00:09:10,560 --> 00:09:15,119
by constant degree polynomials

300
00:09:13,040 --> 00:09:16,880
and therefore it's sufficient now to get

301
00:09:15,120 --> 00:09:18,399
relationshipability for all functions

302
00:09:16,880 --> 00:09:20,240
that can be approximated by constantly

303
00:09:18,399 --> 00:09:21,279
polynomials and this is exactly what we

304
00:09:20,240 --> 00:09:23,920
do

305
00:09:21,279 --> 00:09:26,720
and we use a trapdoor hash and the

306
00:09:23,920 --> 00:09:26,719
airplane assumption

307
00:09:28,080 --> 00:09:32,480
good so let's draw a more elaborate

308
00:09:31,279 --> 00:09:35,360
comparison between

309
00:09:32,480 --> 00:09:36,160
period work and our work so again like i

310
00:09:35,360 --> 00:09:38,640
said

311
00:09:36,160 --> 00:09:40,319
uh period work uses the fact that uh

312
00:09:38,640 --> 00:09:41,680
there exists a sigma protocol for an

313
00:09:40,320 --> 00:09:43,440
a complete language where the bad

314
00:09:41,680 --> 00:09:45,120
challenge is efficiently computable

315
00:09:43,440 --> 00:09:47,120
and therefore a relationship ability for

316
00:09:45,120 --> 00:09:50,480
all efficiently computable functions

317
00:09:47,120 --> 00:09:51,600
suffices for nz and they can get such

318
00:09:50,480 --> 00:09:53,680
relationship immediately using

319
00:09:51,600 --> 00:09:57,279
homomorphism for all efficient functions

320
00:09:53,680 --> 00:09:58,959
or for hormones in other words under lwe

321
00:09:57,279 --> 00:10:00,800
so morphism is a very vague notion but

322
00:09:58,959 --> 00:10:04,000
you can think about fhe in such a case

323
00:10:00,800 --> 00:10:06,560
or fully homomorphic commitments

324
00:10:04,000 --> 00:10:08,160
uh so at a high level what they do is

325
00:10:06,560 --> 00:10:08,560
they use homomorphism for a function

326
00:10:08,160 --> 00:10:10,480
class

327
00:10:08,560 --> 00:10:12,239
f which is in this case any polynomial

328
00:10:10,480 --> 00:10:13,120
time computation to get correlation

329
00:10:12,240 --> 00:10:16,959
stackability for

330
00:10:13,120 --> 00:10:20,000
f for an equilibrium computation

331
00:10:16,959 --> 00:10:22,000
um so again our goal is to start with

332
00:10:20,000 --> 00:10:23,920
other standard assumptions in particular

333
00:10:22,000 --> 00:10:25,760
assumptions that do not uh give us full

334
00:10:23,920 --> 00:10:29,120
homomorphism

335
00:10:25,760 --> 00:10:31,920
so our starting point is um a work

336
00:10:29,120 --> 00:10:32,959
also from last crypto by uh al when we

337
00:10:31,920 --> 00:10:34,479
show how using

338
00:10:32,959 --> 00:10:37,199
uh many standard assumptions in

339
00:10:34,480 --> 00:10:38,880
particular adh we can get

340
00:10:37,200 --> 00:10:40,399
some form of well-structured

341
00:10:38,880 --> 00:10:42,720
homomorphism

342
00:10:40,399 --> 00:10:44,399
um again this is very vague but the uh

343
00:10:42,720 --> 00:10:46,720
formal abstraction for that

344
00:10:44,399 --> 00:10:48,560
was called triple hatch so we get some

345
00:10:46,720 --> 00:10:50,560
sort of well-structured homomorphism for

346
00:10:48,560 --> 00:10:54,160
all constant degree functions

347
00:10:50,560 --> 00:10:55,920
um and we show that um

348
00:10:54,160 --> 00:10:58,240
and using west structure homomorphism

349
00:10:55,920 --> 00:11:00,479
for such a weak class of functions

350
00:10:58,240 --> 00:11:02,480
we can get a flexibility for a much

351
00:11:00,480 --> 00:11:03,839
stronger class of functions

352
00:11:02,480 --> 00:11:05,519
so rather than starting with

353
00:11:03,839 --> 00:11:07,600
homomorphism for f we start with

354
00:11:05,519 --> 00:11:10,959
homomorphism for a much

355
00:11:07,600 --> 00:11:12,240
weaker class c but using some structure

356
00:11:10,959 --> 00:11:14,160
of

357
00:11:12,240 --> 00:11:15,600
the underlying homomorphic primitives we

358
00:11:14,160 --> 00:11:18,640
get politician factability for

359
00:11:15,600 --> 00:11:20,000
the strong class f and more specifically

360
00:11:18,640 --> 00:11:21,680
we get correlation tractability

361
00:11:20,000 --> 00:11:23,040
for all relations that can be

362
00:11:21,680 --> 00:11:24,079
approximately by constant degree

363
00:11:23,040 --> 00:11:26,000
polynomials

364
00:11:24,079 --> 00:11:27,120
and if we want to compare this notion to

365
00:11:26,000 --> 00:11:29,680
the usual

366
00:11:27,120 --> 00:11:30,800
ability notion then in the standard

367
00:11:29,680 --> 00:11:33,120
correlation factorability

368
00:11:30,800 --> 00:11:34,160
we ask that it's hard to find an x such

369
00:11:33,120 --> 00:11:36,800
that h of x

370
00:11:34,160 --> 00:11:39,760
is equal to the band challenge of f of x

371
00:11:36,800 --> 00:11:42,079
but what we want now is a hash function

372
00:11:39,760 --> 00:11:43,120
such that it's hard to find an x for

373
00:11:42,079 --> 00:11:45,680
which h and x

374
00:11:43,120 --> 00:11:47,040
and f of x are even close to each other

375
00:11:45,680 --> 00:11:49,599
in some metric

376
00:11:47,040 --> 00:11:51,519
okay so this is a stronger notion but

377
00:11:49,600 --> 00:11:52,320
we're considering a much weaker class of

378
00:11:51,519 --> 00:11:54,839
functions

379
00:11:52,320 --> 00:11:56,880
in particular a constant degree of

380
00:11:54,839 --> 00:11:59,760
polynomials

381
00:11:56,880 --> 00:12:01,279
and then we show that using uh ci for

382
00:11:59,760 --> 00:12:03,200
approximate relations we can

383
00:12:01,279 --> 00:12:05,439
uh get correlation attractability for

384
00:12:03,200 --> 00:12:08,240
all functions that can be approximately

385
00:12:05,440 --> 00:12:10,800
computed by constant db polynomials

386
00:12:08,240 --> 00:12:12,639
and then we show that under lpm uh this

387
00:12:10,800 --> 00:12:14,319
is sufficient in air coordinates

388
00:12:12,639 --> 00:12:16,160
uh more specifically we show a sigma

389
00:12:14,320 --> 00:12:18,160
protocol for an np language

390
00:12:16,160 --> 00:12:19,519
uh in which the bad challenge function

391
00:12:18,160 --> 00:12:21,439
can be approximated using

392
00:12:19,519 --> 00:12:24,320
using constant degree polynomials under

393
00:12:21,440 --> 00:12:26,399
the ldn assumption of course

394
00:12:24,320 --> 00:12:27,519
and this is how we get our result good

395
00:12:26,399 --> 00:12:29,680
so

396
00:12:27,519 --> 00:12:31,040
following this outline we can divide our

397
00:12:29,680 --> 00:12:32,880
results to three parts

398
00:12:31,040 --> 00:12:34,639
and i'm going to go through uh one after

399
00:12:32,880 --> 00:12:36,320
the other

400
00:12:34,639 --> 00:12:38,480
okay so let's first define what

401
00:12:36,320 --> 00:12:39,760
correlation capability is so we say that

402
00:12:38,480 --> 00:12:41,839
the hash function h

403
00:12:39,760 --> 00:12:43,040
is correlation detectable for a function

404
00:12:41,839 --> 00:12:44,880
f

405
00:12:43,040 --> 00:12:46,240
if for any polynomial time adversary

406
00:12:44,880 --> 00:12:47,760
it's hard to win the following game

407
00:12:46,240 --> 00:12:48,320
which we call the relationship ability

408
00:12:47,760 --> 00:12:50,160
game

409
00:12:48,320 --> 00:12:52,000
so the game goes as follows the

410
00:12:50,160 --> 00:12:54,719
challenger first samples a random

411
00:12:52,000 --> 00:12:56,639
hash key okay and then he gives k to the

412
00:12:54,720 --> 00:12:58,240
adversary and the adversary's goal now

413
00:12:56,639 --> 00:12:59,519
is to find the correlation with respect

414
00:12:58,240 --> 00:13:01,519
to k

415
00:12:59,519 --> 00:13:02,880
namely his goal is to find an x such

416
00:13:01,519 --> 00:13:06,000
that h of x

417
00:13:02,880 --> 00:13:07,279
is equal to f of x so uh h is

418
00:13:06,000 --> 00:13:09,760
relationship for f

419
00:13:07,279 --> 00:13:10,880
if no ppt adversary can win this game

420
00:13:09,760 --> 00:13:12,880
and we say that uh

421
00:13:10,880 --> 00:13:14,079
h is equally detractable for a function

422
00:13:12,880 --> 00:13:16,079
class f

423
00:13:14,079 --> 00:13:18,399
if it is relationship for every function

424
00:13:16,079 --> 00:13:19,920
in the class

425
00:13:18,399 --> 00:13:21,680
it will be useful at this point to talk

426
00:13:19,920 --> 00:13:22,479
about a technique that was used in

427
00:13:21,680 --> 00:13:24,160
period work

428
00:13:22,480 --> 00:13:26,000
to get ci and it's called summer

429
00:13:24,160 --> 00:13:28,399
statistical relationship ability

430
00:13:26,000 --> 00:13:29,120
so we say the following assume that uh

431
00:13:28,399 --> 00:13:32,399
for every

432
00:13:29,120 --> 00:13:33,600
uh function f so given f we can sample a

433
00:13:32,399 --> 00:13:36,160
fake hash

434
00:13:33,600 --> 00:13:36,639
k sub f which is indistinguishable from

435
00:13:36,160 --> 00:13:40,240
the

436
00:13:36,639 --> 00:13:41,920
read hash key and further that uh the ci

437
00:13:40,240 --> 00:13:45,120
game when we sample a field

438
00:13:41,920 --> 00:13:47,120
key rather than a real key is

439
00:13:45,120 --> 00:13:49,120
statistically hard to win so again we

440
00:13:47,120 --> 00:13:49,519
consider the game which is identical to

441
00:13:49,120 --> 00:13:51,519
the

442
00:13:49,519 --> 00:13:53,600
game we've seen before but now rather

443
00:13:51,519 --> 00:13:56,000
rather than sampling

444
00:13:53,600 --> 00:13:57,760
we sample a fake actually using a fake

445
00:13:56,000 --> 00:14:00,079
generation algorithm

446
00:13:57,760 --> 00:14:02,079
and what does it mean for the game to be

447
00:14:00,079 --> 00:14:03,760
hard to win it basically means that

448
00:14:02,079 --> 00:14:05,120
the probability that there exists a

449
00:14:03,760 --> 00:14:07,519
correlation between h

450
00:14:05,120 --> 00:14:09,279
under the fake hash key and f is

451
00:14:07,519 --> 00:14:12,880
negligible

452
00:14:09,279 --> 00:14:14,720
so assuming we have these two properties

453
00:14:12,880 --> 00:14:16,079
then using a standard distinguishability

454
00:14:14,720 --> 00:14:17,680
argument we can claim

455
00:14:16,079 --> 00:14:19,519
that h is actually correlation

456
00:14:17,680 --> 00:14:20,800
flexibility for the entire function

457
00:14:19,519 --> 00:14:23,839
class

458
00:14:20,800 --> 00:14:28,000
calligraphic f good

459
00:14:23,839 --> 00:14:31,120
um so let's start with a very trivial

460
00:14:28,000 --> 00:14:32,639
case towards our final construction so

461
00:14:31,120 --> 00:14:33,360
we consider the case where our function

462
00:14:32,639 --> 00:14:35,199
class

463
00:14:33,360 --> 00:14:37,120
f contains only length expanding

464
00:14:35,199 --> 00:14:38,079
functions more specifically every

465
00:14:37,120 --> 00:14:40,959
function in the class

466
00:14:38,079 --> 00:14:42,000
takes a small domain and expands it to a

467
00:14:40,959 --> 00:14:43,920
large range

468
00:14:42,000 --> 00:14:45,360
and notice that in particular in such a

469
00:14:43,920 --> 00:14:47,279
case um

470
00:14:45,360 --> 00:14:49,680
the image of any function f is some

471
00:14:47,279 --> 00:14:51,040
small subset of the range

472
00:14:49,680 --> 00:14:52,880
so our candidate for relation

473
00:14:51,040 --> 00:14:55,120
detectability in such a case

474
00:14:52,880 --> 00:14:57,439
is a hash function that simply simply

475
00:14:55,120 --> 00:15:00,000
samples a random vector r

476
00:14:57,440 --> 00:15:01,440
in the hash key and outputs it

477
00:15:00,000 --> 00:15:03,519
regardless of the value of x

478
00:15:01,440 --> 00:15:05,760
so notice that once we fix a hash key

479
00:15:03,519 --> 00:15:08,079
then our hash function is constant

480
00:15:05,760 --> 00:15:09,040
so what happens now for every function

481
00:15:08,079 --> 00:15:10,560
in the class

482
00:15:09,040 --> 00:15:12,639
the probability that there exists a

483
00:15:10,560 --> 00:15:13,199
correlation is equal to the probability

484
00:15:12,639 --> 00:15:16,639
that r

485
00:15:13,199 --> 00:15:18,800
is even in the image of f

486
00:15:16,639 --> 00:15:19,839
and if the image of f is sufficiently

487
00:15:18,800 --> 00:15:21,519
small or

488
00:15:19,839 --> 00:15:23,519
more precisely if it's exponentially

489
00:15:21,519 --> 00:15:24,000
sparse in the range then the probability

490
00:15:23,519 --> 00:15:26,560
that r

491
00:15:24,000 --> 00:15:27,680
is in the image or equivalently that the

492
00:15:26,560 --> 00:15:30,239
existing correlation

493
00:15:27,680 --> 00:15:31,519
is negligible good so this simple

494
00:15:30,240 --> 00:15:34,240
construction is actually equally

495
00:15:31,519 --> 00:15:38,320
interactable for expanding functions

496
00:15:34,240 --> 00:15:40,000
and our idea is to impose the same image

497
00:15:38,320 --> 00:15:42,320
in the general case even when our class

498
00:15:40,000 --> 00:15:44,079
contains shrinking functions

499
00:15:42,320 --> 00:15:45,839
so when our class contains shrinking

500
00:15:44,079 --> 00:15:46,560
functions we cannot simply sample a

501
00:15:45,839 --> 00:15:48,959
random r

502
00:15:46,560 --> 00:15:50,079
and uh and assume it's going to be

503
00:15:48,959 --> 00:15:51,359
outside of the image

504
00:15:50,079 --> 00:15:53,120
because the image of the function can be

505
00:15:51,360 --> 00:15:55,680
the entire range

506
00:15:53,120 --> 00:15:56,320
so what we do instead we define our hash

507
00:15:55,680 --> 00:15:58,319
function h

508
00:15:56,320 --> 00:16:00,480
using some other hash function we call h

509
00:15:58,320 --> 00:16:02,480
prime so our hash construction will

510
00:16:00,480 --> 00:16:03,680
look as follows we will use a hash

511
00:16:02,480 --> 00:16:05,839
function h prime

512
00:16:03,680 --> 00:16:07,279
and then h of x will be equal to h prime

513
00:16:05,839 --> 00:16:09,759
on x

514
00:16:07,279 --> 00:16:11,680
a a random r so again r is part of the

515
00:16:09,759 --> 00:16:14,000
hash key and is sampled randomly

516
00:16:11,680 --> 00:16:16,719
so what we require from h prime in order

517
00:16:14,000 --> 00:16:18,399
for it to be uh correlation attractable

518
00:16:16,720 --> 00:16:19,920
so we require that for every function in

519
00:16:18,399 --> 00:16:21,120
the class if there exists

520
00:16:19,920 --> 00:16:23,439
a fake hash key which is

521
00:16:21,120 --> 00:16:25,839
indistinguishable from a real hash key

522
00:16:23,440 --> 00:16:26,959
further we require that the correlation

523
00:16:25,839 --> 00:16:30,160
function

524
00:16:26,959 --> 00:16:31,920
h prime of x under the fetch key store f

525
00:16:30,160 --> 00:16:33,199
of x so i'm calling this the correlation

526
00:16:31,920 --> 00:16:33,920
function because it represents the

527
00:16:33,199 --> 00:16:36,319
correlation

528
00:16:33,920 --> 00:16:37,519
of h prime under the fake hash key and f

529
00:16:36,320 --> 00:16:39,120
we require that this

530
00:16:37,519 --> 00:16:40,639
correlation function has exponentially

531
00:16:39,120 --> 00:16:42,480
sparse image and

532
00:16:40,639 --> 00:16:43,680
in such a case we say that h prime with

533
00:16:42,480 --> 00:16:46,160
fake hash key and f

534
00:16:43,680 --> 00:16:47,839
have its parts correlation so assuming

535
00:16:46,160 --> 00:16:49,680
we have this possible relation between

536
00:16:47,839 --> 00:16:51,680
the fate hash function and f

537
00:16:49,680 --> 00:16:53,439
then we can say that uh with the

538
00:16:51,680 --> 00:16:56,000
overwhelming probability

539
00:16:53,440 --> 00:16:57,680
uh we have that a random r is not in the

540
00:16:56,000 --> 00:17:00,639
image of this correlation function

541
00:16:57,680 --> 00:17:02,079
and uh uh and therefore uh with a

542
00:17:00,639 --> 00:17:03,040
negligible probability that exists a

543
00:17:02,079 --> 00:17:05,599
correlation between

544
00:17:03,040 --> 00:17:07,760
h and f and therefore h is somewhat

545
00:17:05,599 --> 00:17:10,399
statistical relationship

546
00:17:07,760 --> 00:17:12,319
good now that we have reduced our goal

547
00:17:10,400 --> 00:17:12,880
uh to constructing sparse correlations

548
00:17:12,319 --> 00:17:14,480
i'm going to

549
00:17:12,880 --> 00:17:16,240
show you real quick how to do that uh

550
00:17:14,480 --> 00:17:19,439
using trapdoor hash

551
00:17:16,240 --> 00:17:20,079
um so like i already said uh traptor

552
00:17:19,439 --> 00:17:21,520
hash

553
00:17:20,079 --> 00:17:22,959
allows us to construct a homologic

554
00:17:21,520 --> 00:17:24,400
encryption scheme with very strong

555
00:17:22,959 --> 00:17:25,919
structural properties

556
00:17:24,400 --> 00:17:28,160
so in general in a more encryption

557
00:17:25,919 --> 00:17:30,400
scheme we can take an input x

558
00:17:28,160 --> 00:17:32,080
and given an encryption of a function f

559
00:17:30,400 --> 00:17:34,400
we can morphically evaluate

560
00:17:32,080 --> 00:17:35,280
and obtain a ciphertext encrypting f of

561
00:17:34,400 --> 00:17:37,280
x

562
00:17:35,280 --> 00:17:38,960
in a homomorphic encryption scheme which

563
00:17:37,280 --> 00:17:41,600
we construct from trap.hash

564
00:17:38,960 --> 00:17:43,360
the post-evaluation ciphertext can be

565
00:17:41,600 --> 00:17:44,959
divided into two parts

566
00:17:43,360 --> 00:17:46,799
one part we call the rate once

567
00:17:44,960 --> 00:17:47,120
ciphertext and i'm going to refer to it

568
00:17:46,799 --> 00:17:49,200
as

569
00:17:47,120 --> 00:17:52,639
the encryption of f of x and another

570
00:17:49,200 --> 00:17:55,120
part is a small hash h of x

571
00:17:52,640 --> 00:17:56,640
and the decryption integral hash goes as

572
00:17:55,120 --> 00:18:00,479
follows so the first stage

573
00:17:56,640 --> 00:18:03,520
takes the hash of x h of x and produces

574
00:18:00,480 --> 00:18:04,320
a long vector e and then one can recover

575
00:18:03,520 --> 00:18:06,799
f of x

576
00:18:04,320 --> 00:18:07,678
simply by storing e and the encryption

577
00:18:06,799 --> 00:18:09,840
of f of x

578
00:18:07,679 --> 00:18:11,360
so the second stage of the decryption is

579
00:18:09,840 --> 00:18:13,120
public

580
00:18:11,360 --> 00:18:15,760
so how can we use such an encryption

581
00:18:13,120 --> 00:18:18,479
scheme in order to get partial relations

582
00:18:15,760 --> 00:18:19,919
so i'm going to define the fake hash key

583
00:18:18,480 --> 00:18:22,400
for every function f

584
00:18:19,919 --> 00:18:23,919
to be the encryption of f and then given

585
00:18:22,400 --> 00:18:27,039
an input x will compute

586
00:18:23,919 --> 00:18:29,600
h prime of x simply as the

587
00:18:27,039 --> 00:18:30,400
ciphertext or the rate one ciphertext of

588
00:18:29,600 --> 00:18:32,799
f of x

589
00:18:30,400 --> 00:18:35,039
okay so see we so the function f prime

590
00:18:32,799 --> 00:18:36,720
is simply one of the evaluation

591
00:18:35,039 --> 00:18:38,720
so what about the correlation function

592
00:18:36,720 --> 00:18:40,480
now so notice that the correct

593
00:18:38,720 --> 00:18:42,720
the correctness of decryption of chapter

594
00:18:40,480 --> 00:18:44,640
hash

595
00:18:42,720 --> 00:18:47,440
the correlation function is simply this

596
00:18:44,640 --> 00:18:48,799
vector e which is computed only given a

597
00:18:47,440 --> 00:18:51,520
small h of x

598
00:18:48,799 --> 00:18:53,440
and if h of x is sufficiently small then

599
00:18:51,520 --> 00:18:55,200
we can say that e is sampled from

600
00:18:53,440 --> 00:18:56,640
an exponentially sparse image and

601
00:18:55,200 --> 00:18:57,039
therefore the correlation between h

602
00:18:56,640 --> 00:19:00,400
prime

603
00:18:57,039 --> 00:19:03,520
and f is sparse so i didn't say

604
00:19:00,400 --> 00:19:05,360
uh what the real key

605
00:19:03,520 --> 00:19:06,720
is and why is it indistinguishable from

606
00:19:05,360 --> 00:19:08,719
the hash key

607
00:19:06,720 --> 00:19:10,000
but notice that the fake keys are simply

608
00:19:08,720 --> 00:19:11,840
the encryption

609
00:19:10,000 --> 00:19:13,760
of the functions they correspond to so

610
00:19:11,840 --> 00:19:15,360
the real key can be an encryption of any

611
00:19:13,760 --> 00:19:17,039
arbitrary fixed function

612
00:19:15,360 --> 00:19:18,399
and we can claim indistinguishability

613
00:19:17,039 --> 00:19:20,240
based on the security of the encryption

614
00:19:18,400 --> 00:19:22,960
scheme

615
00:19:20,240 --> 00:19:24,559
so good so from the work of docking it

616
00:19:22,960 --> 00:19:26,720
all we know that we can

617
00:19:24,559 --> 00:19:28,160
get such well-structured homomorphism

618
00:19:26,720 --> 00:19:30,160
for constant degree functions

619
00:19:28,160 --> 00:19:32,480
from many standard assumptions including

620
00:19:30,160 --> 00:19:34,400
uh ddh for instance

621
00:19:32,480 --> 00:19:36,000
and like i showed you this gives us

622
00:19:34,400 --> 00:19:36,960
correlation flexibility for all constant

623
00:19:36,000 --> 00:19:38,880
degree functions

624
00:19:36,960 --> 00:19:40,880
but unfortunately this is insufficient

625
00:19:38,880 --> 00:19:42,240
for physics

626
00:19:40,880 --> 00:19:44,080
so now we ask whether we can get

627
00:19:42,240 --> 00:19:45,200
something stronger out of our idea of

628
00:19:44,080 --> 00:19:47,199
sparse relations

629
00:19:45,200 --> 00:19:48,880
and remember that we claimed that a

630
00:19:47,200 --> 00:19:49,600
random r is with overwhelming

631
00:19:48,880 --> 00:19:52,480
probability

632
00:19:49,600 --> 00:19:54,320
not in the image of a sparse correlation

633
00:19:52,480 --> 00:19:55,120
but we also observe that overwhelming

634
00:19:54,320 --> 00:19:58,559
probability

635
00:19:55,120 --> 00:20:00,639
r is actually far away from this image

636
00:19:58,559 --> 00:20:02,080
and almost immediately leads us to

637
00:20:00,640 --> 00:20:03,360
defining a stronger notion of

638
00:20:02,080 --> 00:20:07,840
correlation interactability

639
00:20:03,360 --> 00:20:09,199
which we call c i apx

640
00:20:07,840 --> 00:20:10,959
correlation interactability for

641
00:20:09,200 --> 00:20:12,640
approximable relations

642
00:20:10,960 --> 00:20:14,400
so we say that the hash function h is

643
00:20:12,640 --> 00:20:16,000
correlation tractability is correlation

644
00:20:14,400 --> 00:20:16,960
interactable for relations approximately

645
00:20:16,000 --> 00:20:18,559
by f

646
00:20:16,960 --> 00:20:20,799
if it's hard for an inversity not only

647
00:20:18,559 --> 00:20:21,120
to find a correlation but rather to find

648
00:20:20,799 --> 00:20:25,039
an

649
00:20:21,120 --> 00:20:28,479
x such that h of x and f of x are close

650
00:20:25,039 --> 00:20:29,200
in hamming distance and we can similarly

651
00:20:28,480 --> 00:20:32,840
extend this

652
00:20:29,200 --> 00:20:34,159
a notion to a ci for a class of

653
00:20:32,840 --> 00:20:37,199
functions

654
00:20:34,159 --> 00:20:39,520
good so now we know that we

655
00:20:37,200 --> 00:20:40,559
can get ci for approximately constant

656
00:20:39,520 --> 00:20:44,400
degree relations

657
00:20:40,559 --> 00:20:47,440
based on trap.hash from ddh qr lwe or

658
00:20:44,400 --> 00:20:48,720
dcr and i'm not going

659
00:20:47,440 --> 00:20:50,640
to go through the details of this

660
00:20:48,720 --> 00:20:52,000
transformation but

661
00:20:50,640 --> 00:20:53,840
you will have to believe me that using

662
00:20:52,000 --> 00:20:55,120
such notion of ci we can get

663
00:20:53,840 --> 00:20:56,799
relationship ability

664
00:20:55,120 --> 00:20:59,120
for all functions that we can

665
00:20:56,799 --> 00:21:01,280
approximate using constant degree

666
00:20:59,120 --> 00:21:02,320
and let's be a bit more formal i just

667
00:21:01,280 --> 00:21:04,960
want to tell you

668
00:21:02,320 --> 00:21:05,678
what notion of approximability we're

669
00:21:04,960 --> 00:21:07,120
considering

670
00:21:05,679 --> 00:21:08,480
so we say that the function f is

671
00:21:07,120 --> 00:21:10,080
probabilistically computable by a

672
00:21:08,480 --> 00:21:11,840
constant degree polynomial

673
00:21:10,080 --> 00:21:14,799
there exists a distribution over such

674
00:21:11,840 --> 00:21:17,840
polynomials such that for every input x

675
00:21:14,799 --> 00:21:20,158
the probability that f of x and p

676
00:21:17,840 --> 00:21:21,600
of x are far from each other in hamming

677
00:21:20,159 --> 00:21:23,440
distance is negligible

678
00:21:21,600 --> 00:21:25,600
okay where p here is this polynomial

679
00:21:23,440 --> 00:21:28,000
sampled according to the

680
00:21:25,600 --> 00:21:28,840
distribution which probabilistically

681
00:21:28,000 --> 00:21:32,720
computes

682
00:21:28,840 --> 00:21:32,720
f good

683
00:21:32,799 --> 00:21:36,000
so now all is left to show you is how

684
00:21:35,120 --> 00:21:37,600
under lpn

685
00:21:36,000 --> 00:21:39,280
we have a sigma protocol for an

686
00:21:37,600 --> 00:21:40,879
np-complete language

687
00:21:39,280 --> 00:21:43,120
such that the batch challenge function

688
00:21:40,880 --> 00:21:45,039
has a pro can be progressively computed

689
00:21:43,120 --> 00:21:47,039
using constant degree polynomials

690
00:21:45,039 --> 00:21:48,158
and to do that i'm going to first recall

691
00:21:47,039 --> 00:21:50,240
period work

692
00:21:48,159 --> 00:21:51,520
uh where all they had to do is show the

693
00:21:50,240 --> 00:21:53,600
existing sigma protocol with an

694
00:21:51,520 --> 00:21:55,918
efficiently computable bad challenge

695
00:21:53,600 --> 00:21:57,360
so they start with the classic sigma

696
00:21:55,919 --> 00:21:59,039
protocol for hamiltonicity

697
00:21:57,360 --> 00:22:01,360
which in particular uses some commitment

698
00:21:59,039 --> 00:22:03,200
scheme and they use the observation

699
00:22:01,360 --> 00:22:04,559
that if this commitment scheme is

700
00:22:03,200 --> 00:22:06,640
efficiently extractable

701
00:22:04,559 --> 00:22:08,240
meaning that we can extract the values

702
00:22:06,640 --> 00:22:10,240
underlying some commitment

703
00:22:08,240 --> 00:22:11,840
uh only by seeing the commitment and

704
00:22:10,240 --> 00:22:13,760
possibly using some trouble

705
00:22:11,840 --> 00:22:15,280
then the bad challenge function is

706
00:22:13,760 --> 00:22:17,360
efficiently computable

707
00:22:15,280 --> 00:22:19,120
and more specifically the challenge

708
00:22:17,360 --> 00:22:21,360
function uh given a

709
00:22:19,120 --> 00:22:23,678
it simply consists of first extracting

710
00:22:21,360 --> 00:22:25,678
the values underlying the commitment

711
00:22:23,679 --> 00:22:27,760
a and then applying some polynomial time

712
00:22:25,679 --> 00:22:29,919
computation which we denote here by v

713
00:22:27,760 --> 00:22:31,440
so clearly if both v and the extraction

714
00:22:29,919 --> 00:22:33,360
algorithm are efficiently computable

715
00:22:31,440 --> 00:22:36,880
then so is the batch range function

716
00:22:33,360 --> 00:22:38,320
f so um for us we need something

717
00:22:36,880 --> 00:22:40,880
stronger we need to

718
00:22:38,320 --> 00:22:42,080
show that the sigma protocol has a

719
00:22:40,880 --> 00:22:43,679
challenge which is probabilistic

720
00:22:42,080 --> 00:22:45,520
constant degree

721
00:22:43,679 --> 00:22:48,159
so we make the following observations

722
00:22:45,520 --> 00:22:50,639
first we observe that there exists an lb

723
00:22:48,159 --> 00:22:53,919
lpn based commitment scheme

724
00:22:50,640 --> 00:22:55,520
where the extraction algorithm can be

725
00:22:53,919 --> 00:22:58,080
probabilistically computable by a linear

726
00:22:55,520 --> 00:22:58,799
function which are a constant in which a

727
00:22:58,080 --> 00:23:00,240
special

728
00:22:58,799 --> 00:23:02,480
case of constant degree functions of

729
00:23:00,240 --> 00:23:04,880
course

730
00:23:02,480 --> 00:23:07,280
but the problem is that this polynomial

731
00:23:04,880 --> 00:23:09,600
time verification

732
00:23:07,280 --> 00:23:11,520
is of high degree okay at least in the

733
00:23:09,600 --> 00:23:12,158
protocol formula city and it's not clear

734
00:23:11,520 --> 00:23:14,559
how we can

735
00:23:12,159 --> 00:23:16,559
uh probabilistically compute it using a

736
00:23:14,559 --> 00:23:18,799
constant degree polynomials

737
00:23:16,559 --> 00:23:20,399
um but then we remember that using the

738
00:23:18,799 --> 00:23:22,879
cochlear transform

739
00:23:20,400 --> 00:23:24,080
we can uh transform any polynomial

740
00:23:22,880 --> 00:23:27,200
amplification

741
00:23:24,080 --> 00:23:28,559
to a 3cnf formula uh and this is because

742
00:23:27,200 --> 00:23:29,360
here three synthesis viability is

743
00:23:28,559 --> 00:23:32,639
complete for

744
00:23:29,360 --> 00:23:34,399
uh such political amplification um

745
00:23:32,640 --> 00:23:36,080
and why is this useful this is useful

746
00:23:34,400 --> 00:23:39,440
because 37 formulas actually

747
00:23:36,080 --> 00:23:42,879
have uh probabilistic representations as

748
00:23:39,440 --> 00:23:44,799
constant degree polynomials so um

749
00:23:42,880 --> 00:23:46,159
again using a cochlear viewing we can uh

750
00:23:44,799 --> 00:23:47,918
adjust a bit the uh

751
00:23:46,159 --> 00:23:51,120
metricity protocol into a protocol where

752
00:23:47,919 --> 00:23:53,279
the bad challenge function consists of

753
00:23:51,120 --> 00:23:54,320
first extracting the values underlying

754
00:23:53,279 --> 00:23:56,640
the commitment a

755
00:23:54,320 --> 00:23:58,000
and then applying some three c formula

756
00:23:56,640 --> 00:24:00,320
rather than an arbitrary

757
00:23:58,000 --> 00:24:02,159
normal time computation and now since we

758
00:24:00,320 --> 00:24:03,760
know how to probabilistically compute

759
00:24:02,159 --> 00:24:05,440
both the formula and the extraction

760
00:24:03,760 --> 00:24:07,840
using constant degree functions

761
00:24:05,440 --> 00:24:09,840
we can uh probabilistically compute the

762
00:24:07,840 --> 00:24:13,199
bad challenge function using constant

763
00:24:09,840 --> 00:24:15,360
degree and this completes our result

764
00:24:13,200 --> 00:24:17,200
so let's conclude uh so we show a new

765
00:24:15,360 --> 00:24:19,678
notion of ci for approximate

766
00:24:17,200 --> 00:24:21,520
relations and we show that we can get

767
00:24:19,679 --> 00:24:24,240
physics from standard assumptions

768
00:24:21,520 --> 00:24:26,480
through this new notion in particular we

769
00:24:24,240 --> 00:24:28,080
get the first physics under ddh and lpl

770
00:24:26,480 --> 00:24:30,159
and now there are many natural questions

771
00:24:28,080 --> 00:24:34,240
we can ask first of all whether we can

772
00:24:30,159 --> 00:24:36,720
use this new notion to get applications

773
00:24:34,240 --> 00:24:39,200
maybe in zaps or in complexity or

774
00:24:36,720 --> 00:24:40,880
hardness results

775
00:24:39,200 --> 00:24:42,240
we can also ask questions related to

776
00:24:40,880 --> 00:24:45,120
applications itself

777
00:24:42,240 --> 00:24:46,559
so it will be interesting to see whether

778
00:24:45,120 --> 00:24:47,279
we can minimize the set of standard

779
00:24:46,559 --> 00:24:49,600
assumptions

780
00:24:47,279 --> 00:24:52,080
uh so maybe we can get music only from

781
00:24:49,600 --> 00:24:53,360
ddh or only from lpn

782
00:24:52,080 --> 00:24:55,199
uh it would be interesting to see

783
00:24:53,360 --> 00:24:56,559
whether we can extend our result uh to

784
00:24:55,200 --> 00:24:58,000
get statistical zero knowledge or

785
00:24:56,559 --> 00:25:02,480
statistical soundness

786
00:24:58,000 --> 00:25:05,679
soundness which we don't get either

787
00:25:02,480 --> 00:25:09,600
as opposed to period work

788
00:25:05,679 --> 00:25:09,600
that's it thanks for listening

