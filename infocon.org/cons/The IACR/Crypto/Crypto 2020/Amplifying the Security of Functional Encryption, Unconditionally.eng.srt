1
00:00:00,480 --> 00:00:04,960
hi my name is alexis corb and this talk

2
00:00:03,120 --> 00:00:06,480
is on amplifying the security of

3
00:00:04,960 --> 00:00:08,719
functional encryption

4
00:00:06,480 --> 00:00:09,760
unconditionally this is joint work with

5
00:00:08,720 --> 00:00:12,160
ayush jane

6
00:00:09,760 --> 00:00:15,519
nathan manahar and amit sahai thanks for

7
00:00:12,160 --> 00:00:16,960
watching and i hope you enjoy the talk

8
00:00:15,519 --> 00:00:20,320
so i'll start by defining functional

9
00:00:16,960 --> 00:00:22,160
encryption here i define secret key fe

10
00:00:20,320 --> 00:00:23,519
but our work also extends to public key

11
00:00:22,160 --> 00:00:25,279
fe

12
00:00:23,519 --> 00:00:27,359
in a functional encryption scheme

13
00:00:25,279 --> 00:00:29,439
authority wishes to allow users to learn

14
00:00:27,359 --> 00:00:32,000
functions of some encrypted input

15
00:00:29,439 --> 00:00:32,479
and no other information about the input

16
00:00:32,000 --> 00:00:34,800
so

17
00:00:32,479 --> 00:00:36,718
more formally an authority with a master

18
00:00:34,800 --> 00:00:38,160
secret key can generate function keys

19
00:00:36,719 --> 00:00:39,680
for specific functions

20
00:00:38,160 --> 00:00:41,760
which you can then hand out to different

21
00:00:39,680 --> 00:00:43,760
users

22
00:00:41,760 --> 00:00:46,640
then using the master secret key the

23
00:00:43,760 --> 00:00:48,559
authority can encrypt some message m

24
00:00:46,640 --> 00:00:50,399
correctness holds if a user with a

25
00:00:48,559 --> 00:00:52,800
function key for function f

26
00:00:50,399 --> 00:00:53,600
and a ciphertext for a message m can

27
00:00:52,800 --> 00:00:56,000
compute f

28
00:00:53,600 --> 00:00:57,120
m note that different users with

29
00:00:56,000 --> 00:00:58,079
different function keys

30
00:00:57,120 --> 00:01:00,399
should be able to compute their

31
00:00:58,079 --> 00:01:01,520
corresponding function on the encrypted

32
00:01:00,399 --> 00:01:03,840
input

33
00:01:01,520 --> 00:01:05,760
intuitively for security we want to be

34
00:01:03,840 --> 00:01:09,840
the case that the user learns only f

35
00:01:05,760 --> 00:01:11,439
m and nothing else we can formalize this

36
00:01:09,840 --> 00:01:13,119
by considering an adversary that is

37
00:01:11,439 --> 00:01:14,320
allowed to request function keys for

38
00:01:13,119 --> 00:01:16,080
functions of its choice

39
00:01:14,320 --> 00:01:17,360
along with encryptions and messages of

40
00:01:16,080 --> 00:01:19,360
its choice

41
00:01:17,360 --> 00:01:20,960
at some point the adversary outputs two

42
00:01:19,360 --> 00:01:23,119
messages m0 and

43
00:01:20,960 --> 00:01:24,798
m1 and receives an encryption of one of

44
00:01:23,119 --> 00:01:26,880
the two messages

45
00:01:24,799 --> 00:01:28,240
security holds if the adversary cannot

46
00:01:26,880 --> 00:01:30,079
distinguish between the case where it

47
00:01:28,240 --> 00:01:31,600
gets an encryption of m0

48
00:01:30,079 --> 00:01:33,199
and the case where it gets an encryption

49
00:01:31,600 --> 00:01:35,199
m1

50
00:01:33,200 --> 00:01:36,560
we also require that for every function

51
00:01:35,200 --> 00:01:37,600
for which the adversary requests a

52
00:01:36,560 --> 00:01:39,200
function key

53
00:01:37,600 --> 00:01:41,119
then the function evaluates the same

54
00:01:39,200 --> 00:01:42,799
value on these two messages

55
00:01:41,119 --> 00:01:44,240
otherwise by the correctness of the

56
00:01:42,799 --> 00:01:45,759
functional encryption scheme

57
00:01:44,240 --> 00:01:48,079
the adversary could trivially

58
00:01:45,759 --> 00:01:50,399
distinguish between the encryption of m0

59
00:01:48,079 --> 00:01:52,000
and encryption of m1 by simply computing

60
00:01:50,399 --> 00:01:52,720
this function of the encrypted message

61
00:01:52,000 --> 00:01:54,320
he received

62
00:01:52,720 --> 00:01:55,920
and comparing it to the value of the

63
00:01:54,320 --> 00:02:01,199
function on either m0

64
00:01:55,920 --> 00:02:02,960
or m1 this brings us to fv amplification

65
00:02:01,200 --> 00:02:04,719
amplification is where you take a weakly

66
00:02:02,960 --> 00:02:06,640
secure primitive and use it as a

67
00:02:04,719 --> 00:02:09,038
building block to construct fully secure

68
00:02:06,640 --> 00:02:11,038
primitive of the same type

69
00:02:09,038 --> 00:02:13,920
so what does it mean for an fv scheme to

70
00:02:11,038 --> 00:02:15,920
be weakly secure

71
00:02:13,920 --> 00:02:18,160
returning to our definition of security

72
00:02:15,920 --> 00:02:19,599
we will define a p-secure fe scheme

73
00:02:18,160 --> 00:02:22,400
to be one in which the distinguishing

74
00:02:19,599 --> 00:02:24,480
advantage of the adversary is at most p

75
00:02:22,400 --> 00:02:25,920
as an example the standard notion of fe

76
00:02:24,480 --> 00:02:27,920
security would require

77
00:02:25,920 --> 00:02:29,599
p to be some negligible function of the

78
00:02:27,920 --> 00:02:31,518
security parameter

79
00:02:29,599 --> 00:02:33,359
and a completely insecure scheme would

80
00:02:31,519 --> 00:02:35,360
have p equals 1.

81
00:02:33,360 --> 00:02:37,440
but in the general case p can be any

82
00:02:35,360 --> 00:02:39,599
value between 0 and 1.

83
00:02:37,440 --> 00:02:42,000
note that our notion of security weakens

84
00:02:39,599 --> 00:02:44,319
as p increases

85
00:02:42,000 --> 00:02:45,840
returning back to fe amplification we

86
00:02:44,319 --> 00:02:47,119
see that our goal is to reduce the

87
00:02:45,840 --> 00:02:48,319
distinguishing advantage of the

88
00:02:47,120 --> 00:02:50,800
adversary

89
00:02:48,319 --> 00:02:52,000
so for example we might want to take an

90
00:02:50,800 --> 00:02:53,680
fe scheme which is secure with

91
00:02:52,000 --> 00:02:55,440
probability only one half

92
00:02:53,680 --> 00:02:57,440
and use it to build an fe scheme which

93
00:02:55,440 --> 00:02:58,879
is fully secure

94
00:02:57,440 --> 00:03:00,319
now apart from being a fundamental

95
00:02:58,879 --> 00:03:02,399
question in its own right this is

96
00:03:00,319 --> 00:03:03,920
especially useful for fe

97
00:03:02,400 --> 00:03:05,760
since we do not currently know how to

98
00:03:03,920 --> 00:03:08,000
build the most general version fe

99
00:03:05,760 --> 00:03:09,359
for all functions from any standard

100
00:03:08,000 --> 00:03:12,640
assumptions

101
00:03:09,360 --> 00:03:14,560
so amplification results mean that if we

102
00:03:12,640 --> 00:03:16,238
can show how to construct even a weekly

103
00:03:14,560 --> 00:03:17,040
secure fe scheme from standard

104
00:03:16,239 --> 00:03:18,560
assumptions

105
00:03:17,040 --> 00:03:20,079
then this would imply the existence of a

106
00:03:18,560 --> 00:03:22,000
fully secure fe scheme

107
00:03:20,080 --> 00:03:23,760
from standard assumptions and

108
00:03:22,000 --> 00:03:24,400
constructing such a weakly secure effie

109
00:03:23,760 --> 00:03:26,159
scheme

110
00:03:24,400 --> 00:03:27,840
may be a lot easier than constructing a

111
00:03:26,159 --> 00:03:30,720
fully secure one

112
00:03:27,840 --> 00:03:32,000
finally we note that in amplification

113
00:03:30,720 --> 00:03:34,239
unlike in many other areas

114
00:03:32,000 --> 00:03:35,760
in cryptography the results can be

115
00:03:34,239 --> 00:03:37,280
unconditional

116
00:03:35,760 --> 00:03:39,679
and that the security of the fully

117
00:03:37,280 --> 00:03:40,799
secure fe scheme is dependent only upon

118
00:03:39,680 --> 00:03:43,840
the weak security

119
00:03:40,799 --> 00:03:45,519
of the weaker fe scheme

120
00:03:43,840 --> 00:03:48,159
so what has previously been done in ethi

121
00:03:45,519 --> 00:03:50,640
amplification in ags 18

122
00:03:48,159 --> 00:03:51,920
and aj lms19 they show that you can

123
00:03:50,640 --> 00:03:54,640
amplify fe

124
00:03:51,920 --> 00:03:56,640
from 1 minus 1 over poly lambda security

125
00:03:54,640 --> 00:03:57,839
meaning the adversary can almost always

126
00:03:56,640 --> 00:03:59,599
break the scheme

127
00:03:57,840 --> 00:04:02,640
to full security assuming

128
00:03:59,599 --> 00:04:04,000
sub-exponentially secure lwe

129
00:04:02,640 --> 00:04:05,920
and though i haven't defined either

130
00:04:04,000 --> 00:04:07,599
compactness or sublinearity

131
00:04:05,920 --> 00:04:09,599
for those who know this transformation

132
00:04:07,599 --> 00:04:12,640
does preserve both compactness

133
00:04:09,599 --> 00:04:14,319
and sublinearity additionally they have

134
00:04:12,640 --> 00:04:16,000
both polynomial and sub-exponential

135
00:04:14,319 --> 00:04:18,159
versions of their theorem

136
00:04:16,000 --> 00:04:19,918
in the polynomial version we consider

137
00:04:18,160 --> 00:04:21,280
adversaries of polynomial size

138
00:04:19,918 --> 00:04:23,039
and wish to make distinguishing

139
00:04:21,279 --> 00:04:24,960
advantage negligible

140
00:04:23,040 --> 00:04:26,960
in the sub-exponential version we

141
00:04:24,960 --> 00:04:27,599
consider adversaries of sub-exponential

142
00:04:26,960 --> 00:04:29,039
size

143
00:04:27,600 --> 00:04:31,919
and wish to make the distinguishing

144
00:04:29,040 --> 00:04:33,680
advantage sub-exponentially small

145
00:04:31,919 --> 00:04:35,440
and apart from these two works we do not

146
00:04:33,680 --> 00:04:36,960
know of any other fee amplification

147
00:04:35,440 --> 00:04:39,199
results

148
00:04:36,960 --> 00:04:41,599
so since their work assumes

149
00:04:39,199 --> 00:04:43,840
sub-exponentially secure lwe

150
00:04:41,600 --> 00:04:45,680
this brings up the question of whether

151
00:04:43,840 --> 00:04:49,280
we can get fe amplification

152
00:04:45,680 --> 00:04:50,880
from weaker assumptions and as the title

153
00:04:49,280 --> 00:04:53,758
of this talk might have indicated

154
00:04:50,880 --> 00:04:53,759
the answer is yes

155
00:04:53,919 --> 00:04:58,080
so in our work we show that you can

156
00:04:55,440 --> 00:05:01,280
amplify fe from constant security

157
00:04:58,080 --> 00:05:02,800
to full security unconditionally

158
00:05:01,280 --> 00:05:05,440
our transformation also preserves

159
00:05:02,800 --> 00:05:07,440
compactness and as in the prior version

160
00:05:05,440 --> 00:05:09,199
has both polynomial and sub-exponential

161
00:05:07,440 --> 00:05:10,960
versions

162
00:05:09,199 --> 00:05:12,479
we note that the prior work actually

163
00:05:10,960 --> 00:05:13,440
allows amplification from slightly

164
00:05:12,479 --> 00:05:14,960
weaker fe

165
00:05:13,440 --> 00:05:17,759
whereas our work requires that the weak

166
00:05:14,960 --> 00:05:19,198
fe be at least constantly secure

167
00:05:17,759 --> 00:05:22,800
however our transformation has the

168
00:05:19,199 --> 00:05:22,800
advantage that is unconditional

169
00:05:23,520 --> 00:05:27,440
we achieve our amplification in two

170
00:05:25,120 --> 00:05:28,720
steps first we show that any constant

171
00:05:27,440 --> 00:05:30,479
security scheme

172
00:05:28,720 --> 00:05:32,960
can be transformed into an arbitrarily

173
00:05:30,479 --> 00:05:34,719
small constant security scheme

174
00:05:32,960 --> 00:05:36,960
then we show that from a small enough

175
00:05:34,720 --> 00:05:38,880
constant say less than one sixth

176
00:05:36,960 --> 00:05:40,479
secure security scheme we can go to full

177
00:05:38,880 --> 00:05:42,320
security

178
00:05:40,479 --> 00:05:44,000
the reason we break this into two steps

179
00:05:42,320 --> 00:05:44,960
is because we actually use two different

180
00:05:44,000 --> 00:05:47,280
instructions

181
00:05:44,960 --> 00:05:48,479
for the two different transformations

182
00:05:47,280 --> 00:05:49,840
and the reason we do that

183
00:05:48,479 --> 00:05:51,919
is because the parameters are actually

184
00:05:49,840 --> 00:05:53,919
quite sensitive and neither construction

185
00:05:51,919 --> 00:05:55,359
by itself was sufficient to provide for

186
00:05:53,919 --> 00:05:59,120
the entire amplification

187
00:05:55,360 --> 00:06:01,520
all at once for the first transformation

188
00:05:59,120 --> 00:06:03,199
we nest our ethy scheme and i will

189
00:06:01,520 --> 00:06:05,120
describe later what nesting means in the

190
00:06:03,199 --> 00:06:06,880
context of ethy

191
00:06:05,120 --> 00:06:09,600
but to prove security we use a new

192
00:06:06,880 --> 00:06:11,520
nesting technique for hardcore measures

193
00:06:09,600 --> 00:06:13,039
this nesting technique also allows us to

194
00:06:11,520 --> 00:06:14,159
prove that a simple nesting of public

195
00:06:13,039 --> 00:06:15,840
key encryption

196
00:06:14,160 --> 00:06:18,080
that is where you encrypt the encryption

197
00:06:15,840 --> 00:06:19,599
of a message provides the amplification

198
00:06:18,080 --> 00:06:22,000
we would expect

199
00:06:19,600 --> 00:06:24,080
that is if the original pke scheme was

200
00:06:22,000 --> 00:06:26,080
broken with probability epsilon

201
00:06:24,080 --> 00:06:27,680
then the amplified public key encryption

202
00:06:26,080 --> 00:06:29,199
scheme formed by encrypting an

203
00:06:27,680 --> 00:06:30,880
encryption of a message

204
00:06:29,199 --> 00:06:32,800
would be broken with probability roughly

205
00:06:30,880 --> 00:06:34,319
epsilon squared

206
00:06:32,800 --> 00:06:36,720
now though we do already have

207
00:06:34,319 --> 00:06:38,319
amplification results for pke

208
00:06:36,720 --> 00:06:40,080
prior to this work we did not know how

209
00:06:38,319 --> 00:06:43,280
to prove subject amplification

210
00:06:40,080 --> 00:06:44,880
for simply nested pke in fact our new

211
00:06:43,280 --> 00:06:48,000
nesting technique can apply to other

212
00:06:44,880 --> 00:06:49,680
simply nasty primitives as well

213
00:06:48,000 --> 00:06:51,759
the second transformation has a much

214
00:06:49,680 --> 00:06:54,160
more complicated construction

215
00:06:51,759 --> 00:06:56,319
but as a couple of high-level highlights

216
00:06:54,160 --> 00:06:58,319
we use a pair of parallel repetition

217
00:06:56,319 --> 00:07:00,080
and we also create and use a new form of

218
00:06:58,319 --> 00:07:02,240
secret sharing which we call set

219
00:07:00,080 --> 00:07:03,758
homomorphic secret sharing

220
00:07:02,240 --> 00:07:05,919
we had to use this new form of secret

221
00:07:03,759 --> 00:07:07,440
sharing since in our case the parameters

222
00:07:05,919 --> 00:07:08,880
were actually quite delicate

223
00:07:07,440 --> 00:07:10,240
and the other forms of secret sharing

224
00:07:08,880 --> 00:07:13,520
were insufficient to provide the

225
00:07:10,240 --> 00:07:15,120
parameters we needed for amplification

226
00:07:13,520 --> 00:07:16,639
now unfortunately in this talk i will

227
00:07:15,120 --> 00:07:18,319
not have time to go into more detail

228
00:07:16,639 --> 00:07:20,720
about the second transformation

229
00:07:18,319 --> 00:07:22,319
or about set homomorphic secret sharing

230
00:07:20,720 --> 00:07:22,880
instead i will focus the remainder of

231
00:07:22,319 --> 00:07:25,599
this talk

232
00:07:22,880 --> 00:07:26,960
on our first transformation now one of

233
00:07:25,599 --> 00:07:28,000
the nice things though about our first

234
00:07:26,960 --> 00:07:29,840
transformation

235
00:07:28,000 --> 00:07:31,680
is that it uses a new technique that i

236
00:07:29,840 --> 00:07:33,119
will be able to explain recently fully

237
00:07:31,680 --> 00:07:34,800
in the reading time

238
00:07:33,120 --> 00:07:36,479
and this technique also conveys a few of

239
00:07:34,800 --> 00:07:39,840
the important insights that are used in

240
00:07:36,479 --> 00:07:41,360
their second more complex transformation

241
00:07:39,840 --> 00:07:43,758
so for our first transformation we

242
00:07:41,360 --> 00:07:47,120
amplify by nesting our effie

243
00:07:43,759 --> 00:07:48,960
so how do we nest an appy's game

244
00:07:47,120 --> 00:07:50,240
so we'll first start off with a normal

245
00:07:48,960 --> 00:07:52,159
fp scheme

246
00:07:50,240 --> 00:07:54,160
the ciphertext is the usual encryption

247
00:07:52,160 --> 00:07:55,520
the message and the function key is the

248
00:07:54,160 --> 00:07:57,280
usual function key

249
00:07:55,520 --> 00:07:58,960
in this diagram the keychain with the

250
00:07:57,280 --> 00:08:00,000
function f on it indicates the yellow

251
00:07:58,960 --> 00:08:03,758
function key

252
00:08:00,000 --> 00:08:05,680
is for the function f so now we take an

253
00:08:03,759 --> 00:08:07,280
independent fee scheme and lay it on top

254
00:08:05,680 --> 00:08:09,199
of the original version

255
00:08:07,280 --> 00:08:11,039
so the encryption is now the encryption

256
00:08:09,199 --> 00:08:13,360
under first the yellow fe scheme

257
00:08:11,039 --> 00:08:14,080
and then the blue fe scheme for the blue

258
00:08:13,360 --> 00:08:16,000
function key

259
00:08:14,080 --> 00:08:18,719
we create a function key for the

260
00:08:16,000 --> 00:08:21,440
function that will decrypt this input

261
00:08:18,720 --> 00:08:23,840
using a hardwired yellow function key

262
00:08:21,440 --> 00:08:26,240
for function f

263
00:08:23,840 --> 00:08:27,840
now for correctness of our nested game

264
00:08:26,240 --> 00:08:30,080
recall that we want it to be the case

265
00:08:27,840 --> 00:08:32,159
that if we decrypt the blue ciphertext

266
00:08:30,080 --> 00:08:33,439
with the blue function key we should get

267
00:08:32,159 --> 00:08:36,640
f m

268
00:08:33,440 --> 00:08:38,719
so why does this work well

269
00:08:36,640 --> 00:08:40,159
if we decrypt the blue ciphertext with

270
00:08:38,719 --> 00:08:41,760
the blue function key

271
00:08:40,159 --> 00:08:43,439
then we should get the blue function of

272
00:08:41,760 --> 00:08:45,519
the yellow ciphertext

273
00:08:43,440 --> 00:08:47,040
but the blue function is the decryption

274
00:08:45,519 --> 00:08:47,920
of the input with the yellow function

275
00:08:47,040 --> 00:08:49,360
key

276
00:08:47,920 --> 00:08:51,439
so then we are decrypting the yellow

277
00:08:49,360 --> 00:08:54,000
ciphertext with the yellow function key

278
00:08:51,440 --> 00:08:55,760
which gives us f m and so we satisfy

279
00:08:54,000 --> 00:08:58,160
correctness

280
00:08:55,760 --> 00:09:00,080
and as one final note you can also

281
00:08:58,160 --> 00:09:02,319
extend this to nest more than two layers

282
00:09:00,080 --> 00:09:04,640
of fe

283
00:09:02,320 --> 00:09:07,040
now nested fe is a special case of the

284
00:09:04,640 --> 00:09:08,800
more general idea of nested primitives

285
00:09:07,040 --> 00:09:10,640
the intuition here is that if at least

286
00:09:08,800 --> 00:09:12,079
one layer is secure then the whole thing

287
00:09:10,640 --> 00:09:13,680
should be secure

288
00:09:12,080 --> 00:09:15,040
so in order to get the message inside

289
00:09:13,680 --> 00:09:15,920
both the blue and the yellow encryption

290
00:09:15,040 --> 00:09:17,360
shown here

291
00:09:15,920 --> 00:09:18,399
you'd expect that you'd have to break

292
00:09:17,360 --> 00:09:19,839
through both the blue and yellow

293
00:09:18,399 --> 00:09:21,920
encryptions

294
00:09:19,839 --> 00:09:23,360
so again if each layer is broken with

295
00:09:21,920 --> 00:09:24,959
probability epsilon

296
00:09:23,360 --> 00:09:26,640
you'd expect that both layers would be

297
00:09:24,959 --> 00:09:28,079
broken with probability roughly epsilon

298
00:09:26,640 --> 00:09:29,680
squared

299
00:09:28,080 --> 00:09:31,920
and intuitively this makes a lot of

300
00:09:29,680 --> 00:09:33,439
sense but proving it formally is

301
00:09:31,920 --> 00:09:36,560
actually quite difficult

302
00:09:33,440 --> 00:09:38,320
and this is what we will show next

303
00:09:36,560 --> 00:09:40,560
as a last note for the remainder of this

304
00:09:38,320 --> 00:09:42,240
talk instead of considering nested fe

305
00:09:40,560 --> 00:09:44,800
i will instead consider nested public

306
00:09:42,240 --> 00:09:46,560
key encryption as it is simpler

307
00:09:44,800 --> 00:09:49,040
but the techniques i show do also apply

308
00:09:46,560 --> 00:09:51,359
to nested envy

309
00:09:49,040 --> 00:09:52,240
so just a reminder in nested public key

310
00:09:51,360 --> 00:09:53,920
encryption

311
00:09:52,240 --> 00:09:55,760
our ciphertext is formed by first

312
00:09:53,920 --> 00:09:57,439
encrypting under one public key

313
00:09:55,760 --> 00:09:59,040
and then encrypting this encryption

314
00:09:57,440 --> 00:10:00,560
under a second public key

315
00:09:59,040 --> 00:10:02,560
and the secret key is simply the two

316
00:10:00,560 --> 00:10:04,479
individual secret keys

317
00:10:02,560 --> 00:10:05,839
security is the standard notion that the

318
00:10:04,480 --> 00:10:07,680
encryption of message m should be

319
00:10:05,839 --> 00:10:09,760
indistinguishable from encryption of

320
00:10:07,680 --> 00:10:11,359
xero

321
00:10:09,760 --> 00:10:12,959
to prove security we will rely on

322
00:10:11,360 --> 00:10:14,399
hardcore measures

323
00:10:12,959 --> 00:10:16,000
there is actually already a long line of

324
00:10:14,399 --> 00:10:18,320
study on using hardcore measures for

325
00:10:16,000 --> 00:10:19,760
various types of amplification

326
00:10:18,320 --> 00:10:21,440
for those who are not very familiar with

327
00:10:19,760 --> 00:10:23,600
measures a measure is basically just a

328
00:10:21,440 --> 00:10:24,959
generalized notion of distribution

329
00:10:23,600 --> 00:10:26,320
and for the remainder of this talk if

330
00:10:24,959 --> 00:10:27,439
you want to just consider measure to be

331
00:10:26,320 --> 00:10:30,480
a distribution

332
00:10:27,440 --> 00:10:32,560
the talk is still very understandable

333
00:10:30,480 --> 00:10:34,160
so let us now consider a weekly secure

334
00:10:32,560 --> 00:10:36,000
public key encryption scheme

335
00:10:34,160 --> 00:10:38,000
this means that an adversary can

336
00:10:36,000 --> 00:10:39,680
distinguish between encryption of m

337
00:10:38,000 --> 00:10:42,160
and encryption of zero with some

338
00:10:39,680 --> 00:10:43,279
probability epsilon

339
00:10:42,160 --> 00:10:45,680
recall that encryption is a

340
00:10:43,279 --> 00:10:46,320
probabilistic process so epsilon weak

341
00:10:45,680 --> 00:10:48,079
security

342
00:10:46,320 --> 00:10:49,600
could potentially mean that no matter

343
00:10:48,079 --> 00:10:50,399
what randomness you use to encrypt

344
00:10:49,600 --> 00:10:52,560
either the message

345
00:10:50,399 --> 00:10:53,600
or to crimp zero then the adversary

346
00:10:52,560 --> 00:10:55,439
always has at least an

347
00:10:53,600 --> 00:10:57,839
epsilon probability of its own

348
00:10:55,440 --> 00:10:59,680
randomness to break the encryption

349
00:10:57,839 --> 00:11:01,279
in fact the hardcore measure theorems

350
00:10:59,680 --> 00:11:02,319
that show that this is not in fact the

351
00:11:01,279 --> 00:11:04,160
case

352
00:11:02,320 --> 00:11:06,079
it turns out that there's actually a

353
00:11:04,160 --> 00:11:07,439
small hardcore of the randomness

354
00:11:06,079 --> 00:11:09,439
such that if you encrypt using the

355
00:11:07,440 --> 00:11:10,880
hardcore randomness then all slightly

356
00:11:09,440 --> 00:11:12,160
smaller adversaries

357
00:11:10,880 --> 00:11:14,720
have very little distinguishing

358
00:11:12,160 --> 00:11:15,519
advantage that is if you encrypt either

359
00:11:14,720 --> 00:11:17,600
the message m

360
00:11:15,519 --> 00:11:19,360
or zero with the hardcore randomness

361
00:11:17,600 --> 00:11:22,320
then the adversary has a very hard time

362
00:11:19,360 --> 00:11:24,160
distinguishing between the two

363
00:11:22,320 --> 00:11:25,839
and in fact the density of the hardcore

364
00:11:24,160 --> 00:11:26,880
measures is directly related to the

365
00:11:25,839 --> 00:11:29,440
distinguishing advantage of the

366
00:11:26,880 --> 00:11:30,800
adversary on the original primitive

367
00:11:29,440 --> 00:11:32,800
so if the original adversary could

368
00:11:30,800 --> 00:11:34,000
distinguish with probability epsilon

369
00:11:32,800 --> 00:11:37,680
then the density of these hardcore

370
00:11:34,000 --> 00:11:39,440
measures is one minus epsilon

371
00:11:37,680 --> 00:11:41,599
the last note these hardcore measures

372
00:11:39,440 --> 00:11:43,120
depend on the inputs of the encryption

373
00:11:41,600 --> 00:11:45,279
so consider the case here where you

374
00:11:43,120 --> 00:11:46,800
encrypt either m or zero

375
00:11:45,279 --> 00:11:49,200
then you have some hardcore measures for

376
00:11:46,800 --> 00:11:50,160
this process now suppose in the set of

377
00:11:49,200 --> 00:11:52,240
encrypting m

378
00:11:50,160 --> 00:11:53,360
you encrypted some other message and

379
00:11:52,240 --> 00:11:54,800
prime

380
00:11:53,360 --> 00:11:56,560
then you might have completely different

381
00:11:54,800 --> 00:11:58,399
hardcore measures so it might look

382
00:11:56,560 --> 00:11:59,920
something like this

383
00:11:58,399 --> 00:12:02,800
notice that the hardcore measures now

384
00:11:59,920 --> 00:12:04,399
are different than in the previous case

385
00:12:02,800 --> 00:12:06,079
but in summary you should just remember

386
00:12:04,399 --> 00:12:07,360
the following

387
00:12:06,079 --> 00:12:08,839
when you sample from the hardcore

388
00:12:07,360 --> 00:12:10,800
measures you expect to have strong

389
00:12:08,839 --> 00:12:11,040
security meaning that the encryption of

390
00:12:10,800 --> 00:12:12,719
m

391
00:12:11,040 --> 00:12:14,800
and the crypts of zero are strongly

392
00:12:12,720 --> 00:12:16,560
indistinguishable

393
00:12:14,800 --> 00:12:18,719
okay so now let's go back to our nested

394
00:12:16,560 --> 00:12:19,279
game here we will assume that each layer

395
00:12:18,720 --> 00:12:21,360
encryption

396
00:12:19,279 --> 00:12:22,959
is epsilon secure meaning again the

397
00:12:21,360 --> 00:12:24,720
distinguished advantage of the adversary

398
00:12:22,959 --> 00:12:26,560
is at most epsilon

399
00:12:24,720 --> 00:12:28,160
now in the usual case we will sample the

400
00:12:26,560 --> 00:12:30,880
randomness for the blue encryption

401
00:12:28,160 --> 00:12:32,399
from uniform randomness but sampling

402
00:12:30,880 --> 00:12:33,920
from uniform randomness

403
00:12:32,399 --> 00:12:35,839
is equivalent to sampling from the

404
00:12:33,920 --> 00:12:37,439
hardcore measure of the blue encryption

405
00:12:35,839 --> 00:12:39,600
with probability proportional to its

406
00:12:37,440 --> 00:12:40,560
density and sampling from the complement

407
00:12:39,600 --> 00:12:42,000
of this measure

408
00:12:40,560 --> 00:12:44,719
with probability proportional to its

409
00:12:42,000 --> 00:12:45,920
density so we can think of sampling from

410
00:12:44,720 --> 00:12:47,680
uniform randomness

411
00:12:45,920 --> 00:12:49,439
it's sampling from the hardcore the blue

412
00:12:47,680 --> 00:12:50,160
encryption with probability one minus

413
00:12:49,440 --> 00:12:51,920
epsilon

414
00:12:50,160 --> 00:12:53,920
and sampling from its complement with

415
00:12:51,920 --> 00:12:55,680
probability epsilon

416
00:12:53,920 --> 00:12:57,599
now when we sample from the hardcore of

417
00:12:55,680 --> 00:12:58,880
the blue encryption we expect

418
00:12:57,600 --> 00:13:00,800
that our blue encryption will be

419
00:12:58,880 --> 00:13:02,399
strongly secure so

420
00:13:00,800 --> 00:13:04,160
we expect that we should be able to swap

421
00:13:02,399 --> 00:13:05,360
out our blue encryption for encryption

422
00:13:04,160 --> 00:13:06,719
of zero

423
00:13:05,360 --> 00:13:09,519
and in fact this turns out to be the

424
00:13:06,720 --> 00:13:11,279
case the hardcore theorem states that

425
00:13:09,519 --> 00:13:12,880
the outer blue encryption in this case

426
00:13:11,279 --> 00:13:14,800
is strongly indistinguishable from the

427
00:13:12,880 --> 00:13:16,160
encryption zero and since we have

428
00:13:14,800 --> 00:13:17,199
replaced the blue encryption with an

429
00:13:16,160 --> 00:13:19,199
encryption zero

430
00:13:17,200 --> 00:13:20,480
we now have security since we have lost

431
00:13:19,200 --> 00:13:22,320
all information

432
00:13:20,480 --> 00:13:24,399
about the yellow encryption and our

433
00:13:22,320 --> 00:13:26,880
message

434
00:13:24,399 --> 00:13:28,399
now consider the bottom case since we do

435
00:13:26,880 --> 00:13:29,279
not sample from the hardcore of the blue

436
00:13:28,399 --> 00:13:31,120
encryption

437
00:13:29,279 --> 00:13:32,959
we want to instead rely on the security

438
00:13:31,120 --> 00:13:35,200
of the yellow encryption

439
00:13:32,959 --> 00:13:37,119
so again in the normal case the yellow

440
00:13:35,200 --> 00:13:38,320
encryption is encrypting using uniform

441
00:13:37,120 --> 00:13:40,959
randomness

442
00:13:38,320 --> 00:13:42,480
and similarly this is equivalent to

443
00:13:40,959 --> 00:13:43,199
sampling from the hardcore of the yellow

444
00:13:42,480 --> 00:13:45,279
encryption

445
00:13:43,199 --> 00:13:46,639
with probability one minus epsilon and

446
00:13:45,279 --> 00:13:48,639
sampling from the complement of the

447
00:13:46,639 --> 00:13:50,320
yellow hardcore measure with probability

448
00:13:48,639 --> 00:13:52,240
epsilon

449
00:13:50,320 --> 00:13:53,760
now in the case when we sample from

450
00:13:52,240 --> 00:13:55,279
neither hardcore measure

451
00:13:53,760 --> 00:13:57,360
we're just going to give up and call the

452
00:13:55,279 --> 00:13:58,079
thing insecure and this happens the

453
00:13:57,360 --> 00:14:01,440
probability

454
00:13:58,079 --> 00:14:03,359
epsilon squared in the middle case

455
00:14:01,440 --> 00:14:04,639
when we sample from the hardcore of the

456
00:14:03,360 --> 00:14:07,199
yellow encryption

457
00:14:04,639 --> 00:14:08,560
we again expect strong security for the

458
00:14:07,199 --> 00:14:10,160
yellow encryption

459
00:14:08,560 --> 00:14:11,839
so we expect that we should be able to

460
00:14:10,160 --> 00:14:14,000
replace the yellow encryption

461
00:14:11,839 --> 00:14:16,240
with the encryption of zero in fact we

462
00:14:14,000 --> 00:14:17,760
want something that looks like this

463
00:14:16,240 --> 00:14:19,440
we want to show that you can swap out

464
00:14:17,760 --> 00:14:20,000
the yellow encryption with an encryption

465
00:14:19,440 --> 00:14:21,680
zero

466
00:14:20,000 --> 00:14:23,440
which would give us security because

467
00:14:21,680 --> 00:14:26,239
encryption zero would completely wipe

468
00:14:23,440 --> 00:14:28,639
out information about the message m

469
00:14:26,240 --> 00:14:29,440
so this is what we want and now let's

470
00:14:28,639 --> 00:14:33,279
focus in

471
00:14:29,440 --> 00:14:35,199
on how we can achieve this okay

472
00:14:33,279 --> 00:14:36,560
so we know that the encryption m is

473
00:14:35,199 --> 00:14:37,839
strongly indistinguishable from the

474
00:14:36,560 --> 00:14:39,040
decryption of zero

475
00:14:37,839 --> 00:14:40,800
when the randomness for these

476
00:14:39,040 --> 00:14:41,920
encryptions are drawn from the hardcore

477
00:14:40,800 --> 00:14:43,680
measures

478
00:14:41,920 --> 00:14:45,199
and now we want to show that the two

479
00:14:43,680 --> 00:14:48,239
cases from before

480
00:14:45,199 --> 00:14:50,959
are also strongly indistinguishable so

481
00:14:48,240 --> 00:14:52,720
how might this reduction work we will

482
00:14:50,959 --> 00:14:53,439
first receive a mystery yellow

483
00:14:52,720 --> 00:14:55,600
encryption

484
00:14:53,440 --> 00:14:56,880
which is either an encryption of 0 or

485
00:14:55,600 --> 00:14:58,399
encryption of m

486
00:14:56,880 --> 00:15:00,000
where the randomness is drawn from the

487
00:14:58,399 --> 00:15:02,240
hardcore measures

488
00:15:00,000 --> 00:15:03,600
and then to finish the reduction we will

489
00:15:02,240 --> 00:15:04,160
just sample randomness from the blue

490
00:15:03,600 --> 00:15:05,279
measure

491
00:15:04,160 --> 00:15:08,000
and use it to compute the blue

492
00:15:05,279 --> 00:15:08,639
encryption and now it looks like we're

493
00:15:08,000 --> 00:15:10,800
done

494
00:15:08,639 --> 00:15:12,000
the two cases we end up with are the two

495
00:15:10,800 --> 00:15:13,920
cases we wanted to show are

496
00:15:12,000 --> 00:15:17,040
computationally indistinguishable

497
00:15:13,920 --> 00:15:19,519
so great what's the problem here

498
00:15:17,040 --> 00:15:20,399
so there are actually two problems first

499
00:15:19,519 --> 00:15:22,160
the blue measure

500
00:15:20,399 --> 00:15:24,639
might not be efficiently samplable or

501
00:15:22,160 --> 00:15:26,000
computable recall that the blue measure

502
00:15:24,639 --> 00:15:28,000
is the complement of the hardcore

503
00:15:26,000 --> 00:15:30,160
measure of the blue encryption and in

504
00:15:28,000 --> 00:15:31,199
fact we only know that there exists such

505
00:15:30,160 --> 00:15:32,560
a measure

506
00:15:31,199 --> 00:15:34,319
so we might not be able to efficiently

507
00:15:32,560 --> 00:15:34,959
sample from it which means that this

508
00:15:34,320 --> 00:15:38,240
reduction

509
00:15:34,959 --> 00:15:40,160
might also not be efficient

510
00:15:38,240 --> 00:15:41,759
secondly it turns out that the hardcore

511
00:15:40,160 --> 00:15:43,839
measure of the blue encryption

512
00:15:41,759 --> 00:15:45,279
depends on what we're encrypting and so

513
00:15:43,839 --> 00:15:45,839
we might have two different blue

514
00:15:45,279 --> 00:15:47,199
measures

515
00:15:45,839 --> 00:15:50,800
depending on whether we received an

516
00:15:47,199 --> 00:15:53,199
encryption of zero or an encryption m

517
00:15:50,800 --> 00:15:55,120
to clarify this point recall that the

518
00:15:53,199 --> 00:15:56,399
hardcore measures depend on the input to

519
00:15:55,120 --> 00:15:58,000
the encryption

520
00:15:56,399 --> 00:16:00,160
and previously we had noted that if you

521
00:15:58,000 --> 00:16:03,920
encrypted m prime instead of m

522
00:16:00,160 --> 00:16:03,920
then your hardcore measures might change

523
00:16:04,480 --> 00:16:08,000
so returning back to our diagram we see

524
00:16:06,480 --> 00:16:09,519
that the blue hardcore measure may

525
00:16:08,000 --> 00:16:10,399
depend on which yellow encryption we

526
00:16:09,519 --> 00:16:11,920
received

527
00:16:10,399 --> 00:16:13,440
and the blue measure in the case when we

528
00:16:11,920 --> 00:16:14,880
have a yellow encryption m

529
00:16:13,440 --> 00:16:16,000
may be different from the blue measure

530
00:16:14,880 --> 00:16:17,759
in the case where we have a yellow

531
00:16:16,000 --> 00:16:19,360
encryption of zero

532
00:16:17,759 --> 00:16:20,959
and so now it's unclear how we should

533
00:16:19,360 --> 00:16:22,480
carry out this reduction

534
00:16:20,959 --> 00:16:24,800
we need a sample randomness for this

535
00:16:22,480 --> 00:16:26,639
blue encryption but we don't know which

536
00:16:24,800 --> 00:16:28,399
measure the sample from

537
00:16:26,639 --> 00:16:31,440
and both measures might not be efficient

538
00:16:28,399 --> 00:16:33,680
to sample from anyway

539
00:16:31,440 --> 00:16:34,959
to solve the first problem we will

540
00:16:33,680 --> 00:16:37,758
efficiently simulate

541
00:16:34,959 --> 00:16:39,199
the blue measures so we will first

542
00:16:37,759 --> 00:16:40,720
observe that the blue complement

543
00:16:39,199 --> 00:16:43,199
hardcore measure

544
00:16:40,720 --> 00:16:44,880
actually has high density and by a

545
00:16:43,199 --> 00:16:46,479
theorem from ttv09

546
00:16:44,880 --> 00:16:49,279
it turns out that all high density

547
00:16:46,480 --> 00:16:51,440
measures can be efficiently simulated

548
00:16:49,279 --> 00:16:53,120
so consider a function f that takes the

549
00:16:51,440 --> 00:16:55,120
input either the encryption of m

550
00:16:53,120 --> 00:16:56,560
or the encryption of 0 computes the

551
00:16:55,120 --> 00:16:58,320
corresponding blue measure

552
00:16:56,560 --> 00:17:00,000
and then outputs a sample from the blue

553
00:16:58,320 --> 00:17:02,320
measure then

554
00:17:00,000 --> 00:17:04,640
since the output of f has high density

555
00:17:02,320 --> 00:17:06,319
then there exists an efficient simulator

556
00:17:04,640 --> 00:17:08,160
that given the yellow encryption can

557
00:17:06,319 --> 00:17:10,480
output a sample from a distribution that

558
00:17:08,160 --> 00:17:12,160
is computationally indistinguishable

559
00:17:10,480 --> 00:17:14,160
from the corresponding blue complement

560
00:17:12,160 --> 00:17:15,520
hardcore measure

561
00:17:14,160 --> 00:17:17,280
and so now we have solved our first

562
00:17:15,520 --> 00:17:19,039
problem instead of sampling from the

563
00:17:17,280 --> 00:17:20,160
blue measure we'll instead sample from

564
00:17:19,039 --> 00:17:22,799
the simulated measure

565
00:17:20,160 --> 00:17:25,199
which should be indistinguishable and as

566
00:17:22,799 --> 00:17:26,000
a final note instead of using ttv09

567
00:17:25,199 --> 00:17:27,760
directly

568
00:17:26,000 --> 00:17:30,080
we actually use a theorem from scorsky

569
00:17:27,760 --> 00:17:33,840
15 which is a leakage simulation variant

570
00:17:30,080 --> 00:17:36,000
of the theorem from ttv09

571
00:17:33,840 --> 00:17:38,159
so now we want to fix problem two we

572
00:17:36,000 --> 00:17:39,919
want the simulator to be independent of

573
00:17:38,160 --> 00:17:42,720
the yellow encryption

574
00:17:39,919 --> 00:17:43,600
so how can we do this now the key

575
00:17:42,720 --> 00:17:45,919
observation

576
00:17:43,600 --> 00:17:47,678
is that the efficiency of the simulator

577
00:17:45,919 --> 00:17:50,160
is only dependent on the output of

578
00:17:47,679 --> 00:17:51,440
f so it doesn't matter if we increase

579
00:17:50,160 --> 00:17:53,360
the runtime of f

580
00:17:51,440 --> 00:17:55,200
we just need to somehow get f to take in

581
00:17:53,360 --> 00:17:56,559
some input that is not very dependent on

582
00:17:55,200 --> 00:17:58,480
the yellow encryption

583
00:17:56,559 --> 00:18:00,000
so that our simulator also doesn't need

584
00:17:58,480 --> 00:18:04,160
direct access to the yellow

585
00:18:00,000 --> 00:18:06,640
encryption so to do this we will use a

586
00:18:04,160 --> 00:18:07,919
commitment of the hidden information

587
00:18:06,640 --> 00:18:10,080
instead of receiving the yellow

588
00:18:07,919 --> 00:18:10,880
encryption directly both after the

589
00:18:10,080 --> 00:18:12,720
simulator

590
00:18:10,880 --> 00:18:14,480
will instead receive a commitment of the

591
00:18:12,720 --> 00:18:16,320
yellow encryption

592
00:18:14,480 --> 00:18:18,400
now f does need to know the yellow

593
00:18:16,320 --> 00:18:19,439
encryption in order to compute the blue

594
00:18:18,400 --> 00:18:22,160
measures

595
00:18:19,440 --> 00:18:23,520
so we will modify f so the brute force

596
00:18:22,160 --> 00:18:26,000
breaks open the commitment

597
00:18:23,520 --> 00:18:27,600
to retrieve the yellow encryption this

598
00:18:26,000 --> 00:18:29,039
way f can still compute the blue

599
00:18:27,600 --> 00:18:31,280
measures

600
00:18:29,039 --> 00:18:33,039
now one might think that giving both f

601
00:18:31,280 --> 00:18:34,960
and the simulator a commitment

602
00:18:33,039 --> 00:18:36,799
is so that the actual values would harm

603
00:18:34,960 --> 00:18:38,880
the efficiency of the simulator

604
00:18:36,799 --> 00:18:40,720
but in fact the simulator is just as

605
00:18:38,880 --> 00:18:42,720
efficient as before

606
00:18:40,720 --> 00:18:44,640
this is because the efficiency of the

607
00:18:42,720 --> 00:18:48,240
simulator only depends on the output of

608
00:18:44,640 --> 00:18:48,240
f which is unchanged

609
00:18:48,320 --> 00:18:52,399
so now we have the problem the simulator

610
00:18:50,640 --> 00:18:56,799
needs to know what yellow encryption

611
00:18:52,400 --> 00:18:58,480
to commit to but this is a commitment

612
00:18:56,799 --> 00:19:00,320
and a commitment should hide the

613
00:18:58,480 --> 00:19:02,160
information inside it

614
00:19:00,320 --> 00:19:04,320
so in fact we can swap out the

615
00:19:02,160 --> 00:19:06,880
commitment of the yellow encryption

616
00:19:04,320 --> 00:19:08,559
with a commitment of zero and if the

617
00:19:06,880 --> 00:19:10,160
commitment is strong enough

618
00:19:08,559 --> 00:19:12,080
the night of the adversary nor the

619
00:19:10,160 --> 00:19:13,679
simulator should be able to tell the

620
00:19:12,080 --> 00:19:16,000
difference

621
00:19:13,679 --> 00:19:17,200
but this means that we can now simulate

622
00:19:16,000 --> 00:19:18,880
either the blue measures

623
00:19:17,200 --> 00:19:20,400
by simply running the simulator on the

624
00:19:18,880 --> 00:19:22,240
encryption of zero

625
00:19:20,400 --> 00:19:24,080
so now our simulator is independent of

626
00:19:22,240 --> 00:19:27,520
which yellow encryption we have

627
00:19:24,080 --> 00:19:27,520
and this solves the second problem

628
00:19:28,000 --> 00:19:32,799
returning back to our original reduction

629
00:19:30,320 --> 00:19:35,918
we see that we had two problems

630
00:19:32,799 --> 00:19:37,918
first to compute the blue encryption we

631
00:19:35,919 --> 00:19:40,400
needed to sample from some blue measures

632
00:19:37,919 --> 00:19:42,320
that might not be efficiently samplable

633
00:19:40,400 --> 00:19:44,240
and secondly which measure we needed to

634
00:19:42,320 --> 00:19:46,559
sample from dependent on which yellow

635
00:19:44,240 --> 00:19:48,480
encryption we received

636
00:19:46,559 --> 00:19:50,240
so to fix these problems we can now use

637
00:19:48,480 --> 00:19:51,760
our simulator

638
00:19:50,240 --> 00:19:53,440
instead of sampling the randomness for

639
00:19:51,760 --> 00:19:55,679
the blue encryption from one of two

640
00:19:53,440 --> 00:19:57,520
potentially hard to compute measures

641
00:19:55,679 --> 00:19:59,200
we can instead sample the randomness by

642
00:19:57,520 --> 00:20:00,559
running our simulator on a commitment of

643
00:19:59,200 --> 00:20:02,880
zero

644
00:20:00,559 --> 00:20:04,240
and by what we just showed the simulated

645
00:20:02,880 --> 00:20:05,440
measure is computationally

646
00:20:04,240 --> 00:20:06,720
indistinguishable

647
00:20:05,440 --> 00:20:08,960
from each of the blue complement

648
00:20:06,720 --> 00:20:10,640
hardcore measures and so now we have the

649
00:20:08,960 --> 00:20:12,480
reduction we want

650
00:20:10,640 --> 00:20:16,159
and we can show that these two cases are

651
00:20:12,480 --> 00:20:16,159
computationally indistinguishable

652
00:20:16,480 --> 00:20:20,240
going back to the original diagram we

653
00:20:18,480 --> 00:20:20,880
see that with probability one minus

654
00:20:20,240 --> 00:20:22,559
epsilon

655
00:20:20,880 --> 00:20:24,559
we sample from the hardcore measure of

656
00:20:22,559 --> 00:20:25,280
the blue encryption and by the hardcore

657
00:20:24,559 --> 00:20:26,799
lemma

658
00:20:25,280 --> 00:20:28,960
this means that we can swap out the blue

659
00:20:26,799 --> 00:20:30,639
encryption with an encryption of zero

660
00:20:28,960 --> 00:20:32,400
which is secure since it completely

661
00:20:30,640 --> 00:20:34,960
erases all information

662
00:20:32,400 --> 00:20:35,919
about the encrypted message and then

663
00:20:34,960 --> 00:20:38,480
with probability

664
00:20:35,919 --> 00:20:39,919
epsilon times one minus epsilon we

665
00:20:38,480 --> 00:20:41,200
sample from the hardcore measure of the

666
00:20:39,919 --> 00:20:43,120
yellow encryption

667
00:20:41,200 --> 00:20:44,480
which by the reduction we just showed

668
00:20:43,120 --> 00:20:45,199
means that we can swap out the yellow

669
00:20:44,480 --> 00:20:47,919
encryption

670
00:20:45,200 --> 00:20:49,760
with an encryption of zero and this is

671
00:20:47,919 --> 00:20:51,120
also secure since we have also erased

672
00:20:49,760 --> 00:20:52,640
all information about the encrypted

673
00:20:51,120 --> 00:20:54,639
message

674
00:20:52,640 --> 00:20:55,919
and then finally with probability

675
00:20:54,640 --> 00:20:58,000
epsilon squared

676
00:20:55,919 --> 00:20:59,520
we sample from neither hardcore measure

677
00:20:58,000 --> 00:21:02,960
in which case we give up

678
00:20:59,520 --> 00:21:05,200
and say it's insecure

679
00:21:02,960 --> 00:21:06,960
and so indeed we get the intuitive

680
00:21:05,200 --> 00:21:09,280
result we expected

681
00:21:06,960 --> 00:21:10,880
that is if one layer is broken with

682
00:21:09,280 --> 00:21:12,639
probability epsilon

683
00:21:10,880 --> 00:21:14,000
then both layers are broken with

684
00:21:12,640 --> 00:21:16,960
probability roughly

685
00:21:14,000 --> 00:21:17,919
epsilon squared and so we have achieved

686
00:21:16,960 --> 00:21:20,880
amplification

687
00:21:17,919 --> 00:21:20,880
of nested primitives

688
00:21:21,280 --> 00:21:25,678
in summary we show that you can amplify

689
00:21:23,600 --> 00:21:26,678
fe from constant security to full

690
00:21:25,679 --> 00:21:29,440
security

691
00:21:26,679 --> 00:21:31,360
unconditionally in this transformation

692
00:21:29,440 --> 00:21:33,280
preserves compactness

693
00:21:31,360 --> 00:21:36,080
we also show how to amplify nested

694
00:21:33,280 --> 00:21:38,158
primitives with our new technique

695
00:21:36,080 --> 00:21:40,080
and finally we introduce our new set

696
00:21:38,159 --> 00:21:42,320
homomorphic secret sharing scheme

697
00:21:40,080 --> 00:21:43,678
which may be of independent interest

698
00:21:42,320 --> 00:21:44,559
this is used in our second more

699
00:21:43,679 --> 00:21:47,120
complicated step

700
00:21:44,559 --> 00:21:48,639
of amplification i encourage you to read

701
00:21:47,120 --> 00:21:50,320
the full version of our paper for more

702
00:21:48,640 --> 00:21:55,200
details

703
00:21:50,320 --> 00:21:55,200
thank you

