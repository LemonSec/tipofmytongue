1
00:00:00,880 --> 00:00:04,799
hi i am ostridge ghoshan and this is

2
00:00:03,040 --> 00:00:07,440
joint work with joseph jager

3
00:00:04,799 --> 00:00:07,919
and stefano tessero very broadly this

4
00:00:07,440 --> 00:00:09,840
work

5
00:00:07,919 --> 00:00:12,960
asks whether we can prove time memory

6
00:00:09,840 --> 00:00:15,519
tradeoffs for authenticated encryption

7
00:00:12,960 --> 00:00:17,279
in general concrete security theorems

8
00:00:15,519 --> 00:00:19,039
attempt to prove an upper bound on the

9
00:00:17,279 --> 00:00:21,359
advantage of an adversary

10
00:00:19,039 --> 00:00:24,160
in breaking security in terms of the

11
00:00:21,359 --> 00:00:26,160
resources of the adversary

12
00:00:24,160 --> 00:00:27,840
in most prior work the resources

13
00:00:26,160 --> 00:00:28,960
considered are an adversary's time

14
00:00:27,840 --> 00:00:30,880
complexity

15
00:00:28,960 --> 00:00:32,800
and data complexity or the number of

16
00:00:30,880 --> 00:00:35,040
queries

17
00:00:32,800 --> 00:00:37,760
in this work we additionally consider

18
00:00:35,040 --> 00:00:39,280
the adversary's memory as a resource

19
00:00:37,760 --> 00:00:41,199
this is important because the

20
00:00:39,280 --> 00:00:43,360
feasibility of a certain attack

21
00:00:41,200 --> 00:00:45,680
might be seriously affected by the

22
00:00:43,360 --> 00:00:48,640
amount of available memory

23
00:00:45,680 --> 00:00:51,680
hence concrete security analysis should

24
00:00:48,640 --> 00:00:51,680
take this into account

25
00:00:52,399 --> 00:00:56,559
even though this question is clearly

26
00:00:54,160 --> 00:00:59,038
fundamental only very recently

27
00:00:56,559 --> 00:01:00,800
we have seen some prior work on this and

28
00:00:59,039 --> 00:01:02,480
it has generally taken one of two

29
00:01:00,800 --> 00:01:04,640
approaches

30
00:01:02,480 --> 00:01:06,479
the first gives time memory trade-offs

31
00:01:04,640 --> 00:01:08,720
for symmetric encryption

32
00:01:06,479 --> 00:01:10,840
well the second focuses on either giving

33
00:01:08,720 --> 00:01:13,039
or proving impossibility of memory type

34
00:01:10,840 --> 00:01:14,960
reductions

35
00:01:13,040 --> 00:01:17,040
we will encounter more precisely what

36
00:01:14,960 --> 00:01:19,439
these things are later on in the talk

37
00:01:17,040 --> 00:01:21,600
the former approach has mainly focused

38
00:01:19,439 --> 00:01:24,839
on confidentiality of encryption

39
00:01:21,600 --> 00:01:26,479
while the latter has focused on public

40
00:01:24,840 --> 00:01:28,479
economy

41
00:01:26,479 --> 00:01:30,320
in this work we shall combine elements

42
00:01:28,479 --> 00:01:31,280
from both lines of work for the first

43
00:01:30,320 --> 00:01:33,520
time

44
00:01:31,280 --> 00:01:34,799
we ask whether we can lift the time

45
00:01:33,520 --> 00:01:36,720
memory trade-offs for the

46
00:01:34,799 --> 00:01:38,479
confidentiality of encryption

47
00:01:36,720 --> 00:01:40,560
to the non-based authenticated

48
00:01:38,479 --> 00:01:43,119
encryption setting

49
00:01:40,560 --> 00:01:44,320
very briefly the take away message from

50
00:01:43,119 --> 00:01:47,119
our work is

51
00:01:44,320 --> 00:01:47,758
it's complicated we provide both

52
00:01:47,119 --> 00:01:51,280
positive

53
00:01:47,759 --> 00:01:53,040
and negative results since this talk is

54
00:01:51,280 --> 00:01:55,200
about non-based encryption

55
00:01:53,040 --> 00:01:56,399
let me quickly refresh what i mean by

56
00:01:55,200 --> 00:01:58,479
that

57
00:01:56,399 --> 00:02:00,159
a noise based encryption scheme consists

58
00:01:58,479 --> 00:02:02,079
of three algorithms

59
00:02:00,159 --> 00:02:04,399
the key generation algorithm returns a

60
00:02:02,079 --> 00:02:06,719
key the encryption algorithm

61
00:02:04,399 --> 00:02:09,440
takes as input a message and a non along

62
00:02:06,719 --> 00:02:11,440
with the key and returns the ciphertext

63
00:02:09,440 --> 00:02:13,200
the decryption algorithm takes as input

64
00:02:11,440 --> 00:02:13,599
a nonce and a ciphertext along with the

65
00:02:13,200 --> 00:02:16,000
key

66
00:02:13,599 --> 00:02:19,359
and either returns a message or the

67
00:02:16,000 --> 00:02:21,280
bottom symbol indicating failure

68
00:02:19,360 --> 00:02:24,000
a non-based encryption scheme guarantees

69
00:02:21,280 --> 00:02:27,120
security only if encryption is done

70
00:02:24,000 --> 00:02:28,879
under distinct nonsense

71
00:02:27,120 --> 00:02:30,959
there has been a long line of work

72
00:02:28,879 --> 00:02:32,959
proving concrete security of non-based

73
00:02:30,959 --> 00:02:35,440
authenticated encryption

74
00:02:32,959 --> 00:02:36,959
these works of course ignored the memory

75
00:02:35,440 --> 00:02:39,599
of the bursary

76
00:02:36,959 --> 00:02:43,040
now the question here is can we extend

77
00:02:39,599 --> 00:02:46,160
them to take memory into account

78
00:02:43,040 --> 00:02:47,040
well the problem has already been very

79
00:02:46,160 --> 00:02:49,280
hard for

80
00:02:47,040 --> 00:02:51,040
just for the case of confidentiality

81
00:02:49,280 --> 00:02:53,280
without the additional property of

82
00:02:51,040 --> 00:02:55,760
integrity that we need for authenticated

83
00:02:53,280 --> 00:02:55,760
encryption

84
00:02:55,840 --> 00:03:00,000
to illustrate this here is a toy example

85
00:02:58,080 --> 00:03:02,400
of a nonce based encryption scheme

86
00:03:00,000 --> 00:03:03,840
based on a n-bit block cipher it just

87
00:03:02,400 --> 00:03:04,640
encrypts the nonce using the block

88
00:03:03,840 --> 00:03:07,680
cipher

89
00:03:04,640 --> 00:03:09,440
and exerts the message with it

90
00:03:07,680 --> 00:03:11,680
one can prove this theorem which is a

91
00:03:09,440 --> 00:03:13,280
corollary of two previous works

92
00:03:11,680 --> 00:03:15,680
one of which makes connections to

93
00:03:13,280 --> 00:03:17,519
communication complexity

94
00:03:15,680 --> 00:03:19,680
it proves an upper bound on the

95
00:03:17,519 --> 00:03:20,239
advantage of distinguishing ciphertext

96
00:03:19,680 --> 00:03:22,640
from

97
00:03:20,239 --> 00:03:23,680
random which is the standard notion for

98
00:03:22,640 --> 00:03:26,798
confidentiality

99
00:03:23,680 --> 00:03:28,879
for non-based encryption

100
00:03:26,799 --> 00:03:31,040
in particular the advantage of an

101
00:03:28,879 --> 00:03:32,000
adversary can be upper bounded in terms

102
00:03:31,040 --> 00:03:34,159
of its memory

103
00:03:32,000 --> 00:03:36,159
and number of encryption and the

104
00:03:34,159 --> 00:03:37,519
advantage of breaking the underlying

105
00:03:36,159 --> 00:03:40,159
block cipher is a pseudo random

106
00:03:37,519 --> 00:03:40,159
permutation

107
00:03:40,480 --> 00:03:44,159
the first term here shows that there is

108
00:03:42,560 --> 00:03:46,000
a time memory trade-off

109
00:03:44,159 --> 00:03:47,359
for breaking the confidentiality of the

110
00:03:46,000 --> 00:03:48,959
scheme

111
00:03:47,360 --> 00:03:51,280
the reason we want to have such

112
00:03:48,959 --> 00:03:53,200
tradeoffs is that it gives us exactly

113
00:03:51,280 --> 00:03:54,239
how many queries our memory bounded

114
00:03:53,200 --> 00:03:57,439
adversary

115
00:03:54,239 --> 00:03:58,480
needs to make to break security for

116
00:03:57,439 --> 00:04:00,400
example

117
00:03:58,480 --> 00:04:02,560
for adversaries with memory less than 2

118
00:04:00,400 --> 00:04:05,040
power n by 2 we get beyond both the

119
00:04:02,560 --> 00:04:08,159
security here

120
00:04:05,040 --> 00:04:11,280
so we ask whether we can prove

121
00:04:08,159 --> 00:04:12,000
similar results for a security in

122
00:04:11,280 --> 00:04:16,480
particular

123
00:04:12,000 --> 00:04:16,480
for widely used schemes like gcm

124
00:04:17,040 --> 00:04:22,639
we target the notion of ae that combines

125
00:04:20,000 --> 00:04:24,160
confidentiality and integrity

126
00:04:22,639 --> 00:04:26,720
the usual approach is to prove

127
00:04:24,160 --> 00:04:29,440
separately a bound on indar security

128
00:04:26,720 --> 00:04:30,479
that is indistinguishability from random

129
00:04:29,440 --> 00:04:32,719
ciphertext

130
00:04:30,479 --> 00:04:34,159
and a bound on c text security that is

131
00:04:32,720 --> 00:04:38,320
ciphertext integrity

132
00:04:34,160 --> 00:04:40,479
and then combine them to show aec

133
00:04:38,320 --> 00:04:41,599
this can be cast as a concrete security

134
00:04:40,479 --> 00:04:43,520
theorem that

135
00:04:41,600 --> 00:04:45,840
upper bounds the advantage against a

136
00:04:43,520 --> 00:04:46,320
security in terms of the advantages

137
00:04:45,840 --> 00:04:49,359
against

138
00:04:46,320 --> 00:04:51,520
indar and ctek securities

139
00:04:49,360 --> 00:04:53,520
the question however is how does this

140
00:04:51,520 --> 00:04:55,359
result look like when we take memory

141
00:04:53,520 --> 00:04:58,159
into account

142
00:04:55,360 --> 00:04:59,120
ideally we want a memory tight reduction

143
00:04:58,160 --> 00:05:03,680
that is

144
00:04:59,120 --> 00:05:03,680
we want s1 and s2 to be very close to us

145
00:05:03,759 --> 00:05:08,320
unfortunately the known reduction is not

146
00:05:06,639 --> 00:05:11,840
memory type

147
00:05:08,320 --> 00:05:11,840
let's see why

148
00:05:12,400 --> 00:05:16,080
let me be a bit more precise this

149
00:05:14,960 --> 00:05:18,719
combined notion

150
00:05:16,080 --> 00:05:20,960
of security of authenticated encryption

151
00:05:18,720 --> 00:05:22,800
considers a real world where the key is

152
00:05:20,960 --> 00:05:24,799
generated and the adversary is given

153
00:05:22,800 --> 00:05:26,960
access to two oracles

154
00:05:24,800 --> 00:05:28,560
one issuing encryption of messages under

155
00:05:26,960 --> 00:05:30,719
the chosen nonce

156
00:05:28,560 --> 00:05:32,639
and the other one decrypting ciphertext

157
00:05:30,720 --> 00:05:34,479
under a chosen means

158
00:05:32,639 --> 00:05:36,240
this is compared with an ideal world

159
00:05:34,479 --> 00:05:38,000
where the encryption oracle provides

160
00:05:36,240 --> 00:05:40,560
random ciphertext

161
00:05:38,000 --> 00:05:41,440
and the decryption oracle provides only

162
00:05:40,560 --> 00:05:43,280
decryptions

163
00:05:41,440 --> 00:05:46,080
if the message was previously encrypted

164
00:05:43,280 --> 00:05:46,080
with the same notes

165
00:05:46,160 --> 00:05:49,680
we need to upper bound the advantage of

166
00:05:48,639 --> 00:05:52,800
an adversary

167
00:05:49,680 --> 00:05:54,000
running in time t making q queries and

168
00:05:52,800 --> 00:05:57,520
using memory s

169
00:05:54,000 --> 00:05:57,520
of distinguishing between these two

170
00:05:58,000 --> 00:06:01,759
the traditional approach first

171
00:05:59,759 --> 00:06:03,919
introduces an intermediate world

172
00:06:01,759 --> 00:06:06,240
in which the adversary has access to the

173
00:06:03,919 --> 00:06:07,919
encryption oracle from the real world

174
00:06:06,240 --> 00:06:10,080
and the decryption oracle from the ideal

175
00:06:07,919 --> 00:06:12,159
world

176
00:06:10,080 --> 00:06:13,919
it is actually easy to upper bound the

177
00:06:12,160 --> 00:06:15,680
advantage in distinguishing the real

178
00:06:13,919 --> 00:06:18,240
world from the intermediate world

179
00:06:15,680 --> 00:06:20,000
by invoking c tech security and this

180
00:06:18,240 --> 00:06:22,400
reduction is actually memory

181
00:06:20,000 --> 00:06:23,680
type meaning that the resources of the

182
00:06:22,400 --> 00:06:25,919
sea tech's adversary

183
00:06:23,680 --> 00:06:28,080
are almost same as that of the 88

184
00:06:25,919 --> 00:06:30,318
percent

185
00:06:28,080 --> 00:06:32,560
the real problem occurs in upper

186
00:06:30,319 --> 00:06:34,400
bounding the advantage of distinguishing

187
00:06:32,560 --> 00:06:35,600
the intermediate world from the ideal

188
00:06:34,400 --> 00:06:37,919
world

189
00:06:35,600 --> 00:06:39,600
here we need to assume inner security

190
00:06:37,919 --> 00:06:42,400
for an amount of memory

191
00:06:39,600 --> 00:06:43,039
that grows with the number of queries we

192
00:06:42,400 --> 00:06:48,000
shall see

193
00:06:43,039 --> 00:06:51,199
why that is the case next

194
00:06:48,000 --> 00:06:54,720
remember that indoor security only gives

195
00:06:51,199 --> 00:06:56,720
us the corresponding encryption oracle

196
00:06:54,720 --> 00:06:58,639
if we want to simulate the two words

197
00:06:56,720 --> 00:06:59,680
that the a adversary is trying to

198
00:06:58,639 --> 00:07:01,520
distinguish

199
00:06:59,680 --> 00:07:03,280
we would need to simulate the ideal

200
00:07:01,520 --> 00:07:04,000
decryption oracle which requires

201
00:07:03,280 --> 00:07:07,039
remembering

202
00:07:04,000 --> 00:07:09,360
all the ciphertexts so

203
00:07:07,039 --> 00:07:11,199
the memory grows linearly in the number

204
00:07:09,360 --> 00:07:14,560
of queries

205
00:07:11,199 --> 00:07:16,560
well this was one particular proof

206
00:07:14,560 --> 00:07:18,560
the question is whether we can come up

207
00:07:16,560 --> 00:07:20,240
with a clever proof that bypasses this

208
00:07:18,560 --> 00:07:23,759
problem

209
00:07:20,240 --> 00:07:26,639
that brings us to our contributions

210
00:07:23,759 --> 00:07:28,080
in a nutshell our results are centered

211
00:07:26,639 --> 00:07:30,080
around the question

212
00:07:28,080 --> 00:07:31,440
whether we can make the reduction memory

213
00:07:30,080 --> 00:07:34,159
type

214
00:07:31,440 --> 00:07:36,000
first of all we show that we can indeed

215
00:07:34,160 --> 00:07:38,639
make this reduction memory type

216
00:07:36,000 --> 00:07:39,599
in the restricted setting of channels

217
00:07:38,639 --> 00:07:43,280
this setting

218
00:07:39,599 --> 00:07:45,840
captures usage in protocols like tls

219
00:07:43,280 --> 00:07:47,679
we introduce memory adaptive reductions

220
00:07:45,840 --> 00:07:48,638
a new technique for giving memory tight

221
00:07:47,680 --> 00:07:50,160
reduction

222
00:07:48,639 --> 00:07:53,120
where the memory of the reduction

223
00:07:50,160 --> 00:07:55,440
depends on the memory of the adversary

224
00:07:53,120 --> 00:07:56,800
secondly we give an impossibility result

225
00:07:55,440 --> 00:07:59,039
for a memory type reduction

226
00:07:56,800 --> 00:08:01,840
in the most general setting of nonce

227
00:07:59,039 --> 00:08:03,599
based authenticated encryption

228
00:08:01,840 --> 00:08:05,198
next i shall introduce the channel

229
00:08:03,599 --> 00:08:08,080
setting and talk about the memory

230
00:08:05,199 --> 00:08:08,080
adaptive reduction

231
00:08:08,639 --> 00:08:12,080
the channel setting is motivated by the

232
00:08:10,560 --> 00:08:14,400
typical use of authenticated

233
00:08:12,080 --> 00:08:16,000
encryption as a means to establish a

234
00:08:14,400 --> 00:08:19,120
secure communication channel

235
00:08:16,000 --> 00:08:21,360
as in tls in particular

236
00:08:19,120 --> 00:08:22,560
only certain restricted adversarial

237
00:08:21,360 --> 00:08:24,960
interactions can offer

238
00:08:22,560 --> 00:08:26,639
for example nonsense are implicit they

239
00:08:24,960 --> 00:08:28,479
are used as a counter

240
00:08:26,639 --> 00:08:29,919
the receiver aborts upon the first

241
00:08:28,479 --> 00:08:32,159
encryption failure

242
00:08:29,919 --> 00:08:34,958
one goal in particular is to ensure

243
00:08:32,159 --> 00:08:37,360
inorder delivery of messages

244
00:08:34,958 --> 00:08:40,478
the channel setting that we use captures

245
00:08:37,360 --> 00:08:43,120
this exactly

246
00:08:40,479 --> 00:08:44,240
a bit more precisely a channel consists

247
00:08:43,120 --> 00:08:47,360
of three algorithms

248
00:08:44,240 --> 00:08:49,440
state generation sender and receiver

249
00:08:47,360 --> 00:08:52,080
the state generation algorithm generates

250
00:08:49,440 --> 00:08:54,399
initial sender and receiver states

251
00:08:52,080 --> 00:08:55,839
the center algorithm takes as input the

252
00:08:54,399 --> 00:08:57,839
sender state and message

253
00:08:55,839 --> 00:08:59,600
and outputs the updated sender state and

254
00:08:57,839 --> 00:09:01,519
a ciphertext

255
00:08:59,600 --> 00:09:03,839
the receiver algorithm takes as input

256
00:09:01,519 --> 00:09:05,839
the receiver state and ciphertext

257
00:09:03,839 --> 00:09:07,600
and returns as output the updated

258
00:09:05,839 --> 00:09:11,760
receiver state and either

259
00:09:07,600 --> 00:09:11,760
a message or the error symbol bottom

260
00:09:12,640 --> 00:09:16,640
correctness of a channel requires that

261
00:09:14,640 --> 00:09:18,000
if the receiver is given the ciphertext

262
00:09:16,640 --> 00:09:20,560
sent by the sender

263
00:09:18,000 --> 00:09:22,160
in order and without modification that

264
00:09:20,560 --> 00:09:22,959
is if the receiver is in sync with the

265
00:09:22,160 --> 00:09:25,040
sender

266
00:09:22,959 --> 00:09:28,800
then the receiver will output the same

267
00:09:25,040 --> 00:09:28,800
sequence of messages that were sent

268
00:09:30,000 --> 00:09:34,000
in terms of security we want to look at

269
00:09:32,320 --> 00:09:36,480
the setting where the adversary is

270
00:09:34,000 --> 00:09:38,959
responsible for delivering messages from

271
00:09:36,480 --> 00:09:40,959
the sender to the receiver

272
00:09:38,959 --> 00:09:43,839
obviously the adversary should not learn

273
00:09:40,959 --> 00:09:45,920
any information on what is being sent

274
00:09:43,839 --> 00:09:48,000
but also we want to prevent the

275
00:09:45,920 --> 00:09:48,959
adversary from delivering messages out

276
00:09:48,000 --> 00:09:51,279
of order

277
00:09:48,959 --> 00:09:53,199
for example if an adversary collects

278
00:09:51,279 --> 00:09:55,920
cipher text c1 c2 and c3

279
00:09:53,200 --> 00:09:57,600
and delivers them out of order security

280
00:09:55,920 --> 00:09:58,560
requires that the channel receiver

281
00:09:57,600 --> 00:10:00,800
returns bottom

282
00:09:58,560 --> 00:10:03,199
as soon as the first out of order cipher

283
00:10:00,800 --> 00:10:06,000
text is received

284
00:10:03,200 --> 00:10:08,240
therefore in addition to confidentiality

285
00:10:06,000 --> 00:10:10,240
the a security for channels

286
00:10:08,240 --> 00:10:11,360
has a strong additional integrity

287
00:10:10,240 --> 00:10:13,760
requirement that

288
00:10:11,360 --> 00:10:14,720
as soon as messages are delivered out of

289
00:10:13,760 --> 00:10:18,319
order

290
00:10:14,720 --> 00:10:19,200
decryption fails again we shall

291
00:10:18,320 --> 00:10:22,640
formalize this

292
00:10:19,200 --> 00:10:22,640
using a distinguishing game

293
00:10:22,720 --> 00:10:26,720
in this case the real world runs the

294
00:10:24,959 --> 00:10:29,839
state generation algorithm to get

295
00:10:26,720 --> 00:10:31,760
initial sender and receiver states the

296
00:10:29,839 --> 00:10:32,320
encryption oracle inputs the queried

297
00:10:31,760 --> 00:10:34,319
message

298
00:10:32,320 --> 00:10:35,600
along with the current sender state the

299
00:10:34,320 --> 00:10:37,680
sender algorithm

300
00:10:35,600 --> 00:10:39,519
the sender returns an updated state and

301
00:10:37,680 --> 00:10:42,079
a cipher text the oracle outputs the

302
00:10:39,519 --> 00:10:44,000
cipher text as its answer

303
00:10:42,079 --> 00:10:45,760
the decryption oracle in this case

304
00:10:44,000 --> 00:10:47,600
inputs the query ciphertext

305
00:10:45,760 --> 00:10:49,040
along with the current receiver state to

306
00:10:47,600 --> 00:10:50,959
the receiver algorithm

307
00:10:49,040 --> 00:10:52,079
the receiver returns an updated state

308
00:10:50,959 --> 00:10:53,760
and a message

309
00:10:52,079 --> 00:10:55,519
the oracle outputs the message as its

310
00:10:53,760 --> 00:10:57,600
answer

311
00:10:55,519 --> 00:11:00,079
in the ideal world the encryption oracle

312
00:10:57,600 --> 00:11:03,519
produces random ciphertext that are

313
00:11:00,079 --> 00:11:06,319
only decrypted if delivered in order

314
00:11:03,519 --> 00:11:08,480
concretely the encryption oracle returns

315
00:11:06,320 --> 00:11:11,040
a random ciphertext and enqueues the

316
00:11:08,480 --> 00:11:14,640
message ciphertext pair

317
00:11:11,040 --> 00:11:17,599
the decryption oracle first dqs

318
00:11:14,640 --> 00:11:19,439
a message cipher text pair if the

319
00:11:17,600 --> 00:11:21,920
dequeued cipher text

320
00:11:19,440 --> 00:11:24,079
matches the queried cipher text then it

321
00:11:21,920 --> 00:11:26,240
returns the corresponding message

322
00:11:24,079 --> 00:11:27,120
otherwise it declares itself out of sync

323
00:11:26,240 --> 00:11:30,079
forever

324
00:11:27,120 --> 00:11:30,079
and returns bottom

325
00:11:30,160 --> 00:11:34,480
the advantage of an adversary against a

326
00:11:32,320 --> 00:11:36,079
security for channels is its advantage

327
00:11:34,480 --> 00:11:39,279
in distinguishing between the real and

328
00:11:36,079 --> 00:11:39,279
the ideal worlds shown

329
00:11:40,399 --> 00:11:45,920
our main theorem shows that suitably

330
00:11:43,680 --> 00:11:47,599
defined notions of confidentiality and

331
00:11:45,920 --> 00:11:50,560
ciphertext integrity

332
00:11:47,600 --> 00:11:52,959
tailored to channels imply a security in

333
00:11:50,560 --> 00:11:55,439
channels in a memory type

334
00:11:52,959 --> 00:11:56,800
in particular we prove an upper bound on

335
00:11:55,440 --> 00:11:59,440
the advantage against

336
00:11:56,800 --> 00:12:00,719
a security for channels in terms of

337
00:11:59,440 --> 00:12:03,680
advantages against

338
00:12:00,720 --> 00:12:04,240
indar and ctex security for channels but

339
00:12:03,680 --> 00:12:07,359
this time

340
00:12:04,240 --> 00:12:09,600
the reduction is memory tight

341
00:12:07,360 --> 00:12:10,480
in the literature all memory type

342
00:12:09,600 --> 00:12:13,040
reductions

343
00:12:10,480 --> 00:12:15,519
use a small amount of memory independent

344
00:12:13,040 --> 00:12:18,000
of the underlying adversary

345
00:12:15,519 --> 00:12:19,760
crucial to our result is that we use a

346
00:12:18,000 --> 00:12:22,240
reduction whose memory grows

347
00:12:19,760 --> 00:12:23,279
linearly in the memory of the adversary

348
00:12:22,240 --> 00:12:26,399
and this is enough

349
00:12:23,279 --> 00:12:26,399
to prove memory tightness

350
00:12:27,360 --> 00:12:33,519
let me give some intuition about how the

351
00:12:30,320 --> 00:12:37,360
proof of our theorem proceeds

352
00:12:33,519 --> 00:12:39,360
we follow the same pattern as before

353
00:12:37,360 --> 00:12:41,519
we introduce an intermediate world with

354
00:12:39,360 --> 00:12:43,200
the encryption oracle of the real world

355
00:12:41,519 --> 00:12:45,200
and the decryption oracle of the ideal

356
00:12:43,200 --> 00:12:47,360
world

357
00:12:45,200 --> 00:12:49,040
again we can upper bound the

358
00:12:47,360 --> 00:12:50,800
distinguishing advantage between the

359
00:12:49,040 --> 00:12:52,399
real and the intermediate worlds using

360
00:12:50,800 --> 00:12:54,880
ctex security

361
00:12:52,399 --> 00:12:55,680
this is easy and i am not going to talk

362
00:12:54,880 --> 00:12:59,600
about this

363
00:12:55,680 --> 00:13:00,800
reduction the core which i shall be

364
00:12:59,600 --> 00:13:02,320
talking now about

365
00:13:00,800 --> 00:13:04,800
is going to be to look at the other

366
00:13:02,320 --> 00:13:04,800
reduction

367
00:13:05,680 --> 00:13:09,680
the technical issue that we face when

368
00:13:07,839 --> 00:13:12,079
trying to give a memory tight reduction

369
00:13:09,680 --> 00:13:13,839
is that the size of the cube grows with

370
00:13:12,079 --> 00:13:15,519
the number of encryption query that

371
00:13:13,839 --> 00:13:18,079
virtually makes

372
00:13:15,519 --> 00:13:19,279
for example if the adversary makes three

373
00:13:18,079 --> 00:13:21,040
encryption queries

374
00:13:19,279 --> 00:13:22,959
we need to store three message cipher

375
00:13:21,040 --> 00:13:24,800
text pairs in the queue

376
00:13:22,959 --> 00:13:28,719
besides the queue strings only if the

377
00:13:24,800 --> 00:13:28,719
adversary makes a decryption query

378
00:13:29,440 --> 00:13:33,279
the key idea to make the reduction

379
00:13:31,040 --> 00:13:35,199
memory tight is that bounding the queue

380
00:13:33,279 --> 00:13:36,880
size does not change the behavior of the

381
00:13:35,200 --> 00:13:40,240
experiment

382
00:13:36,880 --> 00:13:41,600
what do i exactly mean by that suppose

383
00:13:40,240 --> 00:13:43,920
for example we store

384
00:13:41,600 --> 00:13:45,680
at most two plaintext ciphertext pairs

385
00:13:43,920 --> 00:13:47,519
in the queue

386
00:13:45,680 --> 00:13:49,120
now if the adversary makes three

387
00:13:47,519 --> 00:13:51,920
encryption queries on messages

388
00:13:49,120 --> 00:13:53,360
m1 m2 and m3 and receive cipher text c1

389
00:13:51,920 --> 00:13:56,319
c2 and c3

390
00:13:53,360 --> 00:13:58,079
only m1 c1 and m2 c2 shall be stored in

391
00:13:56,320 --> 00:13:59,760
the queue

392
00:13:58,079 --> 00:14:02,399
now if the adversary makes decryption

393
00:13:59,760 --> 00:14:05,519
queries on c1 c2 and c3

394
00:14:02,399 --> 00:14:07,839
and it would receive m1 m2 and bottom

395
00:14:05,519 --> 00:14:09,519
when you really should have received m3

396
00:14:07,839 --> 00:14:13,199
instead of bottom

397
00:14:09,519 --> 00:14:15,519
this seems like a problem however

398
00:14:13,199 --> 00:14:16,240
in order for the adversary to cause this

399
00:14:15,519 --> 00:14:19,040
problem

400
00:14:16,240 --> 00:14:20,399
it has to remember three ciphertexts c1

401
00:14:19,040 --> 00:14:23,439
c2 and c3

402
00:14:20,399 --> 00:14:25,519
otherwise it could not have caused this

403
00:14:23,440 --> 00:14:27,600
in general if the memory of the

404
00:14:25,519 --> 00:14:28,480
adversary is not much larger than the

405
00:14:27,600 --> 00:14:30,720
length of the cube

406
00:14:28,480 --> 00:14:33,360
the adversary will not be able to cause

407
00:14:30,720 --> 00:14:33,360
this problem

408
00:14:33,519 --> 00:14:37,440
in particular we can show that the

409
00:14:35,839 --> 00:14:39,360
adversary has very small

410
00:14:37,440 --> 00:14:40,880
probability of causing this problem if

411
00:14:39,360 --> 00:14:42,880
we set the length of the queue

412
00:14:40,880 --> 00:14:44,720
to delta which is proportional to the

413
00:14:42,880 --> 00:14:46,639
memory of the adversary

414
00:14:44,720 --> 00:14:48,320
we shall show this by reduction to an

415
00:14:46,639 --> 00:14:50,320
information theory game

416
00:14:48,320 --> 00:14:52,160
which captures the essence of what the

417
00:14:50,320 --> 00:14:55,519
adversary needs to do

418
00:14:52,160 --> 00:14:55,519
to cause this problem

419
00:14:57,519 --> 00:15:03,519
in this game l and delta are parameters

420
00:15:00,399 --> 00:15:05,360
and it's played by a two-stage adversary

421
00:15:03,519 --> 00:15:07,360
the first stage of the adversary is

422
00:15:05,360 --> 00:15:10,079
given as input

423
00:15:07,360 --> 00:15:12,000
l-bit string r and it outputs a state

424
00:15:10,079 --> 00:15:15,279
sigma of size at most s

425
00:15:12,000 --> 00:15:17,120
and an index i the first i

426
00:15:15,279 --> 00:15:19,199
bits of the string are and the outputs

427
00:15:17,120 --> 00:15:22,560
of the first stage are given as inputs

428
00:15:19,199 --> 00:15:25,120
to the second stage of the adversary

429
00:15:22,560 --> 00:15:26,880
in order to win the game it needs to

430
00:15:25,120 --> 00:15:29,600
guess the next delta bits of

431
00:15:26,880 --> 00:15:29,600
r correctly

432
00:15:30,480 --> 00:15:35,360
setting delta to depend linearly on s

433
00:15:33,600 --> 00:15:37,360
with a fairly straightforward

434
00:15:35,360 --> 00:15:39,199
compression argument we can show that

435
00:15:37,360 --> 00:15:41,600
the probability of an adversary winning

436
00:15:39,199 --> 00:15:43,920
this game is small

437
00:15:41,600 --> 00:15:45,360
i shall refer you to our paper for more

438
00:15:43,920 --> 00:15:47,439
details of the proof

439
00:15:45,360 --> 00:15:49,920
and move on to the main application of

440
00:15:47,440 --> 00:15:49,920
our result

441
00:15:50,880 --> 00:15:54,240
we have shown that a security of a

442
00:15:52,880 --> 00:15:55,199
channel can be reduced to its

443
00:15:54,240 --> 00:15:57,920
constituents

444
00:15:55,199 --> 00:16:00,719
indar and ctek security in a way that

445
00:15:57,920 --> 00:16:03,279
preserves memory complexity

446
00:16:00,720 --> 00:16:05,360
this of course is only meaningful if we

447
00:16:03,279 --> 00:16:08,000
have channels for which we can give

448
00:16:05,360 --> 00:16:08,880
provable time memory tradeoffs for their

449
00:16:08,000 --> 00:16:11,759
indar and c

450
00:16:08,880 --> 00:16:13,839
tech securities we prove such time

451
00:16:11,759 --> 00:16:15,839
memory tradeoffs for gcm

452
00:16:13,839 --> 00:16:17,759
one of the most widely deployed

453
00:16:15,839 --> 00:16:20,240
encryption scheme

454
00:16:17,759 --> 00:16:21,600
cau an abstraction of gcm is an

455
00:16:20,240 --> 00:16:24,959
encryption scheme from an

456
00:16:21,600 --> 00:16:28,399
n bit block cipher e and an almost xor

457
00:16:24,959 --> 00:16:30,638
universal hash function h

458
00:16:28,399 --> 00:16:32,720
we prove a memory sensitive upper bound

459
00:16:30,639 --> 00:16:33,839
on the advantage of an adversary against

460
00:16:32,720 --> 00:16:37,199
a security

461
00:16:33,839 --> 00:16:40,079
of the channel induced by ciu

462
00:16:37,199 --> 00:16:42,319
in particular we show that the advantage

463
00:16:40,079 --> 00:16:43,439
of an adversary against a security of

464
00:16:42,320 --> 00:16:46,240
this channel

465
00:16:43,440 --> 00:16:47,440
is upper bounded in terms of the memory

466
00:16:46,240 --> 00:16:48,560
and the number of queries of the

467
00:16:47,440 --> 00:16:50,240
adversary

468
00:16:48,560 --> 00:16:51,920
and the advantage of breaking the

469
00:16:50,240 --> 00:16:54,320
underlying block cipher as a pseudo

470
00:16:51,920 --> 00:16:56,399
random communication

471
00:16:54,320 --> 00:16:58,320
the second term here shows that there is

472
00:16:56,399 --> 00:17:01,040
a time memory tradeoff for breaking the

473
00:16:58,320 --> 00:17:03,440
a security of this channel

474
00:17:01,040 --> 00:17:04,959
since cau is an abstraction of gcm we

475
00:17:03,440 --> 00:17:06,720
have essentially shown a

476
00:17:04,959 --> 00:17:08,160
time memory tradeoff for a simplified

477
00:17:06,720 --> 00:17:12,319
version of a channel

478
00:17:08,160 --> 00:17:12,319
obtained by using gcm in tls

479
00:17:13,599 --> 00:17:16,879
now i shall briefly talk about our

480
00:17:15,359 --> 00:17:18,799
second contribution

481
00:17:16,880 --> 00:17:20,480
the impossibility result for a memory

482
00:17:18,799 --> 00:17:23,839
type reduction in the general

483
00:17:20,480 --> 00:17:26,079
nonce based encryption setting

484
00:17:23,839 --> 00:17:28,000
our result is in line with prior work

485
00:17:26,079 --> 00:17:29,440
proving impossibilities for memory type

486
00:17:28,000 --> 00:17:31,760
reductions

487
00:17:29,440 --> 00:17:33,039
i would like to explicitly note that our

488
00:17:31,760 --> 00:17:36,000
result rules out

489
00:17:33,039 --> 00:17:37,760
not only memory type reductions that use

490
00:17:36,000 --> 00:17:38,880
memory independent of the underlying

491
00:17:37,760 --> 00:17:41,679
adversary

492
00:17:38,880 --> 00:17:45,200
but also memory adaptive reductions like

493
00:17:41,679 --> 00:17:45,200
the one we gave for channels

494
00:17:45,360 --> 00:17:48,719
these results provide quite a bit of

495
00:17:47,360 --> 00:17:51,600
evidence that

496
00:17:48,720 --> 00:17:52,880
some restrictions are necessary to prove

497
00:17:51,600 --> 00:17:55,600
a security from

498
00:17:52,880 --> 00:17:58,000
indar and c tech security in a memory

499
00:17:55,600 --> 00:17:58,000
title

500
00:17:59,760 --> 00:18:04,080
i shall now state our theorem for the

501
00:18:02,160 --> 00:18:06,960
negative result

502
00:18:04,080 --> 00:18:08,960
we show that for all indar and c tech

503
00:18:06,960 --> 00:18:11,760
secure non-based encryption schemes

504
00:18:08,960 --> 00:18:14,000
any we can construct an inefficient

505
00:18:11,760 --> 00:18:16,720
adversary a star against a security

506
00:18:14,000 --> 00:18:19,919
of any making queue queries that has

507
00:18:16,720 --> 00:18:19,919
advantage close to 1.

508
00:18:20,320 --> 00:18:24,240
we show that for all efficient black box

509
00:18:22,880 --> 00:18:27,200
reductions

510
00:18:24,240 --> 00:18:28,080
if the reduction given access to a star

511
00:18:27,200 --> 00:18:30,720
uses memory

512
00:18:28,080 --> 00:18:32,879
in the little of q then its advantage

513
00:18:30,720 --> 00:18:36,000
against indar security of any

514
00:18:32,880 --> 00:18:38,400
is negligible additionally

515
00:18:36,000 --> 00:18:40,720
for all efficient black box reductions

516
00:18:38,400 --> 00:18:42,960
the reduction given access to a star

517
00:18:40,720 --> 00:18:46,720
can achieve only negligible advantage

518
00:18:42,960 --> 00:18:48,640
against c tech security of any

519
00:18:46,720 --> 00:18:50,400
the a star that we construct is low

520
00:18:48,640 --> 00:18:51,520
memory its memory grows only

521
00:18:50,400 --> 00:18:53,840
logarithmically

522
00:18:51,520 --> 00:18:57,840
in the number of queries so this rules

523
00:18:53,840 --> 00:18:57,840
out even memory adaptive reductions

524
00:18:58,320 --> 00:19:02,000
there are a few caveats however we can

525
00:19:01,200 --> 00:19:03,520
prove this

526
00:19:02,000 --> 00:19:06,160
only for a restricted class of

527
00:19:03,520 --> 00:19:06,160
reductions

528
00:19:06,240 --> 00:19:10,160
the first restriction is that the

529
00:19:07,679 --> 00:19:12,960
reduction is faithful

530
00:19:10,160 --> 00:19:13,840
that is if it answers an encryption

531
00:19:12,960 --> 00:19:17,600
query

532
00:19:13,840 --> 00:19:18,799
with a ciphertext c it has made the same

533
00:19:17,600 --> 00:19:20,399
query to its own

534
00:19:18,799 --> 00:19:22,639
encryption oracle before and had

535
00:19:20,400 --> 00:19:24,720
received c as the answer

536
00:19:22,640 --> 00:19:28,640
this restriction is natural and we are

537
00:19:24,720 --> 00:19:30,240
not aware of any reductions evading it

538
00:19:28,640 --> 00:19:32,000
the second restriction is that the

539
00:19:30,240 --> 00:19:33,760
reduction does not ask for

540
00:19:32,000 --> 00:19:35,760
encryptions with the same nonce if the

541
00:19:33,760 --> 00:19:37,600
adversary does not do so

542
00:19:35,760 --> 00:19:38,799
this is very natural for non-based

543
00:19:37,600 --> 00:19:41,520
encryption scheme since

544
00:19:38,799 --> 00:19:44,559
the security guarantees hold only if

545
00:19:41,520 --> 00:19:44,559
nonsense are distinct

546
00:19:44,640 --> 00:19:48,480
the final restriction is that the

547
00:19:46,240 --> 00:19:49,200
reduction either does not rewind the

548
00:19:48,480 --> 00:19:52,240
adversary

549
00:19:49,200 --> 00:19:54,160
or is fully rewinding that is it can

550
00:19:52,240 --> 00:19:56,000
rewind the adversary at any point

551
00:19:54,160 --> 00:19:58,080
but can only restart it from the

552
00:19:56,000 --> 00:20:01,280
beginning

553
00:19:58,080 --> 00:20:02,960
this restriction is milder than those

554
00:20:01,280 --> 00:20:04,559
in some of the prior impossibility

555
00:20:02,960 --> 00:20:07,360
results where only

556
00:20:04,559 --> 00:20:09,039
straight line reductions were ruled out

557
00:20:07,360 --> 00:20:10,879
handling more general rewinding

558
00:20:09,039 --> 00:20:13,360
strategies seem to require new proof

559
00:20:10,880 --> 00:20:13,360
techniques

560
00:20:14,320 --> 00:20:17,439
i shall briefly talk about the basic

561
00:20:16,320 --> 00:20:20,960
idea behind

562
00:20:17,440 --> 00:20:23,679
the adversary a star that we construct

563
00:20:20,960 --> 00:20:25,760
it has r challenge rounds in every round

564
00:20:23,679 --> 00:20:28,400
it asks for the encryption of u

565
00:20:25,760 --> 00:20:29,840
random messages m1 through mu each l

566
00:20:28,400 --> 00:20:32,960
bits long

567
00:20:29,840 --> 00:20:36,320
under distinct nonsense and it receives

568
00:20:32,960 --> 00:20:38,880
cipher text c1 through cu

569
00:20:36,320 --> 00:20:40,158
it chooses an index j star among one

570
00:20:38,880 --> 00:20:42,880
through u at random and

571
00:20:40,159 --> 00:20:44,880
asked for the decryption of c j star

572
00:20:42,880 --> 00:20:48,320
under the same nonce with which it had

573
00:20:44,880 --> 00:20:50,240
asked for the encryption of md star

574
00:20:48,320 --> 00:20:52,240
if the decryption query returns an

575
00:20:50,240 --> 00:20:55,919
answer different from mj star

576
00:20:52,240 --> 00:20:57,120
it just aborts if it did not abort in

577
00:20:55,919 --> 00:20:59,440
any of the r

578
00:20:57,120 --> 00:21:00,399
rounds it tries to inefficiently break

579
00:20:59,440 --> 00:21:02,480
the scheme

580
00:21:00,400 --> 00:21:03,679
which helps it distinguish the real

581
00:21:02,480 --> 00:21:06,640
world from the ideal world with

582
00:21:03,679 --> 00:21:08,640
probability close to one

583
00:21:06,640 --> 00:21:10,320
the main intuition here is that a

584
00:21:08,640 --> 00:21:13,600
reduction using

585
00:21:10,320 --> 00:21:16,559
k times l bits of memory succeeds in

586
00:21:13,600 --> 00:21:19,918
each round with a probability of at most

587
00:21:16,559 --> 00:21:22,158
k by u of course

588
00:21:19,919 --> 00:21:23,200
making this precise requires lots of

589
00:21:22,159 --> 00:21:25,440
work

590
00:21:23,200 --> 00:21:27,840
i refer you to our paper for details of

591
00:21:25,440 --> 00:21:27,840
the proof

592
00:21:29,200 --> 00:21:35,919
to conclude in this work we proved

593
00:21:32,960 --> 00:21:36,720
memory sensitive bounds for a security

594
00:21:35,919 --> 00:21:38,960
of channels

595
00:21:36,720 --> 00:21:41,039
and subsequently time memory tradeoffs

596
00:21:38,960 --> 00:21:42,640
for the a security of our tls like

597
00:21:41,039 --> 00:21:44,640
channel

598
00:21:42,640 --> 00:21:46,559
we introduced a new technique of proving

599
00:21:44,640 --> 00:21:47,120
memory tightness where the memory of the

600
00:21:46,559 --> 00:21:48,559
reduction

601
00:21:47,120 --> 00:21:51,360
depends on the memory of the underlying

602
00:21:48,559 --> 00:21:54,480
adversary this technique might be of

603
00:21:51,360 --> 00:21:56,479
independent interest

604
00:21:54,480 --> 00:21:58,000
additionally the we proved the

605
00:21:56,480 --> 00:22:00,640
impossibility of a memory type

606
00:21:58,000 --> 00:22:02,159
reduction in the most general setting

607
00:22:00,640 --> 00:22:04,000
providing some evidence that

608
00:22:02,159 --> 00:22:07,360
restrictions might be necessary for

609
00:22:04,000 --> 00:22:07,360
giving a memory type reduction

610
00:22:08,080 --> 00:22:13,280
there are a few open problems one open

611
00:22:10,799 --> 00:22:14,480
problem here is proving memory sensitive

612
00:22:13,280 --> 00:22:17,520
bounds for

613
00:22:14,480 --> 00:22:20,000
other practical examples of channels

614
00:22:17,520 --> 00:22:21,840
another is finding new applications of

615
00:22:20,000 --> 00:22:26,159
memory adaptive reductions

616
00:22:21,840 --> 00:22:27,678
that we introduce in this work

617
00:22:26,159 --> 00:22:29,600
the full version of our paper is

618
00:22:27,679 --> 00:22:33,360
available on eprint

619
00:22:29,600 --> 00:22:33,360
thank you

