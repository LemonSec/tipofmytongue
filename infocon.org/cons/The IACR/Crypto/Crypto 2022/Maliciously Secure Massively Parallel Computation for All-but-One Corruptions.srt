1
00:00:00,960 --> 00:00:03,280
this is an abstract video for the paper

2
00:00:03,280 --> 00:00:05,600
maliciously secure massively parallel

3
00:00:05,600 --> 00:00:08,480
computation for all but one corruptions

4
00:00:08,480 --> 00:00:10,320
my name is rex fernando and my

5
00:00:10,320 --> 00:00:13,200
collaborators are yuval geles ilan

6
00:00:13,200 --> 00:00:16,320
komargodski and elaine she

7
00:00:16,320 --> 00:00:18,320
in our work we're interested in studying

8
00:00:18,320 --> 00:00:20,160
the types of massively parallel

9
00:00:20,160 --> 00:00:22,640
algorithms that run inside data centers

10
00:00:22,640 --> 00:00:24,400
so probably the most

11
00:00:24,400 --> 00:00:26,640
the most famous example of this is the

12
00:00:26,640 --> 00:00:29,199
google search algorithm

13
00:00:29,199 --> 00:00:31,599
and what we're interested in is whether

14
00:00:31,599 --> 00:00:33,360
it's possible to achieve meaningful

15
00:00:33,360 --> 00:00:35,440
notions of security for these massively

16
00:00:35,440 --> 00:00:36,559
parallel

17
00:00:36,559 --> 00:00:38,960
algorithms

18
00:00:38,960 --> 00:00:40,879
the model that we're going to be working

19
00:00:40,879 --> 00:00:42,879
in is called the massively parallel

20
00:00:42,879 --> 00:00:45,280
computation model and this model has

21
00:00:45,280 --> 00:00:47,680
been adopted by the algorithms community

22
00:00:47,680 --> 00:00:50,000
for studying the types of computation

23
00:00:50,000 --> 00:00:52,559
that i was just talking about

24
00:00:52,559 --> 00:00:54,640
and at a very high level it works as

25
00:00:54,640 --> 00:00:56,960
follows so we assume that there's some

26
00:00:56,960 --> 00:00:58,800
very large input string

27
00:00:58,800 --> 00:01:00,480
and we assume that this input string is

28
00:01:00,480 --> 00:01:02,079
divided among

29
00:01:02,079 --> 00:01:05,199
a large set of machines each of which

30
00:01:05,199 --> 00:01:07,520
has very limited local space much less

31
00:01:07,520 --> 00:01:10,320
than the size of the input string

32
00:01:10,320 --> 00:01:13,520
and then this these machines uh run a

33
00:01:13,520 --> 00:01:16,080
protocol together and then the output of

34
00:01:16,080 --> 00:01:17,840
this protocol is defined to be the

35
00:01:17,840 --> 00:01:19,840
concatenation of the local outputs of

36
00:01:19,840 --> 00:01:21,840
each machine

37
00:01:21,840 --> 00:01:23,520
so i'll go into more detail about this

38
00:01:23,520 --> 00:01:25,840
model in the full version of the talk

39
00:01:25,840 --> 00:01:27,920
but two details i wanted to mention here

40
00:01:27,920 --> 00:01:30,640
are that first the local space of each

41
00:01:30,640 --> 00:01:32,400
machine is limited to be n to the

42
00:01:32,400 --> 00:01:34,560
epsilon where n is the size of the input

43
00:01:34,560 --> 00:01:37,280
and epsilon is a small constant

44
00:01:37,280 --> 00:01:39,200
and second in general when studying

45
00:01:39,200 --> 00:01:42,000
distributed algorithms in this setting

46
00:01:42,000 --> 00:01:44,399
we limit ourselves to algorithms that

47
00:01:44,399 --> 00:01:47,040
are very round efficient they so in

48
00:01:47,040 --> 00:01:48,479
particular they take you know

49
00:01:48,479 --> 00:01:52,000
logarithmic rounds or less

50
00:01:53,520 --> 00:01:55,200
the particular type of question we're

51
00:01:55,200 --> 00:01:57,600
interested in this work is whether or

52
00:01:57,600 --> 00:01:59,759
not it's possible to build protocols in

53
00:01:59,759 --> 00:02:00,880
this model

54
00:02:00,880 --> 00:02:03,840
which satisfy like security guarantees

55
00:02:03,840 --> 00:02:05,920
that are similar to those found in

56
00:02:05,920 --> 00:02:09,119
classical secure computation protocols

57
00:02:09,119 --> 00:02:11,200
so in these classical secure protocols

58
00:02:11,200 --> 00:02:14,239
we in general assume that

59
00:02:14,239 --> 00:02:17,760
some subset of the parties are malicious

60
00:02:17,760 --> 00:02:19,520
we can say that they're controlled by

61
00:02:19,520 --> 00:02:22,720
some polynomial time adversary and in

62
00:02:22,720 --> 00:02:24,480
this setting we want to protect the

63
00:02:24,480 --> 00:02:26,480
inputs and outputs of

64
00:02:26,480 --> 00:02:28,239
the honest parties

65
00:02:28,239 --> 00:02:30,400
so we want to prevent the adversary from

66
00:02:30,400 --> 00:02:32,239
learning these inputs and outputs and we

67
00:02:32,239 --> 00:02:34,800
want also the adversary to be to be

68
00:02:34,800 --> 00:02:36,400
prevented from tampering with these

69
00:02:36,400 --> 00:02:38,879
outputs

70
00:02:39,120 --> 00:02:41,360
so going back to the massively parallel

71
00:02:41,360 --> 00:02:43,040
computation model

72
00:02:43,040 --> 00:02:45,840
where recall the two main constraints

73
00:02:45,840 --> 00:02:48,080
are first that the local space of each

74
00:02:48,080 --> 00:02:51,120
machine is limited and second that the

75
00:02:51,120 --> 00:02:52,560
round the number of rounds is very

76
00:02:52,560 --> 00:02:54,800
limited the question is can we achieve

77
00:02:54,800 --> 00:02:57,599
security uh akin to classical secure

78
00:02:57,599 --> 00:02:58,879
computation

79
00:02:58,879 --> 00:03:01,040
uh while still respecting this you know

80
00:03:01,040 --> 00:03:02,879
the constraints of this model as much as

81
00:03:02,879 --> 00:03:05,920
possible so a natural question is you

82
00:03:05,920 --> 00:03:06,720
know

83
00:03:06,720 --> 00:03:09,280
there's a ton of work on classical

84
00:03:09,280 --> 00:03:11,599
secure computation does any of that

85
00:03:11,599 --> 00:03:13,680
apply to this setting

86
00:03:13,680 --> 00:03:15,680
and the answer is unfortunately no

87
00:03:15,680 --> 00:03:17,680
because

88
00:03:17,680 --> 00:03:20,800
at a very high level uh

89
00:03:20,800 --> 00:03:22,640
almost all work on

90
00:03:22,640 --> 00:03:26,560
classical secure computation involves uh

91
00:03:26,560 --> 00:03:28,799
simultaneous broadcast and and this is

92
00:03:28,799 --> 00:03:33,159
very problematic for our model

93
00:03:33,599 --> 00:03:35,519
so i'll close by quickly stating our

94
00:03:35,519 --> 00:03:36,799
results

95
00:03:36,799 --> 00:03:38,799
and just for context the bottom of the

96
00:03:38,799 --> 00:03:40,799
slide contains a table that describes

97
00:03:40,799 --> 00:03:43,280
the state of the art prior to our to our

98
00:03:43,280 --> 00:03:44,959
work

99
00:03:44,959 --> 00:03:46,959
so with that in mind our first result is

100
00:03:46,959 --> 00:03:49,280
an impossibility we show that it's

101
00:03:49,280 --> 00:03:51,200
impossible to achieve anything stronger

102
00:03:51,200 --> 00:03:53,280
than semi-auto security in the setting

103
00:03:53,280 --> 00:03:56,080
of all but one corruptions

104
00:03:56,080 --> 00:03:58,319
and this impossibility applies to any

105
00:03:58,319 --> 00:04:01,120
setting with arbitrary trusted setup

106
00:04:01,120 --> 00:04:03,280
our second result is a fully malicious

107
00:04:03,280 --> 00:04:05,439
secure compiler which works exactly in

108
00:04:05,439 --> 00:04:07,920
this setting of all but one corruptions

109
00:04:07,920 --> 00:04:09,920
and the way that we make this work is we

110
00:04:09,920 --> 00:04:12,080
first observe that our impossibility

111
00:04:12,080 --> 00:04:13,680
result does not apply in the

112
00:04:13,680 --> 00:04:16,238
programmable random oracle model

113
00:04:16,238 --> 00:04:19,358
so more specifically we give a compiler

114
00:04:19,358 --> 00:04:21,759
which takes any insecure massively

115
00:04:21,759 --> 00:04:23,520
parallel protocol and turns it into a

116
00:04:23,520 --> 00:04:25,520
secure one

117
00:04:25,520 --> 00:04:28,479
with minimal efficiency blow up

118
00:04:28,479 --> 00:04:30,320
so i hope this piqued your interest in

119
00:04:30,320 --> 00:04:32,320
our work and if so hopefully i'll see

120
00:04:32,320 --> 00:04:35,560
you on monday

