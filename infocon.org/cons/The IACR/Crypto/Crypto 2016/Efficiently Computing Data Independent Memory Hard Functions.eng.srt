1
00:00:03,880 --> 00:00:06,140
thank you all for sticking around for

2
00:00:06,140 --> 00:00:08,450
the last session of crypto so I'm

3
00:00:08,450 --> 00:00:11,150
excited to talk to you today about data

4
00:00:11,150 --> 00:00:13,009
independent memory hard functions this

5
00:00:13,009 --> 00:00:16,250
is joint work with joelle all win at ISD

6
00:00:16,250 --> 00:00:18,770
Austria so is a basic motivate

7
00:00:18,770 --> 00:00:20,930
motivating example consider the problem

8
00:00:20,930 --> 00:00:24,170
of password storage often times due to

9
00:00:24,170 --> 00:00:26,990
programmer errors or other security

10
00:00:26,990 --> 00:00:29,240
flaws adversaries are able to break into

11
00:00:29,240 --> 00:00:31,310
authentication servers and steal the

12
00:00:31,310 --> 00:00:33,250
cryptographic hashes of user passwords

13
00:00:33,250 --> 00:00:36,140
such an adversary can execute an offline

14
00:00:36,140 --> 00:00:38,780
attack in which he compares the hashes

15
00:00:38,780 --> 00:00:40,580
of likely password guesses with the hash

16
00:00:40,580 --> 00:00:43,010
value of the users true password such an

17
00:00:43,010 --> 00:00:44,750
adversary is only limited by the

18
00:00:44,750 --> 00:00:46,220
resources that he's willing to invest

19
00:00:46,220 --> 00:00:49,360
trying to crack the users password in

20
00:00:49,360 --> 00:00:52,339
fact offline attacks are an increasingly

21
00:00:52,339 --> 00:00:55,100
common problem in the past years we have

22
00:00:55,100 --> 00:00:57,549
seen breaches at many large

23
00:00:57,549 --> 00:00:59,449
organizations which have affected

24
00:00:59,449 --> 00:01:01,879
millions of users and in fact over the

25
00:01:01,879 --> 00:01:03,409
years I've had to update this slide

26
00:01:03,409 --> 00:01:05,269
several times so we can see that this

27
00:01:05,269 --> 00:01:09,200
problem is not going away now offline

28
00:01:09,200 --> 00:01:11,120
attacks on passwords are increasingly

29
00:01:11,120 --> 00:01:13,490
dangerous for several reasons first

30
00:01:13,490 --> 00:01:15,650
password cracking hard work and can use

31
00:01:15,650 --> 00:01:19,460
to improve and second users continue to

32
00:01:19,460 --> 00:01:23,750
select low entropy passwords this

33
00:01:23,750 --> 00:01:25,280
motivates the goal of developing

34
00:01:25,280 --> 00:01:27,950
moderately expensive hash functions the

35
00:01:27,950 --> 00:01:31,310
basic idea is to create a function which

36
00:01:31,310 --> 00:01:34,220
is moderately hard to evaluate once this

37
00:01:34,220 --> 00:01:36,500
way an adversary is trying to try

38
00:01:36,500 --> 00:01:39,580
millions or billions of password guesses

39
00:01:39,580 --> 00:01:45,020
just runs out of resources now the key

40
00:01:45,020 --> 00:01:48,740
question here is after we've done all

41
00:01:48,740 --> 00:01:51,880
this key stretching on the legitimate

42
00:01:51,880 --> 00:01:54,950
authentication server is it really going

43
00:01:54,950 --> 00:01:58,400
to cost the adversary extra to evaluate

44
00:01:58,400 --> 00:02:00,890
this memory hard function once in

45
00:02:00,890 --> 00:02:03,140
particular the adversary doesn't have to

46
00:02:03,140 --> 00:02:05,299
use standard computing hardware he could

47
00:02:05,299 --> 00:02:09,019
build a GPU or an ASIC for example to

48
00:02:09,019 --> 00:02:11,420
compute this memory heart function

49
00:02:11,420 --> 00:02:14,600
multiple times the question the key

50
00:02:14,600 --> 00:02:16,250
question really is are the costs

51
00:02:16,250 --> 00:02:17,480
equitable

52
00:02:17,480 --> 00:02:19,370
if we do a lot of work to make this

53
00:02:19,370 --> 00:02:21,349
function harder to compute on your

54
00:02:21,349 --> 00:02:23,480
desktop is it also going to be harder

55
00:02:23,480 --> 00:02:25,010
for the adversary to compute this

56
00:02:25,010 --> 00:02:26,840
function multiple times on customized

57
00:02:26,840 --> 00:02:31,370
hardware and in fact obtaining a

58
00:02:31,370 --> 00:02:33,049
function with equitable cost is

59
00:02:33,049 --> 00:02:35,959
non-trivial in particular by looking at

60
00:02:35,959 --> 00:02:38,260
Bitcoin mining pools we can see that the

61
00:02:38,260 --> 00:02:40,370
sha256 hash function is far from

62
00:02:40,370 --> 00:02:43,040
equitable in fact the cost of evaluating

63
00:02:43,040 --> 00:02:45,650
sha-256 there is by a factor of about a

64
00:02:45,650 --> 00:02:47,930
million when you compare the cost on a

65
00:02:47,930 --> 00:02:50,569
cpu versus the cost of evaluating the

66
00:02:50,569 --> 00:02:55,910
function once on an ASIC alright so this

67
00:02:55,910 --> 00:02:58,010
hopefully motivates the need for our

68
00:02:58,010 --> 00:02:59,989
data independent memory hard functions

69
00:02:59,989 --> 00:03:02,030
an object that will introduce in the

70
00:03:02,030 --> 00:03:04,970
next section after introducing data

71
00:03:04,970 --> 00:03:06,590
independent memory hard functions I'm

72
00:03:06,590 --> 00:03:09,680
going to go over our attacks and as a

73
00:03:09,680 --> 00:03:12,019
bonus if time permits i'll describe some

74
00:03:12,019 --> 00:03:14,109
exciting subsequent results that we've

75
00:03:14,109 --> 00:03:18,230
obtained in the last few months all

76
00:03:18,230 --> 00:03:21,769
right so the basic goal of a memory hard

77
00:03:21,769 --> 00:03:23,810
function is to develop a moderately hard

78
00:03:23,810 --> 00:03:26,060
function with equitable costs and the

79
00:03:26,060 --> 00:03:28,160
key observation here is that memory

80
00:03:28,160 --> 00:03:31,340
costs tend to be equitable across across

81
00:03:31,340 --> 00:03:34,370
different computer architectures so the

82
00:03:34,370 --> 00:03:36,139
intuition behind a memory heart function

83
00:03:36,139 --> 00:03:38,150
is basically a function for which

84
00:03:38,150 --> 00:03:40,220
computation costs are dominated by

85
00:03:40,220 --> 00:03:44,269
memory costs a script is one example of

86
00:03:44,269 --> 00:03:48,590
a candidate memory hard function but the

87
00:03:48,590 --> 00:03:52,400
data access pattern for s crypt is input

88
00:03:52,400 --> 00:03:54,919
dependent that means that the access

89
00:03:54,919 --> 00:03:56,450
pattern to memory depends on the

90
00:03:56,450 --> 00:03:58,760
sensitive user input which makes the

91
00:03:58,760 --> 00:04:00,590
function potentially vulnerable to

92
00:04:00,590 --> 00:04:04,790
side-channel attacks in this paper we're

93
00:04:04,790 --> 00:04:06,349
going to consider a special subclass of

94
00:04:06,349 --> 00:04:08,299
memory card functions called data

95
00:04:08,299 --> 00:04:09,980
independent memory heart functions as

96
00:04:09,980 --> 00:04:12,709
the name suggests the memory access

97
00:04:12,709 --> 00:04:14,810
pattern does not depend at all on the

98
00:04:14,810 --> 00:04:17,238
input which makes these functions

99
00:04:17,238 --> 00:04:20,988
resistant side-channel attacks all right

100
00:04:20,988 --> 00:04:23,690
so what is a data independent memory

101
00:04:23,690 --> 00:04:26,960
hard function well for our purposes we

102
00:04:26,960 --> 00:04:28,640
can think of a data independent memory

103
00:04:28,640 --> 00:04:29,590
hard function as being

104
00:04:29,590 --> 00:04:33,010
fine by a compression function H which

105
00:04:33,010 --> 00:04:35,680
will model as a random Oracle and a

106
00:04:35,680 --> 00:04:38,350
directed acyclic graph G which encodes

107
00:04:38,350 --> 00:04:42,730
data dependencies during computation so

108
00:04:42,730 --> 00:04:45,190
as an example here if we have this graph

109
00:04:45,190 --> 00:04:47,290
the input to the function is the

110
00:04:47,290 --> 00:04:50,380
password and the salt and we compute the

111
00:04:50,380 --> 00:04:53,320
label of the first node by just hashing

112
00:04:53,320 --> 00:04:56,890
this password value and the salt now the

113
00:04:56,890 --> 00:04:58,870
label of an internal node for example

114
00:04:58,870 --> 00:05:01,990
the label of note 3 is computed by

115
00:05:01,990 --> 00:05:04,120
hashing the labels of its parents in

116
00:05:04,120 --> 00:05:08,140
this case no 2 and node 1 finally the

117
00:05:08,140 --> 00:05:10,180
output of the data independent memory

118
00:05:10,180 --> 00:05:13,180
heart function is just the label of the

119
00:05:13,180 --> 00:05:17,710
final node in this case note for all

120
00:05:17,710 --> 00:05:20,980
right so and we can describe algorithms

121
00:05:20,980 --> 00:05:22,810
that the adversary might use to compute

122
00:05:22,810 --> 00:05:26,470
an IM hf using language of rappelling in

123
00:05:26,470 --> 00:05:29,860
particular placing a pebble on on the

124
00:05:29,860 --> 00:05:31,600
graph corresponds to computing a

125
00:05:31,600 --> 00:05:34,240
particular data label and keeping a

126
00:05:34,240 --> 00:05:36,100
pebble on the graph corresponds to

127
00:05:36,100 --> 00:05:39,400
storing that data label in memory now of

128
00:05:39,400 --> 00:05:42,130
course a pebble is only valid if it

129
00:05:42,130 --> 00:05:45,580
satisfies certain rules for example we

130
00:05:45,580 --> 00:05:47,470
can only place a pebble on the graph in

131
00:05:47,470 --> 00:05:50,440
round I plus 1 if we had pebbles on the

132
00:05:50,440 --> 00:05:53,140
parents of that node in round I this is

133
00:05:53,140 --> 00:05:55,930
because we need any dependent values

134
00:05:55,930 --> 00:05:59,500
before we can compute the new label and

135
00:05:59,500 --> 00:06:02,560
the final rule is that by the end of

136
00:06:02,560 --> 00:06:04,750
this pebble we have to place a pebble on

137
00:06:04,750 --> 00:06:07,810
the final node after all that's the

138
00:06:07,810 --> 00:06:09,010
output that's what we're trying to

139
00:06:09,010 --> 00:06:11,710
compute now the adversary is allowed to

140
00:06:11,710 --> 00:06:14,830
place potentially multiple pebbles on

141
00:06:14,830 --> 00:06:17,230
the graph during a given round we assume

142
00:06:17,230 --> 00:06:19,960
that the adversaries parallel and the

143
00:06:19,960 --> 00:06:21,730
adversary is also allowed to discard

144
00:06:21,730 --> 00:06:24,370
pebbles at any point in time potentially

145
00:06:24,370 --> 00:06:28,630
to save space all right so here's a

146
00:06:28,630 --> 00:06:31,660
simple example of pebble inning so to

147
00:06:31,660 --> 00:06:33,220
start off we can place a pebble one node

148
00:06:33,220 --> 00:06:35,380
1 now that we have this pebble we can

149
00:06:35,380 --> 00:06:38,080
place a pebble one note 2 now we can

150
00:06:38,080 --> 00:06:40,210
pebble note 3 because we had pebbles on

151
00:06:40,210 --> 00:06:41,950
the parents at the same time we can

152
00:06:41,950 --> 00:06:42,650
remove

153
00:06:42,650 --> 00:06:44,540
couples from those 1 & 2 because they're

154
00:06:44,540 --> 00:06:46,580
no longer needed now we can pebble note

155
00:06:46,580 --> 00:06:51,860
4 and finally note 5 all right so how do

156
00:06:51,860 --> 00:06:53,780
we measure the cost of a pebble

157
00:06:53,780 --> 00:06:56,990
algorithm well the first approach which

158
00:06:56,990 --> 00:06:58,460
is kind of a classical approach is

159
00:06:58,460 --> 00:07:01,639
space-time complexity so here the space

160
00:07:01,639 --> 00:07:04,250
time complexity of a graph is the

161
00:07:04,250 --> 00:07:07,789
minimum over all legal peb wings of the

162
00:07:07,789 --> 00:07:10,220
time that the pebble in cakes the number

163
00:07:10,220 --> 00:07:12,770
of rounds times the maximum space usage

164
00:07:12,770 --> 00:07:14,720
the maximum number of pebbles on the

165
00:07:14,720 --> 00:07:18,440
graph at any point in time now this is a

166
00:07:18,440 --> 00:07:20,479
nice notion and there's a rich theory

167
00:07:20,479 --> 00:07:23,720
with lots of space-time trade-off

168
00:07:23,720 --> 00:07:24,979
theorems that have been proved in this

169
00:07:24,979 --> 00:07:28,850
model but I claim that this is not the

170
00:07:28,850 --> 00:07:31,039
appropriate metric for password hashing

171
00:07:31,039 --> 00:07:33,710
and why do I say that well the problem

172
00:07:33,710 --> 00:07:37,310
is amortization so for parallel

173
00:07:37,310 --> 00:07:40,220
computation st complexity can scale

174
00:07:40,220 --> 00:07:42,229
badly in the number of evaluations of

175
00:07:42,229 --> 00:07:44,780
the function remember that the adversary

176
00:07:44,780 --> 00:07:46,310
is trying to compute this function from

177
00:07:46,310 --> 00:07:47,990
multiple different password guesses he's

178
00:07:47,990 --> 00:07:49,729
trying to evaluate many instances of

179
00:07:49,729 --> 00:07:51,710
this function so consider a function

180
00:07:51,710 --> 00:07:54,349
which requires lots of space at the

181
00:07:54,349 --> 00:07:56,030
beginning and then runs for a long time

182
00:07:56,030 --> 00:07:58,970
with minimal space usage well if we can

183
00:07:58,970 --> 00:08:01,940
execute this function in parallel then

184
00:08:01,940 --> 00:08:03,830
effectively the cost of computing say

185
00:08:03,830 --> 00:08:07,550
three instances of this function really

186
00:08:07,550 --> 00:08:10,070
has space time complexity just about

187
00:08:10,070 --> 00:08:12,289
equal to the space time complexity of

188
00:08:12,289 --> 00:08:13,880
computing one instance of this function

189
00:08:13,880 --> 00:08:16,970
and all would answer Benito showed that

190
00:08:16,970 --> 00:08:19,430
you can construct example functions

191
00:08:19,430 --> 00:08:21,710
where this scaling is even much worse

192
00:08:21,710 --> 00:08:23,750
you can compute square root end

193
00:08:23,750 --> 00:08:28,099
functions with the same esky cost all

194
00:08:28,099 --> 00:08:32,599
right so here's an improved cost metric

195
00:08:32,599 --> 00:08:34,909
which is called cumulative complexity

196
00:08:34,909 --> 00:08:38,059
instead of looking at time times the

197
00:08:38,059 --> 00:08:40,669
maximum space usage you just some space

198
00:08:40,669 --> 00:08:44,900
usage over every pebble in time step and

199
00:08:44,900 --> 00:08:46,640
the nice thing about this metric is it

200
00:08:46,640 --> 00:08:50,750
actually does amortize in fact the cost

201
00:08:50,750 --> 00:08:52,820
of pebble in two independent instances

202
00:08:52,820 --> 00:08:55,730
of a graph is exactly twice the cost of

203
00:08:55,730 --> 00:08:56,060
pebble

204
00:08:56,060 --> 00:09:00,020
one instance so in our previous example

205
00:09:00,020 --> 00:09:03,230
the cost of this pebble is seven because

206
00:09:03,230 --> 00:09:04,670
we just some the number of pebbles on

207
00:09:04,670 --> 00:09:07,850
the graph at each point in time all

208
00:09:07,850 --> 00:09:11,240
right so so the metric we use in in this

209
00:09:11,240 --> 00:09:12,860
work is actually a little bit more

210
00:09:12,860 --> 00:09:14,900
refined it's called energy complexity

211
00:09:14,900 --> 00:09:16,820
it's very similar to cumulative

212
00:09:16,820 --> 00:09:18,950
complexity except we add an additional

213
00:09:18,950 --> 00:09:22,000
term to model the cost of querying H

214
00:09:22,000 --> 00:09:24,170
every time we query this function it

215
00:09:24,170 --> 00:09:26,540
costs a little bit extra energy and so

216
00:09:26,540 --> 00:09:29,750
we want to charge ourselves for that

217
00:09:29,750 --> 00:09:32,690
cost so every time we call we're eh

218
00:09:32,690 --> 00:09:36,290
we're going to charge a cost r and in an

219
00:09:36,290 --> 00:09:38,450
asymptotic sense this is actually

220
00:09:38,450 --> 00:09:41,690
equivalent to cumulative complexity but

221
00:09:41,690 --> 00:09:44,330
in a physical sense it seems to more

222
00:09:44,330 --> 00:09:45,680
closely model what's going on in

223
00:09:45,680 --> 00:09:50,480
hardware okay so a data independent

224
00:09:50,480 --> 00:09:52,279
memory heart function is given not only

225
00:09:52,279 --> 00:09:55,250
by a graph but also by a naive peddling

226
00:09:55,250 --> 00:09:57,410
algorithm this is the algorithm that the

227
00:09:57,410 --> 00:10:00,470
honest party is supposed to use so the

228
00:10:00,470 --> 00:10:02,480
naive algorithm coupling algorithm

229
00:10:02,480 --> 00:10:04,520
should be sequential you should only

230
00:10:04,520 --> 00:10:06,260
place one new pebble on the graph at

231
00:10:06,260 --> 00:10:10,640
each during each round and for example

232
00:10:10,640 --> 00:10:14,270
of many IMA chefs are just defined by

233
00:10:14,270 --> 00:10:16,430
the midnight peddling algorithm and the

234
00:10:16,430 --> 00:10:18,350
nice tumbling algorithm you kind of just

235
00:10:18,350 --> 00:10:20,180
pebble the graph in topological order

236
00:10:20,180 --> 00:10:23,570
never removing pebbles from the graph so

237
00:10:23,570 --> 00:10:27,710
the time here is n takes ten rounds to

238
00:10:27,710 --> 00:10:30,320
pebble last node and on average you have

239
00:10:30,320 --> 00:10:31,970
about n over two pebbles on the graph

240
00:10:31,970 --> 00:10:34,040
during each step so the energy

241
00:10:34,040 --> 00:10:38,270
complexity scales is N squared alright

242
00:10:38,270 --> 00:10:42,110
and we'll define a tack quality given an

243
00:10:42,110 --> 00:10:44,240
algorithm a that the adversary might use

244
00:10:44,240 --> 00:10:47,570
to evaluate this I MHS attack quality is

245
00:10:47,570 --> 00:10:50,839
the energy cost the naive algorithm /

246
00:10:50,839 --> 00:10:53,150
the energy cost of the adversaries

247
00:10:53,150 --> 00:10:55,640
algorithm multiplied by the number of

248
00:10:55,640 --> 00:10:57,890
instances that the adversary is

249
00:10:57,890 --> 00:10:59,570
computing so if the adversary is

250
00:10:59,570 --> 00:11:01,310
concluding a hundred instances of this I

251
00:11:01,310 --> 00:11:05,680
mhf then we'll scale this by a hundred

252
00:11:05,709 --> 00:11:08,510
okay so what are the desirable goals for

253
00:11:08,510 --> 00:11:09,470
a data independent

254
00:11:09,470 --> 00:11:11,570
memory hard function well we want to

255
00:11:11,570 --> 00:11:13,490
graph G which ideally should have

256
00:11:13,490 --> 00:11:14,870
constant in degree so we can actually

257
00:11:14,870 --> 00:11:18,050
apply the compression function and we

258
00:11:18,050 --> 00:11:19,940
want to guarantee that for any adversary

259
00:11:19,940 --> 00:11:23,240
a that the attack quality is small less

260
00:11:23,240 --> 00:11:25,130
than or equal to C for some hopefully

261
00:11:25,130 --> 00:11:29,180
small constant C and finally we also

262
00:11:29,180 --> 00:11:31,130
want to guarantee that the cost of the

263
00:11:31,130 --> 00:11:33,530
naive algorithm is fairly large roughly

264
00:11:33,530 --> 00:11:35,600
n squared over tau or hopefully some

265
00:11:35,600 --> 00:11:39,260
small value tau now this last criteria

266
00:11:39,260 --> 00:11:41,000
might seem a little bit confusing why do

267
00:11:41,000 --> 00:11:43,730
we want the knee naive algorithm to be

268
00:11:43,730 --> 00:11:47,210
expensive well for one it rules out this

269
00:11:47,210 --> 00:11:49,250
type of graph where you can pebble it

270
00:11:49,250 --> 00:11:53,150
with very low space in particular that

271
00:11:53,150 --> 00:11:55,100
graph is bad because you have a low cost

272
00:11:55,100 --> 00:11:57,680
per step users are impatient so the

273
00:11:57,680 --> 00:11:59,300
maximum cost you can incur in a

274
00:11:59,300 --> 00:12:02,480
particular time frame is fairly low and

275
00:12:02,480 --> 00:12:04,610
secondly memory costs turn are an

276
00:12:04,610 --> 00:12:06,470
insignificant portion of the total cost

277
00:12:06,470 --> 00:12:08,480
of computing this function which means

278
00:12:08,480 --> 00:12:11,570
that when you implement this attack con

279
00:12:11,570 --> 00:12:14,510
and asic for example you might expect to

280
00:12:14,510 --> 00:12:17,900
see a dramatic cost reduction so this

281
00:12:17,900 --> 00:12:20,150
criteria is really saying that memory

282
00:12:20,150 --> 00:12:22,070
costs this n squared over cow term

283
00:12:22,070 --> 00:12:27,860
should dominate so we'll say that a i m

284
00:12:27,860 --> 00:12:31,070
hf is c ideal if attack quality is

285
00:12:31,070 --> 00:12:34,040
smaller than c and the cost of the naive

286
00:12:34,040 --> 00:12:35,780
algorithm is sufficiently large for some

287
00:12:35,780 --> 00:12:41,720
small constant cal all right so let me

288
00:12:41,720 --> 00:12:44,620
to quickly describe our attacks and the

289
00:12:44,620 --> 00:12:47,060
key takeaway here is that depth

290
00:12:47,060 --> 00:12:50,890
robustness is a necessary condition for

291
00:12:50,890 --> 00:12:54,350
an IM hf to satisfy in particular will

292
00:12:54,350 --> 00:12:56,270
give an attack on any graph that doesn't

293
00:12:56,270 --> 00:12:58,700
satisfy this combinatorial property

294
00:12:58,700 --> 00:13:00,080
called depth robustness which i'm going

295
00:13:00,080 --> 00:13:03,230
to define next so what does it mean to

296
00:13:03,230 --> 00:13:05,330
be a depth or bust well first of all we

297
00:13:05,330 --> 00:13:07,880
say that a graph G is Ed reducible if

298
00:13:07,880 --> 00:13:11,180
there exists a small subset s of at most

299
00:13:11,180 --> 00:13:14,570
enotes such that by removing the notes

300
00:13:14,570 --> 00:13:17,750
in s from the graph G the length of any

301
00:13:17,750 --> 00:13:19,580
path and the remaining graph is that

302
00:13:19,580 --> 00:13:23,220
most of d so for example this graph here

303
00:13:23,220 --> 00:13:26,100
is 12 reducible in particular if we

304
00:13:26,100 --> 00:13:28,920
delete the node 2 node 3 then any path

305
00:13:28,920 --> 00:13:32,339
has a length at most 2 of course if a

306
00:13:32,339 --> 00:13:34,740
graph is not eat irreducible then we'll

307
00:13:34,740 --> 00:13:39,000
call it ed depth robust alright so

308
00:13:39,000 --> 00:13:41,339
here's a general attack that works on

309
00:13:41,339 --> 00:13:44,250
any heed irreducible graph as input will

310
00:13:44,250 --> 00:13:46,889
start off with a set s of at most enotes

311
00:13:46,889 --> 00:13:49,829
such that the depth of G minus s is

312
00:13:49,829 --> 00:13:52,199
small and will also start with an attack

313
00:13:52,199 --> 00:13:55,110
parameter G which has to be larger than

314
00:13:55,110 --> 00:13:58,920
the depth of the resulting graph so the

315
00:13:58,920 --> 00:14:01,290
attack is divided into two phases late

316
00:14:01,290 --> 00:14:04,050
phases which are cheap and balloon

317
00:14:04,050 --> 00:14:06,389
phases which are expensive during the

318
00:14:06,389 --> 00:14:08,639
light phase of each light phase last g

319
00:14:08,639 --> 00:14:10,680
rounds and the goal is just to make

320
00:14:10,680 --> 00:14:13,560
progress pebble the next G Rho G nodes

321
00:14:13,560 --> 00:14:17,550
and G sequential steps now this phase

322
00:14:17,550 --> 00:14:19,350
uses low memory because we're going to

323
00:14:19,350 --> 00:14:20,899
discard all pebbles from the graph

324
00:14:20,899 --> 00:14:23,639
except for pebbles on the set s and

325
00:14:23,639 --> 00:14:25,620
pebbles on the parents of notes that we

326
00:14:25,620 --> 00:14:28,829
need to pebble in this late phase the

327
00:14:28,829 --> 00:14:31,410
key point is that this phase lasts a

328
00:14:31,410 --> 00:14:34,170
long time now of course at the end of

329
00:14:34,170 --> 00:14:37,949
the balloon phase we need to recover the

330
00:14:37,949 --> 00:14:40,230
pebbles of the parents in the next light

331
00:14:40,230 --> 00:14:41,730
phase before you can continue to make

332
00:14:41,730 --> 00:14:43,889
progress so we'll execute a balloon

333
00:14:43,889 --> 00:14:46,019
phase and in a balloon phase we're just

334
00:14:46,019 --> 00:14:47,730
going to greedily recover all the

335
00:14:47,730 --> 00:14:51,059
missing pebbles and this is expensive it

336
00:14:51,059 --> 00:14:53,490
uses parallelism but the key point is

337
00:14:53,490 --> 00:14:55,199
that because the graph has depth at most

338
00:14:55,199 --> 00:14:57,629
D we can compute this we can complete

339
00:14:57,629 --> 00:15:02,009
this phase quickly and in fact the

340
00:15:02,009 --> 00:15:04,500
attack is relatively simple I don't

341
00:15:04,500 --> 00:15:05,910
expect you to read all these lines of

342
00:15:05,910 --> 00:15:08,550
code but my point here is that you can

343
00:15:08,550 --> 00:15:10,470
describe the algorithm completely using

344
00:15:10,470 --> 00:15:15,240
just 13 lines of pseudocode alright so

345
00:15:15,240 --> 00:15:17,129
our main theorem is that depth

346
00:15:17,129 --> 00:15:19,620
robustness is necessary and particularly

347
00:15:19,620 --> 00:15:22,680
if G is ed reducible then there's an

348
00:15:22,680 --> 00:15:24,300
efficient attack a with the following

349
00:15:24,300 --> 00:15:27,209
energy complexity so the first term here

350
00:15:27,209 --> 00:15:29,670
upper bounds pebbles stored on nodes in

351
00:15:29,670 --> 00:15:33,630
the set s here e is an upper bound on

352
00:15:33,630 --> 00:15:35,160
the size of s and n is the number of

353
00:15:35,160 --> 00:15:36,240
public rounds

354
00:15:36,240 --> 00:15:39,240
the next term upper bounds the number of

355
00:15:39,240 --> 00:15:41,700
pebbles kept fun parents of the next G

356
00:15:41,700 --> 00:15:43,620
notes to be pebbled in each light phase

357
00:15:43,620 --> 00:15:46,279
your Delta is the maximum in degree and

358
00:15:46,279 --> 00:15:50,010
this final term here upper bounds the

359
00:15:50,010 --> 00:15:52,170
cost of blue in phases here n over G is

360
00:15:52,170 --> 00:15:54,779
the total number of balloon phases n is

361
00:15:54,779 --> 00:15:57,360
the number of maximum number of pebbles

362
00:15:57,360 --> 00:15:58,830
on the graph during the blue in phase

363
00:15:58,830 --> 00:16:01,529
and D is the maximum length of a balloon

364
00:16:01,529 --> 00:16:04,399
phase so if we set our parameters

365
00:16:04,399 --> 00:16:06,450
appropriately we get the following

366
00:16:06,450 --> 00:16:10,020
energy complexity and in particular

367
00:16:10,020 --> 00:16:14,820
observe that if Ed are sub linear then

368
00:16:14,820 --> 00:16:17,630
the energy complexity is sub quadratic

369
00:16:17,630 --> 00:16:22,890
which is bad alright so this motivates

370
00:16:22,890 --> 00:16:25,680
the natural question our existing I mhf

371
00:16:25,680 --> 00:16:27,480
candidates based on depth robust graphs

372
00:16:27,480 --> 00:16:30,649
and we'll consider three candidates

373
00:16:30,649 --> 00:16:33,240
katina which received special

374
00:16:33,240 --> 00:16:35,250
recognition during the password hashing

375
00:16:35,250 --> 00:16:39,300
competition there's two variants lewin

376
00:16:39,300 --> 00:16:42,000
hashing which is a newer proposal with

377
00:16:42,000 --> 00:16:44,490
three variants two of the variance in

378
00:16:44,490 --> 00:16:46,380
terms of depth robustness are similar to

379
00:16:46,380 --> 00:16:48,930
Cana and left variant in terms of depth

380
00:16:48,930 --> 00:16:51,110
robustness is similar to argon too and

381
00:16:51,110 --> 00:16:54,089
last but not least we analyze are gone

382
00:16:54,089 --> 00:16:56,190
too which is the winner of the password

383
00:16:56,190 --> 00:16:59,339
hashing competition and in particular

384
00:16:59,339 --> 00:17:01,529
are gone to I the data independent mode

385
00:17:01,529 --> 00:17:03,240
is the one that's recommended for

386
00:17:03,240 --> 00:17:06,300
password hashing I should note here that

387
00:17:06,300 --> 00:17:10,290
in the paper we analyzed argon Qi a the

388
00:17:10,290 --> 00:17:11,880
version from the password hashing

389
00:17:11,880 --> 00:17:14,189
competition argon has been updated

390
00:17:14,189 --> 00:17:17,699
several times and I'll just mention that

391
00:17:17,699 --> 00:17:20,220
our attack ideas do extend to argon to

392
00:17:20,220 --> 00:17:22,319
IB which is the newest version of our

393
00:17:22,319 --> 00:17:27,300
gun okay so brief outline of the attack

394
00:17:27,300 --> 00:17:29,760
first we show that any layered graph is

395
00:17:29,760 --> 00:17:32,070
reducible I'll define layered graphs in

396
00:17:32,070 --> 00:17:34,440
the next slide and this shows that we

397
00:17:34,440 --> 00:17:36,390
can attack Katina because Katina DAGs

398
00:17:36,390 --> 00:17:39,000
are layered eggs and then we'll show

399
00:17:39,000 --> 00:17:41,760
that an argon to ID a gag is almost a

400
00:17:41,760 --> 00:17:43,590
layered AG in the sense that we can

401
00:17:43,590 --> 00:17:45,660
remove just a few notes and the

402
00:17:45,660 --> 00:17:47,760
resulting graph is a layered tag hence

403
00:17:47,760 --> 00:17:49,490
art on queue ID eggs are also

404
00:17:49,490 --> 00:17:53,059
usable all right so let's work our way

405
00:17:53,059 --> 00:17:55,940
up and start with layered graph layered

406
00:17:55,940 --> 00:17:58,309
graph is just n nodes arranged into

407
00:17:58,309 --> 00:18:01,070
lambda layers of equal size last note in

408
00:18:01,070 --> 00:18:02,630
each layer is connected to the first

409
00:18:02,630 --> 00:18:06,440
node in the next layer and any

410
00:18:06,440 --> 00:18:09,080
additional edge in this graph must go

411
00:18:09,080 --> 00:18:10,970
from a lower layer to a higher late

412
00:18:10,970 --> 00:18:13,340
layer so in particular the only thing

413
00:18:13,340 --> 00:18:15,320
you note need to know is that edges of

414
00:18:15,320 --> 00:18:18,679
this form are disallowed now I claim

415
00:18:18,679 --> 00:18:21,650
that these graphs are reducible why is

416
00:18:21,650 --> 00:18:23,870
that well we can break up each layer

417
00:18:23,870 --> 00:18:26,179
into segments of size n to the one-third

418
00:18:26,179 --> 00:18:29,210
and now we'll just add the last node in

419
00:18:29,210 --> 00:18:32,840
each segment to our set s well after we

420
00:18:32,840 --> 00:18:34,910
delete these red nodes I claim that any

421
00:18:34,910 --> 00:18:37,190
path P can spend at most n to the

422
00:18:37,190 --> 00:18:39,830
one-third steps on layer I and there's

423
00:18:39,830 --> 00:18:41,840
that most lambda layers where lambda is

424
00:18:41,840 --> 00:18:44,630
a small constant so the total graphs of

425
00:18:44,630 --> 00:18:47,660
the depth of the graph is lambda times

426
00:18:47,660 --> 00:18:50,480
end of the one-third in particular this

427
00:18:50,480 --> 00:18:52,820
gives us attacks with energy complexity

428
00:18:52,820 --> 00:18:55,900
end of the five thirds or if you prefer

429
00:18:55,900 --> 00:18:58,790
attack quality scaling as n to the one

430
00:18:58,790 --> 00:19:02,330
third all right so what does the argon

431
00:19:02,330 --> 00:19:05,120
to i dag look like well you start off

432
00:19:05,120 --> 00:19:07,100
with a chain of n nodes as before and

433
00:19:07,100 --> 00:19:10,070
for every node I you pick a random

434
00:19:10,070 --> 00:19:12,740
predecessor uniformly at random from all

435
00:19:12,740 --> 00:19:15,080
previous nodes I should note that this

436
00:19:15,080 --> 00:19:16,550
randomness doesn't depend on the user

437
00:19:16,550 --> 00:19:21,260
input it's fixed once and for all so now

438
00:19:21,260 --> 00:19:23,270
if we kind of squint a little bit and

439
00:19:23,270 --> 00:19:25,940
just arrange the graphing layers it kind

440
00:19:25,940 --> 00:19:30,530
of looks like a layered crap well except

441
00:19:30,530 --> 00:19:32,660
that when we arrange it in layers there

442
00:19:32,660 --> 00:19:35,570
are some notes here with edges that stay

443
00:19:35,570 --> 00:19:37,580
in the same layer so the first thing

444
00:19:37,580 --> 00:19:39,620
we're going to do is we're going to add

445
00:19:39,620 --> 00:19:44,059
a node to our set s if its parent stays

446
00:19:44,059 --> 00:19:45,770
in the same layer if it's random parent

447
00:19:45,770 --> 00:19:47,630
stays in the same layer and I claim that

448
00:19:47,630 --> 00:19:49,670
by doing so we increase the size of the

449
00:19:49,670 --> 00:19:52,790
set s by a factor of will enter the

450
00:19:52,790 --> 00:19:55,550
three fourths times log in why is this

451
00:19:55,550 --> 00:19:59,300
well consider layer I and consider a

452
00:19:59,300 --> 00:20:01,130
particular note on layer I the

453
00:20:01,130 --> 00:20:03,170
probability that we choose a parent

454
00:20:03,170 --> 00:20:05,150
and the same layer is that most one over

455
00:20:05,150 --> 00:20:08,240
I so the expected number of notes that

456
00:20:08,240 --> 00:20:10,910
we add to our set on layer I is n to the

457
00:20:10,910 --> 00:20:13,810
three-fourths the size of the layer / I

458
00:20:13,810 --> 00:20:15,830
summing over all layers we get a

459
00:20:15,830 --> 00:20:17,540
harmonic some and we get end of the

460
00:20:17,540 --> 00:20:21,770
three ports times log in now as before

461
00:20:21,770 --> 00:20:25,310
we'll split up each layer into segments

462
00:20:25,310 --> 00:20:28,880
of size n to the one-fourth and any path

463
00:20:28,880 --> 00:20:31,610
can spend at most 10 to 14 steps on each

464
00:20:31,610 --> 00:20:33,850
layer there's n to the one-fourth layers

465
00:20:33,850 --> 00:20:36,050
so the total depth of the graph of that

466
00:20:36,050 --> 00:20:42,110
most root n ok so this gives us an

467
00:20:42,110 --> 00:20:44,240
attack with energy complexity scaling as

468
00:20:44,240 --> 00:20:46,700
n to the seven-fourths or quality n to

469
00:20:46,700 --> 00:20:49,670
the one force which is quite high in an

470
00:20:49,670 --> 00:20:52,520
asymptotic sense remember we want energy

471
00:20:52,520 --> 00:20:57,770
complexity n squared ok so this shows

472
00:20:57,770 --> 00:20:59,960
that existing imh up so it can be

473
00:20:59,960 --> 00:21:03,830
attacked the this motivates the question

474
00:21:03,830 --> 00:21:06,590
do I deal memory hard functions even

475
00:21:06,590 --> 00:21:09,170
exist and an answer that might make the

476
00:21:09,170 --> 00:21:11,330
adversary happy is no they don't in

477
00:21:11,330 --> 00:21:14,930
particular any graph with constant in

478
00:21:14,930 --> 00:21:17,890
degree is sufficiently depth reducible

479
00:21:17,890 --> 00:21:20,480
but it end it's at most at least some

480
00:21:20,480 --> 00:21:23,060
attack in particular energy complexity

481
00:21:23,060 --> 00:21:28,400
can be at most n squared over log in so

482
00:21:28,400 --> 00:21:32,480
in practice against argon we start to

483
00:21:32,480 --> 00:21:35,150
get a positive attacks around two to the

484
00:21:35,150 --> 00:21:38,510
18 and attack quality skyrockets after

485
00:21:38,510 --> 00:21:41,180
this I should note that this plot only

486
00:21:41,180 --> 00:21:44,630
shows up only shows theoretical upper

487
00:21:44,630 --> 00:21:46,340
bound so it's very possible that attack

488
00:21:46,340 --> 00:21:49,790
quality is even better in practice but

489
00:21:49,790 --> 00:21:51,890
these plots show that actually in

490
00:21:51,890 --> 00:21:54,230
practice it may still be possible to

491
00:21:54,230 --> 00:21:57,230
obtain a secure I mhf but because if you

492
00:21:57,230 --> 00:22:00,440
look at a kind of the ideal mhf this 10

493
00:22:00,440 --> 00:22:04,130
squared over log in one attack quality

494
00:22:04,130 --> 00:22:07,160
doesn't exceed one until at least two to

495
00:22:07,160 --> 00:22:10,220
the 50 so that still might be a feasible

496
00:22:10,220 --> 00:22:14,360
goal in practice now we have some new

497
00:22:14,360 --> 00:22:17,059
results basically

498
00:22:17,059 --> 00:22:20,330
simulating our attack and these results

499
00:22:20,330 --> 00:22:22,940
show that actually our attack is much

500
00:22:22,940 --> 00:22:26,149
more efficient in practice in particular

501
00:22:26,149 --> 00:22:28,669
we still get high quality attacks

502
00:22:28,669 --> 00:22:31,029
against the new version of argon to I be

503
00:22:31,029 --> 00:22:36,259
with pessimistic parameters and for non

504
00:22:36,259 --> 00:22:37,820
pessimistic parameters which could

505
00:22:37,820 --> 00:22:39,320
easily be chosen by the parameter

506
00:22:39,320 --> 00:22:42,200
selection process attack quality is kind

507
00:22:42,200 --> 00:22:46,669
of through the root all right let me

508
00:22:46,669 --> 00:22:49,960
take 30 seconds and just highlight some

509
00:22:49,960 --> 00:22:53,690
breaking results so this talk we show

510
00:22:53,690 --> 00:22:55,850
that depth robustness is necessary it's

511
00:22:55,850 --> 00:22:58,549
also sufficient if a graph is Ed depth

512
00:22:58,549 --> 00:23:00,409
robust then energy complexity is at

513
00:23:00,409 --> 00:23:03,470
least a times B and this actually does

514
00:23:03,470 --> 00:23:06,409
lead to kind of optimal I mhf

515
00:23:06,409 --> 00:23:07,879
constructions you can actually achieve

516
00:23:07,879 --> 00:23:13,460
this N squared over log in bound some

517
00:23:13,460 --> 00:23:16,100
more results we can improve the upper

518
00:23:16,100 --> 00:23:18,559
and upper bounds on argonne qi by just

519
00:23:18,559 --> 00:23:21,200
applying our attack recursively during a

520
00:23:21,200 --> 00:23:24,769
balloon phase and in fact you can also

521
00:23:24,769 --> 00:23:27,740
prove some lower bounds so our gone to I

522
00:23:27,740 --> 00:23:30,980
has energy complexity at least n to the

523
00:23:30,980 --> 00:23:36,529
1 point 6 6 and finally a script which

524
00:23:36,529 --> 00:23:39,559
the original beta dependent memory heart

525
00:23:39,559 --> 00:23:42,369
function actually does have optimal

526
00:23:42,369 --> 00:23:45,350
energy complexity so there's a clear gap

527
00:23:45,350 --> 00:23:47,389
here between data independent and data

528
00:23:47,389 --> 00:23:50,480
dependent hash functions so in

529
00:23:50,480 --> 00:23:52,549
conclusion depth robustness is a

530
00:23:52,549 --> 00:23:54,669
necessary condition for provably secure

531
00:23:54,669 --> 00:23:57,919
omhs and i would say the major open

532
00:23:57,919 --> 00:23:59,869
challenge in the area right now is to

533
00:23:59,869 --> 00:24:01,669
improve the constructions of depth

534
00:24:01,669 --> 00:24:04,490
robust graphs we have constructions in

535
00:24:04,490 --> 00:24:07,669
theory going back to Erdos at all in the

536
00:24:07,669 --> 00:24:10,759
70s but as you can imagine they didn't

537
00:24:10,759 --> 00:24:12,619
particularly care about the constants

538
00:24:12,619 --> 00:24:14,210
and their constructions and in practice

539
00:24:14,210 --> 00:24:17,960
these constants do matter so thank you

540
00:24:17,960 --> 00:24:20,230
for listening and I'll take questions

541
00:24:20,230 --> 00:24:22,320
you

