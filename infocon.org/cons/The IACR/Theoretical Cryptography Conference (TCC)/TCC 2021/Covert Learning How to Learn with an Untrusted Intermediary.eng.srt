1
00:00:01,040 --> 00:00:04,160
hello and welcome to my tcc talk my name

2
00:00:04,160 --> 00:00:06,480
is ari karchmer and i'll be presenting a

3
00:00:06,480 --> 00:00:08,720
paper titled covert learning how to

4
00:00:08,720 --> 00:00:11,040
learn with an untrusted intermediary

5
00:00:11,040 --> 00:00:14,639
this is joint work with ron connetty

6
00:00:14,639 --> 00:00:17,039
so to illustrate the topic of this talk

7
00:00:17,039 --> 00:00:18,720
i'll start with a story

8
00:00:18,720 --> 00:00:20,480
let's say that there is a biologist

9
00:00:20,480 --> 00:00:22,720
named alice who wishes to develop a

10
00:00:22,720 --> 00:00:25,359
so-called structure activity model

11
00:00:25,359 --> 00:00:27,760
a structure activity model describes how

12
00:00:27,760 --> 00:00:29,920
a certain set of molecule features

13
00:00:29,920 --> 00:00:31,760
influences activity

14
00:00:31,760 --> 00:00:33,760
here features could be any molecule

15
00:00:33,760 --> 00:00:36,960
attributes like components size or shape

16
00:00:36,960 --> 00:00:38,879
while activity is basically whether or

17
00:00:38,879 --> 00:00:41,360
not the molecule in question binds to a

18
00:00:41,360 --> 00:00:45,520
specific fixed protein or cell

19
00:00:45,520 --> 00:00:47,840
now let's say that alice being an expert

20
00:00:47,840 --> 00:00:49,920
in her field has some advanced domain

21
00:00:49,920 --> 00:00:52,239
knowledge that allows her to hypothesize

22
00:00:52,239 --> 00:00:54,480
some subset of structure activity models

23
00:00:54,480 --> 00:00:56,879
out of all such possible

24
00:00:56,879 --> 00:00:58,960
then to actually learn the best model

25
00:00:58,960 --> 00:01:01,120
she encodes her hypothesis into a

26
00:01:01,120 --> 00:01:03,199
specific set of experiments that she

27
00:01:03,199 --> 00:01:05,280
will conduct and then process into her

28
00:01:05,280 --> 00:01:08,880
final structure activity model

29
00:01:08,880 --> 00:01:11,200
so alice takes her experiments and reads

30
00:01:11,200 --> 00:01:12,560
the results

31
00:01:12,560 --> 00:01:14,640
and maybe based on these results alice

32
00:01:14,640 --> 00:01:16,560
designs some new experiments and runs

33
00:01:16,560 --> 00:01:18,400
those

34
00:01:18,400 --> 00:01:20,880
and now the complication and the story

35
00:01:20,880 --> 00:01:23,759
is that alice has a lab mate called eve

36
00:01:23,759 --> 00:01:25,840
eve is quietly spying on alice and so

37
00:01:25,840 --> 00:01:27,600
she observes all the experiments and the

38
00:01:27,600 --> 00:01:28,880
results

39
00:01:28,880 --> 00:01:30,720
so the main question i'll consider in

40
00:01:30,720 --> 00:01:32,640
the majority of this talk is how can

41
00:01:32,640 --> 00:01:34,720
alice continue to run her experiments in

42
00:01:34,720 --> 00:01:36,960
the lab so that she can obtain a good

43
00:01:36,960 --> 00:01:39,119
model while preventing eve from using

44
00:01:39,119 --> 00:01:41,280
the experimental design to gain any

45
00:01:41,280 --> 00:01:42,880
knowledge about alice's initial

46
00:01:42,880 --> 00:01:44,479
hypothesis

47
00:01:44,479 --> 00:01:46,960
and furthermore i'll consider how can

48
00:01:46,960 --> 00:01:49,040
alice prevent any knowledge leakage

49
00:01:49,040 --> 00:01:51,119
about even the actual structure activity

50
00:01:51,119 --> 00:01:53,040
relationship that is revealed by the

51
00:01:53,040 --> 00:01:55,119
experimental results

52
00:01:55,119 --> 00:01:56,880
and i'll note that what makes these

53
00:01:56,880 --> 00:01:58,240
questions interesting is that the

54
00:01:58,240 --> 00:01:59,600
molecules aren't traditional

55
00:01:59,600 --> 00:02:01,840
computational entities we can't just

56
00:02:01,840 --> 00:02:03,600
establish a secure channel with them

57
00:02:03,600 --> 00:02:07,520
which would take eve out of the equation

58
00:02:07,600 --> 00:02:09,440
then in the second part of this talk

59
00:02:09,440 --> 00:02:11,520
i'll further complicate the story

60
00:02:11,520 --> 00:02:13,599
now imagine that after starting her

61
00:02:13,599 --> 00:02:16,000
experiments alice's contact traced and

62
00:02:16,000 --> 00:02:18,319
she must isolate making her unable to

63
00:02:18,319 --> 00:02:20,560
read the experimental results

64
00:02:20,560 --> 00:02:23,200
therefore alice has to ask eve to read

65
00:02:23,200 --> 00:02:25,280
and report to her the results

66
00:02:25,280 --> 00:02:27,200
so in the second part of this talk i'll

67
00:02:27,200 --> 00:02:29,680
consider how can alice verify the

68
00:02:29,680 --> 00:02:31,760
results reported by eve

69
00:02:31,760 --> 00:02:33,760
and this is in addition to maintaining

70
00:02:33,760 --> 00:02:36,160
the privacy of her hypothesis and the

71
00:02:36,160 --> 00:02:39,840
structure activity relationship

72
00:02:39,920 --> 00:02:42,080
let me now distill this story into a

73
00:02:42,080 --> 00:02:44,000
short list of informal goals which

74
00:02:44,000 --> 00:02:46,239
together form the covert verifiable

75
00:02:46,239 --> 00:02:47,840
learning model

76
00:02:47,840 --> 00:02:50,480
first up is learning so if eve reports

77
00:02:50,480 --> 00:02:52,560
the experimental results truthfully

78
00:02:52,560 --> 00:02:54,400
alice learns a good model from her

79
00:02:54,400 --> 00:02:56,080
experiments

80
00:02:56,080 --> 00:02:58,080
then there's concept hiding which is the

81
00:02:58,080 --> 00:03:00,080
guarantee that no or maybe little

82
00:03:00,080 --> 00:03:01,680
information about the molecular

83
00:03:01,680 --> 00:03:03,920
relationship is leaked and this is true

84
00:03:03,920 --> 00:03:05,760
at least when alice's random coins

85
00:03:05,760 --> 00:03:07,680
remain hidden

86
00:03:07,680 --> 00:03:09,920
then there's hypothesis hiding so no

87
00:03:09,920 --> 00:03:12,640
information about alice's hypothesis or

88
00:03:12,640 --> 00:03:14,319
domain knowledge used to influence the

89
00:03:14,319 --> 00:03:16,080
hypothesis is leaked

90
00:03:16,080 --> 00:03:17,599
and again this is true given that

91
00:03:17,599 --> 00:03:20,640
alice's random coins remain hidden

92
00:03:20,640 --> 00:03:23,200
and finally verifiability which is the

93
00:03:23,200 --> 00:03:25,200
guarantee that if eve tampers with the

94
00:03:25,200 --> 00:03:27,760
results she can't deceive alice into

95
00:03:27,760 --> 00:03:30,480
learning a faulty model and here we

96
00:03:30,480 --> 00:03:32,400
might let alice have private access to

97
00:03:32,400 --> 00:03:35,040
some random ground truth experiments

98
00:03:35,040 --> 00:03:36,480
which will allow her to have some

99
00:03:36,480 --> 00:03:40,400
information to leverage against eve

100
00:03:40,400 --> 00:03:42,480
now certain aspects of this problem

101
00:03:42,480 --> 00:03:44,159
setting have been studied before which

102
00:03:44,159 --> 00:03:46,560
i'll very briefly highlight first a

103
00:03:46,560 --> 00:03:48,799
recent work of goldwasser rothbum

104
00:03:48,799 --> 00:03:50,879
shaffer and yahudayoff examined a

105
00:03:50,879 --> 00:03:53,120
related model called pac verification

106
00:03:53,120 --> 00:03:54,959
which only considers analogs of the

107
00:03:54,959 --> 00:03:57,360
learning and verifiability goals

108
00:03:57,360 --> 00:03:59,120
on the other hand we have another recent

109
00:03:59,120 --> 00:04:01,760
work of ishai kushi levitz ostrovsky and

110
00:04:01,760 --> 00:04:04,080
sahai which considers a problem called

111
00:04:04,080 --> 00:04:06,319
cryptographic sensing cryptographic

112
00:04:06,319 --> 00:04:08,480
sensing focuses on analogs of learning

113
00:04:08,480 --> 00:04:11,599
and concept hiding

114
00:04:11,680 --> 00:04:13,599
now to prevent any confusion let me

115
00:04:13,599 --> 00:04:15,680
quickly tell you more what this talk is

116
00:04:15,680 --> 00:04:16,959
not about

117
00:04:16,959 --> 00:04:19,279
first off the model of differentially

118
00:04:19,279 --> 00:04:21,199
private learning considers the privacy

119
00:04:21,199 --> 00:04:23,520
of the owners of the data

120
00:04:23,520 --> 00:04:25,440
the learned hypothesis should not depend

121
00:04:25,440 --> 00:04:28,240
too much on its training data

122
00:04:28,240 --> 00:04:31,120
roughly whereas our model considers the

123
00:04:31,120 --> 00:04:33,680
privacy of the learner itself that is

124
00:04:33,680 --> 00:04:35,360
its intentions and what knowledge is

125
00:04:35,360 --> 00:04:37,120
actually gained

126
00:04:37,120 --> 00:04:38,639
additionally you might consider a

127
00:04:38,639 --> 00:04:40,800
relation of our verifiability goal to

128
00:04:40,800 --> 00:04:42,720
verifiable computation

129
00:04:42,720 --> 00:04:44,800
however this is again a separate issue

130
00:04:44,800 --> 00:04:47,360
because first verifiable computation is

131
00:04:47,360 --> 00:04:49,360
an interaction between two computational

132
00:04:49,360 --> 00:04:51,759
entities and second it is concerned with

133
00:04:51,759 --> 00:04:53,919
the computational steps themselves not

134
00:04:53,919 --> 00:04:55,759
the fact that a good hypothesis is

135
00:04:55,759 --> 00:04:57,680
actually produced

136
00:04:57,680 --> 00:04:59,840
so let me now move on to describing some

137
00:04:59,840 --> 00:05:01,680
real world use cases of covert

138
00:05:01,680 --> 00:05:03,919
verifiable learning

139
00:05:03,919 --> 00:05:07,280
one of which is lab leaks

140
00:05:07,280 --> 00:05:09,759
so it turns out that although the story

141
00:05:09,759 --> 00:05:11,680
about alice and eve might have seemed a

142
00:05:11,680 --> 00:05:14,320
bit magical it might not be too far from

143
00:05:14,320 --> 00:05:16,320
what actually goes on in the real world

144
00:05:16,320 --> 00:05:18,720
in the drug discovery industry

145
00:05:18,720 --> 00:05:20,800
i'll point out a natural correspondence

146
00:05:20,800 --> 00:05:22,960
between alice and a drug company called

147
00:05:22,960 --> 00:05:26,000
a alice's hypothesis or experimental

148
00:05:26,000 --> 00:05:28,160
design and any intellectual property

149
00:05:28,160 --> 00:05:30,560
owned by the drug company and finally

150
00:05:30,560 --> 00:05:32,960
eve and the bio lab corresponding to

151
00:05:32,960 --> 00:05:35,520
some hostile environment such as such as

152
00:05:35,520 --> 00:05:38,880
an experiment outsourcing facility

153
00:05:38,880 --> 00:05:41,199
so put in these terms our questions are

154
00:05:41,199 --> 00:05:43,759
how does a prevent trade secrets from

155
00:05:43,759 --> 00:05:45,600
being revealed by the experimental

156
00:05:45,600 --> 00:05:47,199
design

157
00:05:47,199 --> 00:05:49,600
how does a discourage the facility from

158
00:05:49,600 --> 00:05:52,639
double selling data to a competitor

159
00:05:52,639 --> 00:05:54,720
and finally how does a discourage the

160
00:05:54,720 --> 00:05:58,880
facility from returning faulty data

161
00:05:59,120 --> 00:06:01,360
and now i promise that this is the last

162
00:06:01,360 --> 00:06:03,120
time i'll bring this up but i really

163
00:06:03,120 --> 00:06:05,039
want to hammer home the point that we

164
00:06:05,039 --> 00:06:07,199
are not looking to execute a protocol

165
00:06:07,199 --> 00:06:09,520
with the outsourcing facility this is

166
00:06:09,520 --> 00:06:11,840
essential to understanding our work

167
00:06:11,840 --> 00:06:14,240
in some way or another some experiments

168
00:06:14,240 --> 00:06:16,400
desired by the drug company must be

169
00:06:16,400 --> 00:06:18,720
disclosed to the facility

170
00:06:18,720 --> 00:06:20,960
and so our algorithm can only interact

171
00:06:20,960 --> 00:06:23,120
with nature that is the structure

172
00:06:23,120 --> 00:06:24,880
activity relationship

173
00:06:24,880 --> 00:06:27,199
in other words we must encode hiding and

174
00:06:27,199 --> 00:06:29,280
verifiability into the experiments

175
00:06:29,280 --> 00:06:30,639
themselves

176
00:06:30,639 --> 00:06:32,560
and again this is what makes the problem

177
00:06:32,560 --> 00:06:34,240
interesting if nature were a

178
00:06:34,240 --> 00:06:36,400
computational entity then we could just

179
00:06:36,400 --> 00:06:41,039
establish a secure channel and be done

180
00:06:41,440 --> 00:06:43,520
you can also imagine other applications

181
00:06:43,520 --> 00:06:44,960
of covert learning

182
00:06:44,960 --> 00:06:46,639
not just the scientific discovery

183
00:06:46,639 --> 00:06:48,720
example but more generally anytime you

184
00:06:48,720 --> 00:06:50,240
want to hide what you are learning but

185
00:06:50,240 --> 00:06:52,880
can't work with any other entities

186
00:06:52,880 --> 00:06:54,800
one example of this is a connection to

187
00:06:54,800 --> 00:06:56,720
model extraction attacks

188
00:06:56,720 --> 00:06:58,160
which considers the problem of a

189
00:06:58,160 --> 00:07:00,080
malicious client trying to reverse

190
00:07:00,080 --> 00:07:01,919
engineer some model that is hosted in

191
00:07:01,919 --> 00:07:03,840
the cloud as machine learning as a

192
00:07:03,840 --> 00:07:04,960
service

193
00:07:04,960 --> 00:07:06,960
the client does this by simply querying

194
00:07:06,960 --> 00:07:09,840
the model through the cloud interface

195
00:07:09,840 --> 00:07:12,160
in this setting is a commonly proposed

196
00:07:12,160 --> 00:07:14,639
defense to have the machine learning as

197
00:07:14,639 --> 00:07:17,120
a service provider monitor the incoming

198
00:07:17,120 --> 00:07:19,199
queries per client to try to classify

199
00:07:19,199 --> 00:07:21,520
them as malicious or benign so

200
00:07:21,520 --> 00:07:23,039
essentially covert learning could

201
00:07:23,039 --> 00:07:25,440
provide an attack avenue here by hiding

202
00:07:25,440 --> 00:07:27,440
from these query monitors the intentions

203
00:07:27,440 --> 00:07:30,479
of the client

204
00:07:30,479 --> 00:07:32,400
i'll now informally state our main

205
00:07:32,400 --> 00:07:34,000
contributions which are found in our

206
00:07:34,000 --> 00:07:35,360
paper

207
00:07:35,360 --> 00:07:37,360
first we conceptualize a formal learning

208
00:07:37,360 --> 00:07:39,199
model that takes into account the hiding

209
00:07:39,199 --> 00:07:41,199
goals this is just the basic covert

210
00:07:41,199 --> 00:07:42,720
learning model

211
00:07:42,720 --> 00:07:44,800
so in this basic model we give covert

212
00:07:44,800 --> 00:07:46,639
learning algorithms for noisy parity

213
00:07:46,639 --> 00:07:48,400
functions and decision trees in an

214
00:07:48,400 --> 00:07:50,960
agnostic learning case

215
00:07:50,960 --> 00:07:52,720
then we describe how to augment the

216
00:07:52,720 --> 00:07:54,400
basic model with the verifiability

217
00:07:54,400 --> 00:07:56,560
guarantee this entails extending the

218
00:07:56,560 --> 00:07:58,400
hiding guarantees to accommodate an

219
00:07:58,400 --> 00:08:00,400
active adversary

220
00:08:00,400 --> 00:08:02,080
and then in this model we show how to

221
00:08:02,080 --> 00:08:04,400
augment the previous algorithm with

222
00:08:04,400 --> 00:08:07,520
verifiability guarantees

223
00:08:07,520 --> 00:08:08,879
next we show how to weaken the

224
00:08:08,879 --> 00:08:10,879
assumption that alice has private access

225
00:08:10,879 --> 00:08:12,960
to random ground truth examples for

226
00:08:12,960 --> 00:08:14,400
verifiability

227
00:08:14,400 --> 00:08:16,000
so that there is instead a set of

228
00:08:16,000 --> 00:08:18,479
publicly known ground truth examples

229
00:08:18,479 --> 00:08:20,240
and how to do this was previously

230
00:08:20,240 --> 00:08:22,319
unknown even in the pack verification

231
00:08:22,319 --> 00:08:24,960
model of goldwaterl which does not

232
00:08:24,960 --> 00:08:27,759
consider hiding guarantees at all

233
00:08:27,759 --> 00:08:29,360
and then finally we explore other

234
00:08:29,360 --> 00:08:31,199
settings where we can achieve stronger

235
00:08:31,199 --> 00:08:35,200
privacy and verifiability guarantees

236
00:08:35,200 --> 00:08:37,200
and in this talk we will focus on the

237
00:08:37,200 --> 00:08:40,159
first four in fact the main goal is to

238
00:08:40,159 --> 00:08:42,240
understand an intuitive version of these

239
00:08:42,240 --> 00:08:44,560
new learning models and i will also give

240
00:08:44,560 --> 00:08:46,240
some high level descriptions of the

241
00:08:46,240 --> 00:08:48,480
algorithmic ideas and proof techniques

242
00:08:48,480 --> 00:08:50,480
we use to construct learning protocols

243
00:08:50,480 --> 00:08:53,120
within them

244
00:08:53,360 --> 00:08:55,839
let's now move on to showing the covert

245
00:08:55,839 --> 00:08:57,839
learning model

246
00:08:57,839 --> 00:08:59,920
so the first observation to make when

247
00:08:59,920 --> 00:09:01,920
trying to model convert learning is that

248
00:09:01,920 --> 00:09:03,760
alice's story also hints at a

249
00:09:03,760 --> 00:09:05,519
relationship to learning with membership

250
00:09:05,519 --> 00:09:07,120
query setting

251
00:09:07,120 --> 00:09:08,640
you can view the structure activity

252
00:09:08,640 --> 00:09:10,720
relationship as a boolean function where

253
00:09:10,720 --> 00:09:12,560
the domain is a set of all assignments

254
00:09:12,560 --> 00:09:15,120
of n binary features and the codomain is

255
00:09:15,120 --> 00:09:16,720
a binary label for whether or not the

256
00:09:16,720 --> 00:09:18,959
molecule in question displayed activity

257
00:09:18,959 --> 00:09:21,040
with some fixed protein

258
00:09:21,040 --> 00:09:23,360
and from this perspective any

259
00:09:23,360 --> 00:09:24,959
experiments or screens are essentially

260
00:09:24,959 --> 00:09:26,880
membership queries to this function

261
00:09:26,880 --> 00:09:29,120
while an initially hypothesized set of

262
00:09:29,120 --> 00:09:31,519
models corresponds to a specific choice

263
00:09:31,519 --> 00:09:34,000
of hypothesis class in the agnostic pack

264
00:09:34,000 --> 00:09:35,600
learning design

265
00:09:35,600 --> 00:09:37,200
so it is important to note that we

266
00:09:37,200 --> 00:09:39,040
strongly care about working an agnostic

267
00:09:39,040 --> 00:09:40,880
learning model in order to motivate

268
00:09:40,880 --> 00:09:43,680
hypothesis hiding

269
00:09:43,680 --> 00:09:45,440
i will now go over some of this

270
00:09:45,440 --> 00:09:47,680
pac-learning terminology

271
00:09:47,680 --> 00:09:50,000
we consider a hypothesis class indexed

272
00:09:50,000 --> 00:09:52,080
by a number n as a subset of boolean

273
00:09:52,080 --> 00:09:54,320
functions

274
00:09:54,320 --> 00:09:56,720
similarly a concept class also indexed

275
00:09:56,720 --> 00:09:58,560
by a number n is a set of joint

276
00:09:58,560 --> 00:10:00,560
distributions over n-bit strings and

277
00:10:00,560 --> 00:10:02,320
single bits

278
00:10:02,320 --> 00:10:03,760
and when drawing from the concept

279
00:10:03,760 --> 00:10:05,839
distribution an example consists of an

280
00:10:05,839 --> 00:10:08,000
input and a label

281
00:10:08,000 --> 00:10:10,000
finally a loss function is a function

282
00:10:10,000 --> 00:10:11,440
that evaluates the strength of a

283
00:10:11,440 --> 00:10:14,079
hypothesis for a certain concept for

284
00:10:14,079 --> 00:10:16,320
example the probability that a randomly

285
00:10:16,320 --> 00:10:18,079
sampled data point from the concept is

286
00:10:18,079 --> 00:10:20,000
correctly labeled by the hypothesis in

287
00:10:20,000 --> 00:10:22,399
question

288
00:10:23,279 --> 00:10:25,920
now let's review agnostic pac learning

289
00:10:25,920 --> 00:10:28,079
so fixing some hypothesis class in

290
00:10:28,079 --> 00:10:29,360
concept class

291
00:10:29,360 --> 00:10:31,680
very roughly an algorithm is an agnostic

292
00:10:31,680 --> 00:10:33,760
pac learner if with respect to some

293
00:10:33,760 --> 00:10:35,360
fixed loss function

294
00:10:35,360 --> 00:10:37,279
it receives a sufficiently large set of

295
00:10:37,279 --> 00:10:39,360
random examples and can produce a

296
00:10:39,360 --> 00:10:41,200
hypothesis which is competitive with the

297
00:10:41,200 --> 00:10:45,279
best hypothesis in the fixed class

298
00:10:45,279 --> 00:10:46,800
now when there are membership queries

299
00:10:46,800 --> 00:10:48,320
allowed that means that the learning

300
00:10:48,320 --> 00:10:50,320
algorithm can also query the concept on

301
00:10:50,320 --> 00:10:51,680
specific points

302
00:10:51,680 --> 00:10:53,680
in other words the learner can bypass

303
00:10:53,680 --> 00:10:55,839
the marginal distribution over inputs

304
00:10:55,839 --> 00:10:57,839
and receive a label on any input of its

305
00:10:57,839 --> 00:10:59,360
choice

306
00:10:59,360 --> 00:11:01,600
and so why is this called the agnostic

307
00:11:01,600 --> 00:11:03,680
model well the hypothesis class doesn't

308
00:11:03,680 --> 00:11:05,600
need to contain a perfect hypothesis for

309
00:11:05,600 --> 00:11:06,720
the concept

310
00:11:06,720 --> 00:11:08,720
in fact the hypothesis class could be

311
00:11:08,720 --> 00:11:10,720
chosen independently of the concept

312
00:11:10,720 --> 00:11:11,920
class

313
00:11:11,920 --> 00:11:14,000
perhaps when no or few assumptions can

314
00:11:14,000 --> 00:11:16,880
be made about the concept class

315
00:11:16,880 --> 00:11:18,560
therefore it's clear that the choice of

316
00:11:18,560 --> 00:11:20,480
the hypothesis class is a very important

317
00:11:20,480 --> 00:11:23,120
aspect of agnostic learning the choice

318
00:11:23,120 --> 00:11:26,480
may greatly affect the outcome

319
00:11:27,200 --> 00:11:29,200
so in model and covert learning we

320
00:11:29,200 --> 00:11:31,519
largely stick to this described pac

321
00:11:31,519 --> 00:11:33,200
setting but we depart in an important

322
00:11:33,200 --> 00:11:34,399
way

323
00:11:34,399 --> 00:11:36,480
we consider a collection of hypothesis

324
00:11:36,480 --> 00:11:38,720
classes rather than a single fixed one

325
00:11:38,720 --> 00:11:40,480
for example the collection could be many

326
00:11:40,480 --> 00:11:42,399
sets of monomials where each set of

327
00:11:42,399 --> 00:11:44,720
monomials only contains variables within

328
00:11:44,720 --> 00:11:46,959
some secret subset of variables that are

329
00:11:46,959 --> 00:11:49,200
hypothesized to be relevant or important

330
00:11:49,200 --> 00:11:50,399
or useful

331
00:11:50,399 --> 00:11:52,320
so in this case the secret subset would

332
00:11:52,320 --> 00:11:54,880
be a hypothesis

333
00:11:54,880 --> 00:11:56,639
as unusual pac learning the covert

334
00:11:56,639 --> 00:11:58,240
learning algorithm takes its input

335
00:11:58,240 --> 00:12:00,560
accuracy and confidence parameters but

336
00:12:00,560 --> 00:12:02,639
then in addition some target hypothesis

337
00:12:02,639 --> 00:12:04,959
class within the collection

338
00:12:04,959 --> 00:12:06,720
as you can see from the figure we have

339
00:12:06,720 --> 00:12:08,800
an interaction with an oracle to the

340
00:12:08,800 --> 00:12:10,880
concept here the learner may request

341
00:12:10,880 --> 00:12:14,399
labels on synthesized inputs

342
00:12:14,399 --> 00:12:16,000
at the end the learner outputs a

343
00:12:16,000 --> 00:12:17,760
hypothesis that carries the agnostic

344
00:12:17,760 --> 00:12:19,760
back learning guarantee with respect to

345
00:12:19,760 --> 00:12:22,880
the input target hypothesis class

346
00:12:22,880 --> 00:12:24,720
so what's the catch

347
00:12:24,720 --> 00:12:26,639
well there's also an adversary who've

348
00:12:26,639 --> 00:12:28,240
used the entire interaction between the

349
00:12:28,240 --> 00:12:30,800
learner and the oracle that is it

350
00:12:30,800 --> 00:12:32,639
observes all membership queries and the

351
00:12:32,639 --> 00:12:33,839
results

352
00:12:33,839 --> 00:12:35,200
and then tries to obtain some

353
00:12:35,200 --> 00:12:37,200
information about either the concept or

354
00:12:37,200 --> 00:12:39,600
the chosen hypothesis class

355
00:12:39,600 --> 00:12:41,760
and so recall our goal is no information

356
00:12:41,760 --> 00:12:42,720
leakage

357
00:12:42,720 --> 00:12:44,639
but with respect to concept hiding

358
00:12:44,639 --> 00:12:46,399
obviously there are some concept classes

359
00:12:46,399 --> 00:12:47,839
which we can't hope to achieve no

360
00:12:47,839 --> 00:12:50,480
leakage for example if the concept is

361
00:12:50,480 --> 00:12:52,399
always a constant function then the

362
00:12:52,399 --> 00:12:54,160
moment a single example is shown to the

363
00:12:54,160 --> 00:12:56,800
adversary all information is leaked so

364
00:12:56,800 --> 00:12:58,720
as you probably suspected we cannot hope

365
00:12:58,720 --> 00:13:01,440
to prevent all leakage

366
00:13:01,440 --> 00:13:03,440
a bit more generally the adversary could

367
00:13:03,440 --> 00:13:04,880
apply a technique called outcome

368
00:13:04,880 --> 00:13:06,959
learning very roughly an outcome

369
00:13:06,959 --> 00:13:08,560
learning algorithm takes any set of

370
00:13:08,560 --> 00:13:10,480
examples and outputs a succinct

371
00:13:10,480 --> 00:13:12,240
hypothesis that agrees with all those

372
00:13:12,240 --> 00:13:13,440
examples

373
00:13:13,440 --> 00:13:15,440
here succinct means that some natural

374
00:13:15,440 --> 00:13:17,120
measure of its size is bounded by a

375
00:13:17,120 --> 00:13:19,440
parameter of the learning algorithm

376
00:13:19,440 --> 00:13:21,200
now it is known that outcome learning is

377
00:13:21,200 --> 00:13:23,120
essentially equivalent to pac learning

378
00:13:23,120 --> 00:13:26,560
and that one implies the other

379
00:13:26,800 --> 00:13:29,120
this equivalence will give us a nice way

380
00:13:29,120 --> 00:13:31,040
to both accept the fact that not all

381
00:13:31,040 --> 00:13:33,360
concepts can be hidden but also neatly

382
00:13:33,360 --> 00:13:36,000
put together a privacy definition

383
00:13:36,000 --> 00:13:37,680
in that definition we claim that the

384
00:13:37,680 --> 00:13:39,440
natural choice is to allow leakage of

385
00:13:39,440 --> 00:13:42,000
random examples to the concept

386
00:13:42,000 --> 00:13:44,240
as a result we define hiding as the

387
00:13:44,240 --> 00:13:45,680
requirement that there is a

388
00:13:45,680 --> 00:13:48,320
probabilistic polynomial time simulator

389
00:13:48,320 --> 00:13:50,160
which takes a set of random examples to

390
00:13:50,160 --> 00:13:52,240
the concept whose output forms a

391
00:13:52,240 --> 00:13:54,079
distribution which is computationally

392
00:13:54,079 --> 00:13:55,839
indistinguishable from the real

393
00:13:55,839 --> 00:13:57,839
interaction transcripts

394
00:13:57,839 --> 00:13:59,760
the interaction transcripts tier

395
00:13:59,760 --> 00:14:01,600
consists of all the membership queries

396
00:14:01,600 --> 00:14:04,399
and responses

397
00:14:04,480 --> 00:14:06,320
the simulator crucially works without

398
00:14:06,320 --> 00:14:08,560
knowledge of the target hypothesis class

399
00:14:08,560 --> 00:14:10,959
and no query access to the concept

400
00:14:10,959 --> 00:14:13,199
so only random examples from the concept

401
00:14:13,199 --> 00:14:15,360
are given as input to the simulator and

402
00:14:15,360 --> 00:14:17,680
this forms the only leakage at least to

403
00:14:17,680 --> 00:14:20,320
an efficient adversary

404
00:14:20,320 --> 00:14:21,920
a few more reasons why allowing the

405
00:14:21,920 --> 00:14:24,560
simulator to access random examples is

406
00:14:24,560 --> 00:14:26,959
first we obtain an interesting zero

407
00:14:26,959 --> 00:14:29,360
knowledge style guarantee here in that a

408
00:14:29,360 --> 00:14:31,680
covert learning interaction reveals only

409
00:14:31,680 --> 00:14:33,120
as much as could have already been

410
00:14:33,120 --> 00:14:34,639
learned from a public set of random

411
00:14:34,639 --> 00:14:38,079
examples to the concept that exists

412
00:14:38,079 --> 00:14:40,000
furthermore this is good because we have

413
00:14:40,000 --> 00:14:41,839
a strong idea that learning problems

414
00:14:41,839 --> 00:14:44,079
exist where leakage of random examples

415
00:14:44,079 --> 00:14:45,680
does not give much information on the

416
00:14:45,680 --> 00:14:46,800
concept

417
00:14:46,800 --> 00:14:49,279
specifically decision trees small depth

418
00:14:49,279 --> 00:14:51,440
circuits and parodies with noise are a

419
00:14:51,440 --> 00:14:53,120
few examples

420
00:14:53,120 --> 00:14:54,639
the reason for this is that these

421
00:14:54,639 --> 00:14:56,079
problems are thought to be

422
00:14:56,079 --> 00:14:57,600
computationally hard to learn from

423
00:14:57,600 --> 00:15:00,000
random examples on the other hand they

424
00:15:00,000 --> 00:15:01,600
are tractable when given membership

425
00:15:01,600 --> 00:15:03,760
queries and this is the sweet spot that

426
00:15:03,760 --> 00:15:06,880
gives us a chance to do covert learning

427
00:15:06,880 --> 00:15:08,880
finally it isn't simply an artifact of

428
00:15:08,880 --> 00:15:10,639
this definition that we leak random

429
00:15:10,639 --> 00:15:11,680
examples

430
00:15:11,680 --> 00:15:13,600
at a high level the equivalence of pac

431
00:15:13,600 --> 00:15:15,680
learning and outcome learning means that

432
00:15:15,680 --> 00:15:16,959
in some sense

433
00:15:16,959 --> 00:15:18,880
the leakage of random examples is the

434
00:15:18,880 --> 00:15:22,639
minimum amount of leakage anyway

435
00:15:23,519 --> 00:15:25,920
this definition gives a trivial example

436
00:15:25,920 --> 00:15:29,279
which will not be the focus of this talk

437
00:15:29,279 --> 00:15:31,440
let me explain how pac learnable classes

438
00:15:31,440 --> 00:15:33,920
are also trivially covertly learnable

439
00:15:33,920 --> 00:15:35,759
and so this naturally characterizes

440
00:15:35,759 --> 00:15:37,360
those classes that we can't hide and

441
00:15:37,360 --> 00:15:40,480
therefore will not focus on in

442
00:15:40,480 --> 00:15:42,880
particular if we assume every hypothesis

443
00:15:42,880 --> 00:15:44,720
class in the collection is learnable

444
00:15:44,720 --> 00:15:46,240
that is we can apply an efficient

445
00:15:46,240 --> 00:15:47,839
learning algorithm to any large enough

446
00:15:47,839 --> 00:15:50,639
set of random examples to the concept

447
00:15:50,639 --> 00:15:52,240
then we have a covert learning algorithm

448
00:15:52,240 --> 00:15:53,519
as follows

449
00:15:53,519 --> 00:15:55,600
first get a sufficiently large set of

450
00:15:55,600 --> 00:15:58,720
examples then run the pack learner

451
00:15:58,720 --> 00:16:00,399
and then we can see that if the

452
00:16:00,399 --> 00:16:02,240
simulator returns the random example is

453
00:16:02,240 --> 00:16:04,079
given as input then obviously the

454
00:16:04,079 --> 00:16:05,839
privacy guarantee of cover learning is

455
00:16:05,839 --> 00:16:08,320
satisfied in fact not computationally

456
00:16:08,320 --> 00:16:10,720
but perfectly and it won't hide anything

457
00:16:10,720 --> 00:16:12,399
at all due to the existence of the pack

458
00:16:12,399 --> 00:16:13,680
learner

459
00:16:13,680 --> 00:16:15,600
and so some examples of pac-learnable

460
00:16:15,600 --> 00:16:17,759
classes are constant term dnfs and

461
00:16:17,759 --> 00:16:20,959
parities without noise

462
00:16:21,600 --> 00:16:23,759
okay so with the covert learning model

463
00:16:23,759 --> 00:16:25,519
established we're ready to take a look

464
00:16:25,519 --> 00:16:28,160
at a first example of covert learning

465
00:16:28,160 --> 00:16:30,160
so again parodies with no noise are

466
00:16:30,160 --> 00:16:33,040
trivial but what about the noisy case

467
00:16:33,040 --> 00:16:34,959
i'll now introduce the first learning

468
00:16:34,959 --> 00:16:37,040
algorithm and while discussing it i'll

469
00:16:37,040 --> 00:16:38,800
ask you to focus on the concept how to

470
00:16:38,800 --> 00:16:41,360
guarantee mainly for simplicity but also

471
00:16:41,360 --> 00:16:42,320
because

472
00:16:42,320 --> 00:16:44,160
the instance of covert learning that i'm

473
00:16:44,160 --> 00:16:46,480
about to show you has constipating in a

474
00:16:46,480 --> 00:16:49,120
very strong way

475
00:16:49,120 --> 00:16:51,519
so what is the learning problem first we

476
00:16:51,519 --> 00:16:53,600
need some background the following is

477
00:16:53,600 --> 00:16:56,160
the lpn distribution of which the study

478
00:16:56,160 --> 00:16:58,560
was initiated in a work of bloom first

479
00:16:58,560 --> 00:17:00,639
kerns and lipton

480
00:17:00,639 --> 00:17:03,440
the problem at its core asks to solve a

481
00:17:03,440 --> 00:17:06,480
system of noisy linear equations

482
00:17:06,480 --> 00:17:08,640
another good way to describe it is as a

483
00:17:08,640 --> 00:17:09,919
distribution

484
00:17:09,919 --> 00:17:12,079
in this distribution first an n-bit

485
00:17:12,079 --> 00:17:14,480
secret s is drawn where each bit is

486
00:17:14,480 --> 00:17:16,640
sampled from a bernoulli random variable

487
00:17:16,640 --> 00:17:20,000
with mean p second a noise bit e is

488
00:17:20,000 --> 00:17:22,400
sampled from the same random variable

489
00:17:22,400 --> 00:17:24,880
a uniformly random vector a is then

490
00:17:24,880 --> 00:17:25,839
sampled

491
00:17:25,839 --> 00:17:28,960
and the inner product of a s

492
00:17:28,960 --> 00:17:31,440
x then x sword with e is returned along

493
00:17:31,440 --> 00:17:32,640
with a

494
00:17:32,640 --> 00:17:34,799
this constitutes one sample and over

495
00:17:34,799 --> 00:17:37,360
many samples s remains persistent while

496
00:17:37,360 --> 00:17:41,360
a and e are freshly sampled each time

497
00:17:41,360 --> 00:17:43,440
the classic problem associated with this

498
00:17:43,440 --> 00:17:46,240
distribution is search lpn which asks

499
00:17:46,240 --> 00:17:48,640
how to find s given some bounded number

500
00:17:48,640 --> 00:17:50,000
of samples

501
00:17:50,000 --> 00:17:51,840
and it's not too difficult to see that

502
00:17:51,840 --> 00:17:54,000
search lpn is equivalent to solving the

503
00:17:54,000 --> 00:17:57,280
noisy system of linear equations

504
00:17:57,280 --> 00:17:58,880
this problem is conjectured to be

505
00:17:58,880 --> 00:18:00,480
computationally hard

506
00:18:00,480 --> 00:18:02,480
in fact this being true implies that the

507
00:18:02,480 --> 00:18:04,559
decision analog is also computationally

508
00:18:04,559 --> 00:18:08,960
hard which is particularly useful

509
00:18:09,600 --> 00:18:11,120
the problem we will actually now

510
00:18:11,120 --> 00:18:13,679
consider is the low noise variant due to

511
00:18:13,679 --> 00:18:15,760
a lactovich which he used to give the

512
00:18:15,760 --> 00:18:17,840
first public key encryption scheme from

513
00:18:17,840 --> 00:18:20,000
lpn of any noise rate

514
00:18:20,000 --> 00:18:22,080
the low noise variant allows us to draw

515
00:18:22,080 --> 00:18:24,080
the secret and noise from a bernoulli

516
00:18:24,080 --> 00:18:26,799
random variable of mean one over root n

517
00:18:26,799 --> 00:18:29,760
instead of some constant

518
00:18:29,760 --> 00:18:31,520
so our question will be is there a

519
00:18:31,520 --> 00:18:33,360
covert learning algorithm for learning

520
00:18:33,360 --> 00:18:35,440
the secret s with respect to this low

521
00:18:35,440 --> 00:18:37,200
noise distribution

522
00:18:37,200 --> 00:18:39,120
the reason we are working with low noise

523
00:18:39,120 --> 00:18:41,360
will become clear later but doing covert

524
00:18:41,360 --> 00:18:43,039
learning with respect to the standard

525
00:18:43,039 --> 00:18:45,440
lpn distribution is a very interesting

526
00:18:45,440 --> 00:18:47,760
open problem because it would have

527
00:18:47,760 --> 00:18:49,600
implications on what kind of primitives

528
00:18:49,600 --> 00:18:53,678
we know to exist from standard lpn

529
00:18:54,720 --> 00:18:57,840
so indeed so indeed the answer is that

530
00:18:57,840 --> 00:19:00,320
there is and i've stated this theorem on

531
00:19:00,320 --> 00:19:02,320
the screen as relying on the assumption

532
00:19:02,320 --> 00:19:04,880
that low noise search lpn is hard which

533
00:19:04,880 --> 00:19:07,360
in some sense is the minimal assumption

534
00:19:07,360 --> 00:19:09,200
because it keeps the question

535
00:19:09,200 --> 00:19:11,840
non-trivial and relevant

536
00:19:11,840 --> 00:19:14,080
note that it is actually unconditionally

537
00:19:14,080 --> 00:19:16,480
true because if the search lpn problem

538
00:19:16,480 --> 00:19:18,559
is tractable then we already saw this

539
00:19:18,559 --> 00:19:22,480
makes it easily covertly learnable

540
00:19:23,039 --> 00:19:24,880
now to understand the covert learning

541
00:19:24,880 --> 00:19:26,720
algorithm it's best to first understand

542
00:19:26,720 --> 00:19:29,039
the leaky way to learn the parity

543
00:19:29,039 --> 00:19:31,039
to do this we simply need to query each

544
00:19:31,039 --> 00:19:34,160
bit of secret parity one by one by using

545
00:19:34,160 --> 00:19:36,880
the standard basis vectors as queries

546
00:19:36,880 --> 00:19:39,039
then by applying repetition and majority

547
00:19:39,039 --> 00:19:41,760
voting we can remove the noise

548
00:19:41,760 --> 00:19:43,840
but it's obvious that if alice chooses

549
00:19:43,840 --> 00:19:45,679
to do this in the lab then eve can

550
00:19:45,679 --> 00:19:47,600
easily do the same majority voting and

551
00:19:47,600 --> 00:19:50,959
learn the noisy parody as well

552
00:19:51,679 --> 00:19:53,679
the basic idea of the covert algorithm

553
00:19:53,679 --> 00:19:55,600
will be to transform the queries in the

554
00:19:55,600 --> 00:19:58,160
leaky algorithm to suit a random queries

555
00:19:58,160 --> 00:19:59,840
if we can learn from these then the

556
00:19:59,840 --> 00:20:02,400
simulator is easy it only has to return

557
00:20:02,400 --> 00:20:05,520
the random examples given as input

558
00:20:05,520 --> 00:20:07,280
one way to do this is to generate a

559
00:20:07,280 --> 00:20:09,520
pseudorandom mask for each query by

560
00:20:09,520 --> 00:20:12,559
using the lpn distribution itself

561
00:20:12,559 --> 00:20:14,640
to do this we take one random n by n

562
00:20:14,640 --> 00:20:16,960
matrix and then a fresh secret and noise

563
00:20:16,960 --> 00:20:18,840
vector for each

564
00:20:18,840 --> 00:20:21,679
query once we have the masks we will use

565
00:20:21,679 --> 00:20:23,919
them as one-time pads for each query

566
00:20:23,919 --> 00:20:26,240
pictured i have at the top the first

567
00:20:26,240 --> 00:20:27,679
masked query

568
00:20:27,679 --> 00:20:29,760
below you can see that the result from

569
00:20:29,760 --> 00:20:31,520
querying the oracle for the smashed

570
00:20:31,520 --> 00:20:33,760
query where the secret parity is in

571
00:20:33,760 --> 00:20:36,080
purple

572
00:20:36,080 --> 00:20:37,919
next we also need to query for the

573
00:20:37,919 --> 00:20:39,919
columns of the random blue matrix and

574
00:20:39,919 --> 00:20:43,840
this will help us later for learning s

575
00:20:44,080 --> 00:20:45,840
before analyzing how to extract the

576
00:20:45,840 --> 00:20:47,919
secret from these queries let us quickly

577
00:20:47,919 --> 00:20:49,360
see how our membership queries are

578
00:20:49,360 --> 00:20:51,280
suited right now

579
00:20:51,280 --> 00:20:53,280
the query transcript is at the top and

580
00:20:53,280 --> 00:20:55,280
indeed it follows directly from our

581
00:20:55,280 --> 00:20:57,840
decisional low noise lpn assumption that

582
00:20:57,840 --> 00:21:00,000
the joint distribution is pretty random

583
00:21:00,000 --> 00:21:01,919
since we have used fresh secrets each

584
00:21:01,919 --> 00:21:03,360
time

585
00:21:03,360 --> 00:21:05,919
the total number of queries is 2n so a

586
00:21:05,919 --> 00:21:08,320
simulator needs to return just 2n random

587
00:21:08,320 --> 00:21:10,480
queries from its input

588
00:21:10,480 --> 00:21:12,000
however i want to highlight that the

589
00:21:12,000 --> 00:21:14,159
console padding here is very strong it's

590
00:21:14,159 --> 00:21:16,000
not too hard to see that the oracle

591
00:21:16,000 --> 00:21:17,760
responses on these queries are

592
00:21:17,760 --> 00:21:20,080
pseudorandom due to the low noise lpn

593
00:21:20,080 --> 00:21:22,880
assumption so in fact no information is

594
00:21:22,880 --> 00:21:24,960
leaked here at all the simulator does

595
00:21:24,960 --> 00:21:26,799
not need to access any random examples

596
00:21:26,799 --> 00:21:31,480
and could just return all random bits

597
00:21:32,000 --> 00:21:33,840
now let's talk about how we can leverage

598
00:21:33,840 --> 00:21:35,600
the lpn secrets to find the secret

599
00:21:35,600 --> 00:21:37,760
parity function

600
00:21:37,760 --> 00:21:39,840
we'll need this xor lemma written at the

601
00:21:39,840 --> 00:21:41,919
top which allows us to measure the bias

602
00:21:41,919 --> 00:21:44,559
of inner products of binary vectors now

603
00:21:44,559 --> 00:21:45,520
picture

604
00:21:45,520 --> 00:21:47,679
i have the result of the first masked

605
00:21:47,679 --> 00:21:49,840
query xor with the inner product between

606
00:21:49,840 --> 00:21:51,679
the results on the columns of our blue

607
00:21:51,679 --> 00:21:54,240
matrix and the lpn secret used to mask

608
00:21:54,240 --> 00:21:56,080
the basis vector

609
00:21:56,080 --> 00:21:58,080
now this can be simplified to the inner

610
00:21:58,080 --> 00:22:00,480
product between the unmasked query the

611
00:22:00,480 --> 00:22:03,360
basis vector and the secret parity plus

612
00:22:03,360 --> 00:22:05,760
three noisy terms which are circled

613
00:22:05,760 --> 00:22:07,520
in the case of the first term note that

614
00:22:07,520 --> 00:22:09,520
both the red and purple vectors consist

615
00:22:09,520 --> 00:22:11,679
of bits that are independently drawn

616
00:22:11,679 --> 00:22:13,360
from the bernoulli random variable with

617
00:22:13,360 --> 00:22:15,200
mean one over root n

618
00:22:15,200 --> 00:22:17,440
with this in mind the xor lemma shows

619
00:22:17,440 --> 00:22:19,120
that the inner product is biased towards

620
00:22:19,120 --> 00:22:20,960
zero by a constant

621
00:22:20,960 --> 00:22:22,480
the same argument gives the same

622
00:22:22,480 --> 00:22:24,240
conclusion for the inner product between

623
00:22:24,240 --> 00:22:26,880
the orange vector and yellow vector

624
00:22:26,880 --> 00:22:29,200
finally the last noise term the orange

625
00:22:29,200 --> 00:22:31,280
square bit is one with sub-constant

626
00:22:31,280 --> 00:22:32,640
probability

627
00:22:32,640 --> 00:22:34,240
overall since each noise term is

628
00:22:34,240 --> 00:22:35,919
independent we can conclude that the

629
00:22:35,919 --> 00:22:37,679
final result is the desired inner

630
00:22:37,679 --> 00:22:40,000
product with high probability

631
00:22:40,000 --> 00:22:41,679
from here we can prescribe a usual

632
00:22:41,679 --> 00:22:44,080
course of repetition and majority voting

633
00:22:44,080 --> 00:22:46,080
and then decode the secret parity bit by

634
00:22:46,080 --> 00:22:49,840
bit and then we are done

635
00:22:50,720 --> 00:22:52,559
so moving on

636
00:22:52,559 --> 00:22:54,559
the question is can we covertly learn

637
00:22:54,559 --> 00:22:56,960
more interesting concepts

638
00:22:56,960 --> 00:22:58,480
what i will now show you is how to

639
00:22:58,480 --> 00:23:00,640
conduct fourier analysis based learning

640
00:23:00,640 --> 00:23:02,880
techniques covertly

641
00:23:02,880 --> 00:23:04,480
for background let me review some

642
00:23:04,480 --> 00:23:06,480
boolean fourier analysis and review the

643
00:23:06,480 --> 00:23:09,520
learning techniques to set the stage let

644
00:23:09,520 --> 00:23:11,440
f be a function from

645
00:23:11,440 --> 00:23:13,840
f2 to the n to the reals but in

646
00:23:13,840 --> 00:23:15,600
particular we will consider the range of

647
00:23:15,600 --> 00:23:18,000
f to be the set negative one and one so

648
00:23:18,000 --> 00:23:19,600
you can interpret f as a boolean

649
00:23:19,600 --> 00:23:21,679
function

650
00:23:21,679 --> 00:23:24,640
for some subset s of the n indices of f

651
00:23:24,640 --> 00:23:27,280
we define a character function pi sub s

652
00:23:27,280 --> 00:23:28,880
which just computes the parity of the

653
00:23:28,880 --> 00:23:31,600
input on the bits indexed by the set s

654
00:23:31,600 --> 00:23:33,679
but notice how zero is mapped to one and

655
00:23:33,679 --> 00:23:36,400
one is mapped to negative one

656
00:23:36,400 --> 00:23:38,159
now it turns out that this set of

657
00:23:38,159 --> 00:23:40,159
character functions forms an orthonormal

658
00:23:40,159 --> 00:23:42,320
basis over the functions f so we can

659
00:23:42,320 --> 00:23:44,400
uniquely represent each f by its fourier

660
00:23:44,400 --> 00:23:45,520
expansion

661
00:23:45,520 --> 00:23:48,080
a linear combination of the characters

662
00:23:48,080 --> 00:23:50,159
we call each coefficient the fourier

663
00:23:50,159 --> 00:23:52,720
coefficient on chi sub s and we also

664
00:23:52,720 --> 00:23:55,120
refer to it as heavy if the magnitude is

665
00:23:55,120 --> 00:23:57,440
some noticeable function of n

666
00:23:57,440 --> 00:23:59,520
also the degree of the coefficient is

667
00:23:59,520 --> 00:24:02,400
the size of the set s

668
00:24:02,400 --> 00:24:04,080
now it's also important to understand

669
00:24:04,080 --> 00:24:05,679
why learning fourier coefficients is a

670
00:24:05,679 --> 00:24:07,039
useful task

671
00:24:07,039 --> 00:24:08,960
first by definition it is the case that

672
00:24:08,960 --> 00:24:10,799
the fourier coefficient on a character

673
00:24:10,799 --> 00:24:12,480
measures the correlation between that

674
00:24:12,480 --> 00:24:14,640
character and the function here the

675
00:24:14,640 --> 00:24:16,559
expectation is taken over uniformly

676
00:24:16,559 --> 00:24:18,880
random n bit x

677
00:24:18,880 --> 00:24:20,960
so that means that if we can find some

678
00:24:20,960 --> 00:24:22,960
heavy fourier coefficients that gives a

679
00:24:22,960 --> 00:24:24,799
weak predictor on the function just by

680
00:24:24,799 --> 00:24:26,080
taking the parity function as the

681
00:24:26,080 --> 00:24:28,320
predictor

682
00:24:28,320 --> 00:24:30,000
since fourier coefficients measure a

683
00:24:30,000 --> 00:24:31,760
correlation with respect to uniformly

684
00:24:31,760 --> 00:24:33,919
drawn inputs this shows how learning

685
00:24:33,919 --> 00:24:35,919
fourier coefficient interacts nicely

686
00:24:35,919 --> 00:24:37,919
with learning with respect to a uniform

687
00:24:37,919 --> 00:24:39,919
distribution over inputs

688
00:24:39,919 --> 00:24:41,760
i'll also note that a single fourier

689
00:24:41,760 --> 00:24:43,120
coefficient can be efficiently

690
00:24:43,120 --> 00:24:44,400
approximated

691
00:24:44,400 --> 00:24:47,039
by estimating the expectation at the top

692
00:24:47,039 --> 00:24:49,440
of the slide

693
00:24:49,440 --> 00:24:50,960
and it turns out that an important

694
00:24:50,960 --> 00:24:52,640
application of this is that it allows us

695
00:24:52,640 --> 00:24:55,360
to learn polynomial and n size decision

696
00:24:55,360 --> 00:24:57,440
trees just by obtaining the subsets of

697
00:24:57,440 --> 00:24:59,520
log and degree that are heavy

698
00:24:59,520 --> 00:25:01,679
for a refresher a decision tree is a

699
00:25:01,679 --> 00:25:03,760
representation of a boolean function by

700
00:25:03,760 --> 00:25:06,480
a binary tree where each inner node is

701
00:25:06,480 --> 00:25:09,200
labeled by an index of an input bit each

702
00:25:09,200 --> 00:25:11,760
outgoing edge is labeled by zero or one

703
00:25:11,760 --> 00:25:13,200
and the leaves are labeled by real

704
00:25:13,200 --> 00:25:14,400
numbers

705
00:25:14,400 --> 00:25:16,640
on any input the decision tree follows a

706
00:25:16,640 --> 00:25:18,960
computation path down the tree by going

707
00:25:18,960 --> 00:25:20,480
in the direction of the assignment of

708
00:25:20,480 --> 00:25:22,880
the variable at the labeled index

709
00:25:22,880 --> 00:25:25,279
now the size of the decision tree refers

710
00:25:25,279 --> 00:25:26,960
to the number of leaves on the decision

711
00:25:26,960 --> 00:25:29,840
tree so a polynomial size decision tree

712
00:25:29,840 --> 00:25:32,880
has polynomially many buckets or leaves

713
00:25:32,880 --> 00:25:34,720
the class of polynomial size decision

714
00:25:34,720 --> 00:25:36,640
trees is a very expressive class for

715
00:25:36,640 --> 00:25:37,919
which no efficient pack learning

716
00:25:37,919 --> 00:25:39,520
algorithm is known

717
00:25:39,520 --> 00:25:41,440
plus it's especially relevant to us

718
00:25:41,440 --> 00:25:43,120
because decision trees are the standard

719
00:25:43,120 --> 00:25:45,039
way to conduct structure activity

720
00:25:45,039 --> 00:25:46,880
modeling

721
00:25:46,880 --> 00:25:48,559
i won't get into this further but for

722
00:25:48,559 --> 00:25:50,400
these reasons i'll now explain how to do

723
00:25:50,400 --> 00:25:52,640
covert learning for heavy low degree

724
00:25:52,640 --> 00:25:55,120
fourier coefficients

725
00:25:55,120 --> 00:25:57,039
so let me now explain the problem

726
00:25:57,039 --> 00:25:58,960
setting further here is the type of

727
00:25:58,960 --> 00:26:01,039
concept we are trying to learn when

728
00:26:01,039 --> 00:26:03,039
getting a sample from the concept first

729
00:26:03,039 --> 00:26:05,279
an input will be sampled uniformly at

730
00:26:05,279 --> 00:26:07,600
random then there is always a target

731
00:26:07,600 --> 00:26:09,840
function that labels the input so the

732
00:26:09,840 --> 00:26:11,840
output of the distribution is always a

733
00:26:11,840 --> 00:26:15,120
uniformly random x and f x

734
00:26:15,120 --> 00:26:16,960
in this setting to make a membership

735
00:26:16,960 --> 00:26:19,440
query one simply bypasses the marginal

736
00:26:19,440 --> 00:26:21,600
distribution over inputs to obtain a

737
00:26:21,600 --> 00:26:23,440
label on any input

738
00:26:23,440 --> 00:26:25,760
so in case it is still not crystal clear

739
00:26:25,760 --> 00:26:27,279
our task is to obtain fourier

740
00:26:27,279 --> 00:26:29,360
coefficients of f while satisfying the

741
00:26:29,360 --> 00:26:31,440
covert learning privacy guarantees with

742
00:26:31,440 --> 00:26:33,440
respect to this concept distribution

743
00:26:33,440 --> 00:26:36,400
that i just described

744
00:26:36,640 --> 00:26:38,640
now before going on to describe how we

745
00:26:38,640 --> 00:26:40,559
do it i want to highlight the hypothesis

746
00:26:40,559 --> 00:26:42,400
how to guarantee for this problem which

747
00:26:42,400 --> 00:26:43,919
i kind of skipped over in the first

748
00:26:43,919 --> 00:26:46,480
result for noisy parodies

749
00:26:46,480 --> 00:26:48,240
to give an example let's say that the

750
00:26:48,240 --> 00:26:50,320
learner has some expert domain knowledge

751
00:26:50,320 --> 00:26:52,240
about this function for example in the

752
00:26:52,240 --> 00:26:54,240
drug discovery application domain

753
00:26:54,240 --> 00:26:55,760
knowledge could be a certain subset of

754
00:26:55,760 --> 00:26:57,360
molecule features which are highly

755
00:26:57,360 --> 00:26:59,039
relevant

756
00:26:59,039 --> 00:27:00,880
now in particular let's say that the

757
00:27:00,880 --> 00:27:02,720
domain knowledge is that all heavy

758
00:27:02,720 --> 00:27:05,360
fourier coefficients are on subsets s

759
00:27:05,360 --> 00:27:07,440
which are further contained in some

760
00:27:07,440 --> 00:27:10,240
subset t of the n indices

761
00:27:10,240 --> 00:27:11,919
this knowledge is valuable as the

762
00:27:11,919 --> 00:27:13,840
learner could make more targeted queries

763
00:27:13,840 --> 00:27:15,600
to learn the function while reducing

764
00:27:15,600 --> 00:27:18,240
query complexity and computation time

765
00:27:18,240 --> 00:27:20,159
however the learner does not want their

766
00:27:20,159 --> 00:27:22,720
queries to reveal this valuable set t so

767
00:27:22,720 --> 00:27:25,279
the big hypothesis question is how can

768
00:27:25,279 --> 00:27:28,960
we prevent this leakage

769
00:27:30,240 --> 00:27:32,399
well this is exactly what is formalized

770
00:27:32,399 --> 00:27:34,880
by the hiding guarantee

771
00:27:34,880 --> 00:27:36,480
we can do covert learning for a

772
00:27:36,480 --> 00:27:38,480
collection of hypothesis classes where

773
00:27:38,480 --> 00:27:40,720
each class is indexed by the subset t

774
00:27:40,720 --> 00:27:42,880
which denotes the part information

775
00:27:42,880 --> 00:27:44,480
now we have the guarantee that no

776
00:27:44,480 --> 00:27:46,559
information about t is leaked to an

777
00:27:46,559 --> 00:27:48,159
efficient adversary due to the

778
00:27:48,159 --> 00:27:51,840
guaranteed existence of the simulator

779
00:27:51,840 --> 00:27:53,360
so what we're actually going to do

780
00:27:53,360 --> 00:27:55,039
algorithmically is use a similar

781
00:27:55,039 --> 00:27:57,600
technique to before the masked queries

782
00:27:57,600 --> 00:27:59,679
but we will do it with an lpn variant

783
00:27:59,679 --> 00:28:01,360
due to u and gen

784
00:28:01,360 --> 00:28:03,039
the interesting thing about this variant

785
00:28:03,039 --> 00:28:05,039
is that it can be conjectured to provide

786
00:28:05,039 --> 00:28:06,880
super polynomial hardness even when

787
00:28:06,880 --> 00:28:08,960
secrets are drawn from distributions

788
00:28:08,960 --> 00:28:11,840
with log squared minimum entropy

789
00:28:11,840 --> 00:28:13,440
it will turn out that this allows us to

790
00:28:13,440 --> 00:28:15,440
use sparse secrets which at the end will

791
00:28:15,440 --> 00:28:16,799
be crucial for the success of the

792
00:28:16,799 --> 00:28:18,320
protocol

793
00:28:18,320 --> 00:28:20,480
and finally the hardness of the variant

794
00:28:20,480 --> 00:28:22,240
is implied by a somewhat better known

795
00:28:22,240 --> 00:28:24,080
assumption on the standard lpn

796
00:28:24,080 --> 00:28:25,679
distribution which assumes

797
00:28:25,679 --> 00:28:29,559
sub-exponential hardness

798
00:28:30,640 --> 00:28:32,000
so

799
00:28:32,000 --> 00:28:34,480
graphically depicted is the masked query

800
00:28:34,480 --> 00:28:37,279
technique with the squared log lpn

801
00:28:37,279 --> 00:28:38,799
distribution used to generate the

802
00:28:38,799 --> 00:28:40,159
one-time pads

803
00:28:40,159 --> 00:28:43,440
and then with the labels given by the

804
00:28:43,440 --> 00:28:46,240
function f

805
00:28:46,240 --> 00:28:48,000
with this technique we can get hiding

806
00:28:48,000 --> 00:28:50,320
out of the way quickly it is again quite

807
00:28:50,320 --> 00:28:52,320
easy to see because it follows straight

808
00:28:52,320 --> 00:28:54,720
from the squared log lpn assumption and

809
00:28:54,720 --> 00:28:56,640
using a security under polynomial

810
00:28:56,640 --> 00:28:58,480
composition property

811
00:28:58,480 --> 00:29:00,480
all the similarity needs to do is again

812
00:29:00,480 --> 00:29:02,399
just return its random examples that it

813
00:29:02,399 --> 00:29:05,360
has as input

814
00:29:05,360 --> 00:29:07,279
okay so with this in mind let me begin

815
00:29:07,279 --> 00:29:09,120
to overview why this process will work

816
00:29:09,120 --> 00:29:10,080
for us

817
00:29:10,080 --> 00:29:12,320
again the plan is to mask queries using

818
00:29:12,320 --> 00:29:15,279
this lpm distribution as a one-time pad

819
00:29:15,279 --> 00:29:17,279
the question then becomes what can we

820
00:29:17,279 --> 00:29:18,880
say about the results returned by the

821
00:29:18,880 --> 00:29:20,559
oracle

822
00:29:20,559 --> 00:29:22,240
so the key to the protocol is an

823
00:29:22,240 --> 00:29:24,640
analysis that shows that post-processing

824
00:29:24,640 --> 00:29:26,399
that results by reintroducing a

825
00:29:26,399 --> 00:29:28,799
dependency on the lpn secret for each

826
00:29:28,799 --> 00:29:31,279
respective query allows a type of noisy

827
00:29:31,279 --> 00:29:33,520
access to low degree and heavy fourier

828
00:29:33,520 --> 00:29:36,720
coefficients of the function f

829
00:29:36,720 --> 00:29:39,200
in particular that the result of the

830
00:29:39,200 --> 00:29:41,600
randomized mapping phi on the result of

831
00:29:41,600 --> 00:29:43,600
the matched query has a significant

832
00:29:43,600 --> 00:29:46,080
correlation with any parity function

833
00:29:46,080 --> 00:29:48,080
induced by any heavy login degree

834
00:29:48,080 --> 00:29:50,399
fourier subset when evaluated on the

835
00:29:50,399 --> 00:29:52,159
unmasked query

836
00:29:52,159 --> 00:29:53,679
that's in words with the limit on the

837
00:29:53,679 --> 00:29:55,200
screen states

838
00:29:55,200 --> 00:29:57,039
indeed this setting may be somewhat

839
00:29:57,039 --> 00:29:58,720
familiar

840
00:29:58,720 --> 00:30:00,960
the setting can be seen to be a goldrich

841
00:30:00,960 --> 00:30:03,520
11 environment so to speak the goldberg

842
00:30:03,520 --> 00:30:05,919
11 environment or reduction gives a

843
00:30:05,919 --> 00:30:07,919
method for extracting parity functions

844
00:30:07,919 --> 00:30:09,679
given a noisy predictor and using

845
00:30:09,679 --> 00:30:11,679
membership queries

846
00:30:11,679 --> 00:30:13,360
thus what we have really shown here is

847
00:30:13,360 --> 00:30:14,880
that the randomized mapping on the

848
00:30:14,880 --> 00:30:17,360
oracle result of the masked query is

849
00:30:17,360 --> 00:30:19,200
such a noisy predictor for any heavy

850
00:30:19,200 --> 00:30:21,039
login degree parity function on the

851
00:30:21,039 --> 00:30:23,840
unmasked query

852
00:30:23,840 --> 00:30:26,399
so we can update our algorithmic idea to

853
00:30:26,399 --> 00:30:27,440
the following

854
00:30:27,440 --> 00:30:29,279
run the goldirect 11 algorithm in the

855
00:30:29,279 --> 00:30:31,840
master regime and do this in such a way

856
00:30:31,840 --> 00:30:33,919
that focuses on the secret subset of

857
00:30:33,919 --> 00:30:37,520
indices t that we are interested in

858
00:30:37,520 --> 00:30:39,600
naturally the hypothesis hiding property

859
00:30:39,600 --> 00:30:41,120
given by the pseudo-randomness of the

860
00:30:41,120 --> 00:30:43,200
queries heights t

861
00:30:43,200 --> 00:30:45,039
perhaps an interesting dynamic to

862
00:30:45,039 --> 00:30:46,960
highlight here is that we don't actually

863
00:30:46,960 --> 00:30:48,960
make any specific queries directly to

864
00:30:48,960 --> 00:30:51,520
the function instead we simulate access

865
00:30:51,520 --> 00:30:53,440
to a noisy predictor for some of the

866
00:30:53,440 --> 00:30:56,240
heavy coefficients of f

867
00:30:56,240 --> 00:30:58,559
it is natural to ask why do we only get

868
00:30:58,559 --> 00:31:00,640
log n degree coefficients

869
00:31:00,640 --> 00:31:02,159
one needs to get into the proof of the

870
00:31:02,159 --> 00:31:04,559
key lemma to see why but it boils down

871
00:31:04,559 --> 00:31:06,399
to a basic counting argument that

872
00:31:06,399 --> 00:31:08,080
coefficients of higher degree are

873
00:31:08,080 --> 00:31:10,080
affected more by noise which eventually

874
00:31:10,080 --> 00:31:13,120
becomes too much to handle

875
00:31:13,120 --> 00:31:15,200
and finally i'll recall the utility of

876
00:31:15,200 --> 00:31:17,519
this algorithm as mentioned we can use

877
00:31:17,519 --> 00:31:19,200
knowledge of the heavy login degree

878
00:31:19,200 --> 00:31:21,760
fourier subsets to produce a hypothesis

879
00:31:21,760 --> 00:31:23,279
which is competitive with the best

880
00:31:23,279 --> 00:31:25,360
polynomial size decision tree that fits

881
00:31:25,360 --> 00:31:27,519
any function with respect to the uniform

882
00:31:27,519 --> 00:31:29,440
distribution of our inputs

883
00:31:29,440 --> 00:31:31,919
we formalize this in our work as a

884
00:31:31,919 --> 00:31:33,760
covert learning theorem for decision

885
00:31:33,760 --> 00:31:36,000
trees

886
00:31:36,000 --> 00:31:37,919
so it now looks like we have made it to

887
00:31:37,919 --> 00:31:39,519
the second part of this talk

888
00:31:39,519 --> 00:31:42,559
it's time to introduce verifiability

889
00:31:42,559 --> 00:31:43,679
the best way to think about the

890
00:31:43,679 --> 00:31:45,840
verifiable model is as an interaction

891
00:31:45,840 --> 00:31:48,000
with an adversarial intermediary instead

892
00:31:48,000 --> 00:31:50,159
of passive which i'll now just call the

893
00:31:50,159 --> 00:31:51,600
adversary

894
00:31:51,600 --> 00:31:53,919
in this case the adversary not only just

895
00:31:53,919 --> 00:31:56,080
monitors the queries and responses but

896
00:31:56,080 --> 00:31:57,679
it will actually be allowed to corrupt

897
00:31:57,679 --> 00:31:59,519
responses

898
00:31:59,519 --> 00:32:01,440
this resembles an interactive learning

899
00:32:01,440 --> 00:32:02,799
setting where the learner is not

900
00:32:02,799 --> 00:32:04,799
requesting queries from an oracle but

901
00:32:04,799 --> 00:32:06,640
from the adversary and the adversary

902
00:32:06,640 --> 00:32:09,039
labels the queries as it pleases

903
00:32:09,039 --> 00:32:10,880
i'll note that this is on top of the

904
00:32:10,880 --> 00:32:12,720
already agnostic setting so the

905
00:32:12,720 --> 00:32:15,440
adversary may mislabel the concept which

906
00:32:15,440 --> 00:32:18,000
may be in and of itself an arbitrary

907
00:32:18,000 --> 00:32:20,399
function

908
00:32:21,279 --> 00:32:23,279
the verifiability guarantee that we want

909
00:32:23,279 --> 00:32:25,279
to obtain is essentially that if the

910
00:32:25,279 --> 00:32:27,919
adversary corrupts any oracle responses

911
00:32:27,919 --> 00:32:29,440
then the probability the learner's

912
00:32:29,440 --> 00:32:31,200
output does not satisfy the learning

913
00:32:31,200 --> 00:32:33,120
requirements is low given that the

914
00:32:33,120 --> 00:32:36,159
protocol was not aborted by the learner

915
00:32:36,159 --> 00:32:37,919
in order to achieve this we will allow

916
00:32:37,919 --> 00:32:39,919
the learner to access a secret set of

917
00:32:39,919 --> 00:32:42,080
uncorrupted random examples of the

918
00:32:42,080 --> 00:32:43,919
concept

919
00:32:43,919 --> 00:32:45,679
now it may be useful to compare this

920
00:32:45,679 --> 00:32:47,120
requirement to soundness in an

921
00:32:47,120 --> 00:32:49,120
interactive proof while the learning

922
00:32:49,120 --> 00:32:51,679
requirement corresponds to completeness

923
00:32:51,679 --> 00:32:53,360
and that is essentially how we formalize

924
00:32:53,360 --> 00:32:54,880
verifiability

925
00:32:54,880 --> 00:32:56,799
for any concept in the class any

926
00:32:56,799 --> 00:32:59,120
hypothesis class in the collection any

927
00:32:59,120 --> 00:33:01,279
secret set of random examples and any

928
00:33:01,279 --> 00:33:03,360
adversary the probability that the

929
00:33:03,360 --> 00:33:05,600
algorithm fails is low at least given

930
00:33:05,600 --> 00:33:07,919
that it did not abort the interaction

931
00:33:07,919 --> 00:33:10,480
altogether

932
00:33:10,480 --> 00:33:12,640
now it will be necessary to extend the

933
00:33:12,640 --> 00:33:14,640
privacy requirements to capture the

934
00:33:14,640 --> 00:33:16,880
active nature of the adversary

935
00:33:16,880 --> 00:33:19,039
in order to do this we will follow the

936
00:33:19,039 --> 00:33:20,880
real versus ideal world security

937
00:33:20,880 --> 00:33:23,360
paradigm and separate the adversary from

938
00:33:23,360 --> 00:33:25,519
an external distinguisher who tries to

939
00:33:25,519 --> 00:33:27,679
distinguish between the real and ideal

940
00:33:27,679 --> 00:33:30,080
worlds

941
00:33:30,399 --> 00:33:32,320
so in the real world we allow the

942
00:33:32,320 --> 00:33:34,080
distinguisher to essentially choose the

943
00:33:34,080 --> 00:33:36,080
conditions of the learning task

944
00:33:36,080 --> 00:33:37,760
the concept within the class the

945
00:33:37,760 --> 00:33:39,919
hypothesis class within the collection

946
00:33:39,919 --> 00:33:42,240
and the learning parameters

947
00:33:42,240 --> 00:33:44,320
then a randomly sampled set of examples

948
00:33:44,320 --> 00:33:46,480
is drawn from the concept

949
00:33:46,480 --> 00:33:48,559
this set is given to the learner along

950
00:33:48,559 --> 00:33:50,720
with the relevant learning parameters

951
00:33:50,720 --> 00:33:53,279
the adversary gets just epsilon and

952
00:33:53,279 --> 00:33:55,120
delta

953
00:33:55,120 --> 00:33:57,039
then the learning interaction happens

954
00:33:57,039 --> 00:33:59,039
and the adversary gets to output some

955
00:33:59,039 --> 00:34:01,840
arbitrary string based on this

956
00:34:01,840 --> 00:34:03,440
so finally the output of the

957
00:34:03,440 --> 00:34:05,840
distribution is the learning parameters

958
00:34:05,840 --> 00:34:08,239
plus the string output by the adversary

959
00:34:08,239 --> 00:34:10,079
plus the secret set of random examples

960
00:34:10,079 --> 00:34:12,239
given to the real learner

961
00:34:12,239 --> 00:34:14,079
in contrast the ideal world goes as

962
00:34:14,079 --> 00:34:15,280
follows

963
00:34:15,280 --> 00:34:17,040
the distinguisher still chooses the

964
00:34:17,040 --> 00:34:19,119
conditions of the learning problem

965
00:34:19,119 --> 00:34:21,280
then another set of random examples is

966
00:34:21,280 --> 00:34:23,199
drawn from the concept

967
00:34:23,199 --> 00:34:25,199
and the simulator gets the same inputs

968
00:34:25,199 --> 00:34:27,599
as the real learner but also the set of

969
00:34:27,599 --> 00:34:30,000
extra random examples

970
00:34:30,000 --> 00:34:32,239
finally the simulator interacts with the

971
00:34:32,239 --> 00:34:34,079
oracle in the adversary's head and the

972
00:34:34,079 --> 00:34:36,879
adversary can output any string

973
00:34:36,879 --> 00:34:38,480
the output of the distribution is

974
00:34:38,480 --> 00:34:40,399
analogous to the real world

975
00:34:40,399 --> 00:34:41,679
i'll note that

976
00:34:41,679 --> 00:34:43,520
we have a desirable property here that

977
00:34:43,520 --> 00:34:45,599
the security holds even after the

978
00:34:45,599 --> 00:34:49,839
leakage of the secret set s

979
00:34:51,359 --> 00:34:53,199
we can now move on to discussing how to

980
00:34:53,199 --> 00:34:55,599
transform the basic covert learning

981
00:34:55,599 --> 00:34:57,440
algorithm of learning fourier

982
00:34:57,440 --> 00:35:01,119
coefficients into a verifiable version

983
00:35:01,119 --> 00:35:03,920
so the idea is very simple from the

984
00:35:03,920 --> 00:35:05,599
covert learning algorithm we know that

985
00:35:05,599 --> 00:35:07,839
the learner's queries are pseudorandom

986
00:35:07,839 --> 00:35:09,680
this essentially gives the learner the

987
00:35:09,680 --> 00:35:11,839
ability to hide from the adversary when

988
00:35:11,839 --> 00:35:13,200
it is running a covert learning

989
00:35:13,200 --> 00:35:15,599
algorithm and when it is faking it say

990
00:35:15,599 --> 00:35:18,160
by sending random examples

991
00:35:18,160 --> 00:35:20,960
so this is exactly what we will do

992
00:35:20,960 --> 00:35:22,640
we will randomly conduct a learning

993
00:35:22,640 --> 00:35:25,280
phase and a testing phase where each

994
00:35:25,280 --> 00:35:27,839
happens with probability one half

995
00:35:27,839 --> 00:35:30,240
in pseudocode it looks a bit like this

996
00:35:30,240 --> 00:35:31,920
the learning phase consists of running

997
00:35:31,920 --> 00:35:33,599
the basic learning algorithm for heavy

998
00:35:33,599 --> 00:35:35,680
fourier coefficients while the testing

999
00:35:35,680 --> 00:35:38,079
phase sends a portion of the secret set

1000
00:35:38,079 --> 00:35:40,320
of random examples and then checks for

1001
00:35:40,320 --> 00:35:42,160
consistency

1002
00:35:42,160 --> 00:35:43,200
remember

1003
00:35:43,200 --> 00:35:45,760
that the concept in this case always

1004
00:35:45,760 --> 00:35:48,400
labels every example in the same way so

1005
00:35:48,400 --> 00:35:52,079
a consistency check is possible

1006
00:35:52,079 --> 00:35:53,839
now our main claim is that if the

1007
00:35:53,839 --> 00:35:56,160
adversarial intermediary can with high

1008
00:35:56,160 --> 00:35:58,560
probability corrupt even one oracle

1009
00:35:58,560 --> 00:36:00,400
response without causing the learner to

1010
00:36:00,400 --> 00:36:03,440
abort then the squared log entropy lpn

1011
00:36:03,440 --> 00:36:05,760
problem is solved efficiently

1012
00:36:05,760 --> 00:36:07,839
and this can be seen by observing that

1013
00:36:07,839 --> 00:36:10,640
in the testing phase a dishonest ai is

1014
00:36:10,640 --> 00:36:12,880
always caught and so any cheating

1015
00:36:12,880 --> 00:36:14,240
advantage by the adversarial

1016
00:36:14,240 --> 00:36:16,320
intermediary can be converted into a

1017
00:36:16,320 --> 00:36:18,160
distinguishing advantage for the

1018
00:36:18,160 --> 00:36:20,160
supposedly pseudo-random queries of the

1019
00:36:20,160 --> 00:36:23,440
underlying covert learning algorithm

1020
00:36:23,440 --> 00:36:27,520
this in turn breaks the lpn assumption

1021
00:36:27,520 --> 00:36:29,280
ultimately what this means is that

1022
00:36:29,280 --> 00:36:31,280
either the adversary is caught and the

1023
00:36:31,280 --> 00:36:33,599
interaction is aborted or at least one

1024
00:36:33,599 --> 00:36:35,680
of the r iterations is an uncorrupted

1025
00:36:35,680 --> 00:36:38,320
learning phase with high probability

1026
00:36:38,320 --> 00:36:39,920
then from the learning guarantee of the

1027
00:36:39,920 --> 00:36:41,520
covert learning algorithm the

1028
00:36:41,520 --> 00:36:45,440
verifiability guarantee would follow

1029
00:36:45,440 --> 00:36:47,200
and finally this gives theorems in the

1030
00:36:47,200 --> 00:36:50,000
verifiable setting

1031
00:36:50,000 --> 00:36:52,000
so this nearly concludes my talk but i'd

1032
00:36:52,000 --> 00:36:53,599
like to mention a few interesting

1033
00:36:53,599 --> 00:36:55,200
questions

1034
00:36:55,200 --> 00:36:57,520
first are ultimately smaller questions

1035
00:36:57,520 --> 00:36:59,920
like how to extend these algorithms to

1036
00:36:59,920 --> 00:37:01,760
other interesting regimes like functions

1037
00:37:01,760 --> 00:37:04,480
over real numbers or other large fields

1038
00:37:04,480 --> 00:37:06,800
perhaps also other learning problems are

1039
00:37:06,800 --> 00:37:09,119
interesting specifically the exact

1040
00:37:09,119 --> 00:37:10,720
learning of graphs is particularly

1041
00:37:10,720 --> 00:37:12,800
relevant to the computational problems

1042
00:37:12,800 --> 00:37:15,200
in the application to molecular biology

1043
00:37:15,200 --> 00:37:16,880
and so maybe this could be a fruitful

1044
00:37:16,880 --> 00:37:19,839
ground for future research

1045
00:37:19,839 --> 00:37:21,920
then some bigger questions we have are

1046
00:37:21,920 --> 00:37:24,000
very general inquiries like is there a

1047
00:37:24,000 --> 00:37:25,839
compiler that transforms any pac

1048
00:37:25,839 --> 00:37:27,200
learning with membership queries

1049
00:37:27,200 --> 00:37:29,200
algorithm into a covert learning

1050
00:37:29,200 --> 00:37:31,520
algorithm

1051
00:37:31,520 --> 00:37:33,280
this concludes my talk thank you for

1052
00:37:33,280 --> 00:37:36,280
listening

