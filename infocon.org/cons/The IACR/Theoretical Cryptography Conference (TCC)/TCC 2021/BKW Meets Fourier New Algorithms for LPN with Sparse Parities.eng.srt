1
00:00:01,199 --> 00:00:01,920
hi

2
00:00:01,920 --> 00:00:03,760
i'm going to talk about our work uh

3
00:00:03,760 --> 00:00:06,480
titled bkw meets fury and new algorithms

4
00:00:06,480 --> 00:00:08,480
for lpn which is prosperity decision

5
00:00:08,480 --> 00:00:10,480
joined for with my advisor professor

6
00:00:10,480 --> 00:00:13,360
donald duckman solid eugene gong and

7
00:00:13,360 --> 00:00:15,599
hunter kippen

8
00:00:15,599 --> 00:00:17,039
so let's remind you about the learning

9
00:00:17,039 --> 00:00:18,640
parity with noise

10
00:00:18,640 --> 00:00:20,400
so there is a secret which has n

11
00:00:20,400 --> 00:00:23,119
coordinates each time we call an oracle

12
00:00:23,119 --> 00:00:25,199
x is going to be sampled uniformly at

13
00:00:25,199 --> 00:00:28,400
random so x has also n coordinates and

14
00:00:28,400 --> 00:00:31,119
the inner product of x and the secret s

15
00:00:31,119 --> 00:00:35,040
is gonna uh be computed and we either uh

16
00:00:35,040 --> 00:00:36,800
return the inner product with

17
00:00:36,800 --> 00:00:39,760
probability one minus eta eta being in a

18
00:00:39,760 --> 00:00:42,160
noise rate which is uh less than a half

19
00:00:42,160 --> 00:00:44,480
or we flip the inner product and we

20
00:00:44,480 --> 00:00:46,559
return uh

21
00:00:46,559 --> 00:00:48,079
the inner product plus one with

22
00:00:48,079 --> 00:00:50,000
probability eta and note that everything

23
00:00:50,000 --> 00:00:53,760
here is done uh mod two and the samples

24
00:00:53,760 --> 00:00:55,600
uh coming from this oracle is

25
00:00:55,600 --> 00:00:59,039
represented by a

26
00:00:59,039 --> 00:01:03,039
order paired and x and b b is the label

27
00:01:03,039 --> 00:01:06,479
and we represent this oracle by olpn 0

28
00:01:06,479 --> 00:01:08,400
and eta it

29
00:01:08,400 --> 00:01:10,720
means the noise rate and 0 means that

30
00:01:10,720 --> 00:01:13,360
the x is coming from a uniform

31
00:01:13,360 --> 00:01:15,600
distribution

32
00:01:15,600 --> 00:01:17,759
so it's easy to recover as

33
00:01:17,759 --> 00:01:20,720
if there is no noise so we can just run

34
00:01:20,720 --> 00:01:23,040
gaussian elimination but even for a

35
00:01:23,040 --> 00:01:25,119
constant noise rate the best algorithm

36
00:01:25,119 --> 00:01:27,360
is by uh bloom er caller awesome and

37
00:01:27,360 --> 00:01:30,560
which runs in time to to the uh o n over

38
00:01:30,560 --> 00:01:32,799
log n and needs uh essentially the same

39
00:01:32,799 --> 00:01:35,280
number of sample and later there is an

40
00:01:35,280 --> 00:01:37,920
improvement by uh leo bashevsky which

41
00:01:37,920 --> 00:01:39,920
only needs a polynomial number of

42
00:01:39,920 --> 00:01:42,799
samples but runs in slightly

43
00:01:42,799 --> 00:01:44,479
worse time

44
00:01:44,479 --> 00:01:46,399
uh so there is a search to decision

45
00:01:46,399 --> 00:01:48,799
reduction for lpn problem which makes it

46
00:01:48,799 --> 00:01:50,799
a more interesting for cryptography

47
00:01:50,799 --> 00:01:53,280
construction especially there is a

48
00:01:53,280 --> 00:01:56,799
encryption uh based on lpn

49
00:01:56,799 --> 00:01:58,479
and uh

50
00:01:58,479 --> 00:02:00,479
lpn is believed to be resistant against

51
00:02:00,479 --> 00:02:04,960
quantum computers and it has also been

52
00:02:04,960 --> 00:02:07,439
shown that uh without loss of generality

53
00:02:07,439 --> 00:02:10,399
we can assume that the secret key is uh

54
00:02:10,399 --> 00:02:12,720
drawn from the same distribution as the

55
00:02:12,720 --> 00:02:14,319
noise

56
00:02:14,319 --> 00:02:16,400
so in this work we consider lpn with

57
00:02:16,400 --> 00:02:19,360
sparse secrets so normally uh there is a

58
00:02:19,360 --> 00:02:21,760
eta times n coordinate of the secret key

59
00:02:21,760 --> 00:02:22,800
which are

60
00:02:22,800 --> 00:02:25,920
one but in this work we assume that

61
00:02:25,920 --> 00:02:28,640
k which is the sparsity of the secret is

62
00:02:28,640 --> 00:02:31,280
much less than that and we consider two

63
00:02:31,280 --> 00:02:34,319
cases either a constant noise rate and a

64
00:02:34,319 --> 00:02:36,239
low noise setting in which in that case

65
00:02:36,239 --> 00:02:39,440
the noise rate is a sub constant

66
00:02:39,440 --> 00:02:42,640
so one motivation for this work is that

67
00:02:42,640 --> 00:02:45,120
we can assume that the secret is a

68
00:02:45,120 --> 00:02:47,840
recovered using some type of attacks for

69
00:02:47,840 --> 00:02:50,319
example side channel attacks but we

70
00:02:50,319 --> 00:02:52,480
don't have a high confidence in each

71
00:02:52,480 --> 00:02:54,720
coordinate of the secret key so if we

72
00:02:54,720 --> 00:02:57,760
recover a secret key s prime we don't

73
00:02:57,760 --> 00:02:59,200
have high confidence in all the

74
00:02:59,200 --> 00:03:01,920
coordinates but we can turn our focus on

75
00:03:01,920 --> 00:03:06,080
x s minus x s prime and since s and s

76
00:03:06,080 --> 00:03:08,720
prime are going to be equal in a number

77
00:03:08,720 --> 00:03:10,000
of coordinates

78
00:03:10,000 --> 00:03:13,200
we expect that s minus x s prime to be

79
00:03:13,200 --> 00:03:15,840
sparse and we can turn off and or focus

80
00:03:15,840 --> 00:03:18,319
on that and also a sparse secret might

81
00:03:18,319 --> 00:03:20,640
be used in some applications uh for

82
00:03:20,640 --> 00:03:23,280
efficiency purposes

83
00:03:23,280 --> 00:03:25,280
so for the for the constant noise

84
00:03:25,280 --> 00:03:27,440
setting we show that first partition k

85
00:03:27,440 --> 00:03:29,280
equal n over log

86
00:03:29,280 --> 00:03:31,120
raised to the power of one plus one over

87
00:03:31,120 --> 00:03:34,799
c for a certain uh parameter for certain

88
00:03:34,799 --> 00:03:38,080
range of sc the runtime of our algorithm

89
00:03:38,080 --> 00:03:40,959
is containing a log n over a small

90
00:03:40,959 --> 00:03:43,680
of k and also it's containing two to the

91
00:03:43,680 --> 00:03:47,440
small of n over log n and in this uh

92
00:03:47,440 --> 00:03:50,239
setting the runtime of brute force is a

93
00:03:50,239 --> 00:03:53,120
log n over a big omega of k and the

94
00:03:53,120 --> 00:03:56,959
runtime of bkw is a 2 to the big omega

95
00:03:56,959 --> 00:03:59,280
of n over log n and notice that the

96
00:03:59,280 --> 00:04:01,680
runtime of our algorithm

97
00:04:01,680 --> 00:04:04,640
is asymptotically better in exponent in

98
00:04:04,640 --> 00:04:06,159
comparison to

99
00:04:06,159 --> 00:04:07,680
both of these

100
00:04:07,680 --> 00:04:09,439
two algorithm

101
00:04:09,439 --> 00:04:11,840
and one ranges of k

102
00:04:11,840 --> 00:04:13,840
to give you an idea of the ranges of k

103
00:04:13,840 --> 00:04:16,160
you can think of k being much smaller

104
00:04:16,160 --> 00:04:19,120
than n over log n and much bigger than n

105
00:04:19,120 --> 00:04:22,479
over log squared and this uh smaller and

106
00:04:22,479 --> 00:04:25,440
bigger is captured with the symmetric

107
00:04:25,440 --> 00:04:29,040
in the exponent of the log

108
00:04:29,040 --> 00:04:29,759
so

109
00:04:29,759 --> 00:04:31,040
there is an

110
00:04:31,040 --> 00:04:32,720
for the low noise setting here i'm going

111
00:04:32,720 --> 00:04:35,199
to just talk about the special case

112
00:04:35,199 --> 00:04:36,320
for the full

113
00:04:36,320 --> 00:04:39,360
parameter please refer to the paper so

114
00:04:39,360 --> 00:04:42,320
for a sparsity case such that k equal

115
00:04:42,320 --> 00:04:45,440
equal to square root of square root of n

116
00:04:45,440 --> 00:04:47,759
divided by log log n and for the noise

117
00:04:47,759 --> 00:04:50,720
rate of eta equal log n over square root

118
00:04:50,720 --> 00:04:51,919
of

119
00:04:51,919 --> 00:04:54,479
square root of n and the learning

120
00:04:54,479 --> 00:04:57,360
algorithm runs in time n over k raised

121
00:04:57,360 --> 00:04:59,520
to the power of

122
00:04:59,520 --> 00:05:01,520
raised to the power of small of k and

123
00:05:01,520 --> 00:05:04,080
the run time of brute force is at least

124
00:05:04,080 --> 00:05:06,160
n over k to the k and the run time of

125
00:05:06,160 --> 00:05:07,840
lucky burst force which we're going to

126
00:05:07,840 --> 00:05:09,680
talk about is going to be

127
00:05:09,680 --> 00:05:13,680
n over k to the small omega of k

128
00:05:13,680 --> 00:05:15,440
and again the runtime of our learning

129
00:05:15,440 --> 00:05:17,680
algorithm is better than these two

130
00:05:17,680 --> 00:05:20,320
algorithm asymptotically indexed one

131
00:05:20,320 --> 00:05:23,440
and as an other applications for our

132
00:05:23,440 --> 00:05:25,280
work is we showed that by applying node

133
00:05:25,280 --> 00:05:28,479
reduction to lpn and solving lpn using

134
00:05:28,479 --> 00:05:31,199
our algorithm we can obtain application

135
00:05:31,199 --> 00:05:33,120
to learning other classes of functions

136
00:05:33,120 --> 00:05:37,120
such as dnf and juntus

137
00:05:37,120 --> 00:05:39,280
so here is the outline of this work we

138
00:05:39,280 --> 00:05:40,880
are going to first look at the fourier

139
00:05:40,880 --> 00:05:43,199
analysis of boolean function which is a

140
00:05:43,199 --> 00:05:46,720
basic block of our artwork then we show

141
00:05:46,720 --> 00:05:49,360
how we can recover secret from fourier

142
00:05:49,360 --> 00:05:52,560
coefficient and we show that in case

143
00:05:52,560 --> 00:05:54,800
that the samples are biased we can have

144
00:05:54,800 --> 00:05:58,080
an improvement uh to finding the secret

145
00:05:58,080 --> 00:06:00,560
then our focus shifts toward uh

146
00:06:00,560 --> 00:06:04,000
constructing this bias sample which in

147
00:06:04,000 --> 00:06:07,440
constant noise stating we use a vkw

148
00:06:07,440 --> 00:06:09,520
algorithm and for low noise setting we

149
00:06:09,520 --> 00:06:11,680
use the design by and nissan and

150
00:06:11,680 --> 00:06:13,440
vickerson

151
00:06:13,440 --> 00:06:16,319
so consider boolean function f

152
00:06:16,319 --> 00:06:19,280
from 0 1 to the n to 0 1 and this work

153
00:06:19,280 --> 00:06:21,919
and also in the paper uh we change uh

154
00:06:21,919 --> 00:06:23,520
our mapping and we

155
00:06:23,520 --> 00:06:24,720
we change

156
00:06:24,720 --> 00:06:27,600
our notation from zero one zero and one

157
00:06:27,600 --> 00:06:30,319
to uh minus one one by mapping one to

158
00:06:30,319 --> 00:06:33,840
minus one and map uh mapping uh zero 0

159
00:06:33,840 --> 00:06:37,520
to 1 and in this case the multiplication

160
00:06:37,520 --> 00:06:39,360
on minus 1 1 is

161
00:06:39,360 --> 00:06:43,199
x or in the previous notation

162
00:06:43,199 --> 00:06:44,800
so the free expansion of boolean

163
00:06:44,800 --> 00:06:46,639
function is simply

164
00:06:46,639 --> 00:06:49,599
its representation as real a monthly

165
00:06:49,599 --> 00:06:51,759
linear polynomial which i'll explain

166
00:06:51,759 --> 00:06:52,960
what i mean

167
00:06:52,960 --> 00:06:55,280
just and now so assume that we have a

168
00:06:55,280 --> 00:06:57,840
function that takes a two coordinate x

169
00:06:57,840 --> 00:07:00,960
one x two and just output the maximum of

170
00:07:00,960 --> 00:07:03,520
these two so the right hand side shows

171
00:07:03,520 --> 00:07:05,919
the fourier expansion of the same

172
00:07:05,919 --> 00:07:06,880
function

173
00:07:06,880 --> 00:07:10,319
so here we have a four coordinates so

174
00:07:10,319 --> 00:07:12,960
for example the second coordinate is the

175
00:07:12,960 --> 00:07:15,599
fourier coefficient at this singleton

176
00:07:15,599 --> 00:07:18,880
set one and the last coordinate is a

177
00:07:18,880 --> 00:07:21,680
fourier coefficient at the set uh one

178
00:07:21,680 --> 00:07:24,240
two so we compute uh we see that the

179
00:07:24,240 --> 00:07:26,560
fourier coefficient is defined over uh

180
00:07:26,560 --> 00:07:29,440
some subset of the uh

181
00:07:29,440 --> 00:07:31,440
in inner

182
00:07:31,440 --> 00:07:33,199
subset of basically

183
00:07:33,199 --> 00:07:34,240
x

184
00:07:34,240 --> 00:07:36,960
uh so for example to compute the fourier

185
00:07:36,960 --> 00:07:40,880
coefficient of singleton set one we can

186
00:07:40,880 --> 00:07:44,400
compute this expected value over all the

187
00:07:44,400 --> 00:07:48,800
values of the input x and we compute the

188
00:07:48,800 --> 00:07:50,160
we compute

189
00:07:50,160 --> 00:07:51,759
function times

190
00:07:51,759 --> 00:07:53,599
the first coordinate and to compute the

191
00:07:53,599 --> 00:07:56,319
fourier coefficient of set 1 2 we again

192
00:07:56,319 --> 00:07:58,960
take the expected value of the function

193
00:07:58,960 --> 00:08:00,560
times

194
00:08:00,560 --> 00:08:03,759
those function times coordinate x1 and

195
00:08:03,759 --> 00:08:06,160
x2

196
00:08:07,599 --> 00:08:10,479
so to define a free expansion and more

197
00:08:10,479 --> 00:08:12,639
accurately and we say that every

198
00:08:12,639 --> 00:08:13,680
function

199
00:08:13,680 --> 00:08:15,840
f can be represented as a linear

200
00:08:15,840 --> 00:08:18,800
combination so here the combination is

201
00:08:18,800 --> 00:08:21,440
taken over all the subset s that are

202
00:08:21,440 --> 00:08:24,879
subset of set uh one through n

203
00:08:24,879 --> 00:08:28,400
uh and we have a fourier coefficient f

204
00:08:28,400 --> 00:08:31,680
hat and multiply chi s and the chi is

205
00:08:31,680 --> 00:08:34,640
simply the multiplication of the input

206
00:08:34,640 --> 00:08:37,599
coordinate and in order to compute the

207
00:08:37,599 --> 00:08:39,839
uh fourier coefficient we take we

208
00:08:39,839 --> 00:08:42,799
compute this expected value

209
00:08:42,799 --> 00:08:45,279
and going back to our example we see

210
00:08:45,279 --> 00:08:48,320
that the free coefficient of empty set

211
00:08:48,320 --> 00:08:50,399
is one half the free coefficient of

212
00:08:50,399 --> 00:08:53,519
single listen set one and two is again

213
00:08:53,519 --> 00:08:56,080
one half and the free coefficient of set

214
00:08:56,080 --> 00:09:00,080
uh one two is uh minus one half

215
00:09:00,080 --> 00:09:01,680
uh so

216
00:09:01,680 --> 00:09:03,519
let's see how we can recover secret

217
00:09:03,519 --> 00:09:05,120
using uh

218
00:09:05,120 --> 00:09:07,120
a fourier coefficient so let's focus on

219
00:09:07,120 --> 00:09:09,519
the noiseless case let's focus on the

220
00:09:09,519 --> 00:09:11,360
case that we are only given an inner

221
00:09:11,360 --> 00:09:14,080
product of x times s

222
00:09:14,080 --> 00:09:18,160
so take the function x 1 plus x

223
00:09:18,160 --> 00:09:20,959
3 and mod 2. so this one

224
00:09:20,959 --> 00:09:23,360
this function has as input x which has

225
00:09:23,360 --> 00:09:24,480
only

226
00:09:24,480 --> 00:09:27,040
three coordinates and in this case the

227
00:09:27,040 --> 00:09:30,000
secret is one zero one

228
00:09:30,000 --> 00:09:32,240
and if we change our notation to minus

229
00:09:32,240 --> 00:09:34,320
one one notation then the same function

230
00:09:34,320 --> 00:09:38,480
can be represented as x1 times x3

231
00:09:38,480 --> 00:09:41,600
if we use the previous uh if you use the

232
00:09:41,600 --> 00:09:44,160
previous slides and we compute the

233
00:09:44,160 --> 00:09:45,760
fourier coefficient

234
00:09:45,760 --> 00:09:47,440
we can see that the fourier coefficient

235
00:09:47,440 --> 00:09:50,080
is all is all zero in all the subsets

236
00:09:50,080 --> 00:09:52,480
except the set one three and note that

237
00:09:52,480 --> 00:09:56,000
the set uh subset one three is exactly

238
00:09:56,000 --> 00:09:59,360
the uh the locations that the secret is

239
00:09:59,360 --> 00:10:00,880
a non-zero

240
00:10:00,880 --> 00:10:04,000
and here the free coefficient is uh

241
00:10:04,000 --> 00:10:06,880
only on a single the free coefficient

242
00:10:06,880 --> 00:10:09,279
that the weight of the fourier is

243
00:10:09,279 --> 00:10:11,760
only on a single fourier coefficient and

244
00:10:11,760 --> 00:10:13,920
in order to find the single

245
00:10:13,920 --> 00:10:17,600
uh fourier coefficient we have to

246
00:10:17,600 --> 00:10:20,000
run a brute force search over

247
00:10:20,000 --> 00:10:22,800
all basically parities of size at most k

248
00:10:22,800 --> 00:10:25,519
which is kind of infeasible

249
00:10:25,519 --> 00:10:27,600
but what if the samples are not from a

250
00:10:27,600 --> 00:10:30,880
uniform distribution so what if x is a 0

251
00:10:30,880 --> 00:10:33,200
with uh some probability which is not

252
00:10:33,200 --> 00:10:35,440
one half so what if x is zero with

253
00:10:35,440 --> 00:10:37,680
probability one half plus p essentially

254
00:10:37,680 --> 00:10:39,760
we can have free coefficient in this

255
00:10:39,760 --> 00:10:41,279
case as well

256
00:10:41,279 --> 00:10:44,480
except that this time we change uh our

257
00:10:44,480 --> 00:10:46,959
chi function and we basically normalize

258
00:10:46,959 --> 00:10:48,320
the chi function

259
00:10:48,320 --> 00:10:50,399
and in order to compute the fourier

260
00:10:50,399 --> 00:10:52,800
coefficient we have the same uh

261
00:10:52,800 --> 00:10:55,200
we have the same calculation as before

262
00:10:55,200 --> 00:10:58,240
except that this time x is coming uh is

263
00:10:58,240 --> 00:10:59,839
samples from this

264
00:10:59,839 --> 00:11:02,560
bias distribution which we denoted by

265
00:11:02,560 --> 00:11:04,560
d of p

266
00:11:04,560 --> 00:11:06,480
so in this case it can be shown that the

267
00:11:06,480 --> 00:11:09,360
free coefficient of singleton set j

268
00:11:09,360 --> 00:11:11,440
is zero for the coordinate that the

269
00:11:11,440 --> 00:11:14,480
secret is zero and it's non-zero for the

270
00:11:14,480 --> 00:11:17,120
cases that the secret key is one in

271
00:11:17,120 --> 00:11:19,279
those coordinates so our learning

272
00:11:19,279 --> 00:11:21,279
algorithm wants to distinguish these two

273
00:11:21,279 --> 00:11:24,320
cases so basically it wants to

274
00:11:24,320 --> 00:11:26,399
distinguish if the if the fourier

275
00:11:26,399 --> 00:11:29,279
coefficient at singleton set is 0 or if

276
00:11:29,279 --> 00:11:32,240
it's a non-zero but remember that that

277
00:11:32,240 --> 00:11:34,880
the samples are noisy so we really have

278
00:11:34,880 --> 00:11:37,200
to distinguish between 0 and something

279
00:11:37,200 --> 00:11:40,480
which is multiplied by noise rate so

280
00:11:40,480 --> 00:11:41,600
but still

281
00:11:41,600 --> 00:11:43,760
the goal is to distinguish zero versus

282
00:11:43,760 --> 00:11:47,440
something which is non-zero

283
00:11:47,440 --> 00:11:51,040
so how we we can think of uh p bias lpn

284
00:11:51,040 --> 00:11:53,120
oracle so how we can think about it we

285
00:11:53,120 --> 00:11:54,480
can think of it

286
00:11:54,480 --> 00:11:56,720
exactly the same as before we have a

287
00:11:56,720 --> 00:11:59,440
secret key but this time x is sampled

288
00:11:59,440 --> 00:12:01,839
from a bias distribution so from a

289
00:12:01,839 --> 00:12:04,800
distribution such that x prime is zero

290
00:12:04,800 --> 00:12:07,839
with some probability one half plus p

291
00:12:07,839 --> 00:12:08,959
over two

292
00:12:08,959 --> 00:12:11,839
we have the same inner product as before

293
00:12:11,839 --> 00:12:12,800
but

294
00:12:12,800 --> 00:12:15,279
we flipped this time with probability

295
00:12:15,279 --> 00:12:17,519
one minus eta prime this is different

296
00:12:17,519 --> 00:12:22,160
than lpn for lpn this was eta and uh

297
00:12:22,160 --> 00:12:25,360
again we have we output our samples as a

298
00:12:25,360 --> 00:12:28,639
ordered pair x prime and b prime and b

299
00:12:28,639 --> 00:12:31,040
prime is our label and we represented

300
00:12:31,040 --> 00:12:34,399
this oracle by olpnp which p represents

301
00:12:34,399 --> 00:12:37,519
that the x is not a uniform anymore and

302
00:12:37,519 --> 00:12:41,680
h a prime which is r and noise rate

303
00:12:41,680 --> 00:12:43,839
so in order to construct this oracle we

304
00:12:43,839 --> 00:12:45,519
use uh we use

305
00:12:45,519 --> 00:12:48,160
an algorithm uh by

306
00:12:48,160 --> 00:12:52,959
bkw so what pkw does is that for each

307
00:12:52,959 --> 00:12:54,240
sample

308
00:12:54,240 --> 00:12:56,880
which is represented as x and b it's a

309
00:12:56,880 --> 00:13:00,000
split x into a block each contains b

310
00:13:00,000 --> 00:13:01,120
elements

311
00:13:01,120 --> 00:13:03,920
and then what it does is it partitions

312
00:13:03,920 --> 00:13:06,000
the partitions the query is based on the

313
00:13:06,000 --> 00:13:08,720
first block so for example we put all

314
00:13:08,720 --> 00:13:11,760
the queries which has zero one in the

315
00:13:11,760 --> 00:13:14,560
first block in one partition and all the

316
00:13:14,560 --> 00:13:17,040
queries which has one zero in the second

317
00:13:17,040 --> 00:13:19,360
partition and so on and so forth and we

318
00:13:19,360 --> 00:13:22,160
zero out the queries so we make sure

319
00:13:22,160 --> 00:13:25,040
that the first block in all uh queries

320
00:13:25,040 --> 00:13:27,440
are gonna be zero out and this is

321
00:13:27,440 --> 00:13:30,000
essentially the first step of this

322
00:13:30,000 --> 00:13:31,120
algorithm

323
00:13:31,120 --> 00:13:33,760
and the algorithm progress by looking at

324
00:13:33,760 --> 00:13:36,560
the this time at the second block and

325
00:13:36,560 --> 00:13:39,120
partition based on the second block and

326
00:13:39,120 --> 00:13:42,000
then zero out and then progress to the

327
00:13:42,000 --> 00:13:43,279
next block

328
00:13:43,279 --> 00:13:46,160
so in each step we essentially lose some

329
00:13:46,160 --> 00:13:48,560
number of queries and the noise rate of

330
00:13:48,560 --> 00:13:52,638
the new samples uh grows

331
00:13:52,880 --> 00:13:56,800
so we want to construct a p bias lpn

332
00:13:56,800 --> 00:13:58,480
oracle so we want to buy we want to

333
00:13:58,480 --> 00:14:00,560
construct this uh

334
00:14:00,560 --> 00:14:03,839
p bias oracle but we re we only have

335
00:14:03,839 --> 00:14:06,720
access to the oracle that give a sample

336
00:14:06,720 --> 00:14:09,839
from the original uh oracle which was

337
00:14:09,839 --> 00:14:12,079
not biased so we are given a sample x

338
00:14:12,079 --> 00:14:14,320
and b and from that we have to do

339
00:14:14,320 --> 00:14:17,519
something and construct the p bias and

340
00:14:17,519 --> 00:14:20,480
samples which are denoted by x prime and

341
00:14:20,480 --> 00:14:23,040
b prime so the samples here has a

342
00:14:23,040 --> 00:14:24,560
property that

343
00:14:24,560 --> 00:14:26,480
x is zero in j's coordinate with

344
00:14:26,480 --> 00:14:28,720
probability exactly one-half but the

345
00:14:28,720 --> 00:14:30,639
samples that are

346
00:14:30,639 --> 00:14:34,000
from bias oracle has a proper

347
00:14:34,000 --> 00:14:36,000
property that they're zero with uh

348
00:14:36,000 --> 00:14:38,000
probability one half

349
00:14:38,000 --> 00:14:40,800
plus p over two

350
00:14:40,800 --> 00:14:43,440
so how we can do this so each time we

351
00:14:43,440 --> 00:14:45,680
call an oracle the oracle sample and

352
00:14:45,680 --> 00:14:49,600
index set r so basically for each

353
00:14:49,600 --> 00:14:53,120
index it either it select its index and

354
00:14:53,120 --> 00:14:55,519
independently with probability p

355
00:14:55,519 --> 00:14:58,800
so let's mark the selected index

356
00:14:58,800 --> 00:15:01,279
uh by dark blue

357
00:15:01,279 --> 00:15:02,240
and

358
00:15:02,240 --> 00:15:03,360
we

359
00:15:03,360 --> 00:15:06,560
once we have this index set r we can run

360
00:15:06,560 --> 00:15:10,399
the pkw our algorithm so pkw our

361
00:15:10,399 --> 00:15:12,399
algorithm is essentially

362
00:15:12,399 --> 00:15:16,240
exactly similar to the bkw algorithm but

363
00:15:16,240 --> 00:15:19,040
it's only focus on the coordinates uh

364
00:15:19,040 --> 00:15:21,600
pointed by r so essentially what it

365
00:15:21,600 --> 00:15:24,079
means is that upon receiving some

366
00:15:24,079 --> 00:15:27,600
samples from the original lpn oracle the

367
00:15:27,600 --> 00:15:30,880
samples has some values in the dark blue

368
00:15:30,880 --> 00:15:34,079
coordinates so it can be 0 1 or whatever

369
00:15:34,079 --> 00:15:37,759
and after running the bkwr algorithm

370
00:15:37,759 --> 00:15:40,000
we're making we make sure that we output

371
00:15:40,000 --> 00:15:41,920
a single

372
00:15:41,920 --> 00:15:45,199
simple single query which has zero in

373
00:15:45,199 --> 00:15:49,040
all the dark blue coordinates

374
00:15:50,079 --> 00:15:51,440
okay so

375
00:15:51,440 --> 00:15:52,560
uh

376
00:15:52,560 --> 00:15:56,000
one uh one details is that the size of r

377
00:15:56,000 --> 00:15:58,079
might change across different oracle

378
00:15:58,079 --> 00:16:02,240
calls but if we fix a which is uh some

379
00:16:02,240 --> 00:16:05,279
parameter of the bkw algorithm v make

380
00:16:05,279 --> 00:16:07,279
sure that the constant number of samples

381
00:16:07,279 --> 00:16:10,480
are obtained are combined uh to get a

382
00:16:10,480 --> 00:16:12,160
single uh

383
00:16:12,160 --> 00:16:13,759
bias sample

384
00:16:13,759 --> 00:16:16,880
and we showed that the samples uh

385
00:16:16,880 --> 00:16:20,399
x prime b prime outputted by bkw our

386
00:16:20,399 --> 00:16:22,160
algorithm

387
00:16:22,160 --> 00:16:24,880
are independent and distributed

388
00:16:24,880 --> 00:16:28,399
identically to sample drawn from p bias

389
00:16:28,399 --> 00:16:30,720
lpn oracle uh

390
00:16:30,720 --> 00:16:32,880
for a different noise rate so here is

391
00:16:32,880 --> 00:16:36,320
the relation of the noise rate eta prime

392
00:16:36,320 --> 00:16:38,880
for the p bias lp oracle and the noise

393
00:16:38,880 --> 00:16:42,959
rate of the original lpn oracle

394
00:16:42,959 --> 00:16:45,759
so here really really

395
00:16:45,759 --> 00:16:47,759
reminding you about what the what the

396
00:16:47,759 --> 00:16:49,839
learning algorithm does is it has to

397
00:16:49,839 --> 00:16:52,480
distinguish between a zero and this

398
00:16:52,480 --> 00:16:55,120
parameter which we call it epsilon and

399
00:16:55,120 --> 00:16:57,279
at if

400
00:16:57,279 --> 00:16:59,519
and we said t which is the number of p

401
00:16:59,519 --> 00:17:02,079
by a sample to have an estimate within

402
00:17:02,079 --> 00:17:04,000
an epsilon over

403
00:17:04,000 --> 00:17:05,839
2 distance

404
00:17:05,839 --> 00:17:08,559
so basically in our paper we we show

405
00:17:08,559 --> 00:17:12,319
that for sparsity such that k equal n

406
00:17:12,319 --> 00:17:14,720
over log

407
00:17:14,720 --> 00:17:16,640
n over log raised to the power of 1 plus

408
00:17:16,640 --> 00:17:18,400
1 over c for certain

409
00:17:18,400 --> 00:17:20,640
ranges of parameter we are

410
00:17:20,640 --> 00:17:22,319
we are

411
00:17:22,319 --> 00:17:24,480
we have an algorithm which runs faster

412
00:17:24,480 --> 00:17:25,359
in the

413
00:17:25,359 --> 00:17:26,559
uh

414
00:17:26,559 --> 00:17:28,880
faster in comparison to brute force and

415
00:17:28,880 --> 00:17:32,160
bkw algorithm and faster is captured by

416
00:17:32,160 --> 00:17:36,799
a asymptotic in the exponent

417
00:17:37,280 --> 00:17:39,360
so for the low noise setting we present

418
00:17:39,360 --> 00:17:42,480
an algorithm called sampi that draws

419
00:17:42,480 --> 00:17:45,280
only polynomial number of samples from

420
00:17:45,280 --> 00:17:48,400
lpn oracle and uses them to construct a

421
00:17:48,400 --> 00:17:51,440
larger set of p biased samples and they

422
00:17:51,440 --> 00:17:53,520
catch here this is this the samples are

423
00:17:53,520 --> 00:17:56,320
close to being pairwise independent

424
00:17:56,320 --> 00:17:59,919
and the idea of uh this design is based

425
00:17:59,919 --> 00:18:03,120
on a design of nissan and vietgerson

426
00:18:03,120 --> 00:18:04,960
and the learning algorithm is

427
00:18:04,960 --> 00:18:06,640
essentially very similar to the

428
00:18:06,640 --> 00:18:09,120
algorithm we had before except we we

429
00:18:09,120 --> 00:18:12,799
have to repeat it a number of times

430
00:18:12,799 --> 00:18:15,600
so here is how we generate a p bias

431
00:18:15,600 --> 00:18:19,360
sample so we generate only two np plus

432
00:18:19,360 --> 00:18:22,080
one squared a number of samples from the

433
00:18:22,080 --> 00:18:23,520
original

434
00:18:23,520 --> 00:18:28,400
lpn oracle and the sampy uh put this uh

435
00:18:28,400 --> 00:18:29,840
put this uh

436
00:18:29,840 --> 00:18:31,440
queries into

437
00:18:31,440 --> 00:18:33,600
into this uh bucket

438
00:18:33,600 --> 00:18:37,919
uh so uh for example bucket one and o2

439
00:18:37,919 --> 00:18:41,760
can have at most uh can have at most t

440
00:18:41,760 --> 00:18:43,760
queries that are

441
00:18:43,760 --> 00:18:45,840
common between them

442
00:18:45,840 --> 00:18:49,039
uh so each time that we call each time

443
00:18:49,039 --> 00:18:52,240
that we call an oracle the oracle does

444
00:18:52,240 --> 00:18:55,520
three things so it first sample r

445
00:18:55,520 --> 00:18:59,039
so r is similar to before we have a dark

446
00:18:59,039 --> 00:19:01,120
blue coordinate that has to

447
00:19:01,120 --> 00:19:03,679
zero out and in the second step we look

448
00:19:03,679 --> 00:19:04,400
at

449
00:19:04,400 --> 00:19:07,520
each bucket and we select some queries

450
00:19:07,520 --> 00:19:09,600
from this bucket and we make sure that

451
00:19:09,600 --> 00:19:12,640
we zero out the coordinates that are uh

452
00:19:12,640 --> 00:19:14,720
pointed by uh

453
00:19:14,720 --> 00:19:17,440
set r so we zero out the dark blue

454
00:19:17,440 --> 00:19:20,000
coordinate and in the second step this

455
00:19:20,000 --> 00:19:22,160
is just a detail that

456
00:19:22,160 --> 00:19:24,559
we have we want to make sure that and no

457
00:19:24,559 --> 00:19:27,600
matter what we have the same number of

458
00:19:27,600 --> 00:19:29,760
queries that are added together to

459
00:19:29,760 --> 00:19:32,960
generate our uh biased sample so we

460
00:19:32,960 --> 00:19:35,280
essentially add noise

461
00:19:35,280 --> 00:19:36,640
uh

462
00:19:36,640 --> 00:19:37,679
so the

463
00:19:37,679 --> 00:19:40,400
important thing to notice is that uh

464
00:19:40,400 --> 00:19:44,080
we have we need to only uh two np plus

465
00:19:44,080 --> 00:19:48,000
one squared samples to start with

466
00:19:48,000 --> 00:19:49,440
so uh

467
00:19:49,440 --> 00:19:52,400
we showed that in in our paper we showed

468
00:19:52,400 --> 00:19:54,320
that the sample is generated like this

469
00:19:54,320 --> 00:19:58,720
so the samples x i and b i outputted is

470
00:19:58,720 --> 00:20:01,280
outputted by the previous construction

471
00:20:01,280 --> 00:20:02,640
is uh

472
00:20:02,640 --> 00:20:05,280
distributed identically equal to the

473
00:20:05,280 --> 00:20:08,240
sample drawn from a p bias lpn oracle

474
00:20:08,240 --> 00:20:10,640
but this time with different eta prime

475
00:20:10,640 --> 00:20:12,799
and here is the relation between the eta

476
00:20:12,799 --> 00:20:15,039
prime of this new construction and the

477
00:20:15,039 --> 00:20:18,240
eta of the original lpn oracle and we

478
00:20:18,240 --> 00:20:20,559
showed that x i x j

479
00:20:20,559 --> 00:20:23,120
are pairwise independent

480
00:20:23,120 --> 00:20:24,880
so the thing uh

481
00:20:24,880 --> 00:20:27,360
what we found here is that we showed

482
00:20:27,360 --> 00:20:30,480
that we can really bound the covariance

483
00:20:30,480 --> 00:20:31,360
of the

484
00:20:31,360 --> 00:20:34,720
of the covariance of this new generated

485
00:20:34,720 --> 00:20:37,200
samples

486
00:20:38,240 --> 00:20:41,039
so finally we showed that

487
00:20:41,039 --> 00:20:44,080
the brute force runs in times n over k

488
00:20:44,080 --> 00:20:46,559
obviously the lucky bruce force is the

489
00:20:46,559 --> 00:20:50,159
case that if we sample n which is m

490
00:20:50,159 --> 00:20:52,240
number of samples which m is equal n

491
00:20:52,240 --> 00:20:53,679
over uh

492
00:20:53,679 --> 00:20:57,120
1 minus eta we expect that approximately

493
00:20:57,120 --> 00:20:59,520
n noiseless samples

494
00:20:59,520 --> 00:21:02,080
are among them so the question now is

495
00:21:02,080 --> 00:21:05,199
going to be select

496
00:21:05,840 --> 00:21:08,320
n out of this m number of samples and

497
00:21:08,320 --> 00:21:11,039
run gaussian elimination and since we

498
00:21:11,039 --> 00:21:14,400
expect exactly any number of samples to

499
00:21:14,400 --> 00:21:17,760
be noiseless we expect to recover as

500
00:21:17,760 --> 00:21:18,559
by

501
00:21:18,559 --> 00:21:21,200
doing this uh type of algorithm which we

502
00:21:21,200 --> 00:21:23,840
call a lucky brute force and we show

503
00:21:23,840 --> 00:21:26,080
that the runtime of this algorithm is

504
00:21:26,080 --> 00:21:28,320
essentially e to the eta n

505
00:21:28,320 --> 00:21:31,039
and uh for this uh parameter say for

506
00:21:31,039 --> 00:21:34,080
this sample parameter setting uh our

507
00:21:34,080 --> 00:21:36,159
algorithm is uh

508
00:21:36,159 --> 00:21:39,200
faster than both brute force and the

509
00:21:39,200 --> 00:21:42,480
lucky brute force and for the full range

510
00:21:42,480 --> 00:21:45,679
of parameters this is just one

511
00:21:45,679 --> 00:21:48,159
example of the parameter for the full

512
00:21:48,159 --> 00:21:50,720
range of parameter please refer to the

513
00:21:50,720 --> 00:21:51,760
paper

514
00:21:51,760 --> 00:21:52,640
so

515
00:21:52,640 --> 00:21:57,080
thank you so much for your attention

