1
00:00:01,199 --> 00:00:03,439
hello everyone my name is maxim blossom

2
00:00:03,439 --> 00:00:04,960
and uh in this video i will be

3
00:00:04,960 --> 00:00:06,640
presenting the paper entitled

4
00:00:06,640 --> 00:00:08,400
exactly the sampling from montgomery

5
00:00:08,400 --> 00:00:10,719
distributions which is a joint work with

6
00:00:10,719 --> 00:00:12,400
the marquest

7
00:00:12,400 --> 00:00:15,599
okay let's begin so yeah we're

8
00:00:15,599 --> 00:00:17,359
interested in the following problem

9
00:00:17,359 --> 00:00:19,680
we want uh we're given a description of

10
00:00:19,680 --> 00:00:21,199
a lattice which you can think of as a

11
00:00:21,199 --> 00:00:21,760
basis

12
00:00:21,760 --> 00:00:22,880
and we want to sample from a

13
00:00:22,880 --> 00:00:24,960
distribution d whose support is a subset

14
00:00:24,960 --> 00:00:26,160
of the lattice l

15
00:00:26,160 --> 00:00:28,880
that is independent of the basis so for

16
00:00:28,880 --> 00:00:30,480
an algorithm to be a good solution to

17
00:00:30,480 --> 00:00:32,640
this problem we also require that

18
00:00:32,640 --> 00:00:34,239
it's possible to sample from an error

19
00:00:34,239 --> 00:00:36,399
distribution with respect to the input

20
00:00:36,399 --> 00:00:38,160
description of the lattice

21
00:00:38,160 --> 00:00:40,960
second we want it to be possible to

22
00:00:40,960 --> 00:00:43,120
shift the distribution by any chosen

23
00:00:43,120 --> 00:00:45,200
target vector in the space

24
00:00:45,200 --> 00:00:48,079
okay so there are already uh lattice

25
00:00:48,079 --> 00:00:50,239
some players the two main one being gpv

26
00:00:50,239 --> 00:00:51,680
also known as client sampler and the

27
00:00:51,680 --> 00:00:53,760
second one being pi cut simpler

28
00:00:53,760 --> 00:00:56,480
so both of these algorithms they sample

29
00:00:56,480 --> 00:00:57,120
from

30
00:00:57,120 --> 00:00:58,719
the discrete gaussian distribution with

31
00:00:58,719 --> 00:01:00,320
an expected norm of the output being

32
00:01:00,320 --> 00:01:01,039
about

33
00:01:01,039 --> 00:01:03,680
root n times some value that represents

34
00:01:03,680 --> 00:01:05,119
that represents

35
00:01:05,119 --> 00:01:08,720
the length of the basis that you use

36
00:01:08,720 --> 00:01:10,799
i won't go into the detail about what

37
00:01:10,799 --> 00:01:12,479
length of the basis means but it's

38
00:01:12,479 --> 00:01:12,960
written

39
00:01:12,960 --> 00:01:16,080
on the slides if you're interested okay

40
00:01:16,080 --> 00:01:16,479
so

41
00:01:16,479 --> 00:01:18,320
the discrete gaussian distribution i

42
00:01:18,320 --> 00:01:20,000
just mentioned is defined

43
00:01:20,000 --> 00:01:23,119
as the discretization of the usual

44
00:01:23,119 --> 00:01:25,200
gaussian distribution where the

45
00:01:25,200 --> 00:01:27,119
discretization process is as follows so

46
00:01:27,119 --> 00:01:28,159
you have a distribution d

47
00:01:28,159 --> 00:01:31,200
of density f over r n and the

48
00:01:31,200 --> 00:01:32,640
discretization of d

49
00:01:32,640 --> 00:01:35,759
over l is defined uh as follows so its

50
00:01:35,759 --> 00:01:37,600
density is

51
00:01:37,600 --> 00:01:40,640
the restriction of f normalized

52
00:01:40,640 --> 00:01:44,079
on the lattice okay so

53
00:01:44,079 --> 00:01:47,119
now why this problem well something

54
00:01:47,119 --> 00:01:49,520
distributions analysis is a useful tool

55
00:01:49,520 --> 00:01:50,320
for many

56
00:01:50,320 --> 00:01:52,399
constructions in alice cryptography so

57
00:01:52,399 --> 00:01:53,360
you have your

58
00:01:53,360 --> 00:01:56,399
short list of applications of

59
00:01:56,399 --> 00:01:59,600
such algorithms okay so

60
00:01:59,600 --> 00:02:01,840
now it's not always mandatory to have

61
00:02:01,840 --> 00:02:03,280
the sample distribution to be

62
00:02:03,280 --> 00:02:05,360
gaussian for the applications in

63
00:02:05,360 --> 00:02:06,479
cryptography

64
00:02:06,479 --> 00:02:08,560
and gaussians come with a fair share of

65
00:02:08,560 --> 00:02:10,720
problems regarding implementation and so

66
00:02:10,720 --> 00:02:11,520
on

67
00:02:11,520 --> 00:02:13,120
so we think that it could be interesting

68
00:02:13,120 --> 00:02:15,200
to have various distributions and

69
00:02:15,200 --> 00:02:16,319
various techniques

70
00:02:16,319 --> 00:02:18,400
to sample of our lattices and this is

71
00:02:18,400 --> 00:02:20,000
the point of the framework that we have

72
00:02:20,000 --> 00:02:21,840
constructed

73
00:02:21,840 --> 00:02:25,280
okay and just for example gaussians

74
00:02:25,280 --> 00:02:26,160
they're suited to

75
00:02:26,160 --> 00:02:28,080
euclidean norm but one may need sample

76
00:02:28,080 --> 00:02:29,599
from a distribution that's suitable to

77
00:02:29,599 --> 00:02:31,920
the l1 norm the l-infinity norm

78
00:02:31,920 --> 00:02:34,640
and that's where our framework can

79
00:02:34,640 --> 00:02:36,640
become really useful

80
00:02:36,640 --> 00:02:39,599
okay so the question is can we sample

81
00:02:39,599 --> 00:02:41,120
efficiently from fairly narrow

82
00:02:41,120 --> 00:02:43,680
non-gaussian distributions on lattices

83
00:02:43,680 --> 00:02:45,440
and the answer is pretty much yes

84
00:02:45,440 --> 00:02:47,280
depending on your definition of

85
00:02:47,280 --> 00:02:50,400
efficient and fairly narrow so basically

86
00:02:50,400 --> 00:02:51,920
our framework

87
00:02:51,920 --> 00:02:54,239
offers a trade-off between time and

88
00:02:54,239 --> 00:02:56,480
width of the sample distribution

89
00:02:56,480 --> 00:02:59,760
and you can somewhat have both

90
00:02:59,760 --> 00:03:01,680
meaning both efficiency and a

91
00:03:01,680 --> 00:03:03,440
distribution that's quite concentrated

92
00:03:03,440 --> 00:03:04,640
on the target

93
00:03:04,640 --> 00:03:08,239
but i'll come back to that later

94
00:03:08,239 --> 00:03:11,599
okay so just a quick note

95
00:03:11,599 --> 00:03:13,680
on the round off algorithm since it will

96
00:03:13,680 --> 00:03:15,120
play an important role for the

97
00:03:15,120 --> 00:03:17,440
exposition of our techniques

98
00:03:17,440 --> 00:03:20,000
so the algorithms the algorithm

99
00:03:20,000 --> 00:03:21,200
algorithm sorry

100
00:03:21,200 --> 00:03:23,440
works as follows it takes this input to

101
00:03:23,440 --> 00:03:25,840
basis b and a vector x

102
00:03:25,840 --> 00:03:28,080
and you wanna you wanna compute a

103
00:03:28,080 --> 00:03:29,760
lattice point that is close to x

104
00:03:29,760 --> 00:03:32,720
so first you compute y its coordinates

105
00:03:32,720 --> 00:03:35,120
the coordinates of x in the basis b

106
00:03:35,120 --> 00:03:36,879
then you round them and you return the

107
00:03:36,879 --> 00:03:38,799
lattice point that corresponds to these

108
00:03:38,799 --> 00:03:41,200
coordinates in the basis b

109
00:03:41,200 --> 00:03:44,879
okay so now geometrically

110
00:03:44,879 --> 00:03:48,080
this algorithm can be seen as follows so

111
00:03:48,080 --> 00:03:50,560
the algorithm splits the space rn into a

112
00:03:50,560 --> 00:03:53,200
tessellation as shown in the picture

113
00:03:53,200 --> 00:03:55,360
made of parallel pipettes spanned by the

114
00:03:55,360 --> 00:03:57,040
bases b

115
00:03:57,040 --> 00:04:00,000
and if you want to compute the round off

116
00:04:00,000 --> 00:04:01,519
of some vector x

117
00:04:01,519 --> 00:04:04,400
then you return the unique lattice point

118
00:04:04,400 --> 00:04:06,480
that is within the same parallel pipette

119
00:04:06,480 --> 00:04:07,599
as x

120
00:04:07,599 --> 00:04:10,879
and so as you can see the pre-image of

121
00:04:10,879 --> 00:04:11,920
any lattice point

122
00:04:11,920 --> 00:04:15,760
is the pipette surrounding it

123
00:04:15,760 --> 00:04:17,600
which will be important in the following

124
00:04:17,600 --> 00:04:19,040
okay so

125
00:04:19,040 --> 00:04:22,479
now this is where i move on to

126
00:04:22,479 --> 00:04:25,600
describing what is the id behind

127
00:04:25,600 --> 00:04:28,240
our framework so i will use the simplest

128
00:04:28,240 --> 00:04:29,680
instantiation

129
00:04:29,680 --> 00:04:32,000
that we have which is using the roundup

130
00:04:32,000 --> 00:04:34,000
algorithm to sample uniform distribution

131
00:04:34,000 --> 00:04:36,400
of our hypercube

132
00:04:36,400 --> 00:04:39,120
so first i'll start with a quote from

133
00:04:39,120 --> 00:04:40,000
gpv

134
00:04:40,000 --> 00:04:41,919
where the authors describe a strategy

135
00:04:41,919 --> 00:04:43,360
that has been used

136
00:04:43,360 --> 00:04:46,960
um to sample discrete gaussians

137
00:04:46,960 --> 00:04:49,840
so the strategy goes as follows um if

138
00:04:49,840 --> 00:04:51,280
you want a sample from the discrete

139
00:04:51,280 --> 00:04:52,080
gaussian

140
00:04:52,080 --> 00:04:54,880
you first sample from the continuous the

141
00:04:54,880 --> 00:04:55,520
usual

142
00:04:55,520 --> 00:04:58,400
continuous gaussian and then you run

143
00:04:58,400 --> 00:05:00,479
these samples to the lattice

144
00:05:00,479 --> 00:05:02,000
using the round off algorithm and you

145
00:05:02,000 --> 00:05:03,759
get some distribution defined on the

146
00:05:03,759 --> 00:05:06,080
lattice

147
00:05:06,080 --> 00:05:08,160
so they mentioned and they explained

148
00:05:08,160 --> 00:05:09,440
that if one wants

149
00:05:09,440 --> 00:05:11,120
the output distribution to be close to

150
00:05:11,120 --> 00:05:12,880
the discrete gaussian

151
00:05:12,880 --> 00:05:15,680
then you have to take a somewhat large

152
00:05:15,680 --> 00:05:17,440
standard deviation

153
00:05:17,440 --> 00:05:19,680
and yeah this is because this procedure

154
00:05:19,680 --> 00:05:21,360
samples from the so-called rounded

155
00:05:21,360 --> 00:05:22,639
gaussian

156
00:05:22,639 --> 00:05:24,400
and it's different from the discrete

157
00:05:24,400 --> 00:05:25,840
gaussian that

158
00:05:25,840 --> 00:05:28,720
we were we are actually aiming for and

159
00:05:28,720 --> 00:05:30,560
increasing the parameters

160
00:05:30,560 --> 00:05:32,400
uh decreases the error increasing the

161
00:05:32,400 --> 00:05:34,000
standard deviation decreases the error

162
00:05:34,000 --> 00:05:35,520
and therefore

163
00:05:35,520 --> 00:05:38,880
asymptotically somehow it's working not

164
00:05:38,880 --> 00:05:41,199
not so well for gaussian distributions

165
00:05:41,199 --> 00:05:42,000
so now

166
00:05:42,000 --> 00:05:43,919
let's see what happens if we use this

167
00:05:43,919 --> 00:05:46,479
exact method to sample from the uniform

168
00:05:46,479 --> 00:05:47,600
distribution

169
00:05:47,600 --> 00:05:51,360
on the lattice restricted to a hypercube

170
00:05:51,360 --> 00:05:54,800
so yeah this is uh what we want to do is

171
00:05:54,800 --> 00:05:56,479
to use this method to sample uniform

172
00:05:56,479 --> 00:05:57,440
distribution

173
00:05:57,440 --> 00:05:59,280
over the big black dots here in the

174
00:05:59,280 --> 00:06:01,600
example in dimension two

175
00:06:01,600 --> 00:06:05,039
um okay so let's try the naive

176
00:06:05,039 --> 00:06:07,919
adaptation of this method so first we

177
00:06:07,919 --> 00:06:09,120
sample from the

178
00:06:09,120 --> 00:06:10,880
continuous uniform distribution over the

179
00:06:10,880 --> 00:06:12,720
hypercube here

180
00:06:12,720 --> 00:06:15,919
of radius r then we round

181
00:06:15,919 --> 00:06:18,400
the samples and now we get a picture

182
00:06:18,400 --> 00:06:19,600
like this where the support of the

183
00:06:19,600 --> 00:06:21,039
distribution you get

184
00:06:21,039 --> 00:06:24,400
is the big black dots so as you can see

185
00:06:24,400 --> 00:06:26,479
there are black dots outside of the hype

186
00:06:26,479 --> 00:06:28,560
cube and this is because

187
00:06:28,560 --> 00:06:30,720
a point will have a nonzero probability

188
00:06:30,720 --> 00:06:31,600
whenever

189
00:06:31,600 --> 00:06:33,360
it's parallel pipette the parallel

190
00:06:33,360 --> 00:06:34,639
pipette surrounding it

191
00:06:34,639 --> 00:06:38,639
is intersecting the hype cube

192
00:06:38,639 --> 00:06:40,800
so yeah we see that there are two

193
00:06:40,800 --> 00:06:42,960
problems arising

194
00:06:42,960 --> 00:06:45,199
the first one which i'll call the green

195
00:06:45,199 --> 00:06:46,639
that problem

196
00:06:46,639 --> 00:06:49,599
is that the green dot here on the

197
00:06:49,599 --> 00:06:50,800
picture on the right

198
00:06:50,800 --> 00:06:53,199
is outside of the support of the

199
00:06:53,199 --> 00:06:54,560
distribution

200
00:06:54,560 --> 00:06:57,759
we want to sample but it has a nonzero

201
00:06:57,759 --> 00:06:58,800
probability

202
00:06:58,800 --> 00:07:00,400
because it's probably the pipeline is

203
00:07:00,400 --> 00:07:02,880
intersecting the hypercube and therefore

204
00:07:02,880 --> 00:07:04,720
it has nonzero probability but it

205
00:07:04,720 --> 00:07:06,800
shouldn't so yeah this is the first

206
00:07:06,800 --> 00:07:08,000
problem

207
00:07:08,000 --> 00:07:10,400
and the second problem is what i would

208
00:07:10,400 --> 00:07:12,319
call the blue dot problem

209
00:07:12,319 --> 00:07:16,960
where the blue dot is uh

210
00:07:16,960 --> 00:07:21,199
is uh is is not getting

211
00:07:21,199 --> 00:07:23,919
uh the same probability as the black

212
00:07:23,919 --> 00:07:25,840
dots within the hypercube because

213
00:07:25,840 --> 00:07:27,440
the probability of the blue dot is the

214
00:07:27,440 --> 00:07:30,080
probability that some point is sampled

215
00:07:30,080 --> 00:07:31,840
within the its centered parallely

216
00:07:31,840 --> 00:07:33,039
pipette

217
00:07:33,039 --> 00:07:35,199
but the intersection of this parallel

218
00:07:35,199 --> 00:07:37,120
pipet and the

219
00:07:37,120 --> 00:07:41,039
red hypercube is not full it's

220
00:07:41,039 --> 00:07:42,720
the probability pipette is not a subset

221
00:07:42,720 --> 00:07:44,879
of this hypercube and therefore its

222
00:07:44,879 --> 00:07:46,160
probability is going to be

223
00:07:46,160 --> 00:07:48,000
lower than the probability of the black

224
00:07:48,000 --> 00:07:49,680
dots for which the

225
00:07:49,680 --> 00:07:51,759
vibrate is completely a subset of the

226
00:07:51,759 --> 00:07:52,960
hypercube

227
00:07:52,960 --> 00:07:55,039
and so this is not going to be uniform

228
00:07:55,039 --> 00:07:56,879
and so this is not going to be the

229
00:07:56,879 --> 00:08:00,160
distribution we are aiming for okay

230
00:08:00,160 --> 00:08:03,440
so we bring two modifications to tackle

231
00:08:03,440 --> 00:08:06,720
these two side effects um

232
00:08:06,720 --> 00:08:09,599
so it's pretty much one to one since uh

233
00:08:09,599 --> 00:08:10,960
the solutions we have

234
00:08:10,960 --> 00:08:14,240
do not interfere much uh so yeah the

235
00:08:14,240 --> 00:08:15,199
first thing we do

236
00:08:15,199 --> 00:08:18,240
is we sample uh the

237
00:08:18,240 --> 00:08:20,960
we are aiming for the the uniform

238
00:08:20,960 --> 00:08:23,039
distribution in the red hypercube

239
00:08:23,039 --> 00:08:25,759
and we sample in the blue cube on

240
00:08:25,759 --> 00:08:26,800
picture on the left

241
00:08:26,800 --> 00:08:29,360
which is a little bit wider and this is

242
00:08:29,360 --> 00:08:30,080
so

243
00:08:30,080 --> 00:08:33,360
the blue dot from the last picture

244
00:08:33,360 --> 00:08:35,440
has its parallel pipette completely

245
00:08:35,440 --> 00:08:36,559
within the

246
00:08:36,559 --> 00:08:40,080
continuous support

247
00:08:40,080 --> 00:08:43,039
okay now we run the samples just like

248
00:08:43,039 --> 00:08:44,480
before and we see that there are a lot

249
00:08:44,480 --> 00:08:44,800
of

250
00:08:44,800 --> 00:08:46,480
grinded problems around there because

251
00:08:46,480 --> 00:08:48,080
there's a lot of points outside of the

252
00:08:48,080 --> 00:08:49,360
red hypercube

253
00:08:49,360 --> 00:08:53,040
that are black big black dots

254
00:08:53,040 --> 00:08:55,120
and so what we do is we just discard

255
00:08:55,120 --> 00:08:56,160
them this is

256
00:08:56,160 --> 00:08:58,640
uh the last step the rejection sampling

257
00:08:58,640 --> 00:09:00,080
uh since they should have zero

258
00:09:00,080 --> 00:09:01,680
probability we just discard them

259
00:09:01,680 --> 00:09:04,320
and that's it now as you can see the

260
00:09:04,320 --> 00:09:06,399
support of the distribution is therefore

261
00:09:06,399 --> 00:09:08,480
the lattice intersected with the red

262
00:09:08,480 --> 00:09:09,920
hypercube

263
00:09:09,920 --> 00:09:13,440
and and all of these points their

264
00:09:13,440 --> 00:09:14,640
probability

265
00:09:14,640 --> 00:09:17,440
is the probability that uh the

266
00:09:17,440 --> 00:09:19,040
continuous sample

267
00:09:19,040 --> 00:09:22,480
was in the parallel pipette

268
00:09:22,480 --> 00:09:25,279
around this lattice point and therefore

269
00:09:25,279 --> 00:09:27,760
they all have the same and it's uniform

270
00:09:27,760 --> 00:09:31,600
and it's the distribution we wanted

271
00:09:31,600 --> 00:09:36,320
okay so now about the framework uh based

272
00:09:36,320 --> 00:09:37,920
on this example

273
00:09:37,920 --> 00:09:40,800
uh the the contribution of this

274
00:09:40,800 --> 00:09:41,440
framework

275
00:09:41,440 --> 00:09:44,880
is uh to generalize the the previous

276
00:09:44,880 --> 00:09:45,839
process

277
00:09:45,839 --> 00:09:48,240
uh on two components the first one being

278
00:09:48,240 --> 00:09:49,760
the rounding operation where we use the

279
00:09:49,760 --> 00:09:51,200
round off algorithm

280
00:09:51,200 --> 00:09:52,480
and the second one being target

281
00:09:52,480 --> 00:09:54,640
distribution okay

282
00:09:54,640 --> 00:09:57,839
so first the rounding operation

283
00:09:57,839 --> 00:10:01,680
how do we generalize it we introduce

284
00:10:01,680 --> 00:10:03,680
the following definition of regular

285
00:10:03,680 --> 00:10:06,079
algorithm so we say that some algorithm

286
00:10:06,079 --> 00:10:06,399
a

287
00:10:06,399 --> 00:10:09,680
is regular when a of x y is a of x

288
00:10:09,680 --> 00:10:12,880
plus y y outside of the argument if

289
00:10:12,880 --> 00:10:17,040
y is the last point so

290
00:10:17,279 --> 00:10:18,959
you may recognize that the random

291
00:10:18,959 --> 00:10:21,519
algorithm is a regular algorithm

292
00:10:21,519 --> 00:10:23,920
and there are other examples such as the

293
00:10:23,920 --> 00:10:24,720
nearest plane

294
00:10:24,720 --> 00:10:28,160
algorithm and any exact tdp solver

295
00:10:28,160 --> 00:10:31,200
so why why did this definition

296
00:10:31,200 --> 00:10:33,760
it's because we have the following uh

297
00:10:33,760 --> 00:10:35,680
interesting property

298
00:10:35,680 --> 00:10:39,040
for l regular algorithms

299
00:10:39,040 --> 00:10:41,200
that is if you define t to be at the

300
00:10:41,200 --> 00:10:42,399
preimage of zero

301
00:10:42,399 --> 00:10:45,040
by this algorithm and you take all the

302
00:10:45,040 --> 00:10:46,079
translations

303
00:10:46,079 --> 00:10:49,279
by lattice points of the style then you

304
00:10:49,279 --> 00:10:49,600
get

305
00:10:49,600 --> 00:10:52,560
a periodic tessellation of the space uh

306
00:10:52,560 --> 00:10:52,959
so

307
00:10:52,959 --> 00:10:55,920
i'll just take an example if you take

308
00:10:55,920 --> 00:10:57,519
the round off

309
00:10:57,519 --> 00:10:59,760
t is going to be the centered pipette

310
00:10:59,760 --> 00:11:01,600
spun by the bases

311
00:11:01,600 --> 00:11:04,800
and its translations is going to give

312
00:11:04,800 --> 00:11:07,519
the first picture here

313
00:11:07,519 --> 00:11:09,600
and so this covers the whole space and

314
00:11:09,600 --> 00:11:11,360
there's no intersection between the

315
00:11:11,360 --> 00:11:14,399
pipettes therefore it's desolation

316
00:11:14,399 --> 00:11:17,680
uh okay now the second picture is the

317
00:11:17,680 --> 00:11:19,600
tessellation induced by the nearest

318
00:11:19,600 --> 00:11:20,480
plane algorithm

319
00:11:20,480 --> 00:11:22,320
and the third picture is the

320
00:11:22,320 --> 00:11:24,320
tessellation induced by an exact tpp

321
00:11:24,320 --> 00:11:24,880
solver

322
00:11:24,880 --> 00:11:28,320
so known as the vornoi tessellation

323
00:11:28,320 --> 00:11:31,360
okay so this is what we wanted from the

324
00:11:31,360 --> 00:11:33,120
the rounding process for the first

325
00:11:33,120 --> 00:11:34,800
component and now we move on to the

326
00:11:34,800 --> 00:11:35,680
second

327
00:11:35,680 --> 00:11:38,480
component which is target distribution

328
00:11:38,480 --> 00:11:40,240
so

329
00:11:40,240 --> 00:11:43,279
we'll deal with the density of

330
00:11:43,279 --> 00:11:46,079
the target distribution by introducing

331
00:11:46,079 --> 00:11:47,600
square morning functions

332
00:11:47,600 --> 00:11:51,920
okay so we're given a prototype t

333
00:11:51,920 --> 00:11:55,519
and a function omega in our n

334
00:11:55,519 --> 00:11:59,360
from omega not n to r and we say that

335
00:11:59,360 --> 00:12:02,399
the function f is t square modic

336
00:12:02,399 --> 00:12:05,360
if when for all x for which this

337
00:12:05,360 --> 00:12:06,959
equation would make sense

338
00:12:06,959 --> 00:12:09,040
we have that the mean value of f over t

339
00:12:09,040 --> 00:12:10,320
plus x is f

340
00:12:10,320 --> 00:12:13,920
of x so in particular if you take x is

341
00:12:13,920 --> 00:12:14,480
zero

342
00:12:14,480 --> 00:12:17,120
the mean value of f over t is going to

343
00:12:17,120 --> 00:12:18,320
be f of zero

344
00:12:18,320 --> 00:12:20,320
and this should be true for any

345
00:12:20,320 --> 00:12:21,920
translation of

346
00:12:21,920 --> 00:12:25,600
uh of t okay

347
00:12:25,600 --> 00:12:29,440
so yeah this may remind the definition

348
00:12:29,440 --> 00:12:31,200
of harmonic function where

349
00:12:31,200 --> 00:12:33,519
uh harmonic functions are supposed to

350
00:12:33,519 --> 00:12:35,680
verify the min value property of our l2

351
00:12:35,680 --> 00:12:36,399
balls for

352
00:12:36,399 --> 00:12:39,920
any center any radius and

353
00:12:39,920 --> 00:12:44,000
yeah okay i'll just move on to

354
00:12:44,000 --> 00:12:46,720
an illustration of square ministy what

355
00:12:46,720 --> 00:12:48,480
it means geometrically

356
00:12:48,480 --> 00:12:51,600
so okay you have here two pictures of

357
00:12:51,600 --> 00:12:52,240
graphs

358
00:12:52,240 --> 00:12:56,000
of harmonic functions and as you can see

359
00:12:56,000 --> 00:12:58,880
um there the blue dot is lagging on the

360
00:12:58,880 --> 00:12:59,440
graph

361
00:12:59,440 --> 00:13:02,959
of the function and it takes a specific

362
00:13:02,959 --> 00:13:05,120
okay so the x and y coordinates of the

363
00:13:05,120 --> 00:13:06,720
blue dots

364
00:13:06,720 --> 00:13:10,240
is is invariant of the tile

365
00:13:10,240 --> 00:13:13,760
where the tile is the red square so

366
00:13:13,760 --> 00:13:16,880
the the mean value of the function over

367
00:13:16,880 --> 00:13:18,240
the red square

368
00:13:18,240 --> 00:13:21,360
is the z component of the blue dot and

369
00:13:21,360 --> 00:13:22,880
wherever you move around

370
00:13:22,880 --> 00:13:25,519
the red square it's always going to be

371
00:13:25,519 --> 00:13:26,639
uh the value of the

372
00:13:26,639 --> 00:13:28,560
the mean value of the function on the

373
00:13:28,560 --> 00:13:30,399
style is always going to be

374
00:13:30,399 --> 00:13:35,040
the z component of the blue dot okay

375
00:13:35,040 --> 00:13:38,880
so now i move on to

376
00:13:38,880 --> 00:13:41,839
some examples of square morning

377
00:13:41,839 --> 00:13:43,199
functions

378
00:13:43,199 --> 00:13:44,959
so first we have this very interesting

379
00:13:44,959 --> 00:13:47,199
property that follows from the linearity

380
00:13:47,199 --> 00:13:48,480
of the integral

381
00:13:48,480 --> 00:13:50,639
where the set of square morning

382
00:13:50,639 --> 00:13:51,839
functions for

383
00:13:51,839 --> 00:13:55,120
given productivity t is a vector space

384
00:13:55,120 --> 00:13:58,160
and this will be useful

385
00:13:58,959 --> 00:14:01,600
so examples the first example is quite

386
00:14:01,600 --> 00:14:02,079
trivial

387
00:14:02,079 --> 00:14:03,920
it's constant function since the mean

388
00:14:03,920 --> 00:14:05,680
value of a constant is a constant

389
00:14:05,680 --> 00:14:08,800
and the the value in a specific point is

390
00:14:08,800 --> 00:14:10,240
always constant

391
00:14:10,240 --> 00:14:12,720
so yeah this is quite a trivial example

392
00:14:12,720 --> 00:14:13,279
but it

393
00:14:13,279 --> 00:14:16,480
it it means that uh uniform

394
00:14:16,480 --> 00:14:17,360
distributions

395
00:14:17,360 --> 00:14:19,519
are squirmonic and this is the example i

396
00:14:19,519 --> 00:14:20,399
gave

397
00:14:20,399 --> 00:14:23,920
in the beginning so

398
00:14:23,920 --> 00:14:27,839
yeah um now i'll move on to the next

399
00:14:27,839 --> 00:14:30,639
example where we have linear forms that

400
00:14:30,639 --> 00:14:30,959
are

401
00:14:30,959 --> 00:14:35,680
this harmonic for any symmetrical tile

402
00:14:35,680 --> 00:14:38,560
which geometrically makes sense since

403
00:14:38,560 --> 00:14:39,279
its graph

404
00:14:39,279 --> 00:14:41,440
is a hyperplane and if you take the mean

405
00:14:41,440 --> 00:14:43,120
value over

406
00:14:43,120 --> 00:14:44,800
a symmetrical tile is going to be the

407
00:14:44,800 --> 00:14:46,480
the value in the middle of the tile and

408
00:14:46,480 --> 00:14:47,600
therefore

409
00:14:47,600 --> 00:14:50,800
this is going to be harmonic okay

410
00:14:50,800 --> 00:14:55,199
and as it's a vector space you can add

411
00:14:55,199 --> 00:14:56,959
a linear form and a constant function

412
00:14:56,959 --> 00:14:59,040
and you get the density of what we call

413
00:14:59,040 --> 00:15:01,600
a find of what we call a finite

414
00:15:01,600 --> 00:15:02,880
distributions

415
00:15:02,880 --> 00:15:06,240
okay the next two examples are not

416
00:15:06,240 --> 00:15:09,839
uh really geometrically meaningful

417
00:15:09,839 --> 00:15:12,160
so i'll just summarize we have four

418
00:15:12,160 --> 00:15:14,000
types of distributions that are square

419
00:15:14,000 --> 00:15:15,040
morning

420
00:15:15,040 --> 00:15:18,240
the constant functions which give

421
00:15:18,240 --> 00:15:19,360
uniform

422
00:15:19,360 --> 00:15:21,920
the affine distributions find product

423
00:15:21,920 --> 00:15:23,440
distribution and exponential

424
00:15:23,440 --> 00:15:24,880
distributions

425
00:15:24,880 --> 00:15:28,240
okay um so

426
00:15:28,240 --> 00:15:30,320
now i move on to describing the

427
00:15:30,320 --> 00:15:31,279
framework

428
00:15:31,279 --> 00:15:34,079
probably properly speaking so we have a

429
00:15:34,079 --> 00:15:36,240
lattice l an algorithm a

430
00:15:36,240 --> 00:15:40,639
a description tau of l

431
00:15:40,639 --> 00:15:43,920
uh yeah a distribution d of density f

432
00:15:43,920 --> 00:15:46,240
defined on a support omega prime

433
00:15:46,240 --> 00:15:48,560
omega subset of omega prime and finally

434
00:15:48,560 --> 00:15:50,240
we have a target vector c

435
00:15:50,240 --> 00:15:53,440
in space okay so

436
00:15:53,440 --> 00:15:55,920
the sampling goes as follows first you

437
00:15:55,920 --> 00:15:56,880
sample from

438
00:15:56,880 --> 00:15:59,040
the continuous distribution d which

439
00:15:59,040 --> 00:16:01,120
gives you a sample y

440
00:16:01,120 --> 00:16:04,959
then you round y plus c using

441
00:16:04,959 --> 00:16:07,120
the algorithm a which gives you some

442
00:16:07,120 --> 00:16:08,959
point x on the lattice

443
00:16:08,959 --> 00:16:11,279
and then there's the rejection sampling

444
00:16:11,279 --> 00:16:13,040
step where you reject

445
00:16:13,040 --> 00:16:16,800
x if x minus c is not in omega

446
00:16:16,800 --> 00:16:20,800
okay so and we have the following result

447
00:16:20,800 --> 00:16:23,279
which is if the four conditions listed

448
00:16:23,279 --> 00:16:24,800
here are verified

449
00:16:24,800 --> 00:16:28,000
then x follows the distribution uh

450
00:16:28,000 --> 00:16:31,120
d translated by c discretized on the

451
00:16:31,120 --> 00:16:32,079
lattice l

452
00:16:32,079 --> 00:16:33,920
and this is exactly what we were aiming

453
00:16:33,920 --> 00:16:37,279
for so yeah okay

454
00:16:37,279 --> 00:16:41,360
so yeah about the conditions now

455
00:16:41,360 --> 00:16:43,199
so the first condition basically says

456
00:16:43,199 --> 00:16:45,519
that you can sample from the and this is

457
00:16:45,519 --> 00:16:47,920
an obvious condition for the first step

458
00:16:47,920 --> 00:16:49,279
of the sampling

459
00:16:49,279 --> 00:16:52,800
so okay now the second condition is that

460
00:16:52,800 --> 00:16:56,000
a is l regular and it induces a

461
00:16:56,000 --> 00:16:58,800
dissolution of prototype t

462
00:16:58,800 --> 00:17:01,279
we ask that f is cheese harmonic for the

463
00:17:01,279 --> 00:17:02,240
third condition

464
00:17:02,240 --> 00:17:06,400
with t the prototype of a and

465
00:17:06,400 --> 00:17:09,039
so together the second and the third

466
00:17:09,039 --> 00:17:10,079
condition

467
00:17:10,079 --> 00:17:13,439
they ensure that the distribution d

468
00:17:13,439 --> 00:17:16,959
is such that the rounding of d

469
00:17:16,959 --> 00:17:19,599
waving hands the rounding of d is the

470
00:17:19,599 --> 00:17:20,000
same

471
00:17:20,000 --> 00:17:22,400
as the discretization of the where

472
00:17:22,400 --> 00:17:23,919
rounding is taken

473
00:17:23,919 --> 00:17:27,199
uh with respect to a

474
00:17:27,199 --> 00:17:29,760
and so this is pretty much the step

475
00:17:29,760 --> 00:17:30,880
where

476
00:17:30,880 --> 00:17:32,720
discrete gaussians didn't work out so

477
00:17:32,720 --> 00:17:33,919
well because

478
00:17:33,919 --> 00:17:37,039
uh they don't verify these uh things

479
00:17:37,039 --> 00:17:39,120
and therefore the something wasn't exact

480
00:17:39,120 --> 00:17:40,320
and yeah

481
00:17:40,320 --> 00:17:43,919
it didn't work out so well okay

482
00:17:43,919 --> 00:17:46,400
now the fourth step is that uh the

483
00:17:46,400 --> 00:17:48,480
fourth condition sorry is that we ask

484
00:17:48,480 --> 00:17:50,799
for omega plus t to be a subset of omega

485
00:17:50,799 --> 00:17:51,760
prime

486
00:17:51,760 --> 00:17:54,720
and yeah this is a condition that

487
00:17:54,720 --> 00:17:55,280
prevents

488
00:17:55,280 --> 00:17:58,559
the blue dot problem from happening

489
00:17:58,559 --> 00:18:01,440
since all the points within omega so the

490
00:18:01,440 --> 00:18:03,039
points that we want to sample from

491
00:18:03,039 --> 00:18:05,840
in the discrete uh in the discrete

492
00:18:05,840 --> 00:18:07,039
sampling

493
00:18:07,039 --> 00:18:11,120
um their tile of their polarity pipettes

494
00:18:11,120 --> 00:18:14,799
in the example is within the continuous

495
00:18:14,799 --> 00:18:16,240
support

496
00:18:16,240 --> 00:18:18,270
okay um

497
00:18:18,270 --> 00:18:19,440
[Music]

498
00:18:19,440 --> 00:18:21,919
so just a quick note about the rejection

499
00:18:21,919 --> 00:18:22,960
rate

500
00:18:22,960 --> 00:18:24,960
so there's a lot of information here but

501
00:18:24,960 --> 00:18:26,799
the main takeaway is that

502
00:18:26,799 --> 00:18:30,240
um you have a drawing on the left of

503
00:18:30,240 --> 00:18:33,280
what the so-called acceptance volume is

504
00:18:33,280 --> 00:18:34,640
and the acceptance rate is the

505
00:18:34,640 --> 00:18:36,320
probability of this

506
00:18:36,320 --> 00:18:39,840
thing for the continuous something

507
00:18:39,840 --> 00:18:41,360
and in the example i gave in the

508
00:18:41,360 --> 00:18:43,360
beginning this gives

509
00:18:43,360 --> 00:18:46,720
uh something like r to the n divided by

510
00:18:46,720 --> 00:18:51,360
r plus the the infinity norm of t

511
00:18:51,360 --> 00:18:53,520
to the n and this is going to be a

512
00:18:53,520 --> 00:18:54,640
constant for n

513
00:18:54,640 --> 00:18:58,000
proportional to n

514
00:18:58,000 --> 00:19:01,039
and to the infinite number of t infinity

515
00:19:01,039 --> 00:19:02,320
norm of t meaning that

516
00:19:02,320 --> 00:19:06,240
it's the maximum infinity norm

517
00:19:06,240 --> 00:19:11,600
of a vector in the in t okay

518
00:19:11,600 --> 00:19:14,880
so next slide is a table that summarizes

519
00:19:14,880 --> 00:19:17,440
the expected l2 norm for the

520
00:19:17,440 --> 00:19:18,960
instantiations

521
00:19:18,960 --> 00:19:22,080
so in rows you have

522
00:19:22,080 --> 00:19:25,200
regular algorithms in columns you have

523
00:19:25,200 --> 00:19:28,480
distributions um okay so

524
00:19:28,480 --> 00:19:31,200
there are a few things to notice here so

525
00:19:31,200 --> 00:19:33,280
first if you take the random algorithm

526
00:19:33,280 --> 00:19:36,480
the there's always going to be

527
00:19:36,480 --> 00:19:39,840
a factor uh s1 of b that is going to be

528
00:19:39,840 --> 00:19:42,799
uh the length of the basis factor for

529
00:19:42,799 --> 00:19:44,160
this algotherm

530
00:19:44,160 --> 00:19:47,039
algorithm sorry for the nearest plane

531
00:19:47,039 --> 00:19:48,880
it's going to be

532
00:19:48,880 --> 00:19:53,280
s1 of b tilde which is the gso of b

533
00:19:53,280 --> 00:19:55,360
and for the exact cvp it's going to be

534
00:19:55,360 --> 00:19:57,360
the covering radius

535
00:19:57,360 --> 00:20:01,120
okay now in columns

536
00:20:01,120 --> 00:20:05,120
very much as you can see all but one

537
00:20:05,120 --> 00:20:08,480
distributions have a factor n squared in

538
00:20:08,480 --> 00:20:10,000
front of the

539
00:20:10,000 --> 00:20:13,280
the size of the bases and

540
00:20:13,280 --> 00:20:17,280
yeah this is um this is much bigger than

541
00:20:17,280 --> 00:20:21,679
uh the gpv client sampler and bikeout

542
00:20:21,679 --> 00:20:24,480
sampler which had a root n factor

543
00:20:24,480 --> 00:20:27,760
um but this can somewhat be

544
00:20:27,760 --> 00:20:31,120
explained by the fact that

545
00:20:31,120 --> 00:20:34,720
we measure we measure the l2 norm

546
00:20:34,720 --> 00:20:37,120
of distributions that are more suited to

547
00:20:37,120 --> 00:20:38,080
different norms

548
00:20:38,080 --> 00:20:39,919
so for example if you take the l

549
00:20:39,919 --> 00:20:41,840
infinity norm

550
00:20:41,840 --> 00:20:45,360
of the infinity uniform uh

551
00:20:45,360 --> 00:20:47,520
something then you would get something

552
00:20:47,520 --> 00:20:49,200
like n to the one point five

553
00:20:49,200 --> 00:20:52,559
times s one of b or s one of b tilde

554
00:20:52,559 --> 00:20:55,679
and well this is still a factor n bigger

555
00:20:55,679 --> 00:20:56,320
but

556
00:20:56,320 --> 00:21:00,320
only a factor n uh bigger okay

557
00:21:00,320 --> 00:21:02,960
and uh yeah you would get something

558
00:21:02,960 --> 00:21:04,080
similar for

559
00:21:04,080 --> 00:21:06,320
all the instantiations here if you use

560
00:21:06,320 --> 00:21:07,840
the appropriate

561
00:21:07,840 --> 00:21:11,520
norm for measuring the output okay

562
00:21:11,520 --> 00:21:14,720
so there's a few open questions that

563
00:21:14,720 --> 00:21:17,760
this work lives

564
00:21:17,760 --> 00:21:20,960
so first about carbonicity so

565
00:21:20,960 --> 00:21:23,840
the question is given tile t what what

566
00:21:23,840 --> 00:21:25,760
are the solutions for f

567
00:21:25,760 --> 00:21:28,799
for the squamonic equation so we know

568
00:21:28,799 --> 00:21:30,880
that for harmonic functions

569
00:21:30,880 --> 00:21:34,320
uh which verify stronger

570
00:21:34,320 --> 00:21:38,080
uh hypothesis or like equation

571
00:21:38,080 --> 00:21:41,440
uh it's equivalent to uh location of f

572
00:21:41,440 --> 00:21:44,480
is zero and there's

573
00:21:44,480 --> 00:21:47,280
infinitely many harmonic functions and

574
00:21:47,280 --> 00:21:47,679
we

575
00:21:47,679 --> 00:21:51,760
wonder if uh there's infinitely many

576
00:21:51,760 --> 00:21:54,720
uh solutions infinitely many more or

577
00:21:54,720 --> 00:21:57,120
like more distributions to be sampled

578
00:21:57,120 --> 00:22:00,559
uh using this technique and yeah if we

579
00:22:00,559 --> 00:22:02,000
find more instant

580
00:22:02,000 --> 00:22:03,440
scrambling functions we find more

581
00:22:03,440 --> 00:22:05,679
instantiations and maybe

582
00:22:05,679 --> 00:22:07,600
there would be some improvement on the

583
00:22:07,600 --> 00:22:10,400
quality of the output

584
00:22:10,400 --> 00:22:13,840
uh yeah the the other uh

585
00:22:13,840 --> 00:22:16,880
thing the other open question

586
00:22:16,880 --> 00:22:20,480
is about the size of the output so

587
00:22:20,480 --> 00:22:22,080
as i said it's a main drawback of the

588
00:22:22,080 --> 00:22:24,080
sampler so the question is can we

589
00:22:24,080 --> 00:22:25,280
improve the size

590
00:22:25,280 --> 00:22:29,039
of the of the output um

591
00:22:29,039 --> 00:22:32,400
you could think that uh

592
00:22:32,400 --> 00:22:35,679
the of many ways to improve it actually

593
00:22:35,679 --> 00:22:38,480
so for example what you can do is uh

594
00:22:38,480 --> 00:22:39,760
when you build a mega prime

595
00:22:39,760 --> 00:22:42,320
you you know omega prime is just a

596
00:22:42,320 --> 00:22:42,880
thicker

597
00:22:42,880 --> 00:22:46,480
omega and maybe you can uh

598
00:22:46,480 --> 00:22:49,840
make it not as wide as we do

599
00:22:49,840 --> 00:22:52,400
in which case you would lose the exact

600
00:22:52,400 --> 00:22:54,000
sampling trait

601
00:22:54,000 --> 00:22:56,960
but you would improve uh the size of the

602
00:22:56,960 --> 00:22:57,760
output

603
00:22:57,760 --> 00:22:59,600
and there may be some trade-offs like

604
00:22:59,600 --> 00:23:01,039
that you can find

605
00:23:01,039 --> 00:23:04,000
to improve the the size of the output uh

606
00:23:04,000 --> 00:23:05,360
at a price

607
00:23:05,360 --> 00:23:08,480
okay so now finally to conclude

608
00:23:08,480 --> 00:23:10,640
why is this framework better than client

609
00:23:10,640 --> 00:23:11,600
bike at some player

610
00:23:11,600 --> 00:23:15,440
it's not uh better but it's different

611
00:23:15,440 --> 00:23:18,400
uh in a number of ways so for example by

612
00:23:18,400 --> 00:23:20,159
curtin klein sampler

613
00:23:20,159 --> 00:23:22,799
they sample from the distribution that

614
00:23:22,799 --> 00:23:23,520
is close to

615
00:23:23,520 --> 00:23:25,919
the discrete gaussian whereas we sample

616
00:23:25,919 --> 00:23:26,720
from

617
00:23:26,720 --> 00:23:29,600
uh exactly from various non-gaussian

618
00:23:29,600 --> 00:23:30,480
distributions

619
00:23:30,480 --> 00:23:34,159
instead um

620
00:23:34,159 --> 00:23:37,200
yeah and also uh whereas

621
00:23:37,200 --> 00:23:39,600
the gaussian distribution is suitable to

622
00:23:39,600 --> 00:23:40,720
the l2 norm

623
00:23:40,720 --> 00:23:43,679
we offer uh distributions that are

624
00:23:43,679 --> 00:23:45,360
suitable to

625
00:23:45,360 --> 00:23:49,200
different norms okay

626
00:23:49,200 --> 00:23:51,760
just a quick mention there's a way

627
00:23:51,760 --> 00:23:53,039
rather involved

628
00:23:53,039 --> 00:23:56,080
to sample from exactly from the discrete

629
00:23:56,080 --> 00:23:57,039
gaussian

630
00:23:57,039 --> 00:24:01,279
which i didn't mention before okay

631
00:24:01,919 --> 00:24:05,919
okay next the size of the output is

632
00:24:05,919 --> 00:24:09,760
a bigger than bigger for our sampler

633
00:24:09,760 --> 00:24:10,159
than

634
00:24:10,159 --> 00:24:13,360
the discrete gaussian counterparts

635
00:24:13,360 --> 00:24:17,600
and finally the client backer sampler

636
00:24:17,600 --> 00:24:18,320
they

637
00:24:18,320 --> 00:24:21,200
give a precision with trade-off so if

638
00:24:21,200 --> 00:24:21,520
you

639
00:24:21,520 --> 00:24:24,640
increase if you decrease the width

640
00:24:24,640 --> 00:24:26,799
you decrease the precision of the

641
00:24:26,799 --> 00:24:28,000
sampling

642
00:24:28,000 --> 00:24:30,880
and we offer a runtime width trade-off

643
00:24:30,880 --> 00:24:31,679
instead

644
00:24:31,679 --> 00:24:34,480
so you could sample from a very narrow

645
00:24:34,480 --> 00:24:37,200
distribution but you will take

646
00:24:37,200 --> 00:24:41,440
exponentially many time sample

647
00:24:41,440 --> 00:24:44,840
okay and that's about it thanks for

648
00:24:44,840 --> 00:24:46,400
watching and

649
00:24:46,400 --> 00:24:49,279
bye

