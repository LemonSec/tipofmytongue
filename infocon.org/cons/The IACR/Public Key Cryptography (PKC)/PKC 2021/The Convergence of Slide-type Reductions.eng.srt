1
00:00:00,160 --> 00:00:02,240
hi my name is michael and i'm going to

2
00:00:02,240 --> 00:00:04,400
talk about lettuce block reduction

3
00:00:04,400 --> 00:00:06,399
reduction algorithms are key to encrypt

4
00:00:06,399 --> 00:00:09,280
analysis especially but not limited to

5
00:00:09,280 --> 00:00:12,240
lattice-based cryptography so it is very

6
00:00:12,240 --> 00:00:13,679
important to understand what they can

7
00:00:13,679 --> 00:00:14,160
achieve

8
00:00:14,160 --> 00:00:17,359
both in theory and in practice the focus

9
00:00:17,359 --> 00:00:18,720
of this talk

10
00:00:18,720 --> 00:00:21,359
is a class of algorithms that we call

11
00:00:21,359 --> 00:00:23,199
slide type reductions

12
00:00:23,199 --> 00:00:24,880
that have so far been considered mostly

13
00:00:24,880 --> 00:00:26,400
of theoretical interest because they are

14
00:00:26,400 --> 00:00:29,039
not competitive in practice

15
00:00:29,039 --> 00:00:31,439
in our work we apply a more fine-grained

16
00:00:31,439 --> 00:00:32,800
analysis due to

17
00:00:32,800 --> 00:00:35,920
our puyol and steli from crypto 7 to

18
00:00:35,920 --> 00:00:37,520
this class of algorithms

19
00:00:37,520 --> 00:00:39,760
and this leads to some improved

20
00:00:39,760 --> 00:00:40,719
theoretical

21
00:00:40,719 --> 00:00:44,000
results in particular improved

22
00:00:44,000 --> 00:00:46,960
bounce on their running time but more

23
00:00:46,960 --> 00:00:48,239
importantly

24
00:00:48,239 --> 00:00:50,719
we discover a new trade-off between the

25
00:00:50,719 --> 00:00:51,600
running time and

26
00:00:51,600 --> 00:00:54,000
the output quality of these algorithms

27
00:00:54,000 --> 00:00:55,920
and this leads us to

28
00:00:55,920 --> 00:00:59,280
a variant that is actually quite

29
00:00:59,280 --> 00:01:01,840
competitive in practicing which we

30
00:01:01,840 --> 00:01:02,960
confirm by

31
00:01:02,960 --> 00:01:05,680
experiments and this is interesting

32
00:01:05,680 --> 00:01:06,720
because

33
00:01:06,720 --> 00:01:09,360
this this type of algorithm has some

34
00:01:09,360 --> 00:01:11,200
very nice features for example it is

35
00:01:11,200 --> 00:01:12,720
easy to parallelize

36
00:01:12,720 --> 00:01:15,040
and distribute which is a feature that

37
00:01:15,040 --> 00:01:16,720
other block reduction algorithms don't

38
00:01:16,720 --> 00:01:18,000
have

39
00:01:18,000 --> 00:01:19,600
and we also believe that there's some

40
00:01:19,600 --> 00:01:21,360
room or a lot of room for further

41
00:01:21,360 --> 00:01:22,640
improvement so

42
00:01:22,640 --> 00:01:24,400
this could lead to faster practical

43
00:01:24,400 --> 00:01:26,560
algorithms actually

44
00:01:26,560 --> 00:01:27,920
and now we're going to start with some

45
00:01:27,920 --> 00:01:30,400
background

46
00:01:30,640 --> 00:01:34,400
and that is a discrete subset of rn

47
00:01:34,400 --> 00:01:37,439
yeah i've depicted the letters in r2

48
00:01:37,439 --> 00:01:40,640
and lettuces have a number of

49
00:01:40,640 --> 00:01:43,280
hard problems associated to them and one

50
00:01:43,280 --> 00:01:44,640
of these hard problems

51
00:01:44,640 --> 00:01:47,680
is the so-called shortest vector problem

52
00:01:47,680 --> 00:01:50,880
and here the task is given the lattice

53
00:01:50,880 --> 00:01:52,000
to find

54
00:01:52,000 --> 00:01:53,759
the shortest non-zero vector in this

55
00:01:53,759 --> 00:01:55,040
lattice

56
00:01:55,040 --> 00:01:56,479
the length of the shortest non-zero

57
00:01:56,479 --> 00:01:59,119
vector is usually denoted by lambda one

58
00:01:59,119 --> 00:02:00,799
and called the first minimum

59
00:02:00,799 --> 00:02:02,640
the shortest vector problem is triple in

60
00:02:02,640 --> 00:02:04,320
dimension two

61
00:02:04,320 --> 00:02:07,200
but as dimensional increases it becomes

62
00:02:07,200 --> 00:02:08,479
harder and harder

63
00:02:08,479 --> 00:02:10,080
and all known algorithms have at least

64
00:02:10,080 --> 00:02:12,080
exponential running time in the

65
00:02:12,080 --> 00:02:14,080
dimension of the lattice and we don't

66
00:02:14,080 --> 00:02:15,760
expect that to change anytime soon

67
00:02:15,760 --> 00:02:16,319
because

68
00:02:16,319 --> 00:02:17,840
the shortest vector problem is actually

69
00:02:17,840 --> 00:02:19,440
np hard on

70
00:02:19,440 --> 00:02:21,920
randomized reductions an easy way to

71
00:02:21,920 --> 00:02:23,599
describe the lattice is by

72
00:02:23,599 --> 00:02:26,640
giving a basis and basis is

73
00:02:26,640 --> 00:02:28,319
a set of linearly independent vectors

74
00:02:28,319 --> 00:02:31,280
that you can think of as a matrix

75
00:02:31,280 --> 00:02:35,120
and these basis vectors they generate

76
00:02:35,120 --> 00:02:38,560
the lattice by means of integer linear

77
00:02:38,560 --> 00:02:39,440
combinations

78
00:02:39,440 --> 00:02:42,800
a basis is not unique in fact every

79
00:02:42,800 --> 00:02:44,560
lattice with dimension larger than one

80
00:02:44,560 --> 00:02:47,120
has infinitely many bases

81
00:02:47,120 --> 00:02:50,640
and for example the blue set of vectors

82
00:02:50,640 --> 00:02:53,920
is also the basis for the same lens

83
00:02:53,920 --> 00:02:56,640
and it turns out that some bases are you

84
00:02:56,640 --> 00:02:58,480
know better

85
00:02:58,480 --> 00:03:01,599
than others when it comes to sort of

86
00:03:01,599 --> 00:03:03,280
computational problems

87
00:03:03,280 --> 00:03:05,519
for example if a base is already

88
00:03:05,519 --> 00:03:06,959
includes the shortest non-zero vector

89
00:03:06,959 --> 00:03:08,400
well then the shortest vector problem is

90
00:03:08,400 --> 00:03:09,440
trivial

91
00:03:09,440 --> 00:03:11,920
to solve given zeit bases so the goal of

92
00:03:11,920 --> 00:03:13,360
lattice reduction

93
00:03:13,360 --> 00:03:15,519
is actually to turn bad bases into good

94
00:03:15,519 --> 00:03:17,360
bases

95
00:03:17,360 --> 00:03:21,200
and this requires a way though for us to

96
00:03:21,200 --> 00:03:23,440
quantify the quality of bases and this

97
00:03:23,440 --> 00:03:25,280
is what we're going to look at next

98
00:03:25,280 --> 00:03:29,519
and so consider a specific basis

99
00:03:29,519 --> 00:03:32,799
before we can start talking about how we

100
00:03:32,799 --> 00:03:35,360
quantify the quality of a basis

101
00:03:35,360 --> 00:03:37,440
we need the notion of a projected

102
00:03:37,440 --> 00:03:38,879
sub-block

103
00:03:38,879 --> 00:03:41,360
so consider a set of vectors of the

104
00:03:41,360 --> 00:03:43,040
bases

105
00:03:43,040 --> 00:03:46,480
inside this green block then

106
00:03:46,480 --> 00:03:48,640
we can take all preceding vectors which

107
00:03:48,640 --> 00:03:50,480
we call the head of the bases

108
00:03:50,480 --> 00:03:52,480
and we can project our the vectors in

109
00:03:52,480 --> 00:03:53,519
our green block

110
00:03:53,519 --> 00:03:56,000
orthogonally to the head of the bases

111
00:03:56,000 --> 00:03:57,840
and this gives us a projected subclock

112
00:03:57,840 --> 00:03:58,480
of the

113
00:03:58,480 --> 00:04:02,879
of the bases and these vectors in itself

114
00:04:02,879 --> 00:04:06,399
generate projected subletters

115
00:04:06,560 --> 00:04:08,799
and we can apply this process actually

116
00:04:08,799 --> 00:04:10,159
not only to blocks

117
00:04:10,159 --> 00:04:12,239
or vectors but also to single vectors to

118
00:04:12,239 --> 00:04:13,599
blocks of size one

119
00:04:13,599 --> 00:04:16,000
for example you can apply it to the

120
00:04:16,000 --> 00:04:16,720
first

121
00:04:16,720 --> 00:04:18,720
basis vector which gives it unchanged

122
00:04:18,720 --> 00:04:21,120
because there is no

123
00:04:21,120 --> 00:04:22,639
head of the basis and so there is no

124
00:04:22,639 --> 00:04:24,639
projection so

125
00:04:24,639 --> 00:04:27,680
the first vector remains unchanged but

126
00:04:27,680 --> 00:04:28,560
the second one

127
00:04:28,560 --> 00:04:33,440
changes and gives us a projected vector

128
00:04:33,440 --> 00:04:36,000
and we can continue doing this up to the

129
00:04:36,000 --> 00:04:38,000
last vector

130
00:04:38,000 --> 00:04:41,120
and this gives us a set of vectors

131
00:04:41,120 --> 00:04:43,600
which we call the gso vectors these are

132
00:04:43,600 --> 00:04:45,280
the common schmitt vectors because

133
00:04:45,280 --> 00:04:46,800
they are the result of the gram-schmidt

134
00:04:46,800 --> 00:04:48,479
authorization process

135
00:04:48,479 --> 00:04:51,840
now notice that the gram-schmidt vectors

136
00:04:51,840 --> 00:04:54,000
are not actually a basis of our lattice

137
00:04:54,000 --> 00:04:54,880
they're

138
00:04:54,880 --> 00:04:57,360
a separate matrix that is related to our

139
00:04:57,360 --> 00:04:58,560
basis

140
00:04:58,560 --> 00:05:01,919
but it's not a basis itself

141
00:05:01,919 --> 00:05:03,919
in order to quantify the quality of our

142
00:05:03,919 --> 00:05:05,840
basis we're going to

143
00:05:05,840 --> 00:05:09,199
look at the length of the gso vectors

144
00:05:09,199 --> 00:05:12,479
of our bases and we're going to

145
00:05:12,479 --> 00:05:13,680
take the length of these vectors and

146
00:05:13,680 --> 00:05:16,000
we're going to plot it

147
00:05:16,000 --> 00:05:19,039
against the index i

148
00:05:19,039 --> 00:05:21,440
and we're going to do so in a log scale

149
00:05:21,440 --> 00:05:23,600
and this gives us the shape of the bases

150
00:05:23,600 --> 00:05:24,639
and the shape is

151
00:05:24,639 --> 00:05:27,759
crucial for the quality of our bases in

152
00:05:27,759 --> 00:05:29,759
the rest of this talk we will focus on

153
00:05:29,759 --> 00:05:31,840
the shapes of bases and we'll represent

154
00:05:31,840 --> 00:05:35,520
bases by their shapes and we will also

155
00:05:35,520 --> 00:05:38,720
refer to subplots of such shapes

156
00:05:38,720 --> 00:05:40,639
and i want you to remember throughout

157
00:05:40,639 --> 00:05:42,639
this this talk

158
00:05:42,639 --> 00:05:44,880
that what i really mean by this is

159
00:05:44,880 --> 00:05:46,880
actually the corresponding projected

160
00:05:46,880 --> 00:05:47,759
sub-block

161
00:05:47,759 --> 00:05:49,440
in the corresponding basis the basis

162
00:05:49,440 --> 00:05:52,560
that is associated or represented by

163
00:05:52,560 --> 00:05:55,600
by the shape okay

164
00:05:55,600 --> 00:05:59,039
so let's focus on the shape of

165
00:05:59,039 --> 00:06:02,000
a basis so this shape is pretty typical

166
00:06:02,000 --> 00:06:02,639
for

167
00:06:02,639 --> 00:06:05,520
an input basis we might get into our

168
00:06:05,520 --> 00:06:07,199
algorithm

169
00:06:07,199 --> 00:06:10,240
and as you can see there is this

170
00:06:10,240 --> 00:06:13,759
this linear drop off and

171
00:06:13,759 --> 00:06:15,199
remember that we are plotting this in

172
00:06:15,199 --> 00:06:17,199
log scale so this actually corresponds

173
00:06:17,199 --> 00:06:18,000
to a

174
00:06:18,000 --> 00:06:19,919
exponential drop-off in the actual

175
00:06:19,919 --> 00:06:22,720
length of the gso vectors

176
00:06:22,720 --> 00:06:24,720
but this as i said this linear drop-off

177
00:06:24,720 --> 00:06:26,240
is pretty typical

178
00:06:26,240 --> 00:06:29,280
so we may approximate it with a line and

179
00:06:29,280 --> 00:06:30,560
so

180
00:06:30,560 --> 00:06:32,160
from now on i'm going to work with these

181
00:06:32,160 --> 00:06:34,000
idealized shapes of

182
00:06:34,000 --> 00:06:36,560
bases to get the ideas across in this

183
00:06:36,560 --> 00:06:37,840
talk

184
00:06:37,840 --> 00:06:40,400
so the area under the curve of such a

185
00:06:40,400 --> 00:06:41,520
shape

186
00:06:41,520 --> 00:06:44,319
is actually a lattice constant so any

187
00:06:44,319 --> 00:06:46,960
bases of this lattice will have the same

188
00:06:46,960 --> 00:06:49,840
area underneath this curve

189
00:06:50,639 --> 00:06:52,560
and since this linear drop-off is pretty

190
00:06:52,560 --> 00:06:54,479
typical for lettuce bases

191
00:06:54,479 --> 00:06:56,080
the goal of lattice reduction is

192
00:06:56,080 --> 00:06:58,000
actually to reduce the slope of this

193
00:06:58,000 --> 00:06:59,680
line

194
00:06:59,680 --> 00:07:03,039
and what that means we'll recall

195
00:07:03,039 --> 00:07:06,000
that the first vector of the gso of the

196
00:07:06,000 --> 00:07:08,240
jso vectors is actually a lattice vector

197
00:07:08,240 --> 00:07:10,479
right everything else is projected but

198
00:07:10,479 --> 00:07:12,160
the first vector is not

199
00:07:12,160 --> 00:07:13,840
so the first vector is actually a

200
00:07:13,840 --> 00:07:16,000
lattice vector and so that means if the

201
00:07:16,000 --> 00:07:17,680
slope is smaller of this line

202
00:07:17,680 --> 00:07:20,560
then also the first vector is relatively

203
00:07:20,560 --> 00:07:21,280
short

204
00:07:21,280 --> 00:07:23,039
now assume that we have an algorithm

205
00:07:23,039 --> 00:07:24,479
available

206
00:07:24,479 --> 00:07:26,800
that finds the shortest vector in a

207
00:07:26,800 --> 00:07:28,720
given lettuce

208
00:07:28,720 --> 00:07:31,680
again this is a hard problem but assume

209
00:07:31,680 --> 00:07:33,440
for now that we have such a

210
00:07:33,440 --> 00:07:36,479
algorithm available what can we do

211
00:07:36,479 --> 00:07:38,400
you should be able to convince yourself

212
00:07:38,400 --> 00:07:40,160
that you could come up with a basis that

213
00:07:40,160 --> 00:07:41,919
actually contains this shortest vector

214
00:07:41,919 --> 00:07:43,360
and let's say this vector is in the

215
00:07:43,360 --> 00:07:44,319
first place

216
00:07:44,319 --> 00:07:46,800
of the basis what does such a basis look

217
00:07:46,800 --> 00:07:48,319
like like what's its shape

218
00:07:48,319 --> 00:07:49,840
well it probably looks something like

219
00:07:49,840 --> 00:07:51,440
this

220
00:07:51,440 --> 00:07:53,759
now what we can also do is we can

221
00:07:53,759 --> 00:07:54,960
actually

222
00:07:54,960 --> 00:07:58,000
apply this algorithm also to the dual of

223
00:07:58,000 --> 00:07:59,680
our letters

224
00:07:59,680 --> 00:08:02,160
and you don't need to know what the dual

225
00:08:02,160 --> 00:08:05,280
is to understand this but

226
00:08:05,280 --> 00:08:08,319
what that will do effectively is will

227
00:08:08,319 --> 00:08:10,639
change the shape of our bases such that

228
00:08:10,639 --> 00:08:11,759
it looks like this

229
00:08:11,759 --> 00:08:13,680
so instead of minimizing the first

230
00:08:13,680 --> 00:08:15,440
vector of our basis

231
00:08:15,440 --> 00:08:17,840
what this application does it it is

232
00:08:17,840 --> 00:08:19,840
maximizing the last vector

233
00:08:19,840 --> 00:08:23,039
in our basis right but as i said

234
00:08:23,039 --> 00:08:24,639
solving the shortest vector problem in

235
00:08:24,639 --> 00:08:26,080
such a large dimension is actually

236
00:08:26,080 --> 00:08:27,360
pretty hard

237
00:08:27,360 --> 00:08:28,800
and we might not have enough time

238
00:08:28,800 --> 00:08:30,800
resources to do this

239
00:08:30,800 --> 00:08:34,479
so what we can do instead is we can

240
00:08:34,479 --> 00:08:37,679
apply such an operation to a projected

241
00:08:37,679 --> 00:08:38,320
sub-block

242
00:08:38,320 --> 00:08:41,360
of the basis right so we can

243
00:08:41,360 --> 00:08:44,480
for example pick out this block

244
00:08:44,480 --> 00:08:46,480
and then apply an svp oracle to the

245
00:08:46,480 --> 00:08:48,320
smaller dimensional lattice

246
00:08:48,320 --> 00:08:50,959
and this might turn the bases into a

247
00:08:50,959 --> 00:08:53,200
shape that looks like this

248
00:08:53,200 --> 00:08:57,519
and similarly if we apply the

249
00:08:58,320 --> 00:09:00,480
same operation in the dual and now the

250
00:09:00,480 --> 00:09:01,519
basic idea

251
00:09:01,519 --> 00:09:03,920
of block reduction is simply to apply

252
00:09:03,920 --> 00:09:05,839
these two operations

253
00:09:05,839 --> 00:09:08,800
in certain orders in order to improve

254
00:09:08,800 --> 00:09:09,680
the shape of the

255
00:09:09,680 --> 00:09:12,320
basis overall right like apply these

256
00:09:12,320 --> 00:09:13,920
this local operation

257
00:09:13,920 --> 00:09:17,440
to improve the basis globally and

258
00:09:17,440 --> 00:09:19,279
one of these reduction algorithms is

259
00:09:19,279 --> 00:09:20,839
what is called slide reduction

260
00:09:20,839 --> 00:09:23,839
then algorithm that was proposed by

261
00:09:23,839 --> 00:09:25,360
gamma and gwen in

262
00:09:25,360 --> 00:09:29,360
2008 and the basic idea

263
00:09:29,360 --> 00:09:31,360
is relatively simple so what we're going

264
00:09:31,360 --> 00:09:32,880
to do is we're going to

265
00:09:32,880 --> 00:09:37,839
apply the primal scp reduction

266
00:09:37,839 --> 00:09:39,200
to all the destroying blocks so we're

267
00:09:39,200 --> 00:09:41,040
going to break up the bases

268
00:09:41,040 --> 00:09:44,480
into you know a set of disjoint blocks

269
00:09:44,480 --> 00:09:46,080
and we're going to apply scp reduction

270
00:09:46,080 --> 00:09:50,160
to each of those in parallel

271
00:09:50,160 --> 00:09:51,839
and then the basis might look something

272
00:09:51,839 --> 00:09:53,760
like this

273
00:09:53,760 --> 00:09:56,959
and then as a next step we're going to

274
00:09:56,959 --> 00:10:00,000
apply the dual operation the dual

275
00:10:00,000 --> 00:10:03,600
sap operation to blocks that are shifted

276
00:10:03,600 --> 00:10:07,279
by one position so this gives us

277
00:10:07,279 --> 00:10:10,160
these pivot points right that these are

278
00:10:10,160 --> 00:10:10,800
the

279
00:10:10,800 --> 00:10:13,760
vectors that are in the first step

280
00:10:13,760 --> 00:10:15,519
they're minimized with respect to the

281
00:10:15,519 --> 00:10:17,040
block to the right

282
00:10:17,040 --> 00:10:19,279
and in the second step they are

283
00:10:19,279 --> 00:10:21,120
maximized with respect to the block on

284
00:10:21,120 --> 00:10:22,079
the left

285
00:10:22,079 --> 00:10:24,320
and then we're going to loop this over

286
00:10:24,320 --> 00:10:25,440
and over

287
00:10:25,440 --> 00:10:28,000
and as this happens information is

288
00:10:28,000 --> 00:10:29,760
transported from the right to the left

289
00:10:29,760 --> 00:10:31,839
to the basis

290
00:10:31,839 --> 00:10:34,000
through these pivot points let's have a

291
00:10:34,000 --> 00:10:36,000
look what this looks like in action

292
00:10:36,000 --> 00:10:38,640
so here i'm simulating an example of a

293
00:10:38,640 --> 00:10:40,480
rung of slight reduction on a lattice

294
00:10:40,480 --> 00:10:42,160
with dimension 300

295
00:10:42,160 --> 00:10:45,040
and block size 75 so this means we have

296
00:10:45,040 --> 00:10:48,160
four primer blocks and three dual blocks

297
00:10:48,160 --> 00:10:50,079
and as you can see the point on the left

298
00:10:50,079 --> 00:10:51,680
that represents the length of the first

299
00:10:51,680 --> 00:10:53,920
vector in the basis

300
00:10:53,920 --> 00:10:57,519
is creeping towards the red line it's

301
00:10:57,519 --> 00:10:59,440
gripping slowly but it's getting there

302
00:10:59,440 --> 00:11:01,920
and the red line actually represents

303
00:11:01,920 --> 00:11:04,079
the expected result for the length of

304
00:11:04,079 --> 00:11:06,240
this first vector

305
00:11:06,240 --> 00:11:08,480
now if we were to use larger blocks than

306
00:11:08,480 --> 00:11:09,839
75

307
00:11:09,839 --> 00:11:11,519
for example let's say 100 then we'd only

308
00:11:11,519 --> 00:11:13,120
have three blocks

309
00:11:13,120 --> 00:11:14,959
but then the red line would actually be

310
00:11:14,959 --> 00:11:16,640
lower so the output would actually be

311
00:11:16,640 --> 00:11:18,560
better the first vector would be shorter

312
00:11:18,560 --> 00:11:22,000
in this case but then each of the oracle

313
00:11:22,000 --> 00:11:23,200
calls would be

314
00:11:23,200 --> 00:11:25,600
much more expensive so that's a typical

315
00:11:25,600 --> 00:11:26,959
tradeoff that's provided by block

316
00:11:26,959 --> 00:11:27,760
reduction

317
00:11:27,760 --> 00:11:30,320
it's usually controlled by the size of

318
00:11:30,320 --> 00:11:31,360
these blocks

319
00:11:31,360 --> 00:11:33,040
to understand the improvement in this

320
00:11:33,040 --> 00:11:34,640
work let's have a look

321
00:11:34,640 --> 00:11:37,920
at our shape again our improvement

322
00:11:37,920 --> 00:11:39,839
was actually inspired by a recent

323
00:11:39,839 --> 00:11:41,680
observation made in

324
00:11:41,680 --> 00:11:45,120
the work of either erwild kushanova

325
00:11:45,120 --> 00:11:49,920
pathway stevens and eurocrypt19

326
00:11:49,920 --> 00:11:53,519
and what they observed is that

327
00:11:53,600 --> 00:11:57,040
our model for svp reduction of

328
00:11:57,040 --> 00:11:59,200
a block is actually pretty bad when

329
00:11:59,200 --> 00:12:01,600
using modern stp solvers

330
00:12:01,600 --> 00:12:03,600
so we modeled it in a following way

331
00:12:03,600 --> 00:12:05,519
right like we looked at this specific

332
00:12:05,519 --> 00:12:06,560
sub-block

333
00:12:06,560 --> 00:12:08,480
and we said well if we apply the svp

334
00:12:08,480 --> 00:12:10,399
reduction in this block

335
00:12:10,399 --> 00:12:11,440
as a result it's going to look like

336
00:12:11,440 --> 00:12:13,760
something like this but

337
00:12:13,760 --> 00:12:16,240
if you use modern svp solvers the

338
00:12:16,240 --> 00:12:17,200
observation

339
00:12:17,200 --> 00:12:20,320
in the aforementioned work was that

340
00:12:20,320 --> 00:12:23,680
what actually happens is closer to this

341
00:12:23,680 --> 00:12:25,440
this means that not only the first

342
00:12:25,440 --> 00:12:27,600
vector is reduced by the

343
00:12:27,600 --> 00:12:30,399
by the svp oracle but actually these

344
00:12:30,399 --> 00:12:32,160
modern solvers they reduce

345
00:12:32,160 --> 00:12:35,120
the entire head of the bases so the the

346
00:12:35,120 --> 00:12:36,480
left basis vectors

347
00:12:36,480 --> 00:12:38,639
and analogously for the dual svp

348
00:12:38,639 --> 00:12:39,600
reduction

349
00:12:39,600 --> 00:12:41,920
and in the aforementioned work of europe

350
00:12:41,920 --> 00:12:43,279
19

351
00:12:43,279 --> 00:12:45,279
this observation was used to skip

352
00:12:45,279 --> 00:12:46,639
certain computations

353
00:12:46,639 --> 00:12:48,639
because the blocks are overlapping there

354
00:12:48,639 --> 00:12:50,959
you can skip certain calls to the

355
00:12:50,959 --> 00:12:54,079
oracle this is not really applicable for

356
00:12:54,079 --> 00:12:55,279
slight reduction

357
00:12:55,279 --> 00:12:57,040
because the blocks are destroyed so we

358
00:12:57,040 --> 00:12:59,040
can't really take advantage in the same

359
00:12:59,040 --> 00:12:59,760
way

360
00:12:59,760 --> 00:13:01,360
and this destroyingness of the block is

361
00:13:01,360 --> 00:13:02,959
actually a nice feature right because we

362
00:13:02,959 --> 00:13:03,680
said that this

363
00:13:03,680 --> 00:13:06,079
allows slide reduction to be paralyzed

364
00:13:06,079 --> 00:13:07,360
and distributed

365
00:13:07,360 --> 00:13:10,480
very easily so we could try to take

366
00:13:10,480 --> 00:13:11,680
advantage of

367
00:13:11,680 --> 00:13:14,480
this observation in some other way so

368
00:13:14,480 --> 00:13:15,920
consider again

369
00:13:15,920 --> 00:13:19,279
the shape of the bases after applying

370
00:13:19,279 --> 00:13:21,120
the sap oracle to all these primary

371
00:13:21,120 --> 00:13:23,200
blocks so what the shape actually looks

372
00:13:23,200 --> 00:13:24,720
like is something like this

373
00:13:24,720 --> 00:13:27,839
if we take into account the our updated

374
00:13:27,839 --> 00:13:29,519
model of what happens after sap

375
00:13:29,519 --> 00:13:30,800
reduction

376
00:13:30,800 --> 00:13:35,440
and so now the natural idea here is

377
00:13:35,440 --> 00:13:37,279
to shift the dual blocks by more than

378
00:13:37,279 --> 00:13:39,279
one vector right we're going to apply

379
00:13:39,279 --> 00:13:40,399
the dual

380
00:13:40,399 --> 00:13:43,519
sap reduction by blocks shifted by

381
00:13:43,519 --> 00:13:45,360
a number of indices that is larger than

382
00:13:45,360 --> 00:13:47,199
one

383
00:13:47,199 --> 00:13:51,360
and the question now is is that better

384
00:13:51,360 --> 00:13:53,519
let's have a look at what this looks

385
00:13:53,519 --> 00:13:55,440
like in action

386
00:13:55,440 --> 00:13:58,800
so here's an example again with the same

387
00:13:58,800 --> 00:14:01,120
parameters as before

388
00:14:01,120 --> 00:14:02,880
but with a dual block shifted by 15

389
00:14:02,880 --> 00:14:05,440
instead of one and as you can see

390
00:14:05,440 --> 00:14:08,880
the algorithm converges much faster

391
00:14:08,880 --> 00:14:11,279
now if you if you look closely and paid

392
00:14:11,279 --> 00:14:12,639
attention very closely

393
00:14:12,639 --> 00:14:14,639
you might have noticed that the red line

394
00:14:14,639 --> 00:14:16,320
is now a little bit higher than the one

395
00:14:16,320 --> 00:14:17,440
before

396
00:14:17,440 --> 00:14:19,839
so what this means is that it looks like

397
00:14:19,839 --> 00:14:21,839
we have another tradeoff here between

398
00:14:21,839 --> 00:14:23,279
the output quality and the running time

399
00:14:23,279 --> 00:14:24,959
of the algorithm

400
00:14:24,959 --> 00:14:27,519
and the question now is can we analyze

401
00:14:27,519 --> 00:14:28,959
this to check if it's actually

402
00:14:28,959 --> 00:14:30,560
worthwhile

403
00:14:30,560 --> 00:14:33,120
and so this is a core technical

404
00:14:33,120 --> 00:14:34,560
contribution of this

405
00:14:34,560 --> 00:14:38,000
of this work so first

406
00:14:38,000 --> 00:14:41,040
i want to observe that the idea of using

407
00:14:41,040 --> 00:14:42,959
these larger overlaps is not entirely

408
00:14:42,959 --> 00:14:44,320
new

409
00:14:44,320 --> 00:14:47,519
actually in a work by lian gwen of 2014

410
00:14:47,519 --> 00:14:49,040
they introduced an algorithm called

411
00:14:49,040 --> 00:14:50,959
block rankin reduction

412
00:14:50,959 --> 00:14:53,199
which considers a slightly different

413
00:14:53,199 --> 00:14:56,480
problem and also uses a different oracle

414
00:14:56,480 --> 00:14:59,360
but structurally this algorithm is very

415
00:14:59,360 --> 00:15:00,240
similar

416
00:15:00,240 --> 00:15:02,399
to what we are considering here and we

417
00:15:02,399 --> 00:15:04,160
may exploit the similarity

418
00:15:04,160 --> 00:15:07,279
to reuse their results on the number of

419
00:15:07,279 --> 00:15:08,480
oracle calls

420
00:15:08,480 --> 00:15:10,079
so they proved the bound on the number

421
00:15:10,079 --> 00:15:12,000
of oracle calls which

422
00:15:12,000 --> 00:15:14,880
also holds for our setting here so let's

423
00:15:14,880 --> 00:15:15,600
see

424
00:15:15,600 --> 00:15:18,639
what they proved actually

425
00:15:18,720 --> 00:15:21,360
so if we consider the dimension of

426
00:15:21,360 --> 00:15:24,320
letters and denote by n

427
00:15:24,320 --> 00:15:26,720
and we're going to denote the block size

428
00:15:26,720 --> 00:15:29,040
by d

429
00:15:29,040 --> 00:15:32,000
and the overlap parameter by k the

430
00:15:32,000 --> 00:15:33,600
bounds that they proved on the number of

431
00:15:33,600 --> 00:15:34,880
oracle calls that the

432
00:15:34,880 --> 00:15:38,240
algorithm does before convergence

433
00:15:38,240 --> 00:15:43,839
is n to the 3 over d squared roughly

434
00:15:43,839 --> 00:15:45,440
now their goal was to show that this is

435
00:15:45,440 --> 00:15:47,680
polynomial which is clearly is

436
00:15:47,680 --> 00:15:50,079
so they were fine with this but for our

437
00:15:50,079 --> 00:15:51,120
setting

438
00:15:51,120 --> 00:15:52,880
it is unfortunate that this bound is

439
00:15:52,880 --> 00:15:54,639
independent of k

440
00:15:54,639 --> 00:15:57,920
with this overlap parameter because this

441
00:15:57,920 --> 00:16:00,399
prevents us from from analyzing the

442
00:16:00,399 --> 00:16:01,920
trade-off between the running time and

443
00:16:01,920 --> 00:16:03,440
the upper quality

444
00:16:03,440 --> 00:16:05,360
the reason why they don't have k in

445
00:16:05,360 --> 00:16:07,120
their in their bound is because

446
00:16:07,120 --> 00:16:09,040
they're using an analysis technique that

447
00:16:09,040 --> 00:16:10,160
is too coarse

448
00:16:10,160 --> 00:16:12,160
and so what we do is we apply the

449
00:16:12,160 --> 00:16:14,399
dynamical systems analysis which you can

450
00:16:14,399 --> 00:16:16,399
view as a more fine-grained version of

451
00:16:16,399 --> 00:16:17,680
the analysis

452
00:16:17,680 --> 00:16:20,160
they applied and the bound that we show

453
00:16:20,160 --> 00:16:22,079
through this analysis

454
00:16:22,079 --> 00:16:25,279
looks like this and here you will notice

455
00:16:25,279 --> 00:16:26,959
that for

456
00:16:26,959 --> 00:16:29,440
k equals 1 the bound effectively

457
00:16:29,440 --> 00:16:30,639
coincides

458
00:16:30,639 --> 00:16:33,040
now we also improve this bound with

459
00:16:33,040 --> 00:16:35,440
respect to some

460
00:16:35,440 --> 00:16:37,360
other parameters but we're going to

461
00:16:37,360 --> 00:16:39,839
ignore this for here

462
00:16:39,839 --> 00:16:41,519
but what i want you to focus on is that

463
00:16:41,519 --> 00:16:43,360
with increasing k

464
00:16:43,360 --> 00:16:46,320
our bond actually decreases and for k

465
00:16:46,320 --> 00:16:48,079
being linear in d

466
00:16:48,079 --> 00:16:51,360
we actually get a factor d

467
00:16:51,360 --> 00:16:53,759
improvement in the bond and this gives

468
00:16:53,759 --> 00:16:56,079
us our first set of results

469
00:16:56,079 --> 00:16:58,320
which is an improved running time bound

470
00:16:58,320 --> 00:16:59,920
for block ranking reduction

471
00:16:59,920 --> 00:17:02,560
now we can also analyze the output

472
00:17:02,560 --> 00:17:04,240
quality of our algorithm

473
00:17:04,240 --> 00:17:07,599
relatively easily unfortunately there is

474
00:17:07,599 --> 00:17:08,240
no

475
00:17:08,240 --> 00:17:09,919
nice formula that i could put here in

476
00:17:09,919 --> 00:17:11,839
slides

477
00:17:11,839 --> 00:17:13,359
that would give you an intuition of what

478
00:17:13,359 --> 00:17:15,199
this tradeoff looks like but we can

479
00:17:15,199 --> 00:17:17,039
evaluate it numerically

480
00:17:17,039 --> 00:17:19,919
and so what we can do now is we can

481
00:17:19,919 --> 00:17:20,959
compare

482
00:17:20,959 --> 00:17:22,720
the trade-offs that we gain by tweaking

483
00:17:22,720 --> 00:17:24,240
the parameter k

484
00:17:24,240 --> 00:17:27,679
with the trade-off we get by fixing k

485
00:17:27,679 --> 00:17:30,480
and only considering the block size

486
00:17:30,480 --> 00:17:33,360
and we do so by using a crude model for

487
00:17:33,360 --> 00:17:35,840
the running time of the svp solver

488
00:17:35,840 --> 00:17:39,360
and we do so on an example and in this

489
00:17:39,360 --> 00:17:40,960
example with a

490
00:17:40,960 --> 00:17:43,600
on a 270 dimensional basis with block

491
00:17:43,600 --> 00:17:44,640
size 90

492
00:17:44,640 --> 00:17:47,520
this shows that by tweaking the

493
00:17:47,520 --> 00:17:49,360
parameter k

494
00:17:49,360 --> 00:17:52,799
we can get a speed up a factor uh four

495
00:17:52,799 --> 00:17:56,160
over um the trade of purely achievable

496
00:17:56,160 --> 00:17:56,720
by

497
00:17:56,720 --> 00:17:58,720
speaking the block size in order to

498
00:17:58,720 --> 00:18:00,320
check if our analysis

499
00:18:00,320 --> 00:18:01,919
actually holds up also in practice we

500
00:18:01,919 --> 00:18:03,360
implemented the algorithm

501
00:18:03,360 --> 00:18:07,120
and we ran a set of experiments

502
00:18:07,120 --> 00:18:09,919
and here we see the results of one set

503
00:18:09,919 --> 00:18:12,160
of experiments so the y-axis describes

504
00:18:12,160 --> 00:18:14,720
the length of the first vector in the

505
00:18:14,720 --> 00:18:16,320
base so it's a measure of the output

506
00:18:16,320 --> 00:18:17,360
quality

507
00:18:17,360 --> 00:18:19,840
and on the x-axis we have the running

508
00:18:19,840 --> 00:18:20,960
time

509
00:18:20,960 --> 00:18:24,000
so each of these curves shows how the

510
00:18:24,000 --> 00:18:26,320
length of the first vector in the basis

511
00:18:26,320 --> 00:18:28,000
develops over time during the execution

512
00:18:28,000 --> 00:18:29,280
of the algorithm

513
00:18:29,280 --> 00:18:32,320
and we see indeed that for parameters k

514
00:18:32,320 --> 00:18:34,400
that are larger than one

515
00:18:34,400 --> 00:18:36,320
the algorithm actually converges faster

516
00:18:36,320 --> 00:18:39,039
so this seems to support

517
00:18:39,039 --> 00:18:42,640
our analysis and then also we wanted to

518
00:18:42,640 --> 00:18:44,559
compare this algorithm

519
00:18:44,559 --> 00:18:47,760
um to state-of-the-art lattice reduction

520
00:18:47,760 --> 00:18:48,799
algorithms

521
00:18:48,799 --> 00:18:52,320
and here our algorithm is the hkz slide

522
00:18:52,320 --> 00:18:53,200
algorithm

523
00:18:53,200 --> 00:18:54,640
is a solid line where we chose an

524
00:18:54,640 --> 00:18:56,000
overlap 10 because that seemed to

525
00:18:56,000 --> 00:18:58,640
perform best in the previous experiments

526
00:18:58,640 --> 00:19:00,240
and then we compared to several other

527
00:19:00,240 --> 00:19:02,720
algorithms and we see

528
00:19:02,720 --> 00:19:04,080
that while it's not clearly

529
00:19:04,080 --> 00:19:05,919
outperforming them yet

530
00:19:05,919 --> 00:19:08,400
it is clearly competitive and we believe

531
00:19:08,400 --> 00:19:09,440
that there's some

532
00:19:09,440 --> 00:19:11,360
room of improvement here because this

533
00:19:11,360 --> 00:19:13,280
was just like sort of a prototype first

534
00:19:13,280 --> 00:19:13,919
chart

535
00:19:13,919 --> 00:19:16,080
implementation where i think you can

536
00:19:16,080 --> 00:19:18,240
tweak the parameters a bit more

537
00:19:18,240 --> 00:19:19,919
to probably get some more performance

538
00:19:19,919 --> 00:19:22,320
out of them and also

539
00:19:22,320 --> 00:19:24,240
we have not considered so far as a

540
00:19:24,240 --> 00:19:26,480
problem of progressiveness which means

541
00:19:26,480 --> 00:19:26,799
that

542
00:19:26,799 --> 00:19:28,799
for other reduction algorithms it is a

543
00:19:28,799 --> 00:19:30,080
good idea

544
00:19:30,080 --> 00:19:33,280
to improve the basis bit by bit

545
00:19:33,280 --> 00:19:36,400
using increasingly aggressive parameters

546
00:19:36,400 --> 00:19:37,760
this is what's denoted here by

547
00:19:37,760 --> 00:19:39,840
progressive pkz we have not

548
00:19:39,840 --> 00:19:42,400
yet found a good way to apply this

549
00:19:42,400 --> 00:19:44,880
approach to our algorithm yet

550
00:19:44,880 --> 00:19:46,880
and but we believe this should be

551
00:19:46,880 --> 00:19:48,240
possible and

552
00:19:48,240 --> 00:19:50,880
if this is possible this should give a

553
00:19:50,880 --> 00:19:52,640
faster algorithm

554
00:19:52,640 --> 00:19:55,520
and also recall that our algorithm is

555
00:19:55,520 --> 00:19:57,280
easily distributed and parallelized

556
00:19:57,280 --> 00:19:58,640
that's not necessarily true for the

557
00:19:58,640 --> 00:20:01,200
competition and so with this

558
00:20:01,200 --> 00:20:02,720
i want to conclude this talk and thank

559
00:20:02,720 --> 00:20:06,240
you for your attention

