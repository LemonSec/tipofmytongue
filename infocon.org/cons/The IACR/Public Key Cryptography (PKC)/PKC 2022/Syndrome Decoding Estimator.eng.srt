1
00:00:00,399 --> 00:00:02,480
hi i'm andre and i'm going to present

2
00:00:02,480 --> 00:00:04,960
our paper syndrome decoding estimator

3
00:00:04,960 --> 00:00:06,879
which is joint work with emanuele

4
00:00:06,879 --> 00:00:08,400
bellini

5
00:00:08,400 --> 00:00:10,719
the standardization effort for post

6
00:00:10,719 --> 00:00:13,519
quantum secures cryptographic schemes

7
00:00:13,519 --> 00:00:15,280
is approaching the end of the third

8
00:00:15,280 --> 00:00:18,560
round and as we know this round will end

9
00:00:18,560 --> 00:00:20,880
with a selection of schemes to be

10
00:00:20,880 --> 00:00:22,080
standardized

11
00:00:22,080 --> 00:00:24,320
which makes it an increasingly important

12
00:00:24,320 --> 00:00:26,960
task to understand the

13
00:00:26,960 --> 00:00:30,640
exact security guarantees given by the

14
00:00:30,640 --> 00:00:32,880
proposed parameter sets

15
00:00:32,880 --> 00:00:34,960
since we want to standardize most

16
00:00:34,960 --> 00:00:37,360
efficient meaning the smallest parameter

17
00:00:37,360 --> 00:00:40,160
sets that actually achieve the desired

18
00:00:40,160 --> 00:00:42,079
security levels

19
00:00:42,079 --> 00:00:44,640
in this talk we focus on code-based

20
00:00:44,640 --> 00:00:45,920
schemes

21
00:00:45,920 --> 00:00:47,840
there are still three remaining in the

22
00:00:47,840 --> 00:00:49,840
third round that is classic mclees as

23
00:00:49,840 --> 00:00:53,120
one of the finalists and bike and hqc on

24
00:00:53,120 --> 00:00:55,680
the alternate list

25
00:00:55,680 --> 00:00:58,399
so the goal of this work is to

26
00:00:58,399 --> 00:01:01,760
establish precise security estimates

27
00:01:01,760 --> 00:01:04,080
for the parameter sets of these schemes

28
00:01:04,080 --> 00:01:06,320
under different metrics where these

29
00:01:06,320 --> 00:01:07,840
metrics

30
00:01:07,840 --> 00:01:09,600
especially target different memory

31
00:01:09,600 --> 00:01:11,760
models

32
00:01:11,760 --> 00:01:13,760
code based schemes are usually based on

33
00:01:13,760 --> 00:01:15,920
the hardness of the syndrome decoding

34
00:01:15,920 --> 00:01:16,799
problem

35
00:01:16,799 --> 00:01:18,720
which we define in a minute

36
00:01:18,720 --> 00:01:21,280
and the best known algorithms to attack

37
00:01:21,280 --> 00:01:23,520
this problem are

38
00:01:23,520 --> 00:01:25,759
information set decoding algorithms

39
00:01:25,759 --> 00:01:27,840
and the landscape of information set

40
00:01:27,840 --> 00:01:29,920
decoding algorithms is quite diverse

41
00:01:29,920 --> 00:01:31,840
meaning there are a lot of different

42
00:01:31,840 --> 00:01:33,759
algorithms of this class

43
00:01:33,759 --> 00:01:36,320
and this makes it a difficult task to

44
00:01:36,320 --> 00:01:37,920
estimate

45
00:01:37,920 --> 00:01:39,840
precisely the complexity of each of

46
00:01:39,840 --> 00:01:42,479
these algorithms to then find the

47
00:01:42,479 --> 00:01:44,640
minimum of all these estimates to

48
00:01:44,640 --> 00:01:45,680
finally

49
00:01:45,680 --> 00:01:47,360
derive the

50
00:01:47,360 --> 00:01:48,720
security guarantee of a proposed

51
00:01:48,720 --> 00:01:50,560
parameter set

52
00:01:50,560 --> 00:01:53,119
so in this work we observe relations

53
00:01:53,119 --> 00:01:56,399
between all major isd improvements

54
00:01:56,399 --> 00:01:59,040
which allows us to unify them in a kind

55
00:01:59,040 --> 00:02:01,280
of framework so we find that all of them

56
00:02:01,280 --> 00:02:03,840
are internally solving some kind of

57
00:02:03,840 --> 00:02:06,000
nearest neighbor routine or say nearest

58
00:02:06,000 --> 00:02:07,200
neighbor problem

59
00:02:07,200 --> 00:02:10,639
and their biggest difference is

60
00:02:10,639 --> 00:02:13,280
how they solve this problem so by

61
00:02:13,280 --> 00:02:15,680
substituting the routine used to solve

62
00:02:15,680 --> 00:02:18,080
this problem we obtain different

63
00:02:18,080 --> 00:02:20,000
the different formulas the different

64
00:02:20,000 --> 00:02:21,920
estimates for the complexities of these

65
00:02:21,920 --> 00:02:23,840
algorithms

66
00:02:23,840 --> 00:02:25,280
and we provide these

67
00:02:25,280 --> 00:02:28,160
these formulas in a tool called synonym

68
00:02:28,160 --> 00:02:29,840
decoding estimator

69
00:02:29,840 --> 00:02:32,080
written in python which allows to

70
00:02:32,080 --> 00:02:34,160
estimate the hardness of arbitrary

71
00:02:34,160 --> 00:02:35,280
instances

72
00:02:35,280 --> 00:02:38,160
and using this tool then we obtain

73
00:02:38,160 --> 00:02:40,480
precise security estimates for the

74
00:02:40,480 --> 00:02:42,800
different schemes

75
00:02:42,800 --> 00:02:45,360
the talk is structured as follows in the

76
00:02:45,360 --> 00:02:47,040
first half we will investigate this

77
00:02:47,040 --> 00:02:49,920
framework and see how the different isd

78
00:02:49,920 --> 00:02:52,800
algorithms fit into this and in the

79
00:02:52,800 --> 00:02:55,280
second half we will then talk about the

80
00:02:55,280 --> 00:02:58,159
different memory models and the precise

81
00:02:58,159 --> 00:03:00,720
or concrete security estimates

82
00:03:00,720 --> 00:03:03,040
so let us start with the definition of

83
00:03:03,040 --> 00:03:05,120
the synonym decoding problem

84
00:03:05,120 --> 00:03:06,640
so for the syndrome decoding problem

85
00:03:06,640 --> 00:03:09,040
we're given the parity check matrix of a

86
00:03:09,040 --> 00:03:10,480
code it's

87
00:03:10,480 --> 00:03:13,440
n minus k times n matrix and a syndrome

88
00:03:13,440 --> 00:03:16,000
s a vector of length n minus k

89
00:03:16,000 --> 00:03:17,519
and an

90
00:03:17,519 --> 00:03:19,519
integer omega

91
00:03:19,519 --> 00:03:22,000
so everything is binary here we are

92
00:03:22,000 --> 00:03:23,519
working in f2

93
00:03:23,519 --> 00:03:25,760
and we are asked to find an error vector

94
00:03:25,760 --> 00:03:28,159
e of length n which fulfills the

95
00:03:28,159 --> 00:03:31,599
identity h times e is equal to s and has

96
00:03:31,599 --> 00:03:33,920
a hemming weight of omega so meaning it

97
00:03:33,920 --> 00:03:36,959
has exactly omega coordinates equal to

98
00:03:36,959 --> 00:03:38,000
1.

99
00:03:38,000 --> 00:03:40,640
so visually we will represent this as

100
00:03:40,640 --> 00:03:44,400
follows h times e is equal to s

101
00:03:44,400 --> 00:03:47,440
and note that e is basically a selection

102
00:03:47,440 --> 00:03:49,120
of columns of h

103
00:03:49,120 --> 00:03:52,159
that sums to s

104
00:03:52,480 --> 00:03:54,720
before now diving into the details of

105
00:03:54,720 --> 00:03:56,799
the different isd algorithms

106
00:03:56,799 --> 00:03:59,519
let us make some basic observations so

107
00:03:59,519 --> 00:04:02,400
we can permute an instance by main and

108
00:04:02,400 --> 00:04:05,040
still maintain this identity here so

109
00:04:05,040 --> 00:04:07,280
this means we can permute the columns of

110
00:04:07,280 --> 00:04:09,519
the pretty check matrix as long as we

111
00:04:09,519 --> 00:04:12,080
apply a similar permutation to the error

112
00:04:12,080 --> 00:04:13,120
vector

113
00:04:13,120 --> 00:04:15,519
so this basically models the fact that

114
00:04:15,519 --> 00:04:18,079
we can multiply the parity check matrix

115
00:04:18,079 --> 00:04:20,238
by a permutation matrix from the right

116
00:04:20,238 --> 00:04:23,600
as long as we multiply the error vector

117
00:04:23,600 --> 00:04:26,639
by the inverse permutation from the left

118
00:04:26,639 --> 00:04:28,880
and this allows us to

119
00:04:28,880 --> 00:04:32,160
redistribute the weight of

120
00:04:32,160 --> 00:04:34,000
the weight of the error on the full

121
00:04:34,000 --> 00:04:36,320
coordinates so we can achieve a random

122
00:04:36,320 --> 00:04:39,520
weight distribution on e

123
00:04:40,080 --> 00:04:41,680
so now we have here our permuted

124
00:04:41,680 --> 00:04:43,280
instance and

125
00:04:43,280 --> 00:04:45,840
we can apply another transformation by

126
00:04:45,840 --> 00:04:48,560
still maintaining the identity that is

127
00:04:48,560 --> 00:04:50,960
we can multiply both sides with an

128
00:04:50,960 --> 00:04:53,040
invertible matrix

129
00:04:53,040 --> 00:04:55,520
and we can try craft this matrix such

130
00:04:55,520 --> 00:04:58,639
that we diagonalize the left part the

131
00:04:58,639 --> 00:05:01,360
left n minus k times n minus k

132
00:05:01,360 --> 00:05:04,960
sub matrix of the parity check matrix

133
00:05:04,960 --> 00:05:07,520
and of course this changes the syndrome

134
00:05:07,520 --> 00:05:11,520
but we maintain the identity

135
00:05:11,520 --> 00:05:13,440
and as i said the

136
00:05:13,440 --> 00:05:16,000
permutation allows to redistribute the

137
00:05:16,000 --> 00:05:18,080
weight on the error so in the following

138
00:05:18,080 --> 00:05:20,080
we will assume that this permutation

139
00:05:20,080 --> 00:05:22,560
distributes the weight such such that we

140
00:05:22,560 --> 00:05:25,440
have a weight omega minus p on the first

141
00:05:25,440 --> 00:05:28,240
part of the error and weight p on the

142
00:05:28,240 --> 00:05:29,680
second part

143
00:05:29,680 --> 00:05:32,560
where p is an optimization parameter of

144
00:05:32,560 --> 00:05:34,560
the algorithm

145
00:05:34,560 --> 00:05:37,440
and we can write this identity as h

146
00:05:37,440 --> 00:05:40,560
prime times e2 is equal to s prime plus

147
00:05:40,560 --> 00:05:42,400
e1

148
00:05:42,400 --> 00:05:44,320
and note that the error weight in

149
00:05:44,320 --> 00:05:46,639
general is small compared to the length

150
00:05:46,639 --> 00:05:48,000
of the vector so

151
00:05:48,000 --> 00:05:51,680
so e is a is a small weight vector

152
00:05:51,680 --> 00:05:54,960
meaning that this identity here is

153
00:05:54,960 --> 00:05:57,840
we can somehow define an approximate

154
00:05:57,840 --> 00:06:00,720
identity between h prime times e2 and s

155
00:06:00,720 --> 00:06:03,360
prime approximate in the sense that it

156
00:06:03,360 --> 00:06:06,639
is holds up to the addition of e1 but e1

157
00:06:06,639 --> 00:06:09,199
is small

158
00:06:09,199 --> 00:06:11,039
or of low hemi weight

159
00:06:11,039 --> 00:06:13,919
and isd algorithms then work in a

160
00:06:13,919 --> 00:06:15,840
quite similar fashion

161
00:06:15,840 --> 00:06:17,280
so all algorithms work in a quite

162
00:06:17,280 --> 00:06:20,080
similar fashion they first permute the

163
00:06:20,080 --> 00:06:22,000
instance to redistribute the error

164
00:06:22,000 --> 00:06:25,120
weight hoping for weight p on e2 then

165
00:06:25,120 --> 00:06:27,199
they apply the gaussian elimination to

166
00:06:27,199 --> 00:06:29,680
diagonalize the left part of the matrix

167
00:06:29,680 --> 00:06:32,639
and finally they try to solve this

168
00:06:32,639 --> 00:06:34,400
almost identity

169
00:06:34,400 --> 00:06:37,039
so finding an e2 such that

170
00:06:37,039 --> 00:06:39,759
h prime times e2 is

171
00:06:39,759 --> 00:06:42,479
close to s prime

172
00:06:42,479 --> 00:06:43,360
and

173
00:06:43,360 --> 00:06:44,560
note that

174
00:06:44,560 --> 00:06:46,800
the optimization parameter p

175
00:06:46,800 --> 00:06:50,080
allows to shift either more or less work

176
00:06:50,080 --> 00:06:52,720
into this third step so by

177
00:06:52,720 --> 00:06:55,199
so for example for p equal to zero this

178
00:06:55,199 --> 00:06:56,800
search step becomes trivial because

179
00:06:56,800 --> 00:06:59,199
there's only one possibility

180
00:06:59,199 --> 00:07:00,240
to check

181
00:07:00,240 --> 00:07:03,120
but the higher p gets the

182
00:07:03,120 --> 00:07:06,400
more costly the search for e2 becomes

183
00:07:06,400 --> 00:07:08,960
but on the other hand the more

184
00:07:08,960 --> 00:07:11,680
weight we shift into e2 the

185
00:07:11,680 --> 00:07:13,599
more likely it becomes that we permute

186
00:07:13,599 --> 00:07:16,080
the aero weight as desired so should the

187
00:07:16,080 --> 00:07:19,759
third step not result in a solution the

188
00:07:19,759 --> 00:07:22,240
algorithm starts over with step one so a

189
00:07:22,240 --> 00:07:24,720
new permutation because

190
00:07:24,720 --> 00:07:25,440
it

191
00:07:25,440 --> 00:07:27,120
the permutation did not distribute

192
00:07:27,120 --> 00:07:29,599
weight p on e2

193
00:07:29,599 --> 00:07:31,520
now let us look into different isd

194
00:07:31,520 --> 00:07:34,160
algorithms and how they approach this

195
00:07:34,160 --> 00:07:36,240
third step

196
00:07:36,240 --> 00:07:38,560
so here we will skip the

197
00:07:38,560 --> 00:07:40,880
original isd algorithm by panga which

198
00:07:40,880 --> 00:07:43,120
basically chooses p equal to zero and

199
00:07:43,120 --> 00:07:45,199
dive directly into the improvements made

200
00:07:45,199 --> 00:07:48,800
by stern and duma

201
00:07:48,800 --> 00:07:50,800
so here we have the identity h prime

202
00:07:50,800 --> 00:07:53,280
times e2 equal to s prime plus e1

203
00:07:53,280 --> 00:07:54,560
visualized

204
00:07:54,560 --> 00:07:56,720
and both algorithms so one by stern it's

205
00:07:56,720 --> 00:08:00,160
one by dumeir start by splitting e2 in a

206
00:08:00,160 --> 00:08:02,000
meet in the middle fashion so they split

207
00:08:02,000 --> 00:08:04,800
e2 and two vectors where the first one

208
00:08:04,800 --> 00:08:06,639
has weight only on the first half and

209
00:08:06,639 --> 00:08:08,560
the second one only on the second half

210
00:08:08,560 --> 00:08:10,400
and together they form a vector of

211
00:08:10,400 --> 00:08:14,240
weight p now we label both parts of the

212
00:08:14,240 --> 00:08:17,120
vectors with x and y accordingly

213
00:08:17,120 --> 00:08:19,440
and then by splitting the matrix in the

214
00:08:19,440 --> 00:08:22,080
same fashion we can move the dependence

215
00:08:22,080 --> 00:08:24,319
of x and y on different sides of the

216
00:08:24,319 --> 00:08:26,080
equation

217
00:08:26,080 --> 00:08:28,000
and this allows us then to create two

218
00:08:28,000 --> 00:08:31,440
lists one containing h1 times x for all

219
00:08:31,440 --> 00:08:33,120
possible choices of x

220
00:08:33,120 --> 00:08:35,679
and another list of

221
00:08:35,679 --> 00:08:39,679
containing h 2 times y plus s prime for

222
00:08:39,679 --> 00:08:41,839
all possible choices of y

223
00:08:41,839 --> 00:08:44,240
and now we can find e2

224
00:08:44,240 --> 00:08:47,120
by finding actually e1 close pairs

225
00:08:47,120 --> 00:08:49,200
between those lists

226
00:08:49,200 --> 00:08:51,600
and this means we are basically

227
00:08:51,600 --> 00:08:53,760
interested in finding close pairs

228
00:08:53,760 --> 00:08:56,080
between those lists which are nearest

229
00:08:56,080 --> 00:08:57,200
neighbor

230
00:08:57,200 --> 00:09:00,320
which is the nearest neighbor problem

231
00:09:00,320 --> 00:09:03,680
so now both algorithms do not solve the

232
00:09:03,680 --> 00:09:05,519
nearest neighbor problem directly on all

233
00:09:05,519 --> 00:09:08,560
coordinates they work on a projection of

234
00:09:08,560 --> 00:09:10,560
coordinates so for example let us take

235
00:09:10,560 --> 00:09:13,360
the last l coordinates of of the vectors

236
00:09:13,360 --> 00:09:14,720
and

237
00:09:14,720 --> 00:09:16,880
then try to solve the nearest neighbor

238
00:09:16,880 --> 00:09:19,519
problem on these coordinates and finally

239
00:09:19,519 --> 00:09:22,880
checking if for the found solutions the

240
00:09:22,880 --> 00:09:24,800
they are short on on

241
00:09:24,800 --> 00:09:27,600
overall on all coordinates

242
00:09:27,600 --> 00:09:30,399
so the algorithm by stern now simply

243
00:09:30,399 --> 00:09:33,279
assumes that for the chosen projection

244
00:09:33,279 --> 00:09:36,320
the weight of e1 is 0 so e1 is 0 on the

245
00:09:36,320 --> 00:09:37,680
chosen projection

246
00:09:37,680 --> 00:09:41,200
this then allows to perform a simple

247
00:09:41,200 --> 00:09:43,600
search for equality on this projection

248
00:09:43,600 --> 00:09:45,920
between both lists

249
00:09:45,920 --> 00:09:48,959
and for all matching pairs it then

250
00:09:48,959 --> 00:09:50,640
checks if

251
00:09:50,640 --> 00:09:53,200
the sum is short on the remaining

252
00:09:53,200 --> 00:09:54,640
coordinates

253
00:09:54,640 --> 00:09:57,839
and of course we we do not know if this

254
00:09:57,839 --> 00:10:00,320
if the projection of e1 is zero so we

255
00:10:00,320 --> 00:10:02,079
have to repeat this

256
00:10:02,079 --> 00:10:05,279
procedure for several projections until

257
00:10:05,279 --> 00:10:08,320
we might assume that one of them

258
00:10:08,320 --> 00:10:10,480
does for one of them is the whole set

259
00:10:10,480 --> 00:10:13,279
e1 the weight of e1 is zero

260
00:10:13,279 --> 00:10:15,200
and

261
00:10:15,200 --> 00:10:17,120
some of you might have noticed that this

262
00:10:17,120 --> 00:10:20,000
procedure of finding

263
00:10:20,000 --> 00:10:22,399
near elements between two lists by

264
00:10:22,399 --> 00:10:25,040
projecting them to random coordinates

265
00:10:25,040 --> 00:10:26,480
and searching for equality on these

266
00:10:26,480 --> 00:10:29,519
coordinates is actually known as a

267
00:10:29,519 --> 00:10:32,160
procedure called index modvani locality

268
00:10:32,160 --> 00:10:35,200
sensitive hashing so stern's algorithm

269
00:10:35,200 --> 00:10:38,000
is solving this nearest neighbor problem

270
00:10:38,000 --> 00:10:40,640
by using indic mathwani

271
00:10:40,640 --> 00:10:43,200
nearest neighbor search

272
00:10:43,200 --> 00:10:45,279
so now the mers algorithm differentiates

273
00:10:45,279 --> 00:10:47,200
in the way it solves this problem so it

274
00:10:47,200 --> 00:10:49,360
does not no longer assume that

275
00:10:49,360 --> 00:10:52,000
e1 is zero on this projection but it has

276
00:10:52,000 --> 00:10:53,920
some weight on this projection

277
00:10:53,920 --> 00:10:55,360
and of course we cannot search for

278
00:10:55,360 --> 00:10:58,079
equality anymore because the identity

279
00:10:58,079 --> 00:11:00,959
now depends on e1 again and we did not

280
00:11:00,959 --> 00:11:02,800
account for this

281
00:11:02,800 --> 00:11:05,680
now the algorithm splits the weight on

282
00:11:05,680 --> 00:11:08,240
the projection of e1 again in a meet in

283
00:11:08,240 --> 00:11:10,560
the middle fashion similar to

284
00:11:10,560 --> 00:11:12,959
how we split e2 and x and y

285
00:11:12,959 --> 00:11:14,560
and moves one of these parts to the

286
00:11:14,560 --> 00:11:16,399
other side of the equation

287
00:11:16,399 --> 00:11:18,800
this then allows to not only perform a

288
00:11:18,800 --> 00:11:20,800
meet in the middle on e2 but also on the

289
00:11:20,800 --> 00:11:21,760
difference

290
00:11:21,760 --> 00:11:24,560
meaning we do not only enumerate x in

291
00:11:24,560 --> 00:11:27,120
the list but x and the difference and y

292
00:11:27,120 --> 00:11:29,600
and the difference respectively

293
00:11:29,600 --> 00:11:31,600
and this of course increases the lists

294
00:11:31,600 --> 00:11:32,560
but

295
00:11:32,560 --> 00:11:35,200
we also can search for equality on this

296
00:11:35,200 --> 00:11:36,959
projection again

297
00:11:36,959 --> 00:11:38,800
so this is basically a meet in the

298
00:11:38,800 --> 00:11:40,959
middle algorithm for solving nearest

299
00:11:40,959 --> 00:11:43,279
neighbor the nearest neighbor problem

300
00:11:43,279 --> 00:11:45,120
which is how the mayor solves this

301
00:11:45,120 --> 00:11:47,680
nearest neighbor problem

302
00:11:47,680 --> 00:11:50,320
next let us investigate how

303
00:11:50,320 --> 00:11:53,200
most recent isd improvements work and

304
00:11:53,200 --> 00:11:54,720
how they employ

305
00:11:54,720 --> 00:11:57,839
nearest neighbor search

306
00:11:58,560 --> 00:12:01,760
so most recent isd improvements usually

307
00:12:01,760 --> 00:12:05,519
split e2 not only in two but in four or

308
00:12:05,519 --> 00:12:07,440
even more add-ins

309
00:12:07,440 --> 00:12:09,680
and we find that for the cryptographic

310
00:12:09,680 --> 00:12:13,120
setting four add-ins is almost splitting

311
00:12:13,120 --> 00:12:15,200
into four add-ins is almost always

312
00:12:15,200 --> 00:12:18,240
optimal so let us stay with four for the

313
00:12:18,240 --> 00:12:19,600
moment

314
00:12:19,600 --> 00:12:21,760
and then the algorithm again similar to

315
00:12:21,760 --> 00:12:22,720
the

316
00:12:22,720 --> 00:12:26,240
algorithms by stern and dumair

317
00:12:26,240 --> 00:12:28,639
create multiple lists here containing h

318
00:12:28,639 --> 00:12:31,600
prime times x i and adding the s prime

319
00:12:31,600 --> 00:12:34,240
to the last list so that they are now

320
00:12:34,240 --> 00:12:36,800
needs or they are now searching for one

321
00:12:36,800 --> 00:12:38,399
element from each list

322
00:12:38,399 --> 00:12:39,680
which

323
00:12:39,680 --> 00:12:41,600
such that they sum together to something

324
00:12:41,600 --> 00:12:43,120
that is small

325
00:12:43,120 --> 00:12:45,360
and they

326
00:12:45,360 --> 00:12:47,120
find these elements by combining two

327
00:12:47,120 --> 00:12:48,399
lists at a time

328
00:12:48,399 --> 00:12:50,720
and first again on a projection

329
00:12:50,720 --> 00:12:52,800
searching for some vectors which are

330
00:12:52,800 --> 00:12:54,560
close

331
00:12:54,560 --> 00:12:56,639
or add up to something small

332
00:12:56,639 --> 00:12:59,519
and then in a final step they search for

333
00:12:59,519 --> 00:13:02,560
vectors that are small on the

334
00:13:02,560 --> 00:13:04,959
the other coordinates and as they were

335
00:13:04,959 --> 00:13:06,800
already small in the projection they

336
00:13:06,800 --> 00:13:08,639
will add up to something that stays

337
00:13:08,639 --> 00:13:10,880
somehow small

338
00:13:10,880 --> 00:13:13,360
and of course to create those lists the

339
00:13:13,360 --> 00:13:15,360
algorithms need to

340
00:13:15,360 --> 00:13:16,480
employ

341
00:13:16,480 --> 00:13:19,760
nearest neighbor search algorithms again

342
00:13:19,760 --> 00:13:22,079
we find that by

343
00:13:22,079 --> 00:13:24,399
using the kind of meet in the middle

344
00:13:24,399 --> 00:13:26,880
technique to solve this nearest neighbor

345
00:13:26,880 --> 00:13:28,800
sub this neighbors nearest neighbor

346
00:13:28,800 --> 00:13:30,160
problems

347
00:13:30,160 --> 00:13:33,360
we obtain variance of the improvements

348
00:13:33,360 --> 00:13:35,600
known as mmt and bjm

349
00:13:35,600 --> 00:13:37,920
named after their inventors maimoire and

350
00:13:37,920 --> 00:13:42,320
tumer and becca maimoiro

351
00:13:42,320 --> 00:13:46,480
and now by substituting these

352
00:13:46,480 --> 00:13:48,639
subroutines for nearest neighbor search

353
00:13:48,639 --> 00:13:51,199
we obtain different isd algorithms for

354
00:13:51,199 --> 00:13:52,399
example by

355
00:13:52,399 --> 00:13:54,240
if we exchange the

356
00:13:54,240 --> 00:13:55,760
meet in the middle strategy on the last

357
00:13:55,760 --> 00:13:58,639
level by

358
00:13:58,639 --> 00:14:00,959
a nearest neighbor technique by maya and

359
00:14:00,959 --> 00:14:03,519
otsurov we obtain an isd algorithm

360
00:14:03,519 --> 00:14:06,079
similarly known as myotzorov isd

361
00:14:06,079 --> 00:14:07,360
algorithm

362
00:14:07,360 --> 00:14:08,959
unfortunately the nearest neighbor

363
00:14:08,959 --> 00:14:11,839
search technique by mayan otsurov is

364
00:14:11,839 --> 00:14:14,560
not very practical so it inherits huge

365
00:14:14,560 --> 00:14:17,040
polynomial overheads such that in our

366
00:14:17,040 --> 00:14:19,600
practical considerations we exchanged it

367
00:14:19,600 --> 00:14:21,839
by the indic modvani

368
00:14:21,839 --> 00:14:23,120
procedure

369
00:14:23,120 --> 00:14:25,120
which gives the first practical variant

370
00:14:25,120 --> 00:14:27,920
of the myoth algorithm

371
00:14:27,920 --> 00:14:28,800
and

372
00:14:28,800 --> 00:14:31,279
now by exchanging the subroutines on

373
00:14:31,279 --> 00:14:33,360
both levels by the nearest neighbor

374
00:14:33,360 --> 00:14:35,760
search technique from maya and otsurov

375
00:14:35,760 --> 00:14:37,760
we obtain an improvement made by bose

376
00:14:37,760 --> 00:14:39,279
and mai

377
00:14:39,279 --> 00:14:41,839
again since my author of nearest

378
00:14:41,839 --> 00:14:43,680
neighbor search does not yield good

379
00:14:43,680 --> 00:14:46,160
practical complexities we exchange it by

380
00:14:46,160 --> 00:14:49,920
the iniqu modvani variant

381
00:14:50,160 --> 00:14:52,399
so this gives a simple framework to

382
00:14:52,399 --> 00:14:55,279
determine the practical complexity of

383
00:14:55,279 --> 00:14:57,199
different isd algorithms

384
00:14:57,199 --> 00:14:59,440
of course the time complexity formula

385
00:14:59,440 --> 00:15:02,160
shown here is further simplified but it

386
00:15:02,160 --> 00:15:03,760
boils down to the

387
00:15:03,760 --> 00:15:06,399
number of permutations needed to ensure

388
00:15:06,399 --> 00:15:09,040
the correct weight distribution times

389
00:15:09,040 --> 00:15:12,240
the time it takes to compute the

390
00:15:12,240 --> 00:15:15,199
diagonalization of the matrix plus the

391
00:15:15,199 --> 00:15:17,680
time for the tree computation

392
00:15:17,680 --> 00:15:20,160
and the time for the tree computation is

393
00:15:20,160 --> 00:15:22,800
mainly dependent on the chosen nearest

394
00:15:22,800 --> 00:15:25,199
neighbor routines which determine the

395
00:15:25,199 --> 00:15:26,959
time needed to construct the

396
00:15:26,959 --> 00:15:30,000
intermediate and the final list

397
00:15:30,000 --> 00:15:32,720
before we look into what this means for

398
00:15:32,720 --> 00:15:34,639
the security of the proposed parameter

399
00:15:34,639 --> 00:15:37,759
sets let us investigate the cost of

400
00:15:37,759 --> 00:15:39,040
memory

401
00:15:39,040 --> 00:15:41,199
because all algorithms we've seen in

402
00:15:41,199 --> 00:15:43,279
this talk so far rely on some

403
00:15:43,279 --> 00:15:46,000
enumeration procedures which involve

404
00:15:46,000 --> 00:15:49,279
lists of large size

405
00:15:49,279 --> 00:15:51,440
here we see a timeline of

406
00:15:51,440 --> 00:15:53,040
isd improvements and when they

407
00:15:53,040 --> 00:15:55,120
originated

408
00:15:55,120 --> 00:15:57,040
so please note that this is just a

409
00:15:57,040 --> 00:15:58,800
selection of improvements there are

410
00:15:58,800 --> 00:16:01,519
plenty of others omitted here

411
00:16:01,519 --> 00:16:02,639
and as

412
00:16:02,639 --> 00:16:05,199
we said in the beginning we also omitted

413
00:16:05,199 --> 00:16:06,800
in our presentation the original

414
00:16:06,800 --> 00:16:08,800
algorithm by a prange and also an

415
00:16:08,800 --> 00:16:10,800
improvement by lee and brickell

416
00:16:10,800 --> 00:16:13,360
so note that these isd algorithms would

417
00:16:13,360 --> 00:16:15,040
actually only require a polynomial

418
00:16:15,040 --> 00:16:16,959
amount of memory so they do not rely on

419
00:16:16,959 --> 00:16:18,800
enumeration procedures but all

420
00:16:18,800 --> 00:16:20,959
algorithms we've seen use an exponential

421
00:16:20,959 --> 00:16:23,360
amount of memory and as a rule of thumb

422
00:16:23,360 --> 00:16:25,680
you can say if going from left to right

423
00:16:25,680 --> 00:16:27,839
these algorithms use more and more

424
00:16:27,839 --> 00:16:29,199
memory

425
00:16:29,199 --> 00:16:30,959
and the access to these amounts of

426
00:16:30,959 --> 00:16:33,040
memory will definitely slow down the

427
00:16:33,040 --> 00:16:36,240
computation of the algorithm so the

428
00:16:36,240 --> 00:16:38,240
question is how do we account for this

429
00:16:38,240 --> 00:16:40,399
in our security estimates

430
00:16:40,399 --> 00:16:41,920
where the conservative answer is

431
00:16:41,920 --> 00:16:43,519
probably we don't

432
00:16:43,519 --> 00:16:46,399
but the more realistic answer is we are

433
00:16:46,399 --> 00:16:48,639
we introduce a time penalty so an

434
00:16:48,639 --> 00:16:50,639
algorithm was time complexity t and

435
00:16:50,639 --> 00:16:53,920
memory complexity m is set to have cost

436
00:16:53,920 --> 00:16:55,759
t times f of m

437
00:16:55,759 --> 00:16:59,199
where f is some penalty function

438
00:16:59,199 --> 00:17:01,279
so for example we obtain quite directly

439
00:17:01,279 --> 00:17:04,400
as a conservative setting if we set f of

440
00:17:04,400 --> 00:17:06,959
m to 1 so or some other constant which

441
00:17:06,959 --> 00:17:08,799
is why this setting is known as a

442
00:17:08,799 --> 00:17:11,599
constant axis setting

443
00:17:11,599 --> 00:17:13,839
there are other established penalty

444
00:17:13,839 --> 00:17:16,079
functions such as a logarithmic

445
00:17:16,079 --> 00:17:17,439
logarithm or

446
00:17:17,439 --> 00:17:20,559
the cube root or even square root

447
00:17:20,559 --> 00:17:22,160
which are then

448
00:17:22,160 --> 00:17:24,240
known as the logarithmic the cube root

449
00:17:24,240 --> 00:17:27,280
or the square root memory access setting

450
00:17:27,280 --> 00:17:28,880
and we will investigate these three

451
00:17:28,880 --> 00:17:31,039
settings here constant logarithmic and

452
00:17:31,039 --> 00:17:33,200
cube root in our

453
00:17:33,200 --> 00:17:35,919
in our considerations

454
00:17:35,919 --> 00:17:38,160
now i said that the algorithms have an

455
00:17:38,160 --> 00:17:40,559
exponential amount of memory usage but

456
00:17:40,559 --> 00:17:42,720
this is only half the truth because it

457
00:17:42,720 --> 00:17:45,039
depends on the

458
00:17:45,039 --> 00:17:46,799
on the weight omega so exponential is

459
00:17:46,799 --> 00:17:49,520
the memory usage only if the

460
00:17:49,520 --> 00:17:52,799
error weight is a constant fraction of

461
00:17:52,799 --> 00:17:54,320
the code length of the length of the

462
00:17:54,320 --> 00:17:55,360
vector

463
00:17:55,360 --> 00:17:57,440
but for cryptographic applications this

464
00:17:57,440 --> 00:17:59,280
is usually not the case so let us

465
00:17:59,280 --> 00:18:01,360
investigate how relevant the memory

466
00:18:01,360 --> 00:18:02,559
usage is

467
00:18:02,559 --> 00:18:06,400
for cryptographic sized parameters

468
00:18:06,400 --> 00:18:08,320
here we see the

469
00:18:08,320 --> 00:18:10,720
the memory usage for the bike and hqc

470
00:18:10,720 --> 00:18:12,720
setting where

471
00:18:12,720 --> 00:18:15,760
which uses a very low error weight omega

472
00:18:15,760 --> 00:18:19,280
of just size square root of n

473
00:18:19,280 --> 00:18:20,080
and

474
00:18:20,080 --> 00:18:22,160
on the left we see the plot where we

475
00:18:22,160 --> 00:18:25,200
have on the x axis code length ranging

476
00:18:25,200 --> 00:18:28,960
from basically 0 to parameters offering

477
00:18:28,960 --> 00:18:32,320
about 250 to 300 bits of security and on

478
00:18:32,320 --> 00:18:34,960
the y-axis we see the logarithm of their

479
00:18:34,960 --> 00:18:36,960
memory usage for the exemplary

480
00:18:36,960 --> 00:18:40,840
algorithms or by bjmm stern and

481
00:18:40,840 --> 00:18:44,400
prangen we see that all algorithms for

482
00:18:44,400 --> 00:18:47,200
all parameters use quite moderate amount

483
00:18:47,200 --> 00:18:51,039
of memory so no memory so no algorithm

484
00:18:51,039 --> 00:18:53,039
actually exceeds a memory usage of two

485
00:18:53,039 --> 00:18:56,960
to the 45 bits of memory so for bike and

486
00:18:56,960 --> 00:18:59,760
h you see memory seems not to be the

487
00:18:59,760 --> 00:19:01,840
relevant factor

488
00:19:01,840 --> 00:19:03,679
the picture changes a bit if we

489
00:19:03,679 --> 00:19:05,919
investigate the mega lease setting for

490
00:19:05,919 --> 00:19:08,400
mega lease we have an error weight which

491
00:19:08,400 --> 00:19:10,960
scales with n over log n so it's

492
00:19:10,960 --> 00:19:13,760
higher than in the bike and hqc setting

493
00:19:13,760 --> 00:19:15,039
and this

494
00:19:15,039 --> 00:19:16,960
translates to the memory usage of these

495
00:19:16,960 --> 00:19:19,360
algorithms we see for pranks still we

496
00:19:19,360 --> 00:19:20,080
have

497
00:19:20,080 --> 00:19:22,000
very low memory usage but for the

498
00:19:22,000 --> 00:19:23,120
improvements

499
00:19:23,120 --> 00:19:26,000
which rely on enumeration so for stern

500
00:19:26,000 --> 00:19:29,440
and bjm we have a drastically increased

501
00:19:29,440 --> 00:19:32,559
memory usage where stern uses

502
00:19:32,559 --> 00:19:36,160
roughly 2 to 100 bits of memory and bjm

503
00:19:36,160 --> 00:19:38,480
almost 2 to the 200

504
00:19:38,480 --> 00:19:41,600
bits of memory for parameters that offer

505
00:19:41,600 --> 00:19:46,720
about 250 to 300 bits of security

506
00:19:46,720 --> 00:19:48,000
so for

507
00:19:48,000 --> 00:19:49,919
the megalis

508
00:19:49,919 --> 00:19:51,679
parameters

509
00:19:51,679 --> 00:19:53,840
besides the question if such amounts of

510
00:19:53,840 --> 00:19:57,520
memory will be ever available the

511
00:19:57,520 --> 00:19:59,120
access timings to these amounts of

512
00:19:59,120 --> 00:20:00,799
memory will certainly slow down the

513
00:20:00,799 --> 00:20:03,679
computations of the algorithm

514
00:20:03,679 --> 00:20:06,000
equip with this knowledge let us now

515
00:20:06,000 --> 00:20:09,039
investigate the security

516
00:20:09,039 --> 00:20:11,520
level of the proposed parameter sets

517
00:20:11,520 --> 00:20:15,559
again starting with spikenhqc

518
00:20:16,000 --> 00:20:19,120
nist provides three categories security

519
00:20:19,120 --> 00:20:21,440
categories that relate their security to

520
00:20:21,440 --> 00:20:24,559
aes meaning a set is

521
00:20:24,559 --> 00:20:27,039
set to be secure

522
00:20:27,039 --> 00:20:30,960
in category 1 305 if it is at least as

523
00:20:30,960 --> 00:20:32,960
hard to break as the respective aes

524
00:20:32,960 --> 00:20:34,400
instantiation

525
00:20:34,400 --> 00:20:35,280
and

526
00:20:35,280 --> 00:20:37,600
let us start with a conservative model

527
00:20:37,600 --> 00:20:39,840
so this constant access setting where we

528
00:20:39,840 --> 00:20:41,919
do not account for the memory usage and

529
00:20:41,919 --> 00:20:44,880
we find that bike already matches

530
00:20:44,880 --> 00:20:47,200
all security levels

531
00:20:47,200 --> 00:20:49,440
under this metric

532
00:20:49,440 --> 00:20:52,000
and here in the table we see the

533
00:20:52,000 --> 00:20:55,200
security margin that bike has over

534
00:20:55,200 --> 00:20:59,360
breaking aes meaning in bike category 1

535
00:20:59,360 --> 00:21:02,919
is three bits harder to break as

536
00:21:02,919 --> 00:21:05,200
as128 for example

537
00:21:05,200 --> 00:21:07,120
and a negative number would therefore

538
00:21:07,120 --> 00:21:10,640
correspond to a security deficit

539
00:21:10,640 --> 00:21:12,559
of course if we now introduce memory

540
00:21:12,559 --> 00:21:13,440
access

541
00:21:13,440 --> 00:21:15,919
costs then we can only increase these

542
00:21:15,919 --> 00:21:18,720
security margins and the same holds for

543
00:21:18,720 --> 00:21:20,240
the hqc

544
00:21:20,240 --> 00:21:23,760
for the hqc scheme also here hqc matches

545
00:21:23,760 --> 00:21:26,720
the security levels already under the

546
00:21:26,720 --> 00:21:30,480
conservative in the conservative model

547
00:21:30,480 --> 00:21:33,360
so we recall that bike and hqc both use

548
00:21:33,360 --> 00:21:36,400
a very small value of omega so for all

549
00:21:36,400 --> 00:21:38,880
instantiations we see here the memory

550
00:21:38,880 --> 00:21:41,840
usage is quite low with only 2 to the 40

551
00:21:41,840 --> 00:21:44,400
bits of memory so a maximum of 2 to 40

552
00:21:44,400 --> 00:21:47,520
bits of memory we see again for by kind

553
00:21:47,520 --> 00:21:50,640
of hqc memory is definitely not the most

554
00:21:50,640 --> 00:21:52,880
relevant factor

555
00:21:52,880 --> 00:21:55,440
let us next investigate the megalis the

556
00:21:55,440 --> 00:21:58,159
classic mecalis parameters

557
00:21:58,159 --> 00:22:00,640
so the same categories hold for the

558
00:22:00,640 --> 00:22:02,320
mekalis scheme

559
00:22:02,320 --> 00:22:04,799
the only difference is that the megalist

560
00:22:04,799 --> 00:22:07,039
team provides three

561
00:22:07,039 --> 00:22:11,039
parameter sets for the category 5 5a and

562
00:22:11,039 --> 00:22:12,400
5b

563
00:22:12,400 --> 00:22:14,799
parameter sets roughly

564
00:22:14,799 --> 00:22:16,720
giving the same security

565
00:22:16,720 --> 00:22:20,159
and category 5c set meant to provide

566
00:22:20,159 --> 00:22:22,640
very high security guarantees

567
00:22:22,640 --> 00:22:25,440
starting with a constant access model we

568
00:22:25,440 --> 00:22:27,840
find that only category 1 and the

569
00:22:27,840 --> 00:22:29,840
category 5c set

570
00:22:29,840 --> 00:22:32,799
are matching their security levels

571
00:22:32,799 --> 00:22:35,280
but to be fair this is known to the

572
00:22:35,280 --> 00:22:36,640
mcaleest team

573
00:22:36,640 --> 00:22:39,280
and they say that the algorithms used to

574
00:22:39,280 --> 00:22:42,240
obtain these security estimates use high

575
00:22:42,240 --> 00:22:45,440
amounts of memory and the excess timings

576
00:22:45,440 --> 00:22:47,120
to this amount of memory will make up

577
00:22:47,120 --> 00:22:48,400
for the difference

578
00:22:48,400 --> 00:22:50,080
and they are somehow right these

579
00:22:50,080 --> 00:22:53,840
algorithms use a high amount of memory

580
00:22:53,840 --> 00:22:56,880
which ranges from 2 to the 90 to 2 to

581
00:22:56,880 --> 00:22:59,760
the 200 bits of memory

582
00:22:59,760 --> 00:23:03,200
and as i already said the bare existence

583
00:23:03,200 --> 00:23:04,880
of this amount of memory are already

584
00:23:04,880 --> 00:23:07,840
questionable so before looking into

585
00:23:07,840 --> 00:23:10,320
memory access timing or

586
00:23:10,320 --> 00:23:12,720
memory access costs let us

587
00:23:12,720 --> 00:23:15,440
investigate how the complexity behaves

588
00:23:15,440 --> 00:23:18,480
if we limit the memory so if we employ

589
00:23:18,480 --> 00:23:20,840
some memory bounds so

590
00:23:20,840 --> 00:23:23,919
remember that the algorithm has this

591
00:23:23,919 --> 00:23:26,320
optimization optimization parameter p

592
00:23:26,320 --> 00:23:29,200
which allows them to shift more or less

593
00:23:29,200 --> 00:23:31,760
weight into the enumeration part and by

594
00:23:31,760 --> 00:23:34,480
decreasing this value of p they shift

595
00:23:34,480 --> 00:23:36,320
less weight into the enumeration part

596
00:23:36,320 --> 00:23:38,320
which allows them actually to consume

597
00:23:38,320 --> 00:23:39,600
less memory

598
00:23:39,600 --> 00:23:43,520
and we see that we decrease the deficits

599
00:23:43,520 --> 00:23:46,080
a little bit and we increase the margins

600
00:23:46,080 --> 00:23:49,039
but overall the

601
00:23:49,039 --> 00:23:52,559
so the picture stays the same

602
00:23:52,559 --> 00:23:54,880
the same we observe if we impose

603
00:23:54,880 --> 00:23:57,760
logarithmic memory access costs

604
00:23:57,760 --> 00:23:58,960
so here

605
00:23:58,960 --> 00:24:01,840
the algorithms are penalized by the

606
00:24:01,840 --> 00:24:04,240
logarithm of their memory usage but they

607
00:24:04,240 --> 00:24:06,080
still have the same memory usage as in

608
00:24:06,080 --> 00:24:07,919
the constant axis setting depicted by

609
00:24:07,919 --> 00:24:09,919
the same color here

610
00:24:09,919 --> 00:24:11,440
so

611
00:24:11,440 --> 00:24:13,679
the memory usage as a memory cost is

612
00:24:13,679 --> 00:24:15,760
actually too low to make the

613
00:24:15,760 --> 00:24:17,120
optimization

614
00:24:17,120 --> 00:24:19,520
choose a different strategy

615
00:24:19,520 --> 00:24:21,919
if we then go to the cube root access

616
00:24:21,919 --> 00:24:23,919
setting we see that the picture changes

617
00:24:23,919 --> 00:24:26,400
drastically so here the memory access

618
00:24:26,400 --> 00:24:28,480
cost is so high

619
00:24:28,480 --> 00:24:30,720
that the algorithms optimization

620
00:24:30,720 --> 00:24:32,640
actually tries to avoid the use of

621
00:24:32,640 --> 00:24:33,600
memory

622
00:24:33,600 --> 00:24:36,559
meaning we see that the memory here

623
00:24:36,559 --> 00:24:38,320
ranges only the memory consumption

624
00:24:38,320 --> 00:24:41,840
ranges only from 2 to the 25 to 2 to the

625
00:24:41,840 --> 00:24:43,919
47 bits of memory

626
00:24:43,919 --> 00:24:46,000
and most of the parameter sets are then

627
00:24:46,000 --> 00:24:47,679
able to match their

628
00:24:47,679 --> 00:24:49,520
their security

629
00:24:49,520 --> 00:24:51,440
levels

630
00:24:51,440 --> 00:24:52,480
even if

631
00:24:52,480 --> 00:24:54,880
not equally well

632
00:24:54,880 --> 00:24:56,960
and the category 3 set seems to be

633
00:24:56,960 --> 00:24:59,360
somewhat an outlier here which is not

634
00:24:59,360 --> 00:25:02,480
able to match the security level under

635
00:25:02,480 --> 00:25:05,679
any of the employed metrics

636
00:25:05,679 --> 00:25:07,679
so what does this mean for the code

637
00:25:07,679 --> 00:25:10,640
based cryptographic schemes

638
00:25:10,640 --> 00:25:13,440
for bike and hqc we have seen that they

639
00:25:13,440 --> 00:25:15,919
match their security levels already

640
00:25:15,919 --> 00:25:18,159
under conservative metrics meaning in

641
00:25:18,159 --> 00:25:20,559
the constant access model where we do

642
00:25:20,559 --> 00:25:23,679
not impose memory access costs

643
00:25:23,679 --> 00:25:25,919
which is the result of the very low

644
00:25:25,919 --> 00:25:28,400
over error weight they are using and as

645
00:25:28,400 --> 00:25:31,200
a rule of some one can say that the more

646
00:25:31,200 --> 00:25:33,120
or the higher the arrow weight becomes

647
00:25:33,120 --> 00:25:35,600
the more memory these algorithms use

648
00:25:35,600 --> 00:25:37,440
and hence the more

649
00:25:37,440 --> 00:25:39,440
relevant it becomes or the wall

650
00:25:39,440 --> 00:25:41,600
necessary also to

651
00:25:41,600 --> 00:25:44,799
precisely model the memory access costs

652
00:25:44,799 --> 00:25:47,120
we've seen this especially for the mca

653
00:25:47,120 --> 00:25:48,640
submission

654
00:25:48,640 --> 00:25:52,159
but also for the bike and hqc team we

655
00:25:52,159 --> 00:25:53,840
suggest to

656
00:25:53,840 --> 00:25:56,880
decide for metrics under which the

657
00:25:56,880 --> 00:25:58,960
parameters should be proposed

658
00:25:58,960 --> 00:26:01,600
and then to ensure that all proposed

659
00:26:01,600 --> 00:26:04,880
parameter sets match the security levels

660
00:26:04,880 --> 00:26:06,559
equally well

661
00:26:06,559 --> 00:26:08,640
so our paper is online thank you very

662
00:26:08,640 --> 00:26:10,799
much and for details please give it a

663
00:26:10,799 --> 00:26:13,799
look

