1
00:00:04,640 --> 00:00:07,040
so next we have a joint talk

2
00:00:07,040 --> 00:00:09,840
uh by andrea gascon galista bonovich and

3
00:00:09,840 --> 00:00:12,960
peter carus thanks a lot guys

4
00:00:12,960 --> 00:00:15,519
um so they are all currently at google

5
00:00:15,519 --> 00:00:16,880
they have done tremendous work in

6
00:00:16,880 --> 00:00:18,320
federated learning and differential

7
00:00:18,320 --> 00:00:19,359
privacy

8
00:00:19,359 --> 00:00:20,240
uh

9
00:00:20,240 --> 00:00:22,480
also like kalista was also part of the

10
00:00:22,480 --> 00:00:24,720
paper that introduced federated learning

11
00:00:24,720 --> 00:00:26,560
so today we're gonna listen to the

12
00:00:26,560 --> 00:00:30,640
recent research in federated learning

13
00:00:30,640 --> 00:00:32,960
and we are looking forward to it so we

14
00:00:32,960 --> 00:00:34,960
can start

15
00:00:34,960 --> 00:00:36,880
great thank you

16
00:00:36,880 --> 00:00:38,000
so

17
00:00:38,000 --> 00:00:40,320
i yeah i'm happy to be here today

18
00:00:40,320 --> 00:00:42,239
talking to you about privacy and

19
00:00:42,239 --> 00:00:44,879
federated learning at scale i'm calista

20
00:00:44,879 --> 00:00:46,239
and i'll be co-presenting with audrey

21
00:00:46,239 --> 00:00:47,920
and peter today but really we're

22
00:00:47,920 --> 00:00:49,600
representing the work of many of our

23
00:00:49,600 --> 00:00:53,440
colleagues at google and beyond

24
00:00:53,440 --> 00:00:55,440
so today we're talking about federated

25
00:00:55,440 --> 00:00:57,680
learning what it is and how it relates

26
00:00:57,680 --> 00:00:59,680
to privacy and machine learning

27
00:00:59,680 --> 00:01:01,840
we'll talk about how we distribute trust

28
00:01:01,840 --> 00:01:03,520
by running cryptographic secure

29
00:01:03,520 --> 00:01:06,159
aggregation at industrial scale and by

30
00:01:06,159 --> 00:01:08,560
combining it with randomization to

31
00:01:08,560 --> 00:01:10,400
achieve distributed differential privacy

32
00:01:10,400 --> 00:01:11,520
guarantees

33
00:01:11,520 --> 00:01:13,439
and we'll conclude by highlighting some

34
00:01:13,439 --> 00:01:15,040
of the important challenges and open

35
00:01:15,040 --> 00:01:16,720
problem opportunities in federated

36
00:01:16,720 --> 00:01:19,520
learning alistar sorry to interrupt you

37
00:01:19,520 --> 00:01:21,280
i think there's i'm like are you

38
00:01:21,280 --> 00:01:23,439
addressing the keyboard or is it from

39
00:01:23,439 --> 00:01:26,720
your microphone with some noise coming

40
00:01:26,720 --> 00:01:29,200
out a click

41
00:01:29,200 --> 00:01:31,439
yes something like a click

42
00:01:31,439 --> 00:01:32,640
all right

43
00:01:32,640 --> 00:01:35,040
let's see if it's uh i don't usually use

44
00:01:35,040 --> 00:01:36,720
these headphones so maybe it's that i

45
00:01:36,720 --> 00:01:39,119
think yeah i think now it's good

46
00:01:39,119 --> 00:01:41,200
okay great thank you

47
00:01:41,200 --> 00:01:41,670
um

48
00:01:41,670 --> 00:01:42,799
[Music]

49
00:01:42,799 --> 00:01:44,399
all right so federated learning and

50
00:01:44,399 --> 00:01:46,399
privacy

51
00:01:46,399 --> 00:01:48,479
federated learning is a machine learning

52
00:01:48,479 --> 00:01:50,079
setting where multiple clients

53
00:01:50,079 --> 00:01:51,920
collaborate in solving a machine

54
00:01:51,920 --> 00:01:53,600
learning problem under the coordination

55
00:01:53,600 --> 00:01:56,240
of a central service provider so each

56
00:01:56,240 --> 00:01:58,799
client's raw data is going to be stored

57
00:01:58,799 --> 00:02:01,759
locally and not exchanged or transferred

58
00:02:01,759 --> 00:02:04,159
instead only focused updates intended

59
00:02:04,159 --> 00:02:06,079
for immediate aggregation are used to

60
00:02:06,079 --> 00:02:08,800
achieve the learning goal

61
00:02:08,800 --> 00:02:11,200
now reasoning about privacy in a complex

62
00:02:11,200 --> 00:02:13,440
system like a federated learning system

63
00:02:13,440 --> 00:02:15,520
requires understanding precisely what

64
00:02:15,520 --> 00:02:18,480
pieces of information each actor in the

65
00:02:18,480 --> 00:02:20,080
system will have access

66
00:02:20,080 --> 00:02:21,680
in fact every machine learning system

67
00:02:21,680 --> 00:02:23,680
that operates on end user data whether

68
00:02:23,680 --> 00:02:25,520
it's centralized learning federated

69
00:02:25,520 --> 00:02:27,520
learning or some other decentralized

70
00:02:27,520 --> 00:02:29,599
learning paradigm has a variety of

71
00:02:29,599 --> 00:02:31,360
actors playing different roles in the

72
00:02:31,360 --> 00:02:33,519
system and each actor requires a

73
00:02:33,519 --> 00:02:35,599
different view of the multi-user data

74
00:02:35,599 --> 00:02:36,560
set

75
00:02:36,560 --> 00:02:37,280
so

76
00:02:37,280 --> 00:02:38,959
end users are going to be generating the

77
00:02:38,959 --> 00:02:40,720
data through interaction with one or

78
00:02:40,720 --> 00:02:43,360
more devices we need to ask what could

79
00:02:43,360 --> 00:02:45,519
an adversary with access to one of those

80
00:02:45,519 --> 00:02:47,599
devices observe

81
00:02:47,599 --> 00:02:49,519
some of that information is going to

82
00:02:49,519 --> 00:02:51,519
flow across the network and we need to

83
00:02:51,519 --> 00:02:53,120
know what can be learned by observing

84
00:02:53,120 --> 00:02:55,120
the network transmissions

85
00:02:55,120 --> 00:02:57,120
often servers assist in the collection

86
00:02:57,120 --> 00:02:59,200
and processing of user data and we have

87
00:02:59,200 --> 00:03:01,040
to ask what can be learned by observing

88
00:03:01,040 --> 00:03:02,560
that process

89
00:03:02,560 --> 00:03:04,080
machine learning engineers need to

90
00:03:04,080 --> 00:03:06,080
monitor and evaluate the models as they

91
00:03:06,080 --> 00:03:08,239
are being trained and we need to know

92
00:03:08,239 --> 00:03:09,920
what can such a machine learning

93
00:03:09,920 --> 00:03:12,720
engineer learn through this process

94
00:03:12,720 --> 00:03:14,879
and finally fully trained and evaluated

95
00:03:14,879 --> 00:03:16,400
models will be deployed to power

96
00:03:16,400 --> 00:03:18,080
potentially billions of end user

97
00:03:18,080 --> 00:03:20,560
experiences and we might ask what can be

98
00:03:20,560 --> 00:03:22,159
learned from observing these deployed

99
00:03:22,159 --> 00:03:24,400
models

100
00:03:24,400 --> 00:03:26,480
now federated learning's architecture

101
00:03:26,480 --> 00:03:28,799
comes with built-in data minimization

102
00:03:28,799 --> 00:03:30,560
principles that limit access to

103
00:03:30,560 --> 00:03:32,640
information for each of these actors

104
00:03:32,640 --> 00:03:35,360
minimizing data exposure on each device

105
00:03:35,360 --> 00:03:36,879
collecting

106
00:03:36,879 --> 00:03:38,640
only focused data to the server and

107
00:03:38,640 --> 00:03:40,799
using anonymous ephemeral strategies to

108
00:03:40,799 --> 00:03:43,120
collect that focused data and releasing

109
00:03:43,120 --> 00:03:45,360
data only in aggregate both to ml

110
00:03:45,360 --> 00:03:48,400
engineers and when deploying the final

111
00:03:48,400 --> 00:03:50,560
models

112
00:03:50,560 --> 00:03:52,239
federated learning's privacy principles

113
00:03:52,239 --> 00:03:53,840
can be strengthened and rigorized

114
00:03:53,840 --> 00:03:55,519
through the use of complementary data

115
00:03:55,519 --> 00:03:57,360
anonymization and minimization

116
00:03:57,360 --> 00:04:00,400
technologies such as secure aggregation

117
00:04:00,400 --> 00:04:03,040
differential privacy in all its flavors

118
00:04:03,040 --> 00:04:06,239
model auditing techniques and so on

119
00:04:06,239 --> 00:04:08,000
so let's take differential privacy as an

120
00:04:08,000 --> 00:04:09,040
example

121
00:04:09,040 --> 00:04:10,400
it can be

122
00:04:10,400 --> 00:04:11,920
applied in a centralized setting you

123
00:04:11,920 --> 00:04:14,000
would clip each client's contribution to

124
00:04:14,000 --> 00:04:16,000
bound to that user's influence and then

125
00:04:16,000 --> 00:04:17,680
you would add noise on the server to

126
00:04:17,680 --> 00:04:19,440
prevent the model from overfitting to

127
00:04:19,440 --> 00:04:21,839
any particular client's contribution and

128
00:04:21,839 --> 00:04:23,919
this ensures that the trained model and

129
00:04:23,919 --> 00:04:26,000
the model iterates along the way do not

130
00:04:26,000 --> 00:04:27,680
contain too much information about

131
00:04:27,680 --> 00:04:30,160
participating clients so that that

132
00:04:30,160 --> 00:04:32,400
applies to some of the roles

133
00:04:32,400 --> 00:04:34,880
but now that requires that the clients

134
00:04:34,880 --> 00:04:37,520
trust the server in adding noise which

135
00:04:37,520 --> 00:04:39,360
may not always be desirable depending on

136
00:04:39,360 --> 00:04:41,360
how much you trust the

137
00:04:41,360 --> 00:04:43,840
the actor the server as an actor so

138
00:04:43,840 --> 00:04:46,080
instead of applying dp centrally both

139
00:04:46,080 --> 00:04:48,240
clipping and noising can be applied

140
00:04:48,240 --> 00:04:50,720
locally on the on the clients

141
00:04:50,720 --> 00:04:52,320
unfortunately as shown in the dp

142
00:04:52,320 --> 00:04:54,720
literature this generally leads to poor

143
00:04:54,720 --> 00:04:56,960
performance

144
00:04:56,960 --> 00:04:59,280
so in this talk we ask if we can somehow

145
00:04:59,280 --> 00:05:01,600
combine the best of both worlds and the

146
00:05:01,600 --> 00:05:04,240
good news is the answer is yes we can

147
00:05:04,240 --> 00:05:05,840
use a version of differential privacy

148
00:05:05,840 --> 00:05:07,680
called distributed differential privacy

149
00:05:07,680 --> 00:05:09,520
which offers privacy guarantees and

150
00:05:09,520 --> 00:05:11,360
trust models very similar to local

151
00:05:11,360 --> 00:05:13,520
differential privacy while retaining the

152
00:05:13,520 --> 00:05:15,199
high quality model performance of

153
00:05:15,199 --> 00:05:17,600
central dp

154
00:05:17,600 --> 00:05:18,880
ideally we're going to look for a

155
00:05:18,880 --> 00:05:21,199
solution where we provide some formal dp

156
00:05:21,199 --> 00:05:23,280
guarantees as soon as data is collected

157
00:05:23,280 --> 00:05:25,360
at the server and then we progressively

158
00:05:25,360 --> 00:05:27,360
strengthen our guarantees as the attack

159
00:05:27,360 --> 00:05:29,360
surface gets bigger

160
00:05:29,360 --> 00:05:31,280
it is as we move from the servers having

161
00:05:31,280 --> 00:05:33,199
very few system administrators through

162
00:05:33,199 --> 00:05:35,280
the larger number of ml engineers and

163
00:05:35,280 --> 00:05:36,720
eventually provide the strongest

164
00:05:36,720 --> 00:05:39,759
guarantees for the deployed models

165
00:05:39,759 --> 00:05:41,360
to achieve that we need to look

166
00:05:41,360 --> 00:05:43,360
carefully at how we distribute trust

167
00:05:43,360 --> 00:05:45,600
among the actors in our system there are

168
00:05:45,600 --> 00:05:47,280
many approaches to trust distribution

169
00:05:47,280 --> 00:05:48,960
for example even with a simple sub

170
00:05:48,960 --> 00:05:50,840
problem like aggregation vector

171
00:05:50,840 --> 00:05:53,680
summation we could distribute trust by

172
00:05:53,680 --> 00:05:55,600
establishing a trusted third party to do

173
00:05:55,600 --> 00:05:57,440
the aggregation for us or to at least

174
00:05:57,440 --> 00:06:00,080
shuffle the 2d aggregated values

175
00:06:00,080 --> 00:06:02,600
or we could use trusted execution

176
00:06:02,600 --> 00:06:04,800
environments like secure enclaves as a

177
00:06:04,800 --> 00:06:06,639
source of distributed trust

178
00:06:06,639 --> 00:06:08,160
or we could distribute using

179
00:06:08,160 --> 00:06:09,680
cryptography and that's what we'll focus

180
00:06:09,680 --> 00:06:11,520
on in this talk a version of distributed

181
00:06:11,520 --> 00:06:13,680
privacy that uses cryptographic secure

182
00:06:13,680 --> 00:06:14,960
aggregation

183
00:06:14,960 --> 00:06:16,560
to achieve our goal we need to carefully

184
00:06:16,560 --> 00:06:18,240
mix differential privacy with secure

185
00:06:18,240 --> 00:06:20,479
aggregation at scale so the rest of the

186
00:06:20,479 --> 00:06:22,800
talk will be divided into two parts how

187
00:06:22,800 --> 00:06:25,039
to design a secure aggregation protocol

188
00:06:25,039 --> 00:06:26,960
that scales to large models and millions

189
00:06:26,960 --> 00:06:28,960
of clients and how to properly mix

190
00:06:28,960 --> 00:06:30,560
differential privacy with secure

191
00:06:30,560 --> 00:06:32,319
aggregation

192
00:06:32,319 --> 00:06:34,479
and with that i'll hand the talk over to

193
00:06:34,479 --> 00:06:37,479
adrian

194
00:06:57,520 --> 00:07:00,240
can you hear me well

195
00:07:00,240 --> 00:07:05,039
yes i saw okay let's get fine then

196
00:07:05,919 --> 00:07:06,800
so

197
00:07:06,800 --> 00:07:08,720
in this part of the scaly set we will

198
00:07:08,720 --> 00:07:11,280
discuss a concrete security protocol

199
00:07:11,280 --> 00:07:13,759
that intuitively satisfies what's stated

200
00:07:13,759 --> 00:07:16,000
here and what what would expect that is

201
00:07:16,000 --> 00:07:19,599
that uh the server collecting uh all the

202
00:07:19,599 --> 00:07:20,960
uh

203
00:07:20,960 --> 00:07:22,800
model updates in the in the context of

204
00:07:22,800 --> 00:07:25,599
fl learns nothing but the sum of those

205
00:07:25,599 --> 00:07:27,199
vectors and no individual data

206
00:07:27,199 --> 00:07:28,800
whatsoever and this will be the case

207
00:07:28,800 --> 00:07:31,520
even if some users behave maliciously

208
00:07:31,520 --> 00:07:34,080
and and some drop out

209
00:07:34,080 --> 00:07:35,759
the the previous promise is as you would

210
00:07:35,759 --> 00:07:38,479
expect here at crypto made precise using

211
00:07:38,479 --> 00:07:40,240
the standard real versus ideal paradigm

212
00:07:40,240 --> 00:07:42,400
of mpc and for our protocols we show

213
00:07:42,400 --> 00:07:44,960
that every adversary controlling a given

214
00:07:44,960 --> 00:07:46,400
fraction of the clients

215
00:07:46,400 --> 00:07:48,240
and the server shown on the left can be

216
00:07:48,240 --> 00:07:49,840
simulated in the setting where the

217
00:07:49,840 --> 00:07:52,080
delegator is available this is this ils

218
00:07:52,080 --> 00:07:53,759
setting showed on the right

219
00:07:53,759 --> 00:07:55,360
and this shows that any leakage about

220
00:07:55,360 --> 00:07:57,360
honest input inputs that come from the

221
00:07:57,360 --> 00:08:01,039
aggregation functionality itself

222
00:08:01,840 --> 00:08:04,639
it is inherent to the functionality and

223
00:08:04,639 --> 00:08:07,039
lives out of scope things like enforcing

224
00:08:07,039 --> 00:08:08,800
input validity because that's something

225
00:08:08,800 --> 00:08:09,840
that

226
00:08:09,840 --> 00:08:11,680
i mean something like choosing their

227
00:08:11,680 --> 00:08:13,759
input is something that that malicious

228
00:08:13,759 --> 00:08:15,199
clients can can do themselves right so

229
00:08:15,199 --> 00:08:16,720
we cannot prevent them from doing that

230
00:08:16,720 --> 00:08:18,639
in this setting so although i won't

231
00:08:18,639 --> 00:08:21,440
discuss the proofs uh of the protocols

232
00:08:21,440 --> 00:08:23,440
that i'll describe they are securing

233
00:08:23,440 --> 00:08:25,680
this very concrete setting used in mpc

234
00:08:25,680 --> 00:08:27,520
and the details are in the in the papers

235
00:08:27,520 --> 00:08:29,039
at that site

236
00:08:29,039 --> 00:08:30,560
so let's make our settings and goals

237
00:08:30,560 --> 00:08:31,840
concrete

238
00:08:31,840 --> 00:08:34,479
uh we're in the fl setting right so we

239
00:08:34,479 --> 00:08:36,799
have a single server and n clients in a

240
00:08:36,799 --> 00:08:39,360
star topology and each client holds a

241
00:08:39,360 --> 00:08:41,039
very long private vector which you can

242
00:08:41,039 --> 00:08:43,679
think of as having length 100 000 or a

243
00:08:43,679 --> 00:08:44,720
million

244
00:08:44,720 --> 00:08:46,000
and

245
00:08:46,000 --> 00:08:48,160
the goal here is for the server to

246
00:08:48,160 --> 00:08:50,399
obtain the sum of all

247
00:08:50,399 --> 00:08:53,519
private uh input vectors of all clients

248
00:08:53,519 --> 00:08:54,399
even if

249
00:08:54,399 --> 00:08:56,880
up to a given number of reports happen

250
00:08:56,880 --> 00:08:58,240
and this this

251
00:08:58,240 --> 00:08:59,760
maximum number of dropout is expressed

252
00:08:59,760 --> 00:09:01,440
as a fraction so you can think of delta

253
00:09:01,440 --> 00:09:03,279
as one-third so

254
00:09:03,279 --> 00:09:04,720
if less than one-third of the clients

255
00:09:04,720 --> 00:09:07,200
participating in the in the protocol

256
00:09:07,200 --> 00:09:08,880
dropout then the server should obtain

257
00:09:08,880 --> 00:09:11,200
the sum of the surviving clients

258
00:09:11,200 --> 00:09:13,200
and if more than that number drop out

259
00:09:13,200 --> 00:09:15,120
then the server gets off

260
00:09:15,120 --> 00:09:17,600
now in terms of security

261
00:09:17,600 --> 00:09:19,279
the server should learn only the sum if

262
00:09:19,279 --> 00:09:21,519
it even if it colludes with a

263
00:09:21,519 --> 00:09:23,519
up to a gamma fraction of dishonest

264
00:09:23,519 --> 00:09:25,600
clients and you can think of that as one

265
00:09:25,600 --> 00:09:27,519
field for example

266
00:09:27,519 --> 00:09:29,200
and in terms of related work although

267
00:09:29,200 --> 00:09:30,480
there have been several recent works on

268
00:09:30,480 --> 00:09:32,560
secure aggregation i will be referring

269
00:09:32,560 --> 00:09:35,760
mostly to the ccs 2017

270
00:09:35,760 --> 00:09:37,760
paper this one

271
00:09:37,760 --> 00:09:39,680
as the protocol that i will present

272
00:09:39,680 --> 00:09:42,560
is inspired heavily by by that one

273
00:09:42,560 --> 00:09:44,560
so i will be talking

274
00:09:44,560 --> 00:09:46,080
during the rest of this section of the

275
00:09:46,080 --> 00:09:47,279
talk about this

276
00:09:47,279 --> 00:09:49,680
paper presented at ccs last year and

277
00:09:49,680 --> 00:09:51,519
called to go authored with

278
00:09:51,519 --> 00:09:53,760
kaylee james mariana and tankrett

279
00:09:53,760 --> 00:09:54,880
and

280
00:09:54,880 --> 00:09:56,399
while the

281
00:09:56,399 --> 00:09:59,920
previous ccs 2017 segregation protocol

282
00:09:59,920 --> 00:10:02,560
scaled to roughly a thousand clients for

283
00:10:02,560 --> 00:10:04,160
production

284
00:10:04,160 --> 00:10:06,320
production size at our models

285
00:10:06,320 --> 00:10:08,560
those same client costs allow for allow

286
00:10:08,560 --> 00:10:10,720
for going over a million clients with

287
00:10:10,720 --> 00:10:12,800
this this new protocol okay

288
00:10:12,800 --> 00:10:14,480
and we have protocols for both seminars

289
00:10:14,480 --> 00:10:16,480
and malicious security and in this in

290
00:10:16,480 --> 00:10:18,000
that same paper we'll probably produce a

291
00:10:18,000 --> 00:10:19,519
proposal reduction from aggregation to

292
00:10:19,519 --> 00:10:20,959
shuffling that that clearly we'll talk

293
00:10:20,959 --> 00:10:22,320
about later

294
00:10:22,320 --> 00:10:24,560
okay so let's get into this setup

295
00:10:24,560 --> 00:10:26,240
and guarantees

296
00:10:26,240 --> 00:10:29,360
so in in this kind of protocols um

297
00:10:29,360 --> 00:10:31,040
it is common that the protocol starts by

298
00:10:31,040 --> 00:10:32,480
having all clients share their public

299
00:10:32,480 --> 00:10:34,560
keys with each other through the server

300
00:10:34,560 --> 00:10:35,839
and from then on we can think of the

301
00:10:35,839 --> 00:10:38,880
server as a private channel that

302
00:10:38,880 --> 00:10:40,560
lets clients communicate privately by

303
00:10:40,560 --> 00:10:43,040
relaying messages among themselves

304
00:10:43,040 --> 00:10:44,480
and

305
00:10:44,480 --> 00:10:46,240
only exchanging public keys with every

306
00:10:46,240 --> 00:10:47,440
other client requires linear

307
00:10:47,440 --> 00:10:49,920
communication per client and that

308
00:10:49,920 --> 00:10:52,079
ends up being a leading factor in

309
00:10:52,079 --> 00:10:53,760
handling very large

310
00:10:53,760 --> 00:10:56,079
uh number of clients so the the words

311
00:10:56,079 --> 00:10:57,360
that we present

312
00:10:57,360 --> 00:11:00,160
boils down to reducing

313
00:11:00,160 --> 00:11:02,480
the number of clients that

314
00:11:02,480 --> 00:11:04,240
each client the protocol needs to talk

315
00:11:04,240 --> 00:11:07,760
to from being linear as in the 2017

316
00:11:07,760 --> 00:11:10,079
protocol to being logarithmic okay

317
00:11:10,079 --> 00:11:12,000
that's and that's going to have a

318
00:11:12,000 --> 00:11:13,440
tremendous tremendous impact in

319
00:11:13,440 --> 00:11:15,120
inefficiency

320
00:11:15,120 --> 00:11:17,360
now in terms of guarantees

321
00:11:17,360 --> 00:11:18,800
or adversaries

322
00:11:18,800 --> 00:11:20,560
informally or some young's protocol

323
00:11:20,560 --> 00:11:21,680
which stands anniversary that can

324
00:11:21,680 --> 00:11:23,920
observe the execution of both a server

325
00:11:23,920 --> 00:11:26,560
and a fraction of gamma clients at a set

326
00:11:26,560 --> 00:11:28,560
and then we have this malicious variant

327
00:11:28,560 --> 00:11:30,800
that assumes that the key exchange that

328
00:11:30,800 --> 00:11:32,399
i i just uh

329
00:11:32,399 --> 00:11:34,399
described is done semi honestly so the

330
00:11:34,399 --> 00:11:36,800
server honestly release messages between

331
00:11:36,800 --> 00:11:39,120
client honestly it's public keys within

332
00:11:39,120 --> 00:11:40,079
between

333
00:11:40,079 --> 00:11:41,760
clients and from then on once clients

334
00:11:41,760 --> 00:11:42,800
can

335
00:11:42,800 --> 00:11:44,959
speak to each other privately then the

336
00:11:44,959 --> 00:11:46,640
adversary can actively corrupt the

337
00:11:46,640 --> 00:11:47,760
server

338
00:11:47,760 --> 00:11:50,639
and up to uh gamma fraction of clients

339
00:11:50,639 --> 00:11:52,240
and note that the server in this setting

340
00:11:52,240 --> 00:11:53,680
being malicious

341
00:11:53,680 --> 00:11:55,600
implies that

342
00:11:55,600 --> 00:11:56,959
it controls the communication channel

343
00:11:56,959 --> 00:11:59,360
right so it can drop messages you can

344
00:11:59,360 --> 00:12:03,279
isolate isolate clients and so on

345
00:12:03,279 --> 00:12:05,360
so that adds some difficulties in the

346
00:12:05,360 --> 00:12:06,959
malicious variant

347
00:12:06,959 --> 00:12:09,279
now in terms of guarantees

348
00:12:09,279 --> 00:12:12,000
i want to maybe refresh them informally

349
00:12:12,000 --> 00:12:13,839
in this way by saying that uh from the

350
00:12:13,839 --> 00:12:15,680
perspective of an honest user the

351
00:12:15,680 --> 00:12:17,600
seminars protocol ensures that their

352
00:12:17,600 --> 00:12:18,959
values are related with at least a

353
00:12:18,959 --> 00:12:20,800
constant fraction of honest client

354
00:12:20,800 --> 00:12:22,800
inputs and this will be very important

355
00:12:22,800 --> 00:12:25,279
when combining this protocol with

356
00:12:25,279 --> 00:12:26,800
differential privacy

357
00:12:26,800 --> 00:12:28,560
and in the malicious version the

358
00:12:28,560 --> 00:12:30,720
guarantee is the same except that this

359
00:12:30,720 --> 00:12:32,399
constant fraction is a bit more complex

360
00:12:32,399 --> 00:12:34,000
it depends on the parameters but in a

361
00:12:34,000 --> 00:12:35,279
more complex way

362
00:12:35,279 --> 00:12:37,760
uh so i'm just summarizing it using this

363
00:12:37,760 --> 00:12:39,920
parameter alpha here and as we will see

364
00:12:39,920 --> 00:12:41,440
later we have numerical approaches for

365
00:12:41,440 --> 00:12:43,519
computing this alpha and the constants

366
00:12:43,519 --> 00:12:46,560
hiding in in the big o here are not are

367
00:12:46,560 --> 00:12:48,800
not too bad

368
00:12:48,800 --> 00:12:50,720
all right now in terms of intuition so

369
00:12:50,720 --> 00:12:52,880
let me just give you the ideas behind

370
00:12:52,880 --> 00:12:54,720
this protocol which can be can be

371
00:12:54,720 --> 00:12:56,720
explained in terms of the 2017 protocol

372
00:12:56,720 --> 00:12:58,639
so i'll do that

373
00:12:58,639 --> 00:13:00,399
and at high level what happens in that

374
00:13:00,399 --> 00:13:02,320
protocol is that after two rounds in

375
00:13:02,320 --> 00:13:03,680
which the clients compute some

376
00:13:03,680 --> 00:13:06,399
correlated randomness among pairs of

377
00:13:06,399 --> 00:13:09,120
clients every client submits their input

378
00:13:09,120 --> 00:13:11,440
x i this is the private input masked

379
00:13:11,440 --> 00:13:14,000
with two two kinds of values

380
00:13:14,000 --> 00:13:16,160
to the server okay this is the y i this

381
00:13:16,160 --> 00:13:17,360
is the submission that is done to the

382
00:13:17,360 --> 00:13:19,519
server so the first the first mask we

383
00:13:19,519 --> 00:13:22,160
call pairwise mask and it's the the sum

384
00:13:22,160 --> 00:13:24,800
of uh you know

385
00:13:24,800 --> 00:13:26,800
all pairs of shares of zero that are

386
00:13:26,800 --> 00:13:29,519
computed with uh every other neighbor

387
00:13:29,519 --> 00:13:31,040
and i'm

388
00:13:31,040 --> 00:13:32,000
at this point you should think of

389
00:13:32,000 --> 00:13:34,639
neighbor as every other client which is

390
00:13:34,639 --> 00:13:37,360
which was the case in the 2017

391
00:13:37,360 --> 00:13:39,360
protocol as i described earlier

392
00:13:39,360 --> 00:13:40,800
and then there's also this

393
00:13:40,800 --> 00:13:44,320
self mask okay that is generated by

394
00:13:44,320 --> 00:13:47,600
the client and unknown to everyone else

395
00:13:47,600 --> 00:13:49,120
now

396
00:13:49,120 --> 00:13:51,120
each client also secret shares among the

397
00:13:51,120 --> 00:13:52,720
neighbors

398
00:13:52,720 --> 00:13:55,920
seats ki-1 and k2 that allow to

399
00:13:55,920 --> 00:13:57,440
reconstruct this

400
00:13:57,440 --> 00:13:59,760
two different types of masks

401
00:13:59,760 --> 00:14:01,839
and then the server receives all the y's

402
00:14:01,839 --> 00:14:03,760
adds them up okay

403
00:14:03,760 --> 00:14:06,079
and then

404
00:14:06,079 --> 00:14:09,360
so now let's see what it gets so

405
00:14:09,360 --> 00:14:10,959
note that the correlated masks of

406
00:14:10,959 --> 00:14:12,720
clients that don't drop out and send

407
00:14:12,720 --> 00:14:14,320
their y okay they drop out before

408
00:14:14,320 --> 00:14:16,480
sending their way

409
00:14:16,480 --> 00:14:18,959
those those cancel out right because i

410
00:14:18,959 --> 00:14:20,320
mean this is a

411
00:14:20,320 --> 00:14:22,079
common trick used in in in many

412
00:14:22,079 --> 00:14:24,480
aggregation protocols

413
00:14:24,480 --> 00:14:26,720
and

414
00:14:27,839 --> 00:14:29,360
so this means that to recover the

415
00:14:29,360 --> 00:14:30,800
intended sum of exercise the server

416
00:14:30,800 --> 00:14:33,120
needs to re remove pairwise maps that uh

417
00:14:33,120 --> 00:14:36,160
of dropouts and then self masks

418
00:14:36,160 --> 00:14:38,399
or pollute the output in any case uh and

419
00:14:38,399 --> 00:14:40,079
then they have to be removed for clients

420
00:14:40,079 --> 00:14:42,160
that do submit their white right so this

421
00:14:42,160 --> 00:14:43,920
boils down to this decomposition where

422
00:14:43,920 --> 00:14:45,120
we have

423
00:14:45,120 --> 00:14:48,560
the sum of eyes for survivors minus the

424
00:14:48,560 --> 00:14:50,079
per weight microsoft dropouts plus

425
00:14:50,079 --> 00:14:54,000
submission of survivors so to

426
00:14:55,600 --> 00:14:57,519
to to do a correct discernment then

427
00:14:57,519 --> 00:14:59,680
needs to be do a correction on this some

428
00:14:59,680 --> 00:15:01,440
sum of the y's to obtain the sum of the

429
00:15:01,440 --> 00:15:04,800
x's and to do that it requires shares of

430
00:15:04,800 --> 00:15:08,720
a ki-1 for dropouts and ki-2

431
00:15:08,720 --> 00:15:10,399
for the other ones and then it can

432
00:15:10,399 --> 00:15:12,880
recover them their masks and obtain the

433
00:15:12,880 --> 00:15:13,920
results

434
00:15:13,920 --> 00:15:16,560
so it's crucial for for security okay

435
00:15:16,560 --> 00:15:19,440
that john john's uh client or each

436
00:15:19,440 --> 00:15:21,360
other's neighbor of i will only answer a

437
00:15:21,360 --> 00:15:24,000
request for a pairwise mask or a

438
00:15:24,000 --> 00:15:26,480
self-muscle never both okay

439
00:15:26,480 --> 00:15:28,320
and the security of the protocol boils

440
00:15:28,320 --> 00:15:29,759
down to ensuring that

441
00:15:29,759 --> 00:15:31,199
the threshold in the secret sharing

442
00:15:31,199 --> 00:15:34,079
scheme is is chosen so that the

443
00:15:34,079 --> 00:15:35,759
surviving clients are enough to recover

444
00:15:35,759 --> 00:15:37,759
a required seat for correctness and

445
00:15:37,759 --> 00:15:39,120
malicious neighbors

446
00:15:39,120 --> 00:15:40,959
of a client are not enough to recover a

447
00:15:40,959 --> 00:15:43,759
city from a client unitary for security

448
00:15:43,759 --> 00:15:44,959
okay

449
00:15:44,959 --> 00:15:46,560
so that's uh that's the idea of the

450
00:15:46,560 --> 00:15:48,240
whole protocol

451
00:15:48,240 --> 00:15:50,079
and

452
00:15:50,079 --> 00:15:52,000
after this explanation

453
00:15:52,000 --> 00:15:53,759
everything boils down to choosing t

454
00:15:53,759 --> 00:15:54,880
choosing the threshold in this

455
00:15:54,880 --> 00:15:56,639
encryption

456
00:15:56,639 --> 00:15:59,040
uh and before we move forward i just

457
00:15:59,040 --> 00:16:00,560
want to say that i described the idea

458
00:16:00,560 --> 00:16:02,800
for the semi-honest protocol

459
00:16:02,800 --> 00:16:04,399
but

460
00:16:04,399 --> 00:16:05,519
it's important to remark that the

461
00:16:05,519 --> 00:16:07,199
malicious server can lie about who

462
00:16:07,199 --> 00:16:09,839
dropped out in in various ways in in

463
00:16:09,839 --> 00:16:11,759
this particular stage when a server

464
00:16:11,759 --> 00:16:14,480
request shares of one type of

465
00:16:14,480 --> 00:16:15,680
seat

466
00:16:15,680 --> 00:16:17,759
or the other it can give inconsistent

467
00:16:17,759 --> 00:16:19,600
views of what happened with the

468
00:16:19,600 --> 00:16:22,560
submission of device to to clients

469
00:16:22,560 --> 00:16:24,639
and uh this is the aspect that

470
00:16:24,639 --> 00:16:26,880
introduces most of the complexity in our

471
00:16:26,880 --> 00:16:29,199
malicious protocol variant okay which i

472
00:16:29,199 --> 00:16:30,639
invite you to check in the paper i think

473
00:16:30,639 --> 00:16:33,759
is a beautiful product

474
00:16:33,759 --> 00:16:35,680
all right so as i mentioned earlier in

475
00:16:35,680 --> 00:16:38,480
the ccs 2017 protocol which follows this

476
00:16:38,480 --> 00:16:42,320
kind of high level group blueprint

477
00:16:42,320 --> 00:16:43,600
the communication graph is a complete

478
00:16:43,600 --> 00:16:45,920
graph and then we have to choose this

479
00:16:45,920 --> 00:16:47,759
threshold but in that case it's easy to

480
00:16:47,759 --> 00:16:48,839
choose right

481
00:16:48,839 --> 00:16:50,959
because you can ensure what we need

482
00:16:50,959 --> 00:16:53,440
deterministically by choosing t to be

483
00:16:53,440 --> 00:16:56,000
small less than the the minimum number

484
00:16:56,000 --> 00:16:58,160
of surviving clients because we want

485
00:16:58,160 --> 00:17:00,880
correctness we want to obtain the sum

486
00:17:00,880 --> 00:17:03,759
as long as more than

487
00:17:03,759 --> 00:17:04,480
sorry less than

488
00:17:04,480 --> 00:17:06,000
[Music]

489
00:17:06,000 --> 00:17:08,000
more than one minus delta and clients

490
00:17:08,000 --> 00:17:09,520
could survive

491
00:17:09,520 --> 00:17:11,520
that is on dropout and for security we

492
00:17:11,520 --> 00:17:12,880
just ensure that the threshold is more

493
00:17:12,880 --> 00:17:14,480
than the total number of malicious

494
00:17:14,480 --> 00:17:15,439
clients

495
00:17:15,439 --> 00:17:16,559
now in the

496
00:17:16,559 --> 00:17:18,799
2020 paper that i'm describing here we

497
00:17:18,799 --> 00:17:21,119
instead use a random regular graph for

498
00:17:21,119 --> 00:17:23,039
for the aztec communication graphs with

499
00:17:23,039 --> 00:17:25,679
n clients and key neighbors and login

500
00:17:25,679 --> 00:17:27,359
neighbors per client will be enough okay

501
00:17:27,359 --> 00:17:30,480
so we have to translate this

502
00:17:30,480 --> 00:17:32,720
conditions on t from

503
00:17:32,720 --> 00:17:35,120
one setting to the other intuitively

504
00:17:35,120 --> 00:17:37,120
so how how does that that's how does

505
00:17:37,120 --> 00:17:39,840
that go and why why a logarithmic k is

506
00:17:39,840 --> 00:17:41,280
enough

507
00:17:41,280 --> 00:17:43,120
so if you if you look at the

508
00:17:43,120 --> 00:17:45,200
distribution of uh

509
00:17:45,200 --> 00:17:46,799
so the addition let me just describe the

510
00:17:46,799 --> 00:17:48,720
intuition which is simple

511
00:17:48,720 --> 00:17:50,400
so what we would have to show is that

512
00:17:50,400 --> 00:17:52,799
the threshold t is definitely larger

513
00:17:52,799 --> 00:17:54,960
than any number of malicious neighbors

514
00:17:54,960 --> 00:17:56,480
that a client might expect with high

515
00:17:56,480 --> 00:17:59,039
probability and this is shown here in in

516
00:17:59,039 --> 00:18:00,799
blue this is a hyper geometric

517
00:18:00,799 --> 00:18:02,720
distribution which is

518
00:18:02,720 --> 00:18:04,000
the distribution followed by the number

519
00:18:04,000 --> 00:18:06,480
of dishonest neighbors of a client

520
00:18:06,480 --> 00:18:08,320
and we also want to make sure that uh

521
00:18:08,320 --> 00:18:10,160
that threshold is definitely smaller

522
00:18:10,160 --> 00:18:12,320
with the probability or the probability

523
00:18:12,320 --> 00:18:13,440
that corresponds to the correctness

524
00:18:13,440 --> 00:18:14,400
parameter

525
00:18:14,400 --> 00:18:16,160
then then that's smaller than the number

526
00:18:16,160 --> 00:18:18,000
of surviving neighbors which is shown in

527
00:18:18,000 --> 00:18:20,000
orange here and follows also a hyper

528
00:18:20,000 --> 00:18:21,840
geometric distribution and then since

529
00:18:21,840 --> 00:18:23,120
hypergeometric distributions are

530
00:18:23,120 --> 00:18:25,039
concentrated around their mean

531
00:18:25,039 --> 00:18:26,720
an overlapping number of neighbors

532
00:18:26,720 --> 00:18:28,720
instead of a linear number of numbers in

533
00:18:28,720 --> 00:18:31,200
the 2017 version

534
00:18:31,200 --> 00:18:32,480
will be enough to satisfy the

535
00:18:32,480 --> 00:18:34,240
requirements

536
00:18:34,240 --> 00:18:35,679
of this

537
00:18:35,679 --> 00:18:37,280
can you specify something are the

538
00:18:37,280 --> 00:18:39,679
neighborhood chosen advanced

539
00:18:39,679 --> 00:18:41,200
or the parties are choosing their

540
00:18:41,200 --> 00:18:42,799
neighbors

541
00:18:42,799 --> 00:18:44,160
that's a very good question so that

542
00:18:44,160 --> 00:18:46,559
depends on the on the protocol variant

543
00:18:46,559 --> 00:18:48,240
in the in the semi-image variant it's

544
00:18:48,240 --> 00:18:50,799
okay it's okay for the server to do that

545
00:18:50,799 --> 00:18:53,679
in the malicious variant that the

546
00:18:53,679 --> 00:18:54,840
clients do

547
00:18:54,840 --> 00:18:57,440
that okay so they could choose so and

548
00:18:57,440 --> 00:18:59,280
you're proving that login is enough so

549
00:18:59,280 --> 00:19:00,870
you're gonna have something

550
00:19:00,870 --> 00:19:03,600
[Music]

551
00:19:03,600 --> 00:19:05,280
okay

552
00:19:05,280 --> 00:19:07,120
thanks sorry go ahead i'm not sure if

553
00:19:07,120 --> 00:19:08,799
you want to ask something else

554
00:19:08,799 --> 00:19:11,520
i can ask at the end thanks okay so yeah

555
00:19:11,520 --> 00:19:13,120
that that's a good question i didn't

556
00:19:13,120 --> 00:19:15,760
want to get into that but uh

557
00:19:15,760 --> 00:19:18,320
we have a more efficient structure uh of

558
00:19:18,320 --> 00:19:21,039
the graph for the seminars variant and

559
00:19:21,039 --> 00:19:23,280
for the dishonest variant clients have

560
00:19:23,280 --> 00:19:24,400
to choose themselves

561
00:19:24,400 --> 00:19:26,160
without relying on the

562
00:19:26,160 --> 00:19:28,000
on the server and you have to pay a

563
00:19:28,000 --> 00:19:31,360
factor of two or so in the in the in k

564
00:19:31,360 --> 00:19:33,679
but still logarithmic

565
00:19:33,679 --> 00:19:35,039
and still i'm still building concrete

566
00:19:35,039 --> 00:19:37,520
efficiency

567
00:19:37,600 --> 00:19:38,400
so

568
00:19:38,400 --> 00:19:40,480
that observation

569
00:19:40,480 --> 00:19:42,320
to some extent gives us hopefully

570
00:19:42,320 --> 00:19:44,880
convince you that uh

571
00:19:44,880 --> 00:19:46,240
and

572
00:19:46,240 --> 00:19:48,559
this we now have uh constrained to the

573
00:19:48,559 --> 00:19:50,559
probabilistic and that

574
00:19:50,559 --> 00:19:52,720
k or the log n is enough to

575
00:19:52,720 --> 00:19:54,799
satisfy

576
00:19:54,799 --> 00:19:57,600
the the requirements

577
00:19:57,600 --> 00:19:59,200
given a statistical security parameter

578
00:19:59,200 --> 00:20:02,240
sigma and a correctness parameter eta

579
00:20:02,240 --> 00:20:04,159
so that's the idea

580
00:20:04,159 --> 00:20:05,760
now in terms of asymptotics i want i

581
00:20:05,760 --> 00:20:08,320
won't say much here but uh other than

582
00:20:08,320 --> 00:20:09,520
that

583
00:20:09,520 --> 00:20:12,159
an end turned into a log n

584
00:20:12,159 --> 00:20:14,320
uh which improves everything you can see

585
00:20:14,320 --> 00:20:15,760
in the table going from the first row to

586
00:20:15,760 --> 00:20:18,400
the second row and uh in particular i

587
00:20:18,400 --> 00:20:21,039
want to focus on on client computation

588
00:20:21,039 --> 00:20:21,840
here

589
00:20:21,840 --> 00:20:24,960
so this times n times l client cost was

590
00:20:24,960 --> 00:20:27,360
kind of limit a limiting factor

591
00:20:27,360 --> 00:20:29,679
and we turn that into essentially an log

592
00:20:29,679 --> 00:20:31,200
n sorry l

593
00:20:31,200 --> 00:20:33,520
log n where l is the length of the

594
00:20:33,520 --> 00:20:35,200
input vector

595
00:20:35,200 --> 00:20:38,080
and that

596
00:20:38,400 --> 00:20:40,720
change the whole the whole bottleneck in

597
00:20:40,720 --> 00:20:43,919
this protocol essentially

598
00:20:44,480 --> 00:20:46,840
so the malicious case is

599
00:20:46,840 --> 00:20:49,280
similar as we manage to protect against

600
00:20:49,280 --> 00:20:50,240
attack where the server gives

601
00:20:50,240 --> 00:20:52,320
inconsistent views of who dropped out to

602
00:20:52,320 --> 00:20:53,840
clients

603
00:20:53,840 --> 00:20:56,080
and we did that only using polylock and

604
00:20:56,080 --> 00:20:59,280
communication per client

605
00:20:59,360 --> 00:21:01,360
again i think that's

606
00:21:01,360 --> 00:21:02,880
that's a beautiful part of that paper

607
00:21:02,880 --> 00:21:04,880
and i invite you to take a look but yes

608
00:21:04,880 --> 00:21:06,720
we only have an extra

609
00:21:06,720 --> 00:21:09,120
log square and factor and that's related

610
00:21:09,120 --> 00:21:12,159
to antigone's question

611
00:21:12,159 --> 00:21:14,000
all right um

612
00:21:14,000 --> 00:21:19,280
in terms of um so even if the analytical

613
00:21:19,440 --> 00:21:21,440
bounds for number of neighbors and

614
00:21:21,440 --> 00:21:22,640
threshold that follow from the

615
00:21:22,640 --> 00:21:24,000
observation that i give you are pretty

616
00:21:24,000 --> 00:21:25,919
good one can

617
00:21:25,919 --> 00:21:27,440
make the observation that for for

618
00:21:27,440 --> 00:21:29,520
concrete parameter settings one can just

619
00:21:29,520 --> 00:21:32,240
find find this knt numerically and that

620
00:21:32,240 --> 00:21:33,440
boils down

621
00:21:33,440 --> 00:21:35,440
to see essentially a serious square of

622
00:21:35,440 --> 00:21:36,640
queries on

623
00:21:36,640 --> 00:21:39,200
the cdf of a hyperdramatic distribution

624
00:21:39,200 --> 00:21:41,679
and just to give you an example of how

625
00:21:41,679 --> 00:21:44,000
good the constant inside the big

626
00:21:44,000 --> 00:21:46,159
notation that i'll show you are

627
00:21:46,159 --> 00:21:49,280
with 500 neighbors per client we can

628
00:21:49,280 --> 00:21:51,600
handle

629
00:21:51,600 --> 00:21:54,480
instances with number of clients up to

630
00:21:54,480 --> 00:21:57,600
an over a billion clients while the ccs

631
00:21:57,600 --> 00:21:59,520
2017 paper

632
00:21:59,520 --> 00:22:01,360
needed uh

633
00:22:01,360 --> 00:22:04,400
of course at about a thousand clients

634
00:22:04,400 --> 00:22:06,559
a thousand neighbors for the for the

635
00:22:06,559 --> 00:22:08,880
an instant with uh 10 000 clients okay

636
00:22:08,880 --> 00:22:09,919
so this

637
00:22:09,919 --> 00:22:11,360
these improvements are really really

638
00:22:11,360 --> 00:22:12,400
dramatic

639
00:22:12,400 --> 00:22:15,440
in terms of client computation

640
00:22:15,440 --> 00:22:16,799
now

641
00:22:16,799 --> 00:22:18,159
to give you another data point in terms

642
00:22:18,159 --> 00:22:20,240
of concrete efficiency with only with

643
00:22:20,240 --> 00:22:21,679
one million clients or five percent

644
00:22:21,679 --> 00:22:23,440
dishonest clients and a maximum of a

645
00:22:23,440 --> 00:22:25,520
maximum of 30 dropouts

646
00:22:25,520 --> 00:22:27,760
less than 100 neighbors are enough

647
00:22:27,760 --> 00:22:28,640
and

648
00:22:28,640 --> 00:22:30,240
as i said earlier we can go over a

649
00:22:30,240 --> 00:22:31,520
billion clients in terms of client

650
00:22:31,520 --> 00:22:35,520
computation and if the malicious variant

651
00:22:35,520 --> 00:22:38,159
in a similar setting with 10 000

652
00:22:38,159 --> 00:22:40,960
clients 600 random neighbors are kleiner

653
00:22:40,960 --> 00:22:42,960
enough to ensure that to every honest

654
00:22:42,960 --> 00:22:45,039
client that their value is related with

655
00:22:45,039 --> 00:22:47,360
4 500 honest clients okay so this is the

656
00:22:47,360 --> 00:22:49,360
guarantee that you end up giving to to

657
00:22:49,360 --> 00:22:51,200
the client that is the user

658
00:22:51,200 --> 00:22:53,679
in in this protocol

659
00:22:53,679 --> 00:22:55,440
and i also mentioned earlier our

660
00:22:55,440 --> 00:22:57,520
security primitive that is also

661
00:22:57,520 --> 00:22:59,120
predicted in the paper which clearly

662
00:22:59,120 --> 00:23:00,640
we'll discuss next

663
00:23:00,640 --> 00:23:02,240
and then i'll just i'll conclude now

664
00:23:02,240 --> 00:23:04,400
this section of our joint talk

665
00:23:04,400 --> 00:23:06,480
and i'd like to say that as we get

666
00:23:06,480 --> 00:23:08,559
closer to the cost of computing in the

667
00:23:08,559 --> 00:23:10,159
clear which is

668
00:23:10,159 --> 00:23:12,000
is to some extent happening in this kind

669
00:23:12,000 --> 00:23:14,159
of protocol the crypto stops being a

670
00:23:14,159 --> 00:23:16,480
bottleneck so client compensation is

671
00:23:16,480 --> 00:23:18,240
it's not a bottleneck anymore for

672
00:23:18,240 --> 00:23:21,520
example and all of a sudden you know

673
00:23:21,520 --> 00:23:24,080
issues around good uh systems design

674
00:23:24,080 --> 00:23:25,919
like load balancing handling or after

675
00:23:25,919 --> 00:23:28,159
pouch finalization and so on that

676
00:23:28,159 --> 00:23:30,480
becomes like a pressing issue to scale

677
00:23:30,480 --> 00:23:32,640
this protocol so

678
00:23:32,640 --> 00:23:34,799
and i believe this is the the case uh

679
00:23:34,799 --> 00:23:36,400
after this work right so

680
00:23:36,400 --> 00:23:38,559
we have the crypto being the bottleneck

681
00:23:38,559 --> 00:23:40,240
and now

682
00:23:40,240 --> 00:23:41,440
it stopped being the bottom lane which

683
00:23:41,440 --> 00:23:42,559
is a very

684
00:23:42,559 --> 00:23:44,400
very satisfying

685
00:23:44,400 --> 00:23:46,240
uh thing to say from a cryptographic

686
00:23:46,240 --> 00:23:47,679
point of view i think so i wanted to

687
00:23:47,679 --> 00:23:49,600
share that here

688
00:23:49,600 --> 00:23:51,279
and that's it from my site i'll pass it

689
00:23:51,279 --> 00:23:54,320
on back to kaylee

690
00:23:58,080 --> 00:23:59,679
all right thanks sergio

691
00:23:59,679 --> 00:24:02,480
so um we just heard about a secure

692
00:24:02,480 --> 00:24:04,960
aggregation at scale where scale is

693
00:24:04,960 --> 00:24:07,360
taken to be the number of clients that

694
00:24:07,360 --> 00:24:09,360
we could work over but one of the things

695
00:24:09,360 --> 00:24:11,440
we discover is once you start thinking

696
00:24:11,440 --> 00:24:12,240
about

697
00:24:12,240 --> 00:24:15,360
what can i do with millions or hundreds

698
00:24:15,360 --> 00:24:17,919
of millions of clients the kinds of

699
00:24:17,919 --> 00:24:19,760
models that people start wanting to

700
00:24:19,760 --> 00:24:21,840
train get much larger with all of those

701
00:24:21,840 --> 00:24:24,000
clients you get a lot more data and

702
00:24:24,000 --> 00:24:25,679
there's a lot more nuance that you can

703
00:24:25,679 --> 00:24:30,000
hope to extract from that data privately

704
00:24:30,000 --> 00:24:33,279
while a in order to provide better user

705
00:24:33,279 --> 00:24:35,440
experiences but to get to that nuance

706
00:24:35,440 --> 00:24:37,360
you often need more parameters in your

707
00:24:37,360 --> 00:24:39,678
model

708
00:24:40,080 --> 00:24:40,919
those

709
00:24:40,919 --> 00:24:42,480
parameters

710
00:24:42,480 --> 00:24:44,480
show up um in a bunch of different ways

711
00:24:44,480 --> 00:24:46,960
you end up seeing very large models that

712
00:24:46,960 --> 00:24:48,880
end up having often

713
00:24:48,880 --> 00:24:52,320
a sparsity to them so a couple ways that

714
00:24:52,320 --> 00:24:54,159
you can end up finding yourself in a

715
00:24:54,159 --> 00:24:56,720
sparse setting with federated learning

716
00:24:56,720 --> 00:24:58,960
is if your one day class is embedding

717
00:24:58,960 --> 00:25:01,200
based models so these are things like um

718
00:25:01,200 --> 00:25:02,720
you're trying to train a natural

719
00:25:02,720 --> 00:25:04,480
language model and you have a layer in

720
00:25:04,480 --> 00:25:06,000
your neural network

721
00:25:06,000 --> 00:25:08,159
where there is a set of parameters

722
00:25:08,159 --> 00:25:10,799
associated with every word and those

723
00:25:10,799 --> 00:25:13,039
parameters will only be updated by a

724
00:25:13,039 --> 00:25:15,440
particular user if that user has had

725
00:25:15,440 --> 00:25:17,600
experience with that word

726
00:25:17,600 --> 00:25:19,279
similarly for an object recognition

727
00:25:19,279 --> 00:25:21,279
model you might find yourself with a set

728
00:25:21,279 --> 00:25:23,039
of parameters for each object you're

729
00:25:23,039 --> 00:25:25,200
trying to recognize and those parameters

730
00:25:25,200 --> 00:25:27,200
might only be updated if you've observed

731
00:25:27,200 --> 00:25:28,960
that object

732
00:25:28,960 --> 00:25:31,360
another class of large sparse models

733
00:25:31,360 --> 00:25:33,200
that we see are compound models where

734
00:25:33,200 --> 00:25:36,000
you have multiple copies of some smaller

735
00:25:36,000 --> 00:25:36,880
model

736
00:25:36,880 --> 00:25:38,720
so you might have a copy of a model for

737
00:25:38,720 --> 00:25:41,279
say each location or each company or

738
00:25:41,279 --> 00:25:42,480
some other

739
00:25:42,480 --> 00:25:43,840
um

740
00:25:43,840 --> 00:25:46,880
set of items in a domain and you want to

741
00:25:46,880 --> 00:25:48,159
conceal

742
00:25:48,159 --> 00:25:50,480
in a private setting which domains a

743
00:25:50,480 --> 00:25:52,159
particular or sorry which items in the

744
00:25:52,159 --> 00:25:54,320
domain a particular user interacted with

745
00:25:54,320 --> 00:25:56,720
but still train an individual model for

746
00:25:56,720 --> 00:25:58,799
within each of those domains

747
00:25:58,799 --> 00:26:00,400
similarly you might think of trying to

748
00:26:00,400 --> 00:26:03,520
train a model with genres or clusters of

749
00:26:03,520 --> 00:26:06,559
data or other pluralistic models

750
00:26:06,559 --> 00:26:08,080
finally you know we've been talking

751
00:26:08,080 --> 00:26:10,320
mostly about learning in this context

752
00:26:10,320 --> 00:26:11,919
but there's another large scope of

753
00:26:11,919 --> 00:26:13,520
federation that we're interested in

754
00:26:13,520 --> 00:26:15,919
which is analytics this is the idea of

755
00:26:15,919 --> 00:26:18,159
instead of trying to train a large

756
00:26:18,159 --> 00:26:20,320
neural network for example

757
00:26:20,320 --> 00:26:22,080
instead trying to compute things that

758
00:26:22,080 --> 00:26:24,240
you might expect to compute from say an

759
00:26:24,240 --> 00:26:26,559
analytics query and this arises very

760
00:26:26,559 --> 00:26:28,000
naturally when you start to think about

761
00:26:28,000 --> 00:26:30,320
the task of say an ml engineer who needs

762
00:26:30,320 --> 00:26:32,000
to understand

763
00:26:32,000 --> 00:26:34,400
how is their model performing

764
00:26:34,400 --> 00:26:36,799
either before release or after release

765
00:26:36,799 --> 00:26:39,360
or other fundamental characteristics of

766
00:26:39,360 --> 00:26:41,279
the data set that they're working with

767
00:26:41,279 --> 00:26:44,080
outside of the process of specifically

768
00:26:44,080 --> 00:26:46,000
training the model

769
00:26:46,000 --> 00:26:47,520
so in those settings you might be trying

770
00:26:47,520 --> 00:26:49,919
to say extract a histogram from some set

771
00:26:49,919 --> 00:26:52,159
of data and each user only contributes

772
00:26:52,159 --> 00:26:54,080
to a small number of cells within that

773
00:26:54,080 --> 00:26:58,480
histogram another example of sparsity

774
00:26:58,720 --> 00:27:00,080
so when we think about the federated

775
00:27:00,080 --> 00:27:02,559
learning setup in the context of the of

776
00:27:02,559 --> 00:27:04,480
these sparse

777
00:27:04,480 --> 00:27:06,159
domains

778
00:27:06,159 --> 00:27:08,000
you know we think about federated

779
00:27:08,000 --> 00:27:09,360
learning where we're taking the current

780
00:27:09,360 --> 00:27:11,039
version of the model bringing it to

781
00:27:11,039 --> 00:27:13,919
device computing an update on one device

782
00:27:13,919 --> 00:27:15,600
and then aggregating across a large

783
00:27:15,600 --> 00:27:16,960
number of devices

784
00:27:16,960 --> 00:27:19,120
but if a particular device only has a

785
00:27:19,120 --> 00:27:21,039
very small amount of data relative to

786
00:27:21,039 --> 00:27:23,200
these large sparse models it's likely

787
00:27:23,200 --> 00:27:25,279
the case that that data is only relevant

788
00:27:25,279 --> 00:27:27,679
to a small piece of those large sparse

789
00:27:27,679 --> 00:27:29,279
models so what we really might want to

790
00:27:29,279 --> 00:27:31,919
do is download just the part of the

791
00:27:31,919 --> 00:27:34,399
model that this device has data that's

792
00:27:34,399 --> 00:27:37,279
relevant to it update just that part on

793
00:27:37,279 --> 00:27:39,840
device and then do an aggregation across

794
00:27:39,840 --> 00:27:41,919
all the devices that have you know

795
00:27:41,919 --> 00:27:44,720
sparse updates going into a full model

796
00:27:44,720 --> 00:27:46,960
size update on the server so we want

797
00:27:46,960 --> 00:27:49,279
sparse model sparse sliced model

798
00:27:49,279 --> 00:27:52,240
download and sparse aggregation

799
00:27:52,240 --> 00:27:53,440
and of course

800
00:27:53,440 --> 00:27:55,919
the choice of which slices of the model

801
00:27:55,919 --> 00:27:57,679
a particular device is going to interact

802
00:27:57,679 --> 00:28:00,640
with depends on what data is on that

803
00:28:00,640 --> 00:28:03,440
device and so really what we want is

804
00:28:03,440 --> 00:28:05,200
private versions of both of those

805
00:28:05,200 --> 00:28:07,840
functionalities

806
00:28:07,840 --> 00:28:10,240
so on the private sliced model download

807
00:28:10,240 --> 00:28:12,000
this corresponds naturally to the

808
00:28:12,000 --> 00:28:13,840
private information retrieval domain

809
00:28:13,840 --> 00:28:15,919
which is most likely familiar to many of

810
00:28:15,919 --> 00:28:17,279
the folks in this room so i'm going to

811
00:28:17,279 --> 00:28:18,960
move quickly through it

812
00:28:18,960 --> 00:28:22,159
the idea is that a device can download

813
00:28:22,159 --> 00:28:25,120
one of a set of files from the server

814
00:28:25,120 --> 00:28:28,000
and the choice of which file to download

815
00:28:28,000 --> 00:28:29,600
remains

816
00:28:29,600 --> 00:28:31,279
private to the device

817
00:28:31,279 --> 00:28:34,080
so in this case we can think about each

818
00:28:34,080 --> 00:28:37,279
of the slices of the model as a separate

819
00:28:37,279 --> 00:28:39,039
file to be offered by a private

820
00:28:39,039 --> 00:28:41,120
information table and you can kind of

821
00:28:41,120 --> 00:28:43,360
think about a vector where each element

822
00:28:43,360 --> 00:28:45,120
of the vector is one of these model

823
00:28:45,120 --> 00:28:46,399
slices

824
00:28:46,399 --> 00:28:48,480
and then the device can form a query

825
00:28:48,480 --> 00:28:50,559
which is a one hot vector

826
00:28:50,559 --> 00:28:53,039
um with a one corresponding to the model

827
00:28:53,039 --> 00:28:55,039
slice that it wants to download

828
00:28:55,039 --> 00:28:57,120
encrypt that query using a homomorphic

829
00:28:57,120 --> 00:28:59,520
cryptosystem and then the inner product

830
00:28:59,520 --> 00:29:02,159
of that query vector with the vector

831
00:29:02,159 --> 00:29:04,480
models

832
00:29:10,080 --> 00:29:12,720
slices is an encryption all of that

833
00:29:12,720 --> 00:29:14,720
inside a homomorphic cryptosystem where

834
00:29:14,720 --> 00:29:16,240
only the device has the key to decrypt

835
00:29:16,240 --> 00:29:17,600
the result the server never gets to

836
00:29:17,600 --> 00:29:18,960
learn anything about which slice was

837
00:29:18,960 --> 00:29:20,080
downloaded

838
00:29:20,080 --> 00:29:21,679
so that's a rough schema for how we can

839
00:29:21,679 --> 00:29:22,880
do the

840
00:29:22,880 --> 00:29:23,760
the

841
00:29:23,760 --> 00:29:24,799
private

842
00:29:24,799 --> 00:29:28,799
slice download for for these models

843
00:29:28,799 --> 00:29:31,120
turning to the sparse aggregation side

844
00:29:31,120 --> 00:29:34,000
of things as audrey i alluded to earlier

845
00:29:34,000 --> 00:29:36,000
one of the ways to go after this problem

846
00:29:36,000 --> 00:29:37,840
is to think about it as a shuffling

847
00:29:37,840 --> 00:29:39,600
problem instead there's actually several

848
00:29:39,600 --> 00:29:41,360
ways you could go about this but for for

849
00:29:41,360 --> 00:29:42,640
brevity today i'm just going to talk

850
00:29:42,640 --> 00:29:45,679
about the shuffling version

851
00:29:45,679 --> 00:29:46,559
so one

852
00:29:46,559 --> 00:29:49,039
one interesting thing you can do is use

853
00:29:49,039 --> 00:29:51,039
the secure aggregation protocol that

854
00:29:51,039 --> 00:29:53,679
adria described earlier to bootstrap a

855
00:29:53,679 --> 00:29:55,279
shuffling protocol

856
00:29:55,279 --> 00:29:57,600
and the idea here is you could imagine

857
00:29:57,600 --> 00:29:59,440
taking a vector

858
00:29:59,440 --> 00:30:01,120
that has

859
00:30:01,120 --> 00:30:03,120
message size slices where our messages

860
00:30:03,120 --> 00:30:04,640
here you might think about them as

861
00:30:04,640 --> 00:30:07,600
roughly a particular model slice

862
00:30:07,600 --> 00:30:10,080
and so we take a vector where the slices

863
00:30:10,080 --> 00:30:12,799
or whether the slots are the size of

864
00:30:12,799 --> 00:30:15,279
whatever update the the device is trying

865
00:30:15,279 --> 00:30:17,760
to send and each device is just going to

866
00:30:17,760 --> 00:30:19,440
choose a random slot to put their

867
00:30:19,440 --> 00:30:21,279
message in and you might hope that if

868
00:30:21,279 --> 00:30:24,559
you have a large vector that

869
00:30:24,559 --> 00:30:27,520
the devices will choose um

870
00:30:27,520 --> 00:30:29,120
even with independent choice they will

871
00:30:29,120 --> 00:30:32,559
just happen to luckily choose random

872
00:30:32,559 --> 00:30:34,640
spots that no one else has chosen and at

873
00:30:34,640 --> 00:30:36,720
least most of those messages will will

874
00:30:36,720 --> 00:30:38,960
get through and that's a simple way to

875
00:30:38,960 --> 00:30:40,960
start but unfortunately due to the the

876
00:30:40,960 --> 00:30:43,520
birthday paradox it turns out that even

877
00:30:43,520 --> 00:30:45,520
for quite large vectors you end up

878
00:30:45,520 --> 00:30:47,360
getting quite a lot of conflicts very

879
00:30:47,360 --> 00:30:48,399
easily

880
00:30:48,399 --> 00:30:51,120
very often so there's actually a more

881
00:30:51,120 --> 00:30:53,520
clever thing that you can do which is to

882
00:30:53,520 --> 00:30:55,919
build off of invertible bloom look

883
00:30:55,919 --> 00:30:58,799
tables so now what we're going to do

884
00:30:58,799 --> 00:31:02,480
is have each of our client devices first

885
00:31:02,480 --> 00:31:03,200
ch

886
00:31:03,200 --> 00:31:05,200
choose a random pseudonym so just a

887
00:31:05,200 --> 00:31:07,440
random identifier for themselves

888
00:31:07,440 --> 00:31:10,000
and we're going to use k hash functions

889
00:31:10,000 --> 00:31:13,039
where we take the hash of the pseudonym

890
00:31:13,039 --> 00:31:15,120
under each of the k hash functions and

891
00:31:15,120 --> 00:31:18,640
that selects a slot in our in our vector

892
00:31:18,640 --> 00:31:20,480
that the ser that the devices are going

893
00:31:20,480 --> 00:31:22,480
to place their messages into

894
00:31:22,480 --> 00:31:24,480
so each device is going to place k

895
00:31:24,480 --> 00:31:26,880
copies of their message and every time

896
00:31:26,880 --> 00:31:28,000
they place their message they're

897
00:31:28,000 --> 00:31:29,279
actually going to concatenate it with

898
00:31:29,279 --> 00:31:31,840
their pseudonym as well so you end up

899
00:31:31,840 --> 00:31:35,039
with pseudonym message pairs going into

900
00:31:35,039 --> 00:31:38,880
k randomly chosen slots in this vector

901
00:31:38,880 --> 00:31:41,279
so on the surface you might say well

902
00:31:41,279 --> 00:31:42,960
you just made the problem worse because

903
00:31:42,960 --> 00:31:44,880
now you're putting bigger messages into

904
00:31:44,880 --> 00:31:47,039
these slots and you're putting k copies

905
00:31:47,039 --> 00:31:49,519
into the slide haven't you just

906
00:31:49,519 --> 00:31:51,200
made it more likely to get conflicts out

907
00:31:51,200 --> 00:31:53,360
of any particular size vector

908
00:31:53,360 --> 00:31:54,799
but what you can do

909
00:31:54,799 --> 00:31:56,399
is

910
00:31:56,399 --> 00:32:00,159
for some slots it is like likely that

911
00:32:00,159 --> 00:32:02,399
there will be a single unconflicted copy

912
00:32:02,399 --> 00:32:04,480
of the message in there and you can pull

913
00:32:04,480 --> 00:32:07,120
all of those out recovering both the

914
00:32:07,120 --> 00:32:09,360
message and the pseudonym that was used

915
00:32:09,360 --> 00:32:10,799
to choose the placement of those

916
00:32:10,799 --> 00:32:12,080
messages

917
00:32:12,080 --> 00:32:13,679
once you have the pseudonym the server

918
00:32:13,679 --> 00:32:15,679
also knows the hash function

919
00:32:15,679 --> 00:32:18,399
that all of the devices were using so it

920
00:32:18,399 --> 00:32:20,159
can take that those hash functions in

921
00:32:20,159 --> 00:32:21,840
the pseudonym and figure out all of the

922
00:32:21,840 --> 00:32:24,080
places where those messages were placed

923
00:32:24,080 --> 00:32:25,440
in the vector

924
00:32:25,440 --> 00:32:28,320
it can then remove a copy of all of

925
00:32:28,320 --> 00:32:30,240
those messages remember

926
00:32:30,240 --> 00:32:32,559
these were all aggregated using secure

927
00:32:32,559 --> 00:32:34,080
aggregation essentially adding them

928
00:32:34,080 --> 00:32:36,159
together so the server can just subtract

929
00:32:36,159 --> 00:32:37,279
off

930
00:32:37,279 --> 00:32:39,360
all of the copies of the of the

931
00:32:39,360 --> 00:32:42,000
pseudonym message pairs from the vector

932
00:32:42,000 --> 00:32:44,480
and what you end up with is newly

933
00:32:44,480 --> 00:32:47,440
deconflicted slots so now you can go

934
00:32:47,440 --> 00:32:49,279
back and repeat this process and keep

935
00:32:49,279 --> 00:32:51,840
repeating it pulling out more and more

936
00:32:51,840 --> 00:32:54,159
messages until either you've extracted

937
00:32:54,159 --> 00:32:56,159
all the messages in the vector or you

938
00:32:56,159 --> 00:32:58,080
can make no more progress

939
00:32:58,080 --> 00:33:00,320
and the interesting thing here is that

940
00:33:00,320 --> 00:33:02,159
if you follow this process and you use

941
00:33:02,159 --> 00:33:06,240
say three copies or three hash functions

942
00:33:06,240 --> 00:33:08,480
a vector length of approximately 1.3

943
00:33:08,480 --> 00:33:09,840
times the total number of messages

944
00:33:09,840 --> 00:33:12,559
you're trying to transmit works out to

945
00:33:12,559 --> 00:33:13,519
give you

946
00:33:13,519 --> 00:33:15,600
a nearly

947
00:33:15,600 --> 00:33:17,039
complete confidence that you're going to

948
00:33:17,039 --> 00:33:21,200
recover all of your messages perfectly

949
00:33:21,440 --> 00:33:22,880
so from here i'm going to hand the talk

950
00:33:22,880 --> 00:33:25,039
over to peter to talk about how we can

951
00:33:25,039 --> 00:33:26,960
use those primitives to build into

952
00:33:26,960 --> 00:33:30,559
distributed differential privacy

953
00:33:36,480 --> 00:33:38,399
all right thanks uh kelly and hi

954
00:33:38,399 --> 00:33:40,880
everyone let me just hit the present

955
00:33:40,880 --> 00:33:42,320
button okay

956
00:33:42,320 --> 00:33:44,640
so well in this last part of the talk

957
00:33:44,640 --> 00:33:46,880
we're going to see how we actually can

958
00:33:46,880 --> 00:33:48,640
do distributed differential privacy at

959
00:33:48,640 --> 00:33:49,679
scale

960
00:33:49,679 --> 00:33:52,159
and let me remind you as kalista said in

961
00:33:52,159 --> 00:33:54,000
the beginning of the talk

962
00:33:54,000 --> 00:33:55,840
there's several ways in which we can

963
00:33:55,840 --> 00:33:58,080
distribute trust in this part of the

964
00:33:58,080 --> 00:34:00,320
talk we're going to focus on building a

965
00:34:00,320 --> 00:34:01,919
distributed system of differential

966
00:34:01,919 --> 00:34:04,720
privacy on top of a cryptographic

967
00:34:04,720 --> 00:34:06,320
protocol which is secure aggregation

968
00:34:06,320 --> 00:34:08,480
which adria talked about

969
00:34:08,480 --> 00:34:10,480
so secure aggregation is a complex

970
00:34:10,480 --> 00:34:12,879
protocol adria walked us through some of

971
00:34:12,879 --> 00:34:14,560
the details of how to make it efficient

972
00:34:14,560 --> 00:34:16,560
in its scale but for the rest of this

973
00:34:16,560 --> 00:34:18,079
talk we're going to think about it as a

974
00:34:18,079 --> 00:34:21,040
closed box that performs integer modulo

975
00:34:21,040 --> 00:34:22,719
summations this is just going to

976
00:34:22,719 --> 00:34:24,719
simplify the analysis and the

977
00:34:24,719 --> 00:34:26,399
explanation

978
00:34:26,399 --> 00:34:28,079
so just think about it as an integer

979
00:34:28,079 --> 00:34:29,760
modulo box

980
00:34:29,760 --> 00:34:32,000
all right so one might ask well why

981
00:34:32,000 --> 00:34:34,320
don't i just add gaussian noise locally

982
00:34:34,320 --> 00:34:36,399
i add small little gaussian noise on

983
00:34:36,399 --> 00:34:37,760
each device

984
00:34:37,760 --> 00:34:39,599
and then i rely on the fact that i'm

985
00:34:39,599 --> 00:34:40,960
going to sum all these shares of

986
00:34:40,960 --> 00:34:43,199
gaussian noise to get the amount of

987
00:34:43,199 --> 00:34:45,119
noise that i need on the server wouldn't

988
00:34:45,119 --> 00:34:47,040
that work anyway i have the secure

989
00:34:47,040 --> 00:34:48,800
aggregation box

990
00:34:48,800 --> 00:34:50,639
now there are multiple flaws in this

991
00:34:50,639 --> 00:34:51,599
thinking

992
00:34:51,599 --> 00:34:53,760
the first of which is that as you recall

993
00:34:53,760 --> 00:34:55,359
in the previous slide

994
00:34:55,359 --> 00:34:57,839
secure aggregation itself does integer

995
00:34:57,839 --> 00:35:00,000
modulo arithmetic so we cannot just

996
00:35:00,000 --> 00:35:01,839
think about these continuous

997
00:35:01,839 --> 00:35:03,520
distributions such as continuous

998
00:35:03,520 --> 00:35:06,560
gaussian or laplace so we need to

999
00:35:06,560 --> 00:35:09,040
discretize the data in a clever way and

1000
00:35:09,040 --> 00:35:10,640
this cleverness is interesting and

1001
00:35:10,640 --> 00:35:12,079
important because we don't want to

1002
00:35:12,079 --> 00:35:14,400
inflate the sensitivity of the query and

1003
00:35:14,400 --> 00:35:17,280
i'll talk about it a little bit later on

1004
00:35:17,280 --> 00:35:19,599
and we cannot add continuous noise

1005
00:35:19,599 --> 00:35:21,440
more importantly communication and

1006
00:35:21,440 --> 00:35:23,680
federated learning ends up being an

1007
00:35:23,680 --> 00:35:25,200
important bottleneck in practice

1008
00:35:25,200 --> 00:35:26,880
especially as we scale to these large

1009
00:35:26,880 --> 00:35:29,119
models with millions of parameters we

1010
00:35:29,119 --> 00:35:32,160
want to use as little bits as possible

1011
00:35:32,160 --> 00:35:34,560
to transmit each coordinate of the model

1012
00:35:34,560 --> 00:35:36,480
and we don't want this communication

1013
00:35:36,480 --> 00:35:38,160
bandwidth constrained

1014
00:35:38,160 --> 00:35:42,320
to mess with our dp guarantee

1015
00:35:42,320 --> 00:35:44,320
and once we start talking about these

1016
00:35:44,320 --> 00:35:46,640
discrete mechanisms such as randomized

1017
00:35:46,640 --> 00:35:48,800
response and rapport and others if you

1018
00:35:48,800 --> 00:35:50,880
are familiar with these mechanisms it's

1019
00:35:50,880 --> 00:35:53,599
just really difficult to analyze the sum

1020
00:35:53,599 --> 00:35:56,320
of these mechanisms precisely especially

1021
00:35:56,320 --> 00:35:58,000
in high dimensions so we need something

1022
00:35:58,000 --> 00:36:00,560
that somehow we can either analyze the

1023
00:36:00,560 --> 00:36:04,000
sum exactly or approximately but in high

1024
00:36:04,000 --> 00:36:06,480
dimensions and very accurately we also

1025
00:36:06,480 --> 00:36:09,040
want mechanisms that allow us to give a

1026
00:36:09,040 --> 00:36:10,800
ready differential privacy guarantee or

1027
00:36:10,800 --> 00:36:12,320
a concentrated differential privacy

1028
00:36:12,320 --> 00:36:14,240
guarantee because we want to do

1029
00:36:14,240 --> 00:36:16,000
budgeting we're going to run this

1030
00:36:16,000 --> 00:36:18,079
process for thousands of iterations to

1031
00:36:18,079 --> 00:36:20,320
train a high quality model so we want to

1032
00:36:20,320 --> 00:36:22,240
be able to track the privacy budget and

1033
00:36:22,240 --> 00:36:24,480
as tight of a fashion as possible

1034
00:36:24,480 --> 00:36:26,560
and finally we want to be able to sample

1035
00:36:26,560 --> 00:36:29,119
from this noise on the device

1036
00:36:29,119 --> 00:36:30,800
very efficiently and exactly we don't

1037
00:36:30,800 --> 00:36:33,599
want somehow to have to do floating

1038
00:36:33,599 --> 00:36:36,160
point uh operations because we don't

1039
00:36:36,160 --> 00:36:38,480
usually have access to those or they

1040
00:36:38,480 --> 00:36:40,880
might mess with the dp guarantees all

1041
00:36:40,880 --> 00:36:43,040
right so with all those challenges let's

1042
00:36:43,040 --> 00:36:44,960
look at how we can build a distributed

1043
00:36:44,960 --> 00:36:46,640
dp system

1044
00:36:46,640 --> 00:36:48,000
so as you can see on this slide there

1045
00:36:48,000 --> 00:36:49,760
are so many different steps involved and

1046
00:36:49,760 --> 00:36:51,200
i'm going to walk you through these

1047
00:36:51,200 --> 00:36:52,880
steps one by one

1048
00:36:52,880 --> 00:36:55,440
but first this vector x i that i'm

1049
00:36:55,440 --> 00:36:56,800
showing on the left

1050
00:36:56,800 --> 00:36:59,119
most uh side of this slide is

1051
00:36:59,119 --> 00:37:01,359
representing the model update on each

1052
00:37:01,359 --> 00:37:03,359
device so think of this x i as a high

1053
00:37:03,359 --> 00:37:05,040
dimensional vector representing the

1054
00:37:05,040 --> 00:37:08,000
model and we're going to be agnostic to

1055
00:37:08,000 --> 00:37:10,160
the optimization process that happens on

1056
00:37:10,160 --> 00:37:12,640
the device so how you arrive to this xi

1057
00:37:12,640 --> 00:37:14,640
is not relevant for this talk maybe

1058
00:37:14,640 --> 00:37:16,320
you're running an optimization routine

1059
00:37:16,320 --> 00:37:18,880
or computing a sketch of some sorts

1060
00:37:18,880 --> 00:37:20,960
all right so the first step is we clip

1061
00:37:20,960 --> 00:37:22,800
that vector and this is a typical

1062
00:37:22,800 --> 00:37:26,320
process that's done in dpsgd in order to

1063
00:37:26,320 --> 00:37:28,240
bomb the influence of that client and

1064
00:37:28,240 --> 00:37:30,320
bound the sensitivity of the query so

1065
00:37:30,320 --> 00:37:32,400
this just ensures that the l2 norm of

1066
00:37:32,400 --> 00:37:34,240
this vector is less than or equal to

1067
00:37:34,240 --> 00:37:37,839
some constant c so that's nothing new

1068
00:37:37,839 --> 00:37:39,599
hopefully to anybody

1069
00:37:39,599 --> 00:37:41,760
the second step is something new which

1070
00:37:41,760 --> 00:37:44,000
we call flattening where what we do is

1071
00:37:44,000 --> 00:37:46,560
we multiply by a random unitary matrix

1072
00:37:46,560 --> 00:37:48,800
so think of this random unitary matrix

1073
00:37:48,800 --> 00:37:51,839
as a rotation matrix and the job of this

1074
00:37:51,839 --> 00:37:55,280
rotation matrix is to spread the energy

1075
00:37:55,280 --> 00:37:58,000
of all the coordinates equally across

1076
00:37:58,000 --> 00:38:00,160
the entire vector you can see the small

1077
00:38:00,160 --> 00:38:01,839
drawing on the right hand side of the

1078
00:38:01,839 --> 00:38:04,320
slide showing you a vector where some of

1079
00:38:04,320 --> 00:38:06,160
the coordinates are large others are

1080
00:38:06,160 --> 00:38:09,599
small after we rotate we get roughly

1081
00:38:09,599 --> 00:38:12,720
uh values that are within the same range

1082
00:38:12,720 --> 00:38:16,000
so the idea here is uh when you do these

1083
00:38:16,000 --> 00:38:18,880
kinds of rotations with high probability

1084
00:38:18,880 --> 00:38:21,599
you're going to get uh entries that are

1085
00:38:21,599 --> 00:38:23,359
in a range that you know precisely and

1086
00:38:23,359 --> 00:38:25,520
these entries end up being sub-gaussian

1087
00:38:25,520 --> 00:38:27,359
now from a practical perspective how do

1088
00:38:27,359 --> 00:38:30,079
we do these rotations because this means

1089
00:38:30,079 --> 00:38:32,800
we need to allow to multiply the vector

1090
00:38:32,800 --> 00:38:34,560
by a large matrix how do we do them

1091
00:38:34,560 --> 00:38:36,800
efficiently there are many ways the

1092
00:38:36,800 --> 00:38:38,800
randomized haramar transform has the

1093
00:38:38,800 --> 00:38:40,640
properties we're looking for and the

1094
00:38:40,640 --> 00:38:42,720
randomized discrete fourier transform

1095
00:38:42,720 --> 00:38:45,119
also gives us those properties of of

1096
00:38:45,119 --> 00:38:47,280
ensuring that the uh

1097
00:38:47,280 --> 00:38:49,280
coordinates are in that range that we

1098
00:38:49,280 --> 00:38:50,560
want

1099
00:38:50,560 --> 00:38:52,320
so we're still operating on floats and

1100
00:38:52,320 --> 00:38:54,720
the next step is to go from floats to

1101
00:38:54,720 --> 00:38:56,480
integers so this is the discretization

1102
00:38:56,480 --> 00:38:57,359
step

1103
00:38:57,359 --> 00:38:59,839
and this step has two sub steps the

1104
00:38:59,839 --> 00:39:01,920
first one is scaling so we need to

1105
00:39:01,920 --> 00:39:04,720
multiply by some constant s which we're

1106
00:39:04,720 --> 00:39:07,119
going to take to be one over gamma so

1107
00:39:07,119 --> 00:39:08,640
keep that in mind

1108
00:39:08,640 --> 00:39:11,599
and this scaling stretches the signal

1109
00:39:11,599 --> 00:39:13,599
essentially and when you stretch the

1110
00:39:13,599 --> 00:39:15,599
signal what you are doing is you're

1111
00:39:15,599 --> 00:39:18,000
trying to reduce as much as possible the

1112
00:39:18,000 --> 00:39:19,680
rounding errors or the quantization

1113
00:39:19,680 --> 00:39:21,760
errors for instance if you have a value

1114
00:39:21,760 --> 00:39:24,640
of 4.2 and you multiply by a scale of 10

1115
00:39:24,640 --> 00:39:26,960
you get 42 and then now if you round to

1116
00:39:26,960 --> 00:39:29,119
the nearest integer you don't get any

1117
00:39:29,119 --> 00:39:30,320
error because

1118
00:39:30,320 --> 00:39:32,560
you've scaled by a factor of 10 already

1119
00:39:32,560 --> 00:39:34,480
so anybody who has done quantization in

1120
00:39:34,480 --> 00:39:36,880
the past knows that precision or scaling

1121
00:39:36,880 --> 00:39:39,599
is important for accuracy it's going to

1122
00:39:39,599 --> 00:39:42,000
also end up helping 4dp and you'll see

1123
00:39:42,000 --> 00:39:43,200
that in a bit

1124
00:39:43,200 --> 00:39:44,800
so after we scale

1125
00:39:44,800 --> 00:39:47,520
we do the rounding and one method to

1126
00:39:47,520 --> 00:39:49,760
take here to do randomized rounding

1127
00:39:49,760 --> 00:39:52,960
essentially round to the nearest integer

1128
00:39:52,960 --> 00:39:54,960
with a probability that's proportional

1129
00:39:54,960 --> 00:39:58,480
to how close you are to that integer

1130
00:39:58,480 --> 00:40:00,160
now it turns out that there's a problem

1131
00:40:00,160 --> 00:40:02,320
with randomized browning it's not a big

1132
00:40:02,320 --> 00:40:04,640
problem but it's a subtle small problem

1133
00:40:04,640 --> 00:40:07,440
which is when you round the vector to

1134
00:40:07,440 --> 00:40:10,000
the nearest integers probabilistically

1135
00:40:10,000 --> 00:40:12,560
the l2 norm of this vector is going to

1136
00:40:12,560 --> 00:40:14,880
get larger and this is not

1137
00:40:14,880 --> 00:40:16,640
cool for dp

1138
00:40:16,640 --> 00:40:19,040
probably you guys know that 4dp

1139
00:40:19,040 --> 00:40:21,599
uh you need to control the sensitivity

1140
00:40:21,599 --> 00:40:23,520
of the vector and with randomized

1141
00:40:23,520 --> 00:40:25,520
grounding what happens is that the l2

1142
00:40:25,520 --> 00:40:28,160
sensitivity or the l2 norm of the vector

1143
00:40:28,160 --> 00:40:30,480
grows up by a factor of about muti you

1144
00:40:30,480 --> 00:40:31,920
can show that where d is the

1145
00:40:31,920 --> 00:40:34,000
dimensionality of the value so that's

1146
00:40:34,000 --> 00:40:36,640
not very cool so what we do is we can

1147
00:40:36,640 --> 00:40:39,040
analyze a high probability bound on

1148
00:40:39,040 --> 00:40:41,359
what's going to happen to the norm of

1149
00:40:41,359 --> 00:40:44,560
the vector upon this randomized rounding

1150
00:40:44,560 --> 00:40:46,160
and what we could do is we could do

1151
00:40:46,160 --> 00:40:48,000
something called conditional randomized

1152
00:40:48,000 --> 00:40:49,680
rounding where

1153
00:40:49,680 --> 00:40:52,480
when we round we check the l2 norm

1154
00:40:52,480 --> 00:40:54,480
and if it is above

1155
00:40:54,480 --> 00:40:57,359
this high probability bound that we have

1156
00:40:57,359 --> 00:40:58,079
we

1157
00:40:58,079 --> 00:41:00,400
essentially we do the rounding again we

1158
00:41:00,400 --> 00:41:02,960
ignore that step and we redo we do it

1159
00:41:02,960 --> 00:41:04,960
again and we can show that if you do it

1160
00:41:04,960 --> 00:41:06,880
a constant number of times you're going

1161
00:41:06,880 --> 00:41:09,760
to succeed with very high probability so

1162
00:41:09,760 --> 00:41:11,599
this is easy to see

1163
00:41:11,599 --> 00:41:14,160
and this allows us to actually round to

1164
00:41:14,160 --> 00:41:17,440
something uh very close to c squared

1165
00:41:17,440 --> 00:41:20,000
which is the norm that we clipped to at

1166
00:41:20,000 --> 00:41:22,160
the beginning you can see this extra

1167
00:41:22,160 --> 00:41:24,400
term here in the blue box it has this

1168
00:41:24,400 --> 00:41:26,720
gamma and gamma is something really

1169
00:41:26,720 --> 00:41:28,560
small because we're going to scale to

1170
00:41:28,560 --> 00:41:29,839
something large

1171
00:41:29,839 --> 00:41:31,920
keep in mind that s is equal to 1

1172
00:41:31,920 --> 00:41:33,680
divided by gamma

1173
00:41:33,680 --> 00:41:37,040
so gamma is the rounding granularity

1174
00:41:37,040 --> 00:41:38,160
all right so

1175
00:41:38,160 --> 00:41:40,160
once we manage to do this conditional

1176
00:41:40,160 --> 00:41:42,800
randomized rounding step we now have a

1177
00:41:42,800 --> 00:41:46,240
proper bound on the l2 norm of the

1178
00:41:46,240 --> 00:41:49,119
vector of the rounded vector so now we

1179
00:41:49,119 --> 00:41:51,040
have an integer vector and we have a

1180
00:41:51,040 --> 00:41:53,920
proper l2 norm bound on it and that l2

1181
00:41:53,920 --> 00:41:56,720
norm is hopefully not too far from the

1182
00:41:56,720 --> 00:41:59,119
l2 norm that we clipped to at the very

1183
00:41:59,119 --> 00:42:00,160
beginning

1184
00:42:00,160 --> 00:42:01,920
which is good so now we have integer

1185
00:42:01,920 --> 00:42:05,280
data with a proper type bound on its l2

1186
00:42:05,280 --> 00:42:07,520
norm so this is now the very important

1187
00:42:07,520 --> 00:42:10,079
step for dp we need to add noise we need

1188
00:42:10,079 --> 00:42:12,560
to add integer noise so

1189
00:42:12,560 --> 00:42:14,560
for this talk we're going to use the

1190
00:42:14,560 --> 00:42:16,480
discrete gaussian noise

1191
00:42:16,480 --> 00:42:18,720
and let me try to tell you what the

1192
00:42:18,720 --> 00:42:20,720
discrete gaussian noise hopefully a lot

1193
00:42:20,720 --> 00:42:22,480
of the crypto people are familiar with

1194
00:42:22,480 --> 00:42:24,560
it because it's widely studied in the

1195
00:42:24,560 --> 00:42:26,000
lattice crypto

1196
00:42:26,000 --> 00:42:28,160
community so discrete gaussian is just a

1197
00:42:28,160 --> 00:42:29,839
discrete analog to the continuous

1198
00:42:29,839 --> 00:42:32,000
gaussian as you can see it's essentially

1199
00:42:32,000 --> 00:42:34,160
like the pdf of a gaussian but now we

1200
00:42:34,160 --> 00:42:36,400
form a pmf from it so normal the

1201
00:42:36,400 --> 00:42:38,079
normalizing constant is a little

1202
00:42:38,079 --> 00:42:39,440
different

1203
00:42:39,440 --> 00:42:41,520
and in a recent paper that appeared in

1204
00:42:41,520 --> 00:42:44,160
nurbs of last year was shown that this

1205
00:42:44,160 --> 00:42:45,920
mechanism essentially

1206
00:42:45,920 --> 00:42:48,400
has a performance that is very close to

1207
00:42:48,400 --> 00:42:50,640
the continuous gaussian mechanism so all

1208
00:42:50,640 --> 00:42:52,880
those interesting renny dp and

1209
00:42:52,880 --> 00:42:54,880
concentrated dp guarantees that you can

1210
00:42:54,880 --> 00:42:57,119
prove for the continuous gaussian

1211
00:42:57,119 --> 00:42:59,440
mechanism they carry over almost

1212
00:42:59,440 --> 00:43:02,560
unchanged to this integer version of the

1213
00:43:02,560 --> 00:43:04,960
continuous gaussian which is pretty cool

1214
00:43:04,960 --> 00:43:06,640
but there's a problem when we apply it

1215
00:43:06,640 --> 00:43:08,319
in a distributed setting

1216
00:43:08,319 --> 00:43:09,760
because when we apply it in a

1217
00:43:09,760 --> 00:43:11,760
distributed setting we need to now

1218
00:43:11,760 --> 00:43:14,480
analyze what happens to the sum of such

1219
00:43:14,480 --> 00:43:16,560
discrete gaussian variables

1220
00:43:16,560 --> 00:43:18,319
and it turns out that sums of discrete

1221
00:43:18,319 --> 00:43:21,200
gaussians is not a discrete gaussian so

1222
00:43:21,200 --> 00:43:22,960
this is this was at least to me a

1223
00:43:22,960 --> 00:43:25,440
surprise because i'm not in the lattice

1224
00:43:25,440 --> 00:43:27,280
crypto community

1225
00:43:27,280 --> 00:43:29,520
i always thought sums of gaussians is a

1226
00:43:29,520 --> 00:43:32,240
gaussian and i thought that intuition is

1227
00:43:32,240 --> 00:43:34,560
going to carry over from the continuous

1228
00:43:34,560 --> 00:43:36,480
space to the integer space but it turns

1229
00:43:36,480 --> 00:43:39,040
out that they're not actually

1230
00:43:39,040 --> 00:43:40,640
a agaves when you take a bunch of

1231
00:43:40,640 --> 00:43:42,560
discrete gaussians that are independent

1232
00:43:42,560 --> 00:43:45,119
you sum them up you're not going to get

1233
00:43:45,119 --> 00:43:47,680
a gaussian or a discrete caution but

1234
00:43:47,680 --> 00:43:49,599
what we were able to show

1235
00:43:49,599 --> 00:43:51,200
is that if you look at the max

1236
00:43:51,200 --> 00:43:53,359
divergence between the sum of two

1237
00:43:53,359 --> 00:43:56,480
discrete gaussians and you measure that

1238
00:43:56,480 --> 00:43:59,280
divergence between that sum and a

1239
00:43:59,280 --> 00:44:01,920
discrete gaussian that has the sum of

1240
00:44:01,920 --> 00:44:04,800
the variances that ends up being really

1241
00:44:04,800 --> 00:44:06,960
really small so for instance i'm showing

1242
00:44:06,960 --> 00:44:08,880
you an example on this slide if we

1243
00:44:08,880 --> 00:44:10,880
choose the variances to be

1244
00:44:10,880 --> 00:44:13,920
three for each of x and y the two

1245
00:44:13,920 --> 00:44:15,359
discrete gaussians that we're going to

1246
00:44:15,359 --> 00:44:17,920
sum then the

1247
00:44:17,920 --> 00:44:20,400
divergence max divergence between them

1248
00:44:20,400 --> 00:44:22,240
and a discrete gaussian that has the

1249
00:44:22,240 --> 00:44:23,839
variance being the sum of the two

1250
00:44:23,839 --> 00:44:26,000
variances ends up being less than 10 to

1251
00:44:26,000 --> 00:44:28,960
the negative 12. so we know that

1252
00:44:28,960 --> 00:44:30,560
even though the sum is not a discrete

1253
00:44:30,560 --> 00:44:33,119
gaussian it has to be extremely close to

1254
00:44:33,119 --> 00:44:34,960
the discrete gaussian

1255
00:44:34,960 --> 00:44:37,200
in fact this max divergence bond that we

1256
00:44:37,200 --> 00:44:39,520
derive you can extend it to high

1257
00:44:39,520 --> 00:44:41,839
dimensions you can do lots of things

1258
00:44:41,839 --> 00:44:43,599
with it and then you can use it to

1259
00:44:43,599 --> 00:44:46,720
arrive to a proper dp guarantee which

1260
00:44:46,720 --> 00:44:48,319
i'm showing on the slide and this is a

1261
00:44:48,319 --> 00:44:50,319
concentrated dp guarantee you can view

1262
00:44:50,319 --> 00:44:51,760
it also as a running differential

1263
00:44:51,760 --> 00:44:53,200
privacy guarantee

1264
00:44:53,200 --> 00:44:54,400
the one thing that i would like to

1265
00:44:54,400 --> 00:44:56,880
highlight about this result is that if

1266
00:44:56,880 --> 00:44:58,640
you look at the epsilon that i'm showing

1267
00:44:58,640 --> 00:45:00,960
in the box on the right hand side you'll

1268
00:45:00,960 --> 00:45:03,359
see the first term is this norm squared

1269
00:45:03,359 --> 00:45:06,560
divided by n times sigma squared this is

1270
00:45:06,560 --> 00:45:08,560
exactly what you would get under the

1271
00:45:08,560 --> 00:45:10,720
continuous gaussian mechanism so this

1272
00:45:10,720 --> 00:45:13,119
first order term matches exactly the

1273
00:45:13,119 --> 00:45:15,040
continuous gaussian mechanism but

1274
00:45:15,040 --> 00:45:16,960
there's now an extra penalty term which

1275
00:45:16,960 --> 00:45:19,920
is this tau times d or tau times root d

1276
00:45:19,920 --> 00:45:21,359
if you want term

1277
00:45:21,359 --> 00:45:23,359
now d is very large this is the

1278
00:45:23,359 --> 00:45:25,040
dimensionality of the model so think

1279
00:45:25,040 --> 00:45:26,880
about it as something like one million

1280
00:45:26,880 --> 00:45:28,800
or five million parameters so it's

1281
00:45:28,800 --> 00:45:30,079
really large

1282
00:45:30,079 --> 00:45:32,560
but tau ends up being extremely small

1283
00:45:32,560 --> 00:45:35,119
i'm showing the expression of tao in the

1284
00:45:35,119 --> 00:45:37,119
box as well and

1285
00:45:37,119 --> 00:45:38,720
it turns out that for all intents and

1286
00:45:38,720 --> 00:45:40,480
purposes tau ends up being something

1287
00:45:40,480 --> 00:45:43,040
like 10 to the negative 16 or 10 to the

1288
00:45:43,040 --> 00:45:46,079
negative 19. so it's a very small uh

1289
00:45:46,079 --> 00:45:49,599
parameter and it's smaller as we scale

1290
00:45:49,599 --> 00:45:51,599
the data more and more so if the

1291
00:45:51,599 --> 00:45:54,640
granularity it gets smaller and smaller

1292
00:45:54,640 --> 00:45:56,560
this tau gets even

1293
00:45:56,560 --> 00:45:58,319
you know negligible

1294
00:45:58,319 --> 00:46:00,000
so this tau times through d you can

1295
00:46:00,000 --> 00:46:01,920
essentially ignore it

1296
00:46:01,920 --> 00:46:03,680
all right so now that we've added

1297
00:46:03,680 --> 00:46:05,119
integer noise

1298
00:46:05,119 --> 00:46:07,760
after we discretized we get essentially

1299
00:46:07,760 --> 00:46:09,920
values that are unbounded those are

1300
00:46:09,920 --> 00:46:12,560
integer values right and so we still

1301
00:46:12,560 --> 00:46:14,319
need to do something in order to use the

1302
00:46:14,319 --> 00:46:16,079
secure aggregation protocol because the

1303
00:46:16,079 --> 00:46:18,000
secure aggregation protocol operates on

1304
00:46:18,000 --> 00:46:20,240
a finite group or a finite field

1305
00:46:20,240 --> 00:46:21,200
so

1306
00:46:21,200 --> 00:46:23,440
depending on our communication cost say

1307
00:46:23,440 --> 00:46:27,040
we have we want b bits per uh parameter

1308
00:46:27,040 --> 00:46:28,400
or per coordinate

1309
00:46:28,400 --> 00:46:30,240
then what we can do is we can compute

1310
00:46:30,240 --> 00:46:32,640
the field size of secure aggregation it

1311
00:46:32,640 --> 00:46:34,640
ends up being 2 to the power of that and

1312
00:46:34,640 --> 00:46:37,200
then we can use this to determine how

1313
00:46:37,200 --> 00:46:39,119
much we can scale the data ideally we

1314
00:46:39,119 --> 00:46:41,119
want to scale the data as much as

1315
00:46:41,119 --> 00:46:43,839
possible in order to ensure we get dp

1316
00:46:43,839 --> 00:46:45,920
guarantees close to continuous gaussian

1317
00:46:45,920 --> 00:46:48,560
and in order to also avoid these

1318
00:46:48,560 --> 00:46:50,800
rounding errors that we talked about but

1319
00:46:50,800 --> 00:46:53,040
we cannot scale it beyond a certain

1320
00:46:53,040 --> 00:46:54,880
point because if we scale it beyond a

1321
00:46:54,880 --> 00:46:57,760
certain point then we would be

1322
00:46:57,760 --> 00:47:00,240
modulo wrapping around with high

1323
00:47:00,240 --> 00:47:02,079
probability so we want to balance out

1324
00:47:02,079 --> 00:47:04,079
these two events and in the paper we

1325
00:47:04,079 --> 00:47:06,800
show precisely for a given bit width how

1326
00:47:06,800 --> 00:47:08,960
you can choose a scaling parameter in

1327
00:47:08,960 --> 00:47:11,359
order to balance out these two types of

1328
00:47:11,359 --> 00:47:12,960
error events

1329
00:47:12,960 --> 00:47:15,200
all right so with that i can show you uh

1330
00:47:15,200 --> 00:47:16,880
at least one set of experiments in the

1331
00:47:16,880 --> 00:47:18,640
paper we have a lot more experiments

1332
00:47:18,640 --> 00:47:20,640
that you can take a look at so this is

1333
00:47:20,640 --> 00:47:22,960
the stack overflow data set it's one of

1334
00:47:22,960 --> 00:47:25,680
the biggest federated learning benchmark

1335
00:47:25,680 --> 00:47:28,319
data sets um we are training here in

1336
00:47:28,319 --> 00:47:31,359
lstm for an expert prediction model and

1337
00:47:31,359 --> 00:47:33,920
this model has i believe more than five

1338
00:47:33,920 --> 00:47:36,079
million parameters so it's a very large

1339
00:47:36,079 --> 00:47:39,200
model and um the data set itself has

1340
00:47:39,200 --> 00:47:42,559
more than 342 000 clients so again it's

1341
00:47:42,559 --> 00:47:44,640
it's a pretty large data set

1342
00:47:44,640 --> 00:47:47,200
and on the left hand side the figure

1343
00:47:47,200 --> 00:47:48,640
that i'm showing you shows the

1344
00:47:48,640 --> 00:47:50,640
performance of this distributed discrete

1345
00:47:50,640 --> 00:47:52,800
gaussian method that i just presented

1346
00:47:52,800 --> 00:47:55,920
for a variety of values of bit widths

1347
00:47:55,920 --> 00:47:58,800
communication costs and you can see that

1348
00:47:58,800 --> 00:48:01,280
for 12 bits it doesn't work especially

1349
00:48:01,280 --> 00:48:03,040
for smaller values of epsilon the

1350
00:48:03,040 --> 00:48:06,160
accuracy that we get is very very low

1351
00:48:06,160 --> 00:48:08,960
but as we move to 14 bits or more the

1352
00:48:08,960 --> 00:48:11,280
accuracy of this dd gauss distributed

1353
00:48:11,280 --> 00:48:13,200
discrete gaussian starts matching

1354
00:48:13,200 --> 00:48:14,800
exactly the continuous gaussian

1355
00:48:14,800 --> 00:48:17,839
mechanism so in other words what this

1356
00:48:17,839 --> 00:48:20,240
figure is suggesting is that with about

1357
00:48:20,240 --> 00:48:23,599
14 or more bits 16 or more bits we could

1358
00:48:23,599 --> 00:48:25,839
get the exact performance of continuous

1359
00:48:25,839 --> 00:48:28,640
gaussian while giving provable privacy

1360
00:48:28,640 --> 00:48:30,960
guarantees under secure aggregation and

1361
00:48:30,960 --> 00:48:33,599
this is all again distributed dp

1362
00:48:33,599 --> 00:48:35,520
the figure on the right hand side does

1363
00:48:35,520 --> 00:48:37,680
something a little different it

1364
00:48:37,680 --> 00:48:40,400
goes over a number of noise scales z

1365
00:48:40,400 --> 00:48:42,559
here is how much noise you're adding

1366
00:48:42,559 --> 00:48:44,960
locally to really determines the noise

1367
00:48:44,960 --> 00:48:48,720
scale and it does it with 1 000 clients

1368
00:48:48,720 --> 00:48:50,880
per round and it shows you that if you

1369
00:48:50,880 --> 00:48:53,119
have a bit width about 18 bits per

1370
00:48:53,119 --> 00:48:55,359
parameter you're going to always match

1371
00:48:55,359 --> 00:48:56,880
the performance of the continuous

1372
00:48:56,880 --> 00:48:58,800
caching mechanism so if you have a lot

1373
00:48:58,800 --> 00:49:01,599
of clients per every secure aggregation

1374
00:49:01,599 --> 00:49:04,000
round every round of federated learning

1375
00:49:04,000 --> 00:49:05,920
you need about 18 bits and you're going

1376
00:49:05,920 --> 00:49:07,920
to be able to train this large model of

1377
00:49:07,920 --> 00:49:10,319
5 million parameters

1378
00:49:10,319 --> 00:49:11,440
all right so

1379
00:49:11,440 --> 00:49:12,960
this slide you may remember it from the

1380
00:49:12,960 --> 00:49:14,960
beginning of the talk where callisto is

1381
00:49:14,960 --> 00:49:17,520
saying that we need a privacy in-depth

1382
00:49:17,520 --> 00:49:19,680
analysis where we give some dp

1383
00:49:19,680 --> 00:49:22,000
guarantees to the server and those dp

1384
00:49:22,000 --> 00:49:24,319
guarantees get stronger and stronger as

1385
00:49:24,319 --> 00:49:26,400
the surface of attack gets bigger this

1386
00:49:26,400 --> 00:49:28,319
is essentially what we've managed to do

1387
00:49:28,319 --> 00:49:30,720
in this work where for the server we're

1388
00:49:30,720 --> 00:49:31,599
giving

1389
00:49:31,599 --> 00:49:33,680
some dp guarantee as long as the server

1390
00:49:33,680 --> 00:49:36,559
is honest but curious or semi honest

1391
00:49:36,559 --> 00:49:38,319
and we cannot give the full privacy

1392
00:49:38,319 --> 00:49:41,119
guarantees because it's hard to prove or

1393
00:49:41,119 --> 00:49:44,400
provide the secrecy of the sample we're

1394
00:49:44,400 --> 00:49:46,000
you know doing amplification via

1395
00:49:46,000 --> 00:49:48,240
sampling here this is an open question

1396
00:49:48,240 --> 00:49:50,000
of how to actually strengthen those

1397
00:49:50,000 --> 00:49:51,359
guarantees

1398
00:49:51,359 --> 00:49:53,599
but then for the released model or at

1399
00:49:53,599 --> 00:49:55,680
deployment we give stronger guarantees

1400
00:49:55,680 --> 00:49:58,559
that match the central dp once all right

1401
00:49:58,559 --> 00:50:00,400
in the last one or two minutes of this

1402
00:50:00,400 --> 00:50:02,640
talk i'm going to quickly go off over

1403
00:50:02,640 --> 00:50:04,400
some challenges and some opportunities

1404
00:50:04,400 --> 00:50:07,520
so hopefully you'll find this useful

1405
00:50:07,520 --> 00:50:09,119
the first thing is i want to say that

1406
00:50:09,119 --> 00:50:11,040
and hopefully this is not a surprise to

1407
00:50:11,040 --> 00:50:12,640
anybody in this room privacy is

1408
00:50:12,640 --> 00:50:14,400
multifaceted

1409
00:50:14,400 --> 00:50:16,400
so it's not a binary quantity we cannot

1410
00:50:16,400 --> 00:50:18,480
just like say this is private or not

1411
00:50:18,480 --> 00:50:20,800
private and what's fascinating about it

1412
00:50:20,800 --> 00:50:22,640
is that we need to understand tensions

1413
00:50:22,640 --> 00:50:25,520
between privacy communication cost

1414
00:50:25,520 --> 00:50:28,160
computation accuracy and sparsity as

1415
00:50:28,160 --> 00:50:29,839
kalista mentioned so these trades

1416
00:50:29,839 --> 00:50:31,760
trade-offs are perhaps studied

1417
00:50:31,760 --> 00:50:33,839
separately but they're not studied

1418
00:50:33,839 --> 00:50:35,599
jointly so there's a lot more work to

1419
00:50:35,599 --> 00:50:37,359
couple all these trade-offs and under

1420
00:50:37,359 --> 00:50:39,680
understand how they they interact

1421
00:50:39,680 --> 00:50:40,960
together

1422
00:50:40,960 --> 00:50:42,720
there's a lot of tension between privacy

1423
00:50:42,720 --> 00:50:45,760
robustness and fairness and one way in

1424
00:50:45,760 --> 00:50:46,800
order to

1425
00:50:46,800 --> 00:50:48,720
relax or ease that tension is through

1426
00:50:48,720 --> 00:50:50,640
personalization which we didn't touch on

1427
00:50:50,640 --> 00:50:52,640
in this talk so hopefully maybe another

1428
00:50:52,640 --> 00:50:54,640
time we can talk about how we can do

1429
00:50:54,640 --> 00:50:57,119
model personalization on device in order

1430
00:50:57,119 --> 00:50:58,880
to ease out the tension between

1431
00:50:58,880 --> 00:51:00,559
differential privacy and the other

1432
00:51:00,559 --> 00:51:03,440
things such as fairness and robustness

1433
00:51:03,440 --> 00:51:05,280
and cryptographic techniques which we

1434
00:51:05,280 --> 00:51:07,359
saw in this talk are going to play a

1435
00:51:07,359 --> 00:51:10,079
critical role in strengthening privacy

1436
00:51:10,079 --> 00:51:12,480
and giving stronger guarantees

1437
00:51:12,480 --> 00:51:16,160
now one one important thing is that dp

1438
00:51:16,160 --> 00:51:18,000
uh and i didn't really dwell too much on

1439
00:51:18,000 --> 00:51:20,960
it in this talk ends up almost always

1440
00:51:20,960 --> 00:51:22,800
hurting the accuracy quite a bit

1441
00:51:22,800 --> 00:51:24,720
especially if you want to get dp with

1442
00:51:24,720 --> 00:51:26,960
small epsilon something like one or even

1443
00:51:26,960 --> 00:51:30,400
smaller and so the question becomes

1444
00:51:30,400 --> 00:51:32,400
how can we mitigate the effect of

1445
00:51:32,400 --> 00:51:34,319
differential privacy now obviously if

1446
00:51:34,319 --> 00:51:36,960
you have very large populations tens of

1447
00:51:36,960 --> 00:51:38,640
millions or hundreds of millions or even

1448
00:51:38,640 --> 00:51:40,400
billions of clients in the system you

1449
00:51:40,400 --> 00:51:42,160
can offer such strong

1450
00:51:42,160 --> 00:51:44,720
dp guarantees but in order to offer such

1451
00:51:44,720 --> 00:51:46,400
strong dp guarantees and get good

1452
00:51:46,400 --> 00:51:48,880
accuracy you would need to run

1453
00:51:48,880 --> 00:51:51,599
on larger cohorts so have more clients

1454
00:51:51,599 --> 00:51:54,880
per round and perhaps do more rounds so

1455
00:51:54,880 --> 00:51:57,359
the trade-off here becomes not privacy

1456
00:51:57,359 --> 00:51:59,359
versus accuracy it becomes privacy

1457
00:51:59,359 --> 00:52:01,520
versus communication or privacy versus

1458
00:52:01,520 --> 00:52:03,920
computation so we need to know if we

1459
00:52:03,920 --> 00:52:06,079
want to pay a penalty it shouldn't be a

1460
00:52:06,079 --> 00:52:07,760
penalty in the accuracy it should be a

1461
00:52:07,760 --> 00:52:09,920
penalty and other resources hopefully

1462
00:52:09,920 --> 00:52:11,599
that we can afford

1463
00:52:11,599 --> 00:52:12,480
and

1464
00:52:12,480 --> 00:52:14,720
we still don't have very good privacy

1465
00:52:14,720 --> 00:52:16,960
budgeting and management systems to

1466
00:52:16,960 --> 00:52:18,800
allow us to track the privacy across

1467
00:52:18,800 --> 00:52:21,040
multiple models that we train on the

1468
00:52:21,040 --> 00:52:23,680
same population of clients so we look

1469
00:52:23,680 --> 00:52:26,160
forward in the next few years for a

1470
00:52:26,160 --> 00:52:28,079
development of a nice

1471
00:52:28,079 --> 00:52:31,520
privacy budgeting and management systems

1472
00:52:31,520 --> 00:52:33,680
and finally one of the areas that we

1473
00:52:33,680 --> 00:52:36,559
believe are going to help in ensuring dp

1474
00:52:36,559 --> 00:52:39,119
is deployed at scale in practice is the

1475
00:52:39,119 --> 00:52:40,400
use of

1476
00:52:40,400 --> 00:52:42,160
public data because there's a lot of

1477
00:52:42,160 --> 00:52:44,160
public data and for that data we don't

1478
00:52:44,160 --> 00:52:46,640
need to enforce dp so how do we actually

1479
00:52:46,640 --> 00:52:49,200
combine the availability of large public

1480
00:52:49,200 --> 00:52:51,599
data sets with private data sets in

1481
00:52:51,599 --> 00:52:54,559
order to give better privacy accuracy

1482
00:52:54,559 --> 00:52:56,960
guarantees and also how do we use the

1483
00:52:56,960 --> 00:52:59,359
fact that a lot of these models are

1484
00:52:59,359 --> 00:53:01,680
either sparse and sparsity will help

1485
00:53:01,680 --> 00:53:04,800
with accuracy or they can be projected

1486
00:53:04,800 --> 00:53:07,119
down onto a much smaller lower

1487
00:53:07,119 --> 00:53:08,640
dimensional space

1488
00:53:08,640 --> 00:53:10,079
all right so if you want to learn about

1489
00:53:10,079 --> 00:53:12,319
all these challenges you can either take

1490
00:53:12,319 --> 00:53:14,160
a look at this paper that has been

1491
00:53:14,160 --> 00:53:15,839
around for more than a year now it's

1492
00:53:15,839 --> 00:53:17,520
called advances and open problems in

1493
00:53:17,520 --> 00:53:19,760
federated learning we've updated it

1494
00:53:19,760 --> 00:53:21,280
recently and it got published in

1495
00:53:21,280 --> 00:53:22,640
foundations and trends and machine

1496
00:53:22,640 --> 00:53:25,280
learning and we have very recently put

1497
00:53:25,280 --> 00:53:28,559
another paper up with so many uh great

1498
00:53:28,559 --> 00:53:30,480
co-authors it's called the field guide

1499
00:53:30,480 --> 00:53:33,040
to federated optimization this last

1500
00:53:33,040 --> 00:53:35,920
paper is focused on optimization so it

1501
00:53:35,920 --> 00:53:38,640
still touches on privacy and other

1502
00:53:38,640 --> 00:53:41,359
aspects but the focus is on purely

1503
00:53:41,359 --> 00:53:43,520
optimization so with that i'll thank you

1504
00:53:43,520 --> 00:53:47,119
and we'll be happy to take questions

1505
00:53:48,160 --> 00:53:49,760
thanks a lot to all of you for the very

1506
00:53:49,760 --> 00:53:51,040
interesting talk i have a lot of

1507
00:53:51,040 --> 00:53:52,240
questions

1508
00:53:52,240 --> 00:53:54,160
but for the interest of time let's first

1509
00:53:54,160 --> 00:53:56,000
see the audience questions i can see

1510
00:53:56,000 --> 00:53:57,760
that you have answered most of them in

1511
00:53:57,760 --> 00:53:58,880
the chat

1512
00:53:58,880 --> 00:54:01,119
i think there's 13 hours

1513
00:54:01,119 --> 00:54:02,960
that you didn't ask you know do you want

1514
00:54:02,960 --> 00:54:06,800
to uh answer your question live

1515
00:54:09,280 --> 00:54:10,960
uh it's okay actually we can we can do

1516
00:54:10,960 --> 00:54:13,280
it afterwards uh or i can i can just

1517
00:54:13,280 --> 00:54:14,800
sort of see the answer on chat that's

1518
00:54:14,800 --> 00:54:16,400
fine

1519
00:54:16,400 --> 00:54:18,240
okay great

1520
00:54:18,240 --> 00:54:20,160
so is there any other question from the

1521
00:54:20,160 --> 00:54:22,000
audience

1522
00:54:22,000 --> 00:54:23,920
i can ask a quick one in the meantime if

1523
00:54:23,920 --> 00:54:26,079
somebody has a question i wanted to ask

1524
00:54:26,079 --> 00:54:27,920
if you are thinking of full malicious

1525
00:54:27,920 --> 00:54:30,720
security for your aggregation protocol

1526
00:54:30,720 --> 00:54:31,839
are you thinking of it are you

1527
00:54:31,839 --> 00:54:34,400
interested

1528
00:54:37,200 --> 00:54:39,680
so full malicious meaning more than what

1529
00:54:39,680 --> 00:54:41,760
i presented in the sense that uh

1530
00:54:41,760 --> 00:54:43,920
protecting also in the key distribution

1531
00:54:43,920 --> 00:54:45,440
phase

1532
00:54:45,440 --> 00:54:48,079
or like for example the secret saying is

1533
00:54:48,079 --> 00:54:49,920
not done correctly that the parties are

1534
00:54:49,920 --> 00:54:50,880
sending

1535
00:54:50,880 --> 00:54:55,200
different things different stairs like

1536
00:54:55,200 --> 00:54:56,720
there was something in my background i

1537
00:54:56,720 --> 00:54:58,240
mean like during the protocol as well

1538
00:54:58,240 --> 00:54:59,680
during the online phase for example if

1539
00:54:59,680 --> 00:55:01,359
the secret sharing is not done correct

1540
00:55:01,359 --> 00:55:04,400
from the client side

1541
00:55:04,640 --> 00:55:06,400
yeah that's covered by our malicious

1542
00:55:06,400 --> 00:55:08,000
protocol

1543
00:55:08,000 --> 00:55:09,520
so that's that's handled you don't need

1544
00:55:09,520 --> 00:55:11,040
verifiable secret sharing or anything

1545
00:55:11,040 --> 00:55:13,839
like that in this particular setting

1546
00:55:13,839 --> 00:55:16,319
so you offer full malicious security

1547
00:55:16,319 --> 00:55:19,200
yeah as long as the key distribution

1548
00:55:19,200 --> 00:55:21,839
phase where clients exchange public keys

1549
00:55:21,839 --> 00:55:25,040
with each other through the server in a

1550
00:55:25,040 --> 00:55:26,640
pre-competition phases it's done

1551
00:55:26,640 --> 00:55:28,240
semi-honestly by the server if that's

1552
00:55:28,240 --> 00:55:30,160
the case then we have put security

1553
00:55:30,160 --> 00:55:31,760
in the in the sense of full security

1554
00:55:31,760 --> 00:55:34,799
with the world marijuana with our work

1555
00:55:34,799 --> 00:55:37,440
okay nice and unfortunately

1556
00:55:37,440 --> 00:55:39,200
we're working with very large numbers of

1557
00:55:39,200 --> 00:55:40,880
clients like we see in the real world

1558
00:55:40,880 --> 00:55:42,720
there's no we don't have any public key

1559
00:55:42,720 --> 00:55:44,400
infrastructure to appeal to so it's

1560
00:55:44,400 --> 00:55:46,240
really hard to work around the the need

1561
00:55:46,240 --> 00:55:49,280
for that initial trusted step

1562
00:55:49,280 --> 00:55:50,400
right

1563
00:55:50,400 --> 00:55:53,280
and about practice uh do you have like

1564
00:55:53,280 --> 00:55:57,200
these protocols and practice at google

1565
00:55:58,400 --> 00:56:00,160
yeah we do we've been running the the

1566
00:56:00,160 --> 00:56:03,040
2017 protocol for

1567
00:56:03,040 --> 00:56:05,359
for many years and

1568
00:56:05,359 --> 00:56:07,680
experimenting with the the extended

1569
00:56:07,680 --> 00:56:10,160
protocols

1570
00:56:10,720 --> 00:56:13,040
nice

1571
00:56:13,359 --> 00:56:15,598
so

1572
00:56:18,960 --> 00:56:21,680
yeah please go ahead

1573
00:56:21,680 --> 00:56:22,880
it's a question for you so you mentioned

1574
00:56:22,880 --> 00:56:24,960
that your protocol is

1575
00:56:24,960 --> 00:56:26,720
statistically secure and i understand

1576
00:56:26,720 --> 00:56:28,640
this because of of this arrangement that

1577
00:56:28,640 --> 00:56:30,079
you're doing this random something for

1578
00:56:30,079 --> 00:56:32,079
assigning the parties i wonder if you

1579
00:56:32,079 --> 00:56:34,079
are considering

1580
00:56:34,079 --> 00:56:35,760
another ways of

1581
00:56:35,760 --> 00:56:38,319
getting logarithmic communications on

1582
00:56:38,319 --> 00:56:41,279
without this assumption

1583
00:56:43,359 --> 00:56:44,720
i've not thought about that i wouldn't

1584
00:56:44,720 --> 00:56:46,240
know how to go about it

1585
00:56:46,240 --> 00:56:48,160
uh

1586
00:56:48,160 --> 00:56:50,399
so

1587
00:56:50,640 --> 00:56:52,160
you want you're asking whether when one

1588
00:56:52,160 --> 00:56:53,839
can get logarithmic communication per

1589
00:56:53,839 --> 00:56:56,319
client or more generally

1590
00:56:56,319 --> 00:56:59,520
polylog overhead for secure education

1591
00:56:59,520 --> 00:57:01,440
without a statistical

1592
00:57:01,440 --> 00:57:04,160
security argument

1593
00:57:04,160 --> 00:57:06,480
um yeah i think something similar to the

1594
00:57:06,480 --> 00:57:08,559
to their to the results you already have

1595
00:57:08,559 --> 00:57:11,440
but yes exactly without relying on

1596
00:57:11,440 --> 00:57:13,440
static

1597
00:57:13,440 --> 00:57:15,359
oh okay so you you're asking whether we

1598
00:57:15,359 --> 00:57:17,200
could drop the assumption of

1599
00:57:17,200 --> 00:57:18,559
another

1600
00:57:18,559 --> 00:57:20,480
adversary yes yes yes exactly sorry it

1601
00:57:20,480 --> 00:57:21,760
doesn't mean yeah

1602
00:57:21,760 --> 00:57:23,520
okay i see so let me rephrase that so

1603
00:57:23,520 --> 00:57:25,440
the question is can we get logarithmic

1604
00:57:25,440 --> 00:57:26,720
communication per client or more

1605
00:57:26,720 --> 00:57:29,959
generally organizat

1606
00:57:31,599 --> 00:57:33,280
adaptive adversaries

1607
00:57:33,280 --> 00:57:34,720
and i i don't have an answer i don't

1608
00:57:34,720 --> 00:57:35,680
know

1609
00:57:35,680 --> 00:57:37,760
either way sorry

1610
00:57:37,760 --> 00:57:38,880
or not

1611
00:57:38,880 --> 00:57:40,960
if

1612
00:57:42,640 --> 00:57:44,319
does it seem relevant because at the end

1613
00:57:44,319 --> 00:57:46,160
of the day it's like a short time time

1614
00:57:46,160 --> 00:57:47,599
frame where you can grow up and so on so

1615
00:57:47,599 --> 00:57:49,520
it's probably not the relevant impact

1616
00:57:49,520 --> 00:57:51,839
i'm very satisfied by by in this case

1617
00:57:51,839 --> 00:57:54,559
with with uh i'm happy with an

1618
00:57:54,559 --> 00:57:57,359
assuming an active adversary but

1619
00:57:57,359 --> 00:57:59,839
particularly i think it's

1620
00:57:59,839 --> 00:58:01,630
it's realistic and and fine

1621
00:58:01,630 --> 00:58:02,720
[Music]

1622
00:58:02,720 --> 00:58:04,160
but uh i mean theoretically your

1623
00:58:04,160 --> 00:58:06,480
question makes a lot of sense and

1624
00:58:06,480 --> 00:58:08,720
it's it's very it's a good question i

1625
00:58:08,720 --> 00:58:10,880
think

1626
00:58:10,880 --> 00:58:13,520
understood thank you

1627
00:58:13,839 --> 00:58:15,119
great so

1628
00:58:15,119 --> 00:58:16,799
another question like the last one let's

1629
00:58:16,799 --> 00:58:19,839
make it quick uh somebody amit a corval

1630
00:58:19,839 --> 00:58:21,760
is asking is there any cryptographic

1631
00:58:21,760 --> 00:58:23,280
components in the protocol other than

1632
00:58:23,280 --> 00:58:24,960
name is pki

1633
00:58:24,960 --> 00:58:28,400
what other assumptions do you have

1634
00:58:29,839 --> 00:58:32,880
so we need uh

1635
00:58:32,960 --> 00:58:35,359
authenticated encryption right this

1636
00:58:35,359 --> 00:58:37,440
clients need to talk to each other

1637
00:58:37,440 --> 00:58:38,480
uh

1638
00:58:38,480 --> 00:58:40,079
through the server

1639
00:58:40,079 --> 00:58:43,280
we need uh signatures right to for the

1640
00:58:43,280 --> 00:58:45,119
malicious variant to

1641
00:58:45,119 --> 00:58:47,359
essentially make sure that the claims by

1642
00:58:47,359 --> 00:58:49,440
by one of your neighbors do belong to

1643
00:58:49,440 --> 00:58:52,160
them and but no no fancy assumptions

1644
00:58:52,160 --> 00:58:54,240
it's just all quite standard we use we

1645
00:58:54,240 --> 00:58:56,240
instantiate the random oracle model with

1646
00:58:56,240 --> 00:58:57,839
aes

1647
00:58:57,839 --> 00:59:00,160
i don't know if that answers a question

1648
00:59:00,160 --> 00:59:01,599
i hope so

1649
00:59:01,599 --> 00:59:03,520
there's some diffie-hellman agreement

1650
00:59:03,520 --> 00:59:05,599
and some expansion of a seed with a

1651
00:59:05,599 --> 00:59:07,680
pseudorandom number generator but it's

1652
00:59:07,680 --> 00:59:10,960
it's fairly straightforward

1653
00:59:11,200 --> 00:59:13,680
great thank you thanks a lot guys we can

1654
00:59:13,680 --> 00:59:16,839
get other questions offline thank you so

1655
00:59:16,839 --> 00:59:21,480
much thank you

