1
00:00:00,640 --> 00:00:02,320
hi i'm west van worden and thank you for

2
00:00:02,320 --> 00:00:03,760
joining eurocrypt

3
00:00:03,760 --> 00:00:05,359
in this video i will be discussing our

4
00:00:05,359 --> 00:00:07,120
recent work on advanced led receiving on

5
00:00:07,120 --> 00:00:09,440
gpus with dance of course

6
00:00:09,440 --> 00:00:11,280
and this is joint work with ludica and

7
00:00:11,280 --> 00:00:13,200
mark stevens

8
00:00:13,200 --> 00:00:15,120
so we'll start with a quick overview of

9
00:00:15,120 --> 00:00:18,160
her work so most of the nist post

10
00:00:18,160 --> 00:00:19,520
quantum crypto finalists are based on

11
00:00:19,520 --> 00:00:21,279
heartland's problems

12
00:00:21,279 --> 00:00:23,680
and practical crit analysis is important

13
00:00:23,680 --> 00:00:25,920
to understand concrete security

14
00:00:25,920 --> 00:00:27,599
and to pick concrete parameters for

15
00:00:27,599 --> 00:00:29,519
these schemes

16
00:00:29,519 --> 00:00:31,039
currently let us even algorithms have

17
00:00:31,039 --> 00:00:32,880
the best practical ads to the runtime to

18
00:00:32,880 --> 00:00:35,040
solve these hard lat's problems

19
00:00:35,040 --> 00:00:36,719
and our question was how fit are

20
00:00:36,719 --> 00:00:38,160
different sieving algorithms for

21
00:00:38,160 --> 00:00:41,280
specialized hardware in our case gpus

22
00:00:41,280 --> 00:00:42,640
and this includes the more advanced

23
00:00:42,640 --> 00:00:45,440
sieving techniques that give large

24
00:00:45,440 --> 00:00:47,840
practical gains

25
00:00:47,840 --> 00:00:50,000
to our contributions

26
00:00:50,000 --> 00:00:52,079
we present the first gpu implementation

27
00:00:52,079 --> 00:00:53,600
using all state-of-the-art saving

28
00:00:53,600 --> 00:00:55,360
techniques

29
00:00:55,360 --> 00:00:56,640
this improves both the runtime and

30
00:00:56,640 --> 00:00:58,000
energy efficiency by two orders of

31
00:00:58,000 --> 00:01:00,239
magnitude compared to a cpu-only

32
00:01:00,239 --> 00:01:01,600
approach

33
00:01:01,600 --> 00:01:02,960
and the significantly improved several

34
00:01:02,960 --> 00:01:05,040
lats problem records so we are able to

35
00:01:05,040 --> 00:01:06,159
solve these volumes in much higher

36
00:01:06,159 --> 00:01:08,640
dimensions

37
00:01:08,640 --> 00:01:10,400
and additionally we present the first

38
00:01:10,400 --> 00:01:11,840
optimized implementation of the

39
00:01:11,840 --> 00:01:13,840
asymptotic best known sieve better known

40
00:01:13,840 --> 00:01:18,159
as bgl both for cpu and gpu

41
00:01:18,159 --> 00:01:20,080
so what's lattice well atlantis is a

42
00:01:20,080 --> 00:01:22,159
discrete group that generally buys some

43
00:01:22,159 --> 00:01:23,280
bases

44
00:01:23,280 --> 00:01:24,720
and of course lats can be generated by

45
00:01:24,720 --> 00:01:27,360
multiple bases

46
00:01:27,360 --> 00:01:29,520
given any basis the shortest vector

47
00:01:29,520 --> 00:01:31,520
problem asks to find the shortest

48
00:01:31,520 --> 00:01:33,759
non-zero vector of the letters

49
00:01:33,759 --> 00:01:35,439
and in high dimensions this becomes a

50
00:01:35,439 --> 00:01:37,680
hard problem

51
00:01:37,680 --> 00:01:39,280
a related problem is the boundaries to

52
00:01:39,280 --> 00:01:40,960
coding problem where you're given a

53
00:01:40,960 --> 00:01:43,680
target that lies close to lattice vector

54
00:01:43,680 --> 00:01:45,280
and the goal is to return this lattice

55
00:01:45,280 --> 00:01:47,600
vector

56
00:01:47,600 --> 00:01:49,200
so to give an indication of concrete

57
00:01:49,200 --> 00:01:51,119
hardness of the charge factor problem we

58
00:01:51,119 --> 00:01:53,520
have the tu darms and let's changes

59
00:01:53,520 --> 00:01:55,439
so as challenge we are given a random

60
00:01:55,439 --> 00:01:56,960
d-dimensional lattice

61
00:01:56,960 --> 00:01:58,479
and the goal is to find a vector that's

62
00:01:58,479 --> 00:02:00,399
at most five percent longer than the

63
00:02:00,399 --> 00:02:01,840
expected minimum length of the shortest

64
00:02:01,840 --> 00:02:04,159
vector

65
00:02:04,479 --> 00:02:06,479
and we want to solve this problem using

66
00:02:06,479 --> 00:02:07,759
that perceiving

67
00:02:07,759 --> 00:02:10,160
so what's that deceiving well the idea

68
00:02:10,160 --> 00:02:11,920
is to start with a big list of

69
00:02:11,920 --> 00:02:14,800
exponentially many lattice vectors

70
00:02:14,800 --> 00:02:16,720
then inside of this list we try to find

71
00:02:16,720 --> 00:02:18,879
pairs of factors that are close to each

72
00:02:18,879 --> 00:02:19,840
other

73
00:02:19,840 --> 00:02:21,680
such that their difference would give a

74
00:02:21,680 --> 00:02:24,000
short lattice vector

75
00:02:24,000 --> 00:02:26,239
and what we then do is replace a long

76
00:02:26,239 --> 00:02:28,480
vector in our list with this new shorter

77
00:02:28,480 --> 00:02:29,440
vector

78
00:02:29,440 --> 00:02:32,080
and we repeat this until we have only a

79
00:02:32,080 --> 00:02:35,959
bunch of short factors left

80
00:02:36,959 --> 00:02:38,480
so we would like to execute these letter

81
00:02:38,480 --> 00:02:40,000
c from algorithms on specialized

82
00:02:40,000 --> 00:02:42,319
hardware in our case graphics processing

83
00:02:42,319 --> 00:02:44,560
units better known as gpus

84
00:02:44,560 --> 00:02:46,400
so on this small part of the gpu you can

85
00:02:46,400 --> 00:02:49,360
already have 64 floating point cores 64

86
00:02:49,360 --> 00:02:51,440
intercourse and eight tens of course

87
00:02:51,440 --> 00:02:54,480
about which i will talk a bit more later

88
00:02:54,480 --> 00:02:56,239
so in total on the gpu you can have

89
00:02:56,239 --> 00:02:58,480
thousands of cores which is much more

90
00:02:58,480 --> 00:03:01,280
than the dozen or so you have on the cpu

91
00:03:01,280 --> 00:03:04,000
however on a cpu each of these scores

92
00:03:04,000 --> 00:03:05,760
can work independently and execute their

93
00:03:05,760 --> 00:03:07,040
own instructions

94
00:03:07,040 --> 00:03:09,599
on a gp view all the course have to work

95
00:03:09,599 --> 00:03:11,599
in batches of at least 32

96
00:03:11,599 --> 00:03:14,000
and execute a single construction of

97
00:03:14,000 --> 00:03:16,239
these scores at the same time

98
00:03:16,239 --> 00:03:17,760
also each of these cars have a very

99
00:03:17,760 --> 00:03:19,519
limited amount of registers that you can

100
00:03:19,519 --> 00:03:20,400
use

101
00:03:20,400 --> 00:03:24,080
and and memory that's local

102
00:03:24,480 --> 00:03:26,239
so what are these denser cores well

103
00:03:26,239 --> 00:03:27,760
originally they have been developed for

104
00:03:27,760 --> 00:03:29,680
machine learning and they can do one

105
00:03:29,680 --> 00:03:31,840
thing very well that is efficient low

106
00:03:31,840 --> 00:03:34,239
precision matrix multiplication

107
00:03:34,239 --> 00:03:36,239
so what do i mean with low precision i

108
00:03:36,239 --> 00:03:38,480
mean 16 bit floating point position

109
00:03:38,480 --> 00:03:41,360
while normal float would be 32 bits or

110
00:03:41,360 --> 00:03:44,640
double would be 64 bit large

111
00:03:44,640 --> 00:03:46,879
however the 16-bit position is good

112
00:03:46,879 --> 00:03:49,840
enough for our purposes

113
00:03:49,920 --> 00:03:51,680
and with efficient i mean

114
00:03:51,680 --> 00:03:54,640
that on these old models we used

115
00:03:54,640 --> 00:03:57,439
we can have up to 108 16-bit teraflops

116
00:03:57,439 --> 00:04:00,000
on a single gpu

117
00:04:00,000 --> 00:04:02,159
and on the newer models we even can

118
00:04:02,159 --> 00:04:06,640
reach more than 316-bit teraflops

119
00:04:06,799 --> 00:04:09,200
so how when we compare this to a current

120
00:04:09,200 --> 00:04:11,760
best cpu this would reach with like 64

121
00:04:11,760 --> 00:04:13,840
cores would reach at most about five

122
00:04:13,840 --> 00:04:15,200
teraflops

123
00:04:15,200 --> 00:04:17,680
so you can already see the the order of

124
00:04:17,680 --> 00:04:19,918
two magnitudes improvement

125
00:04:19,918 --> 00:04:22,000
from these gpus

126
00:04:22,000 --> 00:04:23,600
so let's discuss the pros and cons of

127
00:04:23,600 --> 00:04:25,680
these gpus starting with the cons

128
00:04:25,680 --> 00:04:27,120
first as already mentioned these things

129
00:04:27,120 --> 00:04:29,440
are not first though 32 cores have to

130
00:04:29,440 --> 00:04:31,600
execute the same instruction while on a

131
00:04:31,600 --> 00:04:35,759
cpu every core can do what it wants

132
00:04:35,759 --> 00:04:37,840
secondly these gpus are an external

133
00:04:37,840 --> 00:04:39,360
device

134
00:04:39,360 --> 00:04:42,160
and this means that cpu with connect

135
00:04:42,160 --> 00:04:44,080
that's connected with the main memory

136
00:04:44,080 --> 00:04:46,479
has a slow connection to the gpu and the

137
00:04:46,479 --> 00:04:48,639
main memory of this gpu

138
00:04:48,639 --> 00:04:50,000
this means that the connection which

139
00:04:50,000 --> 00:04:52,080
goes via pci bus

140
00:04:52,080 --> 00:04:54,960
in for example our server is limited by

141
00:04:54,960 --> 00:04:57,600
only 16 gigabytes per second

142
00:04:57,600 --> 00:04:59,360
to send data from the main memory to the

143
00:04:59,360 --> 00:05:00,960
gpu

144
00:05:00,960 --> 00:05:02,400
now you can imagine if you have these

145
00:05:02,400 --> 00:05:04,000
gpus that can

146
00:05:04,000 --> 00:05:06,320
get a performance of 100 teraflops per

147
00:05:06,320 --> 00:05:07,520
second

148
00:05:07,520 --> 00:05:09,680
then you have to execute a lot of

149
00:05:09,680 --> 00:05:11,440
instructions you have to reach a lot of

150
00:05:11,440 --> 00:05:13,919
flop pair bytes that you transfer to

151
00:05:13,919 --> 00:05:15,680
this gpu

152
00:05:15,680 --> 00:05:17,919
this very much

153
00:05:17,919 --> 00:05:20,000
and otherwise you get very much memory

154
00:05:20,000 --> 00:05:22,160
bottlenecked

155
00:05:22,160 --> 00:05:24,080
also inside of the gpu memory

156
00:05:24,080 --> 00:05:25,759
bottlenecks often limits the actual

157
00:05:25,759 --> 00:05:28,160
performance

158
00:05:28,160 --> 00:05:31,199
and lastly it's hard to adapt algorithms

159
00:05:31,199 --> 00:05:33,039
for many algorithms that are in

160
00:05:33,039 --> 00:05:36,000
principle serial or maybe can be

161
00:05:36,000 --> 00:05:39,360
paralyzed on multiple cpu cores

162
00:05:39,360 --> 00:05:41,600
it can still be a whole research study

163
00:05:41,600 --> 00:05:44,160
to see how you can adapt them to gpus

164
00:05:44,160 --> 00:05:45,120
such as

165
00:05:45,120 --> 00:05:47,039
our work

166
00:05:47,039 --> 00:05:48,400
but everything if everything works

167
00:05:48,400 --> 00:05:50,800
together then the pros are clear you can

168
00:05:50,800 --> 00:05:52,880
get incredible performance like hundreds

169
00:05:52,880 --> 00:05:54,639
of teraflops instead of just a few

170
00:05:54,639 --> 00:05:57,120
teraflops of the cpu

171
00:05:57,120 --> 00:05:58,240
additionally these things are very

172
00:05:58,240 --> 00:06:00,000
energy efficient so you're gonna get

173
00:06:00,000 --> 00:06:02,479
this incredible performance at only like

174
00:06:02,479 --> 00:06:04,319
at the same energy cost or maybe effect

175
00:06:04,319 --> 00:06:06,319
or two more

176
00:06:06,319 --> 00:06:08,080
so we didn't build our implementation

177
00:06:08,080 --> 00:06:09,919
from scratch

178
00:06:09,919 --> 00:06:12,160
we extended the so-called general sieve

179
00:06:12,160 --> 00:06:15,600
kernel which is from a work from 2018

180
00:06:15,600 --> 00:06:17,120
and this is an open source sieving

181
00:06:17,120 --> 00:06:20,479
framework and implementation

182
00:06:20,479 --> 00:06:22,880
and this implementation combines all the

183
00:06:22,880 --> 00:06:25,280
advanced saving techniques

184
00:06:25,280 --> 00:06:27,759
including all implementation tricks that

185
00:06:27,759 --> 00:06:30,240
you can think of

186
00:06:30,240 --> 00:06:33,199
and it's fully parallel on cpus

187
00:06:33,199 --> 00:06:36,080
for on a single machine

188
00:06:36,080 --> 00:06:36,960
and

189
00:06:36,960 --> 00:06:39,600
they solved the csp record at dimension

190
00:06:39,600 --> 00:06:41,680
155 in about

191
00:06:41,680 --> 00:06:43,680
two weeks

192
00:06:43,680 --> 00:06:46,000
and this was only run on like 72 cpu

193
00:06:46,000 --> 00:06:48,639
cores and 256 gigabytes of memory was

194
00:06:48,639 --> 00:06:50,720
used

195
00:06:50,720 --> 00:06:52,800
so if we compare this to the old way of

196
00:06:52,800 --> 00:06:54,400
solving the surface problem with

197
00:06:54,400 --> 00:06:56,319
enumeration

198
00:06:56,319 --> 00:06:57,440
which is

199
00:06:57,440 --> 00:07:00,240
asymptotically inferior method but it

200
00:07:00,240 --> 00:07:02,160
does only use polynomial memory hence

201
00:07:02,160 --> 00:07:04,960
it's trivial to paralyze

202
00:07:04,960 --> 00:07:08,000
so for this method the old records were

203
00:07:08,000 --> 00:07:10,000
at dimension 152

204
00:07:10,000 --> 00:07:12,400
however using more than 800 000 core

205
00:07:12,400 --> 00:07:13,599
hours

206
00:07:13,599 --> 00:07:16,400
so it's clear that the sieving methods

207
00:07:16,400 --> 00:07:18,240
both in asymptotically but also in

208
00:07:18,240 --> 00:07:20,080
practice usually improve on the

209
00:07:20,080 --> 00:07:22,400
enumeration

210
00:07:22,400 --> 00:07:23,919
so now it's time to discuss these

211
00:07:23,919 --> 00:07:25,599
advanced sieving methods

212
00:07:25,599 --> 00:07:29,599
and how we adapted them to gpus

213
00:07:29,680 --> 00:07:30,560
so

214
00:07:30,560 --> 00:07:32,479
in general our receiving process goes as

215
00:07:32,479 --> 00:07:33,440
follows

216
00:07:33,440 --> 00:07:36,000
we have our big database of lattice

217
00:07:36,000 --> 00:07:37,039
vectors

218
00:07:37,039 --> 00:07:38,720
and then we have three phases that

219
00:07:38,720 --> 00:07:40,160
repeat

220
00:07:40,160 --> 00:07:41,599
first we have a bucketing phase where

221
00:07:41,599 --> 00:07:43,919
the database is partitioned into

222
00:07:43,919 --> 00:07:46,000
multiple buckets

223
00:07:46,000 --> 00:07:47,759
then we have the reducing phase where

224
00:07:47,759 --> 00:07:49,440
inside each bucket

225
00:07:49,440 --> 00:07:52,319
we check all pairs for a

226
00:07:52,319 --> 00:07:54,560
for close factors to give a shorter

227
00:07:54,560 --> 00:07:57,199
vector in return

228
00:07:57,199 --> 00:07:59,440
and then we insert these short factors

229
00:07:59,440 --> 00:08:01,360
back into the database and we repeat

230
00:08:01,360 --> 00:08:02,800
this

231
00:08:02,800 --> 00:08:04,319
so we start with discussing this

232
00:08:04,319 --> 00:08:07,120
bucketing then the reducing part and

233
00:08:07,120 --> 00:08:09,280
then we'll discuss some additional

234
00:08:09,280 --> 00:08:11,280
advanced techniques

235
00:08:11,280 --> 00:08:13,360
so first the bucket thing

236
00:08:13,360 --> 00:08:14,879
what we want to do is want to partition

237
00:08:14,879 --> 00:08:16,960
the sphere and thereby partition our

238
00:08:16,960 --> 00:08:18,319
database

239
00:08:18,319 --> 00:08:21,199
so suppose we have some bucket center c

240
00:08:21,199 --> 00:08:22,879
then we want to

241
00:08:22,879 --> 00:08:25,840
find all the vectors in our database

242
00:08:25,840 --> 00:08:29,440
that are somewhat in the direction of c

243
00:08:29,440 --> 00:08:31,840
and then this gives us a bucket

244
00:08:31,840 --> 00:08:33,519
and then what we want to do is we want

245
00:08:33,519 --> 00:08:35,279
to only check for pairs within each

246
00:08:35,279 --> 00:08:38,958
bucket if they are close to each other

247
00:08:38,958 --> 00:08:40,479
and because they're already pointing

248
00:08:40,479 --> 00:08:42,640
somewhat in the same direction this

249
00:08:42,640 --> 00:08:44,000
heavily increases the reduction

250
00:08:44,000 --> 00:08:47,120
probability per pair

251
00:08:48,080 --> 00:08:50,480
so let's discuss some back techniques

252
00:08:50,480 --> 00:08:53,120
so first as a benchmark suppose we have

253
00:08:53,120 --> 00:08:55,760
no bucketing then we have to check

254
00:08:55,760 --> 00:08:58,720
between all the pairs so if database of

255
00:08:58,720 --> 00:09:01,440
n vectors then we have to check n

256
00:09:01,440 --> 00:09:03,920
squared pairs

257
00:09:03,920 --> 00:09:05,360
and this gives you the time complexity

258
00:09:05,360 --> 00:09:08,000
of 2 to the power 0.415

259
00:09:08,000 --> 00:09:10,560
times the dimension

260
00:09:10,560 --> 00:09:12,160
now the first bucketing method i want to

261
00:09:12,160 --> 00:09:14,959
discuss is the so-called bg-1

262
00:09:14,959 --> 00:09:17,120
related bucketing method here we have

263
00:09:17,120 --> 00:09:20,000
random spherical cones

264
00:09:20,000 --> 00:09:22,560
that form the buckets and we have square

265
00:09:22,560 --> 00:09:24,240
root of n of these packets and each has

266
00:09:24,240 --> 00:09:27,040
size square of n

267
00:09:27,120 --> 00:09:28,640
and if you then do the computation

268
00:09:28,640 --> 00:09:30,640
because of this improved probability to

269
00:09:30,640 --> 00:09:32,560
find reductions

270
00:09:32,560 --> 00:09:34,560
the time complexity goes down to 2 to

271
00:09:34,560 --> 00:09:38,959
the power 0.3 for 9 times the dimension

272
00:09:39,120 --> 00:09:40,800
additionally you can replace these

273
00:09:40,800 --> 00:09:42,959
random directions with random lattice

274
00:09:42,959 --> 00:09:44,800
vectors

275
00:09:44,800 --> 00:09:47,360
and then because these these centers of

276
00:09:47,360 --> 00:09:48,560
the buckets

277
00:09:48,560 --> 00:09:50,800
give our lattice vectors we have two

278
00:09:50,800 --> 00:09:52,560
additional properties first

279
00:09:52,560 --> 00:09:55,040
you can immediately also find reductions

280
00:09:55,040 --> 00:09:56,240
with this

281
00:09:56,240 --> 00:09:58,320
bucket center because you're already

282
00:09:58,320 --> 00:09:59,760
computing the

283
00:09:59,760 --> 00:10:01,120
distances

284
00:10:01,120 --> 00:10:03,600
and secondly this bucket center can be

285
00:10:03,600 --> 00:10:06,720
used to not only check for for pairs but

286
00:10:06,720 --> 00:10:08,480
also for triples

287
00:10:08,480 --> 00:10:12,079
that might give you a certain factor

288
00:10:12,800 --> 00:10:15,920
and note that to compute to see if

289
00:10:15,920 --> 00:10:17,760
in which bucket the vector belongs we

290
00:10:17,760 --> 00:10:19,200
need to compute inner products with

291
00:10:19,200 --> 00:10:20,880
lattice vectors

292
00:10:20,880 --> 00:10:22,399
and if you write it out you actually get

293
00:10:22,399 --> 00:10:24,320
like a matrix product and this is

294
00:10:24,320 --> 00:10:27,920
exactly what denser cores are good at

295
00:10:28,959 --> 00:10:31,040
so now let's get another c which is the

296
00:10:31,040 --> 00:10:32,800
bgl sieve

297
00:10:32,800 --> 00:10:34,399
and this one use structured spherical

298
00:10:34,399 --> 00:10:35,920
cones

299
00:10:35,920 --> 00:10:37,440
and the structure comes from a product

300
00:10:37,440 --> 00:10:39,120
code

301
00:10:39,120 --> 00:10:41,200
and using this structure we can much

302
00:10:41,200 --> 00:10:42,959
more easily find

303
00:10:42,959 --> 00:10:46,160
appropriate bucket for each vector

304
00:10:46,160 --> 00:10:48,079
and as a result we can for some

305
00:10:48,079 --> 00:10:49,279
parameter k

306
00:10:49,279 --> 00:10:52,160
we can have much more buckets

307
00:10:52,160 --> 00:10:54,720
that are of a smaller size

308
00:10:54,720 --> 00:10:56,560
so in the end depending on the parameter

309
00:10:56,560 --> 00:10:59,360
k we can get a lot of small buckets very

310
00:10:59,360 --> 00:11:01,839
cheaply

311
00:11:01,920 --> 00:11:04,240
and this results in a time complexity of

312
00:11:04,240 --> 00:11:08,240
2 to the power 0.292 times the dimension

313
00:11:08,240 --> 00:11:10,800
if you take this k small let's say log

314
00:11:10,800 --> 00:11:14,760
rapidly in the dimension

315
00:11:15,760 --> 00:11:17,360
for our implementation we have some

316
00:11:17,360 --> 00:11:18,720
additional tricks

317
00:11:18,720 --> 00:11:21,440
namely instead of using explicit product

318
00:11:21,440 --> 00:11:23,040
codes and

319
00:11:23,040 --> 00:11:24,720
explicit vectors

320
00:11:24,720 --> 00:11:25,839
we

321
00:11:25,839 --> 00:11:29,040
use implicit directions we take a

322
00:11:29,040 --> 00:11:30,399
lattice vector

323
00:11:30,399 --> 00:11:32,399
and then we use permutations and halomar

324
00:11:32,399 --> 00:11:33,839
transforms and then

325
00:11:33,839 --> 00:11:35,519
and then just read off the coefficients

326
00:11:35,519 --> 00:11:36,800
of this

327
00:11:36,800 --> 00:11:39,440
to do the bucketing you can read the

328
00:11:39,440 --> 00:11:42,000
paper more about this

329
00:11:42,000 --> 00:11:43,920
and the nice thing about this method is

330
00:11:43,920 --> 00:11:45,920
that it's very suitable for

331
00:11:45,920 --> 00:11:48,320
factorized cpu instructions

332
00:11:48,320 --> 00:11:51,920
and also for gpus

333
00:11:52,079 --> 00:11:54,800
and actually we have a avx cpu

334
00:11:54,800 --> 00:11:57,360
implementation and we merge this into

335
00:11:57,360 --> 00:11:59,360
upstream into the general sieve kernel

336
00:11:59,360 --> 00:12:01,279
the open source implementation and this

337
00:12:01,279 --> 00:12:04,480
is currently the fastest cpuc on there

338
00:12:04,480 --> 00:12:06,959
and it beats all the lrcs

339
00:12:06,959 --> 00:12:11,760
around starting dimension 80 or 90.

340
00:12:11,760 --> 00:12:13,040
and i also want to mention that this

341
00:12:13,040 --> 00:12:15,279
pg-1c was the one that was used by the

342
00:12:15,279 --> 00:12:16,800
general sieve kernel

343
00:12:16,800 --> 00:12:21,519
to set the old records at dimension 155.

344
00:12:21,600 --> 00:12:24,079
so we implemented these different

345
00:12:24,079 --> 00:12:26,480
bucketing techniques on the gpu

346
00:12:26,480 --> 00:12:28,880
and they have the following practical

347
00:12:28,880 --> 00:12:30,320
quality

348
00:12:30,320 --> 00:12:32,560
and what this i mean is that the number

349
00:12:32,560 --> 00:12:33,519
of

350
00:12:33,519 --> 00:12:35,360
reductions we find inside the bucket

351
00:12:35,360 --> 00:12:37,040
compared to what we

352
00:12:37,040 --> 00:12:40,480
would expect optimally in theory

353
00:12:40,480 --> 00:12:43,279
so the black bars here indicate the

354
00:12:43,279 --> 00:12:45,440
idealized

355
00:12:45,440 --> 00:12:46,880
performance

356
00:12:46,880 --> 00:12:48,079
if all of these buckets would be

357
00:12:48,079 --> 00:12:49,200
perfectly

358
00:12:49,200 --> 00:12:51,120
random

359
00:12:51,120 --> 00:12:53,760
the second the blue bars showed the brb

360
00:12:53,760 --> 00:12:55,519
g1 implementation

361
00:12:55,519 --> 00:12:57,920
and the red and orange ones show the bgi

362
00:12:57,920 --> 00:13:00,240
implementation for k equal to one and k

363
00:13:00,240 --> 00:13:02,240
equal to two

364
00:13:02,240 --> 00:13:04,720
and what we see is that the

365
00:13:04,720 --> 00:13:08,720
the pg-1 and the bgl for k61 are very

366
00:13:08,720 --> 00:13:11,040
performant and come close to the

367
00:13:11,040 --> 00:13:13,440
idealized performance

368
00:13:13,440 --> 00:13:18,000
and for the the 2b case 2 bgl version we

369
00:13:18,000 --> 00:13:21,279
see a slight deterioration performance

370
00:13:21,279 --> 00:13:22,880
but

371
00:13:22,880 --> 00:13:25,200
note that computing these buckets is

372
00:13:25,200 --> 00:13:28,240
much much faster

373
00:13:30,160 --> 00:13:32,399
so let's now discuss the reducing part

374
00:13:32,399 --> 00:13:34,800
so suppose we have a bucket of a lot of

375
00:13:34,800 --> 00:13:37,040
vectors then for each pair we want to

376
00:13:37,040 --> 00:13:38,800
check if they are somewhat close to each

377
00:13:38,800 --> 00:13:40,079
other

378
00:13:40,079 --> 00:13:42,720
now if we write out this distance then

379
00:13:42,720 --> 00:13:44,320
if we pre-compute all these lengths what

380
00:13:44,320 --> 00:13:46,320
we actually need to compute is the inner

381
00:13:46,320 --> 00:13:49,360
product between these two factors

382
00:13:49,360 --> 00:13:50,959
so we need to compute pairwise inner

383
00:13:50,959 --> 00:13:51,920
products

384
00:13:51,920 --> 00:13:53,360
and this is exactly what tensor cores

385
00:13:53,360 --> 00:13:55,600
are good at

386
00:13:55,600 --> 00:13:57,440
additionally we need sparse output and

387
00:13:57,440 --> 00:13:59,440
only return the successful pairs

388
00:13:59,440 --> 00:14:01,040
if we don't do this

389
00:14:01,040 --> 00:14:04,800
then we get a clear memory bottleneck

390
00:14:04,800 --> 00:14:06,959
but this means that we can't use any

391
00:14:06,959 --> 00:14:09,040
standard methods that have already been

392
00:14:09,040 --> 00:14:11,440
implemented we need to implement our own

393
00:14:11,440 --> 00:14:16,040
highly optimized metrics products

394
00:14:16,160 --> 00:14:17,920
noticeably that the number of

395
00:14:17,920 --> 00:14:19,920
computations we need to do to compute

396
00:14:19,920 --> 00:14:22,160
all these pairwise inner products

397
00:14:22,160 --> 00:14:24,959
is squared in the bucket size b

398
00:14:24,959 --> 00:14:26,800
while the data you need to send to the

399
00:14:26,800 --> 00:14:30,000
gpu is only linear in the bucket size b

400
00:14:30,000 --> 00:14:31,600
so this ratio between the amount of

401
00:14:31,600 --> 00:14:33,199
computation you do and the data you have

402
00:14:33,199 --> 00:14:35,600
to transfer improves for larger bucket

403
00:14:35,600 --> 00:14:37,360
sizes

404
00:14:37,360 --> 00:14:38,320
so what does this mean for the

405
00:14:38,320 --> 00:14:39,600
performance

406
00:14:39,600 --> 00:14:41,680
well if we exclude the overhead for

407
00:14:41,680 --> 00:14:43,680
transferring this data to the gpu then

408
00:14:43,680 --> 00:14:45,440
we already get good performance at about

409
00:14:45,440 --> 00:14:47,839
bucket size of 4000

410
00:14:47,839 --> 00:14:50,959
so we get about 65 teraflops at this

411
00:14:50,959 --> 00:14:52,399
size

412
00:14:52,399 --> 00:14:54,399
and this is very well compared to the

413
00:14:54,399 --> 00:14:56,639
theoretical limit of 108 teraflops

414
00:14:56,639 --> 00:14:58,320
because we didn't count any of the

415
00:14:58,320 --> 00:15:00,320
instructions here to move the data

416
00:15:00,320 --> 00:15:02,480
within the gpu

417
00:15:02,480 --> 00:15:04,720
however if we include the overhead of

418
00:15:04,720 --> 00:15:06,880
sending this data to the gpu we see that

419
00:15:06,880 --> 00:15:08,480
the performance drops significantly at

420
00:15:08,480 --> 00:15:10,000
these pocket sizes

421
00:15:10,000 --> 00:15:12,000
and only at the bucket size of about 16

422
00:15:12,000 --> 00:15:13,440
000 or higher

423
00:15:13,440 --> 00:15:16,880
we can get reasonable performance

424
00:15:17,040 --> 00:15:20,240
so in short for small buckets

425
00:15:20,240 --> 00:15:21,760
sending the data to the gpu is the

426
00:15:21,760 --> 00:15:23,760
actual bottleneck

427
00:15:23,760 --> 00:15:25,120
and we need large bucket to reach

428
00:15:25,120 --> 00:15:27,839
optimal performance

429
00:15:28,800 --> 00:15:31,360
however large buckets go against the

430
00:15:31,360 --> 00:15:35,440
whole id of the vgl bucketing scheme

431
00:15:35,440 --> 00:15:36,560
so what does this mean for our

432
00:15:36,560 --> 00:15:38,240
implementations

433
00:15:38,240 --> 00:15:40,639
well on a cpu-only implementation

434
00:15:40,639 --> 00:15:42,240
we don't have to have these these very

435
00:15:42,240 --> 00:15:44,800
large buckets and if we then compare the

436
00:15:44,800 --> 00:15:47,680
bg-1c which is indicated by the red line

437
00:15:47,680 --> 00:15:49,040
here

438
00:15:49,040 --> 00:15:50,880
and we compare it to our bgr

439
00:15:50,880 --> 00:15:53,040
implementation on the cpu

440
00:15:53,040 --> 00:15:55,519
with k equal to three

441
00:15:55,519 --> 00:15:56,720
then

442
00:15:56,720 --> 00:15:58,480
the bgl implementation becomes much

443
00:15:58,480 --> 00:16:00,240
faster at higher dimensions and

444
00:16:00,240 --> 00:16:02,800
crossover is really a dimension 90.

445
00:16:02,800 --> 00:16:04,399
actually in the implementation that we

446
00:16:04,399 --> 00:16:05,279
later

447
00:16:05,279 --> 00:16:07,600
merge into the general sieve kernel this

448
00:16:07,600 --> 00:16:09,519
crossover already lies at about 10

449
00:16:09,519 --> 00:16:12,079
dimensions lower even

450
00:16:12,079 --> 00:16:14,480
for the gpu we have these minimal bucket

451
00:16:14,480 --> 00:16:16,959
size to get optimal performance and as a

452
00:16:16,959 --> 00:16:18,079
result

453
00:16:18,079 --> 00:16:19,680
the bg-1 implementation is actually

454
00:16:19,680 --> 00:16:22,000
faster than the bgr implementation in

455
00:16:22,000 --> 00:16:23,440
all the dimensions that we actually

456
00:16:23,440 --> 00:16:25,680
could save

457
00:16:25,680 --> 00:16:27,680
and we estimate that the crossover point

458
00:16:27,680 --> 00:16:31,600
is maybe it only a dimension 150 or 160

459
00:16:31,600 --> 00:16:35,480
deceiving dimension here

460
00:16:36,560 --> 00:16:38,240
so here we see a significant difference

461
00:16:38,240 --> 00:16:40,240
between the cpu implementation and the

462
00:16:40,240 --> 00:16:42,560
gpu implementation that we get different

463
00:16:42,560 --> 00:16:44,160
trade-offs and a different crossover

464
00:16:44,160 --> 00:16:45,279
point

465
00:16:45,279 --> 00:16:47,199
for when these asymptotic

466
00:16:47,199 --> 00:16:49,600
best sieves actually take over it from

467
00:16:49,600 --> 00:16:50,399
the

468
00:16:50,399 --> 00:16:52,560
more practical but asthmatically worst

469
00:16:52,560 --> 00:16:54,880
use

470
00:16:55,519 --> 00:16:57,440
so we have discussed the core parts of

471
00:16:57,440 --> 00:16:59,519
our implementation now discuss some of

472
00:16:59,519 --> 00:17:02,000
the more advanced parts

473
00:17:02,000 --> 00:17:04,079
namely one of the techniques that is

474
00:17:04,079 --> 00:17:05,439
very important in practice is the

475
00:17:05,439 --> 00:17:07,679
dimensions for free technique

476
00:17:07,679 --> 00:17:09,359
so instead of sieving in the fill

477
00:17:09,359 --> 00:17:11,119
lattice we only see even projected

478
00:17:11,119 --> 00:17:12,720
subletters

479
00:17:12,720 --> 00:17:14,559
that's protected away from the first say

480
00:17:14,559 --> 00:17:17,280
l basis vectors so we only

481
00:17:17,280 --> 00:17:19,839
see if in this part

482
00:17:19,839 --> 00:17:22,480
and then after saving we have a big list

483
00:17:22,480 --> 00:17:25,199
of short vectors in this context

484
00:17:25,199 --> 00:17:26,880
and then we lift it back to the fill

485
00:17:26,880 --> 00:17:28,960
letters using the by lifting

486
00:17:28,960 --> 00:17:31,760
and because you have this many vectors

487
00:17:31,760 --> 00:17:33,440
you can show that you can still find the

488
00:17:33,440 --> 00:17:35,679
shortest vector of the original letters

489
00:17:35,679 --> 00:17:39,840
for l that is about the overlock t

490
00:17:40,400 --> 00:17:42,000
and we can combine this with so-called

491
00:17:42,000 --> 00:17:44,240
progressive sieving instead of fixing

492
00:17:44,240 --> 00:17:46,480
this l a priori

493
00:17:46,480 --> 00:17:47,440
we can

494
00:17:47,440 --> 00:17:49,280
start with an l that's pretty large and

495
00:17:49,280 --> 00:17:51,039
so receiving dimension that's pretty

496
00:17:51,039 --> 00:17:51,919
small

497
00:17:51,919 --> 00:17:53,520
and then just

498
00:17:53,520 --> 00:17:56,480
slowly step by step decrease this l

499
00:17:56,480 --> 00:17:58,720
until the lifting actually finds the

500
00:17:58,720 --> 00:18:02,320
shorts factor on the full context

501
00:18:02,320 --> 00:18:04,000
and this also means that if we do on the

502
00:18:04,000 --> 00:18:06,000
fly lifting namely we just lift any

503
00:18:06,000 --> 00:18:08,080
shortest vector that we encounter then

504
00:18:08,080 --> 00:18:10,320
we are much more likely to find this

505
00:18:10,320 --> 00:18:12,960
short factor

506
00:18:13,039 --> 00:18:16,480
so this means that we can have an extra

507
00:18:16,480 --> 00:18:19,039
problem namely can we officially detect

508
00:18:19,039 --> 00:18:21,840
if any barrel factor within a bucket

509
00:18:21,840 --> 00:18:23,600
if we take the difference of these

510
00:18:23,600 --> 00:18:24,720
if this

511
00:18:24,720 --> 00:18:26,640
vector might lift to a short factor

512
00:18:26,640 --> 00:18:29,200
inside of the fill context

513
00:18:29,200 --> 00:18:31,360
and actually what this gives us is a bd

514
00:18:31,360 --> 00:18:34,400
problem on this small context between

515
00:18:34,400 --> 00:18:36,320
one and l

516
00:18:36,320 --> 00:18:38,799
so one way to solve this pd problem is

517
00:18:38,799 --> 00:18:40,880
using by by lifting as mentioned before

518
00:18:40,880 --> 00:18:42,559
however this has a quadratic running

519
00:18:42,559 --> 00:18:46,000
time in the lifting dimension

520
00:18:46,000 --> 00:18:47,360
and that's why we introduced the

521
00:18:47,360 --> 00:18:48,960
so-called dual hatch

522
00:18:48,960 --> 00:18:50,880
so given a lattice you can define a dual

523
00:18:50,880 --> 00:18:53,760
lattice by all vectors in the span that

524
00:18:53,760 --> 00:18:55,679
have an inner product with all the

525
00:18:55,679 --> 00:18:58,799
lattices in the primal

526
00:18:58,799 --> 00:19:01,280
so if you pick one of the dual vectors

527
00:19:01,280 --> 00:19:04,160
you can partition the lattice in

528
00:19:04,160 --> 00:19:06,480
hyperplanes where an entire plane with

529
00:19:06,480 --> 00:19:07,919
all the lattice points that have a

530
00:19:07,919 --> 00:19:09,840
certain

531
00:19:09,840 --> 00:19:12,640
product with this dual vector

532
00:19:12,640 --> 00:19:14,400
but now if we get a target that lies

533
00:19:14,400 --> 00:19:16,720
somewhat close to lettuce

534
00:19:16,720 --> 00:19:18,720
then as a result this inner product with

535
00:19:18,720 --> 00:19:20,880
the dual is also expected to be somewhat

536
00:19:20,880 --> 00:19:23,200
small

537
00:19:23,200 --> 00:19:25,039
so our dual hash doesn't consist of just

538
00:19:25,039 --> 00:19:27,200
a single dual vector with multiple dual

539
00:19:27,200 --> 00:19:30,160
vectors c1 and 2ck

540
00:19:30,160 --> 00:19:31,919
and then the dual hash consists of all

541
00:19:31,919 --> 00:19:33,600
inner products between the target and

542
00:19:33,600 --> 00:19:36,480
these two vectors

543
00:19:36,480 --> 00:19:38,080
now if the distance of the target to our

544
00:19:38,080 --> 00:19:39,919
lats is very small

545
00:19:39,919 --> 00:19:41,919
then we can also expect the distance of

546
00:19:41,919 --> 00:19:43,919
this dual hash to the internet to be

547
00:19:43,919 --> 00:19:45,039
small

548
00:19:45,039 --> 00:19:46,960
now note to compute the first we need

549
00:19:46,960 --> 00:19:48,640
the by lifting

550
00:19:48,640 --> 00:19:51,280
which is quadratic in the dimension

551
00:19:51,280 --> 00:19:53,520
for the second part

552
00:19:53,520 --> 00:19:56,080
it's clearly linear in this k if we have

553
00:19:56,080 --> 00:20:00,080
already computed the do hash

554
00:20:01,520 --> 00:20:03,039
but we don't apply this to the filter

555
00:20:03,039 --> 00:20:04,960
mesh we only apply this to like a

556
00:20:04,960 --> 00:20:08,000
smaller lifting dimension of say 16

557
00:20:08,000 --> 00:20:08,960
and then

558
00:20:08,960 --> 00:20:11,679
just using 32 or 48 dual vectors seems

559
00:20:11,679 --> 00:20:15,280
enough for a very strong correlation

560
00:20:15,520 --> 00:20:17,440
and note that we can officially compute

561
00:20:17,440 --> 00:20:19,200
this dual hash

562
00:20:19,200 --> 00:20:21,679
of the difference of two targets

563
00:20:21,679 --> 00:20:25,039
because this function is linear

564
00:20:26,000 --> 00:20:28,000
and last but not least this is very

565
00:20:28,000 --> 00:20:29,919
suitable for gpu as well but by lifting

566
00:20:29,919 --> 00:20:31,039
is very

567
00:20:31,039 --> 00:20:33,840
serial in computation

568
00:20:33,840 --> 00:20:37,360
this can be easily paralyzed

569
00:20:37,520 --> 00:20:39,600
so what's the correlation that we get

570
00:20:39,600 --> 00:20:41,440
on the left we have the value of our

571
00:20:41,440 --> 00:20:42,640
dual hash

572
00:20:42,640 --> 00:20:44,559
and on the bottom we have the distance

573
00:20:44,559 --> 00:20:46,880
of our target to the left

574
00:20:46,880 --> 00:20:48,960
if you get a random target then most of

575
00:20:48,960 --> 00:20:51,280
these targets lie very far from the

576
00:20:51,280 --> 00:20:53,679
letters and only just a few like close

577
00:20:53,679 --> 00:20:56,400
enough that we're interested in them

578
00:20:56,400 --> 00:20:58,559
so if we set our filter at the height as

579
00:20:58,559 --> 00:20:59,520
this

580
00:20:59,520 --> 00:21:01,360
then we don't have to compute the bias

581
00:21:01,360 --> 00:21:02,880
for all of these

582
00:21:02,880 --> 00:21:05,200
pairs here

583
00:21:05,200 --> 00:21:06,960
and we only have to compute it for these

584
00:21:06,960 --> 00:21:09,280
few pairs that fly below here

585
00:21:09,280 --> 00:21:12,080
so that saves a lot of computation

586
00:21:12,080 --> 00:21:13,679
so last but not least we have to discuss

587
00:21:13,679 --> 00:21:15,039
memory

588
00:21:15,039 --> 00:21:16,480
that deceiving algorithms are very

589
00:21:16,480 --> 00:21:18,159
memory intensive

590
00:21:18,159 --> 00:21:20,240
and in our runs we had to store up to

591
00:21:20,240 --> 00:21:23,120
half a billion of factors

592
00:21:23,120 --> 00:21:25,760
so every byte we can save per vector

593
00:21:25,760 --> 00:21:27,840
saves us tens or hundreds of gigabytes

594
00:21:27,840 --> 00:21:29,600
in the end

595
00:21:29,600 --> 00:21:31,440
however the general shift kernel stores

596
00:21:31,440 --> 00:21:33,520
lots of information per factor

597
00:21:33,520 --> 00:21:35,679
for example the coefficients in the base

598
00:21:35,679 --> 00:21:36,880
representation

599
00:21:36,880 --> 00:21:39,520
the so-called transmit representation

600
00:21:39,520 --> 00:21:41,280
the length of the vectors

601
00:21:41,280 --> 00:21:43,280
a unique identifier

602
00:21:43,280 --> 00:21:45,440
this left target is pre-computed this

603
00:21:45,440 --> 00:21:48,320
dual hash is pre-computed if we use it

604
00:21:48,320 --> 00:21:50,080
but also a pop count that's being used

605
00:21:50,080 --> 00:21:51,679
to quickly decide if two vectors are

606
00:21:51,679 --> 00:21:54,799
somewhat close to each other

607
00:21:55,360 --> 00:21:57,520
and we want to remove all this except

608
00:21:57,520 --> 00:22:00,080
this x this length and the unique

609
00:22:00,080 --> 00:22:02,080
identifier

610
00:22:02,080 --> 00:22:03,840
and this means that we reduce the memory

611
00:22:03,840 --> 00:22:06,640
by more than 60 percent

612
00:22:06,640 --> 00:22:08,480
so why can we do this

613
00:22:08,480 --> 00:22:10,320
well this actually additional benefit

614
00:22:10,320 --> 00:22:12,799
from the fact that these bucket sizes

615
00:22:12,799 --> 00:22:14,640
have to have a minimum size of say

616
00:22:14,640 --> 00:22:16,559
sixteen thousand

617
00:22:16,559 --> 00:22:18,320
the overhead of computing all these

618
00:22:18,320 --> 00:22:20,559
things on the fly for inside of a single

619
00:22:20,559 --> 00:22:21,520
bucket

620
00:22:21,520 --> 00:22:24,080
is just linear in the bucket size times

621
00:22:24,080 --> 00:22:27,679
the d squared or these two dimension

622
00:22:27,679 --> 00:22:30,080
however after this we have to check for

623
00:22:30,080 --> 00:22:31,200
reductions

624
00:22:31,200 --> 00:22:34,159
and that is quadratic in the bucket size

625
00:22:34,159 --> 00:22:36,080
so over these large buckets

626
00:22:36,080 --> 00:22:37,840
the overhead of precomputing all these

627
00:22:37,840 --> 00:22:40,480
things on the fly on the gpu

628
00:22:40,480 --> 00:22:43,280
is negligible

629
00:22:44,320 --> 00:22:46,240
so what did this gpu implementation give

630
00:22:46,240 --> 00:22:47,919
us in terms of the two dimensional

631
00:22:47,919 --> 00:22:49,360
status changes

632
00:22:49,360 --> 00:22:51,039
well we got a new record at dimension

633
00:22:51,039 --> 00:22:52,400
180

634
00:22:52,400 --> 00:22:53,919
so here on the bottom we show the

635
00:22:53,919 --> 00:22:55,280
dimension

636
00:22:55,280 --> 00:22:57,440
of these challenges

637
00:22:57,440 --> 00:22:59,120
and on the left we show the wall time

638
00:22:59,120 --> 00:23:01,280
which is just the real lifetime that

639
00:23:01,280 --> 00:23:03,919
these experiments run

640
00:23:03,919 --> 00:23:06,320
so the purple points here represent the

641
00:23:06,320 --> 00:23:09,600
enumeration that are clearly very slow

642
00:23:09,600 --> 00:23:11,039
note that these are very slow while

643
00:23:11,039 --> 00:23:14,000
still running on the supercomputer

644
00:23:14,000 --> 00:23:15,600
the new records by the general sieve

645
00:23:15,600 --> 00:23:17,280
kernel up to dimension 1 and 5 are

646
00:23:17,280 --> 00:23:18,559
represented here

647
00:23:18,559 --> 00:23:20,080
and they are already significantly

648
00:23:20,080 --> 00:23:21,360
faster

649
00:23:21,360 --> 00:23:24,320
and these ran on a single machine

650
00:23:24,320 --> 00:23:26,400
and now in our work we see that we get

651
00:23:26,400 --> 00:23:29,360
an order of 2 magnitude speed up over

652
00:23:29,360 --> 00:23:30,720
the old results

653
00:23:30,720 --> 00:23:32,720
while still executing all this on a

654
00:23:32,720 --> 00:23:34,320
single machine

655
00:23:34,320 --> 00:23:36,880
with a few gpus

656
00:23:36,880 --> 00:23:38,880
and even less cpu cores than were

657
00:23:38,880 --> 00:23:40,799
available on this

658
00:23:40,799 --> 00:23:42,080
for the record for the general sieve

659
00:23:42,080 --> 00:23:44,399
kernel

660
00:23:44,720 --> 00:23:47,279
we stopped at dimension 180 which ran in

661
00:23:47,279 --> 00:23:49,120
about 51 days

662
00:23:49,120 --> 00:23:50,880
and we didn't stop because we didn't

663
00:23:50,880 --> 00:23:52,320
want to run it longer but we stopped

664
00:23:52,320 --> 00:23:54,240
because we reached our maximum ram size

665
00:23:54,240 --> 00:23:57,520
of one of therabat

666
00:23:57,760 --> 00:23:59,840
to go any higher we need more

667
00:23:59,840 --> 00:24:03,200
ram or maybe we need to save more memory

668
00:24:03,200 --> 00:24:05,039
so to conclude let us see if an argument

669
00:24:05,039 --> 00:24:07,200
can officially be implemented on gpus

670
00:24:07,200 --> 00:24:08,559
including all these more advanced

671
00:24:08,559 --> 00:24:10,559
techniques

672
00:24:10,559 --> 00:24:12,400
and the memory bottlenecks disappear

673
00:24:12,400 --> 00:24:15,279
when the buckets are large enough

674
00:24:15,279 --> 00:24:17,039
and this has extra benefit of saving

675
00:24:17,039 --> 00:24:20,400
lots of memory with negligible overhead

676
00:24:20,400 --> 00:24:22,480
however it's important to note that bgl

677
00:24:22,480 --> 00:24:25,120
beats pg-1 in practice on cpus but the

678
00:24:25,120 --> 00:24:29,360
crossover for gpus lies much much higher

679
00:24:29,360 --> 00:24:31,039
thank you for watching this video and

680
00:24:31,039 --> 00:24:32,640
here are some of the citations if you

681
00:24:32,640 --> 00:24:36,039
want to know more

