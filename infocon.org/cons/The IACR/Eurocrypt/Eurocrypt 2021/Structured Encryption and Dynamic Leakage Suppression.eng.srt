1
00:00:00,160 --> 00:00:02,879
hi my name is marilyn and i'm here today

2
00:00:02,879 --> 00:00:05,440
to present our work titled structured

3
00:00:05,440 --> 00:00:07,040
encryption and dynamic leakage

4
00:00:07,040 --> 00:00:08,400
suppression

5
00:00:08,400 --> 00:00:10,960
this is joint work with sunny kamara and

6
00:00:10,960 --> 00:00:13,920
tariq motas

7
00:00:13,920 --> 00:00:15,920
why is data security and privacy

8
00:00:15,920 --> 00:00:17,520
important

9
00:00:17,520 --> 00:00:19,439
it seems like almost every day in the

10
00:00:19,439 --> 00:00:22,560
news we hear of yet another data breach

11
00:00:22,560 --> 00:00:24,960
that compromises the personal data of

12
00:00:24,960 --> 00:00:27,680
millions of users

13
00:00:27,680 --> 00:00:30,000
on this slide are just a few of the

14
00:00:30,000 --> 00:00:34,000
biggest data breaches in 2020 and 2021

15
00:00:34,000 --> 00:00:36,480
each compromising millions of records

16
00:00:36,480 --> 00:00:38,480
and causing billions of dollars worth of

17
00:00:38,480 --> 00:00:40,079
damage

18
00:00:40,079 --> 00:00:43,360
and there are so many more

19
00:00:43,360 --> 00:00:45,440
one possible solution to this ever

20
00:00:45,440 --> 00:00:47,200
increasing problem

21
00:00:47,200 --> 00:00:50,320
is to encrypt all client data before

22
00:00:50,320 --> 00:00:53,199
uploading it to any external untrusted

23
00:00:53,199 --> 00:00:55,599
server

24
00:00:56,079 --> 00:00:57,199
however

25
00:00:57,199 --> 00:00:59,680
once the data is uploaded in encrypted

26
00:00:59,680 --> 00:01:00,559
form

27
00:01:00,559 --> 00:01:03,600
it should still be usable by the client

28
00:01:03,600 --> 00:01:05,840
for instance the client might still want

29
00:01:05,840 --> 00:01:07,439
to run queries

30
00:01:07,439 --> 00:01:08,880
over their data

31
00:01:08,880 --> 00:01:10,960
and receive the correct responses from

32
00:01:10,960 --> 00:01:13,600
the server without having to download

33
00:01:13,600 --> 00:01:17,119
and decrypt all of their data

34
00:01:17,119 --> 00:01:20,320
is it possible to do this efficiently

35
00:01:20,320 --> 00:01:23,119
this question is posed and studied in

36
00:01:23,119 --> 00:01:27,479
the field of encrypted search

37
00:01:28,080 --> 00:01:30,320
there are three main aspects to any

38
00:01:30,320 --> 00:01:32,960
encrypted search scheme

39
00:01:32,960 --> 00:01:35,200
the functionality of the scheme

40
00:01:35,200 --> 00:01:37,200
or how many different types of queries

41
00:01:37,200 --> 00:01:39,040
are supported by it

42
00:01:39,040 --> 00:01:41,040
for instance a scheme might support

43
00:01:41,040 --> 00:01:43,680
boolean combinations of queries or range

44
00:01:43,680 --> 00:01:45,920
queries

45
00:01:45,920 --> 00:01:48,640
the security of the scheme or how much

46
00:01:48,640 --> 00:01:51,119
meaningful information is revealed to

47
00:01:51,119 --> 00:01:52,840
the adversarial

48
00:01:52,840 --> 00:01:56,000
server and the efficiency of the scheme

49
00:01:56,000 --> 00:01:58,640
which can be measured using metrics such

50
00:01:58,640 --> 00:02:01,280
as server-side storage or communication

51
00:02:01,280 --> 00:02:03,680
cost

52
00:02:04,000 --> 00:02:05,360
there are several cryptographic

53
00:02:05,360 --> 00:02:07,520
primitives that can be used to construct

54
00:02:07,520 --> 00:02:09,679
an encrypted search scheme

55
00:02:09,679 --> 00:02:11,680
with varying trade-offs between these

56
00:02:11,680 --> 00:02:14,319
three aspects

57
00:02:14,319 --> 00:02:17,440
for example fully homomorphic encryption

58
00:02:17,440 --> 00:02:19,440
would allow the client to compute any

59
00:02:19,440 --> 00:02:21,200
function over the data with good

60
00:02:21,200 --> 00:02:23,280
security guarantees

61
00:02:23,280 --> 00:02:26,560
but it is not very efficient

62
00:02:26,560 --> 00:02:28,480
on the other hand property preserving

63
00:02:28,480 --> 00:02:29,599
encryption

64
00:02:29,599 --> 00:02:31,760
also allows the client to compute many

65
00:02:31,760 --> 00:02:34,080
functions over the data and it is very

66
00:02:34,080 --> 00:02:35,280
efficient

67
00:02:35,280 --> 00:02:37,680
however it also reveals a large amount

68
00:02:37,680 --> 00:02:40,000
of information about the data to the

69
00:02:40,000 --> 00:02:42,400
server

70
00:02:43,200 --> 00:02:45,040
in between the two we have structured

71
00:02:45,040 --> 00:02:47,280
encryption which offers reasonable

72
00:02:47,280 --> 00:02:50,400
functionality and efficiency

73
00:02:50,400 --> 00:02:52,400
while offering security that is in

74
00:02:52,400 --> 00:02:54,319
between that of fully homomorphic

75
00:02:54,319 --> 00:02:56,400
encryption and property preserving

76
00:02:56,400 --> 00:02:58,879
encryption

77
00:03:00,480 --> 00:03:02,239
structure encryption is a general

78
00:03:02,239 --> 00:03:04,879
primitive that allows a client to upload

79
00:03:04,879 --> 00:03:07,200
any encrypted data structure

80
00:03:07,200 --> 00:03:11,280
and run queries on the data structure

81
00:03:11,360 --> 00:03:14,080
structure encryption also allows for

82
00:03:14,080 --> 00:03:16,560
operations beyond queries

83
00:03:16,560 --> 00:03:19,440
for example ads or edits which change

84
00:03:19,440 --> 00:03:22,800
the underlying data structure

85
00:03:22,879 --> 00:03:24,400
and the security of a structural

86
00:03:24,400 --> 00:03:26,239
encryption scheme

87
00:03:26,239 --> 00:03:28,799
is often expressed with with respect to

88
00:03:28,799 --> 00:03:31,120
a persistent adversary which is an

89
00:03:31,120 --> 00:03:33,840
adversary who controls the server and

90
00:03:33,840 --> 00:03:36,000
observes the entire execution of the

91
00:03:36,000 --> 00:03:38,159
protocol

92
00:03:38,159 --> 00:03:40,239
and observes meaningful information

93
00:03:40,239 --> 00:03:42,959
during this execution about the data

94
00:03:42,959 --> 00:03:45,360
structure and the queries

95
00:03:45,360 --> 00:03:47,680
and this information is referred to as

96
00:03:47,680 --> 00:03:49,599
leakage

97
00:03:49,599 --> 00:03:51,840
and leakage has been studied in many

98
00:03:51,840 --> 00:03:55,200
different ways over the years

99
00:03:58,319 --> 00:04:00,480
one line of work asks the question of

100
00:04:00,480 --> 00:04:03,200
how much information is leaked or is it

101
00:04:03,200 --> 00:04:05,360
possible to quantify the leakage in

102
00:04:05,360 --> 00:04:07,680
terms of the number of bits

103
00:04:07,680 --> 00:04:11,519
for various cryptographic primitives

104
00:04:12,879 --> 00:04:15,200
another line of work asks the question

105
00:04:15,200 --> 00:04:16,000
if

106
00:04:16,000 --> 00:04:18,079
the leaked information can be used to

107
00:04:18,079 --> 00:04:20,478
attack structural encryption schemes and

108
00:04:20,478 --> 00:04:24,240
this was started in 2012

109
00:04:25,520 --> 00:04:27,520
yet another line of work asks the

110
00:04:27,520 --> 00:04:28,479
question

111
00:04:28,479 --> 00:04:31,680
if leakage can be eliminated completely

112
00:04:31,680 --> 00:04:33,600
and this work is known as leakage

113
00:04:33,600 --> 00:04:34,800
suppression

114
00:04:34,800 --> 00:04:37,120
and that is also the subject of our talk

115
00:04:37,120 --> 00:04:39,440
today

116
00:04:40,240 --> 00:04:41,919
and before i continue with leakage

117
00:04:41,919 --> 00:04:43,680
suppression i'd like to set up some

118
00:04:43,680 --> 00:04:46,000
preliminaries for terms that we will use

119
00:04:46,000 --> 00:04:48,240
in this talk

120
00:04:48,240 --> 00:04:50,000
so common data structures that we will

121
00:04:50,000 --> 00:04:51,759
be talking about

122
00:04:51,759 --> 00:04:53,759
include an array ram

123
00:04:53,759 --> 00:04:56,800
which is a set of values in memory

124
00:04:56,800 --> 00:04:59,120
that can be read and written

125
00:04:59,120 --> 00:05:02,800
and are usually indexed by the number

126
00:05:02,800 --> 00:05:06,479
or the position in the array

127
00:05:08,240 --> 00:05:10,880
another data type is a dictionary data

128
00:05:10,880 --> 00:05:14,639
type which maps labels to values

129
00:05:14,639 --> 00:05:16,960
and each label can be used to retrieve

130
00:05:16,960 --> 00:05:20,320
its corresponding value

131
00:05:21,440 --> 00:05:23,440
yet another data type is known as a

132
00:05:23,440 --> 00:05:26,560
multi-map which maps labels to tuples of

133
00:05:26,560 --> 00:05:27,600
values

134
00:05:27,600 --> 00:05:29,440
and these tuples could be of varying

135
00:05:29,440 --> 00:05:31,919
lengths so as you can see label one is

136
00:05:31,919 --> 00:05:34,560
mapped to three values in a tuple but

137
00:05:34,560 --> 00:05:36,800
label four is mapped to only one value

138
00:05:36,800 --> 00:05:39,520
in a tuple and so that is a multi-map

139
00:05:39,520 --> 00:05:42,000
structure

140
00:05:44,479 --> 00:05:46,240
i would also like to introduce some

141
00:05:46,240 --> 00:05:48,080
leakage patterns that will be we'll be

142
00:05:48,080 --> 00:05:50,880
talking about throughout the stock

143
00:05:50,880 --> 00:05:52,400
so given a client

144
00:05:52,400 --> 00:05:55,680
and say a multi-map that's encrypted so

145
00:05:55,680 --> 00:05:56,880
an emm

146
00:05:56,880 --> 00:05:59,440
on the server

147
00:05:59,440 --> 00:06:02,240
what is the query equality leakage

148
00:06:02,240 --> 00:06:04,720
so the query quality leakage

149
00:06:04,720 --> 00:06:06,479
reveals to the server

150
00:06:06,479 --> 00:06:08,160
if two queries

151
00:06:08,160 --> 00:06:11,199
to the multi-map are on the same label

152
00:06:11,199 --> 00:06:14,000
so say the client issues the sequence of

153
00:06:14,000 --> 00:06:15,360
three queries

154
00:06:15,360 --> 00:06:19,440
um l1 then l4 then l1 again

155
00:06:19,440 --> 00:06:21,440
even if the server doesn't know what the

156
00:06:21,440 --> 00:06:24,160
queries are if the server can identify

157
00:06:24,160 --> 00:06:24,960
that

158
00:06:24,960 --> 00:06:26,880
the first and the third queries were for

159
00:06:26,880 --> 00:06:28,479
the same label

160
00:06:28,479 --> 00:06:30,560
while the second one was not

161
00:06:30,560 --> 00:06:32,720
then that scheme leaks the query

162
00:06:32,720 --> 00:06:35,720
equality

163
00:06:38,960 --> 00:06:40,639
another leakage pattern we'll be talking

164
00:06:40,639 --> 00:06:42,960
about is volume

165
00:06:42,960 --> 00:06:44,960
and that is how many values correspond

166
00:06:44,960 --> 00:06:46,400
to a query

167
00:06:46,400 --> 00:06:49,520
so for instance if the client queries

168
00:06:49,520 --> 00:06:50,880
label one

169
00:06:50,880 --> 00:06:53,120
and the server can see that three

170
00:06:53,120 --> 00:06:56,800
encrypted values were returned

171
00:06:56,800 --> 00:06:58,960
and then the client query is labeled

172
00:06:58,960 --> 00:07:01,120
four and the server can see that only

173
00:07:01,120 --> 00:07:03,520
one encrypted value is returned

174
00:07:03,520 --> 00:07:06,479
then this scheme leaks the volume

175
00:07:06,479 --> 00:07:09,280
of the queries

176
00:07:10,000 --> 00:07:11,680
now when dynamic operations are

177
00:07:11,680 --> 00:07:14,080
introduced which is operations that can

178
00:07:14,080 --> 00:07:16,479
change the underlying structure so ads

179
00:07:16,479 --> 00:07:18,800
edits deletes

180
00:07:18,800 --> 00:07:20,960
then there's different types of leakage

181
00:07:20,960 --> 00:07:23,199
that are also introduced

182
00:07:23,199 --> 00:07:25,680
which could reveal information to the

183
00:07:25,680 --> 00:07:27,120
server

184
00:07:27,120 --> 00:07:29,919
so for instance the operation identity

185
00:07:29,919 --> 00:07:32,000
which is just simply which operation is

186
00:07:32,000 --> 00:07:33,680
the client running

187
00:07:33,680 --> 00:07:35,759
so a dynamic scheme would support many

188
00:07:35,759 --> 00:07:37,520
different types of operations like

189
00:07:37,520 --> 00:07:38,720
queries

190
00:07:38,720 --> 00:07:41,840
adding a new label editing an existing

191
00:07:41,840 --> 00:07:43,199
label

192
00:07:43,199 --> 00:07:45,759
and if the server can tell which

193
00:07:45,759 --> 00:07:49,039
operation is running currently

194
00:07:49,039 --> 00:07:50,560
then that is referred to as the

195
00:07:50,560 --> 00:07:54,160
operation identity leakage

196
00:07:54,319 --> 00:07:56,720
and similar to the query equality

197
00:07:56,720 --> 00:07:58,639
leakage there is a notion of operation

198
00:07:58,639 --> 00:08:00,080
equality

199
00:08:00,080 --> 00:08:03,120
which reveals to the server if two

200
00:08:03,120 --> 00:08:05,199
operations are

201
00:08:05,199 --> 00:08:07,360
are performed on the same label

202
00:08:07,360 --> 00:08:09,120
so

203
00:08:09,120 --> 00:08:11,199
if the client queries label one then

204
00:08:11,199 --> 00:08:14,319
queries label four and then edits label

205
00:08:14,319 --> 00:08:15,520
three

206
00:08:15,520 --> 00:08:17,759
and the server is able to

207
00:08:17,759 --> 00:08:19,520
tell that

208
00:08:19,520 --> 00:08:21,919
the first and the third operations

209
00:08:21,919 --> 00:08:24,000
happen on the same label

210
00:08:24,000 --> 00:08:26,160
then that leakage is referred to as the

211
00:08:26,160 --> 00:08:29,599
operation equality

212
00:08:30,800 --> 00:08:33,360
so here's those are some data structures

213
00:08:33,360 --> 00:08:35,200
and leakages that we'll be talking about

214
00:08:35,200 --> 00:08:37,919
in this talk and so we come back

215
00:08:37,919 --> 00:08:40,000
to the question of can leakage be

216
00:08:40,000 --> 00:08:42,399
eliminated completely

217
00:08:42,399 --> 00:08:44,480
and over the years there have been many

218
00:08:44,480 --> 00:08:46,480
works that look to answer this question

219
00:08:46,480 --> 00:08:49,279
for different components of leakage

220
00:08:49,279 --> 00:08:51,920
so for the query equality pattern

221
00:08:51,920 --> 00:08:53,600
there was a suppression framework that

222
00:08:53,600 --> 00:08:56,959
was introduced in 2018

223
00:08:56,959 --> 00:08:57,839
and

224
00:08:57,839 --> 00:08:59,920
similarly there was some work in volume

225
00:08:59,920 --> 00:09:02,640
hiding that was begun in 2019 and there

226
00:09:02,640 --> 00:09:05,040
have been many volume hiding

227
00:09:05,040 --> 00:09:06,080
um

228
00:09:06,080 --> 00:09:09,279
schemes since

229
00:09:09,279 --> 00:09:12,240
so why are these two patterns

230
00:09:12,240 --> 00:09:14,560
interesting they are very common in

231
00:09:14,560 --> 00:09:16,480
structure encryption schemes

232
00:09:16,480 --> 00:09:19,920
they show up in more complex schemes

233
00:09:19,920 --> 00:09:22,720
built out of simpler building blocks

234
00:09:22,720 --> 00:09:24,880
and they are very difficult to hide with

235
00:09:24,880 --> 00:09:26,399
simple approaches

236
00:09:26,399 --> 00:09:29,040
without introducing large inefficiencies

237
00:09:29,040 --> 00:09:31,839
into the scheme

238
00:09:34,560 --> 00:09:36,959
the query equality is one of the most

239
00:09:36,959 --> 00:09:39,519
common components of leakage

240
00:09:39,519 --> 00:09:42,000
so can it be suppressed

241
00:09:42,000 --> 00:09:44,959
a first idea is to use oram as a black

242
00:09:44,959 --> 00:09:49,279
box to suppress the query equality

243
00:09:49,279 --> 00:09:51,519
what does this mean

244
00:09:51,519 --> 00:09:54,000
that any data structure that is stored

245
00:09:54,000 --> 00:09:56,000
and queried by a client

246
00:09:56,000 --> 00:09:58,480
will have to be converted to an array

247
00:09:58,480 --> 00:10:00,480
and the corresponding accesses to the

248
00:10:00,480 --> 00:10:02,240
array

249
00:10:02,240 --> 00:10:05,040
so for during setup the data structure

250
00:10:05,040 --> 00:10:06,880
has to be flattened out

251
00:10:06,880 --> 00:10:08,560
to form an array

252
00:10:08,560 --> 00:10:10,640
and then any subsequent query to the

253
00:10:10,640 --> 00:10:11,760
structure

254
00:10:11,760 --> 00:10:13,920
has to be converted into a series of

255
00:10:13,920 --> 00:10:15,920
oram reads and writes

256
00:10:15,920 --> 00:10:17,760
before the response can be returned to

257
00:10:17,760 --> 00:10:19,839
the client

258
00:10:19,839 --> 00:10:22,880
however this solution incurs overheads

259
00:10:22,880 --> 00:10:25,760
in storage communication and the number

260
00:10:25,760 --> 00:10:27,760
of round trips required for the

261
00:10:27,760 --> 00:10:29,839
interaction

262
00:10:29,839 --> 00:10:30,800
further

263
00:10:30,800 --> 00:10:32,800
there could still be some leakage to the

264
00:10:32,800 --> 00:10:35,760
server including the volume of a query

265
00:10:35,760 --> 00:10:37,279
depending on the underlying data

266
00:10:37,279 --> 00:10:39,760
structure

267
00:10:40,399 --> 00:10:42,959
in order to address this a line of work

268
00:10:42,959 --> 00:10:45,519
on oblivious data structures began

269
00:10:45,519 --> 00:10:48,079
creating custom oram schemes tailored to

270
00:10:48,079 --> 00:10:50,079
specific data structures

271
00:10:50,079 --> 00:10:53,040
such as oblivious trees

272
00:10:53,040 --> 00:10:54,880
so on one end

273
00:10:54,880 --> 00:10:57,600
there was a general purpose solution

274
00:10:57,600 --> 00:11:00,800
which is inefficient and sometimes leaky

275
00:11:00,800 --> 00:11:02,720
and on the other end there are special

276
00:11:02,720 --> 00:11:05,200
purpose constructions made for each data

277
00:11:05,200 --> 00:11:07,600
structure

278
00:11:07,600 --> 00:11:10,079
so it is worth asking if there is a

279
00:11:10,079 --> 00:11:12,839
solution that provides something in

280
00:11:12,839 --> 00:11:15,440
between or can we suppress query

281
00:11:15,440 --> 00:11:17,519
equality for more general data

282
00:11:17,519 --> 00:11:18,720
structures

283
00:11:18,720 --> 00:11:20,880
more efficiently than black box oram

284
00:11:20,880 --> 00:11:23,439
simulation

285
00:11:25,360 --> 00:11:27,440
this question was answered by the query

286
00:11:27,440 --> 00:11:29,920
equality suppression framework that was

287
00:11:29,920 --> 00:11:32,399
introduced in 2018.

288
00:11:32,399 --> 00:11:34,240
this framework was inspired by the

289
00:11:34,240 --> 00:11:36,720
seminal square root oram construction of

290
00:11:36,720 --> 00:11:40,079
goldrich and ostrovsky

291
00:11:40,399 --> 00:11:42,320
the authors noted that the square root

292
00:11:42,320 --> 00:11:44,880
oram could be seen as a zero leakage

293
00:11:44,880 --> 00:11:47,680
dictionary or the cache

294
00:11:47,680 --> 00:11:49,839
being used to suppress the query

295
00:11:49,839 --> 00:11:52,720
equality leakage of an array which is

296
00:11:52,720 --> 00:11:55,519
known as the main memory

297
00:11:55,519 --> 00:11:57,519
and this could be viewed as a leakage

298
00:11:57,519 --> 00:11:59,279
suppression framework

299
00:11:59,279 --> 00:12:01,920
and in fact it could be generalized

300
00:12:01,920 --> 00:12:04,320
to more complex data structures

301
00:12:04,320 --> 00:12:05,920
than just arrays

302
00:12:05,920 --> 00:12:07,279
and therefore

303
00:12:07,279 --> 00:12:09,279
to higher order structure encryption

304
00:12:09,279 --> 00:12:11,600
schemes

305
00:12:11,600 --> 00:12:13,600
and it turned out that this framework

306
00:12:13,600 --> 00:12:16,320
was more efficient than blackbox oram

307
00:12:16,320 --> 00:12:17,600
simulation

308
00:12:17,600 --> 00:12:19,519
and comparable inefficiency to

309
00:12:19,519 --> 00:12:22,839
custom-made oblivious data

310
00:12:22,839 --> 00:12:26,000
structures however the framework only

311
00:12:26,000 --> 00:12:29,519
produced static schemes

312
00:12:30,320 --> 00:12:33,279
so even if the input scheme to this

313
00:12:33,279 --> 00:12:36,320
suppression framework was dynamic

314
00:12:36,320 --> 00:12:39,680
the output scheme would be static

315
00:12:39,680 --> 00:12:43,920
without any query quality leakage

316
00:12:44,560 --> 00:12:47,680
and once again it is natural to ask

317
00:12:47,680 --> 00:12:49,760
is it possible to suppress the query

318
00:12:49,760 --> 00:12:53,920
equality leakage in a dynamic setting

319
00:12:53,920 --> 00:12:55,120
or even

320
00:12:55,120 --> 00:12:57,680
is it possible to create a dynamic query

321
00:12:57,680 --> 00:13:02,079
equality suppressing framework

322
00:13:02,160 --> 00:13:04,720
in our work we show that this is indeed

323
00:13:04,720 --> 00:13:07,720
possible

324
00:13:08,000 --> 00:13:10,160
however there were several challenges to

325
00:13:10,160 --> 00:13:13,279
dynamic leakage suppression

326
00:13:13,279 --> 00:13:15,440
the first of these was that due to our

327
00:13:15,440 --> 00:13:17,600
techniques and the use of cache-based

328
00:13:17,600 --> 00:13:20,079
suppression from the static framework

329
00:13:20,079 --> 00:13:23,279
operation equality had to be suppressed

330
00:13:23,279 --> 00:13:27,040
for example if an ad and an edit were on

331
00:13:27,040 --> 00:13:30,000
the same label of a multi-map structure

332
00:13:30,000 --> 00:13:31,760
then that would have to be hidden from

333
00:13:31,760 --> 00:13:34,160
the server

334
00:13:34,160 --> 00:13:37,040
the second more complex challenge was

335
00:13:37,040 --> 00:13:39,040
that leakages are correlated in the

336
00:13:39,040 --> 00:13:40,639
dynamic setting

337
00:13:40,639 --> 00:13:43,199
for instance the operation identity

338
00:13:43,199 --> 00:13:45,680
leakage which operation is occurring at

339
00:13:45,680 --> 00:13:47,680
the moment in conjunction

340
00:13:47,680 --> 00:13:50,000
with the volume leakage could reveal

341
00:13:50,000 --> 00:13:51,920
additional information about the query

342
00:13:51,920 --> 00:13:53,600
equality

343
00:13:53,600 --> 00:13:56,000
so say the longest volume for a query

344
00:13:56,000 --> 00:13:57,839
was a hundred results

345
00:13:57,839 --> 00:14:00,079
and then the server observes an add

346
00:14:00,079 --> 00:14:02,480
operation and then later observes a

347
00:14:02,480 --> 00:14:05,360
query with 101 results

348
00:14:05,360 --> 00:14:07,360
for some input and query distributions

349
00:14:07,360 --> 00:14:09,839
it is possible for the server to infer

350
00:14:09,839 --> 00:14:11,600
the query equality using these

351
00:14:11,600 --> 00:14:14,560
additional leakages

352
00:14:14,560 --> 00:14:16,480
so our approach was to start with a

353
00:14:16,480 --> 00:14:18,720
volume hiding scheme as input to the

354
00:14:18,720 --> 00:14:21,199
framework so the volume leakage would

355
00:14:21,199 --> 00:14:23,279
already be suppressed

356
00:14:23,279 --> 00:14:25,040
and then we were able to suppress the

357
00:14:25,040 --> 00:14:29,279
operation identity in operation equality

358
00:14:29,279 --> 00:14:31,440
however volume hiding constructions at

359
00:14:31,440 --> 00:14:32,480
the time

360
00:14:32,480 --> 00:14:35,120
had limited dynamicity and could not

361
00:14:35,120 --> 00:14:37,760
support full dynamic operations

362
00:14:37,760 --> 00:14:39,760
and therefore our framework had to

363
00:14:39,760 --> 00:14:41,839
upgrade the dynamicity of these

364
00:14:41,839 --> 00:14:45,399
underlying schemes

365
00:14:48,959 --> 00:14:50,639
so what does the dynamic suppression

366
00:14:50,639 --> 00:14:54,079
framework do and how does it work

367
00:14:54,079 --> 00:14:56,240
so once again given a client and a

368
00:14:56,240 --> 00:14:57,199
server

369
00:14:57,199 --> 00:14:59,760
say the client has a multi-map with four

370
00:14:59,760 --> 00:15:02,240
labels and the four tuples corresponding

371
00:15:02,240 --> 00:15:04,639
to them

372
00:15:04,880 --> 00:15:08,079
our construction has an epoch length

373
00:15:08,079 --> 00:15:10,720
of lambda which is equal to three

374
00:15:10,720 --> 00:15:13,279
and lambda controls

375
00:15:13,279 --> 00:15:16,639
two things during setup

376
00:15:16,639 --> 00:15:20,000
one is that three dummy or empty entries

377
00:15:20,000 --> 00:15:22,639
are added into the multi-map structure

378
00:15:22,639 --> 00:15:24,839
which we will refer to as the main

379
00:15:24,839 --> 00:15:29,279
structure and a cache of size 3

380
00:15:29,279 --> 00:15:31,519
which we can consider as a zero leakage

381
00:15:31,519 --> 00:15:32,720
dictionary

382
00:15:32,720 --> 00:15:35,440
is also initialized and it's empty when

383
00:15:35,440 --> 00:15:37,120
it starts

384
00:15:37,120 --> 00:15:40,000
and both of these structures together

385
00:15:40,000 --> 00:15:42,480
from the encrypted

386
00:15:42,480 --> 00:15:44,240
data structure

387
00:15:44,240 --> 00:15:47,920
and are sent over to the server

388
00:15:49,040 --> 00:15:51,519
so once the server holds

389
00:15:51,519 --> 00:15:55,040
the encrypted structure the epoch begins

390
00:15:55,040 --> 00:15:56,959
and so what is an epoch an epoch

391
00:15:56,959 --> 00:15:59,440
consists of lambda operations on the

392
00:15:59,440 --> 00:16:00,480
structure

393
00:16:00,480 --> 00:16:02,720
and in this case lambda is three

394
00:16:02,720 --> 00:16:04,880
so up to three operations can occur in

395
00:16:04,880 --> 00:16:07,120
one epoch

396
00:16:07,120 --> 00:16:09,519
so say the first operation is

397
00:16:09,519 --> 00:16:12,240
a query on the label l1

398
00:16:12,240 --> 00:16:13,839
so the first thing the client does would

399
00:16:13,839 --> 00:16:16,800
be to read the cache and to check if l1

400
00:16:16,800 --> 00:16:19,440
is in the cache it's not

401
00:16:19,440 --> 00:16:23,680
and so the client now reads the location

402
00:16:23,680 --> 00:16:26,800
where l1 is in the main structure so

403
00:16:26,800 --> 00:16:28,720
it's in the fifth location

404
00:16:28,720 --> 00:16:30,800
so the client receives

405
00:16:30,800 --> 00:16:34,320
the tuple corresponding to l1

406
00:16:34,320 --> 00:16:36,800
and then the client writes the cache

407
00:16:36,800 --> 00:16:39,920
back to the server but now

408
00:16:39,920 --> 00:16:43,600
during the write the client updates l1

409
00:16:43,600 --> 00:16:45,759
and its corresponding tuple into the

410
00:16:45,759 --> 00:16:48,759
cache

411
00:16:50,320 --> 00:16:53,040
and say next the client wants to add

412
00:16:53,040 --> 00:16:55,519
label 5 a completely new label to the

413
00:16:55,519 --> 00:16:57,440
multi-map

414
00:16:57,440 --> 00:16:59,920
once again the client reads the cache

415
00:16:59,920 --> 00:17:01,759
checks for the label in the cache it

416
00:17:01,759 --> 00:17:03,680
does not exist

417
00:17:03,680 --> 00:17:06,079
and so the client now queries a random

418
00:17:06,079 --> 00:17:07,199
location

419
00:17:07,199 --> 00:17:08,880
from the main multi-map so one of the

420
00:17:08,880 --> 00:17:11,599
dummy locations

421
00:17:11,599 --> 00:17:13,679
and in this case it reads the first

422
00:17:13,679 --> 00:17:17,199
dummy just at the first location

423
00:17:17,199 --> 00:17:19,599
and then writes the cache back to the

424
00:17:19,599 --> 00:17:20,799
server

425
00:17:20,799 --> 00:17:22,720
and this time

426
00:17:22,720 --> 00:17:25,439
the client adds the label five into the

427
00:17:25,439 --> 00:17:27,760
cache

428
00:17:28,240 --> 00:17:30,480
and we notice that

429
00:17:30,480 --> 00:17:33,520
the cache is collecting the updates to

430
00:17:33,520 --> 00:17:36,480
the main structure

431
00:17:36,480 --> 00:17:38,640
and say the client now wants to edit the

432
00:17:38,640 --> 00:17:41,679
same label that it already queried

433
00:17:41,679 --> 00:17:43,919
so how does that work once again the

434
00:17:43,919 --> 00:17:46,720
client reads the cache

435
00:17:46,720 --> 00:17:50,000
l1 is in the cache

436
00:17:50,000 --> 00:17:51,919
and so the client

437
00:17:51,919 --> 00:17:53,679
now reads a dummy from the main

438
00:17:53,679 --> 00:17:55,840
structure

439
00:17:55,840 --> 00:17:58,240
and edits l1

440
00:17:58,240 --> 00:18:00,880
while writing back the cache so

441
00:18:00,880 --> 00:18:04,799
at the end of these three operations

442
00:18:04,799 --> 00:18:08,080
a query an add and then edit

443
00:18:08,080 --> 00:18:09,760
where the query and the edit were on the

444
00:18:09,760 --> 00:18:11,120
same label

445
00:18:11,120 --> 00:18:13,120
the server sees that

446
00:18:13,120 --> 00:18:15,679
three random locations in the main

447
00:18:15,679 --> 00:18:17,919
structure have been read

448
00:18:17,919 --> 00:18:19,840
and three entries have been written to

449
00:18:19,840 --> 00:18:22,880
the cache but the server cannot see

450
00:18:22,880 --> 00:18:25,760
inside of the cache

451
00:18:25,760 --> 00:18:28,880
and so one epoch is complete

452
00:18:28,880 --> 00:18:31,360
and at the end of an epoch we have a

453
00:18:31,360 --> 00:18:33,200
rebuild operation

454
00:18:33,200 --> 00:18:34,799
where the high level purpose of the

455
00:18:34,799 --> 00:18:36,000
rebuild

456
00:18:36,000 --> 00:18:39,440
is to regenerate the original state of

457
00:18:39,440 --> 00:18:41,679
the structure and the cache so the

458
00:18:41,679 --> 00:18:43,520
rebuild will

459
00:18:43,520 --> 00:18:45,919
combine the updates into the main

460
00:18:45,919 --> 00:18:48,240
structure and empty out the cache so

461
00:18:48,240 --> 00:18:50,240
that once again

462
00:18:50,240 --> 00:18:53,200
the epoch can start at zero

463
00:18:53,200 --> 00:18:55,679
so once again the cache will be empty

464
00:18:55,679 --> 00:18:58,000
and the execution of the operations can

465
00:18:58,000 --> 00:19:01,120
start all over again

466
00:19:05,520 --> 00:19:08,799
so how does the rebuild work

467
00:19:09,280 --> 00:19:12,240
the rebuild is divided into three stages

468
00:19:12,240 --> 00:19:15,120
so the first is extract and tag

469
00:19:15,120 --> 00:19:18,799
then this short the sort and shuffle

470
00:19:18,799 --> 00:19:21,918
and the update phase

471
00:19:23,280 --> 00:19:26,559
so in the extract and tag phase

472
00:19:26,559 --> 00:19:28,400
what happens

473
00:19:28,400 --> 00:19:30,960
the main challenge is that the client

474
00:19:30,960 --> 00:19:33,280
must must be able

475
00:19:33,280 --> 00:19:36,840
to collect all the correct updated

476
00:19:36,840 --> 00:19:40,240
entries for a new version of the

477
00:19:40,240 --> 00:19:41,919
multi-map

478
00:19:41,919 --> 00:19:44,240
while simultaneously not revealing to

479
00:19:44,240 --> 00:19:47,039
the server which of the labels were

480
00:19:47,039 --> 00:19:48,799
updated

481
00:19:48,799 --> 00:19:51,200
and not revealing to the server which

482
00:19:51,200 --> 00:19:54,000
how many labels were found in the cache

483
00:19:54,000 --> 00:19:56,799
and which they were

484
00:19:57,520 --> 00:19:59,760
so

485
00:19:59,760 --> 00:20:02,320
the client initializes a ram at the

486
00:20:02,320 --> 00:20:04,720
server side and this ram is just to be

487
00:20:04,720 --> 00:20:07,520
thought of as an array

488
00:20:07,520 --> 00:20:09,919
and the client extracts

489
00:20:09,919 --> 00:20:13,120
each entry first from the cache and then

490
00:20:13,120 --> 00:20:15,679
from the main multi-map

491
00:20:15,679 --> 00:20:20,600
and adds them to the ram one by one

492
00:20:20,720 --> 00:20:22,960
so this is now inside the ram each of

493
00:20:22,960 --> 00:20:25,679
these entries has been added to the ram

494
00:20:25,679 --> 00:20:27,280
and while

495
00:20:27,280 --> 00:20:29,360
they were added to the ram

496
00:20:29,360 --> 00:20:32,559
each of them is tagged with what we call

497
00:20:32,559 --> 00:20:34,640
a freshness value

498
00:20:34,640 --> 00:20:36,640
and the freshness value indicates

499
00:20:36,640 --> 00:20:40,320
whether this particular label tuple pair

500
00:20:40,320 --> 00:20:42,799
should be part of the new data structure

501
00:20:42,799 --> 00:20:45,039
so is it a fresh value that should be

502
00:20:45,039 --> 00:20:46,159
considered

503
00:20:46,159 --> 00:20:48,720
in the next data structure

504
00:20:48,720 --> 00:20:50,799
so just for illustration

505
00:20:50,799 --> 00:20:52,559
these freshness values are shown here

506
00:20:52,559 --> 00:20:54,480
but you should think of it as being

507
00:20:54,480 --> 00:20:55,840
inside

508
00:20:55,840 --> 00:20:58,720
each of the corresponding entries

509
00:20:58,720 --> 00:20:59,600
and

510
00:20:59,600 --> 00:21:01,679
we can see that

511
00:21:01,679 --> 00:21:04,000
only two of the entries have zero

512
00:21:04,000 --> 00:21:07,520
freshness or they are stale values

513
00:21:07,520 --> 00:21:08,799
and that is

514
00:21:08,799 --> 00:21:11,280
a dummy that was found in the cache

515
00:21:11,280 --> 00:21:14,000
as well as the label one

516
00:21:14,000 --> 00:21:16,480
which was updated by the client in the

517
00:21:16,480 --> 00:21:19,200
last epoch

518
00:21:19,600 --> 00:21:21,919
and so now we come to how do we separate

519
00:21:21,919 --> 00:21:22,880
out

520
00:21:22,880 --> 00:21:26,159
these scale zero freshness values

521
00:21:26,159 --> 00:21:28,159
from the other values without

522
00:21:28,159 --> 00:21:30,960
revealing to the server

523
00:21:30,960 --> 00:21:33,760
which is which

524
00:21:33,840 --> 00:21:36,320
so for this we have a sort and shuffle

525
00:21:36,320 --> 00:21:39,039
phase so the client and the server run

526
00:21:39,039 --> 00:21:41,600
an oblivious sort protocol

527
00:21:41,600 --> 00:21:44,640
based on the freshness values and this

528
00:21:44,640 --> 00:21:47,840
enables the zero freshness

529
00:21:47,840 --> 00:21:50,240
labels to be sorted out

530
00:21:50,240 --> 00:21:52,000
from the remaining

531
00:21:52,000 --> 00:21:53,600
labels and

532
00:21:53,600 --> 00:21:56,480
the other labels are shuffled

533
00:21:56,480 --> 00:21:58,240
according to their freshness values so

534
00:21:58,240 --> 00:22:00,400
the sort serves two purposes

535
00:22:00,400 --> 00:22:03,200
one is to remove the zero freshness

536
00:22:03,200 --> 00:22:05,520
entries and the other is to

537
00:22:05,520 --> 00:22:06,720
shuffle up

538
00:22:06,720 --> 00:22:10,400
the non-zero freshness entries

539
00:22:10,400 --> 00:22:12,720
and once this step is complete

540
00:22:12,720 --> 00:22:15,200
the zero freshness entries can be

541
00:22:15,200 --> 00:22:18,400
truncated and discarded

542
00:22:18,400 --> 00:22:21,760
and now once again the client uses

543
00:22:21,760 --> 00:22:24,320
the ram the entries in the ram

544
00:22:24,320 --> 00:22:28,000
to rebuild or to create a new structure

545
00:22:28,000 --> 00:22:30,480
which contains these updated fresh

546
00:22:30,480 --> 00:22:31,919
entries

547
00:22:31,919 --> 00:22:34,000
so for each

548
00:22:34,000 --> 00:22:36,080
entry in the ram

549
00:22:36,080 --> 00:22:38,159
the client uses

550
00:22:38,159 --> 00:22:40,159
like downloads it and then uses an

551
00:22:40,159 --> 00:22:41,919
update protocol

552
00:22:41,919 --> 00:22:44,480
to create a new encrypted multi-map

553
00:22:44,480 --> 00:22:46,880
on the server side so each entry in the

554
00:22:46,880 --> 00:22:48,159
ram

555
00:22:48,159 --> 00:22:49,760
is downloaded

556
00:22:49,760 --> 00:22:54,360
and then updated to this new structure

557
00:22:54,559 --> 00:22:57,600
and then at the very end of this

558
00:22:57,600 --> 00:23:01,280
the new cache is initialized new empty

559
00:23:01,280 --> 00:23:04,240
cache once again of size three

560
00:23:04,240 --> 00:23:07,520
and we can run the next epoch of size

561
00:23:07,520 --> 00:23:09,840
three

562
00:23:10,320 --> 00:23:12,159
the ram is discarded

563
00:23:12,159 --> 00:23:15,919
and the rebuilding is complete

564
00:23:17,440 --> 00:23:19,600
so once again to summarize the working

565
00:23:19,600 --> 00:23:21,360
of the dynamic query equality

566
00:23:21,360 --> 00:23:23,200
suppression framework

567
00:23:23,200 --> 00:23:26,320
the client runs lambda operations in one

568
00:23:26,320 --> 00:23:29,039
ebook and for each of these operations

569
00:23:29,039 --> 00:23:30,960
the server only sees

570
00:23:30,960 --> 00:23:33,760
a read of the cache a read of a random

571
00:23:33,760 --> 00:23:36,159
location in the main structure and the

572
00:23:36,159 --> 00:23:38,159
right of the cache

573
00:23:38,159 --> 00:23:40,960
and at the end of this

574
00:23:40,960 --> 00:23:42,159
epoch

575
00:23:42,159 --> 00:23:44,880
the client rebuilds the structure and to

576
00:23:44,880 --> 00:23:48,159
rebuild the structure it creates a ram

577
00:23:48,159 --> 00:23:50,400
uses the ram to create

578
00:23:50,400 --> 00:23:53,200
a new updated structure

579
00:23:53,200 --> 00:23:55,440
and then discards the ram

580
00:23:55,440 --> 00:23:57,679
and all through this epoch the operation

581
00:23:57,679 --> 00:23:59,520
equality the query equality and the

582
00:23:59,520 --> 00:24:02,240
operation identity are suppressed

583
00:24:02,240 --> 00:24:04,080
and therefore are not revealed to the

584
00:24:04,080 --> 00:24:06,480
server

585
00:24:10,400 --> 00:24:12,480
finally on this slide we have some

586
00:24:12,480 --> 00:24:14,480
concrete efficiency numbers for a

587
00:24:14,480 --> 00:24:16,960
sequence of 64 add operations to a

588
00:24:16,960 --> 00:24:20,799
multi-map containing 2 to the 16 values

589
00:24:20,799 --> 00:24:23,120
and we are comparing our framework

590
00:24:23,120 --> 00:24:25,919
applied to avlh which is a volume hiding

591
00:24:25,919 --> 00:24:27,520
scheme

592
00:24:27,520 --> 00:24:31,120
to black box simulation using pathoram

593
00:24:31,120 --> 00:24:33,200
and the standard dynamic encrypted

594
00:24:33,200 --> 00:24:36,000
multi-map scheme

595
00:24:36,000 --> 00:24:38,080
and we are comparing on the measures of

596
00:24:38,080 --> 00:24:40,240
client state that is how much

597
00:24:40,240 --> 00:24:42,960
information the client has to store

598
00:24:42,960 --> 00:24:44,960
how much storage has to be used on the

599
00:24:44,960 --> 00:24:47,600
server side and how much communication

600
00:24:47,600 --> 00:24:49,679
happens

601
00:24:49,679 --> 00:24:52,240
for these lambda operations

602
00:24:52,240 --> 00:24:53,600
and the leakage

603
00:24:53,600 --> 00:24:56,400
and for our particular framework these

604
00:24:56,400 --> 00:25:01,320
numbers also include the rebuild

605
00:25:02,400 --> 00:25:03,760
so

606
00:25:03,760 --> 00:25:06,080
if we compare our framework to black box

607
00:25:06,080 --> 00:25:08,480
simulation using oram we see that we are

608
00:25:08,480 --> 00:25:10,159
more efficient

609
00:25:10,159 --> 00:25:13,679
but we do have more leakage than oram

610
00:25:13,679 --> 00:25:16,559
so at a high level we leak this total

611
00:25:16,559 --> 00:25:18,000
size

612
00:25:18,000 --> 00:25:19,760
of the structures the total number of

613
00:25:19,760 --> 00:25:22,080
labels values and the maximum tuple

614
00:25:22,080 --> 00:25:23,279
length

615
00:25:23,279 --> 00:25:25,600
and we leak the same parameters of the

616
00:25:25,600 --> 00:25:28,080
new structure so after rebuilding but we

617
00:25:28,080 --> 00:25:30,640
leak nothing during the operations or

618
00:25:30,640 --> 00:25:33,600
during the rebuild

619
00:25:35,120 --> 00:25:36,320
so

620
00:25:36,320 --> 00:25:38,240
but if we compare

621
00:25:38,240 --> 00:25:41,120
our construction to standard emms we see

622
00:25:41,120 --> 00:25:42,960
that we are far off from optimal

623
00:25:42,960 --> 00:25:44,320
efficiency

624
00:25:44,320 --> 00:25:45,840
but our leakage

625
00:25:45,840 --> 00:25:47,760
profile is much better because standard

626
00:25:47,760 --> 00:25:50,080
emms always leak the volume and the

627
00:25:50,080 --> 00:25:53,960
query quality patterns

628
00:26:00,640 --> 00:26:02,640
so once again here is a summary of our

629
00:26:02,640 --> 00:26:04,159
contributions

630
00:26:04,159 --> 00:26:05,840
thank you for your time and please see

631
00:26:05,840 --> 00:26:07,679
our paper for more details

632
00:26:07,679 --> 00:26:10,840
thank you

