1
00:00:01,280 --> 00:00:03,280
hello everyone welcome to this

2
00:00:03,280 --> 00:00:06,480
presentation my name is chen chun tan

3
00:00:06,480 --> 00:00:08,400
this presentation is prepared as a

4
00:00:08,400 --> 00:00:11,599
pre-recorded video for eurocrypt 2021

5
00:00:11,599 --> 00:00:14,000
the title of this talk is a deeper look

6
00:00:14,000 --> 00:00:15,200
at machine learning based crypto

7
00:00:15,200 --> 00:00:16,480
analysis

8
00:00:16,480 --> 00:00:18,080
this is a joint work with adrian

9
00:00:18,080 --> 00:00:19,279
benamira

10
00:00:19,279 --> 00:00:22,800
david geron thomas payan and myself

11
00:00:22,800 --> 00:00:24,640
i'll be presenting for the first half

12
00:00:24,640 --> 00:00:26,080
and adrian will be presenting for the

13
00:00:26,080 --> 00:00:28,320
next half

14
00:00:28,320 --> 00:00:30,240
this talk is divided into three main

15
00:00:30,240 --> 00:00:32,079
parts the first part will be the

16
00:00:32,079 --> 00:00:33,840
preliminaries where we will talk about

17
00:00:33,840 --> 00:00:35,280
the background work required to

18
00:00:35,280 --> 00:00:37,040
understand this presentation

19
00:00:37,040 --> 00:00:39,040
in particular a previous work in crypto

20
00:00:39,040 --> 00:00:41,760
19 by erin gore

21
00:00:41,760 --> 00:00:43,440
the next part we will explore the

22
00:00:43,440 --> 00:00:45,680
intuition of gauze neural distinguishers

23
00:00:45,680 --> 00:00:48,480
from a crypto analysis perspective

24
00:00:48,480 --> 00:00:51,280
lastly we will focus on how we can mix a

25
00:00:51,280 --> 00:00:52,719
machine learning pipeline and

26
00:00:52,719 --> 00:00:54,960
traditional crypto analysis to replace

27
00:00:54,960 --> 00:00:58,160
the new distinguishes

28
00:00:58,160 --> 00:01:00,399
this is the wrong function of the spike

29
00:01:00,399 --> 00:01:01,680
cipher

30
00:01:01,680 --> 00:01:04,319
spec is an arg cipher and has a

31
00:01:04,319 --> 00:01:06,159
physical-like structure

32
00:01:06,159 --> 00:01:08,960
the s functions over here represents the

33
00:01:08,960 --> 00:01:10,640
bitwise rotations

34
00:01:10,640 --> 00:01:13,119
alpha and betas are parameters that

35
00:01:13,119 --> 00:01:16,240
changes depending on the block size

36
00:01:16,240 --> 00:01:18,640
the block plus over here represents the

37
00:01:18,640 --> 00:01:22,240
modulo addition by 212 n

38
00:01:22,240 --> 00:01:24,000
and since for the sake of this

39
00:01:24,000 --> 00:01:26,159
presentation we are only focusing on the

40
00:01:26,159 --> 00:01:27,200
smallest

41
00:01:27,200 --> 00:01:29,280
cipher in the spec family

42
00:01:29,280 --> 00:01:32,159
we will fix the block size to be 32 and

43
00:01:32,159 --> 00:01:36,079
therefore the l4 and beta to be 7 and 2.

44
00:01:36,079 --> 00:01:39,200
note that for spec cipher the ddt is

45
00:01:39,200 --> 00:01:41,680
usually too large to be constructed

46
00:01:41,680 --> 00:01:44,240
one alternative will be to approximately

47
00:01:44,240 --> 00:01:46,720
experimentally by keeping the higher

48
00:01:46,720 --> 00:01:50,320
probable differences only

49
00:01:50,479 --> 00:01:53,200
in crypto 2019 aaron gore published a

50
00:01:53,200 --> 00:01:55,200
paper called improving a text on wrong

51
00:01:55,200 --> 00:01:57,920
review spec 32 using deep learning

52
00:01:57,920 --> 00:01:59,520
we will summarize the main points that

53
00:01:59,520 --> 00:02:02,159
are relevant to this presentation

54
00:02:02,159 --> 00:02:03,280
firstly

55
00:02:03,280 --> 00:02:05,520
gold created a new level architecture

56
00:02:05,520 --> 00:02:06,719
and trained them to be new

57
00:02:06,719 --> 00:02:09,679
distinguishers for videos rounds or spec

58
00:02:09,679 --> 00:02:12,400
essentially the aim of the distinguisher

59
00:02:12,400 --> 00:02:14,640
is to distinguish cipher text that come

60
00:02:14,640 --> 00:02:16,879
from plain text pairs with a fixed input

61
00:02:16,879 --> 00:02:19,360
difference as opposed to those that come

62
00:02:19,360 --> 00:02:22,400
from a random input difference

63
00:02:22,400 --> 00:02:25,360
gore did a comparison with his pure

64
00:02:25,360 --> 00:02:27,360
differential distinguishes which are

65
00:02:27,360 --> 00:02:30,080
actually large this large ddt's that

66
00:02:30,080 --> 00:02:32,239
spans for end rounds

67
00:02:32,239 --> 00:02:34,080
the neural distinguishers did a better

68
00:02:34,080 --> 00:02:38,319
job for all 5 to 8 rounds

69
00:02:38,319 --> 00:02:41,280
one notable result that gore has is that

70
00:02:41,280 --> 00:02:43,040
he improved significantly the time

71
00:02:43,040 --> 00:02:45,360
complexity of the 11 round key recovery

72
00:02:45,360 --> 00:02:48,160
attack compared to the previous best

73
00:02:48,160 --> 00:02:52,080
formed by denial in sec 2014

74
00:02:52,080 --> 00:02:54,080
this is the structure of gauze neural

75
00:02:54,080 --> 00:02:56,000
distinguisher the input to the

76
00:02:56,000 --> 00:02:58,560
distinguisher is a pair of ciphertexts

77
00:02:58,560 --> 00:03:00,800
encoded in binary

78
00:03:00,800 --> 00:03:02,959
it passes through multiple convoluted

79
00:03:02,959 --> 00:03:04,720
blocks before moving on to the

80
00:03:04,720 --> 00:03:06,480
prediction head and eventually

81
00:03:06,480 --> 00:03:09,200
outputting a single value in between 0

82
00:03:09,200 --> 00:03:10,400
and 1.

83
00:03:10,400 --> 00:03:12,400
this is also the score that the newer

84
00:03:12,400 --> 00:03:14,560
distinction is giving the ciphertext

85
00:03:14,560 --> 00:03:15,760
pair

86
00:03:15,760 --> 00:03:17,760
if the score is more than or equal to

87
00:03:17,760 --> 00:03:21,440
0.5 it will be considered as real

88
00:03:21,440 --> 00:03:24,080
or comes from the fixed input difference

89
00:03:24,080 --> 00:03:28,400
otherwise it's considered as random

90
00:03:30,080 --> 00:03:32,640
these are the results of gauze pure

91
00:03:32,640 --> 00:03:35,040
differential distinguishes pdd

92
00:03:35,040 --> 00:03:37,360
and neural distinguishes nd

93
00:03:37,360 --> 00:03:39,519
you can see that for each round

94
00:03:39,519 --> 00:03:41,840
the nds are actually performing better

95
00:03:41,840 --> 00:03:44,640
than the pdd

96
00:03:45,680 --> 00:03:48,720
now we move on to the next part

97
00:03:48,720 --> 00:03:50,720
in this part we aim to explore two

98
00:03:50,720 --> 00:03:52,319
questions

99
00:03:52,319 --> 00:03:54,080
the first would be what type of

100
00:03:54,080 --> 00:03:55,840
cryptanalysis is cause

101
00:03:55,840 --> 00:03:58,239
neurodistinguishes learning

102
00:03:58,239 --> 00:03:59,599
and the second

103
00:03:59,599 --> 00:04:01,680
can we actually replicate the results

104
00:04:01,680 --> 00:04:04,159
without using the neural network

105
00:04:04,159 --> 00:04:06,560
but using techniques that crypt analysts

106
00:04:06,560 --> 00:04:09,360
are more familiar with

107
00:04:09,360 --> 00:04:11,120
to answer the first question

108
00:04:11,120 --> 00:04:13,680
you have to conduct multiple experiments

109
00:04:13,680 --> 00:04:16,478
in an attempt to reverse engineer what

110
00:04:16,478 --> 00:04:18,079
the new distinguishers are looking out

111
00:04:18,079 --> 00:04:20,320
for

112
00:04:20,478 --> 00:04:22,400
for the ciphertext pairs gore used to

113
00:04:22,400 --> 00:04:24,400
train the neural distinguishers they

114
00:04:24,400 --> 00:04:26,960
come from plaintext pairs with this

115
00:04:26,960 --> 00:04:28,880
particular input difference

116
00:04:28,880 --> 00:04:31,280
having just a single active bit on the

117
00:04:31,280 --> 00:04:33,040
left part

118
00:04:33,040 --> 00:04:35,600
well this is the best input difference

119
00:04:35,600 --> 00:04:38,000
for differential characteristics for 3

120
00:04:38,000 --> 00:04:40,560
and 4 rounds of the spec round function

121
00:04:40,560 --> 00:04:43,360
it is not for the case of five rounds

122
00:04:43,360 --> 00:04:46,000
for five rounds the best differential

123
00:04:46,000 --> 00:04:47,600
characteristic starts from this

124
00:04:47,600 --> 00:04:50,720
particular input difference

125
00:04:52,160 --> 00:04:54,800
as a first try we retrain gauze neural

126
00:04:54,800 --> 00:04:56,960
distinguisher using this particular

127
00:04:56,960 --> 00:04:58,639
input difference

128
00:04:58,639 --> 00:05:01,039
the accuracy was around 76

129
00:05:01,039 --> 00:05:03,039
compared to 93 percent in the five round

130
00:05:03,039 --> 00:05:04,000
case

131
00:05:04,000 --> 00:05:06,400
this is actually quite counterintuitive

132
00:05:06,400 --> 00:05:08,400
as we would expect the best differential

133
00:05:08,400 --> 00:05:11,440
characteristic will you the same if not

134
00:05:11,440 --> 00:05:14,000
better results

135
00:05:14,000 --> 00:05:16,560
the next experiment we did was to ensure

136
00:05:16,560 --> 00:05:17,840
a fair play between the pure

137
00:05:17,840 --> 00:05:19,280
differential distinguishes and neural

138
00:05:19,280 --> 00:05:20,639
distinctions

139
00:05:20,639 --> 00:05:23,280
that is since rddt only assess the

140
00:05:23,280 --> 00:05:25,199
difference and nothing else

141
00:05:25,199 --> 00:05:26,880
then the neural distinguisher should

142
00:05:26,880 --> 00:05:28,639
only have access to the difference only

143
00:05:28,639 --> 00:05:29,919
as well

144
00:05:29,919 --> 00:05:31,919
therefore we retrain the neural

145
00:05:31,919 --> 00:05:34,320
distinguisher with just the difference

146
00:05:34,320 --> 00:05:37,280
in state of the entire ciphertext pair

147
00:05:37,280 --> 00:05:39,680
the accuracy in this case fell by a few

148
00:05:39,680 --> 00:05:41,440
percentages

149
00:05:41,440 --> 00:05:42,639
this means

150
00:05:42,639 --> 00:05:44,960
that while the bulk of the cases may be

151
00:05:44,960 --> 00:05:46,320
explained by the output difference

152
00:05:46,320 --> 00:05:48,560
distribution some of them have to be

153
00:05:48,560 --> 00:05:51,840
explained in some other manner

154
00:05:51,840 --> 00:05:54,160
with that we decided to do some sort of

155
00:05:54,160 --> 00:05:56,319
reverse engineering based on the scores

156
00:05:56,319 --> 00:05:58,960
that the neural distinguisher is giving

157
00:05:58,960 --> 00:06:01,280
in this case we want to know if a strong

158
00:06:01,280 --> 00:06:03,280
difference would mean everything to the

159
00:06:03,280 --> 00:06:05,360
neural distinguisher

160
00:06:05,360 --> 00:06:07,280
in this case we will send multiple

161
00:06:07,280 --> 00:06:09,039
ciphertext pairs into a new

162
00:06:09,039 --> 00:06:11,280
distinguishable and then we partition

163
00:06:11,280 --> 00:06:13,440
them based on the scores

164
00:06:13,440 --> 00:06:15,759
in particular we will focus on the ones

165
00:06:15,759 --> 00:06:17,919
that have a very high score

166
00:06:17,919 --> 00:06:20,000
as well as the ones that very low score

167
00:06:20,000 --> 00:06:23,199
into the buckets g and b

168
00:06:23,199 --> 00:06:25,600
next we compute the difference

169
00:06:25,600 --> 00:06:27,840
for each ciphertext and then we record

170
00:06:27,840 --> 00:06:31,360
down the top 1000 common differences

171
00:06:31,360 --> 00:06:33,520
for each of this difference

172
00:06:33,520 --> 00:06:34,479
we will

173
00:06:34,479 --> 00:06:38,080
again create a set of 1000 random pairs

174
00:06:38,080 --> 00:06:39,919
with this particular difference and we

175
00:06:39,919 --> 00:06:42,720
put into the set d i

176
00:06:42,720 --> 00:06:43,520
then

177
00:06:43,520 --> 00:06:46,160
for every one of them we send them

178
00:06:46,160 --> 00:06:49,840
through the newer distinction once again

179
00:06:50,080 --> 00:06:52,160
essentially at the very last phase we

180
00:06:52,160 --> 00:06:55,199
are sending a total of 1 million random

181
00:06:55,199 --> 00:06:56,000
pairs

182
00:06:56,000 --> 00:07:00,080
that come from 1 000 unique differences

183
00:07:00,080 --> 00:07:03,280
here are the results for the experiment

184
00:07:03,280 --> 00:07:05,759
for each given difference that is if you

185
00:07:05,759 --> 00:07:07,599
look into each di

186
00:07:07,599 --> 00:07:09,759
about three quarter of the ciphertext

187
00:07:09,759 --> 00:07:10,639
pairs

188
00:07:10,639 --> 00:07:13,440
have a score that is more than 0.5

189
00:07:13,440 --> 00:07:15,599
however we also do note that there are

190
00:07:15,599 --> 00:07:18,880
some exceptions that only have about 38

191
00:07:18,880 --> 00:07:21,680
having a score that's more than 0.5

192
00:07:21,680 --> 00:07:24,080
intuitively we will be expecting a

193
00:07:24,080 --> 00:07:26,800
decreasing percentage trend as we go

194
00:07:26,800 --> 00:07:28,400
from the most common difference to the

195
00:07:28,400 --> 00:07:31,120
least common difference however this is

196
00:07:31,120 --> 00:07:33,199
not the case that we observe

197
00:07:33,199 --> 00:07:35,680
therefore we cannot really say that if a

198
00:07:35,680 --> 00:07:37,680
difference is more probable

199
00:07:37,680 --> 00:07:39,440
then the neural distinguisher is more

200
00:07:39,440 --> 00:07:42,479
likely to recognize it

201
00:07:42,479 --> 00:07:45,440
next we repeat the experiment with some

202
00:07:45,440 --> 00:07:48,080
changes the changes are also highlighted

203
00:07:48,080 --> 00:07:50,000
in red over here

204
00:07:50,000 --> 00:07:51,840
basically before we compute the

205
00:07:51,840 --> 00:07:52,960
difference

206
00:07:52,960 --> 00:07:55,759
we first decrypt it by two rounds using

207
00:07:55,759 --> 00:07:57,759
the actual key

208
00:07:57,759 --> 00:07:58,479
then

209
00:07:58,479 --> 00:08:01,039
we rank and split them into sets based

210
00:08:01,039 --> 00:08:03,759
on their difference once again

211
00:08:03,759 --> 00:08:06,560
lastly we encrypted for two more rounds

212
00:08:06,560 --> 00:08:08,960
with another random key before we

213
00:08:08,960 --> 00:08:13,280
actually send them for evaluation

214
00:08:13,280 --> 00:08:15,599
we also did another one except that we

215
00:08:15,599 --> 00:08:18,000
only decrypt by one round over here and

216
00:08:18,000 --> 00:08:20,080
therefore we encrypt one round over here

217
00:08:20,080 --> 00:08:22,240
as well

218
00:08:22,240 --> 00:08:24,319
in both experiments that we decrypt by

219
00:08:24,319 --> 00:08:27,120
one or two rounds we notice that almost

220
00:08:27,120 --> 00:08:29,039
all of the pairs have a score that is

221
00:08:29,039 --> 00:08:31,199
more than 0.5

222
00:08:31,199 --> 00:08:33,039
and if you compare the true positive

223
00:08:33,039 --> 00:08:35,200
rates in both experiments

224
00:08:35,200 --> 00:08:37,200
this the experiment that we decreate by

225
00:08:37,200 --> 00:08:40,240
two rounds matches more similar to that

226
00:08:40,240 --> 00:08:42,640
of the neural distinguishes

227
00:08:42,640 --> 00:08:44,800
therefore we decide to venture further

228
00:08:44,800 --> 00:08:47,199
into it

229
00:08:47,360 --> 00:08:49,519
now we would like to find if there's any

230
00:08:49,519 --> 00:08:51,839
biases at this particular line over here

231
00:08:51,839 --> 00:08:55,279
which is the difference after we decrypt

232
00:08:55,279 --> 00:08:57,040
by two rounds

233
00:08:57,040 --> 00:08:59,360
after evaluating the biases

234
00:08:59,360 --> 00:09:02,000
of those ciphertext pairs in g and b

235
00:09:02,000 --> 00:09:03,360
respectively

236
00:09:03,360 --> 00:09:05,920
this is the plot that we have

237
00:09:05,920 --> 00:09:08,480
we can see that they are really some bit

238
00:09:08,480 --> 00:09:10,720
positions that are really biased for the

239
00:09:10,720 --> 00:09:13,040
civil tax pairs in g

240
00:09:13,040 --> 00:09:16,160
when we compare to the ones in b

241
00:09:16,160 --> 00:09:17,519
we locate the

242
00:09:17,519 --> 00:09:20,560
positions that the g is the most biased

243
00:09:20,560 --> 00:09:23,040
and we form this particular

244
00:09:23,040 --> 00:09:27,440
truncated differential and we call td3

245
00:09:27,440 --> 00:09:30,000
this td tree can also be explained when

246
00:09:30,000 --> 00:09:32,480
we trace the biases starting from round

247
00:09:32,480 --> 00:09:34,000
zero difference

248
00:09:34,000 --> 00:09:36,399
all the way until the end of round three

249
00:09:36,399 --> 00:09:38,160
as shown over here

250
00:09:38,160 --> 00:09:41,519
the bit positions that the tv3 fixes

251
00:09:41,519 --> 00:09:43,440
have a lower probability

252
00:09:43,440 --> 00:09:47,360
of having a carry propagated to them

253
00:09:47,360 --> 00:09:48,399
with that

254
00:09:48,399 --> 00:09:50,560
we make our first assumption that the

255
00:09:50,560 --> 00:09:52,080
neural network has the ability to

256
00:09:52,080 --> 00:09:54,399
determine the difference of certain bits

257
00:09:54,399 --> 00:09:56,640
at round three and round four with very

258
00:09:56,640 --> 00:09:58,880
high accuracy

259
00:09:58,880 --> 00:10:01,360
and we make our conductor that the five

260
00:10:01,360 --> 00:10:03,279
round numeral distinguisher

261
00:10:03,279 --> 00:10:07,360
is actually detecting td3 instead

262
00:10:07,360 --> 00:10:10,720
to verify our assumption 1 we retrain

263
00:10:10,720 --> 00:10:13,040
the neural distinctions with ciphertext

264
00:10:13,040 --> 00:10:14,720
pairs that actually

265
00:10:14,720 --> 00:10:17,279
satisfy tv3

266
00:10:17,279 --> 00:10:21,440
and we obtain an accuracy of 96.57

267
00:10:21,440 --> 00:10:23,760
and in terms of the true positive rates

268
00:10:23,760 --> 00:10:27,040
it's almost 100

269
00:10:27,279 --> 00:10:29,200
based on what we have learned about what

270
00:10:29,200 --> 00:10:31,440
the new distinguisher is detecting

271
00:10:31,440 --> 00:10:33,920
we present our distinguisher that tests

272
00:10:33,920 --> 00:10:35,760
for similar properties with renewable

273
00:10:35,760 --> 00:10:36,959
distinctions

274
00:10:36,959 --> 00:10:38,560
represent the average key rank

275
00:10:38,560 --> 00:10:40,720
distinguisher

276
00:10:40,720 --> 00:10:44,560
in this discrimination we use a ddt

277
00:10:44,560 --> 00:10:47,040
however we require the ddt

278
00:10:47,040 --> 00:10:50,240
to be at n minus one round for a n round

279
00:10:50,240 --> 00:10:51,680
distinguisher

280
00:10:51,680 --> 00:10:53,680
and also we only need some of the

281
00:10:53,680 --> 00:10:55,120
positions

282
00:10:55,120 --> 00:10:57,200
based on this particular mass itself

283
00:10:57,200 --> 00:10:59,040
therefore it's actually really a must

284
00:10:59,040 --> 00:11:00,720
det state

285
00:11:00,720 --> 00:11:03,200
also note that this ddt is really

286
00:11:03,200 --> 00:11:06,160
generated using a data set of 10 above

287
00:11:06,160 --> 00:11:08,560
7.

288
00:11:08,560 --> 00:11:10,399
the idea of the distinguisher is first

289
00:11:10,399 --> 00:11:12,240
we decrypt the last round using all

290
00:11:12,240 --> 00:11:14,560
possible sum keys note that this all

291
00:11:14,560 --> 00:11:16,480
possible sub keys is actually less than

292
00:11:16,480 --> 00:11:18,720
power of 16 because we are only

293
00:11:18,720 --> 00:11:20,959
interested in some bit positions

294
00:11:20,959 --> 00:11:22,720
and the bit positions will be given by

295
00:11:22,720 --> 00:11:24,480
the mass over here

296
00:11:24,480 --> 00:11:26,800
in this particular case that we have we

297
00:11:26,800 --> 00:11:29,440
are only requiring to the power of 12

298
00:11:29,440 --> 00:11:32,240
different sub keys

299
00:11:32,240 --> 00:11:34,160
after we have decrypt using the last

300
00:11:34,160 --> 00:11:36,560
round sub key we look up the difference

301
00:11:36,560 --> 00:11:38,959
at this red line over here

302
00:11:38,959 --> 00:11:41,360
then we find out the probability of this

303
00:11:41,360 --> 00:11:42,800
red line

304
00:11:42,800 --> 00:11:44,480
using the mass dt that we have

305
00:11:44,480 --> 00:11:46,720
previously prepared

306
00:11:46,720 --> 00:11:48,640
for each ciphertext pair

307
00:11:48,640 --> 00:11:51,839
we compute the average probability of

308
00:11:51,839 --> 00:11:54,160
the differences over here

309
00:11:54,160 --> 00:11:56,240
if the average probability is actually

310
00:11:56,240 --> 00:11:58,079
higher than that of a uniform

311
00:11:58,079 --> 00:11:59,519
distribution

312
00:11:59,519 --> 00:12:02,320
we say that the ciphertext pair comes

313
00:12:02,320 --> 00:12:04,639
from the real distribution

314
00:12:04,639 --> 00:12:06,240
note that the real distribution

315
00:12:06,240 --> 00:12:08,639
indicates that a ciphertext pair comes

316
00:12:08,639 --> 00:12:11,680
from a plaintext pair whose input

317
00:12:11,680 --> 00:12:13,680
difference is the fixed input difference

318
00:12:13,680 --> 00:12:15,760
that we require

319
00:12:15,760 --> 00:12:17,839
otherwise we say that the ciphertext

320
00:12:17,839 --> 00:12:20,560
pair comes from a random distribution

321
00:12:20,560 --> 00:12:22,880
which means that the ciphertext pair

322
00:12:22,880 --> 00:12:25,200
comes from plain text whose input

323
00:12:25,200 --> 00:12:27,120
difference is basically

324
00:12:27,120 --> 00:12:29,120
just random

325
00:12:29,120 --> 00:12:30,399
there are actually several

326
00:12:30,399 --> 00:12:32,800
considerations we take into account when

327
00:12:32,800 --> 00:12:34,480
we crafting our average keyword

328
00:12:34,480 --> 00:12:36,000
distinguisher

329
00:12:36,000 --> 00:12:38,399
firstly we want to use the same amount

330
00:12:38,399 --> 00:12:41,120
of data set as score's neural network

331
00:12:41,120 --> 00:12:43,360
so the gauss neural distinction took 10

332
00:12:43,360 --> 00:12:45,600
to about seven seven tax pair in order

333
00:12:45,600 --> 00:12:46,959
to train it

334
00:12:46,959 --> 00:12:49,279
and that is why in our preparation for

335
00:12:49,279 --> 00:12:50,720
our mass gt

336
00:12:50,720 --> 00:12:54,079
we also use 10 to power 7.

337
00:12:54,079 --> 00:12:56,560
next we want to match the new

338
00:12:56,560 --> 00:12:59,040
distinguishes time complexity

339
00:12:59,040 --> 00:13:01,680
in the case for the new distinguisher

340
00:13:01,680 --> 00:13:02,399
the

341
00:13:02,399 --> 00:13:04,720
deep neural network essentially takes up

342
00:13:04,720 --> 00:13:08,160
to the power of 17 multiplications

343
00:13:08,160 --> 00:13:10,160
for hours we will have to take up to the

344
00:13:10,160 --> 00:13:12,560
power of 13 one round decryption for the

345
00:13:12,560 --> 00:13:15,040
spectrum function with a total of two

346
00:13:15,040 --> 00:13:17,440
total of 13 table lookups to the mass

347
00:13:17,440 --> 00:13:19,600
digit

348
00:13:19,600 --> 00:13:21,760
these are the results of the average q

349
00:13:21,760 --> 00:13:23,040
and distinction with the new

350
00:13:23,040 --> 00:13:25,760
distinguisher from 5 to 7 rounds

351
00:13:25,760 --> 00:13:27,680
in all the cases we actually have the

352
00:13:27,680 --> 00:13:29,360
results that are better than new

353
00:13:29,360 --> 00:13:31,120
distinguishes

354
00:13:31,120 --> 00:13:33,279
another interesting thing would be this

355
00:13:33,279 --> 00:13:34,959
degree of closeness

356
00:13:34,959 --> 00:13:36,880
to see how well both distinguishers

357
00:13:36,880 --> 00:13:38,880
actually agree with each other and if

358
00:13:38,880 --> 00:13:40,399
you look at the diagonals

359
00:13:40,399 --> 00:13:44,560
they made up almost 98 of the results

360
00:13:44,560 --> 00:13:47,040
now we can go back to answering our main

361
00:13:47,040 --> 00:13:49,680
questions can we actually replicate the

362
00:13:49,680 --> 00:13:51,440
results

363
00:13:51,440 --> 00:13:52,240
yes

364
00:13:52,240 --> 00:13:54,000
the degree of closeness between the two

365
00:13:54,000 --> 00:13:56,639
distinguishers is extremely close which

366
00:13:56,639 --> 00:13:58,399
convince us that they are actually

367
00:13:58,399 --> 00:14:02,000
testing for very similar properties

368
00:14:02,000 --> 00:14:04,160
as for what type of crypt analysis is

369
00:14:04,160 --> 00:14:06,560
the neural distinguisher is learning

370
00:14:06,560 --> 00:14:08,639
we are expecting something along the

371
00:14:08,639 --> 00:14:11,199
lines of differential linear

372
00:14:11,199 --> 00:14:13,839
however unlike traditional cryptanalysis

373
00:14:13,839 --> 00:14:15,920
which relies on independencies among

374
00:14:15,920 --> 00:14:17,279
characteristics

375
00:14:17,279 --> 00:14:20,079
the neural distinguisher is able to take

376
00:14:20,079 --> 00:14:22,800
all of them and all of the correlations

377
00:14:22,800 --> 00:14:25,519
into considerations

378
00:14:25,519 --> 00:14:26,880
for the next part

379
00:14:26,880 --> 00:14:28,880
each one will be taking over

380
00:14:28,880 --> 00:14:30,639
welcome in the second part of the

381
00:14:30,639 --> 00:14:32,880
presentation in which we will focus on

382
00:14:32,880 --> 00:14:35,279
exploring the neural distinguisher from

383
00:14:35,279 --> 00:14:38,639
a machine learning perspective

384
00:14:39,360 --> 00:14:40,720
now

385
00:14:40,720 --> 00:14:42,880
in this part we aim to explore two

386
00:14:42,880 --> 00:14:45,360
questions the first one is can gross

387
00:14:45,360 --> 00:14:47,440
neural distinguisher be replaced by a

388
00:14:47,440 --> 00:14:49,920
strategy inspired by both differential

389
00:14:49,920 --> 00:14:53,040
crypto analysis and machine learning

390
00:14:53,040 --> 00:14:56,079
the second one is can this new strategy

391
00:14:56,079 --> 00:14:58,560
be applied to more rounds or to another

392
00:14:58,560 --> 00:14:59,839
cipher

393
00:14:59,839 --> 00:15:01,680
to answer this question

394
00:15:01,680 --> 00:15:03,600
we need first to analyze the normal

395
00:15:03,600 --> 00:15:07,040
distinguished architecture

396
00:15:07,040 --> 00:15:09,760
it is composed of three blocks

397
00:15:09,760 --> 00:15:11,120
the first one

398
00:15:11,120 --> 00:15:13,360
here

399
00:15:13,360 --> 00:15:17,040
takes as input the two ciphertexts c0

400
00:15:17,040 --> 00:15:19,519
and c1

401
00:15:19,680 --> 00:15:22,639
as the first block is a one layer cnn

402
00:15:22,639 --> 00:15:24,720
conventional convolutional neural

403
00:15:24,720 --> 00:15:27,279
networks with kernel size 1 we suppose

404
00:15:27,279 --> 00:15:30,639
that it just do an input transformation

405
00:15:30,639 --> 00:15:34,000
that we need to characterize

406
00:15:34,000 --> 00:15:36,560
the second block is composed of 10

407
00:15:36,560 --> 00:15:38,160
sub-blocks

408
00:15:38,160 --> 00:15:40,480
each of the sub-blocks is composed of a

409
00:15:40,480 --> 00:15:45,519
two layers cnn with canon size 3.

410
00:15:45,519 --> 00:15:49,440
this part is the hardest to explain

411
00:15:49,440 --> 00:15:50,800
at the end

412
00:15:50,800 --> 00:15:52,240
we have

413
00:15:52,240 --> 00:15:56,560
a vector f which is the fitter's vector

414
00:15:56,560 --> 00:15:59,360
and each element of these filter vectors

415
00:15:59,360 --> 00:16:02,639
is a highly non-linear function of the

416
00:16:02,639 --> 00:16:05,279
new input

417
00:16:05,360 --> 00:16:08,480
finally the last block take as input the

418
00:16:08,480 --> 00:16:10,480
features f

419
00:16:10,480 --> 00:16:12,399
and outputs a score of the null

420
00:16:12,399 --> 00:16:14,720
distinguisher it is composed of two

421
00:16:14,720 --> 00:16:17,680
dense layers also called mlp4

422
00:16:17,680 --> 00:16:20,240
multi-layer placetron

423
00:16:20,240 --> 00:16:23,279
our objective here is to replace

424
00:16:23,279 --> 00:16:25,839
each of these individual blocks by a

425
00:16:25,839 --> 00:16:28,320
more interpretable one coming either

426
00:16:28,320 --> 00:16:30,560
from machine learning offer

427
00:16:30,560 --> 00:16:32,720
or from the crypto analysis point of

428
00:16:32,720 --> 00:16:35,720
view

429
00:16:36,079 --> 00:16:37,839
so we are going to start

430
00:16:37,839 --> 00:16:42,320
by block one and block three

431
00:16:44,160 --> 00:16:47,199
so the block three can be replaced by

432
00:16:47,199 --> 00:16:50,720
any other ensemble classifier

433
00:16:50,720 --> 00:16:52,959
for example the mmp block can be

434
00:16:52,959 --> 00:16:55,120
replaced by random forest or gradient

435
00:16:55,120 --> 00:16:55,700
boosting

436
00:16:55,700 --> 00:16:56,800
[Music]

437
00:16:56,800 --> 00:16:59,440
the first block

438
00:16:59,440 --> 00:17:01,519
actually can be replaced by a linear

439
00:17:01,519 --> 00:17:05,760
combination of the input

440
00:17:05,760 --> 00:17:09,039
we choose to fix our choice on delta l

441
00:17:09,039 --> 00:17:12,880
delta v v0 and v1 and the definition is

442
00:17:12,880 --> 00:17:15,600
given above

443
00:17:16,559 --> 00:17:18,319
you can formally proof this

444
00:17:18,319 --> 00:17:20,799
transformation by establishing the truth

445
00:17:20,799 --> 00:17:23,039
table of the first layer

446
00:17:23,039 --> 00:17:25,199
and therefore exhibit the linear input

447
00:17:25,199 --> 00:17:27,919
transformation

448
00:17:28,400 --> 00:17:30,880
what we have done so far

449
00:17:30,880 --> 00:17:33,760
so we managed to replace the first block

450
00:17:33,760 --> 00:17:36,960
by the linear input transformation

451
00:17:36,960 --> 00:17:40,320
and the third block can be any ansible

452
00:17:40,320 --> 00:17:42,480
machine learning classifier that's why

453
00:17:42,480 --> 00:17:43,919
we call

454
00:17:43,919 --> 00:17:46,640
this pi prime uh machine learning

455
00:17:46,640 --> 00:17:49,120
pipeline

456
00:17:49,120 --> 00:17:52,080
now our objective is to approximate the

457
00:17:52,080 --> 00:17:55,280
highly nonlinear vector f with a crypto

458
00:17:55,280 --> 00:17:58,000
analysis point of view

459
00:17:58,000 --> 00:17:59,919
we are going to take the time to explain

460
00:17:59,919 --> 00:18:04,400
how we manage to replace the block 2.

461
00:18:04,799 --> 00:18:06,960
the first interesting experiment that we

462
00:18:06,960 --> 00:18:09,280
have already seen is that if the input

463
00:18:09,280 --> 00:18:10,799
of the node is the

464
00:18:10,799 --> 00:18:13,600
normal distinguisher is c0c1 the

465
00:18:13,600 --> 00:18:16,480
difference between c0 and c1

466
00:18:16,480 --> 00:18:18,720
like for the pdt the model the normal

467
00:18:18,720 --> 00:18:22,160
distinguisher performs like the pdb

468
00:18:22,160 --> 00:18:25,039
therefore our first assumption is that

469
00:18:25,039 --> 00:18:26,840
the block 2 is able to do an

470
00:18:26,840 --> 00:18:29,600
approximation of the ddt but with

471
00:18:29,600 --> 00:18:31,760
different inputs instead of

472
00:18:31,760 --> 00:18:34,640
having the difference between c0 and c1

473
00:18:34,640 --> 00:18:38,160
it takes delta l delta v v01 v1

474
00:18:38,160 --> 00:18:40,720
but there is a limit

475
00:18:40,720 --> 00:18:44,880
of course uh because the new entry is 64

476
00:18:44,880 --> 00:18:46,720
bits and they are 10 to the power of

477
00:18:46,720 --> 00:18:49,120
seven samples it's not tractable

478
00:18:49,120 --> 00:18:50,799
moreover

479
00:18:50,799 --> 00:18:52,480
the null distinguisher actually is

480
00:18:52,480 --> 00:18:56,320
pretty small only 100k parameters

481
00:18:56,320 --> 00:18:57,840
therefore we think that the null

482
00:18:57,840 --> 00:19:00,720
distinguisher is able to compress the

483
00:19:00,720 --> 00:19:02,960
odt

484
00:19:02,960 --> 00:19:06,240
so now let's consider mask m

485
00:19:06,240 --> 00:19:10,600
with having white hw

486
00:19:10,640 --> 00:19:12,080
and now

487
00:19:12,080 --> 00:19:13,919
instead of taking

488
00:19:13,919 --> 00:19:17,120
the full input delta l data visio on v1

489
00:19:17,120 --> 00:19:20,160
we apply the mask on the input and then

490
00:19:20,160 --> 00:19:22,480
we compute the odt

491
00:19:22,480 --> 00:19:25,760
on this input mask

492
00:19:25,760 --> 00:19:28,559
and we get the probability of

493
00:19:28,559 --> 00:19:32,559
having real knowing the input

494
00:19:35,280 --> 00:19:37,280
the limit of the second exception is

495
00:19:37,280 --> 00:19:39,520
that if we consider only one mask of

496
00:19:39,520 --> 00:19:41,440
course we have only one probability at

497
00:19:41,440 --> 00:19:42,960
the end

498
00:19:42,960 --> 00:19:44,799
but the

499
00:19:44,799 --> 00:19:48,240
vector of features f that we need to act

500
00:19:48,240 --> 00:19:50,320
that we want to approximate

501
00:19:50,320 --> 00:19:52,559
has more than only one

502
00:19:52,559 --> 00:19:55,280
parameters therefore we need to consider

503
00:19:55,280 --> 00:19:57,840
a mask

504
00:19:58,240 --> 00:20:01,200
and then we have f tilt and ft is

505
00:20:01,200 --> 00:20:03,679
actually a pretty good approximation for

506
00:20:03,679 --> 00:20:06,679
f

507
00:20:07,120 --> 00:20:09,600
uh how we get that masks actually we

508
00:20:09,600 --> 00:20:11,600
managed to extract it from the neural

509
00:20:11,600 --> 00:20:14,000
distinguisher with different deep

510
00:20:14,000 --> 00:20:16,240
learning techniques interpretability

511
00:20:16,240 --> 00:20:18,080
different techniques

512
00:20:18,080 --> 00:20:22,399
such as for example the shapely values

513
00:20:22,480 --> 00:20:24,799
therefore we are able now to propose the

514
00:20:24,799 --> 00:20:27,120
final conjectures so

515
00:20:27,120 --> 00:20:29,679
how we can replace the block 2 which are

516
00:20:29,679 --> 00:20:34,080
the blocks between 2 1 and 210.

517
00:20:34,080 --> 00:20:35,919
we need to compute the distribution

518
00:20:35,919 --> 00:20:38,320
table for the input delta l delta v 0

519
00:20:38,320 --> 00:20:39,520
and v 1

520
00:20:39,520 --> 00:20:41,760
and we need to find see very relevant

521
00:20:41,760 --> 00:20:44,559
mask in order to apply this mask over

522
00:20:44,559 --> 00:20:45,840
the inputs

523
00:20:45,840 --> 00:20:50,000
then we can compute modt

524
00:20:50,559 --> 00:20:51,480
we

525
00:20:51,480 --> 00:20:53,440
successfully

526
00:20:53,440 --> 00:20:54,559
tried

527
00:20:54,559 --> 00:20:57,760
this conjecture and it works

528
00:20:57,760 --> 00:20:58,960
so

529
00:20:58,960 --> 00:21:00,000
finally

530
00:21:00,000 --> 00:21:02,640
what we have is

531
00:21:02,640 --> 00:21:04,720
we have seen that the block one is

532
00:21:04,720 --> 00:21:07,120
simply doing a linear transformation

533
00:21:07,120 --> 00:21:09,360
over the input

534
00:21:09,360 --> 00:21:12,640
the box three is simply

535
00:21:12,640 --> 00:21:14,640
classification actually a non-linear

536
00:21:14,640 --> 00:21:16,480
classification

537
00:21:16,480 --> 00:21:19,200
and we can replace the 10 layers in the

538
00:21:19,200 --> 00:21:21,760
middle actually the 20 layers of cnn in

539
00:21:21,760 --> 00:21:23,280
the middle by

540
00:21:23,280 --> 00:21:26,000
the modt

541
00:21:26,000 --> 00:21:29,120
we reach our objective to replace if

542
00:21:29,120 --> 00:21:31,360
these individual blocks by a more

543
00:21:31,360 --> 00:21:33,120
interpretable one

544
00:21:33,120 --> 00:21:34,960
coming either from machine learning for

545
00:21:34,960 --> 00:21:37,280
the block 3 or crypto analysis point of

546
00:21:37,280 --> 00:21:39,360
view block 1

547
00:21:39,360 --> 00:21:41,600
now let's replace the blocks step by

548
00:21:41,600 --> 00:21:44,000
steps and observe the evolution of the

549
00:21:44,000 --> 00:21:45,520
accuracy

550
00:21:45,520 --> 00:21:47,039
here is the

551
00:21:47,039 --> 00:21:48,480
summary table

552
00:21:48,480 --> 00:21:51,200
for 5 round spec here you can see the

553
00:21:51,200 --> 00:21:53,039
accuracy for the normal distinguisher

554
00:21:53,039 --> 00:21:55,840
and here for the pdb

555
00:21:55,840 --> 00:21:58,640
so if we replace block three so the m8p

556
00:21:58,640 --> 00:22:02,559
by run the rest we lose 0.5 percent and

557
00:22:02,559 --> 00:22:05,440
we are still higher than pvt

558
00:22:05,440 --> 00:22:08,080
if we replace block 1 by the linear

559
00:22:08,080 --> 00:22:09,280
combination

560
00:22:09,280 --> 00:22:12,880
we lose 0.3 percent and we are very

561
00:22:12,880 --> 00:22:15,039
close to the null distinguished accuracy

562
00:22:15,039 --> 00:22:18,159
and if we replace block 1 and block 2 by

563
00:22:18,159 --> 00:22:19,679
modt

564
00:22:19,679 --> 00:22:23,440
actually we get 92.3 percent

565
00:22:23,440 --> 00:22:27,600
and actually 92.3 is the accuracy of the

566
00:22:27,600 --> 00:22:29,679
overall pipeline

567
00:22:29,679 --> 00:22:30,400
so

568
00:22:30,400 --> 00:22:33,919
modt is when you replace every blocks by

569
00:22:33,919 --> 00:22:36,159
our hypothesis

570
00:22:36,159 --> 00:22:37,840
here

571
00:22:37,840 --> 00:22:39,440
you can see a comparison with no

572
00:22:39,440 --> 00:22:42,240
distinguisher of five rounds and pdd5

573
00:22:42,240 --> 00:22:44,159
rounds for spec again

574
00:22:44,159 --> 00:22:46,799
and you can see that we are

575
00:22:46,799 --> 00:22:48,880
very close from the north distinguisher

576
00:22:48,880 --> 00:22:49,600
and

577
00:22:49,600 --> 00:22:53,480
much higher than the pvd

578
00:22:54,240 --> 00:22:57,280
uh the table three we are now

579
00:22:57,280 --> 00:23:00,320
comparing the matching of the results

580
00:23:00,320 --> 00:23:02,960
between the old extinguisher and modt

581
00:23:02,960 --> 00:23:05,760
that means that if you have an input

582
00:23:05,760 --> 00:23:08,799
on how many samples do we have exactly

583
00:23:08,799 --> 00:23:10,960
the same

584
00:23:10,960 --> 00:23:12,960
prediction so we have the same

585
00:23:12,960 --> 00:23:15,320
prediction for

586
00:23:15,320 --> 00:23:18,559
75.5 percent which is actually pretty

587
00:23:18,559 --> 00:23:20,799
high

588
00:23:21,520 --> 00:23:22,880
other results

589
00:23:22,880 --> 00:23:25,200
so you can see in the paper that we

590
00:23:25,200 --> 00:23:28,640
manage also to extend our pipeline to

591
00:23:28,640 --> 00:23:30,159
six round spec

592
00:23:30,159 --> 00:23:33,039
and also we managed to accelerate it to

593
00:23:33,039 --> 00:23:36,760
eight round simon

594
00:23:37,520 --> 00:23:39,520
discussion

595
00:23:39,520 --> 00:23:43,120
now we can answer our first

596
00:23:43,120 --> 00:23:44,240
question

597
00:23:44,240 --> 00:23:46,159
can cause neural distinguisher be

598
00:23:46,159 --> 00:23:48,640
replaced by a strategy inspired by both

599
00:23:48,640 --> 00:23:50,559
differential crypto analysis and machine

600
00:23:50,559 --> 00:23:52,960
learning

601
00:23:53,520 --> 00:23:56,159
practically i would say almost our

602
00:23:56,159 --> 00:23:58,559
pipeline yields

603
00:23:58,559 --> 00:24:01,120
performances very close to those of the

604
00:24:01,120 --> 00:24:03,679
null distinguisher proposed by core

605
00:24:03,679 --> 00:24:05,039
and

606
00:24:05,039 --> 00:24:06,880
can this new strategy be applied to

607
00:24:06,880 --> 00:24:09,760
morons or to another cipher

608
00:24:09,760 --> 00:24:12,159
we have shown that our pipeline

609
00:24:12,159 --> 00:24:15,039
generalized from five to six front spec

610
00:24:15,039 --> 00:24:18,880
and that can be applied to electron sign

611
00:24:18,880 --> 00:24:23,039
thank you very much for your attention

