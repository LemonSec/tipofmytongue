1
00:00:01,599 --> 00:00:03,679
welcome to the presentation on the work

2
00:00:03,679 --> 00:00:06,640
titled 2 to the n over 2 time algorithm

3
00:00:06,640 --> 00:00:08,800
for square root n approx shortest vector

4
00:00:08,800 --> 00:00:10,800
problem and hermit shortest vector

5
00:00:10,800 --> 00:00:12,160
problem

6
00:00:12,160 --> 00:00:13,840
this is trying to work with diverse

7
00:00:13,840 --> 00:00:18,640
aggro world and noah stevens david do it

8
00:00:19,920 --> 00:00:21,520
so first of all let's look at some

9
00:00:21,520 --> 00:00:23,199
basics

10
00:00:23,199 --> 00:00:24,720
what is a lattice

11
00:00:24,720 --> 00:00:27,359
a lattice is a discrete sub group

12
00:00:27,359 --> 00:00:30,400
so here i have a two dimensional letters

13
00:00:30,400 --> 00:00:32,880
and it's specified by a set of linearly

14
00:00:32,880 --> 00:00:35,760
independent basis vectors

15
00:00:35,760 --> 00:00:38,239
the last the lattice is then generated

16
00:00:38,239 --> 00:00:40,960
by all integer combinations of these

17
00:00:40,960 --> 00:00:44,440
basis vectors

18
00:00:44,640 --> 00:00:46,800
why do we study lattice

19
00:00:46,800 --> 00:00:48,960
lattice has been used for cryptography

20
00:00:48,960 --> 00:00:51,120
since the seminal work of eye tight in

21
00:00:51,120 --> 00:00:52,719
1996

22
00:00:52,719 --> 00:00:54,800
and it has a bunch of

23
00:00:54,800 --> 00:00:56,559
advantages

24
00:00:56,559 --> 00:00:59,120
so there is this worst case to average

25
00:00:59,120 --> 00:01:01,840
case reduction therefore the security of

26
00:01:01,840 --> 00:01:03,680
latin space cryptography

27
00:01:03,680 --> 00:01:06,799
relies on the worst case hardness of

28
00:01:06,799 --> 00:01:10,240
some lattice problem

29
00:01:10,240 --> 00:01:12,560
it is believed to be resistant to

30
00:01:12,560 --> 00:01:15,360
quantum computers

31
00:01:15,360 --> 00:01:17,840
and it can do more for example it can do

32
00:01:17,840 --> 00:01:21,680
homo fully homomorphic inclusion

33
00:01:23,200 --> 00:01:25,439
next let's look at the

34
00:01:25,439 --> 00:01:27,920
lattice problems that is the focus of

35
00:01:27,920 --> 00:01:30,079
this work

36
00:01:30,079 --> 00:01:32,000
so we start with the shortest vector

37
00:01:32,000 --> 00:01:34,240
problem svp

38
00:01:34,240 --> 00:01:36,799
it looks for a shortest non-zero vector

39
00:01:36,799 --> 00:01:38,960
of a given lattice

40
00:01:38,960 --> 00:01:41,360
so for example in the two dimensional

41
00:01:41,360 --> 00:01:43,040
letters here

42
00:01:43,040 --> 00:01:45,520
the red vector v

43
00:01:45,520 --> 00:01:48,640
is a shortest vector

44
00:01:48,640 --> 00:01:52,880
and we use lambda 1 to denote its length

45
00:01:53,759 --> 00:01:56,320
and for an approx version

46
00:01:56,320 --> 00:01:58,079
gamma svp

47
00:01:58,079 --> 00:02:01,280
it looks for a short lattice vector

48
00:02:01,280 --> 00:02:04,000
that is of length within gamma times

49
00:02:04,000 --> 00:02:07,360
lambda 1 and it's a nonzero vector

50
00:02:07,360 --> 00:02:09,280
so for example if we take gamma to be

51
00:02:09,280 --> 00:02:10,800
equals to 2

52
00:02:10,800 --> 00:02:13,920
then any lattice vector within the green

53
00:02:13,920 --> 00:02:15,040
ball here

54
00:02:15,040 --> 00:02:17,040
is a valid solution

55
00:02:17,040 --> 00:02:21,640
to the 2 scp problem

56
00:02:23,440 --> 00:02:25,599
the shortest vector problem is a half

57
00:02:25,599 --> 00:02:26,720
problem

58
00:02:26,720 --> 00:02:30,800
so just to give a simple illustration

59
00:02:30,800 --> 00:02:32,800
for example if

60
00:02:32,800 --> 00:02:35,360
the only information that is given

61
00:02:35,360 --> 00:02:38,640
is two basis vectors b1 and b2

62
00:02:38,640 --> 00:02:41,599
and this set of bases is not a very nice

63
00:02:41,599 --> 00:02:43,200
set of bases

64
00:02:43,200 --> 00:02:45,760
it's not straightforward to see where

65
00:02:45,760 --> 00:02:46,480
the

66
00:02:46,480 --> 00:02:50,599
shortest vector v would lie

67
00:02:51,519 --> 00:02:54,319
and more concretely there has been a lot

68
00:02:54,319 --> 00:02:56,879
of studies on the harness

69
00:02:56,879 --> 00:03:00,400
or the complexity of gamma svp across

70
00:03:00,400 --> 00:03:03,440
different approximation factors

71
00:03:03,440 --> 00:03:04,879
and

72
00:03:04,879 --> 00:03:07,200
when approximation factor is around poly

73
00:03:07,200 --> 00:03:08,080
n

74
00:03:08,080 --> 00:03:12,400
is most relevant to cryptography

75
00:03:15,280 --> 00:03:16,879
the next problem that we'll be looking

76
00:03:16,879 --> 00:03:19,360
at is the hermit shortest vector problem

77
00:03:19,360 --> 00:03:21,280
hsvp

78
00:03:21,280 --> 00:03:24,159
so for each of the letters it has a

79
00:03:24,159 --> 00:03:26,400
determinant

80
00:03:26,400 --> 00:03:28,480
and

81
00:03:28,480 --> 00:03:31,120
basically the determinant of a

82
00:03:31,120 --> 00:03:33,680
lattice is just the

83
00:03:33,680 --> 00:03:34,720
volume

84
00:03:34,720 --> 00:03:36,319
or over here because we have a two

85
00:03:36,319 --> 00:03:38,319
dimensional lattice is the area

86
00:03:38,319 --> 00:03:40,879
of this parallelogram

87
00:03:40,879 --> 00:03:41,760
and

88
00:03:41,760 --> 00:03:44,000
from the diagram we can see that

89
00:03:44,000 --> 00:03:46,959
if a lattice has small determinant

90
00:03:46,959 --> 00:03:51,200
it will imply that it's fairly dense

91
00:03:52,000 --> 00:03:55,040
and the gamma hsvp problem

92
00:03:55,040 --> 00:03:57,680
therefore looks for a short lattice

93
00:03:57,680 --> 00:03:58,799
vector

94
00:03:58,799 --> 00:04:01,200
whose length is within

95
00:04:01,200 --> 00:04:02,959
gamma times

96
00:04:02,959 --> 00:04:05,120
the determinant of the lattice

97
00:04:05,120 --> 00:04:09,040
normalized to the power of one over n

98
00:04:09,920 --> 00:04:12,640
and because of the minkowski's theorem

99
00:04:12,640 --> 00:04:15,120
we know that for any lattice

100
00:04:15,120 --> 00:04:17,600
there exists a its shortest vector is a

101
00:04:17,600 --> 00:04:18,478
within

102
00:04:18,478 --> 00:04:20,160
a factor of square root n

103
00:04:20,160 --> 00:04:23,600
times this normalized determinant

104
00:04:23,600 --> 00:04:26,240
and moreover for random letters

105
00:04:26,240 --> 00:04:28,720
this actually takes equality

106
00:04:28,720 --> 00:04:30,960
up to some constant factor

107
00:04:30,960 --> 00:04:32,160
so in

108
00:04:32,160 --> 00:04:33,600
other words

109
00:04:33,600 --> 00:04:35,680
the best approximation factor that we

110
00:04:35,680 --> 00:04:41,639
can hope for for hsvp it's square root n

111
00:04:42,160 --> 00:04:44,560
so why do we care about this

112
00:04:44,560 --> 00:04:47,280
hermit svp forum

113
00:04:47,280 --> 00:04:50,240
because of the existence of this slide

114
00:04:50,240 --> 00:04:54,320
reduction algorithm or the bkz algorithm

115
00:04:54,320 --> 00:04:58,560
where they reduce poly approx svp

116
00:04:58,560 --> 00:05:01,360
to concern approximately svp of lower

117
00:05:01,360 --> 00:05:03,759
ranks

118
00:05:04,000 --> 00:05:06,400
and we make the observation that

119
00:05:06,400 --> 00:05:08,479
in such reductions

120
00:05:08,479 --> 00:05:10,560
they are using the constant approximate

121
00:05:10,560 --> 00:05:11,440
vector

122
00:05:11,440 --> 00:05:12,479
problem

123
00:05:12,479 --> 00:05:15,919
as a oracle for a square and approx hsvp

124
00:05:15,919 --> 00:05:17,840
oracle

125
00:05:17,840 --> 00:05:20,800
so in other words if we can solve square

126
00:05:20,800 --> 00:05:23,199
root n across hsvp

127
00:05:23,199 --> 00:05:25,440
it suffices for us

128
00:05:25,440 --> 00:05:28,479
to use it in this light reduction to

129
00:05:28,479 --> 00:05:31,520
give to to get a good algorithm for poly

130
00:05:31,520 --> 00:05:34,400
approx svp

131
00:05:35,840 --> 00:05:37,520
so what do we

132
00:05:37,520 --> 00:05:39,600
achieve eventually

133
00:05:39,600 --> 00:05:42,960
we find a 2 to the n 2 time algorithm

134
00:05:42,960 --> 00:05:45,600
for square root n approx svp

135
00:05:45,600 --> 00:05:49,120
and also for square root approx hsvp

136
00:05:49,120 --> 00:05:52,400
and because of the slide reduction

137
00:05:52,400 --> 00:05:54,639
we are able to give faster algorithms

138
00:05:54,639 --> 00:05:56,160
for poly

139
00:05:56,160 --> 00:05:58,240
poly and approx svp

140
00:05:58,240 --> 00:06:00,720
for almost all

141
00:06:00,720 --> 00:06:04,280
polyene factor

142
00:06:08,720 --> 00:06:11,919
i would like to emphasize that this work

143
00:06:11,919 --> 00:06:13,919
actually has no direct impact on

144
00:06:13,919 --> 00:06:15,520
cryptography

145
00:06:15,520 --> 00:06:17,280
because there exists heuristic

146
00:06:17,280 --> 00:06:19,039
algorithms for the shortest vector

147
00:06:19,039 --> 00:06:19,919
problem

148
00:06:19,919 --> 00:06:23,440
that runs in much faster time

149
00:06:23,440 --> 00:06:25,520
so they achieve a running time of 3 over

150
00:06:25,520 --> 00:06:27,520
2 to the n over to

151
00:06:27,520 --> 00:06:28,880
running time

152
00:06:28,880 --> 00:06:31,039
and in these heuristic algorithms

153
00:06:31,039 --> 00:06:33,520
they bring in heuristic assumptions that

154
00:06:33,520 --> 00:06:36,000
are not proven but experimentally

155
00:06:36,000 --> 00:06:38,080
verified

156
00:06:38,080 --> 00:06:40,960
so in some sense there is a huge gap

157
00:06:40,960 --> 00:06:42,880
between probable algorithms and

158
00:06:42,880 --> 00:06:44,960
heuristic algorithms and this will

159
00:06:44,960 --> 00:06:46,080
actually

160
00:06:46,080 --> 00:06:49,280
serve as a step towards closing the gap

161
00:06:49,280 --> 00:06:50,880
between provable and heuristic

162
00:06:50,880 --> 00:06:52,000
algorithms

163
00:06:52,000 --> 00:06:55,599
for the shortest vector problem

164
00:06:58,080 --> 00:07:00,639
next let's look at what our algorithm

165
00:07:00,639 --> 00:07:03,440
actually do

166
00:07:03,440 --> 00:07:05,680
so before that i would like to repeat

167
00:07:05,680 --> 00:07:07,599
again what is our goal

168
00:07:07,599 --> 00:07:10,080
we are looking for lattice vectors

169
00:07:10,080 --> 00:07:11,440
they are short

170
00:07:11,440 --> 00:07:14,800
and they are non-zero the zero vector is

171
00:07:14,800 --> 00:07:17,800
uninteresting

172
00:07:18,560 --> 00:07:21,360
and here is a overview a high level high

173
00:07:21,360 --> 00:07:23,199
level idea of

174
00:07:23,199 --> 00:07:24,960
what's happening

175
00:07:24,960 --> 00:07:26,400
in our algorithm

176
00:07:26,400 --> 00:07:28,160
so in the beginning

177
00:07:28,160 --> 00:07:30,960
we are going to sample a bunch of

178
00:07:30,960 --> 00:07:33,599
vectors lattice vectors from the input

179
00:07:33,599 --> 00:07:35,440
lattice l

180
00:07:35,440 --> 00:07:36,560
such that

181
00:07:36,560 --> 00:07:40,160
this vectors has some nice disk nice

182
00:07:40,160 --> 00:07:43,440
property and the expected square norm is

183
00:07:43,440 --> 00:07:47,440
going to be some parameter t

184
00:07:49,199 --> 00:07:50,639
next

185
00:07:50,639 --> 00:07:53,599
for the next r iterations

186
00:07:53,599 --> 00:07:56,160
we are going to keep pairing the vectors

187
00:07:56,160 --> 00:07:59,120
and subtracting the pair that we have

188
00:07:59,120 --> 00:08:02,319
so in one step we get about a list of

189
00:08:02,319 --> 00:08:05,360
vectors that falls in l1

190
00:08:05,360 --> 00:08:07,360
and after our steps

191
00:08:07,360 --> 00:08:08,720
we're going to

192
00:08:08,720 --> 00:08:11,120
end up with a list of vectors

193
00:08:11,120 --> 00:08:14,479
who falls in lr and we'll make sure that

194
00:08:14,479 --> 00:08:16,000
this lr

195
00:08:16,000 --> 00:08:18,160
is going to be 2 to the k

196
00:08:18,160 --> 00:08:20,560
times the input lattice l

197
00:08:20,560 --> 00:08:22,240
so it's a

198
00:08:22,240 --> 00:08:24,000
scale up version of

199
00:08:24,000 --> 00:08:26,960
the input lattice

200
00:08:26,960 --> 00:08:29,520
and we also then show that the expected

201
00:08:29,520 --> 00:08:30,960
square norm of

202
00:08:30,960 --> 00:08:34,000
these vectors that we receive at the end

203
00:08:34,000 --> 00:08:38,880
we have x would be 2 to the r times t

204
00:08:38,880 --> 00:08:41,760
now we if we do a little bit of scaling

205
00:08:41,760 --> 00:08:43,519
so if we scale them

206
00:08:43,519 --> 00:08:44,720
down

207
00:08:44,720 --> 00:08:45,920
to

208
00:08:45,920 --> 00:08:49,199
become the input lattice

209
00:08:49,279 --> 00:08:51,440
its expected square knob would be 2 to

210
00:08:51,440 --> 00:08:55,120
the r minus 2k times t and if we can

211
00:08:55,120 --> 00:08:56,160
show that

212
00:08:56,160 --> 00:08:58,000
the factor here

213
00:08:58,000 --> 00:09:00,880
it's less than 1 then we are making

214
00:09:00,880 --> 00:09:05,200
progress at least in terms of the length

215
00:09:07,360 --> 00:09:09,600
now let's zoom in into

216
00:09:09,600 --> 00:09:11,279
what happens in one step of the

217
00:09:11,279 --> 00:09:13,839
algorithm

218
00:09:14,160 --> 00:09:16,720
so we start with some nicely distributed

219
00:09:16,720 --> 00:09:18,240
vectors

220
00:09:18,240 --> 00:09:20,000
that falls into the

221
00:09:20,000 --> 00:09:23,839
the force in the lattice l0

222
00:09:23,839 --> 00:09:26,800
and for sub lattice l1

223
00:09:26,800 --> 00:09:29,200
we are going to partition the vectors

224
00:09:29,200 --> 00:09:31,360
into buckets

225
00:09:31,360 --> 00:09:33,760
and for the audience who are familiar

226
00:09:33,760 --> 00:09:36,160
with lattice cosets these brackets are

227
00:09:36,160 --> 00:09:40,560
just cosets in l0 over l1

228
00:09:40,800 --> 00:09:43,680
we partition the vectors into brackets

229
00:09:43,680 --> 00:09:46,080
and within the same bracket we are going

230
00:09:46,080 --> 00:09:47,839
to arbitrarily pair

231
00:09:47,839 --> 00:09:50,720
and subtract vectors

232
00:09:50,720 --> 00:09:52,080
and

233
00:09:52,080 --> 00:09:53,600
in the end we are going to receive a

234
00:09:53,600 --> 00:09:54,800
bunch of

235
00:09:54,800 --> 00:09:57,120
nicely distributed vectors

236
00:09:57,120 --> 00:10:00,080
that falls into the lattice l1

237
00:10:00,080 --> 00:10:02,320
the reason why these vectors falls into

238
00:10:02,320 --> 00:10:05,600
l1 is because when we take

239
00:10:05,600 --> 00:10:08,320
a pair of vectors in the same bucket and

240
00:10:08,320 --> 00:10:09,920
we subtract them

241
00:10:09,920 --> 00:10:11,680
the offset is

242
00:10:11,680 --> 00:10:14,399
cancelled out so the remaining component

243
00:10:14,399 --> 00:10:15,680
has to be

244
00:10:15,680 --> 00:10:19,839
falling in the lattice l1

245
00:10:21,360 --> 00:10:23,680
now let's see what happens to the

246
00:10:23,680 --> 00:10:25,760
expected square norm

247
00:10:25,760 --> 00:10:28,560
so we are taking a pair of vectors and

248
00:10:28,560 --> 00:10:30,399
we subtract them

249
00:10:30,399 --> 00:10:33,200
now if we expand out this

250
00:10:33,200 --> 00:10:34,880
norm squared

251
00:10:34,880 --> 00:10:36,959
we have the expected square number of

252
00:10:36,959 --> 00:10:39,839
the first vector and the second vector

253
00:10:39,839 --> 00:10:41,680
and we have a inner product term in the

254
00:10:41,680 --> 00:10:42,320
b

255
00:10:42,320 --> 00:10:44,079
in the middle

256
00:10:44,079 --> 00:10:46,079
and we claim that this inner product

257
00:10:46,079 --> 00:10:47,040
term

258
00:10:47,040 --> 00:10:48,720
is actually going to take the value of

259
00:10:48,720 --> 00:10:50,640
0.

260
00:10:50,640 --> 00:10:52,399
this is because

261
00:10:52,399 --> 00:10:53,680
this

262
00:10:53,680 --> 00:10:55,760
list of vectors that we get

263
00:10:55,760 --> 00:10:58,320
are going to be distributed as

264
00:10:58,320 --> 00:11:00,560
so x is going to be distributed the same

265
00:11:00,560 --> 00:11:02,480
as minus x

266
00:11:02,480 --> 00:11:04,880
we guarantee this property along the way

267
00:11:04,880 --> 00:11:07,360
therefore the expected

268
00:11:07,360 --> 00:11:09,519
value of the inner product

269
00:11:09,519 --> 00:11:10,959
is going to be

270
00:11:10,959 --> 00:11:13,600
the same as the expected value

271
00:11:13,600 --> 00:11:16,000
of the inner product but we can allow to

272
00:11:16,000 --> 00:11:18,640
take one of the vector to this negation

273
00:11:18,640 --> 00:11:20,399
and it has to be

274
00:11:20,399 --> 00:11:23,200
equals to zero

275
00:11:24,000 --> 00:11:25,040
therefore

276
00:11:25,040 --> 00:11:27,600
the expected square norm has to be

277
00:11:27,600 --> 00:11:30,000
double the expected square number of the

278
00:11:30,000 --> 00:11:32,640
vectors that we start with

279
00:11:32,640 --> 00:11:33,360
so

280
00:11:33,360 --> 00:11:34,800
in one step

281
00:11:34,800 --> 00:11:36,880
the expected square norm

282
00:11:36,880 --> 00:11:38,880
is doubled

283
00:11:38,880 --> 00:11:41,440
in r steps the expected square norm is

284
00:11:41,440 --> 00:11:43,920
going to grow by a factor of exactly 2

285
00:11:43,920 --> 00:11:46,800
to the power of r

286
00:11:49,600 --> 00:11:50,480
next

287
00:11:50,480 --> 00:11:54,000
we recall that the vect the lattice

288
00:11:54,000 --> 00:11:58,000
is also getting faster and faster

289
00:11:58,000 --> 00:12:01,200
so we will have 2 to the n buckets

290
00:12:01,200 --> 00:12:03,200
and over here the number of buckets is

291
00:12:03,200 --> 00:12:04,560
actually the

292
00:12:04,560 --> 00:12:08,000
number of cosets we have

293
00:12:08,079 --> 00:12:10,880
and in our steps it's

294
00:12:10,880 --> 00:12:13,200
not hard to see that

295
00:12:13,200 --> 00:12:14,959
the

296
00:12:14,959 --> 00:12:17,760
lattice that we end up with lr

297
00:12:17,760 --> 00:12:19,839
is going to be 2 to the

298
00:12:19,839 --> 00:12:22,639
m over n times r

299
00:12:22,639 --> 00:12:26,560
times the initial lattice

300
00:12:27,279 --> 00:12:30,320
and we set this value to v2 to decay so

301
00:12:30,320 --> 00:12:32,639
in other words k is equal to m over n

302
00:12:32,639 --> 00:12:35,040
times r

303
00:12:35,120 --> 00:12:37,279
now recall we are going to

304
00:12:37,279 --> 00:12:39,920
scale down the vectors

305
00:12:39,920 --> 00:12:42,320
so after scaling down the expected

306
00:12:42,320 --> 00:12:45,519
square known we have 2 to the r minus 2k

307
00:12:45,519 --> 00:12:48,079
times t

308
00:12:49,040 --> 00:12:51,519
and in order to make progress

309
00:12:51,519 --> 00:12:53,600
we want this 2 to the

310
00:12:53,600 --> 00:12:56,000
power of r minus 2 k term

311
00:12:56,000 --> 00:12:58,240
to be a lot less than 1.

312
00:12:58,240 --> 00:13:00,160
in other words we want the exponent to

313
00:13:00,160 --> 00:13:02,160
be a lot less than 0.

314
00:13:02,160 --> 00:13:04,880
now if we substitute back the value that

315
00:13:04,880 --> 00:13:07,360
k is equal to m over n

316
00:13:07,360 --> 00:13:08,800
times r

317
00:13:08,800 --> 00:13:10,800
we want this term to be less than equals

318
00:13:10,800 --> 00:13:13,360
to be a lot less than zero

319
00:13:13,360 --> 00:13:15,279
and if we manipulate the term a little

320
00:13:15,279 --> 00:13:17,839
bit we can show that we

321
00:13:17,839 --> 00:13:23,040
need m to be above n over 2.

322
00:13:24,320 --> 00:13:27,279
so over here where we have a small

323
00:13:27,279 --> 00:13:30,560
remark on the running time

324
00:13:30,639 --> 00:13:32,880
the running time would be 2 to the m at

325
00:13:32,880 --> 00:13:36,160
least because we need this many vectors

326
00:13:36,160 --> 00:13:38,800
to start with to make sure that

327
00:13:38,800 --> 00:13:42,160
all the buckets had something in it

328
00:13:42,160 --> 00:13:44,639
and we are not losing too many vectors

329
00:13:44,639 --> 00:13:46,560
along the way

330
00:13:46,560 --> 00:13:49,040
so the number of buckets is a minimum

331
00:13:49,040 --> 00:13:50,880
requirement of the number of vectors

332
00:13:50,880 --> 00:13:51,920
that we

333
00:13:51,920 --> 00:13:53,519
have to have

334
00:13:53,519 --> 00:13:55,519
so the running time has to be 2 to the m

335
00:13:55,519 --> 00:13:56,639
ls

336
00:13:56,639 --> 00:13:59,360
and we just show that m has to be above

337
00:13:59,360 --> 00:14:00,639
n over 2

338
00:14:00,639 --> 00:14:02,160
and therefore the best running time that

339
00:14:02,160 --> 00:14:04,160
we managed to achieve at the end is 2 to

340
00:14:04,160 --> 00:14:05,440
the n over 2

341
00:14:05,440 --> 00:14:08,320
plus small of n

342
00:14:11,040 --> 00:14:12,480
so with this

343
00:14:12,480 --> 00:14:15,120
we show that the vectors are actually

344
00:14:15,120 --> 00:14:18,079
getting shorter and shorter

345
00:14:18,079 --> 00:14:20,720
i remain it remains to show that we are

346
00:14:20,720 --> 00:14:23,279
not seeing too many zero vectors in the

347
00:14:23,279 --> 00:14:25,519
end

348
00:14:26,399 --> 00:14:28,880
and to do this we will need the help of

349
00:14:28,880 --> 00:14:31,680
this nice distribution

350
00:14:31,680 --> 00:14:33,199
essentially the discrete gaussian

351
00:14:33,199 --> 00:14:34,880
distribution

352
00:14:34,880 --> 00:14:36,959
so what is this discrete gaussian

353
00:14:36,959 --> 00:14:38,720
distribution

354
00:14:38,720 --> 00:14:42,880
it's basically for any discrete set a

355
00:14:43,120 --> 00:14:45,680
any vector if we draw from the discrete

356
00:14:45,680 --> 00:14:47,440
gaussian distribution

357
00:14:47,440 --> 00:14:49,160
any vector would show up with the

358
00:14:49,160 --> 00:14:52,160
probability that is proportional to the

359
00:14:52,160 --> 00:14:54,959
gaussian mass

360
00:14:55,040 --> 00:14:57,360
and you can take it as a analog of the

361
00:14:57,360 --> 00:14:59,600
continuous gaussian distribution

362
00:14:59,600 --> 00:15:01,360
and it's also associated with a

363
00:15:01,360 --> 00:15:02,720
parameter s

364
00:15:02,720 --> 00:15:05,680
this parameter s can be seen as the

365
00:15:05,680 --> 00:15:07,279
standard deviation

366
00:15:07,279 --> 00:15:11,199
of the continuous gaussian distribution

367
00:15:11,519 --> 00:15:13,440
so in particular here is a nice

368
00:15:13,440 --> 00:15:15,120
illustration on the

369
00:15:15,120 --> 00:15:17,040
discrete gaussian distribution

370
00:15:17,040 --> 00:15:19,199
on z square

371
00:15:19,199 --> 00:15:22,639
so when s is large on the left

372
00:15:22,639 --> 00:15:25,199
it will it looks fairly smooth just like

373
00:15:25,199 --> 00:15:28,800
a continuous gaussian distribution

374
00:15:28,800 --> 00:15:31,120
and when s is small

375
00:15:31,120 --> 00:15:35,120
it looks more and more discretized

376
00:15:37,600 --> 00:15:39,519
so we have a few remarks on this

377
00:15:39,519 --> 00:15:41,920
discrete gaussian distribution

378
00:15:41,920 --> 00:15:44,240
for each of the lattice it has an

379
00:15:44,240 --> 00:15:46,079
associated parameter called the

380
00:15:46,079 --> 00:15:48,720
smoothing parameter

381
00:15:48,720 --> 00:15:50,320
and when the

382
00:15:50,320 --> 00:15:52,160
value of s is above the summoning

383
00:15:52,160 --> 00:15:53,360
parameter

384
00:15:53,360 --> 00:15:55,839
the discrete gaussian behaves nicely

385
00:15:55,839 --> 00:15:58,240
like a continuous gaussian distribution

386
00:15:58,240 --> 00:16:00,560
and this allows us to manipulate

387
00:16:00,560 --> 00:16:03,839
fairly fairly easily

388
00:16:03,839 --> 00:16:06,000
and more importantly why are we

389
00:16:06,000 --> 00:16:07,279
introducing this

390
00:16:07,279 --> 00:16:08,800
it will allow us to upper bound the

391
00:16:08,800 --> 00:16:12,240
probability of seeing the zero vector

392
00:16:12,240 --> 00:16:14,079
and with its help we are going to show

393
00:16:14,079 --> 00:16:14,959
that

394
00:16:14,959 --> 00:16:17,519
we won't see too many zero vectors

395
00:16:17,519 --> 00:16:21,240
at the end of our algorithm

396
00:16:22,399 --> 00:16:25,440
now in the in our algorithm

397
00:16:25,440 --> 00:16:27,680
the actual distribution that we are

398
00:16:27,680 --> 00:16:28,880
using

399
00:16:28,880 --> 00:16:31,440
is a variant of the discrete gaussian

400
00:16:31,440 --> 00:16:33,199
it's called the mixture of discrete

401
00:16:33,199 --> 00:16:34,399
gaussian

402
00:16:34,399 --> 00:16:36,800
so in particular we have some

403
00:16:36,800 --> 00:16:39,440
target subletters l prime

404
00:16:39,440 --> 00:16:41,600
this target sub lattice alpha is not

405
00:16:41,600 --> 00:16:43,040
necessarily known

406
00:16:43,040 --> 00:16:45,839
it's only it only shows up for analysis

407
00:16:45,839 --> 00:16:47,040
purpose

408
00:16:47,040 --> 00:16:49,279
so basically if we look at

409
00:16:49,279 --> 00:16:50,560
vectors

410
00:16:50,560 --> 00:16:54,160
that are in the same process of l prime

411
00:16:54,160 --> 00:16:56,399
these vectors are going to be

412
00:16:56,399 --> 00:16:58,560
distributed like a continuous like a

413
00:16:58,560 --> 00:17:00,240
discrete gaussian

414
00:17:00,240 --> 00:17:02,240
but of course across different code sets

415
00:17:02,240 --> 00:17:03,519
they may

416
00:17:03,519 --> 00:17:05,679
not have any relationship

417
00:17:05,679 --> 00:17:06,959
at all

418
00:17:06,959 --> 00:17:09,119
we only cared what we only care is that

419
00:17:09,119 --> 00:17:10,880
within the same coset

420
00:17:10,880 --> 00:17:13,119
the vectors behaves

421
00:17:13,119 --> 00:17:14,319
like

422
00:17:14,319 --> 00:17:17,959
a discrete gaussian

423
00:17:18,160 --> 00:17:19,359
with this

424
00:17:19,359 --> 00:17:21,280
we can show that when our algorithm

425
00:17:21,280 --> 00:17:22,640
stops

426
00:17:22,640 --> 00:17:25,439
we are going to see vectors of expected

427
00:17:25,439 --> 00:17:26,400
square

428
00:17:26,400 --> 00:17:30,880
of expected length square root n times s

429
00:17:30,880 --> 00:17:33,280
where the value of s is roughly the

430
00:17:33,280 --> 00:17:35,360
smoothing parameter

431
00:17:35,360 --> 00:17:39,360
of this target sub lattice l prime

432
00:17:39,360 --> 00:17:42,080
so it remains to show that

433
00:17:42,080 --> 00:17:44,240
there exists some target sub that is l

434
00:17:44,240 --> 00:17:45,200
prime

435
00:17:45,200 --> 00:17:49,120
that has a small smoothing parameter

436
00:17:49,120 --> 00:17:51,440
and here we are going to use the reverse

437
00:17:51,440 --> 00:17:53,120
minkowski theorem

438
00:17:53,120 --> 00:17:55,600
which is a fairly heavy hammer

439
00:17:55,600 --> 00:17:58,320
and as a direct corollary of this

440
00:17:58,320 --> 00:18:00,720
reverse minkowski theorem we can show

441
00:18:00,720 --> 00:18:03,840
that for any lattice l

442
00:18:03,840 --> 00:18:06,960
there exists a sub lattice l prime

443
00:18:06,960 --> 00:18:09,360
whose small whose smoothing parameter is

444
00:18:09,360 --> 00:18:12,240
upper bounded by poly a log n

445
00:18:12,240 --> 00:18:14,559
times mean of the lambda 1 the shortest

446
00:18:14,559 --> 00:18:17,520
vector of the lattice

447
00:18:17,520 --> 00:18:19,039
or the

448
00:18:19,039 --> 00:18:22,879
normalized determinant of the letters

449
00:18:22,960 --> 00:18:26,160
so one term would then correspond to the

450
00:18:26,160 --> 00:18:28,320
svp problem that we're trying to solve

451
00:18:28,320 --> 00:18:30,000
the other term will correspond to the

452
00:18:30,000 --> 00:18:33,600
hsvp problem that we are trying to solve

453
00:18:33,600 --> 00:18:36,240
now plugging in the values together

454
00:18:36,240 --> 00:18:38,720
would therefore manage to show that the

455
00:18:38,720 --> 00:18:40,960
output length of the vectors

456
00:18:40,960 --> 00:18:43,760
is going to be upper bounded by

457
00:18:43,760 --> 00:18:45,280
square root n

458
00:18:45,280 --> 00:18:47,440
times the mean of lambda 1

459
00:18:47,440 --> 00:18:48,320
and

460
00:18:48,320 --> 00:18:50,080
the the normalized determinant of the

461
00:18:50,080 --> 00:18:51,840
lattice

462
00:18:51,840 --> 00:18:52,559
so

463
00:18:52,559 --> 00:18:56,440
that concludes the algorithm

464
00:18:58,320 --> 00:19:00,799
okay so some of the open problems from

465
00:19:00,799 --> 00:19:02,559
our algorithm

466
00:19:02,559 --> 00:19:06,080
so can we find a better analysis

467
00:19:06,080 --> 00:19:08,799
to bring down the approximation factor

468
00:19:08,799 --> 00:19:11,440
of the algorithm

469
00:19:11,440 --> 00:19:14,000
or in other words can we actually have a

470
00:19:14,000 --> 00:19:15,919
better guarantee on the approximation

471
00:19:15,919 --> 00:19:18,240
factor on svp

472
00:19:18,240 --> 00:19:19,600
in particular

473
00:19:19,600 --> 00:19:22,400
before this work as far as we know

474
00:19:22,400 --> 00:19:23,600
all the

475
00:19:23,600 --> 00:19:25,840
algorithms that solves

476
00:19:25,840 --> 00:19:27,840
square root n hsvp

477
00:19:27,840 --> 00:19:30,400
they will also solve constant approx svp

478
00:19:30,400 --> 00:19:31,840
at the same time

479
00:19:31,840 --> 00:19:34,160
so and there is no reason why our

480
00:19:34,160 --> 00:19:36,720
algorithm is not doing so just that our

481
00:19:36,720 --> 00:19:39,520
analysis at the moment is unable to give

482
00:19:39,520 --> 00:19:42,000
us any better guarantee

483
00:19:42,000 --> 00:19:44,400
for svp

484
00:19:44,400 --> 00:19:47,280
is unable to improve

485
00:19:47,280 --> 00:19:50,559
the approximation factor

486
00:19:51,280 --> 00:19:53,039
and therefore we are wondering if we can

487
00:19:53,039 --> 00:19:56,080
find a different way to analyze the

488
00:19:56,080 --> 00:19:57,360
algorithm

489
00:19:57,360 --> 00:19:59,280
and if we can show that it actually

490
00:19:59,280 --> 00:20:01,360
gives us a better approximation factor

491
00:20:01,360 --> 00:20:04,080
for svp

492
00:20:05,600 --> 00:20:06,720
secondly

493
00:20:06,720 --> 00:20:07,520
um

494
00:20:07,520 --> 00:20:09,840
i've mentioned just now that

495
00:20:09,840 --> 00:20:11,840
there is this our running time is 2 to

496
00:20:11,840 --> 00:20:14,320
the n over 2 plus small of n

497
00:20:14,320 --> 00:20:16,720
and this is exactly because we need at

498
00:20:16,720 --> 00:20:19,200
least 2 to the n over 2

499
00:20:19,200 --> 00:20:20,880
number of code sets

500
00:20:20,880 --> 00:20:23,679
for the algorithm to make progress

501
00:20:23,679 --> 00:20:25,600
so it seems that 2 to the n over 2

502
00:20:25,600 --> 00:20:27,039
running time is a

503
00:20:27,039 --> 00:20:28,320
barrier here

504
00:20:28,320 --> 00:20:31,840
so is there a way to break this barrier

505
00:20:31,840 --> 00:20:34,320
and ultimately matching the running time

506
00:20:34,320 --> 00:20:37,918
of heuristic algorithms

507
00:20:39,520 --> 00:20:41,360
and that's all i have thank you for your

508
00:20:41,360 --> 00:20:44,360
attention

