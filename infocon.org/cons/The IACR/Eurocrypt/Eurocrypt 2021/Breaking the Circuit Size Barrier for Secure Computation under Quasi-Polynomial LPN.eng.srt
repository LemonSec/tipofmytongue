1
00:00:00,560 --> 00:00:02,000
hello everyone

2
00:00:02,000 --> 00:00:03,520
thank you for listening to this talk

3
00:00:03,520 --> 00:00:05,440
about breaking the circuit-sized barrier

4
00:00:05,440 --> 00:00:08,000
on the quasi-polynomial apn

5
00:00:08,000 --> 00:00:10,639
as this is joint work with jeffrey kutto

6
00:00:10,639 --> 00:00:12,400
and the way i like to present our

7
00:00:12,400 --> 00:00:13,599
results

8
00:00:13,599 --> 00:00:15,759
is to say that we show how to achieve

9
00:00:15,759 --> 00:00:18,720
sublinear computation from lpn by using

10
00:00:18,720 --> 00:00:20,560
a tool known as homomorphic secret

11
00:00:20,560 --> 00:00:22,000
sharing

12
00:00:22,000 --> 00:00:24,160
now i'll get into what hss is in a

13
00:00:24,160 --> 00:00:26,240
moment but for now let's just have a

14
00:00:26,240 --> 00:00:28,240
look at our main result

15
00:00:28,240 --> 00:00:29,679
our main result

16
00:00:29,679 --> 00:00:32,880
is that under a reasonable flavor of lpn

17
00:00:32,880 --> 00:00:34,399
there is a two-party protocol for

18
00:00:34,399 --> 00:00:36,880
securely computing any circuit

19
00:00:36,880 --> 00:00:39,040
which uses an amount of communication

20
00:00:39,040 --> 00:00:40,879
which is only sub-linear in the circuit

21
00:00:40,879 --> 00:00:42,800
size

22
00:00:42,800 --> 00:00:45,680
now more precisely and ignoring the

23
00:00:45,680 --> 00:00:47,840
assumption for now

24
00:00:47,840 --> 00:00:50,480
if all you require is very slightly

25
00:00:50,480 --> 00:00:53,039
sublinear communication for instance s

26
00:00:53,039 --> 00:00:55,039
over log star of s

27
00:00:55,039 --> 00:00:56,480
then comp since the amount of

28
00:00:56,480 --> 00:00:58,480
computation required is

29
00:00:58,480 --> 00:01:00,879
nearly linear

30
00:01:00,879 --> 00:01:04,400
but you may wonder how far can we push

31
00:01:04,400 --> 00:01:05,438
the

32
00:01:05,438 --> 00:01:07,760
factor of sublinearity using our

33
00:01:07,760 --> 00:01:09,760
techniques

34
00:01:09,760 --> 00:01:11,920
it so happens communication can be as

35
00:01:11,920 --> 00:01:14,799
low as s over log log s in which case

36
00:01:14,799 --> 00:01:17,360
computation becomes cubic

37
00:01:17,360 --> 00:01:20,880
for the rest of this talk i'll be

38
00:01:20,880 --> 00:01:24,159
explaining how our protocol works

39
00:01:24,159 --> 00:01:25,840
but in order to do that i'll have to

40
00:01:25,840 --> 00:01:29,759
start by introducing a few objects

41
00:01:29,759 --> 00:01:33,680
but once that's done we can go over

42
00:01:33,680 --> 00:01:37,439
step by step how our protocol works

43
00:01:37,439 --> 00:01:39,840
i should start by mentioning that our

44
00:01:39,840 --> 00:01:42,560
protocol is of course not the first one

45
00:01:42,560 --> 00:01:44,720
to achieve sublinear two-party

46
00:01:44,720 --> 00:01:46,159
computation

47
00:01:46,159 --> 00:01:48,320
this was known both in the correlated

48
00:01:48,320 --> 00:01:51,119
randomness model and from a variety of

49
00:01:51,119 --> 00:01:54,479
computational assumptions

50
00:01:54,479 --> 00:01:55,520
so our

51
00:01:55,520 --> 00:01:59,360
contribution as it were is to add lpn to

52
00:01:59,360 --> 00:02:01,920
this list

53
00:02:02,640 --> 00:02:04,799
as a matter of fact our techniques are

54
00:02:04,799 --> 00:02:08,000
very much derived from two lines of work

55
00:02:08,000 --> 00:02:10,318
so the first is

56
00:02:10,318 --> 00:02:13,200
the hss line of work and the second is

57
00:02:13,200 --> 00:02:14,879
kuto 19

58
00:02:14,879 --> 00:02:17,280
in the correlated randomness model but

59
00:02:17,280 --> 00:02:18,800
what is

60
00:02:18,800 --> 00:02:21,120
the lpn assumption

61
00:02:21,120 --> 00:02:22,800
i'm sure most of you are familiar with

62
00:02:22,800 --> 00:02:25,280
this formulation of the learning parity

63
00:02:25,280 --> 00:02:27,280
with noise assumption

64
00:02:27,280 --> 00:02:29,520
so it's parameterized by

65
00:02:29,520 --> 00:02:31,120
three values

66
00:02:31,120 --> 00:02:34,640
so the dimensions of matrix a

67
00:02:34,640 --> 00:02:36,959
as well as the density of the noise

68
00:02:36,959 --> 00:02:38,400
vector

69
00:02:38,400 --> 00:02:41,120
or noise or error

70
00:02:41,120 --> 00:02:42,720
but for our purposes it's more

71
00:02:42,720 --> 00:02:45,440
convenient to consider the dual form of

72
00:02:45,440 --> 00:02:49,120
lpn which is essentially equivalent

73
00:02:49,120 --> 00:02:51,200
so here goes

74
00:02:51,200 --> 00:02:52,879
i can always give you instead of the

75
00:02:52,879 --> 00:02:55,599
matrix it's parity check matrix that's

76
00:02:55,599 --> 00:02:58,560
roughly equivalent

77
00:02:58,560 --> 00:03:00,159
and

78
00:03:00,159 --> 00:03:01,519
let's look at what happens to the second

79
00:03:01,519 --> 00:03:02,480
term

80
00:03:02,480 --> 00:03:04,800
if we multiply it by the parity-check

81
00:03:04,800 --> 00:03:07,840
matrix since h and a cancel out all

82
00:03:07,840 --> 00:03:11,360
you're left with is h times e

83
00:03:12,480 --> 00:03:16,000
so this is the dual lpn assumption

84
00:03:16,000 --> 00:03:17,200
essentially

85
00:03:17,200 --> 00:03:19,360
if you wish to generate a pseudorandom

86
00:03:19,360 --> 00:03:20,480
vector

87
00:03:20,480 --> 00:03:22,480
all you need to do is to multiply a

88
00:03:22,480 --> 00:03:25,200
public contracting matrix

89
00:03:25,200 --> 00:03:27,920
by some sparse noise vector

90
00:03:27,920 --> 00:03:30,080
and the parameters are still there

91
00:03:30,080 --> 00:03:32,720
as the dimension of parity-check matrix

92
00:03:32,720 --> 00:03:37,200
h as well as the density of the noise

93
00:03:37,200 --> 00:03:39,360
and let's look at the values of the

94
00:03:39,360 --> 00:03:40,720
parameters

95
00:03:40,720 --> 00:03:41,680
that

96
00:03:41,680 --> 00:03:45,120
for our specific flavor of assumption

97
00:03:45,120 --> 00:03:47,519
which is the quasi-polynomial lpn

98
00:03:47,519 --> 00:03:49,840
assumption or superpolynomial if you

99
00:03:49,840 --> 00:03:52,000
will

100
00:03:56,000 --> 00:03:58,400
roughly it just it's just that

101
00:03:58,400 --> 00:04:01,200
we assume that the adversary

102
00:04:01,200 --> 00:04:04,560
is allowed to run in a slightly

103
00:04:04,560 --> 00:04:07,760
superpolynomial time

104
00:04:07,760 --> 00:04:10,159
so the best-known attack is exponential

105
00:04:10,159 --> 00:04:12,640
so r leaves you to judge

106
00:04:12,640 --> 00:04:13,680
whether

107
00:04:13,680 --> 00:04:16,160
the gap between the best known attack

108
00:04:16,160 --> 00:04:19,358
and the level of security will require

109
00:04:19,358 --> 00:04:21,600
is large enough to justify this

110
00:04:21,600 --> 00:04:23,280
assumption

111
00:04:23,280 --> 00:04:27,120
the reason why we use the lpn assumption

112
00:04:27,120 --> 00:04:29,440
is that it enables us to instantiate two

113
00:04:29,440 --> 00:04:31,759
key primitives around which our protocol

114
00:04:31,759 --> 00:04:34,080
is built

115
00:04:34,080 --> 00:04:36,320
the first is a pseudorandom correlation

116
00:04:36,320 --> 00:04:39,840
generator or pcg

117
00:04:39,919 --> 00:04:41,440
so the way it works is that there is a

118
00:04:41,440 --> 00:04:43,280
target correlation

119
00:04:43,280 --> 00:04:45,520
and we wish to be able to generate

120
00:04:45,520 --> 00:04:48,160
a pair of very compact seeds that's

121
00:04:48,160 --> 00:04:49,840
that's very important that the seeds be

122
00:04:49,840 --> 00:04:52,080
compact

123
00:04:52,080 --> 00:04:53,440
that can be

124
00:04:53,440 --> 00:04:55,280
each expanded

125
00:04:55,280 --> 00:04:56,720
in such a way

126
00:04:56,720 --> 00:04:59,440
that if you take the distribution of

127
00:04:59,440 --> 00:05:01,440
expanded seeds

128
00:05:01,440 --> 00:05:03,280
that should be computationally

129
00:05:03,280 --> 00:05:05,199
indistinguishable from the target

130
00:05:05,199 --> 00:05:06,720
correlation

131
00:05:06,720 --> 00:05:09,440
here we'll only be interested in a pcg

132
00:05:09,440 --> 00:05:13,039
for a very specific correlation

133
00:05:13,280 --> 00:05:14,960
what we want is to be able to generate

134
00:05:14,960 --> 00:05:18,320
seeds which expand to additive shares of

135
00:05:18,320 --> 00:05:20,880
the first d tensor powers

136
00:05:20,880 --> 00:05:24,560
of a pseudorandom vector r

137
00:05:24,560 --> 00:05:27,360
the reason why this is interesting

138
00:05:27,360 --> 00:05:28,320
is that

139
00:05:28,320 --> 00:05:29,680
any

140
00:05:29,680 --> 00:05:31,919
degree d polynomial

141
00:05:31,919 --> 00:05:34,240
in the elements of r

142
00:05:34,240 --> 00:05:37,840
can be obtained via linear combination

143
00:05:37,840 --> 00:05:42,240
of the elements of these d tensor powers

144
00:05:42,240 --> 00:05:44,080
this specific pcg

145
00:05:44,080 --> 00:05:46,800
allows us to build our second primitive

146
00:05:46,800 --> 00:05:49,919
function secret sharing

147
00:05:50,400 --> 00:05:52,720
so given a function we want to be able

148
00:05:52,720 --> 00:05:56,880
to derive a pair of evaluation keys

149
00:05:56,880 --> 00:05:59,759
which can be used to generate

150
00:05:59,759 --> 00:06:01,360
additive shares

151
00:06:01,360 --> 00:06:06,160
of the evaluation of any point

152
00:06:06,160 --> 00:06:08,240
an important requirement

153
00:06:08,240 --> 00:06:11,600
is that the function be kept secret

154
00:06:11,600 --> 00:06:13,199
so more specifically

155
00:06:13,199 --> 00:06:14,720
if you're only given one of the

156
00:06:14,720 --> 00:06:18,560
evaluation keys k0 or k1

157
00:06:18,560 --> 00:06:21,680
you shouldn't learn what the function is

158
00:06:21,680 --> 00:06:24,240
so function secretary is defined with

159
00:06:24,240 --> 00:06:26,960
respect to a function class

160
00:06:26,960 --> 00:06:28,720
and in this case

161
00:06:28,720 --> 00:06:30,000
um

162
00:06:30,000 --> 00:06:31,440
we're interested in function secret

163
00:06:31,440 --> 00:06:34,080
sharing for the class of all depth d

164
00:06:34,080 --> 00:06:35,600
circuits

165
00:06:35,600 --> 00:06:37,919
i should briefly mention that function

166
00:06:37,919 --> 00:06:39,360
secret sharing

167
00:06:39,360 --> 00:06:43,840
is the dual of homomorphic secretary

168
00:06:43,840 --> 00:06:45,759
where instead of having a secret

169
00:06:45,759 --> 00:06:49,520
function now we have a secret input

170
00:06:49,520 --> 00:06:50,639
but

171
00:06:50,639 --> 00:06:52,479
for the purposes of this talk

172
00:06:52,479 --> 00:06:55,680
we needn't be concerned with hss simply

173
00:06:55,680 --> 00:06:59,039
mentioning that there exist a dual form

174
00:06:59,039 --> 00:07:00,400
finally

175
00:07:00,400 --> 00:07:02,560
and just after this i can present a

176
00:07:02,560 --> 00:07:03,599
protocol

177
00:07:03,599 --> 00:07:05,919
we need to talk about circuits

178
00:07:05,919 --> 00:07:07,440
because our protocol doesn't work for

179
00:07:07,440 --> 00:07:10,000
the class of all circuits but rather for

180
00:07:10,000 --> 00:07:13,599
the class of all layered circuits

181
00:07:13,599 --> 00:07:15,280
and the circuit is led

182
00:07:15,280 --> 00:07:16,639
if you can

183
00:07:16,639 --> 00:07:19,199
partition the gates into

184
00:07:19,199 --> 00:07:20,720
well layers

185
00:07:20,720 --> 00:07:23,039
such that wires don't cross

186
00:07:23,039 --> 00:07:25,599
each wire only goes from one layer to

187
00:07:25,599 --> 00:07:28,080
the next

188
00:07:28,560 --> 00:07:30,400
there is a generic transformation from

189
00:07:30,400 --> 00:07:32,800
circuit to learn circuits

190
00:07:32,800 --> 00:07:33,599
but

191
00:07:33,599 --> 00:07:38,319
it incurs a quadratic blow up in size

192
00:07:38,319 --> 00:07:40,960
so that's why uh sublinear protocols

193
00:07:40,960 --> 00:07:43,360
don't carry over from lead circuits to

194
00:07:43,360 --> 00:07:46,160
general circuits

195
00:07:47,919 --> 00:07:50,639
and in this presentation

196
00:07:50,639 --> 00:07:55,360
alby will will consider the simplified

197
00:07:56,240 --> 00:07:58,479
and in this presentation we'll only be

198
00:07:58,479 --> 00:08:00,879
considering the simplified case of

199
00:08:00,879 --> 00:08:03,919
rectangular lead circuits so every layer

200
00:08:03,919 --> 00:08:05,599
has the same size which recalls the

201
00:08:05,599 --> 00:08:07,599
width of the circuit

202
00:08:07,599 --> 00:08:09,759
so the width times the depth is equal to

203
00:08:09,759 --> 00:08:12,560
the size of the circuit i'd just like to

204
00:08:12,560 --> 00:08:14,240
emphasize that this

205
00:08:14,240 --> 00:08:17,840
simplification is only done so that

206
00:08:17,840 --> 00:08:19,520
because the protocol becomes simpler to

207
00:08:19,520 --> 00:08:20,639
explain

208
00:08:20,639 --> 00:08:21,440
but

209
00:08:21,440 --> 00:08:22,960
the protocol does work for

210
00:08:22,960 --> 00:08:26,160
non-rectangular layered circuits

211
00:08:26,160 --> 00:08:28,160
we now have everything we need in order

212
00:08:28,160 --> 00:08:31,360
to understand the protocol

213
00:08:33,599 --> 00:08:34,399
so

214
00:08:34,399 --> 00:08:38,159
consider for now a circuit c1 of width w

215
00:08:38,159 --> 00:08:40,958
and of depth k

216
00:08:40,958 --> 00:08:43,039
let's now also assume that there exists

217
00:08:43,039 --> 00:08:45,440
a protocol which allows two parties to

218
00:08:45,440 --> 00:08:47,920
convert additive shares of x

219
00:08:47,920 --> 00:08:52,079
into additive shares of c1 of x

220
00:08:52,160 --> 00:08:54,240
and that's this protocol only uses

221
00:08:54,240 --> 00:08:56,560
communication roughly proportional to

222
00:08:56,560 --> 00:08:58,880
width

223
00:08:58,880 --> 00:09:01,279
if such a protocol exists

224
00:09:01,279 --> 00:09:04,959
and we consider now another circuit c2

225
00:09:04,959 --> 00:09:06,959
since the parties can reuse the protocol

226
00:09:06,959 --> 00:09:08,720
in order to convert such additive shares

227
00:09:08,720 --> 00:09:10,160
of c1 of x

228
00:09:10,160 --> 00:09:13,760
into additive shares of c2 of c1 of x

229
00:09:13,760 --> 00:09:16,000
and they can do so over and over for any

230
00:09:16,000 --> 00:09:18,560
sub-circuit

231
00:09:18,560 --> 00:09:20,320
so this is how we use the assumption

232
00:09:20,320 --> 00:09:22,560
that the circuit is led

233
00:09:22,560 --> 00:09:23,440
first

234
00:09:23,440 --> 00:09:26,560
you divide the let's get into chunks of

235
00:09:26,560 --> 00:09:28,480
k consecutive layers

236
00:09:28,480 --> 00:09:30,320
and you apply such a low complexity

237
00:09:30,320 --> 00:09:32,959
protocol to each layer

238
00:09:32,959 --> 00:09:35,440
if you do so you'll apply you'll obtain

239
00:09:35,440 --> 00:09:37,519
a

240
00:09:37,519 --> 00:09:39,440
secure computation protocol

241
00:09:39,440 --> 00:09:42,160
whose total communication is s the

242
00:09:42,160 --> 00:09:45,680
circuit size divided by k

243
00:09:45,680 --> 00:09:49,120
so if k can be super constant

244
00:09:49,120 --> 00:09:53,200
we've won and we have the protocol wind

245
00:09:54,160 --> 00:09:55,839
fortunately for us

246
00:09:55,839 --> 00:09:58,080
such a low communication protocol for

247
00:09:58,080 --> 00:09:59,839
shallow circuits

248
00:09:59,839 --> 00:10:02,720
exists from lpn

249
00:10:02,720 --> 00:10:05,040
the amount of communication is all right

250
00:10:05,040 --> 00:10:07,200
unfortunately the computation is too

251
00:10:07,200 --> 00:10:08,160
large

252
00:10:08,160 --> 00:10:10,800
as soon as k is super constant the

253
00:10:10,800 --> 00:10:14,640
computation will be superpolynomial

254
00:10:15,120 --> 00:10:18,160
in order to understand why that is we'll

255
00:10:18,160 --> 00:10:20,240
have to open up

256
00:10:20,240 --> 00:10:21,200
this

257
00:10:21,200 --> 00:10:23,120
secure computation protocol for shallow

258
00:10:23,120 --> 00:10:24,399
circuits

259
00:10:24,399 --> 00:10:26,560
which actually uses function secret

260
00:10:26,560 --> 00:10:28,240
sharing

261
00:10:28,240 --> 00:10:30,480
so for the next few minutes the talk is

262
00:10:30,480 --> 00:10:31,440
going to be

263
00:10:31,440 --> 00:10:32,720
to be

264
00:10:32,720 --> 00:10:35,360
very technical

265
00:10:35,360 --> 00:10:37,839
fortunately there's only one key idea

266
00:10:37,839 --> 00:10:40,399
which needs to be extracted from this

267
00:10:40,399 --> 00:10:41,360
so

268
00:10:41,360 --> 00:10:43,920
i'll first go into the details and then

269
00:10:43,920 --> 00:10:47,760
we can just extract the main idea

270
00:10:47,760 --> 00:10:48,480
so

271
00:10:48,480 --> 00:10:49,519
consider

272
00:10:49,519 --> 00:10:54,320
a shallow circuit c1 of depth k

273
00:10:54,320 --> 00:10:56,079
recall that the goal of the parties is

274
00:10:56,079 --> 00:10:58,160
to convert additive shares of the input

275
00:10:58,160 --> 00:11:00,560
x into additive shares of the output of

276
00:11:00,560 --> 00:11:03,119
the circuit

277
00:11:03,360 --> 00:11:05,920
so at a high level the protocol has

278
00:11:05,920 --> 00:11:08,079
three steps

279
00:11:08,079 --> 00:11:11,290
the first is to generate

280
00:11:11,290 --> 00:11:13,200
[Music]

281
00:11:13,200 --> 00:11:16,240
the first 2 to the k tensor powers

282
00:11:16,240 --> 00:11:17,839
of some

283
00:11:17,839 --> 00:11:21,360
random vector will call the mask

284
00:11:21,360 --> 00:11:23,040
we call it the mask precisely because

285
00:11:23,040 --> 00:11:24,959
we're going to use it in order to mask

286
00:11:24,959 --> 00:11:26,480
the input

287
00:11:26,480 --> 00:11:29,440
as the second step is for the parties to

288
00:11:29,440 --> 00:11:30,959
exchange

289
00:11:30,959 --> 00:11:33,360
shares of x plus r1 in order to

290
00:11:33,360 --> 00:11:35,360
reconstruct this marked value of the

291
00:11:35,360 --> 00:11:37,680
input

292
00:11:38,480 --> 00:11:40,880
the first the third step

293
00:11:40,880 --> 00:11:43,920
is to use what was generated in the

294
00:11:43,920 --> 00:11:46,320
first two in order to

295
00:11:46,320 --> 00:11:50,320
locally so without communication

296
00:11:50,320 --> 00:11:52,959
uh generate shares of the output

297
00:11:52,959 --> 00:11:57,600
so let's see now how how this works

298
00:11:57,600 --> 00:11:59,519
the first step can be done

299
00:11:59,519 --> 00:12:02,160
by considering a pcg for the

300
00:12:02,160 --> 00:12:04,079
for the correlation we defined much

301
00:12:04,079 --> 00:12:05,600
earlier

302
00:12:05,600 --> 00:12:08,160
and run a generic

303
00:12:08,160 --> 00:12:10,399
two-party computation protocol in order

304
00:12:10,399 --> 00:12:13,760
to distribute the seed generation

305
00:12:13,760 --> 00:12:16,480
since the seed generation is compact and

306
00:12:16,480 --> 00:12:18,160
the seeds is very short

307
00:12:18,160 --> 00:12:20,000
even is this protocol needn't be

308
00:12:20,000 --> 00:12:23,360
sublinear just any

309
00:12:23,360 --> 00:12:26,240
um efficient enough two-part computation

310
00:12:26,240 --> 00:12:28,639
will do

311
00:12:28,880 --> 00:12:31,040
then the parties can just locally run

312
00:12:31,040 --> 00:12:34,800
the seed expansion protocol in order to

313
00:12:34,800 --> 00:12:36,560
get

314
00:12:36,560 --> 00:12:39,839
the shares they need

315
00:12:40,480 --> 00:12:43,760
the next step is simply for each party

316
00:12:43,760 --> 00:12:45,120
to

317
00:12:45,120 --> 00:12:47,519
take the sum of their share of x and

318
00:12:47,519 --> 00:12:50,320
their share of of r one sorry the mark

319
00:12:50,320 --> 00:12:52,480
and the share the input and the share of

320
00:12:52,480 --> 00:12:53,519
the mask

321
00:12:53,519 --> 00:12:55,040
in order to define

322
00:12:55,040 --> 00:12:58,079
the new share of the mast input

323
00:12:58,079 --> 00:13:00,399
the parties can safely exchange these

324
00:13:00,399 --> 00:13:03,360
shares in order to reconstruct the mast

325
00:13:03,360 --> 00:13:06,360
input

326
00:13:07,279 --> 00:13:09,519
and

327
00:13:10,160 --> 00:13:12,639
the third step

328
00:13:12,639 --> 00:13:15,120
is i'll

329
00:13:15,200 --> 00:13:17,839
explain now

330
00:13:17,920 --> 00:13:20,000
so the way it works is that if you

331
00:13:20,000 --> 00:13:22,079
consider the circuit

332
00:13:22,079 --> 00:13:24,319
which

333
00:13:24,399 --> 00:13:28,639
first removes the mask r1

334
00:13:28,639 --> 00:13:30,959
then applies the circuit c1

335
00:13:30,959 --> 00:13:32,959
so consider this circuit which has the

336
00:13:32,959 --> 00:13:36,079
mast hard-coded

337
00:13:36,640 --> 00:13:38,320
[Music]

338
00:13:38,320 --> 00:13:42,880
it can be expressed as a polynomial

339
00:13:43,120 --> 00:13:46,000
whose coefficients are themselves degree

340
00:13:46,000 --> 00:13:48,639
2 to the k polynomials

341
00:13:48,639 --> 00:13:52,560
in the elements of the mask

342
00:13:54,320 --> 00:13:55,839
so since

343
00:13:55,839 --> 00:13:57,279
um

344
00:13:57,279 --> 00:13:59,920
shares of the first two decay tensor

345
00:13:59,920 --> 00:14:03,360
powers of r1 are enough to get additive

346
00:14:03,360 --> 00:14:04,560
shares

347
00:14:04,560 --> 00:14:07,120
of each of those polynomials

348
00:14:07,120 --> 00:14:09,680
the parties have all they need in order

349
00:14:09,680 --> 00:14:11,600
to locally compute

350
00:14:11,600 --> 00:14:16,040
additive shares of c1 of x

351
00:14:16,079 --> 00:14:17,920
now let's just have a look at the

352
00:14:17,920 --> 00:14:20,000
communication complexity

353
00:14:20,000 --> 00:14:22,720
so step one only uses a small amount of

354
00:14:22,720 --> 00:14:25,279
communication because uh

355
00:14:25,279 --> 00:14:27,279
the only thing which requires

356
00:14:27,279 --> 00:14:30,160
interaction is the distribution of the

357
00:14:30,160 --> 00:14:32,560
key of the seed generation but that's

358
00:14:32,560 --> 00:14:34,720
tiny

359
00:14:34,720 --> 00:14:38,160
the second step requires

360
00:14:38,160 --> 00:14:40,000
communication proportional to the size

361
00:14:40,000 --> 00:14:41,199
of the input

362
00:14:41,199 --> 00:14:45,120
ie the width of the circuit and uh this

363
00:14:45,120 --> 00:14:47,040
is going to be an important part of the

364
00:14:47,040 --> 00:14:48,800
rest of this talk

365
00:14:48,800 --> 00:14:50,800
so i'll i'll remind you of that when it

366
00:14:50,800 --> 00:14:53,199
when it

367
00:14:53,680 --> 00:14:56,240
when it's relevant

368
00:14:56,240 --> 00:14:58,079
and what's remarkable is that the third

369
00:14:58,079 --> 00:15:01,360
step is completely silent it requires no

370
00:15:01,360 --> 00:15:03,920
interaction

371
00:15:04,240 --> 00:15:07,360
if you'd like you could pause the video

372
00:15:07,360 --> 00:15:09,120
and observe

373
00:15:09,120 --> 00:15:10,000
that

374
00:15:10,000 --> 00:15:11,279
what we've done

375
00:15:11,279 --> 00:15:12,399
or rather

376
00:15:12,399 --> 00:15:14,639
in what we've done there is actually

377
00:15:14,639 --> 00:15:16,320
hidden a

378
00:15:16,320 --> 00:15:18,240
an instance of a function secret sharing

379
00:15:18,240 --> 00:15:20,320
scheme for the function which first

380
00:15:20,320 --> 00:15:22,000
removes the masks then applies the

381
00:15:22,000 --> 00:15:23,680
circuit c1

382
00:15:23,680 --> 00:15:24,880
but

383
00:15:24,880 --> 00:15:28,000
this observation isn't actually um

384
00:15:28,000 --> 00:15:29,360
central

385
00:15:29,360 --> 00:15:31,600
uh

386
00:15:31,759 --> 00:15:34,880
to our protocol design

387
00:15:34,959 --> 00:15:37,279
now that we've seen how the protocol for

388
00:15:37,279 --> 00:15:39,920
computing a shallow chunk of layers

389
00:15:39,920 --> 00:15:41,040
works

390
00:15:41,040 --> 00:15:42,560
let's try and understand why its

391
00:15:42,560 --> 00:15:45,040
computational complexity is of the form

392
00:15:45,040 --> 00:15:48,319
w to the two decay

393
00:15:49,440 --> 00:15:55,120
it all has to do with how the pcg works

394
00:15:55,120 --> 00:15:57,759
so as you may have guessed

395
00:15:57,759 --> 00:15:59,920
the pseudorandom mask

396
00:15:59,920 --> 00:16:02,560
is in fact generated using an instance

397
00:16:02,560 --> 00:16:04,480
of dual lpn

398
00:16:04,480 --> 00:16:06,839
in other words

399
00:16:06,839 --> 00:16:10,480
um we have some public contracting

400
00:16:10,480 --> 00:16:14,240
matrix which is not as

401
00:16:14,240 --> 00:16:16,399
square as it looks here

402
00:16:16,399 --> 00:16:18,480
which is multiplied by some secret noise

403
00:16:18,480 --> 00:16:20,880
vector

404
00:16:21,360 --> 00:16:23,920
and the fact of linear algebra

405
00:16:23,920 --> 00:16:25,920
is that if you take the tensor power of

406
00:16:25,920 --> 00:16:27,120
a product

407
00:16:27,120 --> 00:16:29,440
this is equal to the product of the

408
00:16:29,440 --> 00:16:32,160
tensor powers

409
00:16:32,720 --> 00:16:35,680
therefore if you wish to compute

410
00:16:35,680 --> 00:16:37,920
additive shares

411
00:16:37,920 --> 00:16:41,120
of the tensor power of r we can do so by

412
00:16:41,120 --> 00:16:44,320
by multiplying some public matrix

413
00:16:44,320 --> 00:16:48,079
by an additive share of a tensor power

414
00:16:48,079 --> 00:16:51,839
of e the noise vector

415
00:16:52,160 --> 00:16:54,560
so what i obfuscated before is that our

416
00:16:54,560 --> 00:16:55,680
pcg

417
00:16:55,680 --> 00:16:57,199
is in fact

418
00:16:57,199 --> 00:17:00,480
a wrapper around another pcg the one

419
00:17:00,480 --> 00:17:02,000
which generates

420
00:17:02,000 --> 00:17:03,839
additive shares

421
00:17:03,839 --> 00:17:08,000
of the tensor powers of the noise vector

422
00:17:08,000 --> 00:17:09,618
so we don't need to to

423
00:17:09,618 --> 00:17:11,679
[Music]

424
00:17:11,679 --> 00:17:15,520
to have a look at how that

425
00:17:16,079 --> 00:17:19,119
that pcg works all we need to know is

426
00:17:19,119 --> 00:17:21,359
that there is some clever way to exploit

427
00:17:21,359 --> 00:17:23,760
the fact that the noise vector e is very

428
00:17:23,760 --> 00:17:25,760
sparse

429
00:17:25,760 --> 00:17:28,960
in order to obtain a very compact seed

430
00:17:28,960 --> 00:17:31,960
generation

431
00:17:33,120 --> 00:17:35,039
but now it should be clear why the

432
00:17:35,039 --> 00:17:37,200
computational complexity

433
00:17:37,200 --> 00:17:39,919
is of the form w to the two decay

434
00:17:39,919 --> 00:17:42,400
it's simply the size

435
00:17:42,400 --> 00:17:45,520
of the matrix the public matrix h

436
00:17:45,520 --> 00:17:49,360
10 said 2 z k times

437
00:17:51,280 --> 00:17:53,919
what we just saw is that the

438
00:17:53,919 --> 00:17:55,520
computational complexity of this

439
00:17:55,520 --> 00:17:57,760
primitive is prohibitively high to

440
00:17:57,760 --> 00:18:00,640
directly apply it to a chunk of

441
00:18:00,640 --> 00:18:02,960
layers

442
00:18:02,960 --> 00:18:05,440
now this can't be the end of it or well

443
00:18:05,440 --> 00:18:09,120
i wouldn't be giving this presentation

444
00:18:09,840 --> 00:18:11,679
as a matter of fact

445
00:18:11,679 --> 00:18:14,640
we can use an observation made by kuto

446
00:18:14,640 --> 00:18:16,960
who fade who faced a similar problem in

447
00:18:16,960 --> 00:18:19,760
the correlated randomness model

448
00:18:19,760 --> 00:18:22,000
and this observation was that we're

449
00:18:22,000 --> 00:18:24,400
dealing with arithmetic circuits

450
00:18:24,400 --> 00:18:27,840
where each gate has fan in at most true

451
00:18:27,840 --> 00:18:29,679
combined with the shallow depth of the

452
00:18:29,679 --> 00:18:32,559
circuit means that it's highly local

453
00:18:32,559 --> 00:18:34,799
each output only depends on at most two

454
00:18:34,799 --> 00:18:36,799
to the k inputs

455
00:18:36,799 --> 00:18:38,960
more generally if you take w prime

456
00:18:38,960 --> 00:18:41,870
outputs they can say only

457
00:18:41,870 --> 00:18:43,200
[Music]

458
00:18:43,200 --> 00:18:46,160
depend on that most 20k times w prime

459
00:18:46,160 --> 00:18:48,480
inputs

460
00:18:48,480 --> 00:18:49,679
so we can

461
00:18:49,679 --> 00:18:51,840
decompose the computation into small

462
00:18:51,840 --> 00:18:53,760
blocks

463
00:18:53,760 --> 00:18:54,840
this

464
00:18:54,840 --> 00:18:57,440
way and each of those blocks is now

465
00:18:57,440 --> 00:18:58,960
small enough

466
00:18:58,960 --> 00:19:01,360
that applying the previous protocol can

467
00:19:01,360 --> 00:19:03,520
be done in polynomial time

468
00:19:03,520 --> 00:19:06,960
indeed if k and w prime are small enough

469
00:19:06,960 --> 00:19:09,679
the computation is 2 to the k times w

470
00:19:09,679 --> 00:19:10,559
prime

471
00:19:10,559 --> 00:19:12,720
to the 2 to the k which can be

472
00:19:12,720 --> 00:19:15,840
polynomial in w

473
00:19:16,240 --> 00:19:18,799
so the question is are we done here

474
00:19:18,799 --> 00:19:21,039
is all we need to do apply this

475
00:19:21,039 --> 00:19:23,200
decomposition into blocks and treats

476
00:19:23,200 --> 00:19:25,440
them as independent instances

477
00:19:25,440 --> 00:19:28,799
independent instances

478
00:19:30,000 --> 00:19:32,559
if the answer were positive the protocol

479
00:19:32,559 --> 00:19:34,880
would be very simple

480
00:19:34,880 --> 00:19:37,360
but we wouldn't be contributing anything

481
00:19:37,360 --> 00:19:40,879
so obviously the answer is no

482
00:19:41,440 --> 00:19:44,000
now to understand why you have to recall

483
00:19:44,000 --> 00:19:46,400
how the protocol worked

484
00:19:46,400 --> 00:19:48,160
step number two

485
00:19:48,160 --> 00:19:50,799
required the parties to reconstruct the

486
00:19:50,799 --> 00:19:54,240
masked value of the input

487
00:19:54,240 --> 00:19:57,200
so the communication

488
00:19:57,200 --> 00:19:58,880
was

489
00:19:58,880 --> 00:20:01,440
equal to the size

490
00:20:01,440 --> 00:20:03,120
of the input

491
00:20:03,120 --> 00:20:05,360
so for each block the input has size 2

492
00:20:05,360 --> 00:20:07,520
to the k times w prime

493
00:20:07,520 --> 00:20:10,000
so plug that in

494
00:20:10,000 --> 00:20:11,600
and you'll see that overall the

495
00:20:11,600 --> 00:20:15,039
computation will be too large

496
00:20:16,640 --> 00:20:20,320
at this point you may pause and wonder

497
00:20:20,320 --> 00:20:23,520
because well you may be convinced that

498
00:20:23,520 --> 00:20:25,600
uh if you take this particular

499
00:20:25,600 --> 00:20:28,400
decomposition the first w prime outputs

500
00:20:28,400 --> 00:20:30,320
followed by the next w primes and the

501
00:20:30,320 --> 00:20:32,080
next and the next

502
00:20:32,080 --> 00:20:34,720
since this decomposition doesn't work

503
00:20:34,720 --> 00:20:37,360
but does this mean that there is no

504
00:20:37,360 --> 00:20:41,120
block deep composition which works

505
00:20:41,520 --> 00:20:42,400
let's

506
00:20:42,400 --> 00:20:46,400
express this as a combinatorial problem

507
00:20:46,480 --> 00:20:49,440
the circuit which is adversarially

508
00:20:49,440 --> 00:20:51,919
chosen

509
00:20:52,400 --> 00:20:55,280
is essentially

510
00:20:55,280 --> 00:20:57,280
for our purposes here

511
00:20:57,280 --> 00:21:00,640
just a list of subsets of inputs

512
00:21:00,640 --> 00:21:03,760
each input corresponds to at most two to

513
00:21:03,760 --> 00:21:06,720
the k inputs

514
00:21:07,039 --> 00:21:09,440
and our goal is to find the nicest

515
00:21:09,440 --> 00:21:13,120
decomposition which works for us

516
00:21:13,280 --> 00:21:15,280
so what we want to do

517
00:21:15,280 --> 00:21:18,480
is instead of just batching uh dub as

518
00:21:18,480 --> 00:21:21,200
the outputs arbitrarily

519
00:21:21,200 --> 00:21:23,760
we would like to batch some

520
00:21:23,760 --> 00:21:26,080
um

521
00:21:26,320 --> 00:21:29,360
to batch together outputs with the most

522
00:21:29,360 --> 00:21:30,960
overlapping inputs

523
00:21:30,960 --> 00:21:33,600
in the hopes of finding a decomposition

524
00:21:33,600 --> 00:21:34,880
into blocks

525
00:21:34,880 --> 00:21:37,200
where each block has a small enough

526
00:21:37,200 --> 00:21:38,400
amount

527
00:21:38,400 --> 00:21:41,280
number of inputs

528
00:21:41,520 --> 00:21:45,360
that if we were to apply the protocol

529
00:21:45,360 --> 00:21:47,679
to each of those blocks

530
00:21:47,679 --> 00:21:49,360
overall the communication would still be

531
00:21:49,360 --> 00:21:52,240
linear in w

532
00:21:52,559 --> 00:21:55,039
now unfortunately no such decomposition

533
00:21:55,039 --> 00:21:56,840
can

534
00:21:56,840 --> 00:21:59,679
exist to understand why we have to

535
00:21:59,679 --> 00:22:02,159
remember that the circuit is is

536
00:22:02,159 --> 00:22:03,760
adversarially chosen

537
00:22:03,760 --> 00:22:05,679
in other words our protocol has to work

538
00:22:05,679 --> 00:22:07,679
for every single circuit

539
00:22:07,679 --> 00:22:10,960
or rather for every single circuit even

540
00:22:10,960 --> 00:22:13,200
worst case for us we have to be able to

541
00:22:13,200 --> 00:22:16,159
come up with a protocol

542
00:22:17,280 --> 00:22:20,000
so in particular if

543
00:22:20,000 --> 00:22:23,600
the matching of outputs to inputs

544
00:22:23,600 --> 00:22:26,400
is just a random bipartite graph with

545
00:22:26,400 --> 00:22:29,280
high probability this is an expander

546
00:22:29,280 --> 00:22:32,240
being an expander means exactly that we

547
00:22:32,240 --> 00:22:34,159
won't be able to find

548
00:22:34,159 --> 00:22:38,600
such a small decomposition

549
00:22:40,720 --> 00:22:42,720
there is no way of simply

550
00:22:42,720 --> 00:22:45,280
decomposing

551
00:22:45,760 --> 00:22:49,120
of finding such a decomposition which

552
00:22:49,120 --> 00:22:50,960
would allow us to just invoke

553
00:22:50,960 --> 00:22:52,320
independence

554
00:22:52,320 --> 00:22:55,360
in the independent instances of the

555
00:22:55,360 --> 00:22:57,440
previous protocol

556
00:22:57,440 --> 00:23:00,159
well if we can't treat these blocks as

557
00:23:00,159 --> 00:23:01,440
independent

558
00:23:01,440 --> 00:23:03,679
we'll just have to deal with them um all

559
00:23:03,679 --> 00:23:07,200
at the same time in a correlated fashion

560
00:23:07,200 --> 00:23:09,360
so since the issue we raised just before

561
00:23:09,360 --> 00:23:11,840
was that we couldn't generate too many

562
00:23:11,840 --> 00:23:13,600
little masks

563
00:23:13,600 --> 00:23:15,760
what about just generating

564
00:23:15,760 --> 00:23:16,559
one

565
00:23:16,559 --> 00:23:18,320
single mask

566
00:23:18,320 --> 00:23:20,240
and whenever we want to compute one of

567
00:23:20,240 --> 00:23:21,440
those blocks

568
00:23:21,440 --> 00:23:25,520
will only consider a sub mask

569
00:23:25,520 --> 00:23:28,240
so unfortunately this doesn't actually

570
00:23:28,240 --> 00:23:32,080
solve the problem of computation

571
00:23:32,559 --> 00:23:35,679
so it's very easy if it's very we can

572
00:23:35,679 --> 00:23:37,360
very easily see why

573
00:23:37,360 --> 00:23:39,039
visually

574
00:23:39,039 --> 00:23:41,760
so this is the mask r

575
00:23:41,760 --> 00:23:43,679
which covers the entire span of the

576
00:23:43,679 --> 00:23:46,480
inputs it has size w

577
00:23:46,480 --> 00:23:48,559
now let's say we're only interested in a

578
00:23:48,559 --> 00:23:51,520
sub mask r prime of size 2 to the k

579
00:23:51,520 --> 00:23:53,520
times w prime

580
00:23:53,520 --> 00:23:55,440
so what we want to do with this vector

581
00:23:55,440 --> 00:23:56,799
is compute

582
00:23:56,799 --> 00:23:59,919
the first two to the k tensor powers of

583
00:23:59,919 --> 00:24:01,919
r prime

584
00:24:01,919 --> 00:24:04,480
unfortunately as you can see

585
00:24:04,480 --> 00:24:05,360
uh

586
00:24:05,360 --> 00:24:06,559
h prime

587
00:24:06,559 --> 00:24:09,520
has still one of its coordinates which

588
00:24:09,520 --> 00:24:11,600
uh depends on w

589
00:24:11,600 --> 00:24:15,279
so if you actually raise r prime to z

590
00:24:15,279 --> 00:24:18,159
to k ten to the power

591
00:24:18,159 --> 00:24:21,279
the computation still

592
00:24:21,279 --> 00:24:24,000
is still of the form w to the 2 to the k

593
00:24:24,000 --> 00:24:26,720
we've only reduced one of the dimensions

594
00:24:26,720 --> 00:24:30,480
of the matrix not both

595
00:24:31,600 --> 00:24:33,840
so

596
00:24:35,520 --> 00:24:38,000
perhaps um

597
00:24:38,000 --> 00:24:40,480
on a more intuitive level

598
00:24:40,480 --> 00:24:42,720
the idea is that when we're considering

599
00:24:42,720 --> 00:24:44,880
a sub mask

600
00:24:44,880 --> 00:24:46,400
we're still looking at a linear

601
00:24:46,400 --> 00:24:51,120
combination of all of the noise vector

602
00:24:51,279 --> 00:24:54,320
so that's why it doesn't really work

603
00:24:54,320 --> 00:24:56,640
it's simply because

604
00:24:56,640 --> 00:24:58,640
the observation that we had input

605
00:24:58,640 --> 00:25:02,720
locality does not translate over to

606
00:25:02,720 --> 00:25:04,720
compactly generated

607
00:25:04,720 --> 00:25:07,039
sub masks

608
00:25:07,039 --> 00:25:09,200
at this point we've reached the heart of

609
00:25:09,200 --> 00:25:11,760
the problem

610
00:25:11,840 --> 00:25:15,039
we need to define a pcg for a new type

611
00:25:15,039 --> 00:25:17,840
of correlation

612
00:25:17,919 --> 00:25:21,120
namely the following

613
00:25:21,760 --> 00:25:25,520
when the seeds have been expanded

614
00:25:25,520 --> 00:25:29,120
we want the parties to get two things

615
00:25:29,120 --> 00:25:30,559
the first

616
00:25:30,559 --> 00:25:32,320
are additive shares

617
00:25:32,320 --> 00:25:36,799
of a long mask of size w

618
00:25:37,520 --> 00:25:39,200
the second

619
00:25:39,200 --> 00:25:42,640
is that for every sub mask of size 2 to

620
00:25:42,640 --> 00:25:45,360
the case times w prime

621
00:25:45,360 --> 00:25:48,000
we want the parties to be able to get

622
00:25:48,000 --> 00:25:50,880
the first 2 to the k tensor powers of

623
00:25:50,880 --> 00:25:52,880
that sub mask

624
00:25:52,880 --> 00:25:55,039
the only question that remains

625
00:25:55,039 --> 00:25:57,039
is whether we can

626
00:25:57,039 --> 00:25:59,200
instantiate

627
00:25:59,200 --> 00:26:02,640
this new pcg under lpn

628
00:26:02,640 --> 00:26:05,200
the answer is yes and the following the

629
00:26:05,200 --> 00:26:08,640
answer the solution is the following

630
00:26:08,640 --> 00:26:11,200
instead of generating the

631
00:26:11,200 --> 00:26:14,799
random mask directly as public matrix

632
00:26:14,799 --> 00:26:16,880
times past noise

633
00:26:16,880 --> 00:26:19,120
we're going to generate it

634
00:26:19,120 --> 00:26:20,400
as the sum

635
00:26:20,400 --> 00:26:24,520
of many shorter masks

636
00:26:24,960 --> 00:26:26,799
now the point is

637
00:26:26,799 --> 00:26:29,520
if we're only interested in a given sub

638
00:26:29,520 --> 00:26:31,520
mask

639
00:26:31,520 --> 00:26:32,799
r prime

640
00:26:32,799 --> 00:26:34,640
it will only depend

641
00:26:34,640 --> 00:26:35,919
on

642
00:26:35,919 --> 00:26:36,640
a

643
00:26:36,640 --> 00:26:38,960
local subset

644
00:26:38,960 --> 00:26:41,760
of the shorter masks

645
00:26:41,760 --> 00:26:44,240
now if each of the shorter masks is

646
00:26:44,240 --> 00:26:45,520
generated

647
00:26:45,520 --> 00:26:49,200
as a small instance of lpn so some small

648
00:26:49,200 --> 00:26:53,840
matrix h i times e i

649
00:26:54,000 --> 00:26:55,679
well it so happens that even if you

650
00:26:55,679 --> 00:26:57,360
concatenate

651
00:26:57,360 --> 00:26:58,559
all

652
00:26:58,559 --> 00:27:00,159
of the

653
00:27:00,159 --> 00:27:02,799
matrices

654
00:27:03,520 --> 00:27:06,640
defining the masks which intersect with

655
00:27:06,640 --> 00:27:09,279
that subset

656
00:27:09,279 --> 00:27:11,840
the concatenation of all these matrices

657
00:27:11,840 --> 00:27:14,720
is still a small matrix

658
00:27:14,720 --> 00:27:16,799
in particular it can be raised to the

659
00:27:16,799 --> 00:27:18,720
power two to the k

660
00:27:18,720 --> 00:27:21,120
while remaining

661
00:27:21,120 --> 00:27:24,799
polynomial in w

662
00:27:27,679 --> 00:27:30,080
so one observation

663
00:27:30,080 --> 00:27:32,159
is that since

664
00:27:32,159 --> 00:27:34,960
we've drastically reduced the size of

665
00:27:34,960 --> 00:27:37,760
our lpn instances

666
00:27:37,760 --> 00:27:39,919
we

667
00:27:40,480 --> 00:27:43,760
uh we need to that we need to assume now

668
00:27:43,760 --> 00:27:44,799
the

669
00:27:44,799 --> 00:27:49,520
quasi or super polynomial uh

670
00:27:49,520 --> 00:27:53,360
security of lpm

671
00:27:54,559 --> 00:27:57,279
but now if we go back

672
00:27:57,279 --> 00:27:58,720
to our main result

673
00:27:58,720 --> 00:28:00,399
we can understand

674
00:28:00,399 --> 00:28:01,200
why

675
00:28:01,200 --> 00:28:03,360
we require the superpolynomial hardness

676
00:28:03,360 --> 00:28:06,080
of lpn in order to instantiate our

677
00:28:06,080 --> 00:28:08,559
protocol

678
00:28:08,559 --> 00:28:10,559
let's now briefly summarize how the

679
00:28:10,559 --> 00:28:12,480
protocol goes

680
00:28:12,480 --> 00:28:14,000
the first step is to take the lead

681
00:28:14,000 --> 00:28:16,320
circuit and divide it into chunk of k

682
00:28:16,320 --> 00:28:17,919
consecutive layers

683
00:28:17,919 --> 00:28:20,320
where k is the desired factor of

684
00:28:20,320 --> 00:28:23,279
sublinearity

685
00:28:23,360 --> 00:28:25,919
then we take each chunk and break it

686
00:28:25,919 --> 00:28:28,399
down into blocks where the goal of each

687
00:28:28,399 --> 00:28:31,120
block is to compute only a small subset

688
00:28:31,120 --> 00:28:33,840
of the outputs

689
00:28:35,039 --> 00:28:36,240
finally

690
00:28:36,240 --> 00:28:38,880
each block can be evaluated

691
00:28:38,880 --> 00:28:42,559
using our new pcg

692
00:28:43,760 --> 00:28:46,399
so when you plug all of this together we

693
00:28:46,399 --> 00:28:48,960
have a certain number of constraints on

694
00:28:48,960 --> 00:28:52,399
uh the dimension of the lpn problem the

695
00:28:52,399 --> 00:28:55,440
size of the blocks the width of the

696
00:28:55,440 --> 00:28:58,559
size the depth of the chunks

697
00:28:58,559 --> 00:29:00,480
and

698
00:29:00,480 --> 00:29:03,120
playing around with all these parameters

699
00:29:03,120 --> 00:29:05,600
we find a sweet spot where everything

700
00:29:05,600 --> 00:29:08,399
works together

701
00:29:09,440 --> 00:29:11,520
the sublinearity factor

702
00:29:11,520 --> 00:29:13,760
can be anywhere from an arbitrarily

703
00:29:13,760 --> 00:29:16,080
small

704
00:29:17,120 --> 00:29:19,200
superconstant factor

705
00:29:19,200 --> 00:29:20,080
to

706
00:29:20,080 --> 00:29:22,799
almost log log s

707
00:29:22,799 --> 00:29:25,919
and computation follows from whatever

708
00:29:25,919 --> 00:29:28,799
the communication is

709
00:29:30,399 --> 00:29:33,840
with this i'd like to thank you

710
00:29:33,840 --> 00:29:36,080
very much for your attention

711
00:29:36,080 --> 00:29:38,240
and

712
00:29:38,320 --> 00:29:41,320
goodbye

