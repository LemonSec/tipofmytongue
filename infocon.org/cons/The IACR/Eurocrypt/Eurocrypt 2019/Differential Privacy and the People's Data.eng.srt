1
00:00:00,000 --> 00:00:03,810
good afternoon everyone my name is

2
00:00:02,399 --> 00:00:06,480
christine kasha and the president of the

3
00:00:03,810 --> 00:00:09,990
is er and i'm here speaking because the

4
00:00:06,480 --> 00:00:12,120
next session the invited talk is the is

5
00:00:09,990 --> 00:00:16,139
your distinguished lecture which is

6
00:00:12,120 --> 00:00:20,130
annually awarded or selected by the is

7
00:00:16,139 --> 00:00:23,910
your board of directors so today i am

8
00:00:20,130 --> 00:00:26,939
pleased to welcome Cynthia to work for

9
00:00:23,910 --> 00:00:30,900
this is a our Distinguished Lecture she

10
00:00:26,939 --> 00:00:32,940
has a long and extremely distinguished

11
00:00:30,900 --> 00:00:36,480
career in our field she is today

12
00:00:32,940 --> 00:00:38,809
Gordon Mackay professor of computer

13
00:00:36,480 --> 00:00:42,449
science at Harvard School of Engineering

14
00:00:38,809 --> 00:00:44,309
she started at Princeton and Cornell and

15
00:00:42,450 --> 00:00:45,989
I guess at Cornell she got involved this

16
00:00:44,309 --> 00:00:49,559
distributed computing because she worked

17
00:00:45,989 --> 00:00:52,890
later at IBM Research in Almaden for a

18
00:00:49,559 --> 00:00:55,410
decade or more including working on

19
00:00:52,890 --> 00:00:58,260
problems in distributed computing so

20
00:00:55,410 --> 00:01:01,019
among other things she got the Dijkstra

21
00:00:58,260 --> 00:01:04,559
award much later for work on the DLS

22
00:01:01,020 --> 00:01:07,290
paper on consensus which is today still

23
00:01:04,559 --> 00:01:10,830
again a prominent work in this area

24
00:01:07,290 --> 00:01:13,710
later she moved to I / - MS or in the

25
00:01:10,830 --> 00:01:16,798
Bay Area and she stay there until 2017

26
00:01:13,710 --> 00:01:18,600
when she became professor at Harvard and

27
00:01:16,799 --> 00:01:22,470
this time also she worked in many things

28
00:01:18,600 --> 00:01:24,390
that are now well very well known basic

29
00:01:22,470 --> 00:01:27,450
foundations in our field such as non

30
00:01:24,390 --> 00:01:30,810
malleable cryptography chosen ciphertext

31
00:01:27,450 --> 00:01:32,520
security differential privacy which is

32
00:01:30,810 --> 00:01:37,380
probably what she's going to talk about

33
00:01:32,520 --> 00:01:40,679
today and last but not all not lot not

34
00:01:37,380 --> 00:01:43,649
least also the kind of proof of work

35
00:01:40,680 --> 00:01:47,520
that has definitely contributed through

36
00:01:43,649 --> 00:01:50,909
Satoshi to a revival of ideas on such

37
00:01:47,520 --> 00:01:53,100
idea this with computing she has reached

38
00:01:50,909 --> 00:01:56,070
the TCC test of time award and the

39
00:01:53,100 --> 00:01:58,500
Dykstra award among many other awards in

40
00:01:56,070 --> 00:02:00,399
our field so please join me to welcome

41
00:01:58,500 --> 00:02:05,009
Cynthia twirled

42
00:02:00,400 --> 00:02:05,009
[Applause]

43
00:02:08,020 --> 00:02:14,270
thank you very much Kristian thank you

44
00:02:10,639 --> 00:02:16,700
for inviting me all right

45
00:02:14,270 --> 00:02:24,410
so differential privacy and the people's

46
00:02:16,700 --> 00:02:26,390
data there are two kinds of data

47
00:02:24,410 --> 00:02:28,640
analysis that you might think about when

48
00:02:26,390 --> 00:02:32,269
you think about privacy preserving data

49
00:02:28,640 --> 00:02:35,510
analysis so in one of them we're looking

50
00:02:32,270 --> 00:02:40,580
at the behavior of the population as a

51
00:02:35,510 --> 00:02:42,649
whole so examples would be census the

52
00:02:40,580 --> 00:02:45,890
Consumer Financial Protection Board in

53
00:02:42,650 --> 00:02:48,790
the United States which looks at loan

54
00:02:45,890 --> 00:02:52,269
applications and mortgages to find

55
00:02:48,790 --> 00:02:56,299
evidence of systematic discrimination

56
00:02:52,270 --> 00:02:58,040
that's great and another thing that you

57
00:02:56,300 --> 00:02:59,959
might do is you might be looking and

58
00:02:58,040 --> 00:03:02,090
doing some kind of machine learning

59
00:02:59,959 --> 00:03:04,519
where you're trying to say learn to

60
00:03:02,090 --> 00:03:07,130
distinguish cancerous cells from healthy

61
00:03:04,519 --> 00:03:08,630
cells and you have data from lots and

62
00:03:07,130 --> 00:03:10,940
lots of different people and you want to

63
00:03:08,630 --> 00:03:12,670
understand sort of statistically how to

64
00:03:10,940 --> 00:03:14,810
make these distinctions without

65
00:03:12,670 --> 00:03:18,649
compromising the privacy of individuals

66
00:03:14,810 --> 00:03:20,269
a different kind of situation where

67
00:03:18,650 --> 00:03:22,430
privacy comes up a different kind of

68
00:03:20,269 --> 00:03:24,320
data analysis would be when you're

69
00:03:22,430 --> 00:03:26,360
looking for a needle in a haystack so an

70
00:03:24,320 --> 00:03:28,730
example of this would have been the

71
00:03:26,360 --> 00:03:31,280
Total Information Awareness program in

72
00:03:28,730 --> 00:03:33,048
the United States intended to detect

73
00:03:31,280 --> 00:03:35,780
terrorists through analyzing troves of

74
00:03:33,049 --> 00:03:41,620
information privacy is an issue in both

75
00:03:35,780 --> 00:03:41,620
of these differential privacy deals with

76
00:03:44,019 --> 00:03:50,180
deals with the case on the left so

77
00:03:47,829 --> 00:03:53,329
preserving privacy when we're trying to

78
00:03:50,180 --> 00:03:56,269
do statistical analysis of data and in

79
00:03:53,329 --> 00:03:59,060
fact differential privacy preserves the

80
00:03:56,269 --> 00:04:01,820
privacy of individuals while allowing

81
00:03:59,060 --> 00:04:06,829
the statistical information to come

82
00:04:01,820 --> 00:04:08,560
through and it's entirely the wrong tool

83
00:04:06,829 --> 00:04:11,269
for the needle in the haystack

84
00:04:08,560 --> 00:04:14,290
differential privacy protects all of the

85
00:04:11,269 --> 00:04:16,699
outliers exactly hiding the needle and

86
00:04:14,290 --> 00:04:18,680
just allowing sort of the shape of the

87
00:04:16,699 --> 00:04:20,019
haystack to come through so it's

88
00:04:18,680 --> 00:04:24,580
completely the wrong tool

89
00:04:20,019 --> 00:04:27,430
the other case now you might have an

90
00:04:24,580 --> 00:04:29,710
intuition that statistics feel private a

91
00:04:27,430 --> 00:04:31,720
statistic is a quantity that's computed

92
00:04:29,710 --> 00:04:33,370
from a sample and it tells us the

93
00:04:31,720 --> 00:04:39,370
population as a whole

94
00:04:33,370 --> 00:04:41,500
so intuitively if we built two data sets

95
00:04:39,370 --> 00:04:43,690
using standard statistical methods to

96
00:04:41,500 --> 00:04:45,879
collect them independently from the same

97
00:04:43,690 --> 00:04:48,520
population for using the correct

98
00:04:45,879 --> 00:04:51,069
methodology we expect these two data

99
00:04:48,520 --> 00:04:56,859
sets to tell us the same things about

100
00:04:51,069 --> 00:04:59,169
our population as a whole now that is

101
00:04:56,860 --> 00:05:01,120
where a source of privacy sort of comes

102
00:04:59,169 --> 00:05:03,068
at least our sense of privacy is derived

103
00:05:01,120 --> 00:05:05,110
from this fact you can say to yourself

104
00:05:03,069 --> 00:05:07,479
well nobody knows I was in the sample if

105
00:05:05,110 --> 00:05:10,240
you were actually in the sample or I can

106
00:05:07,479 --> 00:05:11,889
claim that I opted out or somehow this

107
00:05:10,240 --> 00:05:15,280
isn't about me this is about the

108
00:05:11,889 --> 00:05:17,740
population as a whole and this intuition

109
00:05:15,280 --> 00:05:19,289
is on the right track but it needs some

110
00:05:17,740 --> 00:05:22,030
help to be made rigorous and

111
00:05:19,289 --> 00:05:24,639
differential privacy provides exactly

112
00:05:22,030 --> 00:05:27,068
that help so differential privacy

113
00:05:24,639 --> 00:05:29,949
extends this sort of statistical notion

114
00:05:27,069 --> 00:05:32,560
of privacy to all computations it

115
00:05:29,949 --> 00:05:36,310
preserves the I could have opted out

116
00:05:32,560 --> 00:05:41,409
privacy for every computation including

117
00:05:36,310 --> 00:05:44,949
things like total population counts this

118
00:05:41,409 --> 00:05:47,469
is our general model of computing we

119
00:05:44,949 --> 00:05:49,599
have a database I don't care what form

120
00:05:47,469 --> 00:05:52,210
the databases in for this abstraction

121
00:05:49,599 --> 00:05:55,000
it's just some giant mass of data and

122
00:05:52,210 --> 00:05:57,430
the data analyst interacts with this

123
00:05:55,000 --> 00:06:00,250
data set you can think of this as a

124
00:05:57,430 --> 00:06:02,139
single data analyst who asks a question

125
00:06:00,250 --> 00:06:04,779
of the data some kind of a statistical

126
00:06:02,139 --> 00:06:07,539
query and gets back an answer that q1

127
00:06:04,779 --> 00:06:10,360
and a1 and then based on that adaptively

128
00:06:07,539 --> 00:06:13,150
chooses another query q2 gets an answer

129
00:06:10,360 --> 00:06:16,300
a 2 and so on or you could think of it

130
00:06:13,150 --> 00:06:17,169
more abstractly where q1 is a study done

131
00:06:16,300 --> 00:06:19,990
by

132
00:06:17,169 --> 00:06:22,090
some researcher or research group and

133
00:06:19,990 --> 00:06:24,009
they published the results of their

134
00:06:22,090 --> 00:06:26,229
study and that's a 1 and then they do

135
00:06:24,009 --> 00:06:28,749
another study some other group perhaps

136
00:06:26,229 --> 00:06:31,900
does another study and that would be q2

137
00:06:28,749 --> 00:06:35,560
and published their results a 2 and so

138
00:06:31,900 --> 00:06:39,370
on so this this is a very abstract

139
00:06:35,560 --> 00:06:41,650
notion it allows us to capture collusion

140
00:06:39,370 --> 00:06:43,629
among various data analysts we just do

141
00:06:41,650 --> 00:06:47,109
them as one as different parts of one

142
00:06:43,629 --> 00:06:50,770
giant malevolent analyst that's getting

143
00:06:47,110 --> 00:06:54,310
at the data the driving scenario and we

144
00:06:50,770 --> 00:06:56,109
started this work was a analysis of US

145
00:06:54,310 --> 00:06:58,569
census data and I'll say more about that

146
00:06:56,110 --> 00:07:01,289
quite a bit but this is a very old

147
00:06:58,569 --> 00:07:04,060
problem it's been studied for at least I

148
00:07:01,289 --> 00:07:06,520
guess now 54 years starting with

149
00:07:04,060 --> 00:07:08,050
Warner's work that I know of in 1965 I

150
00:07:06,520 --> 00:07:10,198
don't mention more about that in a

151
00:07:08,050 --> 00:07:13,870
moment

152
00:07:10,199 --> 00:07:16,749
so in English differential privacy says

153
00:07:13,870 --> 00:07:19,749
that the outcome of any analysis is

154
00:07:16,749 --> 00:07:22,629
essentially equally likely independent

155
00:07:19,749 --> 00:07:24,759
of whether any individual joins or

156
00:07:22,629 --> 00:07:26,889
refrains from joining the data set

157
00:07:24,759 --> 00:07:30,430
that's that I could have opted out

158
00:07:26,889 --> 00:07:32,770
intuition so what this says is that the

159
00:07:30,430 --> 00:07:35,349
analyses are going to be randomized and

160
00:07:32,770 --> 00:07:39,339
that's how we're going to get these

161
00:07:35,349 --> 00:07:41,919
similarities of outcomes but still on

162
00:07:39,339 --> 00:07:43,899
the intuitive level what we want is that

163
00:07:41,919 --> 00:07:46,659
we should learn the same things whether

164
00:07:43,899 --> 00:07:48,909
any individual is or is not in the

165
00:07:46,659 --> 00:07:50,680
database we should learn the same

166
00:07:48,909 --> 00:07:52,779
fundamental statistical truths

167
00:07:50,680 --> 00:07:55,839
independent of the participation of any

168
00:07:52,779 --> 00:07:59,349
individual now think about machine

169
00:07:55,839 --> 00:08:01,389
learning you want stability in fact you

170
00:07:59,349 --> 00:08:03,849
need stability in machine learning for

171
00:08:01,389 --> 00:08:05,169
generalization you need that the same

172
00:08:03,849 --> 00:08:08,710
things should have been learned

173
00:08:05,169 --> 00:08:10,870
independent of her whether any sample or

174
00:08:08,710 --> 00:08:13,239
small set of samples was included this

175
00:08:10,870 --> 00:08:16,360
is a requirement for generalization and

176
00:08:13,240 --> 00:08:19,029
so while we often hear about privacy and

177
00:08:16,360 --> 00:08:22,029
utility being at odds with each other we

178
00:08:19,029 --> 00:08:23,860
see that in fact privacy and this very

179
00:08:22,029 --> 00:08:25,250
strong notion of utility which is

180
00:08:23,860 --> 00:08:29,000
generalized

181
00:08:25,250 --> 00:08:34,830
generalizability two samples not in your

182
00:08:29,000 --> 00:08:37,770
training data are actually aligned so

183
00:08:34,830 --> 00:08:42,479
here's the formal definition our

184
00:08:37,770 --> 00:08:44,850
algorithms are called mechanisms M and M

185
00:08:42,479 --> 00:08:47,160
as I mentioned earlier is going to be

186
00:08:44,850 --> 00:08:49,350
randomized so all of the randomness in

187
00:08:47,160 --> 00:08:51,449
our discussion is over the coin flips of

188
00:08:49,350 --> 00:08:52,920
the algorithm which as you know from

189
00:08:51,450 --> 00:08:55,470
crypto is the good source of randomness

190
00:08:52,920 --> 00:09:01,079
we're not talking about who happens to

191
00:08:55,470 --> 00:09:03,600
have been included in the data set all

192
00:09:01,080 --> 00:09:08,459
right and we need the notion of a pair

193
00:09:03,600 --> 00:09:11,670
of adjacent data sets so data sets x and

194
00:09:08,459 --> 00:09:14,939
y are adjacent if they have almost

195
00:09:11,670 --> 00:09:17,490
exactly the same set of people but one

196
00:09:14,940 --> 00:09:21,660
of them has the data of just one more

197
00:09:17,490 --> 00:09:23,490
person so everybody in this room versus

198
00:09:21,660 --> 00:09:27,209
everybody in this room without me I

199
00:09:23,490 --> 00:09:31,350
could have opted out and the requirement

200
00:09:27,209 --> 00:09:34,439
is that for any event s in the output

201
00:09:31,350 --> 00:09:36,480
space of the of the mechanism of the

202
00:09:34,440 --> 00:09:39,000
algorithm the probability that we

203
00:09:36,480 --> 00:09:42,390
observe this event when the database is

204
00:09:39,000 --> 00:09:44,700
X is very close to the probability that

205
00:09:42,390 --> 00:09:47,970
we observe it when the database is why

206
00:09:44,700 --> 00:09:49,560
it's at most e to the epsilon times the

207
00:09:47,970 --> 00:09:52,560
probability of observing it when the

208
00:09:49,560 --> 00:09:55,529
database is y now think of epsilon as a

209
00:09:52,560 --> 00:09:59,160
small constant so e to the epsilon is

210
00:09:55,529 --> 00:10:01,500
about 1 plus Epsilon and notice that the

211
00:09:59,160 --> 00:10:03,300
roles of x and y are symmetric in this

212
00:10:01,500 --> 00:10:08,399
definition so we get the other

213
00:10:03,300 --> 00:10:11,550
inequality as well and epsilon is called

214
00:10:08,399 --> 00:10:14,490
the bound on the privacy loss and again

215
00:10:11,550 --> 00:10:16,740
the randomness is introduced by the

216
00:10:14,490 --> 00:10:19,459
algorithm and of course this is joint

217
00:10:16,740 --> 00:10:22,200
work with McSherry nice Eamonn Smith

218
00:10:19,459 --> 00:10:24,810
so the key properties of differential

219
00:10:22,200 --> 00:10:26,730
privacy are first of all it's

220
00:10:24,810 --> 00:10:30,779
future-proof if you have an algorithm

221
00:10:26,730 --> 00:10:33,900
that's differentially private then it

222
00:10:30,779 --> 00:10:36,600
retains this privacy no matter what

223
00:10:33,900 --> 00:10:37,290
additional computation is performed on

224
00:10:36,600 --> 00:10:40,320
the output

225
00:10:37,290 --> 00:10:43,339
of the algorithm or what auxiliary

226
00:10:40,320 --> 00:10:46,259
information your adversary might come

227
00:10:43,339 --> 00:10:48,959
come in contact with other than of

228
00:10:46,259 --> 00:10:51,000
course seeing right into the database so

229
00:10:48,959 --> 00:10:56,099
it's resilient to present or future

230
00:10:51,000 --> 00:10:58,519
auxiliary information the second

231
00:10:56,100 --> 00:11:03,120
important property is that it composes

232
00:10:58,519 --> 00:11:05,310
gracefully and automatically so we

233
00:11:03,120 --> 00:11:07,500
understand how the Epsilon's of

234
00:11:05,310 --> 00:11:09,869
different analyses or steps or

235
00:11:07,500 --> 00:11:12,029
differentially private steps add up and

236
00:11:09,870 --> 00:11:14,040
we get nice composition properties and

237
00:11:12,029 --> 00:11:15,930
they're automatic we don't have to do

238
00:11:14,040 --> 00:11:19,170
any special work to make composition

239
00:11:15,930 --> 00:11:21,269
happen these two properties together

240
00:11:19,170 --> 00:11:24,089
tell us that differential privacy is

241
00:11:21,269 --> 00:11:26,430
programmable meaning that you can build

242
00:11:24,089 --> 00:11:28,740
complex differentially private analyses

243
00:11:26,430 --> 00:11:32,370
from small differentially private

244
00:11:28,740 --> 00:11:34,440
primitives and building blocks and it's

245
00:11:32,370 --> 00:11:36,480
the only notion of privacy that has this

246
00:11:34,440 --> 00:11:38,519
property and this is of course where it

247
00:11:36,480 --> 00:11:42,050
gets all of its power from and why we

248
00:11:38,519 --> 00:11:42,050
can use it for so many different things

249
00:11:42,079 --> 00:11:48,569
now there are various relaxations to the

250
00:11:45,540 --> 00:11:50,120
formal definition that I gave and in

251
00:11:48,569 --> 00:11:54,000
fact if you think of a pair of adjacent

252
00:11:50,120 --> 00:11:58,350
databases x and y and you run the

253
00:11:54,000 --> 00:12:01,459
algorithm once on database x and get an

254
00:11:58,350 --> 00:12:05,819
output c you can define the privacy loss

255
00:12:01,459 --> 00:12:08,849
of x and y of see with respond X with

256
00:12:05,819 --> 00:12:11,880
respect to Y as the log of this ratio of

257
00:12:08,850 --> 00:12:13,230
probabilities and the privacy loss when

258
00:12:11,880 --> 00:12:15,689
you look at it this way it's clearly

259
00:12:13,230 --> 00:12:18,630
it's a random variable and so then you

260
00:12:15,690 --> 00:12:20,310
can start playing games with well what

261
00:12:18,630 --> 00:12:24,089
does this random variable look like what

262
00:12:20,310 --> 00:12:26,579
is its variance what it's how do these

263
00:12:24,089 --> 00:12:28,470
things add up and so on so it's a random

264
00:12:26,579 --> 00:12:30,510
variable it can be positive and

265
00:12:28,470 --> 00:12:33,420
thankfully it can be negative and that's

266
00:12:30,510 --> 00:12:36,290
very nice for composition because things

267
00:12:33,420 --> 00:12:39,180
add up nicely and there's cancellation

268
00:12:36,290 --> 00:12:42,599
in pure differential privacy the privacy

269
00:12:39,180 --> 00:12:44,609
loss is always bounded by Epsilon but in

270
00:12:42,600 --> 00:12:47,010
what's called relaxed or approximate

271
00:12:44,610 --> 00:12:48,120
differential privacy or epsilon Delta

272
00:12:47,010 --> 00:12:50,519
differential privacy

273
00:12:48,120 --> 00:12:54,360
it's bounded by epsilon with probability

274
00:12:50,519 --> 00:12:57,720
one minus Delta and other relaxation z'

275
00:12:54,360 --> 00:13:00,689
capture various moments of the privacy

276
00:12:57,720 --> 00:13:02,639
loss random variable and I think the key

277
00:13:00,689 --> 00:13:07,189
inside of the last couple of years is

278
00:13:02,639 --> 00:13:09,480
that when you have very heavy levels of

279
00:13:07,189 --> 00:13:14,309
compositions you're doing many many many

280
00:13:09,480 --> 00:13:15,749
computations to some approximation it

281
00:13:14,309 --> 00:13:18,240
doesn't really matter which variant

282
00:13:15,749 --> 00:13:21,420
you're using the privacy loss random

283
00:13:18,240 --> 00:13:25,199
variable is a sub Gaussian and that's

284
00:13:21,420 --> 00:13:27,059
really nice and we can say that you know

285
00:13:25,199 --> 00:13:31,349
the probability that it's going to be K

286
00:13:27,059 --> 00:13:35,430
times this expectation drops with e to

287
00:13:31,350 --> 00:13:38,819
the minus K squared over two okay so

288
00:13:35,430 --> 00:13:41,910
here's a simple mechanism for

289
00:13:38,819 --> 00:13:43,259
differential privacy remember that we're

290
00:13:41,910 --> 00:13:47,249
trying to preserve the opt-in and

291
00:13:43,259 --> 00:13:48,779
opt-out privacy semantics so if we're

292
00:13:47,249 --> 00:13:51,180
trying to get a privacy preserving

293
00:13:48,779 --> 00:13:54,420
computation approximation to the

294
00:13:51,180 --> 00:13:57,029
function f we look at how much the data

295
00:13:54,420 --> 00:13:58,920
of a single person can possibly swing

296
00:13:57,029 --> 00:14:03,480
the value of the function f and that's

297
00:13:58,920 --> 00:14:06,149
called the l1 sensitivity and what we do

298
00:14:03,480 --> 00:14:10,589
is we add noise that's drawn according

299
00:14:06,149 --> 00:14:16,769
to a Laplace with variance death sorry I

300
00:14:10,589 --> 00:14:18,660
mean Delta one over epsilon so if we

301
00:14:16,769 --> 00:14:20,399
have a single counting query how many

302
00:14:18,660 --> 00:14:24,059
people in the database satisfy some

303
00:14:20,399 --> 00:14:26,490
property P we have to add noise that's

304
00:14:24,059 --> 00:14:28,499
scaled to one over epsilon as I said

305
00:14:26,490 --> 00:14:30,179
think of epsilon is a small constant so

306
00:14:28,499 --> 00:14:33,269
we're adding noise that's basically

307
00:14:30,179 --> 00:14:36,920
constant for one counting query if we

308
00:14:33,269 --> 00:14:41,339
want to handle K counting queries a

309
00:14:36,920 --> 00:14:43,860
single individual can affect perhaps

310
00:14:41,339 --> 00:14:46,470
each of these different queries so if

311
00:14:43,860 --> 00:14:48,269
you're asking how many people like

312
00:14:46,470 --> 00:14:49,769
Beethoven and how many people like off

313
00:14:48,269 --> 00:14:51,449
and how many people like Schubert there

314
00:14:49,769 --> 00:14:54,420
may be one person who is in all of those

315
00:14:51,449 --> 00:14:58,280
counts so if that single person could

316
00:14:54,420 --> 00:15:00,020
affect that triple of queries by three

317
00:14:58,280 --> 00:15:02,780
so we would add noise that would be

318
00:15:00,020 --> 00:15:05,990
scaled to three in each case when we

319
00:15:02,780 --> 00:15:08,600
relaxed to epsilon-delta differential

320
00:15:05,990 --> 00:15:10,100
privacy we can use a different notion of

321
00:15:08,600 --> 00:15:16,310
sensitivity which is the L to

322
00:15:10,100 --> 00:15:19,070
sensitivity and here we're adding

323
00:15:16,310 --> 00:15:22,310
Gaussian noise and roughly speaking the

324
00:15:19,070 --> 00:15:26,540
noise is scaled to the square of the L

325
00:15:22,310 --> 00:15:28,250
to sensitivity over I'm sorry the

326
00:15:26,540 --> 00:15:31,819
variance is the square of the L to

327
00:15:28,250 --> 00:15:34,310
sensitivity over epsilon squared so what

328
00:15:31,820 --> 00:15:36,080
that means is this time for cake

329
00:15:34,310 --> 00:15:38,030
counting queries we're adding noise

330
00:15:36,080 --> 00:15:40,520
that's scaled to square root of K for

331
00:15:38,030 --> 00:15:44,270
each one rather than K for each one this

332
00:15:40,520 --> 00:15:46,640
is a major win and in the long run we're

333
00:15:44,270 --> 00:15:48,380
going to get to ignore that term the log

334
00:15:46,640 --> 00:15:51,110
of 2 over Delta divided by epsilon

335
00:15:48,380 --> 00:15:54,830
squared it'll show up every now and then

336
00:15:51,110 --> 00:16:00,800
but in these high levels of composition

337
00:15:54,830 --> 00:16:02,420
it sort of goes away so I thought I tell

338
00:16:00,800 --> 00:16:06,050
you about a beautiful beautiful

339
00:16:02,420 --> 00:16:09,199
algorithm from paper of nickel of tawa

340
00:16:06,050 --> 00:16:12,680
and Zhang it's not their main result in

341
00:16:09,200 --> 00:16:14,540
fact it's algorithm 5 in their paper but

342
00:16:12,680 --> 00:16:16,250
it's really stunning and it has some

343
00:16:14,540 --> 00:16:18,230
nice properties and it'll give you an

344
00:16:16,250 --> 00:16:23,840
idea of some of the things that people

345
00:16:18,230 --> 00:16:27,250
get to do in this field so the paper is

346
00:16:23,840 --> 00:16:30,560
on the geometry of differential privacy

347
00:16:27,250 --> 00:16:33,410
so let's say that we have a query matrix

348
00:16:30,560 --> 00:16:36,709
our query matrix is a set in this case

349
00:16:33,410 --> 00:16:38,510
of K different counting queries so what

350
00:16:36,710 --> 00:16:41,420
I have is U is my universe of

351
00:16:38,510 --> 00:16:45,200
individuals and I'm representing the

352
00:16:41,420 --> 00:16:47,599
database by a vector X which says for

353
00:16:45,200 --> 00:16:50,450
each of the possible kinds of

354
00:16:47,600 --> 00:16:53,420
individuals how many of them are in the

355
00:16:50,450 --> 00:16:58,250
database it's a histogram representation

356
00:16:53,420 --> 00:17:00,079
of the database so for two I can

357
00:16:58,250 --> 00:17:02,600
describe a counting query by describing

358
00:17:00,080 --> 00:17:04,520
what I'm looking for in my counting

359
00:17:02,600 --> 00:17:07,220
query it's say people over 6 feet tall

360
00:17:04,520 --> 00:17:08,990
and and and less than 150 pounds or

361
00:17:07,220 --> 00:17:10,610
something I can say which sorts of

362
00:17:08,990 --> 00:17:12,020
people would be in that and the

363
00:17:10,609 --> 00:17:14,059
a product of that with my histogram

364
00:17:12,020 --> 00:17:15,559
would be the count of the number of

365
00:17:14,059 --> 00:17:17,599
people in the database with that

366
00:17:15,559 --> 00:17:22,879
property so I have a row of this matrix

367
00:17:17,599 --> 00:17:25,609
for each of the queries and Nikolov

368
00:17:22,880 --> 00:17:28,520
Talwar and Jung defined a body convex

369
00:17:25,609 --> 00:17:32,090
body called K which is the query matrix

370
00:17:28,520 --> 00:17:35,780
times the l1 ball so it's the feasible

371
00:17:32,090 --> 00:17:38,270
region in answer space for databases X

372
00:17:35,780 --> 00:17:43,340
if the database contained only one

373
00:17:38,270 --> 00:17:45,740
person and the vertices of this are the

374
00:17:43,340 --> 00:17:52,159
columns plus and minus the columns of

375
00:17:45,740 --> 00:17:55,549
the matrix a now given this convex

376
00:17:52,160 --> 00:17:59,030
bodies okay you can define a K norm

377
00:17:55,549 --> 00:18:03,790
which is sort of how much do I have to

378
00:17:59,030 --> 00:18:08,059
inflate K until I capture the element Z

379
00:18:03,790 --> 00:18:10,370
so if Z is outside of K I have to push

380
00:18:08,059 --> 00:18:13,610
it up more and I get a multiple R which

381
00:18:10,370 --> 00:18:15,969
is larger than one if Z is inside of K

382
00:18:13,610 --> 00:18:21,139
then I can shrink it down a little bit

383
00:18:15,970 --> 00:18:22,429
so that's the K norm the polar norm has

384
00:18:21,140 --> 00:18:24,919
a different and less intuitive

385
00:18:22,429 --> 00:18:28,370
definition and it's the maximum over all

386
00:18:24,919 --> 00:18:32,570
Y in the body of the inner product of y

387
00:18:28,370 --> 00:18:35,120
and z now we care about these because

388
00:18:32,570 --> 00:18:39,678
holder inequality says that for every

389
00:18:35,120 --> 00:18:42,830
pair of vectors U and W the inner

390
00:18:39,679 --> 00:18:47,960
product of U times W is bounded by the K

391
00:18:42,830 --> 00:18:51,710
norm of U times the polar norm of W so

392
00:18:47,960 --> 00:18:53,510
here's their algorithm first of all

393
00:18:51,710 --> 00:18:55,490
instead of looking at the feasible

394
00:18:53,510 --> 00:18:57,679
region in answer space for databases of

395
00:18:55,490 --> 00:19:01,490
size one we look at databases of size n

396
00:18:57,679 --> 00:19:03,679
so that gives us n times K and the

397
00:19:01,490 --> 00:19:05,450
algorithm is simple they're going to use

398
00:19:03,679 --> 00:19:09,410
the Gaussian noise mechanism that I

399
00:19:05,450 --> 00:19:11,690
introduced earlier so for that funny

400
00:19:09,410 --> 00:19:13,220
term B which was like square root log 1

401
00:19:11,690 --> 00:19:15,770
over Delta over Epsilon

402
00:19:13,220 --> 00:19:19,880
they're adding noise that is scaled to K

403
00:19:15,770 --> 00:19:23,090
times B squared I'm sorry whose variance

404
00:19:19,880 --> 00:19:24,260
is K times B squared - the answers for

405
00:19:23,090 --> 00:19:27,199
each of the queries

406
00:19:24,260 --> 00:19:29,410
so they take this point why which is in

407
00:19:27,200 --> 00:19:31,400
the answer space and they add a

408
00:19:29,410 --> 00:19:33,740
phenomenal amount of noise because

409
00:19:31,400 --> 00:19:35,720
little K the number of questions could

410
00:19:33,740 --> 00:19:40,490
be very very large and they get some

411
00:19:35,720 --> 00:19:42,440
point way over outside called Y tilde so

412
00:19:40,490 --> 00:19:45,799
the noise that they've added for each

413
00:19:42,440 --> 00:19:47,660
query is way bigger than n the size of

414
00:19:45,799 --> 00:19:49,309
the database and it's accounting query

415
00:19:47,660 --> 00:19:51,559
how are we ever going to make any sense

416
00:19:49,309 --> 00:19:54,440
out of these things and that's the

417
00:19:51,559 --> 00:19:57,470
amazing thing they then take that and

418
00:19:54,440 --> 00:20:00,320
they project it back onto the body n

419
00:19:57,470 --> 00:20:03,650
times K and that's what they output is

420
00:20:00,320 --> 00:20:05,510
the answer so you add this completely

421
00:20:03,650 --> 00:20:09,770
independent noise to the answers for all

422
00:20:05,510 --> 00:20:11,840
the questions and all the dimensions you

423
00:20:09,770 --> 00:20:13,820
get this point way out there and then

424
00:20:11,840 --> 00:20:19,070
you project it down and you get

425
00:20:13,820 --> 00:20:21,200
something meaningful so the way they

426
00:20:19,070 --> 00:20:24,500
analyze what they do is they analyze the

427
00:20:21,200 --> 00:20:26,679
root mean squared error and the way they

428
00:20:24,500 --> 00:20:31,669
do it is first they do some basic

429
00:20:26,679 --> 00:20:34,520
trigonometry that shows that our error U

430
00:20:31,669 --> 00:20:36,830
which is y hat minus y squared is

431
00:20:34,520 --> 00:20:41,629
bounded by this term which is at most

432
00:20:36,830 --> 00:20:44,210
two times u times W W was that crazy

433
00:20:41,630 --> 00:20:48,049
amount of noise that we added then they

434
00:20:44,210 --> 00:20:58,309
apply holders inequality so first of all

435
00:20:48,049 --> 00:21:01,160
since Y hat is inside the body our our K

436
00:20:58,309 --> 00:21:06,080
norm sorry since Y is inside the body

437
00:21:01,160 --> 00:21:08,630
our K norm for Y is at most R gives it

438
00:21:06,080 --> 00:21:10,970
most n because Y is in n times K it's

439
00:21:08,630 --> 00:21:13,549
inside the body and the same thing is

440
00:21:10,970 --> 00:21:15,350
true for Y hat so by the triangle

441
00:21:13,549 --> 00:21:19,610
inequality we've got a bound of 2 in

442
00:21:15,350 --> 00:21:24,070
there for the polar norm we're looking

443
00:21:19,610 --> 00:21:26,299
at this maximum inner product and

444
00:21:24,070 --> 00:21:29,260
standard techniques say it's reached at

445
00:21:26,299 --> 00:21:32,629
one of the vertices of our convex bodies

446
00:21:29,260 --> 00:21:34,610
and so we get the two from the to u

447
00:21:32,630 --> 00:21:36,330
times W in the upper right and we get

448
00:21:34,610 --> 00:21:39,030
the 2 from the two N and we

449
00:21:36,330 --> 00:21:41,820
for n times the max of this inner

450
00:21:39,030 --> 00:21:44,850
product of one of these corners with our

451
00:21:41,820 --> 00:21:47,040
noise vector W but our noise vector was

452
00:21:44,850 --> 00:21:51,959
really special form it's just a whole

453
00:21:47,040 --> 00:21:56,070
bunch of gaussians added up so we end up

454
00:21:51,960 --> 00:21:58,560
with a total variance for a I times W

455
00:21:56,070 --> 00:22:01,980
bounded by K squared times that funny

456
00:21:58,560 --> 00:22:04,889
term d squared and expectation then of

457
00:22:01,980 --> 00:22:06,450
at most K be so with high probability

458
00:22:04,890 --> 00:22:09,720
the maximum over all of the different

459
00:22:06,450 --> 00:22:11,730
AIS since there are only the size of the

460
00:22:09,720 --> 00:22:13,560
universe of those will be at most square

461
00:22:11,730 --> 00:22:17,790
root of log of the size of the universe

462
00:22:13,560 --> 00:22:24,179
times KB and we get for this term for in

463
00:22:17,790 --> 00:22:25,740
the max I W we get this quantity but now

464
00:22:24,180 --> 00:22:27,240
we're going to divide by K because

465
00:22:25,740 --> 00:22:29,790
that's what the title of the slide says

466
00:22:27,240 --> 00:22:34,170
we want the average error so the number

467
00:22:29,790 --> 00:22:36,210
of queries drops out completely it's

468
00:22:34,170 --> 00:22:39,450
astonishing and the noise that this

469
00:22:36,210 --> 00:22:42,660
algorithm gives is essentially tight you

470
00:22:39,450 --> 00:22:44,700
can't do any better ok so why do I love

471
00:22:42,660 --> 00:22:47,250
this algorithm first of all it's

472
00:22:44,700 --> 00:22:50,670
conceptually simple use the Gaussian

473
00:22:47,250 --> 00:22:53,880
mechanism and project secondly it's

474
00:22:50,670 --> 00:22:57,060
almost uncoordinated there's a result

475
00:22:53,880 --> 00:22:58,980
that says that essentially to get good

476
00:22:57,060 --> 00:23:00,870
answers to more than N squared queries

477
00:22:58,980 --> 00:23:04,770
you have to coordinate the noise that

478
00:23:00,870 --> 00:23:06,959
you use where did we coordinate the only

479
00:23:04,770 --> 00:23:09,300
place we coordinated was in that

480
00:23:06,960 --> 00:23:12,060
projection where we projected down onto

481
00:23:09,300 --> 00:23:18,870
this body n times K which is a publicly

482
00:23:12,060 --> 00:23:20,760
known body and yeah so these are the

483
00:23:18,870 --> 00:23:23,310
reasons that I love it also I love it

484
00:23:20,760 --> 00:23:24,990
because it introduces you ever so

485
00:23:23,310 --> 00:23:27,270
slightly to some of the techniques that

486
00:23:24,990 --> 00:23:32,280
are used in the more advanced geometric

487
00:23:27,270 --> 00:23:35,820
approaches now projection onto this body

488
00:23:32,280 --> 00:23:39,139
is computationally hard and so I'll say

489
00:23:35,820 --> 00:23:39,139
a little bit more about this later

490
00:23:43,110 --> 00:23:48,760
okay so where are we today with

491
00:23:45,610 --> 00:23:52,050
differential privacy first of all it's

492
00:23:48,760 --> 00:23:54,550
being used in industry quite a bit so

493
00:23:52,050 --> 00:23:56,860
Apple is using it for things like

494
00:23:54,550 --> 00:24:01,840
learning new emojis and new spelling

495
00:23:56,860 --> 00:24:04,060
terms Google was using it for detecting

496
00:24:01,840 --> 00:24:06,129
vectors of for malware and the Chrome

497
00:24:04,060 --> 00:24:08,560
browser Microsoft is using it for

498
00:24:06,130 --> 00:24:09,940
Windows telemetry I'm not sure what

499
00:24:08,560 --> 00:24:13,240
Hoover is using it for but I've seen

500
00:24:09,940 --> 00:24:16,240
them advertising for people who know the

501
00:24:13,240 --> 00:24:18,130
field most of this work is in what we

502
00:24:16,240 --> 00:24:20,790
call the local differential privacy

503
00:24:18,130 --> 00:24:23,800
model which means that before

504
00:24:20,790 --> 00:24:27,360
information is sent to the company it's

505
00:24:23,800 --> 00:24:29,950
randomized in some way using for example

506
00:24:27,360 --> 00:24:34,389
techniques of randomize response

507
00:24:29,950 --> 00:24:35,740
introduced by by Warner in 1965 but

508
00:24:34,390 --> 00:24:37,450
modernized of course to be

509
00:24:35,740 --> 00:24:41,170
differentially private and to control

510
00:24:37,450 --> 00:24:43,480
the privacy loss so in industry parlance

511
00:24:41,170 --> 00:24:46,150
this says that the trust boundary is

512
00:24:43,480 --> 00:24:47,950
moved to the client your client is

513
00:24:46,150 --> 00:24:52,030
randomizing so you don't have to worry

514
00:24:47,950 --> 00:24:56,850
about whether the the central server is

515
00:24:52,030 --> 00:24:59,950
sure or not that's the intuition for

516
00:24:56,850 --> 00:25:01,360
simple counting queries we saw that in

517
00:24:59,950 --> 00:25:04,450
the centralized model you could get

518
00:25:01,360 --> 00:25:06,370
errors that look like one and in the in

519
00:25:04,450 --> 00:25:09,520
this model and the error is more like is

520
00:25:06,370 --> 00:25:12,030
its square root of n but there's some

521
00:25:09,520 --> 00:25:17,080
really exciting new directions in which

522
00:25:12,030 --> 00:25:20,050
the elements are randomized and then

523
00:25:17,080 --> 00:25:24,280
shuffled so that you break the tie

524
00:25:20,050 --> 00:25:26,760
between the randomized element and where

525
00:25:24,280 --> 00:25:28,990
it came from in the shuffle process and

526
00:25:26,760 --> 00:25:31,629
there will be a talk on this in the next

527
00:25:28,990 --> 00:25:34,720
session for example and this randomized

528
00:25:31,630 --> 00:25:36,490
and shuffle model and in this world you

529
00:25:34,720 --> 00:25:39,160
can get down to an error of n to the one

530
00:25:36,490 --> 00:25:41,110
sixth on the other hand the trust model

531
00:25:39,160 --> 00:25:43,660
now has to extend a bit to the other

532
00:25:41,110 --> 00:25:45,219
users you have to assume that the other

533
00:25:43,660 --> 00:25:50,740
users are doing what they're supposed to

534
00:25:45,220 --> 00:25:53,650
be doing Facebook is using differential

535
00:25:50,740 --> 00:25:56,140
privacy for social science one which is

536
00:25:53,650 --> 00:26:03,750
a project to allow academic researchers

537
00:25:56,140 --> 00:26:07,510
to do social science research on

538
00:26:03,750 --> 00:26:11,280
Facebook data and they have their first

539
00:26:07,510 --> 00:26:13,870
project running now and they're also

540
00:26:11,280 --> 00:26:16,180
partnering with Udacity to give

541
00:26:13,870 --> 00:26:17,919
scholarships for people to study these

542
00:26:16,180 --> 00:26:22,390
techniques together with federated

543
00:26:17,920 --> 00:26:24,940
learning and encrypted computation the

544
00:26:22,390 --> 00:26:26,950
first large-scale system of differential

545
00:26:24,940 --> 00:26:29,770
privacy that was ever deployed was done

546
00:26:26,950 --> 00:26:32,710
at the US Census Bureau in this tool

547
00:26:29,770 --> 00:26:34,270
which allows users to find out where

548
00:26:32,710 --> 00:26:36,730
workers where people live and where

549
00:26:34,270 --> 00:26:40,660
workers live where people work and where

550
00:26:36,730 --> 00:26:42,660
workers live that's on the map and very

551
00:26:40,660 --> 00:26:46,090
recently there has been some exciting

552
00:26:42,660 --> 00:26:50,500
census based research using two bespoke

553
00:26:46,090 --> 00:26:53,350
techniques by by the economist Raj

554
00:26:50,500 --> 00:26:57,630
Chetty and colleagues building something

555
00:26:53,350 --> 00:27:01,060
called the opportunity Atlas which maps

556
00:26:57,630 --> 00:27:02,830
a demographic mobility or social

557
00:27:01,060 --> 00:27:04,659
mobility according to where people live

558
00:27:02,830 --> 00:27:07,149
and how long they have lived in various

559
00:27:04,660 --> 00:27:09,070
regions in the United States so it's a

560
00:27:07,150 --> 00:27:12,880
fun tool and you can take a look at that

561
00:27:09,070 --> 00:27:16,330
on the web and a final application

562
00:27:12,880 --> 00:27:22,210
that's worth mentioning is that there's

563
00:27:16,330 --> 00:27:28,030
been a lot of discussion of how ways in

564
00:27:22,210 --> 00:27:30,340
which people hack the data and headlines

565
00:27:28,030 --> 00:27:33,550
like most scientific results are false

566
00:27:30,340 --> 00:27:36,399
and so on and so forth so the issue is

567
00:27:33,550 --> 00:27:38,470
what's called activity where the

568
00:27:36,400 --> 00:27:40,570
question that you ask depends on the

569
00:27:38,470 --> 00:27:43,870
data that you are currently exploring

570
00:27:40,570 --> 00:27:47,879
and this is a known statistical pitfall

571
00:27:43,870 --> 00:27:51,040
but people do it all at the time and the

572
00:27:47,880 --> 00:27:52,300
field you are here is that if you

573
00:27:51,040 --> 00:27:54,129
interact with your data in a

574
00:27:52,300 --> 00:27:56,050
differentially private fashion then this

575
00:27:54,130 --> 00:27:58,710
will neutralize the risks to validity

576
00:27:56,050 --> 00:28:03,350
that are caused by that activity

577
00:27:58,710 --> 00:28:07,530
okay so now let's get back to the census

578
00:28:03,350 --> 00:28:10,919
the census is the people's data it's

579
00:28:07,530 --> 00:28:15,440
used to allocate billions of dollars in

580
00:28:10,920 --> 00:28:15,440
resources it's used to determine

581
00:28:16,460 --> 00:28:21,750
allocation of seats in Congress and in

582
00:28:19,950 --> 00:28:26,720
the electoral college it's used in

583
00:28:21,750 --> 00:28:26,720
enforcement of the Voting Rights Act and

584
00:28:26,990 --> 00:28:33,990
the Census Bureau has a legal mandate

585
00:28:30,090 --> 00:28:36,419
for privacy so one of the things that we

586
00:28:33,990 --> 00:28:38,370
found is that you say I have this shiny

587
00:28:36,420 --> 00:28:40,950
new privacy technique you should use it

588
00:28:38,370 --> 00:28:42,750
and people say well we're fine you know

589
00:28:40,950 --> 00:28:44,070
we've had access to data all along we

590
00:28:42,750 --> 00:28:46,680
don't want to hear about you and your

591
00:28:44,070 --> 00:28:48,720
privacy preserving whatever but when

592
00:28:46,680 --> 00:28:51,000
there's a legal mandate for privacy and

593
00:28:48,720 --> 00:28:52,710
you can show that there's a problem then

594
00:28:51,000 --> 00:28:55,920
in some sense people have to pay

595
00:28:52,710 --> 00:28:59,880
attention and in general in other

596
00:28:55,920 --> 00:29:01,980
scenarios if you can say pure data that

597
00:28:59,880 --> 00:29:04,410
people didn't have access to and now we

598
00:29:01,980 --> 00:29:06,270
have privacy preserving technology that

599
00:29:04,410 --> 00:29:11,040
permits it that's another good way of

600
00:29:06,270 --> 00:29:14,129
having technology deployed now back in

601
00:29:11,040 --> 00:29:16,020
2003 long before anybody ever really

602
00:29:14,130 --> 00:29:18,330
started formalizing privacy for

603
00:29:16,020 --> 00:29:22,050
statistical data analysis DeNooyer and

604
00:29:18,330 --> 00:29:24,720
Nissim showed what we showed an amazing

605
00:29:22,050 --> 00:29:26,879
result that overly accurate estimates of

606
00:29:24,720 --> 00:29:28,290
too many statistics completely just

607
00:29:26,880 --> 00:29:32,220
destroys privacy

608
00:29:28,290 --> 00:29:34,620
there wasn't a what they said was here's

609
00:29:32,220 --> 00:29:36,780
this thing we call it now blatant anon

610
00:29:34,620 --> 00:29:39,330
privacy whatever you think privacy is

611
00:29:36,780 --> 00:29:41,970
this is obviously a violation of it and

612
00:29:39,330 --> 00:29:43,710
if you allow overly accurate estimates

613
00:29:41,970 --> 00:29:45,210
of too many statistics you're going to

614
00:29:43,710 --> 00:29:47,670
get this thing which is clearly a

615
00:29:45,210 --> 00:29:52,740
violation of privacy and that set off a

616
00:29:47,670 --> 00:29:55,860
suite of results that strengthen and

617
00:29:52,740 --> 00:30:00,330
generalize that so it says that there's

618
00:29:55,860 --> 00:30:02,219
a limit to what can be done now that and

619
00:30:00,330 --> 00:30:03,899
the definition of overly accurate will

620
00:30:02,220 --> 00:30:05,820
vary according to what is your

621
00:30:03,900 --> 00:30:07,260
definition of many you should have lots

622
00:30:05,820 --> 00:30:09,060
and lots and lots of Statistics they

623
00:30:07,260 --> 00:30:11,400
don't have to be that accurate you only

624
00:30:09,060 --> 00:30:12,050
have to if you only have a few then they

625
00:30:11,400 --> 00:30:17,210
would have to be

626
00:30:12,050 --> 00:30:18,919
accurate so when he became chief

627
00:30:17,210 --> 00:30:20,840
scientist and associate director of

628
00:30:18,920 --> 00:30:21,310
research and methodology at the Census

629
00:30:20,840 --> 00:30:25,129
Bureau

630
00:30:21,310 --> 00:30:28,820
John a bound labor economist started

631
00:30:25,130 --> 00:30:32,740
looking into this and said what he says

632
00:30:28,820 --> 00:30:35,870
is that the techniques that were used in

633
00:30:32,740 --> 00:30:39,170
the 2010 decennial census did not

634
00:30:35,870 --> 00:30:41,510
suffice so the United States has a short

635
00:30:39,170 --> 00:30:43,610
census every 10 years called the

636
00:30:41,510 --> 00:30:45,620
decennial census and then there's a much

637
00:30:43,610 --> 00:30:47,810
more detailed census called the American

638
00:30:45,620 --> 00:30:50,949
Community Survey but everybody has to

639
00:30:47,810 --> 00:30:53,360
answer the decennial and only a small

640
00:30:50,950 --> 00:31:00,040
percentage of the population is required

641
00:30:53,360 --> 00:31:00,040
to respond to the Community Survey okay

642
00:31:00,940 --> 00:31:06,530
so from a talk that he gave staring down

643
00:31:04,100 --> 00:31:09,260
the database reconstruction theorem he

644
00:31:06,530 --> 00:31:11,030
outlined how they actually launched the

645
00:31:09,260 --> 00:31:13,820
attacks that we had been talking about

646
00:31:11,030 --> 00:31:18,080
and did various things and linked with

647
00:31:13,820 --> 00:31:20,330
publicly available data he mapped out

648
00:31:18,080 --> 00:31:22,520
how often they were successful in reaiiy

649
00:31:20,330 --> 00:31:24,949
denta fication he pointed out that the

650
00:31:22,520 --> 00:31:27,050
harm that that that they they were able

651
00:31:24,950 --> 00:31:29,480
to identify was that the attacker could

652
00:31:27,050 --> 00:31:32,389
learn how people describe their race and

653
00:31:29,480 --> 00:31:33,830
their ethnicity the United States form

654
00:31:32,390 --> 00:31:36,490
has quite a bit about race and ethnicity

655
00:31:33,830 --> 00:31:39,800
on it even the short decennial form and

656
00:31:36,490 --> 00:31:42,710
if you do this on the American Community

657
00:31:39,800 --> 00:31:45,350
Survey you get much much more personal

658
00:31:42,710 --> 00:31:48,080
information as a matter of fact oh I'll

659
00:31:45,350 --> 00:31:50,209
tell you that a minute okay so then he

660
00:31:48,080 --> 00:31:52,010
gave you know statistics for exactly how

661
00:31:50,210 --> 00:31:54,740
many times they were able to correctly

662
00:31:52,010 --> 00:31:58,270
identify and he says well we fixed this

663
00:31:54,740 --> 00:32:02,810
by implementing differential privacy so

664
00:31:58,270 --> 00:32:06,020
this was really gratifying to us in part

665
00:32:02,810 --> 00:32:08,450
because the census was our driving

666
00:32:06,020 --> 00:32:13,389
scenario from the very beginning that

667
00:32:08,450 --> 00:32:17,060
was the picture that we had in mind okay

668
00:32:13,390 --> 00:32:20,450
now there are a lot of challenges still

669
00:32:17,060 --> 00:32:22,550
first of all census data is used for

670
00:32:20,450 --> 00:32:24,740
many many purposes

671
00:32:22,550 --> 00:32:27,260
torian's and sociologists demographers

672
00:32:24,740 --> 00:32:29,390
economists they're not trained to

673
00:32:27,260 --> 00:32:32,570
interact with data through any sort of

674
00:32:29,390 --> 00:32:34,970
officials mechanism were certainly not

675
00:32:32,570 --> 00:32:37,490
in a differentially private way we don't

676
00:32:34,970 --> 00:32:39,020
have vast libraries of tools for this

677
00:32:37,490 --> 00:32:41,720
sort of analysis and that sort of

678
00:32:39,020 --> 00:32:44,110
analysis there was a privacy budget I

679
00:32:41,720 --> 00:32:47,030
said that privacy loss accumulates

680
00:32:44,110 --> 00:32:49,250
somebody has to keep watch and make sure

681
00:32:47,030 --> 00:32:52,129
that privacy loss hasn't grown too large

682
00:32:49,250 --> 00:32:54,230
by the way the actual value for the

683
00:32:52,130 --> 00:32:56,450
privacy budget will be chosen by the

684
00:32:54,230 --> 00:33:01,670
Secretary of Commerce I don't know what

685
00:32:56,450 --> 00:33:04,160
they're going to choose so you have all

686
00:33:01,670 --> 00:33:07,100
of these people who work with the data

687
00:33:04,160 --> 00:33:09,590
who are not trained to use it in this

688
00:33:07,100 --> 00:33:12,740
new fashion and there aren't tools for

689
00:33:09,590 --> 00:33:14,959
them to just deploy and so on they're

690
00:33:12,740 --> 00:33:18,110
also used to seeing what are called puns

691
00:33:14,960 --> 00:33:20,690
or public use microdata which are sort

692
00:33:18,110 --> 00:33:23,139
of roughly speaking de-identified

693
00:33:20,690 --> 00:33:26,990
individual records of of real people

694
00:33:23,140 --> 00:33:28,970
with some small changes thrown in by a

695
00:33:26,990 --> 00:33:32,360
process called swapping where

696
00:33:28,970 --> 00:33:34,130
intuitively families that in various

697
00:33:32,360 --> 00:33:36,260
respects are similar in different

698
00:33:34,130 --> 00:33:39,500
regions of the country simply have their

699
00:33:36,260 --> 00:33:40,390
data swapped but the swap rate is not

700
00:33:39,500 --> 00:33:43,960
public

701
00:33:40,390 --> 00:33:48,910
now the decennial form is really meagre

702
00:33:43,960 --> 00:33:48,910
here's the whole form for one person and

703
00:33:49,870 --> 00:33:54,649
this is a description of the the the

704
00:33:52,790 --> 00:33:59,920
kinds of questions so most of the

705
00:33:54,650 --> 00:34:04,460
questions in it in contrast you say in

706
00:33:59,920 --> 00:34:06,890
the American Community Survey the

707
00:34:04,460 --> 00:34:08,960
questions are about housing ancestry

708
00:34:06,890 --> 00:34:11,060
about your journey to work and how you

709
00:34:08,960 --> 00:34:14,150
commute computer and Internet youth

710
00:34:11,060 --> 00:34:15,590
disability employment family and

711
00:34:14,150 --> 00:34:18,380
relationship to the householder

712
00:34:15,590 --> 00:34:20,360
fertility food stamp use grandparents as

713
00:34:18,380 --> 00:34:22,730
caregivers health insurance coverage

714
00:34:20,360 --> 00:34:25,520
Hispanic origin home heating fuel

715
00:34:22,730 --> 00:34:27,650
housing costs for owners industry

716
00:34:25,520 --> 00:34:30,710
occupation and class of worker marital

717
00:34:27,650 --> 00:34:33,290
status and history ownership home value

718
00:34:30,710 --> 00:34:35,000
in rent place in birth and citizenship

719
00:34:33,290 --> 00:34:38,449
and year of entry

720
00:34:35,000 --> 00:34:42,020
plumbing in kitchen and telephone

721
00:34:38,449 --> 00:34:44,598
services residents did you live in this

722
00:34:42,020 --> 00:34:47,810
house a year ago migration when did you

723
00:34:44,599 --> 00:34:50,690
move here school enrollment sex vehicles

724
00:34:47,810 --> 00:34:53,299
available veteran status and the year

725
00:34:50,690 --> 00:34:56,030
that the home was built so it's a huge

726
00:34:53,300 --> 00:35:00,050
trove of information and the techniques

727
00:34:56,030 --> 00:35:04,550
that exist right now don't can't cope

728
00:35:00,050 --> 00:35:07,099
with all of that now what can we do

729
00:35:04,550 --> 00:35:08,840
about it so one possibility might be to

730
00:35:07,099 --> 00:35:11,840
build differentially private synthetic

731
00:35:08,840 --> 00:35:14,869
data this is this wonderful image right

732
00:35:11,840 --> 00:35:17,540
where somehow or other you can look at

733
00:35:14,869 --> 00:35:21,020
the data set and you can make up

734
00:35:17,540 --> 00:35:23,090
synthetic data and publish this little

735
00:35:21,020 --> 00:35:24,740
synthetic data set and let people run

736
00:35:23,090 --> 00:35:26,330
the same kinds of queries they would

737
00:35:24,740 --> 00:35:28,060
have run against the big database but

738
00:35:26,330 --> 00:35:31,069
against this privacy preserving

739
00:35:28,060 --> 00:35:35,619
synthetic database is it doable

740
00:35:31,070 --> 00:35:37,130
is it possible astonishingly yes

741
00:35:35,619 --> 00:35:40,910
theoretically

742
00:35:37,130 --> 00:35:42,710
you can build a small database that is

743
00:35:40,910 --> 00:35:44,899
completely synthetic and you build it in

744
00:35:42,710 --> 00:35:46,849
a differentially private way and you can

745
00:35:44,900 --> 00:35:49,250
even handle exponentially many queries

746
00:35:46,849 --> 00:35:50,869
and this was a result of Blum Liggett &

747
00:35:49,250 --> 00:35:55,280
Roth which absolutely knocked my socks

748
00:35:50,869 --> 00:35:58,550
off in 2008 it was a an offline process

749
00:35:55,280 --> 00:36:04,849
and an online process was then developed

750
00:35:58,550 --> 00:36:07,940
by Hart and Laughlin but there are

751
00:36:04,849 --> 00:36:12,109
hardness results so your cryptographers

752
00:36:07,940 --> 00:36:14,810
suppose the database had records of this

753
00:36:12,109 --> 00:36:17,779
form it had a message a public

754
00:36:14,810 --> 00:36:20,660
verification key and a signature on that

755
00:36:17,780 --> 00:36:23,869
message using the corresponding signing

756
00:36:20,660 --> 00:36:26,598
King and you wanted to release a

757
00:36:23,869 --> 00:36:28,540
synthetic database where the queries

758
00:36:26,599 --> 00:36:31,040
would be verification keys and the

759
00:36:28,540 --> 00:36:33,650
questioner could say how many people in

760
00:36:31,040 --> 00:36:36,520
the database how many rows in the

761
00:36:33,650 --> 00:36:38,930
database are our valid signatures under

762
00:36:36,520 --> 00:36:43,220
that could be very key verified with the

763
00:36:38,930 --> 00:36:46,069
k-star how would you create a synthetic

764
00:36:43,220 --> 00:36:47,899
element that didn't exist in the

765
00:36:46,070 --> 00:36:50,740
database you would need

766
00:36:47,900 --> 00:36:53,450
to forge a signature in order to do it

767
00:36:50,740 --> 00:36:56,629
so you get a hardness result right off

768
00:36:53,450 --> 00:37:01,279
the bat and in fact there's a very tight

769
00:36:56,630 --> 00:37:04,029
connection to trader tracing you can

770
00:37:01,279 --> 00:37:06,650
play similar games now these are

771
00:37:04,029 --> 00:37:11,150
counting queries are very specific and

772
00:37:06,650 --> 00:37:13,220
and and contrived form so what about

773
00:37:11,150 --> 00:37:14,990
simple things like can you create

774
00:37:13,220 --> 00:37:18,410
synthetic data that will give you the

775
00:37:14,990 --> 00:37:19,578
answer for all two-way marginals and

776
00:37:18,410 --> 00:37:21,440
I'll say a little bit more about what

777
00:37:19,579 --> 00:37:26,569
marginals are in a later slide if you

778
00:37:21,440 --> 00:37:28,849
don't know already and you if the

779
00:37:26,569 --> 00:37:32,359
dimension of your data isn't too large

780
00:37:28,849 --> 00:37:34,490
you could answer all of the two-way

781
00:37:32,359 --> 00:37:38,328
marginals using the Gaussian mechanism

782
00:37:34,490 --> 00:37:42,919
or the Laplace mechanism but you can't

783
00:37:38,329 --> 00:37:45,380
make synthetic data that captures all of

784
00:37:42,920 --> 00:37:50,440
these two-way marginals assuming that

785
00:37:45,380 --> 00:37:53,240
one-way functions exist and in fact

786
00:37:50,440 --> 00:37:58,279
there are small families of queries

787
00:37:53,240 --> 00:38:01,098
where it's hard to create just the

788
00:37:58,279 --> 00:38:07,309
answers for these small sets of queries

789
00:38:01,099 --> 00:38:10,819
and this also draws on trader tracing so

790
00:38:07,309 --> 00:38:14,329
this leaves three directions for moving

791
00:38:10,819 --> 00:38:17,808
forward one of them is to look at

792
00:38:14,329 --> 00:38:21,799
structured query classes like threshold

793
00:38:17,809 --> 00:38:24,079
functions and marginals so the previous

794
00:38:21,799 --> 00:38:27,920
hardness results were for arbitrary

795
00:38:24,079 --> 00:38:35,450
families or contrived families what

796
00:38:27,920 --> 00:38:36,440
about very okay and and somehow we're

797
00:38:35,450 --> 00:38:38,000
going to have to go around the

798
00:38:36,440 --> 00:38:39,980
impossibilities result so these are not

799
00:38:38,000 --> 00:38:41,750
going to be necessarily synthetic data

800
00:38:39,980 --> 00:38:47,210
but just answers for structured query

801
00:38:41,750 --> 00:38:51,319
classes another is to try the you know

802
00:38:47,210 --> 00:38:53,809
AI method of punting so use differently

803
00:38:51,319 --> 00:38:56,690
differentially private ganz or

804
00:38:53,809 --> 00:38:58,729
generative adversarial networks to try

805
00:38:56,690 --> 00:39:00,959
to generate synthetic data

806
00:38:58,729 --> 00:39:03,058
well if you're going to generate

807
00:39:00,959 --> 00:39:05,430
synthetic data you have to say what it

808
00:39:03,059 --> 00:39:07,049
is you want these data to capture what

809
00:39:05,430 --> 00:39:09,089
are the statistical tests that you'll

810
00:39:07,049 --> 00:39:11,788
use for evaluating the quality of these

811
00:39:09,089 --> 00:39:14,009
synthetic data so you might say well I

812
00:39:11,789 --> 00:39:16,140
want to do I want to preserve some kind

813
00:39:14,009 --> 00:39:18,539
of low order interactions we know

814
00:39:16,140 --> 00:39:20,368
there's a hardness result here but in

815
00:39:18,539 --> 00:39:22,650
practice a lot of things can be done

816
00:39:20,369 --> 00:39:27,440
even when there are hardness results so

817
00:39:22,650 --> 00:39:29,670
we could say in the third is a fanciful

818
00:39:27,440 --> 00:39:32,400
problem which I will leave you with and

819
00:39:29,670 --> 00:39:37,589
at the very end of the talk this is

820
00:39:32,400 --> 00:39:41,940
Steve Feinberg who is died two years ago

821
00:39:37,589 --> 00:39:45,299
he was a real inspiration to me is a

822
00:39:41,940 --> 00:39:50,609
statistician who did a lot of work among

823
00:39:45,299 --> 00:39:52,949
many fields on on privacy and many of

824
00:39:50,609 --> 00:39:55,848
the forms of the questions that I asked

825
00:39:52,949 --> 00:39:59,359
came from conversations with Steve and

826
00:39:55,849 --> 00:40:03,059
he's pictured here with his wife Joyce

827
00:39:59,359 --> 00:40:05,098
who was murdered along with ten other

828
00:40:03,059 --> 00:40:12,839
people at the Tree of Life synagogue

829
00:40:05,099 --> 00:40:16,829
Massacre in Pittsburgh so differentially

830
00:40:12,839 --> 00:40:19,410
private marginals think about data with

831
00:40:16,829 --> 00:40:23,609
D different boolean attributes so you

832
00:40:19,410 --> 00:40:26,009
can describe each person by just a a D

833
00:40:23,609 --> 00:40:29,190
bit string and you can look at a

834
00:40:26,009 --> 00:40:30,959
histogram or a contingency table that

835
00:40:29,190 --> 00:40:32,699
has a cell for each of the two to the D

836
00:40:30,959 --> 00:40:36,359
settings of these D different attributes

837
00:40:32,699 --> 00:40:39,029
a marginal is just a sub table so in

838
00:40:36,359 --> 00:40:40,859
this picture I've got the marginal the

839
00:40:39,029 --> 00:40:42,989
blue table is the one where the

840
00:40:40,859 --> 00:40:45,058
attribute a has value zero and the red

841
00:40:42,989 --> 00:40:48,390
table is the one where attribute a has

842
00:40:45,059 --> 00:40:50,640
value one now each individual has

843
00:40:48,390 --> 00:40:53,848
exactly one setting of course of their D

844
00:40:50,640 --> 00:40:57,239
bits so they live in just one cell so

845
00:40:53,849 --> 00:41:01,319
the sensitivity of a contingency table

846
00:40:57,239 --> 00:41:04,079
query is just one my adding or deleting

847
00:41:01,319 --> 00:41:07,499
one person can only change one cell and

848
00:41:04,079 --> 00:41:09,819
that cell only by one so we could add

849
00:41:07,499 --> 00:41:11,558
noise scale to 1 over Epsilon

850
00:41:09,819 --> 00:41:13,719
each cell and then when somebody wants a

851
00:41:11,559 --> 00:41:16,749
marginal they just add up all of the

852
00:41:13,719 --> 00:41:18,339
noisy cells and that's that but if

853
00:41:16,749 --> 00:41:21,339
you're adding up an exponential number

854
00:41:18,339 --> 00:41:24,940
of cells even with cancellation in the

855
00:41:21,339 --> 00:41:28,599
in the in the errors we still have big

856
00:41:24,940 --> 00:41:30,509
errors that remain so the marginal

857
00:41:28,599 --> 00:41:33,069
problem is sort of how to deal with that

858
00:41:30,509 --> 00:41:35,619
so there are two general approaches in

859
00:41:33,069 --> 00:41:38,049
the literature one of them sort of

860
00:41:35,619 --> 00:41:40,779
separates the problem into two steps one

861
00:41:38,049 --> 00:41:43,209
step adds privacy and the other one is

862
00:41:40,779 --> 00:41:47,380
some kind of a hard computational step

863
00:41:43,209 --> 00:41:49,569
where people try to get consistency

864
00:41:47,380 --> 00:41:51,729
across the marginals or create synthetic

865
00:41:49,569 --> 00:41:53,890
data distributions or a synthetic data

866
00:41:51,729 --> 00:41:57,910
set and they throw some really

867
00:41:53,890 --> 00:42:00,578
well-established high-powered solvers at

868
00:41:57,910 --> 00:42:04,089
it so here are some examples of that and

869
00:42:00,579 --> 00:42:06,910
a different approach is just to release

870
00:42:04,089 --> 00:42:08,890
noisy values for these marginals without

871
00:42:06,910 --> 00:42:11,308
trying for consistency among them

872
00:42:08,890 --> 00:42:14,680
without trying to say well there's one

873
00:42:11,309 --> 00:42:16,359
table with integer valued people who are

874
00:42:14,680 --> 00:42:18,038
non-negative who give rise to this

875
00:42:16,359 --> 00:42:20,828
number at least collection of marginals

876
00:42:18,039 --> 00:42:23,469
and two approaches to that involve

877
00:42:20,829 --> 00:42:27,849
private approximation via low degree

878
00:42:23,469 --> 00:42:29,890
polynomials or a relaxation of that

879
00:42:27,849 --> 00:42:31,660
algorithm five so remember I mentioned

880
00:42:29,890 --> 00:42:33,879
algorithm five we added all this

881
00:42:31,660 --> 00:42:37,118
Gaussian noise when we projected down

882
00:42:33,880 --> 00:42:39,729
onto this body K and the projection was

883
00:42:37,119 --> 00:42:43,049
a hard step so the idea here is now

884
00:42:39,729 --> 00:42:47,558
we're going to relax that we're going to

885
00:42:43,049 --> 00:42:52,538
approximately project onto a convex body

886
00:42:47,559 --> 00:42:54,940
that contains K and is in some nice way

887
00:42:52,539 --> 00:42:57,789
just a little bit bigger so that the

888
00:42:54,940 --> 00:42:59,529
errors that you get aren't bad and this

889
00:42:57,789 --> 00:43:02,910
gives state-of-the-art results for

890
00:42:59,529 --> 00:43:05,709
two-way marginals in polynomial time

891
00:43:02,910 --> 00:43:10,859
this is a very interesting direction to

892
00:43:05,709 --> 00:43:15,419
experiment with and to keep pursuing

893
00:43:10,859 --> 00:43:15,420
about the gams I'll only say this

894
00:43:17,890 --> 00:43:23,990
so in Ganz we have a fake data generator

895
00:43:21,530 --> 00:43:27,440
that is trying to learn to generate data

896
00:43:23,990 --> 00:43:30,709
that look like the real data and we have

897
00:43:27,440 --> 00:43:32,359
a distinguisher who's trying to tell to

898
00:43:30,710 --> 00:43:34,790
distinguish the real data from the fake

899
00:43:32,359 --> 00:43:36,980
data and the results from the

900
00:43:34,790 --> 00:43:39,190
distinguisher are fed back into the fake

901
00:43:36,980 --> 00:43:45,800
data generator so that it knows how to

902
00:43:39,190 --> 00:43:48,680
try to improve what it's doing now the

903
00:43:45,800 --> 00:43:51,470
only box here that actually sees real

904
00:43:48,680 --> 00:43:53,390
data is the distinguisher so we can make

905
00:43:51,470 --> 00:43:56,379
the distinguisher differentially private

906
00:43:53,390 --> 00:43:58,460
so this is an approach that was

907
00:43:56,380 --> 00:44:02,000
suggested it's been suggested in a few

908
00:43:58,460 --> 00:44:07,880
places there's a nice work on bio

909
00:44:02,000 --> 00:44:12,109
archive that uses this for actually you

910
00:44:07,880 --> 00:44:14,000
see privacy-preserving generative deep

911
00:44:12,109 --> 00:44:16,759
neural networks support clinical data

912
00:44:14,000 --> 00:44:20,510
sharing yeah that's the name of the

913
00:44:16,760 --> 00:44:24,520
paper and Steven Wu is from sort of our

914
00:44:20,510 --> 00:44:27,020
community and so we are working on

915
00:44:24,520 --> 00:44:29,770
variants of this that for example might

916
00:44:27,020 --> 00:44:32,660
be good with respect to low order

917
00:44:29,770 --> 00:44:36,109
interactions among variables this is

918
00:44:32,660 --> 00:44:40,759
very preliminary work also done with

919
00:44:36,109 --> 00:44:43,730
Marcel known hoofer ok so I'm going to

920
00:44:40,760 --> 00:44:47,800
close with this problem the Feinberg

921
00:44:43,730 --> 00:44:52,580
problem because Feinberg used to sort of

922
00:44:47,800 --> 00:44:55,430
pound on on this problem yes how can we

923
00:44:52,580 --> 00:44:59,560
let a trusted researcher access raw data

924
00:44:55,430 --> 00:45:06,080
and then privately publish the results

925
00:44:59,560 --> 00:45:08,570
that is I trust Feinberg to do the right

926
00:45:06,080 --> 00:45:11,270
thing and to follow the instructions and

927
00:45:08,570 --> 00:45:13,280
follow the protocol and only make public

928
00:45:11,270 --> 00:45:17,630
the things that the protocol says can

929
00:45:13,280 --> 00:45:22,700
safely be made public so the question is

930
00:45:17,630 --> 00:45:28,010
how can we let him do this when what he

931
00:45:22,700 --> 00:45:29,560
chooses to make public now will depend

932
00:45:28,010 --> 00:45:32,680
in a very immediate way

933
00:45:29,560 --> 00:45:35,470
because he's looking at the raw data it

934
00:45:32,680 --> 00:45:38,350
will depend very strongly perhaps on a

935
00:45:35,470 --> 00:45:41,109
single individual in the data that's the

936
00:45:38,350 --> 00:45:43,360
worry his choice of what he decided was

937
00:45:41,110 --> 00:45:45,520
interesting might have been completely

938
00:45:43,360 --> 00:45:49,510
different had Warren Buffett not been

939
00:45:45,520 --> 00:45:55,750
included in the data set so what can we

940
00:45:49,510 --> 00:45:57,850
do well the first idea is we assume that

941
00:45:55,750 --> 00:46:01,690
Feinberg is very energetic and that we

942
00:45:57,850 --> 00:46:03,819
can rewind him and we apply a beautiful

943
00:46:01,690 --> 00:46:06,340
technique due to an assumed raskolnikov

944
00:46:03,820 --> 00:46:08,620
on Smith called sample and aggregate

945
00:46:06,340 --> 00:46:10,810
which says essentially how can you take

946
00:46:08,620 --> 00:46:14,529
a function that you absolutely don't

947
00:46:10,810 --> 00:46:16,600
understand and get some kind of a

948
00:46:14,530 --> 00:46:19,870
privacy-preserving approximation to this

949
00:46:16,600 --> 00:46:22,630
function so here was their idea they

950
00:46:19,870 --> 00:46:25,480
take the data we remember we're assuming

951
00:46:22,630 --> 00:46:27,220
that data are copious you take the data

952
00:46:25,480 --> 00:46:28,930
and we split it up into a bunch of

953
00:46:27,220 --> 00:46:35,410
slices in this picture I have four

954
00:46:28,930 --> 00:46:38,109
slices we feed a slice of the data to

955
00:46:35,410 --> 00:46:40,420
the function we do that B different

956
00:46:38,110 --> 00:46:42,880
times if I have V different slices so

957
00:46:40,420 --> 00:46:46,050
the function is operating independently

958
00:46:42,880 --> 00:46:48,460
on each slice let's say in parallel and

959
00:46:46,050 --> 00:46:50,440
then you take all of those answers and

960
00:46:48,460 --> 00:46:54,040
you aggregate them using a differential

961
00:46:50,440 --> 00:46:56,290
a private aggregator so why is this

962
00:46:54,040 --> 00:46:59,890
whole process differentially private

963
00:46:56,290 --> 00:47:01,779
well consider two databases that differ

964
00:46:59,890 --> 00:47:05,950
in the presence or absence of that red

965
00:47:01,780 --> 00:47:08,500
data point the difference affects only

966
00:47:05,950 --> 00:47:10,779
one of the copies of the function only

967
00:47:08,500 --> 00:47:12,820
the second copy of the function so

968
00:47:10,780 --> 00:47:15,700
that's just one of the inputs to the

969
00:47:12,820 --> 00:47:17,380
aggregator and since the aggregator is

970
00:47:15,700 --> 00:47:19,750
differentially private it behaves

971
00:47:17,380 --> 00:47:22,560
essentially the same way independent of

972
00:47:19,750 --> 00:47:26,110
any of the values of one of its inputs

973
00:47:22,560 --> 00:47:28,600
so in this fanciful version my function

974
00:47:26,110 --> 00:47:30,880
is Feinberg and if I could if you were

975
00:47:28,600 --> 00:47:37,560
energetic and I could rerun him this is

976
00:47:30,880 --> 00:47:37,560
something that I could do now

977
00:47:37,970 --> 00:47:47,129
can we relax this so ken feinberg

978
00:47:44,930 --> 00:47:48,450
incorporate some of his friends so here

979
00:47:47,130 --> 00:47:49,520
are some ideas for what the friends

980
00:47:48,450 --> 00:47:52,348
could do

981
00:47:49,520 --> 00:47:54,839
Feinberg does a computation he says I

982
00:47:52,349 --> 00:47:56,220
want to publish statistic T in fact I'd

983
00:47:54,839 --> 00:47:57,750
like to publish it now using

984
00:47:56,220 --> 00:48:01,649
differential privacy to release the

985
00:47:57,750 --> 00:48:04,470
statistic T what do you guys think so he

986
00:48:01,650 --> 00:48:06,780
sends T to all of the other participants

987
00:48:04,470 --> 00:48:12,299
Frank McSherry hoping you seem Adam

988
00:48:06,780 --> 00:48:14,069
Smith and and what do they do we're

989
00:48:12,300 --> 00:48:16,140
gonna hope that there's some

990
00:48:14,069 --> 00:48:17,880
verification procedure that they can run

991
00:48:16,140 --> 00:48:20,190
that's easier than running the Feinberg

992
00:48:17,880 --> 00:48:23,069
problem in the first place verification

993
00:48:20,190 --> 00:48:25,859
might be easier than generating T than

994
00:48:23,069 --> 00:48:28,319
finding tape so what they're gonna do is

995
00:48:25,859 --> 00:48:30,569
they're gonna say hey I'm gonna look at

996
00:48:28,319 --> 00:48:32,369
it on my own slice and if I like it from

997
00:48:30,569 --> 00:48:34,650
my own slice I'll vote 1 otherwise I'm

998
00:48:32,369 --> 00:48:36,359
gonna vote 0 and then we're gonna have

999
00:48:34,650 --> 00:48:38,099
some differentially private aggregator

1000
00:48:36,359 --> 00:48:44,700
for these which I don't have time to

1001
00:48:38,099 --> 00:48:47,369
describe so this is nice but there's a

1002
00:48:44,700 --> 00:48:50,549
problem with this and the problem is if

1003
00:48:47,369 --> 00:48:51,660
the friends are rubber stamps then we

1004
00:48:50,550 --> 00:48:55,319
haven't solved anything

1005
00:48:51,660 --> 00:48:57,750
so we conjecture that there are simple

1006
00:48:55,319 --> 00:49:02,099
picky verifiers for example verifiers

1007
00:48:57,750 --> 00:49:04,859
who would verify T for their own slice s

1008
00:49:02,099 --> 00:49:08,609
only a Feinberg when running on s would

1009
00:49:04,859 --> 00:49:11,640
have produced a T but as I said this is

1010
00:49:08,609 --> 00:49:13,230
a fanciful problem but I think it's also

1011
00:49:11,640 --> 00:49:16,470
an excellent problem for the crypto

1012
00:49:13,230 --> 00:49:17,710
community so with that I thank you for

1013
00:49:16,470 --> 00:49:18,709
your attention

1014
00:49:17,710 --> 00:49:22,650
[Applause]

1015
00:49:18,710 --> 00:49:26,010
[Music]

1016
00:49:22,650 --> 00:49:26,010
[Applause]

1017
00:49:26,580 --> 00:49:32,140
we do certainly have time for questions

1018
00:49:29,040 --> 00:49:38,680
please step up to the microphones there

1019
00:49:32,140 --> 00:49:39,879
or the middle of the audience is here so

1020
00:49:38,680 --> 00:49:43,000
let me open the round of questions they

1021
00:49:39,880 --> 00:49:46,000
will come you had on one slide

1022
00:49:43,000 --> 00:49:51,940
GDP generalized differential privacy and

1023
00:49:46,000 --> 00:49:55,380
in Europe we have GDP or I wanted to ask

1024
00:49:51,940 --> 00:49:57,730
to which extent are you aware that legal

1025
00:49:55,380 --> 00:50:00,250
documents frameworks are influenced by

1026
00:49:57,730 --> 00:50:03,339
the notion to what extent to my where

1027
00:50:00,250 --> 00:50:05,320
what the weeks extend I'll have legal

1028
00:50:03,339 --> 00:50:08,200
documents been influenced by this by the

1029
00:50:05,320 --> 00:50:13,530
technical notions is it's it's not only

1030
00:50:08,200 --> 00:50:17,740
in the lab the right notion the way okay

1031
00:50:13,530 --> 00:50:20,770
so by the way that GDP was Gaussian

1032
00:50:17,740 --> 00:50:22,390
differential privacy but um let me

1033
00:50:20,770 --> 00:50:26,170
answer a couple things along with that

1034
00:50:22,390 --> 00:50:28,210
so first of all I talked about the use

1035
00:50:26,170 --> 00:50:32,170
of differential privacy in industry I

1036
00:50:28,210 --> 00:50:36,720
talked about its use in the US Census

1037
00:50:32,170 --> 00:50:40,300
Bureau this is a very us centric set of

1038
00:50:36,720 --> 00:50:43,109
observations here what about Europe and

1039
00:50:40,300 --> 00:50:46,329
what about the UK so to my knowledge

1040
00:50:43,109 --> 00:50:48,759
there is I'm sorry

1041
00:50:46,329 --> 00:50:50,469
I didn't mean that I didn't mean it that

1042
00:50:48,759 --> 00:50:52,569
way I meant that there's been some

1043
00:50:50,469 --> 00:50:55,900
motion in the UK that I have not yet

1044
00:50:52,569 --> 00:50:58,329
seen in Europe in the rest of Europe and

1045
00:50:55,900 --> 00:51:01,539
I do hope that it stays together okay so

1046
00:50:58,329 --> 00:51:03,429
so so at least there's like real

1047
00:51:01,539 --> 00:51:09,160
awareness in the Office of National

1048
00:51:03,429 --> 00:51:11,890
Statistics in the GDP are there's been a

1049
00:51:09,160 --> 00:51:13,420
lot of resistance I mean the reporter

1050
00:51:11,890 --> 00:51:16,629
wanted to put some things about

1051
00:51:13,420 --> 00:51:23,279
differential privacy in a few years ago

1052
00:51:16,630 --> 00:51:26,140
and it was voted out in I I don't know

1053
00:51:23,279 --> 00:51:29,349
what's happening with legislation and

1054
00:51:26,140 --> 00:51:32,558
regulation here there is interest in

1055
00:51:29,349 --> 00:51:35,140
differential privacy in Germany so for

1056
00:51:32,559 --> 00:51:39,309
example from crota who among her many

1057
00:51:35,140 --> 00:51:42,999
positions as a professor at mine spent

1058
00:51:39,309 --> 00:51:45,219
the semester at the Symons Institute

1059
00:51:42,999 --> 00:51:48,459
just now on the special semester on

1060
00:51:45,219 --> 00:51:52,209
differential privacy and I mentioned one

1061
00:51:48,459 --> 00:52:01,899
of her students Marcel and mine Hoffer

1062
00:51:52,209 --> 00:52:04,390
earlier so regulation is much slower yes

1063
00:52:01,900 --> 00:52:09,309
so about the question of synthetic

1064
00:52:04,390 --> 00:52:11,920
synthetic data so you said that problems

1065
00:52:09,309 --> 00:52:13,660
but I wonder if there are and there are

1066
00:52:11,920 --> 00:52:17,380
actually even with a normal database

1067
00:52:13,660 --> 00:52:19,828
like we of people off isn't there a

1068
00:52:17,380 --> 00:52:22,660
problem like the synthetic data would

1069
00:52:19,829 --> 00:52:24,579
like would have less information than

1070
00:52:22,660 --> 00:52:28,089
the real data so it was still like a

1071
00:52:24,579 --> 00:52:30,539
limitation even in that database so you

1072
00:52:28,089 --> 00:52:34,239
bring up the next an excellent point

1073
00:52:30,539 --> 00:52:38,410
so you're absolutely right and and I

1074
00:52:34,239 --> 00:52:39,670
should have mentioned this so we've been

1075
00:52:38,410 --> 00:52:42,910
looking at this for a couple of years

1076
00:52:39,670 --> 00:52:45,759
and and I was talking to a medical

1077
00:52:42,910 --> 00:52:49,239
researcher on the phone and and and he

1078
00:52:45,759 --> 00:52:51,160
said can't you just give me a synthetic

1079
00:52:49,239 --> 00:52:52,779
table that would let me look up the

1080
00:52:51,160 --> 00:52:54,670
answers to any of the questions I want

1081
00:52:52,779 --> 00:52:56,589
so synthetic data would do that but a

1082
00:52:54,670 --> 00:52:58,250
big table that wasn't a special form

1083
00:52:56,589 --> 00:53:00,740
would also let him do that

1084
00:52:58,250 --> 00:53:03,380
and the answer is of course not because

1085
00:53:00,740 --> 00:53:05,270
if I did then you could launch the

1086
00:53:03,380 --> 00:53:07,340
attack that corresponds to the

1087
00:53:05,270 --> 00:53:10,160
fundamental law of information recovery

1088
00:53:07,340 --> 00:53:14,060
against that table if it would allow you

1089
00:53:10,160 --> 00:53:16,640
to get to to obtain relatively accurate

1090
00:53:14,060 --> 00:53:19,360
answers to essentially all questions

1091
00:53:16,640 --> 00:53:22,009
that you might want to ask then you'd be

1092
00:53:19,360 --> 00:53:24,860
violation of the the fundamental law of

1093
00:53:22,010 --> 00:53:28,010
information recovery yes and so when we

1094
00:53:24,860 --> 00:53:29,900
talk about synthetic data we have to say

1095
00:53:28,010 --> 00:53:31,700
what are the statistical tests what are

1096
00:53:29,900 --> 00:53:33,350
the things that we want these synthetic

1097
00:53:31,700 --> 00:53:35,270
data to capture and it will definitely

1098
00:53:33,350 --> 00:53:37,790
be less and that's why we talk about

1099
00:53:35,270 --> 00:53:42,800
things like low order marginals or some

1100
00:53:37,790 --> 00:53:44,240
small variable interactions and also you

1101
00:53:42,800 --> 00:53:46,280
mentioned the two differential privacy

1102
00:53:44,240 --> 00:53:48,649
is really nice because it's programmable

1103
00:53:46,280 --> 00:53:50,750
so I wondered like how would that happen

1104
00:53:48,650 --> 00:53:52,130
do do we really have the libraries and

1105
00:53:50,750 --> 00:53:54,140
everything that allow us to do that like

1106
00:53:52,130 --> 00:53:56,390
in practice if I have a data base in

1107
00:53:54,140 --> 00:54:03,890
what sense okay now I start saying I

1108
00:53:56,390 --> 00:54:06,859
want to program into it right so there

1109
00:54:03,890 --> 00:54:10,629
are I also said that there aren't really

1110
00:54:06,860 --> 00:54:13,730
big like ready for industrial scale

1111
00:54:10,630 --> 00:54:15,650
libraries nonetheless there are many

1112
00:54:13,730 --> 00:54:18,650
places in which people are starting to

1113
00:54:15,650 --> 00:54:22,160
try to build these libraries quite

1114
00:54:18,650 --> 00:54:24,800
prominently among them in the privacy

1115
00:54:22,160 --> 00:54:27,220
tools for social science research data

1116
00:54:24,800 --> 00:54:30,680
project that Silva done has at Harvard

1117
00:54:27,220 --> 00:54:33,009
so people and if you search around on

1118
00:54:30,680 --> 00:54:37,160
the web you'll find other libraries and

1119
00:54:33,010 --> 00:54:39,850
I think that various industry players

1120
00:54:37,160 --> 00:54:44,859
are sort of starting to get there but

1121
00:54:39,850 --> 00:54:44,860
there's a lot of work to be done yeah

1122
00:54:46,570 --> 00:54:51,770
any other questions

1123
00:54:49,150 --> 00:54:54,040
if not then I would like I really like

1124
00:54:51,770 --> 00:54:54,640
to thank you again very much

1125
00:54:54,040 --> 00:54:59,500
[Applause]

1126
00:54:54,640 --> 00:55:02,980
[Music]

1127
00:54:59,500 --> 00:55:02,980
[Applause]

