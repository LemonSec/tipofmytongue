1
00:00:00,060 --> 00:00:04,409
hi everyone so today I'm going to talk

2
00:00:02,580 --> 00:00:07,770
about incremental proofs of sequential

3
00:00:04,410 --> 00:00:09,300
work and it was very convenient that

4
00:00:07,770 --> 00:00:10,889
there was a talk before me so I don't

5
00:00:09,300 --> 00:00:15,120
have to go through the same things again

6
00:00:10,889 --> 00:00:16,740
but this is again book of talk about

7
00:00:15,120 --> 00:00:18,270
through the sequential work so just let

8
00:00:16,740 --> 00:00:22,709
me give you a brief introduction about

9
00:00:18,270 --> 00:00:24,720
the primitive so the idea is that the

10
00:00:22,710 --> 00:00:27,300
prove receives an input a statement then

11
00:00:24,720 --> 00:00:30,000
it does some work the work takes

12
00:00:27,300 --> 00:00:32,790
approximately time and and then the

13
00:00:30,000 --> 00:00:37,320
prover is able to find and to compute a

14
00:00:32,790 --> 00:00:40,019
small proof which we call pi such that

15
00:00:37,320 --> 00:00:42,390
verifier given the statement X and the

16
00:00:40,020 --> 00:00:44,280
proof pi is able to say it yes or no in

17
00:00:42,390 --> 00:00:46,860
the sense that you accept or reject the

18
00:00:44,280 --> 00:00:48,750
proof and this is a very very natural

19
00:00:46,860 --> 00:00:51,719
primitive to have and if there are many

20
00:00:48,750 --> 00:00:53,519
applications and beyond you know like

21
00:00:51,719 --> 00:00:56,010
the classical block chains with this

22
00:00:53,520 --> 00:00:58,440
this can be used right off the box for

23
00:00:56,010 --> 00:01:00,809
doing things like CPU benchmarking or

24
00:00:58,440 --> 00:01:02,280
you know time stamping of a document and

25
00:01:00,809 --> 00:01:05,069
in general is a nice little primitive

26
00:01:02,280 --> 00:01:09,540
that that that we I think we all agree

27
00:01:05,069 --> 00:01:12,179
this deserves to be studied so let me

28
00:01:09,540 --> 00:01:13,770
let me be slightly more formal and this

29
00:01:12,180 --> 00:01:17,729
is going to be the last formal slide of

30
00:01:13,770 --> 00:01:19,949
the talk so get out of the way and so

31
00:01:17,729 --> 00:01:20,939
what we want from from the proof of

32
00:01:19,950 --> 00:01:22,680
sequential work is of course

33
00:01:20,939 --> 00:01:25,860
completeness complete this means that

34
00:01:22,680 --> 00:01:27,540
Han has proved correctly verify is X I

35
00:01:25,860 --> 00:01:30,780
need to check fine

36
00:01:27,540 --> 00:01:35,310
we want son as son as intuitively means

37
00:01:30,780 --> 00:01:38,280
that I cannot Forge proof in time much

38
00:01:35,310 --> 00:01:41,130
less than N and note that it is

39
00:01:38,280 --> 00:01:43,829
important here that that the son is this

40
00:01:41,130 --> 00:01:45,509
parameterize by a certain constant this

41
00:01:43,829 --> 00:01:46,889
constant doesn't have to be universe and

42
00:01:45,509 --> 00:01:50,610
in the sense that it's a concept might

43
00:01:46,890 --> 00:01:53,070
show up for example the proof size but

44
00:01:50,610 --> 00:01:55,799
the sequentiality of the prover is

45
00:01:53,070 --> 00:01:57,779
required to be at least one minus

46
00:01:55,799 --> 00:01:59,939
constants times n so in the sense there

47
00:01:57,780 --> 00:02:01,740
is some some some slack is not a perfect

48
00:01:59,939 --> 00:02:03,539
proof you are allowed to make some some

49
00:02:01,740 --> 00:02:04,860
shortcuts is not a version that's not as

50
00:02:03,540 --> 00:02:07,459
long as you are not taking too many of

51
00:02:04,860 --> 00:02:10,590
those then then we're okay with it and

52
00:02:07,459 --> 00:02:12,960
if you are too short then then we want

53
00:02:10,590 --> 00:02:14,670
this we want verify

54
00:02:12,960 --> 00:02:16,890
rejects your true with all but

55
00:02:14,670 --> 00:02:19,380
negligible probability and throughout

56
00:02:16,890 --> 00:02:22,950
the next the next talk by time I mean

57
00:02:19,380 --> 00:02:25,320
random Oracle queries and number of

58
00:02:22,950 --> 00:02:27,000
random are it's easy to show that the in

59
00:02:25,320 --> 00:02:30,269
Wrentham Oracle model repeated queries

60
00:02:27,000 --> 00:02:31,950
are inherently sequential right so but

61
00:02:30,270 --> 00:02:34,650
you can substitute time with random

62
00:02:31,950 --> 00:02:36,780
Oracle queries and we have some

63
00:02:34,650 --> 00:02:39,690
efficiency requirement which make the

64
00:02:36,780 --> 00:02:42,560
the primitive non trivial and the

65
00:02:39,690 --> 00:02:45,000
primitive as to as to have short proof

66
00:02:42,560 --> 00:02:47,310
and fast verification in the sense that

67
00:02:45,000 --> 00:02:51,000
you need don't want to go through the

68
00:02:47,310 --> 00:02:53,760
whole computation again and we want

69
00:02:51,000 --> 00:02:55,440
additionally to be non interactive by

70
00:02:53,760 --> 00:02:57,810
non interactive I mean that there is

71
00:02:55,440 --> 00:03:00,230
just a single proof that gas exchange

72
00:02:57,810 --> 00:03:02,880
from the prover to the verifier and

73
00:03:00,230 --> 00:03:05,489
publicly verifiable which was exactly

74
00:03:02,880 --> 00:03:09,510
the point that the years before some I'm

75
00:03:05,490 --> 00:03:11,040
glad that I actually yeah

76
00:03:09,510 --> 00:03:12,560
so it's publicly verifiable everyone

77
00:03:11,040 --> 00:03:15,510
should be able to verify the proof and

78
00:03:12,560 --> 00:03:17,040
well it is a bonus feature which is due

79
00:03:15,510 --> 00:03:20,880
to the fact that our construction

80
00:03:17,040 --> 00:03:24,630
achieves it and that the fact that you

81
00:03:20,880 --> 00:03:27,000
can extend queries for four parameters

82
00:03:24,630 --> 00:03:29,519
greater than than the fixed end without

83
00:03:27,000 --> 00:03:32,370
of course starting over and this is you

84
00:03:29,520 --> 00:03:36,330
know for example this is this feature is

85
00:03:32,370 --> 00:03:38,550
useful for for the time stamping when

86
00:03:36,330 --> 00:03:41,220
you know the your computer your hardware

87
00:03:38,550 --> 00:03:42,840
is a is prone to to some failure and you

88
00:03:41,220 --> 00:03:45,780
don't want to start over every time your

89
00:03:42,840 --> 00:03:47,820
machine shuts down right so you compute

90
00:03:45,780 --> 00:03:50,670
the proof up to a certain point you can

91
00:03:47,820 --> 00:03:56,370
for Q it's it's an interesting feature

92
00:03:50,670 --> 00:03:58,049
and it's good to have it okay so now

93
00:03:56,370 --> 00:04:00,600
this these slides require a bit of

94
00:03:58,050 --> 00:04:03,150
imagination in the sense that I didn't

95
00:04:00,600 --> 00:04:05,280
put any constant here you substitute

96
00:04:03,150 --> 00:04:08,100
with your favorite constant and I didn't

97
00:04:05,280 --> 00:04:12,240
put all the related work here because of

98
00:04:08,100 --> 00:04:15,049
space issues and but like RSW is all

99
00:04:12,240 --> 00:04:17,160
captured by a buddies so that they said

100
00:04:15,049 --> 00:04:19,470
let me let me quickly summarize the

101
00:04:17,160 --> 00:04:21,930
feature of of what's known so the first

102
00:04:19,470 --> 00:04:24,900
two are construction of proof of

103
00:04:21,930 --> 00:04:26,010
sequential work the first was from a

104
00:04:24,900 --> 00:04:29,909
moody tile which we

105
00:04:26,010 --> 00:04:31,830
and the second one is from Coen Peter

106
00:04:29,910 --> 00:04:35,520
Chuck and I don't want to slaughter

107
00:04:31,830 --> 00:04:37,830
anybody's surname so CP okay so the

108
00:04:35,520 --> 00:04:39,599
first the first construction was was the

109
00:04:37,830 --> 00:04:41,039
motivating example motivating work of

110
00:04:39,600 --> 00:04:45,870
this of this line of work

111
00:04:41,040 --> 00:04:47,880
and it achieves essentially logarithmic

112
00:04:45,870 --> 00:04:48,660
proof size and very fire complexity

113
00:04:47,880 --> 00:04:52,620
which is nice

114
00:04:48,660 --> 00:04:54,540
but it had a proven memory complexity

115
00:04:52,620 --> 00:04:57,300
proportional to M F if you think the N

116
00:04:54,540 --> 00:04:59,880
is something around two to the forty

117
00:04:57,300 --> 00:05:01,950
this is like typical parameters of n it

118
00:04:59,880 --> 00:05:04,409
requires really a lot of memories so and

119
00:05:01,950 --> 00:05:09,630
this is why this is were the the kind

120
00:05:04,410 --> 00:05:11,760
Peters CP construction improved a lot

121
00:05:09,630 --> 00:05:13,380
and they they had this very elegant idea

122
00:05:11,760 --> 00:05:16,680
to use this nice graph that we showed we

123
00:05:13,380 --> 00:05:18,810
saw in the talk before and they they

124
00:05:16,680 --> 00:05:20,520
managed to bring down the proving the

125
00:05:18,810 --> 00:05:21,380
prover of memory complexity all the way

126
00:05:20,520 --> 00:05:24,240
to login

127
00:05:21,380 --> 00:05:26,580
however this came at a slight cost in

128
00:05:24,240 --> 00:05:29,250
the sense that the provable computation

129
00:05:26,580 --> 00:05:30,750
is now 2n as opposed to N and we'll see

130
00:05:29,250 --> 00:05:33,000
in a minute where does it where does

131
00:05:30,750 --> 00:05:36,180
this come from and let me mention that

132
00:05:33,000 --> 00:05:38,130
that they also they also outline a the

133
00:05:36,180 --> 00:05:40,470
also have a have a trade-off where they

134
00:05:38,130 --> 00:05:44,550
managed to trade a little bit of frugal

135
00:05:40,470 --> 00:05:47,190
computation for for for decreasing the

136
00:05:44,550 --> 00:05:49,470
the proven memory this in practice is

137
00:05:47,190 --> 00:05:51,150
very good but you know there is this

138
00:05:49,470 --> 00:05:54,090
motivates the question whether we can

139
00:05:51,150 --> 00:05:56,190
get you know the best of both words okay

140
00:05:54,090 --> 00:05:58,409
let me mention all these both this

141
00:05:56,190 --> 00:06:02,850
construction they are based only on or

142
00:05:58,410 --> 00:06:05,060
random Oracle's and and there is no no

143
00:06:02,850 --> 00:06:07,740
no additional assumption they're both

144
00:06:05,060 --> 00:06:10,520
both very very simple and very easy to

145
00:06:07,740 --> 00:06:15,060
implement and practically efficient

146
00:06:10,520 --> 00:06:17,460
right so now it comes to the rest of the

147
00:06:15,060 --> 00:06:21,210
machinery of course as we discussed

148
00:06:17,460 --> 00:06:23,849
before a verifiable delay function is a

149
00:06:21,210 --> 00:06:27,359
proof of sequential work it is a

150
00:06:23,850 --> 00:06:30,570
stronger primitive and as such it

151
00:06:27,360 --> 00:06:33,540
requires at least we it's conjecture

152
00:06:30,570 --> 00:06:35,700
they require stronger assumption we we

153
00:06:33,540 --> 00:06:38,040
known we know new constructions very

154
00:06:35,700 --> 00:06:39,740
recent construction in their presented a

155
00:06:38,040 --> 00:06:43,310
discount

156
00:06:39,740 --> 00:06:46,820
that take the RSW para para dragon and

157
00:06:43,310 --> 00:06:48,290
use the sequentiality of squaring over

158
00:06:46,820 --> 00:06:51,200
it the nor the group plus random

159
00:06:48,290 --> 00:06:53,840
Oracle's but they they essentially

160
00:06:51,200 --> 00:06:56,630
achieve the best of both of all words

161
00:06:53,840 --> 00:07:00,650
they are incremental and they get best

162
00:06:56,630 --> 00:07:02,330
parameter asymptotically and well then

163
00:07:00,650 --> 00:07:04,450
of course if we go one level one level

164
00:07:02,330 --> 00:07:06,800
above in the hierarchy then we get

165
00:07:04,450 --> 00:07:09,860
incremented verifiable computation which

166
00:07:06,800 --> 00:07:11,810
is a verifiable delay function and again

167
00:07:09,860 --> 00:07:13,970
of course proof of sequential work and

168
00:07:11,810 --> 00:07:18,080
what is this is a really really involved

169
00:07:13,970 --> 00:07:19,370
machinery this is built on recursive

170
00:07:18,080 --> 00:07:21,500
compositions of snags

171
00:07:19,370 --> 00:07:23,600
so as far as I'm aware the only two

172
00:07:21,500 --> 00:07:26,480
construction one uses a random Oracle in

173
00:07:23,600 --> 00:07:29,480
non blackbox way so it's an clear what

174
00:07:26,480 --> 00:07:33,070
it means and the other one uses pairings

175
00:07:29,480 --> 00:07:37,220
but but but but it's a trusted set up so

176
00:07:33,070 --> 00:07:39,080
then this brings me to our result we are

177
00:07:37,220 --> 00:07:41,090
interested in the first setting so in

178
00:07:39,080 --> 00:07:44,930
the simple proof of sequential works

179
00:07:41,090 --> 00:07:47,530
based on random Oracle's only and we

180
00:07:44,930 --> 00:07:50,600
want to have passed parameters possible

181
00:07:47,530 --> 00:07:52,960
meaning poly logarithmic prover

182
00:07:50,600 --> 00:07:58,400
complexity in terms of memory n' and

183
00:07:52,960 --> 00:08:01,159
linear with constant one prover called

184
00:07:58,400 --> 00:08:04,669
proved a computation and we propose two

185
00:08:01,160 --> 00:08:09,190
constructions the first achieves is

186
00:08:04,670 --> 00:08:12,650
asymptotically optimal but as an extra

187
00:08:09,190 --> 00:08:16,430
square factor in the in the approval

188
00:08:12,650 --> 00:08:17,870
memory but it's iran's on a single

189
00:08:16,430 --> 00:08:21,310
processor

190
00:08:17,870 --> 00:08:26,420
whereas our second construction and it

191
00:08:21,310 --> 00:08:28,970
it removes this this square from there

192
00:08:26,420 --> 00:08:30,920
from the proven memory but it requires

193
00:08:28,970 --> 00:08:32,810
some parallelism from the prove earth

194
00:08:30,920 --> 00:08:35,870
and we can bound the ferrell the number

195
00:08:32,809 --> 00:08:38,059
of parallel processors to log n which is

196
00:08:35,870 --> 00:08:39,469
which is i think is a reasonable isn't

197
00:08:38,059 --> 00:08:42,500
it reasonable assumption i will talk

198
00:08:39,469 --> 00:08:45,290
more about that later and bonus feature

199
00:08:42,500 --> 00:08:47,360
both both constructions are incremental

200
00:08:45,290 --> 00:08:49,459
both construction are practically

201
00:08:47,360 --> 00:08:50,100
efficient and they're based on a random

202
00:08:49,460 --> 00:08:54,400
walk

203
00:08:50,100 --> 00:08:56,800
okay so this is the one slide about the

204
00:08:54,400 --> 00:08:59,439
CP construction that I want to do they

205
00:08:56,800 --> 00:09:00,939
want to give us a glimpse so this is the

206
00:08:59,440 --> 00:09:03,520
graph that we saw in the previous talk

207
00:09:00,940 --> 00:09:05,200
and as you can see you can you can think

208
00:09:03,520 --> 00:09:07,840
of this as a miracle tree with some

209
00:09:05,200 --> 00:09:10,330
extra G's for example this one and this

210
00:09:07,840 --> 00:09:12,370
one and I highlighted in red the

211
00:09:10,330 --> 00:09:15,270
traversal order so this is the order in

212
00:09:12,370 --> 00:09:19,890
which the prover computes the node so

213
00:09:15,270 --> 00:09:22,210
very very executive summary about this

214
00:09:19,890 --> 00:09:25,240
how does this other disprove the

215
00:09:22,210 --> 00:09:28,180
sequential work work the prover computes

216
00:09:25,240 --> 00:09:31,240
starts computing this graph goes through

217
00:09:28,180 --> 00:09:33,250
the all computation then once it gets to

218
00:09:31,240 --> 00:09:35,890
the root it applies the fish a new

219
00:09:33,250 --> 00:09:39,970
transformation and gets a set s of

220
00:09:35,890 --> 00:09:43,689
challenge leaves right now for all these

221
00:09:39,970 --> 00:09:46,240
leaves as he returns the the miracle

222
00:09:43,690 --> 00:09:48,460
commitment so let's say that this is one

223
00:09:46,240 --> 00:09:50,500
of these leaf is here and he has to

224
00:09:48,460 --> 00:09:53,350
return the path plus all the siblings

225
00:09:50,500 --> 00:09:55,990
and given all this information then the

226
00:09:53,350 --> 00:09:58,060
verifier can verify indeed that that

227
00:09:55,990 --> 00:10:00,490
this is correctly correctly formed and

228
00:09:58,060 --> 00:10:04,660
that the hash are indeed computed

229
00:10:00,490 --> 00:10:07,270
correctly and and this is repeated in

230
00:10:04,660 --> 00:10:11,290
parallel to boost soundness but this is

231
00:10:07,270 --> 00:10:13,000
not no really important all right you

232
00:10:11,290 --> 00:10:15,579
can tell you all the how the labels are

233
00:10:13,000 --> 00:10:17,470
computed well essentially if you take a

234
00:10:15,580 --> 00:10:20,800
note the label of the node consists of

235
00:10:17,470 --> 00:10:24,070
the hash of all the faulted labels of

236
00:10:20,800 --> 00:10:27,490
the node with an incoming edge okay so

237
00:10:24,070 --> 00:10:29,440
this is this is it and what's the

238
00:10:27,490 --> 00:10:32,620
problem where does the where does the

239
00:10:29,440 --> 00:10:35,410
the computational slack come from well

240
00:10:32,620 --> 00:10:37,570
the problem comes from the fact that you

241
00:10:35,410 --> 00:10:40,120
don't know the set F of challenged leaf

242
00:10:37,570 --> 00:10:42,130
until you get to the root and the root

243
00:10:40,120 --> 00:10:44,860
is actually the last step of the

244
00:10:42,130 --> 00:10:47,470
computation right so you have no idea

245
00:10:44,860 --> 00:10:49,570
which which leaves you should keep in

246
00:10:47,470 --> 00:10:51,220
memory until you get at the end of the

247
00:10:49,570 --> 00:10:54,700
computation and that's already n steps

248
00:10:51,220 --> 00:10:56,530
so how do you how do you solve this well

249
00:10:54,700 --> 00:10:58,960
there are there are several solution but

250
00:10:56,530 --> 00:11:02,560
the naive way in a sense is you know you

251
00:10:58,960 --> 00:11:03,470
just compute everything and either you

252
00:11:02,560 --> 00:11:06,050
keep the

253
00:11:03,470 --> 00:11:07,910
Graff in the memory that it's not good

254
00:11:06,050 --> 00:11:11,270
because that goes back to having a

255
00:11:07,910 --> 00:11:13,400
really large memory or you recompute in

256
00:11:11,270 --> 00:11:14,870
the worst case the whole graph and again

257
00:11:13,400 --> 00:11:17,930
let me stress that there is a there is a

258
00:11:14,870 --> 00:11:20,390
trade-off which is which brings this

259
00:11:17,930 --> 00:11:25,839
memory and the hover to square root of M

260
00:11:20,390 --> 00:11:28,189
but question is can we do better okay

261
00:11:25,840 --> 00:11:31,420
and this is this is this is where our

262
00:11:28,190 --> 00:11:34,040
work these are the idea of our work so

263
00:11:31,420 --> 00:11:36,319
just before you turn at this is trivial

264
00:11:34,040 --> 00:11:38,719
I'm just presenting the idea in plain

265
00:11:36,320 --> 00:11:40,460
text and for the the math I refer you to

266
00:11:38,720 --> 00:11:43,550
the paper I just want to give you a very

267
00:11:40,460 --> 00:11:45,440
very high level idea of our of our of

268
00:11:43,550 --> 00:11:48,199
our construction so the idea the basic

269
00:11:45,440 --> 00:11:51,170
idea is actually very simple instead of

270
00:11:48,200 --> 00:11:54,320
waiting until the root to sample the

271
00:11:51,170 --> 00:11:56,449
leaf we start accumulating and pruning

272
00:11:54,320 --> 00:11:58,910
leaves throughout the computation of the

273
00:11:56,450 --> 00:12:03,800
graph so this is what happens for

274
00:11:58,910 --> 00:12:08,839
example at node V let's say that let our

275
00:12:03,800 --> 00:12:12,370
our lambda is actually the in this slide

276
00:12:08,840 --> 00:12:16,910
is the set of challenges so the the the

277
00:12:12,370 --> 00:12:18,950
cardinality of the set and you can think

278
00:12:16,910 --> 00:12:22,760
of this as the hardness parameter of the

279
00:12:18,950 --> 00:12:24,890
of the scheme so now at this point for

280
00:12:22,760 --> 00:12:26,870
the node L we have exactly three paths

281
00:12:24,890 --> 00:12:29,689
and for the node R we have exactly three

282
00:12:26,870 --> 00:12:32,420
paths so everything is fine and once we

283
00:12:29,690 --> 00:12:35,090
get to know V then the idea is to apply

284
00:12:32,420 --> 00:12:37,640
Fiat samir to to the node V and this

285
00:12:35,090 --> 00:12:40,100
will index a subset of size tree of all

286
00:12:37,640 --> 00:12:43,100
this out all this path so what we do is

287
00:12:40,100 --> 00:12:46,970
simply we drop the path which do not

288
00:12:43,100 --> 00:12:49,880
belong to this subset and of course for

289
00:12:46,970 --> 00:12:51,770
for for reasonable values of lambda for

290
00:12:49,880 --> 00:12:54,020
high def node so at the very beginning

291
00:12:51,770 --> 00:12:56,180
of the computation will just keep all

292
00:12:54,020 --> 00:12:58,850
the leaves right and the more we get

293
00:12:56,180 --> 00:13:02,109
higher up to the tree well the more we

294
00:12:58,850 --> 00:13:06,590
start pruning and forgetting about about

295
00:13:02,110 --> 00:13:08,120
about path that that we do not need and

296
00:13:06,590 --> 00:13:09,950
note that as soon as the past is

297
00:13:08,120 --> 00:13:12,880
forgotten we don't need it anymore

298
00:13:09,950 --> 00:13:15,480
because what we do is just pruning

299
00:13:12,880 --> 00:13:19,200
gradually as we go up to 2 to the

300
00:13:15,480 --> 00:13:21,690
and the the conceptual difference is

301
00:13:19,200 --> 00:13:23,640
that instead of performing fishmeal at

302
00:13:21,690 --> 00:13:27,000
the very end of the computation we do it

303
00:13:23,640 --> 00:13:31,380
at each node so except for the for the

304
00:13:27,000 --> 00:13:33,510
for a very high bad note okay so let me

305
00:13:31,380 --> 00:13:36,689
give you let me give you a quick glimpse

306
00:13:33,510 --> 00:13:39,120
of the algorithm and this again is it's

307
00:13:36,690 --> 00:13:41,010
very simplified version but this is the

308
00:13:39,120 --> 00:13:42,300
backbone of the of the ideas from I

309
00:13:41,010 --> 00:13:45,540
think from here you can all reckon

310
00:13:42,300 --> 00:13:48,569
struct so the prover starts the

311
00:13:45,540 --> 00:13:52,620
computation of the same graph of CP log

312
00:13:48,570 --> 00:13:54,840
N and if we define SR and I cell to be

313
00:13:52,620 --> 00:13:57,900
the challenge set for each node V so

314
00:13:54,840 --> 00:14:01,770
first we check whether whether they

315
00:13:57,900 --> 00:14:04,709
exceed the parameter lambda and as such

316
00:14:01,770 --> 00:14:08,910
we apply a Shamir so using a random

317
00:14:04,710 --> 00:14:11,340
Oracle to the node V and we take s we

318
00:14:08,910 --> 00:14:16,339
define s to be a random lambda sized

319
00:14:11,340 --> 00:14:20,040
subset of s ru concatenated with itself

320
00:14:16,340 --> 00:14:23,900
otherwise if they are not not large

321
00:14:20,040 --> 00:14:27,660
enough we just keep s to be the Union

322
00:14:23,900 --> 00:14:30,480
the verifier is identical as GP the only

323
00:14:27,660 --> 00:14:34,370
difference is that additionally to check

324
00:14:30,480 --> 00:14:36,870
the correct labeling of the graph and to

325
00:14:34,370 --> 00:14:39,390
to check that the response is actually

326
00:14:36,870 --> 00:14:42,570
well-formed the verifier is also to

327
00:14:39,390 --> 00:14:45,540
check whether we prune the correct

328
00:14:42,570 --> 00:14:48,420
branches right we need we need to check

329
00:14:45,540 --> 00:14:51,480
that the the subset is correctly chosen

330
00:14:48,420 --> 00:14:55,020
and this can be done by simply computing

331
00:14:51,480 --> 00:14:59,850
the hash of the node and parsing this

332
00:14:55,020 --> 00:15:02,760
appropriately as a subset now it's very

333
00:14:59,850 --> 00:15:06,630
easy to see that we have at most log n

334
00:15:02,760 --> 00:15:09,720
log n nodes in the memory and we have at

335
00:15:06,630 --> 00:15:11,250
most lambda times log n loop root to

336
00:15:09,720 --> 00:15:14,160
leaf pass in the memory so the space

337
00:15:11,250 --> 00:15:17,760
complexity of this of this construction

338
00:15:14,160 --> 00:15:21,449
is roughly lambda log log n square and

339
00:15:17,760 --> 00:15:23,580
this is actually not where the word the

340
00:15:21,450 --> 00:15:26,040
source of inefficiency come from I'll

341
00:15:23,580 --> 00:15:27,480
tell you in a minute oh and let me let

342
00:15:26,040 --> 00:15:29,180
me let me highlight that this scheme is

343
00:15:27,480 --> 00:15:31,070
not really incremental in the

344
00:15:29,180 --> 00:15:33,500
that there is absolutely nothing special

345
00:15:31,070 --> 00:15:35,660
about the root the root node you could

346
00:15:33,500 --> 00:15:38,060
just keep going right there is this

347
00:15:35,660 --> 00:15:40,459
there is no reason to stop at at the

348
00:15:38,060 --> 00:15:41,810
root just the path already there in

349
00:15:40,460 --> 00:15:45,560
memory and you can just keep going and

350
00:15:41,810 --> 00:15:47,270
and and even even after the computation

351
00:15:45,560 --> 00:15:50,569
so that the increment incremental

352
00:15:47,270 --> 00:15:53,000
feature comes essentially for free so

353
00:15:50,570 --> 00:15:54,770
now the the catch is that the the

354
00:15:53,000 --> 00:15:56,840
analysis gets a bit more involved

355
00:15:54,770 --> 00:15:58,760
because now the proof can sheet

356
00:15:56,840 --> 00:16:00,680
adaptively so what what the prover can

357
00:15:58,760 --> 00:16:04,520
do is that it can start some computation

358
00:16:00,680 --> 00:16:07,430
see if some favorable some favorable

359
00:16:04,520 --> 00:16:09,410
subset of nodes is chosen then go back

360
00:16:07,430 --> 00:16:13,400
and change change labels introduce

361
00:16:09,410 --> 00:16:16,010
mistake and this this this messes up a

362
00:16:13,400 --> 00:16:19,459
lot and that's why we need to throw a

363
00:16:16,010 --> 00:16:22,910
lot of tail bounds to into our analysis

364
00:16:19,460 --> 00:16:25,960
and but this increases this is increases

365
00:16:22,910 --> 00:16:28,490
significantly the challenge set lambda

366
00:16:25,960 --> 00:16:31,070
so we need in order to account for this

367
00:16:28,490 --> 00:16:33,860
adaptivity we essentially need to check

368
00:16:31,070 --> 00:16:36,680
many more paths this is the moral behind

369
00:16:33,860 --> 00:16:38,210
it still fine in the sense that is still

370
00:16:36,680 --> 00:16:41,689
poor logarithmic but there is a square

371
00:16:38,210 --> 00:16:45,680
factor when you compare to CP 18 so our

372
00:16:41,690 --> 00:16:49,910
next idea is this based on an extremely

373
00:16:45,680 --> 00:16:52,729
simple observation so take any any

374
00:16:49,910 --> 00:16:56,000
balance Merkel tree right once the left

375
00:16:52,730 --> 00:16:58,130
tree once the left subtree is computed

376
00:16:56,000 --> 00:16:59,840
well then it will take exactly the same

377
00:16:58,130 --> 00:17:02,360
amount of time to compute the right

378
00:16:59,840 --> 00:17:04,700
subtree so that means that for this left

379
00:17:02,360 --> 00:17:08,540
subtree we actually have enough time to

380
00:17:04,700 --> 00:17:10,040
run the CP 18 strategy and recompute

381
00:17:08,540 --> 00:17:10,399
even the left subtree this doesn't

382
00:17:10,040 --> 00:17:12,940
matter

383
00:17:10,400 --> 00:17:16,610
we just spawn a parallel processor and

384
00:17:12,940 --> 00:17:19,220
and this and as long as we have enough

385
00:17:16,609 --> 00:17:21,079
parallelism this this doesn't really

386
00:17:19,220 --> 00:17:23,810
affect the running time because the

387
00:17:21,079 --> 00:17:26,629
moment I need those paths I will be done

388
00:17:23,810 --> 00:17:28,730
with the computation and so the idea is

389
00:17:26,630 --> 00:17:30,410
very simple use essentially a hybrid

390
00:17:28,730 --> 00:17:33,260
approach between what what I just

391
00:17:30,410 --> 00:17:36,140
described and the idea of CP 18 and I

392
00:17:33,260 --> 00:17:39,710
hope that this image helped you

393
00:17:36,140 --> 00:17:41,240
understanding what's going on and so

394
00:17:39,710 --> 00:17:42,770
essentially this is the left subtree

395
00:17:41,240 --> 00:17:44,810
that I was talking about so

396
00:17:42,770 --> 00:17:46,790
what happens is that my prover starts

397
00:17:44,810 --> 00:17:50,840
with a computation it gets up to this

398
00:17:46,790 --> 00:17:52,639
point and at this point there is one the

399
00:17:50,840 --> 00:17:54,620
main thread continued the computation of

400
00:17:52,640 --> 00:17:57,290
this subtree whereas this phones as

401
00:17:54,620 --> 00:17:59,090
parallel thread that goes and recompute

402
00:17:57,290 --> 00:18:01,220
the challenge path so in for this

403
00:17:59,090 --> 00:18:02,480
subtree the female is just applied at

404
00:18:01,220 --> 00:18:04,670
this node we don't need to bother

405
00:18:02,480 --> 00:18:09,410
applying it doing our own the fine

406
00:18:04,670 --> 00:18:13,550
sampling strategy and the point is that

407
00:18:09,410 --> 00:18:16,370
we will merge the two subsets at this

408
00:18:13,550 --> 00:18:18,919
point but and we will need the the paths

409
00:18:16,370 --> 00:18:21,620
that come out of this out of this sub

410
00:18:18,920 --> 00:18:23,900
tree but we will need them only when

411
00:18:21,620 --> 00:18:26,030
this node is also computed and it will

412
00:18:23,900 --> 00:18:29,390
take exactly the same time because it's

413
00:18:26,030 --> 00:18:31,310
a balance tree okay and it's very easy

414
00:18:29,390 --> 00:18:34,100
to see that that you can there is a very

415
00:18:31,310 --> 00:18:36,530
easy proof such that it allows you to

416
00:18:34,100 --> 00:18:40,189
bound the number of parallel process or

417
00:18:36,530 --> 00:18:42,830
used at all time to login and just I

418
00:18:40,190 --> 00:18:45,830
mean there are the logon is a really

419
00:18:42,830 --> 00:18:47,149
reasonable if you think into account

420
00:18:45,830 --> 00:18:50,389
that there are two to the eighty atoms

421
00:18:47,150 --> 00:18:52,250
in the universe that take log an equal

422
00:18:50,390 --> 00:18:55,610
80 you have 80 processors

423
00:18:52,250 --> 00:18:59,120
fine there exist machine with a process

424
00:18:55,610 --> 00:19:01,280
and the point is that what was the point

425
00:18:59,120 --> 00:19:03,260
of this mess the point is that now we do

426
00:19:01,280 --> 00:19:04,460
not have to throw so many tail bounds

427
00:19:03,260 --> 00:19:07,780
because we have no other activity

428
00:19:04,460 --> 00:19:09,890
already in this full subtree right and

429
00:19:07,780 --> 00:19:12,020
you can already see where we have to

430
00:19:09,890 --> 00:19:14,810
throw a tail bound it's here here here

431
00:19:12,020 --> 00:19:16,639
and so on that's very little with

432
00:19:14,810 --> 00:19:19,520
respect when compared to the all three

433
00:19:16,640 --> 00:19:21,730
and now our our our our parameter get

434
00:19:19,520 --> 00:19:25,190
much better and we get proved of size

435
00:19:21,730 --> 00:19:28,400
approximately a factor of 9 greater than

436
00:19:25,190 --> 00:19:30,400
CP 18 which is you know if you think if

437
00:19:28,400 --> 00:19:33,650
you think that this gives you

438
00:19:30,400 --> 00:19:37,340
essentially optimal prover complexity

439
00:19:33,650 --> 00:19:39,620
and and the increment ality feature

440
00:19:37,340 --> 00:19:41,230
almost for free and seems to be a

441
00:19:39,620 --> 00:19:45,229
reasonable price to pay

442
00:19:41,230 --> 00:19:48,590
ok so let me just give you give you a

443
00:19:45,230 --> 00:19:50,930
bit of conclusion like I like to then

444
00:19:48,590 --> 00:19:52,340
conclude with some open problems so what

445
00:19:50,930 --> 00:19:54,380
we showed in this talk is the proof of

446
00:19:52,340 --> 00:19:55,620
sequential work which is asymptotically

447
00:19:54,380 --> 00:19:57,840
optimal with

448
00:19:55,620 --> 00:19:59,729
the prover efficiency it comes from

449
00:19:57,840 --> 00:20:01,889
simple and well understood assumption

450
00:19:59,730 --> 00:20:05,100
and it is completely fishing than and

451
00:20:01,890 --> 00:20:08,190
simple to implement and I think it's

452
00:20:05,100 --> 00:20:09,570
nice it's a nice idea and I'm sure I'm

453
00:20:08,190 --> 00:20:13,200
sure that this idea will find other

454
00:20:09,570 --> 00:20:15,450
applications so then open problems is

455
00:20:13,200 --> 00:20:17,159
are of course can we can we get unique

456
00:20:15,450 --> 00:20:19,529
crew will unique proof of course you can

457
00:20:17,159 --> 00:20:23,580
using verifiable delay function may be

458
00:20:19,529 --> 00:20:25,230
something simple it's good question well

459
00:20:23,580 --> 00:20:27,029
avoid random Oracle's this is also

460
00:20:25,230 --> 00:20:30,360
always an interesting and interesting

461
00:20:27,029 --> 00:20:33,240
question and find other application of

462
00:20:30,360 --> 00:20:34,469
this on the fly sampling technique you

463
00:20:33,240 --> 00:20:38,159
can you can imagine you can think of

464
00:20:34,470 --> 00:20:40,230
this as some sort of random probing over

465
00:20:38,159 --> 00:20:42,690
some data stream whenever you cannot go

466
00:20:40,230 --> 00:20:46,710
back to the data and you need to sample

467
00:20:42,690 --> 00:20:48,480
some probe in some verifiable way if you

468
00:20:46,710 --> 00:20:49,860
if you if you have some idea how to use

469
00:20:48,480 --> 00:20:53,520
this technique please come talk to me

470
00:20:49,860 --> 00:20:56,449
and very interested okay this is it

471
00:20:53,520 --> 00:20:56,450
thank you for your attention

472
00:21:00,990 --> 00:21:12,820
are there any questions so when you mix

473
00:21:10,570 --> 00:21:14,230
your technique with CPA tea and I wonder

474
00:21:12,820 --> 00:21:17,860
if you lose something in terms of

475
00:21:14,230 --> 00:21:19,000
incrementality because so I don't know

476
00:21:17,860 --> 00:21:21,279
sir I completely understood how you

477
00:21:19,000 --> 00:21:23,049
achieve it but actually if CP 18 is not

478
00:21:21,279 --> 00:21:25,779
incremental then and some part of your

479
00:21:23,049 --> 00:21:28,270
proof is using CPA tin then no so the

480
00:21:25,779 --> 00:21:31,059
point yeah that's a very good question

481
00:21:28,270 --> 00:21:34,779
so the point is that imagine imagine

482
00:21:31,059 --> 00:21:36,520
that we are at this point right yet the

483
00:21:34,779 --> 00:21:39,130
proof the fruit will not be increment

484
00:21:36,520 --> 00:21:41,350
the CP 18 is not incremental but the

485
00:21:39,130 --> 00:21:43,539
point is that if we if we keep going on

486
00:21:41,350 --> 00:21:45,370
up on this way then we have enough time

487
00:21:43,539 --> 00:21:49,059
to recompute the old path and to do the

488
00:21:45,370 --> 00:21:52,059
the trivial incrementation so that the

489
00:21:49,059 --> 00:21:54,610
end proved in the end is incremented and

490
00:21:52,059 --> 00:21:57,100
so is there a reason why you just always

491
00:21:54,610 --> 00:22:00,039
go to the left too like this you have

492
00:21:57,100 --> 00:22:02,260
this particular structure of the this

493
00:22:00,039 --> 00:22:03,700
comes why we start from the left and not

494
00:22:02,260 --> 00:22:06,640
the right or what I don't know like

495
00:22:03,700 --> 00:22:08,710
alternating or something and now this is

496
00:22:06,640 --> 00:22:12,340
because of the of the structure of CP

497
00:22:08,710 --> 00:22:15,309
FCP 18 it has to go on this specific

498
00:22:12,340 --> 00:22:17,830
order right so that's why and this

499
00:22:15,309 --> 00:22:21,250
parameter lambda what who chooses it and

500
00:22:17,830 --> 00:22:24,039
is it no it is fixed it's it's the

501
00:22:21,250 --> 00:22:25,360
hardness of decision so I mean a lamb

502
00:22:24,039 --> 00:22:31,779
that was just for the sake of the talk

503
00:22:25,360 --> 00:22:36,370
we have a more fine grain any other

504
00:22:31,779 --> 00:22:37,960
questions so I had a question so in this

505
00:22:36,370 --> 00:22:41,289
construction you're essentially basing

506
00:22:37,960 --> 00:22:44,470
it on CP 18 yeah there's the the tree

507
00:22:41,289 --> 00:22:46,120
which is basically a power of two so can

508
00:22:44,470 --> 00:22:48,429
you have number of iterations the amount

509
00:22:46,120 --> 00:22:52,469
of work that it's not a power of two I

510
00:22:48,429 --> 00:22:56,200
mean you can by the way yes you it works

511
00:22:52,470 --> 00:22:57,960
you have just a log log a lot faster by

512
00:22:56,200 --> 00:23:02,159
just taking the power of two essentially

513
00:22:57,960 --> 00:23:02,159
yeah not very satisfactory

514
00:23:03,970 --> 00:23:06,980
if there are no other questions and

515
00:23:05,259 --> 00:23:13,220
let's thing to speak again

516
00:23:06,980 --> 00:23:13,220
[Applause]

