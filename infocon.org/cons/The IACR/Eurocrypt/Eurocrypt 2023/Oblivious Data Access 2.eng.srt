1
00:00:00,000 --> 00:00:01,439
yeah

2
00:00:01,439 --> 00:00:03,300
okay

3
00:00:03,300 --> 00:00:06,660
welcome to the last session for today

4
00:00:06,660 --> 00:00:09,000
so the session is on oblivious data

5
00:00:09,000 --> 00:00:10,139
access

6
00:00:10,139 --> 00:00:13,860
and the first talk is a lower Bound for

7
00:00:13,860 --> 00:00:15,900
free a lower bound framework for

8
00:00:15,900 --> 00:00:17,460
differentially private and oblivious

9
00:00:17,460 --> 00:00:19,920
data structures by pinot perciano and

10
00:00:19,920 --> 00:00:22,140
Kevin yevo and Kevin is giving the talk

11
00:00:22,140 --> 00:00:23,640
all right thank you for the introduction

12
00:00:23,640 --> 00:00:26,160
so I'll be talking today about our new

13
00:00:26,160 --> 00:00:27,420
work on Lower bound framework for

14
00:00:27,420 --> 00:00:28,500
differentially private and oblivious

15
00:00:28,500 --> 00:00:30,060
data structures this is a drone work

16
00:00:30,060 --> 00:00:32,399
with my co-authorpino preciano

17
00:00:32,399 --> 00:00:34,559
all right so let's get started I'll tell

18
00:00:34,559 --> 00:00:35,940
you guys about three things today in

19
00:00:35,940 --> 00:00:37,260
this talk first I'll Define what an

20
00:00:37,260 --> 00:00:38,340
oblivious and differentially private

21
00:00:38,340 --> 00:00:39,899
data structure is I'll explain to you

22
00:00:39,899 --> 00:00:41,520
our lower Bound in the last couple of

23
00:00:41,520 --> 00:00:43,079
minutes I'll give you a taste of our the

24
00:00:43,079 --> 00:00:44,340
new techniques behind our lower bound

25
00:00:44,340 --> 00:00:45,719
framework

26
00:00:45,719 --> 00:00:47,760
all right so what is an oblivious or

27
00:00:47,760 --> 00:00:49,739
differentially private data structure

28
00:00:49,739 --> 00:00:51,539
to sort of explain I'm going to use the

29
00:00:51,539 --> 00:00:53,219
very famous or classic primitive of

30
00:00:53,219 --> 00:00:55,800
oblivious Ram so here you have a user

31
00:00:55,800 --> 00:00:57,420
device or client on the right and a

32
00:00:57,420 --> 00:00:58,860
server on the left

33
00:00:58,860 --> 00:01:01,440
in an oblivious Ram typically the user

34
00:01:01,440 --> 00:01:03,359
device typically has some private key

35
00:01:03,359 --> 00:01:05,519
and outsources an encryption of an array

36
00:01:05,519 --> 00:01:07,619
to the server when I say encryption I'm

37
00:01:07,619 --> 00:01:09,060
using encryption Loosely it's not only

38
00:01:09,060 --> 00:01:10,320
an encryption usually it's a hidden

39
00:01:10,320 --> 00:01:12,240
permutation and maybe duplication so on

40
00:01:12,240 --> 00:01:13,979
and so forth but for intensive purposes

41
00:01:13,979 --> 00:01:15,479
let's just look at let's look at it like

42
00:01:15,479 --> 00:01:16,560
this

43
00:01:16,560 --> 00:01:18,240
and what is an oblivious Ram let you do

44
00:01:18,240 --> 00:01:20,040
well essentially let you do an operation

45
00:01:20,040 --> 00:01:22,200
such as read the first entry

46
00:01:22,200 --> 00:01:23,640
and what in the belief stream will do is

47
00:01:23,640 --> 00:01:25,320
take this read operation

48
00:01:25,320 --> 00:01:27,060
compile into a sequence of more

49
00:01:27,060 --> 00:01:29,520
complicated obfuscated accesses and

50
00:01:29,520 --> 00:01:30,960
essentially let you get the first entry

51
00:01:30,960 --> 00:01:32,400
so this is the earth index so maybe

52
00:01:32,400 --> 00:01:35,220
three is the first entry

53
00:01:35,220 --> 00:01:36,960
um an oblivious Ram one thing that I

54
00:01:36,960 --> 00:01:38,220
want to note is very clear is that after

55
00:01:38,220 --> 00:01:40,560
each operation it sort of lets you

56
00:01:40,560 --> 00:01:42,240
change the private key so for example

57
00:01:42,240 --> 00:01:44,040
the device may change its private key

58
00:01:44,040 --> 00:01:46,320
and simultaneously the server it'll work

59
00:01:46,320 --> 00:01:47,820
with the server to change the encryption

60
00:01:47,820 --> 00:01:49,619
or re-encrypt various parts of the

61
00:01:49,619 --> 00:01:51,060
encrypted array and when I say

62
00:01:51,060 --> 00:01:52,020
encryption again it's not only

63
00:01:52,020 --> 00:01:53,040
re-encryption it can also be

64
00:01:53,040 --> 00:01:55,799
permutations and so forth

65
00:01:55,799 --> 00:01:57,960
finally obliviousreams also allow you to

66
00:01:57,960 --> 00:02:00,659
overwrite entries in the array

67
00:02:00,659 --> 00:02:02,939
all right so sort of to Define what what

68
00:02:02,939 --> 00:02:05,040
oblivious Ram offers in terms of privacy

69
00:02:05,040 --> 00:02:07,020
or security what he really wants you to

70
00:02:07,020 --> 00:02:07,979
do is like I've written the definition

71
00:02:07,979 --> 00:02:10,440
here but for any two sequences of equal

72
00:02:10,440 --> 00:02:12,180
length operations that could be done by

73
00:02:12,180 --> 00:02:15,000
the client the adversaries view which is

74
00:02:15,000 --> 00:02:16,379
created by the oblivious data structure

75
00:02:16,379 --> 00:02:18,120
should be indistinguishable to a

76
00:02:18,120 --> 00:02:19,860
computational adversary

77
00:02:19,860 --> 00:02:21,180
in short what this really means

78
00:02:21,180 --> 00:02:22,620
essentially is hide the sequence of

79
00:02:22,620 --> 00:02:23,700
operations that are performed by the

80
00:02:23,700 --> 00:02:24,900
client

81
00:02:24,900 --> 00:02:26,700
and when I see adversaries view I want

82
00:02:26,700 --> 00:02:28,140
to make it clear what it exactly means

83
00:02:28,140 --> 00:02:30,900
so here's the adversaries view in red it

84
00:02:30,900 --> 00:02:32,400
contains everything that the server sees

85
00:02:32,400 --> 00:02:34,860
that it stores in its memory and it also

86
00:02:34,860 --> 00:02:36,180
sees all the communication between the

87
00:02:36,180 --> 00:02:38,280
client and the server what the adversary

88
00:02:38,280 --> 00:02:39,959
clearly does not see is the private key

89
00:02:39,959 --> 00:02:43,080
or anything in the client storage

90
00:02:43,080 --> 00:02:45,000
all right so that's let's say an

91
00:02:45,000 --> 00:02:47,580
oblivious ramp you can also consider a

92
00:02:47,580 --> 00:02:49,140
weaker version of oblivious Ram that we

93
00:02:49,140 --> 00:02:51,180
call differentially Private Rams so in

94
00:02:51,180 --> 00:02:52,680
an oblivious realm like I said earlier

95
00:02:52,680 --> 00:02:54,360
we're really trying to protect every

96
00:02:54,360 --> 00:02:57,000
operation so really the two sequences

97
00:02:57,000 --> 00:02:58,739
that it could be inputted could be could

98
00:02:58,739 --> 00:03:00,300
differ in every location so here's an

99
00:03:00,300 --> 00:03:01,379
example that can differ in every

100
00:03:01,379 --> 00:03:02,519
location

101
00:03:02,519 --> 00:03:03,959
this might be too strong so you can

102
00:03:03,959 --> 00:03:05,040
consider something like a differentially

103
00:03:05,040 --> 00:03:07,260
private ram which is slightly weaker in

104
00:03:07,260 --> 00:03:08,819
a sense rather than protecting the

105
00:03:08,819 --> 00:03:10,500
entire sequence we want to only protect

106
00:03:10,500 --> 00:03:12,300
sequences that are very similar so here

107
00:03:12,300 --> 00:03:13,739
we can Define it for example as

108
00:03:13,739 --> 00:03:15,480
neighboring sequences that differ in

109
00:03:15,480 --> 00:03:17,519
only one operation

110
00:03:17,519 --> 00:03:19,980
so again using this definition you can

111
00:03:19,980 --> 00:03:21,840
go ahead and redefine everything from

112
00:03:21,840 --> 00:03:23,159
the belief stream using differential

113
00:03:23,159 --> 00:03:24,360
privacy you can get something called a

114
00:03:24,360 --> 00:03:25,860
differentially private ram

115
00:03:25,860 --> 00:03:27,599
the same thing sort of holds now for any

116
00:03:27,599 --> 00:03:29,280
sequence of equal length operations are

117
00:03:29,280 --> 00:03:31,379
different one at most one operation you

118
00:03:31,379 --> 00:03:33,420
want the adversaries view to satisfy

119
00:03:33,420 --> 00:03:34,980
this Epsilon Delta differential privacy

120
00:03:34,980 --> 00:03:37,319
guarantees so this formula here for

121
00:03:37,319 --> 00:03:38,700
those who've never seen this before it's

122
00:03:38,700 --> 00:03:40,560
just used for composability it's it's

123
00:03:40,560 --> 00:03:43,319
not something too complicated

124
00:03:43,319 --> 00:03:45,120
all right so

125
00:03:45,120 --> 00:03:47,519
I've described this in terms of rams or

126
00:03:47,519 --> 00:03:48,840
what I like to call them which is really

127
00:03:48,840 --> 00:03:50,640
just arrays but you could generalize

128
00:03:50,640 --> 00:03:52,379
these Notions for other data structure

129
00:03:52,379 --> 00:03:54,360
problems so for example you can consider

130
00:03:54,360 --> 00:03:56,159
sets which you know just check whether

131
00:03:56,159 --> 00:03:58,080
an entry exists or not you can also

132
00:03:58,080 --> 00:03:59,400
think consider things like predecessor

133
00:03:59,400 --> 00:04:01,500
successor as well as disjoint sets

134
00:04:01,500 --> 00:04:04,940
that's also known as Union find

135
00:04:04,980 --> 00:04:07,920
all right so when we consider these

136
00:04:07,920 --> 00:04:09,000
oblivious and differentially private

137
00:04:09,000 --> 00:04:10,680
data structures there are two key

138
00:04:10,680 --> 00:04:12,480
parameters that we like to consider one

139
00:04:12,480 --> 00:04:15,239
is W which represents the size or bits

140
00:04:15,239 --> 00:04:16,738
of each memory word or cell in the

141
00:04:16,738 --> 00:04:17,940
system so you can think of this for

142
00:04:17,940 --> 00:04:19,380
example as maybe a cache line in real

143
00:04:19,380 --> 00:04:20,399
life

144
00:04:20,399 --> 00:04:22,380
the other parameter we like to consider

145
00:04:22,380 --> 00:04:24,180
is B which is the size of the query

146
00:04:24,180 --> 00:04:26,460
outputs and this typically depends on

147
00:04:26,460 --> 00:04:28,620
the problem so for example for Rams and

148
00:04:28,620 --> 00:04:30,479
arrays B will be equal to the array

149
00:04:30,479 --> 00:04:31,680
entry size

150
00:04:31,680 --> 00:04:33,600
in sets obviously the output is a single

151
00:04:33,600 --> 00:04:35,820
bit of zero one so b equals one you

152
00:04:35,820 --> 00:04:36,900
could do the same thing for predecessor

153
00:04:36,900 --> 00:04:38,100
successor where you're returning an

154
00:04:38,100 --> 00:04:40,020
element from a universe U or disjoint

155
00:04:40,020 --> 00:04:41,520
sets when you're returning an identifier

156
00:04:41,520 --> 00:04:44,759
for a set which is log n Bits

157
00:04:44,759 --> 00:04:46,500
all right so

158
00:04:46,500 --> 00:04:47,520
all right so we're going to be proving

159
00:04:47,520 --> 00:04:49,020
lower amounts so I'm going to describe

160
00:04:49,020 --> 00:04:50,580
to you what the cell pro model is first

161
00:04:50,580 --> 00:04:51,780
so this is the model throughout the

162
00:04:51,780 --> 00:04:52,919
entire paper that I'm improving lower

163
00:04:52,919 --> 00:04:55,199
bounds and this was introduced by I

164
00:04:55,199 --> 00:04:58,139
think Andy Yao in the 90s or even 80s

165
00:04:58,139 --> 00:05:00,300
so what is the cell pro model you know

166
00:05:00,300 --> 00:05:02,100
it's a very simplistic model essentially

167
00:05:02,100 --> 00:05:03,240
what you do is you take the server's

168
00:05:03,240 --> 00:05:04,979
memory and you break it up to W bit

169
00:05:04,979 --> 00:05:07,860
chunks each of these are words or cells

170
00:05:07,860 --> 00:05:09,960
and really in this model the only time

171
00:05:09,960 --> 00:05:12,180
we ever charge you any unit cost is when

172
00:05:12,180 --> 00:05:13,800
you're probing so what probing really

173
00:05:13,800 --> 00:05:15,600
means is reading or writing from one of

174
00:05:15,600 --> 00:05:17,460
the server cells of w bits

175
00:05:17,460 --> 00:05:19,440
so essentially whenever the client would

176
00:05:19,440 --> 00:05:21,660
instruct the server to read or or locate

177
00:05:21,660 --> 00:05:23,520
or write to an entry in the cell this

178
00:05:23,520 --> 00:05:25,860
would cost you you know charge one

179
00:05:25,860 --> 00:05:28,560
charge you unit one in this model

180
00:05:28,560 --> 00:05:30,660
but critically everything else is free

181
00:05:30,660 --> 00:05:32,280
so you know you could do computation for

182
00:05:32,280 --> 00:05:33,660
free you can solve your favorite and be

183
00:05:33,660 --> 00:05:35,460
complete problem for free generating

184
00:05:35,460 --> 00:05:37,500
store Randomness access the client

185
00:05:37,500 --> 00:05:40,500
storage everything's free and uh so the

186
00:05:40,500 --> 00:05:42,180
good news about this is that a very weak

187
00:05:42,180 --> 00:05:44,100
cost model implies very very strong

188
00:05:44,100 --> 00:05:46,080
lower balance so our lower bound should

189
00:05:46,080 --> 00:05:47,340
apply to any reasonable model

190
00:05:47,340 --> 00:05:48,780
computation where these things would

191
00:05:48,780 --> 00:05:52,159
actually be charged some cost

192
00:05:52,199 --> 00:05:54,539
all right so I guess I'm going to go

193
00:05:54,539 --> 00:05:55,620
through a little bit of the prior Works

194
00:05:55,620 --> 00:05:56,940
to show you what kind of lower bounds

195
00:05:56,940 --> 00:05:58,080
are known for oblivious and

196
00:05:58,080 --> 00:05:59,880
differentially private ramps so the

197
00:05:59,880 --> 00:06:01,500
seminal work by Larson and Nielsen in

198
00:06:01,500 --> 00:06:04,620
2018 they actually showed that you in

199
00:06:04,620 --> 00:06:06,120
the cell probe model or Rams required

200
00:06:06,120 --> 00:06:07,919
logarithmic overhead but there was this

201
00:06:07,919 --> 00:06:09,780
requirement that b which was the array

202
00:06:09,780 --> 00:06:12,479
entry size or the output was at least as

203
00:06:12,479 --> 00:06:14,340
large as the memory size or the word

204
00:06:14,340 --> 00:06:18,300
size or or cell size in the insult model

205
00:06:18,300 --> 00:06:19,620
so

206
00:06:19,620 --> 00:06:21,660
to sort of circumvent this a recent work

207
00:06:21,660 --> 00:06:23,400
by karmagotsky and Lynn actually remove

208
00:06:23,400 --> 00:06:25,500
this restriction they showed in the Cell

209
00:06:25,500 --> 00:06:26,699
Pro Model oblivious random still

210
00:06:26,699 --> 00:06:28,860
required logarithmic overhead even when

211
00:06:28,860 --> 00:06:30,600
the output size B is much smaller than

212
00:06:30,600 --> 00:06:32,699
the word size w

213
00:06:32,699 --> 00:06:34,319
so this is the state of the art for

214
00:06:34,319 --> 00:06:35,580
oblivious Ram

215
00:06:35,580 --> 00:06:37,319
for differentially private Rams you know

216
00:06:37,319 --> 00:06:38,759
my co-author Peter and I showed a couple

217
00:06:38,759 --> 00:06:40,919
years ago that in fact this you still

218
00:06:40,919 --> 00:06:42,720
need logarithmic overhead in the Cell

219
00:06:42,720 --> 00:06:44,400
Pro model for differentiate prior Rams

220
00:06:44,400 --> 00:06:46,080
but with the same restriction that the

221
00:06:46,080 --> 00:06:48,000
array entry size b or the output size is

222
00:06:48,000 --> 00:06:50,880
still larger than the word size

223
00:06:50,880 --> 00:06:53,400
so okay I've sort of shown you this so

224
00:06:53,400 --> 00:06:54,360
the next question should be the

225
00:06:54,360 --> 00:06:56,100
following which is natural it's what

226
00:06:56,100 --> 00:06:57,060
happens when you have a differentiate

227
00:06:57,060 --> 00:06:59,100
private ram but the array entry is much

228
00:06:59,100 --> 00:07:00,840
smaller than the word size in fact

229
00:07:00,840 --> 00:07:02,699
before our work this was a known and in

230
00:07:02,699 --> 00:07:04,380
fact komergovsky and Lynn actually poses

231
00:07:04,380 --> 00:07:06,120
as an open problem in their paper to try

232
00:07:06,120 --> 00:07:07,500
to prove logarithmic lower bounds for

233
00:07:07,500 --> 00:07:10,440
Professor private Rams in this setting

234
00:07:10,440 --> 00:07:12,360
all right so this is exactly what we do

235
00:07:12,360 --> 00:07:14,100
so in this work what we end up doing is

236
00:07:14,100 --> 00:07:15,960
proving that differentiate private Rams

237
00:07:15,960 --> 00:07:18,120
require logarithmic overhead regardless

238
00:07:18,120 --> 00:07:19,919
of the choice of BMW so even if B is

239
00:07:19,919 --> 00:07:21,360
much smaller than W the lower bounds

240
00:07:21,360 --> 00:07:22,800
hold so these are the first lower bounds

241
00:07:22,800 --> 00:07:24,240
known for this resolves the open problem

242
00:07:24,240 --> 00:07:26,580
of kamergotsky and Lynn and in fact one

243
00:07:26,580 --> 00:07:27,780
thing that's interesting is that's the

244
00:07:27,780 --> 00:07:28,860
first differentiate private ram lower

245
00:07:28,860 --> 00:07:30,539
bounds in the multi-server setting for

246
00:07:30,539 --> 00:07:31,919
any choice of BMW so when I say

247
00:07:31,919 --> 00:07:33,840
multi-server you can have imagine two

248
00:07:33,840 --> 00:07:35,400
servers who are not including who each

249
00:07:35,400 --> 00:07:37,259
have the array or you can sort of

250
00:07:37,259 --> 00:07:38,160
utilize the fact that they're not

251
00:07:38,160 --> 00:07:39,960
included

252
00:07:39,960 --> 00:07:42,419
all right so that's good but I promise

253
00:07:42,419 --> 00:07:44,759
you guys a framework right so one thing

254
00:07:44,759 --> 00:07:46,500
I wanted to note is that starting from

255
00:07:46,500 --> 00:07:48,000
the seminal work of larceny Nielsen in

256
00:07:48,000 --> 00:07:49,560
2018 there's been a huge amount of work

257
00:07:49,560 --> 00:07:51,660
on this sort of area

258
00:07:51,660 --> 00:07:53,759
unfortunately what happens is that these

259
00:07:53,759 --> 00:07:55,020
techniques are pretty complicated and

260
00:07:55,020 --> 00:07:57,180
each of these sort of works end up

261
00:07:57,180 --> 00:07:59,099
customizing very small parts of the

262
00:07:59,099 --> 00:08:01,319
proof to enable proving the lower bounds

263
00:08:01,319 --> 00:08:03,120
for their desired primitive

264
00:08:03,120 --> 00:08:05,220
all right so this is not too bad but in

265
00:08:05,220 --> 00:08:07,319
general enabling like to enable yourself

266
00:08:07,319 --> 00:08:08,819
to prove a lower bound here you'd have

267
00:08:08,819 --> 00:08:10,860
to understand the entire technique and

268
00:08:10,860 --> 00:08:12,419
figure out exactly where you wanted to

269
00:08:12,419 --> 00:08:13,440
customize

270
00:08:13,440 --> 00:08:14,520
so this makes it a little bit

271
00:08:14,520 --> 00:08:16,919
inaccessible to the entire Community the

272
00:08:16,919 --> 00:08:18,180
papers are quite long and complicated

273
00:08:18,180 --> 00:08:19,979
and you'd rather want a framework where

274
00:08:19,979 --> 00:08:21,660
you'll need to customize the parts that

275
00:08:21,660 --> 00:08:23,400
you needed to know about the proof

276
00:08:23,400 --> 00:08:24,840
so in fact this is what we ended up

277
00:08:24,840 --> 00:08:26,879
doing so we generalize all these

278
00:08:26,879 --> 00:08:27,960
techniques into what we call a lower

279
00:08:27,960 --> 00:08:29,580
bound framework for proving logarithmic

280
00:08:29,580 --> 00:08:31,800
lower bounds so in particular the main

281
00:08:31,800 --> 00:08:33,479
theorem of our of our paper essentially

282
00:08:33,479 --> 00:08:35,700
says that any data structure problem p

283
00:08:35,700 --> 00:08:38,240
that satisfies two pretty natural

284
00:08:38,240 --> 00:08:41,640
conditions I would like to say then this

285
00:08:41,640 --> 00:08:43,919
problem would require logarithmic

286
00:08:43,919 --> 00:08:44,880
overhead in the Cell Pro Model

287
00:08:44,880 --> 00:08:47,160
regardless of the choice of B and W

288
00:08:47,160 --> 00:08:49,080
so the two conditions that we require

289
00:08:49,080 --> 00:08:51,060
one is what we call large information

290
00:08:51,060 --> 00:08:52,920
retrieval which essentially says that

291
00:08:52,920 --> 00:08:55,260
queries are sufficiently complex in

292
00:08:55,260 --> 00:08:56,459
other words you need to be able to have

293
00:08:56,459 --> 00:08:57,839
a data structure problem that retrieves

294
00:08:57,839 --> 00:08:59,760
information if you add a data structure

295
00:08:59,760 --> 00:09:01,200
problem that doesn't return or just

296
00:09:01,200 --> 00:09:02,160
throws away all the information you

297
00:09:02,160 --> 00:09:04,019
could improve a lower bound so that's

298
00:09:04,019 --> 00:09:05,880
the first condition the second condition

299
00:09:05,880 --> 00:09:08,160
event transfer probability is sort of a

300
00:09:08,160 --> 00:09:09,899
proxy for privacy and what it's

301
00:09:09,899 --> 00:09:11,279
essentially saying is that any event

302
00:09:11,279 --> 00:09:13,500
that an adversary can observe for one

303
00:09:13,500 --> 00:09:15,060
sequence of operations

304
00:09:15,060 --> 00:09:16,920
should transfer over to another sequence

305
00:09:16,920 --> 00:09:18,360
of operations so this is a roughly

306
00:09:18,360 --> 00:09:22,459
speaking uh a proxy for privacy

307
00:09:22,740 --> 00:09:25,380
all right so from this framework we get

308
00:09:25,380 --> 00:09:26,519
a bunch of lower bounds so the first

309
00:09:26,519 --> 00:09:27,420
result like we said was for

310
00:09:27,420 --> 00:09:28,620
differentially private Rams we proved

311
00:09:28,620 --> 00:09:30,360
login like lower amounts but in fact

312
00:09:30,360 --> 00:09:32,100
using our framework we end up getting we

313
00:09:32,100 --> 00:09:33,420
end up proving these lower bounds for a

314
00:09:33,420 --> 00:09:34,800
bunch of other data structure problems

315
00:09:34,800 --> 00:09:36,720
including sets predecessor and successor

316
00:09:36,720 --> 00:09:38,760
as well as disjoint sets Union fine and

317
00:09:38,760 --> 00:09:40,440
I wanted to know that all of these in

318
00:09:40,440 --> 00:09:42,180
plain text land have sub logarithmic and

319
00:09:42,180 --> 00:09:45,620
usually almost constant overhead

320
00:09:45,720 --> 00:09:48,899
all right so I'll come to you I'll

321
00:09:48,899 --> 00:09:49,680
explain to you guys a little about

322
00:09:49,680 --> 00:09:50,880
framework I gave you the two conditions

323
00:09:50,880 --> 00:09:52,140
at a very high level and I'm going to go

324
00:09:52,140 --> 00:09:54,120
to them in more detail and in fact to do

325
00:09:54,120 --> 00:09:55,200
this what I'm going to do is show you

326
00:09:55,200 --> 00:09:56,880
how to use our framework for the

327
00:09:56,880 --> 00:09:58,680
specific example of proving logarithmic

328
00:09:58,680 --> 00:09:59,880
lower bounds for differentially private

329
00:09:59,880 --> 00:10:01,500
sets

330
00:10:01,500 --> 00:10:04,080
all right so again this is the lower

331
00:10:04,080 --> 00:10:05,640
band that we prove essentially we prove

332
00:10:05,640 --> 00:10:07,019
that in the Cell Pro Model differentiate

333
00:10:07,019 --> 00:10:08,220
private side data structures require

334
00:10:08,220 --> 00:10:10,260
logarithmic overhead regardless of the

335
00:10:10,260 --> 00:10:12,060
choice of BMW

336
00:10:12,060 --> 00:10:13,200
and how we're going to go up proving

337
00:10:13,200 --> 00:10:15,000
this is exactly like I said

338
00:10:15,000 --> 00:10:17,459
just prove the two conditions so here's

339
00:10:17,459 --> 00:10:19,200
the formal statement of the first of

340
00:10:19,200 --> 00:10:20,220
condition which is large information

341
00:10:20,220 --> 00:10:22,260
retrieval so the first step of when

342
00:10:22,260 --> 00:10:23,279
you're trying to prove any lower bound

343
00:10:23,279 --> 00:10:25,260
is come up with a hard distribution you

344
00:10:25,260 --> 00:10:26,279
want to come up with a sequence of hard

345
00:10:26,279 --> 00:10:28,440
distribut hard updates that essentially

346
00:10:28,440 --> 00:10:29,760
will allow you to prove the lower bound

347
00:10:29,760 --> 00:10:30,839
and this is what large information

348
00:10:30,839 --> 00:10:32,580
retrieval is saying you want to pick a

349
00:10:32,580 --> 00:10:34,320
sequence of an updates

350
00:10:34,320 --> 00:10:35,880
such that if you picked any consecutive

351
00:10:35,880 --> 00:10:37,680
subset of L updates

352
00:10:37,680 --> 00:10:39,480
there exists roughly speaking a query

353
00:10:39,480 --> 00:10:41,399
set of size l

354
00:10:41,399 --> 00:10:43,500
whose answers have high entropy with

355
00:10:43,500 --> 00:10:46,320
respect to those subset of sequences you

356
00:10:46,320 --> 00:10:47,579
consider

357
00:10:47,579 --> 00:10:49,260
all right that's a lot of words it's

358
00:10:49,260 --> 00:10:50,700
actually not that complicated so rather

359
00:10:50,700 --> 00:10:52,320
than going through this definition in

360
00:10:52,320 --> 00:10:53,459
detail let's just go through a quick

361
00:10:53,459 --> 00:10:54,839
example

362
00:10:54,839 --> 00:10:56,040
so I'm going to show you how to do this

363
00:10:56,040 --> 00:10:57,899
for sets so let's suppose you have a set

364
00:10:57,899 --> 00:11:00,420
that stores a subset of any elements

365
00:11:00,420 --> 00:11:02,220
from one to n

366
00:11:02,220 --> 00:11:03,839
and what we're going to do is for every

367
00:11:03,839 --> 00:11:06,660
pair of of these possible elements we're

368
00:11:06,660 --> 00:11:07,980
going to create one operation so you

369
00:11:07,980 --> 00:11:09,420
know one and two will have operation one

370
00:11:09,420 --> 00:11:11,339
three and four will have operation two

371
00:11:11,339 --> 00:11:12,720
and so on and so forth so we'll have n

372
00:11:12,720 --> 00:11:14,519
over two operations

373
00:11:14,519 --> 00:11:15,480
and then what we're going to do is

374
00:11:15,480 --> 00:11:17,279
generate the following random updates

375
00:11:17,279 --> 00:11:18,660
for each of these operations I'm going

376
00:11:18,660 --> 00:11:20,399
to flip it flip a coin maybe just take a

377
00:11:20,399 --> 00:11:22,740
random bit and this will decide which of

378
00:11:22,740 --> 00:11:24,180
the two elements I'm going to insert so

379
00:11:24,180 --> 00:11:26,880
here I pick C12 to insert two

380
00:11:26,880 --> 00:11:28,320
and I'm going to do this again for all n

381
00:11:28,320 --> 00:11:30,480
over 2 operations and essentially I'm

382
00:11:30,480 --> 00:11:31,920
going to get a sequence of insertions

383
00:11:31,920 --> 00:11:33,300
where that are depending on the random

384
00:11:33,300 --> 00:11:34,860
bits that I generated so you want to CN

385
00:11:34,860 --> 00:11:37,220
over two

386
00:11:37,440 --> 00:11:39,480
okay so now I want to take any

387
00:11:39,480 --> 00:11:41,940
consecutive subset of L update so here

388
00:11:41,940 --> 00:11:43,140
I'm just going to pick the first two so

389
00:11:43,140 --> 00:11:44,519
L equals two

390
00:11:44,519 --> 00:11:46,380
and without knowing the randomness I

391
00:11:46,380 --> 00:11:48,660
want to be able to pick a query a set of

392
00:11:48,660 --> 00:11:50,760
similar size that allows me to extract

393
00:11:50,760 --> 00:11:52,320
the entropy I use to generate the

394
00:11:52,320 --> 00:11:53,399
updates

395
00:11:53,399 --> 00:11:55,740
well it's not too hard here what I would

396
00:11:55,740 --> 00:11:57,660
do is let's say I wanted to do the you

397
00:11:57,660 --> 00:11:59,220
know the first two operations I'm going

398
00:11:59,220 --> 00:12:01,140
to essentially send queries to check

399
00:12:01,140 --> 00:12:02,880
whether one is in the set and three is

400
00:12:02,880 --> 00:12:04,260
in the set

401
00:12:04,260 --> 00:12:06,600
in fact for example you know this it's

402
00:12:06,600 --> 00:12:07,680
not very hard to see that this actually

403
00:12:07,680 --> 00:12:10,019
allows you to get back C1 and C2 so if I

404
00:12:10,019 --> 00:12:11,760
do query one I realize one is not in the

405
00:12:11,760 --> 00:12:14,220
set it means two is in the set so C1 is

406
00:12:14,220 --> 00:12:15,839
equal to you know whatever bit required

407
00:12:15,839 --> 00:12:17,040
to get to

408
00:12:17,040 --> 00:12:18,540
and similarly I would query for three

409
00:12:18,540 --> 00:12:20,100
I'd see it's in the set and I would see

410
00:12:20,100 --> 00:12:22,740
that C2 is equal to zero for example

411
00:12:22,740 --> 00:12:24,420
and that's actually it so whenever you

412
00:12:24,420 --> 00:12:25,560
have a data structure problem all you

413
00:12:25,560 --> 00:12:27,300
have to do is find this sequence of hard

414
00:12:27,300 --> 00:12:29,820
updates and for any sort of operation

415
00:12:29,820 --> 00:12:32,339
sort of find this query set that will

416
00:12:32,339 --> 00:12:35,459
allow you to retrieve this entropy

417
00:12:35,459 --> 00:12:37,440
um all right so that's the first sort of

418
00:12:37,440 --> 00:12:39,240
uh step we need to do

419
00:12:39,240 --> 00:12:41,100
the Second Step I need we need to do is

420
00:12:41,100 --> 00:12:42,839
event transfer probability and again

421
00:12:42,839 --> 00:12:45,180
there's a formal definition roughly

422
00:12:45,180 --> 00:12:46,860
speaking agency just says any event

423
00:12:46,860 --> 00:12:48,300
that's observable by an adversary for

424
00:12:48,300 --> 00:12:50,579
one query should be observable with some

425
00:12:50,579 --> 00:12:52,200
reasonably similar probability for the

426
00:12:52,200 --> 00:12:54,120
second query

427
00:12:54,120 --> 00:12:55,800
um all right so how do we do this for

428
00:12:55,800 --> 00:12:57,839
differential privacy this is literally

429
00:12:57,839 --> 00:13:00,600
the proof you just rearrange the formula

430
00:13:00,600 --> 00:13:02,639
and in fact what I was going to say is

431
00:13:02,639 --> 00:13:04,800
we provide generic memos in the in the

432
00:13:04,800 --> 00:13:06,600
in the paper for any of these standard

433
00:13:06,600 --> 00:13:08,220
Notions of privacy so obliviousness

434
00:13:08,220 --> 00:13:10,740
differential privacy encrypted search or

435
00:13:10,740 --> 00:13:12,899
multi-server variants of any of these so

436
00:13:12,899 --> 00:13:14,279
if you want to use our lower bound

437
00:13:14,279 --> 00:13:15,360
framework for any of these privacy

438
00:13:15,360 --> 00:13:16,680
Notions you can just use the limos

439
00:13:16,680 --> 00:13:18,000
directly from our paper

440
00:13:18,000 --> 00:13:19,800
the reason we put this in specifically

441
00:13:19,800 --> 00:13:21,300
is it allows you to extend the lower

442
00:13:21,300 --> 00:13:22,920
bound to other privacy Notions that

443
00:13:22,920 --> 00:13:24,600
aren't the standard ones so in

444
00:13:24,600 --> 00:13:25,920
particular if you wanted to prove a

445
00:13:25,920 --> 00:13:27,540
lower Bound for a privacy notion that's

446
00:13:27,540 --> 00:13:29,459
either incomparable or weaker than any

447
00:13:29,459 --> 00:13:31,139
of these four things then you can try to

448
00:13:31,139 --> 00:13:32,579
use the event transfer probability to

449
00:13:32,579 --> 00:13:34,860
prove it

450
00:13:34,860 --> 00:13:36,660
all right

451
00:13:36,660 --> 00:13:38,880
um okay so one thing I'll say is that

452
00:13:38,880 --> 00:13:40,500
specifically for this law about for

453
00:13:40,500 --> 00:13:42,720
depressing private sets we showed that

454
00:13:42,720 --> 00:13:43,740
in the in the large information

455
00:13:43,740 --> 00:13:45,600
retrieval that we could extract V equals

456
00:13:45,600 --> 00:13:47,760
one bits for each of the L updates on

457
00:13:47,760 --> 00:13:50,040
average right so if you wanted to use

458
00:13:50,040 --> 00:13:51,000
our lower bound framework more

459
00:13:51,000 --> 00:13:53,519
generically in fact you can consider

460
00:13:53,519 --> 00:13:55,200
there are problems where you can extract

461
00:13:55,200 --> 00:13:56,880
more than one bit you know generic V

462
00:13:56,880 --> 00:13:58,920
bits per update in which case you would

463
00:13:58,920 --> 00:14:00,060
get this lower about

464
00:14:00,060 --> 00:14:01,500
so you know you can see that you

465
00:14:01,500 --> 00:14:03,060
immediately get the set lower Bound by

466
00:14:03,060 --> 00:14:06,199
sending V and B to equal one

467
00:14:06,300 --> 00:14:08,160
all right cool

468
00:14:08,160 --> 00:14:11,339
um so one may ask you know I gave you

469
00:14:11,339 --> 00:14:13,139
this framework is it type you know

470
00:14:13,139 --> 00:14:14,700
you're going to try to use it but are

471
00:14:14,700 --> 00:14:15,899
there data structure lower bounds where

472
00:14:15,899 --> 00:14:17,339
you can prove log and make lower bounds

473
00:14:17,339 --> 00:14:19,980
but not in our framework

474
00:14:19,980 --> 00:14:21,959
so we actually consider this so one

475
00:14:21,959 --> 00:14:23,339
problem that we considered are stacks

476
00:14:23,339 --> 00:14:25,200
and cues which cannot satisfy this it's

477
00:14:25,200 --> 00:14:27,180
not hard to see because if if you if you

478
00:14:27,180 --> 00:14:29,399
insert items into a stack or queue any

479
00:14:29,399 --> 00:14:30,660
consecutive subset in the middle you're

480
00:14:30,660 --> 00:14:32,040
not able to extract the information out

481
00:14:32,040 --> 00:14:34,620
so it wouldn't fit into our framework

482
00:14:34,620 --> 00:14:35,880
but it turns out it was an interesting

483
00:14:35,880 --> 00:14:37,440
question because for oblivious stacks

484
00:14:37,440 --> 00:14:39,000
and queues logarithmic lower bounds were

485
00:14:39,000 --> 00:14:40,800
known when B is larger than equal to W

486
00:14:40,800 --> 00:14:42,420
and when you have differentially private

487
00:14:42,420 --> 00:14:44,040
stacks and queues it's well known it's

488
00:14:44,040 --> 00:14:45,420
known that you need log login overhead

489
00:14:45,420 --> 00:14:46,380
only

490
00:14:46,380 --> 00:14:48,120
so one opening problem we had was you

491
00:14:48,120 --> 00:14:49,199
know what is the override overhead for

492
00:14:49,199 --> 00:14:50,760
oblivious stacks and queues when you

493
00:14:50,760 --> 00:14:53,279
know the the B is much smaller than w

494
00:14:53,279 --> 00:14:55,260
because if it'd be really bad if you can

495
00:14:55,260 --> 00:14:56,519
prove a lower bound here but it wouldn't

496
00:14:56,519 --> 00:14:58,680
fit into our framework

497
00:14:58,680 --> 00:15:00,420
so we end up showing actually when B is

498
00:15:00,420 --> 00:15:01,860
much smaller than w

499
00:15:01,860 --> 00:15:03,779
oblivious tax Infuse requires smaller

500
00:15:03,779 --> 00:15:06,180
than login overhead so in fact it's

501
00:15:06,180 --> 00:15:07,620
inherent that oblivious stacks and cues

502
00:15:07,620 --> 00:15:09,000
cannot satisfy our framework because you

503
00:15:09,000 --> 00:15:09,959
shouldn't be able to prove this lower

504
00:15:09,959 --> 00:15:12,180
amount and in fact uh this result is

505
00:15:12,180 --> 00:15:13,500
actually the first operation for online

506
00:15:13,500 --> 00:15:15,420
Globus data structures between settings

507
00:15:15,420 --> 00:15:17,100
of when B is greater than or equal to W

508
00:15:17,100 --> 00:15:20,000
and B is less than w

509
00:15:20,459 --> 00:15:22,380
all right so I think in the last minute

510
00:15:22,380 --> 00:15:24,120
or so I'll give you a little bit of a

511
00:15:24,120 --> 00:15:25,440
taste of the proof techniques mainly

512
00:15:25,440 --> 00:15:26,459
because I'm out of running out of time I

513
00:15:26,459 --> 00:15:29,040
won't be able to give you too much but

514
00:15:29,040 --> 00:15:31,380
um let me see if I can so what we do is

515
00:15:31,380 --> 00:15:32,880
we build off the chronogram technique by

516
00:15:32,880 --> 00:15:34,800
fredman and sax that was introduced in

517
00:15:34,800 --> 00:15:36,240
the 90s actually

518
00:15:36,240 --> 00:15:38,100
in terms of oblivious or cryptographic

519
00:15:38,100 --> 00:15:39,959
data structures it's been used twice in

520
00:15:39,959 --> 00:15:41,880
the past so one is actually my work or

521
00:15:41,880 --> 00:15:44,279
my previous work with keynote here that

522
00:15:44,279 --> 00:15:46,320
showed login profession private Rams

523
00:15:46,320 --> 00:15:48,120
when B is greater than equal to w

524
00:15:48,120 --> 00:15:50,040
and in fact the techniques we use here

525
00:15:50,040 --> 00:15:51,779
build on top of that paper

526
00:15:51,779 --> 00:15:53,220
I'd also like to note that it's also

527
00:15:53,220 --> 00:15:54,480
used to prove super log in the lower

528
00:15:54,480 --> 00:15:56,040
bounds for statistically oblivious new

529
00:15:56,040 --> 00:15:58,560
neighbor search as well so but that

530
00:15:58,560 --> 00:16:00,540
technique is slightly different so the

531
00:16:00,540 --> 00:16:01,980
specific techniques here built on top of

532
00:16:01,980 --> 00:16:04,079
the first paper

533
00:16:04,079 --> 00:16:06,120
all right so the main new proof

534
00:16:06,120 --> 00:16:08,399
Technique we use is the fact that so

535
00:16:08,399 --> 00:16:09,540
most of these lower bounds what they end

536
00:16:09,540 --> 00:16:11,760
up doing is showing that when you encode

537
00:16:11,760 --> 00:16:13,320
a data structure you're trying to you

538
00:16:13,320 --> 00:16:14,639
couldn't try to find encoding of a data

539
00:16:14,639 --> 00:16:16,980
structure that answers like that that

540
00:16:16,980 --> 00:16:18,839
sort of encodes the database in an

541
00:16:18,839 --> 00:16:20,760
impossible way when queries and updates

542
00:16:20,760 --> 00:16:22,079
are too efficient

543
00:16:22,079 --> 00:16:24,540
and in particular the new core technique

544
00:16:24,540 --> 00:16:26,519
that we've proven here is that we show

545
00:16:26,519 --> 00:16:28,560
that the majority of answers to queries

546
00:16:28,560 --> 00:16:30,899
can be encoded for free as long as

547
00:16:30,899 --> 00:16:32,399
you're assuming a data structure is too

548
00:16:32,399 --> 00:16:33,779
efficient to be true

549
00:16:33,779 --> 00:16:35,519
so at a very high level it's not a very

550
00:16:35,519 --> 00:16:38,160
complicated sort of concept take a data

551
00:16:38,160 --> 00:16:39,120
structure that's too efficient to be

552
00:16:39,120 --> 00:16:41,100
true maybe it only updates two cells on

553
00:16:41,100 --> 00:16:43,019
updates so you know for any update you

554
00:16:43,019 --> 00:16:44,820
up these two cells now let's say you

555
00:16:44,820 --> 00:16:46,199
take a random query you're gonna you're

556
00:16:46,199 --> 00:16:47,759
gonna pick a random query and to see

557
00:16:47,759 --> 00:16:49,320
which sells it probes

558
00:16:49,320 --> 00:16:52,259
let's say approach these cells well in

559
00:16:52,259 --> 00:16:54,420
fact you realize that if the data

560
00:16:54,420 --> 00:16:55,680
structure is too efficient to be true

561
00:16:55,680 --> 00:16:58,139
these are not going to overlap these

562
00:16:58,139 --> 00:16:59,880
cells probably won't overlap so in other

563
00:16:59,880 --> 00:17:01,680
words if you have a small subset of

564
00:17:01,680 --> 00:17:03,600
updates they only touch a few number of

565
00:17:03,600 --> 00:17:05,579
cells on the update if you pick a random

566
00:17:05,579 --> 00:17:07,740
query later it won't change the answer

567
00:17:07,740 --> 00:17:09,599
so in other words even if you don't know

568
00:17:09,599 --> 00:17:11,459
the updates you can still get the answer

569
00:17:11,459 --> 00:17:13,619
to a random query for free

570
00:17:13,619 --> 00:17:15,059
and this is sort of the core Technique

571
00:17:15,059 --> 00:17:17,220
we use to prove our lower Bound in our

572
00:17:17,220 --> 00:17:19,380
lower bound framework

573
00:17:19,380 --> 00:17:21,299
um all right so I did not I mean that's

574
00:17:21,299 --> 00:17:22,859
very high level I encourage all those

575
00:17:22,859 --> 00:17:23,939
people to look at the proof or ask me

576
00:17:23,939 --> 00:17:25,140
questions to get any more ideas about

577
00:17:25,140 --> 00:17:26,819
the proof techniques and

578
00:17:26,819 --> 00:17:28,500
thank you all for listening I'm happy to

579
00:17:28,500 --> 00:17:30,170
answer any questions

580
00:17:30,170 --> 00:17:33,869
[Applause]

581
00:17:35,640 --> 00:17:38,460
thank you so is there any question so if

582
00:17:38,460 --> 00:17:40,260
you have a question please uh stand up

583
00:17:40,260 --> 00:17:43,080
and ask it using the microphone

584
00:17:43,080 --> 00:17:45,240
hi Kevin um thanks for the very nice

585
00:17:45,240 --> 00:17:46,740
talk I wonder

586
00:17:46,740 --> 00:17:48,360
um so in the lower Brown it's very

587
00:17:48,360 --> 00:17:51,000
important that the B the real the

588
00:17:51,000 --> 00:17:53,340
comparison between B and W right so I

589
00:17:53,340 --> 00:17:56,039
wonder uh is B the return

590
00:17:56,039 --> 00:17:58,919
um bit numbers is it right

591
00:17:58,919 --> 00:18:01,440
um yeah so I guess

592
00:18:01,440 --> 00:18:03,360
yes it's essentially the output the size

593
00:18:03,360 --> 00:18:06,120
of the query output so I wonder like is

594
00:18:06,120 --> 00:18:08,640
ISO B is inherent for every data

595
00:18:08,640 --> 00:18:11,220
structure for example in the set example

596
00:18:11,220 --> 00:18:13,500
uh you set the b equals to one but

597
00:18:13,500 --> 00:18:15,299
actually if every time you just return

598
00:18:15,299 --> 00:18:17,700
more information that like but that

599
00:18:17,700 --> 00:18:19,380
makes so what you want to do is yes

600
00:18:19,380 --> 00:18:20,940
you're right if you consider data

601
00:18:20,940 --> 00:18:22,320
structure it's more complicated it's

602
00:18:22,320 --> 00:18:24,000
easier to prove lower bounds right so

603
00:18:24,000 --> 00:18:25,740
when you have a set it only returns a

604
00:18:25,740 --> 00:18:26,880
minimum amount of information it makes

605
00:18:26,880 --> 00:18:28,620
you proving lower bound harder because

606
00:18:28,620 --> 00:18:30,120
it's easier to design data structures

607
00:18:30,120 --> 00:18:30,960
for it

608
00:18:30,960 --> 00:18:33,480
right so in fact in a lot of Cell Pro

609
00:18:33,480 --> 00:18:35,160
lower bounds

610
00:18:35,160 --> 00:18:37,320
the smaller the output so let's say b

611
00:18:37,320 --> 00:18:39,120
equals one which is minimal the less

612
00:18:39,120 --> 00:18:40,740
information you get which means it's

613
00:18:40,740 --> 00:18:42,600
easier to construct data structures but

614
00:18:42,600 --> 00:18:43,860
it's harder to prove lower bounds for

615
00:18:43,860 --> 00:18:45,900
them oh so you cannot like

616
00:18:45,900 --> 00:18:48,360
get better lower Bound by increasing

617
00:18:48,360 --> 00:18:50,760
return from returning information you

618
00:18:50,760 --> 00:18:52,080
can you can but that's a different

619
00:18:52,080 --> 00:18:54,360
problem you're proving for right let's

620
00:18:54,360 --> 00:18:55,320
say

621
00:18:55,320 --> 00:18:57,120
like I said I don't know maybe you can

622
00:18:57,120 --> 00:18:58,200
return

623
00:18:58,200 --> 00:18:59,820
like let's say an augmentation of the

624
00:18:59,820 --> 00:19:01,559
step problem is I return not only the

625
00:19:01,559 --> 00:19:03,419
item is whether this item is in the set

626
00:19:03,419 --> 00:19:05,880
but the login items around it are also

627
00:19:05,880 --> 00:19:07,320
in the set right that makes the problem

628
00:19:07,320 --> 00:19:09,299
harder right if you're designing a data

629
00:19:09,299 --> 00:19:10,919
structure this makes it a lot harder but

630
00:19:10,919 --> 00:19:12,299
it makes it a lot easier to prove lower

631
00:19:12,299 --> 00:19:13,860
bounds actually because the problem is

632
00:19:13,860 --> 00:19:15,059
harder

633
00:19:15,059 --> 00:19:16,740
so b equals one is usually the hardest

634
00:19:16,740 --> 00:19:17,880
case and that's why it requires more

635
00:19:17,880 --> 00:19:21,559
work to prove lower balance thank you

636
00:19:21,660 --> 00:19:24,810
okay so let's thank Kevin again

637
00:19:24,810 --> 00:19:29,919
[Applause]

638
00:19:40,380 --> 00:19:43,460
okay can I come again

639
00:19:43,460 --> 00:19:46,559
second talk is lower bounds for batch

640
00:19:46,559 --> 00:19:49,320
PIR with private pre-processing by

641
00:19:49,320 --> 00:19:50,820
cutting out and Kevin is giving the talk

642
00:19:50,820 --> 00:19:51,900
all right thank you for the introduction

643
00:19:51,900 --> 00:19:53,760
uh if I borrowed you the first time I'm

644
00:19:53,760 --> 00:19:55,200
sorry I'm going to bore you again but

645
00:19:55,200 --> 00:19:57,059
let's go all right so I'm going to tell

646
00:19:57,059 --> 00:19:58,200
you guys about a different work lower

647
00:19:58,200 --> 00:19:59,580
bounds for a different primitive of

648
00:19:59,580 --> 00:20:02,280
badge period with private pre-processing

649
00:20:02,280 --> 00:20:03,960
all right same outline I'm going to

650
00:20:03,960 --> 00:20:05,940
Define to you about Spirit processing is

651
00:20:05,940 --> 00:20:07,799
I'll explain to you our contributions

652
00:20:07,799 --> 00:20:09,480
and I'll give you more of a taste of the

653
00:20:09,480 --> 00:20:10,679
lower bound proof technique this time

654
00:20:10,679 --> 00:20:11,820
around

655
00:20:11,820 --> 00:20:13,320
and throughout this talk I'm going to

656
00:20:13,320 --> 00:20:15,660
leverage my previous talk so uh it's

657
00:20:15,660 --> 00:20:17,039
good to know the schedule

658
00:20:17,039 --> 00:20:18,780
all right so private information to

659
00:20:18,780 --> 00:20:20,760
retrieval if this picture looks familiar

660
00:20:20,760 --> 00:20:24,360
it should again you have a client on the

661
00:20:24,360 --> 00:20:27,299
right and then a server holding an entry

662
00:20:27,299 --> 00:20:29,520
database on the left

663
00:20:29,520 --> 00:20:31,500
what's going to happen is the is the

664
00:20:31,500 --> 00:20:33,660
client will get some index I it'll do

665
00:20:33,660 --> 00:20:35,640
some sequence of obfuscated accesses to

666
00:20:35,640 --> 00:20:36,960
get the it entry

667
00:20:36,960 --> 00:20:38,460
and it should do it in such a way that

668
00:20:38,460 --> 00:20:39,539
the server doesn't know what was the

669
00:20:39,539 --> 00:20:41,520
requested index all right so now you

670
00:20:41,520 --> 00:20:43,260
might be asking all right I'm this looks

671
00:20:43,260 --> 00:20:44,520
identical to all Ram what's going on

672
00:20:44,520 --> 00:20:46,620
right it it should look identical to you

673
00:20:46,620 --> 00:20:47,460
right now

674
00:20:47,460 --> 00:20:49,679
so leveraging off my previous talk I'm

675
00:20:49,679 --> 00:20:50,760
going to give you a quick comparison

676
00:20:50,760 --> 00:20:52,980
between what appear in allram is so it

677
00:20:52,980 --> 00:20:54,240
turns out there's one subtle difference

678
00:20:54,240 --> 00:20:57,419
that makes PIR much more challenging to

679
00:20:57,419 --> 00:20:59,100
sort of construct but also it makes it

680
00:20:59,100 --> 00:21:01,679
easier to prove lower bounds so in PIR

681
00:21:01,679 --> 00:21:03,840
which is on the right

682
00:21:03,840 --> 00:21:05,400
what ends up happening is the server

683
00:21:05,400 --> 00:21:07,980
must create one encoded database that is

684
00:21:07,980 --> 00:21:10,620
allowed to be accessed by multiple users

685
00:21:10,620 --> 00:21:12,360
so in other words what I'm trying to say

686
00:21:12,360 --> 00:21:14,460
is that this encoded database is not

687
00:21:14,460 --> 00:21:16,020
going to be specific to any private key

688
00:21:16,020 --> 00:21:18,900
that the users will hold in contrast for

689
00:21:18,900 --> 00:21:21,299
the Oram on the left side what's going

690
00:21:21,299 --> 00:21:22,980
to happen is the server and the client

691
00:21:22,980 --> 00:21:24,960
will work together to generate an

692
00:21:24,960 --> 00:21:27,299
encrypted version of the database that's

693
00:21:27,299 --> 00:21:29,159
worked specifically for a specific

694
00:21:29,159 --> 00:21:30,419
private key

695
00:21:30,419 --> 00:21:32,280
so in other words what ends up happening

696
00:21:32,280 --> 00:21:33,659
is you have a database that works sort

697
00:21:33,659 --> 00:21:36,900
of for one user with one private key of

698
00:21:36,900 --> 00:21:38,039
course you could generalize it to

699
00:21:38,039 --> 00:21:39,900
multiple users but in an Oram it's still

700
00:21:39,900 --> 00:21:41,340
critical that they all share the same

701
00:21:41,340 --> 00:21:42,480
private key

702
00:21:42,480 --> 00:21:44,340
so in other words this is harder right

703
00:21:44,340 --> 00:21:46,679
PIR is a harder problem because of the

704
00:21:46,679 --> 00:21:48,840
server can't leverage a private key to

705
00:21:48,840 --> 00:21:50,880
make accesses faster and in fact this is

706
00:21:50,880 --> 00:21:52,980
what ends up happening why PIR is

707
00:21:52,980 --> 00:21:54,780
usually much more expensive than o-ramp

708
00:21:54,780 --> 00:21:56,220
but that's good for us I'm proving lower

709
00:21:56,220 --> 00:21:57,480
bound so that makes it easier I can fire

710
00:21:57,480 --> 00:21:59,640
lower bounds

711
00:21:59,640 --> 00:22:02,280
all right so and as an example here

712
00:22:02,280 --> 00:22:03,600
before I was proving logarithmic lower

713
00:22:03,600 --> 00:22:05,400
bounds but it turns out by militia

714
00:22:05,400 --> 00:22:07,500
Malkin in 2000 proved in What's called

715
00:22:07,500 --> 00:22:08,820
the standard peer model I'll get to it

716
00:22:08,820 --> 00:22:09,659
later

717
00:22:09,659 --> 00:22:11,760
the server computation must be linear in

718
00:22:11,760 --> 00:22:13,140
fact you must touch every entry in the

719
00:22:13,140 --> 00:22:15,179
database so again linear versus

720
00:22:15,179 --> 00:22:17,280
logarithmic

721
00:22:17,280 --> 00:22:20,400
so this is pretty bad actually writing a

722
00:22:20,400 --> 00:22:21,539
sense if you have to touch the entire

723
00:22:21,539 --> 00:22:23,039
database for each query it's pretty

724
00:22:23,039 --> 00:22:24,299
inefficient

725
00:22:24,299 --> 00:22:26,640
luckily there were two ways shown to

726
00:22:26,640 --> 00:22:28,740
circumvent this linear lower bound and

727
00:22:28,740 --> 00:22:30,360
I'll talk about them here so one is

728
00:22:30,360 --> 00:22:32,159
called peer with pre-processing I know

729
00:22:32,159 --> 00:22:34,380
this is called batch Bure

730
00:22:34,380 --> 00:22:36,179
and both of these actually enable us to

731
00:22:36,179 --> 00:22:37,919
get sublinear server computation per

732
00:22:37,919 --> 00:22:39,539
query

733
00:22:39,539 --> 00:22:41,039
so okay the first one is what I'm going

734
00:22:41,039 --> 00:22:42,000
to go through is called Pure with

735
00:22:42,000 --> 00:22:44,100
private pre-processing so the setting

736
00:22:44,100 --> 00:22:45,720
should look the same except there's now

737
00:22:45,720 --> 00:22:47,460
a pre-processing stage where the client

738
00:22:47,460 --> 00:22:48,960
and server can work together to compute

739
00:22:48,960 --> 00:22:50,580
some hints without knowing the query is

740
00:22:50,580 --> 00:22:51,720
coming out so it's pre-processing you

741
00:22:51,720 --> 00:22:53,400
don't know the queries yet so what we'll

742
00:22:53,400 --> 00:22:54,480
do is the client and server work

743
00:22:54,480 --> 00:22:57,299
together to create some hints this hint

744
00:22:57,299 --> 00:22:59,159
should be private so in a sense the only

745
00:22:59,159 --> 00:23:00,780
person that ever learns the hint should

746
00:23:00,780 --> 00:23:02,340
be just the user and even though the

747
00:23:02,340 --> 00:23:04,260
server may help to compute the hint the

748
00:23:04,260 --> 00:23:06,960
server should not learn what the hint is

749
00:23:06,960 --> 00:23:08,400
all right so that's the pre-processing

750
00:23:08,400 --> 00:23:10,080
stage and in the query stage you still

751
00:23:10,080 --> 00:23:11,400
get the index I which you didn't which

752
00:23:11,400 --> 00:23:13,140
the user didn't know before it's still

753
00:23:13,140 --> 00:23:14,580
going to do a set of queries it's sort

754
00:23:14,580 --> 00:23:15,720
of going to like you know do its

755
00:23:15,720 --> 00:23:17,580
obfuscated access but it can now

756
00:23:17,580 --> 00:23:19,140
leverage this hint to try to make the

757
00:23:19,140 --> 00:23:21,299
query stage faster in particular and try

758
00:23:21,299 --> 00:23:22,740
not to touch the entire database per

759
00:23:22,740 --> 00:23:25,039
query

760
00:23:25,440 --> 00:23:26,880
um so when we consider period with prior

761
00:23:26,880 --> 00:23:28,080
pre-processing we're going to consider

762
00:23:28,080 --> 00:23:30,179
two complexity measures one is the hint

763
00:23:30,179 --> 00:23:32,340
size which let's say is our bits and the

764
00:23:32,340 --> 00:23:34,440
computational time which essentially the

765
00:23:34,440 --> 00:23:36,059
number of entries T that is probed by

766
00:23:36,059 --> 00:23:38,820
the server during the query

767
00:23:38,820 --> 00:23:40,380
so it turns out period priority

768
00:23:40,380 --> 00:23:42,840
processing is sort of a generic name

769
00:23:42,840 --> 00:23:44,460
that has been studied under many other

770
00:23:44,460 --> 00:23:46,080
different names so like doubly efficient

771
00:23:46,080 --> 00:23:47,640
peer private stateful information

772
00:23:47,640 --> 00:23:49,440
retrieval and more recently offline

773
00:23:49,440 --> 00:23:51,299
online peer

774
00:23:51,299 --> 00:23:52,980
but the really good news is you can get

775
00:23:52,980 --> 00:23:55,320
very very sub linear time so core in the

776
00:23:55,320 --> 00:23:56,700
seminal paper by Corrigan Gibson Cogan

777
00:23:56,700 --> 00:23:58,679
in 2020 they showed that there existed

778
00:23:58,679 --> 00:24:00,539
construction where the product of the

779
00:24:00,539 --> 00:24:03,360
time and the hint size is linear so if

780
00:24:03,360 --> 00:24:04,679
you sort of rearrange it you can figure

781
00:24:04,679 --> 00:24:06,419
out that actually you can make both the

782
00:24:06,419 --> 00:24:07,799
hint and the time be square root n

783
00:24:07,799 --> 00:24:10,380
essentially which is very very sublinear

784
00:24:10,380 --> 00:24:12,299
and in fact Corrigan Gibbs also proved a

785
00:24:12,299 --> 00:24:13,860
lower bound according Gibson kogan also

786
00:24:13,860 --> 00:24:14,880
proved a lower bound showing that the

787
00:24:14,880 --> 00:24:17,100
product must be essentially n divided by

788
00:24:17,100 --> 00:24:20,100
poly login factors

789
00:24:20,100 --> 00:24:21,600
all right so this is one way to get

790
00:24:21,600 --> 00:24:23,520
sublinear server time which is great

791
00:24:23,520 --> 00:24:25,380
here's another way let's consider batch

792
00:24:25,380 --> 00:24:27,419
peers so this is a very famous uh

793
00:24:27,419 --> 00:24:28,559
primitive probably most people know

794
00:24:28,559 --> 00:24:29,940
about it but rather than having one

795
00:24:29,940 --> 00:24:32,520
index you're going to have a batch of K

796
00:24:32,520 --> 00:24:34,320
queries to do at once and the goal

797
00:24:34,320 --> 00:24:35,580
Remains the Same you want to get you

798
00:24:35,580 --> 00:24:37,919
know all K blocks but it's critical that

799
00:24:37,919 --> 00:24:39,240
the batch is given to you ahead of time

800
00:24:39,240 --> 00:24:41,400
so you know before the user is going to

801
00:24:41,400 --> 00:24:43,020
start its query it knows all K indices

802
00:24:43,020 --> 00:24:45,600
that it wants to query for

803
00:24:45,600 --> 00:24:48,539
so here it turns out that in 2004 Shai

804
00:24:48,539 --> 00:24:50,820
Kush Levitz ostrosky and sahi they use

805
00:24:50,820 --> 00:24:52,380
these things called batch codes but they

806
00:24:52,380 --> 00:24:53,280
show that you can actually have a

807
00:24:53,280 --> 00:24:55,500
construction for K query batch peer with

808
00:24:55,500 --> 00:24:57,240
time that's like only a poly login

809
00:24:57,240 --> 00:25:00,120
Factor higher than single query

810
00:25:00,120 --> 00:25:01,980
and this is really amazing right so like

811
00:25:01,980 --> 00:25:03,419
this sort of poly login overhead is

812
00:25:03,419 --> 00:25:06,059
independence of K so now what you get is

813
00:25:06,059 --> 00:25:08,280
amortized server time perquiries order n

814
00:25:08,280 --> 00:25:10,260
over K but I'm going to say k is equal

815
00:25:10,260 --> 00:25:11,280
to square root and this is very

816
00:25:11,280 --> 00:25:12,960
sublinear actually

817
00:25:12,960 --> 00:25:15,720
it's okay these are two ways to sort of

818
00:25:15,720 --> 00:25:17,820
get very sublinear server times but they

819
00:25:17,820 --> 00:25:19,559
have sort of the limitations but

820
00:25:19,559 --> 00:25:20,880
regardless it's an interesting question

821
00:25:20,880 --> 00:25:23,100
of can you combine them

822
00:25:23,100 --> 00:25:26,279
right we have two ways of doing this can

823
00:25:26,279 --> 00:25:28,260
we combine them to make server time even

824
00:25:28,260 --> 00:25:30,480
faster

825
00:25:30,480 --> 00:25:32,100
okay so what do I mean by combining them

826
00:25:32,100 --> 00:25:34,380
like what would the dream be so here we

827
00:25:34,380 --> 00:25:36,120
have a sort of populated on the left the

828
00:25:36,120 --> 00:25:38,100
two things that we knew so sort of for

829
00:25:38,100 --> 00:25:39,600
single query we know that when you have

830
00:25:39,600 --> 00:25:41,940
no preprocessing single query requires

831
00:25:41,940 --> 00:25:43,919
linear time and K query you essentially

832
00:25:43,919 --> 00:25:46,679
get for free ignoring log factors

833
00:25:46,679 --> 00:25:48,179
so we can imagine the same thing would

834
00:25:48,179 --> 00:25:50,940
hold for you know from single query to K

835
00:25:50,940 --> 00:25:53,940
query private pre-processing here where

836
00:25:53,940 --> 00:25:55,020
you would essentially get this for free

837
00:25:55,020 --> 00:25:57,900
as well ignoring poly log factors

838
00:25:57,900 --> 00:26:00,000
it seems like it's a reasonable thing to

839
00:26:00,000 --> 00:26:01,799
hope for and in fact I was hoping to do

840
00:26:01,799 --> 00:26:03,179
this I actually tried to construct this

841
00:26:03,179 --> 00:26:04,140
at first

842
00:26:04,140 --> 00:26:06,240
but I guess I gave away the answer in

843
00:26:06,240 --> 00:26:08,039
the title but the answer is sort of this

844
00:26:08,039 --> 00:26:09,840
is not possible

845
00:26:09,840 --> 00:26:11,520
so this dream doesn't hold and in fact

846
00:26:11,520 --> 00:26:12,779
the main contribution of this work

847
00:26:12,779 --> 00:26:14,220
essentially is that we prove for any

848
00:26:14,220 --> 00:26:16,860
computational secure K query peer with

849
00:26:16,860 --> 00:26:19,380
product processing for even for constant

850
00:26:19,380 --> 00:26:21,480
non-cluding servers it really must be

851
00:26:21,480 --> 00:26:24,299
that the product of T times R is equal

852
00:26:24,299 --> 00:26:25,020
to

853
00:26:25,020 --> 00:26:26,460
Omega n times k

854
00:26:26,460 --> 00:26:28,200
so remember for single query we had that

855
00:26:28,200 --> 00:26:30,179
t times R is equal to order n but

856
00:26:30,179 --> 00:26:31,620
somehow when you want to do K query

857
00:26:31,620 --> 00:26:34,020
simultaneously it becomes the same as

858
00:26:34,020 --> 00:26:36,059
just doing K of them in in sequence you

859
00:26:36,059 --> 00:26:38,400
know the trivial sort of approach I'll

860
00:26:38,400 --> 00:26:39,840
also note that the condition of when the

861
00:26:39,840 --> 00:26:41,700
hint size is less than K this sort of

862
00:26:41,700 --> 00:26:42,840
encompasses the fact that you can always

863
00:26:42,840 --> 00:26:45,419
just run a batch here in linear time so

864
00:26:45,419 --> 00:26:46,919
sort of if the hint is too small then

865
00:26:46,919 --> 00:26:48,059
you can always run batch pure but that

866
00:26:48,059 --> 00:26:50,159
still requires linear time

867
00:26:50,159 --> 00:26:51,360
so like I said this lower bound is

868
00:26:51,360 --> 00:26:52,559
pretty encompassing it holds even when

869
00:26:52,559 --> 00:26:54,840
peers have constant error and it holds

870
00:26:54,840 --> 00:26:58,158
in the multi-server setting as well

871
00:26:58,559 --> 00:27:00,600
um okay so one corollary of this is you

872
00:27:00,600 --> 00:27:02,220
could plug in k equals one to get a

873
00:27:02,220 --> 00:27:03,960
single query lower Bound in which case

874
00:27:03,960 --> 00:27:05,940
do we get T times R is equal to Omega n

875
00:27:05,940 --> 00:27:08,400
and this immediately improves upon the

876
00:27:08,400 --> 00:27:09,840
prior single query lower Bound by poly

877
00:27:09,840 --> 00:27:12,120
login factors by Corgan Gibson kogan and

878
00:27:12,120 --> 00:27:14,100
in fact this is exactly tight because if

879
00:27:14,100 --> 00:27:15,299
there's one construction of Corrigan

880
00:27:15,299 --> 00:27:17,460
Gibbs and kogan if you look at the sort

881
00:27:17,460 --> 00:27:19,740
of the parameters carefully you can

882
00:27:19,740 --> 00:27:21,000
actually construct something where T

883
00:27:21,000 --> 00:27:22,740
times R is equal to order n upper bound

884
00:27:22,740 --> 00:27:26,000
so this is a tight lower about

885
00:27:26,100 --> 00:27:29,159
okay so I'm telling you lower bounds but

886
00:27:29,159 --> 00:27:30,419
I didn't tell you the model I'm proving

887
00:27:30,419 --> 00:27:32,820
them in so let me try to you know pay my

888
00:27:32,820 --> 00:27:35,820
debts in the standard peer model this is

889
00:27:35,820 --> 00:27:37,200
different than the cell pro model so

890
00:27:37,200 --> 00:27:38,400
this is the standard pure model that was

891
00:27:38,400 --> 00:27:40,559
introduced by militia Malkin in 2000 and

892
00:27:40,559 --> 00:27:42,299
it essentially uses what's so called a

893
00:27:42,299 --> 00:27:43,919
non-encoding assumption

894
00:27:43,919 --> 00:27:46,080
in particular the server can only do

895
00:27:46,080 --> 00:27:48,360
sort of two permitted operations

896
00:27:48,360 --> 00:27:49,860
the first is they can arbitrarily

897
00:27:49,860 --> 00:27:51,779
replicate its database so you know you

898
00:27:51,779 --> 00:27:53,279
can take the database and copy it for a

899
00:27:53,279 --> 00:27:54,779
second copy

900
00:27:54,779 --> 00:27:56,100
the other thing is it can permute it

901
00:27:56,100 --> 00:27:57,299
arbitrarily

902
00:27:57,299 --> 00:27:58,679
but these are the only two operations

903
00:27:58,679 --> 00:28:00,059
that are permitted in particular

904
00:28:00,059 --> 00:28:01,260
something that's not permitted is

905
00:28:01,260 --> 00:28:02,940
arbitrary encoding so you can't store

906
00:28:02,940 --> 00:28:05,520
the xor of blocks in a

907
00:28:05,520 --> 00:28:08,480
in any place

908
00:28:08,640 --> 00:28:10,380
um okay so this is what the servers

909
00:28:10,380 --> 00:28:12,059
restrictions are I'll note that the

910
00:28:12,059 --> 00:28:13,380
client has no restrictions so the hint

911
00:28:13,380 --> 00:28:14,820
can be have arbitrary coding if you do

912
00:28:14,820 --> 00:28:16,020
whatever you want it just has to be at

913
00:28:16,020 --> 00:28:18,240
most arbits long

914
00:28:18,240 --> 00:28:20,640
so again leveraging off my previous talk

915
00:28:20,640 --> 00:28:22,140
I can compare the standard pure model

916
00:28:22,140 --> 00:28:24,240
with the cell probe model so in the

917
00:28:24,240 --> 00:28:25,440
standard pure model really what you're

918
00:28:25,440 --> 00:28:26,760
doing is replicating and permuting so

919
00:28:26,760 --> 00:28:28,559
each original block has to be stored as

920
00:28:28,559 --> 00:28:30,600
is in some any arbitrary location you

921
00:28:30,600 --> 00:28:32,580
want whereas in the Cell Pro Model over

922
00:28:32,580 --> 00:28:34,980
there I've thrown random equations there

923
00:28:34,980 --> 00:28:36,360
you could do whatever you want right you

924
00:28:36,360 --> 00:28:38,159
could store whatever you want

925
00:28:38,159 --> 00:28:40,200
so obviously you'd rather prove lower

926
00:28:40,200 --> 00:28:41,520
bounds in the cell probe model than the

927
00:28:41,520 --> 00:28:42,779
standard pure model because if the cell

928
00:28:42,779 --> 00:28:44,700
pro model is all encompassing whereas a

929
00:28:44,700 --> 00:28:46,320
standard peer model is a little let's

930
00:28:46,320 --> 00:28:48,360
say it's very restrictive even though it

931
00:28:48,360 --> 00:28:50,700
actually does cover a lot of known peer

932
00:28:50,700 --> 00:28:52,799
schemes

933
00:28:52,799 --> 00:28:54,600
so okay so one thing we actually prove

934
00:28:54,600 --> 00:28:57,900
in this uh in this paper is a barrier so

935
00:28:57,900 --> 00:28:59,580
this goal of trying to prove these lower

936
00:28:59,580 --> 00:29:01,020
bounds in the cell probe model will end

937
00:29:01,020 --> 00:29:02,700
up being extremely difficult because

938
00:29:02,700 --> 00:29:04,080
what we prove is that if you ended up

939
00:29:04,080 --> 00:29:05,640
doing this you proved the same lower

940
00:29:05,640 --> 00:29:07,559
down and sell pro model what you end up

941
00:29:07,559 --> 00:29:08,880
doing is proving that the online Matrix

942
00:29:08,880 --> 00:29:10,559
Vector conjecture is true

943
00:29:10,559 --> 00:29:11,880
so for those who don't know the online

944
00:29:11,880 --> 00:29:13,500
Matrix Vector conjecture is like a core

945
00:29:13,500 --> 00:29:15,179
tenant of fine green complexity people

946
00:29:15,179 --> 00:29:16,500
have been studying it for decades they

947
00:29:16,500 --> 00:29:18,120
have no clue how to prove it and I find

948
00:29:18,120 --> 00:29:19,860
it very unlikely that you end up proving

949
00:29:19,860 --> 00:29:21,539
it through pure lower bounds in other

950
00:29:21,539 --> 00:29:23,039
words this seems like a very fundamental

951
00:29:23,039 --> 00:29:24,299
barrier that would be hard for us to

952
00:29:24,299 --> 00:29:25,740
prove and that's why it makes sense to

953
00:29:25,740 --> 00:29:28,679
study the standard peer model as well

954
00:29:28,679 --> 00:29:30,360
all right so finally I guess one thing

955
00:29:30,360 --> 00:29:31,440
I'd like to notice to complement all

956
00:29:31,440 --> 00:29:32,640
these lower bounds we prove an upper

957
00:29:32,640 --> 00:29:34,380
bound saying essentially you can take a

958
00:29:34,380 --> 00:29:35,580
black box reduction from any single

959
00:29:35,580 --> 00:29:37,080
query Pier with private processing and

960
00:29:37,080 --> 00:29:39,240
construct a batch version of it with

961
00:29:39,240 --> 00:29:41,880
essentially K overhead and it's not too

962
00:29:41,880 --> 00:29:43,140
complicated it's just via batch codes

963
00:29:43,140 --> 00:29:44,880
but it's interesting because the prior

964
00:29:44,880 --> 00:29:46,799
reduction is known require either

965
00:29:46,799 --> 00:29:48,240
multiple rounds or certain assumptions

966
00:29:48,240 --> 00:29:49,740
on the single query scheme whereas ours

967
00:29:49,740 --> 00:29:53,100
is a black box sort of construction

968
00:29:53,100 --> 00:29:55,320
all right so I'm going to get into lower

969
00:29:55,320 --> 00:29:56,640
bound proof techniques now how do we

970
00:29:56,640 --> 00:29:58,500
actually prove this lower bound and we

971
00:29:58,500 --> 00:30:01,320
do this in three steps the first is what

972
00:30:01,320 --> 00:30:02,580
we're going to do is develop a

973
00:30:02,580 --> 00:30:04,260
relationship between queried and probe

974
00:30:04,260 --> 00:30:06,120
entries I'll go through exactly what a

975
00:30:06,120 --> 00:30:08,039
query and program entry is later the

976
00:30:08,039 --> 00:30:09,000
second thing is we're going to come up

977
00:30:09,000 --> 00:30:10,260
with a hard distribution which is

978
00:30:10,260 --> 00:30:12,299
discovering good batch queries and then

979
00:30:12,299 --> 00:30:13,620
finally like I said the standard

980
00:30:13,620 --> 00:30:14,940
Technique we always do improving lower

981
00:30:14,940 --> 00:30:16,860
bounds is find an impossible encoding of

982
00:30:16,860 --> 00:30:18,179
a database

983
00:30:18,179 --> 00:30:19,740
so because the last is sort of a

984
00:30:19,740 --> 00:30:20,820
standard technique using data structures

985
00:30:20,820 --> 00:30:22,080
I'm only going to focus on the first two

986
00:30:22,080 --> 00:30:25,380
in this talk due to lack of time

987
00:30:25,380 --> 00:30:27,960
all right so when uh we wanted what we

988
00:30:27,960 --> 00:30:29,039
want to do is develop a relationship

989
00:30:29,039 --> 00:30:31,140
between queried and probed entries so

990
00:30:31,140 --> 00:30:33,179
what is a queried entry well these are

991
00:30:33,179 --> 00:30:35,340
the query entries essentially these are

992
00:30:35,340 --> 00:30:36,360
the entries that you're given in your

993
00:30:36,360 --> 00:30:37,500
batch of queries that you want to

994
00:30:37,500 --> 00:30:40,080
retrieve that the user wants to retrieve

995
00:30:40,080 --> 00:30:42,360
and what are probed entries so probed

996
00:30:42,360 --> 00:30:44,159
entries are you know when you have this

997
00:30:44,159 --> 00:30:46,200
batch query you execute your peer scheme

998
00:30:46,200 --> 00:30:47,580
and you're going to end up sort of

999
00:30:47,580 --> 00:30:50,100
having to touch certain blocks in the

1000
00:30:50,100 --> 00:30:51,779
server memory and this is what we call

1001
00:30:51,779 --> 00:30:53,279
the probed entries

1002
00:30:53,279 --> 00:30:54,960
so here is where we're going to use the

1003
00:30:54,960 --> 00:30:56,880
standard pure model actually in

1004
00:30:56,880 --> 00:30:58,020
particular the standard pure model

1005
00:30:58,020 --> 00:31:00,000
allows the server or the adversary to

1006
00:31:00,000 --> 00:31:01,740
see that when you touch a certain block

1007
00:31:01,740 --> 00:31:04,320
you can correlate exactly to which entry

1008
00:31:04,320 --> 00:31:05,940
it was being touched so here I know the

1009
00:31:05,940 --> 00:31:07,740
second entry was being touched in the

1010
00:31:07,740 --> 00:31:09,059
Cell Pro Model we can't do this because

1011
00:31:09,059 --> 00:31:10,919
of for example this block could be the

1012
00:31:10,919 --> 00:31:12,419
xor of three different entries and I

1013
00:31:12,419 --> 00:31:13,559
wouldn't know which one to attribute it

1014
00:31:13,559 --> 00:31:15,059
to so we need the standard peer model

1015
00:31:15,059 --> 00:31:17,299
here

1016
00:31:17,700 --> 00:31:19,140
um okay

1017
00:31:19,140 --> 00:31:21,720
so all right I guess the whole point of

1018
00:31:21,720 --> 00:31:23,820
what we're trying to prove is now if 2

1019
00:31:23,820 --> 00:31:26,039
is let's say you have two which is in

1020
00:31:26,039 --> 00:31:27,960
the queried entry set what is the

1021
00:31:27,960 --> 00:31:30,480
probability that 2 is also probed on the

1022
00:31:30,480 --> 00:31:32,039
server side

1023
00:31:32,039 --> 00:31:33,480
so to do this what we're going to do is

1024
00:31:33,480 --> 00:31:34,440
make an assumption we're going to

1025
00:31:34,440 --> 00:31:36,240
suppose that the scheme Touches at most

1026
00:31:36,240 --> 00:31:38,279
half the entries in the database this is

1027
00:31:38,279 --> 00:31:39,539
without loss of generality because if

1028
00:31:39,539 --> 00:31:40,679
you touch the whole database every

1029
00:31:40,679 --> 00:31:41,700
single time we don't have we already

1030
00:31:41,700 --> 00:31:43,080
proved our lower bound

1031
00:31:43,080 --> 00:31:44,460
and the question we want to ask

1032
00:31:44,460 --> 00:31:46,500
essentially is if index I is queried

1033
00:31:46,500 --> 00:31:48,059
what is the probability that the if

1034
00:31:48,059 --> 00:31:51,139
entry is also probed

1035
00:31:51,720 --> 00:31:54,000
um so it turns out that it's not very

1036
00:31:54,000 --> 00:31:55,440
hard actually let's say we're taking

1037
00:31:55,440 --> 00:31:56,820
information theoretic approach to

1038
00:31:56,820 --> 00:31:59,640
privacy and you know here 2 is in the

1039
00:31:59,640 --> 00:32:01,500
query set but 2 is also in the probe set

1040
00:32:01,500 --> 00:32:03,120
but if you're considering information

1041
00:32:03,120 --> 00:32:06,000
theoretic privacy as soon as I flip two

1042
00:32:06,000 --> 00:32:07,380
to one

1043
00:32:07,380 --> 00:32:09,360
the server's view shouldn't change right

1044
00:32:09,360 --> 00:32:13,020
in which case essentially the set of

1045
00:32:13,020 --> 00:32:14,460
probed entries should also not change

1046
00:32:14,460 --> 00:32:15,840
with high probability otherwise the

1047
00:32:15,840 --> 00:32:17,820
server will be able to detect so this is

1048
00:32:17,820 --> 00:32:19,200
true information theoretically it turns

1049
00:32:19,200 --> 00:32:21,600
out it's not very hard to sort of put it

1050
00:32:21,600 --> 00:32:24,000
to the computational setting as well

1051
00:32:24,000 --> 00:32:25,740
so I said a lot of words what does this

1052
00:32:25,740 --> 00:32:27,480
really mean what I'm essentially saying

1053
00:32:27,480 --> 00:32:29,279
is the probability of whether index I is

1054
00:32:29,279 --> 00:32:31,200
probed is really it almost should be

1055
00:32:31,200 --> 00:32:32,399
independent to whether index I is

1056
00:32:32,399 --> 00:32:33,659
queried or not

1057
00:32:33,659 --> 00:32:35,039
so in particular the probability that

1058
00:32:35,039 --> 00:32:36,779
index is probe given that index high is

1059
00:32:36,779 --> 00:32:38,640
queried is nearly identical to the

1060
00:32:38,640 --> 00:32:40,020
probability of the index is probe given

1061
00:32:40,020 --> 00:32:41,520
the index I is not query in other words

1062
00:32:41,520 --> 00:32:43,260
whether index I is query or not should

1063
00:32:43,260 --> 00:32:45,899
not depend on whether it's probed

1064
00:32:45,899 --> 00:32:48,240
okay so why is this useful yes this

1065
00:32:48,240 --> 00:32:50,580
seems like a cool privacy result but it

1066
00:32:50,580 --> 00:32:52,080
turns out what you can end up doing is

1067
00:32:52,080 --> 00:32:54,600
now by applying markov's inequality you

1068
00:32:54,600 --> 00:32:56,100
can sort of see that the expected number

1069
00:32:56,100 --> 00:32:58,559
of indices that are queried that and

1070
00:32:58,559 --> 00:33:00,120
that are also probed

1071
00:33:00,120 --> 00:33:01,799
essentially is only going to be half so

1072
00:33:01,799 --> 00:33:04,500
half of the query entries will be probed

1073
00:33:04,500 --> 00:33:06,059
and this actually gives you a very neat

1074
00:33:06,059 --> 00:33:07,380
idea to do a compression scheme

1075
00:33:07,380 --> 00:33:08,340
essentially

1076
00:33:08,340 --> 00:33:09,899
so let's suppose again I have this batch

1077
00:33:09,899 --> 00:33:12,779
query I touch I only probe these entries

1078
00:33:12,779 --> 00:33:14,039
on the server

1079
00:33:14,039 --> 00:33:16,080
by correctness my peer scheme says

1080
00:33:16,080 --> 00:33:17,700
essentially that the client should be

1081
00:33:17,700 --> 00:33:20,220
able to retrieve all the entries in this

1082
00:33:20,220 --> 00:33:23,220
in the batch query in particular they

1083
00:33:23,220 --> 00:33:25,740
have to be able to retrieve entries that

1084
00:33:25,740 --> 00:33:27,059
were not probed

1085
00:33:27,059 --> 00:33:29,820
right in other words you're getting

1086
00:33:29,820 --> 00:33:31,440
these entries for free

1087
00:33:31,440 --> 00:33:34,019
almost right essentially all I have to

1088
00:33:34,019 --> 00:33:36,000
use is the probe entries and the hints

1089
00:33:36,000 --> 00:33:38,159
and magically I have a scheme that's

1090
00:33:38,159 --> 00:33:39,960
producing entries that I did not probe

1091
00:33:39,960 --> 00:33:42,179
and that you know that are just in the

1092
00:33:42,179 --> 00:33:43,799
query side

1093
00:33:43,799 --> 00:33:45,720
all right so this is what we want to do

1094
00:33:45,720 --> 00:33:46,740
in the lower bound we want to find

1095
00:33:46,740 --> 00:33:48,779
compression schemes so let's let's try

1096
00:33:48,779 --> 00:33:50,460
to push this right let's say we did it

1097
00:33:50,460 --> 00:33:52,320
once we ran one batch query we were able

1098
00:33:52,320 --> 00:33:55,320
to get B1 and B20 b223 for free

1099
00:33:55,320 --> 00:33:57,179
let's do it again right with this we

1100
00:33:57,179 --> 00:33:58,620
want to find a hard distribution we want

1101
00:33:58,620 --> 00:33:59,700
to be able to keep compressing the

1102
00:33:59,700 --> 00:34:01,799
database so we could run this again we

1103
00:34:01,799 --> 00:34:03,360
have another batch query

1104
00:34:03,360 --> 00:34:05,580
we run the pure scheme we find all the

1105
00:34:05,580 --> 00:34:07,500
program entries throw away everything

1106
00:34:07,500 --> 00:34:09,719
else now we have we use our Pure

1107
00:34:09,719 --> 00:34:12,119
protocol IE a compression scheme to get

1108
00:34:12,119 --> 00:34:14,339
more entries for free

1109
00:34:14,339 --> 00:34:16,980
all right so here's a bad example if I

1110
00:34:16,980 --> 00:34:18,780
if I just do this arbitrarily it's very

1111
00:34:18,780 --> 00:34:20,879
possible that the free entries I get are

1112
00:34:20,879 --> 00:34:22,260
the same every single time

1113
00:34:22,260 --> 00:34:24,000
right I'm not really compressing here

1114
00:34:24,000 --> 00:34:26,280
essentially so this is what I mean by

1115
00:34:26,280 --> 00:34:28,199
discovering good batch queries what we

1116
00:34:28,199 --> 00:34:30,239
really want to do is find a sequence of

1117
00:34:30,239 --> 00:34:32,099
batch queries that when you run it the

1118
00:34:32,099 --> 00:34:33,599
free entries that you get are minimally

1119
00:34:33,599 --> 00:34:36,119
overlapping over time

1120
00:34:36,119 --> 00:34:37,980
so for example that was a bad thing but

1121
00:34:37,980 --> 00:34:39,418
this would be a good one

1122
00:34:39,418 --> 00:34:41,099
if you say for example ran the scheme

1123
00:34:41,099 --> 00:34:44,580
again and you got B2 and b117 for free

1124
00:34:44,580 --> 00:34:46,379
so one of the this is one of the key

1125
00:34:46,379 --> 00:34:47,699
arguments we need to do in our paper and

1126
00:34:47,699 --> 00:34:49,619
essentially we prove that in fact if you

1127
00:34:49,619 --> 00:34:51,480
just do random batch queries it

1128
00:34:51,480 --> 00:34:52,859
satisfies this property with very high

1129
00:34:52,859 --> 00:34:54,239
it satisfies this property with very

1130
00:34:54,239 --> 00:34:56,520
high probability and the argument is via

1131
00:34:56,520 --> 00:34:59,820
some combatorial accounting arguments

1132
00:34:59,820 --> 00:35:01,560
all right so

1133
00:35:01,560 --> 00:35:03,000
given the first two steps what you're

1134
00:35:03,000 --> 00:35:04,020
now going to do is you have a

1135
00:35:04,020 --> 00:35:05,760
compression scheme each of these batch

1136
00:35:05,760 --> 00:35:07,500
queries is letting you encode free

1137
00:35:07,500 --> 00:35:09,300
entries for free and all you're going to

1138
00:35:09,300 --> 00:35:10,320
do is put it together and give an

1139
00:35:10,320 --> 00:35:11,820
impossible impossible encoding for the

1140
00:35:11,820 --> 00:35:12,660
database

1141
00:35:12,660 --> 00:35:13,980
and in a sense what I would like to

1142
00:35:13,980 --> 00:35:16,260
point out specifically is that you can

1143
00:35:16,260 --> 00:35:17,339
see that the compression scheme is

1144
00:35:17,339 --> 00:35:19,500
directly correlated to how many entries

1145
00:35:19,500 --> 00:35:21,720
you probe which is T and the size of the

1146
00:35:21,720 --> 00:35:23,040
hint which is r

1147
00:35:23,040 --> 00:35:24,960
so essentially this compression scheme

1148
00:35:24,960 --> 00:35:27,060
will take this TNR and if TNR are too

1149
00:35:27,060 --> 00:35:28,200
small it'll give you an impossible

1150
00:35:28,200 --> 00:35:31,140
encoding of the database essentially

1151
00:35:31,140 --> 00:35:34,320
um okay uh this is a very high level

1152
00:35:34,320 --> 00:35:36,060
sketch of the proof I encourage you to

1153
00:35:36,060 --> 00:35:37,320
take a look at the paper ask me any

1154
00:35:37,320 --> 00:35:38,640
questions if you have any more and I

1155
00:35:38,640 --> 00:35:40,920
think that's yeah you know thank you for

1156
00:35:40,920 --> 00:35:41,880
listening and if you have any questions

1157
00:35:41,880 --> 00:35:43,010
I'm happy to answer

1158
00:35:43,010 --> 00:35:48,780
[Applause]

1159
00:35:48,780 --> 00:35:52,280
is there any question from the audience

1160
00:35:56,700 --> 00:35:59,220
I was just wondering uh you said earlier

1161
00:35:59,220 --> 00:36:01,260
that if you could prove a lower Bound in

1162
00:36:01,260 --> 00:36:03,119
a Cell probe model then this this fancy

1163
00:36:03,119 --> 00:36:05,040
conjective would be true

1164
00:36:05,040 --> 00:36:07,500
um is there any hope of getting the

1165
00:36:07,500 --> 00:36:09,300
opposite I mean if that conductor was

1166
00:36:09,300 --> 00:36:10,619
true could you prove a law about this

1167
00:36:10,619 --> 00:36:12,060
I'll pro model is that just out of the

1168
00:36:12,060 --> 00:36:15,480
question uh very good question

1169
00:36:15,480 --> 00:36:16,619
um

1170
00:36:16,619 --> 00:36:18,420
so at a high level what we end up doing

1171
00:36:18,420 --> 00:36:20,099
is how to prove this lower bound is you

1172
00:36:20,099 --> 00:36:21,780
take the two server here

1173
00:36:21,780 --> 00:36:23,460
and essentially you notice there's like

1174
00:36:23,460 --> 00:36:24,960
the you know the very first one that

1175
00:36:24,960 --> 00:36:26,160
arranges it into square root and by

1176
00:36:26,160 --> 00:36:27,359
square root and Matrix and does matrix

1177
00:36:27,359 --> 00:36:29,040
Vector multiplication

1178
00:36:29,040 --> 00:36:30,420
so essentially what the online Matrix

1179
00:36:30,420 --> 00:36:31,920
Vector does is it proves that you can't

1180
00:36:31,920 --> 00:36:33,900
do this very fast but if you assume it's

1181
00:36:33,900 --> 00:36:35,880
false you get a very fast algorithm you

1182
00:36:35,880 --> 00:36:37,800
just plug it in directly so

1183
00:36:37,800 --> 00:36:39,119
I'm not sure the other way would hold

1184
00:36:39,119 --> 00:36:40,260
but it's a very interesting question to

1185
00:36:40,260 --> 00:36:41,400
see whether they're equivalent or not

1186
00:36:41,400 --> 00:36:43,020
actually it's a very very interesting

1187
00:36:43,020 --> 00:36:45,839
question I wouldn't know yeah

1188
00:36:45,839 --> 00:36:48,300
any other question

1189
00:36:48,300 --> 00:36:50,660
yeah

1190
00:36:50,839 --> 00:36:53,760
in your first talk you show the

1191
00:36:53,760 --> 00:36:55,560
framework do you have a framework for

1192
00:36:55,560 --> 00:36:58,500
your second talk like

1193
00:36:58,500 --> 00:37:01,920
I can see your conditions in your first

1194
00:37:01,920 --> 00:37:03,720
talk doesn't hold then more in the

1195
00:37:03,720 --> 00:37:05,400
second talk otherwise there's no point

1196
00:37:05,400 --> 00:37:08,700
for a second but uh good question

1197
00:37:08,700 --> 00:37:10,759
um

1198
00:37:11,400 --> 00:37:13,079
I'll get back to you I don't know I

1199
00:37:13,079 --> 00:37:14,339
actually don't know

1200
00:37:14,339 --> 00:37:17,579
um I guess for PIR other note weaker

1201
00:37:17,579 --> 00:37:20,280
Notions haven't really been studied in a

1202
00:37:20,280 --> 00:37:21,839
sense I think differentiate private

1203
00:37:21,839 --> 00:37:23,040
information retrieval has been studied

1204
00:37:23,040 --> 00:37:24,599
but I think you can actually construct

1205
00:37:24,599 --> 00:37:26,760
much better things there so it's very

1206
00:37:26,760 --> 00:37:28,440
possible like the reason the framework

1207
00:37:28,440 --> 00:37:29,940
worked is that

1208
00:37:29,940 --> 00:37:31,140
I don't know all around for some reason

1209
00:37:31,140 --> 00:37:32,520
whatever weaker privacy notion you try

1210
00:37:32,520 --> 00:37:33,839
like I've tried it always ends up being

1211
00:37:33,839 --> 00:37:34,980
logarithmic overhead that's why I end up

1212
00:37:34,980 --> 00:37:36,480
reviewing all these lower bounds but for

1213
00:37:36,480 --> 00:37:38,160
PIR maybe it's not the case so maybe you

1214
00:37:38,160 --> 00:37:39,119
couldn't even get this real I wouldn't

1215
00:37:39,119 --> 00:37:40,320
know actually it's a very good question

1216
00:37:40,320 --> 00:37:42,800
to explore

1217
00:37:43,980 --> 00:37:46,830
okay let's thank

1218
00:37:46,830 --> 00:37:51,600
[Applause]

1219
00:37:58,920 --> 00:38:01,099
foreign

1220
00:38:14,339 --> 00:38:17,339
yeah thank you so uh yeah how to

1221
00:38:17,339 --> 00:38:19,920
compress encrypted data and what do we

1222
00:38:19,920 --> 00:38:21,300
mean by that

1223
00:38:21,300 --> 00:38:22,859
basically the problem is the following

1224
00:38:22,859 --> 00:38:25,440
we have a very long list of encrypted

1225
00:38:25,440 --> 00:38:26,520
values

1226
00:38:26,520 --> 00:38:29,339
and what we want to do is basically take

1227
00:38:29,339 --> 00:38:31,980
this long list of encrypted values and

1228
00:38:31,980 --> 00:38:34,200
compress it down to a shorter list of

1229
00:38:34,200 --> 00:38:35,579
encrypted values

1230
00:38:35,579 --> 00:38:37,560
the problem is that information

1231
00:38:37,560 --> 00:38:39,960
theoretically in general this shouldn't

1232
00:38:39,960 --> 00:38:43,140
be possible right however we know a lot

1233
00:38:43,140 --> 00:38:45,119
about this Vector that we want to

1234
00:38:45,119 --> 00:38:47,160
compress there what we know about this

1235
00:38:47,160 --> 00:38:49,140
Vector is that most of the encryptions

1236
00:38:49,140 --> 00:38:51,240
are actually encryptions of zero

1237
00:38:51,240 --> 00:38:52,920
and that gives us a lot of structure to

1238
00:38:52,920 --> 00:38:53,880
work with

1239
00:38:53,880 --> 00:38:56,220
so what we want is that we can take this

1240
00:38:56,220 --> 00:38:58,079
Vector which is actually a vector that

1241
00:38:58,079 --> 00:38:59,820
contains mostly zeros we want to be able

1242
00:38:59,820 --> 00:39:01,440
to compress it without knowledge of the

1243
00:39:01,440 --> 00:39:04,260
secret key in such a way that at we end

1244
00:39:04,260 --> 00:39:05,880
at the end we can basically decompress

1245
00:39:05,880 --> 00:39:08,760
it again now knowing the secret key and

1246
00:39:08,760 --> 00:39:10,920
get the plain text Vector back including

1247
00:39:10,920 --> 00:39:12,720
all the zeros

1248
00:39:12,720 --> 00:39:15,240
so why would one want this well there

1249
00:39:15,240 --> 00:39:17,160
are many cryptographic protocols that

1250
00:39:17,160 --> 00:39:19,320
actually contain such a subprotocol

1251
00:39:19,320 --> 00:39:21,599
where they do this one example is

1252
00:39:21,599 --> 00:39:24,480
encrypted search for example in the

1253
00:39:24,480 --> 00:39:28,079
paper by Choi dachman zolet Gordon Liu

1254
00:39:28,079 --> 00:39:30,480
and Diego kimovich

1255
00:39:30,480 --> 00:39:31,140
um

1256
00:39:31,140 --> 00:39:34,260
where basically Alice has a large

1257
00:39:34,260 --> 00:39:36,599
database of encrypted values and

1258
00:39:36,599 --> 00:39:39,359
encrypted under a secret key that is

1259
00:39:39,359 --> 00:39:41,520
only known to Bob

1260
00:39:41,520 --> 00:39:43,980
now a bot basically sends encrypted

1261
00:39:43,980 --> 00:39:46,140
Search terms to Alice and Alice now

1262
00:39:46,140 --> 00:39:48,839
wants to give the results for this

1263
00:39:48,839 --> 00:39:50,640
search query

1264
00:39:50,640 --> 00:39:52,099
so this

1265
00:39:52,099 --> 00:39:54,480
encrypted these encrypted values they

1266
00:39:54,480 --> 00:39:55,920
are encrypted under a homomorphic

1267
00:39:55,920 --> 00:39:57,300
encryption scheme in this particular

1268
00:39:57,300 --> 00:39:59,220
application under a fully homomorphic

1269
00:39:59,220 --> 00:40:01,500
encryption scheme

1270
00:40:01,500 --> 00:40:03,359
um and Alice can basically filter this

1271
00:40:03,359 --> 00:40:05,280
very large database in such a way that

1272
00:40:05,280 --> 00:40:08,220
all the messages that do not match the

1273
00:40:08,220 --> 00:40:10,619
Search terms are set to zero and the

1274
00:40:10,619 --> 00:40:13,619
other ones are retained so if only very

1275
00:40:13,619 --> 00:40:15,900
few terms basically match the Search

1276
00:40:15,900 --> 00:40:18,480
terms we can now play apply the

1277
00:40:18,480 --> 00:40:21,480
compression scheme and what we get is a

1278
00:40:21,480 --> 00:40:23,760
much smaller message to send because

1279
00:40:23,760 --> 00:40:25,260
otherwise Alice would basically have to

1280
00:40:25,260 --> 00:40:26,820
send something that's in the size of the

1281
00:40:26,820 --> 00:40:28,800
entire database

1282
00:40:28,800 --> 00:40:30,780
uh one important thing here is that in

1283
00:40:30,780 --> 00:40:33,240
this compression step even though fhe

1284
00:40:33,240 --> 00:40:35,040
for example is used in this application

1285
00:40:35,040 --> 00:40:38,040
we do not want to use homomorphic

1286
00:40:38,040 --> 00:40:39,720
multiplication because that's expensive

1287
00:40:39,720 --> 00:40:42,180
so what we focus on is compression that

1288
00:40:42,180 --> 00:40:45,480
only uses an additive homomorphism

1289
00:40:45,480 --> 00:40:47,760
and on the receiving side Bob could now

1290
00:40:47,760 --> 00:40:50,460
just use a secret key to decompress and

1291
00:40:50,460 --> 00:40:54,060
learn what the matching Search terms are

1292
00:40:54,060 --> 00:40:56,940
okay so how could we be able to do

1293
00:40:56,940 --> 00:40:59,099
something like this

1294
00:40:59,099 --> 00:41:00,720
um there is a conceptually very simple

1295
00:41:00,720 --> 00:41:03,180
construction that is based on sparse

1296
00:41:03,180 --> 00:41:04,740
polynomials

1297
00:41:04,740 --> 00:41:06,960
basically we have our very long list of

1298
00:41:06,960 --> 00:41:09,599
ciphertext and we can interpret the

1299
00:41:09,599 --> 00:41:12,359
messages in those ciphertext as the

1300
00:41:12,359 --> 00:41:14,700
coefficients of a polynomial

1301
00:41:14,700 --> 00:41:17,160
and if we do that one thing we can note

1302
00:41:17,160 --> 00:41:19,380
is that since most of those encryptions

1303
00:41:19,380 --> 00:41:21,240
are encryptions of zero

1304
00:41:21,240 --> 00:41:23,460
this polynomial is very sparse it has

1305
00:41:23,460 --> 00:41:27,240
only very few non-zero coefficients

1306
00:41:27,240 --> 00:41:29,400
now there is a fact about polynomials

1307
00:41:29,400 --> 00:41:31,500
that most people who had high school

1308
00:41:31,500 --> 00:41:34,079
masses should know that if we have a

1309
00:41:34,079 --> 00:41:36,420
polynomial that is of degree T then you

1310
00:41:36,420 --> 00:41:39,000
can uniquely interpolate it from t plus

1311
00:41:39,000 --> 00:41:40,500
one points

1312
00:41:40,500 --> 00:41:43,500
there's a well a bit less known fact

1313
00:41:43,500 --> 00:41:45,720
about sparse polynomials that is very

1314
00:41:45,720 --> 00:41:47,820
similar if you have a polynomial that is

1315
00:41:47,820 --> 00:41:50,760
T sparse meaning that only T of the

1316
00:41:50,760 --> 00:41:53,099
coefficients are non-zero then we can

1317
00:41:53,099 --> 00:41:55,680
uniquely interpolate it from two t plus

1318
00:41:55,680 --> 00:41:57,420
two points so we need twice as many

1319
00:41:57,420 --> 00:42:00,599
points but um eight works

1320
00:42:00,599 --> 00:42:03,180
so how can we apply this here one thing

1321
00:42:03,180 --> 00:42:05,400
we can one way we can apply this is

1322
00:42:05,400 --> 00:42:07,380
taking this polynomial

1323
00:42:07,380 --> 00:42:09,900
evaluating it only uses an additive

1324
00:42:09,900 --> 00:42:12,900
homomorphism so if you need to add and

1325
00:42:12,900 --> 00:42:15,480
we need to multiply by constants

1326
00:42:15,480 --> 00:42:18,780
and so we can evaluate it on two t plus

1327
00:42:18,780 --> 00:42:20,700
two points

1328
00:42:20,700 --> 00:42:23,579
and now we have a list of ciphertext

1329
00:42:23,579 --> 00:42:27,480
that is has only length 2T plus two

1330
00:42:27,480 --> 00:42:30,119
so this is basically in O of T and we

1331
00:42:30,119 --> 00:42:31,920
can just view this as the compressed

1332
00:42:31,920 --> 00:42:35,339
form of our very long vector

1333
00:42:35,339 --> 00:42:36,900
and this compression is in fact

1334
00:42:36,900 --> 00:42:38,940
asymptotically optimal because we only

1335
00:42:38,940 --> 00:42:41,000
have o of T many

1336
00:42:41,000 --> 00:42:43,800
ciphertexts now and this is strictly

1337
00:42:43,800 --> 00:42:46,260
needed to convey

1338
00:42:46,260 --> 00:42:49,440
um of the well exactly T values

1339
00:42:49,440 --> 00:42:52,380
okay so how would this work then we

1340
00:42:52,380 --> 00:42:54,839
basically send this over to Bob in the

1341
00:42:54,839 --> 00:42:58,579
application and Bob can use decryption

1342
00:42:58,579 --> 00:43:03,119
to get well 2T plus two evaluations of

1343
00:43:03,119 --> 00:43:06,359
the polynomial and can then apply the

1344
00:43:06,359 --> 00:43:09,240
interpolation algorithm to get the full

1345
00:43:09,240 --> 00:43:12,000
plain text Vector back

1346
00:43:12,000 --> 00:43:14,640
now as I said the compression here is

1347
00:43:14,640 --> 00:43:17,040
actually asymptotically optimal the

1348
00:43:17,040 --> 00:43:20,040
computational costs are not quite so the

1349
00:43:20,040 --> 00:43:21,960
evaluation if we would do this

1350
00:43:21,960 --> 00:43:24,480
individually would be pretty expensive

1351
00:43:24,480 --> 00:43:26,220
we can do it more efficiently by

1352
00:43:26,220 --> 00:43:28,760
applying a fast free transformation

1353
00:43:28,760 --> 00:43:32,579
however it's still like it's fine but

1354
00:43:32,579 --> 00:43:35,579
not super efficient the interpolation on

1355
00:43:35,579 --> 00:43:38,640
the other hand is super expensive if we

1356
00:43:38,640 --> 00:43:41,579
try to do this what we end up with is a

1357
00:43:41,579 --> 00:43:43,500
cost that scales with the square root of

1358
00:43:43,500 --> 00:43:45,960
n where n is the size of the entire

1359
00:43:45,960 --> 00:43:47,400
database

1360
00:43:47,400 --> 00:43:49,140
since the database could be very very

1361
00:43:49,140 --> 00:43:52,020
large this can become impractical very

1362
00:43:52,020 --> 00:43:53,359
quickly

1363
00:43:53,359 --> 00:43:56,520
so this is a theoretically nice and

1364
00:43:56,520 --> 00:43:59,579
conceptually simple way to do it but we

1365
00:43:59,579 --> 00:44:00,960
would be looking for something more

1366
00:44:00,960 --> 00:44:03,300
efficient

1367
00:44:03,300 --> 00:44:05,579
so we have another solution that is

1368
00:44:05,579 --> 00:44:07,500
based on so-called invertible Bloom

1369
00:44:07,500 --> 00:44:10,020
lookup tables invertible room lookup

1370
00:44:10,020 --> 00:44:12,359
tables are a set membership data

1371
00:44:12,359 --> 00:44:14,579
structure that was first introduced by

1372
00:44:14,579 --> 00:44:16,440
Goodrich and mitsimahub

1373
00:44:16,440 --> 00:44:19,500
and the idea of it is basically that we

1374
00:44:19,500 --> 00:44:21,960
have a sequence of values say M1 through

1375
00:44:21,960 --> 00:44:23,940
M4 out there

1376
00:44:23,940 --> 00:44:25,920
and what we want to do is we want to

1377
00:44:25,920 --> 00:44:28,800
encode them in such a way that the size

1378
00:44:28,800 --> 00:44:30,839
of the encoding is independent of the

1379
00:44:30,839 --> 00:44:33,119
length of our sequence

1380
00:44:33,119 --> 00:44:36,540
but if our sequence is short enough then

1381
00:44:36,540 --> 00:44:39,900
we can completely decode it again

1382
00:44:39,900 --> 00:44:41,760
so how does an invertible Bloom lookup

1383
00:44:41,760 --> 00:44:44,220
table or an iblt work we basically have

1384
00:44:44,220 --> 00:44:45,900
in the simplest form we have two

1385
00:44:45,900 --> 00:44:48,300
matrices on the left hand side we have

1386
00:44:48,300 --> 00:44:50,099
our value Matrix on the right hand side

1387
00:44:50,099 --> 00:44:52,560
we have our account Matrix and for each

1388
00:44:52,560 --> 00:44:54,780
row in the matrices we have a separate

1389
00:44:54,780 --> 00:44:56,579
hash function

1390
00:44:56,579 --> 00:44:59,520
now if we want to set insert M1 into

1391
00:44:59,520 --> 00:45:02,579
this Matrix what we do is we plug M1

1392
00:45:02,579 --> 00:45:04,740
into the hash function the hash function

1393
00:45:04,740 --> 00:45:07,619
tells us a position in the row of the

1394
00:45:07,619 --> 00:45:10,619
Matrix and at this position or in the

1395
00:45:10,619 --> 00:45:13,920
value Matrix we just add M1 and in the

1396
00:45:13,920 --> 00:45:16,200
count Matrix we just increase the value

1397
00:45:16,200 --> 00:45:18,960
by one so we add one

1398
00:45:18,960 --> 00:45:21,480
so we do the same thing for M2 we do the

1399
00:45:21,480 --> 00:45:24,119
same thing for M3 and M4 and we end up

1400
00:45:24,119 --> 00:45:25,859
with this data structure

1401
00:45:25,859 --> 00:45:28,280
now we're supposed to be able to

1402
00:45:28,280 --> 00:45:31,859
decode this again how does that work we

1403
00:45:31,859 --> 00:45:33,960
just look for a one entry in the count

1404
00:45:33,960 --> 00:45:35,819
Matrix

1405
00:45:35,819 --> 00:45:38,099
at one entry in the count Matrix means

1406
00:45:38,099 --> 00:45:40,680
that only a single entry was put into

1407
00:45:40,680 --> 00:45:43,079
this position that means in the value

1408
00:45:43,079 --> 00:45:46,079
Matrix you will find something that was

1409
00:45:46,079 --> 00:45:48,119
actually in our original sequence that

1410
00:45:48,119 --> 00:45:49,920
we're trying to reconstruct

1411
00:45:49,920 --> 00:45:52,859
so we can take this value plug it back

1412
00:45:52,859 --> 00:45:54,780
into the hash functions we learn where

1413
00:45:54,780 --> 00:45:56,700
it was inserted in all of the rows of

1414
00:45:56,700 --> 00:46:00,599
the matrices and now we can remove it

1415
00:46:00,599 --> 00:46:02,520
so this helps because now we have more

1416
00:46:02,520 --> 00:46:04,380
one entries in our account Matrix so

1417
00:46:04,380 --> 00:46:07,319
that we can keep on going and decoding

1418
00:46:07,319 --> 00:46:09,420
this whole thing

1419
00:46:09,420 --> 00:46:12,720
so why is this helpful well

1420
00:46:12,720 --> 00:46:14,940
um all right so first of all this

1421
00:46:14,940 --> 00:46:16,740
successfully decodes with probability uh

1422
00:46:16,740 --> 00:46:18,720
one minus 2 to the minus Epsilon if

1423
00:46:18,720 --> 00:46:20,819
there are at most T elements in there

1424
00:46:20,819 --> 00:46:23,520
and this only requires addition and not

1425
00:46:23,520 --> 00:46:25,380
particularly many of them

1426
00:46:25,380 --> 00:46:27,780
so the idea is now that well can we just

1427
00:46:27,780 --> 00:46:31,200
do this under homomorphic encryption

1428
00:46:31,200 --> 00:46:33,900
the idea being that if we insert a very

1429
00:46:33,900 --> 00:46:37,319
long list of messages but most of them

1430
00:46:37,319 --> 00:46:40,920
are zero into this value Matrix it is

1431
00:46:40,920 --> 00:46:43,319
the same as if we had not inserted those

1432
00:46:43,319 --> 00:46:45,119
zero values at all as if we just

1433
00:46:45,119 --> 00:46:47,940
inserted a small number say t of

1434
00:46:47,940 --> 00:46:49,920
non-zero values

1435
00:46:49,920 --> 00:46:51,839
so we can try to do that

1436
00:46:51,839 --> 00:46:54,359
as a first attempt we can basically

1437
00:46:54,359 --> 00:46:57,540
first now look at the value Matrix uh on

1438
00:46:57,540 --> 00:47:00,180
its own we have now four ciphertexts

1439
00:47:00,180 --> 00:47:02,400
instead of four messages and we try to

1440
00:47:02,400 --> 00:47:05,520
insert them in there so we take C1 we

1441
00:47:05,520 --> 00:47:07,260
plug it into our hash functions we get

1442
00:47:07,260 --> 00:47:10,020
positions we add the ciphertext to the

1443
00:47:10,020 --> 00:47:12,960
corresponding positions and we do the

1444
00:47:12,960 --> 00:47:16,440
same thing for all of the other subjects

1445
00:47:16,440 --> 00:47:19,260
we send this thing now to Bob as the

1446
00:47:19,260 --> 00:47:21,660
encrypted version as the compressed

1447
00:47:21,660 --> 00:47:23,540
version of our very long

1448
00:47:23,540 --> 00:47:27,480
vector and Bob knows the secret key so

1449
00:47:27,480 --> 00:47:31,099
he can decrypt this

1450
00:47:31,380 --> 00:47:34,319
the nice thing is now that wherever

1451
00:47:34,319 --> 00:47:36,540
there's a zero so C2 for example here is

1452
00:47:36,540 --> 00:47:38,760
an encryption of zero basically this

1453
00:47:38,760 --> 00:47:40,740
message just disappears

1454
00:47:40,740 --> 00:47:42,060
in this

1455
00:47:42,060 --> 00:47:43,740
Center cell here

1456
00:47:43,740 --> 00:47:46,200
even though we inserted two ciphertexts

1457
00:47:46,200 --> 00:47:47,819
there after decryption there's only a

1458
00:47:47,819 --> 00:47:49,500
single message in there

1459
00:47:49,500 --> 00:47:51,660
so we could now try to remove it from

1460
00:47:51,660 --> 00:47:53,460
the data structure

1461
00:47:53,460 --> 00:47:56,700
the problem is that to know where we

1462
00:47:56,700 --> 00:47:59,060
need to remove it we need to now

1463
00:47:59,060 --> 00:48:01,619
put the correct thing back into the hash

1464
00:48:01,619 --> 00:48:03,960
functions but the hash functions took

1465
00:48:03,960 --> 00:48:06,960
the ciphertext C3 as input and we no

1466
00:48:06,960 --> 00:48:09,359
longer have C3 because well we did this

1467
00:48:09,359 --> 00:48:10,980
homomorphic computation so this

1468
00:48:10,980 --> 00:48:13,560
ciphertext is gone now

1469
00:48:13,560 --> 00:48:15,660
there's an additional problem which I

1470
00:48:15,660 --> 00:48:17,760
basically hit by not showing you that we

1471
00:48:17,760 --> 00:48:20,280
also need to compute account Matrix we

1472
00:48:20,280 --> 00:48:21,359
don't actually know how to do this

1473
00:48:21,359 --> 00:48:23,880
because we need to somehow identify

1474
00:48:23,880 --> 00:48:26,280
which of those cells only contain a

1475
00:48:26,280 --> 00:48:28,140
single value and if we were trying to

1476
00:48:28,140 --> 00:48:30,900
maintain a count Matrix we would need to

1477
00:48:30,900 --> 00:48:33,420
evaluate this predicate that tells me

1478
00:48:33,420 --> 00:48:35,880
that a message is non-zero

1479
00:48:35,880 --> 00:48:38,160
and we cannot easily do this on using

1480
00:48:38,160 --> 00:48:41,280
only an additive homomorphism

1481
00:48:41,280 --> 00:48:43,800
so what can we do

1482
00:48:43,800 --> 00:48:46,920
we use something else we use a a tool

1483
00:48:46,920 --> 00:48:48,900
that we call a Wunderbar pseudorandom

1484
00:48:48,900 --> 00:48:49,920
vector

1485
00:48:49,920 --> 00:48:53,339
and what it is is basically just a

1486
00:48:53,339 --> 00:48:55,800
vector that Associates an index with

1487
00:48:55,800 --> 00:48:57,359
pseudo-random values

1488
00:48:57,359 --> 00:48:59,339
so far that's pretty simple we can

1489
00:48:59,339 --> 00:49:01,079
easily do that we can just store a long

1490
00:49:01,079 --> 00:49:03,720
list of pseudo-random values however we

1491
00:49:03,720 --> 00:49:05,880
want it to be wonderba and that means

1492
00:49:05,880 --> 00:49:07,380
that it should have a short description

1493
00:49:07,380 --> 00:49:10,079
meaning it should basically only be

1494
00:49:10,079 --> 00:49:12,780
described by Lambda many bits and we

1495
00:49:12,780 --> 00:49:16,140
also want to be able to efficiently go

1496
00:49:16,140 --> 00:49:19,619
from the index to the pseudorandom value

1497
00:49:19,619 --> 00:49:22,140
and then from those pseudo-random values

1498
00:49:22,140 --> 00:49:24,300
which are actually unique so they don't

1499
00:49:24,300 --> 00:49:26,520
repeat in this sequence we want to be

1500
00:49:26,520 --> 00:49:28,800
able to go back to the index efficiently

1501
00:49:28,800 --> 00:49:30,420
as well

1502
00:49:30,420 --> 00:49:33,300
so how would we want to instantiate this

1503
00:49:33,300 --> 00:49:34,560
well

1504
00:49:34,560 --> 00:49:37,980
um if we ignore a bunch of details this

1505
00:49:37,980 --> 00:49:40,319
is essentially just a PRP

1506
00:49:40,319 --> 00:49:43,920
basically the PRP is described by a

1507
00:49:43,920 --> 00:49:46,380
short key of size for example security

1508
00:49:46,380 --> 00:49:49,079
parameter many bits and going from the

1509
00:49:49,079 --> 00:49:51,300
index to the pseudo-random value is just

1510
00:49:51,300 --> 00:49:53,700
applying the PRP and going back is just

1511
00:49:53,700 --> 00:49:55,260
inverting the PRP

1512
00:49:55,260 --> 00:49:56,819
so that works fine

1513
00:49:56,819 --> 00:49:59,460
so how does this help

1514
00:49:59,460 --> 00:50:01,440
now to the real deal the actual

1515
00:50:01,440 --> 00:50:04,920
construction we again have two matrices

1516
00:50:04,920 --> 00:50:08,160
and now we want to insert C1 again into

1517
00:50:08,160 --> 00:50:10,619
this data structure

1518
00:50:10,619 --> 00:50:13,680
what we do now is we don't hash C1

1519
00:50:13,680 --> 00:50:16,740
instead we only look at the index so we

1520
00:50:16,740 --> 00:50:17,880
hash one

1521
00:50:17,880 --> 00:50:20,339
we get positions on the left hand side

1522
00:50:20,339 --> 00:50:23,040
in the value Matrix we still just insert

1523
00:50:23,040 --> 00:50:24,540
the ciphertext

1524
00:50:24,540 --> 00:50:26,520
on the right hand side in what I will

1525
00:50:26,520 --> 00:50:30,180
call the key Matrix we insert K1 times

1526
00:50:30,180 --> 00:50:32,819
C1 so this is the ciphertext multiplied

1527
00:50:32,819 --> 00:50:34,920
by a constant

1528
00:50:34,920 --> 00:50:36,839
where the constant is just the field

1529
00:50:36,839 --> 00:50:38,099
value

1530
00:50:38,099 --> 00:50:39,180
um

1531
00:50:39,180 --> 00:50:42,300
The PRP applied to the index

1532
00:50:42,300 --> 00:50:44,520
so the PRP applied to one basically

1533
00:50:44,520 --> 00:50:47,040
gives us K1

1534
00:50:47,040 --> 00:50:49,140
and we do the same thing for all of the

1535
00:50:49,140 --> 00:50:50,579
other values

1536
00:50:50,579 --> 00:50:53,119
and now this is our compressed

1537
00:50:53,119 --> 00:50:56,160
representation of our vector and we send

1538
00:50:56,160 --> 00:50:58,559
this to Bob Bob still has a secret key

1539
00:50:58,559 --> 00:51:00,359
Bob can decrypt

1540
00:51:00,359 --> 00:51:02,640
so this still has the same nice property

1541
00:51:02,640 --> 00:51:05,819
if one of the messages in this case M2

1542
00:51:05,819 --> 00:51:08,640
is zero basically it just disappears

1543
00:51:08,640 --> 00:51:11,280
from this data structure in this Center

1544
00:51:11,280 --> 00:51:12,240
cell

1545
00:51:12,240 --> 00:51:14,220
we basically on the left hand side we

1546
00:51:14,220 --> 00:51:16,079
only have M3 left on the right hand side

1547
00:51:16,079 --> 00:51:19,740
also because we had K2 times M2 but M2

1548
00:51:19,740 --> 00:51:21,599
turned out to be zero well the whole

1549
00:51:21,599 --> 00:51:24,839
thing is zero so it just disappears

1550
00:51:24,839 --> 00:51:27,480
how can we now tell that this cell only

1551
00:51:27,480 --> 00:51:29,640
contains a single value

1552
00:51:29,640 --> 00:51:31,980
what we can do is we can take the value

1553
00:51:31,980 --> 00:51:35,040
in the right hand Matrix and we can

1554
00:51:35,040 --> 00:51:38,700
divide it by the corresponding value in

1555
00:51:38,700 --> 00:51:40,680
the left-hand Matrix

1556
00:51:40,680 --> 00:51:43,859
if there is only a single value in this

1557
00:51:43,859 --> 00:51:44,760
cell

1558
00:51:44,760 --> 00:51:49,500
what we will get is simply K3

1559
00:51:49,500 --> 00:51:51,720
in this specific case

1560
00:51:51,720 --> 00:51:55,500
and we can then apply the inversion the

1561
00:51:55,500 --> 00:52:00,000
um we can basically apply the PRP to get

1562
00:52:00,000 --> 00:52:02,400
back the index three

1563
00:52:02,400 --> 00:52:04,740
and then we can check if this index

1564
00:52:04,740 --> 00:52:08,099
falls into between 1 and n

1565
00:52:08,099 --> 00:52:10,020
and if there are more than one element

1566
00:52:10,020 --> 00:52:12,359
in this cell then with overwhelming

1567
00:52:12,359 --> 00:52:14,760
probability it will fall outside of this

1568
00:52:14,760 --> 00:52:16,859
range

1569
00:52:16,859 --> 00:52:20,339
therefore we can now say okay this falls

1570
00:52:20,339 --> 00:52:23,339
into this range so this is probably one

1571
00:52:23,339 --> 00:52:25,319
of the values we're looking for so now

1572
00:52:25,319 --> 00:52:27,240
we have the index of this value which

1573
00:52:27,240 --> 00:52:29,160
means we can plug this index back into

1574
00:52:29,160 --> 00:52:32,040
our hash function and we can then find

1575
00:52:32,040 --> 00:52:34,140
out what the positions are and remove

1576
00:52:34,140 --> 00:52:36,720
the value from our data structure

1577
00:52:36,720 --> 00:52:40,020
and this again frees up our matrices and

1578
00:52:40,020 --> 00:52:43,680
we can basically go on decoding it

1579
00:52:43,680 --> 00:52:47,040
and again this basically is successful

1580
00:52:47,040 --> 00:52:50,099
with probability roughly 1 minus 2 to

1581
00:52:50,099 --> 00:52:52,940
the minus Epsilon

1582
00:52:53,700 --> 00:52:57,059
and if we want to actually send this as

1583
00:52:57,059 --> 00:53:00,300
a an encoding of our ciphertext we have

1584
00:53:00,300 --> 00:53:02,220
to think about all the other things that

1585
00:53:02,220 --> 00:53:03,660
we need to send basically what we need

1586
00:53:03,660 --> 00:53:05,940
to send are these two matrices a

1587
00:53:05,940 --> 00:53:07,859
description of the PRP which is just the

1588
00:53:07,859 --> 00:53:10,380
PRP key but also these hash functions

1589
00:53:10,380 --> 00:53:12,119
but these hash functions can just be

1590
00:53:12,119 --> 00:53:14,280
replaced by a single prf so this is also

1591
00:53:14,280 --> 00:53:16,559
not a problem

1592
00:53:16,559 --> 00:53:19,319
okay so how does this compare to um

1593
00:53:19,319 --> 00:53:21,720
previous work as I said there are a

1594
00:53:21,720 --> 00:53:23,099
bunch of cryptographic protocols that

1595
00:53:23,099 --> 00:53:25,319
essentially contain something like this

1596
00:53:25,319 --> 00:53:27,480
as a subprotocol

1597
00:53:27,480 --> 00:53:31,500
and um the first one we have here is by

1598
00:53:31,500 --> 00:53:35,339
acavia Feldman and shall from 19. they

1599
00:53:35,339 --> 00:53:37,380
were basically able to compress to t

1600
00:53:37,380 --> 00:53:40,500
squared log n which isn't particularly

1601
00:53:40,500 --> 00:53:42,660
great because it still scales with the

1602
00:53:42,660 --> 00:53:44,819
size of the entire database and also t

1603
00:53:44,819 --> 00:53:47,220
squared can be pretty large if even for

1604
00:53:47,220 --> 00:53:48,980
modest sizes of t

1605
00:53:48,980 --> 00:53:51,420
and also compression and decompression

1606
00:53:51,420 --> 00:53:54,480
in that case is pretty expensive

1607
00:53:54,480 --> 00:53:57,839
then there was a work by Liu and trommer

1608
00:53:57,839 --> 00:54:00,180
they were basically able to do something

1609
00:54:00,180 --> 00:54:02,760
well comparatively much better they were

1610
00:54:02,760 --> 00:54:05,339
able to compress to Epsilon times t log

1611
00:54:05,339 --> 00:54:06,300
t

1612
00:54:06,300 --> 00:54:08,339
but still compression and decompression

1613
00:54:08,339 --> 00:54:10,980
is pretty bad

1614
00:54:10,980 --> 00:54:12,720
and then there's a work I already

1615
00:54:12,720 --> 00:54:16,500
mentioned by Troy Darkman Zola Gordon

1616
00:54:16,500 --> 00:54:19,980
Liu and uhmovich and they were able to

1617
00:54:19,980 --> 00:54:21,660
do something much better they were able

1618
00:54:21,660 --> 00:54:24,359
to basically get to Epsilon t as a

1619
00:54:24,359 --> 00:54:26,579
compression but also the compression and

1620
00:54:26,579 --> 00:54:28,440
decompression algorithms are much more

1621
00:54:28,440 --> 00:54:30,000
efficient

1622
00:54:30,000 --> 00:54:32,460
so this is basically the Baseline that

1623
00:54:32,460 --> 00:54:34,319
we're trying to break

1624
00:54:34,319 --> 00:54:37,380
um and our polynomial construction

1625
00:54:37,380 --> 00:54:39,839
um basically is much better in the

1626
00:54:39,839 --> 00:54:42,300
compression rate we only need to send o

1627
00:54:42,300 --> 00:54:44,280
of T many ciphertext

1628
00:54:44,280 --> 00:54:47,160
the compression is not terribly

1629
00:54:47,160 --> 00:54:48,960
efficient it is not

1630
00:54:48,960 --> 00:54:52,619
completely impossible but not great but

1631
00:54:52,619 --> 00:54:54,660
decompression is really bad this is

1632
00:54:54,660 --> 00:54:56,160
really inefficient like it's polynomial

1633
00:54:56,160 --> 00:54:57,660
time but

1634
00:54:57,660 --> 00:55:01,800
that's about it our iblt construction is

1635
00:55:01,800 --> 00:55:02,940
much better in the computational

1636
00:55:02,940 --> 00:55:04,500
department so the compression and

1637
00:55:04,500 --> 00:55:06,420
decompression are very efficient there

1638
00:55:06,420 --> 00:55:10,800
and our the size is smaller than the

1639
00:55:10,800 --> 00:55:13,579
best previously known Construction

1640
00:55:13,579 --> 00:55:16,619
basically so we divide by log T there

1641
00:55:16,619 --> 00:55:19,260
which makes it uh well for

1642
00:55:19,260 --> 00:55:21,960
more for some size of T that makes it

1643
00:55:21,960 --> 00:55:24,540
significantly smaller

1644
00:55:24,540 --> 00:55:27,900
and the very good news is that in very

1645
00:55:27,900 --> 00:55:30,000
recent work of the same authors that

1646
00:55:30,000 --> 00:55:32,579
will be on ePrint very soon we are

1647
00:55:32,579 --> 00:55:33,960
basically able to give a new

1648
00:55:33,960 --> 00:55:36,300
construction of iblts that is much more

1649
00:55:36,300 --> 00:55:38,280
space efficient and that allows us to

1650
00:55:38,280 --> 00:55:40,200
bring this size down to actually Epsilon

1651
00:55:40,200 --> 00:55:42,900
log Epsilon plus T so now we no longer

1652
00:55:42,900 --> 00:55:46,079
multiply Epsilon with t which basically

1653
00:55:46,079 --> 00:55:48,180
gives us a much better compression and

1654
00:55:48,180 --> 00:55:49,920
with that I'm done and if you have

1655
00:55:49,920 --> 00:55:52,340
questions I'm happy to answer them

1656
00:55:52,340 --> 00:55:58,859
[Applause]

1657
00:55:58,859 --> 00:56:00,780
uh is there any question from the

1658
00:56:00,780 --> 00:56:03,020
audience

1659
00:56:03,240 --> 00:56:06,000
hi uh very nice talk so I was wondering

1660
00:56:06,000 --> 00:56:08,579
first um what kind of requirement does

1661
00:56:08,579 --> 00:56:11,400
your compression technique need on the

1662
00:56:11,400 --> 00:56:13,440
underlying encryption scheme in addition

1663
00:56:13,440 --> 00:56:16,740
to being additive homomorphic

1664
00:56:16,740 --> 00:56:18,960
so it needs to be additively homomorphic

1665
00:56:18,960 --> 00:56:21,800
over some field technically

1666
00:56:21,800 --> 00:56:25,500
we need to be able uh so in this iBot

1667
00:56:25,500 --> 00:56:28,859
construction we need to be able to do

1668
00:56:28,859 --> 00:56:30,200
this

1669
00:56:30,200 --> 00:56:33,359
to do this division so we need that we

1670
00:56:33,359 --> 00:56:36,720
can actually divide by this value so we

1671
00:56:36,720 --> 00:56:39,059
need to be able to invert it so we need

1672
00:56:39,059 --> 00:56:42,480
it to be a field although something like

1673
00:56:42,480 --> 00:56:44,760
paella would work where we technically

1674
00:56:44,760 --> 00:56:46,380
work in a ring but because you cannot

1675
00:56:46,380 --> 00:56:48,599
detect that it's not a field you would

1676
00:56:48,599 --> 00:56:51,660
still be able to do it I see um and also

1677
00:56:51,660 --> 00:56:53,460
can you elaborate on the application

1678
00:56:53,460 --> 00:56:56,040
again because so typically with the

1679
00:56:56,040 --> 00:56:58,220
application of homomorphic encryption

1680
00:56:58,220 --> 00:57:01,079
only one party will have the ability to

1681
00:57:01,079 --> 00:57:04,079
decrypt so in this case

1682
00:57:04,079 --> 00:57:06,540
um at kind of one party will encrypt and

1683
00:57:06,540 --> 00:57:08,040
decree at the same time and the other

1684
00:57:08,040 --> 00:57:10,800
party does the evaluation but for the

1685
00:57:10,800 --> 00:57:13,020
decompression do you need the receiver

1686
00:57:13,020 --> 00:57:15,839
to also decrypt

1687
00:57:15,839 --> 00:57:18,420
so I'm not sure I completely understood

1688
00:57:18,420 --> 00:57:20,700
the question so the scenario is

1689
00:57:20,700 --> 00:57:22,740
basically that we have

1690
00:57:22,740 --> 00:57:24,839
in all of the scenarios with this

1691
00:57:24,839 --> 00:57:26,400
basically we have that we have two

1692
00:57:26,400 --> 00:57:28,500
parties one of them has a bunch of

1693
00:57:28,500 --> 00:57:30,960
encrypted values that it may for example

1694
00:57:30,960 --> 00:57:33,000
filter or maybe for some reason there

1695
00:57:33,000 --> 00:57:35,099
are already many zeros in there and the

1696
00:57:35,099 --> 00:57:37,559
other party has the secret key so on the

1697
00:57:37,559 --> 00:57:39,480
side that decompresses the secret key is

1698
00:57:39,480 --> 00:57:43,040
always known so and uh it is not

1699
00:57:43,040 --> 00:57:45,119
necessary for the compression to know

1700
00:57:45,119 --> 00:57:48,119
the secret key so this is just the setup

1701
00:57:48,119 --> 00:57:49,079
for it

1702
00:57:49,079 --> 00:57:51,599
I'm not sure I understood the question I

1703
00:57:51,599 --> 00:57:53,700
see yeah we can take it offline thank

1704
00:57:53,700 --> 00:57:56,359
you okay

1705
00:57:58,920 --> 00:58:00,780
um hi very nice presentation I was just

1706
00:58:00,780 --> 00:58:03,059
wondering if we can do this for but for

1707
00:58:03,059 --> 00:58:05,400
things that are not zeros like any other

1708
00:58:05,400 --> 00:58:08,460
number would it still work uh sorry I

1709
00:58:08,460 --> 00:58:10,800
couldn't so if we have encryptions of

1710
00:58:10,800 --> 00:58:13,079
ones so we have like a

1711
00:58:13,079 --> 00:58:14,640
a database where there's a lot of

1712
00:58:14,640 --> 00:58:15,960
encryptions of one instead of

1713
00:58:15,960 --> 00:58:17,280
encryptions of zero can we still

1714
00:58:17,280 --> 00:58:19,200
compress with that so you have lots of

1715
00:58:19,200 --> 00:58:21,480
encryption of one I mean maybe we can

1716
00:58:21,480 --> 00:58:23,280
just subtract one then I made a lot of

1717
00:58:23,280 --> 00:58:24,720
encryptions of zero and then we can do

1718
00:58:24,720 --> 00:58:26,220
the same thing and add one again I think

1719
00:58:26,220 --> 00:58:27,900
that should work so it's not like the

1720
00:58:27,900 --> 00:58:30,119
fine two I mean it it's I think if you

1721
00:58:30,119 --> 00:58:31,859
have it should be generalizable to

1722
00:58:31,859 --> 00:58:33,839
basically any particular value because

1723
00:58:33,839 --> 00:58:36,359
you can just shift things to zero and

1724
00:58:36,359 --> 00:58:40,759
then do the same thing all right thanks

1725
00:58:44,220 --> 00:58:46,140
oh thanks for the talk I wanted to

1726
00:58:46,140 --> 00:58:47,460
clarify

1727
00:58:47,460 --> 00:58:50,099
uh whether the party who compresses data

1728
00:58:50,099 --> 00:58:51,960
knows d

1729
00:58:51,960 --> 00:58:54,839
uh whether the party that compresses the

1730
00:58:54,839 --> 00:58:56,940
data knows how many non-zeroes there are

1731
00:58:56,940 --> 00:58:59,460
in the vector so there is basically we

1732
00:58:59,460 --> 00:59:01,980
need to know an upper bound on the

1733
00:59:01,980 --> 00:59:04,619
number of zeros you can do the same

1734
00:59:04,619 --> 00:59:07,380
thing if this upper bound is violated it

1735
00:59:07,380 --> 00:59:09,119
will just compression will probably will

1736
00:59:09,119 --> 00:59:10,799
fail with high probability in that case

1737
00:59:10,799 --> 00:59:13,260
in the case of the polynomial

1738
00:59:13,260 --> 00:59:15,299
construction it will fail with almost

1739
00:59:15,299 --> 00:59:17,160
certainty you will basically get

1740
00:59:17,160 --> 00:59:19,020
something completely different in the

1741
00:59:19,020 --> 00:59:22,020
iBot construction there is a chance that

1742
00:59:22,020 --> 00:59:24,420
you will get back the correct result but

1743
00:59:24,420 --> 00:59:26,760
the probability goes down significantly

1744
00:59:26,760 --> 00:59:29,640
as soon as you go beyond basically the

1745
00:59:29,640 --> 00:59:31,799
threshold and there so the party that

1746
00:59:31,799 --> 00:59:34,140
compresses data has no way to check

1747
00:59:34,140 --> 00:59:36,180
whether compression has worked right

1748
00:59:36,180 --> 00:59:38,460
they have no way to check it this is

1749
00:59:38,460 --> 00:59:40,500
basically this is basically how it why

1750
00:59:40,500 --> 00:59:42,900
it is possible to do this at all is

1751
00:59:42,900 --> 00:59:45,240
basically because normally when you do

1752
00:59:45,240 --> 00:59:48,839
compression right there is a

1753
00:59:48,839 --> 00:59:51,839
some things are getting get smaller some

1754
00:59:51,839 --> 00:59:53,400
things need to be expanded otherwise you

1755
00:59:53,400 --> 00:59:55,020
cannot do compression of arbitrary data

1756
00:59:55,020 --> 00:59:58,440
but this is not arbitrary data so we do

1757
00:59:58,440 --> 01:00:00,720
something else where we're just saying

1758
01:00:00,720 --> 01:00:03,000
that if basically the condition is

1759
01:00:03,000 --> 01:00:06,480
violated decompression will fail but the

1760
01:00:06,480 --> 01:00:08,940
com the person who compresses has no way

1761
01:00:08,940 --> 01:00:12,180
of knowing whether that happens or not

1762
01:00:12,180 --> 01:00:14,400
thank you

1763
01:00:14,400 --> 01:00:16,740
okay so let's thank all the speakers of

1764
01:00:16,740 --> 01:00:17,350
this session

1765
01:00:17,350 --> 01:00:24,509
[Applause]

