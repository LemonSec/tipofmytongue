1
00:00:02,580 --> 00:00:05,640
welcome back uh welcome to the Latin

2
00:00:05,640 --> 00:00:07,020
script analyst session the session

3
00:00:07,020 --> 00:00:09,380
you've all been waiting for

4
00:00:09,380 --> 00:00:12,360
uh and we're going to start with uh

5
00:00:12,360 --> 00:00:17,839
Xavier bolato on the work with Andrea

6
00:00:19,199 --> 00:00:23,520
thanks Leo for the introduction so this

7
00:00:23,520 --> 00:00:25,800
work is called defining many collisions

8
00:00:25,800 --> 00:00:27,900
we have Quantum works and application to

9
00:00:27,900 --> 00:00:30,779
the receiving and as the title said the

10
00:00:30,779 --> 00:00:34,620
aim is to obtain efficient algorithm to

11
00:00:34,620 --> 00:00:36,540
find many collisions in a Quantum

12
00:00:36,540 --> 00:00:37,500
setting

13
00:00:37,500 --> 00:00:41,160
so first of all I will present the

14
00:00:41,160 --> 00:00:44,040
classical landscape on collision finding

15
00:00:44,040 --> 00:00:47,219
before moving to Quantum algorithms on

16
00:00:47,219 --> 00:00:48,719
the oil Rock

17
00:00:48,719 --> 00:00:51,360
so how can we find the Collision

18
00:00:51,360 --> 00:00:52,800
classically

19
00:00:52,800 --> 00:00:56,579
so we are doing Collision finding in the

20
00:00:56,579 --> 00:00:58,079
random case so we assume we have a

21
00:00:58,079 --> 00:01:01,199
function f from n bit to n bit and we

22
00:01:01,199 --> 00:01:03,300
want to find the two colliding inputs so

23
00:01:03,300 --> 00:01:05,280
two different input that are mapped to

24
00:01:05,280 --> 00:01:07,320
the same output and there's a very

25
00:01:07,320 --> 00:01:09,540
simple algorithm that achieves that

26
00:01:09,540 --> 00:01:11,939
which is simple to take a large list

27
00:01:11,939 --> 00:01:15,020
with to do the n over to

28
00:01:15,020 --> 00:01:18,540
inputs and you sort it according to the

29
00:01:18,540 --> 00:01:20,700
output of the function and then you can

30
00:01:20,700 --> 00:01:22,979
efficiently extract conditions from the

31
00:01:22,979 --> 00:01:25,080
list so this works with one list but

32
00:01:25,080 --> 00:01:27,960
this also works with two list L1 and L2

33
00:01:27,960 --> 00:01:30,119
with the same technique so this is a

34
00:01:30,119 --> 00:01:32,759
very simple algorithm and there have

35
00:01:32,759 --> 00:01:34,860
been some improvements that have been

36
00:01:34,860 --> 00:01:37,680
proposed such as for example for our

37
00:01:37,680 --> 00:01:40,140
role Lambda method

38
00:01:40,140 --> 00:01:42,420
Etc these methods are better because

39
00:01:42,420 --> 00:01:44,420
there are memoryless there are parallel

40
00:01:44,420 --> 00:01:45,659
[Music]

41
00:01:45,659 --> 00:01:48,200
but in terms of

42
00:01:48,200 --> 00:01:51,540
complexity they roughly achieve the same

43
00:01:51,540 --> 00:01:54,240
cost as these very simple list based

44
00:01:54,240 --> 00:01:55,680
algorithm

45
00:01:55,680 --> 00:01:58,200
of course in practice these are the

46
00:01:58,200 --> 00:02:00,600
improved algorithms are the ones you

47
00:02:00,600 --> 00:02:02,820
want to work but if you only care about

48
00:02:02,820 --> 00:02:05,159
query complexity or

49
00:02:05,159 --> 00:02:07,560
even just total number of operations

50
00:02:07,560 --> 00:02:10,919
this simple algorithm

51
00:02:10,919 --> 00:02:13,920
does the same thing we can also have a

52
00:02:13,920 --> 00:02:16,020
look at slightly different settings for

53
00:02:16,020 --> 00:02:17,580
example if you want to find more than

54
00:02:17,580 --> 00:02:20,760
one condition say 2 to the T then you

55
00:02:20,760 --> 00:02:22,560
can just take a larger list if you

56
00:02:22,560 --> 00:02:24,180
multiply the list size by 2 to the T

57
00:02:24,180 --> 00:02:26,040
over 2 you can expect the list to

58
00:02:26,040 --> 00:02:27,599
contain to the thick addition and the

59
00:02:27,599 --> 00:02:29,640
same algorithm works

60
00:02:29,640 --> 00:02:33,360
if you have a function with an output

61
00:02:33,360 --> 00:02:35,760
size that is larger than its input size

62
00:02:35,760 --> 00:02:38,819
then it is harder to find Collision but

63
00:02:38,819 --> 00:02:41,400
the same approach still holds you take a

64
00:02:41,400 --> 00:02:44,280
larger list of size 2 to the 2 over 2

65
00:02:44,280 --> 00:02:46,739
plus M over 2 with M the number of

66
00:02:46,739 --> 00:02:49,379
output bits and it will contain the

67
00:02:49,379 --> 00:02:51,840
expect number of conditions we want two

68
00:02:51,840 --> 00:02:53,099
to the T

69
00:02:53,099 --> 00:02:55,080
and so these are

70
00:02:55,080 --> 00:02:57,540
some very simple list-based algorithm

71
00:02:57,540 --> 00:03:00,000
but there is a general query lower Bound

72
00:03:00,000 --> 00:03:03,300
for classical Collision finding which

73
00:03:03,300 --> 00:03:05,700
actually matches this algorithm

74
00:03:05,700 --> 00:03:09,120
that is in a classical setting if we

75
00:03:09,120 --> 00:03:10,739
only care about query complexity

76
00:03:10,739 --> 00:03:13,860
everything is solved by just taking a

77
00:03:13,860 --> 00:03:15,599
large enough list

78
00:03:15,599 --> 00:03:18,360
so now I remove to Quantum Computing

79
00:03:18,360 --> 00:03:20,220
where the things are a bit more

80
00:03:20,220 --> 00:03:21,780
complicated

81
00:03:21,780 --> 00:03:24,360
so first of all when we talk about

82
00:03:24,360 --> 00:03:27,239
Quantum collisions there's a one

83
00:03:27,239 --> 00:03:29,940
algorithm that comes to mind which is

84
00:03:29,940 --> 00:03:34,019
the bhc algorithm for basa or untap

85
00:03:34,019 --> 00:03:37,860
which is a Quantum Improvement overall

86
00:03:37,860 --> 00:03:40,920
this list based algorithm so the idea is

87
00:03:40,920 --> 00:03:43,860
still to take a large list

88
00:03:43,860 --> 00:03:46,560
but instead of looking for some

89
00:03:46,560 --> 00:03:49,080
Collision inside this list you look for

90
00:03:49,080 --> 00:03:52,980
just another input random that collides

91
00:03:52,980 --> 00:03:56,340
with one element on the list and you

92
00:03:56,340 --> 00:03:58,620
search for this input using Quantum

93
00:03:58,620 --> 00:04:01,980
search this because this will give you a

94
00:04:01,980 --> 00:04:04,620
quadratic speed up and so the cost of

95
00:04:04,620 --> 00:04:06,659
this algorithm is well two to the U in

96
00:04:06,659 --> 00:04:08,040
memory because you have this large

97
00:04:08,040 --> 00:04:10,260
classical list

98
00:04:10,260 --> 00:04:13,500
and Quantum you have two to the U which

99
00:04:13,500 --> 00:04:15,420
is the cost to construct the list plus

100
00:04:15,420 --> 00:04:17,579
the cost of the constant search which

101
00:04:17,579 --> 00:04:19,798
will be

102
00:04:19,798 --> 00:04:22,139
2 to the N over 2 to the U is the

103
00:04:22,139 --> 00:04:23,940
probability and you take the inverse of

104
00:04:23,940 --> 00:04:24,960
the probability and you take the square

105
00:04:24,960 --> 00:04:27,780
root of that and you can see that this

106
00:04:27,780 --> 00:04:31,740
balance is at 2 to the N over over three

107
00:04:31,740 --> 00:04:34,500
and if you want to find more than one

108
00:04:34,500 --> 00:04:36,720
Collision you can have pretty much the

109
00:04:36,720 --> 00:04:40,440
same approach but by taking a largest

110
00:04:40,440 --> 00:04:42,900
list so if you take a list of size to

111
00:04:42,900 --> 00:04:46,380
the N over three plus two thirds of t

112
00:04:46,380 --> 00:04:49,800
then you can do 2 to the T Quantum

113
00:04:49,800 --> 00:04:51,000
searches

114
00:04:51,000 --> 00:04:53,220
this search is records last and but

115
00:04:53,220 --> 00:04:56,400
there is more of them which will balance

116
00:04:56,400 --> 00:04:58,560
the cast with the fact that we had a

117
00:04:58,560 --> 00:05:02,220
larger list that is more expensive to

118
00:05:02,220 --> 00:05:04,139
to construct and we have an overall

119
00:05:04,139 --> 00:05:06,060
algorithm we've cast two to the end of

120
00:05:06,060 --> 00:05:08,280
our Free Press to cell of t

121
00:05:08,280 --> 00:05:12,000
and in a way that is very similar to the

122
00:05:12,000 --> 00:05:14,759
classical setting there is a general

123
00:05:14,759 --> 00:05:16,800
query Quantum lower bound that has been

124
00:05:16,800 --> 00:05:20,280
proposed by humans and Ray in 2019 which

125
00:05:20,280 --> 00:05:23,400
tells us that any Quantum algorithms

126
00:05:23,400 --> 00:05:26,759
that find two to the T conditions must

127
00:05:26,759 --> 00:05:28,800
have a cost of at least two to the MR3

128
00:05:28,800 --> 00:05:31,979
plus to third ft so this BHT algorithm

129
00:05:31,979 --> 00:05:34,740
and its variant actually match the lower

130
00:05:34,740 --> 00:05:37,740
bound when the output size is the same

131
00:05:37,740 --> 00:05:40,560
as the input size and now the question

132
00:05:40,560 --> 00:05:43,380
is what happens when the output is

133
00:05:43,380 --> 00:05:45,419
larger

134
00:05:45,419 --> 00:05:48,780
and if your put is larger so say you

135
00:05:48,780 --> 00:05:50,340
want to find one Collision

136
00:05:50,340 --> 00:05:52,860
you can still try to apply BHT algorithm

137
00:05:52,860 --> 00:05:56,039
with a larger list say of size to to the

138
00:05:56,039 --> 00:05:58,259
MR3 which is what the lower Bond will

139
00:05:58,259 --> 00:06:00,600
give you however there is an issue with

140
00:06:00,600 --> 00:06:04,080
larger output which is that you can't

141
00:06:04,080 --> 00:06:07,440
expect that for all inputs they will

142
00:06:07,440 --> 00:06:10,340
have there will be part of a collision

143
00:06:10,340 --> 00:06:13,680
only a small fraction of all the inputs

144
00:06:13,680 --> 00:06:17,100
are part of a collision so because we

145
00:06:17,100 --> 00:06:19,979
only have two to the two n minus n

146
00:06:19,979 --> 00:06:22,259
Collision

147
00:06:22,259 --> 00:06:26,160
overall on average and for the algorithm

148
00:06:26,160 --> 00:06:28,979
to work we need to have that in this

149
00:06:28,979 --> 00:06:32,039
list of size 2 to the MR3 there is at

150
00:06:32,039 --> 00:06:34,380
least one input which is actually part

151
00:06:34,380 --> 00:06:37,800
of a collision and if we compute the

152
00:06:37,800 --> 00:06:41,100
probability we'll see that this imposses

153
00:06:41,100 --> 00:06:43,680
a restriction on the output size

154
00:06:43,680 --> 00:06:47,520
that is the output size must be at most

155
00:06:47,520 --> 00:06:51,600
1.5 times the input size

156
00:06:51,600 --> 00:06:55,800
so of course if we are not in this case

157
00:06:55,800 --> 00:06:57,840
we can still make it work by taking a

158
00:06:57,840 --> 00:06:59,880
larger list but in this case we no

159
00:06:59,880 --> 00:07:02,280
longer match the the lower bound

160
00:07:02,280 --> 00:07:05,280
so if we want to summarize this

161
00:07:05,280 --> 00:07:07,680
algorithm so this is a graph where the

162
00:07:07,680 --> 00:07:10,380
horizontal axis is the output size

163
00:07:10,380 --> 00:07:12,720
relative to the input size so between n

164
00:07:12,720 --> 00:07:16,620
and 2m and the vertical axis is the

165
00:07:16,620 --> 00:07:19,740
number of collisions in logarithm scale

166
00:07:19,740 --> 00:07:22,800
so from one condition to 2 to the N

167
00:07:22,800 --> 00:07:27,139
collision and with the previous

168
00:07:27,240 --> 00:07:30,599
slides we've seen that BHT algorithm

169
00:07:30,599 --> 00:07:33,479
only tackle this blue triangle here

170
00:07:33,479 --> 00:07:36,300
where it matches the lower bound if we

171
00:07:36,300 --> 00:07:38,759
want to apply it outside of this

172
00:07:38,759 --> 00:07:41,039
triangle for example by taking larger

173
00:07:41,039 --> 00:07:45,419
list or by repeating the algorithm we

174
00:07:45,419 --> 00:07:47,759
can still have an algorithm that works

175
00:07:47,759 --> 00:07:49,740
but it would not be tight it will have

176
00:07:49,740 --> 00:07:51,960
this worst complexity of 2 to the K plus

177
00:07:51,960 --> 00:07:54,720
M minus the n

178
00:07:54,720 --> 00:07:57,599
now if we want to do better than that

179
00:07:57,599 --> 00:08:00,180
we'll have to slightly change the

180
00:08:00,180 --> 00:08:01,139
approach

181
00:08:01,139 --> 00:08:05,819
and use a Quantum algorithm that built

182
00:08:05,819 --> 00:08:09,120
upon Quantum Works framework that I will

183
00:08:09,120 --> 00:08:11,880
quickly present and to present Quantum

184
00:08:11,880 --> 00:08:13,560
work I will

185
00:08:13,560 --> 00:08:17,580
first present the classical analog which

186
00:08:17,580 --> 00:08:21,360
is classical random work and the ID is

187
00:08:21,360 --> 00:08:25,020
fairly simple you see your

188
00:08:25,020 --> 00:08:28,020
search space as a graph in which you

189
00:08:28,020 --> 00:08:30,360
have nodes you start at a random node

190
00:08:30,360 --> 00:08:32,820
and then you do a random work on the

191
00:08:32,820 --> 00:08:35,458
graph until you find a node that's good

192
00:08:35,458 --> 00:08:37,679
that is a node that contain the solution

193
00:08:37,679 --> 00:08:39,539
to your problem so here a node that

194
00:08:39,539 --> 00:08:42,120
contains a collision for example

195
00:08:42,120 --> 00:08:46,500
and if you have this

196
00:08:46,500 --> 00:08:50,100
framework then you can study your random

197
00:08:50,100 --> 00:08:52,920
work by introducing a few parameters so

198
00:08:52,920 --> 00:08:55,800
first of all well P which is the

199
00:08:55,800 --> 00:08:58,140
probability for a node to be good which

200
00:08:58,140 --> 00:09:00,420
will be important another important

201
00:09:00,420 --> 00:09:04,019
parameter is so one of our Epsilon so

202
00:09:04,019 --> 00:09:05,940
the inverse of the spectral gap which is

203
00:09:05,940 --> 00:09:09,420
a graph theoretic notion and the thing

204
00:09:09,420 --> 00:09:12,500
to have in mind is that it

205
00:09:12,500 --> 00:09:15,360
represents the number of steps of a

206
00:09:15,360 --> 00:09:19,320
Quantum work you need to do uh to go

207
00:09:19,320 --> 00:09:22,740
from one node to any other node so if

208
00:09:22,740 --> 00:09:25,800
you work one over Epsilon times you can

209
00:09:25,800 --> 00:09:28,440
reach any node in the graph

210
00:09:28,440 --> 00:09:31,440
and in terms of complexity we also have

211
00:09:31,440 --> 00:09:34,620
we have essentially three things we can

212
00:09:34,620 --> 00:09:37,680
do first we need to construct the first

213
00:09:37,680 --> 00:09:41,339
node to begin our work so this is cost s

214
00:09:41,339 --> 00:09:43,740
and then we have a course to work that

215
00:09:43,740 --> 00:09:46,260
we assume it is efficient

216
00:09:46,260 --> 00:09:48,899
and occurs to test whether or not a node

217
00:09:48,899 --> 00:09:51,839
is marked and from that we can construct

218
00:09:51,839 --> 00:09:54,600
an algorithm which is just start with a

219
00:09:54,600 --> 00:09:57,600
random node this will cost us s and then

220
00:09:57,600 --> 00:10:00,600
we repeat one of our P times

221
00:10:00,600 --> 00:10:03,180
a work from the node we are at one of

222
00:10:03,180 --> 00:10:06,980
our Epsilon times to arrived at another

223
00:10:06,980 --> 00:10:09,120
random node

224
00:10:09,120 --> 00:10:12,360
press a test to check if this new node

225
00:10:12,360 --> 00:10:14,160
that we've obtained is marked and so we

226
00:10:14,160 --> 00:10:16,920
obtain this complexity that's that's

227
00:10:16,920 --> 00:10:18,480
here

228
00:10:18,480 --> 00:10:21,180
and as an application we can do

229
00:10:21,180 --> 00:10:23,760
Collision finding in this framework

230
00:10:23,760 --> 00:10:28,560
so for that we will work on

231
00:10:28,560 --> 00:10:31,620
graph which is a Johnson graph this is a

232
00:10:31,620 --> 00:10:34,920
graph where nodes are sets of two to the

233
00:10:34,920 --> 00:10:38,640
error elements among 2 to the n and you

234
00:10:38,640 --> 00:10:42,360
work on this graph by removing one

235
00:10:42,360 --> 00:10:45,000
element in the set and replacing it by

236
00:10:45,000 --> 00:10:47,279
another element and this graph has a lot

237
00:10:47,279 --> 00:10:49,680
of nice properties and in particular

238
00:10:49,680 --> 00:10:52,140
it's Petrol gas is known and is roughly

239
00:10:52,140 --> 00:10:54,420
to the minus error which is fairly

240
00:10:54,420 --> 00:10:57,000
intuitive it means that if you do two to

241
00:10:57,000 --> 00:10:59,760
the air replacement on a set of size 2

242
00:10:59,760 --> 00:11:03,360
to the air you can obtain any set of

243
00:11:03,360 --> 00:11:05,579
sizes to do the error

244
00:11:05,579 --> 00:11:08,399
and if we do our work

245
00:11:08,399 --> 00:11:12,899
on on this Jensen graph it means that we

246
00:11:12,899 --> 00:11:14,700
have to create a random list of sites to

247
00:11:14,700 --> 00:11:16,980
the error which goes to the error and

248
00:11:16,980 --> 00:11:19,320
then we'll have to do a certain amount

249
00:11:19,320 --> 00:11:21,680
of times we work two to the air times

250
00:11:21,680 --> 00:11:24,180
and once we've arrived we've check

251
00:11:24,180 --> 00:11:26,640
whether the new node contains a career

252
00:11:26,640 --> 00:11:29,100
so the overall complexity is presented

253
00:11:29,100 --> 00:11:32,220
here and we have a trade-off between the

254
00:11:32,220 --> 00:11:34,620
size of the list and the number of work

255
00:11:34,620 --> 00:11:37,560
step we need to do in order to obtain a

256
00:11:37,560 --> 00:11:41,279
collision so 36 of size 2 to the air and

257
00:11:41,279 --> 00:11:43,440
the probability for a node to be marked

258
00:11:43,440 --> 00:11:47,940
is a two to the two error minus n and so

259
00:11:47,940 --> 00:11:50,519
we obtain this complexity here it is Max

260
00:11:50,519 --> 00:11:52,920
of 2 to the error and 2 to the N minus

261
00:11:52,920 --> 00:11:56,579
air which actually matches the

262
00:11:56,579 --> 00:11:59,579
complexity of a very simple classical

263
00:11:59,579 --> 00:12:03,120
algorithm which is take a list of size 2

264
00:12:03,120 --> 00:12:05,399
to the error if it contains a collision

265
00:12:05,399 --> 00:12:07,320
you have one otherwise

266
00:12:07,320 --> 00:12:10,440
drop the list and take another list

267
00:12:10,440 --> 00:12:13,500
so this algorithm is not that

268
00:12:13,500 --> 00:12:16,740
interesting however

269
00:12:16,740 --> 00:12:18,380
as it is

270
00:12:18,380 --> 00:12:23,279
presented in work random work framework

271
00:12:23,279 --> 00:12:26,760
we can improve it quantumly with Quantum

272
00:12:26,760 --> 00:12:30,240
works so the general idea of quantum

273
00:12:30,240 --> 00:12:33,839
work is to simulate a Quantum search on

274
00:12:33,839 --> 00:12:38,519
a graph using a work update operator

275
00:12:38,519 --> 00:12:41,820
and Associates has roughly the same

276
00:12:41,820 --> 00:12:44,700
parameters as classical work so here I

277
00:12:44,700 --> 00:12:47,779
present Quantum Market in the mnrs

278
00:12:47,779 --> 00:12:51,120
framework we use the same property as

279
00:12:51,120 --> 00:12:53,399
for classical work the only thing that

280
00:12:53,399 --> 00:12:57,360
changes is for the cost where

281
00:12:57,360 --> 00:13:00,720
we we have some gains due to Quantum

282
00:13:00,720 --> 00:13:03,959
search that is instead of having to

283
00:13:03,959 --> 00:13:06,779
iterate whenever P times we only iterate

284
00:13:06,779 --> 00:13:09,360
one of our square root of P times and

285
00:13:09,360 --> 00:13:12,420
instead of having to do a work one of

286
00:13:12,420 --> 00:13:14,579
our Epsilon times in order to obtain a

287
00:13:14,579 --> 00:13:17,579
random node we only need to do one of

288
00:13:17,579 --> 00:13:19,920
our square root of Epsilon

289
00:13:19,920 --> 00:13:24,060
updates in our algorithm so this gives

290
00:13:24,060 --> 00:13:26,639
us an improvement over the classical

291
00:13:26,639 --> 00:13:29,339
algorithm and if we want to find

292
00:13:29,339 --> 00:13:30,899
collisions

293
00:13:30,899 --> 00:13:33,180
in this framework then what we obtain is

294
00:13:33,180 --> 00:13:36,899
actually ambanese's algorithm

295
00:13:36,899 --> 00:13:39,420
so we have our function from n to n bit

296
00:13:39,420 --> 00:13:41,940
and we want to find a collision and to

297
00:13:41,940 --> 00:13:44,220
do so we do

298
00:13:44,220 --> 00:13:46,860
a Quantum work in a Johnson graph and so

299
00:13:46,860 --> 00:13:48,180
we have

300
00:13:48,180 --> 00:13:51,000
the same principles as for the classical

301
00:13:51,000 --> 00:13:53,639
work the only thing is that

302
00:13:53,639 --> 00:13:57,300
the cost will be lower so instead of two

303
00:13:57,300 --> 00:14:00,000
to the air and 2 to the m minus error we

304
00:14:00,000 --> 00:14:01,920
obtain a curse that that is the max of 2

305
00:14:01,920 --> 00:14:04,200
to the error and two to the

306
00:14:04,200 --> 00:14:06,360
square root of the classical cursor to

307
00:14:06,360 --> 00:14:10,139
the MR2 minus r over 2 and here this

308
00:14:10,139 --> 00:14:13,440
balance is at 2 to Z M over 3 which is

309
00:14:13,440 --> 00:14:16,079
actually optimal because it matches the

310
00:14:16,079 --> 00:14:18,180
quantum lower bound

311
00:14:18,180 --> 00:14:21,899
and now the question is what happens if

312
00:14:21,899 --> 00:14:24,420
we want to find more collisions so as a

313
00:14:24,420 --> 00:14:27,360
general ID is the same as classical ID

314
00:14:27,360 --> 00:14:29,940
take a larger list and then amortize it

315
00:14:29,940 --> 00:14:32,040
to find more collisions

316
00:14:32,040 --> 00:14:35,279
however there are some issues that is at

317
00:14:35,279 --> 00:14:36,899
the end of the quantum work

318
00:14:36,899 --> 00:14:39,420
we measure to obtain the collision and

319
00:14:39,420 --> 00:14:41,459
if we do so we destroy the quantum state

320
00:14:41,459 --> 00:14:44,100
so we cannot reuse this Quantum memory

321
00:14:44,100 --> 00:14:45,720
we would have to reconstruct it which is

322
00:14:45,720 --> 00:14:47,220
not efficient

323
00:14:47,220 --> 00:14:48,899
and so

324
00:14:48,899 --> 00:14:51,300
our aim is in this work is to have a

325
00:14:51,300 --> 00:14:53,399
procedure that allows us to extract

326
00:14:53,399 --> 00:14:56,660
Collision from the output of a

327
00:14:56,660 --> 00:14:59,639
magnificent work and still have a useful

328
00:14:59,639 --> 00:15:01,320
Quantum data structure that will allow

329
00:15:01,320 --> 00:15:05,339
us to extract more collisions afterwards

330
00:15:05,339 --> 00:15:07,380
and so for that we have to change a bit

331
00:15:07,380 --> 00:15:09,180
the way we

332
00:15:09,180 --> 00:15:13,260
do our work so we first begin with a

333
00:15:13,260 --> 00:15:15,839
minis's work normal Quantum work on a

334
00:15:15,839 --> 00:15:17,579
Johnson graph

335
00:15:17,579 --> 00:15:19,980
and then in the end when we have

336
00:15:19,980 --> 00:15:22,980
obtained the uniform superposition of

337
00:15:22,980 --> 00:15:25,139
nodes that contain a collision

338
00:15:25,139 --> 00:15:27,240
we do a partial measurement on the

339
00:15:27,240 --> 00:15:30,120
number of collisions that we have

340
00:15:30,120 --> 00:15:34,320
and we will remove reversibly from our

341
00:15:34,320 --> 00:15:36,839
Quantum data structure this number of

342
00:15:36,839 --> 00:15:38,040
collisions

343
00:15:38,040 --> 00:15:40,740
and that way and we measure these

344
00:15:40,740 --> 00:15:43,139
conditions and that way we will obtain

345
00:15:43,139 --> 00:15:47,220
still a Quantum state that is still a

346
00:15:47,220 --> 00:15:49,380
uniform superposition of quantum data

347
00:15:49,380 --> 00:15:51,180
structures but with a few constraints

348
00:15:51,180 --> 00:15:53,160
first of all as we've removed collisions

349
00:15:53,160 --> 00:15:57,139
there are Collision free and as we've

350
00:15:57,139 --> 00:16:00,120
removed some inputs that we've measured

351
00:16:00,120 --> 00:16:03,660
they do not contain it and from this

352
00:16:03,660 --> 00:16:07,320
Quantum State we can start a new Quantum

353
00:16:07,320 --> 00:16:10,500
work on a smaller Jensen graph which is

354
00:16:10,500 --> 00:16:14,100
the same as before but as we've removed

355
00:16:14,100 --> 00:16:16,019
some element in the set the sets are

356
00:16:16,019 --> 00:16:19,199
slightly smaller and the ambient set

357
00:16:19,199 --> 00:16:20,820
will be smaller because we don't want to

358
00:16:20,820 --> 00:16:24,120
walk back to the pre images we've we've

359
00:16:24,120 --> 00:16:25,380
removed

360
00:16:25,380 --> 00:16:28,320
and there are a few assumptions in the

361
00:16:28,320 --> 00:16:30,360
algorithm I've just presented the first

362
00:16:30,360 --> 00:16:32,699
one is that we have efficient history

363
00:16:32,699 --> 00:16:35,339
independent operations because in order

364
00:16:35,339 --> 00:16:37,920
to do a Quantum work we need to have a

365
00:16:37,920 --> 00:16:40,259
unique Quantum state that represents

366
00:16:40,259 --> 00:16:42,660
your node in your graph this means that

367
00:16:42,660 --> 00:16:46,320
the quantum State much not depend on the

368
00:16:46,320 --> 00:16:49,320
order in which you've removed and added

369
00:16:49,320 --> 00:16:50,880
elements

370
00:16:50,880 --> 00:16:53,759
and so to have efficient operations we

371
00:16:53,759 --> 00:16:55,860
use a data structure that's built about

372
00:16:55,860 --> 00:16:59,880
Radix 3 and to be history independent

373
00:16:59,880 --> 00:17:02,040
what we do is we have a Quantum memory

374
00:17:02,040 --> 00:17:03,720
layout which is actually the uniform

375
00:17:03,720 --> 00:17:06,000
superposition of all classical layouts

376
00:17:06,000 --> 00:17:09,959
so that way we have to turn the bit or

377
00:17:09,959 --> 00:17:12,599
take care on how we do the update but we

378
00:17:12,599 --> 00:17:14,339
can ensure that we have a unique Quantum

379
00:17:14,339 --> 00:17:15,599
state

380
00:17:15,599 --> 00:17:18,000
and the other assumption is that the

381
00:17:18,000 --> 00:17:20,640
next Quantum work needs to work and for

382
00:17:20,640 --> 00:17:22,079
that

383
00:17:22,079 --> 00:17:25,740
we this means that well first this is a

384
00:17:25,740 --> 00:17:27,419
technicality but the things we obtain

385
00:17:27,419 --> 00:17:30,440
after the measurement must be a node

386
00:17:30,440 --> 00:17:32,880
correspond to a node in an indigenson

387
00:17:32,880 --> 00:17:36,240
graph but also it must be okay to start

388
00:17:36,240 --> 00:17:38,580
from the nodes that do not contain any

389
00:17:38,580 --> 00:17:39,539
Collision

390
00:17:39,539 --> 00:17:41,220
and

391
00:17:41,220 --> 00:17:43,919
for this to be true we need to have that

392
00:17:43,919 --> 00:17:45,539
the superior position of collision free

393
00:17:45,539 --> 00:17:47,460
nodes is close to the uniforms

394
00:17:47,460 --> 00:17:49,559
preparation of all nodes another way to

395
00:17:49,559 --> 00:17:52,080
see it is that on average a node does

396
00:17:52,080 --> 00:17:53,700
not contain collisions node with

397
00:17:53,700 --> 00:17:55,860
collisions are only a small fraction and

398
00:17:55,860 --> 00:17:57,660
under this assumption

399
00:17:57,660 --> 00:18:00,299
our algorithm work and so if we come

400
00:18:00,299 --> 00:18:02,760
back to to the triangle we obtain this

401
00:18:02,760 --> 00:18:05,100
new result where we have this new red

402
00:18:05,100 --> 00:18:07,500
part in which we are optimal and as

403
00:18:07,500 --> 00:18:10,440
before we can extend it with slightly

404
00:18:10,440 --> 00:18:12,120
worse complexity in this smaller

405
00:18:12,120 --> 00:18:14,820
triangle the algorithm also works with

406
00:18:14,820 --> 00:18:17,460
golden Collision we can simply

407
00:18:17,460 --> 00:18:19,679
if we had an additional assumption it

408
00:18:19,679 --> 00:18:21,240
will also work

409
00:18:21,240 --> 00:18:22,679
and

410
00:18:22,679 --> 00:18:24,960
here the constraint on the number of

411
00:18:24,960 --> 00:18:27,480
collision is only the constraint on the

412
00:18:27,480 --> 00:18:29,160
number of golden Collision so our

413
00:18:29,160 --> 00:18:32,280
algorithm has less issues if we want

414
00:18:32,280 --> 00:18:34,919
golden Collision and finally I will

415
00:18:34,919 --> 00:18:37,020
shortly talk about Quantum lattice

416
00:18:37,020 --> 00:18:39,360
ceiling the general idea of ceiling is

417
00:18:39,360 --> 00:18:40,980
fairly simple you start with many

418
00:18:40,980 --> 00:18:43,620
vectors and you want to find some pairs

419
00:18:43,620 --> 00:18:45,960
such as there are several different or

420
00:18:45,960 --> 00:18:48,120
smaller norm and if you have enough pair

421
00:18:48,120 --> 00:18:50,039
you just iterate until you find the

422
00:18:50,039 --> 00:18:52,799
shortest vector there has been recently

423
00:18:52,799 --> 00:18:55,200
some work on Quantum that is seeming

424
00:18:55,200 --> 00:18:57,360
that do that with the quantum work and

425
00:18:57,360 --> 00:18:59,400
what they do is they use locality

426
00:18:59,400 --> 00:19:01,740
sensitive filtering which is an ID that

427
00:19:01,740 --> 00:19:03,660
comes from classical saving the idea is

428
00:19:03,660 --> 00:19:06,720
that you assume there is a code in the

429
00:19:06,720 --> 00:19:08,580
ambient space

430
00:19:08,580 --> 00:19:09,960
and

431
00:19:09,960 --> 00:19:13,559
close vectors that will whose form a

432
00:19:13,559 --> 00:19:16,799
pair that lead to a smaller Norm will

433
00:19:16,799 --> 00:19:19,559
stand if you have a code to decode to

434
00:19:19,559 --> 00:19:22,260
the same value and this means that we

435
00:19:22,260 --> 00:19:23,240
can reduce

436
00:19:23,240 --> 00:19:27,600
lattice ceiling to a problem of finding

437
00:19:27,600 --> 00:19:29,400
a collision and a function the function

438
00:19:29,400 --> 00:19:32,220
being the decoding of a code and of

439
00:19:32,220 --> 00:19:34,919
course we need some efficiently decoding

440
00:19:34,919 --> 00:19:36,000
code but this is what they do

441
00:19:36,000 --> 00:19:38,340
classically and as we have a better

442
00:19:38,340 --> 00:19:40,500
Quantum algorithm to find many

443
00:19:40,500 --> 00:19:42,780
collisions we can improve the previous

444
00:19:42,780 --> 00:19:45,379
algorithm

445
00:19:45,559 --> 00:19:48,260
so from an exponent of

446
00:19:48,260 --> 00:19:53,580
0.257 to a groundbreaking 0.2563

447
00:19:53,700 --> 00:19:56,940
which is an improvement of roughly a

448
00:19:56,940 --> 00:19:59,700
third of of a percent but this is the

449
00:19:59,700 --> 00:20:02,160
best known expression for lattice saving

450
00:20:02,160 --> 00:20:04,380
and this means we qualify for the Latin

451
00:20:04,380 --> 00:20:06,900
script analysis section thank you all

452
00:20:06,900 --> 00:20:09,500
for your attention

453
00:20:11,660 --> 00:20:15,589
[Applause]

454
00:20:16,559 --> 00:20:21,500
any very brief question for our speaker

455
00:20:25,620 --> 00:20:27,480
I have a Latin script analysis question

456
00:20:27,480 --> 00:20:29,160
okay

457
00:20:29,160 --> 00:20:32,640
um there was a lower bound of larvan and

458
00:20:32,640 --> 00:20:35,760
kershanova on those locally density

459
00:20:35,760 --> 00:20:38,760
bashing techniques and they claimed

460
00:20:38,760 --> 00:20:42,600
something for quantum

461
00:20:42,600 --> 00:20:46,200
that you disprove well it was already

462
00:20:46,200 --> 00:20:48,059
disproved by the previous Quantum

463
00:20:48,059 --> 00:20:51,179
algorithm they assumed Grover based

464
00:20:51,179 --> 00:20:53,340
algorithm and here we use a Quantum work

465
00:20:53,340 --> 00:20:55,200
so this is how we can beat the lower

466
00:20:55,200 --> 00:20:57,600
Bond and and if you apply their

467
00:20:57,600 --> 00:20:59,280
technique but to the more Journal

468
00:20:59,280 --> 00:21:00,960
framework do you think that you can get

469
00:21:00,960 --> 00:21:02,820
a lower bound as well

470
00:21:02,820 --> 00:21:07,340
I guess so but I have not studied that

471
00:21:10,320 --> 00:21:12,419
well if that's all let's move to the

472
00:21:12,419 --> 00:21:15,140
next speaker

473
00:21:26,220 --> 00:21:28,679
so the next tool will be given by Huck

474
00:21:28,679 --> 00:21:30,900
Bennett and it is joint work with Atul

475
00:21:30,900 --> 00:21:35,159
ganju Pura petal Tau y chai I'm very

476
00:21:35,159 --> 00:21:36,059
sorry

477
00:21:36,059 --> 00:21:38,960
and Noah Stefan davidovitz

478
00:21:38,960 --> 00:21:44,059
and hook is on the stage and ready

479
00:21:48,299 --> 00:21:50,280
okay so thank you very much for coming

480
00:21:50,280 --> 00:21:52,740
so I'll be talking about I am Puck I'll

481
00:21:52,740 --> 00:21:54,120
be talking about joint work with the

482
00:21:54,120 --> 00:21:57,480
Tool ganju uh Peter thawatai or both

483
00:21:57,480 --> 00:21:58,799
students at the time of this work

484
00:21:58,799 --> 00:22:01,260
undergraduate students and Noah Stevens

485
00:22:01,260 --> 00:22:04,340
davidowitz who's here

486
00:22:04,919 --> 00:22:06,900
um so I think probably most people in

487
00:22:06,900 --> 00:22:08,820
the audience know what a lettuce is so

488
00:22:08,820 --> 00:22:10,260
it's a regular grid of points in

489
00:22:10,260 --> 00:22:12,059
n-dimensional space or more formally

490
00:22:12,059 --> 00:22:14,940
it's the set of all uh integer linear

491
00:22:14,940 --> 00:22:17,039
combinations of some and linearly

492
00:22:17,039 --> 00:22:19,860
independent basis vectors and when we

493
00:22:19,860 --> 00:22:22,140
concatenate these vectors together to

494
00:22:22,140 --> 00:22:24,720
form The Columns of a matrix then we get

495
00:22:24,720 --> 00:22:27,720
a basis Matrix capital B

496
00:22:27,720 --> 00:22:30,240
so one thing that's important for this

497
00:22:30,240 --> 00:22:32,700
talk and just as a reminder so lattice

498
00:22:32,700 --> 00:22:35,820
bases are are typically not unique so if

499
00:22:35,820 --> 00:22:39,000
you're in at least two dimensions and in

500
00:22:39,000 --> 00:22:40,200
particular

501
00:22:40,200 --> 00:22:43,200
two bases generate the same lattice if

502
00:22:43,200 --> 00:22:45,299
you you can write multiply one of them

503
00:22:45,299 --> 00:22:47,820
by a unimodular matrix that is an

504
00:22:47,820 --> 00:22:50,340
integer Matrix whose determinant is plus

505
00:22:50,340 --> 00:22:51,960
or minus one to get the other major

506
00:22:51,960 --> 00:22:53,880
basis

507
00:22:53,880 --> 00:22:56,159
and the shortest Vector problem which is

508
00:22:56,159 --> 00:22:57,780
the most important computational problem

509
00:22:57,780 --> 00:23:01,020
on lattices is given a basis of a

510
00:23:01,020 --> 00:23:03,659
lattice's input to find a shortest

511
00:23:03,659 --> 00:23:06,179
non-zero Vector in the lattice that is a

512
00:23:06,179 --> 00:23:10,580
vector whose Norm is Lambda 1.

513
00:23:11,820 --> 00:23:13,620
so the problem that I'll be talking

514
00:23:13,620 --> 00:23:16,200
about today is the lattice isomorphism

515
00:23:16,200 --> 00:23:18,240
problem so intuitively with lattice

516
00:23:18,240 --> 00:23:20,460
isomorphism problem is it says you get

517
00:23:20,460 --> 00:23:22,740
two different lattices as inputs

518
00:23:22,740 --> 00:23:25,260
specified as bases and your goal is to

519
00:23:25,260 --> 00:23:27,360
determine whether one lattice is a

520
00:23:27,360 --> 00:23:30,000
rotation of the other in other words if

521
00:23:30,000 --> 00:23:31,500
there's an orthogonal linear

522
00:23:31,500 --> 00:23:34,740
transformation o that is a matrix you

523
00:23:34,740 --> 00:23:36,419
can think of this in terms of matrices

524
00:23:36,419 --> 00:23:39,000
as an O such that o transpose o is is

525
00:23:39,000 --> 00:23:42,059
the identity such that o times the first

526
00:23:42,059 --> 00:23:44,460
lattice L1 is equal to the second

527
00:23:44,460 --> 00:23:47,580
lattice L2 so here when we're specifying

528
00:23:47,580 --> 00:23:49,679
this in terms of bases we have both an o

529
00:23:49,679 --> 00:23:51,840
and a u so the question computational

530
00:23:51,840 --> 00:23:54,840
question is whether we can convert a

531
00:23:54,840 --> 00:23:58,440
basis B2 into B1 by left multiplying by

532
00:23:58,440 --> 00:24:00,840
by our rotation o and right multiplying

533
00:24:00,840 --> 00:24:05,959
by some U which is unimodular so

534
00:24:07,020 --> 00:24:09,120
so in in fact in this work we're even

535
00:24:09,120 --> 00:24:10,919
just going to consider a special case of

536
00:24:10,919 --> 00:24:12,600
this which has actually received a lot

537
00:24:12,600 --> 00:24:14,280
of attention particularly in the last

538
00:24:14,280 --> 00:24:15,960
couple of years so what we're going to

539
00:24:15,960 --> 00:24:17,700
do is we're going to fix the first

540
00:24:17,700 --> 00:24:19,919
lattice just to be the simplest lattice

541
00:24:19,919 --> 00:24:22,020
imaginable just the integer lat is the

542
00:24:22,020 --> 00:24:23,880
end so in other words you can think of

543
00:24:23,880 --> 00:24:26,280
B1 as just being i n the n-dimensional

544
00:24:26,280 --> 00:24:28,980
identity Matrix

545
00:24:28,980 --> 00:24:32,280
okay so here's kind of the picture so

546
00:24:32,280 --> 00:24:34,559
this this shows up I guess a reasonable

547
00:24:34,559 --> 00:24:37,260
size on the big screen so on the left we

548
00:24:37,260 --> 00:24:39,480
just have ZN again you can think of the

549
00:24:39,480 --> 00:24:41,159
basis as just being the standard normal

550
00:24:41,159 --> 00:24:44,280
basis and on the left so we have a yes

551
00:24:44,280 --> 00:24:46,679
instance of the problem so we have on

552
00:24:46,679 --> 00:24:48,720
the right we have some rotation of ZN

553
00:24:48,720 --> 00:24:53,000
along with a non-orthogonal basis of it

554
00:24:54,000 --> 00:24:56,760
so first algorithmic question

555
00:24:56,760 --> 00:24:59,039
is there an efficient algorithm for

556
00:24:59,039 --> 00:25:01,820
solving this problem

557
00:25:02,820 --> 00:25:04,919
so one thing to note here is it actually

558
00:25:04,919 --> 00:25:08,280
suffices to solve SVP on this class of

559
00:25:08,280 --> 00:25:11,100
of lattices on rotations of ZN because

560
00:25:11,100 --> 00:25:13,860
if we can find a shortest non-zero

561
00:25:13,860 --> 00:25:16,260
Vector in a rotation of ZN that'll be a

562
00:25:16,260 --> 00:25:18,120
unit vector and we can just project

563
00:25:18,120 --> 00:25:20,580
orthogonally from that and recurse and

564
00:25:20,580 --> 00:25:23,460
therefore recover all of O all

565
00:25:23,460 --> 00:25:26,120
the rotation

566
00:25:26,220 --> 00:25:28,260
so and then there's the the following

567
00:25:28,260 --> 00:25:30,600
cryptographic question which is okay say

568
00:25:30,600 --> 00:25:32,700
that say that this problem is in fact

569
00:25:32,700 --> 00:25:34,799
hard like there doesn't wind up being a

570
00:25:34,799 --> 00:25:36,600
fast algorithm for it then can we build

571
00:25:36,600 --> 00:25:38,700
some cool cryptography

572
00:25:38,700 --> 00:25:40,380
from this assumption

573
00:25:40,380 --> 00:25:41,940
so there's a whole bunch of related work

574
00:25:41,940 --> 00:25:43,799
on this some of which I'll mention again

575
00:25:43,799 --> 00:25:46,260
later but in terms of algorithms there's

576
00:25:46,260 --> 00:25:48,720
been work that's happened for for the

577
00:25:48,720 --> 00:25:51,360
last 20 years on this and including uh

578
00:25:51,360 --> 00:25:53,279
some recent work just in the last few

579
00:25:53,279 --> 00:25:55,460
years

580
00:25:55,559 --> 00:25:58,080
and in terms of cryptography sort of I

581
00:25:58,080 --> 00:26:00,000
think most people sort of started off

582
00:26:00,000 --> 00:26:01,440
thinking that okay this is an easy

583
00:26:01,440 --> 00:26:04,440
question this problem should be easy so

584
00:26:04,440 --> 00:26:06,419
it'd be silly to base cryptography on it

585
00:26:06,419 --> 00:26:09,179
but more recently we and and others have

586
00:26:09,179 --> 00:26:11,700
sort of taken the Assumption well as a

587
00:26:11,700 --> 00:26:13,500
spoiler for for the next couple of

588
00:26:13,500 --> 00:26:15,360
slides but we don't know any efficient

589
00:26:15,360 --> 00:26:16,980
algorithms for this problem

590
00:26:16,980 --> 00:26:19,260
I'll talk about that more but so okay

591
00:26:19,260 --> 00:26:20,880
say we run with this assumption that

592
00:26:20,880 --> 00:26:22,799
maybe this problem is in fact hard what

593
00:26:22,799 --> 00:26:25,520
can we do with it

594
00:26:26,580 --> 00:26:29,220
so results in our paper so the first

595
00:26:29,220 --> 00:26:32,400
result is approvable 2 to the N over two

596
00:26:32,400 --> 00:26:35,340
time algorithm for for zsvp and hence

597
00:26:35,340 --> 00:26:37,380
for zlip

598
00:26:37,380 --> 00:26:40,799
so and this is actually uh so it's still

599
00:26:40,799 --> 00:26:42,600
exponential but this is the first speed

600
00:26:42,600 --> 00:26:44,820
up or non-trivial speed up over just the

601
00:26:44,820 --> 00:26:46,500
fastest generic algorithm for the

602
00:26:46,500 --> 00:26:48,360
shortest Vector problem

603
00:26:48,360 --> 00:26:51,360
and um really the the core to our

604
00:26:51,360 --> 00:26:54,299
algorithm is a reduction from uh the

605
00:26:54,299 --> 00:26:56,460
exact shortest Vector problem on

606
00:26:56,460 --> 00:27:00,000
rotations of ZN zsvp to approximate

607
00:27:00,000 --> 00:27:02,640
unique SVP

608
00:27:02,640 --> 00:27:04,440
so we have a polynomial time reduction

609
00:27:04,440 --> 00:27:08,400
from exact zsvp to gamma usbp for any

610
00:27:08,400 --> 00:27:11,779
constant gamma greater than

611
00:27:13,620 --> 00:27:14,640
and

612
00:27:14,640 --> 00:27:16,200
um just one thing to note here actually

613
00:27:16,200 --> 00:27:18,480
so the algorithmic result in our paper

614
00:27:18,480 --> 00:27:21,000
doesn't just work for solving SVP on

615
00:27:21,000 --> 00:27:23,100
rotations of ZN so it actually works for

616
00:27:23,100 --> 00:27:25,860
solving SVP on a much larger classes of

617
00:27:25,860 --> 00:27:28,020
lattices class of lattices called

618
00:27:28,020 --> 00:27:31,140
semi-stable lattices that don't have

619
00:27:31,140 --> 00:27:31,740
um

620
00:27:31,740 --> 00:27:36,299
two large Lambda 1.

621
00:27:36,299 --> 00:27:39,419
and um so in terms of cryptography we

622
00:27:39,419 --> 00:27:41,400
show how to build Secure Public key

623
00:27:41,400 --> 00:27:44,039
cryptography assuming hardness of worst

624
00:27:44,039 --> 00:27:48,659
case variance of of zsvp

625
00:27:48,659 --> 00:27:53,400
and um finally we talk about we give a

626
00:27:53,400 --> 00:27:56,220
provably hard distribution of bases of

627
00:27:56,220 --> 00:27:58,440
rotations of ZN and give extensive

628
00:27:58,440 --> 00:28:01,559
experiments for for how hard it is to

629
00:28:01,559 --> 00:28:04,380
solve the shortest Vector problem on on

630
00:28:04,380 --> 00:28:06,299
lattices generating according to this

631
00:28:06,299 --> 00:28:08,340
distribution

632
00:28:08,340 --> 00:28:11,159
and um so the the hard distribution of

633
00:28:11,159 --> 00:28:13,860
bases we show is generated via discrete

634
00:28:13,860 --> 00:28:16,020
gaussian sampling and this sort of

635
00:28:16,020 --> 00:28:17,340
essentially resolves a question

636
00:28:17,340 --> 00:28:19,919
addressed by blanks and Miller in 21 who

637
00:28:19,919 --> 00:28:21,059
gave a whole bunch of different

638
00:28:21,059 --> 00:28:24,360
algorithms for generating uh bases hard

639
00:28:24,360 --> 00:28:26,820
bases of ZN

640
00:28:26,820 --> 00:28:28,679
so related work

641
00:28:28,679 --> 00:28:31,380
so in terms of algorithms things that

642
00:28:31,380 --> 00:28:33,840
are directly related to what to what I

643
00:28:33,840 --> 00:28:35,700
want to talk about here so Leo is

644
00:28:35,700 --> 00:28:37,799
sitting right here came up with an

645
00:28:37,799 --> 00:28:41,400
algorithm for solving zsvp that runs in

646
00:28:41,400 --> 00:28:44,279
the same time as the algorithm in in our

647
00:28:44,279 --> 00:28:46,500
paper so it runs in two to the N over

648
00:28:46,500 --> 00:28:47,940
two time but it uses different

649
00:28:47,940 --> 00:28:49,860
techniques and I think it's a really

650
00:28:49,860 --> 00:28:52,080
interesting question to see whether it's

651
00:28:52,080 --> 00:28:53,880
possible to combine our techniques and

652
00:28:53,880 --> 00:28:57,980
his techniques to do even better

653
00:28:58,320 --> 00:29:00,840
um in terms of cryptography Dukan van

654
00:29:00,840 --> 00:29:03,840
werten in in 2022 gave a chem rather

655
00:29:03,840 --> 00:29:05,580
than a public key crypto system but

656
00:29:05,580 --> 00:29:08,760
using similar assumptions and techniques

657
00:29:08,760 --> 00:29:10,500
and

658
00:29:10,500 --> 00:29:13,380
um so similarly a number of previous

659
00:29:13,380 --> 00:29:15,659
papers had explored this idea of using

660
00:29:15,659 --> 00:29:17,640
discrete gaussian sampling to generate

661
00:29:17,640 --> 00:29:19,679
hard lattice bases

662
00:29:19,679 --> 00:29:21,360
and just backing up here before I say

663
00:29:21,360 --> 00:29:23,820
any more details about what we did one

664
00:29:23,820 --> 00:29:25,919
thing that I'd like for you to take away

665
00:29:25,919 --> 00:29:28,740
from this talk as much as what we did is

666
00:29:28,740 --> 00:29:31,020
that this family of problems is really

667
00:29:31,020 --> 00:29:32,820
interesting and I think people should

668
00:29:32,820 --> 00:29:35,279
work on it more or just the family the

669
00:29:35,279 --> 00:29:37,320
sort of problems related to the lightest

670
00:29:37,320 --> 00:29:40,320
isomorphism problem and um specific

671
00:29:40,320 --> 00:29:42,419
special case of it where one lattice is

672
00:29:42,419 --> 00:29:44,460
fixed to bzn so if you think it's easy

673
00:29:44,460 --> 00:29:46,260
great Break It come up with a fast

674
00:29:46,260 --> 00:29:48,779
algorithm for it if you think it's hard

675
00:29:48,779 --> 00:29:52,940
then build some cool crypto from it

676
00:29:54,179 --> 00:29:56,940
okay so first let's start with our

677
00:29:56,940 --> 00:30:01,980
reduction and algorithm for for zsvp

678
00:30:01,980 --> 00:30:03,960
so I have a picture at the bottom which

679
00:30:03,960 --> 00:30:05,940
will sort of just shows the main idea

680
00:30:05,940 --> 00:30:07,620
behind our reduction

681
00:30:07,620 --> 00:30:10,260
but the main technique is that we use is

682
00:30:10,260 --> 00:30:14,039
lattice sparsification so we do here so

683
00:30:14,039 --> 00:30:16,080
this specification works for for

684
00:30:16,080 --> 00:30:18,299
arbitrary lattices but basically what

685
00:30:18,299 --> 00:30:19,860
you do is you have your input lattice

686
00:30:19,860 --> 00:30:22,020
and you sample a random sub lattice of

687
00:30:22,020 --> 00:30:24,080
your input lattice of some specified

688
00:30:24,080 --> 00:30:27,600
index say Prime index queue

689
00:30:27,600 --> 00:30:30,659
and the way you can do this is you just

690
00:30:30,659 --> 00:30:33,840
you define lq of a here so you look at

691
00:30:33,840 --> 00:30:37,460
just so if B is a basis of of your input

692
00:30:37,460 --> 00:30:41,940
lattice then you take the sub lattice

693
00:30:41,940 --> 00:30:44,940
which is formed by B of X such that all

694
00:30:44,940 --> 00:30:47,220
Co like the coefficient vectors X

695
00:30:47,220 --> 00:30:53,000
satisfy a random linear constraint mod Q

696
00:30:54,120 --> 00:30:56,220
and so our algorithm at a high level is

697
00:30:56,220 --> 00:31:00,120
actually quite simple what we do is we

698
00:31:00,120 --> 00:31:01,860
repeatedly do this we repeatedly

699
00:31:01,860 --> 00:31:04,380
sparksify our input lattice so starting

700
00:31:04,380 --> 00:31:06,000
over each time so we start with our

701
00:31:06,000 --> 00:31:07,799
endpoint lattice apply a random linear

702
00:31:07,799 --> 00:31:09,720
constraint to it to get a sub lattice

703
00:31:09,720 --> 00:31:14,100
and then we hope that what we get is uh

704
00:31:14,100 --> 00:31:16,440
an instance of approximate unique SVP

705
00:31:16,440 --> 00:31:18,360
I'll Define that in words in just a

706
00:31:18,360 --> 00:31:19,980
second but if you know what it is so we

707
00:31:19,980 --> 00:31:21,539
hope that we get an instance of

708
00:31:21,539 --> 00:31:25,140
approximate unique SVP as output we feed

709
00:31:25,140 --> 00:31:28,559
that into an oracle for for approximate

710
00:31:28,559 --> 00:31:32,399
unique SVP and if we did correctly in

711
00:31:32,399 --> 00:31:35,700
fact get a an instance of unique

712
00:31:35,700 --> 00:31:38,179
approximate Union SVP then we will have

713
00:31:38,179 --> 00:31:41,399
typically solved

714
00:31:41,399 --> 00:31:42,600
uh

715
00:31:42,600 --> 00:31:44,340
our original

716
00:31:44,340 --> 00:31:46,860
shortest Vector problem on a rotation of

717
00:31:46,860 --> 00:31:48,360
ZN so what we're going to do is we're

718
00:31:48,360 --> 00:31:50,100
going to specifically

719
00:31:50,100 --> 00:31:52,860
what we do is we

720
00:31:52,860 --> 00:31:54,059
um

721
00:31:54,059 --> 00:31:57,480
so we feed so we start with a rotation

722
00:31:57,480 --> 00:31:59,340
of ZN so that's what's shown on the left

723
00:31:59,340 --> 00:32:03,360
and so with this red circle shows is

724
00:32:03,360 --> 00:32:06,720
a circle or ball in general of radius

725
00:32:06,720 --> 00:32:09,419
like say it's slightly larger than two

726
00:32:09,419 --> 00:32:12,000
so between two and three so that's our

727
00:32:12,000 --> 00:32:15,179
gamma here so the shortest Vector in

728
00:32:15,179 --> 00:32:16,860
which is Lambda one the length of the

729
00:32:16,860 --> 00:32:19,740
shortest Vector in a rotation is u n

730
00:32:19,740 --> 00:32:22,380
non-zero vectors of course one

731
00:32:22,380 --> 00:32:26,100
so what our goal is for this algorithm

732
00:32:26,100 --> 00:32:28,620
is to sparsify away

733
00:32:28,620 --> 00:32:31,980
everything except for all non-zero

734
00:32:31,980 --> 00:32:35,940
vectors except for some shortest vector

735
00:32:35,940 --> 00:32:39,299
and integer combinations of it so if you

736
00:32:39,299 --> 00:32:40,919
see what's what's in this picture here

737
00:32:40,919 --> 00:32:43,620
so we keep on the right so this shows a

738
00:32:43,620 --> 00:32:46,200
success we keep one shortest Vector

739
00:32:46,200 --> 00:32:49,020
which is sort of the short red Vector

740
00:32:49,020 --> 00:32:52,380
there and we delete all other vectors

741
00:32:52,380 --> 00:32:54,720
inside this red circle that are linearly

742
00:32:54,720 --> 00:32:56,940
independent of it

743
00:32:56,940 --> 00:33:00,960
okay so this turns out to be an instance

744
00:33:00,960 --> 00:33:04,080
of say two or so unique SVP which is

745
00:33:04,080 --> 00:33:06,659
what we need so what is unique SVP so

746
00:33:06,659 --> 00:33:09,600
gamma unique SVP says that

747
00:33:09,600 --> 00:33:10,200
um

748
00:33:10,200 --> 00:33:12,000
if we have a vector v which is a

749
00:33:12,000 --> 00:33:14,820
shortest non-zero Vector in the lattice

750
00:33:14,820 --> 00:33:18,120
so it has Norm Lambda 1 then all vectors

751
00:33:18,120 --> 00:33:20,700
in the lattice that are linearly

752
00:33:20,700 --> 00:33:22,919
independent of it have Norm greater than

753
00:33:22,919 --> 00:33:25,919
gamma times Lambda 1.

754
00:33:25,919 --> 00:33:29,100
okay so specifically what what's

755
00:33:29,100 --> 00:33:31,260
summarized here is if we we have a

756
00:33:31,260 --> 00:33:34,980
success if when sparsifying we keep a

757
00:33:34,980 --> 00:33:36,720
shortest non-zero Vector in the lattice

758
00:33:36,720 --> 00:33:39,000
that is a unit vector and we delete we

759
00:33:39,000 --> 00:33:41,880
get rid of all other vectors of Norm

760
00:33:41,880 --> 00:33:45,360
less than gamma

761
00:33:45,360 --> 00:33:48,480
so if you just sort of check parameters

762
00:33:48,480 --> 00:33:50,640
and plug in known results

763
00:33:50,640 --> 00:33:52,159
then in fact

764
00:33:52,159 --> 00:33:55,140
for any constant gamma if you set

765
00:33:55,140 --> 00:33:57,299
parameters correctly you can get this to

766
00:33:57,299 --> 00:34:00,059
happen with noticeable probability so

767
00:34:00,059 --> 00:34:02,399
you only need to to iterate this process

768
00:34:02,399 --> 00:34:05,220
a polynomial number of times

769
00:34:05,220 --> 00:34:07,679
so the overall cost for our algorithm

770
00:34:07,679 --> 00:34:10,520
consists of a polynomial number of calls

771
00:34:10,520 --> 00:34:14,580
to a gamma usvp Oracle which we can

772
00:34:14,580 --> 00:34:18,480
instantiate with known results and get 2

773
00:34:18,480 --> 00:34:20,940
to the N over two time algorithm overall

774
00:34:20,940 --> 00:34:24,739
so I should say by combining a reduction

775
00:34:24,739 --> 00:34:26,780
from

776
00:34:26,780 --> 00:34:29,339
lubachevsky and machancho and an

777
00:34:29,339 --> 00:34:31,379
algorithm from agrawal to douche regab

778
00:34:31,379 --> 00:34:33,359
Stevens davidowitz we just get it to the

779
00:34:33,359 --> 00:34:36,119
N over two time algorithm for for like

780
00:34:36,119 --> 00:34:39,000
say two at usvp

781
00:34:39,000 --> 00:34:41,580
okay so that's that's what I want to say

782
00:34:41,580 --> 00:34:44,359
about the algorithm

783
00:34:44,820 --> 00:34:47,040
um so just I'll mention our crypto

784
00:34:47,040 --> 00:34:49,820
system briefly

785
00:34:49,859 --> 00:34:51,960
so for our crypto system we're just

786
00:34:51,960 --> 00:34:53,639
going to imagine that Alicia wants to

787
00:34:53,639 --> 00:34:56,760
send Bob one bit so we're just going to

788
00:34:56,760 --> 00:35:00,359
figure see how to encrypt one bit

789
00:35:00,359 --> 00:35:04,320
and here so we're going to be working on

790
00:35:04,320 --> 00:35:07,380
on a lattice which is a rotation of ZN

791
00:35:07,380 --> 00:35:10,619
and Alicia's public key is going to be a

792
00:35:10,619 --> 00:35:13,800
bad basis of L and Bob's private basis

793
00:35:13,800 --> 00:35:15,839
sorry private key is going to be an

794
00:35:15,839 --> 00:35:19,160
orthogonal basis a good basis event

795
00:35:19,160 --> 00:35:21,060
intuitively

796
00:35:21,060 --> 00:35:22,920
the way that Alicia is going to encrypt

797
00:35:22,920 --> 00:35:24,839
a bit so she's going to choose her

798
00:35:24,839 --> 00:35:27,660
ciphertext by sampling a random point in

799
00:35:27,660 --> 00:35:30,420
space so not a lattice point but some

800
00:35:30,420 --> 00:35:32,700
point in space

801
00:35:32,700 --> 00:35:34,380
and she's going to do this according to

802
00:35:34,380 --> 00:35:36,300
different distributions depending on

803
00:35:36,300 --> 00:35:38,460
whether she wants to encrypt 0 or 1. so

804
00:35:38,460 --> 00:35:40,200
intuitively if she wants to encrypt zero

805
00:35:40,200 --> 00:35:41,579
she's going to choose a point close to

806
00:35:41,579 --> 00:35:43,260
the lattice and if she wants to encrypt

807
00:35:43,260 --> 00:35:45,359
one she'll choose a point far from the

808
00:35:45,359 --> 00:35:47,220
lattice

809
00:35:47,220 --> 00:35:50,400
and then to decrypt Bob can just use

810
00:35:50,400 --> 00:35:53,040
round using his good orthogonal basis to

811
00:35:53,040 --> 00:35:55,859
compute the distance exactly of the

812
00:35:55,859 --> 00:35:57,960
ciphertext point to the lattice

813
00:35:57,960 --> 00:36:00,060
so I should say in our paper we actually

814
00:36:00,060 --> 00:36:02,400
specify everything in terms of quadratic

815
00:36:02,400 --> 00:36:04,859
forms rather than rotations of ZN which

816
00:36:04,859 --> 00:36:07,079
actually are nicer computationally so

817
00:36:07,079 --> 00:36:08,640
you don't have to work with rotations

818
00:36:08,640 --> 00:36:10,740
but this is this is what's going on but

819
00:36:10,740 --> 00:36:13,619
translated back into to lattices which I

820
00:36:13,619 --> 00:36:15,420
find a little bit easier to to think

821
00:36:15,420 --> 00:36:17,460
about but the math is actually better

822
00:36:17,460 --> 00:36:20,720
with quadratic forms

823
00:36:21,359 --> 00:36:22,140
um

824
00:36:22,140 --> 00:36:25,920
right so just looking at encryption more

825
00:36:25,920 --> 00:36:27,240
formally

826
00:36:27,240 --> 00:36:29,579
so I need one more lattice definition

827
00:36:29,579 --> 00:36:31,980
which is that of a fundamental parallel

828
00:36:31,980 --> 00:36:34,680
pipette of a lattice basis so the

829
00:36:34,680 --> 00:36:36,839
fundamental parallel pipette is just the

830
00:36:36,839 --> 00:36:39,660
set of all real

831
00:36:39,660 --> 00:36:42,660
linear combinations of the basis vectors

832
00:36:42,660 --> 00:36:44,700
where the coefficients are restricted to

833
00:36:44,700 --> 00:36:47,040
be between 0 and 1. so for example

834
00:36:47,040 --> 00:36:48,839
you've got a parallelogram like what's

835
00:36:48,839 --> 00:36:50,760
what's shown here in two dimensions and

836
00:36:50,760 --> 00:36:52,980
you get some higher dimensional analog

837
00:36:52,980 --> 00:36:55,920
in N dimensions

838
00:36:55,920 --> 00:36:57,720
okay so how does encryption work and

839
00:36:57,720 --> 00:36:59,400
again this is with respect to the bad

840
00:36:59,400 --> 00:37:01,740
basis

841
00:37:01,740 --> 00:37:04,859
so if Alice wants Alicia wants to to

842
00:37:04,859 --> 00:37:06,960
encrypt a zero what she does is she

843
00:37:06,960 --> 00:37:10,980
first samples a gaussian vector X so

844
00:37:10,980 --> 00:37:14,099
like from from a low variance spherical

845
00:37:14,099 --> 00:37:15,540
gaussian

846
00:37:15,540 --> 00:37:17,700
and then she takes it moduloed the

847
00:37:17,700 --> 00:37:19,980
parallel pipette which means that she

848
00:37:19,980 --> 00:37:22,500
shifts it by she shifts her her sampled

849
00:37:22,500 --> 00:37:25,500
X by lattice vectors until it lands in

850
00:37:25,500 --> 00:37:28,260
in P of B

851
00:37:28,260 --> 00:37:30,420
so there's it going to be a unique uh

852
00:37:30,420 --> 00:37:32,940
lattice Vector she can shift by to get

853
00:37:32,940 --> 00:37:36,660
her her sample the X into P of B

854
00:37:36,660 --> 00:37:39,420
and if she wants to encrypt one she

855
00:37:39,420 --> 00:37:42,119
simply samples a uniformly random Vector

856
00:37:42,119 --> 00:37:45,140
inside P of B

857
00:37:45,960 --> 00:37:48,060
Okay so

858
00:37:48,060 --> 00:37:51,180
it's easy to show that um

859
00:37:51,180 --> 00:37:53,040
in high Dimensions even though this

860
00:37:53,040 --> 00:37:55,980
might not be be clear in two dimensions

861
00:37:55,980 --> 00:37:57,660
there's highest statistical distance

862
00:37:57,660 --> 00:38:00,300
between the encryption distributions for

863
00:38:00,300 --> 00:38:04,500
for zero and one in the case when R is

864
00:38:04,500 --> 00:38:07,680
chosen to be uh sufficiently small and

865
00:38:07,680 --> 00:38:10,260
there's a tension between choosing R to

866
00:38:10,260 --> 00:38:12,359
be small in which case you get high

867
00:38:12,359 --> 00:38:13,980
statistical distance between these

868
00:38:13,980 --> 00:38:16,079
distributions and taking R to be larger

869
00:38:16,079 --> 00:38:17,400
which will lead to higher security

870
00:38:17,400 --> 00:38:19,500
because these two distributions will

871
00:38:19,500 --> 00:38:22,020
look similar so you can maybe sort of

872
00:38:22,020 --> 00:38:24,300
intuitively see that if you took a super

873
00:38:24,300 --> 00:38:26,700
high variance gaussian and took it

874
00:38:26,700 --> 00:38:28,320
modulo the parallel pipette it would

875
00:38:28,320 --> 00:38:30,180
look almost uniform and we actually have

876
00:38:30,180 --> 00:38:32,339
good tools for analyzing the exact

877
00:38:32,339 --> 00:38:34,200
statistical distance between these

878
00:38:34,200 --> 00:38:36,740
distributions

879
00:38:37,200 --> 00:38:40,619
um and um this crypto system is actually

880
00:38:40,619 --> 00:38:41,760
secure

881
00:38:41,760 --> 00:38:44,880
if provably secure if certain worst case

882
00:38:44,880 --> 00:38:47,579
problems that are related to zsvp are

883
00:38:47,579 --> 00:38:49,200
hard in the worst case

884
00:38:49,200 --> 00:38:51,240
so specifically

885
00:38:51,240 --> 00:38:54,660
this is is uh crypto system is provably

886
00:38:54,660 --> 00:38:57,000
secure if it's hard to distinguish a

887
00:38:57,000 --> 00:38:59,700
rotation of ZN from either a lattice

888
00:38:59,700 --> 00:39:02,460
who's with Lambda 1 greater than square

889
00:39:02,460 --> 00:39:04,099
root of n log n

890
00:39:04,099 --> 00:39:08,760
or a lattice that has a small smoothing

891
00:39:08,760 --> 00:39:12,060
parameter compared to ZN

892
00:39:12,060 --> 00:39:14,280
and just a couple of last slides so this

893
00:39:14,280 --> 00:39:17,460
is just building intuition for what the

894
00:39:17,460 --> 00:39:19,380
encryption distributions look like with

895
00:39:19,380 --> 00:39:22,500
respect to both the the good basis which

896
00:39:22,500 --> 00:39:24,240
is the secret key and the bad basis

897
00:39:24,240 --> 00:39:26,940
which is the public key so this is what

898
00:39:26,940 --> 00:39:30,119
if you're imagining sampling a gaussian

899
00:39:30,119 --> 00:39:31,560
just kind of around the origin and

900
00:39:31,560 --> 00:39:33,480
taking it modulo the square so here

901
00:39:33,480 --> 00:39:36,119
we're thinking of of Z2 itself you get

902
00:39:36,119 --> 00:39:37,740
something like this so this is a plot of

903
00:39:37,740 --> 00:39:40,740
the the PDF that you get so like the

904
00:39:40,740 --> 00:39:42,480
orange Parts showing that you get highly

905
00:39:42,480 --> 00:39:44,579
concentrated around around lattice

906
00:39:44,579 --> 00:39:46,680
points

907
00:39:46,680 --> 00:39:50,579
and yeah last slide and uh

908
00:39:50,579 --> 00:39:53,400
in in the the other case sort of if you

909
00:39:53,400 --> 00:39:55,859
have have a bad basis then then you get

910
00:39:55,859 --> 00:39:57,720
something like this and it's more mixed

911
00:39:57,720 --> 00:39:59,520
up where the

912
00:39:59,520 --> 00:40:01,619
um like when you're encrypting zero it's

913
00:40:01,619 --> 00:40:04,140
more mixed up where you are where you're

914
00:40:04,140 --> 00:40:07,680
uh ciphertext lands with respect to the

915
00:40:07,680 --> 00:40:10,560
corners of of the the parallelogram

916
00:40:10,560 --> 00:40:14,579
and to make Leo happy that's it

917
00:40:14,579 --> 00:40:17,960
no that's the end anyway

918
00:40:19,020 --> 00:40:24,639
[Applause]

919
00:40:24,720 --> 00:40:27,180
listen to half an hour more of that but

920
00:40:27,180 --> 00:40:29,339
unfortunately we have come straight a

921
00:40:29,339 --> 00:40:32,240
quick question for her

922
00:40:38,760 --> 00:40:40,440
actually it's a good paper I don't have

923
00:40:40,440 --> 00:40:44,579
questions yeah ah yes thank you

924
00:40:44,579 --> 00:40:46,940
please

925
00:40:52,040 --> 00:40:55,680
yeah so you can see so here you can

926
00:40:55,680 --> 00:40:57,839
imagine that if you sort of if you shift

927
00:40:57,839 --> 00:41:00,720
this parallelogram around bio lattice

928
00:41:00,720 --> 00:41:02,880
points then you'll tile wall of space

929
00:41:02,880 --> 00:41:05,700
and in fact each point in our end will

930
00:41:05,700 --> 00:41:09,240
uniquely lie in some shift of

931
00:41:09,240 --> 00:41:11,700
the parallel piping so what that means

932
00:41:11,700 --> 00:41:13,740
is that if you sample an arbitrary point

933
00:41:13,740 --> 00:41:15,300
in our end then there will be a unique

934
00:41:15,300 --> 00:41:17,579
lattice Vector you can shift by to put

935
00:41:17,579 --> 00:41:21,839
that point which is like X here into P

936
00:41:21,839 --> 00:41:23,880
of B oh I see so does that mean that

937
00:41:23,880 --> 00:41:26,400
you're not associating each point in the

938
00:41:26,400 --> 00:41:28,680
overall Vector space with a specific

939
00:41:28,680 --> 00:41:31,320
point within your parallel pipette

940
00:41:31,320 --> 00:41:32,940
um well there's like a class of points

941
00:41:32,940 --> 00:41:35,760
like it'll be like uh um like a co-set

942
00:41:35,760 --> 00:41:37,740
of the or something that all get maps to

943
00:41:37,740 --> 00:41:40,680
the same yeah point in in p

944
00:41:40,680 --> 00:41:43,740
pu yeah but like just the the support of

945
00:41:43,740 --> 00:41:46,140
both of these distributions like of the

946
00:41:46,140 --> 00:41:47,940
encryption of zero and the encryption of

947
00:41:47,940 --> 00:41:51,680
one is just P of B itself

948
00:41:53,160 --> 00:41:55,380
again it's given in terms of quadratic

949
00:41:55,380 --> 00:41:56,820
form so it looks a little different in

950
00:41:56,820 --> 00:41:58,619
our paper but it's the same thing just

951
00:41:58,619 --> 00:42:01,880
adopted into that language

952
00:42:04,520 --> 00:42:06,420
and let's go get coffee

953
00:42:06,420 --> 00:42:11,789
[Applause]

