1
00:00:02,800 --> 00:00:04,880
so this is the distinguished lecture

2
00:00:04,880 --> 00:00:08,000
session iacr awards the distinguished

3
00:00:08,000 --> 00:00:10,480
lectures to people who may make

4
00:00:10,480 --> 00:00:12,400
important contributions to cryptology

5
00:00:12,400 --> 00:00:13,599
research

6
00:00:13,599 --> 00:00:15,599
and the venue of the distinguished

7
00:00:15,599 --> 00:00:18,240
lecture alternates between eurocrypt

8
00:00:18,240 --> 00:00:20,400
crypto and asia crypt

9
00:00:20,400 --> 00:00:23,279
this year the iacr board of directors

10
00:00:23,279 --> 00:00:25,119
decided to award the distinguished

11
00:00:25,119 --> 00:00:27,840
lecture to ingrid vaubage

12
00:00:27,840 --> 00:00:32,000
from the caustic research group at ku11

13
00:00:32,000 --> 00:00:34,719
ingrid is a world renowned pioneer in

14
00:00:34,719 --> 00:00:36,960
the field of efficient and secure design

15
00:00:36,960 --> 00:00:38,879
of cryptographic algorithms in the

16
00:00:38,879 --> 00:00:40,559
embedded context

17
00:00:40,559 --> 00:00:44,000
on asics fpga and embedded software she

18
00:00:44,000 --> 00:00:46,640
is an inventor of several patents in

19
00:00:46,640 --> 00:00:49,520
these domains and author of two books

20
00:00:49,520 --> 00:00:51,600
she received numerous awards including

21
00:00:51,600 --> 00:00:54,800
the ieee cs technical achievement award

22
00:00:54,800 --> 00:00:58,559
two erc advanced grants and in 2021 she

23
00:00:58,559 --> 00:01:00,800
became a fellow of the iacr

24
00:01:00,800 --> 00:01:04,319
please welcome english

25
00:01:06,640 --> 00:01:09,040
thank you

26
00:01:11,520 --> 00:01:13,439
um i get nervous from these kind of

27
00:01:13,439 --> 00:01:15,200
introductions

28
00:01:15,200 --> 00:01:16,720
um so

29
00:01:16,720 --> 00:01:19,119
i will my presentation is about hardware

30
00:01:19,119 --> 00:01:21,439
you've heard that so maybe it's a bit

31
00:01:21,439 --> 00:01:23,840
out of what you usually hear at this

32
00:01:23,840 --> 00:01:24,960
conference

33
00:01:24,960 --> 00:01:26,400
um so

34
00:01:26,400 --> 00:01:30,079
and but i want to start um with

35
00:01:30,079 --> 00:01:32,799
one slide and that's basically my

36
00:01:32,799 --> 00:01:35,520
background um in the sense that i don't

37
00:01:35,520 --> 00:01:37,520
have a background in cryptography nor in

38
00:01:37,520 --> 00:01:40,720
computer science but in microelectronics

39
00:01:40,720 --> 00:01:42,240
and um

40
00:01:42,240 --> 00:01:44,399
moved a bit to for my phd

41
00:01:44,399 --> 00:01:47,600
to digital circuits but my very very

42
00:01:47,600 --> 00:01:49,280
first conference

43
00:01:49,280 --> 00:01:51,840
when i was a second year phd student was

44
00:01:51,840 --> 00:01:53,840
actually eurocrypt

45
00:01:53,840 --> 00:01:54,799
and

46
00:01:54,799 --> 00:01:56,880
yes

47
00:01:56,880 --> 00:01:59,200
it was eurocrypt they accepted my paper

48
00:01:59,200 --> 00:02:01,920
and this is actually i know i don't know

49
00:02:01,920 --> 00:02:03,840
if this this pointer works but you can

50
00:02:03,840 --> 00:02:07,200
see this is um a dash chip and at that

51
00:02:07,200 --> 00:02:09,440
time it was two levels of metal and you

52
00:02:09,440 --> 00:02:12,080
can see at the bottom that's as eight as

53
00:02:12,080 --> 00:02:15,120
boxes as you got all know um this has

54
00:02:15,120 --> 00:02:17,440
permutation rounding and this has data

55
00:02:17,440 --> 00:02:20,239
parts of 32 bits and 48 bits and you can

56
00:02:20,239 --> 00:02:22,560
see that so this is 32 slices this is

57
00:02:22,560 --> 00:02:25,520
48-bit slices and these are permutations

58
00:02:25,520 --> 00:02:27,280
permutations were a challenge at that

59
00:02:27,280 --> 00:02:29,520
time because we only had two levels of

60
00:02:29,520 --> 00:02:31,200
metal

61
00:02:31,200 --> 00:02:34,160
but i think the the title is uh still

62
00:02:34,160 --> 00:02:36,080
valid and it says security

63
00:02:36,080 --> 00:02:37,760
considerations in the design and

64
00:02:37,760 --> 00:02:40,160
implementation of a new desk chip

65
00:02:40,160 --> 00:02:42,480
and that's also what i

66
00:02:42,480 --> 00:02:45,360
want to do with you is actually link

67
00:02:45,360 --> 00:02:47,840
security cryptography requirements to

68
00:02:47,840 --> 00:02:49,920
hardware design and hopefully provide

69
00:02:49,920 --> 00:02:52,239
you with a

70
00:02:52,239 --> 00:02:55,120
set of new research challenges to work

71
00:02:55,120 --> 00:02:57,680
on all the challenges we have now

72
00:02:57,680 --> 00:03:00,720
to implement um crypto

73
00:03:00,720 --> 00:03:03,360
topics and crypto algorithms okay

74
00:03:03,360 --> 00:03:05,840
so first i will start with uh giving you

75
00:03:05,840 --> 00:03:08,080
kind of position where is cryptography

76
00:03:08,080 --> 00:03:10,319
in the design of embedded systems

77
00:03:10,319 --> 00:03:11,920
um

78
00:03:11,920 --> 00:03:14,080
uh introduce the concept of root of

79
00:03:14,080 --> 00:03:15,840
trust and a bit on how

80
00:03:15,840 --> 00:03:17,840
how we integrate cryptography in

81
00:03:17,840 --> 00:03:19,519
embedded systems

82
00:03:19,519 --> 00:03:21,760
and but i also think

83
00:03:21,760 --> 00:03:24,560
cryptography relies on hardware because

84
00:03:24,560 --> 00:03:26,480
it needs performance see that dash

85
00:03:26,480 --> 00:03:28,560
cheaper from the previous slide

86
00:03:28,560 --> 00:03:30,640
not just performance but also secure

87
00:03:30,640 --> 00:03:32,640
implementations and this is a challenge

88
00:03:32,640 --> 00:03:35,519
we want to imp we want to protect

89
00:03:35,519 --> 00:03:37,599
all these crypto topics against slide

90
00:03:37,599 --> 00:03:40,080
channel attacks fault attacks and so on

91
00:03:40,080 --> 00:03:42,720
and then i go to two topics which are a

92
00:03:42,720 --> 00:03:44,239
bit more circuit

93
00:03:44,239 --> 00:03:46,799
i'm going to show you even transistor

94
00:03:46,799 --> 00:03:49,519
um and that's how we can do secure key

95
00:03:49,519 --> 00:03:51,280
storage which is very important in

96
00:03:51,280 --> 00:03:53,599
embedded context you don't have much

97
00:03:53,599 --> 00:03:56,319
space there and also something which a

98
00:03:56,319 --> 00:03:59,200
lot of crypto and security protocols

99
00:03:59,200 --> 00:04:01,680
rely on that's how to generate random

100
00:04:01,680 --> 00:04:04,239
numbers random numbers don't fall out of

101
00:04:04,239 --> 00:04:05,360
the air

102
00:04:05,360 --> 00:04:07,360
it's tough to generate them and then

103
00:04:07,360 --> 00:04:10,080
maybe some challenges to work on jointly

104
00:04:10,080 --> 00:04:12,319
and some conclusions

105
00:04:12,319 --> 00:04:14,080
so what are these next generation

106
00:04:14,080 --> 00:04:16,160
embedded systems that we work on the

107
00:04:16,160 --> 00:04:18,000
first one i want to show you is from the

108
00:04:18,000 --> 00:04:20,160
context of automotive

109
00:04:20,160 --> 00:04:22,240
um this is a picture from the newspaper

110
00:04:22,240 --> 00:04:24,800
a local newspaper in belgium

111
00:04:24,800 --> 00:04:26,639
and there is a local company called

112
00:04:26,639 --> 00:04:29,040
malexis and what they built is actually

113
00:04:29,040 --> 00:04:30,960
sensors for cars

114
00:04:30,960 --> 00:04:32,639
and these sensors do they measure

115
00:04:32,639 --> 00:04:35,520
everything they measure uh your exhaust

116
00:04:35,520 --> 00:04:38,240
they measure the the steering wheels

117
00:04:38,240 --> 00:04:40,639
they measure the wipers they measure the

118
00:04:40,639 --> 00:04:43,520
tire pressures tire pressure and so on

119
00:04:43,520 --> 00:04:46,240
the the rain whether the rain or light

120
00:04:46,240 --> 00:04:48,960
sensors and so on now one

121
00:04:48,960 --> 00:04:53,840
tesla car oops one tesla car has uh 58

122
00:04:53,840 --> 00:04:56,400
of their chips only of this company i'm

123
00:04:56,400 --> 00:04:58,400
not working for this company just to

124
00:04:58,400 --> 00:05:00,320
give to illustrate to you

125
00:05:00,320 --> 00:05:03,759
if you buy a high-end mercedes eqs you

126
00:05:03,759 --> 00:05:07,280
have 170 of their sensor chips

127
00:05:07,280 --> 00:05:09,280
and this is not including all the chips

128
00:05:09,280 --> 00:05:11,440
from someone else right it's just them

129
00:05:11,440 --> 00:05:13,039
you can imagine what the security

130
00:05:13,039 --> 00:05:15,360
challenge this is if the tires give the

131
00:05:15,360 --> 00:05:18,000
wrong pressure or false pressure number

132
00:05:18,000 --> 00:05:19,520
or if you want to

133
00:05:19,520 --> 00:05:21,039
know what what's the status of your

134
00:05:21,039 --> 00:05:22,840
brakes you have some

135
00:05:22,840 --> 00:05:24,639
issues and

136
00:05:24,639 --> 00:05:26,479
um these card networks have been

137
00:05:26,479 --> 00:05:29,039
attacked the most famous one is this uh

138
00:05:29,039 --> 00:05:32,240
hackers that killed jeep this had been a

139
00:05:32,240 --> 00:05:34,400
financial disaster for chrysler they had

140
00:05:34,400 --> 00:05:36,560
to recall i don't know 1 million or 2

141
00:05:36,560 --> 00:05:38,960
million cars or so so what's the

142
00:05:38,960 --> 00:05:40,160
challenge here

143
00:05:40,160 --> 00:05:43,680
is that these devices are networked and

144
00:05:43,680 --> 00:05:45,680
they have a local network so it means

145
00:05:45,680 --> 00:05:48,320
that they secure authenticated

146
00:05:48,320 --> 00:05:52,639
communication low latency not much data

147
00:05:52,639 --> 00:05:55,440
but it's impact embedded embedded means

148
00:05:55,440 --> 00:05:57,440
whatever solution you provide has to be

149
00:05:57,440 --> 00:05:59,520
compact those things don't have external

150
00:05:59,520 --> 00:06:02,560
memory or disks it has to be cheap

151
00:06:02,560 --> 00:06:04,319
there's no batch processing to speed

152
00:06:04,319 --> 00:06:05,520
things up

153
00:06:05,520 --> 00:06:07,280
and they interact with the environment

154
00:06:07,280 --> 00:06:09,600
so they have sensors and actuators so

155
00:06:09,600 --> 00:06:12,000
they should be low latency compact cheap

156
00:06:12,000 --> 00:06:13,600
and of course they need to be resistant

157
00:06:13,600 --> 00:06:15,280
to attacks

158
00:06:15,280 --> 00:06:17,120
that's from automotive

159
00:06:17,120 --> 00:06:20,240
so but uh how do we evaluate security

160
00:06:20,240 --> 00:06:22,720
i'm not going to show the video but um

161
00:06:22,720 --> 00:06:25,280
this is a work we've done also at cosic

162
00:06:25,280 --> 00:06:27,919
in our hardware lab and it's quite

163
00:06:27,919 --> 00:06:31,120
famous and this is only security of the

164
00:06:31,120 --> 00:06:34,000
key fob so leonard to speech phd in our

165
00:06:34,000 --> 00:06:35,440
group uh

166
00:06:35,440 --> 00:06:38,479
attacked or found weaknesses in both

167
00:06:38,479 --> 00:06:41,120
model x and model s key fobs

168
00:06:41,120 --> 00:06:43,840
um and so for the older key phots

169
00:06:43,840 --> 00:06:46,240
they had basic mistakes like there was

170
00:06:46,240 --> 00:06:48,880
no mutual authentication and they use a

171
00:06:48,880 --> 00:06:52,080
very weak crypto 40 bits of later on 80

172
00:06:52,080 --> 00:06:52,960
bits

173
00:06:52,960 --> 00:06:54,800
but there is lots of improvements in the

174
00:06:54,800 --> 00:06:56,960
second version and second version even

175
00:06:56,960 --> 00:06:59,599
uses a secure element still there are

176
00:06:59,599 --> 00:07:01,520
problems with the protocol so

177
00:07:01,520 --> 00:07:03,599
implementing these things is much more

178
00:07:03,599 --> 00:07:06,400
complex than just implementing secure uh

179
00:07:06,400 --> 00:07:08,639
crypto

180
00:07:08,639 --> 00:07:11,120
um and automotive is not the only one

181
00:07:11,120 --> 00:07:13,199
the second example i want to show is

182
00:07:13,199 --> 00:07:14,479
actually

183
00:07:14,479 --> 00:07:16,560
the internet of things or the internet

184
00:07:16,560 --> 00:07:18,720
of everything or whatever you want to

185
00:07:18,720 --> 00:07:19,680
call it

186
00:07:19,680 --> 00:07:22,160
and these days uh we're talking about

187
00:07:22,160 --> 00:07:25,520
e-health e-commerce e-voting smart grid

188
00:07:25,520 --> 00:07:27,919
everything becomes smart big data and so

189
00:07:27,919 --> 00:07:31,120
on um even the

190
00:07:31,120 --> 00:07:33,759
economists this month had a whole

191
00:07:33,759 --> 00:07:36,560
section on wearable technologies

192
00:07:36,560 --> 00:07:38,880
that promised to revolutionize the

193
00:07:38,880 --> 00:07:40,080
health care

194
00:07:40,080 --> 00:07:42,160
now i have seen some projects like that

195
00:07:42,160 --> 00:07:44,720
who try to do that and this is a project

196
00:07:44,720 --> 00:07:47,199
which was uh developed at imic now a

197
00:07:47,199 --> 00:07:49,360
couple of years old but that's how they

198
00:07:49,360 --> 00:07:51,759
see it so you have the human body will

199
00:07:51,759 --> 00:07:53,440
have a set of sensors and these are

200
00:07:53,440 --> 00:07:56,319
sensors for hearing blood pressure

201
00:07:56,319 --> 00:07:59,120
glucose monitoring implants they even

202
00:07:59,120 --> 00:08:02,400
consider brain implants um

203
00:08:02,400 --> 00:08:04,080
these days you probably can hack your

204
00:08:04,080 --> 00:08:05,280
brains huh

205
00:08:05,280 --> 00:08:06,080
um

206
00:08:06,080 --> 00:08:08,479
but the and this network is called a

207
00:08:08,479 --> 00:08:11,520
body area network body area network

208
00:08:11,520 --> 00:08:13,919
connects to your mobile phone which is

209
00:08:13,919 --> 00:08:16,720
then the little edge server and from

210
00:08:16,720 --> 00:08:19,199
there the data goes to your medical

211
00:08:19,199 --> 00:08:21,440
doctor or your

212
00:08:21,440 --> 00:08:23,360
insurance company and the insurance

213
00:08:23,360 --> 00:08:25,599
company probably doesn't need the same

214
00:08:25,599 --> 00:08:27,520
information as the medical doctor and so

215
00:08:27,520 --> 00:08:29,759
on you can imagine that this is a huge

216
00:08:29,759 --> 00:08:32,640
security challenge beyond having some

217
00:08:32,640 --> 00:08:34,799
crypto there

218
00:08:34,799 --> 00:08:37,039
um and so we can conclude that anything

219
00:08:37,039 --> 00:08:39,360
that starts with either e or smart these

220
00:08:39,360 --> 00:08:41,360
days will need

221
00:08:41,360 --> 00:08:44,080
security

222
00:08:44,880 --> 00:08:47,279
so but how do we start and basically if

223
00:08:47,279 --> 00:08:50,399
we design or we want to add security to

224
00:08:50,399 --> 00:08:53,040
these things we try to figure out what

225
00:08:53,040 --> 00:08:54,800
needs security what doesn't need

226
00:08:54,800 --> 00:08:56,959
security you want to minimize what needs

227
00:08:56,959 --> 00:08:59,200
security and so introduce for that the

228
00:08:59,200 --> 00:09:03,040
concept of trust and trust uh boundaries

229
00:09:03,040 --> 00:09:05,440
and for trust definition i go back

230
00:09:05,440 --> 00:09:07,680
to the definition of ross anderson in

231
00:09:07,680 --> 00:09:08,959
his book

232
00:09:08,959 --> 00:09:11,680
security engineering and he has it after

233
00:09:11,680 --> 00:09:12,880
the nsa

234
00:09:12,880 --> 00:09:15,600
so trusted system or component

235
00:09:15,600 --> 00:09:17,839
is one whose failure can break the

236
00:09:17,839 --> 00:09:21,120
security policy a trustworthy system or

237
00:09:21,120 --> 00:09:24,080
coma component is one that won't fail

238
00:09:24,080 --> 00:09:26,240
basically there's gonna be somewhere a

239
00:09:26,240 --> 00:09:28,959
component that maybe you cannot verify

240
00:09:28,959 --> 00:09:30,399
and that you need to trust and that's

241
00:09:30,399 --> 00:09:32,320
what we want to minimize

242
00:09:32,320 --> 00:09:34,880
trusted computing group has a similar

243
00:09:34,880 --> 00:09:38,080
definition an entity can be trusted if

244
00:09:38,080 --> 00:09:40,640
it always behaves in the expected manner

245
00:09:40,640 --> 00:09:42,880
for the intended purpose

246
00:09:42,880 --> 00:09:45,760
so loosely stated if a trusted system or

247
00:09:45,760 --> 00:09:46,959
common fail

248
00:09:46,959 --> 00:09:48,560
bad things can happen and the whole

249
00:09:48,560 --> 00:09:51,200
thing can fall apart so from a better

250
00:09:51,200 --> 00:09:53,760
security perspective we really want to

251
00:09:53,760 --> 00:09:55,920
minimize what needs to be trusted we

252
00:09:55,920 --> 00:09:57,920
want to minimize that and and

253
00:09:57,920 --> 00:09:59,200
um

254
00:09:59,200 --> 00:10:01,200
and in this context

255
00:10:01,200 --> 00:10:03,760
we want to see how does cryptographer

256
00:10:03,760 --> 00:10:05,680
fits in there right what parts of

257
00:10:05,680 --> 00:10:08,079
cryptography we want to trust

258
00:10:08,079 --> 00:10:11,120
so um let's start with the old model the

259
00:10:11,120 --> 00:10:12,720
model which applied when we were

260
00:10:12,720 --> 00:10:14,560
designing the dutch chip

261
00:10:14,560 --> 00:10:16,079
so in the old days

262
00:10:16,079 --> 00:10:17,279
basically

263
00:10:17,279 --> 00:10:19,760
what the trust model we had is that the

264
00:10:19,760 --> 00:10:20,959
attack

265
00:10:20,959 --> 00:10:23,440
would happen on the communicating

266
00:10:23,440 --> 00:10:26,399
channel between communicating parties so

267
00:10:26,399 --> 00:10:29,120
you had a somewhere a desktop and maybe

268
00:10:29,120 --> 00:10:31,120
somewhere a computer room which were

269
00:10:31,120 --> 00:10:34,079
considered closed and secure and so the

270
00:10:34,079 --> 00:10:36,160
attack would happen on the communicating

271
00:10:36,160 --> 00:10:38,720
channel which means that encryption

272
00:10:38,720 --> 00:10:41,200
cryptographic operations your security

273
00:10:41,200 --> 00:10:43,600
protects it in black boxes and the only

274
00:10:43,600 --> 00:10:45,519
thing we need at that moment

275
00:10:45,519 --> 00:10:47,680
is protection by strong mathematical

276
00:10:47,680 --> 00:10:49,519
algorithms and protocols and i think

277
00:10:49,519 --> 00:10:52,240
this field has evolved enormously over

278
00:10:52,240 --> 00:10:53,360
the last

279
00:10:53,360 --> 00:10:56,000
10 20 years 30 years and there are

280
00:10:56,000 --> 00:10:58,320
strong mathematical algorithms there is

281
00:10:58,320 --> 00:11:00,959
niche standardization efforts and so on

282
00:11:00,959 --> 00:11:03,279
so from hardware perspective what we

283
00:11:03,279 --> 00:11:05,680
focus then is how can we get these

284
00:11:05,680 --> 00:11:08,399
algorithms efficient efficient

285
00:11:08,399 --> 00:11:11,920
meaning um compact in area sometimes

286
00:11:11,920 --> 00:11:13,279
high throughput

287
00:11:13,279 --> 00:11:14,720
low energy

288
00:11:14,720 --> 00:11:17,360
cooling issues things like that

289
00:11:17,360 --> 00:11:19,440
and i have some examples here over the

290
00:11:19,440 --> 00:11:21,519
past projects done

291
00:11:21,519 --> 00:11:23,519
the first one to the left is the this

292
00:11:23,519 --> 00:11:26,320
chip that i showed the second one was

293
00:11:26,320 --> 00:11:28,720
our very first implementation of the

294
00:11:28,720 --> 00:11:31,040
randall algorithm it was no it was not

295
00:11:31,040 --> 00:11:33,279
yet called a yes at that moment

296
00:11:33,279 --> 00:11:35,120
and basically what you see you don't see

297
00:11:35,120 --> 00:11:37,279
anything because this is a standard cell

298
00:11:37,279 --> 00:11:38,160
design

299
00:11:38,160 --> 00:11:40,160
and so it had already bit more levels of

300
00:11:40,160 --> 00:11:43,040
metal so you don't see much on that one

301
00:11:43,040 --> 00:11:45,200
the third one was

302
00:11:45,200 --> 00:11:46,880
an elliptic curve

303
00:11:46,880 --> 00:11:48,160
processor

304
00:11:48,160 --> 00:11:50,160
and that one

305
00:11:50,160 --> 00:11:52,399
we wanted to prove that this could be

306
00:11:52,399 --> 00:11:56,000
integrated in a passive rfid tag passive

307
00:11:56,000 --> 00:11:58,160
rfid tag basically you don't have

308
00:11:58,160 --> 00:12:00,399
battery the only power you have is what

309
00:12:00,399 --> 00:12:02,959
you scavenge from the air

310
00:12:02,959 --> 00:12:04,480
and we want to demonstrate that this is

311
00:12:04,480 --> 00:12:06,079
possible because at that time they were

312
00:12:06,079 --> 00:12:08,160
saying oh public key you cannot put it

313
00:12:08,160 --> 00:12:09,920
in a sensor node it all has to be

314
00:12:09,920 --> 00:12:12,160
symmetric key and so on

315
00:12:12,160 --> 00:12:15,120
um lately together with people at purdue

316
00:12:15,120 --> 00:12:17,680
we finished a saber chip and again you

317
00:12:17,680 --> 00:12:19,440
see even less

318
00:12:19,440 --> 00:12:21,839
on these pictures so the the the

319
00:12:21,839 --> 00:12:23,839
elliptic curve you can still see that

320
00:12:23,839 --> 00:12:26,079
the data part is very regular and the

321
00:12:26,079 --> 00:12:28,399
reason was that uh it gave us some side

322
00:12:28,399 --> 00:12:30,240
channel protections i mean for details

323
00:12:30,240 --> 00:12:31,920
you have to go and read this is the

324
00:12:31,920 --> 00:12:34,959
latest chip this is a saber chip

325
00:12:34,959 --> 00:12:36,880
and so what's next that's pure

326
00:12:36,880 --> 00:12:39,040
efficiency yeah feasibility

327
00:12:39,040 --> 00:12:42,160
uh pooling issues energy better lifetime

328
00:12:42,160 --> 00:12:44,480
issues and so on and so these days what

329
00:12:44,480 --> 00:12:46,639
we focus on is extremely lightweight

330
00:12:46,639 --> 00:12:49,200
crypto or things like fully homomorphic

331
00:12:49,200 --> 00:12:51,279
encryption can we include it in one chip

332
00:12:51,279 --> 00:12:52,480
or in one

333
00:12:52,480 --> 00:12:54,800
fpga and so on

334
00:12:54,800 --> 00:12:56,480
now the

335
00:12:56,480 --> 00:12:58,800
the trust model we're using these days

336
00:12:58,800 --> 00:13:00,480
is the following one

337
00:13:00,480 --> 00:13:02,399
is actually we no longer assume that

338
00:13:02,399 --> 00:13:04,639
these are gray black boxes but we

339
00:13:04,639 --> 00:13:06,560
actually assume that crypto

340
00:13:06,560 --> 00:13:09,200
cryptographic operations sit in gray

341
00:13:09,200 --> 00:13:11,680
boxes so you have attacks

342
00:13:11,680 --> 00:13:14,079
not only on the communicating channels

343
00:13:14,079 --> 00:13:16,480
but on the devices themselves so that's

344
00:13:16,480 --> 00:13:19,680
a different model and so um you still

345
00:13:19,680 --> 00:13:20,560
need

346
00:13:20,560 --> 00:13:22,639
these strong mathematical algorithms and

347
00:13:22,639 --> 00:13:24,880
protocols but you also need secure

348
00:13:24,880 --> 00:13:28,160
implementations um the implementations

349
00:13:28,160 --> 00:13:29,680
leak and you have heard about side

350
00:13:29,680 --> 00:13:31,279
channel attacks you can address them

351
00:13:31,279 --> 00:13:33,600
with fault attacks and so on

352
00:13:33,600 --> 00:13:35,839
so and that will be a bit of focus of

353
00:13:35,839 --> 00:13:38,720
this presentation uh we need secure

354
00:13:38,720 --> 00:13:40,800
implementation not only secure

355
00:13:40,800 --> 00:13:43,839
algorithms the secure algorithms i'm

356
00:13:43,839 --> 00:13:46,000
very confident you guys make extremely

357
00:13:46,000 --> 00:13:48,399
nice job so the problem

358
00:13:48,399 --> 00:13:50,320
is maybe good well done

359
00:13:50,320 --> 00:13:53,360
so um

360
00:13:53,600 --> 00:13:55,279
there have been many side channel

361
00:13:55,279 --> 00:13:57,760
unfault attacks you have heard of those

362
00:13:57,760 --> 00:13:59,920
there's power attacks electromagnetic

363
00:13:59,920 --> 00:14:02,240
attacks timing attacks these days very

364
00:14:02,240 --> 00:14:04,720
popular are micro architectural fight

365
00:14:04,720 --> 00:14:06,720
channel attacks so cache attacks

366
00:14:06,720 --> 00:14:08,480
transient execution attacks you have

367
00:14:08,480 --> 00:14:10,160
heard of spectre and meltdown that can

368
00:14:10,160 --> 00:14:12,320
be used to attack and so on

369
00:14:12,320 --> 00:14:14,560
uh there's many types of faults active

370
00:14:14,560 --> 00:14:17,920
attacks em laser clock voltage glitches

371
00:14:17,920 --> 00:14:19,920
and actually you can combine any of

372
00:14:19,920 --> 00:14:21,839
those the attacker is not limited to

373
00:14:21,839 --> 00:14:22,720
that

374
00:14:22,720 --> 00:14:25,279
the attacks can be local can be remote

375
00:14:25,279 --> 00:14:28,639
and from be from a distance and so on

376
00:14:28,639 --> 00:14:30,880
um these are some of the equipment that

377
00:14:30,880 --> 00:14:33,120
we have in our lab some of these attacks

378
00:14:33,120 --> 00:14:34,480
are very cheap

379
00:14:34,480 --> 00:14:37,760
a simple compact power measurement can

380
00:14:37,760 --> 00:14:39,760
be done with a shunt register or current

381
00:14:39,760 --> 00:14:43,440
probe and you can do that for 150 euros

382
00:14:43,440 --> 00:14:45,120
and you get probably frequency in the

383
00:14:45,120 --> 00:14:46,959
kilohertz megahertz and for many of

384
00:14:46,959 --> 00:14:49,279
these attacks this is sufficient

385
00:14:49,279 --> 00:14:52,399
um contact less power measurements it's

386
00:14:52,399 --> 00:14:54,079
still power measurements but that's with

387
00:14:54,079 --> 00:14:56,079
em probes so you don't have to open up

388
00:14:56,079 --> 00:14:58,160
or you get close to the power pins

389
00:14:58,160 --> 00:15:00,079
that's a bit more expensive because

390
00:15:00,079 --> 00:15:02,560
these probes are a bit more expensive

391
00:15:02,560 --> 00:15:03,360
um

392
00:15:03,360 --> 00:15:06,560
compact less measurements um with em

393
00:15:06,560 --> 00:15:09,199
probes em measurements like this kind of

394
00:15:09,199 --> 00:15:10,560
big bulky

395
00:15:10,560 --> 00:15:13,440
uh antennas they pick up what the chip

396
00:15:13,440 --> 00:15:14,480
is doing

397
00:15:14,480 --> 00:15:16,399
but you can also do what's called local

398
00:15:16,399 --> 00:15:19,040
em measurements and local em means that

399
00:15:19,040 --> 00:15:22,560
you go with small needles you go to the

400
00:15:22,560 --> 00:15:23,760
center of the

401
00:15:23,760 --> 00:15:26,240
the chip and you can have very localized

402
00:15:26,240 --> 00:15:28,079
measurements

403
00:15:28,079 --> 00:15:30,399
and that they can pick up seniors

404
00:15:30,399 --> 00:15:32,320
megahertz to gigahertz but there's quite

405
00:15:32,320 --> 00:15:35,519
expensive material

406
00:15:35,519 --> 00:15:38,639
um so now i want to go

407
00:15:38,639 --> 00:15:41,120
a bit to the different research topics

408
00:15:41,120 --> 00:15:42,959
that i think

409
00:15:42,959 --> 00:15:44,720
more work should be done more

410
00:15:44,720 --> 00:15:46,560
collaboration with hardware designers

411
00:15:46,560 --> 00:15:48,320
should be done

412
00:15:48,320 --> 00:15:51,040
and these are the five topics uh two are

413
00:15:51,040 --> 00:15:53,680
about masking and then about randomness

414
00:15:53,680 --> 00:15:55,519
and maybe at the end some hardware

415
00:15:55,519 --> 00:15:57,040
challenges

416
00:15:57,040 --> 00:15:57,920
so

417
00:15:57,920 --> 00:15:58,959
the first

418
00:15:58,959 --> 00:16:01,279
topic i would like to address or discuss

419
00:16:01,279 --> 00:16:03,759
is side channel attacks side channel

420
00:16:03,759 --> 00:16:06,480
attacks have also been discussed in this

421
00:16:06,480 --> 00:16:07,920
conference

422
00:16:07,920 --> 00:16:10,959
and one of my statements is that masking

423
00:16:10,959 --> 00:16:14,880
is extremely hard in practice

424
00:16:14,880 --> 00:16:17,120
lots of theory has been developed but in

425
00:16:17,120 --> 00:16:20,240
practice it's extremely hard

426
00:16:20,240 --> 00:16:21,199
um

427
00:16:21,199 --> 00:16:23,279
so i guess i don't have to explain what

428
00:16:23,279 --> 00:16:26,160
is masking but masking is actually a

429
00:16:26,160 --> 00:16:28,480
technique to protect against side

430
00:16:28,480 --> 00:16:31,040
channel attacks but you do is you have a

431
00:16:31,040 --> 00:16:34,480
sensitive value you split it in um

432
00:16:34,480 --> 00:16:36,880
random shares and you operate on the

433
00:16:36,880 --> 00:16:39,120
shares individually if those shares

434
00:16:39,120 --> 00:16:42,240
don't minimal you actually product

435
00:16:42,240 --> 00:16:45,440
against um attacks many types of masking

436
00:16:45,440 --> 00:16:47,199
have been proposed boolean masking

437
00:16:47,199 --> 00:16:49,440
arithmetic masking inner product masking

438
00:16:49,440 --> 00:16:52,399
threshold masking and so on

439
00:16:52,399 --> 00:16:54,800
but they all start from a similar

440
00:16:54,800 --> 00:16:57,759
leakage model they all assume that once

441
00:16:57,759 --> 00:17:00,000
you share that these shares leak

442
00:17:00,000 --> 00:17:02,480
independent that they don't interact and

443
00:17:02,480 --> 00:17:04,480
that's kind of hard already and the

444
00:17:04,480 --> 00:17:05,359
second

445
00:17:05,359 --> 00:17:07,839
uh assumption they make they all require

446
00:17:07,839 --> 00:17:10,880
randomness and sometimes they're very

447
00:17:10,880 --> 00:17:12,959
picky about randomness sometimes they

448
00:17:12,959 --> 00:17:14,559
don't need much randomness but

449
00:17:14,559 --> 00:17:18,480
randomness is expensive also

450
00:17:18,480 --> 00:17:19,760
and so i'm going to show you two

451
00:17:19,760 --> 00:17:21,119
experiments

452
00:17:21,119 --> 00:17:23,359
one on symmetric key

453
00:17:23,359 --> 00:17:25,839
that's masking techniques for aes on

454
00:17:25,839 --> 00:17:27,599
microcontrollers so embedded

455
00:17:27,599 --> 00:17:31,039
microcontrollers are m3m4 and the second

456
00:17:31,039 --> 00:17:32,480
one public key

457
00:17:32,480 --> 00:17:35,280
about the cost of masking pus quantum

458
00:17:35,280 --> 00:17:38,080
pos quantum basically limited here about

459
00:17:38,080 --> 00:17:38,960
latin

460
00:17:38,960 --> 00:17:41,679
lattice-based uh encryptions

461
00:17:41,679 --> 00:17:42,880
um

462
00:17:42,880 --> 00:17:45,520
so the first experiment i want to show

463
00:17:45,520 --> 00:17:47,600
is from arthurian leonard

464
00:17:47,600 --> 00:17:50,960
and that's uh side channel attacks first

465
00:17:50,960 --> 00:17:54,799
order cytonal attacks on software masked

466
00:17:54,799 --> 00:17:59,600
aes implementations and we went through

467
00:17:59,600 --> 00:18:02,400
eight publications you see them here

468
00:18:02,400 --> 00:18:04,559
uh winter paper titles and when they

469
00:18:04,559 --> 00:18:06,480
were published

470
00:18:06,480 --> 00:18:08,799
and what the typical masking method was

471
00:18:08,799 --> 00:18:10,720
so most of them on this list are boolean

472
00:18:10,720 --> 00:18:13,679
mask and two of them are inner product

473
00:18:13,679 --> 00:18:14,559
masks

474
00:18:14,559 --> 00:18:16,960
and they were some of them provide

475
00:18:16,960 --> 00:18:20,480
provable secure masking some of them uh

476
00:18:20,480 --> 00:18:23,200
use only pseudorandom numbers generators

477
00:18:23,200 --> 00:18:26,080
um but they have even be published at

478
00:18:26,080 --> 00:18:27,440
eurocrypt

479
00:18:27,440 --> 00:18:30,480
now this is our results this results

480
00:18:30,480 --> 00:18:32,320
were recently published

481
00:18:32,320 --> 00:18:33,679
is that

482
00:18:33,679 --> 00:18:34,559
six

483
00:18:34,559 --> 00:18:37,840
out of the eight um were

484
00:18:37,840 --> 00:18:39,520
simply attacked with the first order

485
00:18:39,520 --> 00:18:41,280
attack not even high road attack a

486
00:18:41,280 --> 00:18:43,600
straightforward sing simple first order

487
00:18:43,600 --> 00:18:46,640
attack to six out of these uh

488
00:18:46,640 --> 00:18:48,240
implementations

489
00:18:48,240 --> 00:18:49,919
um one had an

490
00:18:49,919 --> 00:18:52,880
incorrect random number instantiation

491
00:18:52,880 --> 00:18:55,520
uh some at benchmarking issues

492
00:18:55,520 --> 00:18:57,919
somewhat software picks

493
00:18:57,919 --> 00:19:00,640
so it shows that it's difficult to mask

494
00:19:00,640 --> 00:19:02,799
in practice right

495
00:19:02,799 --> 00:19:04,240
um

496
00:19:04,240 --> 00:19:06,480
so and we use for this no advanced

497
00:19:06,480 --> 00:19:08,320
attacks it's just a straightforward

498
00:19:08,320 --> 00:19:10,240
statistical methods called correlation

499
00:19:10,240 --> 00:19:11,919
power analysis

500
00:19:11,919 --> 00:19:14,000
all implementation we started from the

501
00:19:14,000 --> 00:19:16,720
the given code um we only inserted

502
00:19:16,720 --> 00:19:18,960
triggers for our scope and it's a

503
00:19:18,960 --> 00:19:21,919
textbook first order cpa so we attack

504
00:19:21,919 --> 00:19:24,799
either s box in or outputs uh first

505
00:19:24,799 --> 00:19:26,559
round or last round

506
00:19:26,559 --> 00:19:28,640
bit on hamming weight leakage

507
00:19:28,640 --> 00:19:32,000
um and only 20 000 traces

508
00:19:32,000 --> 00:19:34,320
they're all limited to 20 000 traces or

509
00:19:34,320 --> 00:19:36,080
many of these implementations claim

510
00:19:36,080 --> 00:19:39,520
resistance for uh into the millions or

511
00:19:39,520 --> 00:19:41,520
the billions of traces

512
00:19:41,520 --> 00:19:43,840
and i don't make any claims about the

513
00:19:43,840 --> 00:19:46,160
mathematical concepts or proofs that's

514
00:19:46,160 --> 00:19:49,039
uh outside my uh expertise

515
00:19:49,039 --> 00:19:51,760
um and so so this is how we do these

516
00:19:51,760 --> 00:19:54,080
setups so you see a setup in the lab

517
00:19:54,080 --> 00:19:54,960
here

518
00:19:54,960 --> 00:19:56,559
so you have the only thing you need is a

519
00:19:56,559 --> 00:19:59,600
pc and a scope um this is a standard

520
00:19:59,600 --> 00:20:02,120
evaluation board for sd

521
00:20:02,120 --> 00:20:04,720
microcontrollers and a programmer and

522
00:20:04,720 --> 00:20:06,559
some connections and these are the

523
00:20:06,559 --> 00:20:08,000
results

524
00:20:08,000 --> 00:20:09,200
for those

525
00:20:09,200 --> 00:20:11,280
that have not seen

526
00:20:11,280 --> 00:20:13,440
correlation power analysis if you do

527
00:20:13,440 --> 00:20:16,159
attacks on aes you actually attack bite

528
00:20:16,159 --> 00:20:18,640
by bytes because aes is a byte

529
00:20:18,640 --> 00:20:21,200
oriented algorithm

530
00:20:21,200 --> 00:20:22,320
and

531
00:20:22,320 --> 00:20:24,320
because it's by by byte it's a divide

532
00:20:24,320 --> 00:20:25,679
and conquer

533
00:20:25,679 --> 00:20:28,240
you want to guess one byte out of

534
00:20:28,240 --> 00:20:29,679
256

535
00:20:29,679 --> 00:20:31,039
and so

536
00:20:31,039 --> 00:20:33,039
in excess you see the progress of the

537
00:20:33,039 --> 00:20:34,880
number of samples on the y as the

538
00:20:34,880 --> 00:20:37,200
correlation coefficient and so for each

539
00:20:37,200 --> 00:20:38,320
of these

540
00:20:38,320 --> 00:20:40,880
papers either we attack first round or

541
00:20:40,880 --> 00:20:44,799
last round that the correct key byte

542
00:20:44,799 --> 00:20:47,760
pops out at some point

543
00:20:47,760 --> 00:20:49,600
or two can use this one

544
00:20:49,600 --> 00:20:52,159
so um and yeah you see for other ones

545
00:20:52,159 --> 00:20:53,919
you see for either first round the first

546
00:20:53,919 --> 00:20:56,080
round is well protected then maybe last

547
00:20:56,080 --> 00:20:58,640
round uh has an issue or the other way

548
00:20:58,640 --> 00:21:00,640
around so if you want to see more

549
00:21:00,640 --> 00:21:02,080
details

550
00:21:02,080 --> 00:21:03,840
check the coset paper and i think what's

551
00:21:03,840 --> 00:21:05,520
important is that if you propose

552
00:21:05,520 --> 00:21:07,520
something some conferences have

553
00:21:07,520 --> 00:21:08,880
artifacts

554
00:21:08,880 --> 00:21:11,039
evaluation so it would be nice that this

555
00:21:11,039 --> 00:21:14,880
is also done in this context

556
00:21:14,880 --> 00:21:16,640
so what's the violation why do these

557
00:21:16,640 --> 00:21:17,760
things leak

558
00:21:17,760 --> 00:21:20,240
is because the assumption is made that

559
00:21:20,240 --> 00:21:22,960
the shares leak independently now this

560
00:21:22,960 --> 00:21:25,600
is mostly not the case so we have to

561
00:21:25,600 --> 00:21:27,919
think about new models in this case

562
00:21:27,919 --> 00:21:29,919
and for microcontrollers it means for

563
00:21:29,919 --> 00:21:32,080
instance that you have in a register or

564
00:21:32,080 --> 00:21:34,720
first share and later on you move a

565
00:21:34,720 --> 00:21:36,960
second chair in the same in the same

566
00:21:36,960 --> 00:21:39,600
register so what happened there is that

567
00:21:39,600 --> 00:21:41,360
the um

568
00:21:41,360 --> 00:21:44,799
the information on the two shares being

569
00:21:44,799 --> 00:21:47,440
xor together is leaked

570
00:21:47,440 --> 00:21:49,840
but this is for simple microcontrollers

571
00:21:49,840 --> 00:21:52,240
it gets much more complex if you want to

572
00:21:52,240 --> 00:21:53,360
do the same

573
00:21:53,360 --> 00:21:55,520
exercise for transient execution you

574
00:21:55,520 --> 00:21:57,200
have no control what your processor is

575
00:21:57,200 --> 00:22:00,480
doing um compilers might completely mess

576
00:22:00,480 --> 00:22:02,960
up with everything you're trying to do

577
00:22:02,960 --> 00:22:05,039
you might even have coupling between

578
00:22:05,039 --> 00:22:06,880
power and ground networks of different

579
00:22:06,880 --> 00:22:08,880
parts of your process right

580
00:22:08,880 --> 00:22:11,919
and so i think also below 60 nanometers

581
00:22:11,919 --> 00:22:14,400
cmos the model doesn't hold anymore

582
00:22:14,400 --> 00:22:15,840
because there you start to have what's

583
00:22:15,840 --> 00:22:18,720
called static leakage so you even leak

584
00:22:18,720 --> 00:22:22,480
if you don't do any uh calculations

585
00:22:22,480 --> 00:22:24,640
another one topic the second topic i

586
00:22:24,640 --> 00:22:26,640
want to address is that

587
00:22:26,640 --> 00:22:27,520
um

588
00:22:27,520 --> 00:22:30,320
masking is expensive uh masking is

589
00:22:30,320 --> 00:22:32,400
expensive um

590
00:22:32,400 --> 00:22:34,240
and i want to illustrate that with post

591
00:22:34,240 --> 00:22:36,559
quantum crypto so

592
00:22:36,559 --> 00:22:38,960
um if you have lattice based post

593
00:22:38,960 --> 00:22:42,080
quantum crypto as the standardization is

594
00:22:42,080 --> 00:22:45,520
going on you have this concept of

595
00:22:45,520 --> 00:22:46,559
chem

596
00:22:46,559 --> 00:22:49,280
key encapsulation mechanism where there

597
00:22:49,280 --> 00:22:51,039
is like three

598
00:22:51,039 --> 00:22:53,120
it's probably key so you have a key

599
00:22:53,120 --> 00:22:55,360
generation part an encapsulation part

600
00:22:55,360 --> 00:22:57,600
and a decapsulation part

601
00:22:57,600 --> 00:23:01,200
and on the encryption side basically the

602
00:23:01,200 --> 00:23:02,880
basic concept is you have something

603
00:23:02,880 --> 00:23:05,120
encryption that we're gonna encrypt we

604
00:23:05,120 --> 00:23:06,799
have a public key and a random number

605
00:23:06,799 --> 00:23:09,360
and this generates you a ciphertext

606
00:23:09,360 --> 00:23:12,400
and if on the receiving end

607
00:23:12,400 --> 00:23:15,280
you basically in uh you should decrypt

608
00:23:15,280 --> 00:23:17,440
your ciphertext with the secret key

609
00:23:17,440 --> 00:23:20,400
gives you the random number again but to

610
00:23:20,400 --> 00:23:23,919
make it cca secure which this community

611
00:23:23,919 --> 00:23:25,280
knows what it is

612
00:23:25,280 --> 00:23:26,240
um

613
00:23:26,240 --> 00:23:27,760
we use or

614
00:23:27,760 --> 00:23:29,760
the these developers of this algorithm

615
00:23:29,760 --> 00:23:32,640
using a concept of the fuji thaki

616
00:23:32,640 --> 00:23:35,440
okamoto or fo transformation basically

617
00:23:35,440 --> 00:23:37,760
you re-encrypt

618
00:23:37,760 --> 00:23:39,919
re-encrypt and you actually check if

619
00:23:39,919 --> 00:23:42,240
this cipher text is similar to this

620
00:23:42,240 --> 00:23:44,559
cipher text and this technique is used

621
00:23:44,559 --> 00:23:46,880
both in the kyber and saber

622
00:23:46,880 --> 00:23:49,279
implementation with slight

623
00:23:49,279 --> 00:23:50,880
variations

624
00:23:50,880 --> 00:23:52,640
if you would zoom in

625
00:23:52,640 --> 00:23:53,919
um

626
00:23:53,919 --> 00:23:56,240
and zoom in and you see what people

627
00:23:56,240 --> 00:23:59,039
focus on in implementation so the

628
00:23:59,039 --> 00:24:01,760
feasibility aspect not yet the security

629
00:24:01,760 --> 00:24:02,880
aspect

630
00:24:02,880 --> 00:24:06,799
then the expensive parts so this is the

631
00:24:06,799 --> 00:24:09,520
uh decryption is also the modular

632
00:24:09,520 --> 00:24:12,480
arithmetic the expensive part is also

633
00:24:12,480 --> 00:24:14,799
the hash function and the sampling

634
00:24:14,799 --> 00:24:16,960
so you see in the beginning of the

635
00:24:16,960 --> 00:24:18,880
competition you see quite some papers

636
00:24:18,880 --> 00:24:21,360
that compare the multipliers of saber

637
00:24:21,360 --> 00:24:23,679
versus the multiplier kyber cost

638
00:24:23,679 --> 00:24:25,360
functions and so on

639
00:24:25,360 --> 00:24:27,520
but overall in my opinion they're very

640
00:24:27,520 --> 00:24:29,679
similar the only differences is that

641
00:24:29,679 --> 00:24:33,279
saber works power of two well skyber

642
00:24:33,279 --> 00:24:36,480
works with a prime number power of two

643
00:24:36,480 --> 00:24:38,799
is much nicer for hardware designers so

644
00:24:38,799 --> 00:24:40,480
we really like that

645
00:24:40,480 --> 00:24:43,760
and the first one uses module learning

646
00:24:43,760 --> 00:24:45,440
with rounding

647
00:24:45,440 --> 00:24:47,520
versus model learning with error and

648
00:24:47,520 --> 00:24:50,480
rounding is also much nicer for hardware

649
00:24:50,480 --> 00:24:52,880
designer than this explicit

650
00:24:52,880 --> 00:24:54,400
error additions

651
00:24:54,400 --> 00:24:56,320
so this is if you focus

652
00:24:56,320 --> 00:24:58,880
only on feasibility or performance now

653
00:24:58,880 --> 00:25:01,440
if you want to

654
00:25:01,440 --> 00:25:03,279
mask this again we want to protect it

655
00:25:03,279 --> 00:25:05,360
there's actually two forms of masking

656
00:25:05,360 --> 00:25:07,840
have been used here one is boolean mask

657
00:25:07,840 --> 00:25:09,520
the other one is

658
00:25:09,520 --> 00:25:12,159
arithmetic mask maybe that's also easy

659
00:25:12,159 --> 00:25:13,840
here boolean mask means that your

660
00:25:13,840 --> 00:25:16,880
sensitive value is split in booleans a

661
00:25:16,880 --> 00:25:19,360
boolean shares which then exert them

662
00:25:19,360 --> 00:25:20,400
together

663
00:25:20,400 --> 00:25:22,640
get back to your sensitive mask

664
00:25:22,640 --> 00:25:24,640
the arithmetic mask

665
00:25:24,640 --> 00:25:25,760
is the

666
00:25:25,760 --> 00:25:26,880
the one you

667
00:25:26,880 --> 00:25:30,240
share um oops i'm too fast you should oh

668
00:25:30,240 --> 00:25:33,520
no i don't know

669
00:25:33,679 --> 00:25:35,279
here

670
00:25:35,279 --> 00:25:38,720
you actually um

671
00:25:38,720 --> 00:25:40,799
do arithmetic shares and then

672
00:25:40,799 --> 00:25:44,000
because the algorithm uses both we have

673
00:25:44,000 --> 00:25:46,159
this issue that you have to convert from

674
00:25:46,159 --> 00:25:48,080
boolean to arithmetic shares and from

675
00:25:48,080 --> 00:25:50,159
arithmetic to boolean shares and that

676
00:25:50,159 --> 00:25:52,640
makes the whole thing really expensive

677
00:25:52,640 --> 00:25:54,240
the fact that we have polynomial

678
00:25:54,240 --> 00:25:56,720
multipliers or shafts or hash functions

679
00:25:56,720 --> 00:25:58,320
doesn't matter anymore this is the

680
00:25:58,320 --> 00:26:00,640
expensive part if you want to do these

681
00:26:00,640 --> 00:26:01,600
things

682
00:26:01,600 --> 00:26:03,919
so the arithmetic masking that's easy to

683
00:26:03,919 --> 00:26:07,520
protect you can simply split it over

684
00:26:07,520 --> 00:26:10,480
factors are pretty low so if you

685
00:26:10,480 --> 00:26:11,679
have a

686
00:26:11,679 --> 00:26:14,400
the pointer is gone but if you have two

687
00:26:14,400 --> 00:26:16,159
shares it's a factor two if you have

688
00:26:16,159 --> 00:26:18,000
three shares it's a factor three so

689
00:26:18,000 --> 00:26:19,600
that's that's okay

690
00:26:19,600 --> 00:26:21,279
that's the easy part

691
00:26:21,279 --> 00:26:23,919
um it's a bit more expensive for kyber

692
00:26:23,919 --> 00:26:26,480
because you have these explicit um error

693
00:26:26,480 --> 00:26:27,840
terms here

694
00:26:27,840 --> 00:26:29,760
um if you want to protect the hash

695
00:26:29,760 --> 00:26:32,000
function you actually have to go for

696
00:26:32,000 --> 00:26:34,240
boolean masking but there you see

697
00:26:34,240 --> 00:26:36,320
already the cost becomes a bit bigger

698
00:26:36,320 --> 00:26:38,880
right so if you have two shares it goes

699
00:26:38,880 --> 00:26:41,039
between six and ten depends a bit how

700
00:26:41,039 --> 00:26:43,279
you're you're counting or what you call

701
00:26:43,279 --> 00:26:45,840
consider as your uh base

702
00:26:45,840 --> 00:26:47,919
but three stairs you have an overhead

703
00:26:47,919 --> 00:26:50,640
factor of 73 that's already a lot right

704
00:26:50,640 --> 00:26:51,440
so

705
00:26:51,440 --> 00:26:53,120
that the hardware people consider that

706
00:26:53,120 --> 00:26:54,720
too much right

707
00:26:54,720 --> 00:26:57,600
um the same happens for this centered

708
00:26:57,600 --> 00:27:00,159
binomial sample and that's actually

709
00:27:00,159 --> 00:27:02,400
a really complicated one because it uses

710
00:27:02,400 --> 00:27:04,640
a mix of arithmetic to boolean and

711
00:27:04,640 --> 00:27:06,960
boolean to arithmetic it's expensive i'm

712
00:27:06,960 --> 00:27:09,520
gonna go into detail because the one

713
00:27:09,520 --> 00:27:11,360
thing that i do want to

714
00:27:11,360 --> 00:27:15,039
um focus on is the cost say in this case

715
00:27:15,039 --> 00:27:19,360
only from one one only one arithmetic to

716
00:27:19,360 --> 00:27:21,520
boolean conversion cost

717
00:27:21,520 --> 00:27:22,559
so

718
00:27:22,559 --> 00:27:25,039
optimized with bit slicing

719
00:27:25,039 --> 00:27:26,880
because uh to

720
00:27:26,880 --> 00:27:30,080
amortize the cost a bit it costs

721
00:27:30,080 --> 00:27:32,240
60 000 cycles

722
00:27:32,240 --> 00:27:34,960
of work without any useful work being

723
00:27:34,960 --> 00:27:36,080
done

724
00:27:36,080 --> 00:27:38,320
for two shares 200 cycles for three

725
00:27:38,320 --> 00:27:42,000
shares 350 cycles for four shares and on

726
00:27:42,000 --> 00:27:44,480
purpose we put these blocks in big on

727
00:27:44,480 --> 00:27:46,080
this picture because you see there is

728
00:27:46,080 --> 00:27:48,159
two big arithmetic to boolean shares

729
00:27:48,159 --> 00:27:50,000
here

730
00:27:50,000 --> 00:27:51,039
so

731
00:27:51,039 --> 00:27:53,520
to to illustrate how expensive masking

732
00:27:53,520 --> 00:27:56,399
is this would be a typical table that

733
00:27:56,399 --> 00:27:58,240
people given they would say i'm going to

734
00:27:58,240 --> 00:28:01,279
compare cyber to saber to kyber and you

735
00:28:01,279 --> 00:28:02,640
see that

736
00:28:02,640 --> 00:28:06,000
kyber is a bit more expensive than saber

737
00:28:06,000 --> 00:28:08,320
around the factor two depending on the

738
00:28:08,320 --> 00:28:10,240
order um

739
00:28:10,240 --> 00:28:12,159
so but in my opinion they have similar

740
00:28:12,159 --> 00:28:13,200
costs

741
00:28:13,200 --> 00:28:15,360
must unmask they're about the same

742
00:28:15,360 --> 00:28:18,240
depends who's programming this but

743
00:28:18,240 --> 00:28:20,640
masked kyber is a bit more expensive

744
00:28:20,640 --> 00:28:22,880
because of this power of two and because

745
00:28:22,880 --> 00:28:24,960
of the fact that we can use rounding

746
00:28:24,960 --> 00:28:27,679
versus this explicit error sampling but

747
00:28:27,679 --> 00:28:30,640
i think the message really is the cost

748
00:28:30,640 --> 00:28:33,200
of masking compared to unmasked

749
00:28:33,200 --> 00:28:35,120
implementations that's where the cost is

750
00:28:35,120 --> 00:28:38,080
sitting so if unmask is a factor one

751
00:28:38,080 --> 00:28:40,399
first order you have a factor four to

752
00:28:40,399 --> 00:28:42,799
ten overhead second how order you have

753
00:28:42,799 --> 00:28:45,760
factor 7 to 15 overhead

754
00:28:45,760 --> 00:28:48,480
and third order up to a factor 20

755
00:28:48,480 --> 00:28:51,760
overhead plus it requires a large amount

756
00:28:51,760 --> 00:28:54,960
of random bytes 12 kilobytes here

757
00:28:54,960 --> 00:28:58,799
uh 42 kilobytes here 90 kilobytes here

758
00:28:58,799 --> 00:29:01,679
only for like one execution of the the

759
00:29:01,679 --> 00:29:03,679
algorithm so

760
00:29:03,679 --> 00:29:05,840
masking is expensive and it requires

761
00:29:05,840 --> 00:29:07,039
randomness

762
00:29:07,039 --> 00:29:09,919
and so that's the two topics or that's

763
00:29:09,919 --> 00:29:12,399
that randomness topic is the next topic

764
00:29:12,399 --> 00:29:16,159
i want to address so i think from

765
00:29:16,159 --> 00:29:17,120
crypto

766
00:29:17,120 --> 00:29:19,360
viewpoint it would be nice to come up

767
00:29:19,360 --> 00:29:20,320
with

768
00:29:20,320 --> 00:29:24,000
um computational units which are easy to

769
00:29:24,000 --> 00:29:26,399
mask right if that's at least that could

770
00:29:26,399 --> 00:29:28,720
be a research topic to work on instead

771
00:29:28,720 --> 00:29:31,200
of having this mix and match and have an

772
00:29:31,200 --> 00:29:33,520
expensive hash and so on

773
00:29:33,520 --> 00:29:36,320
so the next topic is randomness

774
00:29:36,320 --> 00:29:38,720
randomness is for many crypt security

775
00:29:38,720 --> 00:29:40,720
protocols something that's kind of

776
00:29:40,720 --> 00:29:42,559
falling out of

777
00:29:42,559 --> 00:29:45,678
out of the air usually

778
00:29:46,799 --> 00:29:47,760
and i

779
00:29:47,760 --> 00:29:49,440
illustrate this

780
00:29:49,440 --> 00:29:51,520
with this

781
00:29:51,520 --> 00:29:53,760
simple protocol what the protocol

782
00:29:53,760 --> 00:29:56,000
exactly does is not important but that's

783
00:29:56,000 --> 00:29:59,039
typically how crypto protocol papers

784
00:29:59,039 --> 00:30:01,760
look at it and so you have somewhere

785
00:30:01,760 --> 00:30:02,880
a state

786
00:30:02,880 --> 00:30:05,279
and this was a protocol for rfid tag

787
00:30:05,279 --> 00:30:07,679
this was the time when we were working

788
00:30:07,679 --> 00:30:11,440
on our um low power elliptic

789
00:30:11,440 --> 00:30:14,399
curve unit um and so we wanted to put

790
00:30:14,399 --> 00:30:16,880
that somewhere in attack and so

791
00:30:16,880 --> 00:30:19,919
some proper uh protocols were developed

792
00:30:19,919 --> 00:30:22,799
so you have a tag and you have a reader

793
00:30:22,799 --> 00:30:24,320
and the tag

794
00:30:24,320 --> 00:30:26,399
is a cheap device

795
00:30:26,399 --> 00:30:28,720
and so you on this thing you actually

796
00:30:28,720 --> 00:30:31,919
see two types of randomness you have

797
00:30:31,919 --> 00:30:34,159
secrets because you have a secret part

798
00:30:34,159 --> 00:30:35,919
and a public part you're also secret

799
00:30:35,919 --> 00:30:38,000
part on a public part and you have

800
00:30:38,000 --> 00:30:40,159
randomness that's being generated by the

801
00:30:40,159 --> 00:30:42,399
tag or randomness being generated by the

802
00:30:42,399 --> 00:30:44,559
reader so we have two forms of

803
00:30:44,559 --> 00:30:47,360
randomness and randomness again

804
00:30:47,360 --> 00:30:50,399
there doesn't appear by itself right

805
00:30:50,399 --> 00:30:51,760
so

806
00:30:51,760 --> 00:30:52,799
we have

807
00:30:52,799 --> 00:30:55,039
uh in hardware and actually two ends of

808
00:30:55,039 --> 00:30:56,320
randomness

809
00:30:56,320 --> 00:30:59,519
the first one is is that we want fixed

810
00:30:59,519 --> 00:31:02,000
randomness which is stable over time

811
00:31:02,000 --> 00:31:04,000
which you can use as a secret key which

812
00:31:04,000 --> 00:31:06,399
provides you entropy for a secret coup

813
00:31:06,399 --> 00:31:07,679
or we have

814
00:31:07,679 --> 00:31:10,159
a varying randomness which changes over

815
00:31:10,159 --> 00:31:11,200
time

816
00:31:11,200 --> 00:31:13,039
and that's the randomness which you use

817
00:31:13,039 --> 00:31:15,360
for a true random number generator

818
00:31:15,360 --> 00:31:17,840
um and on purpose i've shown the same

819
00:31:17,840 --> 00:31:20,720
circuit here this is actually

820
00:31:20,720 --> 00:31:24,080
as ram cell an ezram cell can

821
00:31:24,080 --> 00:31:26,320
part of an sram can be used

822
00:31:26,320 --> 00:31:28,000
to generate physically in clonable

823
00:31:28,000 --> 00:31:29,760
function and from that you can derive a

824
00:31:29,760 --> 00:31:31,360
secret key

825
00:31:31,360 --> 00:31:33,279
the same

826
00:31:33,279 --> 00:31:34,159
cell

827
00:31:34,159 --> 00:31:36,399
but then different differently addressed

828
00:31:36,399 --> 00:31:38,720
actually becomes a meta stable cell and

829
00:31:38,720 --> 00:31:41,039
this meta stability can be used to

830
00:31:41,039 --> 00:31:43,200
generate true random number generators

831
00:31:43,200 --> 00:31:44,960
actually really high quality random

832
00:31:44,960 --> 00:31:46,960
number generators are being developed

833
00:31:46,960 --> 00:31:47,919
for that

834
00:31:47,919 --> 00:31:51,440
now in this case you have

835
00:31:51,440 --> 00:31:54,960
um you want fixed randomness and we are

836
00:31:54,960 --> 00:31:57,679
annoyed by the time varying randomness

837
00:31:57,679 --> 00:31:59,919
it's called time varying noise because

838
00:31:59,919 --> 00:32:02,480
of process variations timing

839
00:32:02,480 --> 00:32:04,880
environmental variations and so on and

840
00:32:04,880 --> 00:32:07,519
here if we want a true number generator

841
00:32:07,519 --> 00:32:10,159
we want fresh randomness each time we

842
00:32:10,159 --> 00:32:12,080
call it but we might sit with fixed

843
00:32:12,080 --> 00:32:14,559
noise because of biases in the circuit

844
00:32:14,559 --> 00:32:17,279
and these are also the consequence of

845
00:32:17,279 --> 00:32:20,320
process variations uh and so on

846
00:32:20,320 --> 00:32:22,159
so i'm gonna discuss both types of

847
00:32:22,159 --> 00:32:25,039
randomness a bit now and maybe give some

848
00:32:25,039 --> 00:32:27,279
in some hints on how we can work

849
00:32:27,279 --> 00:32:28,559
together

850
00:32:28,559 --> 00:32:30,799
so the fixed randomness they're also

851
00:32:30,799 --> 00:32:32,480
called silicon physically on clonable

852
00:32:32,480 --> 00:32:34,159
functions

853
00:32:34,159 --> 00:32:36,480
and so the purpose is to have a cheap

854
00:32:36,480 --> 00:32:38,880
unique id or key

855
00:32:38,880 --> 00:32:41,200
on your chip and they want to use this

856
00:32:41,200 --> 00:32:42,399
to replace

857
00:32:42,399 --> 00:32:45,120
the more expensive non-volatile memory

858
00:32:45,120 --> 00:32:46,399
because you have to realize that

859
00:32:46,399 --> 00:32:49,440
non-volatile memory in a cheap device is

860
00:32:49,440 --> 00:32:51,679
extra processing chips and steps and

861
00:32:51,679 --> 00:32:54,799
makes it more expensive

862
00:32:54,799 --> 00:32:56,960
also you could use if you don't have

863
00:32:56,960 --> 00:32:58,640
non-volatile memory you don't have the

864
00:32:58,640 --> 00:33:01,600
process um you could use fuses but fuses

865
00:33:01,600 --> 00:33:04,480
are big i mean we can you can almost you

866
00:33:04,480 --> 00:33:06,320
don't need much of a microscope to see

867
00:33:06,320 --> 00:33:07,120
them

868
00:33:07,120 --> 00:33:10,159
um and you only have very few maybe 50

869
00:33:10,159 --> 00:33:12,799
to 100 fuses on a chip and the last one

870
00:33:12,799 --> 00:33:14,480
what you sometimes see is battery back

871
00:33:14,480 --> 00:33:16,799
as ram so we have sram to store the key

872
00:33:16,799 --> 00:33:18,559
but there's actually battery a little

873
00:33:18,559 --> 00:33:20,960
coin battery on the outside to keep your

874
00:33:20,960 --> 00:33:23,760
secret now that's also kind of annoying

875
00:33:23,760 --> 00:33:25,039
if people start to play with their

876
00:33:25,039 --> 00:33:27,120
battery things are gone and so on so we

877
00:33:27,120 --> 00:33:29,760
want something which is cheap

878
00:33:29,760 --> 00:33:32,399
and can be used in an embedded context

879
00:33:32,399 --> 00:33:34,240
um

880
00:33:34,240 --> 00:33:35,840
and there can be i mean where we have

881
00:33:35,840 --> 00:33:39,679
constraints and costs and resources

882
00:33:39,679 --> 00:33:42,720
this variability sits in the chips so i

883
00:33:42,720 --> 00:33:45,279
have two pictures here

884
00:33:45,279 --> 00:33:47,600
it could be because you have dopant

885
00:33:47,600 --> 00:33:50,240
variations and this is a

886
00:33:50,240 --> 00:33:52,320
a picture of a wire and you can see this

887
00:33:52,320 --> 00:33:54,080
is not perfect but so you have

888
00:33:54,080 --> 00:33:55,840
variations in resistance value

889
00:33:55,840 --> 00:33:58,960
capacitance values um things like that

890
00:33:58,960 --> 00:34:00,240
so

891
00:34:00,240 --> 00:34:02,799
what during fabrications of of chips

892
00:34:02,799 --> 00:34:04,960
people try to reduce those effects and

893
00:34:04,960 --> 00:34:07,039
you buy a digital chip it's going to be

894
00:34:07,039 --> 00:34:08,719
reliable always

895
00:34:08,719 --> 00:34:10,480
generate the same thing but in practice

896
00:34:10,480 --> 00:34:12,800
there's a lot of compensation techniques

897
00:34:12,800 --> 00:34:14,480
that go into do this

898
00:34:14,480 --> 00:34:17,040
and it gets even worse when you scale

899
00:34:17,040 --> 00:34:18,239
down

900
00:34:18,239 --> 00:34:21,119
um oops these are the pictures uh if you

901
00:34:21,119 --> 00:34:23,440
scale down say moore's law now we are

902
00:34:23,440 --> 00:34:26,320
down to seven nanometers five nanometers

903
00:34:26,320 --> 00:34:28,719
so you get more processing steps more

904
00:34:28,719 --> 00:34:31,679
layers of metals new materials

905
00:34:31,679 --> 00:34:34,560
and decrease sizes actually increases

906
00:34:34,560 --> 00:34:36,639
the variabilities and you can see for

907
00:34:36,639 --> 00:34:38,800
those that ever had an electronics class

908
00:34:38,800 --> 00:34:42,320
this is a just a planar

909
00:34:42,320 --> 00:34:43,359
planar

910
00:34:43,359 --> 00:34:44,960
transistor like the gate drains and

911
00:34:44,960 --> 00:34:48,079
source these days from 60 nanometers on

912
00:34:48,079 --> 00:34:50,719
you have finfets finfets kind of creates

913
00:34:50,719 --> 00:34:52,159
you more surface

914
00:34:52,159 --> 00:34:54,480
so you have more transistor area

915
00:34:54,480 --> 00:34:57,119
and these days these are not in in

916
00:34:57,119 --> 00:34:59,200
production yet i think these are called

917
00:34:59,200 --> 00:35:01,200
gates all around you see all these gates

918
00:35:01,200 --> 00:35:03,839
here going and so you have more surface

919
00:35:03,839 --> 00:35:05,440
but you can understand that this is

920
00:35:05,440 --> 00:35:07,440
going to have actually also much more

921
00:35:07,440 --> 00:35:10,079
process variability

922
00:35:10,079 --> 00:35:12,240
um but to make this useful

923
00:35:12,240 --> 00:35:16,640
in a security or protocol context

924
00:35:16,640 --> 00:35:17,680
these

925
00:35:17,680 --> 00:35:19,599
process variations are modeled by

926
00:35:19,599 --> 00:35:22,079
so-called puffs and a pub is a function

927
00:35:22,079 --> 00:35:24,720
we want this function to be binary so

928
00:35:24,720 --> 00:35:26,880
binary means you give it an input

929
00:35:26,880 --> 00:35:28,720
challenge and there's going to be an

930
00:35:28,720 --> 00:35:32,800
output response and this um the way it

931
00:35:32,800 --> 00:35:34,960
works then you're gonna have a set of

932
00:35:34,960 --> 00:35:37,359
challenge response pairs that go or

933
00:35:37,359 --> 00:35:40,079
corresponds to your chip we want them to

934
00:35:40,079 --> 00:35:44,720
be easy to evaluate of course um

935
00:35:44,720 --> 00:35:45,839
so

936
00:35:45,839 --> 00:35:48,320
this is would be an ideal picture of the

937
00:35:48,320 --> 00:35:50,880
more almost ideal puff picture is that

938
00:35:50,880 --> 00:35:54,000
you give it a random challenge 128 bit

939
00:35:54,000 --> 00:35:57,520
uh challenge and you would get 128-bit

940
00:35:57,520 --> 00:35:59,839
response now

941
00:35:59,839 --> 00:36:00,800
between

942
00:36:00,800 --> 00:36:03,599
two chips two different chips the

943
00:36:03,599 --> 00:36:06,000
responses should be statistically fifty

944
00:36:06,000 --> 00:36:07,520
percent difference right

945
00:36:07,520 --> 00:36:08,640
um

946
00:36:08,640 --> 00:36:10,320
and we and

947
00:36:10,320 --> 00:36:12,480
with the way we want this is that

948
00:36:12,480 --> 00:36:15,040
these responses are of course unique

949
00:36:15,040 --> 00:36:17,760
unpredictable if you have a few

950
00:36:17,760 --> 00:36:19,599
challenge response pairs you should not

951
00:36:19,599 --> 00:36:21,760
be able to predict the next one

952
00:36:21,760 --> 00:36:24,079
unclonable it means if you

953
00:36:24,079 --> 00:36:25,839
kind of open up the chip or you poke

954
00:36:25,839 --> 00:36:27,520
with the chip the the chalice response

955
00:36:27,520 --> 00:36:28,800
pairs are gone

956
00:36:28,800 --> 00:36:31,440
uh intrinsic so no extra processing

957
00:36:31,440 --> 00:36:35,040
steps temper proof stable and so on

958
00:36:35,040 --> 00:36:36,640
um

959
00:36:36,640 --> 00:36:38,560
the first message that i want to give

960
00:36:38,560 --> 00:36:40,560
you is that those are these perfs don't

961
00:36:40,560 --> 00:36:43,599
exist forget about it it doesn't exist

962
00:36:43,599 --> 00:36:47,040
so in reality you actually see two types

963
00:36:47,040 --> 00:36:48,880
of paths appearing

964
00:36:48,880 --> 00:36:50,880
the first one are called keypads

965
00:36:50,880 --> 00:36:52,800
sometimes also called weak paths but i

966
00:36:52,800 --> 00:36:54,400
don't like that terminology

967
00:36:54,400 --> 00:36:56,000
and the second category is called

968
00:36:56,000 --> 00:36:58,079
authentication puffs and authentication

969
00:36:58,079 --> 00:36:59,599
paths have been developed trying to

970
00:36:59,599 --> 00:37:02,320
avoid crypto but i think you need crypto

971
00:37:02,320 --> 00:37:05,520
to make uh quality keypuff right

972
00:37:05,520 --> 00:37:08,160
the key the key generation puffs

973
00:37:08,160 --> 00:37:12,480
actually are an array of identically

974
00:37:12,480 --> 00:37:15,520
designed and identically processed uh

975
00:37:15,520 --> 00:37:16,880
elements

976
00:37:16,880 --> 00:37:18,320
but we're going to use the process

977
00:37:18,320 --> 00:37:19,920
variation all right

978
00:37:19,920 --> 00:37:22,480
so this is uh

979
00:37:22,480 --> 00:37:25,280
and each element generates one or a few

980
00:37:25,280 --> 00:37:27,760
response bits these response bits are

981
00:37:27,760 --> 00:37:31,280
high quality so you have high entropy

982
00:37:31,280 --> 00:37:33,200
um but you have a limited number for

983
00:37:33,200 --> 00:37:37,359
instance in azram buff 1024 or 2000 bits

984
00:37:37,359 --> 00:37:39,839
sram might be able to generate you a

985
00:37:39,839 --> 00:37:43,359
128-bit key

986
00:37:44,160 --> 00:37:46,320
but yeah the weak terminology we don't

987
00:37:46,320 --> 00:37:48,880
like that so don't use it anymore

988
00:37:48,880 --> 00:37:50,640
besides that there has also been

989
00:37:50,640 --> 00:37:52,960
proposed um

990
00:37:52,960 --> 00:37:55,200
authentication puffs so-called strong

991
00:37:55,200 --> 00:37:56,240
puffs

992
00:37:56,240 --> 00:37:57,520
the

993
00:37:57,520 --> 00:38:00,079
what we do there again we have an array

994
00:38:00,079 --> 00:38:03,200
of identically processed elements but we

995
00:38:03,200 --> 00:38:05,680
start to do operations at the circuit

996
00:38:05,680 --> 00:38:08,480
level some of delays comparing

997
00:38:08,480 --> 00:38:11,280
frequencies adding up currents comparing

998
00:38:11,280 --> 00:38:13,280
voltages things like that

999
00:38:13,280 --> 00:38:15,920
so in that this way you can create a

1000
00:38:15,920 --> 00:38:18,480
bigger challenge response space

1001
00:38:18,480 --> 00:38:21,119
also might have authentication purposes

1002
00:38:21,119 --> 00:38:23,119
the problem is that they're really low

1003
00:38:23,119 --> 00:38:25,359
quality that these challenge responses

1004
00:38:25,359 --> 00:38:27,599
are highly correlated usually low

1005
00:38:27,599 --> 00:38:29,760
entropy and mostly broken the individual

1006
00:38:29,760 --> 00:38:32,320
elements might have entropy but not the

1007
00:38:32,320 --> 00:38:34,240
way they're being combined and the

1008
00:38:34,240 --> 00:38:35,839
reason they were introduced is because

1009
00:38:35,839 --> 00:38:37,920
they wanted to avoid that you have push

1010
00:38:37,920 --> 00:38:40,800
processing to generate like a secret key

1011
00:38:40,800 --> 00:38:42,800
most well known example was the arbiter

1012
00:38:42,800 --> 00:38:46,320
puff which comes out of mit and typical

1013
00:38:46,320 --> 00:38:48,800
application was i see authentication but

1014
00:38:48,800 --> 00:38:49,920
basically

1015
00:38:49,920 --> 00:38:52,320
that's broken

1016
00:38:52,320 --> 00:38:55,359
um so i want to show you how a weak path

1017
00:38:55,359 --> 00:38:57,520
is built and so this is an example of an

1018
00:38:57,520 --> 00:38:58,720
ezram

1019
00:38:58,720 --> 00:39:00,960
so these are back to back transistor

1020
00:39:00,960 --> 00:39:03,760
with access transistors uh uh access

1021
00:39:03,760 --> 00:39:05,839
transistors again and here you see a

1022
00:39:05,839 --> 00:39:07,520
typical readout

1023
00:39:07,520 --> 00:39:10,320
if this thing is balancedly processed

1024
00:39:10,320 --> 00:39:12,400
and you power it up

1025
00:39:12,400 --> 00:39:14,320
uh even sram when you power it up it

1026
00:39:14,320 --> 00:39:16,000
doesn't know whether it should have

1027
00:39:16,000 --> 00:39:19,040
stored zero or stored one so it will at

1028
00:39:19,040 --> 00:39:21,440
random either store zero r1 for a

1029
00:39:21,440 --> 00:39:23,200
balanced circuit

1030
00:39:23,200 --> 00:39:26,400
um if and so on this particular sram

1031
00:39:26,400 --> 00:39:29,200
powering it up some bits where zero is

1032
00:39:29,200 --> 00:39:30,079
black

1033
00:39:30,079 --> 00:39:31,040
uh

1034
00:39:31,040 --> 00:39:32,960
one is white but you if you look

1035
00:39:32,960 --> 00:39:35,520
carefully you see also gray dots and the

1036
00:39:35,520 --> 00:39:38,880
gray dots are for puff concept unstable

1037
00:39:38,880 --> 00:39:40,880
bits so if you have multiple power ups

1038
00:39:40,880 --> 00:39:42,560
sometimes they power up to zero

1039
00:39:42,560 --> 00:39:44,800
sometimes they power up at one we don't

1040
00:39:44,800 --> 00:39:47,200
um want them for secret key maybe we can

1041
00:39:47,200 --> 00:39:50,079
use them as a random number right

1042
00:39:50,079 --> 00:39:53,040
and so the quality of um

1043
00:39:53,040 --> 00:39:56,160
puffs is being evaluated by measuring

1044
00:39:56,160 --> 00:39:57,839
actually some statistic the

1045
00:39:57,839 --> 00:40:00,240
interdistance and the interrupt distance

1046
00:40:00,240 --> 00:40:02,160
inter distance means what's the

1047
00:40:02,160 --> 00:40:04,240
statistical difference to

1048
00:40:04,240 --> 00:40:05,839
two identically

1049
00:40:05,839 --> 00:40:08,960
produced paths but the responses and 50

1050
00:40:08,960 --> 00:40:11,760
is ideal interrupt distance means what's

1051
00:40:11,760 --> 00:40:13,599
the difference between multiple readings

1052
00:40:13,599 --> 00:40:15,280
of the same path that gives you a

1053
00:40:15,280 --> 00:40:17,440
measure of uh stability

1054
00:40:17,440 --> 00:40:20,079
and so we want to avoid the gray reads

1055
00:40:20,079 --> 00:40:22,640
up so and these are typical exams 50

1056
00:40:22,640 --> 00:40:24,640
here percent there

1057
00:40:24,640 --> 00:40:26,319
um

1058
00:40:26,319 --> 00:40:27,280
um

1059
00:40:27,280 --> 00:40:29,040
we've done some exercise at some point

1060
00:40:29,040 --> 00:40:31,200
in uh in the context of the european

1061
00:40:31,200 --> 00:40:33,319
project and you can see

1062
00:40:33,319 --> 00:40:35,760
microcontrollers have embedded sram

1063
00:40:35,760 --> 00:40:37,839
because you use it

1064
00:40:37,839 --> 00:40:40,480
but some of them have nicely statistic

1065
00:40:40,480 --> 00:40:42,880
nice statistical properties so this sram

1066
00:40:42,880 --> 00:40:43,920
for instance was in a peak

1067
00:40:43,920 --> 00:40:46,480
microcontroller i would not use it or

1068
00:40:46,480 --> 00:40:49,520
you can clearly see that it has reduced

1069
00:40:49,520 --> 00:40:51,839
entropy and that's also visible here

1070
00:40:51,839 --> 00:40:53,119
it's um

1071
00:40:53,119 --> 00:40:55,119
it's uh interrupt distance was a bit

1072
00:40:55,119 --> 00:40:57,280
better but especially inter distance was

1073
00:40:57,280 --> 00:40:59,680
uh bad

1074
00:40:59,680 --> 00:41:01,359
like this st

1075
00:41:01,359 --> 00:41:05,680
processor has a much better um responses

1076
00:41:05,680 --> 00:41:07,920
so the there's much more entropy in in

1077
00:41:07,920 --> 00:41:09,119
its ezram

1078
00:41:09,119 --> 00:41:10,880
but it has a higher

1079
00:41:10,880 --> 00:41:12,960
noise level so we have to compensate for

1080
00:41:12,960 --> 00:41:15,520
them uh one of the problems here also is

1081
00:41:15,520 --> 00:41:16,640
that we have to look at these

1082
00:41:16,640 --> 00:41:18,720
microcontrollers as black boxes so if

1083
00:41:18,720 --> 00:41:20,400
you buy a new batch you might have to

1084
00:41:20,400 --> 00:41:22,400
characterize it again and so the whole

1085
00:41:22,400 --> 00:41:25,119
exercise has to be done again right

1086
00:41:25,119 --> 00:41:27,520
now that brings me to to

1087
00:41:27,520 --> 00:41:30,000
from this path we still don't have a key

1088
00:41:30,000 --> 00:41:30,880
right

1089
00:41:30,880 --> 00:41:32,319
um so

1090
00:41:32,319 --> 00:41:34,880
cryptographic keys um

1091
00:41:34,880 --> 00:41:38,079
what you want is so you have a puff

1092
00:41:38,079 --> 00:41:40,000
the path comes with its internal

1093
00:41:40,000 --> 00:41:41,359
distance and inter distance

1094
00:41:41,359 --> 00:41:44,079
characterization which is not perfect

1095
00:41:44,079 --> 00:41:47,520
then comes this perf this kind of black

1096
00:41:47,520 --> 00:41:48,480
box

1097
00:41:48,480 --> 00:41:50,960
and out of this black box comes the

1098
00:41:50,960 --> 00:41:54,160
perfect cryptographic key 128 bits

1099
00:41:54,160 --> 00:41:57,760
immediately usable in a crypto algorithm

1100
00:41:57,760 --> 00:42:00,640
now this box this magic box is kind of

1101
00:42:00,640 --> 00:42:03,119
the interface between the hardware

1102
00:42:03,119 --> 00:42:04,880
and the crypto but this is also

1103
00:42:04,880 --> 00:42:07,680
difficult to make right

1104
00:42:07,680 --> 00:42:11,119
so in practice how it goes is actually

1105
00:42:11,119 --> 00:42:14,800
that there is these constructions um and

1106
00:42:14,800 --> 00:42:17,599
so you try to measure the entropy

1107
00:42:17,599 --> 00:42:19,440
or you do that statistically an

1108
00:42:19,440 --> 00:42:22,079
evaluation of bunch of chips and you

1109
00:42:22,079 --> 00:42:22,880
have

1110
00:42:22,880 --> 00:42:25,839
the spuf comes with a certain amount of

1111
00:42:25,839 --> 00:42:28,560
entropy which is not perfect there is

1112
00:42:28,560 --> 00:42:31,440
all these variations and so comes with

1113
00:42:31,440 --> 00:42:33,520
so-called helper data algorithms if

1114
00:42:33,520 --> 00:42:35,760
you're in the field you know what i mean

1115
00:42:35,760 --> 00:42:38,640
um and the helper data on the algorithms

1116
00:42:38,640 --> 00:42:41,359
will help you to stabilize your key will

1117
00:42:41,359 --> 00:42:45,119
also help you to get um um

1118
00:42:45,119 --> 00:42:47,520
perfect 100 i mean perfect perfect

1119
00:42:47,520 --> 00:42:50,240
doesn't exist but a high entropy uh key

1120
00:42:50,240 --> 00:42:52,960
out of it so the remaining key what

1121
00:42:52,960 --> 00:42:54,880
comes out is then the perfect one the

1122
00:42:54,880 --> 00:42:58,880
120 bit uh key that you have now

1123
00:42:58,880 --> 00:43:01,280
implementing implementing this helper

1124
00:43:01,280 --> 00:43:03,760
data algorithms typically the solution

1125
00:43:03,760 --> 00:43:05,599
you see is that

1126
00:43:05,599 --> 00:43:07,760
this is now we're working in the whole

1127
00:43:07,760 --> 00:43:09,520
embedded design

1128
00:43:09,520 --> 00:43:13,440
so um you have a puff um that puff wants

1129
00:43:13,440 --> 00:43:16,079
we want to use this lightweight key and

1130
00:43:16,079 --> 00:43:18,240
then have a lightweight crypto algorithm

1131
00:43:18,240 --> 00:43:21,280
here the problem is between the puff and

1132
00:43:21,280 --> 00:43:23,200
the light with crypto algorithm we have

1133
00:43:23,200 --> 00:43:25,760
two big blocks and the first one is this

1134
00:43:25,760 --> 00:43:28,079
helper data algorithm is to

1135
00:43:28,079 --> 00:43:31,280
uh correct errors drop and unreliable

1136
00:43:31,280 --> 00:43:33,119
bits and things like that and then

1137
00:43:33,119 --> 00:43:35,280
typically it goes to

1138
00:43:35,280 --> 00:43:37,280
universal or cryptographic hash in

1139
00:43:37,280 --> 00:43:39,440
practice cryptographic hash function and

1140
00:43:39,440 --> 00:43:41,920
then you get this perfect 128 bit key

1141
00:43:41,920 --> 00:43:44,640
and i've drawn it small because these

1142
00:43:44,640 --> 00:43:45,520
are

1143
00:43:45,520 --> 00:43:47,520
now the big parts on chip

1144
00:43:47,520 --> 00:43:50,000
so what would be nice from this

1145
00:43:50,000 --> 00:43:52,880
community actually is that

1146
00:43:52,880 --> 00:43:55,599
you can tolerate not so perfect keys

1147
00:43:55,599 --> 00:43:58,079
that would be nice if you can give me an

1148
00:43:58,079 --> 00:44:00,599
algorithm that i can tell you you get

1149
00:44:00,599 --> 00:44:03,920
256 bits or maybe you get 512 bits of

1150
00:44:03,920 --> 00:44:06,160
key material but it's not perfect what

1151
00:44:06,160 --> 00:44:07,920
can you do with it that would be really

1152
00:44:07,920 --> 00:44:09,040
nice right

1153
00:44:09,040 --> 00:44:11,520
that could avoid all this i mean avoid

1154
00:44:11,520 --> 00:44:13,680
part of these intermediate steps and so

1155
00:44:13,680 --> 00:44:16,000
it's okay if that block is now big

1156
00:44:16,000 --> 00:44:17,920
bitter but it's still going to be the

1157
00:44:17,920 --> 00:44:20,800
overall design is going to be uh smaller

1158
00:44:20,800 --> 00:44:23,599
so we need secure lightweight key

1159
00:44:23,599 --> 00:44:26,720
generation but can you work with

1160
00:44:26,720 --> 00:44:28,480
key material which is maybe not so

1161
00:44:28,480 --> 00:44:31,200
perfect um we can discuss how this

1162
00:44:31,200 --> 00:44:33,680
should be modeled right um

1163
00:44:33,680 --> 00:44:35,839
we know if it's we know the

1164
00:44:35,839 --> 00:44:38,400
cryptographic security assuming a

1165
00:44:38,400 --> 00:44:40,720
perfect key but what's the cryptographic

1166
00:44:40,720 --> 00:44:43,359
security if it's not perfect i don't

1167
00:44:43,359 --> 00:44:46,000
have an answer but would be nice topic

1168
00:44:46,000 --> 00:44:48,720
and that brings me last to my last topic

1169
00:44:48,720 --> 00:44:51,280
um that's the cost of true random number

1170
00:44:51,280 --> 00:44:53,040
generators and we basically have a bit

1171
00:44:53,040 --> 00:44:55,359
of the same problem there we have the

1172
00:44:55,359 --> 00:44:57,920
same problem is that many of these

1173
00:44:57,920 --> 00:45:00,079
protocols um

1174
00:45:00,079 --> 00:45:02,839
require perfect randomness perfect

1175
00:45:02,839 --> 00:45:05,520
unpredictability of the numbers and also

1176
00:45:05,520 --> 00:45:06,400
there

1177
00:45:06,400 --> 00:45:08,880
would be nice if some of it could be

1178
00:45:08,880 --> 00:45:11,280
kind of relaxed i would say

1179
00:45:11,280 --> 00:45:13,440
so i'm going to show you some design

1180
00:45:13,440 --> 00:45:16,800
attacks on random numbers

1181
00:45:16,880 --> 00:45:18,480
and for random numbers we actually can

1182
00:45:18,480 --> 00:45:19,920
make similar pictures the only

1183
00:45:19,920 --> 00:45:22,240
difference is they change over time

1184
00:45:22,240 --> 00:45:25,200
so if you look at the architecture of a

1185
00:45:25,200 --> 00:45:27,920
true random number generator that wants

1186
00:45:27,920 --> 00:45:29,520
to pass

1187
00:45:29,520 --> 00:45:32,560
german or u.s standardization efforts

1188
00:45:32,560 --> 00:45:35,119
there's a big design there's a big block

1189
00:45:35,119 --> 00:45:38,319
so you have the noise source the noise

1190
00:45:38,319 --> 00:45:40,800
source can be your um

1191
00:45:40,800 --> 00:45:44,079
metastable meta stable srams can also be

1192
00:45:44,079 --> 00:45:46,400
clogged jitter can can be all kinds of

1193
00:45:46,400 --> 00:45:47,359
effects

1194
00:45:47,359 --> 00:45:51,200
that typically goes to some digitizer

1195
00:45:51,200 --> 00:45:54,240
and out comes what's called the raw bits

1196
00:45:54,240 --> 00:45:56,880
now the raw bits

1197
00:45:56,880 --> 00:45:58,640
are done being

1198
00:45:58,640 --> 00:46:00,400
algorithmic and cryptographic

1199
00:46:00,400 --> 00:46:01,760
post-processing

1200
00:46:01,760 --> 00:46:03,520
goes through these steps

1201
00:46:03,520 --> 00:46:06,480
to generate internal random bits uh

1202
00:46:06,480 --> 00:46:08,800
which then are perfect to be used right

1203
00:46:08,800 --> 00:46:10,400
which get like the label these are the

1204
00:46:10,400 --> 00:46:11,680
right numbers

1205
00:46:11,680 --> 00:46:14,240
at the bottom you see here a set of

1206
00:46:14,240 --> 00:46:15,839
tests that are going on you have

1207
00:46:15,839 --> 00:46:18,160
randomness monitoring you have health

1208
00:46:18,160 --> 00:46:20,319
tests these are extremely important

1209
00:46:20,319 --> 00:46:22,000
that's where we focus a lot of our

1210
00:46:22,000 --> 00:46:23,920
research up because they operate on the

1211
00:46:23,920 --> 00:46:26,960
raw bits can i if i have a small

1212
00:46:26,960 --> 00:46:30,079
embedded device can i on the spot

1213
00:46:30,079 --> 00:46:32,960
kind of detect that the random numbers

1214
00:46:32,960 --> 00:46:34,960
have decreased quality

1215
00:46:34,960 --> 00:46:37,359
because post processing usually consists

1216
00:46:37,359 --> 00:46:39,520
of some crypto algorithms and if you do

1217
00:46:39,520 --> 00:46:42,000
statistical tests here they all pass of

1218
00:46:42,000 --> 00:46:44,000
course right so there are some tests

1219
00:46:44,000 --> 00:46:45,200
there too

1220
00:46:45,200 --> 00:46:48,160
um just to show you what what's the game

1221
00:46:48,160 --> 00:46:50,400
that's going on that's the game between

1222
00:46:50,400 --> 00:46:53,680
uh attacks and and defenses um

1223
00:46:53,680 --> 00:46:57,200
we have uh this is the work of uh saki

1224
00:46:57,200 --> 00:46:59,520
osuka

1225
00:46:59,520 --> 00:47:01,920
this is a ring oscillators uh random

1226
00:47:01,920 --> 00:47:03,440
number generators based on renal

1227
00:47:03,440 --> 00:47:06,640
oscillators and we want to attack them

1228
00:47:06,640 --> 00:47:08,560
from a distance

1229
00:47:08,560 --> 00:47:10,480
so um

1230
00:47:10,480 --> 00:47:13,119
and depending on which frequency you use

1231
00:47:13,119 --> 00:47:15,920
you can either influence it and that's

1232
00:47:15,920 --> 00:47:18,079
already visually seen here and so there

1233
00:47:18,079 --> 00:47:19,920
is quite some correlation between those

1234
00:47:19,920 --> 00:47:22,319
bits there's a reduced entropy maybe a

1235
00:47:22,319 --> 00:47:24,559
different frequency actually don't

1236
00:47:24,559 --> 00:47:26,559
generate anything of

1237
00:47:26,559 --> 00:47:30,559
results but still you want this online

1238
00:47:30,559 --> 00:47:33,040
little test to detect whether you're in

1239
00:47:33,040 --> 00:47:36,160
this situation or in this situation

1240
00:47:36,160 --> 00:47:37,359
um

1241
00:47:37,359 --> 00:47:38,800
here's the basic structure of ring

1242
00:47:38,800 --> 00:47:41,839
oscillators green oscillators i'm we've

1243
00:47:41,839 --> 00:47:44,079
seen the metastability case now this is

1244
00:47:44,079 --> 00:47:46,079
jitter-based so you have a bunch of

1245
00:47:46,079 --> 00:47:49,200
re-running ring oscillators and there

1246
00:47:49,200 --> 00:47:51,599
might be xor together you might use a

1247
00:47:51,599 --> 00:47:53,920
fourth one or an independent one to

1248
00:47:53,920 --> 00:47:55,599
sample this thing

1249
00:47:55,599 --> 00:47:58,240
you have to let them run for a while so

1250
00:47:58,240 --> 00:48:00,319
that there is enough jitter accumulated

1251
00:48:00,319 --> 00:48:03,599
and then you can um you can

1252
00:48:03,599 --> 00:48:05,599
collect your random numbers

1253
00:48:05,599 --> 00:48:06,960
so

1254
00:48:06,960 --> 00:48:10,000
in a non-locked state so you have the

1255
00:48:10,000 --> 00:48:12,240
normal ring oscillators they kind of all

1256
00:48:12,240 --> 00:48:14,960
run independent uh that's the signal

1257
00:48:14,960 --> 00:48:17,119
that you pick up from the scope and so

1258
00:48:17,119 --> 00:48:18,800
that's the output which corresponds with

1259
00:48:18,800 --> 00:48:21,599
it inject something you see that the

1260
00:48:21,599 --> 00:48:25,440
jitter on the signals is reduced uh

1261
00:48:25,440 --> 00:48:29,440
if you if you select the right frequency

1262
00:48:29,440 --> 00:48:30,960
and then this is the

1263
00:48:30,960 --> 00:48:34,559
the the results you get now visually

1264
00:48:34,559 --> 00:48:36,000
we chose this picture because it's

1265
00:48:36,000 --> 00:48:38,319
visually nice but of course in practice

1266
00:48:38,319 --> 00:48:39,760
you should look at the statistical

1267
00:48:39,760 --> 00:48:42,640
properties of the numbers that come out

1268
00:48:42,640 --> 00:48:44,800
and for that we have all these health

1269
00:48:44,800 --> 00:48:47,119
tests here the health tests and

1270
00:48:47,119 --> 00:48:48,480
post-processing

1271
00:48:48,480 --> 00:48:51,200
and the health tests you actually have

1272
00:48:51,200 --> 00:48:53,359
several options to do these health tests

1273
00:48:53,359 --> 00:48:54,160
right

1274
00:48:54,160 --> 00:48:57,359
so the options you have is

1275
00:48:57,359 --> 00:48:59,280
so you assume you have this little

1276
00:48:59,280 --> 00:49:01,440
sensor note it's going to be implanted

1277
00:49:01,440 --> 00:49:04,400
and it needs random numbers or

1278
00:49:04,400 --> 00:49:06,559
it is some iot device and it needs

1279
00:49:06,559 --> 00:49:09,440
random numbers you can run statistical

1280
00:49:09,440 --> 00:49:12,079
tests if you accumulate enough data you

1281
00:49:12,079 --> 00:49:13,839
can run statistical tests and you're

1282
00:49:13,839 --> 00:49:16,559
going to figure out whether

1283
00:49:16,559 --> 00:49:18,720
these random numbers pass these tests

1284
00:49:18,720 --> 00:49:21,280
and the the standardizations processes

1285
00:49:21,280 --> 00:49:24,240
provide you the set of tests

1286
00:49:24,240 --> 00:49:26,400
um when you want your random number

1287
00:49:26,400 --> 00:49:27,920
generator to be standardized you also

1288
00:49:27,920 --> 00:49:29,760
have to provide a stochastic model so

1289
00:49:29,760 --> 00:49:31,839
you can also verify your stochastic

1290
00:49:31,839 --> 00:49:33,920
model you have jitter physical models

1291
00:49:33,920 --> 00:49:34,960
and so on

1292
00:49:34,960 --> 00:49:36,559
but i think the only thing which will

1293
00:49:36,559 --> 00:49:39,119
work on an embedded context

1294
00:49:39,119 --> 00:49:41,440
is a source specific test because you

1295
00:49:41,440 --> 00:49:44,000
want this thing to be low latency so you

1296
00:49:44,000 --> 00:49:46,240
don't want first to accumulate millions

1297
00:49:46,240 --> 00:49:48,559
and millions of bits do some tests and

1298
00:49:48,559 --> 00:49:50,400
then release the bits no you should be

1299
00:49:50,400 --> 00:49:52,640
able to do this on the fly

1300
00:49:52,640 --> 00:49:54,640
the second thing is that on an embedded

1301
00:49:54,640 --> 00:49:57,440
device you don't have a big disk to

1302
00:49:57,440 --> 00:49:59,680
accumulate all your data so you have to

1303
00:49:59,680 --> 00:50:01,520
kind of make a decision and release the

1304
00:50:01,520 --> 00:50:03,200
bits so you have to think about the

1305
00:50:03,200 --> 00:50:05,520
memory requirements and so on

1306
00:50:05,520 --> 00:50:07,599
um if i would have a bit more time i

1307
00:50:07,599 --> 00:50:09,359
would show you a little

1308
00:50:09,359 --> 00:50:10,640
design on it

1309
00:50:10,640 --> 00:50:12,319
and so in for instance in this

1310
00:50:12,319 --> 00:50:13,599
particular

1311
00:50:13,599 --> 00:50:16,960
case what you could do is you can have a

1312
00:50:16,960 --> 00:50:19,280
simple counter measure on chip which

1313
00:50:19,280 --> 00:50:22,720
would be a bias detection because you're

1314
00:50:22,720 --> 00:50:23,920
going to have

1315
00:50:23,920 --> 00:50:26,400
a bias or correlation detection and so

1316
00:50:26,400 --> 00:50:28,079
your neighbors that

1317
00:50:28,079 --> 00:50:29,839
this thing and you don't need that many

1318
00:50:29,839 --> 00:50:31,280
bits for it

1319
00:50:31,280 --> 00:50:33,839
uh but the attacker will also play with

1320
00:50:33,839 --> 00:50:36,240
it he will try to figure out

1321
00:50:36,240 --> 00:50:39,520
um if you have such detectors on chip

1322
00:50:39,520 --> 00:50:41,839
you have what's called um

1323
00:50:41,839 --> 00:50:43,920
you have to avoid false false alarms

1324
00:50:43,920 --> 00:50:45,599
also where's the statistics and you

1325
00:50:45,599 --> 00:50:47,359
don't want the thing to go too much in

1326
00:50:47,359 --> 00:50:50,160
false alarm and so you have to to figure

1327
00:50:50,160 --> 00:50:52,480
out what are the boundaries

1328
00:50:52,480 --> 00:50:55,440
so that means that the attacker can try

1329
00:50:55,440 --> 00:50:57,839
to stay below the detection rate there

1330
00:50:57,839 --> 00:51:01,040
like by actually turning its wave on and

1331
00:51:01,040 --> 00:51:03,599
off which you see here and so this is

1332
00:51:03,599 --> 00:51:06,160
when the wave is on quite long some and

1333
00:51:06,160 --> 00:51:07,280
so

1334
00:51:07,280 --> 00:51:10,000
this kind of random number still has

1335
00:51:10,000 --> 00:51:12,559
some entropy and so protocol should be

1336
00:51:12,559 --> 00:51:14,559
able to use here and here again it would

1337
00:51:14,559 --> 00:51:17,760
be nice that you that we have protocols

1338
00:51:17,760 --> 00:51:20,480
or figure out is my masking scheme still

1339
00:51:20,480 --> 00:51:23,200
working when i don't have perfect

1340
00:51:23,200 --> 00:51:25,839
random numbers or is my protocol still

1341
00:51:25,839 --> 00:51:27,359
okay if i know

1342
00:51:27,359 --> 00:51:30,000
that actually from my random numbers 75

1343
00:51:30,000 --> 00:51:32,480
percents are ones and 25 percents or

1344
00:51:32,480 --> 00:51:34,400
zeros can you work with it can you

1345
00:51:34,400 --> 00:51:36,400
absorb it so that would be nice because

1346
00:51:36,400 --> 00:51:38,880
that makes the overall system a bit more

1347
00:51:38,880 --> 00:51:40,640
secure

1348
00:51:40,640 --> 00:51:42,800
brings me to my last slide

1349
00:51:42,800 --> 00:51:43,920
um

1350
00:51:43,920 --> 00:51:46,480
so what are the lessons hopefully we

1351
00:51:46,480 --> 00:51:48,240
learned

1352
00:51:48,240 --> 00:51:50,400
provable secure masking does not mean

1353
00:51:50,400 --> 00:51:52,480
secure theory and practice are very

1354
00:51:52,480 --> 00:51:53,680
different

1355
00:51:53,680 --> 00:51:54,880
um

1356
00:51:54,880 --> 00:51:57,520
practical evaluation in the lab of

1357
00:51:57,520 --> 00:51:59,760
theoretical security in my opinion is a

1358
00:51:59,760 --> 00:52:02,559
must we have a lap you can come

1359
00:52:02,559 --> 00:52:03,839
um

1360
00:52:03,839 --> 00:52:05,680
papers should include artifacts

1361
00:52:05,680 --> 00:52:07,839
evaluation other conferences do that if

1362
00:52:07,839 --> 00:52:10,000
you go to youtube you have to submit

1363
00:52:10,000 --> 00:52:12,160
your uh artifacts

1364
00:52:12,160 --> 00:52:14,160
uh the second thing is i think a lot of

1365
00:52:14,160 --> 00:52:16,079
collaboration can happen on masking

1366
00:52:16,079 --> 00:52:19,599
especially higher order masking or other

1367
00:52:19,599 --> 00:52:22,079
techniques they are very expensive

1368
00:52:22,079 --> 00:52:24,240
orders of magnitude

1369
00:52:24,240 --> 00:52:26,079
would be nice to have less stringent

1370
00:52:26,079 --> 00:52:28,319
more realistic models

1371
00:52:28,319 --> 00:52:30,640
reduce the randomness requirements maybe

1372
00:52:30,640 --> 00:52:33,599
the amount as well as the quality

1373
00:52:33,599 --> 00:52:35,760
so work with less perfect keys less

1374
00:52:35,760 --> 00:52:38,000
perfect random requirements and maybe

1375
00:52:38,000 --> 00:52:40,720
trade-off security versus entropy

1376
00:52:40,720 --> 00:52:42,880
in this key of random number generators

1377
00:52:42,880 --> 00:52:44,319
right

1378
00:52:44,319 --> 00:52:46,720
so future work i think

1379
00:52:46,720 --> 00:52:48,400
i've been doing this now for a couple of

1380
00:52:48,400 --> 00:52:50,640
years i want to continue in it

1381
00:52:50,640 --> 00:52:53,119
from the feasibility side so which is

1382
00:52:53,119 --> 00:52:55,760
pushing the boundaries at this moment um

1383
00:52:55,760 --> 00:52:57,280
is this implementation of fully

1384
00:52:57,280 --> 00:52:58,640
homomorphic encryption with

1385
00:52:58,640 --> 00:53:00,400
bootstrapping including including

1386
00:53:00,400 --> 00:53:02,559
and so on we had the presentation at the

1387
00:53:02,559 --> 00:53:05,599
fhe workshop uh on sunday where we

1388
00:53:05,599 --> 00:53:08,960
showed the baseless chip in this context

1389
00:53:08,960 --> 00:53:10,800
i think also we should take advantage of

1390
00:53:10,800 --> 00:53:12,880
novel compute architectures

1391
00:53:12,880 --> 00:53:15,119
multi-core heater genius multi-core

1392
00:53:15,119 --> 00:53:18,400
combined cpus fpgas

1393
00:53:18,400 --> 00:53:19,760
things like that

1394
00:53:19,760 --> 00:53:21,599
um

1395
00:53:21,599 --> 00:53:23,440
a bit more side channel security by

1396
00:53:23,440 --> 00:53:25,760
design so you want to be resistant

1397
00:53:25,760 --> 00:53:27,920
against all kinds of combined fault side

1398
00:53:27,920 --> 00:53:30,880
channel micro architectural attacks

1399
00:53:30,880 --> 00:53:33,119
but taking took our new leakage models

1400
00:53:33,119 --> 00:53:35,599
may be used with a bit less

1401
00:53:35,599 --> 00:53:37,760
perfect randomness

1402
00:53:37,760 --> 00:53:40,000
because we know if we

1403
00:53:40,000 --> 00:53:42,640
take turn the random number off we can

1404
00:53:42,640 --> 00:53:44,319
break the chip if we turn the random

1405
00:53:44,319 --> 00:53:46,800
number on and we have perfect randomness

1406
00:53:46,800 --> 00:53:48,559
the masking might work but what's in

1407
00:53:48,559 --> 00:53:50,240
between right

1408
00:53:50,240 --> 00:53:51,599
um

1409
00:53:51,599 --> 00:53:53,200
and take more advantage of these

1410
00:53:53,200 --> 00:53:54,960
inherent variations in silicon

1411
00:53:54,960 --> 00:53:58,400
technology so one example i showed was

1412
00:53:58,400 --> 00:54:02,160
puff source or ids random numbers but

1413
00:54:02,160 --> 00:54:04,720
also the variable randomness so it's not

1414
00:54:04,720 --> 00:54:06,880
just random number generators but like

1415
00:54:06,880 --> 00:54:08,800
new technologies like approximate

1416
00:54:08,800 --> 00:54:11,359
computing approximate computing is this

1417
00:54:11,359 --> 00:54:14,000
technology where you have can go

1418
00:54:14,000 --> 00:54:16,400
extremely low power but once in a while

1419
00:54:16,400 --> 00:54:18,559
computations will fail so what do you do

1420
00:54:18,559 --> 00:54:21,040
with that right crypto cannot tolerate

1421
00:54:21,040 --> 00:54:23,359
other applications can tolerate that

1422
00:54:23,359 --> 00:54:25,680
so that was my last slide i'm open to

1423
00:54:25,680 --> 00:54:28,558
questions thank you

1424
00:54:37,440 --> 00:54:39,119
thank you very much

1425
00:54:39,119 --> 00:54:41,359
thank you very much ingrid

1426
00:54:41,359 --> 00:54:44,640
we have time for questions now

1427
00:54:50,240 --> 00:54:54,479
that's okay questions

1428
00:54:58,960 --> 00:55:01,599
so on your first one you had um

1429
00:55:01,599 --> 00:55:02,880
all of these papers came with

1430
00:55:02,880 --> 00:55:04,559
implementations that the authors had

1431
00:55:04,559 --> 00:55:07,200
done yeah so

1432
00:55:07,200 --> 00:55:09,920
um can you offer a service in leuven for

1433
00:55:09,920 --> 00:55:12,640
people to um submit their papers and and

1434
00:55:12,640 --> 00:55:14,240
you just run an attack against it

1435
00:55:14,240 --> 00:55:16,720
because if obviously the people writing

1436
00:55:16,720 --> 00:55:18,160
the papers could implement it but they

1437
00:55:18,160 --> 00:55:20,720
can't implement the attack because yeah

1438
00:55:20,720 --> 00:55:24,079
you have a good point there um so um but

1439
00:55:24,079 --> 00:55:26,799
say i know the some of this was done

1440
00:55:26,799 --> 00:55:28,400
saying um

1441
00:55:28,400 --> 00:55:29,839
uh

1442
00:55:29,839 --> 00:55:32,000
so the service which was run say

1443
00:55:32,000 --> 00:55:35,440
uh by by uh peter schwab and his people

1444
00:55:35,440 --> 00:55:37,440
i mean people were claiming i'm so much

1445
00:55:37,440 --> 00:55:39,359
faster than this so their codes they

1446
00:55:39,359 --> 00:55:40,720
could evaluate

1447
00:55:40,720 --> 00:55:44,000
code now this work this eight papers uh

1448
00:55:44,000 --> 00:55:46,880
it was uh it was a couple of months work

1449
00:55:46,880 --> 00:55:48,880
yeah and

1450
00:55:48,880 --> 00:55:50,640
the first thing is get the code to

1451
00:55:50,640 --> 00:55:52,559
running i mean documentation is missing

1452
00:55:52,559 --> 00:55:55,359
but yes we we can collaborate i think

1453
00:55:55,359 --> 00:55:56,640
that's possible

1454
00:55:56,640 --> 00:55:58,960
um

1455
00:55:59,040 --> 00:56:02,040
uh

1456
00:56:02,079 --> 00:56:04,559
go to usenix you have to submit it

1457
00:56:04,559 --> 00:56:06,079
for and you have to submit it for others

1458
00:56:06,079 --> 00:56:08,799
still validate

1459
00:56:10,799 --> 00:56:12,319
plus love and should not be the only

1460
00:56:12,319 --> 00:56:15,799
ones doing this

1461
00:56:16,400 --> 00:56:18,480
i'm gonna charge yes

1462
00:56:18,480 --> 00:56:20,240
yes that's true

1463
00:56:20,240 --> 00:56:22,240
yeah thank you uh are there any more

1464
00:56:22,240 --> 00:56:23,920
questions

1465
00:56:23,920 --> 00:56:26,960
yes there's a question over there

1466
00:56:26,960 --> 00:56:29,040
microphone

1467
00:56:29,040 --> 00:56:30,960
oh yeah uh your mind

1468
00:56:30,960 --> 00:56:33,839
oh there is one here

1469
00:56:39,599 --> 00:56:41,040
yeah thank you so much it was very

1470
00:56:41,040 --> 00:56:42,880
fascinating i have a question that maybe

1471
00:56:42,880 --> 00:56:44,480
applies to everybody in this room

1472
00:56:44,480 --> 00:56:47,760
hardware and algorithms

1473
00:56:47,760 --> 00:56:49,280
basically i'd love to hear your

1474
00:56:49,280 --> 00:56:50,960
perspective on whether we're working at

1475
00:56:50,960 --> 00:56:52,640
the correct level or whether this is

1476
00:56:52,640 --> 00:56:55,359
there's somehow an intrinsic sort of

1477
00:56:55,359 --> 00:56:58,160
tension between the vulnerability and

1478
00:56:58,160 --> 00:57:01,119
the needs to actually get into devices

1479
00:57:01,119 --> 00:57:03,040
maintain them repair them understand

1480
00:57:03,040 --> 00:57:04,960
them and that if we continue to work on

1481
00:57:04,960 --> 00:57:06,799
this level we'll still be sort of the

1482
00:57:06,799 --> 00:57:08,799
ants on the surface looking at very low

1483
00:57:08,799 --> 00:57:11,520
level versus uh you know looking at the

1484
00:57:11,520 --> 00:57:13,920
systems that we're trying to build and

1485
00:57:13,920 --> 00:57:15,920
not yet quite understanding or never

1486
00:57:15,920 --> 00:57:17,839
understanding what their ideal kind of

1487
00:57:17,839 --> 00:57:20,160
specification of functionality is um

1488
00:57:20,160 --> 00:57:22,880
yeah i i i get your point i think it's

1489
00:57:22,880 --> 00:57:24,720
indeed very important and

1490
00:57:24,720 --> 00:57:26,640
we also try i mean not just for the

1491
00:57:26,640 --> 00:57:28,400
crypto part but for also the the

1492
00:57:28,400 --> 00:57:29,839
software people don't need to know

1493
00:57:29,839 --> 00:57:32,079
what's going on the processor right but

1494
00:57:32,079 --> 00:57:34,240
what is what extremely important is

1495
00:57:34,240 --> 00:57:37,520
working on models so representing lower

1496
00:57:37,520 --> 00:57:40,240
levels of abstraction for higher levels

1497
00:57:40,240 --> 00:57:43,040
and in some other fields

1498
00:57:43,040 --> 00:57:45,119
this has done pretty well so at high

1499
00:57:45,119 --> 00:57:47,920
level for instance before i

1500
00:57:47,920 --> 00:57:50,480
tape out a chip i know already i can

1501
00:57:50,480 --> 00:57:52,079
predict how much power it's going to

1502
00:57:52,079 --> 00:57:55,359
consume but at this moment

1503
00:57:55,359 --> 00:57:58,319
we come with a new counter measure

1504
00:57:58,319 --> 00:58:00,640
we can we cannot predict anything it's a

1505
00:58:00,640 --> 00:58:02,720
lot about models that doesn't i mean the

1506
00:58:02,720 --> 00:58:04,799
mod and the existing models say for

1507
00:58:04,799 --> 00:58:06,640
power consumption of a whole chip i know

1508
00:58:06,640 --> 00:58:08,400
beforehand how much power so because i

1509
00:58:08,400 --> 00:58:10,400
have to design beforehand i have to know

1510
00:58:10,400 --> 00:58:11,920
how much cooling i have to provide for

1511
00:58:11,920 --> 00:58:14,240
that ship so i can estimate it before

1512
00:58:14,240 --> 00:58:16,640
even the first tape out and in crypto

1513
00:58:16,640 --> 00:58:18,559
that's kind of missing i mean in in

1514
00:58:18,559 --> 00:58:20,880
security not crypto right

1515
00:58:20,880 --> 00:58:24,000
we our models are way too simple

1516
00:58:24,000 --> 00:58:26,000
thank you

1517
00:58:26,000 --> 00:58:28,160
thank you uh i think ron has a question

1518
00:58:28,160 --> 00:58:29,200
right

1519
00:58:29,200 --> 00:58:30,400
yeah

1520
00:58:30,400 --> 00:58:33,040
all right a couple of questions see uh

1521
00:58:33,040 --> 00:58:34,839
thanks for the presentation great

1522
00:58:34,839 --> 00:58:36,880
presentation um

1523
00:58:36,880 --> 00:58:38,720
so

1524
00:58:38,720 --> 00:58:40,559
if you were to design your own you know

1525
00:58:40,559 --> 00:58:42,880
hash function so that you can implement

1526
00:58:42,880 --> 00:58:45,440
it securely without a

1527
00:58:45,440 --> 00:58:47,839
such channel attack would you be able to

1528
00:58:47,839 --> 00:58:49,680
just from scratch don't implement the

1529
00:58:49,680 --> 00:58:51,680
given thing just what would be the idea

1530
00:58:51,680 --> 00:58:53,760
like we have hash functions which are

1531
00:58:53,760 --> 00:58:55,440
snark friendly or you know pairing you

1532
00:58:55,440 --> 00:58:57,280
know pairing you know whatever uh uh

1533
00:58:57,280 --> 00:58:59,040
recursive composition friendly and high

1534
00:58:59,040 --> 00:59:02,079
level maybe they we can think of wearing

1535
00:59:02,079 --> 00:59:05,200
a hash function that is just like a side

1536
00:59:05,200 --> 00:59:07,839
channel friendly from the beginning uh

1537
00:59:07,839 --> 00:59:09,680
that's maybe you know i'm sure you've

1538
00:59:09,680 --> 00:59:11,359
thought about it it's it's sort of you

1539
00:59:11,359 --> 00:59:13,839
think but uh what your thoughts about it

1540
00:59:13,839 --> 00:59:16,400
another question actually given talk was

1541
00:59:16,400 --> 00:59:19,599
given earlier today about this uh notion

1542
00:59:19,599 --> 00:59:22,079
of uh consumable consumable tokens or

1543
00:59:22,079 --> 00:59:23,839
one out of two memories so there was

1544
00:59:23,839 --> 00:59:26,319
this idea presented many years ago but

1545
00:59:26,319 --> 00:59:28,240
one other two memory that can do

1546
00:59:28,240 --> 00:59:30,480
beautiful things in crypto but can be in

1547
00:59:30,480 --> 00:59:32,960
there even thoughts about implementing

1548
00:59:32,960 --> 00:59:35,520
it in hardware you know just a small not

1549
00:59:35,520 --> 00:59:37,359
something which the whole process or

1550
00:59:37,359 --> 00:59:39,359
something but nothing actually as far as

1551
00:59:39,359 --> 00:59:41,920
i know was implemented this talk

1552
00:59:41,920 --> 00:59:43,440
earlier today was trying to go to

1553
00:59:43,440 --> 00:59:44,960
biology doing something like that but

1554
00:59:44,960 --> 00:59:46,799
maybe we could do it yeah

1555
00:59:46,799 --> 00:59:48,799
so is there any thoughts of that yeah so

1556
00:59:48,799 --> 00:59:50,559
for the first question on hash functions

1557
00:59:50,559 --> 00:59:52,720
um uh

1558
00:59:52,720 --> 00:59:55,119
this is a bit how how pushykin levin

1559
00:59:55,119 --> 00:59:58,839
works then i'll go and ask about purnell

1560
00:59:58,839 --> 01:00:02,640
um but uh so to merge you together yes

1561
01:00:02,640 --> 01:00:03,760
indeed

1562
01:00:03,760 --> 01:00:06,079
so that's i think um

1563
01:00:06,079 --> 01:00:08,799
and and i think it it will go into into

1564
01:00:08,799 --> 01:00:10,000
um

1565
01:00:10,000 --> 01:00:11,839
in two steps uh first

1566
01:00:11,839 --> 01:00:13,920
and this was also first we always go and

1567
01:00:13,920 --> 01:00:15,760
so is this thing feasible can i make it

1568
01:00:15,760 --> 01:00:18,079
compact and then only look at side

1569
01:00:18,079 --> 01:00:19,599
channel counters but maybe this is

1570
01:00:19,599 --> 01:00:22,000
things do it early on in the process

1571
01:00:22,000 --> 01:00:24,640
right that's uh something like that and

1572
01:00:24,640 --> 01:00:26,720
the other thing yes i think just

1573
01:00:26,720 --> 01:00:28,640
instead of implementing in biology you

1574
01:00:28,640 --> 01:00:30,640
can have basic elements i'll have to go

1575
01:00:30,640 --> 01:00:32,640
and check exactly what what you wanted

1576
01:00:32,640 --> 01:00:33,920
but yeah

1577
01:00:33,920 --> 01:00:35,119
thank you

1578
01:00:35,119 --> 01:00:37,440
thank you

1579
01:00:37,920 --> 01:00:40,799
i'm gary sorry i'm curious um when you

1580
01:00:40,799 --> 01:00:42,799
have the alarms in your circuit how

1581
01:00:42,799 --> 01:00:44,640
often do those alarms create extra

1582
01:00:44,640 --> 01:00:46,640
leakage of information

1583
01:00:46,640 --> 01:00:48,400
very good point indeed

1584
01:00:48,400 --> 01:00:49,839
um so

1585
01:00:49,839 --> 01:00:52,720
the attacker has freedom so the attacker

1586
01:00:52,720 --> 01:00:55,440
can start playing and so start playing

1587
01:00:55,440 --> 01:00:57,920
and say um what's the boundary when i

1588
01:00:57,920 --> 01:01:00,400
can trigger an alarm right and so from

1589
01:01:00,400 --> 01:01:03,200
that you can try to deduce information

1590
01:01:03,200 --> 01:01:05,440
that's that's a very good point

1591
01:01:05,440 --> 01:01:06,810
um um

1592
01:01:06,810 --> 01:01:07,920
[Music]

1593
01:01:07,920 --> 01:01:10,000
this is for instance i mean this is at

1594
01:01:10,000 --> 01:01:13,520
crypto level what happens if i um

1595
01:01:13,520 --> 01:01:16,079
uh and that's why these things say this

1596
01:01:16,079 --> 01:01:18,160
fo transform you may want to make sure

1597
01:01:18,160 --> 01:01:20,480
you get either a positive response yes

1598
01:01:20,480 --> 01:01:22,480
this was a correct key or no but you

1599
01:01:22,480 --> 01:01:25,200
should not leak back information and so

1600
01:01:25,200 --> 01:01:27,599
this is this is for all alarms the case

1601
01:01:27,599 --> 01:01:29,119
um yeah

1602
01:01:29,119 --> 01:01:31,680
um this has been used um

1603
01:01:31,680 --> 01:01:34,000
not just alarms but also performance

1604
01:01:34,000 --> 01:01:36,160
counters like for instance on big

1605
01:01:36,160 --> 01:01:38,160
processors you have these monitors like

1606
01:01:38,160 --> 01:01:40,559
how much power you're consuming and for

1607
01:01:40,559 --> 01:01:42,079
instance if you're consuming too much

1608
01:01:42,079 --> 01:01:43,520
power they will reduce the clock

1609
01:01:43,520 --> 01:01:45,680
frequency or they reduce the power uh

1610
01:01:45,680 --> 01:01:46,880
the voltage

1611
01:01:46,880 --> 01:01:48,559
um from these counters you can also

1612
01:01:48,559 --> 01:01:50,319
deduce information what's going on on

1613
01:01:50,319 --> 01:01:52,880
the chip so this this this is a good

1614
01:01:52,880 --> 01:01:54,799
point

1615
01:01:54,799 --> 01:01:56,720
but it typically

1616
01:01:56,720 --> 01:01:59,119
solved um

1617
01:01:59,119 --> 01:02:01,680
looking at the complete picture

1618
01:02:01,680 --> 01:02:03,839
you cannot build one genetic thing

1619
01:02:03,839 --> 01:02:05,440
that's gonna solve for everything

1620
01:02:05,440 --> 01:02:07,200
typically in embedded context we say

1621
01:02:07,200 --> 01:02:08,960
this is going to be application this is

1622
01:02:08,960 --> 01:02:10,559
going to be the attacker model this is

1623
01:02:10,559 --> 01:02:12,480
going to be what we cannot

1624
01:02:12,480 --> 01:02:14,400
can afford and what we cannot afford

1625
01:02:14,400 --> 01:02:15,359
yeah

1626
01:02:15,359 --> 01:02:17,598
yes

1627
01:02:18,319 --> 01:02:21,920
thank you uh

1628
01:02:21,920 --> 01:02:23,920
i don't see any more questions so let's

1629
01:02:23,920 --> 01:02:28,319
thank uh ingrid again thank you

1630
01:02:33,200 --> 01:02:34,480
thank you very much

1631
01:02:34,480 --> 01:02:36,720
and now we have a multi-party

1632
01:02:36,720 --> 01:02:38,720
computation session here in this room in

1633
01:02:38,720 --> 01:02:39,839
five minutes

1634
01:02:39,839 --> 01:02:42,000
and symmetric key uh

1635
01:02:42,000 --> 01:02:46,000
session in the other room also

