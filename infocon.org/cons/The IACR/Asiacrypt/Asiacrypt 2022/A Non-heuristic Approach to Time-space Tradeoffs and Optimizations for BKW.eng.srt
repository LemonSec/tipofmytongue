1
00:00:00,480 --> 00:00:03,060
hello everyone I'm going to talk about

2
00:00:03,060 --> 00:00:06,420
our work a non-heristic approach to time

3
00:00:06,420 --> 00:00:09,059
space trade-offs and optimizations for

4
00:00:09,059 --> 00:00:10,800
bkw

5
00:00:10,800 --> 00:00:13,860
first let us record the airplane problem

6
00:00:13,860 --> 00:00:15,780
which is about solving linear congruence

7
00:00:15,780 --> 00:00:19,140
in presence of noise where you know in

8
00:00:19,140 --> 00:00:21,060
the search version of the problem the

9
00:00:21,060 --> 00:00:23,400
challenges to find out the secret X

10
00:00:23,400 --> 00:00:26,580
given the noisy code word where X and

11
00:00:26,580 --> 00:00:29,220
the a are uniformly random and a is

12
00:00:29,220 --> 00:00:30,180
public

13
00:00:30,180 --> 00:00:32,399
and the noise follows the coordinate

14
00:00:32,399 --> 00:00:34,559
wise independent binary distribution

15
00:00:34,559 --> 00:00:38,280
where mu is noise rate

16
00:00:38,280 --> 00:00:40,739
in cryptography it is more convenient to

17
00:00:40,739 --> 00:00:42,840
use the so-called decision RPM to

18
00:00:42,840 --> 00:00:45,840
facilitate facilitate security proofs

19
00:00:45,840 --> 00:00:49,219
and both variants are polynomially

20
00:00:49,219 --> 00:00:52,260
equivalent therefore for security

21
00:00:52,260 --> 00:00:55,140
analysis we we can only consider the

22
00:00:55,140 --> 00:00:57,559
search version

23
00:00:58,379 --> 00:01:00,660
the Appian problem can be categorized by

24
00:01:00,660 --> 00:01:03,239
its noise when the noise rate mu is a

25
00:01:03,239 --> 00:01:04,140
constant

26
00:01:04,140 --> 00:01:07,140
the bkw algorithm by Blum kalai and the

27
00:01:07,140 --> 00:01:09,299
weatherman substituting is the

28
00:01:09,299 --> 00:01:10,799
exponential time and the sample

29
00:01:10,799 --> 00:01:12,119
complexities

30
00:01:12,119 --> 00:01:13,979
based on bkw

31
00:01:13,979 --> 00:01:16,320
Rio bishovsky gave a meaningful

32
00:01:16,320 --> 00:01:18,720
trade-off which compresses the sample

33
00:01:18,720 --> 00:01:21,840
complexity to polynomial with a slightly

34
00:01:21,840 --> 00:01:24,540
lifted up time complexity

35
00:01:24,540 --> 00:01:27,479
and there are other vibrants of big LPN

36
00:01:27,479 --> 00:01:30,299
who has a noise rate decrease with

37
00:01:30,299 --> 00:01:32,640
respect to the dimension but they are

38
00:01:32,640 --> 00:01:35,880
not the focused of our paper

39
00:01:35,880 --> 00:01:38,579
let's recall the original bkw algorithm

40
00:01:38,579 --> 00:01:40,979
it works in iterations

41
00:01:40,979 --> 00:01:44,340
in each iteration it classifies the

42
00:01:44,340 --> 00:01:47,280
samples based on values of the first B

43
00:01:47,280 --> 00:01:51,299
bit of the coefficient vector and within

44
00:01:51,299 --> 00:01:54,479
each group it cancels the first of B bit

45
00:01:54,479 --> 00:01:57,540
by subtracting them with the first

46
00:01:57,540 --> 00:01:58,680
vector

47
00:01:58,680 --> 00:02:01,979
therefore each iteration reduce the

48
00:02:01,979 --> 00:02:04,860
dimension by B bit and reduce the number

49
00:02:04,860 --> 00:02:07,740
of samples by 2 to the B and doubles the

50
00:02:07,740 --> 00:02:10,220
noise rate

51
00:02:10,500 --> 00:02:13,379
we summarize the complexities of the bkw

52
00:02:13,379 --> 00:02:16,440
algorithm to minimize time in the sample

53
00:02:16,440 --> 00:02:19,920
by choosing the block size B properly we

54
00:02:19,920 --> 00:02:22,680
end up with a exponential complexities

55
00:02:22,680 --> 00:02:26,760
which are roughly 2 to the N over log n

56
00:02:26,760 --> 00:02:29,400
and it remains open if we can do

57
00:02:29,400 --> 00:02:31,980
trade-offs between space and time

58
00:02:31,980 --> 00:02:35,340
this is a especially meaningful when

59
00:02:35,340 --> 00:02:38,220
doing say security evaluations of

60
00:02:38,220 --> 00:02:40,680
airplane based crypto systems

61
00:02:40,680 --> 00:02:42,780
if the time complexity and the space

62
00:02:42,780 --> 00:02:46,440
consumption is both 2 to the 80. it's

63
00:02:46,440 --> 00:02:48,780
not a practical estimate at all because

64
00:02:48,780 --> 00:02:51,239
in practice we don't have a memory of

65
00:02:51,239 --> 00:02:54,480
size 2 to the 80. so indeed in addition

66
00:02:54,480 --> 00:02:58,140
we we didn't know if we can improve the

67
00:02:58,140 --> 00:03:01,319
financial Factor which which is

68
00:03:01,319 --> 00:03:03,660
highlighted corresponding to the number

69
00:03:03,660 --> 00:03:05,640
of iterations

70
00:03:05,640 --> 00:03:08,459
further we would like a more efficient

71
00:03:08,459 --> 00:03:12,000
approach to reduce sample complexity

72
00:03:12,000 --> 00:03:14,159
in this work we give a tree based

73
00:03:14,159 --> 00:03:16,739
structure for the bkw algorithm

74
00:03:16,739 --> 00:03:18,659
the original European samples were

75
00:03:18,659 --> 00:03:21,420
divided into several subsets these

76
00:03:21,420 --> 00:03:25,019
subsets are mutually independent

77
00:03:25,019 --> 00:03:27,540
within each subset the samples are only

78
00:03:27,540 --> 00:03:30,000
required to be pairwise the independent

79
00:03:30,000 --> 00:03:33,000
and this will enable you know of sample

80
00:03:33,000 --> 00:03:35,340
optimization because we can use a small

81
00:03:35,340 --> 00:03:37,920
number of independent samples to

82
00:03:37,920 --> 00:03:39,900
generate a much larger number of

83
00:03:39,900 --> 00:03:42,599
pairwise independent samples

84
00:03:42,599 --> 00:03:45,480
and in the meantime the pairwise

85
00:03:45,480 --> 00:03:49,080
independence services to give a rigorous

86
00:03:49,080 --> 00:03:53,099
estimate of the complexities

87
00:03:53,099 --> 00:03:57,360
and during each iteration we pick say C

88
00:03:57,360 --> 00:04:01,140
samples one from each parent's node

89
00:04:01,140 --> 00:04:03,060
and to cancel out the first B

90
00:04:03,060 --> 00:04:04,920
coordinates

91
00:04:04,920 --> 00:04:07,260
and we do this all the way down to the

92
00:04:07,260 --> 00:04:10,620
root node where we get many candidates

93
00:04:10,620 --> 00:04:14,459
for a thing for a single coordinate

94
00:04:14,459 --> 00:04:20,000
therefore no repetition is needed

95
00:04:20,279 --> 00:04:23,040
based on our tree based algorithm we get

96
00:04:23,040 --> 00:04:25,560
our first result which is a trade-off

97
00:04:25,560 --> 00:04:27,240
between time and space

98
00:04:27,240 --> 00:04:30,660
here this C is a tunable parameter by

99
00:04:30,660 --> 00:04:32,580
changing different values for C we get

100
00:04:32,580 --> 00:04:34,560
different trade-offs between time and

101
00:04:34,560 --> 00:04:35,639
the space

102
00:04:35,639 --> 00:04:38,460
and compiled with the previous work we

103
00:04:38,460 --> 00:04:40,740
optimized time in the sample complexity

104
00:04:40,740 --> 00:04:44,400
by a substantial factor which accounts

105
00:04:44,400 --> 00:04:46,139
for the number of reiterations in the

106
00:04:46,139 --> 00:04:48,540
original pkw levels

107
00:04:48,540 --> 00:04:51,240
further compared with Ruby JavaScript

108
00:04:51,240 --> 00:04:54,240
algorithm the time complexity is also

109
00:04:54,240 --> 00:04:57,960
optimized by a sub-exponential vector

110
00:04:57,960 --> 00:05:00,540
that is very brief introduction of our

111
00:05:00,540 --> 00:05:04,160
work thank you for your time

