1
00:00:00,160 --> 00:00:02,080
hello everyone welcome

2
00:00:02,080 --> 00:00:04,000
so

3
00:00:04,000 --> 00:00:06,640
good morning good afternoon good evening

4
00:00:06,640 --> 00:00:07,440
yeah

5
00:00:07,440 --> 00:00:09,280
so

6
00:00:09,280 --> 00:00:11,519
welcome to the

7
00:00:11,519 --> 00:00:12,320
uh

8
00:00:12,320 --> 00:00:17,160
the mother talk section of sap 2018

9
00:00:17,279 --> 00:00:20,400
and also the first section of the last

10
00:00:20,400 --> 00:00:23,039
day on this congress

11
00:00:23,039 --> 00:00:25,359
and it is my greatest pleasure to

12
00:00:25,359 --> 00:00:30,720
introduce our speaker invite speaker for

13
00:00:30,760 --> 00:00:34,239
2021 professor ee

14
00:00:34,239 --> 00:00:36,800
professor ee is a professor in shanghai

15
00:00:36,800 --> 00:00:38,399
jiangtong university

16
00:00:38,399 --> 00:00:40,559
he obtained his special science from

17
00:00:40,559 --> 00:00:43,440
public university in 2003

18
00:00:43,440 --> 00:00:44,640
and learned he

19
00:00:44,640 --> 00:00:47,039
his phd from london technological

20
00:00:47,039 --> 00:00:49,840
university in 2006

21
00:00:49,840 --> 00:00:51,520
so he has a

22
00:00:51,520 --> 00:00:55,039
was a post doctor research in the ucla

23
00:00:55,039 --> 00:00:58,399
quito group during 2008 in

24
00:00:58,399 --> 00:01:00,640
uh 2010

25
00:01:00,640 --> 00:01:03,600
after returning to china he worked in

26
00:01:03,600 --> 00:01:07,600
east china loma university from 2011 to

27
00:01:07,600 --> 00:01:11,920
2012 and chinwat university for 2012 and

28
00:01:11,920 --> 00:01:14,000
2013.

29
00:01:14,000 --> 00:01:17,040
his research interests include

30
00:01:17,040 --> 00:01:19,680
side channel analysis and counter

31
00:01:19,680 --> 00:01:20,720
management

32
00:01:20,720 --> 00:01:22,960
efficient construction of pseudo-random

33
00:01:22,960 --> 00:01:24,159
objects

34
00:01:24,159 --> 00:01:26,960
in landing parity with noise

35
00:01:26,960 --> 00:01:29,680
he is a member of asia quit stealing

36
00:01:29,680 --> 00:01:31,920
committee in his serve on the program

37
00:01:31,920 --> 00:01:35,200
committee of asia with europe with quit

38
00:01:35,200 --> 00:01:39,600
chase pkc and tcc okay let's welcome uh

39
00:01:39,600 --> 00:01:43,520
professor e okay so yeah

40
00:01:43,520 --> 00:01:45,119
okay um

41
00:01:45,119 --> 00:01:46,960
let me share my

42
00:01:46,960 --> 00:01:48,000
sites

43
00:01:48,000 --> 00:01:50,000
okay can you see my source in full

44
00:01:50,000 --> 00:01:50,880
screen

45
00:01:50,880 --> 00:01:52,479
yeah yeah

46
00:01:52,479 --> 00:01:53,280
yeah

47
00:01:53,280 --> 00:01:55,200
so i can start thank you

48
00:01:55,200 --> 00:01:56,079
thank you

49
00:01:56,079 --> 00:01:58,079
thank you question for for for the

50
00:01:58,079 --> 00:02:00,079
introduction for inviting me and having

51
00:02:00,079 --> 00:02:01,200
me here

52
00:02:01,200 --> 00:02:04,719
and it is my great opportunity to

53
00:02:04,719 --> 00:02:07,040
to talk about our recent works on

54
00:02:07,040 --> 00:02:08,878
learning parity with noise

55
00:02:08,878 --> 00:02:11,599
this is a joint work with many people uh

56
00:02:11,599 --> 00:02:13,760
tranquil

57
00:02:13,760 --> 00:02:15,760
honey leo and janjang

58
00:02:15,760 --> 00:02:17,840
and with a bunch of papers published at

59
00:02:17,840 --> 00:02:18,879
uh

60
00:02:18,879 --> 00:02:23,760
crypto 2016 crypto 2021 pcr and asia

61
00:02:23,760 --> 00:02:25,520
crypt 2019

62
00:02:25,520 --> 00:02:28,000
and a manuscript that is working

63
00:02:28,000 --> 00:02:30,400
progress

64
00:02:30,400 --> 00:02:31,840
okay uh

65
00:02:31,840 --> 00:02:33,200
so you know

66
00:02:33,200 --> 00:02:36,080
the topic is learning parity is noise

67
00:02:36,080 --> 00:02:37,920
the airplane problem

68
00:02:37,920 --> 00:02:40,959
is about solving linear congruence in

69
00:02:40,959 --> 00:02:42,720
presence of noise

70
00:02:42,720 --> 00:02:45,120
or from the coding theoretical point of

71
00:02:45,120 --> 00:02:47,760
view it's called decoding random linear

72
00:02:47,760 --> 00:02:48,720
codes

73
00:02:48,720 --> 00:02:50,879
so the original problem

74
00:02:50,879 --> 00:02:53,360
called the search version it challenges

75
00:02:53,360 --> 00:02:55,920
to find out the secret given the noisy

76
00:02:55,920 --> 00:02:57,519
code word

77
00:02:57,519 --> 00:03:00,560
where the secret is uniformly random and

78
00:03:00,560 --> 00:03:02,400
this matrix is also uniformly random

79
00:03:02,400 --> 00:03:04,640
animated public

80
00:03:04,640 --> 00:03:05,760
and

81
00:03:05,760 --> 00:03:08,720
this noise is a bit complicated it

82
00:03:08,720 --> 00:03:10,720
follows from the coordinate wise

83
00:03:10,720 --> 00:03:12,400
independent uh

84
00:03:12,400 --> 00:03:13,680
distribution which is called the

85
00:03:13,680 --> 00:03:15,280
bandwidth distribution with par with

86
00:03:15,280 --> 00:03:18,000
noise rate mu so every individual noise

87
00:03:18,000 --> 00:03:20,480
will be equals to one with some

88
00:03:20,480 --> 00:03:22,159
probability mu

89
00:03:22,159 --> 00:03:24,720
and this mu is parameter

90
00:03:24,720 --> 00:03:26,239
and in cryptography it is more

91
00:03:26,239 --> 00:03:28,879
convenient to use the so-called

92
00:03:28,879 --> 00:03:31,280
decisional airplane where it asks to

93
00:03:31,280 --> 00:03:33,120
distinguish the european samples from

94
00:03:33,120 --> 00:03:34,879
uniform randomness

95
00:03:34,879 --> 00:03:37,920
so these two variants they are

96
00:03:37,920 --> 00:03:39,360
they are

97
00:03:39,360 --> 00:03:42,480
polynomial polynomially equivalent

98
00:03:42,480 --> 00:03:45,440
and it is also worth to point out that

99
00:03:45,440 --> 00:03:47,280
you know the noise distribution for the

100
00:03:47,280 --> 00:03:49,680
secret is sometimes uh

101
00:03:49,680 --> 00:03:50,799
to con

102
00:03:50,799 --> 00:03:53,120
can be drawn from the unit

103
00:03:53,120 --> 00:03:54,720
from the from the

104
00:03:54,720 --> 00:03:57,280
noise distribution without without

105
00:03:57,280 --> 00:04:00,400
compromising the security

106
00:04:00,400 --> 00:04:02,480
it will be very convenient to use in

107
00:04:02,480 --> 00:04:04,239
applications such as public key

108
00:04:04,239 --> 00:04:06,799
encryptions

109
00:04:07,360 --> 00:04:09,519
and the airplane comes with many

110
00:04:09,519 --> 00:04:11,840
variants based on the noise rate

111
00:04:11,840 --> 00:04:13,120
the standard

112
00:04:13,120 --> 00:04:14,640
the standard erp

113
00:04:14,640 --> 00:04:15,519
no

114
00:04:15,519 --> 00:04:17,519
the noise rate is constant

115
00:04:17,519 --> 00:04:19,519
meaning that it is independent of the

116
00:04:19,519 --> 00:04:21,600
secret size n

117
00:04:21,600 --> 00:04:24,560
and the best known attacks is called bkw

118
00:04:24,560 --> 00:04:26,479
as we show in this slide

119
00:04:26,479 --> 00:04:28,960
it's only like slightly below its

120
00:04:28,960 --> 00:04:31,840
exponential right it's 2 to the n over

121
00:04:31,840 --> 00:04:33,600
log n

122
00:04:33,600 --> 00:04:36,320
and when noise is smaller

123
00:04:36,320 --> 00:04:38,560
typically the square root of square root

124
00:04:38,560 --> 00:04:41,919
of n the complexity of the tax will drop

125
00:04:41,919 --> 00:04:43,360
accordingly

126
00:04:43,360 --> 00:04:46,400
but then that a typical hardness

127
00:04:46,400 --> 00:04:48,880
assumption is to assume that this

128
00:04:48,880 --> 00:04:51,680
problem is a polynomially hard

129
00:04:51,680 --> 00:04:54,080
but in many cases it will be very

130
00:04:54,080 --> 00:04:55,600
convenient to

131
00:04:55,600 --> 00:04:58,320
be a bit more aggressive to to assume

132
00:04:58,320 --> 00:05:00,800
that you know this airplane problem is

133
00:05:00,800 --> 00:05:02,479
exponential hard

134
00:05:02,479 --> 00:05:05,440
as long as there is a still a

135
00:05:05,440 --> 00:05:07,759
significant security gap from the best

136
00:05:07,759 --> 00:05:10,720
known attacks

137
00:05:10,720 --> 00:05:12,960
and there are also

138
00:05:12,960 --> 00:05:16,080
another more extremely case of airplane

139
00:05:16,080 --> 00:05:18,080
which we call

140
00:05:18,080 --> 00:05:20,320
extremely low noise airplane

141
00:05:20,320 --> 00:05:22,160
where you know the hardness assumptions

142
00:05:22,160 --> 00:05:25,120
very hard hardness assumed is very

143
00:05:25,120 --> 00:05:28,560
close to known attacks

144
00:05:29,199 --> 00:05:31,360
and this is the overview of this

145
00:05:31,360 --> 00:05:32,960
presentation

146
00:05:32,960 --> 00:05:35,680
and the relevant work

147
00:05:35,680 --> 00:05:37,840
revise you how to construct public key

148
00:05:37,840 --> 00:05:40,240
encryption and the collision-resistant

149
00:05:40,240 --> 00:05:42,400
hash functions from airplane

150
00:05:42,400 --> 00:05:45,199
and there are some like over overlap

151
00:05:45,199 --> 00:05:46,800
overlapping with the concurrent

152
00:05:46,800 --> 00:05:51,840
independent worker over blank ski at all

153
00:05:51,840 --> 00:05:53,520
also show that how to construct the

154
00:05:53,520 --> 00:05:55,919
collision-resistant hash functions from

155
00:05:55,919 --> 00:05:59,120
their extremely low raw noise airplane

156
00:05:59,120 --> 00:06:02,319
which is highlighted in in pink

157
00:06:02,319 --> 00:06:04,400
so another major contribution of blank

158
00:06:04,400 --> 00:06:07,280
scale is that they give the first

159
00:06:07,280 --> 00:06:09,280
worst case to average case reductions

160
00:06:09,280 --> 00:06:10,479
for airplane

161
00:06:10,479 --> 00:06:12,240
namely they show that the worst case

162
00:06:12,240 --> 00:06:14,880
hardness of the coding problem

163
00:06:14,880 --> 00:06:17,199
reduces to the average case hardness of

164
00:06:17,199 --> 00:06:19,600
a high noise airplane

165
00:06:19,600 --> 00:06:21,440
and in this talk we show how to

166
00:06:21,440 --> 00:06:23,840
generalize their results to prove

167
00:06:23,840 --> 00:06:26,880
uh the sub exponential hardness for

168
00:06:26,880 --> 00:06:28,639
airplane

169
00:06:28,639 --> 00:06:31,680
and finally we also report some our

170
00:06:31,680 --> 00:06:35,199
latest result on how to do various

171
00:06:35,199 --> 00:06:36,319
trade-offs

172
00:06:36,319 --> 00:06:39,520
between the time space and sample

173
00:06:39,520 --> 00:06:43,680
complexities of bkw without relying on

174
00:06:43,680 --> 00:06:47,560
heuristic assumptions

175
00:06:48,240 --> 00:06:50,479
first uh we show how to construct the

176
00:06:50,479 --> 00:06:52,880
public key encryption and the collision

177
00:06:52,880 --> 00:06:56,160
resistance hash functions from airplane

178
00:06:56,160 --> 00:06:57,199
so

179
00:06:57,199 --> 00:06:59,120
building pk and

180
00:06:59,120 --> 00:07:02,000
cih from standard airplane was a

181
00:07:02,000 --> 00:07:04,000
long-standing urban problem

182
00:07:04,000 --> 00:07:06,080
as you can see it's mentioned in the

183
00:07:06,080 --> 00:07:08,880
christophe's airplane survey paper in

184
00:07:08,880 --> 00:07:11,039
2012

185
00:07:11,039 --> 00:07:15,599
and the van dimes airplane survey talk

186
00:07:15,680 --> 00:07:18,080
and we made some progress in solving

187
00:07:18,080 --> 00:07:20,639
this problem in the sense that

188
00:07:20,639 --> 00:07:23,199
we show how to construct the cih

189
00:07:23,199 --> 00:07:24,880
and pke from

190
00:07:24,880 --> 00:07:30,240
standard erpm with exponential hardness

191
00:07:30,240 --> 00:07:32,000
that means we don't solve this problem

192
00:07:32,000 --> 00:07:34,400
completely because we still need the

193
00:07:34,400 --> 00:07:36,720
this exponential hardness assumption for

194
00:07:36,720 --> 00:07:39,680
for the standard erp

195
00:07:40,240 --> 00:07:42,720
um here we briefly recall the definition

196
00:07:42,720 --> 00:07:44,400
of pke

197
00:07:44,400 --> 00:07:46,000
so you know where the decryption

198
00:07:46,000 --> 00:07:48,400
algorithm must be successful

199
00:07:48,400 --> 00:07:53,199
except with some negligible probability

200
00:07:53,199 --> 00:07:55,759
and there was also some security notions

201
00:07:55,759 --> 00:07:57,759
like you know cpa security which is

202
00:07:57,759 --> 00:07:59,120
about the

203
00:07:59,120 --> 00:08:00,319
distinct computational

204
00:08:00,319 --> 00:08:03,440
distinguishability of the cipher text

205
00:08:03,440 --> 00:08:06,240
and in cca security where the adversary

206
00:08:06,240 --> 00:08:08,240
gets additional access to the decryption

207
00:08:08,240 --> 00:08:09,199
oracle

208
00:08:09,199 --> 00:08:11,120
except for the

209
00:08:11,120 --> 00:08:14,720
challenging ciphertext of course

210
00:08:15,840 --> 00:08:18,000
um

211
00:08:18,000 --> 00:08:20,639
previously we know how to construct pke

212
00:08:20,639 --> 00:08:22,479
from um

213
00:08:22,479 --> 00:08:24,639
from a special virus called the low

214
00:08:24,639 --> 00:08:28,240
noise via airplane by aleknowicz

215
00:08:28,240 --> 00:08:29,879
at the fox

216
00:08:29,879 --> 00:08:31,680
2003

217
00:08:31,680 --> 00:08:34,640
so let's take a look

218
00:08:34,640 --> 00:08:35,839
first

219
00:08:35,839 --> 00:08:38,958
alice would do the key generation

220
00:08:38,958 --> 00:08:41,440
alice sample airplane samples and keeps

221
00:08:41,440 --> 00:08:43,360
the secret to herself

222
00:08:43,360 --> 00:08:45,519
and then he she said send over the

223
00:08:45,519 --> 00:08:47,440
public key to ball

224
00:08:47,440 --> 00:08:49,600
and then bob you know do the

225
00:08:49,600 --> 00:08:51,680
encryption with the

226
00:08:51,680 --> 00:08:53,519
encryption with the public key

227
00:08:53,519 --> 00:08:56,320
so he samples another airplane sample

228
00:08:56,320 --> 00:08:58,800
but for the same matrix a

229
00:08:58,800 --> 00:09:00,399
and encrypted

230
00:09:00,399 --> 00:09:03,600
the message with the hardcore bit

231
00:09:03,600 --> 00:09:06,560
and then he sent back to the ciphertext

232
00:09:06,560 --> 00:09:11,360
to alice who decrypts out the message

233
00:09:11,360 --> 00:09:13,200
so the

234
00:09:13,200 --> 00:09:15,279
so the cpa security thing

235
00:09:15,279 --> 00:09:17,040
is simply implied

236
00:09:17,040 --> 00:09:19,760
actually trivially follows from the

237
00:09:19,760 --> 00:09:22,560
decisional european assumption

238
00:09:22,560 --> 00:09:23,279
so

239
00:09:23,279 --> 00:09:25,040
because you know the public key is

240
00:09:25,040 --> 00:09:26,880
actually the european samples and the

241
00:09:26,880 --> 00:09:29,920
ciphertext are not another instant

242
00:09:29,920 --> 00:09:32,160
another instance of the airplane samples

243
00:09:32,160 --> 00:09:34,959
plus the hard copy right so every the

244
00:09:34,959 --> 00:09:37,120
security proof is trivial

245
00:09:37,120 --> 00:09:39,440
and here we can analyze the the

246
00:09:39,440 --> 00:09:42,480
successful probability of the decryption

247
00:09:42,480 --> 00:09:44,720
though you can see that in order to

248
00:09:44,720 --> 00:09:47,279
decrypt with high probability

249
00:09:47,279 --> 00:09:50,240
so the noise rate cannot be much greater

250
00:09:50,240 --> 00:09:54,720
than the square inverse square root of n

251
00:09:54,720 --> 00:09:56,000
right

252
00:09:56,000 --> 00:09:57,920
which is why previous

253
00:09:57,920 --> 00:09:59,040
approach

254
00:09:59,040 --> 00:10:02,320
to construct to constructing pk from

255
00:10:02,320 --> 00:10:06,560
airplane needs the low noise

256
00:10:07,200 --> 00:10:08,320
then uh

257
00:10:08,320 --> 00:10:10,720
before showing our construction

258
00:10:10,720 --> 00:10:12,720
let's discuss what the european

259
00:10:12,720 --> 00:10:14,800
assumption we need

260
00:10:14,800 --> 00:10:17,040
it is actually conjunction that the

261
00:10:17,040 --> 00:10:18,720
airplane is hard

262
00:10:18,720 --> 00:10:21,040
even when you know the secret

263
00:10:21,040 --> 00:10:22,720
is arbitrary

264
00:10:22,720 --> 00:10:24,880
as long as it has some non-trivial

265
00:10:24,880 --> 00:10:27,600
amount of entropy like like say two

266
00:10:27,600 --> 00:10:29,519
lambda bits where lambda is a new

267
00:10:29,519 --> 00:10:31,120
parameter

268
00:10:31,120 --> 00:10:34,079
we call this assumption the entropic

269
00:10:34,079 --> 00:10:37,120
airplane which is we needed we which is

270
00:10:37,120 --> 00:10:40,160
actually we need to construct the pke

271
00:10:40,160 --> 00:10:42,959
but unfortunately it's not known to be

272
00:10:42,959 --> 00:10:44,959
reducible from the standard airplane

273
00:10:44,959 --> 00:10:46,800
assumption

274
00:10:46,800 --> 00:10:49,680
so here we actually cheated a little bit

275
00:10:49,680 --> 00:10:52,399
so we use a non-uniform matrix

276
00:10:52,399 --> 00:10:53,360
which is

277
00:10:53,360 --> 00:10:55,920
actually a product of two uniform

278
00:10:55,920 --> 00:10:57,920
rectangular matrixes

279
00:10:57,920 --> 00:11:03,279
the n by lambda and and m by lambda

280
00:11:03,279 --> 00:11:07,600
dimension the a and the lambda by n

281
00:11:07,600 --> 00:11:09,279
matrix v

282
00:11:09,279 --> 00:11:10,399
right

283
00:11:10,399 --> 00:11:12,079
so this distribution actually can

284
00:11:12,079 --> 00:11:15,200
consider as a drone from

285
00:11:15,200 --> 00:11:18,160
random subspace of dimension

286
00:11:18,160 --> 00:11:20,160
lambda

287
00:11:20,160 --> 00:11:21,360
and then

288
00:11:21,360 --> 00:11:24,160
so if you if you look take a closer look

289
00:11:24,160 --> 00:11:26,160
and consider vx

290
00:11:26,160 --> 00:11:28,880
because v is a actually a random matrix

291
00:11:28,880 --> 00:11:31,920
so by the left over hash lemma

292
00:11:31,920 --> 00:11:34,560
v x is very statistical close to a very

293
00:11:34,560 --> 00:11:37,279
short uniform seed and therefore you

294
00:11:37,279 --> 00:11:38,079
know

295
00:11:38,079 --> 00:11:39,519
this uh

296
00:11:39,519 --> 00:11:42,160
this entropic airplane assumption here

297
00:11:42,160 --> 00:11:43,600
is reduceable

298
00:11:43,600 --> 00:11:46,399
from a standard airplane

299
00:11:46,399 --> 00:11:48,240
but only when the airplane is

300
00:11:48,240 --> 00:11:50,880
sufficiently hard

301
00:11:50,880 --> 00:11:53,120
for example if the entropy parameter

302
00:11:53,120 --> 00:11:57,200
lambda is say log a squared log in

303
00:11:57,200 --> 00:12:00,240
then the standard airplane

304
00:12:00,240 --> 00:12:02,320
needs to be at least the sub

305
00:12:02,320 --> 00:12:04,480
exponentially hard

306
00:12:04,480 --> 00:12:07,200
because this is because you know

307
00:12:07,200 --> 00:12:09,040
the entropic

308
00:12:09,040 --> 00:12:11,920
airplane has much larger dimension than

309
00:12:11,920 --> 00:12:13,519
the standard erp

310
00:12:13,519 --> 00:12:17,760
so by substituting the value of lambda

311
00:12:17,760 --> 00:12:20,720
into into this uh you know two to the

312
00:12:20,720 --> 00:12:22,880
lambda squared lambda

313
00:12:22,880 --> 00:12:25,519
we only get like like a slightly super

314
00:12:25,519 --> 00:12:28,560
polynomial hardness in in the security

315
00:12:28,560 --> 00:12:30,480
parameter of the entropy

316
00:12:30,480 --> 00:12:33,360
entropic erpin

317
00:12:33,360 --> 00:12:34,800
so

318
00:12:34,800 --> 00:12:37,800
then

319
00:12:38,240 --> 00:12:40,240
but then it is sufficient

320
00:12:40,240 --> 00:12:43,600
uh then we can show how to construct the

321
00:12:43,600 --> 00:12:47,200
pke from the entropy entropic airplane

322
00:12:47,200 --> 00:12:50,079
which in turn is implied by the standard

323
00:12:50,079 --> 00:12:53,519
sub-exponential hub airplane right

324
00:12:53,519 --> 00:12:55,680
so the weak secretive now is a random

325
00:12:55,680 --> 00:12:58,880
string that has exact exact hemming

326
00:12:58,880 --> 00:13:01,120
weight log n

327
00:13:01,120 --> 00:13:04,000
so that means that this uh this this

328
00:13:04,000 --> 00:13:07,279
weak secret as entropy squared login

329
00:13:07,279 --> 00:13:10,079
right because if you take a logarithm of

330
00:13:10,079 --> 00:13:13,040
n choose log n which is just a roughly

331
00:13:13,040 --> 00:13:14,480
squared log n

332
00:13:14,480 --> 00:13:16,800
so we will set lambda to be squared log

333
00:13:16,800 --> 00:13:18,639
n

334
00:13:18,639 --> 00:13:20,480
and then also

335
00:13:20,480 --> 00:13:23,760
this uh uh entropic airpin

336
00:13:23,760 --> 00:13:25,920
whose noise has constant noise rate

337
00:13:25,920 --> 00:13:27,360
right

338
00:13:27,360 --> 00:13:29,200
then we just you know follow the same

339
00:13:29,200 --> 00:13:30,560
protocol as

340
00:13:30,560 --> 00:13:32,560
i like novich's pke

341
00:13:32,560 --> 00:13:35,519
except we use a different matrix a we

342
00:13:35,519 --> 00:13:38,560
use a very small entropy secret s and we

343
00:13:38,560 --> 00:13:40,480
use constant noise

344
00:13:40,480 --> 00:13:41,360
e

345
00:13:41,360 --> 00:13:43,040
here we highlighted the

346
00:13:43,040 --> 00:13:45,920
highlighted difference with colors

347
00:13:45,920 --> 00:13:47,680
like before you know

348
00:13:47,680 --> 00:13:50,079
the security truly follows from the

349
00:13:50,079 --> 00:13:52,560
entropic erp assumption

350
00:13:52,560 --> 00:13:54,480
and you know

351
00:13:54,480 --> 00:13:56,880
the correctness of the scheme

352
00:13:56,880 --> 00:13:59,279
is essentially the correlation of a

353
00:13:59,279 --> 00:14:02,320
vector that has has happened with

354
00:14:02,320 --> 00:14:05,760
exactly log n which is in blue

355
00:14:05,760 --> 00:14:08,240
and another vector that has constant

356
00:14:08,240 --> 00:14:09,199
noise

357
00:14:09,199 --> 00:14:11,440
you know follows uh the coordinate wise

358
00:14:11,440 --> 00:14:13,040
bandwidth distribution with constant

359
00:14:13,040 --> 00:14:15,279
noise rate which is in yellow

360
00:14:15,279 --> 00:14:17,440
and by piling up lemma we know that you

361
00:14:17,440 --> 00:14:18,240
know

362
00:14:18,240 --> 00:14:20,240
the decryption successful

363
00:14:20,240 --> 00:14:23,680
probability is at least noticeable close

364
00:14:23,680 --> 00:14:27,360
to uniform noticeably close to uniform

365
00:14:27,360 --> 00:14:28,240
so

366
00:14:28,240 --> 00:14:30,160
this is already sufficient to show the

367
00:14:30,160 --> 00:14:34,000
feasibility of the construction

368
00:14:34,800 --> 00:14:36,639
then it's not uh it's not

369
00:14:36,639 --> 00:14:40,399
fully like a fully cps qr pk yet but we

370
00:14:40,399 --> 00:14:43,040
can add a redundancy and use error

371
00:14:43,040 --> 00:14:44,399
correction codes

372
00:14:44,399 --> 00:14:47,040
to amplify the decryption decryption

373
00:14:47,040 --> 00:14:48,800
successful probability

374
00:14:48,800 --> 00:14:53,440
you know from noticeable to overwhelming

375
00:14:53,440 --> 00:14:55,279
so that we can get the standard the cpa

376
00:14:55,279 --> 00:14:56,880
secures ke

377
00:14:56,880 --> 00:14:59,480
and if we want to build a cca secure

378
00:14:59,480 --> 00:15:01,839
airplane-based-based pke

379
00:15:01,839 --> 00:15:04,160
we can first build a cca secure

380
00:15:04,160 --> 00:15:07,199
tag-based pke and then we transform it

381
00:15:07,199 --> 00:15:09,120
into a standard

382
00:15:09,120 --> 00:15:12,560
cc apke cci secure apk without tags

383
00:15:12,560 --> 00:15:14,880
using you know the known transforms you

384
00:15:14,880 --> 00:15:16,560
you

385
00:15:16,560 --> 00:15:19,120
know techniques so here we just omitted

386
00:15:19,120 --> 00:15:22,079
the details

387
00:15:23,360 --> 00:15:25,360
next we will discuss how to construct

388
00:15:25,360 --> 00:15:27,600
the collision resistant hash functions

389
00:15:27,600 --> 00:15:29,920
from from lpn

390
00:15:29,920 --> 00:15:33,199
i see already a few

391
00:15:35,600 --> 00:15:37,759
oh so so you can see my screen right

392
00:15:37,759 --> 00:15:39,600
because some actually some someone said

393
00:15:39,600 --> 00:15:43,199
in the chat you cannot see the screen

394
00:15:43,360 --> 00:15:46,880
yes i can see it i can see it too

395
00:15:46,880 --> 00:15:49,360
so uh you know a cryptographic hash

396
00:15:49,360 --> 00:15:52,320
functions maps the messages of arbitrary

397
00:15:52,320 --> 00:15:55,360
lens to fixed lens outputs

398
00:15:55,360 --> 00:15:58,160
and there are many secret notions like

399
00:15:58,160 --> 00:16:00,240
pre-image resistance

400
00:16:00,240 --> 00:16:01,920
secondary image resistance and

401
00:16:01,920 --> 00:16:04,240
collision-resistant

402
00:16:04,240 --> 00:16:05,600
resistance

403
00:16:05,600 --> 00:16:07,600
which is the strongest and we care about

404
00:16:07,600 --> 00:16:10,079
in this in this talk

405
00:16:10,079 --> 00:16:12,000
so design a hash function we typically

406
00:16:12,000 --> 00:16:13,519
follow two steps

407
00:16:13,519 --> 00:16:15,680
first we build the hash function that is

408
00:16:15,680 --> 00:16:18,399
lens regular namely the compressor fixed

409
00:16:18,399 --> 00:16:20,839
length inputs to pick fixed length

410
00:16:20,839 --> 00:16:24,079
outputs with the collision resistance

411
00:16:24,079 --> 00:16:26,399
resistance property

412
00:16:26,399 --> 00:16:28,480
and then we extend the domain of this

413
00:16:28,480 --> 00:16:32,720
cih from fixed lens to arbitrary lens

414
00:16:32,720 --> 00:16:35,120
using the main extenders

415
00:16:35,120 --> 00:16:38,079
such as the miracle dengue

416
00:16:38,079 --> 00:16:39,920
okay

417
00:16:39,920 --> 00:16:42,880
so that so our construction will look

418
00:16:42,880 --> 00:16:44,959
like look very similar to

419
00:16:44,959 --> 00:16:48,079
airtight's syst-based cih

420
00:16:48,079 --> 00:16:50,399
so let's basically record a short

421
00:16:50,399 --> 00:16:54,160
shorter in t integer solution assumption

422
00:16:54,160 --> 00:16:56,639
which says that uh given a random query

423
00:16:56,639 --> 00:16:57,759
matrix

424
00:16:57,759 --> 00:17:00,079
it is infeasible to find any short

425
00:17:00,079 --> 00:17:01,199
solution

426
00:17:01,199 --> 00:17:03,120
in terms of l2 just

427
00:17:03,120 --> 00:17:06,240
l2 this distance or f2 or

428
00:17:06,240 --> 00:17:10,160
infinity norm such that a az is zero

429
00:17:10,160 --> 00:17:11,439
modular

430
00:17:11,439 --> 00:17:15,760
congruent to zero modular q right

431
00:17:15,919 --> 00:17:17,199
so

432
00:17:17,199 --> 00:17:20,160
if this is this assumption is true then

433
00:17:20,160 --> 00:17:24,720
it immediately implies a cih by itself

434
00:17:24,720 --> 00:17:27,039
okay just prove it the proof is very

435
00:17:27,039 --> 00:17:28,240
straightforward

436
00:17:28,240 --> 00:17:30,559
if you if we could find the collision

437
00:17:30,559 --> 00:17:34,000
for two distinct binary input

438
00:17:34,000 --> 00:17:36,000
then the difference of the two inputs is

439
00:17:36,000 --> 00:17:37,919
a short constitute a short solution to

440
00:17:37,919 --> 00:17:40,160
this problem right

441
00:17:40,160 --> 00:17:42,960
since we require the inputs are binary

442
00:17:42,960 --> 00:17:45,520
so they are diff with their difference

443
00:17:45,520 --> 00:17:47,200
which the solution

444
00:17:47,200 --> 00:17:49,280
will be short by definition

445
00:17:49,280 --> 00:17:51,520
right

446
00:17:52,480 --> 00:17:54,880
and then here is the

447
00:17:54,880 --> 00:17:58,320
technical route of our cih construction

448
00:17:58,320 --> 00:18:01,120
it looks very similar to the case

449
00:18:01,120 --> 00:18:04,160
where we have you know lwe can implies

450
00:18:04,160 --> 00:18:06,799
for certain range of parameters then cs

451
00:18:06,799 --> 00:18:09,520
can in turn imply cih

452
00:18:09,520 --> 00:18:11,679
but our construction works with binary

453
00:18:11,679 --> 00:18:12,640
strings

454
00:18:12,640 --> 00:18:14,400
namely the queue is two

455
00:18:14,400 --> 00:18:16,480
so we first show that you know we can

456
00:18:16,480 --> 00:18:19,679
construct the cih from vsvp binary

457
00:18:19,679 --> 00:18:22,320
shortest vector problem and we show that

458
00:18:22,320 --> 00:18:27,879
the european can in turn implies vsvp

459
00:18:28,320 --> 00:18:31,280
so similar to this uh this problem

460
00:18:31,280 --> 00:18:33,039
there's another problem called the you

461
00:18:33,039 --> 00:18:35,919
know in binary case we call it a binary

462
00:18:35,919 --> 00:18:39,039
shortest vector problem

463
00:18:39,600 --> 00:18:41,600
some people say it's not a good bspp

464
00:18:41,600 --> 00:18:43,360
it's not a good name but

465
00:18:43,360 --> 00:18:46,720
let's call it a bsvp for now

466
00:18:46,720 --> 00:18:48,400
in the binary case

467
00:18:48,400 --> 00:18:49,919
a short solution

468
00:18:49,919 --> 00:18:52,080
means that you know a short solution

469
00:18:52,080 --> 00:18:54,480
means that

470
00:18:54,480 --> 00:18:57,360
it is a sparse one right namely it has

471
00:18:57,360 --> 00:18:59,120
very small harming weight

472
00:18:59,120 --> 00:19:01,120
right or equivalently

473
00:19:01,120 --> 00:19:03,200
in terms of the dual code defined by the

474
00:19:03,200 --> 00:19:05,280
matrix a

475
00:19:05,280 --> 00:19:07,440
the problem is to find the short

476
00:19:07,440 --> 00:19:10,000
non-zero codeword defined by the dual

477
00:19:10,000 --> 00:19:12,000
code of a right

478
00:19:12,000 --> 00:19:13,760
so that's where that's where this name

479
00:19:13,760 --> 00:19:16,240
uh sdsub comes from

480
00:19:16,240 --> 00:19:17,760
anyway

481
00:19:17,760 --> 00:19:21,120
so our construction which follows the

482
00:19:21,120 --> 00:19:24,080
the construction cih from vspp will

483
00:19:24,080 --> 00:19:27,200
follow the the so-called expand then

484
00:19:27,200 --> 00:19:29,919
compress approach so in order to use

485
00:19:29,919 --> 00:19:33,760
bsvp the target vector has to be sparse

486
00:19:33,760 --> 00:19:35,760
which is not always guaranteed for

487
00:19:35,760 --> 00:19:37,280
arbitrary input

488
00:19:37,280 --> 00:19:39,919
so we we need first to apply expanding

489
00:19:39,919 --> 00:19:40,960
function

490
00:19:40,960 --> 00:19:43,440
that flatten the input to a long button

491
00:19:43,440 --> 00:19:45,200
sparse string

492
00:19:45,200 --> 00:19:47,520
and then we multiply this sparse string

493
00:19:47,520 --> 00:19:49,280
with the random matrix a

494
00:19:49,280 --> 00:19:51,200
right

495
00:19:51,200 --> 00:19:53,520
so this proof is very similar to the

496
00:19:53,520 --> 00:19:55,679
sysbase the cih

497
00:19:55,679 --> 00:19:58,160
so once we have the collision then the

498
00:19:58,160 --> 00:20:00,400
different of their output will

499
00:20:00,400 --> 00:20:04,080
constitute short solution to bsvp

500
00:20:04,080 --> 00:20:06,080
for that purpose we will require this

501
00:20:06,080 --> 00:20:08,080
expanding function to be

502
00:20:08,080 --> 00:20:10,480
one two one name letter preserves the

503
00:20:10,480 --> 00:20:13,600
distinct distinctiveness so

504
00:20:13,600 --> 00:20:15,840
and uh if

505
00:20:15,840 --> 00:20:18,080
to distinct the input implied to

506
00:20:18,080 --> 00:20:20,480
distinct output so that their difference

507
00:20:20,480 --> 00:20:22,400
will be nonzero

508
00:20:22,400 --> 00:20:23,679
and the sparse

509
00:20:23,679 --> 00:20:25,200
sparsity of the

510
00:20:25,200 --> 00:20:28,159
difference is at most doubled compared

511
00:20:28,159 --> 00:20:31,120
to the output of this expanding function

512
00:20:31,120 --> 00:20:32,159
right

513
00:20:32,159 --> 00:20:34,240
so now it remains to show that how to

514
00:20:34,240 --> 00:20:36,799
construct a such a expanding function

515
00:20:36,799 --> 00:20:39,120
that is one two one with a spot sparse

516
00:20:39,120 --> 00:20:40,320
output

517
00:20:40,320 --> 00:20:42,880
there are actually a few proposals on

518
00:20:42,880 --> 00:20:44,480
how to construct the spanning function

519
00:20:44,480 --> 00:20:46,159
efficiently

520
00:20:46,159 --> 00:20:48,679
for instance we can like you know

521
00:20:48,679 --> 00:20:51,679
divide the input into small blocks of

522
00:20:51,679 --> 00:20:54,400
equivalence and we map each block into a

523
00:20:54,400 --> 00:20:56,799
sparse selection vector

524
00:20:56,799 --> 00:21:00,320
that is we view each block as an integer

525
00:21:00,320 --> 00:21:03,039
which specifies the position of the bit

526
00:21:03,039 --> 00:21:05,520
one in its output

527
00:21:05,520 --> 00:21:07,600
and of course we set the rest of the

528
00:21:07,600 --> 00:21:09,520
best bits to zero

529
00:21:09,520 --> 00:21:11,440
so in this way we can see that you know

530
00:21:11,440 --> 00:21:14,000
the expanding function enjoys

531
00:21:14,000 --> 00:21:16,880
many like nice properties it runs in

532
00:21:16,880 --> 00:21:19,760
parallel which is the way it's defined

533
00:21:19,760 --> 00:21:23,200
and uh it is a sparse and it is uh

534
00:21:23,200 --> 00:21:26,320
injective right so every sub sub

535
00:21:26,320 --> 00:21:27,440
function

536
00:21:27,440 --> 00:21:31,280
distracts sel is one two one so

537
00:21:31,280 --> 00:21:32,960
so is the expanding function which is

538
00:21:32,960 --> 00:21:35,440
just to calculate all the sub functions

539
00:21:35,440 --> 00:21:38,000
all together

540
00:21:38,880 --> 00:21:40,320
so

541
00:21:40,320 --> 00:21:41,919
now next and

542
00:21:41,919 --> 00:21:44,559
so we just show that the bsvp implies

543
00:21:44,559 --> 00:21:45,760
cih

544
00:21:45,760 --> 00:21:47,360
it then remains to show that the

545
00:21:47,360 --> 00:21:50,640
airplane implies bsvp

546
00:21:50,640 --> 00:21:53,520
so we recall that the bsbp aims to find

547
00:21:53,520 --> 00:21:56,720
the sparse solution x such that ax is

548
00:21:56,720 --> 00:22:00,320
zero and we recall that the

549
00:22:00,320 --> 00:22:03,360
decision airplane is just about you know

550
00:22:03,360 --> 00:22:05,280
distinguished european samples from

551
00:22:05,280 --> 00:22:06,960
uniform

552
00:22:06,960 --> 00:22:08,799
so the proof

553
00:22:08,799 --> 00:22:12,320
suppose we have a vspp server that

554
00:22:12,320 --> 00:22:15,120
returns a sparse solution x with good

555
00:22:15,120 --> 00:22:16,400
chance

556
00:22:16,400 --> 00:22:19,280
then we can just multiply it

557
00:22:19,280 --> 00:22:22,400
with the string z to be distinguished

558
00:22:22,400 --> 00:22:24,480
in case that you know this z it comes

559
00:22:24,480 --> 00:22:26,640
from the airplane sample

560
00:22:26,640 --> 00:22:29,440
the output is the inner product between

561
00:22:29,440 --> 00:22:32,320
a noise vector essentially and a sparse

562
00:22:32,320 --> 00:22:33,280
vector

563
00:22:33,280 --> 00:22:35,840
so they'll be biased by the piling up

564
00:22:35,840 --> 00:22:37,440
lemma

565
00:22:37,440 --> 00:22:39,679
and in case that you know this d is

566
00:22:39,679 --> 00:22:41,520
uniformly random

567
00:22:41,520 --> 00:22:44,880
and the x is now zero

568
00:22:44,880 --> 00:22:46,799
then their product will be you know

569
00:22:46,799 --> 00:22:50,559
uniform just a uniform random bit

570
00:22:50,559 --> 00:22:51,679
and

571
00:22:51,679 --> 00:22:52,400
so

572
00:22:52,400 --> 00:22:53,600
um

573
00:22:53,600 --> 00:22:56,640
so so we'll be able to use

574
00:22:56,640 --> 00:22:57,440
the

575
00:22:57,440 --> 00:22:59,600
svp server to solve

576
00:22:59,600 --> 00:23:02,080
decisional erpm with non-negligible

577
00:23:02,080 --> 00:23:04,799
probability

578
00:23:07,520 --> 00:23:10,559
so now we can give the main statement

579
00:23:10,559 --> 00:23:13,440
about the airplane implies cih

580
00:23:13,440 --> 00:23:15,280
so informally

581
00:23:15,280 --> 00:23:19,200
the t-heart airplane assumption implies

582
00:23:19,200 --> 00:23:22,559
a square root t hat

583
00:23:22,559 --> 00:23:26,880
cih where this lowercase t in red

584
00:23:26,880 --> 00:23:29,600
is a tunable parameter with certain

585
00:23:29,600 --> 00:23:32,080
degree of freedom

586
00:23:32,080 --> 00:23:34,799
and then we can derive many calories

587
00:23:34,799 --> 00:23:36,400
from this main theory

588
00:23:36,400 --> 00:23:38,640
such as you know the ones shown in this

589
00:23:38,640 --> 00:23:40,080
table

590
00:23:40,080 --> 00:23:42,400
such as the second one like second one

591
00:23:42,400 --> 00:23:45,200
is essentially the result of epidural at

592
00:23:45,200 --> 00:23:47,200
itcs

593
00:23:47,200 --> 00:23:48,480
and

594
00:23:48,480 --> 00:23:51,279
actually we can prove improved version

595
00:23:51,279 --> 00:23:53,919
stated as a

596
00:23:53,919 --> 00:23:56,400
culinary one number one

597
00:23:56,400 --> 00:23:59,039
where you know we reduce the assumption

598
00:23:59,039 --> 00:24:00,720
hardness assumption of airplane to

599
00:24:00,720 --> 00:24:02,240
roughly two to the

600
00:24:02,240 --> 00:24:04,400
square root of n

601
00:24:04,400 --> 00:24:06,240
and the correlation number four is

602
00:24:06,240 --> 00:24:09,120
exactly the one given by brexit or at

603
00:24:09,120 --> 00:24:10,799
the euro crypt

604
00:24:10,799 --> 00:24:13,440
and to prove this uh calculator is we

605
00:24:13,440 --> 00:24:15,919
you know we just set this uh

606
00:24:15,919 --> 00:24:17,279
lowercase t

607
00:24:17,279 --> 00:24:18,960
to different values

608
00:24:18,960 --> 00:24:19,840
and

609
00:24:19,840 --> 00:24:21,679
derive the corresponding hardness

610
00:24:21,679 --> 00:24:23,760
parameter capital capital t for

611
00:24:23,760 --> 00:24:25,919
different noise rate right

612
00:24:25,919 --> 00:24:30,000
the proof is just very straightforward

613
00:24:30,000 --> 00:24:33,120
but but here we have some uh technical

614
00:24:33,120 --> 00:24:35,919
issues which is hidden um

615
00:24:35,919 --> 00:24:38,480
like like for the currently collaborated

616
00:24:38,480 --> 00:24:40,880
number two number three and number four

617
00:24:40,880 --> 00:24:43,120
the matrix dimensions are polymer

618
00:24:43,120 --> 00:24:45,279
polynomially related which is not a

619
00:24:45,279 --> 00:24:46,640
problem at all

620
00:24:46,640 --> 00:24:49,679
but uh for the calendar number one

621
00:24:49,679 --> 00:24:52,799
you know we have like a very huge matrix

622
00:24:52,799 --> 00:24:55,520
with many many like sub exponential many

623
00:24:55,520 --> 00:24:56,799
columns

624
00:24:56,799 --> 00:24:59,200
so this means the construction is not

625
00:24:59,200 --> 00:25:02,480
polynomial time computable

626
00:25:02,480 --> 00:25:05,200
but we can actually fix this problem by

627
00:25:05,200 --> 00:25:07,440
using another parameter a new parameter

628
00:25:07,440 --> 00:25:09,120
let's call it lambda

629
00:25:09,120 --> 00:25:11,120
is that lambda to be 2 to the square

630
00:25:11,120 --> 00:25:12,240
root of n

631
00:25:12,240 --> 00:25:14,559
such that you know the function is now

632
00:25:14,559 --> 00:25:17,440
polynomial time computable with super

633
00:25:17,440 --> 00:25:21,360
polynomial should be polynomial hardness

634
00:25:21,360 --> 00:25:23,679
both in the secret parameter

635
00:25:23,679 --> 00:25:24,880
of

636
00:25:24,880 --> 00:25:28,240
both as a function of the new lambda

637
00:25:28,240 --> 00:25:29,360
but then

638
00:25:29,360 --> 00:25:31,279
you know the input and output is too

639
00:25:31,279 --> 00:25:32,159
short

640
00:25:32,159 --> 00:25:33,120
which

641
00:25:33,120 --> 00:25:35,360
whose lengths are only poly logarithmic

642
00:25:35,360 --> 00:25:38,320
in lambda but this is not a problem we

643
00:25:38,320 --> 00:25:40,080
can just you know do

644
00:25:40,080 --> 00:25:43,279
do a parallel repetition

645
00:25:43,279 --> 00:25:45,279
run you know many sufficiently many

646
00:25:45,279 --> 00:25:48,000
copies to make the input and output

647
00:25:48,000 --> 00:25:50,559
linear size in lambda

648
00:25:50,559 --> 00:25:52,400
where you know the collision resistance

649
00:25:52,400 --> 00:25:57,000
is preserved under the repetition

650
00:25:57,600 --> 00:26:00,799
okay next uh we introduce how to how to

651
00:26:00,799 --> 00:26:03,279
build more efficient more parallel

652
00:26:03,279 --> 00:26:05,039
domain standards from the hardness of

653
00:26:05,039 --> 00:26:07,440
european so

654
00:26:07,440 --> 00:26:08,320
you know

655
00:26:08,320 --> 00:26:10,960
you know we know many many many domain

656
00:26:10,960 --> 00:26:13,200
standards for cih like the merkel

657
00:26:13,200 --> 00:26:15,679
dengard which is basically sequential

658
00:26:15,679 --> 00:26:17,200
and when you know when the compression

659
00:26:17,200 --> 00:26:20,159
rate is uh it's two we can use a more

660
00:26:20,159 --> 00:26:22,080
parallel mode

661
00:26:22,080 --> 00:26:24,640
called the merkle tree right so that you

662
00:26:24,640 --> 00:26:26,640
know to compress

663
00:26:26,640 --> 00:26:28,400
you know for a polynomial compression

664
00:26:28,400 --> 00:26:30,640
rate we only need a logarithm

665
00:26:30,640 --> 00:26:33,919
logarithmic depth

666
00:26:34,080 --> 00:26:35,679
next we have yeah we are actually more

667
00:26:35,679 --> 00:26:37,200
ambitious so we can

668
00:26:37,200 --> 00:26:40,320
we show that we can come up with a

669
00:26:40,320 --> 00:26:42,400
a better domain standard under the

670
00:26:42,400 --> 00:26:44,080
hardness of airplane

671
00:26:44,080 --> 00:26:46,080
so one may find that this problem is

672
00:26:46,080 --> 00:26:49,279
actually durable to the domain extension

673
00:26:49,279 --> 00:26:50,159
for

674
00:26:50,159 --> 00:26:53,720
first render generators

675
00:26:53,760 --> 00:26:56,159
okay suppose we have a random function

676
00:26:56,159 --> 00:26:57,520
that has a

677
00:26:57,520 --> 00:26:59,279
small domain

678
00:26:59,279 --> 00:27:01,200
and we want to you know expand the

679
00:27:01,200 --> 00:27:04,400
domain polynomially by polynomial factor

680
00:27:04,400 --> 00:27:05,279
right

681
00:27:05,279 --> 00:27:08,720
the best we can hope for is this

682
00:27:08,720 --> 00:27:10,000
so we

683
00:27:10,000 --> 00:27:13,440
split split the input into many blocks

684
00:27:13,440 --> 00:27:14,159
we

685
00:27:14,159 --> 00:27:16,480
pack them with different numbers

686
00:27:16,480 --> 00:27:19,039
and we evaluate the target block in

687
00:27:19,039 --> 00:27:21,200
parallel with the random function

688
00:27:21,200 --> 00:27:24,240
and then we produce their output xor sum

689
00:27:24,240 --> 00:27:27,120
as output right

690
00:27:27,120 --> 00:27:28,240
so

691
00:27:28,240 --> 00:27:30,880
note that the tagging block

692
00:27:30,880 --> 00:27:33,440
is essentially necessary otherwise one

693
00:27:33,440 --> 00:27:36,000
could find the trivial collisions

694
00:27:36,000 --> 00:27:40,080
by simply permuting the blocks

695
00:27:40,080 --> 00:27:40,799
but

696
00:27:40,799 --> 00:27:42,640
now what i can tell you that you know

697
00:27:42,640 --> 00:27:46,159
this zoom version is indeed true

698
00:27:46,159 --> 00:27:48,240
if this i is a random function and

699
00:27:48,240 --> 00:27:50,399
assume this airplane is

700
00:27:50,399 --> 00:27:51,919
exponentially hard

701
00:27:51,919 --> 00:27:53,120
then the

702
00:27:53,120 --> 00:27:55,600
construction is collision resistant

703
00:27:55,600 --> 00:27:58,080
with very nice advantages like you know

704
00:27:58,080 --> 00:28:00,080
polynomial

705
00:28:00,080 --> 00:28:03,360
uh compression rate and maximum

706
00:28:03,360 --> 00:28:06,240
parallelizability since we only evaluate

707
00:28:06,240 --> 00:28:08,720
a single layer of random functions plus

708
00:28:08,720 --> 00:28:13,840
a plus another layer of xor gates right

709
00:28:13,840 --> 00:28:14,720
um

710
00:28:14,720 --> 00:28:17,679
but uh it remains to prove how or why

711
00:28:17,679 --> 00:28:19,679
and how we can prove this construction

712
00:28:19,679 --> 00:28:21,200
right but

713
00:28:21,200 --> 00:28:23,279
but let me say that some people may ask

714
00:28:23,279 --> 00:28:25,200
that if you have a random function then

715
00:28:25,200 --> 00:28:26,640
you know

716
00:28:26,640 --> 00:28:29,520
then you truly get a cih right but this

717
00:28:29,520 --> 00:28:32,080
is true but the problem here the

718
00:28:32,080 --> 00:28:34,480
challenge here is just we want to build

719
00:28:34,480 --> 00:28:37,279
a very very very parallel mode over

720
00:28:37,279 --> 00:28:39,919
compression where preserving

721
00:28:39,919 --> 00:28:40,799
the

722
00:28:40,799 --> 00:28:44,918
property of collision resistance

723
00:28:45,440 --> 00:28:47,840
so now i'm telling you that

724
00:28:47,840 --> 00:28:50,000
we already proved that this dream

725
00:28:50,000 --> 00:28:54,559
version is actually collision resistant

726
00:28:55,760 --> 00:28:58,640
so recall that in the pre previous slide

727
00:28:58,640 --> 00:29:00,720
we showed this construction is collision

728
00:29:00,720 --> 00:29:02,159
resistant

729
00:29:02,159 --> 00:29:04,880
but the matrix is so huge that the

730
00:29:04,880 --> 00:29:07,600
construction can not be computed in

731
00:29:07,600 --> 00:29:09,120
polynomial time

732
00:29:09,120 --> 00:29:11,840
in the standard model

733
00:29:11,840 --> 00:29:13,760
you know it will be a good this will be

734
00:29:13,760 --> 00:29:16,000
a good thing in the idealized model

735
00:29:16,000 --> 00:29:16,720
right

736
00:29:16,720 --> 00:29:18,720
we simply let you know the

737
00:29:18,720 --> 00:29:21,039
the output of the random function

738
00:29:21,039 --> 00:29:23,520
corresponding to a column of the random

739
00:29:23,520 --> 00:29:25,440
matrix right

740
00:29:25,440 --> 00:29:28,080
then we can divide the matrix into many

741
00:29:28,080 --> 00:29:30,640
sub-matrices accordingly

742
00:29:30,640 --> 00:29:31,600
right

743
00:29:31,600 --> 00:29:34,159
and then we recall the instantiation of

744
00:29:34,159 --> 00:29:36,000
the expanding function

745
00:29:36,000 --> 00:29:36,960
is that

746
00:29:36,960 --> 00:29:39,520
we output many selection vectors

747
00:29:39,520 --> 00:29:40,399
right

748
00:29:40,399 --> 00:29:42,720
you know then the output is simply

749
00:29:42,720 --> 00:29:45,039
multiplying these sub matrices with the

750
00:29:45,039 --> 00:29:47,600
corresponding selection vector component

751
00:29:47,600 --> 00:29:48,559
wise

752
00:29:48,559 --> 00:29:52,720
and then then output there are x or some

753
00:29:52,720 --> 00:29:54,399
that is that we essentially prove that

754
00:29:54,399 --> 00:29:56,960
the the in efficient construction in the

755
00:29:56,960 --> 00:29:58,240
standard model

756
00:29:58,240 --> 00:29:59,919
which is culinary number one if you can

757
00:29:59,919 --> 00:30:02,559
recall in the previous slide

758
00:30:02,559 --> 00:30:04,480
is essentially our dream version of the

759
00:30:04,480 --> 00:30:06,640
domain standard in the idlet in the

760
00:30:06,640 --> 00:30:08,960
idealized model with

761
00:30:08,960 --> 00:30:11,919
exponential hardness

762
00:30:12,080 --> 00:30:13,039
okay

763
00:30:13,039 --> 00:30:15,840
so uh next i will talk about recent

764
00:30:15,840 --> 00:30:18,240
works on worst case to average case

765
00:30:18,240 --> 00:30:21,520
reduction for european

766
00:30:21,520 --> 00:30:24,000
so we know that the other ad we already

767
00:30:24,000 --> 00:30:24,799
said

768
00:30:24,799 --> 00:30:26,000
uh

769
00:30:26,000 --> 00:30:28,240
the appian represents the average case

770
00:30:28,240 --> 00:30:29,919
problem

771
00:30:29,919 --> 00:30:32,720
namely decoding running linear codes

772
00:30:32,720 --> 00:30:34,840
and it's worst case

773
00:30:34,840 --> 00:30:38,960
analog it's quite uh obvious

774
00:30:38,960 --> 00:30:40,000
no

775
00:30:40,000 --> 00:30:43,120
except that no the effect the matrix

776
00:30:43,120 --> 00:30:44,880
the vector

777
00:30:44,880 --> 00:30:46,080
have not

778
00:30:46,080 --> 00:30:48,240
have not any entropy at all

779
00:30:48,240 --> 00:30:50,640
but we have the promise that you know

780
00:30:50,640 --> 00:30:51,760
the noise

781
00:30:51,760 --> 00:30:54,880
the noise vector e has some exact amount

782
00:30:54,880 --> 00:30:56,880
of uh hamming weight

783
00:30:56,880 --> 00:31:00,480
right this is just uh you know

784
00:31:01,440 --> 00:31:03,600
in the average case in in the european

785
00:31:03,600 --> 00:31:05,760
problem we say that you know

786
00:31:05,760 --> 00:31:07,919
the er the

787
00:31:07,919 --> 00:31:08,799
the

788
00:31:08,799 --> 00:31:09,600
the

789
00:31:09,600 --> 00:31:12,000
noise vector has uh the having weight

790
00:31:12,000 --> 00:31:15,679
has ex expected to have like with some

791
00:31:15,679 --> 00:31:19,760
fixed amount of weight right

792
00:31:19,760 --> 00:31:22,399
in general we we cannot show a reduction

793
00:31:22,399 --> 00:31:25,279
for any code because this code could be

794
00:31:25,279 --> 00:31:27,440
a bad code for example the generator

795
00:31:27,440 --> 00:31:30,159
matrix is just all zero right

796
00:31:30,159 --> 00:31:32,559
so we can only prove it for a good code

797
00:31:32,559 --> 00:31:35,120
which has some non-trivial amount of

798
00:31:35,120 --> 00:31:38,479
minimum harming distance

799
00:31:38,880 --> 00:31:40,240
but some

800
00:31:40,240 --> 00:31:42,480
some previous works like the the work of

801
00:31:42,480 --> 00:31:44,799
actually the work of bankruptcy.org

802
00:31:44,799 --> 00:31:46,960
consider a stronger version of hamming

803
00:31:46,960 --> 00:31:49,039
distance requirement

804
00:31:49,039 --> 00:31:50,799
called the balanced code

805
00:31:50,799 --> 00:31:52,480
where the you know the timing distance

806
00:31:52,480 --> 00:31:54,960
has both upper bound and the lower bound

807
00:31:54,960 --> 00:31:57,440
so in other words the codeword has

808
00:31:57,440 --> 00:31:59,760
almost the same number of ones and zeros

809
00:31:59,760 --> 00:32:03,519
up to a beta fraction

810
00:32:03,679 --> 00:32:04,720
and

811
00:32:04,720 --> 00:32:06,720
in our work we also consider another

812
00:32:06,720 --> 00:32:08,399
code called

813
00:32:08,399 --> 00:32:11,279
called the independence independent code

814
00:32:11,279 --> 00:32:13,600
where the generator matrix has been wise

815
00:32:13,600 --> 00:32:16,480
independent rows

816
00:32:17,279 --> 00:32:20,159
you know mds code maximum distance

817
00:32:20,159 --> 00:32:22,000
separation uh maximum distance

818
00:32:22,000 --> 00:32:24,799
separatable code mbs code it's a special

819
00:32:24,799 --> 00:32:27,279
case of independence code for k for k

820
00:32:27,279 --> 00:32:30,080
equals to n

821
00:32:31,120 --> 00:32:33,200
and we know that the prob the problem

822
00:32:33,200 --> 00:32:36,799
promising ncp is known to be mp hard in

823
00:32:36,799 --> 00:32:38,480
the high noise region

824
00:32:38,480 --> 00:32:39,360
and

825
00:32:39,360 --> 00:32:42,000
when the noise rate is a superconstant

826
00:32:42,000 --> 00:32:44,320
the best known attacks for ncp and

827
00:32:44,320 --> 00:32:46,720
airplane has complexity of roughly two

828
00:32:46,720 --> 00:32:48,960
to the power of the product of noise

829
00:32:48,960 --> 00:32:51,200
rate and dimension

830
00:32:51,200 --> 00:32:53,279
in other words in the noise in the low

831
00:32:53,279 --> 00:32:55,279
noise region we don't know any algorithm

832
00:32:55,279 --> 00:33:00,240
that solve the airplane better than ncp

833
00:33:02,150 --> 00:33:04,640
[Music]

834
00:33:04,640 --> 00:33:07,440
so next we are going to show how to do

835
00:33:07,440 --> 00:33:10,559
worst case to aggregate reductions for

836
00:33:10,559 --> 00:33:12,480
for european um

837
00:33:12,480 --> 00:33:13,440
so

838
00:33:13,440 --> 00:33:16,000
brex blank schedule at the euro crypt

839
00:33:16,000 --> 00:33:19,360
2019 they give the first worst case to

840
00:33:19,360 --> 00:33:21,600
average case reduction from ncp to

841
00:33:21,600 --> 00:33:22,880
european

842
00:33:22,880 --> 00:33:25,600
so suppose that we have uh have an ncp

843
00:33:25,600 --> 00:33:27,519
instance

844
00:33:27,519 --> 00:33:29,279
so we need to

845
00:33:29,279 --> 00:33:32,320
we need to transform the ncp instance uh

846
00:33:32,320 --> 00:33:35,200
into a airplane sample right

847
00:33:35,200 --> 00:33:37,360
we can do this by simply multiplying

848
00:33:37,360 --> 00:33:40,080
with a with a random sparse random

849
00:33:40,080 --> 00:33:41,519
vector r

850
00:33:41,519 --> 00:33:43,600
right we're just multiplying this this

851
00:33:43,600 --> 00:33:46,159
vector in yellow color and

852
00:33:46,159 --> 00:33:47,200
right

853
00:33:47,200 --> 00:33:50,320
then we also need to you know

854
00:33:50,320 --> 00:33:53,679
we also need to extra this message s

855
00:33:53,679 --> 00:33:55,679
because this s is the worst case

856
00:33:55,679 --> 00:33:58,080
instance this s had no entropy at all we

857
00:33:58,080 --> 00:34:01,840
need to xor this s with a with another

858
00:34:01,840 --> 00:34:04,399
equivalence vector that is uniformly

859
00:34:04,399 --> 00:34:07,039
random right

860
00:34:07,039 --> 00:34:09,040
of course we can do this many times to

861
00:34:09,040 --> 00:34:10,719
get as many

862
00:34:10,719 --> 00:34:13,760
european samples as needed

863
00:34:13,760 --> 00:34:15,679
so black blanks together they show a

864
00:34:15,679 --> 00:34:18,000
smooth dilemma which says that you know

865
00:34:18,000 --> 00:34:20,320
for balanced code c and for random

866
00:34:20,320 --> 00:34:22,000
sparse

867
00:34:22,000 --> 00:34:24,800
where the sparse sparsity of these eyes

868
00:34:24,800 --> 00:34:28,079
perimeter parameterized by d

869
00:34:28,079 --> 00:34:30,719
such that you know c r calculated with

870
00:34:30,719 --> 00:34:32,839
uh with this

871
00:34:32,839 --> 00:34:36,399
xr is the statistic close to

872
00:34:36,399 --> 00:34:38,159
uniform randomness

873
00:34:38,159 --> 00:34:40,000
calculated with a binary distribution

874
00:34:40,000 --> 00:34:43,839
biased bandwidth distribution right

875
00:34:43,839 --> 00:34:44,800
so

876
00:34:44,800 --> 00:34:47,679
this uh so this this approach

877
00:34:47,679 --> 00:34:49,839
actually works as long as you know the

878
00:34:49,839 --> 00:34:52,719
under on the underlying binary linear

879
00:34:52,719 --> 00:34:54,399
code is balanced built

880
00:34:54,399 --> 00:34:56,480
and r is sampled from some special

881
00:34:56,480 --> 00:34:58,560
sparse distribution

882
00:34:58,560 --> 00:35:01,359
they actually prove this by through this

883
00:35:01,359 --> 00:35:02,400
binary

884
00:35:02,400 --> 00:35:04,320
free transform technique

885
00:35:04,320 --> 00:35:06,960
and in our paper we give a

886
00:35:06,960 --> 00:35:09,359
alternative proof using vezrani's

887
00:35:09,359 --> 00:35:11,359
xolemma

888
00:35:11,359 --> 00:35:12,640
actually these two techniques are

889
00:35:12,640 --> 00:35:14,640
equivalent to just you know

890
00:35:14,640 --> 00:35:17,760
make some simplifications

891
00:35:17,760 --> 00:35:20,079
now we take a closer look

892
00:35:20,079 --> 00:35:22,000
at the brvw

893
00:35:22,000 --> 00:35:24,160
quantitatively now

894
00:35:24,160 --> 00:35:26,400
first we look at their

895
00:35:26,400 --> 00:35:28,720
smooth dilemma for balanced coasts

896
00:35:28,720 --> 00:35:31,520
there are some lower bound on the ncp

897
00:35:31,520 --> 00:35:33,839
noise rate due to the known attacks you

898
00:35:33,839 --> 00:35:36,320
know otherwise they may keep it so

899
00:35:36,320 --> 00:35:38,400
lambda can cannot be too small otherwise

900
00:35:38,400 --> 00:35:39,520
where

901
00:35:39,520 --> 00:35:41,440
there will be polynomial time

902
00:35:41,440 --> 00:35:43,280
attacks right

903
00:35:43,280 --> 00:35:47,119
there also there's also this gb bound

904
00:35:47,119 --> 00:35:50,160
ggv type bound on beta you know to

905
00:35:50,160 --> 00:35:52,320
guarantee that you know the balanced

906
00:35:52,320 --> 00:35:55,760
code we care about indeed exists right

907
00:35:55,760 --> 00:35:57,839
finally the problem has to you know the

908
00:35:57,839 --> 00:36:01,760
this can be seen as a extract determine

909
00:36:01,760 --> 00:36:04,079
determine deterministic randomness

910
00:36:04,079 --> 00:36:05,599
extraction from

911
00:36:05,599 --> 00:36:08,560
from a structured source r

912
00:36:08,560 --> 00:36:12,880
in presence of leakage xr right so in g

913
00:36:12,880 --> 00:36:15,119
so in general there's a

914
00:36:15,119 --> 00:36:17,200
lower bound on the sparsity of the

915
00:36:17,200 --> 00:36:19,200
randomness distribution

916
00:36:19,200 --> 00:36:21,599
right so d has to be at least

917
00:36:21,599 --> 00:36:22,560
an

918
00:36:22,560 --> 00:36:24,880
n over log n

919
00:36:24,880 --> 00:36:27,200
so under these very strong strong

920
00:36:27,200 --> 00:36:29,280
assumptions we they get very like a

921
00:36:29,280 --> 00:36:31,440
conservative result

922
00:36:31,440 --> 00:36:34,079
right here we can see you know the range

923
00:36:34,079 --> 00:36:36,960
of lambda represent

924
00:36:36,960 --> 00:36:39,040
represents the tension between the

925
00:36:39,040 --> 00:36:41,520
assumption under the conclusion

926
00:36:41,520 --> 00:36:42,720
right

927
00:36:42,720 --> 00:36:43,760
so

928
00:36:43,760 --> 00:36:46,640
that means uh

929
00:36:47,359 --> 00:36:49,520
the random lambda is quite limited

930
00:36:49,520 --> 00:36:52,160
lambda has to be super constant

931
00:36:52,160 --> 00:36:54,160
otherwise there will be polynomial tanks

932
00:36:54,160 --> 00:36:57,680
attacks on ncp falsifying falsifying the

933
00:36:57,680 --> 00:36:58,720
assumption

934
00:36:58,720 --> 00:37:01,280
and the lambda is upper bounded by a

935
00:37:01,280 --> 00:37:02,400
logarithm

936
00:37:02,400 --> 00:37:04,960
at the same time because any larger

937
00:37:04,960 --> 00:37:08,000
lambda would make airplane noise

938
00:37:08,000 --> 00:37:11,040
negligibly close to uniform

939
00:37:11,040 --> 00:37:13,040
so that they know

940
00:37:13,040 --> 00:37:14,480
make it making the result less

941
00:37:14,480 --> 00:37:15,839
meaningful

942
00:37:15,839 --> 00:37:19,200
so typically they has to they typically

943
00:37:19,200 --> 00:37:23,839
tries to set lambda to log n

944
00:37:26,000 --> 00:37:27,520
so

945
00:37:27,520 --> 00:37:30,640
so we actually observe

946
00:37:30,640 --> 00:37:33,119
we actually observe this it's uh it's

947
00:37:33,119 --> 00:37:34,880
it's very easy to prove that you know

948
00:37:34,880 --> 00:37:37,920
the unconditional case that the cr is a

949
00:37:37,920 --> 00:37:40,400
statistically close to uniform

950
00:37:40,400 --> 00:37:43,119
but proving the conditional case

951
00:37:43,119 --> 00:37:45,359
that the ci is close to uniform given

952
00:37:45,359 --> 00:37:46,480
the leakage

953
00:37:46,480 --> 00:37:48,480
seems to be very less

954
00:37:48,480 --> 00:37:50,880
more challenging and less efficient

955
00:37:50,880 --> 00:37:53,280
you know since one has to guarantee that

956
00:37:53,280 --> 00:37:56,320
you know it is true for all possible

957
00:37:56,320 --> 00:37:58,880
or possible all possibilities of the

958
00:37:58,880 --> 00:38:01,680
error x

959
00:38:01,760 --> 00:38:04,320
so what we observe and what we prove is

960
00:38:04,320 --> 00:38:05,680
the following

961
00:38:05,680 --> 00:38:06,480
so

962
00:38:06,480 --> 00:38:09,520
if r is drawn from a proper distribution

963
00:38:09,520 --> 00:38:11,920
that is coordinate wise independent

964
00:38:11,920 --> 00:38:13,520
and the sparse

965
00:38:13,520 --> 00:38:14,880
which is essentially the binary

966
00:38:14,880 --> 00:38:16,480
distribution

967
00:38:16,480 --> 00:38:19,119
and then the bond the bond in the

968
00:38:19,119 --> 00:38:20,640
conditional case

969
00:38:20,640 --> 00:38:22,960
is implied by that of the unconditional

970
00:38:22,960 --> 00:38:23,920
case

971
00:38:23,920 --> 00:38:26,000
paying reasonable cost

972
00:38:26,000 --> 00:38:29,920
and we can show this is almost tight

973
00:38:30,079 --> 00:38:32,320
therefore it is uh sufficient to prove

974
00:38:32,320 --> 00:38:34,000
that you know

975
00:38:34,000 --> 00:38:35,440
the easy con

976
00:38:35,440 --> 00:38:38,880
unconditional case for a specific code

977
00:38:38,880 --> 00:38:40,880
such as you know the balanced code or

978
00:38:40,880 --> 00:38:41,599
the

979
00:38:41,599 --> 00:38:43,440
independent code we

980
00:38:43,440 --> 00:38:46,880
we we talked about

981
00:38:46,880 --> 00:38:49,440
actually you can uh you can

982
00:38:49,440 --> 00:38:53,680
do a problem probabilistic analysis

983
00:38:53,680 --> 00:38:57,040
and give a very non-construct

984
00:38:57,040 --> 00:38:59,119
non-constructive form of the smoothie

985
00:38:59,119 --> 00:39:02,560
lamber to illustrate to to illustrate

986
00:39:02,560 --> 00:39:03,839
the difficulty

987
00:39:03,839 --> 00:39:05,839
of proving the

988
00:39:05,839 --> 00:39:08,000
a meaningful

989
00:39:08,000 --> 00:39:10,480
a more useful

990
00:39:10,480 --> 00:39:12,160
smooth dilemma

991
00:39:12,160 --> 00:39:12,839
that

992
00:39:12,839 --> 00:39:17,119
is they are you know uh

993
00:39:17,119 --> 00:39:18,480
you know uh

994
00:39:18,480 --> 00:39:20,720
they are by you know

995
00:39:20,720 --> 00:39:23,119
there exist at least a certain fraction

996
00:39:23,119 --> 00:39:25,839
of the code such that for any error

997
00:39:25,839 --> 00:39:28,800
vector of waiting w

998
00:39:28,800 --> 00:39:32,480
and any like a sparse distribution cr is

999
00:39:32,480 --> 00:39:35,520
a close to uniform given the noise

1000
00:39:35,520 --> 00:39:39,280
given the leakage xor xr

1001
00:39:39,280 --> 00:39:41,680
so the proof is just you know follows

1002
00:39:41,680 --> 00:39:43,280
three steps the first step is just the

1003
00:39:43,280 --> 00:39:45,920
left of the hash number right

1004
00:39:45,920 --> 00:39:47,839
and then you know we have the macro

1005
00:39:47,839 --> 00:39:50,320
macro for inequality and for every x

1006
00:39:50,320 --> 00:39:52,960
every error x there there exists a

1007
00:39:52,960 --> 00:39:54,400
certain fraction

1008
00:39:54,400 --> 00:39:56,160
a certain fraction that fails the

1009
00:39:56,160 --> 00:39:58,240
randomness extraction right

1010
00:39:58,240 --> 00:40:00,720
and finally we can you know we have like

1011
00:40:00,720 --> 00:40:02,640
infinite and

1012
00:40:02,640 --> 00:40:04,800
we just take it taking into account that

1013
00:40:04,800 --> 00:40:07,200
we have like at most m

1014
00:40:07,200 --> 00:40:09,760
m choose w different the possibilities

1015
00:40:09,760 --> 00:40:12,160
for the error vector right so we can

1016
00:40:12,160 --> 00:40:14,400
essentially bond something summing up to

1017
00:40:14,400 --> 00:40:17,119
all the fraction of the bad code by a

1018
00:40:17,119 --> 00:40:19,119
union bond

1019
00:40:19,119 --> 00:40:21,440
okay so in the end the end goal is to

1020
00:40:21,440 --> 00:40:22,720
prove that this hardness for the

1021
00:40:22,720 --> 00:40:24,319
standard erp whose noise rate is

1022
00:40:24,319 --> 00:40:25,920
constant

1023
00:40:25,920 --> 00:40:27,280
and we recall that the entropy

1024
00:40:27,280 --> 00:40:28,400
requirement

1025
00:40:28,400 --> 00:40:31,119
then the bad fraction

1026
00:40:31,119 --> 00:40:32,240
will be

1027
00:40:32,240 --> 00:40:33,280
much

1028
00:40:33,280 --> 00:40:35,040
much greater than one

1029
00:40:35,040 --> 00:40:37,440
so which means that you know

1030
00:40:37,440 --> 00:40:39,760
this uh this analysis is meaningless

1031
00:40:39,760 --> 00:40:42,560
right put it put it differently

1032
00:40:42,560 --> 00:40:45,119
it seems that you know

1033
00:40:45,119 --> 00:40:46,960
it seems not possible to get the worst

1034
00:40:46,960 --> 00:40:48,480
case to ever case reduction from

1035
00:40:48,480 --> 00:40:51,440
standard engine and as a more tighter

1036
00:40:51,440 --> 00:40:54,079
techniques are employed

1037
00:40:54,079 --> 00:40:54,880
so

1038
00:40:54,880 --> 00:40:57,440
which is the technique we we show in the

1039
00:40:57,440 --> 00:41:00,240
previous slides

1040
00:41:01,280 --> 00:41:02,560
sorry

1041
00:41:02,560 --> 00:41:05,040
it's just what we prove

1042
00:41:05,040 --> 00:41:08,160
we we we reduce the case of uh the under

1043
00:41:08,160 --> 00:41:09,440
conditioner case to that of the

1044
00:41:09,440 --> 00:41:11,119
unconditioned sorry it's running too

1045
00:41:11,119 --> 00:41:13,359
fast

1046
00:41:14,160 --> 00:41:14,880
so

1047
00:41:14,880 --> 00:41:17,040
this is the titanic the tighter

1048
00:41:17,040 --> 00:41:21,400
technique we talked about right

1049
00:41:23,200 --> 00:41:26,078
the next uh

1050
00:41:26,560 --> 00:41:29,200
okay so now we can state our main main

1051
00:41:29,200 --> 00:41:30,400
crm

1052
00:41:30,400 --> 00:41:32,720
no first uh

1053
00:41:32,720 --> 00:41:35,280
this is the main theorem and we can get

1054
00:41:35,280 --> 00:41:39,119
a similar result as blvw in the first as

1055
00:41:39,119 --> 00:41:42,800
a the calibrated number one

1056
00:41:43,680 --> 00:41:45,760
because you know under you know

1057
00:41:45,760 --> 00:41:48,319
uh when the

1058
00:41:48,319 --> 00:41:49,280
when the

1059
00:41:49,280 --> 00:41:53,119
noise rate of the promised ncp is

1060
00:41:53,119 --> 00:41:56,560
extremely low we get the standard erp uh

1061
00:41:56,560 --> 00:41:58,880
we can you know hide not we

1062
00:41:58,880 --> 00:42:00,800
we can show that the high noise airplane

1063
00:42:00,800 --> 00:42:03,520
is average it's hard in the average case

1064
00:42:03,520 --> 00:42:04,319
right

1065
00:42:04,319 --> 00:42:07,280
if we compare our results to blvw

1066
00:42:07,280 --> 00:42:09,280
quantitatively you can see that

1067
00:42:09,280 --> 00:42:12,400
it's it's actually slightly better no

1068
00:42:12,400 --> 00:42:13,119
when

1069
00:42:13,119 --> 00:42:14,400
when a

1070
00:42:14,400 --> 00:42:16,480
1m which is polynomial

1071
00:42:16,480 --> 00:42:17,520
of n

1072
00:42:17,520 --> 00:42:19,760
increase you know

1073
00:42:19,760 --> 00:42:24,000
the the noise rate of brvw sees to cease

1074
00:42:24,000 --> 00:42:26,160
to increase at some point

1075
00:42:26,160 --> 00:42:28,640
but for our case that's uh

1076
00:42:28,640 --> 00:42:31,359
it's always a it's always improving when

1077
00:42:31,359 --> 00:42:34,400
md increases

1078
00:42:34,400 --> 00:42:35,839
okay

1079
00:42:35,839 --> 00:42:37,520
so

1080
00:42:37,520 --> 00:42:40,880
now it comes to our main result

1081
00:42:40,880 --> 00:42:45,680
so if the low noise rate ncp problem

1082
00:42:45,680 --> 00:42:46,480
has

1083
00:42:46,480 --> 00:42:47,680
almost

1084
00:42:47,680 --> 00:42:50,000
almost optimal hardness

1085
00:42:50,000 --> 00:42:51,680
namely

1086
00:42:51,680 --> 00:42:53,599
the best known attacks

1087
00:42:53,599 --> 00:42:56,960
are almost optimal up to arbitrary

1088
00:42:56,960 --> 00:42:58,960
polynomial speed up

1089
00:42:58,960 --> 00:43:01,440
then it will imply

1090
00:43:01,440 --> 00:43:03,280
sub-exponential hardness for the

1091
00:43:03,280 --> 00:43:05,680
standard error pin meaning that the the

1092
00:43:05,680 --> 00:43:08,400
fps has constant noise rate

1093
00:43:08,400 --> 00:43:11,599
so this is the main result of our

1094
00:43:11,599 --> 00:43:13,200
of our work

1095
00:43:13,200 --> 00:43:15,280
and proof is quite straightforward we

1096
00:43:15,280 --> 00:43:16,800
just you know

1097
00:43:16,800 --> 00:43:20,400
based on the theorem we just you know

1098
00:43:20,400 --> 00:43:22,880
said substitute the noise rate the

1099
00:43:22,880 --> 00:43:24,960
corresponding noise rate

1100
00:43:24,960 --> 00:43:27,839
right and here we can see the end result

1101
00:43:27,839 --> 00:43:30,079
is you know

1102
00:43:30,079 --> 00:43:32,160
a sum of two terms

1103
00:43:32,160 --> 00:43:33,839
so that's why we have to consider

1104
00:43:33,839 --> 00:43:35,440
different values for

1105
00:43:35,440 --> 00:43:39,480
different values for c

1106
00:43:41,440 --> 00:43:42,720
next uh

1107
00:43:42,720 --> 00:43:45,280
i'm going to i'm going to

1108
00:43:45,280 --> 00:43:46,800
introduce our

1109
00:43:46,800 --> 00:43:50,480
recent work works on optimizing the bkw

1110
00:43:50,480 --> 00:43:52,240
algorithm for

1111
00:43:52,240 --> 00:43:54,880
for airplane

1112
00:43:54,880 --> 00:43:56,560
so let's uh

1113
00:43:56,560 --> 00:43:59,040
let's basically record the the process

1114
00:43:59,040 --> 00:44:01,920
of the bkw

1115
00:44:01,920 --> 00:44:04,640
so suppose we have you know

1116
00:44:04,640 --> 00:44:07,119
a matrix a which is uniformly random and

1117
00:44:07,119 --> 00:44:08,880
we have also b

1118
00:44:08,880 --> 00:44:10,800
b

1119
00:44:10,800 --> 00:44:13,760
which is a s plus e

1120
00:44:13,760 --> 00:44:17,280
namely the last the last column in in

1121
00:44:17,280 --> 00:44:20,079
in darker color

1122
00:44:21,119 --> 00:44:23,520
the first day if we look at the you know

1123
00:44:23,520 --> 00:44:25,520
look at the first uh

1124
00:44:25,520 --> 00:44:28,960
first b bit block of the matrix right

1125
00:44:28,960 --> 00:44:30,560
then we can

1126
00:44:30,560 --> 00:44:32,079
we can

1127
00:44:32,079 --> 00:44:35,119
class it and we can divide this matrix

1128
00:44:35,119 --> 00:44:36,640
into

1129
00:44:36,640 --> 00:44:39,280
many classes based on the value of the

1130
00:44:39,280 --> 00:44:42,000
first b block

1131
00:44:42,000 --> 00:44:44,560
in fact in fact we can divide them into

1132
00:44:44,560 --> 00:44:46,560
like two to the b

1133
00:44:46,560 --> 00:44:47,920
different groups

1134
00:44:47,920 --> 00:44:50,960
within each group the first b

1135
00:44:50,960 --> 00:44:53,920
the first b bit of the block is zero

1136
00:44:53,920 --> 00:44:57,280
it has the same value right

1137
00:44:57,280 --> 00:44:58,079
okay

1138
00:44:58,079 --> 00:44:59,920
then we you know

1139
00:44:59,920 --> 00:45:02,640
then we can you know uh

1140
00:45:02,640 --> 00:45:04,480
xor the first row

1141
00:45:04,480 --> 00:45:06,800
within each group within each class we

1142
00:45:06,800 --> 00:45:08,800
can xor the first row

1143
00:45:08,800 --> 00:45:11,200
with the rest of vectors

1144
00:45:11,200 --> 00:45:13,680
to cancel out you know the values

1145
00:45:13,680 --> 00:45:17,879
of the first block to zero

1146
00:45:18,000 --> 00:45:20,960
then we can combine all the resulting

1147
00:45:20,960 --> 00:45:23,359
vectors all together

1148
00:45:23,359 --> 00:45:24,319
right

1149
00:45:24,319 --> 00:45:26,800
so that we can uh

1150
00:45:26,800 --> 00:45:28,560
we can get the you know

1151
00:45:28,560 --> 00:45:29,440
uh

1152
00:45:29,440 --> 00:45:30,319
we can

1153
00:45:30,319 --> 00:45:33,560
get a

1154
00:45:33,839 --> 00:45:36,640
european samples with reduce the

1155
00:45:36,640 --> 00:45:39,040
dimension and then double the

1156
00:45:39,040 --> 00:45:41,200
double the noise right

1157
00:45:41,200 --> 00:45:42,640
but you know

1158
00:45:42,640 --> 00:45:44,319
when it comes to the same number of

1159
00:45:44,319 --> 00:45:48,160
samples we also lose 2 to the b

1160
00:45:48,160 --> 00:45:50,220
we also lose 2 to the

1161
00:45:50,220 --> 00:45:51,680
[Music]

1162
00:45:51,680 --> 00:45:52,640
so

1163
00:45:52,640 --> 00:45:54,879
sorry

1164
00:45:56,640 --> 00:45:59,680
to use the 10 we also lose like two to

1165
00:45:59,680 --> 00:46:01,520
the two to the b

1166
00:46:01,520 --> 00:46:04,319
samples because you know we have to

1167
00:46:04,319 --> 00:46:06,079
when we do the xor

1168
00:46:06,079 --> 00:46:08,319
when we do the exile

1169
00:46:08,319 --> 00:46:10,400
with the first which with the first row

1170
00:46:10,400 --> 00:46:12,640
all these first row they are discarded

1171
00:46:12,640 --> 00:46:14,880
so in the end we will lose uh two to the

1172
00:46:14,880 --> 00:46:15,920
b

1173
00:46:15,920 --> 00:46:18,240
samples and you know

1174
00:46:18,240 --> 00:46:21,440
after after this uh after this after

1175
00:46:21,440 --> 00:46:24,400
after this iteration the dimension

1176
00:46:24,400 --> 00:46:26,400
the dimension of the airplane was

1177
00:46:26,400 --> 00:46:29,599
reduced by b by b bits right

1178
00:46:29,599 --> 00:46:32,560
so we will get the redu airplane samples

1179
00:46:32,560 --> 00:46:35,440
with reduced dimensions and

1180
00:46:35,440 --> 00:46:36,319
and

1181
00:46:36,319 --> 00:46:39,440
you know double the noise

1182
00:46:39,599 --> 00:46:41,359
but you know this is this is only the

1183
00:46:41,359 --> 00:46:44,000
first retreat iteration we can do this

1184
00:46:44,000 --> 00:46:46,000
many many iterations with this many many

1185
00:46:46,000 --> 00:46:48,480
iterations and here in the end you know

1186
00:46:48,480 --> 00:46:49,839
we get only like

1187
00:46:49,839 --> 00:46:53,440
we reduce the dimension to one

1188
00:46:53,440 --> 00:46:55,760
so if you look at the you know the the

1189
00:46:55,760 --> 00:46:58,480
main idea of bkw

1190
00:46:58,480 --> 00:47:00,560
it's a

1191
00:47:00,560 --> 00:47:03,920
no it's essentially

1192
00:47:03,920 --> 00:47:05,520
uh it's essentially the problem called

1193
00:47:05,520 --> 00:47:06,560
the

1194
00:47:06,560 --> 00:47:08,800
wagon the wagoner's

1195
00:47:08,800 --> 00:47:11,040
generalized the birthday problem

1196
00:47:11,040 --> 00:47:13,440
so first we you know we find many

1197
00:47:13,440 --> 00:47:14,800
vectors

1198
00:47:14,800 --> 00:47:16,720
say b vectors

1199
00:47:16,720 --> 00:47:19,040
that sums to

1200
00:47:19,040 --> 00:47:21,440
sums to

1201
00:47:21,440 --> 00:47:23,520
specify the target

1202
00:47:23,520 --> 00:47:25,680
for for example the unit the

1203
00:47:25,680 --> 00:47:28,319
the the unit vector

1204
00:47:28,319 --> 00:47:31,040
okay so then uh

1205
00:47:31,040 --> 00:47:33,920
then then this uh the x extra sum of the

1206
00:47:33,920 --> 00:47:36,559
currents corresponding european samples

1207
00:47:36,559 --> 00:47:39,280
they were corresponding to uh

1208
00:47:39,280 --> 00:47:40,720
to a candidate

1209
00:47:40,720 --> 00:47:43,359
for a single single bit a single secret

1210
00:47:43,359 --> 00:47:44,319
bit

1211
00:47:44,319 --> 00:47:48,400
but only with very admired confidence

1212
00:47:48,960 --> 00:47:50,079
right

1213
00:47:50,079 --> 00:47:52,800
because you know the the noise is so

1214
00:47:52,800 --> 00:47:55,440
huge when they exhale all together

1215
00:47:55,440 --> 00:47:57,920
this gives us very a good candidate a

1216
00:47:57,920 --> 00:47:59,839
candidate but only with very small

1217
00:47:59,839 --> 00:48:01,119
confidence

1218
00:48:01,119 --> 00:48:02,960
so then we have to

1219
00:48:02,960 --> 00:48:05,280
we have to repeat the process many many

1220
00:48:05,280 --> 00:48:10,160
times and on fresh new samples

1221
00:48:10,640 --> 00:48:12,559
because if you do this on the same

1222
00:48:12,559 --> 00:48:13,599
samples

1223
00:48:13,599 --> 00:48:15,599
then you know

1224
00:48:15,599 --> 00:48:17,760
then you do the majority voting there

1225
00:48:17,760 --> 00:48:21,440
will be you know correlations among

1226
00:48:21,440 --> 00:48:24,240
those accumulated noise

1227
00:48:24,240 --> 00:48:25,520
right

1228
00:48:25,520 --> 00:48:27,280
so overall

1229
00:48:27,280 --> 00:48:29,839
if we talk about the con

1230
00:48:29,839 --> 00:48:31,680
if we talk about the complexity of the

1231
00:48:31,680 --> 00:48:32,839
bkw

1232
00:48:32,839 --> 00:48:34,319
if uh

1233
00:48:34,319 --> 00:48:36,880
if the noise rate is a constant for for

1234
00:48:36,880 --> 00:48:40,319
instance uh q is like

1235
00:48:40,319 --> 00:48:43,200
a quarter then the complexity of the

1236
00:48:43,200 --> 00:48:45,280
space is roughly two to the b

1237
00:48:45,280 --> 00:48:47,760
here we omit a poly

1238
00:48:47,760 --> 00:48:50,559
polynomial factors

1239
00:48:50,559 --> 00:48:51,760
and the

1240
00:48:51,760 --> 00:48:54,319
time and the sample complexity will be 2

1241
00:48:54,319 --> 00:48:55,520
to the b

1242
00:48:55,520 --> 00:48:58,079
multiplied by 2 to the n over v 2 to the

1243
00:48:58,079 --> 00:48:58,960
2

1244
00:48:58,960 --> 00:49:00,839
to the n over b

1245
00:49:00,839 --> 00:49:02,640
right

1246
00:49:02,640 --> 00:49:06,000
here and this is actually you know if we

1247
00:49:06,000 --> 00:49:08,079
if we want to minimize

1248
00:49:08,079 --> 00:49:10,240
minimize the time complexity

1249
00:49:10,240 --> 00:49:12,480
we have to set that we have to set this

1250
00:49:12,480 --> 00:49:15,119
b to be like n over log n

1251
00:49:15,119 --> 00:49:18,800
so that you know this the product of

1252
00:49:18,800 --> 00:49:19,599
the

1253
00:49:19,599 --> 00:49:21,119
these two terms

1254
00:49:21,119 --> 00:49:22,800
these two terms

1255
00:49:22,800 --> 00:49:26,640
are roughly of the same order right

1256
00:49:28,640 --> 00:49:32,079
so this is uh the main idea of week w

1257
00:49:32,079 --> 00:49:34,400
and then

1258
00:49:34,400 --> 00:49:37,760
actually there remain a few questions

1259
00:49:37,760 --> 00:49:41,599
such as if we can do if we can do uh

1260
00:49:41,599 --> 00:49:43,359
trade-offs between

1261
00:49:43,359 --> 00:49:45,040
space time

1262
00:49:45,040 --> 00:49:46,720
sample right

1263
00:49:46,720 --> 00:49:47,920
right

1264
00:49:47,920 --> 00:49:50,000
in a way that we do not

1265
00:49:50,000 --> 00:49:53,440
rely on any heuristics

1266
00:49:53,440 --> 00:49:54,400
and

1267
00:49:54,400 --> 00:49:56,839
question number two is that we can you

1268
00:49:56,839 --> 00:49:58,559
know

1269
00:49:58,559 --> 00:50:00,800
remove the factor

1270
00:50:00,800 --> 00:50:02,800
essentially we if we can remove the

1271
00:50:02,800 --> 00:50:04,079
second step

1272
00:50:04,079 --> 00:50:04,800
right

1273
00:50:04,800 --> 00:50:06,240
then we can just you know save the

1274
00:50:06,240 --> 00:50:07,440
factor

1275
00:50:07,440 --> 00:50:10,640
2 to the 2 to the n 2 to the n to the 1

1276
00:50:10,640 --> 00:50:12,480
over episode

1277
00:50:12,480 --> 00:50:13,680
right

1278
00:50:13,680 --> 00:50:15,599
although this factor is uh relatively

1279
00:50:15,599 --> 00:50:19,040
small compared with the first term

1280
00:50:19,040 --> 00:50:20,960
it's actually quite large right by

1281
00:50:20,960 --> 00:50:24,160
itself because it's ex

1282
00:50:24,160 --> 00:50:26,400
it's quite exponential sub-exponential

1283
00:50:26,400 --> 00:50:29,200
where this epsilon is a is a small

1284
00:50:29,200 --> 00:50:30,559
constant

1285
00:50:30,559 --> 00:50:33,599
arbitrary close to zero

1286
00:50:33,599 --> 00:50:34,559
so

1287
00:50:34,559 --> 00:50:36,079
so in our

1288
00:50:36,079 --> 00:50:38,960
manuscript we presented uh three

1289
00:50:38,960 --> 00:50:41,440
structured algorithm framework

1290
00:50:41,440 --> 00:50:44,000
for optimizing the bkw

1291
00:50:44,000 --> 00:50:46,319
algorithm

1292
00:50:46,319 --> 00:50:48,640
so instead of having a single list we

1293
00:50:48,640 --> 00:50:50,400
have many lists

1294
00:50:50,400 --> 00:50:53,040
and they are mutually independent

1295
00:50:53,040 --> 00:50:55,119
and within each list

1296
00:50:55,119 --> 00:50:58,000
we only need each list to consist of uh

1297
00:50:58,000 --> 00:51:01,359
to contain pairwise independent vectors

1298
00:51:01,359 --> 00:51:03,200
so that means all these

1299
00:51:03,200 --> 00:51:05,760
lists they are mutually independent but

1300
00:51:05,760 --> 00:51:08,640
each list consists consists of like two

1301
00:51:08,640 --> 00:51:12,799
wise independent vectors right

1302
00:51:12,960 --> 00:51:14,000
and

1303
00:51:14,000 --> 00:51:16,400
the rest of the steps

1304
00:51:16,400 --> 00:51:20,800
uh will is are roughly the same as bkw

1305
00:51:20,800 --> 00:51:22,400
and you know

1306
00:51:22,400 --> 00:51:24,880
then i know the powers independence we

1307
00:51:24,880 --> 00:51:28,160
are preserved from all the leaves

1308
00:51:28,160 --> 00:51:31,200
all the way down to the root

1309
00:51:31,200 --> 00:51:33,440
right

1310
00:51:33,440 --> 00:51:36,480
and here we our contribution is that you

1311
00:51:36,480 --> 00:51:37,920
know this uh

1312
00:51:37,920 --> 00:51:40,319
two-wide uh power-wise independence is a

1313
00:51:40,319 --> 00:51:42,319
very characterization

1314
00:51:42,319 --> 00:51:44,000
characterization and

1315
00:51:44,000 --> 00:51:46,720
it is sufficient to give a

1316
00:51:46,720 --> 00:51:50,640
non-heuristic analysis of the algorithm

1317
00:51:50,640 --> 00:51:52,160
with the

1318
00:51:52,160 --> 00:51:53,280
regular

1319
00:51:53,280 --> 00:51:55,760
complexity time complexity space

1320
00:51:55,760 --> 00:51:58,160
complexity and sample complexity

1321
00:51:58,160 --> 00:52:01,040
and in in the in the same time at enable

1322
00:52:01,040 --> 00:52:03,839
various tradeoffs between sample time

1323
00:52:03,839 --> 00:52:05,119
and space

1324
00:52:05,119 --> 00:52:06,960
and in addition

1325
00:52:06,960 --> 00:52:08,800
we're sure that there's no need to

1326
00:52:08,800 --> 00:52:11,040
repeat the process many times

1327
00:52:11,040 --> 00:52:12,800
and therefore we can save this uh you

1328
00:52:12,800 --> 00:52:14,559
know

1329
00:52:14,559 --> 00:52:17,599
sub-exponential factor

1330
00:52:17,599 --> 00:52:20,880
that is we can uh you know

1331
00:52:21,280 --> 00:52:22,559
once we

1332
00:52:22,559 --> 00:52:25,440
once we uh run this arrogance and

1333
00:52:25,440 --> 00:52:29,599
run this algorithm all to the oh sorry

1334
00:52:29,839 --> 00:52:33,280
all the way down to the down to the root

1335
00:52:33,280 --> 00:52:36,240
then we can just you know do the

1336
00:52:36,240 --> 00:52:38,480
do the majority voting on on this this

1337
00:52:38,480 --> 00:52:40,160
column

1338
00:52:40,160 --> 00:52:42,559
right then

1339
00:52:42,559 --> 00:52:44,640
so that so that we don't need to repeat

1340
00:52:44,640 --> 00:52:46,800
the process many times on fresh new

1341
00:52:46,800 --> 00:52:49,280
samples

1342
00:52:50,079 --> 00:52:52,480
so with our optimize the bkw we can do

1343
00:52:52,480 --> 00:52:54,720
time space trade-offs where n is time

1344
00:52:54,720 --> 00:52:57,520
space complexity of dkw

1345
00:52:57,520 --> 00:53:01,200
here we introduce this in teach intj c

1346
00:53:01,200 --> 00:53:04,960
and you know we use this c to to

1347
00:53:04,960 --> 00:53:06,400
to do the trade-off

1348
00:53:06,400 --> 00:53:09,040
when t is two then you know the space

1349
00:53:09,040 --> 00:53:12,160
and time complexity are the same

1350
00:53:12,160 --> 00:53:14,800
when we increase the value of c

1351
00:53:14,800 --> 00:53:17,440
we get a larger time

1352
00:53:17,440 --> 00:53:19,920
but with a smaller space right

1353
00:53:19,920 --> 00:53:21,520
we can also use the distraction

1354
00:53:21,520 --> 00:53:24,880
technique to do further optimizations

1355
00:53:24,880 --> 00:53:28,480
and we also introduce another

1356
00:53:28,480 --> 00:53:30,880
parameter beta for further adjustment

1357
00:53:30,880 --> 00:53:33,119
right

1358
00:53:33,520 --> 00:53:35,520
in the meantime we can also use the

1359
00:53:35,520 --> 00:53:38,559
growth algorithm to do a quadratic speed

1360
00:53:38,559 --> 00:53:40,720
up

1361
00:53:40,720 --> 00:53:43,119
so in summary we actually get the same

1362
00:53:43,119 --> 00:53:45,359
result as

1363
00:53:45,359 --> 00:53:46,640
sr

1364
00:53:46,640 --> 00:53:47,520
from

1365
00:53:47,520 --> 00:53:52,319
crypto 2018 but we don't need to rely on

1366
00:53:52,319 --> 00:53:56,440
any heuristic assumptions

1367
00:53:57,440 --> 00:54:00,800
so our optimized vkw can

1368
00:54:00,800 --> 00:54:02,000
can also

1369
00:54:02,000 --> 00:54:04,480
optimize the time and sample complexity

1370
00:54:04,480 --> 00:54:07,040
of the bkw algorithm

1371
00:54:07,040 --> 00:54:09,440
yeah if we compile

1372
00:54:09,440 --> 00:54:11,760
compile to compare with you know the

1373
00:54:11,760 --> 00:54:13,359
original vkw

1374
00:54:13,359 --> 00:54:15,920
or the recent

1375
00:54:15,920 --> 00:54:17,920
the recent work of

1376
00:54:17,920 --> 00:54:21,680
devadas at all at the tcc 2017

1377
00:54:21,680 --> 00:54:24,880
we kind of saving a

1378
00:54:24,880 --> 00:54:28,720
sub-exponential factor right

1379
00:54:29,520 --> 00:54:30,720
and

1380
00:54:30,720 --> 00:54:32,000
similar to

1381
00:54:32,000 --> 00:54:33,119
uh

1382
00:54:33,119 --> 00:54:35,520
rebecca's this environment

1383
00:54:35,520 --> 00:54:37,680
we can also reduce the same sample

1384
00:54:37,680 --> 00:54:39,280
complexity

1385
00:54:39,280 --> 00:54:41,640
to for example to two to the n

1386
00:54:41,640 --> 00:54:42,960
[Music]

1387
00:54:42,960 --> 00:54:44,960
two to the n to the epsilon where

1388
00:54:44,960 --> 00:54:47,040
epsilon is a small constant

1389
00:54:47,040 --> 00:54:50,000
without uh you know while keeping the

1390
00:54:50,000 --> 00:54:53,839
time complexity to

1391
00:54:53,920 --> 00:54:56,240
keeping the time complexity to

1392
00:54:56,240 --> 00:54:58,400
to disorder right

1393
00:54:58,400 --> 00:55:00,960
oh sorry

1394
00:55:03,440 --> 00:55:04,880
so here we can

1395
00:55:04,880 --> 00:55:06,640
keeping the time complexity at the order

1396
00:55:06,640 --> 00:55:07,760
of n

1397
00:55:07,760 --> 00:55:08,880
and one

1398
00:55:08,880 --> 00:55:11,760
you know but we use much less samples

1399
00:55:11,760 --> 00:55:14,000
right

1400
00:55:14,000 --> 00:55:16,079
or further we can further push the

1401
00:55:16,079 --> 00:55:18,240
sample complexity to

1402
00:55:18,240 --> 00:55:22,240
to polynomial to a polynomial sorry and

1403
00:55:22,240 --> 00:55:24,479
right

1404
00:55:27,520 --> 00:55:29,119
we can further push the time complexity

1405
00:55:29,119 --> 00:55:31,839
to a polynomial and the compared with

1406
00:55:31,839 --> 00:55:32,559
the

1407
00:55:32,559 --> 00:55:34,640
algorithm of uh

1408
00:55:34,640 --> 00:55:37,760
rib chefsky's approach we save the

1409
00:55:37,760 --> 00:55:40,960
exponential factor which is n2 right

1410
00:55:40,960 --> 00:55:43,440
sub-exponential factor right

1411
00:55:43,440 --> 00:55:45,440
okay let me quickly

1412
00:55:45,440 --> 00:55:47,280
let me quickly summarize

1413
00:55:47,280 --> 00:55:50,000
what we have done in this uh paper in

1414
00:55:50,000 --> 00:55:52,400
this will talk we first we show how to

1415
00:55:52,400 --> 00:55:55,200
construct you know pke and cih from

1416
00:55:55,200 --> 00:55:58,000
super exponential hard standard rpm and

1417
00:55:58,000 --> 00:56:00,480
then we show how to do worst case

1418
00:56:00,480 --> 00:56:02,880
average case reductions for

1419
00:56:02,880 --> 00:56:05,359
sub-exponential hard standard error pin

1420
00:56:05,359 --> 00:56:07,839
then we give a non-heuristic approach to

1421
00:56:07,839 --> 00:56:08,880
the

1422
00:56:08,880 --> 00:56:11,839
time space and the sample trade-offs and

1423
00:56:11,839 --> 00:56:14,960
optimizations for the bkw algorithm

1424
00:56:14,960 --> 00:56:16,880
of course there remain a few open

1425
00:56:16,880 --> 00:56:20,480
problems like uh you know

1426
00:56:20,480 --> 00:56:23,280
if we based on a standard polynomial uh

1427
00:56:23,280 --> 00:56:26,319
standard erpm with polynomial hardness

1428
00:56:26,319 --> 00:56:29,520
how to build pke cih or even

1429
00:56:29,520 --> 00:56:31,920
fhe uh nijk

1430
00:56:31,920 --> 00:56:35,200
from it right or if it's not possible

1431
00:56:35,200 --> 00:56:37,520
why and we need a better understanding

1432
00:56:37,520 --> 00:56:39,760
why they are not possible

1433
00:56:39,760 --> 00:56:42,240
okay that that is uh that concludes my

1434
00:56:42,240 --> 00:56:44,880
talk thank you for your time and i will

1435
00:56:44,880 --> 00:56:47,440
be happy to take questions

1436
00:56:47,440 --> 00:56:52,079
okay thank you e for very exciting talk

1437
00:56:52,079 --> 00:56:53,839
okay we have time for combining

1438
00:56:53,839 --> 00:56:56,839
questions

1439
00:57:01,839 --> 00:57:04,640
on the chat ball uh

1440
00:57:04,640 --> 00:57:06,160
do you have any question you might try

1441
00:57:06,160 --> 00:57:09,599
to unveil yourself in yeah just uh yeah

1442
00:57:09,599 --> 00:57:11,359
i have a question first of all thank you

1443
00:57:11,359 --> 00:57:13,680
for the talk that was very nice

1444
00:57:13,680 --> 00:57:15,680
so on your last slide you said like uh

1445
00:57:15,680 --> 00:57:17,040
you want to

1446
00:57:17,040 --> 00:57:19,200
the cs open problem so

1447
00:57:19,200 --> 00:57:20,720
this is more of a speculative question

1448
00:57:20,720 --> 00:57:21,920
like what do you think that this would

1449
00:57:21,920 --> 00:57:23,680
be possible or do you somehow

1450
00:57:23,680 --> 00:57:25,520
intuitively feel that it's not possible

1451
00:57:25,520 --> 00:57:29,280
but it's just an instinctual feeling

1452
00:57:29,280 --> 00:57:32,480
i i believe uh like for pke

1453
00:57:32,480 --> 00:57:35,359
a cih would be

1454
00:57:35,359 --> 00:57:37,839
i believe it's quite negative right if

1455
00:57:37,839 --> 00:57:39,440
you have like standard polynomial

1456
00:57:39,440 --> 00:57:42,640
hardness therapy and it's quite

1457
00:57:42,640 --> 00:57:46,240
hard to know to build a pke not even to

1458
00:57:46,240 --> 00:57:48,400
mention fhe

1459
00:57:48,400 --> 00:57:49,839
okay

1460
00:57:49,839 --> 00:57:51,200
thank you very much

1461
00:57:51,200 --> 00:57:54,680
thank you thank you

1462
00:57:56,480 --> 00:58:00,480
any other questions or comments

1463
00:58:03,760 --> 00:58:06,880
so i guess i have one

1464
00:58:06,960 --> 00:58:09,359
um so

1465
00:58:09,359 --> 00:58:11,760
what about signatures so so of course

1466
00:58:11,760 --> 00:58:13,440
since you have uh

1467
00:58:13,440 --> 00:58:16,880
crt if you have one-way functions then

1468
00:58:16,880 --> 00:58:18,559
you have standard construction of

1469
00:58:18,559 --> 00:58:19,839
signatures but

1470
00:58:19,839 --> 00:58:23,680
so can you construct uh efficient ones

1471
00:58:23,680 --> 00:58:25,200
like similar to

1472
00:58:25,200 --> 00:58:27,359
uh the the seas-based construction that

1473
00:58:27,359 --> 00:58:29,200
we have for lattices that it's for

1474
00:58:29,200 --> 00:58:31,359
example fiat chamier

1475
00:58:31,359 --> 00:58:33,520
style constructions or

1476
00:58:33,520 --> 00:58:35,280
let's say identification schemes or

1477
00:58:35,280 --> 00:58:37,119
things like this

1478
00:58:37,119 --> 00:58:39,280
um

1479
00:58:39,359 --> 00:58:41,359
yeah like you said it's very good

1480
00:58:41,359 --> 00:58:42,880
question like you said you can do they

1481
00:58:42,880 --> 00:58:45,119
do it from the generic

1482
00:58:45,119 --> 00:58:46,400
directory

1483
00:58:46,400 --> 00:58:48,319
transforms from one way function but if

1484
00:58:48,319 --> 00:58:51,920
we if we want to do like this based

1485
00:58:51,920 --> 00:58:53,520
i don't know which

1486
00:58:53,520 --> 00:58:55,920
we did we made some attempts but it

1487
00:58:55,920 --> 00:58:58,000
doesn't work out like if you want to do

1488
00:58:58,000 --> 00:58:59,250
rejection sampling then

1489
00:58:59,250 --> 00:59:00,880
[Music]

1490
00:59:00,880 --> 00:59:03,280
on the binary field

1491
00:59:03,280 --> 00:59:04,960
it's not possible it's seemingly not

1492
00:59:04,960 --> 00:59:06,799
possible just

1493
00:59:06,799 --> 00:59:07,680
um

1494
00:59:07,680 --> 00:59:09,200
i don't know

1495
00:59:09,200 --> 00:59:11,200
my guess is

1496
00:59:11,200 --> 00:59:13,359
quite negative maybe very nice

1497
00:59:13,359 --> 00:59:15,520
maybe negative negative

1498
00:59:15,520 --> 00:59:17,200
i don't know

1499
00:59:17,200 --> 00:59:18,559
thank you very much

1500
00:59:18,559 --> 00:59:20,000
thank you

1501
00:59:20,000 --> 00:59:22,079
okay good we have one from the chat

1502
00:59:22,079 --> 00:59:23,839
board

1503
00:59:23,839 --> 00:59:24,720
so

1504
00:59:24,720 --> 00:59:27,279
can you see it

1505
00:59:29,040 --> 00:59:31,359
can we

1506
00:59:31,359 --> 00:59:33,520
i i i i don't

1507
00:59:33,520 --> 00:59:35,119
i don't okay

1508
00:59:35,119 --> 00:59:38,880
okay can we interpret the pke from

1509
00:59:38,880 --> 00:59:40,880
code-based assumptions

1510
00:59:40,880 --> 00:59:44,000
and what are the advantages of this pke

1511
00:59:44,000 --> 00:59:45,280
over

1512
00:59:45,280 --> 00:59:48,480
mac dish in questions

1513
00:59:48,480 --> 00:59:50,720
oh

1514
00:59:51,520 --> 00:59:53,760
we don't think we have advantage over

1515
00:59:53,760 --> 00:59:56,480
mac alice because you know

1516
00:59:56,480 --> 00:59:58,960
in this case we just you know it shows

1517
00:59:58,960 --> 01:00:00,960
the feasibility

1518
01:00:00,960 --> 01:00:03,760
but in this case then the security we

1519
01:00:03,760 --> 01:00:05,920
actually like you know

1520
01:00:05,920 --> 01:00:08,720
we we do some trade-off you know we we

1521
01:00:08,720 --> 01:00:10,880
lose we use very

1522
01:00:10,880 --> 01:00:12,240
very

1523
01:00:12,240 --> 01:00:13,839
very strong assumptions like sub

1524
01:00:13,839 --> 01:00:16,400
exponential hardness only to get you

1525
01:00:16,400 --> 01:00:19,040
know quantity polynomial secure pke so

1526
01:00:19,040 --> 01:00:21,040
that will be not practical

1527
01:00:21,040 --> 01:00:23,119
if we want to if we want a more

1528
01:00:23,119 --> 01:00:26,079
practical pke we can go for

1529
01:00:26,079 --> 01:00:28,720
aleknovich's pke

1530
01:00:28,720 --> 01:00:31,440
and then but in that case i don't think

1531
01:00:31,440 --> 01:00:34,160
uh it's just uh i like nov now which is

1532
01:00:34,160 --> 01:00:37,280
pk is still not

1533
01:00:37,280 --> 01:00:39,280
it's not efficient enough to compare

1534
01:00:39,280 --> 01:00:43,240
with uh macales

1535
01:00:44,559 --> 01:00:47,119
theoretical

1536
01:00:47,119 --> 01:00:49,680
okay okay thank you

1537
01:00:49,680 --> 01:00:51,599
yeah i guess we don't know all the time

1538
01:00:51,599 --> 01:00:54,240
allow that we we probably you you you

1539
01:00:54,240 --> 01:00:56,959
allocation of

1540
01:00:58,960 --> 01:01:01,839
okay so we thank you again for uh e for

1541
01:01:01,839 --> 01:01:04,880
the talk and we close this section

1542
01:01:04,880 --> 01:01:08,240
and come back in half hour yeah

1543
01:01:08,240 --> 01:01:11,839
thank you thank you for inviting me

