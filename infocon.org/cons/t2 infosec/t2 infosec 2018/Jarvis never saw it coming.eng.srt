1
00:00:00,940 --> 00:00:04,210
[Music]

2
00:00:07,160 --> 00:00:10,279
[Music]

3
00:00:12,820 --> 00:00:15,919
[Music]

4
00:00:17,189 --> 00:00:23,890
let's begin so welcome to our talk the

5
00:00:21,460 --> 00:00:26,920
title Jarvis never saw it coming where

6
00:00:23,890 --> 00:00:29,470
we will describe our work and stuff that

7
00:00:26,920 --> 00:00:31,240
we've been doing around attacking

8
00:00:29,470 --> 00:00:33,730
machine learning systems a bit of a

9
00:00:31,240 --> 00:00:36,790
background and some data points of what

10
00:00:33,730 --> 00:00:39,640
it looks like in the real world first a

11
00:00:36,790 --> 00:00:42,280
world of disclaimer by our generous

12
00:00:39,640 --> 00:00:45,250
employers who have allowed us to come

13
00:00:42,280 --> 00:00:46,680
here and I will now read it verbatim now

14
00:00:45,250 --> 00:00:51,160
I'm just kidding

15
00:00:46,680 --> 00:00:53,410
okay so first will disclaimers we

16
00:00:51,160 --> 00:00:54,309
haven't harmed any horses you will know

17
00:00:53,410 --> 00:00:56,468
why in a moment

18
00:00:54,309 --> 00:00:58,328
no flamingoes hedgehogs turtles or any

19
00:00:56,469 --> 00:01:01,329
sentient AI models that we know of

20
00:00:58,329 --> 00:01:03,280
during the preparation for this talk a

21
00:01:01,329 --> 00:01:05,619
bit of background about ourselves my

22
00:01:03,280 --> 00:01:07,930
name is guy-guy Barnhart McGann and this

23
00:01:05,619 --> 00:01:11,080
is my colleague Ezra as Puckle tomb and

24
00:01:07,930 --> 00:01:13,240
we are both founding members for besides

25
00:01:11,080 --> 00:01:15,880
Tel Aviv which is a security conference

26
00:01:13,240 --> 00:01:17,470
held each year in sunny Tel Aviv which

27
00:01:15,880 --> 00:01:19,869
you are more than invited to come and

28
00:01:17,470 --> 00:01:24,520
join us as well is also the leader for

29
00:01:19,869 --> 00:01:28,259
the local DC group Def Con group and we

30
00:01:24,520 --> 00:01:31,689
are working on this topic for the past

31
00:01:28,259 --> 00:01:37,420
10 months more or less so it's about

32
00:01:31,689 --> 00:01:39,399
since the last December more or less but

33
00:01:37,420 --> 00:01:42,310
we haven't been working on it alone so I

34
00:01:39,400 --> 00:01:45,009
do want to take a moment and say that

35
00:01:42,310 --> 00:01:46,450
it's not often recognized in many types

36
00:01:45,009 --> 00:01:49,299
the amount of work that you are doing

37
00:01:46,450 --> 00:01:51,579
which is based on other people's work so

38
00:01:49,299 --> 00:01:53,770
I will include a small link at the

39
00:01:51,579 --> 00:01:55,179
bottom part of the slide which you will

40
00:01:53,770 --> 00:01:56,679
probably not be able to read or

41
00:01:55,180 --> 00:01:59,020
photograph but we will release a slide

42
00:01:56,680 --> 00:02:01,689
later with references to everybody that

43
00:01:59,020 --> 00:02:03,939
we have been using their work their

44
00:02:01,689 --> 00:02:06,219
thoughts their abstracts their ideas and

45
00:02:03,939 --> 00:02:08,590
incorporating into the job that we are

46
00:02:06,219 --> 00:02:10,508
doing here but in order to begin I want

47
00:02:08,590 --> 00:02:13,840
to expand for a moment how we actually

48
00:02:10,508 --> 00:02:16,059
got here so last year at Def Con a

49
00:02:13,840 --> 00:02:19,180
couple of friends we sat around one of

50
00:02:16,060 --> 00:02:21,010
the sofas there and we had a very

51
00:02:19,180 --> 00:02:24,010
nice discussion about let's assume that

52
00:02:21,010 --> 00:02:25,450
we can hack machine learning system what

53
00:02:24,010 --> 00:02:26,709
does it actually mean to hack machine

54
00:02:25,450 --> 00:02:28,929
Linux says what would you actually

55
00:02:26,709 --> 00:02:30,879
target so we all know that machine

56
00:02:28,930 --> 00:02:33,370
learning systems are software running

57
00:02:30,879 --> 00:02:36,790
and doing stuff but what does the

58
00:02:33,370 --> 00:02:38,739
hacking machine learning means and that

59
00:02:36,790 --> 00:02:40,179
brought a lot of different ideas of how

60
00:02:38,739 --> 00:02:41,799
you would actually approach such a

61
00:02:40,180 --> 00:02:44,260
problem what your motivations are going

62
00:02:41,799 --> 00:02:46,780
to be what your objectives are going to

63
00:02:44,260 --> 00:02:50,920
be and we are going to discuss this here

64
00:02:46,780 --> 00:02:52,900
today so we are going to talk about what

65
00:02:50,920 --> 00:02:56,138
machine learning is and what you would

66
00:02:52,900 --> 00:02:58,389
do about it we are going to direct your

67
00:02:56,139 --> 00:03:00,060
attention gracefully using colors into

68
00:02:58,389 --> 00:03:02,230
what you should really pay attention to

69
00:03:00,060 --> 00:03:04,239
but we are not going to release like

70
00:03:02,230 --> 00:03:06,280
zero days or anything similar to that

71
00:03:04,239 --> 00:03:07,840
because I don't think that this is an

72
00:03:06,280 --> 00:03:09,609
important part of the talk the important

73
00:03:07,840 --> 00:03:11,349
part of the talk is the methodology and

74
00:03:09,609 --> 00:03:13,090
the way that we approach the problem

75
00:03:11,349 --> 00:03:14,560
which we hope we can impart some

76
00:03:13,090 --> 00:03:17,560
knowledge to you to do the same thing

77
00:03:14,560 --> 00:03:19,060
wherever you want to do them so in order

78
00:03:17,560 --> 00:03:21,129
to start I want to start with a story

79
00:03:19,060 --> 00:03:22,329
about a horse so this is a very nice

80
00:03:21,129 --> 00:03:24,220
horse which you can see in the picture

81
00:03:22,329 --> 00:03:26,949
here his name is hunts or he used to be

82
00:03:24,220 --> 00:03:29,949
clever hunts and clever Hans was a horse

83
00:03:26,949 --> 00:03:32,379
around 1903 1905 and he used to tour

84
00:03:29,949 --> 00:03:34,780
Austria in Germany because he could do

85
00:03:32,379 --> 00:03:36,459
really clever tricks for example if

86
00:03:34,780 --> 00:03:38,979
you'd ask him simple arithmetic

87
00:03:36,459 --> 00:03:40,599
questions how much is two plus three he

88
00:03:38,979 --> 00:03:42,909
would have his hoof one two three four

89
00:03:40,599 --> 00:03:45,220
five and give you the answer so that's

90
00:03:42,909 --> 00:03:47,439
pretty good but he also could spell in

91
00:03:45,220 --> 00:03:51,489
German which is amazing for anyone not

92
00:03:47,439 --> 00:03:54,720
just for a horse and that actually was

93
00:03:51,489 --> 00:03:57,159
pretty phenomenal at the time and then a

94
00:03:54,720 --> 00:03:59,530
psychologist was assigned to try to

95
00:03:57,159 --> 00:04:02,078
understand how come that this horse is

96
00:03:59,530 --> 00:04:03,759
so clever and he he went and he did

97
00:04:02,079 --> 00:04:06,099
tests and he developed a methodology

98
00:04:03,759 --> 00:04:07,958
which we now know is called double-blind

99
00:04:06,099 --> 00:04:10,119
testing and what he found out that the

100
00:04:07,959 --> 00:04:11,799
horse was actually very clever it was

101
00:04:10,120 --> 00:04:13,959
very clever in the sense that it could

102
00:04:11,799 --> 00:04:15,189
read off cues from his handlers the body

103
00:04:13,959 --> 00:04:17,470
language this is the handler here in the

104
00:04:15,189 --> 00:04:19,180
middle with a hat so whenever he would

105
00:04:17,470 --> 00:04:20,590
ask him how much is two plus three he

106
00:04:19,180 --> 00:04:23,159
would tap his hoof and it would read the

107
00:04:20,589 --> 00:04:25,810
body cue to stop when he reached five so

108
00:04:23,159 --> 00:04:27,969
in a sense he was a very clever horse

109
00:04:25,810 --> 00:04:29,770
the reason I'm telling you this story is

110
00:04:27,969 --> 00:04:31,810
because when we are thinking about

111
00:04:29,770 --> 00:04:32,919
machine learning systems we are in a

112
00:04:31,810 --> 00:04:35,620
very much the similar

113
00:04:32,919 --> 00:04:37,979
position we are very good at building

114
00:04:35,620 --> 00:04:42,279
machine learning systems when we have

115
00:04:37,979 --> 00:04:43,659
well one moment building machine

116
00:04:42,279 --> 00:04:46,240
learning systems when we have a very

117
00:04:43,659 --> 00:04:49,180
well specific defined problem whenever

118
00:04:46,240 --> 00:04:51,310
we try to move into a broader scheme or

119
00:04:49,180 --> 00:04:53,710
a more generalized problem everything

120
00:04:51,310 --> 00:04:55,330
breaks and usually it breaks horribly we

121
00:04:53,710 --> 00:04:58,650
are going to discuss a couple of those

122
00:04:55,330 --> 00:05:02,050
horrible failures during the talk today

123
00:04:58,650 --> 00:05:03,998
first some background common language

124
00:05:02,050 --> 00:05:06,069
when I'm saying machine learning what I

125
00:05:03,999 --> 00:05:08,650
mean by that is that we have a system

126
00:05:06,069 --> 00:05:10,569
that gets some inputs usually inputs and

127
00:05:08,650 --> 00:05:12,489
some metadata attached to that inputs

128
00:05:10,569 --> 00:05:14,770
there is a system that encodes that

129
00:05:12,490 --> 00:05:16,300
information and provide some outputs so

130
00:05:14,770 --> 00:05:17,740
this is classical machine learning

131
00:05:16,300 --> 00:05:19,750
they're very a lot of different

132
00:05:17,740 --> 00:05:22,120
algorithms to implement these kind of

133
00:05:19,750 --> 00:05:23,770
systems but the bottom line is that you

134
00:05:22,120 --> 00:05:26,319
have inputs and metadata you have

135
00:05:23,770 --> 00:05:28,508
outputs deep learning which is a very

136
00:05:26,319 --> 00:05:30,339
nice buzzword usually is about the same

137
00:05:28,509 --> 00:05:32,830
thing but with much less metadata

138
00:05:30,339 --> 00:05:34,389
usually even without any metadata so we

139
00:05:32,830 --> 00:05:35,949
have a lot of inputs and you have an

140
00:05:34,389 --> 00:05:37,389
algorithm that will self train the

141
00:05:35,949 --> 00:05:39,699
system to produce the outputs that you

142
00:05:37,389 --> 00:05:41,680
are looking for both machine learning

143
00:05:39,699 --> 00:05:43,629
and deep learning are not artificial

144
00:05:41,680 --> 00:05:45,339
intelligence when we are saying

145
00:05:43,629 --> 00:05:46,990
artificial intelligence we are thinking

146
00:05:45,339 --> 00:05:49,539
of something like I don't know the

147
00:05:46,990 --> 00:05:51,669
Terminator something that can reason

148
00:05:49,539 --> 00:05:54,580
that can have context that can have some

149
00:05:51,669 --> 00:05:56,859
understanding of the world we are years

150
00:05:54,580 --> 00:05:58,210
10 years away from having a machine

151
00:05:56,860 --> 00:06:00,879
learning system that can actually

152
00:05:58,210 --> 00:06:03,068
encompass this and I would like to

153
00:06:00,879 --> 00:06:04,779
apologize everybody mixes the two

154
00:06:03,069 --> 00:06:06,879
concepts together whenever you hear

155
00:06:04,779 --> 00:06:09,250
anyone says AI he actually means

156
00:06:06,879 --> 00:06:11,469
machinery and I make the same mistake if

157
00:06:09,250 --> 00:06:14,969
you hear me I meant machine learning

158
00:06:11,469 --> 00:06:14,969
always there is no such thing as AI

159
00:06:15,319 --> 00:06:22,009
so intelligence systems are designed to

160
00:06:17,930 --> 00:06:23,509
solve very specific problems what kind

161
00:06:22,009 --> 00:06:26,599
of trouble problems and how do you

162
00:06:23,509 --> 00:06:30,409
actually approach those problems so when

163
00:06:26,599 --> 00:06:32,710
I originally developed this part of the

164
00:06:30,409 --> 00:06:35,240
talk I went through a very mathematical

165
00:06:32,710 --> 00:06:36,919
rigorous approach to try to impart the

166
00:06:35,240 --> 00:06:38,719
audience of how does that actually work

167
00:06:36,919 --> 00:06:41,270
I want to try something a bit different

168
00:06:38,719 --> 00:06:43,159
right now I want to give you a mental

169
00:06:41,270 --> 00:06:45,229
model of what a machine learning system

170
00:06:43,159 --> 00:06:47,119
is it would be a bit hand wavy it won't

171
00:06:45,229 --> 00:06:48,740
be very accurate but I think it would be

172
00:06:47,119 --> 00:06:50,209
very useful to understand the kind of

173
00:06:48,740 --> 00:06:52,610
attacks and concept that we're going to

174
00:06:50,209 --> 00:06:54,499
discuss here today so when you're

175
00:06:52,610 --> 00:06:55,909
thinking about machine learning models

176
00:06:54,499 --> 00:06:58,249
think about it as a sort of

177
00:06:55,909 --> 00:07:00,199
representation of information there are

178
00:06:58,249 --> 00:07:03,050
different pathways to traverse to that

179
00:07:00,199 --> 00:07:04,449
informational model and the inputs and

180
00:07:03,050 --> 00:07:06,289
the outputs that you provide the system

181
00:07:04,449 --> 00:07:08,479
determine the way that these pathways

182
00:07:06,289 --> 00:07:10,159
are constructed so if you're starting

183
00:07:08,479 --> 00:07:12,438
with a clean slate with a brain that has

184
00:07:10,159 --> 00:07:14,180
no memory nothing at all and we are

185
00:07:12,439 --> 00:07:16,099
presenting it with an image of a dog he

186
00:07:14,180 --> 00:07:17,330
has no idea what the dog is so we

187
00:07:16,099 --> 00:07:19,490
presenting with an image of a dog and

188
00:07:17,330 --> 00:07:22,330
then we tell it this is a dog and we do

189
00:07:19,490 --> 00:07:24,889
this once twice 10,000 times eventually

190
00:07:22,330 --> 00:07:27,019
most people will get the concept that

191
00:07:24,889 --> 00:07:28,999
these images relate to this labeled

192
00:07:27,019 --> 00:07:31,309
called the dog machine learning system

193
00:07:28,999 --> 00:07:33,139
do the same thing we give them inputs

194
00:07:31,309 --> 00:07:34,610
and provide some native data so we give

195
00:07:33,139 --> 00:07:36,319
them an image of a dog in a label of a

196
00:07:34,610 --> 00:07:38,659
doll and we measure their performance

197
00:07:36,319 --> 00:07:40,669
how accurately were they able to predict

198
00:07:38,659 --> 00:07:43,430
that a certain input matches a certain

199
00:07:40,669 --> 00:07:46,549
level so this is the basics of machine

200
00:07:43,430 --> 00:07:48,559
learning models from a practical

201
00:07:46,550 --> 00:07:51,249
perspective machine learning models are

202
00:07:48,559 --> 00:07:54,199
graphs in one way to look at it or

203
00:07:51,249 --> 00:07:56,209
connected neuron layers for a different

204
00:07:54,199 --> 00:07:58,249
example to look at it but the basic

205
00:07:56,209 --> 00:08:00,559
tenants still hold it's a structure

206
00:07:58,249 --> 00:08:02,930
usually matrix that holds a lot of

207
00:08:00,559 --> 00:08:05,119
values and those values in code pieces

208
00:08:02,930 --> 00:08:07,759
of information that we trained that

209
00:08:05,119 --> 00:08:11,300
machine learning software to recognize

210
00:08:07,759 --> 00:08:13,339
and understand so some immediate caveats

211
00:08:11,300 --> 00:08:15,050
that come from this definition are if we

212
00:08:13,339 --> 00:08:17,029
don't train it to don't know something

213
00:08:15,050 --> 00:08:19,430
it won't know it it has no way to

214
00:08:17,029 --> 00:08:22,459
generalize to into inputs that it has

215
00:08:19,430 --> 00:08:24,409
never seen before and this is a very big

216
00:08:22,459 --> 00:08:26,120
fallacy in the way that we're thinking

217
00:08:24,409 --> 00:08:29,270
about machine learning system examples

218
00:08:26,120 --> 00:08:31,130
especially in infoset so if I have

219
00:08:29,270 --> 00:08:34,549
a very cutting-edge malware detection

220
00:08:31,130 --> 00:08:36,470
system that is promising to detect

221
00:08:34,549 --> 00:08:39,079
zero-days and see everything that cells

222
00:08:36,470 --> 00:08:40,910
never seen before remember machine

223
00:08:39,080 --> 00:08:44,000
learning systems are built by training

224
00:08:40,909 --> 00:08:45,560
them on example seen in the past you can

225
00:08:44,000 --> 00:08:47,480
train them on examples are going to be

226
00:08:45,560 --> 00:08:51,170
in the future doesn't work like that

227
00:08:47,480 --> 00:08:52,910
well not yet the other thing is is that

228
00:08:51,170 --> 00:08:56,270
the way that those models are

229
00:08:52,910 --> 00:08:59,329
constructed are very different from a

230
00:08:56,270 --> 00:09:01,250
piece of software I'm going to delve

231
00:08:59,330 --> 00:09:04,850
into this a bit more deeply in a moment

232
00:09:01,250 --> 00:09:06,700
but the basic structure for those

233
00:09:04,850 --> 00:09:09,680
systems are that you have some sort of

234
00:09:06,700 --> 00:09:12,290
topology or network layout of how this

235
00:09:09,680 --> 00:09:14,449
model represents information you have

236
00:09:12,290 --> 00:09:16,910
the actual encoding of that information

237
00:09:14,450 --> 00:09:18,770
into the matrix values or weights or

238
00:09:16,910 --> 00:09:21,020
parameters and you have transfer

239
00:09:18,770 --> 00:09:23,420
functions that actually move data along

240
00:09:21,020 --> 00:09:26,090
a path so if you have an input it moves

241
00:09:23,420 --> 00:09:27,530
into this layer of the matrix into that

242
00:09:26,090 --> 00:09:31,160
layer of the matrix again and again and

243
00:09:27,530 --> 00:09:33,500
again until you have a prediction in the

244
00:09:31,160 --> 00:09:36,100
end this is a matrix and we all know

245
00:09:33,500 --> 00:09:38,480
matrices and we also know that matrix

246
00:09:36,100 --> 00:09:39,710
computation is just math and it's not a

247
00:09:38,480 --> 00:09:41,510
very complex that might be

248
00:09:39,710 --> 00:09:44,690
computationally intensive but it's not

249
00:09:41,510 --> 00:09:46,160
very complex piece of math so whenever

250
00:09:44,690 --> 00:09:48,050
we are talking about matrices or

251
00:09:46,160 --> 00:09:50,420
operation on matrices we're actually

252
00:09:48,050 --> 00:09:52,339
talking about getting matrices and

253
00:09:50,420 --> 00:09:54,949
inputs producing matrices that outputs

254
00:09:52,340 --> 00:09:59,150
so multiplying columns and rows gives

255
00:09:54,950 --> 00:10:02,030
you new matrices a single dimension is

256
00:09:59,150 --> 00:10:05,240
just an array a two-dimensional matrix

257
00:10:02,030 --> 00:10:07,760
is just an array so usually when

258
00:10:05,240 --> 00:10:09,650
mathematicians or the data scientists

259
00:10:07,760 --> 00:10:10,850
discuss these ideas this is the way that

260
00:10:09,650 --> 00:10:12,350
they're thinking about this world these

261
00:10:10,850 --> 00:10:15,110
are all matrices and there's matrix

262
00:10:12,350 --> 00:10:18,320
sensation and linear algebraic algorithm

263
00:10:15,110 --> 00:10:20,030
to solve these things but for us this is

264
00:10:18,320 --> 00:10:23,450
our point of view so when we're looking

265
00:10:20,030 --> 00:10:25,280
at this everything are just arrays in

266
00:10:23,450 --> 00:10:27,350
memory just buffers in memory it doesn't

267
00:10:25,280 --> 00:10:29,329
matter if it's a one-dimensional matrix

268
00:10:27,350 --> 00:10:31,190
or two-dimensional matrix because if

269
00:10:29,330 --> 00:10:32,720
you're just there to steal the matrix it

270
00:10:31,190 --> 00:10:35,300
doesn't care what kind of encoding

271
00:10:32,720 --> 00:10:37,400
you've used to represent it and this is

272
00:10:35,300 --> 00:10:39,800
something that is often forgotten by

273
00:10:37,400 --> 00:10:42,630
people deploying those systems where

274
00:10:39,800 --> 00:10:44,519
they are so much focused on

275
00:10:42,630 --> 00:10:46,439
did they represent it in the most

276
00:10:44,519 --> 00:10:48,660
efficient way possible that they're not

277
00:10:46,440 --> 00:10:50,790
thinking of well who has access to that

278
00:10:48,660 --> 00:10:53,509
information are I actually leaking that

279
00:10:50,790 --> 00:10:53,509
information out

280
00:10:53,970 --> 00:10:58,529
I'm trying to give you a good sense of

281
00:10:56,249 --> 00:11:00,269
what machine learning systems are doing

282
00:10:58,529 --> 00:11:02,489
and I really want to take away much of

283
00:11:00,269 --> 00:11:04,470
the Voodoo as possible these are not

284
00:11:02,489 --> 00:11:06,209
magical systems it are not magical black

285
00:11:04,470 --> 00:11:09,479
boxes in the end is just a piece of

286
00:11:06,209 --> 00:11:11,909
technology that works in some cases

287
00:11:09,479 --> 00:11:13,409
doesn't work in other cases but it's

288
00:11:11,909 --> 00:11:16,019
anything anything and everything that

289
00:11:13,409 --> 00:11:17,549
each and every one of you can learn that

290
00:11:16,019 --> 00:11:19,470
there's nothing here that data

291
00:11:17,549 --> 00:11:22,919
scientists are doing that any of us

292
00:11:19,470 --> 00:11:25,049
cannot do so attacking the machinery

293
00:11:22,919 --> 00:11:26,279
system requires you to have some pieces

294
00:11:25,049 --> 00:11:28,319
of knowledge that you might be lacking

295
00:11:26,279 --> 00:11:30,179
at the moment but you can fill up the

296
00:11:28,319 --> 00:11:33,209
gaps and do this next week there's

297
00:11:30,179 --> 00:11:36,478
nothing magical about it and I want to

298
00:11:33,209 --> 00:11:39,329
describe what the process is so

299
00:11:36,479 --> 00:11:40,499
generally speaking whatever your inputs

300
00:11:39,329 --> 00:11:43,108
are it doesn't matter if you have images

301
00:11:40,499 --> 00:11:44,970
audios or text or binaries in the end

302
00:11:43,109 --> 00:11:46,470
you have inputs but when you're trying

303
00:11:44,970 --> 00:11:48,899
to fill them into an algorithm that is

304
00:11:46,470 --> 00:11:50,789
based on matrix multiplications you

305
00:11:48,899 --> 00:11:52,259
can't really take an image and multiply

306
00:11:50,789 --> 00:11:53,909
it by a matrix or a binary and

307
00:11:52,259 --> 00:11:56,519
multiplied by matrix so you need

308
00:11:53,909 --> 00:11:59,669
intermediate representation so there is

309
00:11:56,519 --> 00:12:01,829
a step in this process a pre-processing

310
00:11:59,669 --> 00:12:05,939
step and that needs to translate those

311
00:12:01,829 --> 00:12:07,679
inputs into something that the matrix

312
00:12:05,939 --> 00:12:11,179
multiplication algorithms can actually

313
00:12:07,679 --> 00:12:15,329
chew on they can actually ingest but

314
00:12:11,179 --> 00:12:18,539
that part intermediate representation

315
00:12:15,329 --> 00:12:20,488
that part of the process loses a lot of

316
00:12:18,539 --> 00:12:22,229
information and introduces a lot of

317
00:12:20,489 --> 00:12:24,659
attack surface and we will explore that

318
00:12:22,229 --> 00:12:25,919
in a moment the matrix multiplication

319
00:12:24,659 --> 00:12:27,389
there are many different algorithm which

320
00:12:25,919 --> 00:12:28,949
I'm not going to cover at all if

321
00:12:27,389 --> 00:12:30,899
somebody wants to know talk to me later

322
00:12:28,949 --> 00:12:33,539
it's not very interesting but the

323
00:12:30,899 --> 00:12:35,159
outputs are interesting because in the

324
00:12:33,539 --> 00:12:37,889
end when you do matrix multiplication

325
00:12:35,159 --> 00:12:40,379
you get a new matrix something some

326
00:12:37,889 --> 00:12:42,059
someone has to interpret those results

327
00:12:40,379 --> 00:12:45,749
and bring them back into real-world

328
00:12:42,059 --> 00:12:47,728
human understandable results so we have

329
00:12:45,749 --> 00:12:49,619
another stage where we aggregate the

330
00:12:47,729 --> 00:12:51,689
outputs and then we have to map them

331
00:12:49,619 --> 00:12:53,849
back into a real-world application and

332
00:12:51,689 --> 00:12:56,368
usually what this looks like is that we

333
00:12:53,849 --> 00:13:00,809
have result at index 7 mapped into

334
00:12:56,369 --> 00:13:03,559
string which says account ok in the end

335
00:13:00,809 --> 00:13:07,108
we provide predictions which are usually

336
00:13:03,559 --> 00:13:07,740
classifications or confidence levels

337
00:13:07,109 --> 00:13:10,950
probability

338
00:13:07,740 --> 00:13:14,580
this is a cat in point seven six percent

339
00:13:10,950 --> 00:13:17,460
confidence so those systems just chew on

340
00:13:14,580 --> 00:13:20,029
inputs on one end and spew out results

341
00:13:17,460 --> 00:13:22,160
or confidence levels at the other end

342
00:13:20,029 --> 00:13:24,540
generally speaking there are two

343
00:13:22,160 --> 00:13:27,060
different distinct systems the first one

344
00:13:24,540 --> 00:13:29,579
is used to train the model which is just

345
00:13:27,060 --> 00:13:32,430
taking an input going through those

346
00:13:29,580 --> 00:13:35,399
phases measuring the result was the

347
00:13:32,430 --> 00:13:37,170
result good or not if it was good take a

348
00:13:35,399 --> 00:13:37,860
take another step in that direction if

349
00:13:37,170 --> 00:13:39,959
it was bad

350
00:13:37,860 --> 00:13:41,970
adjust your direction and try take

351
00:13:39,959 --> 00:13:44,130
another input and you do this again and

352
00:13:41,970 --> 00:13:45,959
again and again and again let's say you

353
00:13:44,130 --> 00:13:47,760
have a hundred thousand data points in

354
00:13:45,959 --> 00:13:50,579
your data set and you want to do this 50

355
00:13:47,760 --> 00:13:54,060
50 to 100 times on the entire data set

356
00:13:50,580 --> 00:13:56,850
so 500,000 to 1 million times over each

357
00:13:54,060 --> 00:13:58,770
data point that you have over all of the

358
00:13:56,850 --> 00:14:01,350
data points that you have but in the end

359
00:13:58,770 --> 00:14:02,939
you have a model that model is just a

360
00:14:01,350 --> 00:14:04,529
matrix so you take that matrix and you

361
00:14:02,940 --> 00:14:08,220
deploy it in the real world you plug an

362
00:14:04,529 --> 00:14:10,350
API to it and now you have an object

363
00:14:08,220 --> 00:14:12,240
classification cloud machine learning

364
00:14:10,350 --> 00:14:13,950
service you put an image and it tells

365
00:14:12,240 --> 00:14:16,500
you there's the house and there's a girl

366
00:14:13,950 --> 00:14:19,440
in this image in the end is just a model

367
00:14:16,500 --> 00:14:23,070
in the real world but models are not

368
00:14:19,440 --> 00:14:24,600
code and what do I mean by that when I'm

369
00:14:23,070 --> 00:14:26,310
saying that models are not code is

370
00:14:24,600 --> 00:14:28,410
because the way that we are used to look

371
00:14:26,310 --> 00:14:31,020
at this world is very different when we

372
00:14:28,410 --> 00:14:32,850
want to test or measure or understand

373
00:14:31,020 --> 00:14:34,770
what a piece of code does we have

374
00:14:32,850 --> 00:14:37,140
reverse engineering tools at our hands

375
00:14:34,770 --> 00:14:40,589
we have source code at our hands we have

376
00:14:37,140 --> 00:14:41,970
various degrees of tooling and the

377
00:14:40,589 --> 00:14:44,040
ability to write new toolings to

378
00:14:41,970 --> 00:14:46,230
understand what this is machine learning

379
00:14:44,040 --> 00:14:48,050
models behave differently there are just

380
00:14:46,230 --> 00:14:49,980
and matrix and they're multiplying

381
00:14:48,050 --> 00:14:52,050
representation of the input to get an

382
00:14:49,980 --> 00:14:54,089
output there is no code to reverse

383
00:14:52,050 --> 00:14:55,949
engineer here all of the algorithms are

384
00:14:54,089 --> 00:14:58,170
open there's nothing secret or

385
00:14:55,950 --> 00:15:01,529
interesting in how you multiply two

386
00:14:58,170 --> 00:15:03,959
matrices together more than that the way

387
00:15:01,529 --> 00:15:05,730
that data is represented means a lot to

388
00:15:03,959 --> 00:15:08,010
us when we are looking at code so if you

389
00:15:05,730 --> 00:15:10,079
look at data structure in memories where

390
00:15:08,010 --> 00:15:11,970
how its hold which register does what

391
00:15:10,079 --> 00:15:14,189
it's very interesting and gives us a lot

392
00:15:11,970 --> 00:15:15,959
of information but the intermediate

393
00:15:14,190 --> 00:15:17,760
representation for model doesn't hold

394
00:15:15,959 --> 00:15:20,189
that information just a way to encode

395
00:15:17,760 --> 00:15:21,560
the same thing for example if I want to

396
00:15:20,190 --> 00:15:23,090
encode a sentence

397
00:15:21,560 --> 00:15:24,619
the time talking about into something

398
00:15:23,090 --> 00:15:27,170
that the machine learning model can use

399
00:15:24,620 --> 00:15:30,020
and hint a take a sentence like hello

400
00:15:27,170 --> 00:15:33,110
world and turn it into a vector that has

401
00:15:30,020 --> 00:15:35,930
like the 2000 most common words and I

402
00:15:33,110 --> 00:15:38,900
set two bits to one for the world hello

403
00:15:35,930 --> 00:15:40,459
and for the world world it's not a very

404
00:15:38,900 --> 00:15:42,470
interesting data structure it doesn't

405
00:15:40,460 --> 00:15:44,390
convey us with a lot of information

406
00:15:42,470 --> 00:15:46,700
about what the designer of the system

407
00:15:44,390 --> 00:15:50,089
did what his intentions were is just

408
00:15:46,700 --> 00:15:52,130
another way to represent data the bottom

409
00:15:50,089 --> 00:15:54,170
line is we can't really do code review

410
00:15:52,130 --> 00:15:57,500
for matrices we have no way to reverse

411
00:15:54,170 --> 00:16:00,680
engineer given a matrix what caused that

412
00:15:57,500 --> 00:16:02,270
matrix to exist we in it's an open

413
00:16:00,680 --> 00:16:05,479
problem in academia how do you actually

414
00:16:02,270 --> 00:16:07,250
reverse engineer a model but I do want

415
00:16:05,480 --> 00:16:09,529
to give you some sort some sense of what

416
00:16:07,250 --> 00:16:11,779
this actually is so this is just a

417
00:16:09,529 --> 00:16:14,930
binary dump you can see here the name of

418
00:16:11,779 --> 00:16:16,850
the model ResNet 50 in the end this is

419
00:16:14,930 --> 00:16:20,120
just data dumps in memory there's blocks

420
00:16:16,850 --> 00:16:22,610
of data that you can relate to have

421
00:16:20,120 --> 00:16:25,270
access to copy exfiltrate do whatever

422
00:16:22,610 --> 00:16:25,270
you want for them

423
00:16:25,480 --> 00:16:28,570
a couple of notions that I want you to

424
00:16:26,920 --> 00:16:30,579
keep in mind about machine learning

425
00:16:28,570 --> 00:16:33,100
models and this will be the end of the

426
00:16:30,579 --> 00:16:34,779
theoretical stuff machine learning

427
00:16:33,100 --> 00:16:37,000
models are built and designed to

428
00:16:34,779 --> 00:16:39,699
optimize for the stronger signal that

429
00:16:37,000 --> 00:16:41,860
they are looking for in the data so if

430
00:16:39,699 --> 00:16:43,180
they have in the mental model that I

431
00:16:41,860 --> 00:16:45,190
mentioned earlier that pathway is

432
00:16:43,180 --> 00:16:47,229
walking going through the system a

433
00:16:45,190 --> 00:16:49,959
couple of those pathways will be much

434
00:16:47,230 --> 00:16:51,550
stronger meaning a lot more inputs will

435
00:16:49,959 --> 00:16:54,729
achieve those pathways than others

436
00:16:51,550 --> 00:16:56,290
meaning that if you have an object

437
00:16:54,730 --> 00:16:59,350
classification system that knows how to

438
00:16:56,290 --> 00:17:01,360
classify ten different models then five

439
00:16:59,350 --> 00:17:03,220
of those will have very strong pathways

440
00:17:01,360 --> 00:17:05,260
which will attract a lot more inputs and

441
00:17:03,220 --> 00:17:07,510
three or four of them would be very rare

442
00:17:05,260 --> 00:17:09,540
and very difficult to achieve so it's

443
00:17:07,510 --> 00:17:12,910
not like they're uniformly distributed

444
00:17:09,540 --> 00:17:15,040
the machines are biased just to fix it

445
00:17:12,910 --> 00:17:17,140
to lock onto the strongest signal and we

446
00:17:15,040 --> 00:17:19,569
can take advantage of that the other

447
00:17:17,140 --> 00:17:21,880
thing is that we are looking at stuff

448
00:17:19,569 --> 00:17:23,589
that is usually huge when we are looking

449
00:17:21,880 --> 00:17:25,720
at binary analysis we might have

450
00:17:23,589 --> 00:17:28,030
megabytes of data tens of megabytes of

451
00:17:25,720 --> 00:17:29,679
data analyzing a system that has a

452
00:17:28,030 --> 00:17:32,559
hundred megabytes of data is already a

453
00:17:29,679 --> 00:17:34,450
big problem models can reach gigabytes

454
00:17:32,559 --> 00:17:36,940
of data in size five to ten gigabytes

455
00:17:34,450 --> 00:17:40,270
for deep learning models so it's a huge

456
00:17:36,940 --> 00:17:42,340
thing to try to analyze and the last

457
00:17:40,270 --> 00:17:44,168
point that I want to convey is that bias

458
00:17:42,340 --> 00:17:46,750
is an integral part of the system and

459
00:17:44,169 --> 00:17:48,970
usually what bias means here is very

460
00:17:46,750 --> 00:17:51,580
difficult to explain but I'll give you

461
00:17:48,970 --> 00:17:54,549
an example to get the gist of it so

462
00:17:51,580 --> 00:17:56,260
there was a very interesting study being

463
00:17:54,549 --> 00:17:59,500
conducted I think it was in John Hopkins

464
00:17:56,260 --> 00:18:01,000
in the United States and they tried to

465
00:17:59,500 --> 00:18:03,910
build a classification system to

466
00:18:01,000 --> 00:18:06,580
determine if patients have cancer based

467
00:18:03,910 --> 00:18:08,980
on their data data from their blood

468
00:18:06,580 --> 00:18:10,270
samples so they built a database with

469
00:18:08,980 --> 00:18:11,679
all of those blood samples with all

470
00:18:10,270 --> 00:18:12,970
those different peoples and they

471
00:18:11,679 --> 00:18:14,530
analyzed the data and they built a very

472
00:18:12,970 --> 00:18:16,600
good machine learning system very high

473
00:18:14,530 --> 00:18:18,070
accuracy and they tried to deploy it in

474
00:18:16,600 --> 00:18:20,080
the real world and to run it on some

475
00:18:18,070 --> 00:18:22,149
test data and it blew horribly in the

476
00:18:20,080 --> 00:18:24,909
faces and the reason for that was

477
00:18:22,150 --> 00:18:26,320
actually because of bias and when they

478
00:18:24,910 --> 00:18:29,740
investigated they found out that the

479
00:18:26,320 --> 00:18:32,168
system would very accurately predict if

480
00:18:29,740 --> 00:18:34,540
someone has cancer based on the name of

481
00:18:32,169 --> 00:18:35,770
the hospital that they took the sample

482
00:18:34,540 --> 00:18:38,570
from

483
00:18:35,770 --> 00:18:41,870
because if you took a sample from Mount

484
00:18:38,570 --> 00:18:45,439
Sinai center for cancer research you

485
00:18:41,870 --> 00:18:48,080
might have cancer so data scientists

486
00:18:45,440 --> 00:18:48,950
often make these mistakes not because

487
00:18:48,080 --> 00:18:50,149
they're bad not because they're

488
00:18:48,950 --> 00:18:52,430
malicious is because they are

489
00:18:50,150 --> 00:18:55,490
introducing bias into the system there's

490
00:18:52,430 --> 00:18:57,320
a famous I think it was maybe eight ten

491
00:18:55,490 --> 00:18:59,210
years ago the Kodak cameras with a face

492
00:18:57,320 --> 00:19:01,189
recognition if you remember the yellow

493
00:18:59,210 --> 00:19:04,580
triangles on smaller who could not

494
00:19:01,190 --> 00:19:06,380
detect African descent people or Chinese

495
00:19:04,580 --> 00:19:08,110
people because obviously there have no

496
00:19:06,380 --> 00:19:10,670
faces and he cannot recognize them

497
00:19:08,110 --> 00:19:12,860
because the training set was just white

498
00:19:10,670 --> 00:19:14,480
Caucasian Americans so the system was

499
00:19:12,860 --> 00:19:16,100
built to detect white Caucasian

500
00:19:14,480 --> 00:19:19,490
Americans he could not detect anything

501
00:19:16,100 --> 00:19:24,230
else so this is very common for

502
00:19:19,490 --> 00:19:26,300
machinery so mentioning the threat model

503
00:19:24,230 --> 00:19:28,910
that we discussed earlier I want to

504
00:19:26,300 --> 00:19:31,520
mention a couple of attack vectors that

505
00:19:28,910 --> 00:19:33,800
we are going to discuss now from our

506
00:19:31,520 --> 00:19:36,080
analysis we are only going to discuss

507
00:19:33,800 --> 00:19:37,760
the one highlighted in red but there are

508
00:19:36,080 --> 00:19:39,740
more and more interesting stuff that you

509
00:19:37,760 --> 00:19:42,980
can do we encourage you to talk to us

510
00:19:39,740 --> 00:19:46,010
later the way that we approach this is

511
00:19:42,980 --> 00:19:49,160
that we took our top five attacks and we

512
00:19:46,010 --> 00:19:51,110
assigned CBS s scores to each and then

513
00:19:49,160 --> 00:19:53,240
we had a lot of conversations with

514
00:19:51,110 --> 00:19:55,729
different customers and partners in the

515
00:19:53,240 --> 00:19:57,140
that actually deploying machine learning

516
00:19:55,730 --> 00:20:00,140
system or want to deploy machine memory

517
00:19:57,140 --> 00:20:02,180
systems and we asked them well from a

518
00:20:00,140 --> 00:20:04,520
business perspective what do you care

519
00:20:02,180 --> 00:20:06,500
about most which attack actually scares

520
00:20:04,520 --> 00:20:08,840
you what do you feel machine learning

521
00:20:06,500 --> 00:20:10,460
security should look like and we thought

522
00:20:08,840 --> 00:20:11,870
these are they like the most important

523
00:20:10,460 --> 00:20:14,870
things that we should tackle first and

524
00:20:11,870 --> 00:20:18,050
we were wrong we were very wrong so from

525
00:20:14,870 --> 00:20:20,239
a business perspective 95 percent of

526
00:20:18,050 --> 00:20:23,270
people we talked about cared about IP

527
00:20:20,240 --> 00:20:25,760
theft about 5% more cared about model

528
00:20:23,270 --> 00:20:28,000
tampering and absolutely no one cared

529
00:20:25,760 --> 00:20:29,870
about denial of service backdoors

530
00:20:28,000 --> 00:20:31,760
misprediction and any other thing that

531
00:20:29,870 --> 00:20:33,739
we had on the list previously they

532
00:20:31,760 --> 00:20:36,020
honestly didn't care because from their

533
00:20:33,740 --> 00:20:37,730
perspective if somebody steals their IP

534
00:20:36,020 --> 00:20:39,830
that they invested so much money to

535
00:20:37,730 --> 00:20:41,720
develop Soma so much time to acquire

536
00:20:39,830 --> 00:20:43,250
data sellers with those data scientists

537
00:20:41,720 --> 00:20:45,470
which doesn't come cheap to develop

538
00:20:43,250 --> 00:20:47,420
those models somebody's stealing that IP

539
00:20:45,470 --> 00:20:48,890
is much more important than somebody

540
00:20:47,420 --> 00:20:51,610
doing denial of service on their

541
00:20:48,890 --> 00:20:56,050
API denial of service are very solvable

542
00:20:51,610 --> 00:20:56,050
somebody's stealing the IP is not

543
00:20:56,620 --> 00:21:02,529
so if you want to build an attack taking

544
00:21:00,309 --> 00:21:04,750
all of that I mentioned so far in mind

545
00:21:02,529 --> 00:21:06,340
what we do what would you need to know

546
00:21:04,750 --> 00:21:11,080
what would you target what would you go

547
00:21:06,340 --> 00:21:15,789
after so I'll hand over to Ezra to

548
00:21:11,080 --> 00:21:17,799
discuss the attack scenario okay so when

549
00:21:15,789 --> 00:21:21,158
we are thinking about the alumina tack

550
00:21:17,799 --> 00:21:23,860
we need to be very careful to understand

551
00:21:21,159 --> 00:21:25,809
what is the infrastructure and what are

552
00:21:23,860 --> 00:21:29,110
the parts in the process that you are

553
00:21:25,809 --> 00:21:32,710
taking a look at and we could go either

554
00:21:29,110 --> 00:21:35,189
after the maths or either after the

555
00:21:32,710 --> 00:21:37,480
system infrastructure

556
00:21:35,190 --> 00:21:40,899
just to recap a little bit I'm going to

557
00:21:37,480 --> 00:21:43,149
return to guys explanation about what is

558
00:21:40,899 --> 00:21:46,479
a process and we are going to categorize

559
00:21:43,149 --> 00:21:49,029
which parts are falling inside the

560
00:21:46,480 --> 00:21:51,940
mathematical part the algorithms part

561
00:21:49,029 --> 00:21:54,880
and which parts are dependent on the

562
00:21:51,940 --> 00:21:59,049
infrastructure work we are running these

563
00:21:54,880 --> 00:22:02,640
predictions so remember we are getting

564
00:21:59,049 --> 00:22:05,649
images audio text binaries whatever and

565
00:22:02,640 --> 00:22:09,990
we are making it into an internal

566
00:22:05,649 --> 00:22:09,989
representation parsing

567
00:22:10,320 --> 00:22:15,450
for structure then we're running the

568
00:22:13,200 --> 00:22:17,399
algorithms the mathematical parts are

569
00:22:15,450 --> 00:22:21,110
kicking in the model is being processed

570
00:22:17,399 --> 00:22:25,408
and then the neurons are being working

571
00:22:21,110 --> 00:22:28,949
algorithms afterwards we get an output

572
00:22:25,409 --> 00:22:32,870
from the system that is translated in

573
00:22:28,950 --> 00:22:39,120
some into something readable like a map

574
00:22:32,870 --> 00:22:42,570
system again so now that we had a talk a

575
00:22:39,120 --> 00:22:46,479
little bit about this let's start to

576
00:22:42,570 --> 00:22:51,340
explain what was our attack process

577
00:22:46,480 --> 00:22:54,250
and again I'm going to say this worth

578
00:22:51,340 --> 00:23:00,010
parsing remember that we need to work in

579
00:22:54,250 --> 00:23:04,660
matrices and the input can be different

580
00:23:00,010 --> 00:23:09,070
file formats so we are going to be doing

581
00:23:04,660 --> 00:23:10,510
a lot of parsing and I don't believe

582
00:23:09,070 --> 00:23:15,399
that I need to explain to this audience

583
00:23:10,510 --> 00:23:20,140
that parsing is hard like parsing is

584
00:23:15,400 --> 00:23:23,740
very very hard and most of the fun that

585
00:23:20,140 --> 00:23:28,900
we probably how had in the past has been

586
00:23:23,740 --> 00:23:31,870
related to parsing furthermore people

587
00:23:28,900 --> 00:23:34,630
that develop for AI or machine learning

588
00:23:31,870 --> 00:23:37,418
are amazing that these scientists are

589
00:23:34,630 --> 00:23:40,740
amazing mathematicians and they

590
00:23:37,419 --> 00:23:43,990
developed models and they developed that

591
00:23:40,740 --> 00:23:48,210
stuff they are not file formats

592
00:23:43,990 --> 00:23:52,390
developers further they are not parser

593
00:23:48,210 --> 00:23:56,380
developers and it was really really

594
00:23:52,390 --> 00:23:59,020
funny that how verse was taught was

595
00:23:56,380 --> 00:24:01,120
talking a lot about third parties and

596
00:23:59,020 --> 00:24:04,750
dependencies and bringing stuff into

597
00:24:01,120 --> 00:24:07,270
your project because that's exactly what

598
00:24:04,750 --> 00:24:10,350
it's happening with most of the machine

599
00:24:07,270 --> 00:24:16,040
learning world they are just bringing

600
00:24:10,350 --> 00:24:20,209
external dependencies into their project

601
00:24:16,040 --> 00:24:24,350
amazing so I would say dependencies that

602
00:24:20,210 --> 00:24:26,630
need to stay true to the way they work

603
00:24:24,350 --> 00:24:28,909
because if the matrix changes with our

604
00:24:26,630 --> 00:24:31,610
changes on the way the parsing is

605
00:24:28,910 --> 00:24:33,860
working the models are going to be also

606
00:24:31,610 --> 00:24:35,810
screwed because they were straight if

607
00:24:33,860 --> 00:24:38,810
they were trained with particular data

608
00:24:35,810 --> 00:24:44,149
structures that are representations so

609
00:24:38,810 --> 00:24:46,520
bad and they are bringing a very common

610
00:24:44,150 --> 00:24:50,260
problem with them like supply chain and

611
00:24:46,520 --> 00:24:57,500
patch management and an upstream and

612
00:24:50,260 --> 00:25:02,210
sometimes further specifically one of my

613
00:24:57,500 --> 00:25:05,060
favorite ones is that you must support

614
00:25:02,210 --> 00:25:07,790
multiple file formats I mean it's not

615
00:25:05,060 --> 00:25:09,889
enough to support a single image file

616
00:25:07,790 --> 00:25:13,430
format you need to support them all

617
00:25:09,890 --> 00:25:17,330
because if not you are not able to do it

618
00:25:13,430 --> 00:25:24,560
your magic so yeah let's first let's

619
00:25:17,330 --> 00:25:29,090
fuzz the file formats and it's a lot of

620
00:25:24,560 --> 00:25:33,379
fun so we felt me certainly at the

621
00:25:29,090 --> 00:25:38,000
beginning we feel miserably because we

622
00:25:33,380 --> 00:25:41,060
had a pretty big computer cluster for

623
00:25:38,000 --> 00:25:44,260
doing fuzzing and we were having

624
00:25:41,060 --> 00:25:48,770
terrible performance and we were having

625
00:25:44,260 --> 00:25:50,629
little runs per second and we were not

626
00:25:48,770 --> 00:25:54,490
fully understanding what's happening so

627
00:25:50,630 --> 00:25:56,559
we take a look at what we did wrong

628
00:25:54,490 --> 00:25:58,840
and to be able to explain this I'm going

629
00:25:56,559 --> 00:26:02,290
to talk a little bit about the stack

630
00:25:58,840 --> 00:26:04,899
that needs inside a machine learning

631
00:26:02,290 --> 00:26:09,940
and we had different places where we can

632
00:26:04,900 --> 00:26:11,830
focus our our our attacks so we started

633
00:26:09,940 --> 00:26:17,070
attacking the entire machine learning

634
00:26:11,830 --> 00:26:19,629
framework which in this case was affair

635
00:26:17,070 --> 00:26:23,590
the our focus here was because it was

636
00:26:19,630 --> 00:26:27,070
full coverage I mean any crash we will

637
00:26:23,590 --> 00:26:29,379
find over here would probably be a real

638
00:26:27,070 --> 00:26:32,860
crash and would not be irrelevant to

639
00:26:29,380 --> 00:26:36,550
option or whatever so it was extremely

640
00:26:32,860 --> 00:26:38,800
slow think that the entire process then

641
00:26:36,550 --> 00:26:44,379
tired prediction process entire parsing

642
00:26:38,800 --> 00:26:48,409
process entire machine learning voodoo

643
00:26:44,380 --> 00:26:52,190
was happening and it was extremely slow

644
00:26:48,410 --> 00:26:55,270
and then we went ahead and say hmm they

645
00:26:52,190 --> 00:26:57,830
are using a computer vision

646
00:26:55,270 --> 00:27:01,160
infrastructure below which was called

647
00:26:57,830 --> 00:27:03,830
OpenCV they were not using fully they

648
00:27:01,160 --> 00:27:06,980
were using certain parts only so the

649
00:27:03,830 --> 00:27:12,409
cordials limited the speed was medium it

650
00:27:06,980 --> 00:27:15,650
was okay and we will return to this you

651
00:27:12,410 --> 00:27:20,120
know a few then we could go directly to

652
00:27:15,650 --> 00:27:23,570
live TIFF or live BMP or live JPEG or

653
00:27:20,120 --> 00:27:29,239
you name it which would be extremely

654
00:27:23,570 --> 00:27:31,310
extremely extremely fast however on the

655
00:27:29,240 --> 00:27:32,600
machine learning frameworks that we were

656
00:27:31,310 --> 00:27:38,990
seeing they were not using the entire

657
00:27:32,600 --> 00:27:41,000
Colpitts wouldn't be relevant oh and my

658
00:27:38,990 --> 00:27:46,130
favorite one and we are going to see it

659
00:27:41,000 --> 00:27:47,870
in a few of 3,000 not needed however now

660
00:27:46,130 --> 00:27:50,690
we will need to check against the

661
00:27:47,870 --> 00:27:52,719
different payloads that are in the world

662
00:27:50,690 --> 00:27:57,190
and see if there are relevant for our

663
00:27:52,720 --> 00:28:00,680
distinct platforms that we were running

664
00:27:57,190 --> 00:28:02,770
at the end which was open CV or we

665
00:28:00,680 --> 00:28:11,470
choose open CV the speed was good enough

666
00:28:02,770 --> 00:28:11,470
and it was cool however

667
00:28:12,200 --> 00:28:16,940
we failed miserably at the beginning so

668
00:28:15,289 --> 00:28:19,429
you know we used to run this slurry the

669
00:28:16,940 --> 00:28:24,080
process and we needed fast

670
00:28:19,429 --> 00:28:26,389
starve and then another part of the team

671
00:28:24,080 --> 00:28:28,939
it's gonna be the researchers part of

672
00:28:26,389 --> 00:28:31,609
the team it's a I machine learning guys

673
00:28:28,940 --> 00:28:33,830
and they also needed high power

674
00:28:31,609 --> 00:28:37,428
computation so they needed to do a

675
00:28:33,830 --> 00:28:40,029
research and yeah it was my fault I

676
00:28:37,429 --> 00:28:44,259
rebooted the server was my fault

677
00:28:40,029 --> 00:28:49,489
yeah so we lost a few brushes over there

678
00:28:44,259 --> 00:28:52,669
and then we also forgot to turn off all

679
00:28:49,489 --> 00:28:56,509
the logging and stuff which fill our

680
00:28:52,669 --> 00:28:58,669
disks on the logging parts and it's

681
00:28:56,509 --> 00:29:01,009
amazing how fast you can turn terabytes

682
00:28:58,669 --> 00:29:02,749
of logs running fuzzing especially if

683
00:29:01,009 --> 00:29:06,169
you don't remember that you don't need

684
00:29:02,749 --> 00:29:13,639
logs for running this which again we

685
00:29:06,169 --> 00:29:17,749
lost some many Bally crushes so we suck

686
00:29:13,639 --> 00:29:18,309
at fuzzing scaling the exploitation is

687
00:29:17,749 --> 00:29:20,840
hard

688
00:29:18,309 --> 00:29:24,859
maybe we should hatches in that career

689
00:29:20,840 --> 00:29:31,119
on dev ops or whatever but eventually we

690
00:29:24,859 --> 00:29:31,119
got our quit and oh

691
00:29:31,870 --> 00:29:39,879
and almost every exploit whatever it you

692
00:29:34,780 --> 00:29:45,460
can imagine and bad collisions this was

693
00:29:39,880 --> 00:29:47,590
terrible because we we saw that we found

694
00:29:45,460 --> 00:29:49,420
backs and at the same time we see that

695
00:29:47,590 --> 00:29:53,080
other teams were finding bags and

696
00:29:49,420 --> 00:29:56,050
everybody was playing in this new field

697
00:29:53,080 --> 00:30:02,860
and everybody was exploiting the

698
00:29:56,050 --> 00:30:04,480
out of it so many crashes we stopped

699
00:30:02,860 --> 00:30:06,370
counting at one point that we have

700
00:30:04,480 --> 00:30:08,380
enough after we reached a couple of

701
00:30:06,370 --> 00:30:11,169
thousands we don't have time to analyze

702
00:30:08,380 --> 00:30:12,880
all of that we just thought you know

703
00:30:11,170 --> 00:30:14,920
it's terrible it's the worst situation

704
00:30:12,880 --> 00:30:17,890
that you can find yourself in like in a

705
00:30:14,920 --> 00:30:19,690
child a child in a candy store and you

706
00:30:17,890 --> 00:30:22,120
see oh this is how you have to feel it

707
00:30:19,690 --> 00:30:24,610
you know but I like this other one and

708
00:30:22,120 --> 00:30:26,169
you bright a moment when you don't know

709
00:30:24,610 --> 00:30:29,490
what to do because you have everything

710
00:30:26,170 --> 00:30:36,309
that you can imagine and you can ask for

711
00:30:29,490 --> 00:30:38,980
at the end we were lazy people and we we

712
00:30:36,309 --> 00:30:43,540
focus on processing the bitmap file

713
00:30:38,980 --> 00:30:47,440
format mostly because it's it's easy to

714
00:30:43,540 --> 00:30:50,230
do to handcraft it it's it's a compress

715
00:30:47,440 --> 00:30:54,420
it's it's it's it's nice file format

716
00:30:50,230 --> 00:31:00,450
it's relatively simple to do handcrafted

717
00:30:54,420 --> 00:31:00,450
with necks elite or whatever so

718
00:31:01,299 --> 00:31:06,019
actually I'm going to there's something

719
00:31:03,379 --> 00:31:07,789
that it's not on those lights and and we

720
00:31:06,019 --> 00:31:09,049
talked about it yesterday and just

721
00:31:07,789 --> 00:31:11,059
remember and I also want to share with

722
00:31:09,049 --> 00:31:13,429
you another one of our fails that which

723
00:31:11,059 --> 00:31:14,809
was extremely extremely hilarious

724
00:31:13,429 --> 00:31:17,029
one of the things that we were

725
00:31:14,809 --> 00:31:21,080
discussing yesterday night is testing

726
00:31:17,029 --> 00:31:23,600
it's big pain and one of the other

727
00:31:21,080 --> 00:31:25,668
issues that we have is that we were

728
00:31:23,600 --> 00:31:30,529
showing between my my team of

729
00:31:25,669 --> 00:31:32,419
researchers our proof of concepts but

730
00:31:30,529 --> 00:31:35,629
they were not working and also we were

731
00:31:32,419 --> 00:31:38,749
copying it from the output of AFL into

732
00:31:35,629 --> 00:31:41,629
into the into the mobile server and if

733
00:31:38,749 --> 00:31:44,359
you remember in a fold we see those huge

734
00:31:41,629 --> 00:31:46,369
file names but then we were lazy and we

735
00:31:44,359 --> 00:31:50,090
want to put small file names so it will

736
00:31:46,369 --> 00:31:52,689
be easier to just do to try it and

737
00:31:50,090 --> 00:31:56,269
where's the sage copy then we were lazy

738
00:31:52,690 --> 00:31:59,720
and it turned out that nothing was

739
00:31:56,269 --> 00:32:03,169
working the reason why it was what it

740
00:31:59,720 --> 00:32:05,149
was not working this because these gifts

741
00:32:03,169 --> 00:32:07,970
of silver that we were taking a look was

742
00:32:05,149 --> 00:32:10,428
using outdoor buffers and depending on

743
00:32:07,970 --> 00:32:12,379
the size of the fat and some of the

744
00:32:10,429 --> 00:32:14,659
explosives were using we were using heap

745
00:32:12,379 --> 00:32:17,178
exploitation so if the file name was too

746
00:32:14,659 --> 00:32:19,399
small it would go into the stack however

747
00:32:17,179 --> 00:32:22,399
when we started using them the big file

748
00:32:19,399 --> 00:32:26,209
names it would go into the hip and stuff

749
00:32:22,399 --> 00:32:31,820
was funded we learn we learn we enjoyed

750
00:32:26,210 --> 00:32:35,239
a lot so yeah what can we do now can we

751
00:32:31,820 --> 00:32:37,309
actually do our initial objectives that

752
00:32:35,239 --> 00:32:43,059
we classified with certain scores and

753
00:32:37,309 --> 00:32:43,059
whatever using the crushes that we found

754
00:32:43,780 --> 00:32:51,970
so yeah let's try to demonstrate the top

755
00:32:47,080 --> 00:32:54,330
five k when you build the toy system

756
00:32:51,970 --> 00:32:58,030
were the input would be an image file

757
00:32:54,330 --> 00:33:01,090
ten case something the output would be

758
00:32:58,030 --> 00:33:05,200
the label string which kind of picture

759
00:33:01,090 --> 00:33:07,659
the system received and basic prediction

760
00:33:05,200 --> 00:33:10,240
okay

761
00:33:07,660 --> 00:33:13,270
we build the system ourselves we didn't

762
00:33:10,240 --> 00:33:16,240
want to we cannot we shouldn't we

763
00:33:13,270 --> 00:33:20,170
wouldn't test anything that it's not in

764
00:33:16,240 --> 00:33:23,230
our level very important I want to say

765
00:33:20,170 --> 00:33:25,090
something about this we we were in in

766
00:33:23,230 --> 00:33:27,460
California last August and had a meeting

767
00:33:25,090 --> 00:33:29,199
with I won't say the name of that

768
00:33:27,460 --> 00:33:32,560
company but let's assume it's from the

769
00:33:29,200 --> 00:33:34,750
Far East and we discussed what IP theft

770
00:33:32,560 --> 00:33:36,520
is and how IP theft works and why we

771
00:33:34,750 --> 00:33:38,650
built a toy system to do IP theft

772
00:33:36,520 --> 00:33:40,690
against because we don't really want to

773
00:33:38,650 --> 00:33:42,520
steal IP from other people and so no no

774
00:33:40,690 --> 00:33:43,930
we actually did this and we took IP from

775
00:33:42,520 --> 00:33:48,820
one of the competitors this attack works

776
00:33:43,930 --> 00:33:53,740
we agree we said there like this I said

777
00:33:48,820 --> 00:33:59,080
ok moving on and for whatever computer

778
00:33:53,740 --> 00:33:59,880
software words but so let's start to

779
00:33:59,080 --> 00:34:06,250
have fun

780
00:33:59,880 --> 00:34:10,810
the first one its denial of service on

781
00:34:06,250 --> 00:34:12,639
our left side we have our system both of

782
00:34:10,810 --> 00:34:14,649
them are connect to the same machine we

783
00:34:12,639 --> 00:34:17,820
can it's virtual machines we connect

784
00:34:14,649 --> 00:34:20,469
locally to be able to do this testing

785
00:34:17,820 --> 00:34:24,070
we're going to see what is the status of

786
00:34:20,469 --> 00:34:26,408
the system the the H table we are all

787
00:34:24,070 --> 00:34:30,370
familiar with this to know how many

788
00:34:26,409 --> 00:34:33,990
processes are are being used and on the

789
00:34:30,370 --> 00:34:37,270
other side we are using our toy system

790
00:34:33,989 --> 00:34:41,379
where we are sending pin and exploit

791
00:34:37,270 --> 00:34:45,149
that it's called very cleverly RAM and

792
00:34:41,379 --> 00:34:45,149
CPU denial of service dot BMP

793
00:34:45,199 --> 00:34:54,520
and it starts to run and it will

794
00:34:50,719 --> 00:34:57,348
continue to run this 10k image and I'm

795
00:34:54,520 --> 00:34:59,060
not going to wait until it continues

796
00:34:57,349 --> 00:35:02,359
running because it's takes something

797
00:34:59,060 --> 00:35:05,390
like six minutes so let's fast forward a

798
00:35:02,359 --> 00:35:08,569
little bit and we have with the 10k file

799
00:35:05,390 --> 00:35:11,598
of six gigabyte representation and it's

800
00:35:08,570 --> 00:35:15,190
still going up and up and up and we will

801
00:35:11,599 --> 00:35:18,500
continue to be using a lot of resources

802
00:35:15,190 --> 00:35:20,089
and remember this kind of stuff is

803
00:35:18,500 --> 00:35:24,440
running on clouds and whatever and it

804
00:35:20,089 --> 00:35:26,690
will crush now so imagine the scenario

805
00:35:24,440 --> 00:35:28,940
you are start off running machine

806
00:35:26,690 --> 00:35:37,070
learning and this is going to cause you

807
00:35:28,940 --> 00:35:38,900
a lot of financial costs sometimes but

808
00:35:37,070 --> 00:35:45,740
we'll we didn't came to see

809
00:35:38,900 --> 00:35:49,220
denial-of-service here sorry yeah same

810
00:35:45,740 --> 00:35:51,200
scenario on one side we are going to to

811
00:35:49,220 --> 00:35:53,000
have running the exploit on the second

812
00:35:51,200 --> 00:35:57,410
one who are going to be connecting to

813
00:35:53,000 --> 00:36:00,360
the shell that we are going to that same

814
00:35:57,410 --> 00:36:02,970
hostname WM

815
00:36:00,360 --> 00:36:07,410
we are going to the library where stuff

816
00:36:02,970 --> 00:36:15,180
is running and yes big filenames to get

817
00:36:07,410 --> 00:36:17,220
into they to hit and we run it and it's

818
00:36:15,180 --> 00:36:21,120
doing something and it's going to wait

819
00:36:17,220 --> 00:36:23,520
and nothing happens and then we are

820
00:36:21,120 --> 00:36:28,020
doing and say to connect to the box that

821
00:36:23,520 --> 00:36:29,700
we had binded the shell and I'm sorry

822
00:36:28,020 --> 00:36:31,590
because I did a mistake instead of

823
00:36:29,700 --> 00:36:37,620
writing hostname I just wrote host or

824
00:36:31,590 --> 00:36:42,690
yeah same machine and we are there we

825
00:36:37,620 --> 00:36:44,759
can see stuff and whatever we're going

826
00:36:42,690 --> 00:36:45,720
to return to this this is extremely

827
00:36:44,760 --> 00:36:50,040
important

828
00:36:45,720 --> 00:36:52,910
just remember this screen because we

829
00:36:50,040 --> 00:37:01,500
will have fun with it but bottom line

830
00:36:52,910 --> 00:37:03,779
simple image speed so shell it was it's

831
00:37:01,500 --> 00:37:05,340
not important but I mean our objective

832
00:37:03,780 --> 00:37:11,630
was not getting a shell our objective

833
00:37:05,340 --> 00:37:14,160
was to do some fun stuff because it's

834
00:37:11,630 --> 00:37:17,910
funny when you can actually tie it with

835
00:37:14,160 --> 00:37:22,200
your original objectives so could we do

836
00:37:17,910 --> 00:37:24,200
model tampering absolutely as we are

837
00:37:22,200 --> 00:37:27,270
running we are going to deliver to the

838
00:37:24,200 --> 00:37:29,669
folder world we have our files and if

839
00:37:27,270 --> 00:37:32,810
you remember we have we talked about

840
00:37:29,670 --> 00:37:37,910
this mapping file that has a number and

841
00:37:32,810 --> 00:37:42,360
then has what does this label represents

842
00:37:37,910 --> 00:37:46,710
so it's trivial just to run an image

843
00:37:42,360 --> 00:37:50,010
that will do a segmentation fault of

844
00:37:46,710 --> 00:37:56,880
course and when we open this file again

845
00:37:50,010 --> 00:38:03,090
and when we do every yeah so my cat is

846
00:37:56,880 --> 00:38:05,340
now called hacked sometimes

847
00:38:03,090 --> 00:38:08,520
and yeah the last one if you remember

848
00:38:05,340 --> 00:38:11,780
the biggest square was the IP theft

849
00:38:08,520 --> 00:38:14,370
which is my favorite demo of them all

850
00:38:11,780 --> 00:38:16,830
because you actually saw it already

851
00:38:14,370 --> 00:38:20,190
if you remember we had the ability to

852
00:38:16,830 --> 00:38:23,250
see all the files including the mobile

853
00:38:20,190 --> 00:38:26,430
file that was in the system

854
00:38:23,250 --> 00:38:32,550
I'm not going to return to this world

855
00:38:26,430 --> 00:38:38,180
very very smart people so yeah RC is the

856
00:38:32,550 --> 00:38:42,060
king after all however you don't always

857
00:38:38,180 --> 00:38:45,089
have an an RC and you know what we do

858
00:38:42,060 --> 00:38:50,720
when we don't have an RC we do something

859
00:38:45,090 --> 00:38:50,720
very very very smart we talked with guy

860
00:38:51,619 --> 00:38:56,869
so what I want to describe now is what

861
00:38:54,799 --> 00:38:58,940
kind of approaches can you take if

862
00:38:56,869 --> 00:39:00,529
remote exploitation of that machine

863
00:38:58,940 --> 00:39:02,390
learning service are not possible

864
00:39:00,529 --> 00:39:04,219
usually they are but let's assume that

865
00:39:02,390 --> 00:39:06,109
they are not so the first most

866
00:39:04,219 --> 00:39:08,930
interesting attack that I can describe

867
00:39:06,109 --> 00:39:11,089
here is a completely let's call it an

868
00:39:08,930 --> 00:39:12,469
algorithmic attack and it's inherent to

869
00:39:11,089 --> 00:39:14,989
the way that machine learning processes

870
00:39:12,469 --> 00:39:15,979
work so for this if scenario imagine

871
00:39:14,989 --> 00:39:17,479
that you have some sort of machine

872
00:39:15,979 --> 00:39:20,509
learning service running in the cloud

873
00:39:17,479 --> 00:39:22,640
giving you some public API that you can

874
00:39:20,509 --> 00:39:25,789
query zuchini run queries against the

875
00:39:22,640 --> 00:39:27,710
API get results from that API apparently

876
00:39:25,789 --> 00:39:29,809
that is enough information for you to

877
00:39:27,710 --> 00:39:31,400
train your own model so you can use it

878
00:39:29,809 --> 00:39:33,829
in that information that you're wearing

879
00:39:31,400 --> 00:39:36,589
your Oracle in order to create a better

880
00:39:33,829 --> 00:39:39,200
model yourself when we did this

881
00:39:36,589 --> 00:39:41,420
experiment initially our hypothesis was

882
00:39:39,200 --> 00:39:44,029
that we would need hundreds of thousands

883
00:39:41,420 --> 00:39:46,910
of queries maybe even more than that to

884
00:39:44,029 --> 00:39:48,799
train another model a replica model and

885
00:39:46,910 --> 00:39:52,279
which would achieve the same kind of

886
00:39:48,799 --> 00:39:54,529
accuracy that the original Oracle had to

887
00:39:52,279 --> 00:39:56,719
our surprise we cut it off at about

888
00:39:54,529 --> 00:39:59,839
5,000 queries because the accuracy was

889
00:39:56,719 --> 00:40:02,839
about two percent difference so just

890
00:39:59,839 --> 00:40:05,538
five thousand queries to actually steal

891
00:40:02,839 --> 00:40:07,700
the IP you create a functional clone on

892
00:40:05,539 --> 00:40:09,109
your own premise that does the exactly

893
00:40:07,700 --> 00:40:11,538
the same thing that somebody else did

894
00:40:09,109 --> 00:40:14,089
have done and you accelerated your

895
00:40:11,539 --> 00:40:16,039
research significantly utilizing someone

896
00:40:14,089 --> 00:40:18,650
else's work by replicating those

897
00:40:16,039 --> 00:40:20,539
pathways that I mentioned earlier into

898
00:40:18,650 --> 00:40:23,119
your own model and this is a very

899
00:40:20,539 --> 00:40:24,680
interesting type of attack because the

900
00:40:23,119 --> 00:40:26,390
two most common mitigations people

901
00:40:24,680 --> 00:40:29,118
suggest whenever I mention this kind of

902
00:40:26,390 --> 00:40:31,430
attack is so do rate limiting well it's

903
00:40:29,119 --> 00:40:33,650
just 5,000 queries I'll just ask them

904
00:40:31,430 --> 00:40:35,960
very slowly it's not doesn't really

905
00:40:33,650 --> 00:40:37,190
matter or let's attach a cost to each

906
00:40:35,960 --> 00:40:39,859
API query

907
00:40:37,190 --> 00:40:42,650
well you invested five to ten million

908
00:40:39,859 --> 00:40:44,930
dollars developing your IP I'll spend

909
00:40:42,650 --> 00:40:47,119
$5,000 to steal it it's perfectly fine

910
00:40:44,930 --> 00:40:49,160
or there are the kinds of mitigation

911
00:40:47,119 --> 00:40:52,609
search that don't really make much sense

912
00:40:49,160 --> 00:40:54,799
in this kind of scenario so we dug a bit

913
00:40:52,609 --> 00:40:57,410
deeper into this cloning attack and we

914
00:40:54,799 --> 00:41:00,710
defined like three different models of

915
00:40:57,410 --> 00:41:02,299
attack the first one is white box what

916
00:41:00,710 --> 00:41:04,009
box assumes that you have full access to

917
00:41:02,299 --> 00:41:04,640
everything except the actual values of

918
00:41:04,009 --> 00:41:06,740
the matron

919
00:41:04,640 --> 00:41:08,600
and this sounds like a not an

920
00:41:06,740 --> 00:41:10,580
unreasonable assumption to make because

921
00:41:08,600 --> 00:41:13,069
why would someone actually publish their

922
00:41:10,580 --> 00:41:14,720
topology or give you access to the

923
00:41:13,070 --> 00:41:16,430
functions that they've created or to the

924
00:41:14,720 --> 00:41:18,859
knowledge that they've encoded in their

925
00:41:16,430 --> 00:41:20,569
IP but then you go and find out on

926
00:41:18,860 --> 00:41:23,150
LinkedIn who actually works at that

927
00:41:20,570 --> 00:41:25,300
company and where he did his PhD and you

928
00:41:23,150 --> 00:41:28,340
go and look at these theses for PhD and

929
00:41:25,300 --> 00:41:30,110
it's there or you look for academic

930
00:41:28,340 --> 00:41:32,660
conferences where those dirty sciences

931
00:41:30,110 --> 00:41:34,280
go and present their work and there is a

932
00:41:32,660 --> 00:41:37,100
correlation between what they do and

933
00:41:34,280 --> 00:41:38,960
what they publish so we show that this

934
00:41:37,100 --> 00:41:40,339
is actually a very reasonable model for

935
00:41:38,960 --> 00:41:42,770
attack because there's a lot more

936
00:41:40,340 --> 00:41:45,050
information about the way that companies

937
00:41:42,770 --> 00:41:46,400
are developing their machine learning

938
00:41:45,050 --> 00:41:50,420
models than what you would actually

939
00:41:46,400 --> 00:41:52,220
assume if it was just code a gray box of

940
00:41:50,420 --> 00:41:53,990
text is a bit different a grey box of

941
00:41:52,220 --> 00:41:55,850
text means that you have no idea what's

942
00:41:53,990 --> 00:41:57,410
going on internally on the Oracle side

943
00:41:55,850 --> 00:41:59,299
but you have a lot of domain knowledge

944
00:41:57,410 --> 00:42:01,460
for example if we have an object

945
00:41:59,300 --> 00:42:04,250
classification system for traffic signs

946
00:42:01,460 --> 00:42:06,800
so we know that this system has been

947
00:42:04,250 --> 00:42:09,830
trained on the traffic signs from

948
00:42:06,800 --> 00:42:11,030
Finland okay but I don't have access to

949
00:42:09,830 --> 00:42:13,040
the training data set I don't have

950
00:42:11,030 --> 00:42:14,900
access to that model but we know that

951
00:42:13,040 --> 00:42:16,910
traffic signs are more or less the same

952
00:42:14,900 --> 00:42:19,040
in all countries so I can take a

953
00:42:16,910 --> 00:42:21,830
database coming from Brazil or from the

954
00:42:19,040 --> 00:42:24,560
United States and use that in order to

955
00:42:21,830 --> 00:42:25,840
give me the the bootstrapping that I

956
00:42:24,560 --> 00:42:28,820
need in order to steal that information

957
00:42:25,840 --> 00:42:31,220
so if you have domain knowledge it's

958
00:42:28,820 --> 00:42:32,750
enough to conduct these attacks so for

959
00:42:31,220 --> 00:42:34,970
these two specific attacks I can tell

960
00:42:32,750 --> 00:42:37,550
you that for the white box attacks we

961
00:42:34,970 --> 00:42:39,680
reached accuracies of plus two plus

962
00:42:37,550 --> 00:42:40,790
minus two percents so in some of our

963
00:42:39,680 --> 00:42:42,440
attacks we actually got better

964
00:42:40,790 --> 00:42:45,650
performance than the original Oracle

965
00:42:42,440 --> 00:42:47,630
which is not so amazing when you think

966
00:42:45,650 --> 00:42:48,830
about it because we actually took

967
00:42:47,630 --> 00:42:50,420
advantage of the fact that they've

968
00:42:48,830 --> 00:42:53,090
already trained their model and we

969
00:42:50,420 --> 00:42:55,100
improved upon it so it does it does make

970
00:42:53,090 --> 00:42:57,620
sense and for the gray box attack we

971
00:42:55,100 --> 00:42:59,750
were around ten to 15% off from the

972
00:42:57,620 --> 00:43:01,339
original accuracy which again is an

973
00:42:59,750 --> 00:43:03,230
attacker if all I want is to accelerate

974
00:43:01,340 --> 00:43:04,730
my NRE I don't want to spend a

975
00:43:03,230 --> 00:43:06,380
year-and-a-half developing this model I

976
00:43:04,730 --> 00:43:09,260
want to spend three months and getting

977
00:43:06,380 --> 00:43:11,390
to market before my competitor I can do

978
00:43:09,260 --> 00:43:13,190
10% off and improve on that and that is

979
00:43:11,390 --> 00:43:14,660
a very reasonable attack and very

980
00:43:13,190 --> 00:43:16,310
reasonable trade-off between the amount

981
00:43:14,660 --> 00:43:18,080
of money you spend on it and the result

982
00:43:16,310 --> 00:43:19,520
that you get

983
00:43:18,080 --> 00:43:22,220
but we've also looked at black box

984
00:43:19,520 --> 00:43:23,660
attacks black bloc attacks is you have

985
00:43:22,220 --> 00:43:26,240
no knowledge what's going on you are not

986
00:43:23,660 --> 00:43:27,830
even sure what kind of labels the system

987
00:43:26,240 --> 00:43:30,229
is outputting other than the one that

988
00:43:27,830 --> 00:43:31,819
you have knowledge of so assuming that I

989
00:43:30,230 --> 00:43:34,910
have some object classification system

990
00:43:31,820 --> 00:43:37,130
it might hold ten classes it might hold

991
00:43:34,910 --> 00:43:39,529
100 classes and 19 that I have never

992
00:43:37,130 --> 00:43:42,260
encountered so for black boxes attacks

993
00:43:39,530 --> 00:43:44,360
currently we are a failure we haven't

994
00:43:42,260 --> 00:43:46,280
made it work yet but we do believe that

995
00:43:44,360 --> 00:43:48,770
there is at least something that can be

996
00:43:46,280 --> 00:43:50,840
done for a black box attacks or at least

997
00:43:48,770 --> 00:43:54,440
some understanding that can be utilized

998
00:43:50,840 --> 00:43:55,730
for grey box and white box later but

999
00:43:54,440 --> 00:43:57,110
what if you don't have any kind of

1000
00:43:55,730 --> 00:43:59,840
access to the training data or no

1001
00:43:57,110 --> 00:44:01,670
knowledge of the topology itself sorry

1002
00:43:59,840 --> 00:44:03,440
if you do have access to the training

1003
00:44:01,670 --> 00:44:05,540
data so you can do something even more

1004
00:44:03,440 --> 00:44:07,040
interesting so the attack scenario here

1005
00:44:05,540 --> 00:44:09,020
is someone who has access to the data

1006
00:44:07,040 --> 00:44:10,520
center to the data scientist or to the

1007
00:44:09,020 --> 00:44:13,310
weathered models are being developed and

1008
00:44:10,520 --> 00:44:16,100
he would introduce his own crafted data

1009
00:44:13,310 --> 00:44:16,940
into the training data set so imagine

1010
00:44:16,100 --> 00:44:19,610
that you have an intrusion detection

1011
00:44:16,940 --> 00:44:22,100
system that is built to recognize the

1012
00:44:19,610 --> 00:44:24,080
NetFlow packets and you will introduce

1013
00:44:22,100 --> 00:44:26,450
your own samples into the training data

1014
00:44:24,080 --> 00:44:28,640
set that says if you see this magic

1015
00:44:26,450 --> 00:44:31,430
header then this is a benign packet

1016
00:44:28,640 --> 00:44:33,430
nothing malicious here walk away and you

1017
00:44:31,430 --> 00:44:37,250
give enough samples of this into this

1018
00:44:33,430 --> 00:44:39,290
100,000 won millions sample database you

1019
00:44:37,250 --> 00:44:41,570
introduce your own 10 to 15 samples in

1020
00:44:39,290 --> 00:44:43,160
it and now we have a backdoor because

1021
00:44:41,570 --> 00:44:44,720
when this machine learning model is

1022
00:44:43,160 --> 00:44:47,180
going to be deployed if you introduce

1023
00:44:44,720 --> 00:44:49,250
your magic packet into a magic number

1024
00:44:47,180 --> 00:44:50,810
into that packet the training system

1025
00:44:49,250 --> 00:44:52,250
would think well this is not malicious I

1026
00:44:50,810 --> 00:44:54,200
know this I've seen this before

1027
00:44:52,250 --> 00:44:56,570
I've been trained to recognize this as

1028
00:44:54,200 --> 00:44:58,100
non malicious but the interesting part

1029
00:44:56,570 --> 00:44:59,240
is not how you construct backdoors

1030
00:44:58,100 --> 00:45:01,279
because we all know how to construct

1031
00:44:59,240 --> 00:45:03,529
backdoors but remember when I mentioned

1032
00:45:01,280 --> 00:45:06,590
earlier we have no way to reverse

1033
00:45:03,530 --> 00:45:08,450
engineer an inference system deployed

1034
00:45:06,590 --> 00:45:10,670
machine learning model to know if it has

1035
00:45:08,450 --> 00:45:12,560
a backdoor or not because if I bought an

1036
00:45:10,670 --> 00:45:14,180
appliance from a vendor and that

1037
00:45:12,560 --> 00:45:16,730
appliance has a machine learning model

1038
00:45:14,180 --> 00:45:18,980
it just has a matrix and the matrix has

1039
00:45:16,730 --> 00:45:20,780
some values and I have no way there is

1040
00:45:18,980 --> 00:45:22,940
no way known to man to reverse-engineer

1041
00:45:20,780 --> 00:45:25,580
a matrix to understand what kind of data

1042
00:45:22,940 --> 00:45:27,910
they develop that matrix design that

1043
00:45:25,580 --> 00:45:27,910
matrix

1044
00:45:29,980 --> 00:45:35,380
encoding is is very important is very

1045
00:45:33,160 --> 00:45:38,049
difficult to know what the system

1046
00:45:35,380 --> 00:45:40,869
actually learned what what it actually

1047
00:45:38,050 --> 00:45:43,540
what kind of pathway is in constructed

1048
00:45:40,869 --> 00:45:44,200
and where those pathways might take you

1049
00:45:43,540 --> 00:45:46,570
in the future

1050
00:45:44,200 --> 00:45:49,328
and I'll give an example of that this is

1051
00:45:46,570 --> 00:45:51,730
work by IBM presented in this year's

1052
00:45:49,329 --> 00:45:53,320
blackhat a couple of months ago so what

1053
00:45:51,730 --> 00:45:54,940
they've done they've constructed a piece

1054
00:45:53,320 --> 00:45:57,760
of malware they called it deep blocker

1055
00:45:54,940 --> 00:46:00,640
where the triggering mechanism for the

1056
00:45:57,760 --> 00:46:02,349
malware was a machine learning model so

1057
00:46:00,640 --> 00:46:04,270
what change here usually when you have a

1058
00:46:02,349 --> 00:46:05,859
piece of malware it takes input from the

1059
00:46:04,270 --> 00:46:08,710
environment it looks at registry keys

1060
00:46:05,859 --> 00:46:11,290
file system file names they might look

1061
00:46:08,710 --> 00:46:13,390
at other a characteristics of the system

1062
00:46:11,290 --> 00:46:14,829
and make a decision okay I look at all

1063
00:46:13,390 --> 00:46:16,509
of those inputs I want to trigger the

1064
00:46:14,829 --> 00:46:18,310
payload I will now produce the

1065
00:46:16,510 --> 00:46:20,109
decryption key for the encrypted payload

1066
00:46:18,310 --> 00:46:22,210
recruit a payload and run the malicious

1067
00:46:20,109 --> 00:46:24,670
payload that's the usual way that those

1068
00:46:22,210 --> 00:46:26,589
descriptors work now that they've

1069
00:46:24,670 --> 00:46:28,839
constructed the machine learning model

1070
00:46:26,589 --> 00:46:31,420
inside it it still reads inputs it still

1071
00:46:28,839 --> 00:46:33,640
produces a decryption key but we as

1072
00:46:31,420 --> 00:46:36,369
researchers have no way to understand

1073
00:46:33,640 --> 00:46:38,170
what is the relationship between inputs

1074
00:46:36,369 --> 00:46:39,940
and triggering the key to the decryption

1075
00:46:38,170 --> 00:46:41,770
key so there's no way to reverse

1076
00:46:39,940 --> 00:46:43,359
engineer it and that means that if

1077
00:46:41,770 --> 00:46:45,730
somebody now released that malware out

1078
00:46:43,359 --> 00:46:48,069
in the wild and we have a sample and we

1079
00:46:45,730 --> 00:46:50,440
copy to our own protected system to

1080
00:46:48,069 --> 00:46:52,029
analyze it we don't have access to the

1081
00:46:50,440 --> 00:46:54,069
same inputs and we have no way to

1082
00:46:52,030 --> 00:46:55,480
determine what those inputs were unless

1083
00:46:54,069 --> 00:46:57,520
it's in a controlled environment which

1084
00:46:55,480 --> 00:46:59,290
is very rare when you have outbreaks

1085
00:46:57,520 --> 00:47:01,030
somewhere in the world so this really

1086
00:46:59,290 --> 00:47:02,770
changes the way that you think of these

1087
00:47:01,030 --> 00:47:04,359
problems when you can't have reverse

1088
00:47:02,770 --> 00:47:07,900
engineering when you don't have all of

1089
00:47:04,359 --> 00:47:11,710
the information I also want to mention

1090
00:47:07,900 --> 00:47:13,930
briefly as class of attacks called

1091
00:47:11,710 --> 00:47:17,200
adversarial attacks or mis-predictions

1092
00:47:13,930 --> 00:47:18,640
where basically you take advantage of

1093
00:47:17,200 --> 00:47:21,279
the fact that the machine learning

1094
00:47:18,640 --> 00:47:22,900
models focus on the most important or

1095
00:47:21,280 --> 00:47:26,500
the strongest signal that they've

1096
00:47:22,900 --> 00:47:29,230
encoded and that means that a lot of

1097
00:47:26,500 --> 00:47:31,630
that information those pathways can be

1098
00:47:29,230 --> 00:47:33,579
taken advantage of by an attacker and

1099
00:47:31,630 --> 00:47:37,540
I'll give you an example there was a

1100
00:47:33,579 --> 00:47:39,280
bigger discussion or let's say an

1101
00:47:37,540 --> 00:47:41,770
argument in the community are these

1102
00:47:39,280 --> 00:47:43,550
attacks real-world at all because if I

1103
00:47:41,770 --> 00:47:47,810
can take object detection

1104
00:47:43,550 --> 00:47:51,050
and consider convincing it there to

1105
00:47:47,810 --> 00:47:53,930
recognize turtle as a rifle then I

1106
00:47:51,050 --> 00:47:56,360
broken the assumption of that system but

1107
00:47:53,930 --> 00:47:59,089
for 2d images it's been shown to be very

1108
00:47:56,360 --> 00:48:00,830
very easy but for 3d objects it's a very

1109
00:47:59,090 --> 00:48:02,600
difficult problem because we have

1110
00:48:00,830 --> 00:48:04,250
different aspects and you have lighting

1111
00:48:02,600 --> 00:48:05,810
conditions that you have zoom and you

1112
00:48:04,250 --> 00:48:08,330
have a lot of different things that you

1113
00:48:05,810 --> 00:48:10,549
need to consider when you're doing 2d

1114
00:48:08,330 --> 00:48:12,529
attempts so if there a big argument was

1115
00:48:10,550 --> 00:48:15,020
is this kind of attack even feasible in

1116
00:48:12,530 --> 00:48:17,120
the real world and the answer is well

1117
00:48:15,020 --> 00:48:19,400
yes first of all this is not a real

1118
00:48:17,120 --> 00:48:23,240
turtle this is a 3d printed turtle so no

1119
00:48:19,400 --> 00:48:25,760
turtles were harmed it's not ours anyway

1120
00:48:23,240 --> 00:48:27,259
and if you look at the left north side

1121
00:48:25,760 --> 00:48:30,980
you will see that the machine learning

1122
00:48:27,260 --> 00:48:32,570
system classifies it as rifle when you

1123
00:48:30,980 --> 00:48:33,920
see the bar going to the top and the

1124
00:48:32,570 --> 00:48:35,600
reason that it does so if you look at

1125
00:48:33,920 --> 00:48:38,030
the top side of the shell you see like

1126
00:48:35,600 --> 00:48:40,819
little red spots so what the researchers

1127
00:48:38,030 --> 00:48:43,040
have done is they understood what kind

1128
00:48:40,820 --> 00:48:45,020
of signal causes the system to determine

1129
00:48:43,040 --> 00:48:47,720
that this is a rifle and they've painted

1130
00:48:45,020 --> 00:48:50,690
the shell of the turtle to mimic those

1131
00:48:47,720 --> 00:48:53,839
signals now whenever the shell is facing

1132
00:48:50,690 --> 00:48:55,550
the camera those signals saying rifle

1133
00:48:53,840 --> 00:48:58,760
are much stronger than the signals that

1134
00:48:55,550 --> 00:49:01,040
are saying turtle so it's very very

1135
00:48:58,760 --> 00:49:04,370
possible to convince that system that

1136
00:49:01,040 --> 00:49:05,720
this is actually a rifle and I'll try to

1137
00:49:04,370 --> 00:49:11,180
give you an example from a different

1138
00:49:05,720 --> 00:49:16,520
domain please listen closely and I'll

1139
00:49:11,180 --> 00:49:18,620
play it again so this is the unmodified

1140
00:49:16,520 --> 00:49:21,820
original attack and I want you to listen

1141
00:49:18,620 --> 00:49:21,819
to the attack version

1142
00:49:22,360 --> 00:49:29,420
and again show of hands how many of you

1143
00:49:27,950 --> 00:49:39,049
have actually heard the attack the

1144
00:49:29,420 --> 00:49:41,270
second time no.1 do it again now anybody

1145
00:49:39,050 --> 00:49:43,430
listen to the beginning it was a bit of

1146
00:49:41,270 --> 00:49:47,270
perturbation like noise in the beginning

1147
00:49:43,430 --> 00:49:49,580
in the background exactly so when a

1148
00:49:47,270 --> 00:49:51,860
voice recognition system listens to the

1149
00:49:49,580 --> 00:49:53,870
strongest signal that he detects what it

1150
00:49:51,860 --> 00:49:56,510
actually heard was Google brows to evil

1151
00:49:53,870 --> 00:49:58,370
calm and that is a much stronger signal

1152
00:49:56,510 --> 00:50:00,710
than the person who says without the

1153
00:49:58,370 --> 00:50:02,660
data set the article is useless so we

1154
00:50:00,710 --> 00:50:04,400
can craft those inputs in those

1155
00:50:02,660 --> 00:50:06,980
different domains and different spaces

1156
00:50:04,400 --> 00:50:08,720
in order to maliciously drive the

1157
00:50:06,980 --> 00:50:11,390
results of the machine learning system

1158
00:50:08,720 --> 00:50:13,129
to whatever we choose them to be and we

1159
00:50:11,390 --> 00:50:15,680
can probably do that in a way that

1160
00:50:13,130 --> 00:50:17,860
nobody would even notice because the

1161
00:50:15,680 --> 00:50:20,029
machine learning system need very little

1162
00:50:17,860 --> 00:50:22,400
inputs in order to make those decisions

1163
00:50:20,030 --> 00:50:24,080
you there has actually been an attack

1164
00:50:22,400 --> 00:50:26,000
where you change the single pixel in an

1165
00:50:24,080 --> 00:50:28,460
image and you cause a dog to become an

1166
00:50:26,000 --> 00:50:31,940
airplane so it's not like you need a

1167
00:50:28,460 --> 00:50:34,120
whole lot of perturbation another tag

1168
00:50:31,940 --> 00:50:37,340
this is from last year's Def Con and

1169
00:50:34,120 --> 00:50:39,259
what this his name was Hyrum Anderson

1170
00:50:37,340 --> 00:50:40,880
and what he did was actually pretty

1171
00:50:39,260 --> 00:50:43,340
amazing in my opinion he attacked

1172
00:50:40,880 --> 00:50:45,050
virustotal so I assume that you all from

1173
00:50:43,340 --> 00:50:47,080
you're all familiar with virus solo it's

1174
00:50:45,050 --> 00:50:50,690
an aggregation of different antivirus

1175
00:50:47,080 --> 00:50:52,549
machine aggregating scores when you're

1176
00:50:50,690 --> 00:50:54,530
uploading binaries so he built the

1177
00:50:52,550 --> 00:50:57,020
machine learning system that would

1178
00:50:54,530 --> 00:50:59,450
modify his malicious code compile it

1179
00:50:57,020 --> 00:51:01,160
uploaded a virus total get the score

1180
00:50:59,450 --> 00:51:03,680
decide is he moving in the right

1181
00:51:01,160 --> 00:51:05,870
direction yes or no changed the code

1182
00:51:03,680 --> 00:51:09,080
again compile it and upload it again so

1183
00:51:05,870 --> 00:51:10,970
he started with a score 0.75 which is

1184
00:51:09,080 --> 00:51:13,190
obviously malicious and it was able to

1185
00:51:10,970 --> 00:51:15,560
find a path to decrease the likelihood

1186
00:51:13,190 --> 00:51:19,010
of this actually being malicious down to

1187
00:51:15,560 --> 00:51:20,930
0.49 technically speaking the the final

1188
00:51:19,010 --> 00:51:22,700
results has been that he needed to

1189
00:51:20,930 --> 00:51:24,049
remove the dot text section into a

1190
00:51:22,700 --> 00:51:26,029
different name renamed it to do

1191
00:51:24,050 --> 00:51:27,830
something else and copy pasted the dot

1192
00:51:26,030 --> 00:51:29,740
text session from notepad or taxa that

1193
00:51:27,830 --> 00:51:31,910
was enough to be considered benign

1194
00:51:29,740 --> 00:51:34,279
functionally speaking it's exactly the

1195
00:51:31,910 --> 00:51:35,180
same thing not no other changes and this

1196
00:51:34,280 --> 00:51:36,640
is completely

1197
00:51:35,180 --> 00:51:39,529
taking down the virustotal as

1198
00:51:36,640 --> 00:51:40,970
non-malicious so you can take if you

1199
00:51:39,530 --> 00:51:43,280
have an Oracle you can take information

1200
00:51:40,970 --> 00:51:45,230
from that Oracle as an attacker to

1201
00:51:43,280 --> 00:51:46,940
improve your own systems because the way

1202
00:51:45,230 --> 00:51:49,069
that those Oracle's are designed they

1203
00:51:46,940 --> 00:51:52,220
give out a lot of information that is

1204
00:51:49,069 --> 00:51:54,650
very useful for you and I want to close

1205
00:51:52,220 --> 00:51:57,500
up with an example about privacy so this

1206
00:51:54,650 --> 00:51:59,119
is a very simple example but I want to

1207
00:51:57,500 --> 00:52:00,920
give you a notion of what privacy

1208
00:51:59,119 --> 00:52:03,920
leakage means in machine learning model

1209
00:52:00,920 --> 00:52:06,680
so let's assume that we have a company

1210
00:52:03,920 --> 00:52:08,839
developing a diabetes recognition system

1211
00:52:06,680 --> 00:52:10,879
so they take a blood sample and do some

1212
00:52:08,839 --> 00:52:13,609
measurements on it and calculate a score

1213
00:52:10,880 --> 00:52:14,930
that you either have diabetes or don't

1214
00:52:13,609 --> 00:52:17,000
have a diabetes or the likelihood that

1215
00:52:14,930 --> 00:52:19,129
you would have diabetes so they train

1216
00:52:17,000 --> 00:52:20,510
this data set with a bunch of people and

1217
00:52:19,130 --> 00:52:22,490
now they have an appliance and they sell

1218
00:52:20,510 --> 00:52:24,859
it to an insurance company the insurance

1219
00:52:22,490 --> 00:52:26,899
company has Joe Joe comes along and

1220
00:52:24,859 --> 00:52:28,578
wants to buy an insurance policy so they

1221
00:52:26,900 --> 00:52:30,470
run his blood tests against that system

1222
00:52:28,579 --> 00:52:33,200
and the system comes up with a score of

1223
00:52:30,470 --> 00:52:35,118
7.4 his he does not have the high risk

1224
00:52:33,200 --> 00:52:36,890
for diabetes or maybe comes back with a

1225
00:52:35,119 --> 00:52:38,599
score of thirty five point three here he

1226
00:52:36,890 --> 00:52:41,089
has a high risk for diabetes so

1227
00:52:38,599 --> 00:52:43,130
basically that what the system does so

1228
00:52:41,089 --> 00:52:45,259
where's this where's the issue the issue

1229
00:52:43,130 --> 00:52:47,240
is when Philip which was part of the

1230
00:52:45,260 --> 00:52:49,430
original data set comes into the game

1231
00:52:47,240 --> 00:52:52,759
because when the system will see he is

1232
00:52:49,430 --> 00:52:54,379
data it will not give a very low integer

1233
00:52:52,760 --> 00:52:55,849
score or a very low numbered score it

1234
00:52:54,380 --> 00:52:58,220
will give a very high numbered score

1235
00:52:55,849 --> 00:53:00,530
because it trained on his data it

1236
00:52:58,220 --> 00:53:02,899
already knows his data and whenever I

1237
00:53:00,530 --> 00:53:04,760
see this kind of 96.2%

1238
00:53:02,900 --> 00:53:06,920
it means I'm not encountering some

1239
00:53:04,760 --> 00:53:08,270
random data out from the street I know

1240
00:53:06,920 --> 00:53:09,859
that this data has already been

1241
00:53:08,270 --> 00:53:12,950
introduced to the system in the past and

1242
00:53:09,859 --> 00:53:15,049
if we have that score we have that

1243
00:53:12,950 --> 00:53:16,939
knowledge it means that we know that

1244
00:53:15,049 --> 00:53:18,170
Philip has diabetes we are not assuming

1245
00:53:16,940 --> 00:53:20,119
that he has diabetes

1246
00:53:18,170 --> 00:53:22,160
we already leaked his private

1247
00:53:20,119 --> 00:53:26,150
information by the very fact that we ran

1248
00:53:22,160 --> 00:53:29,180
his result against the database so to

1249
00:53:26,150 --> 00:53:30,650
summarize if you are researcher what we

1250
00:53:29,180 --> 00:53:33,379
would like the message we would like you

1251
00:53:30,650 --> 00:53:34,700
to to take home with you is that we need

1252
00:53:33,380 --> 00:53:36,680
a better trust model for machine

1253
00:53:34,700 --> 00:53:38,149
learning systems right now we don't

1254
00:53:36,680 --> 00:53:39,890
really have a transponder for machine

1255
00:53:38,150 --> 00:53:41,690
learning systems and when I'm saying

1256
00:53:39,890 --> 00:53:43,279
this is not just the algorithmic part

1257
00:53:41,690 --> 00:53:44,869
which is where most data scientists are

1258
00:53:43,280 --> 00:53:46,579
focused I'm talking about the end-to-end

1259
00:53:44,869 --> 00:53:48,079
system how do you protect everything

1260
00:53:46,579 --> 00:53:48,920
from the input that you get from the

1261
00:53:48,079 --> 00:53:50,240
user to the out

1262
00:53:48,920 --> 00:53:51,770
you're giving him and what you're

1263
00:53:50,240 --> 00:53:55,029
leaking what kind of information you're

1264
00:53:51,770 --> 00:53:55,030
leaking when you give it in the way

1265
00:53:55,400 --> 00:53:58,819
if you're an attacker wow this is so

1266
00:53:57,289 --> 00:54:00,500
much fun there's so much stuff to do

1267
00:53:58,819 --> 00:54:02,869
here this is a right field green field

1268
00:54:00,500 --> 00:54:04,970
you can do a lot of amazing stuff and a

1269
00:54:02,869 --> 00:54:05,859
lot of low-hanging fruits still here

1270
00:54:04,970 --> 00:54:08,299
today

1271
00:54:05,859 --> 00:54:09,828
Annie Ruffin if you're in a defender and

1272
00:54:08,299 --> 00:54:11,720
you want to defend against these kinds

1273
00:54:09,829 --> 00:54:12,799
of attacks which is another thing that

1274
00:54:11,720 --> 00:54:14,930
we're doing on our team trying to

1275
00:54:12,799 --> 00:54:17,029
develop those mitigations you have to

1276
00:54:14,930 --> 00:54:18,859
think differently about how machine

1277
00:54:17,029 --> 00:54:19,250
learning models are being used in the

1278
00:54:18,859 --> 00:54:20,839
world

1279
00:54:19,250 --> 00:54:22,670
what kind of attack models you are

1280
00:54:20,839 --> 00:54:24,349
trying to defend against and what are

1281
00:54:22,670 --> 00:54:28,730
the capabilities of your attackers and

1282
00:54:24,349 --> 00:54:29,299
maybe the most important thing it's not

1283
00:54:28,730 --> 00:54:31,339
magic

1284
00:54:29,299 --> 00:54:33,079
there's no Voodoo here in the end is

1285
00:54:31,339 --> 00:54:35,509
just a piece of software doing something

1286
00:54:33,079 --> 00:54:36,710
that people designed it to do and if you

1287
00:54:35,510 --> 00:54:38,029
understand what it does and you

1288
00:54:36,710 --> 00:54:40,430
understand the limitations just like

1289
00:54:38,029 --> 00:54:43,220
with any other system you can break it

1290
00:54:40,430 --> 00:54:45,618
you can hack it you can attack it with

1291
00:54:43,220 --> 00:54:47,930
that I want to acknowledge the other

1292
00:54:45,619 --> 00:54:50,089
people on our team that done much of

1293
00:54:47,930 --> 00:54:53,058
this research Oh melody Dennis Tracy

1294
00:54:50,089 --> 00:54:54,650
Adele Sapir and Oleg I'll give you some

1295
00:54:53,059 --> 00:54:59,029
references for light reading for later

1296
00:54:54,650 --> 00:54:59,359
and I would challenge you what to do

1297
00:54:59,029 --> 00:55:01,069
next

1298
00:54:59,359 --> 00:55:02,690
come and talk to us we are here we're

1299
00:55:01,069 --> 00:55:04,160
going to be here today and tomorrow and

1300
00:55:02,690 --> 00:55:12,010
with that

1301
00:55:04,160 --> 00:55:12,009
[Applause]

1302
00:55:18,720 --> 00:55:21,839
[Music]

1303
00:55:24,050 --> 00:55:27,209
[Music]

