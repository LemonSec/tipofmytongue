1
00:00:06,899 --> 00:00:09,080
foreign

2
00:00:53,660 --> 00:00:55,739
thank you for coming I know it's late on

3
00:00:55,739 --> 00:00:57,480
a Friday and uh you guys are like the

4
00:00:57,480 --> 00:01:00,719
real hardcore fans so uh props to you so

5
00:01:00,719 --> 00:01:02,340
my name is Arthur I manage one of the

6
00:01:02,340 --> 00:01:03,899
product security teams at Ping Identity

7
00:01:03,899 --> 00:01:08,220
we do IAM and SSO things before I was a

8
00:01:08,220 --> 00:01:10,200
manager I was a developer for for a few

9
00:01:10,200 --> 00:01:11,580
years and I worked in security after

10
00:01:11,580 --> 00:01:14,400
that but before all that I was I studied

11
00:01:14,400 --> 00:01:16,860
math in college and so this is kind of

12
00:01:16,860 --> 00:01:18,299
an amalgamation of all the things that

13
00:01:18,299 --> 00:01:20,159
I've learned over time to build a

14
00:01:20,159 --> 00:01:22,820
management tool

15
00:01:23,280 --> 00:01:23,939
um

16
00:01:23,939 --> 00:01:27,960
so uh uh back in 2019 I was at rmisc

17
00:01:27,960 --> 00:01:29,880
which was a conference out in Denver and

18
00:01:29,880 --> 00:01:32,580
the keynote speaker was uh Miko hipponen

19
00:01:32,580 --> 00:01:35,100
who is the head of research for a

20
00:01:35,100 --> 00:01:37,200
company called f-secure

21
00:01:37,200 --> 00:01:39,420
he had a big slide in during his keynote

22
00:01:39,420 --> 00:01:41,759
uh of a bunch of tires burning

23
00:01:41,759 --> 00:01:44,100
perpetually and he said in security when

24
00:01:44,100 --> 00:01:47,159
we do our jobs right nothing happens I

25
00:01:47,159 --> 00:01:48,720
just gotten promoted to management and

26
00:01:48,720 --> 00:01:50,939
my job is literally to make the people

27
00:01:50,939 --> 00:01:53,460
on my team successful and when you hear

28
00:01:53,460 --> 00:01:55,020
something like that it's a problem that

29
00:01:55,020 --> 00:01:57,360
you shouldn't ignore so at that time I

30
00:01:57,360 --> 00:01:58,320
started thinking about the different

31
00:01:58,320 --> 00:02:00,600
ways I could improve there and uh and

32
00:02:00,600 --> 00:02:03,540
this is one of the one of the Avenues

33
00:02:03,540 --> 00:02:06,200
that we went down

34
00:02:07,380 --> 00:02:09,000
um a word about product security real

35
00:02:09,000 --> 00:02:12,599
quick we uh we have two main functions

36
00:02:12,599 --> 00:02:14,280
in my in my opinion we have two main

37
00:02:14,280 --> 00:02:16,260
missions uh the first one is to enable

38
00:02:16,260 --> 00:02:18,540
the business to sell things and the

39
00:02:18,540 --> 00:02:20,459
other one is for us to reduce how much

40
00:02:20,459 --> 00:02:22,260
money the business loses due to security

41
00:02:22,260 --> 00:02:24,780
issues against our products

42
00:02:24,780 --> 00:02:27,599
uh the first uh Mission sort of takes a

43
00:02:27,599 --> 00:02:30,300
form of compliance Frameworks uh so

44
00:02:30,300 --> 00:02:32,459
compliance is essentially as far as I

45
00:02:32,459 --> 00:02:34,860
can tell a protocol for trust between

46
00:02:34,860 --> 00:02:37,260
two parties that don't know each other

47
00:02:37,260 --> 00:02:39,120
that can be implemented by a third party

48
00:02:39,120 --> 00:02:42,000
that's impartial to the to the deal and

49
00:02:42,000 --> 00:02:44,040
then on the other side we reduce how

50
00:02:44,040 --> 00:02:45,660
much money uh the company loses

51
00:02:45,660 --> 00:02:47,700
sometimes it's called shift left at a in

52
00:02:47,700 --> 00:02:49,200
my opinion it's a rudimentary approach

53
00:02:49,200 --> 00:02:53,238
but uh but that's one way to look at it

54
00:02:55,800 --> 00:02:58,019
so a quick agenda uh we're going to talk

55
00:02:58,019 --> 00:02:59,459
a little bit more about uh the

56
00:02:59,459 --> 00:03:01,140
background of the material in this talk

57
00:03:01,140 --> 00:03:03,000
we're going to talk about stride and how

58
00:03:03,000 --> 00:03:05,760
that uh how that how we do it and what

59
00:03:05,760 --> 00:03:07,560
some of the shortcomings are we're going

60
00:03:07,560 --> 00:03:09,319
to talk about fair and some of the

61
00:03:09,319 --> 00:03:11,340
quantitative risk methods that we can

62
00:03:11,340 --> 00:03:13,080
use from there we'll talk about Monte

63
00:03:13,080 --> 00:03:14,760
Carlo simulations and then I'll close up

64
00:03:14,760 --> 00:03:16,980
with a demo to show y'all how this stuff

65
00:03:16,980 --> 00:03:19,860
works in a mock sort of practice threat

66
00:03:19,860 --> 00:03:22,040
model

67
00:03:23,760 --> 00:03:26,760
foreign

68
00:03:28,819 --> 00:03:31,620
these are three main resources that I

69
00:03:31,620 --> 00:03:35,640
base this uh uh this material on

70
00:03:35,640 --> 00:03:37,739
on the top left and this is uh the

71
00:03:37,739 --> 00:03:40,080
Genesis of uh of where this all started

72
00:03:40,080 --> 00:03:43,080
uh Clint Gibbler gave a keynote at

73
00:03:43,080 --> 00:03:45,540
B-side San Francisco back in 2020 uh

74
00:03:45,540 --> 00:03:47,819
before everything shut down uh called

75
00:03:47,819 --> 00:03:49,560
how to 10x your security without the

76
00:03:49,560 --> 00:03:51,239
series d

77
00:03:51,239 --> 00:03:54,120
um that talk is mostly about how to

78
00:03:54,120 --> 00:03:55,560
scalably reduce the risk of your

79
00:03:55,560 --> 00:03:57,180
applications

80
00:03:57,180 --> 00:04:00,599
um he was he circled it all into

81
00:04:00,599 --> 00:04:02,459
um essentially writing some grep rules

82
00:04:02,459 --> 00:04:04,200
to remove bug classes from your from

83
00:04:04,200 --> 00:04:06,659
your code base the idea behind that is

84
00:04:06,659 --> 00:04:08,519
that if you spend 10 of your time

85
00:04:08,519 --> 00:04:10,439
triaging cross-site scripting findings

86
00:04:10,439 --> 00:04:12,900
and you remove cross-site scripting from

87
00:04:12,900 --> 00:04:14,819
your uh from your code base then you

88
00:04:14,819 --> 00:04:17,699
gain 10 of time to do other stuff

89
00:04:17,699 --> 00:04:19,320
um it can be some grep rules it can be

90
00:04:19,320 --> 00:04:20,880
Frameworks that are secure by default it

91
00:04:20,880 --> 00:04:22,079
doesn't really matter

92
00:04:22,079 --> 00:04:24,419
but that's the general idea of it and so

93
00:04:24,419 --> 00:04:26,520
if we go back to what Mikko said earlier

94
00:04:26,520 --> 00:04:29,580
oh great I actually have like a path to

95
00:04:29,580 --> 00:04:32,100
to make things

96
00:04:32,100 --> 00:04:34,560
um to put my team uh on a trail that

97
00:04:34,560 --> 00:04:36,240
goes upwards rather than all over the

98
00:04:36,240 --> 00:04:38,360
place

99
00:04:39,360 --> 00:04:42,240
um then that prompted me to realize that

100
00:04:42,240 --> 00:04:43,860
I don't actually know what the hell risk

101
00:04:43,860 --> 00:04:45,840
is or how to measure it or how to do

102
00:04:45,840 --> 00:04:47,759
anything with it so I grabbed that book

103
00:04:47,759 --> 00:04:49,320
on the right I actually picked up the

104
00:04:49,320 --> 00:04:51,060
audiobook which is like nine bucks

105
00:04:51,060 --> 00:04:52,500
probably the best nine bucks I ever

106
00:04:52,500 --> 00:04:54,360
spent for my career

107
00:04:54,360 --> 00:04:55,680
um but it's called how to measure

108
00:04:55,680 --> 00:04:57,660
anything in cyber security risk it's

109
00:04:57,660 --> 00:04:59,460
written by uh Doug Hubbard and Richard

110
00:04:59,460 --> 00:05:01,259
searson

111
00:05:01,259 --> 00:05:03,479
it's basically a textbook about how to

112
00:05:03,479 --> 00:05:05,759
use quantitative methods to uh to

113
00:05:05,759 --> 00:05:07,320
express risks to express the risk

114
00:05:07,320 --> 00:05:10,199
posture of your Enterprise they're very

115
00:05:10,199 --> 00:05:12,360
much uh scoped to the whole Enterprise

116
00:05:12,360 --> 00:05:15,300
so it's more of a CSO view for them

117
00:05:15,300 --> 00:05:17,040
um but this is this is the the

118
00:05:17,040 --> 00:05:18,660
foundation of all the all the little

119
00:05:18,660 --> 00:05:20,340
tools that you need to to make this

120
00:05:20,340 --> 00:05:21,660
thing work

121
00:05:21,660 --> 00:05:23,400
and of course at the bottom left there

122
00:05:23,400 --> 00:05:26,240
you have Fair U which is sort of a more

123
00:05:26,240 --> 00:05:29,280
distilled elegant like you get 80 of the

124
00:05:29,280 --> 00:05:31,979
value for 20 of the effort type thing

125
00:05:31,979 --> 00:05:33,600
um which is really really excellent I

126
00:05:33,600 --> 00:05:35,220
highly recommend it for anybody who

127
00:05:35,220 --> 00:05:38,120
wants to give this thing a shot

128
00:05:41,419 --> 00:05:43,680
so let's talk a little bit about stride

129
00:05:43,680 --> 00:05:46,620
uh stride was originated in the early

130
00:05:46,620 --> 00:05:49,080
2000s at Microsoft as a part of their

131
00:05:49,080 --> 00:05:51,120
secure Computing initiatives

132
00:05:51,120 --> 00:05:52,620
um for those of you who haven't used it

133
00:05:52,620 --> 00:05:54,300
it's basically a framework for threat

134
00:05:54,300 --> 00:05:56,280
modeling there are many Frameworks out

135
00:05:56,280 --> 00:05:57,840
there for threat modeling they're more

136
00:05:57,840 --> 00:05:59,940
art sort of more artistic approaches to

137
00:05:59,940 --> 00:06:00,960
it as well

138
00:06:00,960 --> 00:06:02,580
but this is great if you're running a

139
00:06:02,580 --> 00:06:03,900
team and if you want to do something

140
00:06:03,900 --> 00:06:06,539
repeatable at a at a scale of more than

141
00:06:06,539 --> 00:06:08,520
like two people

142
00:06:08,520 --> 00:06:10,500
um essentially what you do is you build

143
00:06:10,500 --> 00:06:12,120
a data flow diagram of the application

144
00:06:12,120 --> 00:06:14,759
that you want to model threats for you

145
00:06:14,759 --> 00:06:17,699
draw trust boundaries and processes and

146
00:06:17,699 --> 00:06:21,000
data stores and data flowing with arrows

147
00:06:21,000 --> 00:06:22,800
to and from different processes there's

148
00:06:22,800 --> 00:06:24,419
areas where things are trusted there's

149
00:06:24,419 --> 00:06:26,520
web browsers Etc but essentially you

150
00:06:26,520 --> 00:06:28,199
come up with a logical construction of

151
00:06:28,199 --> 00:06:30,600
your application that you can look at

152
00:06:30,600 --> 00:06:32,940
and then you model threats based on on

153
00:06:32,940 --> 00:06:34,380
the stride acronym so you'll look for

154
00:06:34,380 --> 00:06:36,900
threats pertinent to spoofing tampering

155
00:06:36,900 --> 00:06:38,819
repudiation information disclosure

156
00:06:38,819 --> 00:06:40,740
denial of service and elevation of

157
00:06:40,740 --> 00:06:42,240
privilege and so you'll basically look

158
00:06:42,240 --> 00:06:43,919
for things that can go wrong that would

159
00:06:43,919 --> 00:06:45,600
fit in those buckets and you enumerate

160
00:06:45,600 --> 00:06:47,400
them

161
00:06:47,400 --> 00:06:50,340
once you're done with that you have

162
00:06:50,340 --> 00:06:52,199
um you have a list of stuff and you have

163
00:06:52,199 --> 00:06:54,660
to order it somehow and so most of the

164
00:06:54,660 --> 00:06:56,520
time across the industry we order them

165
00:06:56,520 --> 00:06:58,020
as critical high medium low

166
00:06:58,020 --> 00:07:00,479
informational but these are all cbss

167
00:07:00,479 --> 00:07:03,240
score computations or some permutation

168
00:07:03,240 --> 00:07:05,100
of that

169
00:07:05,100 --> 00:07:06,840
basically what you do if you're being

170
00:07:06,840 --> 00:07:08,699
really formal about it is you go to the

171
00:07:08,699 --> 00:07:10,680
nist calculator you click on a bunch of

172
00:07:10,680 --> 00:07:13,020
buttons about attack complexity and uh

173
00:07:13,020 --> 00:07:14,699
you know what you do you have to be on

174
00:07:14,699 --> 00:07:16,560
the box is it a network thing is the

175
00:07:16,560 --> 00:07:18,600
impact on confidentiality availability

176
00:07:18,600 --> 00:07:20,880
and integrity high medium or low

177
00:07:20,880 --> 00:07:23,699
and then it spits out a cbss score

178
00:07:23,699 --> 00:07:26,280
and the CBS escort then gets mapped to

179
00:07:26,280 --> 00:07:30,559
an ordinal scale of high medium low

180
00:07:33,660 --> 00:07:35,460
so that's supposed to be giving us some

181
00:07:35,460 --> 00:07:37,199
priority right

182
00:07:37,199 --> 00:07:38,759
um but it's very difficult to do algebra

183
00:07:38,759 --> 00:07:40,860
on ordinal scales so it's very difficult

184
00:07:40,860 --> 00:07:45,120
to compare two highs together so that is

185
00:07:45,120 --> 00:07:47,220
um remote code execution due to xxe

186
00:07:47,220 --> 00:07:49,020
something you should spend your time

187
00:07:49,020 --> 00:07:51,180
fixing or should you be fixing Json

188
00:07:51,180 --> 00:07:53,580
digitalization issues which one which

189
00:07:53,580 --> 00:07:55,319
one actually matters more and it's not

190
00:07:55,319 --> 00:07:57,120
possible to answer with uh with that

191
00:07:57,120 --> 00:07:58,199
type of scale

192
00:07:58,199 --> 00:08:00,060
it's really good at saying that a high

193
00:08:00,060 --> 00:08:01,860
is higher than a medium and that a

194
00:08:01,860 --> 00:08:04,259
medium is higher than a low but how do

195
00:08:04,259 --> 00:08:06,660
you combine 50 lows together right

196
00:08:06,660 --> 00:08:09,300
should we be spending our time fixing 10

197
00:08:09,300 --> 00:08:13,440
highs or 10 mediums or 5 000 lows

198
00:08:13,440 --> 00:08:15,539
it's not possible

199
00:08:15,539 --> 00:08:17,880
um a lot of the compliance Frameworks

200
00:08:17,880 --> 00:08:19,919
that that we deal with and a lot of what

201
00:08:19,919 --> 00:08:21,599
I've seen in the industry has been very

202
00:08:21,599 --> 00:08:23,759
much okay we're going to look at all

203
00:08:23,759 --> 00:08:25,319
your risk register with the list of all

204
00:08:25,319 --> 00:08:27,240
the things that can go wrong and we're

205
00:08:27,240 --> 00:08:28,560
just going to address the highs and if

206
00:08:28,560 --> 00:08:30,660
we get to the other ones awesome but we

207
00:08:30,660 --> 00:08:33,059
just really care about the highs

208
00:08:33,059 --> 00:08:35,520
it's hard to blame people to take that

209
00:08:35,520 --> 00:08:37,260
approach because that's pretty much what

210
00:08:37,260 --> 00:08:39,679
you're given

211
00:08:42,360 --> 00:08:43,919
I had to drive this point home a little

212
00:08:43,919 --> 00:08:45,959
bit further uh Bishop Fox this year put

213
00:08:45,959 --> 00:08:47,459
out this e-book called the wolf in

214
00:08:47,459 --> 00:08:48,839
sheep's clothing

215
00:08:48,839 --> 00:08:51,060
um it's basically a

216
00:08:51,060 --> 00:08:53,880
a story not a story but a a compilation

217
00:08:53,880 --> 00:08:55,860
of bad things that their Consultants did

218
00:08:55,860 --> 00:08:58,080
with a chain of lows so as it turns out

219
00:08:58,080 --> 00:08:59,519
if you have a bunch of lows you can do

220
00:08:59,519 --> 00:09:01,320
bad stuff which means that there is in

221
00:09:01,320 --> 00:09:02,940
fact something that we combine you know

222
00:09:02,940 --> 00:09:04,380
sometimes called the Cyber kill chain

223
00:09:04,380 --> 00:09:06,600
but there is a way to combine these

224
00:09:06,600 --> 00:09:08,399
things at the application layer that

225
00:09:08,399 --> 00:09:10,560
actually causes an impact so ignoring

226
00:09:10,560 --> 00:09:14,479
5000 lows is probably not a good idea

227
00:09:17,959 --> 00:09:22,800
so how can we attempt to do better

228
00:09:22,800 --> 00:09:24,180
um well the approach we're going to take

229
00:09:24,180 --> 00:09:26,339
today is that we're going to

230
00:09:26,339 --> 00:09:28,200
um we're going to analyze our threats

231
00:09:28,200 --> 00:09:30,240
based on the impact that they have on

232
00:09:30,240 --> 00:09:32,339
the business rather than the impact that

233
00:09:32,339 --> 00:09:34,500
they have on applications

234
00:09:34,500 --> 00:09:37,019
so CVSs score looks at what the impact

235
00:09:37,019 --> 00:09:38,760
is to the application are you able to

236
00:09:38,760 --> 00:09:41,220
elevate privileges are you able to have

237
00:09:41,220 --> 00:09:43,200
remote remote code execution are you

238
00:09:43,200 --> 00:09:44,519
able to deny the service of the

239
00:09:44,519 --> 00:09:46,320
application the way we're going to

240
00:09:46,320 --> 00:09:48,360
consider this is with the dollars

241
00:09:48,360 --> 00:09:51,360
Associated the dollars lost associated

242
00:09:51,360 --> 00:09:54,360
with each one of the threats

243
00:09:54,360 --> 00:09:58,380
so there's a tiered approach to this we

244
00:09:58,380 --> 00:10:00,360
have to look inward at our program and

245
00:10:00,360 --> 00:10:01,920
inward at our company and how it

246
00:10:01,920 --> 00:10:04,440
operates for us to be able to to model

247
00:10:04,440 --> 00:10:07,019
our uh our threats in this way

248
00:10:07,019 --> 00:10:08,700
so

249
00:10:08,700 --> 00:10:09,300
um

250
00:10:09,300 --> 00:10:12,839
I have an opsec team uh there are things

251
00:10:12,839 --> 00:10:14,760
that are reported to us right it can

252
00:10:14,760 --> 00:10:17,279
come from external uh pen testers it can

253
00:10:17,279 --> 00:10:18,779
come from customers it can come from

254
00:10:18,779 --> 00:10:20,880
tools it can come from bug Bounty

255
00:10:20,880 --> 00:10:22,560
programs it can come from wherever

256
00:10:22,560 --> 00:10:24,839
and our team takes it in

257
00:10:24,839 --> 00:10:27,600
we apply our expertise of the pro of the

258
00:10:27,600 --> 00:10:29,519
products that we oversee as well as our

259
00:10:29,519 --> 00:10:31,560
expertise of the of the bug classes that

260
00:10:31,560 --> 00:10:34,380
were that are being reported and uh then

261
00:10:34,380 --> 00:10:36,240
we say oh okay this one's not a problem

262
00:10:36,240 --> 00:10:38,100
and this one is a problem and then we

263
00:10:38,100 --> 00:10:40,260
triage it that way and we pass it to a

264
00:10:40,260 --> 00:10:42,060
remediation team the remediation team is

265
00:10:42,060 --> 00:10:43,740
going to go spend some time and

266
00:10:43,740 --> 00:10:46,380
therefore some money on fixing the issue

267
00:10:46,380 --> 00:10:47,820
and then there's going to be some QA

268
00:10:47,820 --> 00:10:49,800
cycles and then there's going to be some

269
00:10:49,800 --> 00:10:51,839
Cycles to make a release happen and then

270
00:10:51,839 --> 00:10:53,519
there might be some documentation Cycles

271
00:10:53,519 --> 00:10:55,320
you may have to alert your customers

272
00:10:55,320 --> 00:10:57,000
saying hey we had a problem with this

273
00:10:57,000 --> 00:10:59,279
thing but it was fixed here's a KB that

274
00:10:59,279 --> 00:11:01,019
tells you how we fixed it you know

275
00:11:01,019 --> 00:11:02,579
there's a whole array of things that

276
00:11:02,579 --> 00:11:04,740
that can happen anytime a finding is

277
00:11:04,740 --> 00:11:07,200
reported but sometimes the finding is

278
00:11:07,200 --> 00:11:09,120
reported and the security team takes it

279
00:11:09,120 --> 00:11:11,040
in and goes yeah we don't care we know

280
00:11:11,040 --> 00:11:12,360
about the compensating control we don't

281
00:11:12,360 --> 00:11:14,940
care and so depending on

282
00:11:14,940 --> 00:11:17,940
the maturity of your program and uh and

283
00:11:17,940 --> 00:11:19,740
the different uh vulnerabilities that

284
00:11:19,740 --> 00:11:21,839
are reported you may or may not spend

285
00:11:21,839 --> 00:11:24,120
the full amount of money you may spend

286
00:11:24,120 --> 00:11:25,740
only a subset of it

287
00:11:25,740 --> 00:11:26,940
and so this is how we're going to

288
00:11:26,940 --> 00:11:30,980
approach our uh our prioritization

289
00:11:34,459 --> 00:11:37,019
thank you

290
00:11:37,019 --> 00:11:39,180
so let's talk about Fair

291
00:11:39,180 --> 00:11:41,880
um fair is a very very elegant way to

292
00:11:41,880 --> 00:11:44,339
model risk and all this stuff is you can

293
00:11:44,339 --> 00:11:46,380
Google for this it's like the fair the

294
00:11:46,380 --> 00:11:47,640
fair breakdown

295
00:11:47,640 --> 00:11:49,019
um but it stands for factory analysis

296
00:11:49,019 --> 00:11:51,500
and information risk so it's a way of

297
00:11:51,500 --> 00:11:54,540
decomposing a risk into smaller pieces

298
00:11:54,540 --> 00:11:56,760
so if you don't have enough information

299
00:11:56,760 --> 00:11:58,140
to

300
00:11:58,140 --> 00:11:58,980
um

301
00:11:58,980 --> 00:12:00,480
to be able to assess the risk of

302
00:12:00,480 --> 00:12:03,660
something you are given smaller uh bits

303
00:12:03,660 --> 00:12:05,459
that you can get information on and

304
00:12:05,459 --> 00:12:08,220
recompose those into the risk

305
00:12:08,220 --> 00:12:10,380
um there's a dotted line there which is

306
00:12:10,380 --> 00:12:12,480
not part of the fair framework but I put

307
00:12:12,480 --> 00:12:14,519
it there if you're able to decompose

308
00:12:14,519 --> 00:12:16,560
risk into a loss event frequency and a

309
00:12:16,560 --> 00:12:17,820
loss magnitude

310
00:12:17,820 --> 00:12:19,680
in a way that

311
00:12:19,680 --> 00:12:21,240
um trustworthy

312
00:12:21,240 --> 00:12:22,560
then you don't have to go any further

313
00:12:22,560 --> 00:12:24,779
down but if you can't because you either

314
00:12:24,779 --> 00:12:26,640
don't have the data or because you don't

315
00:12:26,640 --> 00:12:28,500
have the smes or because you don't have

316
00:12:28,500 --> 00:12:29,579
the relationships with the business

317
00:12:29,579 --> 00:12:31,260
owners to figure out how much things

318
00:12:31,260 --> 00:12:33,600
cost then you can go and break things

319
00:12:33,600 --> 00:12:36,920
down further if you need to

320
00:12:40,680 --> 00:12:41,880
so

321
00:12:41,880 --> 00:12:43,980
um risk at its most basic is broken down

322
00:12:43,980 --> 00:12:45,420
into loss of end frequency and lost

323
00:12:45,420 --> 00:12:47,040
magnitude I'm quickly going to talk

324
00:12:47,040 --> 00:12:48,540
about lost magnitude and then I'll move

325
00:12:48,540 --> 00:12:51,180
over to the last event frequency side

326
00:12:51,180 --> 00:12:53,339
uh loss magnitude is essentially how

327
00:12:53,339 --> 00:12:56,700
much money you're going to be losing uh

328
00:12:56,700 --> 00:12:58,139
it's an estimate and everything we're

329
00:12:58,139 --> 00:13:00,060
giving here are estimations and there

330
00:13:00,060 --> 00:13:01,860
are ways to calibrate your estimators so

331
00:13:01,860 --> 00:13:03,120
that they can give you good estimations

332
00:13:03,120 --> 00:13:05,940
there's a way to measure uh whether or

333
00:13:05,940 --> 00:13:08,100
not your estimators are are giving you

334
00:13:08,100 --> 00:13:10,019
good estimates and all that is covered

335
00:13:10,019 --> 00:13:11,880
in how to measure everything in cyber

336
00:13:11,880 --> 00:13:13,019
security risk I'm not going to talk

337
00:13:13,019 --> 00:13:14,459
about it here because it would take

338
00:13:14,459 --> 00:13:16,260
hours

339
00:13:16,260 --> 00:13:18,959
lost magnitude is as I said the number

340
00:13:18,959 --> 00:13:20,760
of dollars that you're going to use this

341
00:13:20,760 --> 00:13:22,740
is always expressed as a 90 confidence

342
00:13:22,740 --> 00:13:24,480
interval here

343
00:13:24,480 --> 00:13:26,459
um and this is just based on uh the way

344
00:13:26,459 --> 00:13:28,560
that fair uh has set the standard for

345
00:13:28,560 --> 00:13:30,000
this

346
00:13:30,000 --> 00:13:31,680
um a confidence interval is an interval

347
00:13:31,680 --> 00:13:34,320
of uh dollars that can be lost that

348
00:13:34,320 --> 00:13:36,240
you're 90 of the time that you're

349
00:13:36,240 --> 00:13:37,560
confident that ninety percent of the

350
00:13:37,560 --> 00:13:39,779
time the value that's going to happen

351
00:13:39,779 --> 00:13:41,579
actually in the next year is going to

352
00:13:41,579 --> 00:13:43,079
fall within that interval and you

353
00:13:43,079 --> 00:13:44,940
account for five percent of outliers on

354
00:13:44,940 --> 00:13:47,040
each side of that

355
00:13:47,040 --> 00:13:48,899
so if I ask somebody in Austin to

356
00:13:48,899 --> 00:13:50,519
estimate how much the price of a gallon

357
00:13:50,519 --> 00:13:52,560
of gas is going to be in 12 months you

358
00:13:52,560 --> 00:13:54,200
can say oh it'll be

359
00:13:54,200 --> 00:13:57,180
3.53 but you're going to be wrong a lot

360
00:13:57,180 --> 00:13:59,519
of the time because it could be 352 it

361
00:13:59,519 --> 00:14:01,980
could be 270 it can be three I mean

362
00:14:01,980 --> 00:14:03,180
there's a whole bunch of values there

363
00:14:03,180 --> 00:14:05,519
however if you say it'll be somewhere in

364
00:14:05,519 --> 00:14:06,420
the

365
00:14:06,420 --> 00:14:09,180
um I'm 90 sure that it'll be between 150

366
00:14:09,180 --> 00:14:11,940
and 425. you can say all right that's a

367
00:14:11,940 --> 00:14:14,040
good range maybe maybe I'm a little bit

368
00:14:14,040 --> 00:14:15,660
off on the numbers but that that's

369
00:14:15,660 --> 00:14:17,880
that's the point it's a good range where

370
00:14:17,880 --> 00:14:19,740
unless there's another sort of

371
00:14:19,740 --> 00:14:21,480
geopolitical issue that happens that

372
00:14:21,480 --> 00:14:23,040
pushes it in One Direction or the other

373
00:14:23,040 --> 00:14:25,139
or another pandemic or whatever

374
00:14:25,139 --> 00:14:27,420
it's probably going to be in that range

375
00:14:27,420 --> 00:14:28,920
and so that's what we're seeking with

376
00:14:28,920 --> 00:14:30,720
the Lost magnitude

377
00:14:30,720 --> 00:14:32,700
that's broken down into primary losses

378
00:14:32,700 --> 00:14:35,100
and secondary losses so primary losses

379
00:14:35,100 --> 00:14:36,899
are losses that are inflicted on the

380
00:14:36,899 --> 00:14:39,180
business by itself so when we talk about

381
00:14:39,180 --> 00:14:40,980
engineering Cycles to go fix something

382
00:14:40,980 --> 00:14:43,680
that's a primary loss because they're

383
00:14:43,680 --> 00:14:45,720
not able to spend time building features

384
00:14:45,720 --> 00:14:48,839
that would then bring Revenue in

385
00:14:48,839 --> 00:14:50,760
a secondary loss is a loss that's

386
00:14:50,760 --> 00:14:53,579
incurred by the business due to external

387
00:14:53,579 --> 00:14:56,820
pressures so these could be gdpr fines

388
00:14:56,820 --> 00:14:59,699
they can be PR campaigns you have to put

389
00:14:59,699 --> 00:15:02,100
out to restore confidence the market has

390
00:15:02,100 --> 00:15:05,100
in you or your customers have in you all

391
00:15:05,100 --> 00:15:06,839
those things that are sort of inflicted

392
00:15:06,839 --> 00:15:09,240
upon you are secondary losses and that's

393
00:15:09,240 --> 00:15:10,680
further broken down at the loss of then

394
00:15:10,680 --> 00:15:13,760
frequency and magnitude

395
00:15:16,399 --> 00:15:18,779
on the other side we have loss event

396
00:15:18,779 --> 00:15:20,820
frequency now this is the probability

397
00:15:20,820 --> 00:15:22,920
that an event that will cause a loss

398
00:15:22,920 --> 00:15:25,560
over the next 12 months will occur

399
00:15:25,560 --> 00:15:28,260
so the reason we pick 12 months is

400
00:15:28,260 --> 00:15:31,019
because for because it's a reasonable

401
00:15:31,019 --> 00:15:33,060
time frame for us to build some

402
00:15:33,060 --> 00:15:34,680
initiatives and then go act on those

403
00:15:34,680 --> 00:15:37,680
initiatives and it's also what uh What

404
00:15:37,680 --> 00:15:40,079
uh Hubbard and searson recommend

405
00:15:40,079 --> 00:15:42,240
it's very important to time box this

406
00:15:42,240 --> 00:15:43,740
because the probability that your

407
00:15:43,740 --> 00:15:45,000
company is going to get owned tomorrow

408
00:15:45,000 --> 00:15:47,040
is very close to zero but the

409
00:15:47,040 --> 00:15:48,240
probability that your company is going

410
00:15:48,240 --> 00:15:50,220
to get on the next 15 years is close to

411
00:15:50,220 --> 00:15:53,160
100. so it's very important to time box

412
00:15:53,160 --> 00:15:54,899
that portion of it and we're going to be

413
00:15:54,899 --> 00:15:57,120
looking at it at a 12-month period

414
00:15:57,120 --> 00:16:00,600
for the purposes of this as well

415
00:16:00,600 --> 00:16:02,579
lost event frequency is broken down into

416
00:16:02,579 --> 00:16:04,199
threat event frequency and vulnerability

417
00:16:04,199 --> 00:16:06,600
threat event frequency is the frequency

418
00:16:06,600 --> 00:16:08,279
with which you see events that are

419
00:16:08,279 --> 00:16:09,839
threatening to you so maybe you see a

420
00:16:09,839 --> 00:16:11,940
cross-site scripting payload

421
00:16:11,940 --> 00:16:13,500
um and maybe you have appropriate

422
00:16:13,500 --> 00:16:15,480
defenses against that you see the

423
00:16:15,480 --> 00:16:17,880
payload nothing happens because you have

424
00:16:17,880 --> 00:16:19,740
a secure by default framework and

425
00:16:19,740 --> 00:16:21,660
therefore that threat doesn't convert up

426
00:16:21,660 --> 00:16:23,220
to a loss

427
00:16:23,220 --> 00:16:25,500
that brings me to the concept of

428
00:16:25,500 --> 00:16:27,420
vulnerability which is broken down into

429
00:16:27,420 --> 00:16:28,980
the threat capability and resistance

430
00:16:28,980 --> 00:16:31,380
strength so if you've taken the time and

431
00:16:31,380 --> 00:16:32,639
by the way vulnerability here is

432
00:16:32,639 --> 00:16:34,740
described or is defined differently from

433
00:16:34,740 --> 00:16:36,740
how we what we call a security bug

434
00:16:36,740 --> 00:16:38,820
vulnerability here is the relationship

435
00:16:38,820 --> 00:16:41,040
between the strength of our controls

436
00:16:41,040 --> 00:16:44,399
versus the strength of the threat actors

437
00:16:44,399 --> 00:16:47,639
against those controls so in the in the

438
00:16:47,639 --> 00:16:49,380
example of the WAFF

439
00:16:49,380 --> 00:16:51,180
if you've taken the time to put a WAFF

440
00:16:51,180 --> 00:16:53,579
in place and have appropriate rules to

441
00:16:53,579 --> 00:16:56,279
stop gndi payloads

442
00:16:56,279 --> 00:16:57,839
um that increases your resistance

443
00:16:57,839 --> 00:17:00,120
strength on the right side of that while

444
00:17:00,120 --> 00:17:02,639
uh addressing the threat capabilities so

445
00:17:02,639 --> 00:17:04,799
the vulnerability is the capability

446
00:17:04,799 --> 00:17:06,599
essentially to convert a threat event

447
00:17:06,599 --> 00:17:09,500
into a loss event

448
00:17:10,740 --> 00:17:12,419
threat of end frequency is broken down

449
00:17:12,419 --> 00:17:13,980
into contact frequency and probability

450
00:17:13,980 --> 00:17:16,859
of action so contact frequency is how

451
00:17:16,859 --> 00:17:18,419
many times a threat actor is making

452
00:17:18,419 --> 00:17:20,099
contact with your asset so maybe

453
00:17:20,099 --> 00:17:21,900
somebody's doing some basic Recon

454
00:17:21,900 --> 00:17:23,220
they're going through your website

455
00:17:23,220 --> 00:17:25,679
they're signing up for a trial account

456
00:17:25,679 --> 00:17:27,419
or whatever it all looks like normal

457
00:17:27,419 --> 00:17:28,439
traffic

458
00:17:28,439 --> 00:17:30,540
that's contact frequency

459
00:17:30,540 --> 00:17:32,820
probability of action is the conversion

460
00:17:32,820 --> 00:17:35,039
of those contacts into threat events so

461
00:17:35,039 --> 00:17:38,160
as soon as they decide okay I've looked

462
00:17:38,160 --> 00:17:39,720
around the website I found that there's

463
00:17:39,720 --> 00:17:41,340
an input field here that's interesting

464
00:17:41,340 --> 00:17:42,900
I'm going to put a payload and see if it

465
00:17:42,900 --> 00:17:44,820
does something that converts into a

466
00:17:44,820 --> 00:17:46,679
threat and then based on your controls

467
00:17:46,679 --> 00:17:50,240
it may or may not convert up to a loss

468
00:17:55,260 --> 00:17:56,340
so

469
00:17:56,340 --> 00:17:58,320
um the estimations that we have in that

470
00:17:58,320 --> 00:18:00,720
decomposition get fed into a Monte Carlo

471
00:18:00,720 --> 00:18:02,039
simulation

472
00:18:02,039 --> 00:18:04,559
uh Monte Carlo simulations uh were

473
00:18:04,559 --> 00:18:06,480
invented during the Manhattan Project by

474
00:18:06,480 --> 00:18:10,200
John Von Neumann and stanisla ulam

475
00:18:10,200 --> 00:18:12,059
uh obviously in the Manhattan Project

476
00:18:12,059 --> 00:18:13,679
they were doing very cutting-edge stuff

477
00:18:13,679 --> 00:18:15,720
that had no historical data to base

478
00:18:15,720 --> 00:18:17,520
their uh to educate their decision

479
00:18:17,520 --> 00:18:18,480
making

480
00:18:18,480 --> 00:18:20,340
so they had to come up with a way to use

481
00:18:20,340 --> 00:18:23,640
whatever it is that they knew to educate

482
00:18:23,640 --> 00:18:25,080
decisions that they might have to make

483
00:18:25,080 --> 00:18:26,820
so that you know hydrogen bombs would

484
00:18:26,820 --> 00:18:28,080
not explode at the wrong time or

485
00:18:28,080 --> 00:18:30,199
whatever

486
00:18:30,840 --> 00:18:33,059
um they had to give they had to give

487
00:18:33,059 --> 00:18:36,059
this uh this method a name and because

488
00:18:36,059 --> 00:18:37,559
everything had to have a code name in

489
00:18:37,559 --> 00:18:38,940
The Manhattan Project they called it the

490
00:18:38,940 --> 00:18:41,220
Monte Carlo simulation after the casino

491
00:18:41,220 --> 00:18:44,280
apparently ulam's uh uncle had a

492
00:18:44,280 --> 00:18:46,260
gambling problem and so they figured

493
00:18:46,260 --> 00:18:47,700
they would use this to when they were

494
00:18:47,700 --> 00:18:49,260
done to model how much money he might

495
00:18:49,260 --> 00:18:50,580
have to borrow from the family or

496
00:18:50,580 --> 00:18:52,700
whatever

497
00:18:52,700 --> 00:18:55,020
but essentially the purpose of this is

498
00:18:55,020 --> 00:18:57,120
to take our estimations and to generate

499
00:18:57,120 --> 00:18:59,039
and simulate

500
00:18:59,039 --> 00:19:01,980
um quote unquote historical data so

501
00:19:01,980 --> 00:19:04,500
Linux time has started in 1970 that's

502
00:19:04,500 --> 00:19:05,960
about 50 years

503
00:19:05,960 --> 00:19:09,059
the infosec industry has existed from

504
00:19:09,059 --> 00:19:11,940
you know 15 to 20 years depending on who

505
00:19:11,940 --> 00:19:14,580
you ask well with this we could take

506
00:19:14,580 --> 00:19:16,080
what we know about our company and about

507
00:19:16,080 --> 00:19:17,460
our products and we can generate

508
00:19:17,460 --> 00:19:20,039
thousands of years of simulated data and

509
00:19:20,039 --> 00:19:21,360
what that means is that it's historical

510
00:19:21,360 --> 00:19:24,000
data we can use to ask questions like

511
00:19:24,000 --> 00:19:25,559
what is the probability that we're going

512
00:19:25,559 --> 00:19:27,660
to lose x amount of dollars over the

513
00:19:27,660 --> 00:19:30,020
next year

514
00:19:31,980 --> 00:19:34,020
foreign

515
00:19:34,020 --> 00:19:36,000
so the way these these simulations work

516
00:19:36,000 --> 00:19:37,440
and please pardon the axes they don't

517
00:19:37,440 --> 00:19:38,700
mean anything

518
00:19:38,700 --> 00:19:40,679
um but the way these simulations work is

519
00:19:40,679 --> 00:19:42,480
that you have a probability of an event

520
00:19:42,480 --> 00:19:45,660
occurring if the event does occur based

521
00:19:45,660 --> 00:19:47,820
on that probability then you pick a

522
00:19:47,820 --> 00:19:49,440
random Point under one of these curves

523
00:19:49,440 --> 00:19:51,059
and so these curves are log normal

524
00:19:51,059 --> 00:19:53,580
distributions they share they look

525
00:19:53,580 --> 00:19:54,600
different but they share some

526
00:19:54,600 --> 00:19:56,760
similarities in their definition the

527
00:19:56,760 --> 00:19:57,960
first one is that they have no negative

528
00:19:57,960 --> 00:19:59,580
values so you're never going to lose

529
00:19:59,580 --> 00:20:02,400
negative dollars uh the second one is

530
00:20:02,400 --> 00:20:04,020
that they have very long tails to pick

531
00:20:04,020 --> 00:20:06,299
up outlier events

532
00:20:06,299 --> 00:20:10,080
um these will be calibrated based on the

533
00:20:10,080 --> 00:20:11,280
upper and lower bounds of your

534
00:20:11,280 --> 00:20:13,380
confidence intervals that will Define

535
00:20:13,380 --> 00:20:14,940
the mean and the standard deviation of

536
00:20:14,940 --> 00:20:16,740
each one of them so they look different

537
00:20:16,740 --> 00:20:18,539
because different things cost different

538
00:20:18,539 --> 00:20:21,000
money so you can think of the black one

539
00:20:21,000 --> 00:20:22,440
as engineering site as the cost of

540
00:20:22,440 --> 00:20:24,000
engineering Cycles to implement a fix

541
00:20:24,000 --> 00:20:26,640
you can think of the blue one as bug

542
00:20:26,640 --> 00:20:28,620
Bounty payouts you can think of the red

543
00:20:28,620 --> 00:20:32,600
one as the cost of PR campaigns

544
00:20:38,340 --> 00:20:40,380
so what's the tldr for the fair stride

545
00:20:40,380 --> 00:20:42,059
method we're going to model threats with

546
00:20:42,059 --> 00:20:42,900
stride

547
00:20:42,900 --> 00:20:45,900
we're going to take those threats and

548
00:20:45,900 --> 00:20:48,059
feed the output of them into a Monte

549
00:20:48,059 --> 00:20:50,580
Carlo simulation rather than a CV a set

550
00:20:50,580 --> 00:20:53,100
of CVSs score calculators and then we're

551
00:20:53,100 --> 00:20:54,660
going to use lost exceedance curves

552
00:20:54,660 --> 00:20:56,520
which are the output of the Monte Carlo

553
00:20:56,520 --> 00:20:59,220
simulation to define a goal post a

554
00:20:59,220 --> 00:21:01,140
Baseline and a PR and measure the

555
00:21:01,140 --> 00:21:02,700
progress of how we go from the Baseline

556
00:21:02,700 --> 00:21:04,080
to the goal post and I'll show you what

557
00:21:04,080 --> 00:21:07,699
Allah succeedings curve is in just a sec

558
00:21:11,640 --> 00:21:13,440
so we're going to do a demo uh I'm going

559
00:21:13,440 --> 00:21:14,760
to show you a big spreadsheet it's going

560
00:21:14,760 --> 00:21:15,960
to look really ugly but I'll walk you

561
00:21:15,960 --> 00:21:16,980
through it

562
00:21:16,980 --> 00:21:18,299
um

563
00:21:18,299 --> 00:21:20,340
uh real quick the none of the data in

564
00:21:20,340 --> 00:21:22,679
here the threats or the loss types or

565
00:21:22,679 --> 00:21:24,120
any of that stuff are specific to Ping

566
00:21:24,120 --> 00:21:26,880
it's kind of a generalized thing uh this

567
00:21:26,880 --> 00:21:29,760
is heavily heavily heavily based on uh

568
00:21:29,760 --> 00:21:31,980
Hubbard's one for one substitution model

569
00:21:31,980 --> 00:21:34,080
and that's available for free at how to

570
00:21:34,080 --> 00:21:35,880
measureanything.com cyber security

571
00:21:35,880 --> 00:21:37,919
there's also a bunch of stuff there on

572
00:21:37,919 --> 00:21:39,419
how to calibrate your estimators and

573
00:21:39,419 --> 00:21:40,559
stuff like that it's really phenomenal

574
00:21:40,559 --> 00:21:44,299
that they make that like literally free

575
00:21:44,580 --> 00:21:46,679
I also want to give a shout out to Jack

576
00:21:46,679 --> 00:21:48,179
Jones who is nice enough to spend some

577
00:21:48,179 --> 00:21:49,500
time with me and give me some feedback

578
00:21:49,500 --> 00:21:51,179
on the model so a big thank you to Jack

579
00:21:51,179 --> 00:21:53,760
if you're watching

580
00:21:53,760 --> 00:21:55,919
uh before we hop into the demo are there

581
00:21:55,919 --> 00:21:58,760
any questions about this

582
00:22:04,799 --> 00:22:07,679
is there any type of like publicly

583
00:22:07,679 --> 00:22:09,120
available

584
00:22:09,120 --> 00:22:11,039
anything that would allow you to kind of

585
00:22:11,039 --> 00:22:13,340
average that for a good place to start

586
00:22:13,340 --> 00:22:15,179
there may be

587
00:22:15,179 --> 00:22:18,299
uh but there may not be

588
00:22:18,299 --> 00:22:19,740
um sometimes sometimes you have to

589
00:22:19,740 --> 00:22:21,299
estimate things you know sometimes you

590
00:22:21,299 --> 00:22:22,860
don't have data and you have people that

591
00:22:22,860 --> 00:22:24,419
have a lot of experience and they might

592
00:22:24,419 --> 00:22:26,580
say you know this is about what it's

593
00:22:26,580 --> 00:22:28,679
going to look like

594
00:22:28,679 --> 00:22:30,360
okay

595
00:22:30,360 --> 00:22:31,679
and that's kind of the point of this

596
00:22:31,679 --> 00:22:32,940
whole thing it's like if you don't have

597
00:22:32,940 --> 00:22:35,340
enough you can do with what you have

598
00:22:35,340 --> 00:22:37,799
and the purpose of this is not to uh to

599
00:22:37,799 --> 00:22:39,419
predict the future but it's to educate

600
00:22:39,419 --> 00:22:41,960
decision making

601
00:22:45,840 --> 00:22:48,840
nice

602
00:22:51,360 --> 00:22:52,860
is that too tiny yeah that's a little

603
00:22:52,860 --> 00:22:55,459
too small man

604
00:22:58,740 --> 00:23:00,299
is that all right like can you guys read

605
00:23:00,299 --> 00:23:01,500
that

606
00:23:01,500 --> 00:23:03,780
all right

607
00:23:03,780 --> 00:23:04,380
um

608
00:23:04,380 --> 00:23:06,539
so if you look over here in the in this

609
00:23:06,539 --> 00:23:09,900
column uh this is the index for uh

610
00:23:09,900 --> 00:23:12,960
spoofing one so we're gonna go the big

611
00:23:12,960 --> 00:23:16,080
um the big merge cells those are uh each

612
00:23:16,080 --> 00:23:17,400
one of the spoofing tampering

613
00:23:17,400 --> 00:23:19,440
repudiation information disclosure etc

614
00:23:19,440 --> 00:23:22,380
etc for uh that we found for this

615
00:23:22,380 --> 00:23:25,140
specific application uh so S1 is

616
00:23:25,140 --> 00:23:27,900
spoofing one spoofing two spoofing three

617
00:23:27,900 --> 00:23:30,299
we got a tampering one we got some

618
00:23:30,299 --> 00:23:31,919
repudiation down here some information

619
00:23:31,919 --> 00:23:35,520
disclosure some denial of service and

620
00:23:35,520 --> 00:23:37,380
some elevation of privilege

621
00:23:37,380 --> 00:23:41,900
and you'll see that these are mapped to

622
00:23:42,720 --> 00:23:43,980
these are mapped to a whole bunch of

623
00:23:43,980 --> 00:23:45,720
loss types and the loss types are the

624
00:23:45,720 --> 00:23:47,039
same for each one of the different

625
00:23:47,039 --> 00:23:48,600
threats because they're mapped to the

626
00:23:48,600 --> 00:23:50,400
processes that we have to run through as

627
00:23:50,400 --> 00:23:54,020
a company to respond to these threats

628
00:23:54,480 --> 00:23:55,919
so you'll see the security engineering

629
00:23:55,919 --> 00:24:00,059
Cycles product to go fix stuff maybe you

630
00:24:00,059 --> 00:24:01,740
have to implement stop gaps maybe you

631
00:24:01,740 --> 00:24:05,419
have to pay a bounty et cetera et cetera

632
00:24:08,460 --> 00:24:10,559
and you'll see here lower and upper

633
00:24:10,559 --> 00:24:12,600
Bound for the cost of of each one of

634
00:24:12,600 --> 00:24:15,480
these processes and the probability that

635
00:24:15,480 --> 00:24:18,860
this will occur over the next year

636
00:24:18,860 --> 00:24:21,419
uh you'll see here that this is uh this

637
00:24:21,419 --> 00:24:23,159
is saying 20

638
00:24:23,159 --> 00:24:25,020
um if we assume if we have a mature

639
00:24:25,020 --> 00:24:26,640
program and we've already done all the

640
00:24:26,640 --> 00:24:28,320
compliance stuff that we have to do to

641
00:24:28,320 --> 00:24:30,240
enable the business we're probably doing

642
00:24:30,240 --> 00:24:32,400
static analysis we're probably picking

643
00:24:32,400 --> 00:24:34,799
up all the low hanging fruit and so what

644
00:24:34,799 --> 00:24:36,240
we're seeing here is that we've

645
00:24:36,240 --> 00:24:38,640
implemented industry best practices to

646
00:24:38,640 --> 00:24:40,500
prevent all the bad stuff from happening

647
00:24:40,500 --> 00:24:44,220
but zero days exist Defcon exists black

648
00:24:44,220 --> 00:24:46,260
hat exists there's a whole bunch of

649
00:24:46,260 --> 00:24:48,659
opportunities for people to break those

650
00:24:48,659 --> 00:24:51,539
assumptions and so if you have a

651
00:24:51,539 --> 00:24:52,860
conversation with your engineering team

652
00:24:52,860 --> 00:24:54,360
about encryption and Transit maybe

653
00:24:54,360 --> 00:24:56,340
you're passing Secrets around or

654
00:24:56,340 --> 00:24:57,900
something like that in transit and they

655
00:24:57,900 --> 00:25:00,000
say oh don't worry we're we're covered

656
00:25:00,000 --> 00:25:02,820
by https it's totally reasonable but

657
00:25:02,820 --> 00:25:04,260
there is a probability that that

658
00:25:04,260 --> 00:25:05,820
assumption will be broken over the next

659
00:25:05,820 --> 00:25:07,860
year and so what you can do is say all

660
00:25:07,860 --> 00:25:09,600
right well let's go back five years

661
00:25:09,600 --> 00:25:11,400
historically or ten years whatever

662
00:25:11,400 --> 00:25:13,559
whatever sample size you have so long as

663
00:25:13,559 --> 00:25:15,059
you apply the same one to all the

664
00:25:15,059 --> 00:25:17,039
different thread types and you can say

665
00:25:17,039 --> 00:25:20,100
how many are you going and ask how many

666
00:25:20,100 --> 00:25:22,140
years has there been one or more cve

667
00:25:22,140 --> 00:25:23,940
that's been disclosed that has broken

668
00:25:23,940 --> 00:25:25,980
the confidentiality of TLS

669
00:25:25,980 --> 00:25:27,299
and then you can say all right maybe

670
00:25:27,299 --> 00:25:28,919
there were two years in the last 10

671
00:25:28,919 --> 00:25:30,539
where that happened and then you could

672
00:25:30,539 --> 00:25:32,520
say it's reasonable to estimate that

673
00:25:32,520 --> 00:25:34,260
there's a 20 chance that that'll happen

674
00:25:34,260 --> 00:25:37,100
over the next year

675
00:25:42,659 --> 00:25:44,880
and so that value is then compared to

676
00:25:44,880 --> 00:25:46,860
this value so there's a pseudo-random

677
00:25:46,860 --> 00:25:50,059
number between zero and one

678
00:25:50,059 --> 00:25:53,720
uh and if this number is greater than 20

679
00:25:53,720 --> 00:25:56,340
then nothing happens and if the number

680
00:25:56,340 --> 00:25:59,279
is less than 20 a loss occurs for that

681
00:25:59,279 --> 00:26:01,620
simulated year for that specific loss

682
00:26:01,620 --> 00:26:04,440
type for that threat

683
00:26:04,440 --> 00:26:06,779
and so you'll see here that

684
00:26:06,779 --> 00:26:08,700
the random number for all of these loss

685
00:26:08,700 --> 00:26:12,179
types here was uh 89 or 0.89

686
00:26:12,179 --> 00:26:15,000
and therefore nothing bad happened

687
00:26:15,000 --> 00:26:18,380
we didn't lose any money

688
00:26:19,260 --> 00:26:22,440
the simulation itself is kind of gross

689
00:26:22,440 --> 00:26:24,240
to look at inside of excel but I'll do

690
00:26:24,240 --> 00:26:26,580
I'll do what I can here

691
00:26:26,580 --> 00:26:28,799
uh it first does the comparison between

692
00:26:28,799 --> 00:26:31,320
the random number and uh the probability

693
00:26:31,320 --> 00:26:33,000
that we estimated so you'll see there

694
00:26:33,000 --> 00:26:36,919
between the blue and the red

695
00:26:37,320 --> 00:26:39,840
and then uh if the number is smaller

696
00:26:39,840 --> 00:26:41,820
then uh so if the randomly generated

697
00:26:41,820 --> 00:26:43,380
number is smaller than the probability

698
00:26:43,380 --> 00:26:45,539
that we estimated we're going to feed

699
00:26:45,539 --> 00:26:48,179
that into a log normal.m function which

700
00:26:48,179 --> 00:26:50,220
is the function that picks a random

701
00:26:50,220 --> 00:26:51,960
Point under the log normal curve that I

702
00:26:51,960 --> 00:26:53,640
talked about earlier that's the function

703
00:26:53,640 --> 00:26:55,320
that actually Returns the dollar value

704
00:26:55,320 --> 00:26:57,299
for you

705
00:26:57,299 --> 00:27:00,960
and you feed it a random number

706
00:27:00,960 --> 00:27:02,840
you feed it the mean

707
00:27:02,840 --> 00:27:06,480
based on the um based on the upper and

708
00:27:06,480 --> 00:27:08,279
lower bounds

709
00:27:08,279 --> 00:27:09,960
and then you

710
00:27:09,960 --> 00:27:12,000
derive the standard deviation from again

711
00:27:12,000 --> 00:27:14,100
the upper bound and lower bound

712
00:27:14,100 --> 00:27:17,580
the point the 3.29 that we're dividing

713
00:27:17,580 --> 00:27:18,720
by has to do with the confidence

714
00:27:18,720 --> 00:27:20,460
interval that we're using and depending

715
00:27:20,460 --> 00:27:21,840
on the confidence interval if you want a

716
00:27:21,840 --> 00:27:24,779
95 or 80 there's different values but

717
00:27:24,779 --> 00:27:27,900
I don't know the details of that

718
00:27:27,900 --> 00:27:30,120
and obviously nothing happens right if

719
00:27:30,120 --> 00:27:32,460
you have a random number that's greater

720
00:27:32,460 --> 00:27:34,260
than 0.2

721
00:27:34,260 --> 00:27:36,539
but if you look down here

722
00:27:36,539 --> 00:27:39,600
the random number was 0.12 there was a

723
00:27:39,600 --> 00:27:41,460
hundred percent chance of the issue

724
00:27:41,460 --> 00:27:42,419
occurring

725
00:27:42,419 --> 00:27:45,480
and that specific year we lost 22 000

726
00:27:45,480 --> 00:27:49,039
because of

727
00:27:49,620 --> 00:27:52,140
security engineering Cycles

728
00:27:52,140 --> 00:27:55,880
due to a spoofing issue

729
00:27:56,760 --> 00:27:58,919
and you'll see also that that twenty two

730
00:27:58,919 --> 00:28:01,320
thousand dollars is greater than this

731
00:28:01,320 --> 00:28:03,179
twelve thousand so

732
00:28:03,179 --> 00:28:06,480
we only calibrated the distribution we

733
00:28:06,480 --> 00:28:08,279
didn't say hey we're never going to

734
00:28:08,279 --> 00:28:10,679
we're for sure going to be less than 12

735
00:28:10,679 --> 00:28:12,919
000.

736
00:28:14,880 --> 00:28:16,320
and so then you'll see here that if we

737
00:28:16,320 --> 00:28:18,960
look at the sum of all the values in the

738
00:28:18,960 --> 00:28:21,600
simulated inherit loss column we end up

739
00:28:21,600 --> 00:28:27,379
with 225 807 down there at the bottom

740
00:28:28,080 --> 00:28:30,720
and for this specific year

741
00:28:30,720 --> 00:28:33,960
number 62 that's how much money we lost

742
00:28:33,960 --> 00:28:36,179
due to this application and again this

743
00:28:36,179 --> 00:28:38,779
is a simulation

744
00:28:39,120 --> 00:28:43,158
so when we then go to the

745
00:28:43,679 --> 00:28:46,200
simulated inherent loss table we can say

746
00:28:46,200 --> 00:28:50,820
all right cool year 62 we lost 225 807

747
00:28:50,820 --> 00:28:52,140
dollars

748
00:28:52,140 --> 00:28:55,200
on year 61 we lost a little bit more on

749
00:28:55,200 --> 00:28:58,880
year 63 we lost 800 Grand

750
00:28:58,919 --> 00:29:02,279
on year 56 we lost 190 thousand dollars

751
00:29:02,279 --> 00:29:04,080
and you'll see here that the values are

752
00:29:04,080 --> 00:29:05,820
are varying quite a bit right here we

753
00:29:05,820 --> 00:29:07,380
have a million

754
00:29:07,380 --> 00:29:10,500
and here we have a lot less right 167

755
00:29:10,500 --> 00:29:12,740
000.

756
00:29:13,020 --> 00:29:16,320
so what we did is we formalized our

757
00:29:16,320 --> 00:29:18,000
uncertainty about the application that

758
00:29:18,000 --> 00:29:18,960
we have

759
00:29:18,960 --> 00:29:21,480
and we extrapolated that into a thousand

760
00:29:21,480 --> 00:29:23,220
years of simulated data

761
00:29:23,220 --> 00:29:25,080
and you can see here there's thousand

762
00:29:25,080 --> 00:29:27,500
rows

763
00:29:27,659 --> 00:29:29,159
and now we can ask a really important

764
00:29:29,159 --> 00:29:30,299
question which is what is the

765
00:29:30,299 --> 00:29:31,860
probability that we're going to lose

766
00:29:31,860 --> 00:29:34,440
more than two hundred thousand dollars

767
00:29:34,440 --> 00:29:36,539
over the next year due to this specific

768
00:29:36,539 --> 00:29:39,600
application because of security issues

769
00:29:39,600 --> 00:29:41,700
and we can just count out of the

770
00:29:41,700 --> 00:29:44,460
Thousand uh points that we uh that we

771
00:29:44,460 --> 00:29:46,980
generated in our simulation

772
00:29:46,980 --> 00:29:50,100
and in this case 92.3 percent of the

773
00:29:50,100 --> 00:29:52,320
time we lost more than 200 Grand due to

774
00:29:52,320 --> 00:29:54,860
this application

775
00:29:55,679 --> 00:29:57,779
it's important to note too here that uh

776
00:29:57,779 --> 00:29:59,940
we never lost less than 140 thousand

777
00:29:59,940 --> 00:30:02,179
dollars

778
00:30:03,179 --> 00:30:04,980
and that can be because you have a

779
00:30:04,980 --> 00:30:06,480
full-time security staff it can be

780
00:30:06,480 --> 00:30:08,820
because you have a full-time engineering

781
00:30:08,820 --> 00:30:10,799
staff there's things that cost money all

782
00:30:10,799 --> 00:30:13,580
the time yes

783
00:30:26,580 --> 00:30:30,779
uh tangentially so the question is uh is

784
00:30:30,779 --> 00:30:33,020
the variance in how many dollars lost

785
00:30:33,020 --> 00:30:35,520
proportional to the number of CVS that

786
00:30:35,520 --> 00:30:37,799
are discovered right right I guess the

787
00:30:37,799 --> 00:30:39,179
better answer is what's driving the

788
00:30:39,179 --> 00:30:41,279
variance

789
00:30:41,279 --> 00:30:43,260
as in how much the probability is

790
00:30:43,260 --> 00:30:47,779
reducing or the fact that it's reducing

791
00:30:49,740 --> 00:30:50,760
all right let's talk about it more

792
00:30:50,760 --> 00:30:53,179
afterwards

793
00:30:54,059 --> 00:30:55,980
um and so now we could take these dollar

794
00:30:55,980 --> 00:30:57,720
values and these probabilities and plot

795
00:30:57,720 --> 00:30:59,520
them against each other and those are

796
00:30:59,520 --> 00:31:01,200
called loss exceedance curves which is

797
00:31:01,200 --> 00:31:02,580
what I what I mentioned at the beginning

798
00:31:02,580 --> 00:31:05,039
and loss exceedance curves are so in

799
00:31:05,039 --> 00:31:08,039
this case here we have one it's green

800
00:31:08,039 --> 00:31:10,080
um it says residual risk but in this

801
00:31:10,080 --> 00:31:11,940
case inherent risk and residual risk are

802
00:31:11,940 --> 00:31:13,320
on top of each other and for some reason

803
00:31:13,320 --> 00:31:15,179
Excel pushed the residual one on top but

804
00:31:15,179 --> 00:31:17,640
it's supposed to be a red curve

805
00:31:17,640 --> 00:31:21,120
this curve is the representation of the

806
00:31:21,120 --> 00:31:23,820
risk associated with that application it

807
00:31:23,820 --> 00:31:26,940
is the more mathematically sophisticated

808
00:31:26,940 --> 00:31:28,980
version of a list of highs mediums and

809
00:31:28,980 --> 00:31:30,480
lows

810
00:31:30,480 --> 00:31:33,840
and this curve is super cool because we

811
00:31:33,840 --> 00:31:36,240
can actually do Algebra with the inputs

812
00:31:36,240 --> 00:31:38,039
and get something different at the end

813
00:31:38,039 --> 00:31:40,860
I'll show that in a sec

814
00:31:40,860 --> 00:31:43,380
but even more importantly this curve

815
00:31:43,380 --> 00:31:45,539
speaks the same language as the people

816
00:31:45,539 --> 00:31:47,340
that invest in our program

817
00:31:47,340 --> 00:31:50,520
so I said earlier that the purpose of an

818
00:31:50,520 --> 00:31:52,860
appsec team is first and foremost to

819
00:31:52,860 --> 00:31:54,899
speak a language of trust with uh the

820
00:31:54,899 --> 00:31:56,039
people that will be consuming your

821
00:31:56,039 --> 00:31:58,860
services or your software this is a

822
00:31:58,860 --> 00:32:00,120
Common Language with the people that

823
00:32:00,120 --> 00:32:02,159
invest into our program

824
00:32:02,159 --> 00:32:04,940
and so we can go to an executive and say

825
00:32:04,940 --> 00:32:08,760
hey uh are you okay with uh accepting a

826
00:32:08,760 --> 00:32:11,700
uh say 25 chance that you will lose 200

827
00:32:11,700 --> 00:32:13,799
Grand or more against this application

828
00:32:13,799 --> 00:32:15,179
and they might say I don't want to

829
00:32:15,179 --> 00:32:16,799
accept any risk whatsoever that I'm

830
00:32:16,799 --> 00:32:18,539
going to lose that money and you can say

831
00:32:18,539 --> 00:32:20,100
yeah well you know based on our

832
00:32:20,100 --> 00:32:22,799
computations you're already accepting a

833
00:32:22,799 --> 00:32:26,220
20 chance so what's what's acceptable

834
00:32:26,220 --> 00:32:28,399
there and they might say well you know

835
00:32:28,399 --> 00:32:31,980
22 21 you can negotiate but effectively

836
00:32:31,980 --> 00:32:33,480
you're speaking Apples to Apples with

837
00:32:33,480 --> 00:32:35,039
them on something that they care about

838
00:32:35,039 --> 00:32:37,799
that matters in their budget sheet and

839
00:32:37,799 --> 00:32:39,240
then you can come up with a reasonable

840
00:32:39,240 --> 00:32:41,039
number in this case we mocked up 20

841
00:32:41,039 --> 00:32:42,360
percent

842
00:32:42,360 --> 00:32:43,980
maybe when you get to a million they

843
00:32:43,980 --> 00:32:45,480
don't want to accept much risk and you

844
00:32:45,480 --> 00:32:47,220
might end up with half a percent

845
00:32:47,220 --> 00:32:49,020
but the great thing is that you can plot

846
00:32:49,020 --> 00:32:51,600
those points on the same plot as your

847
00:32:51,600 --> 00:32:54,600
inherent risk curve and so now I have a

848
00:32:54,600 --> 00:32:56,399
starting point of where I believe that

849
00:32:56,399 --> 00:33:00,419
I'm at as a as a team and a goal post

850
00:33:00,419 --> 00:33:02,760
this is where my executive team wants me

851
00:33:02,760 --> 00:33:03,600
to be

852
00:33:03,600 --> 00:33:06,179
and I can actually move from the

853
00:33:06,179 --> 00:33:08,520
inherent risk curve to the

854
00:33:08,520 --> 00:33:11,580
um to the loss exceedance tolerance and

855
00:33:11,580 --> 00:33:14,159
this is awesome because we can build a

856
00:33:14,159 --> 00:33:16,500
project that'll move from one point to

857
00:33:16,500 --> 00:33:18,360
the other and I'm going to show you real

858
00:33:18,360 --> 00:33:22,620
quick how uh how we can approach this so

859
00:33:22,620 --> 00:33:24,600
I talked about sem grep earlier which is

860
00:33:24,600 --> 00:33:26,159
by the way a phenomenal tool if you guys

861
00:33:26,159 --> 00:33:27,779
haven't looked into it you should it's

862
00:33:27,779 --> 00:33:31,039
it's amazing

863
00:33:31,440 --> 00:33:34,140
um but maybe I can write a sem grep role

864
00:33:34,140 --> 00:33:36,419
so let's talk about this elevation of

865
00:33:36,419 --> 00:33:38,220
privilege here I've identified two

866
00:33:38,220 --> 00:33:40,740
attack vectors for um for remote code

867
00:33:40,740 --> 00:33:42,899
execution one of them is coming through

868
00:33:42,899 --> 00:33:45,539
Json deserialization and one of them is

869
00:33:45,539 --> 00:33:47,940
coming through parsing XML

870
00:33:47,940 --> 00:33:50,120
what if I can put in a stem grab rule

871
00:33:50,120 --> 00:33:53,279
that will remove the XML attack Vector

872
00:33:53,279 --> 00:33:55,500
maybe I can appropriately format the way

873
00:33:55,500 --> 00:33:58,380
that my XML parser sets its Flags so

874
00:33:58,380 --> 00:34:00,179
that we don't have to worry about about

875
00:34:00,179 --> 00:34:02,640
xxe

876
00:34:02,640 --> 00:34:04,919
well I can reduce the probability that

877
00:34:04,919 --> 00:34:08,480
this will occur by 50 percent

878
00:34:13,320 --> 00:34:15,418
and so all of the losses associated with

879
00:34:15,418 --> 00:34:18,799
this will be reduced by 50 percent

880
00:34:19,980 --> 00:34:22,859
and then I can rerun my simulation

881
00:34:22,859 --> 00:34:24,899
and you'll see here very very faintly

882
00:34:24,899 --> 00:34:27,418
that the green curve has moved away from

883
00:34:27,418 --> 00:34:29,219
the red curve

884
00:34:29,219 --> 00:34:30,780
and it's moved away from the red curve

885
00:34:30,780 --> 00:34:33,719
in that specific area which means that

886
00:34:33,719 --> 00:34:35,520
the area under the green curve is now

887
00:34:35,520 --> 00:34:37,139
different from the area under the red

888
00:34:37,139 --> 00:34:40,679
curve so we've moved the needle by some

889
00:34:40,679 --> 00:34:43,379
amount measurably by the area under the

890
00:34:43,379 --> 00:34:45,060
Curve

891
00:34:45,060 --> 00:34:47,339
but then I can say hey

892
00:34:47,339 --> 00:34:50,520
what is the value of spending time doing

893
00:34:50,520 --> 00:34:53,699
this versus spending time helping my

894
00:34:53,699 --> 00:34:55,139
support team respond to escalations

895
00:34:55,139 --> 00:34:57,599
maybe I can put out an FAQ that'll help

896
00:34:57,599 --> 00:35:00,359
them respond faster and reduce the time

897
00:35:00,359 --> 00:35:01,380
for

898
00:35:01,380 --> 00:35:04,500
um for a support case to be closed

899
00:35:04,500 --> 00:35:09,080
so I can compare those two now I can say

900
00:35:16,619 --> 00:35:19,260
I can look at my lost types and say all

901
00:35:19,260 --> 00:35:21,380
right

902
00:35:21,780 --> 00:35:23,339
I have

903
00:35:23,339 --> 00:35:25,500
two customer success loss types for

904
00:35:25,500 --> 00:35:27,660
responding to escalations as well as One

905
00:35:27,660 --> 00:35:29,160
support one

906
00:35:29,160 --> 00:35:31,740
and maybe I hope to reduce that

907
00:35:31,740 --> 00:35:35,339
conservatively by say 10 so I can apply

908
00:35:35,339 --> 00:35:38,599
a 10 reduction to that

909
00:35:40,800 --> 00:35:44,180
as well as to this one and this one yes

910
00:35:44,180 --> 00:35:47,040
so when you do these scenarios you

911
00:35:47,040 --> 00:35:49,200
should probably change the color on the

912
00:35:49,200 --> 00:35:51,300
spreadsheet about everything you try so

913
00:35:51,300 --> 00:35:53,720
you can revert it back or take control

914
00:35:53,720 --> 00:35:56,420
otherwise it gets to be pretty difficult

915
00:35:56,420 --> 00:35:58,740
and you can you can reduce those things

916
00:35:58,740 --> 00:36:00,540
to if you have something that computes

917
00:36:00,540 --> 00:36:01,980
the area under the curve you can just

918
00:36:01,980 --> 00:36:05,579
look at what the Delta is from the base

919
00:36:05,579 --> 00:36:09,240
it's much easier to track it definitely

920
00:36:09,240 --> 00:36:12,259
I'm going for easy

921
00:36:12,599 --> 00:36:15,200
macro

922
00:36:15,359 --> 00:36:16,920
I'm actually not a spreadsheet guy I

923
00:36:16,920 --> 00:36:19,460
just use this

924
00:36:19,880 --> 00:36:24,140
I'll check it out for sure

925
00:36:30,300 --> 00:36:33,119
all right so I've applied this now

926
00:36:33,119 --> 00:36:34,680
to all of my different threats and I

927
00:36:34,680 --> 00:36:36,420
rerun my simulation

928
00:36:36,420 --> 00:36:38,700
and lo and behold the curve has moved

929
00:36:38,700 --> 00:36:41,400
differently now whether it's one or the

930
00:36:41,400 --> 00:36:43,260
other that you decide to pursue

931
00:36:43,260 --> 00:36:45,599
is a different question but you actually

932
00:36:45,599 --> 00:36:47,579
have an idea of what the impact is to

933
00:36:47,579 --> 00:36:49,320
your overall risk posture for each one

934
00:36:49,320 --> 00:36:51,060
of them so maybe it's a lot cheaper to

935
00:36:51,060 --> 00:36:52,619
write a sem grep Rule and that's a quick

936
00:36:52,619 --> 00:36:54,000
win and you want to do that regardless

937
00:36:54,000 --> 00:36:55,800
maybe you don't have some grep

938
00:36:55,800 --> 00:36:57,300
implemented at all and therefore it's

939
00:36:57,300 --> 00:36:58,440
going to be a big lift to start

940
00:36:58,440 --> 00:36:59,760
implementing this

941
00:36:59,760 --> 00:37:02,099
so you can you can educate your decision

942
00:37:02,099 --> 00:37:04,800
making and in this case we educated our

943
00:37:04,800 --> 00:37:07,260
decision making between a process and a

944
00:37:07,260 --> 00:37:08,880
technical control and they don't usually

945
00:37:08,880 --> 00:37:10,980
speak Apples to Apples but when we talk

946
00:37:10,980 --> 00:37:12,900
dollars you can actually make that

947
00:37:12,900 --> 00:37:15,300
comparison

948
00:37:15,300 --> 00:37:17,160
and so this is awesome because I can

949
00:37:17,160 --> 00:37:20,820
build a strategic road map for my team

950
00:37:20,820 --> 00:37:24,300
that the business cares about that helps

951
00:37:24,300 --> 00:37:26,700
uh that helps us move in a direction

952
00:37:26,700 --> 00:37:28,500
that is Meaningful

953
00:37:28,500 --> 00:37:29,940
and I think that's awesome from a

954
00:37:29,940 --> 00:37:32,660
leadership perspective

955
00:37:44,640 --> 00:37:46,380
all right

956
00:37:46,380 --> 00:37:48,839
so what's the tldr tldr is the model

957
00:37:48,839 --> 00:37:51,000
threats with stride we feed the output

958
00:37:51,000 --> 00:37:52,680
from stride into a fair simulation

959
00:37:52,680 --> 00:37:54,780
rather than a set of cbss score

960
00:37:54,780 --> 00:37:56,700
calculators and then we use loss

961
00:37:56,700 --> 00:37:58,440
exceedance curves to represent our risk

962
00:37:58,440 --> 00:38:00,839
as a baseline or goal post and how to

963
00:38:00,839 --> 00:38:02,280
measure our progress from one to the

964
00:38:02,280 --> 00:38:04,400
next

965
00:38:07,920 --> 00:38:10,079
so what are some improvements uh that

966
00:38:10,079 --> 00:38:11,760
this can that this can bring to a broad

967
00:38:11,760 --> 00:38:14,220
SEC program or an appsec program the

968
00:38:14,220 --> 00:38:15,960
first one is by far the most important

969
00:38:15,960 --> 00:38:17,460
one it's the meaningfully prioritize

970
00:38:17,460 --> 00:38:19,380
your team's efforts Beyond compliance

971
00:38:19,380 --> 00:38:21,839
compliance is in my opinion the most

972
00:38:21,839 --> 00:38:22,980
important thing because it actually

973
00:38:22,980 --> 00:38:25,500
enables the business to bring dollars in

974
00:38:25,500 --> 00:38:27,780
but beyond that once you've enabled all

975
00:38:27,780 --> 00:38:29,099
the check boxes and you've automated

976
00:38:29,099 --> 00:38:31,079
your way through it this is a way to

977
00:38:31,079 --> 00:38:32,640
meaningfully prioritize your team's

978
00:38:32,640 --> 00:38:34,140
effort

979
00:38:34,140 --> 00:38:37,200
this is heavily uh related to the third

980
00:38:37,200 --> 00:38:39,300
point there about reducing burnout

981
00:38:39,300 --> 00:38:41,700
I went to B-side San Francisco this year

982
00:38:41,700 --> 00:38:44,099
and I saw two or three talks that were

983
00:38:44,099 --> 00:38:45,660
about burnout at the engineering level

984
00:38:45,660 --> 00:38:47,460
how to manage people that are burning

985
00:38:47,460 --> 00:38:51,060
out how do you deal with burnout etc etc

986
00:38:51,060 --> 00:38:52,980
um it's a it's a problem in our industry

987
00:38:52,980 --> 00:38:54,780
we got a lot of cynical people that see

988
00:38:54,780 --> 00:38:56,520
everything broken all the time and

989
00:38:56,520 --> 00:38:59,099
businesses that go faster and faster and

990
00:38:59,099 --> 00:39:02,220
faster and you know it's it's rough on

991
00:39:02,220 --> 00:39:03,839
it's from a leadership perspective it's

992
00:39:03,839 --> 00:39:05,940
rough on on your team

993
00:39:05,940 --> 00:39:08,099
and uh if you're able to build a road

994
00:39:08,099 --> 00:39:10,680
map where when everything is not on fire

995
00:39:10,680 --> 00:39:12,480
you're actually improving your position

996
00:39:12,480 --> 00:39:14,520
that helps you work in the direction

997
00:39:14,520 --> 00:39:17,160
that you know is productive rather than

998
00:39:17,160 --> 00:39:18,900
constantly reactive oh my God

999
00:39:18,900 --> 00:39:21,599
everything's on fire oh my God or

1000
00:39:21,599 --> 00:39:23,099
there's a calm and you're like when is

1001
00:39:23,099 --> 00:39:25,920
the storm going to start holy

1002
00:39:25,920 --> 00:39:27,839
um the second point about justifying

1003
00:39:27,839 --> 00:39:30,359
investment is more around

1004
00:39:30,359 --> 00:39:32,820
understanding and this is just my

1005
00:39:32,820 --> 00:39:34,200
opinion but understanding whether or not

1006
00:39:34,200 --> 00:39:36,240
it's worth spending time on certain

1007
00:39:36,240 --> 00:39:38,220
things or on certain tools so if a

1008
00:39:38,220 --> 00:39:39,540
vendor comes to you with a novel

1009
00:39:39,540 --> 00:39:41,640
solution to a problem you can actually

1010
00:39:41,640 --> 00:39:43,020
figure out what the value of that

1011
00:39:43,020 --> 00:39:44,820
problem is to your uh to your

1012
00:39:44,820 --> 00:39:46,500
applications into your to your practice

1013
00:39:46,500 --> 00:39:48,480
and so if the vendor is asking you for a

1014
00:39:48,480 --> 00:39:49,740
whole bunch of money

1015
00:39:49,740 --> 00:39:51,240
you may be able to say well you know

1016
00:39:51,240 --> 00:39:52,800
it's not worth it or you're able to say

1017
00:39:52,800 --> 00:39:55,820
oh that's a really good deal

1018
00:39:58,680 --> 00:40:01,380
so how does this work in practice

1019
00:40:01,380 --> 00:40:02,880
um you do a fair Strat assessment at T

1020
00:40:02,880 --> 00:40:04,619
equals zero

1021
00:40:04,619 --> 00:40:06,720
you threat model your applications you

1022
00:40:06,720 --> 00:40:08,520
figure out where all the all the

1023
00:40:08,520 --> 00:40:10,260
different loss types uh what all the

1024
00:40:10,260 --> 00:40:11,579
different loss types are what all the

1025
00:40:11,579 --> 00:40:12,780
different teams that are involved in

1026
00:40:12,780 --> 00:40:15,300
your security processes are maybe you

1027
00:40:15,300 --> 00:40:16,859
run a SAS app and you have a whole bunch

1028
00:40:16,859 --> 00:40:18,420
of incident response processes that

1029
00:40:18,420 --> 00:40:20,220
would be in scope for this

1030
00:40:20,220 --> 00:40:22,440
uh you go and you bug All Of Your

1031
00:40:22,440 --> 00:40:24,660
Business Leaders about how much all

1032
00:40:24,660 --> 00:40:26,339
these things cost how they measure them

1033
00:40:26,339 --> 00:40:28,560
a support team might measure their

1034
00:40:28,560 --> 00:40:30,480
effort and their their costs as the

1035
00:40:30,480 --> 00:40:32,160
number of support cases that are raised

1036
00:40:32,160 --> 00:40:34,260
but an engineering team might measure

1037
00:40:34,260 --> 00:40:36,480
their uh their costs in how much time it

1038
00:40:36,480 --> 00:40:37,980
takes to close a ticket

1039
00:40:37,980 --> 00:40:39,780
uh and so you take all that information

1040
00:40:39,780 --> 00:40:42,180
from all the different sources and you

1041
00:40:42,180 --> 00:40:43,560
bug people and you bug people and

1042
00:40:43,560 --> 00:40:45,060
eventually they give you what what you

1043
00:40:45,060 --> 00:40:46,740
ask for

1044
00:40:46,740 --> 00:40:48,900
and then you go talk to your your appsec

1045
00:40:48,900 --> 00:40:49,920
team and you figure out what the

1046
00:40:49,920 --> 00:40:51,720
probability of something going wrong is

1047
00:40:51,720 --> 00:40:53,520
which is the the loss event frequency

1048
00:40:53,520 --> 00:40:55,380
piece and you put those things together

1049
00:40:55,380 --> 00:40:57,119
and you build the risk posture for your

1050
00:40:57,119 --> 00:40:58,560
applications

1051
00:40:58,560 --> 00:41:00,540
uh based on that risk posture you look

1052
00:41:00,540 --> 00:41:01,980
at different things that would improve

1053
00:41:01,980 --> 00:41:03,599
your uh that would improve your program

1054
00:41:03,599 --> 00:41:04,980
and you compare them with the Lost

1055
00:41:04,980 --> 00:41:06,780
exceedance curves to determine some

1056
00:41:06,780 --> 00:41:08,400
strategic initiatives that make sense to

1057
00:41:08,400 --> 00:41:10,260
pursue over the course of a year or six

1058
00:41:10,260 --> 00:41:12,619
months or whatever it may be

1059
00:41:12,619 --> 00:41:15,359
you then execute on those on those plans

1060
00:41:15,359 --> 00:41:17,220
and you measure the effectiveness of

1061
00:41:17,220 --> 00:41:19,560
those plans or of those uh those new

1062
00:41:19,560 --> 00:41:21,839
process improvements or controls

1063
00:41:21,839 --> 00:41:23,940
in the ways that are relevant to those

1064
00:41:23,940 --> 00:41:25,500
different processes so as I mentioned

1065
00:41:25,500 --> 00:41:28,260
you may be able to reduce the amount of

1066
00:41:28,260 --> 00:41:30,359
time it takes to close a support case or

1067
00:41:30,359 --> 00:41:31,920
you may be able to reduce the number of

1068
00:41:31,920 --> 00:41:33,420
support cases that get escalated

1069
00:41:33,420 --> 00:41:35,700
depending on your depending on your

1070
00:41:35,700 --> 00:41:37,740
implementation or you may be able to

1071
00:41:37,740 --> 00:41:39,780
increase or reduce the amount of time

1072
00:41:39,780 --> 00:41:41,820
that it takes to fix a bug and those

1073
00:41:41,820 --> 00:41:43,440
things are measured differently

1074
00:41:43,440 --> 00:41:45,540
But ultimately they will either impact

1075
00:41:45,540 --> 00:41:49,140
loss event frequency or lost magnitude

1076
00:41:49,140 --> 00:41:50,700
and then 12 months after you've done

1077
00:41:50,700 --> 00:41:52,200
this and this is not for every feature

1078
00:41:52,200 --> 00:41:54,420
right this is a once a year thing

1079
00:41:54,420 --> 00:41:56,040
12 months after you've done this you

1080
00:41:56,040 --> 00:41:58,079
repeat the process so over the course of

1081
00:41:58,079 --> 00:41:59,579
12 months your application is going to

1082
00:41:59,579 --> 00:42:02,040
change tremendously your processes will

1083
00:42:02,040 --> 00:42:03,780
have definitely changed you will have

1084
00:42:03,780 --> 00:42:05,579
implemented controls that will change

1085
00:42:05,579 --> 00:42:07,440
lost magnitude or loss of end frequency

1086
00:42:07,440 --> 00:42:10,140
there will be new things in the security

1087
00:42:10,140 --> 00:42:11,700
space that will have come out new bug

1088
00:42:11,700 --> 00:42:14,099
classes new threats new issues

1089
00:42:14,099 --> 00:42:16,140
so everything in 12 months from now will

1090
00:42:16,140 --> 00:42:18,000
be completely different right if you

1091
00:42:18,000 --> 00:42:19,980
made one of these before log for Shell

1092
00:42:19,980 --> 00:42:21,540
it will look very different from

1093
00:42:21,540 --> 00:42:22,980
afterlog for Shell you would have new

1094
00:42:22,980 --> 00:42:24,780
threat items new things that could be

1095
00:42:24,780 --> 00:42:26,400
broken and so you just repeat the

1096
00:42:26,400 --> 00:42:27,960
process to come up with new proactive

1097
00:42:27,960 --> 00:42:29,520
things you can do to improve your risk

1098
00:42:29,520 --> 00:42:30,839
posture

1099
00:42:30,839 --> 00:42:33,720
and you just keep repeating every 12

1100
00:42:33,720 --> 00:42:36,078
months

1101
00:42:36,900 --> 00:42:38,820
and that's it um hit me up on LinkedIn

1102
00:42:38,820 --> 00:42:40,320
if you want to know more I have a blog

1103
00:42:40,320 --> 00:42:42,480
post I'm happy to share that spreadsheet

1104
00:42:42,480 --> 00:42:43,920
with you guys I know it's not a great

1105
00:42:43,920 --> 00:42:45,599
form to share a QR code at a security

1106
00:42:45,599 --> 00:42:50,099
conference but uh you know it's easy if

1107
00:42:50,099 --> 00:42:51,599
you're spooked out by it I'm happy to do

1108
00:42:51,599 --> 00:42:53,579
it

1109
00:42:53,579 --> 00:42:55,560
uh if you're spooked out by it I'm happy

1110
00:42:55,560 --> 00:42:57,540
to do it in person

1111
00:42:57,540 --> 00:42:59,040
um but yeah I'm happy to take any

1112
00:42:59,040 --> 00:43:00,540
questions if you guys have some

1113
00:43:00,540 --> 00:43:03,140
thank you

1114
00:43:03,540 --> 00:43:06,780
yeah what's up question so how practical

1115
00:43:06,780 --> 00:43:08,940
is it to do this depending on the size

1116
00:43:08,940 --> 00:43:12,119
and scale of an organization or a team

1117
00:43:12,119 --> 00:43:15,000
or application portfolio like at what

1118
00:43:15,000 --> 00:43:16,560
point does something like this become a

1119
00:43:16,560 --> 00:43:18,720
little bit too cumbersome

1120
00:43:18,720 --> 00:43:22,500
um and just not not beneficial I guess

1121
00:43:22,500 --> 00:43:24,839
yeah so the the question is about uh

1122
00:43:24,839 --> 00:43:27,960
this being a heavy-handed process and it

1123
00:43:27,960 --> 00:43:29,400
can become cumbersome and how do you

1124
00:43:29,400 --> 00:43:30,780
relate that to the size of your

1125
00:43:30,780 --> 00:43:33,780
organization is really up to you

1126
00:43:33,780 --> 00:43:36,780
um in my my experience I reached a point

1127
00:43:36,780 --> 00:43:38,520
where we were doing everything really

1128
00:43:38,520 --> 00:43:41,040
well and we were checking all the boxes

1129
00:43:41,040 --> 00:43:42,900
and this was something that you know

1130
00:43:42,900 --> 00:43:44,520
from all the materials that I that I had

1131
00:43:44,520 --> 00:43:46,980
consumed that made sense to me I said oh

1132
00:43:46,980 --> 00:43:49,319
I can I can use this in this way and so

1133
00:43:49,319 --> 00:43:51,359
if it makes sense do it if it doesn't

1134
00:43:51,359 --> 00:43:52,380
make sense

1135
00:43:52,380 --> 00:43:55,319
don't ultimately again it's just it's to

1136
00:43:55,319 --> 00:43:57,660
educate decision making so if you have a

1137
00:43:57,660 --> 00:43:59,339
good road map already to educate your

1138
00:43:59,339 --> 00:44:01,619
decisions and use that

1139
00:44:01,619 --> 00:44:04,099
thanks

1140
00:44:06,480 --> 00:44:10,319
um do you also do uh non-fair uh threat

1141
00:44:10,319 --> 00:44:13,200
models as well you said you only or you

1142
00:44:13,200 --> 00:44:15,240
recommend doing this every 12 months but

1143
00:44:15,240 --> 00:44:17,460
uh I think really like their models have

1144
00:44:17,460 --> 00:44:19,079
to be done more frequently or otherwise

1145
00:44:19,079 --> 00:44:22,260
deal on the Strip so yeah

1146
00:44:22,260 --> 00:44:23,940
yeah so the question is do you use

1147
00:44:23,940 --> 00:44:25,560
traditional threat modeling in addition

1148
00:44:25,560 --> 00:44:29,099
to to this absolutely this is more of a

1149
00:44:29,099 --> 00:44:31,800
strategic uh thing that you would use uh

1150
00:44:31,800 --> 00:44:33,359
every 12 months but if you actually want

1151
00:44:33,359 --> 00:44:34,859
to go and look at features you should

1152
00:44:34,859 --> 00:44:36,720
absolutely do that independently it's

1153
00:44:36,720 --> 00:44:38,339
it's augmentation rather than a

1154
00:44:38,339 --> 00:44:40,520
replacement

1155
00:44:51,060 --> 00:44:54,240
um so the exploitability um

1156
00:44:54,240 --> 00:44:57,900
uh exploit prediction system

1157
00:44:57,900 --> 00:44:59,460
um have you look into that as a part of

1158
00:44:59,460 --> 00:45:00,900
this process or something I can kind of

1159
00:45:00,900 --> 00:45:02,460
compliment it because it can be hard and

1160
00:45:02,460 --> 00:45:05,819
it can estimate the likelihoods but it

1161
00:45:05,819 --> 00:45:08,460
seems like this is kind of a replacement

1162
00:45:08,460 --> 00:45:11,579
for cbss where you actually get a

1163
00:45:11,579 --> 00:45:13,319
probability so it sounds like a

1164
00:45:13,319 --> 00:45:15,060
naturally kind of bit into this yeah the

1165
00:45:15,060 --> 00:45:16,980
the question is about epss scores and

1166
00:45:16,980 --> 00:45:19,260
having that scoring system to to help

1167
00:45:19,260 --> 00:45:20,579
estimate whether or not something is

1168
00:45:20,579 --> 00:45:22,380
going to be exploited

1169
00:45:22,380 --> 00:45:23,460
um

1170
00:45:23,460 --> 00:45:25,680
I don't know about epss scores but I

1171
00:45:25,680 --> 00:45:27,480
will tell you that there are ways to

1172
00:45:27,480 --> 00:45:30,660
augment this statistically so if you

1173
00:45:30,660 --> 00:45:31,859
um if you're familiar with beta

1174
00:45:31,859 --> 00:45:34,079
distributions that's a great way to

1175
00:45:34,079 --> 00:45:35,579
simulate the probability of something

1176
00:45:35,579 --> 00:45:37,740
happening so

1177
00:45:37,740 --> 00:45:39,720
um I didn't use it in this one because I

1178
00:45:39,720 --> 00:45:41,160
already have to explain all these all

1179
00:45:41,160 --> 00:45:42,480
these different things and only have an

1180
00:45:42,480 --> 00:45:45,359
hour but if you say for example in the

1181
00:45:45,359 --> 00:45:47,220
last 10 years there were two years where

1182
00:45:47,220 --> 00:45:49,200
one or more cbes occurred

1183
00:45:49,200 --> 00:45:51,720
instead of saying instead of feeding

1184
00:45:51,720 --> 00:45:53,280
down to a ratio and saying oh it's 2

1185
00:45:53,280 --> 00:45:56,220
over 10. you can say I'm going to use a

1186
00:45:56,220 --> 00:45:58,140
beta distribution where the hits are 2

1187
00:45:58,140 --> 00:46:00,180
and the misses are 10.

1188
00:46:00,180 --> 00:46:02,640
I'm sorry nine

1189
00:46:02,640 --> 00:46:04,500
and that will every time you run a

1190
00:46:04,500 --> 00:46:06,660
simulation so you saw how we had a

1191
00:46:06,660 --> 00:46:08,099
different dollar value every time we ran

1192
00:46:08,099 --> 00:46:09,900
a simulation every time you run a

1193
00:46:09,900 --> 00:46:11,220
simulation with that kind of setup

1194
00:46:11,220 --> 00:46:13,260
you'll get a different probability that

1195
00:46:13,260 --> 00:46:17,119
is modeled after your your uncertainty

1196
00:46:24,000 --> 00:46:26,660
yeah

1197
00:46:29,420 --> 00:46:32,660
it's a very actual knowledge

1198
00:46:32,660 --> 00:46:35,880
do you find that this has

1199
00:46:35,880 --> 00:46:39,540
uh or I guess any sort of correlations

1200
00:46:39,540 --> 00:46:41,940
with what uh financial analysis could be

1201
00:46:41,940 --> 00:46:43,920
happening inside of a business or some

1202
00:46:43,920 --> 00:46:45,960
sort of data analytics and also is

1203
00:46:45,960 --> 00:46:48,720
trying to research yeah so the question

1204
00:46:48,720 --> 00:46:50,760
is uh how does this relate to financial

1205
00:46:50,760 --> 00:46:53,220
modeling inside your organization I'm

1206
00:46:53,220 --> 00:46:55,380
sure it does uh I don't know how though

1207
00:46:55,380 --> 00:46:57,119
but I'm sure it does there's got to be

1208
00:46:57,119 --> 00:46:58,619
something somewhere that you can you can

1209
00:46:58,619 --> 00:47:00,839
relate to

1210
00:47:00,839 --> 00:47:02,579
that

1211
00:47:02,579 --> 00:47:04,740
um I definitely I showed this to an exec

1212
00:47:04,740 --> 00:47:06,420
and he immediately picked up and he goes

1213
00:47:06,420 --> 00:47:08,339
oh I I know what you're I know what

1214
00:47:08,339 --> 00:47:09,660
you're talking about

1215
00:47:09,660 --> 00:47:10,740
um but I have I haven't made that

1216
00:47:10,740 --> 00:47:13,339
correlation yet

1217
00:47:15,859 --> 00:47:18,240
assuming you do this on each system or

1218
00:47:18,240 --> 00:47:19,980
or every system that's that's the scope

1219
00:47:19,980 --> 00:47:21,599
for this type of activity do you have

1220
00:47:21,599 --> 00:47:23,880
any way that you aggregate the the bulk

1221
00:47:23,880 --> 00:47:27,060
of all of the the results up to kind of

1222
00:47:27,060 --> 00:47:32,099
uh a higher level of dollars uh like

1223
00:47:32,099 --> 00:47:35,220
like Risk mitigation or

1224
00:47:35,220 --> 00:47:36,960
um cost savings something like that that

1225
00:47:36,960 --> 00:47:38,339
you would report on like a program level

1226
00:47:38,339 --> 00:47:39,420
and is that what it's done like

1227
00:47:39,420 --> 00:47:41,400
prescription kind of thing

1228
00:47:41,400 --> 00:47:43,619
um so the question is uh if you have

1229
00:47:43,619 --> 00:47:45,480
more than just one system how do you

1230
00:47:45,480 --> 00:47:47,579
represent that at a more macro strategic

1231
00:47:47,579 --> 00:47:48,780
level

1232
00:47:48,780 --> 00:47:50,700
um the there's a few ways you can do

1233
00:47:50,700 --> 00:47:53,220
this you can either have uh all the Lost

1234
00:47:53,220 --> 00:47:55,740
exceedance curves on the same on the on

1235
00:47:55,740 --> 00:47:57,599
the same graph with the same scale to

1236
00:47:57,599 --> 00:47:59,819
show to compare them to one another or

1237
00:47:59,819 --> 00:48:01,440
you can look at them combined together

1238
00:48:01,440 --> 00:48:03,060
and because we're using dollars you

1239
00:48:03,060 --> 00:48:04,619
could just add all the dollar values

1240
00:48:04,619 --> 00:48:06,540
together and you'll end up with a

1241
00:48:06,540 --> 00:48:08,160
massive loss exceedance curve that'll be

1242
00:48:08,160 --> 00:48:09,780
on a much bigger scale so depending on

1243
00:48:09,780 --> 00:48:11,460
what you're trying to do you can use

1244
00:48:11,460 --> 00:48:14,160
algebra to get there

1245
00:48:14,160 --> 00:48:16,279
okay

1246
00:48:24,060 --> 00:48:26,460
all right cool no questions about jots

1247
00:48:26,460 --> 00:48:28,500
all right sweet thanks guys I really

1248
00:48:28,500 --> 00:48:31,040
appreciate it

