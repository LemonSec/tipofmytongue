1
00:00:09,300 --> 00:00:32,280
[Music]

2
00:00:34,550 --> 00:00:38,629
all right well go ahead and get started

3
00:00:38,720 --> 00:00:50,700
so welcome my name is Nick Leghorn

4
00:00:48,540 --> 00:00:52,110
I run the information security or risk

5
00:00:50,700 --> 00:00:57,510
management team and indeed here in

6
00:00:52,110 --> 00:00:58,950
Austin Texas I've wanted to give this

7
00:00:57,510 --> 00:01:01,710
talk for a while now and I'm I'm

8
00:00:58,950 --> 00:01:05,489
borrowing heavily from our bosses eight

9
00:01:01,710 --> 00:01:07,080
on this there is a problem in

10
00:01:05,489 --> 00:01:10,560
information security especially with

11
00:01:07,080 --> 00:01:12,119
employment it generally follows this

12
00:01:10,560 --> 00:01:14,550
kind of cycle where as soon as you get

13
00:01:12,119 --> 00:01:17,250
hired at a place there's this immediate

14
00:01:14,550 --> 00:01:18,630
optimism this cool I'm gonna go fix all

15
00:01:17,250 --> 00:01:20,430
the things you hired me to do all the

16
00:01:18,630 --> 00:01:24,509
stuff we're gonna go out and roll the

17
00:01:20,430 --> 00:01:26,610
world and as things progress you find

18
00:01:24,509 --> 00:01:28,590
places you want to impact you find

19
00:01:26,610 --> 00:01:31,710
things that you want to change you try

20
00:01:28,590 --> 00:01:32,910
and make it happen and you don't get the

21
00:01:31,710 --> 00:01:34,500
traction that you're looking for it

22
00:01:32,910 --> 00:01:35,940
there's some pushback from the business

23
00:01:34,500 --> 00:01:37,369
you don't find that you're being as

24
00:01:35,940 --> 00:01:40,200
effective as you thought you would be

25
00:01:37,369 --> 00:01:42,090
and that leads to frustration and

26
00:01:40,200 --> 00:01:44,250
frustration leads to burnout and then

27
00:01:42,090 --> 00:01:45,750
burnout leads to turnover and then you

28
00:01:44,250 --> 00:01:48,390
go to the next job and the cycle starts

29
00:01:45,750 --> 00:01:50,069
again where you get hired optimistic

30
00:01:48,390 --> 00:01:54,899
find a thing to change doesn't change

31
00:01:50,069 --> 00:01:56,940
get tired burnout start again and I have

32
00:01:54,899 --> 00:02:00,000
felt this at company as I worked for

33
00:01:56,940 --> 00:02:02,459
I've been I've worked at my Toliver to

34
00:02:00,000 --> 00:02:04,229
ShoreTel I've worked at Rackspace I've

35
00:02:02,459 --> 00:02:07,020
worked at a bunch of different places

36
00:02:04,229 --> 00:02:11,430
and it's the same thing over and over

37
00:02:07,020 --> 00:02:14,370
again right so what I want to do and

38
00:02:11,430 --> 00:02:16,920
indeed was I wanted to find a way to

39
00:02:14,370 --> 00:02:18,959
take this responsibility off of us

40
00:02:16,920 --> 00:02:25,099
because the reason for this burnout the

41
00:02:18,959 --> 00:02:27,630
reason that people start to feel this

42
00:02:25,099 --> 00:02:30,060
this burnout is because they they feel

43
00:02:27,630 --> 00:02:32,790
like they're responsible for security

44
00:02:30,060 --> 00:02:34,709
we're responsible people we want things

45
00:02:32,790 --> 00:02:36,989
to be secure we are the people that

46
00:02:34,709 --> 00:02:38,730
should be doing that and so we feel

47
00:02:36,989 --> 00:02:40,260
personally responsible for the security

48
00:02:38,730 --> 00:02:41,670
of the company we feel that if the

49
00:02:40,260 --> 00:02:44,130
company gets hacked if there's a problem

50
00:02:41,670 --> 00:02:46,190
that it's ours to fix that's something

51
00:02:44,130 --> 00:02:49,310
that we need to be working

52
00:02:46,190 --> 00:02:51,590
and in reality that's not really the

53
00:02:49,310 --> 00:02:52,849
case it's our job to point out what's

54
00:02:51,590 --> 00:02:54,680
going on it's our job to help the

55
00:02:52,849 --> 00:02:57,260
business understand how bad the things

56
00:02:54,680 --> 00:02:59,629
are it's not our job to fix them and so

57
00:02:57,260 --> 00:03:01,310
I want to talk a little bit about how

58
00:02:59,629 --> 00:03:04,760
we're implementing some things indeed

59
00:03:01,310 --> 00:03:06,620
that are in that line that helped put

60
00:03:04,760 --> 00:03:08,149
the emphasis back on the business that

61
00:03:06,620 --> 00:03:10,099
instead of taking all that

62
00:03:08,150 --> 00:03:11,420
responsibility on ourselves we're making

63
00:03:10,099 --> 00:03:14,179
the business aware of what's going on

64
00:03:11,420 --> 00:03:17,030
and it's providing a cooperative instead

65
00:03:14,180 --> 00:03:20,000
of a adversarial relationship so let me

66
00:03:17,030 --> 00:03:21,440
take an example and I I realize is an

67
00:03:20,000 --> 00:03:22,940
application security conference and I'm

68
00:03:21,440 --> 00:03:25,940
gonna talk about a networking issue

69
00:03:22,940 --> 00:03:27,950
because I'm a network guy but this could

70
00:03:25,940 --> 00:03:31,069
be anything that the company wants to do

71
00:03:27,950 --> 00:03:33,500
that's particularly dumb in this case if

72
00:03:31,069 --> 00:03:35,630
someone like a manager wants to Remote

73
00:03:33,500 --> 00:03:39,230
Desktop into production from anywhere on

74
00:03:35,630 --> 00:03:43,010
on the road without a VPN that's not a

75
00:03:39,230 --> 00:03:45,399
great idea obviously that's why VPN

76
00:03:43,010 --> 00:03:47,569
exists is to make these things secure

77
00:03:45,400 --> 00:03:49,790
but it could be there's a vulnerability

78
00:03:47,569 --> 00:03:51,980
discovered in the code that engineering

79
00:03:49,790 --> 00:03:53,989
doesn't want to fix this could be a

80
00:03:51,980 --> 00:03:56,090
feature that takes precedent that has

81
00:03:53,989 --> 00:03:58,100
some security vulnerability inherent in

82
00:03:56,090 --> 00:04:00,560
it this could be anything that's an

83
00:03:58,100 --> 00:04:03,950
issue as you want to find in fix in this

84
00:04:00,560 --> 00:04:05,329
case stuff like this at previous

85
00:04:03,950 --> 00:04:06,798
companies I've worked out has been ways

86
00:04:05,329 --> 00:04:09,650
that ransomware has gotten in the system

87
00:04:06,799 --> 00:04:12,530
its ways that they've had breaches and

88
00:04:09,650 --> 00:04:18,739
and other issues so this is a huge

89
00:04:12,530 --> 00:04:20,630
problem if in a normal situation right

90
00:04:18,738 --> 00:04:23,419
it's the engineering department says I

91
00:04:20,630 --> 00:04:24,860
need X I need this thing I need to open

92
00:04:23,419 --> 00:04:27,889
up these ports I need these firewall

93
00:04:24,860 --> 00:04:29,360
rules done I need this functionality the

94
00:04:27,889 --> 00:04:30,979
request goes to the network team Network

95
00:04:29,360 --> 00:04:32,450
team goes to security and says hey this

96
00:04:30,979 --> 00:04:35,990
is a stupid idea I don't want to do it

97
00:04:32,450 --> 00:04:38,630
help me and at that point really it's

98
00:04:35,990 --> 00:04:40,280
not much that we can do about it they're

99
00:04:38,630 --> 00:04:42,169
in a different work structure right if

100
00:04:40,280 --> 00:04:44,388
we're over here in information security

101
00:04:42,169 --> 00:04:45,500
and networking right and engineering

102
00:04:44,389 --> 00:04:48,460
isn't it completely different part of

103
00:04:45,500 --> 00:04:50,599
the business it's hard to get that

104
00:04:48,460 --> 00:04:52,849
cross-functional support to say that

105
00:04:50,599 --> 00:04:54,560
this is a bad idea it's a lot easier for

106
00:04:52,849 --> 00:04:56,000
their management to say that no

107
00:04:54,560 --> 00:04:57,029
engineering or networking is being a

108
00:04:56,000 --> 00:04:58,979
blocker or

109
00:04:57,029 --> 00:05:02,129
security stopping us from doing this

110
00:04:58,979 --> 00:05:03,719
it's that adversarial concept again

111
00:05:02,129 --> 00:05:05,729
engineering really wants to do this they

112
00:05:03,719 --> 00:05:07,379
see there's obviously a benefit to it

113
00:05:05,729 --> 00:05:09,149
they're just not seeing the downside of

114
00:05:07,379 --> 00:05:10,979
it as much and so they don't understand

115
00:05:09,149 --> 00:05:13,499
that concept they keep pushing forward

116
00:05:10,979 --> 00:05:15,808
security seen as a blocker everyone's

117
00:05:13,499 --> 00:05:18,479
sad because there's fighting and and

118
00:05:15,809 --> 00:05:19,830
confusion and frustration and at the end

119
00:05:18,479 --> 00:05:21,779
of the day they just do it anyway

120
00:05:19,830 --> 00:05:25,469
because they want engineering to shut up

121
00:05:21,779 --> 00:05:27,179
and go away so that's the normal way of

122
00:05:25,469 --> 00:05:29,699
happening right is there's frustration

123
00:05:27,179 --> 00:05:34,558
there's anger there's confusion there's

124
00:05:29,699 --> 00:05:36,869
fighting but in reality it's there's two

125
00:05:34,559 --> 00:05:38,219
aspects of theirs one is security needs

126
00:05:36,869 --> 00:05:39,959
to understand how bad do we want to

127
00:05:38,219 --> 00:05:42,089
fight this like is this the business the

128
00:05:39,959 --> 00:05:43,349
hill that we're on die on and the second

129
00:05:42,089 --> 00:05:47,159
is we need the business to understand

130
00:05:43,349 --> 00:05:49,469
how bad of an idea this is so that's

131
00:05:47,159 --> 00:05:51,389
kind of where risk comes in is to help

132
00:05:49,469 --> 00:05:53,189
ease that conversation and put that

133
00:05:51,389 --> 00:05:55,979
decision-making capability backwards

134
00:05:53,189 --> 00:05:57,929
backward belongs the concept of the

135
00:05:55,979 --> 00:05:59,969
alignment of power and responsibility if

136
00:05:57,929 --> 00:06:01,828
you want to do this thing you should

137
00:05:59,969 --> 00:06:03,329
understand what you're doing you should

138
00:06:01,829 --> 00:06:06,360
understand the risk it poses and you

139
00:06:03,329 --> 00:06:09,449
should be able to balance that out in

140
00:06:06,360 --> 00:06:11,569
deeds ethos thing mission statement is

141
00:06:09,449 --> 00:06:13,529
that we help people get jobs my team's

142
00:06:11,569 --> 00:06:17,069
mission statement is that we help the

143
00:06:13,529 --> 00:06:20,339
business take healthy risks what I mean

144
00:06:17,069 --> 00:06:23,639
about that is risk isn't a value risk

145
00:06:20,339 --> 00:06:26,429
isn't necessarily a point in time

146
00:06:23,639 --> 00:06:29,069
security isn't a destination scary to

147
00:06:26,429 --> 00:06:31,888
the journey right and depending on the

148
00:06:29,069 --> 00:06:34,860
kind of business depending on how the

149
00:06:31,889 --> 00:06:36,869
business feels can determine whether

150
00:06:34,860 --> 00:06:38,129
they want to be fast or they want to be

151
00:06:36,869 --> 00:06:40,319
secure right

152
00:06:38,129 --> 00:06:43,740
the the three-legged stool of fast

153
00:06:40,319 --> 00:06:45,619
secure and cheap generally looking at

154
00:06:43,740 --> 00:06:48,709
just the security of versus speed aspect

155
00:06:45,619 --> 00:06:50,909
you can be anywhere on this this

156
00:06:48,709 --> 00:06:53,219
anywhere on the spectrum you can be

157
00:06:50,909 --> 00:06:54,569
superfast and insecure if you're trying

158
00:06:53,219 --> 00:06:55,979
to get into a new market if there's a

159
00:06:54,569 --> 00:06:58,289
new project that you're trying to launch

160
00:06:55,979 --> 00:07:01,889
that the company is not going to survive

161
00:06:58,289 --> 00:07:03,899
if it doesn't get this right you can be

162
00:07:01,889 --> 00:07:05,129
super secure if you've got an

163
00:07:03,899 --> 00:07:06,959
established thing in the market and you

164
00:07:05,129 --> 00:07:08,370
don't really need to innovate that much

165
00:07:06,959 --> 00:07:09,629
but you're more concerned about losing

166
00:07:08,370 --> 00:07:13,199
market share then

167
00:07:09,629 --> 00:07:16,559
security is more of a concern and really

168
00:07:13,199 --> 00:07:19,469
we as security people want to be on the

169
00:07:16,559 --> 00:07:21,779
secure side of the spectrum but that's

170
00:07:19,469 --> 00:07:25,558
not necessarily the correct call for the

171
00:07:21,779 --> 00:07:27,869
company so what we as security people

172
00:07:25,559 --> 00:07:30,599
need to do is understand where on the

173
00:07:27,869 --> 00:07:33,179
spectrum does the company want to be and

174
00:07:30,599 --> 00:07:35,279
then we need to help them make the

175
00:07:33,179 --> 00:07:37,739
decisions to let them stay at that spot

176
00:07:35,279 --> 00:07:39,629
to identify when things exceed their

177
00:07:37,740 --> 00:07:42,899
tolerance if this is too risky for

178
00:07:39,629 --> 00:07:47,520
things they want to do or if this is an

179
00:07:42,899 --> 00:07:49,979
acceptable risk that they want to do so

180
00:07:47,520 --> 00:07:50,998
why do we rent manage risk we manage

181
00:07:49,979 --> 00:07:52,619
risk because it helps the business

182
00:07:50,999 --> 00:07:53,610
understand where they are right now on

183
00:07:52,619 --> 00:07:55,709
that spectrum

184
00:07:53,610 --> 00:07:56,610
it gives them understanding of are they

185
00:07:55,709 --> 00:07:58,259
being too fast

186
00:07:56,610 --> 00:08:01,019
are they being too secure can they take

187
00:07:58,259 --> 00:08:03,360
more risk it allows the business to

188
00:08:01,019 --> 00:08:06,089
define their risk tolerance it lets them

189
00:08:03,360 --> 00:08:08,490
tell us what they care about so we can

190
00:08:06,089 --> 00:08:10,740
determine how do we measure that how do

191
00:08:08,490 --> 00:08:14,279
we know that we're in the right spot how

192
00:08:10,740 --> 00:08:15,479
do we help them make those decisions and

193
00:08:14,279 --> 00:08:18,269
then for businesses where they don't

194
00:08:15,479 --> 00:08:20,849
quite have that knowledge yet starting

195
00:08:18,269 --> 00:08:22,559
to catalog and document the decisions

196
00:08:20,849 --> 00:08:25,649
that they are making because there are

197
00:08:22,559 --> 00:08:27,149
even if they don't have a mature risk

198
00:08:25,649 --> 00:08:29,430
management function yet they're gonna be

199
00:08:27,149 --> 00:08:32,279
able to intuitively understand this

200
00:08:29,430 --> 00:08:33,750
feels too risky this feels okay and by

201
00:08:32,279 --> 00:08:35,818
documenting those decisions we're gonna

202
00:08:33,750 --> 00:08:37,889
be able to understand where on that

203
00:08:35,818 --> 00:08:40,338
spectrum they fall and help them figure

204
00:08:37,889 --> 00:08:40,339
that out themselves

205
00:08:40,789 --> 00:08:45,420
so there's two aspects to this right so

206
00:08:43,799 --> 00:08:47,399
the first is is this the hill that

207
00:08:45,420 --> 00:08:49,920
security wants to die on and the second

208
00:08:47,399 --> 00:08:52,439
is helping the business understand how

209
00:08:49,920 --> 00:08:54,240
bad of an idea this is so the way that

210
00:08:52,439 --> 00:08:57,269
we break that out is operational versus

211
00:08:54,240 --> 00:08:59,130
strategic risk so operational risk is

212
00:08:57,269 --> 00:09:01,339
about do we care is this something that

213
00:08:59,130 --> 00:09:03,899
we care about if I have a queue of

214
00:09:01,339 --> 00:09:07,259
600 Network requests coming in to open

215
00:09:03,899 --> 00:09:09,060
up ACLs right which of these 600 do I

216
00:09:07,259 --> 00:09:10,800
want to spend my resources on because I

217
00:09:09,060 --> 00:09:12,959
as a security engineer can't do all of

218
00:09:10,800 --> 00:09:15,029
them I can't spend the same amount of

219
00:09:12,959 --> 00:09:16,800
time on all of them are there some that

220
00:09:15,029 --> 00:09:19,470
are more important than others how do we

221
00:09:16,800 --> 00:09:21,930
define that so if we can define the risk

222
00:09:19,470 --> 00:09:23,910
posed by each of those requests

223
00:09:21,930 --> 00:09:25,800
we can start stack ranking we can start

224
00:09:23,910 --> 00:09:27,329
identifying maybe this one needs

225
00:09:25,800 --> 00:09:30,359
additional scrutiny maybe this one's

226
00:09:27,330 --> 00:09:33,630
okay to proceed as is so instead of

227
00:09:30,360 --> 00:09:35,100
having just one bar maybe we can set

228
00:09:33,630 --> 00:09:38,250
different bars based on the risk it

229
00:09:35,100 --> 00:09:39,870
poses its transactional operational risk

230
00:09:38,250 --> 00:09:41,760
of strands action will focus on specific

231
00:09:39,870 --> 00:09:45,090
requests so request response sort of

232
00:09:41,760 --> 00:09:45,780
thing queue management used to find a

233
00:09:45,090 --> 00:09:51,180
level of security

234
00:09:45,780 --> 00:09:54,000
scrutiny understanding doing operational

235
00:09:51,180 --> 00:09:55,829
risk requires you to understand the risk

236
00:09:54,000 --> 00:09:57,630
appetite or at least have a guess of

237
00:09:55,830 --> 00:09:59,880
what the kind of risk appetite you're

238
00:09:57,630 --> 00:10:01,470
looking at is if the company hasn't

239
00:09:59,880 --> 00:10:03,930
defined it maybe you just take a best

240
00:10:01,470 --> 00:10:06,960
estimate at I think we can handle this

241
00:10:03,930 --> 00:10:08,819
level of tickets through our queue or we

242
00:10:06,960 --> 00:10:10,530
can do this level of investigation maybe

243
00:10:08,820 --> 00:10:13,260
that's what sets our risk tolerance is

244
00:10:10,530 --> 00:10:15,720
just what are we capable of doing and

245
00:10:13,260 --> 00:10:16,980
then things that are with our exceeding

246
00:10:15,720 --> 00:10:20,040
that risk tolerance or things that we

247
00:10:16,980 --> 00:10:24,360
look at strategic risk of this should we

248
00:10:20,040 --> 00:10:25,920
care part and we'll talk about how those

249
00:10:24,360 --> 00:10:28,080
roles up in a minute but operational

250
00:10:25,920 --> 00:10:29,640
risks will inform strategic risks if you

251
00:10:28,080 --> 00:10:31,460
have a bunch of little things if you've

252
00:10:29,640 --> 00:10:34,380
left through maybe those all

253
00:10:31,460 --> 00:10:35,940
individually are okay but in a group

254
00:10:34,380 --> 00:10:37,800
they are actually a problem it

255
00:10:35,940 --> 00:10:38,810
identifies a larger issue that needs to

256
00:10:37,800 --> 00:10:41,310
be good tact

257
00:10:38,810 --> 00:10:43,500
it's broader in scope and in scope we

258
00:10:41,310 --> 00:10:45,270
can incorporate dozens hundreds

259
00:10:43,500 --> 00:10:48,420
thousands of individual transactions

260
00:10:45,270 --> 00:10:50,130
individual decisions one server with one

261
00:10:48,420 --> 00:10:52,860
missing vulnerable one missing patch

262
00:10:50,130 --> 00:10:55,950
isn't necessarily a problem 500 servers

263
00:10:52,860 --> 00:10:57,870
but the same missing patch might it's

264
00:10:55,950 --> 00:10:59,850
designed to high to inform at a higher

265
00:10:57,870 --> 00:11:01,860
level so where as operational risk is

266
00:10:59,850 --> 00:11:03,930
about for this request what do we care

267
00:11:01,860 --> 00:11:05,790
about strategic risk is here's

268
00:11:03,930 --> 00:11:07,890
everything that's broken which of these

269
00:11:05,790 --> 00:11:10,199
things do you want me to fix first which

270
00:11:07,890 --> 00:11:13,430
of these problems should I make a

271
00:11:10,200 --> 00:11:13,430
priority within my team

272
00:11:14,190 --> 00:11:20,170
so when we talk about risk even within

273
00:11:18,040 --> 00:11:23,530
the word risk right risk which is a the

274
00:11:20,170 --> 00:11:25,719
probability of loss for a given event we

275
00:11:23,530 --> 00:11:28,360
can dissect that into a couple different

276
00:11:25,720 --> 00:11:30,400
ways it's I likelihood and impact is

277
00:11:28,360 --> 00:11:32,140
something that's pretty common but even

278
00:11:30,400 --> 00:11:33,579
there we can dissect likelihood into

279
00:11:32,140 --> 00:11:36,850
threatened vulnerability we can talk

280
00:11:33,580 --> 00:11:38,350
about how many how many times prettier

281
00:11:36,850 --> 00:11:40,750
do we expect someone to try and attack

282
00:11:38,350 --> 00:11:42,700
this how likely are they to succeed we

283
00:11:40,750 --> 00:11:45,910
can get super granular into this my

284
00:11:42,700 --> 00:11:48,010
background I I did terrorism risk

285
00:11:45,910 --> 00:11:49,420
analysis for DHS for a while so

286
00:11:48,010 --> 00:11:52,270
understanding and trying to calculate

287
00:11:49,420 --> 00:11:54,040
out all the different probabilities of

288
00:11:52,270 --> 00:11:56,800
terrorism attacks in the United States

289
00:11:54,040 --> 00:11:58,870
gets to be super granular and confusing

290
00:11:56,800 --> 00:12:00,010
if you don't have a formula to figure

291
00:11:58,870 --> 00:12:02,050
that out

292
00:12:00,010 --> 00:12:03,340
so dissecting it into threat phone or

293
00:12:02,050 --> 00:12:05,319
building consequence gives us that

294
00:12:03,340 --> 00:12:09,070
ability to go that granular level and

295
00:12:05,320 --> 00:12:10,990
get a value for these things but even

296
00:12:09,070 --> 00:12:12,640
within the higher levels if you're just

297
00:12:10,990 --> 00:12:16,650
looking at likelihood an impact or if

298
00:12:12,640 --> 00:12:18,340
you just want a category a threat

299
00:12:16,650 --> 00:12:20,829
there's different ways we can

300
00:12:18,340 --> 00:12:26,560
communicate this we can communicate in

301
00:12:20,830 --> 00:12:28,360
broad categories for if you if you're

302
00:12:26,560 --> 00:12:30,760
just looking at risk right just you want

303
00:12:28,360 --> 00:12:33,040
some t-shirt sizing of risk of

304
00:12:30,760 --> 00:12:35,439
categories a great way to do it it's

305
00:12:33,040 --> 00:12:38,380
useful for quick analysis it's not very

306
00:12:35,440 --> 00:12:42,070
precise the problems with using this

307
00:12:38,380 --> 00:12:45,850
sort of format for communicating it if

308
00:12:42,070 --> 00:12:47,470
you have a stakeholder who doesn't quite

309
00:12:45,850 --> 00:12:48,640
isn't quite bought into your process

310
00:12:47,470 --> 00:12:50,170
doesn't quite understand what you're

311
00:12:48,640 --> 00:12:51,340
doing it can be confusing to say that

312
00:12:50,170 --> 00:12:55,000
this is a high risk without any

313
00:12:51,340 --> 00:12:56,850
supporting documentation but when you're

314
00:12:55,000 --> 00:12:59,620
trying to just do that quick initial

315
00:12:56,850 --> 00:13:01,780
categorization of this request that's

316
00:12:59,620 --> 00:13:04,990
coming into my Q do I care about it

317
00:13:01,780 --> 00:13:08,550
being able to define just t-shirt sizes

318
00:13:04,990 --> 00:13:08,550
of risk is very useful for that

319
00:13:10,740 --> 00:13:15,900
if you want to get a little bit more

320
00:13:12,510 --> 00:13:17,670
granular than that similarly just that

321
00:13:15,900 --> 00:13:20,250
single value for risk right instead of

322
00:13:17,670 --> 00:13:23,939
that hierarchical one two three four

323
00:13:20,250 --> 00:13:25,650
critical high medium low annualized loss

324
00:13:23,940 --> 00:13:27,870
expectancy is a really good value to use

325
00:13:25,650 --> 00:13:29,819
but that requires a lot of deep

326
00:13:27,870 --> 00:13:32,730
understanding of the problem and a lot

327
00:13:29,820 --> 00:13:34,830
of deep quantification of risk it's

328
00:13:32,730 --> 00:13:38,190
super useful for when you're trying to

329
00:13:34,830 --> 00:13:40,470
figure out mitigations so if if I have a

330
00:13:38,190 --> 00:13:41,970
situation where I'm looking at solutions

331
00:13:40,470 --> 00:13:44,370
that are in the millions of dollars per

332
00:13:41,970 --> 00:13:46,200
year to implement trying to figure out

333
00:13:44,370 --> 00:13:47,580
if that makes sense as a company to

334
00:13:46,200 --> 00:13:50,550
invest in is a great thing to use

335
00:13:47,580 --> 00:13:53,310
annualized loss expectancy for so this

336
00:13:50,550 --> 00:13:54,990
is a measure of how how much money per

337
00:13:53,310 --> 00:13:57,989
year do we expect to lose for these

338
00:13:54,990 --> 00:14:01,410
events so if there's a $10,000 event

339
00:13:57,990 --> 00:14:03,360
that happens once every 10 years that's

340
00:14:01,410 --> 00:14:05,969
$1,000 per year for annualized loss

341
00:14:03,360 --> 00:14:09,020
expectancy that we can expect again it's

342
00:14:05,970 --> 00:14:11,070
super technical but it's very useful

343
00:14:09,020 --> 00:14:13,250
legal departments might have a problem

344
00:14:11,070 --> 00:14:16,670
with this if you start using it for

345
00:14:13,250 --> 00:14:18,990
talking about the impact of lawsuits

346
00:14:16,670 --> 00:14:21,750
just because writing down and

347
00:14:18,990 --> 00:14:25,500
quantifying the value of a potential

348
00:14:21,750 --> 00:14:28,970
lawsuit is potentially discoverable in

349
00:14:25,500 --> 00:14:28,970
litigation and could be an issue so

350
00:14:30,080 --> 00:14:34,470
going a step backwards from that right

351
00:14:33,030 --> 00:14:36,150
if we're starting at that high level of

352
00:14:34,470 --> 00:14:38,100
risk and trying to dissect it into more

353
00:14:36,150 --> 00:14:39,630
just digestible chunks we can also talk

354
00:14:38,100 --> 00:14:43,110
about just likelihood and expect an

355
00:14:39,630 --> 00:14:44,250
impact we expect a thousand times a year

356
00:14:43,110 --> 00:14:45,870
this thing is going to happen it's gonna

357
00:14:44,250 --> 00:14:46,950
cost us a grand each time it happens

358
00:14:45,870 --> 00:14:49,590
right

359
00:14:46,950 --> 00:14:51,900
someone spray paints my wall every year

360
00:14:49,590 --> 00:14:53,610
it cost me 50 bucks to fix that's 50

361
00:14:51,900 --> 00:14:55,110
bucks that I put in the bank I know that

362
00:14:53,610 --> 00:14:57,900
at the end of the year it's gonna wash

363
00:14:55,110 --> 00:14:59,280
out if you're talking to decision makers

364
00:14:57,900 --> 00:15:02,340
and stakeholders it's a great way to

365
00:14:59,280 --> 00:15:05,189
illustrate how much of a problem is this

366
00:15:02,340 --> 00:15:06,420
thing that we expect to happen how bad

367
00:15:05,190 --> 00:15:08,160
could it be

368
00:15:06,420 --> 00:15:10,020
and gives them that sort of t-shirt

369
00:15:08,160 --> 00:15:13,579
sizing concept as well without needing

370
00:15:10,020 --> 00:15:13,579
to go into annualized loss expectancy

371
00:15:17,639 --> 00:15:21,819
another good way of talking about it is

372
00:15:19,779 --> 00:15:25,720
not necessarily calculating your own

373
00:15:21,819 --> 00:15:28,259
impact we can know that for our company

374
00:15:25,720 --> 00:15:31,769
if something like this happens it's

375
00:15:28,259 --> 00:15:33,910
$5,000 to get back up and running right

376
00:15:31,769 --> 00:15:35,829
that's still hypothetical a good way of

377
00:15:33,910 --> 00:15:37,689
talking about it could to management

378
00:15:35,829 --> 00:15:39,758
could also be other companies that have

379
00:15:37,689 --> 00:15:44,199
experienced this have seen X dollars and

380
00:15:39,759 --> 00:15:45,540
lost for each reports the Verizon breach

381
00:15:44,199 --> 00:15:48,370
reports I think have a good

382
00:15:45,540 --> 00:15:49,870
quantification of companies have seen

383
00:15:48,370 --> 00:15:52,149
this kind of breach have this kind of

384
00:15:49,870 --> 00:15:53,649
dollar value loss we expect that in the

385
00:15:52,149 --> 00:15:56,230
next year we're going to have one of

386
00:15:53,649 --> 00:15:58,360
these events it really starts to put

387
00:15:56,230 --> 00:16:00,420
into perspective of how much does the

388
00:15:58,360 --> 00:16:04,149
company care about these sort of things

389
00:16:00,420 --> 00:16:05,829
if it's a huge value but it's really

390
00:16:04,149 --> 00:16:08,889
improbable that might still be a thing

391
00:16:05,829 --> 00:16:10,599
they care about so when we're talking

392
00:16:08,889 --> 00:16:11,800
about risk with management or we're

393
00:16:10,600 --> 00:16:13,149
talking about risk internally or we're

394
00:16:11,800 --> 00:16:18,310
using it for different versions of

395
00:16:13,149 --> 00:16:20,319
things there's not a right way to talk

396
00:16:18,310 --> 00:16:21,758
about risk necessarily it's just a right

397
00:16:20,319 --> 00:16:22,870
way to communicate it depends on what

398
00:16:21,759 --> 00:16:26,230
you're doing it depends on how are you

399
00:16:22,870 --> 00:16:28,149
using it so going back to operational

400
00:16:26,230 --> 00:16:30,630
versus strategic right operational being

401
00:16:28,149 --> 00:16:33,160
that I have a cue I need to prioritize

402
00:16:30,630 --> 00:16:34,360
the first two categories might be good

403
00:16:33,160 --> 00:16:36,850
ways of doing that to give you that

404
00:16:34,360 --> 00:16:38,410
stack ranking but maybe it's not the

405
00:16:36,850 --> 00:16:40,930
right thing to communicate to management

406
00:16:38,410 --> 00:16:42,310
maybe management wants to understand a

407
00:16:40,930 --> 00:16:44,138
little bit more context around it so you

408
00:16:42,310 --> 00:16:46,060
have to communicate it differently

409
00:16:44,139 --> 00:16:47,949
the point being essentially that there's

410
00:16:46,060 --> 00:16:49,930
different ways of talking about it

411
00:16:47,949 --> 00:16:51,250
and it doesn't need to be a single value

412
00:16:49,930 --> 00:16:56,170
that you come up with it can be

413
00:16:51,250 --> 00:16:59,350
dependent and so for us we've started

414
00:16:56,170 --> 00:17:00,639
using a multi-step approach that has a

415
00:16:59,350 --> 00:17:04,419
different couple of different

416
00:17:00,639 --> 00:17:06,520
categorizations of risk for us so in

417
00:17:04,419 --> 00:17:08,289
that situation going back to person

418
00:17:06,520 --> 00:17:11,220
wants to open up access to their data

419
00:17:08,289 --> 00:17:11,220
center from anywhere in the world

420
00:17:11,549 --> 00:17:17,770
normally like security would say this is

421
00:17:14,230 --> 00:17:20,860
a dumb idea push back conversations

422
00:17:17,770 --> 00:17:24,309
happen don't get a lot of don't get a

423
00:17:20,859 --> 00:17:25,418
lot of support and buy-in just happens

424
00:17:24,309 --> 00:17:28,760
anyway because there's a lack of

425
00:17:25,419 --> 00:17:31,309
understanding of how bad that thing is

426
00:17:28,760 --> 00:17:33,980
using a risk-based approach maybe the

427
00:17:31,309 --> 00:17:36,678
first step is well let's analyze how bad

428
00:17:33,980 --> 00:17:38,059
is this thing actually it could be the

429
00:17:36,679 --> 00:17:39,890
situation that we're blowing it out of

430
00:17:38,059 --> 00:17:41,299
proportion maybe it's not as bad as we

431
00:17:39,890 --> 00:17:44,320
thought maybe there's mitigations in

432
00:17:41,299 --> 00:17:47,120
place that make it not such a bad idea

433
00:17:44,320 --> 00:17:49,908
so one of the ways that we've come up

434
00:17:47,120 --> 00:17:52,010
with figuring out how how much risk is

435
00:17:49,909 --> 00:17:56,090
involved in a thing without going really

436
00:17:52,010 --> 00:17:59,830
to depth in it it's just a quick quick

437
00:17:56,090 --> 00:18:02,120
matrix of high medium level versus CIA

438
00:17:59,830 --> 00:18:04,428
we looked at all the things that we were

439
00:18:02,120 --> 00:18:07,820
getting all the security requests we

440
00:18:04,429 --> 00:18:09,320
were getting and really it boiled down

441
00:18:07,820 --> 00:18:10,879
to these are the categories that matter

442
00:18:09,320 --> 00:18:12,799
for the things that we were talking

443
00:18:10,880 --> 00:18:16,240
about is confidentiality integrity and

444
00:18:12,799 --> 00:18:19,340
availability so data classification is

445
00:18:16,240 --> 00:18:22,250
number one or two on the CIOs top 20

446
00:18:19,340 --> 00:18:24,678
super important parameter control where

447
00:18:22,250 --> 00:18:25,880
is it going to and then is this

448
00:18:24,679 --> 00:18:29,779
something that's required for business

449
00:18:25,880 --> 00:18:33,799
operations right and if you look at it

450
00:18:29,779 --> 00:18:35,330
in that aspect you can start to very

451
00:18:33,799 --> 00:18:37,250
quickly and without asking a lot of

452
00:18:35,330 --> 00:18:39,168
questions identify what are the things

453
00:18:37,250 --> 00:18:40,850
that we actually care about if it's just

454
00:18:39,169 --> 00:18:42,049
something that's happening in QA versus

455
00:18:40,850 --> 00:18:43,189
something that's happening in production

456
00:18:42,049 --> 00:18:45,950
maybe those are different things you

457
00:18:43,190 --> 00:18:48,710
look at with different intensity so for

458
00:18:45,950 --> 00:18:51,200
our example of person wants to open up

459
00:18:48,710 --> 00:18:54,590
VPN or open up access to production

460
00:18:51,200 --> 00:18:56,450
without a VPN that's super critical data

461
00:18:54,590 --> 00:18:58,340
because it's production that's access to

462
00:18:56,450 --> 00:19:01,010
production so it's crossing that trust

463
00:18:58,340 --> 00:19:02,570
boundary and it's real-time critical

464
00:19:01,010 --> 00:19:04,340
applications so it's something that

465
00:19:02,570 --> 00:19:06,428
would impact the business immediately so

466
00:19:04,340 --> 00:19:09,590
that's a high risk so what does that

467
00:19:06,429 --> 00:19:12,080
mean for us so we've identified that

468
00:19:09,590 --> 00:19:13,580
it's a high risk this is still an

469
00:19:12,080 --> 00:19:15,439
operational risk management right this

470
00:19:13,580 --> 00:19:19,279
is that transactional do we care about

471
00:19:15,440 --> 00:19:23,539
things we define what the priority is

472
00:19:19,279 --> 00:19:24,980
and we need to figure out how do we rank

473
00:19:23,539 --> 00:19:28,158
this how do we how many resources do we

474
00:19:24,980 --> 00:19:32,690
put against this so for a high risk

475
00:19:28,159 --> 00:19:34,159
level thing for example maybe maybe for

476
00:19:32,690 --> 00:19:35,570
low-risk we just let it go through we

477
00:19:34,159 --> 00:19:37,580
have some standard mitigations we

478
00:19:35,570 --> 00:19:38,840
suggest like cool you're trying to do a

479
00:19:37,580 --> 00:19:40,309
thing maybe you should think about doing

480
00:19:38,840 --> 00:19:40,520
this stuff maybe there's some things you

481
00:19:40,309 --> 00:19:43,340
can

482
00:19:40,520 --> 00:19:46,520
implement that would make it better but

483
00:19:43,340 --> 00:19:47,540
in general like go ahead and for

484
00:19:46,520 --> 00:19:49,700
high-risk things those are the things

485
00:19:47,540 --> 00:19:51,740
that we actually care about so we assign

486
00:19:49,700 --> 00:19:55,670
a team we talk with stakeholders we

487
00:19:51,740 --> 00:19:57,410
analyze it a little bit more in-depth so

488
00:19:55,670 --> 00:19:59,660
for our high-risk thing that's being

489
00:19:57,410 --> 00:20:02,000
asked of us that would be the path we go

490
00:19:59,660 --> 00:20:04,360
down this is our top priority this is

491
00:20:02,000 --> 00:20:12,140
the thing we need to do right now that

492
00:20:04,360 --> 00:20:14,840
goes to the topic you risk ownership and

493
00:20:12,140 --> 00:20:18,020
this is this is where we're starting to

494
00:20:14,840 --> 00:20:19,428
get out of the responsibility on us and

495
00:20:18,020 --> 00:20:22,309
starting to put the responsibility back

496
00:20:19,429 --> 00:20:24,050
on the business I talked about alignment

497
00:20:22,309 --> 00:20:27,559
of power and responsibility earlier and

498
00:20:24,050 --> 00:20:29,480
in reality like it's not up to security

499
00:20:27,559 --> 00:20:31,760
to actually implement any of the things

500
00:20:29,480 --> 00:20:33,559
they're requesting it's not up to us to

501
00:20:31,760 --> 00:20:35,570
determine if this is something of the

502
00:20:33,559 --> 00:20:37,730
business things is a good idea that risk

503
00:20:35,570 --> 00:20:39,409
versus reward calculation isn't

504
00:20:37,730 --> 00:20:41,210
necessarily up to us it's up to us to

505
00:20:39,410 --> 00:20:43,460
help them figure out if it meets that

506
00:20:41,210 --> 00:20:49,040
criteria or if this is something they

507
00:20:43,460 --> 00:20:51,200
want to look at more so in that lens

508
00:20:49,040 --> 00:20:52,490
right we need to figure out what level

509
00:20:51,200 --> 00:20:54,920
the business cares about different

510
00:20:52,490 --> 00:20:57,230
things it's a really simple way of doing

511
00:20:54,920 --> 00:20:58,550
that is we have figured out that this is

512
00:20:57,230 --> 00:21:00,320
a high risk we figure out this is the

513
00:20:58,550 --> 00:21:02,659
thing we need to look at who in the

514
00:21:00,320 --> 00:21:04,939
business needs to look at this and sign

515
00:21:02,660 --> 00:21:06,440
off on it to say yeah I've looked at

516
00:21:04,940 --> 00:21:09,830
this I think this is OK for us I think

517
00:21:06,440 --> 00:21:15,080
we're willing to take that risk and so

518
00:21:09,830 --> 00:21:18,500
for an example having some documented

519
00:21:15,080 --> 00:21:20,928
chart and process chart and process is

520
00:21:18,500 --> 00:21:22,490
huge by the way having a documented

521
00:21:20,929 --> 00:21:24,380
process of this is how we do things is

522
00:21:22,490 --> 00:21:27,880
how we analyze it this is consistent

523
00:21:24,380 --> 00:21:29,870
every time takes out a lot of the

524
00:21:27,880 --> 00:21:32,030
feeling like they're being ganged up on

525
00:21:29,870 --> 00:21:33,229
right it's not security doesn't like me

526
00:21:32,030 --> 00:21:36,980
they're not letting this through it's

527
00:21:33,230 --> 00:21:39,140
not security as being a blocker it's now

528
00:21:36,980 --> 00:21:41,120
we have a process we go through this

529
00:21:39,140 --> 00:21:43,130
process every time this is consistent

530
00:21:41,120 --> 00:21:45,620
this is documented this is uniform and

531
00:21:43,130 --> 00:21:46,880
it points out we're not the people that

532
00:21:45,620 --> 00:21:48,590
you should be talking to and complaining

533
00:21:46,880 --> 00:21:49,580
to the person who should be talking to

534
00:21:48,590 --> 00:21:51,949
you and complaining to you for a

535
00:21:49,580 --> 00:21:53,810
high-risk thing is actually this vice

536
00:21:51,950 --> 00:21:55,310
president or c-level over here

537
00:21:53,810 --> 00:21:57,470
actually has the responsibility for

538
00:21:55,310 --> 00:22:00,230
safeguarding these things it's not our

539
00:21:57,470 --> 00:22:02,030
job to make sure that we're safeguarding

540
00:22:00,230 --> 00:22:03,740
it's this person's job it's their

541
00:22:02,030 --> 00:22:04,280
responsibility they need to be signing

542
00:22:03,740 --> 00:22:07,610
off on it

543
00:22:04,280 --> 00:22:09,980
I almost liken this to security judo

544
00:22:07,610 --> 00:22:13,129
right we're not blocking and tackling

545
00:22:09,980 --> 00:22:15,200
we're not stopping a person we're using

546
00:22:13,130 --> 00:22:17,090
their own momentum and transferring it

547
00:22:15,200 --> 00:22:19,220
into risk production we're transferring

548
00:22:17,090 --> 00:22:20,870
it into them having to discuss with

549
00:22:19,220 --> 00:22:23,360
management and prove that this is a good

550
00:22:20,870 --> 00:22:28,729
idea rather than ostrich trying to stop

551
00:22:23,360 --> 00:22:30,620
them and block them suffering system we

552
00:22:28,730 --> 00:22:36,200
need to describe to management how bad

553
00:22:30,620 --> 00:22:38,330
of an idea this is and the way that in

554
00:22:36,200 --> 00:22:40,760
incorporated with that having some

555
00:22:38,330 --> 00:22:44,030
suggested mitigations in place is a good

556
00:22:40,760 --> 00:22:45,680
way of doing that so cool this is a high

557
00:22:44,030 --> 00:22:47,720
risk what would make it a medium risk

558
00:22:45,680 --> 00:22:49,280
what would make it a low risk what are

559
00:22:47,720 --> 00:22:51,350
the steps and the concrete things that

560
00:22:49,280 --> 00:22:53,450
could you could be put in place the

561
00:22:51,350 --> 00:22:57,260
things that could happen in order to

562
00:22:53,450 --> 00:22:59,090
reduce this level of risk and this is

563
00:22:57,260 --> 00:23:01,250
seemed like a very complex chart but

564
00:22:59,090 --> 00:23:02,720
really it's cool it's a high risk we

565
00:23:01,250 --> 00:23:05,660
figured that out by asking the three

566
00:23:02,720 --> 00:23:09,470
main questions from there we've got some

567
00:23:05,660 --> 00:23:11,120
mitigations we propose we think that you

568
00:23:09,470 --> 00:23:12,620
should put a VPN in place if you don't

569
00:23:11,120 --> 00:23:14,600
want to do that still gonna be a high

570
00:23:12,620 --> 00:23:16,879
risk if you do put a VPN in place maybe

571
00:23:14,600 --> 00:23:19,280
it's the medium maybe it's a low but

572
00:23:16,880 --> 00:23:21,110
that reduces the seniority of the person

573
00:23:19,280 --> 00:23:23,210
you have to go talk to instead of having

574
00:23:21,110 --> 00:23:24,530
to go bother a c-level or vice president

575
00:23:23,210 --> 00:23:26,060
now maybe you just have to get your

576
00:23:24,530 --> 00:23:30,230
manager to sign off on it because it's

577
00:23:26,060 --> 00:23:32,600
not such a terrible idea but by by

578
00:23:30,230 --> 00:23:34,160
putting the requirement to talk to

579
00:23:32,600 --> 00:23:37,790
someone at a significantly high enough

580
00:23:34,160 --> 00:23:39,080
level there's immediately be oh crap I

581
00:23:37,790 --> 00:23:41,480
don't really want to bother that person

582
00:23:39,080 --> 00:23:44,060
like there's that level of seniority and

583
00:23:41,480 --> 00:23:46,010
that respect for the position that makes

584
00:23:44,060 --> 00:23:49,730
people reconsider what they were doing

585
00:23:46,010 --> 00:23:51,920
initially and provides a little bit of

586
00:23:49,730 --> 00:23:53,270
emphasis and helps them make the right

587
00:23:51,920 --> 00:23:55,520
decision to actually do something about

588
00:23:53,270 --> 00:23:57,530
it and if they think it actually is

589
00:23:55,520 --> 00:23:59,090
important to do this thing then there's

590
00:23:57,530 --> 00:24:00,139
a pathway to do it you just have to talk

591
00:23:59,090 --> 00:24:02,409
to that person and get them to

592
00:24:00,140 --> 00:24:08,470
understand it

593
00:24:02,410 --> 00:24:09,880
so for us or for a national security

594
00:24:08,470 --> 00:24:12,670
team like if there's something that's

595
00:24:09,880 --> 00:24:15,700
high-risk communicating it in an

596
00:24:12,670 --> 00:24:17,530
effective way just saying like hey we're

597
00:24:15,700 --> 00:24:19,150
not approving things like security team

598
00:24:17,530 --> 00:24:21,670
doesn't approve stuff that's not our job

599
00:24:19,150 --> 00:24:23,680
we're here to tell you and inform your

600
00:24:21,670 --> 00:24:25,750
decision we think that this is a high

601
00:24:23,680 --> 00:24:28,210
risk based on the process that we have

602
00:24:25,750 --> 00:24:29,560
we're suggesting these mitigations for

603
00:24:28,210 --> 00:24:31,570
you we think that you should do these

604
00:24:29,560 --> 00:24:33,790
things which would reduce it to a lower

605
00:24:31,570 --> 00:24:35,350
risk level if you don't do that this is

606
00:24:33,790 --> 00:24:38,110
the person you need to go talk to you

607
00:24:35,350 --> 00:24:40,360
okay thanks bye like that's a very

608
00:24:38,110 --> 00:24:43,409
simple statement that is very quick easy

609
00:24:40,360 --> 00:24:46,479
to come up with getting to this point is

610
00:24:43,410 --> 00:24:48,130
minutes maybe an hour of work versus

611
00:24:46,480 --> 00:24:49,510
having to sit with the people having to

612
00:24:48,130 --> 00:24:51,550
talk with them every time this comes up

613
00:24:49,510 --> 00:24:55,690
having to go through this process and

614
00:24:51,550 --> 00:24:58,240
and be that blocker now we're just we

615
00:24:55,690 --> 00:24:59,680
can categorize risks or categories

616
00:24:58,240 --> 00:25:01,300
requests that come in into general

617
00:24:59,680 --> 00:25:02,800
buckets and then based on what they're

618
00:25:01,300 --> 00:25:05,230
asking for we can suggest pretty

619
00:25:02,800 --> 00:25:08,800
standard mitigations like the number of

620
00:25:05,230 --> 00:25:10,900
times that you see requests for specific

621
00:25:08,800 --> 00:25:13,090
things come in it's going to be

622
00:25:10,900 --> 00:25:14,410
following a pretty consistent pattern so

623
00:25:13,090 --> 00:25:16,470
if you can figure out what those things

624
00:25:14,410 --> 00:25:19,810
are they come in a lot replied

625
00:25:16,470 --> 00:25:22,180
consistent and pre-approved mitigations

626
00:25:19,810 --> 00:25:24,490
it gets to be a very quick very simple

627
00:25:22,180 --> 00:25:26,500
process instead of having to sit there

628
00:25:24,490 --> 00:25:29,550
and for each time figure out what you

629
00:25:26,500 --> 00:25:34,690
want to do suggesting common mitigations

630
00:25:29,550 --> 00:25:38,680
and a path forward so what this does

631
00:25:34,690 --> 00:25:41,170
right is instead of this being a

632
00:25:38,680 --> 00:25:45,190
conversation at the low level where it's

633
00:25:41,170 --> 00:25:48,580
people in different silos that maybe

634
00:25:45,190 --> 00:25:51,070
disagree on what's going on or don't

635
00:25:48,580 --> 00:25:53,980
understand the full context now instead

636
00:25:51,070 --> 00:25:57,850
of that project manager network engineer

637
00:25:53,980 --> 00:25:59,230
in InfoSec all fighting it out now that

638
00:25:57,850 --> 00:26:04,179
project manager needs to go talk to a

639
00:25:59,230 --> 00:26:06,280
CEO or a CTO and they're the person

640
00:26:04,180 --> 00:26:07,810
who's making the request is now in the

641
00:26:06,280 --> 00:26:10,600
reporting chain of the person who has to

642
00:26:07,810 --> 00:26:13,030
approve it so it's their management it's

643
00:26:10,600 --> 00:26:16,330
people they understand it's their risk

644
00:26:13,030 --> 00:26:24,610
to accept so they feel some responsible

645
00:26:16,330 --> 00:26:27,449
to do the right thing so important to do

646
00:26:24,610 --> 00:26:29,260
right an important note is that

647
00:26:27,450 --> 00:26:30,789
sometimes saying that this is a

648
00:26:29,260 --> 00:26:32,980
high-risk is good enough

649
00:26:30,789 --> 00:26:35,559
sometimes saying we think this is a

650
00:26:32,980 --> 00:26:37,870
1,000 thing that will cost us 10 million

651
00:26:35,559 --> 00:26:39,490
dollars is good enough it's going to

652
00:26:37,870 --> 00:26:40,870
depend on the decision-maker it's going

653
00:26:39,490 --> 00:26:43,600
to depend on who you're trying to

654
00:26:40,870 --> 00:26:45,969
influence new you're talking to so

655
00:26:43,600 --> 00:26:47,320
starting with that t-shirt size of we

656
00:26:45,970 --> 00:26:49,450
think this is a higher risk we think

657
00:26:47,320 --> 00:26:52,029
this is a low risk that sort of thing

658
00:26:49,450 --> 00:26:53,889
and moving on from there is good just

659
00:26:52,029 --> 00:26:55,269
understand that you're probably gonna

660
00:26:53,889 --> 00:26:56,559
have to discuss this in a couple

661
00:26:55,269 --> 00:27:03,639
different ways depending on you're

662
00:26:56,559 --> 00:27:07,210
talking to this is the important part so

663
00:27:03,639 --> 00:27:09,100
that's all great right we've using risk

664
00:27:07,210 --> 00:27:11,260
we figured out a way to prioritize our

665
00:27:09,100 --> 00:27:13,510
cue we figured out how do we identify

666
00:27:11,260 --> 00:27:14,590
the things that we want to work on how

667
00:27:13,510 --> 00:27:17,470
do we know them where we're gonna get

668
00:27:14,590 --> 00:27:20,309
the most impact for our time used we're

669
00:27:17,470 --> 00:27:22,899
able to move the conversation away from

670
00:27:20,309 --> 00:27:25,870
information security is blocking us and

671
00:27:22,899 --> 00:27:30,158
on to my CTO is blocking me because this

672
00:27:25,870 --> 00:27:31,510
is a dumb thing I want to do but that

673
00:27:30,159 --> 00:27:33,190
still doesn't quite work right because

674
00:27:31,510 --> 00:27:35,260
the CTO can just approve things it

675
00:27:33,190 --> 00:27:36,639
doesn't really matter if there's no

676
00:27:35,260 --> 00:27:38,559
oversight if there's no accountability

677
00:27:36,639 --> 00:27:40,779
so how do we make sure that they're

678
00:27:38,559 --> 00:27:42,760
accountable and that's the key part is

679
00:27:40,779 --> 00:27:44,919
we need to be able to record what

680
00:27:42,760 --> 00:27:46,750
happened and report on it and this is

681
00:27:44,919 --> 00:27:50,740
where that operational risk management

682
00:27:46,750 --> 00:27:56,440
flows into strategic risk management so

683
00:27:50,740 --> 00:27:58,210
when when that decision is made right so

684
00:27:56,440 --> 00:28:00,639
the CTO says cool you can go ahead and

685
00:27:58,210 --> 00:28:03,549
do this remove all these rules open it

686
00:28:00,639 --> 00:28:05,529
all up it's all good how that looks

687
00:28:03,549 --> 00:28:07,480
it isn't on the security team to ever

688
00:28:05,529 --> 00:28:08,919
proved it it's not even on the project

689
00:28:07,480 --> 00:28:11,980
manager to have approved it it's on the

690
00:28:08,919 --> 00:28:14,440
CTO that he approved it so when the CEO

691
00:28:11,980 --> 00:28:17,620
looks down and says who's responsible

692
00:28:14,440 --> 00:28:20,559
for this giant idiotic thing that we've

693
00:28:17,620 --> 00:28:23,080
done the big red spot is on the CTL

694
00:28:20,559 --> 00:28:25,870
because it's his responsibility

695
00:28:23,080 --> 00:28:27,520
so we've now aligned power and

696
00:28:25,870 --> 00:28:29,020
responsibility he was empowered to do

697
00:28:27,520 --> 00:28:29,590
that but he's also responsible for the

698
00:28:29,020 --> 00:28:35,139
real

699
00:28:29,590 --> 00:28:37,629
results of his actions and put together

700
00:28:35,140 --> 00:28:40,539
with all the other risks that are done

701
00:28:37,630 --> 00:28:42,640
and accepted in the year you can compile

702
00:28:40,539 --> 00:28:44,320
a report that shows who in the

703
00:28:42,640 --> 00:28:46,450
businesses accept the most risk which

704
00:28:44,320 --> 00:28:49,720
people are responsible for opening these

705
00:28:46,450 --> 00:28:51,400
things and providing that visibility up

706
00:28:49,720 --> 00:28:53,230
top or management putting their name on

707
00:28:51,400 --> 00:28:56,730
the record saying this person made this

708
00:28:53,230 --> 00:28:59,500
decision this person took this action

709
00:28:56,730 --> 00:29:02,919
sunlight is the best disinfectant right

710
00:28:59,500 --> 00:29:04,690
if these are allowed to happen in a

711
00:29:02,919 --> 00:29:06,130
vacuum if people are allowed to just to

712
00:29:04,690 --> 00:29:08,380
prove things willy nilly and there's no

713
00:29:06,130 --> 00:29:10,299
reporting there's no accountability then

714
00:29:08,380 --> 00:29:13,570
it's gonna keep taking the path of least

715
00:29:10,299 --> 00:29:16,029
resistance which is just get it done but

716
00:29:13,570 --> 00:29:17,830
by making them accountable and by

717
00:29:16,029 --> 00:29:19,690
putting their name on a list saying this

718
00:29:17,830 --> 00:29:22,449
person took this action this person made

719
00:29:19,690 --> 00:29:23,590
this decision and not the skirty guy a

720
00:29:22,450 --> 00:29:26,380
security guy didn't make the decision

721
00:29:23,590 --> 00:29:28,178
CTO made this decision that takes the

722
00:29:26,380 --> 00:29:29,799
responsibility off the engineer that

723
00:29:28,179 --> 00:29:31,809
puts the responsibility where it should

724
00:29:29,799 --> 00:29:33,820
be and that make sure that the people

725
00:29:31,809 --> 00:29:37,620
who are responsible for making the right

726
00:29:33,820 --> 00:29:37,620
decisions make the right decisions so

727
00:29:39,510 --> 00:29:45,039
once we've got that once you have the

728
00:29:43,179 --> 00:29:47,350
right people identified once we have the

729
00:29:45,039 --> 00:29:49,419
risks identified the operational side is

730
00:29:47,350 --> 00:29:52,539
done moving more into strategic risk

731
00:29:49,419 --> 00:29:55,149
management it's entirely possible that

732
00:29:52,539 --> 00:29:57,220
that one decision to open up that access

733
00:29:55,149 --> 00:29:59,699
for production might not be the

734
00:29:57,220 --> 00:30:03,100
terriblest thing that happened that year

735
00:29:59,700 --> 00:30:04,779
so if access to DC without VPN is down

736
00:30:03,100 --> 00:30:06,879
there at the bottom left like in yellow

737
00:30:04,779 --> 00:30:10,090
if we roll up everything that happened

738
00:30:06,880 --> 00:30:11,350
during the year and we can you can look

739
00:30:10,090 --> 00:30:13,029
through all the risks that have been

740
00:30:11,350 --> 00:30:15,279
opened and you can start grouping them

741
00:30:13,029 --> 00:30:15,870
into common things ACLs that have been

742
00:30:15,279 --> 00:30:17,919
opened

743
00:30:15,870 --> 00:30:21,959
vulnerabilities for systems that aren't

744
00:30:17,919 --> 00:30:23,740
patched applications that don't have

745
00:30:21,960 --> 00:30:25,659
remediations for vulnerable eyes they've

746
00:30:23,740 --> 00:30:27,340
been found through bugcrowd whatever it

747
00:30:25,659 --> 00:30:29,830
is you can roll these into larger and

748
00:30:27,340 --> 00:30:32,080
larger categories until it's up a level

749
00:30:29,830 --> 00:30:35,110
that management is more concerned about

750
00:30:32,080 --> 00:30:36,460
that higher level grouping so if data

751
00:30:35,110 --> 00:30:39,039
protection is the thing they care about

752
00:30:36,460 --> 00:30:40,710
right we can dissect that into technical

753
00:30:39,039 --> 00:30:43,210
and

754
00:30:40,710 --> 00:30:45,520
technical attacks and on potential leaks

755
00:30:43,210 --> 00:30:48,040
we can dissect that even further you can

756
00:30:45,520 --> 00:30:49,360
get down to understanding what what is

757
00:30:48,040 --> 00:30:50,889
the thing what is the thing that is the

758
00:30:49,360 --> 00:30:53,500
biggest risk for the company and how do

759
00:30:50,890 --> 00:30:55,180
I go about reducing risk you inform

760
00:30:53,500 --> 00:30:57,010
decision-makers about the level of risk

761
00:30:55,180 --> 00:30:59,680
they're taking and show them where this

762
00:30:57,010 --> 00:31:02,170
is happening and so if that does come

763
00:30:59,680 --> 00:31:03,790
back that access to the DC without a VPN

764
00:31:02,170 --> 00:31:06,760
is the biggest problem the company has

765
00:31:03,790 --> 00:31:09,159
now not only can you say yes this is our

766
00:31:06,760 --> 00:31:17,230
problem you also can say and the CTO

767
00:31:09,160 --> 00:31:18,520
approved this so when you're when you're

768
00:31:17,230 --> 00:31:20,470
talking to senior management a good way

769
00:31:18,520 --> 00:31:24,760
of talking about it is that likelihood

770
00:31:20,470 --> 00:31:27,040
and impact thing it's like I said maybe

771
00:31:24,760 --> 00:31:28,750
so sensitive data leaking is the biggest

772
00:31:27,040 --> 00:31:30,159
thing there might be some other things

773
00:31:28,750 --> 00:31:33,010
on there but just keeping and rolling it

774
00:31:30,160 --> 00:31:35,290
up into larger and larger groups until

775
00:31:33,010 --> 00:31:38,440
you have a level of understanding that

776
00:31:35,290 --> 00:31:40,000
management cares about and displaying it

777
00:31:38,440 --> 00:31:41,230
even if something as simple as this like

778
00:31:40,000 --> 00:31:43,570
with everything all rolled together

779
00:31:41,230 --> 00:31:45,370
where there's one chart that just shows

780
00:31:43,570 --> 00:31:48,730
all the things together at a very high

781
00:31:45,370 --> 00:31:50,229
level is a good place to start if you've

782
00:31:48,730 --> 00:31:51,370
got nothing right now if you're just

783
00:31:50,230 --> 00:31:53,770
saying there's a bunch of stuff out

784
00:31:51,370 --> 00:31:56,520
there having something that's just broad

785
00:31:53,770 --> 00:32:02,110
categories it's a great place to start

786
00:31:56,520 --> 00:32:04,480
so what this is right for people who've

787
00:32:02,110 --> 00:32:06,399
gone through NIST or other compliance

788
00:32:04,480 --> 00:32:07,990
frameworks or whatever probably

789
00:32:06,400 --> 00:32:10,690
recognize that this is just basically

790
00:32:07,990 --> 00:32:14,140
GRC that I've talked about right this is

791
00:32:10,690 --> 00:32:16,330
literally just GRC this is risk

792
00:32:14,140 --> 00:32:17,950
informing governance right so risk

793
00:32:16,330 --> 00:32:20,020
tolerance within the business informs

794
00:32:17,950 --> 00:32:22,420
what policies you create policies in its

795
00:32:20,020 --> 00:32:24,040
governance and that's what management

796
00:32:22,420 --> 00:32:25,840
says it needs to be done and then

797
00:32:24,040 --> 00:32:28,240
governance is checked by compliance

798
00:32:25,840 --> 00:32:29,649
compliance sees are these things

799
00:32:28,240 --> 00:32:31,930
actually being done in the business and

800
00:32:29,650 --> 00:32:33,970
then level of non-compliance goes back

801
00:32:31,930 --> 00:32:35,580
in reinforced resk which Korean forms

802
00:32:33,970 --> 00:32:37,450
governance and the cycle starts again

803
00:32:35,580 --> 00:32:40,110
it's the circle of life

804
00:32:37,450 --> 00:32:40,110
and this is

805
00:32:40,870 --> 00:32:46,370
it's a critical section of a security

806
00:32:44,540 --> 00:32:48,530
program right if you're just sitting

807
00:32:46,370 --> 00:32:50,570
there and introducing if you're just

808
00:32:48,530 --> 00:32:53,690
being the squeaky wheel in in the the

809
00:32:50,570 --> 00:32:55,159
machine right it's not necessarily gonna

810
00:32:53,690 --> 00:32:57,020
be the most effective way to get things

811
00:32:55,160 --> 00:32:58,730
done but if you have a process if you

812
00:32:57,020 --> 00:33:02,870
have a way to influence the company if

813
00:32:58,730 --> 00:33:05,150
you're making if you're providing data

814
00:33:02,870 --> 00:33:06,949
based decisions and data to support

815
00:33:05,150 --> 00:33:15,890
those decisions it's a lot more

816
00:33:06,950 --> 00:33:18,260
effective so what do we do so we so by

817
00:33:15,890 --> 00:33:20,030
implementing a risk-based approach to

818
00:33:18,260 --> 00:33:21,140
security management right you can

819
00:33:20,030 --> 00:33:22,820
improve the relationship between

820
00:33:21,140 --> 00:33:24,830
security in the business you stopped

821
00:33:22,820 --> 00:33:27,740
being a blocker right instead of being a

822
00:33:24,830 --> 00:33:30,889
blocker so the business now says cool

823
00:33:27,740 --> 00:33:32,810
how do I reduce risk right if I'm if my

824
00:33:30,890 --> 00:33:36,470
metrics are now about risk reduction if

825
00:33:32,810 --> 00:33:38,899
I'm now being judged on how well I'm

826
00:33:36,470 --> 00:33:41,600
doing for Risk Reduction they're gonna

827
00:33:38,900 --> 00:33:44,570
actually look at you as someone who can

828
00:33:41,600 --> 00:33:46,129
help right they're gonna understand okay

829
00:33:44,570 --> 00:33:47,780
I'm taking these actions how can you

830
00:33:46,130 --> 00:33:50,330
mitigate them what can we do to support

831
00:33:47,780 --> 00:33:51,290
that and not only that you're not a

832
00:33:50,330 --> 00:33:52,639
blocker anymore

833
00:33:51,290 --> 00:33:54,440
like if the business wants to do

834
00:33:52,640 --> 00:33:55,970
something that's fine

835
00:33:54,440 --> 00:33:57,410
that's up to the business that's not you

836
00:33:55,970 --> 00:33:59,840
to say no that's not you to feel

837
00:33:57,410 --> 00:34:01,700
responsible for the business can take

838
00:33:59,840 --> 00:34:03,290
that risk and move forward and now it's

839
00:34:01,700 --> 00:34:05,660
categorized and that's catalog maybe

840
00:34:03,290 --> 00:34:07,159
later we'll get back to it but for now

841
00:34:05,660 --> 00:34:09,639
the business says we're going forward

842
00:34:07,160 --> 00:34:12,350
cool that's great

843
00:34:09,639 --> 00:34:15,739
it improves visibility so now we know

844
00:34:12,350 --> 00:34:18,199
what's wrong instead of maybe we've got

845
00:34:15,739 --> 00:34:20,299
a word doc that we've been working on

846
00:34:18,199 --> 00:34:22,460
for years with all the terrible things

847
00:34:20,300 --> 00:34:25,000
that are wrong at the company that we've

848
00:34:22,460 --> 00:34:27,139
been updating forever maybe we've got a

849
00:34:25,000 --> 00:34:29,330
bunch of post-it notes somewhere with

850
00:34:27,139 --> 00:34:31,009
all this stuff instead of having it in

851
00:34:29,330 --> 00:34:32,989
different places now we have a single

852
00:34:31,010 --> 00:34:35,000
place that has a good repository of

853
00:34:32,989 --> 00:34:37,069
here's all the things we need to fix so

854
00:34:35,000 --> 00:34:39,020
when it comes time to say well tell me

855
00:34:37,070 --> 00:34:40,340
what we need to go after I've got five

856
00:34:39,020 --> 00:34:42,050
million dollars for a security budget

857
00:34:40,340 --> 00:34:44,149
this year what are we gonna do now we've

858
00:34:42,050 --> 00:34:45,710
got actual intelligence that tells us

859
00:34:44,149 --> 00:34:47,389
these are the things that we care about

860
00:34:45,710 --> 00:34:48,889
here are the high-risk things within the

861
00:34:47,389 --> 00:34:53,290
business this is where we need to go

862
00:34:48,889 --> 00:34:55,270
first and faster response time

863
00:34:53,290 --> 00:34:58,990
one of the biggest challenges that I've

864
00:34:55,270 --> 00:35:00,759
had as a security engineer is I it takes

865
00:34:58,990 --> 00:35:02,830
a lot of time to come up with a good

866
00:35:00,760 --> 00:35:05,590
response to a lot of the things that

867
00:35:02,830 --> 00:35:07,270
people ask for it right even for some of

868
00:35:05,590 --> 00:35:09,369
the small things some of the small

869
00:35:07,270 --> 00:35:12,940
firewall changes or products that want

870
00:35:09,369 --> 00:35:16,090
to go out there coming up with a good a

871
00:35:12,940 --> 00:35:18,760
good well-thought-out sound response

872
00:35:16,090 --> 00:35:21,250
takes a lot of time so being able to

873
00:35:18,760 --> 00:35:23,230
identify what do I actually want to what

874
00:35:21,250 --> 00:35:24,910
requests what things do I want to take

875
00:35:23,230 --> 00:35:27,280
the most time on what do I want to spend

876
00:35:24,910 --> 00:35:29,020
my energy on versus what are the things

877
00:35:27,280 --> 00:35:31,300
that I'm not really gonna get we're good

878
00:35:29,020 --> 00:35:32,770
for risk reduction for being able to

879
00:35:31,300 --> 00:35:36,880
identify the difference between those

880
00:35:32,770 --> 00:35:39,460
two is huge and allows us to to let a

881
00:35:36,880 --> 00:35:42,010
lot of the lower stuff go with a lot

882
00:35:39,460 --> 00:35:43,630
less scrutiny and we're still getting

883
00:35:42,010 --> 00:35:46,390
risk reduction we're still going after

884
00:35:43,630 --> 00:35:48,760
the high value things but maybe the

885
00:35:46,390 --> 00:35:50,980
things that don't matter so much maybe

886
00:35:48,760 --> 00:35:52,570
we can provide some generic assistance

887
00:35:50,980 --> 00:35:56,170
and some generic advice but they're not

888
00:35:52,570 --> 00:35:57,790
getting that the same level of effort

889
00:35:56,170 --> 00:36:02,109
and care that a company ending risk

890
00:35:57,790 --> 00:36:07,330
would get right so what are we get

891
00:36:02,109 --> 00:36:10,299
instead so instead of feeling

892
00:36:07,330 --> 00:36:11,890
responsible instead of being the

893
00:36:10,300 --> 00:36:14,590
responsible person feeling that burden

894
00:36:11,890 --> 00:36:16,270
on yourself now you're putting the

895
00:36:14,590 --> 00:36:18,100
burden back on the business now it's up

896
00:36:16,270 --> 00:36:19,920
to the business to tell you what do I

897
00:36:18,100 --> 00:36:23,440
care about are these things that matter

898
00:36:19,920 --> 00:36:25,420
so instead of feeling all that pressure

899
00:36:23,440 --> 00:36:28,420
yourself you're putting it back on the

900
00:36:25,420 --> 00:36:30,609
business so when you attempt for her

901
00:36:28,420 --> 00:36:32,260
security managers actually support it

902
00:36:30,609 --> 00:36:33,670
you actually have their support because

903
00:36:32,260 --> 00:36:34,960
now they're being they're the ones that

904
00:36:33,670 --> 00:36:37,359
are being judged they're the ones with

905
00:36:34,960 --> 00:36:39,580
their names on the line so they're

906
00:36:37,359 --> 00:36:41,350
responsible for ensuring security so

907
00:36:39,580 --> 00:36:44,560
they actually want to happen so you get

908
00:36:41,350 --> 00:36:45,700
support or you don't get support they

909
00:36:44,560 --> 00:36:49,390
let it through and it's not your problem

910
00:36:45,700 --> 00:36:50,439
anymore it doesn't matter actual

911
00:36:49,390 --> 00:36:52,210
implementation of new measures you

912
00:36:50,440 --> 00:36:55,300
actually get things done things actually

913
00:36:52,210 --> 00:36:57,340
improve you feel better about it and you

914
00:36:55,300 --> 00:37:00,220
feel reinvigorated so instead of burning

915
00:36:57,340 --> 00:37:02,260
out that burnout is gone and instead you

916
00:37:00,220 --> 00:37:02,830
get this sense of wow that actually

917
00:37:02,260 --> 00:37:04,570
worked

918
00:37:02,830 --> 00:37:06,460
someone actually wanted to do something

919
00:37:04,570 --> 00:37:07,160
I want to do this again and you get

920
00:37:06,460 --> 00:37:11,540
people that are

921
00:37:07,160 --> 00:37:15,529
reinvigorated and want to continue so

922
00:37:11,540 --> 00:37:17,860
that's for me at least that's how I've

923
00:37:15,530 --> 00:37:21,740
figured out how to get out of that

924
00:37:17,860 --> 00:37:24,460
burnout cycle and using risk to put that

925
00:37:21,740 --> 00:37:28,879
back on management using a consistent

926
00:37:24,460 --> 00:37:31,340
well-documented format has been critical

927
00:37:28,880 --> 00:37:32,990
i think our boss has said in the last

928
00:37:31,340 --> 00:37:34,550
couple months liked it by implementing

929
00:37:32,990 --> 00:37:37,729
this process he feels like the dog that

930
00:37:34,550 --> 00:37:39,350
caught the car he's he's been in this

931
00:37:37,730 --> 00:37:40,790
business so long and been fighting that

932
00:37:39,350 --> 00:37:42,589
battle for so long that he's not sure

933
00:37:40,790 --> 00:37:48,279
what to do when business actually helps

934
00:37:42,590 --> 00:37:51,530
so it's it works and i think that's

935
00:37:48,280 --> 00:38:06,530
pretty much the the point that's all my

936
00:37:51,530 --> 00:38:07,910
stuff i hope your questions so two

937
00:38:06,530 --> 00:38:10,580
aspects that question which is a good

938
00:38:07,910 --> 00:38:12,710
one by having a consistent and

939
00:38:10,580 --> 00:38:15,440
documented method right for saying

940
00:38:12,710 --> 00:38:18,340
people at this level accept this level

941
00:38:15,440 --> 00:38:20,270
of risk you can't get them out of

942
00:38:18,340 --> 00:38:22,070
accepting that risk if they're either

943
00:38:20,270 --> 00:38:24,640
going to have to accept themselves or

944
00:38:22,070 --> 00:38:28,610
designate someone else doing that risk

945
00:38:24,640 --> 00:38:29,900
if they say that this risk can be

946
00:38:28,610 --> 00:38:31,730
accepted or mitigated by someone else

947
00:38:29,900 --> 00:38:34,070
it's still them who has their name on

948
00:38:31,730 --> 00:38:36,920
the line it's just the decision was made

949
00:38:34,070 --> 00:38:39,020
by someone else so that's again where

950
00:38:36,920 --> 00:38:41,950
that consistent documentation comes into

951
00:38:39,020 --> 00:38:41,950
play and is a huge factor

952
00:38:50,170 --> 00:38:56,420
yeah but so that's that's where the the

953
00:38:55,100 --> 00:39:01,250
jus aspect comes back into play right

954
00:38:56,420 --> 00:39:04,610
instead of if you set up yourself to be

955
00:39:01,250 --> 00:39:06,200
in line with those requests if security

956
00:39:04,610 --> 00:39:08,960
has to sign off on network requests

957
00:39:06,200 --> 00:39:10,520
before they're done then it's it's not a

958
00:39:08,960 --> 00:39:12,440
question of well security didn't sign

959
00:39:10,520 --> 00:39:14,240
off on it it's that person didn't sign

960
00:39:12,440 --> 00:39:15,920
off on it and so now they're the blocker

961
00:39:14,240 --> 00:39:18,259
that has to have come back and put their

962
00:39:15,920 --> 00:39:19,760
name on the line and so putting that

963
00:39:18,260 --> 00:39:21,470
into the process that being the

964
00:39:19,760 --> 00:39:23,150
documented process of how things happen

965
00:39:21,470 --> 00:39:26,180
is this person needs to put their name

966
00:39:23,150 --> 00:39:27,890
on it gives them that concrete reason to

967
00:39:26,180 --> 00:39:39,319
go in and do that instead of that verbal

968
00:39:27,890 --> 00:39:40,819
I guess go ahead yeah we've been pretty

969
00:39:39,320 --> 00:39:43,910
successful with network requests so far

970
00:39:40,820 --> 00:39:45,890
at least and when a new request comes in

971
00:39:43,910 --> 00:39:48,799
it goes to security for analysis and

972
00:39:45,890 --> 00:39:51,160
review and then the risk process takes

973
00:39:48,800 --> 00:39:53,660
over there's a person that accepts it's

974
00:39:51,160 --> 00:39:55,069
surprisingly little resistance to that

975
00:39:53,660 --> 00:39:57,649
process because we've been quick enough

976
00:39:55,070 --> 00:39:59,960
that we're not seen as the blocker right

977
00:39:57,650 --> 00:40:02,360
the problem comes in when if the process

978
00:39:59,960 --> 00:40:04,310
is so long and so tedious that it

979
00:40:02,360 --> 00:40:07,580
becomes the blocker itself that's the

980
00:40:04,310 --> 00:40:10,370
problem so having those three questions

981
00:40:07,580 --> 00:40:11,990
that we asked right being so quick in

982
00:40:10,370 --> 00:40:13,339
the response is critical to getting that

983
00:40:11,990 --> 00:40:15,430
buy-in and people just going with the

984
00:40:13,340 --> 00:40:15,430
flow

985
00:40:18,860 --> 00:40:23,320
all right well thanks folks that's

986
00:40:20,660 --> 00:40:23,319
that's

987
00:40:25,440 --> 00:40:29,420
[Applause]

988
00:40:35,599 --> 00:40:37,660
you

