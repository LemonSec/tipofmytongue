1
00:00:17,920 --> 00:00:21,039
i'm excited to be here in texas excited

2
00:00:21,039 --> 00:00:23,760
to be in front of a live studio audience

3
00:00:23,760 --> 00:00:25,359
i was joking around i was i was speaking

4
00:00:25,359 --> 00:00:26,960
at another event on thursday morning

5
00:00:26,960 --> 00:00:28,720
another virtual event i was joking with

6
00:00:28,720 --> 00:00:31,119
the kind of virtual moderator about like

7
00:00:31,119 --> 00:00:32,640
i hope i don't look up at some point

8
00:00:32,640 --> 00:00:33,760
during the talk and be like hey could

9
00:00:33,760 --> 00:00:36,160
you mute yourself ooh that's a zoom

10
00:00:36,160 --> 00:00:39,280
thing sorry live room wasn't really sure

11
00:00:39,280 --> 00:00:41,520
i'm going to get rid of this

12
00:00:41,520 --> 00:00:42,399
okay

13
00:00:42,399 --> 00:00:43,520
so we're going to talk about using the

14
00:00:43,520 --> 00:00:45,440
threat modeling manifesto to build an

15
00:00:45,440 --> 00:00:48,559
enterprise threat modeling program so

16
00:00:48,559 --> 00:00:50,640
just tiny bit of background about me i'm

17
00:00:50,640 --> 00:00:52,719
the ceo and co-founder of security

18
00:00:52,719 --> 00:00:54,239
journey so we focus on security

19
00:00:54,239 --> 00:00:57,440
education and uh security belt programs

20
00:00:57,440 --> 00:00:58,800
i've been running around the world of

21
00:00:58,800 --> 00:01:00,879
security for quite a while now i'm

22
00:01:00,879 --> 00:01:03,520
almost 25 years i spent 10 years of that

23
00:01:03,520 --> 00:01:05,680
time at cisco i did a number of things

24
00:01:05,680 --> 00:01:08,000
at cisco building education but also

25
00:01:08,000 --> 00:01:09,439
rolling out cisco's threat modeling

26
00:01:09,439 --> 00:01:11,200
program in the very early days

27
00:01:11,200 --> 00:01:13,360
so a lot of my experience comes from the

28
00:01:13,360 --> 00:01:15,119
trenches of trying to figure this stuff

29
00:01:15,119 --> 00:01:17,280
out and do it at scale at a really big

30
00:01:17,280 --> 00:01:18,240
company

31
00:01:18,240 --> 00:01:20,240
i'm also the co-host of the application

32
00:01:20,240 --> 00:01:22,799
security podcast so i know not a great

33
00:01:22,799 --> 00:01:24,720
marketing name but you do know exactly

34
00:01:24,720 --> 00:01:26,479
what you're going to hear if you tune in

35
00:01:26,479 --> 00:01:28,720
we've done 170 episodes with the likes

36
00:01:28,720 --> 00:01:31,280
of matt cesaro for example pretty famous

37
00:01:31,280 --> 00:01:32,799
guy in the room here it's just because

38
00:01:32,799 --> 00:01:34,640
he's been on the podcast you know

39
00:01:34,640 --> 00:01:36,640
but yeah check it out it's uh you know

40
00:01:36,640 --> 00:01:38,320
it's just i talked to lots of people

41
00:01:38,320 --> 00:01:39,920
from owasp lots of different project

42
00:01:39,920 --> 00:01:41,600
leads talk to matt in the defect dojo

43
00:01:41,600 --> 00:01:43,439
context trying to understand what is

44
00:01:43,439 --> 00:01:44,799
this project what can it do for your

45
00:01:44,799 --> 00:01:46,720
appsec program i'm also a big fan of

46
00:01:46,720 --> 00:01:47,920
twitter so you can always hit me up

47
00:01:47,920 --> 00:01:49,200
there as well you'll find me at

48
00:01:49,200 --> 00:01:52,720
edgeroute or the podcast address as well

49
00:01:52,720 --> 00:01:54,159
so here's how i'm going to use my time

50
00:01:54,159 --> 00:01:56,719
today and i want to make this very

51
00:01:56,719 --> 00:01:58,719
interactive as well and i want to leave

52
00:01:58,719 --> 00:02:01,040
a lot of time for questions at the end

53
00:02:01,040 --> 00:02:04,079
but i want you to first understand this

54
00:02:04,079 --> 00:02:05,280
thing called the threat modeling

55
00:02:05,280 --> 00:02:07,280
manifesto so i'm going to introduce that

56
00:02:07,280 --> 00:02:08,399
to you and tell you a little bit of the

57
00:02:08,399 --> 00:02:10,560
back story about how we got there

58
00:02:10,560 --> 00:02:11,680
then i'm going to walk through the

59
00:02:11,680 --> 00:02:13,200
values and principles of the threat

60
00:02:13,200 --> 00:02:15,280
modeling manifesto talk about some of

61
00:02:15,280 --> 00:02:17,680
the patterns and anti-patterns that this

62
00:02:17,680 --> 00:02:19,360
group of people put together in this

63
00:02:19,360 --> 00:02:20,400
document

64
00:02:20,400 --> 00:02:21,840
and then i'll give you some of my

65
00:02:21,840 --> 00:02:23,200
perspective on

66
00:02:23,200 --> 00:02:24,879
how can you build an enterprise grade

67
00:02:24,879 --> 00:02:26,640
threat modeling program some tips and

68
00:02:26,640 --> 00:02:28,640
things that i've just learned over time

69
00:02:28,640 --> 00:02:29,599
and i've

70
00:02:29,599 --> 00:02:31,360
shared those with different people and

71
00:02:31,360 --> 00:02:32,640
they've been able to put those into

72
00:02:32,640 --> 00:02:34,400
action

73
00:02:34,400 --> 00:02:35,920
so one of the challenges that a lot of

74
00:02:35,920 --> 00:02:37,599
people face with threat modeling now

75
00:02:37,599 --> 00:02:39,360
it's not the challenge is not the fact

76
00:02:39,360 --> 00:02:41,599
that we want to do threat modeling right

77
00:02:41,599 --> 00:02:43,120
like most people are like oh yeah we

78
00:02:43,120 --> 00:02:45,120
need to do threat modeling the challenge

79
00:02:45,120 --> 00:02:47,200
i hear from a lot of people is

80
00:02:47,200 --> 00:02:48,959
where do we start what is threat

81
00:02:48,959 --> 00:02:50,480
modeling how do we get this thing to

82
00:02:50,480 --> 00:02:51,760
scale to a point where we've got

83
00:02:51,760 --> 00:02:54,000
everybody doing it it's easy to teach

84
00:02:54,000 --> 00:02:55,840
two people how to threat model

85
00:02:55,840 --> 00:02:57,280
teaching a thousand people how to threat

86
00:02:57,280 --> 00:02:59,040
model and getting them to do it in on a

87
00:02:59,040 --> 00:03:01,120
regular basis is a lot bigger challenge

88
00:03:01,120 --> 00:03:03,519
so how many people in the room right now

89
00:03:03,519 --> 00:03:06,480
are doing threat modeling as appsec

90
00:03:06,480 --> 00:03:08,400
people

91
00:03:08,400 --> 00:03:10,080
okay do we have any developers in the

92
00:03:10,080 --> 00:03:11,360
room

93
00:03:11,360 --> 00:03:13,200
okay a couple developers as well okay

94
00:03:13,200 --> 00:03:14,400
have you done threat modeling as a

95
00:03:14,400 --> 00:03:16,080
developer

96
00:03:16,080 --> 00:03:18,480
yeah okay cool all right um so let's

97
00:03:18,480 --> 00:03:21,120
let's dive in and uh and kind of explore

98
00:03:21,120 --> 00:03:24,000
this topic in a little more depth so

99
00:03:24,000 --> 00:03:26,879
the threat modeling manifesto uh is a

100
00:03:26,879 --> 00:03:29,120
group of us came together oh boy about a

101
00:03:29,120 --> 00:03:31,120
year and a half ago now a bunch of

102
00:03:31,120 --> 00:03:32,480
people that have done threat modeling at

103
00:03:32,480 --> 00:03:34,239
a lot of different places we have some

104
00:03:34,239 --> 00:03:36,480
people on this list who are academic

105
00:03:36,480 --> 00:03:38,400
folks we have consultants we have

106
00:03:38,400 --> 00:03:40,640
authors somehow i got my name on the

107
00:03:40,640 --> 00:03:42,640
list this is what happens if you start a

108
00:03:42,640 --> 00:03:44,080
group and invite a bunch of really smart

109
00:03:44,080 --> 00:03:45,599
people they let you stay at the party

110
00:03:45,599 --> 00:03:47,680
after after you bring them to the party

111
00:03:47,680 --> 00:03:48,480
um

112
00:03:48,480 --> 00:03:50,159
but you know like if you look at any if

113
00:03:50,159 --> 00:03:51,920
you look up a threat modeling book on

114
00:03:51,920 --> 00:03:53,920
amazon likely one of the names on this

115
00:03:53,920 --> 00:03:55,360
list is going to appear as the author

116
00:03:55,360 --> 00:03:57,840
you know izar taran dash and matt coles

117
00:03:57,840 --> 00:03:59,599
and adam shostak and brook schoenfeld a

118
00:03:59,599 --> 00:04:01,200
lot of people that have written a lot

119
00:04:01,200 --> 00:04:02,959
about this topic and so what we did is

120
00:04:02,959 --> 00:04:04,400
we got together and said

121
00:04:04,400 --> 00:04:05,599
what could we

122
00:04:05,599 --> 00:04:07,360
how can we bring all of our experience

123
00:04:07,360 --> 00:04:09,840
together into one document and try to

124
00:04:09,840 --> 00:04:11,680
give people a foundation to understand

125
00:04:11,680 --> 00:04:13,680
what is threat modeling and then what

126
00:04:13,680 --> 00:04:14,959
are some of the things that we've seen

127
00:04:14,959 --> 00:04:17,759
be successful in in doing this at a lot

128
00:04:17,759 --> 00:04:20,160
of different levels and scale and so the

129
00:04:20,160 --> 00:04:21,839
document itself is at the threat model

130
00:04:21,839 --> 00:04:23,680
it's at threatmodelingmanifesto.org

131
00:04:23,680 --> 00:04:25,040
you can go check it out and i'm going to

132
00:04:25,040 --> 00:04:27,600
highlight a lot of pieces of it here but

133
00:04:27,600 --> 00:04:28,960
it was designed to be something you

134
00:04:28,960 --> 00:04:30,560
could take as a practitioner and share

135
00:04:30,560 --> 00:04:32,880
with your organization as a foundational

136
00:04:32,880 --> 00:04:34,639
piece for you know what we're trying to

137
00:04:34,639 --> 00:04:35,919
do

138
00:04:35,919 --> 00:04:37,280
i'm not going to talk about basics of

139
00:04:37,280 --> 00:04:39,120
threat modeling very much in this talk

140
00:04:39,120 --> 00:04:41,360
but i will share the definition that we

141
00:04:41,360 --> 00:04:42,800
as a group came together i mean look at

142
00:04:42,800 --> 00:04:44,639
that there's 15 people on that list

143
00:04:44,639 --> 00:04:46,479
guess what this is a very opinionated

144
00:04:46,479 --> 00:04:48,160
group of people especially when it comes

145
00:04:48,160 --> 00:04:50,240
to threat modeling and so

146
00:04:50,240 --> 00:04:52,320
this is the definition that we all

147
00:04:52,320 --> 00:04:54,080
manage to live with

148
00:04:54,080 --> 00:04:56,880
i'll put it at that i didn't love it at

149
00:04:56,880 --> 00:04:58,639
first but i've come around i've started

150
00:04:58,639 --> 00:05:00,639
it to to use it naturally now because it

151
00:05:00,639 --> 00:05:01,840
is a good description of what we're

152
00:05:01,840 --> 00:05:03,600
trying to do with threat modeling so

153
00:05:03,600 --> 00:05:04,960
when we say threat modeling this is

154
00:05:04,960 --> 00:05:07,039
analyzing representations of a system to

155
00:05:07,039 --> 00:05:08,960
highlight concerns about security and

156
00:05:08,960 --> 00:05:10,639
privacy don't forget that and privacy

157
00:05:10,639 --> 00:05:12,479
part that's really important threat

158
00:05:12,479 --> 00:05:14,560
modeling has been primarily a security

159
00:05:14,560 --> 00:05:16,880
thing in the past and we've got some

160
00:05:16,880 --> 00:05:18,720
ways to do it from a privacy perspective

161
00:05:18,720 --> 00:05:20,479
now as well and and we need to encourage

162
00:05:20,479 --> 00:05:22,400
a lot more of that but analyzing

163
00:05:22,400 --> 00:05:24,080
representations what's a representation

164
00:05:24,080 --> 00:05:26,000
representation could be a data flow

165
00:05:26,000 --> 00:05:28,560
diagram it could be a piece of code

166
00:05:28,560 --> 00:05:29,680
threat modeling you know in a threat

167
00:05:29,680 --> 00:05:31,840
modeling as code type of world it could

168
00:05:31,840 --> 00:05:33,520
be something that's drawn on a napkin

169
00:05:33,520 --> 00:05:35,039
not even a data flow diagram just a

170
00:05:35,039 --> 00:05:37,120
couple of boxes on a napkin right that's

171
00:05:37,120 --> 00:05:38,560
a representation but at the end of the

172
00:05:38,560 --> 00:05:40,320
day it's all about what are the security

173
00:05:40,320 --> 00:05:41,919
and privacy challenges that we have with

174
00:05:41,919 --> 00:05:43,120
this and what are we going to do about

175
00:05:43,120 --> 00:05:44,479
it

176
00:05:44,479 --> 00:05:45,680
and so one of the other things that we

177
00:05:45,680 --> 00:05:47,360
all agreed on when we came together is

178
00:05:47,360 --> 00:05:48,800
that threat modeling is something that

179
00:05:48,800 --> 00:05:50,880
we want to see be for everyone

180
00:05:50,880 --> 00:05:52,960
so i've seen a number of different

181
00:05:52,960 --> 00:05:54,960
scenarios for how people roll out threat

182
00:05:54,960 --> 00:05:57,199
modeling inside their companies uh one

183
00:05:57,199 --> 00:05:58,400
way will be

184
00:05:58,400 --> 00:05:59,840
okay the security team is going to do

185
00:05:59,840 --> 00:06:02,000
all the threat modeling

186
00:06:02,000 --> 00:06:03,280
challenge there is the security team

187
00:06:03,280 --> 00:06:05,120
gets a stack if we had you know paper

188
00:06:05,120 --> 00:06:06,479
printouts they have a stack of threat

189
00:06:06,479 --> 00:06:08,639
models yay high and they're never going

190
00:06:08,639 --> 00:06:10,800
to clear the backlog that pile's just

191
00:06:10,800 --> 00:06:12,080
going to grow bigger and bigger over

192
00:06:12,080 --> 00:06:13,199
time

193
00:06:13,199 --> 00:06:14,639
and then i've seen other organizations

194
00:06:14,639 --> 00:06:15,759
that say well we're going to have the

195
00:06:15,759 --> 00:06:17,120
security champions do the threat

196
00:06:17,120 --> 00:06:18,160
modeling they're going to be the ones

197
00:06:18,160 --> 00:06:21,120
responsible for this well sure

198
00:06:21,120 --> 00:06:22,880
they can do that the stack is smaller

199
00:06:22,880 --> 00:06:24,639
but we have the same problem because

200
00:06:24,639 --> 00:06:26,560
there's more threat models that they can

201
00:06:26,560 --> 00:06:28,000
do then you know they don't have enough

202
00:06:28,000 --> 00:06:30,160
time to do their regular work and try to

203
00:06:30,160 --> 00:06:31,840
do threat models as well

204
00:06:31,840 --> 00:06:32,720
and so

205
00:06:32,720 --> 00:06:34,639
my expectation when i'm helping people

206
00:06:34,639 --> 00:06:36,400
roll out threat modeling is that this is

207
00:06:36,400 --> 00:06:38,080
going to be something that everyone is

208
00:06:38,080 --> 00:06:39,120
doing

209
00:06:39,120 --> 00:06:40,720
across the organization

210
00:06:40,720 --> 00:06:42,560
i want to see a threat model happening

211
00:06:42,560 --> 00:06:45,120
where there's a developer a tester and a

212
00:06:45,120 --> 00:06:46,960
product manager maybe even a program

213
00:06:46,960 --> 00:06:48,639
manager all coming together all

214
00:06:48,639 --> 00:06:50,880
providing their unique perspectives

215
00:06:50,880 --> 00:06:52,400
because that's really the key to

216
00:06:52,400 --> 00:06:54,319
successful threat modeling

217
00:06:54,319 --> 00:06:55,280
and so

218
00:06:55,280 --> 00:06:57,520
we also described why why did we put

219
00:06:57,520 --> 00:06:59,280
this threat modeling manifesto together

220
00:06:59,280 --> 00:07:00,880
well we wanted to share the knowledge

221
00:07:00,880 --> 00:07:02,960
that we had put together as a group of

222
00:07:02,960 --> 00:07:04,800
people with a lot of diverse backgrounds

223
00:07:04,800 --> 00:07:06,240
and perspectives

224
00:07:06,240 --> 00:07:08,240
we wanted to inform and educate the

225
00:07:08,240 --> 00:07:10,639
industry you know take a stab at what

226
00:07:10,639 --> 00:07:12,479
this thing is but also inspire other

227
00:07:12,479 --> 00:07:13,680
people such as yourselves that are

228
00:07:13,680 --> 00:07:15,520
practitioners to say i'm going to go

229
00:07:15,520 --> 00:07:17,280
make my threat modeling program even

230
00:07:17,280 --> 00:07:19,360
better than it is today or i'm going to

231
00:07:19,360 --> 00:07:21,120
use this as a foundational piece to get

232
00:07:21,120 --> 00:07:22,880
going and be able to do something with

233
00:07:22,880 --> 00:07:24,800
my program

234
00:07:24,800 --> 00:07:26,240
so who's familiar with the four key

235
00:07:26,240 --> 00:07:27,840
questions

236
00:07:27,840 --> 00:07:29,680
okay a couple people all right who is

237
00:07:29,680 --> 00:07:32,560
the author of the four key questions

238
00:07:32,560 --> 00:07:34,800
adam shostak the i hate to call him the

239
00:07:34,800 --> 00:07:36,240
godfather of threat modeling but i want

240
00:07:36,240 --> 00:07:38,160
to all the time i hope he doesn't i hope

241
00:07:38,160 --> 00:07:40,880
he never sees this recording um

242
00:07:40,880 --> 00:07:42,240
but yeah so he came up with these four

243
00:07:42,240 --> 00:07:43,520
key questions adam's a great guy but

244
00:07:43,520 --> 00:07:44,960
came up with these four key questions

245
00:07:44,960 --> 00:07:46,720
and he let us bring these and drop them

246
00:07:46,720 --> 00:07:48,240
into the manifesto since he was a part

247
00:07:48,240 --> 00:07:49,680
of it but

248
00:07:49,680 --> 00:07:51,680
this is really in its essence the most

249
00:07:51,680 --> 00:07:53,039
simple way you can explain threat

250
00:07:53,039 --> 00:07:55,039
modeling to anybody like i i use this

251
00:07:55,039 --> 00:07:57,120
all the time to say there's really four

252
00:07:57,120 --> 00:07:58,400
simple things we have to consider here

253
00:07:58,400 --> 00:07:59,919
when we're doing threat modeling first

254
00:07:59,919 --> 00:08:01,199
of all we have to answer the question

255
00:08:01,199 --> 00:08:02,639
what are we working on

256
00:08:02,639 --> 00:08:03,520
okay

257
00:08:03,520 --> 00:08:05,440
once we establish that scope then we can

258
00:08:05,440 --> 00:08:07,840
say what can go wrong with that thing

259
00:08:07,840 --> 00:08:09,199
that we're looking at

260
00:08:09,199 --> 00:08:10,560
and then we ask ourselves what are we

261
00:08:10,560 --> 00:08:12,319
going to do about it for me that is

262
00:08:12,319 --> 00:08:13,599
where all of the value and threat

263
00:08:13,599 --> 00:08:15,599
modeling comes from

264
00:08:15,599 --> 00:08:17,120
if you don't answer question number

265
00:08:17,120 --> 00:08:19,120
three everything you did for one and two

266
00:08:19,120 --> 00:08:21,120
is a waste of your time

267
00:08:21,120 --> 00:08:23,520
it is because you i've seen threat

268
00:08:23,520 --> 00:08:25,440
models done where those like they'll

269
00:08:25,440 --> 00:08:26,639
i'll look at it there's a hundred

270
00:08:26,639 --> 00:08:28,319
threats that have been identified and

271
00:08:28,319 --> 00:08:30,479
zero mitigations and i'm like you have

272
00:08:30,479 --> 00:08:32,159
just wasted two to four hours of your

273
00:08:32,159 --> 00:08:33,440
life

274
00:08:33,440 --> 00:08:34,719
we got to talk about mitigation we're

275
00:08:34,719 --> 00:08:35,760
gonna talk about how we're gonna fix

276
00:08:35,760 --> 00:08:37,679
these things and make things better then

277
00:08:37,679 --> 00:08:39,440
the last key question here is did we do

278
00:08:39,440 --> 00:08:40,799
a good enough job

279
00:08:40,799 --> 00:08:41,519
so

280
00:08:41,519 --> 00:08:43,599
retrospective we're talking about that

281
00:08:43,599 --> 00:08:45,760
in the context of devops right it's all

282
00:08:45,760 --> 00:08:46,560
about

283
00:08:46,560 --> 00:08:47,839
looking at what we're doing and seeing

284
00:08:47,839 --> 00:08:49,040
hey there things we could do differently

285
00:08:49,040 --> 00:08:50,800
we're not blaming anybody what are the

286
00:08:50,800 --> 00:08:51,839
things that we could do differently we

287
00:08:51,839 --> 00:08:53,120
want to do the same thing here from a

288
00:08:53,120 --> 00:08:54,959
threat model perspective we look at what

289
00:08:54,959 --> 00:08:56,800
we came up with and we say

290
00:08:56,800 --> 00:08:58,399
did we do a good enough job could we

291
00:08:58,399 --> 00:09:00,080
have done better in some areas in future

292
00:09:00,080 --> 00:09:03,440
threat models helps to scope where we go

293
00:09:03,440 --> 00:09:05,360
so benefits of threat modeling according

294
00:09:05,360 --> 00:09:06,800
to the manifesto first of all

295
00:09:06,800 --> 00:09:08,320
recognizing what those things are that

296
00:09:08,320 --> 00:09:10,560
can go wrong right um how many people

297
00:09:10,560 --> 00:09:12,000
were in the keynote this morning in

298
00:09:12,000 --> 00:09:13,519
jeff's keynote okay so when he was

299
00:09:13,519 --> 00:09:14,560
talking about he was talking about

300
00:09:14,560 --> 00:09:16,880
threat modeling and he was saying like

301
00:09:16,880 --> 00:09:18,800
you got to pinpoint the one thing and

302
00:09:18,800 --> 00:09:19,920
that's the one that everybody should

303
00:09:19,920 --> 00:09:21,600
focus on and so the challenge i have

304
00:09:21,600 --> 00:09:23,200
with that is somebody who loves threat

305
00:09:23,200 --> 00:09:25,120
modeling is if i haven't done the whole

306
00:09:25,120 --> 00:09:26,399
threat model how do i know what the one

307
00:09:26,399 --> 00:09:27,519
thing is

308
00:09:27,519 --> 00:09:29,440
right right like a lot of us in the room

309
00:09:29,440 --> 00:09:31,200
that are security people we live and die

310
00:09:31,200 --> 00:09:33,680
this we love this stuff we can pick out

311
00:09:33,680 --> 00:09:34,959
the one thing

312
00:09:34,959 --> 00:09:37,760
but if you're a developer who's you know

313
00:09:37,760 --> 00:09:39,360
two three years into your career can you

314
00:09:39,360 --> 00:09:40,720
pick out the one key thing out of the

315
00:09:40,720 --> 00:09:42,880
100 that you need to do so

316
00:09:42,880 --> 00:09:45,279
um yeah so then also pinpointing design

317
00:09:45,279 --> 00:09:47,279
and implementation issues for mitigation

318
00:09:47,279 --> 00:09:48,959
and then informing the other phases

319
00:09:48,959 --> 00:09:50,320
that's a big part a lot of people miss

320
00:09:50,320 --> 00:09:52,480
out on that threat modeling is something

321
00:09:52,480 --> 00:09:54,560
that will help testers when they're

322
00:09:54,560 --> 00:09:56,720
further down and even you know hopefully

323
00:09:56,720 --> 00:09:58,399
they're doing this in a devops world and

324
00:09:58,399 --> 00:09:59,680
tests are being written at the same time

325
00:09:59,680 --> 00:10:01,920
codes being written and all that but but

326
00:10:01,920 --> 00:10:03,760
threat modeling because it causes you to

327
00:10:03,760 --> 00:10:05,760
have to think about the design in such a

328
00:10:05,760 --> 00:10:06,560
way

329
00:10:06,560 --> 00:10:08,640
it can help to have other people you

330
00:10:08,640 --> 00:10:10,000
know it can help to inform those other

331
00:10:10,000 --> 00:10:12,880
phases of development as well

332
00:10:12,880 --> 00:10:14,320
and so really when we think about how

333
00:10:14,320 --> 00:10:15,200
are you what are you going to do with

334
00:10:15,200 --> 00:10:16,240
this how are you going to use the

335
00:10:16,240 --> 00:10:17,839
manifesto it's really about you know

336
00:10:17,839 --> 00:10:19,600
developing or refining a methodology

337
00:10:19,600 --> 00:10:22,000
that best fits your needs

338
00:10:22,000 --> 00:10:23,440
and so we when we got together as a

339
00:10:23,440 --> 00:10:25,040
group and we said okay what is this what

340
00:10:25,040 --> 00:10:27,600
is the result of this thing gonna be

341
00:10:27,600 --> 00:10:28,800
right we could sit and argue about

342
00:10:28,800 --> 00:10:30,399
threat modeling for five years and

343
00:10:30,399 --> 00:10:31,680
probably we'd probably still be at it

344
00:10:31,680 --> 00:10:33,600
now we'd be enjoying ourselves but

345
00:10:33,600 --> 00:10:34,880
there'd be nothing that we would share

346
00:10:34,880 --> 00:10:36,959
with the industry and so we said what

347
00:10:36,959 --> 00:10:37,920
we're going to do is we're going to

348
00:10:37,920 --> 00:10:39,920
borrow from the agile manifesto so the

349
00:10:39,920 --> 00:10:42,079
agile manifesto has this list of things

350
00:10:42,079 --> 00:10:44,560
that they value and it's this idea of we

351
00:10:44,560 --> 00:10:46,480
value this over this

352
00:10:46,480 --> 00:10:48,000
both things are good but the one on the

353
00:10:48,000 --> 00:10:49,440
left is better than the one on the right

354
00:10:49,440 --> 00:10:51,279
it's kind of the general idea that that

355
00:10:51,279 --> 00:10:52,880
we use with values that we borrowed from

356
00:10:52,880 --> 00:10:55,600
the agile manifesto and so you know

357
00:10:55,600 --> 00:10:56,959
value these are the things that from a

358
00:10:56,959 --> 00:10:58,320
threat modeling perspective they have

359
00:10:58,320 --> 00:11:00,000
worth merit importance we think they're

360
00:11:00,000 --> 00:11:02,240
things that will bolster your program

361
00:11:02,240 --> 00:11:04,079
if you can establish these things as

362
00:11:04,079 --> 00:11:05,519
kind of key

363
00:11:05,519 --> 00:11:07,120
benchmarks or things that you're

364
00:11:07,120 --> 00:11:08,399
considering

365
00:11:08,399 --> 00:11:09,680
and then we think about principles from

366
00:11:09,680 --> 00:11:11,200
a threat modeling perspective these are

367
00:11:11,200 --> 00:11:12,880
the fundamental truths that we think are

368
00:11:12,880 --> 00:11:14,399
going to going to apply to everybody in

369
00:11:14,399 --> 00:11:15,920
every situation

370
00:11:15,920 --> 00:11:17,360
so let's look at the first one and this

371
00:11:17,360 --> 00:11:18,720
is where i want to dive in and spend

372
00:11:18,720 --> 00:11:21,760
some spend a lot of our time

373
00:11:21,760 --> 00:11:23,519
so with value number one from the threat

374
00:11:23,519 --> 00:11:26,320
modeling manifesto we have like i said

375
00:11:26,320 --> 00:11:28,959
before it's a over b a culture of

376
00:11:28,959 --> 00:11:31,839
finding and fixing design issues over

377
00:11:31,839 --> 00:11:33,839
checkbox compliance

378
00:11:33,839 --> 00:11:36,320
so let's work our way back from right to

379
00:11:36,320 --> 00:11:38,079
left here to kind of unpack what we're

380
00:11:38,079 --> 00:11:39,760
looking at here

381
00:11:39,760 --> 00:11:42,480
if somebody does threat modeling purely

382
00:11:42,480 --> 00:11:44,320
to check the box

383
00:11:44,320 --> 00:11:45,839
now i'm hoping if they're doing it to

384
00:11:45,839 --> 00:11:47,200
purely check the box there is some

385
00:11:47,200 --> 00:11:48,640
amount of value they're following a

386
00:11:48,640 --> 00:11:50,000
process they're going through a series

387
00:11:50,000 --> 00:11:52,000
of steps they're not just writing threat

388
00:11:52,000 --> 00:11:53,600
model on a piece of paper making a check

389
00:11:53,600 --> 00:11:55,519
thing and going check like they're doing

390
00:11:55,519 --> 00:11:56,720
something

391
00:11:56,720 --> 00:11:57,920
from my perspective and from the

392
00:11:57,920 --> 00:11:59,600
perspective of those that help to write

393
00:11:59,600 --> 00:12:01,440
this like that's okay that's that has

394
00:12:01,440 --> 00:12:03,920
some value to it it's nowhere nearly as

395
00:12:03,920 --> 00:12:06,000
valuable as having a culture where

396
00:12:06,000 --> 00:12:07,839
people are like hey we're all about

397
00:12:07,839 --> 00:12:10,480
finding and fixing design issues

398
00:12:10,480 --> 00:12:12,240
and and i've seen that happen in

399
00:12:12,240 --> 00:12:13,680
different points in my career you can

400
00:12:13,680 --> 00:12:15,120
get development teams where they're to

401
00:12:15,120 --> 00:12:17,040
the point where they understand and

402
00:12:17,040 --> 00:12:18,800
really appreciate

403
00:12:18,800 --> 00:12:20,399
the ideas of security and what we're

404
00:12:20,399 --> 00:12:21,680
trying to accomplish and they get on

405
00:12:21,680 --> 00:12:23,600
board with us and that's a culture shift

406
00:12:23,600 --> 00:12:25,760
a culture move and so you want to have

407
00:12:25,760 --> 00:12:27,440
that culture where developers are

408
00:12:27,440 --> 00:12:29,040
sitting around and they're talking about

409
00:12:29,040 --> 00:12:31,120
a particular design and they're like you

410
00:12:31,120 --> 00:12:32,639
know let's let's let's figure out what

411
00:12:32,639 --> 00:12:34,079
the problem is let's figure out what the

412
00:12:34,079 --> 00:12:35,839
mitigation is to that

413
00:12:35,839 --> 00:12:37,600
you know how can we find and fix these

414
00:12:37,600 --> 00:12:38,639
things

415
00:12:38,639 --> 00:12:39,519
and so

416
00:12:39,519 --> 00:12:41,040
you know when you're talking about

417
00:12:41,040 --> 00:12:42,320
metrics from a threat modeling

418
00:12:42,320 --> 00:12:43,760
perspective

419
00:12:43,760 --> 00:12:45,839
using the number of issues that are

420
00:12:45,839 --> 00:12:47,360
coming out of this is an interesting

421
00:12:47,360 --> 00:12:48,880
metric to keep the number of issues that

422
00:12:48,880 --> 00:12:50,399
are coming out of your threat model the

423
00:12:50,399 --> 00:12:51,680
threat modeling process that you're

424
00:12:51,680 --> 00:12:53,519
using i used to do this at cisco i would

425
00:12:53,519 --> 00:12:55,839
keep metrics to say hey just let me know

426
00:12:55,839 --> 00:12:57,279
you know give me a total number of

427
00:12:57,279 --> 00:12:58,480
issues that are coming out from a

428
00:12:58,480 --> 00:13:00,000
particular particular threat model

429
00:13:00,000 --> 00:13:01,600
that's happening because when you start

430
00:13:01,600 --> 00:13:03,279
thinking about return on investment one

431
00:13:03,279 --> 00:13:04,720
of the most complicated things to do in

432
00:13:04,720 --> 00:13:06,000
the world of security someone should do

433
00:13:06,000 --> 00:13:07,600
a 10-day class on how to calculate

434
00:13:07,600 --> 00:13:09,680
return on investment for security i'd

435
00:13:09,680 --> 00:13:10,959
probably go and listen to the first five

436
00:13:10,959 --> 00:13:12,959
minutes and maybe run out but because i

437
00:13:12,959 --> 00:13:15,120
don't think it'd be that interesting but

438
00:13:15,120 --> 00:13:16,959
we want we want to you know from a

439
00:13:16,959 --> 00:13:18,480
metrics perspective we want to have some

440
00:13:18,480 --> 00:13:20,639
type of return on investment and we can

441
00:13:20,639 --> 00:13:22,240
do that by saying hey our threat

442
00:13:22,240 --> 00:13:24,160
modeling program in the last quarter

443
00:13:24,160 --> 00:13:27,200
there were 278 design time issues that

444
00:13:27,200 --> 00:13:28,720
we identified and we were able to

445
00:13:28,720 --> 00:13:31,279
mitigate 212 of them right that's a

446
00:13:31,279 --> 00:13:33,040
metric that we can build on top of from

447
00:13:33,040 --> 00:13:34,639
this program because you think about

448
00:13:34,639 --> 00:13:35,680
threat modeling what else are we going

449
00:13:35,680 --> 00:13:37,600
to metric total number of threat models

450
00:13:37,600 --> 00:13:39,199
that's valuable in the early days

451
00:13:39,199 --> 00:13:40,880
especially just the bulk of doing threat

452
00:13:40,880 --> 00:13:43,279
models and getting things moving is good

453
00:13:43,279 --> 00:13:44,880
but that's not something that sustains

454
00:13:44,880 --> 00:13:46,240
us five years in the future you know

455
00:13:46,240 --> 00:13:47,519
we're doing more threat models than we

456
00:13:47,519 --> 00:13:48,720
ever have before oh but we're not we

457
00:13:48,720 --> 00:13:50,399
still have more vulnerabilities not a

458
00:13:50,399 --> 00:13:51,920
great metric

459
00:13:51,920 --> 00:13:54,240
so our second value here is people in

460
00:13:54,240 --> 00:13:56,079
collaboration over processes

461
00:13:56,079 --> 00:13:58,160
methodologies and tools

462
00:13:58,160 --> 00:13:59,760
this is a bit of a tricky one because

463
00:13:59,760 --> 00:14:00,800
you're looking at the things on the

464
00:14:00,800 --> 00:14:03,040
right going wait process that's kind of

465
00:14:03,040 --> 00:14:04,480
important we gotta have a process if

466
00:14:04,480 --> 00:14:06,240
we're gonna do it in a standard way

467
00:14:06,240 --> 00:14:08,160
methodologies yeah we gotta have we've

468
00:14:08,160 --> 00:14:09,920
gotta have a structure for how we're

469
00:14:09,920 --> 00:14:11,680
showing people how to do this

470
00:14:11,680 --> 00:14:13,519
tools we gotta try to automate some of

471
00:14:13,519 --> 00:14:15,120
this

472
00:14:15,120 --> 00:14:17,440
what we found in our conversations and

473
00:14:17,440 --> 00:14:18,880
and looking across our collective

474
00:14:18,880 --> 00:14:21,600
experiences is we really do value the

475
00:14:21,600 --> 00:14:23,680
people in collaboration at the end of

476
00:14:23,680 --> 00:14:25,839
the day over any of the any other things

477
00:14:25,839 --> 00:14:28,480
we can do from a set of process steps or

478
00:14:28,480 --> 00:14:30,639
you know stride versus linden versus

479
00:14:30,639 --> 00:14:32,399
pasta versus i don't know one of the

480
00:14:32,399 --> 00:14:33,519
other there's lots of different

481
00:14:33,519 --> 00:14:35,120
methodologies that people are using out

482
00:14:35,120 --> 00:14:36,480
there but at the end of the day it

483
00:14:36,480 --> 00:14:37,920
doesn't matter what methodology you're

484
00:14:37,920 --> 00:14:39,279
using what tool you're using what

485
00:14:39,279 --> 00:14:40,800
process you're using if you don't have

486
00:14:40,800 --> 00:14:43,040
the people collaborating together in

487
00:14:43,040 --> 00:14:45,120
this threat modeling process

488
00:14:45,120 --> 00:14:46,399
that's been some of the most valuable

489
00:14:46,399 --> 00:14:48,160
times i've ever had threat modeling like

490
00:14:48,160 --> 00:14:50,000
my the way that i love to do this is to

491
00:14:50,000 --> 00:14:51,680
go in with the development team in front

492
00:14:51,680 --> 00:14:53,360
of the white board and i just asked

493
00:14:53,360 --> 00:14:55,199
start asking a million questions some

494
00:14:55,199 --> 00:14:56,800
questions i know the answer to others i

495
00:14:56,800 --> 00:14:58,560
have no idea i'll just ask wild

496
00:14:58,560 --> 00:15:00,079
questions you know like what does that

497
00:15:00,079 --> 00:15:01,519
do what would happen if somebody sent

498
00:15:01,519 --> 00:15:04,000
something to that would would that work

499
00:15:04,000 --> 00:15:05,360
still you think

500
00:15:05,360 --> 00:15:06,880
um and so that's you know kind of the

501
00:15:06,880 --> 00:15:08,480
socratic method i guess of of

502
00:15:08,480 --> 00:15:10,399
approaching threat modeling

503
00:15:10,399 --> 00:15:11,760
i think there's a lot of value in

504
00:15:11,760 --> 00:15:14,000
investing and teaching the developers

505
00:15:14,000 --> 00:15:15,760
the testers those those people that are

506
00:15:15,760 --> 00:15:17,680
doing threat modeling so that they have

507
00:15:17,680 --> 00:15:19,120
the knowledge and experience and then

508
00:15:19,120 --> 00:15:20,720
give them the right tools especially

509
00:15:20,720 --> 00:15:22,000
still in the world we're in now to

510
00:15:22,000 --> 00:15:24,560
collaborate and do threat modeling

511
00:15:24,560 --> 00:15:27,680
using you know virtual tools we did a uh

512
00:15:27,680 --> 00:15:29,519
a remote threat modeling session adam

513
00:15:29,519 --> 00:15:31,680
shostak and i did uh just to try it out

514
00:15:31,680 --> 00:15:33,040
to see how it would work using i think

515
00:15:33,040 --> 00:15:35,279
we use draw.io which is a you know

516
00:15:35,279 --> 00:15:37,279
web-based drawing package

517
00:15:37,279 --> 00:15:38,959
the cool thing is it works like google

518
00:15:38,959 --> 00:15:41,440
docs does now where you can be two

519
00:15:41,440 --> 00:15:42,880
people working at the same time and

520
00:15:42,880 --> 00:15:44,480
you're both seeing all the impacts

521
00:15:44,480 --> 00:15:46,160
coming and so we had a lot of fun with

522
00:15:46,160 --> 00:15:47,360
it because we were just kind of curious

523
00:15:47,360 --> 00:15:48,639
trying to see like how would this even

524
00:15:48,639 --> 00:15:50,399
work if we if we tried to tell people

525
00:15:50,399 --> 00:15:51,839
you should do this

526
00:15:51,839 --> 00:15:53,120
and so it was it was it was a good

527
00:15:53,120 --> 00:15:54,240
experience to see how that comes

528
00:15:54,240 --> 00:15:56,639
together how it fits

529
00:15:56,639 --> 00:15:58,800
so my third our third value here is a

530
00:15:58,800 --> 00:16:00,720
journey of understanding over a security

531
00:16:00,720 --> 00:16:02,959
or privacy snapshot so

532
00:16:02,959 --> 00:16:05,120
a snapshot a threat model that's done

533
00:16:05,120 --> 00:16:08,160
once in time still has value presuming

534
00:16:08,160 --> 00:16:10,240
the the the analysis is happening the

535
00:16:10,240 --> 00:16:12,160
mitigations are occurring i i still

536
00:16:12,160 --> 00:16:13,839
believe there's a lot of value in that

537
00:16:13,839 --> 00:16:15,519
but what we said is that we want to

538
00:16:15,519 --> 00:16:17,199
value and we want we see a lot more

539
00:16:17,199 --> 00:16:19,279
value in somebody going on a journey of

540
00:16:19,279 --> 00:16:20,800
understanding

541
00:16:20,800 --> 00:16:21,920
because for those that have done threat

542
00:16:21,920 --> 00:16:23,360
models like the first time you do threat

543
00:16:23,360 --> 00:16:25,519
modeling you get to the end and like if

544
00:16:25,519 --> 00:16:26,959
you open that threat model up a year or

545
00:16:26,959 --> 00:16:28,320
two later you're like ooh what was i

546
00:16:28,320 --> 00:16:30,160
even thinking like i didn't have any of

547
00:16:30,160 --> 00:16:32,000
the perspective or context and stuff

548
00:16:32,000 --> 00:16:33,680
that i do now and that's okay i'm not

549
00:16:33,680 --> 00:16:35,360
saying that's a bad thing that's how we

550
00:16:35,360 --> 00:16:36,959
learn we learn we want to learn threat

551
00:16:36,959 --> 00:16:38,399
modeling by doing

552
00:16:38,399 --> 00:16:40,480
but going on that journey with a product

553
00:16:40,480 --> 00:16:42,480
or an application over a period of time

554
00:16:42,480 --> 00:16:44,240
you can really you can really see it

555
00:16:44,240 --> 00:16:45,759
start to get better as and your threat

556
00:16:45,759 --> 00:16:47,120
model gets better as you start to learn

557
00:16:47,120 --> 00:16:48,240
more and more about how to do the

558
00:16:48,240 --> 00:16:49,759
process you learn more about different

559
00:16:49,759 --> 00:16:52,639
threats maybe you grow above stride as a

560
00:16:52,639 --> 00:16:54,160
methodology and you start thinking up

561
00:16:54,160 --> 00:16:55,519
stuff on your own or going to other

562
00:16:55,519 --> 00:16:56,800
sources

563
00:16:56,800 --> 00:16:58,639
so you know just knowing that threat

564
00:16:58,639 --> 00:16:59,920
models in the early days are going to

565
00:16:59,920 --> 00:17:02,720
have holes and you know that in an

566
00:17:02,720 --> 00:17:04,559
iterative approach to this is gonna it's

567
00:17:04,559 --> 00:17:06,160
gonna result in threat models getting

568
00:17:06,160 --> 00:17:07,599
better you know the threat model of

569
00:17:07,599 --> 00:17:09,919
tomorrow is gonna be no worse than the

570
00:17:09,919 --> 00:17:11,520
threat model of yesterday it's only and

571
00:17:11,520 --> 00:17:12,640
it's likely gonna be a little bit

572
00:17:12,640 --> 00:17:15,599
incrementally better over time

573
00:17:15,599 --> 00:17:18,160
so then our fourth value is doing threat

574
00:17:18,160 --> 00:17:20,160
modeling over talking about threat

575
00:17:20,160 --> 00:17:21,280
modeling

576
00:17:21,280 --> 00:17:22,400
so

577
00:17:22,400 --> 00:17:24,559
i have this rule and i'm breaking my own

578
00:17:24,559 --> 00:17:26,480
rule here in this just let the record

579
00:17:26,480 --> 00:17:27,760
show for the permanent record i'm

580
00:17:27,760 --> 00:17:29,679
staring at the camera now

581
00:17:29,679 --> 00:17:31,360
i have what i call the 30 minute rule

582
00:17:31,360 --> 00:17:33,120
for threat modeling and that is i'm not

583
00:17:33,120 --> 00:17:35,520
normally unless i'm at last con allowed

584
00:17:35,520 --> 00:17:37,440
to talk for about threat modeling for

585
00:17:37,440 --> 00:17:39,039
more than 30 minutes before we have to

586
00:17:39,039 --> 00:17:40,799
do some threat modeling

587
00:17:40,799 --> 00:17:42,160
because this is a this is something

588
00:17:42,160 --> 00:17:44,799
that's it's an experience right i can do

589
00:17:44,799 --> 00:17:46,320
an eight-hour lecture and i would be

590
00:17:46,320 --> 00:17:47,679
happy to do it

591
00:17:47,679 --> 00:17:48,960
but at the end of the day on threat

592
00:17:48,960 --> 00:17:50,799
modeling but at the end of the day those

593
00:17:50,799 --> 00:17:52,000
people the people that are listening to

594
00:17:52,000 --> 00:17:53,600
me are going to be like hmm i don't

595
00:17:53,600 --> 00:17:54,720
still really know what i'm supposed to

596
00:17:54,720 --> 00:17:56,000
do i watched him do a whole bunch of

597
00:17:56,000 --> 00:17:57,360
examples and he seems to know what he's

598
00:17:57,360 --> 00:17:59,200
doing maybe but they're not gonna be

599
00:17:59,200 --> 00:18:00,640
able to go back to their desk on monday

600
00:18:00,640 --> 00:18:02,000
morning and do their own threat modeling

601
00:18:02,000 --> 00:18:04,080
so doing threat modeling is much more

602
00:18:04,080 --> 00:18:05,520
powerful than talking about it talking

603
00:18:05,520 --> 00:18:08,160
about it's okay it's not a bad thing but

604
00:18:08,160 --> 00:18:10,160
but getting people to to go step in

605
00:18:10,160 --> 00:18:11,679
front of a virtual whiteboard or a

606
00:18:11,679 --> 00:18:14,320
physical whiteboard and go through the

607
00:18:14,320 --> 00:18:15,840
threat model process there's there's a

608
00:18:15,840 --> 00:18:18,000
lot of value in that

609
00:18:18,000 --> 00:18:19,679
so value number five is continuous

610
00:18:19,679 --> 00:18:21,039
refinement over a single delivery i

611
00:18:21,039 --> 00:18:22,160
talked about a single delivery a little

612
00:18:22,160 --> 00:18:23,679
bit in a previous one but you know

613
00:18:23,679 --> 00:18:25,760
threat models are never done right so we

614
00:18:25,760 --> 00:18:27,760
value the continuous refinement that's

615
00:18:27,760 --> 00:18:31,120
happening as a product application or

616
00:18:31,120 --> 00:18:33,600
feature matures over time we're opening

617
00:18:33,600 --> 00:18:35,200
those threat models we're refining them

618
00:18:35,200 --> 00:18:37,039
as we make tweaks and add new features

619
00:18:37,039 --> 00:18:38,960
and stuff and so we're ending up with

620
00:18:38,960 --> 00:18:40,240
this threat model that's getting better

621
00:18:40,240 --> 00:18:41,840
and better all the way until we get to

622
00:18:41,840 --> 00:18:44,160
the end of the product life cycle and

623
00:18:44,160 --> 00:18:46,000
that feature gets end of life and then

624
00:18:46,000 --> 00:18:47,760
we can let the threat model go away at

625
00:18:47,760 --> 00:18:48,960
that point so

626
00:18:48,960 --> 00:18:50,640
um going through this continuous

627
00:18:50,640 --> 00:18:52,400
refinement though is a very powerful

628
00:18:52,400 --> 00:18:53,600
approach to how we can do threat

629
00:18:53,600 --> 00:18:55,280
modeling

630
00:18:55,280 --> 00:18:57,200
so here's the principles and i thought i

631
00:18:57,200 --> 00:18:59,120
said we had values and principles both

632
00:18:59,120 --> 00:19:00,559
that we had that we had brought into

633
00:19:00,559 --> 00:19:02,400
this conversation

634
00:19:02,400 --> 00:19:03,520
and so when we think about the

635
00:19:03,520 --> 00:19:05,120
principles the first one is just early

636
00:19:05,120 --> 00:19:07,440
and frequent analysis people always say

637
00:19:07,440 --> 00:19:08,559
you know when should i do threat

638
00:19:08,559 --> 00:19:11,200
modeling well you know yesterday or at

639
00:19:11,200 --> 00:19:12,799
the beginning of the time that you were

640
00:19:12,799 --> 00:19:13,919
thinking about whatever it is you're

641
00:19:13,919 --> 00:19:14,960
going to build

642
00:19:14,960 --> 00:19:16,400
i don't i'm not going to get mad at

643
00:19:16,400 --> 00:19:18,480
anybody who has an existing giant

644
00:19:18,480 --> 00:19:19,760
application architecture and they're

645
00:19:19,760 --> 00:19:20,799
like now we want to start threat

646
00:19:20,799 --> 00:19:22,320
modeling that's okay we got to all start

647
00:19:22,320 --> 00:19:24,960
somewhere but in a perfect world

648
00:19:24,960 --> 00:19:27,280
we are threat modeling a feature at the

649
00:19:27,280 --> 00:19:29,039
time that somebody thinks about it as a

650
00:19:29,039 --> 00:19:30,880
product manager and they write the user

651
00:19:30,880 --> 00:19:32,240
story and we're going to our say we're

652
00:19:32,240 --> 00:19:34,000
in an agile world we're going to our

653
00:19:34,000 --> 00:19:36,480
scrum meeting we're talking doing our

654
00:19:36,480 --> 00:19:38,559
planning cycle for the next sprint i

655
00:19:38,559 --> 00:19:40,240
want to see some planning hours set

656
00:19:40,240 --> 00:19:42,320
aside to do the threat model that's

657
00:19:42,320 --> 00:19:44,080
early infrequent analysis in an agile

658
00:19:44,080 --> 00:19:46,320
world but you can also look at it at the

659
00:19:46,320 --> 00:19:48,000
macro level from the perspective of you

660
00:19:48,000 --> 00:19:49,679
know the product life cycle

661
00:19:49,679 --> 00:19:50,960
once again we don't always have the

662
00:19:50,960 --> 00:19:54,080
luxury of dealing with a

663
00:19:54,080 --> 00:19:55,919
product that you know is has not been

664
00:19:55,919 --> 00:19:57,200
released to the public ever or anything

665
00:19:57,200 --> 00:19:59,039
like that that's okay you know but early

666
00:19:59,039 --> 00:20:00,400
and frequent analysis is always going to

667
00:20:00,400 --> 00:20:02,480
be better

668
00:20:02,480 --> 00:20:03,840
second principle is alignment with

669
00:20:03,840 --> 00:20:06,320
development practices and iterations

670
00:20:06,320 --> 00:20:08,720
often as security people we look at

671
00:20:08,720 --> 00:20:10,320
development and say

672
00:20:10,320 --> 00:20:12,159
let's just kind of put our stuff you

673
00:20:12,159 --> 00:20:13,760
know just kind of just just wedge it

674
00:20:13,760 --> 00:20:15,120
into all the things that they're already

675
00:20:15,120 --> 00:20:16,640
doing and yeah we'll give them some new

676
00:20:16,640 --> 00:20:18,000
systems they can just connect with new

677
00:20:18,000 --> 00:20:20,080
systems and put the results of threat

678
00:20:20,080 --> 00:20:22,080
modeling into this other system we want

679
00:20:22,080 --> 00:20:24,080
to use i know they use jira all day long

680
00:20:24,080 --> 00:20:25,280
and we don't need to use geo we're going

681
00:20:25,280 --> 00:20:27,840
to use something else to do it and so

682
00:20:27,840 --> 00:20:30,640
for smoother threat modeling integration

683
00:20:30,640 --> 00:20:32,880
aligning with development practices and

684
00:20:32,880 --> 00:20:34,799
and iterations like where where the

685
00:20:34,799 --> 00:20:36,640
developers are working now that should

686
00:20:36,640 --> 00:20:37,760
be where you keep your threat model

687
00:20:37,760 --> 00:20:39,600
results don't make them do something

688
00:20:39,600 --> 00:20:41,360
different all you're doing is making

689
00:20:41,360 --> 00:20:43,280
driving more of a wedge and putting up

690
00:20:43,280 --> 00:20:45,120
more of a stop sign more likely that

691
00:20:45,120 --> 00:20:46,799
they're not going to move forward with

692
00:20:46,799 --> 00:20:48,240
whatever it is that you're asking them

693
00:20:48,240 --> 00:20:50,720
to do in this case

694
00:20:50,720 --> 00:20:52,320
the third one is that outcomes are

695
00:20:52,320 --> 00:20:53,600
meaningful when they are of value to

696
00:20:53,600 --> 00:20:56,000
stakeholders so who are stakeholders for

697
00:20:56,000 --> 00:20:58,400
a threat model well

698
00:20:58,400 --> 00:21:01,200
product managers executives

699
00:21:01,200 --> 00:21:03,120
program managers

700
00:21:03,120 --> 00:21:05,760
you know maybe engineering leadership

701
00:21:05,760 --> 00:21:08,000
those are our stakeholders and so we

702
00:21:08,000 --> 00:21:09,840
have to we have to ensure that whatever

703
00:21:09,840 --> 00:21:10,960
we're doing from threat modeling

704
00:21:10,960 --> 00:21:13,120
perspective is is providing meaningful

705
00:21:13,120 --> 00:21:14,720
results for everyone that's involved in

706
00:21:14,720 --> 00:21:17,520
the process and then really a dialogue

707
00:21:17,520 --> 00:21:19,600
is is the most important thing

708
00:21:19,600 --> 00:21:20,880
um

709
00:21:20,880 --> 00:21:22,640
it's a dialogue is having that

710
00:21:22,640 --> 00:21:24,880
collaborative conversation we still want

711
00:21:24,880 --> 00:21:26,400
to document the results of what we do

712
00:21:26,400 --> 00:21:27,840
but it's really about the collaboration

713
00:21:27,840 --> 00:21:29,039
that's that's really the thing that's

714
00:21:29,039 --> 00:21:31,360
driving us here

715
00:21:31,360 --> 00:21:33,760
so then the the last two parts of the

716
00:21:33,760 --> 00:21:35,679
manifesto are what we called

717
00:21:35,679 --> 00:21:37,440
anti-patterns that inhibit threat

718
00:21:37,440 --> 00:21:40,159
modeling and patterns that are are good

719
00:21:40,159 --> 00:21:41,440
patterns for things that will make

720
00:21:41,440 --> 00:21:43,440
threat modeling better

721
00:21:43,440 --> 00:21:45,039
and so for those of you that have done a

722
00:21:45,039 --> 00:21:46,960
lot of threat modeling get ready you're

723
00:21:46,960 --> 00:21:48,320
going to see yourself on the screen here

724
00:21:48,320 --> 00:21:49,840
a couple of times i know i did the first

725
00:21:49,840 --> 00:21:51,360
time when i looked at this final list i

726
00:21:51,360 --> 00:21:52,960
was like oh yeah i'm guilty of that one

727
00:21:52,960 --> 00:21:54,320
guilty of that one

728
00:21:54,320 --> 00:21:55,600
didn't do enough of that one that was

729
00:21:55,600 --> 00:21:56,960
green

730
00:21:56,960 --> 00:21:58,320
the first one that we have here is the

731
00:21:58,320 --> 00:22:00,159
hero threat modeler

732
00:22:00,159 --> 00:22:01,840
remember this is an anti-pattern don't

733
00:22:01,840 --> 00:22:02,960
look at this and go hey i want to be the

734
00:22:02,960 --> 00:22:04,240
hero threat model i want to go threat

735
00:22:04,240 --> 00:22:06,480
model everything my company does

736
00:22:06,480 --> 00:22:08,400
and that's really the idea is that you

737
00:22:08,400 --> 00:22:10,640
can't have it's not beneficial to have

738
00:22:10,640 --> 00:22:13,120
one person do the threat modeling

739
00:22:13,120 --> 00:22:15,440
because they don't have the perspective

740
00:22:15,440 --> 00:22:17,520
like as a security person when i sit

741
00:22:17,520 --> 00:22:18,880
down with those developers to do that

742
00:22:18,880 --> 00:22:20,000
threat model

743
00:22:20,000 --> 00:22:21,520
i really don't understand a lot about

744
00:22:21,520 --> 00:22:22,880
what their feature does

745
00:22:22,880 --> 00:22:25,039
if i rely on my own understanding that

746
00:22:25,039 --> 00:22:26,559
threat model is going to be really weak

747
00:22:26,559 --> 00:22:28,320
what makes it strong is i ask lots of

748
00:22:28,320 --> 00:22:30,159
questions about how the feature works

749
00:22:30,159 --> 00:22:32,000
because you know what they're the expert

750
00:22:32,000 --> 00:22:34,320
in the feature i just am a guy who knows

751
00:22:34,320 --> 00:22:36,480
a few things about threats and so this

752
00:22:36,480 --> 00:22:38,400
this anti-pattern of hero threat modeler

753
00:22:38,400 --> 00:22:40,480
can be where the security team is the

754
00:22:40,480 --> 00:22:43,039
hero the champion is the hero somebody

755
00:22:43,039 --> 00:22:44,880
is the hero that everybody's pointing at

756
00:22:44,880 --> 00:22:46,559
saying that's who should do the threat

757
00:22:46,559 --> 00:22:48,400
modeling and sometimes you can fall into

758
00:22:48,400 --> 00:22:50,000
that trap as an individual going well i

759
00:22:50,000 --> 00:22:51,360
want to be the hero i want to save the

760
00:22:51,360 --> 00:22:52,720
day for everyone

761
00:22:52,720 --> 00:22:55,039
but it's not it's a not not a scalable

762
00:22:55,039 --> 00:22:56,400
practice and that's why it's an

763
00:22:56,400 --> 00:22:58,320
anti-pattern

764
00:22:58,320 --> 00:22:59,679
second anti-pattern we have here is

765
00:22:59,679 --> 00:23:01,840
admiration for the problem

766
00:23:01,840 --> 00:23:02,799
so

767
00:23:02,799 --> 00:23:04,240
i won't even ask for a show of hands

768
00:23:04,240 --> 00:23:05,919
here as far as who's who's been trapped

769
00:23:05,919 --> 00:23:07,039
in this one before i know i've been

770
00:23:07,039 --> 00:23:08,799
there you know admiration for the

771
00:23:08,799 --> 00:23:10,799
problem is where i spend a few more

772
00:23:10,799 --> 00:23:13,039
minutes slash hours creating this

773
00:23:13,039 --> 00:23:14,640
representation of the system that i'm

774
00:23:14,640 --> 00:23:16,720
trying to threat model and i'll get it

775
00:23:16,720 --> 00:23:18,320
to the point where it's it's really a

776
00:23:18,320 --> 00:23:20,240
good representation

777
00:23:20,240 --> 00:23:23,280
it's you know it's just it's just

778
00:23:23,280 --> 00:23:25,360
getting caught up in the problem

779
00:23:25,360 --> 00:23:26,720
which is possible you know when we're

780
00:23:26,720 --> 00:23:28,240
trying to fix something from an

781
00:23:28,240 --> 00:23:29,600
engineering perspective it's it's

782
00:23:29,600 --> 00:23:32,080
possible to admire the problem too much

783
00:23:32,080 --> 00:23:33,919
like i said at the beginning for me it's

784
00:23:33,919 --> 00:23:35,840
all about the mitigations the problem is

785
00:23:35,840 --> 00:23:37,280
great that's what that's what gets us to

786
00:23:37,280 --> 00:23:38,720
the table but it's about getting to the

787
00:23:38,720 --> 00:23:40,240
mitigations that's where the true value

788
00:23:40,240 --> 00:23:42,320
is found

789
00:23:42,320 --> 00:23:44,080
okay so our second set here of

790
00:23:44,080 --> 00:23:46,640
anti-patterns the first the third one

791
00:23:46,640 --> 00:23:50,640
here is tendency to over focus

792
00:23:50,640 --> 00:23:52,799
and so this this can play out a couple

793
00:23:52,799 --> 00:23:55,360
different ways sometimes over focusing

794
00:23:55,360 --> 00:23:58,480
can be we get we get so hyper focused on

795
00:23:58,480 --> 00:24:01,039
one piece of a feature that we kind of

796
00:24:01,039 --> 00:24:02,720
we lose the ability to see the big

797
00:24:02,720 --> 00:24:03,840
picture of other things that are

798
00:24:03,840 --> 00:24:05,840
happening around what we're trying to

799
00:24:05,840 --> 00:24:07,760
threat model and so we want to make sure

800
00:24:07,760 --> 00:24:09,279
that we don't lose sight of that big

801
00:24:09,279 --> 00:24:11,039
picture

802
00:24:11,039 --> 00:24:13,039
you know we want to we and we've also we

803
00:24:13,039 --> 00:24:14,240
also discussed in the process of the

804
00:24:14,240 --> 00:24:16,400
manifesto being written like some people

805
00:24:16,400 --> 00:24:17,919
will get caught up on a particular

806
00:24:17,919 --> 00:24:20,159
adversary that'll be how they'll over

807
00:24:20,159 --> 00:24:22,240
focus they'll be like but i mean nation

808
00:24:22,240 --> 00:24:23,279
states

809
00:24:23,279 --> 00:24:25,200
everything for them is nation-states

810
00:24:25,200 --> 00:24:27,039
like every threat they see on there is

811
00:24:27,039 --> 00:24:28,480
nation-states

812
00:24:28,480 --> 00:24:29,919
which it's good that they're considering

813
00:24:29,919 --> 00:24:31,919
that and in a diverse group of people

814
00:24:31,919 --> 00:24:33,360
that are doing threat modeling i like

815
00:24:33,360 --> 00:24:34,640
the fact that because i'm not thinking

816
00:24:34,640 --> 00:24:35,919
all about nation states somebody's

817
00:24:35,919 --> 00:24:37,520
really thinking about it but in a

818
00:24:37,520 --> 00:24:39,600
smaller situation

819
00:24:39,600 --> 00:24:41,679
focusing too much on one adversary can

820
00:24:41,679 --> 00:24:43,039
result in well we didn't even think

821
00:24:43,039 --> 00:24:44,320
about what a cyber criminal would do

822
00:24:44,320 --> 00:24:45,600
with this feature

823
00:24:45,600 --> 00:24:47,440
that has a credit card processing engine

824
00:24:47,440 --> 00:24:49,039
attached to the back of it you know

825
00:24:49,039 --> 00:24:50,480
nation states might not care as much

826
00:24:50,480 --> 00:24:52,559
about the ability to process or process

827
00:24:52,559 --> 00:24:53,919
credit card data

828
00:24:53,919 --> 00:24:55,679
or cards to see if they're real

829
00:24:55,679 --> 00:24:57,919
but a cyber criminal would

830
00:24:57,919 --> 00:24:59,520
and then our final anti-pattern here is

831
00:24:59,520 --> 00:25:01,440
perfect representation it's another one

832
00:25:01,440 --> 00:25:03,279
that i'm guilty of here of of saying

833
00:25:03,279 --> 00:25:05,520
like i just spent a little bit more time

834
00:25:05,520 --> 00:25:07,200
i can get more i can come up with more

835
00:25:07,200 --> 00:25:08,480
threats there's got to be more threats

836
00:25:08,480 --> 00:25:09,600
there's got to be more problems with

837
00:25:09,600 --> 00:25:11,120
this let's just keep churning keep

838
00:25:11,120 --> 00:25:12,240
churning

839
00:25:12,240 --> 00:25:13,520
challenge here is we get caught in this

840
00:25:13,520 --> 00:25:16,159
loop and we never get to a an actionable

841
00:25:16,159 --> 00:25:18,080
result coming out of this

842
00:25:18,080 --> 00:25:19,760
right like we have to time box anything

843
00:25:19,760 --> 00:25:20,799
we're doing from a threat modeling

844
00:25:20,799 --> 00:25:22,559
perspective so we don't get trapped into

845
00:25:22,559 --> 00:25:24,159
this perfect representation where it's

846
00:25:24,159 --> 00:25:25,039
like

847
00:25:25,039 --> 00:25:26,559
we just spend a few more hours we can

848
00:25:26,559 --> 00:25:27,919
get it we'll get it to where it's it's

849
00:25:27,919 --> 00:25:29,520
done it's perfect it's never going to be

850
00:25:29,520 --> 00:25:31,840
done right well since we've been sitting

851
00:25:31,840 --> 00:25:33,279
in the room here somebody's come up with

852
00:25:33,279 --> 00:25:34,720
some new threat somewhere that we'll

853
00:25:34,720 --> 00:25:36,960
hear about in six months some new type

854
00:25:36,960 --> 00:25:39,279
of attack some new some new challenge

855
00:25:39,279 --> 00:25:40,480
that we're going to have to deal with as

856
00:25:40,480 --> 00:25:42,640
absent people

857
00:25:42,640 --> 00:25:44,240
so let's look at a couple of patterns

858
00:25:44,240 --> 00:25:45,679
now so we talked about anti-patterns

859
00:25:45,679 --> 00:25:47,279
these are the what not to do so let's

860
00:25:47,279 --> 00:25:49,840
come back over now to some positive

861
00:25:49,840 --> 00:25:51,840
things that can

862
00:25:51,840 --> 00:25:53,440
really help your threat modeling program

863
00:25:53,440 --> 00:25:56,240
as you as you move forward

864
00:25:56,240 --> 00:25:58,080
so the first one is taking a systematic

865
00:25:58,080 --> 00:26:00,080
approach so being thorough and having

866
00:26:00,080 --> 00:26:02,080
reproducible results

867
00:26:02,080 --> 00:26:04,559
by applying the security and privacy

868
00:26:04,559 --> 00:26:05,919
things that we were talking about here

869
00:26:05,919 --> 00:26:08,480
in a structured manner so

870
00:26:08,480 --> 00:26:10,159
i've seen organizations that have kind

871
00:26:10,159 --> 00:26:12,320
of a chaotic approach to threat modeling

872
00:26:12,320 --> 00:26:13,840
where there's really not a structure

873
00:26:13,840 --> 00:26:16,000
there's really not you know the guidance

874
00:26:16,000 --> 00:26:17,520
is really just we have to do threat

875
00:26:17,520 --> 00:26:20,240
modeling okay what does that mean well

876
00:26:20,240 --> 00:26:21,760
some people are doing one way some

877
00:26:21,760 --> 00:26:23,520
people are doing another way so we're

878
00:26:23,520 --> 00:26:25,600
ending up with really different results

879
00:26:25,600 --> 00:26:28,559
for the same amount of effort and so a

880
00:26:28,559 --> 00:26:30,320
positive pattern here is to take a

881
00:26:30,320 --> 00:26:32,320
systematic approach how we do these

882
00:26:32,320 --> 00:26:34,000
things

883
00:26:34,000 --> 00:26:35,520
the second

884
00:26:35,520 --> 00:26:39,120
positive pattern is informed creativity

885
00:26:39,120 --> 00:26:41,039
and uh i don't remember who actually

886
00:26:41,039 --> 00:26:43,039
came up with this exact verbiage but

887
00:26:43,039 --> 00:26:45,120
it's it's brilliant allow for creativity

888
00:26:45,120 --> 00:26:48,640
by including both craft and science

889
00:26:48,640 --> 00:26:50,559
so yes there is a science to threat

890
00:26:50,559 --> 00:26:52,400
modeling there's a science to applying

891
00:26:52,400 --> 00:26:54,480
the methodology and understanding how it

892
00:26:54,480 --> 00:26:56,559
rolls out but let's also have some craft

893
00:26:56,559 --> 00:26:58,720
some creativity that goes into it you

894
00:26:58,720 --> 00:27:00,480
know let's not just say we're only going

895
00:27:00,480 --> 00:27:01,919
to consider the stride methodology and

896
00:27:01,919 --> 00:27:03,440
then we're going to stop

897
00:27:03,440 --> 00:27:05,440
let's use let's give people the ability

898
00:27:05,440 --> 00:27:08,000
to do some brainstorming and the way i

899
00:27:08,000 --> 00:27:09,679
approach this is i tell people there is

900
00:27:09,679 --> 00:27:11,919
no threat that's off the table here if

901
00:27:11,919 --> 00:27:14,320
you can dream it i'll write it down

902
00:27:14,320 --> 00:27:16,080
we may decide at the end that there's

903
00:27:16,080 --> 00:27:17,679
very unlikely it's ever going to be come

904
00:27:17,679 --> 00:27:20,080
to fruition that's okay but everything

905
00:27:20,080 --> 00:27:21,840
is on the table and some of the creative

906
00:27:21,840 --> 00:27:23,679
things that come out of that you'll end

907
00:27:23,679 --> 00:27:25,279
up needing a mitigation for but what you

908
00:27:25,279 --> 00:27:26,559
don't want to do is shut them down by

909
00:27:26,559 --> 00:27:28,399
saying ah that could never happen like i

910
00:27:28,399 --> 00:27:29,919
when i when i host a threat muddling

911
00:27:29,919 --> 00:27:31,279
session of someone turns to someone else

912
00:27:31,279 --> 00:27:32,880
and goes you know what that could never

913
00:27:32,880 --> 00:27:35,440
happen i'm like whoa time out sorry you

914
00:27:35,440 --> 00:27:36,880
can't make that could you prove that

915
00:27:36,880 --> 00:27:38,320
could never happen

916
00:27:38,320 --> 00:27:39,919
no okay well then it goes on the board

917
00:27:39,919 --> 00:27:41,039
because we wanna we wanna have that

918
00:27:41,039 --> 00:27:43,840
creativity that creative engine running

919
00:27:43,840 --> 00:27:45,279
and then i talked about varied

920
00:27:45,279 --> 00:27:46,799
viewpoints a little bit earlier as well

921
00:27:46,799 --> 00:27:49,120
but having that diverse team is really

922
00:27:49,120 --> 00:27:51,279
valuable because product managers see

923
00:27:51,279 --> 00:27:52,720
the world differently than developers

924
00:27:52,720 --> 00:27:54,320
than testers like we're all coming at

925
00:27:54,320 --> 00:27:55,760
this looking at it differently with

926
00:27:55,760 --> 00:27:57,440
different motivations

927
00:27:57,440 --> 00:27:59,039
and product managers have a lot of good

928
00:27:59,039 --> 00:28:01,360
insight if you can get them to the table

929
00:28:01,360 --> 00:28:03,760
invite them in try to get them there

930
00:28:03,760 --> 00:28:05,440
show them some value coming out of that

931
00:28:05,440 --> 00:28:06,880
as well because that cross-functional

932
00:28:06,880 --> 00:28:09,919
collaboration is really powerful

933
00:28:09,919 --> 00:28:11,600
okay useful toolkit i know one of our

934
00:28:11,600 --> 00:28:14,159
values was you know over process

935
00:28:14,159 --> 00:28:15,679
methodologies and tools but you know

936
00:28:15,679 --> 00:28:17,760
tools it's a good pattern

937
00:28:17,760 --> 00:28:19,760
do i recommend that on day one of your

938
00:28:19,760 --> 00:28:21,760
enterprise program you go buy a tool and

939
00:28:21,760 --> 00:28:23,600
try to apply it as the way you do threat

940
00:28:23,600 --> 00:28:25,520
modeling no

941
00:28:25,520 --> 00:28:27,279
because threat modeling is really about

942
00:28:27,279 --> 00:28:29,600
the people and the collaboration and i

943
00:28:29,600 --> 00:28:31,520
haven't there's a lot of tools

944
00:28:31,520 --> 00:28:33,440
i like i think i even put a tool slide

945
00:28:33,440 --> 00:28:34,880
in here i'll show you some of the ones i

946
00:28:34,880 --> 00:28:35,600
like

947
00:28:35,600 --> 00:28:36,720
but

948
00:28:36,720 --> 00:28:38,720
for me i want people to understand the

949
00:28:38,720 --> 00:28:40,960
process first and then you use the tool

950
00:28:40,960 --> 00:28:43,279
to get better at executing the process

951
00:28:43,279 --> 00:28:44,720
but if you don't understand the process

952
00:28:44,720 --> 00:28:46,240
you can get lost in the tool that's

953
00:28:46,240 --> 00:28:47,919
available

954
00:28:47,919 --> 00:28:49,360
and then the last pattern here is really

955
00:28:49,360 --> 00:28:51,039
you know putting that theory into

956
00:28:51,039 --> 00:28:53,279
practice so taking those things looking

957
00:28:53,279 --> 00:28:54,640
across the industries a lot of people

958
00:28:54,640 --> 00:28:55,919
that are writing a lot about threat

959
00:28:55,919 --> 00:28:58,399
modeling and new methodologies and new

960
00:28:58,399 --> 00:29:00,720
strategies and stuff and so a positive

961
00:29:00,720 --> 00:29:02,480
pattern is just staying abreast of all

962
00:29:02,480 --> 00:29:04,399
those things and bringing the ones that

963
00:29:04,399 --> 00:29:05,600
work that need that you want to take

964
00:29:05,600 --> 00:29:09,918
advantage of into your own program

965
00:29:10,960 --> 00:29:13,120
okay so now i've got 10 tips that i want

966
00:29:13,120 --> 00:29:14,880
to share with you when i think about

967
00:29:14,880 --> 00:29:17,120
what are some things you can do to

968
00:29:17,120 --> 00:29:18,399
build a

969
00:29:18,399 --> 00:29:21,440
enterprise grade threat modeling program

970
00:29:21,440 --> 00:29:22,960
so the first one is really choosing a

971
00:29:22,960 --> 00:29:25,360
solid process to fall behind

972
00:29:25,360 --> 00:29:26,559
what i'm sharing with you here is the

973
00:29:26,559 --> 00:29:28,159
way that i've approached threat modeling

974
00:29:28,159 --> 00:29:29,679
this is the same one i did at cisco it's

975
00:29:29,679 --> 00:29:31,679
been like 10 plus years since or more

976
00:29:31,679 --> 00:29:33,039
than that since i rolled out threat

977
00:29:33,039 --> 00:29:35,840
modeling there i still use and speak

978
00:29:35,840 --> 00:29:37,679
about the same exact process because i

979
00:29:37,679 --> 00:29:39,039
just i can't think of any way to refine

980
00:29:39,039 --> 00:29:42,080
it to make it to make it better

981
00:29:42,080 --> 00:29:43,520
the first

982
00:29:43,520 --> 00:29:45,200
kind of piece of this process for me is

983
00:29:45,200 --> 00:29:47,440
always scope okay i want people i want

984
00:29:47,440 --> 00:29:49,279
folks because developers are going to

985
00:29:49,279 --> 00:29:50,880
have multiple user stories they may not

986
00:29:50,880 --> 00:29:52,640
be able to threat model every user story

987
00:29:52,640 --> 00:29:54,399
that's in front of them in this sprint

988
00:29:54,399 --> 00:29:55,760
i want them to be able to quickly be

989
00:29:55,760 --> 00:29:57,760
able to look and understand the scope

990
00:29:57,760 --> 00:29:59,679
and then understand security relevance

991
00:29:59,679 --> 00:30:01,039
and choose the one that's going to have

992
00:30:01,039 --> 00:30:03,039
the most bang for the buck to jeff's

993
00:30:03,039 --> 00:30:04,960
point this morning in the keynote about

994
00:30:04,960 --> 00:30:06,640
being able to have that way to look

995
00:30:06,640 --> 00:30:08,799
across an entire set of threats in the

996
00:30:08,799 --> 00:30:10,240
threat model and then pick the one out

997
00:30:10,240 --> 00:30:11,360
that you're like this is the one we have

998
00:30:11,360 --> 00:30:12,880
to worry about the most

999
00:30:12,880 --> 00:30:14,559
that i mean that's that's that's the

1000
00:30:14,559 --> 00:30:16,559
same goal that i have in threat modeling

1001
00:30:16,559 --> 00:30:18,559
as well is that you know we may have

1002
00:30:18,559 --> 00:30:20,159
some of those scope conversations i'd

1003
00:30:20,159 --> 00:30:21,679
love to hear that we have time to do all

1004
00:30:21,679 --> 00:30:22,399
of them

1005
00:30:22,399 --> 00:30:24,399
but i live it i also live in reality and

1006
00:30:24,399 --> 00:30:25,840
so i know that that's not always going

1007
00:30:25,840 --> 00:30:27,360
to be the case

1008
00:30:27,360 --> 00:30:29,200
personally i like to draw i like the

1009
00:30:29,200 --> 00:30:31,200
data flow diagram approach

1010
00:30:31,200 --> 00:30:33,039
i'm also a fan i've become a fan of a

1011
00:30:33,039 --> 00:30:35,200
owass project called pi tm

1012
00:30:35,200 --> 00:30:36,480
if you haven't seen pi tm you should

1013
00:30:36,480 --> 00:30:37,600
check it out

1014
00:30:37,600 --> 00:30:39,440
i've known the guys izar and math that

1015
00:30:39,440 --> 00:30:41,039
are behind it for a long time and i've

1016
00:30:41,039 --> 00:30:42,000
always heard about it and they're like

1017
00:30:42,000 --> 00:30:43,440
ah that's cool that's cool and then

1018
00:30:43,440 --> 00:30:45,039
about oh let's

1019
00:30:45,039 --> 00:30:46,960
put the honesty cap on about a month ago

1020
00:30:46,960 --> 00:30:48,240
i actually downloaded it start and

1021
00:30:48,240 --> 00:30:49,520
played around with it for an example i

1022
00:30:49,520 --> 00:30:50,640
was doing for something else i'm like

1023
00:30:50,640 --> 00:30:52,159
whoa this is cool

1024
00:30:52,159 --> 00:30:54,480
it allows you to define the

1025
00:30:54,480 --> 00:30:56,320
the threat model as code and then it

1026
00:30:56,320 --> 00:30:58,080
generates the data flow diagram for you

1027
00:30:58,080 --> 00:30:59,519
and generates a list of threats for you

1028
00:30:59,519 --> 00:31:01,840
based on a database so very very cool

1029
00:31:01,840 --> 00:31:03,360
tool i'm jumping ahead of my own list

1030
00:31:03,360 --> 00:31:05,919
here but um but so but i'm still a fan

1031
00:31:05,919 --> 00:31:07,760
of dataflow diagrams i like to i like to

1032
00:31:07,760 --> 00:31:09,840
see and visualize the way things are

1033
00:31:09,840 --> 00:31:11,679
connecting and i find that to be an

1034
00:31:11,679 --> 00:31:13,679
easier way to like when i go in front of

1035
00:31:13,679 --> 00:31:15,519
a whiteboard and i ask a dev hey can you

1036
00:31:15,519 --> 00:31:16,720
um just draw me a picture what you're

1037
00:31:16,720 --> 00:31:18,960
working on right now it doesn't have to

1038
00:31:18,960 --> 00:31:20,559
conform to the

1039
00:31:20,559 --> 00:31:22,480
data flow diagram standard whatever that

1040
00:31:22,480 --> 00:31:24,960
might be like i can work with just boxes

1041
00:31:24,960 --> 00:31:26,799
and arrows and you know just regular

1042
00:31:26,799 --> 00:31:28,399
whiteboarding stuff we can threat model

1043
00:31:28,399 --> 00:31:29,600
that as well

1044
00:31:29,600 --> 00:31:31,279
and then for me analyze is the next step

1045
00:31:31,279 --> 00:31:32,480
what are the threats

1046
00:31:32,480 --> 00:31:34,240
mitigate and then some way to document

1047
00:31:34,240 --> 00:31:36,559
it so you got to choose a solid process

1048
00:31:36,559 --> 00:31:37,440
um

1049
00:31:37,440 --> 00:31:40,799
you know the the four adam's four steps

1050
00:31:40,799 --> 00:31:43,279
lay four questions kind of layer very

1051
00:31:43,279 --> 00:31:44,960
close to what i'm talking about here as

1052
00:31:44,960 --> 00:31:45,760
well

1053
00:31:45,760 --> 00:31:47,039
so it kind of all fits together but

1054
00:31:47,039 --> 00:31:48,080
really from an enterprise-grade

1055
00:31:48,080 --> 00:31:49,519
perspective you got to have a good a

1056
00:31:49,519 --> 00:31:52,240
good process to work from

1057
00:31:52,240 --> 00:31:54,080
so the second tip i have for you is

1058
00:31:54,080 --> 00:31:55,919
embed threat modeling in the secure

1059
00:31:55,919 --> 00:31:58,720
development life cycle well

1060
00:31:58,720 --> 00:32:01,120
so i left that put that well on the end

1061
00:32:01,120 --> 00:32:03,120
on purpose like we could embed threat

1062
00:32:03,120 --> 00:32:04,720
modeling in the stl and just because

1063
00:32:04,720 --> 00:32:06,159
everybody's got it in their picture it's

1064
00:32:06,159 --> 00:32:07,679
a part of what everybody's trying to do

1065
00:32:07,679 --> 00:32:09,519
but to do it well

1066
00:32:09,519 --> 00:32:10,960
there's a few other things that i'd like

1067
00:32:10,960 --> 00:32:12,799
to see you do

1068
00:32:12,799 --> 00:32:15,600
one of those is you know documenting the

1069
00:32:15,600 --> 00:32:17,760
process at a high level

1070
00:32:17,760 --> 00:32:18,960
so

1071
00:32:18,960 --> 00:32:20,799
i've kind of got my my you know we are

1072
00:32:20,799 --> 00:32:22,799
talking about an enterprise grade

1073
00:32:22,799 --> 00:32:25,039
project here or program here you know if

1074
00:32:25,039 --> 00:32:27,279
you're working at a smaller startup that

1075
00:32:27,279 --> 00:32:29,279
document the process at a high level may

1076
00:32:29,279 --> 00:32:31,919
be half a page with a picture

1077
00:32:31,919 --> 00:32:33,279
it just shows people hey here's what

1078
00:32:33,279 --> 00:32:34,960
we're trying to do from a feature by

1079
00:32:34,960 --> 00:32:36,559
feature perspective when it comes to

1080
00:32:36,559 --> 00:32:38,559
threat modeling in a bigger enterprise

1081
00:32:38,559 --> 00:32:39,440
company

1082
00:32:39,440 --> 00:32:41,039
there may be more depth that goes into

1083
00:32:41,039 --> 00:32:43,600
that but i want to see the process in a

1084
00:32:43,600 --> 00:32:44,640
way because if i'm going to ask people

1085
00:32:44,640 --> 00:32:46,480
to replicate it and repeat it over and

1086
00:32:46,480 --> 00:32:48,240
over i want them to be able to have

1087
00:32:48,240 --> 00:32:51,279
something tangible to work from

1088
00:32:51,279 --> 00:32:52,799
and then place the second piece of this

1089
00:32:52,799 --> 00:32:54,480
is placing the threat modeling artifacts

1090
00:32:54,480 --> 00:32:56,159
inside of existing deliverables if they

1091
00:32:56,159 --> 00:32:57,200
exist

1092
00:32:57,200 --> 00:32:58,880
so you know when i was at cisco we were

1093
00:32:58,880 --> 00:33:00,799
a little more old school they were still

1094
00:33:00,799 --> 00:33:01,919
using

1095
00:33:01,919 --> 00:33:03,039
a whole bunch of different

1096
00:33:03,039 --> 00:33:04,799
specifications there was a functional

1097
00:33:04,799 --> 00:33:07,120
spec a design spec there was there was

1098
00:33:07,120 --> 00:33:09,440
more documentation that was going into

1099
00:33:09,440 --> 00:33:10,720
each of

1100
00:33:10,720 --> 00:33:11,679
the

1101
00:33:11,679 --> 00:33:13,200
features that were being built by a

1102
00:33:13,200 --> 00:33:15,600
given developer and so i went to the

1103
00:33:15,600 --> 00:33:17,519
templates and said hey let's add threat

1104
00:33:17,519 --> 00:33:19,200
modeling the results of threat modeling

1105
00:33:19,200 --> 00:33:21,360
into an existing template

1106
00:33:21,360 --> 00:33:22,880
now that was that was where we were at a

1107
00:33:22,880 --> 00:33:24,559
particular place in time that was not in

1108
00:33:24,559 --> 00:33:27,200
a devops not even in devops universe

1109
00:33:27,200 --> 00:33:29,039
right we were very far away from devops

1110
00:33:29,039 --> 00:33:31,039
and agile at that point

1111
00:33:31,039 --> 00:33:33,600
but i think that we can still

1112
00:33:33,600 --> 00:33:35,519
we still want to bring threat modeling

1113
00:33:35,519 --> 00:33:37,279
as close to the feature as possible so

1114
00:33:37,279 --> 00:33:40,159
i'll give you an example from pitm

1115
00:33:40,159 --> 00:33:42,240
so if you if you use pi tm and you have

1116
00:33:42,240 --> 00:33:43,840
your developers do threat modeling as

1117
00:33:43,840 --> 00:33:45,120
code they write this little python

1118
00:33:45,120 --> 00:33:47,200
script that defines all the connections

1119
00:33:47,200 --> 00:33:48,399
and things that are happening with a

1120
00:33:48,399 --> 00:33:49,919
particular threat model

1121
00:33:49,919 --> 00:33:51,440
why not have them just check that right

1122
00:33:51,440 --> 00:33:52,720
in with the pr

1123
00:33:52,720 --> 00:33:54,559
add it to the code base with the pr you

1124
00:33:54,559 --> 00:33:56,559
know store that as part of the code base

1125
00:33:56,559 --> 00:33:57,760
because somebody else is going to need

1126
00:33:57,760 --> 00:33:59,279
to go make an update to that at some

1127
00:33:59,279 --> 00:34:00,559
point in the future

1128
00:34:00,559 --> 00:34:01,440
and

1129
00:34:01,440 --> 00:34:02,880
you know what happens if we don't put it

1130
00:34:02,880 --> 00:34:04,799
in as part of the pr

1131
00:34:04,799 --> 00:34:06,960
hey uh where's the threat model for that

1132
00:34:06,960 --> 00:34:08,159
i don't know

1133
00:34:08,159 --> 00:34:10,320
no idea it's gone it's disappeared

1134
00:34:10,320 --> 00:34:12,480
so you know putting the putting the the

1135
00:34:12,480 --> 00:34:14,879
threat model in the repository is a good

1136
00:34:14,879 --> 00:34:16,800
place to keep it available for

1137
00:34:16,800 --> 00:34:18,399
uh for for the next people who are gonna

1138
00:34:18,399 --> 00:34:20,399
do stuff with it

1139
00:34:20,399 --> 00:34:21,679
and i already mentioned the third one

1140
00:34:21,679 --> 00:34:23,520
here you know wherever your developers

1141
00:34:23,520 --> 00:34:24,639
are that's where you need to integrate

1142
00:34:24,639 --> 00:34:26,320
threat modeling you know if you're using

1143
00:34:26,320 --> 00:34:28,000
jira use it you integrate your threat

1144
00:34:28,000 --> 00:34:29,839
modeling process into jira

1145
00:34:29,839 --> 00:34:32,000
where whatever tools you're using don't

1146
00:34:32,000 --> 00:34:33,839
give them another tool i've seen that

1147
00:34:33,839 --> 00:34:36,239
happen with

1148
00:34:36,239 --> 00:34:39,119
some different tools in in the world and

1149
00:34:39,119 --> 00:34:41,119
it's always a challenge because

1150
00:34:41,119 --> 00:34:42,480
half the people aren't even updating it

1151
00:34:42,480 --> 00:34:44,239
because it's a one it's a it's a tool

1152
00:34:44,239 --> 00:34:45,839
for a single purpose versus where

1153
00:34:45,839 --> 00:34:47,760
they're living their lives every day and

1154
00:34:47,760 --> 00:34:49,040
so by integrating where they're living

1155
00:34:49,040 --> 00:34:50,239
their lives you can have a lot better

1156
00:34:50,239 --> 00:34:52,159
impact

1157
00:34:52,159 --> 00:34:53,599
i kind of touched on this one a little

1158
00:34:53,599 --> 00:34:56,239
bit more but you know a couple of times

1159
00:34:56,239 --> 00:34:58,079
already but i feel so strongly about it

1160
00:34:58,079 --> 00:35:00,240
i threw it in again

1161
00:35:00,240 --> 00:35:01,440
the strength of your threat modeling

1162
00:35:01,440 --> 00:35:02,960
program really comes down to the

1163
00:35:02,960 --> 00:35:05,040
different perspectives and and you know

1164
00:35:05,040 --> 00:35:06,960
that's i think what's gotten us into

1165
00:35:06,960 --> 00:35:09,119
kind of squashed our ability to really

1166
00:35:09,119 --> 00:35:11,520
have a giant impact with threat modeling

1167
00:35:11,520 --> 00:35:13,680
over you know the history as i've seen

1168
00:35:13,680 --> 00:35:15,440
it happen has been just not having that

1169
00:35:15,440 --> 00:35:17,200
diverse collection of champions let's

1170
00:35:17,200 --> 00:35:19,280
call them threat modeling champions that

1171
00:35:19,280 --> 00:35:20,800
are going to help

1172
00:35:20,800 --> 00:35:23,359
you know move threat modeling forward

1173
00:35:23,359 --> 00:35:24,560
could be that they're your security

1174
00:35:24,560 --> 00:35:25,920
champions they're the same people could

1175
00:35:25,920 --> 00:35:27,200
be they're different people don't

1176
00:35:27,200 --> 00:35:28,240
necessarily mean they have to be

1177
00:35:28,240 --> 00:35:30,160
security champions you could find some

1178
00:35:30,160 --> 00:35:32,400
people who just really like architecture

1179
00:35:32,400 --> 00:35:34,000
and doing that type of stuff and you

1180
00:35:34,000 --> 00:35:35,280
know make them a threat modeling

1181
00:35:35,280 --> 00:35:36,800
champion doesn't cost anything to give

1182
00:35:36,800 --> 00:35:39,359
somebody that label

1183
00:35:39,359 --> 00:35:41,040
okay so threat modeling coaches tip

1184
00:35:41,040 --> 00:35:42,560
number four

1185
00:35:42,560 --> 00:35:44,400
i had a chance to

1186
00:35:44,400 --> 00:35:47,599
hear from a gentleman who works at a

1187
00:35:47,599 --> 00:35:50,000
large financial and we were talking

1188
00:35:50,000 --> 00:35:51,680
about security champions and just

1189
00:35:51,680 --> 00:35:53,359
security programs

1190
00:35:53,359 --> 00:35:55,440
and he started telling me about this

1191
00:35:55,440 --> 00:35:57,680
this how they have

1192
00:35:57,680 --> 00:35:59,920
application security coaches

1193
00:35:59,920 --> 00:36:01,359
on their team does anybody here have

1194
00:36:01,359 --> 00:36:02,720
application security coaches that are

1195
00:36:02,720 --> 00:36:04,480
part of your program

1196
00:36:04,480 --> 00:36:06,880
okay just one okay i think it's still a

1197
00:36:06,880 --> 00:36:08,880
relatively new concept and idea but i

1198
00:36:08,880 --> 00:36:10,880
was fascinated by it the idea with an

1199
00:36:10,880 --> 00:36:13,040
application security coach is that you

1200
00:36:13,040 --> 00:36:14,240
have a group of people that are part of

1201
00:36:14,240 --> 00:36:16,400
your appsec team and developers can just

1202
00:36:16,400 --> 00:36:17,760
reach out and schedule a one-hour

1203
00:36:17,760 --> 00:36:19,520
meeting with them or they a developer

1204
00:36:19,520 --> 00:36:20,720
can reach out and say hey i'm having

1205
00:36:20,720 --> 00:36:22,320
this challenge can you consult with me

1206
00:36:22,320 --> 00:36:24,160
they're almost like consultants internal

1207
00:36:24,160 --> 00:36:26,160
consultants and as i started to hear

1208
00:36:26,160 --> 00:36:27,520
about how this had been rolled out in

1209
00:36:27,520 --> 00:36:29,839
this large large financial i was just

1210
00:36:29,839 --> 00:36:32,160
fascinated by the idea and said this is

1211
00:36:32,160 --> 00:36:33,839
going to become part of what i recommend

1212
00:36:33,839 --> 00:36:35,200
from a threat modeling perspective as

1213
00:36:35,200 --> 00:36:37,119
well

1214
00:36:37,119 --> 00:36:39,760
you know so to to empower threat

1215
00:36:39,760 --> 00:36:41,359
modeling coaches they have to have some

1216
00:36:41,359 --> 00:36:43,520
how-to guidance right you got to do some

1217
00:36:43,520 --> 00:36:45,359
you got to invest in them a little bit

1218
00:36:45,359 --> 00:36:46,880
you're looking for people that have some

1219
00:36:46,880 --> 00:36:49,119
natural aptitude that are having success

1220
00:36:49,119 --> 00:36:52,000
with it but you also are looking for

1221
00:36:52,000 --> 00:36:54,000
people that can they can go deeper with

1222
00:36:54,000 --> 00:36:55,040
it

1223
00:36:55,040 --> 00:36:56,880
and so you're going to need to educate

1224
00:36:56,880 --> 00:36:59,200
them deeper but you also want to get

1225
00:36:59,200 --> 00:37:00,400
these threat modeling coaches to the

1226
00:37:00,400 --> 00:37:01,440
point where they're multiplying

1227
00:37:01,440 --> 00:37:03,200
themselves so that was my general

1228
00:37:03,200 --> 00:37:05,280
rollout not not with the coaches but

1229
00:37:05,280 --> 00:37:07,440
multiplication at cisco

1230
00:37:07,440 --> 00:37:08,800
is i would

1231
00:37:08,800 --> 00:37:10,800
do a small setting a small threat

1232
00:37:10,800 --> 00:37:12,480
modeling instructional session with you

1233
00:37:12,480 --> 00:37:14,000
know eight to ten people and then i

1234
00:37:14,000 --> 00:37:16,560
would just beg them at the end

1235
00:37:16,560 --> 00:37:18,800
do me this one favor

1236
00:37:18,800 --> 00:37:20,640
go to some other part without the the

1237
00:37:20,640 --> 00:37:21,839
people in the room go to different

1238
00:37:21,839 --> 00:37:24,160
people in your team and do a threat

1239
00:37:24,160 --> 00:37:25,920
model with them and try to replicate

1240
00:37:25,920 --> 00:37:28,000
what i just did here and you know do

1241
00:37:28,000 --> 00:37:30,160
your best with it have fun with it but

1242
00:37:30,160 --> 00:37:32,240
but try to replicate it and

1243
00:37:32,240 --> 00:37:34,640
i saw as the knowledge of threat

1244
00:37:34,640 --> 00:37:36,720
modeling and hands-on abilities with it

1245
00:37:36,720 --> 00:37:38,000
started to replicate across the

1246
00:37:38,000 --> 00:37:39,680
organization because it was more than

1247
00:37:39,680 --> 00:37:42,000
just me as one individual when there

1248
00:37:42,000 --> 00:37:44,320
were 25 000 engineers i was working with

1249
00:37:44,320 --> 00:37:47,040
i mean at the rate of 10 per hour

1250
00:37:47,040 --> 00:37:48,640
i'd still i would have never even i'd

1251
00:37:48,640 --> 00:37:50,000
still be working on it and i left there

1252
00:37:50,000 --> 00:37:52,480
10 years ago or whatever right so we

1253
00:37:52,480 --> 00:37:54,160
have to get we have to magnify the

1254
00:37:54,160 --> 00:37:56,000
resources that we have available here to

1255
00:37:56,000 --> 00:37:57,440
make something like threat modeling

1256
00:37:57,440 --> 00:37:59,280
really pop

1257
00:37:59,280 --> 00:38:01,119
okay i workshop the teaching of threat

1258
00:38:01,119 --> 00:38:02,800
modeling so i talked about my 30-minute

1259
00:38:02,800 --> 00:38:04,079
threat modeling rule already that

1260
00:38:04,079 --> 00:38:06,640
applies to how i teach it in general but

1261
00:38:06,640 --> 00:38:08,240
i think one of the things you can do in

1262
00:38:08,240 --> 00:38:10,480
your enterprise grade program is

1263
00:38:10,480 --> 00:38:12,800
have a very hands-on workshop approach

1264
00:38:12,800 --> 00:38:15,680
to how you introduce people to this

1265
00:38:15,680 --> 00:38:18,000
play by this 30-minute rule it's tough

1266
00:38:18,000 --> 00:38:19,440
to do sometimes because you're like i

1267
00:38:19,440 --> 00:38:20,880
got more things i want to say i

1268
00:38:20,880 --> 00:38:22,480
literally set a timer when i do one of

1269
00:38:22,480 --> 00:38:24,160
these sessions and i tell people at the

1270
00:38:24,160 --> 00:38:26,079
beginning hey when the timer goes off

1271
00:38:26,079 --> 00:38:27,520
then you can all you know yell at me

1272
00:38:27,520 --> 00:38:28,720
because i'm not allowed to lecture

1273
00:38:28,720 --> 00:38:30,480
anymore we got to get after it it's only

1274
00:38:30,480 --> 00:38:31,599
happened once or i wasn't paying

1275
00:38:31,599 --> 00:38:33,280
attention and the timer starts going off

1276
00:38:33,280 --> 00:38:34,480
and people are booing me and stuff in

1277
00:38:34,480 --> 00:38:35,839
the room but

1278
00:38:35,839 --> 00:38:37,359
the idea with the workshop approach

1279
00:38:37,359 --> 00:38:39,040
though is

1280
00:38:39,040 --> 00:38:40,800
what i try to do is i try to start with

1281
00:38:40,800 --> 00:38:42,160
a physical

1282
00:38:42,160 --> 00:38:43,920
threat model

1283
00:38:43,920 --> 00:38:46,160
i do something as simple as i put up i

1284
00:38:46,160 --> 00:38:47,359
have this beautiful picture i should

1285
00:38:47,359 --> 00:38:48,320
have put it in the slide i have this

1286
00:38:48,320 --> 00:38:50,400
beautiful picture of an english cottage

1287
00:38:50,400 --> 00:38:52,560
with trees around it and like a meadow

1288
00:38:52,560 --> 00:38:54,160
off to the side and it's got like a

1289
00:38:54,160 --> 00:38:56,320
thatched roof and really kind of you

1290
00:38:56,320 --> 00:38:57,040
know

1291
00:38:57,040 --> 00:38:58,880
early you know hundreds of years ago

1292
00:38:58,880 --> 00:39:00,800
style cottage and all i do is i

1293
00:39:00,800 --> 00:39:02,000
challenge the folks in the first

1294
00:39:02,000 --> 00:39:03,280
exercise i say

1295
00:39:03,280 --> 00:39:04,480
how are you going to get into that

1296
00:39:04,480 --> 00:39:06,960
cottage imagine sitting on the dining

1297
00:39:06,960 --> 00:39:09,119
room table is the world's best chocolate

1298
00:39:09,119 --> 00:39:10,640
cake

1299
00:39:10,640 --> 00:39:11,760
how are you going to get into that

1300
00:39:11,760 --> 00:39:13,760
cottage and then i split people off into

1301
00:39:13,760 --> 00:39:15,520
small groups and i let them start going

1302
00:39:15,520 --> 00:39:17,359
i give them about 10 or 12 minutes i

1303
00:39:17,359 --> 00:39:18,480
bring the group back together and i'm

1304
00:39:18,480 --> 00:39:20,640
like group one what's the what's the

1305
00:39:20,640 --> 00:39:22,079
best way you came up with to get into

1306
00:39:22,079 --> 00:39:24,160
college or college get in the cottage

1307
00:39:24,160 --> 00:39:26,480
get the chocolate cake okay and then i

1308
00:39:26,480 --> 00:39:28,400
kind of play moderator i'm no longer the

1309
00:39:28,400 --> 00:39:30,079
teacher i'm just facilitating the

1310
00:39:30,079 --> 00:39:32,079
conversation and what's happening is

1311
00:39:32,079 --> 00:39:34,160
group three is listening to group one

1312
00:39:34,160 --> 00:39:35,920
and go oh that's kind of cool how they

1313
00:39:35,920 --> 00:39:37,680
thought about that and all this learning

1314
00:39:37,680 --> 00:39:39,680
is happening and all i'm doing is just

1315
00:39:39,680 --> 00:39:42,960
emceeing and and teeing everybody up

1316
00:39:42,960 --> 00:39:45,280
so then in my second example i go to an

1317
00:39:45,280 --> 00:39:47,680
alarm system in your house so now i'm

1318
00:39:47,680 --> 00:39:49,839
transferring into half real world half

1319
00:39:49,839 --> 00:39:52,720
cyber half network internet based and so

1320
00:39:52,720 --> 00:39:54,720
i i make it like a ring alarm i didn't

1321
00:39:54,720 --> 00:39:56,640
put ring alarm on there but i intend

1322
00:39:56,640 --> 00:39:58,320
it's like an internet connected alarm

1323
00:39:58,320 --> 00:39:59,920
system so there's physical windows but

1324
00:39:59,920 --> 00:40:02,400
there's also an internet connected app

1325
00:40:02,400 --> 00:40:04,240
that's running it and i challenge them

1326
00:40:04,240 --> 00:40:05,760
okay you know what are the threats that

1327
00:40:05,760 --> 00:40:07,839
exist in this particular thing and only

1328
00:40:07,839 --> 00:40:09,839
in my third example towards my last you

1329
00:40:09,839 --> 00:40:12,720
know 25 minutes or so do i

1330
00:40:12,720 --> 00:40:14,160
give them a

1331
00:40:14,160 --> 00:40:15,920
high level data flow diagram of a web

1332
00:40:15,920 --> 00:40:18,800
application with a mobile app and

1333
00:40:18,800 --> 00:40:20,560
micro services and some other juicy

1334
00:40:20,560 --> 00:40:21,839
things that they can dig their teeth

1335
00:40:21,839 --> 00:40:22,800
into

1336
00:40:22,800 --> 00:40:24,560
but what i've done is i've taken them

1337
00:40:24,560 --> 00:40:26,319
into the real world where everybody

1338
00:40:26,319 --> 00:40:28,079
everybody has loads of threats when

1339
00:40:28,079 --> 00:40:29,760
they're looking at the cottage but by

1340
00:40:29,760 --> 00:40:30,960
the time they get to the the

1341
00:40:30,960 --> 00:40:32,960
technological side they can apply that

1342
00:40:32,960 --> 00:40:34,800
learning that they've done and they can

1343
00:40:34,800 --> 00:40:36,319
start they start to see things in the

1344
00:40:36,319 --> 00:40:37,760
technology because they've got the

1345
00:40:37,760 --> 00:40:40,319
framework down for i don't i just have

1346
00:40:40,319 --> 00:40:42,160
to look for an issue so a thread that i

1347
00:40:42,160 --> 00:40:44,160
can pull on along the way so it's a lot

1348
00:40:44,160 --> 00:40:45,680
of fun to do workshops like that but

1349
00:40:45,680 --> 00:40:47,520
that's how i recommend you know even at

1350
00:40:47,520 --> 00:40:49,040
the enterprise it's the best it's the

1351
00:40:49,040 --> 00:40:51,599
best way to approach it

1352
00:40:51,599 --> 00:40:54,000
embrace stride so

1353
00:40:54,000 --> 00:40:55,280
i have kind of a

1354
00:40:55,280 --> 00:40:57,359
not my relationship with stride is what

1355
00:40:57,359 --> 00:40:59,599
i would describe as a love hate love

1356
00:40:59,599 --> 00:41:01,119
relationship

1357
00:41:01,119 --> 00:41:02,720
so for those that know stride in the

1358
00:41:02,720 --> 00:41:04,319
very beginning i was like when i first

1359
00:41:04,319 --> 00:41:05,440
learned threat modeling i'm like this

1360
00:41:05,440 --> 00:41:06,960
stride thing is great

1361
00:41:06,960 --> 00:41:09,359
makes sense it's simple it's it's

1362
00:41:09,359 --> 00:41:11,040
something that we can easily explain to

1363
00:41:11,040 --> 00:41:12,160
people

1364
00:41:12,160 --> 00:41:13,920
then the hate face came around you know

1365
00:41:13,920 --> 00:41:16,400
what happened i was like it's too simple

1366
00:41:16,400 --> 00:41:18,079
it's too easy

1367
00:41:18,079 --> 00:41:20,000
uh no it's just it's it's not

1368
00:41:20,000 --> 00:41:21,680
sophisticated enough

1369
00:41:21,680 --> 00:41:23,040
and then i started to try to get more

1370
00:41:23,040 --> 00:41:25,119
sophisticated and guess what i came back

1371
00:41:25,119 --> 00:41:27,440
to stride because

1372
00:41:27,440 --> 00:41:28,880
when because all i'm trying to do when

1373
00:41:28,880 --> 00:41:30,319
we're trying to to launch your

1374
00:41:30,319 --> 00:41:32,400
enterprise grade program is we're trying

1375
00:41:32,400 --> 00:41:34,400
to get people to to understand these

1376
00:41:34,400 --> 00:41:35,839
things that we're trying to do

1377
00:41:35,839 --> 00:41:37,760
and by making it overly complicated it

1378
00:41:37,760 --> 00:41:39,280
just didn't work and so i came back now

1379
00:41:39,280 --> 00:41:41,119
i'm back to loving stride it's it's my

1380
00:41:41,119 --> 00:41:43,359
best friend because it is so simple to

1381
00:41:43,359 --> 00:41:45,440
say hey let's consider what the threats

1382
00:41:45,440 --> 00:41:47,040
are this we've got spoofing you know

1383
00:41:47,040 --> 00:41:48,400
pretending to be someone you're not

1384
00:41:48,400 --> 00:41:50,240
tampering someone's modifying your data

1385
00:41:50,240 --> 00:41:52,560
along the way repediation the only way i

1386
00:41:52,560 --> 00:41:54,240
can think up to explain repudiation is

1387
00:41:54,240 --> 00:41:56,160
to use bart simpson

1388
00:41:56,160 --> 00:41:58,160
as an example i didn't do it nobody saw

1389
00:41:58,160 --> 00:41:59,839
me do it can't prove anything that's

1390
00:41:59,839 --> 00:42:01,040
repediation

1391
00:42:01,040 --> 00:42:02,560
you know mic drop and i walk off the

1392
00:42:02,560 --> 00:42:04,640
stage or whatever um

1393
00:42:04,640 --> 00:42:06,240
so yeah so embrace stride i'm back to

1394
00:42:06,240 --> 00:42:07,760
loving stride i think it's i think it's

1395
00:42:07,760 --> 00:42:10,319
a good solid foundation to start with

1396
00:42:10,319 --> 00:42:11,760
yes people are going to outgrow it and

1397
00:42:11,760 --> 00:42:13,680
that's great i love the fact that people

1398
00:42:13,680 --> 00:42:14,720
are going to outgrow it and they're

1399
00:42:14,720 --> 00:42:16,160
going to get more sophisticated as they

1400
00:42:16,160 --> 00:42:18,160
become more more knowledgeable about

1401
00:42:18,160 --> 00:42:19,839
threats and you know somebody asked me

1402
00:42:19,839 --> 00:42:21,359
on another session yesterday like you

1403
00:42:21,359 --> 00:42:23,760
know what are other sources for threats

1404
00:42:23,760 --> 00:42:25,520
you know when you get above stride and i

1405
00:42:25,520 --> 00:42:27,119
said ah there's just there's a world of

1406
00:42:27,119 --> 00:42:28,800
them common weakness enumeration from

1407
00:42:28,800 --> 00:42:30,079
mitre

1408
00:42:30,079 --> 00:42:31,760
cap act common attack patterns from

1409
00:42:31,760 --> 00:42:33,200
mitre attack

1410
00:42:33,200 --> 00:42:34,720
more of a red team pen testing

1411
00:42:34,720 --> 00:42:36,400
perspective if you got people that are

1412
00:42:36,400 --> 00:42:38,880
like hey we this is too simple let them

1413
00:42:38,880 --> 00:42:40,560
start chewing on those i mean there's

1414
00:42:40,560 --> 00:42:42,480
cwe's you know a thousand entries of

1415
00:42:42,480 --> 00:42:43,920
common weaknesses that happen in

1416
00:42:43,920 --> 00:42:46,000
software start using that as your threat

1417
00:42:46,000 --> 00:42:47,359
modeling base and then you're starting

1418
00:42:47,359 --> 00:42:50,160
to go to a whole other level

1419
00:42:50,160 --> 00:42:52,720
so number seven tip number seven here is

1420
00:42:52,720 --> 00:42:56,160
adapt with the asvs methodology

1421
00:42:56,160 --> 00:42:57,760
i like to say that i invented this but i

1422
00:42:57,760 --> 00:42:59,920
didn't somebody in the owasp world used

1423
00:42:59,920 --> 00:43:01,280
to call

1424
00:43:01,280 --> 00:43:02,720
what do they call it application

1425
00:43:02,720 --> 00:43:05,359
security

1426
00:43:05,680 --> 00:43:07,520
it was a threat modeling thing and like

1427
00:43:07,520 --> 00:43:10,000
the last reference to it was like 2006

1428
00:43:10,000 --> 00:43:11,119
or something but really all they were

1429
00:43:11,119 --> 00:43:12,640
talking about was taking a requirement

1430
00:43:12,640 --> 00:43:14,240
and kind of pointing it back towards the

1431
00:43:14,240 --> 00:43:16,480
threat model and so as i was reading i

1432
00:43:16,480 --> 00:43:17,680
was like i'm going to just call this the

1433
00:43:17,680 --> 00:43:19,599
asvs methodology

1434
00:43:19,599 --> 00:43:21,040
because these are questions that i would

1435
00:43:21,040 --> 00:43:23,119
ask at that whiteboard anyway like when

1436
00:43:23,119 --> 00:43:24,560
someone draws their feature one of the

1437
00:43:24,560 --> 00:43:26,640
things i always ask is okay so how you

1438
00:43:26,640 --> 00:43:28,400
how are you doing authentication on that

1439
00:43:28,400 --> 00:43:29,760
feature how are you handling

1440
00:43:29,760 --> 00:43:31,359
administrators is there a separate login

1441
00:43:31,359 --> 00:43:32,960
process for them is there a multi-factor

1442
00:43:32,960 --> 00:43:34,640
like what's happening and so all i did

1443
00:43:34,640 --> 00:43:36,240
here is just took the high-level

1444
00:43:36,240 --> 00:43:38,400
categories out of asps and said

1445
00:43:38,400 --> 00:43:40,400
let's start asking questions about these

1446
00:43:40,400 --> 00:43:42,800
things in the threat modeling process

1447
00:43:42,800 --> 00:43:44,880
because all too often we think of we

1448
00:43:44,880 --> 00:43:46,800
think threat modeling and requirements

1449
00:43:46,800 --> 00:43:48,240
are two separate things and you know

1450
00:43:48,240 --> 00:43:50,240
what they are not at all they need to be

1451
00:43:50,240 --> 00:43:51,839
interwoven with each other because there

1452
00:43:51,839 --> 00:43:53,359
is not a threat that doesn't point back

1453
00:43:53,359 --> 00:43:55,440
to a requirement somewhere

1454
00:43:55,440 --> 00:43:57,440
and so that's the that that's the what i

1455
00:43:57,440 --> 00:43:59,520
refer to as the asps methodology but i

1456
00:43:59,520 --> 00:44:01,040
think it's it's really about reverse

1457
00:44:01,040 --> 00:44:03,280
engineering those threats are those

1458
00:44:03,280 --> 00:44:04,720
requirements turning them back into

1459
00:44:04,720 --> 00:44:06,720
threats it gives people another source

1460
00:44:06,720 --> 00:44:08,560
if they don't want to dive into cwe or

1461
00:44:08,560 --> 00:44:10,160
attack or something like that it's

1462
00:44:10,160 --> 00:44:12,480
another source it's a great document so

1463
00:44:12,480 --> 00:44:14,240
well written it's it's it's something

1464
00:44:14,240 --> 00:44:15,440
that they can they can have a lot of

1465
00:44:15,440 --> 00:44:17,359
success with

1466
00:44:17,359 --> 00:44:18,880
okay tip number eight focus on the

1467
00:44:18,880 --> 00:44:21,040
mitigations like that is key

1468
00:44:21,040 --> 00:44:22,400
i've said it like five times i'll

1469
00:44:22,400 --> 00:44:23,680
probably say it two more times before i

1470
00:44:23,680 --> 00:44:25,599
finish here for me because that's really

1471
00:44:25,599 --> 00:44:27,599
the the true value that comes in in the

1472
00:44:27,599 --> 00:44:29,040
threat modeling process is the

1473
00:44:29,040 --> 00:44:31,200
mitigations and so what i did i just

1474
00:44:31,200 --> 00:44:34,319
took my stride and my asvs methodology

1475
00:44:34,319 --> 00:44:35,359
and said hey what are some of the

1476
00:44:35,359 --> 00:44:37,040
compensating controls that we can have

1477
00:44:37,040 --> 00:44:39,040
here these are hot this is high level

1478
00:44:39,040 --> 00:44:40,319
stuff that's okay that's what threat

1479
00:44:40,319 --> 00:44:41,760
modeling is about right we're not coding

1480
00:44:41,760 --> 00:44:43,680
at this point sometimes we are but we're

1481
00:44:43,680 --> 00:44:46,160
trying to do this and as a design time

1482
00:44:46,160 --> 00:44:47,920
activity even in a devops world you got

1483
00:44:47,920 --> 00:44:49,280
a design you can't just code something

1484
00:44:49,280 --> 00:44:51,200
and then go that's my design i don't

1485
00:44:51,200 --> 00:44:52,240
believe it

1486
00:44:52,240 --> 00:44:53,920
i mean you might be able to do it but i

1487
00:44:53,920 --> 00:44:55,920
won't believe you

1488
00:44:55,920 --> 00:44:57,680
so spoofing authentication session

1489
00:44:57,680 --> 00:44:59,280
management this all points back to

1490
00:44:59,280 --> 00:45:01,359
strong authentication with mfa strong

1491
00:45:01,359 --> 00:45:02,880
frameworks and libraries you know

1492
00:45:02,880 --> 00:45:04,000
there's nothing i'm not creating

1493
00:45:04,000 --> 00:45:05,839
anything new here right this is this is

1494
00:45:05,839 --> 00:45:07,760
all old stuff that's been said a million

1495
00:45:07,760 --> 00:45:08,880
times but

1496
00:45:08,880 --> 00:45:10,400
you know this is the key this is what

1497
00:45:10,400 --> 00:45:11,440
we're trying to get to are those

1498
00:45:11,440 --> 00:45:13,040
compensating controls when we do this

1499
00:45:13,040 --> 00:45:14,400
why we do this whole thing this whole

1500
00:45:14,400 --> 00:45:15,920
process

1501
00:45:15,920 --> 00:45:17,760
and you know frameworks and libraries

1502
00:45:17,760 --> 00:45:19,359
are really where it's at

1503
00:45:19,359 --> 00:45:20,960
when when you think about you know

1504
00:45:20,960 --> 00:45:22,240
what's that what's the best thing we can

1505
00:45:22,240 --> 00:45:24,400
do to cancel as many threats as possible

1506
00:45:24,400 --> 00:45:27,119
at least in a web app world

1507
00:45:27,119 --> 00:45:29,040
okay so tip number nine adopt the right

1508
00:45:29,040 --> 00:45:31,599
tool sets at the right time so to my

1509
00:45:31,599 --> 00:45:33,200
earlier point

1510
00:45:33,200 --> 00:45:34,560
we don't i don't want you to go buy a

1511
00:45:34,560 --> 00:45:35,839
tool and say now we're going to threat

1512
00:45:35,839 --> 00:45:38,720
model because it's just it's not you

1513
00:45:38,720 --> 00:45:40,240
haven't taught anybody how to do it

1514
00:45:40,240 --> 00:45:42,720
right it's like you know hey

1515
00:45:42,720 --> 00:45:44,240
15 and a half year old kid i just bought

1516
00:45:44,240 --> 00:45:46,160
you a car jump in go try and learn how

1517
00:45:46,160 --> 00:45:47,280
to drive

1518
00:45:47,280 --> 00:45:48,720
right it's not going to end well same

1519
00:45:48,720 --> 00:45:49,760
thing here

1520
00:45:49,760 --> 00:45:51,040
so people always ask me what's my

1521
00:45:51,040 --> 00:45:53,040
favorite tool and i always half jokingly

1522
00:45:53,040 --> 00:45:55,040
say the whiteboard but i really mean it

1523
00:45:55,040 --> 00:45:56,800
that's my favorite tool even a virtual

1524
00:45:56,800 --> 00:45:58,880
whiteboard or a in person you know on

1525
00:45:58,880 --> 00:46:00,800
the wall whiteboard because it's just

1526
00:46:00,800 --> 00:46:02,319
the collaboration that happens looking

1527
00:46:02,319 --> 00:46:03,760
people in the eye and kind of seeing oh

1528
00:46:03,760 --> 00:46:06,000
that person's got something to say

1529
00:46:06,000 --> 00:46:07,599
or you know drawing people into the

1530
00:46:07,599 --> 00:46:10,079
conversation in front of the whiteboard

1531
00:46:10,079 --> 00:46:12,560
that's my favorite tool

1532
00:46:12,560 --> 00:46:14,079
microsoft has the threat modeling tool

1533
00:46:14,079 --> 00:46:15,040
if you've been around threat modeling

1534
00:46:15,040 --> 00:46:16,480
you know it's been here since the days

1535
00:46:16,480 --> 00:46:18,000
of you know when you have a vizio

1536
00:46:18,000 --> 00:46:19,760
license on your computer to run the

1537
00:46:19,760 --> 00:46:21,200
threat modeling tool

1538
00:46:21,200 --> 00:46:22,160
um

1539
00:46:22,160 --> 00:46:24,640
i find that i mean i put it here i it's

1540
00:46:24,640 --> 00:46:26,640
still worth taking a look at if your

1541
00:46:26,640 --> 00:46:29,440
windows slash azure centric

1542
00:46:29,440 --> 00:46:30,640
it's probably the best one that's out

1543
00:46:30,640 --> 00:46:32,640
there but i find that i tend to kind of

1544
00:46:32,640 --> 00:46:34,240
drift away from it as soon as i get out

1545
00:46:34,240 --> 00:46:37,359
of the microsoft world it's just me

1546
00:46:37,359 --> 00:46:39,520
erious risk is a commercial tool that i

1547
00:46:39,520 --> 00:46:40,960
add on here and look at that disclaimer

1548
00:46:40,960 --> 00:46:42,400
at the bottom i should have said it like

1549
00:46:42,400 --> 00:46:43,440
in you know those practices have

1550
00:46:43,440 --> 00:46:44,319
occurred for any of these tool

1551
00:46:44,319 --> 00:46:46,400
recommendations like this isn't i don't

1552
00:46:46,400 --> 00:46:47,920
have any interest in any of these things

1553
00:46:47,920 --> 00:46:49,440
right this is just me as a practitioner

1554
00:46:49,440 --> 00:46:51,599
going and people ask me what what tools

1555
00:46:51,599 --> 00:46:53,119
they should look at this is what i tell

1556
00:46:53,119 --> 00:46:55,280
them to look at so yeah areas risk is a

1557
00:46:55,280 --> 00:46:57,440
is a commercial tool stephen devries was

1558
00:46:57,440 --> 00:46:59,040
one of the threat modeling manifesto

1559
00:46:59,040 --> 00:47:01,119
authors who's the ceo of iris risk i

1560
00:47:01,119 --> 00:47:02,800
still like their tool i think it's i

1561
00:47:02,800 --> 00:47:05,119
think it's the best tool out there for

1562
00:47:05,119 --> 00:47:06,400
it does a good job of melding the

1563
00:47:06,400 --> 00:47:08,319
requirements together does a good job of

1564
00:47:08,319 --> 00:47:09,920
giving you a drawing engine a lot of

1565
00:47:09,920 --> 00:47:11,040
really good templates so you don't have

1566
00:47:11,040 --> 00:47:12,960
to start from scratch on stuff so i like

1567
00:47:12,960 --> 00:47:14,480
it

1568
00:47:14,480 --> 00:47:16,160
and then in the owasp world i already

1569
00:47:16,160 --> 00:47:18,480
mentioned pi tm which i'm now i was a

1570
00:47:18,480 --> 00:47:19,760
giant fan of but now that i've actually

1571
00:47:19,760 --> 00:47:22,079
used it i'm even a bigger fan of it

1572
00:47:22,079 --> 00:47:24,640
and then owasp also has threat dragon so

1573
00:47:24,640 --> 00:47:28,079
thread dragon is a a web-based there's a

1574
00:47:28,079 --> 00:47:29,760
browser version there's now a desktop

1575
00:47:29,760 --> 00:47:31,599
version it lets you draw data flow

1576
00:47:31,599 --> 00:47:34,400
diagrams and then apply stride to it

1577
00:47:34,400 --> 00:47:37,200
apply linden the privacy methodology

1578
00:47:37,200 --> 00:47:38,720
and

1579
00:47:38,720 --> 00:47:40,160
the thing about threat dragon is it

1580
00:47:40,160 --> 00:47:41,359
appeared to be

1581
00:47:41,359 --> 00:47:43,440
dead about maybe a year and a half or

1582
00:47:43,440 --> 00:47:44,960
two years ago and now a couple other

1583
00:47:44,960 --> 00:47:46,240
people have joined the project and

1584
00:47:46,240 --> 00:47:48,240
there's like all this life and energy in

1585
00:47:48,240 --> 00:47:50,079
it and they're doing really some really

1586
00:47:50,079 --> 00:47:51,440
cool things so

1587
00:47:51,440 --> 00:47:53,440
it's a good tool to use as a starting

1588
00:47:53,440 --> 00:47:55,119
point for a program you know i would

1589
00:47:55,119 --> 00:47:56,720
spend some time like i said teaching

1590
00:47:56,720 --> 00:47:58,319
people the process get bringing them

1591
00:47:58,319 --> 00:48:00,000
along but if you don't have a giant

1592
00:48:00,000 --> 00:48:02,000
budget take a look at threat dragon as a

1593
00:48:02,000 --> 00:48:04,400
potential enterprise solution

1594
00:48:04,400 --> 00:48:06,160
to at least get you started and start to

1595
00:48:06,160 --> 00:48:07,280
you know get to the point where you've

1596
00:48:07,280 --> 00:48:09,680
got some results to show pi tm is such a

1597
00:48:09,680 --> 00:48:11,920
different approach that

1598
00:48:11,920 --> 00:48:14,240
um you know it's i don't know anybody

1599
00:48:14,240 --> 00:48:16,240
that's doing threat modeling as code

1600
00:48:16,240 --> 00:48:18,240
from a commercial perspective

1601
00:48:18,240 --> 00:48:20,400
but i the pi tm i can't speak enough

1602
00:48:20,400 --> 00:48:22,319
about it it's just a it's it's fun to

1603
00:48:22,319 --> 00:48:24,480
lay out how something's supposed to work

1604
00:48:24,480 --> 00:48:26,880
in python code and then watch diagrams

1605
00:48:26,880 --> 00:48:28,240
come out of that

1606
00:48:28,240 --> 00:48:29,599
so you got to have the right tool sets

1607
00:48:29,599 --> 00:48:31,119
at the right time for your enterprise

1608
00:48:31,119 --> 00:48:32,640
program

1609
00:48:32,640 --> 00:48:35,200
and then the final tip i have here is

1610
00:48:35,200 --> 00:48:38,400
threat model quality checks

1611
00:48:38,400 --> 00:48:40,880
so i guess i'm somebody who

1612
00:48:40,880 --> 00:48:43,200
i see value in

1613
00:48:43,200 --> 00:48:45,040
a community moving in a particular

1614
00:48:45,040 --> 00:48:46,720
direction

1615
00:48:46,720 --> 00:48:48,240
i'm not somebody who's going to sit and

1616
00:48:48,240 --> 00:48:51,200
start grading for the threat models nor

1617
00:48:51,200 --> 00:48:53,119
do i recommend that you do that

1618
00:48:53,119 --> 00:48:54,240
because what happens if i grade

1619
00:48:54,240 --> 00:48:55,599
somebody's threat model and i give them

1620
00:48:55,599 --> 00:48:58,000
a d minus on it

1621
00:48:58,000 --> 00:48:58,960
what are they going to do they're going

1622
00:48:58,960 --> 00:49:00,160
to be happy the next time they have to

1623
00:49:00,160 --> 00:49:01,119
do a threat model they're going to be

1624
00:49:01,119 --> 00:49:03,040
like this thing's stupid that's going to

1625
00:49:03,040 --> 00:49:04,720
be their immediate reaction to to what

1626
00:49:04,720 --> 00:49:06,319
they're at we're asking them to do

1627
00:49:06,319 --> 00:49:07,599
people are going to get better at threat

1628
00:49:07,599 --> 00:49:09,920
modeling the more they do it okay so we

1629
00:49:09,920 --> 00:49:11,839
just we have to just acknowledge the

1630
00:49:11,839 --> 00:49:13,040
fact that there's going to be sometimes

1631
00:49:13,040 --> 00:49:14,000
we're going to look at a threat model

1632
00:49:14,000 --> 00:49:15,280
we're going to be like

1633
00:49:15,280 --> 00:49:16,720
not how i would have done it but they're

1634
00:49:16,720 --> 00:49:18,319
moving in the right direction there is a

1635
00:49:18,319 --> 00:49:20,319
positive trajectory that we're on here

1636
00:49:20,319 --> 00:49:21,359
as a group

1637
00:49:21,359 --> 00:49:23,680
so don't be judgmental or harsh think

1638
00:49:23,680 --> 00:49:25,760
about the longer term play of this

1639
00:49:25,760 --> 00:49:27,280
strong security culture that's where

1640
00:49:27,280 --> 00:49:29,599
you're trying to get to right is

1641
00:49:29,599 --> 00:49:31,599
when i think threat modeling

1642
00:49:31,599 --> 00:49:33,119
and this is what was my approach at

1643
00:49:33,119 --> 00:49:34,880
cisco how am i going to work myself out

1644
00:49:34,880 --> 00:49:37,200
of a job in five years

1645
00:49:37,200 --> 00:49:39,040
where we don't need a threat modeling

1646
00:49:39,040 --> 00:49:41,119
person anymore because developers are

1647
00:49:41,119 --> 00:49:42,800
just sitting around going uh yeah of

1648
00:49:42,800 --> 00:49:44,240
course we threat model so that's how we

1649
00:49:44,240 --> 00:49:45,440
that's what we do here it's part of our

1650
00:49:45,440 --> 00:49:46,720
design we don't even

1651
00:49:46,720 --> 00:49:47,760
couldn't imagine doing it a different

1652
00:49:47,760 --> 00:49:48,640
way

1653
00:49:48,640 --> 00:49:49,760
that's a world where we don't need a

1654
00:49:49,760 --> 00:49:51,280
threat modeling coach anymore but that's

1655
00:49:51,280 --> 00:49:52,800
okay don't worry there'll be a lot of

1656
00:49:52,800 --> 00:49:54,160
other problems for us to solve there's

1657
00:49:54,160 --> 00:49:56,000
already you know 212 other problems we

1658
00:49:56,000 --> 00:49:57,680
need to solve so we're not going to work

1659
00:49:57,680 --> 00:49:58,880
ourselves out of a job we're just going

1660
00:49:58,880 --> 00:50:00,400
to move to a different challenge where

1661
00:50:00,400 --> 00:50:02,800
we can try to replicate the same idea

1662
00:50:02,800 --> 00:50:04,240
so when i'm doing a quality check i'm

1663
00:50:04,240 --> 00:50:05,599
saying hey did they follow the process

1664
00:50:05,599 --> 00:50:07,359
that we've laid out

1665
00:50:07,359 --> 00:50:08,800
was there any interesting threats that

1666
00:50:08,800 --> 00:50:10,400
came out of it

1667
00:50:10,400 --> 00:50:12,720
did they have mitigations applied did

1668
00:50:12,720 --> 00:50:14,400
they document this correctly the way

1669
00:50:14,400 --> 00:50:16,079
that that we've specified that we need

1670
00:50:16,079 --> 00:50:17,680
it to be done

1671
00:50:17,680 --> 00:50:19,520
and so you know those are that's what

1672
00:50:19,520 --> 00:50:20,559
i'm thinking about from a quality

1673
00:50:20,559 --> 00:50:22,559
perspective so there's my summary of all

1674
00:50:22,559 --> 00:50:24,800
the tips um you know having that solid

1675
00:50:24,800 --> 00:50:27,280
process embedding in your sdl well

1676
00:50:27,280 --> 00:50:28,640
bringing a diverse group of people to

1677
00:50:28,640 --> 00:50:30,720
the table having those coaches using

1678
00:50:30,720 --> 00:50:32,800
that workshop approach

1679
00:50:32,800 --> 00:50:34,640
embrace stride you know you can just

1680
00:50:34,640 --> 00:50:36,160
stick with the love relationship with

1681
00:50:36,160 --> 00:50:37,359
stride you don't have to try to hate one

1682
00:50:37,359 --> 00:50:38,480
i can tell you from experience that

1683
00:50:38,480 --> 00:50:41,359
didn't work well use asvs and some of

1684
00:50:41,359 --> 00:50:44,000
those other things i talked about cwe

1685
00:50:44,000 --> 00:50:46,640
capex miter attack use those for those

1686
00:50:46,640 --> 00:50:48,079
for those that are a little further down

1687
00:50:48,079 --> 00:50:49,200
the road

1688
00:50:49,200 --> 00:50:51,359
it's all about the mitigations the tools

1689
00:50:51,359 --> 00:50:52,880
and then quality checks are something

1690
00:50:52,880 --> 00:50:55,599
that we can that can help us to to grow

1691
00:50:55,599 --> 00:50:56,960
the enterprise program and help people

1692
00:50:56,960 --> 00:50:59,119
to get better at it

1693
00:50:59,119 --> 00:51:00,319
so yeah i mean we talked about the

1694
00:51:00,319 --> 00:51:02,240
definition of threat modeling you know

1695
00:51:02,240 --> 00:51:04,160
we did this to inspire folks such as

1696
00:51:04,160 --> 00:51:06,079
yourselves to get out there and improve

1697
00:51:06,079 --> 00:51:07,920
your programs that's the whole reason

1698
00:51:07,920 --> 00:51:09,280
why we created this document in the

1699
00:51:09,280 --> 00:51:10,240
beginning

1700
00:51:10,240 --> 00:51:12,000
you can use those values and principles

1701
00:51:12,000 --> 00:51:14,400
to help drive your culture

1702
00:51:14,400 --> 00:51:16,640
inside your your program

1703
00:51:16,640 --> 00:51:17,920
take those tips hopefully you'll have

1704
00:51:17,920 --> 00:51:20,319
some good success with it and like i end

1705
00:51:20,319 --> 00:51:22,000
all of my threat modeling talks threat

1706
00:51:22,000 --> 00:51:23,599
model all the things that's the

1707
00:51:23,599 --> 00:51:25,520
challenge that i send you out to do i

1708
00:51:25,520 --> 00:51:26,720
should say teach everybody else to

1709
00:51:26,720 --> 00:51:28,960
threat model all the things but

1710
00:51:28,960 --> 00:51:30,880
there's my uh some some ways you can

1711
00:51:30,880 --> 00:51:32,960
connect with me there's the uh if you

1712
00:51:32,960 --> 00:51:34,480
want to check out what security journey

1713
00:51:34,480 --> 00:51:36,480
does as a you know from a training

1714
00:51:36,480 --> 00:51:37,920
perspective we've got a free trial

1715
00:51:37,920 --> 00:51:40,960
mentioned there um check out the podcast

1716
00:51:40,960 --> 00:51:43,200
i also do something we call high five

1717
00:51:43,200 --> 00:51:44,240
which is where i have a little bit of

1718
00:51:44,240 --> 00:51:46,160
fun with the security news myself some

1719
00:51:46,160 --> 00:51:47,520
articles that catch my attention and

1720
00:51:47,520 --> 00:51:49,359
then i may add a little bit of snark and

1721
00:51:49,359 --> 00:51:51,920
video form on top of it um there's my

1722
00:51:51,920 --> 00:51:54,000
email address and uh twitter handles and

1723
00:51:54,000 --> 00:51:55,280
stuff so i'd love to keep the

1724
00:51:55,280 --> 00:51:57,280
conversation going i'll talk about

1725
00:51:57,280 --> 00:51:59,839
threat modeling 24 7 if people want to

1726
00:51:59,839 --> 00:52:00,800
so

1727
00:52:00,800 --> 00:52:02,480
but i am curious to see does anybody

1728
00:52:02,480 --> 00:52:05,200
have any questions

1729
00:52:05,200 --> 00:52:07,119
okay we need a microphone for somebody

1730
00:52:07,119 --> 00:52:08,640
asking a question are we just shouting

1731
00:52:08,640 --> 00:52:09,839
good to go all right i'm gonna start in

1732
00:52:09,839 --> 00:52:11,200
the back because his hand was up really

1733
00:52:11,200 --> 00:52:12,640
long

1734
00:52:12,640 --> 00:52:14,400
is it okay to have an endless sea of

1735
00:52:14,400 --> 00:52:16,319
threat models one for each feature or

1736
00:52:16,319 --> 00:52:18,960
how do you get those

1737
00:52:20,079 --> 00:52:22,400
ah you identify and one of the big

1738
00:52:22,400 --> 00:52:24,079
challenges of building a

1739
00:52:24,079 --> 00:52:27,680
a threat model for an entire system

1740
00:52:27,680 --> 00:52:28,400
so

1741
00:52:28,400 --> 00:52:31,119
many people have tried to find ways to

1742
00:52:31,119 --> 00:52:32,720
bring the threat a bunch of smaller

1743
00:52:32,720 --> 00:52:34,640
threat models back together into a super

1744
00:52:34,640 --> 00:52:37,280
threat model and many people have failed

1745
00:52:37,280 --> 00:52:39,520
going down that road myself included and

1746
00:52:39,520 --> 00:52:42,000
so what i really focus in on is is all i

1747
00:52:42,000 --> 00:52:43,920
care about is individual features

1748
00:52:43,920 --> 00:52:45,359
if we get to the point where we're we're

1749
00:52:45,359 --> 00:52:47,760
threat modeling individual features

1750
00:52:47,760 --> 00:52:49,200
for one we're going to build a group of

1751
00:52:49,200 --> 00:52:50,480
people that are going to be able at some

1752
00:52:50,480 --> 00:52:52,240
point to step back and say now we're

1753
00:52:52,240 --> 00:52:54,160
ready to threat model a bigger piece

1754
00:52:54,160 --> 00:52:55,520
because one of the challenges i've seen

1755
00:52:55,520 --> 00:52:57,440
in threat modeling is if we jump in and

1756
00:52:57,440 --> 00:52:59,040
we say let's threat model this whole

1757
00:52:59,040 --> 00:53:00,400
application

1758
00:53:00,400 --> 00:53:02,559
we end up just spinning our wheels

1759
00:53:02,559 --> 00:53:03,839
people are like i don't even understand

1760
00:53:03,839 --> 00:53:05,200
what we're supposed to be doing and then

1761
00:53:05,200 --> 00:53:06,720
six months later we just cancel it and

1762
00:53:06,720 --> 00:53:09,200
stop doing it so but what i'm saying is

1763
00:53:09,200 --> 00:53:10,079
if we

1764
00:53:10,079 --> 00:53:11,440
get in the habit of threat modeling the

1765
00:53:11,440 --> 00:53:13,040
smaller features further down the road

1766
00:53:13,040 --> 00:53:14,400
there'll be a time where we can look at

1767
00:53:14,400 --> 00:53:15,839
them all together with some people that

1768
00:53:15,839 --> 00:53:18,160
have really understood the process so my

1769
00:53:18,160 --> 00:53:20,240
guidance is really and what i stick to

1770
00:53:20,240 --> 00:53:21,839
is stick to the feature

1771
00:53:21,839 --> 00:53:23,280
if you stick to the features and you're

1772
00:53:23,280 --> 00:53:24,800
hitting enough a good percentage of

1773
00:53:24,800 --> 00:53:26,400
stuff that's coming out you're going to

1774
00:53:26,400 --> 00:53:29,359
be in a good place

1775
00:53:29,359 --> 00:53:30,720
okay i think there's another hand up

1776
00:53:30,720 --> 00:53:34,799
here towards the front ah yes please

1777
00:53:35,119 --> 00:53:37,520
you can hear me um

1778
00:53:37,520 --> 00:53:39,599
so i i've sort of been tasked with the

1779
00:53:39,599 --> 00:53:41,280
threat modeling that's going on in our

1780
00:53:41,280 --> 00:53:43,440
organization and there's a lot of threat

1781
00:53:43,440 --> 00:53:44,720
modeling on the asset side that

1782
00:53:44,720 --> 00:53:46,160
including some of the infrastructure and

1783
00:53:46,160 --> 00:53:48,240
social development as well

1784
00:53:48,240 --> 00:53:51,280
and relating it to risk management

1785
00:53:51,280 --> 00:53:54,079
and how to convey risk to executive

1786
00:53:54,079 --> 00:53:55,440
leadership

1787
00:53:55,440 --> 00:53:56,480
and

1788
00:53:56,480 --> 00:53:57,599
i think

1789
00:53:57,599 --> 00:53:59,280
maybe that's like another part of puzzle

1790
00:53:59,280 --> 00:54:01,440
i'm not sure how to put that together

1791
00:54:01,440 --> 00:54:03,440
yeah that is that is an interesting

1792
00:54:03,440 --> 00:54:06,000
challenge to bridge two different worlds

1793
00:54:06,000 --> 00:54:08,960
of engineering and kind of the more

1794
00:54:08,960 --> 00:54:11,119
audit risk management side of the house

1795
00:54:11,119 --> 00:54:12,400
and um

1796
00:54:12,400 --> 00:54:14,960
yeah i think um

1797
00:54:14,960 --> 00:54:16,240
is there a reason that you have to get

1798
00:54:16,240 --> 00:54:18,079
back to risk like the

1799
00:54:18,079 --> 00:54:20,640
why you can't take executives

1800
00:54:20,640 --> 00:54:22,559
kind of educate them about threats as if

1801
00:54:22,559 --> 00:54:24,240
they already understand risk or what's

1802
00:54:24,240 --> 00:54:26,480
the motivation to to to have to convert

1803
00:54:26,480 --> 00:54:28,160
it along the way

1804
00:54:28,160 --> 00:54:30,559
i think because we do have a regular

1805
00:54:30,559 --> 00:54:33,200
cadence of reporting on this and it's a

1806
00:54:33,200 --> 00:54:35,040
good way for

1807
00:54:35,040 --> 00:54:36,839
getting the message across

1808
00:54:36,839 --> 00:54:38,400
yeah

1809
00:54:38,400 --> 00:54:39,599
yeah i mean my

1810
00:54:39,599 --> 00:54:41,599
my advice to would be to

1811
00:54:41,599 --> 00:54:43,599
i mean i think of of threat and risk as

1812
00:54:43,599 --> 00:54:44,799
very different

1813
00:54:44,799 --> 00:54:45,760
things

1814
00:54:45,760 --> 00:54:47,599
you know risk is the chance of something

1815
00:54:47,599 --> 00:54:49,040
happening threat is the bad thing that's

1816
00:54:49,040 --> 00:54:50,480
going to happen that's what i that's how

1817
00:54:50,480 --> 00:54:52,160
i approach it in from an appsec

1818
00:54:52,160 --> 00:54:53,280
perspective

1819
00:54:53,280 --> 00:54:54,400
and so

1820
00:54:54,400 --> 00:54:56,240
yeah i don't know that i have i don't

1821
00:54:56,240 --> 00:54:57,599
really have any great advice for how to

1822
00:54:57,599 --> 00:54:59,680
convert it i would try to lead with the

1823
00:54:59,680 --> 00:55:01,200
threat side of it of like let's

1824
00:55:01,200 --> 00:55:02,640
understand here's all the bad things

1825
00:55:02,640 --> 00:55:03,839
that can happen

1826
00:55:03,839 --> 00:55:05,200
and then maybe from a risk management

1827
00:55:05,200 --> 00:55:07,040
perspective you can you can then pull

1828
00:55:07,040 --> 00:55:08,960
the you know what's the chance of this

1829
00:55:08,960 --> 00:55:11,119
these bad things happening and stuff

1830
00:55:11,119 --> 00:55:12,720
from more of an engineering perspective

1831
00:55:12,720 --> 00:55:14,559
but yeah it's an interesting challenge i

1832
00:55:14,559 --> 00:55:15,680
think you have a conference talk for

1833
00:55:15,680 --> 00:55:18,079
next year at last con i recommend

1834
00:55:18,079 --> 00:55:20,400
how to meld together risk and threat

1835
00:55:20,400 --> 00:55:21,920
in a big company i think there was

1836
00:55:21,920 --> 00:55:23,280
another hand behind right here first

1837
00:55:23,280 --> 00:55:25,839
then i'll come back over here yes

1838
00:55:25,839 --> 00:55:27,760
oh last one i got my last call and i'll

1839
00:55:27,760 --> 00:55:29,599
be available out in the hallway too so

1840
00:55:29,599 --> 00:55:31,119
i'll be in the hallway

1841
00:55:31,119 --> 00:55:34,960
just to go on marion as

1842
00:55:40,480 --> 00:55:42,480
they want to quantify

1843
00:55:42,480 --> 00:55:44,480
like the potential risk so that they

1844
00:55:44,480 --> 00:55:46,720
could understand their correct landscape

1845
00:55:46,720 --> 00:55:48,879
so

1846
00:55:52,079 --> 00:55:55,680
modeling and you relate it then your

1847
00:55:55,680 --> 00:55:58,400
executive leadership is relatable risks

1848
00:55:58,400 --> 00:55:59,830
it becomes

1849
00:55:59,830 --> 00:56:00,960
[Music]

1850
00:56:00,960 --> 00:56:02,119
it true

1851
00:56:02,799 --> 00:56:05,040
something that could potentially be real

1852
00:56:05,040 --> 00:56:06,559
because then that helps the leadership

1853
00:56:06,559 --> 00:56:08,480
priority so once you

1854
00:56:08,480 --> 00:56:09,599
once you

1855
00:56:09,599 --> 00:56:11,839
do this right modelling you can join it

1856
00:56:11,839 --> 00:56:13,920
with the risk factors and then

1857
00:56:13,920 --> 00:56:15,119
classified

1858
00:56:15,119 --> 00:56:17,359
so then you have your correct landscape

1859
00:56:17,359 --> 00:56:18,640
and that helps

1860
00:56:18,640 --> 00:56:22,000
the executives understand

1861
00:56:22,000 --> 00:56:24,079
if they're gonna you know be charged or

1862
00:56:24,079 --> 00:56:26,079
lose some money or lose some data or

1863
00:56:26,079 --> 00:56:28,319
something like that and then it helps

1864
00:56:28,319 --> 00:56:30,558
them

1865
00:56:37,440 --> 00:56:40,319
old-school dread so when you use that

1866
00:56:40,319 --> 00:56:42,240
and you let them know they look it's

1867
00:56:42,240 --> 00:56:45,280
repeatable it is repeatable

1868
00:56:45,280 --> 00:56:46,160
and

1869
00:56:46,160 --> 00:56:48,240
it's like it's easy somebody without a

1870
00:56:48,240 --> 00:56:50,079
tool can do it

1871
00:56:50,079 --> 00:56:52,240
yeah that's a good point that's a

1872
00:56:52,240 --> 00:56:53,680
i mean and executives want to get back

1873
00:56:53,680 --> 00:56:55,359
to the money right at the end of the day

1874
00:56:55,359 --> 00:56:56,319
that's what that's what they're

1875
00:56:56,319 --> 00:56:58,799
concerned with that was good that was

1876
00:56:58,799 --> 00:57:00,480
good so thanks everybody i'm gonna i'll

1877
00:57:00,480 --> 00:57:01,680
be out in the hallway right outside the

1878
00:57:01,680 --> 00:57:02,720
doors here so if you want to keep

1879
00:57:02,720 --> 00:57:04,240
talking about threat modeling i mean i

1880
00:57:04,240 --> 00:57:05,839
got a few more hours so

1881
00:57:05,839 --> 00:57:09,319
thank you very much

1882
00:57:12,319 --> 00:57:14,400
you

