00:00:00.133,00:00:05.138
>>So, without anymore waiting,
I’m just going to give chance-
give ahh give Bruce a chance to

00:00:08.442,00:00:13.447
get started so umm, please
welcome Bruce Schneier.
[applause] >>Good Morning,

00:00:21.521,00:00:28.128
thanks for waking up for me, I
appreciate it. I always worry
about starting at the early hour

00:00:28.128,00:00:34.668
of 10. And also I would have
done the hand wa- raise as who
has two or more seats next to

00:00:34.668,00:00:39.673
them and has taken a shower this
morning? [laughing]. Because
there might be a reason. I wanna

00:00:44.511,00:00:49.516
talk about the uhh the “going
dark” debate for a second. And
this is a 25-year-old issue.

00:00:52.753,00:00:58.992
Government has wanted access to
encrypted communications.
Mid-90’s clipper chip, that was

00:00:58.992,00:01:03.931
uhh the first example of that.
You remember access to iPhones
uhh a few years ago. Very

00:01:07.935,00:01:12.940
recently Attorney General Barr
remade demands that companies
make communications systems

00:01:16.643,00:01:21.648
available for law enforcement. A
lot of politics here, Five eyes,
the law enforcement arms

00:01:24.318,00:01:30.524
released a statement a couple of
weeks ago. So there’s actually
some real technology to talk

00:01:30.524,00:01:35.529
about in this problem. Alright
we can talk about key escrow
technologies; Ways to make keys

00:01:38.265,00:01:44.304
available to a third party under
cryptographic rules. We can talk
about obfuscation technologies.

00:01:44.304,00:01:49.943
How to write code that can be
reverse engineered.
Vulnerability finding is

00:01:49.943,00:01:56.249
relevant here and we can
actually do research in building
better or worse backdoors.

00:01:56.249,00:02:02.422
Different kinds of backdoors,
what’s the mechanism? How does
it work? There’s more stuff in

00:02:02.422,00:02:07.561
this debate. How the
underpinnings of surveillance
capitalism, right, how companies

00:02:07.561,00:02:12.566
are already spying on us. Gmail
is already backdoored for a
reason, right, we want the cloud

00:02:15.602,00:02:21.675
provider to do work on our email
therefore they must have the
plain text. We have other

00:02:21.675,00:02:28.015
systems backdoored because of
uhh of surveillance. Companies
want to spy on us to sell us

00:02:28.015,00:02:33.020
stuff. Underlying security needs
a society matter here. The
systems that are being

00:02:35.589,00:02:42.095
backdoored are increasingly
being used for very sensitive,
personal Government Military,

00:02:42.095,00:02:47.100
National Security applications.
There’s some real policy
decisions to make. There is a

00:02:49.503,00:02:54.508
security benefit to making data
available to the FBI to solve
crimes, even though, that

00:02:56.977,00:03:02.149
necessarily makes that data
available to others. And there’s
a security benefit to making

00:03:02.149,00:03:08.755
sure our data is secure from
everybody- Even if that makes
that also secure from law

00:03:08.755,00:03:15.262
enforcement. Which is more
important? To what degree it’s
more important. I also have

00:03:15.262,00:03:20.667
questions about consumer
acceptance, International
taratives, how this count- this

00:03:20.667,00:03:26.673
technology would be exported to
other countries who would use
the same systems for different

00:03:26.673,00:03:31.678
reasons. And so here’s the
issue: Almost no policy makers
discussing this issue have the

00:03:37.117,00:03:42.122
technological chops to
understand the tech part. “Going
dark” is a scare term. It’s an

00:03:45.759,00:03:50.764
effective one. So 60 years ago,
there was a British scientist
named C.P. Snow, and he wrote an

00:03:52.766,00:03:59.739
essay called the ‘Two Cultures.’
And in that essay, he lamented
on the lack of dialogue between

00:03:59.739,00:04:04.678
what he called the scientific
technical culture and the
humanist culture. He kinda

00:04:07.214,00:04:12.786
bemoaned that there was- that
neither culture understood each
other. And it was like they were

00:04:12.786,00:04:17.791
in two completely different
worlds. So today we still have
those two separate worlds. We

00:04:20.494,00:04:26.500
have the world of the
technologists who build really
cool tools often without regard

00:04:26.500,00:04:31.505
of how they affect society, and
then there’s the world of policy
that can criticize technology

00:04:33.707,00:04:38.712
and propose solutions without
actually understanding how the
technology works. So those two

00:04:41.114,00:04:46.119
cultures, that split, was
largely okay in 1959. And for
the most part, tech and policy

00:04:49.422,00:04:54.427
didn’t interact with each other
very much. There are exceptions:
large government programs like

00:04:56.997,00:05:01.935
nuclear weapons and the space
program, but you could see the
two as separate. Today it’s

00:05:05.138,00:05:10.143
really different, tech and
policy are deeply intertwined.
Tech makes defacto policy. Laws

00:05:13.980,00:05:18.985
forever catching up with what
tech does. And it’s no longer
sustainable for tech and policy

00:05:21.087,00:05:26.092
to be in different worlds. So
specifically what I’m calling
for, what I write about, is the

00:05:28.528,00:05:34.501
case for public interest
technologists. Important in all
aspects of technology,

00:05:34.501,00:05:39.506
especially in security. Alright,
so start by saying how we got
here. Most people know this

00:05:43.176,00:05:47.981
story, the internet was never
designed with security in mind.
Absolutely crazy when I say it.

00:05:47.981,00:05:53.587
Today, go back to the early
80’s, two things true about the
internet, one it wasn’t used for

00:05:53.587,00:05:59.192
anything important, ever. And
two, you had to be a member of a
research institution to get

00:05:59.192,00:06:04.731
access to it in the first place.
Those constraints were
sufficient, and the designers

00:06:04.731,00:06:09.736
decided to ignore security, push
it to the end points. Internet
develops, and you had a very

00:06:12.606,00:06:17.611
specific ethos. Very American
centric, male dominated, profit
motivated IT industry that

00:06:20.413,00:06:23.083
didn’t spend a lot of time
thinking about the social
effects of what they were

00:06:23.083,00:06:29.089
building. So, of course,
deliberately excluded it from
normal liability laws. Policy

00:06:29.089,00:06:34.094
makers didn’t want to touch it,
because there was very much an
engine of economic growth,

00:06:36.963,00:06:41.968
couple that with a libertarian
ethos in Silicon Valley, and you
have an internet which is not

00:06:44.271,00:06:46.273
really touched by regulation, by
societal concerns. And Internet
tech is different to 1960’s

00:06:46.273,00:06:48.275
tech. More democratic, more
distributed, more diffused, more
commercial, moves a lot faster.

00:06:48.275,00:06:50.277
The internet became critical,
kind of in all levels of our
society really by accident,

00:06:50.277,00:06:53.480
without any planning, without
any forethought. Today it’s
embedded in every aspect of our

00:06:53.480,00:06:59.719
lives. Pretty much every form of
communication uses the internet,
including communications between

00:06:59.719,00:07:04.958
like really important people.
Add the internet of things, add
a critical infrastructure. Add

00:07:04.958,00:07:09.963
in the coming years automation,
autonomy, physical agency, and
suddenly these systems are

00:07:32.852,00:07:37.857
affecting life and property. And
tech has become defacto policy.
There are companies that have

00:07:43.029,00:07:49.402
effective control on free
speech, on censorship,
regardless of the laws.

00:07:49.402,00:07:55.809
Companies can set limits on
personal freedoms, regardless of
the laws. A lot of it’s because

00:07:55.809,00:08:00.413
there’s still a belief that
these things are personal choice
to use, as if you could be a

00:08:00.413,00:08:05.452
fully functioning member of
society in our century without a
cell phone, without an email

00:08:05.452,00:08:10.457
address. So now we hear terms
like algorithmic discrimination,
digital-ivide, information

00:08:12.459,00:08:18.732
attacks on democracies,
surveillance capitalisms. The
internet is no longer a separate

00:08:18.732,00:08:25.472
thing, it’s part of everything.
It’s part of consumer policy. Go
to the villages, it’s part of

00:08:25.472,00:08:32.245
automobile policy, airplane
policy, medical device policy,
etc., etc. It effects

00:08:32.245,00:08:36.950
discrimination, equal
protection, fairness, liberty,
power, democracy. It’s part of

00:08:36.950,00:08:41.955
national security, it’s part of
everything. So now you think of
going dark, it’s suddenly a

00:08:45.492,00:08:51.998
bigger question, as internet
security becomes everything
security. Internet security

00:08:51.998,00:08:58.171
technology becomes more
important to overall security
policy. And you’ll never get the

00:08:58.171,00:09:03.109
policy right, if policy makers
get the tech wrong; And this is
why we need public interest

00:09:06.746,00:09:11.751
technologists. Actually fixing
this has two parts. The first is
policy makers need to understand

00:09:14.287,00:09:19.292
tech. We want is all policy
discussions to be informed by
the relevant technologies.

00:09:22.929,00:09:28.334
Reality is more that policy
makers ignore the tech if it
doesn’t conform to their

00:09:28.334,00:09:34.240
politics. Maybe they don’t know
enough to uhh to do anything
useful. I think that stifling

00:09:34.240,00:09:39.245
innovation is still a big fear.
Lobbyists will easily provide
whatever information matches the

00:09:41.281,00:09:46.286
political beliefs. I saw this I
think in full display in the
facebook hearings. The question,

00:09:49.122,00:09:54.127
“how do you make money?” We
laugh, but the fact that a
sitting senator doesn’t think it

00:09:57.330,00:10:03.937
would be a idiotic question to
ask? Means we have some serious
problems. And I don’t need

00:10:03.937,00:10:09.375
policy makers to be
technologists. We have
Government that- where things

00:10:09.375,00:10:14.314
are governed that the people
governing don’t understand them,
they have staffers that do. They

00:10:14.314,00:10:19.619
have staffers that know to ask
the right questions, that have
good bull s**t detectors, that

00:10:19.619,00:10:25.525
believe in the truths of
technology. This is, like, no
different from any other area of

00:10:25.525,00:10:31.464
society. So that’s the first
part. The second part, is that
we need technologists to get

00:10:31.464,00:10:37.403
involved in public policy. We
need more public interest
technologists. So let me define

00:10:37.403,00:10:42.709
that term. Bunch of different
definitions, gunna read the Ford
Foundations definition:

00:10:42.709,00:10:47.614
Technical practitioners who
focus on social justice, the
common good and or the public

00:10:47.614,00:10:54.120
interest. Ehh, a little bit
issue focused. Tim Berners Lee
has a great term: Philosophical

00:10:54.120,00:11:00.360
engineers. Another definition I
read is, people who study the
application of technology

00:11:00.360,00:11:05.398
expertise to advance the public
interest, generate public
benefits, or, promote the public

00:11:05.398,00:11:10.203
good. Alright, so it’s not one
thing, it’s a lot of things. I
think of public interest

00:11:10.203,00:11:16.376
technologists as people who’ve
combined their tech expertise
with a public interest focus. By

00:11:16.376,00:11:21.381
working on tech policy. By
working on a tech project with a
public benefit. By working for a

00:11:24.017,00:11:30.623
more traditional organization in
an IT role with has a public
benefit. Or working on a

00:11:30.623,00:11:35.628
technology inside government.
Still kind of a developing term,
not everyone likes it, but I

00:11:37.830,00:11:44.337
think it’s a decent umbrella
term for what we all do.
Alright, large tent, lot of job

00:11:44.337,00:11:49.342
descriptions. Do we need these
people who can weigh in on
public interest- on public

00:11:51.544,00:11:56.549
policy debates. So, a second
example, where policy
desperately needs some tech

00:11:59.552,00:12:04.490
focus: Supply chain security. In
the news a lot- This year last
year, China, Huawei. Should we

00:12:08.761,00:12:13.766
trust networking equipment built
by a company who resides in a
country that we don’t trust?

00:12:18.571,00:12:23.576
Reasonable question to ask?
Couple years ago, same question
is about Kaspersky. And sure,

00:12:28.381,00:12:33.620
yes, companies are subject to
the pressures by the governments
of their own country, alright,

00:12:33.620,00:12:38.625
U.S. companies included. But
supply chain securitys’ a lot
more complicated than that, this

00:12:40.693,00:12:46.933
is not made in the United
States. It’s chips are not
fabbed in the United States.

00:12:46.933,00:12:51.938
It’s programmers carry 100
different passports. And we all
know that the security of this

00:12:55.441,00:13:01.981
device can be subverted at any
of those points. We all know
that you have to trust the

00:13:01.981,00:13:08.021
distribution mechanism. We have
fake apps in the Google Play
store. We have to trust the

00:13:08.021,00:13:13.926
update mechanism. Remember not
pet yet distributed through a
malicious update of a Ukranian

00:13:13.926,00:13:18.364
accounting package? We know you
have to trust the shipping
mechanism, because we all

00:13:18.364,00:13:24.937
remember that photograph of NSA
employees opening up a Cisco box
that was intended for the Syrian

00:13:24.937,00:13:29.942
telephone company. Supply chain
security is a lot harder
problem, you have to trust

00:13:32.311,00:13:37.316
everyone, yet you can’t trust
anyone. And the solutions are
equally problematic. We could

00:13:41.788,00:13:46.125
build the U.S. only version of
an IPhone. It’ll cost, what, ten
times as much and no one will

00:13:46.125,00:13:51.130
buy it. And the policy
discussions would take this all
into account. And I think there

00:13:55.501,00:14:02.075
actually is a major research
effort we should undergo. Just
like the internet was built

00:14:02.075,00:14:07.080
around the question, “Can we
create a reliable network with
unreliable parts? Can we create

00:14:10.817,00:14:15.822
a secure system with insecure
parts?.” That’s another one,
there are more policy debates.

00:14:19.926,00:14:25.398
Insecurity that technologists
need to get involved in.
Vulnerabilities equity debate

00:14:25.398,00:14:31.404
talked about a lot here. Offense
vs. defense, how bug bounties
work, the international aspects

00:14:31.404,00:14:36.409
of it, The cyber weapons arms
manufacturers. The debates on
election security. Blocked

00:14:39.846,00:14:46.819
shame; what it does, what it
doesn’t do, how to regulate it.
Internet of things, safety and

00:14:46.819,00:14:53.192
security, I’m kind of listing
the villages we have here. I
mean 5g security vs. 5g

00:14:53.192,00:14:58.197
surveillance, critical
infrastructure. Data privacy in
big data, algorithmic security,

00:15:00.800,00:15:05.805
algorithmic fairness, AI
robotics; These are all going to
be major policy issues that need

00:15:09.809,00:15:14.413
to be informed by technology.
And there are a lot more once
you broaden the definition of

00:15:14.413,00:15:21.354
internet security. I wrote in a
series of papers on influence
operations against democracies

00:15:21.354,00:15:26.359
looking at a democracy as an
information system. And what can
we learn by bringing in our way

00:15:28.528,00:15:33.533
of thinking about security to
this very much nontraditional
question? So we need this and we

00:15:38.004,00:15:43.810
need it now. There’s one report
written about this, that called
this the “Pivotal Moment”. I

00:15:43.810,00:15:49.215
wanna read this from the report,
read a sentence. “While we site
individual instances of

00:15:49.215,00:15:52.785
visionary leadership but
successful deployment of
technology skill for the public

00:15:52.785,00:15:58.424
interest, there was consensus
that the stubborn cycle of
inadequate supply,

00:15:58.424,00:16:05.031
misarticulated demand and an
inefficient marker place stymies
progress.” Alright, so that

00:16:05.031,00:16:10.837
quote speaks to how we can
intervene to try fixing this
problem. Okay three things.

00:16:10.837,00:16:17.009
First was the supply side, and I
think in the end this is our
biggest problem. There isn’t

00:16:17.009,00:16:23.316
enough raw talent to tack for
the public interest. Especially
acute in cyber security cause

00:16:23.316,00:16:28.421
it’s actually enough raw talent
to tap into the regular
corporate needs. It’s cyber

00:16:28.421,00:16:33.426
security’s cap is a big deal.
And when you look at the public
interest technologists today,

00:16:36.195,00:16:39.332
it’s a very diverse group of
people, it’s a very
multidisciplinary group of

00:16:39.332,00:16:45.805
people. Backgrounds come from
tech, from policy, from law. A
lot of people without a computer

00:16:45.805,00:16:51.344
science degree doing this work.
We need to make a list- we need
a lot of different ways for

00:16:51.344,00:16:58.084
people to engage in this sphere.
It’s not just taking it as your
job. How can we do it on the

00:16:58.084,00:17:03.022
side? How can people take a
couple of years between regular
jobs and do this? Or sabbatical

00:17:07.093,00:17:12.098
years and work for a company
that has those? So we need
clinics at Universities, which

00:17:15.368,00:17:20.373
people can get a taste for this
kind of public interest tech
work. And we need to really

00:17:22.475,00:17:27.480
force in diversity. What we’ve
learned I think very graphically
in the past decade or so, is

00:17:31.450,00:17:37.690
that if a population’s using
tech are not represented in the
groups that shape the tech, you

00:17:37.690,00:17:42.695
get really lousy tech. Second is
the demand side, and right now
at this moment, as bad as supply

00:17:48.801,00:17:54.740
is, demand is worse. I get more
people asking me after talks
like this, “I want to do this,

00:17:54.740,00:17:59.745
where do I go?” And there are
few places to go. So we need
jobs funded at a variety of

00:18:01.948,00:18:06.953
NGO’s inside government at all
levels. More organizations doing
this kind of work. And the third

00:18:11.190,00:18:17.196
intervention is the marketplace.
And here we just need things
that reduce the friction. Where

00:18:17.196,00:18:22.601
people who want to do this will
find people who need this done.
And right now, it’s a little

00:18:22.601,00:18:27.606
haphazard. Here maybe rights
come more in a freedom festival,
and those are places where

00:18:29.675,00:18:35.815
public interest tech happens. If
somebody called a non-profit
technology conference, anyone

00:18:35.815,00:18:40.820
heard of it? I sure didn’t, but
places like that. There are
organizations doing this. We can

00:18:46.692,00:18:51.297
list Electronic Frontier
Foundation, Electronic Privacy
Information Center, Acces Now,

00:18:51.297,00:18:58.204
lots more. There are now
academic programs. I teach at
Harvard, but, Carnegie Mellon,

00:18:58.204,00:19:03.943
Georgetown, Stanford,
everywhere. New America last
year formed the public interest

00:19:03.943,00:19:08.714
technology University Network.
21 Universities going to be
starting up different programs.

00:19:10.950,00:19:16.622
There are technologists inside
government. Some of our
colleagues have taken senior

00:19:16.622,00:19:22.328
positions inside the federal
trade commission, for a year,
for two years. There’s an

00:19:22.328,00:19:27.500
organization called tech
congress that put technologists
like us on congressional staffs’

00:19:27.500,00:19:32.505
for a year. Aspen Institute has
a tech policy hub- has fellows.
And there are even programs as

00:19:36.842,00:19:43.249
initiatives inside corporations.
The big one you’ve probably
heard of is Jigsaw, inside

00:19:43.249,00:19:48.254
google alphabet. Something more
near and dear to our community
are public interest

00:19:50.256,00:19:56.562
technologists building
technology to benefit the public
interest. So you know, Tour,

00:19:56.562,00:20:03.235
Signal and all the others.
Tails, cubes, etc., etc. Or apps
that track public policy issues.

00:20:03.235,00:20:09.809
So something I don’t think we
give enough credit to, are the
people who are doing IT security

00:20:09.809,00:20:15.181
work inside public interest
organizations. Like Ames
International, Human Rights

00:20:15.181,00:20:21.520
Watch, Greenpeace. It’s a hard
job. You’d make like half what
you’d make elsewhere, and

00:20:21.520,00:20:26.525
honestly the government of China
vs. Human Rights Watch is not a
fair fight. And our colleagues

00:20:29.795,00:20:36.402
are fighting that fight. Lastly
there are public interest
technologists doing training.

00:20:36.402,00:20:41.307
They have tactical tech or
digital security exchange, you
know, matching expertise with

00:20:41.307,00:20:46.312
people that need it. And there
are foundations funding in this
space. Fort, Mcarthur, Hewitt,

00:20:49.682,00:20:54.687
Maticula, there are others. And
this all might seem like a lot,
but it’s really not. These are

00:20:57.857,00:21:02.795
examples, but they’re still
largely exceptions, still
largely on the edges. We have to

00:21:05.431,00:21:11.837
scale this. We know about these
examples cause we’re paying
attention. Right now there

00:21:11.837,00:21:17.009
aren’t enough people doing it,
and there aren’t enough people
who know it needs to be done. So

00:21:17.009,00:21:22.014
I want to create a world where
all this is normal, all this is
common. There’s a viable career

00:21:24.416,00:21:29.421
path for a public interest
technologist. And to do that we
need a cultural shift. We need

00:21:34.660,00:21:39.665
all the pieces working together,
and I think we also need to
recognize that what’s in the

00:21:42.268,00:21:46.472
best interest of corporations,
is not necessarily the best
interest for society, and that

00:21:46.472,00:21:51.477
that’s okay. That’s not a
failure of the market, that’s
normal. And it needs to start

00:21:53.612,00:22:00.186
from the top. A lot of public
interest talents came from the 8
years of the Obama

00:22:00.186,00:22:05.191
administration, embracing tech
change and building tech
organizations inside government.

00:22:09.528,00:22:15.000
There’s an interesting parallel
here to public interest law.
I’ll tell a story of public

00:22:15.000,00:22:21.640
interest law, in the 1970’s
there was no such thing, it
didn’t exist. The field was

00:22:21.640,00:22:26.645
created deliberately by an
organizations like The Fort, and
they would fund law clinics,

00:22:29.348,00:22:35.554
Universities, so law students
get a taste of housing law,
discriminiation law, immigration

00:22:35.554,00:22:40.559
law. They funded fellowships at
places like the ACLU, the NAACP.
So the places for these new

00:22:43.195,00:22:48.200
attorneys to go and do this
work. They created a world where
public interest law is a valued

00:22:51.303,00:22:56.308
career. If you tell your parents
you’re doing that, they’re
impressed. Evey partner at a

00:22:58.477,00:23:05.217
major law firm is expected to
have done pro bono work.
Expected to continue to do pro

00:23:05.217,00:23:10.222
bono work throughout their
career. And today, ACLU
advertised a position for a

00:23:12.358,00:23:17.363
staff attorney. It pays between
one-third and one-tenth of what
an attorney would make out in

00:23:20.666,00:23:25.671
the corporate world, and they
get hundreds of applications.
Today, 20 percent of harvard law

00:23:29.475,00:23:35.748
school graduates don’t go to
work for a major law firm for a
major law firm or a major

00:23:35.748,00:23:40.152
corporation, they go to work for
the public interest. And a
couple of years ago, that

00:23:40.152,00:23:45.157
University had a soul searching
seminar, because that percentage
was so low. Number of computer

00:23:47.660,00:23:52.665
science grads from Harvard that
go into public interest?
Probably zero. Not their fault,

00:23:55.234,00:24:00.172
but the ecosystem doesn’t exist.
So more generally, we
technologists need to understand

00:24:04.710,00:24:11.550
the policy ramifications of our
work. This pervasive myth in
Silicon Valley that tech is

00:24:11.550,00:24:16.555
politically neutral- it’s not, I
think we all here know that, but
it is a widely held truth. Our

00:24:19.591,00:24:24.596
work is deeply imbedded in
policy. The things we do affect
the world we live in, and we all

00:24:28.701,00:24:35.307
need to decide what tools we’re
willing to build. Do we build
technologies of surveillance and

00:24:35.307,00:24:40.312
control? Do we build
technologies of liberty and
autonomy? This matters when we

00:24:43.015,00:24:48.020
work on spyware, on censorship,
control tools. Historically we
have created a world where

00:24:52.591,00:24:59.198
programmers had an inherent
right to code the world as they
saw fit. We did that because

00:24:59.198,00:25:04.136
historically it didn’t matter.
Alright, Tech was tools. Now it
does matter. In a lot of ways

00:25:11.477,00:25:16.482
the special privilege needs to
end. Everything we build is a
complex, socio-technical system.

00:25:19.651,00:25:24.656
It is not just a tool. So a
third example: 5g, IOT, big
data. The next disruption in

00:25:27.926,00:25:32.931
technology is going to be about
things and not about people. 5g
is not being built so you can

00:25:35.501,00:25:41.240
watch Netflix faster, it is
being built so things can talk
to other things behind your

00:25:41.240,00:25:46.245
back. The number of things, the
number of the people on the
internet- These will be

00:25:49.048,00:25:54.086
semi-autonomous things, and
they’ll be generating data about
us, and they’ll be using data

00:25:54.086,00:26:00.359
about us. And right now we’re
building that world. And when we
build these systems, we can

00:26:00.359,00:26:07.166
prioritize different aspects of
society. We can prioritize
corporate profits, we can

00:26:07.166,00:26:12.171
prioritize individual autonomy,
we can prioritize privacy, we
can prioritize group benefit of

00:26:15.574,00:26:20.579
information. Government control,
we can prioritize human rights;
All of these are possible. The

00:26:25.451,00:26:30.456
question is which future will we
collectively build? And I like
some of the talk I’m hearing the

00:26:33.826,00:26:39.231
past couple years about the
decentralized internet- the
decentralized web. Movements

00:26:39.231,00:26:44.236
that try to pull back from the
centralized control we’ve seen
sort of since the mid-90’s. And

00:26:47.840,00:26:54.646
as much as deride Blockchain
pretty much every chance I get,
right, the politics of that is

00:26:54.646,00:26:59.651
heartening, cause it’s the
politics of reducing centralized
control. It’s not just that-

00:27:02.888,00:27:07.893
everything we do has a moral
dimension, and we need to engage
in that. And a lot of times it’s

00:27:10.529,00:27:15.534
really hard in security because
so much of what we do is dual
use. The same tool has positive

00:27:18.637,00:27:23.642
and negative effects depending
on who is using it and how it’s
being used, that makes it hard.

00:27:25.677,00:27:30.749
And of course we are not
responsible for every different
use of something we build, but

00:27:30.749,00:27:35.754
we are responsible for the world
we create with the technologies
we build. And we have a

00:27:38.790,00:27:43.795
surprising amount of power. Kind
of as consumers we don’t- a lot
of these things are monopolies,

00:27:48.066,00:27:54.740
a lot of these things are solved
with deep psychological
manipulation. And consumer

00:27:54.740,00:28:01.446
choice doesn’t really work the
way it’s supposed to in an
effective market, but as

00:28:01.446,00:28:06.451
employees we do. Because even if
the big companies don’t have to
compete with each other on

00:28:10.055,00:28:16.662
products, they all have to
compete for our talent. And
we’ve seen this in the past

00:28:16.662,00:28:23.602
couple of years as employees
taking a stand against what
their companies are doing, and I

00:28:23.602,00:28:28.607
assure you this terrifies
companies. Google has already
has problems recruiting enough

00:28:31.476,00:28:37.749
people. Ten percent walk out,
it’s a fricken disaster.
Employees demand that they don’t

00:28:37.749,00:28:42.754
work on something- they don’t
work on it. And law and policy
have to work together. Either

00:28:46.825,00:28:49.695
they work together or they don’t
work at all. And I think
actually this is the fundamental

00:28:49.695,00:28:54.700
lesson of Edward Snowden. We all
knew that we could build tech to
subvert policy. He showed us you

00:28:57.269,00:29:02.207
can build policy to subvert
tech. And if they’re not working
together, they’re failing. Again

00:29:04.943,00:29:09.948
this is bigger than computer
security. Nearly all the major
policy debates of this century,

00:29:12.718,00:29:17.723
will have a strong tech
component. Robotics, climate
change, food safety, drones, AI,

00:29:20.726,00:29:25.731
bio-engineering. These have deep
tech components, and there are
places that we as hackers can

00:29:30.435,00:29:35.440
get involved. And I actually
think this is where the core
issues of society lie. So the

00:29:37.776,00:29:42.781
20th century, the question that
organized society was basically
this: How much of our lives

00:29:47.019,00:29:52.424
should be governed by the state
and how much of our lives should
be governed by the market?

00:29:52.424,00:29:57.429
That’s the Cold War in a sense.
That’s most countries politics
in a sense. The defining

00:30:02.467,00:30:06.538
question of this century, at
least the first half of this
century, I think will look like

00:30:06.538,00:30:13.512
this: How much of our lives
should be governed by technology
and under what terms? Now the

00:30:13.512,00:30:18.517
20th century, the question was
really an economic one, and
that’s why economists basically

00:30:22.320,00:30:27.325
were the ones who made public
policy. This century’s question
is technological, and we are the

00:30:32.864,00:30:37.869
people who need to make policy.
So this future is coming. I
think it’s coming faster than we

00:30:42.441,00:30:47.212
think. I think it’s coming
faster than our policy tools-
today’s politics can deal with.

00:30:47.212,00:30:52.217
I think the only way to fix this
is to develop a new set of
policy tools that work for the

00:30:56.722,00:31:03.462
environment we live in. And we
need technologists in all
aspects of public policy, all

00:31:03.462,00:31:09.968
aspects of public interest work.
Informing policy, creating tools
and building the future. And you

00:31:09.968,00:31:14.973
know this field. We do not need
permission to do this. Our ethos
is that we can do this without

00:31:19.978,00:31:26.752
permission. When you hack a
public system and make that
information available, that is

00:31:26.752,00:31:33.725
public interest work. When you
build tools of security and
tools to counter surveillance,

00:31:33.725,00:31:38.730
that is public interest work.
When you decide the world you
want to live in is not the world

00:31:40.999,00:31:46.838
you’re living in and you move to
create that world, that’s public
interest work. We need it, we

00:31:46.838,00:31:51.843
need more of it and need your
help. Thank you. [audience
clapping] Alright, so I left a

00:32:02.754,00:32:06.792
bunch of time for questions. I
see people are escaping through
the correct door. You all listen

00:32:06.792,00:32:12.297
the uhh, listened to the
announcement. There’s no
microphone, so you either have

00:32:12.297,00:32:17.302
to walk to the front or be loud.
Yes [points to member of
audience] >>Umm I was wondering

00:32:20.238,00:32:26.011
if [incoherent] borders internet
os >>Uhh- The uhh open borders
internet? Yes so the question’s

00:32:26.011,00:32:31.016
about internet uh uh- not
bifurcation- balkanization. I
don’t know- I see three- split

00:32:34.886,00:32:39.925
three different ways, we’ll see
how it lasts. Uhh sort of U.S.
centric, Europe centric and

00:32:39.925,00:32:44.930
China centric. And right now
that’s a split on the way policy
works, and it’s- I don’t know if

00:32:47.299,00:32:52.637
it’ll turn into hard splits-
China is doing a hard split
within its own country, but

00:32:52.637,00:32:58.176
we’ll see. It really depends on
how incompantible the laws are
and how much the different

00:32:58.176,00:33:04.883
spheres don’t want each other
in. I do worry about it, I think
it is not a big worry right now,

00:33:04.883,00:33:09.454
but easily can turn into a big
worry because it’s based on
perception of policy. You can

00:33:09.454,00:33:13.992
imagine Europe saying, Facebook
you’re no longer welcome. You’re
not following our laws, we’re

00:33:13.992,00:33:19.898
just done with you. And that
would be a big deal, but it
certainly could happen. Is there

00:33:19.898,00:33:25.604
a question further up? Yes
[points to member of audience]
>>So what do you think about

00:33:25.604,00:33:28.306
government involvement in
election security? >>Question
about Government involvement

00:33:28.306,00:33:35.213
election security- I mean U.S.
is very unique in that we don’t
have a professional election

00:33:35.213,00:33:41.686
organization that many other
countries do. Uhh it is because
of the way the U.S. is

00:33:41.686,00:33:46.424
organized, we don’t have one
election, we have 52 separate
elections that are autonomous.

00:33:46.424,00:33:51.429
Uhh that was great in the mid
1800’s, great idea, I think it’s
like less good today because,

00:33:54.633,00:34:00.472
again right, Russia vs. North
Carolina is not a fair fight
[audience laughs] but there’s a

00:34:00.472,00:34:06.444
lot of politics in the way of
free and fair elections in the
United States right. This isn’t

00:34:06.444,00:34:12.784
a debate you can have purely
technically, although it would
be nice if we could. And that

00:34:12.784,00:34:16.154
is- that is the problem. Other
countries I think we are doing
better because they can

00:34:16.154,00:34:21.159
nationalize it. Because they can
bring nation level defenses in a
way, I mean, that you can’t in

00:34:23.528,00:34:29.134
the United States. So, I think
our uniqueness makes that
harder, and this is very much a

00:34:29.134,00:34:34.139
political issue. Alright because
after an election the winning
side wants the results to stand

00:34:36.541,00:34:42.714
no matter what happens. So you
need a professional class that
have been charged with fairness

00:34:42.714,00:34:47.719
and not outcome, and we don’t
have that, not sure we’ll get
that. I saw a hand there, and

00:34:50.055,00:34:54.192
then I’ll go this way. >>Um with
the rise of totalitarianism and
[incoherent] politics globally

00:34:54.192,00:34:59.197
time has come for us to build
the tools to do the right thing
basically. What are some of the

00:35:01.967,00:35:06.972
suggestions that we can do in
order to build that tools in
order to >>So I think abuse is

00:35:09.007,00:35:14.746
hard because a lot of tools can
be abused. A lot of it’s having
the right people in the room

00:35:14.746,00:35:19.884
when you’re building them. We’ve
built them as tools where
they’re techy, and us techy’s

00:35:19.884,00:35:24.889
just create them. You need the
people using them- you need the
different groups understanding

00:35:26.891,00:35:31.896
how uhh an affected disempowered
group is using a tool makes a
huge difference. And I think you

00:35:36.468,00:35:42.774
know even big things, the right
people aren’t in the room early
enough to understand it. I don’t

00:35:42.774,00:35:48.413
know the answers, but I think we
have to learn how to ask the
questions at a point where we

00:35:48.413,00:35:54.619
can make the design trade-offs
and not when it’s too late. So
that’s really what I want right

00:35:54.619,00:36:00.291
now. That these- think of these
as complex social-integral
systems from the beginning, and

00:36:00.291,00:36:05.563
getting the sociologists in the
room, getting the activists in
the room, getting the users in

00:36:05.563,00:36:10.568
the room, getting the soft
science people with the
programmers at the beginning.

00:36:12.871,00:36:18.543
Uhh Google invented a job
classification a few years ago
called staff attorney. The idea

00:36:18.543,00:36:23.381
was- a really good idea, that
what they build is going to have
legal implications down the

00:36:23.381,00:36:27.552
road, wouldn’t it be great to
have an attorney on staff at the
beginning of the design? Now

00:36:27.552,00:36:34.559
they do that. Let’s do that for
uhh public interest as well.
Right, get- and I think some

00:36:34.559,00:36:40.999
companies are doing that, we
just need it to be part of our
ethos. Saw a hand down there-

00:36:40.999,00:36:46.004
yes. >>Um two lame questions
>>You only get one. [laughter]
>>Okay, Um I protect against the

00:36:49.207,00:36:55.513
activists who actually become
these um [inaudible]
technologists [inaudible] >>You

00:36:55.513,00:37:01.019
know, I think the problem of
activists getting so powerful
and pushing their agendas is far

00:37:01.019,00:37:05.323
from reality, I’m totally not
worried about it [audience
laughs]. I’m way more worried

00:37:05.323,00:37:09.727
about the money pushing their
agenda. I mean, if the
disempowered get a little more

00:37:09.727,00:37:14.732
powerful, I think we’ll do good.
I’m not really worried about
that, we’ve got a long way to go

00:37:17.736,00:37:22.741
before marginal agendas are at
the top. Alright I’m gonna go
down there. >>As someone who

00:37:27.145,00:37:31.616
works in public policy I really
want to encourage people to
[inaudible] freaking regulation

00:37:31.616,00:37:38.456
>>Comment on fricken regulations
is a huge issue. And by comment
we don’t mean, “write a bot that

00:37:38.456,00:37:44.095
sends a million other comments”
[audience laughs]. Cause we’re
kind of on to you for that and

00:37:44.095,00:37:50.435
that like messes up the whole
process, but yes more tech
comments on regulatory matters

00:37:50.435,00:37:55.440
is really useful. That did a lot
of good in the uhh- in the uhh
open-open internet debate. Why

00:37:57.775,00:38:02.714
am I blanking on the term of it?
Not SOPA PIPA but after that the
uhh oh the- the uhh FCC wanting

00:38:06.551,00:38:11.556
to-to allow companies to
throttle. Net neutrality,
alright it’s early, yes. I mean

00:38:13.858,00:38:18.863
the public comment made a huge
effect in that, we think they
don’t matter, they do. Uhh I see

00:38:21.166,00:38:26.171
a hand over there. >>the arms
race is [inaudible] the
government wants a uh p escrow

00:38:36.915,00:38:41.920
[inaudible] secure it but I’m
guessing [inaudible] >>Questions
about arms racing and cash go

00:38:44.455,00:38:49.761
and where they end and the
answer is we don’t know. I mean
a lot of our debate on

00:38:49.761,00:38:55.133
insecurity of backdoors is
undercut by the fact that
corporations backdoor their

00:38:55.133,00:39:01.005
stuff all the time for corporate
reasons. I mean, it’s hard to
argue that look, you must make

00:39:01.005,00:39:06.010
iMessage secure, or, bad things
will happen, when your email is
all escroed by whatever service

00:39:09.347,00:39:14.352
provider you have. Now my belief
is sort of in the long game,
these systems become so critical

00:39:17.689,00:39:24.562
for society that there’s no
choice but to make them secure.
That defense wins, offense

00:39:24.562,00:39:29.901
loses, because defense becomes
much more important. Now there’s
a lot of short term between here

00:39:29.901,00:39:34.906
and there, but I think once the
internet starts killing people,
all these debates change. And

00:39:38.576,00:39:41.846
this was the subject of -
actually I’ll hold up my latest
book which you might be able to

00:39:41.846,00:39:47.785
see in the front row - which has
the wonderful title of “Click
Here to Kill Everybody”

00:39:47.785,00:39:52.190
[audience laughs] where I talk
about the world of physically
capable computers and how that

00:39:52.190,00:39:57.195
changes the debate. I think that
changes the key-escrow debate at
an enormous degree. But short

00:40:00.865,00:40:06.137
term, mean we just recently
heard that the FBI can’t get
into the phone of one of the two

00:40:06.137,00:40:11.142
mass shooters a couple of weeks
ago. That’s going to become a
talking point. Now why do we

00:40:13.745,00:40:17.482
need to get into his phone? The
question of digital forensics is
a much bigger question, and one

00:40:17.482,00:40:24.322
that I think we also could help.
The reason the FBI wants into
your phone is cause they don’t

00:40:24.322,00:40:30.361
know how to do anything else,
and getting them better at
actual forensics- cause we know

00:40:30.361,00:40:35.033
it’s the golden ages of
surveillance, we know a lot of
datas’ out there, we know that

00:40:35.033,00:40:40.338
you can do an enormous amount if
you can’t get into the phone or
get into WhatsApp. But that

00:40:40.338,00:40:47.178
data, that information is not
being transmitted to the FBI.
Part of public interest tech is

00:40:47.178,00:40:52.183
going to work for the justice
department and making them
smarter on fighting digital

00:40:52.183,00:40:57.188
crime. Right, take one more
question. Oh way in the side.
>>Uhh the micro [inaudible

00:41:23.948,00:41:27.852
audience question] >>You know,
so there’s a lot of danger for
us like parachuting in and

00:41:27.852,00:41:32.957
helping other industries. That
almost never works out well,
even if we do it like for

00:41:32.957,00:41:37.261
corporate ways or for public
interest ways. Uhh If you want
to help, there’s an issue you

00:41:37.261,00:41:42.567
care about, find an organization
that is doing that and ask them
what they need. Ask them how you

00:41:42.567,00:41:48.506
help. And it might be our
computers aren’t, you know our
neck keeps coming down. And it

00:41:48.506,00:41:54.812
might be we need this tool that
we can use or, it might be we
need data analysis expertise.

00:41:54.812,00:42:01.419
The people doing the work know
what they need. If you want to
help whatever the issue is, find

00:42:01.419,00:42:06.424
those people, ask them. Alright
I’mma get off stage. I have one
more thing to say, I do uhh I

00:42:08.826,00:42:15.666
keep uhh a webpage with public
interest tech public interest
tech with the hyphens dot com.

00:42:15.666,00:42:19.704
It has a whole list of
resources: organizations,
documents, talks, people doing

00:42:19.704,00:42:25.610
this. Uhh I will be around to
uhh say hi to people afterwards,
I have to get off stage, I can’t

00:42:25.610,00:42:30.581
stay here. So I’m going to go
out that door which is totally
illegal don’t you do it. I’ll go

00:42:30.581,00:42:36.220
around and I’ll meet you all at
the back there, and then we can
chat later. Thank you for

00:42:36.220,00:42:40.358
coming, enjoy your DefCon. I’ve
been coming since I think Defcon
4 [audience claps] and it’s

00:42:40.358,00:42:45.363
really always neat to be here
and thank you again. [applause]

