00:00:00.200,00:00:04.938
>>So it’s 9 and we starting on
time, which is, it feels just
wrong [panel laughs] why are we

00:00:04.938,00:00:09.943
starting on time, this is, this
is Defcon. Oh no [panel laughs]
I do this to please proctor.

00:00:13.180,00:00:18.785
umm, so we’ve got a number of
people on the panel here, uh I
will introduce to you briefly,

00:00:18.785,00:00:22.155
they’ll get plenty of
opportunity to talk, umm, and
then I wanna give you a little

00:00:22.155,00:00:27.160
background and then we’re going
to, take off. So err, on the far
end of the table we have, umm we

00:00:29.930,00:00:34.935
have Corbin Souffrant from
Leviathan Security and then
we’ve got Jennifer Granick umm,

00:00:37.037,00:00:43.877
from the ACLU umm super-hero to
hackers around the world. Err,
we’ve got, who’s next, Runa

00:00:43.877,00:00:48.882
Sandvik from the New York times,
we’ve got Pablo Bower from the,
>>Bruwer >>Oh, Bruwer I’m sorry

00:00:51.585,00:00:56.256
you know it’s funny, I have only
read your name, never actually
said your last name, umm, from

00:00:56.256,00:01:01.194
the, Donovan group. Mark Rodgers
A.K.A cyber junkie. Umm and then
Chris Cribbs from uh Sisa. Ok

00:01:06.033,00:01:11.038
so, why are we here, umm. We
want Defcon uh Is about building
a community and I’m always

00:01:15.575,00:01:20.580
looking for another opportunity,
to either build bridges or build
relationships, or solve problems

00:01:23.150,00:01:28.989
just like we started Defcon in
China to build bridges umm with
hackers in China because they’re

00:01:28.989,00:01:33.994
just like us, try to hack sh*t,
but umm, the relationship
between researchers wanting to

00:01:37.464,00:01:42.536
report vulnerabilities to save
the government is very strange
because there’s a lot of

00:01:42.536,00:01:49.176
apprehension. So is there a way
to create a process, for people
to report vulnerabilities,

00:01:49.176,00:01:54.181
hackers, researchers, to report
vulnerabilities into the cert,
of a, a U.S cert, to help do

00:01:57.584,00:02:01.989
some good, now if you wanted to
make money, there’s a 1000000
ways for molentize

00:02:01.989,00:02:06.460
vulnerability, if you want to
get recognition you compete in
bug bounties, you get your name

00:02:06.460,00:02:13.033
attached to bug reports you
know. This is sort of a edge
case, umm and we don’t know big

00:02:13.033,00:02:17.371
the edge case is, we don’t how
critical it is, we don’t know
how many people are with

00:02:17.371,00:02:22.409
holding, not reporting, or maybe
monetizing because they have no
other avenues to report, or do

00:02:22.409,00:02:27.647
the right thing, but it’s
interesting enough that we want
to find out umm, if there is a

00:02:27.647,00:02:30.717
way for Defcon to act as a
facilitator an immeditary
between people trying to report

00:02:30.717,00:02:33.787
anonymously and then uh U.S
cert. And to explain how defcon
even got into this conversation,

00:02:33.787,00:02:38.792
I want to first send it over to
Pablio and uh and Mark a little
bit, so maybe just give us a

00:02:46.099,00:02:51.638
quick history of why, how we got
here?, why Defcon? >>Yeah,
thanks Jeffery, so err, we-we

00:02:51.638,00:02:53.640
all have different lives, we got
personal lives, we got >>oh move
in closer to the mic >>oh, we

00:02:53.640,00:02:59.379
got different lives, we got
personal lives, we got
professional lives and uh I have

00:02:59.379,00:03:05.686
been fortunate enough to be
involved uh as an attendee in
Defcon since Defcon 4, so it’s

00:03:05.686,00:03:10.691
been a big part of my life, ummm
and >>whooo >>yeah errr and err,
because I have in the community

00:03:14.461,00:03:18.598
for a while people in the
community will occasionally
reach out and say like, hey look

00:03:18.598,00:03:23.703
I-I notice this thing and I
don’t want to explain how I
notice this thing or umm I’m

00:03:23.703,00:03:28.175
afraid of the repercussions, but
somebody should do something
about that, uh and that’s great

00:03:28.175,00:03:32.279
and that’s wonderful but they,
>>and that that’s because they
knew you weren’t concealing that

00:03:32.279,00:03:35.982
you were involved with the
government >>No no I am not
concealing I’m I’m a active duty

00:03:35.982,00:03:42.222
navy officer I was young, I
needed the money umm [ audience
laughs] umm, but because I’ve

00:03:42.222,00:03:46.660
been in the community for a
while an- and and I’ve got
friends in community trust and

00:03:46.660,00:03:51.665
so uh myself and umm my partner
at the Gotadam group uh JK Snow
uh we got to thinking you know,

00:03:53.900,00:03:58.405
we could we could do something
about this, we can have long
term impact and so we called on

00:03:58.405,00:04:05.078
Mark, who kindly volunteered his
time for about 2 years to come
down and help us, kind of scope

00:04:05.078,00:04:10.083
how this could happen. How could
we link the hacker community to
a national surrances what kind

00:04:12.786,00:04:17.591
of assurances would the hacker
community need, how would that
tactical implementations happen

00:04:17.591,00:04:23.663
and what projects exists that we
could leverage, by the way
theres and open source thing we

00:04:23.663,00:04:28.668
could contribute to which is a
show of good faith and so, what
do you wan, >>So, So then Mark

00:04:31.338,00:04:35.942
gets a call >>So then mark gets
down [panel laughs] >>Narrative
voice >>So hopefully most you

00:04:35.942,00:04:40.947
know me, umm I am a hacker and I
have been hacking all my life, I
consider this community my

00:04:43.250,00:04:49.556
family, umm, so when Pablo
reached out and said this is
what we want to build, I

00:04:49.556,00:04:53.927
immediately had some, some
concerns about how could we do
something like this,this is

00:04:53.927,00:04:57.464
really an interesting and
challenging problem, and if
there is 1 thing that hackers

00:04:57.464,00:05:04.371
like, that is charging problems,
umm plus uh they give you access
to a really sweet hackers space

00:05:04.371,00:05:09.676
that has lots of toys to play
with. And so uh it was a
pleasure to kind of a to come

00:05:09.676,00:05:15.549
down and play with the toys and
help do this. But we set about
to kind of work out yer, what is

00:05:15.549,00:05:22.055
the safe way we can do this, and
the most critical thing is, how
can we foster trust in this,

00:05:22.055,00:05:27.060
because even just thinking from
my perspective, eh how can I
trust, a process to disclose

00:05:30.263,00:05:36.836
something to a government
entity, without there being any
potential repercussions for me,

00:05:36.836,00:05:41.841
if I wanted to insure a problem
solved and so we looked at
architecting the solution and I

00:05:44.511,00:05:49.249
have to say there are still
many, many open questions and
that’s when the reasons why,

00:05:49.249,00:05:54.254
like we hope you guys can feed
into this, because I think the
only way this works is if the

00:05:56.489,00:06:01.428
community is behind it. And the
community helps shape it. >>So
then uh we suppose to be

00:06:04.064,00:06:09.669
announced last year, uh so here
we are a year later. Umm
timelines things you know, got

00:06:09.669,00:06:15.675
complicated. But uhmm but then
all of sudden things started
moving really quickly, umm ,

00:06:15.675,00:06:21.348
although there was some
technology explored and audited
umm, and so now it’s starting to

00:06:21.348,00:06:26.319
becom- become real and so now
I’m getting more and more
involved and it’s like OK well

00:06:26.319,00:06:31.925
where would the data go, who is
going to get these reports?
Because there is concern power

00:06:31.925,00:06:35.428
to talk about, there is concern
that if it goes to the wrong
agency they going to sit on the

00:06:35.428,00:06:41.568
data, they going to recognize
the data, they going to hold it
from other agencies or industry

00:06:41.568,00:06:47.407
or manufacturer or whatever. So,
umm in my mind it’s pretty much
why we, there needs to a

00:06:47.407,00:06:52.646
civilian organisation can’t be a
military organisation that gets
these reports, right and who is

00:06:52.646,00:06:57.217
historically gotten these
reports that would be U S cert.
Umm sss and I have good

00:06:57.217,00:07:03.790
relations, uh I know a bit of
the berdomic inside of DHS and
ugh it just made sense, umm that

00:07:03.790,00:07:08.795
it would be umm a civilian
partner. Well, umm, the other
question is well if you know the

00:07:14.000,00:07:18.104
government, the right hand, left
hand problem,I-I asked Pablo
what’s my biggest risk, like

00:07:18.104,00:07:23.076
Defcon, what do you see the
biggest risks to Defcon for
doing this, and I don’t know if

00:07:23.076,00:07:28.081
you want to tell that story
>>Yeah so umm, I had a lot of
very interesting conversations,

00:07:28.081,00:07:32.018
so as a government person I am
calling, calling Defcon and
going hey listen I want to work

00:07:32.018,00:07:37.757
with you, you kind of get the
side eye a little bit, so, so
Jeff asks uh you know what is

00:07:37.757,00:07:42.729
what is the concern, I said,
well Jeff yer here is my biggest
concern, umm th- the 2 biggest

00:07:42.729,00:07:49.202
concerns I see from, the hacker
community is that we as the
government mess this up and burn

00:07:49.202,00:07:55.775
the bridge again, for Defcon the
biggest concern is you got tips
from some of the hard, some of

00:07:55.775,00:07:59.779
the smartest hackers on the
planet and this is going to
become the best target ever for

00:07:59.779,00:08:06.019
possibly for foreign nation
stakes. Umm and so it- it is
something done with significant

00:08:06.019,00:08:11.024
risk, umm but, hopefully in-in
good spirits, umm and Jeff was-
was kind enough to go well Iet

00:08:14.761,00:08:20.166
me talk to my folks and let’s
get together and tell me the
story and uh take back. >>So I

00:08:20.166,00:08:25.171
immediately called Jeff a panic
[panel laughs] I’m like ok
lawyer [panel laughs] what am I

00:08:28.541,00:08:35.081
getting myself into if umm what
are the risks here umm and
Jennifer’s been on uh the

00:08:35.081,00:08:40.086
defence side uh forever, mostly
your whole career << Defcon 3 we
met << Over microphone,

00:08:42.422,00:08:47.193
microphone >>Oh sorry [speaker
laughs] I think you and I met
Defcon 3 >>Yeah 2 or 3 it was

00:08:47.193,00:08:52.699
really early 1’s >>Yeah >>Umm
and so I called you up and
explained this is kind of what

00:08:52.699,00:08:57.871
we want to do, what are the
risks, do we have to build a
whole new data centres and new

00:08:57.871,00:09:02.609
location in case there is a
search warrant and they take my
web server by accident [

00:09:02.609,00:09:06.279
laughing] you know like how does
it work, so Jennifer was
stepping me a little bit through

00:09:06.279,00:09:11.451
the legal concerns >>Yeah I-I
mean so you-you first have the
legal concerns for the people

00:09:11.451,00:09:15.755
who are the reporters which is
you know the vulnerability
finders, the reporters who are

00:09:15.755,00:09:21.594
usually the people that I worked
with in the past. But so,
put-put that side of umm people

00:09:21.594,00:09:26.766
aside for a second and think
about what are the legal risks
potentially for Defcon and I

00:09:26.766,00:09:32.238
think there are, umm you know
sort of the subsistence problem
of what information is going to

00:09:32.238,00:09:37.677
be on the server and then umm
the kind of procedural legal
problem, what happens if

00:09:37.677,00:09:43.116
somebody shows up with a
subpoena or search warrant and
wants this information . And so

00:09:43.116,00:09:47.787
to some extent you know, you
think about air gapping your
machines to make sure that if

00:09:47.787,00:09:53.693
something does happen to it and
it’s taken or taken down that
you know the rest of the umm,

00:09:53.693,00:09:59.499
the rest of the stuff is still
available and it still happens,
you know can still proceed umm,

00:09:59.499,00:10:05.605
that you don’t loose the
entirety of Defcon functionality
if the box is taken. And then

00:10:05.605,00:10:11.611
obviously the technological
concerns about, if it is taken,
if somebody does cease it, umm

00:10:11.611,00:10:16.749
making sure that, you know they
not going to be able to see
anything, umm without any

00:10:16.749,00:10:22.288
opportunity for us to uh to get
into court and challenge it. Umm
but I think you know 1 of the

00:10:22.288,00:10:26.960
problems is that uh search
warrants authority goes from you
know people in the smallest

00:10:26.960,00:10:31.698
towns or police officers in the
smallest towns in umm in America
all the way through to uh

00:10:31.698,00:10:36.336
international organisations,
until you meet- with you know
varying levels of sophistication

00:10:36.336,00:10:41.141
and understanding of the, the
goals of the umm,
vulnerabilities of disclosure

00:10:41.141,00:10:46.880
and of how the legal procedure
ought to work. So you got to be
ready for umm, responses from

00:10:46.880,00:10:51.518
all those, those sets of people
and I think of the substance
problem which is what kind of

00:10:51.518,00:10:57.190
information might people put on
this particular box, and you
know it’s going to be, umm, a

00:10:57.190,00:11:02.595
chile, you know a vulnerability
information, it’s going to be
very attractive as uh as target

00:11:02.595,00:11:07.300
there could be, you know people
giving, you know s-sort of
information about their

00:11:07.300,00:11:12.171
co-workers. I think so and so is
a spy or something like that is
that defamation you know, we

00:11:12.171,00:11:16.042
give that to the government
what’s the issue there, and then
of cause, 1 of the things that,

00:11:16.042,00:11:21.748
that as a privacy lawyers is
that uh we see a lot is hydro
ban information. uh usually

00:11:21.748,00:11:25.852
child pornagraphy, so you to be
careful and have a process in
place for how you going to deal

00:11:25.852,00:11:29.656
with, if you going to see the
information. How you going to
deal with all of that. And umm,

00:11:29.656,00:11:35.028
really in some ways, you know
the best situation is 1 where
the imtermadiatry, umm who

00:11:35.028,00:11:41.734
secures the box and keeps it up
and running.and you know, is
responsive to the community amd

00:11:41.734,00:11:47.507
give the information an uh
doesn’t have the ability to see
any information on the box at

00:11:47.507,00:11:53.613
all. That’s the that’s the, the
best way to, to umm, to protect
everyone, I think >>And you

00:11:53.613,00:11:58.251
engineer yourself out of the
problem >>Absolutely >>Yeah, umm
so I want to to get to Chris,

00:11:58.251,00:12:04.457
but I first want to go to, to
Runa, umm, whose err, I-I’m not
I don’t know who is responsible

00:12:04.457,00:12:09.462
but highly involved in umm
operating, umm the New York
times. >>Yeah so >>Yeah and

00:12:12.065,00:12:16.502
maybe the parallels between this
problem and what you face.
>>Sure so uh I am the senior

00:12:16.502,00:12:20.340
director of information security
at the times, I have been there
for about 3 and a half years

00:12:20.340,00:12:25.578
>>Go closer to the microphone
>>Umm and before then, I worked
for freedom of the press, umm,

00:12:25.578,00:12:31.718
consulting different media
world, help set up and support,
umm secure drop umm which is a

00:12:31.718,00:12:36.723
system which allows people to
anonymously submit tips to, umm,
anyone hosting the instance, in

00:12:39.158,00:12:44.163
this case, it’s the New York
Times, Umm, so back in 2016, we
found that there was, there was

00:12:48.534,00:12:53.539
no way for, a source to contact
the New York Times, the newsroom
full stop. It was a case where

00:12:57.543,00:13:02.749
sources had to build
relationships with reporters and
establish that sort of level of

00:13:02.749,00:13:07.754
trust and err, agree on a method
of comps before they could umm
communicate or before the source

00:13:11.457,00:13:17.230
would be comfortable sharing
info, umm, so we then set up our
tips channel, which has signal

00:13:17.230,00:13:22.802
and whatsapp and secure grab and
a couple of other options, to
allow anyone really to send

00:13:22.802,00:13:27.807
anything to the New York Times.
And so we then developed a
process internally for who is

00:13:30.610,00:13:35.748
going to check the submissions,
what do they do with the valid
submissions, they things we

00:13:35.748,00:13:41.954
consider a legitimate tips. How
do we safely share them with the
rest of the newsroom, what do we

00:13:41.954,00:13:48.061
do when we get info that isn’t a
tip. What do we do when we get
information that really should

00:13:48.061,00:13:53.066
be, sitting with law enforcement
in some cases, umm. And we
really built that out and

00:13:55.535,00:14:01.774
running, really successfully now
for about 3 years umm, and
before that I think back in,

00:14:01.774,00:14:06.779
when was it 2015 the tail centre
for digital journalism did a
survey of I think a dozen media

00:14:09.248,00:14:14.420
works with secure grab to sort
of answer the question of is
this system actually helpful,

00:14:14.420,00:14:21.327
are you getting legitimate tips
are you getting valuable data
from having this system. Umm and

00:14:21.327,00:14:27.333
I think back then everyone said,
yes. There was sort of this,
yes, but I am also getting a lot

00:14:27.333,00:14:33.606
of crap, and I think it was
gottum that said that we
actually get, far more just crap

00:14:33.606,00:14:38.778
in memes in images that we don’t
want to see, but having this
system is far more, like the

00:14:38.778,00:14:43.783
value that we get from it does
outweigh getting all that crap
in the first place. >>So umm,

00:14:46.719,00:14:52.091
so, then after talking with
everyone I-I was thinking, Ok
there is something here, there’s

00:14:52.091,00:14:56.529
probably a benefit to the
community, the risks can
probably be engineered out, or

00:14:56.529,00:15:02.735
managed. Now we need to talk
with, who can be a possible
partner and I think that’s when

00:15:02.735,00:15:08.174
the conversation started with
err, with Serwen and Enkit and
err, and so, uh I want to

00:15:08.174,00:15:12.979
introduce umm Chris Cribbs who
is going to talk about it from
the other perspective. Having

00:15:12.979,00:15:18.184
this sort of blab >>So can we be
interactive here >>we can, yes
>>Alright let me ask a question

00:15:18.184,00:15:24.090
here, with a show of hands, has
anybody heard or know what Sisa
is, those who work for me, don’t

00:15:24.090,00:15:30.596
count, umm, alright US cert?
Show of hands, alright better,
so US cert is Sisa. SISA is the

00:15:30.596,00:15:34.767
cybersecurity infrastructure of
security agency, we like
security so much that it’s in

00:15:34.767,00:15:41.307
our name twice [speaker laughs]
umm so we, uh are new by law as
of last November, umm, created

00:15:41.307,00:15:47.346
out of a portion of contrame
homeland security set up as an
operational agency on the level

00:15:47.346,00:15:53.352
of err, other agencies. Umm but
we are uh the advocate within
the government for the

00:15:53.352,00:15:59.192
researcher community, the
private sector, you know, kind
of team internet. uh we have

00:15:59.192,00:16:05.164
managed vulnerability reporting
processing for years now. Umm
through the US cert portal,so

00:16:05.164,00:16:09.468
first, first kind of first
principal though is always you
know our preferences, the the

00:16:09.468,00:16:14.774
vulnerabilities are disclosed to
the vendor. Understanding that
doesn’t always work, the

00:16:14.774,00:16:20.613
communities not mature enough,
necessarily across the board not
you guys, but the vendors. uh so

00:16:20.613,00:16:26.152
that leaves the back stop so US
cert has the capability for
reporting vulnerabilities, uh on

00:16:26.152,00:16:30.923
the IT’s side we’ve contracted
with the federal funded research
and development centre at uh

00:16:30.923,00:16:35.895
Columentral university the
software engineering institute,
they run the seaark CC process,

00:16:35.895,00:16:41.200
so you go there uh you enter all
the information, it’s anonymous
uh as far as I know it’s never

00:16:41.200,00:16:46.772
had a bridge or spillage or any
sort of disclosure. I think this
year through June at least,

00:16:46.772,00:16:52.712
we’ve already managed triogued
almost 8000 vulnerabilities, umm
so we think we have a process

00:16:52.712,00:16:58.184
that works. Now the challenge
here is that I’ve got a
numerator. I don’t have a

00:16:58.184,00:17:04.257
dominator. I don’t know what the
potential for vulnerability
recording there are still

00:17:04.257,00:17:09.061
clearly through this
conversation or at least very
much potentially through this

00:17:09.061,00:17:15.535
conversation some that still,err
have reluctance to engage with
the government on to have these

00:17:15.535,00:17:21.107
issues addressed, directly with
the government and there needs
to be some sort of err, arbrat,

00:17:21.107,00:17:26.112
uh arbiter. So, you know what we
thinking and what Jeff mentioned
upfront, is er what is the edge

00:17:28.214,00:17:34.687
cases out there, what are the
impediments or challenges that
the community sees err, in terms

00:17:34.687,00:17:39.592
of reporting through the
standard process again w-we
think this is successful maybe

00:17:39.592,00:17:44.196
I’m throwing a random number
round 95 percent solution, what
does it take to get that 5

00:17:44.196,00:17:48.234
percent. What are the
concerns,how do we do this in a
way, you know, we talk about

00:17:48.234,00:17:54.073
risks, umm, yes this could be
targeted by foreign intelligence
services, but it could also be

00:17:54.073,00:17:58.511
other things put in through the
process you know, I think about
the, the junk, the memes, the,

00:17:58.511,00:18:02.848
err, other sort of collateral
that could come through this
process. W-we don’t necessarily

00:18:02.848,00:18:07.853
want to work with, so what I’m
interested in is figuring out, A
what are those kind of edge

00:18:07.853,00:18:14.226
cases or th- the the, maybe the
best way to put it, is you know,
we can’t take an approach where

00:18:14.226,00:18:18.965
I’m from government and I’m here
to help. We’ve got the answer
for you, I need to have more of

00:18:18.965,00:18:24.870
a customer service mindset, so
we think we have a product, if
it’s not answering the, the 99

00:18:24.870,00:18:30.710
point 9 percent of the problem
set, what do we do to get over
that final hump, and so this I

00:18:30.710,00:18:36.649
think secured drop is a, is a
conversation that is useful in
terms of closing out the top

00:18:36.649,00:18:43.189
end, those more, potentially
highly valuable vulnerabilities,
but how do we get there, how do

00:18:43.189,00:18:47.693
we do it in, in a way that both
manages the engineering piece,
but also some of the

00:18:47.693,00:18:54.166
administrative infrastructures
stuff from my side, the people
side, umm so , kind of top of

00:18:54.166,00:19:00.106
mine at least for now so >>Ok
so,umm, so I think maybe Pablo
you ought to mention that, umm,

00:19:00.106,00:19:06.479
some of that sweet government
money was spent on an audit.
>>yeah so, err, we-we did the

00:19:06.479,00:19:10.683
initial meetings we started
taking looks at existing
architectures, umm we found the

00:19:10.683,00:19:16.589
freedom of the press secure
drop, it was open source, it had
been tested, uh it had been in

00:19:16.589,00:19:22.261
use err, and so we were able to
convince some government
partners to, err, fund a code

00:19:22.261,00:19:28.634
review. Umm we wanted to be very
transparent about this, uh we
reached out to freedom of the

00:19:28.634,00:19:33.906
press uh who-who co-cautiously
and nervously took my call
initially uh until we were, uh

00:19:33.906,00:19:38.511
th they were sure we were
transparent and we uh we got
linked up with their def group,

00:19:38.511,00:19:45.051
umm we paid for a code review
that we uh asked Leviathan
security to do, uh we shared the

00:19:45.051,00:19:50.089
report with err, with freedom of
the press of the def group, and
said here are the things we

00:19:50.089,00:19:55.094
found, here’s how much money we
have to contribute to def fixes,
what would be your priorities?

00:19:57.196,00:20:03.335
And so between Leviathan and the
freedom of the press development
group, umm, they set out the

00:20:03.335,00:20:06.605
priorities they filled us in on
some improvements they got
coming, err, that they hadn’t

00:20:06.605,00:20:12.411
announced yet, so they said
don’t fix those, we already got
fixes for those. Umm we’ll take

00:20:12.411,00:20:18.918
the other fixes uh so Leviathan
went through, uh and worked
right through the github and uh

00:20:18.918,00:20:25.858
all of the fixes were submitted
and have been accepted into the
main branch and are available

00:20:25.858,00:20:31.764
for everybody else to use
through the official secure drop
box repro. >>So err, all that

00:20:31.764,00:20:36.769
I’m uh my left your right is
Corbin who led that effort in
Leviathan to do the security on

00:20:39.038,00:20:43.609
it, and I thought, it would be
interesting just to, what is the
quality, what is, you know how

00:20:43.609,00:20:48.614
much confidence, umm, what do
you think of the, technology.
>>Yeah so, we’ve had a card

00:20:50.716,00:20:56.255
review of everything like,
infrastructures, uhmm secure
drop pass would be deployed by

00:20:56.255,00:20:59.992
individual companies, freedom of
the press doesn’t deploy it. It
is a product so, New York times

00:20:59.992,00:21:04.997
just went on servers and
everything umm, every other umm
organisation that uses it, so

00:21:04.997,00:21:09.235
you went through the
documentation on are they
recommending same deployments,

00:21:09.235,00:21:14.240
because IT get like uh a news
organisation may not be like, as
great err, umm, err, maybe like

00:21:17.643,00:21:22.648
si, uh regular, umm company, so
we went through them, we looked
through the cryptography umm, to

00:21:26.018,00:21:30.589
make sure that, are things being
submitted actually being
submitted securely umm is there

00:21:30.589,00:21:35.995
a risk of somebody being
deanon-denonamized or manned in
the middle umm all, all that

00:21:35.995,00:21:41.800
sort of effort. Over all the
code based it’s a open source
project and it’s, used by

00:21:41.800,00:21:48.040
important people so it was umm
pretty well put together. Umm
uh, w-we didn’t come across any

00:21:48.040,00:21:54.580
like remote executioner umm,
anything critical like that, umm
and as Pablo mentioned after we

00:21:54.580,00:21:59.585
submitted the report of our
findings to the uh secure drop,
uh sorry to freedom of press, we

00:22:01.654,00:22:06.659
then made some contributions
back, uh the biggest
contributions were the wondering

00:22:08.727,00:22:13.732
how they could securely delete
files, umm, because you don’t
want someone to come in with uh

00:22:16.202,00:22:21.407
supeno take your servers and
just frantically grab everything
off the disk and figure out what

00:22:21.407,00:22:27.413
was submitted. Umm, then we also
wer-were working with them to
set up a proto type to provide

00:22:27.413,00:22:34.320
umm, enter ending encryption
file uploads right now the file
uploads are submitted umm,

00:22:34.320,00:22:39.325
unencrypted elletor, and then
they are encrypted in ram before
written in disk, umm so we kind

00:22:42.228,00:22:47.233
of helped work on potentially uh
making a browser plugin that
would encrypt the files, before

00:22:49.535,00:22:56.175
they are uploaded, umm, the uh
javascript in the browser plugin
err, in one of the interesting

00:22:56.175,00:23:01.780
things about that is the plug in
can execute the signed
javascript without having you

00:23:01.780,00:23:06.785
to, without forcing you to
enable scripts by the browser,
so it’s a way you can have

00:23:06.785,00:23:11.457
javascript encryption without
risking some man in the middle
in your connection and umm,

00:23:11.457,00:23:16.395
throwing in malicious javascript
encryption thing up there. Umm
and Furnel press wants to work

00:23:16.395,00:23:22.701
in the future potentially get a
browser plugin that can do that
umm, maybe in, built into the

00:23:22.701,00:23:29.275
torfire box bundle umm,
eventually uh but those are long
term plans and they kind of

00:23:29.275,00:23:32.745
looking at what would be the
best solution for end to end the
encryption, because would it

00:23:32.745,00:23:38.817
worse if it was something that
make it less secure, umm so,
that is sort of what we working

00:23:38.817,00:23:45.257
on as far as that goes. >>Ok so,
I wanna really spend a little
bit of time getting questions

00:23:45.257,00:23:49.028
with the audience, cos the point
of this was pretty much err,
community consultation, but we

00:23:49.028,00:23:53.065
had to get you up to speed of
what we were thinking so i don't
know does anyone have anything

00:23:53.065,00:23:57.870
else to say? Should we go to
questions? Does anybody have
anything, wanna do questions? Do

00:23:57.870,00:24:02.808
we have a microphone somewhere?
Team, team Goon. No I think, I
don’t think all of the

00:24:05.744,00:24:10.749
microphones got put in this
early, umm, so if you do have a
question, yeah stand up and kind

00:24:13.752,00:24:15.754
of shout it, then we will repeat
it uh so everybody else can hear
it and it can get into the

00:24:15.754,00:24:17.756
recording. So raise your hand,
anybody have a question? If not,
ok this gentleman over here,

00:24:17.756,00:24:19.758
[off mic] so the question was
that Defcon is sort of
international now with China and

00:24:19.758,00:24:24.763
US cert is uh international
getting reports all around the
world. Umm is is there any

00:25:03.569,00:25:08.040
potential future for either
sharing or working with say
europeans certs or others if

00:25:08.040,00:25:13.445
that was it. >>I, you know Pablo
nodded his head and I was
thinking yu, well absolutely I

00:25:13.445,00:25:19.418
mean, cert to cert relationship
across the world. uh we, don’t
differentiate you know again,

00:25:19.418,00:25:24.289
certs are, if you look at uh
some of the norms that have,
that have been agreed to across

00:25:24.289,00:25:30.129
the country, certs are that kind
of DMZ, that space that uh is
protecting the overall

00:25:30.129,00:25:36.101
ecosystem, so umm you know first
blush at least right now uh
again so still working some of

00:25:36.101,00:25:42.508
the thornier policy and legal
questions, but that’s ultimately
where it has to go, because we

00:25:42.508,00:25:48.480
not just talking about US
vendors, we talking about a
global community, uh instead of

00:25:48.480,00:25:52.184
companies that will need to
coordinate these things and do
hand-offs and things in that

00:25:52.184,00:25:56.388
nature. But there’s likely
again, getting into the thornier
policy principals, it’s jus, you

00:25:56.388,00:26:01.560
have to think through what are
the,what are the implications
with sharing with certain states

00:26:01.560,00:26:07.332
tha or countries that may not
share our same system of values
and what are our triggers and

00:26:07.332,00:26:13.472
thresholds to walk through that
process, but. Uh, I will pass
that down the line. >>An answer

00:26:13.472,00:26:19.945
in an ideal world, I mean, the
hacker community is a global
community, it’s not just a US

00:26:19.945,00:26:24.950
community, and so whatever ends
up being built has to support
that global community. And yes

00:26:26.952,00:26:32.624
that means there are significant
challenges ahead in terms of how
we handle certain things, how

00:26:32.624,00:26:37.629
things get disclosed etcetera,
but that absolutely has to be a
priority. >>Go on pile on 1

00:26:40.532,00:26:45.604
piece here, my ultimate concern
here is when I, when we receive
vulnerabilities, we do not turn

00:26:45.604,00:26:50.075
around and share those with the
intelligence community for
exploitation. We have a bias a

00:26:50.075,00:26:55.948
very pres, uh a preference and
an almost argumentative and an
er a posture in the federal

00:26:55.948,00:27:00.919
government on disclosure. And
that will be 1 of the
considerations when you think

00:27:00.919,00:27:06.425
about some of the uh s nations
that we engage with. How are
they going to use this? what are

00:27:06.425,00:27:10.562
they going to do this? And what
is that again? What is the
arbiter? Maybe that is 1 of the

00:27:10.562,00:27:16.869
pieces to think through is, is,
is, can Defcon play a roll, in,
facilitating some of the or at

00:27:16.869,00:27:22.341
least some of the oversight of
some of the engagements. >>Ok,
let’s do another question. May

00:27:22.341,00:27:27.346
we, ok this gentleman in the
front, and then that gentleman
in the back. Yeah yea, [off mic

00:28:09.955,00:28:15.127
question] So I think I can try
to summarize the question, well,
err, his uh chu uh participates

00:28:15.127,00:28:21.600
in err, in uh bug bounty
programs and and is er tester,
and umm, he says before he will

00:28:21.600,00:28:25.137
even get to the point of
reporting, he generally, he
wants to make sure he can test

00:28:25.137,00:28:29.608
the properly on the crank
server, umm and so, could this
system or something

00:28:29.608,00:28:34.613
similar,[cough] umm help in the
future, enable test umm of
government systems to to sort of

00:28:36.715,00:28:42.354
make sure before you report that
it’s feasible. So I think, I-I
mean it’s not contemplated in

00:28:42.354,00:28:46.725
what we are talking about, I
think if you,your a tester you
don’t have a problem being

00:28:46.725,00:28:50.929
identified reporting so you
would probably go through all
the normal pact to pentagon or

00:28:50.929,00:28:56.735
other existing programs. Umm and
if you have a problem with a
specific technology used by the

00:28:56.735,00:29:00.572
government, [cough] maybe you
would be able to test that
technology somewhere else,

00:29:00.572,00:29:04.476
because we-we’re not necessarily
interested in the threshold of
you have to reproduce it, and we

00:29:04.476,00:29:10.282
give you money, it’s more like
we want to know if there is a
problem. Is ss tha >>What I was

00:29:10.282,00:29:17.255
going to say was that, bug
bounty programs have a very
clear set of rules of engagement

00:29:17.255,00:29:21.960
and there is a , is an implicit
invitation to come in and look
at that infrastructure and find

00:29:21.960,00:29:28.634
stuff. This is to cover these
edge cases like for example,
there are edge cases where just

00:29:28.634,00:29:35.240
through ne- just through normal
operations will find
vulnerabilities or will find

00:29:35.240,00:29:40.245
hints to vulnerabilities. And we
not nes we no we definitely not
inviting people to go hack into

00:29:42.514,00:29:46.985
infrastructure to find
vulnerabilities that are not
covered by programs to programs.

00:29:46.985,00:29:52.024
All we saying is, if you find
something or if you see
something, we want to give you

00:29:52.024,00:29:57.295
the channel so that you can
disclose it and so it can be
triaged. >>Hey umm,

00:29:57.295,00:30:04.269
Jennifer.[laughing] I can see
you chomp in >>I’ll just, I’ll
just add you know that the

00:30:04.269,00:30:09.274
riskiness, legally riskiest part
of vulnerability disclosure is
research umm, because of the uh

00:30:11.510,00:30:18.050
legal roles that arguably either
arguably or definately limit of
what you can do with somebody

00:30:18.050,00:30:24.489
else’s box or somebody else's
data, umm and I think that you
know, what we-there are other

00:30:24.489,00:30:29.494
means out there to report
vulnerability information, but
the 1 things is annuminaty can

00:30:31.630,00:30:38.637
do is protect you know goo good
faith testers, but not allowing
them to report but actually

00:30:38.637,00:30:43.642
revealing their identity. Umm I
would say that you know i-it’s
always you know if you can it

00:30:46.478,00:30:51.650
can be a good idea to consult
with a lawyer if your planning
something, that is umm,

00:30:51.650,00:30:56.788
potentially legally risky with
somebody else's machine or
somebody’s data, umm but it is

00:30:56.788,00:31:02.060
going to be risky er and
ultimately the answer really, yu
you know can’t always be no,

00:31:02.060,00:31:05.964
right? There are going to be
times where, unfortunately
people are going to have to take

00:31:05.964,00:31:12.571
on that legal risk. It’s good to
do it, with the benefit of uh a
good consultation ahead of time,

00:31:12.571,00:31:18.877
but I think that umm, you know 1
of the goals of the project is
to be able to, removed that

00:31:18.877,00:31:24.516
legal risk, which is a
disincentive for people to
report things that really should

00:31:24.516,00:31:29.521
be reported. >>Can I do a show
of hands, umm well this might
deanonymize you but, [ laughing]

00:31:33.125,00:31:38.396
anybody in the audience, do you
think a system like this would
be remotely useful? Are, can you

00:31:38.396,00:31:44.536
see it’s use, or see it’s
utility, show of hands. Well
tha-well that’s actually more

00:31:44.536,00:31:51.143
than, more than I thought. [off
mic question] >>So, so there’s
err, there’s uh a quick question

00:31:51.143,00:31:57.616
I want to ask as well, which is,
I’ve been a security researcher
for over 20 years and I have run

00:31:57.616,00:32:03.488
into scenarios where I have
found things, just through
browsing the internet,

00:32:03.488,00:32:09.094
interacting with an application,
and I have struggled to disclose
them, because the company has no

00:32:09.094,00:32:14.599
disclosure policy, company
doesn’t have bug bounty programs
in some cases, decades before

00:32:14.599,00:32:21.072
bug bounty programs existed. How
many of you in the audience have
run into issues, potential

00:32:21.072,00:32:26.411
vulnerability etcetera that you
haven’t been able to disclose,
because there is no process or

00:32:26.411,00:32:31.483
there is concern about how you
would of disclosed it. >>Can I
put an second order question on

00:32:31.483,00:32:37.889
top of that, is what would be
umm, the impediment of reporting
it through the standard US cert

00:32:37.889,00:32:42.527
process, is it you just don’t
like GDP uh that’s what I am
trying to get through this, like

00:32:42.527,00:32:47.532
what, what are the use cases
that the standard, US government
SISA process US serk process,

00:32:50.702,00:32:56.308
isn’t addressing the
requirement. >>So going back a
few years, that process wasn’t

00:32:56.308,00:33:01.246
in place >>that only, >>eh yu,
err, but the other issue is,
there is always concern when you

00:33:03.782,00:33:09.721
find something about how err,
various entities are going to
react. I have been legally

00:33:09.721,00:33:15.427
pursued by companies for
finding, good faith
vulnerabilities. And so

00:33:15.427,00:33:21.399
protection would encourage me to
go forward more, >>Well this is,
this is potentially the

00:33:21.399,00:33:26.204
Misqinsky problem, Dan
Misquinsky, when he found the
famous GMS bug. It took him 9

00:33:26.204,00:33:31.243
months of his life to coordinate
with all the other effective
parties, and he felt really good

00:33:31.243,00:33:37.415
and he made great change, after
that he said never again,like
I’m not doing that twice. And so

00:33:37.415,00:33:40.685
sometimes people find the bug
and they want to drop it and
they want to walk away and get

00:33:40.685,00:33:45.991
on with their life, because he
can’t commit to a certain level,
umm, so i-if there’s a Pablo

00:33:45.991,00:33:51.329
there’s comment then we have go
to the next question >>Can we
get a vote though >>Oh yes the

00:33:51.329,00:33:54.666
vote yeah yeah >>Mar-marks
question >>Ho-How many people
have trouble with umm

00:33:54.666,00:33:58.737
vulnerability reporting, when
they had something they wanted
to contact someone and reveal it

00:33:58.737,00:34:05.310
and they just had difficulty
figuring out how to do it, or
doing it, >>Show of hands

00:34:05.310,00:34:11.182
>>whose had that >>Ok, thank
you, oh Pablo, oops >>yes >>Ok,
did you have a comment, I'd like

00:34:11.182,00:34:16.755
to go to the next question >>No,
I wanted to clarify the last
question, if the question was

00:34:16.755,00:34:23.061
about security testing, the
secure drop instance, err, I
would be, so first of all the

00:34:23.061,00:34:27.365
software is up there and it’s
open source sec of all it’s not
going to be hosted by the

00:34:27.365,00:34:33.538
government, umm, wo-wo-working
with the uh with Jeff and err,
I-I think we going to be able to

00:34:33.538,00:34:38.510
get Defcon to host the servers,
uh, but I would be very
interested to see if we could

00:34:38.510,00:34:44.015
sponsor maybe a black badge
competition in the following
years that we can ask the

00:34:44.015,00:34:47.752
community >>Hack the system and
help improve it >>Hack the
system and help improve it,

00:34:47.752,00:34:52.824
w-w-we wanna make that sure the
system is secure, not just for,
for the US government instance

00:34:52.824,00:34:57.829
but also for the fronts
instance, yeah, >>W-w-wait we
have to go to this gentlemans

00:35:32.397,00:35:37.402
question [off mic question]
right, here’s maybe to summarize
that, do you wanna >>Yeah so

00:35:49.280,00:35:55.587
>>Do you wanna >>The question
was, this, this boils down to
trust and the uh US government

00:35:55.587,00:36:01.259
has practically done a hideous
job of, working with
researchers, working with the

00:36:01.259,00:36:06.731
press, uh you know going after
people, attacking the tour
networks so how do we work on

00:36:06.731,00:36:12.103
that, how do we work on the
outside entrust and the inside
entrust, uh hopefully this is a

00:36:12.103,00:36:16.775
step we trying to be as
transparent as possible, umm
it’s going to be tentative at

00:36:16.775,00:36:21.279
first, not everybody is going to
trusted it, uh there’s gonna be
issues somebody’s gonna find a

00:36:21.279,00:36:25.083
issue with secure drop, uh,
hopefully we get it fixed.
Somebody is going to submit a

00:36:25.083,00:36:31.056
bug and feel it wasn’t uh
handled correctly, uh there are
going to be mishaps absolutely,

00:36:31.056,00:36:36.761
I-I think with the intent of
good faith needs to be there, we
need to be transparent >>So 1 of

00:36:36.761,00:36:41.900
the main reasons I got involved
in this is because I believe
that trust is the critical

00:36:41.900,00:36:48.273
element that will make this
work. And I want to see you rip
this thing apart, and find

00:36:48.273,00:36:53.545
issues with it, and point out
these flaws and so that we can
work through it. And it may take

00:36:53.545,00:36:58.917
irretagations to get to a real
good trustworthy product, but by
engaging with the community and

00:36:58.917,00:37:04.556
having the community do that
work, I have confidence that we
can get there. >>Well what I

00:37:04.556,00:37:09.894
want to add here is that we not
going to engineer trust. And
it’s not a single solution

00:37:09.894,00:37:14.432
approach, I think there was
actually a really good
conversation yesterday uh in 1

00:37:14.432,00:37:21.106
of the Healow suites, umm about,
err, some of the legal issues
DUJ plays a role, they need more

00:37:21.106,00:37:26.511
guidance and more clarity on
what the things, and how CFA
comes into play here, but in

00:37:26.511,00:37:32.350
terms of where I sit, I am not
the IC I am not the law
enforcement. I am the private

00:37:32.350,00:37:36.488
sectors advocate, within the
federal government, I think we
have a pretty good track record,

00:37:36.488,00:37:40.992
from at least, from where sit,
what I have been told, unless
they lying to my face. I think

00:37:40.992,00:37:46.931
we can manage this, I think we
have a good ability here but
trust is a 2 way street, umm, so

00:37:46.931,00:37:50.668
the there’s obviously based on
this conversation, based on the
feedback from today, that trust

00:37:50.668,00:37:54.873
isn’t where it need to be, but
this is a maturing discipline
it’s a maturing conversation

00:37:54.873,00:38:00.512
tion, uh there is still
obviously still work left to do.
>>Ye we got time for 1 more

00:38:00.512,00:38:05.517
question. You got to make some
noise so we can find you >>Right
there over >>There, there we go,

00:38:10.822,00:38:14.225
If you wanna if you wanna to run
up and answer ask a question
which is closer to us then we

00:38:14.225,00:38:19.230
will repeat it for everybody,
[off mic question] yep, yep [off
mic question] [laughing] Come on

00:38:23.501,00:38:28.506
down. >>So I’m just curious like
[off mic question] so, ya,
interesting qu- >>Do you want

00:38:35.547,00:38:40.552
>>Yeah yeah you have >>Ok uh so
I don’t have the answer for
this, but it’s a great

00:38:49.127,00:38:54.132
question,umm basically uh
potential summary of this
project is witness protection

00:38:57.435,00:39:02.373
for hackers and the federal
government has experience with
witness protection in other

00:39:07.145,00:39:12.917
context for example, the law
enforcement context,umm you know
for this project would it

00:39:12.917,00:39:18.590
beneficial and wo-would we want
to do in order to take the
knowledge and lessons from

00:39:18.590,00:39:24.362
witness protection umm, legally
and umm otherwise security wise
and these other context and how

00:39:24.362,00:39:29.367
we might apply that knowledge to
this particular project. >>So,
now you’ve asked the question

00:39:31.569,00:39:35.173
[laughing] >>That’s not fair
>>Uhh, well so, umm, so unlike
witness protection we not

00:39:35.173,00:39:40.178
dealing with uh with a physical
person, it’s it’s information,
so it would be more about

00:39:42.914,00:39:48.119
protecting, umm separating the
person submission and you know
to prevent deanonymization,

00:39:48.119,00:39:53.191
segregation, and I think that’s
where the idea that Defcon
operating the servers in the

00:39:53.191,00:39:59.264
middle we get torgue connection
to us, the magic happens, the
torque connection to uh cert, so

00:39:59.264,00:40:05.937
cert never sees or the discern
the IP you know, the exit mode
and back and forth there are 2

00:40:05.937,00:40:10.642
separate touring instances
running and so there is some
operational s s a little bit of

00:40:10.642,00:40:16.614
sophistication, that like Chris
says we not going to engineer uh
trust, but there is a lot of

00:40:16.614,00:40:22.053
things we can do to reduce the,
the risk. You know like files
are deleted, so lets say an

00:40:22.053,00:40:25.924
analytical cert, get a file,
well then they, they download
the file and delete it off the

00:40:25.924,00:40:31.129
server, so if the server does
get on you got what there
between the last time and the

00:40:31.129,00:40:36.067
analyst downloaded, right there
is operational things we can do
to make it not a juicy target,

00:40:36.067,00:40:41.606
right, it’s not, there’s not a
lot of stuff there,like 6hours
of things that kind of eh and I

00:40:41.606,00:40:45.910
think kind of that’s why, uh I
like consulting with Runo
because she deal with this with

00:40:45.910,00:40:51.849
real people and other sketchy
countries where life safety is
at risk and they all are trying

00:40:51.849,00:40:58.456
to do the right thing,bu-but at
a significant risk. >>I-I think
1 of the >>wait Lasher >>Umm I

00:40:58.456,00:41:02.193
actually wanted to add a
question, even though that’s a
great question, that a challenge

00:41:02.193,00:41:08.433
might pop up in this case that
we don’t have in the media
context is that if a source

00:41:08.433,00:41:12.804
submits something to the New
York Times, our rule is to
report on the content, our rule

00:41:12.804,00:41:17.809
is to verify if it is accurate,
and then report on the content.
We do not, work to,umm,

00:41:20.912,00:41:27.385
deanonymize the source, we do
not work to figure out who they
are and how many laws they

00:41:27.385,00:41:31.122
broken to >>But we not trying to
put it the reporter in context ,
you just try to take their

00:41:31.122,00:41:35.560
information and try to validate
it, >>Correct, so we take the
information and we do whatever

00:41:35.560,00:41:40.865
we can to validate it, either by
communicating with the source,
through secure drop or some

00:41:40.865,00:41:44.869
other channel, if we can, just
then there is a process in which
the reporter would have to get

00:41:44.869,00:41:50.575
the information verified through
other channels, but our rule is
never to try to de anonymize the

00:41:50.575,00:41:54.912
source, and I think that might
be a concern in this context, if
you submit something, think

00:41:54.912,00:42:01.552
through this process, would the
government then make an effort
to figure out who sent the

00:42:01.552,00:42:07.024
information. [pannel chatter]
>>Yeah and just to add to this,
1 of the goals of the err,

00:42:07.024,00:42:12.563
assessment that we did, uhmm,
was part of the attack servers,
depending where an actor is

00:42:12.563,00:42:17.335
sitting trying to deanonymize a
source,like how much damage
could they do, if someone owns

00:42:17.335,00:42:21.439
the Defcon server, and has some
implants sitting on there,
reading everything that comes

00:42:21.439,00:42:26.110
in. we looked at where would
they actually be able to see the
information and what would they

00:42:26.110,00:42:32.617
be able to deanonymize, that was
also why we looked into after
you pull the data on too, off

00:42:32.617,00:42:37.822
the server and the journalist
looks at it, how do you actually
get it securely deleted so that

00:42:37.822,00:42:42.260
even if somebody comes in, takes
the server physically and tries
to analyse what was on there.

00:42:42.260,00:42:46.230
Umm like how do we prevent
anything from happening as soon
as it’s read by a journalist

00:42:46.230,00:42:51.702
like delete all evidence. Umm so
hopefully it doesn’t get to the
point,of having to deal with

00:42:51.702,00:42:56.574
that witness protection thing,
it’s a it’s a recorded
everything is deleted and

00:42:56.574,00:43:01.579
tha-that’s it for the source and
they don’t have to look at it
again. >>who- ho, and honestly

00:43:01.579,00:43:07.685
I-I will tell you honestly 1 of
my plans is that if there is a
little engineering to do, it is

00:43:07.685,00:43:11.789
to make sure that Defcon can
honestly answer a subpoena
request that says no we don’t

00:43:11.789,00:43:16.794
have the keys, we can’t tell you
what’s on the server, but FBI
the, you know US cert can, so

00:43:19.564,00:43:22.400
you part of the government go
talk to you part of the
government and I’m going to be

00:43:22.400,00:43:27.772
having a coffee. [ laughing]
right, the idea is to get us out
of the middle if there’s an

00:43:27.772,00:43:34.645
internal dispute. And I am sorry
Chris, but [ speaker laughs] you
might be in the middle of that.

00:43:34.645,00:43:37.748
[laughing] >>Thanks [laughing]
>>So umm we kind of coming to
the end of time. I wanna have

00:43:37.748,00:43:42.820
one more question to the
audience, so after hearing this,
this is our since this is our

00:43:42.820,00:43:47.425
first ever sort of consultation
after hearing this, umm
obviously there’s a lot more

00:43:47.425,00:43:52.430
discussions we have but by a
show of hands who thinks Defcon
should pursue this? Ok who

00:43:55.433,00:44:01.239
thinks this is the most castro
traffic disaster uh thing in
the, you know, threat to to

00:44:01.239,00:44:06.244
Defcon, ok. Well a threat to
defcon >>Defcon >>Yeah there are
many threats to Defcon [panel

00:44:10.381,00:44:14.018
laughs] you all are a threat to
defcon.[laughter] Alright so if
anybody has any concluding

00:44:14.018,00:44:20.258
remarks then I think we done,
>>I-I just have 1 little comment
to make, just to kind of sum up

00:44:20.258,00:44:25.997
what I think I hear from people
in terms of, I see a lot of
support obviously, but what I

00:44:25.997,00:44:30.167
think I hear from people in
terms of concerns is that
there’s a heavy reliance on

00:44:30.167,00:44:34.772
technology to to do the
protection, the hard work of
protecting the community of

00:44:34.772,00:44:38.543
people who are going to be be
reporting, but what I am hearing
in the comments is where people

00:44:38.543,00:44:44.148
have concerns is that technology
we, you guys know better than
anybody else that technology can

00:44:44.148,00:44:49.287
fail. And there are other things
in terms of trust processes,
relationships inside the

00:44:49.287,00:44:55.593
government and government to
government, umm you know having
more of an appreciation for the

00:44:55.593,00:45:01.732
importance of research and less
of a punitive approach by umm,
law enforcement and that these

00:45:01.732,00:45:06.737
other non technical human legal
policy relationship parts where
the areas where people really

00:45:08.773,00:45:13.077
feeling so concerned and want to
make that stronger, in order to
make the project like this to

00:45:13.077,00:45:17.648
really actually be be
trustworthy and beneficial to
the, the everybody who is

00:45:17.648,00:45:21.886
involved. That’s, that’s what I
am hearing. >>Yeah yeah and I
would agree with that, that I

00:45:21.886,00:45:25.590
think it’s been a good
conversation, helpful feedback
and if I think if we look at

00:45:25.590,00:45:31.562
this, th-the US government is
littered with a graveyard of
good ideas and in so, we need to

00:45:31.562,00:45:37.768
manage expectations, do this in
a way that is pilot based , but
let’s really focus on maybe some

00:45:37.768,00:45:43.574
of the use cases, I think you
guys know this stuff,umm, really
darn well and just tell us why,

00:45:43.574,00:45:49.213
what are some of these examples
or hyper equals where this might
be at use,obviously

00:45:49.213,00:45:53.217
implementation a 1000 more will
come up that we never really
anticipated but it is always

00:45:53.217,00:45:58.222
helpful to kind of scope the
issue and er and er start small
and spririal it up >>alright,

00:46:00.791,00:46:05.029
well thank you for
participating, we around, we’ll
be here all week umm [laughing]

00:46:05.029,00:46:10.034
around to, to answer questions,
thank you very much. [applause]

