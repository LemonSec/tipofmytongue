00:00:00.000,00:00:03.971
>>I'm really looking forward
to this talk if you if
you've been to a lot of

00:00:03.971,00:00:08.175
talks so far you know that
they have all been pretty,
pretty technical my

00:00:08.175,00:00:11.178
understanding is that we are
going to get some
entertainment and some jokes

00:00:11.178,00:00:17.017
and some stories from uh
from Ben here. So, let's get
excited, give Ben Morris a

00:00:17.017,00:00:22.422
big round of applause he's
going to talk to us about
AWS. [applause] Have a great

00:00:22.422,00:00:28.896
time man >>Thanks, very much
>>have fun >>Thanks very
much, I really appreciate

00:00:28.896,00:00:31.932
it. Hey everyone how's it
going? You guys having a
good time? [woo] alright so

00:00:31.932,00:00:34.935
am I, so am I thank you for
coming in today I know you
guys have probably been

00:00:34.935,00:00:39.106
waiting in a lot of lines
and uh yeah I just really
appreciate you guys being so

00:00:39.106,00:00:44.278
excited coming here to see
this talk. I put a lot of
work into it so thank you.

00:00:44.278,00:00:47.247
And uh, we're gonna be
talking about a lot of cool
stuff today we're gonna be

00:00:47.247,00:00:52.352
stealing lots of secrets and
we're gonna be hacking AWS
and showing how I did it all

00:00:52.352,00:00:59.426
and then talking about how
we can basically help fix
the issue and uh if you just

00:00:59.426,00:01:04.064
uh give me one sec to
actually get my timer
started cause I am okay

00:01:04.064,00:01:10.704
perfect. So, yeah, thank you
very much for coming just a
little bit of a disclaimer

00:01:10.704,00:01:17.311
before we uh get started
here uh please do not arrest
me FBI uh no post

00:01:17.311,00:01:23.417
exploitation was performed
and everything I found was
basically publicly available

00:01:23.417,00:01:29.122
already. Um, I'm not going
to be talking about any AWS
zero days or any exploits in

00:01:29.122,00:01:35.462
customer specific software.
This is just a wide spread
misconfiguration issue with

00:01:35.462,00:01:40.434
AWS and uh I'll talk about
that a little bit more later
but basically I was just

00:01:40.434,00:01:44.571
kind of driving down the
road and I looked out the
window and said to myself

00:01:44.571,00:01:49.142
huh a lot of people's discs
are on fire. I should
probably you know just call

00:01:49.142,00:01:53.146
the police and let them deal
with it and I just kind of
kept driving so I didn't do

00:01:53.146,00:01:57.217
a lot of post exploitation
and I definitely stuck to
you know the look but don't

00:01:57.217,00:02:07.127
touch. But, anyway, um so
what is EBS? EBS stands for
elastic block store and it's

00:02:07.127,00:02:14.167
essentially a virtual hard
disc that you can attach to
a VM so anytime you spin up

00:02:14.167,00:02:19.072
a virtual machine inside of
AWS, it's going to have a
disc that's automatically

00:02:19.072,00:02:26.480
provisioned to it. And that
disc is an EBS volume they
can vary in size and the

00:02:26.480,00:02:29.916
default is like 8 gigabytes
like basically anytime you
start building an

00:02:29.916,00:02:36.957
application using uh Amazon
ec2 you're gonna be running
one of these EBS volumes.

00:02:36.957,00:02:41.628
So, they contain your
application code, your data
and everything else you

00:02:41.628,00:02:48.702
would want to deploy. So
these volumes, they can
basically be attached and

00:02:48.702,00:02:55.175
reattached to various
machines, you can move them
around kind of like uh

00:02:55.175,00:02:59.012
network attached storage in
a way. So, um they can you
can clone them, you can

00:02:59.012,00:03:02.115
delete them, you can copy
them, you can do everything
with them that you would

00:03:02.115,00:03:08.522
expect and um they come in
generally 4 flavors for
security purposes they come

00:03:08.522,00:03:16.096
in unencrypted, encrypted
and public and private so
you can have a combination

00:03:16.096,00:03:21.168
of them like a public
unencrypted, private
encrypted, public encrypted

00:03:21.168,00:03:28.608
and what not and we're gonna
be looking at the public and
unencrypted ones today.

00:03:28.608,00:03:33.814
Those are the ones that are
interesting and uh those are
just the fun ones that have

00:03:33.814,00:03:38.051
all the credentials in it so
if you have you know an
encrypted uh or private disc

00:03:38.051,00:03:45.559
they're not really
vulnerable. And also, these
discs by public- or by

00:03:45.559,00:03:49.429
default are private so, when
you do spin up that
instance, it is going to be

00:03:49.429,00:03:53.433
backed by a private volume
which kind of made this uh
vulnerability really

00:03:53.433,00:03:58.238
interesting to me. I wanted
to know you know who is out
there exposing their discs

00:03:58.238,00:04:05.145
to the public when AWS
actually makes it pretty
tough you know you have to

00:04:05.145,00:04:07.948
go into a separate menu
after you create the
snapshot and after you

00:04:07.948,00:04:10.750
create the image to actually
go check that public box.
So, I was really curious to

00:04:10.750,00:04:16.623
know you know who is out
there doing this. So, what
could possibly go wrong with

00:04:16.623,00:04:25.132
an unencrypted and public
disc? Well, basically eh
back in January I was at an

00:04:25.132,00:04:30.070
onsite for a client and you
know I was just really jet
lagged and not able to

00:04:30.070,00:04:33.707
sleep, I'm sure you guys
have all been there it's
like you you know you're on

00:04:33.707,00:04:35.775
the west coast you've got to
fly all the way to the east
coast or you're on the east

00:04:35.775,00:04:39.379
coast you've gotta fly to
the west coast you get to
that hotel and you sit there

00:04:39.379,00:04:46.386
and you're at the bar, but
there's nothing to do you
know you're just stuck there

00:04:46.386,00:04:52.325
and then it's like 1 a.m the
bar's closed, there's
nothing there and you

00:04:52.325,00:04:55.162
basically just say well I'll
go sit on my computer, fine.
So, I thought to myself well

00:04:55.162,00:04:59.199
I'll look at uh this clients
cloud security controls,
that'll definitely put me to

00:04:59.199,00:05:05.739
sleep you know. Um, except
that it really didn't uh I
basically found an

00:05:05.739,00:05:11.211
unencrypted EBS volume that
was public on their account
and I really wasn't familiar

00:05:11.211,00:05:16.216
with this vulnerability so,
I just did what everyone
else does and I just googled

00:05:16.216,00:05:20.620
it. You know and I found
some blog posts but there
were only a couple of them

00:05:20.620,00:05:25.792
and they didn't really talk
about um this vulnerability
very much, they basically oh

00:05:25.792,00:05:32.666
well that's bad but just
don't do it and it's fine.
Which is always you know

00:05:32.666,00:05:39.439
just peaks my interest I'm
like okay well I gotta know
more now. Um, so you know I

00:05:39.439,00:05:43.643
basically took this clients
disc and I went through the
27 steps of attaching it to

00:05:43.643,00:05:46.746
my VM through the console
and mounted it and I
realized that this client

00:05:46.746,00:05:54.988
had made a copy of their
entire web application,
available to the public

00:05:54.988,00:06:01.261
internet and this basically
had everything to run the
app including their AWS

00:06:01.261,00:06:05.932
access keys, their AWS
secret keys, API keys for
3rd parties, database

00:06:05.932,00:06:13.573
credentials, because you
know of course and of course
the database was exposed to

00:06:13.573,00:06:18.278
the internet because why
not? Of course you'd want to
do that when you have AWS

00:06:18.278,00:06:23.583
you know that's totally
normal. So, after I
discovered that disc, and

00:06:23.583,00:06:28.688
basically had this you know
incredibly critical finding
um I knew I basically had to

00:06:28.688,00:06:32.993
investigate more. I needed
to know you know how how um
how widespread was this bug,

00:06:32.993,00:06:38.898
because this bug was really
powerful. It had you know
the keys to the kingdom for

00:06:38.898,00:06:44.704
this whole application. So,
you know I started doing
some digging and I wanted to

00:06:44.704,00:06:49.809
ask myself well why does
this happen? You know, how
can this happen um and

00:06:49.809,00:06:55.782
basically, there's two
screenshots here you want
your discs to look like the

00:06:55.782,00:07:00.954
top screenshot there. I-if
you can see it says uh
there's a this snapshot is

00:07:00.954,00:07:04.958
currently private and that's
what you want it to look
like. By default that's what

00:07:04.958,00:07:09.562
it will be. But if you go
into that tab, and you
change it to public or you

00:07:09.562,00:07:15.402
use the API you have some
kind of broken API code that
ends up setting that uh

00:07:15.402,00:07:21.775
snapshot to public what
happens is it shows up in
that nice search box down

00:07:21.775,00:07:26.913
there at the bottom, and
this search box is wonderful
because you type in the word

00:07:26.913,00:07:31.818
Jenkins and Jenkins servers
come up and you type in the
word backup and backup

00:07:31.818,00:07:37.991
servers come up. So, at-
basically at that point I
kind of realized like woah

00:07:37.991,00:07:44.397
this is really cool, got
something here and basically
when you do set that public

00:07:44.397,00:07:49.135
tab and it shows up in that
search box if it does have
sensitive information in it

00:07:49.135,00:07:52.539
you have to assume it's
compromised at this point um
because anyone can go search

00:07:52.539,00:07:57.010
through it and I don't know
if you guys have heard about
um the Capital One stuff

00:07:57.010,00:08:02.115
that just happened recently
or any kind of other like S3
bucket exposures, this is

00:08:02.115,00:08:06.219
kind of a similar
vulnerability to that um in
that it you know it-it's

00:08:06.219,00:08:09.422
kind of going through
someone's uh private data
storage that they think is

00:08:09.422,00:08:13.893
private but it's really not
and one cool thing about
this bug is all of the

00:08:13.893,00:08:20.166
snapshots are queryable you
can pull all of the ID's
back from the API. It's not

00:08:20.166,00:08:26.406
like an S3 bucket where you
would have to start guessing
people's uh bucket names to

00:08:26.406,00:08:36.016
try to find one and if they
set something like a goo-ed
for their bucket name you're

00:08:36.016,00:08:40.854
not really gonna be able to
find it. So, this-this made
it really, really

00:08:40.854,00:08:43.990
fascinating and really cool
to me because you could
basically just start going

00:08:43.990,00:08:46.860
through all of their stuff
um in a programmatic fashion
very easy and you know even

00:08:46.860,00:08:49.496
if you just want to use the
web gooey you just start you
know typing in stuff in

00:08:49.496,00:08:53.767
there. So, um at that point
I was just like this is
awesome um and so let's just

00:08:53.767,00:08:59.105
talk a little bit about what
I found because everyone
likes loot and uh yeah

00:08:59.105,00:09:03.777
that's what you're all here
for so what did I find on
these buckets? I found a lot

00:09:03.777,00:09:08.882
of stuff. So, I'm gonna
give, first I'm gonna give
uh examples of some full

00:09:08.882,00:09:13.853
exposures that I was able to
find and then I'm gonna kind
of talk at a higher level

00:09:13.853,00:09:19.659
and talk about um overall
trends and some more stuff
that I did find. Um, so the

00:09:19.659,00:09:28.034
first example I'm going to
talk about is about some
robots and I like robots,

00:09:28.034,00:09:34.007
robots are great, there our
friends and if you think
about robots and service

00:09:34.007,00:09:37.277
accounts in your own
organizations you may be
thinking about you know your

00:09:37.277,00:09:42.081
slackbot or you know other
chat bots you have and think
about the what those robots

00:09:42.081,00:09:46.920
can do they can do things
like push code, or you know
deploy new builds. They can

00:09:46.920,00:09:51.991
do a lot of stuff and have a
lot of access but usually
there's this you know

00:09:51.991,00:09:57.096
interface between you and
the bot like some kind of
chat or something that lets

00:09:57.096,00:10:02.502
you, you know that delegates
permissions. So, um this
case I was able to find

00:10:02.502,00:10:07.574
these credentials in this
user data dot config file on
this random disc basically

00:10:07.574,00:10:12.378
and I was robot so, what
could I do with robot, well
I didn't have any permission

00:10:12.378,00:10:18.151
restrictions and you know
the ability to you know
deploy stuff seems pretty

00:10:18.151,00:10:24.791
great and um when I started
looking at the disc uh one
more thing uh this uh output

00:10:24.791,00:10:29.829
right here is basically the
equivalent of who am I for
AWS. There's one command you

00:10:29.829,00:10:35.101
want to run whenever you
find a set of credentials
it's called uh a STS get

00:10:35.101,00:10:37.971
caller identity and that
basically is like who am I?
Any time you have a set of

00:10:37.971,00:10:41.374
any credentials you can
pretty much always call this
API in point um no matter

00:10:41.374,00:10:42.942
your region and it will come
back with who you are. So,
this is just a simple

00:10:42.942,00:10:52.552
listing of you know who I am
and uh so I started looking
through this disc to try to

00:10:52.552,00:10:55.788
find clues uh one thing
that's interesting about
this is you always gotta

00:10:55.788,00:11:03.029
have a scavenger hunt to
figure out who owns the disc
and who uh you know who owns

00:11:03.029,00:11:06.533
it so um in some config
files that these creds were
near um there was some

00:11:06.533,00:11:12.105
database configs with some
internal urls and uh
some-some just some domain

00:11:12.105,00:11:16.709
names and these domain names
led me to a pretty cool
company and uh the company

00:11:16.709,00:11:24.851
ended up uh doing a lot of
really interesting things
like uh tracking ISIL social

00:11:24.851,00:11:31.558
media requests and uh posts
and they did things like uh
record border interdictions

00:11:31.558,00:11:37.163
and they were basically uh
software as a service
company that sold pretty

00:11:37.163,00:11:39.499
much exclusively to the
government so they're just
doing government stuff and

00:11:39.499,00:11:42.468
uh their robots keys are
just sitting out there for
anyone to go grab. So, if

00:11:42.468,00:11:48.174
you guys wanted to you know
read up on what isis is
doing uh you know on social

00:11:48.174,00:11:56.749
media these are the guys you
want to talk to. So, you
know at this point I

00:11:56.749,00:11:59.118
basically s*** my pants and
it's like you know what am I
in control of right now um

00:11:59.118,00:12:01.988
so you know we reached out
to this company and they
were of course very grateful

00:12:01.988,00:12:04.624
and they you know a super
positive response um and
they gave us like some

00:12:04.624,00:12:10.163
remediation steps so uh they
really liked this and um
yeah this was this one just

00:12:10.163,00:12:15.068
kind of highlights this
problem entirely like it's
just you know you could find

00:12:15.068,00:12:18.805
anything out there and these
accidental exposures could
contain anything really. Um,

00:12:18.805,00:12:24.877
so it was really interesting
just kind of going through
them all. The uh, the next

00:12:24.877,00:12:32.218
set of credentials I want to
highlight is uh something I
just call w00t w00t and

00:12:32.218,00:12:37.924
basically there was a disc
with a docker file and if
you guys aren't familiar

00:12:37.924,00:12:41.394
with docker, it's just a way
to manage your
infrastructure basically and

00:12:41.394,00:12:47.033
there was some other code
around there there was like
a golang program uh that was

00:12:47.033,00:12:50.503
compiled and then there was
some kind of scripts and it
looked like they were mostly

00:12:50.503,00:12:54.107
for system administration it
looked like this thing was
responsible for a spitting

00:12:54.107,00:13:02.048
up infrastructure and the
one thing uh that I couldn't
really figure out was who

00:13:02.048,00:13:06.486
actually owned this disc.
Um, the config files didn't
really have any clues there

00:13:06.486,00:13:10.356
weren't any domains it was
just like internal 10 dot
addresses so it was just

00:13:10.356,00:13:14.260
kind of like okay well I
don't know who owns this
disc but what I did know was

00:13:14.260,00:13:20.366
you know which account I was
and who I was and who I was
was root! So, just out of

00:13:20.366,00:13:26.305
thin air I was able to grab
some root credentials for
this account and if you're

00:13:26.305,00:13:31.544
not familiar AWS root is is
basically God permissions on
an AWS account it has

00:13:31.544,00:13:37.750
unrestricted access it's an
administrative account and
you're actually not even

00:13:37.750,00:13:46.592
really supposed to use them,
you're kind of supposed to
delegate uh an account or

00:13:46.592,00:13:48.861
your supposed to create an
admin account and delegate
admin permissions to it so

00:13:48.861,00:13:51.964
that way you're not directly
using the root account. But,
these guys thought it was a

00:13:51.964,00:13:56.235
bright idea to just start
using that root account and
they said oh well, no one

00:13:56.235,00:14:00.073
will ever find this disc you
know it's just some internal
thing that uh spins up

00:14:00.073,00:14:05.011
infrastructure no one really
interacts with it except me
you know the you know the-

00:14:05.011,00:14:13.319
the highlight here is just
you know you could find
everything this was actually

00:14:13.319,00:14:16.889
the only set of root creds I
found in the discs so that
was kind of cool. Um, I-I

00:14:16.889,00:14:19.625
honestly wasn't even
expecting to find it um just
because I think everyone

00:14:19.625,00:14:23.296
kind of knows not to do this
now. But, this just
highlights again just the

00:14:23.296,00:14:27.033
critical nature of these uh
discs and what they contain
because a lot of people

00:14:27.033,00:14:32.772
aren't just expecting you to
be able to get access to
these ones. So, um the next

00:14:32.772,00:14:38.644
one I want to talk about is
a little it's about a little
piece of software I love,

00:14:38.644,00:14:45.251
near and dear to my heart,
it's Jenkins and if any of
you guys have you know owned

00:14:45.251,00:14:49.122
some Jenkins machines out
there you know why I love
it, it's always full of

00:14:49.122,00:14:54.160
credentials it like has
access to production source
code and it can like push

00:14:54.160,00:14:58.698
builds. People do all kinds
of crazy stuff in their
Jenkins jobs so you know

00:14:58.698,00:15:02.201
anytime you come across a
Jenkins server, it's just
great you know tons of

00:15:02.201,00:15:06.539
stuff. So, um, in this case
I found a Jenkins server and
it was basically, it looked

00:15:06.539,00:15:13.513
like a developer instance it
looked like to me some
developer was trying to get

00:15:13.513,00:15:19.685
an internal application to
work with their um their own
uh Jenkins set up. So, they

00:15:19.685,00:15:26.259
kind of like spun up a copy
of their Jenkins server and
we're trying to you know get

00:15:26.259,00:15:35.668
an application to work
properly with it. Um, so you
know in the Jenkins server I

00:15:35.668,00:15:38.337
found some AWS credentials
and I popped them in to the
STS sketcaller identity and

00:15:38.337,00:15:42.675
I found out I was a dude
named Kumar. And I thought,
well that's great. I uh I'm

00:15:42.675,00:15:50.883
Kumar now sounds good. So,
uh I looked in the users dot
xml file which is if you're

00:15:50.883,00:15:55.121
not familiar with Jenkins it
is just a file that holds
basically all of your

00:15:55.121,00:15:59.192
usernames and passwords for
users on the machine and
that's kind of assuming

00:15:59.192,00:16:02.562
there's no single sign in
place or no active directory
integration. But, um so this

00:16:02.562,00:16:10.069
users dot xml file was kind
of funny because um I looked
at who made the server, who

00:16:10.069,00:16:15.241
had the admin account in
their email address and it
was definitely not anyone

00:16:15.241,00:16:24.817
named Kumar. So, you know it
was kind of funny some guy
sat there and first they

00:16:24.817,00:16:26.586
exposed their disc publicly
which was really bad and
they exposed their AWS

00:16:26.586,00:16:29.355
credentials but then they
like also framed their
co-worker somehow I don't

00:16:29.355,00:16:33.359
why maybe they maybe they
were trying to frame their
co-worker, I don't

00:16:33.359,00:16:39.365
understand um yeah, so Kumar
we got his keys and uh you
know started looking around

00:16:39.365,00:16:44.670
um trying to figure out uh
who this was and from the
email address we were able

00:16:44.670,00:16:50.843
to determine it was a
software company. And the
software company um I can't

00:16:50.843,00:16:56.515
name them but I can talk
about you know who uh who
they do business with and

00:16:56.515,00:17:00.119
from their website you know
these are the people they
work with. They work with

00:17:00.119,00:17:02.688
you know Salesforce, Apple,
FIS um a lot of other like
fortune you know fortune

00:17:02.688,00:17:08.761
whatever n companies. Um, so
you know this is a large
software kind of consultancy

00:17:08.761,00:17:13.065
firm and uh they just did
you know a lot of cool stuff
but you know these keys are

00:17:13.065,00:17:17.303
just uh they're just sitting
out there. And, they're keys
that could potentially

00:17:17.303,00:17:22.675
impact these other companies
who you know I'm sure
Salesforce and Apple and all

00:17:22.675,00:17:25.878
of them they have you know
very good perimeter security
and they're making sure that

00:17:25.878,00:17:29.582
they have a tight-a tight
leash on developers so
they're not doing this kind

00:17:29.582,00:17:35.121
of stuff. But, in this case
you know you could almost
have a compromise happen

00:17:35.121,00:17:40.660
because of a contractor who
maybe you know only has
indirect access and you know

00:17:40.660,00:17:44.730
are-are-are you really
watching that whole supply
chain of you know your

00:17:44.730,00:17:48.334
contractors and who you're
actually doing business with
to make sure their security

00:17:48.334,00:17:51.671
is also not weak. Um,
because in this case you
know the compromise could

00:17:51.671,00:17:57.310
you know could definitely
lead to some pretty severe
consequences. Um, just with

00:17:57.310,00:18:02.848
the amount of work this
company does. So, you know
overall these kind of 3

00:18:02.848,00:18:07.053
exposures highlight the
critical severity and-and uh
just the kind of stuff

00:18:07.053,00:18:12.959
you're gonna find when you
come across these disks. And
all this makes sense you

00:18:12.959,00:18:15.595
know these are just like
peoples application servers,
it's just a lot of

00:18:15.595,00:18:19.165
developers kind of you know
uh doing whatever and trying
to just make their stuff

00:18:19.165,00:18:23.970
work um so, you know overall
we had uh these are kind of
the things I was looking for

00:18:23.970,00:18:33.679
um when uh when you get into
a disk you find a lot of
leaked source code of course

00:18:33.679,00:18:37.783
because they're you know
mostly application servers
so a lot of people are doing

00:18:37.783,00:18:43.255
AWS right and they have a
set of temporary credentials
which allows their

00:18:43.255,00:18:48.260
credentials to basically
expire. So, you know if you
don't get access to those

00:18:48.260,00:18:52.965
credentials within about 24
hours I think is the default
um you know those

00:18:52.965,00:18:57.303
credentials rotate out. So,
you know that's good, but,
even if those credentials

00:18:57.303,00:19:01.140
rotate out you're still
gonna have that source code
laying around on someone's

00:19:01.140,00:19:08.748
disk. So you know we found
uh source code for some
government contractors um

00:19:08.748,00:19:12.018
some large tech companies
and a lot of these are just
like boring internal

00:19:12.018,00:19:14.787
applications but a lot of
them also give really good
insight into how these

00:19:14.787,00:19:18.057
companies operate even just
having their source code is
really dangerous. Um you

00:19:18.057,00:19:22.395
know we got like source code
for a bunch of internal
applications to um like host

00:19:22.395,00:19:26.565
like huge databases for uh
some tech companies and
stuff so it's just like a

00:19:26.565,00:19:33.539
really, really cool uh
source code even if even if
that's all you get and at

00:19:33.539,00:19:36.776
the end of the day it's just
a medium kind of like a
medium risk finding. But, um

00:19:36.776,00:19:39.478
another thing we got was
tons of private keys I know
it says SSH up there but

00:19:39.478,00:19:43.182
just lots of uh private keys
think about like tls
certificates and what not uh

00:19:43.182,00:19:48.788
we're we have just like tons
of client and server keys.
And anytime you know you're

00:19:48.788,00:19:54.794
using one of those exposed
uh server keys you can be
man in the middle and some

00:19:54.794,00:19:58.297
of the client keys we got
you know just allow SSH
access you know you're like

00:19:58.297,00:20:01.801
going through people's bash
histories and trying to
figure out well where are

00:20:01.801,00:20:05.504
these IP's you know who's
who's running these servers
trying to figure it out. Um,

00:20:05.504,00:20:09.241
so you know that was a
little bit harder to um
determine if those creds

00:20:09.241,00:20:12.845
were valid so a lot of the
SSH keys and what not we
just directly handed over to

00:20:12.845,00:20:16.215
AWS and just responsibly
disclosed it with them to
make sure they got you know

00:20:16.215,00:20:22.855
word to their customers hey
your keys are just sitting
there uh you should probably

00:20:22.855,00:20:29.328
do something about that. So,
um another thing we got a
lot of which was kind of

00:20:29.328,00:20:33.332
surprising to me was uh like
SQL files that contained a
lot of people's uh personal

00:20:33.332,00:20:38.471
information and I think a
lot of these came from
developers they would uh you

00:20:38.471,00:20:45.711
know ste- or borrow some
data from production move it
down to a development

00:20:45.711,00:20:49.582
environment and so they can
play around debug their
application, do whatever

00:20:49.582,00:20:55.287
they needed to do but then
they kind of left their disk
out there just sitting there

00:20:55.287,00:20:59.291
and the SQL files contained
like thousands of peoples uh
you know usernames, hashed

00:20:59.291,00:21:04.530
passwords, email addresses,
phone numbers all of that
stuff. So, just some like

00:21:04.530,00:21:08.901
really nasty hygiene around
uh like SQL files and just
kind of all that. And um

00:21:08.901,00:21:14.073
another thing we got a lot
of were like wordpress
installations which are

00:21:14.073,00:21:19.712
pretty cool um they, if you
get a wordpress uh backup um
I-I should clarify that you

00:21:19.712,00:21:23.349
know the wordpress like uh
some of the- some of the
things we found were

00:21:23.349,00:21:26.919
wordpress backups actually
so uh in the backup you're
gonna have like the database

00:21:26.919,00:21:32.625
which will be a SQL file and
that'll contain all the
password hashes and also

00:21:32.625,00:21:38.564
like API tokens for third
parties which are always
great to find because they

00:21:38.564,00:21:41.700
allow you to escalate
further do uh you know more
privilege escalation kind of

00:21:41.700,00:21:45.437
in their own environment.
You can potentially start
taking over more and more

00:21:45.437,00:21:49.375
resources. So, you know
finding those API tokens was
also really, really great.

00:21:49.375,00:21:56.015
Um, and a lot of just kind
of off the shelf software it
seemed like a common pattern

00:21:56.015,00:21:59.652
would be developers again
kind of like uh just doing a
bunch of dev debug work,

00:21:59.652,00:22:06.725
pulling down some stuff,
like a drupal instance,
throwing it up there and

00:22:06.725,00:22:10.629
then just leaving it there.
So, um a lot of those kind
of uh credentials rolling

00:22:10.629,00:22:15.701
around and also VPN
credentials uh lots of open
VPN uh creds and some of

00:22:15.701,00:22:20.306
them were for legitimate
companies, who you know were
using it to access their

00:22:20.306,00:22:26.011
internal network so at you
know at that point, um it's
pretty much game over

00:22:26.011,00:22:30.516
because that's kind of one
of the big goals of an
external attacker is to get

00:22:30.516,00:22:34.920
internal network access so
uh that was really cool but
also I found a lot of people

00:22:34.920,00:22:38.490
had their like hide my ask
creds and other like VPN
providers just sitting out

00:22:38.490,00:22:42.194
there on these disks and
that made me really, really
cu- you know curious. Um,

00:22:42.194,00:22:47.366
just like what kind of
attacks could you
accomplish? You know you

00:22:47.366,00:22:49.568
could definitely just you
know abuse them but you also
like maybe man in the middle

00:22:49.568,00:22:52.404
them when they think they're
on their VPN's I'm not
really sure, but um I

00:22:52.404,00:22:55.608
thought that was really cool
to find. And also really
curious you know people are

00:22:55.608,00:23:01.513
kind of automa- automating
their hide my a** set ups.
Um and then also, just in

00:23:01.513,00:23:04.984
general we just found lots
of AWS keys, google Oauth
tokens, you know third party

00:23:04.984,00:23:12.958
API tokens, email passwords
think about like your SMTP
creds, your web apps are

00:23:12.958,00:23:18.063
using SMTP to send mail or
mail gun. Um, like one thing
I re- one app I specifically

00:23:18.063,00:23:22.968
remember uh very clearly is
something called uh it was
just called Surveillanceapp,

00:23:22.968,00:23:27.973
like that was the repo name
I found the- like that git
directory and it's just like

00:23:27.973,00:23:31.644
Surveillance-app okay and so
I looked at it, and it's
just a- a bunch of code that

00:23:31.644,00:23:38.651
just takes raw RTSP streams
and just dumps them into S3
buckets. So, you know

00:23:38.651,00:23:42.855
whoever or whatever this
thing is surveilling I have
all of their keys now you

00:23:42.855,00:23:47.693
know I can go read their
buckets, I can go you know
look at who's uh you know

00:23:47.693,00:23:51.764
who's being watched and I
could basically surveil
their surveillers and uh

00:23:51.764,00:23:55.734
that one was so hard to like
not touch. I did not you
know like it's so hard to

00:23:55.734,00:23:59.838
just not touch this stuff
and and want to just
explore, so that one in

00:23:59.838,00:24:03.809
particular you know like you
want to see like web cam
roulette you know you always

00:24:03.809,00:24:06.645
want to see what's behind
that webcam or like a you
know one of those uh crappy

00:24:06.645,00:24:10.949
cameras that uh you know
exist on the internet. So,
um that one in particular

00:24:10.949,00:24:13.986
was just kind of funny to me
it was really hard to just
kind of bite my tongue

00:24:13.986,00:24:19.591
there. Um, so yeah so
overall we just we just uh
looked for a lot of the easy

00:24:19.591,00:24:23.595
wins um you know when I ori-
when I initially started off
with a lot of this research

00:24:23.595,00:24:28.634
I kinda had this dream of
like oh I'll steal
everything under the sun and

00:24:28.634,00:24:31.370
then just deal with it later
and you'll kind of like go
through it but it just

00:24:31.370,00:24:40.045
turned out that uh kind of
prepping for the common
stuff you'd think uh would

00:24:40.045,00:24:42.381
be good it wa-was a good
approach um you know jus-
this just kind of goes to

00:24:42.381,00:24:45.784
show we had a lot of success
there so um yeah just a lot
of uh great stuff and um you

00:24:45.784,00:24:48.520
know sad I couldn't do a lot
more poking with what it
actually was you know when

00:24:48.520,00:24:56.061
you do find something, but
it was still really, really
cool to uh find all this

00:24:56.061,00:25:00.132
stuff. So, um, basically I
want to talk a little bit
about uh how I did find all

00:25:00.132,00:25:10.843
of this. Um, the-the
vulnerability and the
misconfiguration on the

00:25:10.843,00:25:16.181
surface is pretty easy to
exploit and you know my uh
you know that client eh back

00:25:16.181,00:25:20.719
in January you know I was
doing all that manually and
you can definitely do that

00:25:20.719,00:25:27.993
it's uh it's totally
possible but um, I basically
wanted to kind of automate

00:25:27.993,00:25:35.234
that process a little bit
because um, when you talk
about temporary credentials

00:25:35.234,00:25:39.738
and things like that it is
uh a bit tricky to deal with
those manually like if you

00:25:39.738,00:25:44.209
if you have some set of
temporary credentials you
know those are exposed for a

00:25:44.209,00:25:48.013
good window of you know 24
hours and if you get those
credentials you can

00:25:48.013,00:25:54.920
basically endlessly refresh
credentials. I wasn't you
know i didn't really get

00:25:54.920,00:25:57.956
like a you know look at this
too hard but uh it's
definitely a known technique

00:25:57.956,00:26:00.826
like if you get those
temporary IM credentials you
can just refresh them

00:26:00.826,00:26:08.000
endlessly until they
basically rotate them out
from underneath you. So, it

00:26:08.000,00:26:10.903
was really important to uh
have some automation under
your tool belt. You can

00:26:10.903,00:26:13.839
exploit some instances
manually, but a lot of the
ones you're gonna find are

00:26:13.839,00:26:16.775
just unlabeled and uh
difficult to detect. So, you
definitely want to have some

00:26:16.775,00:26:20.779
automation there and uh
there's basically a really
simple 3 step exploit

00:26:20.779,00:26:25.350
process here. Um, you know
you're just gonna pick a
snapshot and attach that

00:26:25.350,00:26:29.688
snapshot to uh your EC2
instance and then you're
gonna search it for secrets.

00:26:29.688,00:26:35.527
Um, but the problem is
there's about 120,000 disks
that are exposed across all

00:26:35.527,00:26:45.304
regions and a lot of them
are just um you-you're just
not sure what they're gonna

00:26:45.304,00:26:47.940
be because they're not
really labeled and a lot of
them are just garbage.

00:26:47.940,00:26:51.076
They're just totally
illegitimate disks um so
each o- each of these steps

00:26:51.076,00:26:58.550
has some nuances that are
you know kind of tricky. So,
uh, the first step well

00:26:58.550,00:27:09.895
clicker oh sorry uh clicker
was malfunctioning uh so uh
at a high level this is kind

00:27:09.895,00:27:12.297
of the architecture I used
um there's nothing really
crazy here I'm basically

00:27:12.297,00:27:16.335
just using an asynchronous
cue to uh send new snapshots
to workers and then that

00:27:16.335,00:27:19.771
master in the middle is just
a just a little application
that kind of coordinates

00:27:19.771,00:27:23.275
everything. So, that master,
he just pulls all the
snapshots uh about every

00:27:23.275,00:27:28.714
minute, looking for new
ones, when a new one is
detected it just-it just

00:27:28.714,00:27:35.220
puts it in the cue, and then
the worker in each region um
you know that the message is

00:27:35.220,00:27:44.496
destined for will just pick
up that message and start
the scraping process. Which

00:27:44.496,00:27:47.199
uh you know extracts all the
secrets and it just throws
it into the database. So,

00:27:47.199,00:27:50.469
it's a pretty simple process
and uh this-this uh this
asynchronous cue and worker

00:27:50.469,00:27:53.872
set up gives us the ability
to scale up and down the
worker processes as we need,

00:27:53.872,00:27:58.977
so we can save a little bit
of money too uh, which is
always nice. So, um and all

00:27:58.977,00:28:05.017
of the all of the code and
all of the um the scanning
has is within the default

00:28:05.017,00:28:11.623
AWS API limits. I didn't
have to um like ask for you
know I need to scan lots of

00:28:11.623,00:28:16.628
disks, um they let you do 5
disks concurrently uh across
everything so you know

00:28:16.628,00:28:20.999
within those limits, within
a default AWS account limit
I was able to- to scan these

00:28:20.999,00:28:25.871
disks. So, there wasn't
anything uh any-any like um
you know any-anything

00:28:25.871,00:28:31.343
preventing me from doing
this uh basically. So, uh
with the architecture out of

00:28:31.343,00:28:41.253
the way uh step 1 ex- pick
an exposed snapshot. So, uh
what to read? And, there's

00:28:41.253,00:28:45.290
kind of two ways you can go
about this. Uh, you can do
an exhaustive brute force

00:28:45.290,00:28:48.827
over all of the disks and
that's totally possible, uh
you can spend a you know a

00:28:48.827,00:28:51.930
couple months doing that um,
or you can kind of do a more
careful approach and I

00:28:51.930,00:28:55.000
initially started off doing
the brute force approach
like I said, I just wanted

00:28:55.000,00:29:05.611
to steal everything under
the sun you know, but that
just didn't really uh work

00:29:05.611,00:29:08.580
out. For mostly a couple for
basically like 3 reasons.
Um, I was just phishing up a

00:29:08.580,00:29:11.984
lot of garbage so, uh the
human genome project is on
AWS and there's you know

00:29:11.984,00:29:15.420
genome sequencing happening
so you get like 20 genome
sequencing disks in a row

00:29:15.420,00:29:17.823
and your just like man I
really want some AWS creds.
All I'm getting is a ton of

00:29:17.823,00:29:20.759
garbage. And there's no
faster way to you know just
uh thrash your database than

00:29:20.759,00:29:24.196
just filling it with
worthless uh worthless files
from that. So, um so there's

00:29:24.196,00:29:34.006
that and then each disk also
takes about 2-5 minutes to
uh to scan so, at a minimum

00:29:34.006,00:29:36.708
just the logistics of-of
cloning the disk, mounting
it to your image, and then

00:29:36.708,00:29:39.645
detaching it and force
detaching it um takes about
2-5 minutes. So, the more

00:29:39.645,00:29:49.554
disks you have to scan,
exponentially you know more
time y-you kinda spend um

00:29:49.554,00:29:54.793
not exponentially but just a
lot more time you spend uh
doing it. And, also, it just

00:29:54.793,00:30:01.700
costs money, so you know who
likes spending the profits
right? So, um so basically

00:30:01.700,00:30:12.477
I- I kind of came up with
a-a-a a way to filter out
these disks uh if each disk

00:30:12.477,00:30:18.817
has an owner id and that
owner id basically uh just
tells you who made the disk.

00:30:18.817,00:30:25.757
So, I looked at the owner
ids, so I just counted them
and I looked at the

00:30:25.757,00:30:29.528
frequency that owners would
publish disks. And, what I
found was there were a

00:30:29.528,00:30:32.964
couple of outliers that
published about you know uh
like 50 or 60% of the disks

00:30:32.964,00:30:35.600
there about 4 to 5 of them
uh one of them is Amazon
themselves. So, uh these

00:30:35.600,00:30:38.470
disks were basically just
kind of worthless. They're
just deployments of like

00:30:38.470,00:30:40.939
github enterprise and just a
bunch of stuff you don't
care about. So, um I took

00:30:40.939,00:30:43.508
those and I figured the
smaller owner ids would have
a better chance to kind of

00:30:43.508,00:30:48.346
reel in those credentials
an-and get them going. Um,
so, using that owner id I

00:30:48.346,00:30:53.018
was able to cut down the
number of disks I had to
scan to about 20,000 and uh

00:30:53.018,00:30:55.854
that just made the whole
process much faster and I
was able to finish it in

00:30:55.854,00:31:01.626
time um. So, the next step
is attaching the volume and
there's this like nice AWS

00:31:01.626,00:31:05.363
butterfly effect that
happens where uh you end up
wasting a lot of money

00:31:05.363,00:31:13.038
because this tiny bug in
your code ended up like
breaking everything. And um

00:31:13.038,00:31:15.640
there's some really
interesting failure points
that I didn't realize exist.

00:31:15.640,00:31:18.844
Like, I didn't know the
metadata url could fail um
and you know one day it

00:31:18.844,00:31:22.781
failed, it crashed my python
script, and I had to uh you
know just manually k-you

00:31:22.781,00:31:27.552
know kill those disks, those
zombie disks that were
laying around. But, it-it

00:31:27.552,00:31:30.355
kind of made me think about
well, if I'm testing for
SSRF and I have a scanning

00:31:30.355,00:31:33.692
you know some scanner and it
throws the metadata url at
the- at the you know target,

00:31:33.692,00:31:40.732
and that metadata url ha-
just happens to be broken
during that time period you

00:31:40.732,00:31:45.103
know I just got a false
negative and it kind of made
me rethink some of the AWS

00:31:45.103,00:31:50.475
testing um that I do myself
um just in simple cases like
that. And then also your

00:31:50.475,00:31:59.184
gonna have like a ton of
file system issues like lvm
disks that just you know for

00:31:59.184,00:32:03.255
some reason it just needs a
totally separate tool to
unmount and mount, I don't

00:32:03.255,00:32:06.124
know why but you know that's
just the way it is. So, um,
you're gonna run into a lot

00:32:06.124,00:32:08.527
of those issues and you kind
of just want to make sure
that you're uh you know

00:32:08.527,00:32:10.695
taking care of them. And
then, searching the disk for
secrets um, so one thing you

00:32:10.695,00:32:15.834
can do is you can use
something like DLP diggity
or um like gitrob or uh

00:32:15.834,00:32:18.703
trufflehog to kind of go
through like specific things
and that's pretty much what

00:32:18.703,00:32:22.240
I did, I just uh I stole the
grips from trufflehog, thank
you and then I kind of came

00:32:22.240,00:32:29.681
up with some-some of my own
to just uh look for the
private keys and what not so

00:32:29.681,00:32:35.720
um so th- so this process uh
was pretty-pretty straight
forward just mostly uh

00:32:35.720,00:32:40.292
repping for like really high
signal stuff and also uh I
did sniff the MIME type for

00:32:40.292,00:32:44.896
each file I would attempt to
kind of only scan files that
didn't look like um you know

00:32:44.896,00:32:49.634
binary or images or what
not. So, uh, so this kind of
cut down on the number of

00:32:49.634,00:32:55.473
files I had to scan for each
disk and led to you know
faster uh you know faster uh

00:32:55.473,00:33:00.478
scanning. So, um an-and
another interesting thing I
did with this as well is uh

00:33:00.478,00:33:06.618
because you have access to
all the default disks on AWS
I spun up all of the default

00:33:06.618,00:33:19.397
disks and made like a huge
blacklist of every file that
you don't want um and then I

00:33:19.397,00:33:21.132
manually like added some for
/etc shadow we always want
to steal shadow files so we

00:33:21.132,00:33:24.236
kind of go through this uh
this white listing and black
listing process and um all

00:33:24.236,00:33:27.472
of this uh you know ended up
uh kind of coming together
to make it pretty quick to

00:33:27.472,00:33:30.942
scan these disks you know,
each disk can kind of go- go
down in about like 7

00:33:30.942,00:33:35.146
minutes. So, that's pretty
good for uh you know for the
purposes of my research and

00:33:35.146,00:33:40.952
uh it- it ended up working
pretty good. Um, yeah, so we
just uh end up grepping

00:33:40.952,00:33:44.856
through everything and you
know it's just-just uh just
kind of like s- uh some

00:33:44.856,00:33:49.461
lessons learned um like have
tests for your code the AWS
butterfly effect is

00:33:49.461,00:33:54.966
definitely real and it's
going to return things uh
the a- the AWS APIs will

00:33:54.966,00:33:57.869
return errors you definitely
don't expect like the
metadata url failing. And

00:33:57.869,00:34:02.841
also, you definitely want to
design for multi-region up
front. Um, I made some

00:34:02.841,00:34:07.746
design decisions that ended
up kinda you know uh sc
messing that up a bit

00:34:07.746,00:34:15.320
because I didn't realize
snapshot ids are actually uh
not um unique across

00:34:15.320,00:34:19.190
regions. So, you could have
two regions, two different
snapshots, one snapshot id

00:34:19.190,00:34:23.929
and uh you know for the
primary key in your database
is that id your kinda gonna

00:34:23.929,00:34:31.436
have a bad time. So uh yeah
just make sure you uh think
about all of these things up

00:34:31.436,00:34:36.107
front before you start you
know uh kind of looking at
it. So, we've kinda talked a

00:34:36.107,00:34:41.046
little bit about um you know
what this is, how to find it
and uh we can talk about

00:34:41.046,00:34:53.291
fixing this problem. So,
remediation. What does
remediation look like? In

00:34:53.291,00:34:58.229
this case it is uh pretty
easy but there's a couple of
things that t-to keep in

00:34:58.229,00:35:03.635
mind. Uh, you definitely
want to go and search for
through your AWS account to

00:35:03.635,00:35:12.711
find any public disks that
are unencrypted. Um, if you
do find one that is sensi-

00:35:12.711,00:35:27.158
has sensitive information in
it and is meant to be uh is
not meant to be public, you

00:35:27.158,00:35:27.959
wanna take town the snapshot
first of all that should be
obvious to everyone. But

00:35:27.959,00:35:31.262
then you also want to rotate
your credentials and, I know
a lot of people like to skip

00:35:31.262,00:35:33.264
this step because it's a
pain, it's hard oh there's
that one system you know

00:35:33.264,00:35:35.133
that someone built 5 years
ago, we can't rotate the
creds I'm sorry you know,

00:35:35.133,00:35:37.969
uh, but you should
definitely rotate the
credentials because if you

00:35:37.969,00:35:42.374
think about the
vulnerability I'm scanning
every single disk every

00:35:42.374,00:35:45.677
minute basically, and as
soon as you make that
snapshot public, I'm going

00:35:45.677,00:35:49.647
to initiate a copy on it and
once that copy is initiated
it takes about 2 to 3

00:35:49.647,00:36:03.228
minutes to actually finish
the copying process and from
that point, the copy is

00:36:03.228,00:36:06.031
mine. If that copy finishes,
you can't do anything about
it and you're not even going

00:36:06.031,00:36:09.267
to know honestly. Um, and
that's one cool thing I
thought that was uh

00:36:09.267,00:36:14.072
interesting about this
attack surface is, unlike a
lot of other attacks um

00:36:14.072,00:36:18.309
w-with AWS if you're like
sending a lot of web
requests to try brute force

00:36:18.309,00:36:20.378
directories or so-or
something like that um
you're going to you know

00:36:20.378,00:36:23.314
show up in logs. But, in
this case you're not
actually directly attacking

00:36:23.314,00:36:29.554
a-a customer on AWS so
you're actually not gonna
log anything, and it's going

00:36:29.554,00:36:32.991
to be really difficult for
someone to actually detect
that you're cloning their

00:36:32.991,00:36:37.796
disks. There's basically no
way to do it. So, um, at
least that I could find you

00:36:37.796,00:36:49.908
know in my in my uh
research. There might be
some some logging set up

00:36:49.908,00:36:51.142
somewhere, but I couldn't
find it, so it's kind of a
sneaky attack you know

00:36:51.142,00:36:54.045
you're gonna, you're gonna
have your creds stolen and
you're going to uh not

00:36:54.045,00:36:56.381
really even understand how
it happened because there's
no logs. So, if I'm stealing

00:36:56.381,00:36:59.784
your disks every minute,
you're gonna wanna make sure
even if it's only a brief

00:36:59.784,00:37:03.188
exposure of the disks you're
gonna want to make sure you
actually rotate those

00:37:03.188,00:37:06.357
credentials because anyone
performing this attack is
almost certainly gonna have

00:37:06.357,00:37:08.793
a set up similar to mine
where they're just kind of
pulling it down all of the

00:37:08.793,00:37:11.930
time and uh an-and not
letting you you know kind of
get away with uh without

00:37:11.930,00:37:19.504
rotating those credentials.
So, um and then the last
step is of course to have a

00:37:19.504,00:37:25.143
little post mortem. You want
to make sure that you
understand how this

00:37:25.143,00:37:27.812
vulnerability happened in
the first place. You
definitely don't want to uh

00:37:27.812,00:37:37.222
just let your developers you
know just kind of go and uh
and just kind of have free

00:37:37.222,00:37:39.057
rain uh is this an SDLC
problem or is this like a
random script that we have

00:37:39.057,00:37:41.860
that we occasionally use and
just happens to create
public snapshots. Um, you

00:37:41.860,00:37:45.997
just don't really know that
so definitely check it out
and investigate how you got

00:37:45.997,00:37:52.070
there and uh you're gonna
want to uh you know uh go
through this process. Uh,

00:37:52.070,00:37:56.040
you can go through it
manually, I'm going to uh
delay the release of the

00:37:56.040,00:38:00.378
tool just by a couple of
weeks to uh coordinate with
Amazon and get some of these

00:38:00.378,00:38:04.783
uh disks you know taken
down, give people an
opportunity to go through

00:38:04.783,00:38:09.220
their own disks and just
make sure there's no
exposures um but after after

00:38:09.220,00:38:14.025
a couple of weeks I'm going
to release duffle bag and
you can you know just go

00:38:14.025,00:38:17.896
download that and that will
help you scan disks. And,
I've written it in such a

00:38:17.896,00:38:22.634
way so that um it will work
on kind of any disk you have
if it's private or public.

00:38:22.634,00:38:26.571
So, it can help in your own
organization uh scan for
disks you know because one

00:38:26.571,00:38:35.013
thing uh that I find a lot
is um you'll run a scout
suite report and then you'll

00:38:35.013,00:38:38.650
get a bunch of EBS volumes
that are unencrypted and
sometimes there's like 1,000

00:38:38.650,00:38:42.387
of them and you're like how
do I go through all of these
and figure out if any of

00:38:42.387,00:38:46.024
these are actually i-if
anyone should care about
them. So, this tool should

00:38:46.024,00:38:51.162
work with public and private
disks as well as like a wide
variety of file systems. So

00:38:51.162,00:38:55.567
you should be able to use
this to kind of help uh sift
through uh that pile of hard

00:38:55.567,00:39:00.438
drives you do need to go
through and uh in your own
organization. So, definitely

00:39:00.438,00:39:06.077
check out that in a couple
of weeks that will also help
remediate it and um we also

00:39:06.077,00:39:13.017
uh just kind of wrapping up
here, some more loot that I
thought was pretty funny um

00:39:13.017,00:39:16.521
so I always like to look at
my favorite password you
know I always like when I

00:39:16.521,00:39:18.957
crack passwords I always
like to you know pull out my
favorites, so I found like

00:39:18.957,00:39:25.063
nuglovers password and that
was for like a docker
account um so thank you

00:39:25.063,00:39:32.704
nuglover and if that's your
password you should probably
change it. Um, yeah, and

00:39:32.704,00:39:37.642
another thing uh I was
looking at some disks and I
found some creds on there I

00:39:37.642,00:39:41.112
was super excited I was you
know going through
everything and uh super-

00:39:41.112,00:39:46.651
super jazzed yes creds and
then I realized oh my God
this is a capture the flag

00:39:46.651,00:39:51.789
box, I just captured the
flag on a disk I didn't even
on a CTF I didn't even know

00:39:51.789,00:39:57.328
I was playing you know it's
just [laughter] it's like
yeah [applause] it was it

00:39:57.328,00:40:03.635
was it was pretty good,
thank you, thank you. Yeah,
so, so that was a great find

00:40:03.635,00:40:12.377
uh, and uh another thing I
found on there was wallet
dot dat and uh if you don't

00:40:12.377,00:40:16.648
know what that is, that's
your private key for your
bitcoin wallet um and I

00:40:16.648,00:40:19.951
found some like z cash
wallets too and everything
so. Basically when I found

00:40:19.951,00:40:24.522
those I mean my heart rate
went up so much you have no
idea I thought I was about

00:40:24.522,00:40:30.094
to be crypto rich and you
know like go live on my
island uh yeah um it didn't

00:40:30.094,00:40:35.433
turn out that way, I'm here
and not on an island so, you
can definitely know that uh

00:40:35.433,00:40:37.835
I didn't really get any
money from that but it was
mostly just people toying

00:40:37.835,00:40:42.140
with uh crypto currency
which is great but um you
know didn't get crypto rich

00:40:42.140,00:40:46.544
unfortunately with this bug
um but that would have been
nice. So, you know, maybe in

00:40:46.544,00:40:49.247
the future maybe someone
will throw their wallet dot
dat up there with a couple

00:40:49.247,00:40:54.552
hundred bitcoins, whatever
um and another thing I found
a lot of was SSH keys on

00:40:54.552,00:41:00.191
Windows machines. And I was
really curious about this
because I thought a lot of

00:41:00.191,00:41:07.632
people using AWS and and
what not would be um just
using linux or some other

00:41:07.632,00:41:10.768
disk and it just turned out
there was a lot of windows
disks that I wasn't

00:41:10.768,00:41:14.539
expecting and I had to go
and make better black lists
and what not. But like every

00:41:14.539,00:41:19.010
time I get an id_rsa off of
a windows box, I just kind
of smile a little bit

00:41:19.010,00:41:23.348
because you know it's kind
of like this cool. Um, so
there was like a surprising

00:41:23.348,00:41:26.184
number of Windows machines
uh out there and a lot of
them were misconfigured in

00:41:26.184,00:41:30.054
this matter to uh you know
to to facilitate uh all the
secret exposure. So, um lots

00:41:30.054,00:41:36.461
of Windows disks just some
really cool stuff there and
uh yeah I'm sure that you

00:41:36.461,00:41:39.364
know there's a lot more out
there you know I was only- I
was pretty timeboxed on this

00:41:39.364,00:41:42.867
research cause you know it
started in January and then
I kind of put it off and you

00:41:42.867,00:41:47.572
know uh you know just said
oh well you know noone noone
is really going to worry

00:41:47.572,00:41:50.274
about this, but then I
realized like how spread
this is and wanted to start

00:41:50.274,00:41:54.278
looking at it more and more
in detail. So, you know
there's still a lot out

00:41:54.278,00:41:57.548
there I was only able to
look at like text files and
what not there still could

00:41:57.548,00:42:02.053
be like database files and
lots of other interesting
information. Um, and I also

00:42:02.053,00:42:08.126
only you know I kind of
limited myself to uh disks
that were under about 100

00:42:08.126,00:42:10.962
gigabytes. So, there's still
like more attack surface and
the cool thing is new disks

00:42:10.962,00:42:15.066
pop up everyday, there's
about 5 or 10 disks that pop
up every single day. So,

00:42:15.066,00:42:19.504
it's like everyday you get a
nice little chance like a
present uh you know like

00:42:19.504,00:42:23.808
treasure hunt every single
day. Um, which is just fun
you know. Uh, you get you

00:42:23.808,00:42:27.879
get those uh emails back you
know like ooo found found
some creds. So, um just kind

00:42:27.879,00:42:32.617
of have some conclusions
here, um I manually
validated about 50 you know

00:42:32.617,00:42:35.820
sets of credentials and then
after that I was like
alright dude I can't do this

00:42:35.820,00:42:40.858
anymore like my eye my eyes
are bleeding you know from
like grepping out uh creds

00:42:40.858,00:42:44.262
and testing them on like a
million different things so
I would just kind of give

00:42:44.262,00:42:49.367
them to uh Amazon and let
them deal with it um, I kind
of estimate there's about uh

00:42:49.367,00:42:55.440
750-1250 you know high and
critical exposures across
all the regions um and this

00:42:55.440,00:43:00.211
is just kind of a direct
extrapolation from my uh you
know my region and the disks

00:43:00.211,00:43:04.982
I was able to look at in
this time. And, there wasn't
really a pattern for uh you

00:43:04.982,00:43:08.753
know who was impacted it was
just kind of like random um
software, uh government

00:43:08.753,00:43:12.757
contractors, health care,
everyone uh everyone was
just kind of random so not

00:43:12.757,00:43:19.363
really a whole lot of
patterns there. Um, and
overall it would cost about

00:43:19.363,00:43:24.802
$300 plus R & D time. Um, so
it's a very cost effective
attack which is not my

00:43:24.802,00:43:30.241
assumption it would not it
would not have been my
assumption and it wasn't my

00:43:30.241,00:43:32.543
assumption when I first
started this um because I
thought you know spinning up

00:43:32.543,00:43:35.146
these hard disks would
actually be pretty expensive
but it turns out if you

00:43:35.146,00:43:38.983
destroy them pretty quick
after you scan them, it just
doesn't cost that much. So,

00:43:38.983,00:43:43.955
it's a very cost effective
attack and because you can
kind of do it passively you

00:43:43.955,00:43:49.560
know over time and when a
new snapshot pops up you
just go scan it really quick

00:43:49.560,00:43:52.697
and turn it off um it's
pretty cheap to do which I
thought was great you know

00:43:52.697,00:43:54.966
getting a set of root keys
for 300 bucks it seems like
a pretty good deal you know

00:43:54.966,00:43:58.236
along with all the other
stuff so um you know the
research and development

00:43:58.236,00:44:02.640
time of course and uh yeah
and that was basically uh
you know just uh really cool

00:44:02.640,00:44:07.812
aspect of this I really
liked uh just super cheap,
free creds what could go

00:44:07.812,00:44:11.582
wrong? Um, yeah so that's
pretty much it uh you know I
just want to thank you guys

00:44:11.582,00:44:18.689
again for coming and I want
to thank these people as
well and uh thank you so

00:44:18.689,00:44:26.464
much for coming here today
um and that's pretty much it
so. [applause] yeah, yeah,

00:44:26.464,00:44:35.139
enjoy the rest of your
Defcon guys I'ma hit the bar
and I'll probably field some

00:44:35.139,00:44:38.609
questions outside if you
guys want to chat with me I-
I would love to talk about

00:44:38.609,00:44:42.680
this stuff and uh any ideas
you guys got um so yeah have
a good one, enjoy.

00:44:42.680,00:00:00.000
[woo][applause] >>yeah
>>thank you, thank you.

