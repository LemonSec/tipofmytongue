00:00:00.067,00:00:05.706
>>Uh, we are going to hear now,
from, uh, Jeff, but first, a
couple of announcements - uh, no

00:00:05.706,00:00:12.513
smoking or vaping in this room,
uh, of anything, of any kind, at
any time. Uh, if you manage to

00:00:12.513,00:00:19.386
sneak in outside beverages,
shame on you! Uh, uh, and uhm,
if you are, uh, consume any, uh,

00:00:19.386,00:00:26.059
anything that you brought it, it
needs to be water, and that is
all. That is all. Yeah? Cool!

00:00:26.059,00:00:31.565
So, Jeff here, uh, came in from
New York, he is giving an update
on a talk that he has given

00:00:31.565,00:00:36.737
before. He is unfortunately not
a first-time speaker, but it's
good that he came back! And was

00:00:36.737,00:00:43.744
not terrified into, uh, uh, uh
never returning. So, let's give
Jeff a big round of applause!

00:00:43.744,00:00:49.917
[applause] Have a good time,
man. >>Thank you. [applause] Hey
folks, so, uh, I'd just like to

00:00:49.917,00:00:56.089
start by saying that this sort
of a 45 minute condensed
snapshot of, uh, 105 minutes

00:00:56.089,00:01:02.562
talk submissions. So, this is
gonna get pretty dense. So, uh,
I'm Jeff, I work for NCC group,

00:01:02.562,00:01:06.700
uh, doing lots of research and
other hacking stuff, and, uh,
one of the things that brought

00:01:06.700,00:01:12.105
me to this topic was the fact
that I've done a lot of, uhm
pcap processing stuff. Uhm, and

00:01:12.105,00:01:16.276
also, dynamic instrumentation
and this kind of work has
actually tickled both of those

00:01:16.276,00:01:22.182
for me. Uhm, so, we're going to
be covering a whole bunch of
things. Uhm, and, uh, part of, a

00:01:22.182,00:01:27.421
big part of this talk is, is set
up and then, uh, the rest of it
is, kind of, a whole bunch of

00:01:27.421,00:01:31.825
very, uhm, fundamental,
primitive techniques that can be
used to build up some really

00:01:31.825,00:01:36.830
nasty things. Uhm, so, first,
eBPF - it is extended BPF what,
what is all this BPF nonsense?

00:01:40.067,00:01:46.206
So, BPF is "Berkeley Packet
Filter", it is this sort of
bytecode instructions set

00:01:46.206,00:01:52.679
virtual machine that runs in
kernel space ideally to process
packets in plane. And, the idea

00:01:52.679,00:01:58.685
is that, uh, when you run TCP
dump and you give it like a port
filter, uhm, TCP dump doesn't

00:01:58.685,00:02:01.688
want to, you know, process
through all the packets. And you
don't, and it's a lot of, uh,

00:02:01.688,00:02:06.293
it's very expensive to send it
down to a lot of user space for
it to print them out or not. So,

00:02:06.293,00:02:10.597
it sends up a little program to
the kernel and then the kernel
decides on which packets, based

00:02:10.597,00:02:15.702
on the program, to actually send
back down the user space to TCP
dump. eBPF on the other hand,

00:02:15.702,00:02:22.242
uh, is extended stuff is sort
of, takes the same general idea
but extends a very limited

00:02:22.242,00:02:26.580
instruction set to just
something that basically is ,
kind of, just almost 1-to-1 with

00:02:26.580,00:02:32.452
x86. Uhm, and it's, it's to the
point that you can actually,
basically compile, like C-code

00:02:32.452,00:02:36.990
down to it. Uhm, it's used for a
lot of this you can still do the
packet processing stuff but it's

00:02:36.990,00:02:41.895
also being used for kind of, uh,
dynamic tracing along the lines
of, uh, d-trace on other unix

00:02:41.895,00:02:47.300
systems. Uh, and everything it
does is basically done through
this BPF syscall. Uh, the main

00:02:47.300,00:02:52.005
two things you do with it are
your load programs and your
programs are the code and the

00:02:52.005,00:02:56.743
maps are these kind of internal
data structures that map, that
allow you to share data between

00:02:56.743,00:03:02.549
the code runs in the kernel and
code that you have that runs in
the user space. So, uh, eBPFs,

00:03:02.549,00:03:07.654
uhm, instruction set
architecture are like super
featureful. And because of that

00:03:07.654,00:03:12.059
there's a whole but of stuff
that's done in the kernel to
make sure it doesn't crash the

00:03:12.059,00:03:16.663
kernel or hang it and stuff like
that. Uhm, I'm not really
talking about that too much in

00:03:16.663,00:03:20.500
this talk, I talked about it in
my previous talk. We're just
gonna kinda go straight into

00:03:20.500,00:03:25.572
doing stuff with bb, BPF and
simply, simply hope that the
code works in the first place -

00:03:25.572,00:03:30.911
doesn't get rejected. So, uhm,
the general idea with this is
you create one of these eBPF

00:03:30.911,00:03:32.913
programs and then, uh, you
create some maps, you hook them
together, and ideally they run.

00:03:32.913,00:03:34.915
All of these things are file
descriptors on the userland
side. And, uh, the, the programs

00:03:34.915,00:03:36.917
will, you get to attach them to
various facets of the system
using very specific APIs and

00:03:36.917,00:03:41.922
then they kind of get called
inline to process the events,
uh, when they happen. So, uh,

00:03:55.902,00:04:01.575
most of the interesting eBPF
stuff requires cap sys admin -
the sort of God root privilege

00:04:01.575,00:04:08.181
of Root that makes Root, Root.
Uhm, but you can still do stuff
without it, uhm, specifically,

00:04:08.181,00:04:13.286
uh, socket filters. Uhm, there
are other types but they require
other, other privileges to

00:04:13.286,00:04:18.558
actually use. Uhm, the main
thing within this restricted
runtime, uh, that you need, that

00:04:18.558,00:04:21.862
you do, that's useful, is you
call these helper functions that
are essentially APIs to the

00:04:21.862,00:04:26.600
kernel, to actually do the heavy
lifting that you otherwise can't
do in a restricted environment.

00:04:26.600,00:04:32.672
Uhm, and then, the code is, is
verified both for like loops and
stuff but also to make sure that

00:04:32.672,00:04:35.642
the arguments are passing to
those helper functions aren't
gonna, like, crash the kernel or

00:04:35.642,00:04:37.644
corrupt memory inside the
kernel. Uhm, so, why eBPF? Uhm,
why am I doing all this stuff?

00:04:37.644,00:04:39.646
So, it's got a lot of
interesting APIs and things to
play around with, it was created

00:04:39.646,00:04:41.648
for a kind of high performance
packet processing, now it's just
being applied to anything and

00:04:41.648,00:04:46.653
everything in the kernel because
programmatic logic is the best
logic. Uhm,and it, it really

00:04:58.498,00:05:01.935
had, kind of, 2 modes - there's
no, no inbetween right now.
There is work on it but it's not

00:05:01.935,00:05:06.506
really done and it really just
scratched the surface. So,
basically, when you're running

00:05:06.506,00:05:11.545
your eBPF code it's either
running like super unprivileged
or does ALL of the privileges!

00:05:11.545,00:05:17.050
And there really isn't anything
between, uhm, which makes it
really hard to sandbox to the

00:05:17.050,00:05:23.390
point that, you know, if you're
actually using this, in say a
container, uhm, to use it, it,

00:05:23.390,00:05:27.394
like you have to turn on.
Certain things you have to turn
off all the security just to use

00:05:27.394,00:05:33.500
it properly and then that leaves
you a very vulnerable target to,
to attack. Uhm, so, why "evil"

00:05:33.500,00:05:38.872
eBPF? Uh, because there are a
lot of fun things we can do with
these fancy new APIs that the

00:05:38.872,00:05:42.809
people who made them were not
really thinking of because, uh,
they were trying to move really

00:05:42.809,00:05:49.216
fast. Uh, so, what does this
talk about? Uh, "shenanigans"
and, and what I mean by that is

00:05:49.216,00:05:53.220
we're going to be doing things
along the lines of, uh,
obfuscated, uh, obfuscated

00:05:53.220,00:05:58.692
communication channels between
process that are really hard for
someone on the system to track

00:05:58.692,00:06:03.129
unless they're using very
similar technologies to follow
them, and rootkits - lots of

00:06:03.129,00:06:08.602
rootkits. Uh, so, we're gonna
talk, start with a bit of
tooling on what we need to do to

00:06:08.602,00:06:12.639
get all of this stuff working up
and running. And then we're kind
of gonna jump straight into the

00:06:12.639,00:06:18.879
meat of it. So, you know, we
want to build all this stuff. We
want to get this eBPF code

00:06:18.879,00:06:22.849
running. But, you know we have
to, we have to, we have to
actually have like a tool chain

00:06:22.849,00:06:26.853
that does stuff so we have to,
you know, figure out a way to
compile code in this eBPF stuff.

00:06:26.853,00:06:31.024
Uhm, actually get it to load
another kernel. Uh, we have to
set up, uh, you know, comms

00:06:31.024,00:06:37.163
between the kernel and user
space code and eBPF code. Uh,
and then potentially we're also

00:06:37.163,00:06:43.470
worrying about, uhm, portability
across systems because if we're
building this thing, uhm, to

00:06:43.470,00:06:48.174
target and run on a system that
is not our own, we can't
necessarily assume it is is

00:06:48.174,00:06:53.179
going to be amenable to run, uh,
us running our code on it. So,
we wanna keep things very

00:06:53.179,00:07:00.053
lightweight and small. So, uh,
as with many things in Linux,
there's a lot of choices to

00:07:00.053,00:07:05.058
shoot various digits off with.
Uhm, so, uh, you kind of have to
pick a way to do a bunch of eBPF

00:07:07.661,00:07:13.967
stuff. Uhm, and, uh, heads up,
I, I went with the LLVM/Clang
approach but I think it's

00:07:13.967,00:07:18.738
important to kind of go cover
all of them in what they're good
at, what they're not good at.

00:07:18.738,00:07:23.877
So, at a high level, you know,
you can do raw eBPF
instructions, uh, by hand,

00:07:23.877,00:07:28.381
C-macro domain specific
language. Uhm, it's, it's often
used for very simple examples,

00:07:28.381,00:07:34.087
it's, it's hard to build up
bigger stuff with it. Uhm, you
could use this LLVM too chain to

00:07:34.087,00:07:39.793
compile C-code into these eBPF
architecture ELF binaries. Uhm,
there's a lot of infrastructure

00:07:39.793,00:07:46.766
to build it, uh, to build into
the links kernel, it's a, uh,
it's build infrastructure is a

00:07:46.766,00:07:50.603
little slow to get it done, so,
there are also, uh, tool chains
to do it out of tree, out of

00:07:50.603,00:07:55.875
Linux tree. Uhm, but then you
have to manage all your headers.
Uhm, and then at a high-level

00:07:55.875,00:08:01.348
there are things like "bcc" ad
"gobpf", which, uh, essentially,
uh, have a bunch of

00:08:01.348,00:08:07.687
instrumentation happens to your
c-code and they do a bunch of
stuff that kind of make a, a

00:08:07.687,00:08:13.493
variant of c that allows for
easier auto registering of
things. And then the rest of the

00:08:13.493,00:08:18.031
code you interact with from
either Python or go on the
userland side. After that, you

00:08:18.031,00:08:22.135
know, generally at a high-level,
just interact with the eBPF,
APIs, there are raw syscalls

00:08:22.135,00:08:26.439
because libcs don't actually
ship, uhm, wrapper stub
functions to call these things.

00:08:26.439,00:08:30.510
Uhm, but then there's lib bpf
which is maintained in the
kernel which basically solves

00:08:30.510,00:08:35.415
that problem and provides a
couple of other nifty things.
And then this magic "bpf load

00:08:35.415,00:08:41.321
dot c", which I'll get to in a
bit. So, uh, raw bpf, uhm, is
very unsanitary, uhm, yeah, I

00:08:41.321,00:08:45.025
wouldn't really recommend it for
building anything complicated.
Uhm, but you're going to be able

00:08:45.025,00:08:48.962
to generate bpf code - that
LLVM-toolchain and the kernel
may not be expecting, because it

00:08:48.962,00:08:53.900
may not be expecting the sorts
of things that the
LLVM-toolchain is going to build

00:08:53.900,00:08:58.905
and not stuff that you cobbled
together by hand. So, I'll leave
you with that. Uhm, and then,

00:09:04.677,00:09:09.949
the LLVM stuff is pretty simple,
assuming you've got a basic
toolchain that can kind of just

00:09:09.949,00:09:14.220
build this stuff for you. Uhm,
I've got a load of code
snippets, I'm not necessarily

00:09:14.220,00:09:17.757
gonna walk through all of them -
they're kind of more for
reference material. Uhm, so

00:09:17.757,00:09:20.927
don't feel like you've go to
read and understand every line
of code that appears in this

00:09:20.927,00:09:27.300
talk. Uhm, so, I have kind of
avoided using the Linux kernel,
uh, toolchain, because it's

00:09:27.300,00:09:31.738
really slow and I like to make
small changes and rebuild -
quickly. So, I've been using

00:09:31.738,00:09:36.876
this XTP project, XTP tutorial
repo, uhm, from what appears to
be Facebook developers who have

00:09:36.876,00:09:41.481
been doing stuff with, uhm,
packet processing and I'm not
using this for packet processing

00:09:41.481,00:09:46.286
all that much, but it works.
Uhm, it's a very hackible build
system. Uhm, and then, once you

00:09:46.286,00:09:50.723
actually have your binary, you
need to actually load it. So,
the interesting thing about how

00:09:50.723,00:09:56.996
this stuff works, is that to
reference those maps, uhm, you
actually have to take the, uhm,

00:09:56.996,00:10:02.302
instructions and then inline
into them map, uh, file
descriptors. You actually have

00:10:02.302,00:10:08.174
to create the maps first. Uhm,
and then shunt them into the
bytecode and then load that into

00:10:08.174,00:10:13.513
the kernel. And the libBPF and
BPF load, uh, do a lot of magic
to pull the code out of sections

00:10:13.513,00:10:18.017
of the binary and pass it up to
the kernel. Then there's the
high-level APIs, they're really

00:10:18.017,00:10:21.688
useful for things like tracing.
They make a lot of stuff very
easy, they take care of a lot of

00:10:21.688,00:10:25.291
heavy lifting. But they also do
a lot of magic and it could be
hard to figure out what's going

00:10:25.291,00:10:30.196
on at the deeper layers of these
things and they also require a
very extended runtime presence

00:10:30.196,00:10:34.767
to have access to headers and
their own libraries and do
things dynamically. So, you

00:10:34.767,00:10:39.105
basically have to get the whole
thing on top of a system to use
it in the, in the first place.

00:10:39.105,00:10:45.111
Uhm, I, so I went with the
LLVM/Clang approach, uhm, by
modifying the make files of that

00:10:45.111,00:10:50.450
xdp tutorial repo - I have been
able to make statically linked
binaries that also statically

00:10:50.450,00:10:55.455
link in their, uhm, eBPF ELF
file into it. And then I've been
using, uhm, MEFds called APIs to

00:10:58.358,00:11:03.630
actually load that buffer as a
file path, uhm, due to how..
Those libraries want to load it

00:11:03.630,00:11:09.602
from a file path and not just
straight from a buffer. Uh, BCC,
gobpf can't really reasonably do

00:11:09.602,00:11:15.708
this kind of stuff. I just want
to drop a binary on and have
like an extended everything but

00:11:15.708,00:11:19.279
BCC is really useful to get
started with a lot of this
stuff. Uhm, and it's useful for

00:11:19.279,00:11:22.916
kernel tracing but it doesn't
support all the kernel tracing
APIs I'll actually be talking

00:11:22.916,00:11:28.755
about today. So, let's talk a
little bit about doing bad
things with IPC, and, and this

00:11:28.755,00:11:34.494
really means, uhm, obscuring
communications, leading people
astray and sending data without

00:11:34.494,00:11:39.632
sending it and reading data
without reading it. So, uh, to
talk a little bit about the

00:11:39.632,00:11:44.637
maps, uhm, the maps basically
are what you use to share data
in the kernel and your userland

00:11:46.739,00:11:51.578
stuff. But it turns out you
actually don't need to attach
them to a bpf program to use

00:11:51.578,00:11:57.951
them. Uhm, you can just make the
calls from userland to store
data off, off process. Uhm, and

00:11:57.951,00:12:01.054
then the maps are actually, you
know, they're just file
descriptors and you just make a

00:12:01.054,00:12:05.925
special syscall to them to
interact with them. So, because
their file descriptors, we can

00:12:05.925,00:12:11.030
just pass them between processes
using things like unix domain
sockets, or binder if you're on

00:12:11.030,00:12:17.036
Android and have access to this
stuff. And basically this allows
us to do a very, uhm,

00:12:17.036,00:12:22.609
interesting form of IPC. Where
we'll send the file descriptors
across and then, uh, we'll have

00:12:22.609,00:12:27.347
the other process kind off write
into the map and then we in the
original process will read from

00:12:27.347,00:12:32.352
it or vice versa, and basically
just have a couple of indices in
your map, uh, spread out. Uhm,

00:12:35.588,00:12:41.127
so, in this case we have, uh, 2,
2 slots in the map - they're
each 256 bytes, they're indexed

00:12:41.127,00:12:43.329
by, like, just a regular
unsigned integer. And, uh, you
just kind of associate them

00:12:43.329,00:12:45.331
with, with one particular
processor writer-reader. Uhm,
sender-receiver. And you just

00:12:45.331,00:12:47.333
write to them using bpf-map
update elem and you read form it
out, uh, using bpf map, uh,

00:12:47.333,00:12:52.338
lookup elem and both of these
are just kind of wrappers around
that same bpf syscall - it just

00:13:02.982,00:13:07.720
has a bunch of different
sub-commands. Uhm, word of
warning though, all of the

00:13:07.720,00:13:11.324
things about these maps are
managed by the kernel -
including the sizes of their

00:13:11.324,00:13:16.396
values. So, uhm, if you're
blindly receiving these file
descriptors from untrusted

00:13:16.396,00:13:22.068
processes, you're very,
potentially going to run into
problems. So, uhm, if we go back

00:13:22.068,00:13:26.139
to this example, you'll not that
in a bpf map update elem call
here, you don't actually pass a

00:13:26.139,00:13:30.376
size but we've made sure that
the buffer is 256 bytes even
though we've only put "Hello

00:13:30.376,00:13:34.113
World" which is a couple of
bytes. The reason for this is
the kernel knows that if the

00:13:34.113,00:13:39.318
entry is, is 256 bytes it's
going to read those 256 bytes
from whatever pointer you give

00:13:39.318,00:13:43.623
it. So, if that buffer isn't big
enough, it's gonna start reading
the values after it and vice

00:13:43.623,00:13:48.561
versa when you're trying to pull
data out, if your buffer isn't
big enough to hold the max value

00:13:48.561,00:13:54.333
- it's just gonna clobber,
clobber wherever you put the
buffer, uhm, or after it really.

00:13:54.333,00:14:00.406
Uhm, but there's a way to deal
with this, uhm, bpf is very kind
of reflective - you can query

00:14:00.406,00:14:03.376
the kernel for all sorts of
metadata about the programs,
including the size of these

00:14:03.376,00:14:08.381
things. You can just dynamically
allocate the amount of size that
you need. Uhm, so, the programs

00:14:10.783,00:14:15.555
are a little bit interesting,
because they're actually just
sort of single functions and

00:14:15.555,00:14:19.525
every time you have really a
separate function it is actually
treated as a separate program.

00:14:19.525,00:14:24.864
Uhm, and, generally you call a
bunch of static inline functions
so they just get kind of bundled

00:14:24.864,00:14:31.137
into the 1 program. Uhm, and, it
turns out you can actually have
multiple of these - at the same

00:14:31.137,00:14:36.843
time, the same execution
context. You make, uh, special
bpf map called a "program array"

00:14:36.843,00:14:40.646
and you can fill it with these
file descriptions from user
space and then in the kernel

00:14:40.646,00:14:45.518
side you can call this "bpf tail
call function", uh, which will
essentially just jump the

00:14:45.518,00:14:50.590
context over and it will never
return. So, if there is a file
descriptor for a program in the

00:14:50.590,00:14:54.594
map in the indices, indices,
your, uh, index you're trying to
call. It'll just jump to it and

00:14:54.594,00:14:58.698
never come back. If it isn't, it
will just fall through and keep
executing. Uhm, so, the

00:14:58.698,00:15:02.969
interesting thing about this is
that these, these, uh,
programmer remaps can actually

00:15:02.969,00:15:07.974
be updated dynamically at
runtime. So, uh, you can just,
kind of, keep updating it and

00:15:10.777,00:15:16.582
each call will just call a new,
uh, function whenever, whenever
it sees it. Uhm, so, what this

00:15:16.582,00:15:21.587
means is, is that we can just
pass over some maps to another
process, have them kind of,

00:15:23.790,00:15:29.962
dynamically fill in, uh, their
own programs that will, uh, take
the spots in that program array

00:15:29.962,00:15:35.802
and then every time sort of
event happens such as a packet
is received. Uhm, it will call

00:15:35.802,00:15:41.407
their code which can then send a
message back to us. And so the
idea here is you actually need

00:15:41.407,00:15:45.044
to send 2, uh, map file
descriptors. You need to send a
program array that they're gonna

00:15:45.044,00:15:50.049
write into and then you actually
need to send the map, uhm, to,
to put in that it's going to

00:15:50.049,00:15:54.887
write to because it doesn't have
a global context awareness of
the file descriptors up on eBPF

00:15:54.887,00:16:00.059
side, so each program is
associated with its own maps,
they, uh, they simply can't call

00:16:00.059,00:16:04.630
each other separately through
the arrays. Uhm, so, in this
case we have a very simple

00:16:04.630,00:16:09.869
program that all it does is call
this bpf tailcall and then the
idea is that we send the file

00:16:09.869,00:16:15.441
descriptors over to, to the
other process. In our process
we're actually just gonna setup

00:16:15.441,00:16:18.845
something like a TCP socket
server and we're actually just
gonna keep sending packets to

00:16:18.845,00:16:23.349
ourselves so that at regular
intervals we can, we can trigger
the functionality to run in the

00:16:23.349,00:16:28.521
kernel And then we'll pull the
data out from, uh, from the map
afterwards. You, the, the thing

00:16:28.521,00:16:34.093
with this is that, why we need
the 2 file descriptors, is that
you will, uh, first, uh, in your

00:16:34.093,00:16:37.630
regular code that the one, uh,
that the writer is gonna be, is
your gonna, you're gonna be

00:16:37.630,00:16:41.801
dynamically updating, uhm,
you're going to be defining your
own map and generally speaking,

00:16:41.801,00:16:45.705
the way that the, the libraries
work, is they'll just kind of
create a map for it. You

00:16:45.705,00:16:49.475
actually don't wanna use that
map. You have to actually go
through that code after the

00:16:49.475,00:16:54.680
fact, iterate over it and shut
the, the actual map that you
want to be writing to which you

00:16:54.680,00:17:00.419
go over the unix domain socket
or binder, etcetera. Uhm, and
then reload that program and

00:17:00.419,00:17:06.192
then you put, uhm, you use bpf
map update elem to shunt the
program's file descriptor into

00:17:06.192,00:17:11.197
the, uh, the program array. Uhm,
and so, the demo for this, uhm..
The demo for this, basically to,

00:17:14.901,00:17:18.537
to start, we have a couple of
things going on here. I'm going
to briefly explain, on the right

00:17:18.537,00:17:25.077
side we have the code that
actually does the updating, uhm
and the iteration of, uhm, all

00:17:25.077,00:17:28.648
the functionality. Uh, so, it's
iterating through the
instructions and every time

00:17:28.648,00:17:32.285
there's one that would have a
map file descriptor, it puts in
the map that the map file

00:17:32.285,00:17:36.589
descriptor it's received and
then at the end it does, it
loads the program and then it

00:17:36.589,00:17:41.360
updates the map entry and in the
middle we have the, uh, the
actual code that's going to be

00:17:41.360,00:17:47.633
dynamically updated injected in
- it just prints out "DefCon 27"
and on the left, uh, we have the

00:17:47.633,00:17:51.871
original programs which are the
main entry point and then kind
of, this fall back

00:17:51.871,00:17:57.009
implementation that prints
"waiting" until, uh, until it
gets overwritten. And so, in

00:17:57.009,00:18:01.647
this example, uh, we're just
gonna, start, start the thing up
and, uh, the first couple of

00:18:01.647,00:18:05.718
times it's got that "Waiting"
printing, and now, it's been
updated dynamically after the

00:18:05.718,00:18:10.723
fact and so, this, essentially
allows us to, uh, do a bunch of
very, uh, dynamic updates. So,

00:18:13.526,00:18:19.031
hold on, there we go. Uh, so
that we can just sneak data in,
in places that people aren't

00:18:19.031,00:18:22.802
gonna be looking. You could do
all sorts of other stuff where
you could actually have data

00:18:22.802,00:18:27.573
that's being sent over the
socket that's, then it's being,
uh, potentially transformed in

00:18:27.573,00:18:31.711
kernel and then written out as
the real message to the bpf
buffer. So, if someone that's

00:18:31.711,00:18:35.848
just looking at what's going on,
in the socket, if that's not
actually the data that the

00:18:35.848,00:18:41.454
application is really operating
on, Uhm, so, to talk a little
bit more about the sockets. The

00:18:41.454,00:18:46.459
socket filters. Uhm, they are
really special. Because they are
the only ones you can use

00:18:49.095,00:18:55.568
really, uhm, from unprivileged
processes. So, uhm, I say this
"unprivileged" - docker actually

00:18:55.568,00:19:00.906
blocks the bpf t syscall unless
you're running capsys admin,
uhm, for whatever reason. But in

00:19:00.906,00:19:05.177
general, this is an unprivileged
dot call and doesn't require
anything. Uhm, it's also super

00:19:05.177,00:19:11.017
poorly documented, as it turns
out. So, privilege processes can
create, uhm, like raw IP

00:19:11.017,00:19:15.454
sockets, you know, this is what
ping does to send you those,
those the i-net packets over the

00:19:15.454,00:19:20.659
internet, raw. Uhm, but without
privileges, you know, you can
create normal tcp, udp sockets,

00:19:20.659,00:19:25.431
unix domain sockets either
stream sockets or datagram. When
you attach your socket filter

00:19:25.431,00:19:30.436
program to it, uh, either the
eBPF of the classic bpf, uhm,
different things happen. So, for

00:19:32.605,00:19:36.675
the raw sockets you, the, the
program will actually see the
packets from the beginning of

00:19:36.675,00:19:42.481
their ethernet frame. And for,
kind of, the regular IP-based
ones, like TCP, UDP, it'll see

00:19:42.481,00:19:47.753
them from the start of the
transport header, the UDP
header. For unix sockets, it

00:19:47.753,00:19:52.491
actually just, the start of the,
the array into the buffer is
actually just like the data

00:19:52.491,00:19:58.164
payload itself. Additionally,
while these, uh, socket filters
can't modify the packets

00:19:58.164,00:20:03.936
directly, they can drop them,
uh, which would just completely
break TCP. Uhm, but they can

00:20:03.936,00:20:09.542
also truncate them. Uhm, and so
that can cause, that can cause
very interesting things. And you

00:20:09.542,00:20:14.180
can potentially build a very
complicated, uh, setup that
might fool wire shark where you

00:20:14.180,00:20:19.985
say, uh, drop a packet that
contains like the real message
and then, uh, with a modified,

00:20:19.985,00:20:24.924
uh, TCP stack on remote coast
you have full control over, you
send another magic packet that

00:20:24.924,00:20:28.794
will actually be accepted and
then when someone tries to, in
wire shark reassemble the

00:20:28.794,00:20:34.033
stream, uh they see something
different from what your
application actually processed

00:20:34.033,00:20:39.105
because it was reading from the
packets and not from the
sockets. Uhm, so, this leads to

00:20:39.105,00:20:45.277
an interesting, uh, just attack
in general, like, you can also
read without reading - you don't

00:20:45.277,00:20:50.850
actually have to call "read" or
any receive syscall on the
socket because these events get

00:20:50.850,00:20:56.021
called every time the packet is
received, not when the userland
product actually tries to read

00:20:56.021,00:21:00.960
from the socket. So, if you just
set up a socket server and you
never actually receive on it,

00:21:03.062,00:21:07.800
you can have someone send you
data and then if someone's, uh,
trying to look at your data, not

00:21:07.800,00:21:14.240
like tcp dump, but through like
s-trace, they won't see the data
because s-trace doesn't actually

00:21:14.240,00:21:19.678
print out the strings that are
passed over, uhm the bpf syscall
for, uh, for reads and writes as

00:21:19.678,00:21:23.883
it turns out. They'll just see a
random pointer and they won't
know what's going on. Uhm, so

00:21:23.883,00:21:27.820
it's fairly simple to do this.
You just kind of register your
socket filter to it and then

00:21:27.820,00:21:33.359
every time that a packet comes
in, you just write it down to
the map that gets red out every

00:21:33.359,00:21:37.596
so often by the userland process
which then, it never, it never
calls read. Uh, you can also do

00:21:37.596,00:21:42.034
this in reverse direction. So,
you can, uh, you can write to
things and then block the data

00:21:42.034,00:21:44.570
from actually going out, such
that it won't actually, such
that it won't actually send

00:21:44.570,00:21:49.842
packets. But every writer will
then be shunted into the, the
memory in the kernel and then,

00:21:49.842,00:21:53.712
depending if you've actually
communicated this with the map
communication, you can then link

00:21:53.712,00:21:59.118
the data out to another map file
descriptor every time you hot
write. And, and anyone who's on

00:21:59.118,00:22:03.923
that computer will be like, none
the wiser about it. Uhm, you can
also use these techniques, using

00:22:03.923,00:22:07.693
other bpf programs that can
actually write to these packets.
So, they might be able to hide

00:22:07.693,00:22:12.031
data in and then take it back
out. So, that everything looks
normal to user lan level but

00:22:12.031,00:22:15.601
actually everything that goes
over the network - or doesn't go
over the network - is sort of,

00:22:15.601,00:22:20.506
some secret data so it's hard to
see what's going on. Uhm, but
they vary in required privileges

00:22:20.506,00:22:25.511
and you could do all kinds of
crazy stuff with them too. So,
as a demo of this, uhm, I have

00:22:27.613,00:22:34.453
this, uh, piece of code here
that runs a regular tcb socket
server and it never calls

00:22:34.453,00:22:38.924
receive, read, receive from,
receive message - all of these
kind of standard syscalls for

00:22:38.924,00:22:43.829
reading data from a socket and
on the right side I just echo
into, like, telnet into the

00:22:43.829,00:22:49.835
service. So, I'm running s-trace
on this to prove that like no,
none of these syscalls are being

00:22:49.835,00:22:55.274
issued and so if someone were
looking for these, they just
would not see anything happen.

00:22:55.274,00:23:01.046
[coughing] So, we've now, we get
the data from this - 41, 42, 43
- that's all just hex for, you

00:23:01.046,00:23:05.885
know, capital A, B, C, D
etcetera. And, uh, the signal
stuff that goes on at the top is

00:23:05.885,00:23:10.222
just because that's how I'm
doing, uh, I'm checking, I'm
pulling at the eBDF buffer. I

00:23:10.222,00:23:14.360
have a signal handler that pulls
that at like once a second. So,
I have not actually, if you look

00:23:14.360,00:23:18.697
at this, I have not issued any
of these standard reading
syscalls on the socket and yet I

00:23:18.697,00:23:25.337
have somehow I have obtained the
data that was sent to it. Uhm,
you can do all sorts of stuff to

00:23:25.337,00:23:31.010
build up on this to hide data
from people who, depending on
how they're trying to look at

00:23:31.010,00:23:36.482
what you're doing. So, let's
talk a little bit about the,
uhm, the kernel tracing. So,

00:23:36.482,00:23:41.220
eBPF, uh, basically supports a
whole bunch of modes to do
dynamic instrumentation of

00:23:41.220,00:23:46.525
kernel functionality, to see the
data that's flowing through.
Uhm, this is very privileged,

00:23:46.525,00:23:52.865
uhm, and can be used to, you
know, compromise systems as it
turns out and these things could

00:23:52.865,00:23:58.504
read arbitrary kernel memory and
user space memory. And this
presents us with an interesting

00:23:58.504,00:24:04.943
opportunity for covert IP on a
system we've really kinda posed.
So, we can actually just read

00:24:04.943,00:24:09.114
data out of processes that they
were never actually going to
send to the kernel. They never

00:24:09.114,00:24:12.584
attempted to send it there, it
was just sitting in memory and
they're not issuing any

00:24:12.584,00:24:18.390
syscalls. Also, what they can
do, they can issue bad syscalls
that are gonna get rejected and

00:24:18.390,00:24:22.494
the data's not actually gonna
make it through the kernel so,
like, if they do a send on a bad

00:24:22.494,00:24:27.800
file descriptor, it's not gonna
result in a packet and so TCP
dump is not gonna see it. But we

00:24:27.800,00:24:32.805
can. So, I, uh, I like to do
this mind reading trick, uh,
with the code, uh, where, uh,

00:24:36.041,00:24:40.813
because close is the magic
syscall it takes a file
descriptor and that's it. FIle

00:24:40.813,00:24:44.216
descriptors have to be
non-negative, they're
non-negative integers. So,

00:24:44.216,00:24:48.620
anytime it receives a negative
integer, it just rejects it and
doesn't do anything and it's

00:24:48.620,00:24:54.626
kind of by deponent. So, uh,
what you can do here is you can
hooked closed and you can just

00:24:54.626,00:24:59.465
wait for like certain magic
negative file descriptors, to
start a stateful handshake with

00:24:59.465,00:25:04.770
a particular, uh, process. And,
uh, after that, just start
unmarshalling data out of these

00:25:04.770,00:25:09.875
negative file descriptors, to
communicate,with, with yourself,
basically, and, you know, if

00:25:09.875,00:25:14.079
someone's looking at this,
probably, they don't really like
it closed if they see it, they

00:25:14.079,00:25:17.916
may think something is wrong.
But are they really gonna
attempt to figure out what's

00:25:17.916,00:25:22.621
going on here. Maybe, maybe not.
So, that's a neat trick like it
would just absolutely corrupt

00:25:22.621,00:25:24.623
memory. Uhm, so, there is this
special bpf probe-like user help
function, uh, which I talked

00:25:24.623,00:25:26.625
about in my previous talk nd
this is sort of the that gives
it rootkit capability. So, when

00:25:26.625,00:25:28.627
you use this, it raises an event
that like goes out on d-message,
but, it's so useful. Uhm, you

00:25:28.627,00:25:30.629
can, also, when you're using
these things, you can actually
abort syscalls at entry. Uh,

00:25:30.629,00:25:33.565
syscalls on a couple of
functions of the kernel that
have this special macro that

00:25:33.565,00:25:35.567
denotes that it can be, uhm,
aborted. But, basically, this
bpf override return allows you

00:25:35.567,00:25:39.338
to bail out of executing this
syscall and you can also just
give an arbitrary return value.

00:25:39.338,00:25:44.343
So, uhm, you know, we need to
write things that are useful and
most of the interesting, uh,

00:26:11.970,00:26:17.142
data that are in syscalls are
pointers to userland memory.
Uhm, so, we can actually,

00:26:17.142,00:26:21.880
potentially override strings and
other trucks that are being, uh,
sent to the kernel or written

00:26:21.880,00:26:27.619
back by the kernel. Uhm, uh, and
we can just prevent syscall from
reaching the kernel. So, there

00:26:27.619,00:26:32.624
are a couple of variants of this
attack. Uhm, this kind of way of
building a rootkit, uhm, you can

00:26:34.793,00:26:40.165
redirect syscalls, you can
modify them, you can make opens
for a, like a, a shell file, a

00:26:40.165,00:26:45.604
shell script. Open a path that
is something you control,
somewhere else, so it just opens

00:26:45.604,00:26:50.642
and reads your code. You could
also, every time they read, you
could just send bad data back to

00:26:50.642,00:26:55.214
it, uhm, and just lie. So you
can, uh, after the kernel has
written the code, you can, you

00:26:55.214,00:26:59.551
can stomp over it with your own
data. You can also just fake the
return by aborting the call and

00:26:59.551,00:27:03.622
write the data yourself. And you
can also just completely
blackhole the data so they just

00:27:03.622,00:27:08.260
can't communicate with the
outside world. Uhm, so in the
first one we're going to be

00:27:08.260,00:27:12.731
modifying the data that's being
sent to the kernel. Uhm,
generally speaking, the way this

00:27:12.731,00:27:17.970
works is you set kind of a
tracing hook, a k-probe, is on
this syscall entry, k-probe gets

00:27:17.970,00:27:23.275
called the, the syscall return,
after the kernel's, like,
processed it. And, generally

00:27:23.275,00:27:27.679
speaking, uh, you know, when
you're hooking the syscall, all
the calls across the entire

00:27:27.679,00:27:31.817
system, regardless of container,
make it they're all sharing the
same kernel, they're all using

00:27:31.817,00:27:35.821
the same syscalls. All of them
go through that. And so,
potentially you're having a lot

00:27:35.821,00:27:39.625
of throughput going through
there. And so, if you're going
to be messing around with this,

00:27:39.625,00:27:42.294
you're actually wanna be very
careful you're not gonna crash
stuff. So, you wanna, you wanna

00:27:42.294,00:27:47.499
kind of filter through and
determine if the particular
process that's calling in, in

00:27:47.499,00:27:51.737
its particular inputs, are stuff
you actually wanna mess with,
otherwise you might just crash

00:27:51.737,00:27:57.509
the system accidentally. Uhm,
when you do this, uh, you could,
you could just overwrite it and

00:27:57.509,00:28:02.247
then be done with it. But, if
you wanna be sneakier, you
actually want to persist the

00:28:02.247,00:28:07.586
stack data, or keep data
wherever it was from the, uh,
the userland process that's

00:28:07.586,00:28:13.258
being sent up. Uhm, so that, on
the return, after the syscalls
have finished, uh, like,

00:28:13.258,00:28:17.863
processing, but before context
returns back to userspace, you
can actually try and write back

00:28:17.863,00:28:21.266
their data to it. So, if they
checked it after the fact, it
would look clean. Like nothing

00:28:21.266,00:28:26.805
happened. And the way that you
want to do this, uhm, is you
wanna use the process ID, uh,

00:28:26.805,00:28:30.809
thread group ID, and then maybe
a file descriptor as well, if
you're keeping track of it.

00:28:30.809,00:28:35.480
Because, uh, all of this is
essentially stateless, other
than the data that you maintain

00:28:35.480,00:28:40.852
in your bpf maps, so you kind of
can't maintain context without
using those maps. And the only

00:28:40.852,00:28:44.990
anchor point you have for
context is this kind of, very
basic information about the

00:28:44.990,00:28:48.860
process and kernel thread it's
using. Uhm, but that, but that's
good enough actually, as it

00:28:48.860,00:28:54.399
turns out. Uhm, and the, the
opposite approach, where you're
just modifying the data, you do

00:28:54.399,00:28:59.271
basically exactly the same
stuff. Uhm, word for word. But,
uh, you do your filtering to

00:28:59.271,00:29:03.508
determine whether or not you're
gonna do stuff at the entry
point. Because the entry point

00:29:03.508,00:29:08.146
is the one that actually
receives the arguments. And, at
the end, uhm, you can either

00:29:08.146,00:29:12.484
have persisted the arguments and
then decide at the end if you
wanna do something or not. Or

00:29:12.484,00:29:15.821
you could have just decided at
the beginning. But, it's at the
end, after the syscall's been

00:29:15.821,00:29:20.859
processed that you need to write
the data because otherwise, if
you overwrite their stuff, the

00:29:20.859,00:29:25.163
kernel's just gonna overwrite
you again. Uhm, and then
nothing's gonna happen. Uhm, but

00:29:25.163,00:29:28.700
other, other than that, it's
basically the same exact
approach. "Black hole-ing"

00:29:28.700,00:29:34.206
everything is fun, uh, you, you
can just block the syscalls, but
you can do so much more than

00:29:34.206,00:29:38.076
that. Because you can just
pretend to be the kernel,
essentially, and write in

00:29:38.076,00:29:42.681
arbitrary data as if they had
succeeded. And so, they think
they're communicating out, they

00:29:42.681,00:29:47.386
think they've alerted, like the
IDS or whatever it is, that
something bad is going on. They

00:29:47.386,00:29:51.356
think they're writing out to
like their, their, log stash or
whatever, it hasn't happened.

00:29:51.356,00:29:56.628
It's not happening. They think
it's happened, it hasn't. Uhm so
we, that, that's really useful,

00:29:56.628,00:30:00.899
depending on if you're trying to
like reverse something and you
don't want to let it kind of

00:30:00.899,00:30:05.504
communicate out. Whereas, like,
if you're attempting to use set
comp to deny stuff, you know,

00:30:05.504,00:30:11.810
it's gonna know that it's got
rejected. And it's gonna be able
to act accordingly. Uhm, so,

00:30:11.810,00:30:16.815
there's one other limitation to
this probe right user call - you
can't write non-writable pages .

00:30:18.884,00:30:24.256
So, you know, we can't just
clobber the text section with
shell code, unfortunately. Uhm,

00:30:24.256,00:30:28.226
at least for like properly
compiled programs, if they've
got bad, bad protections on

00:30:28.226,00:30:33.265
their sections, then, or they
jit stuff a lot, uhm, things
change, uh, but we can't assume

00:30:33.265,00:30:38.737
that for all processes. Uhm, so,
this limits us to, kind of,
what's in the stack heap other

00:30:38.737,00:30:43.208
sections that are writable. Uhm,
things like function pointers,
uh, same file descriptors, maybe

00:30:43.208,00:30:46.745
they have, they generate scripts
like dynamically or shell
commands that we could write

00:30:46.745,00:30:51.683
into. Uhm, things like that. But
can't, we can't guarantee that
these things are there. The only

00:30:51.683,00:30:57.556
thing that we can kind of, at a
high level guarantee exists, is
their return addresses. Uhm,

00:30:57.556,00:31:02.494
mostly. So, I put together kind
of a very, uh, concrete way of,
of writing raw payloads into

00:31:06.264,00:31:11.269
userland processes from eBPF,
uh, kernel tracing stuff. And
this is kind of the stuff you

00:31:11.269,00:31:15.273
wanna do, uh, you can do for
real rootkits to get into, like,
kit 1 which is what I did in my

00:31:15.273,00:31:20.679
previous talk. But, uh, to
really cover the whole thing,
there's a lot of things to do,

00:31:20.679,00:31:24.750
so, you can either start with
kind of 1 or 2 ways of looking
at it. You can say that you want

00:31:24.750,00:31:28.920
1 payload that you wanna
indiscriminately inject into all
processes and if you wanna do

00:31:28.920,00:31:32.224
that, you need to, you need to
have it be working on something
like a shared library that

00:31:32.224,00:31:36.895
they're all gonna load, like
their libc. So, jewel lib c is a
great target for this because

00:31:36.895,00:31:41.099
it's got all sorts of wacky
functionality built into, uhm,
like, a deal open

00:31:41.099,00:31:45.670
implementation, which allows you
to dynamically download a shared
library from a file path. And,

00:31:45.670,00:31:48.640
um, and the moment a shared
library is loaded, it actually
gives it arbitrary code

00:31:48.640,00:31:52.210
execution right then and there.
So, all you have to do is scan
for some gadgets, put it

00:31:52.210,00:31:55.847
together, uhm.
budda-bing-budda-boom, you have
code execution if you can get

00:31:55.847,00:32:00.619
your opchain to actually like
load into a process. Uhm, very
reliable, uhm, they have every

00:32:00.619,00:32:04.456
gadget you could ever want to
make this across every version
of the binary I've looked at

00:32:04.456,00:32:11.129
across multiple different
distros. Uhm, then, you know,
you wanna do your raw payload,

00:32:11.129,00:32:15.567
but maybe, maybe you're not
gonna be dynamic, you're not
gonna be generating like this,

00:32:15.567,00:32:17.569
maybe you're dealing with a
statically linked binary, maybe
you're dealing with one that

00:32:17.569,00:32:21.473
does code gen. And where you're
getting called from isn't
necessarily stuff that you can

00:32:21.473,00:32:25.410
really know what's going on
easily so, uhm, I'll talk a
little bit about, uh, dynamic,

00:32:25.410,00:32:30.949
uh, generation of raw gadgets
and things. So, when we do this
eBPF stuff, we need to, you know

00:32:30.949,00:32:34.920
pick some syscalls that ideally
are target, target process will
be calling. And we're gonna

00:32:34.920,00:32:38.423
register some k-probes, some
k-rec probes on it. Just so we
can get stuff, just so we can

00:32:38.423,00:32:44.296
get a userland context to be
able to get the ability to 1 -
have pointers to, uh, to their

00:32:44.296,00:32:48.233
userland and also actually be on
the right kind of processing
context to write the data to

00:32:48.233,00:32:54.940
them. Uhm, so, then, within the
code, much like before, we kind
of need to sift through and, uh,

00:32:54.940,00:33:00.245
see that the particular calls
are actually coming through
processes we want. Uhm, the only

00:33:00.245,00:33:04.182
system you could very easily,
the only process you could very
easily detect is pit 1, because

00:33:04.182,00:33:07.986
it's pit 1 across the entire
system regardless of containers
and namespacing and things like

00:33:07.986,00:33:12.424
that. The real pit 1 is always
pit 1 for real. Uhm, so it's a
very easy target, uhm, but,

00:33:12.424,00:33:16.628
other than that, you know, if
you wanna know that someone's
doing a specific, a specific

00:33:16.628,00:33:20.966
process. So, if you're gonna
change the world view of a
process, uhm, and not target

00:33:20.966,00:33:25.403
others, you kinda need to watch
what it's doing and some state
about it to know that it's

00:33:25.403,00:33:30.642
actually the one that you wanna
hook. Then, there, there are two
step 3s here on purpose. The

00:33:30.642,00:33:34.946
first one is when you're running
this kind of pre-generated raw
payload. And the second one is

00:33:34.946,00:33:40.185
when you're gonna try and
dynamically generate it on the
fly. So, in the former, there's

00:33:40.185,00:33:44.222
in your, in your k-probes, uh,
when they get called, they
actually receive all of the user

00:33:44.222,00:33:48.927
land, uh, registers that were
that were the state of the
registers when the syscall was

00:33:48.927,00:33:53.932
made to trap upto the kernel.
And so, we can just like pull
out the instruction pointer, uhm

00:33:56.101,00:34:01.940
and, and we know that that is
probably, that's gonna be made
in libc somewhere. So, we know

00:34:01.940,00:34:06.778
exactly the offset from the
start - just by what the address
of the syscall instruction was.

00:34:06.778,00:34:13.051
And, like, then we know exactly
where we are. Uhm, if, on the
other side, depending on kind

00:34:13.051,00:34:19.257
of, how ridiculous the binary
you're dealing with is, uhm, you
could do the same thing but the,

00:34:19.257,00:34:24.296
the instructions at, at where
it's executing may not all, uh,
be that useful. They may be, you

00:34:24.296,00:34:27.532
know, in the heap somewhere
where there's not actually a
whole bunch of code it's just a

00:34:27.532,00:34:34.372
bunch of jitted code. Uhm, and
so, you probably wanna, uh, scan
through the stack and so you can

00:34:34.372,00:34:38.343
do this, uh, you just kind of
look at valid stack offsets from
the where the, uhm, where the

00:34:38.343,00:34:43.014
stack pointer was, uh, stack
pointer register. And then, you
essentially want to look back

00:34:43.014,00:34:47.485
and see if the thing that, like,
the former instruction that
would have been, uhm, the one

00:34:47.485,00:34:53.892
before, uh, so, when you like an
x86 when you make a call
instruction, uhm, it's going to

00:34:53.892,00:34:57.896
increment the, uh, the address
and then put that in the stack.
So, what you're returning to is

00:34:57.896,00:35:02.033
the next instruction. We need
the previous instruction that
actually issued the call. And

00:35:02.033,00:35:06.871
so, we can then try and detect
what that instruction was and if
it was a call, and it actually

00:35:06.871,00:35:11.109
looks like it went to where we
are and everything's good. But
it may have actually been a plt

00:35:11.109,00:35:15.847
entry and those are actually,
uh, those are like the entries
to dynamically linked functions,

00:35:15.847,00:35:22.487
like your lib C. And, so those,
uhm, are the call will actually
go to a jump and the jump will

00:35:22.487,00:35:26.791
go to where, where the code
you're, you were, it was
formally executing before maybe

00:35:26.791,00:35:30.328
the syscall was. And so, you
need to just parse those
instructions a little bit to

00:35:30.328,00:35:34.899
dump out kind of the offsets and
things, and then, and then you
know where you are. Uhm, after

00:35:34.899,00:35:36.901
that in both cases, uhm, you can
just, uh, go backwards as far as
you can until you get page

00:35:36.901,00:35:38.903
faults essentially that are free
for you. And don't crash
anything. And then you know

00:35:38.903,00:35:44.409
where the memory regions
started. And then you can just
scan the data straight forward

00:35:44.409,00:35:49.414
and dump it all out until you,
again, reach a page that's not
read-writable etcetera. After

00:35:54.586,00:35:59.057
that, you potentially are going
to, uh, generate your payload
based off of this. So, you've

00:35:59.057,00:36:03.595
dumped out all of the raw memory
of process, you know exactly
where it sits, uhm, you can just

00:36:03.595,00:36:07.632
attempt to find gadgets and
build them into some generic
payload that does whatever you

00:36:07.632,00:36:13.371
want it to do. Uhm, you just
need to make sure there's a
clean up routine. Uhm, after

00:36:13.371,00:36:18.209
that we go back in with another
hook and we need to do the stack
skimming stuff again because we

00:36:18.209,00:36:23.148
need to, uh, find out, uh, where
we were so that when we, when we
write into the raw payload, this

00:36:23.148,00:36:27.185
time, it's actually in the right
place, so when the syscall
returns, then the kind of

00:36:27.185,00:36:31.690
syscall stub will then attempt
to return back in user space and
it'll jump right into a raw

00:36:31.690,00:36:36.694
payload. Uhm, before we do this
though. Uh, we need to back up
the memory from userspace.

00:36:36.694,00:36:40.065
Because we're just gonna clobber
all of it, we need to return
cleanly so the thing doesn't

00:36:40.065,00:36:45.937
crash after our code runs. Uhm,
and so we do, is we, we not only
need to get the general stacks

00:36:45.937,00:36:49.808
we're writing to, we also need
to backup all the space we're
potentially going to clobber as

00:36:49.808,00:36:56.748
part of our chain itself. Uhm,
then after that, we write it in,
the opchain starts executing and

00:36:56.748,00:37:02.287
it's done, it's whatever it's
magic task is, that's up to you.
And then it starts its

00:37:02.287,00:37:06.758
co-ordinated cleanup routine and
what this needs, what I like to
do with this is I like to do

00:37:06.758,00:37:13.098
those hooks on close to signal
that I, it, it should, uh, the
kernel side should write back

00:37:13.098,00:37:16.968
most of the stack. Not all of it
because we have we have a couple
of ROP gadgets we still need.

00:37:16.968,00:37:21.639
So, last ROP, uh, as we do this
we're actually gonna write some
new ROP gadgets pass the end of

00:37:21.639,00:37:25.710
the stack, uhm, and those are
gonna help with our cleanup
routine. The remaining ROP

00:37:25.710,00:37:29.848
gadgets that are still there
that we haven't overwritten with
the backed up data. Uh, those

00:37:29.848,00:37:34.018
will then execute once you
return back to userspace. And
they'll exist simply to shift

00:37:34.018,00:37:38.690
the stack pointer to where the
new ROP gadgets we put are,
which weren't actually in what's

00:37:38.690,00:37:43.294
considered the stack, until we
shifted the stack pointer. The
new ROP gadgets will then exist

00:37:43.294,00:37:45.296
to overwrite and, uh, restore
the backed up data to the, the
last ROP gadget we didn't

00:37:45.296,00:37:47.332
overwrite. And then it will, uh,
set a return value for all the
way back the thing we actually

00:37:47.332,00:37:52.337
hooked on. Uhm, and then it
will, uh, uh, ship the stack
pointer back to where it needs

00:37:54.706,00:37:59.711
to be and then the code will
return back into whatever it
actually called the original

00:38:04.816,00:38:09.654
syscall wrapper in the first
place. And everything's clean
and it never, it didn't now what

00:38:09.654,00:38:14.659
happened. Uhm, but there's a
limitation on these, on these
k-rpobe, k-upoint trace APIs.

00:38:17.061,00:38:22.967
Uhm they all use the sysFS -
uhm, it's a special mounted
files system that does a lot of

00:38:22.967,00:38:28.740
magic stuff on Linux, a lot of
things are under it. Uhm, but,
docker by default has an

00:38:28.740,00:38:34.479
AppArmor profile that blocks
access to this and docker also,
doesn't mount it as a fully

00:38:34.479,00:38:39.684
writable, uhm, mount. Which you
otherwise need to do this, this
k-probe tracing stuff. However,

00:38:39.684,00:38:44.189
eBPF is another type of tracing
program that doesn't interact
with the sysFS at all. And there

00:38:44.189,00:38:48.560
hasn't actually been all that
much tooling built on it yet.
Uhm, even BCC, uhm, the, the

00:38:48.560,00:38:54.866
main, like, instrumentation
framework, doesn't actually
support these raw tracepoints.

00:38:54.866,00:39:00.805
These are magic, uh, and it's
got a very complicated process
for setting it up - step 1, you

00:39:00.805,00:39:06.010
call the system, the BPF syscall
with the raw trace point open
subcommand and you literally

00:39:06.010,00:39:12.317
just give it a name of the
registered tracepoint event you
want to attach to. That's it.

00:39:12.317,00:39:18.156
That's it! All there is. Uhm,
you also, you know, have a BPF
program that you've loaded in

00:39:18.156,00:39:21.292
there, put it in there as well.
But, like that's, that's what
we've already done that before.

00:39:21.292,00:39:26.297
Uhm, so, M and M once, once
said, "And Moby, you can get
stomped by Obie", uh, mobile is

00:39:30.702,00:39:35.640
the sort of upstream, open
source code base that docker is
built from and so, we're gonna

00:39:35.640,00:39:40.945
break out of that. Uhm, in a way
that otherwise hasn't been
displayed publicly. Uhm, because

00:39:40.945,00:39:45.516
everyone who's been showing
docker breakouts using bpf
stuff, that isn't otherwise

00:39:45.516,00:39:50.154
exploit like a kernel
vulnerability, has basically
turned off AppArmor to do it.

00:39:50.154,00:39:55.326
Uhm, which like, we don't need
to! We'll just leave it on, I
don't care. Uhm, this is a

00:39:55.326,00:39:59.464
slight modification of the
previous ones we've been talking
about. Uhm, which is necessary

00:39:59.464,00:40:03.101
because of the way the raw
tracepoints work. You can't
actually trace all events with

00:40:03.101,00:40:08.273
them like you can with k-probe.
They'll probably add it in the
future, they only did it for

00:40:08.273,00:40:12.543
regular trace points, not the
raw trace points. What we can
hook on are these sort of

00:40:12.543,00:40:17.582
primordial syscall events, sys
enter and sys exit. Uh, which
essentially gives all of the

00:40:17.582,00:40:21.986
same data anyway. It just means
that need to reimplement,
reimplement the hooks so instead

00:40:21.986,00:40:26.991
of having like a separate BPF
program for each like function
return. We just have one fro

00:40:26.991,00:40:31.496
like the entry to all syscalls
and one for the end, uh, the
return of all syscalls and we

00:40:31.496,00:40:37.535
just use like a switch on top of
the syscall ID and just handle
it differently. So, we can write

00:40:37.535,00:40:42.607
essentially all the same code.
Uhm, and it all just works. And
even if we can't necessarily

00:40:42.607,00:40:47.712
have very fancy DSL that gives
us all the arguments as actual
function permateres - they're

00:40:47.712,00:40:53.418
all just in the registers anyway
so we get the register state,
You know, RDI, RSI, RDX etcetera

00:40:53.418,00:40:57.655
and your standard AMD-64 calling
convention. Like, those are the
first couple of, couple of

00:40:57.655,00:41:01.993
arguments past any syscall. So,
uhm, this is very easy. The one
thing that you need to make sure

00:41:01.993,00:41:07.398
to do, is, again, you need to
save that state because on the
return we absolutely 0 context

00:41:07.398,00:41:13.004
other than that we know the
particular, uh, process ID
thread group ID again. So, in

00:41:13.004,00:41:17.842
this particular case. We're just
gonna serialise like all the
register state and the syscall

00:41:17.842,00:41:23.181
ID. We're just gonna shove it in
there. We're gonna index into
hat, uh, hat map, like, it's a

00:41:23.181,00:41:28.152
hashmap data type so we can, we
don't have to be like regular
indexes from 0, we can just pet

00:41:28.152,00:41:32.790
use the, uh, process ID thread
group ID in there. And, uh, and
everything's good. and then in

00:41:32.790,00:41:37.995
the return, the first thing we
do is we just see if we even
have a state associated with us.

00:41:37.995,00:41:42.133
Because if we don't then we
didn't even attempt to do
anything on the entry, we don't

00:41:42.133,00:41:45.636
care about the return, we just
bail out and let the, let the
syscall happen, but if it's

00:41:45.636,00:41:49.374
something we want to be dealing
with, then we're actually gonna
start processing again with

00:41:49.374,00:41:53.478
another switch on top of the
syscall ID and then we're
potentially going to process the

00:41:53.478,00:41:58.483
data. Uhm, so, my example here,
I'm doing, uh, basically the
same sort of, uh, clot, using

00:42:02.487,00:42:07.458
the, uh, the syscall hooking
stuff, uh, that, I'm not, I'm
not just writing into memory.

00:42:07.458,00:42:13.598
Uhm, like to do an opchain, I'm
just overwriting, uhm, say, file
IO without things realizing it.

00:42:13.598,00:42:19.704
So, uhm, I've started up a
docker container. The only thing
I've added to it is the sys

00:42:19.704,00:42:24.042
admin capability, uhm, that's
it. I haven't turned off app
armor. I've got a binary in

00:42:24.042,00:42:28.079
there [sneeze] I'm about to run
it, it's got some, some payload
there. I'm going to cap this

00:42:28.079,00:42:32.483
file that otherwise doesn't
exist. And, mind you, I'm
cladding it on the outside. Uhm,

00:42:32.483,00:42:38.956
what this payload does, is it
actually overrides crontab when,
whenever any file tries to read

00:42:38.956,00:42:44.162
it. And, so, basically, we're
going to download our code and
now, when we try to load

00:42:44.162,00:42:49.500
crontab, now we have our own
thing, our own code in the top
level crontab of the host,

00:42:49.500,00:42:54.038
outside of the docker container
. So, now we're just going to
wait a little bit for cron on

00:42:54.038,00:42:59.343
the system to pick it up and
start executing our code. And,
now, we've, we've completely

00:42:59.343,00:43:02.680
successfully broken out of the
docker container using nothing
but capsys admin. We haven't

00:43:02.680,00:43:06.818
turned off any of the actual
security mechanisms. Uhm, we
just gave a regular privilege

00:43:06.818,00:43:12.156
that people o whenever they're
gonna do, like fancy BPF stuff,
uhm, we've just broken out,

00:43:12.156,00:43:17.161
we're done. [applause] We've
escaped. [applause] Uh, yea.
Here we go. So, what can we,

00:43:23.000,00:43:28.272
what can we do to defend against
this stuff? Uhm, you could
remove or blacklist this bpf

00:43:28.272,00:43:32.210
sys, syscall entirely. Docker
sort of tries to do this when
it's unprivileged. But the

00:43:32.210,00:43:37.315
moment you cap sysadmin, it
dynamically updates its syscall
filter that uses seccomp BPF to

00:43:37.315,00:43:41.118
actually allow it back in
because you need to do stuff.
Uhm, unfortunately that's not

00:43:41.118,00:43:44.755
gonna work because modern Linux
systems are increasingly relying
on BPF stuff - so, system D

00:43:44.755,00:43:48.392
relies on it, so, if you're in
it, you don't want your in it
crash right at the beginning of

00:43:48.392,00:43:51.329
boot cause you've decided to,
you know, mess around with your
kernel, now, that would be bad.

00:43:51.329,00:43:56.367
Uhm, so, and then, you know, you
really need to be prepared for
what someone could do when they,

00:43:56.367,00:44:00.004
when they have access. So, you
can actually just log all of
these eBPF programs. Uhm, using

00:44:00.004,00:44:04.141
that same API, that we, uh,
pulled out, uhm, the sizes of
the maps - if you're privileged,

00:44:04.141,00:44:07.845
you can actually just dump out
the context of the maps; you can
dump out all of the code of the

00:44:07.845,00:44:13.885
programs, uh, when they're
loaded. Uhm, BPF tool, uh, is
the utility to do this, it's,

00:44:13.885,00:44:18.656
it's very simple. Unfortunately,
because they all use the BPF to
syscall, uhm, they are

00:44:18.656,00:44:22.894
susceptible. So, if someone has
one of those k-probes in there,
they can start overriding the

00:44:22.894,00:44:27.165
response data and lie to it and
they can hide what's actually
going on. So, once it's in

00:44:27.165,00:44:32.803
there, it's kind of, it's still
game over. Uhm, but we can
actually yourself, use tracing.

00:44:32.803,00:44:38.776
Uhm, to see things that maybe
are bad. So, we can look for
when, like their eBPF maps that

00:44:38.776,00:44:43.548
are transferred, are being
processed. We can look for, uh,
you know eBPF maps that aren't

00:44:43.548,00:44:47.418
actually associated with eBPF
programs. We can look for just
when eBPF programs are being

00:44:47.418,00:44:51.222
sent between processes. I didn't
talk about this too much
because, because it's kind of,

00:44:51.222,00:44:54.926
it's a 1- to -1. Every Time you
have to send a new message, you
kinda need to send a new file

00:44:54.926,00:44:59.297
descriptor over. I'd rather have
like a 1 setup, uhm, of the
example in the call where we

00:44:59.297,00:45:03.401
just send a couple of maps over.
and then no one sends any magic
file descriptors to each other -

00:45:03.401,00:45:07.972
they just magically appear and
start executing. It's much, it's
much sneakier to do the other,

00:45:07.972,00:45:11.776
the other way around. And then
you could also just look for
when there are unexpected, uh,

00:45:11.776,00:45:16.113
eBPF programs being attached to
things that they shouldn't be.
And when they're unexpected, you

00:45:16.113,00:45:20.284
know, eBPF tracing programs that
are being added, that's probably
a sign that something bad is

00:45:20.284,00:45:24.555
going on. But, it's honestly
unclear how much more common
these operations are gonna get.

00:45:24.555,00:45:29.560
So, they may not be, uhm, kind
of anomalies in the future, as
they are now. Uhm, so, the more

00:45:31.829,00:45:35.633
APIs that we have, the more
problems that we have, uh,
because there's more kind of

00:45:35.633,00:45:40.304
chicanery that people can do
with them. Uhm, and even the
unprivileged APIs, uhm, can

00:45:40.304,00:45:45.276
enable really like skew
behaviours to avoid people to,
to see what's happening on the

00:45:45.276,00:45:51.649
system. And, once you get the
privilege eBPF, it's impossible
to stop. And, honestly, a good

00:45:51.649,00:45:54.719
number of these APIs shouldn't
even require these privileges in
the first place. There is work

00:45:54.719,00:45:59.123
being done to kind of change
this. But like, they shouldn't,
shouldn't, you shouldn't have

00:45:59.123,00:46:03.427
required cap sysadmin to do a
lot of things that really don't
require it. Because a lot of it

00:46:03.427,00:46:10.234
is essentially analogues to raw
packet IO. Uhm, so, they, like
they shouldn't require that and

00:46:10.234,00:46:14.238
if you do that makes that
programs a softer target because
they need to be less and less

00:46:14.238,00:46:18.142
sandboxed to be able to work
properly because of all the
stuff that gets layered on here.

00:46:18.142,00:46:22.546
Uhm, I'm personally waiting for
a special eBPF map type that
allows us to just generically

00:46:22.546,00:46:26.684
pass file descriptors across
processes, but, I doubt that
one's gonna happen. Uhm, I'd

00:46:26.684,00:46:32.390
like to thank Andy and JKF, uh,
for their help with a lot of
this research. And a wise man

00:46:32.390,00:46:36.961
once said, you can't hide
secrets from the future using
math, I think a simpler version

00:46:36.961,00:46:40.831
of this that also holds true is
you simply can't hide from the
future. Uh, I don't have time

00:46:40.831,00:46:44.702
for questions, uh, but I'd be
happy to talk about all this
stuff and other research I'm

00:46:44.702,00:46:49.306
doing at MMC group. Uhm,
somewhere else, uh, feel free to
find me. I'm also on twitter,

00:46:49.306,00:46:54.312
uhm, happy to talk. Uhm, thank
you. [applause] [whistling]

