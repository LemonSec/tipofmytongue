00:00:00.067,00:00:05.706
>>Bonjour! My name is Ellie and
today with Jean Michel uh we’re
going to talk about uh

00:00:05.706,00:00:12.079
side-channel attack using
deep-learning. We are both part
of the uh Google uh we we’re

00:00:12.079,00:00:18.852
security and on the research
team. So side-channel attacks is
one of the most efficient way to

00:00:18.852,00:00:23.423
attack uh secure hardware
because it targets the
implementation while in the

00:00:23.423,00:00:28.629
algorithm and usually
implementations have are harder
to secure then the algorithm

00:00:28.629,00:00:35.002
itself. So for example, last
year Johan Hoenicke, I hope I
pronounced his name right, uh

00:00:35.002,00:00:41.241
they used uh side-channel attack
recover the private key of the
crypto wallet Trezor. Uh

00:00:41.241,00:00:47.247
actually use the power of
attacking the implementation
rather than the algorithm. Um so

00:00:47.247,00:00:52.185
side problem with uh
side-channel attacks is the uh
require a lot of ex domain

00:00:52.185,00:00:56.723
expertise and they because the
target is specific
implementation uh they’re not

00:00:56.723,00:01:02.562
very reusable. So [clears
throat] if we have a super cool
class of attacks and they’re

00:01:02.562,00:01:07.067
very specialized, the questions
is can we do something about it,
can we make them more generic

00:01:07.067,00:01:11.705
and, can we make them more
reusable so can we reuse them
across a wide range of device?

00:01:11.705,00:01:17.644
And the answer is yes. Uh we do
believe that deep-learning, a
form of machine learning is the

00:01:17.644,00:01:22.649
answer to make uh well
side-channel attacks more usable
and more efficient. And uh we

00:01:25.218,00:01:30.457
see a lot of you funning and
it’s like AI? Really? Again? One
more talk about that? But uh

00:01:30.457,00:01:36.396
trust us. Actually deep-learning
is a really, really good fit for
uh cryptanalysis, hardware

00:01:36.396,00:01:41.935
analysis, and we’re going to
hope to show you that today. Um
fundamentally the reason why

00:01:41.935,00:01:48.642
it’s such a good fit uh for uh
performing uh side-channel
attacks is because it’s like

00:01:48.642,00:01:55.315
template attacks which are state
of the art but on steroid. And
what we mean by that is uh using

00:01:55.315,00:02:00.954
deep-learning help us to address
a few problems. The first one is
that uh when you do it, when you

00:02:00.954,00:02:05.759
use deep-learning, you do not
need any type of uh trace
processing. So you don’t have to

00:02:05.759,00:02:09.463
curb them. You don’t have to
align them. The machine-learning
take care of that which is one

00:02:09.463,00:02:16.203
of the biggest problems when you
target uh secure implementation.
The second thing is uh we can

00:02:16.203,00:02:22.476
get rid of a lot of assumption
such as the models of attacks
for the people in the know like

00:02:22.476,00:02:27.881
the Hamming Weight Model is not
needed and directly target part
of the algorithm direct with

00:02:27.881,00:02:32.619
deep-learning so a lot of the
human assumption are out of the
loop and as a result uh your

00:02:32.619,00:02:37.824
attack is more efficient and
easier to understand and carry.
Uh the third one is because

00:02:37.824,00:02:43.230
deep-learning has its ability to
offer probability when we
perform the cover covert attack.

00:02:43.230,00:02:47.701
We are going to show you uh we
can combine deep-learning
probability to make a very nice

00:02:47.701,00:02:52.272
and efficient probabilistic
attack which is something which
is way harder to do with other

00:02:52.272,00:02:57.077
technique. And last but not
least uh deep-learning have a
lot of metrics and we can see

00:02:57.077,00:03:02.249
the algorithm progressing so we
get the better sense of how well
the algorithm is learning or

00:03:02.249,00:03:06.620
attacking the hardware. And so
we have way more interesting
metrics that we can leverage.

00:03:06.620,00:03:13.593
Which we are going to show that
as well uh during the talk. So
there is also a more fundamental

00:03:13.593,00:03:17.898
reason why deep-learning is such
a powerful tool and you keep
hearing people saying

00:03:17.898,00:03:22.069
deep-learning deep-learning
deep-learning everywhere. It is
because as far as we can tell

00:03:22.069,00:03:27.074
deep-learning is the only
technology we have um period uh
for any domain which scales uh

00:03:29.276,00:03:33.413
with data and computing. So more
data, the more computing you
have the better deep-learning

00:03:33.413,00:03:38.919
become and they’re the only one
we have. And that’s really why
the reason is of why it become

00:03:38.919,00:03:44.191
so powerful. And you’re like,
ok, fine, I can see that for
calculations but what’s what’s

00:03:44.191,00:03:50.597
up with the attacking
side-channels? Well, what it
means is we can push further our

00:03:50.597,00:03:55.135
attacks with more trace. The one
thing is that more trace you
have about your implementation

00:03:55.135,00:03:59.306
and we can always generate more
trace. Right? It’s just a bunch
of crypto computation the better

00:03:59.306,00:04:04.678
it become. So we have a way even
for hard target to scale up
because deep-learning scale

00:04:04.678,00:04:09.382
linearly so all we have to do is
generate more data now which is
something which for side-channel

00:04:09.382,00:04:14.821
attacks is very easy to do when
you have the board. So in a way
it’s a perfect fit. Um so all

00:04:14.821,00:04:20.260
this will become a little bit
blurry today but as as it now
don’t worry about it as we go

00:04:20.260,00:04:24.965
through talk, it’s going to be
more clear and it will start to
make sense. So today what we

00:04:24.965,00:04:29.102
wanted to do because as DefCon
um we get rid of all the
equation and we’ll also get rid

00:04:29.102,00:04:33.940
of all the complicated stuff and
we going to focus on showing you
step by step how you can do it

00:04:33.940,00:04:38.111
and show you it works. Uh a lot
of people have attempted it to
use machine learning for

00:04:38.111,00:04:43.283
side-channel. Many people have
failed. Uh we failed a lot. Been
3 years since we work on it so

00:04:43.283,00:04:47.220
we failed a lot but when it
works it works and we wanted to
show it you step by step how to

00:04:47.220,00:04:52.959
get there. So that will be very
practical. No equations, no
boring math, just straight up it

00:04:52.959,00:04:58.765
works it could, that’s what it
would look like. And so we call
those attacks side-channel

00:04:58.765,00:05:02.903
attack associated with machine
learning, also known as SCAAML.
So during the talk we’re going

00:05:02.903,00:05:07.908
to create SCAAML because it’s a
shorter and nicer uh name. Um
this talk is based on a long

00:05:10.043,00:05:14.414
project uh that we’ve been on
about two years ago with a bunch
internal and external

00:05:14.414,00:05:19.419
collaborators around uh
improving and hardening
hardwares uh crypto hardware we

00:05:19.419,00:05:25.458
have uh to provide the best
hardware more security we can.
Um the slide uh today we are

00:05:25.458,00:05:29.696
going making the slide public.
They’re already on the web uh we
also tweeted them with Jean

00:05:29.696,00:05:34.801
Michel so you can have them
today. In uh hopefully very soon
we’re going to also give the

00:05:34.801,00:05:40.140
code words that we use to carry
the attack, so you will run it
yourself and in hopefully in the

00:05:40.140,00:05:44.711
not to distant future will also
make available those whole
research paper as well as all

00:05:44.711,00:05:49.716
the data set we collected and
the model we trained so we can
reproduce our results. So blast

00:05:52.052,00:05:57.924
this disclaimer before we delve
into the matter. Um we decided
with Jean Michel to focus on

00:05:57.924,00:06:02.462
showcasing how to get the attack
working and as a result we don’t
use state of the art machine

00:06:02.462,00:06:06.333
learning. We don’t choose state
of the art processing because we
think it’s more important to

00:06:06.333,00:06:10.470
focus on clarity. We will
succeed to be clear. The attack
works 100 percent of the time

00:06:10.470,00:06:17.010
but we wanted to make real focus
on getting you guys a clear
understanding so don’t expect

00:06:17.010,00:06:22.082
like super advanced machine
learning here. Uh which is
probably fair evidence. Ok so

00:06:22.082,00:06:27.087
how it going to go today: uh
Jean Michel is going to talk
about what are side-channel

00:06:27.087,00:06:30.490
attacks? What is deep-learning?
So we want to stay on the same
page and then I come back and

00:06:30.490,00:06:34.828
I’ll talk to you how to use both
techniques and combine them to
do a SCAAML attack and then

00:06:34.828,00:06:41.534
we’ll briefly talk about the
research itself and what to
expect next. Jean Michel take it

00:06:41.534,00:06:48.375
away. >>Thank you Elie. So first
let’s step back and get the same
definition on what we mean by

00:06:48.375,00:06:53.380
side-channel attack. So every
time you do computation with an
embedded device, a CPU,

00:06:55.515,00:07:01.554
etcetera, it will result in some
artifact created by this
computation. And if you have a

00:07:01.554,00:07:07.027
way to measure that and you have
a collation between those
artifact and a secret you want

00:07:07.027,00:07:12.032
to extract then you can conduct
a side-channel attack. It can be
used to recover encryption key,

00:07:14.167,00:07:19.673
which is the thing that we are
discussing today. You can also
its uh has also been used in the

00:07:19.673,00:07:25.145
past uh to perform blind SQL
injections. You can also steal
password and pins, extract

00:07:25.145,00:07:31.918
cryptowallet private keys. Can
be used for a wide variety of
things. So we have a component

00:07:31.918,00:07:38.091
an electronic uh electronic
component, this component follow
cryptography we feed it with

00:07:38.091,00:07:44.664
plaintext data and it has a
secret key inside that we don’t
know and we want to extract. At

00:07:44.664,00:07:49.969
the end we will have some
artifact, as I said, that we uh
that we call leakage and those

00:07:49.969,00:07:54.641
leakage can be, for example, the
timing when you do a cache
timing attack if the data is in

00:07:54.641,00:08:00.547
the cache or not your CPU, your
execution will last longer or
not and by deriving that you can

00:08:00.547,00:08:07.387
get one bit of data. Uh you can
also measure the port
consumption during the uh the

00:08:07.387,00:08:11.825
encryption of the data and
that’s the one that we are uh
using on the on this

00:08:11.825,00:08:18.131
presentation. Theoretically you
could also use the heat but the
problem with the heat is that it

00:08:18.131,00:08:24.571
spreads and you have a huge
latency so despite using an
infrared camera on the big CPU

00:08:24.571,00:08:30.610
to see exactly which part is
warming up to locate exactly
where your crypto accelerator is

00:08:30.610,00:08:36.082
located the heat cannot be used
to recover an encryption key as
far as we know. And for this we

00:08:36.082,00:08:40.153
prefer to use electromagnetic
emission instead of the heat
which is more precise and

00:08:40.153,00:08:44.457
doesn’t have the side the same
side effect. But we’re not using
it uh on the attack we are

00:08:44.457,00:08:50.730
showing you today. So
side-channel attack in a
nutshell. We do some encryption

00:08:50.730,00:08:55.602
with the with the uh
microprocessor. We are measuring
the current consumption within

00:08:55.602,00:09:02.041
an oscilloscope. We accumulate
all the time with different
plaintexts and we do a template

00:09:02.041,00:09:08.348
attack for the for the state of
the art attack. A template
attack is still uh an attack

00:09:08.348,00:09:13.753
that requires a powerful
attacker because most of the
time uh to to train a template

00:09:13.753,00:09:20.060
attack it's a probabilistic
model that you have to train on
what is called a wide box chip.

00:09:20.060,00:09:25.799
The wide box the bo the wide box
chip sorry, is the chip on which
you can control the encryption

00:09:25.799,00:09:30.904
key. You train your
probabilistic model and then you
apply it on the chip where you

00:09:30.904,00:09:36.910
don’t know the key and you want
to recover it. And at the end
you’re probabilistic model will

00:09:36.910,00:09:43.316
give you the AES key. So as we
see here on the on this
theoretical curves, not the real

00:09:43.316,00:09:48.321
ones, uh we can see that most of
the time the trace of the lapse
but on the top of the of the

00:09:51.291,00:09:55.995
curve we have some discrepancies
and those discrepancies
hopefully will happen on the

00:09:55.995,00:10:02.168
clock signal for the CPU which
means that it’s the register
which are changing values,

00:10:02.168,00:10:08.675
creating different kind uh of
part consumption at a given time
for the different bits that are

00:10:08.675,00:10:14.380
set. And that’s the kind of
thing that you are looking for.
And ideally if this point at the

00:10:14.380,00:10:20.854
time or you realize on a part of
the plaintexts that the attacker
control and uh part of the key

00:10:20.854,00:10:26.659
that you want to recover, this
is the attack point. Here we see
a full trace of lightly

00:10:26.659,00:10:31.664
protected AES trace. It’s AES 1
uh 128 and if we take a deeper
look at this particular box we

00:10:35.969,00:10:41.941
can see some humps and some
repeating patterns and if we
count them there’s actually 10

00:10:41.941,00:10:46.946
humps and that exactly
corresponds to the 10 rounds of
AES 128. So we see that it can

00:10:49.082,00:10:54.387
also be a very visual. Uh this
how we were doing that in the
past uh at the beginning of the

00:10:54.387,00:11:00.093
project. It was sitting on the
corner of my desk. So we have a
PCB which has a target chip

00:11:00.093,00:11:04.597
which is the one containing the
encryption key that we want to
recover. Here we have a

00:11:04.597,00:11:09.802
differential probe that is
measuring the port consumption
of time and it’s connected to

00:11:09.802,00:11:14.407
the oscilloscope that is here.
And here we have the
communication interface to be

00:11:14.407,00:11:19.412
able to feed the plaintext to
the chip. And that’s that’s all
it takes. If you want to start

00:11:21.548,00:11:26.553
uh NewAE tech and calling with
sitting on the second bran uh on
the uh second row uh is the

00:11:28.721,00:11:33.726
creator of Chipwhisperer which
is a very cheap and easy way to
start with side-channel attacks.

00:11:36.062,00:11:41.701
Uh on the board you have all you
need. You have an oscilloscope,
you have um the communication

00:11:41.701,00:11:47.006
interface, and it has multiple
targets to try uh to try this.
Uh if you’re interested we

00:11:47.006,00:11:52.745
invite you to talk to Collin, he
has a few Chipwhisperer nano
that he can uh give to some of

00:11:52.745,00:11:57.750
you. Uh but most of the time the
imitation of the Chipwhisperer
is that it’s feeding um it’s uh

00:12:00.853,00:12:05.858
yeah the clock that it generates
and the sampling rate for the
oscilloscope is limited and when

00:12:09.729,00:12:14.167
you’re attacking more secure
elements most of the time they
won’t allow you to feed any

00:12:14.167,00:12:19.472
clock to it to uh to slow them
down the clock which means that
you will need a very high

00:12:19.472,00:12:23.376
sampling rate for your
oscilloscope. Uh and for this
you will need a real

00:12:23.376,00:12:26.446
oscilloscope but the software’s
tech provided by the
Chipwhisperer is already

00:12:26.446,00:12:33.252
compatible with that. Also
during our paper we do
asynchronous capture so the

00:12:33.252,00:12:38.691
Chipwhisperer usually works with
asynchronous capture which means
you have one single clock that

00:12:38.691,00:12:43.463
you feed to the chip and the
oscilloscope will capture the
data exactly at the right amount

00:12:43.463,00:12:49.335
of time. Most of the time if you
use uh an external oscilloscope
this won’t happen you will have

00:12:49.335,00:12:53.773
exactly what you see on the
screen. You will have different
clocks, one for the oscilloscope

00:12:53.773,00:12:59.278
sampling and one for the CPU and
they will be out of sync. Which
means that if you want to

00:12:59.278,00:13:05.585
sample, in this in this setup
you need the oscilloscope to run
at least 4 times faster than the

00:13:05.585,00:13:12.191
CP uh the clock of the CPU you
are attacking. And that’s why
with our setup evolved over time

00:13:12.191,00:13:16.296
during the project and right now
we using the Chipwhisperer Pro
which is a bit more expensive

00:13:16.296,00:13:22.135
then the the Chipwhisperer light
or the Chipwhisperer nano kits.
And we use Picoscope 6000

00:13:22.135,00:13:27.240
series. This is not an
advertisement, this talk is not
sponsored, this just what we use

00:13:27.240,00:13:32.078
so that if you want to reproduce
the setup you know thagtthis
works. And the reason we picked

00:13:32.078,00:13:37.250
the Picoscope 6000 series is
because it can sample at a very
very high speed rate. It can go

00:13:37.250,00:13:42.922
up to 5 gigabytes sample per
second so we can attack a chip
that is running at 1 gigahurtz

00:13:42.922,00:13:49.028
and it also has very big memory.
Uh it can store up to 2
gigasample in memory and it is

00:13:49.028,00:13:53.299
very important when you start
attacking asymmetric
cryptography like RSA or liptif

00:13:53.299,00:13:58.938
er elliptic curve because the
traces are really big. So now
let’s move to what is

00:13:58.938,00:14:05.678
deep-learning. Deep-learning is
basically a neural network but
with many layers and they are

00:14:05.678,00:14:12.318
stacked together like pancakes.
So at the beginning you have uh
series of neurons mimicked with

00:14:12.318,00:14:18.825
uh with the biologic biological
1. The number of neurons that
you have defines the width of

00:14:18.825,00:14:24.464
your layer. Then you start
packing stacking them like
pancakes and it’s uh creates a

00:14:24.464,00:14:31.003
depth on your network and the
deep-learning. Then you add an
input layer to process your

00:14:31.003,00:14:36.676
input and one for the output to
do the prediction. Here between
“dogs” and “cat”. When you want

00:14:36.676,00:14:43.216
to use the the machine-learning
you feed, for example this image
of a puppy, you feed it to the

00:14:43.216,00:14:48.554
input layer, it will activate
some neurons that will propagate
their predictions to the next

00:14:48.554,00:14:53.292
layer and the next layer and at
the end of your of your output
layer it will issue the

00:14:53.292,00:14:58.131
prediction whether this picture
was the picture of a dog or a
cat and it here it will say that

00:14:58.131,00:15:03.970
it’s a dog. But when you have
different use-cases you will
need to use different types of

00:15:03.970,00:15:07.807
layers, different types of
network network archi-
architecture so it can make

00:15:07.807,00:15:14.380
things quite complex very
quickly. So what do you need to
train a deep-learning model?

00:15:14.380,00:15:19.519
Basically Tensorflow will allow
you to write and to train your
model uh it’s written in Python.

00:15:19.519,00:15:24.524
Uh but it’s very very slow to
train on the CPU so don’t try
that. You will need a hardware

00:15:26.993,00:15:32.398
accelerator for that. You can
use either a GPU or if you use
on Google cloud we have what we

00:15:32.398,00:15:38.504
call TPU, Tensorflow processing
unit, and this is a dedicated
ASIC that is there for eh for

00:15:38.504,00:15:44.443
specially Tensorflow and
deep-learning trainings. The
demo code will try to make it

00:15:44.443,00:15:50.516
available as soon as possible uh
on Colab. Uh Colab is basically
GPU/TPU notebook but hosting in

00:15:50.516,00:15:55.822
the cloud and it already comes
with the Tensorflow already set
up and free GPU/TPU time

00:15:55.822,00:16:00.760
computation. And now I will give
back the the mic to Elli to who
will guide you through to uh

00:16:05.665,00:16:11.971
your first SCAAML attacks.
>>Thank you Jean Michel. Alright
so now that we have the basics

00:16:11.971,00:16:17.844
down uh we going to try to see
how we combine both and um
making it work in practice. So

00:16:17.844,00:16:24.750
uh I said our goal is to get
used to the attack step by step
and try to provide as much

00:16:24.750,00:16:29.989
information as we can so we we
can reproduce and understand
what is going on. So the first

00:16:29.989,00:16:35.394
thing to decide is what we’re
going to attack and for this
presentation we selected uh a

00:16:35.394,00:16:40.399
chip which is the STM32F415.
This is one of our favorite
boards because it brought a lot

00:16:42.869,00:16:47.406
of uh. So to implementation but
those who have hardware
implementation you can run on it

00:16:47.406,00:16:52.211
so we can compare hardware
protected AES versus software
one then try to test many of

00:16:52.211,00:16:57.416
those. And for the
implementation we’re going to
use TinyAES uh which is an

00:16:57.416,00:17:02.521
unprotected uh version of AES
because it’s easiest one to
attack and they’re the one you

00:17:02.521,00:17:08.194
will get the best result. Um so
there is one downside to it that
I’m going to explain it in more

00:17:08.194,00:17:13.132
detail later but because it’s
software is very slow so those
traces are very big and that

00:17:13.132,00:17:19.305
make it harder to train um
because you need more GPU
memory. Ok so Jean Michel showed

00:17:19.305,00:17:25.478
you earlier uh what is a Aca Eeg
implant so we’re going to
upgrade it to making the SCAAML

00:17:25.478,00:17:31.083
implant so uh the same as before
we do our encryption on the
chip. We hooked our

00:17:31.083,00:17:37.523
Chipwhisperer and picoscope up,
gets us the data, feed it to a
neural network. And we need to

00:17:37.523,00:17:41.727
talk about how we’re going to
train that thing and that uh
we’ll have to combine those

00:17:41.727,00:17:46.933
things and do some sort of uh
inversion and a little bit more
extra work to actually recover

00:17:46.933,00:17:53.539
the actual key and if everything
goes well uh you uh get a AES
key or in our case we try to get

00:17:53.539,00:18:00.079
many AES key. Alright, so as I
mentioned uh AES is great, it’s
software is open source, you can

00:18:00.079,00:18:06.419
have it. However, it is super
super slow and why I mentioned
that is because is because it’s

00:18:06.419,00:18:10.923
going to take about 80,000 point
as in input uh it’s fairly
large. It’s actually larger than

00:18:10.923,00:18:16.195
the most of the images we fit
into a neural network for a
collection of images so we will

00:18:16.195,00:18:21.867
have to do a little bit of um
different type of architecture
to kind of reduce uh the amount.

00:18:21.867,00:18:26.706
Uh for the demo we’re going to
provide to you on Collab. Uh
Collab only have 20 gigs of

00:18:26.706,00:18:30.443
memory. That seems a lot but
it’s actually not for the
deep-learning. And so what we

00:18:30.443,00:18:35.014
did is we also have another
dataset coming out uh which is
Collab specific where we

00:18:35.014,00:18:39.952
basically uh took one fifth of
the uh the trace so you can
really get in and play with it.

00:18:39.952,00:18:45.524
So you can do that uh it’s more
efficient because you have uh
sure point to process so you can

00:18:45.524,00:18:50.296
put more memory. The problem is
we uh were writing our first
permissive which is what you can

00:18:50.296,00:18:53.966
full trace. So if you want to do
your own full trace, you need a
lot of memory and you need

00:18:53.966,00:19:00.172
pretty beefy GPUs uh we use
between uh GPU each have between
12 and 16 gigs of RAM, one with

00:19:00.172,00:19:05.344
trans am and the real thing.
Alright so what model, what
deep-learning architecture do I

00:19:05.344,00:19:10.349
need? Alright that’s a question
is. Ah ok I have my data what do
I process it with? Well, the

00:19:13.419,00:19:18.557
obvious answer uh is you, we’re
going to do this same thing that
we use for speech processing and

00:19:18.557,00:19:22.762
immeasurable connection, which
is what we’ll call a Conv Net,
also known as a convolutional

00:19:22.762,00:19:29.435
neural network. So reason why
those are better is because it’s
slide across the data and so you

00:19:29.435,00:19:33.606
don’t have to protect all the
point at once. So the number of
parameters and connection is

00:19:33.606,00:19:38.978
lower and because we really want
to have locality. Right? What we
want is to fill them and then

00:19:38.978,00:19:45.151
slide them. So that’s our
favorite network of choice.
However, if you want, you can

00:19:45.151,00:19:50.990
also use, the people who like
deep-learning use uh LSTMs, uh
more precisely GRUs, works

00:19:50.990,00:19:55.161
pretty well too, it’s just that
exam. So you can use other
architecture but this one works

00:19:55.161,00:20:01.967
well, it’s fast, so that’s how
our fav that’s our favorite one.
Um what it look like? Right? So

00:20:01.967,00:20:06.705
a little bit of code. Um I
promise no equation but I didn’t
promise no code so you guys have

00:20:06.705,00:20:13.112
a little bit of code. Uh this is
a tensor flow two uh code uh or
Keras for those that like that

00:20:13.112,00:20:17.283
better. And the idea is that
with a bunch of constants uh
which is just setting setting

00:20:17.283,00:20:23.589
everything up uh our network.
The important one is the last
one called “pool size”. So what

00:20:23.589,00:20:29.228
pool size will do is by how much
are we going to combine at the
first layer uh which is going to

00:20:29.228,00:20:33.999
be in a second. So first we take
the input. So we convert it
basically as an input for our

00:20:33.999,00:20:39.672
layer, our networks. Then we do
a max pool. So what is a max
pool do? The max pool do the

00:20:39.672,00:20:44.477
following: it attacks both
sliding windows. So we put 4.
And it’s going to take the

00:20:44.477,00:20:51.250
maximum value for each of those
4. So in a way it’s basically
trimming down your trace from 80

00:20:51.250,00:20:56.255
point to well 20,000 point and
then uh you going then to
process them with conv con

00:20:59.125,00:21:03.963
convolutional layers uh which
are here. Uh they are not the
same as the images because they

00:21:03.963,00:21:09.068
are 1 dimension. Why 1
dimension? Is because we have a
trace of 1 point. Right? So you

00:21:09.068,00:21:13.606
see it’s just the value of the
current. We don’t have 2D like
images, X and Y. So that’s why

00:21:13.606,00:21:18.844
we use 1D. Uh for those who like
my channeling, you might already
recognize that we don’t use a

00:21:18.844,00:21:23.716
normal convolution, we use a
collection of blocks where we
did put batch normalization in

00:21:23.716,00:21:29.121
the middle. And the reason for
that is it’s a bit of training.
And then we keep uh doing a few

00:21:29.121,00:21:34.527
of those. Um I’m thinking that
example we did 4, 5. So we did 5
times those 3 layers so you

00:21:34.527,00:21:38.998
already have 25 layers here. So
that’s why we create
deep-learning is because we have

00:21:38.998,00:21:44.503
already about uh 30 layers at
that point. Then we do another
max pool so that final final one

00:21:44.503,00:21:49.308
where basically we have all of
those convolutions, which create
a lot of um uh depth, if you

00:21:49.308,00:21:53.913
will, if you would, like a
number of filters it is way it
adapts and then we combine them

00:21:53.913,00:21:59.518
to find the maximum one for each
of those point. And then we add
a little bit of a dropout and

00:21:59.518,00:22:03.923
dense layer to connect
everything and do our
predictions. And our prediction

00:22:03.923,00:22:08.060
which is a last layer, is the
output of the layer. If you
remember the cat and dog here we

00:22:08.060,00:22:11.997
don’t have cat and dog. What we
have is we have 200 256 values.
And I’m going to explain a

00:22:11.997,00:22:18.304
little bit more where they are
in a minute but basically what
we have 256 values of the uh

00:22:18.304,00:22:23.309
network is providing to you. The
important point here is you
might consider the idea of using

00:22:26.445,00:22:31.717
sigmoid, which is another way to
do it. Uh if you do that for
deep-learning uh for

00:22:31.717,00:22:37.056
side-channel attack it’s a
horrible idea. It’s a horrible
idea because uh we have only 1

00:22:37.056,00:22:42.228
value which is true, right? If
you try to predict an image you
can have a cat and a bench and

00:22:42.228,00:22:45.464
something too. So you have
multiple classes. You know what
kid when you’re a single class,

00:22:45.464,00:22:50.302
which is true, which is a value
you want to predict and nothing
else so you have a lot of zeros.

00:22:50.302,00:22:54.840
So basically every time there
was a mention of what it’s going
to learn is if I have 256

00:22:54.840,00:23:00.713
zeroes, I have 99.9% accuracy so
your model showed nothing for a
very long time so you should

00:23:00.713,00:23:05.618
always use soft max. Uh we try
both and really that’s the best
way to do it. So don’t use

00:23:05.618,00:23:11.156
sigmoid, if you try that at
home. Okay, so now the one thing
I haven’t explained is like okay

00:23:11.156,00:23:17.162
so I have the model, I have
data, what am I trying to
predict? Well, that’s where

00:23:17.162,00:23:22.167
things get complicated. Uh so
this is AES. Uh this is a round
of AES to be precise. Uh we’re

00:23:25.237,00:23:29.008
going to talk about the first
round of AES and the question is
what do we do? So as Jean Michel

00:23:29.008,00:23:35.714
explained, uh we are doing power
consumption and the question is
why is power consumptions

00:23:35.714,00:23:42.321
reflecting the key right? What
happened is if you want to set a
bit of memory to one you need

00:23:42.321,00:23:48.994
power. If you want to set the
bit of memory to zero you need
no power right? So basically uh

00:23:48.994,00:23:54.533
you have you need more power if
you have 8 bits at one then you
should have 4 and not 2 right?

00:23:54.533,00:24:00.606
So basically we need to find
every point in the algorithm
where there is a shift of some

00:24:00.606,00:24:05.744
memory and those are going to be
where the power differences will
going to kick in and we’ll have

00:24:05.744,00:24:12.718
some sort of different shifts or
place to look at. Fair? Ok so
where are those? Well, first

00:24:12.718,00:24:17.923
when you feel the key. You feel
the key memory you lose your key
so your key is loaded so that’s

00:24:17.923,00:24:22.594
the first point. Then you have
to do something where you
combine the key with the

00:24:22.594,00:24:28.500
plaintext so that’s it’s an X or
so when you do this combination
well again you might have also

00:24:28.500,00:24:33.639
some loading there. Then you
have the S box and after the S
box, again you you go out of the

00:24:33.639,00:24:37.710
S box where it shifts the
things. Again you’re loading the
new the new value of memory. So

00:24:37.710,00:24:42.514
again, you start at that point.
Then you have one more which is
before the key scheduling one

00:24:42.514,00:24:47.386
after the key scheduling and
then you repeat that 16 times
because well there’s 16 bits for

00:24:47.386,00:24:53.692
each of those things and then uh
in the actual model uh you can
repeat that 10 times because

00:24:53.692,00:25:00.532
there is 10 rounds. Uh however,
there is only 2 rounds you can
use uh to recover the key

00:25:00.532,00:25:05.170
directly which is the first one
and the last one. So one in the
middle are way more complicated.

00:25:05.170,00:25:09.942
Why during cryptography we can
considers it as an attack is
because they leak stuff. It’s

00:25:09.942,00:25:14.680
really hard to exploit. It might
be possible in the future. You
may be able to do stuff but for

00:25:14.680,00:25:19.685
now we’re just going to focus on
the initial round where you have
only 3 places uh or 3 type of

00:25:21.987,00:25:27.092
prediction you can do. So first
one, as I mention, that we
create AP 1 is use you just

00:25:27.092,00:25:32.498
predict the key. You say hey
give me back the value of the
key. It’s the easiest one to do

00:25:32.498,00:25:37.703
because, well that’s a direct
prediction. The second one is
please predict the value of the

00:25:37.703,00:25:41.673
key in plaintext and there is
what I explained to you, you
need a little bit of computation

00:25:41.673,00:25:47.679
and after the com after the
prediction we have to well,
de-explore the plaintext. So

00:25:47.679,00:25:53.085
this only work for uh attack
where you have a chosen
plaintext which is the one we

00:25:53.085,00:25:58.390
are demonstrating today. And
finally the last one you can do,
which is also a very common one,

00:25:58.390,00:26:04.763
is you go after the S box. So in
that case you have to invert the
S box, Inversion is a little bit

00:26:04.763,00:26:09.701
more computation and you have
that uh don’t worry about it, we
have implemented all those 3

00:26:09.701,00:26:14.807
type of attacks into the code
we’re going to give you in a few
hopefully soon and you will be

00:26:14.807,00:26:20.979
able to run them. So where does
that leave us? That leave us to
this idea of we take the power

00:26:20.979,00:26:25.584
trace, we feed it to the
networks and that why we do all
those crazy layers I showed you

00:26:25.584,00:26:31.757
and output of value to uh
softmax. So what is a softmax?
Basically a softmax is you take

00:26:31.757,00:26:36.762
your 26 20 uh 256 value and you
say, no more line, just the sum
of all those value is 1. The

00:26:40.098,00:26:44.636
reason of 1 is because make a
very nice uh smooth probability
and we constrain the the output

00:26:44.636,00:26:49.208
so every prediction is
comparable and that’s going to
be important later. Uh it’s a

00:26:49.208,00:26:54.880
connected by the way to machine
learning so this how we built
it. And so we make 256 value

00:26:54.880,00:26:59.585
prediction by the model for each
attack point value. So for to
target the key, each of those

00:26:59.585,00:27:04.523
output is a value of a byte uh
the value we can have. Um so
last thing I need to tell you

00:27:08.527,00:27:13.232
and this is where it become um
not complicated but it’s it’s a
little bit different from what

00:27:13.232,00:27:18.237
you expect. It is we do 1 byte
at a time. So if you were to
attack a full key, what you will

00:27:21.206,00:27:28.180
do is you will have to train 16
models. 1 for each byte of the
key. 1 for byte 0, 1 for byte 1,

00:27:28.180,00:27:33.986
1 for byte 2, 1 for byte 3, and
so forth. And you’re like why?
Well we have 256 value for the

00:27:33.986,00:27:40.425
first byte and then you repeat
that 16 time. So we don’t want
to predict a 3000 value to

00:27:40.425,00:27:45.430
predict. That’s not useful. We
could uh but it also um uh push
a model to have high capacity

00:27:49.201,00:27:53.238
right? Because you have now the
model have to learn all the
number linearity to predict the

00:27:53.238,00:27:57.676
all the value so your model is
going to be bigger and it’s
going to be harder to train so

00:27:57.676,00:28:02.247
it’s easier to have one model
per key. And a question that
we’ve been asked quite a bit is

00:28:02.247,00:28:07.252
is there any bytes which happen
to be harder? The answer is most
notably no but in some

00:28:10.255,00:28:16.562
implementations it seemed that
the byte which are the model
which is 4, 6, and uh sorry 4,

00:28:16.562,00:28:22.000
8, and 12 are little bit
different because of uh um the
power of 2. So in some

00:28:22.000,00:28:28.874
implementations it’s made it
greater but they all work the
same. In the end. Um ok so you

00:28:28.874,00:28:34.079
do that, you’re ready, you have
the code, you click fire and
then you wait because it takes

00:28:34.079,00:28:38.817
hours. Sorry. It’s not very easy
training a machine, a new model
takes time. Uh you have to train

00:28:38.817,00:28:45.390
about 50,000 example. You come
back and you cry. It doesn’t
work. We lied. We actually, the

00:28:45.390,00:28:51.697
model I showed you, I lied it
just doesn’t work. And then
you’re like ok, should work. Why

00:28:51.697,00:28:57.436
is code not working? Well you
try many of those and none of
them works. And that’s where

00:28:57.436,00:29:03.642
most people have stopped and we
have context people say it
doesn’t work. And that is true.

00:29:03.642,00:29:09.648
Learning crypto is hard and
you’re going to fail a lot and a
lot and a lot and a lot. And for

00:29:09.648,00:29:14.653
a year, about a year, we had
only failure to report. We knew
it should work. We just don’t

00:29:14.653,00:29:20.792
know why. And to be honest, we
still don’t know why. However,
[laughs] we have a way. Right?

00:29:20.792,00:29:26.999
So how do we deal with it if we
can’t find it by hand? Well the
answer is don’t do it [laughs],

00:29:26.999,00:29:32.037
rely on hyper-tuning. So
hyper-tuning is the idea that
you are fine tuning your model

00:29:32.037,00:29:36.975
architecture to try to find the
optimal one. And you try to do
it until you find the right one

00:29:36.975,00:29:41.980
and you just throw out at it
more CPU and more computation.
So even for this simple example,

00:29:44.650,00:29:49.588
we had to do that. I I really
wish I would show you a model
which is super easy to

00:29:49.588,00:29:54.593
understand, that will work just
right. I don’t have one. What
what I did is I trained about a

00:29:56.862,00:30:01.933
thousand model on uh on Google
Cloud by using Kubernetes and
Keras Tuner. Which is a

00:30:01.933,00:30:07.205
hyper-tuner with lock for the
tensorflow 2 with the tensorflow
team and I selected one which

00:30:07.205,00:30:13.311
works. And they said “we have a
super amazing model to show you
but it’s not going to be as

00:30:13.311,00:30:18.350
simple as the previous one.
We’re like okay. So you brace
yourself and you’re like ok,

00:30:18.350,00:30:23.789
what do you mean by more
complicated? Well uh this is a
simplified view of it. It’s not

00:30:23.789,00:30:28.794
that bad. Uh kind of. It’s a few
hundred layers now. So same as
usual, we have the input. And

00:30:31.163,00:30:35.967
then we have a maxpool. Uh
Maxpool is 6 this time. Um we
don’t have the space to put

00:30:35.967,00:30:42.040
everything. Then we do 2 normal
convolutions which helped us to
decrease the number of points

00:30:42.040,00:30:47.746
and increase the number of
filters. Then we do uh what we
call “residual blocks” and so

00:30:47.746,00:30:53.485
the residual blocks the idea is
you I are adding shortcuts into
the network to actually form the

00:30:53.485,00:30:58.857
gradient. Uh so the gradient is
when you make an error, you back
prop the error to the network.

00:30:58.857,00:31:05.764
And one thing we found is the
gradient is vanishing a lot when
we do training on crypto so user

00:31:05.764,00:31:10.502
shortcut to retain the gradient.
This is something they also do
in images. Uh It’s called res

00:31:10.502,00:31:15.741
net, residual blocks. We do a
few of those and here what
happened, it decreased the num-

00:31:15.741,00:31:20.045
the size of the trace and
increases the number of filters.
So decrease the width, increase

00:31:20.045,00:31:27.018
the depth and then you need a
lot of residual blocks. So
that’s not the same way. That’s

00:31:27.018,00:31:33.992
not the same one. In this case
the number of points did not
decrease. But you increase the

00:31:33.992,00:31:38.697
depth. So basically you do a
combination of all of those
again with the residual. You do

00:31:38.697,00:31:44.636
max pool. You do a dense. You
remove the dropout because that
doesn’t help at all. And you

00:31:44.636,00:31:49.474
don’t try to fix the 6 layers
and you have something which
works. And that is a example I

00:31:49.474,00:31:54.479
can show you which works. And I
cannot find by hand and you’re
like “Elli what is intuition?”

00:31:56.815,00:32:01.753
And the answer is I have no
intuitions. Absolutely 0. Don’t
know. Uh for some reason it’s

00:32:04.656,00:32:10.428
very very finicky and we have
some which works so I’m pretty
clear it works. Uh the intuition

00:32:10.428,00:32:16.168
is not easy to get. And you and
the cat is happy and we’re happy
too because now we have

00:32:16.168,00:32:21.373
something to show you which
works. How well does it works?
Well this is the trace out of 10

00:32:21.373,00:32:27.345
to borg and the model is going
to do nothing for sure box. So
also another thing, don’t get

00:32:27.345,00:32:31.917
discouraged if your training
model for deep for crypto for 4,
5, 8 bugs it seems to do

00:32:31.917,00:32:37.823
nothing. I mean it it it kind of
goes to 5 percent maybe and then
go down go up, it’s not really

00:32:37.823,00:32:42.828
really good and then it start to
learn and then it’s going to to
spike at uh 35 percent accuracy,

00:32:46.331,00:32:52.070
around 38 box. 5 5 minutes per
box. So about 2 hours later you
have your result and then the

00:32:52.070,00:32:57.943
thing collapse. So this is why
edition occurs images are on uh
traces that we have been using

00:32:57.943,00:33:02.914
during the training. These are
traces we use to monitor the
generalization of the model. And

00:33:02.914,00:33:06.785
yes it’s going to collapse and
neural model collapse at the
end, we’re not sure why or what

00:33:06.785,00:33:12.991
happened. Uh and then you get
that model and you change it and
you save it and that’s your

00:33:12.991,00:33:16.394
model. Uh we tried a data
augmentation uh sometime it
works and sometimes it does not.

00:33:16.394,00:33:22.667
A lot of people say it does uh
it kind of except if you make it
wrong. Uh It actually actually

00:33:22.667,00:33:26.638
completely destroy your ability
of your model to learn because
it seems to destroy some models

00:33:26.638,00:33:32.143
and the correlation you need. So
do not choose the data
augmentation unless you have to

00:33:32.143,00:33:38.350
or you feel you are you are want
to push further and have a good
baseline. So let’s go back a

00:33:38.350,00:33:43.355
second to what I mentioned
earlier which was we have
multiple attack point and answer

00:33:43.355,00:33:48.460
a question which is does it make
a difference whether you attacks
the key. The key explore the

00:33:48.460,00:33:53.899
plaintext or the output of the
Sbox. And the answer is yes it
does if you try to predict the

00:33:53.899,00:33:58.904
key it just doesn’t work. If you
try to predict uh the out
plaintext X or uh the key it

00:34:03.408,00:34:07.445
actually works really well. It’s
the one I showed you. The 5
percent work really well. Uh

00:34:07.445,00:34:12.450
spike a little bit after uh the
sub byte in which is plaintext X
or the key. So both work in that

00:34:16.821,00:34:23.428
implementation. However, if you
were to use something else it
might completely be different.

00:34:23.428,00:34:29.401
Uh it’s actually a different
implementation, it is dependent
on where is the leakage coming

00:34:29.401,00:34:33.405
from and so you don’t know where
the leakage is coming from so
that is another reason why we

00:34:33.405,00:34:39.644
need to scan computation is we
don’t know. So let finish this
thing by okay so now we have a

00:34:39.644,00:34:44.182
model, a working model, how do I
recover the key? Well as I said,
we’re going to make this very

00:34:44.182,00:34:48.386
nice probabilistic attack using
our predictions. And the way
it’s going to work is we’re

00:34:48.386,00:34:52.958
going to take a trace. Right?
The model which is trained and
it’s going to say, here are my

00:34:52.958,00:34:59.230
prediction. And we’re going to
accumulate them. So we’re going
to do it on a few traces. Uh you

00:34:59.230,00:35:04.869
can go to a 1000, 2000, 3000,
but really we don’t need that
much and then you going to sum

00:35:04.869,00:35:09.674
them and you’re going to take
the mon- the value of the
maximum value will be your best

00:35:09.674,00:35:13.678
predictions. What is very
interesting about deep-learning
is we also know what is a second

00:35:13.678,00:35:17.916
value and the third value and
the fourth value. So you even if
you don’t get it, try to again

00:35:17.916,00:35:22.087
with brute force and it’s very
easy to brute force because you
know it in which order to test

00:35:22.087,00:35:25.790
each of the byte because the
machine learning will tell you
which one are the most likely,

00:35:25.790,00:35:30.095
the second most likely is, third
most likely and the system which
is unique to deep-learning

00:35:30.095,00:35:36.601
compared to template attacks. Uh
also we cheated here again uh we
used log10 to track our traces

00:35:36.601,00:35:42.007
because it correct way to do it.
Um mathematically just probably
people who try to do it. And

00:35:42.007,00:35:46.511
then an important thing we found
out that very very few people
didn’t [inaudible] trace making

00:35:46.511,00:35:52.517
sure it works across chip. And
the way we do that is we train
the model on once one chip but

00:35:52.517,00:35:57.122
then we do the real attack we do
it on a second chip because we
want to make sure that the model

00:35:57.122,00:36:01.192
generalize around the difference
that there is between the chips
that are from the same family

00:36:01.192,00:36:05.196
right? You don’t want to test on
the same chip because all you
learn is the model which may be

00:36:05.196,00:36:10.602
dependent on the specific uh
chip you got. So we do 2 chips.
One for tech training, one for

00:36:10.602,00:36:15.607
testing. And then uh the last we
need to mention is ok so we have
our data set on our second chip,

00:36:17.742,00:36:22.480
how do we evaluate the
effectiveness of the attack. So
there is 4 ways. Uh the first

00:36:22.480,00:36:28.586
one is top 1 that curates which
is how many of your predictions
are in the top 1. Top 5. How

00:36:28.586,00:36:33.758
many predictions are in the top
5. Then mean rank. What is the
mean rank of your key? Remember

00:36:33.758,00:36:38.329
you are trying 56 predictions.
Crypto is supposed to be look
like random so 128 is your

00:36:38.329,00:36:42.967
baseline. And what is the max
rank? So the idea is, is the
machine learning have shifted

00:36:42.967,00:36:48.306
the spacer space and reduced it.
So the maximum give you some of
the idea. Now one thing we do

00:36:48.306,00:36:53.144
which is very different is we
try to recover 100 key and the
reason to recover 100 key is

00:36:53.144,00:36:57.182
because we want to make sure we
can recover wide range of key
rather than one specific key to

00:36:57.182,00:37:03.354
make sure we generalize. So the
holdout dataset is made of 100
key and we use 300 power trace

00:37:03.354,00:37:08.359
uh that we can accumulate uh and
see how well we do. So do we do
well? You know? The cat is very

00:37:11.229,00:37:16.234
anxious. He try and then yes!
Actually you can recover 100
percent of the tiniest key uh

00:37:18.870,00:37:23.875
using the attack I showed you
moreover. So 100 percent so 100
percent of the material because

00:37:26.444,00:37:31.249
while we have all of them
moreover what is a pull perhaps
what is more impressive for

00:37:31.249,00:37:34.185
people who know side-channel
attacks is why is the model
accuracy percent I see? And

00:37:34.185,00:37:40.558
that’s a very deceptive metric
uh we recover 100 percent of the
key with no prior processing but

00:37:40.558,00:37:46.698
also, in at most, 4 traces. Uh
when you computate that attack
uh with coding it’s about 5-6

00:37:46.698,00:37:51.803
traces so you are bet better
than state of the art even with
a simple model. And perhaps more

00:37:51.803,00:37:58.610
impressively if you are to use a
single trace you’ll get 81
percent of the key correct. And

00:37:58.610,00:38:02.947
I will show you how much more
powerful deep-learning is to do
such an attack, at least from my

00:38:02.947,00:38:07.418
tests and it’s really why we
claim it’s going to be the
future of it and that’s why we

00:38:07.418,00:38:11.723
try to get more people excited
to work with us on that. So to
wrap up because I think we have

00:38:11.723,00:38:16.361
uh 2 minute left uh we need to
deal with also protected
implementation which is not the

00:38:16.361,00:38:22.267
focus of this talk but are very
active field of research and to
deal with those things which

00:38:22.267,00:38:28.273
actually have no pattern uh you
need something way more and that
is what we are going to what we

00:38:28.273,00:38:33.444
are doing we are doing next.
Which is we are built a large
data test bed with 6 hardware 6

00:38:33.444,00:38:38.983
implementations including a few
hardware ones and protected
ones, created a 9 million sample

00:38:38.983,00:38:45.223
traces uh and trained over 5
thousand models and we hope to
make uh all the results as well

00:38:45.223,00:38:49.494
as well as all the model that
we’ve learned and all we’ve
learned into a paper soon uh so

00:38:49.494,00:38:55.500
you can share and try and
reproduce and help us uh work on
the next step. So the take away

00:38:55.500,00:39:02.240
is deep-learning is a future of
SCA and I hope we convince you
by the result and the advantage

00:39:02.240,00:39:06.644
of deep-learning of virtual
training technique are really
really big so it’s a big leap

00:39:06.644,00:39:10.949
it’s very different from what we
did before but that’s really
worth it. It’s really hard, you

00:39:10.949,00:39:15.587
fail a lot and so don’t get
discouraged. Uh you really need
automation. We don’t know how to

00:39:15.587,00:39:20.225
do it without automation. We are
not making it a pitch of like
hey let’s use their chip. We

00:39:20.225,00:39:23.861
don’t know how to do it
otherwise and this is how we
found a way the last few years

00:39:23.861,00:39:29.300
we are doing it and we really
built the beginning we are aware
of other researcher working on

00:39:29.300,00:39:34.339
symmetric, asymmetric and that
is with deep-learning and
finding great success. So this

00:39:34.339,00:39:39.811
is really where this thing is
heading and really uh if we can
automate side-channel attacks

00:39:39.811,00:39:44.282
then we will be able to go back
and focus on designing section
implementations of crypto that

00:39:44.282,00:39:49.687
we can test very efficiently so
we can provide the world way
more stronger crypto which is

00:39:49.687,00:39:53.758
really like strong
implementation which is really
what we want. We want to provide

00:39:53.758,00:39:58.830
uh very strong chip that we can
trust to put our secret in it.
So thank you so much for

00:39:58.830,00:40:03.768
attending today we are really
happy you take an hour to be
with us uh we hope that some of

00:40:03.768,00:40:08.339
you are inspired to do some of
this work with us or on your
own. Uh we put the slides today

00:40:08.339,00:40:13.344
on the url we have here. Thank
you so much. [applause]

