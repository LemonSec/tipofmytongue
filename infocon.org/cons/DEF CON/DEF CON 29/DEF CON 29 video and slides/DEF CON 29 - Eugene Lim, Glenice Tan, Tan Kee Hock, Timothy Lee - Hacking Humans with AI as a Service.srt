1
00:00:01,090 --> 00:00:01,923
- Hello, everyone.

2
00:00:01,923 --> 00:00:03,580
Thank you for attending our session.

3
00:00:03,580 --> 00:00:04,810
My name is Glenice.

4
00:00:04,810 --> 00:00:07,500
And together with my team,
we will be presenting,

5
00:00:07,500 --> 00:00:09,960
Hacking Humans with AI as a Service.

6
00:00:09,960 --> 00:00:12,390
We are part of a research
team of four from Singapore.

7
00:00:12,390 --> 00:00:14,530
We work at a government
technology agency's

8
00:00:14,530 --> 00:00:17,620
Cyber Security Group, or CSG for short.

9
00:00:17,620 --> 00:00:20,090
Let me introduce to you our team.

10
00:00:20,090 --> 00:00:22,763
Firstly, we have Eugene,
who has been working at CSG

11
00:00:22,763 --> 00:00:24,420
for about one and a half years.

12
00:00:24,420 --> 00:00:26,360
He specializes in Application Security

13
00:00:26,360 --> 00:00:28,260
and Vulnerability Research.

14
00:00:28,260 --> 00:00:30,120
He is also an avid white hat hacker.

15
00:00:30,120 --> 00:00:33,296
And many will know him by
his handle, Spaceracoon.

16
00:00:33,296 --> 00:00:34,600
Next up, this is me.

17
00:00:34,600 --> 00:00:35,760
I'm a part of the Red Team

18
00:00:35,760 --> 00:00:38,060
and Social Engineering Team in CSG.

19
00:00:38,060 --> 00:00:39,600
Apart from human hacking.

20
00:00:39,600 --> 00:00:42,580
I'm also interested in
web in cloud security.

21
00:00:42,580 --> 00:00:45,160
Along with Kee Hock be
presenting with us today.

22
00:00:45,160 --> 00:00:47,033
We lead the AI phishing exercises.

23
00:00:48,320 --> 00:00:51,190
Kee Hock has been at CSG for
about two and a half years,

24
00:00:51,190 --> 00:00:52,560
where he contributes to our Red Team

25
00:00:52,560 --> 00:00:54,750
and Cyber Engineering Capabilities.

26
00:00:54,750 --> 00:00:56,880
On top of that, he participates actively

27
00:00:56,880 --> 00:00:58,530
in Capture the Flag competitions.

28
00:00:59,800 --> 00:01:01,870
Last but not least, Timothy is a member

29
00:01:01,870 --> 00:01:04,620
of the Mobile Penetration
Testing Team at CSG.

30
00:01:04,620 --> 00:01:06,800
And also a (indistinct)
in Red Team exercises.

31
00:01:06,800 --> 00:01:08,580
He led the Technical Defense Research

32
00:01:08,580 --> 00:01:11,020
against AI generated texts.

33
00:01:11,020 --> 00:01:13,100
All right, let's get on
to the exciting stuff.

34
00:01:13,100 --> 00:01:14,850
Here's what we will cover today.

35
00:01:14,850 --> 00:01:17,100
Starting with an introduction
of human hacking.

36
00:01:17,100 --> 00:01:19,200
We also experience some challenges faced

37
00:01:19,200 --> 00:01:22,230
when conducting social
engineering exercises.

38
00:01:22,230 --> 00:01:25,630
Next, we'll have a quick look
at the recent advances in AI

39
00:01:25,630 --> 00:01:27,370
and how the challenges faced in phishing

40
00:01:27,370 --> 00:01:30,030
could be addressed with AI as a service.

41
00:01:30,030 --> 00:01:32,830
Then we will examine the
viability of human hacking

42
00:01:32,830 --> 00:01:35,420
using AI as a service with Tuna Fish,

43
00:01:35,420 --> 00:01:36,820
a service pipeline we developed

44
00:01:36,820 --> 00:01:39,370
for simulated phishing exercises.

45
00:01:39,370 --> 00:01:41,330
Finally, we're going to the defenses

46
00:01:41,330 --> 00:01:44,860
against AI phishing, such
as, automated AI detection

47
00:01:44,860 --> 00:01:48,610
before summing up important
takeaways from our presentation.

48
00:01:48,610 --> 00:01:51,410
Let's begin an introduction
to social engineering,

49
00:01:51,410 --> 00:01:52,510
the old school method.

50
00:01:53,950 --> 00:01:56,930
Social engineering is a
psychological manipulation of people

51
00:01:56,930 --> 00:01:59,560
into performing actions
they usually may not.

52
00:01:59,560 --> 00:02:02,810
Three common influencing
tactics include, authority,

53
00:02:02,810 --> 00:02:04,740
whether a attacker assimilates someone

54
00:02:04,740 --> 00:02:06,920
with the right to exercise their power.

55
00:02:06,920 --> 00:02:08,350
They may also attempt to manipulate

56
00:02:08,350 --> 00:02:11,840
the decision making process by
creating a sense of urgency.

57
00:02:11,840 --> 00:02:13,640
Providing context specific information

58
00:02:13,640 --> 00:02:15,360
tends to lower people's guard

59
00:02:15,360 --> 00:02:17,380
as the attacker attempts
to exploit the pattern

60
00:02:17,380 --> 00:02:18,793
targets are comfortable in.

61
00:02:19,690 --> 00:02:21,660
All this aims to exploit our blind spots

62
00:02:21,660 --> 00:02:23,710
and break security checks.

63
00:02:23,710 --> 00:02:25,140
Here are three common
ways social engineers

64
00:02:25,140 --> 00:02:26,780
can deliver their attack.

65
00:02:26,780 --> 00:02:28,290
Firstly, email phishing,

66
00:02:28,290 --> 00:02:30,830
which is the main focus
of our presentation today.

67
00:02:30,830 --> 00:02:33,090
I believe many of us here
are familiar with it.

68
00:02:33,090 --> 00:02:35,170
If you haven't received
a phishing email before,

69
00:02:35,170 --> 00:02:37,850
chances are you have, just unknowingly.

70
00:02:37,850 --> 00:02:39,890
Phishing can also be
done via a phone call,

71
00:02:39,890 --> 00:02:42,020
and that is known as vishing.

72
00:02:42,020 --> 00:02:44,900
Lastly, impersonation often
allows social engineers

73
00:02:44,900 --> 00:02:47,580
to enter a basis they
shouldn't have access to.

74
00:02:47,580 --> 00:02:50,410
Social engineering is practiced
for many different reasons,

75
00:02:50,410 --> 00:02:52,920
malicious actors wants
your money and information,

76
00:02:52,920 --> 00:02:55,568
so they create a pretext
in an attempt to beat you.

77
00:02:55,568 --> 00:02:57,490
But it can also be used
by authorized actors,

78
00:02:57,490 --> 00:03:00,080
such as Red Team engineers,
and those involved

79
00:03:00,080 --> 00:03:02,780
in raising awareness and
conducting security training.

80
00:03:03,910 --> 00:03:06,310
Speaking of security
training and exercises,

81
00:03:06,310 --> 00:03:08,200
here are some statistics.

82
00:03:08,200 --> 00:03:11,270
According to a 2020 report
by Terranova Security,

83
00:03:11,270 --> 00:03:14,150
almost one fifth of employees
in the targeted companies

84
00:03:14,150 --> 00:03:16,320
click on simulated phishing email links,

85
00:03:16,320 --> 00:03:19,780
even after going through a
training program previously.

86
00:03:19,780 --> 00:03:22,010
This rate increased to 43% in the study

87
00:03:22,010 --> 00:03:25,143
on spear-phishing emails
against more general users.

88
00:03:26,340 --> 00:03:28,660
How are phishing emails
sent to the victims?

89
00:03:28,660 --> 00:03:30,910
Let's now take a look at
email phishing campaign

90
00:03:30,910 --> 00:03:32,793
from a victim engineer's perspective.

91
00:03:35,190 --> 00:03:37,170
Here is a typical manual phishing workflow

92
00:03:37,170 --> 00:03:39,030
in a simulated phishing exercise.

93
00:03:39,030 --> 00:03:40,670
The victim operator would typically start

94
00:03:40,670 --> 00:03:43,040
with intelligence gathering of the target.

95
00:03:43,040 --> 00:03:45,303
This is also commonly
referred to as OSINT.

96
00:03:46,490 --> 00:03:49,040
This includes looking at
your social media presence.

97
00:03:49,040 --> 00:03:51,690
OSINT can be done manually
or with the help of tools.

98
00:03:53,070 --> 00:03:55,100
Then with the understanding
of the targets,

99
00:03:55,100 --> 00:03:58,550
the operators work on crafting
a suitable phishing email.

100
00:03:58,550 --> 00:04:00,880
The amount of time required
for context generation

101
00:04:00,880 --> 00:04:02,890
varies depending on each target.

102
00:04:02,890 --> 00:04:05,040
The Red Team operator will
also craft their email

103
00:04:05,040 --> 00:04:07,240
based on different weapons of influence,

104
00:04:07,240 --> 00:04:11,250
such as, authority, scarcity, and so on.

105
00:04:11,250 --> 00:04:13,490
We can see that the
entire workflow is manual

106
00:04:13,490 --> 00:04:15,103
and dependent on the operators.

107
00:04:16,270 --> 00:04:19,090
Even though spear-phishing
often yields good results,

108
00:04:19,090 --> 00:04:21,640
it may require significant time and effort

109
00:04:21,640 --> 00:04:23,570
to analyze the results from OSINT,

110
00:04:23,570 --> 00:04:27,080
contextualize it and bring
some of possible pretexts.

111
00:04:27,080 --> 00:04:29,360
These efforts increase
with each new target

112
00:04:29,360 --> 00:04:31,560
and these challenges can
be broadly categorized

113
00:04:31,560 --> 00:04:36,190
as behavior analysis and text generation.

114
00:04:36,190 --> 00:04:38,503
Interestingly, these are
also strengths of AI.

115
00:04:40,340 --> 00:04:43,490
Capabilities of AI have
improved over the past few years

116
00:04:43,490 --> 00:04:45,520
and we now have a greater understanding

117
00:04:45,520 --> 00:04:47,000
and more realistic expectation

118
00:04:47,000 --> 00:04:49,650
of what AI can do and cannot do.

119
00:04:49,650 --> 00:04:51,390
For a start, here are some tools

120
00:04:51,390 --> 00:04:53,660
that are meant to be used
by recruiters and promoters

121
00:04:53,660 --> 00:04:56,120
to automatically analyze
public information

122
00:04:56,120 --> 00:04:58,270
such as LinkedIn profiles.

123
00:04:58,270 --> 00:05:00,210
Coming from an ethics perspective,

124
00:05:00,210 --> 00:05:03,800
we could repurpose it to
perform personality analysis.

125
00:05:03,800 --> 00:05:06,520
Although the results could only
provide a general direction,

126
00:05:06,520 --> 00:05:08,040
it is a good foundation for the Red Team

127
00:05:08,040 --> 00:05:09,093
engineers to work on.

128
00:05:10,500 --> 00:05:13,030
Humantic AI was used in
our phishing pipeline,

129
00:05:13,030 --> 00:05:14,880
but many of these tools have a freedom

130
00:05:14,880 --> 00:05:17,780
that allows anyone to register
and use the API right away.

131
00:05:18,880 --> 00:05:20,550
Next up, text generation.

132
00:05:20,550 --> 00:05:23,240
During last year OpenAI
released a text-in, text-out

133
00:05:23,240 --> 00:05:24,510
interface for assessing the state

134
00:05:24,510 --> 00:05:27,690
of the GPT-3 language model family.

135
00:05:27,690 --> 00:05:30,320
The initial release of the
API generated a lot of hype,

136
00:05:30,320 --> 00:05:32,420
such as, an article in "The Guardian",

137
00:05:32,420 --> 00:05:34,883
that's claimed to be
written by the GBT-3 API.

138
00:05:35,760 --> 00:05:37,960
While the amount of
curation inputs are unknown,

139
00:05:37,960 --> 00:05:41,270
it was good, GPT-3 possessed
significant capabilities

140
00:05:41,270 --> 00:05:42,943
in natural language generation.

141
00:05:43,990 --> 00:05:46,990
In practical terms, the GPT-3 API in this

142
00:05:46,990 --> 00:05:49,163
presents a major accessibility.

143
00:05:50,050 --> 00:05:52,070
Based on the estimates by Lambda Labs,

144
00:05:52,070 --> 00:05:54,730
GPT-3 will have taken
a really long copy time

145
00:05:54,730 --> 00:05:56,630
and millions of dollars (indistinct).

146
00:05:56,630 --> 00:05:59,200
But users can now use it via the API

147
00:05:59,200 --> 00:06:01,343
for just a few cents per thousand tokens.

148
00:06:03,180 --> 00:06:05,220
Open API provides four language models

149
00:06:05,220 --> 00:06:08,053
of different quality and
price from Ada to Davinci.

150
00:06:08,900 --> 00:06:11,460
The instruct-series beta
for Curie and Davinci

151
00:06:11,460 --> 00:06:13,950
are recently released,
optimized to understand

152
00:06:13,950 --> 00:06:15,570
and follow text instruction.

153
00:06:15,570 --> 00:06:17,510
As a simple example, we could input

154
00:06:17,510 --> 00:06:19,030
the following instructions.

155
00:06:19,030 --> 00:06:21,340
Explain quantum physics to a six year old

156
00:06:21,340 --> 00:06:24,470
and here's what the API
returned to the instruction.

157
00:06:24,470 --> 00:06:27,217
How realistic are the
emails generated by OpenAI?

158
00:06:28,060 --> 00:06:30,480
With this few sentence,
we instruct the model

159
00:06:30,480 --> 00:06:32,770
to create an email to encourage target

160
00:06:32,770 --> 00:06:34,660
to open an attached document.

161
00:06:34,660 --> 00:06:35,493
Right.

162
00:06:35,493 --> 00:06:37,120
Nicely done there with
a proper email format.

163
00:06:38,750 --> 00:06:41,130
We've created a context
and detailed instructions.

164
00:06:41,130 --> 00:06:43,420
No model may generate
coherent email content

165
00:06:43,420 --> 00:06:45,943
for the considerations of
the Red Team operators.

166
00:06:47,680 --> 00:06:49,210
When generating context,

167
00:06:49,210 --> 00:06:52,190
the temperature parameter
in OpenAI comes in handy.

168
00:06:52,190 --> 00:06:54,730
It controls the randomness
of the text generator,

169
00:06:54,730 --> 00:06:56,950
the lower the temperature,
the more deterministic

170
00:06:56,950 --> 00:06:58,750
area of the particular results.

171
00:06:58,750 --> 00:07:00,440
Thus, with the same prompt,

172
00:07:00,440 --> 00:07:02,890
a different type of
output can be obtained.

173
00:07:02,890 --> 00:07:05,690
This will likely ease the
process of pretext generation.

174
00:07:07,200 --> 00:07:10,000
Having introduced the viability
of an AI phishing pipeline,

175
00:07:10,000 --> 00:07:11,850
how are the results in the real world?

176
00:07:11,850 --> 00:07:13,190
I'll let Kee Hock elaborate on this

177
00:07:13,190 --> 00:07:15,390
and deliver the rest of our presentation.

178
00:07:15,390 --> 00:07:16,530
Over to you, Kee Hock.

179
00:07:18,830 --> 00:07:20,060
- Thanks, Glenice.

180
00:07:20,060 --> 00:07:20,910
Hello, everyone.

181
00:07:20,910 --> 00:07:22,320
I'm Kee Hock.

182
00:07:22,320 --> 00:07:24,840
I will be sharing more on how
we can use AI as a service

183
00:07:24,840 --> 00:07:27,550
in Red Team operations, particularly

184
00:07:27,550 --> 00:07:29,503
in the conduct of phishing campaigns.

185
00:07:30,560 --> 00:07:32,730
In addition, I'll be
sharing our team's work

186
00:07:32,730 --> 00:07:35,080
on detecting synthetic texts and also

187
00:07:35,080 --> 00:07:37,320
to highlight some good
governance practices

188
00:07:37,320 --> 00:07:40,983
in which both AI service
suppliers and consumers can adopt.

189
00:07:45,080 --> 00:07:47,070
Previously, Glanice did a good job

190
00:07:47,070 --> 00:07:49,200
on highlighting some of the AI services

191
00:07:49,200 --> 00:07:50,553
available in the market.

192
00:07:51,430 --> 00:07:52,700
What you see in this diagram

193
00:07:52,700 --> 00:07:54,500
is the revised phishing workflow

194
00:07:54,500 --> 00:07:56,900
after we applied various AI services,

195
00:07:56,900 --> 00:08:00,030
during the different stages
of the phishing campaign.

196
00:08:00,030 --> 00:08:02,873
I'll be focusing on the key
differences in the workflow.

197
00:08:05,047 --> 00:08:07,290
Firstly, Red Team operators will perform

198
00:08:07,290 --> 00:08:09,060
reconnaissance on the target, such as,

199
00:08:09,060 --> 00:08:11,540
gathering the target's LinkedIn profile,

200
00:08:11,540 --> 00:08:13,413
Twitter profile, blog posts.

201
00:08:18,350 --> 00:08:21,000
Next, we'll feed this
open source information

202
00:08:21,000 --> 00:08:23,800
into Humantics AI, which will perform

203
00:08:23,800 --> 00:08:25,803
personality analysis on the target.

204
00:08:26,870 --> 00:08:28,600
For phishing context generation,

205
00:08:28,600 --> 00:08:31,760
we repurposed Humantics AI API demo

206
00:08:31,760 --> 00:08:33,633
to perform personality analysis.

207
00:08:34,650 --> 00:08:36,800
The service is meant to
be used by recruiters

208
00:08:36,800 --> 00:08:40,490
and sales people to automatically
analyze public information

209
00:08:40,490 --> 00:08:44,210
such as LinkedIn profiles, to
produce a personality report

210
00:08:44,210 --> 00:08:46,393
and generate competition advice.

211
00:08:47,520 --> 00:08:50,700
The Humantics AI API will
return adjacent output

212
00:08:50,700 --> 00:08:52,800
as shown in this snippet here.

213
00:08:52,800 --> 00:08:55,853
It contains the personality
analysis results of the target.

214
00:08:56,980 --> 00:08:58,640
Just a point to note, Humantics AI

215
00:08:58,640 --> 00:09:00,300
is just one of many AI services

216
00:09:00,300 --> 00:09:02,800
which you can adopt in this pipeline.

217
00:09:02,800 --> 00:09:05,900
Depending on your preferences,
you can choose to integrate

218
00:09:05,900 --> 00:09:08,163
other personality analysis services.

219
00:09:09,460 --> 00:09:11,190
We thought it would be
cool to use these services

220
00:09:11,190 --> 00:09:12,700
from a different speed, especially

221
00:09:12,700 --> 00:09:14,283
with a Red Teaming perspective.

222
00:09:15,230 --> 00:09:16,880
These services are extremely useful

223
00:09:16,880 --> 00:09:19,500
as they help us quickly
analyze the targets

224
00:09:19,500 --> 00:09:21,910
and allows us to crop up more
personalized instruction set

225
00:09:21,910 --> 00:09:23,060
to feed OpenAI's GPT-3.

226
00:09:27,090 --> 00:09:29,330
Next, we have passed the adjacent output

227
00:09:29,330 --> 00:09:31,610
into simple set of plaintext instructions

228
00:09:31,610 --> 00:09:34,990
and feed it to OpenAI's GPT-3 model.

229
00:09:34,990 --> 00:09:36,830
Essentially, the plaintext instruction

230
00:09:36,830 --> 00:09:38,740
described to the model about the target

231
00:09:38,740 --> 00:09:40,790
and how to approach them.

232
00:09:40,790 --> 00:09:42,180
Depending on a team's requirement,

233
00:09:42,180 --> 00:09:44,930
the logic to pass adjacent
output can be customized

234
00:09:44,930 --> 00:09:47,160
to feed a certain context.

235
00:09:47,160 --> 00:09:49,230
For example, you may
want the AI to generate

236
00:09:49,230 --> 00:09:51,523
a text message instead of an email.

237
00:09:52,560 --> 00:09:55,110
In this example, we are
simply asking the model

238
00:09:55,110 --> 00:09:57,760
to craft an email, to convince the target

239
00:09:57,760 --> 00:10:00,090
to take interest in our company.

240
00:10:00,090 --> 00:10:02,603
We ask the model to be
formal and objective.

241
00:10:04,790 --> 00:10:08,180
Finally, we have the
output for OpenAI's GPT-3.

242
00:10:08,180 --> 00:10:10,590
At this point, depending on
the team's comfort level,

243
00:10:10,590 --> 00:10:12,190
you may choose to edit the output

244
00:10:12,190 --> 00:10:14,500
to repay some of the
elements of the content.

245
00:10:14,500 --> 00:10:17,350
For example, you may
choose to change the sender

246
00:10:17,350 --> 00:10:19,630
to another team or department.

247
00:10:19,630 --> 00:10:21,610
In our experiment, which
we will share later on,

248
00:10:21,610 --> 00:10:24,950
we made edits to the center
and the subject title.

249
00:10:24,950 --> 00:10:27,400
We refrained from editing
the main email content.

250
00:10:28,440 --> 00:10:30,990
As you can see, the
generated email is coherent

251
00:10:30,990 --> 00:10:33,980
and fairly convincing, applying authority

252
00:10:33,980 --> 00:10:36,493
and consistency in its instructions.

253
00:10:37,890 --> 00:10:40,780
However, there are a few quotes
that require human edits.

254
00:10:40,780 --> 00:10:43,699
For example, you may want
to add in a phishing link

255
00:10:43,699 --> 00:10:45,743
or you are containing the phishing link.

256
00:10:46,780 --> 00:10:50,520
Nevertheless, this demonstrates
the need for a human

257
00:10:50,520 --> 00:10:53,023
in the loop for this AI phishing pipeline.

258
00:10:54,800 --> 00:10:56,320
Now, the phishing content is generated

259
00:10:56,320 --> 00:10:57,653
and ready to be delivered.

260
00:10:58,520 --> 00:10:59,740
For the subsequent steps,

261
00:10:59,740 --> 00:11:02,080
it'll be the same as any
other phishing workflow

262
00:11:02,080 --> 00:11:04,460
like the one Glenice shared earlier.

263
00:11:04,460 --> 00:11:07,280
So, in our case, each phishing
email sent to the target

264
00:11:07,280 --> 00:11:09,670
has a unique phishing
link, which helps to track

265
00:11:09,670 --> 00:11:11,840
if the target click on that phishing link.

266
00:11:13,660 --> 00:11:15,610
You may choose to use
any phishing framework

267
00:11:15,610 --> 00:11:18,270
to perform the delivery
or the phishing emails.

268
00:11:18,270 --> 00:11:20,000
In our case, we built a custom pipeline

269
00:11:20,000 --> 00:11:23,010
with a custom phishing tracking system.

270
00:11:23,010 --> 00:11:24,760
This will still accommodate
some of the constraints

271
00:11:24,760 --> 00:11:27,143
we face when conducting
the phishing exercises.

272
00:11:28,050 --> 00:11:29,560
Before I talk about experiment,

273
00:11:29,560 --> 00:11:31,710
I would like to share that,
although we build our pipeline

274
00:11:31,710 --> 00:11:34,040
with a custom user interface and backend,

275
00:11:34,040 --> 00:11:36,220
the possibility of your API's

276
00:11:36,220 --> 00:11:38,010
meant that we could easily integrate this

277
00:11:38,010 --> 00:11:39,770
into any existing tools,

278
00:11:39,770 --> 00:11:43,100
such as the GoFish open
source phish Framework.

279
00:11:43,100 --> 00:11:45,870
This highlights how AI
service offers a step up

280
00:11:45,870 --> 00:11:49,250
in accessibility from open
source language models,

281
00:11:49,250 --> 00:11:51,930
rather than having to
worry about a compute

282
00:11:51,930 --> 00:11:54,150
and server-side generation.

283
00:11:54,150 --> 00:11:56,910
Adding AI capabilities
simply requires an API key

284
00:11:56,910 --> 00:11:58,403
and a (indistinct) request.

285
00:12:01,640 --> 00:12:04,670
We put the revised workflow
to the test for three months.

286
00:12:04,670 --> 00:12:06,670
We conducted two types of experiments

287
00:12:06,670 --> 00:12:09,750
with over 200 targets across multiple

288
00:12:09,750 --> 00:12:11,833
authorized phishing exercises.

289
00:12:12,690 --> 00:12:13,820
The first side of our experiment,

290
00:12:13,820 --> 00:12:15,700
which we call Type One Experiment,

291
00:12:15,700 --> 00:12:18,180
is designed to investigate
the effectiveness

292
00:12:18,180 --> 00:12:21,110
of convincing the targets to
click on the phishing link

293
00:12:21,110 --> 00:12:22,333
in a phishing email.

294
00:12:23,182 --> 00:12:27,380
Our Type One Experiment, each
target receive two emails.

295
00:12:27,380 --> 00:12:28,820
One will be generated by the AI,

296
00:12:28,820 --> 00:12:30,640
while the other will be generated manually

297
00:12:30,640 --> 00:12:32,003
by the Red Team operator.

298
00:12:32,860 --> 00:12:34,080
The second type of experiment

299
00:12:34,080 --> 00:12:36,110
which we call Type Two Experiment,

300
00:12:36,110 --> 00:12:38,130
is designed to investigate effectiveness

301
00:12:38,130 --> 00:12:39,670
of convincing the targets to open

302
00:12:39,670 --> 00:12:42,073
malicious attachment in the email.

303
00:12:43,000 --> 00:12:44,620
For Type Two Experiment, the target group

304
00:12:44,620 --> 00:12:47,420
is further divided into two subgroups.

305
00:12:47,420 --> 00:12:50,260
One subgroup will receive AI
generated phishing content,

306
00:12:50,260 --> 00:12:52,290
while the other will
receive phishing content

307
00:12:52,290 --> 00:12:54,490
generated manually by
the Red Team operator.

308
00:12:59,040 --> 00:13:00,990
Next, I'll elaborate more about a set up

309
00:13:00,990 --> 00:13:02,670
for a Type One Experiment.

310
00:13:02,670 --> 00:13:06,380
Essentially, we conducted in two stages.

311
00:13:06,380 --> 00:13:08,930
Stage one, is a mass phishing exercise

312
00:13:08,930 --> 00:13:12,690
to identify targets who are
susceptible to phishing.

313
00:13:12,690 --> 00:13:15,460
Stage two, is a spear-phishing exercise

314
00:13:15,460 --> 00:13:17,350
to harvest credentials from the targets

315
00:13:17,350 --> 00:13:18,793
identified from stage one.

316
00:13:20,180 --> 00:13:23,500
For each stage, we
collect a few key metrics.

317
00:13:23,500 --> 00:13:25,400
First, we measure the
phishing success rate,

318
00:13:25,400 --> 00:13:27,171
which is the percentage of targets

319
00:13:27,171 --> 00:13:28,671
clicking on the phishing link.

320
00:13:29,680 --> 00:13:31,440
Next, I'll elaborate more about a set up

321
00:13:31,440 --> 00:13:33,160
for a Type One Experiment.

322
00:13:33,160 --> 00:13:35,970
Essentially, we conducted
it in two stages.

323
00:13:35,970 --> 00:13:37,720
Stage one is a mass phishing exercise

324
00:13:37,720 --> 00:13:40,990
to identify targets who are
susceptible to phishing.

325
00:13:40,990 --> 00:13:43,150
Stage two is a spear-phishing exercise

326
00:13:43,150 --> 00:13:44,790
to harvest credentials from the targets

327
00:13:44,790 --> 00:13:46,193
identified from stage one.

328
00:13:47,570 --> 00:13:50,440
For each stage, we
collect a few key metrics.

329
00:13:50,440 --> 00:13:52,350
First, we measure the
phishing success rate,

330
00:13:52,350 --> 00:13:53,980
which is the percentage of targets

331
00:13:53,980 --> 00:13:55,480
clicking on the phishing link.

332
00:13:56,330 --> 00:13:58,710
Next, from the victims
who click on the links,

333
00:13:58,710 --> 00:14:00,810
we observe the interaction
and measure the percentage

334
00:14:00,810 --> 00:14:03,653
of victims that interacted
with the phishing site.

335
00:14:04,550 --> 00:14:06,520
The table you see on the
right is a sample size

336
00:14:06,520 --> 00:14:08,100
for each phishing exercise conducted

337
00:14:08,100 --> 00:14:10,660
using Type One Experiment set up.

338
00:14:10,660 --> 00:14:12,810
Notice that there are some
rows under the human column

339
00:14:12,810 --> 00:14:16,070
that are empty, especially for stage two.

340
00:14:16,070 --> 00:14:18,370
This is because there are
no victims who fell prey

341
00:14:18,370 --> 00:14:21,423
in stage one for the content
generated by human operators.

342
00:14:26,010 --> 00:14:28,280
So this is the results from
our Type One Experiment

343
00:14:28,280 --> 00:14:31,470
for stage one mass phishing campaign.

344
00:14:31,470 --> 00:14:33,660
The results are encouraging.

345
00:14:33,660 --> 00:14:35,430
To then interpret the chart,

346
00:14:35,430 --> 00:14:37,030
we take a look at the bar chart.

347
00:14:46,080 --> 00:14:49,300
Next, we will show the results
from our Type One Experiment,

348
00:14:49,300 --> 00:14:52,290
for stage one mass phishing campaign.

349
00:14:52,290 --> 00:14:54,250
The results are encouraging.

350
00:14:54,250 --> 00:14:55,370
To interpret this chart,

351
00:14:55,370 --> 00:14:57,420
we take a look at the bar chart first.

352
00:14:57,420 --> 00:15:00,920
For example, the column
represents the exercise.

353
00:15:00,920 --> 00:15:03,710
In exercise A, 20% of the targets

354
00:15:03,710 --> 00:15:05,670
picked on the phishing link
from the phishing content

355
00:15:05,670 --> 00:15:07,700
generated by AI, while none fell prey

356
00:15:07,700 --> 00:15:11,030
for the phishing content
generated by humans.

357
00:15:11,030 --> 00:15:12,460
Then we move down.

358
00:15:12,460 --> 00:15:14,720
We look at a corresponding pie chart.

359
00:15:14,720 --> 00:15:16,670
For exercise A, 80% of victims

360
00:15:16,670 --> 00:15:18,520
who clicked on the phishing link

361
00:15:18,520 --> 00:15:20,600
interacted with the phishing site.

362
00:15:20,600 --> 00:15:22,220
In our case, they
interacted with the forms

363
00:15:22,220 --> 00:15:23,270
on our phishing site.

364
00:15:24,970 --> 00:15:27,190
While AI outperformed
the human counterparts

365
00:15:27,190 --> 00:15:30,380
in exercise A and C, exercise B

366
00:15:30,380 --> 00:15:32,680
tells us a slightly different story.

367
00:15:32,680 --> 00:15:34,110
In the bar chart for exercise B,

368
00:15:34,110 --> 00:15:36,330
we see that human generated content

369
00:15:36,330 --> 00:15:39,280
had a 9.4% phishing success rate,

370
00:15:39,280 --> 00:15:42,950
while the AI generated
content only had an 8.55%

371
00:15:42,950 --> 00:15:44,660
phishing success rate.

372
00:15:44,660 --> 00:15:45,710
In terms of raw numbers,

373
00:15:45,710 --> 00:15:47,310
the differences in percentages

374
00:15:47,310 --> 00:15:49,290
translated just one more victim

375
00:15:49,290 --> 00:15:51,590
who fell pray for the
human generated content.

376
00:15:54,720 --> 00:15:57,180
Now, we move on to stage two results.

377
00:15:57,180 --> 00:15:59,370
Just want to reiterate
that stage two victims

378
00:15:59,370 --> 00:16:01,570
were identified from stage one.

379
00:16:01,570 --> 00:16:03,880
Basically, those who click on
a phishing link from stage one

380
00:16:03,880 --> 00:16:06,220
will be our target for stage two.

381
00:16:06,220 --> 00:16:07,900
The only difference here
is that we are conducting

382
00:16:07,900 --> 00:16:09,940
a spear-phishing exercise,

383
00:16:09,940 --> 00:16:12,290
which means that phishing
content is more personalized

384
00:16:12,290 --> 00:16:14,023
using the workflow revised.

385
00:16:15,070 --> 00:16:18,280
In this chart, for exercise
A, we see considerable success

386
00:16:18,280 --> 00:16:21,740
in convincing the victims to
click on the phishing link.

387
00:16:21,740 --> 00:16:25,333
And 33.3% of them attempted
to submit their credentials.

388
00:16:26,960 --> 00:16:28,980
Exercise B, results were more interesting

389
00:16:28,980 --> 00:16:31,620
because in stage one,
human generated content

390
00:16:31,620 --> 00:16:33,760
outperformed the AI counterpart.

391
00:16:33,760 --> 00:16:35,850
But in stage two, AI outperformed

392
00:16:35,850 --> 00:16:37,273
the human generated content.

393
00:16:38,150 --> 00:16:40,810
For exercise C, our phishing site

394
00:16:40,810 --> 00:16:43,450
is (indistinct) by most
browsers as a deceptive site.

395
00:16:43,450 --> 00:16:45,940
We postulate that the
corresponding phishing emails

396
00:16:45,940 --> 00:16:48,140
are likely to be caught by email filters

397
00:16:48,140 --> 00:16:50,350
or any other defensive controls.

398
00:16:50,350 --> 00:16:53,073
Thus, the experiment kind
of stopped for exercise C.

399
00:16:56,660 --> 00:16:59,110
Finally, let's talk about
Type Two Experiment,

400
00:16:59,110 --> 00:17:01,070
whereby we investigated effectiveness

401
00:17:01,070 --> 00:17:04,030
of phishing content
generated by AI and human

402
00:17:04,030 --> 00:17:06,700
in convincing the targets
to open malicious documents

403
00:17:06,700 --> 00:17:07,933
attached in the email.

404
00:17:08,860 --> 00:17:11,980
For Type Two Experiment,
we only conducted stage one

405
00:17:11,980 --> 00:17:14,930
mass phishing campaign
for both target groups.

406
00:17:14,930 --> 00:17:16,110
Do note that the target groups

407
00:17:16,110 --> 00:17:18,790
are receiving either
of the phishing content

408
00:17:18,790 --> 00:17:20,043
are mutually exclusive.

409
00:17:21,040 --> 00:17:23,570
For Type Two Experiment, we
are looking at the percentage

410
00:17:23,570 --> 00:17:26,800
of targets who open
the malicious document.

411
00:17:26,800 --> 00:17:29,300
In this exercise, the AI generated content

412
00:17:29,300 --> 00:17:32,513
convinced more targets to
open the malicious document.

413
00:17:36,230 --> 00:17:39,250
From our experiment, we've
made thee key observations.

414
00:17:39,250 --> 00:17:41,660
Firstly, the revised phishing workflow

415
00:17:41,660 --> 00:17:43,320
using AI as a service definitely helped

416
00:17:43,320 --> 00:17:45,560
to reduce the time required
for phishing content

417
00:17:45,560 --> 00:17:47,680
curation and context analysis.

418
00:17:47,680 --> 00:17:50,510
This allows Red Team operators
to focus on other tasks,

419
00:17:50,510 --> 00:17:53,500
such as performing OSINT
investigation on targets,

420
00:17:53,500 --> 00:17:55,250
which can be difficult to automate.

421
00:17:56,170 --> 00:17:58,370
Next, we observed that
AI generated content

422
00:17:58,370 --> 00:18:01,160
was more convincing compared
to the human counterparts.

423
00:18:01,160 --> 00:18:02,910
However, this is still not conclusive,

424
00:18:02,910 --> 00:18:05,300
as there may be other variables at work.

425
00:18:05,300 --> 00:18:06,790
Nonetheless, this is an indication

426
00:18:06,790 --> 00:18:08,810
that AI does have a lot of potential

427
00:18:08,810 --> 00:18:10,993
in innovating Red Team operations.

428
00:18:12,000 --> 00:18:14,050
Lastly, we observed that
there's a varying degree

429
00:18:14,050 --> 00:18:15,710
of governance relating to the access

430
00:18:15,710 --> 00:18:17,810
of AI services in the market.

431
00:18:17,810 --> 00:18:19,360
For example, during our research,

432
00:18:19,360 --> 00:18:21,600
some of the AI services can be accessed

433
00:18:21,600 --> 00:18:24,920
by simply registering for a trial account,

434
00:18:24,920 --> 00:18:28,270
while services like OpenAI
was certainly way stricter

435
00:18:28,270 --> 00:18:30,690
in terms of the usage, as
they validated use cases

436
00:18:30,690 --> 00:18:32,600
by the individual when they attempt

437
00:18:32,600 --> 00:18:33,950
to register for an account.

438
00:18:39,190 --> 00:18:40,740
Having demonstrated the viability

439
00:18:40,740 --> 00:18:43,100
of an AI phishing pipeline,

440
00:18:43,100 --> 00:18:46,508
we decided to explore
potential defenses against it.

441
00:18:46,508 --> 00:18:48,000
This is a important question,

442
00:18:48,000 --> 00:18:50,943
as success to AI as a
service grows over time.

443
00:18:51,850 --> 00:18:53,570
In the next segment, I'll be sharing more

444
00:18:53,570 --> 00:18:55,250
about the possible defenses against

445
00:18:55,250 --> 00:18:57,350
AI generated phishing content.

446
00:18:57,350 --> 00:18:59,330
Kudos to Timothy for the heavy lifting

447
00:18:59,330 --> 00:19:01,163
on this aspect of the research.

448
00:19:06,350 --> 00:19:08,540
Naturally, the first thing
that came into our mind

449
00:19:08,540 --> 00:19:10,610
is to detect synthetic text.

450
00:19:10,610 --> 00:19:14,450
However, detecting synthetic
texts remains a hard problem.

451
00:19:14,450 --> 00:19:17,690
There are three main ways that
we can go about solving this.

452
00:19:17,690 --> 00:19:19,860
Simple classifiers where
we define certain rules

453
00:19:19,860 --> 00:19:24,053
based on tags or using
MLBs and LT classifiers.

454
00:19:25,230 --> 00:19:26,710
Fine-tuning based detection,

455
00:19:26,710 --> 00:19:28,580
where we train a new model based on inputs

456
00:19:28,580 --> 00:19:31,744
from different kinds of
language models from GPT-3,

457
00:19:31,744 --> 00:19:34,773
GPT-2, BRT, and so on.

458
00:19:35,640 --> 00:19:37,950
Zero-shot detection, using this method,

459
00:19:37,950 --> 00:19:40,400
the models learn a classifier
on a set of labels,

460
00:19:40,400 --> 00:19:42,960
and then evaluates on a
different set of labels

461
00:19:42,960 --> 00:19:45,283
that a classifier had never seen before.

462
00:19:46,530 --> 00:19:47,980
We have decided on this approach

463
00:19:47,980 --> 00:19:50,140
as it gives us more flexibility,

464
00:19:50,140 --> 00:19:51,610
as we will be able to use it

465
00:19:51,610 --> 00:19:53,660
to predict other sets of language models.

466
00:19:55,400 --> 00:19:57,920
The white paper for GLTR has given us

467
00:19:57,920 --> 00:20:00,363
insightful solution to tackle our problem.

468
00:20:01,970 --> 00:20:04,730
Again, we want to highlight
that detecting synthetic texts

469
00:20:04,730 --> 00:20:08,210
still depends on the model
that's used to generate a text

470
00:20:08,210 --> 00:20:10,193
and a model use for text detection.

471
00:20:12,805 --> 00:20:15,980
(indistinct) Language Model
Test Room, or GLTR for short,

472
00:20:15,980 --> 00:20:17,850
is a project based on a collaboration

473
00:20:17,850 --> 00:20:22,850
between MITIBM (indistinct)
and Harvard NRP.

474
00:20:23,240 --> 00:20:24,810
Based on the white paper released by them,

475
00:20:24,810 --> 00:20:26,710
the approach to detect synthetic texts

476
00:20:26,710 --> 00:20:28,490
were the probability of a word

477
00:20:28,490 --> 00:20:31,290
given the previous words in sequence.

478
00:20:31,290 --> 00:20:33,290
The absolute rank of a word,

479
00:20:33,290 --> 00:20:36,173
the entropy of the predicted distribution.

480
00:20:37,390 --> 00:20:40,170
Our research used the same
metrics along with GPT-3

481
00:20:40,170 --> 00:20:41,960
to evaluate if an email is written

482
00:20:41,960 --> 00:20:44,780
by a language model or a human.

483
00:20:44,780 --> 00:20:47,600
We have also formed GLTR report

484
00:20:47,600 --> 00:20:50,893
and used the GPT-3 model
as shown in the screenshot.

485
00:20:56,630 --> 00:20:59,400
While deciding the approach
of detecting synthetic texts

486
00:20:59,400 --> 00:21:02,320
by GPT-3, one major
challenge our team faced

487
00:21:02,320 --> 00:21:04,840
was that we do not have
direct access to the model.

488
00:21:04,840 --> 00:21:07,720
Without their access, we are
limited in the parameters

489
00:21:07,720 --> 00:21:09,740
that we are able to control.

490
00:21:09,740 --> 00:21:11,480
We are also limited in the datasets

491
00:21:11,480 --> 00:21:13,390
that has returned from generated texts,

492
00:21:13,390 --> 00:21:17,430
such as, top 100, lock
prop, or choice of words.

493
00:21:17,430 --> 00:21:19,780
We have decided to extend
GLTR in our research

494
00:21:19,780 --> 00:21:21,660
as the data we can get from GPT-3

495
00:21:21,660 --> 00:21:24,600
has transferable patterns from GPT-2,

496
00:21:24,600 --> 00:21:26,820
which was used in GLTR.

497
00:21:26,820 --> 00:21:29,823
With that you will look at
the finding from our research.

498
00:21:31,140 --> 00:21:33,090
In our tests, we compared GPT-3,

499
00:21:33,090 --> 00:21:38,090
GPT-2, GPT-2 Tuned and human samples.

500
00:21:38,120 --> 00:21:41,870
Our GPT-2 Tuned model is
based on an email corpus

501
00:21:41,870 --> 00:21:43,270
that our team has harvested.

502
00:21:44,420 --> 00:21:46,830
For GPT-2 and GPT-2 Tune model,

503
00:21:46,830 --> 00:21:48,480
we followd the settings that was described

504
00:21:48,480 --> 00:21:49,523
in the white paper.

505
00:21:50,820 --> 00:21:52,640
We found that human samples,

506
00:21:52,640 --> 00:21:55,850
humans frequently use words
that are out of the top 100

507
00:21:55,850 --> 00:21:58,053
predictions from the GPT models.

508
00:22:01,870 --> 00:22:03,340
We found that for human samples,

509
00:22:03,340 --> 00:22:06,510
humans frequently use words
that are out of the top 100

510
00:22:06,510 --> 00:22:08,493
predictions from the GPT-3 model.

511
00:22:10,890 --> 00:22:13,580
Looking at the KDE graph
reinforces the conclusion

512
00:22:13,580 --> 00:22:15,710
that humans frequently use words

513
00:22:15,710 --> 00:22:19,120
that are out of the top 100
predictive words from GPT-3.

514
00:22:20,000 --> 00:22:22,730
The graph for humans also
looks more distributed

515
00:22:22,730 --> 00:22:24,790
compared to GPT-3.

516
00:22:24,790 --> 00:22:26,470
From our research, we can conclude

517
00:22:26,470 --> 00:22:29,490
that evaluating a probability
for a sequence of texts

518
00:22:29,490 --> 00:22:31,420
is a good indicator of whether the text

519
00:22:31,420 --> 00:22:34,080
is synthetic or written by humans.

520
00:22:34,080 --> 00:22:36,830
However, there are
limitations in this approach,

521
00:22:36,830 --> 00:22:39,460
as it is heavily dependent on the model

522
00:22:39,460 --> 00:22:41,840
that's used to predict
the sequence of texts

523
00:22:41,840 --> 00:22:43,840
and the model used to generate the text.

524
00:22:46,966 --> 00:22:48,880
Next, we put our proof of concept

525
00:22:48,880 --> 00:22:51,680
GPT-3 detection two to the test.

526
00:22:51,680 --> 00:22:54,360
In this slide, you will
see three email samples.

527
00:22:54,360 --> 00:22:56,690
Only one is crafted manually by hand,

528
00:22:56,690 --> 00:22:59,690
while the other two is
generated by OpenAI.

529
00:22:59,690 --> 00:23:00,960
Do not worry if you cannot figure out

530
00:23:00,960 --> 00:23:02,800
which one is generated by AI.

531
00:23:02,800 --> 00:23:04,710
Even for our team, we find it difficult

532
00:23:04,710 --> 00:23:07,277
to differentiate which
content is generated by AI

533
00:23:07,277 --> 00:23:08,313
and which isn't.

534
00:23:09,740 --> 00:23:11,880
Let's take a look at sample A.

535
00:23:11,880 --> 00:23:15,472
This is the visual output
from the tool for sample E the

536
00:23:15,472 --> 00:23:17,913
ratio between the properties
of a top predictor and the

537
00:23:17,913 --> 00:23:19,530
following. What is that?

538
00:23:19,530 --> 00:23:20,933
0.8 tree tree.

539
00:23:22,620 --> 00:23:27,620
Then we look at sample B,
the ratio is zero point fall.

540
00:23:27,680 --> 00:23:29,480
So an observation from the GLT,

541
00:23:29,480 --> 00:23:33,966
our team is that when you
think are to the detection that

542
00:23:33,966 --> 00:23:37,780
attacks attacks generated
by humans tend to be more or

543
00:23:37,780 --> 00:23:39,380
rather have more highlights.

544
00:23:39,380 --> 00:23:42,740
This is because human generated
content tend to have more

545
00:23:42,740 --> 00:23:44,880
random words in terms
of the choice of words,

546
00:23:44,880 --> 00:23:47,670
and often forced out of the top
a hundred predict of what by

547
00:23:47,670 --> 00:23:50,860
GB tree needs to be. Look at sample B.

548
00:23:50,860 --> 00:23:52,693
The ratio is that 0.84.

549
00:23:54,060 --> 00:23:56,920
So an observation from the
GITR team is that when you,

550
00:23:56,920 --> 00:24:00,760
you have to detect synthetic
text or tax generator by humans

551
00:24:00,760 --> 00:24:02,430
tend to have more real highlights.

552
00:24:02,430 --> 00:24:04,580
This is the costume and
generated content tend to be more

553
00:24:04,580 --> 00:24:06,050
random in terms of choice of words,

554
00:24:06,050 --> 00:24:09,340
any of the force out of the
top hundred period of words,

555
00:24:09,340 --> 00:24:10,543
as highlighted earlier.

556
00:24:11,980 --> 00:24:13,590
Finally, we look at sample C.

557
00:24:13,590 --> 00:24:18,590
The ratio is at 0.55 for the
relative lower ratio is an

558
00:24:18,610 --> 00:24:21,330
indication that is
human generated content,

559
00:24:21,330 --> 00:24:22,240
which in the case,

560
00:24:22,240 --> 00:24:26,120
this is true on top of identical defenses.

561
00:24:26,120 --> 00:24:28,530
We look at the non-technical
aspect of the book.

562
00:24:28,530 --> 00:24:30,490
We found that model EA governance,

563
00:24:30,490 --> 00:24:33,330
Fremont released by Singapore
is a useful reference to

564
00:24:33,330 --> 00:24:35,830
address key ethical and governance issues.

565
00:24:35,830 --> 00:24:37,623
When deploying AI solutions,

566
00:24:38,850 --> 00:24:40,870
we will not be covering
the content of framework,

567
00:24:40,870 --> 00:24:45,300
but rather we extract the
development details of it for both

568
00:24:45,300 --> 00:24:49,630
suppliers and consumers,
they can adopt the following,

569
00:24:49,630 --> 00:24:52,270
use the proposed implementation
and self-assessment guide

570
00:24:52,270 --> 00:24:53,220
from the framework,

571
00:24:54,080 --> 00:24:57,560
establish policies for
explanation and practice general

572
00:24:57,560 --> 00:25:01,033
disclosure use perform ethical evaluation,

573
00:25:01,870 --> 00:25:04,490
implement clear roles and
responsibilities for ethical

574
00:25:04,490 --> 00:25:05,723
deployment of AI.

575
00:25:07,050 --> 00:25:07,883
For consumers,

576
00:25:07,883 --> 00:25:10,738
they can adopt the human in
the loop approach for AI,

577
00:25:10,738 --> 00:25:14,903
the decision-making for suppliers
and show traceability and

578
00:25:14,903 --> 00:25:19,903
auditability of use also to
enforce acceptable use policies.

579
00:25:22,350 --> 00:25:23,693
Finally, our conclusion,

580
00:25:25,520 --> 00:25:28,470
we somehow are sharing three
key points for everyone to take

581
00:25:28,470 --> 00:25:29,520
away.

582
00:25:29,520 --> 00:25:30,353
Firstly,

583
00:25:30,353 --> 00:25:33,530
the rapid growth of AI service
has placed advance cost

584
00:25:33,530 --> 00:25:37,230
effective AI text generation
capabilities in the hands of

585
00:25:37,230 --> 00:25:38,970
the global market.

586
00:25:38,970 --> 00:25:42,293
They can be used by both
authorized or malicious actors,

587
00:25:43,550 --> 00:25:46,810
but ultimately the tools can
be used to build defenses

588
00:25:46,810 --> 00:25:48,700
against AI generated texts.

589
00:25:48,700 --> 00:25:51,660
Current approaches are
brittle and model dependent.

590
00:25:51,660 --> 00:25:54,900
AI assisted human detection
of AI generated text could be

591
00:25:54,900 --> 00:25:55,793
more effective.

592
00:25:57,230 --> 00:25:58,240
Lastly,

593
00:25:58,240 --> 00:26:00,890
decision makers have the
responsibility to implement sound

594
00:26:00,890 --> 00:26:01,723
strategies,

595
00:26:01,723 --> 00:26:05,890
governing the supply and
consumption of advance AI service

596
00:26:05,890 --> 00:26:08,280
tightening the usage of
advanced AI as a service can

597
00:26:08,280 --> 00:26:10,860
potentially reduce the likelihood of abuse

598
00:26:14,470 --> 00:26:15,710
we've reached the end of our sharing,

599
00:26:15,710 --> 00:26:18,940
and we hope that there are
takeaways for you from our work

600
00:26:18,940 --> 00:26:22,280
to catch us live at Def con
and we are more than willing to

601
00:26:22,280 --> 00:26:24,740
discuss our resist review.

602
00:26:24,740 --> 00:26:25,573
Thank you.

