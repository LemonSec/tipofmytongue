1
00:00:02,110 --> 00:00:03,860
- Hi, welcome.

2
00:00:03,860 --> 00:00:05,700
Today, I'm going to be talking about

3
00:00:05,700 --> 00:00:10,700
new phishing attacks that exploit
OAuth authorization flows.

4
00:00:12,780 --> 00:00:13,960
My name is Jenko Hwong,

5
00:00:13,960 --> 00:00:16,533
I'm currently a Researcher at Netskope.

6
00:00:17,398 --> 00:00:19,360
Here are some of the
areas that I've dabbled in

7
00:00:19,360 --> 00:00:24,183
and are interesting to me
from my research perspective.

8
00:00:26,460 --> 00:00:30,890
So to recap some of the
past about phishing,

9
00:00:30,890 --> 00:00:33,830
I'd like to just spend a
minute talking about that,

10
00:00:33,830 --> 00:00:38,570
so that we can understand
some of the latest evolution

11
00:00:38,570 --> 00:00:40,560
of techniques.

12
00:00:40,560 --> 00:00:41,560
So in the beginning,

13
00:00:41,560 --> 00:00:46,560
certainly phishing was
predominantly carried over SMTP.

14
00:00:46,710 --> 00:00:51,110
This is probably late 90s when
we started to see phishing.

15
00:00:51,110 --> 00:00:54,970
Attacker is very focused on
fake domains, creating them,

16
00:00:54,970 --> 00:00:59,356
hosting websites, maybe
creating SSL certs as well

17
00:00:59,356 --> 00:01:02,070
to lend some validity

18
00:01:02,070 --> 00:01:04,710
to their fake site

19
00:01:04,710 --> 00:01:06,720
and ultimately tricking the user

20
00:01:06,720 --> 00:01:09,423
into supplying their
username and password.

21
00:01:12,260 --> 00:01:13,663
As mobile came along,

22
00:01:15,020 --> 00:01:20,000
more apps, protocols came phishing,

23
00:01:20,000 --> 00:01:22,270
then targeted those applications

24
00:01:22,270 --> 00:01:26,203
and so we got SMS phishes,
snitches, IMs chats.

25
00:01:27,190 --> 00:01:29,530
For the most part, a lot was the same,

26
00:01:29,530 --> 00:01:33,640
but because of the limited
UX and real estate,

27
00:01:33,640 --> 00:01:36,803
certain things like URL shorteners,

28
00:01:37,930 --> 00:01:40,550
being able to detect the cells,

29
00:01:40,550 --> 00:01:44,170
or you can see the SSL
cert or even see the URL

30
00:01:44,170 --> 00:01:47,760
were different or challenges
affecting the user

31
00:01:47,760 --> 00:01:51,273
as well as any software security
controls in the picture.

32
00:01:53,930 --> 00:01:57,720
With cloud infrastructure providers,

33
00:01:57,720 --> 00:02:02,530
suddenly the attackers
had an easier way to host

34
00:02:02,530 --> 00:02:07,530
and their actual fake
website, on top of that,

35
00:02:07,550 --> 00:02:11,900
the domains now, and the SSL
certs reflected those same

36
00:02:11,900 --> 00:02:14,540
popular cloud providers, so the victims,

37
00:02:14,540 --> 00:02:18,470
as well as the security controls
have more of a challenge

38
00:02:18,470 --> 00:02:23,223
in detecting fake domains,
phishes, certs, et cetera.

39
00:02:25,520 --> 00:02:26,893
So none of this is new.

40
00:02:28,628 --> 00:02:30,100
And in this case,

41
00:02:30,100 --> 00:02:32,290
maybe the attackers trying to create

42
00:02:32,290 --> 00:02:37,290
something like Citibank's
website hosted in Azure.

43
00:02:39,680 --> 00:02:43,600
The controls I alluded
to and for the most part

44
00:02:43,600 --> 00:02:46,630
grew into a series of techniques upfront,

45
00:02:46,630 --> 00:02:51,380
detection of phishes using
various link analysis domains,

46
00:02:51,380 --> 00:02:53,943
URLs, the certs themselves,

47
00:02:54,800 --> 00:02:56,470
checking on the sender reputation,

48
00:02:56,470 --> 00:02:58,720
having threat Intel, that helps with that,

49
00:02:58,720 --> 00:03:01,320
so that phish on the incoming
basis could be blocked

50
00:03:01,320 --> 00:03:03,440
before reaching the user.

51
00:03:03,440 --> 00:03:07,843
Post-user receiving an actual phish,

52
00:03:08,720 --> 00:03:10,530
some of the same techniques might be used

53
00:03:10,530 --> 00:03:13,590
to prevent the user
from actually connecting

54
00:03:13,590 --> 00:03:17,453
on an HTTP request outbound
to their fake website.

55
00:03:18,540 --> 00:03:22,127
There might be additional
content inspection

56
00:03:22,127 --> 00:03:23,300
(sneezes) excuse me,

57
00:03:23,300 --> 00:03:26,490
content inspection use
to detect credentials

58
00:03:26,490 --> 00:03:29,583
within the payload as well,
form, fields, et cetera.

59
00:03:30,610 --> 00:03:34,200
Ultimately, if credentials were hijacked,

60
00:03:34,200 --> 00:03:38,340
set of controls like MFA and
policies governing IP addresses

61
00:03:38,340 --> 00:03:43,050
that can be used with credentials
also were applied MFA,

62
00:03:43,050 --> 00:03:44,650
especially was pretty effective

63
00:03:44,650 --> 00:03:48,500
at minimizing the impact
of compromised credentials.

64
00:03:48,500 --> 00:03:50,670
So none of this is new,

65
00:03:50,670 --> 00:03:55,670
this has been sort of 10 or 20
years of phishing evolution.

66
00:03:57,060 --> 00:03:59,280
If I could simplify it at that.

67
00:03:59,280 --> 00:04:02,670
Now what's changed with
some of the last few years,

68
00:04:02,670 --> 00:04:06,680
well as OAuth, which
was introduced in 2013,

69
00:04:06,680 --> 00:04:11,180
as OAuth got more popular,
driven a lot by security

70
00:04:11,180 --> 00:04:14,823
and the interaction of all
these websites and web apps,

71
00:04:16,200 --> 00:04:19,360
that part of OAuth that
dealt with authorization

72
00:04:19,360 --> 00:04:22,580
in a secure manner became very popular

73
00:04:23,680 --> 00:04:27,600
and sort of has caused us to rethink

74
00:04:27,600 --> 00:04:30,760
both how to phish and
how to defend against it.

75
00:04:30,760 --> 00:04:34,410
And OAuth at a high level,
if you're not that familiar,

76
00:04:34,410 --> 00:04:36,860
involves the application,
this could be the website,

77
00:04:36,860 --> 00:04:40,913
or it could be a local application
on the desktop or mobile,

78
00:04:41,910 --> 00:04:44,240
often referred to as the client or device,

79
00:04:44,240 --> 00:04:46,620
while the application
might request authorization

80
00:04:46,620 --> 00:04:51,620
from the user to do something,
and that could be approved,

81
00:04:51,860 --> 00:04:54,650
hey, have the payment log in so on.

82
00:04:54,650 --> 00:04:57,450
And it directs the user to
identity platform, right?

83
00:04:57,450 --> 00:05:01,320
Part of the OAuth model is
to not have the applications,

84
00:05:01,320 --> 00:05:05,900
handle no store, anything
about the user credential.

85
00:05:05,900 --> 00:05:06,733
So in this case,

86
00:05:06,733 --> 00:05:10,620
there's a redirect the
user then authenticates

87
00:05:10,620 --> 00:05:13,130
as they would with
their identity platform.

88
00:05:13,130 --> 00:05:14,320
And when we're talking about OAuth,

89
00:05:14,320 --> 00:05:18,090
it's really Azure AD or Google Identity.

90
00:05:18,090 --> 00:05:20,980
That authentication process
could be a very secure

91
00:05:20,980 --> 00:05:22,073
and have MFA.

92
00:05:23,490 --> 00:05:26,210
Ultimately, the user is
presented with some kind of

93
00:05:26,210 --> 00:05:29,510
authorization step,
approve these permissions,

94
00:05:29,510 --> 00:05:31,270
approve this task.

95
00:05:31,270 --> 00:05:36,080
The permissions are called
scopes in OAuth land.

96
00:05:36,080 --> 00:05:38,470
And if everything goes
well, the session tokens,

97
00:05:38,470 --> 00:05:42,597
OAuth session tokens are
supplied back to the application

98
00:05:42,597 --> 00:05:46,600
and the application
has these access tokens

99
00:05:46,600 --> 00:05:49,500
and can generate new ones
with the refresh token,

100
00:05:49,500 --> 00:05:53,070
and can use it to actually gain access

101
00:05:53,070 --> 00:05:56,310
to the resources of the
user or to perform a task

102
00:05:57,210 --> 00:06:01,153
because they essentially have
post authentication status.

103
00:06:02,798 --> 00:06:06,450
So as a user, this is
familiar in various contexts,

104
00:06:06,450 --> 00:06:08,250
one is payments, you're shopping,

105
00:06:08,250 --> 00:06:12,560
you get to checkout and PayPal,
which isn't OAuth provider

106
00:06:14,630 --> 00:06:17,673
allows you, websites to
easily pay with PayPal,

107
00:06:18,600 --> 00:06:21,530
websites, if you clicked
through as a user,

108
00:06:21,530 --> 00:06:24,150
redirect the user to PayPal,

109
00:06:24,150 --> 00:06:28,420
so that you can go through
your authentication MFA,

110
00:06:28,420 --> 00:06:31,060
and right now we're dealing
with PayPal as a user,

111
00:06:31,060 --> 00:06:34,710
so the original website does not see

112
00:06:34,710 --> 00:06:37,510
or have a chance to
compromise your credentials.

113
00:06:37,510 --> 00:06:40,310
And as you complete the
process with PayPal,

114
00:06:40,310 --> 00:06:42,830
you end up on the right with their version

115
00:06:42,830 --> 00:06:46,820
of an authorization or
consent screen, which is,

116
00:06:46,820 --> 00:06:50,290
do you agree to pay that original website

117
00:06:50,290 --> 00:06:54,083
such and such money for
whatever you are shopping for?

118
00:06:55,580 --> 00:06:59,077
There are other contexts,
even technical tools like CLIs

119
00:06:59,077 --> 00:07:03,590
and Google Cloud have a login process,

120
00:07:04,870 --> 00:07:05,793
of course.

121
00:07:07,245 --> 00:07:08,790
And in this case, it creates a URL

122
00:07:08,790 --> 00:07:10,940
that you can copy and
paste into a browser,

123
00:07:12,230 --> 00:07:14,820
but it's actually an OAuth flow.

124
00:07:14,820 --> 00:07:17,030
And in the browser,
once you go to that URL,

125
00:07:17,030 --> 00:07:19,913
you're prompted to enter
your username and password,

126
00:07:22,560 --> 00:07:24,390
and then you get to a
consent screen saying,

127
00:07:24,390 --> 00:07:25,520
hey, the CLI,

128
00:07:25,520 --> 00:07:28,853
which is really registered
as the Google Cloud SDK,

129
00:07:29,780 --> 00:07:31,563
once access your Google account,

130
00:07:32,840 --> 00:07:35,350
and it's asking for these permissions.

131
00:07:35,350 --> 00:07:39,000
If you go ahead and hit
allow you just confirmed

132
00:07:39,000 --> 00:07:40,730
and you see some confirmation messages,

133
00:07:40,730 --> 00:07:43,020
and back on the command line,

134
00:07:43,020 --> 00:07:44,470
you might see a final message that,

135
00:07:44,470 --> 00:07:46,343
hey, you're now logged in.

136
00:07:49,040 --> 00:07:52,010
So initially phishing responded

137
00:07:52,010 --> 00:07:57,010
to this new authorization
identity platform called OAuth

138
00:07:57,600 --> 00:08:02,440
with so similar techniques,
just, here's a new login.

139
00:08:02,440 --> 00:08:03,273
Yeah, great.

140
00:08:03,273 --> 00:08:05,033
We have an OAuth log in, but
it's just another log in,

141
00:08:05,033 --> 00:08:06,820
I'll just move it.

142
00:08:06,820 --> 00:08:10,690
So, a lot of this was business as usual

143
00:08:10,690 --> 00:08:12,290
from the phishing side.

144
00:08:12,290 --> 00:08:13,940
However, we did see some evolution

145
00:08:13,940 --> 00:08:18,690
where the code presenting
that actual fake login

146
00:08:18,690 --> 00:08:21,550
would actually do a
real-time validation check

147
00:08:22,550 --> 00:08:25,580
against the identity provider
to validate that credential

148
00:08:25,580 --> 00:08:27,380
and then based on whether
it was valid or not,

149
00:08:27,380 --> 00:08:28,720
it might take different actions

150
00:08:28,720 --> 00:08:30,610
that would help maintain stealth.

151
00:08:30,610 --> 00:08:34,840
It might redirect to a
valid domain login screen

152
00:08:34,840 --> 00:08:36,943
or something else depending.

153
00:08:37,870 --> 00:08:40,040
And that might help prevent the user

154
00:08:40,040 --> 00:08:42,293
from maybe raising a flag manually,

155
00:08:43,770 --> 00:08:47,080
also provide an opportunity to
validate credentials upfront,

156
00:08:47,080 --> 00:08:51,643
so that you could do that check
right away instead of later.

157
00:08:52,810 --> 00:08:54,370
The controls for the most part,

158
00:08:54,370 --> 00:08:56,750
I would say have stay the same

159
00:08:56,750 --> 00:08:59,843
because really the techniques
have not changed much.

160
00:09:00,860 --> 00:09:03,280
So why do we care to maybe delve

161
00:09:03,280 --> 00:09:06,940
and research into the
protocol deeper, right?

162
00:09:06,940 --> 00:09:09,670
So far, this hasn't made much difference.

163
00:09:09,670 --> 00:09:14,670
Well, obviously I wouldn't be
talking if that were the case.

164
00:09:14,770 --> 00:09:17,600
Here's why attackers

165
00:09:18,970 --> 00:09:21,610
have dealt deeper and why
from a research perspective,

166
00:09:21,610 --> 00:09:23,870
it's worth us focusing on this.

167
00:09:23,870 --> 00:09:27,170
One is, instead of targeting
the username and password,

168
00:09:27,170 --> 00:09:29,183
we target the OAuth session tokens.

169
00:09:30,130 --> 00:09:31,440
There are some advantages there,

170
00:09:31,440 --> 00:09:34,530
the model of OAuth essentially
allows a refresh of them

171
00:09:34,530 --> 00:09:37,803
and the defaults pretty much
allow you to do that forever.

172
00:09:38,989 --> 00:09:40,420
The session token gives you the same power

173
00:09:40,420 --> 00:09:44,400
as the original credential,
has one advantage,

174
00:09:44,400 --> 00:09:49,400
which is we don't have
to rechallenge with MFA.

175
00:09:49,960 --> 00:09:51,900
If MFA is enabled the user,

176
00:09:51,900 --> 00:09:54,400
once they go through that manually,

177
00:09:54,400 --> 00:09:56,810
the tokens effectively are blessed

178
00:09:56,810 --> 00:10:01,800
and the refresh token just
allows this unlimited ability

179
00:10:01,800 --> 00:10:05,290
to have a long duration credential.

180
00:10:05,290 --> 00:10:10,290
So getting access to session
tokens effectively allows us

181
00:10:10,590 --> 00:10:13,437
to quote, bypass MFA.

182
00:10:13,437 --> 00:10:17,680
The second reason is that
all of this is REST enabled,

183
00:10:17,680 --> 00:10:21,480
so hijacking, the actual
tokens does not require

184
00:10:21,480 --> 00:10:23,700
a compromise of an endpoint.

185
00:10:23,700 --> 00:10:26,550
We have these nice REST APIs,
we have a complicated flow,

186
00:10:26,550 --> 00:10:28,680
there's the ability to
insert us into the flow

187
00:10:28,680 --> 00:10:32,710
or perhaps gain access to tokens remotely,

188
00:10:32,710 --> 00:10:36,000
which is huge because tokens
are not a new concept,

189
00:10:36,000 --> 00:10:38,640
they've been around since
the beginning of the web.

190
00:10:38,640 --> 00:10:40,150
We've had web sessions

191
00:10:41,040 --> 00:10:44,630
and we've had session IDs kept
in cookies or local storage,

192
00:10:44,630 --> 00:10:46,620
and we've had web attacks,

193
00:10:46,620 --> 00:10:50,270
SSRF that exploited those
sessions to hijack them,

194
00:10:50,270 --> 00:10:54,240
we've had endpoint
compromises that have also,

195
00:10:54,240 --> 00:10:59,050
looked at grabbing or
harvesting those tokens.

196
00:10:59,050 --> 00:11:02,990
However, there's a pretty high
bar to take advantage of that

197
00:11:02,990 --> 00:11:05,010
because you would have to
compromise the endpoint

198
00:11:05,010 --> 00:11:06,900
or do a browser attack.

199
00:11:06,900 --> 00:11:11,900
This is far easier, far easier
because we have REST APIs

200
00:11:11,920 --> 00:11:15,883
and we'll see that in
the upcoming deep dives.

201
00:11:17,660 --> 00:11:21,430
So, there have been actual attacks.

202
00:11:21,430 --> 00:11:26,120
So, one of them is called
illicit consent grants,

203
00:11:26,120 --> 00:11:29,290
the texts that have exploited
the protocol, I'm sorry,

204
00:11:29,290 --> 00:11:31,210
I didn't quite finish that.

205
00:11:31,210 --> 00:11:32,650
So in the illicit consent grants,

206
00:11:32,650 --> 00:11:36,100
it's exploiting wider
consensus privileges,

207
00:11:36,100 --> 00:11:38,010
tricking the user to approve them.

208
00:11:38,010 --> 00:11:42,690
So this works with attacker,
creating their own application,

209
00:11:42,690 --> 00:11:46,160
a fake application, perhaps
named close to an existing app.

210
00:11:46,160 --> 00:11:48,490
They register it in the identity platform,

211
00:11:48,490 --> 00:11:49,990
it could be their own account.

212
00:11:51,340 --> 00:11:56,327
They send out ultimately
a phish to the user

213
00:11:57,360 --> 00:12:00,360
requesting broad scopes to some resource,

214
00:12:00,360 --> 00:12:05,193
so imagine it could be
a Google Drive my sync,

215
00:12:06,280 --> 00:12:08,760
some name that seems plausible.

216
00:12:08,760 --> 00:12:13,760
I asked the user to give
this application access,

217
00:12:14,600 --> 00:12:17,490
read and write to
everything in Google Drive.

218
00:12:17,490 --> 00:12:19,820
If I can get the user to click,

219
00:12:19,820 --> 00:12:21,420
they'll approve these bigger scopes

220
00:12:21,420 --> 00:12:24,250
and OAuth tokens will be created,

221
00:12:24,250 --> 00:12:29,090
and will be accessible by the user

222
00:12:30,810 --> 00:12:34,400
because the user that's part of the flow

223
00:12:34,400 --> 00:12:37,840
is specifying how to retrieve those tokens

224
00:12:37,840 --> 00:12:41,030
and they get actually pushed
through a redirect URL

225
00:12:41,030 --> 00:12:42,363
to application.

226
00:12:43,320 --> 00:12:47,410
So, from a user perspective
or victim perspective,

227
00:12:47,410 --> 00:12:50,750
the chance they either have to identify

228
00:12:50,750 --> 00:12:52,780
or know that it's a fake application

229
00:12:52,780 --> 00:12:57,780
or an administrator security,
or IT administrator needs

230
00:12:58,740 --> 00:13:00,990
to be able to prevent users from clicking

231
00:13:00,990 --> 00:13:03,870
and approving these app requests.

232
00:13:03,870 --> 00:13:07,940
So this has happened and
there was a reference here

233
00:13:08,950 --> 00:13:11,200
just in the last year or so,

234
00:13:11,200 --> 00:13:13,750
of illicit consent grant attacks.

235
00:13:13,750 --> 00:13:14,930
From a user perspective,

236
00:13:14,930 --> 00:13:17,450
they've just see in a consent screen,

237
00:13:17,450 --> 00:13:20,360
a list of permissions that might be wider

238
00:13:20,360 --> 00:13:22,233
or deeper than they expect.

239
00:13:23,200 --> 00:13:25,990
And the controls against these are,

240
00:13:25,990 --> 00:13:26,823
as I have mentioned,

241
00:13:26,823 --> 00:13:30,610
the administrators
running the organization,

242
00:13:30,610 --> 00:13:32,120
watching the network,

243
00:13:32,120 --> 00:13:35,010
having ability to prevent
users from creating

244
00:13:35,010 --> 00:13:37,670
or registering fake apps and ID,

245
00:13:37,670 --> 00:13:40,580
which might prevent a insider attack,

246
00:13:40,580 --> 00:13:43,040
and they can prevent users
from consenting and hitting,

247
00:13:43,040 --> 00:13:45,300
except it changes this flow,

248
00:13:45,300 --> 00:13:48,810
they're not actually present
it with an Accept button,

249
00:13:48,810 --> 00:13:50,553
the administrator's thing control.

250
00:13:51,640 --> 00:13:55,660
I just wanted to point out that
the Microsoft documentation

251
00:13:55,660 --> 00:13:59,370
has this nice 12 point numbered
system, I did not add that,

252
00:13:59,370 --> 00:14:01,530
that's actually part of the documentation

253
00:14:01,530 --> 00:14:03,830
and they're explained pretty
well within the documentation,

254
00:14:03,830 --> 00:14:04,663
kudos to them.

255
00:14:04,663 --> 00:14:08,260
It's great as a researcher
and I have to say as a user,

256
00:14:08,260 --> 00:14:10,410
it's extremely confusing to have 12 points

257
00:14:10,410 --> 00:14:12,720
to explain in okay dialogue.

258
00:14:12,720 --> 00:14:17,720
So, this is where complexity
is the enemy of security.

259
00:14:20,150 --> 00:14:22,200
So let's get to device code authorization,

260
00:14:22,200 --> 00:14:26,540
which is really the flow
I want to focus on today.

261
00:14:26,540 --> 00:14:27,763
What's the purpose?

262
00:14:29,070 --> 00:14:31,720
Briefly to provide usability

263
00:14:31,720 --> 00:14:34,910
that is easier authentication
or authorization

264
00:14:34,910 --> 00:14:38,120
on a limited input device where you need

265
00:14:38,120 --> 00:14:40,830
some kind of authorization
and authentication.

266
00:14:40,830 --> 00:14:44,070
Best example is smart TV,
where you need to authenticate

267
00:14:44,070 --> 00:14:45,770
against your content subscription,

268
00:14:45,770 --> 00:14:47,760
so you can get your movies on the TV.

269
00:14:47,760 --> 00:14:52,340
They'll have this menu these
days could be, you know,

270
00:14:52,340 --> 00:14:55,933
some device like a Roku
or, you know, Apple TV.

271
00:14:57,160 --> 00:15:02,040
But the problem is if you
were to enter that credential

272
00:15:02,040 --> 00:15:03,710
on the actual device,

273
00:15:03,710 --> 00:15:06,030
you'd be faced with something
like a remote control,

274
00:15:06,030 --> 00:15:07,713
completely heinous.

275
00:15:09,170 --> 00:15:13,670
So, well, there's an RFC to solve that.

276
00:15:13,670 --> 00:15:14,960
Back in 2019,

277
00:15:14,960 --> 00:15:19,390
some smart people came
up with a way to do that.

278
00:15:19,390 --> 00:15:23,070
And when it's implemented
the application vendor,

279
00:15:23,070 --> 00:15:25,200
in this case, the smart TV vendor

280
00:15:25,200 --> 00:15:27,500
implements the device code flow,

281
00:15:27,500 --> 00:15:32,150
and now the user has a better flow.

282
00:15:32,150 --> 00:15:34,820
They're presented with a short URL.

283
00:15:34,820 --> 00:15:36,500
They're told to go to a different device

284
00:15:36,500 --> 00:15:39,400
that has a real keyboard or
something that they can do.

285
00:15:39,400 --> 00:15:41,620
Here's a relatively short
URL to punch in there

286
00:15:41,620 --> 00:15:44,610
and relatively a short
code to type in there,

287
00:15:44,610 --> 00:15:47,680
and then you will go through
a normal authentication

288
00:15:47,680 --> 00:15:52,680
or login process to prove
this TV gaining access to,

289
00:15:54,350 --> 00:15:56,170
in this case, your Netflix subscription.

290
00:15:56,170 --> 00:15:58,930
They even have a QR code capability,

291
00:15:58,930 --> 00:16:03,930
so that your mobile device can
even go to the URL directly.

292
00:16:05,190 --> 00:16:07,600
So that's all well and good,

293
00:16:07,600 --> 00:16:09,350
but the user gets when they follow the URL

294
00:16:09,350 --> 00:16:12,170
something like this,
punch in that short code,

295
00:16:12,170 --> 00:16:14,120
voila, everything's working.

296
00:16:14,120 --> 00:16:18,560
However, usability is one
of the biggest drivers here

297
00:16:18,560 --> 00:16:20,250
and I have a saying that,

298
00:16:20,250 --> 00:16:23,113
on usability is the father of insecurity.

299
00:16:24,210 --> 00:16:26,090
It drives less security

300
00:16:26,090 --> 00:16:28,570
and that is our opportunity to exploit

301
00:16:30,010 --> 00:16:32,690
because things get simplified,
things get dropped,

302
00:16:32,690 --> 00:16:33,910
things get less secure

303
00:16:33,910 --> 00:16:38,910
or things just aren't looked
at from a security viewpoint.

304
00:16:39,970 --> 00:16:42,640
So, let's look at device
code authorization

305
00:16:43,545 --> 00:16:45,360
a little bit deeper.

306
00:16:45,360 --> 00:16:47,530
So, what really happens under the hood

307
00:16:47,530 --> 00:16:51,410
is a user is trying to
log in or do some tasks,

308
00:16:51,410 --> 00:16:52,290
the device

309
00:16:55,450 --> 00:16:57,630
gets some user codes

310
00:16:58,580 --> 00:17:01,520
and sends a URL with that
user code to the user,

311
00:17:01,520 --> 00:17:03,600
so that they can authenticate
and once they do,

312
00:17:03,600 --> 00:17:05,320
OAuth tokens are created,

313
00:17:05,320 --> 00:17:07,280
which are then accessible from the device.

314
00:17:07,280 --> 00:17:08,873
So, okay.

315
00:17:09,720 --> 00:17:11,713
Similar to what I said before.

316
00:17:13,750 --> 00:17:17,550
But to show how easy it is to abuse that,

317
00:17:17,550 --> 00:17:19,940
or at least how difficult it is as a user

318
00:17:19,940 --> 00:17:21,140
to protect your credentials,

319
00:17:21,140 --> 00:17:22,940
I'd like to go through the demo now.

320
00:17:24,000 --> 00:17:25,100
Just a short note,

321
00:17:25,100 --> 00:17:30,100
Dr. Syynimaa has a great
deal of information

322
00:17:30,320 --> 00:17:32,013
at his blog, o365blog,

323
00:17:33,760 --> 00:17:35,020
super great resource.

324
00:17:35,020 --> 00:17:38,170
He has his tool set AAD internals,

325
00:17:38,170 --> 00:17:41,483
great stuff about Windows
AD, Outlook Office,

326
00:17:42,500 --> 00:17:45,000
as well as OAuth in there.

327
00:17:45,000 --> 00:17:46,200
It's highly recommended.

328
00:17:47,060 --> 00:17:49,750
So let's jump into

329
00:17:51,240 --> 00:17:52,180
demonstrations.

330
00:17:52,180 --> 00:17:54,880
So, lay the stage here

331
00:17:54,880 --> 00:17:57,350
on the left side will be
the browser of the victim,

332
00:17:57,350 --> 00:18:00,313
the right side will be
the terminal of attacker.

333
00:18:01,350 --> 00:18:04,230
And we'll actually go
through a device code flow

334
00:18:04,230 --> 00:18:07,930
and sort of see the
implications from both sides.

335
00:18:07,930 --> 00:18:08,830
So in this case,

336
00:18:08,830 --> 00:18:10,250
we're logging into

337
00:18:11,890 --> 00:18:14,850
the standard URL

338
00:18:14,850 --> 00:18:16,060
for this company.

339
00:18:16,060 --> 00:18:17,940
That Ed is part of Feast Health,

340
00:18:17,940 --> 00:18:20,930
and we want to gain
access first to Outlook.

341
00:18:20,930 --> 00:18:25,930
So we punch in name,
password, get two factor.

342
00:18:27,460 --> 00:18:30,273
This case it's software
based, we punch in that code.

343
00:18:31,887 --> 00:18:33,680
Do you want to stay signed in? No.

344
00:18:33,680 --> 00:18:36,380
We'll go through it and
boom, we're on Outlook.

345
00:18:36,380 --> 00:18:37,760
Now, meanwhile,

346
00:18:37,760 --> 00:18:41,600
the attacker independently
is thinking of phishing.

347
00:18:41,600 --> 00:18:46,220
We'll start up a script,
sort of running in demo mode.

348
00:18:46,220 --> 00:18:49,930
This is part of the open source software,

349
00:18:49,930 --> 00:18:52,560
we are releasing concurrently.

350
00:18:52,560 --> 00:18:53,930
I want to point out a few things.

351
00:18:53,930 --> 00:18:56,260
One of the first steps that we're doing

352
00:18:56,260 --> 00:18:57,450
as part of the phishing

353
00:18:57,450 --> 00:19:01,400
is actually following the
device code authorization flow.

354
00:19:01,400 --> 00:19:03,123
We're gonna generate a code.

355
00:19:04,240 --> 00:19:08,870
If you look at a post or
specifying a set of APIs,

356
00:19:08,870 --> 00:19:11,450
the graph APIs as our resource,

357
00:19:11,450 --> 00:19:13,240
and we're actually using a client ID,

358
00:19:13,240 --> 00:19:15,030
this is the application client ID.

359
00:19:15,030 --> 00:19:17,730
When you create an
application, the OAuth world,

360
00:19:17,730 --> 00:19:21,660
you have to get back ID in a secret.

361
00:19:21,660 --> 00:19:22,730
We're actually reusing one,

362
00:19:22,730 --> 00:19:25,130
we didn't have to create an
app to carry out this phish.

363
00:19:25,130 --> 00:19:27,453
This is the Outlook ID that we're reusing.

364
00:19:28,815 --> 00:19:29,970
(couch) When we execute this four step,

365
00:19:29,970 --> 00:19:31,070
we get back a user code

366
00:19:31,070 --> 00:19:32,430
that we're gonna phish the user with,

367
00:19:32,430 --> 00:19:34,240
along with the login URL,

368
00:19:34,240 --> 00:19:36,870
it's called the verification URL.

369
00:19:36,870 --> 00:19:40,060
Okay, we'll explain the
other fields as we go.

370
00:19:40,060 --> 00:19:42,310
Now I'm gonna send out the phish

371
00:19:42,310 --> 00:19:44,210
and in a second

372
00:19:46,380 --> 00:19:47,380
the phish will appear,

373
00:19:47,380 --> 00:19:49,880
I'm gonna pause and just say that

374
00:19:49,880 --> 00:19:51,090
after the phish is sent out,

375
00:19:51,090 --> 00:19:53,670
part of the device code authorization flow

376
00:19:53,670 --> 00:19:57,150
is to poll the identity platform,

377
00:19:57,150 --> 00:19:58,743
in this case, Azure,

378
00:20:00,130 --> 00:20:02,560
for OAuth tokens,

379
00:20:02,560 --> 00:20:05,160
which will be created
after the user logs in.

380
00:20:05,160 --> 00:20:07,113
So it will sit there waiting.

381
00:20:07,960 --> 00:20:10,460
And in a second there it is,

382
00:20:10,460 --> 00:20:13,610
on the left, we see a new email,

383
00:20:13,610 --> 00:20:17,370
let's check it out and
has received an email

384
00:20:17,370 --> 00:20:20,530
from the Microsoft
Office 365 product team.

385
00:20:20,530 --> 00:20:23,090
It is thanking for being
such a great customer

386
00:20:23,090 --> 00:20:26,690
and as part of that, he'll
get one terabyte extra storage

387
00:20:26,690 --> 00:20:28,600
and increased file size,

388
00:20:28,600 --> 00:20:30,520
attachments file size
of a hundred megabytes.

389
00:20:30,520 --> 00:20:34,070
It's awesome, Ed can't resist
and he types in the code.

390
00:20:34,070 --> 00:20:39,070
Now let me go back and
point out in the message.

391
00:20:39,090 --> 00:20:42,120
There's a real URL in
here, it's microsoft.com,

392
00:20:42,120 --> 00:20:43,443
nothing shady or funny.

393
00:20:46,210 --> 00:20:49,360
It's a trap link but
it's actually pointing

394
00:20:49,360 --> 00:20:54,340
to the text as part of the
device code authorization.

395
00:20:54,340 --> 00:20:58,240
So we can see that some phish
detection might fail right off

396
00:20:58,240 --> 00:21:02,680
here on domain alone because
of this microsoft.com.

397
00:21:02,680 --> 00:21:05,200
Okay, so let's go back as follows

398
00:21:05,200 --> 00:21:08,530
that punches in the
supply code in the phish

399
00:21:08,530 --> 00:21:09,363
and

400
00:21:11,650 --> 00:21:12,600
what's happening?

401
00:21:12,600 --> 00:21:15,440
He is being prompted to authenticate.

402
00:21:15,440 --> 00:21:16,890
Okay.

403
00:21:16,890 --> 00:21:19,710
Since he had already logged into Outlook,

404
00:21:19,710 --> 00:21:24,420
it is cached in the browser
otherwise to type in as username

405
00:21:24,420 --> 00:21:27,903
and password, and perhaps MFA code.

406
00:21:29,120 --> 00:21:32,201
And then get to this stage.

407
00:21:32,201 --> 00:21:33,770
I want to point out, here's the prompt,

408
00:21:33,770 --> 00:21:36,380
are you trying to sign
into Microsoft Office?

409
00:21:36,380 --> 00:21:41,380
That Microsoft Office came
from the use of the client ID

410
00:21:41,470 --> 00:21:46,010
in our phishing step initially.

411
00:21:46,010 --> 00:21:47,310
Okay.

412
00:21:47,310 --> 00:21:50,853
We use the client ID and we get the title.

413
00:21:51,960 --> 00:21:54,770
All right, so there's continue

414
00:21:54,770 --> 00:21:56,530
and that's it for the user.

415
00:21:56,530 --> 00:22:00,010
They entered the code, they
authenticated, they're done.

416
00:22:00,010 --> 00:22:04,940
Meanwhile, we are polling the
attacker script is polling,

417
00:22:04,940 --> 00:22:06,980
checking every five seconds.

418
00:22:06,980 --> 00:22:08,780
This is all part of the protocol

419
00:22:08,780 --> 00:22:10,860
for device code authorization.

420
00:22:10,860 --> 00:22:12,870
Now that the user is logged
in, we should have OAuth tokens

421
00:22:12,870 --> 00:22:15,740
and this will return in a few seconds

422
00:22:15,740 --> 00:22:18,640
with access tokens, session tokens.

423
00:22:18,640 --> 00:22:19,920
There it is.

424
00:22:19,920 --> 00:22:23,270
So let's note a few things, okay.

425
00:22:23,270 --> 00:22:24,320
Number one,

426
00:22:24,320 --> 00:22:29,320
what's in the response is scopes
associated with the tokens.

427
00:22:30,640 --> 00:22:32,280
These are the permissions that

428
00:22:35,160 --> 00:22:38,290
we have access too with this token.

429
00:22:38,290 --> 00:22:39,920
The resource,

430
00:22:39,920 --> 00:22:44,160
the tokens applied to scrapped API,

431
00:22:44,160 --> 00:22:48,040
we have an access token, we
have a refresh token, okay.

432
00:22:48,040 --> 00:22:48,873
This is great.

433
00:22:48,873 --> 00:22:51,470
What can we do in the graph API?

434
00:22:51,470 --> 00:22:53,510
Okay, you can see the indirection here.

435
00:22:53,510 --> 00:22:57,190
We put the application Microsoft Office,

436
00:22:57,190 --> 00:22:59,830
that's what the user
thinks they've approved.

437
00:22:59,830 --> 00:23:03,003
We've got access to the graph API,

438
00:23:03,960 --> 00:23:08,960
which is a little bit
broader than just Outlook.

439
00:23:09,070 --> 00:23:12,370
So one thing we can do is get all 80 users

440
00:23:12,370 --> 00:23:14,180
with that access token,

441
00:23:14,180 --> 00:23:16,630
running as Ed or with his permissions.

442
00:23:16,630 --> 00:23:18,720
And there's a list of three users, Ed,

443
00:23:18,720 --> 00:23:20,980
included David and Sandra.

444
00:23:20,980 --> 00:23:24,880
We will go to, just to
compare, we'll go to

445
00:23:27,330 --> 00:23:29,983
Ed's view, the victim,

446
00:23:31,530 --> 00:23:33,200
in Azure Portal.

447
00:23:33,200 --> 00:23:38,030
We will actually go into
the Azure Active Directory

448
00:23:38,030 --> 00:23:40,230
and check out the users
just to convince theirselves

449
00:23:40,230 --> 00:23:43,570
this is real data matching, right?

450
00:23:43,570 --> 00:23:45,460
All matches.

451
00:23:45,460 --> 00:23:46,293
What else can we do?

452
00:23:46,293 --> 00:23:49,150
We can gain access to Ed's email.

453
00:23:49,150 --> 00:23:52,130
So we just did a call with
that same access token

454
00:23:52,130 --> 00:23:55,673
and got three emails.

455
00:23:56,670 --> 00:23:59,210
Thank you from 365 team,

456
00:23:59,210 --> 00:24:03,800
some social security credit
card numbers, all looks great.

457
00:24:03,800 --> 00:24:07,440
Switch to Outlook as Ed and
you can see in the inbox,

458
00:24:07,440 --> 00:24:10,160
nav pane on the left, the same emails.

459
00:24:10,160 --> 00:24:12,010
So this is great.

460
00:24:12,010 --> 00:24:15,753
Through the graph API, we have
access to email, some of AD,

461
00:24:17,640 --> 00:24:19,930
but to make it interesting,

462
00:24:19,930 --> 00:24:24,100
we want to show that
you can actually pivot,

463
00:24:24,100 --> 00:24:26,130
move laterally and trade in,

464
00:24:26,130 --> 00:24:30,070
or rather use the refresh token we have

465
00:24:30,070 --> 00:24:33,800
to gain a different access
token with different scopes,

466
00:24:33,800 --> 00:24:36,020
different implicit scopes.

467
00:24:36,020 --> 00:24:38,090
So let's do one that allows us

468
00:24:38,090 --> 00:24:41,650
to get more at all of Azure, okay?

469
00:24:41,650 --> 00:24:45,460
More of all of Azure resources.

470
00:24:45,460 --> 00:24:48,430
So what did we do here?

471
00:24:48,430 --> 00:24:52,120
We use the refresh token that we got

472
00:24:52,120 --> 00:24:57,077
under the guise of Microsoft
Office against the graph API

473
00:24:57,077 --> 00:25:02,077
and we use that refresh token
to get a new access token

474
00:25:03,050 --> 00:25:07,383
that has access to the resources in Azure.

475
00:25:08,770 --> 00:25:13,770
We are still using the Outlook
client ID and the scope.

476
00:25:14,010 --> 00:25:16,510
We have to specify scope before we didn't,

477
00:25:16,510 --> 00:25:20,460
we got a bunch of scope permissions.

478
00:25:20,460 --> 00:25:21,670
Here we're using open ID,

479
00:25:21,670 --> 00:25:25,920
which is a pretty basic scope
sort of username, email,

480
00:25:25,920 --> 00:25:27,573
basic profile information.

481
00:25:28,810 --> 00:25:32,543
Okay, and what we got back is interesting.

482
00:25:34,410 --> 00:25:37,500
We request their resource
or Azure and that's fine.

483
00:25:37,500 --> 00:25:39,520
But look at the scope, it changed,

484
00:25:39,520 --> 00:25:41,200
which is part of the protocol.

485
00:25:41,200 --> 00:25:44,720
It comes back with what
you really have access to.

486
00:25:44,720 --> 00:25:47,420
We asked for open ID, we
got back user impersonation,

487
00:25:47,420 --> 00:25:49,740
user impersonation is we can
do everything that user can

488
00:25:49,740 --> 00:25:53,610
within this resource area of Azure.

489
00:25:53,610 --> 00:25:58,183
That happens to be a global
administrator, we have hit gold.

490
00:26:00,660 --> 00:26:02,140
Okay, we got a new access token.

491
00:26:02,140 --> 00:26:06,500
This access token has the scope
privilege for this resource.

492
00:26:06,500 --> 00:26:10,780
So, and we didn't really have
to supply anything special.

493
00:26:10,780 --> 00:26:12,713
I want to point out no secrets.

494
00:26:15,230 --> 00:26:16,610
So what can we do with that?

495
00:26:16,610 --> 00:26:20,960
Let's enumerate all resources in Azure,

496
00:26:20,960 --> 00:26:23,453
at least in the subscription
that Ed is part of.

497
00:26:24,660 --> 00:26:25,750
Okay, long list.

498
00:26:25,750 --> 00:26:27,510
Let's go back to the beginning.

499
00:26:27,510 --> 00:26:28,873
Let's take a look at this.

500
00:26:31,190 --> 00:26:33,540
First, we listed the subscription

501
00:26:34,490 --> 00:26:37,940
that this user has access to this token,

502
00:26:37,940 --> 00:26:40,370
just to convince ourselves we're
in Ed's view in the portal.

503
00:26:40,370 --> 00:26:43,360
Let's look at subscriptions,
it is in fact,

504
00:26:43,360 --> 00:26:45,430
Azure subscription 1, great.

505
00:26:45,430 --> 00:26:47,300
A bunch of resources in that subscription.

506
00:26:47,300 --> 00:26:49,740
So let's look at all resources

507
00:26:49,740 --> 00:26:51,770
and compare it with what we retrieved,

508
00:26:51,770 --> 00:26:54,820
just to convince ourselves
we're looking at real data

509
00:26:54,820 --> 00:26:57,480
and discs, and computes.

510
00:26:57,480 --> 00:27:00,940
Virtual machines that has SSH keys.

511
00:27:00,940 --> 00:27:04,023
There's a storage account for data.

512
00:27:06,035 --> 00:27:09,440
SAJEH1 is listed there, right there,

513
00:27:09,440 --> 00:27:12,120
and on that is a container

514
00:27:12,120 --> 00:27:15,420
that storage account has
a container as SCJEH1

515
00:27:18,950 --> 00:27:21,280
drilling into that
container are two files,

516
00:27:21,280 --> 00:27:25,737
ss1.txt and ss3.txt.

517
00:27:25,737 --> 00:27:27,033
And in fact,

518
00:27:29,040 --> 00:27:30,510
there is the container

519
00:27:30,510 --> 00:27:33,090
and there is ss1,

520
00:27:33,090 --> 00:27:34,260
ss3.

521
00:27:34,260 --> 00:27:36,200
So everything matches up

522
00:27:36,200 --> 00:27:38,350
and we've just enumerated everything.

523
00:27:38,350 --> 00:27:40,793
And since, as a global administrator,

524
00:27:40,793 --> 00:27:45,420
we could do anything pretty
much within the whole AD,

525
00:27:45,420 --> 00:27:47,330
as well as the subscription.

526
00:27:47,330 --> 00:27:50,333
So that's the end of the phish.

527
00:27:52,880 --> 00:27:57,053
And the super interesting part
from this view is the pivot,

528
00:27:58,110 --> 00:28:00,110
as well as that we had to supply,

529
00:28:00,110 --> 00:28:03,180
and we did not need to supply
any secrets along the way,

530
00:28:03,180 --> 00:28:04,913
it was really easy.

531
00:28:06,870 --> 00:28:10,920
Let's switch back and look at
the voice code authorization

532
00:28:12,940 --> 00:28:14,630
and a little bit more detail

533
00:28:14,630 --> 00:28:16,920
going back to the protocol itself

534
00:28:16,920 --> 00:28:18,220
and let's figure out

535
00:28:19,650 --> 00:28:22,663
how we abused and carried out that demo.

536
00:28:24,080 --> 00:28:27,053
So let me highlight a few things.

537
00:28:29,240 --> 00:28:31,703
When we turn this into a phish,

538
00:28:32,730 --> 00:28:36,700
you pretty much use the standard
device code authorization,

539
00:28:36,700 --> 00:28:41,700
but of course there is no initial
login or task by the user.

540
00:28:41,860 --> 00:28:44,490
Normally with a smart TV example,

541
00:28:44,490 --> 00:28:48,660
the user's explicitly trying
to hook up a streaming service

542
00:28:48,660 --> 00:28:49,690
and authenticate to it.

543
00:28:49,690 --> 00:28:53,883
So the user is expecting
to be part of this flow.

544
00:28:55,240 --> 00:28:58,700
Here, the attacker's in
control, user is sitting,

545
00:28:58,700 --> 00:29:02,600
minding their own business,
we will, as an attacker,

546
00:29:02,600 --> 00:29:04,870
start with generating some user codes.

547
00:29:04,870 --> 00:29:07,780
And I want to point out
this is a real snippet

548
00:29:07,780 --> 00:29:10,430
of all the key attributes
in the REST API call

549
00:29:10,430 --> 00:29:15,410
to generate a code and
get the standard URL.

550
00:29:15,410 --> 00:29:18,880
I supply client ID, which
we have seen can be spoofed

551
00:29:18,880 --> 00:29:23,880
or rather be an existing client
ID, including the vendors,

552
00:29:24,030 --> 00:29:25,970
in this case, it's Outlook.

553
00:29:25,970 --> 00:29:28,623
I don't need to supply a secret here.

554
00:29:29,860 --> 00:29:32,200
And I can specify a resource,

555
00:29:32,200 --> 00:29:34,503
whether it's graph API or outlook.com

556
00:29:35,700 --> 00:29:38,170
and I immediately get back
the information I need

557
00:29:38,170 --> 00:29:39,473
to start my phish.

558
00:29:40,514 --> 00:29:42,960
Device_code, which I'll use later,

559
00:29:42,960 --> 00:29:44,225
user_code, which I'll give to the user

560
00:29:44,225 --> 00:29:46,325
to log in the device with expiration time.

561
00:29:47,490 --> 00:29:51,203
I give that to the user
and my phish, the user,

562
00:29:52,150 --> 00:29:55,270
if they're convinced, this is
the key step, the number four,

563
00:29:55,270 --> 00:29:58,510
but if they're convinced
they go and authenticate,

564
00:29:58,510 --> 00:30:02,480
enter the code, go through
authentication, including MFA.

565
00:30:02,480 --> 00:30:04,180
And once they're done,

566
00:30:04,180 --> 00:30:07,480
what's happened is the
device is in the background,

567
00:30:07,480 --> 00:30:11,620
polling and checking
the identity platform,

568
00:30:11,620 --> 00:30:12,670
which will let it know

569
00:30:12,670 --> 00:30:16,060
once the user is finished
logging in successfully,

570
00:30:16,060 --> 00:30:19,760
at which case a lot tokens will be created

571
00:30:19,760 --> 00:30:23,933
and returned as part of
this polling API call.

572
00:30:25,450 --> 00:30:28,070
Look at all of the stuff
that the application

573
00:30:28,070 --> 00:30:29,430
or the device has done.

574
00:30:29,430 --> 00:30:31,120
No secrets required.

575
00:30:31,120 --> 00:30:32,760
All public information in fact,

576
00:30:32,760 --> 00:30:34,323
client IDs are,

577
00:30:35,397 --> 00:30:38,933
for the most part easily
determined for local clients.

578
00:30:39,910 --> 00:30:40,910
And they're also logged,

579
00:30:40,910 --> 00:30:43,670
so it's actually really
easy in the Microsoft area

580
00:30:43,670 --> 00:30:46,603
to identify client IDs,
no secrets are needed.

581
00:30:48,050 --> 00:30:50,290
So you can see that this
is a little disturbing

582
00:30:50,290 --> 00:30:55,090
because if you squint and
step back and ignore the text,

583
00:30:55,090 --> 00:31:00,050
we now have a process where I
just need to convince the user

584
00:31:00,050 --> 00:31:04,167
to type in a code in a standard
Microsoft or Google URL.

585
00:31:07,490 --> 00:31:08,673
If I do that,

586
00:31:09,940 --> 00:31:10,773
then

587
00:31:11,960 --> 00:31:12,793
just to note,

588
00:31:12,793 --> 00:31:16,400
I do know that I've mixed
and matched Google URLs

589
00:31:16,400 --> 00:31:17,823
with Microsoft ones,

590
00:31:21,860 --> 00:31:26,860
but in all cases, this is very
real and often common, right?

591
00:31:28,140 --> 00:31:31,410
All of these attributes
are similar across both

592
00:31:31,410 --> 00:31:35,853
and what I was saying is
that to carry out this phish,

593
00:31:36,820 --> 00:31:38,780
if you step back from it all,

594
00:31:38,780 --> 00:31:40,780
all you need to do is convince the user

595
00:31:40,780 --> 00:31:43,663
to go to a particular URL,

596
00:31:44,620 --> 00:31:47,300
enter in a code,

597
00:31:47,300 --> 00:31:48,283
authenticate,

598
00:31:49,350 --> 00:31:50,700
OAuth tokens will be created,

599
00:31:50,700 --> 00:31:53,850
stored by the identity platform,

600
00:31:53,850 --> 00:31:58,120
and you can go and retrieve them.

601
00:31:58,120 --> 00:32:00,240
That's a little bit crazy, all right?

602
00:32:00,240 --> 00:32:02,980
You don't have to create your
own infrastructure to do that,

603
00:32:02,980 --> 00:32:06,060
your own login page, your own application.

604
00:32:06,060 --> 00:32:11,060
You just had to point the
user to identity platform

605
00:32:11,170 --> 00:32:13,993
and give them a code, and
then you have their tokens.

606
00:32:17,040 --> 00:32:19,593
Once you have access tokens,

607
00:32:19,593 --> 00:32:24,593
that pivot from a Microsoft
perspective does look like this.

608
00:32:26,160 --> 00:32:30,100
You supply, you make a refresh token call

609
00:32:30,100 --> 00:32:32,280
and you get back a fresh set.

610
00:32:32,280 --> 00:32:34,820
And here's where you can
see the scope changes.

611
00:32:34,820 --> 00:32:36,230
We pointed this out during the demo,

612
00:32:36,230 --> 00:32:39,493
and this is just repeated
just to show that.

613
00:32:42,390 --> 00:32:46,230
So, to summarize some of the key points,

614
00:32:46,230 --> 00:32:48,410
what's not just with Microsoft,

615
00:32:48,410 --> 00:32:50,810
but common across all off vendors

616
00:32:50,810 --> 00:32:53,160
is a device code authorization

617
00:32:53,160 --> 00:32:55,490
that has three aspects or qualities.

618
00:32:55,490 --> 00:32:58,120
You don't need server infrastructure.

619
00:32:58,120 --> 00:33:01,580
You don't need to register
your own OAuth application,

620
00:33:01,580 --> 00:33:04,240
in fact, you can use an existing one,

621
00:33:04,240 --> 00:33:06,393
even the vendor's client application.

622
00:33:07,450 --> 00:33:09,600
The user does not see a consent screen,

623
00:33:09,600 --> 00:33:11,820
does not see a list of permissions.

624
00:33:11,820 --> 00:33:12,920
They're not prompted for that.

625
00:33:12,920 --> 00:33:16,330
They are prompted with
this somewhat obscured,

626
00:33:16,330 --> 00:33:18,580
do you want to sign into the application?

627
00:33:18,580 --> 00:33:20,320
But that's it, not,

628
00:33:20,320 --> 00:33:22,210
do you want to grant
the application access

629
00:33:22,210 --> 00:33:26,000
to everything in your
email, all users and AD,

630
00:33:26,000 --> 00:33:29,520
and your Azure, as well as other services?

631
00:33:29,520 --> 00:33:31,053
They don't see that, right?

632
00:33:33,260 --> 00:33:38,120
Microsoft has sense of
implicit or default scopes

633
00:33:38,120 --> 00:33:38,953
that is

634
00:33:40,460 --> 00:33:43,130
in step two, the application,

635
00:33:43,130 --> 00:33:46,240
when it starts this whole process,

636
00:33:46,240 --> 00:33:47,810
never supply a scope.

637
00:33:47,810 --> 00:33:50,643
Google's a bit different,
we do supply a scope.

638
00:33:51,970 --> 00:33:54,160
It just means that the scopes you get,

639
00:33:54,160 --> 00:33:56,160
ultimately with OAuth tokens

640
00:33:56,160 --> 00:33:59,240
are things you never had to request.

641
00:33:59,240 --> 00:34:01,490
And we ended up getting
user impersonation,

642
00:34:01,490 --> 00:34:03,830
scopes and Microsoft, which
allows us to do anything

643
00:34:03,830 --> 00:34:05,183
that the user can do.

644
00:34:08,350 --> 00:34:12,340
Microsoft allows this lateral
move to other services

645
00:34:12,340 --> 00:34:16,170
or resources, I should say, as that user,

646
00:34:16,170 --> 00:34:18,140
by being able to refresh a token

647
00:34:18,140 --> 00:34:21,053
and for a different
resource and get that back.

648
00:34:23,160 --> 00:34:27,163
Logging is limited and what is logged?

649
00:34:28,270 --> 00:34:32,570
Is when attacker actually
retrieves though off token,

650
00:34:32,570 --> 00:34:34,620
their IP address is logged

651
00:34:34,620 --> 00:34:38,910
and it shows as an actual
authentication or sign in,

652
00:34:38,910 --> 00:34:43,910
in the sign-in logs of
Azure for this user.

653
00:34:45,460 --> 00:34:47,870
Okay, but this is limited

654
00:34:47,870 --> 00:34:50,030
because the lateral move is not logged.

655
00:34:50,030 --> 00:34:53,360
The lateral move being, when we refreshed

656
00:34:55,010 --> 00:34:59,540
the token to get an Azure access
token, that was not logged.

657
00:34:59,540 --> 00:35:00,373
So,

658
00:35:01,550 --> 00:35:03,260
partial information.

659
00:35:03,260 --> 00:35:07,210
Here's some of the details
in that line item or entry

660
00:35:07,210 --> 00:35:08,680
and we can see that

661
00:35:10,440 --> 00:35:14,400
the application information ID is shown,

662
00:35:14,400 --> 00:35:15,710
but not much else.

663
00:35:15,710 --> 00:35:19,360
We know what user is
operating here, right?

664
00:35:19,360 --> 00:35:20,790
The attacker did this

665
00:35:24,360 --> 00:35:27,170
retrieval of OAuth tokens for Ed,

666
00:35:27,170 --> 00:35:30,253
but this just looks like
an Ed action, right?

667
00:35:32,160 --> 00:35:33,870
Nothing identifies the attacker,

668
00:35:33,870 --> 00:35:38,490
other than the IP address
on the prior view,

669
00:35:38,490 --> 00:35:42,693
which can easily be obfuscated
through a proxy or VPN.

670
00:35:43,800 --> 00:35:48,090
So what can reasonably be
done to protect against this?

671
00:35:48,090 --> 00:35:49,770
Or what would be encountered?

672
00:35:49,770 --> 00:35:51,100
Probably the most effective one

673
00:35:51,100 --> 00:35:54,370
would be blocking a verification URL.

674
00:35:54,370 --> 00:35:57,220
So that is the sign-in URLs

675
00:35:57,220 --> 00:35:59,600
that start this whole
process off for the user.

676
00:35:59,600 --> 00:36:01,710
There are some standard ones for Google,

677
00:36:01,710 --> 00:36:02,570
Microsoft has two

678
00:36:02,570 --> 00:36:05,383
because the second one
redirects to the third.

679
00:36:06,270 --> 00:36:08,623
So we could block those URIs,

680
00:36:10,210 --> 00:36:11,593
security team could.

681
00:36:12,530 --> 00:36:14,230
But it's an imperfect solution

682
00:36:14,230 --> 00:36:18,820
because you actually
might need to allow it

683
00:36:18,820 --> 00:36:20,960
for some valid log-ins.

684
00:36:20,960 --> 00:36:22,640
What's an example of that?

685
00:36:22,640 --> 00:36:27,640
Not a smart TV that could
probably be against all policy,

686
00:36:27,740 --> 00:36:29,170
but it could be

687
00:36:30,900 --> 00:36:32,320
Azure.

688
00:36:32,320 --> 00:36:33,860
Azure CLI

689
00:36:35,430 --> 00:36:37,853
does device code authorization,

690
00:36:39,050 --> 00:36:40,140
at least has one flow

691
00:36:40,140 --> 00:36:44,810
where it does verbatim
device code authorization.

692
00:36:44,810 --> 00:36:45,643
So,

693
00:36:47,200 --> 00:36:49,570
you have to be careful what is broken

694
00:36:49,570 --> 00:36:51,320
if you're on the defensive side.

695
00:36:51,320 --> 00:36:54,230
And it just means that
there's opportunities

696
00:36:54,230 --> 00:36:56,440
where the prevention may be imperfect

697
00:36:56,440 --> 00:36:58,620
or can't be put in place.

698
00:36:58,620 --> 00:37:00,573
There are some recommendation to use,

699
00:37:02,200 --> 00:37:07,200
to block access or use
of tokens based on IP,

700
00:37:07,600 --> 00:37:12,240
or location, or endpoint and
if that's within control,

701
00:37:12,240 --> 00:37:13,920
that's a possibility.

702
00:37:13,920 --> 00:37:17,953
But IP allow lists and
often our challenge,

703
00:37:17,953 --> 00:37:21,900
as well as geolocation
and other characteristics.

704
00:37:21,900 --> 00:37:24,770
So prevention is best described as

705
00:37:26,060 --> 00:37:30,010
imperfect but possibility
detection is difficult

706
00:37:30,010 --> 00:37:33,250
because the logging of anything
related to OAuth tokens

707
00:37:33,250 --> 00:37:37,540
or temporary session
tokens is very limited.

708
00:37:37,540 --> 00:37:39,910
Remediation does exist if,

709
00:37:39,910 --> 00:37:42,030
once you do know there's
a problem with a user,

710
00:37:42,030 --> 00:37:45,150
you can revoke all OAuth
tokens in Microsoft's world.

711
00:37:45,150 --> 00:37:49,530
In Google, that is more
obscure, you can do it,

712
00:37:49,530 --> 00:37:53,800
but it's not as obvious
as a straight API call.

713
00:37:53,800 --> 00:37:56,610
There are some practical
considerations to keep in mind,

714
00:37:56,610 --> 00:37:58,570
the main one is that the user

715
00:37:58,570 --> 00:38:01,000
or device code one generated is temporary.

716
00:38:01,000 --> 00:38:03,610
It will expire typically
after 15 or 30 minutes,

717
00:38:03,610 --> 00:38:07,140
it's in the response of the REST API call.

718
00:38:07,140 --> 00:38:09,760
And it just means the attacker
can either in response,

719
00:38:09,760 --> 00:38:14,000
play a phishing numbers
game that is ignored

720
00:38:14,000 --> 00:38:17,810
and just blast out to
a large number of users

721
00:38:17,810 --> 00:38:21,793
at a certain time in order
to get them to respond.

722
00:38:22,830 --> 00:38:26,120
If going over email, an email
would have its advantages

723
00:38:26,120 --> 00:38:28,490
and that the phish could
be rich, all right?

724
00:38:28,490 --> 00:38:29,323
It could sell a story.

725
00:38:29,323 --> 00:38:34,290
However, the timing may have
a result in a low response

726
00:38:35,910 --> 00:38:39,190
to the phish, so practically
speaking, though,

727
00:38:39,190 --> 00:38:42,030
you could choose other
forms of communication,

728
00:38:42,030 --> 00:38:44,240
including chat, SMS,

729
00:38:44,240 --> 00:38:48,590
that might create a more instant response

730
00:38:48,590 --> 00:38:52,730
because of how those
application are actually used

731
00:38:52,730 --> 00:38:55,780
in everyday interactions.

732
00:38:55,780 --> 00:39:00,220
So there's ways around
this temporary timeframe,

733
00:39:00,220 --> 00:39:02,600
you could also fall
back and actually create

734
00:39:02,600 --> 00:39:04,490
some infrastructure hosted websites

735
00:39:04,490 --> 00:39:09,490
and then have your phish
instead of supplying a code,

736
00:39:10,870 --> 00:39:13,440
instead points the user to a website,

737
00:39:13,440 --> 00:39:16,200
the fake hosted website to generate a code

738
00:39:16,200 --> 00:39:17,410
and get your discount code,

739
00:39:17,410 --> 00:39:21,610
so discount codes exist
in that model today,

740
00:39:21,610 --> 00:39:22,900
and it's probably reasonable

741
00:39:22,900 --> 00:39:24,510
that someone would fall through that.

742
00:39:24,510 --> 00:39:27,190
You could even have images
dynamically generated

743
00:39:28,640 --> 00:39:32,510
that show codes and images are suggested

744
00:39:32,510 --> 00:39:35,390
because that would be
allowed over JavaScript

745
00:39:35,390 --> 00:39:37,610
in actual mail browsers.

746
00:39:37,610 --> 00:39:38,443
They might be blocked,

747
00:39:38,443 --> 00:39:40,540
but the user always has
an option to load images

748
00:39:40,540 --> 00:39:42,590
and that could dynamically
at that point in time

749
00:39:42,590 --> 00:39:47,190
generate a code and would
give a fresh 15 minutes

750
00:39:47,190 --> 00:39:48,930
for the user to do that.

751
00:39:48,930 --> 00:39:53,650
So I pointed that out mainly
because that is the one area

752
00:39:53,650 --> 00:39:56,440
from a practical implementation viewpoint

753
00:39:56,440 --> 00:39:58,063
would need to be accommodated.

754
00:39:59,160 --> 00:40:03,120
So, there are some comparisons
between OAuth providers,

755
00:40:03,120 --> 00:40:04,950
in this case, it took the two major ones,

756
00:40:04,950 --> 00:40:06,273
Microsoft and Google.

757
00:40:07,200 --> 00:40:08,290
The main difference is,

758
00:40:08,290 --> 00:40:10,250
there's more exposure
on the Microsoft side

759
00:40:10,250 --> 00:40:12,310
because of the handling of the scopes

760
00:40:12,310 --> 00:40:14,870
are implicit in default,

761
00:40:14,870 --> 00:40:18,840
and you can get quite a lot of permissions

762
00:40:18,840 --> 00:40:20,960
without even asking for
them, whereas on Google,

763
00:40:20,960 --> 00:40:23,600
they really tightened
up the scopes you get

764
00:40:25,250 --> 00:40:27,023
from device code authorization,

765
00:40:28,870 --> 00:40:31,470
meaning the access tokens
can access user profile

766
00:40:31,470 --> 00:40:34,590
have limited Google Drive
access mainly to files

767
00:40:34,590 --> 00:40:36,560
that the app itself has created

768
00:40:36,560 --> 00:40:38,780
and some YouTube more profile info.

769
00:40:38,780 --> 00:40:39,940
So because of that,

770
00:40:39,940 --> 00:40:43,640
the lateral movements very
different on the Microsoft side,

771
00:40:43,640 --> 00:40:48,020
it was easy as we saw in
the demo to switch between

772
00:40:48,020 --> 00:40:50,920
or among a large number of
services, as well as on Google,

773
00:40:52,310 --> 00:40:54,243
it's pretty limited and strict.

774
00:40:55,150 --> 00:40:57,683
You get what you get
with the initial scope.

775
00:41:01,200 --> 00:41:03,920
But all in all this drives towards

776
00:41:03,920 --> 00:41:06,933
maybe mentioning some
ongoing research areas.

777
00:41:09,250 --> 00:41:12,170
The problem with OAuth is not that

778
00:41:13,360 --> 00:41:16,110
it's got flaws or is insecure,

779
00:41:16,110 --> 00:41:18,573
the problem is more that it's complicated.

780
00:41:19,550 --> 00:41:23,330
We talked about the normal
OAuth flow, the payments,

781
00:41:23,330 --> 00:41:27,000
examples, in CLI log in examples,

782
00:41:27,000 --> 00:41:30,723
we did a demo of how one
other flow, the device code,

783
00:41:32,370 --> 00:41:35,640
authorization flow can
be easily exploited.

784
00:41:35,640 --> 00:41:36,850
There's three more flows,

785
00:41:36,850 --> 00:41:40,770
which aren't quite as
obvious as device code off

786
00:41:42,040 --> 00:41:47,040
on authorization, but in
terms of having exposure,

787
00:41:47,630 --> 00:41:50,560
but certainly are
interesting areas to research

788
00:41:50,560 --> 00:41:54,050
because some of them have
usability type requirements

789
00:41:54,050 --> 00:41:57,800
like implicit grants where
thing like consent can be bypass

790
00:41:57,800 --> 00:42:01,250
because there's a way to
get access token silently

791
00:42:01,250 --> 00:42:02,500
in the background, right?

792
00:42:04,430 --> 00:42:06,970
The default scopes that Microsoft has

793
00:42:06,970 --> 00:42:08,230
in their implementation

794
00:42:09,740 --> 00:42:12,360
is another area to delve further into,

795
00:42:12,360 --> 00:42:17,360
just to see how those scopes
are specified and returned,

796
00:42:18,410 --> 00:42:21,830
because there maybe
areas to explore there.

797
00:42:21,830 --> 00:42:24,573
Consent is described.

798
00:42:26,110 --> 00:42:27,360
Let me preface that with,

799
00:42:27,360 --> 00:42:29,580
there is a model for incremental consent,

800
00:42:29,580 --> 00:42:34,580
so that an application can
present one at a time permissions

801
00:42:34,590 --> 00:42:37,860
or ask the user one at a
time for certain permissions

802
00:42:38,700 --> 00:42:39,663
as needed.

803
00:42:40,690 --> 00:42:44,210
But then it gets into dynamic user consent

804
00:42:44,210 --> 00:42:45,490
and some language that just hints

805
00:42:45,490 --> 00:42:48,320
that it's not as quite straight forward

806
00:42:48,320 --> 00:42:50,970
in terms of behavior, as you might think,

807
00:42:50,970 --> 00:42:55,970
and complexity breeds sort
of opportunities for exploit.

808
00:42:56,416 --> 00:42:59,810
And the last area is
particularly interesting in that.

809
00:42:59,810 --> 00:43:04,160
Browsers today allow sort
of usability features

810
00:43:04,160 --> 00:43:06,240
where you log into one application,

811
00:43:06,240 --> 00:43:08,770
let's say you're in
Chrome, you log into Gmail,

812
00:43:08,770 --> 00:43:13,770
then you suddenly open up a tab
and put in that same browser

813
00:43:15,078 --> 00:43:18,590
URL for G Drive, we don't
have to reauthenticate

814
00:43:18,590 --> 00:43:22,043
to G Drive, even though
that it's a separate app,

815
00:43:22,043 --> 00:43:25,890
you not even presented
with a consent screen

816
00:43:25,890 --> 00:43:27,250
for either application.

817
00:43:27,250 --> 00:43:30,240
So already browsers today for usability

818
00:43:30,240 --> 00:43:32,940
provide this kind of auto log-in

819
00:43:32,940 --> 00:43:36,260
and scope expansion in the
sense of switching scopes that

820
00:43:38,360 --> 00:43:41,870
don't involve users explicitly,

821
00:43:41,870 --> 00:43:43,410
entering credentials every time,

822
00:43:43,410 --> 00:43:46,710
and reapproving scopes and permissions.

823
00:43:46,710 --> 00:43:48,060
What does that mean?

824
00:43:48,060 --> 00:43:50,430
It just means usability
might have short cut

825
00:43:50,430 --> 00:43:51,820
some parts of the protocol

826
00:43:51,820 --> 00:43:53,920
because it is OAuth underneath, right?

827
00:43:53,920 --> 00:43:58,900
So back in 2013, it's not
all hypothetical, there was

828
00:43:58,900 --> 00:44:02,540
some opportunity

829
00:44:02,540 --> 00:44:05,330
to mimic what happened

830
00:44:05,330 --> 00:44:09,160
with certain Chromium browsers

831
00:44:09,160 --> 00:44:11,040
or Chrome browsers,

832
00:44:11,040 --> 00:44:13,480
basically where you could
have a token traded in

833
00:44:13,480 --> 00:44:17,010
and get more of a super or uber token

834
00:44:17,010 --> 00:44:20,430
that could access a lot
of information across apps

835
00:44:20,430 --> 00:44:25,430
without have gone through
any reauthentication.

836
00:44:25,650 --> 00:44:29,520
Anyway, long story short,
it's a very interesting area.

837
00:44:29,520 --> 00:44:34,520
And beyond this list of the
more important takeaway is that,

838
00:44:35,390 --> 00:44:40,390
we have a complicated
authorization protocol.

839
00:44:42,790 --> 00:44:46,500
We have differences in plan
implementation as we've seen.

840
00:44:46,500 --> 00:44:49,740
Microsoft's has a few quirks,

841
00:44:49,740 --> 00:44:51,490
Google has some different ones,

842
00:44:51,490 --> 00:44:53,580
results in different behavior.

843
00:44:53,580 --> 00:44:54,960
It's ubiquitous.

844
00:44:54,960 --> 00:44:59,103
It is as much a standard as
anything on the internet.

845
00:45:00,220 --> 00:45:04,950
You can't avoid it, everyone's using it

846
00:45:04,950 --> 00:45:08,440
and it's distributed by
nature over a large network

847
00:45:08,440 --> 00:45:10,490
with REST APIs.

848
00:45:10,490 --> 00:45:12,080
So,

849
00:45:12,080 --> 00:45:15,500
this is particularly
interesting area for us

850
00:45:15,500 --> 00:45:16,480
to keep an eye on,

851
00:45:16,480 --> 00:45:20,223
in terms of security
risks and opportunities.

852
00:45:21,670 --> 00:45:24,103
So thank you, that is the end of the talk.

853
00:45:24,960 --> 00:45:26,380
We didn't cover in detail,

854
00:45:26,380 --> 00:45:30,200
but there are open source
tools that you can use

855
00:45:30,200 --> 00:45:34,160
to run the demo as well
as do self phishing,

856
00:45:34,160 --> 00:45:37,683
as well as explore what
permissions are available.

857
00:45:38,530 --> 00:45:41,920
Once you do get responses to phishes,

858
00:45:43,900 --> 00:45:46,480
and finally, there is
a list of references,

859
00:45:46,480 --> 00:45:49,000
which is in the initial presentation,

860
00:45:49,000 --> 00:45:51,060
but repeated here as well.

861
00:45:51,060 --> 00:45:52,900
So thank you for your time

862
00:45:52,900 --> 00:45:55,433
and if there's time for
questions, we'll take them now.

