1
00:00:01,140 --> 00:00:02,360
- Hey, what's up DEF CON?

2
00:00:02,360 --> 00:00:04,960
This is Cedric Owens, I'm
super humbled and excited

3
00:00:04,960 --> 00:00:08,240
to be here, and I'll be talking about,

4
00:00:08,240 --> 00:00:09,390
basically giving a perspective

5
00:00:09,390 --> 00:00:12,980
of what red teaming looks like
in macOS environments here

6
00:00:12,980 --> 00:00:14,323
in the year 2021.

7
00:00:15,960 --> 00:00:18,220
Some background information on myself,

8
00:00:18,220 --> 00:00:20,740
I'm a full-time offensive
security engineer

9
00:00:20,740 --> 00:00:21,970
on the red team side,

10
00:00:21,970 --> 00:00:25,810
and I've been dedicated red
teamer now for the past four,

11
00:00:25,810 --> 00:00:27,260
almost five years.

12
00:00:27,260 --> 00:00:30,270
Prior to that, vast
majority of my career's been

13
00:00:30,270 --> 00:00:32,340
on the blue team side
doing incident response,

14
00:00:32,340 --> 00:00:34,400
threat detection, threat hunting,

15
00:00:34,400 --> 00:00:37,630
both in the intel community
and in the private sector,

16
00:00:37,630 --> 00:00:40,280
and so even as a full-time red teamer now,

17
00:00:40,280 --> 00:00:42,570
I highly value
collaborating with blue team

18
00:00:42,570 --> 00:00:44,800
just to help uplift
each other's trade craft

19
00:00:44,800 --> 00:00:47,970
and move the needle forward
in our organizations.

20
00:00:47,970 --> 00:00:50,260
I personally enjoy macOS post exploitation

21
00:00:50,260 --> 00:00:51,720
as an interest area of mine,

22
00:00:51,720 --> 00:00:53,530
that and infrastructure automation,

23
00:00:53,530 --> 00:00:55,470
so whenever I do have free time,

24
00:00:55,470 --> 00:00:57,480
I'm typically working on projects that fit

25
00:00:57,480 --> 00:00:59,240
into one of those two buckets.

26
00:00:59,240 --> 00:01:01,137
Also as an early '80s
baby, I do enjoy '80s

27
00:01:01,137 --> 00:01:05,570
and '90s nostalgia such as what
you see here in the picture,

28
00:01:05,570 --> 00:01:07,520
just reminds me a lot of my childhood,

29
00:01:07,520 --> 00:01:10,970
and it's even cooler now
to see my kids playing

30
00:01:10,970 --> 00:01:13,580
with a lot of these same toys
or watching these same shows,

31
00:01:13,580 --> 00:01:15,530
and just kinda cool to see the legacy

32
00:01:15,530 --> 00:01:16,940
of these things live on.

33
00:01:16,940 --> 00:01:19,680
I am on Twitter, handle @cedowens

34
00:01:19,680 --> 00:01:21,610
where occasionally I'll post blog posts

35
00:01:21,610 --> 00:01:23,270
or tools that may be of interest,

36
00:01:23,270 --> 00:01:25,853
so check that out if
that's of interest to you.

37
00:01:26,880 --> 00:01:29,890
So what I plan to talk about
today, first one being,

38
00:01:29,890 --> 00:01:32,370
why do we even care about macOS,

39
00:01:32,370 --> 00:01:34,940
especially in a Windows-centric world?

40
00:01:34,940 --> 00:01:37,030
Why are we even here for this talk?

41
00:01:37,030 --> 00:01:39,000
Overviews of common tech environments

42
00:01:39,000 --> 00:01:41,640
and what the tech stacks
look like in organizations

43
00:01:41,640 --> 00:01:43,690
that are heavy Mac users.

44
00:01:43,690 --> 00:01:46,930
Options for macOS payloads
and post exploitation,

45
00:01:46,930 --> 00:01:49,170
and I look at how the
different options you pick

46
00:01:49,170 --> 00:01:51,450
usually will have a pro and
a con associated with it.

47
00:01:51,450 --> 00:01:54,040
We'll also look at other attack vectors,

48
00:01:54,040 --> 00:01:58,400
so things in macOS environment
that become attack targets

49
00:01:58,400 --> 00:02:01,310
that may not themselves
necessarily be macOS,

50
00:02:01,310 --> 00:02:04,460
but you'll find them often
in macOS environments,

51
00:02:04,460 --> 00:02:07,300
and then we'll end off talking
about detection opportunities

52
00:02:07,300 --> 00:02:09,300
to look at from a blue team perspective.

53
00:02:11,090 --> 00:02:14,560
So again, first question
is macOS, why do we care?

54
00:02:14,560 --> 00:02:16,950
And to your point, if
you're asking that question,

55
00:02:16,950 --> 00:02:21,690
most Fortune 500 companies
today are still Windows shops,

56
00:02:21,690 --> 00:02:24,100
and you may find there that maybe 90%

57
00:02:24,100 --> 00:02:26,900
of their endpoints are
Windows, maybe five Mac,

58
00:02:26,900 --> 00:02:31,600
five Linux or Chromebooks, but in the,

59
00:02:31,600 --> 00:02:34,650
there's a sliver of companies
in the San Francisco Bay Area,

60
00:02:34,650 --> 00:02:36,130
your Silicon Valley companies

61
00:02:36,130 --> 00:02:37,820
that are basically the opposite,

62
00:02:37,820 --> 00:02:41,540
where you may find 80 to 90%
of the endpoints being Mac,

63
00:02:41,540 --> 00:02:44,730
may find five to 10%

64
00:02:44,730 --> 00:02:47,017
or somewhere around there
being Windows endpoints

65
00:02:47,017 --> 00:02:49,630
and you may have Chromebook
and Linux mixed in,

66
00:02:49,630 --> 00:02:52,500
so essentially it's the
flip of what you'll see

67
00:02:52,500 --> 00:02:54,480
in your Fortune 500 environments.

68
00:02:54,480 --> 00:02:57,160
It makes it for an interesting
environment to assess

69
00:02:57,160 --> 00:02:58,590
from an attacker's perspective

70
00:02:58,590 --> 00:03:00,300
because there's often a mentality,

71
00:03:00,300 --> 00:03:03,230
well, if we're not a
enterprise Windows shop,

72
00:03:03,230 --> 00:03:06,060
then we're more secure, and
I can understand the line

73
00:03:06,060 --> 00:03:08,220
of thinking there, but it really depends

74
00:03:08,220 --> 00:03:11,520
on how you implement your
Mac/cloud environment.

75
00:03:11,520 --> 00:03:13,673
In other words, if you
have keys laying around

76
00:03:13,673 --> 00:03:16,180
that are in code repos
or other easy places

77
00:03:16,180 --> 00:03:17,660
for an attacker to find,

78
00:03:17,660 --> 00:03:19,520
you may find that even
though you've migrated off

79
00:03:19,520 --> 00:03:21,840
of a Windows enterprise environment,

80
00:03:21,840 --> 00:03:23,780
your environment can still
be easily compromised,

81
00:03:23,780 --> 00:03:26,940
so we'll talk about that a
little bit more as we go.

82
00:03:26,940 --> 00:03:29,390
It is a slowly growing trend that,

83
00:03:29,390 --> 00:03:30,630
at least that I've been seeing,

84
00:03:30,630 --> 00:03:32,720
where newer companies are adopting more

85
00:03:32,720 --> 00:03:37,230
of a quote unquote non-Windows
enterprise environment,

86
00:03:37,230 --> 00:03:39,180
and what I've noticed
is that Active Directory

87
00:03:39,180 --> 00:03:40,300
is typically gonna be there

88
00:03:40,300 --> 00:03:42,810
because it usually is
the best LDAP solution

89
00:03:42,810 --> 00:03:45,340
for enterprises, so even
in these environments,

90
00:03:45,340 --> 00:03:47,640
you will have Active
Directory which will be used

91
00:03:47,640 --> 00:03:49,670
to back your authentication,

92
00:03:49,670 --> 00:03:53,410
but just your typical
end-to-end enterprise rollout

93
00:03:53,410 --> 00:03:55,490
of Windows will be different here.

94
00:03:55,490 --> 00:03:59,100
And I like it too because
it allows, as a red teamer,

95
00:03:59,100 --> 00:04:01,400
it allows you to point
out different vectors

96
00:04:01,400 --> 00:04:03,640
that really have nothing
to do with Active Directory

97
00:04:03,640 --> 00:04:05,490
and compromising domain controllers,

98
00:04:05,490 --> 00:04:07,410
but other very interesting vectors

99
00:04:07,410 --> 00:04:10,630
that can still be impactful
and in some cases devastating

100
00:04:10,630 --> 00:04:11,590
to your organization,

101
00:04:11,590 --> 00:04:13,570
so I think it's a very
interesting environment

102
00:04:13,570 --> 00:04:15,173
from a red team perspective.

103
00:04:16,600 --> 00:04:19,020
So first we're gonna look
at common tech stacks

104
00:04:19,020 --> 00:04:22,060
and what you might encounter
in a common tech company

105
00:04:22,060 --> 00:04:24,450
in a Silicon Valley area.

106
00:04:24,450 --> 00:04:27,470
First thing is there's a concept
of realms or environments,

107
00:04:27,470 --> 00:04:29,130
and so you may have a
corporate environment,

108
00:04:29,130 --> 00:04:32,530
a dev or stage environment,
production environment,

109
00:04:32,530 --> 00:04:35,280
and so here's an example,
we'll walk from left to right

110
00:04:35,280 --> 00:04:36,910
where you may have employees

111
00:04:36,910 --> 00:04:40,360
that remote in using an
identity as a service solution.

112
00:04:40,360 --> 00:04:43,790
Two common IDaaS solutions
are Okta and OneLogin

113
00:04:43,790 --> 00:04:46,810
where the employee authenticates
with their username,

114
00:04:46,810 --> 00:04:48,790
password, and a 2FA token

115
00:04:48,790 --> 00:04:52,210
which is usually gonna
be a Okta verify push

116
00:04:52,210 --> 00:04:54,400
or a Duo push to their mobile devices.

117
00:04:54,400 --> 00:04:57,530
Once they log in, they're
now inside of their identity

118
00:04:57,530 --> 00:05:00,030
as a service portal, and
they have access to a lot

119
00:05:00,030 --> 00:05:03,970
of different productivity
applications like email,

120
00:05:03,970 --> 00:05:07,981
you may have Atlassian products like Jira,

121
00:05:07,981 --> 00:05:10,060
you may have Salesforce, internal Git,

122
00:05:10,060 --> 00:05:11,780
even custom application servers,

123
00:05:11,780 --> 00:05:14,770
all accessible to the
user based on their roles

124
00:05:14,770 --> 00:05:16,410
in Active Directory.

125
00:05:16,410 --> 00:05:18,660
Then you also, on a production side,

126
00:05:18,660 --> 00:05:22,410
you may find a combination of
cloud-based production hosts

127
00:05:22,410 --> 00:05:25,180
and on-prem, and you may find a lot

128
00:05:25,180 --> 00:05:27,470
of different things there,
but typically in production,

129
00:05:27,470 --> 00:05:29,810
you're gonna find your customer-ready code

130
00:05:29,810 --> 00:05:32,180
and maybe even customer
data that's stored here,

131
00:05:32,180 --> 00:05:34,960
and you're gonna find things
like your build hosts,

132
00:05:34,960 --> 00:05:39,890
your CI/CD pipeline, you may
find some cloud-hosted services

133
00:05:39,890 --> 00:05:42,100
and servers there, you
might find HashiCorp

134
00:05:42,100 --> 00:05:44,330
for managing application secrets,

135
00:05:44,330 --> 00:05:46,300
and of course you may
have some on-prem stuff,

136
00:05:46,300 --> 00:05:49,310
you may have Jenkins on-prem
or even in the cloud.

137
00:05:49,310 --> 00:05:51,090
We have some Windows servers,

138
00:05:51,090 --> 00:05:53,110
segmented environment of
Windows servers there,

139
00:05:53,110 --> 00:05:55,550
so a lot of different things going on here

140
00:05:55,550 --> 00:05:57,080
and it makes it interesting

141
00:05:57,080 --> 00:05:59,750
because of course there's
a lot of complexities,

142
00:05:59,750 --> 00:06:00,583
and sometimes

143
00:06:00,583 --> 00:06:02,600
with more complexities
comes more opportunities

144
00:06:02,600 --> 00:06:04,390
from an attacker perspective.

145
00:06:04,390 --> 00:06:06,580
Another thing to point
out is on the bottom left,

146
00:06:06,580 --> 00:06:09,330
I have rough percentages
over the different endpoints,

147
00:06:09,330 --> 00:06:13,540
so I'm showing macOS being
80% and Windows being 15

148
00:06:13,540 --> 00:06:17,110
and Google Chromebooks
being 5%, just a rough,

149
00:06:17,110 --> 00:06:18,120
rough numbers there.

150
00:06:18,120 --> 00:06:20,800
Some organizations you may
actually find Mac being higher

151
00:06:20,800 --> 00:06:22,670
or closer to 90%,

152
00:06:22,670 --> 00:06:25,630
and the Windows population
being even smaller,

153
00:06:25,630 --> 00:06:26,510
so it's interesting

154
00:06:26,510 --> 00:06:30,210
because with Mac being
such a high percentage

155
00:06:30,210 --> 00:06:32,580
of endpoints in tech environments,

156
00:06:32,580 --> 00:06:35,190
and engineers using their Macs often

157
00:06:35,190 --> 00:06:37,740
to either do dev work locally on a Mac

158
00:06:37,740 --> 00:06:41,410
or log into a cloud-hosted server

159
00:06:41,410 --> 00:06:43,920
or an application server or a jump box,

160
00:06:43,920 --> 00:06:44,910
or from other places

161
00:06:44,910 --> 00:06:47,410
that they can do their
development work from there,

162
00:06:47,410 --> 00:06:50,490
you typically may find that
there are sensitive keys,

163
00:06:50,490 --> 00:06:52,920
tokens, credentials, things
like that that are stored

164
00:06:52,920 --> 00:06:56,560
on the endpoint, so really end-to-end,

165
00:06:56,560 --> 00:06:59,040
this makes for a very
interesting environment to assess

166
00:06:59,040 --> 00:07:00,590
from an attacker's perspective.

167
00:07:02,230 --> 00:07:04,840
Next, gonna talk quickly
about some different ways

168
00:07:04,840 --> 00:07:08,640
that macOS is deployed from
an enterprise perspective.

169
00:07:08,640 --> 00:07:12,327
One option is custom deployment
where you hire your own team

170
00:07:12,327 --> 00:07:16,160
and they build out some
custom solution to manage

171
00:07:16,160 --> 00:07:19,510
and hook into Macs and control
them and push policies,

172
00:07:19,510 --> 00:07:24,380
et cetera, and basically loop
back into your LDAP solution.

173
00:07:24,380 --> 00:07:26,520
Organizations that do that custom tend

174
00:07:26,520 --> 00:07:29,670
to be maybe like your big five in tech,

175
00:07:29,670 --> 00:07:32,450
so something like your Apple
or your Facebook, Google,

176
00:07:32,450 --> 00:07:35,120
may all be custom, where
they have the money,

177
00:07:35,120 --> 00:07:37,040
the resources to throw at that.

178
00:07:37,040 --> 00:07:40,190
But typically what I find
is outside of the big five,

179
00:07:40,190 --> 00:07:43,290
most organizations in
the Silicon Valley area,

180
00:07:43,290 --> 00:07:46,420
most companies there
tend to use a solution

181
00:07:46,420 --> 00:07:48,230
that they purchase, such as Jamf Pro

182
00:07:48,230 --> 00:07:50,900
which is really the most
common that I've encountered,

183
00:07:50,900 --> 00:07:53,050
but I also notice products,

184
00:07:53,050 --> 00:07:55,640
other products that are
up and coming like Kandji,

185
00:07:55,640 --> 00:07:57,780
and so we're gonna take a look at those.

186
00:07:57,780 --> 00:08:00,440
I also wanted to point out
Calum Hall and Luke Roberts

187
00:08:00,440 --> 00:08:02,840
and their Black Hat talk this year,

188
00:08:02,840 --> 00:08:06,450
did a really good talk on abusing
Jamf for remote management

189
00:08:06,450 --> 00:08:08,950
and how an attacker can
leverage that to control

190
00:08:08,950 --> 00:08:12,410
and compromise managed Macs
in an enterprise environment,

191
00:08:12,410 --> 00:08:14,783
so highly recommend checking that out.

192
00:08:16,340 --> 00:08:18,250
So here's a very high-level overview

193
00:08:18,250 --> 00:08:20,660
of common Jamf deployments
that you may see.

194
00:08:20,660 --> 00:08:23,270
You have, typically have an admin server.

195
00:08:23,270 --> 00:08:25,310
If you're in an
environment that uses Jamf,

196
00:08:25,310 --> 00:08:28,070
you can run Jamf, check JSS
connection from Terminal

197
00:08:28,070 --> 00:08:32,170
and that will return the URL
to your Jamf admin server.

198
00:08:32,170 --> 00:08:33,590
You also have your endpoints,

199
00:08:33,590 --> 00:08:35,540
which have the Jamf agent on them

200
00:08:35,540 --> 00:08:38,730
that receives the configuration
for the admin server.

201
00:08:38,730 --> 00:08:41,350
You also have self-service
that runs on the endpoints,

202
00:08:41,350 --> 00:08:44,610
and allows users to
install software versions

203
00:08:44,610 --> 00:08:47,400
that their IT department
has already vetted,

204
00:08:47,400 --> 00:08:49,560
so essentially they don't have
to open tickets for these,

205
00:08:49,560 --> 00:08:51,880
they can just install
them from self-service.

206
00:08:51,880 --> 00:08:53,933
Really nifty way of doing things.

207
00:08:54,890 --> 00:08:57,100
Also, Jamf does include the ability

208
00:08:57,100 --> 00:08:58,680
to have remote management,

209
00:08:58,680 --> 00:09:02,450
where admins can remote
in to do screen sharing

210
00:09:02,450 --> 00:09:05,250
or other troubleshooting on the endpoints,

211
00:09:05,250 --> 00:09:08,990
and typically that is
through an admin account

212
00:09:08,990 --> 00:09:12,210
that has SSH access into the endpoints.

213
00:09:12,210 --> 00:09:13,990
Often times from what I've seen

214
00:09:13,990 --> 00:09:15,960
in enterprise macOS environments,

215
00:09:15,960 --> 00:09:18,940
SSH is enabled on the endpoints,

216
00:09:18,940 --> 00:09:23,197
and the IT team will use
an account that can SSH in

217
00:09:23,197 --> 00:09:26,430
and it has pseudo-rights on the macOS host

218
00:09:26,430 --> 00:09:27,900
where they can perform administration,

219
00:09:27,900 --> 00:09:29,060
so that's a very common thing

220
00:09:29,060 --> 00:09:31,810
that I've seen in
environments, and of course,

221
00:09:31,810 --> 00:09:33,568
one thing to be aware of

222
00:09:33,568 --> 00:09:38,180
is if that is how your
environment is set up,

223
00:09:38,180 --> 00:09:40,350
because very similar to the problem

224
00:09:40,350 --> 00:09:43,670
on a Windows side years
ago about dealing with SMB

225
00:09:43,670 --> 00:09:46,090
and local admin passwords

226
00:09:46,090 --> 00:09:48,640
and LAPS coming out being a solution

227
00:09:48,640 --> 00:09:50,270
to randomize those passwords,

228
00:09:50,270 --> 00:09:51,870
well the same thing would apply here

229
00:09:51,870 --> 00:09:54,100
if remote management's being used,

230
00:09:54,100 --> 00:09:56,680
is it a static password

231
00:09:56,680 --> 00:09:58,630
or is there random passwords being used,

232
00:09:58,630 --> 00:10:00,670
and of course if it's static password,

233
00:10:00,670 --> 00:10:02,710
then that means if you get that password,

234
00:10:02,710 --> 00:10:06,600
you can now access any Mac
in the environment over SSH

235
00:10:06,600 --> 00:10:10,150
with pseudo-rights, and the
SSH has full disk access,

236
00:10:10,150 --> 00:10:12,660
so it bypasses privacy protection,

237
00:10:12,660 --> 00:10:14,400
so that could be really
bad for the environment,

238
00:10:14,400 --> 00:10:16,350
so just something to think about there.

239
00:10:17,550 --> 00:10:21,850
Another thing, another aspect
to look at here is if you run,

240
00:10:21,850 --> 00:10:24,130
as a red teamer you
run a phishing exercise

241
00:10:24,130 --> 00:10:26,650
and you target Jamf admins,

242
00:10:26,650 --> 00:10:29,050
which is usually a Active Directory group

243
00:10:29,050 --> 00:10:32,570
in your environment that
limited people have access to

244
00:10:32,570 --> 00:10:36,220
that that organization has
identified to administer Jamf,

245
00:10:36,220 --> 00:10:37,540
and you phish them,

246
00:10:37,540 --> 00:10:40,620
you gain access to their
Active Directory credentials,

247
00:10:40,620 --> 00:10:42,750
and then you use those credentials

248
00:10:42,750 --> 00:10:46,520
to log into the Jamf management
server, Jamf admin server,

249
00:10:46,520 --> 00:10:48,187
and depending on the environment,

250
00:10:48,187 --> 00:10:50,820
that admin server may be behind Okta

251
00:10:50,820 --> 00:10:53,430
where 2FA push is required, or it may not,

252
00:10:53,430 --> 00:10:57,300
may just be locally in the
environment without 2FA,

253
00:10:57,300 --> 00:10:59,170
and you can get access that way,

254
00:10:59,170 --> 00:11:02,050
and then from there you
can start to push policies

255
00:11:02,050 --> 00:11:05,220
and scripts to run on the
endpoints, and really,

256
00:11:05,220 --> 00:11:08,320
there you almost, you
essentially do have full control

257
00:11:08,320 --> 00:11:10,600
over your macOS environment,
so this is something,

258
00:11:10,600 --> 00:11:12,750
an attack path to think about as well

259
00:11:12,750 --> 00:11:14,900
if you're in an enterprise
Mac environment.

260
00:11:16,280 --> 00:11:18,660
But now, even when it comes to Jamf,

261
00:11:18,660 --> 00:11:22,653
there's really so many different
ways to implement Jamf,

262
00:11:22,653 --> 00:11:25,180
there's really no one way to do it,

263
00:11:25,180 --> 00:11:27,010
so we're just gonna
look at a few examples.

264
00:11:27,010 --> 00:11:28,870
First example is probably the simplest

265
00:11:28,870 --> 00:11:33,110
where macOS hosts are
bound directly to AD,

266
00:11:33,110 --> 00:11:35,980
and in that case, you
can run different DSCL

267
00:11:35,980 --> 00:11:39,870
or LDAP search commands to
pull AD information directly

268
00:11:39,870 --> 00:11:41,410
from the domain controllers,

269
00:11:41,410 --> 00:11:43,670
just as you can on the Windows side,

270
00:11:43,670 --> 00:11:47,180
like for example with net
user commands like that.

271
00:11:47,180 --> 00:11:51,180
You can do the same here,
and tools such as MacHound,

272
00:11:51,180 --> 00:11:54,220
which is a macOS port of Bloodhound,

273
00:11:54,220 --> 00:11:58,050
or Cody Thomas's Bifrost which
does Kerberos manipulation,

274
00:11:58,050 --> 00:11:59,720
those tools would work and apply

275
00:11:59,720 --> 00:12:01,540
in this environment since the host,

276
00:12:01,540 --> 00:12:04,680
the macOS hosts are bound
directly to Active Directory

277
00:12:04,680 --> 00:12:06,123
and can query it directly.

278
00:12:07,420 --> 00:12:11,630
Another example is via, access
via a tool called NoMAD,

279
00:12:11,630 --> 00:12:15,010
where in this case, macOS
hosts are not bound directly

280
00:12:15,010 --> 00:12:17,750
to AD, so if you try to
query Active Directory

281
00:12:17,750 --> 00:12:18,650
from these hosts,

282
00:12:18,650 --> 00:12:21,170
you won't be able to reach
it directly that way,

283
00:12:21,170 --> 00:12:23,370
and essentially the user logs in locally

284
00:12:23,370 --> 00:12:26,520
with a local account and then
they do network authentication

285
00:12:26,520 --> 00:12:30,800
for access to resources,
which is where NoMAD comes in,

286
00:12:30,800 --> 00:12:34,530
and that, NoMAD then performs
Kerberos authentication

287
00:12:34,530 --> 00:12:37,279
on our behalf, and so, and this,

288
00:12:37,279 --> 00:12:39,773
if this setup is how your
environment is configured,

289
00:12:39,773 --> 00:12:42,080
then there are files
that you can read from

290
00:12:42,080 --> 00:12:44,770
that you might find
interesting on an assessment,

291
00:12:44,770 --> 00:12:47,770
such as different plists
that I have mentioned here.

292
00:12:47,770 --> 00:12:52,420
Also things like klist, KCC,
Cody Thomas's Bifrost tool

293
00:12:52,420 --> 00:12:54,740
that does Kerberos manipulation,

294
00:12:54,740 --> 00:12:56,310
those tools would still work,

295
00:12:56,310 --> 00:12:58,760
since Kerberos is still
happening from your endpoint,

296
00:12:58,760 --> 00:13:00,460
so something to think about there.

297
00:13:01,790 --> 00:13:05,210
Another example, same
setup or similar setup here

298
00:13:05,210 --> 00:13:08,550
where your macOS endpoints
do not have direct access

299
00:13:08,550 --> 00:13:12,000
to Active Directory to query
domain controllers directly.

300
00:13:12,000 --> 00:13:15,120
In this case they have
Jamf Connect on them,

301
00:13:15,120 --> 00:13:16,700
and Jamf Connect is synced through Okta,

302
00:13:16,700 --> 00:13:20,510
and Okta does the syncing
with Active Directory

303
00:13:20,510 --> 00:13:22,370
when it comes to authentication.

304
00:13:22,370 --> 00:13:25,100
And so a federated model there.

305
00:13:25,100 --> 00:13:27,900
And what's interesting here
is, just in this example,

306
00:13:27,900 --> 00:13:30,610
the Active Directory controllers are,

307
00:13:30,610 --> 00:13:33,810
domain controllers are
walled off by firewall rules

308
00:13:33,810 --> 00:13:37,690
or VPN access, maybe a specific
VPN profile that you need,

309
00:13:37,690 --> 00:13:41,210
so again, if you try to query
directly, this would not work,

310
00:13:41,210 --> 00:13:44,100
but if this were how your
environment's set up,

311
00:13:44,100 --> 00:13:45,900
there still are some interesting plists

312
00:13:45,900 --> 00:13:48,530
and files on the system
that you could pull from

313
00:13:48,530 --> 00:13:50,690
to learn more about the
host and the environment

314
00:13:50,690 --> 00:13:52,810
that you're in, such as what's your,

315
00:13:52,810 --> 00:13:54,783
the two files highlighted above.

316
00:13:56,830 --> 00:13:59,550
So as I mentioned, AD is still present

317
00:13:59,550 --> 00:14:00,820
in macOS environments,

318
00:14:00,820 --> 00:14:02,570
but it just looks a little bit different

319
00:14:02,570 --> 00:14:05,800
from what you see in your
enterprise Windows environments,

320
00:14:05,800 --> 00:14:08,360
and I enjoy it because it
gives me a chance to focus

321
00:14:08,360 --> 00:14:10,920
on something else outside
of Active Directory.

322
00:14:10,920 --> 00:14:13,870
And of course when you're in
these types of environments,

323
00:14:13,870 --> 00:14:16,600
they're heavy Mac and
cloud implementations,

324
00:14:16,600 --> 00:14:18,870
so a lot of interesting things to look at,

325
00:14:18,870 --> 00:14:21,140
so let's talk about that.

326
00:14:21,140 --> 00:14:23,610
First thing we talk about, initial access,

327
00:14:23,610 --> 00:14:27,730
in this case targeting our
identity as a service portal,

328
00:14:27,730 --> 00:14:31,240
so the two most common
are Okta and OneLogin.

329
00:14:31,240 --> 00:14:35,140
A tool that is pretty
popular here is Evilginx 2

330
00:14:35,140 --> 00:14:37,990
by Kuba Gretzky, and what
it does is you point it

331
00:14:37,990 --> 00:14:42,080
to a target login portal,
it clones that portal,

332
00:14:42,080 --> 00:14:43,970
and as, and you basically send out a link

333
00:14:43,970 --> 00:14:47,410
to the fake portal, and as
people log into the fake Okta

334
00:14:47,410 --> 00:14:51,350
or fake OneLogin portal, it
captures the username, password,

335
00:14:51,350 --> 00:14:53,880
and it authenticates
it to the actual site,

336
00:14:53,880 --> 00:14:56,200
and does the same thing
for your 2FA token.

337
00:14:56,200 --> 00:15:00,270
So then the attacker's able
to grab the token for Okta

338
00:15:00,270 --> 00:15:02,500
or for OneLogin, import it

339
00:15:02,500 --> 00:15:05,550
into their browser using a
plugin like EditThisCookie,

340
00:15:05,550 --> 00:15:07,450
and now you're the compromised user.

341
00:15:07,450 --> 00:15:10,380
And what's so interesting
about this attack path is,

342
00:15:10,380 --> 00:15:12,900
once you're inside of someone's identity

343
00:15:12,900 --> 00:15:15,230
as a service portal,
you have access to a ton

344
00:15:15,230 --> 00:15:17,680
of different productivity
apps, so you got Slack,

345
00:15:17,680 --> 00:15:22,340
think about the credentials,
configuration files, secrets,

346
00:15:22,340 --> 00:15:24,270
things that people have shared in Slack

347
00:15:24,270 --> 00:15:26,320
that may be pinned in different channels,

348
00:15:26,320 --> 00:15:29,210
think about Gmail or Google Drive,

349
00:15:29,210 --> 00:15:31,140
people may email themselves passwords

350
00:15:31,140 --> 00:15:34,970
so they don't forget or
sensitive information,

351
00:15:34,970 --> 00:15:36,640
you have access to search all of that.

352
00:15:36,640 --> 00:15:40,730
Imagine, your Confluence,
your Jira tickets,

353
00:15:40,730 --> 00:15:43,760
things that may have
interesting data there or Wiki,

354
00:15:43,760 --> 00:15:47,040
all sorts of juicy information
there, and as a red teamer,

355
00:15:47,040 --> 00:15:48,630
you may opt to take this path

356
00:15:48,630 --> 00:15:50,210
and essentially meet your objectives

357
00:15:50,210 --> 00:15:53,120
without ever even needing to land access

358
00:15:53,120 --> 00:15:55,280
on a macOS endpoint.

359
00:15:55,280 --> 00:15:57,660
So this is definitely worth
running in your environment

360
00:15:57,660 --> 00:16:00,740
from both a red and a
blue team perspective,

361
00:16:00,740 --> 00:16:02,750
and one of the big wins for,

362
00:16:02,750 --> 00:16:05,160
from the blue team side is allowing,

363
00:16:05,160 --> 00:16:06,850
basically running through
your procedures to see

364
00:16:06,850 --> 00:16:10,280
if you have visibility into
this attack path, and if you do,

365
00:16:10,280 --> 00:16:13,960
do you have the ability to
revoke compromised tokens,

366
00:16:13,960 --> 00:16:16,780
because in this case,
password resets are great,

367
00:16:16,780 --> 00:16:19,470
but if you don't revoke
the compromised token,

368
00:16:19,470 --> 00:16:21,140
you're not gonna be able
to boot out the attacker,

369
00:16:21,140 --> 00:16:24,500
so a good way to test your detection

370
00:16:24,500 --> 00:16:25,913
and response procedures.

371
00:16:27,500 --> 00:16:30,130
So I mentioned a lot of interesting data

372
00:16:30,130 --> 00:16:32,170
in your productivity portals,

373
00:16:32,170 --> 00:16:34,090
and there're some tools
that people have written

374
00:16:34,090 --> 00:16:36,250
to actually automate
this if you're using this

375
00:16:36,250 --> 00:16:38,910
from a red team attack perspective,

376
00:16:38,910 --> 00:16:41,870
one being a colleague
of mine, Antonio Piazza,

377
00:16:41,870 --> 00:16:45,832
he wrote a few different,
what I call thief tools of GD,

378
00:16:45,832 --> 00:16:48,910
GDir, and Conf-Thief to simulate

379
00:16:48,910 --> 00:16:51,100
or speed up downloading sensitive files

380
00:16:51,100 --> 00:16:52,320
from those platforms.

381
00:16:52,320 --> 00:16:53,410
Also a colleague of mind,

382
00:16:53,410 --> 00:16:55,900
Brad Richardson over at
Credit Karma wrote a tool

383
00:16:55,900 --> 00:16:58,490
called Slackhound that
does a similar thing,

384
00:16:58,490 --> 00:17:01,500
if you find a Slack token
on a host, you just feed in

385
00:17:01,500 --> 00:17:04,350
and it uses API calls
and things of that nature

386
00:17:04,350 --> 00:17:06,960
to pull down data, as well as SlackPirate,

387
00:17:06,960 --> 00:17:09,850
so a lot of different and
interesting attack paths

388
00:17:09,850 --> 00:17:10,753
on this vector.

389
00:17:12,630 --> 00:17:15,140
So now, we talked about
identity as a service briefly,

390
00:17:15,140 --> 00:17:17,900
I'm gonna pivot over to the
macOS side of the house,

391
00:17:17,900 --> 00:17:20,560
and talk about some of
the basics around macOS

392
00:17:20,560 --> 00:17:22,360
from a security perspective.

393
00:17:22,360 --> 00:17:25,180
I like to break it into three
different areas, prevention,

394
00:17:25,180 --> 00:17:26,970
detection, and removal.

395
00:17:26,970 --> 00:17:29,200
Gatekeeper, on the prevention side,

396
00:17:29,200 --> 00:17:33,230
is essentially the engine that, or the,

397
00:17:33,230 --> 00:17:34,720
I guess you'd say the service with,

398
00:17:34,720 --> 00:17:37,580
since Policy D is behind it as the engine,

399
00:17:37,580 --> 00:17:40,760
it evaluates certain file
types like application bundles,

400
00:17:40,760 --> 00:17:43,300
installer packages, Mach-Os, et cetera.

401
00:17:43,300 --> 00:17:44,980
It looks for files

402
00:17:44,980 --> 00:17:49,020
that have a com.apple.quarantine
attribute appended to them,

403
00:17:49,020 --> 00:17:52,700
which the operating system
appends for any files downloaded

404
00:17:52,700 --> 00:17:57,700
from the internet, so if
a file is of the types

405
00:17:57,810 --> 00:18:00,890
that Gatekeeper evaluates,
such as Mach-Os, apps,

406
00:18:00,890 --> 00:18:02,570
installer packages, et cetera,

407
00:18:02,570 --> 00:18:04,490
and it has that quarantine attribute,

408
00:18:04,490 --> 00:18:06,470
then Gatekeeper enforcement kicks in.

409
00:18:06,470 --> 00:18:09,830
It checks to see if it's
signed and if it's notarized,

410
00:18:09,830 --> 00:18:12,330
and if it's not, it will
block it from running.

411
00:18:12,330 --> 00:18:14,410
If it does, it still does a popup,

412
00:18:14,410 --> 00:18:18,220
but what's of interest here
is that even for a non-signed,

413
00:18:18,220 --> 00:18:20,270
non-notarized, like app packages,

414
00:18:20,270 --> 00:18:22,500
installers, Mach-O binaries, et cetera,

415
00:18:22,500 --> 00:18:25,020
they usually can still right-click open

416
00:18:25,020 --> 00:18:27,410
and click through one other prompt

417
00:18:27,410 --> 00:18:30,180
to run it despite Gatekeeper.

418
00:18:30,180 --> 00:18:33,030
On the detection side, you have XProtect,

419
00:18:33,030 --> 00:18:34,680
which is also a part of Gatekeeper

420
00:18:34,680 --> 00:18:37,490
and it's really more of
the malware definitions

421
00:18:37,490 --> 00:18:40,430
and blacklisting that I
guess you could say comes

422
00:18:40,430 --> 00:18:44,810
from Apple intel, from
real-world malware resources,

423
00:18:44,810 --> 00:18:47,570
or malware sources that
they have analyzed,

424
00:18:47,570 --> 00:18:49,640
and then you have the
malware removal tool,

425
00:18:49,640 --> 00:18:52,540
MRT.app that does the remediation.

426
00:18:52,540 --> 00:18:54,140
From a red team perspective,

427
00:18:54,140 --> 00:18:58,290
the prevention side of it
really is the hardest hurdle

428
00:18:58,290 --> 00:18:59,400
to overcome.

429
00:18:59,400 --> 00:19:02,810
XProtect and MRT.app usually are not much,

430
00:19:02,810 --> 00:19:04,570
usually not big factors for red teamers

431
00:19:04,570 --> 00:19:07,910
because we tend to write
our own stuff for macOS,

432
00:19:07,910 --> 00:19:11,390
since it's kind of a niche
space, and since XProtect

433
00:19:11,390 --> 00:19:14,840
and MRT.app tend to
look at existing samples

434
00:19:14,840 --> 00:19:17,770
for their intel, usually when
you write in your own stuff,

435
00:19:17,770 --> 00:19:20,630
those two aspects become less of a factor,

436
00:19:20,630 --> 00:19:23,560
it's just really Gatekeeper
that becomes the pain

437
00:19:23,560 --> 00:19:25,610
and headache from a red team perspective.

438
00:19:27,130 --> 00:19:30,090
Other things to think
about is the concept of TCC

439
00:19:30,090 --> 00:19:32,290
or privacy protections, so, and that,

440
00:19:32,290 --> 00:19:34,280
essentially you have certain folders

441
00:19:34,280 --> 00:19:37,490
or certain places on
disk that TCC protects,

442
00:19:37,490 --> 00:19:40,170
so you have things like the
user's desktop, documents,

443
00:19:40,170 --> 00:19:43,310
downloads, all sorts of
other places on the system

444
00:19:43,310 --> 00:19:45,120
that TCC protects.

445
00:19:45,120 --> 00:19:48,490
What's of interest though are
things that are not protected,

446
00:19:48,490 --> 00:19:53,030
so the home directory itself,
and within the home directory,

447
00:19:53,030 --> 00:19:56,233
certain other subdirectories
like a .ssh or .aws directory.

448
00:19:57,710 --> 00:20:01,270
Both of those would contain
credentials, and the ability,

449
00:20:01,270 --> 00:20:04,300
if they're captured, to
provide lateral movement,

450
00:20:04,300 --> 00:20:06,660
a temp directory is also not protected,

451
00:20:06,660 --> 00:20:09,390
which is why malware
typically is dropped there,

452
00:20:09,390 --> 00:20:11,250
so just something to
think about because again,

453
00:20:11,250 --> 00:20:14,340
if TCC is enforced, a popup
will show up to the user

454
00:20:14,340 --> 00:20:17,970
where they can allow or deny
if that directory's requested,

455
00:20:17,970 --> 00:20:20,200
but for not protected folders,

456
00:20:20,200 --> 00:20:22,060
there's no notification to the user

457
00:20:22,060 --> 00:20:24,550
and access is not prevented at all by TCC

458
00:20:24,550 --> 00:20:26,900
if it's not protected by TCC.

459
00:20:26,900 --> 00:20:28,120
TheEvilBit and Reggi

460
00:20:28,120 --> 00:20:30,610
did an excellent Black Hat talk this year

461
00:20:30,610 --> 00:20:33,310
on 20 different ways to bypass TCC,

462
00:20:33,310 --> 00:20:34,650
so definitely check that out.

463
00:20:34,650 --> 00:20:38,330
They'll dig way more into what TCC is

464
00:20:38,330 --> 00:20:41,083
and different methods for
bypassing, so check that out.

465
00:20:42,930 --> 00:20:45,170
From an initial access perspective on Mac,

466
00:20:45,170 --> 00:20:46,857
a lot of different options here

467
00:20:46,857 --> 00:20:49,750
and they all have different pros and cons.

468
00:20:49,750 --> 00:20:51,210
You have your Mach-O binaries,

469
00:20:51,210 --> 00:20:52,630
which are checked by Gatekeeper,

470
00:20:52,630 --> 00:20:54,930
but you typically need a delivery method,

471
00:20:54,930 --> 00:20:56,450
because most of the time your Mach-Os

472
00:20:56,450 --> 00:20:58,220
are not gonna be double-click friendly.

473
00:20:58,220 --> 00:20:59,670
I mean there are some tricks you can do,

474
00:20:59,670 --> 00:21:01,180
but just generally speaking,

475
00:21:01,180 --> 00:21:04,705
you'll use your Mach-O as
a second stage payload.

476
00:21:04,705 --> 00:21:06,400
Apps are checked by Gatekeeper.

477
00:21:06,400 --> 00:21:08,040
They're pretty
remote-friendly, because again,

478
00:21:08,040 --> 00:21:11,000
they're app packages and
they're double-clicked usually,

479
00:21:11,000 --> 00:21:12,600
and so they are remote-friendly,

480
00:21:12,600 --> 00:21:14,050
but they are checked by Gatekeeper.

481
00:21:14,050 --> 00:21:17,390
Installer packages are also
checked and remote-friendly.

482
00:21:17,390 --> 00:21:18,780
They allow a user to double-click.

483
00:21:18,780 --> 00:21:22,450
You got weaponized PDFs,
shell script trickeration

484
00:21:22,450 --> 00:21:24,020
which we'll talk about later.

485
00:21:24,020 --> 00:21:25,790
Essentially that is a bug that I found

486
00:21:25,790 --> 00:21:28,970
in Gatekeeper this year
and reported to Apple

487
00:21:28,970 --> 00:21:31,090
and worked with them to get it fixed.

488
00:21:31,090 --> 00:21:32,790
You also have your scripting languages

489
00:21:32,790 --> 00:21:35,010
that are not checked by Gatekeeper,

490
00:21:35,010 --> 00:21:38,420
things such as JXA which is
JavaScript for automation.

491
00:21:38,420 --> 00:21:41,140
Cody Thomas did an excellent
job a couple years back

492
00:21:41,140 --> 00:21:44,430
of highlighting how powerful JXA is on Mac

493
00:21:44,430 --> 00:21:48,373
and how it's essentially like
an AppleScript alternative,

494
00:21:49,370 --> 00:21:51,310
and some, it's kinda interesting

495
00:21:51,310 --> 00:21:54,890
because sometimes I'll
view JXA as the replacement

496
00:21:54,890 --> 00:21:56,760
for AppleScript, but
they're both still around

497
00:21:56,760 --> 00:21:59,300
and they'll probably both
be around for a while.

498
00:21:59,300 --> 00:22:03,150
Of course Python is not
checked by Gatekeeper, however,

499
00:22:03,150 --> 00:22:07,720
Mac or Apple will remove
Python from base macOS installs

500
00:22:07,720 --> 00:22:09,010
at some point in the future.

501
00:22:09,010 --> 00:22:11,760
Don't know when, but from
an attacker's perspective,

502
00:22:11,760 --> 00:22:13,020
it's just something to keep in mind

503
00:22:13,020 --> 00:22:15,560
if you're heavily relying on Python.

504
00:22:15,560 --> 00:22:17,720
Office macros are not
checked by Gatekeeper,

505
00:22:17,720 --> 00:22:21,480
but it is sandbox, meaning it will be,

506
00:22:21,480 --> 00:22:24,110
if you gain access
remotely via Office macro,

507
00:22:24,110 --> 00:22:26,510
you'll only have access to
certain parts of the disk

508
00:22:26,510 --> 00:22:28,540
and certain binaries, et cetera,

509
00:22:28,540 --> 00:22:30,760
so a lot of different options here.

510
00:22:30,760 --> 00:22:33,990
Got AppleScript browser extensions.

511
00:22:33,990 --> 00:22:38,167
One thing I wanted to point
out was that on macOS,

512
00:22:38,167 --> 00:22:40,980
D00MFist Leo Pitt wrote a
really neat tool called Mystical

513
00:22:40,980 --> 00:22:43,343
that is a payload generator for several

514
00:22:43,343 --> 00:22:45,640
of these types of payloads
where you can provide

515
00:22:45,640 --> 00:22:48,513
in information that will
generate the payload for you.

516
00:22:48,513 --> 00:22:51,290
I also wanted to point
out Mythic by Cody Thomas

517
00:22:51,290 --> 00:22:54,070
at SpecterOps, is what
I consider at this stage

518
00:22:54,070 --> 00:22:56,470
to be the king of macOS
command and control

519
00:22:56,470 --> 00:22:59,050
because of its innovative use of JXA

520
00:22:59,050 --> 00:23:03,000
and has a lot of other cool
features with how it's built

521
00:23:03,000 --> 00:23:05,210
and how it's managed, so
definitely check that out

522
00:23:05,210 --> 00:23:06,813
from a red and blue perspective.

523
00:23:08,550 --> 00:23:10,127
Quickly gonna jump into
some different examples,

524
00:23:10,127 --> 00:23:12,710
so the first example
being installer packages,

525
00:23:12,710 --> 00:23:14,900
and I'm gonna briefly
talk about script only,

526
00:23:14,900 --> 00:23:16,290
because they're the most common

527
00:23:16,290 --> 00:23:18,460
and pretty simple example here,

528
00:23:18,460 --> 00:23:21,860
but you have a pre-install
and a post-install script,

529
00:23:21,860 --> 00:23:25,290
and both require the shebang
at the top and exit at the end

530
00:23:25,290 --> 00:23:27,600
in order to run successfully.

531
00:23:27,600 --> 00:23:30,530
They run as child processes
of the installer packages,

532
00:23:30,530 --> 00:23:33,500
so whatever scripts you have running,

533
00:23:33,500 --> 00:23:37,330
and it runs elevates as root
from an attacker's perspective,

534
00:23:37,330 --> 00:23:40,390
which is a nice plus because
any installer package

535
00:23:40,390 --> 00:23:43,380
that a user detonates and, to install,

536
00:23:43,380 --> 00:23:44,640
they end up authenticating,

537
00:23:44,640 --> 00:23:46,630
and usually in macOS environments,

538
00:23:46,630 --> 00:23:50,280
the user is the local admin,
so when they authenticate,

539
00:23:50,280 --> 00:23:54,133
that installs with elevated
or root access on a host.

540
00:23:55,710 --> 00:23:57,180
As I mentioned before, this check,

541
00:23:57,180 --> 00:23:59,030
installer packages are
checked by Gatekeeper,

542
00:23:59,030 --> 00:24:01,150
but they can right-click and open,

543
00:24:01,150 --> 00:24:04,370
and that's a common technique
that's used in the wild

544
00:24:04,370 --> 00:24:06,260
with real-world malware samples,

545
00:24:06,260 --> 00:24:07,670
so Patrick Wardle

546
00:24:07,670 --> 00:24:10,780
and Objective-See have
a lot of good examples

547
00:24:10,780 --> 00:24:13,570
of real-world malware samples for macOS,

548
00:24:13,570 --> 00:24:17,370
so you can look through
their Mac malware reports

549
00:24:17,370 --> 00:24:20,240
of 2020 and 2019, et cetera,

550
00:24:20,240 --> 00:24:23,370
and look for different
examples for how these types

551
00:24:23,370 --> 00:24:26,000
of things done, like an image is included

552
00:24:26,000 --> 00:24:28,880
and the user's instructed to
right-click and press open

553
00:24:28,880 --> 00:24:31,100
in order to run a non-signed,

554
00:24:31,100 --> 00:24:33,233
non-notarized installer package.

555
00:24:34,680 --> 00:24:37,160
Here's an example of pre-install script,

556
00:24:37,160 --> 00:24:39,070
so we talked about
pre-install and post-install.

557
00:24:39,070 --> 00:24:41,057
This is an example on
the pre-install side,

558
00:24:41,057 --> 00:24:44,870
and it essentially just
pulls down a unsigned,

559
00:24:44,870 --> 00:24:46,950
non-notarized Mach-O binary,

560
00:24:46,950 --> 00:24:49,940
writes it to the temp folder
and sets the executable bit.

561
00:24:49,940 --> 00:24:52,150
On the bottom is a example of,

562
00:24:52,150 --> 00:24:53,870
with us being remote these days

563
00:24:53,870 --> 00:24:56,140
and so many employees being from home,

564
00:24:56,140 --> 00:24:59,080
this is an example of how you
could add a guardrail in there

565
00:24:59,080 --> 00:25:00,930
to check for the host name to ensure

566
00:25:00,930 --> 00:25:03,070
that it's not running on
someone's personal machine

567
00:25:03,070 --> 00:25:04,670
but on a corporate machine.

568
00:25:04,670 --> 00:25:06,780
If it's found to be running
on a personal machine,

569
00:25:06,780 --> 00:25:10,010
it will exit, if not, then
it will perform the pull down

570
00:25:10,010 --> 00:25:12,233
of the payload and set the executable bit.

571
00:25:13,500 --> 00:25:15,320
And here's an example of
a post-install script,

572
00:25:15,320 --> 00:25:19,563
where it just runs the
Mach-O binary backgrounded.

573
00:25:21,470 --> 00:25:22,660
So once you have that set up,

574
00:25:22,660 --> 00:25:25,280
you can just run this
package build command here

575
00:25:25,280 --> 00:25:28,700
to generate the package,
host it, get it to the user,

576
00:25:28,700 --> 00:25:30,620
they detonate it, they
authenticate, right,

577
00:25:30,620 --> 00:25:32,320
or basically double-click and authenticate

578
00:25:32,320 --> 00:25:34,950
through the installation, and it detonates

579
00:25:34,950 --> 00:25:37,090
in the background, and as you
can see at the bottom here,

580
00:25:37,090 --> 00:25:41,080
this is my Mythic, I
screenshotted my Mythic C2 server,

581
00:25:41,080 --> 00:25:44,973
and the payload detonated
as root level access.

582
00:25:46,720 --> 00:25:48,760
Another example, you have app bundles

583
00:25:48,760 --> 00:25:52,100
or app packages where you have the app,

584
00:25:52,100 --> 00:25:56,570
the name of it with content/macOS
and then a Mach-O binary

585
00:25:56,570 --> 00:26:00,010
at the bottom, and so to
do this, a very simple way,

586
00:26:00,010 --> 00:26:02,840
you could go into Xcode,
create a new project,

587
00:26:02,840 --> 00:26:05,460
in my example I'm using Swift here,

588
00:26:05,460 --> 00:26:08,610
and then you would design a
window with buttons, icons,

589
00:26:08,610 --> 00:26:11,310
text, et cetera, for a
user to interact with.

590
00:26:11,310 --> 00:26:13,900
Once you have that
designed and ready to go,

591
00:26:13,900 --> 00:26:17,610
you go into info.plist for
any app transport security,

592
00:26:17,610 --> 00:26:21,150
so app transport security
are restrictions on Apple

593
00:26:21,150 --> 00:26:23,610
to limit the types of outbound connections

594
00:26:23,610 --> 00:26:26,290
that app packages can make, so
if you're trying to talk out

595
00:26:26,290 --> 00:26:31,290
to a non-HTTPS server, so just plain HTTP,

596
00:26:31,950 --> 00:26:34,660
it's certain entries you have
to put in there to allow that,

597
00:26:34,660 --> 00:26:36,900
and even if you're
talking to an SSL server,

598
00:26:36,900 --> 00:26:38,930
it does not like self-signed certificates,

599
00:26:38,930 --> 00:26:41,020
so you actually have to get
a valid signed certificate

600
00:26:41,020 --> 00:26:42,666
for that to work.

601
00:26:42,666 --> 00:26:45,200
And then of course you set
your sandbox accordingly,

602
00:26:45,200 --> 00:26:46,850
or the settings there that you need,

603
00:26:46,850 --> 00:26:48,720
and then you can add code like here below

604
00:26:48,720 --> 00:26:51,970
that uses a dispatcher,
and gain access Swift

605
00:26:51,970 --> 00:26:55,090
as a background task to
execute a JXA payload

606
00:26:55,090 --> 00:26:56,623
that's hosted on a server.

607
00:26:58,190 --> 00:27:01,100
And here's an example of the
window that you can design

608
00:27:01,100 --> 00:27:02,380
for the user to interact with,

609
00:27:02,380 --> 00:27:04,900
and as you can see it
can be very convincing.

610
00:27:04,900 --> 00:27:08,490
When the user clicks Update
now, then the Mythic command

611
00:27:08,490 --> 00:27:11,793
and control server receives
a callback from the user.

612
00:27:13,500 --> 00:27:16,530
So again, app packages
are checked by Gatekeeper,

613
00:27:16,530 --> 00:27:19,060
but as you can see here, as I mentioned,

614
00:27:19,060 --> 00:27:21,070
same with installer
packages, same with here,

615
00:27:21,070 --> 00:27:23,440
you can right-click and
open, so here's an example

616
00:27:23,440 --> 00:27:26,750
from a Shlayer which is a
common macOS malware family

617
00:27:26,750 --> 00:27:28,030
that's been around for a while,

618
00:27:28,030 --> 00:27:30,860
the simple image to
social engineer the user

619
00:27:30,860 --> 00:27:34,440
into right-clicking and
opening to run an unsigned,

620
00:27:34,440 --> 00:27:37,593
non-notarized app package.

621
00:27:39,160 --> 00:27:42,220
Of course you have
Microsoft Office macros.

622
00:27:42,220 --> 00:27:44,850
They still work, they've
been around for a while,

623
00:27:44,850 --> 00:27:48,010
and even today, when you,

624
00:27:48,010 --> 00:27:50,810
I like to do tests with macros
where I just will attach it

625
00:27:50,810 --> 00:27:55,810
and see, let the email system's
antivirus filter scan it

626
00:27:55,840 --> 00:27:58,150
and see if it detects it as malicious,

627
00:27:58,150 --> 00:27:59,100
and one thing I've noticed

628
00:27:59,100 --> 00:28:02,390
is that simple string
concatenation is usually enough

629
00:28:02,390 --> 00:28:03,790
to get it around those filters,

630
00:28:03,790 --> 00:28:06,050
so if you're taking the word exec

631
00:28:06,050 --> 00:28:08,780
and doing E plus X plus
E plus C for example,

632
00:28:08,780 --> 00:28:10,810
that will get around a lot of the filters.

633
00:28:10,810 --> 00:28:14,050
We'll look an example a
little bit later for that.

634
00:28:14,050 --> 00:28:16,440
No Gatekeeper concerns,
but as I mentioned earlier,

635
00:28:16,440 --> 00:28:19,860
it is sandbox, meaning you
have limited disk access

636
00:28:19,860 --> 00:28:23,350
and limited functions or binaries
that are available to you.

637
00:28:23,350 --> 00:28:27,160
You can still access things
such as osascript curl,

638
00:28:27,160 --> 00:28:30,640
screen capture, Python, so
still a lot of potential there,

639
00:28:30,640 --> 00:28:32,700
and Adam Chester who's currently

640
00:28:32,700 --> 00:28:36,170
at TrustedSec did a blog
post a couple years back

641
00:28:36,170 --> 00:28:39,630
where he looked at entitlements
that Office products had,

642
00:28:39,630 --> 00:28:41,860
and he found that they had one entitlement

643
00:28:41,860 --> 00:28:45,320
to drop files outside of the sandbox

644
00:28:45,320 --> 00:28:49,000
if the file name was prepended
with tilde dollar sign.

645
00:28:49,000 --> 00:28:50,220
So really good research,

646
00:28:50,220 --> 00:28:52,760
and that technique still
works where you can drop files

647
00:28:52,760 --> 00:28:57,070
on disk outside of the macOS
sandbox using that technique.

648
00:28:57,070 --> 00:28:59,230
A colleague of mine, Madhav Bhatt,

649
00:28:59,230 --> 00:29:01,280
who's also at Credit Karma,

650
00:29:01,280 --> 00:29:04,210
he recently published a sandbox escape,

651
00:29:04,210 --> 00:29:07,730
where essentially you create a zshenv file

652
00:29:07,730 --> 00:29:09,270
that executes a payload.

653
00:29:09,270 --> 00:29:11,050
You zip it, and for that zip file,

654
00:29:11,050 --> 00:29:14,300
you prepend the tilde
dollar sign in front of it,

655
00:29:14,300 --> 00:29:16,650
you drop it to the user's home directory,

656
00:29:16,650 --> 00:29:20,040
you add it as a login
item, and then on reboot,

657
00:29:20,040 --> 00:29:21,220
when the user restarts,

658
00:29:21,220 --> 00:29:23,920
the login item extracts the zip file,

659
00:29:23,920 --> 00:29:27,620
drops the zshenv file to
the user's home directory,

660
00:29:27,620 --> 00:29:29,750
and then when the user opens the Terminal,

661
00:29:29,750 --> 00:29:33,470
you have non-sandboxed
callback to your server.

662
00:29:33,470 --> 00:29:37,410
So definitely check it out,
a very informative blog post

663
00:29:37,410 --> 00:29:38,623
and does still work.

664
00:29:40,565 --> 00:29:43,976
An example, Office macro
generators for macOS,

665
00:29:43,976 --> 00:29:45,760
MacPhish has been around for a while,

666
00:29:45,760 --> 00:29:47,460
and honestly that's where I learned,

667
00:29:47,460 --> 00:29:51,220
I took a lot of my cues for
how to write macro generators

668
00:29:51,220 --> 00:29:52,638
from MacPhish.

669
00:29:52,638 --> 00:29:54,230
It's got a lot of cool options

670
00:29:54,230 --> 00:29:58,330
where you can generate
Office macros that use Python

671
00:29:58,330 --> 00:30:02,060
or curl or osascript or
combinations of them.

672
00:30:02,060 --> 00:30:04,950
I also wrote a couple
macro generators as well

673
00:30:04,950 --> 00:30:07,780
for Mythic that uses curl and osascript,

674
00:30:07,780 --> 00:30:11,290
and I did my own for
MacC2, which is a command

675
00:30:11,290 --> 00:30:14,340
and control tool that I wrote for macOS

676
00:30:14,340 --> 00:30:15,900
that leverages Python.

677
00:30:15,900 --> 00:30:18,240
I did highlight Python
in red, because again,

678
00:30:18,240 --> 00:30:23,050
Python will be eventually taken
off of base macOS installs,

679
00:30:23,050 --> 00:30:24,960
so just, I like to highlight it in red

680
00:30:24,960 --> 00:30:26,990
so you can be prepared when that happens,

681
00:30:26,990 --> 00:30:29,960
which is why things like switching

682
00:30:29,960 --> 00:30:31,930
to JXA for example is a good option

683
00:30:31,930 --> 00:30:34,380
because that will be around for a while.

684
00:30:34,380 --> 00:30:36,400
Also, when it comes to Office macros,

685
00:30:36,400 --> 00:30:40,330
AutoOpen subroutine is useful

686
00:30:40,330 --> 00:30:43,193
so that when the document
is double-clicked,

687
00:30:43,193 --> 00:30:46,810
the Office macro can be executed,

688
00:30:46,810 --> 00:30:48,080
and here's an example here

689
00:30:48,080 --> 00:30:51,820
of how I concatenated the
word Python and the word exec,

690
00:30:51,820 --> 00:30:55,620
and you see long strings
of base 64 characters,

691
00:30:55,620 --> 00:30:58,110
or I guess in this case
hex characters, excuse me,

692
00:30:58,110 --> 00:31:01,310
long strings of hex characters,
and what those do is,

693
00:31:01,310 --> 00:31:04,850
in this payload that I've
written, I basically read from a,

694
00:31:04,850 --> 00:31:07,610
I read the actual payload from a file,

695
00:31:07,610 --> 00:31:09,940
read it into a long hex string,

696
00:31:09,940 --> 00:31:11,670
and now it's just breaking that hex string

697
00:31:11,670 --> 00:31:12,953
into smaller chunks.

698
00:31:14,800 --> 00:31:18,780
So now I'm gonna quickly
talk about CVE-2021-30657.

699
00:31:18,780 --> 00:31:21,470
This was the bug I
reported to Apple this year

700
00:31:21,470 --> 00:31:24,780
that was Gatekeeper bypass
around the March timeframe,

701
00:31:24,780 --> 00:31:28,710
and kinda where the
idea for this came from

702
00:31:28,710 --> 00:31:30,150
was I started thinking about,

703
00:31:30,150 --> 00:31:33,590
well, here's the typical
structure of app bundles on macOS.

704
00:31:33,590 --> 00:31:37,220
You have the app name, you
have the contents directory,

705
00:31:37,220 --> 00:31:40,160
macOS directory, and then
there's a Mach-O inside of that,

706
00:31:40,160 --> 00:31:42,270
so when you double-click an app bundle,

707
00:31:42,270 --> 00:31:44,510
the Mach-O inside of it is what executes,

708
00:31:44,510 --> 00:31:46,590
and it just has all these
other wrappers around it

709
00:31:46,590 --> 00:31:49,690
like info.plist, et cetera,
so I started thinking,

710
00:31:49,690 --> 00:31:51,300
what if we put something else here,

711
00:31:51,300 --> 00:31:53,260
something that's not
checked by Gatekeeper,

712
00:31:53,260 --> 00:31:55,090
because Mach-Os are checked,

713
00:31:55,090 --> 00:31:57,800
which is why when you download
an app from the internet

714
00:31:57,800 --> 00:32:00,980
and try to execute it,
Gatekeeper will pop up,

715
00:32:00,980 --> 00:32:03,970
like if you just try to normally run it.

716
00:32:03,970 --> 00:32:05,860
But in this case, what if
we put something like Bash

717
00:32:05,860 --> 00:32:09,030
or Python in place of the
Mach-O binary since neither

718
00:32:09,030 --> 00:32:11,893
of those scripting languages
are checked by Gatekeeper?

719
00:32:12,870 --> 00:32:14,000
So I did that.

720
00:32:14,000 --> 00:32:16,250
That's kind of what led to the bug,

721
00:32:16,250 --> 00:32:19,510
I found that it worked and
it did bypass Gatekeeper,

722
00:32:19,510 --> 00:32:22,350
and I reported this to
Apple March, I believe,

723
00:32:22,350 --> 00:32:24,540
of this year and they
fixed it in short order

724
00:32:24,540 --> 00:32:28,500
in Big Sur 11.3 and in Catalina updates.

725
00:32:28,500 --> 00:32:31,670
From the Apple Security Bounty website,

726
00:32:31,670 --> 00:32:34,750
they have a section there for
user-installed applications

727
00:32:34,750 --> 00:32:36,143
and access to sensitive data.

728
00:32:36,143 --> 00:32:40,070
$100,000, all right,
really big bounty payment,

729
00:32:40,070 --> 00:32:41,270
but they have a very,

730
00:32:41,270 --> 00:32:45,360
you see the two asterisks
there next to that first line,

731
00:32:45,360 --> 00:32:46,370
I wanted to highlight that

732
00:32:46,370 --> 00:32:48,830
because Apple has a very narrow definition

733
00:32:48,830 --> 00:32:51,610
of what they consider sensitive
data, and in my opinion,

734
00:32:51,610 --> 00:32:55,580
it's much more a consumer
focus versus enterprise focus,

735
00:32:55,580 --> 00:32:59,340
because they only consider
contacts, mail, messages, notes,

736
00:32:59,340 --> 00:33:04,230
photos, or location data to
be sensitive information,

737
00:33:04,230 --> 00:33:08,120
which makes sense from an
individual consumer perspective,

738
00:33:08,120 --> 00:33:09,760
but when you're starting to look at Macs

739
00:33:09,760 --> 00:33:12,050
in an enterprise like what
we're talking about here,

740
00:33:12,050 --> 00:33:15,680
macOS environments where
organizations have thousands

741
00:33:15,680 --> 00:33:17,440
of users that are using Macs

742
00:33:17,440 --> 00:33:19,960
and they're doing development
and engineering work

743
00:33:19,960 --> 00:33:22,220
with sensitive data on the host,

744
00:33:22,220 --> 00:33:25,010
this definition certainly
should be expanded.

745
00:33:25,010 --> 00:33:29,080
And in my case, my app
detonated, got remote access,

746
00:33:29,080 --> 00:33:31,330
and then I was able to
access sensitive data,

747
00:33:31,330 --> 00:33:36,330
which is things like SSH keys,
AWS keys, Azure, GCP keys,

748
00:33:37,230 --> 00:33:39,750
other files in the user's home directory,

749
00:33:39,750 --> 00:33:41,560
the user's shell history

750
00:33:41,560 --> 00:33:43,890
that contains sensitive
information depending

751
00:33:43,890 --> 00:33:47,400
on what they've done, so
a lot of different pieces

752
00:33:47,400 --> 00:33:50,310
of sensitive information that
this payload had access to,

753
00:33:50,310 --> 00:33:52,420
but because of Apple's very restricted

754
00:33:52,420 --> 00:33:55,010
and limited definition, kind of consumer,

755
00:33:55,010 --> 00:33:58,230
individual consumer-focused
definition of sensitive data,

756
00:33:58,230 --> 00:34:01,930
I received a tiny bounty
payment in this case,

757
00:34:01,930 --> 00:34:04,310
nowhere near that 100,000 there,

758
00:34:04,310 --> 00:34:06,500
so just wanted to point that out.

759
00:34:06,500 --> 00:34:09,747
For researchers, if you're
submitting things to Apple,

760
00:34:09,747 --> 00:34:14,747
to just be aware of that, and
the reality is Apple may say

761
00:34:14,920 --> 00:34:16,590
that this is the small breadth

762
00:34:16,590 --> 00:34:18,450
of sensitive data we care about,

763
00:34:18,450 --> 00:34:20,390
but from an attacker's perspective,

764
00:34:20,390 --> 00:34:22,950
you may have a bypass and
you're able to get things

765
00:34:22,950 --> 00:34:26,270
that are outside of that window of Apple,

766
00:34:26,270 --> 00:34:29,060
in terms of their definition
of sensitive data,

767
00:34:29,060 --> 00:34:32,290
but it's still sensitive
data, and so that can happen

768
00:34:32,290 --> 00:34:33,210
in your case as well

769
00:34:33,210 --> 00:34:34,880
where you receive a small bounty payment,

770
00:34:34,880 --> 00:34:37,280
so just wanted to give
you a heads up with that.

771
00:34:38,309 --> 00:34:40,430
Some interesting things
about this payload,

772
00:34:40,430 --> 00:34:42,410
so I mentioned it does bypass Gatekeeper

773
00:34:42,410 --> 00:34:45,090
and app transport security
that we talked about earlier,

774
00:34:45,090 --> 00:34:49,280
where the system restricts what
websites an app can talk to

775
00:34:49,280 --> 00:34:52,020
or what types of protocols
it can talk over,

776
00:34:52,020 --> 00:34:55,240
those things don't apply,
also you'll have access

777
00:34:55,240 --> 00:34:57,710
to non-TCC folders so
you'll have the ability

778
00:34:57,710 --> 00:35:00,310
to grab things like SSH and AWS keys,

779
00:35:00,310 --> 00:35:03,620
et cetera off the host,
and it's very convincing,

780
00:35:03,620 --> 00:35:06,760
so as you can see here,
just by copying icons over

781
00:35:06,760 --> 00:35:10,180
to my fake app and it's
got the OneDrive logo

782
00:35:10,180 --> 00:35:11,603
and it looks pretty close.

783
00:35:12,630 --> 00:35:14,960
And so serves as a really good payload

784
00:35:14,960 --> 00:35:17,730
that a user can just
simply double-click a DMG

785
00:35:17,730 --> 00:35:20,260
or a zip and double-click
the app inside of it,

786
00:35:20,260 --> 00:35:22,600
and that's it, so it's
not, no need to right-click

787
00:35:22,600 --> 00:35:23,740
and do all these other things,

788
00:35:23,740 --> 00:35:25,943
which made this a very powerful bypass.

789
00:35:26,810 --> 00:35:31,140
And I, in my tests, I did both
with trying a shell script

790
00:35:31,140 --> 00:35:34,160
at the bottom of the app
bundle as well as having Python

791
00:35:34,160 --> 00:35:35,660
at the bottom of the app I'm doing.

792
00:35:35,660 --> 00:35:38,390
In both cases they work,
because neither Python

793
00:35:38,390 --> 00:35:41,090
or Bash scripts are checked by Gatekeeper,

794
00:35:41,090 --> 00:35:43,530
so I was able to get a
callback in both cases,

795
00:35:43,530 --> 00:35:44,640
and here's an example,

796
00:35:44,640 --> 00:35:48,380
just kinda walking you through
what the payload looks like,

797
00:35:48,380 --> 00:35:49,360
and I'm just showing you here

798
00:35:49,360 --> 00:35:51,840
that Terminal does not
have full disk access,

799
00:35:51,840 --> 00:35:55,200
it did not have any folder access as well,

800
00:35:55,200 --> 00:35:57,550
and Gatekeeper's set to App Store

801
00:35:57,550 --> 00:35:59,040
which is the most restrictive level,

802
00:35:59,040 --> 00:36:02,250
so just wanted to show that
there's no trickeration going on

803
00:36:02,250 --> 00:36:03,710
in the background.

804
00:36:03,710 --> 00:36:06,350
Here is the payload that pulls down curl,

805
00:36:06,350 --> 00:36:08,900
or uses curl to pull down the payload,

806
00:36:08,900 --> 00:36:10,190
and runs it backgrounded,

807
00:36:10,190 --> 00:36:12,090
and then there's an
osascript message there

808
00:36:12,090 --> 00:36:14,220
which is a fake prompt to the user,

809
00:36:14,220 --> 00:36:16,220
saying thank you for installing this app,

810
00:36:16,220 --> 00:36:18,610
so you'll see what that looks
like a little bit later.

811
00:36:18,610 --> 00:36:21,170
Next, I'm using this masquerade script.

812
00:36:21,170 --> 00:36:25,170
It's a slightly modified
version of a tool called Appify

813
00:36:25,170 --> 00:36:28,700
that's been out for years, that
basically took shell scripts

814
00:36:28,700 --> 00:36:32,000
and put them in the bottom
of an app bundle structure,

815
00:36:32,000 --> 00:36:33,110
and so that's what I did here

816
00:36:33,110 --> 00:36:37,830
is just ran that masquerade
script and created a fake app

817
00:36:37,830 --> 00:36:40,870
that has the structure of an
app, but instead of a Mach-O,

818
00:36:40,870 --> 00:36:43,520
it has the shell script
downloader at the bottom

819
00:36:43,520 --> 00:36:44,650
of the bundle.

820
00:36:44,650 --> 00:36:48,860
Now what I'm doing is taking
the icon from OneDrive

821
00:36:48,860 --> 00:36:52,330
and I'm copying it over
to remove the default logo

822
00:36:52,330 --> 00:36:55,220
in my fake app to make it look
a little bit more realistic,

823
00:36:55,220 --> 00:36:57,620
and notice that the operating
system labels both of them

824
00:36:57,620 --> 00:36:59,410
as apps, even though in my case,

825
00:36:59,410 --> 00:37:01,223
I don't even have an info.plist.

826
00:37:01,223 --> 00:37:04,580
Just there, it just kinda
follows the app bundle structure,

827
00:37:04,580 --> 00:37:08,210
so now that I have my
fake app with the logo,

828
00:37:08,210 --> 00:37:11,360
what I'm doing now is
copying it over to a folder,

829
00:37:11,360 --> 00:37:14,800
and then I'm gonna go into Disk Utility

830
00:37:14,800 --> 00:37:19,080
and essentially create a
DMG file to host the app.

831
00:37:19,080 --> 00:37:20,653
So that's kinda what I'm doing here.

832
00:37:20,653 --> 00:37:24,420
I just moved the fake app over
to a folder called hosting,

833
00:37:24,420 --> 00:37:27,710
and now I'm saving it there

834
00:37:27,710 --> 00:37:29,991
and I'm gonna give it a
new name called RealApp,

835
00:37:29,991 --> 00:37:32,773
so it'll be saved as RealApp.dmg.

836
00:37:34,640 --> 00:37:38,060
So that's what's happening
here, so now that that's done,

837
00:37:38,060 --> 00:37:42,500
you'll see RealApp.dmg was dropped there,

838
00:37:42,500 --> 00:37:46,090
so the next step will be
to show that when a user,

839
00:37:46,090 --> 00:37:48,880
basically to simulate a user
downloading it from the web,

840
00:37:48,880 --> 00:37:52,280
so I'm gonna host the RealApp.dmg

841
00:37:52,280 --> 00:37:56,650
to a local web server here
using simple HTTP server,

842
00:37:56,650 --> 00:37:58,660
and that way I can click it, download it,

843
00:37:58,660 --> 00:38:00,020
and when I download it,

844
00:38:00,020 --> 00:38:02,610
it will have the same quarantine attribute

845
00:38:02,610 --> 00:38:05,320
that a user would have if
they had to download it

846
00:38:05,320 --> 00:38:07,943
as part of a phishing
exercise, for example.

847
00:38:09,170 --> 00:38:10,700
So I just hosted it.

848
00:38:10,700 --> 00:38:14,190
Here's me accessing it here locally,

849
00:38:14,190 --> 00:38:17,230
and you can see there's RealApp.dmg,

850
00:38:17,230 --> 00:38:18,350
so just single-click it,

851
00:38:18,350 --> 00:38:20,810
it downloads to the Downloads folder,

852
00:38:20,810 --> 00:38:22,450
and now we'll just confirm

853
00:38:22,450 --> 00:38:26,160
that the DMG file does have
the quarantine attribute

854
00:38:26,160 --> 00:38:27,543
that Gatekeeper checks.

855
00:38:28,540 --> 00:38:30,040
We'll take a look at that now.

856
00:38:31,740 --> 00:38:32,573
And as you can see,

857
00:38:32,573 --> 00:38:35,640
it does have the com Apple
quarantine attribute appended

858
00:38:35,640 --> 00:38:39,630
to it, so now we're
ready to take that file

859
00:38:39,630 --> 00:38:41,410
that we just downloaded and detonate it

860
00:38:41,410 --> 00:38:44,003
and see what happens.

861
00:38:45,070 --> 00:38:49,360
So you detonate the DMG,
outside the DMG is the fake app

862
00:38:49,360 --> 00:38:52,763
that we created here in the
demo, we double-click that.

863
00:38:53,720 --> 00:38:56,860
Notice no Gatekeeper popups
anywhere, and as you can see,

864
00:38:56,860 --> 00:38:58,940
you got the fake popup
there that says thank you

865
00:38:58,940 --> 00:39:01,010
for installing this provisioner,

866
00:39:01,010 --> 00:39:04,320
it fakes to be from the IT
team, and in the background,

867
00:39:04,320 --> 00:39:07,710
I get a callback from my Mythic
command and control server.

868
00:39:07,710 --> 00:39:09,610
So again, Apple has fixed this,

869
00:39:09,610 --> 00:39:13,360
but I just wanted to show you
what the bypass looked like

870
00:39:13,360 --> 00:39:14,760
when I submitted it to them.

871
00:39:15,810 --> 00:39:17,970
Other things to keep in mind from TCC,

872
00:39:17,970 --> 00:39:19,470
a lot of this we've already talked about

873
00:39:19,470 --> 00:39:20,980
of what's not protected.

874
00:39:20,980 --> 00:39:24,430
Another thing to mention is SSH is often,

875
00:39:24,430 --> 00:39:25,870
kinda touched on it early,

876
00:39:25,870 --> 00:39:28,240
but in enterprise macOS environments,

877
00:39:28,240 --> 00:39:31,280
SSH is usually running by
default on the endpoints,

878
00:39:31,280 --> 00:39:34,560
and SSH daemon was recently pointed out

879
00:39:34,560 --> 00:39:37,210
in the Mac security community

880
00:39:37,210 --> 00:39:41,070
that the SSH daemon actually
has full disk access,

881
00:39:41,070 --> 00:39:43,980
so if a machine, if you're on a machine

882
00:39:43,980 --> 00:39:47,563
and you have credentials of the
user and you SSH in locally,

883
00:39:48,860 --> 00:39:50,690
using those, that set of credentials,

884
00:39:50,690 --> 00:39:54,020
you now can have full disk
access and bypass TCC,

885
00:39:54,020 --> 00:39:55,990
so something to point out there.

886
00:39:55,990 --> 00:39:57,780
The quarantine attribute,

887
00:39:57,780 --> 00:40:00,790
using curl does not append
the quarantine attribute,

888
00:40:00,790 --> 00:40:05,750
just downloading through
browsers or through Bluetooth,

889
00:40:05,750 --> 00:40:08,150
sharing files from one
machine to the next,

890
00:40:08,150 --> 00:40:10,490
which is AirDrop, things
like that will append it

891
00:40:10,490 --> 00:40:13,590
but using curl does not, so
that's something to keep in mind

892
00:40:13,590 --> 00:40:16,140
because I used that in
my Gatekeeper bypass,

893
00:40:16,140 --> 00:40:18,680
and from signing and
notarization perspective,

894
00:40:18,680 --> 00:40:21,550
you could totally sign
and notarize your payload

895
00:40:21,550 --> 00:40:25,440
if you want in order to get
around some of the controls,

896
00:40:25,440 --> 00:40:28,720
but in my personal experience,
I found that it was pretty,

897
00:40:28,720 --> 00:40:29,860
a pretty painful process,

898
00:40:29,860 --> 00:40:32,850
and when I did sign and
notarize my red team payload,

899
00:40:32,850 --> 00:40:36,730
I had about a week before
Apple retroactively found it

900
00:40:36,730 --> 00:40:40,510
and deactivated the developer account

901
00:40:40,510 --> 00:40:41,870
and revoked the certificate,

902
00:40:41,870 --> 00:40:44,070
so just something to think about.

903
00:40:44,070 --> 00:40:45,970
I personally believe it's
probably not worth the time

904
00:40:45,970 --> 00:40:50,970
since real-world malware samples
are often using unsigned,

905
00:40:51,450 --> 00:40:53,980
non-notarized payloads
and social engineering

906
00:40:53,980 --> 00:40:57,033
that right-click open
execution of the payload.

907
00:40:58,970 --> 00:41:02,680
Once you're on a host, lots of
different things you can do.

908
00:41:02,680 --> 00:41:05,530
You can, again, you can
grab the system credentials

909
00:41:05,530 --> 00:41:08,980
from the host, so like
AWS credentials, GCP,

910
00:41:08,980 --> 00:41:13,060
Azure credentials, you can look
through users' Bash history,

911
00:41:13,060 --> 00:41:15,700
you can look for maybe
sensitive files on the system,

912
00:41:15,700 --> 00:41:20,700
sometimes users might save
tokens or passwords to a file,

913
00:41:21,020 --> 00:41:25,650
MangoPDF did a really good
blog post on cookie crimes,

914
00:41:25,650 --> 00:41:29,500
things you can do there
with, for Google Chrome,

915
00:41:29,500 --> 00:41:30,800
so definitely check that out.

916
00:41:30,800 --> 00:41:33,670
I have a link in the
resources section later

917
00:41:33,670 --> 00:41:34,793
to that blog post.

918
00:41:35,750 --> 00:41:37,780
Course you can prompt
the user for credentials,

919
00:41:37,780 --> 00:41:39,440
you can do it via osascript

920
00:41:39,440 --> 00:41:40,800
or you can do it programmatically

921
00:41:40,800 --> 00:41:44,670
to not leave any command line artifacts.

922
00:41:44,670 --> 00:41:48,310
You can also search for other
interesting files on the host,

923
00:41:48,310 --> 00:41:51,040
and even this file here on the bottom,

924
00:41:51,040 --> 00:41:56,040
this login data Chrome database,
contains a stats table,

925
00:41:56,710 --> 00:42:01,650
and that stats table contains
the username and the login URL

926
00:42:01,650 --> 00:42:05,320
for various sites, and it's,
of course it's unencrypted,

927
00:42:05,320 --> 00:42:09,160
and you do not need root to
read it, and it's not protected

928
00:42:09,160 --> 00:42:13,190
by TCC meaning any non-sandbox
payload can now read

929
00:42:13,190 --> 00:42:14,930
from that table, which means

930
00:42:14,930 --> 00:42:16,770
if you already have the user's password,

931
00:42:16,770 --> 00:42:19,970
considering often times
passwords are reused,

932
00:42:19,970 --> 00:42:22,000
that table now provides usernames

933
00:42:22,000 --> 00:42:24,533
to try that password
against for different sites.

934
00:42:26,450 --> 00:42:28,920
Also if you have root access,

935
00:42:28,920 --> 00:42:30,510
you can grab the keychain database

936
00:42:30,510 --> 00:42:34,470
and take it offline using
forensic tools like chainbreaker,

937
00:42:34,470 --> 00:42:37,790
and so you can gain root access
via either installer package

938
00:42:37,790 --> 00:42:40,290
which we talked about,
that gives you root access

939
00:42:40,290 --> 00:42:41,930
because you use authenticate,

940
00:42:41,930 --> 00:42:44,810
or if you get normal
user access, you can use,

941
00:42:44,810 --> 00:42:47,230
you can basically prompt
the user for credentials,

942
00:42:47,230 --> 00:42:50,020
and once you get those
credentials, you can then,

943
00:42:50,020 --> 00:42:51,180
through tools like Mythic,

944
00:42:51,180 --> 00:42:53,880
you can run elevated
commands since the user,

945
00:42:53,880 --> 00:42:55,110
via the username and password,

946
00:42:55,110 --> 00:42:58,060
that user is usually root on their Mac,

947
00:42:58,060 --> 00:43:00,510
so then you can use that
to run elevated commands

948
00:43:00,510 --> 00:43:03,513
and pull of the keychain, so
something to look at as well.

949
00:43:04,720 --> 00:43:06,120
When it comes to persistence,

950
00:43:06,120 --> 00:43:09,080
lots of different options
beyond just launch agents

951
00:43:09,080 --> 00:43:11,610
and launch daemons, which
are probably the most popular

952
00:43:11,610 --> 00:43:13,040
for macOS.

953
00:43:13,040 --> 00:43:16,890
TheEvilBit did a really good
long-running blog post on,

954
00:43:16,890 --> 00:43:20,440
titled Beyond Good Old
LaunchAgents, which goes,

955
00:43:20,440 --> 00:43:22,820
it's like the Mac version
of Beyond Good Ole Run key

956
00:43:22,820 --> 00:43:23,960
on a Windows side and looks

957
00:43:23,960 --> 00:43:27,663
at all sorts of interesting
persistence options on macOS.

958
00:43:28,800 --> 00:43:32,680
Leo Pitt or D00MFist also
has a PersistentJXA repo,

959
00:43:32,680 --> 00:43:36,270
looking at JXA implementations
of a lot of the techniques

960
00:43:36,270 --> 00:43:39,090
that TheEvilBit talks
about in his blog post.

961
00:43:39,090 --> 00:43:43,970
I also then took a subset
of D00MFist PersistentJXA

962
00:43:43,970 --> 00:43:46,210
and did some Swift implementations,

963
00:43:46,210 --> 00:43:48,290
so I have a repo now
called Persistent-Swift,

964
00:43:48,290 --> 00:43:50,780
so you have a lot of different
resources there to play with,

965
00:43:50,780 --> 00:43:54,510
different, to look into
different persistence options

966
00:43:54,510 --> 00:43:57,160
and different implementations for macOS.

967
00:43:57,160 --> 00:44:01,020
Lots of other options here
like Vim plugin persistence,

968
00:44:01,020 --> 00:44:06,020
SSHrc persistence, profile
persistence, Xorrior, Chris Ross,

969
00:44:06,100 --> 00:44:09,730
he has a really cool
authorization plugin that,

970
00:44:09,730 --> 00:44:10,810
he did a lot of research there,

971
00:44:10,810 --> 00:44:14,143
so a lot of different options
to look into for persistence.

972
00:44:15,070 --> 00:44:18,310
So some other attack vectors
beyond Mac that you'll,

973
00:44:18,310 --> 00:44:21,110
typically will see in a macOS environment,

974
00:44:21,110 --> 00:44:24,090
one being the build pipeline or also known

975
00:44:24,090 --> 00:44:26,070
as the CI/CD pipeline,

976
00:44:26,070 --> 00:44:28,840
and the way I like to describe
it is this is the process

977
00:44:28,840 --> 00:44:31,850
that an initial concept
for code goes through

978
00:44:31,850 --> 00:44:35,980
from the initial draft,
thought, or concept,

979
00:44:35,980 --> 00:44:38,310
all the way through to
being customer-ready,

980
00:44:38,310 --> 00:44:41,310
and it hits various stages
and checks along the way,

981
00:44:41,310 --> 00:44:43,490
and what makes this so
interesting is there's a lot

982
00:44:43,490 --> 00:44:46,480
of interconnections here
across different hosts,

983
00:44:46,480 --> 00:44:48,820
so if you can access one of these hosts,

984
00:44:48,820 --> 00:44:50,773
chances are you'll get a lot of access.

985
00:44:51,830 --> 00:44:54,070
And sometimes your build environment,

986
00:44:54,070 --> 00:44:57,240
your CI/CD process will
traverse environments depending

987
00:44:57,240 --> 00:45:00,060
on what you have implemented
in your organization,

988
00:45:00,060 --> 00:45:02,450
and as I mentioned, a lot of integrations,

989
00:45:02,450 --> 00:45:04,960
like there may be some
internal Git integration,

990
00:45:04,960 --> 00:45:08,260
and of course internal Git
becomes a target internally

991
00:45:08,260 --> 00:45:11,540
because there tends to be more
trust for your internal Git

992
00:45:11,540 --> 00:45:14,590
than your external Git, meaning
that since it's internal,

993
00:45:14,590 --> 00:45:18,360
people may feel like posting
or committing secrets

994
00:45:18,360 --> 00:45:21,190
in your code is not as
damaging, but ironically,

995
00:45:21,190 --> 00:45:22,023
that's gonna be one

996
00:45:22,023 --> 00:45:23,450
of the first places an attacker will look

997
00:45:23,450 --> 00:45:26,700
in a tech environment is
looking through Git repos.

998
00:45:26,700 --> 00:45:30,990
Jenkins is often commonly
part of the build process

999
00:45:30,990 --> 00:45:33,110
and is usually misconfigured in some way

1000
00:45:33,110 --> 00:45:34,890
that will allow easy access,

1001
00:45:34,890 --> 00:45:37,610
and often times Jenkins will contain a lot

1002
00:45:37,610 --> 00:45:39,860
of different secrets on it, given that,

1003
00:45:39,860 --> 00:45:41,670
given its role in the environment,

1004
00:45:41,670 --> 00:45:43,700
and then of course you have workstations

1005
00:45:43,700 --> 00:45:46,830
where engineers may be doing
development from their Macs,

1006
00:45:46,830 --> 00:45:50,280
and there you'll have local
keys stored there as well.

1007
00:45:50,280 --> 00:45:53,183
Quick look at Jenkins, two
common misconfigurations,

1008
00:45:53,183 --> 00:45:58,183
this is the first one, allowing
unauthenticated build jobs

1009
00:45:58,240 --> 00:46:00,840
to be executed, so if this is
present in your environment,

1010
00:46:00,840 --> 00:46:03,040
you could hit the view default newjob URL

1011
00:46:03,040 --> 00:46:05,840
in your Jenkins host, and
it will bring you to a page

1012
00:46:05,840 --> 00:46:08,560
that will allow you to
run a new build job,

1013
00:46:08,560 --> 00:46:11,630
where then you can add a
single step to executor shell,

1014
00:46:11,630 --> 00:46:14,050
and you put whatever shell
command you want in there,

1015
00:46:14,050 --> 00:46:18,930
could be running a remote
shell, reverse shell payload,

1016
00:46:18,930 --> 00:46:22,250
it could be catting
out files on the system

1017
00:46:22,250 --> 00:46:24,050
that are sensitive, it could be querying

1018
00:46:24,050 --> 00:46:26,820
for metadata service IAM credentials

1019
00:46:26,820 --> 00:46:29,900
if your Jenkins host is
in a cloud environment.

1020
00:46:29,900 --> 00:46:30,980
And so you execute it

1021
00:46:30,980 --> 00:46:33,410
and you can see the console output there.

1022
00:46:33,410 --> 00:46:36,030
So essentially, this will allow compromise

1023
00:46:36,030 --> 00:46:38,980
and access to secrets which
can then be used to pivot

1024
00:46:38,980 --> 00:46:41,210
to other parts of the environment.

1025
00:46:41,210 --> 00:46:43,690
Another misconfiguration for
Jenkins that's pretty common

1026
00:46:43,690 --> 00:46:47,270
is the script console page
allowing unauthenticated access.

1027
00:46:47,270 --> 00:46:48,983
So if you, if this is
configured in your environment,

1028
00:46:48,983 --> 00:46:52,370
you can just hit the script
page of your Jenkins console,

1029
00:46:52,370 --> 00:46:54,740
Jenkins host, you'll be
brought to the console,

1030
00:46:54,740 --> 00:46:57,420
and then here you can run groovy script

1031
00:46:57,420 --> 00:46:59,840
and essentially get reverse shell access,

1032
00:46:59,840 --> 00:47:03,590
you can cat local files, query
for IAM metadata credentials

1033
00:47:03,590 --> 00:47:04,690
and the metadata service,

1034
00:47:04,690 --> 00:47:07,540
so all sorts of different
things you can do here as well.

1035
00:47:08,820 --> 00:47:12,560
A few other juicy targets,
of course internal Wiki,

1036
00:47:12,560 --> 00:47:15,550
so thinking about all the
organizational information,

1037
00:47:15,550 --> 00:47:17,010
system environment information,

1038
00:47:17,010 --> 00:47:19,490
credentials that are there
that can be leveraged

1039
00:47:19,490 --> 00:47:20,430
by an attacker,

1040
00:47:20,430 --> 00:47:22,730
thinking about your
internal ticketing system.

1041
00:47:23,620 --> 00:47:25,930
Imagine the environment information

1042
00:47:25,930 --> 00:47:28,010
that can be learned there, or processes

1043
00:47:28,010 --> 00:47:30,900
and architecture information.

1044
00:47:30,900 --> 00:47:33,690
Slack, of course, we mentioned
that earlier, credentials,

1045
00:47:33,690 --> 00:47:37,330
keys, VPN profiles, all that
stuff can be found often times

1046
00:47:37,330 --> 00:47:38,210
in Slack.

1047
00:47:38,210 --> 00:47:41,150
Another one, if you have
Docker in your environment,

1048
00:47:41,150 --> 00:47:45,220
if Docker's configured with
unauthenticated API sockets,

1049
00:47:45,220 --> 00:47:50,220
then those hosts can be
hit on port 2375 or 2376,

1050
00:47:50,600 --> 00:47:53,840
usually default ports,
but those hosts can be hit

1051
00:47:53,840 --> 00:47:56,870
and shell commands can be
run unauthenticated on those,

1052
00:47:56,870 --> 00:47:58,950
and potentially extract secrets out

1053
00:47:58,950 --> 00:48:00,870
from your containers there.

1054
00:48:00,870 --> 00:48:03,050
Of course we talked about internal Git,

1055
00:48:03,050 --> 00:48:05,580
so a lot of different
juicy targets once you're

1056
00:48:05,580 --> 00:48:08,373
in a macOS environment
outside of just macOS.

1057
00:48:09,820 --> 00:48:12,420
And of course you have cloud-hosted.

1058
00:48:12,420 --> 00:48:14,030
Usually if you're in a macOS environment,

1059
00:48:14,030 --> 00:48:16,260
there's gonna be a good
amount of cloud there as well,

1060
00:48:16,260 --> 00:48:17,980
and so the entry points

1061
00:48:17,980 --> 00:48:21,060
for cloud keys often times
can be phishing payloads

1062
00:48:21,060 --> 00:48:25,060
like grabbing cloud keys
off a compromised endpoint,

1063
00:48:25,060 --> 00:48:28,700
maybe code internal repos
for your internal Git,

1064
00:48:28,700 --> 00:48:31,980
so finding secrets that've
been committed there,

1065
00:48:31,980 --> 00:48:35,460
of course your build hosts like
your Jenkins as an example,

1066
00:48:35,460 --> 00:48:39,867
sometimes even build logs
will write the cloud keys

1067
00:48:40,890 --> 00:48:42,750
that it used during the build,

1068
00:48:42,750 --> 00:48:45,570
so that's a misconfiguration
to check for as well.

1069
00:48:45,570 --> 00:48:48,010
And it's good I think to also test

1070
00:48:48,010 --> 00:48:49,270
from a blue team perspective

1071
00:48:49,270 --> 00:48:53,040
to see what your cloud visibility
and detection posture is,

1072
00:48:53,040 --> 00:48:56,040
so can blue team see things
like accessing secrets

1073
00:48:56,040 --> 00:48:59,490
in the environment and using
those secrets to pivot,

1074
00:48:59,490 --> 00:49:03,030
different post exploitation
examples, like on the AWS side,

1075
00:49:03,030 --> 00:49:05,990
like looking at secrets
manager or parameter store

1076
00:49:05,990 --> 00:49:08,410
for additional credentials
which may provide access

1077
00:49:08,410 --> 00:49:11,940
to another environment or
a higher level of access,

1078
00:49:11,940 --> 00:49:13,983
assuming into other roles, so maybe,

1079
00:49:14,940 --> 00:49:18,760
let's say red team has
access to an AWS role,

1080
00:49:18,760 --> 00:49:21,820
that role has the ability
to assume into another role.

1081
00:49:21,820 --> 00:49:24,880
The role that they can assume
into has higher privileges,

1082
00:49:24,880 --> 00:49:27,300
so that would be a form
of privilege escalation

1083
00:49:27,300 --> 00:49:30,760
or lateral movement, to see
if blue team can see that,

1084
00:49:30,760 --> 00:49:32,920
attaching policies to users or roles,

1085
00:49:32,920 --> 00:49:35,480
all sorts of different
things here that can be done.

1086
00:49:35,480 --> 00:49:38,500
And I think it's worth
running through these types

1087
00:49:38,500 --> 00:49:40,860
of scenarios proactively or even looking

1088
00:49:40,860 --> 00:49:43,700
at the MITRE ATT&CK matrix
for a cloud that they have.

1089
00:49:43,700 --> 00:49:46,190
I'm looking at some common
privilege escalation

1090
00:49:46,190 --> 00:49:47,630
and lateral movement techniques

1091
00:49:47,630 --> 00:49:49,983
for different cloud environments.

1092
00:49:51,220 --> 00:49:53,530
So other recommendations
on the blue team side

1093
00:49:53,530 --> 00:49:56,050
is I definitely recommend leveraging

1094
00:49:56,050 --> 00:49:58,440
the Apple endpoint security framework.

1095
00:49:58,440 --> 00:50:01,060
It's good both from a personal standpoint,

1096
00:50:01,060 --> 00:50:03,780
so let's say you have
a payload, a red team

1097
00:50:03,780 --> 00:50:06,030
or a real malware sample payload,

1098
00:50:06,030 --> 00:50:07,810
you wanna understand what it does,

1099
00:50:07,810 --> 00:50:11,240
you can take Patrick
Wardle's process monitor

1100
00:50:11,240 --> 00:50:13,930
or file monitor that he
wrote and you can take it

1101
00:50:13,930 --> 00:50:17,060
on a sandbox macOS system, detonate it,

1102
00:50:17,060 --> 00:50:17,893
and then you can look

1103
00:50:17,893 --> 00:50:19,890
at the endpoint security framework logs.

1104
00:50:19,890 --> 00:50:23,630
It's almost like the
equivalent of Sysmon for Apple

1105
00:50:23,630 --> 00:50:26,110
or for macOS, so
definitely check that out,

1106
00:50:26,110 --> 00:50:26,943
and then you can look

1107
00:50:26,943 --> 00:50:30,330
for things like suspicious
command line executions,

1108
00:50:30,330 --> 00:50:32,760
persistence methodologies,
we talked about repos

1109
00:50:32,760 --> 00:50:35,890
that you can use there,
parent-child relationships,

1110
00:50:35,890 --> 00:50:39,840
so things like an Office
document spawning VEN SH

1111
00:50:39,840 --> 00:50:42,210
for example, that would
be something to key in on.

1112
00:50:42,210 --> 00:50:43,880
Course, network detection,

1113
00:50:43,880 --> 00:50:48,250
so looking for one host
accessing one or many ports

1114
00:50:48,250 --> 00:50:49,940
on multiple hosts over a short period

1115
00:50:49,940 --> 00:50:53,750
of time might indicate
scanning or sweeping activity,

1116
00:50:53,750 --> 00:50:56,720
course identity as a service
abuse, we talked about Okta,

1117
00:50:56,720 --> 00:51:00,020
OneLogin, so being able to
see if you have the ability

1118
00:51:00,020 --> 00:51:02,120
to see compromised tokens, and if so,

1119
00:51:02,120 --> 00:51:04,680
do you have the ability
and procedures in place

1120
00:51:04,680 --> 00:51:06,990
to revoke those tokens?

1121
00:51:06,990 --> 00:51:08,210
Of course Jenkins abuse,

1122
00:51:08,210 --> 00:51:10,940
so getting visibility
into script console abuse,

1123
00:51:10,940 --> 00:51:14,450
or build jobs running
suspicious shell commands,

1124
00:51:14,450 --> 00:51:19,450
and then within a cloud itself,
like AWS or GCP for example,

1125
00:51:19,580 --> 00:51:21,740
looking at your common post exploitation

1126
00:51:21,740 --> 00:51:24,530
and privilege escalation
methods, and auditing,

1127
00:51:24,530 --> 00:51:27,910
you could even proactively
audit your roles and see what,

1128
00:51:27,910 --> 00:51:29,520
like you can work with, I guess,

1129
00:51:29,520 --> 00:51:31,360
if you have a cloud security team,

1130
00:51:31,360 --> 00:51:33,230
you all can work together
to see what the state

1131
00:51:33,230 --> 00:51:35,270
of your current IAM roles are,

1132
00:51:35,270 --> 00:51:36,740
what roles they could assume into,

1133
00:51:36,740 --> 00:51:39,760
and look for easy
privilege escalation paths

1134
00:51:39,760 --> 00:51:42,723
and see what can be done
to reduce those paths.

1135
00:51:44,010 --> 00:51:46,130
Lots of different resources here,

1136
00:51:46,130 --> 00:51:48,450
lots of cool people I've
done a lot of awesome work

1137
00:51:48,450 --> 00:51:51,460
in the macOS space, so
this is not all-inclusive,

1138
00:51:51,460 --> 00:51:53,500
but just wanted to shout
out some good resources

1139
00:51:53,500 --> 00:51:55,490
for people who are
interested in delving more

1140
00:51:55,490 --> 00:51:57,330
into these topics.

1141
00:51:57,330 --> 00:51:58,880
Definitely check those out.

1142
00:51:58,880 --> 00:52:01,460
So thank you all for
listening, appreciate it,

1143
00:52:01,460 --> 00:52:04,053
and if you have any questions,
feel free to reach out.

