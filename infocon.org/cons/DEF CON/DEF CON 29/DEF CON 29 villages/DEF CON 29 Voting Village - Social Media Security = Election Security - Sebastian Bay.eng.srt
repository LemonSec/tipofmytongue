1
00:00:01,280 --> 00:00:03,360
my name is sebastian bay and i'm a

2
00:00:03,360 --> 00:00:05,359
researcher with the swedish defense

3
00:00:05,359 --> 00:00:08,559
research agency specializing in election

4
00:00:08,559 --> 00:00:11,440
security and digital harms

5
00:00:11,440 --> 00:00:13,840
this year the defcon voting village is

6
00:00:13,840 --> 00:00:15,519
focused on the spread of election

7
00:00:15,519 --> 00:00:17,279
related disinformation

8
00:00:17,279 --> 00:00:19,600
and misinformation and i'm going to give

9
00:00:19,600 --> 00:00:21,439
a short talk introducing some of my

10
00:00:21,439 --> 00:00:22,400
research

11
00:00:22,400 --> 00:00:24,720
and highlighting the need for increased

12
00:00:24,720 --> 00:00:25,760
cyber security

13
00:00:25,760 --> 00:00:28,320
for social media companies as part of

14
00:00:28,320 --> 00:00:29,199
our combined

15
00:00:29,199 --> 00:00:33,360
efforts to strengthen election security

16
00:00:33,360 --> 00:00:35,440
there are of course several aspects of

17
00:00:35,440 --> 00:00:36,559
election security

18
00:00:36,559 --> 00:00:38,640
and traditionally we have focused on the

19
00:00:38,640 --> 00:00:40,719
conduct of elections when we talk about

20
00:00:40,719 --> 00:00:42,320
cyber security

21
00:00:42,320 --> 00:00:45,440
that means safeguarding the i.t systems

22
00:00:45,440 --> 00:00:47,680
needed to administer elections from

23
00:00:47,680 --> 00:00:49,039
registering voters

24
00:00:49,039 --> 00:00:51,520
to counting and tallying the results

25
00:00:51,520 --> 00:00:52,480
this is clear

26
00:00:52,480 --> 00:00:54,559
and this is also something that is

27
00:00:54,559 --> 00:00:56,079
needed we have seen

28
00:00:56,079 --> 00:00:59,920
continuous effort to try to undermine

29
00:00:59,920 --> 00:01:03,440
election systems using i.t

30
00:01:03,440 --> 00:01:06,560
attacks of different sorts however

31
00:01:06,560 --> 00:01:08,880
recently we've also seen that digital

32
00:01:08,880 --> 00:01:09,840
disinformation

33
00:01:09,840 --> 00:01:12,240
is an equal or perhaps even larger

34
00:01:12,240 --> 00:01:15,040
threat to the conduct of elections

35
00:01:15,040 --> 00:01:17,600
where digital disinformation is used to

36
00:01:17,600 --> 00:01:18,880
try to undermine

37
00:01:18,880 --> 00:01:21,360
trust in the election process it is used

38
00:01:21,360 --> 00:01:23,040
to try to undermine

39
00:01:23,040 --> 00:01:25,920
the will and the ability of people to

40
00:01:25,920 --> 00:01:28,240
participate in the elections

41
00:01:28,240 --> 00:01:30,799
and it is of course used in an attempt

42
00:01:30,799 --> 00:01:33,119
to toward or undermine the political

43
00:01:33,119 --> 00:01:34,079
process

44
00:01:34,079 --> 00:01:36,560
often with the illegitimate use of

45
00:01:36,560 --> 00:01:38,960
influence in different forms

46
00:01:38,960 --> 00:01:42,640
but i will argue today that much or

47
00:01:42,640 --> 00:01:45,759
a huge part of this problem is also a

48
00:01:45,759 --> 00:01:47,600
cyber security problem

49
00:01:47,600 --> 00:01:50,399
but a cyber security problem primarily

50
00:01:50,399 --> 00:01:54,640
for social media companies

51
00:01:54,640 --> 00:01:57,360
now if we simplify enough this

52
00:01:57,360 --> 00:01:58,240
information

53
00:01:58,240 --> 00:02:01,600
can be um divided into two separate

54
00:02:01,600 --> 00:02:02,240
issues

55
00:02:02,240 --> 00:02:04,960
the issue of content and the issue of

56
00:02:04,960 --> 00:02:07,680
inauthentic behavior

57
00:02:07,680 --> 00:02:10,639
now content can be disinformation it can

58
00:02:10,639 --> 00:02:11,599
be illegal

59
00:02:11,599 --> 00:02:14,160
and it can be many other things and

60
00:02:14,160 --> 00:02:16,160
we've seen during the last few years

61
00:02:16,160 --> 00:02:18,640
that regulating and moderating content

62
00:02:18,640 --> 00:02:20,000
is difficult

63
00:02:20,000 --> 00:02:22,400
even if we're now seeing better policies

64
00:02:22,400 --> 00:02:24,879
in regard to election related content

65
00:02:24,879 --> 00:02:28,080
on social media platforms but if

66
00:02:28,080 --> 00:02:30,800
content is tricky to develop clear

67
00:02:30,800 --> 00:02:32,239
policies for

68
00:02:32,239 --> 00:02:35,120
inauthentic behavior and other forms of

69
00:02:35,120 --> 00:02:36,800
social media manipulation

70
00:02:36,800 --> 00:02:39,280
is far less tricky it is simply not

71
00:02:39,280 --> 00:02:39,920
allowed

72
00:02:39,920 --> 00:02:42,400
on all the major uh platforms i've

73
00:02:42,400 --> 00:02:43,760
studied

74
00:02:43,760 --> 00:02:46,000
you are simply not allowed to run

75
00:02:46,000 --> 00:02:47,599
thousands of fake accounts

76
00:02:47,599 --> 00:02:49,920
on any of the large platforms you're not

77
00:02:49,920 --> 00:02:52,000
allowed to manipulate their algorithms

78
00:02:52,000 --> 00:02:53,440
you are not allowed to scrape their

79
00:02:53,440 --> 00:02:55,280
content you are not allowed to hack

80
00:02:55,280 --> 00:02:57,120
their systems

81
00:02:57,120 --> 00:03:00,480
yet we see that this

82
00:03:00,480 --> 00:03:03,120
is a large problem it is a large

83
00:03:03,120 --> 00:03:05,120
industry and of course this is something

84
00:03:05,120 --> 00:03:06,319
that is being done

85
00:03:06,319 --> 00:03:10,000
all the time this is what a bot farm can

86
00:03:10,000 --> 00:03:10,720
look like

87
00:03:10,720 --> 00:03:13,920
in real life these pictures are provided

88
00:03:13,920 --> 00:03:16,080
by the ukrainian security services

89
00:03:16,080 --> 00:03:18,400
showing what they argue is a

90
00:03:18,400 --> 00:03:20,480
russian-sponsored bot farm

91
00:03:20,480 --> 00:03:22,959
inside of ukraine to try to avoid

92
00:03:22,959 --> 00:03:24,159
detection

93
00:03:24,159 --> 00:03:27,920
what we're seeing is sim card it is

94
00:03:27,920 --> 00:03:32,720
various forms of antennas used to run

95
00:03:32,720 --> 00:03:36,239
used to run different forms of proxies

96
00:03:36,239 --> 00:03:39,120
and of course to set up and avoid

97
00:03:39,120 --> 00:03:41,760
detection

98
00:03:42,480 --> 00:03:44,879
now the european union has long

99
00:03:44,879 --> 00:03:46,000
underscored a need

100
00:03:46,000 --> 00:03:49,280
for social media companies to intensify

101
00:03:49,280 --> 00:03:51,760
and demonstrate the effectiveness of

102
00:03:51,760 --> 00:03:52,959
efforts to close

103
00:03:52,959 --> 00:03:55,840
fake accounts this has been in a code of

104
00:03:55,840 --> 00:03:56,560
practice

105
00:03:56,560 --> 00:03:58,159
to address the spread of this

106
00:03:58,159 --> 00:04:00,560
information also within an election

107
00:04:00,560 --> 00:04:03,680
related context

108
00:04:05,760 --> 00:04:07,599
the social media companies have been

109
00:04:07,599 --> 00:04:09,680
asked by the european commission

110
00:04:09,680 --> 00:04:12,480
to conduct regular reporting to the

111
00:04:12,480 --> 00:04:13,439
commission

112
00:04:13,439 --> 00:04:16,238
where they report on the number of fake

113
00:04:16,238 --> 00:04:17,839
accounts that have been closed

114
00:04:17,839 --> 00:04:19,358
during the last quarter and during the

115
00:04:19,358 --> 00:04:21,759
last year and we've seen in this

116
00:04:21,759 --> 00:04:22,720
reporting

117
00:04:22,720 --> 00:04:25,520
that fake accounts continue to be a huge

118
00:04:25,520 --> 00:04:26,240
problem

119
00:04:26,240 --> 00:04:29,600
measured in the billions and it is a

120
00:04:29,600 --> 00:04:30,880
large problem

121
00:04:30,880 --> 00:04:32,720
because fake engagement trigger

122
00:04:32,720 --> 00:04:34,400
algorithms to spread

123
00:04:34,400 --> 00:04:37,280
content to authentic users fake

124
00:04:37,280 --> 00:04:38,000
engagement

125
00:04:38,000 --> 00:04:40,560
trick authentic users to believe that

126
00:04:40,560 --> 00:04:42,639
content is more popular than it really

127
00:04:42,639 --> 00:04:43,680
is

128
00:04:43,680 --> 00:04:46,880
fake engagement misleads users

129
00:04:46,880 --> 00:04:50,000
fake engagement manipulate democratic

130
00:04:50,000 --> 00:04:51,280
conversation

131
00:04:51,280 --> 00:04:54,160
and fake engagement create loss of

132
00:04:54,160 --> 00:04:54,800
genuine

133
00:04:54,800 --> 00:04:57,840
advertisement spend

134
00:04:58,800 --> 00:05:01,360
i've co-authored three reports on the

135
00:05:01,360 --> 00:05:02,160
topic of

136
00:05:02,160 --> 00:05:04,800
inauthentic behavior on social media

137
00:05:04,800 --> 00:05:06,880
ranging from the black market

138
00:05:06,880 --> 00:05:09,600
to trying to develop metrics and methods

139
00:05:09,600 --> 00:05:11,280
for assessing the ability

140
00:05:11,280 --> 00:05:13,680
of social media companies to counter the

141
00:05:13,680 --> 00:05:15,120
abuse

142
00:05:15,120 --> 00:05:18,400
of their platforms in effect trying to

143
00:05:18,400 --> 00:05:19,039
assess

144
00:05:19,039 --> 00:05:20,960
the level of cybersecurity in these

145
00:05:20,960 --> 00:05:22,880
platforms when it comes to

146
00:05:22,880 --> 00:05:26,880
preventing inauthentic behavior

147
00:05:26,880 --> 00:05:30,080
if we start by looking into the black

148
00:05:30,080 --> 00:05:32,960
market for social media manipulation

149
00:05:32,960 --> 00:05:35,600
and which i think is a good base for

150
00:05:35,600 --> 00:05:37,520
understanding the problem of social

151
00:05:37,520 --> 00:05:39,600
media manipulation

152
00:05:39,600 --> 00:05:41,680
i'm going to give you three main

153
00:05:41,680 --> 00:05:43,199
takeaways here

154
00:05:43,199 --> 00:05:46,639
the first is that the scale of the black

155
00:05:46,639 --> 00:05:48,000
market infrastructure

156
00:05:48,000 --> 00:05:52,000
is extensive we see that an

157
00:05:52,000 --> 00:05:54,160
entire industry has developed not only

158
00:05:54,160 --> 00:05:55,919
around providing the manipulation

159
00:05:55,919 --> 00:05:56,880
services

160
00:05:56,880 --> 00:05:59,600
but providing the infrastructure needed

161
00:05:59,600 --> 00:06:01,759
for the manipulation services

162
00:06:01,759 --> 00:06:04,960
to work and that ranges from

163
00:06:04,960 --> 00:06:08,160
fake sim cards digital fingerprinting

164
00:06:08,160 --> 00:06:11,440
scripts and capture services

165
00:06:11,440 --> 00:06:15,919
for the manipulation services to provide

166
00:06:15,919 --> 00:06:19,280
that is used to generate provide and

167
00:06:19,280 --> 00:06:23,120
maintain fake accounts and we also see

168
00:06:23,120 --> 00:06:25,120
management platforms that are used by

169
00:06:25,120 --> 00:06:27,039
the

170
00:06:27,039 --> 00:06:30,240
inauthentic engagement services

171
00:06:30,240 --> 00:06:34,080
but they're also sold as software to um

172
00:06:34,080 --> 00:06:36,160
to independent contractors and to

173
00:06:36,160 --> 00:06:37,919
private companies that wish to run their

174
00:06:37,919 --> 00:06:40,639
own campaigns

175
00:06:40,720 --> 00:06:43,600
seeing this entire service we initially

176
00:06:43,600 --> 00:06:45,919
thought that this was a black market

177
00:06:45,919 --> 00:06:47,759
and that is also why we labeled the

178
00:06:47,759 --> 00:06:50,080
report a black market for social media

179
00:06:50,080 --> 00:06:51,360
manipulation

180
00:06:51,360 --> 00:06:53,199
but what we saw is that it's not

181
00:06:53,199 --> 00:06:54,800
actually a black market

182
00:06:54,800 --> 00:06:57,599
it is an illegitimate market perhaps but

183
00:06:57,599 --> 00:06:58,080
it's

184
00:06:58,080 --> 00:07:01,120
extremely easy to find and the openness

185
00:07:01,120 --> 00:07:02,000
of this industry

186
00:07:02,000 --> 00:07:05,199
is still today quite striking

187
00:07:05,199 --> 00:07:06,880
we see that the larger social media

188
00:07:06,880 --> 00:07:08,960
manipulation service providers they

189
00:07:08,960 --> 00:07:11,840
fearlessly promote their services they

190
00:07:11,840 --> 00:07:13,840
promote them on their own websites of

191
00:07:13,840 --> 00:07:15,039
course

192
00:07:15,039 --> 00:07:18,080
but they also promote them um on app

193
00:07:18,080 --> 00:07:18,800
stores

194
00:07:18,800 --> 00:07:22,960
on um on the social media platforms

195
00:07:22,960 --> 00:07:25,680
themselves uh they usually run tutorial

196
00:07:25,680 --> 00:07:26,720
accounts on

197
00:07:26,720 --> 00:07:29,759
youtube facebook instagram etc

198
00:07:29,759 --> 00:07:32,000
and of course you can find them in all

199
00:07:32,000 --> 00:07:33,520
major searches

200
00:07:33,520 --> 00:07:36,800
it is even so that they they use

201
00:07:36,800 --> 00:07:39,599
ads on search engines to promote their

202
00:07:39,599 --> 00:07:42,159
services

203
00:07:42,400 --> 00:07:44,800
third much of this infrastructure seems

204
00:07:44,800 --> 00:07:46,000
to be russian

205
00:07:46,000 --> 00:07:47,120
it doesn't mean that it's

206
00:07:47,120 --> 00:07:51,039
state-sponsored but many of these

207
00:07:51,039 --> 00:07:53,919
primary service providers that are

208
00:07:53,919 --> 00:07:56,000
reselling their services to many of the

209
00:07:56,000 --> 00:07:56,960
companies

210
00:07:56,960 --> 00:07:59,039
offering manipulation services in the

211
00:07:59,039 --> 00:08:00,240
west

212
00:08:00,240 --> 00:08:02,800
are russian and they seem to be russian

213
00:08:02,800 --> 00:08:03,759
simply because

214
00:08:03,759 --> 00:08:05,360
this is a place where this industry has

215
00:08:05,360 --> 00:08:06,800
existed for a long time

216
00:08:06,800 --> 00:08:08,479
and there is a lot of know-how in this

217
00:08:08,479 --> 00:08:10,240
area

218
00:08:10,240 --> 00:08:13,759
but this is also a global industry

219
00:08:13,759 --> 00:08:15,199
and we're seeing more and more of

220
00:08:15,199 --> 00:08:17,759
fragmentation uh where for an example

221
00:08:17,759 --> 00:08:20,319
uh if you live in nigeria and you want

222
00:08:20,319 --> 00:08:22,160
to buy manipulation you might go to a

223
00:08:22,160 --> 00:08:23,680
nigerian provider

224
00:08:23,680 --> 00:08:26,319
they might use russian infrastructure

225
00:08:26,319 --> 00:08:26,960
and

226
00:08:26,960 --> 00:08:29,039
but they might also use infrastructure

227
00:08:29,039 --> 00:08:31,360
from southeast asia etc

228
00:08:31,360 --> 00:08:33,440
and we're seeing these companies in all

229
00:08:33,440 --> 00:08:34,799
parts of the world

230
00:08:34,799 --> 00:08:38,320
even though a lot of the services

231
00:08:38,320 --> 00:08:40,399
provided are being generated in

232
00:08:40,399 --> 00:08:42,320
southeast asia or russia

233
00:08:42,320 --> 00:08:44,240
we're seeing resellers and customer

234
00:08:44,240 --> 00:08:45,360
support and

235
00:08:45,360 --> 00:08:49,600
development in the west as well

236
00:08:51,120 --> 00:08:54,080
so social media manipulation we've tried

237
00:08:54,080 --> 00:08:55,360
to assess

238
00:08:55,360 --> 00:08:57,440
to what extent social media companies

239
00:08:57,440 --> 00:08:59,440
are able to counter the manipulation of

240
00:08:59,440 --> 00:09:00,640
their services

241
00:09:00,640 --> 00:09:02,640
how good they are and how big of a

242
00:09:02,640 --> 00:09:04,720
difference it is between the individual

243
00:09:04,720 --> 00:09:07,200
companies and we've done this in two

244
00:09:07,200 --> 00:09:10,640
consecutive reports in 2019 and 2020

245
00:09:10,640 --> 00:09:12,240
and we're now in the process of setting

246
00:09:12,240 --> 00:09:16,480
up an experiment for 2021

247
00:09:17,600 --> 00:09:21,519
and this of course is done to assess

248
00:09:21,519 --> 00:09:24,320
the ability of social media companies to

249
00:09:24,320 --> 00:09:26,240
combat inauthentic behavior

250
00:09:26,240 --> 00:09:30,480
on their platforms in 2019 we ran an

251
00:09:30,480 --> 00:09:31,279
experiment

252
00:09:31,279 --> 00:09:33,760
where we bought engagement during two

253
00:09:33,760 --> 00:09:34,320
months

254
00:09:34,320 --> 00:09:37,600
on 105 different posts on facebook

255
00:09:37,600 --> 00:09:40,959
instagram twitter and youtube in 2019 we

256
00:09:40,959 --> 00:09:41,360
bought

257
00:09:41,360 --> 00:09:44,399
54 000 fake engagement from these

258
00:09:44,399 --> 00:09:46,160
social media manipulation service

259
00:09:46,160 --> 00:09:48,080
providers

260
00:09:48,080 --> 00:09:51,040
and 3 000 comments more than 20 000

261
00:09:51,040 --> 00:09:52,080
likes

262
00:09:52,080 --> 00:09:56,080
and more than 20 000 views for 300 euros

263
00:09:56,080 --> 00:09:59,600
the equivalent in dollars and we ran

264
00:09:59,600 --> 00:10:01,680
re-ran this experiment during six weeks

265
00:10:01,680 --> 00:10:04,560
in october november 2020

266
00:10:04,560 --> 00:10:06,959
in the context of the u.s election and

267
00:10:06,959 --> 00:10:09,120
we then bought engagement on 39

268
00:10:09,120 --> 00:10:12,399
different posts also including tick tock

269
00:10:12,399 --> 00:10:15,760
last year we increased the number of

270
00:10:15,760 --> 00:10:17,720
engagements bought so we bought

271
00:10:17,720 --> 00:10:20,959
335 000 engagement still spending

272
00:10:20,959 --> 00:10:23,360
roughly 300 euros

273
00:10:23,360 --> 00:10:25,680
after buying this fake engagements we

274
00:10:25,680 --> 00:10:27,519
measured

275
00:10:27,519 --> 00:10:29,760
how much of it got through how much of

276
00:10:29,760 --> 00:10:31,040
it got blocked

277
00:10:31,040 --> 00:10:33,200
and when what happened when we reported

278
00:10:33,200 --> 00:10:36,800
it to the social media companies

279
00:10:36,800 --> 00:10:39,120
our main takeaway was that social media

280
00:10:39,120 --> 00:10:40,640
companies overall

281
00:10:40,640 --> 00:10:43,360
were unable to block the inauthentic

282
00:10:43,360 --> 00:10:45,279
engagement bot

283
00:10:45,279 --> 00:10:48,160
four weeks after purchase more than 98

284
00:10:48,160 --> 00:10:48,959
of the bot

285
00:10:48,959 --> 00:10:52,320
engagement were still online four days

286
00:10:52,320 --> 00:10:55,920
after reporting a sample of the

287
00:10:59,200 --> 00:11:03,120
accounts inaudible were still active

288
00:11:03,120 --> 00:11:06,000
our conclusion last year was that

289
00:11:06,000 --> 00:11:07,760
facebook instagram twitter

290
00:11:07,760 --> 00:11:10,480
youtube and tick tock are still failing

291
00:11:10,480 --> 00:11:12,000
to sufficiently combat

292
00:11:12,000 --> 00:11:15,519
inauthentic behavior on their platforms

293
00:11:15,519 --> 00:11:19,040
enabling the widespread disinformation

294
00:11:19,040 --> 00:11:22,079
and a dissemination of this information

295
00:11:22,079 --> 00:11:25,279
on their platforms

296
00:11:25,440 --> 00:11:26,959
we also looked at several of the

297
00:11:26,959 --> 00:11:29,040
parameters and

298
00:11:29,040 --> 00:11:31,600
that are very useful for understanding

299
00:11:31,600 --> 00:11:33,760
the scope and scale

300
00:11:33,760 --> 00:11:35,839
of this problem for an example we've

301
00:11:35,839 --> 00:11:38,000
tracked the cost of manipulating social

302
00:11:38,000 --> 00:11:39,600
media platforms

303
00:11:39,600 --> 00:11:43,279
from 2018 up until 2020 by

304
00:11:43,279 --> 00:11:46,480
creating baskets that

305
00:11:46,480 --> 00:11:50,959
contain like likes comments

306
00:11:50,959 --> 00:11:53,600
retweets etc and we've seen that a

307
00:11:53,600 --> 00:11:55,680
standardized basket

308
00:11:55,680 --> 00:11:59,440
from 2018 to 2019 and

309
00:11:59,440 --> 00:12:03,920
got cheaper and then from 2019 to 2020

310
00:12:03,920 --> 00:12:04,959
the prices

311
00:12:04,959 --> 00:12:07,040
in general leveled off but we can also

312
00:12:07,040 --> 00:12:08,399
see here that there's a difference

313
00:12:08,399 --> 00:12:09,279
between the

314
00:12:09,279 --> 00:12:12,000
various social media platforms that it

315
00:12:12,000 --> 00:12:14,000
differs between the companies

316
00:12:14,000 --> 00:12:16,639
how the prices have changed and why is

317
00:12:16,639 --> 00:12:17,760
the price

318
00:12:17,760 --> 00:12:20,480
interesting well we believe the prices

319
00:12:20,480 --> 00:12:20,959
is an

320
00:12:20,959 --> 00:12:23,200
indicator for how difficult it is to

321
00:12:23,200 --> 00:12:24,000
manipulate

322
00:12:24,000 --> 00:12:26,639
platforms the stronger security the

323
00:12:26,639 --> 00:12:27,760
platforms have

324
00:12:27,760 --> 00:12:29,519
the more difficult it will be to

325
00:12:29,519 --> 00:12:31,760
manipulate them the more it will cost

326
00:12:31,760 --> 00:12:34,079
the manipulation service providers

327
00:12:34,079 --> 00:12:35,920
and we're seeing that there isn't a

328
00:12:35,920 --> 00:12:38,000
fundamental change in the price

329
00:12:38,000 --> 00:12:39,440
but we're also seeing that there's a

330
00:12:39,440 --> 00:12:41,680
difference between the platforms

331
00:12:41,680 --> 00:12:43,440
regarding how difficult they are

332
00:12:43,440 --> 00:12:47,200
to manipulate we've also looked at the

333
00:12:47,200 --> 00:12:48,639
speed of delivery

334
00:12:48,639 --> 00:12:51,440
that is how quick or how fast you can

335
00:12:51,440 --> 00:12:52,079
manipulate

336
00:12:52,079 --> 00:12:55,279
social media platforms

337
00:12:55,279 --> 00:12:58,399
and if you take 2020 for an example

338
00:12:58,399 --> 00:13:00,399
we could see that for an example tick

339
00:13:00,399 --> 00:13:01,760
tock

340
00:13:01,760 --> 00:13:05,279
last year um was not sufficiently

341
00:13:05,279 --> 00:13:07,600
effective when it came to countering

342
00:13:07,600 --> 00:13:10,320
inauthentic bot behavior almost all of

343
00:13:10,320 --> 00:13:11,399
it were delivered

344
00:13:11,399 --> 00:13:14,160
instantaneously on tick tock while for

345
00:13:14,160 --> 00:13:15,279
example some

346
00:13:15,279 --> 00:13:18,160
of the other platforms about half of the

347
00:13:18,160 --> 00:13:19,200
content were

348
00:13:19,200 --> 00:13:21,680
delivered within 12 hours and then it

349
00:13:21,680 --> 00:13:23,839
took um

350
00:13:23,839 --> 00:13:26,639
in many cases several days before 100 of

351
00:13:26,639 --> 00:13:27,120
the bot

352
00:13:27,120 --> 00:13:29,360
engagement were delivered and of course

353
00:13:29,360 --> 00:13:31,519
the speed of delivery is an important

354
00:13:31,519 --> 00:13:32,480
indicator

355
00:13:32,480 --> 00:13:35,519
for how effective the platforms are at

356
00:13:35,519 --> 00:13:38,800
countering abuse of their services

357
00:13:38,800 --> 00:13:41,440
another indicator is the ability of the

358
00:13:41,440 --> 00:13:42,160
platforms

359
00:13:42,160 --> 00:13:45,920
to remove fake accounts reported to them

360
00:13:45,920 --> 00:13:49,199
and last year when we tested this um

361
00:13:49,199 --> 00:13:51,440
several of the platforms didn't remove

362
00:13:51,440 --> 00:13:53,120
any of the reported accounts

363
00:13:53,120 --> 00:13:56,000
the most effective platform facebook uh

364
00:13:56,000 --> 00:13:56,399
only

365
00:13:56,399 --> 00:13:58,639
removed nine percent or nine out of the

366
00:13:58,639 --> 00:14:00,399
100

367
00:14:00,399 --> 00:14:04,399
fake accounts that we reported to them

368
00:14:05,279 --> 00:14:06,800
overall our takeaway from these

369
00:14:06,800 --> 00:14:08,720
experiments have been that there is a

370
00:14:08,720 --> 00:14:09,519
significant

371
00:14:09,519 --> 00:14:11,279
difference between the different social

372
00:14:11,279 --> 00:14:12,639
media platforms

373
00:14:12,639 --> 00:14:14,320
the amount of money the amount of

374
00:14:14,320 --> 00:14:16,000
resources and the amount of

375
00:14:16,000 --> 00:14:18,720
human skill spent to directing and

376
00:14:18,720 --> 00:14:20,160
trying to combat

377
00:14:20,160 --> 00:14:22,959
platform manipulation makes a huge

378
00:14:22,959 --> 00:14:24,240
difference

379
00:14:24,240 --> 00:14:27,519
and we can see that when platforms

380
00:14:27,519 --> 00:14:30,639
make a concerted effort to try to change

381
00:14:30,639 --> 00:14:31,519
this

382
00:14:31,519 --> 00:14:34,000
we also see that it becomes harder to

383
00:14:34,000 --> 00:14:36,000
manipulate the platforms

384
00:14:36,000 --> 00:14:38,000
facebook has made progress during the

385
00:14:38,000 --> 00:14:39,600
last year for an example

386
00:14:39,600 --> 00:14:41,760
they've become much better even though

387
00:14:41,760 --> 00:14:43,680
we assessed that

388
00:14:43,680 --> 00:14:45,440
twitter is still the industry leader

389
00:14:45,440 --> 00:14:47,360
when it comes to countering abuse of

390
00:14:47,360 --> 00:14:49,360
their systems

391
00:14:49,360 --> 00:14:51,600
and tick tock which was a new platform

392
00:14:51,600 --> 00:14:52,560
last year

393
00:14:52,560 --> 00:14:55,680
scored at least well

394
00:14:55,680 --> 00:14:58,079
but we have reason to believe uh that

395
00:14:58,079 --> 00:15:00,160
they have improved during this year

396
00:15:00,160 --> 00:15:02,800
uh spending more efforts more resources

397
00:15:02,800 --> 00:15:04,959
on trying to improve themselves

398
00:15:04,959 --> 00:15:07,360
uh it will be interesting to see during

399
00:15:07,360 --> 00:15:08,959
the rerun of this experiment

400
00:15:08,959 --> 00:15:12,000
uh this year if this ranking stays

401
00:15:12,000 --> 00:15:15,360
or if we can see that um that some of

402
00:15:15,360 --> 00:15:17,199
these platforms which we suspect have

403
00:15:17,199 --> 00:15:18,720
put more effort into

404
00:15:18,720 --> 00:15:21,360
combating this problem also show a

405
00:15:21,360 --> 00:15:22,720
significant improvement

406
00:15:22,720 --> 00:15:26,880
in our measurements we have seen

407
00:15:26,880 --> 00:15:28,639
uh another interesting takeaway that

408
00:15:28,639 --> 00:15:30,480
we've seen is that there can even be a

409
00:15:30,480 --> 00:15:32,000
significant difference

410
00:15:32,000 --> 00:15:34,639
between um platforms owned by the same

411
00:15:34,639 --> 00:15:35,440
company

412
00:15:35,440 --> 00:15:37,600
and the best example is the significant

413
00:15:37,600 --> 00:15:39,120
difference between facebook

414
00:15:39,120 --> 00:15:42,720
and instagram instagram is much more

415
00:15:42,720 --> 00:15:43,199
easy

416
00:15:43,199 --> 00:15:45,839
to manipulate than facebook is and this

417
00:15:45,839 --> 00:15:47,519
is surprising

418
00:15:47,519 --> 00:15:51,199
one would think that um two platforms

419
00:15:51,199 --> 00:15:52,800
owned by the same company

420
00:15:52,800 --> 00:15:55,600
would have equal levels of security but

421
00:15:55,600 --> 00:15:57,360
this isn't the case at all

422
00:15:57,360 --> 00:16:01,199
um from creating fake accounts

423
00:16:01,199 --> 00:16:03,279
to buying fake engagement there's a

424
00:16:03,279 --> 00:16:04,880
clear difference between these two

425
00:16:04,880 --> 00:16:06,320
platforms

426
00:16:06,320 --> 00:16:08,560
and that illustrates that this is a

427
00:16:08,560 --> 00:16:11,040
technical problem to a large extent

428
00:16:11,040 --> 00:16:13,279
um when we ran this experiment two years

429
00:16:13,279 --> 00:16:14,639
ago we even saw

430
00:16:14,639 --> 00:16:17,839
on instagram that uh even when fake

431
00:16:17,839 --> 00:16:18,720
accounts

432
00:16:18,720 --> 00:16:21,680
that had delivered fake engagements were

433
00:16:21,680 --> 00:16:22,399
removed

434
00:16:22,399 --> 00:16:25,120
the fake engagement remained which of

435
00:16:25,120 --> 00:16:25,920
course is a

436
00:16:25,920 --> 00:16:29,600
technical issue with the platforms so

437
00:16:29,600 --> 00:16:32,480
to a large extent combating manipulation

438
00:16:32,480 --> 00:16:32,880
of

439
00:16:32,880 --> 00:16:35,120
social media platforms is a technical

440
00:16:35,120 --> 00:16:36,079
problem

441
00:16:36,079 --> 00:16:38,720
um that social media companies have to

442
00:16:38,720 --> 00:16:40,560
pour

443
00:16:40,560 --> 00:16:43,360
financial resources into solving and

444
00:16:43,360 --> 00:16:45,120
that hasn't been done

445
00:16:45,120 --> 00:16:49,279
enough before but we have seen

446
00:16:49,279 --> 00:16:52,240
from year to year from 2019 to 2020

447
00:16:52,240 --> 00:16:53,680
improvement

448
00:16:53,680 --> 00:16:56,160
but as it was at the end of last year

449
00:16:56,160 --> 00:16:58,240
when we ran this experiment

450
00:16:58,240 --> 00:17:00,240
the manipulation service providers were

451
00:17:00,240 --> 00:17:02,560
still winning by a large margin

452
00:17:02,560 --> 00:17:04,720
that is you could still effectively and

453
00:17:04,720 --> 00:17:06,799
cheaply buy manipulation

454
00:17:06,799 --> 00:17:09,919
and it would be speedily delivered onto

455
00:17:09,919 --> 00:17:11,599
social media platforms and it would

456
00:17:11,599 --> 00:17:12,240
remain

457
00:17:12,240 --> 00:17:15,439
up for weeks and weeks um

458
00:17:15,439 --> 00:17:17,679
to this day some of this fake

459
00:17:17,679 --> 00:17:18,959
engagements that we bought

460
00:17:18,959 --> 00:17:21,919
already back in 2019 remain active

461
00:17:21,919 --> 00:17:24,319
online

462
00:17:24,319 --> 00:17:27,520
so seeing this and studying the problem

463
00:17:27,520 --> 00:17:30,400
of this information and misinformation

464
00:17:30,400 --> 00:17:33,520
on social media we understand that

465
00:17:33,520 --> 00:17:35,520
inauthentic behavior is a central

466
00:17:35,520 --> 00:17:36,799
component

467
00:17:36,799 --> 00:17:39,840
of coordinated inauthentic behavior

468
00:17:39,840 --> 00:17:41,760
that is the coordinated spread of

469
00:17:41,760 --> 00:17:43,760
disinformation

470
00:17:43,760 --> 00:17:47,679
and one important solution for tackling

471
00:17:47,679 --> 00:17:48,400
that

472
00:17:48,400 --> 00:17:51,200
is through enhanced cyber security for

473
00:17:51,200 --> 00:17:52,799
social media companies

474
00:17:52,799 --> 00:17:54,960
protecting their platforms against

475
00:17:54,960 --> 00:17:56,720
technical abuse

476
00:17:56,720 --> 00:17:59,760
so in that sense social media cyber

477
00:17:59,760 --> 00:18:00,480
security

478
00:18:00,480 --> 00:18:03,520
equals election security because we're

479
00:18:03,520 --> 00:18:04,799
seeing that the spread of

480
00:18:04,799 --> 00:18:07,120
this information we're spread seeing

481
00:18:07,120 --> 00:18:08,400
that

482
00:18:08,400 --> 00:18:10,799
that intentional efforts to undermine

483
00:18:10,799 --> 00:18:12,720
the will and ability of voters

484
00:18:12,720 --> 00:18:15,679
to vote on election day and we're seeing

485
00:18:15,679 --> 00:18:16,480
that the

486
00:18:16,480 --> 00:18:18,720
intentional manipulation of political

487
00:18:18,720 --> 00:18:21,440
conversations on social media platforms

488
00:18:21,440 --> 00:18:25,200
um happen online and some of it also

489
00:18:25,200 --> 00:18:26,880
happens using

490
00:18:26,880 --> 00:18:29,919
bots and technical manipulation

491
00:18:29,919 --> 00:18:32,960
and that can easily be prevented

492
00:18:32,960 --> 00:18:35,840
with additional cyber security for the

493
00:18:35,840 --> 00:18:38,959
social media companies

494
00:18:39,830 --> 00:18:40,960
[Music]

495
00:18:40,960 --> 00:18:43,039
during last year's experiment we

496
00:18:43,039 --> 00:18:44,880
developed a number of recommendations

497
00:18:44,880 --> 00:18:47,840
for platforms and for policy makers

498
00:18:47,840 --> 00:18:50,080
um first of all of course the social

499
00:18:50,080 --> 00:18:51,760
media platforms need to do more to

500
00:18:51,760 --> 00:18:53,919
counter abuse of their services

501
00:18:53,919 --> 00:18:56,080
but also that we need to set standards

502
00:18:56,080 --> 00:18:57,360
and require

503
00:18:57,360 --> 00:18:59,760
reporting from the companies based on

504
00:18:59,760 --> 00:19:01,600
more meaningful criteria

505
00:19:01,600 --> 00:19:04,320
today it's very difficult to compare and

506
00:19:04,320 --> 00:19:06,080
contrast

507
00:19:06,080 --> 00:19:08,000
reports from different social media

508
00:19:08,000 --> 00:19:09,280
companies

509
00:19:09,280 --> 00:19:11,600
we also need to increase transparency

510
00:19:11,600 --> 00:19:12,559
and enable

511
00:19:12,559 --> 00:19:15,200
independent verification of figures

512
00:19:15,200 --> 00:19:17,679
reported by the social media companies

513
00:19:17,679 --> 00:19:20,000
and in the same way we need independent

514
00:19:20,000 --> 00:19:23,360
and well-resourced oversight

515
00:19:23,360 --> 00:19:25,679
we also need to regulate the market for

516
00:19:25,679 --> 00:19:27,120
social media manipulation

517
00:19:27,120 --> 00:19:30,320
we need to counter manipulation services

518
00:19:30,320 --> 00:19:32,160
to a much larger extent

519
00:19:32,160 --> 00:19:34,080
we have seen some important steps being

520
00:19:34,080 --> 00:19:36,799
taken by social media companies suing

521
00:19:36,799 --> 00:19:39,200
manipulation service providers and we've

522
00:19:39,200 --> 00:19:41,120
also seen a number of governments

523
00:19:41,120 --> 00:19:44,400
file charges but still today most of

524
00:19:44,400 --> 00:19:45,280
these

525
00:19:45,280 --> 00:19:48,320
core services remain online

526
00:19:48,320 --> 00:19:50,960
and some more needs to be done but we

527
00:19:50,960 --> 00:19:52,000
also need to understand

528
00:19:52,000 --> 00:19:53,600
that we need a whole of industry

529
00:19:53,600 --> 00:19:55,919
solution to combat this problem

530
00:19:55,919 --> 00:19:59,840
and from a cyber security standpoint

531
00:19:59,840 --> 00:20:02,799
if we take the case of the ukrainian

532
00:20:02,799 --> 00:20:04,480
security services

533
00:20:04,480 --> 00:20:06,799
we could see that these bot farms they

534
00:20:06,799 --> 00:20:08,159
heavily rely on

535
00:20:08,159 --> 00:20:10,240
sim cards and other telecommunication

536
00:20:10,240 --> 00:20:11,440
equipment

537
00:20:11,440 --> 00:20:13,840
and that of course means that regulation

538
00:20:13,840 --> 00:20:14,640
of this

539
00:20:14,640 --> 00:20:17,679
equipment of sim cards remains a

540
00:20:17,679 --> 00:20:19,360
critical component

541
00:20:19,360 --> 00:20:23,039
in combating the misuse of social media

542
00:20:23,039 --> 00:20:24,400
platforms

543
00:20:24,400 --> 00:20:27,280
but we also need to to make sure that

544
00:20:27,280 --> 00:20:28,960
social media companies spend more

545
00:20:28,960 --> 00:20:30,159
efforts

546
00:20:30,159 --> 00:20:33,039
preventing the abuse of their services

547
00:20:33,039 --> 00:20:34,880
so cyber security

548
00:20:34,880 --> 00:20:37,760
remains and will continue to be for the

549
00:20:37,760 --> 00:20:38,799
coming years

550
00:20:38,799 --> 00:20:40,799
a very critical component when it comes

551
00:20:40,799 --> 00:20:42,720
to election security

552
00:20:42,720 --> 00:20:44,320
especially in the field of

553
00:20:44,320 --> 00:20:47,200
disinformation and misinformation

554
00:20:47,200 --> 00:20:49,840
thank you

