1
00:00:05,839 --> 00:00:07,839
hey everybody i hope you're all doing

2
00:00:07,839 --> 00:00:10,080
well i hope you're all staying safe

3
00:00:10,080 --> 00:00:13,759
welcome to absec 101 at defcon 29's

4
00:00:13,759 --> 00:00:14,920
absec

5
00:00:14,920 --> 00:00:17,840
village over the next 30 minutes let's

6
00:00:17,840 --> 00:00:20,880
take a journey from engineer to hacker

7
00:00:20,880 --> 00:00:22,800
to appreciate the value that application

8
00:00:22,800 --> 00:00:25,920
security adds to modern secure software

9
00:00:25,920 --> 00:00:27,599
development

10
00:00:27,599 --> 00:00:29,439
but before we jump into it though i do

11
00:00:29,439 --> 00:00:31,279
want to call out that this is a 101

12
00:00:31,279 --> 00:00:32,479
level talk

13
00:00:32,479 --> 00:00:34,239
approachable to people who may be

14
00:00:34,239 --> 00:00:36,880
unfamiliar with application security

15
00:00:36,880 --> 00:00:38,879
it's what i like to call

16
00:00:38,879 --> 00:00:41,840
cyber fried chicken

17
00:00:41,840 --> 00:00:44,719
why do i call it that well let's just

18
00:00:44,719 --> 00:00:47,520
take a quick bite and find out

19
00:00:47,520 --> 00:00:49,520
just like you can eat a single chicken

20
00:00:49,520 --> 00:00:52,800
wing instead of tasted an eaten chicken

21
00:00:52,800 --> 00:00:54,239
it's just a small part of the whole

22
00:00:54,239 --> 00:00:56,399
chicken it's part of the whole bird

23
00:00:56,399 --> 00:00:57,920
you cannot say that you've eaten an

24
00:00:57,920 --> 00:00:59,120
entire chicken you cannot say you've

25
00:00:59,120 --> 00:01:01,120
eaten a lot of meat you've just had one

26
00:01:01,120 --> 00:01:02,960
or a couple of bites

27
00:01:02,960 --> 00:01:04,159
similarly

28
00:01:04,159 --> 00:01:05,680
this talk will give you a broad

29
00:01:05,680 --> 00:01:07,439
understanding of the field without

30
00:01:07,439 --> 00:01:09,040
diving too deep or pretending to give

31
00:01:09,040 --> 00:01:10,799
you the whole bird so in some sense

32
00:01:10,799 --> 00:01:13,119
we're just dipping our feet in the water

33
00:01:13,119 --> 00:01:14,080
also

34
00:01:14,080 --> 00:01:16,159
i love chicken wings and i just needed

35
00:01:16,159 --> 00:01:18,159
an excuse to pull that into the stock so

36
00:01:18,159 --> 00:01:20,880
here we are

37
00:01:20,880 --> 00:01:22,720
clucking along

38
00:01:22,720 --> 00:01:26,240
in this talk we will learn what absec is

39
00:01:26,240 --> 00:01:28,320
and how it is applied to secure software

40
00:01:28,320 --> 00:01:29,920
engineering

41
00:01:29,920 --> 00:01:31,600
we'll look at a fictional example of

42
00:01:31,600 --> 00:01:33,520
insecure core development

43
00:01:33,520 --> 00:01:36,000
and contrast that with sec devops or

44
00:01:36,000 --> 00:01:38,320
devsecops

45
00:01:38,320 --> 00:01:40,240
so we may all leave here with a better

46
00:01:40,240 --> 00:01:42,240
appreciation for the role that

47
00:01:42,240 --> 00:01:44,159
application security plays in modern

48
00:01:44,159 --> 00:01:46,159
software engineering

49
00:01:46,159 --> 00:01:47,520
but first

50
00:01:47,520 --> 00:01:50,640
a word from our sponsor

51
00:01:50,640 --> 00:01:52,560
have you ever felt like there were way

52
00:01:52,560 --> 00:01:55,360
too many social networks to keep tabs on

53
00:01:55,360 --> 00:01:57,040
like there needed to be a better

54
00:01:57,040 --> 00:01:59,439
consolidation of our feeds so we can

55
00:01:59,439 --> 00:02:00,399
spend

56
00:02:00,399 --> 00:02:02,880
less time in front of our screens and

57
00:02:02,880 --> 00:02:03,759
more

58
00:02:03,759 --> 00:02:06,640
out in the real world

59
00:02:06,640 --> 00:02:08,720
of course not

60
00:02:08,720 --> 00:02:10,000
presenting

61
00:02:10,000 --> 00:02:13,520
the newest anti-social network

62
00:02:13,520 --> 00:02:15,200
tatter

63
00:02:15,200 --> 00:02:18,239
tatter is launching soon on the web

64
00:02:18,239 --> 00:02:19,520
mobile

65
00:02:19,520 --> 00:02:20,480
ar

66
00:02:20,480 --> 00:02:21,360
vr

67
00:02:21,360 --> 00:02:23,040
and everywhere else your wi-fi network

68
00:02:23,040 --> 00:02:24,720
reaches

69
00:02:24,720 --> 00:02:26,720
sign up for an account or multiple

70
00:02:26,720 --> 00:02:28,879
accounts today

71
00:02:28,879 --> 00:02:30,160
tatter

72
00:02:30,160 --> 00:02:33,760
it's where your friends aren't

73
00:02:33,920 --> 00:02:36,160
now to be clear tatter is entirely made

74
00:02:36,160 --> 00:02:37,840
up it's not a real company it doesn't

75
00:02:37,840 --> 00:02:39,680
exist there is no alternative

76
00:02:39,680 --> 00:02:41,680
anti-social network

77
00:02:41,680 --> 00:02:43,120
called tatter

78
00:02:43,120 --> 00:02:44,400
regardless of whether arrested

79
00:02:44,400 --> 00:02:45,599
development would like you to believe

80
00:02:45,599 --> 00:02:47,519
that through the usage of hacker traps

81
00:02:47,519 --> 00:02:49,519
and other things like that there is such

82
00:02:49,519 --> 00:02:50,879
a thing

83
00:02:50,879 --> 00:02:52,959
in our case it's completely made up but

84
00:02:52,959 --> 00:02:54,640
we can use it as a very useful case

85
00:02:54,640 --> 00:02:57,599
study to see how the tattered team

86
00:02:57,599 --> 00:02:59,680
in one iteration cut corners and

87
00:02:59,680 --> 00:03:01,200
software development

88
00:03:01,200 --> 00:03:03,760
and the consequences of those actions

89
00:03:03,760 --> 00:03:05,440
and we usually only get this kind of

90
00:03:05,440 --> 00:03:07,840
hindsight with an equifax breach or a

91
00:03:07,840 --> 00:03:09,200
yahoo breach

92
00:03:09,200 --> 00:03:10,879
let's instead learn from tatter and

93
00:03:10,879 --> 00:03:12,640
their missteps

94
00:03:12,640 --> 00:03:14,800
then once we have seen that play out

95
00:03:14,800 --> 00:03:17,040
let's time travel back in time

96
00:03:17,040 --> 00:03:19,519
and fix things by ensuring that tatter

97
00:03:19,519 --> 00:03:21,599
follows abstract practices

98
00:03:21,599 --> 00:03:23,519
and extrapolate that story arc to see

99
00:03:23,519 --> 00:03:26,159
how it ends up

100
00:03:26,560 --> 00:03:27,440
now

101
00:03:27,440 --> 00:03:29,440
tattoos started as an anti-social

102
00:03:29,440 --> 00:03:31,519
network from an ivy league college where

103
00:03:31,519 --> 00:03:33,599
a bunch of students got together and

104
00:03:33,599 --> 00:03:36,480
started writing code from their dorms

105
00:03:36,480 --> 00:03:37,680
they were able to leverage their

106
00:03:37,680 --> 00:03:39,680
connections with venture capitalists to

107
00:03:39,680 --> 00:03:41,920
get funding to hire more engineers so

108
00:03:41,920 --> 00:03:44,560
that the vc is good as i emphasized it

109
00:03:44,560 --> 00:03:46,720
increased velocity

110
00:03:46,720 --> 00:03:49,200
freshly funded and on a full belly of vc

111
00:03:49,200 --> 00:03:50,159
money

112
00:03:50,159 --> 00:03:52,080
tatter hired engineers to add more

113
00:03:52,080 --> 00:03:55,360
features they added a dislike button

114
00:03:55,360 --> 00:03:58,480
photo uploads advanced search and many

115
00:03:58,480 --> 00:04:00,560
other features

116
00:04:00,560 --> 00:04:02,879
in the race to launch publicly

117
00:04:02,879 --> 00:04:04,879
many corners were cut

118
00:04:04,879 --> 00:04:06,959
technical debt accrued

119
00:04:06,959 --> 00:04:10,720
the focus was on velocity not veracity

120
00:04:10,720 --> 00:04:12,239
mistakes were made

121
00:04:12,239 --> 00:04:14,799
but they weren't caught yet

122
00:04:14,799 --> 00:04:16,320
as tattered grew

123
00:04:16,320 --> 00:04:18,880
they added a marketing department legal

124
00:04:18,880 --> 00:04:20,000
department

125
00:04:20,000 --> 00:04:23,120
and inevitably hr department

126
00:04:23,120 --> 00:04:24,880
limiting their engineering workforce to

127
00:04:24,880 --> 00:04:26,320
just developers

128
00:04:26,320 --> 00:04:27,680
they just wanted to focus on getting the

129
00:04:27,680 --> 00:04:29,440
product out the door

130
00:04:29,440 --> 00:04:30,800
things were looking good for a product

131
00:04:30,800 --> 00:04:32,800
launch soon the founders were happy the

132
00:04:32,800 --> 00:04:34,320
vcs were happy

133
00:04:34,320 --> 00:04:35,680
the engineers

134
00:04:35,680 --> 00:04:37,280
let's just say they were happy because

135
00:04:37,280 --> 00:04:40,160
this is all hypothetical anyway

136
00:04:40,160 --> 00:04:42,800
from a soft launch to an open launch

137
00:04:42,800 --> 00:04:44,800
tattoo saw increasing consumer usage and

138
00:04:44,800 --> 00:04:46,160
engagement

139
00:04:46,160 --> 00:04:48,320
in their first months they grew the user

140
00:04:48,320 --> 00:04:49,199
base

141
00:04:49,199 --> 00:04:52,160
all while it focused just on growth

142
00:04:52,160 --> 00:04:54,960
however as these things tend to play out

143
00:04:54,960 --> 00:04:56,880
one fine friday evening at four o'clock

144
00:04:56,880 --> 00:04:58,639
in the evening

145
00:04:58,639 --> 00:05:01,360
news broke that tatter was hacked

146
00:05:01,360 --> 00:05:03,360
the news spread like wildfire picked up

147
00:05:03,360 --> 00:05:05,440
by major news outlets

148
00:05:05,440 --> 00:05:07,840
the tata team would have to pay up their

149
00:05:07,840 --> 00:05:10,639
technical debt it seemed

150
00:05:10,639 --> 00:05:12,880
as news of the hack spread and as time

151
00:05:12,880 --> 00:05:14,479
went by

152
00:05:14,479 --> 00:05:16,880
we are now at a timeline ahead of when

153
00:05:16,880 --> 00:05:19,759
they were originally hacked hacked

154
00:05:19,759 --> 00:05:21,280
so let's spend a few minutes learning

155
00:05:21,280 --> 00:05:23,520
how tatter was hacked this will give us

156
00:05:23,520 --> 00:05:25,120
insight into everything that went wrong

157
00:05:25,120 --> 00:05:27,039
at tatter itself

158
00:05:27,039 --> 00:05:27,919
and

159
00:05:27,919 --> 00:05:29,440
to understand this better let's just

160
00:05:29,440 --> 00:05:30,800
look at a high level architecture

161
00:05:30,800 --> 00:05:34,000
diagram of everything that it involves

162
00:05:34,000 --> 00:05:35,680
tattoos just had

163
00:05:35,680 --> 00:05:37,440
a client so it was either a mobile

164
00:05:37,440 --> 00:05:39,840
client using the app or the browser on

165
00:05:39,840 --> 00:05:41,840
the desktop machine

166
00:05:41,840 --> 00:05:44,240
communicating using an api

167
00:05:44,240 --> 00:05:46,160
which allowed clients to interact with

168
00:05:46,160 --> 00:05:47,520
the backend

169
00:05:47,520 --> 00:05:50,160
in the back end we've simplified it here

170
00:05:50,160 --> 00:05:52,400
as a database which is where the user

171
00:05:52,400 --> 00:05:54,160
data is stored for the anti-social

172
00:05:54,160 --> 00:05:55,360
network

173
00:05:55,360 --> 00:05:56,960
now let's pick these apart piece by

174
00:05:56,960 --> 00:05:59,120
piece to see the entire kill chain of

175
00:05:59,120 --> 00:06:02,319
how they went from initial breach to

176
00:06:02,319 --> 00:06:04,240
outright ownage

177
00:06:04,240 --> 00:06:06,560
let's start with the mobile apps

178
00:06:06,560 --> 00:06:08,960
tatter was meant as a mobile first

179
00:06:08,960 --> 00:06:10,960
anti-social network

180
00:06:10,960 --> 00:06:12,639
the focus of the engineering team was

181
00:06:12,639 --> 00:06:15,280
around the mobile user experience with a

182
00:06:15,280 --> 00:06:17,039
lot of attention paid to the visual

183
00:06:17,039 --> 00:06:18,080
design

184
00:06:18,080 --> 00:06:19,680
more than the entire architectural

185
00:06:19,680 --> 00:06:21,759
design of the app itself

186
00:06:21,759 --> 00:06:24,000
as a result many shortcuts were taken to

187
00:06:24,000 --> 00:06:24,880
launch

188
00:06:24,880 --> 00:06:26,880
and get the apps reviewed and published

189
00:06:26,880 --> 00:06:28,800
on time

190
00:06:28,800 --> 00:06:32,240
one such shortcut was that the api key

191
00:06:32,240 --> 00:06:34,479
used to communicate with the back end

192
00:06:34,479 --> 00:06:36,319
using the tattoo api

193
00:06:36,319 --> 00:06:39,680
was stored in the code of the app itself

194
00:06:39,680 --> 00:06:41,600
as a string in the resources file in

195
00:06:41,600 --> 00:06:42,639
fact

196
00:06:42,639 --> 00:06:44,479
so when the app was published in the app

197
00:06:44,479 --> 00:06:46,080
stores

198
00:06:46,080 --> 00:06:47,440
especially on android you know you can

199
00:06:47,440 --> 00:06:49,280
download the apk and disassemble it to

200
00:06:49,280 --> 00:06:50,800
look inside it

201
00:06:50,800 --> 00:06:52,479
hackers did just that they got all of

202
00:06:52,479 --> 00:06:55,120
the apks they cracked it open

203
00:06:55,120 --> 00:06:56,880
they were able to extract the resources

204
00:06:56,880 --> 00:06:59,039
from reverse engineering the app package

205
00:06:59,039 --> 00:07:00,960
to find the api key because you can find

206
00:07:00,960 --> 00:07:03,520
strings inside the strings.xml file when

207
00:07:03,520 --> 00:07:06,240
you open up an apk file

208
00:07:06,240 --> 00:07:07,520
so they had

209
00:07:07,520 --> 00:07:09,680
one secret

210
00:07:09,680 --> 00:07:11,199
additionally let's look at let's look at

211
00:07:11,199 --> 00:07:12,560
the api

212
00:07:12,560 --> 00:07:14,880
when signing up for a tatter account the

213
00:07:14,880 --> 00:07:16,560
user is prompted to enter the email

214
00:07:16,560 --> 00:07:19,120
address as part of the sign up process

215
00:07:19,120 --> 00:07:20,880
we're all familiar with this is very

216
00:07:20,880 --> 00:07:22,160
normal

217
00:07:22,160 --> 00:07:23,440
however

218
00:07:23,440 --> 00:07:25,680
if an account already existed that used

219
00:07:25,680 --> 00:07:27,440
the same email address

220
00:07:27,440 --> 00:07:29,280
tatter would prompt the user to sign in

221
00:07:29,280 --> 00:07:30,479
instead

222
00:07:30,479 --> 00:07:31,759
even at this point we're feeling

223
00:07:31,759 --> 00:07:33,759
comfortable that okay it's information

224
00:07:33,759 --> 00:07:35,599
disclosure at some level but

225
00:07:35,599 --> 00:07:37,599
how bad can it be well

226
00:07:37,599 --> 00:07:39,520
the username was pre-populated that

227
00:07:39,520 --> 00:07:42,720
match the email address entered

228
00:07:42,720 --> 00:07:43,599
now

229
00:07:43,599 --> 00:07:45,360
even at this level if it feels like a

230
00:07:45,360 --> 00:07:47,599
convenience you realize that anybody can

231
00:07:47,599 --> 00:07:49,680
abuse the api and cycle through a bunch

232
00:07:49,680 --> 00:07:51,680
of email addresses and find the

233
00:07:51,680 --> 00:07:53,919
associated usernames

234
00:07:53,919 --> 00:07:56,560
and to use this api you need the api key

235
00:07:56,560 --> 00:07:58,240
hackers already had that from reverse

236
00:07:58,240 --> 00:07:59,919
engineering the mobile app

237
00:07:59,919 --> 00:08:00,720
so

238
00:08:00,720 --> 00:08:02,319
they were able to cycle through a bunch

239
00:08:02,319 --> 00:08:04,319
of email addresses find a bunch of

240
00:08:04,319 --> 00:08:05,440
usernames

241
00:08:05,440 --> 00:08:08,800
using the api which coincidentally was

242
00:08:08,800 --> 00:08:11,440
not rate rate limited it did not lock

243
00:08:11,440 --> 00:08:13,280
out after a bunch of fail login attempts

244
00:08:13,280 --> 00:08:14,160
either

245
00:08:14,160 --> 00:08:17,039
so using automation they could find

246
00:08:17,039 --> 00:08:18,639
many usernames

247
00:08:18,639 --> 00:08:20,560
and crack a bunch of passwords and

248
00:08:20,560 --> 00:08:22,400
password cracking they could have used

249
00:08:22,400 --> 00:08:23,919
password spring they could have used

250
00:08:23,919 --> 00:08:26,000
credential stuffing

251
00:08:26,000 --> 00:08:28,000
the point of the matter is

252
00:08:28,000 --> 00:08:30,800
with the api key and in security in the

253
00:08:30,800 --> 00:08:32,399
design itself

254
00:08:32,399 --> 00:08:33,760
without rate limiting and things like

255
00:08:33,760 --> 00:08:36,159
that they never had a bunch of usernames

256
00:08:36,159 --> 00:08:38,880
not starting from the emails

257
00:08:38,880 --> 00:08:40,399
and their passwords which they were able

258
00:08:40,399 --> 00:08:42,240
to crack

259
00:08:42,240 --> 00:08:44,159
now let's switch our attention back to

260
00:08:44,159 --> 00:08:46,800
the website a given user's profile on

261
00:08:46,800 --> 00:08:48,240
tata.com

262
00:08:48,240 --> 00:08:50,800
could be navigated to using the username

263
00:08:50,800 --> 00:08:54,320
so it was a url like data.com slash

264
00:08:54,320 --> 00:08:55,440
users

265
00:08:55,440 --> 00:08:57,360
slash username so slash jondo for

266
00:08:57,360 --> 00:08:59,279
example

267
00:08:59,279 --> 00:09:01,040
from the list they obtained by abusing

268
00:09:01,040 --> 00:09:02,720
the api

269
00:09:02,720 --> 00:09:05,680
now they had a list of usernames so

270
00:09:05,680 --> 00:09:07,440
they essentially had a list of urls that

271
00:09:07,440 --> 00:09:10,000
pointed to varied profile pages

272
00:09:10,000 --> 00:09:12,399
and again abusing the api without rate

273
00:09:12,399 --> 00:09:13,519
limiting

274
00:09:13,519 --> 00:09:15,360
hackers were able to scrape the profile

275
00:09:15,360 --> 00:09:17,360
pages of many users

276
00:09:17,360 --> 00:09:20,000
including that of site admins and the

277
00:09:20,000 --> 00:09:21,839
reason they were able to do this was the

278
00:09:21,839 --> 00:09:24,720
accounts registered to

279
00:09:24,720 --> 00:09:27,279
guessable email addresses like admin dot

280
00:09:27,279 --> 00:09:29,040
com the username may have been different

281
00:09:29,040 --> 00:09:30,640
but essentially were able to get that

282
00:09:30,640 --> 00:09:32,880
from the api itself

283
00:09:32,880 --> 00:09:35,360
and additionally the admin accounts many

284
00:09:35,360 --> 00:09:38,560
of them used poor password choices and

285
00:09:38,560 --> 00:09:40,320
they were easily cracked

286
00:09:40,320 --> 00:09:41,839
so hackers were able to sign into the

287
00:09:41,839 --> 00:09:43,279
admin accounts

288
00:09:43,279 --> 00:09:45,920
using just the username and password

289
00:09:45,920 --> 00:09:48,640
and view all profile metadata

290
00:09:48,640 --> 00:09:50,399
now you might be asking

291
00:09:50,399 --> 00:09:52,640
so what's the big deal if someone logs

292
00:09:52,640 --> 00:09:55,360
into a nascent anti-social network with

293
00:09:55,360 --> 00:09:57,519
username and password and you see five

294
00:09:57,519 --> 00:09:59,120
posts

295
00:09:59,120 --> 00:10:01,279
well password reuse is a problem so

296
00:10:01,279 --> 00:10:03,760
let's talk about source code

297
00:10:03,760 --> 00:10:05,440
a lot of the source code in fact all of

298
00:10:05,440 --> 00:10:07,120
the source code for tattered was hosted

299
00:10:07,120 --> 00:10:09,200
on the private github repo

300
00:10:09,200 --> 00:10:10,000
and

301
00:10:10,000 --> 00:10:12,720
the email addresses and the passwords

302
00:10:12,720 --> 00:10:14,560
used for github was the same as the ones

303
00:10:14,560 --> 00:10:16,959
they used on tata so they use both the

304
00:10:16,959 --> 00:10:18,720
emails and passwords

305
00:10:18,720 --> 00:10:21,440
between their header accounts and github

306
00:10:21,440 --> 00:10:24,480
and in the case of their github setup

307
00:10:24,480 --> 00:10:26,320
there was no two-factor or multi-factor

308
00:10:26,320 --> 00:10:28,240
authentication either

309
00:10:28,240 --> 00:10:30,000
so hackers were able to get access to

310
00:10:30,000 --> 00:10:31,760
the entirety of the source code for

311
00:10:31,760 --> 00:10:33,760
tatter product code internal

312
00:10:33,760 --> 00:10:36,560
infrastructure code everything

313
00:10:36,560 --> 00:10:38,000
and in there

314
00:10:38,000 --> 00:10:39,120
they found

315
00:10:39,120 --> 00:10:41,120
more nuggets they found database

316
00:10:41,120 --> 00:10:43,279
connection strings they found cloud

317
00:10:43,279 --> 00:10:45,360
storage account connection strings and

318
00:10:45,360 --> 00:10:46,399
other credentials

319
00:10:46,399 --> 00:10:49,600
so many other secrets in code and more

320
00:10:49,600 --> 00:10:52,079
using the newly discovered credentials

321
00:10:52,079 --> 00:10:55,120
hackers were ultimately able to breach

322
00:10:55,120 --> 00:10:58,079
access and exfiltrate the cloud stored

323
00:10:58,079 --> 00:11:00,720
customer data

324
00:11:00,720 --> 00:11:03,120
additionally reminiscent of the yahoo

325
00:11:03,120 --> 00:11:04,079
breach

326
00:11:04,079 --> 00:11:06,399
tatter also stored customer passwords as

327
00:11:06,399 --> 00:11:08,720
md5 hashes they did not use the most

328
00:11:08,720 --> 00:11:10,720
secure hashing algorithm

329
00:11:10,720 --> 00:11:13,680
so by exfiltrating the md5 hashes

330
00:11:13,680 --> 00:11:15,600
hackers were also able to crack a large

331
00:11:15,600 --> 00:11:17,760
number of customer passwords

332
00:11:17,760 --> 00:11:18,880
which

333
00:11:18,880 --> 00:11:20,800
we just re visited the problem of

334
00:11:20,800 --> 00:11:22,160
password reviews

335
00:11:22,160 --> 00:11:24,880
these parts were also invariably used in

336
00:11:24,880 --> 00:11:26,480
multiple other sites

337
00:11:26,480 --> 00:11:28,880
with these user accounts so you end up

338
00:11:28,880 --> 00:11:31,200
having the username and passwords for so

339
00:11:31,200 --> 00:11:34,320
many users not just on tattoo.com but

340
00:11:34,320 --> 00:11:35,760
potentially their banking websites and

341
00:11:35,760 --> 00:11:36,880
so on

342
00:11:36,880 --> 00:11:38,640
this was this is huge

343
00:11:38,640 --> 00:11:40,640
the case of the kingdoms was theirs and

344
00:11:40,640 --> 00:11:42,399
tattered did not have clue

345
00:11:42,399 --> 00:11:44,640
what was the outcome of all of this

346
00:11:44,640 --> 00:11:47,040
for trivia the photo on you see on

347
00:11:47,040 --> 00:11:49,519
screen is an image of the wildfires in

348
00:11:49,519 --> 00:11:52,160
california from last year as seen from

349
00:11:52,160 --> 00:11:54,720
the international space station

350
00:11:54,720 --> 00:11:57,120
you see all the smoke emanating from the

351
00:11:57,120 --> 00:11:58,880
forest which are on fire

352
00:11:58,880 --> 00:12:00,800
going off the coast

353
00:12:00,800 --> 00:12:02,800
into the pacific ocean

354
00:12:02,800 --> 00:12:04,800
and this is what happens when a fire

355
00:12:04,800 --> 00:12:07,279
goes unchecked till its impact is so

356
00:12:07,279 --> 00:12:09,040
massive

357
00:12:09,040 --> 00:12:11,120
now if you could anticipate that a

358
00:12:11,120 --> 00:12:12,720
certain set of actions was going to

359
00:12:12,720 --> 00:12:14,880
result in a massive wildfire

360
00:12:14,880 --> 00:12:16,320
now let's say you saw somebody lighting

361
00:12:16,320 --> 00:12:18,399
a match and you know they'd

362
00:12:18,399 --> 00:12:20,720
start a campfire which you could foresee

363
00:12:20,720 --> 00:12:22,720
would go out of control

364
00:12:22,720 --> 00:12:25,120
and set fire to the forest

365
00:12:25,120 --> 00:12:26,720
would you extinguish the flames when the

366
00:12:26,720 --> 00:12:28,800
match was less lit

367
00:12:28,800 --> 00:12:30,399
would you extinguish the flames when the

368
00:12:30,399 --> 00:12:32,639
campfire got out of control or would you

369
00:12:32,639 --> 00:12:34,399
wait till millions of acres were burning

370
00:12:34,399 --> 00:12:36,320
it is a rhetorical question but it has

371
00:12:36,320 --> 00:12:38,880
to be asked so we see tatter ended up in

372
00:12:38,880 --> 00:12:40,720
a bad place

373
00:12:40,720 --> 00:12:42,480
by russian new design

374
00:12:42,480 --> 00:12:45,440
by using insecure development practices

375
00:12:45,440 --> 00:12:47,519
poor implementation

376
00:12:47,519 --> 00:12:49,440
and ultimately for the sake of our

377
00:12:49,440 --> 00:12:51,200
discussion without an application

378
00:12:51,200 --> 00:12:53,279
security program let's switch gears and

379
00:12:53,279 --> 00:12:54,720
talk about the application security

380
00:12:54,720 --> 00:12:56,720
program itself let's talk about starting

381
00:12:56,720 --> 00:12:59,040
with a software development lifecycle

382
00:12:59,040 --> 00:13:01,120
the sdlc we're all aware of it

383
00:13:01,120 --> 00:13:02,800
we decompose the entire development

384
00:13:02,800 --> 00:13:04,560
process into stages

385
00:13:04,560 --> 00:13:06,399
traditionally in the case of a waterfall

386
00:13:06,399 --> 00:13:07,680
model which

387
00:13:07,680 --> 00:13:09,279
by the way the image you see on screen

388
00:13:09,279 --> 00:13:11,279
is that of multnomah falls just outside

389
00:13:11,279 --> 00:13:13,600
portland oregon

390
00:13:13,600 --> 00:13:16,240
the sdlc traditionally comprises

391
00:13:16,240 --> 00:13:18,240
an initial requirements phase followed

392
00:13:18,240 --> 00:13:20,399
by a development phase then a testing

393
00:13:20,399 --> 00:13:22,240
phase and then release

394
00:13:22,240 --> 00:13:24,079
in this traditional model testing

395
00:13:24,079 --> 00:13:26,560
especially security testing happens only

396
00:13:26,560 --> 00:13:28,160
if the product has been built to some

397
00:13:28,160 --> 00:13:30,800
degree of maturity and usability not

398
00:13:30,800 --> 00:13:31,839
earlier

399
00:13:31,839 --> 00:13:34,320
application security is a process of

400
00:13:34,320 --> 00:13:37,600
finding fixing and preventing security

401
00:13:37,600 --> 00:13:40,160
vulnerabilities at the application level

402
00:13:40,160 --> 00:13:41,680
as part of the software development

403
00:13:41,680 --> 00:13:43,199
process

404
00:13:43,199 --> 00:13:45,279
this manifests as multiple parallel

405
00:13:45,279 --> 00:13:47,920
processes that aim to find an address

406
00:13:47,920 --> 00:13:50,880
issues early in the stlc

407
00:13:50,880 --> 00:13:52,800
this is also called shifting left

408
00:13:52,800 --> 00:13:54,720
because we're essentially shifting the

409
00:13:54,720 --> 00:13:56,480
testing specifically the security

410
00:13:56,480 --> 00:13:57,920
testing part

411
00:13:57,920 --> 00:13:59,760
left in the stlc it doesn't happen

412
00:13:59,760 --> 00:14:02,000
specifically after development it runs

413
00:14:02,000 --> 00:14:04,800
in parallel with requirements gathering

414
00:14:04,800 --> 00:14:07,199
with design with development with

415
00:14:07,199 --> 00:14:09,279
testing there's aspects to each of these

416
00:14:09,279 --> 00:14:11,199
so we can catch issues early

417
00:14:11,199 --> 00:14:13,040
so we can extinguish the flames before

418
00:14:13,040 --> 00:14:14,800
we end up with a wildfire

419
00:14:14,800 --> 00:14:17,440
and here are some of the things that are

420
00:14:17,440 --> 00:14:19,040
generally part of an abstract program

421
00:14:19,040 --> 00:14:20,720
that we'll look at

422
00:14:20,720 --> 00:14:22,320
kind of at a high level but should give

423
00:14:22,320 --> 00:14:24,000
you an appreciation for the role that

424
00:14:24,000 --> 00:14:26,399
appsec plays in software development and

425
00:14:26,399 --> 00:14:28,000
an understanding of the processes

426
00:14:28,000 --> 00:14:31,000
themselves

427
00:14:31,040 --> 00:14:33,120
now let's travel back in time to when

428
00:14:33,120 --> 00:14:35,440
tatter began as an idea

429
00:14:35,440 --> 00:14:37,760
we saw how their lack of a knapsack

430
00:14:37,760 --> 00:14:41,360
program and insecure practices ended up

431
00:14:41,360 --> 00:14:42,720
so let's

432
00:14:42,720 --> 00:14:44,639
try out in the time machine

433
00:14:44,639 --> 00:14:46,720
let's infuse application security into

434
00:14:46,720 --> 00:14:48,639
their engineering processes

435
00:14:48,639 --> 00:14:50,480
and follow that development and see

436
00:14:50,480 --> 00:14:51,920
where they end up

437
00:14:51,920 --> 00:14:53,440
using some of the processes that an

438
00:14:53,440 --> 00:14:57,600
appsec program uses which we just saw

439
00:14:57,600 --> 00:14:59,920
we know there is a requirements phase

440
00:14:59,920 --> 00:15:02,240
as part of the sdlc similarly an

441
00:15:02,240 --> 00:15:04,720
application security program might have

442
00:15:04,720 --> 00:15:07,040
a security requirements phase where you

443
00:15:07,040 --> 00:15:08,160
have

444
00:15:08,160 --> 00:15:10,240
personas you have user stories you

445
00:15:10,240 --> 00:15:12,800
understand the security requirements and

446
00:15:12,800 --> 00:15:14,399
lock down

447
00:15:14,399 --> 00:15:16,079
security controls you understand to make

448
00:15:16,079 --> 00:15:18,000
sure that there are security controls

449
00:15:18,000 --> 00:15:20,639
i'll be very brief about this

450
00:15:20,639 --> 00:15:21,440
but

451
00:15:21,440 --> 00:15:25,360
the traditionally more prominent and

452
00:15:25,360 --> 00:15:27,680
aware parts of application security that

453
00:15:27,680 --> 00:15:29,920
people see especially engineers is i

454
00:15:29,920 --> 00:15:30,639
think

455
00:15:30,639 --> 00:15:32,959
things like thread modeling

456
00:15:32,959 --> 00:15:35,759
so as part of the system design

457
00:15:35,759 --> 00:15:38,320
since we're in tatter 2.0

458
00:15:38,320 --> 00:15:40,240
tattered developers and security

459
00:15:40,240 --> 00:15:42,959
engineers are collaborating on a threat

460
00:15:42,959 --> 00:15:45,680
modeling exercise to identify the key

461
00:15:45,680 --> 00:15:47,839
assets that need to be protected

462
00:15:47,839 --> 00:15:49,759
once you identify the assets

463
00:15:49,759 --> 00:15:51,920
you recognize trust boundaries between

464
00:15:51,920 --> 00:15:55,040
the internal assets and external actors

465
00:15:55,040 --> 00:15:57,279
and you ensure that appropriate controls

466
00:15:57,279 --> 00:16:00,160
exist to secure your assets against

467
00:16:00,160 --> 00:16:02,720
external threats

468
00:16:02,720 --> 00:16:04,320
now since we're working

469
00:16:04,320 --> 00:16:05,759
hand-in-hand between developers and

470
00:16:05,759 --> 00:16:08,240
security engineers to keep the content

471
00:16:08,240 --> 00:16:10,560
approachable to all collaborators

472
00:16:10,560 --> 00:16:12,560
a diagrammatic approach is used in the

473
00:16:12,560 --> 00:16:14,560
form of what's called a data flow

474
00:16:14,560 --> 00:16:16,480
diagram a dfd

475
00:16:16,480 --> 00:16:18,399
where the flow of data from external

476
00:16:18,399 --> 00:16:20,959
users through internal infrastructure is

477
00:16:20,959 --> 00:16:22,560
followed

478
00:16:22,560 --> 00:16:24,399
as the data flows from external to

479
00:16:24,399 --> 00:16:26,480
internal and potentially back you

480
00:16:26,480 --> 00:16:27,680
identify

481
00:16:27,680 --> 00:16:30,000
a bunch of security risks you identify a

482
00:16:30,000 --> 00:16:32,079
bunch of threats you identify

483
00:16:32,079 --> 00:16:33,920
controls to make sure those threats are

484
00:16:33,920 --> 00:16:36,880
monitored mitigated reduce eliminated

485
00:16:36,880 --> 00:16:38,959
and threat modelling is used to ensure

486
00:16:38,959 --> 00:16:41,199
that controls exist to prevent things

487
00:16:41,199 --> 00:16:43,120
such as spoofing

488
00:16:43,120 --> 00:16:45,519
tampering repudiation information

489
00:16:45,519 --> 00:16:46,800
disclosure

490
00:16:46,800 --> 00:16:50,480
denial of service elevation of privilege

491
00:16:50,480 --> 00:16:53,040
this the six that i have rattled off

492
00:16:53,040 --> 00:16:55,040
you can remember it using the stride

493
00:16:55,040 --> 00:16:57,759
acronym s for spoofing d for tampering

494
00:16:57,759 --> 00:17:00,160
or for repudiation eye for information

495
00:17:00,160 --> 00:17:02,720
disclosure d for denial of service and e

496
00:17:02,720 --> 00:17:05,280
for elevation of privilege

497
00:17:05,280 --> 00:17:07,280
once threat modelling is done as part of

498
00:17:07,280 --> 00:17:10,160
the original design part of the stlc and

499
00:17:10,160 --> 00:17:12,160
code starts being written

500
00:17:12,160 --> 00:17:14,079
code reviews come in handy to try to

501
00:17:14,079 --> 00:17:15,520
catch things early if they have been

502
00:17:15,520 --> 00:17:18,000
missed so far or to catch issues in

503
00:17:18,000 --> 00:17:20,319
business logic whether design secure but

504
00:17:20,319 --> 00:17:22,240
the implementation is flawed

505
00:17:22,240 --> 00:17:24,160
so code reviews are an essential part of

506
00:17:24,160 --> 00:17:26,079
any collaborative software development

507
00:17:26,079 --> 00:17:28,240
if you're writing code you're probably

508
00:17:28,240 --> 00:17:29,600
hopefully getting that code reviewed

509
00:17:29,600 --> 00:17:31,679
before you check things in

510
00:17:31,679 --> 00:17:32,960
and when you have code you think is

511
00:17:32,960 --> 00:17:34,720
ready to be checked in you seek review

512
00:17:34,720 --> 00:17:36,320
and approval from your peers that's

513
00:17:36,320 --> 00:17:38,640
normal for normal code review as well

514
00:17:38,640 --> 00:17:40,720
a security focus code review is more

515
00:17:40,720 --> 00:17:42,559
focused on the security controls it's

516
00:17:42,559 --> 00:17:44,400
not that security engineers are trying

517
00:17:44,400 --> 00:17:46,640
to understand the implementation itself

518
00:17:46,640 --> 00:17:49,760
but anything specific to security

519
00:17:49,760 --> 00:17:51,360
they want to make sure it's implemented

520
00:17:51,360 --> 00:17:54,240
correctly it's implemented in a standard

521
00:17:54,240 --> 00:17:55,919
way in a safe way

522
00:17:55,919 --> 00:17:57,200
this is where you try to catch things

523
00:17:57,200 --> 00:17:59,360
like custom crypto instead of using

524
00:17:59,360 --> 00:18:01,039
standardized cryptographic algorithms

525
00:18:01,039 --> 00:18:02,480
and libraries

526
00:18:02,480 --> 00:18:03,840
it's a very effective way to get an

527
00:18:03,840 --> 00:18:06,080
extra set of eyes or any new code that's

528
00:18:06,080 --> 00:18:08,639
being added

529
00:18:08,720 --> 00:18:10,320
now at this point

530
00:18:10,320 --> 00:18:11,760
we have gone through the requirements

531
00:18:11,760 --> 00:18:13,280
we've gone through threat modeling we've

532
00:18:13,280 --> 00:18:15,360
gone through a code review let's assume

533
00:18:15,360 --> 00:18:17,280
for some reason there's still things

534
00:18:17,280 --> 00:18:19,200
that are missing so tattoo's gone

535
00:18:19,200 --> 00:18:20,559
through things that hasn't done it at

536
00:18:20,559 --> 00:18:22,720
1.0 but it's running 2.0 it's caught a

537
00:18:22,720 --> 00:18:24,000
bunch of issues

538
00:18:24,000 --> 00:18:26,000
but nobody's perfect or should i say

539
00:18:26,000 --> 00:18:28,400
poor but is perfect so issues have

540
00:18:28,400 --> 00:18:29,520
gotten in

541
00:18:29,520 --> 00:18:31,360
and have been checked in

542
00:18:31,360 --> 00:18:33,280
now this is where you use something like

543
00:18:33,280 --> 00:18:36,000
a static application security testing

544
00:18:36,000 --> 00:18:38,240
tool suite or a sas

545
00:18:38,240 --> 00:18:39,760
so once the code's been committed to a

546
00:18:39,760 --> 00:18:41,280
product's code base

547
00:18:41,280 --> 00:18:42,960
additional sets of tools used to scan

548
00:18:42,960 --> 00:18:45,440
this code

549
00:18:45,520 --> 00:18:47,679
so a stash tool can be used to find

550
00:18:47,679 --> 00:18:49,440
security issues that might have been

551
00:18:49,440 --> 00:18:52,160
missed in code reviews so things like

552
00:18:52,160 --> 00:18:54,160
secrets in source which we'll get in a

553
00:18:54,160 --> 00:18:55,120
little bit

554
00:18:55,120 --> 00:18:56,960
um and that you will talk about that

555
00:18:56,960 --> 00:18:58,080
about how

556
00:18:58,080 --> 00:19:00,000
you can use regular expressions and

557
00:19:00,000 --> 00:19:02,400
entropy to try to find those things

558
00:19:02,400 --> 00:19:05,200
insecure query construction where you're

559
00:19:05,200 --> 00:19:07,039
not standardizing your user input we'll

560
00:19:07,039 --> 00:19:08,720
look at that as well

561
00:19:08,720 --> 00:19:10,559
and on screen you see the image where

562
00:19:10,559 --> 00:19:13,200
i've used a security windows product

563
00:19:13,200 --> 00:19:15,760
that scans github repos

564
00:19:15,760 --> 00:19:19,120
and i forked the os juice shop repo and

565
00:19:19,120 --> 00:19:21,039
i run the tool against it

566
00:19:21,039 --> 00:19:22,559
you can see it flags a whole host of

567
00:19:22,559 --> 00:19:24,559
security issues based on criticality

568
00:19:24,559 --> 00:19:26,960
classifies them as critical moderate in

569
00:19:26,960 --> 00:19:28,080
others

570
00:19:28,080 --> 00:19:30,720
it's also found secrets in source

571
00:19:30,720 --> 00:19:33,600
it has a bunch of other insights

572
00:19:33,600 --> 00:19:35,520
it's very useful to incorporate a sas

573
00:19:35,520 --> 00:19:37,280
tool as part of your

574
00:19:37,280 --> 00:19:39,919
continuous integration pipeline so as

575
00:19:39,919 --> 00:19:42,160
code gets committed in you're monitoring

576
00:19:42,160 --> 00:19:44,799
the hygiene of incoming code

577
00:19:44,799 --> 00:19:46,799
now what are some things that assass can

578
00:19:46,799 --> 00:19:47,919
catch

579
00:19:47,919 --> 00:19:49,919
one great example is

580
00:19:49,919 --> 00:19:52,240
memory safety issues especially when it

581
00:19:52,240 --> 00:19:54,960
comes to unsafe functions

582
00:19:54,960 --> 00:19:57,919
now the function might

583
00:19:57,919 --> 00:20:00,080
work logically but it might be flawed in

584
00:20:00,080 --> 00:20:01,919
its own internal implementation and

585
00:20:01,919 --> 00:20:03,200
these are things that could be a mess in

586
00:20:03,200 --> 00:20:04,799
the human code review

587
00:20:04,799 --> 00:20:05,760
so

588
00:20:05,760 --> 00:20:08,400
as an example the c function string copy

589
00:20:08,400 --> 00:20:11,200
strcpy which is used to copy a string

590
00:20:11,200 --> 00:20:13,120
from a source to a destination

591
00:20:13,120 --> 00:20:15,039
it is an unsafe function because it

592
00:20:15,039 --> 00:20:17,360
doesn't check if the destination has

593
00:20:17,360 --> 00:20:20,080
enough space to store the source string

594
00:20:20,080 --> 00:20:21,919
and if the source string is larger than

595
00:20:21,919 --> 00:20:24,320
the destination string buffer

596
00:20:24,320 --> 00:20:26,159
it'll overflow the bounce and this can

597
00:20:26,159 --> 00:20:27,679
lead to a buffer overflow which may be

598
00:20:27,679 --> 00:20:28,960
exploited

599
00:20:28,960 --> 00:20:31,520
so if such a documented unsafe function

600
00:20:31,520 --> 00:20:35,039
is used a sas tool was will flag it and

601
00:20:35,039 --> 00:20:38,000
there's steps to remediate this to use a

602
00:20:38,000 --> 00:20:39,600
more safe function

603
00:20:39,600 --> 00:20:43,039
so this is one class of bugs that can be

604
00:20:43,039 --> 00:20:45,440
found and stopped

605
00:20:45,440 --> 00:20:47,360
in fact mitral just came out with their

606
00:20:47,360 --> 00:20:49,919
list of the most critical

607
00:20:49,919 --> 00:20:51,919
bugs or vulnerabilities that have been

608
00:20:51,919 --> 00:20:54,240
used in recent past and

609
00:20:54,240 --> 00:20:56,400
buffer over buffer overflows or out of

610
00:20:56,400 --> 00:20:59,120
bound rights was the highest buy a long

611
00:20:59,120 --> 00:21:02,159
shot so if you can even cut down some

612
00:21:02,159 --> 00:21:03,760
some percentage of that

613
00:21:03,760 --> 00:21:05,919
it's better than nothing right you also

614
00:21:05,919 --> 00:21:07,840
have things like input sanitization

615
00:21:07,840 --> 00:21:08,880
where

616
00:21:08,880 --> 00:21:11,200
you're seeking input from a user and

617
00:21:11,200 --> 00:21:13,120
you're taking a space at face value

618
00:21:13,120 --> 00:21:14,080
without

619
00:21:14,080 --> 00:21:16,480
potentially sanitizing the input passing

620
00:21:16,480 --> 00:21:18,799
that in as a parameter or an argument to

621
00:21:18,799 --> 00:21:20,559
another function you're calling which

622
00:21:20,559 --> 00:21:22,799
could lead to unintended consequences

623
00:21:22,799 --> 00:21:24,720
this is how you end up with

624
00:21:24,720 --> 00:21:26,320
cross-site scripting this is how you end

625
00:21:26,320 --> 00:21:28,960
up with sql injection where you don't

626
00:21:28,960 --> 00:21:30,799
sanitize the input you don't create a

627
00:21:30,799 --> 00:21:34,480
parameter as query for example you don't

628
00:21:34,480 --> 00:21:36,480
get rid of the html content that could

629
00:21:36,480 --> 00:21:39,760
be passed in as textual input

630
00:21:39,760 --> 00:21:41,520
which you then potentially pass on to

631
00:21:41,520 --> 00:21:43,120
vulnerable functions

632
00:21:43,120 --> 00:21:45,200
so catching this class of issues as well

633
00:21:45,200 --> 00:21:46,240
because

634
00:21:46,240 --> 00:21:48,799
sqli and xss has been

635
00:21:48,799 --> 00:21:51,200
a fairly large scale

636
00:21:51,200 --> 00:21:52,799
set of issues

637
00:21:52,799 --> 00:21:54,640
for for a long time now

638
00:21:54,640 --> 00:21:55,520
and

639
00:21:55,520 --> 00:21:57,760
tools sas tools especially

640
00:21:57,760 --> 00:21:59,919
are able to flag some of these

641
00:21:59,919 --> 00:22:01,200
issues

642
00:22:01,200 --> 00:22:02,640
we've talked about secrets and code a

643
00:22:02,640 --> 00:22:04,480
few times now but why is this such a big

644
00:22:04,480 --> 00:22:05,840
deal

645
00:22:05,840 --> 00:22:08,320
for any or many intermediate processes

646
00:22:08,320 --> 00:22:10,320
that an app does security is a big part

647
00:22:10,320 --> 00:22:12,799
of those transactions and often the

648
00:22:12,799 --> 00:22:14,880
security depends on the uses of a secret

649
00:22:14,880 --> 00:22:17,280
of some sort so this could be an api key

650
00:22:17,280 --> 00:22:21,840
an ssh key an odd token etc

651
00:22:21,840 --> 00:22:23,760
committing any of these into source is

652
00:22:23,760 --> 00:22:25,679
dangerous due to how easily they may be

653
00:22:25,679 --> 00:22:28,720
found as we saw with tatter tatter had

654
00:22:28,720 --> 00:22:30,320
it in their mobile app they also had it

655
00:22:30,320 --> 00:22:32,720
in their private github repos

656
00:22:32,720 --> 00:22:35,120
to store these secrets securely

657
00:22:35,120 --> 00:22:37,280
use a key vault or a secret store which

658
00:22:37,280 --> 00:22:39,840
allows programmatic access and retrieval

659
00:22:39,840 --> 00:22:41,760
of the storage secrets versus hard

660
00:22:41,760 --> 00:22:44,559
coding it in in the code itself

661
00:22:44,559 --> 00:22:46,400
and the point here is there is no such

662
00:22:46,400 --> 00:22:49,039
thing as a partial secret compromise

663
00:22:49,039 --> 00:22:51,760
any accidentally disclosed keys need to

664
00:22:51,760 --> 00:22:53,679
be changed

665
00:22:53,679 --> 00:22:55,440
i will add even though it doesn't fall

666
00:22:55,440 --> 00:22:56,640
under the purview of application

667
00:22:56,640 --> 00:22:59,679
security per se the choice of strong

668
00:22:59,679 --> 00:23:02,080
secure pass phrases over weaker

669
00:23:02,080 --> 00:23:04,320
passwords

670
00:23:04,320 --> 00:23:06,240
enough with the password one two threes

671
00:23:06,240 --> 00:23:08,400
enough with the one two three four fives

672
00:23:08,400 --> 00:23:10,159
let me ins

673
00:23:10,159 --> 00:23:13,919
let's move to more secure passphrases

674
00:23:13,919 --> 00:23:16,080
additionally in today's complex

675
00:23:16,080 --> 00:23:18,320
interdependent software systems where

676
00:23:18,320 --> 00:23:21,280
your code interacts closely with other

677
00:23:21,280 --> 00:23:23,440
code from dependent libraries

678
00:23:23,440 --> 00:23:25,840
it's important to protect the full tree

679
00:23:25,840 --> 00:23:27,280
of dependencies

680
00:23:27,280 --> 00:23:28,880
it's possible that the code you wrote is

681
00:23:28,880 --> 00:23:31,039
secure but you are dependent on an

682
00:23:31,039 --> 00:23:33,280
insecure library

683
00:23:33,280 --> 00:23:36,400
software composition analysis sca is

684
00:23:36,400 --> 00:23:37,600
used to better understand the

685
00:23:37,600 --> 00:23:39,919
dependencies that your product uses

686
00:23:39,919 --> 00:23:41,600
and this is also something that a sas

687
00:23:41,600 --> 00:23:43,440
tool can find

688
00:23:43,440 --> 00:23:44,159
so

689
00:23:44,159 --> 00:23:46,880
once you have done

690
00:23:47,600 --> 00:23:50,080
sas scanning of code that's been checked

691
00:23:50,080 --> 00:23:50,880
in

692
00:23:50,880 --> 00:23:52,640
and you have

693
00:23:52,640 --> 00:23:54,159
through your continuous deployment

694
00:23:54,159 --> 00:23:56,320
pipeline a bill that contains these new

695
00:23:56,320 --> 00:23:59,279
changes or a version of it you can use

696
00:23:59,279 --> 00:24:00,880
we can move to something that's a little

697
00:24:00,880 --> 00:24:02,960
more dynamic in testing where you're

698
00:24:02,960 --> 00:24:04,400
actually testing the product as it's

699
00:24:04,400 --> 00:24:05,520
being run

700
00:24:05,520 --> 00:24:08,000
and one such thing is fuzzing and let's

701
00:24:08,000 --> 00:24:09,440
understand fuzzing with the joke which i

702
00:24:09,440 --> 00:24:10,799
read a while ago

703
00:24:10,799 --> 00:24:12,720
it goes this way

704
00:24:12,720 --> 00:24:15,200
a qa engineer walks into a bar and

705
00:24:15,200 --> 00:24:17,200
orders one beer

706
00:24:17,200 --> 00:24:18,640
two beers

707
00:24:18,640 --> 00:24:20,400
one hundred beers

708
00:24:20,400 --> 00:24:22,320
negative one beers

709
00:24:22,320 --> 00:24:24,320
one bear

710
00:24:24,320 --> 00:24:26,480
an actual customer walks into the same

711
00:24:26,480 --> 00:24:27,360
bar

712
00:24:27,360 --> 00:24:28,960
and asks the bartender where the

713
00:24:28,960 --> 00:24:30,880
restroom is located

714
00:24:30,880 --> 00:24:35,520
the bartender halts and catches fire

715
00:24:35,520 --> 00:24:37,840
fuzzing is the process of feeding a

716
00:24:37,840 --> 00:24:39,919
system unexpected input

717
00:24:39,919 --> 00:24:41,760
to see if can handle the unexpected

718
00:24:41,760 --> 00:24:43,520
input appropriately

719
00:24:43,520 --> 00:24:46,159
and if needed fails gracefully and

720
00:24:46,159 --> 00:24:47,279
safely

721
00:24:47,279 --> 00:24:49,600
so when you have a build of your

722
00:24:49,600 --> 00:24:51,360
application under test

723
00:24:51,360 --> 00:24:55,039
you can pass various sets of first input

724
00:24:55,039 --> 00:24:56,880
and there's multiple sets of tools that

725
00:24:56,880 --> 00:24:57,760
let you

726
00:24:57,760 --> 00:24:59,520
create first inputs

727
00:24:59,520 --> 00:25:01,039
whether it's an api or whether it's an

728
00:25:01,039 --> 00:25:04,000
actual set of inputs itself on the web

729
00:25:04,000 --> 00:25:05,919
app or any other app

730
00:25:05,919 --> 00:25:07,840
for any code really where it's taking

731
00:25:07,840 --> 00:25:10,000
input from a user instead of generating

732
00:25:10,000 --> 00:25:11,600
expected input you can generate

733
00:25:11,600 --> 00:25:13,279
unexpected input password and see what

734
00:25:13,279 --> 00:25:15,760
happens

735
00:25:15,760 --> 00:25:18,159
we've seen sas we've looked at

736
00:25:18,159 --> 00:25:20,240
a static application security tool what

737
00:25:20,240 --> 00:25:22,159
about a dash a dynamic application

738
00:25:22,159 --> 00:25:23,760
security testing tool

739
00:25:23,760 --> 00:25:25,120
since you have a build since you have a

740
00:25:25,120 --> 00:25:26,720
version you can play with

741
00:25:26,720 --> 00:25:29,840
you can scan it you can find out or try

742
00:25:29,840 --> 00:25:31,200
to find out

743
00:25:31,200 --> 00:25:33,520
using spidering all the different

744
00:25:33,520 --> 00:25:35,760
so places that you can interact with it

745
00:25:35,760 --> 00:25:38,000
you can try to

746
00:25:38,000 --> 00:25:40,799
use yourself fuzzing but not

747
00:25:40,799 --> 00:25:42,159
true fuzzing but there's a way of

748
00:25:42,159 --> 00:25:44,480
passing in a range of inputs to the

749
00:25:44,480 --> 00:25:46,000
application to see if it behaves

750
00:25:46,000 --> 00:25:50,159
differently and on screen we have one

751
00:25:50,159 --> 00:25:52,960
free open source popular

752
00:25:52,960 --> 00:25:56,240
intercepting proxy wasp zap the zed

753
00:25:56,240 --> 00:25:58,000
attack proxy

754
00:25:58,000 --> 00:26:00,240
there's also

755
00:26:00,240 --> 00:26:02,960
the proprietary but very popular burp

756
00:26:02,960 --> 00:26:04,000
suite

757
00:26:04,000 --> 00:26:06,400
and these are both intercepting http

758
00:26:06,400 --> 00:26:09,279
proxies where any requests from browser

759
00:26:09,279 --> 00:26:11,200
on that machine can be intercepted and

760
00:26:11,200 --> 00:26:12,559
you can

761
00:26:12,559 --> 00:26:14,159
at some level use it

762
00:26:14,159 --> 00:26:17,039
as a netcat ask tool where you can pass

763
00:26:17,039 --> 00:26:18,159
it into

764
00:26:18,159 --> 00:26:20,080
the repeater

765
00:26:20,080 --> 00:26:22,559
or the intruder and

766
00:26:22,559 --> 00:26:24,320
mess with the parameters or the request

767
00:26:24,320 --> 00:26:25,840
itself

768
00:26:25,840 --> 00:26:27,200
now we have seen

769
00:26:27,200 --> 00:26:28,720
starting with requirements threat

770
00:26:28,720 --> 00:26:30,559
modeling code review

771
00:26:30,559 --> 00:26:32,240
using sas using

772
00:26:32,240 --> 00:26:34,159
dynamic testing and fuzzing

773
00:26:34,159 --> 00:26:36,000
we're so far ahead of the curve compared

774
00:26:36,000 --> 00:26:37,760
to tatter 1.0

775
00:26:37,760 --> 00:26:41,120
and in this version of of tatter

776
00:26:41,120 --> 00:26:43,200
in this version of reality tattered

777
00:26:43,200 --> 00:26:44,880
launched successfully

778
00:26:44,880 --> 00:26:47,200
its customer data is kept secure thanks

779
00:26:47,200 --> 00:26:49,279
to early identification and remediation

780
00:26:49,279 --> 00:26:51,440
of security issues

781
00:26:51,440 --> 00:26:53,840
this was a result of a good application

782
00:26:53,840 --> 00:26:55,440
security program

783
00:26:55,440 --> 00:26:58,000
that worked with devops to prioritize

784
00:26:58,000 --> 00:26:59,840
product security

785
00:26:59,840 --> 00:27:03,760
and shift left successfully

786
00:27:03,760 --> 00:27:05,520
tattered was praised for as privacy and

787
00:27:05,520 --> 00:27:08,320
security and over time gained enough

788
00:27:08,320 --> 00:27:11,200
users and revenue to allow its ceo to

789
00:27:11,200 --> 00:27:13,200
purchase a ticket to space in the near

790
00:27:13,200 --> 00:27:15,360
future

791
00:27:15,360 --> 00:27:18,159
the outcome in tata 2.0 is that tata had

792
00:27:18,159 --> 00:27:20,159
a good run the second time around they

793
00:27:20,159 --> 00:27:22,640
had a successful laptop program

794
00:27:22,640 --> 00:27:24,720
that allowed them to find and fix

795
00:27:24,720 --> 00:27:27,600
security issues when the impact and cost

796
00:27:27,600 --> 00:27:29,200
were still low

797
00:27:29,200 --> 00:27:31,120
this was a far cry from the wildfire of

798
00:27:31,120 --> 00:27:32,720
tatter 1.0

799
00:27:32,720 --> 00:27:34,640
in summary

800
00:27:34,640 --> 00:27:37,120
and by the way this is a great bit of

801
00:27:37,120 --> 00:27:40,240
visualization from tanya's book alice

802
00:27:40,240 --> 00:27:42,880
and bob learn application security

803
00:27:42,880 --> 00:27:44,799
on the left you have essentially the

804
00:27:44,799 --> 00:27:46,640
flow of the sdlc starting with

805
00:27:46,640 --> 00:27:48,480
requirements designed through test and

806
00:27:48,480 --> 00:27:49,919
deployment

807
00:27:49,919 --> 00:27:51,520
on the right you have

808
00:27:51,520 --> 00:27:53,440
application security processes that

809
00:27:53,440 --> 00:27:56,320
occur in parallel with the stlc relevant

810
00:27:56,320 --> 00:27:58,399
to that stage of the sdlc so you have

811
00:27:58,399 --> 00:28:00,399
security requirements for design you

812
00:28:00,399 --> 00:28:02,640
have threat modeling design reviews

813
00:28:02,640 --> 00:28:04,880
for code you have code review and sas

814
00:28:04,880 --> 00:28:07,279
for testing you have sas dashed pen

815
00:28:07,279 --> 00:28:10,000
testing when you have more idea about

816
00:28:10,000 --> 00:28:11,279
and a deeper understanding of the

817
00:28:11,279 --> 00:28:13,200
product itself

818
00:28:13,200 --> 00:28:14,240
so

819
00:28:14,240 --> 00:28:16,320
by injecting and standing up in

820
00:28:16,320 --> 00:28:18,480
application security program

821
00:28:18,480 --> 00:28:21,279
parallel to your sdlc you're going to be

822
00:28:21,279 --> 00:28:23,200
much better off from a security

823
00:28:23,200 --> 00:28:24,799
standpoint

824
00:28:24,799 --> 00:28:26,080
a couple of other things i wanted to

825
00:28:26,080 --> 00:28:28,399
touch upon

826
00:28:28,399 --> 00:28:30,640
all the issues that we saw tatter have

827
00:28:30,640 --> 00:28:32,640
with their 1.0

828
00:28:32,640 --> 00:28:35,520
are part of what is known as the os top

829
00:28:35,520 --> 00:28:36,320
10

830
00:28:36,320 --> 00:28:40,159
the owasp organization owaspec stands to

831
00:28:40,159 --> 00:28:42,480
the open web application security

832
00:28:42,480 --> 00:28:43,679
project

833
00:28:43,679 --> 00:28:46,240
and it's an open source group of

834
00:28:46,240 --> 00:28:48,240
security volunteers who come together to

835
00:28:48,240 --> 00:28:49,360
identify

836
00:28:49,360 --> 00:28:52,080
the top threats to web applications they

837
00:28:52,080 --> 00:28:53,600
come to identify not just web

838
00:28:53,600 --> 00:28:56,000
applications but apis and other

839
00:28:56,000 --> 00:28:57,600
attack services as well

840
00:28:57,600 --> 00:28:58,960
they identify

841
00:28:58,960 --> 00:29:01,919
testing guidelines and the os top 10 is

842
00:29:01,919 --> 00:29:04,799
a list of the top 10 critical issues

843
00:29:04,799 --> 00:29:07,760
that that applica that web apps face on

844
00:29:07,760 --> 00:29:09,039
the web today

845
00:29:09,039 --> 00:29:11,600
and we saw things like um

846
00:29:11,600 --> 00:29:14,240
injection we saw things like

847
00:29:14,240 --> 00:29:16,240
authentication issues

848
00:29:16,240 --> 00:29:17,919
they're all part of the wasp top 10 so i

849
00:29:17,919 --> 00:29:19,600
highly recommend checking out the wasp

850
00:29:19,600 --> 00:29:22,080
top 10 list to understand

851
00:29:22,080 --> 00:29:23,919
the top 10

852
00:29:23,919 --> 00:29:25,440
critical

853
00:29:25,440 --> 00:29:26,799
vulnerabilities

854
00:29:26,799 --> 00:29:29,520
that your web app or api or someone can

855
00:29:29,520 --> 00:29:30,559
face

856
00:29:30,559 --> 00:29:32,240
another project i'd like to highlight

857
00:29:32,240 --> 00:29:35,039
from a wasp is the oauth juice shop

858
00:29:35,039 --> 00:29:37,760
and the owasp juice shop is

859
00:29:37,760 --> 00:29:40,000
a purposefully vulnerable web

860
00:29:40,000 --> 00:29:42,720
application based around an e-commerce

861
00:29:42,720 --> 00:29:45,120
marketplace so what it looks like

862
00:29:45,120 --> 00:29:46,559
think of this as

863
00:29:46,559 --> 00:29:49,120
like an online shopping website

864
00:29:49,120 --> 00:29:51,279
that is it has specific vulnerabilities

865
00:29:51,279 --> 00:29:52,480
for you to find

866
00:29:52,480 --> 00:29:55,120
almost like a ctf

867
00:29:55,120 --> 00:29:57,279
so here's an example

868
00:29:57,279 --> 00:29:58,559
there is

869
00:29:58,559 --> 00:30:00,799
what what they call a shenanigan

870
00:30:00,799 --> 00:30:03,520
you have multiple types corresponding to

871
00:30:03,520 --> 00:30:04,799
different

872
00:30:04,799 --> 00:30:06,960
points of the os top 10 so you have

873
00:30:06,960 --> 00:30:08,880
sensor data exposure you have

874
00:30:08,880 --> 00:30:11,120
cryptographic issues injection in

875
00:30:11,120 --> 00:30:13,279
security realization

876
00:30:13,279 --> 00:30:16,399
and in the in the os dew shop app

877
00:30:16,399 --> 00:30:17,520
you can

878
00:30:17,520 --> 00:30:19,919
use it as your own ctf at home to find

879
00:30:19,919 --> 00:30:22,000
these issues and what's even great about

880
00:30:22,000 --> 00:30:24,240
this is when you find one you can also

881
00:30:24,240 --> 00:30:25,679
look at the actual code that is

882
00:30:25,679 --> 00:30:27,919
vulnerable so for example here

883
00:30:27,919 --> 00:30:29,200
for this

884
00:30:29,200 --> 00:30:32,640
i for this xss vulnerability i see that

885
00:30:32,640 --> 00:30:35,039
there is a bypass security trust hml

886
00:30:35,039 --> 00:30:37,120
function which should not have been used

887
00:30:37,120 --> 00:30:38,240
because

888
00:30:38,240 --> 00:30:42,000
that is the root of that vulnerability

889
00:30:42,000 --> 00:30:44,799
and just for fun using the same

890
00:30:44,799 --> 00:30:47,200
vendors sas tool

891
00:30:47,200 --> 00:30:49,440
and for king zoo shop i ran it against

892
00:30:49,440 --> 00:30:51,919
the jew shop source code and i found a

893
00:30:51,919 --> 00:30:54,720
bunch of or the tool found a bunch of

894
00:30:54,720 --> 00:30:57,039
issues that found secrets in code one

895
00:30:57,039 --> 00:30:59,440
caveat i will call out about sas tools

896
00:30:59,440 --> 00:31:02,320
is that it tends to have or tends to

897
00:31:02,320 --> 00:31:04,480
surface false positives

898
00:31:04,480 --> 00:31:06,960
where you think they are actual issues

899
00:31:06,960 --> 00:31:08,960
but they are not and then there needs to

900
00:31:08,960 --> 00:31:10,640
be manual triage

901
00:31:10,640 --> 00:31:11,840
to find and

902
00:31:11,840 --> 00:31:13,840
validate that they are

903
00:31:13,840 --> 00:31:16,159
legitimate issues or not

904
00:31:16,159 --> 00:31:17,440
because you don't want to bombard the

905
00:31:17,440 --> 00:31:19,919
team the developer team with your 50

906
00:31:19,919 --> 00:31:21,200
bugs

907
00:31:21,200 --> 00:31:22,880
and it turns out maybe only four or five

908
00:31:22,880 --> 00:31:24,240
of them are actually legitimate and the

909
00:31:24,240 --> 00:31:25,600
others aren't

910
00:31:25,600 --> 00:31:27,919
here's another screenshot of a couple of

911
00:31:27,919 --> 00:31:29,360
the critical ones

912
00:31:29,360 --> 00:31:32,559
i i see that it says http data to sql

913
00:31:32,559 --> 00:31:34,080
database

914
00:31:34,080 --> 00:31:36,240
points out the line of code in the file

915
00:31:36,240 --> 00:31:38,880
open it up since it's a github project

916
00:31:38,880 --> 00:31:40,640
i see that

917
00:31:40,640 --> 00:31:43,120
a parameter from the request body is

918
00:31:43,120 --> 00:31:45,200
concatenated with

919
00:31:45,200 --> 00:31:47,360
or concatenated and added on to my

920
00:31:47,360 --> 00:31:49,760
database query so i can use sql

921
00:31:49,760 --> 00:31:51,279
injection to escape the rest of the

922
00:31:51,279 --> 00:31:53,600
query and exfiltrate data or get access

923
00:31:53,600 --> 00:31:55,679
to more data than was designed at that

924
00:31:55,679 --> 00:31:57,840
point

925
00:31:57,840 --> 00:31:59,919
it's also flagged bunch of secrets so

926
00:31:59,919 --> 00:32:03,440
for example in code there's a private

927
00:32:03,440 --> 00:32:05,120
rsa private key

928
00:32:05,120 --> 00:32:06,960
committed to code which is not a good

929
00:32:06,960 --> 00:32:09,600
idea we saw what happened header 1.0

930
00:32:09,600 --> 00:32:11,519
again these are the kinds of things that

931
00:32:11,519 --> 00:32:14,880
a sas tool can find out

932
00:32:14,880 --> 00:32:16,480
so having seen everything that we have

933
00:32:16,480 --> 00:32:17,760
seen for

934
00:32:17,760 --> 00:32:19,679
an application security program and how

935
00:32:19,679 --> 00:32:21,760
it parallels in stlc a couple more

936
00:32:21,760 --> 00:32:24,240
resources i wanted to leave you with

937
00:32:24,240 --> 00:32:26,799
tanya has a great book titled alice and

938
00:32:26,799 --> 00:32:29,440
bob learn application security

939
00:32:29,440 --> 00:32:31,600
it is a very well structured look at

940
00:32:31,600 --> 00:32:33,360
abstech from

941
00:32:33,360 --> 00:32:35,760
how you look at it from a design phase

942
00:32:35,760 --> 00:32:37,519
through the development phase to how you

943
00:32:37,519 --> 00:32:39,279
stand one up to how you apply to

944
00:32:39,279 --> 00:32:40,240
different

945
00:32:40,240 --> 00:32:43,760
types of applications themselves

946
00:32:43,760 --> 00:32:45,840
the the tangled web is an amazing

947
00:32:45,840 --> 00:32:48,559
amazing book as well which looks at

948
00:32:48,559 --> 00:32:52,559
web apps html not html web traffic and

949
00:32:52,559 --> 00:32:55,279
html some level http is what i wanted to

950
00:32:55,279 --> 00:32:57,279
say

951
00:32:57,279 --> 00:32:59,519
and when it comes to threat modeling

952
00:32:59,519 --> 00:33:01,440
adam shaw stack's book threat modeling

953
00:33:01,440 --> 00:33:03,760
designing for security is a very very

954
00:33:03,760 --> 00:33:05,360
well structured book to understand and

955
00:33:05,360 --> 00:33:07,360
ramp up and get familiar with threat

956
00:33:07,360 --> 00:33:10,000
modeling as an exercise

957
00:33:10,000 --> 00:33:11,519
i hope this session has given you a

958
00:33:11,519 --> 00:33:13,360
better appreciation for the value that

959
00:33:13,360 --> 00:33:15,440
application security adds especially

960
00:33:15,440 --> 00:33:17,440
when run parallel to secure software

961
00:33:17,440 --> 00:33:18,799
development

962
00:33:18,799 --> 00:33:20,000
to learn more

963
00:33:20,000 --> 00:33:22,159
please visit tatter.dev

964
00:33:22,159 --> 00:33:24,159
it includes the notes we've used so far

965
00:33:24,159 --> 00:33:25,360
including a transcript for

966
00:33:25,360 --> 00:33:29,279
internationalization and accessibility

967
00:33:29,279 --> 00:33:31,120
in closing i want to thank you for

968
00:33:31,120 --> 00:33:33,279
attending my talk

969
00:33:33,279 --> 00:33:36,159
take care stay safe and keep hacking

970
00:33:36,159 --> 00:33:39,399
thank you

971
00:33:52,399 --> 00:33:54,479
you

