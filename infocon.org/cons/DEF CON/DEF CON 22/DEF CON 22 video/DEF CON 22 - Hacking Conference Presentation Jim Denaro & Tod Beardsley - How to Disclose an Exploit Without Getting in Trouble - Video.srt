1
00:00:00,917 --> 00:00:06,917
>>	Hello... Alright, we're here.
Thank you so much for coming to
DEF CON and umm, also for coming

2
00:00:09,042 --> 00:00:15,333
to our talk here on how to
disclose and exploit without
getting in trouble. As an

3
00:00:15,333 --> 00:00:21,292
initial matter, you should know
that uh, I have to tell you I
guess. I'm an attorney >>	Boo.

4
00:00:21,292 --> 00:00:27,542
>>	Just put that (Laughing)
>>	Yay. >>	Actually I am an
attorney, I represent hackers.

5
00:00:27,542 --> 00:00:33,083
And uh one of the things I think
you might like about this talk,
I hope, is that, in addition to

6
00:00:33,083 --> 00:00:39,583
TOD's excellent portion of it.
Is that this not about the law.
It's not about what the law is.

7
00:00:39,583 --> 00:00:44,292
It's not about what the law
should be. I uh don't like going
to those talks myself. And I

8
00:00:44,292 --> 00:00:51,375
imagine you like them even less.
What this really about is it's
about trying to keep you safe,

9
00:00:51,375 --> 00:00:56,792
enabling you to continue to do
the research that you want to do
without getting in trouble. It's

10
00:00:56,792 --> 00:01:01,458
that simple. And there's
basically a few pointers that
we're trying to get across and

11
00:01:01,458 --> 00:01:06,708
some techniques and some ideas
about how research can be done
and how disclosure can be done

12
00:01:06,708 --> 00:01:12,625
that will increase the safety
for the research community. We
can't -- one of the things we're

13
00:01:12,625 --> 00:01:17,583
not going to be able to do is
completely eliminate risk. This
is sort of a risky business in a

14
00:01:17,583 --> 00:01:23,250
lot of ways. And what we can do
is manage it and we can be aware
of it and we can reduce it and

15
00:01:23,250 --> 00:01:29,292
mitigate it as much as we
possibly can. So with that said,
I should tell you this is part

16
00:01:29,292 --> 00:01:36,708
two of a talk I gave in a
20-minute slot here last year.
It's worth giving an update on,

17
00:01:36,708 --> 00:01:40,917
because some things have
happened since then. In
particular, the United States

18
00:01:40,917 --> 00:01:47,208
department of justice and their
computer crime section are now
actively engaging with the

19
00:01:47,208 --> 00:01:52,042
research community and they're
getting together. They're having
sit downs and they're looking

20
00:01:52,042 --> 00:01:57,792
for a way forward because they
recognize that there is
potentially a chilling effect to

21
00:01:57,792 --> 00:02:02,542
the way computer crime laws are
being interpreted and being
enforced. And they recognize

22
00:02:02,542 --> 00:02:07,625
there is a public good in
research that's going on and
they want to find a way to make

23
00:02:07,625 --> 00:02:13,958
sure that the bad guys or the
right bad guys, as we define
them, are deterred from doing

24
00:02:13,958 --> 00:02:20,958
bad stuff. But the good guys are
still enabled to continue to do
what they do. So as an initial

25
00:02:20,958 --> 00:02:26,958
matter, I should introduce. Oh
my God oh oh >>	I work at Rapid
7. I work mostly in metasploit.

26
00:02:30,667 --> 00:02:36,667
Maybe you heard of it. And I
deal with a lot of disclosure
issues all the time. We

27
00:02:39,500 --> 00:02:45,250
sometimes find our own 0-day and
then go through a disclosure
process that is pretty easy and

28
00:02:45,250 --> 00:02:50,417
straight forward. Sometimes
people come to us and say like
hey I have this awesome bug and

29
00:02:50,417 --> 00:02:57,583
I don't know what to do with it
and so we just kind of help them
say what we think they should do

30
00:02:57,583 --> 00:03:02,333
and sometimes people just drop
0-day on med display in the form
of a poll request so hurray um

31
00:03:02,333 --> 00:03:09,750
you know I think that approach
is totally effective at getting
some attention on it and it's

32
00:03:09,750 --> 00:03:13,833
probably the highest possible
risk you could take. Especially
if you are standing in a

33
00:03:13,833 --> 00:03:18,542
jurisdiction that shares
jurisdiction with the vendor
that you are dropping 0-day on

34
00:03:18,542 --> 00:03:24,875
and that could be a problem But
anyway, I'm Todd. That's my PGP
key the first one is the one

35
00:03:24,875 --> 00:03:32,167
that lived on my phone. So it's
okay. The second one lives on um
in here actually, it's here. So,

36
00:03:32,167 --> 00:03:38,167
good luck. And that's it. >>	So
my contact info is here as well
PGP, red phone, tech secure,

37
00:03:41,500 --> 00:03:49,292
sound circle, et cetera. Twitter
as well. Anything works. So this
again is an over view of what we

38
00:03:49,292 --> 00:03:54,958
are gunna cover here is two
types of risks, the risk that
comes from the activity, the

39
00:03:54,958 --> 00:03:59,833
research activity itself. And
then there's the risk that comes
on the back end when you

40
00:03:59,833 --> 00:04:04,625
disclose the research that maybe
no one else knew about before.
Risk mitigation strategies some

41
00:04:04,625 --> 00:04:09,917
ways you might be able to do
disclosure while keeping that
risk to a minimum. Overall the

42
00:04:09,917 --> 00:04:15,125
point of this is to make
yourself a harder target. Okay
so what are the kinds of the

43
00:04:15,125 --> 00:04:19,208
activities, it is always worth
getting this out there. What are
the activities that are

44
00:04:19,208 --> 00:04:23,042
potentially risky. They are on a
spectrum there are no real
answers there are some things

45
00:04:23,042 --> 00:04:28,292
that are probably not too risky
and there are some things that
are really they are much more

46
00:04:28,292 --> 00:04:33,625
risky. On the sort of less risky
end one might be changing an
ATTP query strain and seeing

47
00:04:33,625 --> 00:04:39,917
somebody's utility bill. This
seems like a relatively innocent
thing. Technically yes this

48
00:04:39,917 --> 00:04:43,792
could be a violation of the
computer fraud and abuse act. We
will get to why this is not a

49
00:04:43,792 --> 00:04:49,833
big risk for you if you do that.
But technically, this is
technically a violation of a law

50
00:04:49,833 --> 00:04:55,167
in almost any context. Another
example would be you find out
your neighbor's WiFi or no

51
00:04:55,167 --> 00:05:01,167
password and you're able to
access files and see some things
on that net work. A little more

52
00:05:03,750 --> 00:05:10,958
risky, you break some DRM or
write a better RAT and start
using it out there somehow. So

53
00:05:10,958 --> 00:05:15,583
the risk, the bad things that
could happen, your research
could get buried. You could be

54
00:05:15,583 --> 00:05:21,292
barred from disclosing it by
court order usually by a vendor
perhaps or there maybe some

55
00:05:21,292 --> 00:05:28,083
pressure from a government who
is also interested in this not
coming out. You might get sued

56
00:05:28,083 --> 00:05:34,125
and umm, you might accidentally
disclose a zero day. So all
these things happen, I don't

57
00:05:34,125 --> 00:05:42,125
want to put too negative a spin
on it. Because there are some
rewards for disclosure. As you

58
00:05:42,125 --> 00:05:48,125
can see, It's just not -- it's
not really that bad. Kind of.
But really just I think as we'll

59
00:05:51,333 --> 00:05:57,500
find out the best you're likely
to get is some recognition
hopefully, if we do it right,

60
00:05:57,500 --> 00:06:01,833
that'll be it. So the main thing
everyone's concerned about right
now is the computer fraud and

61
00:06:01,833 --> 00:06:07,125
abuse act, because there have
been some high profile
prosecutions of some members of

62
00:06:07,125 --> 00:06:14,125
the community that have a lot of
sympathy. And the sort of act
of, without going into the

63
00:06:14,125 --> 00:06:20,750
details of it because we don't
need to in for presentation, is
the meat of it, the ambiguity

64
00:06:20,750 --> 00:06:26,792
that causes so much trouble is
that what you need to do to
follow in this statute is to

65
00:06:26,792 --> 00:06:31,792
access someone else's system
without authorization or exceed
the authorization that you had

66
00:06:31,792 --> 00:06:35,917
been granted. And it's very hard
to figure out what is
authorization? How is it

67
00:06:35,917 --> 00:06:40,292
granted? Especially when you're
out in a public internet,
because we're not engaging in

68
00:06:40,292 --> 00:06:45,625
this back and forth, can I be
here? Okay. Come in, no you just
show up. That makes it really

69
00:06:45,625 --> 00:06:53,500
hard to answer the question. But
we can kind of break it down
into a simple checklist. If you

70
00:06:53,500 --> 00:06:57,333
can check all of these boxes,
there's going to be some risk.
Are you connected to your

71
00:06:57,333 --> 00:07:02,125
internet. Well if you are just
in your own box doing your own
thing, you might do something

72
00:07:02,125 --> 00:07:06,917
else that runs into trouble, but
at least you don't have this
problem. Are you accessing a

73
00:07:06,917 --> 00:07:12,625
remote system that's not yours?
Do you have permission to access
it? We don't know right, That's

74
00:07:12,625 --> 00:07:17,167
what we were just talking about.
And did you obtain information?
Probably did. Otherwise what

75
00:07:17,167 --> 00:07:24,875
happened? It's not a valid point
of being there if you didn't.
Here's some examples and this is

76
00:07:24,875 --> 00:07:30,875
really where people start
getting concerned. Because these
are not, the point of these

77
00:07:33,083 --> 00:07:37,917
cases is to give you an idea of
what kind of activities are to
be charged under the computer

78
00:07:37,917 --> 00:07:41,792
fraud and abuse act. In some of
the cases the charges were
ultimately dropped or dismissed

79
00:07:41,792 --> 00:07:47,333
or reversed on appeal and so on.
But this is not about the law,
this is about am I going to get

80
00:07:47,333 --> 00:07:52,708
arrested? And even if win in the
end, this it's already too late,
so what kind of things that get

81
00:07:52,708 --> 00:07:57,542
you in trouble in the first
place? Since we're in Vegas, a
good one to mention is the case

82
00:07:57,542 --> 00:08:04,375
of Nestor who exploited a bug in
video poker. And what he was
able to do is play one game. And

83
00:08:04,375 --> 00:08:08,875
switch into a bit up and switch
into another game and get out
these huge pay outs. He didn't

84
00:08:08,875 --> 00:08:13,125
actually connect anything into
the computer poker machine,
didn't change any code and

85
00:08:13,125 --> 00:08:17,375
didn't hack a machine. He caused
a code that was written for that
machine to execute the exactly

86
00:08:17,375 --> 00:08:22,958
the way it was supposed to
execute. It just gave out too
much money. He was charged under

87
00:08:22,958 --> 00:08:30,583
the computer fraud and abuse act
under a hacking statute for
that. There is another defendant

88
00:08:30,583 --> 00:08:35,000
that had other people use their
valid employee log in
credentials to obtain

89
00:08:35,000 --> 00:08:41,000
information from the first
gentleman's former employer. No
one hacked anything, but access

90
00:08:43,208 --> 00:08:47,958
was made to that system. Of
course there is the case of
Aaron Swartz who, among other

91
00:08:47,958 --> 00:08:55,833
things, spoofed his MAC address.
Andrew Auernheimer who had a
script to run queries on public

92
00:08:55,833 --> 00:09:01,375
facing API and get a lot of
e-mail addresses and then Jeremy
Hammond who pulled whole lot of

93
00:09:01,375 --> 00:09:06,083
e-mails out of Stratfor. These
are the type of activities that
you are the subject of high

94
00:09:06,083 --> 00:09:11,458
profile computer fraud and abuse
act prosecution. But there's
also the risk of civil

95
00:09:11,458 --> 00:09:18,208
prosecution. And ironically, you
are far more likely to be sued
on the civil side than by the

96
00:09:18,208 --> 00:09:24,208
criminal side. There's hundreds
and hundreds of cases where
employees, actually, get sued by

97
00:09:26,583 --> 00:09:31,500
their employers because the
employee has been terminated or
left for some other reason and

98
00:09:31,500 --> 00:09:37,833
decides to take some documents
with them. So this is, usually
there's some other trade secret

99
00:09:37,833 --> 00:09:42,500
claims, other intellectual
property claims that you see in
these cases but the computer

100
00:09:42,500 --> 00:09:48,500
fraud and abuse act gets loaded
on with that too. But, even
though some -- even though many

101
00:09:52,708 --> 00:09:58,708
of the activities that these
researchers were engaged in seem
to be just really basic things

102
00:10:01,750 --> 00:10:06,625
that you should be able to do,
why can't I query this public
facing API? I can do this all

103
00:10:06,625 --> 00:10:12,792
day long, that's not
unauthorized, they made it
available right? So no passwords

104
00:10:12,792 --> 00:10:18,375
were required to do it? But what
we find, what you'll see is that
in the cases that are getting

105
00:10:18,375 --> 00:10:23,000
actually getting prosecuted,
there are these aggravating
factors, these extenuating

106
00:10:23,000 --> 00:10:28,875
circumstances that make that
prosecution feasible and make it
happen. This is what we want to

107
00:10:28,875 --> 00:10:34,875
cover. We want to get to a point
where we know that if I do X, I
can not run into legal trouble.

108
00:10:38,208 --> 00:10:42,125
Well we could have another talk
with what that law might look
like. That's not the law we

109
00:10:42,125 --> 00:10:48,750
have. But none the less, we can
take the look at the cases that
are out there and see what these

110
00:10:48,750 --> 00:10:53,500
people did beyond just the
technical act. And this is where
you can reduce your risk,

111
00:10:53,500 --> 00:10:57,000
because even if you have to hit
that public facing API in order
to do the research, there may be

112
00:10:57,000 --> 00:11:01,750
no other way to find out if the
systems work. So you may have a
technical violation of the

113
00:11:01,750 --> 00:11:06,583
computer fraud and abuse act,
but the question is, is the DOJ
going to come and get you. In

114
00:11:06,583 --> 00:11:13,208
the case of video poker, this
guy didn't just find out this
bug, make a hundred bucks and

115
00:11:13,208 --> 00:11:18,250
say cool, and disclose it to the
vendor. He made, he pulled out
over half a million dollars of

116
00:11:18,250 --> 00:11:25,542
the machines to do that. Great,
great use of the exploit. But
that's going to, grab a, that's

117
00:11:25,542 --> 00:11:31,917
going to get some attention,
right? And in the case of
Nozzle, where you're -- he had

118
00:11:31,917 --> 00:11:36,708
used the -- he had other
employees in the company use
their valid credentials to

119
00:11:36,708 --> 00:11:41,875
download highly sensitive
documents that he was going to
use in a competitive way against

120
00:11:41,875 --> 00:11:44,542
his old employer. Aaron Swartz
entered the premises to connect
equipment. Maybe that certainly

121
00:11:44,542 --> 00:11:50,542
might not have been a
dispositive reason why the
prosecution continued, but it

122
00:11:53,042 --> 00:11:58,083
certainly heightens the stakes
when something like that
happens. Of course Andrew

123
00:11:58,083 --> 00:12:05,333
Auernheimer , famous as a troll,
that made him less sympathetic
as a defendant. And beyond that,

124
00:12:05,333 --> 00:12:10,083
he harvested over a hundred
thousand e-mail addresses. And
certainly far more were

125
00:12:10,083 --> 00:12:16,458
necessary to prove that, to make
his point that the system was
insecure. In the case of Jeremy

126
00:12:16,458 --> 00:12:23,083
Hammond the intentional
disclosure of the sensitive
documents for the point of

127
00:12:23,083 --> 00:12:29,083
making those documents public as
a statement. So there are some
-- in this context of this

128
00:12:31,208 --> 00:12:38,000
really over-broad statute that
everyone recognize sweeps in
legitimate security research and

129
00:12:38,000 --> 00:12:42,042
in light of these aggravating
factors that seem to get the
attention of the department of

130
00:12:42,042 --> 00:12:47,333
justice in bringing case, the
question is well what do we do?
What it's a take away? With

131
00:12:47,333 --> 00:12:54,667
respect to the research itself,
stick the proof of concept.
Don't go beyond that and hold

132
00:12:54,667 --> 00:13:00,542
down a hundred and ten thousand
e-mail addresses. Hold down ten
if that's what it is, and then

133
00:13:00,542 --> 00:13:06,792
you can do this responsible
disclosure as we'll get to in a
little bit. That'll keep it much

134
00:13:06,792 --> 00:13:12,208
safer, and makes it look like a
legitimate researcher and not
somebody with an agenda and or

135
00:13:12,208 --> 00:13:18,208
on a mission. In disclosing, be
professional. I can quote Mr.
Pink from Reservoir Dogs "We're

136
00:13:21,167 --> 00:13:27,167
supposed to be professionals
right? " I, keep it that way.
And in that regard, one of the

137
00:13:30,083 --> 00:13:36,417
things you really got to be
careful about, and this can't be
over emphasized, when you make a

138
00:13:36,417 --> 00:13:43,208
disclosure, don't ask for
anything, at all, Because then
it starts to look like

139
00:13:43,208 --> 00:13:48,792
extortion. I know even if
intentions are good, I'm sure
we've all heard many cases where

140
00:13:48,792 --> 00:13:55,042
this happened or been involved
in them yourselves where you
approach a vendor and they

141
00:13:55,042 --> 00:14:00,292
become very hostile to the
disclosure right off the bat.
And once you're in this

142
00:14:00,292 --> 00:14:05,667
adversarial relationship, it
could go bad quickly and to the
extent you've asked for

143
00:14:05,667 --> 00:14:12,125
anything. Even disclosure, if
you've asked a vendor to
disclose it even that could be

144
00:14:12,125 --> 00:14:15,917
taken as a threat. So nothing,
don't ask for money, don't ask
for recognition, don't ask for

145
00:14:15,917 --> 00:14:22,250
disclosure and don't is ask for
employment. Any of those things,
you're welcome too, to do that,

146
00:14:22,250 --> 00:14:26,917
of course, but these increase,
this is about we are trying to
decrease the risk of getting in

147
00:14:26,917 --> 00:14:34,375
trouble, that will decrease the
risk. You can ask for anything
you want. You get the risk that

148
00:14:34,375 --> 00:14:40,875
comes with that. Beyond that,
when you're making a disclosure,
not just to the vendor, but if

149
00:14:40,875 --> 00:14:45,083
you're blogging about something
you found, you want to talk
about it, there's some basic

150
00:14:45,083 --> 00:14:51,083
things you want to do that can
help keep it safe for you. Seems
kind of obvious, maybe, don't

151
00:14:53,750 --> 00:15:00,000
direct technique information if
someone you know might use it
illegally. That starts heading

152
00:15:00,000 --> 00:15:06,208
in the wrong direction for you.
In that vein, be careful
providing support. If someone

153
00:15:06,208 --> 00:15:12,792
has questions for you about
your, the vulnerability and
you're not sure exactly what

154
00:15:12,792 --> 00:15:17,750
their intentions are or who they
might be, I'd be very careful
about answering questions or

155
00:15:17,750 --> 00:15:24,792
discussing it further. A few
more points Don't, consider not
disclosing, not discussing it

156
00:15:24,792 --> 00:15:30,833
directly with individuals. Keep
it, the keep the public, so you
don't get, so you reduce the

157
00:15:30,833 --> 00:15:36,083
risk of having conspiracy with
other individuals. Don't prompt
it on forums that known to

158
00:15:36,083 --> 00:15:42,583
support or promote illegal
activity. Maybe disable comments
to avoid being in a conversation

159
00:15:42,583 --> 00:15:46,958
about it with somebody who might
be using it illegally. And then
of course, use secure

160
00:15:46,958 --> 00:15:52,958
communications as much as you
possibly can. (Accumulative
chatting.) >> Well go on >> Ah

161
00:15:59,500 --> 00:16:05,500
this is great. Do I get to too?
>> Oh you think so now	 Raise
your hand if you're a new

162
00:16:12,083 --> 00:16:18,083
speaker today. (Applause.) >>
	We're not kidding in the last
one there was a situation like

163
00:16:20,292 --> 00:16:26,333
this and the guy in your
position got Jack Daniels
spilled all over him. So we'll

164
00:16:26,333 --> 00:16:32,333
give that to you. >> 	Cheers >>
	To our first time speaker!
(Applause.) >>	Thank you.

165
00:16:38,000 --> 00:16:44,000
Delicious. Alright so going on
>>	Go ahead, keep doing your
thing >> 	Thank you, thank you

166
00:16:50,375 --> 00:16:56,375
so much. >>	Nice work,
congratulations >>	I promise I
am actually part of this talk

167
00:17:02,792 --> 00:17:08,792
>>	We will switch over in a
second. Some basic ideas about
disclosure here, you might want

168
00:17:12,000 --> 00:17:15,417
to think about whether or not
you've done everything right, as
you're making your disclosure.

169
00:17:15,417 --> 00:17:21,417
If you that, if you feel very
confident in the fact that you
haven't broken any law and

170
00:17:21,417 --> 00:17:26,583
nobody thinks you're breaking
any laws and your clearance is
not gunna be at risk. Go ahead

171
00:17:26,583 --> 00:17:32,542
and acknowledge your identity
and put it out there and have
the have at it. Absolutely,

172
00:17:35,000 --> 00:17:39,333
there's some others, we'll talk
about some additional ways that
can happen to do that

173
00:17:39,333 --> 00:17:43,667
responsibly. One of the things
you might want to consider if
you're a little bit concerned,

174
00:17:43,667 --> 00:17:51,500
but not terribly concern is to
offer that vulnerability up with
a, well we'll get into this in a

175
00:17:51,500 --> 00:17:57,500
minute. Let me hold off on that.
So, as we were saying, if you
aren't sure if you did

176
00:17:59,875 --> 00:18:06,042
everything right, you may want
to stay anonymous. I'll have
more about how to make that

177
00:18:06,042 --> 00:18:13,208
happen effectively. As a last
note, I want to introduce this
concept to everyone and get some

178
00:18:13,208 --> 00:18:19,208
feedback. The goal here is just
to get some feedback to the
community. One of the things I'm

179
00:18:19,208 --> 00:18:24,667
working on, in connection with
the good folks at Bug Crab, is
an open source responsible

180
00:18:24,667 --> 00:18:29,792
disclosure frame work. What
we're trying to do is
essentially create a procedure,

181
00:18:29,792 --> 00:18:37,542
a process that we can all kind
of agree on that will enable
researchers to continue to do

182
00:18:37,542 --> 00:18:43,208
their work, enable companies to
accept that work, and reduce the
risk. Again, it's about reducing

183
00:18:43,208 --> 00:18:46,375
the risk to researchers and
reducing the risk to the
companies so everyone can be

184
00:18:46,375 --> 00:18:52,583
comfortable with that and there
by promote the research. So you
can find this online if you

185
00:18:52,583 --> 00:18:59,542
Google That. The basic concept,
is that the company, whoever is
being pen tested essentially,

186
00:18:59,542 --> 00:19:04,833
publishes their scope ahead of
time. What kind of domains you
look at, what kind of tests you

187
00:19:04,833 --> 00:19:09,625
can run, what you can hit, what
you have to stay away from. The
researcher agrees to stay in

188
00:19:09,625 --> 00:19:14,583
scope ,of course. And that
includes avoiding pulling out
personal identifiable

189
00:19:14,583 --> 00:19:21,250
information, disruption to the
service, or whatever else the
company wants to keep off of.

190
00:19:21,250 --> 00:19:27,750
And in exchange for that, the
company agrees not to pursue
legal claims against the

191
00:19:27,750 --> 00:19:33,167
security researcher. And in
exchange for that, the vendor,
sorry the researcher will agree

192
00:19:33,167 --> 00:19:39,542
to keep the bug confidential for
a period of time until a patch
can be put in. So anyway we're

193
00:19:39,542 --> 00:19:45,542
just going down this road now
and kicking around these ideas
and we'd be delighted to hear

194
00:19:48,583 --> 00:19:54,583
any feedback that you might
have, and with that. >> Hello,
cool so, one of the things that

195
00:20:05,250 --> 00:20:10,750
you need to do if you're going
to be disclosing through an
attorney, as we, as I did a

196
00:20:10,750 --> 00:20:17,875
couple months ago. You have to
train your lawyer. I don't have
to train Jim at all. His name is

197
00:20:17,875 --> 00:20:24,250
Cyber Law on twitter he knows
kind of what he is doing. He's
got the text secured. He's got

198
00:20:24,250 --> 00:20:30,333
the red phone, and the PGP. I
asked him yesterday, so when you
go to your bar association

199
00:20:30,333 --> 00:20:36,708
barbecue, how often do you talk
about PGP and secure mail, he's
tells me it never ever comes up

200
00:20:36,708 --> 00:20:41,583
and this is a problem. So one
thing I want to do is figure
out, how do you train your

201
00:20:41,583 --> 00:20:49,125
lawyer? And so last year when
Jim presented, I saw his talk
and he said some things that I

202
00:20:49,125 --> 00:20:56,625
thought seem a little fishy. So
we worked out a procedure where
in we could pen test it, we

203
00:20:56,625 --> 00:21:02,625
could test drive it. How do I
disclose anonymously with my
attorney cut out? And the

204
00:21:06,708 --> 00:21:08,708
biggest thing I get out of that
is this notion of
attorney-client privilege, and

205
00:21:08,708 --> 00:21:14,292
umm, the idea is if I'm a
vulnerability researcher, I can
find my valn, I can see if that

206
00:21:14,292 --> 00:21:20,292
works. I can try not to violate
CFA too hard. And then hand it
over to my attorney. And say,

207
00:21:24,083 --> 00:21:30,083
here, you go. I need to talk to
these people. Don't mention my
name and if they ask you, say

208
00:21:32,958 --> 00:21:38,958
just no thanks. And this, we
believe, is fairly effective.
Unfortunately, we didn't get

209
00:21:41,083 --> 00:21:46,625
investigated or prosecuted by
anybody. So we really couldn't
get to that end point. So maybe

210
00:21:46,625 --> 00:21:54,417
next time we'll give the DOJ a
heads up or something. The
biggest thing we need to do

211
00:21:54,417 --> 00:22:02,375
though is, obfuscating the meta
data of the material you hand to
your attorney. When I do

212
00:22:02,375 --> 00:22:07,792
vulnerability disclosure, I'm
almost always am armed with a
metasploit module. One of the,

213
00:22:07,792 --> 00:22:15,292
if, if I hand over a metasploit
module to a vendor or cert CC or
whatever coordinating body I am

214
00:22:15,292 --> 00:22:22,917
handing it over, I'm pretty much
giving away who that author is.
It's a really great paper. It's

215
00:22:22,917 --> 00:22:29,667
the authorship analysis in cyber
crime investigation. It is the
tiny little URL there, but just

216
00:22:29,667 --> 00:22:35,667
Google it. You'll find it. It's
-- I think it's fairly seminal.
It gets cited a lot and it's all

217
00:22:38,167 --> 00:22:45,375
about authorship analysis. Some
people do -- sorry, some people
do like you know, they will just

218
00:22:45,375 --> 00:22:52,583
always have like a return faults
unless not, not, something.
Which is a bizarre way to say

219
00:22:52,583 --> 00:22:59,792
true, I think. I dunno it's
really hard, it gets uses and
this looks like a fingerprint.

220
00:22:59,792 --> 00:23:07,125
You can fingerprint people off
the code all the time. So first
step is don't provide proof of

221
00:23:07,125 --> 00:23:11,750
concept code unless you secure
this hold harmless clause,
because otherwise, if you open

222
00:23:11,750 --> 00:23:17,750
with that, you've given up the
game. So that's the big thing.
When you go down this path, the

223
00:23:31,125 --> 00:23:35,292
big thing you have to know is
your adversary. If you are going
against a uh, if you have a

224
00:23:35,292 --> 00:23:38,625
disclosure that you believe
would be interesting to the NSA,
don't talk on your phone, all

225
00:23:38,625 --> 00:23:41,958
that stuff. Don't talk on the
phone, don't get photographed
with your attorney, and don't do

226
00:23:41,958 --> 00:23:45,583
anything on your computer and
should probably just walk away.
There's very little you could do

227
00:23:45,583 --> 00:23:50,667
to defend against that
adversary. If you're merely
dealing with a litigious

228
00:23:50,667 --> 00:23:55,542
multinational corporation,
chances are good you can still
talk about this stuff on the

229
00:23:55,542 --> 00:24:01,542
phone as long as you're aware of
like where you are and who
you're with and your bosses is

230
00:24:04,000 --> 00:24:11,583
one cube over and maybe you're
dropping 0-day on your employer,
like don't do it at work,

231
00:24:11,583 --> 00:24:18,000
obviously. Which has happened,
we've had, I haven't had anybody
- not lately at least, I haven't

232
00:24:18,000 --> 00:24:25,458
had anybody at least drop 0-day
on their own employer, at least
through metasploit. If you're

233
00:24:25,458 --> 00:24:30,292
doing it on some free and open
source software project, again
you could probably talk on the

234
00:24:30,292 --> 00:24:34,542
phone, you could probably meet
up a lot. You could do a lot of
clear text e-mail. You don't

235
00:24:34,542 --> 00:24:41,833
have worry about PGP. It's a
shame PGP is so difficult. How
many people ever tried to teach

236
00:24:41,833 --> 00:24:47,833
a non-professional PGP and was
successful? Hey look at that.
That's like a solid half a

237
00:24:51,292 --> 00:24:58,292
percent? Yeah. Congrats.
(Laughing) just keep up that
good fight. Text secure and red

238
00:24:58,292 --> 00:25:04,958
phone are both fairly easy to
use. And umm, but they have
their own issues, by the way, if

239
00:25:04,958 --> 00:25:10,083
you try to text secure me, I
can't -- text secure believes
I'm a user of text secure so all

240
00:25:10,083 --> 00:25:16,083
I get cyber text so don't send
it, do it for Jim al day long.
If it's an important free open

241
00:25:20,000 --> 00:25:25,500
source software project, you
might want to tread a little
lightly cuz again, you may be

242
00:25:25,500 --> 00:25:31,500
attracting the attention of
things like the department of
homeland security, whatever the

243
00:25:34,958 --> 00:25:41,042
equivalent is in your home
country. You want to air on the
side of anonymity at least until

244
00:25:41,042 --> 00:25:47,125
you get a hold of this hold
harmless clause. But it all
comes down of taking some kind

245
00:25:47,125 --> 00:25:52,583
of reasonable precautions. You
don't have to be super cloak and
dagger about this. More is

246
00:25:52,583 --> 00:25:58,333
better, but it turns out, secure
communications is really hard,
me and Jim are both like pretty

247
00:25:58,333 --> 00:26:04,417
well versed in security. And we
screwed up like at least three
times. We totally gave away the

248
00:26:04,417 --> 00:26:11,208
game. We were using PGP and then
at one point, one of us, I'm not
naming any names, mentioned the

249
00:26:11,208 --> 00:26:17,292
vendor in the subject line of
the e-mail. Whoops, so like if
we were actually trying to like

250
00:26:17,292 --> 00:26:22,375
avoid attention with the NSA
that would have been not
greatest. Oh and the other

251
00:26:22,375 --> 00:26:27,792
unspoken adversary all the
people that like all the people
who like to drop docs on

252
00:26:27,792 --> 00:26:33,917
hackers. If you're 0-day in your
e-mail in the clear, you may
find that you get your stuff

253
00:26:33,917 --> 00:26:41,125
disclosed before you are
planning to, right? So moving
onto our case study, so this is

254
00:26:41,125 --> 00:26:48,500
a vulnerability that is present
in Yokagawa's Centium 3,000
Human Interface System, This is

255
00:26:48,500 --> 00:26:54,500
a piece of software. Yokogawa
makes a human interface system
disc data software that runs on

256
00:26:56,875 --> 00:27:04,458
Windows, like you do. It
controls things like really
expensive turbines and factory

257
00:27:04,458 --> 00:27:09,375
floors and all that stuff. It's
real popular in Japan, not so
much here, but they have a have

258
00:27:09,375 --> 00:27:15,375
a fair number of customers in
Europe, UK, I'm almost positive
in Russia and probably Ukraine.

259
00:27:19,833 --> 00:27:25,833
So, what this bug does is we've,
somebody, I'm not naming any
names, discovered this. And I've

260
00:27:28,625 --> 00:27:34,125
learned about it and said hey
Jim, I totally have an 0-day for
you. Let's test this process. So

261
00:27:34,125 --> 00:27:40,125
we did it. So we went through,
what happened was, let me back
up a little bit. You can see the

262
00:27:43,167 --> 00:27:47,250
details. I don't have to read
this slide to you. I think it's
published on the blog now. Yeah

263
00:27:47,250 --> 00:27:54,792
if you go there you will see all
the details on it. That's what I
was doing over here I was

264
00:27:54,792 --> 00:28:01,625
prepping it up and finishing it
up the blog. That was fun and
then drank. So our disclosure on

265
00:28:01,625 --> 00:28:07,958
this was sometime after the last
DEF CON, Rapid 7 and Jim we
entered into an attorney-client

266
00:28:07,958 --> 00:28:13,958
relationship. On April 14th, we
-- I'm obviously blowing Rapid
7's cover right now. But that's

267
00:28:18,250 --> 00:28:24,750
okay, because it's important to
show that we actually tried to
do this and it was really hard.

268
00:28:24,750 --> 00:28:30,750
On April 14th, I disclosed all
the details to my attorney. And
then we had some negotiation and

269
00:28:33,917 --> 00:28:38,625
back and forth on how we're
going to present this. And this
is where we came up with the

270
00:28:38,625 --> 00:28:44,375
whole authorship analysis thing.
And gee, we probably shouldn't
give the metasploit modules. One

271
00:28:44,375 --> 00:28:50,375
of the best things we did --
well let me back up a little bit
on, May 1st about two weeks

272
00:28:53,792 --> 00:28:59,292
later. We offered the details.
We, Jim, actually wrote to
Yokagawa offering details of

273
00:28:59,292 --> 00:29:06,042
this vulnerability in exchange
for some hold harmless thing.
Which by the way I don't know is

274
00:29:06,042 --> 00:29:13,208
this exchange for hold harmless
thing not extortion too? I don't
know. I don't know. Maybe it is.

275
00:29:13,208 --> 00:29:20,792
Like I'm going to promise not to
sue you and that extortion, I
don't know. But any way, they

276
00:29:20,792 --> 00:29:26,292
didn't reply at all. They didn't
get angry, they didn't demand to
know who it was, they just

277
00:29:26,292 --> 00:29:32,375
didn't say anything. And I'm
suspecting that when people get
random unsolicited

278
00:29:32,375 --> 00:29:36,625
communications from attorneys,
that is probably the way to go.
You don't -- maybe you don't

279
00:29:36,625 --> 00:29:42,083
want to talk to they will. But
we are offering this
vulnerability details on their

280
00:29:42,083 --> 00:29:47,083
software. But they were not -- I
don't know why they didn't
respond, but they didn't

281
00:29:47,083 --> 00:29:53,792
respond. On June 25th, after
giving them several weeks to
give us some kind of guidance on

282
00:29:53,792 --> 00:29:59,958
what they want to do with this,
we disclosed to Cert CC, not to
be confused with U.S. cert, they

283
00:29:59,958 --> 00:30:06,542
are totally different. We
disclosed to Cert CC. Fairly
complete details minus the

284
00:30:06,542 --> 00:30:12,542
metasploit module of course, but
we have a nice PDF about it and
talking about all the technical

285
00:30:16,833 --> 00:30:23,083
details of this bug. Which by
the way, the bug is, if you are
on the same net work as one of

286
00:30:23,083 --> 00:30:29,083
these things, you can use some
undocumented UDP based commands
to rewrite the file system that

287
00:30:31,250 --> 00:30:38,792
is all, so it's pretty good. And
so then today, details got
published right there. I did it.

288
00:30:38,792 --> 00:30:44,792
So here's some source code.
Because it's not a DEF CON talk
without source code, I'm going

289
00:30:46,958 --> 00:30:52,875
to step through every line. So
hang on. You can read about it
yourself. It's up on the blog,

290
00:30:52,875 --> 00:30:59,708
up on Github. It's merged to
master right now. If you happen
to have access and authorization

291
00:30:59,708 --> 00:31:06,292
to own some Yokagawa gear,
you're -- today's a good day for
you. This is a disclosure doc we

292
00:31:06,292 --> 00:31:12,292
sent to Cert. Like I said, it
details out fairly completely
what the vulnerability is like

293
00:31:19,542 --> 00:31:24,125
hey maybe you should put some
communication mechanism in front
of these like store and reter

294
00:31:24,125 --> 00:31:28,875
commands instead of just like
letting them get run. And umm,
the surprising thing to me was,

295
00:31:28,875 --> 00:31:32,500
I wasn't super surprised that
Yokogawa didn't reply, I was
surprised that we didn't get

296
00:31:32,500 --> 00:31:37,000
much response from Cert for
this. I deal with cert a lot as
under my own name, but Jim I

297
00:31:37,000 --> 00:31:44,458
guess doesn't deal with cert too
much so maybe they don't know
who this dude is and maybe they

298
00:31:44,458 --> 00:31:50,458
think it's a scam or something
like that. But we didn't get any
reply from them. I'm super

299
00:31:52,667 --> 00:31:58,667
curious to talk to them almost
immediately after this talk. And
I was hoping Art would be here

300
00:32:00,875 --> 00:32:06,875
but he's not. Anyone work at
cert CC? No? Aw guys, gosh you
should totally come. Well I'll

301
00:32:10,625 --> 00:32:16,625
hook up with him later. And I
think that's it for my part.
I've already disclosed one. You

302
00:32:19,042 --> 00:32:26,625
can see what it is. Obviously by
disclosing it I'm blowing my
cover, but the point of this

303
00:32:26,625 --> 00:32:31,458
particular flavor of anonymity
is that we wanted to keep -- we
wanted to be able to give this

304
00:32:31,458 --> 00:32:36,917
talk and be able to disclose a
vulnerability. Imagine I just
did a whole long boring talk

305
00:32:36,917 --> 00:32:44,125
about Yokogawa. I want to be
able to do that. The point is
it's not anonymity forever. It's

306
00:32:44,125 --> 00:32:50,292
anonymity for three months or
four months or something like
that. That's fairly useful for

307
00:32:50,292 --> 00:32:56,292
people in our community. So if
you have bugs to disclose, feel
free to tell me. Maybe retain

308
00:32:59,917 --> 00:33:06,167
Jim he was super cheap.
(Laughing) in fact, I think I
make money out of this deal

309
00:33:06,167 --> 00:33:11,708
because I'm the co-speaker too.
But yeah, that's all I got.
Anybody have any questions?

310
00:33:11,708 --> 00:33:17,708
Please go to the mic in the
middle. Ya know climb over all
each other to do it and uh riot.

311
00:33:23,500 --> 00:33:29,708
>>	So Jim, you know this, the
hold harmless agreements don't
bind criminal prosecution. And

312
00:33:29,708 --> 00:33:34,500
lawyers are prohibited from
using privilege to protect
conspiracy to do criminal

313
00:33:34,500 --> 00:33:40,500
activity. Doesn't this just
mostly kind of theoretically
protect against the DOJ and then

314
00:33:40,500 --> 00:33:46,208
they are still gunna smack you
around? >>	That's a fair point.
It's not possible for anyone

315
00:33:46,208 --> 00:33:51,500
except the department itself to
say, okay, we're not going to
pursue this accident. And even

316
00:33:51,500 --> 00:33:57,458
then, I've spoke with the people
in the department, that said can
we come -- can we create even a

317
00:33:57,458 --> 00:34:02,417
no action letter sort of thing
where we would be able to, the
department would say, we don't

318
00:34:02,417 --> 00:34:06,375
think, it would be great if you
had a letter from the department
of justice, we don't think port

319
00:34:06,375 --> 00:34:13,958
scanning is a crime. That's all
you do is port scanning. This is
okay, you can't even get that.

320
00:34:13,958 --> 00:34:19,000
So for sure, even if you have
this agreement with Yokagawa or
whoever it happens to be, give

321
00:34:19,000 --> 00:34:26,917
us the deets on this bug and we
promise that we're not going to
sue you. But it can go further.

322
00:34:26,917 --> 00:34:31,625
It says we don't sue you, we
don't chase you down assuming
you are not misrepresenting what

323
00:34:31,625 --> 00:34:34,458
you did if you did something
really nasty and you're not
telling me about you're telling

324
00:34:34,458 --> 00:34:38,000
me you did this but you actually
did that then of course the
agreement is not going to fly.

325
00:34:38,000 --> 00:34:41,792
But if you're being honest with
me and your telling me you did
this or you didn't do whatever

326
00:34:41,792 --> 00:34:47,208
the bad thing is that we think
you might have done. We're not
going to come after you

327
00:34:47,208 --> 00:34:50,833
ourselves. They can go a little
bit farther and say we're not
going to support a prosecution

328
00:34:50,833 --> 00:34:56,667
by the department of justice.
And that makes a big difference.
Because you know >> And

329
00:34:56,667 --> 00:35:00,583
subpoena, but JSTOR didn't
support the Aaron Swartz
prosecution and look where that

330
00:35:00,583 --> 00:35:06,458
ended up. But MIT did. So that's
the difference. When -- so the
cases come out in a couple

331
00:35:06,458 --> 00:35:10,750
different ways , CCIPS the
computer Crime and Intellectual
Property Section of the

332
00:35:10,750 --> 00:35:14,750
department of justice can do its
own investigation if it has
reason to believe something's

333
00:35:14,750 --> 00:35:19,958
going on. Or some aggrieved
party comes whining to the
department saying these people

334
00:35:19,958 --> 00:35:25,083
are hacking my system and you
need to do something about it.
If you are AT&T and do that the

335
00:35:25,083 --> 00:35:32,000
department is gunna listen. If
you don't go to them, the
department is not, no one can

336
00:35:32,000 --> 00:35:37,000
promise. That's the thing no one
can ever promise. But I sit down
with folks from DOJ and they

337
00:35:37,000 --> 00:35:43,042
tell me we're not out there
hunting the internet for people
who are doing slightly fishy

338
00:35:43,042 --> 00:35:48,458
stuff. So it's risk right? It's
risk at where you draw the line
But we can -- the best we can do

339
00:35:48,458 --> 00:35:56,042
is reduce the risk so people can
continue to do the research.
>>	So if I find an exploit I can

340
00:35:56,042 --> 00:35:59,167
hit you up and you're gunna do
it for free, because I know my
local lawyer is gunna be like

341
00:35:59,167 --> 00:36:04,417
what are you talking about and
ya know I have a thousand dollar
retainer. How are we expected to

342
00:36:04,417 --> 00:36:09,875
go out and find an attorney to
do this? Because I don't think
that is something reasonable for

343
00:36:09,875 --> 00:36:15,333
us to do and pay out of pocket.
>>	There is a really big
interesting question out there

344
00:36:15,333 --> 00:36:23,083
with respect to scale. Right? So
we did one bug. And it costs,
it's not a -- a dollar would be

345
00:36:23,083 --> 00:36:28,875
too much to pay for this sort of
thing. But if you have thousands
and thousands of people coming

346
00:36:28,875 --> 00:36:33,375
through the system looking for
this measure of anonymity of
disclosure to attorneys, it's

347
00:36:33,375 --> 00:36:40,250
not, there needs to be some way
to make it work. It's not real
clear what that is yet, but

348
00:36:40,250 --> 00:36:43,125
that's definitely an issue.
>>	So question is any devices
coming out from unknown Chinese

349
00:36:43,125 --> 00:36:45,792
vendors with vulnerabilities in
them? >>	I'm sorry can you say
that? >>	Devices coming out from

350
00:36:45,792 --> 00:36:49,625
Chinese vendors and their
vulnerable and these Chinese
companies are. Many times you

351
00:36:49,625 --> 00:36:55,625
don't know who they are, no
e-mail address or whatever. And
how do you deal with those.

352
00:37:05,542 --> 00:37:10,917
>>	With things like that, we
have run in with that before
with metasploit. Typically what

353
00:37:10,917 --> 00:37:17,292
we do is make some kind of
effort to find out who it is
first. That generally doesn't go

354
00:37:17,292 --> 00:37:24,333
anywhere. So we get in touch, I
work with cert CC a lot. And
they have a nice long list of

355
00:37:24,333 --> 00:37:29,667
people that they can talk to. We
have gone through cert CC and
generally cert CC will get in

356
00:37:29,667 --> 00:37:35,667
touch with someone like JP Cert
or Cert CR or responsible
entities in china, whoever they

357
00:37:38,208 --> 00:37:45,917
are. Possibly they know who it
is. The main concern we would
have is not so much, you know,

358
00:37:45,917 --> 00:37:53,750
I'm an American, I'm standing in
America, and uh, I'm happy to
help the people of china. I'm

359
00:37:53,750 --> 00:37:58,042
totally one to do that. But it
gets really hard really fast
because there are languages

360
00:37:58,042 --> 00:38:04,167
barriers and there is time zone
barriers. So I could usually
make a play like ICS cert or

361
00:38:04,167 --> 00:38:09,792
department of homeland security
and say hey, we have all these
boxes of unknown origins, ya

362
00:38:09,792 --> 00:38:14,750
know anybody? And it is, it's a
very personal kind of process
with a lot of people talking to

363
00:38:14,750 --> 00:38:20,750
other people. It doesn't scale
great. But it's -- that's how we
do it today. >> So presumably, a

364
00:38:24,208 --> 00:38:30,208
cy -- cyber lawyer would have a
fairly finite list of clients.
And portions of that list would

365
00:38:33,167 --> 00:38:39,292
be exposed during the
litigation. So wouldn't the,
wouldn't just communication from

366
00:38:39,292 --> 00:38:46,458
that particular lawyer be a risk
of losing your anonymity? >>	The
fact of the attorney client

367
00:38:46,458 --> 00:38:52,167
relationship itself is
confidential. And the identities
of criminal defendants in a

368
00:38:52,167 --> 00:38:59,083
criminal case would be. So for
example, if someone came to a
criminal defense attorney and

369
00:38:59,083 --> 00:39:05,542
said you know I robbed this
bank. That is confidential
information that only the

370
00:39:05,542 --> 00:39:11,833
attorney has. So it's --
attorney client relationship is
probably the most secure

371
00:39:11,833 --> 00:39:16,667
relationship that you could
build in terms of disclosure
that involves potentially

372
00:39:16,667 --> 00:39:21,542
criminal conduct. >>	I know what
you're saying here. You're
asking more about traffic

373
00:39:21,542 --> 00:39:27,542
analysis. If I'm e-mailing Jim
in space and Jim is known to
sometimes disclose bug, it gets

374
00:39:29,917 --> 00:39:32,042
real easy real fast to figure
out who's talking. So obviously
you would want to, if you're

375
00:39:32,042 --> 00:39:38,042
really that concern, again, your
adversary, if my adversary is GE
or AT&T, they're not, unless

376
00:39:40,292 --> 00:39:46,292
it's AT&T's network, they're not
going to be, really have a lot
of reach into like getting a

377
00:39:52,500 --> 00:39:58,458
hold of my e-mail. Sure they can
subpoena it. They could try to
subpoena all day long. Good luck

378
00:39:58,458 --> 00:40:04,333
subpoenaing an attorney for all
their points of contact. I don't
think any judge would ever do

379
00:40:04,333 --> 00:40:07,375
that ever. They could try to
subpoena me, but they already
know who I am. I can have

380
00:40:07,375 --> 00:40:14,208
throwaway e-mail addresses and
use have PGP because I know his
key and that's how Cryptography

381
00:40:14,208 --> 00:40:20,583
works. I don't have to ask him
for his first. So I could just
say, hey Jim this is Todd and I

382
00:40:20,583 --> 00:40:27,792
know I'm on like hot dudes 22 at
Yahoo. But it's really me I
promise. Or something like that.

383
00:40:27,792 --> 00:40:33,792
You know? That's how I would
solve it just throw away. >>	I
had a question, like

384
00:40:35,875 --> 00:40:40,500
clarification from the example
you present. There was no
response from the vendor. But

385
00:40:40,500 --> 00:40:45,292
like if they had responded in a
really adversarial way, like if
you're a researcher and you get

386
00:40:45,292 --> 00:40:52,417
an unexpectedly hostile response
from the vendor, like what
should you do then or like how

387
00:40:52,417 --> 00:40:58,417
do you approach that? >> 	Hire
Jim! >>	Yeah yeah, you hire Jim,
he's very reasonable. So

388
00:40:58,417 --> 00:41:03,542
generally, we have gotten --
I've gotten hostile responses
from vendors like that weren't

389
00:41:03,542 --> 00:41:10,000
this. I've disclosed a lot and
when we do that, we just,
generally try to calm them down,

390
00:41:10,000 --> 00:41:15,667
we assure them we're not asking
them anything we're not selling
them pen testing. A lot of times

391
00:41:15,667 --> 00:41:19,042
they'll get on the phone and say
what do you sell me here?
Because I don't need like pen

392
00:41:19,042 --> 00:41:24,875
testing services. I'm like well
A. you do, and B. we're not
selling that. (Laughing) so I

393
00:41:24,875 --> 00:41:31,500
mean, it's, generally, it's
talking like sometimes you have
to talk on the phone and be a

394
00:41:31,500 --> 00:41:37,500
person. You know, it's very
human hacking to kind of walk
them off that edge. >>	Thank

395
00:41:40,417 --> 00:41:45,750
you. >>	If you're going to go
the lawyer disclosure route,
where would jurisdiction fall

396
00:41:45,750 --> 00:41:50,083
in? I don't know if that's
necessarily the right term, but
let's say you live in one state.

397
00:41:50,083 --> 00:41:56,792
Your, the target or, you know,
the software group or whatever
lives in another, lives works or

398
00:41:56,792 --> 00:42:03,583
whatever. How'd that play in?
Would it play in? The answer is
jurisdiction never found in New

399
00:42:03,583 --> 00:42:10,250
Jersey. That's for sure
(Laughing) . >>	Yeah, got to
make a New Jersey joke >>	That's

400
00:42:10,250 --> 00:42:16,708
a real issue. Because in weev's
prosecution, they bought the
case against him in New Jersey

401
00:42:16,708 --> 00:42:24,167
and that was THE basis for
overturning that conviction. So
it doesn't, where matters.

402
00:42:24,167 --> 00:42:30,167
>>	Assuming we can't afford a
lawyer as a researcher, is it
reasonable to contact a vendor

403
00:42:33,250 --> 00:42:39,250
or try to contact them using
just a website e-mail then you
don't get a response as

404
00:42:42,917 --> 00:42:48,917
indicated and you disclose
publicly on a blog or something
>>	Right. Right right. Yeah,

405
00:42:51,458 --> 00:42:53,500
exactly. Just for the record,
this sort of disclosure
intermediate thing is not

406
00:42:53,500 --> 00:42:56,292
something I would charge money
for. This is something I just do
community. It's a project we're

407
00:42:56,292 --> 00:43:02,583
working on. It's not like a
service for sale, to be honest
for you. And it couldn't scale.

408
00:43:02,583 --> 00:43:10,500
It wouldn't make any sense to do
it. To answer your question,
that's really I think an

409
00:43:10,500 --> 00:43:17,042
opportunity where this hold
harmless agreement could come
in. If you're going to stay

410
00:43:17,042 --> 00:43:21,542
anonymous behind the attorney,
the hold harmless is not as
necessary, because you can't

411
00:43:21,542 --> 00:43:27,250
find out who to go after any
way. If you are going to have an
identity, this two step process

412
00:43:27,250 --> 00:43:34,917
starts to make sense where you
reach out to the vendor and say
I found something and I can tell

413
00:43:34,917 --> 00:43:40,000
you about it, but I'd like you
to agree not to come after me or
support prosecution. There's

414
00:43:40,000 --> 00:43:44,333
going to have to be some
negotiation back and forth. If
you do something really

415
00:43:44,333 --> 00:43:48,625
horrible, they're not going to
be like fine I really do care
what you did. I think that can

416
00:43:48,625 --> 00:43:53,417
be worked out, but if that
negotiation process can complete
successful that would enable

417
00:43:53,417 --> 00:44:00,375
independent researchers to go to
companies. And of course the
other option would be

418
00:44:00,375 --> 00:44:07,208
>>	Metasploit? >>	Yes the
metasploit module. Exactly do
that. >>	Like I'm not an

419
00:44:07,208 --> 00:44:12,167
attorney and can't offer the
attorney client privilege, but
I've done it before for

420
00:44:12,167 --> 00:44:17,625
individual people. They'll come
on IRC or ask me on twitter for
some reason. Or e-mail me. They

421
00:44:17,625 --> 00:44:22,708
are like hey, I have this bug I
don't know what to do with it.
And generally I say we can help

422
00:44:22,708 --> 00:44:28,417
you with it, we can write the
metasploit module, that's what I
get out of it. And we generally

423
00:44:28,417 --> 00:44:35,750
just do, we tell the vendor, we
wait 15 days. We tell Cert CC
and we wait 45 days, we publish

424
00:44:35,750 --> 00:44:40,667
the metasploit module. That's
generally how we do it. It's
working so far. I'm not in jail

425
00:44:40,667 --> 00:44:46,667
yet, and that's the door.
(Laughing.) >>	That's it, Thank
you so much for coming

426
00:44:52,083 --> 00:44:54,083
everybody. (Applause.) 

