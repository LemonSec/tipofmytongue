1
00:00:00,208 --> 00:00:04,875
 >> It's time for our next talk,
and it sure looks like we are
picking on every little thing

2
00:00:04,875 --> 00:00:09,708
that you can buy at Best Buy and
plug into your network today,
and that's awesome, that's

3
00:00:09,708 --> 00:00:15,333
awesome. So we're going to hear
from the guys from Duo right
now. We've got Mark and Zach,

4
00:00:15,333 --> 00:00:20,833
and let's give them a big party
track welcome. In fact, one of
these guys is a new speaker. So

5
00:00:20,833 --> 00:00:26,833
that will be fun. [Applause] >>
I think he was expecting his
shot. Anyway, so welcome to the

6
00:00:40,750 --> 00:00:48,458
Internet of fails. Where IoT has
gone wrong and how we're making
it right. I'm Zach Lanier,

7
00:00:48,458 --> 00:00:53,333
Senior Security Researcher with
Duo Security. >> And I'm Mark
Stanislav with Duo Security as

8
00:00:53,333 --> 00:00:59,333
well. >> Thank you. Thank you.
So IoT, you know, if you have
been in the space for a while,

9
00:01:04,500 --> 00:01:09,792
you probably know similar things
as M2M, so machine-to-machine.
If you've been doing embedded

10
00:01:09,792 --> 00:01:14,292
security research, you're
probably much more friendly with
that term. I think cloud

11
00:01:14,292 --> 00:01:18,667
computing is a good example of
how we all bitched about
semantics for the first five

12
00:01:18,667 --> 00:01:22,500
years, and now everyone is just,
like, yeah, cloud computing,
cool. But everyone was, like,

13
00:01:22,500 --> 00:01:27,583
oh, that is not a thing, this is
bullshit no one will do this. So
I think IoT is the same way, you

14
00:01:27,583 --> 00:01:31,958
know, probably get passed the
definitions and the semantics of
a lot of this stuff, and kind of

15
00:01:31,958 --> 00:01:38,042
look at it for what it is, which
is a huge sector for research. A
lot of the talks I think will be

16
00:01:38,042 --> 00:01:45,042
seen at DEF CON for many years
to come we'll be around these
kinds of devices. There is a lot

17
00:01:45,042 --> 00:01:50,708
to talk about today. So let's
get onto it. In terms of what we
have going, you know,

18
00:01:50,708 --> 00:01:55,792
pervasiveness really is kind of
where it comes down to. You
think about like home router,

19
00:01:55,792 --> 00:02:00,500
right? You have the home router
hacking lab, all that going on.
The number of devices that we

20
00:02:00,500 --> 00:02:06,500
have in IoT where you have
firmware going, right? We can
barely update one router. What

21
00:02:06,500 --> 00:02:10,708
makes us think we're going to
update like hundreds of devices
in our households in five years?

22
00:02:10,708 --> 00:02:16,875
There is a lot going on there,
the service, whether it is a
business or whether it's your

23
00:02:16,875 --> 00:02:22,083
personal life, right? You're
going to bring the stuff in IoT
into your offices and if you do

24
00:02:22,083 --> 00:02:26,208
penetration testing, I'm
guessing you're hoping people
are going to bring these random

25
00:02:26,208 --> 00:02:33,625
things off the shelf of Best Buy
that reverse proxy out into the
office. In terms of the overall

26
00:02:33,625 --> 00:02:40,375
environment, there is a lot
going on in terms of how diverse
the technologies are. So the

27
00:02:40,375 --> 00:02:44,750
ecosystem are really messed up
right now. You see companies big
and small trying to standardize

28
00:02:44,750 --> 00:02:48,708
and make sense of it all, but
really we don't see that quite
yet and I don't think we will

29
00:02:48,708 --> 00:02:52,708
for a while. Part of the cool
thing about IoT right now and
where we're at with a lot of

30
00:02:52,708 --> 00:02:56,833
technologies we'll talk about
today is you can innovate really
easily. You have a lot of

31
00:02:56,833 --> 00:03:01,583
agility and IoT is really taking
advantage of that right now. So
how do you patch a bunch of

32
00:03:01,583 --> 00:03:06,042
firmware on the devices? Do you
auto update? Do you have people
manually do it? What's that

33
00:03:06,042 --> 00:03:10,542
going to look like, again, when
you're on that scale? And the
problem we've always had with

34
00:03:10,542 --> 00:03:15,292
embedded hardware is you get
random, you know, ODMs. You have
firmware that no one has

35
00:03:15,292 --> 00:03:20,458
actually done. Security audits
of kernels that are like 15
years old. And, you know, this

36
00:03:20,458 --> 00:03:23,750
is the kind of stuff that we're
putting in our networks right
now. So even though the device

37
00:03:23,750 --> 00:03:30,542
is new, the actual technology
underlined is probably not.
Ecosystem overall, if you buy an

38
00:03:30,542 --> 00:03:35,125
IoT device, guess what? That IoT
device probably has like three
or four services behind it from

39
00:03:35,125 --> 00:03:39,250
three or four other vendors. So
you're not just buying a piece
of hardware and on you're

40
00:03:39,250 --> 00:03:41,250
putting it on your network.
You're buying a piece of
hardware, putting it on your

41
00:03:41,250 --> 00:03:44,625
network, and then it's calling
out to three other services that
then have data that you have for

42
00:03:44,625 --> 00:03:49,250
your device to function or
service accounts to make it tie
into something else you're

43
00:03:49,250 --> 00:03:53,792
doing. So where does your data
go when it goes to the IoT? It's
the same problem as CloudRight.

44
00:03:53,792 --> 00:03:58,542
Where is my data at? Um, with
IoT you definitely don't know
where it's going. At least with

45
00:03:58,542 --> 00:04:03,042
Cloud Services you at least know
who, like, what provider might
have it. With IoT you're kind of

46
00:04:03,042 --> 00:04:07,542
just blindly trusting that the
person that created the hardware
has a good service provider on

47
00:04:07,542 --> 00:04:12,042
the back end. And like I
mentioned, the proxy
connections, if you haven't done

48
00:04:12,042 --> 00:04:17,500
this kind of research yet,
you'll see a lot of devices
traversing through all of your

49
00:04:17,500 --> 00:04:21,833
security, going out to the
Internet and then exposing web
interfaces on a public port

50
00:04:21,833 --> 00:04:26,750
through one of the search
providers. So again for
attackers this is kind of a big

51
00:04:26,750 --> 00:04:32,750
deal. Internet things. A lot of
insanity is trademarked by me,
unofficially. So if you think

52
00:04:35,542 --> 00:04:40,542
about IoT and you think about
attack surface, right? IT
cameras seem crazy because they

53
00:04:40,542 --> 00:04:44,875
are cameras in your home
recording you, audio and video
whatever. But really, that's

54
00:04:44,875 --> 00:04:50,833
kind of the purpose of this
technology world. It is
convenience, yes, there is some

55
00:04:50,833 --> 00:04:53,833
risk, but at the same time, if
I'm in Las Vegas I can see my
home right now, and that's

56
00:04:53,833 --> 00:05:01,708
pretty cool. But if you go down
the line though, an egg tray
that is connected, it tells you

57
00:05:01,708 --> 00:05:07,458
how soon your eggs are going to
expire. That really kind of
solidifies the insanity part of

58
00:05:07,458 --> 00:05:14,708
this for me because imagine what
company wants to be the company
that gets breached by an egg

59
00:05:14,708 --> 00:05:19,917
trainer office. We get really,
really scared when fridges start
sending spam. How about you

60
00:05:19,917 --> 00:05:25,833
actually have someone running
code execution from your egg
tray or running Wireshark from

61
00:05:25,833 --> 00:05:33,125
an egg tray, that should scare
you. >> So one of the things
that we have noticed is, so

62
00:05:33,125 --> 00:05:37,833
there is IoT, you're probably
familiar with a lot of big
commercial vendors who have kind

63
00:05:37,833 --> 00:05:45,333
of occupy the IoT space. But,
lately, there has been this,
this explosion in terms of just

64
00:05:45,333 --> 00:05:49,000
anyone can buy, any one of these
things like an electric end,
they don't really have to

65
00:05:49,000 --> 00:05:54,458
understand hardware or software.
They buy this thing and they
Sauder some stuff maybe or they

66
00:05:54,458 --> 00:05:57,958
get their friends to do it, and
they go to this web based IDE
and they plug in some code, and

67
00:05:57,958 --> 00:06:02,542
then they get $800,000 on kick
starter. So hardware is really,
really cheap and very

68
00:06:02,542 --> 00:06:07,417
accessible. And the
possibilities are endless here,
and it's great because anyone

69
00:06:07,417 --> 00:06:13,875
can do this, but at the same
time, any one of these pieces of
hardware might have its own

70
00:06:13,875 --> 00:06:19,417
security-related idiosyncrasies,
the people developing the
software, the people running the

71
00:06:19,417 --> 00:06:26,208
services that back some of these
pieces of hardware might not
actually have any security

72
00:06:26,208 --> 00:06:31,500
experience or actually apply any
controls whatsoever. So, you
know, the low barrier to entry

73
00:06:31,500 --> 00:06:37,500
is $25 to become a new IoT
vendor. I don't know if any of
you are familiar with some of

74
00:06:39,958 --> 00:06:43,667
the WiFi enabled lightbulbs but
is one of the things that we
started to thinking about. We

75
00:06:43,667 --> 00:06:50,958
actually have some WiFi enabled
lightbulbs back in one of our
offices. And you see something

76
00:06:50,958 --> 00:06:56,625
like Philips, which is a $60
WiFi enabled lightbulb which you
would assume all things being

77
00:06:56,625 --> 00:07:01,625
equal. Philips probably took
into account some security
measures, maybe, but then you

78
00:07:01,625 --> 00:07:08,417
have, you know, the $23 kind of
Alibaba special that comes from
who knows where, made by who

79
00:07:08,417 --> 00:07:13,167
knows who. And probably not as
robust from a security
standpoint. So if you're going

80
00:07:13,167 --> 00:07:19,167
to be deploying these lightbulbs
across your office so that you
can maybe, you know, cut down on

81
00:07:19,167 --> 00:07:23,667
your electricity bill and
automate some of the lighting,
what are you going to pay for?

82
00:07:23,667 --> 00:07:31,417
Are you going to pay the $60 or
go as low price point as you
possibly can? So this is kind

83
00:07:31,417 --> 00:07:37,542
of, I think, really represents
Mark's point about the IoT
ecosystem. It basically stacks

84
00:07:37,542 --> 00:07:42,208
all of the way down, right? Just
like with mobile, we've built on
top of existing services and

85
00:07:42,208 --> 00:07:47,917
added a whole new device of
software with its own
vulnerabilities and hardware

86
00:07:47,917 --> 00:07:53,417
issues. So have we done with IoT
as well because now we have
mobile apps that control these

87
00:07:53,417 --> 00:07:58,750
devices and they talk to web
services. So it's just a
spaghetti of security to

88
00:07:58,750 --> 00:08:04,750
connect. >> So the to point out,
you know, if this and that,
we're not talking about phones

89
00:08:08,042 --> 00:08:11,750
and their service and everything
else. But we want to kind of
talk about the principle that

90
00:08:11,750 --> 00:08:14,917
when you have all of these
embedded devices on your
network, the next thing you want

91
00:08:14,917 --> 00:08:19,333
to do is connect them all,
clearly. You want them to do
cool things, and some that are

92
00:08:19,333 --> 00:08:24,667
practical, right? Like my
example here, you have a CO2
monitor, if all of a sudden CO2

93
00:08:24,667 --> 00:08:29,833
goes up, aside from of course,
like alarms, maybe the lightbulb
turns red, or some other way

94
00:08:29,833 --> 00:08:34,792
that can actually, you know,
permeate your household or your
office space to add value to

95
00:08:34,792 --> 00:08:41,375
what you already have deployed
for technology. However, if you
have 110 platforms and if this

96
00:08:41,375 --> 00:08:46,667
and that, what happens when, you
know, they have tens of
thousands of users and they get

97
00:08:46,667 --> 00:08:52,333
compromised? What does that mean
for infrastructure, for
businesses, for personal homes?

98
00:08:52,333 --> 00:08:58,542
What could you do if you had
access to APIs, maybe you found
a venerability in one of the

99
00:08:58,542 --> 00:09:05,417
APIs that they are using for
customers. What could that mean
to people actually leveraging

100
00:09:05,417 --> 00:09:13,333
these platforms? So government,
of course, at DEF CON is always
a tricky topic. I think, though,

101
00:09:13,333 --> 00:09:18,167
if you paid attention, FTC is
ideally there at all times to
help consumers protect their

102
00:09:18,167 --> 00:09:21,750
interests. Whether that is
companies lying to you, that
company is saying that, Oh yeah,

103
00:09:21,750 --> 00:09:25,250
we secure your stuff, don't
worry about this. It turns out
they don't use encryption or

104
00:09:25,250 --> 00:09:30,042
whatever else. So FTC is
actually been pretty forward on
this, you know, they've had

105
00:09:30,042 --> 00:09:35,792
panels and they have meetings
and talking to different people
in this space, but TRENDnet,

106
00:09:35,792 --> 00:09:39,875
which we'll talk about an
example here in a second. That
was actually a case where they

107
00:09:39,875 --> 00:09:44,083
came down pretty hard on
TRENDnet because they had a
vulnerable IP camera with a

108
00:09:44,083 --> 00:09:48,250
pathetic vulnerability that
should never get out the door
from any respectable business,

109
00:09:48,250 --> 00:09:53,583
and that put a lot of people in
danger. So for better or for
worse, there is government

110
00:09:53,583 --> 00:09:59,667
oversight in this space and so
the people in this room, you
don't want to be left behind. If

111
00:09:59,667 --> 00:10:03,500
the government is ahead of you
in technology we've got a
problem. So think about what

112
00:10:03,500 --> 00:10:10,083
you're working on that, that
would definitely set a
precedent. >> So just to kind of

113
00:10:10,083 --> 00:10:14,667
give an overview of some of the
challenges that small vendors in
particular face and large

114
00:10:14,667 --> 00:10:19,542
vendors as well, when it comes
to IoT. We'll just kind of run
though some of these. The talk

115
00:10:19,542 --> 00:10:27,250
that preceded ours and many of
the talks that will probably
happen throughout this entire

116
00:10:27,250 --> 00:10:32,083
conference, and I'm sure that
none of you are strangers to
this, but hardware security can

117
00:10:32,083 --> 00:10:39,875
be a death nail for a lot of
these devices. And as we showed
with the $25 to the $130 devices

118
00:10:39,875 --> 00:10:45,792
that are out there, a lot of
these devices that are out in
production use just sort of

119
00:10:45,792 --> 00:10:50,083
generic development, you know,
system on chips, or development
boards and they're designed

120
00:10:50,083 --> 00:10:54,667
basically facilitate rapid
prototype and quick development.
They don't really have a lot of

121
00:10:54,667 --> 00:11:00,583
security features for a variety
of reasons. They want to make it
as agile as possible, they want

122
00:11:00,583 --> 00:11:06,500
to make it as quick as possible,
they want to have a lower power
consumption. Any number of

123
00:11:06,500 --> 00:11:10,417
things and another thing that
can be overlooked is the
prevalence of the same

124
00:11:10,417 --> 00:11:16,458
components if they're using the
same SoC or if they're using the
same micro code or any number of

125
00:11:16,458 --> 00:11:22,375
things. Finding one issue in one
of those things could affect a
whole swath of devices that

126
00:11:22,375 --> 00:11:27,583
might have been not even by the
same vendor. Like we said,
there's almost no expertise

127
00:11:27,583 --> 00:11:32,125
required to really a common IoT
vendor at this point. So the
least common denominator any of

128
00:11:32,125 --> 00:11:36,792
this is, I'm not really a great
hardware hacker, but this has
cropped up time and time again,

129
00:11:36,792 --> 00:11:40,667
it is literally, like, these
devices getting shipped out in
production with things as simple

130
00:11:40,667 --> 00:11:45,792
as UR headers, so exposed and,
you know, you just drop right to
a root shell on one of these

131
00:11:45,792 --> 00:11:50,083
devices and you start stealing
the whole thing. And then you go
and repeat that on every one of

132
00:11:50,083 --> 00:11:55,542
those devices. Software security
is still a big issue here as
well. Because of a lot of the

133
00:11:55,542 --> 00:12:01,708
environments, in particular, an
example, you are kind of
restricted as to what language

134
00:12:01,708 --> 00:12:07,708
you can actually develop in. So
people might not necessarily, if
it is something like a really

135
00:12:10,375 --> 00:12:16,667
low end, or really like, great
embedded device, you might have
to learn C and people continue

136
00:12:16,667 --> 00:12:24,125
to fuck up and not learn C
correctly. So they use functions
that they are not supposed to,

137
00:12:24,125 --> 00:12:28,875
right? There are is dangerous
behavior repeating itself
because we write C pretty one

138
00:12:28,875 --> 00:12:34,750
day. So it's just sort of
history repeating. And then
because you might be picking a

139
00:12:34,750 --> 00:12:39,875
platform that restricts your
language, you might be also
restricted to what operating

140
00:12:39,875 --> 00:12:44,250
system you can run as well. And
if it's, you know, if the OS is
already loaded there or you're

141
00:12:44,250 --> 00:12:49,000
using a vendor-provided OS, they
might not have taken into
account simple things like

142
00:12:49,000 --> 00:12:56,833
exploit mitigation. They might
not have even done things like
DPA Solar or XN. They might not

143
00:12:56,833 --> 00:13:04,167
be doing any sort of mitigation,
nothing. So just an example over
here from an embedded device

144
00:13:04,167 --> 00:13:10,667
which actually runs a web server
that talks to a bunch of other
things that are really

145
00:13:10,667 --> 00:13:16,667
important. There is zero, pretty
much zero memory address
randomization. So the dependency

146
00:13:21,208 --> 00:13:26,542
on other libraries, if you think
about things like heart bleed,
for instance, relying on these

147
00:13:26,542 --> 00:13:33,250
other opaque, or open source
libraries you basically get this
bug inheritance as well. And

148
00:13:33,250 --> 00:13:40,375
this applies to mobile
applications that run these
things as well. So

149
00:13:40,375 --> 00:13:43,208
communications and network
security for a lot of the
devices. There might be some

150
00:13:43,208 --> 00:13:49,292
really weird goofiness. I know
someone in the audience is going
to recognize this example, but

151
00:13:49,292 --> 00:13:56,167
when the device actually acts as
an access point or it connects
to a remote control that they

152
00:13:56,167 --> 00:14:03,750
are acting on either mode, when
they don't necessarily enable
things like WEP, or WAP or WAP2

153
00:14:03,750 --> 00:14:10,417
or they just have some other
exploitable behavior. There are
cases where they will transmit

154
00:14:10,417 --> 00:14:17,500
things like software updates
over plaintext or if they do
transmit them securely or over

155
00:14:17,500 --> 00:14:22,417
SSL/TLS they don't sign the
firmware update blogs or
anything like that. Numerous

156
00:14:22,417 --> 00:14:26,042
services that are exposed on a
lot of these devices that don't
necessarily enhance

157
00:14:26,042 --> 00:14:30,042
functionality in any way, so
just remote administration
services. Shared accounts are a

158
00:14:30,042 --> 00:14:37,833
problem as well when the vendor
might provide a support account
for updates or remote support.

159
00:14:37,833 --> 00:14:43,458
And maybe there's a static SSH
key shared across all of these
devices or the same hardcoded

160
00:14:43,458 --> 00:14:47,750
password, things of that nature.
And these are complicated even
furthermore by use of other

161
00:14:47,750 --> 00:14:53,125
technologies like 6LoPAN,
ZigBee, et cetera. And then the
simple example where you can

162
00:14:53,125 --> 00:14:57,333
spend I think $50 and plug a GSM
modem on to your device. There
are talks here to we'll discuss

163
00:14:57,333 --> 00:15:03,333
yet again how ridiculous GSM is.
So COM security is still a
really hard thing to solve if

164
00:15:07,542 --> 00:15:14,417
you're a small IT guy. >> Kind
of getting back to the fact that
the IoT device you have really

165
00:15:14,417 --> 00:15:20,500
is not just an IoT device, it's
really just kind of a hub for a
bunch of services that are then

166
00:15:20,500 --> 00:15:24,375
going to connect to from like
four or five or third-party
vendors. So if you think of

167
00:15:24,375 --> 00:15:31,083
things like APIs, APIs rarely
are actually APIs. They're just
like, oh, I did a get against a

168
00:15:31,083 --> 00:15:37,083
web server, therefore API. What
we're not seeing, A,
authentication against these

169
00:15:40,042 --> 00:15:46,042
devices is really there. It will
just say, oh, well, this
embedded hardware, clearly you

170
00:15:57,417 --> 00:16:00,292
can't see what these calls are
over the network and have no
protection on them because they

171
00:16:00,292 --> 00:16:03,333
think that no one is going to
look at this kind of stuff, or
signing request to ensure

172
00:16:03,333 --> 00:16:06,333
integrity to what API calls are
made in the first place. So
OWASP mobile, you know, web top

173
00:16:06,333 --> 00:16:09,708
ten. This is all alive and well
in the world of IoT. The same
problems that we all, you know,

174
00:16:09,708 --> 00:16:12,583
attack online and the Internet,
guess what, they're all on these
IoT devices as well. So if

175
00:16:12,583 --> 00:16:17,167
you're looking to get a shell on
one of these devices, maybe it
has a sequel server, because why

176
00:16:17,167 --> 00:16:22,167
not add a sequel server to
everything, and maybe it has a
web app with poor code handling.

177
00:16:22,167 --> 00:16:26,750
Well, guess what, now you write
your PHP shell or suburb, CGIF
and you drop it on the IoT

178
00:16:26,750 --> 00:16:32,375
device, and you have, you know,
CNC over this entire network of
IoT devices in that home. So

179
00:16:32,375 --> 00:16:36,875
just kind of conflating all of
these different technologies
that we already screwed up

180
00:16:36,875 --> 00:16:42,417
really badly all the time. Now
it's just like this magical box
of terribleness, and that's what

181
00:16:42,417 --> 00:16:48,458
you're buying for $150. So the
third party provider thing, you
know, I have seen those go

182
00:16:48,458 --> 00:16:53,750
really badly. We will talk about
that today, but not too much. If
you think about cloud

183
00:16:53,750 --> 00:16:59,417
infrastructure and the services
that people stand up, whether it
is a pass or they are doing

184
00:16:59,417 --> 00:17:04,250
infrastructure, like, EC2 or
something. A lot of these cases
they might understand how to get

185
00:17:04,250 --> 00:17:07,708
the software out, which is
probably isn't true, but they at
least know how to get a nice

186
00:17:07,708 --> 00:17:11,500
piece of hardware out. And then
they're saying oh, we need all
this infrastructure now to

187
00:17:11,500 --> 00:17:14,292
support this, well, they're
going to have infrastructure
vulnerabilities, they're going

188
00:17:14,292 --> 00:17:19,750
to have, you know, OS updated
packs, and default credentials
to web app services and

189
00:17:19,750 --> 00:17:23,667
everything else that people do
wrong already. Now you're going
to have that across four or five

190
00:17:23,667 --> 00:17:30,792
vendors. Kind of getting back to
what I started on which is this
idea where, you know, it is hard

191
00:17:30,792 --> 00:17:36,333
enough to get people to update
their routers, but at the level
of coverage in IoT that I think

192
00:17:36,333 --> 00:17:39,625
we will see in the next few
years. That's going to be a
really big problem for most

193
00:17:39,625 --> 00:17:43,500
consumers out there. This
audience is exempt, you guys
will upgrade your firmware

194
00:17:43,500 --> 00:17:50,083
hopefully, but if you have all
these different examples across
your life in technology, you

195
00:17:50,083 --> 00:17:54,083
know, some things you bootstrap
by and opening a mobile app and
saying, like, oh, new firmware

196
00:17:54,083 --> 00:17:57,500
version, hit, you know, update.
And then some of them you hold
the button on the back of the

197
00:17:57,500 --> 00:18:02,167
thing to call home, and you
know, bootstrap to that process.
And some of them you go to the

198
00:18:02,167 --> 00:18:06,333
web interface on the device. You
know, the web interface that was
mentioned once in the

199
00:18:06,333 --> 00:18:10,208
instruction booklet that you
threw promptly away. So there's
all these different ways to do

200
00:18:10,208 --> 00:18:15,208
firmware, and one thing we're
not seeing very commonly is
auto-updating firmware. Now you

201
00:18:15,208 --> 00:18:20,000
can make pros and cons to
whether you should update
firmware. Certainly for the

202
00:18:20,000 --> 00:18:26,542
vendor, it is a harder process
to get right and have a recovery
mode and all that, but again,

203
00:18:26,542 --> 00:18:30,375
how many of these you're going
to have, and what's that gonna
look like if one bug comes out,

204
00:18:30,375 --> 00:18:34,542
if another heart bleed happens
in five years, what would that
mean to all these devices that

205
00:18:34,542 --> 00:18:39,875
have SSL snaps that are
compromised now. So let's jump
into some failures. So a lot of

206
00:18:39,875 --> 00:18:45,667
this section at the top is
really an anti-pattern talk. You
know, what happened, why it's

207
00:18:45,667 --> 00:18:49,792
wrong, how you should be doing
it right, because I think that's
a pretty good methodology to

208
00:18:49,792 --> 00:18:53,750
help people understand what is
going on. So the TRENDnet that I
mentioned earlier, basically

209
00:18:53,750 --> 00:18:59,583
they had a CGI app on this thing
where it was viewing video --
and don't let this /anony part

210
00:18:59,583 --> 00:19:05,167
fool you. That's not supposed to
be typed anonymous endpoint for
this thing. They actually just

211
00:19:05,167 --> 00:19:10,708
failed -- I think it was a code
regression, some of the firmware
that was across dozens of their

212
00:19:10,708 --> 00:19:16,667
cameras and in this case, the
first time the bug came out,
someone actually indexed 700

213
00:19:16,667 --> 00:19:21,000
cameras almost immediately, put
them online, they actually
created a Twitter account to

214
00:19:21,000 --> 00:19:24,208
say, like, oh, look, a new
camera that is vulnerable to
this. And you could just watch

215
00:19:24,208 --> 00:19:28,583
the video stream by going to
this URL on any IP you could
find off Shodan or Google. So

216
00:19:28,583 --> 00:19:32,750
it's kind of a big risk for
people that bought this camera
thinking, like, yeah, TRENDnet

217
00:19:32,750 --> 00:19:36,708
company, they have been around
for a while. In this case, this
is all that you do. You go to

218
00:19:36,708 --> 00:19:40,917
Google into your URL and find
some cameras, and that's of
course if you don't just go to

219
00:19:40,917 --> 00:19:46,708
one of the many aggregation
sites for big creepers, but
don't be a big creeper. And

220
00:19:46,708 --> 00:19:50,042
really what frustrates me, this
isn't a security thing, right?
This is like basic QA101, does

221
00:19:50,042 --> 00:19:56,042
your admin have access to admin
pages, do your guests have
access to guest pages, and can

222
00:19:59,667 --> 00:20:04,208
your guests get to admin pages?
The answer should be no. And
they didn't take the time to run

223
00:20:04,208 --> 00:20:08,500
a curl script on a loop or
Selenium tasks or anything else.
That would have very quickly

224
00:20:08,500 --> 00:20:15,208
caught that this was a problem.
So second one, you know,
IOActive has done amazing

225
00:20:15,208 --> 00:20:22,708
research. One section they did a
little while back was on some of
the Belkin WeMo stuff. And, you

226
00:20:22,708 --> 00:20:27,208
know, in this case, you have
Belkin which is actually doing
some of the best practices out

227
00:20:27,208 --> 00:20:33,708
there. They're actually signing
firmware. Unfortunately, and you
know, anyone who has ever got a

228
00:20:33,708 --> 00:20:38,167
key burn knows how this feels.
They had the key, and then the
pass phrase is actually

229
00:20:38,167 --> 00:20:44,083
hardcoded in the firmware. So
the firmware got dumped, they
extracted the signing key and

230
00:20:44,083 --> 00:20:48,417
pass phrase and now they're at a
point as an attacker where you
can actually sign valid

231
00:20:48,417 --> 00:20:54,000
firmware. So if you can amend
the middle of the update request
or you can somehow otherwise

232
00:20:54,000 --> 00:20:57,417
interface into the update
mechanism, at that point you
would actually be able to push

233
00:20:57,417 --> 00:21:04,417
valid firmware on to that
device. So you know, QLDR on
this one, and we're going to

234
00:21:04,417 --> 00:21:08,583
touch this one or two more times
while we're standing up here.
Don't hide stuff in firmware.

235
00:21:08,583 --> 00:21:11,333
It's not hidden, like, whether
someone gets the firmware today
or tomorrow, whether you think

236
00:21:11,333 --> 00:21:17,375
that you obfuscated a key in
there, you didn't, it's not
hidden. The same thing applies

237
00:21:17,375 --> 00:21:23,542
to mobile apps. Just because
it's encrypted when it goes up
to the app store, it doesn't

238
00:21:23,542 --> 00:21:30,417
mean that someone can't just
dump the memory and get all of
the ASCII out of that binder and

239
00:21:30,417 --> 00:21:37,417
go through. >> So contact
security was looking at these
LIFX devices and what they

240
00:21:37,417 --> 00:21:43,417
discovered was that -- so
6LoWPAN and other low-powered,
you know, IPV6 over this low

241
00:21:46,542 --> 00:21:53,583
power -- inside of the device,
once again, hardcoded symmetric
key for encrypting all sorts of

242
00:21:53,583 --> 00:21:59,792
data, including credentials, and
WiFi pass phrases and such for
the other side of this device.

243
00:21:59,792 --> 00:22:05,750
So the hypothetical exploit, you
give this to someone as a gift,
you creep up on their house

244
00:22:05,750 --> 00:22:12,833
pretty usual, and one they add
the bulb to their network, you
just capture traffic decrypted

245
00:22:12,833 --> 00:22:19,167
with symmetric key and then you
get all their WiFi credentials.
And then you just jump on to

246
00:22:19,167 --> 00:22:24,917
their WiFi network and you creep
on them there as well. So,
again, repeating the same exact

247
00:22:24,917 --> 00:22:30,458
thing from before. Don't
hardcode things if you don't
want them to be found. They will

248
00:22:30,458 --> 00:22:34,958
be found. So that's why --
Dubbie and Dolan are over there.
So another example here. This is

249
00:22:34,958 --> 00:22:41,542
a whole automation gateway that
was built by a large utility
group. Well, provided by a large

250
00:22:41,542 --> 00:22:49,042
utility provider. What they did
was they actually outsourced all
of this to another service

251
00:22:49,042 --> 00:22:54,708
provider who gets these
basically like white label
devices that connect to their

252
00:22:54,708 --> 00:22:58,958
infrastructure so that you can
on there and, you know, have
your lights flip on and off, and

253
00:22:58,958 --> 00:23:03,375
have your pool pump flip on and
off, and it has this beautiful
web interface. It's really ugly,

254
00:23:03,375 --> 00:23:07,000
it wasn't that beautiful. It can
be controlled though a mobile
app as well, so, you know, you

255
00:23:07,000 --> 00:23:14,750
talk to this magical cloud site
and then over this verse
connection to this gateway will

256
00:23:14,750 --> 00:23:18,792
push down directives from the
users of scheduling and things
of that nature. So this kind of

257
00:23:18,792 --> 00:23:24,083
represents sort of the whole
swathe of things that, you know,
the web interface itself was

258
00:23:24,083 --> 00:23:30,083
vulnerable to all sorts of OWASP
top 10 101 things. And then the
gateway itself had unfettered

259
00:23:32,875 --> 00:23:36,917
console access, there were the
UR headers exposed that dumped
you right into the root shell.

260
00:23:36,917 --> 00:23:40,500
There was no privileges
separation for any services on
the device. The same support

261
00:23:40,500 --> 00:23:45,917
credentials are used to manage
all of the devices. And then on
the other side, on the ZigBee

262
00:23:45,917 --> 00:23:50,417
side of it, where it talked to
the controllers there was
vulnerable, like, things

263
00:23:50,417 --> 00:23:57,500
extraction, replay, injection,
et cetera. So this is sort of an
example of we start to kind of

264
00:23:57,500 --> 00:24:03,500
encroach upon utility and more
ICS-type stuff. >> Cool, so that
is pretty cool stuff that other

265
00:24:05,750 --> 00:24:11,625
people have squared away in this
space. So this next topic
someone actually did last year,

266
00:24:11,625 --> 00:24:16,000
does anyone have an IZON IP
camera? There's plenty of
people. There's got to be one or

267
00:24:16,000 --> 00:24:22,708
two in here. Yeah! Did you get
rid of it? It's not surprising.
So a couple examples. So IP

268
00:24:22,708 --> 00:24:28,708
camera, I bought it, I had the
best of intentions. I happened
to scan my network one day as

269
00:24:31,375 --> 00:24:36,458
you do, and there was Telnet
listening, and whenever Telnet
is listening in 2013 of this

270
00:24:36,458 --> 00:24:41,417
time, you should just stop what
you are doing, and figure out
why Telnet is on your network

271
00:24:41,417 --> 00:24:47,417
and stop it immediately. So in
trying to break into this device
and do bad things to it, one

272
00:24:49,708 --> 00:24:55,708
thing I did getting back to my
don't hardcode stuff anywhere
is, okay. All right. No, setup.

273
00:24:57,917 --> 00:25:02,292
So the mobile app in this case,
again, people assume mobile apps
are safe and they're encrypted.

274
00:25:02,292 --> 00:25:06,708
Well, when you have them in your
phone and you start them, guess
what? They decrypt. So you dump

275
00:25:06,708 --> 00:25:12,000
the memory and you get the
decrypted version of this. In
this case, you know, in this IDA

276
00:25:12,000 --> 00:25:17,625
screen shot, this was actually
shell scripting that connected
over Telnet to do the firmware

277
00:25:17,625 --> 00:25:23,625
upgrade kickoff. So you have
hardcoded root credentials over
Telnet firmware upgrade. This is

278
00:25:26,000 --> 00:25:30,958
what we're talking about in IoT
and the Internet of fails. This
is like a collapsing of

279
00:25:30,958 --> 00:25:37,833
terribleness. So in this case,
run strings, get some details.
Drop your admin credentials and

280
00:25:37,833 --> 00:25:42,667
log-in. And now, you've guess
what? You have access to root on
every single camera because this

281
00:25:42,667 --> 00:25:47,042
isn't a mobile app. This isn't
one off thing, this is every
single one. >> All right. Let's

282
00:25:47,042 --> 00:25:53,042
congratulate our first time
speaker to DEF CON. [Applause]
>> Thank you. >> There you go.

283
00:26:03,542 --> 00:26:09,125
>> Oh, I feel so much better
now. >> All right. I just want
to point out, I love that

284
00:26:09,125 --> 00:26:14,167
Internet of fail comment about
the Internet of things. >> Is
there anything different? It's

285
00:26:14,167 --> 00:26:19,625
not just a synonym? >> Well,
that is true. That's where we've
been for ages. >> So if you are

286
00:26:19,625 --> 00:26:26,083
ever in charge of this scenario,
do not use Telnet, if you do,
you're not a DEF CON, so let's

287
00:26:26,083 --> 00:26:31,375
face it, you guys are fine. And
don't hardcode passwords.
Another example, this gets to

288
00:26:31,375 --> 00:26:36,583
the service layer. So Amazon web
services was being used to
actually store the video

289
00:26:36,583 --> 00:26:41,500
recording. So if you had a
motion alert, or sound alert, it
recorded, drop it to S3, your

290
00:26:41,500 --> 00:26:46,292
mobile up would then go, hey, I
need to see that alert, and then
it would pull it up. So in this

291
00:26:46,292 --> 00:26:52,583
case, there was no
authentication required to hit
the endpoints for S3. So they

292
00:26:52,583 --> 00:27:00,250
weren't using the IAM or any of
the other very smart ways you
should do things. The times were

293
00:27:00,250 --> 00:27:06,833
protected with MD5 strings for
the actual file digest, and
there's no SSL. So A, if you're

294
00:27:06,833 --> 00:27:09,458
in a coffee shop and someone is
on the network, guess what?
They're going to see the same

295
00:27:09,458 --> 00:27:14,083
video you are watching on your
own. B, if you have a shit load
of time, and a cluster and want

296
00:27:14,083 --> 00:27:18,333
to piss off AWS, you could
probably get through a little
bit of key space and maybe find

297
00:27:18,333 --> 00:27:24,708
a video or two. But it's one of
those things, you take something
as simple as upload a video and

298
00:27:24,708 --> 00:27:30,000
store it, they don't encrypt it
in transit, they don't encrypt
it as rest, and they don't

299
00:27:30,000 --> 00:27:36,208
actually protect it with
anything more than just a file
name stream. So if you thought

300
00:27:36,208 --> 00:27:39,417
your video of you getting out of
shower and walking by was going
to be deleted off of the

301
00:27:39,417 --> 00:27:46,083
Internet securely, I wouldn't
hold hope out. So yes, simple
things like AWS has identity

302
00:27:46,083 --> 00:27:50,500
access management. It's very
easy. You can give credentials
per users. Block things off, put

303
00:27:50,500 --> 00:27:54,667
it in a mobile app, and make it
connect out and actually do API
calls the right way, and segment

304
00:27:54,667 --> 00:28:00,667
data. Also, hey, Amazon, you can
just encrypt before you upload,
simple as that. Yes, good cat

305
00:28:02,708 --> 00:28:09,417
video is cat videoing. So you
guys enjoy that for a second.
Getting back to my tirade

306
00:28:09,417 --> 00:28:15,417
against APIs. Is it the poorly
implement or is it the low sack?
Okay. So API calls in this case,

307
00:28:20,542 --> 00:28:24,417
the API calls that were actually
going out, again, without SSL,
because why would you encrypt

308
00:28:24,417 --> 00:28:30,000
anything? And the secret token
in the API call, this is how you
can tell that this is always

309
00:28:30,000 --> 00:28:35,000
true. The secret token was just
the user's password that was
MD5. So if you didn't already

310
00:28:35,000 --> 00:28:39,333
have their password, and you
were on the network with them,
you sniff the terrible password,

311
00:28:39,333 --> 00:28:47,125
anyway, and now you can just
login as that person and look at
their video realtime and see

312
00:28:47,125 --> 00:28:52,208
them when they're getting out of
the shower. One thing that
happened here which really

313
00:28:52,208 --> 00:28:58,000
pissed me off, and I made that
very clear to the vendor is they
actually took my password that I

314
00:28:58,000 --> 00:29:03,417
signed up with for their
service, and transmitted the MD5
sum to their vendor, and they

315
00:29:03,417 --> 00:29:07,458
thought that was like okay to
do. So when we do things like
use, you know, one password or

316
00:29:07,458 --> 00:29:12,042
last password or whatever, and
we're like, yeah, we have one
password per site. Guess what? I

317
00:29:12,042 --> 00:29:16,792
didn't know that this was a
vendor. So if they get breached
I'm not changing my password

318
00:29:16,792 --> 00:29:21,292
because I don't think I'm
impacted, but I am because
they've passed my password on to

319
00:29:21,292 --> 00:29:28,750
someone else without telling me
about it. So I think one thing
that helps is looking at kind of

320
00:29:28,750 --> 00:29:33,250
the big picture of what is
happening in IoT. Remember, this
is one device. All of those

321
00:29:33,250 --> 00:29:37,333
things that you're seeing on the
screen are a direct
vulnerability I found, just a

322
00:29:37,333 --> 00:29:42,292
terrible failure of best
practices or just a total
compromises of security for all

323
00:29:42,292 --> 00:29:47,250
customers to the point where
they actually had hardcoded
Amazon S3 credentials in the

324
00:29:47,250 --> 00:29:51,375
mobile app. Remember how I was
just saying that Amazon S3 was
the place they stored everyone's

325
00:29:51,375 --> 00:29:59,333
videos without any kind of
segmentation? So we're supposed
to say this vendor is redacted,

326
00:29:59,333 --> 00:30:05,333
but -- yeah, whatever. So these
are real, real issues that we
identified maybe six, or seven

327
00:30:12,583 --> 00:30:15,542
months ago. Well, even longer.
So basically just to give you an
idea, this device is basically a

328
00:30:15,542 --> 00:30:18,750
little embedded device, there's
a mobile app that goes with it.
You can pretty much control

329
00:30:18,750 --> 00:30:23,833
everything through this mobile
app and it talks to AWS and
pushes messages back and forth

330
00:30:23,833 --> 00:30:29,833
and down. And it uses the
electric input. So the session
IDs to talk to their service to

331
00:30:32,042 --> 00:30:38,042
actually manage and push
messages down to this device
were just based on UNIX epoch,

332
00:30:42,417 --> 00:30:45,292
period. Just the UNIX epoch as
timestamp for when you logged
into that service. So that's a

333
00:30:45,292 --> 00:30:51,292
very small space in which to
actually root write. So with all
of the recent timestamps, just,

334
00:30:53,500 --> 00:30:59,500
you know, brute force through
them. So then you become a user
simply with this little browser

335
00:30:59,500 --> 00:31:05,917
header. So clearly the fix is,
use real session management,
right? This is all back to ten

336
00:31:05,917 --> 00:31:11,917
10 OWASP 101 basic web security
stuff. The impact here is pretty
bad because it has to do with

337
00:31:16,125 --> 00:31:22,125
kids. So they also have a system
where you can buy credits to
then send messages to these

338
00:31:25,792 --> 00:31:31,500
various devices. So you purchase
these, these credits via an app
purchasing inside of the mobile

339
00:31:31,500 --> 00:31:37,708
application. Now, it turns out
that -- the, it was the client's
side enforcement. The client

340
00:31:37,708 --> 00:31:44,500
would tell the server how many
credits it wanted. The server is
like cool, whatever you say. You

341
00:31:44,500 --> 00:31:51,708
can pick a number, any number, a
signed integer, add and remove
credits as you felt fit. So you

342
00:31:51,708 --> 00:31:57,375
get that many of whatever
things, whatever credit things
this gives you. So obviously do

343
00:31:57,375 --> 00:32:04,167
not let the client be the
authority for this because you
must assume that it is in the

344
00:32:04,167 --> 00:32:10,375
bad creeper's control. Excuse
me. So there was also this sort
of -- I don't really want to

345
00:32:10,375 --> 00:32:17,417
confuse deputy problem, but just
basically a major fuck up where
-- if you, the analogy here, is

346
00:32:17,417 --> 00:32:23,833
if you are using something like
Facebook, I send you a friend
request, you have to then accept

347
00:32:23,833 --> 00:32:28,667
or reject that friend request
before we see each other's
stuff, right? Technically, like,

348
00:32:28,667 --> 00:32:33,417
that's generally how it works.
Here, however, you could ask the
user or whoever, you know,

349
00:32:33,417 --> 00:32:38,542
whoever your target is to be
your friend and immediately
access their stuff. So you could

350
00:32:38,542 --> 00:32:44,292
start sending messages to this
device. So, you know, ask a user
to be your friend, you get some

351
00:32:44,292 --> 00:32:51,000
stuff back about the user and
then you can just start sending
messages to their device. So,

352
00:32:51,000 --> 00:32:57,750
obviously, have, you know,
authorization process for all of
these things. I don't actually

353
00:32:57,750 --> 00:33:02,750
transmit anything about target
back that the attacker can then
use. You know, actually have

354
00:33:02,750 --> 00:33:08,750
control be on the target's side.
And then, of course, there is
the heart bleed discussion that

355
00:33:12,083 --> 00:33:16,375
doesn't seem to want to die. So
you've got MoLEP speaking to
embedded devices, you've got

356
00:33:16,375 --> 00:33:22,708
embedded devices speaking to
remote services and back and
forth. You know, there's been

357
00:33:22,708 --> 00:33:27,750
these stats, I think it's been
something like 300,000 services
that have been identified out,

358
00:33:27,750 --> 00:33:32,708
live out on the Internet that
are vulnerable to heart bleed
and probably other things as

359
00:33:32,708 --> 00:33:36,958
well. But you have to ask
yourself, what about these
devices that are employed

360
00:33:36,958 --> 00:33:41,708
internally or the services that
they are talking to or even the
clients, are the clients

361
00:33:41,708 --> 00:33:44,958
actually vulnerable to heart
bleed, obviously, that's been
demonstrated as well. So you

362
00:33:44,958 --> 00:33:52,250
really think that the $25 Ali
Baba special lightbulb that you
bought. If that happens to be

363
00:33:52,250 --> 00:33:56,542
vulnerable to something like
this, do you really think that
you're going actually get that

364
00:33:56,542 --> 00:34:00,917
addressed that the vendor
actually cares? They might even
be a fly by night operation or

365
00:34:00,917 --> 00:34:06,917
may not have the expertise to
actually deal with this. >> So
one problem that we're seeing

366
00:34:09,208 --> 00:34:14,750
and why we're so interested in
this space in trying to make it
suck less is the vendors that

367
00:34:14,750 --> 00:34:18,833
you're going to see in this
space are not, you know, the
Belkins. You know, obviously

368
00:34:18,833 --> 00:34:22,250
they have some stuff, Cisco has
some stuff, but they're not the
people that you're going to get

369
00:34:22,250 --> 00:34:28,125
most of your devices from. A lot
of the stuff -- if you look at
the kick starter, and you go-go

370
00:34:28,125 --> 00:34:32,333
dragging innovation, you know,
there's a lot of IoT right now,
and if you think of like

371
00:34:32,333 --> 00:34:36,583
$80,000, you have to do R&D,
prototyping, software
development, hardware

372
00:34:36,583 --> 00:34:42,500
management, Cloud Services,
hiring marketing and
salespeople. To build devices,

373
00:34:42,500 --> 00:34:47,792
ship them and then have like
legal, right? $80,000 is going
to go very, very, very quickly.

374
00:34:47,792 --> 00:34:53,500
They're not going to have money
to spend on protecting your
device. Again, everyone has the

375
00:34:53,500 --> 00:34:58,500
best of intentions, right? And
that's why this road is paved,
you know, to hell with IoT

376
00:34:58,500 --> 00:35:03,333
devices all along the way. We're
going to be in a really bad
place, much worse than we are

377
00:35:03,333 --> 00:35:10,500
now, which is pretty bad. And if
you look at postscapes.com or
devices that are from alpha.com,

378
00:35:10,500 --> 00:35:14,292
go see how many companies you've
ever heard of because they're
probably brand new

379
00:35:14,292 --> 00:35:19,167
entrepreneurs, brand new
bootstrap startups, or someone
that crowdfunded a device. And

380
00:35:19,167 --> 00:35:24,750
this is the kind of stuff all of
us are going to want to buy, but
at what cost, right? One other

381
00:35:24,750 --> 00:35:31,500
main point to this is a security
researcher to Belkin, or Cisco
or Samsung at least mean

382
00:35:31,500 --> 00:35:38,000
something, right? Security
researcher, these vendors with
two people on staff that are

383
00:35:38,000 --> 00:35:42,500
both like maybe one product
designer and one guy that is
okay at mobile apps they don't

384
00:35:42,500 --> 00:35:45,958
know what security research is,
they probably don't come to DEF
CON, and they are going to be

385
00:35:45,958 --> 00:35:48,958
the people that are trying to
triage bugs in thinking that
you're breaking in to their

386
00:35:48,958 --> 00:35:54,292
company and trying to extort
them. And we've been told on a
call by a lawyer that we hacked

387
00:35:54,292 --> 00:35:58,542
their systems, and that we were
doing like terrible things to
their company when all we were

388
00:35:58,542 --> 00:36:01,542
doing was testing the device
locally in our home. So
crowdfunding, again, a lot of

389
00:36:01,542 --> 00:36:05,292
this is coming out of
crowdfunding. It's not just,
like, speaking of platitudes,

390
00:36:05,292 --> 00:36:10,917
like, literally some of these
devices are that you might be
using right now actually or

391
00:36:10,917 --> 00:36:16,667
probably crowdfunded. And it's a
great way to innovate, for sure,
but again, the margins on these

392
00:36:16,667 --> 00:36:22,750
things are nil and the amount of
extra capital they have to
invest is also nil. So it

393
00:36:22,750 --> 00:36:27,375
doesn't really turn out too
well. >> So kind of back to what
Mark was just saying a minute

394
00:36:27,375 --> 00:36:32,125
ago. A lot of these small
vendors, and we've had this
experience time and time again,

395
00:36:32,125 --> 00:36:37,042
as I'm sure many of you probably
have as well, the small vendors,
even some large ones to this

396
00:36:37,042 --> 00:36:44,208
day, right? That's why we still
have CFA reform and shit like
that. They just don't quite get

397
00:36:44,208 --> 00:36:49,333
why you're coming to them and
telling them that their baby is
ugly. Why would anyone want to

398
00:36:49,333 --> 00:36:54,500
hack my device? What are you
selling? Why would you want to
talk about this publicly? They

399
00:36:54,500 --> 00:36:59,500
don't have the resources or the
experience to necessarily deal
with this. Like Mark said, Mark

400
00:36:59,500 --> 00:37:05,500
said they might be strapped for
cash or they're just trying to
get the product out the door. So

401
00:37:05,500 --> 00:37:11,167
the need for this space as well
means that certain researchers
even if you're like bad ass, you

402
00:37:11,167 --> 00:37:16,292
know, super mega cool exploit,
but haven't really ever
interacted with an IoT vendor

403
00:37:16,292 --> 00:37:21,625
before, especially one of the
smaller ones, you might not know
how to approach them. So we kind

404
00:37:21,625 --> 00:37:29,292
of like to bridge that gap
between, like other initiatives
have done before for the

405
00:37:29,292 --> 00:37:33,250
traditional space. We kind of
like to make sure that stuff is
fixed and that you-all stay out

406
00:37:33,250 --> 00:37:40,458
of jail when it comes to IoT. So
born out of some of that
redacted slides you saw, and

407
00:37:40,458 --> 00:37:44,250
just general frustration talking
to vendors in this space and
realizing that they're not going

408
00:37:44,250 --> 00:37:49,375
to get it. We started an
initiative called build it
securely. So primarily we're

409
00:37:49,375 --> 00:37:56,375
focused on the small company.
The vendor that is kick starter
or it's bootstrapped because

410
00:37:56,375 --> 00:38:03,292
more often than not, they're
going to have no money. Even
some of the big vendors don't

411
00:38:03,292 --> 00:38:07,708
actually have as many security
resources on staff as you would
like to know or like to think.

412
00:38:07,708 --> 00:38:13,667
Ad so primarily we're trying to
bridge that gap for them and
help them get better devices in

413
00:38:13,667 --> 00:38:18,708
your hands so we're going to
still do research. You're going
to get devices you don't have to

414
00:38:18,708 --> 00:38:23,750
throw away after two days. We're
also trying to create resources
on the site. So if you want to

415
00:38:23,750 --> 00:38:28,500
know, hey, I'm an engineer, what
is the one document I should
look at for IOS security, what's

416
00:38:28,500 --> 00:38:33,542
the one API presentation I
should look at, and we'll try to
create some of those on the site

417
00:38:33,542 --> 00:38:37,500
and just give resources that we
think are pretty legit, and
hopefully they actually read

418
00:38:37,500 --> 00:38:41,458
them and go through them. And
then of course, presenting
conferences like this to talk

419
00:38:41,458 --> 00:38:46,000
about this and, you know,
getting people involved. Okay.
It has been a long road. We will

420
00:38:46,000 --> 00:38:51,167
look at a timeline in a second.
But where we're at now is the
drop cam was just acquired by

421
00:38:51,167 --> 00:38:57,167
NASA for $550 million, unrelated
to our impact on them, I assure
you. And Belkin just came on. So

422
00:38:59,708 --> 00:39:05,708
obviously we talked earlier
about IOActive and Belkin's
research. Brian over at Belkin

423
00:39:07,875 --> 00:39:13,875
actually has a good security
pedigree, and he really does
want to make things better. So

424
00:39:16,125 --> 00:39:21,458
we're going to be working with
his team as well to give them
extra resources and make things

425
00:39:21,458 --> 00:39:24,667
more secure for all of the cool
stuff they have coming out. Dip
Jar is actually an incubator

426
00:39:24,667 --> 00:39:27,708
startup out of Boston, and they
are doing some cool stuff with
basically a tip jar, GSM

427
00:39:27,708 --> 00:39:31,083
enabled, that you can just dip
your card in and that's how you
tip people if you don't have

428
00:39:31,083 --> 00:39:36,167
cash and you kind of want to go
and like say, here's two bucks.
And who else do we have?

429
00:39:36,167 --> 00:39:41,167
Pinoccio which is actually a
system on ship vendor, you might
have saw them in earlier slides.

430
00:39:41,167 --> 00:39:45,667
Zendo is a stealth startup right
now in the IoT space. They're
going to have a pretty large

431
00:39:45,667 --> 00:39:50,792
product line coming out here.
Fun fact, the CEO of Zendo is
actually the former CEO of

432
00:39:50,792 --> 00:39:56,250
Steminnovation who made the eyes
on camera. He saw my research
previously, and that this new

433
00:39:56,250 --> 00:39:59,958
company he doesn't want to do it
the wrong way. So, you know, we
get really cynical about

434
00:39:59,958 --> 00:40:05,792
companies not giving a shit, but
I had a cold call from a CEO of
someone I burned in the news.

435
00:40:05,792 --> 00:40:10,458
And he reached out to me to have
me come in and give security
lectures to his engineering

436
00:40:10,458 --> 00:40:15,250
staff. So it's not all doom and
gloom as much as we might
pretend. There are companies

437
00:40:15,250 --> 00:40:19,875
that are trying to work hard on
security, and we should try to
support them. Amazing

438
00:40:19,875 --> 00:40:25,875
researchers, IOActive, Steven
Routley, Stephan Chenette, Don
Bailey, did we forget anyone?

439
00:40:28,125 --> 00:40:34,167
Zack, and then Bugcrowd is
providing their entire platform
pro bono to us. So that

440
00:40:34,167 --> 00:40:39,917
researchers can triage bugs to
vendors through a private
communication between them. And

441
00:40:39,917 --> 00:40:43,792
the best part about all of this
is, all of the researchers are
basically doing this, one,

442
00:40:43,792 --> 00:40:49,792
because they want to help some
people, two, because they're
going to get research done and

443
00:40:54,833 --> 00:40:59,292
not be sued for it. They already
have opt in from these vendors.
So, these are some pretty

444
00:40:59,292 --> 00:41:03,000
awesome companies. Some
companies you might not have
heard of up here, but these are

445
00:41:03,000 --> 00:41:06,208
really interesting companies
doing some pretty impressive
product lines coming out in the

446
00:41:06,208 --> 00:41:09,208
space. And we're going to have
researchers looking at
preproduction hardware, doing

447
00:41:09,208 --> 00:41:12,417
assessments against them,
getting them bugs and actually
making this device better before

448
00:41:12,417 --> 00:41:16,625
they go in people's hands rather
than after. But, again, they'll
be at DEF CON hopefully next

449
00:41:16,625 --> 00:41:20,583
year talking about some of the
stuff they brought because
that's part of the deal. In

450
00:41:20,583 --> 00:41:24,292
terms of timeline, we just
started this up in February,
besides San Francisco, you know,

451
00:41:24,292 --> 00:41:28,250
we've really been kind of
spinning things up pretty
slowly. We don't want to have a

452
00:41:28,250 --> 00:41:33,000
situation where we say every
researcher on Earth get involved
in this. We're not trying to

453
00:41:33,000 --> 00:41:37,750
have the largest list of people.
We're trying to have the most
output and the most production.

454
00:41:37,750 --> 00:41:42,792
And sometimes you have to kind
of do the walk before you run.
So far so good. We actually just

455
00:41:42,792 --> 00:41:46,750
in July shipped hardware from
Pinoccio to two of our
researchers. So that's kind of

456
00:41:46,750 --> 00:41:50,958
our first line in the sand that
hey we accomplished something
that we were trying to

457
00:41:50,958 --> 00:41:55,542
accomplish. And we have a lot
more coming out for the next few
months, and we'll be bringing

458
00:41:55,542 --> 00:42:00,167
for researchers on. We have
contact details at the end if
you want to look at some of

459
00:42:00,167 --> 00:42:04,375
that. Pinoccio has got the
hardware. Bugcrowd is setup for
our vendors at this point. We're

460
00:42:04,375 --> 00:42:08,167
still kind of doing some of the
stuff that we all deal with
already which is like timelines,

461
00:42:08,167 --> 00:42:13,458
triage, when the bugs have to
get fixed, when we going to drop
bugs and is the kind of stuff

462
00:42:13,458 --> 00:42:17,292
that any kind of coordinator
goes through when you do this
sort of process. And we're

463
00:42:17,292 --> 00:42:23,542
growing. It's not about having
the most people on our website,
but it's about having the most

464
00:42:23,542 --> 00:42:27,833
people getting shit done and
associated with us, which is
something that our vendors have

465
00:42:27,833 --> 00:42:35,208
taken kindly to. They don't want
to have you throwing 300 people
at them because it's hard for

466
00:42:35,208 --> 00:42:39,375
vendors that don't have security
in-house to understand how to
work with vendors. So we're

467
00:42:39,375 --> 00:42:43,833
actually doing a lot of
knowledge transfer and teaching
vendors in this space, what kind

468
00:42:43,833 --> 00:42:48,000
of research it is, how it works,
why people do it, and why we're
at DEF CON in the first place.

469
00:42:48,000 --> 00:42:54,000
>> So what does it all mean?
What's the conclusion? So
basically what we've learned is

470
00:42:56,625 --> 00:43:03,750
that people can actually be
altruistic occasionally. There
is a lot of cynicism, but

471
00:43:03,750 --> 00:43:09,208
sometimes people can suspend
that or actually erase it
entirely and, and don't be

472
00:43:09,208 --> 00:43:13,042
afraid to actually reach out to
people, and vice-versa. Don't be
afraid -- we would encourage

473
00:43:13,042 --> 00:43:18,083
like collaboration. We want
people to want to do this. We
want this to be a community

474
00:43:18,083 --> 00:43:24,083
effort so we can have an impact.
That's why we've partnered with
like I Am The Cavalry, for

475
00:43:33,667 --> 00:43:37,333
instance, because this kind of
falls in line with some of the
stuff that they're doing. It

476
00:43:37,333 --> 00:43:40,583
gives us visibility and gets
them resources. Of course, we
did have some aggressive goals

477
00:43:40,583 --> 00:43:43,833
initially, but we've stepped
back and kind of made it a
little more comfortable. Doubled

478
00:43:43,833 --> 00:43:47,750
the timeline, basically. Since a
lot of the researchers are doing
this, you know, pro bono, they

479
00:43:47,750 --> 00:43:52,750
are doing this, they get the
benefit of business, they are
doing it for us. Pro bono,

480
00:43:52,750 --> 00:43:58,000
they're pretty busy, they have
day jobs, so do we. So this is
also us kind of taking spare

481
00:43:58,000 --> 00:44:02,667
cycles and working on this
project. And, again, like Mark
said we want quality, not

482
00:44:02,667 --> 00:44:07,167
quantity. We want more people to
be involved, but we want to make
sure that everyone is kind of on

483
00:44:07,167 --> 00:44:11,625
the same page and everyone is
going to be able to relax into
this. And measured successes and

484
00:44:11,625 --> 00:44:17,625
milestones. So far we have done
pretty well in hitting some
pretty significant milestones.

485
00:44:19,750 --> 00:44:23,833
They might not be significant to
a lot of people in the grand
scheme of things, but it's

486
00:44:23,833 --> 00:44:29,250
definitely accelerating to where
we want to be. So IoT is still
malleable enough. This is still

487
00:44:29,250 --> 00:44:34,708
enough space that we can
actually have an impact versus
like some other spaces like --

488
00:44:34,708 --> 00:44:42,000
web security has been solved or
some shit, but you know, we're
not going to have there is some

489
00:44:42,000 --> 00:44:47,250
shit, but we don't have to shoe
horn this into everything else.
IoT we can make a difference now

490
00:44:47,250 --> 00:44:54,667
before it comes catastrophic.
This could also help consumers
make better decisions as well.

491
00:44:54,667 --> 00:45:00,750
If they see not so much an
underwriters laboratory-type of
thing but something similar, it

492
00:45:00,750 --> 00:45:08,167
would give consumers a, sort of
a yardstick to say, oh, this is
been vetted, this vendor cares

493
00:45:08,167 --> 00:45:14,167
and people can decide with their
wallet, right? So if nothing
else, if this goes haywire. We

494
00:45:16,167 --> 00:45:23,542
helped vendors and got
researchers to do doing cool
stuff. At the end of the day,

495
00:45:23,542 --> 00:45:29,542
that's not bad. So the site is
BuildItSecure.ly. You can also
reach -- there's a mailing list.

496
00:45:32,833 --> 00:45:38,375
I think we actually did mention,
the mailing list, the thing
about that we have our vendors,

497
00:45:38,375 --> 00:45:43,250
our partners and the researchers
on the same mailing list. So
there is no silo, and talk bad

498
00:45:43,250 --> 00:45:49,833
about this vendor over here.
That created a nice open
communication, if there is a

499
00:45:49,833 --> 00:45:55,833
question, someone says I'm going
to be deploying firmware XYZ do
you want to help me. So there is

500
00:46:06,458 --> 00:46:11,792
no silanization. So with that I
think we have a couple of
minutes left if there are any

501
00:46:11,792 --> 00:46:17,792
questions. Otherwise you can
meet us in the chill out lounge
afterwards. [Applause] >> And,

502
00:46:23,792 --> 00:46:26,958
and thanks. 

