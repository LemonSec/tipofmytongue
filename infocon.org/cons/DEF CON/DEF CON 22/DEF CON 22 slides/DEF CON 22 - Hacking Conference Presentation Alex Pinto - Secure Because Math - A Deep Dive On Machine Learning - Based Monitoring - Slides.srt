1
00:00:00,042 --> 00:00:03,125
>> : It's DEFCON time. Yeah, all
right. This is secure because
math a deep dive on machine

2
00:00:03,125 --> 00:00:09,125
learning based monitoring. So
please join me in welcoming Alex
Pinto. [Applause]. >> : Thank

3
00:00:11,875 --> 00:00:17,875
you guys. Glad to see you all
here and just before we start I
just want to ask for all of you

4
00:00:21,375 --> 00:00:28,000
that are from the internet and
you like to do the Twitterings
we have a hash tag for the talk

5
00:00:28,000 --> 00:00:35,792
so make sure when you make fun
of me you hash tag it or
something like that because I

6
00:00:35,792 --> 00:00:42,750
also do want to laugh. I
actually check Twitter while
you're talking so I can read the

7
00:00:42,750 --> 00:00:47,917
funny stuff you are talking
about. But anyway thank you so
much. Let's get started. Just a

8
00:00:47,917 --> 00:00:54,250
little about me. Chief Data
Sciences. The cool thing about
doing your own stuff is that you

9
00:00:54,250 --> 00:01:00,250
can just make up any title that
you want. I've pretty much been
doing machine learning research

10
00:01:02,958 --> 00:01:08,750
learning and training for a
while now and just for anyone
who is interested in this

11
00:01:08,750 --> 00:01:15,083
subject I found out machine
learning training is different
from Pokémon training. I might

12
00:01:15,083 --> 00:01:21,083
have got the wrong brochure or
something but anyway... You guys
might enjoy it. Anyway I'm

13
00:01:24,875 --> 00:01:30,083
focusing my research on national
security and a little bit of
response. As a child I never

14
00:01:30,083 --> 00:01:36,083
wanted to do that again so I'm
trying to figure out a way where
we have to do less or maybe do

15
00:01:40,917 --> 00:01:47,417
it in the more smart way.
Anyway... If for some reason you
think I have something and you

16
00:01:47,417 --> 00:01:53,417
need an attribution from me I am
Caffeinated Capybara. All right.
Let's get going. Anyway I want

17
00:01:56,708 --> 00:02:04,250
to talk about what is upcoming,
security singularity later
because of all the amazing

18
00:02:04,250 --> 00:02:10,250
products launched. And I just
want to make sure that I give
you some context, specifically

19
00:02:16,250 --> 00:02:22,250
about the messaging of, I
obviously don't know precise
detail technically what these

20
00:02:25,042 --> 00:02:29,417
companies are doing, it's secret
and saucey. It's so secretive
and stuff like that but I can

21
00:02:29,417 --> 00:02:34,542
guess based on their marketing
materials and I just wanted to
break down for you what I think

22
00:02:34,542 --> 00:02:39,417
that those people were doing and
if that's what they are doing.
So maybe these are the questions

23
00:02:39,417 --> 00:02:46,333
you should be asking them
because this stuff is hard. I
mean honestly math is hard. And

24
00:02:46,333 --> 00:02:51,042
there's a lot of potential
pitfalls and a lot of kind of
due diligence in your

25
00:02:51,042 --> 00:02:57,417
experiments and I just really
want to spend quality time
together talking about math here

26
00:02:57,417 --> 00:03:03,417
while we can try to decode a
little bit. Anyway... Let's get
going. So I specifically would

27
00:03:05,917 --> 00:03:12,625
like to thank all of you because
you guys are on vacation now.
Nobody has to work anymore and

28
00:03:12,625 --> 00:03:16,042
you guys actually are coming
here to see someone talk about
security singularity. Why. This

29
00:03:16,042 --> 00:03:22,042
has been solved for a while now.
It's sad because the guys that
did this network security thing

30
00:03:25,000 --> 00:03:30,167
have nothing to do with machine
learning. I thought this was so
amazing I had to put it out

31
00:03:30,167 --> 00:03:34,750
there. Maybe she should persue
machine learning products
because that would make it even

32
00:03:34,750 --> 00:03:42,125
more awesome I think.
Anyway... Of course you kind of
get the point where I'm coming

33
00:03:42,125 --> 00:03:47,125
from. Before I continue I just
want to make a quick side note.
If you ever do a Google images

34
00:03:47,125 --> 00:03:54,042
search for network security
solve, Jack Daniel was the first
hit. That's branding. I'll tell

35
00:03:54,042 --> 00:04:01,542
you that man. It's just amazing.
I wish I was  okay, who knows
maybe Pokémon will train us some

36
00:04:01,542 --> 00:04:09,458
day. The point is there's a lot
of confusion. Right? And this is
understandable. There's always a

37
00:04:09,458 --> 00:04:14,833
lot of confusion about specific
technologies we're working on.
We're always like for some

38
00:04:14,833 --> 00:04:20,833
reason there's a cycle where we
stop trusting and we start
looking for new so people have

39
00:04:20,833 --> 00:04:27,542
to come up with new stuff. And
the point is that I'm frequently
being asked a bunch of questions

40
00:04:27,542 --> 00:04:32,417
because of the kind of work I'm
trying to do. Hey I'm talking to
this guy and he tells me he's

41
00:04:32,417 --> 00:04:37,750
doing the math or something like
that. Can you help me out and
try to understand? I'm not

42
00:04:37,750 --> 00:04:43,375
talking about someone at the
street. These are people who
have been doing extensive

43
00:04:43,375 --> 00:04:51,042
product research or have been
actual running security programs
for a while. And they are

44
00:04:51,042 --> 00:04:56,417
failing to grasp, it's a pain to
grasp what the hell the
companies are doing. It's almost

45
00:04:56,417 --> 00:05:03,083
like, you know, there was some
sort of marketing employ to make
it kind of obscure to make

46
00:05:03,083 --> 00:05:10,042
people think it's better than
then it is. I'm not saying that.
But maybe you can argue the

47
00:05:10,042 --> 00:05:16,250
point. And I think that's kind
of bad for everyone. Right? And
this is pretty much the point

48
00:05:16,250 --> 00:05:21,708
I'm coming from here. By the way
is if any of you ever want to do
a big data presentation there's

49
00:05:21,708 --> 00:05:26,500
this big data fix tumbler. So
waves with bits. Best data ever.
But anyway  no. I'm here to

50
00:05:26,500 --> 00:05:29,042
teach something. Right? If you
pick something out of this talk
it's the data fix tumbler.

51
00:05:29,042 --> 00:05:35,042
Anyway I guess my point is are
we even trying to explain what's
the security. You guys know that

52
00:05:44,750 --> 00:05:49,500
like if it's more than 3 you're
already hyper right.? Artificial
intelligence. It's like the

53
00:05:49,500 --> 00:05:54,167
third level of the matrix. What
is that? I mean honestly. It
kind of gets to me because  I

54
00:05:54,167 --> 00:06:00,167
mean isn't enough to go to the
cyber wars and things like that.
Do we have to scare people? I

55
00:06:16,083 --> 00:06:23,292
mean... Yeah. And I wasn't able
to find  I don't know if I
dreamed about it or if it was a

56
00:06:23,292 --> 00:06:29,083
company but I think it's
perfect. It's exactly that. It's
secure because of math. Math.

57
00:06:33,417 --> 00:06:38,833
The point, okay. This is hurting
us. Right? We are unable to
differentiate the products. The

58
00:06:38,833 --> 00:06:44,833
investors have no idea they're
funding stuff. Oh I have this
security magic there here, okay

59
00:06:47,208 --> 00:06:53,208
here is $10 million. And the
point, it's like we're not even
sure it's the same words yet in

60
00:06:55,292 --> 00:07:01,292
many levels and things. And I
mean I don't know about you
guys, I don't have a lot of time

61
00:07:03,542 --> 00:07:08,167
to waste. I don't want to be
like beta testing a bunch of
this stuff. I want to make sure

62
00:07:08,167 --> 00:07:13,833
the people that are trying to do
the research or work I can have
some way to identify more easily

63
00:07:13,833 --> 00:07:19,875
if what they're talking makes
sense or not. I have people
argue to me the point that it's

64
00:07:19,875 --> 00:07:25,417
all about communication really.
Right? If you get the people
from the technical side of

65
00:07:25,417 --> 00:07:31,417
things, right, and they try to
explain  [Laughing]. Come on
guys I have to keep a straight

66
00:07:34,000 --> 00:07:40,917
face here. And they explain to
the marketing field. This is
what we do. So we're actually

67
00:07:40,917 --> 00:07:46,875
working on this big selection
process ... No. No. No. That
sounds advanced. Yeah let's go

68
00:07:46,875 --> 00:07:52,458
with advanced. So maybe it's
that. Maybe I'm being unfair.
Maybe there's a lot of very

69
00:07:52,458 --> 00:07:58,458
different good stuff happening
under the hood but I sure as
hell cannot figure it out.

70
00:08:00,500 --> 00:08:05,208
Right? By reading what they're
doing. And anytime we try to get
a little closer it's like no,

71
00:08:05,208 --> 00:08:10,958
no, no. That's the secret sauce.
It's like someone telling you
honestly my perspective is like

72
00:08:10,958 --> 00:08:16,542
no, no, no I'm using this
proprietary crypto algorithm. To
a point it's that. So let's do

73
00:08:16,542 --> 00:08:22,542
an exercise. I want you guys to
guess the year when this was
written. So I will make it more

74
00:08:29,542 --> 00:08:35,333
simpler because there's not like
there's going to be a lot of
interaction. Of the 3 which one

75
00:08:35,333 --> 00:08:42,750
do you think was written like
today or like 2014? I would like
a show of hands for number 1.

76
00:08:42,750 --> 00:08:48,750
Okay there's like very, very few
people. Show of hands for number
2. Show of hands for number 3.

77
00:08:59,292 --> 00:09:06,167
Okay it looks like you guys
don't like to play a lot of
games. There's no right or wrong

78
00:09:06,167 --> 00:09:13,375
least all these suck so don't
worry about it. Anyway... The
first one is actually from 10

79
00:09:13,375 --> 00:09:19,375
years ago. I don't know if
there's any ISS bugs here. Guys
released a product and I used to

80
00:09:24,708 --> 00:09:30,292
work for one of the largest
integrators they had in Latin
America. It was like the hugest

81
00:09:30,292 --> 00:09:34,875
thing, we sold a bazillion. We
never could get the shit to
work. I don't know maybe it was

82
00:09:34,875 --> 00:09:40,875
just us but... If you go to  the
middle one is actually from this
year. I'm not telling you who it

83
00:09:46,125 --> 00:09:52,000
is but you can do research. And
the third one is actually when
it gets interesting. It's

84
00:09:52,000 --> 00:09:58,000
actually from 1995. It's from
actually some research that is
being done  University research

85
00:10:03,750 --> 00:10:09,750
and they created a product
pretty much like it was right
there. That sounds very

86
00:10:15,875 --> 00:10:22,417
familiar. Right? And there's
this woman, Dorothy Denning, a
respected professor at the

87
00:10:22,417 --> 00:10:29,833
graduate school she did the
first paper that came up with
what the IDS should look like in

88
00:10:29,833 --> 00:10:35,833
86. Okay there's two parts of
this. One is it's a rule based
engine where we have signatures

89
00:10:40,667 --> 00:10:47,833
and the other will be an anomaly
detection engine that will help
pick up the stuff that we don't

90
00:10:47,833 --> 00:10:53,833
have signatures for. Maybe this
will give you a hint. Let's keep
people informed that they

91
00:10:55,958 --> 00:11:01,958
shouldn't trust this part as
much as that part. So 86. And
anyway they actually built it

92
00:11:04,542 --> 00:11:10,250
out to the intrusion detection
expert system. I think people
drop the E because too many

93
00:11:10,250 --> 00:11:17,875
letters, too confusing. But the
point I find funny actually is
that from 95 was perfect

94
00:11:17,875 --> 00:11:23,708
colleagues all males stole her
work and made it like the next
generation idea. The next

95
00:11:23,708 --> 00:11:29,708
generation has been for a while
here. So anyway let's get with
the times. Right? And the point 

96
00:11:35,083 --> 00:11:41,500
everything changed because of a
3 letter acronym really. So
there was a 3 letter acronym

97
00:11:41,500 --> 00:11:47,958
that did something that was very
significant for information
security and that actually

98
00:11:47,958 --> 00:11:52,167
changed the way that we do
research and we do a lot of
things. It's probably not who

99
00:11:52,167 --> 00:11:58,167
you're thinking of. It's the
KDD. It's actually a program 
program? It's kind of a research

100
00:12:00,917 --> 00:12:06,917
track or conference from ACM and
guided by DARPA, because you
will probably never need another

101
00:12:11,542 --> 00:12:15,250
signature engine. Boy were they
right. And they decided to start
funding and creating data sets

102
00:12:15,250 --> 00:12:18,708
that people could use. So they
had their own data sets which
was focused on user anomaly

103
00:12:18,708 --> 00:12:23,792
detection. Man I'm talking like,
soloris whoa. This is what the
specific organization looks like

104
00:12:23,792 --> 00:12:29,792
for like 6 weeks. Let's see if
you can pick it up here. It was
a great success. It was a great

105
00:12:41,625 --> 00:12:47,625
success in the sense that a lot
of people started using those
data sets for research and there

106
00:13:00,167 --> 00:13:06,167
was nothing previously there
that people could reliably use
and repeat. So a lot of the

107
00:13:09,292 --> 00:13:16,833
research was based on this and
they used this to actually try
to improve their algorithms. I

108
00:13:16,833 --> 00:13:22,208
mean at first it's okay but
after a while if you go through
this  I mean it's like one

109
00:13:22,208 --> 00:13:27,792
bazillion in 99 and as you go
across the years it looks like
everyone is trying to warm up.

110
00:13:27,792 --> 00:13:34,167
The other one I got a little
better percentage the data set
and that's fine. I don't know

111
00:13:34,167 --> 00:13:40,167
what the fuck they do there but
what bothers me is that if you
do a search in Google today

112
00:13:45,083 --> 00:13:52,208
there are 300 papers in 2014
they are still using this 15
year old data set to come up

113
00:13:52,208 --> 00:13:56,583
with conclusions with what is
good you know what is bad and
what is promising in anomaly

114
00:13:56,583 --> 00:14:02,000
detection. I mean, I have no
idea what exactly is the
modifying information based

115
00:14:02,000 --> 00:14:08,583
selection but don't do it in a
15 year old data set. I'm pretty
sure things have kind of

116
00:14:08,583 --> 00:14:14,083
evolved, things are kind of
changed. Right? And I understand
that there are limitations.

117
00:14:14,083 --> 00:14:20,083
Right? I understand the
reproducibility thing. For some
respect I'm going to get to that

118
00:14:23,042 --> 00:14:26,917
but I want you guys to think
about this. I want you guys to
think about this. If you were

119
00:14:26,917 --> 00:14:32,917
going to med school and you're
going to learn anatomy and all
that you have to go for is this

120
00:14:39,083 --> 00:14:46,667
picture of Rembrandt. Right?
Granted the human body hasn't
changed that much. Right? But

121
00:14:46,667 --> 00:14:52,375
it's like hey professor what if
we cut a fresh one open? That
would be a privacy violation.

122
00:14:52,375 --> 00:14:58,375
Okay I'm not advocating like
unlawful sharing but I'm pretty
sure we can do better than

123
00:15:05,500 --> 00:15:09,583
public data sets right now. I'm
pretty sure there's enough
people interested in this that

124
00:15:09,583 --> 00:15:16,167
we can generate more stuff that
people can use for this
research. Right? And a funny

125
00:15:16,167 --> 00:15:21,958
side note is that actually there
was a professor that was pretty
much in 2000 raving about, okay,

126
00:15:21,958 --> 00:15:29,500
guys this was a bad identify.
The data sets actually sucked.
They are not representative of

127
00:15:29,500 --> 00:15:36,375
what should be going on and he
was raving about reproducibility
because, yeah, I mean it's not

128
00:15:36,375 --> 00:15:43,000
clear what technique these guys
are using. And they are like 
like they like to one up the

129
00:15:43,000 --> 00:15:48,250
other one. They have a point
percentage improvement so it
doesn't seem like we're having

130
00:15:48,250 --> 00:15:54,250
success here. That's pretty much
how everything works in academia
but I don't know. It's like for

131
00:15:56,875 --> 00:16:02,875
me it's mind blowing and people
talk a lot about potential
disconnect from academia in some

132
00:16:06,583 --> 00:16:14,042
instances. Why are we using a 15
year old data set? I don't know.
Maybe it's a joke. Maybe it's

133
00:16:14,042 --> 00:16:20,042
like if you're researching this
stuff you actually have to go
back to 1999. I'm not here to

134
00:16:25,625 --> 00:16:31,625
bash them. Right? They're all
very scary people. Right? Yeah
man. You should meet my friend

135
00:16:39,125 --> 00:16:45,125
Kyle who is a math smuggler. But
anyway I just want to put you in
the mind set. Right? You've done

136
00:16:49,583 --> 00:16:55,583
your research and let's assume
for a point that I'm making up
unnecessary fun of them and you

137
00:16:57,625 --> 00:17:03,417
have this publishing protocols
and everything which you had to
try to focus to do specific data

138
00:17:03,417 --> 00:17:09,417
sets. What I think could
potentially happen, I'm not sure
if this has actually happened

139
00:17:12,167 --> 00:17:19,083
before but I think a potential
outcome from something like that
and with apology to the guard

140
00:17:19,083 --> 00:17:25,667
life cycle I think the guy will
get to grad school. Right? And
he will be like, he will go

141
00:17:25,667 --> 00:17:31,417
there and go to the party and
everybody would be like turn
down for math. You know? And

142
00:17:31,417 --> 00:17:38,125
then they're going to come and
it's like man I got this sweet,
sweet data set. You guys want to

143
00:17:38,125 --> 00:17:43,667
have a look? You know? And he
looks at the data set and gets
hooked on it. Okay maybe there's

144
00:17:43,667 --> 00:17:48,292
interesting stuff in the data
set. Let's do research. Low and
behold he gets a bunch of

145
00:17:48,292 --> 00:17:56,042
results. These kind of things we
talk about in machine learning
is called over fitting which is

146
00:17:56,042 --> 00:18:01,500
pretty much that you know a data
set so much inside out that
you're actually writing instead

147
00:18:01,500 --> 00:18:06,958
of doing machine learning you're
writing a program to exactly
parse the data set. Right? And

148
00:18:06,958 --> 00:18:13,167
it's a very  it's a very real
problem. It happens all the
time. And it's one of the

149
00:18:13,167 --> 00:18:19,792
reasons why in model design
you're always like okay just get
random stuff. If you don't know

150
00:18:19,792 --> 00:18:25,458
want to get, get random stuff
because it doesn't have an
immune system and you need to

151
00:18:25,458 --> 00:18:31,458
try to keep it on its toes. And
that's the point. The guy
publishes a bunch of papers then

152
00:18:34,917 --> 00:18:41,083
goes to his business friend and
they're like oh my God you're
going to be rich. Right? The

153
00:18:41,083 --> 00:18:47,500
security field is so hard. And
then they go and they actually
get customer data. I don't know

154
00:18:47,500 --> 00:18:54,250
how they actually convinced
these guys. And we get to the
results, you know? I was

155
00:18:54,250 --> 00:18:58,750
expecting this thing to be
awesome. Right? But then when I
tried to realize data it's

156
00:18:58,750 --> 00:19:05,042
something that doesn't look like
it's going to work because
you're actually training a very

157
00:19:05,042 --> 00:19:10,667
biased and very weird kind of
model then you actually expose
it to real life data. It doesn't

158
00:19:10,667 --> 00:19:15,208
know what to do. What ends up
happening in my belief, right,
is that people start, okay,

159
00:19:15,208 --> 00:19:21,208
let's not do this math thing
anymore. Right? The guys get
frustrated. The business guy,

160
00:19:27,167 --> 00:19:31,708
like hey bro we have to make
some dough and yeah, okay let's
do people or something like

161
00:19:31,708 --> 00:19:37,708
that. And low and behold math is
hard. Let's go shopping. By
shopping I mean selling. Right?

162
00:19:39,833 --> 00:19:47,208
I don't know you become general
consulting company. You do
response for people. But then

163
00:19:47,208 --> 00:19:52,000
that thing you said you were
going to do specifically about
machine learning is not actually

164
00:19:52,000 --> 00:19:56,583
what you do anymore. For some
reason it still lingers in your
marketing materials. That's not

165
00:19:56,583 --> 00:20:03,583
who you are. Right. I maybe
sound a little too righteous. If
you get money to build something

166
00:20:03,583 --> 00:20:07,750
and you don't, you are going to
fail. I'm sorry... Right. What
do I know? I mean there are

167
00:20:07,750 --> 00:20:12,125
these guys that are filthy rich.
I had to think this morning if I
was going to take the bottle

168
00:20:12,125 --> 00:20:18,125
from the mini bar. But the point
is, guys, I'm pretty sure you're
successful and doing great work

169
00:20:29,875 --> 00:20:37,042
but let other people play with
the ball in a sense. If you're
not doing machine learning don't

170
00:20:37,042 --> 00:20:41,625
crowd your marketing materials
with machine learning because it
gets people confused. Right?

171
00:20:41,625 --> 00:20:44,250
There are people who are
actually trying to build
programs. There are quite a few

172
00:20:44,250 --> 00:20:51,500
startups. And I don't know if
the worst part is them or the
guys that are like hey, machine

173
00:20:51,500 --> 00:20:57,833
learning we should put that in
our brochure. It's like yeah we
deliver lemons by bicycles with

174
00:20:57,833 --> 00:21:03,833
machine learning. How does that
work? But I mean I'm pretty sure
you guys would be able to figure

175
00:21:05,917 --> 00:21:10,208
that out. I mean those two
different types of companies.
Right? There is a sweet spot.

176
00:21:10,208 --> 00:21:16,208
But there are people; ain't not
like I'm talking about myself. A
bunch of people that are doing

177
00:21:18,500 --> 00:21:26,125
research. What I'm trying to do
now for this next part of the
talk is to go through a little

178
00:21:26,125 --> 00:21:30,417
bit more technical about if
people are telling you about X
this is probably what they're

179
00:21:30,417 --> 00:21:36,417
doing and what are the potential
pitfalls. I want to start with
anomaly detection. Anomaly

180
00:21:38,792 --> 00:21:46,292
detection is kind of interesting
for me as a solution to
something because when you are

181
00:21:46,292 --> 00:21:50,833
doing machine learning research
when you're doing modeling when
you're trying to figure out what

182
00:21:50,833 --> 00:21:58,250
you're going to train and
predict against, alomaly
detection like stuff I'm pretty

183
00:21:58,250 --> 00:22:05,250
much talking about the
clustering, I'm talking about
decomposition, it's actually

184
00:22:05,250 --> 00:22:10,500
very, very important for your
exploratory phase because you
just got a bunch of data and you

185
00:22:10,500 --> 00:22:15,208
have no idea what it looks like
and what's the shape of it and
what you can do with it so we

186
00:22:15,208 --> 00:22:23,083
start asking the computer like
questions. Okay is this weird in
some way? Is there a normal

187
00:22:23,083 --> 00:22:29,083
thing going on here? And then
you use the feedback that the
model gave you so you can

188
00:22:33,375 --> 00:22:39,375
actually design something that
could potentially work. Okay.
And so my point is the kind of

189
00:22:44,167 --> 00:22:50,708
stuff you do you would have no
idea what's going on and it's
weird for people to say we're

190
00:22:50,708 --> 00:22:57,500
doing anomaly detection. You're
like what? What are you actually
doing? What is normal? What is

191
00:22:57,500 --> 00:23:03,417
weird? I mean what's the
measure? What are all those
different things? And to be

192
00:23:03,417 --> 00:23:09,417
honest this actually works very
well for when you have a very
well defined process. Right? So

193
00:23:09,417 --> 00:23:13,750
this is a factory, you're
putting together bolts, right?
And you want to measure if the

194
00:23:13,750 --> 00:23:19,750
bolts you're pumping out from
your bolt making machine,
however it's done is not like

195
00:23:19,750 --> 00:23:27,458
too big or too small. It extends
to that standard that you want
to do. They know the standard

196
00:23:27,458 --> 00:23:33,458
and you have an effective way of
measuring that. And even so when
you check your balance, it

197
00:23:39,542 --> 00:23:44,167
actually still works well. A lot
of historical work has been
done. It's way more complicated

198
00:23:44,167 --> 00:23:50,625
than that now but historical
work was based on this. How much
was this guy standing and has he

199
00:23:50,625 --> 00:23:56,625
just been to Vegas and spent ten
thousands of dollars? Never mind
he's been to Defcon. So  but

200
00:24:00,958 --> 00:24:06,958
this works because you measure
one thing like money S  you have
one operation goes in or it goes

201
00:24:10,000 --> 00:24:17,750
out. Right? And so this was
clearly picked up quickly by the
dev guys. And because when you

202
00:24:17,750 --> 00:24:22,875
think about it they're actually
running a pretty tight shop.
Right? They got all this bunch

203
00:24:22,875 --> 00:24:30,333
of server farms and different
things they can measure about
the performance of the servers

204
00:24:30,333 --> 00:24:37,458
and anyway how many databases
and all those things and when
you look at those independently,

205
00:24:37,458 --> 00:24:42,458
stuff like anomaly detection,
most people would do rooting
averages. They actually work.

206
00:24:42,458 --> 00:24:49,250
Okay I know what I'm measuring
and I know what I'm thinking
about. I know what or I should

207
00:24:49,250 --> 00:24:53,958
expect to be the norm. So it
makes very easy for a human
being to make a decision. Right?

208
00:24:58,625 --> 00:25:04,708
And it's not like  but it's not
like if the bolt is like a
little bit bigger and a little

209
00:25:04,708 --> 00:25:10,917
thinner that means it's
(unknown) threat from China.
Right? That's the leap of

210
00:25:10,917 --> 00:25:16,917
thinking that sometimes I do not
understand. I want to talk in
more detail. Here when I talk

211
00:25:19,417 --> 00:25:26,333
about that I'm specifically
talking about network/netflow
behavior analysis and also this

212
00:25:26,333 --> 00:25:32,125
new user behavioral analysis
thing which is a new hotness and
there's 3 challenges I want to

213
00:25:32,125 --> 00:25:39,708
talk about. The curse of the
missionality, the life of ground
crew and the last is my

214
00:25:39,708 --> 00:25:46,167
favorite. So the curse of
missionality is actually
something real. The point is if

215
00:25:46,167 --> 00:25:53,917
you're trying to measure a bunch
of different things at the same
time and trying to see how

216
00:25:53,917 --> 00:25:58,250
similar they are or how
different they are if you think
about anomaly detection the

217
00:25:58,250 --> 00:26:04,708
actual problem you're trying to
solve is I got this space, let's
say I have a square. Right? And

218
00:26:04,708 --> 00:26:09,875
I have a bunch of points drawn
in the square. So which one of
these is the closest together?

219
00:26:09,875 --> 00:26:15,875
That's probably normal. Right?
Because most of them are there.
But the things that are further

220
00:26:15,875 --> 00:26:21,417
apart are potentially those
anomalies. The fact is you need
to measure the distance. Right?

221
00:26:21,417 --> 00:26:28,625
Okay. So what's the point? How
do you separate a point? And you
can do some very simple stuff

222
00:26:28,625 --> 00:26:35,792
like distance which would be
like draw a straight line or the
Manhattan distance where you

223
00:26:35,792 --> 00:26:43,708
have to go straight angles.
Right. I think this is a stupid
name but it's intuitive. The

224
00:26:43,708 --> 00:26:50,042
point is when you start growing
the number of dimensions like
when you go like okay 3D, 4D,

225
00:26:50,042 --> 00:26:56,042
like 10 dimensions the actual
distances they stop meaning
stuff. They stop meaning

226
00:26:58,417 --> 00:27:04,417
anything because it's such a
huge space. Right? And until the
regulation, on the real, Las

227
00:27:06,500 --> 00:27:12,500
Vegas, United States actually
allows expanding you will not be
able to see it properly. It's

228
00:27:15,375 --> 00:27:21,333
very hard to imagine but it's
like very far away. Everything
is so, so far away. It doesn't

229
00:27:21,333 --> 00:27:27,250
make any sense. It becomes very
hard to measure distances
between things. Right? And

230
00:27:27,250 --> 00:27:33,750
another way of seeing that is if
you calculate like what's the
size of a sphere, right? So you

231
00:27:33,750 --> 00:27:39,292
have a cube. What's the size of
this sphere inside this? Which
you can argue is like what's the

232
00:27:39,292 --> 00:27:44,458
unit distance between my point
and this other point that I'm
trying to measure. Right? The

233
00:27:44,458 --> 00:27:50,750
actual volume of this sphere
compared to the cube becomes
very, very close to zero very,

234
00:27:50,750 --> 00:27:56,750
very fast. And this is a graph I
stole, because... But the point
is the practical result is

235
00:28:02,917 --> 00:28:06,250
everything looks the same.
Right? So what's the kind of
stuff I'm talking about? Can you

236
00:28:06,250 --> 00:28:09,583
give us a more practical
example? Well let's do Netflow
data. Right? I have a company

237
00:28:09,583 --> 00:28:16,625
with N nodes. Right? Okay. All
machines can talk to them. All
machines can potentially talk to

238
00:28:16,625 --> 00:28:22,625
any machine, NTC port, UDP prot.
Right? It chooses ports for each
one of these. Pretty much means

239
00:28:24,667 --> 00:28:31,542
if I have a thousand nodes I
potential have I half a trillion
possible dimensions. So

240
00:28:31,542 --> 00:28:37,542
measuring how much packets went
from one place to the other.
Okay. That's very hard to figure

241
00:28:39,875 --> 00:28:45,875
something out. Right? To be
honest this is a very, very open
problem and people have been

242
00:28:53,875 --> 00:28:58,583
trying to work. I mean this is
not like security stuff. This
isn't math stuff, this is

243
00:28:58,583 --> 00:29:03,625
actually what people have been
trying to figure outweighs to
represent the data and better

244
00:29:03,625 --> 00:29:10,667
represent the matrix to actually
solve this. And those solutions
sometimes there's breakthroughs

245
00:29:10,667 --> 00:29:16,375
and okay we have this new idea
which is going to help a bunch
of these problems and some

246
00:29:16,375 --> 00:29:22,375
become very specific. And
there's actually some companies,
right, they are basing their

247
00:29:28,958 --> 00:29:35,208
claims on anomaly detection on a
lot of research they have been
doing on trying to account for

248
00:29:35,208 --> 00:29:41,625
this problem. Some of them
believe  I mean after 20 years
of research they actually have

249
00:29:41,625 --> 00:29:47,833
some very good solutions
involving subspaces et cetera,
et cetera, et cetera. If that's

250
00:29:47,833 --> 00:29:52,458
true that is actually very,
very, very awesome because
there's a whole class of

251
00:29:52,458 --> 00:29:57,958
problems that can be solved by
this. Right? This is not just
security. I mean I do get a

252
00:29:57,958 --> 00:30:05,167
little bit, you know, sinai
glare. If people had actually
solved this, right, we would be 

253
00:30:05,167 --> 00:30:09,917
I don't know  first of all we
would be doing a killing in the
ad selling market. That's for

254
00:30:09,917 --> 00:30:15,833
sure. Second of all we could
potentially be literally free of
cancer with stuff like this

255
00:30:15,833 --> 00:30:23,125
because I mean Google just did
project baseline which is okay
let's get this DNA data and put

256
00:30:23,125 --> 00:30:29,458
the data sets together and do
some anomaly detection to figure
out what are the gene that is

257
00:30:29,458 --> 00:30:34,292
are actually not represented. So
Google with all the resources
are going to start something

258
00:30:34,292 --> 00:30:40,708
similar to this. Because it's
hard. Because it's not a solved
problem at all. Anyway people

259
00:30:40,708 --> 00:30:47,750
might have solved aspects of the
problem. It might be a good part
of their research. Right? I just

260
00:30:47,750 --> 00:30:53,750
wanted to ask. I just wanted to
try to understand and you might
not be able to understand the

261
00:30:59,333 --> 00:31:01,458
actual technical part of it. I
certainly don't. When I say
interesting that means I

262
00:31:01,458 --> 00:31:03,875
couldn't get past the abstract
otherwise I would totally tell
you about the ideas. But what I

263
00:31:03,875 --> 00:31:11,792
don't want is that you guys fall
prey to this guy. We do not want
the goal to have this one trick.

264
00:31:11,792 --> 00:31:17,583
Right? And anyway the point I'm
trying to make here guys is that
this is not something that's

265
00:31:17,583 --> 00:31:22,458
been new. It's been here
forever. Right? And it's
something that  it's something

266
00:31:22,458 --> 00:31:29,500
that you can wave your hand
away. You just have to deal with
it. Right? Just deal with it.

267
00:31:29,500 --> 00:31:34,083
Right? And try to come up with
some solutions for that. I have
to put the other glasses on

268
00:31:34,083 --> 00:31:40,083
otherwise I can't see. So
anyway... The second class is
what I talk about normality

269
00:31:45,167 --> 00:31:48,708
attacks. Which pretty much the
problem that you have in anomaly
detection in general which is

270
00:31:48,708 --> 00:31:54,708
there is no real labeling.
There's no real ground truth.
You don't know what you're

271
00:31:56,792 --> 00:32:02,333
holding against and again it
comes back to what is normal.
When you do the other machine

272
00:32:02,333 --> 00:32:09,292
learning which is label you know
that okay I think that these
things are good. I have a very

273
00:32:09,292 --> 00:32:14,000
good feeling things are good,
let's try to get them apart. So
some of the end  the problems of

274
00:32:14,000 --> 00:32:20,000
this is there's asymmetry
because there's usually much
more stuff that looks kind of

275
00:32:22,042 --> 00:32:28,583
normal than stuff that looks
anomalous. So, you have to,
sometimes you have to push the

276
00:32:28,583 --> 00:32:33,375
models too hard to actually
recognize what's anomalous and
they become problems. If you

277
00:32:33,375 --> 00:32:41,292
have detected anomaly you know
what I'm talking about. It's
hard to fine tune and also very

278
00:32:41,292 --> 00:32:47,292
easy to tamper with. Some of you
are familiar with waves and
people like the cross source. Oh

279
00:32:56,958 --> 00:33:02,958
there was a car crash here. So I
have a bunch of friends they're
about to leave work and there's

280
00:33:07,167 --> 00:33:13,167
a bunch of accidents around and
they can get out and go.
Anyway... I'm taking too long

281
00:33:15,500 --> 00:33:22,792
here. I have to rush a little
bit. Finally and I think is the
most important thing even if

282
00:33:22,792 --> 00:33:28,792
you  okay my anomalies are very
accurate. What does an anomaly
even mean? Right? Why is it

283
00:33:36,708 --> 00:33:42,667
necessarily evil? Right? And
this is a thing I saw all the
time, is that you turn on

284
00:33:42,667 --> 00:33:47,542
something like anomaly detection
engine and it picks up all sorts
of weird stuff that is not

285
00:33:47,542 --> 00:33:49,667
necessarily security. This is
mostly a problem of process, of
how do you actually put this in

286
00:33:49,667 --> 00:33:54,375
and it's funny you will never
see an anomaly detection company
specifically only marketing

287
00:33:54,375 --> 00:34:00,375
itself as security. It will also
use the word performance because
that's what anomaly detection is

288
00:34:10,125 --> 00:34:16,125
good for. I guess the point I'm
trying to make is if there's a
spy on the production server

289
00:34:18,500 --> 00:34:26,208
it's using a bench of memory,
who is more likely to have done
this? Is it the evil hacker or

290
00:34:26,208 --> 00:34:32,208
is it the hipster developer that
said yeah let's bring the
machine closer... I mean

291
00:34:39,625 --> 00:34:45,625
honestly guys. It can't be all
of that. So I just want to get
to user behavior quickly. User

292
00:34:48,125 --> 00:34:54,917
behavior actually works but
you've got to have a limited
scope. So everyone here who does

293
00:34:54,917 --> 00:35:01,333
the product security, so yeah we
are the start up or we have this
product on the web, you will be

294
00:35:01,333 --> 00:35:06,500
doing user behavioral analysis
and fraud detection things in
your product. It works

295
00:35:06,500 --> 00:35:11,792
surprisingly well because you
have a limited scope. You know
exactly your application inside

296
00:35:11,792 --> 00:35:18,250
out so you can actually program
relatively easy all the
shortcuts you need to have to go

297
00:35:18,250 --> 00:35:24,167
through some of the problems
that I described. What bothers
me, right, and again people use

298
00:35:24,167 --> 00:35:31,958
anomaly detection to actually
then view the classification
model. Right? But what bothers

299
00:35:31,958 --> 00:35:39,250
me is can this be generalized?
Right? Can we come to people and
say, oh, I just filed these. It

300
00:35:39,250 --> 00:35:45,250
works like a charm, the math is
amazing. You just have to have
role based access to all your

301
00:35:54,042 --> 00:36:00,042
users and do classifications. If
I do that I do not. This is
something that bothers me. I

302
00:36:05,125 --> 00:36:11,917
guess a lot of these companies
actually come from more of
military background where this

303
00:36:11,917 --> 00:36:18,375
is all a given. Right? And I'm
pretty sure it potentially has
good results in that

304
00:36:18,375 --> 00:36:24,000
environment. It's just that
that's not how the thing works.
Anyway... The other point is if

305
00:36:24,000 --> 00:36:30,000
I'm actually doing user behavior
do I average it all out like all
the different  oh, yeah. I was

306
00:36:33,333 --> 00:36:39,667
putting a bunch of stuff in my
expense system here because I've
been to DEFCON then it blocks my

307
00:36:39,667 --> 00:36:44,833
access to the work order because
I was dos.ing this. How does
this work, how does this

308
00:36:44,833 --> 00:36:48,958
actually interact with the
other? How does one thing
actually direct? There's a lot

309
00:36:48,958 --> 00:36:55,125
of open questions. I really wish
there was a way to build a
general user behavioral thing.

310
00:36:55,125 --> 00:37:01,125
Right? But I mean question mark
for me too. Anyway I'm very
late. I just want to quickly go

311
00:37:03,917 --> 00:37:08,583
through classification. I'm
sorry this is a repeat slide but
there's no way to talk about

312
00:37:08,583 --> 00:37:15,667
this to someone. So you're
trying to talk about cats and
dogs and you are trying to teach

313
00:37:15,667 --> 00:37:21,667
the program what is a cat and
what is a dog. The point is it's
really about how many cats and

314
00:37:23,917 --> 00:37:28,750
how many dogs and how many
different cats and how many
different dogs. If you only got

315
00:37:28,750 --> 00:37:34,167
grumpy cats in your data set you
have a serious case of bad
labeling, you will definitely

316
00:37:34,167 --> 00:37:41,667
not be able to pick this cat.
It's a happy cat. There are no
such things as happy cats

317
00:37:41,667 --> 00:37:46,250
because all the cats, so because
all the cats I've seen are
grumpy. It's a problem that's

318
00:37:46,250 --> 00:37:52,250
similar. In the sense that you
don't have a good sample. It's a
little biased. In the same way

319
00:37:55,833 --> 00:38:01,833
if it's all majestic and you
will miss this guy. I mean come
on. Poor guy. I love teen tuna.

320
00:38:05,083 --> 00:38:11,083
Tuna is awesome. Anyway there's
been malware activity. The point
is everyone has been doing this.

321
00:38:17,375 --> 00:38:24,792
There's been a lot of public
data sets and a renaissance of a
sort of research because a lot

322
00:38:24,792 --> 00:38:30,542
of people are publishing those
hundreds and hundreds of
gigabytes of malware so it's

323
00:38:30,542 --> 00:38:37,792
productive of doing this. My
opinion, right, is that we've
actually got pretty good in

324
00:38:37,792 --> 00:38:44,500
telling malware apart. I already
know this is malware so I can
know pretty much what family it

325
00:38:44,500 --> 00:38:48,917
comes from by analyzing code
paths and things like that. I've
seen interesting work in that

326
00:38:48,917 --> 00:38:55,375
field. But actually detecting
it, I mean just like that based
on this stuff it's not there.

327
00:38:55,375 --> 00:39:00,875
One of the arguments is
companies have been doing that
forever. I mean we all think

328
00:39:00,875 --> 00:39:06,875
this is brand new but the people
who started doing this, I don't
know, like 5 years ago I was

329
00:39:11,583 --> 00:39:18,000
hearing about the implementation
about story and processing the
malware. I don't think we're

330
00:39:18,000 --> 00:39:21,875
much better off. I don't think
they've actually cracked the
problem. Right? People tell me

331
00:39:21,875 --> 00:39:28,750
the lead researchers here and
there left for this other
company because the guys at the

332
00:39:28,750 --> 00:39:36,542
av's didn't believe that was the
way to go. But I don't know.
Maybe there is something here. I

333
00:39:36,542 --> 00:39:41,750
just really, really wanted to be
better than those av's on my
computer because that crashes my

334
00:39:41,750 --> 00:39:47,500
computer every single time.
Let's all hope for that. Right?
Again we have to make sure about

335
00:39:47,500 --> 00:39:55,333
the bad data. The bad specific
labels that you're picking up.
So I mean the problem is if

336
00:39:55,333 --> 00:39:59,917
you're writing a paper and
you're doing classification and
you're like, yeah, I'm comparing

337
00:39:59,917 --> 00:40:06,333
this evil effort I'm pretty sure
your models will be great. But
that's not representative of

338
00:40:06,333 --> 00:40:12,333
what is really out there, what
people actually use. So imagine
what could we possibly use to

339
00:40:18,750 --> 00:40:24,750
compare a piece of evil malware
from the internet, the file
system, that can access the

340
00:40:28,792 --> 00:40:36,083
camera and send data to a remote
controller, if there was
legitimate problems that look

341
00:40:36,083 --> 00:40:42,750
exactly like this and do exactly
this kind of thing, right, and
the point is that looking at

342
00:40:42,750 --> 00:40:47,583
that I almost thought I had it
figured out because oh my God I
know the thing that tells them

343
00:40:47,583 --> 00:40:52,167
apart is the features. Browsers
have sand boxes. So that's what
we should be looking for as a

344
00:40:52,167 --> 00:40:58,625
feature. Then I remember, ah,
sorry FireFox, we almost had
discovered but anyway... Point

345
00:40:58,625 --> 00:41:04,625
is good data. It's not so much
having all the bad samples. You
also have to have good

346
00:41:07,125 --> 00:41:12,667
representative good samples for
the research that you're trying
to do. And I'm really beating

347
00:41:12,667 --> 00:41:20,042
myself up here like everyone
makes mistakes. Right? How the
fuck do I do training of my

348
00:41:20,042 --> 00:41:26,042
machine learning models and all
that I have to show for good is
stuff for  I don't think I even

349
00:41:28,667 --> 00:41:34,667
got to use Chromium. It was not
only different classes of things
I was comparing at the time and

350
00:41:37,875 --> 00:41:45,167
were more representative of
stuff you're going to get,
right? And of course the model

351
00:41:45,167 --> 00:41:51,167
was like, oh yeah here is a
banana and a fire engine. So can
you tell these apart? Yeah I'm

352
00:41:53,667 --> 00:42:00,583
pretty sure I can. So, um,
anyway the point is don't use
bad data for good samples. I

353
00:42:00,583 --> 00:42:06,583
mean there's much more stuff and
anyway you can go for that. But
let me try to wrap it up here.

354
00:42:11,833 --> 00:42:17,833
How's it going then in right?
How have things been? So what
I've been trying to do is really

355
00:42:20,083 --> 00:42:24,583
to extrapolate information from
intelligent feeds. So the
problem I'm currently trying to

356
00:42:24,583 --> 00:42:30,875
solve is if I got a bunch of
samples of bad data and just
like mal ware the amount of

357
00:42:30,875 --> 00:42:36,458
information we have increased
exponentially for the last years
or so. So there's good samples

358
00:42:36,458 --> 00:42:43,167
there that can be used and I'm
talking about indicators and
domain indicators and things

359
00:42:43,167 --> 00:42:49,167
like that. Right? And so models
with this information and give
it the same data that an analyst

360
00:42:52,167 --> 00:42:59,000
would use. Get addresses for
analyzing. Where are they coming
from? Why should you care? You

361
00:42:59,000 --> 00:43:05,000
should care because I think it's
much easier to do everything in
the computer to do the first

362
00:43:09,958 --> 00:43:15,958
triage. If you want to do it
yourself I have some tools you
can use to reach them and do

363
00:43:23,750 --> 00:43:30,542
statistical thinking with them.
This was covered in the other
talk that I did this year. But I

364
00:43:30,542 --> 00:43:35,875
think having everything
automatic is kind of cool. And
the actual ground truth I use

365
00:43:35,875 --> 00:43:43,542
like I said is the data from the
anomaly  sorry the data from the
feeds and there's a lot of

366
00:43:43,542 --> 00:43:46,625
things I've tacked on. Using
Alexa. The good thing about
designing this model the way I

367
00:43:46,625 --> 00:43:52,625
did is that I don't have to
worry too much about data
tampering because the only thing

368
00:44:07,208 --> 00:44:12,958
that I can actually change is
the log data inside the company
which they would be sending me

369
00:44:12,958 --> 00:44:18,000
to compare this. If they're
changing the log data there's a
whole bunch of different

370
00:44:18,000 --> 00:44:23,083
problems much right? But they
cannot inject something that
would look more normal because

371
00:44:23,083 --> 00:44:28,667
I'm not really doing anomaly
detection here. All the stuff
I'm using is actually external

372
00:44:28,667 --> 00:44:32,708
to any other company. And
they're kind of hard.
[Indiscernible]. It's hard to

373
00:44:32,708 --> 00:44:38,708
change that then just to try to
inject random stuff into your
environment. False positives.

374
00:44:46,542 --> 00:44:52,542
The point is it's intrinsic and
will always be. It's like the
100 percent in machine security

375
00:44:57,917 --> 00:45:04,292
thing. There's no 100 percent
accuracy. If you do model it's
100 percent you've done

376
00:45:04,292 --> 00:45:10,042
something wrong. Go back to the
drawing board. That's the
biggest thing you can find. I

377
00:45:10,042 --> 00:45:15,083
believe it's all about you
creating an actual process
around this. Right? And the

378
00:45:15,083 --> 00:45:21,750
idea  what I'm presenting this
as is it's a way to facilitate
triage. You still have to have a

379
00:45:21,750 --> 00:45:28,667
human being to do the last leg
of the investigation and they'll
be able to actually tell us for

380
00:45:28,667 --> 00:45:34,667
feedback that something was bad
or something was not bad. And
based on all that I propose a

381
00:45:37,875 --> 00:45:41,417
buyer's guide. Specifically
these questions I've talked
about, right, these are the

382
00:45:41,417 --> 00:45:48,292
questions you should be asking
the machine learning. And for
some reason you do not use them.

383
00:45:48,292 --> 00:45:55,500
If they give you bad answers if
for some reason you try to argue
and they are like no, no, no

384
00:45:55,500 --> 00:45:59,042
we're different, you don't
understand. That's the other
guys. That's not me. I am very

385
00:45:59,042 --> 00:46:05,042
different. You know, you can
hash tag them not all
algorithms. Right? Because

386
00:46:09,708 --> 00:46:16,583
that's pretty much the argument
they're making and feel free to
tag me as well of course. But

387
00:46:16,583 --> 00:46:23,500
just make sure you disagree with
me first. Anyway this is us.
Don't take my word for it. You

388
00:46:23,500 --> 00:46:30,000
can try it out. We're trying to
get this data up and running, we
have some limited capacity. Take

389
00:46:30,000 --> 00:46:36,000
your time. I mean it might take
a little while and that's pretty
much all I have. Thank you very

390
00:46:39,667 --> 00:46:44,458
much, guys. [Applause]. 

