1
00:00:00,250 --> 00:00:05,167
>>>: Good morning party track
how are we doing? How many
people here came to learn about

2
00:00:05,167 --> 00:00:11,167
home alarm systems? Alright.
You're not going to learn about
home alarm systems. The spearker

3
00:00:21,167 --> 00:00:27,167
had a small problem with his
employer to that talk is not
going to happen I can guess and

4
00:00:29,792 --> 00:00:32,208
I'll summarize is even though I
have not read the talk.

5
00:00:32,208 --> 00:00:38,833
Your home alarm system
is kind of fucked.

6
00:00:38,833 --> 00:00:41,792
>>>: Oh, alright! Yeah. 

7
00:00:41,792 --> 00:00:49,333
>>>: So with that out of the way
let's fit in a bonus talk ok?
This is my good friend Zack, we

8
00:00:49,333 --> 00:00:55,333
go back a long way. He's going
to give you the most
entertaining talk about logs

9
00:00:57,625 --> 00:01:05,417
that you're all day. So let's
give him a big Party Track
welcome! (Clapping) 

10
00:01:05,417 --> 00:01:08,375
>>>: This is the most exciting
one because there's no other
one. 

11
00:01:08,375 --> 00:01:14,375
>>>: Okay, before we get started
this is Logan. And we'll say hi
to Logan. He was supposed to

12
00:01:19,083 --> 00:01:25,083
speak in this slot about home
alarm systems. But last week
this article came out and it

13
00:01:30,500 --> 00:01:37,125
sounds that we had to cancel.
More recently NPR got an article
with him, I pinged him a few

14
00:01:37,125 --> 00:01:43,167
times, we wanted to see if he
wanted to share some
information, but he didn't

15
00:01:43,167 --> 00:01:49,542
respond. So I wanted to post
this NPR article quick because
this summarizes pretty much what

16
00:01:49,542 --> 00:01:57,125
happened. He was supposed to be
on stage but because of the
pressure put on him he can't. So

17
00:01:57,125 --> 00:02:03,125
I'm going to leave those names
up there for a second ... and
we're moving on ... so in honor

18
00:02:09,167 --> 00:02:13,750
of Logan because he couldn't
make it I decided to start this
with a ridiculously good‑looking

19
00:02:13,750 --> 00:02:19,750
researcher so he can impress us
with his smile. And this is your
top gear top tip so if you're

20
00:02:25,125 --> 00:02:32,042
going to do this the top tip
number one is follow responsible
disclosure if you're feeling

21
00:02:32,042 --> 00:02:37,792
nice. And tip number two don't
name the vendor in a press
release unless your goal is to

22
00:02:37,792 --> 00:02:45,208
get your talk pulled and if
you're going to give the talk
and you're worried about legal

23
00:02:45,208 --> 00:02:51,958
action and go ahead and up the
skate and make sure that you
sell the job and if you're going

24
00:02:51,958 --> 00:02:58,750
to do what Logan did for the
future maybe you're considering
his talk or doing his talk, but

25
00:02:58,750 --> 00:03:04,750
instead you get me, logging by
Zack. Yeah! 

26
00:03:12,583 --> 00:03:18,583
>>>: This is Party Track, isn't
it? Okay, good. Okay, so I would
like to talk start off with what

27
00:03:22,083 --> 00:03:25,583
this talk is and what this talk
is not. So you don't have to
spend the next 45 minutes

28
00:03:25,583 --> 00:03:31,542
listening to me ramble. This is
going to be a defense focused
talk. Okay, so if you're looking

29
00:03:31,542 --> 00:03:37,375
for some sexy Ode you're not
going to find it here. We're
going to be talking about

30
00:03:37,375 --> 00:03:44,125
collecting, storing, monitoring,
parsing – having fun with logs.
And make it fun and the reason

31
00:03:44,125 --> 00:03:48,958
is because it's a reoccurring
problem we keep having it over
and over and over. We're not

32
00:03:48,958 --> 00:03:53,583
getting good logging systems put
together, we're not getting good
logging data in most situations.

33
00:03:53,583 --> 00:03:58,333
Sure you may be the 1% here who
is like "Yea I've got this shit
covered." This talk is not for

34
00:03:58,333 --> 00:04:05,250
you. And if you know what "ELK"
stands for and you're an "ELK"
rock star then you may want to

35
00:04:05,250 --> 00:04:10,833
go get a few minutes elsewhere.
Okay, this is going to be about
a 200, 300 level talk on logging

36
00:04:10,833 --> 00:04:18,167
and big logging environments.
This is not about hacking your
alarm systems and the wireless

37
00:04:18,167 --> 00:04:23,125
problems with it. This is not an
offensive security talk. And I'm
not going to be addressing the

38
00:04:23,125 --> 00:04:27,167
challenges of dealing with over
200 gigs of log data a day.
And ‑‑ and that's going to be a

39
00:04:27,167 --> 00:04:34,375
whole different barrel of
monkeys to deal with. So who am
I? ‑‑ I'm Zack. I'm a managing

40
00:04:34,375 --> 00:04:40,375
partner over in Chicago. I do
things and stuff and everybody
has their big line of

41
00:04:43,750 --> 00:04:49,750
credentials. This is mine.
Moving on. Okay, so offensives
talks can get up here and rant

42
00:04:54,125 --> 00:05:00,333
about their cool awesomeness for
a full hour about how awesome
things are ‑‑ but really we're

43
00:05:00,333 --> 00:05:04,542
not going to use a lot of that
stuff. Yea it's cool to hear
about the insecurities and this

44
00:05:04,542 --> 00:05:11,417
and thatand when we come back to
our day job we have to deal with
protecting stuff so the vast

45
00:05:11,417 --> 00:05:17,417
majority of us need more
defensive talks. So let's start
with logging... and I'm going to

46
00:05:22,208 --> 00:05:26,833
say it with an Irish or Boston
accent. Okay, so we're still
having a logging problem, we're

47
00:05:26,833 --> 00:05:32,833
still relying on log data and
log formats that are archaic ...
and we've seen that the

48
00:05:36,417 --> 00:05:40,458
technical community has this
figured out but not from a
security perspective. There

49
00:05:40,458 --> 00:05:46,417
focus is on, you know we want to
know if there's errors, what
their habits are. But InfoSec

50
00:05:46,417 --> 00:05:51,208
hasn't really figured it out ...
and I don't know if it's because
we're lazy or haven't taken the

51
00:05:51,208 --> 00:05:56,375
time to look at it, but I
figured let's dive into this a
little more. We're not going to

52
00:05:56,375 --> 00:06:01,292
talk about generating logs,
because that's easy. A
configuration file and we could

53
00:06:01,292 --> 00:06:06,125
call it a day. And I'm not going
to fill 45 minutes explaining a
config file, it will put you all

54
00:06:06,125 --> 00:06:10,875
to sleep, even if there was
music here at Party Track. We're
going to talk about the

55
00:06:10,875 --> 00:06:17,167
collecting log and storing and
processing and most importantly
the actual monitoring and

56
00:06:17,167 --> 00:06:23,167
security events for logs. Why do
we need logs? Because, Oh, I'm
just storing them. It goes

57
00:06:26,500 --> 00:06:32,958
beyond security. We need it just
from a management perspective to
convince our bosses that we're

58
00:06:32,958 --> 00:06:39,417
doing what we're supposed to be
doing and we're doing it right.
A lot of the time we have to

59
00:06:39,417 --> 00:06:45,833
deal with the compliance stuff
... okay, full disclosure I'm a
QSA now ‑‑ and I can't say

60
00:06:45,833 --> 00:06:53,292
anything about it ... so. So
logs are very short. Compliances
is going to be a driving force

61
00:06:53,292 --> 00:07:00,375
for stuff a lot of times. And we
can use that from a security
point of view of hey I've got to

62
00:07:00,375 --> 00:07:05,833
meet this ICO, PCI, HIPAA,
whatever it may be. Whatever you
have to deal with—we can use

63
00:07:05,833 --> 00:07:12,875
that to say, hey I need a little
money and time to do the cool
security stuff that I want to do

64
00:07:12,875 --> 00:07:17,708
... we need it from the security
monitoring perspective duh,
incident responses duh and from

65
00:07:17,708 --> 00:07:22,500
a technical operations side, Dev
Ops has this figured out.
They've got this figured out

66
00:07:22,500 --> 00:07:27,375
from the operational side. But
they don't really share that
information. Or we don't have a

67
00:07:27,375 --> 00:07:33,375
dev ops thing .... And let's be
honest about our current state
of logs. Most stuff just kind of

68
00:07:40,458 --> 00:07:45,000
sits there or gets deleted and
we have our logs rotate stuff
for 90 days because we have to

69
00:07:45,000 --> 00:07:50,000
for compliance reasons and it's
getting deleted or we have to
send it to some product that's a

70
00:07:50,000 --> 00:07:55,000
pretty little box or pretty
little BM or pretty little
software and we're storing it

71
00:07:55,000 --> 00:08:01,125
and when we have somebody come
in to troubleshoot it or having
an auditor or assessor come in

72
00:08:01,125 --> 00:08:07,417
and showing it to them. But
let's be honest with ourselves
and confess right now. We're not

73
00:08:07,417 --> 00:08:14,125
really watching them as much as
we should. We don't actually
watch them. And I think that a

74
00:08:14,125 --> 00:08:19,417
lot of it comes from the usual
approach of watching a log. But
so the traditional approach of

75
00:08:27,333 --> 00:08:33,083
using a syslog server and regexs
and grep and sending alerts and
if it hits a certain thing it

76
00:08:33,083 --> 00:08:39,083
doesn't really scale well. We
can take and setup for multiple
systems ... it really defeats

77
00:08:41,167 --> 00:08:43,458
the purpose and being able to
search leverage those and again
like I said we can love our

78
00:08:43,458 --> 00:08:49,458
vendor products. We have a lot
of vendors. But a lot of them
have great products out there.

79
00:08:52,417 --> 00:08:59,417
But they're expensive as shit.
And the whole model to do it
as a volume based licensing. If

80
00:08:59,417 --> 00:09:04,708
you want to log more it's going
to cost you more. But I'm hosing
my own data, it's going to cost

81
00:09:04,708 --> 00:09:08,708
you more. It makes sense from a
business standpoint and it makes
sense from an up scale

82
00:09:08,708 --> 00:09:14,625
standpoint but it can get very
expensive quickly. I was talking
to a friend the other day. They

83
00:09:14,625 --> 00:09:19,458
had a two million dollar IT
budget for all of their
operating expenses. And they had

84
00:09:19,458 --> 00:09:25,458
a large vendor and they wanted
400 thousand dollars to do the
logging for their environment.

85
00:09:30,375 --> 00:09:37,125
That's almost 25 percent of
their years budget just to do
their logs. And we can use our

86
00:09:37,125 --> 00:09:44,750
moneys more wisely and I'm not
saying that vendors are a bad
thing. If you work for a vendors

87
00:09:44,750 --> 00:09:49,167
and a lot of you probably do,
I'm not saying oh don't go buy
the big guys data. It's great a

88
00:09:49,167 --> 00:09:54,333
lot of times. If you have the
financial resources they are
definitely great. And the offer

89
00:09:54,333 --> 00:10:01,042
of not having to have the
typical talent to manage them‑‑
you can hire the guy who just

90
00:10:01,042 --> 00:10:06,333
graduated from college and say,
here have fun with this product.
And they'll figure it out. But

91
00:10:06,333 --> 00:10:11,500
we can be a little smarter since
we're people who like to tinker
with things, break things and do

92
00:10:11,500 --> 00:10:19,000
things right. Okay, I've been on
this journey to find open source
solutions. And to actually share

93
00:10:19,000 --> 00:10:23,458
the open source solutions and
how to configure them. So I
looked for scalable logging

94
00:10:23,458 --> 00:10:28,708
solutions that open sourced so
we can tinker with it and don't
have to pay a license to

95
00:10:28,708 --> 00:10:32,250
distribute. It's reliable,
scalable and secure. And
reliable and scalable is really

96
00:10:32,250 --> 00:10:37,125
important when it comes to your
log and meets the compliance
requirements that you have to

97
00:10:37,125 --> 00:10:43,958
follow. Here are our top 3
winners, we've got LogStash,
Elastic Search, Kibana, which

98
00:10:43,958 --> 00:10:49,542
I'll be talking about today, aka
ELK. Also as runner up we have
FluentD which leverages Elastic

99
00:10:49,542 --> 00:10:54,333
Search, they're a great
solution, I don't want to call
it a product because they don't

100
00:10:54,333 --> 00:11:00,667
really sell it. And there's
Graylog2 as well. Okay, as you
can tell Log Stash and Graylog

101
00:11:00,667 --> 00:11:07,458
are JAVA based, I know, boo,
hiss, JAVA memory consumption
but they work and then FluentD

102
00:11:07,458 --> 00:11:15,208
is based so groovy. So we'll be
focusing on Log Stash, kind of
going through what is this Log

103
00:11:15,208 --> 00:11:20,417
Stash, Elastic Search, Kibana
stuff and how do we get events
and process them and search them

104
00:11:20,417 --> 00:11:26,417
and most importantly impress
that boss. Okay, that's the end
of my talk and you should just

105
00:11:29,167 --> 00:11:33,458
go use it and we're done. This
is my water break. 

106
00:11:33,458 --> 00:11:40,083
>>>: Okay, so the biggest pains
for logging a lot of us face is
we're getting a lot of log data

107
00:11:40,083 --> 00:11:43,542
data from a lot of different
sources that come in all these
different formats and all these

108
00:11:43,542 --> 00:11:48,042
different time stamp formats and
sometimes they're this and
sometimes they're that. And we

109
00:11:48,042 --> 00:11:54,417
have to parse them, make sure we
have the accurate time for them.
So Log Stash processor tries to

110
00:11:54,417 --> 00:12:00,417
do that. So this is a look into
how Log Stash processes its
data. So from a shipper

111
00:12:03,042 --> 00:12:07,750
perspective that's kind of your
agents that are actually
entering those logs and sending

112
00:12:07,750 --> 00:12:13,500
them to a central source. You
have a broker that queues
everything up so it can process

113
00:12:13,500 --> 00:12:18,458
everything as fast as possible
and distribute that job across.
You have an indexer that looks

114
00:12:18,458 --> 00:12:24,833
at it as the analysis of, what
is this log, how do I parse it,
how do I tag it and where do I

115
00:12:24,833 --> 00:12:28,750
ship it and send it off to
search and storage. And then we
have the pretty little web

116
00:12:28,750 --> 00:12:33,792
interface to actually monitor
everything, sounds familiar to a
lot of other products out there.

117
00:12:33,792 --> 00:12:38,708
But the cool thing with Elastic
Search and Log Stash is that you
can scale it. So instead of just

118
00:12:38,708 --> 00:12:42,958
having system, you know you may
be logging ten gigs of data a
day and then next week you've

119
00:12:42,958 --> 00:12:49,667
got to log a hundred. Obviously
the whole talk is log all the
things. I'll start on the ramble

120
00:12:49,667 --> 00:12:54,583
of sharing logs later but the
more data we have the more we
can do actionable intelligence

121
00:12:54,583 --> 00:12:59,917
for it. So to scale it off all
you have to do is take the
little individual parts and

122
00:12:59,917 --> 00:13:04,583
split them across more systems.
So you can take a split the
broker across multiple systems

123
00:13:04,583 --> 00:13:08,583
to queue everything up and have
a little bit more redundancy.
You can take the Log Stash

124
00:13:08,583 --> 00:13:13,083
indexer split it up over
multiple systems to actually
process those logs. And then

125
00:13:13,083 --> 00:13:20,583
your Elastic Search cluster will
grow as well from the storing
and searching. Okay, so we're

126
00:13:20,583 --> 00:13:25,333
going to focus on the aspects of
collecting and shipping logs,
storing logs, processing,

127
00:13:25,333 --> 00:13:30,125
monitoring them and searching
them, and obviously there's that
generating log. So first thing

128
00:13:30,125 --> 00:13:35,458
is first the biggest reason that
a lot of us don't generate the
logs we need to is because we

129
00:13:35,458 --> 00:13:40,792
are using some commercial
product and paying based upon
how much we generate. That

130
00:13:40,792 --> 00:13:45,667
doesn't work well for security
and event monitoring because you
start to get into picking and

131
00:13:45,667 --> 00:13:50,833
choosing before you get the
intel. We should build something
that we can collect all the logs

132
00:13:50,833 --> 00:13:56,708
we want and the only costs to us
is more disc space and more
processing power which it's not

133
00:13:56,708 --> 00:14:02,708
relatively cheap compared to the
other things. And in order to
collect the logs, logs actually

134
00:14:05,875 --> 00:14:11,500
have these thigns called inputs.
And we can use the traditional
Syslog that everybody is

135
00:14:11,500 --> 00:14:17,542
familiar with. The archaic
Syslog of text and we can also
leverage Lunberjack, which is

136
00:14:17,542 --> 00:14:24,042
the thinner version that can do
the parsing of the data on the
client. We can also do time

137
00:14:24,042 --> 00:14:29,250
queries as inputs, I'll touch on
that in a second. So going
through the different systems

138
00:14:29,250 --> 00:14:34,750
you typically have to face for
your Linux, Unix and Mac logs
obviously you can leverage

139
00:14:34,750 --> 00:14:40,958
Syslog agents as is and send
that data to Log Stash or you
can also leverage the Log Stash

140
00:14:40,958 --> 00:14:44,500
agent which is JAVA based. Now
obviously you have to do that
trade off of, do I want to

141
00:14:44,500 --> 00:14:50,500
install JAVA or do I just want
to send it with SysLog? It also
supports TLS as well, so for

142
00:15:00,417 --> 00:15:06,417
those of you that are like, oh
it will lose stuff, it's not
encrypted it does support TCP

143
00:15:10,625 --> 00:15:17,333
and TLS. The good old windows
logs that everybody is making
their money off of because

144
00:15:17,333 --> 00:15:21,083
there's no good solution out
there for windows logging agent.
You're able to do it with Log

145
00:15:21,083 --> 00:15:24,167
Stash agent again installing
JAVA on systems or there are
Syslog systems that are

146
00:15:24,167 --> 00:15:27,667
available, open source, free and
community editions of them
online. So ExLog is a great one

147
00:15:27,667 --> 00:15:31,042
that basically takes whatever
you're sending it, files for
windows event logs and sends it

148
00:15:31,042 --> 00:15:37,000
off to SysLog...same thing for
the open source edition. Both of
these agents, Nxlog and Snare

149
00:15:37,000 --> 00:15:41,708
have commercial version, so
before you go they have a paid
version they also have an open

150
00:15:41,708 --> 00:15:47,375
source edition. It just doesn't
have as much "pretties." Then
obviously the third option for

151
00:15:47,375 --> 00:15:50,792
those of you who are banging
your heads about the windows
logs and how you can deploy this

152
00:15:50,792 --> 00:15:54,875
across your environment is to
just use the windows build an
event collector. Using windows

153
00:15:54,875 --> 00:15:59,000
event collector with one windows
system to kind of collect all
those logs, use that central

154
00:15:59,000 --> 00:16:03,833
event collector system to parse
the logs and then ship them off
over Syslog. That way you can

155
00:16:03,833 --> 00:16:08,000
easily deploy it with a group
policy and not to have to worry
about installing software on all

156
00:16:08,000 --> 00:16:15,125
of your production systems. And
then obviously the device logs,
your network devices, your

157
00:16:15,125 --> 00:16:18,958
storage devices, your
traditional Syslog works well
but that's one of the cool

158
00:16:18,958 --> 00:16:24,208
things about Log Stash that it
offers SNMP traps as well. So
you're able to send SNMP traps

159
00:16:24,208 --> 00:16:31,083
to it and it's able to parse
that and push it into the
logging complex. You can send

160
00:16:31,083 --> 00:16:35,750
raw socket data and then I'll be
able to parse whatever is coming
in and then able to make exec

161
00:16:35,750 --> 00:16:40,417
calls which I'll touch on in a
second. But most importantly
sometimes we focus on the

162
00:16:40,417 --> 00:16:46,417
operating system logs and
application system logs can get
fed into Syslog complex. But one

163
00:16:46,417 --> 00:16:51,833
of the biggest things we miss
are these application logs. So
we need to log more than just

164
00:16:51,833 --> 00:16:57,833
the default, "hey, I requested
this page. Moving on."
Leveraging web app logs and

165
00:17:00,292 --> 00:17:03,333
integrating into the web app
code with your development team
to generate, "hey I saw a

166
00:17:03,333 --> 00:17:07,458
password change, that seems
weird and we just got a bunch of
sessions that didn't exist."

167
00:17:07,458 --> 00:17:12,625
Send something into the main
logging complex and it creates a
single source for you and the

168
00:17:12,625 --> 00:17:16,083
rest of the security teams out
there to kind of monitor
everything and so having all

169
00:17:16,083 --> 00:17:22,042
these different aspects to pull.
And obviously you can generate
from those applications in text

170
00:17:22,042 --> 00:17:26,708
files depending on the
application that you're using,
file an event in SysLog or use

171
00:17:26,708 --> 00:17:32,083
Redis to queue up the logs and
pretty much anything. One of the
things about Log Stash is the

172
00:17:32,083 --> 00:17:36,750
ability to pull from any source
with your own plug ins. That
would be a whole other talk for

173
00:17:36,750 --> 00:17:42,208
a whole other day so we won't'
get too far deep into there but
it's an option. So what about

174
00:17:42,208 --> 00:17:48,208
the cloud? So, more and more
providers are offering cloud
infrastructure and a lot of more

175
00:17:51,208 --> 00:17:57,208
people are moving to the cloud
infrastructure are offering the
ability to grab the audit logs

176
00:18:02,625 --> 00:18:08,625
without having to do a formal
request. So a lot of people
aren't monitoring this. And

177
00:18:14,000 --> 00:18:20,000
recently, I'm trying to remember
the name that had their AWS
systems completely, poof. Code

178
00:18:23,958 --> 00:18:30,167
Spaces, thank you. Code Spaces
recently had an AWS attach and
we can argue over how their

179
00:18:30,167 --> 00:18:33,083
infrastructure was actually set
up, they should have had their
backups in a whole other

180
00:18:33,083 --> 00:18:39,083
environment that wasn't AWS but
we aren't monitoring those logs.
We are pushing all our logs, not

181
00:18:42,667 --> 00:18:49,792
we all but a lot of places are
pushing these logs and data out
everywhere and not monitoring

182
00:18:49,792 --> 00:18:53,583
it. We're not monitoring who's
logging in to our google aps
account. Somebody could be

183
00:18:53,583 --> 00:18:57,708
sitting there for months or
logging in from some other geo
location that doesn't normally

184
00:18:57,708 --> 00:19:02,833
log into and nobody is checking
AWS to see who has our API key
that may have accidentally ended

185
00:19:02,833 --> 00:19:06,542
up somewhere, something seems
weird. So some of these services
have started to offer the

186
00:19:06,542 --> 00:19:13,000
ability to actually take and
grab these logs from AWS, Google
Apps, Box, Sales Force, but

187
00:19:13,000 --> 00:19:20,542
others aren't yet. So these are
kind of a top gear top tip of
different options for logging

188
00:19:20,542 --> 00:19:26,750
when you start to pull logs from
these cloud services. AWS has
Coudtrail. Thank you! The

189
00:19:26,750 --> 00:19:32,750
gentleman is keeping me honest!
Thank you, sir ... AWS has mmmm
trail. Which basically takes

190
00:19:40,500 --> 00:19:43,375
event logs every five minutes
and pushes we can send the log
every five minutes and pushes

191
00:19:43,375 --> 00:19:48,250
them into an S3 bucket. And Log
Stash can pull those buckets and
parse those logs and google apps

192
00:19:48,250 --> 00:19:51,750
has their reports API which is
basically and API you can make
queries against. Box has their

193
00:19:51,750 --> 00:19:57,417
events API and SalesForce has
their LoginHistory now. Correct
me if I'm wrong but Office 365

194
00:19:57,417 --> 00:20:01,875
doesn't currently offer any live
parsing but you can request
them, but that doesn't help you

195
00:20:01,875 --> 00:20:06,333
with monitoring it. Drop Box,
same thing, you can see it
through their dashboard but you

196
00:20:06,333 --> 00:20:11,917
can't have any kind of API
access to it. And Gighub I have
yet to find any kind of logging

197
00:20:11,917 --> 00:20:16,917
other than enterprise. And more
and more people for some reason
think it's a good idea to push

198
00:20:16,917 --> 00:20:21,292
all of your enterprise code into
Gighub. I love Gighub, don't get
me wrong. But I think that it's

199
00:20:21,292 --> 00:20:28,042
a bad idea to push everything
out there. So LogSash can pull
from these from either an Exec

200
00:20:28,042 --> 00:20:31,042
or from a built in input. Now
you're going to be like you're
talking about all these inputs

201
00:20:31,042 --> 00:20:38,208
whatthey? This is a list of the
current version of Inputs.
There's a lot that are, we'll

202
00:20:38,208 --> 00:20:43,042
call them Alpha and we're touch
on that later. But there's a lot
that have been established,

203
00:20:43,042 --> 00:20:48,750
tested and well-rouned. So as I
said, you have Exec. Exec will
let you write any kind of shell

204
00:20:48,750 --> 00:20:54,042
script, and kind of ruby script,
any kind of command whatsoever,
take whatever the output is and

205
00:20:54,042 --> 00:20:58,750
you can send it into logging
infrastructure. And you can
customize exactly how you want

206
00:20:58,750 --> 00:21:03,292
to get that log data. If you
don't have a traditional source
of data you can start querying

207
00:21:03,292 --> 00:21:07,250
other API's and in fact you
might see also on this list
there's a Twitter plug-in. You

208
00:21:07,250 --> 00:21:11,750
can have it monitor the Twitter
stream for mentions of
something, hashtags, whatever

209
00:21:11,750 --> 00:21:17,917
and put that into yur logging
complex. That's pretty cool. And
like I said it has the S3 input,

210
00:21:17,917 --> 00:21:23,458
it's got Exec and it's got a few
other things in there as well.
So those are the different

211
00:21:23,458 --> 00:21:29,458
inputs. So as I said,
traditional inputs you can still
use. The Syslog to collect

212
00:21:35,292 --> 00:21:41,292
events and Redis and all those
other agents. And the idea then
is do you really trust a

213
00:21:44,625 --> 00:21:49,833
somewhat young product and I
didn't mention that Log Stash is
now a part of Elastic Search and

214
00:21:49,833 --> 00:21:54,583
their whole parent family so
they have commercial support
behind them. Do you really trust

215
00:21:54,583 --> 00:22:01,083
this new JAVA based application
with all of your logs all the
time? So yeah, if you're one of

216
00:22:01,083 --> 00:22:05,375
these people that live on the
wild side like me, you can send
it straight to Log Stash, like

217
00:22:05,375 --> 00:22:10,208
here have fun. But you can also
take and build a logging complex
where you're able to send these

218
00:22:10,208 --> 00:22:14,042
logs and parse these logs in
different ways. So my
recommendation is that if you

219
00:22:14,042 --> 00:22:19,208
don't always trust it you can
always build up an Arc SysLog or
SysLog or SysLog NG layer.

220
00:22:19,208 --> 00:22:24,917
Basically send the logs to the
log system first then send it to
LogStash and also send it to UDP

221
00:22:24,917 --> 00:22:29,417
and send it to traditional
filing for storage. So you still
have have that retention. And

222
00:22:29,417 --> 00:22:33,500
you still have that log being
archived elsewhere but you still
have all of the cool new

223
00:22:33,500 --> 00:22:39,500
pretties that LogStash offers.
So once LogStash has all these
events what do you do with them?

224
00:22:42,042 --> 00:22:47,833
It's kind of awesome and sucks
at the same time. It's awesome
because you can do anything with

225
00:22:47,833 --> 00:22:53,708
it ... it sucks because you can
do anything with it and you have
to learn how to do anything with

226
00:22:53,708 --> 00:22:58,542
it. So LogStash decided to make
this thing called, this parsing
engine called GROK. It still

227
00:22:58,542 --> 00:23:05,750
supports RegEx the traditional
statements but GROK is pretty
awesome as it simplifies not

228
00:23:05,750 --> 00:23:10,708
having to know RegEx. They
prebuilt all of these different
syntax in here and I'll go

229
00:23:10,708 --> 00:23:16,042
through examples in a second,
this is probably just ten
percent of them. But if you want

230
00:23:16,042 --> 00:23:22,042
a map and an IP address, a log
status level you're able to do
that with just saying what the

231
00:23:25,083 --> 00:23:31,083
syntax is. So you can just say
"word" or "data." It makes life
easy. So even those who are not

232
00:23:34,083 --> 00:23:39,625
super technical with RegEx are
able to write a pattern this
quickly to parse the patching

233
00:23:39,625 --> 00:23:43,625
logs. And this is really it. As
soon as you get an input,
obviously you need to have the

234
00:23:43,625 --> 00:23:48,958
input in there too but this is
it for the filter. Combine a
patching log, done this is it,

235
00:23:48,958 --> 00:23:54,292
happy days. What about more
complex data? The stuff that
doesn't really fit an existing

236
00:23:54,292 --> 00:24:00,292
syntax. Let's think of this as
an example, we have a typical
PAM notification. This is raw

237
00:24:03,375 --> 00:24:09,375
sys log data that I generated
August 8th. You do the math.
Basically your typical, hey PAM

238
00:24:11,875 --> 00:24:18,000
detected somebody login. Now,
this may look a little
complicated but I'm doing two

239
00:24:18,000 --> 00:24:21,708
levels of parsing here and this
is an actual working config and
I'll be posting more later. This

240
00:24:21,708 --> 00:24:27,333
is all you have to do in order
to parse it. First we parse to
see, is it a PAgrab all the daM

241
00:24:27,333 --> 00:24:33,542
message, so we look for the PAM
Unix flag, ta, pick which
module, then what phase it's

242
00:24:33,542 --> 00:24:38,458
coming from. Is it
authentication, is it
authorization? Then once you tag

243
00:24:38,458 --> 00:24:43,208
it you can see in there, there's
those add tags, add tag for PAM,
add tag for login so you can do

244
00:24:43,208 --> 00:24:48,417
filtering and bondering for it.
Once you tag it with that you
can easily say alright let me

245
00:24:48,417 --> 00:24:52,958
grab all the other data out of
it. I want to grab the user, the
session ID, I want to grab the

246
00:24:52,958 --> 00:24:59,958
remote host. And that's it for
the RegEx and it gets parsed.
And you're able to take and

247
00:24:59,958 --> 00:25:05,375
here's a quick from Elastic
Search parsing into all the
different fields and without

248
00:25:05,375 --> 00:25:10,292
having to know all of this crazy
RegEx to figure out we have a
missing case here. You're able

249
00:25:10,292 --> 00:25:15,000
to quickly say, alright grab the
data and put it into this format
and its pretty easy to figure

250
00:25:15,000 --> 00:25:20,208
out how to start parsing and
filtering your logs. But that's
not all the filters it has on

251
00:25:20,208 --> 00:25:24,708
the way in. We can tag metrics
with it. We can track to see,
alright lets grab everything

252
00:25:24,708 --> 00:25:28,542
that has a failed log in and
assign a metrics to it and know
how many failed log ins we have

253
00:25:28,542 --> 00:25:36,125
for this IP for this user over a
1 minute, 5 minute, 15 minute, 1
hour window. We can get you IP

254
00:25:36,125 --> 00:25:41,750
information with the filters as
well. Those pretty graphs that
your bosses love. I don't know

255
00:25:41,750 --> 00:25:47,458
why people love to see that we
have a bunch of attacks coming
from this other country. Did

256
00:25:47,458 --> 00:25:53,458
they get in? No, but we have a
bunch of attacks. You're on the
internet bro. But management for

257
00:25:56,208 --> 00:25:59,333
some reason loves that, you can
give them those pretty little
graphs. You can do GYP tagging

258
00:25:59,333 --> 00:26:04,208
and pull from the GYP databases.
You can do reverse DNS look ups
to be able to make your matches

259
00:26:04,208 --> 00:26:08,458
easier if you have a dynamic
environment or just want to
start logging that data. And

260
00:26:08,458 --> 00:26:14,750
then there's URL decode so you
can take a decode if you have a
URL inside of a URL. You can do

261
00:26:14,750 --> 00:26:18,500
multiline data so if it crosses
more than one line. You can do
key values so if it's a

262
00:26:18,500 --> 00:26:23,417
situation as you saw in the
previous one of our host equals,
action equals you can just key

263
00:26:23,417 --> 00:26:27,375
value it and it parses
automatically. And then the
coolest thing is it can do

264
00:26:27,375 --> 00:26:32,083
anonymize. And if you happen not
to be here in the United
States and have to not store

265
00:26:32,083 --> 00:26:37,708
data of people you can anonymize
that data as soon as it comes in
with random data or hash data,

266
00:26:37,708 --> 00:26:42,917
however you can take and
sanitize that. So those of you
who have to deal with European

267
00:26:42,917 --> 00:26:50,292
laws or other laws that say y
can't restore this after so
long, great option. So after you

268
00:26:50,292 --> 00:26:56,500
filter that data, LogStash can
output it to pretty much
anywhere. Traditionally people

269
00:26:56,500 --> 00:26:59,750
will send it to Elastic Search
for monitoring and searching.
And that's what we're going to

270
00:26:59,750 --> 00:27:04,917
cover next. But you can send it
to different indexes just like
you can with other large logging

271
00:27:04,917 --> 00:27:11,458
products. You can also do what's
really cool, it's called Exec.
So with Exec if you see a

272
00:27:11,458 --> 00:27:16,833
certain set of flags or you
parse it out and filter it out
you can take and go, oh this

273
00:27:16,833 --> 00:27:21,875
looks interesting. I want to do
something every time that I see
this. I don't want an e‑mail; I

274
00:27:21,875 --> 00:27:27,417
want it to automatically block
something. You can just make an
Exec call to whatever script and

275
00:27:27,417 --> 00:27:33,417
I'll touch on some cool things
later. If you are like me and
you don't want to keep changing

276
00:27:35,833 --> 00:27:38,792
your filters and want to
dynamically change how things
are, you can make a simple web

277
00:27:38,792 --> 00:27:42,625
call to some other monitoring
app that you wrote and say I saw
a bunch of odd things or saw a

278
00:27:42,625 --> 00:27:46,167
log in from this IP. Do
something with that. And write
up a web app, instead of having

279
00:27:46,167 --> 00:27:51,000
to script and write up all this
stuff and keep restarting your
filters you can just say send

280
00:27:51,000 --> 00:27:55,375
all this log in information to
this other web source and tell
me if I should generate any kind

281
00:27:55,375 --> 00:27:59,792
of alerts. And if you're
somebody who HipChats all day
you can send it to your chat

282
00:27:59,792 --> 00:28:06,250
logs. I don't think there is an
IRC output which I was kind of
disappointed in. If you're a

283
00:28:06,250 --> 00:28:11,583
user of PagerDuty you can send
it there or your traditional
email notifications to go in

284
00:28:11,583 --> 00:28:16,583
that bucket you never monitor.
Appliance vendors, a successful
log‑in, and if there's too many

285
00:28:16,583 --> 00:28:21,250
failed log‑ins and then you can
scale. So as I was saying you
can filter you can parse. You

286
00:28:21,250 --> 00:28:25,000
can do all this fun stuff. What
do we care about? We're sending
it to these places and we're not

287
00:28:25,000 --> 00:28:28,083
monitoring it. The biggest most
important thing is for us to
actually monitor these security

288
00:28:28,083 --> 00:28:33,833
events. So as I was saying we
setup filters and parsing and
stuff, we tag them saying this

289
00:28:33,833 --> 00:28:38,083
is a security event this is a
compliance event, this is a
failed login a success login. We

290
00:28:38,083 --> 00:28:42,208
can create all the tags you
want. Add metrics if you want to
see if there are too many failed

291
00:28:42,208 --> 00:28:47,417
logins over a certain window.
You pick the output and then you
can scale. So here are two

292
00:28:47,417 --> 00:28:53,083
simple outputs that I wrote
together real fast that shows if
it's a failed login and if it's

293
00:28:53,083 --> 00:29:00,500
been over two for this specific
user within a minute, send me an
email. That's how simple it is

294
00:29:00,500 --> 00:29:05,833
(whispering) and if you want to
send it, like I was saying all
the auth requests, you want to

295
00:29:05,833 --> 00:29:09,042
send it to some other source to
dynamically determine, hey I
wrote this cool little PHP app

296
00:29:09,042 --> 00:29:14,792
that will tell me, if you send
the IP and the username it will
determine if it's new. If you're

297
00:29:14,792 --> 00:29:19,083
comfortable with some other
language, RUBY, or whatever send
it there. You can start sending

298
00:29:19,083 --> 00:29:24,250
all these kinds of actions
elsewhere that traditional
logging complexes can't do. Yes,

299
00:29:24,250 --> 00:29:31,375
some commercial products have
worked as well, but this one is
free. So then the second

300
00:29:31,375 --> 00:29:35,792
example, obviously anytime there
is an auth request that's tagged
as an auth request after we do

301
00:29:35,792 --> 00:29:40,667
all of those filters, send it to
whatever. That's not actually
real so don't go trying to query

302
00:29:40,667 --> 00:29:47,000
that you're not going to get
anything. So as I was saying we
can do these Execs, we can do

303
00:29:47,000 --> 00:29:51,375
these remote calls. As the
security people this is awesome.
We can have it do whatever. We

304
00:29:51,375 --> 00:29:56,917
can have it update, this is for
those that like to live
dangerously on the edge. You can

305
00:29:56,917 --> 00:30:01,250
have it automatically update
firewalls, ACLS, switches, oh I
saw somebody new join the thing.

306
00:30:01,250 --> 00:30:06,458
I don't have a traditional NAC
complex, so go ahead and tell it
to disable the switchboard. Ok

307
00:30:06,458 --> 00:30:11,958
cool, Exec, dun duh dun duh dun,
wrote this cool script, done.
You're able to do that with this

308
00:30:11,958 --> 00:30:16,208
new logging complex. Notifying
user directly, hey somebody
logged in from a new IP address

309
00:30:16,208 --> 00:30:21,375
and this looks weird or it's not
from within the U.S. or whatever
country you're from, hey this is

310
00:30:21,375 --> 00:30:26,417
weird for them, let me send that
user an email and make it their
responsibility to go, hey

311
00:30:26,417 --> 00:30:31,417
security something is up, I
didn't log in. You don't have to
monitor that all and you can

312
00:30:31,417 --> 00:30:35,792
start using your logging complex
to generate those kind of alerts
directly to your users.

313
00:30:35,792 --> 00:30:40,000
Obviously notify for admin
logins, both on the internal and
external side. One of the

314
00:30:40,000 --> 00:30:45,583
greatest things (indiscernible
30:40) will talk about it, oh
yea I got admin on all these

315
00:30:45,583 --> 00:30:47,792
systems, oh yea I crawled across
the environment. Why aren't we
logging and detecting that? A

316
00:30:47,792 --> 00:30:51,542
lot of admins shouldn't be
logging in remotely typically
and why not generate events for

317
00:30:51,542 --> 00:30:56,375
people to follow up? And then
obviously for user log ins on
new machines, hey Jim doesn't

318
00:30:56,375 --> 00:31:01,250
normally log in to this machine
and I haven't seen this before,
I'm going to generate an event.

319
00:31:01,250 --> 00:31:07,250
And this is easy to do then with
these filters with these custom
outputs that some other logging

320
00:31:07,250 --> 00:31:11,708
complexes don't support. So
again, we've got the monitoring;
we've got the collection and the

321
00:31:11,708 --> 00:31:16,333
storage. What about the
searching? That's one of the
biggest problems on traditional

322
00:31:16,333 --> 00:31:22,792
Syslogs is that you have to
write, run through this text
file, wait, wait, wait, 10 gigs,

323
00:31:22,792 --> 00:31:29,167
come on give me something. So
since it's based on Elastic
Search, the crew over at Elastic

324
00:31:29,167 --> 00:31:33,917
Search, this complex has a
pretty little front end called
Kibana. Kibana pretty much looks

325
00:31:33,917 --> 00:31:38,708
like every other logging
searching thing you can ever
imagine. And you're able to

326
00:31:38,708 --> 00:31:42,917
quickly search for the events,
correlate the events. I'm not
going to go too far into Kibana

327
00:31:42,917 --> 00:31:47,125
because you can create all these
pretty custom dashboards. You
can go through have the pretty

328
00:31:47,125 --> 00:31:53,125
graphys for the management. Your
boss loves them. Do this for
your boss to get a better job.

329
00:31:55,792 --> 00:32:01,792
But no, or get a raise, sorry.
But this works great ... but
that's the pretty dash board,

330
00:32:04,583 --> 00:32:07,583
you can do all the searches, but
really like I said we are
focusing on the security side,

331
00:32:07,583 --> 00:32:13,583
getting those alerts, getting
those notifications. But you may
be going, for those of you who

332
00:32:16,417 --> 00:32:18,875
know what Elastic Search is, is
maybe going dude, uh elastic
search, really? This shit

333
00:32:18,875 --> 00:32:22,958
doesn't have any security
control whatsoever. Yea it
doesn't have security controls

334
00:32:22,958 --> 00:32:28,292
whatsoever. You would have to
build them. So as I said it's
not an easy solution but it's

335
00:32:28,292 --> 00:32:33,292
one you can scale and customize
greatly. So Elastic Search is
made so that basically you can

336
00:32:33,292 --> 00:32:37,167
cluster with everything,
multicast to figure out all the
peers. It doesn't have

337
00:32:37,167 --> 00:32:41,583
authentication and just trust
everyone, give every one pseudo
rights, yea it's bad from a

338
00:32:41,583 --> 00:32:46,333
security perspective. But it's
great from a data perspective.
So we have to build in these

339
00:32:46,333 --> 00:32:51,667
security controls on top of
that. We have to write an nginx
proxy in order to bind locally,

340
00:32:51,667 --> 00:32:55,250
really simple config. Have to
segment this stuff off on the
network so it doesn't take and

341
00:32:55,250 --> 00:33:01,083
multicast everywhere else.
Again, simple change and you
have to enable to logging on you

342
00:33:01,083 --> 00:33:06,542
nginx that you're doing the
proxy for, for compliance
reasons and for the tracking of

343
00:33:06,542 --> 00:33:10,375
that. Again, simple configs but
people are like oh, you can't
use that because of security

344
00:33:10,375 --> 00:33:17,958
reasons. You just have to add a
few additional controls. Now,
from a performance side you can

345
00:33:17,958 --> 00:33:22,667
tweak a lot more when you built
your own system. So you can take
in and tweak if you are starting

346
00:33:22,667 --> 00:33:28,292
to scale up the size of your
indexes, sometimes by default
LogStash and Elastic Search do

347
00:33:28,292 --> 00:33:33,792
daily indexes. But if you start
logging 200 gigs a day, a 200
gig index is kind of a bad

348
00:33:33,792 --> 00:33:39,167
thing, so you can start to
change the size of your indexes
to hourly, minutes, so on and so

349
00:33:39,167 --> 00:33:42,333
forth. You can increase the
number of workers in LogStash in
order to parse that stuff

350
00:33:42,333 --> 00:33:47,542
faster. You can enable
compression in elastic search.
And you can enable queuing for

351
00:33:47,542 --> 00:33:53,875
the network traffic coming in.
And the whole point of this is
so you can scale. In traditional

352
00:33:53,875 --> 00:33:58,208
systems you can't scale, you
can't cluster, it's not
tolerant. You can easily scale

353
00:33:58,208 --> 00:34:02,750
up with LogStash, elastic search
and Kibana by cleaning up more
instances of Elastic Search. And

354
00:34:02,750 --> 00:34:09,208
as I was saying putting more
steps in front of it that can
kind of distribute and spit it

355
00:34:09,208 --> 00:34:13,333
out and they recommend Redis.
Works well if you LogStash in
front of LogStash. I know this

356
00:34:13,333 --> 00:34:19,250
doesn't make sense, but it does.
So the question is: Is it as
good or better than the vendor?

357
00:34:19,250 --> 00:34:22,208
We are up here preaching, you
should look at open source stuff
and you should take and do

358
00:34:22,208 --> 00:34:27,125
something different than just
buy a product. Is it better?
It's your call. If you have a

359
00:34:27,125 --> 00:34:31,042
technical ability, a team with
the technical ability or
coworkers then yea it works well

360
00:34:31,042 --> 00:34:36,042
and doesn't come at the
licensure costs of other things.
But it's not as easy to manage

361
00:34:36,042 --> 00:34:41,333
as a paid solution. It's still
relatively young so there may be
bugs that you encounter. So if

362
00:34:41,333 --> 00:34:46,333
you're sitting there with
critical logs that you cannot
lose at all you may want to look

363
00:34:46,333 --> 00:34:51,625
as somebody who is more
established or like I was saying
add a few steps in there and

364
00:34:51,625 --> 00:34:55,417
send it off to multiple storage
locations. It lacks
authentication out of the box,

365
00:34:55,417 --> 00:34:58,917
it's something you can easily
change but you'll hear people
shacking their stick at that

366
00:34:58,917 --> 00:35:05,583
saying, you've got to be able to
authenticate to it, nginx proxy,
HT password, done. But on the

367
00:35:05,583 --> 00:35:11,375
plus side it's extremely
customizable. The price is just
right and some enterprises

368
00:35:11,375 --> 00:35:17,375
support is available. And you
can even use it in the cloud.
(Cheering) I had to wet my

369
00:35:23,000 --> 00:35:28,833
whistle there. So what's next? I
just rambled here about how
great this thing is, what's

370
00:35:28,833 --> 00:35:34,833
next? We have this thing we call
the Open PCI Project, the domain
hack PCI also works for some

371
00:35:38,500 --> 00:35:44,875
reason, I don't' know why. But
basically the idea is there
shouldn't be any secrets as to

372
00:35:44,875 --> 00:35:50,042
how to secure stuff. People have
been selling this whole magic
bean of oh we can give you these

373
00:35:50,042 --> 00:35:56,750
configs and keep reselling them.
They're configs guys, like we
can share that info, it doesn't

374
00:35:56,750 --> 00:36:01,083
provide any competitive edge and
in fact it just makes things
easier for all of us. So we have

375
00:36:01,083 --> 00:36:08,167
this thing called the Open PCI
Project, it needs an update for
all of this stuff but I'll get

376
00:36:08,167 --> 00:36:14,500
that soon. As soon as possible.
Okay, but basically to take and
share this information and share

377
00:36:14,500 --> 00:36:19,042
all the configs, all the base
parsing a VM that's ready to go
that you just spin up right

378
00:36:19,042 --> 00:36:24,083
away. And obviously the
hardening guides, Elastic
Search, insecure by default,

379
00:36:24,083 --> 00:36:29,875
some hardening guides to just,
here paste a config, it works,
great, awesome. To make it as

380
00:36:29,875 --> 00:36:36,417
close as similar to these large
commercial projects but
obviously you need a little more

381
00:36:36,417 --> 00:36:42,500
hands on support. So with that
I'm ending a bit early, I'm
sorry. I'll let you guys get in

382
00:36:42,500 --> 00:36:47,542
lines for the next talks here.
But that's me, that's the talk
about all that stuff, all in all

383
00:36:47,542 --> 00:36:53,583
log stuff. Fuck the companies
that sue people or "legal
pressure" for giving talks about

384
00:36:53,583 --> 00:36:56,958
stuff they don't want and that's
it. Thanks all! 

