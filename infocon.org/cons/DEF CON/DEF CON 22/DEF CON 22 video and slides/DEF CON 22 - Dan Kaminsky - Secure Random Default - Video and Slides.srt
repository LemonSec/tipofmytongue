1
00:00:00,000 --> 00:00:06,000
>>DEFCON, I missed you. Wow. I
mean, so, show of hands, how
many people are here for their

2
00:00:09,333 --> 00:00:15,333
absolute very first DEF CON?
Thank you! You know, I have been
doing DEF CON for a long time,

3
00:00:21,750 --> 00:00:28,083
this is about my 15th year, and
I've watched it grow up. I've
watched it grow from a tiny

4
00:00:28,083 --> 00:00:34,542
little thing at the Alexis Park
to we've kind of over filled the
Rio and the one thing that

5
00:00:34,542 --> 00:00:41,708
amazes me is just like wow,
people are just here having
incredible amounts of fun and

6
00:00:41,708 --> 00:00:47,708
joy, and did you guys see this I
hack pineapples guy? I don't
know who you are but you're my

7
00:00:51,833 --> 00:00:57,958
freaking hero. Basically this
guy's like, you're going to come
to DEF CON and you're going to

8
00:00:57,958 --> 00:01:01,917
hijack the wi-fi? Yeah, I'm
going to take that crappy piece
of gear you bought and I'm going

9
00:01:01,917 --> 00:01:08,917
to break it and if you're elite
you can fix it and if not, go
get a refund. So. Awesome. So

10
00:01:08,917 --> 00:01:13,958
what am I here to talk to you
about? So I have a little bit of
a tradition when it comes to my

11
00:01:13,958 --> 00:01:19,250
DEF CON talk. I never actually
tell people what I'm going to
talk about. Sorry, I don't know

12
00:01:19,250 --> 00:01:23,875
what I'm going to talk about.
The subjects of my talk is a
decent random number of

13
00:01:23,875 --> 00:01:29,875
generators. So, my talks are
weird for DEF CON because you
know, we're hackers, we like to

14
00:01:34,583 --> 00:01:40,583
break things. But that's not
really just what I do here. I
like to show what's possible. I

15
00:01:44,208 --> 00:01:50,292
like to show hey, we can scan
the entire internet in a series
of seconds. We can bust people

16
00:01:50,292 --> 00:01:54,375
who are doing violations of
network neutrality. There's a
few funny things we can do over

17
00:01:54,375 --> 00:02:02,250
DNS. Actually it was great, I
once had like Darth Vader
dancing on stage video streaming

18
00:02:02,250 --> 00:02:07,667
over DNS. Somebody told me you
couldn't get high bandwidth over
DNS. Somebody was wrong. But

19
00:02:07,667 --> 00:02:13,667
this is not the same thing as
just showing what can be broken.
So, let's talk about why, what

20
00:02:18,708 --> 00:02:21,958
we're actually going to talk
about today because we're going
to be here for a few hours and

21
00:02:21,958 --> 00:02:26,375
you should have some idea that
maybe there will be something
you are interested in. We have a

22
00:02:26,375 --> 00:02:31,833
bunch of subjects. We are
actually going to talk about why
random number generation keeps

23
00:02:31,833 --> 00:02:38,625
getting things owned year after
year. I have a quote which is, I
would like to not be fixing the

24
00:02:38,625 --> 00:02:44,542
same bugs 15 years from now. I'd
like to be fixing new bugs but
that would require dealing with

25
00:02:44,542 --> 00:02:50,542
the existing stuff. I want to
talk about how we're sort of
expecting users to recognize

26
00:02:50,542 --> 00:02:57,917
these huge strings of hex and
it's bullshit. I want to talk
about browser roday. There's a

27
00:02:57,917 --> 00:03:03,042
ton of vulnerabilities that are
undiscovered and they all kind
of follow the same form and we

28
00:03:03,042 --> 00:03:09,458
have to start dealing with them.
I want to talk about D DOS. We
really are getting distributed

29
00:03:09,458 --> 00:03:14,208
denial of service attacks that
are scaling at a level where
really it's an open question if

30
00:03:14,208 --> 00:03:20,208
the internet's going to keep
working. So how much did the NSA
shit the bed anyway? But before

31
00:03:23,750 --> 00:03:30,750
any of that I want to talk about
why hackers are useful and I
want to do that by discussing of

32
00:03:30,750 --> 00:03:36,750
all things, hard drives. So let
me give you a scenario. An
attacker has compromised a

33
00:03:38,792 --> 00:03:44,917
system and put something
malicious on the hard drive. How
bad could it be? What could

34
00:03:44,917 --> 00:03:50,250
possibly go wrong? Well, you
know they might have put in an
auto launching game in, you boot

35
00:03:50,250 --> 00:03:54,208
up your machine, it's got a root
kit. You might have replaced
some core operating system

36
00:03:54,208 --> 00:03:59,417
files. Maybe they got really,
really clever and they like hit
the master boot records. The

37
00:03:59,417 --> 00:04:04,208
first thing the computer does
right when it turns on is loads
some piece of malware and in all

38
00:04:04,208 --> 00:04:09,667
of these cases it sucks but at
least you can like format the
hard drive. The bad guy's gone.

39
00:04:09,667 --> 00:04:15,667
They're destroyed, right? Well,
a funny thing happens when you
start researching hard drives.

40
00:04:18,083 --> 00:04:24,083
So, little bit of a joke. What
is the difference between a hard
drive and a brick? The answer to

41
00:04:27,750 --> 00:04:33,750
this question is, given
sufficient research, there is no
difference. Never in my life

42
00:04:36,583 --> 00:04:40,708
have I done more expensive
research. Oops there goes 75
bucks, oops there it's gone

43
00:04:40,708 --> 00:04:46,708
again. See here's the deal. In
theory a hard drive is a thing
you put data on. Bits go in,

44
00:04:51,833 --> 00:04:57,833
bits come out, the bits stay the
same. In reality, we have what I
like to call exhibits iron law

45
00:05:02,042 --> 00:05:09,000
of computer architecture. Yo,
dog I heard you like computers
so I put a computer in your

46
00:05:09,000 --> 00:05:15,000
computer so you can compute
while you compute. [Applause]
Now, what is great about this

47
00:05:21,625 --> 00:05:28,625
iron law is that the more you
understand about computer
architecture the truer it gets.

48
00:05:28,625 --> 00:05:33,958
Pretty much everything that runs
automatically is another little
computer that is running on its

49
00:05:33,958 --> 00:05:40,708
own cycle that is going and
doing stuff. And of course, it's
doing it fast. It's doing it

50
00:05:40,708 --> 00:05:46,958
trusted. It's doing it
insecurely. The reality is, is
that everything in your computer

51
00:05:46,958 --> 00:05:52,958
has become very generic. Your
iPhone has 7 arm chips. The
biggest lie about a computer is

52
00:05:57,208 --> 00:06:04,917
that it's just one, okay? Every
device you have ever owned is a
small network of mutually

53
00:06:04,917 --> 00:06:12,792
trusting overly mutually
trusting devices. The hard drive
is really just another computer

54
00:06:12,792 --> 00:06:17,375
with direct access to your
system memory via specially
designed physical and logical

55
00:06:17,375 --> 00:06:22,792
protocols. Now maybe you doubt
me. Maybe you think, oh come on
Dan, you might be exaggerating.

56
00:06:22,792 --> 00:06:29,000
So let me actually show you what
actually happens when you know,
log into your hard drive. I did

57
00:06:29,000 --> 00:06:33,042
this project with Travis
Goodspeed, probably the single
most entertaining hardware

58
00:06:33,042 --> 00:06:39,542
hacker in the world. He's the
guy behind POF GTFO, proof of
concept or get the fuck out. And

59
00:06:39,542 --> 00:06:45,875
so we sit down one day. We buy a
huge stack of hard drives and it
turns out on the back of them

60
00:06:45,875 --> 00:06:51,208
there's a serial port. What
happens when you go into the
serial port? Well you know,

61
00:06:51,208 --> 00:06:57,292
there's like an entire shell. It
has documentation. It actually
tells you what your commands

62
00:06:57,292 --> 00:07:02,333
are. Oh really, edit processer
memory and here are my arguments
that I need to know for that.

63
00:07:02,333 --> 00:07:07,458
Sweet. You can get some internal
drive meta data. Like there's no
hacking here, it's like a

64
00:07:07,458 --> 00:07:12,375
straight up interface, right.
You can go ahead and you can
like learn about your main disk,

65
00:07:12,375 --> 00:07:17,000
you know public one. There's a
second one. There's an entire
system partition. You can go

66
00:07:17,000 --> 00:07:22,792
ahead and scrape through that
too. Read the data back out,
actually take a look at the

67
00:07:22,792 --> 00:07:28,375
data. You know when a hard drive
is started -initialized they run
a bunch of tests. This is a C

68
00:07:28,375 --> 00:07:34,583
gate hard drive. It's actually C
gate's test output. My favorite
part of course being being WTF

69
00:07:34,583 --> 00:07:40,583
status. Sweet. Now you might be
saying, but Dan you had to like
hook up special pins to the hard

70
00:07:45,667 --> 00:07:50,583
drive, and what? An hacker is
going to teleport to your home
and do that? No, no, no. An

71
00:07:50,583 --> 00:07:55,250
attacker's going to go ahead and
there's a great command for
messing with hard drives called

72
00:07:55,250 --> 00:07:59,917
HD parm. We're going to run help
on it. We're going grip from my
favorite phrase in computer

73
00:07:59,917 --> 00:08:05,917
security, extremely dangerous.
And you will notice nowhere does
it ask for a password but it

74
00:08:15,250 --> 00:08:21,250
totally wants the firmware to
replace the system partition. So
I wasn't kidding about making

75
00:08:24,417 --> 00:08:29,292
bricks. I actually have my lab
notes from this and it looks
like - - a wake. It's like this

76
00:08:29,292 --> 00:08:34,417
hard drive: fate, platters
exposed. Fingerprinted and I
think we actually have like our

77
00:08:34,417 --> 00:08:40,417
fingers on the platters from
where dumped is the 011 wrong.
Predicted by Dan when he went to

78
00:08:43,500 --> 00:08:47,750
the buffer, problably
repairable. Ripped by Dan with
HD parm. Ripped by Dan when he

79
00:08:47,750 --> 00:08:53,750
set the serial port to 62500.
You look at these things funny
and they blow up. I tell you

80
00:08:56,125 --> 00:09:02,917
it's the most effective security
technology of the hard drives.
So this eventually became a

81
00:09:02,917 --> 00:09:07,292
paper with a somewhat
predictable subject.
Implementation and implications

82
00:09:07,292 --> 00:09:13,958
of a stealth hard drive back
door. I'm kind of an unindicted
co-conspirator on this. They did

83
00:09:13,958 --> 00:09:21,042
10 months of work. They actually
built malicious firmware that
hides on the hard drive,

84
00:09:21,042 --> 00:09:25,667
corrupts the surrounding
operating system, whether or not
the drive's been formatted, it's

85
00:09:25,667 --> 00:09:31,667
owned forever. Kind of nice. Why
do I tell you all of this? There
is something which I have been

86
00:09:34,458 --> 00:09:41,667
discussing privately for some
time called Storage EXOR
Execution which basically says

87
00:09:41,667 --> 00:09:46,833
from an architectural
standpoint, if you have code you
are running that you know is

88
00:09:46,833 --> 00:09:52,833
malicious, that you are
completely aware is exposed to
skilled attackers, at minimum

89
00:09:55,875 --> 00:10:02,625
separate the piece of the system
that remembers, that persists,
that stores from the piece of

90
00:10:02,625 --> 00:10:09,750
the system that computes, that
operates, that parses. So sure
you can go ahead and provide

91
00:10:09,750 --> 00:10:16,625
some malicious input and own the
machine. That might happen. But
you can't keep your ownership

92
00:10:16,625 --> 00:10:22,958
without storing it somewhere
where it might get discovered.
When you actually spend time

93
00:10:22,958 --> 00:10:27,167
with attackers, one of the
things they tell you is it's not
about ownage. It's about

94
00:10:27,167 --> 00:10:32,167
continued ownage. It's about
coming back in a year and your
root kit is still ready to go.

95
00:10:32,167 --> 00:10:38,167
You don't have to break your way
back in. Ok, you can't even
start discussing storage X or

96
00:10:40,917 --> 00:10:46,917
execution if you don't have the
paranoia of realizing all of
these places to persist your

97
00:10:49,042 --> 00:10:55,250
attacks. You know, I'm one of
these rare people in information
security that is happy we are

98
00:10:55,250 --> 00:11:00,333
talking about APT, about
advanced persisting threats.
People say how can we be

99
00:11:00,333 --> 00:11:05,167
discussing this, these attacks
aren't advanced? I'm like holy
hell we have people admitting we

100
00:11:05,167 --> 00:11:10,083
have vulnerabilities we have no
idea what to do about. Great.
Stuff's not working. Let's at

101
00:11:10,083 --> 00:11:16,083
least talk about that. We aren't
even having it as a basic part
of discussion that maybe when

102
00:11:21,750 --> 00:11:29,000
you use resources in a cloud the
underlying hardware should only
be shared with other people in

103
00:11:29,000 --> 00:11:34,083
your cloud, like in your
organization. Perhaps there
should not be one piece of

104
00:11:34,083 --> 00:11:40,208
hardware for two different
customers. Two customers, one
hard - anyway. Works about as

105
00:11:40,208 --> 00:11:46,208
well as you think. This, this is
the value of hacker engineering.
See what I like about hacking is

106
00:11:52,792 --> 00:11:59,542
that we have no delusions okay?
We are willing to see what
systems are actually capable of

107
00:11:59,542 --> 00:12:06,917
from first principles. In fact
you say something's impossible
and we get to work. We are

108
00:12:06,917 --> 00:12:11,875
needed. Let me tell you, there's
a lot of people out there who
want to modify the internet who

109
00:12:11,875 --> 00:12:17,875
have no idea how it works. At
least we have a fighting chance.
You know what? I gotta say I

110
00:12:20,625 --> 00:12:27,750
like hacking all the things but
I also like all of the things.
Let me show you something very

111
00:12:27,750 --> 00:12:33,750
near and dear to my heart. This
is a cat in a shark costume on a
Roomba chasing a duck. Fuck

112
00:12:46,667 --> 00:12:54,292
yeah! The internet has changed
things. I get this cat. There's
no Bob Sagget, there's no

113
00:12:54,292 --> 00:13:00,958
America's Funniest Home Videos,
no whiffle ball hitting some kid
in the nuts. There's just the

114
00:13:00,958 --> 00:13:06,958
kitty ok, and that, that is
awesome. Ok. One of my favorite
artists she goes on television,

115
00:13:09,292 --> 00:13:14,917
she's told your music sounds
like rapping stringle. She goes
yes, why there's a market for

116
00:13:14,917 --> 00:13:22,833
Dub Step. I should play violin
while playing Dub Step. She gets
a half billion views on YouTube.

117
00:13:22,833 --> 00:13:28,833
She's a big deal now. And yeah,
she does it while playing songs
from Skyrim and Halo and Zelda.

118
00:13:30,875 --> 00:13:37,708
This appeals to my interests,
ok. Lindsay [indiscernible] has
rocked it, ok. We live in a

119
00:13:37,708 --> 00:13:43,708
world that sucks less because of
the internet. I believe in
e-mail over, like I have never

120
00:13:46,417 --> 00:13:53,250
in my life received an
interoffice memo and I hope I
never do. I prefer Skype over

121
00:13:53,250 --> 00:13:59,250
plain old telephone service. I
prefer online banking over
having to sit for hours and

122
00:14:01,625 --> 00:14:07,625
hours in line at a bank. The
internet has changed how things
work. We could lose it. Like,

123
00:14:11,167 --> 00:14:18,208
there's a level of compromise
out there when we don't get all
these nice things and there are

124
00:14:18,208 --> 00:14:24,208
some people who even prefer
that. You gotta remember, the
internet was not the first time

125
00:14:26,542 --> 00:14:32,167
we tried to create the internet.
It's very matrix like that. This
is like the 8th attempt. Who

126
00:14:32,167 --> 00:14:38,375
here knows about prodigy or
minitel or AOL? Like we tried
this a bunch of times. AOL spent

127
00:14:38,375 --> 00:14:44,375
like a billion dollars on modems
one year. Turns out it was a
good investment, they're still

128
00:14:48,542 --> 00:14:54,542
making 160 million a year off
that stuff. Grandma loves her
dial up. The reason the internet

129
00:14:57,833 --> 00:15:03,833
worked is because it was ours,
okay? This was the playground of
nerds. This wasn't biz dudes who

130
00:15:06,500 --> 00:15:13,833
made something for biz reasons.
This was nerds who were like,
I've got to send me some e-mail.

131
00:15:13,833 --> 00:15:19,833
And the key is, my God it was
cheap. No one on the internet
ever said that you had to pay

132
00:15:22,542 --> 00:15:28,708
some portion of your revenues.
People complain about paying for
DNS names. What is the ratio

133
00:15:28,708 --> 00:15:34,750
between how much money Google
makes and how much they pay for
Google.com? I don't think

134
00:15:34,750 --> 00:15:40,750
there's a smaller number.
[Laughing] 1 over Google.
Contrast that with the Apple

135
00:15:47,083 --> 00:15:54,250
situation. Oh you would like to
be on our device? 30% gross
please. YOu know it's a very,

136
00:15:54,250 --> 00:16:00,250
very different model. And the
free internet has disrupted so
much, and there are those who

137
00:16:02,500 --> 00:16:08,958
would like to disrupt it back.
So here's the challenge. We're
the guys who actually know how

138
00:16:08,958 --> 00:16:14,958
this damn thing works. We are
the people who know that
breaking everything is possible.

139
00:16:14,958 --> 00:16:21,125
We don't know that fixing
everything is impossible. Now,
you know technically it's a bit

140
00:16:21,125 --> 00:16:28,000
of a game but technically
correct is the best kind of
correct. So why do I do this?

141
00:16:28,000 --> 00:16:34,000
Why am I here? Because I see
openness to the possibilities. I
see that there's sheer joy in

142
00:16:36,333 --> 00:16:42,417
this community for understanding
how things work. I see people
willing to call bullshit on

143
00:16:42,417 --> 00:16:49,333
everything especially the parts
of security theory that are just
clearly wrong because what? You

144
00:16:49,333 --> 00:16:55,917
think everyone else in
engineering can screw up and we
in security are infallible? We

145
00:16:55,917 --> 00:17:03,833
screw things up all the time. We
just have way more attitude
about it. So, that's kind of my,

146
00:17:03,833 --> 00:17:09,833
whoa, why did everything just go
dark? Get back here. Come back.
I believe in you. All right. So

147
00:17:17,708 --> 00:17:23,708
that's the grand world vision,
kitties on Roombas. Let's nerd
out a bit. I want to talk to you

148
00:17:25,750 --> 00:17:30,667
guys about random number
generators. The generation of
random numbers, is indeed too

149
00:17:30,667 --> 00:17:36,667
important to be left to chance.
What does it actually mean to
need a random number generator?

150
00:17:46,167 --> 00:17:51,458
Many processes require a
generator of unpredictable
numbers. That means if you get

151
00:17:51,458 --> 00:17:56,583
the last thousand, you can't
figure out what the next one is
going to be, you can't go back

152
00:17:56,583 --> 00:18:03,417
and figure out what some of the
older ones were that you missed.
Now, just because we require a

153
00:18:03,417 --> 00:18:08,458
strong random number generator
doesn't mean we're actually
getting strong random number

154
00:18:08,458 --> 00:18:12,667
generators. Here's a couple of
various talks, How I met your
girlfriend, yeah that's a great

155
00:18:12,667 --> 00:18:19,708
Sammy cam car. Yeah there's many
web applications are failing
professional management, expert

156
00:18:19,708 --> 00:18:25,500
information for Python,
unexplained information from
Ruby. What the hell is going on?

157
00:18:25,500 --> 00:18:29,708
Well the deal is that all of
these various web frameworks
don't actually log into them

158
00:18:29,708 --> 00:18:35,708
that frequently. One of my
friends was an admin at a major
e-commerce site. He's like yeah

159
00:18:39,167 --> 00:18:44,000
-- wait, wait we have an
interruption. >> Excuse me. So
as you all know we have a

160
00:18:44,000 --> 00:18:49,792
tradition here at DEF CON with
new speakers. We have a new
speaker with us this year his

161
00:18:49,792 --> 00:18:55,792
name is Kamen Skow, Kamen Skow.
I think that's the right way to
pronounce this. >> No, I think

162
00:18:58,042 --> 00:19:04,042
you messed it up. Try again. >>
Kami Cow? Kami Cow. Yah, it's
Kami Cow. Anyway. >> Come here.

163
00:19:06,333 --> 00:19:12,333
It's good to be back. >> Yah,
it's good to see you. >> Cheers.
>> Cheers. Magnificent bastards!

164
00:19:20,375 --> 00:19:25,708
>> New speakers and really
fucking old speakers. >> Oh
snap. >> It overflows back to

165
00:19:25,708 --> 00:19:31,708
zero. [Laughing] >> Actually I
missed a year, so. So the deal
is this. You have literally one

166
00:19:42,125 --> 00:19:48,125
of the largest e-commerce sites
in the world. >> We found a
phone. Does anybody -- >> I'd

167
00:19:56,083 --> 00:20:02,875
say drink, but I just did. Yes
you've got one of the largest
e-commerce sites in the world

168
00:20:02,875 --> 00:20:07,625
and you would be like how many
log-ins per second do you
process? You would think it's

169
00:20:07,625 --> 00:20:13,625
like tens of thousands or
thousands. Hundreds? They're
like hundreds? Yeah. Seven.

170
00:20:15,625 --> 00:20:22,292
Seven times a second we have to
accept a password. And it's
surprising but when you actually

171
00:20:22,292 --> 00:20:28,500
think about what happens you put
in your password, you get a
cookie, that is now password

172
00:20:28,500 --> 00:20:34,708
equivalent, that's the thing
that's shoved into the web app
every single time you visit.

173
00:20:34,708 --> 00:20:42,375
That value ideally is a random
value. Man, it would suck if you
could go ahead log in a thousand

174
00:20:42,375 --> 00:20:49,208
times then predict the next
thousand log-in magic numbers.
Yeah but that's actually totally

175
00:20:49,208 --> 00:20:55,208
what's happening. More recently,
a few days ago - awesome attack.
One of the - mmm, it was so

176
00:20:57,917 --> 00:21:04,042
beautiful. A guy by the name of
Dominique Bongard reversed the
ID on twitter. Came up with an

177
00:21:04,042 --> 00:21:10,042
attack against a scheme called
WPS. WPS exists so that you can
relatively efficiently negotiate

178
00:21:12,875 --> 00:21:17,833
with an access point and find
out what the pass rate is, you
can log in and use the internet.

179
00:21:17,833 --> 00:21:24,792
And they made up this incredibly
ill advised protocol for it. I
mean just like, like

180
00:21:24,792 --> 00:21:32,667
impressively. But the one part
of the protocol that wasn't
actually awful was this piece

181
00:21:32,667 --> 00:21:38,167
where at the beginning you have
some random value, you have some
value and it's encrypted with

182
00:21:38,167 --> 00:21:44,167
128 bit key. It's randomly
generated but it's encrypted and
you know, breaking 128 bit key

183
00:21:47,333 --> 00:21:51,750
is not going to happen. Like
that's a 20 to the 128 work
effort. That's going to take

184
00:21:51,750 --> 00:21:58,708
until the end of the universe.
However it requires you to
actually have 128 bits of

185
00:21:58,708 --> 00:22:06,625
entropy which none of the
devices did. Device one had
what's called an LFSR, a linear

186
00:22:06,625 --> 00:22:11,417
feedback shift register. They
keep showing up in this space
because they're the quickest and

187
00:22:11,417 --> 00:22:18,000
easiest way to get this stream
of numbers. You start with a
seed value and it keeps rolling

188
00:22:18,000 --> 00:22:23,875
and rolling and rolling. Well
the seed value in the first
device was 32 bits long so you

189
00:22:23,875 --> 00:22:30,792
try all 32 bits in combination.
Second one another 32 bits. The
third one just encrypted with

190
00:22:30,792 --> 00:22:36,792
zero. God. Beautiful attack. So,
let's talk about why really we
keep getting owned by random

191
00:22:46,583 --> 00:22:52,958
number generators. And the most
important thing to realize is
there's a huge amount of

192
00:22:52,958 --> 00:23:00,292
discussion in the cryptographic
world about the absolute right
way to build a cryptographically

193
00:23:00,292 --> 00:23:07,375
secure random number generator
and for the love of God, most of
it doesn't matter. No one's

194
00:23:07,375 --> 00:23:14,000
getting owned because they use
Shaw 1 or Shaw 256 or hell, MD4.
No one's getting owned because

195
00:23:14,000 --> 00:23:19,333
they use hash instead of
HMACDBRG. They're not getting
owned because they used the same

196
00:23:19,333 --> 00:23:23,667
entropy for too long, they
didn't mix in new entropy. We're
not getting owned because we had

197
00:23:23,667 --> 00:23:30,833
one pool instead of 32 pools.
Like there's a disconnect
between what's getting us owned

198
00:23:30,833 --> 00:23:37,875
and what we argue about. The
fundamental truth is there's
like a thousand different ways

199
00:23:37,875 --> 00:23:44,833
to build a cryptographically
secure pseudo random number
generator and they all have an

200
00:23:44,833 --> 00:23:52,125
incredibly high security margin.
That is the fundamental truth.
When you actually look at the

201
00:23:52,125 --> 00:23:58,917
systems in the field that are
breaking and they're all
breaking, your two problems are

202
00:23:58,917 --> 00:24:05,750
one, there's no entropy at all
and two we're not even using
cryptographically secure pseudo

203
00:24:05,750 --> 00:24:11,750
random number generators. We're
using LFSRs. We're using crap.
This is what's actually

204
00:24:11,750 --> 00:24:17,750
happening. So let's talk about
the no entropy problem. What
does a cryptographically secure

205
00:24:20,500 --> 00:24:28,042
pseudo random number generator
do? It takes a little bit of
entropy. 128 little values that

206
00:24:28,042 --> 00:24:34,833
are either 0 or 1, that have no
particular pattern. It takes
that little tiny chunk and

207
00:24:34,833 --> 00:24:40,833
spreads it out into number after
number after number, gigabytes,
hundreds of gigabytes, whatever.

208
00:24:42,875 --> 00:24:49,083
Your idea is from an attacker's
standpoint you can look at as
much of this output as possible.

209
00:24:49,083 --> 00:24:55,083
You learn nothing about the
secret. Your best attack is
unfortunately to guess what all

210
00:24:58,000 --> 00:25:04,000
128 bits of that seed are and
it's just not feasible. There's
too many. Now, in order for this

211
00:25:08,083 --> 00:25:14,083
to be true you actually need 128
bits. What killed WPS is there
actually wasn't. Generally there

212
00:25:16,333 --> 00:25:23,917
was 32 bits which is a meaning,
which is a successful amount to
break. One case there was 0.

213
00:25:23,917 --> 00:25:30,625
This isn't an obscure bug. Nadia
Henninger did this incredibly
beautiful attack a few years ago

214
00:25:30,625 --> 00:25:38,458
where she found one out of 200
RSA keys on the internet were
actually badly generated. Now

215
00:25:38,458 --> 00:25:46,417
here's what's scary. If she
finds that 1 out of 200 keys are
identical, the method she used

216
00:25:46,417 --> 00:25:53,250
doesn't actually tell her if the
keys are almost identical. If
there's a single bit of

217
00:25:53,250 --> 00:25:59,250
difference, otherwise everything
is the same, Nadia's method
wouldn't be able to find it. So,

218
00:26:02,000 --> 00:26:07,833
unfortunately we have this
really ugly situation where 1
out of 200 is a floor and really

219
00:26:07,833 --> 00:26:13,875
it's something like 1 out of 50
keys on the internet is bad.
That's an incredible failure

220
00:26:13,875 --> 00:26:19,750
rate. Shouldn't Dev random and
Dev U Random have prevented
this? Because these keys are

221
00:26:19,750 --> 00:26:26,875
actually being generated out of
what are supposed to be well
engineered kernel systems. Let's

222
00:26:26,875 --> 00:26:32,875
talk about why we actually
really do like kernel random
number generators. First off

223
00:26:35,250 --> 00:26:41,125
when you have hardware in the
machine - in your computer,
remember, the biggest lie of a

224
00:26:41,125 --> 00:26:48,250
computer is it's just one
computer. When one of the other
pieces on the computers talks to

225
00:26:48,250 --> 00:26:55,667
your CPU, literally what happens
is a piece of the kernel is run.
An interrupt is fired, the CPU

226
00:26:55,667 --> 00:27:03,625
jumps to a certain point. You
get a time stamp at that. You
now have an interaction of

227
00:27:03,625 --> 00:27:11,125
someone else's clock with yours.
You ever wonder what it means to
actually collect random

228
00:27:11,125 --> 00:27:16,833
information? What it means to
collect entropy? Like what are
you doing? At the end of the day

229
00:27:16,833 --> 00:27:23,292
what you're doing is you are
measuring a slow system with a
fast system. You know I can snap

230
00:27:23,292 --> 00:27:28,125
my fingers and I think I have a
rhythm going. You think I have a
rhythm going accurate to the

231
00:27:28,125 --> 00:27:35,500
nanosecond? No I don't because
that's not how accurate human
systems are. We are at best

232
00:27:35,500 --> 00:27:41,500
accurate to the hundredth of a
second. When you have a computer
that says I'm going to watch

233
00:27:43,583 --> 00:27:47,875
your mouth's movements, I'm
going to watch interkey stroke
timings you basically have a

234
00:27:47,875 --> 00:27:54,875
situation where a CPU that is
running at billions and billions
of cycles a second is measuring

235
00:27:54,875 --> 00:27:59,500
a system that's running at
hundreds of times a second. And
that's what's happening in this

236
00:27:59,500 --> 00:28:04,125
kernel situation. The kernel is
seeing an event come in and it's
hoping it's coming from some

237
00:28:04,125 --> 00:28:10,125
other computer that's running
slower or at least out of its
control. Another great thing

238
00:28:10,125 --> 00:28:14,750
about kernel RNGs is that
there's just one kernel, at
least ideally. So you don't have

239
00:28:14,750 --> 00:28:19,875
some situation where one process
is doing something right and one
process is doing something

240
00:28:19,875 --> 00:28:27,750
wrong. Every process benefits
from whatever randomness is
available. It's shared. Finally,

241
00:28:27,750 --> 00:28:34,458
this is tricky stuff and one of
the whole points of an operating
system is to take tricky stuff

242
00:28:34,458 --> 00:28:40,458
and put it into a box that smart
people build it and it's done
right. So that was the idea.

243
00:28:42,667 --> 00:28:48,500
What went wrong? Well all those
devices that were going ahead
and generating these random

244
00:28:48,500 --> 00:28:56,167
keys, all these devices were
started up. There was nobody at
the keyboard. There was nobody

245
00:28:56,167 --> 00:29:03,833
at the mouse. There was no hard
drive to be getting friction
from air. There were no events

246
00:29:03,833 --> 00:29:08,625
coming in from the hardware. It
was just sitting there. And if
you have got no events you've

247
00:29:08,625 --> 00:29:14,625
got no entropy to operate on.
Now, it would be nice if CPUs
actually had hardware random

248
00:29:16,833 --> 00:29:22,125
number generation but for
whatever reason that just
consistantly seems to be outside

249
00:29:22,125 --> 00:29:29,458
the purview of our modern CPU
manufacturers. You just can't
figure out how to do it. So how

250
00:29:29,458 --> 00:29:36,292
do you solve this problem? Like
really? The truth is you don't
have to be perfect. You could

251
00:29:36,292 --> 00:29:42,208
fail every once in a while and
you're still going to beat the 1
9 out of reliability that we got

252
00:29:42,208 --> 00:29:48,208
out of RSA. That really sucks.
You have to force the synthesis
of events. You have to actually

253
00:29:51,083 --> 00:29:59,042
force the situation where the
device, whatever device that it
actually is has something on a

254
00:29:59,042 --> 00:30:05,750
slower clock that's pinging the
fast clock. And realistically
what that means is using the

255
00:30:05,750 --> 00:30:11,208
realtime clock which tends to be
a separate chip, tends to run at
some amount of kilohertz and

256
00:30:11,208 --> 00:30:17,500
having that ping the CPU which
tends to be running at some
amount of hundreds of megahertz

257
00:30:17,500 --> 00:30:24,917
to gigahertz. This actually
works. Now you can also go ahead
and do some actions that take a

258
00:30:24,917 --> 00:30:30,458
hopefully non-deterministic
amount of time. So reading
values out of memory, causing

259
00:30:30,458 --> 00:30:36,333
contention for resources. You
want to do what's called
whitening. So that means you

260
00:30:36,333 --> 00:30:42,542
take any sequence of bits, if
it's a 00 you throw it out. If
it's a 11 you throw it out. The

261
00:30:42,542 --> 00:30:47,625
0 to 1 transition is considered
a 0. The 1 to 0 transition is
considered a 1. This is what's

262
00:30:47,625 --> 00:30:54,125
called debiasing your data. I
released a piece of code called
DOCORAND about two years ago.

263
00:30:54,125 --> 00:31:02,000
DOCORAND was based on truerand
from Matt Blaze from about 10
years ago. I think it was like

264
00:31:02,000 --> 00:31:08,000
1996. If we had followed Matt
Blaze's guidance in 1996 we
would not have a single 9 of

265
00:31:11,750 --> 00:31:19,708
reliability for RSA in you know,
2012. That wouldn't have
happened. Part of security is

266
00:31:19,708 --> 00:31:25,417
accepting maybe there is some
weird ass environment where
Docorand fails but is it going

267
00:31:25,417 --> 00:31:31,417
to fail as much as status quo?
No. No it's not. So let's talk
about the larger issue. Even

268
00:31:37,417 --> 00:31:42,792
worse than the fact that we
don't have true entropy to seed
this cryptographically secure

269
00:31:42,792 --> 00:31:50,750
pseudo random number generator
is the fact that we're not
actually using the CSPRNGs at

270
00:31:50,750 --> 00:31:56,500
all. When you look at the
languages that people use to
write software, JavaScript has

271
00:31:56,500 --> 00:32:02,500
math random. LFSO. Ruby has ruby
rand. LFSR. Java has Java util
random. PHPrand. Glib C. It's

272
00:32:07,167 --> 00:32:13,167
all crap. Why? Why are we doing
this? Well, what ends up
happening is every time someone

273
00:32:17,417 --> 00:32:24,500
complains about the nature of
the random number generator that
we have we end up making secure

274
00:32:24,500 --> 00:32:30,500
random. It's not fixing the old
broken stuff. We make some new
API. Then we make it weird. It's

275
00:32:34,000 --> 00:32:41,167
never just like math dot secure
random. It's like bar A equals
nu, into ray 1 window crypto get

276
00:32:41,167 --> 00:32:47,167
random values. What? That wasn't
what I was using when it was
easy. Why are you making secure

277
00:32:49,375 --> 00:32:55,375
not easy and not default? Does
that work anywhere else? No. So
why not be secure by default?

278
00:33:00,625 --> 00:33:07,333
Why not instead of requiring
some weird ass random API, why
not take the broken APIs and

279
00:33:07,333 --> 00:33:14,375
make them not broken? So thus,
we've actually been doing that.
Ryan Casaluchi works with me

280
00:33:14,375 --> 00:33:21,333
over at White Ops and what we've
been doing is systematically
going through each and every one

281
00:33:21,333 --> 00:33:29,208
of the popular web programming
environments and we're taking
their crappy little math randoms

282
00:33:29,208 --> 00:33:35,708
and making them a shell for DEVU
random. So we've gotten
JavaScript for node in the

283
00:33:35,708 --> 00:33:41,708
browsers. We've gotten ruby.
We've made C's rand function
actually Rand. PHP, Python, Open

284
00:33:44,708 --> 00:33:50,583
JDK. It's not like it's that
hard to write this code. We
actually just need to write it

285
00:33:50,583 --> 00:33:58,458
and get it something that people
agree hey, maybe we should just
have an easy to use path here.

286
00:33:58,458 --> 00:34:03,458
Now, there's gonna be some run
time features support like being
able to interrogate how good is

287
00:34:03,458 --> 00:34:09,583
this random number generator? Do
we support fixed seeds? Do we
support high speed? So I'm going

288
00:34:09,583 --> 00:34:14,333
to do something now, which I
love, which people tend to call
when I play chess against

289
00:34:14,333 --> 00:34:20,333
myself. Let's talk about what's
wrong with what we've named
Liburandy. Besides the name. >>

290
00:34:24,750 --> 00:34:28,333
[indiscernible] >> Ryan actually
named it and I'm like sorry
can't think of this code as any

291
00:34:28,333 --> 00:34:35,583
other name now. There are two
reasons why generally you
wouldn't use an approach like

292
00:34:35,583 --> 00:34:41,583
this. The first reason is
testers tend to like predictable
test results. So they tend to

293
00:34:45,542 --> 00:34:51,208
like situations where they can
say I want it to be a random
stream but I want it to be the

294
00:34:51,208 --> 00:34:57,667
same random stream so the system
will always behave in a
predictable way that can be

295
00:34:57,667 --> 00:35:03,667
regression tested. Now, I
actually never ever like this
approach and here's why. People

296
00:35:06,542 --> 00:35:13,917
say it's a two line change. Why
do you need to go ahead and
retest everything for a two line

297
00:35:13,917 --> 00:35:21,125
change? And here's the answer.
It's because there's a bunch of
bugs that don't show up in the

298
00:35:21,125 --> 00:35:28,292
field for - not because there
isn't a bug, but because the
house of cards fell in just the

299
00:35:28,292 --> 00:35:35,625
same precise way so that when
the memory corruption occurred,
nothing bad visibly happened.

300
00:35:35,625 --> 00:35:41,625
And so when the house of cards
falls the same way every time
you never discover the bug. And

301
00:35:44,000 --> 00:35:49,833
you only discover it when you do
that two line change that
shouldn't break anything. But

302
00:35:49,833 --> 00:35:55,042
now the house of cards falls
like this and now everything
blows up. I really don't like

303
00:35:55,042 --> 00:36:01,042
these sort of fixed seeds
because they allow the ugly bugs
to stay unfound unless you go

304
00:36:03,250 --> 00:36:08,083
ahead and do like a complete
massive retest. Which now have
to do every time because you

305
00:36:08,083 --> 00:36:14,083
keep getting burnt. It sucks.
But people want it so okay we'll
go ahead and do a special mode

306
00:36:16,167 --> 00:36:21,083
for Liburandy that allows you to
say no, no, no I intentionally
want my randomness to suck. Okay

307
00:36:21,083 --> 00:36:27,083
fine we'll set an environment
flag. More seriously U random is
actually slower than LFSRs. So

308
00:36:31,417 --> 00:36:38,208
you do have a situation where
it's 4 megabytes a second out of
U random and 260 megabytes a

309
00:36:38,208 --> 00:36:44,208
second out of your crappy bad
randomness. And when you
actually look at the - so I was

310
00:36:48,833 --> 00:36:56,667
interested. I believe in being
historical. Let's look at the
historical record and see why

311
00:36:56,667 --> 00:37:01,750
did these APIs get screwed up
like this in the first place?
And at least in the browser case

312
00:37:01,750 --> 00:37:07,000
they realized they had a bad
random number generator but they
also had benchmarks. And they

313
00:37:07,000 --> 00:37:11,750
really didn't want to lose at
the benchmarks. It's like well
we're not secure but we're not

314
00:37:11,750 --> 00:37:17,750
being benchmarked for security.
Fuck. So even at 4 megabytes a
second, it's still like a

315
00:37:22,458 --> 00:37:28,458
million random numbers a second.
It's generally fast enough for
everything, but not always. So

316
00:37:31,542 --> 00:37:37,667
this brings up the question
should we be using a user space
cryptographically secure pseudo

317
00:37:37,667 --> 00:37:42,792
random number generator? Now it
doesn't mean that we don't use U
Random, we still mine it as

318
00:37:42,792 --> 00:37:47,500
frequently as we might like. If
it happens to get some new bits
of randomness from the kernel,

319
00:37:47,500 --> 00:37:54,625
great. Let's use them, let's
integrate them in. But like I
said a few minutes ago, pretty

320
00:37:54,625 --> 00:38:01,208
much every variant of a CSPRNG
is still secure. So one of the
fastest hashes out there is

321
00:38:01,208 --> 00:38:07,708
what's called siphash. It comes
from our buddy DJB. If you just
siphash seed with and

322
00:38:07,708 --> 00:38:13,875
incremented counter this
actually works. It's 20 times
faster than DEvu random on

323
00:38:13,875 --> 00:38:18,625
Linux. It's competitive with
then non-cryptographically
secure pseudo random number

324
00:38:18,625 --> 00:38:25,458
generators. I guess what I'm
trying to tell you is there's no
advantage to sucking. You can be

325
00:38:25,458 --> 00:38:31,458
fast and secure. It's okay. Now,
there is a possible improvement
that we could do and that is the

326
00:38:33,667 --> 00:38:41,042
integration of time. Specifially
it was called Clock monotonic.
Now while you can't get, for

327
00:38:41,042 --> 00:38:47,375
whatever mysterious reasons,
NSA, a good hardware random
number generator, you can at

328
00:38:47,375 --> 00:38:53,375
least get a time stamp. And it
turns outs you just need bits
that are different. We've got

329
00:38:57,500 --> 00:39:05,000
this problem with what is called
forking where you have a
process. You make a copy of it.

330
00:39:05,000 --> 00:39:10,500
The copy has the same seed and
the same counter value. Now you
have the same entropy happening

331
00:39:10,500 --> 00:39:16,500
twice, and it sucks. If you
integrate time, it turns out
empirically it's a pain in the

332
00:39:19,250 --> 00:39:26,042
butt to get two things to happen
at exactly the same CPU
nanosecond. It's not that it

333
00:39:26,042 --> 00:39:32,042
can't, it's that it won't.
That's a good thing. So you
could actually have on a per

334
00:39:34,792 --> 00:39:42,292
query to the random interface
basis you could actually say
give me this time stamped view

335
00:39:42,292 --> 00:39:48,750
of the randomness. So my
preferred CSPRNG looks something
like siphash and the seeker,

336
00:39:48,750 --> 00:39:54,458
counter the previous output and
what I call the shifted time. So
you don't just do the time

337
00:39:54,458 --> 00:39:59,667
directly, you shift it by some
amount so the attacker can't
just say, well I know according

338
00:39:59,667 --> 00:40:05,500
to NTP that this value is going
to be almost zero. It forced
there to be some fixed offset.

339
00:40:05,500 --> 00:40:13,125
I'm not doing this yet in
Liburandy and here's why.
Reasonable people can disagree

340
00:40:13,125 --> 00:40:19,125
about whether CSPRNG should be
in user space and kernel space
but we all hate LFSRs so let's

341
00:40:21,292 --> 00:40:28,958
at least do something which
causes those damn things to die.
Another change is maybe we don't

342
00:40:28,958 --> 00:40:34,875
use siphash. It turns out
because of quirks you can do
faster with Blake. You can

343
00:40:34,875 --> 00:40:40,167
really do faster with Skind. So
both of them are alternate
hashing systems. We've found

344
00:40:40,167 --> 00:40:46,083
things that are twice as fast.
So really the right answer at
the end of the day might not be

345
00:40:46,083 --> 00:40:53,500
do a user space CSPRNG, it may
be, fix up the really weird one
inside of Linux. Which is

346
00:40:53,500 --> 00:40:59,500
obsessed with, you know mixing
stuff in multiples, etc., etc.
The problems we don't have. So,

347
00:41:02,333 --> 00:41:08,250
that's kind of the soup to nuts
on what's going on with entropy
generation. But there's another

348
00:41:08,250 --> 00:41:15,375
problem around representation.
Apparently you are supposed to
do something with

349
00:41:15,375 --> 00:41:21,375
D3BO7384D1NGJU42MA1$JH-89 and
whatever the hell that is
squiggly stuff. What the hell is

350
00:41:30,667 --> 00:41:36,667
that? Stop puking bits. We are
lying to ourselves if we think
users can do anything with that.

351
00:41:42,625 --> 00:41:48,625
They are lost. The problem is,
is that computers actually needs
humans to recognize and to

352
00:41:52,167 --> 00:41:58,167
remember large amounts of bits
and it's hopeless okay? We have
hardware acceleration for human

353
00:42:01,708 --> 00:42:07,708
faces and even then we maybe can
get about 16 bits. There may be,
if we're absolutely at the edge

354
00:42:10,125 --> 00:42:17,125
of our capability, able to
differentiate 65,000 people.
It's not that much and computers

355
00:42:17,125 --> 00:42:24,667
want more, so much more, 24 to
128 bits. They want recognition.
Have you ever seen this before?

356
00:42:24,667 --> 00:42:30,000
And they want repetition. Hey,
give me that long ass password.
And the standard stuff doesn't

357
00:42:30,000 --> 00:42:36,000
work. We did not evolve to deal
with hex or base 64 or base 58
or squiggly SSHR. It's just not

358
00:42:38,750 --> 00:42:43,875
how we're built. Now I've looked
at this problem before. And in
some work I call it

359
00:42:43,875 --> 00:42:51,750
cryptoneumonics. I went ahead
and took 512 male names. 1,024
female names. 8,192 last names.

360
00:42:51,750 --> 00:42:57,625
I represented entropy by married
couples. I'm sorry totally
heteronormative but actually

361
00:42:57,625 --> 00:43:03,625
really diverse. Julio and
[indiscernible] and Manuel and
Twila and Bessie. Definite range

362
00:43:07,875 --> 00:43:13,875
of people here. This actually
works as a way to get yourself
to be used to some pattern of

363
00:43:16,042 --> 00:43:22,333
bits. You do have to show it
every single time you interact
with something. You can't just

364
00:43:22,333 --> 00:43:27,333
show the entropy representation
when there's a problem. It's
like you only see someone's face

365
00:43:27,333 --> 00:43:31,875
when there's a problem,
otherwise they're in a mass. It
doesn't work that way. That's

366
00:43:31,875 --> 00:43:37,875
not how the brain works. It
needs spaced repetition to
remember. Now, can we do better?

367
00:43:41,208 --> 00:43:48,042
Humans do have memory capacity.
It's just not for arbitrary
bits. Like Homer's epics are

368
00:43:48,042 --> 00:43:55,292
enormous. There's kilobytes of
entropy in there. The deal is,
is that we remember objects, we

369
00:43:55,292 --> 00:44:01,833
remember stories, we remember
narratives far more than we
remember arbitrary ones and

370
00:44:01,833 --> 00:44:09,625
zeros. So if you can represent
ones and zeros as these sort of
narratives that humans are built

371
00:44:09,625 --> 00:44:16,167
to remember, you actually have
something. Heck maybe you could
have a password and have it

372
00:44:16,167 --> 00:44:22,167
spell check. So what we've been
exploring has using triads of
adjectives, nouns and verbs and

373
00:44:24,250 --> 00:44:31,667
having these be selected to be
maximally distant from each
other and to encode whatever

374
00:44:31,667 --> 00:44:36,625
entropy someone needs to
recognize or repeat in these
stories. Now I haven't been

375
00:44:36,625 --> 00:44:41,875
doing this work alone, I have
been working with my co-worker
Ryan Casaluci over at White Ops.

376
00:44:41,875 --> 00:44:48,292
And, it's his code. It's his
work. He's the one who should be
talking about it so he's going

377
00:44:48,292 --> 00:44:54,292
to come on stage and we're going
to talk about how he did this.
[Applause] >> So Ryan, pick up a

378
00:45:02,250 --> 00:45:08,250
mic. >> Hi guys. How's is going?
>> So, I just have to say I've
known Ryan for many, many years.

379
00:45:11,958 --> 00:45:17,667
He recently started working with
me at White Ops. I've never had
a guest come up in the middle of

380
00:45:17,667 --> 00:45:23,292
my talk and there's no one I
would rather have be here. >>
Thank you. >> So Ryan, tell me

381
00:45:23,292 --> 00:45:29,292
what we're looking at here. >>
Ok. So we have up on the slide a
randomly generated sample. >>

382
00:45:33,167 --> 00:45:38,875
It's like 5e, 4D. It's like a
bunch of bits. >> Right. There's
a couple algorithms that are

383
00:45:38,875 --> 00:45:45,583
combined together to generate
the encoding we have there. As
you can see there's 4 groups of

384
00:45:45,583 --> 00:45:52,750
three words. Each one is a
adjective, noun and verb. >>
This is like macho, acid,

385
00:45:52,750 --> 00:45:59,958
answering. Rustic, cable,
fetching. >> Right. And we have
a known amount of entropy there.

386
00:45:59,958 --> 00:46:05,958
So what we can do, spell check
for passwords, well pass
phrases. So unfortunately we

387
00:46:09,292 --> 00:46:15,875
don't have a live demo to - I
could not get the code to work
fast enough for that. I will fix

388
00:46:15,875 --> 00:46:21,750
that soon. The code will be
released. It is awesome. >> But
we actually do have sort of have

389
00:46:21,750 --> 00:46:28,417
a view of what's going on here.
>> Yes. That is - it can fix far
worse than that. But as you can

390
00:46:28,417 --> 00:46:36,042
see transpositions, deleted
spaces, replaced characters,
added letters, deleted letters,

391
00:46:36,042 --> 00:46:41,167
random garbage symbols, it can
fix all of this. >> And the
words are out of order, even. >>

392
00:46:41,167 --> 00:46:48,625
Yes. It is also order
insensitive because people will
commonly mix up the order of

393
00:46:48,625 --> 00:46:54,333
words when they're trying to
remember something like this and
we can fix it, so we should. >>

394
00:46:54,333 --> 00:46:58,792
Interesting. So you don't have
to remember if the acid is macho
or rustic you just have to know

395
00:46:58,792 --> 00:47:03,083
acid and macho and rustic in
whatever order. >> Exactly. >>
Ok. So let's talk about how you

396
00:47:03,083 --> 00:47:09,333
actually did this. >> Ok. It's
kind of complicated. I have code
implemented in JavaScript and

397
00:47:09,333 --> 00:47:15,708
Python. We will, it's on Rehub,
the post private name, currently
private. That will be changed

398
00:47:15,708 --> 00:47:22,833
soon. So we have two major
components. There's a combinatic
or combinatorial number system

399
00:47:22,833 --> 00:47:28,833
encoder. That is an obscure but
really neat trick where you can
take an arbitrary number and

400
00:47:31,833 --> 00:47:39,417
encode it as a series of
non-repeating symbols. So, as
the example shows if you have

401
00:47:39,417 --> 00:47:47,333
multiple A's, you know, that's
not going to work because you
can't use the same symbol more

402
00:47:47,333 --> 00:47:52,875
than once. >> This is like you
have an encoding of possible
letters from A to Z. You could

403
00:47:52,875 --> 00:47:58,875
have, BADFGC. >> You are picking
N of them where N might be 3 or
4 or 5 depending upon how large

404
00:48:01,958 --> 00:48:07,833
a range of numbers you want to
encode. Ah, and this is fairly
efficient. This is, you can do

405
00:48:07,833 --> 00:48:13,333
this fast. You don't have to
walk through all possible
combinations. You can generate a

406
00:48:13,333 --> 00:48:19,458
specific numbered combination
and that's your encoding. >> And
so you're actually able to take

407
00:48:19,458 --> 00:48:25,333
arbitrary bits of input and map
them to the scheme that says
it's these numbers and because

408
00:48:25,333 --> 00:48:30,000
the numbers are the
combinatorial systems they can
show up in any order. >> They

409
00:48:30,000 --> 00:48:35,708
can show up in any order. Yes.
>> OK. >> For decode we just
have to sort them. >> All right.

410
00:48:35,708 --> 00:48:40,042
So talking about the decode
you're not having it be raw
numbers, you're having it be

411
00:48:40,042 --> 00:48:45,458
words. >> Right. So there's
another step here which is our
word mapper. Our word mapper has

412
00:48:45,458 --> 00:48:51,458
a dictionary file. In the
implementation we were showing
in the last slide we actually

413
00:48:53,667 --> 00:48:58,708
have three dictionaries. One for
nouns, one for adjectives, one
for verbs. And we actually

414
00:48:58,708 --> 00:49:04,583
include three values. One with X
nouns, one with X verbs and one
with X adjectives and interlace

415
00:49:04,583 --> 00:49:10,583
them, but it gets a little
messy. Anyway. So our dictionary
has our words in it and variant

416
00:49:13,833 --> 00:49:19,458
forms of the words because you
know, it makes things easier for
people. So for the verbs for

417
00:49:19,458 --> 00:49:25,458
example, doesn't matter if you
say forbidding or forbidden or
forbade or whatever, they're all

418
00:49:30,917 --> 00:49:36,917
forms of the same verb. We know
that. We canonicallize them and
in coding we just take the

419
00:49:39,458 --> 00:49:45,458
canonical form which in this
case would be forbidding. So. >>
So we're basically taking all of

420
00:49:48,458 --> 00:49:51,708
the common errors of password
input and we're saying those
common errors no longer count.

421
00:49:51,708 --> 00:49:57,708
We're going to correct for them
before we even let them get into
the decoder. >> Exactly. And

422
00:50:03,250 --> 00:50:09,333
I've got some crazy Python code
using something I think called
node box, which is a linguistic

423
00:50:09,333 --> 00:50:15,333
suite that we use to generate
all of the verb forms. And then
we have a recursive algorithm

424
00:50:20,042 --> 00:50:24,708
that goes through and maximizes
the edit distance between words.
If you're not familiar with edit

425
00:50:24,708 --> 00:50:30,708
distance, I don't remember the
specific one I'm using but each
character insertion, deletion,

426
00:50:34,667 --> 00:50:41,375
alteration or transposition of
adjacent characters counts as an
edit. So we want to have at

427
00:50:41,375 --> 00:50:47,375
least two edits between any
words possible so that a single
typo cannot possibly result in a

428
00:50:49,750 --> 00:50:56,208
valid but wrong word. >> Nice.
Basically computational
linguistics as applied to

429
00:50:56,208 --> 00:51:02,208
security. Basically a path out
of using lead speak as a
security technology. There's no

430
00:51:07,458 --> 00:51:13,750
more of this like, I used an at
sign. I'm secure. >> We know
exactly how well that works and

431
00:51:13,750 --> 00:51:19,417
if you don't, go talk to the
core logic guys. They have a
contest that I think might

432
00:51:19,417 --> 00:51:25,417
change your mind. >> Nice. So it
seems prett cool. You think this
is going to let us have

433
00:51:25,417 --> 00:51:32,042
passwords generated server side?
>> That's the idea. We generate,
not necessarily server side but

434
00:51:32,042 --> 00:51:38,042
computer generated pass phrases
that there's a reasonable hope
of people understanding and

435
00:51:40,250 --> 00:51:44,167
remembering. >> Yah. It always
seemed to me like victim
shaming. We make the user

436
00:51:44,167 --> 00:51:48,417
generate the password so we can
blame them when their password
sucks, meanwhile we have no idea

437
00:51:48,417 --> 00:51:52,917
how to build them one. >> Yes. I
remember when a few months ago
when we first started working on

438
00:51:52,917 --> 00:51:59,500
this you know, Dan came up with
some examples and I think there
was, I still remember most of

439
00:51:59,500 --> 00:52:05,583
what we had. We had a flat
monkey staring and we had a
green house jumping. And there

440
00:52:05,583 --> 00:52:09,250
was another couple which I have
forgotten but the point is I
have looked at these maybe twice

441
00:52:09,250 --> 00:52:15,667
ever and I still remember them.
>> So we were talking last night
about what the implications are

442
00:52:15,667 --> 00:52:20,667
for allowing more key
stretching. How do you explain
what key stretching is and why

443
00:52:20,667 --> 00:52:26,708
this makes it a more feasible
thing? >> Oh yes, this is really
cool. So key stretching is the

444
00:52:26,708 --> 00:52:34,500
idea where in addition to
randomness in the pass phrase as
a sorce of difficulty to crack

445
00:52:34,500 --> 00:52:41,625
it, we also just make the
hashing slow as hell. You've
probably all heard of B crypt or

446
00:52:41,625 --> 00:52:47,625
PBKF2 or S crypt. Yes, thank
you. And this is somewhat
limited because if you're

447
00:52:51,792 --> 00:52:58,708
spinning for five seconds and it
takes you three times to get
your password right, you are

448
00:52:58,708 --> 00:53:04,583
going to just throw the computer
through the window. But if we
have spell correct, even if you

449
00:53:04,583 --> 00:53:10,958
make a few small typos it works
the first time. It's fantastic
and people generally aren't

450
00:53:10,958 --> 00:53:17,958
going to mind nearly so much
waiting for their log in to
complete as they are waiting to

451
00:53:17,958 --> 00:53:23,292
see if they typed their password
correctly, and if not having to
re-enter it. I had a high

452
00:53:23,292 --> 00:53:29,208
security thing I built a while
ago. It would spin the CPU for
60 seconds and it was a

453
00:53:29,208 --> 00:53:34,333
threshold scheme so we had like
five of us having to type
passwords and when somebody

454
00:53:34,333 --> 00:53:41,167
mistyped it, it sucked. But if
you knew it was going to be
right one minute wouldn't even

455
00:53:41,167 --> 00:53:47,167
be that bad for disk encryption.
>> So we're basically dealing
with a common failure mode of

456
00:53:50,000 --> 00:53:54,750
what would otherwise be a useful
and effective security
technology. >> Exactly. >> The

457
00:53:54,750 --> 00:53:58,958
more effective a security
technology works the more we can
use it. >> Exactly. >> Cool. All

458
00:53:58,958 --> 00:54:04,958
right Ryan. Thank you very much.
I really appreciate you building
this out. >> Thank you. >>

459
00:54:13,208 --> 00:54:19,208
[indiscernible] >> Do we have a
drink? Someone bring a drink.
All right. >> I will be back, I

460
00:54:22,667 --> 00:54:28,667
have somewhere to go. >> So,
there's a major use case to be
considered with a lot of this

461
00:54:31,750 --> 00:54:37,750
stuff. Speaking of work from a
previous talk, a few years ago I
did something called FIDELIOUS,

462
00:54:37,750 --> 00:54:44,542
and FIDELIOUS is basically a
trick that allows you to use a
pasts phrase, any string of

463
00:54:44,542 --> 00:54:51,792
characters and use that to seed
any a-symmetric system. So you
can have a pass phrase for an

464
00:54:51,792 --> 00:54:58,750
SSH key, SSL certificate.
Basically what I did was say a
pass phrase will seed a pseudo

465
00:54:58,750 --> 00:55:04,958
random number generator and a
random stream of bits is the
input to all key generators. So

466
00:55:04,958 --> 00:55:09,000
you hook the two together, you
get what's called a password
authenticated key exchange

467
00:55:09,000 --> 00:55:15,000
scheme. It always works. This
was relatively obscure two years
ago. This is becoming straight

468
00:55:18,958 --> 00:55:24,292
up main stream now. There's a
scheme called brain wallet that
allows you to have a word or

469
00:55:24,292 --> 00:55:29,500
phrase going to a bit coin
address. There's a scheme called
mini lock that has a word or

470
00:55:29,500 --> 00:55:36,208
phrase going to you know, the
rough equivalent of a PGP key.
Not actually PGP, but still.

471
00:55:36,208 --> 00:55:44,042
These systems are incredibly
vulnerable to having a low
amount of true entropy. Because

472
00:55:44,042 --> 00:55:50,042
by definition you're publishing
your public key. It's almost
like it's called a public key.

473
00:55:53,792 --> 00:55:59,000
So this has been a straight up
expensive problem in brain
wallet. Tens of thousands of

474
00:55:59,000 --> 00:56:06,625
dollars worth of bit coin have
been stolen. What we need is a
way for people to remember more

475
00:56:06,625 --> 00:56:13,083
entropy. The idea is, is that
storing all of these bits on a
hard drive ends up being a screw

476
00:56:13,083 --> 00:56:17,708
up. People want something they
can hold in their head. If we
have these sorts of

477
00:56:17,708 --> 00:56:24,375
representation schemes that are
self-correcting, people can
remember more. Stuff will work

478
00:56:24,375 --> 00:56:32,042
better. So, the general idea,
brain wallet and mini lock need
human memorable entropy. Actual

479
00:56:32,042 --> 00:56:38,875
security needs more entropy.
This story bit system increases
memorable entropy. Now there is

480
00:56:38,875 --> 00:56:44,250
some interesting variations on
the scheme. You can go ahead and
have what we call split mode

481
00:56:44,250 --> 00:56:52,125
where you have a normal password
you use, it allows things to
work but it takes like two hours

482
00:56:52,125 --> 00:56:58,542
to crack a key. And then you
have a secondary password that's
really there to allow for key

483
00:56:58,542 --> 00:57:05,458
exchange. So moving a key from
one location to another. So that
can be set to take a few seconds

484
00:57:05,458 --> 00:57:10,583
while the slow mode, the one
that's really in your head, that
one might take hours and hours.

485
00:57:10,583 --> 00:57:16,792
The general idea is that yeah,
it might take you hours and
hours but the relative slow down

486
00:57:16,792 --> 00:57:22,250
to the attacker that's trying to
brute force your keys from the
public key, that guy is screwed.

487
00:57:22,250 --> 00:57:27,250
Because he has to run an attempt
only one every few hours, a
couple of attempts a day. He can

488
00:57:27,250 --> 00:57:33,292
wait until the end of time, he's
not going to get your money. Two
more tricks that we can do.

489
00:57:33,292 --> 00:57:40,625
These aren't necessarily good
ideas but we're hackers. Good
ideas are ahh, not exactly

490
00:57:40,625 --> 00:57:46,625
required here. It is an argument
that no matter how you slice it,
at minimum it's easier to

491
00:57:51,125 --> 00:57:57,125
remember 24 bits than to
remember 80 to 128 bits. So
there has long been a desire on

492
00:58:00,458 --> 00:58:06,417
the part of software developers
who are presenting a key for
memory to have, here's the full

493
00:58:06,417 --> 00:58:11,625
fingerprint which we understand
you can't remember, and here is
a shrunk down version of it.

494
00:58:11,625 --> 00:58:19,583
Here's the PGP key ID. Here's
the RSA ID. Here's some smaller
amount of bits. And the problem

495
00:58:19,583 --> 00:58:25,625
is from the attacker's
standpoint they're like great, I
don't need to collide with the

496
00:58:25,625 --> 00:58:32,125
big thing, I just need to match
this 24 bits. It will take me a
little bit of math but it won't

497
00:58:32,125 --> 00:58:38,125
be that bad. So here's the
scheme that you can do. If the
user can remember even a small

498
00:58:40,625 --> 00:58:46,875
pass phrase that is never
submitted to the server, that
pass phrase can be a sort of

499
00:58:46,875 --> 00:58:53,042
shrinker or a bit limiter. So
you take the full hash, you hash
it with the pass phase, you

500
00:58:53,042 --> 00:58:59,042
truncate the results. So the
attacker still has to match all
128 bits. Doesn't know the pass

501
00:59:02,750 --> 00:59:09,542
phrase. Doesn't know what the 24
bits are that he actually does
need to collide with. So this is

502
00:59:09,542 --> 00:59:16,667
going ahead and creating a
differential between the work
effort of the bad guy and the

503
00:59:16,667 --> 00:59:23,500
work effort of the good guy. You
want things to be easier for the
good guy. He has a cost. Your

504
00:59:23,500 --> 00:59:29,250
legitimate user has to remember
something. But the idea is 10
people who are trying to

505
00:59:29,250 --> 00:59:35,250
remember the same key, each have
their own personal recognition
appearance, like they see the

506
00:59:37,375 --> 00:59:42,792
same face but for themselves
every time they see someone's
face it's the same face. But 10

507
00:59:42,792 --> 00:59:47,417
people are seeing 10 different
faces. Doesn't matter. They need
to see the same face for

508
00:59:47,417 --> 00:59:53,667
themselves. That makes sense.
There's a way of doing this in
the opposite direction called

509
00:59:53,667 --> 01:00:01,000
local stretching. There is a
problem where you have some web
server - you have some password

510
01:00:01,000 --> 01:00:08,958
server. It's not particularly
doing any work to make it so
when somebody compromises the

511
01:00:08,958 --> 01:00:15,292
password store, because you know
it happens a lot, that the
attacker can't go ahead and

512
01:00:15,292 --> 01:00:20,750
figure out, ah-ha I got the
password store, now I've got the
plain text password. What you

513
01:00:20,750 --> 01:00:28,625
could do is have the stretching,
the complexifier of the
password, acutally happen in the

514
01:00:28,625 --> 01:00:34,625
client. It's like, yah the
user's remembering ABC123 but
it's being expanded out a

515
01:00:36,667 --> 01:00:42,667
billion times before it's ever
sent to the server. Where things
get messy in having basically

516
01:00:46,417 --> 01:00:53,583
software generate the pass
phrase, the one that is the
actual password for a server, is

517
01:00:53,583 --> 01:01:00,792
every freaking website has its
own rules for what password has
to look like. Oh, it has to have

518
01:01:00,792 --> 01:01:07,125
symbols. It must not have
symbols. It has to have 3
numbers, 2 numbers, 8 numbers.

519
01:01:07,125 --> 01:01:10,792
By the way, going from a scheme
that has to have a letter to a
scheme that has to have a

520
01:01:10,792 --> 01:01:14,333
number, you know there are more
letters than numbers. Uou kinda
just made things worse. What you

521
01:01:14,333 --> 01:01:19,333
can do is kind of a cute trick
and that is you can examine the
pattern of the pass phrase that

522
01:01:19,333 --> 01:01:25,333
was provided by the user. So the
user says, ABC123 with a symbol
and that could be interpreted

523
01:01:25,333 --> 01:01:31,333
as, requires 3 numbers and a
symbol, and that is actually
what is stretched or expanded

524
01:01:39,958 --> 01:01:45,958
out. So it's inferred discovery
of password policies. Kind of a
neat trick. So, now we've gone

525
01:01:49,875 --> 01:01:56,333
ahead and we've gone into a
pretty amount of detail on how
we generate random numbers and

526
01:01:56,333 --> 01:02:00,542
we've also talked about how we
represent arbitrary data. Now
let's talk about some

527
01:02:00,542 --> 01:02:06,542
[inaudible] okay? The other shoe
was kind of dropped. IE had more
attacks in 2013 than Java, and

528
01:02:08,917 --> 01:02:15,625
you know how much we love making
fun of Java. How is this
possible? IE, Microsoft has been

529
01:02:15,625 --> 01:02:21,625
working to secure IE for a
decade. How is it that things
have fallen so far? So, excuse

530
01:02:27,500 --> 01:02:33,500
me for one second. I have to get
some water in me. Here's the
deal, guys. Anyone remember way

531
01:02:40,625 --> 01:02:45,792
way back in the day when
Microsoft was just like, you
know Internet Explorer is just

532
01:02:45,792 --> 01:02:51,292
Windows, like they can't be
separated. Are you crazy?
Everyone thought that they were

533
01:02:51,292 --> 01:02:57,333
lying. They were full of it.
When you actually look at
Internet Explorer that damn

534
01:02:57,333 --> 01:03:03,958
thing is Windows the remix
featuring the internet, ok. It
really is Windows. You have this

535
01:03:03,958 --> 01:03:08,917
object model that was built back
in the 90s called com and
they're like hell, let's go put

536
01:03:08,917 --> 01:03:14,042
that on the internet. It's like
if you put mem copy on the
internet. Like hey, we've got

537
01:03:14,042 --> 01:03:21,250
this API here and it takes bytes
from somewhere and puts it
somewhere else. What? You want

538
01:03:21,250 --> 01:03:27,250
it secure now? We barely have
this working. And don't worry,
because of the nature of

539
01:03:29,375 --> 01:03:34,583
browsers, because they're all
implementing the same standards,
everybody ended up with

540
01:03:34,583 --> 01:03:42,500
something that looked pretty
much exactly like com. Like for
example, XPcom from Firefox.

541
01:03:42,500 --> 01:03:47,708
It's not exactly subtle. I mean
it is literally was is called an
interface description language

542
01:03:47,708 --> 01:03:55,292
literally built into the very
standards of the web. This is
how it would have to work. Yes

543
01:03:55,292 --> 01:04:01,292
attackers loved attacking plug
ins, because it didn't matter if
you were attacking an IE or

544
01:04:03,625 --> 01:04:07,208
Firefox or Chrome it was still
Java, write once, own
everywhere. You didn't have to

545
01:04:07,208 --> 01:04:12,000
customize it at all. You even
got to escape all these weird
little sandboxes that weren't

546
01:04:12,000 --> 01:04:18,000
worth messing around with. And
so, you know, as a, as has
finally come out. My TOR

547
01:04:22,583 --> 01:04:28,583
deanonymization has a first
name. It's Firefox-o-day, as the
gruck might sing.

548
01:04:31,958 --> 01:04:37,958
Vulnerabilities in the browsers
have taken over vulnerabilities
in their plugins. And that's

549
01:04:40,458 --> 01:04:44,125
because we've been exposing the
underlying object model to
something that it was never

550
01:04:44,125 --> 01:04:50,125
really designed to be exposed
to. The bad guys. Browsers in
their normal operation are

551
01:04:53,042 --> 01:05:00,750
constantly allocating memory and
associating a type with it. This
pointer is to a table. This

552
01:05:00,750 --> 01:05:06,833
pointer is to an image. Now, if
you're going to be constantly
allocating memory, you've got to

553
01:05:06,833 --> 01:05:12,500
free it at some point, right?
You've got to reuse that memory.
So what happens is a pointer

554
01:05:12,500 --> 01:05:19,042
starts out, and it's pointing to
a table. And eventually the
system says user's moved on to a

555
01:05:19,042 --> 01:05:26,500
new web page, I don't need that
table anymore. So that pointer
is freed. And then later it

556
01:05:26,500 --> 01:05:33,250
says, ahh I've got space, let's
go make an image. Go put an
image there. Problem is you've

557
01:05:33,250 --> 01:05:39,083
looked at JavaScript, there's a
million ways to have a pointer
to a pointer to a pointer. This

558
01:05:39,083 --> 01:05:43,417
table has an image inside of it.
This image has a CSS thing
inside of it which has a link

559
01:05:43,417 --> 01:05:49,417
back to another image. There's a
billion ways for objects in HTML
and JavaScript to point to

560
01:05:49,417 --> 01:05:56,750
another. And if you ever get the
system screwing up, getting it
to free memory and still has

561
01:05:56,750 --> 01:06:02,750
some pointer still pointing to
it, you now have two object
contexts, one pointer. And that

562
01:06:05,417 --> 01:06:10,750
also works about as well as
you'd hope. So use that for
free. That's when you have two

563
01:06:10,750 --> 01:06:16,875
different contexts in one. Use
that for free it's something
like 90 to 98% of the

564
01:06:16,875 --> 01:06:22,875
undiscovered vulnerabilites in
browsers today. And it's a real
problem and it's not going away.

565
01:06:25,500 --> 01:06:29,583
Except that it kind of is.
Google and Microsoft are
actually doing some pretty

566
01:06:29,583 --> 01:06:36,875
serious things to deal with use
after free. The Google solution
is a typed keep. So what they're

567
01:06:36,875 --> 01:06:42,750
saying is, we're going to keep
all the tables together. We're
going to keep all the images

568
01:06:42,750 --> 01:06:49,000
together so when you go back and
make a second allocation,
everything is with its peers.

569
01:06:49,000 --> 01:06:54,458
You don't get some situation
where you use a method of an
image on a table. You use a

570
01:06:54,458 --> 01:07:00,417
method of a table on an image
because everything is sticking
together. And this actually

571
01:07:00,417 --> 01:07:07,542
makes it incredibly harder to go
ahead and exploit
vulnerabilities. Microsoft as

572
01:07:07,542 --> 01:07:13,083
well is doing stuff. They're
doing a lot of things. But the
fundamental advantage of their

573
01:07:13,083 --> 01:07:19,250
approach is what's called
non-deterministic fuzzing,
freeing. They're making it so

574
01:07:19,250 --> 01:07:25,708
the attacker never quite knows
if they go ahead and pull their
stunt it's going to work. It

575
01:07:25,708 --> 01:07:33,375
might work. It could work, but
they don't know it will. This is
great. This is attacking the

576
01:07:33,375 --> 01:07:40,667
unique needs of an exploit. This
is counter exploitation. Sure
you have probablistic likelihood

577
01:07:40,667 --> 01:07:46,667
but your requirement, your deed
is guaranteed reliability. So
Microsoft is playing that game.

578
01:07:49,708 --> 01:07:55,708
I've got a trick. Trick's called
Iron Heap, named by Rob Graham
and the idea is really simple.

579
01:07:58,250 --> 01:08:04,250
You can't use after free if you
just don't free memory. Nope,
just not going to do it. There's

580
01:08:09,542 --> 01:08:15,208
a little bit of a problem with
this, you might know. We don't
actually have an infinite amount

581
01:08:15,208 --> 01:08:21,833
of physical memory, but you know
on 64 bit machines we have an
awfully large amount of virtual

582
01:08:21,833 --> 01:08:27,833
memory. Ahhh. So the basic idea
is we never reuse an allocation.
Your virtual memory space is 64

583
01:08:30,667 --> 01:08:36,583
bits long, and it is basically
mapped. Say this chunk of the
address space points to this

584
01:08:36,583 --> 01:08:42,417
page and this chunk points to
that page. You keep reusing
physical memory but the

585
01:08:42,417 --> 01:08:48,667
pointers, the stuff that's
actually exposed to user space,
the addresses that are actually

586
01:08:48,667 --> 01:08:55,208
exploitable by the various use
after free techniques, they're
never reused because you just

587
01:08:55,208 --> 01:09:01,167
have so much room. Look we've
only had 64 bit browsers really
for a short amount of time. This

588
01:09:01,167 --> 01:09:07,458
is the best possible use of 64
bit space. So the idea is that
OX1234123412341234, once it's

589
01:09:07,458 --> 01:09:13,458
freed, that's it. It never
points again to an image or a
CSS script or a JavaScript. That

590
01:09:18,708 --> 01:09:24,708
page stays unmapped forever.
Exploit that. So, we've got to
do some stuff to make this

591
01:09:29,292 --> 01:09:35,417
efficient. You can only have a
finite number of active
allocations. The reason this can

592
01:09:35,417 --> 01:09:40,833
work at all is because there's
actually hardware acceleration.
It's what's called a memory

593
01:09:40,833 --> 01:09:48,542
management unit that very
quickly allows a process to say
hey, I'm accessing this virtual

594
01:09:48,542 --> 01:09:54,167
fake address. Make it really
quick for me to go ahead and
figure out what page of memory

595
01:09:54,167 --> 01:10:00,875
has the real content. Make it
really quick for me to find out
there is no page. You can't have

596
01:10:00,875 --> 01:10:06,208
an infinite amount on these
mappings but you don't need an
infinite amount of these

597
01:10:06,208 --> 01:10:12,208
mappings. You need to have like
the top 10,000 or the top
15,000. Anything else can swap.

598
01:10:16,208 --> 01:10:22,208
Guess what? Machines swap. Maybe
to disk, maybe to more RAM but
the idea is you handle the case

599
01:10:24,875 --> 01:10:31,792
where the 0.01% of the time. The
other trick you can of course do
is what is called having guard

600
01:10:31,792 --> 01:10:38,042
pages. So that means you have
unallocated space between
allocations. This gets a little

601
01:10:38,042 --> 01:10:43,000
fat because now you have to have
8 kilobytes used every time even
if you have an 8 byte

602
01:10:43,000 --> 01:10:48,958
allocation, and that sort of
sucks. But again, you can do
this probablistically. You don't

603
01:10:48,958 --> 01:10:53,583
always have to go ahead and make
an exploit work you just have to
make it a nightmare enough so

604
01:10:53,583 --> 01:10:59,000
that the attacker never really
knows if their stuff's going to
work or not. That is cheating.

605
01:10:59,000 --> 01:11:05,917
Good. We get to cheat. We're
defenders. Implementation wise.
This can be done entirely in

606
01:11:05,917 --> 01:11:12,500
user space. So, you manage
memory in user space, you handle
the exception when it's

607
01:11:12,500 --> 01:11:17,833
unmapped. You populate it in the
exception. It can be run into
kernel because kernels are

608
01:11:17,833 --> 01:11:22,083
already managing page tables. I
don't object to doing this in
the kernel. I don't object to

609
01:11:22,083 --> 01:11:27,375
kernel modules. I'm willing to
say the operating system needs
to adapt to the new needs of

610
01:11:27,375 --> 01:11:33,250
software. If I don't -- right
now to figure out what
permissions are on a page in

611
01:11:33,250 --> 01:11:38,958
Linux, you can process a frickin
proc file out of the text file
system. We can be more efficient

612
01:11:38,958 --> 01:11:45,542
than that. Down sides of iron
heap. For one, there's no code
yet, just some proof of

613
01:11:45,542 --> 01:11:53,250
concepts. And two, it really
does lean on 64 bit and
browsers, particularly Flash,

614
01:11:53,250 --> 01:11:59,375
aren't entirely fantastic at 64
bit yet. This is true and it
matters. People like their

615
01:11:59,375 --> 01:12:06,458
freaking Flash. So what may work
today is a piece of software
that got really popular, I don't

616
01:12:06,458 --> 01:12:12,750
want to say popular, but really
was being developed around 2007,
2008. Piece of code called Die

617
01:12:12,750 --> 01:12:18,833
Hard. It's an interesting secure
allocator from Emory Berger of U
Mass. It was an advanced ASLR

618
01:12:18,833 --> 01:12:24,917
implementation with out of band
heat metadata. It's a long way
of saying when you allocate

619
01:12:24,917 --> 01:12:28,167
memory it goes to hard to
predict pointers, you don't
really know where it's going to

620
01:12:28,167 --> 01:12:34,875
be and you don't have obvious
things for you to corrupt.
Expresses free, very similar to

621
01:12:34,875 --> 01:12:41,208
the Microsoft allocators. So you
don't know when the memory is
actually freed. It is

622
01:12:41,208 --> 01:12:45,958
eventually, but you know
Internet Explorer actually has a
command that says run the

623
01:12:45,958 --> 01:12:51,958
garbage collector now. Like,
that's not so good. The big
thing about Die Hard is that

624
01:12:56,417 --> 01:13:02,917
they're available today. There's
code for Windows. There's code
for Mac. There's code for Linux.

625
01:13:02,917 --> 01:13:09,375
Probably worth exploring for
tails. There's something
different about this stuff. So

626
01:13:09,375 --> 01:13:15,750
when we have normal ASLR for
like loading libraries, when you
have what's called NX which

627
01:13:15,750 --> 01:13:19,083
means you can't execute code
that you've thrown on to the
stack somewhere or heap

628
01:13:19,083 --> 01:13:25,083
somewhere, a lot of other
defenses assume the corruption
has occurred and say, now that

629
01:13:27,292 --> 01:13:34,167
it's occurred let's make it
really tough to figure out what
to do. What the end game is that

630
01:13:34,167 --> 01:13:39,917
leads to arbitrary code
execution. Yes you've corrupted
but you don't have a path. And

631
01:13:39,917 --> 01:13:45,458
this class of defense is
different because you're
actually preventing the initial

632
01:13:45,458 --> 01:13:51,458
corrupting moment. If you don't
have the free complete, the use
after free can never start.

633
01:13:54,583 --> 01:14:00,625
There is nothing going on in
info sect that is killing more
oday than use after free

634
01:14:00,625 --> 01:14:06,083
killers. You cannot imagine how
many undiscovered vones are
under this space. I still

635
01:14:06,083 --> 01:14:11,958
remember the first time I wrote
a fuzzer. They found this stuff.
Pow. Come to work every morning

636
01:14:11,958 --> 01:14:16,875
it's like oh look at all these,
like dozens. Can I just say, by
the way, Whenever people who

637
01:14:16,875 --> 01:14:24,750
like actually write fuzzers hear
things like, and they used four
odays. It's like dude I wrote 4

638
01:14:24,750 --> 01:14:30,750
odays at lunch! Really like you
get the pattern down, and
quantity. So here's the plan

639
01:14:33,083 --> 01:14:39,083
okay? IE's got a story around
use after free. Chrome's got a
story around use after free.

640
01:14:42,667 --> 01:14:49,708
Firefox has got some ODAY.
Firefox needs a story around
memory hardening. So it's gonna

641
01:14:49,708 --> 01:14:53,750
take some time and it's going to
be hard to convince them to give
up their beautiful memory

642
01:14:53,750 --> 01:14:59,750
allocator genalic but we're
going to put together an actual
strong secure allocator for

643
01:15:03,542 --> 01:15:07,958
production Firefox in the field
today. We're going to start by
building this for the tour

644
01:15:07,958 --> 01:15:12,750
browser combinations for the
tails environment. We're going
to get into these

645
01:15:12,750 --> 01:15:18,042
indistinguishable
performance-wise from real
native Firefox. It's not going

646
01:15:18,042 --> 01:15:23,583
to be me alone. I'm doing this
as a White Ops project and I've
actually managed to recruit Dr

647
01:15:23,583 --> 01:15:28,750
Emory Berger, the creator of Die
Hard. We're going to go ahead
and we're going to get Firefox a

648
01:15:28,750 --> 01:15:34,750
heck of a lot safer, but that's
what we're up to. [Applause] Dr.
Berger actually came on board

649
01:15:41,333 --> 01:15:48,750
about 80 minutes ago so I'm
really excited to be announcing
this. I'm like dude you want to

650
01:15:48,750 --> 01:15:56,625
join in on this? He's like hell
yeah! So that's what we're going
to do about browsers. Now I'm

651
01:15:56,625 --> 01:16:02,625
going to talk about DDOS. We're
almost there. A little bit left.
Everyone having fun here? I know

652
01:16:05,667 --> 01:16:11,667
I'm nerding out like crazy, but.
[Applause] >> All right. So,
we're going to talk about DDOS

653
01:16:15,250 --> 01:16:21,250
here because the bad guys are
filling up our pipes. Series of
tubes getting clogged here. We

654
01:16:24,125 --> 01:16:30,125
had all of 100 gigabit flood in
2013. We've had like 114 in 2014
okay? Like the bad guys are

655
01:16:35,250 --> 01:16:41,250
making a mess of things. I had
assumed that DDOS had just
turned into botnets. You know

656
01:16:43,875 --> 01:16:48,750
you've got millions of desk
tops, you fire them all from web
site, they all have full stacks,

657
01:16:48,750 --> 01:16:56,167
there's millions of machines,
like life sucks. It turns out
the biggest and ugliest of the

658
01:16:56,167 --> 01:17:02,167
DDOSs are actually something
else. They're not using desktop
machines. They're using DNS

659
01:17:05,000 --> 01:17:12,917
servers. That's my protocols,
damn it. Using NTP servers.
They're lying about their source

660
01:17:12,917 --> 01:17:18,000
address. They're pinging some
machine on the internet. They're
causing those machines to reply

661
01:17:18,000 --> 01:17:25,708
to some poor target and it is
filling everything up. And I
want to take a minute to explain

662
01:17:25,708 --> 01:17:31,708
why this variation is quite so
damaging. See here's the deal. I
am a terrible artist. But I've

663
01:17:37,250 --> 01:17:45,250
tried to draw the internet. So
what we've got here is we've got
some source and then you know,

664
01:17:45,250 --> 01:17:49,125
if you're going to go down one
network path you'll take the
left fork and the other one

665
01:17:49,125 --> 01:17:55,917
you'll take the right fork. It
spreads out and eventually as
you get closer and closer to the

666
01:17:55,917 --> 01:18:00,750
destination there are fewer and
fewer paths and finally you're
at your destination. Does that

667
01:18:00,750 --> 01:18:08,000
make sense? Depending on where
you go you have a fan out and
then a fan in. Now if you are

668
01:18:08,000 --> 01:18:15,875
flooding a single destination
all your traffic takes pretty
much one route and goes down

669
01:18:15,875 --> 01:18:21,875
down, up up, up down and that's
the one route 99.9% of your
traffic is going to take. So the

670
01:18:24,375 --> 01:18:30,375
most bandwidth you can consume
is the least bandwidth of any of
these hops. But now let's say

671
01:18:33,625 --> 01:18:39,583
we're going to reflect off of
machines all around the
internet. What happens is, is

672
01:18:39,583 --> 01:18:46,625
that your traffic fans out in
all possible directions, hits
all of these various name

673
01:18:46,625 --> 01:18:54,375
servers, each of which has their
own fastest route back to some
poor network. And I don't know

674
01:18:54,375 --> 01:19:01,875
if you can see it but the entire
damn network is red. Boom. And
this is what's going on. And

675
01:19:01,875 --> 01:19:07,333
it's ugly and it's not going
away. So what are we going to
do? Going to lose our toy? I

676
01:19:07,333 --> 01:19:14,667
don't want to lose my toy. I
like my toy. I like my kitties
on Roombas damn it. So what are

677
01:19:14,667 --> 01:19:22,625
we going to do? Ideally there's
this thing called PCP38. Ideally
there's a technology called

678
01:19:22,625 --> 01:19:30,292
PRPF. Ideally networks couldn't
lie. So you can't be in the
middle of San Francisco and be

679
01:19:30,292 --> 01:19:36,292
like, hey, I'm Porsche Lub in
London and I want this DNS
reply. Tee-hee-hee. Yeah. I'm

680
01:19:40,375 --> 01:19:47,250
not saying that this is a bad
idea. I'm just saying there's a
heck of a lot of networks out

681
01:19:47,250 --> 01:19:54,917
there that don't give a crap
about filtering routes. The
technology, I'm not saying it

682
01:19:54,917 --> 01:20:01,042
doesn't scale but it totally
doesn't scale. Effectively the
technology works by dropping

683
01:20:01,042 --> 01:20:06,875
traffic. You know what ISPs
don't like doing? Dropping
traffic. It fails once and

684
01:20:06,875 --> 01:20:12,750
they're like I am never turning
this back on again. I'm not
saying we shouldn't strive to be

685
01:20:12,750 --> 01:20:18,000
PCP38 compliant. Some crazy
paper came out a while ago. They
found at least 2300 networks

686
01:20:18,000 --> 01:20:25,750
that don't have it. You only get
the real advantage of PCP38 when
it's almost entirely universal.

687
01:20:25,750 --> 01:20:33,292
Now, it's been a tremendous
success for cable modems, for
DSL lines, even for a bunch of

688
01:20:33,292 --> 01:20:40,208
corporate environments. But the
really big pipes that are really
able to do huge reflection

689
01:20:40,208 --> 01:20:46,500
attacks, they're not getting
secured any time soon. At least
not if we can't bust them a hell

690
01:20:46,500 --> 01:20:52,000
of a lot quicker. So I want to
bust them. Here's what we're
going to do. We're going to

691
01:20:52,000 --> 01:20:58,333
bring back an old idea called
stochastic tracing. I did not
come up with this idea, maybe

692
01:20:58,333 --> 01:21:06,083
I've refined it a bit. First
heard this idea about 12 or 13
years ago. And the idea is

693
01:21:06,083 --> 01:21:13,750
you've got a router and one out
of maybe a million packets it
says, hi, I'm this router and I

694
01:21:13,750 --> 01:21:19,833
routed some traffic to you. It
doesn't do anything for your
standard normal flows but if

695
01:21:19,833 --> 01:21:24,375
you've a router being made to
move billions and billions of
packets you are going to end up

696
01:21:24,375 --> 01:21:30,500
with a nice stream of hundreds
and hundreds of tracers and
these things actually

697
01:21:30,500 --> 01:21:36,250
incrementally improve the
internet over time because
there's more and more traces and

698
01:21:36,250 --> 01:21:41,417
it's harder for an attacker to
know whether or not their spoof
traffic it going to be quickly

699
01:21:41,417 --> 01:21:49,042
detected back to them. As it
happens, routers have most of
the technology necessary to

700
01:21:49,042 --> 01:21:53,000
already do this. It's very
simple to configure a router.
What you do is what is called a

701
01:21:53,000 --> 01:21:59,917
GRE stream to say please send me
one out of every million
packets. That can go to an

702
01:21:59,917 --> 01:22:04,625
individual damen. We don't need
to patch the router, for gods
sake. Then go to a damen. The

703
01:22:04,625 --> 01:22:09,375
damen can then go ahead and send
this trace packet. And what does
it actually mean to send a

704
01:22:09,375 --> 01:22:15,917
trace? Because by the way, I
don't want random people on the
internet knowing all the traffic

705
01:22:15,917 --> 01:22:21,667
I'm receiving. I don't even want
them knowing my DDOSs. So the
idea is the traces go to the

706
01:22:21,667 --> 01:22:27,667
destination of the flows and
maybe the source. There are only
two IPs that are really supposed

707
01:22:30,250 --> 01:22:35,792
to be seeing traffic and it's
the source and destination IP.
So if you're spoofing traffic I

708
01:22:35,792 --> 01:22:40,417
don't think you have an
expectation of privacy for the
network to hide that you were

709
01:22:40,417 --> 01:22:46,375
lying about being the guy in
London. What does the payload
actually look like? That's a

710
01:22:46,375 --> 01:22:52,125
good question. Do we encapsulate
in this in ICMP? Do we make and
HTTP post? I don't know. All I

711
01:22:52,125 --> 01:22:56,500
know is if you're on the
internet you're already
receiving crap. I know this

712
01:22:56,500 --> 01:23:02,500
because I'm sending you crap.
And you haven't crashed yet, I
think. There's an alternate

713
01:23:06,292 --> 01:23:13,417
option. And this of course comes
back to my own history in DNS.
Sometimes it's a pain in the

714
01:23:13,417 --> 01:23:19,958
butt to hijack say, all the
trace traffic that's coming out
of ICNP to IP, or HTTP to an IP.

715
01:23:19,958 --> 01:23:25,958
That might actually be hard.
There's a space called reverse
DNS. 4.3.2.1.inadder.

716
01:23:30,292 --> 01:23:37,167
[indiscernible] can say my DNS
name is blah blah.foo.com. with
what's called a PTR record. You

717
01:23:37,167 --> 01:23:44,667
can actually host more than just
PTR records inside of reverse
DNS. So you can host something

718
01:23:44,667 --> 01:23:50,667
that actually says, yeah I know
you're trying to do tracing for
1.2.3.4, here's the server that

719
01:23:56,958 --> 01:23:59,375
accepts those trace packets and
it's still trust associated with
the IP. It's very nice.

720
01:23:59,375 --> 01:24:03,583
Obviously we want to assign
trace payloads otherwise you can
spoof a whole bunch of things

721
01:24:03,583 --> 01:24:10,167
and be like, yeah I'm totally
Verizon moving all this traffic
over Verizon. So we've got to

722
01:24:10,167 --> 01:24:16,167
prevent that, and we can do that
with EGT5519 keys. So that can
work. The long-term vision is to

723
01:24:18,167 --> 01:24:25,208
reduce the time between a DDOS
and tracing the involved
networks. We've got to make this

724
01:24:25,208 --> 01:24:30,708
stuff happen faster. Ultimately
what we need to do is we need to
get to the point where DDOS

725
01:24:30,708 --> 01:24:36,500
isn't automatically suppressed.
Where there can be firewall
rules that are automatically

726
01:24:36,500 --> 01:24:41,958
applied. Now, this is rough
because there's a lot of hops
that are going to see enough to

727
01:24:41,958 --> 01:24:48,458
be able to request firewalling.
So I don't know exactly how this
works. But what I do know is

728
01:24:48,458 --> 01:24:54,292
that these floods are growing
fast enough and nasty enough
that we may actually get the

729
01:24:54,292 --> 01:25:00,958
greatly feared congestion
collapse. There may actually be
entire countries, entire regions

730
01:25:00,958 --> 01:25:06,875
of the globe that just have too
much traffic for anything to
work. And I think Paul basically

731
01:25:06,875 --> 01:25:11,375
would kill me if I didn't say,
by the way you know we can like
patch name servers that don't

732
01:25:11,375 --> 01:25:18,167
participate in this anymore
called LRD. But unfortunately it
requires so many hosts to

733
01:25:18,167 --> 01:25:25,542
upgrade versus this kind of
stuff which is just
incrementally improving. So

734
01:25:25,542 --> 01:25:32,208
let's talk about practically the
last thing I wanted to discuss
in this epcically long talk

735
01:25:32,208 --> 01:25:36,833
today. I don't know why I said I
wanted to do a two hour talk. Am
I trying to kill myself here?

736
01:25:36,833 --> 01:25:42,833
All right. I can't just not talk
about the whole NSA thing. Can't
just leave it to Bruce Snyder. I

737
01:25:46,667 --> 01:25:52,667
love Bruce. I'm worried. I'm
worried about the long-term
reaction to the NSA revelations.

738
01:25:57,958 --> 01:26:05,750
See, there are two ways that you
can win in technology. You can
have the better technology or

739
01:26:05,750 --> 01:26:12,208
you can have fud. Oh sure you
could go with that competitor.
They're cheaper, faster, nicer,

740
01:26:12,208 --> 01:26:18,250
more powerful but
oogabooganationstate. This
sounds ridiculous and do you

741
01:26:18,250 --> 01:26:23,875
realize there really are
proposals to go ahead and keep
all traffic within a country

742
01:26:23,875 --> 01:26:30,167
within a country. This really
sure BGP says this route is
faster, better, easier but the

743
01:26:30,167 --> 01:26:36,167
law says you have to keep within
our borders where we can monitor
it all. Thank you very much. The

744
01:26:38,500 --> 01:26:43,417
internet again was not the first
time we tried to make the
internet. It was the first one

745
01:26:43,417 --> 01:26:50,000
that worked at large scale
because you didn't have this
sort of political interference.

746
01:26:50,000 --> 01:26:55,917
This was a network made by nerds
who had one thing they wanted
which was make this work. Make

747
01:26:55,917 --> 01:27:01,583
this work as fast as possible.
And a lot of these political
actors have a different goal in

748
01:27:01,583 --> 01:27:09,125
mind. You know we didn't want
the Chinese internet or the
Iranian internet before Snowden

749
01:27:09,125 --> 01:27:15,625
and I hope we don't want that
now. But I look out there and I
look at the reactions to the

750
01:27:15,625 --> 01:27:21,625
NSA, and especially their
manipulation of crypto standards
and there really is only one

751
01:27:25,333 --> 01:27:31,333
thing I can think. You maniacs,
you finally did it! You blew it
all up! Damn you to hell!

752
01:27:46,042 --> 01:27:52,167
[Applause] Let me tell you the
honest truth about cryptography.
And if you don't know, the NSA

753
01:27:52,167 --> 01:27:58,708
pushed and got a broken crypto
standard into - well, they
wanted to have everyone use it

754
01:27:58,708 --> 01:28:04,708
but really the only screwed are
the Feds. Um, oops! There's a
reason we were asking the NSA's

755
01:28:08,417 --> 01:28:15,125
advice for cryptographic
vulnerabilities. Most crypto
functions do not need the NSA's

756
01:28:15,125 --> 01:28:21,125
help to suck. They get that for
free. It takes us like 10 years
to figure out that a cypher or a

757
01:28:27,542 --> 01:28:33,542
hash or whatever might actually
be safe. And the NSA has
actually been pretty good in

758
01:28:35,542 --> 01:28:42,958
saying something is wrong here.
This thing in nes, it's not
good. This thing in Shaw 0, it's

759
01:28:42,958 --> 01:28:48,958
not good. Exuse me, my throat's
a little dry. You know, sucks.
Wouldn't it be nice if we had

760
01:29:00,500 --> 01:29:06,500
like a department of the
government that was dedicated to
defense? Like a Department of

761
01:29:10,125 --> 01:29:16,125
Defense? They could have like a
conference, like a DEF CON.
What's happening is that even

762
01:29:22,500 --> 01:29:30,458
good advice is being treated
with deep suspicion. This is
like hey, yeah we standardized

763
01:29:30,458 --> 01:29:36,625
on this kesac algorithm and wow
Shaw 3 is slower than Shaw 256
in performance patterns. And you

764
01:29:36,625 --> 01:29:42,625
know this is not a controversial
opinion. Zuco of Tahoe LFS is
like hey, this site is too slow

765
01:29:45,042 --> 01:29:50,708
in performance patterns.
Community's like NIST, NIST is
evil. NIST is doing more evil.

766
01:29:50,708 --> 01:29:58,500
They've got NSA pulling their
strings and what's the end
result? We are totally replacing

767
01:29:58,500 --> 01:30:04,500
NIST with GJB, with some guy.
Now, I want to be clear, I'm an
enormous GJB fan. I've been

768
01:30:10,417 --> 01:30:16,417
advocating curve 25519 for TLS
replacing protocol for literally
like half a decade but fewer

769
01:30:19,375 --> 01:30:25,208
trusted resources in a time of
great need. Not actually
helpful. There's that great

770
01:30:25,208 --> 01:30:31,208
quote, Linux scales. Linux does
not scale. I have a graph and
this graph explains the problem

771
01:30:36,500 --> 01:30:42,500
very clearly. The NSA has two
missions. GJB, pretty sure only
has one. This is what's going on

772
01:30:52,333 --> 01:30:58,333
here, okay? Like sometimes one
of these guys finds a bug and
says, cool. And it's not GJB. So

773
01:31:05,792 --> 01:31:11,667
we're all kind of waiting for
the other shoe to drop, um, not
implementers. If you've noticed

774
01:31:11,667 --> 01:31:18,000
pretty much everything new that
comes out just uses GJB sec.
Like his stuff has won.

775
01:31:18,000 --> 01:31:25,667
Everything new is you know,
25519 or bad ass or lipsodium.
His stuff has won the day with

776
01:31:25,667 --> 01:31:31,667
implementers. There is what's
called epistomology. There's,
how do you know what you know?

777
01:31:34,375 --> 01:31:38,875
Academics aren't really allowed
to know things without some
degree of evidence. This is kind

778
01:31:38,875 --> 01:31:46,750
of a barrier to a lot of fud and
B.S. This is kind of the heart
of science. We do know that dual

779
01:31:46,750 --> 01:31:53,292
ECDRGPC is bad. We have hard
evidence, we have math and so
on. But there's another shoe and

780
01:31:53,292 --> 01:31:58,375
that shoe is what's called the
NIST P curves. There's this
great technology, it's called

781
01:31:58,375 --> 01:32:04,250
elliptical curves. Elliptical
curves requires parameters.
There are two major sets of

782
01:32:04,250 --> 01:32:10,833
parameters that came out of
NIST. The P curves and the K
curves. We know exactly how the

783
01:32:10,833 --> 01:32:16,000
K curves were constructed. You
take this value that comes from
a mathematical function. You put

784
01:32:16,000 --> 01:32:20,917
it in what is called, a nothing
up your sleeve generator to show
there's nothing up your sleeve.

785
01:32:20,917 --> 01:32:27,667
And now you have your parameters
and everything is good. And then
there's the P curves where that

786
01:32:27,667 --> 01:32:33,667
thing that's going into the
nothing up your sleeve generator
is C49E3608.... Well you know,

787
01:32:36,625 --> 01:32:42,625
every shirt has two sleeves. I'm
not saying we know that the P
curves are compromised. However,

788
01:32:46,583 --> 01:32:52,208
if you don't plan on the P
curves being compromised you're
an idiot and you should get

789
01:32:52,208 --> 01:32:58,583
fired. And in fact that's pretty
much what all implementers have
realized. One of probably the

790
01:32:58,583 --> 01:33:04,583
most interesting things about
bit coin is a long time ago they
said yeah this P curve stuff is

791
01:33:06,750 --> 01:33:11,958
garbage, let's go with the K
curves. So this is something
that everyone's sort of waiting

792
01:33:11,958 --> 01:33:17,958
for. It's not like we know it.
But we know it. The larger
issue, and it's not like crypto

793
01:33:21,792 --> 01:33:27,083
worked particularly well before
the NSA caught revelations, so,
ok. The hard problems in crypto

794
01:33:27,083 --> 01:33:33,500
actually aren't the math.
They're not actually even the
implementations, although DPG

795
01:33:33,500 --> 01:33:37,625
and GJB are god inside. Key
management is the hard part
because this is what actually

796
01:33:37,625 --> 01:33:43,875
touches users and organizations.
We keep modeling cryptography as
math implementation, but there's

797
01:33:43,875 --> 01:33:50,042
a complexity that goes unnoticed
and that's operations, ok. Every
project in the real world, who

798
01:33:50,042 --> 01:33:56,042
here works in IT? Okay? Tell me
I'm wrong when I say every
project needs to be measured

799
01:33:58,583 --> 01:34:06,417
only in terms of how many God
damn meetings you need to do in
order to complete it. That is

800
01:34:06,417 --> 01:34:12,417
the metric. When is the last
time you saw meeting count
measured in anything to do with

801
01:34:15,333 --> 01:34:22,708
cryptography? When is the last
time you saw crypto work in the
field? Not unrelated thing. We

802
01:34:22,708 --> 01:34:27,250
have to learn to respect
usability. We have to learn that
this is't the operational

803
01:34:27,250 --> 01:34:34,000
requirement. Over at Black Hat
one of the most significant
announcements in some time

804
01:34:34,000 --> 01:34:41,708
happened. Somehow Alex Stamos,
one of the founders of Isac got
root at Yahoo. I don't know how

805
01:34:41,708 --> 01:34:47,958
he did it, but he was like, you
know what, I'm going to do end
to end PGP for Yahoo fricking

806
01:34:47,958 --> 01:34:53,958
mail. Sweet! Because you know
what, Google might understand
user experience but Yahoo

807
01:34:59,667 --> 01:35:07,000
really, really understands it.
So, summary of what we have
talked about today, and we're

808
01:35:07,000 --> 01:35:13,292
almost done here. Don't let an
attacker touch your storage. Let
it store, let it execute but

809
01:35:13,292 --> 01:35:19,292
don't let it do both. Actively
gather true entropy. Death to
crptographically non secure NGs.

810
01:35:21,458 --> 01:35:27,875
Please, for the love of god,
represent entropy in a way other
than bit vomit. Browsers become

811
01:35:27,875 --> 01:35:32,125
vastly more secure when use
after free is prevented and we
are going to fix this in

812
01:35:32,125 --> 01:35:40,042
Firefox. The NSA crypto fallout
continues, it hasn't gone away.
There's been a wholesale

813
01:35:40,042 --> 01:35:46,042
movement to, while I'm a fan of
the guy, he's a guy. He's a
professor at UIC. Yahoo's PGP

814
01:35:48,750 --> 01:35:53,875
news is fantastic, one of the
most significant things of the
year, maybe of a couple years.

815
01:35:53,875 --> 01:35:59,875
And, just cause I can, just one
more thing. I totally get to
pool this. It's Apple related.

816
01:36:06,583 --> 01:36:14,333
Apple went ahead and put into
their latest release nodes for
IOS8, Safari now blocks ads from

817
01:36:14,333 --> 01:36:19,417
automatically redirecting from
the app store without user
interaction. If you still see

818
01:36:19,417 --> 01:36:23,250
the previous behavior or find
legitimate redirection to the
app store to be broken in some

819
01:36:23,250 --> 01:36:29,250
way, please file a bug. Yes! Ok,
I am tired of browsing something
on my phone and it's like, I

820
01:36:33,875 --> 01:36:38,542
know you're trying to browse
this website, but what I really
think you want to do is pay

821
01:36:38,542 --> 01:36:44,542
money to Kim Kardashian. No!
That is not what I want to do,
fuck those guys. Apple wants

822
01:36:47,417 --> 01:36:53,417
help, let's give it to them. Now
I talked about this on Twitter
before and I said, hey I'll give

823
01:36:57,167 --> 01:37:02,667
you 250 bucks. Screw that, I've
got a company. I'll give 5
fricking grand for the first

824
01:37:02,667 --> 01:37:08,750
person to go give Apple some
bugs they can fix. I want to see
this dead off the mobile

825
01:37:08,750 --> 01:37:14,917
internet, ok. I've become a
believer in bug bounties. This
is a complete 180 on my old

826
01:37:14,917 --> 01:37:20,917
postition. I used to think that
bug bounties would lead to
crappy bugs and people being

827
01:37:20,917 --> 01:37:27,542
idiots and demanding money
anyway, and it would just be
cheaper to pay them off. You

828
01:37:27,542 --> 01:37:33,458
can't imagine how crappy bugs
are that come in from the
outside world sometimes. People

829
01:37:33,458 --> 01:37:41,375
have no idea how stuff works and
they think they're geniuses. But
I was wrong. I'm telling you

830
01:37:41,375 --> 01:37:47,750
this. I have seen the results
first hand. If you want richer
bugs from the outside world,

831
01:37:47,750 --> 01:37:54,250
maybe you should make bug
finders richer. Turns out that
when you actually have a sample

832
01:37:54,250 --> 01:37:59,875
of good bugs that you pay for,
you can now be like, yah we paid
for the good bug, your thing's

833
01:37:59,875 --> 01:38:06,375
crap. So, we're not just doing
250 bucks, we're going to give
$5,000 to the first finder.

834
01:38:06,375 --> 01:38:11,917
$2500 to the second. $1,000 to
maybe the next 5. If we get
more, we might keep throwing

835
01:38:11,917 --> 01:38:18,708
more money at this. I don't know
how many bugs there are but we
believe in A, this sort of

836
01:38:18,708 --> 01:38:23,917
behavior is toxic. It destroys
the mobile web. It is some of
the worst stuff we see in

837
01:38:23,917 --> 01:38:30,917
advertising and I even run a
company that fixes advertising.
This is still offensive. And I

838
01:38:30,917 --> 01:38:36,917
think hackers can fix things,
and I'm willing to put my money
where my mouth is. So, thank you

839
01:38:36,917 --> 01:38:39,458
all. This has been a blast.

