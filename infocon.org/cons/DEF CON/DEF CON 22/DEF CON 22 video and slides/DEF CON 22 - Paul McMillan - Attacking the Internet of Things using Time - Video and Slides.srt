1
00:00:00,250 --> 00:00:06,542
>>Paul McMillan is going to talk
to us about attacking the
Internet of Things, seems to be

2
00:00:06,542 --> 00:00:13,417
kind of a theme today but he
brought in light. So he wins and
this demo is going to go just

3
00:00:13,417 --> 00:00:19,708
fine for him plus we had plenty
of prep time. For the last talk
of the day in party track let's

4
00:00:19,708 --> 00:00:25,708
give a big party track welcome
to Paul McMillan. (Applause)
 >> Okay. So I'll talk about

5
00:00:29,125 --> 00:00:35,250
timing attacks and the Internet
of Things is a great place. I'm
a security engineer at Nebula. I

6
00:00:35,250 --> 00:00:42,042
work on building clouds. This is
not directly related to what I
do in my all-day job, I do

7
00:00:42,042 --> 00:00:47,583
security. We'll talk about a
number of different ways you
can -- there are lots of kinds

8
00:00:47,583 --> 00:00:52,833
of timing attacks. The one we're
talking about is a string
comparison timing attack. One

9
00:00:52,833 --> 00:00:58,833
property is that it takes a
while to run so we'll get the
demo started first and can you

10
00:01:02,333 --> 00:01:08,333
hear me from over here? No.
Okay. There's a mic. One of
these. Yeah, okay.  So what we

11
00:01:12,458 --> 00:01:19,333
have -- the demonstration we're
doing today is using the
Phillips cube network light bulb

12
00:01:19,333 --> 00:01:25,083
controller in order to
demonstrate I have nothing up my
sleeve I'm resetting it there.

13
00:01:25,083 --> 00:01:31,458
And turning the lamp on. Now
they are not connected and there
are no user names or anything

14
00:01:31,458 --> 00:01:37,458
other data in the controller
here. The rest of the setup I
have here is a extension for my

15
00:01:40,375 --> 00:01:47,583
PCI express bus which allows me
to run server-grade network card
attached to my laptop. We'll get

16
00:01:47,583 --> 00:01:54,500
to that in a little bit why
that's useful but the most
important part is that the

17
00:01:54,500 --> 00:02:01,875
network card allows me to do
hardware assisted time stamping,
all the packets that come in and

18
00:02:01,875 --> 00:02:07,875
out of the device. So talking
about timing attacks, at the
most basic level asking a

19
00:02:13,292 --> 00:02:18,250
computer to do any operation
takes time, a measurable amount
of time. Timing attack exploits

20
00:02:18,250 --> 00:02:25,375
this by noticing differences in
the amount of time it takes to
process something. This is a

21
00:02:25,375 --> 00:02:31,375
typical example of user
authentication flow.  You start
with the getting a user name and

22
00:02:34,750 --> 00:02:40,750
password from your attacker. You
look up the hash in the
database. You compare the hash

23
00:02:44,625 --> 00:02:48,792
you got from the hash you have
in the database and then you
return. I know there are issues

24
00:02:48,792 --> 00:02:54,792
but it's the basic work flow.
 The obvious timing attack here
is that if the user doesn't

25
00:02:58,875 --> 00:03:04,875
exist in the database, this will
take a lot longer or take a lot
less time to run. An attacker

26
00:03:07,792 --> 00:03:13,792
can use this kind of work flow
to enumerate, guess a bunch of
users in a database and use that

27
00:03:16,083 --> 00:03:21,208
to accelerate attacks. That's
not the kind of timing attack
we're talking about today. There

28
00:03:21,208 --> 00:03:27,917
are lots of other kinds as well.
We have blind SQL injectiong,
CPU timing cache attacks against

29
00:03:27,917 --> 00:03:34,292
crypto. What we are talking
about today is string comparison
timing attacks. This is a pretty

30
00:03:34,292 --> 00:03:39,417
typical implementation of the
string comparison function. I
pulled it from the source code

31
00:03:39,417 --> 00:03:45,958
for the device sitting over here
and this is the relevant bit.
 The most important thing about

32
00:03:45,958 --> 00:03:53,708
this piece of code is that
rather than comparing all of the
pieces of the string together at

33
00:03:53,708 --> 00:03:58,375
once and saying they are the
same or not, atomic CPU
operation, it starts with the

34
00:03:58,375 --> 00:04:01,833
first two characters in the
string, first in each string
you're comparing, compares them

35
00:04:01,833 --> 00:04:09,625
if they match it moves on to the
next two and so on until you get
to the end of the string or they

36
00:04:09,625 --> 00:04:15,625
don't match.  The important
behavior here is that we have a
very small timing difference

37
00:04:19,000 --> 00:04:25,042
when you have a string which is
partly correct but not all the
way correct, and the string

38
00:04:25,042 --> 00:04:30,917
which is not correct at all.
They, the amount of time where
it either tries to do that next

39
00:04:30,917 --> 00:04:37,750
comparison and fails or just
stops doing the comparison is
something we can exploit.  If

40
00:04:37,750 --> 00:04:43,750
you look at properties you get
out of this, this means when you
are trying to brute-force a

41
00:04:48,375 --> 00:04:55,792
credential if you can do a
string comparison timing attack
on it, the time it takes to run

42
00:04:55,792 --> 00:05:03,083
the operation goes from an
exponential function to a
constant function of the number

43
00:05:03,083 --> 00:05:10,292
of items you have in the string.
 There are a lot of, you'll see
recommendations to make the

44
00:05:10,292 --> 00:05:17,000
passwords ten characters long.
The thing about that is adding
another two characters to an

45
00:05:17,000 --> 00:05:23,625
authentication credential that
is vulnerable to a string
comparison timing attack means

46
00:05:23,625 --> 00:05:30,542
it only takes two more of the
constant amount of time rather
than raising to another power of

47
00:05:30,542 --> 00:05:37,333
two.  So this is a very powerful
method if you can do it. The
problem is it's really hard to

48
00:05:37,333 --> 00:05:43,000
do. A lot of people will tell
you that this is only a
theoretical vulnerability. Not

49
00:05:43,000 --> 00:05:49,000
really an issue. I kind of just
explained why I think timing
attacks are interesting. The

50
00:05:52,917 --> 00:05:58,917
drawback is they generally make
a lot of noise. You have to take
a lot of samples of whatever it

51
00:06:01,833 --> 00:06:07,000
is you are trying to compare,
whatever it is you are trying to
attack before you can make a

52
00:06:07,000 --> 00:06:13,000
decision, a statistical decision
about whether or not the data
you have means anything.  So

53
00:06:15,208 --> 00:06:21,208
let's talk a little bit about
time.  The -- sort of
intuitively we know getting from

54
00:06:23,292 --> 00:06:29,417
San Francisco to New York takes
about 70 milliseconds, we know
that getting data off a scanning

55
00:06:29,417 --> 00:06:35,417
disc takes about 13. Going down
further RAM latency is 83
nanoseconds and then getting

56
00:06:38,750 --> 00:06:44,750
cache in CPU you are in the 1
nano second area. Then down to
the CPU cycle which is one-third

57
00:06:47,125 --> 00:06:52,333
of a nano second. By the way the
reference is for everything I'm
speaking of an my slides which

58
00:06:52,333 --> 00:06:59,417
will be on get hub after the
talk.  So go down a little
further. We have speed of light

59
00:06:59,417 --> 00:07:06,333
in a network cable. In a meter
it goes about five nanoseconds,
takes five nanoseconds to move

60
00:07:06,333 --> 00:07:12,333
meter and so when -- getting
lost here.  So the other thing
to remember when we are talking

61
00:07:17,458 --> 00:07:23,458
about network latency here is
that usually the peaks you are
working with are generally

62
00:07:25,667 --> 00:07:30,917
captured in milliseconds, not
nano seconds. Wireshark will
show you nanoseconds but

63
00:07:30,917 --> 00:07:38,167
generally that's when you've
done a bunch of work to make
that but that's not the case.

64
00:07:38,167 --> 00:07:44,917
 So the string comparison,
timing difference I talked of
earlier does, you know, it's on

65
00:07:44,917 --> 00:07:52,750
the order of nanoseconds. Of a
difference. But that's on a
three GHz machine. This device

66
00:07:52,750 --> 00:07:57,958
down here is only 120 MHz,
running a little embedded
processor,it doesn't do multi

67
00:07:57,958 --> 00:08:03,958
dual processing, it is not very
smart.  Um, so here is a picture
of it. The way the system works

68
00:08:09,917 --> 00:08:16,042
is that the base controller
connects via a wired connection
to the network or in this case

69
00:08:16,042 --> 00:08:23,125
my attack system. And then the
controller speaks the ZigBee
protocol. At the moment the

70
00:08:23,125 --> 00:08:29,125
light bulb just acts like a
normal light bulb and comes up
when you turn on the power. It

71
00:08:33,500 --> 00:08:39,458
looks like the device has
finished so I'll start actually
attacking it. Give me a moment

72
00:08:39,458 --> 00:08:45,458
here. (Pause) Unfortunately, I
can't show you both screens at
once. What I'm doing over here

73
00:09:03,583 --> 00:09:09,583
is starting a TCP dump, starting
a TCP dump session to collect
the network traffic between the

74
00:09:15,833 --> 00:09:21,833
network card, the network card
and the hue. The important thing
about that is that this is the

75
00:09:24,500 --> 00:09:30,500
very latest version of TCP dump
which allows you to capture
nanosecond-level differences if

76
00:09:32,625 --> 00:09:39,958
you have the hardware to support
it. So once I have started the
TCP dump, I'm going to also go

77
00:09:39,958 --> 00:09:46,250
ahead and start my data
collection script. What the data
collection script -- so to back

78
00:09:46,250 --> 00:09:52,250
up, the Hue API is very simple.
It's just to access the device,
you send a get request and put

79
00:09:58,250 --> 00:10:04,458
the authentication credential in
the URL and that's all there is
to it. Only one authentication

80
00:10:04,458 --> 00:10:10,458
credential, it's ten characters
long, and it's not -- not hash,
not encrypted. And so I have a

81
00:10:13,333 --> 00:10:20,042
python script here that is
starting trying to do a whole
bunch of requests to that

82
00:10:20,042 --> 00:10:26,042
authentication credential,
starting with a set of known
characters and we're collecting

83
00:10:28,750 --> 00:10:34,750
data now. We're guessing the
first couple character sets.  So
let me make the data over

84
00:10:57,375 --> 00:11:03,375
here... (Pause) So we are not
getting data. I was hoping to
have this computer do the

85
00:11:36,542 --> 00:11:43,625
analysis while that one collects
data. What I'll have to do is
analyze the data on that

86
00:11:43,625 --> 00:11:49,625
computer as we go.  The downside
to that is I can't use both
CPUs. If I run the analysis on

87
00:11:52,583 --> 00:11:59,167
that computer it's kind of noisy
and pollutes the data a little
bit.  While we collect the

88
00:11:59,167 --> 00:12:05,167
initial chunk of data here,
we'll talk about network timing
precision.  The milliseconds you

89
00:12:09,417 --> 00:12:15,833
get for the kernels default
drivers are not what you want to
the TCP dump, they're not what

90
00:12:15,833 --> 00:12:23,458
you want with the dump, they're
not what you want for this kind
of attack. The details you're

91
00:12:23,458 --> 00:12:31,042
looking for are as I said
earlier nanosecond range. You
just are really going to lose a

92
00:12:31,042 --> 00:12:37,417
lot of data if all you have to
work with is milliseconds.
 There are lots of things that

93
00:12:37,417 --> 00:12:44,500
can make your data collection
imprecise. Graphics drivers,
background networking. Basically

94
00:12:44,500 --> 00:12:51,500
you want to turn as much of the
machine off as you can. Then
once you have verified that you

95
00:12:51,500 --> 00:12:58,625
can actually conduct the timing
attack, then you can move it
back to being a more normal

96
00:12:58,625 --> 00:13:06,333
system and design your
parameters so that works. The
other thing that is really

97
00:13:06,333 --> 00:13:14,167
important is using the hardware
time stamping. Default software
time-stamping is really noisy,

98
00:13:14,167 --> 00:13:20,208
you get -- you're not top
priority and that's just the way
it is. The hardware I'm using

99
00:13:20,208 --> 00:13:26,208
here is the Intel I 350 NIC. A
lot of the newer laptop drivers
are starting to have precision

100
00:13:28,833 --> 00:13:34,833
time support. These are getting
added because NTP doesn't cut it
for a lot of data center needs.

101
00:13:37,333 --> 00:13:43,333
The data sheet on the I 350 says
it can capture at precision of
around eight and a half seconds.

102
00:13:45,417 --> 00:13:51,417
I'm thinking that's probably a
little bit optimistic but it's
not too far out.  I didn't put

103
00:13:54,458 --> 00:14:01,458
the picture here. I wanted to
get the demo working more than I
wanted the slides to be pretty,

104
00:14:01,458 --> 00:14:07,458
so I hope that doesn't bother
you too much.  So I already kind
of explained it but the other

105
00:14:09,750 --> 00:14:17,000
thing that is relevant here is
the express card to PCI express
adapter is just the direct bus

106
00:14:17,000 --> 00:14:22,000
adapter, not a very complicated
piece of hardware. We're not
going through other protocols to

107
00:14:22,000 --> 00:14:29,500
do that which allow this to
retain the performance that we
need for the network card.  So I

108
00:14:29,500 --> 00:14:35,250
talked through what we're doing
for the data collection. When
you go to look at the code

109
00:14:35,250 --> 00:14:41,375
you'll see a couple really
simple scripts doing individual
things. The idea was to break it

110
00:14:41,375 --> 00:14:47,375
down, not give you a giant
monolithic thing you have to run
on the same attack machine.  We

111
00:14:50,292 --> 00:14:58,167
have a traffic generator, just
repeatedly sending different
variations of the guess for the

112
00:14:58,167 --> 00:15:05,708
next character in the
authentication token to the
server. We have the data

113
00:15:05,708 --> 00:15:11,792
collection which is TCP dump and
then we have the separate
analysis script and then the

114
00:15:11,792 --> 00:15:17,250
idea was we would feed that back
through the analysis script on
this machine and update the next

115
00:15:17,250 --> 00:15:23,583
guess as we got enough data to
assume that or to prove that we
knew what the next character

116
00:15:23,583 --> 00:15:29,042
was. Unfortunately I'm going to
have to do that by hand because
the machines aren't talking to

117
00:15:29,042 --> 00:15:35,042
each other.  I'm -- I'll let
that run for a little bit longer
here.  So things to make this

118
00:15:44,042 --> 00:15:50,042
work. You need at least Libpcap
version 1.5. TCP dump 4.60 or
otherwise you don't have

119
00:15:53,250 --> 00:15:59,250
hardware time support and you
don't have the ability to
capture the nanosecond level.

120
00:16:01,917 --> 00:16:07,917
They work on 1404, I haven't
tried them anywhere else, and
TCP dump 1.6.1 just came out

121
00:16:10,333 --> 00:16:17,542
like a week ago. So that's a
pretty good choice. So
nanoseconds turned out to be

122
00:16:17,542 --> 00:16:23,625
really invent to work with.
Scapy doesn't like to read the
PCAP files. Doesn't like the new

123
00:16:23,625 --> 00:16:29,625
format with nanoseconds from TCP
dump. Wireshark will read it but
it's not a generally useful

124
00:16:32,333 --> 00:16:38,000
packet parsing library that you
can use in other things. For
better or worse I ended up doing

125
00:16:38,000 --> 00:16:44,125
that and what I'm using to parse
these packets in the analysis
script is a package called T

126
00:16:44,125 --> 00:16:50,125
shark, command line version and
a router called pie shark, I
think. Another thing to remember

127
00:16:52,792 --> 00:16:59,333
when you work with these numbers
(Pie shark) You can't convert to
flow because you lose precision,

128
00:16:59,333 --> 00:17:06,958
easy way is use use in
nanoseconds and subtract a large
value from every value work with

129
00:17:06,958 --> 00:17:14,000
or just deal with the
differences.  And the other
problem is oftentimes you don't

130
00:17:14,000 --> 00:17:21,333
realize you're converting if you
call out to data analysis
libraries. It's better to

131
00:17:21,333 --> 00:17:27,333
convert these into smaller
differences when you are
actually going to work with

132
00:17:30,958 --> 00:17:36,042
them.  This is the Hue API, very
basic, the networking stack is
very interesting and I mean that

133
00:17:36,042 --> 00:17:42,042
in the nicest possible way. It
always return the http 200
status code. It doesn't really

134
00:17:44,625 --> 00:17:52,333
mind if you just don't send AK
packets. It just kind of keeps
going. It, as I said, it's just

135
00:17:52,333 --> 00:17:58,333
the user token. There is no user
name and password and it's not
very fast. Depending on how the

136
00:18:00,500 --> 00:18:08,333
device is feeling during any
given day it's between 30 and 60
requests per second. So this is

137
00:18:08,333 --> 00:18:12,667
the other limiting factor, it's
nice it's slow because the
timing track we're trying to

138
00:18:12,667 --> 00:18:19,625
exploit is more obvious but it's
not nice because it takes a long
time to collect the data.  Other

139
00:18:19,625 --> 00:18:22,500
things about the Hue. It's
running FreeRTOS 6.05. SSDP
implementation which I'm using

140
00:18:22,500 --> 00:18:28,500
to discover it on the network
here is pretty much someone
looked at some traffic and said

141
00:18:36,458 --> 00:18:42,458
oh that must be how it works and
didn't read any of the
documentation.  The behavior

142
00:18:44,750 --> 00:18:50,750
with the http responses is very
interesting. As I said before
the speed you can get out of it

143
00:18:56,708 --> 00:19:01,083
is variable and the properties
of the network stack seems to
have is rather than buffering

144
00:19:01,083 --> 00:19:08,625
packets in some kind of sane
manner, you send a request, it
gets a request and sends back a

145
00:19:08,625 --> 00:19:16,292
few hundred bytes response which
is always http 200, doesn't even
think about that. Then it cuts

146
00:19:16,292 --> 00:19:22,250
and makes a packet break and
goes and thinks about it for a
while longer. Now, any time it's

147
00:19:22,250 --> 00:19:27,375
thinking about it and
constructing the rest of your
response, if you send the ARP

148
00:19:27,375 --> 00:19:32,667
packet to that initial part of
the response, it will stop
processing, go back to the

149
00:19:32,667 --> 00:19:39,542
network stack, dump whatever is
in the network buffer, send it
out and go back to processing.

150
00:19:39,542 --> 00:19:45,000
This might make sense or work
out well but if your machine is
a lot faster than it, you can

151
00:19:45,000 --> 00:19:52,000
spend most of the response time
having it switch between that
and the thing it's actually

152
00:19:52,000 --> 00:19:58,000
trying to do, and you get
very -- an extremely variable
amount of time that the whole

153
00:20:01,417 --> 00:20:07,833
process takes. It's really
problematic for your precision.
 Let's see. Other things. Yeah,

154
00:20:07,833 --> 00:20:13,000
http stack basically ignores
whatever headers you send in.
Doesn't pay attention content

155
00:20:13,000 --> 00:20:18,958
type of anything like that.  It
sometimes sends out the wrong
ethernet sequence and it sends a

156
00:20:18,958 --> 00:20:26,708
lot of random stuff even when
not connected to the Internet. I
have noticed occasionally when

157
00:20:26,708 --> 00:20:32,708
it has an IP address it will
still be trying to the TCP. It's
always looking for open DNS even

158
00:20:35,292 --> 00:20:41,292
when it knows where it is. So
let's go back to the principles
of the attack we're doing here.

159
00:20:45,000 --> 00:20:51,000
 I think we collected about five
minutes of data here. I'm going
to start the first of what will

160
00:20:58,000 --> 00:21:04,000
be several statistical analyses
on the data we have collected
and I will show you what we're

161
00:21:06,500 --> 00:21:12,500
getting.  So we're stopping the
packet capture here because I
would normally be doing it on

162
00:21:14,667 --> 00:21:20,667
that machine but it's not
working out. The other thing
that takes time as I mentioned

163
00:21:30,792 --> 00:21:37,042
before I can't use a normal
packet, nothing supports the
nanosecond time stamp magic

164
00:21:37,042 --> 00:21:43,042
cookie at the top of the file,
rather than building A parser by
hand I figured for the demo it

165
00:21:47,917 --> 00:21:54,583
was okay to use someone else's.
The process of converting raw
packet data to something I can

166
00:21:54,583 --> 00:22:02,083
parse is going through T shark
and then turning into an XML
representation of the packet,

167
00:22:02,083 --> 00:22:07,458
then turning that, parsing that
XML and pulling out a few stats
and writing them back to the

168
00:22:07,458 --> 00:22:13,458
file. Ends up packing CPU on the
machine that is doing it. I
would like to do better but I am

169
00:22:16,250 --> 00:22:20,042
more interested in the
properties of the perfect
concept rather than the actual

170
00:22:22,417 --> 00:22:28,750
time it took to implement it.
 Let's talk about statistics.
The statistical things that

171
00:22:28,750 --> 00:22:34,750
we're going to do to the data in
a minute are not going to be the
ones that immediately spring to

172
00:22:44,375 --> 00:22:52,395
mind. You can't use the T test.
You have to be very careful. You
have to read about statistical

173
00:22:52,400 --> 00:23:00,140
methods a great many of them
require your data to be normal.
Your data in this case is most

174
00:23:00,140 --> 00:23:07,600
fundamentally assuredly nothing
like normal. The distributions
are banded and striated and I'll

175
00:23:07,600 --> 00:23:14,240
show you what they look like in
a minute.  The statistical test
we'll be using is called the

176
00:23:14,240 --> 00:23:26,000
Comogeral Smirnoff Test and it
is a test which allows us to --
the hypothesis, it allows us to

177
00:23:26,000 --> 00:23:32,000
assert whether or not a pair of
samples come from the same
distribution. Doesn't allow us

178
00:23:32,000 --> 00:23:38,333
to say anything more about them
other than if they are -- other
than whether or not they appear

179
00:23:38,333 --> 00:23:44,958
to be the same, from the same or
different distributions so in
this case we are going to be --

180
00:23:44,958 --> 00:23:50,958
so we have -- to back up, let's
talk about the hue API. That
user token, what we are using

181
00:23:53,667 --> 00:24:04,333
for the token right here is a 10
randomly chosen characters 0
through 8 and so for our

182
00:24:04,333 --> 00:24:13,153
hypothesis testing, we are
picking, we're generating a
random user token and starting

183
00:24:13,160 --> 00:24:21,080
with a guess from each of these
categories. Once we have parsed
the data, the -- we sort the

184
00:24:21,083 --> 00:24:26,875
results that we got from each
test into buckets based on what
the first character in the first

185
00:24:26,875 --> 00:24:34,458
character that we're
investigating is in the string.
 So this means that what we're

186
00:24:34,458 --> 00:24:42,083
trying to do is say which of
these, which of these data sets
and in this case it will be

187
00:24:42,083 --> 00:24:47,875
several probably several tens of
thousands of data points, which
of them is different from all

188
00:24:47,875 --> 00:24:59,835
the other ones. (coughing) We're
trying to identify it. So as I said
before we can't use the --

189
00:24:59,840 --> 00:25:08,792
requires data be normal and the
Smirnoff test is the best one
that I have found. I've tried a

190
00:25:08,792 --> 00:25:19,332
number of different things and
the ones identified in the
literature from 2009 their box

191
00:25:19,333 --> 00:25:24,583
test didn't work super well for
my data. Not sure whether my
data looks very different from

192
00:25:24,583 --> 00:25:30,583
there's or what was going on
there. But KFS work pretty well.
Where are my graphs? So this

193
00:25:37,000 --> 00:25:46,600
this is still parsing.  Once
we've collected this data what
do we do to actually prepare it

194
00:25:46,600 --> 00:25:52,380
for running into the algorithm?
We can't identify the timing
difference by taking all the

195
00:25:52,380 --> 00:25:56,340
data putting it into the
algorithm and say sort it out
and collecting more samples

196
00:25:56,340 --> 00:26:02,333
until we get the difference
we're looking for. Unfortunately
that takes a very long time.

197
00:26:02,333 --> 00:26:09,292
When I submitted the talk, the
amount of time it took to do a
single, identify a single string

198
00:26:09,292 --> 00:26:15,667
that was different took me about
eight hours worth of data. I
have gotten that down to about

199
00:26:15,667 --> 00:26:22,042
12 minutes if the parsing works
right but unfortunately I have
to go back and forth through

200
00:26:22,042 --> 00:26:32,792
that.  The various ways you can
prep your data, lot of ways to
screw it up. If you filter data

201
00:26:32,792 --> 00:26:38,792
and then you end up, so you have
time series data but you're
treating, the KS test does not

202
00:26:40,917 --> 00:26:48,875
care about the time series. It
is just sorting your data and
dealing with it. So if you have

203
00:26:48,875 --> 00:26:57,195
data where you have a jump in
the overall processing time for
a while, and you do a linear

204
00:26:57,208 --> 00:27:03,208
filter, you know, just an upper
and lower bounds, you end up
with samples where you have a

205
00:27:05,280 --> 00:27:10,000
lot of samples from a time
period that is not well
represented by the rest of your

206
00:27:10,000 --> 00:27:16,000
groups. This really screws up
the statistics and if you do
that you end up with data that

207
00:27:18,083 --> 00:27:24,083
just isn't useful.  The Code is,
is up int the repo or it will
be. I showed you how it

208
00:27:29,958 --> 00:27:37,250
separated out. The code is
really starting point for the
analysis. It's not a full-blown

209
00:27:37,250 --> 00:27:43,250
click it and run tool,
especially not against some
other device. The -- let me

210
00:28:01,875 --> 00:28:07,875
actually show you some of this
code here. (Pause) Looks like we
have finished the initial

211
00:28:32,375 --> 00:28:38,375
analysis of the first round of
data so I'll go ahead and see if
I can plug the laptop into the

212
00:28:40,792 --> 00:28:46,792
projector to show that to you.
The script we're doing now is
the Calculate Guesses Script,

213
00:29:43,250 --> 00:29:49,250
which is taking the -- this was
working earlier. Okay. Start by
looking to see what the process

214
00:30:16,875 --> 00:30:22,875
data looks like. This it what
data looks like after. What
these are showing is these are

215
00:30:43,333 --> 00:30:49,333
showing relative differences in
packet arrival times as we
interrogate the unit. If we look

216
00:30:52,292 --> 00:30:58,292
at the raw data for Wireshark we
can see the conversation that I
was telling you about with the

217
00:31:12,458 --> 00:31:19,458
device here. You get requests,
we get back this one part of the
packet and then get back the

218
00:31:19,458 --> 00:31:25,375
rest of the packet and have
other network connection
handling. Device doesn't know

219
00:31:25,375 --> 00:31:32,542
how to keep the socket open.
 What we're looking at when we
actually analyze data is that we

220
00:31:32,542 --> 00:31:37,583
are taking this time between
this first packet and the time
that the rest of the packet

221
00:31:37,583 --> 00:31:43,583
arrives. A lot of times it will
say look at the total time that
the request for response cycle

222
00:31:46,750 --> 00:31:51,167
takes. In this request just the
difference between those two
response packets provided a much

223
00:31:51,167 --> 00:31:57,167
better signal. Um, the...
(Silence) I don't know what's
wrong. Very frustrated. Huh?

224
00:33:02,083 --> 00:33:08,083
Yeah. So what that should have
shown us and immediately after
the talk I'm sure, what that

225
00:33:13,292 --> 00:33:19,292
should have shown us was a
collection, a set of the KS test
analysis for each of the

226
00:33:21,500 --> 00:33:29,458
combinations of the data points.
We have eight different guesses
so zero compared to 1, zero

227
00:33:29,458 --> 00:33:37,417
compared to 2 and so on, all
combinations of the data. In
general what you see when you do

228
00:33:37,417 --> 00:33:43,417
that is that the as you gather
more data, the values fluctuate
and so you have a p value from

229
00:33:51,125 --> 00:33:57,125
the KS statistic but the p value
from the KS statistic is not
going to be the one that you

230
00:34:02,250 --> 00:34:09,125
look at for the overall result
you're looking for, because
the -- it's only relevant to

231
00:34:09,125 --> 00:34:14,125
that individual comparison
because you're making the
combination of that many

232
00:34:14,125 --> 00:34:17,917
comparisons. Your overall p
value has to be much lower. Your
overall expected value has to be

233
00:34:17,917 --> 00:34:23,917
much lower than the system. So
the way that we -- the way that
I handled choosing which one is

234
00:34:27,958 --> 00:34:35,708
different is I take all those p
values, pick a threshold and say
when the threshold, when the

235
00:34:35,708 --> 00:34:42,458
values are at the acceptable
threshold, we count that as a
vote for each item, being

236
00:34:42,458 --> 00:34:48,333
different from all the others.
As you see when you collect data
as you get up into about 10,000

237
00:34:48,333 --> 00:34:54,333
packets the thresholds start to
become very obvious. You start
to see that everyone is saying

238
00:34:57,167 --> 00:35:03,167
this one, whichever one it is is
different so in general when the
system is not broken that takes

239
00:35:05,792 --> 00:35:11,792
on the order of 12 minutes per
character to brute-force the
system. If you want to be really

240
00:35:16,708 --> 00:35:22,708
really sure and not accidentally
choose the wrong character, if
you go up to 15 minutes, the

241
00:35:24,750 --> 00:35:30,750
statistical difference starts to
get just ridiculously obvious.
So I will get this working and

242
00:35:37,042 --> 00:35:43,125
post a YouTube video of it
later.  We'll go through some of
the things that I learned while

243
00:35:43,125 --> 00:35:50,750
implementing this attack. If you
can keep the socket open, do it.
Anything to reduce noise,

244
00:35:50,750 --> 00:35:56,250
anything to reduce the number of
packets that you have while
you're interacting with target

245
00:35:56,250 --> 00:36:01,792
device makes your life easier.
Difference is you are looking
for a really small, do

246
00:36:01,792 --> 00:36:07,792
everything you can.  The -- is
this not -- no, not... (Pause)
I'm just reading the slides

247
00:36:17,792 --> 00:36:23,792
anyway so... (Pause) When you
are configuring your network
parameters use the hardware time

248
00:36:31,958 --> 00:36:37,958
stamps, turn off the queues and
hardware assist on the network
card, obviously use nanoseconds

249
00:36:41,917 --> 00:36:48,333
and just everything that you can
do make everything quiet. If
your device is multithreaded it

250
00:36:48,333 --> 00:36:54,917
turns out using Solaris to tie
up everything except for the
thing you're trying to do worked

251
00:36:54,917 --> 00:37:00,583
pretty well. This thing can't
handle multithreading but in
other things I've tried it on,

252
00:37:00,583 --> 00:37:08,500
that helps. In this case don't
run extra stuff, don't try to
analyze and capture data at the

253
00:37:08,500 --> 00:37:14,458
same time. I probably should
have done that and the demo
might have worked but the other

254
00:37:14,458 --> 00:37:21,750
thing is profile your victim.
When you are -- when you look at
this thing you can actually see

255
00:37:21,750 --> 00:37:27,750
that the it has noisy periods
and quiet periods and you can
discard the noisy periods and

256
00:37:32,500 --> 00:37:38,500
the way you want to do that is
picking a time around when the
noise occurs and discarding that

257
00:37:38,500 --> 00:37:43,542
as opposed to just filtering
values that are too high or low.
Reason you don't want to filters

258
00:37:43,542 --> 00:37:50,208
values that are too high or low
for discarding things around
noisy periods is then you end up

259
00:37:50,208 --> 00:37:56,208
biasing your data towards the
sample that may not be relevant.
 Another thing that helps is if

260
00:37:59,292 --> 00:38:05,292
you get it warm before you
start. The differences are
fairly small but as it heats up

261
00:38:08,125 --> 00:38:14,500
it changes. If you don't warm it
up before you start data
collection you will have more

262
00:38:14,500 --> 00:38:21,000
trouble getting statistical
certainty.  Again, finding the
simplest request possible. It

263
00:38:21,000 --> 00:38:28,000
doesn't have a lot of processing
power. Shorten the length, you
get better results. In this case

264
00:38:28,000 --> 00:38:34,000
I took away all http headers
except for the first and second
lines and it didn't notice.

265
00:38:37,000 --> 00:38:43,792
Again, the most common mistake I
think that I ended up making as
I was working through different

266
00:38:43,792 --> 00:38:51,000
ways to analyze data was
accidentally making assumptions
about normality. Assuming data

267
00:38:51,000 --> 00:38:57,042
was normal, picking a test that
assumed it was normal, doing
things that required data to be

268
00:38:57,042 --> 00:39:03,083
normal.  Another thing that is
important is to gather data on
all hypotheses concurrently. If

269
00:39:03,083 --> 00:39:09,083
you gather all data on A, B, and
C, because they are not linked
in time you end up with sort of

270
00:39:11,792 --> 00:39:19,250
macro level drifts which mean
that you can't compare the data.
It's completely worthless. In

271
00:39:19,250 --> 00:39:25,250
the code I'm using here it
randomly resorts my array of
things I'm testing every time it

272
00:39:27,375 --> 00:39:34,917
cycles through them but doesn't
just randomly pick. It does make
sure it runs each hypothesis

273
00:39:34,917 --> 00:39:40,917
about the same number of times.
 Another thing, don't overwhelm
the device. If you slow down and

274
00:39:45,667 --> 00:39:52,167
give the device time to process
the request, you end up with
less noisy data. In my case the

275
00:39:52,167 --> 00:39:58,250
way I did that was by setting up
firewall to block packets
because they were making the

276
00:39:58,250 --> 00:40:05,500
data noisy. The other thing to
remember about this is don't
forget you can just stop and

277
00:40:05,500 --> 00:40:11,083
brute-force a token. You don't
have to do the timing attack all
the way to the end and

278
00:40:11,083 --> 00:40:16,583
10-character password if you can
do the first five the rest of it
may be easy to do online brute

279
00:40:16,583 --> 00:40:22,958
force depending on the size of
the key space. Another thing to
remember is not the case in this

280
00:40:22,958 --> 00:40:28,083
device but in many devices, the
code will short-circuit if the
strings you are comparing aren't

281
00:40:28,083 --> 00:40:34,708
the same lengths so in this case
you know how on the
authentication token is. It's

282
00:40:34,708 --> 00:40:40,708
worth sending a full token with
each request. Some code will
short-circuit in that case.  I

283
00:40:43,250 --> 00:40:49,250
talked earlier about taking a
moment to let the device breathe
between requests, once you have

284
00:40:52,458 --> 00:40:59,000
the statistical tests, you can
very easily tell the data that
allows you to do hypotheses

285
00:40:59,000 --> 00:41:05,000
testing and say if I do this one
thing does it make data better
or worse and verify it as

286
00:41:07,375 --> 00:41:13,208
opposed to just relying on your
gut feeling.  The other thing
about this is it's really easy

287
00:41:13,208 --> 00:41:19,208
to get fooled by your own data.
You'll sit there, you'll gather
data, analyze it and go, I have

288
00:41:21,792 --> 00:41:27,333
a way to analyze this data that
tells me the right answer
because you know what it is. And

289
00:41:27,333 --> 00:41:33,250
then you'll gather, you'll write
it down, apply it and gather
more data and find out that the

290
00:41:33,250 --> 00:41:39,042
test you came up with, which
relied on some magic numbers and
maybe a multiple of something

291
00:41:39,042 --> 00:41:43,458
totally only worked for that
collection of data you had. When
in doubt always take more

292
00:41:43,458 --> 00:41:50,083
samples and take samples,
analyze them, and then take more
when you change method. Don't

293
00:41:50,083 --> 00:41:58,520
assume you have a method that
works when you have the data
that you have fit and give the

294
00:41:58,520 --> 00:42:06,333
result you want. I like this
quote because I think it
explains that really well. If

295
00:42:06,333 --> 00:42:10,042
you try hard enough eventually
statistically significant
findings will emerge from any

296
00:42:10,042 --> 00:42:17,167
reasonably complicated set. When
result are analyzed the results
simply cannot be interpreted. At

297
00:42:17,167 --> 00:42:21,333
best you have to treat the
findings as a hypothesis to be
tested in future studies with

298
00:42:21,333 --> 00:42:28,417
new data. So that's the end of
my slides and looks like I'm out
of time so other than the

299
00:42:28,417 --> 00:42:36,083
non-working demo, does anyone
have any questions? >>Yep? >>Are
the tools for this online? >>I'm

300
00:42:36,083 --> 00:42:41,083
going to make the get hub repo
with all the embarrassing code
in it public as soon as I step

301
00:42:41,083 --> 00:42:50,663
away from the mic here. >>Would
this work on a wireless network?
>>You would have to work very

302
00:42:50,667 --> 00:42:56,958
hard to make this work on a
wireless network. It's probably
possible. The things you have to

303
00:42:56,958 --> 00:43:04,998
do to make network cards
consistent enough would require
a lot more samples than what I

304
00:43:05,000 --> 00:43:11,375
was trying to demo today. You
would probably be looking at on
the order of days' worth of data

305
00:43:11,375 --> 00:43:21,155
to analyze a single character
difference. >>So you said there
were some graphs you had of the

306
00:43:21,167 --> 00:43:27,167
data plotted. Can you show us
the statistically significant...
oh then the next character must

307
00:43:27,167 --> 00:43:37,200
be a port or something. >>I may
have miss placed all of that.
That may not be here. (Silence)

308
00:43:44,250 --> 00:43:48,958
>>Yeah, I don't think I have the
graphs handy. Sorry. Yeah? >>I
have to design a system to

309
00:43:48,958 --> 00:43:55,198
defend against an attack, which
is very difficult to do. What
would you do? >>To design a

310
00:43:55,200 --> 00:44:00,340
system to defend against this
attack you have to make the
correct and incorrect paths take

311
00:44:00,340 --> 00:44:07,400
the same amount of time. A lot
of people say I'll just add
random amount of delay, which

312
00:44:07,400 --> 00:44:11,480
that has a predictable
distribution, then I take more
samples and the random amount of

313
00:44:11,480 --> 00:44:18,900
delay goes away. Adding a fixed
amount of delay doesn't change
statistics at all. Makes it just

314
00:44:18,900 --> 00:44:25,220
about the same. Anything else?
 >> All right. (Applause)
 >> Thank you! (Applause)

