1
00:00:00,167 --> 00:00:04,042
And so for our last talk of the
day I think this is going to be
a big one these guys have a lot

2
00:00:04,042 --> 00:00:07,862
of information to share with you
guys with some really
interesting stories and

3
00:00:07,862 --> 00:00:15,080
background. Without further ado
I'd like to introduce Thor. [
laughter ] I'm just kidding.

4
00:00:18,500 --> 00:00:25,417
This is Ladar Levison and
Stephen Watt who are going to
talk about Dark Mail. Give it

5
00:00:25,417 --> 00:00:35,157
up. [ Applause ] [Applause] >> I
know everybody gets upset when
it's time to get down to work

6
00:00:35,167 --> 00:00:42,458
they just want to keep watching
the video. We're here the talk
about Dark Mail. Unfortunately

7
00:00:42,458 --> 00:00:49,333
we're not calling it Dark Mail
any more. Like all the really
catchy names, domain keys,

8
00:00:49,333 --> 00:00:53,893
pretty good privacy,
they all tend to change,
lengthen when you go

9
00:00:53,900 --> 00:00:57,740
through that standards
and formalization
process. And I

10
00:00:57,740 --> 00:01:02,640
think the entire point to
lengthen it just so you can turn
it back in to a shortened

11
00:01:02,640 --> 00:01:08,080
acronym. There's a pay phone
joke in there I'm just not sure
it's funny so I'm not going to

12
00:01:08,083 --> 00:01:16,458
tell it. But you can make up
your own later. I figured the
easiest way to explain what DIME

13
00:01:16,458 --> 00:01:19,738
was, was to draw it all up on a
black board and take a picture.

14
00:01:22,458 --> 00:01:24,458
Did everyone get that?

15
00:01:26,140 --> 00:01:34,120
get your pencils ready I'll do
it one more time. Oops. How did
that get there? Those private

16
00:01:34,120 --> 00:01:41,040
keys are supposed to be
private. What is DIME?

17
00:01:44,900 --> 00:01:53,200
It's two protocols, two formats and
management and configuration
record and DNS system.

18
00:01:55,080 --> 00:02:02,000
We've got the Dark Mail
transfer protocol, which is an
unauthenticated protocol that

19
00:02:02,000 --> 00:02:08,708
provides inner domain message
transfer and key look ups, we've
got the Dark Mail access

20
00:02:08,708 --> 00:02:15,250
protocol. Which is
authenticated, handles
persistent access to messages.

21
00:02:15,250 --> 00:02:23,125
Synchronization of Caches and
key information. And a
submission protocol. It's worth

22
00:02:23,125 --> 00:02:30,333
noting even know DMAP and DMTP
are pictured together on that
slide I'm only trying to

23
00:02:30,333 --> 00:02:35,083
indicate that both are on a
server they don't necessarily
have to be on the same server.

24
00:02:35,083 --> 00:02:41,083
Just like mail is today. The
formats, we have a Signet, which
is a signing and encryption key

25
00:02:44,708 --> 00:02:50,500
along with collection of
attributes and a signature very
much like what we're familiar

26
00:02:50,500 --> 00:02:56,500
with when it comes to PGP public
key. Or X509 certificate. Of
course, it's neither of those.

27
00:02:59,000 --> 00:03:06,042
Don't call them either of those
call them a Signet. Like a
Signet ring. We've got the dark

28
00:03:06,042 --> 00:03:12,042
message format which is
mine‑like as we'll get to later.
It breaks up the mine structure

29
00:03:19,042 --> 00:03:25,042
in to independent chunks that
are encrypted with different
symmetric keys. And the goal of

30
00:03:27,917 --> 00:03:34,625
designing that was to basically
create a format that would
translate lost-lessly between

31
00:03:34,625 --> 00:03:41,875
mine and the format. The only
information that is lost is
actually the original mine

32
00:03:41,875 --> 00:03:48,417
boundary. And since that happens
to be something that is easily
fingerprinted, losing that

33
00:03:48,417 --> 00:03:54,417
information might actually be a
good thing. So, we've got this
complex ecosystem that we're

34
00:03:56,417 --> 00:04:02,417
trying to build here, it's all
up here, all I need now is an
easy button. There was supposed

35
00:04:07,750 --> 00:04:13,750
to be audio file that plays. An
easy button that would turn it
all in to working software. But

36
00:04:18,833 --> 00:04:24,833
in lieu that have I have
Stephen. I tried the Apple key,
that didn't work. Tried the

37
00:04:27,500 --> 00:04:32,667
Windows key, that didn't work
either. And then I went looking
for the Linux key and I just

38
00:04:32,667 --> 00:04:40,333
didn't find it. Like to point
out even they we use the word
"Dark" quite a bit we never

39
00:04:40,333 --> 00:04:46,333
follow it with the word tangent.
I think it's important to spend
a few minutes talking about why

40
00:04:49,333 --> 00:04:55,708
something like DIME is so
important. And why it has to be
as complex as it is. The

41
00:04:55,708 --> 00:05:01,708
original idea was actually far
simpler. It was centered around
managing the key generation and

42
00:05:04,208 --> 00:05:10,208
look‑up process for PGP. And
because of everything that has
come out in the last year we've

43
00:05:13,917 --> 00:05:19,917
really had to expand what we're
trying to accomplish to include
both minimizing the leakage of

44
00:05:22,375 --> 00:05:30,333
metadata and create a system
that was resistant to
manipulation by advanced

45
00:05:30,333 --> 00:05:36,750
persistent threats. And
unfortunately each one of those
additional goals only compounded

46
00:05:36,750 --> 00:05:42,750
the complexity of the ecosystem.
By a few orders of magnitude
each. But I think it's important

47
00:05:50,208 --> 00:05:56,000
because with the type of
metadata collection that's going
on today we have guilty by

48
00:05:56,000 --> 00:06:01,333
association. Imagine being
placed on a no‑fly list because
you happen to sit next to a

49
00:06:01,333 --> 00:06:07,333
criminal at a convention like
this. Or the problem of mass
surveillance, record everything

50
00:06:13,250 --> 00:06:21,208
and let the NSA sort it out. And
then of course there's the
problem that I came in to, which

51
00:06:21,208 --> 00:06:28,333
is the idea that as a service
provider I'm beholding to my
customers, those are the people

52
00:06:28,333 --> 00:06:34,083
who I serve without them the
business does not exist. And
here's this entity that comes

53
00:06:34,083 --> 00:06:38,083
along with a bunch of guns and
piece of paper that says you
have to betray the people that

54
00:06:38,083 --> 00:06:44,083
are funding your business. It's
creating a crisis of confidence.
But I'd use a couple of excerpts

55
00:06:48,875 --> 00:06:54,125
from my own case, this is a
court transcript and as you can
see from the judge's very own

56
00:06:54,125 --> 00:07:00,125
words that today the court feels
that they are entitled to access
everyone's information. And the

57
00:07:06,458 --> 00:07:12,458
only way we can stop that is
through the introduction of end
to end encryption. But in order

58
00:07:16,583 --> 00:07:22,583
for everyone to start using
end‑to‑end encryption, we need
to make it easier. We need to

59
00:07:24,750 --> 00:07:30,750
make it Auto‑magical. And making
security and cryptography happen
automatically while remaining

60
00:07:35,667 --> 00:07:41,667
secure and doing it for e‑mail
while preserving all of the
functionality that e‑mail

61
00:07:43,708 --> 00:07:49,708
provides is actually a very
technical difficult challenge. I
touch briefly on what the goals

62
00:07:54,833 --> 00:08:00,833
were but I think it's worth
reiterating them here. PGP and
S-mine give us author validation

63
00:08:04,083 --> 00:08:10,917
and message confidentiality but
don't do a very good job at any
of the other goals. Dark Mail

64
00:08:10,917 --> 00:08:16,917
was really started to achieve
these additional bullet points.
And it meant building a system

65
00:08:23,875 --> 00:08:29,875
that was both secure, automatic
and could be accessed from
different types of clients on

66
00:08:33,125 --> 00:08:38,500
different platforms with
different types of constraints
in the very same way that we

67
00:08:38,500 --> 00:08:44,500
access e‑mail today. And that to
do it and build it in a way that
can handle Internet scale. Last

68
00:08:48,917 --> 00:08:54,792
time I checked there were about
three billion e‑mail users on
this planet. That's the reason I

69
00:08:54,792 --> 00:09:00,792
got in to the business, I knew
I'd never have a shortage of
potential customers. But doing

70
00:09:04,375 --> 00:09:10,375
that while also minimizing the
leakage of metadata is
incredibly difficult. Might be

71
00:09:13,458 --> 00:09:19,458
why we borrowed the onion
concept from TOR. Now we're not
TOR. But we do come a lot closer

72
00:09:24,458 --> 00:09:28,750
to limiting the amount of
information that a service
provider has available to turn

73
00:09:28,750 --> 00:09:36,667
over. And the goal is really to
get the leakage down to what an
attacker could discover through

74
00:09:36,667 --> 00:09:42,667
extensive traffic analysis of
the entire Internet. Not that
anybody actually does that. But

75
00:09:44,958 --> 00:09:51,458
the idea is if they can see
every DNS query you make and
they can see every encrypted

76
00:09:51,458 --> 00:09:57,542
packet where it flows to they
can discern certain things. They
may not be able to discern who

77
00:09:57,542 --> 00:10:02,625
you're talking to but they may
be able to discern that you sent
a message to your provider and

78
00:10:02,625 --> 00:10:08,625
that provider handed it off to
this other provider. And the
thing is we need to make it

79
00:10:13,583 --> 00:10:19,583
bulletproof. I thought I'd use
this other example from my own
case to illustrate why the

80
00:10:23,125 --> 00:10:30,542
protection of metadata is so
important. Here I am in court
saying that I would like to tell

81
00:10:30,542 --> 00:10:36,542
people that the FBI is asking
for my SSL private key and in
response to that request the

82
00:10:39,875 --> 00:10:47,000
prosecutor stands up and says,
"Well, we know he's been talking
to the EFF and to other

83
00:10:47,000 --> 00:10:53,583
attorneys who have been
associated with Wikileaks cases
in the past." Now, I was a

84
00:10:53,583 --> 00:10:59,583
little taken back by that
because, one, how did they know
that. I didn't know that. I'd

85
00:11:02,125 --> 00:11:05,917
spoken to maybe a dozen
attorneys trying to find
somebody who could represent me

86
00:11:05,917 --> 00:11:13,292
in four days that I had to find
one. But then as I thought about
it more I started wondering,

87
00:11:13,292 --> 00:11:19,875
well how do they even know that
in the first place? What
happened to attorney‑client

88
00:11:19,875 --> 00:11:25,875
privilege? How bad has it really
gotten? And it's become clear
that if they can find the

89
00:11:35,792 --> 00:11:41,792
tiniest of openings they will go
in and take everything.
Theoretical is now reality. The

90
00:11:47,167 --> 00:11:53,167
impractical has already been
deployed. Now, can anyone spot
the typo in this sentence? It's

91
00:12:02,250 --> 00:12:10,167
actually my second favorite
excerpt. In the court's haste
they forgot to substitute the

92
00:12:10,167 --> 00:12:16,500
word "Google" for the word
Lavabit. If you read that
sentence again with the word

93
00:12:16,500 --> 00:12:22,500
"Lavabit" it actually makes
sense. On the next page, though,
we see why I put this slide

94
00:12:28,917 --> 00:12:37,237
together. They were coming in
and not only do demanding the
encryption keys but the source

95
00:12:37,250 --> 00:12:45,458
code that was used to protect
the system. Think about that.
Think about what we've been

96
00:12:45,458 --> 00:12:53,458
talking about the last couple of
days with firmware exploits and
hardware exploits. And then ask

97
00:12:53,458 --> 00:13:01,098
yourself, do you really think
they're finding those exploits
based on binary dumps of Bios or

98
00:13:01,100 --> 00:13:06,660
starting with the source code. I
think I already know the answer
to that question. I actually had

99
00:13:14,125 --> 00:13:24,583
to go to court to get B, C and D
unredacted. Because I wanted to
be able to tell people that just

100
00:13:24,583 --> 00:13:33,243
communicating with somebody now
makes you a co‑conspirator. It's
enough of a justification for

101
00:13:33,250 --> 00:13:40,250
the court to issue a warrant for
your communications, they call
it hopping. Like such a friendly

102
00:13:40,250 --> 00:13:46,875
term associated with bunny
rabbits in a field would make it
any better. So if I sound a

103
00:13:46,875 --> 00:13:52,333
little bit upset, it's because I
am. I'm not upset that I got
railroaded and I had to shut

104
00:13:52,333 --> 00:13:59,500
down my business. I'm upset
because we need a mill Spec
cryptographic mail system for

105
00:13:59,500 --> 00:14:04,625
the entire planet just to be
able to talk to your friends and
family without any kind of fear

106
00:14:04,625 --> 00:14:10,625
of government surveillance.
[Applause] 

107
00:14:15,060 --> 00:14:18,458
I'm upset because
I thought we won
this war back in the

108
00:14:18,458 --> 00:14:25,667
the '90s when we earned the
right to have secure
cryptographic algorythms to

109
00:14:25,667 --> 00:14:33,625
encrypt our communications. I'm
upset that I need to take our
e‑mail which is traveled around

110
00:14:33,625 --> 00:14:40,245
the Internet unprotected for the
last 40 years and stick it in an
M182 just to feel safe. I'm

111
00:14:42,208 --> 00:14:51,000
upset because you shouldn't need
an Abrams tank for your e‑mail
just to keep anybody from

112
00:14:51,000 --> 00:14:58,917
reading it. And I'm upset
because the design for DIME
needs to be resistant to

113
00:14:58,917 --> 00:15:04,917
manipulation by a three‑letter
agency with 40,000 people and
$10 billion annual budget. Did I

114
00:15:07,458 --> 00:15:14,000
the math, their budge set a
little bit bigger than mine.
This is who you should worry

115
00:15:14,000 --> 00:15:20,000
about. These guys, too. They
have guns. Probably mention
these folks, too. And of course

116
00:15:23,458 --> 00:15:31,458
if one kid on the playground has
a toy, everybody else wants it.
So you start to understand we

117
00:15:33,667 --> 00:15:41,292
don't just need DIME, we need it
yesterday. I keep telling
Stephen that but it doesn't make

118
00:15:41,300 --> 00:15:51,200
him go any faster. So, I've
talked about what it's going to
do and before I get in to how it

119
00:15:51,208 --> 00:15:57,208
does it, I'm going to talk a
little bit about the weak spots.

120
00:15:59,080 --> 00:16:03,300
The first one is the DNS system.

121
00:16:04,667 --> 00:16:13,333
Yes, DNS SEC helps. But in the
real world it's only been
deployed on less than 1% of all

122
00:16:13,333 --> 00:16:21,167
the domain names out there. And
the simple fact is, if somebody
can hijack your domain, your DNS

123
00:16:21,167 --> 00:16:29,247
entries, they can point your
domain at whatever server they
want. Now we've built in a

124
00:16:29,250 --> 00:16:36,167
concept called the chain of
custody check. Which can be used
to ensure when you're

125
00:16:36,167 --> 00:16:45,667
communicating with somebody over
a period of time and they have
rotated their keys that the new

126
00:16:45,667 --> 00:16:52,750
key information will sign by the
previous. So if the domain does
get repointed at a new server,

127
00:16:52,750 --> 00:16:57,250
all the people who communicated
with people on that domain in
the past would get chain of

128
00:16:57,250 --> 00:17:03,500
custody warnings. But everybody
else, everybody who is hitting
it for the first time wouldn't

129
00:17:03,500 --> 00:17:12,333
know any better. The other
problem with DNS is that it's
very leaky. We still don't have

130
00:17:12,333 --> 00:17:20,493
an accepted standard for
encrypting our DNS queries which
means if somebody sitting on

131
00:17:20,500 --> 00:17:28,000
your upstream link they can see
every DNS query that you do. I
think that's interesting because

132
00:17:28,000 --> 00:17:38,240
we also rely quite heavily upon
DLS which has the OCSP protocol
built in to the latest versions.

133
00:17:38,250 --> 00:17:44,750
Which check for the revocation
of a certificate and they do it
over unencrypted channel. So

134
00:17:44,750 --> 00:17:52,917
somebody can actually sit on the
link for the OCSP server for a
certificate authority and

135
00:17:52,917 --> 00:17:59,458
actually see where particular
people are coming from when they
access that domain because that

136
00:17:59,458 --> 00:18:05,750
very same IP is going to fire
off a request to that OCSP
server. If the FBI had been a

137
00:18:05,750 --> 00:18:11,250
little bit smarter they may have
been able to discover the IP
address information that alluded

138
00:18:11,250 --> 00:18:18,970
them by doing that very same
attack. Without actually taking
my private key. If your password

139
00:18:22,917 --> 00:18:31,917
is "Password" nothing I do will
save you. Now we've designed
mechanisms in to the

140
00:18:31,917 --> 00:18:38,292
authentication scheme that will
make brute forcing more
difficult. But ultimately it

141
00:18:38,292 --> 00:18:47,972
still comes down to you. And like
the God father told me, humans
are a very poor source of entropy

142
00:18:51,720 --> 00:19:01,660
Our devices as we're
learning have a very horrid
track record when it comes to

143
00:19:01,667 --> 00:19:11,500
security, particularly consumer
devices. They stand very little
chance of defending you against

144
00:19:11,500 --> 00:19:17,500
a sophisticated and determined
attacker, particularly one with
physical access. You also have

145
00:19:21,167 --> 00:19:28,447
problems with things like poor
implementations. Even if you
have good online hygiene and

146
00:19:30,625 --> 00:19:40,542
you're using open BSD, if the
entropy provider for your random
number generator gets commented

147
00:19:40,542 --> 00:19:46,542
out your crypto won't be
secure. We can thank Devian
for that example. 

148
00:19:51,500 --> 00:19:58,540
The algorithms themselves, the thing
about cryptography you can never
prove something is secure, you can

149
00:19:58,542 --> 00:20:06,833
never prove it's insecure. So
just because we don't know of a
vulnerability doesn't mean

150
00:20:06,833 --> 00:20:13,417
somebody else does. And then of
course if you buy in to all of
the hype we've only got so many

151
00:20:13,417 --> 00:20:19,417
years before the bad guys
develop quantum computers can
break the crypto anyways the way

152
00:20:19,417 --> 00:20:25,417
I look at it we got at least 20
years for that to happen.

153
00:20:28,420 --> 00:20:32,160
 We still depend
on programmers. And

154
00:20:32,167 --> 00:20:38,125
the number of programmers who
understand how to make complex
systems work and make them work

155
00:20:38,125 --> 00:20:44,000
securely is still very, very,
very small. Seems like all the
people who know a lot about

156
00:20:44,000 --> 00:20:48,708
security like to get in to
Dev‑ops and system
administration and very few

157
00:20:48,708 --> 00:20:56,748
follow my path and Stephen's
path and end up as programmers.
We need more. People who

158
00:20:56,750 --> 00:21:05,333
understand how systems work,
understand how they're attacked.
And can build defenses directly

159
00:21:05,333 --> 00:21:13,042
in to the architecture and
design of the system. I think
it's funny that all of a sudden

160
00:21:13,042 --> 00:21:19,622
keeping your attack surface
small has become all the rage.
Been doing that for like 12 years.

161
00:21:23,740 --> 00:21:28,417
We have the problem that
everybody likes using a web
browser on the web mail system

162
00:21:28,417 --> 00:21:35,917
with client written java script.
Yeah, we can do the crypto on
your device but if we're loading

163
00:21:35,917 --> 00:21:43,417
the code to the client off of an
untrusted server kind of open
yourself up to attack. Just ask

164
00:21:43,417 --> 00:21:44,297
hush mail.

165
00:21:47,760 --> 00:21:56,080
And then we have the
problem that bull run had a $250
million budget. Annually. Do you

166
00:21:56,083 --> 00:22:05,375
think they're just going to
return that money to the
taxpayers? They're going to keep

167
00:22:05,375 --> 00:22:14,915
coming after us, I thought I'd
be fair to issue a little
warning, I think what we need to

168
00:22:14,917 --> 00:22:19,500
be afraid of is that if
everybody started using
something like DIME and ZRTP to

169
00:22:19,500 --> 00:22:25,708
communicate it wouldn't be too
long before we started seeing
vulnerabilities embedded

170
00:22:25,708 --> 00:22:33,917
directly in the silicon. As kids
we like to play a little game
called "Where's Waldo". Our kids

171
00:22:33,917 --> 00:22:40,917
might actually get to play
"Where's the clipper chip". Make
something like this look a

172
00:22:40,917 --> 00:22:48,208
little more useful. All right.
Time to climb back down off my
Soapbox and get back to talking Dime.

173
00:22:54,300 --> 00:22:58,240
I've decided that I don't
just want to create a
specification hope the world

174
00:22:58,250 --> 00:23:04,000
listens to me. I think the best
way to prove that DIME is
secure, prove that DIME

175
00:23:04,000 --> 00:23:05,980
functions is to build it. 

176
00:23:08,540 --> 00:23:18,360
I'd like to introduce Magma
and Volcano. Magma is the
server and Volcano is the client.

177
00:23:23,420 --> 00:23:25,792
>> All right. We're
going to do a quick little

178
00:23:25,792 --> 00:23:30,375
visual demonstration here
hopefully everybody is going to
be able to follow this as much

179
00:23:30,375 --> 00:23:36,625
as possible. What you're go fog
see right now is called volcano
and that's the client we've been

180
00:23:36,625 --> 00:23:44,292
working on a Thunderbird for it.
As Ladar mentioned one of the
important things about this,

181
00:23:44,292 --> 00:23:51,542
this is all usable in a ‑‑ with
a friendly experience for
everybody, it's familiar to

182
00:23:51,542 --> 00:23:57,542
them. So just to give you a
little taste of this here, start
this off here. See our little

183
00:24:00,708 --> 00:24:09,500
custom branding here. And we're
going to start off by composing
a new message so in the first

184
00:24:09,500 --> 00:24:17,333
example case here I'm going to
be sending a message and the
first recipient here is going to

185
00:24:17,333 --> 00:24:26,233
be Ladar. This isn't pausing
like it was supposed to so I'm
going to start talking a little

186
00:24:26,250 --> 00:24:33,292
bit faster. As you see there to
the right the Cigna information
for Dark Mail recipients that

187
00:24:33,292 --> 00:24:41,083
only shows off if you're sending
e‑mail to a Dark Mail protected
domain. The second case here

188
00:24:41,083 --> 00:24:48,917
we're going to send an e‑mail to
a domain that's not encrypted by
Dark Mail. This is an e‑mail I

189
00:24:48,917 --> 00:24:55,083
got from actually Keith
Alexander uses this one to send
e‑mails to one of his buddies at

190
00:24:55,083 --> 00:25:01,083
Google. I don't know if you can
read that. As you see there the
address cannot be found when you

191
00:25:01,083 --> 00:25:08,458
attempt to send it you get this
warning dialogue saying that, at
least one of the recipients is

192
00:25:08,458 --> 00:25:15,125
not protected by Dark Mail. Then
finally we're going to try to do
a mixed recipient message where

193
00:25:15,125 --> 00:25:20,583
we have one user that's
protected by Dark Mail as we saw
before, Ladar's e‑mail address

194
00:25:20,583 --> 00:25:27,750
then we're going to use that
same G‑mail address and as you
can see there once again you get

195
00:25:27,750 --> 00:25:34,583
the little warning icon, the
address Cigna cannot be found if
I attempt to fill in the body of

196
00:25:34,583 --> 00:25:41,000
the message and the subject and
send it we're going to see
another warning message popped

197
00:25:41,000 --> 00:25:48,292
up. So it's our hope that we can
badger the users and
administrators of these domains

198
00:25:48,292 --> 00:25:56,083
in to protecting themselves
properly. The last little bit of
information here we're going to

199
00:25:56,083 --> 00:26:04,042
go in to DEF CON presentation
folder here and click on an
e‑mail that has been received

200
00:26:04,042 --> 00:26:10,958
from a Dark Mail sender so
again, you see there's a
completely different graphic

201
00:26:10,958 --> 00:26:17,333
representation of how that
looks. Sorry I wasn't able to do
a live demo here today but I

202
00:26:17,333 --> 00:26:22,458
wasn't quite adventurous to
trust transmitting across a
network in this sort of

203
00:26:22,458 --> 00:26:29,500
environment seemed a little bit
suicidal. I'm in to self
deprecation don't want to

204
00:26:29,500 --> 00:26:34,708
humiliate myself in public by
everything somebody hijack my
session. I'm going to turn it

205
00:26:34,708 --> 00:26:40,708
back to Ladar for a second.
[Applause] >>

206
00:26:45,160 --> 00:26:48,080
 What Stephen
illustrated quite perfectly that

207
00:26:48,083 --> 00:26:53,208
somebody doesn't need any
specialized knowledge in order
to use DIME. All they need to

208
00:26:53,208 --> 00:26:59,750
know how to do is type in an
e‑mail address and their client
does everything else. We still

209
00:26:59,750 --> 00:27:04,542
have the one burden of education
which is don't send out that
classified document if you get

210
00:27:04,542 --> 00:27:10,500
the warning that says you're
sending it out insecurely, but I
seem to remember an old adage

211
00:27:10,500 --> 00:27:20,380
about taking horses to water and
throwing them in. How does it
work. Let's start by looking at

212
00:27:22,125 --> 00:27:27,708
the most important piece, the
cornerstone, so to speak. And
that's the DIME management

213
00:27:27,708 --> 00:27:35,583
record and the DNS system. For
those of you who are eminently
familiar with how e‑mail works,

214
00:27:35,583 --> 00:27:42,167
you'll recognize concepts that
are already out there with
sender I.D. mark, DCAM and

215
00:27:42,167 --> 00:27:47,542
sender policy framework. The
idea that you can stick some
information in the DNS system

216
00:27:47,542 --> 00:27:58,500
and it's really easy to find.
Again, DNS system is a weak
point. It's out of DNS‑SEC this

217
00:27:58,500 --> 00:28:06,200
information is less reliable.
What that long string of
characters is, is actually the

218
00:28:06,208 --> 00:28:13,750
public signing key for the
SIGNET. When you get the SIGNET
from the DMTP server for the

219
00:28:13,750 --> 00:28:20,000
organization it's actually
encrypted with the private
version of this key. So you need

220
00:28:20,000 --> 00:28:26,833
this information in order to
access the encryption key. It
forces the two‑step process that

221
00:28:26,833 --> 00:28:33,000
is at the corner stone of our
trust. That you need a primary
source and a second

222
00:28:33,000 --> 00:28:39,500
preauthenticated source for
validation verification. Now
what I'm showing you here is the

223
00:28:39,500 --> 00:28:45,500
most simplistic version of a
DIME record. All of the other
attributes are assumed. We're

224
00:28:47,542 --> 00:28:54,417
assuming that the DMTP server
can be found by looking at the
MX record. And we're assuming

225
00:28:54,417 --> 00:28:59,333
that the TLS certificate that
we'll run in to when we access
is actually signed by one of the

226
00:28:59,333 --> 00:29:05,500
recognized CAs. But if we didn't
want to do that we could set up
a much more complicated DX

227
00:29:05,500 --> 00:29:14,120
record. Highlight some of the
properties here, the attributes.
In this case we actually specify

228
00:29:14,125 --> 00:29:22,285
an alt server so that you can put
your DMTP host on a different
server than you're SMTP host.

229
00:29:24,583 --> 00:29:33,623
And perhaps you don't like using
CA. You'd much rather prefer
storing a hash of your TLS

230
00:29:33,625 --> 00:29:41,145
certificate in the DNS system so
that you can use a self‑sign
Cert. It's simplified. You know.

231
00:29:48,580 --> 00:29:54,580
I said that in the
first slide. If there is no
explicit DX specified the

232
00:29:54,583 --> 00:30:02,208
assumption is that your MX is
your DX. So if you connect to
the SMTP host it's also your

233
00:30:02,208 --> 00:30:08,750
DMTP host. I'm starting with the
most simplified use case in
trying to build in the necessary

234
00:30:08,750 --> 00:30:13,792
flexibility that the more
complicated and larger
environments can actually adapt

235
00:30:13,792 --> 00:30:22,112
during deployment. What is a
Signet? Looks like bit like
this. It's a relatively simple

236
00:30:22,125 --> 00:30:27,208
format. It has a four-byte
header that tells you the
version. Three of those bytes

237
00:30:27,208 --> 00:30:33,208
determine the length. You have
defined attributes. Still trying
to come up with exactly what

238
00:30:33,208 --> 00:30:40,120
that list of defined attributes
is going to be, we know a few of
them.Your signing key, your

239
00:30:40,125 --> 00:30:45,708
encryption key, your user
signature, your Org Signature,
your photo, name, maybe website

240
00:30:45,708 --> 00:30:51,708
address, telephone number, your
address. But we're not going to
be able to think of everything.

241
00:30:53,750 --> 00:31:00,167
So we leave open the possibility
of creating undefined
attributes. Where you actually

242
00:31:00,167 --> 00:31:09,500
provide the name of the
attribute and the value. Now,
because the overall length

243
00:31:09,500 --> 00:31:15,750
parameters is three bytes, we've
got an effective technical limit
here of 16 megabytes for a

244
00:31:15,750 --> 00:31:27,167
Signet. Please don't make your
SIG‑NET 16 megabytes. In reality
they should be far smaller. It's

245
00:31:27,167 --> 00:31:33,000
just trying to determine what to
cap at is much more difficult
proposition. I think the only

246
00:31:33,000 --> 00:31:39,000
field that we're going to allow
to be longer than 64k and many
of them we'll probably actually

247
00:31:41,250 --> 00:31:45,010
end up defining as a one byte
length would be a photo. 

248
00:31:47,180 --> 00:31:53,000
But the idea is
it must be under 16

249
00:31:53,000 --> 00:32:03,580
megabytes and I mean a real 16
megabytes not what Google thinks
is 16 megabytes. It seems that

250
00:32:03,583 --> 00:32:10,375
the IEEE recommended making
kilobyte one thousand bytes,
it's like they got paid off by

251
00:32:10,375 --> 00:32:18,575
the hard drive manufacturers and
I couldn't believe Google
actually listened. I think all

252
00:32:18,583 --> 00:32:27,375
those PhDs would be smarter.
They actually listen to the very
same bodies that gave us WEP and

253
00:32:27,375 --> 00:32:36,115
dual ECDRBG. How did that work
out? I mean if we're going to
start changing stuff why don't

254
00:32:36,125 --> 00:32:40,625
we change around the
gravitational constant for
earth, wouldn't it be a lot

255
00:32:40,625 --> 00:32:48,865
easier fit was a simple number
that ended in zero? >>[ laughter ] >>
Kind of reminds me of what

256
00:32:50,792 --> 00:32:54,833
happens when you got one team
working with the metrics system
and another one working with the

257
00:32:54,833 --> 00:33:04,153
imperial system. Just ask NASA
how many satellites that little
screw up has cost them. But this

258
00:33:04,167 --> 00:33:12,833
is your most basic SIG‑NET. The
four required properties and the
section that I like to refer to

259
00:33:12,833 --> 00:33:20,292
as the security portion. The
portion that is signed by both
the user and the organization

260
00:33:20,292 --> 00:33:30,452
and contains the encryption
information. Now, if this were a
rotated key there would be an

261
00:33:30,458 --> 00:33:39,038
additional signature here that
was created by the previous key.
That is so once you have a

262
00:33:39,042 --> 00:33:45,960
SIG‑NET in your Cache if your
client does a look up and
discovers that the key has been

263
00:33:45,960 --> 00:33:51,700
rotated it can trace the chain
of trust back to the SIG‑NET
that it actually had in its

264
00:33:51,708 --> 00:33:59,542
cache. And if there's a break,
if this parameter is missing or
invalid you know that something

265
00:33:59,542 --> 00:34:05,292
may have happened. Maybe
something innocent or innocuous
like password reset. Or

266
00:34:05,292 --> 00:34:11,292
something nefarious like a man
in the middle attack. But at
least you get warned.

267
00:34:15,708 --> 00:34:22,625
Of course I added a couple of
defined attributes, it's worth noting
that they are outside of the

268
00:34:22,625 --> 00:34:28,000
user signature which means they
are only signed by the
organization which means that

269
00:34:28,000 --> 00:34:34,333
the SIG‑NET signing request can
actually be taken by the server
and these attributes can be

270
00:34:34,333 --> 00:34:40,792
appended based on a profile or
configuration. We're still
considering whether or not we

271
00:34:40,792 --> 00:34:47,000
want to give users the ability
to submit attributes with every
request. But it's the idea that

272
00:34:47,000 --> 00:34:51,320
the organization can still have
some control over the non-
security portions of the Signet.

273
00:34:56,080 --> 00:35:01,000
Thought it would be
worth it to throw in couple of
what I'm calling undefined

274
00:35:01,000 --> 00:35:10,700
attributes. Mr. Greenwald likes
bitcoin and wants to know his
address. And because he's

275
00:35:10,708 --> 00:35:16,500
somewhat political he thought
he'd add a motto to his SIG‑NET.
The idea is we're creating a

276
00:35:16,500 --> 00:35:23,333
framework for you guys to build
upon. The most important piece
of DIME is actually this SIG‑NET

277
00:35:23,333 --> 00:35:30,333
process. Because if you can
translate a e-mail address in to
a public key what you can do

278
00:35:30,333 --> 00:35:36,708
with that is almost infinite.
Imagine a ZRTP phone call where
you don't need to do short

279
00:35:36,708 --> 00:35:42,708
authentication string to know
there's no man in the middle
attack but you can actually have

280
00:35:42,708 --> 00:35:50,000
the handshake signed by the
signing key that you then verify
through this DIME look‑up

281
00:35:50,000 --> 00:35:52,000
process.

282
00:35:56,180 --> 00:35:57,440
Trust.

283
00:36:00,220 --> 00:36:07,333
It's earned not given.
But I thought it was
important to illustrate how it

284
00:36:07,333 --> 00:36:16,733
works. Now this is the most
simplistic trust model and it
only applies if DNSSEC is in

285
00:36:16,750 --> 00:36:24,333
play. There are at models I
don't have time to get in to but
if you recall the cardinal rule

286
00:36:24,333 --> 00:36:29,500
is, you need a primary source
and then a second
preauthenticated source for

287
00:36:29,500 --> 00:36:35,833
verification and validation.
DNS‑Sec is preauthenticated. The
TLV root keys shift with your

288
00:36:35,833 --> 00:36:45,873
resolver. Preauthenticated. And
what it means is that if an
attacker wants to give you

289
00:36:45,875 --> 00:36:51,875
spoofed or false information,
fake data they actually need to
compromise one of the keys in

290
00:36:51,875 --> 00:36:58,215
this chain in order to do it.
They can't just make up an
entire at Internet and stick you.

291
00:37:02,000 --> 00:37:10,292
Thought it would be worth
talking about who controls these
keys. Because at a certain point

292
00:37:10,292 --> 00:37:16,833
you realize that even with
DNS‑SEC you have to trust your
registrar to publish the correct

293
00:37:16,833 --> 00:37:25,613
DS record. And then you have to
trust the top level domain to
protect its root signing key,

294
00:37:25,625 --> 00:37:33,042
otherwise the entire system of
trust breaks down. Like I said,
DNS is still somewhat of a weak

295
00:37:33,042 --> 00:37:39,750
point. DNS‑SEC makes it that
much better. We have mechanisms
that I'm not going to be able to

296
00:37:39,750 --> 00:37:46,667
get in to today that were built
specifically because of this
problem. Things that

297
00:37:46,667 --> 00:37:54,458
particularly security sensitive
domains can actually implement
optionally that clients can then

298
00:37:54,458 --> 00:37:59,583
check for additional
verification of information that
is coming out of the DNS system.

299
00:38:05,250 --> 00:38:14,370
My motto. I figure if I need
someone to trust it will be a
dog.

300
00:38:17,120 --> 00:38:20,560
I'd like to introduce Princess,
the project mascot.

301
00:38:22,880 --> 00:38:28,880
 >> Alright, The second
part of the demo here, I
guess my big person's mic is

302
00:38:28,880 --> 00:38:35,160
malfunctioning just a little
disclaimer I was mentioning
before this seems like the video

303
00:38:35,167 --> 00:38:42,000
is unpausable luckily Ladar
slowed it down to 70% last night
but I want to try to keep pace,

304
00:38:42,000 --> 00:38:46,333
I will pause a little bit longer
in between the different
components here. What I'm going

305
00:38:46,333 --> 00:38:53,917
to show you right now is the
differentiation between Modes
for DMTP and SMTP from a client

306
00:38:53,917 --> 00:39:02,997
perspective and you're about to
see the magma server being run,
and some simulated SMPT and Dark

307
00:39:03,000 --> 00:39:05,920
Mail sessions or at least the
beginning of them. 

308
00:39:13,560 --> 00:39:18,080
Nope not working for him
either. All right. This
is the output of Magma

309
00:39:18,083 --> 00:39:26,292
being run there you can see the
dependencies scroll by. We're
telnetting the host Port 25,

310
00:39:26,292 --> 00:39:32,750
you can see the banner there,
ESTP and DMTP1 issued a mode
command showing that both of

311
00:39:32,750 --> 00:39:38,333
them are currently available.
Now with traditional E‑hello
command and we're going to issue

312
00:39:38,333 --> 00:39:47,613
a traditional mail‑from command.
And you see that receive the
success, that way we issue the

313
00:39:47,625 --> 00:39:54,417
mode command it says ESMTP now
try to issue Dark Mail, the
SIG-NEt command, and we're going

314
00:39:54,417 --> 00:40:01,375
to see the SIG‑NET is disabled.
And that is because we fell in
to ESMTP mode with the mail‑from

315
00:40:01,375 --> 00:40:08,375
command from RFC822 sal email.
We're connecting again, we tried
issuing the Dark Mail SIG‑NET

316
00:40:08,375 --> 00:40:15,125
command we that requires start
TLS first. Now you don't have to
worry it's going to scroll by

317
00:40:15,125 --> 00:40:23,292
the python code. Long story
short we use this to start TLS
so this shows the command being

318
00:40:23,292 --> 00:40:29,458
executed and reply we're doing
start TLS, we got the
certificate, we execute a mode

319
00:40:29,458 --> 00:40:35,458
command and now we're DMTP V-1
now we try an E‑ hello. We issue
a SIG‑NET command we get the

320
00:40:38,542 --> 00:40:44,583
successful response, now we try
issuing that old school
mail‑from with the RFC822 style

321
00:40:44,583 --> 00:40:51,708
e-mail address, we get error,
now dark style mail from the
specifies a fingerprint only

322
00:40:51,708 --> 00:40:57,333
domain and it's successful.
We're going to tweak something
here in the config file we're

323
00:40:57,333 --> 00:41:02,708
going to search for the dual
mode parameter we're going to
set it to false so that is going

324
00:41:02,708 --> 00:41:08,542
to basically cause it to revert
from dual mode into Dark Mail
mode only. And now we're going

325
00:41:08,542 --> 00:41:16,167
to kill the magma daemon and
start it over. Go back to our
session here. Telnetting back in.

326
00:41:20,500 --> 00:41:26,958
And now if we try to do that
same innocuous E‑hello command
it tells us that it requires

327
00:41:26,958 --> 00:41:33,333
start TLS first. As opposed to
saying, okay, then allowing the
mail from command to determine

328
00:41:33,333 --> 00:41:39,333
which of the servers it's going
to fall in to.

329
00:41:41,900 --> 00:41:46,720
 All right. This next
bit here is going to illustrate

330
00:41:46,720 --> 00:41:55,333
the cypher sweet that magma
uses. So we're going to
see here the dedicated SSL port

331
00:41:55,333 --> 00:42:03,413
for DMTP is 31301 we're going to
launch server again, go to run
SSL scan against it. You see

332
00:42:03,417 --> 00:42:11,208
whole bunch of crap scroll by in
server log because the scans,
now we're going to scroll up

333
00:42:11,208 --> 00:42:18,500
going to see all these failed
cybernegotiation attempts. A lot
of them. We're going to get the

334
00:42:18,500 --> 00:42:21,720
end of them there's going to be
only one of them accepted.

335
00:42:26,580 --> 00:42:29,460
You see the EC
depihelman exchange

336
00:42:29,460 --> 00:42:39,080
RSAES256 shot 384, which is the
mandatory cypher sweet that
we've opted for for Dark Mail

337
00:42:39,080 --> 00:42:45,080
for DMTP and Dmap insuring both
perfect for secrecy and
mandating that the connection we

338
00:42:45,083 --> 00:42:51,083
established was over TLS version
1.2. Back to Ladar for a second.
[ Applause ] >> 

339
00:42:58,260 --> 00:43:03,417
We're not able to achieve perfect
forward secrecy or messaging because
it's contrary to what people

340
00:43:03,417 --> 00:43:09,208
want which is persistent access
for a long period of time to all
of your historical messages. But

341
00:43:09,208 --> 00:43:16,068
by requiring TLS1.2 and
cyphersweet to provide for PFS
we get it at the wire level.

342
00:43:20,680 --> 00:43:28,417
I don't know if anybody can read
this. But this is how we break
up sample message. We've got

343
00:43:28,417 --> 00:43:39,077
the ‑‑ I just realized that this
diagram is wrong. The tracing,
the first box with the the top

344
00:43:39,083 --> 00:43:44,667
is actually only data that is
actually unencrypted. And can
actually be stripped off with

345
00:43:44,667 --> 00:43:54,292
each successive hop. In theory,
a DMTP Spec conforming server
wouldn't put any sensitive

346
00:43:54,292 --> 00:44:01,125
information in that area. But if
you happen to be a little more
on the paranoid side you just

347
00:44:01,125 --> 00:44:08,250
strip it off when it arrives.
The next two boxes are the ones
I want to you pay the most

348
00:44:08,250 --> 00:44:15,542
attention to. The origin and
destination boxes. They're the
envelope. They contain the

349
00:44:15,542 --> 00:44:22,917
information that historically
and traditionally been part of
the SMTP conversation. And what

350
00:44:22,917 --> 00:44:30,417
you'll see based on the letters
that indicate who can access
that information you'll see that

351
00:44:32,333 --> 00:44:39,667
we have somewhat of a
pseudo‑onion. The origin can see
who sent the message and the

352
00:44:39,667 --> 00:44:47,167
destination domain, but it can't
see the destination mailbox. The
destination server can see what

353
00:44:47,167 --> 00:44:54,333
the origin domain was and who
the recipient is but can't see
who the actual sender is. So we

354
00:44:54,333 --> 00:45:02,292
achieve a level of data
protection at the organizational
level. Like I said, you can

355
00:45:02,292 --> 00:45:08,458
discover that information if you
had enough resources and were
doing traffic analysis because

356
00:45:08,458 --> 00:45:17,658
you could just follow the flow
of packets. Now we also break up
the traditional headers in to

357
00:45:17,667 --> 00:45:23,417
two separate blocks. That are
separately encrypted so that a
resource constrained client can

358
00:45:23,417 --> 00:45:31,957
download the most commonly used
headers without downloading the
rest. We separate out the

359
00:45:31,958 --> 00:45:36,458
display portion of the message
then of course each individual
attachment so that they can also

360
00:45:36,458 --> 00:45:44,258
be downloaded and verified
independently. I don't have time
to get in to all of the details,

361
00:45:45,250 --> 00:45:53,042
but suffice it to say it's kind
of a new concept. And it's what
we need in order to have an

362
00:45:53,042 --> 00:45:59,792
encrypted e‑mail message that
will function under the very
same conditions that we use

363
00:45:59,792 --> 00:46:08,332
e‑mail today. In web browsers,
on phones, on desktop clients,
even occasionally via telenet

364
00:46:08,333 --> 00:46:16,792
and pine. And protect the
metadata we use some what of a
pseudo‑onion. There's only

365
00:46:16,792 --> 00:46:24,992
illustrates what I was just
saying. Who can see what, it's
not perfect. But it's a big step

366
00:46:25,000 --> 00:46:32,958
in the right direction and the
hope is that once we get this
system working we can start

367
00:46:32,958 --> 00:46:38,917
building extensions to it that
will allow you to upgrade your
communications with specific

368
00:46:38,917 --> 00:46:44,125
recipients, that may even allow
you to you send a message
directly peer to peer through

369
00:46:44,125 --> 00:46:51,000
something like a TOR circuit.
If you happen to need that kind
of security. It's about

370
00:46:51,000 --> 00:46:55,500
understanding what your threat
model is, there's a lot I
haven't been able to talk about

371
00:46:55,500 --> 00:47:02,250
today, like the client modes or
any of the access protocol stuff
or the different deployment

372
00:47:02,250 --> 00:47:11,083
scenarios. Typically it takes me
about three days to brief
somebody. But I hope you start

373
00:47:11,083 --> 00:47:17,083
to understand how the system
works because I need your
feedback. If I'm going to be

374
00:47:18,720 --> 00:47:26,040
doing something wrong I'd rather
you guys find it and tell me
than somebody else find it and

375
00:47:26,042 --> 00:47:33,942
exploit it for year's before
anybody knows about it. Do we
have time for this?

376
00:47:39,042 --> 00:47:44,167
>> This is the only slide I designed in the
presentation. Somebody posted it
to my Facebook wall the other

377
00:47:44,167 --> 00:47:50,500
day, I was pretty impulsive,
this needs to go in my talk
immediately. So we're pretty low

378
00:47:50,500 --> 00:47:57,458
on time I'm going to cut this
short just going to give you
sort of vague idea of what magma

379
00:47:57,458 --> 00:48:03,750
the client and server suite will
look like. So first thing to
know is that Ladar actually

380
00:48:03,750 --> 00:48:10,167
worked on the server for over
ten years. He pretty much wrote
everything from scratch in C and

381
00:48:10,167 --> 00:48:15,750
this was a code that was
deployed live on Lavabit.com.
Everything as I said written in

382
00:48:15,750 --> 00:48:21,167
C. It's one
massively multi-threaded
process for anybody out there

383
00:48:21,167 --> 00:48:25,800
that is irritated with large
installers and packages and tons
of dependencies you might be

384
00:48:25,800 --> 00:48:32,417
thrilled to now there basically
three files ‑‑ there's
executable, there's a one

385
00:48:32,417 --> 00:48:37,583
massive library that all
dependency libraries get linked
in together you have config

386
00:48:37,583 --> 00:48:43,542
file. Technically at the very
base that's all you need to run
magma all running in one process

387
00:48:43,542 --> 00:48:46,917
space you have all these
different servers that might
typically be different

388
00:48:46,917 --> 00:48:56,397
executables or different
packages so you have IMAP, SMTP,
pop 3 now DMTP and DMAP and

389
00:48:56,400 --> 00:49:01,417
integrated web server no matter
which part of this
infrastructure you choose to

390
00:49:01,417 --> 00:49:11,197
deploy that is all you need
including free web mail clients.
We have our thin client in java

391
00:49:11,208 --> 00:49:14,833
script and our thick client,
which I demonstrated to you
earlier which is a Thunderbird

392
00:49:14,833 --> 00:49:20,375
fork, the thick client is one
that works directing our
immediate attention to and our

393
00:49:20,375 --> 00:49:26,625
resources to it's not only our
top priority as developers but
also what we recommend that

394
00:49:26,625 --> 00:49:33,083
people use for security
purposes. The java script client
is really just something for

395
00:49:33,083 --> 00:49:40,083
laziness or convenience. As far
as how the java script client
works, the web server that we

396
00:49:40,083 --> 00:49:45,792
have integrated it actually
interfaces directly with the
message store so unlike Squirrel

397
00:49:45,792 --> 00:49:49,958
mail where you have the
dependency on the scripting
platform that in and of itself

398
00:49:49,958 --> 00:49:57,000
might have 0-Day vulnerabilities
in it, you don't have to go
through that intermediary step,

399
00:49:57,000 --> 00:50:03,417
everything is merged together in
to one coherent whole. I'm going
to turn it back to Ladar for the

400
00:50:03,417 --> 00:50:08,250
conclusion. >> For the record I
was always worried about running
Clam AV in the same process

401
00:50:08,250 --> 00:50:13,458
particularly when they
integrated the LLVM compiler
decided shipping executable code

402
00:50:13,458 --> 00:50:20,375
with the virus signatures, I had
to disable that feature,
developers didn't agree with me.

403
00:50:20,375 --> 00:50:27,750
We're almost out of time. So I
thought I'd just give out some
attributes ‑‑ whatever. To the

404
00:50:27,750 --> 00:50:34,083
people who created couple of the
photos. Particularly I'd like to
call out Dave Crocker, he was

405
00:50:34,083 --> 00:50:39,042
one of those people that
invented the Internet. Although
the way he tells the story he

406
00:50:39,042 --> 00:50:43,542
couldn't have done it without
his brother Steve making coffee
in the other room. He's been

407
00:50:43,542 --> 00:50:51,083
incredibly helpful translating
my micro‑ideas in to a macro
concept. And ensuring that we

408
00:50:51,083 --> 00:50:57,750
get the nomenclature right. I'd
love to hang out answer
questions but they are about to

409
00:50:57,750 --> 00:51:02,375
kick me off stage I see we have
couple of people up there do I
have time to take couple of

410
00:51:02,375 --> 00:51:08,750
questions? Okay. We'll try and
go through them quickly. >> Is
there any provision for

411
00:51:08,750 --> 00:51:17,000
tunneling existing SMTP mail
through the system? >> It
operates at a domain level,

412
00:51:17,000 --> 00:51:23,458
either domain support stark mail
or it doesn't and if it doesn't
support Dark Mail and you have

413
00:51:23,458 --> 00:51:30,250
dual protocol mode enabled, it's
non‑dark domain can still
connect to your SMTP server and

414
00:51:30,250 --> 00:51:36,250
send a message. When it arrives
the volcano client just indicate
that it arrived insecurely.

415
00:51:39,667 --> 00:51:45,208
>> I don't actually have any
questions but I wanted to
express my gratitude to you and

416
00:51:45,208 --> 00:51:51,208
your team it was ‑‑ [Applause]
>> The way I look at it is I
just did what I expect anybody

417
00:51:58,208 --> 00:52:04,417
else in this room to do in the
same situation. >> It was pretty
gut wrenching to watch what

418
00:52:04,417 --> 00:52:09,667
happened to the company I just
wanted to thank you and your
team continuing to offer

419
00:52:09,667 --> 00:52:14,833
products and services to the
customers. >> I think it's funny
you said that we're not offering

420
00:52:14,833 --> 00:52:19,500
any products or services right
now. >> You're continuing to
expand. >> We raised couple

421
00:52:19,500 --> 00:52:24,542
hundred thousand dollars which
is what we're using to fund the
development of the Dark Mail

422
00:52:24,542 --> 00:52:30,333
project and reference
implementation but we need
programmers because we basically

423
00:52:30,333 --> 00:52:36,958
decided to take a year off from
seeking out personal gain and
earning a living to build this

424
00:52:36,958 --> 00:52:42,292
and make this happen. And we
need more people to help us
because there's a lot of code we

425
00:52:42,292 --> 00:52:47,083
yet to write, we've only been
working on the Dark Mail pieces
for about four weeks. So if

426
00:52:47,083 --> 00:52:51,292
anybody is interested in moving
to Dallas and earning a
subsistence wage while working

427
00:52:51,292 --> 00:52:58,458
on a piece of code to change
the world, come talk to us. >>
Hi, I have relatively uninformed

428
00:52:58,458 --> 00:53:05,542
question about spam, Dark Mail,
PGP, that kind of thing. Once
everyone is using encryption

429
00:53:05,542 --> 00:53:10,167
spam is expensive to send. But
while we're getting there all
these key servers have e‑mails

430
00:53:10,167 --> 00:53:16,417
with real names, see if an
e‑mail is active and find out
their name that kind of thing.

431
00:53:16,417 --> 00:53:21,750
>> There's two parts to that
question. The first thing you
need to understand is that when

432
00:53:21,750 --> 00:53:27,833
everything is encrypted
reputation actually becomes a
much more viable tool for

433
00:53:27,833 --> 00:53:33,875
blocking abuse. Because you know
the messages actually came from
that domain. The second half

434
00:53:33,875 --> 00:53:39,083
that have equation is
understanding that just because
that kind of abuse prevention

435
00:53:39,083 --> 00:53:44,708
can't happen on the server
doesn't mean it can't still
happen in the client. Really

436
00:53:44,708 --> 00:53:48,917
just about every piece of
functionality that we think
can't happen in a Dark Mail

437
00:53:48,917 --> 00:53:54,917
world is because we're thinking
of it as something that has to
happen on the server when in

438
00:53:54,917 --> 00:54:00,875
reality it could just be moved
out to the client. Google could
still scan your messages for key

439
00:54:00,875 --> 00:54:04,792
words if you just have to do
them in java script in your
client after they have been

440
00:54:04,792 --> 00:54:12,167
decrypted. >> I think you
misunderstood the question. >>
I've got just general kudos and

441
00:54:12,167 --> 00:54:17,292
questions. I really appreciate
when you are forced to turn over
your key and you literally took

442
00:54:17,292 --> 00:54:24,625
pen to paper and handing that
over I think was artful
expression. >> We're calling it

443
00:54:24,625 --> 00:54:31,333
information. Information and
paper should have been fine.
Right? >> Incredibly reasonable.

444
00:54:31,333 --> 00:54:35,750
>> And it was to buy me time I
figured while they were busy
transcribing it all into the

445
00:54:35,750 --> 00:54:40,583
computer I could be busy
shutting down my systems, making
sure they didn't show up and

446
00:54:40,583 --> 00:54:45,375
confiscate everything. Everybody
forgets I actually thought I was
going to get arrested they were

447
00:54:45,375 --> 00:54:53,595
going to confiscate all of my
servers. I think ‑‑ >> Go ahead.
>> Question around sort of the

448
00:54:53,600 --> 00:54:59,520
connection between keys and the
different user SIG‑NETs had
like ‑‑ TLV value custody that

449
00:54:59,520 --> 00:55:02,500
you could use to sign like a
future SIGNET but with people
that don't communicate

450
00:55:02,500 --> 00:55:07,167
frequently, a client that's not
frequent looking up the user's
SIGNET >> You can actually

451
00:55:07,167 --> 00:55:12,667
connect ‑‑ I'm cutting you off
because we're out of time. You
can actually connect to the DMTP

452
00:55:12,667 --> 00:55:17,333
server and you wouldn't be able
to pull the full SIG‑NET with
all of the additional attributes

453
00:55:17,333 --> 00:55:24,125
but be able to pull history of a
security that have portion see
the chain of those security

454
00:55:24,125 --> 00:55:30,125
portions of SIG‑NET over time
and link it between the one that
you had in the cache the one

455
00:55:30,125 --> 00:55:38,458
that you discovered. The way to
think about it is to think about
same way about DNS. You have a

456
00:55:38,458 --> 00:55:43,000
domain name that you need to
translate in to an I.P. address
and you have resolver that goes

457
00:55:43,000 --> 00:55:49,000
out and does that process for
you. Well in the Dark Mail world
we're going to have a SIG‑NET

458
00:55:49,000 --> 00:55:54,708
resolver that will go out do
that resolution for you and
translate that address in to a

459
00:55:54,708 --> 00:56:00,792
SIG‑NET. And it will apply those
chain of custody checks for you
and tell you ‑‑ tell the client

460
00:56:00,792 --> 00:56:07,250
if it needs to show warning to
the user. >> Thank you. >> I'll
be around for the next couple of

461
00:56:07,250 --> 00:56:12,458
days for those who didn't get
chance to ask me questions. Just
flag me down and talk to me. [

462
00:56:12,458 --> 00:56:15,250
Applause ] "This text is being
provided in a rough draft
format.  Communication Access

463
00:56:15,250 --> 00:56:18,042
Realtime Translation (CART) is
provided in order to facilitate
communication accessibility and

464
00:56:18,042 --> 00:56:20,333
may not be a totally verbatim
record of the proceedings." 

