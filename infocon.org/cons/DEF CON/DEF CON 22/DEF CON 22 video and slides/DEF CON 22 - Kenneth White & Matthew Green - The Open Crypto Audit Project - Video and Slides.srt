1
00:00:00,000 --> 00:00:07,417
All right, well, I think we'll
hear another somewhat technical
talk about the Open True Crypt

2
00:00:07,417 --> 00:00:12,792
or rathe The Open Crypto Audit
Project. You guys have already
seen if you use true crypt at

3
00:00:12,792 --> 00:00:20,625
all that there has been a little
bit of a change with that
project and now it's something I

4
00:00:20,625 --> 00:00:25,583
think we're all interested in,
whether you are using it to do
holistic, protect your own data

5
00:00:25,583 --> 00:00:31,667
or if you do things like me and
do forensics and need to
transfer data and need a secure,

6
00:00:31,667 --> 00:00:37,458
trusted way and easy way to get
muggles to understand how to use
crypto. Crypto usually served

7
00:00:37,458 --> 00:00:44,208
that purpose for me so this is a
pretty important project and
well we only have half of the

8
00:00:44,208 --> 00:00:49,125
original slated speaking team. I
think Mr. White will do a great
job for us, so let's give him a

9
00:00:49,125 --> 00:00:55,125
big party track welcome!
(Applause) 	>> Go Hello, DEF
CON. I want to send regrets for

10
00:00:58,333 --> 00:01:04,458
Matt, we thought up until about
a week ago that he was going to
be able to come. Unfortunately

11
00:01:04,458 --> 00:01:06,458
he wasn't able so it's me.
Hopefully we'll have a good
lively discussion. I have quite

12
00:01:06,458 --> 00:01:13,292
a bit of material and also
really great swag for questions
at the end. The idea is I want

13
00:01:13,292 --> 00:01:20,500
to tell a little bit about the
history of what we've done, how
we got here and kind of the

14
00:01:20,500 --> 00:01:25,167
community aspect. There is a
technical element here. I'm a
security engineer, not

15
00:01:25,167 --> 00:01:30,875
cryptographer so we'll do a
reasonably deep dive into some
of the technical material but

16
00:01:30,875 --> 00:01:37,250
I'll be the first to raise my
hand if I'm cheated by my weight
class here so here is what I'd

17
00:01:37,250 --> 00:01:43,250
like to do. Sort of go over some
basics for security engineering.
This may be old hat for people

18
00:01:45,917 --> 00:01:51,917
in the room but sometimes I
think people go through this
cycle in their career where

19
00:01:54,083 --> 00:02:02,000
their foundation for ideas and
sort of guiding ways to think
about things that are kind of

20
00:02:02,000 --> 00:02:08,833
memorized but not really
applied, takes a while before we
start to see the elegance in I

21
00:02:08,833 --> 00:02:15,333
guess simple ideas. I want to
talk a little bit about
revelations, specifically around

22
00:02:15,333 --> 00:02:19,500
crypto and how that impacts and
then obviously what people are
here is for true crypt story

23
00:02:19,500 --> 00:02:25,833
because you can't make this
stuff up and then a little bit
about our project and people

24
00:02:25,833 --> 00:02:33,583
that are behind that. 	Then as
we go. So just couple things
about me and Matt. I have been

25
00:02:33,583 --> 00:02:38,250
around the scene for a while but
I haven't done tons of
presenting. My first DEF CON was

26
00:02:38,250 --> 00:02:44,250
about ten years ago. I have a
weird background, I just confuse
recruiters in HR departments and

27
00:02:48,708 --> 00:02:54,708
so a lot of training in signal
analysis, lot of work in brain
and biomedical imaging and sort

28
00:02:57,458 --> 00:03:05,042
of distributed systems. I spent
a fair amount of time working on
cardiac safety, ECG analysis and

29
00:03:05,042 --> 00:03:10,167
in that world, people think a
lot about secure systems, right?
When you are evaluating

30
00:03:10,167 --> 00:03:17,167
medication to see if there is
tiny microdifferences in heart
wave rhythms, the kind of

31
00:03:17,167 --> 00:03:23,458
principles one applies to
software assurance is a really
different class. Have done a

32
00:03:23,458 --> 00:03:27,583
fair about of software
assurance. More recently I've
been working on public cloud

33
00:03:27,583 --> 00:03:33,583
security so location systems for
Amazon and Google Compute. Most
recently with the OCAP project,

34
00:03:35,917 --> 00:03:42,708
we're working with the Linux
Foundation core infrastructure
initiative. We'll talk about

35
00:03:42,708 --> 00:03:49,667
that and then on the private
side I have some disclosures in
terms of NGOs, so doctors

36
00:03:49,667 --> 00:03:55,667
without borders, couple of other
familiar ones and I'm doing some
work with them. 	So, yes, I like

37
00:03:58,792 --> 00:04:04,792
to work on strange signal
problems like ECG and direct
safety. Little bit about Matt.

38
00:04:06,875 --> 00:04:12,333
Most people know him here by
reputation but for the record
his background, research

39
00:04:12,333 --> 00:04:18,333
interests, not his Dachshunds
but he has pictures of his
Dachshunds. He does not have

40
00:04:22,000 --> 00:04:28,000
pictures on the website. 	These
are my two hounds, I was telling
Jack Daniel I think I was

41
00:04:30,625 --> 00:04:36,625
channeling him. Just to give you
a little perspective on getting
here, I think that yeah, so

42
00:04:39,667 --> 00:04:46,375
Wednesday drove across country
in the wagon with two dogs.
	>> Would have! 	(Laughter)

43
00:04:46,375 --> 00:04:53,167
	>> Landed, unpacked, kissed
everybody good-bye and hopped on
the plane. So it's been a good

44
00:04:53,167 --> 00:05:00,208
journey. This is the spirit of
what I want to frame things. I
think we have a lot to learn

45
00:05:00,208 --> 00:05:06,208
from lots of different levels of
technical background and this
quote from Jack I thought was

46
00:05:11,625 --> 00:05:18,458
really apropos. 	So if you have
seen these I think they are
called 10 rules of security

47
00:05:18,458 --> 00:05:24,125
engineering. Scott Culp has a
great quote and I want to
emphasize this a little bit,

48
00:05:24,125 --> 00:05:31,500
too, because we can get so
caught up I think sometimes in
mechanics of these projects that

49
00:05:31,500 --> 00:05:37,500
we have to keep things in
perspective. I added a slightly
minor addition to that which is

50
00:05:40,750 --> 00:05:46,750
"Even with this crypto, we have
got to keep an eye out." These
are classics I think people

51
00:05:49,125 --> 00:05:56,000
generally know these but people
that may not be familiar with
security engineering. 	So this

52
00:05:56,000 --> 00:06:02,000
particular one is more I guess
for an Archeological statement,
I think there's no one in this

53
00:06:04,625 --> 00:06:10,083
room that is all aware of these
but if this deck turns up
sometimes with the future, we'll

54
00:06:10,083 --> 00:06:16,583
have more context of what we're
doing. But crucially around the
mass surveillance. What drew a

55
00:06:16,583 --> 00:06:22,583
lot of attention in the academic
crypto world were the
revelations around bull run and

56
00:06:24,750 --> 00:06:30,750
intentionally subverting the
processes and committees around
our critical security systems.

57
00:06:34,917 --> 00:06:40,917
EFF has a fantastic timeline so
those are the entire spectrum.
	So besides the sort of

58
00:06:49,375 --> 00:06:56,250
sociological and political
pieces, I think a lot of people
kind of woke up when this came

59
00:06:56,250 --> 00:07:00,833
out and said we're actually
going to be this entire body in
existing of cryptographic work.

60
00:07:00,833 --> 00:07:06,833
This was late fall of last year.
Presence of committees implied
that you know these were serious

61
00:07:09,625 --> 00:07:15,625
issues and then eventually with
the deterministic, random
regenerator, one of the official

62
00:07:18,542 --> 00:07:25,125
standards was just pulled so
which brings us to TrueCrypt, so
I think people generally know

63
00:07:25,125 --> 00:07:31,583
but it's a piece of software for
file volume and full disc or
whole disc encryption. Sorry.

64
00:07:31,583 --> 00:07:37,667
It's been downloaded about 30
million times, been around for
about ten years. In the open

65
00:07:37,667 --> 00:07:43,667
world, there is -- it's
literally listed as Fedora and,
Debian, umm, license archives as

66
00:07:46,500 --> 00:07:50,500
forbidden items, you have to go
out of your way to include it
and we'll talk about that in a

67
00:07:50,500 --> 00:07:56,500
second. 	But it's you know it's
a really popular tool. It's used
by quite a lot of people. Not

68
00:07:59,042 --> 00:08:05,042
just human rights workers and
activists but corporations, too.
This is a snapshot from this

69
00:08:07,333 --> 00:08:12,333
morning, so if you want to get
bulk data in and out of Amazon
Web Services this is what they

70
00:08:12,333 --> 00:08:18,333
officially support. So this
stuff is out there. The problem
is looking at trusted systems

71
00:08:23,625 --> 00:08:29,625
and sort of the history of
things we realize late last
summer, maybe this wasn't news

72
00:08:33,208 --> 00:08:38,000
to some people but for many it
was, the TrueCrypt network may
have been audited, you see a lot

73
00:08:38,000 --> 00:08:45,833
of things with tech press,
statements about maybe this is
about compliant or maybe someone

74
00:08:45,833 --> 00:08:51,833
adopted it for a PCI thing or
whatever, but if you cut through
all that, it turns out at least

75
00:08:54,542 --> 00:09:00,125
through last fall there had
never been a form of
cryptanalysis on TrueCrypt, so

76
00:09:00,125 --> 00:09:06,125
people are relying on it in some
cases it was basically activists
putting ... there were huge

77
00:09:09,292 --> 00:09:15,292
stakes riding on this. 	There
were issues around the different
versions of whether we got with

78
00:09:17,750 --> 00:09:23,125
the binary or the source, volume
set of differences in the
different platforms, originally

79
00:09:23,125 --> 00:09:29,125
by the way Windows project and
it was eventually imported to
Mac and Linux. 	Bruce and

80
00:09:31,292 --> 00:09:38,875
Colleen a few years ago did a
formal cryptanalysis on the
deniability aspects so there's

81
00:09:38,875 --> 00:09:44,875
an idea one can create a hidden
volume and then within that or
adjacent to that you could also

82
00:09:46,958 --> 00:09:52,458
have a volume that is known so
you give up your keys or
password and the idea is that

83
00:09:52,458 --> 00:09:58,458
you can still have secure
information and plausible
deniability. It's not a great

84
00:10:00,958 --> 00:10:06,833
 umm ... the implementation was
not that strong. 	Around the
time it was kicked off, just a

85
00:10:06,833 --> 00:10:12,833
few weeks after the project
began, Xavier did an amazing job
through his blog and look at the

86
00:10:15,750 --> 00:10:23,625
process in some cases seven and
7 or 8-year-old RSA headers and
fairly obscured dependencies

87
00:10:23,625 --> 00:10:29,625
without which you just cannot
compile this code on Windows.
The last license reviews from

88
00:10:32,292 --> 00:10:37,708
2008 that attorneys from Red Hat
and fedora and OpenSource
groups... would have said

89
00:10:37,708 --> 00:10:43,708
language in this license is so
unconventional we can't have
any -- we can't make any

90
00:10:45,708 --> 00:10:51,708
assurances about litigation and
just said it's not a free
license. 	So there are some

91
00:10:54,583 --> 00:10:56,583
really, really strong elements
of this. This is from what's it
called (inaudible) Jeremy's and

92
00:10:56,583 --> 00:11:02,583
(inaudible) company that does
these monster cracking systems.
This is 8 Radeon 290X's, so the

93
00:11:05,917 --> 00:11:11,917
numbers on the right are hashes
per second so straight, you
know, UNIX, descrypt, 952

94
00:11:14,750 --> 00:11:20,750
million per second, TrueCrypt
with this particular chain
together, 17,000. So if the as

95
00:11:38,750 --> 00:11:44,958
word is strong, at least by
cursory measures, you know,
that's pretty interesting that

96
00:11:44,958 --> 00:11:52,875
the contenders is OSX, by the
way, that's as I understand it
actually adjusted on a

97
00:11:52,875 --> 00:11:59,542
permissioning basis or
calibrated to your CPU. So it's
at least from people who have

98
00:11:59,542 --> 00:12:06,125
looked at this initially there's
not... there doesn't seem to be
obvious bypasses for this in

99
00:12:06,125 --> 00:12:12,750
terms of raw brute force. 	One
other thing that is interesting
about this is the development

100
00:12:12,750 --> 00:12:19,875
team. If you just go on
Wikipedia there's a ton of
information out there, right. So

101
00:12:19,875 --> 00:12:26,708
what we know is some of the
original developers were
interviewed, these things are on

102
00:12:26,708 --> 00:12:32,708
multiple gethub repositories.
There are trademark filings, and
in the UK, France, China, Czech

103
00:12:35,708 --> 00:12:43,375
Republic, U.S., and it was set
up to be an entity about a year
and a half, maybe a year after

104
00:12:43,375 --> 00:12:50,333
the project kicked off. It was a
piece of software called
encryption for the masses and

105
00:12:50,333 --> 00:12:56,333
you could do a whole talk on
that. But only to say that there
was some controversy around how

106
00:12:58,625 --> 00:13:05,042
clean the code was and why it
was included and there was very
early on some sort of fairly

107
00:13:05,042 --> 00:13:12,458
serious threats of litigation
against the TrueCrypt
developers. I think that in

108
00:13:12,458 --> 00:13:19,292
combination with what was very
common at the time which was
sharing and download sites would

109
00:13:19,292 --> 00:13:25,792
sort of highlight that this is
TrueCrypt or whatever the
package was, and then maybe

110
00:13:25,792 --> 00:13:32,083
there's bundles or other things.
In a way, there is almost like a
brand dilution. Like people

111
00:13:32,083 --> 00:13:38,125
weren't really clear what the
official sources of the code. To
be fair, for the first year and

112
00:13:38,125 --> 00:13:44,125
a half, it had sort of a you
know had sort of a quirky
source. This was created, a

113
00:13:48,750 --> 00:13:53,042
non-profit organization, so
therefore there are public IRS
filings, there is the original

114
00:13:53,042 --> 00:13:59,917
announcements that are still
archived. Here is the thing a
lot of this information is sort

115
00:13:59,917 --> 00:14:07,625
of hiding in plain site. So some
people on this first day or
second day when it was announced

116
00:14:07,625 --> 00:14:15,167
are still quite active on
Usernet with the same e-mail
addresses. We did a little

117
00:14:15,167 --> 00:14:19,667
digging and there are some
published academic papers with
colleagues and there is actually

118
00:14:19,667 --> 00:14:24,833
acknowledgment and a few
dissertations and thesis that
say no, thank you so and so for

119
00:14:24,833 --> 00:14:30,833
working with me on this and on
TrueCrypt. And so the
information is out there. 	But

120
00:14:30,833 --> 00:14:38,125
some things were not at least I
won't be quite as comfortable in
sharing, why is that? Well,

121
00:14:38,125 --> 00:14:43,708
remember this, right, everybody
get a good laugh and a few days
later this story sort of died

122
00:14:43,708 --> 00:14:47,208
down, the official mailing list
or form or whatever, Dorian
Nakamoto, people forget it was a

123
00:14:47,208 --> 00:14:53,208
weird story and not the best
journalism but a lot of people
forget this part. Within hours

124
00:14:56,292 --> 00:15:02,292
of that story breaking, Dorian's
house was surrounded in this and
I think crucially this: He had

125
00:15:15,875 --> 00:15:21,708
some serious health problems as
a result of potentially serious
financial problems, his life was

126
00:15:21,708 --> 00:15:27,583
turned upside down. All that is
just a way of saying there's a
huge amount of information

127
00:15:27,583 --> 00:15:35,333
already out there, endless
discussions and forums and
things where as I said, these

128
00:15:35,333 --> 00:15:42,750
public records can be obtained.
I don't think it benefits anyone
to try to a docsync I want to

129
00:15:42,750 --> 00:15:47,042
leave the last 20 minutes or so
for questions so we can talk
more about that if you like.

130
00:15:47,042 --> 00:15:53,042
	Back to the code. So this was I
think attributed to (inaudible)
...shallow, well, in the crypto

131
00:16:00,000 --> 00:16:05,375
world, one thing that I have
come to appreciate is it's a
very, very small community.

132
00:16:05,375 --> 00:16:11,375
Security engineering is fairly
small anyway. But cryptographic
engineering is a very different

133
00:16:14,583 --> 00:16:20,583
beast. Cryptography engineering,
it's a very very special narrow
area. 	So it's not the case that

134
00:16:26,542 --> 00:16:32,792
with just lots of people
looking, bugs will be found but
some of the subtle, you know,

135
00:16:32,792 --> 00:16:40,042
cypher chain and implementations
for random generators, you know
they will be missed. I mean,

136
00:16:40,042 --> 00:16:45,583
there is value in the open
community and there is value in
all that. But it's not the same

137
00:16:45,583 --> 00:16:53,375
as really really you know highly
skilled, highly trained crypto
engineer. I love this picture.

138
00:16:53,375 --> 00:16:59,375
This is from 1920, Sam
Reshevsky, he beat 14 chess
masters at the same time. So, I

139
00:17:01,458 --> 00:17:08,500
mean, the point of this is there
are some skill sets which are
just orders of magnitude

140
00:17:08,500 --> 00:17:15,792
different than others. 	So we
talked and we said, you know,
this is important software.

141
00:17:15,792 --> 00:17:20,583
People seem to be using it. We
have people on the project using
it. We really didn't know a

142
00:17:20,583 --> 00:17:26,583
think about it. 	So let's do it.
	So there was a conversation on
Twitter with Matt and I, I sort

143
00:17:33,208 --> 00:17:40,000
of announced it, Matt threw some
money. We were contacted by a
group called FundFill and I

144
00:17:40,000 --> 00:17:45,625
didn't realize at the time but
they were just starting out,
startup company. And then anyway

145
00:17:45,625 --> 00:17:51,625
this went out so Matt noodled on
it a while. Couple weeks go by
and he was like we need to talk

146
00:17:55,167 --> 00:18:00,542
about this. There's something
here. So we blogged about it and
it hit the front page of Why

147
00:18:00,542 --> 00:18:06,542
Comminator and then the
Internet showed up, umm yeah. So
we were assuming the

148
00:18:10,792 --> 00:18:18,083
conversations would be around
the code and analysis but what I
didn't fully appreciate and what

149
00:18:18,083 --> 00:18:24,750
I now understand is the enormous
amount of work is sort of the
community piece of that. We

150
00:18:24,750 --> 00:18:31,875
advertised rather, we sort of
promoted the idea that you know
this, here are basic goals,

151
00:18:31,875 --> 00:18:37,875
basic cryptanalysis, some bug
bounties would be a good idea.
The dream would be if we could

152
00:18:40,375 --> 00:18:45,917
raise enough money to have one
of the few security engineering
firms in the world who not only

153
00:18:45,917 --> 00:18:52,792
have the skills but whose
reputation is with people we
trust and are likely to say,

154
00:18:52,792 --> 00:18:58,250
yes, this is credible. So there
was no shortage of people
wanting to help, no shortage of

155
00:18:58,250 --> 00:19:05,500
firms stepping up saying we have
a free static analyzer or
whatever. 	There is a very small

156
00:19:05,500 --> 00:19:11,500
number of professional firms
that do this sort of work. 	Then
set up a thing on indigogo and

157
00:19:15,333 --> 00:19:20,750
he says well maybe we can offer
people T-shirts if they get to a
certain level or DVDs and

158
00:19:20,750 --> 00:19:26,875
sneakers and things and, wow!
So, yeah, in the first,
arbitrary number of days for a

159
00:19:26,875 --> 00:19:32,875
campaign. We set it for 60. This
is day one. Like in the first
four hours, okay. We really

160
00:19:37,292 --> 00:19:44,833
struck a chord here. When we set
a bitcoin you have to understand
this was nation mechanism,

161
00:19:44,833 --> 00:19:50,833
sorry... this was the history
through the year. Right. So
coming out here. So this is

162
00:19:52,875 --> 00:19:58,875
April and the project started
around here. And we could talk
about the speculation and the

163
00:20:02,792 --> 00:20:08,792
market price of Bitcoin, but
when people are sending
literally $5 donation and $1

164
00:20:11,750 --> 00:20:19,458
donations and you know really
sweet elderly ladies from
Yorkshire are asking for an

165
00:20:19,458 --> 00:20:25,458
address to send a check if they
are not really online, you take
a serious responsibility. So in

166
00:20:30,167 --> 00:20:36,167
that context, we are taking
Bitcoin and this starts
happening. You know, we're not

167
00:20:40,417 --> 00:20:46,417
like some investment house, so
people there's -- I don't know
if it makes sense to hang on to

168
00:20:48,417 --> 00:20:55,167
this. For all we know this was
the monster crash that happened
and there were some crashes but

169
00:20:55,167 --> 00:21:02,333
anyway the point of all that is
to say we took it very
seriously, um, the people had

170
00:21:02,333 --> 00:21:09,417
trusted us with you know their
support. 	Anyway now we are
still in like a week into this,

171
00:21:09,417 --> 00:21:16,625
right, eventually within a few
days our technical guys, the
economist and nature pick up on

172
00:21:16,625 --> 00:21:22,625
this, and then one morning
there's 30 grand in the Paypal
account, what! How much? So,

173
00:21:25,750 --> 00:21:31,083
yeah, we hadn't really thought
about it seriously. At the point
we were like, this isn't just a

174
00:21:31,083 --> 00:21:37,792
couple thousand dollars sitting
here and there for a bug bounty
this is serious, we created a

175
00:21:37,792 --> 00:21:44,542
non-profit corporation and one
of the ideas was that it doesn't
make sense to spend a

176
00:21:44,542 --> 00:21:51,458
significant chunk of money on
taxes because it's not what
people intended the funds to go

177
00:21:51,458 --> 00:21:59,000
for it. We have a mission
statement, a charter and by-laws
and so forth, and all the

178
00:21:59,000 --> 00:22:01,833
standard things that you have,
that's on the website. Nice
logo. And one of the most

179
00:22:01,833 --> 00:22:07,833
important things we did was Matt
and I said, you know, we have
some interest and expertise in

180
00:22:11,500 --> 00:22:17,500
area X but Y,Z you know, A, B,
C, D, E, F, we were out of our
element. Ah, yes. Okay.

181
00:22:21,542 --> 00:22:27,542
(Laughter) (Applause) 	>> Yeah,
yeah, yeah. Yeah. 	>> Very good
with it. (Laughter) 	>> I guess

182
00:22:43,875 --> 00:22:49,875
we have a pause. All right.
	>> First-time speaker at DEF
CON! 	>> Woo-hoo! 	(Laughter)

183
00:22:53,000 --> 00:22:59,000
(Applause) 	>> Oh yeah! I like
it. 	>> Congratulations.Good
Luck at getting back to your

184
00:23:06,667 --> 00:23:12,667
talk. 	>> Where were we? Dammit.
Thank you, sir. I don't know
what give short shrift to the

185
00:23:18,375 --> 00:23:25,125
incredible people that stepped
up and offered to help in ways
small and large. I really want

186
00:23:25,125 --> 00:23:31,125
people to go to the Open Crypto
Audit website the people page.
This is an extraordinary group

187
00:23:31,125 --> 00:23:37,083
of people who stepped up and
offered to be technical advisors
and part of what that means is

188
00:23:37,083 --> 00:23:42,000
we knew we'd be compiling a
report. We knew we'd be dealing
with a lot of different material

189
00:23:42,000 --> 00:23:49,500
but we also knew that would span
basic cryptography, security
engineering, protocol

190
00:23:49,500 --> 00:23:55,500
engineering, legal reviews. So I
don't know if people know but, I
mean, Jim Denaro is one of the

191
00:23:58,292 --> 00:24:04,292
top sort of IP and sort of
security-oriented attorneys and
he's also a CISSP and a

192
00:24:06,333 --> 00:24:12,333
practitioner which is really
amazing. Thomas Ptacek, if you
don't know them, definitely

193
00:24:15,750 --> 00:24:23,500
check that out. It just came out
a couple days ago at BlackHat
they are going through level

194
00:24:23,500 --> 00:24:31,333
eight. It's an incredible
program. Runa Sandvik, formerly
with Tor, Nate, I mean, it's

195
00:24:31,333 --> 00:24:36,667
just an incredible line up.
Moxie even said, you know, I'll
take a look and see what you got

196
00:24:36,667 --> 00:24:42,667
and, you know, give you some
thoughts and ideas as we get
further along. Jo is here from

197
00:24:45,417 --> 00:24:50,167
his group. 	It's an
extraordinary group and if you
don't know Trevor Perrin, he's

198
00:24:50,167 --> 00:24:57,292
one of the brightest in the
world in cryptographic
engineering and crypto

199
00:24:57,292 --> 00:25:03,625
protocols. So anyway, just
incredibly honored to be working
with people of this caliber.

200
00:25:03,625 --> 00:25:09,667
	Because we have a non-profit so
we need officers and Matt and I
stepped up and then we put a

201
00:25:09,667 --> 00:25:14,042
call to Marcia Hoffman, she is
still special counsel for EFF
and she's been extraordinary.

202
00:25:14,042 --> 00:25:20,042
	Then we had our first board
meeting. This is how we roll.
Take that, Man! So, you know,

203
00:25:31,167 --> 00:25:35,458
lots of connections. There is
sort of the problem with the
history of the project and

204
00:25:35,458 --> 00:25:42,917
trying to make sense of things
and obviously lots and lots of
questions began. 	So we did as I

205
00:25:42,917 --> 00:25:47,750
said we reached out to a small
number in the organization that
can do this. We had tremendous

206
00:25:47,750 --> 00:25:53,750
response. If you don't know
iSech, find the... you know,
find someone who you really,

207
00:25:57,917 --> 00:26:02,958
really, really respect in the
crypto world, and ask them about
iSech. They've been

208
00:26:02,958 --> 00:26:08,958
extraordinary partners.
	Technology fun stuff happens,
we have an arrangement with

209
00:26:11,750 --> 00:26:14,042
iSech, we've done some, I mean
we have existing contract
mechanism, we're actually

210
00:26:14,042 --> 00:26:20,042
willing to kick in a match grant
so you can double the amount of
engineering hours on this and

211
00:26:22,042 --> 00:26:27,125
that will be our contribution. I
don't know if I actually put
this in but we also did --

212
00:26:27,125 --> 00:26:34,042
fairly in the audit we got a
$10,000 donation from Austria.
And some other large donations,

213
00:26:34,042 --> 00:26:42,000
I'll get to that in a second.
	So fast-forward, I don't know
if people have seen this but

214
00:26:42,000 --> 00:26:48,000
it's online. We spent many, many
weeks working with iSech on
standups, going through each of

215
00:26:50,917 --> 00:26:56,917
the different sort of pieces of
the, their part of the project.
It's important to say, too, what

216
00:26:59,083 --> 00:27:05,083
we talked with them about and
there was the group and there
was pretty broad consensus with

217
00:27:07,375 --> 00:27:13,750
the group, there's a long
history of you know security
failures that have nothing to do

218
00:27:13,750 --> 00:27:20,000
with crypto but they are in
crypto products. So, you know,
this was all sort of post

219
00:27:20,000 --> 00:27:26,000
Heartbleed and around this time,
too, preHeartBleed but that
tradition is very well known and

220
00:27:28,250 --> 00:27:36,125
so while crypto is hard, all the
other things on sort of the
foundation of this stack are

221
00:27:36,125 --> 00:27:42,125
also very hard and also easy to
get wrong. 	So this is what we
wanted them to focus on. 	So,

222
00:27:45,750 --> 00:27:51,750
you know, memory management,
construction of the different
classes, data structures, these

223
00:27:58,167 --> 00:28:04,167
are not random number
generators, not you know
multiple cypher block chains and

224
00:28:06,208 --> 00:28:12,208
that different suite. But more
sort of the foundation elements.
	So couple of their engineers

225
00:28:14,333 --> 00:28:22,083
were augmented by peer-reviewed
by senior principles and looked
at this and they basically came

226
00:28:22,083 --> 00:28:29,375
up with, well the way the volume
header is derived is maybe not
so strong. But again, remember

227
00:28:29,375 --> 00:28:34,042
the issue a lot earlier with the
number of hashes per second.
These things are all relative,

228
00:28:34,042 --> 00:28:40,042
right? 	So there was some
discussion about information
being paged out. So the idea is

229
00:28:43,000 --> 00:28:50,667
that let's say you have true
crypto and you have a volume
open and keys in memory or

230
00:28:50,667 --> 00:28:56,667
passwords in memory. Say you hit
a malicious website that is
doing XML entity, explosion like

231
00:29:02,500 --> 00:29:08,500
a -- quadratic header where you
declare a single entity in XML
block and then the way that is

232
00:29:13,167 --> 00:29:20,167
invoked, you can basically
exhaust memory, you can max out
CPU. The idea was that

233
00:29:20,167 --> 00:29:27,042
particularly on Windows systems
it's easy to contrive very
simple proofs of concept where

234
00:29:27,042 --> 00:29:31,667
memory is just getting paged
like mad. 	So when that is
happening you could get raw key

235
00:29:31,667 --> 00:29:37,667
material being saved to disc, to
non-encrypted disc. The
decompression system not unlike

236
00:29:43,542 --> 00:29:49,542
libLZ, which is very prominent
int he Linux world and, I mean,
we have systems all over that

237
00:29:53,458 --> 00:29:59,667
depend on that. 	The particular
one you used was sort of
deprecated but again this has

238
00:29:59,667 --> 00:30:05,375
been around for ten years. Some
of the core elements were built
six or seven years ago. There

239
00:30:05,375 --> 00:30:10,750
were several places where they
are using mem set to clear data.
So the idea is I have a password

240
00:30:10,750 --> 00:30:17,417
or key, do manipulation on it
and say mem set and wipe that
out. I'll show you in a minute

241
00:30:17,417 --> 00:30:23,375
why that's a problem. 	But the
thing is none of those actually
address the true crypt security

242
00:30:23,375 --> 00:30:29,958
model. Because one of the
reasons I spent time on the
fundamentals earlier is let's

243
00:30:29,958 --> 00:30:34,333
say that scenario plays out and
you have true crypto and the
volume up and you have true

244
00:30:34,333 --> 00:30:41,083
material in memory. You hit a
malicious website. Well, the
fact the vector is very

245
00:30:41,083 --> 00:30:47,500
specialized in paging memory to
somehow get those keys to disc
which can be five or eight hours

246
00:30:47,500 --> 00:30:55,333
later, take a step back. You
have hit a malicious site that
is, you know, running an exploit

247
00:30:55,333 --> 00:31:01,667
on your machine. It is just not
a TrueCrypt model. It's not part
of the security guarantee or the

248
00:31:01,667 --> 00:31:07,667
security promise. 	What does
that mean? In aggregate, none of
those vulnerabilities discovered

249
00:31:09,875 --> 00:31:15,250
are, I was gonna say part of the
security model. If you had
physical access to the machine,

250
00:31:15,250 --> 00:31:20,292
to the amounted volume, like the
machine was in sleep mode, they
already contain exploits for

251
00:31:20,292 --> 00:31:24,792
that, like $200 but that's not
just TrueCrypt. That's bit
locker, that's others. Deluxe

252
00:31:24,792 --> 00:31:30,792
family of Linux. All major disc
and all this encryption
implementations have similar

253
00:31:33,708 --> 00:31:39,708
attack vectors. 	So if we're not
really weak in the things that
are actually you know in the

254
00:31:47,250 --> 00:31:55,000
security promises, again, the
key derivation, we could
probably on the password drive

255
00:31:55,000 --> 00:32:01,583
key you know increase the
iteration count, you already saw
in the group force, it's going

256
00:32:01,583 --> 00:32:07,583
to be decent. It can be improved
but there's no show-stoppers so
this is around the time, you

257
00:32:10,333 --> 00:32:16,708
know we have sent them
manuscript for view, team looked
at it, I signed off for the peer

258
00:32:16,708 --> 00:32:23,958
review and then the great line
by John Lennon, life is what
happens when you're busy making

259
00:32:23,958 --> 00:32:30,208
other plans. TrueCrypt.org gets
dark, my Twitter starts lighting
up, what's wrong with the

260
00:32:30,208 --> 00:32:36,167
website. Did you guys -- did you
do this? Are you kidding me? You
don't know how much pain we went

261
00:32:36,167 --> 00:32:43,542
through because you never know
what, what people are gonna have
us spend time on. We went

262
00:32:43,542 --> 00:32:50,958
through a fair amount of pain to
harden our site. It's basic like
HTML and like not some ancient

263
00:32:50,958 --> 00:32:55,875
WordPress or something. 	I'm
looking like what are you
talking about? Our site is fine.

264
00:32:55,875 --> 00:33:01,875
Not your site. True crypt
organization. What? Yeah, at
first it didn't even show this.

265
00:33:06,250 --> 00:33:11,667
The morning or afternoon this
happened, I don't have a
screenshot of it basically we

266
00:33:11,667 --> 00:33:17,750
had an error message source code
saying this may be a malicious
Web page and I guess they have

267
00:33:17,750 --> 00:33:24,208
like automatic intrusion
software that says, if your
volume is more than like this,

268
00:33:24,208 --> 00:33:30,583
and then one day it shoots
towards magnitude and it's a
header redirect, looks like a

269
00:33:30,583 --> 00:33:36,583
crawl, pop-up messages, this was
the message you see on source.
	You go to true crypt.org and

270
00:33:39,333 --> 00:33:44,833
get redirected to sourceforge
where the project was originally
launched but years ago, it sort

271
00:33:44,833 --> 00:33:50,833
of was not abandoned but sort of
there was a -- there were
basically directions, you know,

272
00:33:53,917 --> 00:34:01,333
the official website
truecrypt.org. But look at the
language here. Not secure, may

273
00:34:01,333 --> 00:34:06,458
contain unfit security issues.
What? What are you talking
about! So the I got my phone and

274
00:34:06,458 --> 00:34:12,458
Matt's and, you know, got the
whole board was just everybody
is getting pinged on this, like

275
00:34:15,667 --> 00:34:23,333
what's the deal? 	The short
answer is we don't know. We had
an official line of

276
00:34:23,333 --> 00:34:29,333
communication, official e-mail
contact but the mail exchange
went offline, too. Well, if your

277
00:34:33,792 --> 00:34:38,958
official line of communication
has gone silent and you have
some people's personal e-mail

278
00:34:38,958 --> 00:34:44,208
addresses, okay, we can try
that, too. Some other people
were involved that just when the

279
00:34:44,208 --> 00:34:50,167
story broke we're curious too,
they started contacting people
and there were some other lines

280
00:34:50,167 --> 00:34:54,083
of communication but it wasn't
really clear because some of the
conversations we've had with

281
00:34:54,083 --> 00:34:58,667
people who are listed in the
public record were like, well,
the key to, well our developer

282
00:34:58,667 --> 00:35:05,750
keys have been destroyed. We're
not even sure if we have access
to the site anymore, meaning

283
00:35:05,750 --> 00:35:11,250
TrueCryptOrg, how do you not
know if you have access to the
site? What does that even mean?

284
00:35:11,250 --> 00:35:17,250
	And so there is all this
speculation. So we sort of took
a step back and we said, okay,

285
00:35:24,042 --> 00:35:30,042
whatever this sort of
sociological equivalent is,
maybe it's middle-aged guys that

286
00:35:33,333 --> 00:35:39,667
just said, meh, I don't need the
headache, I don't need the, you
know, one of the messages was XP

287
00:35:39,667 --> 00:35:46,417
has been stopped; and that's
sort of what it has been built
around. But there's so much, so

288
00:35:46,417 --> 00:35:53,625
many strange inconsistencies on
here, there were just so many
question marks. But you know,

289
00:35:53,625 --> 00:36:00,000
the thing is we have a project.
We have, you know, we have
stated goals. We have taken

290
00:36:00,000 --> 00:36:04,708
support from people around the
world. So we talked about it for
a while and we said what, you

291
00:36:04,708 --> 00:36:12,208
know, doesn't matter. I don't
care if someone flipped out or
someone rage quit or an agency

292
00:36:12,208 --> 00:36:18,417
got to somebody, you know, I
don't -- if it's an internal
battle. All these things we are

293
00:36:18,417 --> 00:36:24,417
sort of speculating and many of
which could have been
possilities, we're in the middle

294
00:36:24,417 --> 00:36:32,250
of an audit so we'll continue
on. We have the findings from
the iSech team, we'll start

295
00:36:32,250 --> 00:36:39,417
phase 2, the formal crypt
analysis so one of the other
things that is a real drag about

296
00:36:39,417 --> 00:36:45,417
this is, you know, there were
lots and lots of documentation
and examples and sources and

297
00:36:48,375 --> 00:36:53,417
materials on the website. All
that got wiped. I mean, there
are mirrors that people have set

298
00:36:53,417 --> 00:37:00,500
up. One of the first questions
was, well, what the hell code do
you use? You can't use the stuff

299
00:37:00,500 --> 00:37:06,417
on sourceforge because it was
labeled 7.2. That's read-only.
It only has popups. If you

300
00:37:06,417 --> 00:37:13,917
install 7.2 TrueCrypt it has
popups and you basically don't
use this, it may have issues.

301
00:37:13,917 --> 00:37:20,167
	Then literally they ripped out
the, you know, the right in the
update code. No! You know,

302
00:37:20,167 --> 00:37:27,333
whatever issues existed the day
before, and whatever security
guarantees could be made the day

303
00:37:27,333 --> 00:37:33,333
before in the announcement. They
are still there from a pure
software perspective. So we had

304
00:37:36,750 --> 00:37:43,958
a couple delays and I was hoping
to give more update on phase 2.
But basically Thomas and Nate

305
00:37:43,958 --> 00:37:49,917
are kind of mentoring or
organizing phase 2 but that will
be full crypt analysis that

306
00:37:49,917 --> 00:37:55,792
we'll be looking at the
cyberchains, excuse me, at the
random number generator

307
00:37:55,792 --> 00:38:00,583
instructions and the protocol
instructions and so forth. 	We
have talked about several

308
00:38:00,583 --> 00:38:06,750
post-audit scenarios but what we
can't do is we can't support the
development of a project now

309
00:38:06,750 --> 00:38:13,917
that's a moving target. The
people who contributed to the
project said, we want a verdict

310
00:38:13,917 --> 00:38:18,333
on true crypt 7.1, this is used
by several million people. So
we're going to give you a

311
00:38:18,333 --> 00:38:24,500
verdict on true crypt 7.1. We
can't tell you it's absolutely
secure, rock solid or not. But

312
00:38:24,500 --> 00:38:30,833
what we can say is we looked at
these 10 things and didn't find
any issues. And as much as that

313
00:38:30,833 --> 00:38:36,750
is possible, we'll do, we can
do. 	Obviously lots of
questions. But we have had some

314
00:38:36,750 --> 00:38:42,250
conversations with the I think
originally they were calling
themselves the next crypt

315
00:38:42,250 --> 00:38:48,250
organization in Europe but they
have sort of announced they are
holding off until we finish. You

316
00:38:51,000 --> 00:38:57,000
can't audit an ongoing live
project which is just, you know,
ripping out core classes and

317
00:39:00,625 --> 00:39:07,958
things. 	So I want to spend just
a minute or two on some secure
coding pieces. And I want to

318
00:39:07,958 --> 00:39:11,667
explain a little bit more on the
Isech findings and then we can
open it up for questions. 	This

319
00:39:11,667 --> 00:39:17,667
is a great quote! I think it's
Maciej, founder of Pinboard,
I'll let you read it but

320
00:39:24,500 --> 00:39:28,167
"There's no difference from the
attacker's point of view,
between gross and tidy errors.

321
00:39:28,167 --> 00:39:33,542
Both of them are equally
exploitable... This lesson is
very hard to internalize. In the

322
00:39:33,542 --> 00:39:38,375
real world, if you build a
bookshelf and forget to tighten
one of the screws all the way it

323
00:39:38,375 --> 00:39:42,917
does not burn down your house."
I love that. So one of the
things people thought about is

324
00:39:42,917 --> 00:39:48,292
there are all kinds of tools,
tons of tools. Static analyzers,
dynamic analyzers, intelligent

325
00:39:48,292 --> 00:39:54,500
static analyzers , and yes, some
of those help. Some are
crucially needed. The world is

326
00:39:54,500 --> 00:40:00,500
not for lack of auditing tools.
	I highly recommend people take
a look at the examples. But

327
00:40:04,542 --> 00:40:11,292
prepare yourself before you do.
I will also go through this
quickly. This is a quote by the

328
00:40:11,292 --> 00:40:17,500
former director insurance
director. Basically saying
"Source code is interesting and

329
00:40:17,500 --> 00:40:24,167
sometimes helpful but computers
don't work on source code, they
won't. (Laughter) They work on

330
00:40:24,167 --> 00:40:30,167
machine code. So real quick,
consider hypothetical. Does that
work or not? Well, depends.

331
00:40:34,083 --> 00:40:38,792
Depends on the compiler, depends
on the flags, your primer, tour
optimizations. I'm going to show

332
00:40:38,792 --> 00:40:45,750
you several real quick from the
64 group. Visual studio, I know,
they have to deal with Windows,

333
00:40:45,750 --> 00:40:51,750
here are Windows, example one,
example 2 using that security
secure set. Mim set just gets

334
00:40:55,583 --> 00:41:02,292
optimized out so this is a
simple example pop-up of a
dialogue box but what if it are

335
00:41:02,292 --> 00:41:10,083
the earlier example, password,
key, mem sech clear? Meh, this
is where the function would have

336
00:41:10,083 --> 00:41:15,750
started. This is where the code
returns. You didn't do anything
with the memory you set so

337
00:41:15,750 --> 00:41:21,750
therefore we won't bother to do
the inline compile and actually
do anything for you. 	Secure

338
00:41:24,375 --> 00:41:31,125
zero memory does. This is not a
slam on GCC, it's not a slam on
the studio or any particular one

339
00:41:31,125 --> 00:41:37,792
but these are complex tools and
have lots of non obvious side
effects and even if they have

340
00:41:37,792 --> 00:41:43,708
been around for, say, four or
five years, your OS may not have
anything posted, a current

341
00:41:43,708 --> 00:41:49,708
version. And learning from other
people. From the Tor project, I
see six. Five, yeah, I see five

342
00:41:56,208 --> 00:42:02,208
key files. That's a problem.
Yeah. NSS, that's a problem.
Then you get to stuff like this.

343
00:42:07,917 --> 00:42:13,917
Basically the issue there?
(Pause) All right. So just a
couple thoughts on trust. This

344
00:42:20,333 --> 00:42:26,208
is true. It's really depressing.
This is a -- it's not Unicode, I
forget but there's a coding

345
00:42:26,208 --> 00:42:32,208
standard. This is accepted as
legit from every major mobile
system, every major desktop

346
00:42:37,542 --> 00:42:43,542
browser. Do you have any idea
who that is? I don't. More on
trust. Linksys, net gear home

347
00:42:47,333 --> 00:42:53,333
router, see that? Pcap utility
built in. Thats diagnostics. It
randomly sends other frames back

348
00:42:57,000 --> 00:43:03,000
to the mother ship just for
diagnostics. What? As recently
as February, if you were running

349
00:43:07,375 --> 00:43:13,375
Red Hat, sent OS, Amazon Linux,
Oracle Linux, you were actually
running Hubble-open ssl because

350
00:43:19,708 --> 00:43:25,708
there are upstream requirements
with the shift of actual
controls. 	Anyway, HeartBleed,

351
00:43:28,958 --> 00:43:34,958
so this is a board, cipher,
which was happy to give out the
goods. So takeaways. Again, most

352
00:43:41,417 --> 00:43:45,583
of the catastrophic failures,
were secure coding errors, they
were not crypto errors, we have

353
00:43:45,583 --> 00:43:51,583
a long tradition of that. Tools
report but they are not enough.
And subject matter expertise is

354
00:43:54,583 --> 00:44:02,500
crucial. Also in terms of unpaid
volunteers, hey, volunteers are
also crucial. They are not

355
00:44:02,500 --> 00:44:09,500
enough. What we really need and
we have been working on, we're
in talks with the Linux

356
00:44:09,500 --> 00:44:15,375
Foundation, core infrastructure
initiative as well as some other
organizations. I'm really

357
00:44:15,375 --> 00:44:19,583
developing a working model for
public code review.Because this
is important stuff and

358
00:44:19,583 --> 00:44:25,125
particularly in the crypto world
but security engineering
broadly. 	Because even with a

359
00:44:25,125 --> 00:44:31,125
great chain, um... (Pause)
Right. Oh, just gonna tell you,
we have a few extras. Probably

360
00:44:38,417 --> 00:44:44,417
not your threat model. We can
talk about that if you want.
(Pause) Then we can add in, so

361
00:44:55,375 --> 00:45:02,583
reports released, we are working
on the reports. In phase 2, so
we can open it up. Five minutes?

362
00:45:02,583 --> 00:45:09,625
Five minutes for questions. I
have for a really good question,
I have original vintage movie

363
00:45:09,625 --> 00:45:15,625
posters of war games, I have
sneakers DVDs and T-shirts. So
questions, please. 	>> So you

364
00:45:24,208 --> 00:45:29,375
mentioned that there is all
these static analyses and demand
analysis tools and they're great

365
00:45:29,375 --> 00:45:36,125
but they're not enough and you
also mentioned that a lot of the
errors are not crypto errors,

366
00:45:36,125 --> 00:45:43,125
they are coding errors, ignoring
crypto errors for the moment,
what do we need to bridge the

367
00:45:43,125 --> 00:45:48,833
gap between what tools can find
now and just general coding
secure coding errors to the

368
00:45:48,833 --> 00:45:53,458
point where your average coder,
because there's a lot of people
in the world who don't spend

369
00:45:53,458 --> 00:45:57,917
time learning how to code
securely, so what tools are we
missing to make your average

370
00:45:57,917 --> 00:46:05,042
coder able to run a checker and
have some reasonable assurance
they haven't made stupid errors?

371
00:46:05,042 --> 00:46:11,667
	>> I think one of those crucial
things are project initiatives
like Tessa challenge or crypto

372
00:46:11,667 --> 00:46:17,667
palace. I can't say enough about
the service to the community
that Thomas and the group is

373
00:46:19,792 --> 00:46:25,583
doing. We could talk more about
it afterwards but I think is
really, it's a training and

374
00:46:25,583 --> 00:46:32,625
visibility thing and awareness
and a lot of it is things that
are not obvious. But I think

375
00:46:32,625 --> 00:46:39,042
there are some tools, I think
awareness and training are
crucial but we also need to work

376
00:46:39,042 --> 00:46:45,375
on a better model in general
because I think the model is
broken. 	When Cisco takes a week

377
00:46:45,375 --> 00:46:52,000
to literally just count they had
60 plus devices post HeartBleed
just to enumerate how many other

378
00:46:52,000 --> 00:46:56,000
systems were affected --
(Inaudible) -- AG, then the -- I
mean, yeah, we have got to be

379
00:47:00,125 --> 00:47:06,125
rethinking the whole way we
approach systems. 	Come on up.
	>> What sort of steps have been

380
00:47:12,417 --> 00:47:18,417
taken to address either incoming
legal or governmental requests
that information not be

381
00:47:20,667 --> 00:47:27,792
disseminated toward or to the
public or what are your plans?
Is there a fallback plan for

382
00:47:27,792 --> 00:47:35,125
when these challenges do occur?
	>> You mean on the project
itself? 	>> Right. 	>>

383
00:47:35,125 --> 00:47:38,917
Obligations or security letters?
	>> Uh-huh. 	>> Seen the
national security letter which

384
00:47:38,917 --> 00:47:46,083
was already online. We have
Signed statements from the Isech
team and other people on this

385
00:47:46,083 --> 00:47:52,083
project so we have not been
served or noticed by any
government agency. I suppose if

386
00:47:56,458 --> 00:48:00,875
we were, we have some of the
best constitutional attorneys in
the world working with us. I

387
00:48:00,875 --> 00:48:06,875
don't know if that's a great
plan but it's our plan. 	Come on
up. 	>> Do you guys have any

388
00:48:11,125 --> 00:48:16,708
plans to after this is all done
continue on with other open
source projects and audit them,

389
00:48:16,708 --> 00:48:21,125
because I think that's a
problem. There are so many open
source projects and if we all

390
00:48:21,125 --> 00:48:27,125
just go on faith that they're
good -- 	>> No, no, I appreciate
that. Thanks. I didn't even

391
00:48:30,792 --> 00:48:34,625
mention I'm sorry we're
auditing open SLL, the Open
Crypto Audit Project is doing

392
00:48:34,625 --> 00:48:40,292
it. It's one of the most
ambitious security projects in
history. We're doing it. That's

393
00:48:40,292 --> 00:48:46,292
great. (Applause) And I think by
the way there are probably 12
other like runners-up that are

394
00:48:49,750 --> 00:48:55,625
really involved in that
position, too. I think we'll do
a couple more and I'll be in the

395
00:48:55,625 --> 00:49:01,708
chill cafe and we can talk as
long as you guys want. 	>> Real
quick. How do you get involved

396
00:49:01,708 --> 00:49:07,708
with this open crypto audit
project? 	>> For phase 2 it will
be a mix of sort of guided sort

397
00:49:12,417 --> 00:49:18,375
of exercises but it's going to
have much more of the community
kind of full participation. We

398
00:49:18,375 --> 00:49:24,375
needed the sort of phase 1 to go
and it did. The second one will
not be near as much professional

399
00:49:26,958 --> 00:49:30,542
services although it will have
some of the top cryptographers
in the world working and

400
00:49:30,542 --> 00:49:38,083
coordinating but basically
reaching out and contacting.
Matt and I are online in Twitter

401
00:49:38,083 --> 00:49:44,833
and crypto audit.org. We are
talking to people. Be patient,
we get flooded sometimes with

402
00:49:44,833 --> 00:49:48,917
requests so you know you won't
hurt our feelings if you ping us
again in a week or two and say

403
00:49:48,917 --> 00:49:55,167
what can I do to help? This is
by no means Matt and I. There
are many many people that made

404
00:49:55,167 --> 00:50:01,167
it possible so far. Last one?
	>> First of all, just want to
say thanks to you guys for doing

405
00:50:03,625 --> 00:50:09,625
this. Two quick questions. One
how can the community support
you? Two, can you offer any

406
00:50:11,708 --> 00:50:17,708
comment on the possibility of
TrueCrypt support for GPT and
UEFI? 	>> You know, I think

407
00:50:20,458 --> 00:50:26,208
that's maybe a Matt question on
the last one. 	The first one
again, sorry. 	>> How can the

408
00:50:26,208 --> 00:50:32,250
community support you guys while
you work on it? 	>> Get involved
and stay aware of things like

409
00:50:32,250 --> 00:50:37,167
the core infrastructure
initiative. This is looking at
every core element of the stack.

410
00:50:37,167 --> 00:50:42,083
From you know the most basic,
all the way up to staff. There
will be big announcements

411
00:50:42,083 --> 00:50:48,500
coming. We're getting approached
by sizable organizations and how
they can help. For phase 2 it

412
00:50:48,500 --> 00:50:55,292
will be a global you know, bug
hunt, by the way we still have
like $30,000 so there will be

413
00:50:55,292 --> 00:51:01,167
way to pay outs for the next
couple months. Ideally we get
more but that's where we are so

414
00:51:01,167 --> 00:51:07,083
far. I think we'll stop there.
I'll take questions out and then
so all that swag. Thank you.

415
00:51:07,083 --> 00:51:13,083
(Applause)

