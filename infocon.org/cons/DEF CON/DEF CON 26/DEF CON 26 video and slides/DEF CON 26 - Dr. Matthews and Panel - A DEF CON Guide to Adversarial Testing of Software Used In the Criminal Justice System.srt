00:00:00.000-->00:00:05.172
>>Hi, I'm Jeanna Matthews. I'm a
computer science professor at
Clarkson and we have Nathan

00:00:05.172-->00:00:10.477
Adams uh who's a systems
engineer forensic bioinformatic
services and Jerome Greco who is

00:00:10.477-->00:00:16.149
a defense attorney at the Legal
Aid Society. We're all super
thankful that you uh got up uh

00:00:16.149-->00:00:22.823
for 10 a.m. to come hear what we
think is a really important
topic for all citizens of the

00:00:22.823-->00:00:29.763
modern world and uh to and
people interested in technology.
We're gonna be talking about

00:00:29.763-->00:00:34.234
adversarial testing of software
using the criminal justice
system. You're Just Complaining

00:00:34.234-->00:00:39.239
Because You're Guilty. So
software is increasingly used to
make huge decisions about all of

00:00:43.944-->00:00:48.949
our lives. I think in this room
we know that. From hiring to
housing to how we find partners

00:00:51.418-->00:00:58.058
and friends, how we navigate
streets, how we get our news.
And the weightier the decision,

00:00:58.058-->00:01:02.996
the more crucial that we can
understand it and question it.
What input is being given to

00:01:05.799-->00:01:11.805
that decision, is the decision
correct, for whatever metric you
would like to measure it by, is

00:01:11.805-->00:01:18.145
there other information that
really needs to be considered
that's not being considered, and

00:01:18.145-->00:01:22.583
what kind of bias is involved in
that decision? Are there
protected attributes that are

00:01:22.583-->00:01:27.354
being considered, like race and
gender? Or even if those
attributes are not considered

00:01:27.354-->00:01:32.259
directly, what about proxies for
those characteristics that are
just as effective as the

00:01:32.259-->00:01:38.765
characteristics themselves? The
criminal justice system is just
one example of this but it's a

00:01:38.765-->00:01:43.937
pretty important one. And
software and algorithmic
decision making is increasingly

00:01:43.937-->00:01:50.677
used throughout the criminal
justice system and usually its
black boxes for which traits

00:01:50.677-->00:01:57.451
secret protection is
aggressively claimed. And often
the rights, the intellectual

00:01:57.451-->00:02:01.788
property rights of companies are
being deemed more important than
the rights of individual

00:02:01.788-->00:02:05.993
defendants to understand or
question the decisions that are
made about them or the public's

00:02:05.993-->00:02:11.331
right to a trial, you know, a
public trial, understanding the
public trial process. And even

00:02:11.331-->00:02:16.336
besides that, there are many
evidences of problems that
bubble up. So it's not just that

00:02:18.805-->00:02:24.811
it's a black box, we have
evidence that there's trouble.
And how are we going to find

00:02:24.811-->00:02:29.816
bugs and fix the problems if the
answer is always you can't
question that? You're just

00:02:31.885-->00:02:36.990
complaining because you're
guilty. For example, can you
imagine being sent to prison

00:02:36.990-->00:02:40.727
rather than given probation
because proprietary software
says you're likely to commit

00:02:40.727-->00:02:46.133
another crime? But you can't ask
how the software makes that
decision. That's the Loomis vs.

00:02:46.133-->00:02:52.172
Wisconsin case. What about the
primary evidence against you in
a murder trial being the results

00:02:52.172-->00:02:57.677
of DNA software? The one program
says you did it and another says
you didn't. That's the Hillary

00:02:57.677-->00:03:04.251
case. What about being accused
of murder solely because of DNA
transferred by paramedics to the

00:03:04.251-->00:03:10.223
scene, but they don't figure
that out for months? That's the
Anderson case. Those are real

00:03:10.223-->00:03:15.228
examples. For those of us who
build technology. Software, we
know, that software complex

00:03:18.832-->00:03:24.204
systems need an iterative
process of debugging and
improvement. That's just a fact.

00:03:24.204-->00:03:29.810
Anyone who who uses technology
let alone builds it knows there
are glitches and bugs and

00:03:29.810-->00:03:34.815
unintended consequences. And um,
you know, how easy it is for
there to be substantial bugs

00:03:37.350-->00:03:43.590
that you just haven't found yet,
that you're shocked when you
find them. There's a huge

00:03:43.590-->00:03:48.595
advantage to independent,
third-party testing. We just
know that. It's well documented.

00:03:50.964-->00:03:56.803
You need teams that are
incentivized to find problems,
rather than teams that have a

00:03:56.803-->00:04:01.775
vested interest in showing that
the system is working just fine,
thank you very much. And we're

00:04:01.775-->00:04:07.581
dealing with a system that
actively de-incentivizes that.
If only those with interest in

00:04:07.581-->00:04:14.087
the success of software see the
details, we have a huge problem
and a big recipe for injustice,

00:04:14.087-->00:04:18.692
and that's what we're gonna be
talking about this morning. I'll
hand it over to Nathan, er to

00:04:18.692-->00:04:23.697
Jerome. >>So black boxes and
proprietary software and trade
secrets are increasingly

00:04:29.636-->00:04:34.541
becoming a problem in the
criminal justice system. Uh,
unfortunately so much so that we

00:04:34.541-->00:04:37.611
can't discuss all of them today
or in as much detail as I'd
like, but I'm going to give you

00:04:37.611-->00:04:42.516
an overview of with some
examples so you understand how
the problem, what the problem is

00:04:42.516-->00:04:47.521
and how it's actually affecting
cases. Uh just quickly, this is
a graph from OSAC which shows

00:04:50.023-->00:04:54.694
all the different forensic
disciplines that are being used
in the criminal justice system.

00:04:54.694-->00:04:59.699
Uh some are a lot more accurate
and reliable than others. Sss
Um, we've broken down the

00:05:02.569-->00:05:06.940
technology being used by law
enforcement to four distinct
categories, uh although they're

00:05:06.940-->00:05:12.913
not as distinct as as they may
appear, some technology fits in
multiple categories. Um in fact,

00:05:12.913-->00:05:17.484
the evidence gathering, evidence
assessment categories often
bleed into each other. But I

00:05:17.484-->00:05:24.090
will be giving at least one
example from each category. Uh
before we get into that, um I've

00:05:24.090-->00:05:27.828
broken down a lot of the
technology based on what I’ve
they have three different

00:05:27.828-->00:05:33.500
secrecy levels. So there's
secret we don't want you to know
this exists uh but if you find

00:05:33.500-->00:05:37.637
out it exists we don't want you
to know that we have it at all.
And there's secret as applied,

00:05:37.637-->00:05:42.709
which is we have it but we don't
want to tell you when we're
using it or we don't want to

00:05:42.709-->00:05:47.480
tell you how we're using it. And
then there's the trust us
category, which is okay we have

00:05:47.480-->00:05:52.185
it, we yeah we used it in this
case, uh but don't look at the
man behind the curtain, stop

00:05:52.185-->00:05:57.457
asking questions uh just trust
us. It works exactly like we say
it does. I mean, why wouldn't

00:05:57.457-->00:06:02.395
it? Uh, starting with predictive
policing, so predictive policing
is is basically using data and

00:06:04.431-->00:06:09.269
algorithms to make decisions
that were traditionally left up
to human law enforcement

00:06:09.269-->00:06:14.975
officers, which in theory that
sounds great, right? You can
remove the bias from uh the

00:06:14.975-->00:06:19.913
system. Except in reality that's
not actually how it works. Cuz
if you’ve train the algorithm

00:06:19.913-->00:06:26.820
based upon data that was from
years and decades worth of
racist uh policing, you're going

00:06:26.820-->00:06:31.825
to end up with a racist output.
And so if you have uh you know,
an-and the problem with that is

00:06:33.994-->00:06:39.132
that you have officers who-who
now can say, well the computer
told [audio cuts], right? It's

00:06:39.132-->00:06:44.337
not my fault, the computer made
the decision. And and you know,
the computer it has no bias. And

00:06:44.337-->00:06:50.310
it's like well you kinda of
trained it to have a bias. Um
and so for example, if you

00:06:50.310-->00:06:53.847
overpolice a neighborhood,
you're gonna make more arrests
in that neighborhood, whether or

00:06:53.847-->00:06:58.985
not there's more crime there. Uh
If you feed that into the
algorithm, the algorithm's gonna

00:06:58.985-->00:07:03.490
think oh there's more arrests
there so there's more crime
there. So we'll send more

00:07:03.490-->00:07:07.761
officers there, which then will
increase more officers making
more arrests to meet their

00:07:07.761-->00:07:12.332
quotas and to justify their jobs
and their existence and it
becomes a self-feeding circle.

00:07:12.332-->00:07:18.171
Um which is not always actually
the best method, in fact often
it is not. With this comes a who

00:07:18.171-->00:07:23.009
a lot of a lack of transparency.
Most of these companies are
requiring nondisclosure

00:07:23.009-->00:07:27.514
agreements, uh claiming that
they have proprietary trade
secrets so you can't see how it

00:07:27.514-->00:07:31.651
works under the hood. Uh and
also saying that the data that
they're using to train these

00:07:31.651-->00:07:36.890
programs or to make the programs
work are sensitive so you can't
review them. All this is

00:07:36.890-->00:07:41.895
preventing uh public scrutiny
of-of the programs themselves
and how they're being used. For

00:07:44.164-->00:07:48.802
evidence gathering today, we're
going to focus on cell-site
simulators and uh mobile device

00:07:48.802-->00:07:54.274
forensics. Uh so cell-site
simulator for those of you who
don't know is a device that uh

00:07:54.274-->00:07:59.012
force that mimics being a
cellphone tower and forces all
the cellphones within range of

00:07:59.012-->00:08:05.485
it uh to connect to it and then
it can lock on to a particular
uh phone and use that to get a

00:08:05.485-->00:08:11.057
very precise location. Uh for
example, in a particular
apartment in a multistory

00:08:11.057-->00:08:17.330
building, which is the US v
Lambis case. Uh it also, some of
them also have the capability of

00:08:17.330-->00:08:22.035
intercepting content, meaning
they can intercept text messages
and voice phone calls. The

00:08:22.035-->00:08:26.740
reason why I don't use the term
Stingray device, which is
probably what a lot of you have

00:08:26.740-->00:08:31.211
heard it be called is that
Stingray is a very specific
model. There are other models

00:08:31.211-->00:08:36.416
like the hail storm uh and they
all have their own capabilities
and differences and so cell site

00:08:36.416-->00:08:42.389
simulator covers all those
models instead of just referring
to one specific one. Um most

00:08:42.389-->00:08:48.361
people had no idea uh actually
pretty much anyone outside of
law enforcement and military had

00:08:48.361-->00:08:51.931
no idea these were being used
because they all required
nondisclosure agreements. So

00:08:51.931-->00:08:57.070
local, state, and feder, local
state and uh law enforcement
were signing non disclosure

00:08:57.070-->00:09:01.708
agreements with the company,
usually Harris Corporation and
also with the federal

00:09:01.708-->00:09:05.278
government. And so they were
being used in criminal cases
without without defense

00:09:05.278-->00:09:07.981
attorneys knowing, without
defendants knowing, and of
course without the general

00:09:07.981-->00:09:13.520
public knowing. Uh that has
obviously changed but they're
still making their efforts to

00:09:13.520-->00:09:18.525
keep it secret. In fact, NYPD
used one of these devices over a
thousand times between 2008 and

00:09:21.161-->00:09:26.166
2015 without ever once getting a
warrant. Uh we can thank the
NYCLU for their great work in

00:09:28.468-->00:09:35.508
being able to prove that. On top
of that, to this day, we still
don't know which model the NYPD

00:09:35.508-->00:09:42.048
is using because they still
refuse to give up that
information. And they're doing

00:09:42.048-->00:09:45.018
everything they can to keep that
quiet, including spending lots
of money litigating against it.

00:09:45.018-->00:09:51.291
Uh we're gonna talk about a case
in which I uh had worked on,
which was People v. Gordon, a

00:09:51.291-->00:09:55.261
case out of Brooklyn. So People
v. Gordon, this was Matthew
Creda was the attorney of record

00:09:55.261-->00:09:58.798
on the case and we also had a
lot of help from Michael Wexler,
who was at that time a legal

00:09:58.798-->00:10:03.703
felt, at the legal aid society.
And essentially, they found our
client in a location that really

00:10:03.703-->00:10:09.609
was not connected to him and
traditional cellphone tracking
was not accurate enough to get

00:10:09.609-->00:10:14.414
them to where he was. And so we
said, well, the only possible
way they could have done this is

00:10:14.414-->00:10:20.186
a cell site simulator. So in our
motion we said, we’re moving
suppressed, you used a cell site

00:10:20.186-->00:10:23.590
simulator without a warrant. And
if you didn't use a Cell Site
Simulator, explain to us what

00:10:23.590-->00:10:28.294
you did because we can't think
of another technologically
possible way. Prosecutor

00:10:28.294-->00:10:35.335
responds and says, concedes, and
goes yeah okay we did. We used
one. Alright. For us, this was a

00:10:35.335-->00:10:39.873
big deal. This is the first time
we're aware of ih in New York
state uh in an open case uh that

00:10:39.873-->00:10:45.144
we've been able to identify when
a cell-site simulator had been
used, so we're ecstatic we think

00:10:45.144-->00:10:51.184
we're gonna win, gonna, it's a
great thing going, uh judge
issues a decision a few months

00:10:51.184-->00:10:57.724
later, grants our motion to
suppress the alleged ID, and
we're on top of the world. We

00:10:57.724-->00:11:02.328
think we've broken new ground.
The decision gets published, a
New York Times article comes

00:11:02.328-->00:11:07.667
out, and then all of a sudden,
the NYPD says, no no no, you're
all wrong. We didn't use one. I

00:11:07.667-->00:11:11.671
said, well, a prosecutor in the
case just filed in court, you
know, with uh affirmed in court

00:11:11.671-->00:11:18.111
that you did use one. Obviously
not beneficial to their case, so
it seems weird that they would

00:11:18.111-->00:11:22.115
lie about something that was
only going to hurt them uh and
then on top of it, you had

00:11:22.115-->00:11:26.619
months to correct that record
and you did nothing. It was only
when it became very public and

00:11:26.619-->00:11:30.089
there was an article about it
that all of the sudden you said
no no we we have to deny this.

00:11:30.089-->00:11:33.993
And the only thing we can
possibly think of is that
they're bound by a nondisclosure

00:11:33.993-->00:11:38.398
agreement and they felt it was
necessary to continue their
denials, uh especially when it

00:11:38.398-->00:11:43.403
went public, which is uh
particularly problematic because
now it's already been

00:11:43.403-->00:11:48.308
established and they're still in
denial, they're still trying to
keep it secret even afterwards.

00:11:48.308-->00:11:55.114
Keeping in with this year's
DefCon theme, uh looking from
1983 looking uh year in the

00:11:55.114-->00:12:02.121
future 1984 uh this basically is
a description of all of us uh
what we have in our pockets. As

00:12:02.121-->00:12:08.895
most of us know, uh our cell
phones are the the most
successful mass surveillance to

00:12:08.895-->00:12:14.667
ever created. Uh so we're going
to talk about mobile digital
forensics. Riley v California

00:12:14.667-->00:12:17.870
was the case where the US
Supreme Court said a warrant is
required to look through

00:12:17.870-->00:12:22.475
somebody’s phone or pull data
from somebody's phone. This is
often done uh with a device

00:12:22.475-->00:12:26.846
called the Cellebrite UFED
Touch, this is a version 2 that
you see see on the screen, uh

00:12:26.846-->00:12:31.250
but there are other companies
like Magnum, Paraben, and and
others that also provide similar

00:12:31.250-->00:12:35.989
hardware and software. Uh and
the purposes of these is to
extract data from your phone so

00:12:35.989-->00:12:41.728
they can be reviewed and and
tagged by law enforcement. Now
this isn't really as terrible,

00:12:41.728-->00:12:47.033
right? cuz it it's available to
outside law enforcement, you we
can test it, see if we get the

00:12:47.033-->00:12:51.471
same results, you can see what
mistakes it has, uh there is a
financial barrier, but beyond

00:12:51.471-->00:12:56.275
that, you know, my office has
one, and I can see if I get the
same thing as law enforcement,

00:12:56.275-->00:13:00.413
if I pick up something
different, or or the mistakes
that they make, right? But

00:13:00.413-->00:13:07.887
that's not true with Cellebrite
Advanced Services and GrayKey.
So we all probably remember the

00:13:07.887-->00:13:13.359
uh 2015 the San Bernardino
shooting case and law
enforcement, the FBI, and

00:13:13.359-->00:13:17.730
Department of Justice saying to
Apple you need to help us get
into this iPhone, right you need

00:13:17.730-->00:13:22.368
to put backdoors into your
encryption and Apple saying h**l
no, we're not going to do that.

00:13:22.368-->00:13:28.641
Thank you, Apple, for once. Um,
[laughs] and yeah. One time they
do deserve a round of applause.

00:13:28.641-->00:13:36.949
Um but with that, they um we get
the FBI and Department of
Justice later withdraws their

00:13:36.949-->00:13:40.953
request and says well we got
into the phone we don't need
your help anyway. And everybody

00:13:40.953-->00:13:44.791
goes well you just told us it
was impossible and you couldn't
crack it, so what did you do?

00:13:44.791-->00:13:50.163
Uh, shortly after Cellebrite
Advanced Services pops up, and
what that is is it’s allows uh

00:13:50.163-->00:13:56.069
law enforcement to send a phone
to Cellebrite, they conduct some
secret process, and then they

00:13:56.069-->00:14:00.973
send it back to law enforcement
agency unlocked without the
encryption. And no longer a

00:14:00.973-->00:14:07.947
problem. Recently GrayKey, which
is a product by GrayShift has
appeared and it also does a

00:14:07.947-->00:14:13.586
similar process or has a similar
result, I should say, uh but
instead of sending it off to a

00:14:13.586-->00:14:19.192
lab, they actually send uh an
actual product of Graykey to law
enforcement agencies and they

00:14:19.192-->00:14:24.397
can do it in-house. Uh the
problem with these though, is
they won't sell it to me. And I

00:14:24.397-->00:14:28.735
can't look at any of this. As
you can see, there's even an
email telling me uh no. And I

00:14:28.735-->00:14:35.108
can't know exactly how it works
and I can't verify that it's not
deleting information, that it's

00:14:35.108-->00:14:39.579
not changing metadata, but law
enforcement's still trying to
put this into evidence without

00:14:39.579-->00:14:43.950
anybody an-and including law
enforcement, they're not really
sure how it works, they're not

00:14:43.950-->00:14:48.621
in-in uh Cellebrite's lab and
they're not taking apart the
GrayKey device, and they're just

00:14:48.621-->00:14:53.793
trusting it because it benefits
them. Um and to be clear, I
don't think Cellebrite or

00:14:53.793-->00:14:57.864
GrayShift uh are doing anything
intentionally malicious, but of
course we all know just because

00:14:57.864-->00:15:01.534
you program something to work
one way doesn't mean it's
actually is going to work that

00:15:01.534-->00:15:06.405
way, right? There are bugs,
there are flaws, there are
plenty of problem, in fact if

00:15:06.405-->00:15:11.210
that wasn't true, most of this
audience wouldn't have jobs or
at least would have to find a

00:15:11.210-->00:15:16.716
different hobby. Uh [laughs] and
we probably would have a
different conference at DefCon.

00:15:16.716-->00:15:21.954
So in terms of evidence
assessment, I’m gonna talk about
facial recognition is that one

00:15:21.954-->00:15:25.158
of the big things that we're
seeing now in the media,
especially with recently the

00:15:25.158-->00:15:30.997
ACLU uh ch-challenging Amazon's
now foray into this and eh
connecting to actual

00:15:30.997-->00:15:36.202
politicians. Uh instead of to
the actual people that it was
meant to connect to. Um the

00:15:36.202-->00:15:42.008
problems we're having with this
is uh multiple. One is we’re
often not being told what

00:15:42.008-->00:15:47.914
company is the actual uh company
being used to determine the
facial uh recognition, the

00:15:47.914-->00:15:52.051
match. Um and then even if we
are, we don't know the algorithm
works or how it is programmed.

00:15:52.051-->00:15:59.225
And we're uh being told that
this blurry surveillance still
has 70 percent confidence

00:15:59.225-->00:16:04.463
matched to either uh a mugshot
or driver's license photo or
sometimes social media profile,

00:16:04.463-->00:16:11.270
right? And the whole thing comes
down to okay let's assume, let's
assume that's right. Let's say

00:16:11.270-->00:16:15.441
it is 70 percent and you know, I
can't even verify that because I
don't know how it works, or you

00:16:15.441-->00:16:20.313
won't let me see how it works.
But is that enough for that to
be used for evidence in a in a

00:16:20.313-->00:16:24.517
trial? Is that enough for you to
arrest somebody? And okay let's
say 70 percent is not enough. Is

00:16:24.517-->00:16:29.622
80 percent? Is that what we
really want as evidence in court
cases? And if you say 70 percent

00:16:29.622-->00:16:34.093
is is more than enough, okay,
then what about 60 percent?
Where do we start drawing the

00:16:34.093-->00:16:39.298
line on who gets to make that
determination, right? And most
of the law enforcement that eh

00:16:39.298-->00:16:44.337
has very limited rules if any on
how they're using this and how
they're being trained uh

00:16:44.337-->00:16:49.008
including examples of them
actually manipulating photos to
make them more likely to get a

00:16:49.008-->00:16:54.313
match. Uh which seems just like
evidence tampering to me. Um, in
particular when we have had

00:16:54.313-->00:16:59.819
limited ability to do testing on
on this facial recognition um
which and and uh facial

00:16:59.819-->00:17:07.894
identification through examples
of actual line up, which is uh
Georgetown law and also the

00:17:07.894-->00:17:13.599
gender shades project, we've
seen significant flaws in based
on race, gender, and age. Uh for

00:17:13.599-->00:17:20.740
example, the gender shaves
project shows that uh women, uh
dark skinned women were more

00:17:20.740-->00:17:25.845
likely to be misgendered by the
program uh than say, a light
skinned man, right? And leading

00:17:25.845-->00:17:32.852
to more uh false false
identification. And so part of
the reason that that's believed

00:17:32.852-->00:17:37.089
is the way that a lot of these
programs are training their
algorithms the the data they're

00:17:37.089-->00:17:41.560
using is, uh are light skinned
men so there tend to be more
accurate for that than they

00:17:41.560-->00:17:46.999
would be for a dark-skinned
women, and as a public defender
a large percentage of my clients

00:17:46.999-->00:17:53.773
are people of color and it makes
them already vulnerable uh in
the criminal justice system even

00:17:53.773-->00:17:59.845
more vulnerable and likely to be
falsely identified. So we’ll
talk about individualist uh

00:17:59.845-->00:18:05.651
individualized assessment,
there's a couple different
examples there, um, today I'm

00:18:05.651-->00:18:10.389
talking about sentencing
algorithms, in particular, the
State versus Loomis case. This

00:18:10.389-->00:18:16.462
is a case that came out of
Wisconsin uh, it's US Supreme
Court decides not to take it up

00:18:16.462-->00:18:21.801
so it's not law across the
country uh but is indicative of
the fights that are happening

00:18:21.801-->00:18:26.038
everywhere right now across the
country and if and if those
local defense attorneys are not

00:18:26.038-->00:18:30.176
challenging it they should be,
and if you're in the room I'd be
happy to talk to you about that

00:18:30.176-->00:18:36.048
later. Um in this case they used
a risk assessment tool called
COMPAS made by NorthPointe uh in

00:18:36.048-->00:18:41.153
order to get a report of a
recommendation of uh sentence
for the defendant Loomis. Um one

00:18:41.153-->00:18:46.892
of the things that is is
acknowledged even by the company
is that it takes gender into

00:18:46.892-->00:18:51.464
account when it makes this
decision. Uh one of the was it
does that is that uh there's the

00:18:51.464-->00:18:56.402
idea that men are more like to
be recidivist, meaning they're
more likely to reoffend or be

00:18:56.402-->00:19:01.741
rearrested. Therefore, uh, there
should be less likely to be
given probation. So if you take

00:19:01.741-->00:19:07.546
a both a man and a woman, uh who
are exactly the same in all
other aspects, same crime, same

00:19:07.546-->00:19:14.086
criminal record, everything else
uh this program is less likely
to suggest probation for the man

00:19:14.086-->00:19:23.095
than it is for the woman. Uh and
it's also more likely to suggest
uh higher sentence uh for the

00:19:23.095-->00:19:26.999
man rather than the woman. That
seems extremely problematic,
especially when we're calling

00:19:26.999-->00:19:31.037
this individualized assessment
when you're doing it based upon
the history of a group that uh

00:19:31.037-->00:19:37.143
you were born into. Uh that then
sou sounds terrible to me. Uh
the other problem is oftentimes

00:19:37.143-->00:19:40.946
we don't know what factors are
being included at all. Uh we
don't know exactly how- what

00:19:40.946-->00:19:45.918
factors are using, um and this
is not just for sentencing. This
we're having this problem for uh

00:19:45.918-->00:19:51.924
bail, for parole, uh these
decisions are being made and
it's not just COMPAS, it is

00:19:51.924-->00:19:57.563
plenty of programs out there and
more coming up every day uh to
try to take over the market. And

00:19:57.563-->00:20:03.202
even when we know the factors,
we don't know how they're
weighing it. So for example, I

00:20:03.202-->00:20:06.939
don't know how much COMPAS took
into account gender, how
significant was that when it

00:20:06.939-->00:20:13.045
makes its decisions. That seems
like an pretty important thing.
But of course they're hiding

00:20:13.045-->00:20:17.650
behind proprietary trade secrets
by saying well if we release
this information, somebody will

00:20:17.650-->00:20:21.253
steal it from us, some
competitor and all of the sudden
we'll we'll have no jobs, and

00:20:21.253-->00:20:26.192
well look, I'm sympathetic to
some extent, but that doesn't
trump somebody's right. You

00:20:26.192-->00:20:29.795
know, we're talking about
people's liberty here. This
isn't like a uh uh a a minor

00:20:29.795-->00:20:35.601
thing. Like people are going to
prison, right? And that's really
important that they be able to

00:20:35.601-->00:20:38.170
challenge it, that their defense
attorneys be able to give them a
full defense. And it's not that

00:20:38.170-->00:20:42.074
we don't want to, it's just that
we're actually being hamstrung
from doing so. And that uh

00:20:42.074-->00:20:48.114
obviously very uh problematic um
and so these black boxes and
these claim trade secrets should

00:20:48.114-->00:20:52.852
not be able to be used in the
criminal justice system to
override somebody's right to

00:20:52.852-->00:20:57.623
face their accuser and to
challenge what's happening to
them. >>Woo! >>uh Thank you

00:20:57.623-->00:21:13.572
[laughs] [applause] Uh with
that, I'll I'll leave it to
Nathan. >>Hi, so I'm Nathan

00:21:13.572-->00:21:19.245
Adams. I work for a forensic DNA
consulting company in Ohio. And
uh my background is in

00:21:19.245-->00:21:23.549
computing, so I have a little
different flavor than a lot of
the folks who work in forensic

00:21:23.549-->00:21:28.420
DNA who are typically
biologists. So we had the
opportunity in a criminal case

00:21:28.420-->00:21:34.793
to examine a previously secret
software program that evaluates
forensic DNA information um that

00:21:34.793-->00:21:41.700
was developed by the New York
City office of the chief medical
examiner. So when I say OCME

00:21:41.700-->00:21:46.338
that's the the lab that
developed this program and FST,
Forensics Statistical Tool, is

00:21:46.338-->00:21:53.846
the name they used for it. A
little background [clears
throat] on it is that FST is

00:21:53.846-->00:22:00.753
approved for use on DNA mixtures
containing DNA from two or three
individuals. So as a as a

00:22:00.753-->00:22:05.191
general rule, the more DNA you
have from different individuals
in in a mixture, the harder it

00:22:05.191-->00:22:10.396
is to evaluate whether any
single person could have
contributed. The program does

00:22:10.396-->00:22:16.569
attempt to account for missing
data. So if you have an complete
uh sample, if it's low level,

00:22:16.569-->00:22:23.842
the signal doesn't uh isn't very
clear, it also allows for
spurious noise, uh drop in of uh

00:22:23.842-->00:22:31.584
DNA information and the output
is intended to be a very concise
likelihood ratio, which is a uh

00:22:31.584-->00:22:37.756
statistical weight in United
States, at least, all DNA
conclusions uh that suggest some

00:22:37.756-->00:22:43.762
defendant could be included as a
contributor to a sample that is
their DNA uh is possibly present

00:22:43.762-->00:22:49.802
on the item of evidence in
question, they need to provide a
statistical weight because if

00:22:49.802-->00:22:55.140
every other person in the world
could have contributed their
DNA, if that's a specific as as

00:22:55.140-->00:22:59.845
we get for that test, that
doesn't give us very much
information at all. Half the the

00:22:59.845-->00:23:04.016
box the jury box could uh
similarly be contributors. On
the other hand, we get

00:23:04.016-->00:23:09.021
statistics that are uh
suggesting that on-only one
person in the world could have

00:23:09.021-->00:23:14.159
DNA that matches this item and
oh look here it's the defendant.
So FST is supposed to streamline

00:23:14.159-->00:23:20.933
the process for complex mixture
interpretation um problems. Uh
they never sold this to other

00:23:20.933-->00:23:27.039
labs although they tried.
It-What we learned uh ultimately
is it is uh a fairly

00:23:27.039-->00:23:33.545
straightforward visual studio
project uh running C Sharp with
a a SQL backend. And the

00:23:33.545-->00:23:40.219
timeline uh will during the
middle of the timeline we’ll
take a break and uh go into the

00:23:40.219-->00:23:47.493
the problems that we looked into
and identified but FST's initial
use was uh approved by the New

00:23:47.493-->00:23:54.066
York State commission on
forensic science in 2010. It uh
evaluates data at fifteen

00:23:54.066-->00:23:59.538
locations on the human genome,
so we're looking at at fifteen
separate genetic uh locations

00:23:59.538-->00:24:05.611
that it will evaluate a single
reference to that is locus,
plural is loci, those are the

00:24:05.611-->00:24:09.815
the locations we're looking at
for those mixtures up to three
people. They initially attempted

00:24:09.815-->00:24:14.787
to go up to four people. They
published an article that
expresses the statement of their

00:24:14.787-->00:24:21.727
intent to do so. They never did
that. In 2011, it took them a
little time to-to bring it

00:24:21.727-->00:24:26.699
online. But online, um it was
online as of April of 2011,
started to be used on on

00:24:26.699-->00:24:32.538
criminal case work, so keep in
mind that that all forensic
science is uh fairly expensive

00:24:32.538-->00:24:38.143
to to conduct these texts. DNA
is no exception to that. So a
lot of these investigations are

00:24:38.143-->00:24:42.548
reserved for particularly
violent crimes. So in New York
City that would include um

00:24:42.548-->00:24:47.019
possession of a firearm, uh
there's a lot of um sexual
assault, homicide investigations

00:24:47.019-->00:24:53.759
that use DNA or or they evaluate
DNA at least and uh sometimes
property crimes. But these are

00:24:53.759-->00:25:02.801
um particularly um uh
significant investigations that
they're making so if uh someone

00:25:02.801-->00:25:07.206
is incriminated by the software,
it is in a a pretty serious
situation where they could be

00:25:07.206-->00:25:14.179
facing a lot of time in prison.
In 2011, um I don't if anybody
wants to predict what what

00:25:14.179-->00:25:22.187
happens next , but um that same
month, they modified their
production version of the system

00:25:22.187-->00:25:28.127
and caused it they had to take
it off line. Um, so this goes
back to what what Jeanna and

00:25:28.127-->00:25:33.665
Jerome were saying, you know
everybody makes mistakes, um
OCME made a big one by modifying

00:25:33.665-->00:25:39.905
their live version of the
software, taking it offline, uh
I think we have documentation

00:25:39.905-->00:25:43.742
now through freedom of
information request that
suggests this happened either

00:25:43.742-->00:25:49.748
the first or second week uh that
it was being used on case work
again, in likely in uh sexual

00:25:49.748-->00:25:54.486
assault and homicide
investigations. So these are
pretty serious investigations uh

00:25:54.486-->00:26:01.827
we were only told that it was
taken offline last fall. That it
went 7 years without us knowing

00:26:01.827-->00:26:09.668
that uh that they had messed up
and had to take it offline. They
fixed the problem that they

00:26:09.668-->00:26:14.239
caused, taking the the system
offline, but they also made some
additional modifications to the

00:26:14.239-->00:26:20.412
program. It was later claimed
that these modifications made
after the system was validated,

00:26:20.412-->00:26:24.249
after it was approved for use in
case work. After it was brought
online for case work. They claim

00:26:24.249-->00:26:28.387
that these changes that they
made uh did not affect the
underlying methodology of the

00:26:28.387-->00:26:34.493
program, but they didn't tell us
they thought that until 2017
'cause nobody knew that ti had

00:26:34.493-->00:26:41.333
happened in the first place. In
July of 2011, they finally
brought it back online so it

00:26:41.333-->00:26:45.904
took them three three months or
so to actually get it up and
running, again uh after they

00:26:45.904-->00:26:52.444
broke it. In 2016, my company
was hired to to work on a case
where the source code to the

00:26:52.444-->00:26:59.017
software had actually been
ordered over uh by a federal
court. So uh Chris Flood and

00:26:59.017-->00:27:04.056
Sylvie Levine, the two public
defenders in that case, uh
contacted us and asked us to

00:27:04.056-->00:27:08.627
take a look at the software, so
we were involved in in an
investigations into what FST was

00:27:08.627-->00:27:12.130
actually doing because this was
not only the first time anybody
had access to the the source

00:27:12.130-->00:27:17.769
code, uh but anybody, the first
time that anybody had access to
an executable version of the

00:27:17.769-->00:27:24.409
system. So no nobody had been
able to put through uh different
sets of data to test it at any

00:27:24.409-->00:27:34.453
point in its its uh lifetime
until we got it. This is uh a
short uh fairly small set of

00:27:34.453-->00:27:41.560
output that FST produces when
it's run in a single case on a
single eleven entry item. It

00:27:41.560-->00:27:46.999
produces a single PDF as output.
This is a portion of that PDF
that we generated during our our

00:27:46.999-->00:27:50.936
investigation. If you look at
the columns, they have
alphanumeric designations that

00:27:50.936-->00:27:56.475
uh indicate which genetic
location we're looking at uh on
the human genome. So these are

00:27:56.475-->00:28:03.549
our one through fifteen that FST
is looking at. The first row is
a reference profile. So this is

00:28:03.549-->00:28:08.253
somebody's uh DNA profile,
typically it would be the
defendant's DNA profile that

00:28:08.253-->00:28:12.491
they got from a cheek swab or a
blood draw. And uh we're making
an evaluation to see if that

00:28:12.491-->00:28:20.632
person could be a contributor to
the sample and the three lines
below the reference profile or

00:28:20.632-->00:28:25.504
the evidentiary profile is OCME
tests each uh evidence item
three times, two or three times

00:28:25.504-->00:28:31.243
to develop DNA profiles from
those items. So now FST is
intending to compare the

00:28:31.243-->00:28:36.715
reference profile to the
evidence profile to see whether
or not there's support that that

00:28:36.715-->00:28:42.354
person could have contributed
their DNA to that item. The
statistical weight is reported

00:28:42.354-->00:28:46.925
uh for four different
subpopulations in New York. Uh
Asian, Black, Caucasian, and

00:28:46.925-->00:28:53.065
Hispanic are the
desig-designations because DNA
has uh a tendency to be more

00:28:53.065-->00:28:58.403
similar between or within a
population than between
populations there is um going to

00:28:58.403-->00:29:02.874
be a different statistic
reported for each one of these
and in an effort to be

00:29:02.874-->00:29:07.613
conservative, the laboratory
will report the lowest of those
four statistics. The higher that

00:29:07.613-->00:29:13.952
number is, the more support
there is for this person
included, to be included as a

00:29:13.952-->00:29:22.494
contributor and um typically
that is an incriminating issue.
If the defendant's DNA is

00:29:22.494-->00:29:25.931
present on an item, typically
that's a bad situation for the
defense, so this is the

00:29:25.931-->00:29:31.837
laboratory's attempt to be
conservative, to report the
lowest uh statistic. So this is

00:29:31.837-->00:29:35.941
the significance of the
statistic. This is a likelihood
ratio. It says that the evidence

00:29:35.941-->00:29:41.480
that is these three rows of DNA
profiles generated from from
evaluating that sample is

00:29:41.480-->00:29:47.252
seventy times more probable if
the sampler originated from the
reference profile that is the

00:29:47.252-->00:29:52.124
defendant and two unknown,
unrelated individuals, so this
is a three person mixture the

00:29:52.124-->00:29:58.397
this is the prosecutions
hypothesis. They posit that the
defendant and two unknown,

00:29:58.397-->00:30:03.535
unrelated individuals
contributed their DNA to this
item as opposed to the defense's

00:30:03.535-->00:30:07.539
theory that it's just three
random people whose whose
identities we don't know. So in

00:30:07.539-->00:30:13.311
the comparison of these two
hypothesis, the statistical
weight is that it's seventy

00:30:13.311-->00:30:18.116
times uh more support for the
prosecution hypothesis. If the
prosecution hypothesis is true,

00:30:18.116-->00:30:25.123
rather than if the the defense
hypothesis. The issue with this
is that we have uh documentation

00:30:25.123-->00:30:32.898
of the validation studies
conducted by OCME in 2010. And
for this same sample, the same

00:30:32.898-->00:30:36.301
evaluation that I just showed
you, it wasn't seventy point
six, it should have been

00:30:36.301-->00:30:40.706
reported, it was one fifty
seven. So we were scratching our
heads when we came across this.

00:30:40.706-->00:30:45.077
It was just a sample that we put
through the executable of the uh
the executable version of the

00:30:45.077-->00:30:50.549
source code that we were
provided in this case. And so we
found that something was wrong.

00:30:50.549-->00:30:55.187
At first, of course I thought
that I hadn't configured my
version of it correctly. But

00:30:55.187-->00:31:00.125
after double and triple checking
everything, we realized these
were in fact two different

00:31:00.125-->00:31:06.832
values to be reported. There had
been no noise from OCME that it
this should be the case that

00:31:06.832-->00:31:11.002
this is the case that this will
be the case. So it was upon us
to identify what happened. So

00:31:11.002-->00:31:19.211
these fifteen genetic locations
we identified an issue where if
we ran the um so sorry, these

00:31:19.211-->00:31:24.983
are the different likelihood
ratios that were reported
between the 2010 validation

00:31:24.983-->00:31:31.323
study and the calculations I'm
doing in 2016. We realized that
in the the bottom most image

00:31:31.323-->00:31:35.393
you'll see that there are three
columns, that's three genetic
locations at which I did not

00:31:35.393-->00:31:40.565
give the system uh any
information about the DNA
present on the item. And it came

00:31:40.565-->00:31:47.105
up with the same seventy point
six value as if I had gave it
information at all fifteen

00:31:47.105-->00:31:51.877
locations. So this is uh this
was the smell test that led us
to uncover some code that was

00:31:51.877-->00:31:57.282
actually tossing data. So
they're without acknowledging it
to uh the analyst running the

00:31:57.282-->00:32:05.991
system to the defendant or even
saying to the world that they do
this OCME in 2011 had started

00:32:05.991-->00:32:11.263
tossing data uh based on some
rule within their system. So
this calls into question whether

00:32:11.263-->00:32:16.535
the validation study is is
relevant. Um because it's
studying a system that had been

00:32:16.535-->00:32:20.939
modified and uh pieces of
information were not being
considered any longer in the

00:32:20.939-->00:32:27.145
case work version. So as uh a
bit of a refresher, a likelihood
ratio above one is

00:32:27.145-->00:32:33.552
incriminating. The higher it is
above one, the stronger that
that evidence is supposed to be.

00:32:33.552-->00:32:42.828
A likelihood ratio below one is
generally exculpatory is
generally uh supporting um the

00:32:42.828-->00:32:48.900
the defense's theory. So when we
did a breakdown of this, we
identified that one of these

00:32:48.900-->00:32:52.270
locations actually has a
likelihood ratio. These
likelihood ratios are calculated

00:32:52.270-->00:32:57.475
at each lo-genetic location and
then multiplied together uh
using the product rule. But we

00:32:57.475-->00:33:02.914
identified that one of them was
actually exculpatory. So OCME uh
had told FST to throw out

00:33:02.914-->00:33:08.153
certain types of data and it
turns out that sometimes that
data is exculpatory. So they are

00:33:08.153-->00:33:12.357
removing information that
supports the defense's theory
without telling anybody,

00:33:12.357-->00:33:18.630
including the analyst case
worker running the system. Two
of these other locations for

00:33:18.630-->00:33:21.933
this particular sampler are are
inculpatory, so they would
support the inclusion of this

00:33:21.933-->00:33:24.469
person as a contributor, but
what we do know from the
validation study is this

00:33:24.469-->00:33:30.175
particular individual whose
reference profile we're we're
comparing is not a contributor

00:33:30.175-->00:33:37.515
to this system. So it is a false
positive that it's above one at
all. And we're kind of at a loss

00:33:37.515-->00:33:42.888
why it would be so high as a a
statistic of one fifty seven in
the validation study. And then

00:33:42.888-->00:33:49.094
after they make modifications to
the system, which now in 2017,
2018 they're purporting to make

00:33:49.094-->00:33:55.066
it an improvement to the system
or or that it has no substantial
impact. We're finding out that

00:33:55.066-->00:34:00.472
they're throwing out data uh
some of which should be uh
considered exclusionary, should

00:34:00.472-->00:34:04.342
be considered in supportive of
the defense's theory of the
case. The first public

00:34:04.342-->00:34:11.149
acknowledgement of this was in
2017. It was acknowledged by a
US attorney, an an assistant US

00:34:11.149-->00:34:17.422
attorney. So the first person to
publicly disclose that this was
in fact happening was uh a

00:34:17.422-->00:34:22.494
prosecutor. That is not uh a
biologist, that is not a
laboratory director, that is not

00:34:22.494-->00:34:28.667
a scientist of any sort, but but
uh a prosecutor. The protective
order that had been uh covering

00:34:28.667-->00:34:36.508
our investigation was vacated
after uh substantial effort by
uh ProPublica and the Yale Media

00:34:36.508-->00:34:43.648
of Freedom and Information
Access Clinic uh who who wrote
to the judge and asked for the

00:34:43.648-->00:34:50.188
protective order to be vacated
in the interest of of the public
good public interest. The OCME

00:34:50.188-->00:34:54.759
for some reason did not oppose
this. Uh and then ProPublica
posted the code online. So if

00:34:54.759-->00:35:04.235
you uh [applause] >> If you want
to go to this this GitHub repo
has everything that you need um

00:35:04.235-->00:35:10.041
data wise to get this running on
your system you will need some
some um Microsoft products

00:35:10.041-->00:35:15.747
though at least to make that
expeditious. So as a brief recap
and I'm sorry I need to-to wrap

00:35:15.747-->00:35:21.653
this up quick, but um twelve
samples were tested as a
regression test when this

00:35:21.653-->00:35:25.590
modification had been made. And
only two of those twelve had
samples where data was tossed.

00:35:25.590-->00:35:31.463
So we're modifying, they-they're
modifying FST in a way that is
is throwing out data and then to

00:35:31.463-->00:35:37.502
demonstrate that that doesn't
affect the operation of the
system. They only evaluated

00:35:37.502-->00:35:41.606
twelve samples but only two of
them were affected by the uh the
modification made. So we have an

00:35:41.606-->00:35:46.478
incredibly small sample size for
them to be basing their their
conclusions on and this is out

00:35:46.478-->00:35:49.948
of a total of four hundred and
thirty nine possible samples
that they could have evaluated

00:35:49.948-->00:35:55.854
in this regression test. So
that's uh a problem and then we
recently learned that they have

00:35:55.854-->00:36:01.860
had uh sixteen additional
quality control tests they call
it. Uh which could indicate that

00:36:01.860-->00:36:08.166
additional modifications to FST
have been made that we're not
aware of yet. It's only seventy

00:36:08.166-->00:36:13.038
lines including whitespace and
comments uh of the
modifi-modification that was

00:36:13.038-->00:36:18.309
made in 2011 uh so that's just
demonstrating how much uh a
little bit of code can affect it

00:36:18.309-->00:36:24.783
and we're just gonna run you
through a few quotes from uh
other from another case involved

00:36:24.783-->00:36:31.389
similar probabilistic genotyping
software. Uh and the reasons why
a defendants should not have uh

00:36:31.389-->00:36:37.862
access to the source code. The
responses include from a
developer of one of these

00:36:37.862-->00:36:42.667
probabilistic genotyping
systems, these complex software
systems, is that you don't use

00:36:42.667-->00:36:52.077
source code to validate
software. [laughter] And it
doesn't get better. [laughter] A

00:36:52.077-->00:36:56.347
professor of medicines says the
only reason you would need to
have source code is if you want

00:36:56.347-->00:37:06.458
to modify the program. Uh DNA
technical leader, this is in a
forensic DNA laboratory says we

00:37:06.458-->00:37:12.730
don't need the source code
because the source code isn't
normally used when we validate

00:37:12.730-->00:37:20.905
software. So we don't need it
because we don't need it.
Another laboratory director said

00:37:20.905-->00:37:26.878
that uh you know what, DNA
analysts only get one class in
statistics and typically none in

00:37:26.878-->00:37:34.452
computer science, so you know,
what are we gonna do with it?
[laughter] Well I'm here so you

00:37:34.452-->00:37:44.462
know. [laughter then applause]
[speaker laughs] [applause] So I
I think this is a great one to

00:37:44.462-->00:37:49.367
cap it off and then Jeanna will
take it over. So he poses a
question to the court—the-these

00:37:49.367-->00:37:52.704
are sworn declarations to a
court, by the way. They're not
just you know I was chatting

00:37:52.704-->00:37:58.443
with them and they told me these
things. Um, if I were discuss
errors in DNA testing, would you

00:37:58.443-->00:38:05.283
want to to capture and aerate
for the entire workflow, for the
entire DNA testing process?

00:38:05.283-->00:38:13.124
Yeah, exactly. [laughter] Like
uh ha ha is is that really a
question? So Jeanna's uh gonna

00:38:13.124-->00:38:21.366
explain what else we've got
going on. >>So um we, in
addition to this talk, we are uh

00:38:21.366-->00:38:29.007
we have uh Brown Institute Magic
Grant uh to do comparison
testing of probabilistic

00:38:29.007-->00:38:35.046
genotyping software systems.
We're s we're focusing on FST
with and without uh this uh

00:38:35.046-->00:38:41.619
check frequency for removal
function um and also comparison
to other systems. There are

00:38:41.619-->00:38:45.256
other open source systems
available. Um we're trying to
tell this story to a variety of

00:38:45.256-->00:38:53.531
audiences, including um
hopefully coverage in the press
for a general audience, uh to

00:38:53.531-->00:38:56.601
the technology audience like you
guys. And also to a legal
audience. We recently had

00:38:56.601-->00:39:01.406
articles in The Champion, which
is the a magazine for the
national association of criminal

00:39:01.406-->00:39:07.212
defense lawyers. And basically
we're arguing what I think all
of us in the room know perfectly

00:39:07.212-->00:39:14.385
well, that independent
third-party testing is
essential. And unfortunately

00:39:14.385-->00:39:18.990
independent third-party testing
of these systems are really
hard. It's hard to get access to

00:39:18.990-->00:39:23.861
the executables, to the
hardware, um and even if you do,
it's often under protective

00:39:23.861-->00:39:28.466
order or it's very expensive.
You know, it might be thirty
thousand dollars to get the

00:39:28.466-->00:39:33.271
program and five thousand
dollars to go to t-training, or
you might not even be able, it

00:39:33.271-->00:39:39.310
might even be sold to-to
independent testers. Um, it's
difficult to get old copies of

00:39:39.310-->00:39:44.315
the software or match up results
that were reported for a
particular defendants to the

00:39:44.315-->00:39:49.721
version that was applicable at
that time, let alone getting,
this is just access to

00:39:49.721-->00:39:54.959
executables. Let alone source
code or bug databases or testing
plans or design documentation or

00:39:54.959-->00:39:58.796
other things that would be
incredibly relevant to
understanding what the heck is

00:39:58.796-->00:40:03.601
going on. And even if you
acquire these things, there's
often terms of service that

00:40:03.601-->00:40:11.209
limit the publishing of results.
How crazy is that? This problem
of trade secret protection

00:40:11.209-->00:40:17.148
aggressively being claimed over
the rights of the public and of
defendants, we feel is often

00:40:17.148-->00:40:22.754
done really to shield from
legitimate questions of quality
and fairness. Legitimate

00:40:22.754-->00:40:29.060
questions of quality and
fairness. Much more so than to
protect from competitors. And it

00:40:29.060-->00:40:34.098
is fundamentally thwarting the
essential iterative improvement
and accountability to

00:40:34.098-->00:40:40.238
stakeholders beyond buyers. If
the people purchasing this
software are basically just

00:40:40.238-->00:40:43.741
asking the question are we
sending to people to jail? Ok
good. Then we have a big

00:40:43.741-->00:40:51.382
problem. Um and there's also
difficult to connect audiences.
If you were to find a bug in

00:40:51.382-->00:40:57.055
FST, how would you be hooked up
to that particular defense
attorney that might, that bug

00:40:57.055-->00:41:04.495
might be relevant? Um and we
would really love you to help.
What are some ways you can help?

00:41:04.495-->00:41:10.501
Um help just listening to this
talk. You say to yourself, I
could have debunked those

00:41:10.501-->00:41:16.908
quotes, right? And I have some
serious credentials. Why don't
they ask me? So if you that to

00:41:16.908-->00:41:25.049
yourself, we could hook you up
with some defense attorneys that
could help you say those things.

00:41:25.049-->00:41:29.020
Um also, we would really love to
see um advocacy for um
requirements in the procurement

00:41:29.020-->00:41:34.759
phase of software. Once it's in
use, under you know certain
terms of service, or whatever,

00:41:34.759-->00:41:37.862
it's harder but why not say if
we're gonna use public money for
criminal justice software,

00:41:37.862-->00:41:42.500
require would be great or at
least give a lot of credit in
the procurement phase for source

00:41:42.500-->00:41:47.538
code. Software artifacts like
bug reports, internal testing
plans, software requirements, um

00:41:47.538-->00:41:52.877
no clause is presenting ah
preventing third-party review.
How hard would that be? Come on.

00:41:52.877-->00:41:57.915
Access to ex-executables for
third-party testing under
reasonable conditions. And

00:41:57.915-->00:42:02.887
here's a big one. Scriptable
interfaces to facilitate
automated testing. You can get

00:42:02.887-->00:42:06.858
your hands on these things and
if you want to run it through,
you know, a a thousand sample

00:42:06.858-->00:42:13.898
test, you know, what are you
gonna do that by hand? Um bug
bounties for finding things

00:42:13.898-->00:42:17.502
would be great. Uh funds for
nonprofit third-party entities
to do independent testing. All

00:42:17.502-->00:42:21.906
these things would be on our
wishlist. We'd love to see you
be third-party reviewers. Go get

00:42:21.906-->00:42:27.812
your hands on FST or Lab
Retriever or LRmix or LikeLTD or
EuroForMix, other open source PG

00:42:27.812-->00:42:32.683
systems, predictive policing
software like CivaScape, take a
look. Find some bugs or bad

00:42:32.683-->00:42:37.455
code. Please, do something about
it yourself, but also let us
know. Um, construct software

00:42:37.455-->00:42:42.260
yourself, based on published
alternatives and then compare
the results you're getting to

00:42:42.260-->00:42:46.764
the black boxes. So many things
our community could do to change
this conversation. Please help

00:42:46.764-->00:42:52.870
us do that. Um and the big
picture is that black box
decision making is happening all

00:42:52.870-->00:42:58.543
around us. And our community
could do a lot to bust open
those black boxes or compare

00:42:58.543-->00:43:04.949
them to one another or to fight
for accountability and
transparency. Um the association

00:43:04.949-->00:43:08.886
for computing machinery tech
policies groups came out with a
set of principles for

00:43:08.886-->00:43:12.323
algorithmic accountability and
transparency. That could be a
place to start if you're

00:43:12.323-->00:43:16.194
involved in building software
systems. You could point your
team and your boss and your

00:43:16.194-->00:43:20.498
company to this is some
professional ethics guidelines
that say we should be building

00:43:20.498-->00:43:24.368
an awareness, access and
redress, accountability,
explanation, data provenance,

00:43:24.368-->00:43:29.774
audit-ability, validation, and
testing. We can all do a lot to
provide the evidence that's

00:43:29.774-->00:43:35.279
needed to improve systems for
all stakeholders. So that we're
not running our society on buggy

00:43:35.279-->00:43:41.018
or possibly even malicious
algorithms that are hidden from
view. We would like to thank the

00:43:41.018-->00:43:47.391
many people uh without whom our
work would not be possible. Um a
special shout out to we have

00:43:47.391-->00:43:52.663
four of our students who are are
working with us here in the
crowd, uh Mariama, Marzieh,

00:43:52.663-->00:44:00.104
Stephen, and Abby. [applause]
you guys could wave. Um
[applause] and I will simply end

00:44:00.104-->00:44:06.911
with um please get in touch with
us, if if you if you think you
can help with this effort. In

00:44:06.911-->00:44:13.050
full disclosure, the best way to
get a hold of us is probably the
three direct emails, but uh we

00:44:13.050-->00:44:17.855
tried to set up some more joint
ways uh we we set up a Twitter,
Software Justice, it's just

00:44:17.855-->00:44:23.494
recently set up so um be gentle
with it. We also set up a
discord channel. Um if you find

00:44:23.494-->00:44:28.533
us Software Justice on Twitter,
there's a recent uh link with an
invitation to our discord

00:44:28.533-->00:44:34.071
channel. We're working on
setting up a sub uh a subreddit
for Software Justice uh but it's

00:44:34.071-->00:44:40.845
not uh up yet. But please uh,
get a hold of us and uh let's
all work on this 'cause I think

00:44:40.845-->00:00:00.000
our community could make a big
difference and a big difference
is really needed. [applause]

