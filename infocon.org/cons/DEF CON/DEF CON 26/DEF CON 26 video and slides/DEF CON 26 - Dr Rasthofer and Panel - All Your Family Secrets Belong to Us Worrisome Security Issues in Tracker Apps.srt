00:00:00.868-->00:00:06.940
[Applause] >> Ya, thank you, for
the short introduction. Um I'm
Siegfried and this is my

00:00:06.940-->00:00:12.579
colleague ah Stephan and today
we'll talk about our, ah,
tracking application

00:00:12.579-->00:00:18.418
investigation. Ah we are both
from Germany, from a research
institute called Fraunhofer SIT.

00:00:18.418-->00:00:24.258
Its located in Darmstadt close
to Frankfort. Um, few words
about my, ourselves so I'm

00:00:24.258-->00:00:29.863
Siegfried. I'm leading a
research group at this research
institute called secured

00:00:29.863-->00:00:34.401
software engineering and our
main focus is on static and
dynamic code analysis. So

00:00:34.401-->00:00:39.373
writing new analysis in order to
find vulnerabilities in
binaries, as well as soft, uh,

00:00:39.373-->00:00:45.779
source code, and was the founder
of team called TeamSIK, which we
will say in a second and the

00:00:45.779-->00:00:49.783
founder of code inspector which
is a reverse engineering for
tool for android. So, Stephan

00:00:49.783-->00:00:54.321
would you like to say a few
words about yourself. >>Ya
hello. My name is ah Stephan and

00:00:54.321-->00:00:59.693
I belong to the Testlab mobile
security group. I'm also
developing static and dynamic

00:00:59.693-->00:01:05.432
analysis tools and in my spare
time I'm digging around bit with
IOT stuff and together with

00:01:05.432-->00:01:11.638
Siegfried I'm a co-founder of
our hacking team. >>Thank you.
So, we talked about this

00:01:11.638-->00:01:18.211
TeamSIK, so what we present
today is not, um, the results of
our, of both of us, it's

00:01:18.211-->00:01:22.816
basically the results of the
team, which is called TeamSIK.
So what is it? A few words about

00:01:22.816-->00:01:29.389
it. It's a research, it's ah
hacking group so we meet once a
week in our spare time. So, the

00:01:29.389-->00:01:34.494
team cons, the team consists of
researchers of the research
institute as well as students

00:01:34.494-->00:01:40.167
around our Universities, uh
around the university and um, so
we usually look into different

00:01:40.167-->00:01:45.005
interesting projects, then we
try to find someone abilities
and that's basically the goal to

00:01:45.005-->00:01:48.875
learn from each other. So, the
credits definitely goes to those
brilliant students and

00:01:48.875-->00:01:54.381
researchers mentioned below. Two
of them are actually here in the
audience. Good, so before we

00:01:54.381-->00:01:59.386
start with the talk um a short
beer announcement, um, since we
are uh, well you already know,

00:02:01.655-->00:02:05.826
we are from Germany and actually
from Munich well close to Munich
thought it might be a yet

00:02:05.826-->00:02:12.799
another cool idea to bring or
import some boxes of beer and
since this is our 3rd, first, ah

00:02:12.799-->00:02:17.804
Defcon talk [speaker laughs] ah
we imported 2 boxes of beer this
year, so, after the talk feel

00:02:21.475-->00:02:26.480
free to come and grab a cold
beer. There are 40 bottles for
you guys. [audience cheers and

00:02:30.817-->00:02:36.356
claps] Thank you. So, let's get
started. Ah. Short agenda for
today, um I'll start with a

00:02:36.356-->00:02:40.894
little motivation, um, and then
do a little background
information and then we dig into

00:02:40.894-->00:02:46.867
our results of our security
findings ah first topics is
client-side authorization. I

00:02:46.867-->00:02:51.705
will explain what I mean by
that. Then we will talk about
the client-side vulnerabilities

00:02:51.705-->00:02:56.209
and then we will talk about
server-side vulnerabilities. In
the end, a few words about

00:02:56.209-->00:03:02.549
responsible disclosure because
this was funny this year, and ah
summary in the end. Good,

00:03:02.549-->00:03:07.554
motivation. Um so when I started
um, we started um, putting the
slides together I said how can I

00:03:09.589-->00:03:14.661
motivate tracker application so
while you first of all think
about surveillance. So looked a

00:03:14.661-->00:03:20.634
little bit up online and I found
a cool block post about a CIA
museum and well instance in the

00:03:20.634-->00:03:26.039
60's already there was um, um,
radio receivers inside of pipe,
so very small stuff which was

00:03:26.039-->00:03:32.646
interesting to see. In the 60's,
again, like ah camera inside a
pack of cigarettes to hide

00:03:32.646-->00:03:37.651
into-to video record the
environment. And in the 70's um
like a microphone fit already

00:03:40.053-->00:03:45.425
into a dragonfly ah in order
to-to spy on people. So guess
you already get it that was the

00:03:45.425-->00:03:50.363
past so how is it right now? I
guess we all have it in our
pocket. Um, it the smart phone.

00:03:50.363-->00:03:57.137
Um, well because there is like
sensors in it like GPS and this
kind of stuff so you get a lot

00:03:57.137-->00:04:02.275
of information from people. Um,
this is the reason why there
already spyware and wraps um,

00:04:02.275-->00:04:06.880
abusing this um, this stuff
and-and-and extracting all the
information and using it for

00:04:06.880-->00:04:11.785
whatever reason. Um, what we
also ask ourselves or we ask are
there any benign reasons good

00:04:11.785-->00:04:16.790
reasons to use such kind of apps
or surveillance apps or tracking
applications. And then we found

00:04:19.159-->00:04:24.564
3 different topics which was
interesting. First of all, app
families. So, there are apps out

00:04:24.564-->00:04:30.437
there where adults want to know
where their child's are. So they
want to know if they are safe in

00:04:30.437-->00:04:35.308
the environment based on a
location information. Um, there
are couples, which was

00:04:35.308-->00:04:41.281
interesting like, track my
boyfriend, track my girlfriend
apps. Um I don't know why they

00:04:41.281-->00:04:46.186
do this. So, they mutually agree
on installing the application
and whatever to check if they

00:04:46.186-->00:04:50.824
are not cheating on each other.
I don't know. But there are many
of them out there. And friends

00:04:50.824-->00:04:56.830
as well. So, while you want to
know where your buddy is in
order to meet or whatever. So

00:04:56.830-->00:05:01.168
there are benign reasons. The
question is how do you
differentiate between the good

00:05:01.168-->00:05:05.305
and the bad now, right. Because
from the implementation
prospective both are implemented

00:05:05.305-->00:05:10.911
in the same way. So, for this we
looked up on Google play and we
found these kind of apps so we

00:05:10.911-->00:05:15.849
thought there might be a
definition. What are good apps
and what are bad apps. So, I

00:05:15.849-->00:05:22.789
found ah, well one of them us a,
The Android Security Report that
stated, that ah commercial

00:05:22.789-->00:05:28.261
spyware is any application that
transmits sensitive information
off the device without user

00:05:28.261-->00:05:33.466
content um, doesn't display a
persistent notification that
this is happening. So this means

00:05:33.466-->00:05:37.771
if you wanna install a benign
tracking application and if you
wanna upload it to the play

00:05:37.771-->00:05:41.308
store you need to show the
monitor person notifications
like, whatever, right now I'm

00:05:41.308-->00:05:45.345
accessing your um, location
information whatever and I'm
sending it to your mom,

00:05:45.345-->00:05:51.551
some-some kind of this. If this
is the case then this is ah
legitimate app and if not its um

00:05:51.551-->00:05:56.590
considered a spyware and it
shouldn't be in the play store.
This is at least ah, what we

00:05:56.590-->00:06:02.996
found. Good. So, so we've only
focused on this in your talk on
your project on those legitimate

00:06:02.996-->00:06:08.201
apps um, and we ask ourselves
the questions cause they are
collecting a lot of data um, how

00:06:08.201-->00:06:13.206
well is the collected data
protected. On the client-side or
on the server side. For that um,

00:06:16.176-->00:06:20.880
we looked up as I said, Google
play store, we typed in tracking
application, track my boyfriend,

00:06:20.880-->00:06:22.882
track my girlfriend and then we
found 19 different apps. Why is
this an odd number? Well we just

00:06:22.882-->00:06:24.884
founded a few of them the first
hints and at some point we
stopped. And then we found so

00:06:24.884-->00:06:29.889
many vulnerabilities that at
some point we got bored and this
is the reason why there are 19.

00:06:32.926-->00:06:37.931
This is no special reason for
19. So we looked at we at least
those um, that have um, the most

00:06:43.003-->00:06:49.643
installations um uh based on
google play store statistics.
And another point is we only

00:06:49.643-->00:06:54.481
look for free applications so I
know that there are a lot of
commercial spyware applications

00:06:54.481-->00:07:00.654
out there. Those where not um,
the target in this um, project.
Only the ones that you can

00:07:00.654-->00:07:07.560
download for free. And you get
for free. And can use for free.
So as a spoiler um, we found 37

00:07:07.560-->00:07:12.432
different vulnerabilities in
total. A very very sensitive
ones. And um well in this talk

00:07:12.432-->00:07:19.339
we will show a few of them or at
least a few categories of them.
Good um, well before we sssss ya

00:07:19.339-->00:07:25.378
the takeaways of this talk um so
what will you learn today um, I
have to tell you that if you

00:07:25.378-->00:07:31.718
expect any sophisticated exploit
in this talk unfortunately I
have to disappoint you. So It

00:07:31.718-->00:07:38.591
was in this project very easy to
get access to this highly
sensitive data and even to do

00:07:38.591-->00:07:43.596
mass surveillance in real time.
Um and we usually play this game
of um, can we upgrade the

00:07:45.632-->00:07:51.237
applications which you have to
pay for premium features be
up-upgraded for free and ya, we

00:07:51.237-->00:07:56.276
will also say a few words about
that. And yes it was possible
again this year. Good um, and

00:07:56.276-->00:08:01.014
then we come to the background
information just very very um
small background information

00:08:01.014-->00:08:07.520
very easy set up that your all
on the same page. So how does
this work? So usually you have

00:08:07.520-->00:08:12.258
this application and you have an
observer and a monitor person
and both install this

00:08:12.258-->00:08:17.097
application and then there is
some kind of pairing process
where they know ok I belong to

00:08:17.097-->00:08:22.602
this guy or whatever or I can
monitor this person and on the
monitored side well it collects

00:08:22.602-->00:08:27.040
all this sensitive information
like location end zone and sends
it to the backend and on the

00:08:27.040-->00:08:31.544
backend side you basically
observe a pulse the information
saying right now I want know

00:08:31.544-->00:08:38.151
where my kid is or whatever. So
this-ah this means on the
backend side there are

00:08:38.151-->00:08:44.023
information like location
information and call history
text messages Whatsup messages,

00:08:44.023-->00:08:49.529
whatever and apart ah- couple
applications also had the cool
features of installing a

00:08:49.529-->00:08:53.967
messenger into this tracking
applications of this means that
you can chat with your

00:08:53.967-->00:08:59.806
girlfriend or whatever. So you
can also send pictures and
videos and this is important for

00:08:59.806-->00:09:06.012
the remaining talk. So all this
data are stored in the backend.
So what are the attack factors

00:09:06.012-->00:09:12.252
here? Well like I said the usual
gain can be upgrade um, premium
features for free, so we will

00:09:12.252-->00:09:17.357
say a few words about that. Then
obviously the 2 complications
channels um, can be a man in the

00:09:17.357-->00:09:20.393
middle and how was it
implemented and how was the
product implemented and we will

00:09:20.393-->00:09:25.398
say a few words about that. And
the ah last um, attack factor is
um the backend basically. Good

00:09:28.234-->00:09:33.973
so in the following we will talk
about all of those 3 stages now.
First client-side authorization.

00:09:33.973-->00:09:40.780
Um, so before I do this I stop
cause we all know this just to
get-get clear, what-how and what

00:09:40.780-->00:09:46.119
it means to access the sensitive
data, so you have an observer
and you would like to access

00:09:46.119-->00:09:50.757
sensitive data or data from the
backend. So there usually 2
steps involved. First

00:09:50.757-->00:09:54.894
authentication, including
identification and then
authorization that your

00:09:54.894-->00:10:01.835
authorized the check on the
backend that which checks if
your allowed to access this

00:10:01.835-->00:10:08.508
data. We all know this but I'm
just saying. Um. And then what
we saw is usually, so there was

00:10:08.508-->00:10:13.580
most of the time this kind of
authentication process. Many
times broken many times there

00:10:13.580-->00:10:19.319
was none but at least it wasn't
there. Then there was something
where we found a client-side

00:10:19.319-->00:10:25.625
authorization and I will explain
this ah in second. So I will
show you 4 different examples of

00:10:25.625-->00:10:30.630
what we found out which was not
okay. Good. The first one um, ya
as I said the usual gain of

00:10:32.765-->00:10:38.171
premium features. So this kind
of applications contains um
features which are disabled by

00:10:38.171-->00:10:43.042
default and if you pay whatever
5 dollars or something like
this, then you get super cool

00:10:43.042-->00:10:48.548
premium features one of them are
for instance um, removing
advertisement that you've rid

00:10:48.548-->00:10:53.253
[speaker stutters] that you're
not seeing advertisement
anymore. Very easy. So, we ask

00:10:53.253-->00:10:58.825
ourselves um how was this
implemented to for instance to
get rid of the advertisement and

00:10:58.825-->00:11:05.331
then we looked into the code.
And we found the following um,
shared preferences get Boolean

00:11:05.331-->00:11:11.638
`l_ads` for instance then there
was a check if removed so if
this flag is set to true, if yes

00:11:11.638-->00:11:17.844
then they basically disable
thi-this few on the client side.
For those of you who don't know

00:11:17.844-->00:11:22.482
the code here or wh-wh-what the
shared preferences is in
android. Shared preferences is a

00:11:22.482-->00:11:27.487
file that comes with the
application um, it's a XML based
file and it has a key value pair

00:11:29.756-->00:11:35.195
so in this case `l_ads` for
instance was set to faults. If
you set it to true then you can

00:11:35.195-->00:11:41.568
basically get rid of the um,
advertisement um the question is
for those who don't know it can

00:11:41.568-->00:11:46.272
how can we manipulate this file
while there are basically 2
ways. First one if you have a

00:11:46.272-->00:11:52.045
routed device, it's very easy to
change this um, value on a
un-routed device you and the

00:11:52.045-->00:11:56.649
application allows you to backup
so you backup the application
including this file. Then you

00:11:56.649-->00:12:01.788
can then you do modify a file
and then you restore it. This is
all known and well known from

00:12:01.788-->00:12:08.228
learned from the past. Then when
we look into this ah shared
preferences file, we found some

00:12:08.228-->00:12:13.233
other cool settings there. So
one of them was SMS full. So SMS
full is like um for a monitor

00:12:15.702-->00:12:22.508
person, all the text message are
basically can be um, can be
accessed by the observer. Um. So

00:12:22.508-->00:12:26.846
for the first text message
because they want to know if the
girlfriend or the boyfriend is

00:12:26.846-->00:12:31.217
cheating or whatever so they
want to ah, exactly know what's
going on and as I already

00:12:31.217-->00:12:36.122
mentioned so if you said this
one guy from faults to true, uh
oh yeah sorry, I forgot to say

00:12:36.122-->00:12:42.028
what this full mean. This full
means if you did not pay, you
only get first x characters of

00:12:42.028-->00:12:47.634
the text message and if you pay
then you get the complete text
message as an observer. Um, well

00:12:47.634-->00:12:52.438
if you set it to true we already
learned this right now then you
get the full text message. But

00:12:52.438-->00:12:56.776
the question is how is this
implemented. It was implemented
in such a way so that the

00:12:56.776-->00:13:02.081
observer basically says, hey,
please give me all text messages
from this guy or from my kid or

00:13:02.081-->00:13:06.953
from my girlfriend and then the
service says ok then sure, you
get the complete text message.

00:13:06.953-->00:13:12.191
Text message 1, 2, 3 like the
complete one and then at the
client-side there was a check

00:13:12.191-->00:13:17.764
like, okay, so if you did not
pay, I only show the first 50
characters. And if this is not

00:13:17.764-->00:13:22.802
the case you, basically see the
complete text message and this
was a little bit funny to see

00:13:22.802-->00:13:27.807
and you shouldn't do this.
[audience laughs] Ya because I
mean come on [presenter laughs]

00:13:29.976-->00:13:34.981
so ya [presenter laughs] what
the f**k. Um, good so next
stage, ah, second stage of of

00:13:38.584-->00:13:45.391
this kind of box where um, so as
I said there are basically these
2 roads you all have a parent

00:13:45.391-->00:13:51.330
which has the admin role and
then you have your kid which has
a le-less privileges and if you

00:13:51.330-->00:13:56.302
are an admin you can um create a
new admin or whatever and if
while um you can monitor

00:13:56.302-->00:14:02.208
basically your kid. And the
question was okay how do these
apps differentiate between an

00:14:02.208-->00:14:09.148
admin or a a a a parent and a
child a children. So and the
question was ya there's a shared

00:14:09.148-->00:14:15.455
preferences file and there is a
set called east parent and if
this guy is set to true, um then

00:14:15.455-->00:14:21.527
your parent and your admin so
this means that if you are the
kid and you change your shared

00:14:21.527-->00:14:25.331
preferences file to true then
you are an admin and you can spy
back to your parents if you

00:14:25.331-->00:14:30.336
want. [audience laughs and
applauds] Good, next stage and
another example of this kind I

00:14:35.908-->00:14:41.614
guess you already get this um,
thing there was this application
that contained um additional

00:14:41.614-->00:14:46.619
security protection mechanisms
which um, once you opened the
application umm you can enter a

00:14:48.888-->00:14:53.559
pin and then it asks you for the
pin and if you enter the correct
pin then you ow- ad then you can

00:14:53.559-->00:14:58.531
access the the application and
the data in the application. So
this is ah ah good security

00:14:58.531-->00:15:04.504
feature. The question again was
ah how was this implemented and
I guess you already get this

00:15:04.504-->00:15:10.643
kind game now. There was a flag
in the shared preferences file.
This time pflag so it's not so

00:15:10.643-->00:15:16.716
directly pointed to remove ah,
to lock screen or something and
if you set this to false then

00:15:16.716-->00:15:21.420
you do not see any lock screen
at all. Even if you edit a pin
or something you can directly

00:15:21.420-->00:15:26.425
access the data there. Ya. And
last but not least um obviously
the same also worked for log in,

00:15:29.629-->00:15:35.701
so honestly so there is an is
login and if you were logged in
before so the store basically

00:15:35.701-->00:15:41.307
user and a password and if you
set this guy to true it
automatically locks you in even

00:15:41.307-->00:15:47.513
without typing the user name and
password. Again shared
preferences. I mean ya . So the

00:15:47.513-->00:15:52.118
last slide here in this case is
please don't use shared
preference for authorization

00:15:52.118-->00:15:56.856
checks. So for those of you who
are buck hunters so please look
into shared preferences it's

00:15:56.856-->00:16:02.495
always fun and you find a lot of
stuff. And for developers please
don't use this again. We talked

00:16:02.495-->00:16:09.302
about this 2 years ago and last
year about shared preferences
and ya. There are for sure more

00:16:09.302-->00:16:13.773
apps that um don't under- or
developers that don't understand
this so please don't do this

00:16:13.773-->00:16:19.478
again. Good so this was it from
my side I will now hand over to
Stephan who will continue um

00:16:19.478-->00:16:26.385
with the remaining slides. >>
Okay tha-thank you. Um I will
explain the rest of our findings

00:16:26.385-->00:16:31.324
and vulnerabilities now. First
the the client-side and
communication vulnerabilities.

00:16:31.324-->00:16:37.930
And um for the people who are
not aware about the concept ah a
few words about um the man in

00:16:37.930-->00:16:42.935
the middle attacks. The basic
idea is just to to get as an
attacker between the

00:16:42.935-->00:16:48.374
communications. So between the
user and the backend and try to
eavesdrop or even manipulate the

00:16:48.374-->00:16:53.613
communication. If for instance
the app communicates in plain
text this would be very easy for

00:16:53.613-->00:16:59.719
an attacker we can cause he can
read everything change data and
so on. Another case would if the

00:16:59.719-->00:17:06.626
app has implementation laws like
it uses broken inscription or
has um errors so that the

00:17:06.626-->00:17:11.631
attackers easily can can bypass
the inscription and the last
step so this would be ah the

00:17:13.633-->00:17:18.938
only reliable protection against
many middle attacker to
implement secure correct and um

00:17:18.938-->00:17:24.644
and confidential integrity
protected authenticated um
communication. So, our first

00:17:24.644-->00:17:30.950
step, as I mentioned to the man
in the middle attack we had a
application where is was

00:17:30.950-->00:17:35.955
required to sign in and we
wanted to know how secure this
ah is um log in process. So as a

00:17:38.858-->00:17:43.763
user, you have to enter your
credentials as an attacker we
observe them the first thing

00:17:43.763-->00:17:49.402
that you can see is a http
connection so it's plain text.
So man in the middle attacker

00:17:49.402-->00:17:54.440
would be able to read the plain
text credentials but as you can
see in this GET request, they

00:17:54.440-->00:17:59.445
are not our credentials. So we
replied a few times to get to
see some pattern and as you can

00:18:02.381-->00:18:07.386
see, we have different parameter
names and different parameter
positions but we always have 2

00:18:10.723-->00:18:16.996
um, same parameter values. So
this this looks interesting and
we we dig now in-onto the code

00:18:16.996-->00:18:22.935
to find more um about the
implementation. The first thing
we saw was our hot coded

00:18:22.935-->00:18:29.575
encryption key. Reverse
engineering then this algorithm
we saw ok, the user data, the

00:18:29.575-->00:18:34.580
user name XOR with this key
base64 encoded and there was a
pretty fine set of um, random

00:18:38.017-->00:18:44.123
values. One of them was randomly
picked and combined with the um
user name. This is the same

00:18:44.123-->00:18:50.029
procedure for the ah um
password. So this means if that
now as the man in the middle of

00:18:50.029-->00:18:56.302
the attacker observe the traffic
we just simply take the value,
decode it, xor'ed it and we get

00:18:56.302-->00:19:01.240
the credentials in plain text.
The other parameters we saw so
where um garbage. So we had 2

00:19:03.776-->00:19:08.981
additional parameters that were
also randomly selected from a
predefined set and but they had

00:19:08.981-->00:19:15.054
no no value and this this is
some kind of obfuscation we
don't know why are this would

00:19:15.054-->00:19:21.961
stand by the developer but um
it's the wrong way. So, as I
said, if you were able to

00:19:21.961-->00:19:28.100
eavesdrop this data you can
decrypt it can get the log in
data and authenticate. How to do

00:19:28.100-->00:19:33.539
it rightly in android so secure
communication is not so hard.
You just have to do an https

00:19:33.539-->00:19:38.544
connection, use TLS 1 dot um 2
or then later 1 dot 3. You just
need a valid service certificate

00:19:41.180-->00:19:46.185
to get it for free for instance
from Let's Encrypt and on the um
android side doing ah https is

00:19:48.387-->00:19:53.392
very easy. Define a new ah URL
object, open a connection. Ya an
an that's all. Then it's done.

00:19:56.395-->00:20:01.400
Um k. So the next thing we saw
problems with authentication. Um
as Siegfried already mentioned,

00:20:06.105-->00:20:11.610
um the apps are transferring all
the the tracking and location
data to some kind of backend. In

00:20:11.610-->00:20:18.517
most cases, this backend hosts
the database. And if you want to
connect to a database, ah for

00:20:18.517-->00:20:22.321
instance an android, you have to
for instance instantiate the
database driver and then you

00:20:22.321-->00:20:27.693
have to establish a connection.
Now what we-we saw in the
application is typically a

00:20:27.693-->00:20:33.332
Patton how you should not do it
in an application. At first they
established the connections so

00:20:33.332-->00:20:39.438
you need the URL. You need your
log in name and you need a
password. And the problem now is

00:20:39.438-->00:20:44.643
that the password is stored in
the application. This means
everybody who has access to this

00:20:44.643-->00:20:50.616
application or to this code can
simply extract the password so
when the user name has the URL

00:20:50.616-->00:20:57.189
and has complete access to the
backend storage where all the
data was stored. We have a few

00:20:57.189-->00:21:02.828
apps that you will see uh um
simplified um database schemes
so this backend stores the email

00:21:02.828-->00:21:08.534
address, some name, and
especially also the location
information. And in our findings

00:21:08.534-->00:21:13.539
we had in common 860 thousand
um, tracking apps uh locations
and even if you make regular

00:21:16.976-->00:21:23.115
requests of quarry you also can
um observe or tra-track the
people in real time cause the

00:21:23.115-->00:21:28.120
app regularly sends um updated
data to this um database. Um
that's not all. Um of course so

00:21:33.259-->00:21:40.166
when we looked also in the code
a bit um a step further. We
thought okay ya SQL um so they

00:21:40.166-->00:21:44.937
for SQL you should in the right
way you should use prepared
statement. You can see okay they

00:21:44.937-->00:21:50.543
already define a prepared
statement and now we will expect
some some method which will set

00:21:50.543-->00:21:56.482
the values in this statement.
But what we see was they
override the prepared statement

00:21:56.482-->00:22:01.554
with the concatenated statement
and as a user you can for
instance control the email

00:22:01.554-->00:22:08.093
address and in this sample that
you see here, is a classic SQL
injection vulnerability. So

00:22:08.093-->00:22:13.098
th-the app was broken already by
this sign but we stumbled above
this additionally. So, I don't

00:22:15.634-->00:22:21.407
want to be unpolite but this is
really stupid code. [audience
laughs] Okay now there are more

00:22:21.407-->00:22:27.746
exciting things, let's get to
the servers, um, which are
hosting all the data's. Um

00:22:27.746-->00:22:32.785
Siegfried already introduced we
have an we need a authentication
process and authorization

00:22:32.785-->00:22:39.325
process and we um try to analyze
and find if there are problems,
design flaws, or rather

00:22:39.325-->00:22:46.265
vulnerabilities to bypass or to
break this uh um processes. So
we have deferent let's say

00:22:46.265-->00:22:53.038
stages of vulnerabilities and
findings, in some fife and um I
will now explain the different

00:22:53.038-->00:22:59.812
findings on the server side. So
the first thing is not really a
vulnerability its more um, let's

00:22:59.812-->00:23:04.750
say a feature or ah um, a
usability thing. Um. Um. The
application after the

00:23:06.919-->00:23:11.924
instillation by design or by
default a-an option that says
all located and tracked data are

00:23:15.694-->00:23:21.233
sent to the backend and
everybody has excess. This means
they are freely accessible. So

00:23:21.233-->00:23:26.839
this is kind of let's say design
flaw. A better option would be
some op in where a default is

00:23:26.839-->00:23:31.877
not everybody can access it and
if the user agrees, he can
activate that everyone can

00:23:31.877-->00:23:37.449
access this data. How you can
look at this data or how you can
access it is very easy you just

00:23:37.449-->00:23:43.822
need to know the website and the
user name of the person you want
to track or want to listen and

00:23:43.822-->00:23:48.827
for this we have prepared a
short um demo video. So if you
go to the website, um, you just

00:23:52.665-->00:23:59.471
as I said you have to know the
URL of the website. Then you
have to answer ah ah a user

00:23:59.471-->00:24:04.410
name. for this we choose a
random user name we call the
user the sexy. If you open it,

00:24:07.980-->00:24:12.985
you already see, you get some
some tracking on on Google maps
and now you can open um details

00:24:15.554-->00:24:20.559
to see when the track was
stored. You also click on-on
this um track button you get the

00:24:23.462-->00:24:29.368
correct location when the track
was stored the starting time. Um
you get some some kind of

00:24:29.368-->00:24:34.373
profile information the altitude
and so on. You also see a
altitude diagram. And now you

00:24:37.743-->00:24:42.748
can also track or reply the
track the person you can see
okay he is entering his car, you

00:24:49.188-->00:24:55.361
see his speed. He's driving
around. Cause with the
connection with Google maps, you

00:24:55.361-->00:25:01.200
can also zoom in or look in
details so they can see okay the
person is going to some some

00:25:01.200-->00:25:06.205
school. He's driving around and
so on. It's also a bit curious.
This this in this track this

00:25:11.944-->00:25:18.050
person who is going to a school
at 1 pm he is moving between the
school and the ATM several

00:25:18.050-->00:25:23.055
times. Don't ask what she is
doing or he's doing there and ya
at the end she is just going

00:25:25.791-->00:25:30.796
back to his um um home address.
Okay. As I said this was just a
feature, this was not really a

00:25:35.801-->00:25:41.807
bug but this is not all we also
stumbled about a bug in this
website. So this is not a

00:25:41.807-->00:25:47.813
feature, this is a bug in form
of an XSS. So, next step,
authentication problems.

00:25:47.813-->00:25:53.619
Sometimes you have the,
impression ya, authentication
what. Um we took another

00:25:53.619-->00:25:58.624
application, if you look at the
traffic of the application or
reverse engineering the code,

00:26:00.793-->00:26:07.800
you see some http request there,
so already mentioned, nothing
new. Plain text communication.

00:26:07.800-->00:26:12.805
Then we have a user id. The user
id is the id of the user itself
so th-the person who wants to

00:26:15.073-->00:26:21.713
monitor something. This user id
was protected by Caesar
encryption. I don't know why um,

00:26:21.713-->00:26:28.120
makes no really sense. [audience
laughs] Then we have the child
id. This is the id of the person

00:26:28.120-->00:26:33.125
you want to observe. This is a
simple 10 digit large number and
we have the current date. This

00:26:36.061-->00:26:41.066
is the date where the last um
tracking of the person was
stored. And as you can see, this

00:26:41.066-->00:26:46.071
is not a very complex request if
you can also try it or guess
this child id if the person who

00:26:48.073-->00:26:53.579
you want to monitor. If you
enter this, the host responds
the whole track of the person.

00:26:53.579-->00:26:59.585
We choose this um tracking data
and printed it into some Google
maps and here you see some

00:26:59.585-->00:27:05.224
tracking profile of one of our
students. And this is completely
um assessable without any

00:27:05.224-->00:27:10.863
authentication log in process or
whatever. Everybody who knows
this well can track other

00:27:10.863-->00:27:15.868
persons. Okay, so Siegfried
already introduced some some
additional features. Apps also

00:27:17.970-->00:27:22.975
have th-the possibility to send
um or track um text messages.
And the question was can you

00:27:26.278-->00:27:31.283
also get this um messages. Oh
sorry. Um. Um, if you look into
the traffic again to to get our

00:27:36.355-->00:27:41.927
message from the monitored
person you have to make a
simple, there is a API you have

00:27:41.927-->00:27:46.999
to make a simple post request,
you get ah ah a number ah how
much SMS you want to have from

00:27:46.999-->00:27:52.004
this user and his user ID. So
after that you get ah timestamp
and the phone number and ah the

00:27:55.173-->00:28:00.112
messages the monitor person um
sent. Now what happens when you
leave the user name empty? You

00:28:02.247-->00:28:07.252
get all storage text messages
from the server. [audience
applauds] Ya. Okay. So, as you

00:28:16.762-->00:28:22.434
can see this is not no rocket
science. We have no complex
exploits. You just have to know

00:28:22.434-->00:28:27.439
who to to use your browser and
send a UL. Now we get into
exploiting. Um we have here SQL

00:28:30.375-->00:28:37.049
injection, very simple. So again
we have another type of app. And
in this app it is also possible

00:28:37.049-->00:28:42.788
to track a person. Here you have
to know the the mobile number of
the person. So this means um a

00:28:42.788-->00:28:49.394
the backend provides an API if
you enter the mobile number. You
get the latitude, the longitude,

00:28:49.394-->00:28:54.166
the location, timestamp of the
person you want to monitor. K
now a little spoiler, we are

00:28:54.166-->00:29:00.706
talking about SQL injection, so
what do you think will happens
if you do this. Yes, you get all

00:29:00.706-->00:29:06.645
um data, phone number, location
data from the backend. If you
look at the history, the um

00:29:06.645-->00:29:11.650
first recorded started in the
year 2016. That's all. Simple
SQL injection. The next one is a

00:29:15.921-->00:29:21.893
little bit more um let's say
complex SQL. Um Siegfried also
mentioned additional features

00:29:21.893-->00:29:27.332
like messenger functions or
people can for instance with
your girlfriend you can exchange

00:29:27.332-->00:29:33.772
images. As an unusual messenger
these images are storage on a
cloud system and of course there

00:29:33.772-->00:29:40.679
are 1 cloud for all images. Not
every user has its own cloud and
in this case the user is needing

00:29:40.679-->00:29:45.584
to authenticate the cloud on the
backend. There are also filters
that means okay this user has

00:29:45.584-->00:29:51.490
authenticated the images belong
to the user so he just gets the
images of just his girlfriend or

00:29:51.490-->00:29:56.995
not images of foreign people.
The question is now, can we
somehow bypass this

00:29:56.995-->00:30:02.000
authentication or where we able
to compromise the cloud. Um,
spoiler, a little demo. So. If

00:30:11.243-->00:30:16.815
you take a look at this cloud.
It already provides some some
simple web interface. Um, by the

00:30:16.815-->00:30:22.087
way we have to obfuscate the UL
because this um bug was still
not fixed from the vendor. So,

00:30:22.087-->00:30:27.092
um. We provide a the a cloud
storage provides us some simple
web interface but you see when

00:30:29.261-->00:30:35.233
you enter the URL in the
browser, we get no images
because we are not

00:30:35.233-->00:30:41.707
authenticated. And, we are in
the section SQL injections so
let's try a simple SQL injection

00:30:41.707-->00:30:46.712
at the parameter. That should be
in the upper corner um bigger
image of the injector, of the

00:30:48.847-->00:30:55.754
SQL injection you can see it
here. And surprise surprise, we
get a preview of the images

00:30:55.754-->00:31:00.692
stored on the cloud system. We
can also, um, open these images
and download. And as you can can

00:31:03.862-->00:31:09.267
imagine if people are exchanging
images and there is a
possibility to exchange images,

00:31:09.267-->00:31:14.272
they also will exchange not just
burgers or or selfies, they will
also exchange um more private or

00:31:17.175-->00:31:22.180
sensitive information. Let's say
from the section of um adult
entertainment and so on. Um so

00:31:24.583-->00:31:29.588
we also found very um um
sensitive data. On the cloud and
um[audience laughs] yes we I

00:31:33.425-->00:31:38.430
cannot say how much data we um
we did not count them or
download them because of-of um

00:31:42.834-->00:31:47.839
um, privacy reasons and so on.
And um as I said, the block is
still not fixed. Okay and so in

00:31:50.275-->00:31:55.280
this way we would be able to
dump all images. So. Ya thank
you. [audience claps] Then the

00:31:59.584-->00:32:05.857
last step these where just
images, now we want to go to the
crown jewels. So can we get the

00:32:05.857-->00:32:12.230
credentials? And um one of our
application had a strange ummmm
lets say strange insolation

00:32:12.230-->00:32:17.235
process. So the app, we are able
to recognize if it was already
installed on the device. So they

00:32:19.671-->00:32:24.075
had some special installation
procedure. This means when you
install the app for the first

00:32:24.075-->00:32:30.448
time it generates some kind of
um device id and stores this on
the backend. And you remove the

00:32:30.448-->00:32:35.620
application and reinstall it, it
requests to the server for the
device id and it compares and

00:32:35.620-->00:32:41.760
able to detect ok it was already
installed on this device. And if
it realizes that it was already

00:32:41.760-->00:32:47.432
installed on the device, the
server already sends ah the user
name and the password um and the

00:32:47.432-->00:32:54.239
email address back to the
application. So our first idea
was ok the device id, um how can

00:32:54.239-->00:32:59.811
we spoof it but um the problem
is th-the device id is a long
number its very complex and then

00:32:59.811-->00:33:04.749
um {3302} number and it's hard
to reproduce it but perhaps it
is not the best way. So, I would

00:33:06.885-->00:33:11.890
rather trick the empty ID does
it also not work? So let's try
an SQL injection. Here you see a

00:33:15.026-->00:33:21.833
little curl command which is ah
doing the SQL injection. And
what we get was a storage um

00:33:21.833-->00:33:26.838
user credentials. The user name,
the user id, the password in
plaintext. Now you can imagine,

00:33:28.974-->00:33:33.979
we can iterate over all values
and all in all we were able to
or could extract of 1 point

00:33:36.014-->00:33:41.019
seven million data's. Passwords,
credentials, everything in
plaintext. So if you think, what

00:33:45.523-->00:33:50.528
the f**k, so then um [audience
laughs] okay, there's there's
more. [everyone laughs] Surprise

00:33:59.204-->00:34:04.809
surprise. Um a few words at
first about firebase. Who are
not aware, firebase is a service

00:34:04.809-->00:34:09.814
from Googles supporting um app
or app developer. They providing
service for crash analysis,

00:34:12.350-->00:34:19.157
cloud messaging storage. In our
case we focus on 2 services. The
1 is a real time database and

00:34:19.157-->00:34:24.329
the other thing is a
authentication processor API on
this. So, just imagine this real

00:34:24.329-->00:34:30.502
time database like a classic
database if you are not aware
about this firebase um service.

00:34:30.502-->00:34:36.574
So we have another app that have
implemented an authentication
process. They hosted their own

00:34:36.574-->00:34:42.847
authentication server. And as a
user or or an attacker, first
you have to send a login

00:34:42.847-->00:34:48.620
request. For this you have to
send the user email. In our case
as an attacker, we will send the

00:34:48.620-->00:34:53.625
victims email. On this um,
backend, there's ah, there is ah
database, a classic database,

00:34:56.094-->00:35:03.034
with ah public available table.
And this table stores the user
email and a corresponding user

00:35:03.034-->00:35:08.039
id. And so if you are sending
your post request, the database
is querying the database, if it

00:35:10.575-->00:35:15.580
finds the corresponding um email
address he replies this user id.
In the next step, the app now

00:35:19.150-->00:35:24.956
try's to access to this firebase
database by sending the user and
this queried or corresponding

00:35:24.956-->00:35:29.961
user id to get access to the
stored data. So we are querying
in this user id in this publicly

00:35:32.864-->00:35:37.869
available table. And as a
response, we get the location
data, the address, um date when

00:35:40.472-->00:35:45.610
the request was sent. So, that
was the first thing as you can
imagine, guessing the email

00:35:45.610-->00:35:50.281
address will give you very easy
access. I'm sorry I have found
in this movie not a better

00:35:50.281-->00:35:57.255
facepalm but this is the first
one. So in the next step you see
in the app or the ah database

00:35:57.255-->00:36:02.727
back and also replies the
userbase credentials back to the
app. [audience laughs] The

00:36:02.727-->00:36:07.732
question. The question is now
why, ya um, this is an example
of how you should not do it. Um

00:36:10.568-->00:36:16.374
the developer implemented a
client-side verification. This
is mean there um expecting the

00:36:16.374-->00:36:22.547
credentials from the server and
comparing it in the application
and if its correct, they allow

00:36:22.547-->00:36:27.552
access. So, I think your aware
of it, it's not the correct way
how to do this. Another thing is

00:36:30.155-->00:36:37.062
our old trick, what do you think
what happens if you remove the
user id. Of course we get all

00:36:37.062-->00:36:42.634
stored data from this database
containing location, address
status, user credentials,

00:36:42.634-->00:36:47.639
security token, whatever. Ya,
s**t happens. [audience claps]
So, it's sometimes easy to to

00:36:55.647-->00:37:01.753
bash um people so whats the
problem here? The first thing is
um they did not set any any

00:37:01.753-->00:37:05.657
authorization rules on the
firebase. This is always a
common problem developers are

00:37:05.657-->00:37:10.862
not aware about this thing and
they use some different
configuration and then the

00:37:10.862-->00:37:17.335
authorization is is disabled.
Further thing as I explained, if
you're doing um authentication,

00:37:17.335-->00:37:22.340
you don't do it on the
client-side, you have to do this
on the service side. Especially

00:37:22.340-->00:37:27.345
if if you want to work with
firebase then use the SDK. Don't
um um conduct some strange code

00:37:29.948-->00:37:36.921
constructs by yourself. The SDK
reports um ah Google sign-in can
use um email password sign-in

00:37:36.921-->00:37:43.561
Facebook, whatever, they already
implemented it in the correct
way in this SDK. It's also

00:37:43.561-->00:37:49.033
possible to use your own
authentication backend. Um um
there a good tutorial on the

00:37:49.033-->00:37:54.672
firebase side. If you do this
step by step, you are on the
right way but don't do anything

00:37:54.672-->00:38:01.246
with public available database
construction and other weird
things. Okay a few experiences

00:38:01.246-->00:38:07.018
about our responsible disclosure
process. Of course we informed
informed all vendors. We gave

00:38:07.018-->00:38:12.423
them 90 days to fix them but 90
days are not strict. If the
vendor says ok, I need longer

00:38:12.423-->00:38:19.097
because of some development
cycles or whatever, we say its
ok, long as you fix it. Um this

00:38:19.097-->00:38:24.769
time we got a few strange
reaction, the first one as
expected. We will fix it, thank

00:38:24.769-->00:38:29.774
you, everybody is fine. Second
is um ya sometimes you have no
reaction. Um, one reacted um how

00:38:33.111-->00:38:38.850
much money do you want? They
thought we want ah ah eavesdrop
them but then we clarified no,

00:38:38.850-->00:38:45.323
we just want to give you the the
report. Please fix it. Ya the
last thing, it's not a block,

00:38:45.323-->00:38:51.863
it's a feature. [audience
laughed] Um, for this um, people
are um or manufacture that do

00:38:51.863-->00:38:57.202
not react, on on on our emails,
we tried tried to involve
Google. Google has this um app

00:38:57.202-->00:39:02.740
security improvement team and
also security team. We wrote an
email, ah to them and send the

00:39:02.740-->00:39:09.214
advisory's report everything,
but we didn't get any direct
replay or any um reaction. Um

00:39:09.214-->00:39:15.153
last week we checked the store
and 12 of the applications where
removed. So 7 are still

00:39:15.153-->00:39:21.292
vulnerable. I also di-di-did the
demo video you saw, this backend
is still active and and nobody's

00:39:21.292-->00:39:26.297
is ah um um reacting. So a short
um summary of our talk. Um as
always as you saw, don't use

00:39:30.969-->00:39:37.575
plaintext communication in
mobile. This is is a radio
communication. In most cases,

00:39:37.575-->00:39:44.048
its very easy to eavesdrop sniff
from many [indiscernible]
data-ers. SQL prepared

00:39:44.048-->00:39:50.622
statements, its its nothing new.
Each, especially android that
will provide a huge API of of a

00:39:50.622-->00:39:55.627
for SQL and prepared statements.
Um. If you are doing app
development, don't don't just

00:39:57.762-->00:40:02.800
focus on the app. If you use
backend, this this is a bunch
you have to consider also the

00:40:02.800-->00:40:09.607
security on-on the back-end
side. And very important also,
don't store any user secrets

00:40:09.607-->00:40:14.846
like passwords, inscription
keys, or whatever on the clients
side. Everybody who has excess

00:40:14.846-->00:40:21.019
to the app and there a lot of
like reverse engineering android
apps , it's very easy to extract

00:40:21.019-->00:40:27.725
the information. Um also
Siegfried already explained the
shared preference thing, if you

00:40:27.725-->00:40:33.131
have anything um, any special
feature, you need you need a
license. Google provides an API

00:40:33.131-->00:40:38.136
for this. And also if you're
working with firebase, use ah
read the firebase tutorials um,

00:40:40.471-->00:40:45.476
use the authentication and
authorization API they provide.
Here you see at the end, ah

00:40:47.578-->00:40:53.785
again, the list of the apps we
analyzed. Um so you can see the
left um column are the apps with

00:40:53.785-->00:40:59.457
the client-side vulnerability.
The right side, this where, apps
where, ah the backend is

00:40:59.457-->00:41:06.397
involved where we are able to
access location data or even all
storage data. If you look at the

00:41:06.397-->00:41:11.402
table, nearly all apps um ah ah,
especially on the backend where
vulnerability against some some

00:41:14.505-->00:41:19.510
kind of attack. So this is the
end of the talk. So thank you
for your attention. Um [audience

00:41:22.613-->00:41:27.618
applauds] Ya, 2 last words um,
all our findings we wrote ah
even for the vendor, we wrote

00:41:32.991-->00:41:38.863
advisories. The advisories are
accessible on-on the website.
Find on the findings. And the

00:41:38.863-->00:41:44.969
last thing who wats to talk with
us, or discuss or has a
question, come to us. Grab a

00:41:44.969-->00:41:49.974
cool beer. We also have a bottle
opener, so you don't have to be
thirsty and thank you again.

00:41:55.279-->00:41:56.914
[applause] 

