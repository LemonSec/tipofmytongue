00:00:00.000-->00:00:11.378
We’ll start with Ruo Ando
[Applause][cheers] >>Ah, [clears
throat]. Hello everyone. Uh, I’m

00:00:11.378-->00:00:19.920
really excited to talk here, so
thank you for listening to me
and uh, in this presentation,

00:00:19.920-->00:00:28.896
um, I’m going to talk about
[audio cuts] we’re application
Uh, using multithreading for

00:00:28.896-->00:00:37.871
analyzing uh, future PCAP file
Uh, this is a tool which take
full advantage of

00:00:37.871-->00:00:48.415
[indiscernible] core processor
and um, cheap high performance
improvement. Actually, is there

00:00:48.415-->00:00:57.291
anyone uh, in this room that
thinks that Wireshark is a
little bit slow? No. [audience

00:00:57.291-->00:01:06.066
response]. This angle of this
tool uh, is uh, kind of my
threaded Wireshark, who is

00:01:06.066-->00:01:14.241
automated deduction. So I guess
uh, multithreading can be uh,
one of the new frontier for

00:01:14.241-->00:01:24.351
packet inspection. Ok, uh,
sorry. Uh, my name is Ruo Ando.
I’m working in government uh

00:01:24.351-->00:01:35.262
organization, so I’m not weird
[laughs]. So uh, my talk is
divided 4 parts. The at first. I

00:01:35.262-->00:01:43.503
would like to uh, talk about uh,
current catastrophic situation
of traffic analysis. The funny

00:01:43.503-->00:01:53.113
thing here is that uh, we have
too many packets to be
inspected, however, for the

00:01:53.113-->00:02:02.089
program uh, to have a solution,
we have 4 packets. Uh, this is
uh, kind, very helpless

00:02:02.089-->00:02:10.931
situation. I’ll tell you what
later. And uh, second one is the
main part, uh, when you build a

00:02:10.931-->00:02:21.475
tool for analyzing huge PCAP
file using massive threads, you
have some selections, um, how to

00:02:21.475-->00:02:30.117
combat code into your
[indiscernible] and a selection
of features and containers and

00:02:30.117-->00:02:43.463
uh, synchronisation mechanisms
such as Mutexe, [indiscernible]
and um, something like that. And

00:02:43.463-->00:02:52.472
the third part is a demo and the
experimental result, uh, simply
stated, um, speed up is ratio of

00:02:52.472-->00:03:00.680
uh parallel execution time to CR
execution time, so I’ll show you
the comparison then, let me

00:03:00.680-->00:03:15.629
conclude this talk. Um, this
slide uh shows uh, an
catastrophic situation as

00:03:15.629-->00:03:25.405
everyone of audience already
know, internet traffic is
increasing at exponential rate.

00:03:25.405-->00:03:42.055
However, uh, there are 2 huge
professionals. Um, sorry uh
[clear throat] sorry um, sorry,

00:03:42.055-->00:03:54.835
I am so excited to uh I forgot
what I was going to [applause],
thank you, thank you. Um,

00:03:54.835-->00:04:10.951
[indiscernible] software imposes
a great burden on security
researchers and analysts, but

00:04:10.951-->00:04:19.926
uh, traffic explosion is not
singular to the hacking or
exploit, because hacking and

00:04:19.926-->00:04:27.801
exploit is imported and will be
finished uh, within several
minutes. But this is not the

00:04:27.801-->00:04:36.910
case of a traffic explosion.
And, unfortunately track,
traffic explosion keeps

00:04:36.910-->00:04:50.924
exploding like an accident or
nuclear power plant so um. In my
case, in my laboratory, I have

00:04:50.924-->00:05:02.536
200 to 300 raw file, uh to
restore uh, in the server to
reinspect it. Well, during this

00:05:02.536-->00:05:14.080
20 minute presentation three to
five gigabyte file to uh is
stored, to be inspected. Uh,

00:05:14.080-->00:05:20.921
[laughs] this is really helpless
situation for me. So uh,
alteration is really important

00:05:20.921-->00:05:29.896
uh, for me and uh everyone of
audience, but, for my
experience, uh, open source,

00:05:29.896-->00:05:39.105
data mining tool doesn’t work in
many cases uh, because in the
world of advertisement and

00:05:39.105-->00:05:50.050
marketing, uh, commercial too,
uh, is not going to find people
trying to hide these activities

00:05:50.050-->00:06:01.995
and uh, to make things more
worse, uh, open source data
mining tool uh, simply ignore

00:06:01.995-->00:06:10.737
people trying to hide and assume
human behaviour is a part of
everyone else. So that, I would

00:06:10.737-->00:06:20.580
like to emphasise that uh, a
packet dump is last resort. Uh,
PCAP file is there and hard to

00:06:20.580-->00:06:32.726
find source to be trusted, and
uh machine lear uh uh on this
one one million versus one

00:06:32.726-->00:06:42.569
trillion. Machine learning has
capable property. Uh I tell you
what, machine learning doesn’t

00:06:42.569-->00:06:56.016
work on the dataset comprising 1
million trillion dataset what is
needed? What is needed is much

00:06:56.016-->00:07:04.658
more bigger set, uh, this is
unexpected, uh because if
machine learning failed to pair

00:07:04.658-->00:07:13.733
in the dataset compromising on 1
million trillion dataset uh, the
intuitive conclusion, is that it

00:07:13.733-->00:07:22.142
doesn’t work at all, but uh,
according to this paper, all we
need is much more data packets.

00:07:22.142-->00:07:35.588
So the situation is very
curious, isn’t it. So, Asura has
more features. At first Asura

00:07:35.588-->00:07:45.265
uh, should be run on commodity
workstation and laptops. It can
run uh, with reasonable

00:07:45.265-->00:07:53.873
computing resources. Because GPU
and uh, crossing system such as
Spark, is still expensive and a

00:07:53.873-->00:08:05.118
high cost and sometimes Spark
and uh, more importantly, uh,
Asura uses Posix Pthread which

00:08:05.118-->00:08:13.326
is really your parallel
programming style. Uh, when
writing a program and choosing a

00:08:13.326-->00:08:21.668
appropriate level of obstruction
is really important. Usually
hardly anyone uh, misses the

00:08:21.668-->00:08:31.478
other program method, except
hackers. What we are copying
here is the uh [indiscernible]

00:08:31.478-->00:08:39.652
packet stream, um, which is
huge, not nice, uh, not
organised in regular pattern and

00:08:39.652-->00:08:49.262
um, unfortunately unpredictable.
So, why it’s security is
important, like you use a single

00:08:49.262-->00:09:02.675
language for uh analyzing
malware binaries, so raw threads
and MPI uh, expose a control of

00:09:02.675-->00:09:15.355
parallel computing at lowest
level, but, at lowest level we
not have libraries, containers

00:09:15.355-->00:09:27.700
uh, and schedules, so you have
to implement uh, this utilities
in first scratch uh, by

00:09:27.700-->00:09:35.742
yourselves. Right
[indiscernible] 1980’s or
1990’s. I guess this field can

00:09:35.742-->00:09:43.817
be one of the new frontier for
public inspection. As a result,
Asura is compact but powerful,

00:09:43.817-->00:09:54.294
actually, Asura has about 2000
lines of code, but, can process
about 75 million packets in um,

00:09:54.294-->00:10:13.513
200 to 400 minutes. This tool
intuitively simple. Asura takes
two steps. Reduction using tax

00:10:13.513-->00:10:22.655
task decomposition and
clustering, uh, day, using data
decomposition. Uh, as you know

00:10:22.655-->00:10:28.261
reduction takes a collection of
data and reduce it to single
[indiscernible] body and the

00:10:28.261-->00:10:37.237
clustering is a task of groupin
grouping data um, in the same
group, in such a way that, data

00:10:37.237-->00:10:45.578
in the same group is more
singular than to those in other
groups. And the important thing

00:10:45.578-->00:10:53.553
here is, deduction passes
container to cluster. The
container is a really important

00:10:53.553-->00:11:05.532
um, key in this two stage
processing. Uh, container is
cross uh, cross template of C

00:11:05.532-->00:11:16.943
plus plus and the feature
selection uh, almost, oh, a
normal detection on packet based

00:11:16.943-->00:11:27.520
on features. There are many such
imports and uh, features could
be many, but the important thing

00:11:27.520-->00:11:39.999
here is to find uh, proper
representation for deducing
massive PCAP file. We use this

00:11:39.999-->00:11:48.875
representation and the middle of
this right two barrier and we
use 2 structures, um, and this

00:11:48.875-->00:12:00.954
is a little bit complicated and
please see the source coding in
the detail. And uh, let me talk

00:12:00.954-->00:12:16.035
more about containers. Uh,
containers is uh, mm, really
important, point, for mass

00:12:16.035-->00:12:29.582
threading. You have three
options. First one is STL. Uh,
STL is an old, basic and regular

00:12:29.582-->00:12:42.095
programming style, but STL is
not concurrent friendly, so, it
is a standard practice to wrap

00:12:42.095-->00:12:51.337
up a lock around STL uh, to make
them safe for concurrent access
and the second one

00:12:51.337-->00:13:03.116
[indiscernible] second one is
Intel TBB. It’s an excellent
library but, uh Intel TBB

00:13:03.116-->00:13:11.024
provides uh, highly concrete
container, but a highly concrete
container is sometimes in a high

00:13:11.024-->00:13:20.466
cost. It takes longer time and
uh, I guess this ones mainly for
scientific computation. So

00:13:20.466-->00:13:27.940
unfortunately, uh, what, what
everyone here is doing is of
like science competition, so the

00:13:27.940-->00:13:37.650
data is not very nice and
unpredictable so, uh, in this
case TBB’s not suitable I guess.

00:13:37.650-->00:13:44.490
And someone is uh, emerging
technology of Thrust. Thrust is
a T, C plus plus template

00:13:44.490-->00:13:54.100
library for GPU. Uh, by using
Thrust, uh, you can write a code
to have a hole uh, they used

00:13:54.100-->00:14:03.142
scan and something like that,
accelerated by GPU, but
unfortunately as far as I know,

00:14:03.142-->00:14:13.920
there is no plan to implement
the hashtable map associated
container uh, in GPU. So I guess

00:14:13.920-->00:14:22.729
there’ll be time to be common
for packet inspection. I guess
this is a, this could be a

00:14:22.729-->00:14:37.210
future work. And uh this thread
is the main architecture of
Asura. Uh, if you have our case,

00:14:37.210-->00:14:50.022
uh, when the computation time on
individual PCAP file is variable
and unpredictable, you’d be

00:14:50.022-->00:14:57.530
better served by task
decomposition. Specifically if
you have a case uh, the amount

00:14:57.530-->00:15:06.873
of decomposition time, will
vary, uh, dynamic scheduler will
be best and here, as we’ve done

00:15:06.873-->00:15:14.647
a scheduler of task
decomposition uh, load balancing
is important to take into

00:15:14.647-->00:15:26.492
consideration. Uh, you have to
implement scheduler by yourself.
So that we see the opposite side

00:15:26.492-->00:15:37.103
of this thread. Uh, this is a
shared container which is good.
Dynamic scheduler involves

00:15:37.103-->00:15:45.745
setting up the shared container,
uh, which hold data and other
threads to throw out tasks uh,

00:15:45.745-->00:15:57.890
when the previous task is
completed. So you should uh,
protect shared container, uh, so

00:15:57.890-->00:16:11.771
that the thread um, can be
assigned correctly and uh, task
should not lost through some

00:16:11.771-->00:16:28.821
corruption of, uh, shared
container. Ok, let me show you
about experimental result. Uh,

00:16:28.821-->00:16:38.865
to put it simply that, speed up
here is ratio of parallel
computing time to sequential

00:16:38.865-->00:16:48.774
computing time. And uh, scarity
so what is scarity? I think
scarcity is a measure of how

00:16:48.774-->00:17:10.196
much speed up the program get as
you add more and more core and
thread. With, I guess that this,

00:17:10.196-->00:17:17.970
kind of tuning is proper but, I,
I don’t know exactly but with
proper tuning of in it’s Kernel

00:17:17.970-->00:17:33.286
Asura can, 75 million packets,
uh, with 500 threads, and about
287 minutes, um, you can choose,

00:17:33.286-->00:17:40.693
um, there’s some rooms to be
improved, in, to be improved,
uh, because the size of the

00:17:40.693-->00:17:49.502
shared container is not proper.
Uh, rogue intention and uh,
context switching, okay too

00:17:49.502-->00:17:57.910
much, so, but uh, I guess it’s
reasonable that it can process
more than 7 million packets in

00:17:57.910-->00:18:13.059
several hours. Um uh, I’m trying
to skip the attack detected in
detail, because some issues of

00:18:13.059-->00:18:30.843
public data set, so instead, let
me show you a demo. 1 Minutes
demo. [Short silence]. Uh first

00:18:30.843-->00:18:39.251
of all binary is compiled
according to the configuration
of number of sets actually. And

00:18:39.251-->00:18:48.060
in reduction step one, Sorry,
this demo is too fast, so, I
can’t [laughs]. Reduction step

00:18:48.060-->00:19:00.439
two and uh, building binaries
for clustering. Clustering has
uh, 5 to 7 dimensions and that

00:19:00.439-->00:19:13.686
data is truncated to for this
demo which is too short. Do you
know what’s going on? Sorry, I

00:19:13.686-->00:19:28.234
don’t know what’s going on. Um,
because uh, machine learning is
too fast. Machine learning

00:19:28.234-->00:19:39.645
relies on so huge data set and
uh, processing speed, is so
fast, so machine learning might

00:19:39.645-->00:19:46.886
stop program, uh, we cannot
expect it to solve. You know,
besides that, we don’t fully

00:19:46.886-->00:20:01.300
understand, so, this demos too
fast so I can not talk about it.
Don’t worry. So let me conclude

00:20:01.300-->00:20:11.077
this talk. Sss Um, I talk about
a little bit weird application
uh, which is called Asura, uh,

00:20:11.077-->00:20:23.589
using multithreading. For coping
with real world pick up stream,
which is huge, uh, not nice and

00:20:23.589-->00:20:31.731
sometimes evil, uh, for it’s
security it’s needed. Just like
uh, you should assembly language

00:20:31.731-->00:20:43.209
for modular binaries. But uh,
using roll thread and then API,
and takes an advantages of

00:20:43.209-->00:20:54.186
retreat performance on large
core processors and uh, pthread
can expose the control of pirate

00:20:54.186-->00:21:02.394
computing at the lowest level.
And tha, unfortunately, or not,
uh, we should implement,

00:21:02.394-->00:21:12.138
everything drivers, containers,
schedulers. This is, which is
really exciting, for me. And as

00:21:12.138-->00:21:23.415
a result there are maximum
flexibility. So as a result
Asura is compact but powerful.

00:21:23.415-->00:21:32.558
Asura has thousand of code and
uh, can process more than uh, 70
million packets in 200 to 5

00:21:32.558-->00:21:46.472
million, sorry, 200 to, huh, 200
to 5 minutes. For future work,
uh, Asura must be speeded up,

00:21:46.472-->00:21:55.247
because there’s rooms to
improve, uh, ok, configure uh,
size of containers and the

00:21:55.247-->00:22:06.992
applying TBB and GPU and uh, I
really recommend uh, this uh
multithreading, applying

00:22:06.992-->00:22:12.364
multithreading for packet
inspection. It's very exciting.
This can be one of the new

00:22:12.364-->00:00:00.000
frontiers for public inspection.
So, thank you everyone, that’s
all, thank you for listening.

