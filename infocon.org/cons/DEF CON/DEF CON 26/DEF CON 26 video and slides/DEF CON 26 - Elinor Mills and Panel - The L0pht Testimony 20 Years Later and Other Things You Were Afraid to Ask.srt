00:00:00.100-->00:00:05.973
>>So twenty years ago, most
people didn’t know what a DDOSS
was. What- They thought phishing

00:00:05.973-->00:00:11.411
was a boating activity and
hacker was a bad word. In a loft
in Boston, a group of hackers

00:00:11.411-->00:00:16.650
stumbled into this world in the
early ‘90’s. They created L0pht
Heavy Industries and in ‘98,

00:00:16.650-->00:00:20.988
they were invited to testify
before the Senate committee on
governmental affairs about the

00:00:20.988-->00:00:27.227
risks and the- risks with the
emerging internet. That unlikely
event marked a turning point for

00:00:27.227-->00:00:32.266
the industry. Today’s cyber
attacks dominate the news and
eth- ethical hackers and

00:00:32.266-->00:00:36.470
researchers are on the front
lines pushing for better
security practices and more

00:00:36.470-->00:00:41.275
critical thinking. We’re going
to hear some never before
revealed details about that

00:00:41.275-->00:00:46.546
historic trip hopefully. And
we’re going to, um, hear their
vie- how- see how they view

00:00:46.546-->00:00:52.819
security issues that are still
problems today. Um. So. I’m
going to introduce them. So. Um.

00:00:52.819-->00:00:57.824
King Pin, also known as Joe
Grand, is a computer engineer
hardware hacker former DefCo-

00:01:05.666-->00:01:12.306
DefCon ba- badge designer and
proprietor of Grand Idea Studio.
He joined L0pht as a 16 year old

00:01:12.306-->00:01:17.277
and worked on the- a bunch of
acronyms- POCSAG Pager. Thanks
Grant- Thanks King Pin.

00:01:17.277-->00:01:22.716
>>[inaudible] A little tracking
of the president. You know.
>>Decoder Kit AMPS based

00:01:22.716-->00:01:27.721
cellular phone hacking and palm
OS application development.
>>You guys remember that one,

00:01:30.023-->00:01:35.128
right? [laughter and applause]
>>What- what was the name of
that, Joey? >>Harry Pom >>Was

00:01:35.128-->00:01:41.802
that Harry Pom or Booty Call? I
don’t remember which one it was.
The wart dialer probably. >>Yup.

00:01:41.802-->00:01:46.807
>>So Chris Wysopal, also known
as Weld Pond is a co-founder and
chief technology, uh, officer at

00:01:50.043-->00:01:55.382
Veracode- was at CTO at
Veracode. At L0pht, he was a
thorn in Microsoft’s side

00:01:55.382-->00:02:01.388
researching security in Windows
and writing Windows versions of
L0phtCrack and Net Cat and was

00:02:01.388-->00:02:06.393
web- webmaster for L0pht dot
com. Tan- [applause] >>That was
Space Rogue right there. >>Tan,

00:02:15.068-->00:02:20.507
um, published a paper in ‘99
envisioning a cyber
underwriter’s lab to test

00:02:20.507-->00:02:25.779
softw-software for security
weaknesses. And he led incident
response after a logic bomb was

00:02:25.779-->00:02:30.784
planted in a UBS, um, at- at
UBS. He did pen testing and red
teaming for 12- 12 and a half

00:02:33.587-->00:02:38.191
years at JP Morgan Chase and now
works in security at a large
health insurance company.

00:02:45.499-->00:02:51.905
[applause] Peiter Zatko, aka
Mudge, uh-uh, worked in DARPA as
a senior government official for

00:02:51.905-->00:02:56.910
DOD running cyber- [laughter and
applause] He also worked as VP
of engineer- engineering at

00:03:04.484-->00:03:11.458
Motorola and he was a deputy
director at Google. He’s head of
security for Stripe and chairman

00:03:11.458-->00:03:16.463
of the board at the Cyber
Independent Testing Lab.
[applause] Uh. Cris Thomas, aka

00:03:24.204-->00:03:28.075
Space Rogue, is a founding
member of L0pht, was a longtime
editor of the hacker news

00:03:28.075-->00:03:33.547
network, and is a public
advocate for security topics
through speaking, writing, and

00:03:33.547-->00:03:39.920
general gadflyness. He worked at
AtStake and then went on to work
in research Trustwave Spiderlabs

00:03:39.920-->00:03:44.925
and Tenable. He currently leads
global strategy for IBM’s
X-Force Red Team. [applause] And

00:03:53.633-->00:03:58.972
then Dildog, Christien Rioux,
better known here as Dildog was
the cofounder and chief

00:03:58.972-->00:04:03.910
scientist at Veracode. He’s the
founder of Hailstone, a security
incubator inside CA Broadcom. He

00:04:06.947-->00:04:11.084
was a researcher at L0pht and
Outstake and a member of the
Cult of the def- Dead Cow. And

00:04:11.084-->00:04:16.089
anyone remember Cult of the Dead
Cow? [applause and cheering] He
wrote original code for Back

00:04:21.394-->00:04:26.399
Orifice 2000. [applause and
laughing] Co-authored L0phtCrack
and AntiSniff and wrote some of

00:04:32.706-->00:04:37.711
the- some of the first buffer
overflows for Windows.
[applause] So thinking back to

00:04:40.714-->00:04:45.719
that testimony that was May of
1998, what, um, what did you say
or convey to them that day that

00:04:52.392-->00:04:59.099
you think worked? >>Um. So I’ll
start. So I-I-I think the thing
that worked and it was something

00:04:59.099-->00:05:05.572
that, you know, you never plan
it, right? I-I think Mudge
dropping his-his line of the 30-

00:05:05.572-->00:05:12.312
30 minutes worked. But, um, we
were like a visrable-visual
representation of what the

00:05:12.312-->00:05:17.317
adversary viewpoint was. Like we
were the first ones, to actually
talk like- these guys, you know,

00:05:19.619-->00:05:23.089
these guys who were building
security systems, building the
software, they didn’t know what

00:05:23.089-->00:05:29.563
we were doing. We’re hackers. We
could break this stuff. Like we
made it really real to them, um,

00:05:29.563-->00:05:33.400
that-that there are people that
can do that stuff. Um. And we
were talking, you know, person

00:05:33.400-->00:05:38.238
to person. I think the other
thing that we did that was
important was we conveyed the

00:05:38.238-->00:05:43.243
poor state of software security
and vendors just couldn’t say,
you know, all software has bugs,

00:05:45.912-->00:05:49.716
we have security bugs. Because
if we could find them, we said
they should be able to find

00:05:49.716-->00:05:54.054
them. So I think those were some
of the- some of the basic
foundational things that, you

00:05:54.054-->00:05:59.659
know, go-got through. >>I think
going-going along with-with what
Weld had said, sort of raising

00:05:59.659-->00:06:05.932
awareness of hackers in general.
Um. I was just at the- the Mob
Museum in Las Vegas recently and

00:06:05.932-->00:06:09.436
learned about something that was
pretty cool. The Kefauver
Committee back in like the ‘50’s

00:06:09.436-->00:06:13.773
where they were basically
exposing organized crime to the
masses- it was the first time

00:06:13.773-->00:06:17.143
people learned about organized
crime- this is like a little bit
of an exaggeration- like a

00:06:17.143-->00:06:21.014
little bit of an exaggeration,
but the testimony was sort of
like that because people that

00:06:21.014-->00:06:24.684
sort of heard about hackers and
up to that point they’d thought
they were always bad, criminals,

00:06:24.684-->00:06:28.655
whatever. You’d see something in
the newspaper once in a while,
but this was the first time

00:06:28.655-->00:06:31.992
where we were on stage and
saying “We can do good.” Like
hackers can actually do the good

00:06:31.992-->00:06:36.396
side. Besides the adversarial,
we can educate people and do
stuff that we, you know, think

00:06:36.396-->00:06:41.401
is helping. And I think that was
really important. >>It was, um,
sensitivities that was. I’ve got

00:06:43.603-->00:06:50.243
a mic. [laughs] >>You’re the
only one with it on you. >>Um.
It was one of the first examples

00:06:50.243-->00:06:55.882
of cultivating sensitivities
across the chasm. Um. Hackers
were criminals. That’s the only

00:06:55.882-->00:07:01.121
way we were referred to in the
media. Uh. It’s actually kind of
how that whole thing came about

00:07:01.121-->00:07:06.459
in a strange way. Um. And on the
government, uh, side, you know,
we knew that there was some

00:07:06.459-->00:07:11.031
overlap where we all wanted the
same thing but we didn’t want to
become government and we-

00:07:11.031-->00:07:15.335
government didn’t- sure the heck
didn’t want to become us. Uh.
Sort of set up. So why can’t you

00:07:15.335-->00:07:19.005
just ignore the other parts and
like figure out how to make
progress in the areas where you

00:07:19.005-->00:07:24.277
both have interest. One of the
things that actually worked
really well out of it, um, which

00:07:24.277-->00:07:30.817
took about 2 years afterwards
was that Senate testimony was
leveraged to introduce, uh,

00:07:30.817-->00:07:36.923
verbiage into PDD63, President
Decisional Directive 63 under
Clinton which stood up the

00:07:36.923-->00:07:41.928
scholarship for service program.
Uh. So if anybody went to one of
the 73 colleges, um, and got a

00:07:43.963-->00:07:49.502
tuition and then later had to go
work for the FAA, FFC, FTC or
anything else but had your

00:07:49.502-->00:07:54.507
tuition paid for, that was
largely driven by that senate
testimony as an exemplar of this

00:07:57.410-->00:08:02.849
is why we need smart young
people. Not just the old like,
you know, old guard and the

00:08:02.849-->00:08:07.253
bureaucrats, and the policy
wanks which are very valuable
but maybe didn’t know that new

00:08:07.253-->00:08:13.426
thing coming in. So it was- it
was an awareness sort of set up.
Historically, the government was

00:08:13.426-->00:08:18.631
being briefed that, you know,
um, you know, like it was the
cold war. That if cyber was

00:08:18.631-->00:08:22.302
coming, you’d be able to see it
the same way you’d be able to
see missile silos built up. But

00:08:22.302-->00:08:27.407
it would take 10 years that
you’d see large movements of,
you know, equipment and funds

00:08:27.407-->00:08:31.511
and everything else and you can
track it. And this was different
because it was like, you know,

00:08:31.511-->00:08:37.384
here are some kids in Boston who
did nation state stuff out of
dumpsters as far as they were

00:08:37.384-->00:08:41.554
concerned. And they did it in a
matter of months. So what does
that do for your threat

00:08:41.554-->00:08:46.593
modeling. And I think that was
probably the biggest wake up
call for the government. >>How

00:08:48.661-->00:08:53.666
do you think change- things have
changed since then? >>Well, uh,
is this thing on? Ok. Um. Like I

00:08:59.773-->00:09:05.078
think that definitely, uh, that,
uh, exploits have definitely
gotten significantly harder to

00:09:05.078-->00:09:10.550
write over the last 20 years.
Um. I remember writing a lot of
the first early Windows exploits

00:09:10.550-->00:09:14.687
and finding bugs was something
that I literally stumbled
across- it was not something

00:09:14.687-->00:09:20.260
that I had to search for. Um.
You know. Exploit trading, uh,
for cash definitely existed but

00:09:20.260-->00:09:24.864
this sort of nation state
support for, uh, exploit market
places and things didn’t exist

00:09:24.864-->00:09:29.736
back then. Um. So as
vulnerabilities have gotten
harder to exploit, the relative

00:09:29.736-->00:09:35.408
cost, uh, and price associated
with an exploit is skyrocketed-
sky- has completely skyrocketed.

00:09:35.408-->00:09:41.114
So. Um. Exploits also didn’t
usually, uh, require nearly the
amount of training that we have

00:09:41.114-->00:09:47.287
to do today to actually, you
know, fully exploit a system.
Uh. Laying, you know, all these

00:09:47.287-->00:09:53.326
layered defenses, um, have
really raised the bar on
attackers. Um. It had an effect.

00:09:53.326-->00:09:56.629
Uh. And the most well-f
well-funded attackers are also
finding that the lowest hanging

00:09:56.629-->00:10:02.402
fruit is-is uninformed and
unlucky users. Um. You know, you
happen to click on the dancing

00:10:02.402-->00:10:07.707
bears. Um. So. That- but that’s
it. Instead of, like, phishing
people’s email, just, email or

00:10:07.707-->00:10:12.412
making a crappy phone call,
you’ve got online forums and SMS
texts, and, uh, whatever it

00:10:12.412-->00:10:16.015
takes to get to people. Tinder.
I don’t know. Um. [laughter]
There- there are a lot more

00:10:16.015-->00:10:20.453
opportunities to phish people
these days because of our
increased connectedness. So

00:10:20.453-->00:10:25.825
while that it may be harder to
exploit things, it has become
easier to exploit people over

00:10:25.825-->00:10:30.630
time. Um. That’s it on the plus
side. More- far more people are
aware of, uh, the need for

00:10:30.630-->00:10:35.702
security these days. Uh. Even a
grandma on Facebook knows about
hacking, um, and might even know

00:10:35.702-->00:10:40.640
what phishing looks like. Um.
Two-factor authentication is
available in many places and-

00:10:40.640-->00:10:45.712
and when it wasn’t and- and, but
that’s a- still surprisingly not
in a lot of banks. You know, out

00:10:45.712-->00:10:49.582
of all the places they should
have it, more, uh, banks don’t
have it in enough places.

00:10:49.582-->00:10:52.352
>>[muffled] even in your games
though. >>Yeah, yeah. Right.
Video games have it. Not your

00:10:52.352-->00:10:56.956
bank. I don’t know. Um. And,
yes, SMS two factor sucks.
Please everyone stop using it.

00:10:56.956-->00:11:01.895
Um. Um. So yeah, I mean, I
definitely- the- the profile,
um, for the attacker has changed

00:11:04.330-->00:11:08.768
in terms of the amount of work.
Um. You know, it took me weeks
to write a really good

00:11:08.768-->00:11:13.106
weaponized exploit back in 1998
and now it would take nine
months to write something that

00:11:13.106-->00:11:18.711
was, you know, from initial, uh,
you know, injection point
to-to-to full control. I mean,

00:11:18.711-->00:11:22.682
it’s >>Against a hard target.
Yeah. >>Yeah. Against a hard
target. Yeah. >>One-one of the

00:11:22.682-->00:11:26.519
things that’s changed, and
actually since we have two folks
from Veracode here [cough] and

00:11:26.519-->00:11:30.056
this goes back to Slent, uh-
>>Yeah. >> which was like the
original, you know, Lexecal

00:11:30.056-->00:11:34.727
Integrity source code checker
that >>Yup. >>was, you know,
kind of maybe helped you guys a

00:11:34.727-->00:11:39.265
little bit with the idea there
>>Yup. >>was, um, Apple often
wanted to do this sort of like

00:11:39.265-->00:11:43.937
consumer reports thing and say,
like, let’s look at software,
whether it’s binary whether it’s

00:11:43.937-->00:11:47.941
source code and say like, you
know, tell people what’s good
and what’s bad. And the problem

00:11:47.941-->00:11:54.614
was there were no examples of
good. Everything, you know, was
just >>Yup. Yup. >>crap. And you

00:11:54.614-->00:11:58.484
can’t go out there and give
people actionable advice by
saying like, “well if you’re

00:11:58.484-->00:12:02.989
going to choose web browsers
well you’ve got, um, you know
Serns browser and that’s it, um,

00:12:02.989-->00:12:08.094
and it sucks so there you go.
You’re welcome.” Uh. If you want
a word processor, you know,

00:12:08.094-->00:12:14.367
you’ve got this one option and
it’s crap so you can’t do it.
Now we actually have examples. I

00:12:14.367-->00:12:18.571
think Window 10- Windows 10 was
a huge step function for
Microsoft. >>Yeah. >>as far as

00:12:18.571-->00:12:22.942
hardening. You’ve got Chrome.
You’ve got a couple of good
examples that show that you can

00:12:22.942-->00:12:28.081
do solid build quality really
hard targets. You know, at the
same time for every one of those

00:12:28.081-->00:12:32.752
you get like 1-->000 things that
just don’t do it, uh, that are
out there at mass. But now we

00:12:32.752-->00:12:36.389
have examples of good and bad.
>>And- and- and plenty, you
know. >>Beforehand we didn’t

00:12:36.389-->00:12:39.525
have examples of good. >>You
know. Plenty more examples in
general. Uh. Now it’s all

00:12:39.525-->00:12:44.163
indexed. Um. It used to be that,
you know, if I wanted to exploit
every single, um, network driver

00:12:44.163-->00:12:48.001
on the planet, I would go find a
bug in MSDN’s example code.
>>Mhm. >>because everyone would

00:12:48.001-->00:12:51.104
cut and paste that. Now if I
wanted to do something like that
[inaudible] >>I-I go to stack

00:12:51.104-->00:12:54.974
overflow and find bugs in stack
overflow samples because people
are just going to cut and paste

00:12:54.974-->00:12:58.011
that. So, yeah. >>One option,
yeah. >>Yup. If you want to find
bugs in ICS stuff or SCADA DCS

00:12:58.011-->00:13:03.016
stuff, stack overflow. >>Yeah.
>>Seriously, you’ll find- or
look for the resumes and people

00:13:03.016-->00:13:08.721
will post examples of what
they’ve done in code in those,
uh, embedded control systems.

00:13:08.721-->00:13:14.227
Yeah, and, uh, then you just
look for where they worked.
[laughter] >>So- so >>And by the

00:13:14.227-->00:13:19.465
way, Github is the new Payspend.
Anyway. >>I-I-I think another
dimension of what’s changed

00:13:19.465-->00:13:24.470
is-is definitely the adversary
space. Um. Senator Thompson
asked us when we were there, he

00:13:26.572-->00:13:32.211
said, “Could a nation state hire
a group of hackers such as
yourselves and hack the United

00:13:32.211-->00:13:38.651
States?” I don’t think he would
ask that question in 2018 ‘cause
it’s in the news every day. But

00:13:38.651-->00:13:44.624
it was actually, like, a
theoretical thing back in 1998.
Will governments do this? And,

00:13:44.624-->00:13:48.795
yeah, of course our answer was,
yeah, you know, yes, yes then
can. >>Well, a funny thing was

00:13:48.795-->00:13:53.966
the national security council
visiting the L0pht prior to the
Aenate testimony where, uh, they

00:13:53.966-->00:13:58.705
all huddled out in our parking
lot and we all got freaked out
so we ran over. And, uh, and we

00:13:58.705-->00:14:01.841
said, no- no, we just invited
you in. That was a huge
extension of trust sort of

00:14:01.841-->00:14:04.644
stuff, you know, you have to go
back to your skiffs in
Washington and talk all you

00:14:04.644-->00:14:08.414
want, you have to tell us what
you’re talking about in front of
us, like, huddling. And they

00:14:08.414-->00:14:12.752
said, “Well, this blows our
threat models. What you’ve done
we’ve always thought was only

00:14:12.752-->00:14:17.957
nation-state capable and so we
were wondering if any
governments have approached you

00:14:17.957-->00:14:22.028
yet.” And you know, the answer
was no, but if you’d like to be
the first we’re willing to

00:14:22.028-->00:14:28.401
entertain offers. [laughter]
>>And, uh, luckily they laughed.
[applause] >>I think that’s- I

00:14:28.401-->00:14:33.406
think that that’s the time when
we gave them the L0pht root beer
also and all of you got

00:14:35.508-->00:14:40.246
headaches and stomach problems.
>>And everybody got sick. Thanks
Joe. >It’s amazing they invited

00:14:40.246-->00:14:43.850
us back. Um. But yeah, related
to the- >>Joe poisoned the, uh,
uh, uh >>poisoning the

00:14:43.850-->00:14:46.319
government unintentionally
>>national security council in
mass. Yup. With homemade root

00:14:46.319-->00:14:52.125
beer. >>Um. But going off- going
off what Weld said is that
nation state or not, like,

00:14:52.125-->00:14:55.394
attacks are some common now
where back in the day they
weren’t. We’re, like, so

00:14:55.394-->00:15:00.967
desensitized to it, and, you
know, we’re naming our bugs and
we have giant presentations

00:15:00.967-->00:15:05.772
about it. And it’s like a real
circus. When an attacks happens,
you know, stock price goes up,

00:15:05.772-->00:15:09.442
there’s a media frenzy, stock
price goes up, and then everyone
goes back to work, and then you

00:15:09.442-->00:15:14.413
do the next one. Right? So it’s
like really this, it- very
different cycle. Um. Related to

00:15:14.413-->00:15:17.984
the tools, you know, like we
were creating our own tools and
we were getting stuff out of

00:15:17.984-->00:15:21.053
dumpsters and- and reverse
engineering thing that weren’t
available because the

00:15:21.053-->00:15:26.492
documentation wasn’t there. Now
everything’s online. And the
tools to do stuff, especially

00:15:26.492-->00:15:30.062
from the hardware perspective
from where I’m from, the
resources are- are out there.

00:15:30.062-->00:15:34.033
You can get every tool you need
to hack hardware for under 100
dollars. >>I mean, we went

00:15:34.033-->00:15:37.403
dumpster diving for
documentation on more than one
occasion. >>Mhm. >>But now you

00:15:37.403-->00:15:41.007
can just Google for it. >>Right?
>>Yeah. So that’s, you know. I
think it’s the access to

00:15:41.007-->00:15:46.212
information and the resources,
uh, which is great and possibly,
you know, for people on the

00:15:46.212-->00:15:53.052
defense maybe not so great.
>>So, uh, one question before I
let the audience have a chance,

00:15:53.052-->00:15:58.357
um, how did the testimony- the
invitation to come to Congress
happen? [panel laughter]

00:15:58.357-->00:16:02.829
>>That’s a point of debate.
>>Yeah. It’s actually really not
a point of debate. >>No. It’s a

00:16:02.829-->00:16:08.601
point of a debate. >>We can have
a debate. You might as well tell
it. >>Well, um. So. Uh. Well, I

00:16:08.601-->00:16:13.806
mean. What had happened was at
the L0pht, we were trying to do
it full time. Um. So we actually

00:16:13.806-->00:16:18.144
had a couple folks on really
payroll and I was going out-
>>This is pre-payroll. >>Well,

00:16:18.144-->00:16:21.247
actually, yeah, it’s- that’s
right. Well, L0phtCrack was
paying a little bit of stuff.

00:16:21.247-->00:16:23.983
>>A little bit. Yeah. I mean,
L0pht crack. But we got press.
>>Yeah, we were getting a lot of

00:16:23.983-->00:16:27.920
press and that’s actually what
kind of started this in my mind.
Um. We were getting a bit too

00:16:27.920-->00:16:31.757
much press. And I was really
worried. And this was- Remember
the MIT thing where I had to sit

00:16:31.757-->00:16:36.062
up there against Annette Day who
was the FBI director- or the
>>Yup. >>cyber crime FBI part?

00:16:36.062-->00:16:39.532
And this was hackers for
girlies, when they had hacked
the New York Times and so I’m

00:16:39.532-->00:16:43.102
sitting on a panel, you know,
that MIT had invited me with-
all the L0pht guys were there,

00:16:43.102-->00:16:48.107
Tan was there- you know this one
really well. And, um, you know,
and the FBI Boston cyber part,

00:16:51.310-->00:16:55.014
uh, says like, “We- we’re
investigating all the leads.
We’ve already talked to all the

00:16:55.014-->00:16:59.919
relative people.” And so I
opened my big mouth and say,
“No-” on the same panel “No you

00:16:59.919-->00:17:03.723
haven’t. Because if you look at
the source code on the hacked
page, it calls out greets to the

00:17:03.723-->00:17:07.426
L0pht and Mudge. And I’m sitting
here on the panel with you and
I’m telling the audience that

00:17:07.426-->00:17:13.232
you never talked to me.” You
know. [laughter] >>Didn’t go
over too well with the Boston

00:17:13.232-->00:17:18.237
FBI. [laughter] >>Um. We were
also, you know, making like a
lot of news, you know, the local

00:17:18.237-->00:17:22.308
AO ABCN the cable news and stuff
like that. And I honestly
thought that we needed a

00:17:22.308-->00:17:27.079
contingency plan. So I actually
started to go out to the
government. And very quietly I

00:17:27.079-->00:17:30.816
started to advertise that I
would train. And you guys
remember me going out to a bunch

00:17:30.816-->00:17:36.956
of these. Air Force Information
Warfare Center, you know, uh-
um, you know, Quantico, uh, NSA,

00:17:36.956-->00:17:41.894
FRY4, C4, EXGroups and stuff
like that. Anybody in the
government could get me to go

00:17:41.894-->00:17:46.499
out and I would educate them and
train them just on tech stuff.
And I would not take any payment

00:17:46.499-->00:17:50.102
because I didn’t want to be
under- you know, I didn’t want
them to have chains or strings

00:17:50.102-->00:17:55.541
to pull sort of stuff. And the
goal was- I figured that the FBI
or the DOJ was going to at some

00:17:55.541-->00:18:00.379
point just for the media, try to
make an example out of us. And
like pull us up and make us some

00:18:00.379-->00:18:04.584
big sort of like, we’ve got the
hackers. You all know about
them, sort of set up. I-If that

00:18:04.584-->00:18:09.221
happened that, um, I wanted to
be able to, like, reach out to
the folks at West Point and

00:18:09.221-->00:18:13.960
have, like, you know, Colonels
and Majors show up in uniform
and say, “No. These- these guys

00:18:13.960-->00:18:18.331
aren’t the bad guys. They’ve
actually just been very up front
and help.” Through that, um, I

00:18:18.331-->00:18:21.634
ended up briefing the national
security council several times
and became friends with Richard

00:18:21.634-->00:18:26.138
Clark. And then we had the
meetings with them and then he
became kind of a friend of the

00:18:26.138-->00:18:33.045
L0pht and he brokered it with
the Senate. Um. And he and I
kind of talked a lot about that

00:18:33.045-->00:18:38.484
and I was uncomfortable with it.
And then they reached out to us,
uh, and then I had to approach

00:18:38.484-->00:18:43.122
it with the other law folks. And
I remember Weld is familiar and
Tan with some of the back stuff-

00:18:43.122-->00:18:47.827
I didn’t do a great job of
sharing it with all of the L0pht
folks. Uh. But it was kind of

00:18:47.827-->00:18:52.798
prepared because we were not
going to go into the Senate and
get ambushed and just get- get

00:18:52.798-->00:18:57.603
raked up and down the hills. It
was going to be friendly or else
we weren’t going to do it. >>We

00:18:57.603-->00:19:01.173
were- we were very scared ahead
of time. >>We were terrified.
>>Walking into that room what

00:19:01.173-->00:19:04.443
kind of reception we would get.
Right? I think it’s one of the
reasons why I dem- demanded

00:19:04.443-->00:19:08.614
everybody wear a suit. Uh.
[laughter] >>Because we didn’t
know >>I hate you for that >>if

00:19:08.614-->00:19:13.619
we were going to walk in there
and have the senators call us
all brown noses, right? >>King

00:19:13.619-->00:19:18.090
did not have a suit. He wore his
father’s. [laughter and
applause] >>And I haven’t worn

00:19:18.090-->00:19:21.694
one since. >>I mean, I mean,
we-we were assured that it was
going to be a friendly meeting

00:19:21.694-->00:19:24.730
but we also in the back of our
minds felt that, you know, we
could get in there and they’re

00:19:24.730-->00:19:27.566
just going to call us all
criminals and-and what do we do
then? So. >>And-and ‘cause if-

00:19:27.566-->00:19:32.071
if you watch it, you’ll actually
see that it was Senator Thompson
that says, like, uh, “I’m

00:19:32.071-->00:19:36.008
informed that you think that you
can take the Internet down in 30
minutes.” And he was talking

00:19:36.008-->00:19:38.611
about my BPG work that I was
doing at my day job which was a
government contractor at the

00:19:38.611-->00:19:43.482
time. Um. And there’s no way
that they would have known that
had it not been the fact that

00:19:43.482-->00:19:46.719
from the day job and the night
job, I shared that with the
folks at national security

00:19:46.719-->00:19:52.425
council. So I mean a lot of
these questions, you know, were
sensational but they were

00:19:52.425-->00:19:57.663
relatively safe. And it was a
little weird because we were
still terrified. Well, I think

00:19:57.663-->00:20:02.501
we worked out for-for
sensitivities. >>I think we did
a good job preparing the written

00:20:02.501-->00:20:06.739
testimony because looking at
that, like, the spoken, for me,
I’m sort of embarrassed about.

00:20:06.739-->00:20:12.178
But the wri- you guys were fine.
[laughter] >>The written
testimony was like a really good

00:20:12.178-->00:20:16.215
description of what could happen
and so we prepared that in
advance. I think we had to send

00:20:16.215-->00:20:19.985
that to them a little bit in
advance. So we had no-
>>it’s-it’s still a part of the

00:20:19.985-->00:20:22.688
public record if you can find
it. >>Right. It’s in the public
record. So we didn’t know how

00:20:22.688-->00:20:25.191
they were going to react to us,
but by doing that, it put
something into the public record

00:20:25.191-->00:20:30.596
that actually was going to stick
regardless. >>And John Glen
obviously, uh, messed up a

00:20:30.596-->00:20:33.199
little bit when he was like,
“Awh, and I’ve worked with some
of you.” And I’m like, “Oh,

00:20:33.199-->00:20:37.837
geeze.” >>So one of the other
interesting things about it was
we only agreed to do it if we

00:20:37.837-->00:20:44.810
could testify under our hacker
aliases. [laughter] And, um, we-
we- we just almost couldn’t

00:20:44.810-->00:20:49.281
believe that they allowed this.
[laughter] They said- they said
the only people who, uh, ever

00:20:49.281-->00:20:53.152
testified before under their
aliases were in the Witness
Protection Program. [laughter]

00:20:53.152-->00:20:58.457
Which might not have been a-
>>This ma- this made expense
reimbursement really difficult.

00:20:58.457-->00:21:02.128
>>Well, this-this was hilarious
and I-I might be giving away a
little bit of opsec for it um

00:21:02.128-->00:21:06.532
part of it was- was, I mean, and
these guys all know this
intimately. I hate flying. I’ve

00:21:06.532-->00:21:11.537
got- I’m- I’m petrified of
flying. And we wanted to go to
NSA Crypto Museum And if we took

00:21:11.537-->00:21:15.741
a train, we weren’t going to get
to the Crypto Museum before it
closed so we rented a Dodge Ram

00:21:15.741-->00:21:20.679
3500, you know, 15 passenger-
>>Like an 11-seater van. >>Yeah,
15 passenger van, black,

00:21:20.679-->00:21:24.316
tinted-out windows and like
Brian Oblivian and everybody
else- like the hardware guys

00:21:24.316-->00:21:28.454
were like let’s put in atenas.
Let’s actually, like, you know,
map the northeast corridor. The

00:21:28.454-->00:21:32.791
thing looked like, you know, it
was- it was a SIGINT sort of van
going on. [laughter] This is

00:21:32.791-->00:21:37.429
1998. And, um, there’s a story
about taking the wrong turn
which I won’t go into when we

00:21:37.429-->00:21:41.000
went into the NSA wrong
entrance. Um. [laughter] With a
van that looked like SIGINT.

00:21:41.000-->00:21:45.137
>>We really fit in because we
had all the atenas. They didn’t
know what to make of it. >>But,

00:21:45.137-->00:21:49.175
um, when- when we get down
there, um, uh, they were like,
you know, uh, we’re checking

00:21:49.175-->00:21:54.280
into the hotel and it was Al
Anderson, Bob Bondurant, you
know, CC, DD, EE, FF- >>We got

00:21:54.280-->00:21:56.348
some big names at the hotel.
>>and the weird thing was the
hotel was like, “Yeah, we’ve

00:21:56.348-->00:22:01.153
seen this before. You’re going
to the senate aren’t you?”
[laughter] >>So the- the other

00:22:01.153-->00:22:05.691
thing about under the hacker
names was the reason we did that
was because we were protective

00:22:05.691-->00:22:10.829
of our day jobs. Right? Like we
were going to be talking- we
didn’t know how the vendors and

00:22:10.829-->00:22:15.100
the partners of the companies we
worked at were going to- we’re
going to take this. >>Well, we

00:22:15.100-->00:22:18.737
did know how Microsoft used to
handle it. >>Yeah, Microsoft,
you know, because obviously they

00:22:18.737-->00:22:23.342
can pull strings with your
employer, right? Um. But it
didn’t work out so well because

00:22:23.342-->00:22:28.480
there was reporters there with
microphone- with cameras and our
picture was on the front of

00:22:28.480-->00:22:32.318
Internet Week when we got back
into work the next week- Monday.
>>Our picture was on the front

00:22:32.318-->00:22:35.087
of the Washington Post. >>Yeah.
Washington Post. Yeah [laughter]
>>I mean the handles- the

00:22:35.087-->00:22:40.626
handles though it wasn’t just
for day jobs because not all of
us had day jobs, um. [laughter]

00:22:40.626-->00:22:46.498
>>Some of us weren’t old enough
to work yet. >>But the- you
know, we were pi**sing a lot of

00:22:46.498-->00:22:52.137
people off because we were seven
kids in a warehouse and- and
there- you know, you had some

00:22:52.137-->00:22:55.941
professional jobs still, but
whatever. It was- We were- I
remember reading some mailing

00:22:55.941-->00:23:00.279
list post that people f- on,
like, academic cyber security-
whatever we called it back then

00:23:00.279-->00:23:03.782
list saying why don’t you guys
come out from behind your
handles if you have something to

00:23:03.782-->00:23:07.319
share and whatever. And we’re
like we’re sharing the technical
information. You don’t need to

00:23:07.319-->00:23:10.089
really know who we are. We’re
the L0pht in Boston. We’re King
Pin and Mudge- this is what you

00:23:10.089-->00:23:16.128
need. Uh. But it was also a
protection mechanism just in
general because we- you know,

00:23:16.128-->00:23:19.898
what we were doing was not
normal. >>Also even at that
point, we had built up a-a

00:23:19.898-->00:23:23.903
considerable reputation
individually and as a group
under those names. And if we

00:23:23.903-->00:23:27.339
suddenly started using our real
names, nobody would know who the
hell we were. [laughter] >>Well,

00:23:27.339-->00:23:30.409
one of the reasons you don’t
give up the names, if you- if
you remember when I- when I went

00:23:30.409-->00:23:35.014
down to the- to the Clinton
round table in the- in the White
House, uh, for that and this is

00:23:35.014-->00:23:39.151
where my name actually- ‘cause I
had done I thought a pretty
decent job of never having a

00:23:39.151-->00:23:43.322
picture of me, never having my
name on the internet or
whatever. And so I get invited

00:23:43.322-->00:23:47.226
to go down, uh, ‘cause Dick
Clark was like, “Hey, you know
you guys have done good. Mudge,

00:23:47.226-->00:23:50.396
why don’t you come down and meet
with the president for this,
like, sort of photo op?” You

00:23:50.396-->00:23:55.267
know. This was right after
StekleDrot, the big Ddot sort of
stuff And to go into the White

00:23:55.267-->00:23:58.437
House, you know, you have to
always give them your social
security number and other stuff

00:23:58.437-->00:24:02.274
like that. You know, ‘cause they
want to check- it’s embarrassing
if you owe child support or if

00:24:02.274-->00:24:06.312
you have, like, warrants out for
you and you’re, you know, being
he- you know, being invited in

00:24:06.312-->00:24:11.116
to see, like, the president.
They gave that list directly
over to the media. And so they

00:24:11.116-->00:24:14.586
had my name. You know, they
don’t give the social part, but
they give the names. And I think

00:24:14.586-->00:24:18.957
it was- yeah. >>Well and I get a
call from a reporter. I’m back
in Boston and they’re like,

00:24:18.957-->00:24:22.962
“Hey, uh- uh, Space Rogue. You
know, I just got this sheet from
the press report at the White

00:24:22.962-->00:24:26.699
House and it has everybody’s
name on it.” >>Is- is Mudge
really Peiter Zatko? >>And I’m

00:24:26.699-->00:24:30.402
like- I-I was like, “Ok. Thank
you very much.” I hung up and I
immediately called you. >>So I

00:24:30.402-->00:24:34.373
called the national security
council going, “You just blew my
cover.” Um. And goes the White

00:24:34.373-->00:24:38.377
House communications agency, and
they’re like, “Oh, we’ll fix
it.” So they- so what they do-

00:24:38.377-->00:24:43.148
[laughter] Well, yeah, they
fixed it. What they did is then
they- then they send out to the

00:24:43.148-->00:24:49.722
same press folks the exact same
thing with my real name replaced
with Mudge, uh, on- on the exact

00:24:49.722-->00:24:55.961
same thing. [laughter] Now, I
got death threats from that from
the hacker community, uh, ‘cause

00:24:55.961-->00:24:59.331
folks were like, “Hey, you know,
you’re a sell-out. You know.
What are you doing? Are you- you

00:24:59.331-->00:25:03.068
know, are you a fed? Are you a
hacker?” I mean, look at all the
stuff I contributed open source

00:25:03.068-->00:25:07.639
or whatever. You can look at
CFT. You can see why I’m doing
it I hope. But, yeah, this is

00:25:07.639-->00:25:11.076
part of the reason why you don’t
want your real name out there
sometimes. I mean, that wasn’t a

00:25:11.076-->00:25:16.782
lot of fun as, like, 26 year old
getting random phone calls to my
cell phone, even cell phones

00:25:16.782-->00:25:20.285
that nobody else knew ‘cause,
you know, there are some good
phone freaks out there, you

00:25:20.285-->00:25:25.290
know, threatening your life.
>>So you guys caused some, um,
uh, prompted some interesting

00:25:25.290-->00:25:30.229
news room discussions when I
was, um, reporting on your
activities and- and my editor

00:25:30.229-->00:25:35.501
would say, “Um. Ok. So we’re
supposed to identify people with
their real names. So who is

00:25:35.501-->00:25:40.072
Space Rogue? We need a real
name.” And I’d be like, “Well.
But that’s the name that I have

00:25:40.072-->00:25:44.076
to report. You know, that’s what
they’re giving me.” You know. So
I-I had to do some education

00:25:44.076-->00:25:49.181
that this is a new type of, you
know, world. A new, um, you
know, reporting era. And so, um,

00:25:49.181-->00:25:53.552
that was really fun in the
newsroom. >>Not just the media.
The academic journals had to do

00:25:53.552-->00:25:57.222
the same thing. I published
papers with Bruce Shnier and
David Wagner, Microsoft, Crypto

00:25:57.222-->00:26:03.962
stuff that I worked on. Useniex
wouldn’t accept, you know, my,
you know, my uh- uh, judged and,

00:26:03.962-->00:26:07.666
you know, vetted paper because
they didn’t have my real name on
it. >>I don’t know if you

00:26:07.666-->00:26:10.469
remember the >>Do you remember
those federal’s papers? >>Well,
yeah. I don’t know if you

00:26:10.469-->00:26:13.906
remember this Eleanor but I
think it was- you specifically
asked me, uh, what my real name

00:26:13.906-->00:26:17.976
was. And I was like, “You know
what, if it’s good enough for
the US Senate, it’s good enough

00:26:17.976-->00:26:22.981
for Wired.” [laughter and
applause] >>Alright. So let’s
take it to anyone have any

00:26:26.084-->00:26:29.888
questions? >>Alright. So we’re
going to take some questions.
I’m going to ask pe- >>Really?

00:26:29.888-->00:26:33.826
>>Come on over. Alright. Anyone
who has questions please queue
up right here. >>Oh boy. Hey

00:26:33.826-->00:26:39.164
Render. >>I hope at least it
should be a friendly question I
hope. >>You never know with him.

00:26:39.164-->00:26:42.701
>>Well, you wonder who was
sending you all those death
threats and everything.

00:26:42.701-->00:26:47.706
[laughter] >>No. Uh. I just want
to say all of you are directly
responsible for me. [laughter]

00:26:51.543-->00:26:56.548
>>Is that- is that- >>Sorry. >>I
don’t know if we should take
credit for that. [applause]

00:27:00.552-->00:27:06.458
>>No. Formative years, you know,
late ‘90’s there was no- there
weren’t a lot of examples out

00:27:06.458-->00:27:12.030
there of what to do with these
skills and these interests. So
you guys were really the only

00:27:12.030-->00:27:18.470
thing out there. And I think you
did a damn good job. So thank
you very much. [applause] >>And

00:27:18.470-->00:27:24.810
if you agree and you think that
these guys, like, you know,
helped form who you are, please

00:27:24.810-->00:27:29.815
stand up. I want to see. You are
responsible for all of this.
Yeah. And it’s- some of these

00:27:34.853-->00:27:39.324
people probably have- probably
weren’t even born then. But
thank you. Thank you for

00:27:39.324-->00:27:42.427
everything you’ve done. >>That-
that- that actually means a lot
because when we were doing the

00:27:42.427-->00:27:46.532
L0pht, I mean, especially when
we were trying to figure out how
to fund ourselves, we looked at

00:27:46.532-->00:27:50.002
going into government contract.
And we looked at any sort of
funding thing where we wouldn’t,

00:27:50.002-->00:27:54.439
like, have to become a
commercial entity. And it’s
honest to God why I did cyber

00:27:54.439-->00:27:57.843
fast track when I went into
Darpa because I’m like, I want
what we needed at the L0pht in

00:27:57.843-->00:28:02.014
order to keep doing stuff
available for other folks even
if I don’t get to do it. And

00:28:02.014-->00:28:05.717
actually some of the guys
actually did do, you know, get
to take advantage of it, uh, in

00:28:05.717-->00:28:10.155
there. And the biggest thing was
it was a pain in the butt for us
to figure this out. And it

00:28:10.155-->00:28:13.892
shouldn’t be that pain in the
butt for other folks because
they should be able to do it

00:28:13.892-->00:28:18.130
more easily so they can figure
out the next thing and take it
further. And, like, that’s the

00:28:18.130-->00:28:22.467
whole sort of thing. Like how do
you get the next team and
inspire them or the other people

00:28:22.467-->00:28:26.438
and not make it as difficult.
And you’ve released a lot of
really good stuff. And a lot of

00:28:26.438-->00:28:31.276
other folks in here have
released a lot of really good
stuff. >>No, you have man. >>No,

00:28:31.276-->00:28:34.613
it’s good stuff and that- [off
mic comment] that- that’s why I
think we were successful. Is

00:28:34.613-->00:28:39.952
that other folks who think that-
or that we might have inspired
did neater stuff than we did.

00:28:39.952-->00:28:43.522
>>And, well, I mean, look how
Defcon has grown too. Like, we
were standing on the shoulders

00:28:43.522-->00:28:47.025
of other people that inspired by
other people. And then it just
keeps growing where it’s like

00:28:47.025-->00:28:51.563
this exponential growth where
everybody can do something.
>>Yup. >>Right? It’s amazing. So

00:28:51.563-->00:28:55.200
it’s just going to keep going.
And, you know, I feel like we
were just this little- >>Yeah.

00:28:55.200-->00:28:57.769
ADLGM. There was LOD. There was
a whole bunch of just- we were
just [inaudible] >>Yeah. We were

00:28:57.769-->00:29:00.405
just this little piece of it.
And it really is- is- it’s, I
mean, yeah, it’s an honor to

00:29:00.405-->00:29:05.978
hear that. And- and other than
feeling old, thank you. But it’s
amazing. So yeah, thank you.

00:29:05.978-->00:29:10.983
Thanks. >>We’re- yeah. >>What’d
you guys screw up along the way?
>>What? >>What did we screw up

00:29:13.652-->00:29:19.591
along the way? >>A lot. >>A lot.
>>Yup. >>A lot of stuff we’ll
not talk about. >>Yup. >>That

00:29:19.591-->00:29:23.128
answers the best. >>You’ll
notice AtStake’s not being
talked about a lot although it

00:29:23.128-->00:29:26.331
actually was really important
for a lot of other- other areas.
But it was very personally

00:29:26.331-->00:29:30.002
painful for all of us. And
that’s just- that’s not
comfortable. >>Yup. I- I- I

00:29:30.002-->00:29:32.004
don’t want to say that was a
screw up, but it was definitely
a learning and growing

00:29:32.004-->00:29:35.173
experience. >>Yeah, but I- I- I
tell people that I wouldn’t have
changed it. Like, even though it

00:29:35.173-->00:29:38.644
was hard. >>Yeah, it is what it
is. >>And it is what it is. And
we were trying to do something.

00:29:38.644-->00:29:41.947
We wanted to fund ourselves and
we were trying to do something
that nobody had done. There were

00:29:41.947-->00:29:44.483
not sm- small security
consultant companies. >>For
those that don’t know, AtStake

00:29:44.483-->00:29:49.021
was the commercial entity that
L0pht turned into after we got
DC funding or got bought or

00:29:49.021-->00:29:52.190
however that went out >>Right.
Pack or sell out. >>And then
that all kind of fell apart.

00:29:52.190-->00:29:55.927
>>But we want- but we wanted to
do it full time and- and we took
a risk. And nobody- it’s not

00:29:55.927-->00:29:59.231
like we could follow the path of
anybody else. We didn’t know
what would happen. And yeah,

00:29:59.231-->00:30:02.434
there were a lot of personal
stories- >>There weren’t a lot
of vendor appointed security

00:30:02.434-->00:30:05.103
companies out there at the time.
>>Especially [inaudible] one-
>>Yeah. But it shaped- it shaped

00:30:05.103-->00:30:08.907
a lot of what we did moving
forward also. >>I’ll tell you
one of the things I always

00:30:08.907-->00:30:14.212
wondered, uh, if I did right or
not is- I kind of buried what
the take the internet down in 30

00:30:14.212-->00:30:18.717
minutes was. And I did that
during my day job. I did it
during my night job. I didn’t

00:30:18.717-->00:30:22.688
even share a real lot of it
inside the L0pht with, like, the
BGD update attacks, there’s a

00:30:22.688-->00:30:26.958
whole bunch of tricks with
putting, like, the target inside
an AS set so it gets discarded.

00:30:26.958-->00:30:31.263
There’s a lot of- we’re seeing
it now in the media. And it’s a
very viable one. And actually if

00:30:31.263-->00:30:35.734
you go back through, um, you
know, uh, like Batarus or some
of the other route views sort of

00:30:35.734-->00:30:39.371
thing, you can see some
interesting nation state stuff
going on if you know what to

00:30:39.371-->00:30:44.409
look for. And it goes back
almost to 1998 which was
interesting. And I always

00:30:44.409-->00:30:49.414
wondered if I shouldn’t have
actually released a proof of
concept for them. >>Yeah, no.

00:30:52.884-->00:30:56.955
[laughter] >>I’m still wonder-
I’m still wondering if >>Not
then. Maybe now, but not then.

00:30:56.955-->00:31:00.525
>>I know! Well- well- well now
it’s actually more like, you
know, an hour and a half rather

00:31:00.525-->00:31:03.995
than 30 minutes because all of
the- all of the ind- you know,
the private peering exchanges

00:31:03.995-->00:31:08.567
and the IXB’s and stuff like
that. Uh. But, yeah, I mean,
that was our big thing. >>Yeah.

00:31:08.567-->00:31:13.605
>>was you can’t hide behind it.
You can’t make it opaque. Here’s
how it works so both offense and

00:31:13.605-->00:31:17.909
defense can understand it. And
there was a lot of confusion
about that. And a lot of

00:31:17.909-->00:31:23.482
sensationalism. And I always
wonder if it shouldn’t have been
backed up with an actual O-day

00:31:23.482-->00:31:30.322
release >>So scary. >>Uh oh, uh
oh! Man down. >>Hey guys. Um, I-
>>The panel recognizes Deviant

00:31:30.322-->00:31:35.827
Nolan >>How do you do? Uh. I
guess what I wanted to ask about
the changing landscape- both of

00:31:35.827-->00:31:41.199
the hacker community and- and
the world at large because
people- my first question’s kind

00:31:41.199-->00:31:46.171
of easy because I think it’s a
no. Could the- could the L0pht
exist today? Or we- we think of

00:31:46.171-->00:31:51.443
the L0pht, we think of Hacker
Halfway House. We have like
maker spaces and hacker spaces,

00:31:51.443-->00:31:57.315
but a lot of younger people
could see you like, “Oh my god.
I want to do that.” But that

00:31:57.315-->00:32:02.921
isn’t really that any more. If
people want to share minds and
maybe even crash together or

00:32:02.921-->00:32:07.893
maybe not- maybe that’s not-
what is feasible for people who
really want to collaborate in

00:32:07.893-->00:32:11.797
this economy and in this time
and in this job market and- and
could the L0pht exist today or

00:32:11.797-->00:32:15.534
what is it now? What should
other people do now? >>I mean,
look at all the hacker spaces

00:32:15.534-->00:32:19.704
that exist all over the world.
And there not exactly like the
L0pht because we were much more

00:32:19.704-->00:32:24.009
private and, you know, careful
with what we were releasing.
>>And focused. >>Private just as

00:32:24.009-->00:32:27.379
far as people couldn’t come
over. >>We- We- We wanted to be
physically located. We wouldn’t

00:32:27.379-->00:32:30.682
have virtual members. >>Right.
>>Because of the direct
interchange when we had, like,

00:32:30.682-->00:32:33.351
you know, group meetings and
stuff. >>Well we couldn’t do
virtual back then because

00:32:33.351-->00:32:36.922
virtual didn’t exist. [laughter]
>>But the hacker spaces that
exist are in different regions,

00:32:36.922-->00:32:40.125
you know, around the world for
people to get together- like
minded people to get together

00:32:40.125-->00:32:44.296
and work. It’s not exactly the
same. You know, it was just that
particular time I feel like we

00:32:44.296-->00:32:48.934
were lucky that the seven of us
plus Sillian and Dildog when
they came in later, like- >>And

00:32:48.934-->00:32:52.871
Stephan. >>And Stephan. We just
happened to all click. And it
was just- it just worked.

00:32:52.871-->00:32:56.274
Because there was a lot of other
people in the Boston community
that we hung out with and did

00:32:56.274-->00:33:01.446
stuff with. But for us, it was
just a really special, sort of
lucky thing. Um. Maybe- maybe it

00:33:01.446-->00:33:06.451
can exist. I- I feel like the-
there’s more kind of
commercialism of it. Right?

00:33:06.451-->00:33:11.656
Because we were doing it and we
didn’t expect to make money at
first. When we wanted to, we

00:33:11.656-->00:33:15.327
tried to by selling tshirts and
services and stuff. But it was-
>>L0phtCrack [inaudible]

00:33:15.327-->00:33:19.564
>>L0phtCrack. Yeah, I mean. It-
we weren’t- we weren’t planning
on doing that. But now- >>People

00:33:19.564-->00:33:23.401
want my code. >>It’s- it’s very
financially driven I think a lot
of times. And you can- you can

00:33:23.401-->00:33:28.807
do things on your own and have a
hobby, but if you want to
survive, you have to promote and

00:33:28.807-->00:33:33.411
do things that maybe are more
sensational than prior. >>I’d-
I’d like to go and say, “Yes, it

00:33:33.411-->00:33:38.516
can.” And here are the examples:
Kiosk Computer Club, right
there, you know, Tool, right

00:33:38.516-->00:33:43.421
there. Fantastic examples of,
you know, that sort of hacker
mentality at a much larger

00:33:43.421-->00:33:47.759
scale. You want to look at,
like, specialization as stuff
Dildog really started to go in

00:33:47.759-->00:33:52.330
to. You know, Project 0, I mean,
who doesn’t want to be a part of
that. You know, sort of set up.

00:33:52.330-->00:33:57.202
So it exists out in that sort of
like, uh, you know, uh,
philanthropic sort of thing,

00:33:57.202-->00:34:01.740
that sort of like open thing
like CCC. It exists inside of
organizations like the Google

00:34:01.740-->00:34:06.511
Project 0 sort of stuff. So,
yeah, I think it’s even better
than it used to be. >>One- one-

00:34:06.511-->00:34:12.150
one observation that I’ve got on
that is, um, that many times,
um, um, the availability of the

00:34:12.150-->00:34:17.122
internet conntra- internet
connectivity has allowed people
to collaborate on shorter

00:34:17.122-->00:34:22.594
projects. Like, individual
projects. Um. You know, we have
re- Repose now where people

00:34:22.594-->00:34:26.765
collaborate. We have slack
channels were we collaborate.
And they usually- they might be

00:34:26.765-->00:34:30.769
overlapping from person- you
know, uh, certain groups of
people, but um, you know, you’ll

00:34:30.769-->00:34:36.841
have people working together for
a sole- a single purpose. Um. As
opposed to simply just having a

00:34:36.841-->00:34:41.947
group of friends that hang out.
So instead of being people and
sort of place orientated, a lot

00:34:41.947-->00:34:47.285
of the organization these days
is project oriented and, you
know, outcome and goal oriented

00:34:47.285-->00:34:51.289
type work. Um. You know. I can’t
count the number of slack
channels that I’m on now. Um.

00:34:51.289-->00:34:56.161
And, you know, it just, you
know- all for different kinds of
purposes. And not necessarily

00:34:56.161-->00:35:00.498
for the- the purpose of, like,
making friends and being a close
knit group, but for helping,

00:35:00.498-->00:35:05.437
like, to bring something to bear
to help solve problems, to push
some agenda forward, to make

00:35:05.437-->00:35:10.809
some software that should exist
a reality, or whatever. Um. But
it’s a- I’ve- I’ve just found

00:35:10.809-->00:35:15.880
that it’s easier to, like, make,
uh, small bubbles of projects
and- and work on iterit on

00:35:15.880-->00:35:20.885
those. >>So I’m actually going
to comp the mic. So, uh, I have
a day job and, uh, we actually

00:35:23.321-->00:35:27.892
had Karen Olizary at our
conference in Washington and one
of the things Karen talked about

00:35:27.892-->00:35:32.097
was that corporate environments
and corporate America need to
embrace the hacker community,

00:35:32.097-->00:35:37.502
the security community ‘cause a
lot of the clients that I talk
to still view all of us as

00:35:37.502-->00:35:41.806
enemies. And I’ll walk into a
client meeting and I obviously
don’t dress like this and people

00:35:41.806-->00:35:46.611
are like, “I know you from
Defcon.” And I have to say, “No.
That’s not me.” Because it’s

00:35:46.611-->00:35:50.715
still- there’s still a
perception, and I, like- I
brought my- buy my daughter a

00:35:50.715-->00:35:54.152
tshirt and she goes to school
and people go, “Oh, aren’t
hackers bad?” And she knows the

00:35:54.152-->00:35:57.822
answer. You know. Hackers are
people who get stuff to do
things that the creator didn’t

00:35:57.822-->00:36:03.194
think could be done. Right? >>Do
you have a question? >>Yes.
[laughter] The question is- >>I

00:36:03.194-->00:36:07.132
specifically told you before
the- before you got out here.
>>No, but I can’t moderate

00:36:07.132-->00:36:12.137
myself. So- so what are your
thoughts on- on how we can
better get that sort of-

00:36:14.239-->00:36:18.610
>>desensitivity. >>fix the
relationship between what we all
do here and what businesses do

00:36:18.610-->00:36:24.849
‘cause we’re in conflict more
than not. >>I- I- This was
actually, you know, what drove

00:36:24.849-->00:36:29.888
cyber fast track and what a lot
of folks don’t know is that I
would get pings from NSA and the

00:36:29.888-->00:36:34.092
White House periodically saying,
“You seem to be a DayWater. You
can, you know- you’re- you’re

00:36:34.092-->00:36:37.796
friends with the hacker
community. You may or may not
have a whole bunch of clearances

00:36:37.796-->00:36:42.701
sort of stuff like that. Over
here, you know. How can you- how
can we trick them into doing

00:36:42.701-->00:36:47.105
work for us? ‘Cause they seem
really clever.” And I’m like-
[laughter] Did you really just

00:36:47.105-->00:36:51.776
phrase it that way? I mean, this
is how you make new adversaries.
And I think the- the thing that

00:36:51.776-->00:36:57.215
worked the best is not embrace
the hackers or whatever. It’s to
recognize that it is another,

00:36:57.215-->00:37:01.453
you know, group of people. And
they’re different. And you don’t
have to turn them into you and

00:37:01.453-->00:37:05.990
you don’t have to turn into
them. So if the lost city of
Atlantis just pops up out of

00:37:05.990-->00:37:10.095
nowhere. It has significant
capabilities, you don’t go,
like, “Oh, we got to make them

00:37:10.095-->00:37:13.364
become Americans.” And you don’t
say, like, “Oh. Well we have to
just, you know, attack them.”

00:37:13.364-->00:37:17.736
You don’t know what it is. You
build out a relationship and you
figure out where you have like,

00:37:17.736-->00:37:21.973
you know, goals and
similarities. And you focus on
those and you let people be

00:37:21.973-->00:37:26.077
themselves in the other areas.
That’s what worked. And that’s
where- I- I- I can’t tell you

00:37:26.077-->00:37:31.049
how many times I just sent back
nasty emails. Heath Alexander
and I went head to head a number

00:37:31.049-->00:37:35.954
of times on this. But I don’t
think you have to embrace it. I
think you have to respect it and

00:37:35.954-->00:37:39.657
figure out where you have like
overlaps and where everybody can
move forward without trying to

00:37:39.657-->00:37:43.695
co-opt people. And say like,
“Oh. Cut your hair and become a
government person.” Or, you

00:37:43.695-->00:37:48.700
know, “the hacker way is the
only way.” >>Well, if you cut
your hair! >>Where’s my hair?

00:37:48.700-->00:37:52.670
[laughter] >>But I-I think it,
you know, it’s funny that you
say that because I don’t go into

00:37:52.670-->00:37:56.908
a lot of corporations but I feel
like we’ve done a really good
job as, like, a community to

00:37:56.908-->00:38:01.846
share the good side. And what I
get from people when I do- when
I do go into organizations, they

00:38:04.783-->00:38:07.919
say it’s nice that somebody’s
here that has a different
perspective, right? Because so

00:38:07.919-->00:38:12.223
many people are in their sylos,
they’re working, they don’t go
to Defcon. We sort of think it’s

00:38:12.223-->00:38:17.228
normal to come here. But it’s
not. Right? So having that
perspective and- and- [laughter

00:38:19.264-->00:38:24.536
and applause] Much better. >>You
may not have noticed but that’s
not Weld’s real hair either.

00:38:24.536-->00:38:29.174
>>Yeah, you’re still wearing
your wig you know. >>It’s my
real hair. >>Yeah so I think

00:38:29.174-->00:38:34.379
being- you know, coming in and-
and having a fresh perspective
is ok. It’s just trying to maybe

00:38:34.379-->00:38:39.384
convince people that that’s ok.
>>But we- we feel you. >>Yeah.
[laughter] >>Alright. Thanks

00:38:42.554-->00:38:45.590
Render for breaking the seal on
this one, but I just wanted to
say you guys, um, you were the

00:38:45.590-->00:38:50.495
original bad boys. You know, you
were the original sort of
hackers and, uh, you guys

00:38:50.495-->00:38:54.098
through ups and downs through
the years, here you are all
these years later and, uh,

00:38:54.098-->00:38:57.101
you’re doing good. You know.
You- you turned it around and
you’re doing good for the

00:38:57.101-->00:39:00.738
community and for our industry.
And I just applaud that because
it paved the way and showed that

00:39:00.738-->00:39:04.642
it’s possible no matter how you
started out that you can turn
around. You know. And you can-

00:39:04.642-->00:39:08.313
you can encourage the community
to do awesome things so thank
you for that. And yes, there is

00:39:08.313-->00:39:14.219
a question. So if- >>But- but
folks should realize, who this-
that means a lot to us because

00:39:14.219-->00:39:18.957
that’s Johnny Long for Hacker’s
Charity. >>Yeah [applause] >>So
hearing that from you, given

00:39:18.957-->00:39:24.729
that that’s how we feel about
you means a lot. Thank you.
>>Yeah, thank you. That- You

00:39:24.729-->00:39:30.868
guys showed me that it was
possible so, you know, it really
encouraged me so thank you. But,

00:39:30.868-->00:39:34.339
uh, my question is so let’s
assume you weren’t the good
guys, how long would it take you

00:39:34.339-->00:39:40.078
to take the internet down today?
[laughter] >>Well, kinetically
or? [laughter] [inaudible]

00:39:40.078-->00:39:46.884
>>Well, it’s- it’s actually- we
got that a lot right afterwards
and it was weird ‘cause we- we

00:39:46.884-->00:39:52.390
rode that a lot, but honestly, I
mean, I honestly didn’t even
share a lot of the PGP stuff

00:39:52.390-->00:39:58.630
inside of the L0pht. Um. And a
lot of the questions were well,
if somebody could take the

00:39:58.630-->00:40:03.101
entire internet down, why
haven’t they done it to
demonstrate it? And even back at

00:40:03.101-->00:40:07.105
that time, you saw people
hijacking prefixes. You saw
people redirecting it. I had a

00:40:07.105-->00:40:10.942
friend at MIT that used to
periodically take the east coast
and just route it to a dorm in

00:40:10.942-->00:40:16.014
MIT in order to saturate the
lines just to mess with the
other dorms, uh, over there.

00:40:16.014-->00:40:21.019
[laughter] You know. The- the
L0pht web server was physically
at May East. It was on the fiddy

00:40:23.288-->00:40:28.660
ring at May East. So we- we knew
from whence we spoke, we had a
friend who actually put it there

00:40:28.660-->00:40:34.098
for us free of charge which was
nice. Um. The MD5 components
were all zeros for everybody for

00:40:34.098-->00:40:39.270
the shared secret in order to
talk PGP for the national access
point. Um. But what people

00:40:39.270-->00:40:43.608
didn’t realize is there’s no
value in actually taking down
all of the internet because then

00:40:43.608-->00:40:49.414
you take down all of your
targets as well. If I want to go
in to a foreign area and do a

00:40:49.414-->00:40:55.186
strike, why would I black out
the skies so I can’t fly in
there myself? So the problem is

00:40:55.186-->00:40:59.924
that you can still take it all
down. It will be- it would take
a lot more because the cascading

00:40:59.924-->00:41:05.797
effect and some of the
dampening. And there’s a little
bit of RPKI, some 3379 BGPish

00:41:05.797-->00:41:11.369
sort of stuff. Um. Not much. But
by going to private peering
points, they’ve made it really

00:41:11.369-->00:41:17.108
easy to go in with a scalpel and
take out individual areas,
reroute it, and nobody else

00:41:17.108-->00:41:21.913
notices. And we are seeing the
Crypto hijacking for the mining
pools happening. We’re seeing

00:41:21.913-->00:41:26.317
that, you know, places like, you
know, Iran and other areas, you
know, occasionally, you know,

00:41:26.317-->00:41:30.822
leak the- you know, their route
advertisements out. It’s
probably not even a hijack. It’s

00:41:30.822-->00:41:34.125
because they’re intentionally
routing the stuff through their
own monitoring infrastructure.

00:41:34.125-->00:41:37.328
>>Remember that time North Korea
just disappeared from the
internet for, like, I don’t

00:41:37.328-->00:41:39.764
know. How long? >>I have no
recollection of what you’re
talking about senator.

00:41:39.764-->00:41:43.401
[laughter] >>There’s another-
there’s another aspect to this
question. Uh. Because after we

00:41:43.401-->00:41:47.138
did the testimony, we had
several people come up to us and
say, “Hey. I heard your

00:41:47.138-->00:41:51.042
testimony, take down the
internet, blah, blah, blah. Was
it because you can do X, Y, and

00:41:51.042-->00:41:54.812
Z?” And we’d be like, “Well,
that’s not what we were talking
about, but that would work.”

00:41:54.812-->00:41:59.183
[laughter] >>Yeah. That would
work too. >>And so there were-
at the time there were multiple

00:41:59.183-->00:42:02.820
ways to do what we were talking
about and it- are there other
ways that we don’t know about to

00:42:02.820-->00:42:07.358
do it now? Maybe. >>I mean, I
think you’re seeing it being
taken down in a very interesting

00:42:07.358-->00:42:12.363
way by social media right now on
its own. >>Yeah. >>Thanks John.
>>Hello. Uh. I’m guessing you

00:42:15.867-->00:42:20.371
guys all have a lot of
experience, uh, with the law and
being on the good side and the

00:42:20.371-->00:42:26.911
bad side so my question’s kind
of around that. Uh. The supreme
court came out with the decision

00:42:26.911-->00:42:31.916
a few months ago, uh, and this
is my translation of what I read
was police need a search warrant

00:42:34.352-->00:42:39.857
to go track down a cell phone,
but, uh, the government for
national security reasons,

00:42:39.857-->00:42:45.263
don’t. What do you think of
that? >>I-I think it only
applies to geolocation

00:42:45.263-->00:42:51.969
information. That, in other
words, where the location of the
phone is and tracking of it if

00:42:51.969-->00:42:56.441
I’m remembering the court case
properly. No? >>I thought there
was more to it. >>I don’t know.

00:42:56.441-->00:42:59.744
>>I’m sorry. I thought there was
a lot more to it ‘cause it
rambled on [inaudible] >>Yeah, I

00:42:59.744-->00:43:04.015
didn’t- I didn’t follow up on
that particular case. >>Ok.
>>And I definitely wouldn’t say

00:43:04.015-->00:43:08.319
that we’re all caught up on the
law. How I- [laughter] >>I don’t
think the law’s caught up with

00:43:08.319-->00:43:12.457
Joey G. >>How I- how I ended up
in the L0pht was I got arrested
as a kid because I had nowhere

00:43:12.457-->00:43:19.163
to do what I wanted to do and
these guys accepted me in. So
no, the law is- I don’t think- I

00:43:19.163-->00:43:21.699
don’t know how much we’ve
actually paid attention. At
least, I haven’t paid attention

00:43:21.699-->00:43:26.771
to it even now because I would
rather do something I want to do
and share it and then pay the

00:43:26.771-->00:43:31.909
consequences later. Than not be
able to do it and then, you
know, not be able to release the

00:43:31.909-->00:43:38.516
information. So. [applause]
>>So. So literally I was a
senior official of the

00:43:38.516-->00:43:44.455
department of defense, um, and I
funded, uh, about, uh, 180
different small projects from

00:43:44.455-->00:43:49.827
hacker spaces and individual
folks. I did have to follow the
law, uh, a lot and in particular

00:43:49.827-->00:43:56.100
a lot of US code for Title 10
and Title 50 in addition to CFAA
and electronic communications

00:43:56.100-->00:44:00.738
and privacy act sort of stuff.
Um. I’m not familiar with that
particular case so. Yes, some of

00:44:00.738-->00:44:04.976
us had to follow the law. And
that’s why we became midnight
basketball for hackers for King

00:44:04.976-->00:44:09.480
Pin. >>So I will say though that
since you brought the legal
question, there are a lot of,

00:44:09.480-->00:44:15.820
uh, issues that occur at the
federal level and the state
level that can require, um, a

00:44:15.820-->00:44:22.059
different viewpoint for input.
Ok? Uh. A lot of the people who
are writing these laws may not

00:44:22.059-->00:44:27.732
have the vision to see all the
angles that a specific law or
rule may impact. And that’s

00:44:27.732-->00:44:33.104
where we can come in as hackers.
Right? We can help, uh, inform
the lawmakers of our point of

00:44:33.104-->00:44:37.208
view and how we think that
certain proposed laws may impact
us or other parts of the

00:44:37.208-->00:44:43.281
internet. And so, you know, one
call to action I’ll give now is
to get involved in that process.

00:44:43.281-->00:44:47.385
Right? Call your senator. Write
your representative.
>>Seriously. >>It- it makes a

00:44:47.385-->00:44:52.390
difference. And if you hear
about a law or proposal that’s
getting put forth, let them know

00:44:52.390-->00:44:55.793
that you may be an expert in
that topic and are willing to
talk to their- their staff and

00:44:55.793-->00:44:58.930
their aides. >>Or at the very
least, give them your opinion.
>>Give them your opinion. Write

00:44:58.930-->00:45:02.199
the letter. That stuff makes a
big difference. It makes a big
difference. >>They assume for

00:45:02.199-->00:45:04.435
each call, that there are 100
people that didn’t call. >>Now-
now might be a great time to

00:45:04.435-->00:45:09.207
tell every, you know,
congressperson that you can to
go ahead and read Matt Blazer’s

00:45:09.207-->00:45:14.212
paper on the safety of, uh,
secure voting machines. >>Yeah.
[applause] >>I mean, and that’s

00:45:17.682-->00:45:22.453
a key topic right there. I mean,
I’ve done several briefings in
DC for different staffers of

00:45:22.453-->00:45:27.291
different representatives and
senators and they eat this stuff
up. They really do because

00:45:27.291-->00:45:30.261
they’re hungry and thirsty for
that knowledge. >>For data- for
quantified data. >>They don’t

00:45:30.261-->00:45:33.831
have any other place to get an
unbiased third party opinion
that’s not paid for by a

00:45:33.831-->00:45:37.868
lobbyist. So if you can get
those- maybe if you can write
those letters and let them know

00:45:37.868-->00:45:42.907
your opinions of- of whatever
bills are being passed, it makes
a huge difference. >>And even

00:45:42.907-->00:45:49.513
more importantly, give them your
opinion, but if you have data
points, nobody’s bringing data

00:45:49.513-->00:45:54.819
to this game. >>Yup. >>Our
industry is the only industry
that doesn’t have clinical

00:45:54.819-->00:46:00.725
trials and ground truth and
anything else. You bring numbers
or other things, you stand out.

00:46:00.725-->00:46:05.630
Give them your opinion but for
god's sakes, if you have data or
if you start to measure stuff.

00:46:05.630-->00:46:09.266
That’s how I rebooted DARPA.
That was the entire ALIAC
framework. That was the 125

00:46:09.266-->00:46:13.804
lines of code malware that took
half a billion dollars away from
Keith Alexander and redirected

00:46:13.804-->00:46:17.141
it. You know. ‘Cause it was,
like, we brought data. What do
you have? Well, you’ve got an

00:46:17.141-->00:46:22.146
opinion. That’s great. Here’s
data. [applause] >>Uh, that
actually leads right into my

00:46:27.785-->00:46:33.057
question. Uh. If you guys were
invited back to the Senate now
20 years later, what would be

00:46:33.057-->00:46:39.864
your main message to the
senators? [inaudible] >>I don’t
know. So many to choose from.

00:46:39.864-->00:46:43.401
>>Well, we sort of did that.
>>We did- we did that a couple
of weeks ago- months ago.

00:46:43.401-->00:46:46.671
[laughter] >>Yeah. A couple
months ago. But it wasn’t
directly with the senators. It

00:46:46.671-->00:46:50.608
was- it was with staffers and-
>>It was with staffers. >>you
know, it was basically what had

00:46:50.608-->00:46:56.013
changed, what hadn’t changed.
Um. And you should wa- watch the
video. I mean, there are, you

00:46:56.013-->00:46:59.684
know. >>I guess- I guess a big
message that I would like to
bring is that we’ve come a long

00:46:59.684-->00:47:04.722
way in 20 years, but we’ve got a
lot longer to go- long way to go
with what we’re doing.

00:47:04.722-->00:47:09.960
Especially with the rise of new
technologies like IOT, the risk
in electronic voting, uh, we’ve

00:47:09.960-->00:47:14.665
got, uh, other issues that we
need to talk about. So we have
come a long way in 20 years.

00:47:14.665-->00:47:19.537
We’re not dealing with the same
old doom and gloom, but we still
have a long way to go. >>And my-

00:47:19.537-->00:47:26.210
my personal campaign is, um, you
know, don’t stamp things with
safe or not safe. Don’t do and,

00:47:26.210-->00:47:29.947
you know, I- I’ve got this thing
going back and forth- >>It’s not
hackable. >>Like a UL Seal or a

00:47:29.947-->00:47:33.984
fips with 40. Sort of like does
it pass or not pass sort of
thing. Give them a continuum.

00:47:33.984-->00:47:38.689
Give them a fuel economy. Give
them crash test- crash test
rating. Give them the

00:47:38.689-->00:47:42.760
nutritional labels on the food
so folks can make informed
decisions. Give them

00:47:42.760-->00:47:47.364
transparency about the libraries
that are coming with it.
Something that is measurable

00:47:47.364-->00:47:52.536
because all of the other
industries have this. And we
don’t. And I have nothing for or

00:47:52.536-->00:47:57.508
against. Like, FireEye versus
CrowdStrike versus, you know,
Carbon Black versus whatever.

00:47:57.508-->00:48:01.946
But, like, they all say they’re
the best. And they’re all very
different and you’re putting

00:48:01.946-->00:48:05.116
them in your environment. I
mean, like, if you went to the
grocery store and you’re like,

00:48:05.116-->00:48:09.754
“Well, all the food is just
food.” And there’s nothing else.
No other information. And your

00:48:09.754-->00:48:14.792
doctor’s like, “Don’t you dare
have sodium because you’re going
to die.” And you’re like, “Oh I

00:48:14.792-->00:48:18.996
don’t know. This looks pretty
good. Bacon.” [laughs] There’s-
if there’s no information you

00:48:18.996-->00:48:22.166
can’t make an informed decision
so that’s what I actually talked
to the senators about. It’s

00:48:22.166-->00:48:27.238
like, that is something that the
government can do a little bit
and I wouldn’t use liability

00:48:27.238-->00:48:31.542
like we said during the first
time. That went over like a lead
balloon, um, with the Senate. I

00:48:31.542-->00:48:35.579
didn’t said- say- like, you
know, instead of structures. Um.
You know, or other ways of,

00:48:35.579-->00:48:39.850
like, encouraging people, to you
know, in- you know, maybe giving
them tax breaks or whatever for

00:48:39.850-->00:48:44.722
organizations if they al- you
know, gave that data so that
folks can make their informed

00:48:44.722-->00:48:48.492
decisions ‘cause one size
doesn’t fit all. >>It’s all how
you word it, right? >>Yeah.

00:48:48.492-->00:48:52.763
>>Yeah, I think the other thing
sor- that we sort of touched on
in this meeting here and

00:48:52.763-->00:48:56.734
something I think that I would
spend more time talking about is
they had asked us, like, “Well,

00:48:56.734-->00:49:01.705
what can we do for legislation.”
And sort of the answer was have
less of it. You know. Get rid of

00:49:01.705-->00:49:05.943
DMCA and- and don’t prevent us
from doing security research
‘cause we’re- we’re the good

00:49:05.943-->00:49:10.414
guys. We’re still the good guys.
So I think that would have to be
a big point of, like, letting

00:49:10.414-->00:49:13.851
them you know you don’t need
more laws to make stuff happen.
You can kind of let back a

00:49:13.851-->00:49:17.655
little bit and let people get
some more freedom to do things.
>>Well, that was an interesting

00:49:17.655-->00:49:22.059
time because they draw 514,
DMCA, and, uh, uh, WIPO, uh,
Weld and Intellectual Property,

00:49:22.059-->00:49:27.932
you know, uh, stuff was all
coming out. So our big message
to them then was do not make it

00:49:27.932-->00:49:32.703
illegal to see what’s in the
sausage. Uh, you know, because
that’s what they were going to

00:49:32.703-->00:49:37.007
do. And I think today,
unfortunately, it’s kind of the
same message except now it’s

00:49:37.007-->00:49:41.111
advertise what’s in all the
sausage so that folks can figure
out whether it’s kosher or not

00:49:41.111-->00:49:46.116
because it matters to certain
people. >>So this is a tweet
from Dan Kenzking 2014. For an

00:49:49.353-->00:49:53.123
industry built on layers of
abstraction, there is a
remarkable lack of historical

00:49:53.123-->00:49:58.095
awareness around older technical
design decisions. In the context
of the Cloud and DevOps

00:49:58.095-->00:50:03.467
development, do you think that’s
making the problem worse or
better? [off mic] >>It’s what I

00:50:03.467-->00:50:07.838
heard the question. >>Could you
repeat that? >>Yeah. Sorry.
[laughter] We missed a little of

00:50:07.838-->00:50:11.942
that. >>Sorry. Uh. You- you
could tweet wo- >>At the
beginning. >>Just swallow the

00:50:11.942-->00:50:16.947
mic also please. We can’t hear
you. Thank you. >>There you go.
Right up there. >>Ok. Dan

00:50:16.947-->00:50:20.317
Kenzking tweet, 2014. For an
industry built on layers of
abstraction, there is a

00:50:20.317-->00:50:26.123
remarkable lack of historical
awareness around older technical
design decisions. In the context

00:50:26.123-->00:50:31.161
of the Cloud and DevOps
development, do you think that
the problem is getting worse or

00:50:31.161-->00:50:36.500
better? >>Awh. >>So- you know,
some of these foundational
things that everything still

00:50:36.500-->00:50:43.107
sits on have really not been
fixed. Like- like BGP still has
problems. DNS has problems. Uh.

00:50:43.107-->00:50:48.345
The whole SSL certificates
system has problems. Um. And
this is something that we talked

00:50:48.345-->00:50:53.918
about when we talked, uh, a few
months ago up, uh, up at the
Senate is, you know, it just

00:50:53.918-->00:50:58.422
seems like we’re just sort of
biting time and just hoping
everything just keeps going ok

00:50:58.422-->00:51:02.793
as we become more and more
dependent on- on- on technical-
that- that technical

00:51:02.793-->00:51:06.597
infrastructure. You know. Every
year goes by, we’re more and
more dependent. You know. I- I

00:51:06.597-->00:51:10.401
don’t want to be dependent on
that when, like, the only doctor
that can operate on me is doing,

00:51:10.401-->00:51:15.072
like, telepresence across the
planet and someone launches a
BPG attack. Right? So we’re

00:51:15.072-->00:51:19.076
getting more dependent on this
stuff, but nobody’s really going
back and doing a good job trying

00:51:19.076-->00:51:24.315
to fix the foundations. >>And I
think the hacker community and
InfoSec in general has a pretty

00:51:24.315-->00:51:29.019
short memory. Right? So because
there’s so much information
coming out, there’s, what, 500

00:51:29.019-->00:51:35.192
something talks just at Defcon
now. Um. And it’s hard to sort
of know what the pri-prior

00:51:35.192-->00:51:39.596
decisions were or even prior
work. Right? So we’re seeing
repeating stuff and I don’t know

00:51:39.596-->00:51:45.569
if there’s a way Cloud or not,
like how to- how to cha- how to
consolidate that in some way.

00:51:45.569-->00:51:50.407
And I know, you know, the Dark
Tangent’s trying to do it with
InfoSet dot org or something to

00:51:50.407-->00:51:55.012
harvest all of everybody’s talks
from all over the world, but I
don’t know how- how we can get-

00:51:55.012-->00:51:59.249
have a cohesive memory of, like,
our entire community or
something. But I think that’s

00:51:59.249-->00:52:02.853
what you need to- to learn what
happened in the past. [off mic
comment] What’s that? [off mic]

00:52:02.853-->00:52:06.090
>>A lot you might want to
forget. Well, a lot of you might
want to forget. But- oh, you

00:52:06.090-->00:52:09.760
know what. Maybe we should just
put everything in, like,
blockchain. [applause and

00:52:09.760-->00:52:14.765
laughter] Woul- would that work?
I’m a hardware guy. >>Uh. Ha. In
terms of, uh, you know, the

00:52:18.502-->00:52:25.109
processes by which we, uh, write
software and things changing
over time, um, it used to be

00:52:25.109-->00:52:30.214
that you simply did not find out
about security issues until
software was published. Um.

00:52:30.214-->00:52:35.319
These days we find out about it
sooner and sooner because of the
availability of, uh, various

00:52:35.319-->00:52:39.289
types of testing. You know, I
made it my business for, like,
10 years to write static

00:52:39.289-->00:52:43.827
analysis software that can make
it easier to find flaws before
they went out the door. Um. But

00:52:43.827-->00:52:50.501
that was met with a lot of
resistance by developers. Um. To
really continue to affect change

00:52:50.501-->00:52:55.672
in the future, to improve the
state of things, developers need
to be more involved in finding

00:52:55.672-->00:53:01.712
their bugs and fixing them
sooner. Um. That said, there’s a
lot of friction there because

00:53:01.712-->00:53:05.783
the tools aren’t very good for
developers. They’re not written
with developers in mind. They’re

00:53:05.783-->00:53:12.322
written with AbSec people in
mind. And the profile, the use
case for developers iterating

00:53:12.322-->00:53:18.362
quickly on code and trying to
get things out the door quicker,
is, uh, counter- it- it- it’s

00:53:18.362-->00:53:23.634
dis- disincentivizes, uh, uh,
uh, security analysis. So coming
up with tools that developers

00:53:23.634-->00:53:29.239
can actually use that are low
false positive rate and, uh,
fast enough to be part of their

00:53:29.239-->00:53:33.444
process is really key. And I
know, I’m going to go ahead and
say this is something that I’m

00:53:33.444-->00:53:38.949
working on actively, um, you
know, today I know that that’s,
you know, where I need to be in

00:53:38.949-->00:53:43.787
terms of developing tools. Um.
You know, but, in general
pushing the cultural envelope

00:53:43.787-->00:53:48.859
for developers to make it such
that security is something that
not only is something that they

00:53:48.859-->00:53:53.063
want to do, um, because it makes
them feel good. I mean, the
developers that I talk to do

00:53:53.063-->00:53:56.800
want to write secure code. They
do want to use tools. They just
don’t want to be a pain- have it

00:53:56.800-->00:54:01.738
be a pain in the butt. Um. So,
meeting them where they are.
Instead of forcing their- the

00:54:01.738-->00:54:06.643
hand through, uh, you know,
draconian security teams who
won’t let code out the door, um,

00:54:06.643-->00:54:11.648
is- is really where we have to
be. Um. It’s hard work for the
security community to do that.

00:54:13.750-->00:54:19.323
It’s been historically over the
last 10 years, we have simply
said, you know, “Fix your code

00:54:19.323-->00:54:24.495
or by the time it goes out
you’re going to be a- you’re
going to have your pants pulled

00:54:24.495-->00:54:26.930
down or be embarrassed by all
these vulnerabilities.” Uh. But
that’s intellectually lazy on

00:54:26.930-->00:54:33.670
our part. It’s simply, you know,
saying that, um, it’s good
enough to, you know,

00:54:33.670-->00:54:38.408
em-embarrass developers, uh,
into- into attempting to write
more secure code. That’s not

00:54:38.408-->00:54:42.646
going to attack the problem at
scale. We actually have to help
them make it easier. Um. And

00:54:42.646-->00:54:46.283
that means becoming their
friend. Uh. It- it means not
being an advers- seen as an

00:54:46.283-->00:54:50.154
adversary to development. So.
>>One- one of the things that
would actually help a lot for

00:54:50.154-->00:54:54.024
developers and DevOps and
everything, and then I’ll touch
upon the Cloud thing because I

00:54:54.024-->00:54:58.128
think that’s a very, uh,
important question, is some sort
of feedback. So if you turn on,

00:54:58.128-->00:55:01.331
like, StackGuards, you have no
clue whether it actually
inserted them or not. >>Right.

00:55:01.331-->00:55:04.902
Right. >>You turn on Fortify
Source on, like, a linux system,
you have no clue whether it

00:55:04.902-->00:55:08.071
removed 90 percent of the weak
functions that you didn’t know
that you shouldn’t have put in

00:55:08.071-->00:55:13.377
there with strong ones. Or point
0, 0, 5 and actually it’s closer
to the latter in a lot of cases.

00:55:13.377-->00:55:17.247
So there’s no feedback for
developers- >>Right. >>as to
whether, you know, when they’re

00:55:17.247-->00:55:21.485
trying to do the right thing,
it’s having an effect or not.
Um. So I do think that’s

00:55:21.485-->00:55:25.956
something that we could do a lot
better as a security community
is, like, providing feedback and

00:55:25.956-->00:55:30.928
measurements. Um. But on the
Cloud stuff, I’m actually really
impressed with the Cloud from

00:55:30.928-->00:55:35.432
the large providers, not so much
from the small ones. And it’s
because they’re essentially

00:55:35.432-->00:55:42.172
getting fuzzed all the time by
their users. So if you look at
Amazon or GCE or anybody else,

00:55:42.172-->00:55:48.045
they’ve- they’re really hardened
in a lot of ways- or Azure- you
know, sort of stuff because they

00:55:48.045-->00:55:52.716
have millions of users who are
doing crazy stuff all the time
in the real world and also

00:55:52.716-->00:55:57.921
they’re doing AB testing as to
what to roll out. So, yeah, I
actually think that abstraction

00:55:57.921-->00:56:02.359
at scale if it was, like- if you
think of the world as AFL at
large, you know, just, you know,

00:56:02.359-->00:56:07.898
as a- a Mechanical Turk version
of AFL, um, yeah, that’s
actually really useful for the

00:56:07.898-->00:56:14.471
large providers, but the small
ones don’t get that benefit. And
I- they scare me. So Cloud’s a

00:56:14.471-->00:56:19.509
mixed bag. >>Yeah. >>This is for
Mudge. Tell us about the
election hacking and your

00:56:19.509-->00:56:26.083
response. >>Does it have to be
Mudge? >>Does it have to be
Mudge? >>It doesn’t have to be.

00:56:26.083-->00:56:30.621
I just know- >>It’s a topic I’ve
talked about a lot. >>Um. >>So
I’ve got a question for you.

00:56:30.621-->00:56:36.760
>>You’ve got a question? Go
ahead. >>I’ve been wondering
how- if you can tell me, um, I

00:56:36.760-->00:56:40.964
don’t know, statute of
limitations- when they- you
know, when that ends, but, um,

00:56:40.964-->00:56:44.134
what’s your most- >>Are you
implying that we did anything
that requires statute of

00:56:44.134-->00:56:48.238
limitations? Ma’am? [laughter]
>>I don’t know! You’re- you’re-
you’re at Defcon. You’re up on

00:56:48.238-->00:56:53.610
this stage. I don’t- I don’t
know. Um. [laughter] >>What-
what was- what are your most,

00:56:53.610-->00:57:00.083
like, what’s your most fun or
entertaining or memorable hack
that you can talk about? [panel

00:57:00.083-->00:57:05.289
laughter] >>No comment. >>Yeah,
no comment. [laughter] >>Do you
guys remember the midnight poker

00:57:05.289-->00:57:10.227
nights with Hobbit? [laughter]
I’ll see you a guddopleble a
high Sp enlotvia and raise you

00:57:10.227-->00:57:16.033
a- a small, uh, internet
connectivity area in the, uh,
gulf states for, um, you know

00:57:16.033-->00:57:21.805
>>Ok. You- you need to shut up
right now. [laughter] >>It’s a
joke. It’s a joke. >>But back to

00:57:21.805-->00:57:25.475
the- back to, uh, Rogue Agent’s
election question. Um. I think
the thing to keep in mind when

00:57:25.475-->00:57:31.348
we read about election hacking
in the press is that there’s a
big difference between, uh,

00:57:31.348-->00:57:36.353
probing a registration database,
and changing an actual vote in a
real election. Uh. And there’s a

00:57:39.089-->00:57:44.795
very big blurring in the media
between oh, my god. The election
was hacked. Or the- the- the

00:57:44.795-->00:57:51.001
voters were hacked in some state
and whether or not a vote was
actually changed. I, aeh- You

00:57:51.001-->00:57:56.540
ok? >>Yeah. >>Alright. So that-
>>But what have you heard?
[laughter] >>So I just- I think

00:57:56.540-->00:58:00.944
it’s important to keep that in
mind. And when you- when you see
these, uh, media reports of a

00:58:00.944-->00:58:04.481
registration database was probed
or- or copied or whatever,
that’s not the same thing as

00:58:04.481-->00:58:08.018
someone breaking into an
election and changing an actual
vote. >>It- it- it’s not the

00:58:08.018-->00:58:12.356
same thing, but all this in the
media over and over again, votes
are getting hacked. Votes are-

00:58:12.356-->00:58:17.761
systems are vulnerable with
this. It makes it so that people
don’t trust the system. >>And I

00:58:17.761-->00:58:21.665
think that that’s partly-
>>Right? People don’t understand
it so they aren’t going to trust

00:58:21.665-->00:58:23.667
the system. >>That’s- >>So less
people are going to vote. And
there are actually people out

00:58:23.667-->00:58:26.903
there who don’t believe our
president was elected
legitimately because they

00:58:26.903-->00:58:30.474
believe systems were hacked.
There are people who believe
that- >>Right. And I think

00:58:30.474-->00:58:33.143
that’s part of the problem.
Right? >>So if that gets worse,
right? >>That’s part of- that

00:58:33.143-->00:58:38.215
was part of the goal was that
they’re trying to dis- uh, cause
mayhem by forcing people- or

00:58:38.215-->00:58:42.352
changing people’s mind. >>Who’s
they? >>I’m not going to get
into who’s they. It could- it

00:58:42.352-->00:58:45.288
could be anybody, but a lot of
this- [laughter] a lot of the
information that we’re seeing

00:58:45.288-->00:58:50.293
reported in the media. And I’m
not going to 400 pounds.
[laughter] I’m not going there.

00:58:50.293-->00:58:57.000
Uh. There’s a lot of people in-
that- now I’ve lost my train of
thought. Go ahead. >>So- so it’s

00:58:57.000-->00:59:01.004
>>Actually it’s- it’s- it’s
really- >>We only have a few
more minutes left. But- >>I just

00:59:01.004-->00:59:04.274
want to give a pointer to the
answer there. Um. >>Ok. Please
do. >>Alex Handleman and the

00:59:04.274-->00:59:08.612
folks that- of, uh, University
of Michigan, uh, went over to
Winstonia and what a lot of what

00:59:08.612-->00:59:12.182
folks don’t know is that was
actually a part of the Google
project that I ran for Project

00:59:12.182-->00:59:18.522
Vault. And watch the video of an
actual online e-voting internet
sort of environment. It is

00:59:18.522-->00:59:24.494
amazing and terrifying and it is
15 years old and hasn’t been
updated. And it is still the

00:59:24.494-->00:59:29.499
exemplar of the best thing out
there which should make people
pause. >>Yeah. Bear in mind that

00:59:31.835-->00:59:36.239
the real election hacking is
being done by our own government
is called gerrymandering and you

00:59:36.239-->00:59:41.912
can vote against it. [applause]
>>Yeah! >>That is the perfect
point to close on. >>We can just

00:59:41.912-->00:59:45.682
drop the mic and walk out on
that. Honestly. >>So- so I want
to thank all you guys >>So-

00:59:45.682-->00:59:51.087
>>That- that was awesome. Uh. Go
ahead, Eleanor. I’m sorry. >>One
last question. Um. If you- what

00:59:51.087-->00:59:55.559
advice to you have for hackers
are researchers- security
researchers today? Let’s go-

00:59:55.559-->01:00:00.096
let’s start with at the end of
the- the line and just move this
way. Advice for people in the

01:00:00.096-->01:00:05.101
audience. >>Um. Never be afraid
to get started on something. Um.
I, uh, often times get into form

01:00:10.574-->01:00:15.879
of analysis paralysis wondering
if the thing I’m going to do is
going to either make me money or

01:00:15.879-->01:00:20.717
be valuable or whether, you
know, people will notice it. Um.
You just simply don’t know. Um.

01:00:20.717-->01:00:25.655
If it’s interesting, get started
on it. Tear it apart. Um. You
know. Make it your quest to

01:00:25.655-->01:00:30.927
learn that thing as much as
possible. Um. Break new ground
whenever you can. Uh. If you

01:00:30.927-->01:00:35.932
think nobody else has maybe done
it, just do it. Um. And try to
finish what you start. It’s the

01:00:35.932-->01:00:39.669
hardest thing ever when you’ve
got a million ideas but it’s-
that’s the only way anything

01:00:39.669-->01:00:45.308
ever gets done. So. >>I think my
big advice to security
researchers today is just be

01:00:45.308-->01:00:50.780
careful. Alright? There’s a lot
of companies that don’t like
you. There are laws that don’t

01:00:50.780-->01:00:57.087
like you. Uh. Um. That doesn’t
mean don’t do it. Please keep
doing what you do, but be

01:00:57.087-->01:01:03.159
careful. Do some research on the
laws. Don’t cross the lines.
Stay out of jail. Stay out of

01:01:03.159-->01:01:08.164
the courtroom. >>I’d say play
the long game. Um. You know, I
remember going out to talk to

01:01:11.601-->01:01:17.574
kadets when I was at the L0pht.
Those kadets are now Colonels.
Um. And they actually have

01:01:17.574-->01:01:22.812
impact. Same thing with
senators’ aides. Um. Same thing
with CFT. I mean, King Pin came

01:01:22.812-->01:01:26.816
up at the end of my talk at
Defcon, like, a few years back
going like we didn’t know what

01:01:26.816-->01:01:30.954
the heck, you know, Mudge turned
into the man. What’s going on?
[laughter] And I got a lot of

01:01:30.954-->01:01:35.292
crap for it, but then folks saw
that no- actually, no. It’s
still kind of Mudge trying to

01:01:35.292-->01:01:38.662
make a dent in the universe sort
of thing. >>And you made it easy
for us to take government money.

01:01:38.662-->01:01:42.832
[laughter] >>We got one minute
guys. >>So but- play the long
game. Everybody else is

01:01:42.832-->01:01:49.639
optimizing locally. Optimize
globally and for the long term.
>>Uh. I guess a lot of people

01:01:49.639-->01:01:55.712
ask me, like, what they should
focus on in terms of uh, uh, you
know, people I work with that

01:01:55.712-->01:02:01.284
are actually coming to me to
learn how to get more advanced
in their security testing and,

01:02:01.284-->01:02:06.189
uh, everybody wants me to point
them at something that companies
using or would be useful or

01:02:06.189-->01:02:09.759
whatever. But ultimately it has
to be something you’re really
interested in because it’s going

01:02:09.759-->01:02:15.599
to take tons of hours of, uh,
your devotion so, um, obviously
focus on that. And then the

01:02:15.599-->01:02:20.870
other thing I would say is that,
uh, it’s really easy to get
wrapped up in the excitement of

01:02:20.870-->01:02:26.610
things and make mistakes and
today desk space is cheap and
there’s this concept of big

01:02:26.610-->01:02:30.880
data- everybody’s collecting
data on everything. So a lot of
things that we may have gotten

01:02:30.880-->01:02:36.920
away with as kids, I think we
got really lucky. Um. And, uh,
so def- definitely a much more

01:02:36.920-->01:02:43.126
dangerous, uh, environment out
there for people so, um, you
know, make sure you- you, uh,

01:02:43.126-->01:02:47.731
are careful not to cross the
line. More careful than, you
know, I think kids normally are.

01:02:47.731-->01:02:52.602
>>Yeah. But don’t be afraid to
fail either. Otherwise you’ll,
you know- >>Uh. So- so I would

01:02:52.602-->01:02:57.340
say, you know, I hope you
welcome the newbies. Be nice to
them. They have imposter

01:02:57.340-->01:03:03.680
syndrome. Um. And, uh- but- but
if they’re here, they want to
learn. Um. And the- the other

01:03:03.680-->01:03:08.685
thing I would say is network
with people that aren’t just
like you. Like people when you

01:03:08.685-->01:03:14.424
go back to the office [applause]
developers, UI people, managers-
get them to understand how we

01:03:14.424-->01:03:20.864
think. Um. So, you know, s- s-
spread it a little bit outside
our community. >>I think you

01:03:20.864-->01:03:24.668
just have to love what you do.
And it doesn’t matter what it
is, but if you are passionate

01:03:24.668-->01:03:27.804
about something, like, that’s
really what you want to do. You
want to find something that you

01:03:27.804-->01:03:30.874
really care about. And you
shouldn’t be searching for
money. You shouldn’t be

01:03:30.874-->01:03:35.045
searching for being on a stage.
You shouldn’t be searching for,
you know, branding your

01:03:35.045-->01:03:40.750
whatever. Yes, I’m up here. That
wasn’t the goal when I started
hacking. [laughter] But it’s

01:03:40.750-->01:03:44.487
because I love what I do and if
you do that, you can look around
Defcon and there’s a lot of

01:03:44.487-->01:03:49.492
people that do amazing things
that- that are not on a stage.
They’re doing stuff that you’re-

01:03:49.492-->01:03:53.496
you’re not going to read about
in the news. And it’s all over
this entire hotel. Right? So

01:03:53.496-->01:03:58.501
you- you find something that you
love and good things are going
to happen. >>Great. Thank you.

01:04:04.708-->01:04:07.343
[applause]

