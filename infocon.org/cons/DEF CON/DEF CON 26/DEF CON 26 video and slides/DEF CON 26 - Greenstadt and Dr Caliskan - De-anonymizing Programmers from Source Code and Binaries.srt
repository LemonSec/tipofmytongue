00:00:00.000-->00:00:06.039
>>So I am Aylin Caliskan and I
used to be Rachel's PhD student
but I just started as a

00:00:06.039-->00:00:10.410
professor and this is my first
talk as a professor so it’s very
exciting for me. [audience

00:00:16.283-->00:00:19.953
applauds] [sigh from speaker]
And I’ll go over the first half
of slides, half set of slides,

00:00:19.953-->00:00:24.658
and after that Rachel will
continue with her new findings
in our research and today we

00:00:24.658-->00:00:31.531
will be talking about how we can
de-anonymize programmers based
on their coding style. Uh,

00:00:31.531-->00:00:37.638
Stylometry. Stylometry is the
study of language. Study of
style in language. And when we

00:00:37.638-->00:00:42.376
say language, um, we mostly
think about natural language
which is for example, English,

00:00:42.376-->00:00:46.914
that we speak or our native
languages but there also are
artificial languages. For

00:00:46.914-->00:00:53.020
example, programming languages
are artificial languages and,
uh, when we say Stylometry we

00:00:53.020-->00:00:57.758
wanted to look at all kinds of
languages. And on the natural
language side we have been

00:00:57.758-->00:01:02.262
looking at English, or English
as a second language, to
identify the native language of

00:01:02.262-->00:01:08.769
a speaker or translated text so
that we can again identify the
native language or the

00:01:08.769-->00:01:13.640
translator that has been used as
well as the alter. And we will
be looking at underground forum

00:01:13.640-->00:01:19.479
texts where underground, uh,
forum users engage in business
transactions and so on and

00:01:19.479-->00:01:25.786
they’re still able to identify
the alters, uh, from the
ambassadors. And in artificial

00:01:25.786-->00:01:31.358
languages we wanted to see if
coding style, um, is unique for
each programmer so that it

00:01:31.358-->00:01:36.964
becomes a fingerprint for them.
And we have been focusing on
Python as a list C and C plus

00:01:36.964-->00:01:42.002
plus. And we looked at Source
Code and we saw that there’s
very high accuracy in

00:01:42.002-->00:01:47.040
[inaudible] programs for source
code so we wanted to see if we
can do this with binaries as

00:01:47.040-->00:01:52.379
well. And, uh, this work, the
tools that we have developed and
made open source are being used

00:01:52.379-->00:01:57.651
by many researchers or different
agencies as well, such as the
FBI or expert witnesses. They

00:01:57.651-->00:02:02.622
can use this scientific
information in court while
testifying. And European high

00:02:02.622-->00:02:09.229
tech crime units are using this
to, for example, identify
suspects uh, in different online

00:02:09.229-->00:02:14.234
platforms. And uh, regarding
artificial languages, focusing
on, uh, code, uh, DARPA is

00:02:16.837-->00:02:21.641
interested in this project as
you might imagine, since they
are a part of department of

00:02:21.641-->00:02:26.646
defense and they might want to
know the identities of malicious
actors as well as, uh, oops, as

00:02:28.715-->00:02:33.954
well as expert witnesses and the
US Army Research Laboratory,
which we are collaborating with

00:02:33.954-->00:02:39.993
and this has been an ongoing
collaboration for 4 years now.
Okay, why would we like to be an

00:02:39.993-->00:02:44.498
optimized program? Well first of
all, uh, it’s uh, out of
scientific curisodity. I would

00:02:44.498-->00:02:49.803
like to know since we learned
programming on an individual
basis, do we end up able to open

00:02:49.803-->00:02:54.908
up a unique coding style? And
this can be used for software
forensics or detecting

00:02:54.908-->00:03:00.747
plagiarism, but at the same time
we can use this, for example,
verification of altership or,

00:03:00.747-->00:03:07.054
uh, disconaiding copyright, uh,
investigations. But at the same
time, such uh, for example,

00:03:07.054-->00:03:13.093
security enhancing technologies
can be very privacy infringing
and it can be used at the same

00:03:13.093-->00:03:18.131
time for surveillance and to
track some programmers. Uh,
Saeed Malekpour is one example

00:03:18.131-->00:03:23.036
where we can see security
enhancing technologies can at
the same time be very privacy

00:03:23.036-->00:03:28.041
infringing. Uh, Saeed Malekpour,
he’s an Iranian citizen and he
was identified as the programmer

00:03:30.310-->00:03:36.616
of a porn site and when he went
to Iran he was arrested and he
was sentenced to death and he

00:03:36.616-->00:03:42.189
has been in prison for years now
and he couldn't get out even
though he’s a Canadian resident

00:03:42.189-->00:03:46.726
just because he was identified
as the programmer of this site
that is against Iranian

00:03:46.726-->00:03:51.731
government's, uh, views. Okay
how can you source code
Stylometry, uh, from a machine

00:03:54.101-->00:03:59.473
learning perspective? Um, I’ll
try to go not into too many
details but try to give you the

00:03:59.473-->00:04:03.910
basics about machine learning so
that you understand the flow of
how we can deanonymize

00:04:03.910-->00:04:09.149
programmers. And we are looking
at different tasks such as
multiclass or two class machine

00:04:09.149-->00:04:14.020
learning. Uh, tasks where we
can, for example, do software
forensics, plagiarism

00:04:14.020-->00:04:18.425
detections, copyright
investigations in two party
cases as well as altership

00:04:18.425-->00:04:24.698
verification which will be a
long class to open world machine
learning task. And in order to

00:04:24.698-->00:04:29.970
do this we have the traditional
machine learning verb flow
where, first of all, we need

00:04:29.970-->00:04:35.475
training data that is presenting
to both what we’re looking for
and then with this training data

00:04:35.475-->00:04:40.780
we extract some features that
are presentative of coding
properties or coding style and

00:04:40.780-->00:04:47.721
we feed this these features into
machine learning classifier so
that we can train the classifier

00:04:47.721-->00:04:53.493
to learn each alters coding
style from the features that we
extracted and after that, take

00:04:53.493-->00:04:59.499
the test samples and use the
machine learning classifier to
identify who this take, uh, who

00:04:59.499-->00:05:04.504
this source code sample or
binary or text sample belongs
to. And in this case we are

00:05:04.504-->00:05:10.577
using random forums because, uh,
by nature they’re multiclass
classifiers and then den, they

00:05:10.577-->00:05:15.582
don't tend to over fit. And when
we use this classic, um, machine
learning verb flow, we see that

00:05:18.051-->00:05:22.589
we get very high accuracies in
de-anonymizing programmers which
is showing that, uh, if

00:05:22.589-->00:05:27.627
programmers would like to remain
anonymous this is a serious
track to their anonymity if they

00:05:27.627-->00:05:32.098
want to, uh, for example,
contribute to open source
depositories and it would still

00:05:32.098-->00:05:38.205
like to remain anonymous. And,
for example, with light scale
the anonymization of 1,600

00:05:38.205-->00:05:43.877
programmers each with 9 source
code samples that are on average
50, uh, 70 lines of code, uh, we

00:05:43.877-->00:05:48.882
get 94 percent accuracy in
de-anonymizing or identifying
the alters of 14,400 code

00:05:53.220-->00:05:59.159
samples. And in order to do this
we need to develop a method and
while we were first developing

00:05:59.159-->00:06:04.431
the method, uh, we need a
controlled environment to do
this. And for that we chose

00:06:04.431-->00:06:09.169
Google Code Jam as our
development data set. Google
Code Jam is an annual

00:06:09.169-->00:06:13.907
competition where contestants
from all over the world try to
solve algorithmic questions, uh,

00:06:13.907-->00:06:18.979
within a limited amount of time.
And as they are able to provide
their solutions, correct

00:06:18.979-->00:06:23.984
solutions, they get posted
online uh, Google post them and
they uh, they go to higher

00:06:26.119-->00:06:32.425
rounds where programs become, or
the, uh, problem becomes harder
and they have to implement more

00:06:32.425-->00:06:38.465
sophisticated functionality so
that we can control for the, uh,
the difficulty of the problem as

00:06:38.465-->00:06:44.137
well as how advanced the
programmer is. Okay, we have our
data set, and we collected uh,

00:06:44.137-->00:06:49.142
source code samples from 1,600
programmers and we pre-process
uh, the code samples especially

00:06:51.378-->00:06:56.750
to get the abstract syntax trees
from source code. And for that
we used a fuzzy abstract syntax

00:06:56.750-->00:07:03.056
tree for our serve which is able
to uh, even pass incomplete
source code. And uh, with the

00:07:03.056-->00:07:09.529
abstract syntax tree that
represents the grammatical
structure of code uh, we start

00:07:09.529-->00:07:15.869
extracting features, feed it
into a random forest, and each
tree of these 500 trees in the

00:07:15.869-->00:07:21.508
random forest are voting for one
particular programmer as the
most likely programmer to have

00:07:21.508-->00:07:27.847
written uh, a particular
disputed test sample and then we
do classification. And when

00:07:27.847-->00:07:32.285
we’re talking about features uh,
we’ll look at different
categories of features. For

00:07:32.285-->00:07:38.758
example, uh when we look at the
source code sample on the left
side we see how function names,

00:07:38.758-->00:07:43.897
or variable names, uh, are
chosen by programmers and these
are higher level features that

00:07:43.897-->00:07:49.002
can be more easily changed. Uh,
and they are called lexical
features. And spaces, or

00:07:49.002-->00:07:53.440
deformatting, is also part of
these lexical features. But
there are also syntactic

00:07:53.440-->00:07:58.912
features such as the grammar of
natural language. In this case
this is the syntax, the

00:07:58.912-->00:08:04.284
properties of this programming
language. And when we get to
abstract syntax tree we can see

00:08:04.284-->00:08:09.823
how complicated this uh,
structure can get. And based on
this, we extract features such

00:08:09.823-->00:08:16.029
as, okay, from the lexical side,
things like just variable names,
function names uh, spacing,

00:08:16.029-->00:08:22.235
bigrams, or uh, features like
this. But on the abstract syntax
tree side we are looking at more

00:08:22.235-->00:08:27.507
structured features and we
abstract things from about uh,
50 different abstract syntax

00:08:27.507-->00:08:32.278
tree notes such as function and
statement. Two notes that are
connected to each other with an

00:08:32.278-->00:08:38.718
edge. And then how, the, the
average, uh depth of uh, a note
is, for example. And these are

00:08:38.718-->00:08:44.724
very identifying features and
they are not as trivial to
change quickly. And how can we

00:08:44.724-->00:08:50.597
use these in real world
scenarios? Okay we, uh, extract
these features and lets try to

00:08:50.597-->00:08:56.603
see how we can represent and or
replicate real world cases.
Let’s say that we would like to

00:08:56.603-->00:09:01.541
find out who Satoshi Nakamoto
is. And let's say that uh, we
have a suspect set of size X. We

00:09:03.743-->00:09:10.350
take the suspect sets um, source
code samples from the past so
that we can uh, train

00:09:10.350-->00:09:16.623
classifiers with this training
data from the suspect set.
Extract features and then take

00:09:16.623-->00:09:23.396
bitcoin’s initial gitcode as a
test sample and then try to see
which programmer is most likely

00:09:23.396-->00:09:28.401
the alter of bitcoin’s uh, first
git commit. And when we try to
replicate this scenario, take

00:09:31.638-->00:09:36.342
1,600 programmers from Google
Code Jam though, this is not a
suspect set. Uh, with these

00:09:36.342-->00:09:41.347
1,600 programmers we use 9 files
for each of them and then uh, we
get 94 percent accuracy in

00:09:45.018-->00:09:50.023
correctly identifying these and
we use 9 fold cross validation
for this. Uh, what happens if a

00:09:52.892-->00:09:58.465
programmer would like to stay
anonymous and no set coding
style will give them away? Uh,

00:09:58.465-->00:10:03.937
obfuscation is the first thing
that comes to my mind an uh, off
the shelf obfuscators such as

00:10:03.937-->00:10:09.876
Stunnix, and it’s available
online many programmers use it.
And when we take it to obfuscate

00:10:09.876-->00:10:15.782
our code, here we see the origin
of sample and we can see
different spacing or formatting

00:10:15.782-->00:10:21.087
with uh, a certain abstract
syntax tree, uh, structure as
well as different function and

00:10:21.087-->00:10:26.092
variable names. And once it is
obfuscated all the function
names or lexical features are

00:10:28.094-->00:10:34.334
refactored uh, with random
representations and all the
comments are replaced with

00:10:34.334-->00:10:39.339
hexadecimal obscure
representations. So everything
is refactored, spaces are

00:10:39.339-->00:10:44.978
stripped and so on. But we see
that the deanonymization
accuracy is not affected by such

00:10:44.978-->00:10:49.949
obfuscations at all. Because
when we look at how the
obfuscation happened we see that

00:10:49.949-->00:10:56.256
refactoring uh, did not change
that data abstract syntax tree
at all and it remains unchanged

00:10:56.256-->00:11:02.395
so our method is impervious to
such off the shelf obfuscators.
Okay what happens when we use

00:11:02.395-->00:11:08.601
more sophisticated obfuscators
such as Tigress? I take about 15
lines of code and obfuscate it

00:11:08.601-->00:11:13.973
with this function virtualizer
and then I end up with about 500
lines of code. It looks much

00:11:13.973-->00:11:19.812
more cryptic and I cannot really
tell what’s going on easily from
higher level. And uh, at the

00:11:19.812-->00:11:25.418
same time, the abstract syntax
tree, most importantly, changes
in this case. Okay and this

00:11:25.418-->00:11:32.025
affects accuracy significantly
so, the accuracy of being able
to identify uh, C programmers

00:11:32.025-->00:11:38.064
was 96 percent for 20
programmers and here the random
chance of correctly identifying

00:11:38.064-->00:11:43.069
a programmer is 5 percent. When
we obfuscated with Tigress the
accuracy drops down to 67

00:11:45.104-->00:11:50.810
percent okay. There is a
significant drop in accuracy but
compared to 5 percent of random

00:11:50.810-->00:11:55.815
chance, 67 percent is still on a
high track to anonymity. Even
when we obfuscated with such

00:11:57.951-->00:12:02.889
sophisticated obfuscators. And
another case, uh, another real
world case would be uh,

00:12:05.592-->00:12:11.230
altership verification. For
example, someone comes up and
says that “Okay I’m Satoshi

00:12:11.230-->00:12:16.603
Nakamoto.” And in that case we
can ask for their past uh,
coding samples, take those

00:12:16.603-->00:12:21.608
samples to train a classifier
where uh, this person, Satoshi
or Mallory, uh is one class and

00:12:24.043-->00:12:29.182
then the second class is the
open world, it’s program where
random programmers from the open

00:12:29.182-->00:12:35.321
world. And then I take bitcoin
uh, source code and try to see
who it belongs to. Does it

00:12:35.321-->00:12:41.694
belong to Mallory or to the open
world? And based on this we can
see if it belongs to this

00:12:41.694-->00:12:46.699
Mallory person. And at the same
time if we have uh, training
data from this person in the

00:12:49.035-->00:12:55.675
past in different open world
scenarios. Okay what about
executable binaries though? When

00:12:55.675-->00:13:02.015
we compile code it goes through
various transformations. Does
coding style remain in compiled

00:13:02.015-->00:13:08.921
code? And uh, again we have a
few lines of code and in binary
it looks quite cryptic we cannot

00:13:08.921-->00:13:13.926
tell much. But thanks to um,
improvements in reverse
engineering methods we can uh,

00:13:16.629-->00:13:22.468
generate which feature sets even
from binaries. And in this case
we know that malware alters

00:13:22.468-->00:13:28.307
would like to remain anonymous
and do not have any identifying
information out there in the

00:13:28.307-->00:13:34.514
public. And there was this one
interview with the law about
malware alter, and this used to

00:13:34.514-->00:13:40.320
be recent but it’s 2016
September, it’s not recent
anymore. Uh, but when this alter

00:13:40.320-->00:13:45.058
is asked “Who are you?”, the
answer is “Just some guy who
likes programming. I’m not known

00:13:45.058-->00:13:49.328
security or researcher,
programmer or a member of any
hate groups.” So probably best

00:13:49.328-->00:13:54.133
answer for this would be
“Nobody.” Malware alters, or
people that like to remain

00:13:54.133-->00:13:59.906
anonymous, would like to be
“nobodies” but if in binaries
coding style is embedded then

00:13:59.906-->00:14:05.845
that shows that that is a
fingerprint identifying
information for certain uh,

00:14:05.845-->00:14:10.850
users online. Okay again, we
have our classical um, machine
learning verb flow. We need

00:14:13.252-->00:14:18.491
course code samples uh, for
controlled environment, which we
take from Google Code Jam,

00:14:18.491-->00:14:23.396
compile it, and then reverse
engineer it to get disassembly
features, assembly features,

00:14:23.396-->00:14:30.303
decompile it to get uh, the
source code so that we can
extract or generate the abstract

00:14:30.303-->00:14:36.075
syntax tree as well as the
control flow graph. And then for
100 programmers we are left with

00:14:36.075-->00:14:41.514
about 1-->000-->000-->000 features.
Uh, with 1-->000-->000-->000 features
I cannot really tell what’s

00:14:41.514-->00:14:46.252
going about, what's going on
about the style of these
programmers. So we apply uh,

00:14:46.252-->00:14:52.325
attribute selection methods to
select the features that are
most representative of style in

00:14:52.325-->00:14:57.296
binaries. And I feed this again
into a random forest of 500
trees, and then the

00:14:57.296-->00:15:02.435
classification to deanonymize
the programmers. And the
features that we are talking

00:15:02.435-->00:15:08.908
about are, for example, once the
code is uh, once the binary is
assembled, disassembled, we have

00:15:08.908-->00:15:14.680
assembly features and we take
assembly token bigrams, or 2
consecutive lines, and so on.

00:15:14.680-->00:15:19.485
And from syntactic features,
again, from the abstract syntax
tree we are taking note bigrams

00:15:19.485-->00:15:25.591
or the average step of a certain
note and so on. And from control
flow graphs we have similar

00:15:25.591-->00:15:31.364
features to abstract syntax
trees and once we extract all of
these we have a lot of features

00:15:31.364-->00:15:35.535
that we are dealing with. And
for that uh, when we are
planning dimensionality

00:15:35.535-->00:15:41.174
reduction the first thing we do
is, uh apply the information
gain criterion so that we take

00:15:41.174-->00:15:47.446
features out of these 700-->000
features uh, that reduced
entropy when they are taken out

00:15:47.446-->00:15:52.451
of the features set. And then we
are left about, with 2-->000
features that keep the accuracy

00:15:54.854-->00:16:00.059
at its highest and it’s most
representative of the coding
style in binaries. But again, if

00:16:00.059-->00:16:07.033
I want to understand where code
is in binaries I won’t be able
to see this from 2-->000 very low

00:16:07.033-->00:16:12.605
level features that don’t really
mean much when you first take a
look at them. And for that I

00:16:12.605-->00:16:17.543
also apply correlation based
features selection which is
taking the features that have

00:16:17.543-->00:16:22.048
the highest interclass
correlation which means that for
an alter, it tells the highest

00:16:22.048-->00:16:27.053
correlation but it has the
lowest in, inter correlation
with other programmers. And it

00:16:29.622-->00:16:35.761
becomes the most identifying for
individual programmers. And I’m
left with about 50 features.

00:16:35.761-->00:16:41.901
Now, I can get a better
understand of what might be
representing coding style or in

00:16:41.901-->00:16:47.373
binaries. And when I try to
analyze these 50 features even
though they are very low level,

00:16:47.373-->00:16:51.143
we still get low level
properties that are
representative of style that

00:16:51.143-->00:16:56.515
remain in binaries. And we have
things such as arithmetic or
logic operations, stack

00:16:56.515-->00:17:01.854
operations as well as file input
operations, and variable
declarations and

00:17:01.854-->00:17:07.627
initializations. And these are
not very trivial to uh,
basically refactor or change to

00:17:07.627-->00:17:13.833
hide your coding style. Okay uh,
we said that we have a
controlled environment. We take

00:17:13.833-->00:17:18.838
code samples from Google Code
Jam and then compile it. And the
reason for doing this was so

00:17:21.040-->00:17:26.646
that we can control for
optimizations which might affect
the deanonymization accuracy or

00:17:26.646-->00:17:31.651
the anonymity of these samples.
And when I take 100 programers
and I apply no uh, optimizations

00:17:34.186-->00:17:39.191
and compiling, I get 96 percent
accuracy, again, with 9 samples
with 9 fold cross validation.

00:17:41.594-->00:17:46.599
And when I apply optimizations
and then as well as stripping
symbols, the accuracy uh, keeps

00:17:48.601-->00:17:54.440
decreasing. With optimizations
it’s not affected a lot, it
drops to 89 percent accuracy.

00:17:54.440-->00:17:59.612
But with stripped symbols the
accuracy is affected more. But
again, here we see that the

00:17:59.612-->00:18:04.116
stripped symbols we have 72
percent accuracy but through
random chance of correctly

00:18:04.116-->00:18:09.922
identifying these programmers is
1 percent. So even stripping
symbols is not anonymizing these

00:18:09.922-->00:18:14.927
people. Okay what kind of
obfuscations can apply to
anonymize myself in an automated

00:18:17.096-->00:18:22.101
way? And for that I used an open
source uh, project uh, open at
LVN and applied 3 different

00:18:24.270-->00:18:29.141
types of obfuscations. First of
all, bogus control flow
insertion, where code will never

00:18:29.141-->00:18:35.081
reach that eh, but it’s still in
the binary so it looks as if,
like a feature. And what if I

00:18:35.081-->00:18:40.953
substitute instructions with
e-colon instructions making the
codes uh, shorter or more

00:18:40.953-->00:18:47.426
complicated and so on. Or
flatten the control flow to mess
with the control flow features.

00:18:47.426-->00:18:54.233
And we see that uh, obfuscations
are decreasing the accuracy to
88 percent from 96 for 100

00:18:54.233-->00:19:00.139
programmers. And again, this is
showing that such obfuscations
are not sufficient to hide

00:19:00.139-->00:19:06.512
coding style. Even in binaries
coding style remains after many
transformations, compilations or

00:19:06.512-->00:19:11.517
obfuscations. What happens if
you try to increase our um,
class size? And we have 600

00:19:14.687-->00:19:20.192
programers. We see that uh, with
20 programmers uh, having 99
percent accuracy and correctly

00:19:20.192-->00:19:26.332
deanonymizing them. Uh, with 600
programmers we get 83 percent
accuracy where the random chance

00:19:26.332-->00:19:32.638
of correctly identifying these
people is less than 0 point uh 2
percent. And we see that the

00:19:32.638-->00:19:38.511
accuracy degrades gracefully in
this case. Okay what about real
world cases? This was a very

00:19:38.511-->00:19:43.816
controlled environment. Google
Code Jam people are uh,
implementing the source code,

00:19:43.816-->00:19:50.356
the functionality, in a limited
amount of time and it’s small
snippets of code and so on. Um,

00:19:50.356-->00:19:55.361
for that first of all I um, I
parsed the top repositories and
ended up taking a bunch of codes

00:19:59.665-->00:20:06.205
from 100’s of programmers. And
after that I compiled those and
many of them did not compile.

00:20:06.205-->00:20:11.210
And GitHub repositories are work
in progress so, that’s okay but
it took me days. Uh, I’m left

00:20:13.312-->00:20:19.952
with 50 GitHub programmers and
able to deanonymize them with 65
percent accuracy. Okay. This is

00:20:19.952-->00:20:24.757
one real world uh, scenario.
What about malicious
programmers? Uh, I’m currently

00:20:24.757-->00:20:30.596
actively working on that. But
one case study I had in a
published paper was with 6

00:20:30.596-->00:20:35.601
malicious programmers and uh, 10
samples. Some of these uh,
samples came from the hect uh,

00:20:37.636-->00:20:43.976
Hacker Forum, Nulled dot IO
Forum. And uh, once the forum
was leaked, I was able to find

00:20:43.976-->00:20:48.981
some live links to um, malicious
code that they were selling and
providing to their customers.

00:20:52.718-->00:20:57.723
And I was able to download those
and find the ones that was um,
relevant to my training set and

00:20:59.959-->00:21:05.564
reverse engineer it to get the
features as well as some malware
alters from uh, security reports

00:21:05.564-->00:21:10.569
and so on. And please, please if
you have a data set with no
alters of malware or, if you

00:21:13.973-->00:21:20.880
have good automated methods for
quickly reversing malware or,
malicious software or, encrypted

00:21:20.880-->00:21:26.719
or pegged or so on, anything
that can help it, please, come
and talk to us after the talk.

00:21:26.719-->00:21:31.757
And we see that with these 6
malicious programmers we have
100 percent accuracy but I would

00:21:31.757-->00:21:37.563
like to make this experiment uh,
much larger scale. And for that
you need help with the data set.

00:21:37.563-->00:21:42.134
And now I will leave it to
Rachel so that she can talk
about more fascinating details

00:21:42.134-->00:21:47.139
about programmer
deanonymization. >>Thanks Aylin!
[applause] So I’m gonna dig a

00:21:54.547-->00:22:01.287
bit deeper on to uh, programmer
deanonymization on GitHub. Uh,
when we did this experiment we

00:22:01.287-->00:22:07.393
got much lower accuracy than um,
in the original Google Code Jam
data set. And with the

00:22:07.393-->00:22:11.630
experiments I’m gonna show over
the next couple slides I think a
lot of this comes down to the

00:22:11.630-->00:22:18.170
fact that a lot of these repos
we only had like, a couple of
files per author and it turns

00:22:18.170-->00:22:21.941
out that this sort of, I think
that’s the thing that matters
the most. There is a lot of

00:22:21.941-->00:22:27.279
noise where sometimes people
will like, link in other things
and so on. But I think one of

00:22:27.279-->00:22:33.886
the biggest issues is that uh,
when you only have like, 2 files
to train on or 1 file in this

00:22:33.886-->00:22:38.390
case and 1 to test as opposed to
the 9 files that we used for our
experiments, I think that makes

00:22:38.390-->00:22:43.395
a big difference. Um, so, we’ve
been, up till now we’ve only
talked about situations where

00:22:45.698-->00:22:50.502
people are writing code
individually on their own. So
um, most people probably don’t

00:22:50.502-->00:22:56.709
actually code that way in, in
real life most of the time. Most
code is collaborative. So when

00:22:56.709-->00:23:01.447
we started uh, presenting the
initial word, uh we had a couple
tweets about it. Uh, Havar, who

00:23:01.447-->00:23:05.351
some of you might know, said
“I’ll believe that this code
stylometry stuff works when it

00:23:05.351-->00:23:09.488
can be shown to work on big
commit GitHub histories instead
of the Google Code Jam data

00:23:09.488-->00:23:15.327
sets.” And um, Zooko talked
about hearing from an intern at
Apple that they disallow her

00:23:15.327-->00:23:20.933
from contributing to open source
on her own time. And so we were
interested from this like,

00:23:20.933-->00:23:26.372
perspective both of, ya know,
privacy. Like, if I wanna
contribute to something and, and

00:23:26.372-->00:23:31.243
I wanna know if that particular
commit is gonna cause me
problems later. Um, and also

00:23:31.243-->00:23:37.049
just, ya know, to be more, to
validate this stuff more in the
real world, we wanted to do some

00:23:37.049-->00:23:43.656
experiments. So, in this case,
right, we’re only carrying maybe
who wrote a small piece of code

00:23:43.656-->00:23:50.095
or we wanna deanonymize some
synonymous account on GitHub who
we have like, several snippets

00:23:50.095-->00:23:56.969
or segments of code, right? So
we don’t have these whole files
nicely written. Um, and in this

00:23:56.969-->00:24:01.607
case we’re using uh, the same
feature set uh, that we used
before. Um, we’re trimming it

00:24:01.607-->00:24:06.612
down to about 3,400 features. So
like, quite a bit more than um,
Aylin was using earlier on but

00:24:08.914-->00:24:14.887
these are very small um,
segments and snippets so
sometimes we need more features

00:24:14.887-->00:24:21.827
for that. Um, and you know the,
the ultimately when we were
doing this uh, we get about 73

00:24:21.827-->00:24:26.031
percent accuracy at identi, at
identifying the author when
we’re talking about 100, about

00:24:26.031-->00:24:31.036
100 programmers uh, for a
snippet of code that’s about 5
lines long. Um, so we’re

00:24:33.539-->00:24:38.043
interested in kind of
understanding when this works
and when this doesn't work. So

00:24:38.043-->00:24:42.748
what we did was we built this
calibration curve. Um, and what
that does is it just shows us

00:24:42.748-->00:24:48.220
like, in general what the
confidence of the classifier is
relative to its accuracy for

00:24:48.220-->00:24:53.225
individual samples. And we can
see that in some cases we have
pretty like, high confidence and

00:24:53.225-->00:24:59.431
in a lot of cases we don’t have
such high confidence. Um, and
yeah, so this can help us

00:24:59.431-->00:25:04.570
understand. Even though we have
73 percent accuracy we can say
given this, you know, answer

00:25:04.570-->00:25:09.541
that that um, attribution has
given us should we believe it or
not based on this confidence?

00:25:09.541-->00:25:15.748
And then we can know like, if we
know it with high confidence we
have much better uh, belief that

00:25:15.748-->00:25:22.054
this is actually the programmer
that we’re looking for. Um, and
we’re also interested in, you

00:25:22.054-->00:25:27.626
know, how long these um,
snippets need to be and how many
snippets you need to train on in

00:25:27.626-->00:25:32.131
order to get good results. So
here’s an like, like an
interesting kind of, we have

00:25:32.131-->00:25:36.735
this, sort of, curve that
happens where, so say we have
fairly large snippets that are

00:25:36.735-->00:25:41.240
like 38 lines of code. In
general, with the Google Code
Jam data that we were talking

00:25:41.240-->00:25:47.112
about before they were about 70
lines of code, uh, the files.
Um, but in this case we only

00:25:47.112-->00:25:53.652
have 4 samples for each author,
or programmer, right? And this
gives us about 54 percent

00:25:53.652-->00:25:58.657
accuracy out of 90 programmers.
But even if we have smaller
samples um, but much more of

00:26:00.659-->00:26:05.564
them, typically our result goes
up. So even when we’re only
looking at single lines of code,

00:26:05.564-->00:26:10.135
uh, and I’m a little nervous
about this result cause it’s
really preliminary, but if we

00:26:10.135-->00:26:16.341
had like 150 samples to train on
uh, we can usually identify the
author about 75 percent of the

00:26:16.341-->00:26:22.114
time. So, we’re still trying to
kind of understand what makes
lines of code more attributable

00:26:22.114-->00:26:27.119
or not. I mean certain lines of
code are gonna be pretty generic
but other ones not so much. But

00:26:30.956-->00:26:36.929
what happens when we wanna
identify accounts, not
necessarily individual commits?

00:26:36.929-->00:26:42.201
Right? This actually works a lot
better because what happens here
is that the uh, the errors

00:26:42.201-->00:26:48.440
aren't correlated. So we get
close to about 100 percent
accuracy if we have 4 snippets

00:26:48.440-->00:26:52.845
meaning like, the way that we,
the way that we analyzed this is
we ran like, git blame on these

00:26:52.845-->00:26:58.717
repositories right? So that’s
how we get the, the repository
clipped into, into snippets. And

00:26:58.717-->00:27:03.789
it turns out that the errors,
the 73 percent are not,
typically not that correlated.

00:27:03.789-->00:27:08.794
So we, if we try multiple times
and then we vote, um, our
results go close, get close to

00:27:11.163-->00:27:16.468
100 percent. Not perfect. So you
can see this sort of heat map
here. Um, where the red area is

00:27:16.468-->00:27:23.008
basically over 90 percent
accuracy and it tends to happen
once you end up having more than

00:27:23.008-->00:27:28.013
about 9 samples and more than
about 5 um, account, 5, 5
snippets to train on right? Like

00:27:31.450-->00:27:37.456
that you're, or to test on. So,
once you have like, a certain
amount of training data and a

00:27:37.456-->00:27:41.593
certain amount of like, testing
data meaning the account that
you’re wandering around, bout

00:27:41.593-->00:27:46.965
has commited, you know, more
than 4 or 5 times. Then your
results get pretty good. Um,

00:27:46.965-->00:27:52.804
interestingly we were also, well
and then the other things we
tried was, instead of saying

00:27:52.804-->00:27:58.443
okay we’re gonna identify these
little snippets um, individually
and then, and then vote. What if

00:27:58.443-->00:28:03.415
we merged them all to make a big
sample? And it turns out that’s
better than the initial snippets

00:28:03.415-->00:28:08.287
but it’s not as good as doing
them sort of one at a time and
averaging because then the, the

00:28:08.287-->00:28:14.159
errors tend to get compounded
and in the single merge thing.
Um, okay now for something a

00:28:14.159-->00:28:20.265
little bit different. I’m gonna
talk about deep learning cause
it's the new hotness. And

00:28:20.265-->00:28:26.371
[speaker laughs] so um, we, we
talked about in, in, in one of
the things that's sort of novel

00:28:26.371-->00:28:32.077
about this work is using the
abstract syntax tree. In the
past most people had just used

00:28:32.077-->00:28:37.282
lexical and layout features and
sort of they had been doing this
sort of code attribution stuff

00:28:37.282-->00:28:42.955
since the 70’s but it gets, it
tend, it tended to get around 80
percent accuracy and not scale

00:28:42.955-->00:28:49.194
above like, 30 programmers or
so. So using these AST type
features allowed us to get good

00:28:49.194-->00:28:54.800
results. But the thing is an AST
itself is not a feature, right?
A tree is not a feature, you

00:28:54.800-->00:29:01.406
can’t just feed this into a
random forest and have it, you
know, tell you who it is. Um, we

00:29:01.406-->00:29:06.945
manually chose these features as
Aylin has mentioned. We chose
unigrams and bigrams and depth.

00:29:06.945-->00:29:12.818
And so, these tend to give us
like, very local features and
very global features. Um, but

00:29:12.818-->00:29:18.190
what we want actually is the
ability to get maybe more
newance features than that. So

00:29:18.190-->00:29:23.195
enter like, a deep neural net so
we’re gonna try and
automatically learn a new

00:29:23.195-->00:29:29.935
feature um, representation. So
what we do is we first map the
AST nodes into a vector and we

00:29:29.935-->00:29:34.640
just use this embedding layer to
do that. And then we create the
subtree layers and they're gonna

00:29:34.640-->00:29:40.245
be using LASTM’s or
bidirectional LSTM’s in order to
learn new structures of the AST.

00:29:40.245-->00:29:46.451
And then we have a soft max
layer to actually do the
classification. So, little bit

00:29:46.451-->00:29:52.324
of background on LSTM’s if
you've not um, learned too much
about them. So we have our

00:29:52.324-->00:29:57.896
neural net here, um, on the
right uh, it’s an RNN which
basically allows us to handle

00:29:57.896-->00:30:03.435
sequential input and actually
have some memory to be able to
remember information that’s

00:30:03.435-->00:30:09.808
where those little feedback
loops are. And an LSTM actually
adds memory cells to this to

00:30:09.808-->00:30:15.313
have sort of more useful memory.
Again, so we can not just have
super local features. So these

00:30:15.313-->00:30:19.518
cells have gates in them and
they asked sort of what should I
remember of this information

00:30:19.518-->00:30:22.621
that's going in? What should I
just ignore? And what should I
forget that we’ve already

00:30:22.621-->00:30:27.626
learned? So that we can over
time develop a richer
representation of the AST. So in

00:30:29.761-->00:30:33.432
this case we’re only trying to
use the AST features, we’re not
using any of the layout or

00:30:33.432-->00:30:37.102
lexical features and that’s why
these results for the random
forest are lower than what Aylin

00:30:37.102-->00:30:43.408
showed. Um, but you can see in,
in this is using Python and C
plus plus so we get, you know,

00:30:43.408-->00:30:48.814
86 percent accuracy on 25
programmers or 73 percent
accuracy um, on 70 programmers

00:30:48.814-->00:30:50.816
in Python. Again, just using the
AST’s so this layout and lexical
stuff matters too. But when we

00:30:50.816-->00:30:52.818
use our new um, AST features we
do get a big jump here. Um, in,
an so this new um, feature of

00:30:52.818-->00:30:54.820
resignation does seem helpful.
And it’s nice to have a sort of
a sole AST representation

00:30:54.820-->00:30:56.822
because it does allow us to,
it’s mo, as, as we mentioned
before it’s much harder to

00:30:56.822-->00:31:01.760
obfuscate um, it’s easy to port
and so on. Um, yeah. So this
allows us to learn better AST’s

00:31:22.748-->00:31:29.488
without doing it in this manual
feature, engineering and it’s
language independent. Um, and in

00:31:29.488-->00:31:33.525
our future work we’d like to
actually combine the, these
features that have been learned

00:31:33.525-->00:31:37.829
with the random forest and the
fuller feature set to see if we
get better results or if this

00:31:37.829-->00:31:42.100
just overlaps with some of the
stuff that we’re learning from
the layout and lexical features.

00:31:42.100-->00:31:48.640
Okay. So what about other
languages? As I mentioned um,
basically porting this to a new

00:31:48.640-->00:31:53.245
language requires an AST parser,
which exists for almost
everything, and lexical and

00:31:53.245-->00:31:56.782
layout features that you choose
for the language. So, so far
we’ve done thing, we’ve done

00:31:56.782-->00:32:01.887
things for C plus plus, C,
Python and JavaScript and we get
similar accuracies so far uh, on

00:32:01.887-->00:32:08.660
the Google Code Jam data set.
Um, the results with just using
the AST tend to vary more, which

00:32:08.660-->00:32:13.098
is kinda interesting. Um, one of
the holy grail kind of
applications of this would be

00:32:13.098-->00:32:17.202
able to test on, to sort of
train on one language and test
another language. And we don’t

00:32:17.202-->00:32:21.740
know currently like, how much
does your programming style
change when you actually change

00:32:21.740-->00:32:26.878
languages? Um, so do this we
need some sort of universal
intermediate AST representation

00:32:26.878-->00:32:32.350
or some, or some sort of just
pairwise, you know, porting
between two languages. Um, there

00:32:32.350-->00:32:37.789
is a project to work on this,
it’s like the Babblefish
Project, but it doesn't really

00:32:37.789-->00:32:42.727
appear like, ready yet um, for
this kind of application. Uh
it’s something we’re planning to

00:32:42.727-->00:32:48.133
look into a little bit if people
know about sort of uh, generic
AST representations. That’d be

00:32:48.133-->00:32:53.839
another thing we’d love to get
your feedback on. Um, so I’m
gonna end the talk with a couple

00:32:53.839-->00:32:59.044
interesting sort of software
engineering insights that we’ve
gathered as we’ve done this

00:32:59.044-->00:33:05.250
work. About like, what makes
programming unique uh, which I
think is kind of fun. So, in

00:33:05.250-->00:33:10.055
general we will, we started with
looking at competing groups of
people with, so there’s a

00:33:10.055-->00:33:14.893
another programming contest
called The Codeforces Contest
which has a team competition and

00:33:14.893-->00:33:21.333
the teams can compete on sets of
problems. Uh, we, we looked at,
we had very preliminary results

00:33:21.333-->00:33:27.439
with 118 teams with about 20
submissions each. Um, and they
get about 67 per, we had about

00:33:27.439-->00:33:32.210
67 percent accuracy. Now, I
think this is one of the hardest
cases for group attribution

00:33:32.210-->00:33:37.082
because the way that Codeforces
works is it gives you a big
group of problems to work on as

00:33:37.082-->00:33:41.186
a team together, so I think
people are mostly splitting
those up. So it’s not actually

00:33:41.186-->00:33:45.123
group coding. So I’m kinda
surprised that it even works as
well as it does at identifying

00:33:45.123-->00:33:50.929
the team. Um so in, in the
future we’d like to work, again,
with some more code repositories

00:33:50.929-->00:33:54.399
to get a better sense of like,
stuff that we know and can
control for how much

00:33:54.399-->00:33:59.404
collaboration actually went into
it. Um, difficult versus easy
tasks. It turns out that um,

00:34:01.473-->00:34:05.844
implementing harder
functionality makes programming
style more unique. So when

00:34:05.844-->00:34:10.882
you’re solving, you know, and we
can kinda control for this
because the problems in the

00:34:10.882-->00:34:15.086
programming contest are supposed
to get harder as they move on.
So if we look at uh, the same

00:34:15.086-->00:34:20.725
set of 62 programmers solving 7
easy problems, we get 90 percent
accuracy which is pretty good.

00:34:20.725-->00:34:25.297
But when we look at the same set
solving 7 harder problems it,
the accuracy goes up to 95

00:34:25.297-->00:34:30.302
percent. So, that tends to
matter. Also programmer skill
matters so, programmers who got

00:34:32.671-->00:34:38.677
further in the contest, which is
some measure of skill perhaps,
were easier to attribute. So in

00:34:38.677-->00:34:45.483
general like, the, the, the
coders that advanced less far uh
I got 8, we got 80 percent

00:34:45.483-->00:34:50.388
accuracy on them on the, again,
these are on the easy problems
because they, they did that much

00:34:50.388-->00:34:54.259
but then when we look even on
the easy problems at the people
who got further in the

00:34:54.259-->00:34:59.664
competition uh, we’re able to
classify them with 95 percent
accuracy. So it’s kinda

00:34:59.664-->00:35:05.470
interesting that as you develop
programming skill your, your um,
your style tends to be more

00:35:05.470-->00:35:10.475
unique. Um, we’re also
interested in how coding style
changes over time. So we looked

00:35:13.445-->00:35:19.818
at um, again, the, this
competition where people uh, are
training and testing on to the,

00:35:19.818-->00:35:26.124
on, are competing in both 2012
and 2014. So when we trained on
2012 and we test on 2014 the

00:35:26.124-->00:35:31.896
accuracy goes down from 92
percent on this, uh 2012 set to
80, 88 percent at, when we test

00:35:31.896-->00:35:38.803
on the 2014 set. Um, so it's a
little bit of a drop. I'd be
more interested in maybe looking

00:35:38.803-->00:35:43.208
at like, when we look at even
larger time scales and that, or
sort of particularly uh,

00:35:43.208-->00:35:47.412
formative sort of years maybe
like, university and things like
that, and how it affects

00:35:47.412-->00:35:52.417
people’s um, programming style.
Lastly we’re interested in
coding style by country, right?

00:35:55.253-->00:35:59.824
So, one of the things that uh,
this contest does it had has
contestants from all over the

00:35:59.824-->00:36:05.964
world so when we were porting
this to JavaScript we grabbed a
bunch of uh, Javascript files.

00:36:05.964-->00:36:12.170
84 files written by programmers
in Canada and then programs,
programmers in China. And we

00:36:12.170-->00:36:16.174
were interested in just a binary
classification whether we could
tell whether the file had been

00:36:16.174-->00:36:21.846
written by a Canadian or a
Chinese programmer. Um, now this
we expected to be like,

00:36:21.846-->00:36:25.784
particularly easy because
there’s like, a native language
difference which may show up in

00:36:25.784-->00:36:30.021
things like variable names and
so on. And, in fact, it worked
pretty well. So it was around,

00:36:30.021-->00:36:34.426
it was 91 point 9 percent
accuracy for this task. Uh, in
the future we’re planning to

00:36:34.426-->00:36:39.431
look at a much larger set of
countries and a much larger sort
of set of files and see about

00:36:42.133-->00:36:47.505
sort of if there’s actually kind
of, if this is a native language
affect or maybe um, sort of an

00:36:47.505-->00:36:52.510
education system style culture
affect and what’s going on
there. Um, but I think it’ll be

00:36:55.480-->00:37:00.085
interesting. So, in future
applications we’re, as we said,
we’re really interested in um,

00:37:00.085-->00:37:05.924
whether this actually works to
find malicious code authors. Um,
and also, you know, what sort of

00:37:05.924-->00:37:09.994
anonymous contributors have to
worry about when they contribute
code online. We’re interested in

00:37:09.994-->00:37:14.599
breaking the stuff. So writing
better obfuscators, all the
obfuscators we’ve tried so far

00:37:14.599-->00:37:19.771
have not been really targeted
specifically to the AST. Uh, so
we think that can happen. There

00:37:19.771-->00:37:23.842
was some research uh, done at
the University of Washington
building on our work, showing

00:37:23.842-->00:37:28.947
that people can kinda imitate
other people’s style when
they’re given that as a task to

00:37:28.947-->00:37:34.352
some extent. Uh, so that’s, you
know, there, there’s hope,
right? Um [Speaker laughs] Don’t

00:37:34.352-->00:37:39.057
leave, Don’t leave here thinking
you can’t ever write a non-risk
code again but, be careful. Um,

00:37:39.057-->00:37:44.662
when we, and in, and in
particular like, if you're going
to contribute uh, to a

00:37:44.662-->00:37:49.534
repository anonymously you might
wanna create a new account for
each commit, even though that’s

00:37:49.534-->00:37:55.273
annoying. Um, to find uh,
authors who write vulnerable
code who are interested in

00:37:55.273-->00:38:00.945
looking at um, source code and,
and understanding kind of what
uh, software engineering type

00:38:00.945-->00:38:05.650
stylistic features lead to, to
vulnerabilities. And also, you
know, some people have talked to

00:38:05.650-->00:38:09.854
us about finding out who to
recruit directly by looking at
how unique their coding style is

00:38:09.854-->00:38:16.060
and whether that suggests
something about their programmer
skill. Um, so uh, this was not

00:38:16.060-->00:38:21.666
work done just by Aylin and
myself alone, I have lots of
students and other collaborators

00:38:21.666-->00:38:26.938
at Drexel University, and at
Princeton, at the, and at the
Army Research Lab, and at

00:38:26.938-->00:38:31.876
Gottingen in Germany, who’ve all
worked on various aspects of
this project. So thanks to

00:38:31.876-->00:38:38.316
Bander, Edwin, Rich, Andrew
Spiros, Arvend, Fredricka,
Mushfiqur, Dennis, Conrad, Greg,

00:38:38.316-->00:38:44.589
Claire, Mike, and Fabian for all
of your uh, contributions to
this work. Um, this is our

00:38:44.589-->00:38:50.795
contact information. Our code to
do all of this um, stuff so if
you actually wanna try and

00:38:50.795-->00:38:54.933
figure out who Satoshi Nakamoto
is and have a, like actual
suspect set you’re more than

00:38:54.933-->00:39:01.072
welcome to try that. That’s not
something that we’re going to
do, we respect privacy. So um,

00:39:01.072-->00:39:07.645
but you know the code is out
there. And we have I think,
about um, 4 ish minutes for

00:39:07.645-->00:39:12.450
questions so if people have some
questions we would love to take
them. And then after the talk

00:39:12.450-->00:39:17.455
we’ll walk out the back and ask
any, any of you can ask any more
questions that you have. Thanks!

00:39:26.164-->00:39:31.169
[audience applauds] Any
questions? Yeah. Um, how do we
do this? >>I don’t know

00:39:33.171-->00:39:37.609
[audience laughs] >>There’s,
seriously no one ever does Q and
A? [speaker laughs] Um, maybe we

00:39:37.609-->00:39:42.614
should [inaudible noises in the
audience] I intentionally left
time. [inaudible noises in the

00:39:48.219-->00:39:53.224
audience] >>Come here handsome
[laughter] No, no you come on
stage I have to kill you.

00:40:00.131-->00:40:06.371
[laughter] [inaudible noises in
the audience] >>Or you can just
ask and I’ll. Wow no one’s ever

00:40:06.371-->00:40:12.010
done questions, okay. >>So, for
the coding styles that you were
going through, for the people

00:40:12.010-->00:40:16.581
for the Google Coding Challenge,
you said you were able to look
at people who were going the

00:40:16.581-->00:40:21.919
furthest in the challenge. Did
you see trends that were going
along that we could later help

00:40:21.919-->00:40:26.924
make better coders later using
that information? >>No, we have
>>Before you answer, so for

00:40:29.527-->00:40:33.298
those of you that are leaving,
again, go out through the back
door. Do not go out through the

00:40:33.298-->00:40:38.303
side door. >>Yeah and we’ll,
we’ll meet out there so. Um, so
yeah, so they uh, I, we have not

00:40:40.505-->00:40:46.244
done much analysis of sort of
what makes uh, the coding style
uh, people who get further in

00:40:46.244-->00:40:50.548
the programming competition. Um,
you know, different or more
attributable? But I think that

00:40:50.548-->00:40:54.886
that would be a really
interesting direction and we’d
like to look at it. Do you have

00:40:54.886-->00:40:59.891
anything? >>And one property was
that more advanced programmers
tend to write longer code.

00:41:02.160-->00:41:07.165
[inaudible response] >>Right.
>>That’s one trend. [inaudible
response] >>Yeah. Yeah, I mean,

00:41:07.165-->00:41:11.169
it’s, it’s tricky cause we don’t
know if that’s like, the causal
thing or just sort of a, a side

00:41:11.169-->00:41:16.708
thing. But, um, but yea, the, in
general the code was longer
which helped. So. >>Thank you.

00:41:16.708-->00:41:21.713
>>Yeah. Did you have a. >>Uh, I
just have a comment uh, this is
very interesting. Uh, one thing

00:41:23.881-->00:41:30.221
I would see this going towards
is uh, cataloging programmer
reputation. Which is kinda like

00:41:30.221-->00:41:34.092
what we've gotten into with
penetration testing. So instead
of going towards like an,

00:41:34.092-->00:41:39.764
completely open source
ecosystem, we’re pushing for
statistical testing and this can

00:41:39.764-->00:41:45.636
now further be used uh, to look
at programmers and see their
history uh, with, with security

00:41:45.636-->00:41:51.642
and then give a score to the
code in that regards. Uh, so do
you think there’s any value to

00:41:51.642-->00:41:57.382
cataloging people in terms of
looking at security for code? Or
that’s just an underlying

00:41:57.382-->00:42:02.320
ecosystem problem? >>Do you
wanna um, that one, or? >>Yeah,
there is uh, ongoing research

00:42:05.656-->00:42:11.763
for automatically uh,
understanding security
properties of code. And they are

00:42:11.763-->00:42:16.768
working with similar properties
and, does this answer your
question? >>A, A, Abso,

00:42:20.038-->00:42:25.042
Absolutely. >>Alright, so let’s
give the speakers a hand. Whoa.
[audience applauds]

