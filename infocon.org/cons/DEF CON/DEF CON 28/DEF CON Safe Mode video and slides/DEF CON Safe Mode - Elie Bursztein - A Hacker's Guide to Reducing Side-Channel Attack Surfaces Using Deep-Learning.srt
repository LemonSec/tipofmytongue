1
00:00:05,473 --> 00:00:09,090
- Bonjour! My name is
Elie, I work at Google,

2
00:00:09,090 --> 00:00:12,060
where I lead the Security
and Anti-Abuse Research team.

3
00:00:12,060 --> 00:00:14,830
Today, we (mumbles),
which is here in spirit,

4
00:00:14,830 --> 00:00:16,950
we're going to tell you how we can use

5
00:00:16,950 --> 00:00:20,220
deep-learning to reduce
side-channel attack surface.

6
00:00:20,220 --> 00:00:22,320
Before getting started, I
would like to point out that

7
00:00:22,320 --> 00:00:24,130
the research you're about to see,

8
00:00:24,130 --> 00:00:26,570
are part of a larger project that we do

9
00:00:26,570 --> 00:00:28,230
in collaboration with many Googlers,

10
00:00:28,230 --> 00:00:30,487
and external collaborators around

11
00:00:30,487 --> 00:00:32,680
hardening hardware cryptography,

12
00:00:32,680 --> 00:00:34,560
to create more secure devices.

13
00:00:34,560 --> 00:00:36,580
Side-channel attack is one
of the most efficient ways

14
00:00:36,580 --> 00:00:38,230
to attack secure hardware,

15
00:00:38,230 --> 00:00:41,540
because instead of
targeting the algorithm,

16
00:00:41,540 --> 00:00:43,800
which is usually well
understood and well scrutinized,

17
00:00:43,800 --> 00:00:44,870
Let's say, AES,

18
00:00:44,870 --> 00:00:47,930
instead we target the implementation.

19
00:00:47,930 --> 00:00:51,270
And the interplay with a given hardware.

20
00:00:51,270 --> 00:00:53,110
And this is way less scrutinized because

21
00:00:53,110 --> 00:00:54,770
A, there is many of them,

22
00:00:54,770 --> 00:00:57,390
and B, it is way more subtle to understand

23
00:00:57,390 --> 00:01:00,570
how side effect of code
affect a specific hardware,

24
00:01:00,570 --> 00:01:03,150
and how that can be
exploited by attackers.

25
00:01:03,150 --> 00:01:05,030
Here is a concrete example to show you

26
00:01:05,030 --> 00:01:05,983
how powerful such an attack are.

27
00:01:05,983 --> 00:01:10,513
Back in 2017, researchers
were able to recover

28
00:01:10,513 --> 00:01:14,200
Bitcoin private keys, out of
a the Trezor hardware wallet,

29
00:01:14,200 --> 00:01:15,693
by using side-channel attack.

30
00:01:16,530 --> 00:01:19,610
This shows you that, despite
the algorithm being reviewed,

31
00:01:19,610 --> 00:01:22,339
and the hardware being well understood,

32
00:01:22,339 --> 00:01:23,859
the interplay between the two,

33
00:01:23,859 --> 00:01:25,424
still had some problems,

34
00:01:25,424 --> 00:01:28,993
that you can exploit through
side-channel attacks.

35
00:01:30,800 --> 00:01:33,040
And from the defender side,

36
00:01:33,040 --> 00:01:34,920
side-channel attacks are
very difficult because

37
00:01:34,920 --> 00:01:36,930
they are very hard to debug and fix it.

38
00:01:36,930 --> 00:01:39,100
So even you know that
you have a side-channel,

39
00:01:39,100 --> 00:01:41,610
it's really hard to know
where it's coming from,

40
00:01:41,610 --> 00:01:43,790
and what you can do to fix it.

41
00:01:43,790 --> 00:01:47,550
So, a side-channel attack
are both very important,

42
00:01:47,550 --> 00:01:48,940
and hard to debug, which means

43
00:01:48,940 --> 00:01:51,000
that there is a room for innovation,

44
00:01:51,000 --> 00:01:53,620
on how to help with a situation.

45
00:01:53,620 --> 00:01:55,677
And that's where as
these projects comes in.

46
00:01:55,677 --> 00:01:58,230
And our idea was, maybe we can try

47
00:01:58,230 --> 00:02:01,558
to develop new technology, to
accurately pinpoint the code,

48
00:02:01,558 --> 00:02:03,870
which is vulnerable to
side-channel attack.

49
00:02:03,870 --> 00:02:06,090
So, developer can quickly isolate it

50
00:02:06,090 --> 00:02:08,124
and try to improve it and strengthen,

51
00:02:08,124 --> 00:02:11,580
and improve the quality
of the implementation,

52
00:02:11,580 --> 00:02:14,390
and be more resistant
to side-channel attack.

53
00:02:14,390 --> 00:02:16,010
So was the idea we had,

54
00:02:16,010 --> 00:02:18,300
and then, the way we went about that

55
00:02:18,300 --> 00:02:21,320
was we propose to use a deep-learning

56
00:02:21,320 --> 00:02:23,610
and dynamic analysis and combine the two

57
00:02:23,610 --> 00:02:28,470
to be able to accurately pinpoint
the origin of the leakage,

58
00:02:28,470 --> 00:02:31,290
which is responsible or
which is exploited by

59
00:02:31,290 --> 00:02:33,220
a given side-channel attack.

60
00:02:33,220 --> 00:02:36,070
And I know, I know, what you're thinking.

61
00:02:36,070 --> 00:02:37,330
You're going to be like, Oh my God,

62
00:02:37,330 --> 00:02:39,210
one more deep-learning talk. Really?

63
00:02:39,210 --> 00:02:42,850
It's all going to be all
hype and etcetera et cetera.

64
00:02:42,850 --> 00:02:44,210
Well, actually, no.

65
00:02:44,210 --> 00:02:46,900
This talk as I promise
is a hacker (indistinct).

66
00:02:46,900 --> 00:02:48,860
So, we want to make it very concrete.

67
00:02:48,860 --> 00:02:51,460
And what we really want
to do today is showcase

68
00:02:51,460 --> 00:02:53,490
to you our deep-learning tool,

69
00:02:53,490 --> 00:02:55,250
which we call SCALD

70
00:02:55,250 --> 00:02:58,410
which stands for Side
Channel Attack Leak Detector,

71
00:02:58,410 --> 00:03:00,620
and how that works in practice.

72
00:03:00,620 --> 00:03:03,270
And to make it very concrete,

73
00:03:03,270 --> 00:03:06,440
today I'm going to show
you how we can use SCALD,

74
00:03:06,440 --> 00:03:10,750
to debug tinyAES a very
vanilla plain implementation

75
00:03:10,750 --> 00:03:15,750
of AES running on a well known,
CPU, which is the SMT32F4.

76
00:03:17,350 --> 00:03:21,660
So, we're going to really
see in practice today,

77
00:03:21,660 --> 00:03:23,960
how you can use the
technique we developed,

78
00:03:23,960 --> 00:03:25,920
to isolate a very clear leakage.

79
00:03:25,920 --> 00:03:27,660
And hopefully by end of the talk,

80
00:03:27,660 --> 00:03:29,640
you will have a good understanding

81
00:03:29,640 --> 00:03:31,700
of what the tool is about

82
00:03:31,700 --> 00:03:34,700
and why it maybe useful if you're working

83
00:03:34,700 --> 00:03:38,450
in the field of cryptography
and hardware crypto.

84
00:03:38,450 --> 00:03:40,540
or if you're interested in the subject.

85
00:03:40,540 --> 00:03:43,728
So, with this, how are we
going to go about that?

86
00:03:43,728 --> 00:03:48,060
First, I'm going to briefly
detail how side-channel works.

87
00:03:48,060 --> 00:03:49,790
Then we're going to discuss

88
00:03:49,790 --> 00:03:51,350
how AI based side-channel attack works

89
00:03:51,350 --> 00:03:52,630
because we are new.

90
00:03:52,630 --> 00:03:55,360
We need those to be able
to pinpoint a leakage.

91
00:03:55,360 --> 00:03:57,220
Then I'm going to dive a little bit

92
00:03:57,220 --> 00:03:59,610
into what is AI explainability

93
00:03:59,610 --> 00:04:01,390
and how you go about explaining

94
00:04:01,390 --> 00:04:03,530
what the machine-learning sees,

95
00:04:03,530 --> 00:04:06,490
or understands or how it makes a decision.

96
00:04:06,490 --> 00:04:09,040
And finally, we're bring
everything together.

97
00:04:09,040 --> 00:04:12,370
I talked to you a little
bit about the part

98
00:04:12,370 --> 00:04:14,530
of the project and how we fit all together

99
00:04:14,530 --> 00:04:16,870
to well, pinpoint a leakage,

100
00:04:16,870 --> 00:04:18,890
and I'll show you how
it works in practice,

101
00:04:18,890 --> 00:04:22,370
for the target or tinyAES on SMT32F4.

102
00:04:22,370 --> 00:04:24,117
We can follow along by
getting on the site,

103
00:04:24,117 --> 00:04:25,290
at the very least.

104
00:04:25,290 --> 00:04:26,700
And hopefully links of code,

105
00:04:26,700 --> 00:04:28,790
by going to https://elie.net/scald

106
00:04:29,950 --> 00:04:32,596
As I mentioned, the
purpose of this talk is

107
00:04:32,596 --> 00:04:36,120
to be a very practical, down to earth,

108
00:04:36,120 --> 00:04:38,550
on how can you use and how this type of

109
00:04:38,550 --> 00:04:40,020
tool works at a high level,

110
00:04:40,020 --> 00:04:42,625
and how you can use it, as a practitioner,

111
00:04:42,625 --> 00:04:45,410
not necessarily how you
can develop such technique,

112
00:04:45,410 --> 00:04:47,680
and how you can research
on how to improve it.

113
00:04:47,680 --> 00:04:49,850
If this is something
you are interested in,

114
00:04:49,850 --> 00:04:52,280
we are working on a
paper, a research paper,

115
00:04:52,280 --> 00:04:53,750
which have all the technical details

116
00:04:53,750 --> 00:04:56,533
about the question technic
we used for benchmarking

117
00:04:56,533 --> 00:04:59,400
and the alternative and also good stuff.

118
00:04:59,400 --> 00:05:03,600
And hopefully, the paper
will be out shortly,

119
00:05:03,600 --> 00:05:04,870
by the time you see this recording,

120
00:05:04,870 --> 00:05:06,910
or will have been already put

121
00:05:06,910 --> 00:05:08,750
on archive by the time you see it.

122
00:05:08,750 --> 00:05:10,957
With that out the way, let's talk with,

123
00:05:10,957 --> 00:05:14,430
recapping what side-channel are,

124
00:05:14,430 --> 00:05:16,800
At its core, a side-channel attack is,

125
00:05:16,800 --> 00:05:20,330
an indirect measurement
of a computation result,

126
00:05:20,330 --> 00:05:22,260
using an auxiliary mechanism.

127
00:05:22,260 --> 00:05:24,790
So, basically instead of
observing direct as a result,

128
00:05:24,790 --> 00:05:29,350
we try to infer what it is,
using a third party way,

129
00:05:29,350 --> 00:05:32,248
which is what we call
an auxiliary mechanism.

130
00:05:32,248 --> 00:05:36,590
Side-channel attack, are
using many, many ways,

131
00:05:36,590 --> 00:05:38,370
to attack various targets.

132
00:05:38,370 --> 00:05:40,740
Obviously as discussed in this talk,

133
00:05:40,740 --> 00:05:42,560
they are used to recover encryption key,

134
00:05:42,560 --> 00:05:44,683
out of hardware secure implementation.

135
00:05:44,683 --> 00:05:46,960
They're also used in web security

136
00:05:46,960 --> 00:05:48,700
to perform blind disc SOL injection.

137
00:05:48,700 --> 00:05:51,430
Where you cannot see the
return of a history statement

138
00:05:51,430 --> 00:05:53,420
or it's SOL injection.

139
00:05:53,420 --> 00:05:55,900
And then they also used,

140
00:05:55,900 --> 00:05:59,270
to steal password pins
from secure implementation.

141
00:05:59,270 --> 00:06:03,000
And they're also used, as I
mentioned in already example,

142
00:06:03,000 --> 00:06:06,850
at the beginning, to recover,
crypto wallet, private keys.

143
00:06:06,850 --> 00:06:08,430
And those are only four examples,

144
00:06:08,430 --> 00:06:10,870
of the many way you can
use side-channel attack,

145
00:06:10,870 --> 00:06:14,470
which is basically, when
do you need to either write

146
00:06:14,470 --> 00:06:16,820
something you cannot
observe side-channel attack

147
00:06:16,820 --> 00:06:18,080
is usually the way to go.

148
00:06:18,080 --> 00:06:19,960
Let's make that a little bit
more concrete for use case.

149
00:06:19,960 --> 00:06:23,690
So when you do a computation, for crypto,

150
00:06:23,690 --> 00:06:26,191
what you do is you feed for a plain text,

151
00:06:26,191 --> 00:06:28,860
and you feed a secret key.

152
00:06:28,860 --> 00:06:31,670
And the algorithm is running on the CPU,

153
00:06:31,670 --> 00:06:35,010
and what it's running, we
have some leakage, right?

154
00:06:35,010 --> 00:06:35,843
The first one is,

155
00:06:35,843 --> 00:06:37,520
how long the computation takes,

156
00:06:37,520 --> 00:06:39,680
what is not very relevant to AES

157
00:06:39,680 --> 00:06:41,820
when you have hardware
acceleration, actually,

158
00:06:41,820 --> 00:06:43,547
depending on the computation,

159
00:06:43,547 --> 00:06:45,940
time might change depending on the key

160
00:06:45,940 --> 00:06:47,910
that was mostly used
for, say a long time ago,

161
00:06:47,910 --> 00:06:50,123
because RSA use exponentiations

162
00:06:50,123 --> 00:06:52,530
and when it's not constant time,

163
00:06:52,530 --> 00:06:54,250
it can actually help to recover the key.

164
00:06:54,250 --> 00:06:56,210
That's one, the example, but again,

165
00:06:56,210 --> 00:06:58,960
timing is part of the computation text.

166
00:06:58,960 --> 00:07:00,670
Then we have the one we use in this talk,

167
00:07:00,670 --> 00:07:02,654
which is current, of course,

168
00:07:02,654 --> 00:07:04,540
depending on the operation you do,

169
00:07:04,540 --> 00:07:06,530
depending on how many register you load,

170
00:07:06,530 --> 00:07:08,380
how many registers you unload,

171
00:07:08,380 --> 00:07:09,950
the amount of power consumption

172
00:07:09,950 --> 00:07:13,630
and will rise, from, clock to clock.

173
00:07:13,630 --> 00:07:15,090
And so that's what we can measure.

174
00:07:15,090 --> 00:07:18,520
And that's what can use to
infer what is happening.

175
00:07:18,520 --> 00:07:21,550
Then we have a third
one, which is less used,

176
00:07:21,550 --> 00:07:23,880
but it's still possible, It is heat,

177
00:07:23,880 --> 00:07:26,820
of course depending on
which part of the type

178
00:07:26,820 --> 00:07:28,440
of operation you do,

179
00:07:28,440 --> 00:07:30,354
different parts CPU will
be used and as result,

180
00:07:30,354 --> 00:07:33,174
some parts will be hotter than others.

181
00:07:33,174 --> 00:07:37,090
But (indistinct) not most values.

182
00:07:37,090 --> 00:07:39,330
I think I haven't seen
very much concrete example,

183
00:07:39,330 --> 00:07:41,430
but it does exist.

184
00:07:41,430 --> 00:07:42,340
Last but not least,

185
00:07:42,340 --> 00:07:46,780
we also have what we call
extra magnetic emission, E-M

186
00:07:46,780 --> 00:07:49,990
And E-M is also a powerful channel,

187
00:07:49,990 --> 00:07:53,080
widely used to recover, public keys?

188
00:07:53,080 --> 00:07:54,170
It is with current,

189
00:07:54,170 --> 00:07:58,110
probably one of the two most
used in side-channel attack,

190
00:07:58,110 --> 00:08:01,740
timing being also
important as I mentioned.

191
00:08:01,740 --> 00:08:03,440
But purely current and E-M,

192
00:08:03,440 --> 00:08:06,340
is probably likes the two
leading technologies these days.

193
00:08:07,250 --> 00:08:08,510
What does it look like in practice?

194
00:08:08,510 --> 00:08:12,770
So here is a power trace of a AES.

195
00:08:12,770 --> 00:08:15,890
And if you look carefully
in the middle of the slide,

196
00:08:15,890 --> 00:08:19,540
you'll see, well, about
10 times the same pattern

197
00:08:19,540 --> 00:08:24,340
and they do correspond
to the turnaround of AES.

198
00:08:24,340 --> 00:08:26,000
So you can and visually see

199
00:08:26,000 --> 00:08:29,410
on a non-protected very
lightly protected in the AES.

200
00:08:29,410 --> 00:08:32,000
That we can observe around,

201
00:08:32,000 --> 00:08:33,450
by just working out the power trace.

202
00:08:33,450 --> 00:08:35,400
If we can observe it, as human,

203
00:08:35,400 --> 00:08:38,660
it means there are some
statistical information there,

204
00:08:38,660 --> 00:08:41,950
that can be exploited to I
understand what is happening.

205
00:08:41,950 --> 00:08:44,660
And that's in a sense, the searching out,

206
00:08:44,660 --> 00:08:46,100
the side effect.

207
00:08:46,100 --> 00:08:49,123
And that we can use to recover an AES key.

208
00:08:50,020 --> 00:08:51,420
In nutshell, how you go about that?

209
00:08:51,420 --> 00:08:56,420
Well, you get the CPU or the
target, to do the encryption.

210
00:08:56,990 --> 00:08:58,600
And what you do is you do inquire

211
00:08:58,600 --> 00:09:00,430
while your encryption is performed,

212
00:09:00,430 --> 00:09:03,620
the power trace using an oscilloscope.

213
00:09:03,620 --> 00:09:07,460
And then, in a traditional
side-channel attack.

214
00:09:07,460 --> 00:09:09,053
As the state-of-the-art is
called a template attack

215
00:09:09,053 --> 00:09:11,550
were you basically combine
the traces you observe,

216
00:09:11,550 --> 00:09:13,410
and you make statistical estimates,

217
00:09:13,410 --> 00:09:14,650
on what it could be.

218
00:09:14,650 --> 00:09:16,970
And the statistical estimate will help you

219
00:09:16,970 --> 00:09:18,350
to recover your AES key.

220
00:09:18,350 --> 00:09:20,698
This is how it works.

221
00:09:20,698 --> 00:09:23,560
If you wonder what type
of hardware we used.

222
00:09:23,560 --> 00:09:25,580
And again, this is what
we used doesn't mean

223
00:09:25,580 --> 00:09:26,883
that's the best,

224
00:09:26,883 --> 00:09:27,990
just what works for us.

225
00:09:27,990 --> 00:09:30,730
We used a NewAES Chipwhisperer Pro,

226
00:09:30,730 --> 00:09:33,320
and for some of our work,
however, notice still

227
00:09:33,320 --> 00:09:35,980
we also used Picoscope 6,000,

228
00:09:35,980 --> 00:09:37,460
when we need faster sampling,

229
00:09:37,460 --> 00:09:39,210
when the target is very fast,

230
00:09:39,210 --> 00:09:40,350
and we need all the information.

231
00:09:40,350 --> 00:09:42,950
So for example, last year,
when we talk about SCAAML,

232
00:09:42,950 --> 00:09:44,113
which is a way to do,

233
00:09:45,100 --> 00:09:47,530
a side-channel attack
using machine-learning,

234
00:09:47,530 --> 00:09:50,550
which we're going to
briefly recap in a second,

235
00:09:50,550 --> 00:09:52,480
then we do use a Picoscope.

236
00:09:52,480 --> 00:09:56,040
For this work, we just used
plain old Chipwhisperers.

237
00:09:56,040 --> 00:09:58,110
And again, this is not an Ad,

238
00:09:58,110 --> 00:10:00,360
this is just happened to be what we used

239
00:10:00,360 --> 00:10:03,020
in practice as how we
want to make this talk

240
00:10:03,020 --> 00:10:04,120
as concrete as we can.

241
00:10:04,960 --> 00:10:06,360
Now that we have an idea

242
00:10:06,360 --> 00:10:07,810
of what a side-channel are,

243
00:10:07,810 --> 00:10:12,040
let's talk about, how you
would go about using AI

244
00:10:12,040 --> 00:10:13,610
to perform side-channel attack.

245
00:10:13,610 --> 00:10:16,497
Well, this is something we
call side-channel attack,

246
00:10:16,497 --> 00:10:18,620
automated with machine-learning,

247
00:10:18,620 --> 00:10:20,680
also known as SCAAML.

248
00:10:20,680 --> 00:10:24,320
This is what we did present
in depths last year.

249
00:10:24,320 --> 00:10:26,382
But let me briefly recap,

250
00:10:26,382 --> 00:10:28,503
how does they work in practice.

251
00:10:28,503 --> 00:10:30,510
Because we're going to need a model

252
00:10:30,510 --> 00:10:32,170
that we create using a SCAAML attack

253
00:10:32,170 --> 00:10:34,247
to do the explainability,

254
00:10:34,247 --> 00:10:36,347
and then find out what the the leakage is.

255
00:10:37,340 --> 00:10:39,230
If you want to have more detail by the way

256
00:10:39,230 --> 00:10:40,590
about this type of attack,

257
00:10:40,590 --> 00:10:43,044
where you can check out last year talk,

258
00:10:43,044 --> 00:10:46,140
it's available at the,

259
00:10:46,140 --> 00:10:49,213
on my website at elie.net/scaaml

260
00:10:49,213 --> 00:10:52,330
I'll also probably put
a link on to Twitter.

261
00:10:52,330 --> 00:10:53,220
I just want you to follow along.

262
00:10:53,220 --> 00:10:55,500
And again, you have way more detail.

263
00:10:55,500 --> 00:10:57,300
I'm going to try to shrink down

264
00:10:57,300 --> 00:11:00,442
the explanation as much as I
can, so you can follow along

265
00:11:00,442 --> 00:11:01,920
But if you want all the details,

266
00:11:01,920 --> 00:11:04,400
they are on the previous document,

267
00:11:04,400 --> 00:11:06,290
I also want to say this year,

268
00:11:06,290 --> 00:11:08,090
is different from last year.

269
00:11:08,090 --> 00:11:11,470
So, for people who follow
both, in two senses.

270
00:11:11,470 --> 00:11:12,840
This time, last year,

271
00:11:12,840 --> 00:11:14,700
when we talk about using machine-learning

272
00:11:14,700 --> 00:11:16,840
to attack hardware encryption,

273
00:11:16,840 --> 00:11:18,350
we took the worst case,

274
00:11:18,350 --> 00:11:21,170
which is we're doing Blackbox attack,

275
00:11:21,170 --> 00:11:24,280
where the attacker doesn't
have any knowledge,

276
00:11:24,280 --> 00:11:25,810
about the target.

277
00:11:25,810 --> 00:11:26,643
And for example,

278
00:11:26,643 --> 00:11:29,130
it cannot have access to
the clock because the clock

279
00:11:30,360 --> 00:11:31,350
is usually not accessible

280
00:11:31,350 --> 00:11:34,590
after when the key is in both the hardware

281
00:11:34,590 --> 00:11:37,210
and condition is in operation mode, right?

282
00:11:37,210 --> 00:11:40,040
And so as a visual tool or creating traces

283
00:11:40,040 --> 00:11:41,690
in a asynchronous manner,

284
00:11:41,690 --> 00:11:43,507
which means that the clock or the target

285
00:11:43,507 --> 00:11:45,640
and the clock on the
oscilloscope were different.

286
00:11:45,640 --> 00:11:47,203
Which is why we had to use,

287
00:11:47,203 --> 00:11:48,470
very high sampling rate,

288
00:11:48,470 --> 00:11:50,770
In this specific case, we, this year,

289
00:11:50,770 --> 00:11:52,210
we are changing the model because

290
00:11:52,210 --> 00:11:54,840
this time SCALD is for people who

291
00:11:54,840 --> 00:11:57,130
are developing implementation.

292
00:11:57,130 --> 00:12:00,410
So we do assume you have the code,

293
00:12:00,410 --> 00:12:03,410
you have the hardware target,
you can put it in debug mode.

294
00:12:03,410 --> 00:12:07,430
And so we don't need to
create asynchronous trace's.

295
00:12:07,430 --> 00:12:08,680
We also have a good idea,

296
00:12:08,680 --> 00:12:12,050
if you a developer, at what time AES

297
00:12:13,025 --> 00:12:14,490
starts and what time it ends.

298
00:12:14,490 --> 00:12:17,620
So you can also create shorter traces.

299
00:12:17,620 --> 00:12:20,130
So reason why to do shorter captures is

300
00:12:20,130 --> 00:12:22,760
because the machine-learning
have an easier time.

301
00:12:22,760 --> 00:12:24,540
If you don't capture the whole thing,

302
00:12:24,540 --> 00:12:27,760
because that means you spend
less time when it trains,

303
00:12:27,760 --> 00:12:30,730
to eliminate part of the
traces which is useless.

304
00:12:30,730 --> 00:12:33,590
So again, this is a whitebox attack model,

305
00:12:33,590 --> 00:12:35,450
it makes more sense for that work.

306
00:12:35,450 --> 00:12:37,070
However, do not try to compare

307
00:12:37,070 --> 00:12:38,830
the model you use in this talk,

308
00:12:38,830 --> 00:12:41,220
which are easier and smarter than the one

309
00:12:41,220 --> 00:12:42,053
in the previous talk,

310
00:12:42,053 --> 00:12:44,390
where we had the way harder task

311
00:12:44,390 --> 00:12:45,280
with the machine-learning. Right?

312
00:12:45,280 --> 00:12:46,537
So when you're in the blackbox,

313
00:12:46,537 --> 00:12:48,060
the machine-learning work harder,

314
00:12:48,060 --> 00:12:49,470
which means you have to train more,

315
00:12:49,470 --> 00:12:52,660
and use more complicated and
more deeper architectures.

316
00:12:52,660 --> 00:12:54,270
In the case of a whitebox,

317
00:12:54,270 --> 00:12:57,350
when you are really laser
focusing on one part

318
00:12:57,350 --> 00:13:00,240
of the implementation here
will be the first round.

319
00:13:00,240 --> 00:13:01,810
We don't need that.

320
00:13:01,810 --> 00:13:04,410
So the way side-channel attack assisted

321
00:13:04,410 --> 00:13:06,990
by machine-learning works is very similar

322
00:13:06,990 --> 00:13:08,840
to the traditional
side-channel attacks. Right?

323
00:13:08,840 --> 00:13:10,360
Whereas in the previous case,

324
00:13:10,360 --> 00:13:12,370
you have the encryption which is running

325
00:13:12,370 --> 00:13:15,360
and then you capture the traces,

326
00:13:15,360 --> 00:13:16,850
don't forget that you capture the traces

327
00:13:16,850 --> 00:13:18,280
and you store them to normalize

328
00:13:18,280 --> 00:13:20,300
them between one and minus one,

329
00:13:20,300 --> 00:13:23,210
because the machine-learning
actually works in that range,

330
00:13:23,210 --> 00:13:26,740
which is not what your traditional
oscilloscope will output.

331
00:13:26,740 --> 00:13:31,740
And then, we feed those traces
to a deep neural network

332
00:13:32,140 --> 00:13:33,510
and we could show it,

333
00:13:33,510 --> 00:13:37,500
make prediction on what
it thinks are, the value,

334
00:13:37,500 --> 00:13:39,700
which can be used to recover the key.

335
00:13:39,700 --> 00:13:41,620
And then we combine those

336
00:13:42,610 --> 00:13:44,010
to do a statistical estimate.

337
00:13:44,010 --> 00:13:46,908
And hopefully you get back AES key.

338
00:13:46,908 --> 00:13:48,607
One of the advantages of that,

339
00:13:48,607 --> 00:13:50,350
as you were shown last year is

340
00:13:50,350 --> 00:13:53,940
that you did not need to do
any kind of pre-processing.

341
00:13:53,940 --> 00:13:55,640
You can just see the traces directly,

342
00:13:55,640 --> 00:13:57,340
and there is less expert knowledge on it.

343
00:13:57,340 --> 00:14:01,740
So it's open to place to do
that almost automatically.

344
00:14:01,740 --> 00:14:05,080
And so that make it a little bit easier.

345
00:14:05,080 --> 00:14:07,690
And also it's more
powerful than in a sense

346
00:14:07,690 --> 00:14:10,390
than the traditional competitor attack.

347
00:14:10,390 --> 00:14:12,280
Because of the reason I mentioned.

348
00:14:12,280 --> 00:14:14,544
when you do a side-channel attack,

349
00:14:14,544 --> 00:14:17,220
you do not necessarily directly target

350
00:14:17,220 --> 00:14:18,470
to record the key,

351
00:14:18,470 --> 00:14:21,090
you target what we call attack point,

352
00:14:21,090 --> 00:14:24,600
in the case tinyAES, they
are three, two points,

353
00:14:24,600 --> 00:14:26,010
which works really well,

354
00:14:26,010 --> 00:14:27,360
which is a sub_byte_in which is

355
00:14:27,360 --> 00:14:30,200
when you extract the
key with the plain text.

356
00:14:30,200 --> 00:14:31,790
And there is also the sub_byte_out,

357
00:14:31,790 --> 00:14:34,280
which is when you look at the output

358
00:14:34,280 --> 00:14:35,253
of the SBOX.

359
00:14:36,600 --> 00:14:39,152
In this talk, we're going
to focus on one of them,

360
00:14:39,152 --> 00:14:41,840
which is a sub_byte_in which
we know work really well,

361
00:14:41,840 --> 00:14:43,170
based on our experience.

362
00:14:43,170 --> 00:14:44,560
And this is something which is a point.

363
00:14:44,560 --> 00:14:46,220
So basically, so the machine-learning

364
00:14:46,220 --> 00:14:47,520
will not predict the key

365
00:14:47,520 --> 00:14:50,530
that really doesn't
work when you try that.

366
00:14:50,530 --> 00:14:52,927
But instead, its going to
predict the sub_byte_in,

367
00:14:52,927 --> 00:14:56,140
and well basically, if you
want to do the real attack,

368
00:14:56,140 --> 00:14:57,281
you take the sub_byte-in,

369
00:14:57,281 --> 00:14:58,870
and then you have to invert it,

370
00:14:58,870 --> 00:15:01,458
using the Plain text or do another XOR,

371
00:15:01,458 --> 00:15:02,291
and then you get the key,

372
00:15:02,291 --> 00:15:04,190
and then you can do
your prediction. Right?

373
00:15:04,190 --> 00:15:06,240
So the target point today is sub_byte-in.

374
00:15:07,580 --> 00:15:09,480
When the machine-learning
will predict the sub_byte_in

375
00:15:09,480 --> 00:15:11,640
what it does is you get a trace,

376
00:15:11,640 --> 00:15:13,950
and they tell you, okay,
sure, it's a soft mark.

377
00:15:13,950 --> 00:15:18,810
So a, almost a probabilistic
output of 254 evaluated

378
00:15:18,810 --> 00:15:20,420
which is the most important value,

379
00:15:20,420 --> 00:15:22,930
but also, what it thinks
is the second best value,

380
00:15:22,930 --> 00:15:24,630
third best value and so forth.

381
00:15:24,630 --> 00:15:26,900
And that's what the soft marks do.

382
00:15:26,900 --> 00:15:29,960
So what you do on how
to combine those things,

383
00:15:29,960 --> 00:15:32,118
that's why we created
probabilistic attack.

384
00:15:32,118 --> 00:15:33,670
It gives you basically summed it up,

385
00:15:33,670 --> 00:15:34,869
using locked-in,

386
00:15:34,869 --> 00:15:38,130
because of finding errors
and then you combine them,

387
00:15:38,130 --> 00:15:40,070
and hopefully by combining them,

388
00:15:40,070 --> 00:15:43,630
So you get the most likely value.

389
00:15:43,630 --> 00:15:45,787
And as machine-learning is
correct most of the time,

390
00:15:45,787 --> 00:15:47,970
So we can quickly converge.

391
00:15:47,970 --> 00:15:50,660
Last year, we showed that for tinyAES,

392
00:15:50,660 --> 00:15:53,140
on a full trace we only need four traces.

393
00:15:53,140 --> 00:15:54,540
So you can see your,

394
00:15:54,540 --> 00:15:57,570
see that in specific settings today,

395
00:15:57,570 --> 00:16:00,800
where is even easier where
we need us later that two.

396
00:16:00,800 --> 00:16:02,350
So basically three,

397
00:16:02,350 --> 00:16:03,970
four traces for simple cases,

398
00:16:03,970 --> 00:16:05,870
you get the correct value

399
00:16:05,870 --> 00:16:08,640
and you recovered one byte at the key.

400
00:16:08,640 --> 00:16:10,210
What's important to mention as well,

401
00:16:10,210 --> 00:16:12,890
here we have one model to byte.

402
00:16:12,890 --> 00:16:14,240
So we shall 16 bytes,

403
00:16:14,240 --> 00:16:17,570
which is in the more input
we have in reality, 16 model,

404
00:16:17,570 --> 00:16:19,600
which are performing one byte at a time,

405
00:16:19,600 --> 00:16:21,220
it is easier for the
machine-learning to predict

406
00:16:21,220 --> 00:16:22,090
one byte at a time.

407
00:16:22,090 --> 00:16:24,810
So, well, you have to train 16 in times.

408
00:16:24,810 --> 00:16:27,120
I'm not going to show that on the slide

409
00:16:27,120 --> 00:16:28,680
because it's not relevant.

410
00:16:28,680 --> 00:16:31,000
If you can do it for one,
you can do it for 16.

411
00:16:31,000 --> 00:16:32,110
However, there are some difference

412
00:16:32,110 --> 00:16:33,290
of accuracy between the byte,

413
00:16:33,290 --> 00:16:36,530
but that's not relevant for this talk.

414
00:16:36,530 --> 00:16:37,960
Okay. All right.

415
00:16:37,960 --> 00:16:39,210
For those who're curious,

416
00:16:40,450 --> 00:16:41,617
this year we used a

417
00:16:41,617 --> 00:16:46,617
Hypertuned residual 1D
convolution neural network,

418
00:16:47,804 --> 00:16:50,390
difference between this
model and last year,

419
00:16:50,390 --> 00:16:53,870
is that its way more efficient, smarter.

420
00:16:53,870 --> 00:16:56,020
And I think it's 300,000 points

421
00:16:56,020 --> 00:16:58,437
or something travels at
Southern neurons (indistinct).

422
00:16:59,452 --> 00:17:02,350
Its weight too works
really well out of the box,

423
00:17:02,350 --> 00:17:04,920
this is kind of our like
our go to model this days,

424
00:17:04,920 --> 00:17:06,620
which is based on our previous work

425
00:17:06,620 --> 00:17:09,060
and has seen a ton and ton of models,

426
00:17:09,060 --> 00:17:12,970
The a paper, I said last
year, it's kind of funny, but,

427
00:17:12,970 --> 00:17:14,200
the paper on all our tests

428
00:17:14,200 --> 00:17:16,350
about all the machine-learning
model will be out,

429
00:17:16,350 --> 00:17:19,796
At some point, I said,
last year, it will be soon.

430
00:17:19,796 --> 00:17:21,490
We had some technical difficulty,

431
00:17:21,490 --> 00:17:23,324
to make everything producible.

432
00:17:23,324 --> 00:17:24,570
And we have had our improvement,

433
00:17:24,570 --> 00:17:26,763
but hopefully I'm really
hopefully knocking on wood.

434
00:17:26,763 --> 00:17:28,980
(Knocks wood)

435
00:17:28,980 --> 00:17:30,160
These models,

436
00:17:30,160 --> 00:17:32,810
and the data-sets we
use to get our expertise

437
00:17:32,810 --> 00:17:33,957
into this would be out.

438
00:17:33,957 --> 00:17:36,195
And you guys can test it out.

439
00:17:36,195 --> 00:17:38,060
Hopefully in the near future.

440
00:17:38,060 --> 00:17:40,940
Lets carry around, you need the 16 models

441
00:17:40,940 --> 00:17:42,370
because you need to know,

442
00:17:42,370 --> 00:17:45,370
what is the commonality
between all the byte

443
00:17:45,370 --> 00:17:46,870
to know then exactly, where there is

444
00:17:46,870 --> 00:17:47,830
the main source of leakage,

445
00:17:47,830 --> 00:17:50,346
So you train 16 models.

446
00:17:50,346 --> 00:17:53,370
As I mentioned, the accuracy varies,

447
00:17:53,370 --> 00:17:55,000
as you can see your reach (indistinct)

448
00:17:55,000 --> 00:17:57,260
validation accuracy to be clear,

449
00:17:57,260 --> 00:17:59,690
so data, which has not
been seen during the 20s,

450
00:17:59,690 --> 00:18:03,600
or which am seen between
60s, three for the worst one,

451
00:18:03,600 --> 00:18:05,350
which has in cases by four,

452
00:18:05,350 --> 00:18:10,300
up to 87% for the best
one, which is by zeros.

453
00:18:10,300 --> 00:18:12,790
And again, they're all between that.

454
00:18:12,790 --> 00:18:15,840
For SCALD It doesn't really
matter what you need is

455
00:18:15,840 --> 00:18:18,040
to be able to isolate enough examples

456
00:18:18,040 --> 00:18:19,790
that the machine-learning is correct.

457
00:18:19,790 --> 00:18:23,260
Because those are one we're
going to use for explainability.

458
00:18:23,260 --> 00:18:25,700
Because we want to know what the model,

459
00:18:25,700 --> 00:18:28,080
is using when it's correct.

460
00:18:28,080 --> 00:18:29,370
That's why we don't train more than that.

461
00:18:29,370 --> 00:18:32,550
Try to imagine each of them is about,

462
00:18:32,550 --> 00:18:34,610
I would say 15 to 20 minutes.

463
00:18:34,610 --> 00:18:38,198
So you three per hour,
and you have 16 to go.

464
00:18:38,198 --> 00:18:42,160
So, that's already about
five hours of training time.

465
00:18:42,160 --> 00:18:44,450
So we don't want to do 28 box,

466
00:18:44,450 --> 00:18:46,610
which will be completely over kill.

467
00:18:46,610 --> 00:18:49,420
And they said, unsurprisingly,

468
00:18:49,420 --> 00:18:51,810
because tinyAES is not protected

469
00:18:51,810 --> 00:18:53,270
against side-channel attacks.

470
00:18:53,270 --> 00:18:55,542
And our model is really well optimized.

471
00:18:55,542 --> 00:18:59,680
We have high accuracy in for all of them.

472
00:18:59,680 --> 00:19:03,170
Now, the model is good
at extracting the key,

473
00:19:03,170 --> 00:19:05,230
So we are able to use it,

474
00:19:05,230 --> 00:19:07,210
and we can consistently recover keys.

475
00:19:07,210 --> 00:19:08,550
Now, the question is, okay,

476
00:19:08,550 --> 00:19:10,730
how does it help us to go back

477
00:19:10,730 --> 00:19:13,490
and well find where's
the leakage coming from?

478
00:19:13,490 --> 00:19:15,400
Well, so this is where you need

479
00:19:15,400 --> 00:19:16,500
to add another pieces,

480
00:19:16,500 --> 00:19:18,920
which is deep-learning in explainability.

481
00:19:18,920 --> 00:19:20,490
So what's deep-learning explainability?

482
00:19:20,490 --> 00:19:23,375
The deep-learning explainability,

483
00:19:23,375 --> 00:19:25,430
was first developed a belief of vision.

484
00:19:25,430 --> 00:19:28,480
And the idea was I have
a deep-learning network

485
00:19:28,480 --> 00:19:32,080
and it says in this
picture, we have a boxer

486
00:19:32,080 --> 00:19:33,670
and we have a tiger cat.

487
00:19:33,670 --> 00:19:36,470
Now you can ask the
question, okay but why?

488
00:19:36,470 --> 00:19:38,400
Does it really look at the cat,

489
00:19:38,400 --> 00:19:39,423
but it's really look at dog or

490
00:19:39,423 --> 00:19:41,760
does it look at statistics.

491
00:19:41,760 --> 00:19:45,330
I don't know, maybe, so
stripe in this stripe,

492
00:19:45,330 --> 00:19:48,130
colors of the tail of the cat,

493
00:19:48,130 --> 00:19:50,960
or maybe the dog leash
or something like that.

494
00:19:50,960 --> 00:19:52,900
So what you want to do
is you want to have a way

495
00:19:52,900 --> 00:19:54,700
to ask the neural network.

496
00:19:54,700 --> 00:19:55,710
What do you look at, right?

497
00:19:55,710 --> 00:19:58,010
And that's what explainability is about,

498
00:19:58,010 --> 00:20:00,560
is being able to say for a model,

499
00:20:00,560 --> 00:20:03,150
how does it come up
with a given prediction?

500
00:20:03,150 --> 00:20:05,140
Why for this specific class outputs,

501
00:20:05,140 --> 00:20:07,370
are one-of output neuron,

502
00:20:07,370 --> 00:20:08,440
what did you use as input?

503
00:20:08,440 --> 00:20:10,379
What does that input matter to you, right?

504
00:20:10,379 --> 00:20:11,740
So it basically almost

505
00:20:11,740 --> 00:20:15,030
inverting the machine-learning
model if you will.

506
00:20:15,030 --> 00:20:17,369
And so we call that explainability,

507
00:20:17,369 --> 00:20:18,202
(clears throat)

508
00:20:18,202 --> 00:20:19,160
there are many techniques, but the idea

509
00:20:19,160 --> 00:20:21,830
is all these technique have in common

510
00:20:21,830 --> 00:20:24,210
that you feed the machine to the model,

511
00:20:24,210 --> 00:20:27,150
to the explainer, then you feed the input,

512
00:20:27,150 --> 00:20:28,890
you would like information about,

513
00:20:28,890 --> 00:20:31,840
And then you have, to tell
him which class you want

514
00:20:31,840 --> 00:20:33,560
to have an explanation for.

515
00:20:33,560 --> 00:20:35,677
This is why, as I explained earlier,

516
00:20:35,677 --> 00:20:39,910
we need for SCALD to have
model, which work well,

517
00:20:39,910 --> 00:20:42,190
not necessarily 99%,
but at least very well,

518
00:20:42,190 --> 00:20:45,330
because we need to have
example of prediction,

519
00:20:45,330 --> 00:20:47,740
which are successful
because we want to know,

520
00:20:47,740 --> 00:20:51,150
for a given trace, and
a successful prediction,

521
00:20:51,150 --> 00:20:52,070
what to think.

522
00:20:52,070 --> 00:20:55,114
So, as I mentioned, you
give it to the explainer,

523
00:20:55,114 --> 00:20:58,430
the other side, you put the gift bags,

524
00:20:58,430 --> 00:21:00,406
the picture we had, and we say, okay,

525
00:21:00,406 --> 00:21:03,940
why did you believe it was a boxer?

526
00:21:03,940 --> 00:21:06,230
And hopefully it will tell you, well,

527
00:21:06,230 --> 00:21:09,563
I look at the face of the puppy.

528
00:21:10,460 --> 00:21:11,720
It's a boxer.

529
00:21:11,720 --> 00:21:13,690
Okay. That's understandable.

530
00:21:13,690 --> 00:21:15,610
And you can ask also, okay.

531
00:21:15,610 --> 00:21:18,550
How about the cat and hopefully,

532
00:21:18,550 --> 00:21:21,560
And again, those are
real example out of one

533
00:21:21,560 --> 00:21:22,410
of the explanation technique

534
00:21:22,410 --> 00:21:24,920
he will tell you, well, I look at the cat,

535
00:21:24,920 --> 00:21:27,920
and the reason why I think it's a cat

536
00:21:27,920 --> 00:21:29,290
is because well, there is a face

537
00:21:29,290 --> 00:21:32,260
of the cat but the most
important is there are stripes.

538
00:21:32,260 --> 00:21:35,670
As you can see as the
right part of the image.

539
00:21:35,670 --> 00:21:37,470
And you're like, okay, that makes sense.

540
00:21:37,470 --> 00:21:39,810
I guess a cat, which have stripes

541
00:21:39,810 --> 00:21:41,970
is probably a tiger cat makes sense.

542
00:21:41,970 --> 00:21:45,650
the machine-learning is actually
looking at what it should.

543
00:21:45,650 --> 00:21:48,000
Was this thinking ever useful.

544
00:21:48,000 --> 00:21:50,120
And the answer is yes, absolutely.

545
00:21:50,120 --> 00:21:52,070
There is this very, very famous,

546
00:21:52,070 --> 00:21:54,800
dataset in machine-learning for vision

547
00:21:54,800 --> 00:21:59,110
and is called the Pascal
vocabulary, visual vocabulary.

548
00:21:59,110 --> 00:22:01,902
And what happened was,
in the early version of

549
00:22:01,902 --> 00:22:04,520
this data set,

550
00:22:04,520 --> 00:22:06,560
I think one picture in five,

551
00:22:06,560 --> 00:22:10,043
four horses had a bottom left,

552
00:22:11,139 --> 00:22:13,410
a name of who took it

553
00:22:13,410 --> 00:22:15,150
and what the machine-learning learnt,

554
00:22:15,150 --> 00:22:16,990
was not recognize the horse,

555
00:22:16,990 --> 00:22:19,190
It was to recognize well that there

556
00:22:19,190 --> 00:22:21,710
was something on the bottom left.

557
00:22:21,710 --> 00:22:23,520
Alright. So that's what
explainability is for,

558
00:22:23,520 --> 00:22:24,910
so therefore we like,

559
00:22:24,910 --> 00:22:26,920
because essentially what we
want to ask the machine-learning

560
00:22:26,920 --> 00:22:31,920
is given a input and a
prediction, can you tell me,

561
00:22:32,710 --> 00:22:35,440
how you figure out why is
the leakage and what part

562
00:22:35,440 --> 00:22:38,520
where do you get information
to get to the conclusion

563
00:22:38,520 --> 00:22:41,113
that the correct key, or
the correct attack point?

564
00:22:42,210 --> 00:22:44,691
Well, that seems great in practice.

565
00:22:44,691 --> 00:22:46,570
That's too great in theory

566
00:22:46,570 --> 00:22:48,860
and we can't see where
it's going, the thing is,

567
00:22:48,860 --> 00:22:50,260
so don't tell us how we're going

568
00:22:50,260 --> 00:22:52,200
to combine this expandability techniques.

569
00:22:52,200 --> 00:22:54,520
And then recognize this to debug leakage.

570
00:22:54,520 --> 00:22:57,130
Because so far what I
explained to you is maybe

571
00:22:57,130 --> 00:23:01,380
how we can get some part
of the output highlighted

572
00:23:01,380 --> 00:23:03,090
that doesn't tell you how you go back,

573
00:23:03,090 --> 00:23:04,870
to know where the leakage come from.

574
00:23:04,870 --> 00:23:08,441
And so that's all the
difficulty of SCALD is even,

575
00:23:08,441 --> 00:23:10,970
and that's why it took us about one year,

576
00:23:10,970 --> 00:23:13,800
over a year, to actually really know how

577
00:23:13,800 --> 00:23:16,020
to get that done is because you need

578
00:23:16,020 --> 00:23:18,330
to be very creative around how

579
00:23:18,330 --> 00:23:19,163
to combine the things,

580
00:23:19,163 --> 00:23:21,158
which in theory makes sense,

581
00:23:21,158 --> 00:23:22,700
to actually get the result you want.

582
00:23:22,700 --> 00:23:25,670
So let's deep dive into how you get there.

583
00:23:25,670 --> 00:23:27,670
Our game plan was fairly straightforward.

584
00:23:27,670 --> 00:23:29,620
Again, we start with an explainer,

585
00:23:29,620 --> 00:23:32,065
we're going to give you the train models

586
00:23:32,065 --> 00:23:34,390
and then we're going to give it the trace

587
00:23:34,390 --> 00:23:36,590
and the prediction and say, okay,

588
00:23:36,590 --> 00:23:39,590
please tell me, of all the traces,

589
00:23:39,590 --> 00:23:41,110
what are the important point for you

590
00:23:41,110 --> 00:23:42,260
to make your prediction?

591
00:23:42,260 --> 00:23:44,420
We're going to call that the leakage map.

592
00:23:44,420 --> 00:23:49,420
Then we go into also do a
run, not necessarily after,

593
00:23:50,560 --> 00:23:53,790
but which is parallel a target emulator,

594
00:23:53,790 --> 00:23:55,690
which is basically we're going to run,

595
00:23:57,320 --> 00:24:00,270
our target, which is the given CPU

596
00:24:00,270 --> 00:24:05,270
in this specific talk
SMT32F4 and the firmware.

597
00:24:05,310 --> 00:24:08,252
So, in our case the firmware was tinyAES

598
00:24:08,252 --> 00:24:09,890
and we're going to emulate it,

599
00:24:09,890 --> 00:24:14,890
to be able to know at which
every instruction cycle,

600
00:24:15,860 --> 00:24:20,320
AM CPU correspond, which, of code, right?

601
00:24:20,320 --> 00:24:21,920
So basically we need to know,

602
00:24:21,920 --> 00:24:24,245
at what time precise point in time,

603
00:24:24,245 --> 00:24:28,340
a given code instruction was run,

604
00:24:28,340 --> 00:24:30,480
and then which current
instruction was run, right?

605
00:24:30,480 --> 00:24:34,260
And so with that, we can
combine both of them.

606
00:24:34,260 --> 00:24:37,380
We can combine the leakage
map, which has machine-learning

607
00:24:37,380 --> 00:24:39,040
which has at what time,

608
00:24:39,040 --> 00:24:41,930
the leakage occurred and the emulation

609
00:24:41,930 --> 00:24:43,940
which started at what time each

610
00:24:43,940 --> 00:24:46,020
instruction was run to be able

611
00:24:46,020 --> 00:24:48,813
annotated code which was
leakages that the idea.

612
00:24:50,420 --> 00:24:51,278
In practice,

613
00:24:51,278 --> 00:24:53,760
This is where it becomes complicated.

614
00:24:53,760 --> 00:24:55,990
There is of course love the techniques.

615
00:24:55,990 --> 00:24:59,340
Appears as the screenshots,
here's a figure from one

616
00:24:59,340 --> 00:25:00,690
of the recent paper,

617
00:25:00,690 --> 00:25:03,990
which is called "Sanity
Checks for Saliency Maps,"

618
00:25:03,990 --> 00:25:05,840
which basically we're looking at

619
00:25:05,840 --> 00:25:08,810
how efficient is different type
of explainability technique.

620
00:25:08,810 --> 00:25:10,910
And you can see some of them have

621
00:25:10,910 --> 00:25:13,810
more the finer prove than others,

622
00:25:13,810 --> 00:25:16,360
in this specific, in our research,

623
00:25:16,360 --> 00:25:17,230
we tried a bunch of them,

624
00:25:17,230 --> 00:25:19,840
including even say a Guided GradCAM

625
00:25:19,840 --> 00:25:22,570
which seemed, when we started to be giving

626
00:25:22,570 --> 00:25:25,454
some more define precisely leakage.

627
00:25:25,454 --> 00:25:28,180
And then we tested a bunch of them, right.

628
00:25:28,180 --> 00:25:30,510
The idea was which
explainability technique

629
00:25:30,510 --> 00:25:31,440
will work best for us.

630
00:25:31,440 --> 00:25:35,550
Because we want to
highlight a very precisely,

631
00:25:35,550 --> 00:25:38,240
which part of the traces
was the most important one,

632
00:25:38,240 --> 00:25:39,073
how you do that?

633
00:25:39,073 --> 00:25:40,270
Well, you get the explanation.

634
00:25:40,270 --> 00:25:42,250
So, you run a loss, tracing,

635
00:25:42,250 --> 00:25:45,020
which was successful into the explanation,

636
00:25:45,020 --> 00:25:47,360
here is the activation map technique.

637
00:25:47,360 --> 00:25:49,670
Then you combined them,

638
00:25:49,670 --> 00:25:51,120
and you're not managed between two and one

639
00:25:51,120 --> 00:25:53,930
to create some sort of a mask.

640
00:25:53,930 --> 00:25:57,750
And then, you eliminate all the noise

641
00:25:57,750 --> 00:26:01,420
and hopefully you get, the bottom images,

642
00:26:01,420 --> 00:26:03,947
which is a leakage map.

643
00:26:03,947 --> 00:26:05,960
And you can see, stride here.

644
00:26:05,960 --> 00:26:08,720
And you can see that some
places which are lighter

645
00:26:08,720 --> 00:26:10,154
are supposed to be the place where,

646
00:26:10,154 --> 00:26:12,600
the model is the key to most.

647
00:26:12,600 --> 00:26:14,500
So according to activation maps,

648
00:26:14,500 --> 00:26:17,391
there is a, I think it was bytes by zero.

649
00:26:17,391 --> 00:26:20,880
The very, very early, there was a leakage

650
00:26:20,880 --> 00:26:23,940
and they were late around the 4,000 points

651
00:26:23,940 --> 00:26:28,610
so at the end of our traces,
some, leakage, right?

652
00:26:28,610 --> 00:26:30,327
Depending on techniques you use,

653
00:26:30,327 --> 00:26:32,120
you going to get different results.

654
00:26:32,120 --> 00:26:34,330
The first one we tested is SNR,

655
00:26:34,330 --> 00:26:35,720
which is not a deep-learning technique,

656
00:26:35,720 --> 00:26:37,860
but is the standard technique,

657
00:26:37,860 --> 00:26:40,490
use intentional attacks to detect whether

658
00:26:40,490 --> 00:26:41,670
or not there is a leak.

659
00:26:41,670 --> 00:26:44,650
So it's a very much, a very robust way,

660
00:26:44,650 --> 00:26:46,110
statistical workable way and that kind

661
00:26:46,110 --> 00:26:47,150
of like a baseline.

662
00:26:47,150 --> 00:26:50,015
So it was the signal
to noise ratio tell you

663
00:26:50,015 --> 00:26:54,630
that as you can see, there is a main leak

664
00:26:54,630 --> 00:26:56,540
and there is a secondary
leak somewhere in the middle

665
00:26:56,540 --> 00:26:57,710
of the tracer.

666
00:26:57,710 --> 00:27:00,194
And then if we look at GradCAM++,

667
00:27:00,194 --> 00:27:02,044
which is one of the latest technique,

668
00:27:03,350 --> 00:27:05,120
the results are not so clear,

669
00:27:05,120 --> 00:27:08,380
we have a bunch of different points,

670
00:27:08,380 --> 00:27:11,840
which doesn't seem to
align well with the SNR,

671
00:27:11,840 --> 00:27:13,520
or at least they are less defined.

672
00:27:13,520 --> 00:27:14,517
There already exists in parts,

673
00:27:14,517 --> 00:27:16,560
but not exactly the same.

674
00:27:16,560 --> 00:27:21,340
And then, the activation
map looks almost equivalent

675
00:27:21,340 --> 00:27:23,120
to the GradCAM.

676
00:27:23,120 --> 00:27:25,523
The first one was the
events of activation map

677
00:27:25,523 --> 00:27:29,758
look at the output of
lay up, the lowest layer.

678
00:27:29,758 --> 00:27:31,940
This seems very, very much the same.

679
00:27:31,940 --> 00:27:34,410
So how do you benchmark how
good explainability are?

680
00:27:34,410 --> 00:27:36,843
So the idea is, well, we
have a leak map, right?

681
00:27:36,843 --> 00:27:39,254
What we can do is we
can take our test traces

682
00:27:39,254 --> 00:27:40,880
that we know the machine-learning

683
00:27:40,880 --> 00:27:43,610
is successful at predicting,
and then we can decide

684
00:27:43,610 --> 00:27:45,390
to use the leak map.

685
00:27:45,390 --> 00:27:50,360
And let's say remove the four
point or the eight points,

686
00:27:50,360 --> 00:27:51,860
which are supposed to
be the most important.

687
00:27:51,860 --> 00:27:53,500
According to the leakage
map out to the traces.

688
00:27:53,500 --> 00:27:55,030
We can just get blank them,

689
00:27:55,030 --> 00:27:58,520
Blanking them means for them
to zero or to minus one,

690
00:27:58,520 --> 00:27:59,353
put them to zero.

691
00:27:59,353 --> 00:28:04,130
But same idea, you basically,
remove the information there,

692
00:28:04,130 --> 00:28:06,181
and hopefully either
the most important part

693
00:28:06,181 --> 00:28:09,410
of the prediction and the
accuracy of the model,

694
00:28:09,410 --> 00:28:11,150
which should feed again,

695
00:28:11,150 --> 00:28:12,762
should result in aggregate

696
00:28:12,762 --> 00:28:14,480
to decrease accuracy, right?

697
00:28:14,480 --> 00:28:16,960
The idea is that it
should blank-out the point

698
00:28:16,960 --> 00:28:19,750
which are used by the
machine-learning to the prediction.

699
00:28:19,750 --> 00:28:21,250
The accuracy should decrease.

700
00:28:21,250 --> 00:28:23,130
So mechanical is the best technique,

701
00:28:23,130 --> 00:28:25,840
should yield the best decrease.

702
00:28:25,840 --> 00:28:29,800
Baseline as I said 100%
because we only used traces.

703
00:28:29,800 --> 00:28:31,220
You removed four points.

704
00:28:31,220 --> 00:28:34,830
Why four points is because
in instruction text,

705
00:28:34,830 --> 00:28:37,890
when we capture them with the oscilloscope

706
00:28:37,890 --> 00:28:39,100
is four points, right?

707
00:28:39,100 --> 00:28:42,740
So each cycle of a CPU is
supposed to be four points.

708
00:28:42,740 --> 00:28:44,110
So if we know that, if we say, okay,

709
00:28:44,110 --> 00:28:47,563
let's try to remove the
most important cycle.

710
00:28:49,190 --> 00:28:50,726
If we do it with SNR,

711
00:28:50,726 --> 00:28:52,110
the technique seems to work, right.

712
00:28:52,110 --> 00:28:55,621
It seems we reduced by 57% and 44%.

713
00:28:55,621 --> 00:28:58,350
If we do the activation map,

714
00:28:58,350 --> 00:29:00,900
and it was our first
vary big disappointment,

715
00:29:00,900 --> 00:29:03,990
sometime in the project
last year, not last year,

716
00:29:03,990 --> 00:29:05,320
but like a few months back was like,

717
00:29:05,320 --> 00:29:06,818
ooh, well, doesn't work as well

718
00:29:06,818 --> 00:29:08,709
SNR is better.

719
00:29:08,709 --> 00:29:11,476
So activation map
doesn't work really well.

720
00:29:11,476 --> 00:29:15,030
And, if you remember, I
should use the leakage map

721
00:29:15,030 --> 00:29:17,630
almost the same and the
visual (indistinct) GradCAM+

722
00:29:18,510 --> 00:29:21,035
So the idea seems Alright.

723
00:29:21,035 --> 00:29:24,224
It's working the same that SNR works,

724
00:29:24,224 --> 00:29:25,820
our deep-learning explainability

725
00:29:25,820 --> 00:29:28,054
which is way more
complicated than should be,

726
00:29:28,054 --> 00:29:28,940
working better doesn't.

727
00:29:28,940 --> 00:29:33,050
So that was a little bit disappointing.

728
00:29:33,050 --> 00:29:35,550
And so it was like back
to the drawing board,

729
00:29:35,550 --> 00:29:37,810
what can we do? Let's go back to that.

730
00:29:37,810 --> 00:29:41,415
And so the way we went
about that is like, okay,

731
00:29:41,415 --> 00:29:44,190
let's write our own technique
because what we want

732
00:29:44,190 --> 00:29:46,410
is to only find the top point.

733
00:29:46,410 --> 00:29:49,990
So we can probably do
something with a very old idea,

734
00:29:49,990 --> 00:29:53,020
which is occlusion and try to
make it a little bit better.

735
00:29:53,020 --> 00:29:55,410
So I know it seems weird to say, okay,

736
00:29:55,410 --> 00:29:58,910
let's invent a new technique
for a specific task,

737
00:29:58,910 --> 00:30:00,230
but the thing is we are trying

738
00:30:00,230 --> 00:30:02,257
to do something very first unique and

739
00:30:02,257 --> 00:30:03,710
very, very precise is we don't want

740
00:30:03,710 --> 00:30:05,240
to have like the exact region

741
00:30:05,240 --> 00:30:06,960
and have more like a
holistic understanding

742
00:30:06,960 --> 00:30:09,880
And we want like top
five or top 20 points.

743
00:30:09,880 --> 00:30:13,730
So, because our optimization
for our technique is different

744
00:30:13,730 --> 00:30:16,580
than the type of underlying algorithm.

745
00:30:16,580 --> 00:30:18,230
You want to use it a little bit different

746
00:30:18,230 --> 00:30:19,490
we can use or occlusion,

747
00:30:19,490 --> 00:30:22,420
which should literally try
to use a window to do that.

748
00:30:22,420 --> 00:30:27,420
And so SCALD, explanation
technique is actually,

749
00:30:27,700 --> 00:30:32,310
exactly that it's a hybrid
version of occlusion,

750
00:30:32,310 --> 00:30:34,957
where we start to eliminate
large regional to,

751
00:30:34,957 --> 00:30:36,990
we assume we don't choose more region.

752
00:30:36,990 --> 00:30:39,520
And then we use convolutions

753
00:30:39,520 --> 00:30:40,960
convolutive occlusion,

754
00:30:40,960 --> 00:30:42,120
something we developed for this

755
00:30:42,120 --> 00:30:46,354
to actually really pinpoint
which part of the traces,

756
00:30:46,354 --> 00:30:48,910
for the region that we
think are predictive,

757
00:30:48,910 --> 00:30:51,950
which of the point exact
point are the most important.

758
00:30:51,950 --> 00:30:53,480
And as you can see,

759
00:30:53,480 --> 00:30:58,016
the traces are way cleaner
than the one we had before.

760
00:30:58,016 --> 00:31:02,350
And they clearly outline, leakage.

761
00:31:02,350 --> 00:31:05,820
Also, as you can see for two,
the byte zero and byte seven,

762
00:31:05,820 --> 00:31:10,307
it is clear that byte
zero is before byte seven,

763
00:31:10,307 --> 00:31:11,190
for in term of leakage

764
00:31:11,190 --> 00:31:12,400
which make a ton of sense,

765
00:31:12,400 --> 00:31:16,140
because obviously tinyAES
process one after the other

766
00:31:16,140 --> 00:31:17,730
Alright, it's not (indistinct) as code.

767
00:31:17,730 --> 00:31:20,243
So that will be exactly what we expect.

768
00:31:21,170 --> 00:31:24,370
Okay. So we're like, okay,

769
00:31:24,370 --> 00:31:26,830
traces is good should work. Right?

770
00:31:26,830 --> 00:31:29,490
So go back to the
benchmark, run the scene.

771
00:31:29,490 --> 00:31:32,360
And voila! our number are way better,

772
00:31:32,360 --> 00:31:35,780
or at least better for byte 7

773
00:31:35,780 --> 00:31:40,610
And so again, so now we have a
technique which works better.

774
00:31:40,610 --> 00:31:41,610
Our map is not precise.

775
00:31:41,610 --> 00:31:44,360
We hope that the leakage
pinpoint will be more precise.

776
00:31:45,280 --> 00:31:48,460
And just to give you a
visual comparison to finish

777
00:31:48,460 --> 00:31:50,329
on that side is very clear that,

778
00:31:50,329 --> 00:31:54,320
the SNR SCALD basically
find for precise and major,

779
00:31:54,320 --> 00:31:57,720
except the regions are
better defined with SCALD

780
00:31:57,720 --> 00:32:00,800
which is good because the
SNR is not wrong in general.

781
00:32:00,800 --> 00:32:03,160
And B we have something which is cleaner,

782
00:32:03,160 --> 00:32:07,220
which means that we have
improved over existing

783
00:32:07,220 --> 00:32:10,260
state-of-the-art and also
finding something completely out

784
00:32:10,260 --> 00:32:11,260
of the telcos model.

785
00:32:11,260 --> 00:32:16,107
So this tech model is
more precise is good.

786
00:32:16,107 --> 00:32:21,107
So I said, benchmark
shows that in every case

787
00:32:21,237 --> 00:32:24,970
SCALD actually outperform
everything we tested.

788
00:32:24,970 --> 00:32:26,680
It's not to say there is not a better way,

789
00:32:26,680 --> 00:32:28,420
but this is working for us.

790
00:32:28,420 --> 00:32:30,780
And this is good enough as we'll see.

791
00:32:30,780 --> 00:32:32,740
So we came to favor the same,

792
00:32:32,740 --> 00:32:34,670
because it's also quite fast.

793
00:32:34,670 --> 00:32:39,150
It takes about 10 minutes
to explain a network.

794
00:32:39,150 --> 00:32:42,650
Okay. Now let's explain in
greater detail how you go

795
00:32:42,650 --> 00:32:43,850
from leakage map,

796
00:32:43,850 --> 00:32:45,840
how we can go from model to leakage map,

797
00:32:45,840 --> 00:32:48,190
The question is how it goes
from leakage map to code.

798
00:32:48,190 --> 00:32:49,800
Well, for that, as I mentioned,

799
00:32:49,800 --> 00:32:54,800
we have an emulator which is
base of unicorn and rainbow.

800
00:32:55,160 --> 00:32:59,180
And basically we run it
with a firmware and the CPU,

801
00:32:59,180 --> 00:33:02,800
and we basically have a set of automaton

802
00:33:02,800 --> 00:33:04,530
We'll try to emulate whats happening

803
00:33:04,530 --> 00:33:06,680
during the leakage map.

804
00:33:06,680 --> 00:33:09,170
But the idea is you want to do a start

805
00:33:09,170 --> 00:33:13,370
run the AES and stop and
basically pick up what is

806
00:33:13,370 --> 00:33:15,360
in sync with the leakage map.

807
00:33:15,360 --> 00:33:16,670
And then what happened then

808
00:33:16,670 --> 00:33:19,630
is you get a Mapped ASM.

809
00:33:19,630 --> 00:33:21,470
So what you get is you get, okay,

810
00:33:21,470 --> 00:33:24,409
this cycle maps to this time,

811
00:33:24,409 --> 00:33:27,020
this point in the trace
map is that cycle, so

812
00:33:27,020 --> 00:33:31,980
that they can map to this
specific CPU instruction.

813
00:33:31,980 --> 00:33:33,970
And then what we do is

814
00:33:33,970 --> 00:33:35,670
when we have a CPU instruction,

815
00:33:35,670 --> 00:33:37,610
we build a tree, and the tree,

816
00:33:37,610 --> 00:33:39,130
we bubble up the instruction

817
00:33:39,130 --> 00:33:43,390
to a given code line using

818
00:33:43,390 --> 00:33:45,860
the debug symbol of our firmware.

819
00:33:45,860 --> 00:33:47,760
The firmware will run both firmware

820
00:33:49,525 --> 00:33:51,190
The firmware we have is in debug mode.

821
00:33:51,190 --> 00:33:53,270
Again, we're back to this idea that,

822
00:33:53,270 --> 00:33:54,960
this is a tool for developers.

823
00:33:54,960 --> 00:33:57,210
So when you test for leakage,

824
00:33:57,210 --> 00:33:59,174
you can compile with it very simple,

825
00:33:59,174 --> 00:34:00,590
because you don't try to harden it.

826
00:34:00,590 --> 00:34:01,680
We just want to debug it.

827
00:34:01,680 --> 00:34:03,570
So with debug symbol
will help us to go back

828
00:34:03,570 --> 00:34:07,060
from the instruction
back to the line of code.

829
00:34:07,060 --> 00:34:10,120
And hopefully that give
us an idea of where

830
00:34:10,120 --> 00:34:10,953
to map the code.

831
00:34:12,700 --> 00:34:15,790
So there's the theory,
but we haven't told you,

832
00:34:15,790 --> 00:34:18,787
or haven't shown you
precision work in practice.

833
00:34:18,787 --> 00:34:19,956
And the thing is,

834
00:34:19,956 --> 00:34:21,240
before I do that,

835
00:34:21,240 --> 00:34:24,550
I want to be on phase three
points in about this project.

836
00:34:24,550 --> 00:34:26,460
So the first one is,

837
00:34:26,460 --> 00:34:28,500
we spend a lot of time talking
about the explainability,

838
00:34:28,500 --> 00:34:33,470
because if we don't have
extremely precise technique

839
00:34:33,470 --> 00:34:35,190
which exactly our point,

840
00:34:35,190 --> 00:34:39,070
which exactly pinpoint,
what point is the trace

841
00:34:40,620 --> 00:34:42,930
is responsible for the leakage.

842
00:34:42,930 --> 00:34:44,050
We're going to fail.

843
00:34:44,050 --> 00:34:46,680
We're going to fail
because most instructions

844
00:34:46,680 --> 00:34:51,680
on AM are two, maybe three,
maybe four seconds long,

845
00:34:52,240 --> 00:34:53,270
at most right?

846
00:34:53,270 --> 00:34:55,030
Not at most, but two, one, two,

847
00:34:55,030 --> 00:34:56,550
two instruction for an addition,

848
00:34:56,550 --> 00:34:57,640
since priority is standard.

849
00:34:57,640 --> 00:35:00,600
So it's literally four to eight points.

850
00:35:00,600 --> 00:35:03,080
Like our margin of error
is maybe one point,

851
00:35:03,080 --> 00:35:04,560
but that's about all we get.

852
00:35:04,560 --> 00:35:07,100
So if we don't have precise mapping,

853
00:35:07,100 --> 00:35:09,000
then if we map, let's say 10 points ahead.

854
00:35:09,000 --> 00:35:10,490
Or if you have a windows of 10 points,

855
00:35:10,490 --> 00:35:11,630
it's meaningless for us,

856
00:35:11,630 --> 00:35:13,730
because then it may be three instruction.

857
00:35:13,730 --> 00:35:14,930
And also instructions may be wrong

858
00:35:14,930 --> 00:35:16,340
to different lines of codes.

859
00:35:16,340 --> 00:35:20,060
So basically your analysis
is completely botched.

860
00:35:20,060 --> 00:35:24,040
At the same time, we
need to have an emulator,

861
00:35:24,040 --> 00:35:26,060
which is also thinkers like a precision,

862
00:35:26,060 --> 00:35:30,180
because what happen is if
do not take into account,

863
00:35:30,180 --> 00:35:32,130
let's say pipeline
flush, if you don't take

864
00:35:32,130 --> 00:35:35,550
into account the CPU pipeline side,

865
00:35:35,550 --> 00:35:38,120
and things like that, you get it wrong.

866
00:35:38,120 --> 00:35:39,630
You get it wrong because you're going

867
00:35:39,630 --> 00:35:40,960
to shift everything by, let's say,

868
00:35:40,960 --> 00:35:43,910
you're wrong let's say by
one second for each addition,

869
00:35:43,910 --> 00:35:46,500
then your whole traces
is completely shifted.

870
00:35:46,500 --> 00:35:48,960
And then even if your
leakage mapping is good,

871
00:35:48,960 --> 00:35:51,480
you get somewhere in the
code, which is not relevant.

872
00:35:51,480 --> 00:35:55,150
So you need second precision
emulator, second precision,

873
00:35:55,150 --> 00:35:57,600
a single point precision explanation.

874
00:35:57,600 --> 00:35:59,513
So you need something extremely precise.

875
00:35:59,513 --> 00:36:03,070
This is very, very much a precise work.

876
00:36:03,070 --> 00:36:04,620
And then on top of that,

877
00:36:04,620 --> 00:36:06,160
you need a bit of computation.

878
00:36:06,160 --> 00:36:08,830
Again, as I said, you
need to (mumbles) about,

879
00:36:08,830 --> 00:36:12,560
we use I think 1 million data
point, something like that.

880
00:36:12,560 --> 00:36:14,370
And then even for the explanation time,

881
00:36:14,370 --> 00:36:18,410
we use 60,000 traces, you need 16 models,

882
00:36:18,410 --> 00:36:20,530
as I mentioned, you can
shorten the time, of course,

883
00:36:20,530 --> 00:36:23,107
by using good model who
convolution quickly,

884
00:36:23,107 --> 00:36:25,390
And then, to 16 explanations

885
00:36:25,390 --> 00:36:27,530
for all those models in your trace,

886
00:36:27,530 --> 00:36:29,420
and then you need to map everything.

887
00:36:29,420 --> 00:36:33,480
So with our, optimizations,
that will take you,

888
00:36:33,480 --> 00:36:35,115
a day or so of work.

889
00:36:35,115 --> 00:36:37,170
And of course, as I said,

890
00:36:37,170 --> 00:36:38,670
most of it is part is (indistinct)

891
00:36:38,670 --> 00:36:41,300
because the 16 model and 16 explanation

892
00:36:41,300 --> 00:36:43,600
can be run on distinct CPU. Right.

893
00:36:43,600 --> 00:36:47,630
So, you can make it 16
times faster, usually.

894
00:36:47,630 --> 00:36:49,880
So that's really good
because we want to use

895
00:36:49,880 --> 00:36:52,533
that as a fast iterative
tool for the reverse.

896
00:36:53,600 --> 00:36:54,740
Alright.

897
00:36:54,740 --> 00:36:56,690
So is it all bunch of like, okay.

898
00:36:56,690 --> 00:36:57,620
He gave me a long speech

899
00:36:57,620 --> 00:36:59,905
of it's very hard, so probably it failed.

900
00:36:59,905 --> 00:37:01,840
And that's really,
really hard because yeah,

901
00:37:01,840 --> 00:37:04,860
emulating a CPU is hard and
I'm telling you it's true.

902
00:37:04,860 --> 00:37:07,270
I don't think we have a
perfect emulation of CPU.

903
00:37:07,270 --> 00:37:11,799
I think we have very
precise emulation of the

904
00:37:11,799 --> 00:37:15,360
instruction we need for AES.

905
00:37:15,360 --> 00:37:18,670
In particular one thing we
don't have, a disclaimer,

906
00:37:18,670 --> 00:37:21,303
if we don't have implemented
mapping for the divide.

907
00:37:23,380 --> 00:37:28,103
Why is because division actually
takes a lot of cycle and,

908
00:37:29,156 --> 00:37:32,200
a very different range of cycle on AM CPU.

909
00:37:32,200 --> 00:37:33,900
So we don't really know what to do there.

910
00:37:33,900 --> 00:37:38,900
So, only working for now
AES in full transparency.

911
00:37:39,510 --> 00:37:40,623
That been said,

912
00:37:41,590 --> 00:37:44,020
If we try to apply what
I said, to our model,

913
00:37:44,020 --> 00:37:47,450
what we expect to see
in the technical sense

914
00:37:47,450 --> 00:37:51,200
is we supposed is the model
is targeting sub_byte_in,

915
00:37:51,200 --> 00:37:53,840
then it most exploits something

916
00:37:53,840 --> 00:37:56,340
in the AddRoundKey because AddRoundKey

917
00:37:56,340 --> 00:37:59,080
where you do the key
extract the plain text,

918
00:37:59,080 --> 00:38:02,400
so it must have most of the
leakage should be there.

919
00:38:02,400 --> 00:38:04,210
So it's a technical thing.

920
00:38:04,210 --> 00:38:07,280
And so what we do to verify
that's what we said worked,

921
00:38:07,280 --> 00:38:09,540
is to actually try to verify that.

922
00:38:09,540 --> 00:38:12,210
And so that's what the
schedule could look like.

923
00:38:12,210 --> 00:38:13,690
It's a terminal thing.

924
00:38:13,690 --> 00:38:14,530
You basically run it.

925
00:38:14,530 --> 00:38:17,730
And at the end you spit out this tree,

926
00:38:17,730 --> 00:38:20,200
which map, cycle instructional machine

927
00:38:20,200 --> 00:38:23,160
on display for visibility to code line,

928
00:38:23,160 --> 00:38:25,370
which is basically numbers.

929
00:38:25,370 --> 00:38:29,030
And then I filter everything
which is not leaking.

930
00:38:29,030 --> 00:38:32,450
And then what this
mapping tell you is yes,

931
00:38:32,450 --> 00:38:35,172
it's the main leakage
is online tool searching

932
00:38:35,172 --> 00:38:36,830
of AddRoundKey.

933
00:38:36,830 --> 00:38:37,870
So that's promising

934
00:38:37,870 --> 00:38:40,480
It also have interestingly
enough, a secondary leakage,

935
00:38:40,480 --> 00:38:44,303
which is later on into
the cipher functions.

936
00:38:46,010 --> 00:38:49,253
So, where is the line 213, Right.

937
00:38:50,250 --> 00:38:54,300
Well, the good news is it's
exactly what we predicted.

938
00:38:54,300 --> 00:38:58,210
This is exactly the, the
line is a whole code,

939
00:38:58,210 --> 00:39:00,150
that you can find on GitHub,

940
00:39:00,150 --> 00:39:03,840
which is Exactly, where the key is XOR

941
00:39:03,840 --> 00:39:05,030
with the plain text.

942
00:39:05,030 --> 00:39:08,230
So the model and SCALD in
general, really clearly

943
00:39:08,230 --> 00:39:12,160
is using what a JIRA would predict,

944
00:39:12,160 --> 00:39:15,060
which is there is a leak
in that specific line

945
00:39:15,060 --> 00:39:17,363
because they are doing,(mumbles)

946
00:39:17,363 --> 00:39:19,610
they are sharing the values of registers.

947
00:39:19,610 --> 00:39:22,950
It's (mumbles) some assignments, sorry,

948
00:39:22,950 --> 00:39:24,220
And so this is what it is.

949
00:39:24,220 --> 00:39:25,740
So that's a success.

950
00:39:25,740 --> 00:39:27,200
That's what gives us confidence that

951
00:39:27,200 --> 00:39:28,710
when we do work in practice

952
00:39:28,710 --> 00:39:32,810
is not a, it's really giving
us interesting results.

953
00:39:32,810 --> 00:39:34,570
I will not claim it's
working in every case.

954
00:39:34,570 --> 00:39:38,280
I'm sure that with a more
complex implementation,

955
00:39:38,280 --> 00:39:41,950
like mask ASM or more
complicated security,

956
00:39:41,950 --> 00:39:43,620
the results may be drastically differ.

957
00:39:43,620 --> 00:39:47,670
As I said, our emulator
do not fully emulate

958
00:39:47,670 --> 00:39:49,660
all the operation you get on AM.

959
00:39:49,660 --> 00:39:51,150
There is still a lot of uncertainty,

960
00:39:51,150 --> 00:39:54,410
but however it works.

961
00:39:54,410 --> 00:39:56,500
I think it's a very promising step

962
00:39:56,500 --> 00:39:59,610
towards the right direction
of having tool who go back

963
00:39:59,610 --> 00:40:02,890
from leakage to, exact line of code.

964
00:40:02,890 --> 00:40:04,530
As far as we can tell it's the first time

965
00:40:04,530 --> 00:40:06,193
it has ever been done.

966
00:40:06,193 --> 00:40:07,796
Based on secondary leakage,

967
00:40:07,796 --> 00:40:09,921
I don't have a good explanation for it.

968
00:40:09,921 --> 00:40:11,590
So the best thing we can come up,

969
00:40:11,590 --> 00:40:15,070
I can come up with today is
that it probably went some

970
00:40:15,070 --> 00:40:16,920
of the register unloaded.

971
00:40:16,920 --> 00:40:20,610
And so, this is where as it
starts to use a mixed column,

972
00:40:20,610 --> 00:40:23,280
you should look at line 371.

973
00:40:23,280 --> 00:40:27,280
So maybe that's what happened
is unloading some registers,

974
00:40:27,280 --> 00:40:28,570
and then we can go back.

975
00:40:28,570 --> 00:40:30,020
We did have a bit more analysis for that,

976
00:40:30,020 --> 00:40:31,700
but basically we interesting

977
00:40:31,700 --> 00:40:34,140
to know why there secondary leakage.

978
00:40:34,140 --> 00:40:37,000
So hopefully today I
showed you how we use SCALD

979
00:40:37,000 --> 00:40:39,640
to automatically isolate vulnerable code

980
00:40:39,640 --> 00:40:41,373
and show how it works in practice.

981
00:40:41,373 --> 00:40:43,165
And showed you concretely.

982
00:40:43,165 --> 00:40:45,730
What's the benefit of the tool?

983
00:40:45,730 --> 00:40:48,120
And really our hope is this type of tool

984
00:40:48,120 --> 00:40:49,920
we keep building it and we'll get feedback

985
00:40:49,920 --> 00:40:51,700
from the community to build something

986
00:40:51,700 --> 00:40:55,110
which will empower people
who develop secure hardware

987
00:40:55,110 --> 00:40:58,093
to quickly figure out and patch,

988
00:40:58,960 --> 00:41:00,120
where the leakages are coming from.

989
00:41:00,120 --> 00:41:01,980
So we can develop stronger crypto

990
00:41:01,980 --> 00:41:04,450
in a easier way and a faster iteration.

991
00:41:04,450 --> 00:41:06,847
So we all benefit from a stronger,

992
00:41:06,847 --> 00:41:08,453
more secure devices.

993
00:41:09,339 --> 00:41:11,350
And takeaways of the talk,

994
00:41:11,350 --> 00:41:14,050
I said, as we discussed last year,

995
00:41:14,050 --> 00:41:18,750
machine-learning is a way to
automate side-channel attack

996
00:41:18,750 --> 00:41:20,180
and you wish it was the opposite.

997
00:41:20,180 --> 00:41:23,020
So it's really one of the most,

998
00:41:23,020 --> 00:41:24,940
it's at the forefront of
side-channel at attack.

999
00:41:24,940 --> 00:41:29,940
And, this year we flipped
the use case on its head,

1000
00:41:30,060 --> 00:41:32,360
which is really what was
the intent of the project

1001
00:41:32,360 --> 00:41:34,050
from the onset two years ago,

1002
00:41:34,050 --> 00:41:36,310
which is you try to
use all those knowledge

1003
00:41:36,310 --> 00:41:39,758
to actually have developer
building better tooling

1004
00:41:39,758 --> 00:41:41,876
for the to reduce the cost

1005
00:41:41,876 --> 00:41:45,200
of developing secure implementation,
and make them better.

1006
00:41:45,200 --> 00:41:46,100
So that being said,

1007
00:41:46,100 --> 00:41:49,370
this is a very very new
field of exciting field

1008
00:41:49,370 --> 00:41:51,770
with the rough ideas,
rough energy around it.

1009
00:41:51,770 --> 00:41:53,760
And it can really use more interest,

1010
00:41:53,760 --> 00:41:54,730
more people interested in it.

1011
00:41:54,730 --> 00:41:55,960
So if you have some interest

1012
00:41:55,960 --> 00:41:58,353
into crypto or machine-learning,

1013
00:41:58,353 --> 00:42:01,120
it's a great time to get in and work

1014
00:42:01,120 --> 00:42:03,333
with the community on this type of ideas.

1015
00:42:04,650 --> 00:42:06,690
Thank you so much for attending
this (indistinct) talk.

1016
00:42:06,690 --> 00:42:08,090
I wish it would be in person.

1017
00:42:08,090 --> 00:42:09,750
I'm going to miss a DEF CON

1018
00:42:09,750 --> 00:42:11,360
as you will probably do.

1019
00:42:11,360 --> 00:42:13,490
I hope you are well
and that she would like

1020
00:42:13,490 --> 00:42:15,410
to follow up and keep up
with what we're doing.

1021
00:42:15,410 --> 00:42:18,494
We'll try to publish as fast as we can,

1022
00:42:18,494 --> 00:42:22,340
module some delay to
provide you information

1023
00:42:22,340 --> 00:42:26,690
about what we do on side-channel
attacks, on the website.

1024
00:42:26,690 --> 00:42:29,110
And hopefully we'll have
an official project website

1025
00:42:29,110 --> 00:42:30,250
in the future as well.

1026
00:42:30,250 --> 00:42:32,544
Thank you so much for
listening to this talk.

1027
00:42:32,544 --> 00:42:35,210
And then, do not hesitate

1028
00:42:35,210 --> 00:42:36,870
to reach out on Twitter

1029
00:42:36,870 --> 00:42:39,030
or by email or any other means.

1030
00:42:39,030 --> 00:42:41,667
Happy to answer questions,
Thank you so much.

1031
00:42:41,667 --> 00:42:42,500
Bye.

