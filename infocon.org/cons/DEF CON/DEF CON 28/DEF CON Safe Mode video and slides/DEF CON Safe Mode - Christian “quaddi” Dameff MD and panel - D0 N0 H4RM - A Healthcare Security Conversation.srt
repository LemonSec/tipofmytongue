1
00:00:00,120 --> 00:00:02,130
- Welcome DEFCON 28.

2
00:00:02,130 --> 00:00:03,510
The Do No Harm Panel.

3
00:00:03,510 --> 00:00:05,987
This is a healthcare
security conversation.

4
00:00:05,987 --> 00:00:09,741
For the next 45 minutes,
followed by a 45 minute Q and A,

5
00:00:09,741 --> 00:00:12,320
you're gonna hear from some
of the world's top experts

6
00:00:12,320 --> 00:00:15,423
on the healthcare cyber
security space, welcome.

7
00:00:17,320 --> 00:00:18,153
- Thanks, quaddi.

8
00:00:18,153 --> 00:00:19,270
I am r3plicant.

9
00:00:19,270 --> 00:00:20,850
We're gonna get out of the way here,

10
00:00:20,850 --> 00:00:23,460
in just a moment and introduce
you to our panelists.

11
00:00:23,460 --> 00:00:27,160
But obviously, a little bit
different of a venue for us,

12
00:00:27,160 --> 00:00:28,320
than the last couple of years.

13
00:00:28,320 --> 00:00:31,400
We hope that everyone is
staying safe and healthy.

14
00:00:31,400 --> 00:00:32,670
We're thinking of you and look forward to

15
00:00:32,670 --> 00:00:35,163
when we can hang out together, in-person.

16
00:00:36,080 --> 00:00:37,700
Without any further adieu,

17
00:00:37,700 --> 00:00:40,300
I'm gonna let our panelists
take it away and say hi.

18
00:00:42,803 --> 00:00:44,400
- Hi everyone, my name's Ash Luft.

19
00:00:44,400 --> 00:00:47,750
I am a biochemist, a computer scientist

20
00:00:47,750 --> 00:00:49,183
and electrical engineer.

21
00:00:51,640 --> 00:00:55,149
I work at a medical device
firm called Starfish in Canada,

22
00:00:55,149 --> 00:00:57,490
and I'm a software engineer there

23
00:00:57,490 --> 00:01:00,303
and an advocate for security and privacy.

24
00:01:03,180 --> 00:01:04,690
- I think that means that I'm next.

25
00:01:04,690 --> 00:01:07,750
So I don't have a handle, unfortunately.

26
00:01:07,750 --> 00:01:09,830
So I am just Jessica Wilkerson.

27
00:01:09,830 --> 00:01:11,530
I am a cyber policy analyst

28
00:01:11,530 --> 00:01:13,127
with the Food and Drug Administration.

29
00:01:13,127 --> 00:01:15,500
and I work on cyber
cybersecurity policy there

30
00:01:15,500 --> 00:01:17,720
for medical devices.

31
00:01:17,720 --> 00:01:18,680
Some of you may know me

32
00:01:18,680 --> 00:01:20,030
from my previous time with

33
00:01:20,030 --> 00:01:22,440
the United States Congress
Energy and Commerce Committee,

34
00:01:22,440 --> 00:01:26,070
where I worked on
cybersecurity policy for them.

35
00:01:26,070 --> 00:01:27,440
Very nice to talk with everyone.

36
00:01:27,440 --> 00:01:28,330
I'm looking forward to the panel.

37
00:01:28,330 --> 00:01:29,163
Thank you.

38
00:01:33,240 --> 00:01:35,010
- Hi, this is Vee.

39
00:01:35,010 --> 00:01:35,860
Everyone should know me.

40
00:01:35,860 --> 00:01:38,840
The short, the sweet,
the sassy, the spunky.

41
00:01:38,840 --> 00:01:43,000
I am leaving my company for
the world tours in Norway,

42
00:01:43,000 --> 00:01:45,260
we'll be having a whole host of minions

43
00:01:45,260 --> 00:01:47,217
to help me do medical device research.

44
00:01:47,217 --> 00:01:49,340
Currently doing independent research,

45
00:01:49,340 --> 00:01:50,720
informing Tronic,

46
00:01:50,720 --> 00:01:52,550
aiding them to give more visualization

47
00:01:52,550 --> 00:01:54,970
on their products and their security.

48
00:01:54,970 --> 00:01:57,100
I'm an advocate for patient rights,

49
00:01:57,100 --> 00:01:58,890
as well as keeping things safe,

50
00:01:58,890 --> 00:02:01,130
making it, keeping it simple,

51
00:02:01,130 --> 00:02:02,973
keeping it stupid, is my saying.

52
00:02:03,990 --> 00:02:05,977
That's me, short and sweet.

53
00:02:08,460 --> 00:02:09,293
- that leaves me.

54
00:02:09,293 --> 00:02:10,680
My name is Vidya Murthy.

55
00:02:10,680 --> 00:02:13,904
I work for Med Crypt, a
startup in the space of

56
00:02:13,904 --> 00:02:17,220
bringing cyber security
features to medical devices.

57
00:02:17,220 --> 00:02:20,300
I absolutely am passionate
about the subject matter

58
00:02:20,300 --> 00:02:24,210
and think that we're at
an inflection point here,

59
00:02:24,210 --> 00:02:26,053
and there's gonna be a
big amount of change,

60
00:02:26,053 --> 00:02:27,393
as we go forward.

61
00:02:30,350 --> 00:02:32,400
- Well, on behalf of quaddi and myself,

62
00:02:32,400 --> 00:02:33,870
we are just so incredibly grateful

63
00:02:33,870 --> 00:02:36,983
to have an amazing panel, this year.

64
00:02:36,983 --> 00:02:39,320
For those of us who are
joining us for the first time,

65
00:02:39,320 --> 00:02:41,030
and this is kind of one
of the silver linings,

66
00:02:41,030 --> 00:02:43,480
I think about this format
is that, in past years,

67
00:02:43,480 --> 00:02:44,740
we've had folks who wanted to kind of

68
00:02:44,740 --> 00:02:45,810
get in on this conversation

69
00:02:45,810 --> 00:02:47,710
that weren't able to,
due to space constraints.

70
00:02:47,710 --> 00:02:49,282
So we're really thankful
for the opportunity

71
00:02:49,282 --> 00:02:51,460
to have anybody who wants to come in,

72
00:02:51,460 --> 00:02:54,080
listen in and join with
us to be able to do so.

73
00:02:54,080 --> 00:02:56,200
So for those who may not be familiar,

74
00:02:56,200 --> 00:02:57,033
what we're gonna do is,

75
00:02:57,033 --> 00:02:58,436
we're gonna have a
little conversation here,

76
00:02:58,436 --> 00:03:01,860
between the four of
these awesome panelists,

77
00:03:01,860 --> 00:03:03,920
and we're gonna stay out
of it as much as possible,

78
00:03:03,920 --> 00:03:05,880
but get their insights and kind of

79
00:03:05,880 --> 00:03:08,230
what their thought processes are.

80
00:03:08,230 --> 00:03:10,040
Some of the things we've been
seeing in the space lately,

81
00:03:10,040 --> 00:03:11,930
and then part of this session will be

82
00:03:11,930 --> 00:03:15,740
a live Q and A follow-up
conversation, afterwards.

83
00:03:15,740 --> 00:03:19,220
So we don't really have a
formal set of questions,

84
00:03:19,220 --> 00:03:22,160
like most of these kind
of more rigid panels do,

85
00:03:22,160 --> 00:03:24,160
but I do wanna kind of start off

86
00:03:24,160 --> 00:03:25,530
on a little bit of a brighter note.

87
00:03:25,530 --> 00:03:26,760
I think some of the times that we've

88
00:03:26,760 --> 00:03:28,988
had this event in past years,

89
00:03:28,988 --> 00:03:31,980
we spend about 45 minutes talking,

90
00:03:31,980 --> 00:03:34,900
the term dumpster fire
comes up, not infrequently.

91
00:03:34,900 --> 00:03:37,080
Then at the end we try and
push a little optimism,

92
00:03:37,080 --> 00:03:40,140
because there really
is a lot to be sort of

93
00:03:40,140 --> 00:03:41,550
hopeful about in large part,

94
00:03:41,550 --> 00:03:43,840
because of the types of
things that we're able to do,

95
00:03:43,840 --> 00:03:44,780
at places like DEFCON.

96
00:03:44,780 --> 00:03:47,089
But I wanna kind of start off this time,

97
00:03:47,089 --> 00:03:49,367
upfront by asking each of our panelists,

98
00:03:49,367 --> 00:03:52,389
what are some developments lately,

99
00:03:52,389 --> 00:03:54,820
that have helped make you feel

100
00:03:54,820 --> 00:03:56,250
particularly hopeful or optimistic

101
00:03:56,250 --> 00:03:58,370
about where we're heading
in healthcare security,

102
00:03:58,370 --> 00:04:00,880
before we get into some of the
challenges that still remain?

103
00:04:00,880 --> 00:04:02,860
So kind of toss it back to our panel

104
00:04:02,860 --> 00:04:05,313
for us to get a little dose of optimism.

105
00:04:06,970 --> 00:04:11,360
- Yeah, so I think I'm looking
at this year in particular,

106
00:04:11,360 --> 00:04:13,890
we've seen more and more devices
going home with patients.

107
00:04:13,890 --> 00:04:16,350
We've seen hospitals go online,

108
00:04:16,350 --> 00:04:18,630
in a way that they've never planned to

109
00:04:18,630 --> 00:04:20,860
in 10 years from now, right?

110
00:04:20,860 --> 00:04:24,420
I think the notion that we can now

111
00:04:24,420 --> 00:04:27,250
build security into is a need to

112
00:04:27,250 --> 00:04:28,680
let patients have confidence

113
00:04:28,680 --> 00:04:30,790
and them operating from their homes,

114
00:04:30,790 --> 00:04:32,620
is something that seems to be top of mind

115
00:04:32,620 --> 00:04:34,520
for folks in actual common practice.

116
00:04:34,520 --> 00:04:38,880
So it feels like a
confluence of various factors

117
00:04:38,880 --> 00:04:41,380
that are coming together
at just the right moment.

118
00:04:41,380 --> 00:04:43,415
So you have this push of
devices leaving the hospital.

119
00:04:43,415 --> 00:04:47,730
We have this push of device
vendors really getting into

120
00:04:47,730 --> 00:04:49,527
the narrative more than ever before.

121
00:04:49,527 --> 00:04:52,380
This collaboration like
DEFCON brings together

122
00:04:52,380 --> 00:04:56,890
with researchers and devices themselves.

123
00:04:56,890 --> 00:04:58,040
I just I have a lot of hope

124
00:04:58,040 --> 00:05:00,480
that this year has the momentum behind it

125
00:05:00,480 --> 00:05:02,970
to really get this to
stick and have the forces

126
00:05:02,970 --> 00:05:05,520
that are really gonna make
this last in the future.

127
00:05:09,974 --> 00:05:11,393
- Yeah.
- Yeah.

128
00:05:11,393 --> 00:05:13,660
Yeah, so I echo that,

129
00:05:13,660 --> 00:05:16,372
but I've also seen this big
push over the past two years,

130
00:05:16,372 --> 00:05:18,240
where you could not even have

131
00:05:18,240 --> 00:05:20,280
a conversation with a manufacturer.

132
00:05:20,280 --> 00:05:21,630
It was a brick wall.

133
00:05:21,630 --> 00:05:23,370
This year we're having conversations.

134
00:05:23,370 --> 00:05:24,951
This year, we invited to the table,

135
00:05:24,951 --> 00:05:28,270
hackers are now no longer the criminals

136
00:05:28,270 --> 00:05:30,830
that are lurking in the darkness.

137
00:05:30,830 --> 00:05:32,513
We've brought things to light.

138
00:05:32,513 --> 00:05:35,703
We're having difficult
conversations, but we're having them.

139
00:05:35,703 --> 00:05:39,230
I think that's a major push
forward, but except for that,

140
00:05:39,230 --> 00:05:41,213
we now having developers and engineers

141
00:05:41,213 --> 00:05:43,030
think more security-wise,

142
00:05:43,030 --> 00:05:44,596
we started to change the cultures

143
00:05:44,596 --> 00:05:49,596
of working in silos, to start
working as a collective.

144
00:05:49,640 --> 00:05:52,160
One example that I've seen is the way that

145
00:05:52,160 --> 00:05:53,610
the community has jumped in with

146
00:05:53,610 --> 00:05:56,413
the 3-D printing PPE mask making.

147
00:05:57,310 --> 00:05:59,610
Supporting medical people
really (indistinct).

148
00:06:00,480 --> 00:06:02,220
I mean, even the CTI lead gets

149
00:06:02,220 --> 00:06:07,220
protecting hospitals around the
globe, from cyber criminals.

150
00:06:07,460 --> 00:06:09,990
I mean, that is just a
collective pool of humanity

151
00:06:09,990 --> 00:06:11,560
showing that if we work together,

152
00:06:11,560 --> 00:06:15,550
we can change the world
one byte at a time.

153
00:06:15,550 --> 00:06:18,090
What do you think, Jessica?

154
00:06:18,090 --> 00:06:19,743
- Well, I liked the prompt.

155
00:06:21,240 --> 00:06:23,550
I mean, I think I started working on

156
00:06:23,550 --> 00:06:24,900
healthcare cybersecurity issues,

157
00:06:24,900 --> 00:06:28,410
I think right around 2015, 2016 timeframe.

158
00:06:28,410 --> 00:06:29,490
At that point,

159
00:06:29,490 --> 00:06:30,610
obviously I was working on them

160
00:06:30,610 --> 00:06:33,013
for the United States Congress.

161
00:06:33,859 --> 00:06:36,270
It was just an entirely
different conversation.

162
00:06:36,270 --> 00:06:38,430
I mean, the things that
we were talking about,

163
00:06:38,430 --> 00:06:42,740
like the had said about let's
bring in security researchers,

164
00:06:42,740 --> 00:06:44,680
let's have them be part
of the conversation.

165
00:06:44,680 --> 00:06:47,780
They have valuable experience
and things to contribute.

166
00:06:47,780 --> 00:06:50,060
That was just such a nonstarter.

167
00:06:50,060 --> 00:06:51,170
You had all these manufacturers

168
00:06:51,170 --> 00:06:53,600
who absolutely were never gonna do that.

169
00:06:53,600 --> 00:06:55,470
That was completely unacceptable.

170
00:06:55,470 --> 00:06:57,990
We are still in some cases

171
00:06:57,990 --> 00:07:00,310
getting asked for help by
the manufacturers essentially

172
00:07:00,310 --> 00:07:03,453
to be like, can you make
this problem go away?

173
00:07:04,970 --> 00:07:06,474
There were just other policy issues.

174
00:07:06,474 --> 00:07:08,621
That have come up over the years,

175
00:07:08,621 --> 00:07:11,230
I work a lot on legacy device issues.

176
00:07:11,230 --> 00:07:13,810
I work a lot on software
transparency issues

177
00:07:14,780 --> 00:07:18,830
and they always started out
as this is never gonna happen.

178
00:07:18,830 --> 00:07:20,040
We're never gonna be able to do this.

179
00:07:20,040 --> 00:07:22,043
The industry will never accept this.

180
00:07:23,220 --> 00:07:26,660
In 2020, it's completely different.

181
00:07:26,660 --> 00:07:28,240
I work on those issues every day.

182
00:07:28,240 --> 00:07:31,230
They are starting to be
operationalized security.

183
00:07:31,230 --> 00:07:33,540
Researchers are a huge
part of medical device

184
00:07:33,540 --> 00:07:36,030
and healthcare cyber security overall.

185
00:07:36,030 --> 00:07:38,243
We've definitely made so much progress.

186
00:07:39,192 --> 00:07:41,150
We've made the progress in such a way

187
00:07:41,150 --> 00:07:42,980
that it has its own momentum now,

188
00:07:42,980 --> 00:07:44,760
it's gonna carry itself through.

189
00:07:44,760 --> 00:07:46,920
I just think that that
really can't be overstated,

190
00:07:46,920 --> 00:07:47,970
how valuable that is.

191
00:07:50,340 --> 00:07:52,420
- Yeah, so I agree with
what everyone said.

192
00:07:52,420 --> 00:07:57,270
I would say that I think
one of the biggest things

193
00:07:57,270 --> 00:07:58,810
I've noticed over the last five, 10 years,

194
00:07:58,810 --> 00:08:01,020
is the people so community

195
00:08:01,020 --> 00:08:03,460
and like the number of people
sort of coming together,

196
00:08:03,460 --> 00:08:04,890
there seems to be lots of different

197
00:08:04,890 --> 00:08:06,890
groups and organizations popping up,

198
00:08:06,890 --> 00:08:08,753
like even the last couple of years,

199
00:08:08,753 --> 00:08:11,484
advocacy groups, people working together.

200
00:08:11,484 --> 00:08:13,810
Yeah, medical device manufacturers.

201
00:08:13,810 --> 00:08:17,210
I mean, even when I five years ago,

202
00:08:17,210 --> 00:08:18,770
started having these conversations

203
00:08:18,770 --> 00:08:21,428
and asking questions about
security and privacy,

204
00:08:21,428 --> 00:08:24,380
it was harder to find other people

205
00:08:24,380 --> 00:08:28,030
to even have a discussion
with about these things.

206
00:08:28,030 --> 00:08:30,670
Now it just seems like
there's this momentum

207
00:08:30,670 --> 00:08:31,760
that's really building.

208
00:08:31,760 --> 00:08:35,122
The number of people who are engaged

209
00:08:35,122 --> 00:08:36,410
and wanna make a difference

210
00:08:36,410 --> 00:08:39,140
and wanna be a part of the
conversation, is growing.

211
00:08:39,140 --> 00:08:40,850
I see that as a huge positive thing.

212
00:08:40,850 --> 00:08:42,740
'Cause realistically, like the more people

213
00:08:42,740 --> 00:08:45,373
that we have participating
in the conversation,

214
00:08:45,373 --> 00:08:48,040
the more action that we're gonna be able

215
00:08:48,040 --> 00:08:49,683
to take sooner and faster.

216
00:08:51,770 --> 00:08:54,790
- Yeah, I think one of the big things also

217
00:08:54,790 --> 00:08:56,110
as we see physicians

218
00:08:56,110 --> 00:08:59,120
coming to the table and
wanting to learn more

219
00:08:59,120 --> 00:09:02,940
about the devices they
have and work with, right?

220
00:09:02,940 --> 00:09:05,560
It's not just the CTI people driving

221
00:09:05,560 --> 00:09:08,417
policy driving and I think
the (indistinct) industry's

222
00:09:08,417 --> 00:09:09,988
come back and saying,

223
00:09:09,988 --> 00:09:13,310
how can we make this
better for our patients?

224
00:09:13,310 --> 00:09:14,593
Because in the end,

225
00:09:14,593 --> 00:09:16,280
I think every physician wants to make it

226
00:09:16,280 --> 00:09:18,173
safer for their patients.

227
00:09:19,520 --> 00:09:21,600
That's a big thing to me
that I've seen this year

228
00:09:21,600 --> 00:09:24,137
is the physicians tending
to the table saying,

229
00:09:24,137 --> 00:09:26,300
"Well, how can we learn more?

230
00:09:26,300 --> 00:09:31,300
How do we translate this to our patients

231
00:09:31,390 --> 00:09:33,227
in a way that they understand?"

232
00:09:36,090 --> 00:09:37,990
- Yeah, I think-
- Yeah, I think, oh.

233
00:09:38,950 --> 00:09:41,130
I love conference calls.

234
00:09:41,130 --> 00:09:45,870
I was gonna say, I'd really I'd echo that,

235
00:09:45,870 --> 00:09:49,463
because I think, even going
beyond patients and things,

236
00:09:50,318 --> 00:09:54,750
one of the things that my boss
is really quite insistent on,

237
00:09:54,750 --> 00:09:57,010
and you probably all know Suzanne Schwartz

238
00:09:57,010 --> 00:10:00,640
one way or another, is
the shared responsibility

239
00:10:00,640 --> 00:10:02,770
of the healthcare sector where,

240
00:10:02,770 --> 00:10:05,070
even we are the Food
and Drug Administration.

241
00:10:05,070 --> 00:10:06,280
We can only do so much.

242
00:10:06,280 --> 00:10:09,050
We have jurisdiction
over the medical device.

243
00:10:09,050 --> 00:10:10,930
We don't have jurisdiction
over hospital networks.

244
00:10:10,930 --> 00:10:13,608
We don't have jurisdiction
over other parts of it

245
00:10:13,608 --> 00:10:17,580
that, sometimes that
are certainly implicated

246
00:10:17,580 --> 00:10:19,233
in cybersecurity concerns.

247
00:10:20,772 --> 00:10:23,927
So, there's traditionally been a very

248
00:10:25,600 --> 00:10:27,730
fraught relationship between, for example,

249
00:10:27,730 --> 00:10:29,060
medical device manufacturers

250
00:10:29,060 --> 00:10:31,040
and healthcare delivery organizations.

251
00:10:31,040 --> 00:10:32,793
So hospitals and others.

252
00:10:34,190 --> 00:10:37,190
What I started to see and
have personally experienced

253
00:10:37,190 --> 00:10:38,730
over the last couple of years,

254
00:10:38,730 --> 00:10:41,810
is a greater and greater
breakdown of the barriers

255
00:10:41,810 --> 00:10:43,000
between those two groups.

256
00:10:43,000 --> 00:10:46,362
So with some of the
partnership groups that exist,

257
00:10:46,362 --> 00:10:49,190
I spend a lot of time working
with the healthcare sector,

258
00:10:49,190 --> 00:10:50,310
coordinating council.

259
00:10:50,310 --> 00:10:53,010
For example, you have
hospital (indistinct)

260
00:10:53,010 --> 00:10:54,190
who are on the phone every day with

261
00:10:54,190 --> 00:10:55,730
global product security officers

262
00:10:55,730 --> 00:10:57,216
at medical device companies.

263
00:10:57,216 --> 00:10:59,430
They're just having conversations.

264
00:10:59,430 --> 00:11:00,910
I mean, sometimes they're
just shooting the shit

265
00:11:00,910 --> 00:11:03,480
and sometimes they're actually
talking about work stuff,

266
00:11:03,480 --> 00:11:06,180
but like those relationships being there

267
00:11:06,180 --> 00:11:10,470
and being already established
are just so meaningful

268
00:11:10,470 --> 00:11:13,280
and the progress in the sector

269
00:11:13,280 --> 00:11:15,788
to be made so much faster and problems

270
00:11:15,788 --> 00:11:16,830
will be addressed so much quicker.

271
00:11:16,830 --> 00:11:19,360
So I would echo what Vee said about,

272
00:11:19,360 --> 00:11:22,581
we're having almost new
entrance into the conversation.

273
00:11:22,581 --> 00:11:25,123
That's letting the
conversation really take off.

274
00:11:27,150 --> 00:11:28,883
- I wanna kind of say-
- Sorry.

275
00:11:30,050 --> 00:11:31,310
Go ahead, Christian.

276
00:11:31,310 --> 00:11:33,279
- I just wanna say these
are all fantastic insights.

277
00:11:33,279 --> 00:11:36,370
I love to hear the optimism around

278
00:11:36,370 --> 00:11:37,980
how the conversation's changed,

279
00:11:37,980 --> 00:11:40,730
because every year when
we have this event,

280
00:11:40,730 --> 00:11:44,060
we undoubtedly have to talk about an event

281
00:11:44,060 --> 00:11:46,020
that's happened during the year,

282
00:11:46,020 --> 00:11:47,330
whether or not it's WannaCry,

283
00:11:47,330 --> 00:11:49,980
or whether or not it's
a security researcher

284
00:11:49,980 --> 00:11:53,045
that's been shunned or threatened
by a device manufacturer

285
00:11:53,045 --> 00:11:55,930
for I think I can say
this is the first year

286
00:11:55,930 --> 00:11:59,670
where I have not been publicly
aware of such an event.

287
00:11:59,670 --> 00:12:02,190
So I think that's really proved

288
00:12:02,190 --> 00:12:03,180
to what everyone's saying here

289
00:12:03,180 --> 00:12:06,430
is at least part of the interaction

290
00:12:06,430 --> 00:12:09,070
with hackers has changed.

291
00:12:09,070 --> 00:12:10,370
Now whether or not that'll stick,

292
00:12:10,370 --> 00:12:12,000
or whether or not this
is just an off year,

293
00:12:12,000 --> 00:12:13,140
I think we'll have to see.

294
00:12:13,140 --> 00:12:16,270
But when we have strong
partners in this space,

295
00:12:16,270 --> 00:12:18,700
hackers coming together with
healthcare organizations

296
00:12:18,700 --> 00:12:20,350
and device manufacturers,

297
00:12:20,350 --> 00:12:25,090
welcoming their
collaboration, everyone wins.

298
00:12:25,090 --> 00:12:27,060
That's really what makes patients safer

299
00:12:27,060 --> 00:12:28,620
at the end of the day.

300
00:12:28,620 --> 00:12:30,830
I wanted to just also say though,

301
00:12:30,830 --> 00:12:32,080
a lot of what was discussed

302
00:12:32,080 --> 00:12:34,630
is this is optimism around.

303
00:12:34,630 --> 00:12:36,580
This is a great year.

304
00:12:36,580 --> 00:12:38,710
It's also a horrible year.

305
00:12:38,710 --> 00:12:41,590
COVID and 2020 is one
I would love to forget.

306
00:12:41,590 --> 00:12:44,020
There are so many things about this year

307
00:12:44,020 --> 00:12:46,030
that have absolutely sucked.

308
00:12:46,030 --> 00:12:47,600
One of the things that's been voiced to me

309
00:12:47,600 --> 00:12:49,780
by a variety of people is,

310
00:12:49,780 --> 00:12:52,040
how is COVID going to impact this?

311
00:12:52,040 --> 00:12:54,380
How is COVID gonna impact hackers,

312
00:12:54,380 --> 00:12:57,250
security researchers,
security professionals,

313
00:12:57,250 --> 00:13:00,598
and the momentum that we have made,

314
00:13:00,598 --> 00:13:02,860
because there's legitimate concern.

315
00:13:02,860 --> 00:13:06,960
I feel that a lot of security work,

316
00:13:06,960 --> 00:13:10,062
a lot of securing these
types of spaces cost money,

317
00:13:10,062 --> 00:13:12,130
and how a lot of that money

318
00:13:12,130 --> 00:13:14,507
is being sucked from what
would be security budgets

319
00:13:14,507 --> 00:13:16,674
into responding to COVID.

320
00:13:16,674 --> 00:13:18,200
As a consequence,

321
00:13:18,200 --> 00:13:22,230
do you people here think
we're gonna see a regression?

322
00:13:22,230 --> 00:13:23,750
We've made 10 steps forward.

323
00:13:23,750 --> 00:13:25,280
Are we gonna go five steps back,

324
00:13:25,280 --> 00:13:28,300
because COVID really stopped it.

325
00:13:28,300 --> 00:13:29,440
It stopped the momentum.

326
00:13:29,440 --> 00:13:31,090
Love to hear your guys' thoughts.

327
00:13:33,030 --> 00:13:35,593
- So I'll start, sorry Vidya.

328
00:13:37,430 --> 00:13:39,990
I think it's broken the barometer, right?

329
00:13:39,990 --> 00:13:44,703
It's forced us to pull
up our socks, right?

330
00:13:45,876 --> 00:13:46,709
The healthcare barometer

331
00:13:46,709 --> 00:13:48,890
is now no longer within your hospital.

332
00:13:48,890 --> 00:13:50,593
You have patients at varied areas

333
00:13:50,593 --> 00:13:53,240
and everything's different,

334
00:13:53,240 --> 00:13:56,200
but I don't necessarily
think taking 10 steps back

335
00:13:56,200 --> 00:13:58,430
is a bad thing.

336
00:13:58,430 --> 00:14:00,623
This year, has given us time to assess,

337
00:14:01,500 --> 00:14:03,720
time to view the healthcare scene,

338
00:14:03,720 --> 00:14:06,120
the medical devices, and if anything,

339
00:14:06,120 --> 00:14:09,800
forces us to slow down and observe

340
00:14:11,210 --> 00:14:15,240
and just take note of
what's happening, right?

341
00:14:15,240 --> 00:14:18,650
I see hospitals crumbling
underneath a pandemic,

342
00:14:18,650 --> 00:14:22,120
which is something that their function

343
00:14:22,120 --> 00:14:24,690
is to care for patients.

344
00:14:24,690 --> 00:14:29,690
We see that even the biggest
hospitals are struggling

345
00:14:30,960 --> 00:14:32,560
and that perhaps we just need to

346
00:14:32,560 --> 00:14:35,854
take a step back and re-build.

347
00:14:35,854 --> 00:14:38,580
Maybe 2021 could be the year that

348
00:14:38,580 --> 00:14:40,100
we build things better,

349
00:14:40,100 --> 00:14:42,630
instead of trying to slap a Bandaid on.

350
00:14:42,630 --> 00:14:44,780
We do things right and
we do things better,

351
00:14:46,870 --> 00:14:48,033
from the ground up.

352
00:14:50,120 --> 00:14:53,390
- Yeah, I love that notion of
taking the time to rebuild.

353
00:14:53,390 --> 00:14:57,420
I mean, we've seen where
healthcare facilities

354
00:14:57,420 --> 00:14:58,850
have already been compromised,

355
00:14:58,850 --> 00:15:00,320
before they saw their first patient

356
00:15:00,320 --> 00:15:03,986
as part of trying to
meet the need for COVID.

357
00:15:03,986 --> 00:15:05,360
Well, one of the things I worry about,

358
00:15:05,360 --> 00:15:08,320
is in some sense, I think
there's this urgency

359
00:15:08,320 --> 00:15:10,270
from a clinical perspective
to get devices out

360
00:15:10,270 --> 00:15:11,960
to patients and then kind of solve

361
00:15:11,960 --> 00:15:14,470
some of the medical problems,

362
00:15:14,470 --> 00:15:17,390
as that resulted in these devices,

363
00:15:17,390 --> 00:15:21,050
having security measures
that were intentionally

364
00:15:21,050 --> 00:15:23,470
not so robustly built
in from the beginning,

365
00:15:23,470 --> 00:15:25,479
just so they could get out

366
00:15:25,479 --> 00:15:26,870
and treat these patients,
and what do you do now?

367
00:15:26,870 --> 00:15:28,740
Right, can you walk that back?

368
00:15:28,740 --> 00:15:30,710
Can you say, "Hey, give all
those devices back to us.

369
00:15:30,710 --> 00:15:32,661
We don't wanna necessarily see it?"

370
00:15:32,661 --> 00:15:35,920
So I think your point of needing to build

371
00:15:35,920 --> 00:15:37,650
from the beginning is absolutely heard.

372
00:15:37,650 --> 00:15:40,910
But I wonder if you're
realistically able to

373
00:15:40,910 --> 00:15:43,603
call pause on the care
that's already out there.

374
00:15:44,560 --> 00:15:45,470
- Oh no.

375
00:15:45,470 --> 00:15:48,850
I mean, I always refer to it
as the legacy problem, right?

376
00:15:48,850 --> 00:15:51,900
Literally it's a sea of devices after.

377
00:15:51,900 --> 00:15:53,857
I mean, if you look at
the number of devices

378
00:15:53,857 --> 00:15:55,580
out there every year,

379
00:15:55,580 --> 00:15:57,480
it just increases exponentially.

380
00:15:57,480 --> 00:16:00,110
I mean, the maths blows my head.

381
00:16:00,110 --> 00:16:01,490
I sat into that the other day,

382
00:16:01,490 --> 00:16:04,776
knowing, well, how do we solve this?

383
00:16:04,776 --> 00:16:07,060
I think one of the solutions

384
00:16:07,060 --> 00:16:09,720
is to do things going better forward,

385
00:16:09,720 --> 00:16:12,786
is not to introduce new
devices with the same flaws

386
00:16:12,786 --> 00:16:15,873
and the same vulnerabilities
and adding to our problem,

387
00:16:15,873 --> 00:16:19,970
because those devices will
knowing if you take an ICD,

388
00:16:19,970 --> 00:16:23,090
for example, can last
in excess of a decade.

389
00:16:23,090 --> 00:16:24,650
If that's 600,000 devices

390
00:16:24,650 --> 00:16:29,650
implanted a year lasting 10 years,

391
00:16:29,960 --> 00:16:33,770
it is an ocean that you find to boil.

392
00:16:33,770 --> 00:16:35,687
You can't necessarily say to someone,

393
00:16:35,687 --> 00:16:37,570
"Hey, I need some catheter device,

394
00:16:37,570 --> 00:16:39,070
'cause it's got a flaw in it.

395
00:16:39,070 --> 00:16:42,053
My device has got a flaw
in that I'm fully aware of.

396
00:16:43,171 --> 00:16:45,775
But what are the options?

397
00:16:45,775 --> 00:16:50,510
I have to go for 10 years
license until it's made better."

398
00:16:50,510 --> 00:16:51,390
But these devices,

399
00:16:51,390 --> 00:16:56,390
were not built with a security
as a functional requirement.

400
00:16:56,450 --> 00:16:58,223
Okay, it's a technical requirement.

401
00:16:58,223 --> 00:17:01,210
I think if we start
shifting and start building

402
00:17:01,210 --> 00:17:03,661
and designing with security in mind,

403
00:17:03,661 --> 00:17:06,770
we can start addressing
the problem forward,

404
00:17:06,770 --> 00:17:08,492
in terms of the legacy problem.

405
00:17:08,492 --> 00:17:10,747
I actually don't have.

406
00:17:10,747 --> 00:17:13,240
I don't know how to boil that ocean,

407
00:17:13,240 --> 00:17:14,563
to be honest with you.

408
00:17:17,280 --> 00:17:19,550
- Yeah, I like what everyone was saying.

409
00:17:19,550 --> 00:17:23,130
I liked the idea of being able to rebuild

410
00:17:23,130 --> 00:17:25,380
and taking a step back to think about

411
00:17:25,380 --> 00:17:26,880
how we wanna solve some of these problems.

412
00:17:26,880 --> 00:17:29,040
I think that in practice,

413
00:17:29,040 --> 00:17:31,870
it's really hard again with the clinical

414
00:17:31,870 --> 00:17:33,480
looking at the clinical perspective.

415
00:17:33,480 --> 00:17:34,400
Like right now,

416
00:17:34,400 --> 00:17:37,800
we're working on trying to create

417
00:17:37,800 --> 00:17:41,290
a massive number of
respirators and ventilators

418
00:17:43,360 --> 00:17:46,000
in a short period of
time and make them safe

419
00:17:46,000 --> 00:17:47,250
and make them functional.

420
00:17:48,990 --> 00:17:51,480
How much security, like if it costs more

421
00:17:51,480 --> 00:17:53,720
and it takes more time
to add the security,

422
00:17:53,720 --> 00:17:54,833
it's hard to make the argument.

423
00:17:54,833 --> 00:17:57,857
like, what's more important?

424
00:17:57,857 --> 00:18:02,190
If people are dying and
it's literally minutes,

425
00:18:02,190 --> 00:18:03,323
hours makes a difference,

426
00:18:03,323 --> 00:18:05,160
between life or death and you could get

427
00:18:05,160 --> 00:18:07,670
one more ventilator into a room.

428
00:18:07,670 --> 00:18:11,870
If it took an extra two days even day to,

429
00:18:11,870 --> 00:18:13,480
add security, let's just say

430
00:18:13,480 --> 00:18:18,480
for the sake of this
problem, is that worth it?

431
00:18:18,860 --> 00:18:23,810
Whose lives should we
sacrifice to add the security?

432
00:18:23,810 --> 00:18:26,170
Like, it's tough.

433
00:18:26,170 --> 00:18:28,860
I don't know how we can
sort of push for that

434
00:18:28,860 --> 00:18:32,410
and where we draw the line in practice.

435
00:18:32,410 --> 00:18:33,773
- It's a bad thing.
- I think.

436
00:18:35,150 --> 00:18:37,360
- Sorry, Jessica.
- No, no.

437
00:18:37,360 --> 00:18:38,350
I was just gonna say,

438
00:18:38,350 --> 00:18:41,160
I think the way that we
have certain experience

439
00:18:41,160 --> 00:18:44,510
at the FDA, is we're
doing things in parallel.

440
00:18:44,510 --> 00:18:47,430
So I have been very
blessed in my time at FDA

441
00:18:48,490 --> 00:18:52,203
not to have been fully pulled
into the COVID response,

442
00:18:53,230 --> 00:18:56,383
but I'm still 100% on cybersecurity.

443
00:18:57,850 --> 00:18:59,170
Essentially, what that's allowed us to do

444
00:18:59,170 --> 00:19:02,300
is while a significant
portion of the agency

445
00:19:02,300 --> 00:19:04,590
is all in on COVID and then figuring out

446
00:19:04,590 --> 00:19:06,330
what they need to do and
doing some of the things

447
00:19:06,330 --> 00:19:07,750
exactly what you all are saying,

448
00:19:07,750 --> 00:19:10,065
getting devices to patients who need them.

449
00:19:10,065 --> 00:19:14,250
We also still have a very
dedicated team at FDA,

450
00:19:14,250 --> 00:19:16,173
looking at cyber security.

451
00:19:17,500 --> 00:19:18,635
Another thing that I was really lucky

452
00:19:18,635 --> 00:19:21,575
when I came into FDA, I think everybody,

453
00:19:21,575 --> 00:19:24,391
elementary school feels
like a bajillion years ago,

454
00:19:24,391 --> 00:19:27,320
but like you'd walk into elementary school

455
00:19:27,320 --> 00:19:28,570
and there's that one person there

456
00:19:28,570 --> 00:19:30,700
that who's just like, "We're
gonna be best friends.

457
00:19:30,700 --> 00:19:33,250
We're gonna do great things together."

458
00:19:33,250 --> 00:19:36,210
For those of you who have
not met Matt Hayzlett,

459
00:19:36,210 --> 00:19:38,020
he probably is like sick
of me talking about him.

460
00:19:38,020 --> 00:19:40,710
But anyway, Matt Hayzlett is great.

461
00:19:40,710 --> 00:19:44,200
He is essentially the
one of the leads at FDA

462
00:19:44,200 --> 00:19:48,830
for doing cybersecurity reviews
of devices as they come in.

463
00:19:48,830 --> 00:19:50,920
So at the same time that all of this

464
00:19:50,920 --> 00:19:52,340
is going on with COVID

465
00:19:52,340 --> 00:19:54,980
what Matt and his team within

466
00:19:54,980 --> 00:19:56,680
the device review office of the FDA

467
00:19:56,680 --> 00:19:57,775
have really started doing,

468
00:19:57,775 --> 00:20:00,130
is they're getting tighter
and tighter and tighter

469
00:20:00,130 --> 00:20:03,520
and tighter and looking at
exactly what you all are saying.

470
00:20:03,520 --> 00:20:06,840
We're learning so many
lessons from deployed devices

471
00:20:06,840 --> 00:20:09,310
about vulnerabilities that are showing up.

472
00:20:09,310 --> 00:20:11,860
We're learning so much
about what manufacturers

473
00:20:11,860 --> 00:20:14,291
maybe aren't doing on the front end,

474
00:20:14,291 --> 00:20:16,285
that are causing problems on the back end

475
00:20:16,285 --> 00:20:19,060
and what Matt and his
team have really been able

476
00:20:19,060 --> 00:20:20,713
to do is they're taking
all of those things.

477
00:20:20,713 --> 00:20:22,063
They're taking the vulnerabilities

478
00:20:22,063 --> 00:20:23,670
that are showing up in post-market,

479
00:20:23,670 --> 00:20:28,510
they're taking the missing
pieces of the process,

480
00:20:28,510 --> 00:20:29,730
the gaps in the process,

481
00:20:29,730 --> 00:20:31,713
in the development of medical devices.

482
00:20:31,713 --> 00:20:34,420
They're putting that into
the pre-market review process

483
00:20:34,420 --> 00:20:35,407
where they're essentially saying,

484
00:20:35,407 --> 00:20:38,799
"Okay, we are learning every day,

485
00:20:38,799 --> 00:20:41,140
how to get better at reviewing devices

486
00:20:41,140 --> 00:20:43,240
and they're implementing it.

487
00:20:43,240 --> 00:20:46,983
So I think, you know, while
we're certainly seeing.

488
00:20:49,345 --> 00:20:54,120
There's just this very valid urgency

489
00:20:54,120 --> 00:20:57,243
about getting devices out
where they need to be.

490
00:20:58,210 --> 00:21:02,400
We also still have this
very robust mechanism at FDA

491
00:21:02,400 --> 00:21:05,170
in particular for making sure that

492
00:21:05,170 --> 00:21:06,380
anything that we're learning,

493
00:21:06,380 --> 00:21:08,770
anything that's coming up
with regard to cybersecurity

494
00:21:08,770 --> 00:21:11,383
is actually making it
back into our process.

495
00:21:15,760 --> 00:21:17,393
- Yeah, which the one thing I would say,

496
00:21:17,393 --> 00:21:18,720
I think the financial,

497
00:21:18,720 --> 00:21:19,890
which was the original question, right?

498
00:21:19,890 --> 00:21:22,380
What's the financial
drain gonna have an impact

499
00:21:22,380 --> 00:21:23,213
on these devices?

500
00:21:23,213 --> 00:21:24,220
I think that's exactly,

501
00:21:24,220 --> 00:21:25,800
there's almost a compliment there, right?

502
00:21:25,800 --> 00:21:28,450
If we can get the financial decisions

503
00:21:28,450 --> 00:21:30,940
to be informed by what the pre-market

504
00:21:30,940 --> 00:21:32,110
is telling us in terms of

505
00:21:32,110 --> 00:21:33,700
meeting certain security requirements

506
00:21:33,700 --> 00:21:35,710
and really having that be key criteria

507
00:21:35,710 --> 00:21:38,790
in decisions and not just no
offense to the clinicians,

508
00:21:38,790 --> 00:21:40,486
the clinician really likes this one brand.

509
00:21:40,486 --> 00:21:41,900
That's what they're going with.

510
00:21:41,900 --> 00:21:44,430
Having it be part of that core decision,

511
00:21:44,430 --> 00:21:47,263
I think absolutely will drive that change.

512
00:21:49,010 --> 00:21:50,670
- My only decision about whether or not

513
00:21:50,670 --> 00:21:53,960
I use a device is how many
5G microchips I can inject

514
00:21:53,960 --> 00:21:55,862
into the patient.
(laughing)

515
00:21:55,862 --> 00:21:58,727
- Wait doesn't that have to say AI in it?

516
00:21:58,727 --> 00:22:00,147
(laughing)
- No, that's the

517
00:22:00,147 --> 00:22:01,570
(indistinct) version.

518
00:22:01,570 --> 00:22:03,470
- This is being recorded, man.

519
00:22:03,470 --> 00:22:05,530
That is gonna be, that
was gonna be clipped.

520
00:22:05,530 --> 00:22:07,250
That is gonna be taken out of context.

521
00:22:07,250 --> 00:22:09,150
It's gonna be viral on Twitter

522
00:22:09,150 --> 00:22:10,789
in the next couple of days.

523
00:22:10,789 --> 00:22:12,880
We're gonna hear about how doctors

524
00:22:12,880 --> 00:22:14,500
are part of the 5G conspiracy.

525
00:22:14,500 --> 00:22:17,203
So strong work on that one.

526
00:22:18,040 --> 00:22:19,823
- Yeah, well done.

527
00:22:20,740 --> 00:22:22,600
What I did wanna ask, right,

528
00:22:22,600 --> 00:22:23,433
so I'm gonna turn it,

529
00:22:23,433 --> 00:22:25,790
I wanna ask Christian and Jeff a question,

530
00:22:25,790 --> 00:22:27,870
seeing, as we're being grilled here.

531
00:22:29,000 --> 00:22:30,473
You have clinicians, right?

532
00:22:32,022 --> 00:22:32,855
When you are doing,

533
00:22:32,855 --> 00:22:34,420
making a decision for your patient, right,

534
00:22:34,420 --> 00:22:39,420
in security versus clinical functionality,

535
00:22:39,500 --> 00:22:41,030
how do you deal with that balancing act?

536
00:22:41,030 --> 00:22:44,140
'Cause you guys are
fortunate as physicians

537
00:22:44,140 --> 00:22:46,380
to have your feet in both worlds.

538
00:22:46,380 --> 00:22:49,120
So from your perspective,
how do you balance it out?

539
00:22:49,120 --> 00:22:52,470
How do you work it out in your mind?

540
00:22:52,470 --> 00:22:56,110
Because for us, it is
security first and foremost

541
00:22:56,110 --> 00:22:58,811
and patient care where
we almost moved from

542
00:22:58,811 --> 00:23:00,060
the security perspective,

543
00:23:00,060 --> 00:23:01,240
I've been a patient.

544
00:23:01,240 --> 00:23:02,830
I've seen that side,

545
00:23:02,830 --> 00:23:05,580
but I'd like to hear from your side,

546
00:23:05,580 --> 00:23:07,913
what's your perspective on it is?

547
00:23:09,690 --> 00:23:11,146
- Yeah, that's a great question.

548
00:23:11,146 --> 00:23:14,710
I think that COVID is really starkly

549
00:23:14,710 --> 00:23:18,740
forcing us to understand
and choose between

550
00:23:18,740 --> 00:23:22,010
some of these seemingly opposite goals.

551
00:23:22,010 --> 00:23:23,720
In medicine, we frequently have to

552
00:23:23,720 --> 00:23:26,330
weigh multiple different pros and cons

553
00:23:26,330 --> 00:23:28,760
for any particular treatment or situation.

554
00:23:28,760 --> 00:23:30,550
A patient may need
anesthesia for a procedure,

555
00:23:30,550 --> 00:23:31,880
but they're also very tenuous

556
00:23:31,880 --> 00:23:33,390
from a cardiovascular standpoint.

557
00:23:33,390 --> 00:23:34,770
So, what's more dangerous.

558
00:23:34,770 --> 00:23:36,980
Not getting the procedure or
putting them under anesthesia?

559
00:23:36,980 --> 00:23:38,740
So oftentimes you have to say,

560
00:23:38,740 --> 00:23:41,900
well, we need to take both
into account simultaneously.

561
00:23:41,900 --> 00:23:46,440
The points that we've
made about the necessity

562
00:23:46,440 --> 00:23:47,730
and the urgency of the situation,

563
00:23:47,730 --> 00:23:50,540
are absolutely correct
when we're in the ICU

564
00:23:50,540 --> 00:23:53,070
or the OR, dealing with these patients.

565
00:23:53,070 --> 00:23:55,600
Security is not at the
forefront of our mind.

566
00:23:55,600 --> 00:23:57,660
It's what technology
do we need to achieve?

567
00:23:57,660 --> 00:23:59,160
The physiologic goals we have

568
00:23:59,160 --> 00:24:01,380
for that particular
patient when we go home

569
00:24:01,380 --> 00:24:02,530
and we talk to people like you,

570
00:24:02,530 --> 00:24:03,510
and we're able to put it on

571
00:24:03,510 --> 00:24:05,130
our hacker and security researcher hat,

572
00:24:05,130 --> 00:24:07,770
obviously we start to
be able to understand

573
00:24:07,770 --> 00:24:08,683
and conceptualize the consequences

574
00:24:08,683 --> 00:24:12,050
of some of the downstream effects, right?

575
00:24:12,050 --> 00:24:15,440
So it is a complete balancing
act, 100% of the time,

576
00:24:15,440 --> 00:24:16,280
anybody who tells you,

577
00:24:16,280 --> 00:24:18,530
they have a perfect
formula for that answer,

578
00:24:18,530 --> 00:24:20,180
is lying to you.

579
00:24:20,180 --> 00:24:21,900
The thing that's been
somewhat reassuring to me

580
00:24:21,900 --> 00:24:24,550
is we have had conversations with people

581
00:24:24,550 --> 00:24:26,213
that we work with in our
hospitals and elsewhere,

582
00:24:26,213 --> 00:24:28,980
where they understand
that you kind of have to

583
00:24:28,980 --> 00:24:32,293
shoot for both and some
of our institutions,

584
00:24:32,293 --> 00:24:33,997
I've had people say I'm from

585
00:24:33,997 --> 00:24:36,780
the disaster and emergency
management side of things,

586
00:24:36,780 --> 00:24:38,980
Hey, we're gaming up the COVID response

587
00:24:38,980 --> 00:24:39,813
and going on that right now,

588
00:24:39,813 --> 00:24:44,813
but we wanna fold a security information

589
00:24:44,860 --> 00:24:46,959
infrastructure exercise into that as well,

590
00:24:46,959 --> 00:24:49,693
understanding that some of these events,

591
00:24:51,150 --> 00:24:53,470
whether it's (indistinct)
or ransomware issue,

592
00:24:53,470 --> 00:24:56,720
or some of the hospitals
in the Czech Republic,

593
00:24:56,720 --> 00:24:58,224
who have been hit during this period,

594
00:24:58,224 --> 00:25:01,250
the underlying assumption that
people are now realizing is

595
00:25:01,250 --> 00:25:03,270
that you need a stable infrastructure

596
00:25:03,270 --> 00:25:06,840
and good devices to be
able to treat patients

597
00:25:06,840 --> 00:25:10,150
and have the best outcomes in
a crisis situation like this.

598
00:25:10,150 --> 00:25:12,020
So deficiencies on the security side

599
00:25:12,020 --> 00:25:15,130
only hinder your ability to
achieve your main mission.

600
00:25:15,130 --> 00:25:17,830
So it's less of a shunting of resources

601
00:25:17,830 --> 00:25:18,960
from one to the other.

602
00:25:18,960 --> 00:25:22,504
Then how can we maximally
benefit both of those aspects,

603
00:25:22,504 --> 00:25:23,900
which is never perfect,

604
00:25:23,900 --> 00:25:24,870
but it's a better way
of thinking about it,

605
00:25:24,870 --> 00:25:26,403
then the trade off.

606
00:25:27,840 --> 00:25:29,230
- Yeah, I just completely echo that.

607
00:25:29,230 --> 00:25:33,390
Like one of my nightmare
scenarios is treating a hospital

608
00:25:33,390 --> 00:25:36,822
full of COVID patients where
the ICUs are overflowing

609
00:25:36,822 --> 00:25:39,750
and then getting hit with
ransomware, for example.

610
00:25:39,750 --> 00:25:43,090
So what little bandwidth we have left

611
00:25:43,090 --> 00:25:46,160
to handle the surge to treat the patients

612
00:25:46,160 --> 00:25:49,340
as best we can, goes out the window,

613
00:25:49,340 --> 00:25:52,020
when the digital tools we use,

614
00:25:52,020 --> 00:25:53,640
whether or not it's the
electronic health record,

615
00:25:53,640 --> 00:25:55,200
or connected medical devices,

616
00:25:55,200 --> 00:25:59,140
or all of the above, would
be impacted by an attack.

617
00:25:59,140 --> 00:26:03,610
So it's not just maybe
a little bit of impact

618
00:26:03,610 --> 00:26:07,190
to patient care, it's gonna be huge.

619
00:26:07,190 --> 00:26:08,307
One of the things we
all like to talk about,

620
00:26:08,307 --> 00:26:09,950
and I think we all know in this space,

621
00:26:09,950 --> 00:26:13,020
is just how dependent doctors are

622
00:26:13,020 --> 00:26:15,010
on connected medical technology, doctors,

623
00:26:15,010 --> 00:26:16,160
nurses, technicians,

624
00:26:16,160 --> 00:26:19,190
modern healthcare is
exceptionally connected.

625
00:26:19,190 --> 00:26:20,773
Hyper-connected, if you will.

626
00:26:21,680 --> 00:26:22,790
A lot of doctors,

627
00:26:22,790 --> 00:26:25,332
and as you've heard us
say this many times,

628
00:26:25,332 --> 00:26:27,810
Jeff and myself included,

629
00:26:27,810 --> 00:26:30,540
we haven't worked on paper charts.

630
00:26:30,540 --> 00:26:35,540
We never had light boxes
where we pull up a CT scan,

631
00:26:36,020 --> 00:26:37,570
that's printed on something and put it up

632
00:26:37,570 --> 00:26:38,660
against a wall to read it.

633
00:26:38,660 --> 00:26:40,423
We've always accessed
those through workstations

634
00:26:40,423 --> 00:26:43,300
and PAC system software.

635
00:26:43,300 --> 00:26:46,730
So you take what we're trained on,

636
00:26:46,730 --> 00:26:47,940
this digital infrastructure,

637
00:26:47,940 --> 00:26:49,780
connected, vulnerable infrastructure,

638
00:26:49,780 --> 00:26:52,550
and you add a pandemic on top of it.

639
00:26:52,550 --> 00:26:54,810
Then you take away the tools

640
00:26:54,810 --> 00:26:57,900
that we're used to using,
undoubtedly patients with suffer.

641
00:26:57,900 --> 00:26:59,560
So that one, two punch
is definitely something

642
00:26:59,560 --> 00:27:00,780
very concerning.

643
00:27:00,780 --> 00:27:01,920
To the heart of your question,

644
00:27:01,920 --> 00:27:06,420
which is, how do we as
clinicians make that trade off

645
00:27:06,420 --> 00:27:09,270
or decision about here's
a more secure device,

646
00:27:09,270 --> 00:27:13,240
but it has less clinical
utility or functionality,

647
00:27:13,240 --> 00:27:16,090
compared to this more
secure device, et cetera.

648
00:27:17,420 --> 00:27:18,510
So how do we make that trade off?

649
00:27:18,510 --> 00:27:21,363
Honestly, I'm looking
straight into the camera.

650
00:27:22,320 --> 00:27:27,240
It's really hard to even have
any bearing on that decision.

651
00:27:27,240 --> 00:27:29,810
So a lot of the devices
that we use every day

652
00:27:29,810 --> 00:27:33,090
in clinical practice, we don't choose,

653
00:27:33,090 --> 00:27:34,410
we show up to the hospital

654
00:27:34,410 --> 00:27:36,830
and their monitors that are there,

655
00:27:36,830 --> 00:27:39,220
because they made that
purchasing decision,

656
00:27:39,220 --> 00:27:41,360
five, 10 years ago.

657
00:27:41,360 --> 00:27:42,911
When you train to become a doctor,

658
00:27:42,911 --> 00:27:46,680
you may train for four or five years

659
00:27:46,680 --> 00:27:50,060
on a particular set of medical devices

660
00:27:50,060 --> 00:27:51,970
that you're gonna implant
a particular brand.

661
00:27:51,970 --> 00:27:54,150
You become familiar with that.

662
00:27:54,150 --> 00:27:56,190
Then, so what do you do when
you get out of practice?

663
00:27:56,190 --> 00:27:58,400
You use the exact same one.

664
00:27:58,400 --> 00:28:01,960
So there are, believe it or not,

665
00:28:01,960 --> 00:28:06,240
there's much less time to
reflect and much less ability

666
00:28:06,240 --> 00:28:07,620
than most people believe for us

667
00:28:07,620 --> 00:28:11,500
to pick which devices we
use in clinical practice.

668
00:28:11,500 --> 00:28:13,360
To make that decision.

669
00:28:13,360 --> 00:28:14,486
With that being said,

670
00:28:14,486 --> 00:28:18,250
we're trying to educate
other doctors on this.

671
00:28:18,250 --> 00:28:21,660
When we do, like Jeff
mentioned, they care.

672
00:28:21,660 --> 00:28:23,350
They want their patients to be safer.

673
00:28:23,350 --> 00:28:25,220
They wanna use secure medical devices.

674
00:28:25,220 --> 00:28:27,640
They don't want their
patient's health information,

675
00:28:27,640 --> 00:28:29,210
or even their health to be at risk.

676
00:28:29,210 --> 00:28:33,190
So we have sympathetic
ears from the clinicians.

677
00:28:33,190 --> 00:28:37,010
We just lack the ability
to make it easy for them.

678
00:28:37,010 --> 00:28:39,377
What you don't want is your
doctor to have to go to,

679
00:28:39,377 --> 00:28:42,400
14 years to train, to be a doctor,

680
00:28:42,400 --> 00:28:44,665
and then go and have to
take another year or two

681
00:28:44,665 --> 00:28:47,010
of cybersecurity coursework or whatever,

682
00:28:47,010 --> 00:28:48,400
to become competent.

683
00:28:48,400 --> 00:28:50,120
You really have to make it easy for them

684
00:28:50,120 --> 00:28:53,530
to make the right
decision and convince them

685
00:28:53,530 --> 00:28:56,320
that they should tell other
people in their hospital

686
00:28:56,320 --> 00:28:58,220
and other doctors that it's important.

687
00:28:59,600 --> 00:29:02,400
- I think to that point that
that's maybe a misperception,

688
00:29:02,400 --> 00:29:05,520
that the expectation is that
everyone in the supply chain

689
00:29:05,520 --> 00:29:07,690
has to become a cybersecurity expert.

690
00:29:07,690 --> 00:29:09,210
I think maybe that's a fatal flaw

691
00:29:09,210 --> 00:29:12,240
in how we think about
solving this is if we need to

692
00:29:12,240 --> 00:29:17,140
sufficiently educate
individuals by having them,

693
00:29:17,140 --> 00:29:19,860
you're not a medical device practitioner,

694
00:29:19,860 --> 00:29:21,680
but hey we got to teach you
all about cybersecurity here.

695
00:29:21,680 --> 00:29:24,760
Like it's really hard to think
that you can sufficiently

696
00:29:24,760 --> 00:29:27,850
educate folks that this isn't
their core competency on.

697
00:29:27,850 --> 00:29:29,380
Not to say they can't have some

698
00:29:29,380 --> 00:29:31,350
level of understanding what the impact is.

699
00:29:31,350 --> 00:29:32,658
I think making it tangible for

700
00:29:32,658 --> 00:29:35,890
their work stream or function
or whatever the case may be,

701
00:29:35,890 --> 00:29:37,530
is the perfect way to do that.

702
00:29:37,530 --> 00:29:41,880
But I would love to hear
kind of the thought around

703
00:29:41,880 --> 00:29:45,740
how we think about leveraging
those who are experts

704
00:29:45,740 --> 00:29:47,530
and not necessarily trying
to solve it ourselves

705
00:29:47,530 --> 00:29:48,640
and like going at it alone.

706
00:29:48,640 --> 00:29:50,614
Because I think that that's
probably a fatal flaw

707
00:29:50,614 --> 00:29:53,156
and has caused some of
the historical challenge

708
00:29:53,156 --> 00:29:54,370
that you're talking about

709
00:29:54,370 --> 00:29:56,440
when you inherit a
hospital full of devices

710
00:29:56,440 --> 00:29:57,490
that you didn't pick.

711
00:29:59,220 --> 00:30:03,126
- Surely as well, like Jeff was saying,

712
00:30:03,126 --> 00:30:05,870
normally physicians are
used to sort of having to

713
00:30:05,870 --> 00:30:08,420
balance different pros and cons

714
00:30:08,420 --> 00:30:11,120
of different parts to make
the best medical choice

715
00:30:11,120 --> 00:30:12,498
for each patient.

716
00:30:12,498 --> 00:30:14,276
But I think historically,

717
00:30:14,276 --> 00:30:17,810
maybe they weren't even aware
that this is one of the things

718
00:30:17,810 --> 00:30:18,643
they need to consider.

719
00:30:18,643 --> 00:30:21,901
So even just, how can we raise awareness

720
00:30:21,901 --> 00:30:24,587
and just in the consciousness of,

721
00:30:24,587 --> 00:30:26,580
"Oh, that's something
that I need to consider,

722
00:30:26,580 --> 00:30:27,610
even if I'm not an expert,

723
00:30:27,610 --> 00:30:29,630
maybe I can have an expert on hand,

724
00:30:29,630 --> 00:30:32,310
or I can read a rating for a device

725
00:30:32,310 --> 00:30:34,280
and make a decision somewhere that way.

726
00:30:34,280 --> 00:30:35,930
What kind of solutions are there,

727
00:30:36,890 --> 00:30:38,590
moving forward in that direction?"

728
00:30:39,690 --> 00:30:43,660
So I've actually spent some
time working a lot with the

729
00:30:43,660 --> 00:30:47,360
cardiologists and they
technicians in South Africa,

730
00:30:47,360 --> 00:30:50,360
trying to just have the discussion on,

731
00:30:50,360 --> 00:30:52,750
I had a phone call from my cardiologist

732
00:30:52,750 --> 00:30:55,970
saying, "We had a recall of devices.

733
00:30:55,970 --> 00:30:58,240
I need to explain a device,

734
00:30:58,240 --> 00:31:01,300
but I don't know how to
explain it to my patient.

735
00:31:01,300 --> 00:31:03,630
I don't even sufficiently understand

736
00:31:03,630 --> 00:31:06,310
engineering talk on the document.

737
00:31:06,310 --> 00:31:08,120
Can you translate?"

738
00:31:08,120 --> 00:31:12,000
So I think the big thing is
we are using our language,

739
00:31:12,000 --> 00:31:16,043
our linguistics, instead
of making it familiar,

740
00:31:17,075 --> 00:31:19,790
the medical practitioners.

741
00:31:19,790 --> 00:31:22,420
I think there should be
that portion in the hospital

742
00:31:22,420 --> 00:31:24,223
that does that translation,

743
00:31:25,130 --> 00:31:26,950
because I can tell you that was

744
00:31:26,950 --> 00:31:28,410
a very difficult conversation

745
00:31:28,410 --> 00:31:30,423
having with a 65 year old lady

746
00:31:30,423 --> 00:31:33,190
that doesn't understand technology.

747
00:31:33,190 --> 00:31:35,800
I mean, the doctor didn't
even sufficiently understand

748
00:31:35,800 --> 00:31:40,603
why he had to explain the
device was just being recalled.

749
00:31:43,374 --> 00:31:44,450
That's unfortunate thing is,

750
00:31:44,450 --> 00:31:47,340
they are expected to make these decisions.

751
00:31:47,340 --> 00:31:50,025
As he says, he has a patient coming in,

752
00:31:50,025 --> 00:31:52,760
his blood pressure is high.

753
00:31:52,760 --> 00:31:55,800
He needs to adjust the
ICD and the pacemaker.

754
00:31:55,800 --> 00:31:57,130
What he doesn't tell him is

755
00:31:57,130 --> 00:31:59,330
that his wife cooked the high sodium meal,

756
00:31:59,330 --> 00:32:01,111
which affected his blood pressure.

757
00:32:01,111 --> 00:32:03,830
The week later he goes back,
'cause he's having issues

758
00:32:06,080 --> 00:32:08,520
that will have changed significantly.

759
00:32:08,520 --> 00:32:11,590
So those are the challenges
they deal with us,

760
00:32:11,590 --> 00:32:14,380
having to solve the clinical puzzles.

761
00:32:14,380 --> 00:32:19,050
I think adding the technical
stuff on top of it,

762
00:32:19,050 --> 00:32:22,480
especially using terminology
they don't understand,

763
00:32:22,480 --> 00:32:25,160
is where we've been going wrong.

764
00:32:25,160 --> 00:32:28,977
We should be finding ways to
translate it better for them.

765
00:32:29,950 --> 00:32:31,980
- Yeah, I think and also that that's

766
00:32:31,980 --> 00:32:35,700
a failure overall of how we've designed

767
00:32:35,700 --> 00:32:37,880
not only medical devices,

768
00:32:37,880 --> 00:32:40,140
but how we do cybersecurity
overall, right?

769
00:32:40,140 --> 00:32:43,480
Like so many times if somebody
gets hacked or whatever,

770
00:32:43,480 --> 00:32:44,820
it's their fault.

771
00:32:44,820 --> 00:32:47,377
Setting aside, corporations who get,

772
00:32:47,377 --> 00:32:48,350
(indistinct) or whatever,

773
00:32:48,350 --> 00:32:50,140
and then claim to have been a victim of

774
00:32:50,140 --> 00:32:51,489
a sophisticated cyber attack.

775
00:32:51,489 --> 00:32:54,520
Like there are times when
people get hit by something

776
00:32:54,520 --> 00:32:56,310
and it really wasn't their fault.

777
00:32:56,310 --> 00:32:57,650
There were so many different things

778
00:32:57,650 --> 00:32:59,553
that have been expected to know.

779
00:33:00,588 --> 00:33:05,588
I think a professor once
said to me, stuck with me,

780
00:33:05,770 --> 00:33:07,127
we were talking about this
whole thing about like,

781
00:33:07,127 --> 00:33:09,100
"Oh, like, people are
just so damn about cyber.

782
00:33:09,100 --> 00:33:10,790
Like, why can't they just be better?"

783
00:33:10,790 --> 00:33:12,080
He's like, "Yeah and all those people

784
00:33:12,080 --> 00:33:13,370
who were driving Ford Pintos,

785
00:33:13,370 --> 00:33:14,700
like what the hell were they thinking,

786
00:33:14,700 --> 00:33:16,567
letting their cars blow up?"

787
00:33:18,559 --> 00:33:20,470
I think that that's kind of the way

788
00:33:20,470 --> 00:33:22,130
that was sort of light bulb moment for me

789
00:33:22,130 --> 00:33:25,480
and being like, "Oh, we
have to design devices

790
00:33:25,480 --> 00:33:28,000
that don't blow up in people's faces."

791
00:33:28,000 --> 00:33:31,960
we have to make it as
easy as humanly possible

792
00:33:31,960 --> 00:33:34,240
to do something securely,

793
00:33:34,240 --> 00:33:35,820
like doing something securely,

794
00:33:35,820 --> 00:33:37,310
needs to be the easiest thing.

795
00:33:37,310 --> 00:33:38,850
If doing something securely

796
00:33:38,850 --> 00:33:40,400
is the most difficult thing.

797
00:33:40,400 --> 00:33:42,250
That's not the fault of the user

798
00:33:42,250 --> 00:33:43,720
who then didn't do the secure thing.

799
00:33:43,720 --> 00:33:45,104
That is the fault of the designer

800
00:33:45,104 --> 00:33:47,760
who made the device poorly.

801
00:33:47,760 --> 00:33:50,740
So I think we've gotten away with frankly,

802
00:33:50,740 --> 00:33:52,700
in a lot of cases, being really lazy

803
00:33:52,700 --> 00:33:56,780
and offloading the
responsibility onto other people.

804
00:33:56,780 --> 00:33:58,710
I think what we have to do,

805
00:33:58,710 --> 00:34:01,770
especially within the healthcare
sector is all parts of it.

806
00:34:01,770 --> 00:34:04,630
We have to sort of
reclaim the responsibility

807
00:34:04,630 --> 00:34:06,029
that has been ours all along

808
00:34:06,029 --> 00:34:08,973
and actually really do what we need to do.

809
00:34:10,540 --> 00:34:12,880
- Yeah, I mean the responsibility

810
00:34:12,880 --> 00:34:16,210
the big responsibility
to build this better

811
00:34:16,210 --> 00:34:18,543
is the manufacturers, right?

812
00:34:18,543 --> 00:34:21,150
They're the ones that have the control

813
00:34:21,150 --> 00:34:23,150
over the firmware and the hardware.

814
00:34:23,150 --> 00:34:25,937
We shouldn't be pointing the
finger at the hospital saying,

815
00:34:25,937 --> 00:34:28,560
"Hey, your device are gonna get hacked,

816
00:34:28,560 --> 00:34:30,930
because you have vulnerable devices."

817
00:34:30,930 --> 00:34:35,710
Well, they should have
been built better, right?

818
00:34:35,710 --> 00:34:37,438
Because now in the industry

819
00:34:37,438 --> 00:34:40,060
we're putting Bandaids on, right?

820
00:34:40,060 --> 00:34:41,771
Vulnerabilities are (indistinct),

821
00:34:41,771 --> 00:34:43,150
so now we have to run and we're always on

822
00:34:43,150 --> 00:34:45,620
that back foot fixing stuff.

823
00:34:45,620 --> 00:34:47,379
But the manufacturer should be stepping up

824
00:34:47,379 --> 00:34:51,010
and should be doing a better job at this.

825
00:34:51,960 --> 00:34:55,020
- I completely agree.
- It's a big responsibility.

826
00:34:55,020 --> 00:34:56,000
- I completely agree.

827
00:34:56,000 --> 00:34:58,625
There's a lot that the
device manufacturers

828
00:34:58,625 --> 00:35:00,880
can do, should do.

829
00:35:00,880 --> 00:35:03,265
I think some of them have been doing,

830
00:35:03,265 --> 00:35:06,550
but there is also a key important thing.

831
00:35:06,550 --> 00:35:08,930
They can't control it, once it's deployed.

832
00:35:08,930 --> 00:35:13,930
So if they're deploying a
somewhat secure medical device,

833
00:35:14,030 --> 00:35:16,227
on an unsecured network,

834
00:35:16,227 --> 00:35:19,370
or if they're turning off
security controls for sake of ease

835
00:35:19,370 --> 00:35:22,720
of integrating into their
clinical environment,

836
00:35:22,720 --> 00:35:24,900
or if they're not
patching critical systems

837
00:35:24,900 --> 00:35:26,639
around these medical devices,

838
00:35:26,639 --> 00:35:29,340
there's some shared responsibility there.

839
00:35:29,340 --> 00:35:31,260
I think that's really important is

840
00:35:31,260 --> 00:35:33,340
that we need to be having not only

841
00:35:33,340 --> 00:35:36,170
a strong conversation
with device manufacturers,

842
00:35:36,170 --> 00:35:38,100
to do the right thing the start,

843
00:35:38,100 --> 00:35:39,730
but we need to be able to be

844
00:35:39,730 --> 00:35:43,510
giving hospitals the appropriate
resources, education,

845
00:35:43,510 --> 00:35:45,052
then holding them accountable

846
00:35:45,052 --> 00:35:47,420
when there's something egregious.

847
00:35:47,420 --> 00:35:51,500
Now I don't think they should
be asked to solve the issues

848
00:35:51,500 --> 00:35:54,610
of insecure medical devices,
because they just can't.

849
00:35:54,610 --> 00:35:56,960
But we've seen time and time again,

850
00:35:56,960 --> 00:35:59,440
some pretty horrible security practices

851
00:35:59,440 --> 00:36:00,538
by healthcare institutions

852
00:36:00,538 --> 00:36:03,810
that have nothing to do with
medical device manufacturers,

853
00:36:03,810 --> 00:36:06,637
but yet still could have
patient safety implications.

854
00:36:06,637 --> 00:36:09,400
Things like all the denial
of service attacks we see.

855
00:36:09,400 --> 00:36:11,900
The ransomware attacks, the theft.

856
00:36:11,900 --> 00:36:12,733
I mean, it's not just

857
00:36:12,733 --> 00:36:16,000
critical healthcare
infrastructure like hospitals.

858
00:36:16,000 --> 00:36:18,280
We've been seeing attacks on research.

859
00:36:18,280 --> 00:36:20,310
So I'm sure people have seen in the news.

860
00:36:20,310 --> 00:36:22,650
I think Jeff mentioned ransomware attacks

861
00:36:22,650 --> 00:36:25,446
on critical medical
research infrastructure,

862
00:36:25,446 --> 00:36:30,123
a state-sponsored
attacks on COVID research

863
00:36:30,123 --> 00:36:33,540
and vaccine trials data.

864
00:36:33,540 --> 00:36:36,620
So we have to have a
shared responsibility.

865
00:36:36,620 --> 00:36:38,060
This is a whole ecosystem.

866
00:36:38,060 --> 00:36:40,390
It's really trying to figure out,

867
00:36:40,390 --> 00:36:42,270
what's the best bang for our buck.

868
00:36:42,270 --> 00:36:43,970
I feel like a lot of the conversations

869
00:36:43,970 --> 00:36:45,320
focused around medical devices,

870
00:36:45,320 --> 00:36:48,170
because it's a much easier thing to tackle

871
00:36:48,170 --> 00:36:51,850
than trying to go to a
rural access hospital

872
00:36:51,850 --> 00:36:55,680
in South Dakota and fixing
their broken network.

873
00:36:55,680 --> 00:36:57,200
Then being able to monitor that

874
00:36:57,200 --> 00:36:58,760
and continually say,

875
00:36:58,760 --> 00:37:03,760
how are we gonna secure
every hospital and clinic

876
00:37:03,820 --> 00:37:06,160
and doctor's office in
the entire United States?

877
00:37:06,160 --> 00:37:08,313
That's a much harder problem.

878
00:37:09,533 --> 00:37:10,366
- Just...

879
00:37:13,194 --> 00:37:14,027
Carry on.

880
00:37:14,870 --> 00:37:16,140
- Oh, that's it.

881
00:37:16,140 --> 00:37:17,290
- I'd like to (laughs).

882
00:37:18,260 --> 00:37:19,480
- Sorry.

883
00:37:19,480 --> 00:37:20,900
I just wanted to say, right.

884
00:37:20,900 --> 00:37:23,600
It's not just a United
States problem, right?

885
00:37:23,600 --> 00:37:26,305
It's a global problem.

886
00:37:26,305 --> 00:37:28,330
Hate to be the one to point it,

887
00:37:28,330 --> 00:37:32,600
but this is a big problem everywhere.

888
00:37:32,600 --> 00:37:35,020
I know everyone on here is from the U.S.

889
00:37:35,020 --> 00:37:36,283
I'm the only oddball.

890
00:37:37,230 --> 00:37:38,794
- I'm from Canada.

891
00:37:38,794 --> 00:37:40,030
(laughing)
- Oh, (indistinct).

892
00:37:42,010 --> 00:37:46,403
But the thing is just, every
hospital's different, right?

893
00:37:47,290 --> 00:37:50,750
There's no cookie cutter way
of looking at the problem.

894
00:37:50,750 --> 00:37:53,000
Every hospital network is different.

895
00:37:53,000 --> 00:37:54,860
I think sometimes what we forget

896
00:37:54,860 --> 00:37:59,860
is that patient record systems,
I never used to consider it.

897
00:38:00,010 --> 00:38:01,420
But then I sat back and sort of

898
00:38:01,420 --> 00:38:03,210
from the cyber-criminal perspective,

899
00:38:03,210 --> 00:38:05,450
it is the ultimate identity theft.

900
00:38:05,450 --> 00:38:08,940
It's the thing that you can
keep selling constantly.

901
00:38:08,940 --> 00:38:11,600
It's often the thing
that's least protected.

902
00:38:11,600 --> 00:38:13,890
'Cause we're focusing so
much on medical devices.

903
00:38:13,890 --> 00:38:17,290
We've forgotten what a
treasure trove that holds.

904
00:38:17,290 --> 00:38:19,203
I mean, that's moving to the cloud.

905
00:38:20,140 --> 00:38:23,430
So, you know, Microsoft is
one of the big proponents.

906
00:38:23,430 --> 00:38:25,280
That's moving everything now to the card,

907
00:38:25,280 --> 00:38:29,840
in terms of patient records
and clinical systems.

908
00:38:29,840 --> 00:38:32,367
So I'd be interested to see
how the smaller house hospitals

909
00:38:32,367 --> 00:38:35,473
are actually gonna be able
to cope with having to do,

910
00:38:36,790 --> 00:38:39,610
permitless defenses,

911
00:38:39,610 --> 00:38:43,147
zero trust networks, or
even cloud solutions.

912
00:38:44,543 --> 00:38:48,040
Because I think the big hospitals
like Mayo might be fine,

913
00:38:48,040 --> 00:38:51,110
but you have the smaller, rural hospitals

914
00:38:51,110 --> 00:38:53,530
that I don't even know if they have

915
00:38:53,530 --> 00:38:55,610
IT or security on the premises,

916
00:38:55,610 --> 00:38:57,360
or whether they're paying someone

917
00:38:57,360 --> 00:38:59,533
a third party to do the solution for them.

918
00:39:01,790 --> 00:39:03,263
- Yeah.
- (laughs) Sorry.

919
00:39:03,263 --> 00:39:04,410
- Go ahead, take over.

920
00:39:04,410 --> 00:39:06,285
- Okay, I wanted to go back to

921
00:39:06,285 --> 00:39:08,993
the topic of responsibility

922
00:39:08,993 --> 00:39:12,510
and I would have to echo with Christian.

923
00:39:12,510 --> 00:39:15,417
I think it is a shared responsibility.

924
00:39:15,417 --> 00:39:17,670
Obviously, I think that,

925
00:39:17,670 --> 00:39:19,610
I work for a medical device manufacturer.

926
00:39:19,610 --> 00:39:22,200
I'm a medical software engineer.

927
00:39:22,200 --> 00:39:23,900
I think about these things.

928
00:39:23,900 --> 00:39:26,370
I want to make sure that
I'm doing my part to

929
00:39:26,370 --> 00:39:31,370
build really secure and awesome
safe products for end users.

930
00:39:31,450 --> 00:39:32,946
I care a lot about that,

931
00:39:32,946 --> 00:39:37,820
but I think it's easy to blame
manufacturers and it's often

932
00:39:37,820 --> 00:39:40,050
more complicated again,
it's this balancing act.

933
00:39:40,050 --> 00:39:43,350
So I work for a medical
device manufacturer.

934
00:39:43,350 --> 00:39:44,400
That's a consulting firm.

935
00:39:44,400 --> 00:39:46,860
So we don't have any of
our own in-house products.

936
00:39:46,860 --> 00:39:49,350
We have people who come
to us and we have clients

937
00:39:49,350 --> 00:39:52,770
and some of them are business people

938
00:39:52,770 --> 00:39:54,340
and some of them are other

939
00:39:54,340 --> 00:39:57,520
medical device manufacturers
that subcontract to us.

940
00:39:57,520 --> 00:39:59,250
But we have a lot of people who are

941
00:39:59,250 --> 00:40:01,150
just doctors and clinicians

942
00:40:01,150 --> 00:40:03,180
and other people who are
really passionate about

943
00:40:03,180 --> 00:40:05,387
saving lives and they come
to us and they're like,

944
00:40:05,387 --> 00:40:07,180
"We have this idea.

945
00:40:07,180 --> 00:40:08,975
We think we see this gap.

946
00:40:08,975 --> 00:40:11,310
We desperately wanna help our patients.

947
00:40:11,310 --> 00:40:13,120
Please help us build this.

948
00:40:13,120 --> 00:40:15,170
We have this tiny, tiny budget.

949
00:40:15,170 --> 00:40:16,860
We only have this amount
of time to do it in,

950
00:40:16,860 --> 00:40:19,350
because we got this little
budget from these people,

951
00:40:19,350 --> 00:40:21,651
but they say we have to
get it done by this time."

952
00:40:21,651 --> 00:40:24,660
We were working really, really hard

953
00:40:24,660 --> 00:40:26,140
to try to meet all these deadlines

954
00:40:26,140 --> 00:40:29,166
and actually make this little device that,

955
00:40:29,166 --> 00:40:33,460
if we can get it to those
doctors, it might save lives.

956
00:40:33,460 --> 00:40:37,727
Then for us to come in
and try to say like,

957
00:40:37,727 --> 00:40:40,410
"Oh, well we have to add
all of these security things

958
00:40:40,410 --> 00:40:43,760
and maybe it's gonna affect the budget.

959
00:40:43,760 --> 00:40:45,152
It's gonna affect the timeline.

960
00:40:45,152 --> 00:40:48,420
Again, I care about these
things I'm in there.

961
00:40:48,420 --> 00:40:52,750
I'm advocating for this
stuff, but it's hard to say,

962
00:40:52,750 --> 00:40:54,008
if you only have this much budget

963
00:40:54,008 --> 00:40:56,760
and it's, how do you choose?

964
00:40:56,760 --> 00:40:59,580
How do you tell them, okay, you shouldn't,

965
00:40:59,580 --> 00:41:01,220
we just, aren't gonna be able to make this

966
00:41:01,220 --> 00:41:03,160
and implement this part of security,

967
00:41:03,160 --> 00:41:04,470
like where to draw the line.

968
00:41:04,470 --> 00:41:09,470
I think it's more complicated
and harder like in practice.

969
00:41:11,610 --> 00:41:13,440
It's hard to just say, well,

970
00:41:13,440 --> 00:41:18,440
the medical device
manufacturer should just do it.

971
00:41:20,360 --> 00:41:21,760
How do you make that choice?

972
00:41:23,500 --> 00:41:25,480
- I actually wanna add to that story.

973
00:41:25,480 --> 00:41:27,570
So I started working with Tronic.

974
00:41:27,570 --> 00:41:28,920
and I'm a hottest.

975
00:41:28,920 --> 00:41:30,050
Everyone knows that.

976
00:41:30,050 --> 00:41:32,246
I say a bunch of things three years ago,

977
00:41:32,246 --> 00:41:36,737
'cause I was unhappy
with how our conversation

978
00:41:36,737 --> 00:41:39,550
and we had a legal situation

979
00:41:39,550 --> 00:41:43,710
and I founded the first
six months of my project

980
00:41:43,710 --> 00:41:47,040
listening and getting
to know the developers

981
00:41:47,040 --> 00:41:50,863
and the software engineers
and the hardware engineers.

982
00:41:52,370 --> 00:41:54,260
I sat back and listened

983
00:41:54,260 --> 00:41:56,650
and realized that these are real people

984
00:41:56,650 --> 00:41:58,660
that are wanting to
make a real difference.

985
00:41:58,660 --> 00:41:59,893
Really, they are.

986
00:42:00,792 --> 00:42:03,180
One of the specific engineers,

987
00:42:03,180 --> 00:42:05,480
the master, had a big impact on my life,

988
00:42:05,480 --> 00:42:07,297
because he said to me,

989
00:42:07,297 --> 00:42:08,950
"Tell me me what you're
wanting your device.

990
00:42:08,950 --> 00:42:11,310
Tell me all the security you want.

991
00:42:11,310 --> 00:42:14,500
Give the list to me and
let's discuss this."

992
00:42:14,500 --> 00:42:16,683
He turned around and say to me,

993
00:42:16,683 --> 00:42:17,641
"Well, so you're getting

994
00:42:17,641 --> 00:42:20,059
a new device every three years, right?"

995
00:42:20,059 --> 00:42:21,770
I said to him, "Well, no,
there's no fucking way

996
00:42:21,770 --> 00:42:23,340
that I'm doing that to myself."

997
00:42:23,340 --> 00:42:26,860
He's like, "Well then you
can't have all of that."

998
00:42:26,860 --> 00:42:29,670
He says, "There's
trade-offs for everything."

999
00:42:29,670 --> 00:42:33,280
So specifically with
embedded implanted devices,

1000
00:42:33,280 --> 00:42:34,963
the more security you add,

1001
00:42:36,750 --> 00:42:39,290
the less lifetime you'll
have on your battery,

1002
00:42:39,290 --> 00:42:41,210
because I can tell you the one thing that

1003
00:42:41,210 --> 00:42:45,470
that is worth gold, is how
long your device lasts,

1004
00:42:45,470 --> 00:42:48,480
because it is a horrible thing to cut out.

1005
00:42:48,480 --> 00:42:51,705
I don't know if you guys,
but the more you cut it out,

1006
00:42:51,705 --> 00:42:55,060
the more scar tissue forms

1007
00:42:55,060 --> 00:42:57,463
and the worse it gets, right.

1008
00:42:58,350 --> 00:43:00,670
I've had my device since '19.

1009
00:43:00,670 --> 00:43:02,030
I wouldn't be here without it.

1010
00:43:02,030 --> 00:43:06,156
So people building these
things I'm with the date

1011
00:43:06,156 --> 00:43:06,989
I had two weeks left.

1012
00:43:06,989 --> 00:43:08,923
That was, that was the serious situation.

1013
00:43:09,889 --> 00:43:14,889
So I think sometimes we want
all the security in the world

1014
00:43:15,262 --> 00:43:17,103
where we don't realize these trade off.

1015
00:43:18,180 --> 00:43:21,170
These devices are there to save lives.

1016
00:43:21,170 --> 00:43:23,320
If we try and push security too much,

1017
00:43:23,320 --> 00:43:25,920
there's a whole lot of second devices

1018
00:43:25,920 --> 00:43:28,260
that will never come to market

1019
00:43:28,260 --> 00:43:30,100
and they will never save lives.

1020
00:43:30,100 --> 00:43:32,280
That's one big lesson that I had to learn

1021
00:43:32,280 --> 00:43:33,843
and I have to have humble pie

1022
00:43:33,843 --> 00:43:37,463
and I had to swallow my
words and realize that,

1023
00:43:38,676 --> 00:43:40,530
there's people behind this wanting to

1024
00:43:40,530 --> 00:43:43,210
make a difference with
technology and science.

1025
00:43:43,210 --> 00:43:45,060
Without that device,

1026
00:43:45,060 --> 00:43:49,623
I wouldn't be, I wouldn't have my kids.

1027
00:43:50,660 --> 00:43:53,340
So technology does save lives, in ways.

1028
00:43:53,340 --> 00:43:55,303
We must just find the perfect balance

1029
00:43:55,303 --> 00:43:57,483
to balance everything out.

1030
00:43:58,620 --> 00:44:00,043
- In your perspective, Vee,

1031
00:44:01,464 --> 00:44:03,940
and folks like you like Marie Moe,

1032
00:44:03,940 --> 00:44:06,550
who have these incredible
security backgrounds,

1033
00:44:06,550 --> 00:44:09,780
but also our patients is so
incredibly valuable to be able

1034
00:44:09,780 --> 00:44:12,000
to consider these types of trade-offs

1035
00:44:12,000 --> 00:44:13,370
in like a human person, right?

1036
00:44:13,370 --> 00:44:14,860
Like a very real way.

1037
00:44:14,860 --> 00:44:17,780
One of the things that Christian
and I are working on is,

1038
00:44:17,780 --> 00:44:21,780
how do we understand
the role of the patient

1039
00:44:21,780 --> 00:44:24,563
as a stakeholder in these
types of conversations.

1040
00:44:26,730 --> 00:44:30,170
Is there a utility in having those

1041
00:44:30,170 --> 00:44:31,010
types of conversations,

1042
00:44:31,010 --> 00:44:32,370
with this 60 year old man who needs to

1043
00:44:32,370 --> 00:44:34,150
get his pacemaker revised,

1044
00:44:34,150 --> 00:44:36,180
or is there a trade-off

1045
00:44:36,180 --> 00:44:38,100
between the potential
risk of a vulnerability

1046
00:44:38,100 --> 00:44:40,350
being exploited and then
just putting him through

1047
00:44:40,350 --> 00:44:41,990
that process of having it revised?

1048
00:44:41,990 --> 00:44:43,900
I think it highlights one of the things

1049
00:44:43,900 --> 00:44:46,690
that Christian and I are so interested in,

1050
00:44:46,690 --> 00:44:50,780
is just developing a data
and a science around this,

1051
00:44:50,780 --> 00:44:53,470
to be able to say in other
types of medical therapies,

1052
00:44:53,470 --> 00:44:54,890
we have very clear risks.

1053
00:44:54,890 --> 00:44:56,290
If I give you a blood transfusion,

1054
00:44:56,290 --> 00:44:58,820
there's a about a one in
1.5 to 2 million chance

1055
00:44:58,820 --> 00:45:01,030
that you might have an
infection that's serious,

1056
00:45:01,030 --> 00:45:04,270
as a result of that or
heart or lung issues.

1057
00:45:04,270 --> 00:45:05,540
We really don't have the ability

1058
00:45:05,540 --> 00:45:07,040
to have conversations
with patients and say,

1059
00:45:07,040 --> 00:45:09,050
yeah, this is the clearcut risk,

1060
00:45:09,050 --> 00:45:11,158
because thankfully we haven't seen

1061
00:45:11,158 --> 00:45:13,629
many incidents that have issues.

1062
00:45:13,629 --> 00:45:15,720
That doesn't mean that
there's an absence of risk,

1063
00:45:15,720 --> 00:45:16,910
but it makes it harder for us

1064
00:45:16,910 --> 00:45:18,400
to have discussions with patients

1065
00:45:18,400 --> 00:45:20,010
and say, really, this is the type of math

1066
00:45:20,010 --> 00:45:22,840
that you have to weigh as a
patient with your own values

1067
00:45:22,840 --> 00:45:24,289
and preferences and things like that.

1068
00:45:24,289 --> 00:45:26,970
We've kind of done some work
on touching on this idea of

1069
00:45:26,970 --> 00:45:30,120
a cybersecurity informed consent to say,

1070
00:45:30,120 --> 00:45:31,337
we talk about risks,

1071
00:45:31,337 --> 00:45:34,720
medical risks of surgeries and medications

1072
00:45:34,720 --> 00:45:36,260
and things like that there may be on.

1073
00:45:36,260 --> 00:45:37,950
Should we start thinking
about cybersecurity

1074
00:45:37,950 --> 00:45:39,300
as a potential risk that should be

1075
00:45:39,300 --> 00:45:41,230
included in this conversation?

1076
00:45:41,230 --> 00:45:44,483
A clinician has with
the patient and Jessica,

1077
00:45:44,483 --> 00:45:47,510
I know the FDA has also
really interested in this

1078
00:45:47,510 --> 00:45:49,560
and you've had a lot
of really cool outreach

1079
00:45:50,948 --> 00:45:53,810
types of events to be able
to talk to people like Vee,

1080
00:45:53,810 --> 00:45:56,570
and I think it's a challenge
of moving beyond people who are

1081
00:45:56,570 --> 00:45:59,110
security literate to people
who may not have heard about

1082
00:45:59,110 --> 00:46:00,180
these issues whatsoever,

1083
00:46:00,180 --> 00:46:02,800
for as much as we talk about
them and to be able to kind of

1084
00:46:02,800 --> 00:46:06,230
have that enter the
conversation so that they can,

1085
00:46:06,230 --> 00:46:07,970
without having a
background in cybersecurity

1086
00:46:07,970 --> 00:46:11,340
weigh that as part of
their clinical process.

1087
00:46:12,450 --> 00:46:13,690
- Yeah, and I mean,

1088
00:46:13,690 --> 00:46:14,530
I think that there's a couple of things

1089
00:46:14,530 --> 00:46:16,030
that I would bring up on this.

1090
00:46:16,030 --> 00:46:19,070
I mean, like, I think one,

1091
00:46:19,070 --> 00:46:20,900
you had mentioned that FDA has been doing

1092
00:46:20,900 --> 00:46:23,045
a lot of this and I think
Vee, you were actually at

1093
00:46:23,045 --> 00:46:25,560
it was October, 2019 meeting,

1094
00:46:25,560 --> 00:46:29,330
but we have the patient engagement
advisory council meeting,

1095
00:46:29,330 --> 00:46:30,180
the PEAC meeting.

1096
00:46:31,461 --> 00:46:34,670
So FDA is very much trying to

1097
00:46:34,670 --> 00:46:37,160
make sure that the patient
perspective is heard

1098
00:46:38,641 --> 00:46:42,000
and it's not just yearly
meeting some things like that.

1099
00:46:42,000 --> 00:46:44,140
As many of you know, Suzanne
Schwartz is very approachable.

1100
00:46:44,140 --> 00:46:46,620
You can pretty much get
her email and email her

1101
00:46:46,620 --> 00:46:49,023
and she'll find time to talk to you.

1102
00:46:50,353 --> 00:46:52,940
So that is a really critical part of this,

1103
00:46:52,940 --> 00:46:56,270
because not that all
of you are going around

1104
00:46:56,270 --> 00:46:59,110
reading government,
white papers and things,

1105
00:46:59,110 --> 00:47:00,310
but a couple of years ago,

1106
00:47:00,310 --> 00:47:03,070
the FDA put out this medical
device safety action plan

1107
00:47:03,070 --> 00:47:06,590
and sort of setting aside
the flowery language

1108
00:47:06,590 --> 00:47:07,780
that all government documents

1109
00:47:07,780 --> 00:47:10,433
I think have were like
decreed that they must use.

1110
00:47:11,570 --> 00:47:15,630
Essentially what it says is,
look there, it's exactly this,

1111
00:47:15,630 --> 00:47:16,463
this issue of,

1112
00:47:16,463 --> 00:47:19,990
of balancing the idea that patient safety

1113
00:47:19,990 --> 00:47:21,810
is a twofold concern, right?

1114
00:47:21,810 --> 00:47:24,760
There's the concern that we
all typically think about

1115
00:47:24,760 --> 00:47:29,417
on cybersecurity is this device
safe and effective enough

1116
00:47:29,417 --> 00:47:32,570
to justify its use with the patient?

1117
00:47:32,570 --> 00:47:34,210
There's also the flip side of that though,

1118
00:47:34,210 --> 00:47:36,510
of what Ash was talking about and what

1119
00:47:36,510 --> 00:47:38,053
Vee was talking about in that,

1120
00:47:39,000 --> 00:47:41,740
what happens with the
patient can't get the device?

1121
00:47:41,740 --> 00:47:42,573
That is another,

1122
00:47:42,573 --> 00:47:45,490
that's gotta be a thing
that gets considered too.

1123
00:47:45,490 --> 00:47:49,070
So FDA, when we talk about cybersecurity,

1124
00:47:49,070 --> 00:47:52,307
when we usually do it, we're
very explicitly talking about,

1125
00:47:52,307 --> 00:47:54,570
do you have security controls?

1126
00:47:54,570 --> 00:47:57,640
Do you have sufficient whatever
to make sure that the device

1127
00:47:57,640 --> 00:48:01,350
is cyber secure, but a less
talked about part of the work,

1128
00:48:01,350 --> 00:48:04,638
but that is equally important
is this idea that we recognize

1129
00:48:04,638 --> 00:48:09,190
that sometimes devices
need to get to patients,

1130
00:48:09,190 --> 00:48:11,940
because of the benefit that
they're gonna be able to ride.

1131
00:48:11,940 --> 00:48:14,000
Maybe we don't have as much information.

1132
00:48:14,000 --> 00:48:18,780
Maybe we don't have as much
of assurance of the things

1133
00:48:18,780 --> 00:48:20,170
that we would like to, but you know,

1134
00:48:20,170 --> 00:48:21,800
this is the breakthrough device program.

1135
00:48:21,800 --> 00:48:24,020
This is some of these other
investigational devices

1136
00:48:24,020 --> 00:48:27,590
that come up and that FDA
has specific categories,

1137
00:48:27,590 --> 00:48:29,633
foreign authorities for them,
things that you can do this.

1138
00:48:29,633 --> 00:48:33,470
Then it's exactly this
recognition that the other folks

1139
00:48:33,470 --> 00:48:35,230
on the panel are pointing out,

1140
00:48:35,230 --> 00:48:38,510
which is that in some cases
not having access to a device

1141
00:48:38,510 --> 00:48:40,610
can be as big of a risk
of having access to

1142
00:48:40,610 --> 00:48:42,630
a device that isn't secure enough.

1143
00:48:42,630 --> 00:48:45,852
So, I think that is just an
important point to highlight.

1144
00:48:45,852 --> 00:48:48,520
That we as an agency keep in mind,

1145
00:48:48,520 --> 00:48:52,920
but that this community in
addition also keeps in mind,

1146
00:48:52,920 --> 00:48:54,963
as we have these kinds of conversations.

1147
00:48:57,970 --> 00:48:59,420
- All right, I wanna change this.

1148
00:48:59,420 --> 00:49:00,700
Oh, can I,

1149
00:49:00,700 --> 00:49:02,800
I'm gonna change this up real quick,

1150
00:49:02,800 --> 00:49:05,280
because I heard a rumor,

1151
00:49:05,280 --> 00:49:07,900
there are thousands of hackers

1152
00:49:07,900 --> 00:49:10,110
watching this stream right now.

1153
00:49:10,110 --> 00:49:12,500
There are literally thousands of hackers

1154
00:49:12,500 --> 00:49:14,223
from across the globe watching,

1155
00:49:16,810 --> 00:49:20,330
very interested in what
we're talking about

1156
00:49:20,330 --> 00:49:21,798
and I'm sure they're
thinking to themselves,

1157
00:49:21,798 --> 00:49:23,810
"wow, there are a lot of issues here.

1158
00:49:23,810 --> 00:49:25,809
I might not have been aware of

1159
00:49:25,809 --> 00:49:27,130
and I really wanna get involved."

1160
00:49:27,130 --> 00:49:29,880
So hackers out there wanting
to get involved in this space,

1161
00:49:29,880 --> 00:49:32,531
how does, we've heard some examples.

1162
00:49:32,531 --> 00:49:35,080
There's been a group of hackers

1163
00:49:35,080 --> 00:49:36,870
that have tried to defend hospitals

1164
00:49:36,870 --> 00:49:39,870
against attackers during COVID.

1165
00:49:39,870 --> 00:49:41,480
There are hackers printing,

1166
00:49:41,480 --> 00:49:44,890
a protective equipment for
doctors on the front line,

1167
00:49:44,890 --> 00:49:47,190
et cetera, nurses, but like,

1168
00:49:47,190 --> 00:49:48,900
what's the next generation of this, right?

1169
00:49:48,900 --> 00:49:50,123
Like when the pandemic's done,

1170
00:49:50,123 --> 00:49:53,603
how do hackers play a role in this space?

1171
00:49:53,603 --> 00:49:56,680
Continuing to research,
is it bug bounties?

1172
00:49:56,680 --> 00:49:58,980
Does the hospital have a bug bounty,

1173
00:49:58,980 --> 00:50:01,500
should a device manufacturer
have a bug bounty?

1174
00:50:01,500 --> 00:50:03,444
How does HIPAA play into that?

1175
00:50:03,444 --> 00:50:06,201
The protection of patient information,

1176
00:50:06,201 --> 00:50:10,853
how do we really kind of bring
hackers more into this space?

1177
00:50:16,560 --> 00:50:18,173
- Okay, I'm gonna jump in, yeah.

1178
00:50:19,930 --> 00:50:21,690
I have a dream and I have a dream with

1179
00:50:21,690 --> 00:50:23,133
a friend of mine, Nina.

1180
00:50:24,010 --> 00:50:29,010
We wanna establish a laboratory
set up with devices, right?

1181
00:50:30,370 --> 00:50:32,367
That people can actually
do research on that.

1182
00:50:32,367 --> 00:50:35,564
We can put on networks that we can

1183
00:50:35,564 --> 00:50:38,903
stand for vulnerabilities,
that we can reverse engineer,

1184
00:50:38,903 --> 00:50:42,736
that we can work with
manufacturers to make better.

1185
00:50:42,736 --> 00:50:47,430
I always see people wanting
to break things, right?

1186
00:50:47,430 --> 00:50:49,070
We wanna find flaws.

1187
00:50:49,070 --> 00:50:50,550
We wanna find problems,

1188
00:50:50,550 --> 00:50:53,510
but often we don't wanna find
the solution to the problem.

1189
00:50:53,510 --> 00:50:55,906
'Cause that's the harder part.

1190
00:50:55,906 --> 00:51:00,906
So I wanna say that if you
find a device that's vulnerable

1191
00:51:01,648 --> 00:51:05,690
first, remember there are
human lives at stake, okay.

1192
00:51:05,690 --> 00:51:07,560
This is not an ego thing.

1193
00:51:07,560 --> 00:51:11,160
Try and find the solution to
the problem that you found.

1194
00:51:11,160 --> 00:51:14,090
Write it up as you would,
any scientific paper.

1195
00:51:14,090 --> 00:51:15,130
I know it's hard work.

1196
00:51:15,130 --> 00:51:18,150
I know it's not glorious
and it's not sexy.

1197
00:51:18,150 --> 00:51:21,471
But when you hand that
over to the manufacturer,

1198
00:51:21,471 --> 00:51:25,720
they have all the data and
the more data they have,

1199
00:51:25,720 --> 00:51:27,843
the faucet that they can verify the claim,

1200
00:51:27,843 --> 00:51:31,780
they can start acting accordingly, right?

1201
00:51:31,780 --> 00:51:32,640
It's not gonna be easy.

1202
00:51:32,640 --> 00:51:35,650
Not all engineers are
gonna wanna be friendly,

1203
00:51:35,650 --> 00:51:37,210
but it is changing.

1204
00:51:37,210 --> 00:51:41,000
But the biggest thing is the
more thorough your research is,

1205
00:51:41,000 --> 00:51:43,200
the less dispute there can be.

1206
00:51:43,200 --> 00:51:45,940
The more we can find a way to fixing it,

1207
00:51:45,940 --> 00:51:48,570
but it's not all about just bug bounties,

1208
00:51:48,570 --> 00:51:50,250
because I think that for me,

1209
00:51:50,250 --> 00:51:52,310
creates a negative thing of aren't we just

1210
00:51:52,310 --> 00:51:54,631
finding the problems.

1211
00:51:54,631 --> 00:51:57,960
We should be finding problems
and then solving them.

1212
00:51:57,960 --> 00:51:59,653
That's the hacker mindset.

1213
00:52:00,530 --> 00:52:02,897
It's not just about
pointing fingers and saying,

1214
00:52:02,897 --> 00:52:04,550
"This is a problem."

1215
00:52:04,550 --> 00:52:06,193
We should be working at the solution,

1216
00:52:06,193 --> 00:52:09,440
which is finding new ways of doing things.

1217
00:52:09,440 --> 00:52:12,660
So I wanna see a lab
full of medical devices

1218
00:52:12,660 --> 00:52:14,980
that hackers can build solutions.

1219
00:52:14,980 --> 00:52:17,100
But not only hackers.

1220
00:52:17,100 --> 00:52:19,899
You need people like Ash, right?

1221
00:52:19,899 --> 00:52:23,780
'Cause I mean, we're good
at the other side of it,

1222
00:52:23,780 --> 00:52:26,170
but I can't build these devices.

1223
00:52:26,170 --> 00:52:28,380
I wouldn't even know where it stopped.

1224
00:52:28,380 --> 00:52:31,513
So I think it needs to be a
multidisciplinary approach.

1225
00:52:32,800 --> 00:52:34,931
Even people like the FDA,

1226
00:52:34,931 --> 00:52:38,893
should be involved in
a policy perspective.

1227
00:52:40,263 --> 00:52:42,150
Everyone should just be working together.

1228
00:52:42,150 --> 00:52:45,380
We should be building the
bridges towards having synergy

1229
00:52:45,380 --> 00:52:47,960
and having a space
where we can exclude us.

1230
00:52:47,960 --> 00:52:50,090
I think hackers, is awesome for that

1231
00:52:50,090 --> 00:52:52,130
is they would really do a lot of that.

1232
00:52:55,000 --> 00:52:56,640
- Sorry, I'm going to accuse my cat.

1233
00:52:56,640 --> 00:52:59,170
He just desperately jumped into my lap.

1234
00:52:59,170 --> 00:53:01,380
I was trying to prevent that and failed.

1235
00:53:01,380 --> 00:53:02,213
(laughing)

1236
00:53:02,213 --> 00:53:04,700
He just tailed the side of the chair.

1237
00:53:04,700 --> 00:53:06,928
- A welcome addition to the panel.

1238
00:53:06,928 --> 00:53:08,840
(laughing)

1239
00:53:08,840 --> 00:53:12,050
- So I love the notion of
being part of the solution.

1240
00:53:12,050 --> 00:53:15,820
I think to your point, it
does require multiple voices.

1241
00:53:15,820 --> 00:53:18,220
You hit on a point that I think
is really important, right?

1242
00:53:18,220 --> 00:53:22,070
You, as someone who does a
lot of security research,

1243
00:53:22,070 --> 00:53:24,310
is not totally in the space of,

1244
00:53:24,310 --> 00:53:25,970
how do I build a medical device?

1245
00:53:25,970 --> 00:53:28,460
I think we similarly need to
not have the expectation of the

1246
00:53:28,460 --> 00:53:31,090
people building medical
devices to know how to

1247
00:53:31,090 --> 00:53:33,300
solve some of these cybersecurity issues.

1248
00:53:33,300 --> 00:53:36,230
So I think having the
willingness to partner

1249
00:53:36,230 --> 00:53:39,750
and really helping them
not make cybersecurity,

1250
00:53:39,750 --> 00:53:42,500
their number two core capability

1251
00:53:42,500 --> 00:53:45,770
and instead offering them
solutions is absolutely critical.

1252
00:53:45,770 --> 00:53:48,123
And the way to make things actually stick.

1253
00:53:49,270 --> 00:53:51,420
- So should we have
solution bounties then?

1254
00:53:52,440 --> 00:53:55,872
- Oh I love it.
- You should trademark that.

1255
00:53:55,872 --> 00:53:57,760
(laughing)
- Yeah absolutely!

1256
00:53:57,760 --> 00:54:00,410
- But I just, I wanted to
bring up just a scenario.

1257
00:54:00,410 --> 00:54:02,350
So it's not just for medical devices.

1258
00:54:02,350 --> 00:54:03,630
You have a medical device,

1259
00:54:03,630 --> 00:54:04,800
bug bounty, for example.

1260
00:54:04,800 --> 00:54:06,420
If that's a good or a bad thing,

1261
00:54:06,420 --> 00:54:08,440
we could talk hours on that,

1262
00:54:08,440 --> 00:54:11,150
but you don't have the issue
of patient health information.

1263
00:54:11,150 --> 00:54:15,380
So hospitals can't offer hackers

1264
00:54:15,380 --> 00:54:17,350
to come in and poke around the periphery

1265
00:54:17,350 --> 00:54:21,230
of their networks or to give
them that type of experience,

1266
00:54:21,230 --> 00:54:22,120
because of a couple of things.

1267
00:54:22,120 --> 00:54:24,257
One, they're live networks
are taking care of patients.

1268
00:54:24,257 --> 00:54:27,100
Who would hate for
something bad to happen.

1269
00:54:27,100 --> 00:54:29,270
But then two, there's so much protected

1270
00:54:29,270 --> 00:54:31,546
health information floating
around a hospital's network.

1271
00:54:31,546 --> 00:54:36,546
If a security researcher
or a hacker in good faith

1272
00:54:36,680 --> 00:54:39,240
trying to do right, finds something.

1273
00:54:39,240 --> 00:54:40,750
It happens to be commingled

1274
00:54:40,750 --> 00:54:42,470
with patient health information.

1275
00:54:42,470 --> 00:54:44,800
The hospital's required to report that

1276
00:54:44,800 --> 00:54:46,380
as a HIPAA breach, right?

1277
00:54:46,380 --> 00:54:48,310
So there are some, there are some,

1278
00:54:48,310 --> 00:54:50,130
perhaps some would call barriers,

1279
00:54:50,130 --> 00:54:51,851
perhaps some would call safeguards.

1280
00:54:51,851 --> 00:54:56,182
But what I think it's done
is it's made not just the

1281
00:54:56,182 --> 00:54:59,370
delivery of healthcare itself,

1282
00:54:59,370 --> 00:55:02,410
particularly difficult to engage with

1283
00:55:02,410 --> 00:55:04,570
from the hacker perspective.

1284
00:55:04,570 --> 00:55:07,340
I think maybe we don't have
to figure out that solution.

1285
00:55:07,340 --> 00:55:09,380
Maybe that's one of the solution
boundaries we should offer

1286
00:55:09,380 --> 00:55:12,350
and how can hackers get more
involved, give us your ideas.

1287
00:55:12,350 --> 00:55:15,357
But particularly, at hospitals
where we've talked about,

1288
00:55:15,357 --> 00:55:18,560
they don't have a lot of
in-house security expertise,

1289
00:55:18,560 --> 00:55:19,620
if anything,

1290
00:55:19,620 --> 00:55:24,570
but yet they're still asked
to do all of that work.

1291
00:55:24,570 --> 00:55:26,570
How can the community come
together and help them out?

1292
00:55:26,570 --> 00:55:29,205
Because that could be a
lot of good right there.

1293
00:55:29,205 --> 00:55:30,850
- One very easy answer to that

1294
00:55:30,850 --> 00:55:32,580
is just working in healthcare, right?

1295
00:55:32,580 --> 00:55:33,860
So I would encourage anybody

1296
00:55:33,860 --> 00:55:36,290
who's thinking about a career change.

1297
00:55:36,290 --> 00:55:37,900
If you're looking for an area

1298
00:55:37,900 --> 00:55:39,610
where you can make an incredible impact

1299
00:55:39,610 --> 00:55:44,210
and have a lot of really
challenging problems to solve,

1300
00:55:44,210 --> 00:55:46,090
consider working for a hospital,

1301
00:55:46,090 --> 00:55:47,590
or a healthcare delivery organization,

1302
00:55:47,590 --> 00:55:49,420
or being adjacent to that in some ways

1303
00:55:49,420 --> 00:55:52,183
we know that some of these hospitals

1304
00:55:52,183 --> 00:55:54,050
that we talked about in certain areas

1305
00:55:54,050 --> 00:55:55,220
are critically underserved

1306
00:55:55,220 --> 00:55:56,053
and may not even have

1307
00:55:56,053 --> 00:55:58,270
a full-time IT security professionals.

1308
00:55:58,270 --> 00:56:00,990
So one way to get involved is just to

1309
00:56:01,953 --> 00:56:05,830
join that effort as an actual employee

1310
00:56:05,830 --> 00:56:07,243
of a healthcare organization.

1311
00:56:08,420 --> 00:56:11,440
- So I got some specific
suggestions, I think,

1312
00:56:11,440 --> 00:56:12,850
it's funny that you bring up HIPAA

1313
00:56:12,850 --> 00:56:14,870
and other things like that,

1314
00:56:14,870 --> 00:56:17,810
because I think one of the best ways

1315
00:56:17,810 --> 00:56:20,295
that folks like these could get involved,

1316
00:56:20,295 --> 00:56:24,390
whatever, there are
actually specific programs

1317
00:56:24,390 --> 00:56:25,500
that are being offered now,

1318
00:56:25,500 --> 00:56:28,187
within like the federal government

1319
00:56:28,187 --> 00:56:31,832
that puts you in policymakers offices

1320
00:56:31,832 --> 00:56:34,130
and lets you be the cybersecurity expert

1321
00:56:34,130 --> 00:56:35,900
in the room for those people.

1322
00:56:35,900 --> 00:56:39,790
So, there's the tech Congress fellowship.

1323
00:56:39,790 --> 00:56:40,730
Some of you may have heard of it.

1324
00:56:40,730 --> 00:56:43,760
Some of you may have
met some of the fellows,

1325
00:56:43,760 --> 00:56:47,770
Chris (indistinct) who's
probably a well known name

1326
00:56:47,770 --> 00:56:49,130
for some of you all.

1327
00:56:49,130 --> 00:56:50,180
Was a tech Congress fellow.

1328
00:56:50,180 --> 00:56:52,280
He's now works permanently for a Senator

1329
00:56:52,280 --> 00:56:55,300
and is like that senator's tech person,

1330
00:56:55,300 --> 00:56:57,740
but there's been dozens of others there.

1331
00:56:57,740 --> 00:56:59,190
They've got great folks.

1332
00:56:59,190 --> 00:57:01,063
That's a great program
places you with either

1333
00:57:01,063 --> 00:57:03,443
in House office or a Senate office.

1334
00:57:05,117 --> 00:57:06,900
So that's one of the most
direct ways that you can

1335
00:57:06,900 --> 00:57:09,970
actually influence policy
making in this sense is actually

1336
00:57:09,970 --> 00:57:12,403
go be in the room when the
policies is being made.

1337
00:57:12,403 --> 00:57:14,304
So I would highly recommend that.

1338
00:57:14,304 --> 00:57:16,360
I don't know when the
application process opens for

1339
00:57:16,360 --> 00:57:18,950
next year's class, but
Travis Moore's your man.

1340
00:57:18,950 --> 00:57:19,790
So go find Travis.

1341
00:57:19,790 --> 00:57:24,170
The other thing I'll
mentioned is I Am the Cavalry.

1342
00:57:24,170 --> 00:57:27,320
When I Am the Cavalry was first started,

1343
00:57:27,320 --> 00:57:31,160
it was kind of this weird
cookie thing for the Hill,

1344
00:57:31,160 --> 00:57:32,540
for the United States Congress,

1345
00:57:32,540 --> 00:57:34,220
who's very used to dealing with,

1346
00:57:34,220 --> 00:57:37,610
various like buttoned up
everyone's suit and tie

1347
00:57:37,610 --> 00:57:41,410
professional turn associations
and things like that when

1348
00:57:41,410 --> 00:57:43,940
they were trying to get
information on whatever they needed

1349
00:57:43,940 --> 00:57:45,310
to get information on.

1350
00:57:45,310 --> 00:57:46,730
I Am the Cavalry is sort of just kind of

1351
00:57:46,730 --> 00:57:48,617
like came up to the
Hill and was just like,

1352
00:57:48,617 --> 00:57:50,760
"Hi, we're a bunch of
cybersecurity experts.

1353
00:57:50,760 --> 00:57:52,390
We'd like to talk to you about this".

1354
00:57:52,390 --> 00:57:55,770
But the thing is, there were (indistinct)

1355
00:57:55,770 --> 00:58:00,090
groups in like national
policymaking right now.

1356
00:58:00,090 --> 00:58:02,590
Because they were just so

1357
00:58:03,620 --> 00:58:06,240
everyone could tell in
a city where sometimes

1358
00:58:06,240 --> 00:58:10,005
people's motivations are
a little bit shrouded,

1359
00:58:10,005 --> 00:58:11,630
but they just want it to be there.

1360
00:58:11,630 --> 00:58:13,510
They were there with good faith.

1361
00:58:13,510 --> 00:58:15,340
They really just wanted
to do the right thing.

1362
00:58:15,340 --> 00:58:17,120
They were gonna answer whatever questions

1363
00:58:17,120 --> 00:58:20,013
needed to answering without bias.

1364
00:58:21,020 --> 00:58:24,950
So I know FDA works a ton
with I Am the Cavalry.

1365
00:58:24,950 --> 00:58:29,780
I know the Hill works a
ton with I Am the Cavalry.

1366
00:58:29,780 --> 00:58:32,200
So if you wanna get involved

1367
00:58:32,200 --> 00:58:34,328
and have an opportunity to meet with

1368
00:58:34,328 --> 00:58:36,430
the movers and shakers of the country of

1369
00:58:36,430 --> 00:58:37,650
cybersecurity policy,

1370
00:58:37,650 --> 00:58:41,053
I Am the Cavalry is another
really great place to do that.

1371
00:58:45,680 --> 00:58:48,380
- I just would like to perhaps add that

1372
00:58:48,380 --> 00:58:50,161
from other perspective,

1373
00:58:50,161 --> 00:58:53,130
if you want to get hold of working in

1374
00:58:53,130 --> 00:58:55,535
a hospital or getting your hands

1375
00:58:55,535 --> 00:58:58,160
just on some medical equipment, or just,

1376
00:58:58,160 --> 00:59:01,310
having conversations
with the manufacturers.

1377
00:59:01,310 --> 00:59:02,143
Three years ago,

1378
00:59:02,143 --> 00:59:03,830
I spoke at Biohack Village.

1379
00:59:03,830 --> 00:59:05,220
This was my first day on.

1380
00:59:05,220 --> 00:59:08,250
This was my first ever meeting,

1381
00:59:08,250 --> 00:59:10,423
another group of hackers like myself.

1382
00:59:12,040 --> 00:59:15,060
That's how I was set on the
path to do research, right.

1383
00:59:15,060 --> 00:59:16,830
That was how I got access to the,

1384
00:59:16,830 --> 00:59:20,330
and I no longer have to
smuggle them through customs

1385
00:59:20,330 --> 00:59:22,166
at an airport,

1386
00:59:22,166 --> 00:59:23,664
or because I bought them on eBay.

1387
00:59:23,664 --> 00:59:27,823
Because you can't (indistinct)
in South Africa, right?

1388
00:59:27,823 --> 00:59:30,720
So I would buy them in the
UK, I'd go visit a friend.

1389
00:59:30,720 --> 00:59:32,340
Then I'd put them on my luggage

1390
00:59:32,340 --> 00:59:36,090
and smuggle them back home,
so that I can work on them.

1391
00:59:36,090 --> 00:59:39,010
Right. Or even, you
know, when they exploded,

1392
00:59:39,010 --> 00:59:40,570
my first device is eight.

1393
00:59:40,570 --> 00:59:41,460
Give me, give them, give me,

1394
00:59:41,460 --> 00:59:42,900
I wanna have that on my doctor's

1395
00:59:42,900 --> 00:59:44,770
why I'm like sentimental reasons,

1396
00:59:44,770 --> 00:59:48,510
of course, but that's
how I got my hands on.

1397
00:59:48,510 --> 00:59:51,960
But here I walked into a place
in Vegas that had devices

1398
00:59:51,960 --> 00:59:54,810
that had a lab that had everything that,

1399
00:59:54,810 --> 00:59:58,530
makes a young hacker's heart, do jumps.

1400
00:59:58,530 --> 01:00:00,630
So that tickles your fancy.

1401
01:00:00,630 --> 01:00:03,960
Then that's somewhere that
you should go visit, right?

1402
01:00:03,960 --> 01:00:06,120
You should go try your hand at it.

1403
01:00:06,120 --> 01:00:07,800
You should go play with this device

1404
01:00:07,800 --> 01:00:09,320
to speak to the manufacturers

1405
01:00:09,320 --> 01:00:11,053
and go see how they implement it.

1406
01:00:12,010 --> 01:00:14,400
And I mean, even if you're a patient,

1407
01:00:14,400 --> 01:00:16,840
nothing precludes you from giving advice

1408
01:00:16,840 --> 01:00:18,610
at a hospital for me.

1409
01:00:18,610 --> 01:00:20,760
I've given advice from my ICU bed

1410
01:00:20,760 --> 01:00:23,930
is the reason I'm not
allowed a laptop in anymore.

1411
01:00:23,930 --> 01:00:26,760
Right, except for that, the
doctor wants me to ask more.

1412
01:00:26,760 --> 01:00:28,550
Apparently, that's the reason.

1413
01:00:28,550 --> 01:00:33,550
But I mean, give advice,
reach out, get enrolled.

1414
01:00:34,250 --> 01:00:36,490
If someone doesn't listen
to you the first time,

1415
01:00:36,490 --> 01:00:39,340
keep on trying, because
it's a patient's game.

1416
01:00:39,340 --> 01:00:41,610
It's not gonna happen overnight.

1417
01:00:41,610 --> 01:00:45,040
I've learned, I've dealt with many bodies

1418
01:00:45,040 --> 01:00:49,193
and it's not gonna happen fast,
because it's a big industry.

1419
01:00:50,250 --> 01:00:53,030
Just get involved, get your hands dirty.

1420
01:00:53,030 --> 01:00:55,080
'Cause that's how we change the world.

1421
01:00:55,080 --> 01:00:57,350
Every new researcher
that comes into the fold

1422
01:00:57,350 --> 01:01:00,180
is a new mind to things differently.

1423
01:01:00,180 --> 01:01:03,363
And that's, I think how we
change things one step at a time.

1424
01:01:05,270 --> 01:01:06,670
- I love that because I think

1425
01:01:06,670 --> 01:01:09,040
the idiosyncratic notion that it

1426
01:01:09,040 --> 01:01:12,360
takes a specific individual
or an elite person or someone

1427
01:01:12,360 --> 01:01:14,850
who's an expert to make a change,

1428
01:01:14,850 --> 01:01:17,309
it is absolutely a misconception.

1429
01:01:17,309 --> 01:01:19,135
So the notion of just getting involved,

1430
01:01:19,135 --> 01:01:21,010
there's no inner circle here, right?

1431
01:01:21,010 --> 01:01:23,050
Like I think every
person in this community

1432
01:01:23,050 --> 01:01:25,250
is more than willing to
share their networks,

1433
01:01:25,250 --> 01:01:26,170
share their expertise

1434
01:01:26,170 --> 01:01:29,380
and share whatever corner of
this problem that they have.

1435
01:01:29,380 --> 01:01:31,330
It's a really hard problem.

1436
01:01:31,330 --> 01:01:34,470
We need all the talent that
we can muster up right now

1437
01:01:34,470 --> 01:01:35,730
to really make a change.

1438
01:01:35,730 --> 01:01:38,980
I think if we look at
the diversity of roles,

1439
01:01:38,980 --> 01:01:41,650
functions, experience,
thought, process, background,

1440
01:01:41,650 --> 01:01:43,370
education, everything,

1441
01:01:43,370 --> 01:01:46,540
any under representation
of that population

1442
01:01:46,540 --> 01:01:50,210
is indicative of missing
a potential attack factor.

1443
01:01:50,210 --> 01:01:52,040
We really have to really
have to account for that

1444
01:01:52,040 --> 01:01:54,240
and try to bring in as
many folks as we can.

1445
01:01:55,260 --> 01:01:58,027
- Yeah, I think this is
a cool tool to enjoy.

1446
01:01:58,027 --> 01:02:00,830
How many hackers can we
round up with one guy?

1447
01:02:00,830 --> 01:02:03,277
Well, not, it's not just
even hackers, right?

1448
01:02:04,690 --> 01:02:05,993
Everyone from physicians,

1449
01:02:05,993 --> 01:02:09,970
from patients, from
builders and policymakers.

1450
01:02:09,970 --> 01:02:13,960
I think if we start
breaking down the silos,

1451
01:02:13,960 --> 01:02:16,450
which we've been functioning in

1452
01:02:16,450 --> 01:02:18,060
and independently working,

1453
01:02:18,060 --> 01:02:21,530
and start this collective movement,

1454
01:02:21,530 --> 01:02:23,203
that's how we change the world.

1455
01:02:24,730 --> 01:02:26,870
It's not a one person thing.

1456
01:02:26,870 --> 01:02:29,640
It's never gonna be one
person that's gonna come up

1457
01:02:29,640 --> 01:02:33,980
with the magic solution
or the silver bullet.

1458
01:02:33,980 --> 01:02:37,306
Right. it takes more than one village,

1459
01:02:37,306 --> 01:02:40,013
as I always say, to solve the problem.

1460
01:02:41,540 --> 01:02:43,557
I think that's time into (indistinct),

1461
01:02:45,130 --> 01:02:48,183
we as a society build
together instead of a bot,

1462
01:02:49,520 --> 01:02:52,960
because we've seen what
a virus can do, right?

1463
01:02:52,960 --> 01:02:54,850
It's locked us in our houses.

1464
01:02:54,850 --> 01:02:56,917
So I think it's time
we take our power back

1465
01:02:56,917 --> 01:03:00,976
and start moving the world
into a positive future.

1466
01:03:00,976 --> 01:03:03,440
'Cause I can tell you from
a patient perspective,

1467
01:03:03,440 --> 01:03:05,660
not having access to being able to go into

1468
01:03:05,660 --> 01:03:08,800
a cardiologist office, because
we are afraid of COVID,

1469
01:03:08,800 --> 01:03:11,933
because currently it's more
dangerous going into a hospital.

1470
01:03:12,770 --> 01:03:17,680
If denial of patient
care is a non-acceptable

1471
01:03:17,680 --> 01:03:21,430
non-negotiable, not gonna stand for it.

1472
01:03:21,430 --> 01:03:24,257
I think we should be kicking
down the doors and saying,

1473
01:03:24,257 --> 01:03:28,047
"No, now I was at the
time, not yesterday, now."

1474
01:03:31,120 --> 01:03:32,030
- I love it.

1475
01:03:32,030 --> 01:03:34,780
Are there any better sentiments
to go out on than that?

1476
01:03:36,460 --> 01:03:39,710
I think it's easy to be cynical

1477
01:03:39,710 --> 01:03:40,960
about all this and it's easy to say

1478
01:03:40,960 --> 01:03:42,310
we're having the same conversations

1479
01:03:42,310 --> 01:03:44,210
year after year and the
problems are still there.

1480
01:03:44,210 --> 01:03:46,620
But I mean, you know, in 2015,

1481
01:03:46,620 --> 01:03:48,240
the Biohacking Village didn't exist

1482
01:03:48,240 --> 01:03:51,070
in the idea of people
from device manufacturers,

1483
01:03:51,070 --> 01:03:54,660
bringing stuff for hackers
to poke and prod at would be

1484
01:03:54,660 --> 01:03:55,820
laughed out of the room.

1485
01:03:55,820 --> 01:03:58,320
So for people who don't believe

1486
01:03:58,320 --> 01:03:59,930
that we can do awesome things

1487
01:03:59,930 --> 01:04:01,110
when we work together and hang out

1488
01:04:01,110 --> 01:04:03,610
at places like DEFCON I mean,

1489
01:04:03,610 --> 01:04:05,050
we have evidence to the contrary.

1490
01:04:05,050 --> 01:04:10,050
So I think that's about an
hour and I'm looking forward to

1491
01:04:10,320 --> 01:04:12,660
seeing you guys in a
little bit for a Q and A.

1492
01:04:14,990 --> 01:04:15,870
- Take care, everyone.

1493
01:04:15,870 --> 01:04:17,470
Thank you DEFCON for having us.

1494
01:04:17,470 --> 01:04:20,060
A shout out to Nikita, especially.

1495
01:04:20,060 --> 01:04:22,140
for taking another shot at us.

1496
01:04:22,140 --> 01:04:24,330
We're gonna go ahead and
open up the Q and A here

1497
01:04:24,330 --> 01:04:28,543
in five, four, three, two, one.

