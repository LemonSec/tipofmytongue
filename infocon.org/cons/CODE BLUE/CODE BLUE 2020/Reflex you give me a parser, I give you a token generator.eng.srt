1
00:01:20,960 --> 00:01:23,680
okay so let's start in english now

2
00:01:23,680 --> 00:01:26,400
i'm paulo montezel and i'm going to talk

3
00:01:26,400 --> 00:01:27,280
about

4
00:01:27,280 --> 00:01:29,600
reflex a tool that i built that takes a

5
00:01:29,600 --> 00:01:31,040
a parser

6
00:01:31,040 --> 00:01:32,560
in a binary and gives you a token

7
00:01:32,560 --> 00:01:34,960
generator

8
00:01:34,960 --> 00:01:37,040
about myself i'm a ctf player with

9
00:01:37,040 --> 00:01:38,079
macaroni

10
00:01:38,079 --> 00:01:39,920
and i'm currently working as a

11
00:01:39,920 --> 00:01:42,799
contractor at revenge srls

12
00:01:42,799 --> 00:01:44,560
an italian company that's creating an

13
00:01:44,560 --> 00:01:46,560
llvm based compiler

14
00:01:46,560 --> 00:01:48,320
i'm a security research engineer and i

15
00:01:48,320 --> 00:01:49,759
mainly work on dynamic binary

16
00:01:49,759 --> 00:01:51,360
translation and machine learning

17
00:01:51,360 --> 00:01:53,520
for reverse engineering i'm also

18
00:01:53,520 --> 00:01:54,880
interested in reverse engineering

19
00:01:54,880 --> 00:01:57,759
i'm a reverse engineer and full system

20
00:01:57,759 --> 00:02:00,960
fuzzing and obfuscation

21
00:02:01,119 --> 00:02:03,360
okay so the presentation is going to

22
00:02:03,360 --> 00:02:04,640
start with a brief introduction about

23
00:02:04,640 --> 00:02:06,240
the tool how it was born and why it's

24
00:02:06,240 --> 00:02:07,200
useful

25
00:02:07,200 --> 00:02:08,399
and then we're going to talk about the

26
00:02:08,399 --> 00:02:10,959
technical details so let's start with

27
00:02:10,959 --> 00:02:14,000
what's reflex reflex is a tool

28
00:02:14,000 --> 00:02:17,280
that is able to extract

29
00:02:17,280 --> 00:02:19,599
valid tokens and regular expressions

30
00:02:19,599 --> 00:02:20,640
from

31
00:02:20,640 --> 00:02:25,440
a new bison-generated parser

32
00:02:25,680 --> 00:02:29,760
okay the scenario in which you might

33
00:02:29,760 --> 00:02:31,760
want to use something like this is you

34
00:02:31,760 --> 00:02:33,680
are looking at a binary

35
00:02:33,680 --> 00:02:35,599
that implements a custom language of

36
00:02:35,599 --> 00:02:38,000
some kind for which you don't have

37
00:02:38,000 --> 00:02:39,519
documentation or maybe you have it but

38
00:02:39,519 --> 00:02:41,360
it's not well written

39
00:02:41,360 --> 00:02:42,879
and maybe you don't have or maybe you

40
00:02:42,879 --> 00:02:46,879
have a few valid samples

41
00:02:46,879 --> 00:02:48,319
and you might not be able to instrument

42
00:02:48,319 --> 00:02:50,319
the target efficiently for example

43
00:02:50,319 --> 00:02:53,518
let's think about firmware

44
00:02:54,400 --> 00:02:58,239
i was born well last year the nsa

45
00:02:58,239 --> 00:03:00,480
released gidra and open source the

46
00:03:00,480 --> 00:03:02,000
compiler

47
00:03:02,000 --> 00:03:03,360
but at the beginning the source code was

48
00:03:03,360 --> 00:03:05,280
not available

49
00:03:05,280 --> 00:03:08,480
anyway this uh unofficial gita account

50
00:03:08,480 --> 00:03:10,400
started screaming that the sources were

51
00:03:10,400 --> 00:03:12,400
available in the zip files

52
00:03:12,400 --> 00:03:14,400
uh in the binary distribution which was

53
00:03:14,400 --> 00:03:16,319
true but only for the java part

54
00:03:16,319 --> 00:03:19,120
so i told them that yeah the compiler

55
00:03:19,120 --> 00:03:19,840
part

56
00:03:19,840 --> 00:03:22,000
which is the most interesting it's not

57
00:03:22,000 --> 00:03:23,440
available yet

58
00:03:23,440 --> 00:03:25,680
and they replied in a not so friendly

59
00:03:25,680 --> 00:03:26,990
way so i decided to

60
00:03:26,990 --> 00:03:28,080
[Music]

61
00:03:28,080 --> 00:03:31,360
uh basically get my revenge against the

62
00:03:31,360 --> 00:03:32,879
nsa

63
00:03:32,879 --> 00:03:37,200
so i wrote this tool um that takes

64
00:03:37,200 --> 00:03:39,599
the that took this part of the gyro the

65
00:03:39,599 --> 00:03:40,959
compiler

66
00:03:40,959 --> 00:03:43,360
which is called slay and it's able to

67
00:03:43,360 --> 00:03:44,400
extract

68
00:03:44,400 --> 00:03:47,840
the tokens for the for the for the

69
00:03:47,840 --> 00:03:50,640
for that binary

70
00:03:51,280 --> 00:03:53,760
that allowed me after some 10 minutes in

71
00:03:53,760 --> 00:03:54,799
afl to

72
00:03:54,799 --> 00:03:56,640
find an integer underflow which is still

73
00:03:56,640 --> 00:03:58,480
there in the

74
00:03:58,480 --> 00:03:59,920
in the current version but it's not

75
00:03:59,920 --> 00:04:01,840
exploitable

76
00:04:01,840 --> 00:04:04,319
but anyway i had my victory against the

77
00:04:04,319 --> 00:04:06,400
nsa

78
00:04:06,400 --> 00:04:09,360
then again in august last year we were

79
00:04:09,360 --> 00:04:09,840
at

80
00:04:09,840 --> 00:04:12,560
defcon ctf with macaroni and we were

81
00:04:12,560 --> 00:04:13,760
able to use my tool

82
00:04:13,760 --> 00:04:15,519
to gain advantage over the other teams

83
00:04:15,519 --> 00:04:16,880
because one of the challenges

84
00:04:16,880 --> 00:04:20,238
i was using bison

85
00:04:20,880 --> 00:04:22,720
then i quit my psd and here we are at

86
00:04:22,720 --> 00:04:25,199
cod blue

87
00:04:25,360 --> 00:04:29,360
so why you should be interested

88
00:04:29,360 --> 00:04:32,560
in in reflex well

89
00:04:32,560 --> 00:04:35,199
analyzing parsers in binaries is very

90
00:04:35,199 --> 00:04:36,479
time consuming

91
00:04:36,479 --> 00:04:39,680
most of the times the code is not

92
00:04:39,680 --> 00:04:41,680
manually written but it's auto-generated

93
00:04:41,680 --> 00:04:43,840
from some kind of specification

94
00:04:43,840 --> 00:04:46,960
and in the case of language parsers you

95
00:04:46,960 --> 00:04:50,240
often have finite state machines

96
00:04:50,240 --> 00:04:53,919
that are encoded either as table based

97
00:04:53,919 --> 00:04:57,040
parsers like flex and bison or

98
00:04:57,040 --> 00:05:00,800
control flow graph based parsers

99
00:05:00,800 --> 00:05:03,919
so the table based parser are basically

100
00:05:03,919 --> 00:05:06,400
a bunch of tables that encode a finite

101
00:05:06,400 --> 00:05:07,600
state machine plus

102
00:05:07,600 --> 00:05:09,919
a generic matching function which in

103
00:05:09,919 --> 00:05:10,800
this case is called

104
00:05:10,800 --> 00:05:15,280
yylx while in the other cases the

105
00:05:15,280 --> 00:05:17,199
the finite state machine is encoded in

106
00:05:17,199 --> 00:05:18,960
the code itself

107
00:05:18,960 --> 00:05:21,840
like you can see here

108
00:05:23,600 --> 00:05:26,320
so how do you get the tokens out of the

109
00:05:26,320 --> 00:05:27,600
binary well

110
00:05:27,600 --> 00:05:30,320
the most of the literature around this

111
00:05:30,320 --> 00:05:30,880
subject

112
00:05:30,880 --> 00:05:34,080
is centered on dynamic approaches

113
00:05:34,080 --> 00:05:35,759
and they assume that the target can be

114
00:05:35,759 --> 00:05:37,680
executed and so that

115
00:05:37,680 --> 00:05:41,280
you can also get coverage information

116
00:05:41,280 --> 00:05:42,160
out of

117
00:05:42,160 --> 00:05:45,840
some randomly generated input but this

118
00:05:45,840 --> 00:05:48,639
uh approach these approaches fail on

119
00:05:48,639 --> 00:05:50,560
table based parsers because

120
00:05:50,560 --> 00:05:53,600
the the code that does the matching

121
00:05:53,600 --> 00:05:56,639
on the input is the generic function and

122
00:05:56,639 --> 00:05:57,759
it's always the same

123
00:05:57,759 --> 00:05:59,840
so you don't get a valuable coverage out

124
00:05:59,840 --> 00:06:01,759
of it

125
00:06:01,759 --> 00:06:04,560
they also usually require large covers

126
00:06:04,560 --> 00:06:04,960
of

127
00:06:04,960 --> 00:06:08,400
a large corpus of valid inputs

128
00:06:08,400 --> 00:06:11,120
so you can try to guess the format or

129
00:06:11,120 --> 00:06:12,479
make strong assumption on program

130
00:06:12,479 --> 00:06:14,319
behavior for example

131
00:06:14,319 --> 00:06:17,919
an early exit in case of error

132
00:06:18,240 --> 00:06:21,840
some papers go as far as saying that uh

133
00:06:21,840 --> 00:06:23,680
table-based parsers are not interesting

134
00:06:23,680 --> 00:06:26,080
because if you have a table based parser

135
00:06:26,080 --> 00:06:27,440
you have the grammar

136
00:06:27,440 --> 00:06:30,080
but what about close source software

137
00:06:30,080 --> 00:06:32,318
right

138
00:06:32,400 --> 00:06:33,759
these are some popular open source

139
00:06:33,759 --> 00:06:36,880
parsers parser generators rather

140
00:06:36,880 --> 00:06:38,479
we're going to focus on bizon and flex

141
00:06:38,479 --> 00:06:39,840
specifically on flex which is the

142
00:06:39,840 --> 00:06:42,479
tokenizer

143
00:06:42,800 --> 00:06:45,280
you can find bison in many places for

144
00:06:45,280 --> 00:06:46,400
example

145
00:06:46,400 --> 00:06:49,840
i found it in vxworks which is a very

146
00:06:49,840 --> 00:06:53,199
popular commercial real-time operating

147
00:06:53,199 --> 00:06:53,759
system

148
00:06:53,759 --> 00:06:57,919
that's also used in plc's you can find

149
00:06:57,919 --> 00:07:00,880
bison inside out oit which is a windows

150
00:07:00,880 --> 00:07:02,479
automation software

151
00:07:02,479 --> 00:07:04,560
or you can find it in sixer routers for

152
00:07:04,560 --> 00:07:07,039
example

153
00:07:07,039 --> 00:07:09,120
you can probably find it somewhere also

154
00:07:09,120 --> 00:07:10,960
in in

155
00:07:10,960 --> 00:07:14,080
bosch india software because they were

156
00:07:14,080 --> 00:07:16,400
asking about commercial licensing stuff

157
00:07:16,400 --> 00:07:18,800
on the mailing list so if you have any

158
00:07:18,800 --> 00:07:20,319
information

159
00:07:20,319 --> 00:07:23,120
i would like to know

160
00:07:23,440 --> 00:07:26,639
and let's get to the technical part but

161
00:07:26,639 --> 00:07:27,520
then again

162
00:07:27,520 --> 00:07:30,720
i need to give some a refresher on

163
00:07:30,720 --> 00:07:31,840
parcel theory

164
00:07:31,840 --> 00:07:33,440
very simple then we're going to talk

165
00:07:33,440 --> 00:07:35,360
about how we can identify the

166
00:07:35,360 --> 00:07:36,960
information we need in a binary in order

167
00:07:36,960 --> 00:07:37,440
to

168
00:07:37,440 --> 00:07:41,520
recover uh the fine state machine

169
00:07:41,520 --> 00:07:42,880
and from the finite state machine we are

170
00:07:42,880 --> 00:07:45,440
able to recover the regular expressions

171
00:07:45,440 --> 00:07:49,360
and generate value tokens out of them

172
00:07:50,400 --> 00:07:53,440
so very simple and

173
00:07:53,440 --> 00:07:56,639
yeah too simple maybe parser theory as i

174
00:07:56,639 --> 00:07:58,319
said earlier a developer usually writes

175
00:07:58,319 --> 00:08:00,000
some kind of specification in the case

176
00:08:00,000 --> 00:08:01,440
of language parsers

177
00:08:01,440 --> 00:08:05,039
usually it's a grammar of of some kind

178
00:08:05,039 --> 00:08:06,400
and then there is a tool that takes the

179
00:08:06,400 --> 00:08:08,879
grammar and outputs uh two pieces of

180
00:08:08,879 --> 00:08:10,400
code one is the lecture and one is the

181
00:08:10,400 --> 00:08:12,720
parser and they work together

182
00:08:12,720 --> 00:08:15,199
the lexer is the first part that touches

183
00:08:15,199 --> 00:08:15,840
the input

184
00:08:15,840 --> 00:08:18,799
and it's basically

185
00:08:19,360 --> 00:08:21,599
a piece of code that tokenizes the input

186
00:08:21,599 --> 00:08:22,639
and so you get

187
00:08:22,639 --> 00:08:24,479
as an input you get a stream of bytes

188
00:08:24,479 --> 00:08:26,000
and as an output you get

189
00:08:26,000 --> 00:08:29,039
a stream of tokens

190
00:08:29,039 --> 00:08:31,440
then comes the parser which takes the

191
00:08:31,440 --> 00:08:32,320
the tokens

192
00:08:32,320 --> 00:08:34,000
and put them in some structure

193
00:08:34,000 --> 00:08:35,440
representation

194
00:08:35,440 --> 00:08:37,360
most of the times especially for

195
00:08:37,360 --> 00:08:38,479
language parsers

196
00:08:38,479 --> 00:08:41,279
it's some kind of abstract syntax stream

197
00:08:41,279 --> 00:08:44,959
as the one you can see in the example

198
00:08:45,600 --> 00:08:49,200
but how do we get how does flex work and

199
00:08:49,200 --> 00:08:50,640
how does it get to the final state

200
00:08:50,640 --> 00:08:51,680
machine

201
00:08:51,680 --> 00:08:54,160
well what you do when you when you write

202
00:08:54,160 --> 00:08:54,880
a

203
00:08:54,880 --> 00:08:58,080
alexa using flex is you define

204
00:08:58,080 --> 00:09:00,880
a set of rules these ones that are made

205
00:09:00,880 --> 00:09:01,440
like this

206
00:09:01,440 --> 00:09:03,040
on the left you have a regular

207
00:09:03,040 --> 00:09:04,560
expression like this one

208
00:09:04,560 --> 00:09:07,120
and on the right you have some kind of

209
00:09:07,120 --> 00:09:09,839
token id

210
00:09:09,920 --> 00:09:12,560
so you can see here i i put an ename to

211
00:09:12,560 --> 00:09:13,440
give a symbol

212
00:09:13,440 --> 00:09:16,480
give a symbolic name to the tokens

213
00:09:16,480 --> 00:09:19,760
so for the finest two flex takes this

214
00:09:19,760 --> 00:09:22,560
and generate some code

215
00:09:22,560 --> 00:09:27,518
that that uses this finite state machine

216
00:09:27,600 --> 00:09:29,279
for those of you who are not familiar

217
00:09:29,279 --> 00:09:30,640
with fine state machines

218
00:09:30,640 --> 00:09:33,600
so basically they are some kind of

219
00:09:33,600 --> 00:09:34,800
graphs

220
00:09:34,800 --> 00:09:36,160
and you have a starting state in this

221
00:09:36,160 --> 00:09:38,480
case which is one this is the lab

222
00:09:38,480 --> 00:09:41,120
the label is the id of the of the state

223
00:09:41,120 --> 00:09:43,600
state or node is the same

224
00:09:43,600 --> 00:09:46,399
and then you have some uh some state

225
00:09:46,399 --> 00:09:46,800
with a

226
00:09:46,800 --> 00:09:50,000
double circle that means that if

227
00:09:50,000 --> 00:09:52,000
from the starting state we are able to

228
00:09:52,000 --> 00:09:53,279
reach

229
00:09:53,279 --> 00:09:55,279
uh for example this state with a double

230
00:09:55,279 --> 00:09:56,640
circle

231
00:09:56,640 --> 00:09:58,720
the current input is a valid token so if

232
00:09:58,720 --> 00:10:00,560
we get d then e then f

233
00:10:00,560 --> 00:10:02,640
we get a valid token in state four of

234
00:10:02,640 --> 00:10:05,040
type define okay

235
00:10:05,040 --> 00:10:06,959
and this is the same for the other for

236
00:10:06,959 --> 00:10:09,359
the others

237
00:10:11,200 --> 00:10:14,720
but then flex doesn't only generate

238
00:10:14,720 --> 00:10:17,600
this fine state machine for performance

239
00:10:17,600 --> 00:10:18,320
reason

240
00:10:18,320 --> 00:10:21,680
and for historical reason uh flex

241
00:10:21,680 --> 00:10:22,399
compresses

242
00:10:22,399 --> 00:10:24,800
this this fine state machine using some

243
00:10:24,800 --> 00:10:26,320
techniques from the dragon book which is

244
00:10:26,320 --> 00:10:27,040
a

245
00:10:27,040 --> 00:10:30,560
very popular compiler book

246
00:10:30,560 --> 00:10:32,240
and what you get as an output is a bunch

247
00:10:32,240 --> 00:10:35,279
of tables which are equivalent to the

248
00:10:35,279 --> 00:10:38,399
to the graph on the left plus

249
00:10:38,399 --> 00:10:40,720
this generic matching function which is

250
00:10:40,720 --> 00:10:43,200
in this case is called yylx

251
00:10:43,200 --> 00:10:44,800
and keep in mind these tables because we

252
00:10:44,800 --> 00:10:46,959
are going to see them again

253
00:10:46,959 --> 00:10:49,518
okay so

254
00:10:50,880 --> 00:10:55,040
what do we need to extract

255
00:10:55,040 --> 00:10:58,640
the fine steel machine from a binary

256
00:10:58,959 --> 00:11:00,800
well it turns out that we just need the

257
00:11:00,800 --> 00:11:02,480
tables and

258
00:11:02,480 --> 00:11:05,920
the size of their elements plus

259
00:11:05,920 --> 00:11:08,800
this uh small this integer constant that

260
00:11:08,800 --> 00:11:09,120
we

261
00:11:09,120 --> 00:11:12,160
we find in in the function code okay

262
00:11:12,160 --> 00:11:15,120
once we have that we can recover the

263
00:11:15,120 --> 00:11:18,320
original finest machine

264
00:11:19,040 --> 00:11:21,279
and the steps needed to do that is well

265
00:11:21,279 --> 00:11:22,640
first you need to find the matching

266
00:11:22,640 --> 00:11:25,040
function

267
00:11:25,040 --> 00:11:27,440
then you need to find the tables and

268
00:11:27,440 --> 00:11:28,720
we're going to do it in

269
00:11:28,720 --> 00:11:30,480
a simple way using some data flow

270
00:11:30,480 --> 00:11:32,720
analysis

271
00:11:32,720 --> 00:11:35,920
then we can infer the element size of

272
00:11:35,920 --> 00:11:37,120
the tables

273
00:11:37,120 --> 00:11:40,640
from the memory accesses in the code

274
00:11:40,640 --> 00:11:43,040
and finally we can interpret the tables

275
00:11:43,040 --> 00:11:44,800
so that we recover the original fine

276
00:11:44,800 --> 00:11:47,359
state machine

277
00:11:47,760 --> 00:11:50,959
so the first part to identify the table

278
00:11:50,959 --> 00:11:53,839
we can start with gidra okay we load the

279
00:11:53,839 --> 00:11:54,480
binary

280
00:11:54,480 --> 00:11:56,880
and we let it analyze it and then we

281
00:11:56,880 --> 00:11:58,800
extract the data flow graph

282
00:11:58,800 --> 00:12:02,240
for the matching function

283
00:12:02,399 --> 00:12:04,000
i i'm not going to talk about how you

284
00:12:04,000 --> 00:12:05,760
find the matching function because it's

285
00:12:05,760 --> 00:12:08,160
orthogonal to this work

286
00:12:08,160 --> 00:12:10,880
there are many many um papers about

287
00:12:10,880 --> 00:12:12,480
function recognition you can look them

288
00:12:12,480 --> 00:12:14,000
up

289
00:12:14,000 --> 00:12:16,399
okay so we have the data flow graph here

290
00:12:16,399 --> 00:12:18,320
it gets simplified

291
00:12:18,320 --> 00:12:21,279
by our tool and then we put it inside

292
00:12:21,279 --> 00:12:22,639
apache tinker pop

293
00:12:22,639 --> 00:12:25,440
and apache tinker pop is a graph db an

294
00:12:25,440 --> 00:12:26,959
open source graph db

295
00:12:26,959 --> 00:12:29,600
which uses gremlin as a query language

296
00:12:29,600 --> 00:12:31,120
so you can

297
00:12:31,120 --> 00:12:35,279
write query on the on the graph

298
00:12:35,279 --> 00:12:37,440
so let's see an example of a query let's

299
00:12:37,440 --> 00:12:38,639
say we want to match

300
00:12:38,639 --> 00:12:41,519
this code this is taken from the

301
00:12:41,519 --> 00:12:43,680
matching function

302
00:12:43,680 --> 00:12:46,160
uh of course when you analyze a target

303
00:12:46,160 --> 00:12:47,839
this is going to be the compile code so

304
00:12:47,839 --> 00:12:48,639
it's not going to

305
00:12:48,639 --> 00:12:50,320
be as nice and you might not have

306
00:12:50,320 --> 00:12:52,800
symbols but

307
00:12:52,800 --> 00:12:54,720
just to explain i'm going to show the

308
00:12:54,720 --> 00:12:56,560
the source code

309
00:12:56,560 --> 00:12:58,079
let's say we want to identify why why

310
00:12:58,079 --> 00:13:00,079
def so what we can do

311
00:13:00,079 --> 00:13:02,320
is we're going to look in the data flow

312
00:13:02,320 --> 00:13:03,839
all the places in which we have

313
00:13:03,839 --> 00:13:07,040
a constant sorry a variable

314
00:13:07,040 --> 00:13:09,440
that ends up being used as an index

315
00:13:09,440 --> 00:13:11,120
inside a table

316
00:13:11,120 --> 00:13:13,600
which is a global variable itself and

317
00:13:13,600 --> 00:13:14,880
the result is stored

318
00:13:14,880 --> 00:13:19,120
in the same variable and then

319
00:13:19,120 --> 00:13:22,240
the the data flow reaches this

320
00:13:22,240 --> 00:13:23,120
comparison

321
00:13:23,120 --> 00:13:26,399
with uh with a constant and

322
00:13:26,399 --> 00:13:28,560
then we have a conditional jump to reach

323
00:13:28,560 --> 00:13:30,800
this part of of the code

324
00:13:30,800 --> 00:13:33,360
and you can represent this in this kind

325
00:13:33,360 --> 00:13:34,720
of way this is a simplified version of

326
00:13:34,720 --> 00:13:36,160
the

327
00:13:36,160 --> 00:13:38,880
of what you might write in in gremlin so

328
00:13:38,880 --> 00:13:40,560
you write okay give me

329
00:13:40,560 --> 00:13:42,399
every places in which there are two

330
00:13:42,399 --> 00:13:44,639
global variables that are added together

331
00:13:44,639 --> 00:13:48,800
and then they are used as a pointer

332
00:13:48,800 --> 00:13:50,959
that flows into uh sorry that gets the

333
00:13:50,959 --> 00:13:52,240
reference the reference

334
00:13:52,240 --> 00:13:54,320
and then flows into a comparison

335
00:13:54,320 --> 00:13:55,360
operator that

336
00:13:55,360 --> 00:13:59,199
flows into a conditional jump

337
00:13:59,199 --> 00:14:01,279
of course this might get you the

338
00:14:01,279 --> 00:14:03,120
duplicates

339
00:14:03,120 --> 00:14:06,800
but if you piece together

340
00:14:06,800 --> 00:14:10,079
many small queries like this

341
00:14:10,079 --> 00:14:12,480
you are able to recover the tables the

342
00:14:12,480 --> 00:14:14,240
table names and their size

343
00:14:14,240 --> 00:14:17,279
and also like the the magic value that

344
00:14:17,279 --> 00:14:18,000
we want to

345
00:14:18,000 --> 00:14:20,399
to find

346
00:14:21,120 --> 00:14:24,160
okay so how do we get from the table

347
00:14:24,160 --> 00:14:26,160
that we found using data flow analysis

348
00:14:26,160 --> 00:14:29,760
to the final state machine we need to

349
00:14:29,760 --> 00:14:30,560
reverse

350
00:14:30,560 --> 00:14:33,199
the the effect of the algorithms from

351
00:14:33,199 --> 00:14:34,160
the dragon ball

352
00:14:34,160 --> 00:14:37,839
so again we have the tables

353
00:14:37,839 --> 00:14:40,160
and what we do is we start from the

354
00:14:40,160 --> 00:14:41,040
starting node

355
00:14:41,040 --> 00:14:44,480
and we want to visit all the other nodes

356
00:14:44,480 --> 00:14:48,399
in the compressed tables

357
00:14:48,399 --> 00:14:51,120
and this is gonna allow us to recreate

358
00:14:51,120 --> 00:14:52,079
the original

359
00:14:52,079 --> 00:14:56,639
uh the original fine state machine

360
00:14:56,639 --> 00:14:59,199
as you can see here we we don't have the

361
00:14:59,199 --> 00:15:00,399
enum anymore because

362
00:15:00,399 --> 00:15:02,240
this is from a binary so we don't know

363
00:15:02,240 --> 00:15:03,519
the symbolic name of

364
00:15:03,519 --> 00:15:07,760
token type 2 but it's equivalent

365
00:15:09,040 --> 00:15:11,040
table decoding is a bit complicated so

366
00:15:11,040 --> 00:15:13,199
i'm going to give a simplified

367
00:15:13,199 --> 00:15:15,600
version of it so let's assume that you

368
00:15:15,600 --> 00:15:16,880
start that you have a table

369
00:15:16,880 --> 00:15:18,639
which is called transition table that

370
00:15:18,639 --> 00:15:20,160
gives you the next state

371
00:15:20,160 --> 00:15:21,839
based on the current state and the input

372
00:15:21,839 --> 00:15:23,199
character okay

373
00:15:23,199 --> 00:15:26,959
what you can do is this so

374
00:15:26,959 --> 00:15:28,639
you have the states here and here the

375
00:15:28,639 --> 00:15:31,519
input the current input character

376
00:15:31,519 --> 00:15:33,440
if we start for example in the initial

377
00:15:33,440 --> 00:15:36,880
state of our of our graph

378
00:15:36,880 --> 00:15:38,320
and we want to know what happens when

379
00:15:38,320 --> 00:15:40,240
the the user types

380
00:15:40,240 --> 00:15:42,320
a d or we have a file that starts with a

381
00:15:42,320 --> 00:15:43,440
d

382
00:15:43,440 --> 00:15:45,680
we go into the table look at the the

383
00:15:45,680 --> 00:15:46,560
state number one

384
00:15:46,560 --> 00:15:48,880
which is this column and we cross

385
00:15:48,880 --> 00:15:50,240
reference it with

386
00:15:50,240 --> 00:15:51,839
the row relative to the current

387
00:15:51,839 --> 00:15:53,519
character which is d

388
00:15:53,519 --> 00:15:55,680
and what we find is that the next state

389
00:15:55,680 --> 00:15:56,720
is two

390
00:15:56,720 --> 00:15:59,600
and as you can see here when you get an

391
00:15:59,600 --> 00:16:00,880
input d

392
00:16:00,880 --> 00:16:03,680
and you are in state one you reach state

393
00:16:03,680 --> 00:16:05,199
two

394
00:16:05,199 --> 00:16:07,040
of course this is a simplified version

395
00:16:07,040 --> 00:16:08,320
because as i said

396
00:16:08,320 --> 00:16:10,000
the tables are compressed using some

397
00:16:10,000 --> 00:16:12,000
tricky algorithms

398
00:16:12,000 --> 00:16:15,040
but you can look at the code because

399
00:16:15,040 --> 00:16:16,320
there's not enough time for me to

400
00:16:16,320 --> 00:16:18,399
explain everything indeed sorry in

401
00:16:18,399 --> 00:16:20,800
detail

402
00:16:21,680 --> 00:16:24,240
so now we have the final state machine

403
00:16:24,240 --> 00:16:25,759
and we want to recover the regular

404
00:16:25,759 --> 00:16:28,240
expression

405
00:16:30,000 --> 00:16:31,440
a way to do it and this is what we

406
00:16:31,440 --> 00:16:36,480
implemented is this one so we have many

407
00:16:36,480 --> 00:16:38,000
accepting states in our fine state

408
00:16:38,000 --> 00:16:40,320
machine

409
00:16:40,320 --> 00:16:42,240
but let's say we are interested only in

410
00:16:42,240 --> 00:16:43,519
the token at this step

411
00:16:43,519 --> 00:16:46,720
only the tokens of type 2 so

412
00:16:46,720 --> 00:16:48,480
we want to find all the ways that we can

413
00:16:48,480 --> 00:16:50,000
reach state

414
00:16:50,000 --> 00:16:53,040
four and seven starting from one what

415
00:16:53,040 --> 00:16:54,160
you can do is

416
00:16:54,160 --> 00:16:56,320
take the other accepting states and make

417
00:16:56,320 --> 00:16:57,519
them non-accepting

418
00:16:57,519 --> 00:17:00,240
so like this

419
00:17:02,160 --> 00:17:04,640
then uh what you can do is you reverse

420
00:17:04,640 --> 00:17:06,160
the edges of the graph

421
00:17:06,160 --> 00:17:09,280
like this and you start from the

422
00:17:09,280 --> 00:17:11,760
accepting state you care about and visit

423
00:17:11,760 --> 00:17:13,599
all the nodes you can reach

424
00:17:13,599 --> 00:17:15,599
in this case you only get the the blue

425
00:17:15,599 --> 00:17:16,640
path

426
00:17:16,640 --> 00:17:20,720
that ends in the initial state okay

427
00:17:22,079 --> 00:17:25,280
you can then take this blue path that

428
00:17:25,280 --> 00:17:27,679
generically speaking is a graph

429
00:17:27,679 --> 00:17:31,280
and take it as a sub graph

430
00:17:31,280 --> 00:17:34,000
so it's simpler to analyze you can

431
00:17:34,000 --> 00:17:35,200
already see that

432
00:17:35,200 --> 00:17:37,200
it's pretty clear what this piece of

433
00:17:37,200 --> 00:17:40,240
fine state machine does

434
00:17:43,440 --> 00:17:46,000
then from here thanks to clean's theorem

435
00:17:46,000 --> 00:17:46,720
we know that

436
00:17:46,720 --> 00:17:48,480
it's always possible to go from finite

437
00:17:48,480 --> 00:17:50,880
state machine to a regular expression

438
00:17:50,880 --> 00:17:52,480
and back

439
00:17:52,480 --> 00:17:54,720
so we apply some computer science

440
00:17:54,720 --> 00:17:56,080
algorithm from

441
00:17:56,080 --> 00:17:59,760
op craft another famous book

442
00:17:59,760 --> 00:18:02,000
and we also apply some simplification

443
00:18:02,000 --> 00:18:02,799
passes

444
00:18:02,799 --> 00:18:05,840
to get a better looking regular

445
00:18:05,840 --> 00:18:06,799
expression

446
00:18:06,799 --> 00:18:09,280
and you can see here so we have an

447
00:18:09,280 --> 00:18:10,799
initial prefix which is

448
00:18:10,799 --> 00:18:13,120
a constant and we need to have it so you

449
00:18:13,120 --> 00:18:14,640
can see the first accepting state is

450
00:18:14,640 --> 00:18:15,760
after death

451
00:18:15,760 --> 00:18:17,360
and it's equivalent to this and then we

452
00:18:17,360 --> 00:18:19,280
have an optional part here which is

453
00:18:19,280 --> 00:18:23,039
ine and this is the second state

454
00:18:23,039 --> 00:18:26,320
and so we have uh if we repeat this for

455
00:18:26,320 --> 00:18:28,080
every accepting state we get back

456
00:18:28,080 --> 00:18:31,678
all the different driver expressions

457
00:18:32,000 --> 00:18:33,520
the final part is to generate valid

458
00:18:33,520 --> 00:18:36,240
tokens and there are many ways to do it

459
00:18:36,240 --> 00:18:36,880
but

460
00:18:36,880 --> 00:18:38,559
one of the simplest way the most simple

461
00:18:38,559 --> 00:18:41,360
way is the

462
00:18:41,360 --> 00:18:44,320
is to recursively generate valid sub uh

463
00:18:44,320 --> 00:18:45,200
substrings

464
00:18:45,200 --> 00:18:47,200
so for example if we have a regular

465
00:18:47,200 --> 00:18:49,039
expression that just matches

466
00:18:49,039 --> 00:18:52,320
the letter a we are gonna return a

467
00:18:52,320 --> 00:18:55,200
if we have a set of values we can choose

468
00:18:55,200 --> 00:18:58,799
one one character randomly

469
00:18:59,120 --> 00:19:02,160
if we have uh either a or b

470
00:19:02,160 --> 00:19:04,000
we can flip a coin and generate either

471
00:19:04,000 --> 00:19:05,440
from a or from b

472
00:19:05,440 --> 00:19:08,799
if we have a then b we can concatenate

473
00:19:08,799 --> 00:19:10,960
the result from

474
00:19:10,960 --> 00:19:13,120
the generation from a from b and so on

475
00:19:13,120 --> 00:19:15,679
it's pretty simple

476
00:19:15,679 --> 00:19:19,360
okay so demo time so this is the example

477
00:19:19,360 --> 00:19:21,600
uh from the slides you can see here the

478
00:19:21,600 --> 00:19:22,720
most interesting rule

479
00:19:22,720 --> 00:19:27,280
of the tree and we're gonna build

480
00:19:27,280 --> 00:19:30,480
this file using a simple make file and

481
00:19:30,480 --> 00:19:31,520
this is gonna give us

482
00:19:31,520 --> 00:19:35,760
in the end this object file

483
00:19:36,400 --> 00:19:39,200
so what we're to do is we load it into

484
00:19:39,200 --> 00:19:41,679
gydra

485
00:19:43,679 --> 00:19:46,799
and let it analyze

486
00:19:47,360 --> 00:19:50,000
while it lags basically so you can see

487
00:19:50,000 --> 00:19:51,280
here we have

488
00:19:51,280 --> 00:19:52,960
it's not as nice as the source code but

489
00:19:52,960 --> 00:19:56,000
it's still quite recognizable

490
00:19:56,000 --> 00:19:59,360
these are some tables and of course um

491
00:19:59,360 --> 00:20:01,039
the script we are going to run now

492
00:20:01,039 --> 00:20:03,039
doesn't assume we have symbols so the

493
00:20:03,039 --> 00:20:04,640
symbols are here just to

494
00:20:04,640 --> 00:20:08,320
to make it easier to to read

495
00:20:08,320 --> 00:20:10,799
this is the main data flow extraction

496
00:20:10,799 --> 00:20:13,200
script

497
00:20:13,679 --> 00:20:15,840
it takes some time and then we have okay

498
00:20:15,840 --> 00:20:16,880
so

499
00:20:16,880 --> 00:20:20,640
this message tells us that it worked

500
00:20:20,640 --> 00:20:24,159
go back to the shell and first of all

501
00:20:24,159 --> 00:20:25,600
let's look at the

502
00:20:25,600 --> 00:20:28,799
extracted data flow

503
00:20:32,240 --> 00:20:35,840
this is what it looks like

504
00:20:36,159 --> 00:20:39,840
so you can see here even for a simple um

505
00:20:39,840 --> 00:20:44,159
definition file it's quite complex

506
00:20:44,159 --> 00:20:45,440
and this is because giter doesn't

507
00:20:45,440 --> 00:20:48,559
optimize the

508
00:20:48,559 --> 00:20:50,480
the this intermediate representation

509
00:20:50,480 --> 00:20:52,880
very well

510
00:20:52,960 --> 00:20:56,240
okay so now we're gonna try to see

511
00:20:56,240 --> 00:20:58,559
if we can find the tables using this

512
00:20:58,559 --> 00:20:59,919
wrapper script that runs the

513
00:20:59,919 --> 00:21:04,559
the java part of reflex

514
00:21:04,799 --> 00:21:10,559
and this is tmp out.xml is a graphicsml

515
00:21:10,559 --> 00:21:13,280
graphml file so it it's just the

516
00:21:13,280 --> 00:21:16,640
exported graph and

517
00:21:16,640 --> 00:21:19,120
if it works we get all the options we

518
00:21:19,120 --> 00:21:21,360
need to fit to the other scripts

519
00:21:21,360 --> 00:21:31,840
so let's see what it does

520
00:21:34,480 --> 00:21:38,159
this script takes the table and

521
00:21:38,159 --> 00:21:42,840
uncompresses them and this is what we

522
00:21:42,840 --> 00:21:45,840
get

523
00:21:46,720 --> 00:21:49,440
this is a bit different from the the

524
00:21:49,440 --> 00:21:51,280
example i give on the slide but

525
00:21:51,280 --> 00:21:53,200
it's because uh flex creates some

526
00:21:53,200 --> 00:21:56,000
implicit rules and some

527
00:21:56,000 --> 00:21:57,600
some additional state that we don't care

528
00:21:57,600 --> 00:21:59,120
about

529
00:21:59,120 --> 00:22:03,600
but we can run a simplification on it

530
00:22:05,600 --> 00:22:09,600
this is the pickled version of the graph

531
00:22:11,039 --> 00:22:12,400
okay so now we have the simplified

532
00:22:12,400 --> 00:22:14,720
version of the finite machine

533
00:22:14,720 --> 00:22:19,840
you can look at one of them so

534
00:22:20,880 --> 00:22:22,960
this one is the finest machine that we

535
00:22:22,960 --> 00:22:25,120
extracted that it's relative to the

536
00:22:25,120 --> 00:22:28,720
define define rule so there's an

537
00:22:28,720 --> 00:22:30,400
additional state

538
00:22:30,400 --> 00:22:32,799
it's not important but you can see here

539
00:22:32,799 --> 00:22:33,760
basically

540
00:22:33,760 --> 00:22:37,200
def reaches the first accepting state

541
00:22:37,200 --> 00:22:38,400
and then we have another one

542
00:22:38,400 --> 00:22:42,559
for the optional i n e

543
00:22:43,120 --> 00:22:46,720
okay so now let's recover the regex

544
00:22:46,720 --> 00:22:49,200
from this

545
00:22:49,840 --> 00:22:55,840
this is done with this comment

546
00:23:02,240 --> 00:23:06,080
and you can see that we have

547
00:23:06,159 --> 00:23:08,159
a regular expression that's equivalent

548
00:23:08,159 --> 00:23:09,360
to the one i

549
00:23:09,360 --> 00:23:12,640
i put on the slide so they are the same

550
00:23:12,640 --> 00:23:15,760
just written a different way

551
00:23:16,320 --> 00:23:19,360
and to generate valid tokens we can use

552
00:23:19,360 --> 00:23:22,000
this other command and we get a stream

553
00:23:22,000 --> 00:23:24,000
an infinite stream of uh

554
00:23:24,000 --> 00:23:26,960
of valid tokens

555
00:23:27,120 --> 00:23:30,480
but now let's try with a more real life

556
00:23:30,480 --> 00:23:31,200
example

557
00:23:31,200 --> 00:23:34,400
like a slag which is the

558
00:23:34,400 --> 00:23:39,360
part of the c plus plus part of kidro

559
00:23:41,360 --> 00:23:43,279
because now it's running ghidra in

560
00:23:43,279 --> 00:23:44,559
endless mode

561
00:23:44,559 --> 00:23:46,320
and it's gonna take some time to analyze

562
00:23:46,320 --> 00:23:48,240
the the binary and then

563
00:23:48,240 --> 00:23:50,720
run our script to extract the data flow

564
00:23:50,720 --> 00:23:51,840
and then automatically

565
00:23:51,840 --> 00:23:54,480
do everything i've done manually so far

566
00:23:54,480 --> 00:23:55,840
but it's gonna do it uh

567
00:23:55,840 --> 00:23:59,440
all together so we're gonna just get

568
00:23:59,440 --> 00:24:02,240
a valid stream of tokens out of this so

569
00:24:02,240 --> 00:24:02,640
just

570
00:24:02,640 --> 00:24:05,840
let's wait a minute

571
00:24:07,760 --> 00:24:09,840
okay so the analysis is done now it's

572
00:24:09,840 --> 00:24:12,159
running our script to exploit

573
00:24:12,159 --> 00:24:14,640
exports or in the data flow this is the

574
00:24:14,640 --> 00:24:18,000
python part

575
00:24:18,000 --> 00:24:21,520
these are valid tokens for

576
00:24:22,799 --> 00:24:25,760
this lake binary

577
00:24:26,720 --> 00:24:30,000
and this is pretty much it

578
00:24:30,720 --> 00:24:32,400
can you take away from this works so we

579
00:24:32,400 --> 00:24:33,840
are able to identify flex table

580
00:24:33,840 --> 00:24:34,960
automatically

581
00:24:34,960 --> 00:24:36,640
and then from the tables we can extract

582
00:24:36,640 --> 00:24:38,000
the finest machine

583
00:24:38,000 --> 00:24:40,159
and recover the regular expressions and

584
00:24:40,159 --> 00:24:42,159
from the regular expressions we can get

585
00:24:42,159 --> 00:24:44,720
valid tokens without running the target

586
00:24:44,720 --> 00:24:46,080
even once

587
00:24:46,080 --> 00:24:47,279
however of course we have some

588
00:24:47,279 --> 00:24:49,440
limitation the first one

589
00:24:49,440 --> 00:24:50,799
uh and the main one is that the

590
00:24:50,799 --> 00:24:52,480
github-based dataflow analysis is not

591
00:24:52,480 --> 00:24:53,760
very reliable

592
00:24:53,760 --> 00:24:55,120
because we're doing pattern matching on

593
00:24:55,120 --> 00:24:56,880
the data flow and the data flow that

594
00:24:56,880 --> 00:24:58,240
gidra gives you

595
00:24:58,240 --> 00:25:00,000
changes a bit between for example

596
00:25:00,000 --> 00:25:03,039
different architectures

597
00:25:03,039 --> 00:25:04,480
of course this only works for table

598
00:25:04,480 --> 00:25:07,039
driven parsers and the implementation is

599
00:25:07,039 --> 00:25:08,480
limited to bison and flex

600
00:25:08,480 --> 00:25:11,760
even though this is just an

601
00:25:11,760 --> 00:25:13,520
implementation detail you can apply the

602
00:25:13,520 --> 00:25:14,240
same idea

603
00:25:14,240 --> 00:25:17,760
to different table based parsers

604
00:25:17,760 --> 00:25:20,720
and yes we don't yet handle the parsing

605
00:25:20,720 --> 00:25:22,159
part just the

606
00:25:22,159 --> 00:25:24,640
the tokenizer part so you don't you are

607
00:25:24,640 --> 00:25:26,559
not able to generate

608
00:25:26,559 --> 00:25:29,600
structured files with this approach

609
00:25:29,600 --> 00:25:32,720
yet as future work we want to find more

610
00:25:32,720 --> 00:25:34,080
bison-based target

611
00:25:34,080 --> 00:25:35,760
that's difficult to do because they are

612
00:25:35,760 --> 00:25:37,679
usually not advertised so

613
00:25:37,679 --> 00:25:40,480
contact me if you have information and

614
00:25:40,480 --> 00:25:41,919
then yeah we want to look at the parsing

615
00:25:41,919 --> 00:25:44,159
part

616
00:25:44,320 --> 00:25:46,320
and an idea we have to improve on the

617
00:25:46,320 --> 00:25:48,480
data flow limitation

618
00:25:48,480 --> 00:25:51,279
data flow analysis limitation is to use

619
00:25:51,279 --> 00:25:53,600
the binary lifter that my companies

620
00:25:53,600 --> 00:25:57,440
created that gives you llvmir that

621
00:25:57,440 --> 00:26:00,000
you can feed into llvm optimization

622
00:26:00,000 --> 00:26:01,600
passes

623
00:26:01,600 --> 00:26:04,159
and analysis and they are very robust

624
00:26:04,159 --> 00:26:05,919
and gives you a consistent

625
00:26:05,919 --> 00:26:08,960
output they also have this thing called

626
00:26:08,960 --> 00:26:11,200
a scalar evolution which gives you

627
00:26:11,200 --> 00:26:12,960
information about

628
00:26:12,960 --> 00:26:16,159
table accesses array accesses and

629
00:26:16,159 --> 00:26:20,320
and stride so you already know the size

630
00:26:20,320 --> 00:26:22,400
of the tables without needing to do

631
00:26:22,400 --> 00:26:24,799
pattern matching for example

632
00:26:24,799 --> 00:26:26,240
finally we want to look at other partial

633
00:26:26,240 --> 00:26:28,000
generators for example ntlr

634
00:26:28,000 --> 00:26:30,799
is still kind of table based but it's

635
00:26:30,799 --> 00:26:33,120
more powerful than bison

636
00:26:33,120 --> 00:26:35,440
and yeah we want to find bugs in closed

637
00:26:35,440 --> 00:26:38,559
source software

638
00:26:38,559 --> 00:26:40,799
the code for the tool is available on

639
00:26:40,799 --> 00:26:42,400
github

640
00:26:42,400 --> 00:26:45,039
and feel free to open issues ask me

641
00:26:45,039 --> 00:26:46,159
about it

642
00:26:46,159 --> 00:26:49,600
fork it and make pull requests i'll be

643
00:26:49,600 --> 00:26:52,799
happy to merge them and thank you very

644
00:26:52,799 --> 00:26:53,360
much

645
00:26:53,360 --> 00:26:54,960
you can find my contact information on

646
00:26:54,960 --> 00:26:56,720
the corner

647
00:26:56,720 --> 00:26:59,279
and in the bottom right that's my email

648
00:26:59,279 --> 00:27:00,640
my twitter account

649
00:27:00,640 --> 00:27:03,919
and my website thank you i'm available

650
00:27:03,919 --> 00:27:07,840
in the chat for the questions

