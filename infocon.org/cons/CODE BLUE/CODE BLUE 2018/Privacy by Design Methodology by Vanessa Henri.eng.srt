1
00:00:04,480 --> 00:00:08,900
so let me start with a quick

2
00:00:06,529 --> 00:00:11,420
introduction about myself so you can

3
00:00:08,900 --> 00:00:13,010
understand where I'm coming from when

4
00:00:11,420 --> 00:00:16,100
I'm talking about software development

5
00:00:13,010 --> 00:00:19,160
and why is a lawyer coming here to talk

6
00:00:16,100 --> 00:00:21,800
to you about software development so I

7
00:00:19,160 --> 00:00:23,900
work a detaches system security we are a

8
00:00:21,800 --> 00:00:27,280
division of Hitachi that is located in

9
00:00:23,900 --> 00:00:30,169
Canada Quebec here's the French accent

10
00:00:27,280 --> 00:00:32,899
I'm a director of legal and compliance

11
00:00:30,170 --> 00:00:35,030
I'm on a Data Protection Officer so my

12
00:00:32,899 --> 00:00:37,089
job at itachi is to make sure that we

13
00:00:35,030 --> 00:00:39,319
process personal information and

14
00:00:37,089 --> 00:00:42,440
compliance with all the applicable

15
00:00:39,319 --> 00:00:45,710
regulations and Evon that we go beyond

16
00:00:42,440 --> 00:00:47,599
above industry standard to make sure

17
00:00:45,710 --> 00:00:50,870
that we respect the rights and freedom

18
00:00:47,600 --> 00:00:55,280
of our users and I do other boring stuff

19
00:00:50,870 --> 00:00:58,549
like contracts and the likes I want to

20
00:00:55,280 --> 00:01:00,679
start this discussion about some general

21
00:00:58,549 --> 00:01:04,670
discussion about the economy in general

22
00:01:00,679 --> 00:01:09,049
so this is a picture of the biggest

23
00:01:04,670 --> 00:01:11,060
economy in the world Walmart in 2016 was

24
00:01:09,049 --> 00:01:15,740
the 10th biggest economy in the world

25
00:01:11,060 --> 00:01:20,149
bigger economy than Australia India or

26
00:01:15,740 --> 00:01:23,179
South Korea today in 2018 you're looking

27
00:01:20,149 --> 00:01:27,049
at economies like Facebook Twitter you

28
00:01:23,180 --> 00:01:29,780
Bert they are built on data so that is

29
00:01:27,049 --> 00:01:32,869
an interesting question how much is that

30
00:01:29,780 --> 00:01:35,810
are worth that may seems like a silly

31
00:01:32,869 --> 00:01:39,829
question but Forbes looking to it in

32
00:01:35,810 --> 00:01:42,229
2015 and they found that companies like

33
00:01:39,829 --> 00:01:45,020
Facebook if you look at their actual

34
00:01:42,229 --> 00:01:48,619
worth and if you look at their market

35
00:01:45,020 --> 00:01:51,619
valuation they are actually worth more

36
00:01:48,619 --> 00:01:53,060
on the market then you can look in there

37
00:01:51,619 --> 00:01:55,579
if you open their accounting book

38
00:01:53,060 --> 00:01:57,380
they're not even worth as much as you

39
00:01:55,579 --> 00:01:59,928
feel they are worth on the trade

40
00:01:57,380 --> 00:02:03,469
exchange because there's one asset that

41
00:01:59,929 --> 00:02:05,960
is not accounted for and that is data so

42
00:02:03,469 --> 00:02:10,759
data as a value you could even say that

43
00:02:05,960 --> 00:02:13,220
is the new gold the accountants today

44
00:02:10,759 --> 00:02:14,780
are actually looking at how they can

45
00:02:13,220 --> 00:02:17,450
change the general

46
00:02:14,780 --> 00:02:20,810
account accounting practices to take

47
00:02:17,450 --> 00:02:23,510
into consideration that value of data so

48
00:02:20,810 --> 00:02:26,950
that when we do merger an acquisition we

49
00:02:23,510 --> 00:02:29,030
can actually have better measures of

50
00:02:26,950 --> 00:02:32,030
what we are buying

51
00:02:29,030 --> 00:02:36,080
so today data is not accounted for in

52
00:02:32,030 --> 00:02:39,110
the books but data is the new goal and

53
00:02:36,080 --> 00:02:42,980
that typically comes with a particular

54
00:02:39,110 --> 00:02:45,950
dynamic so when we have a new resources

55
00:02:42,980 --> 00:02:49,250
that has so much value there's three

56
00:02:45,950 --> 00:02:51,320
things that generally happen first you

57
00:02:49,250 --> 00:02:54,070
have this big giant company that

58
00:02:51,320 --> 00:02:59,120
eventually abused of that resource

59
00:02:54,070 --> 00:03:00,980
you've seen Cambridge analytical so you

60
00:02:59,120 --> 00:03:02,930
have that we had that in the environment

61
00:03:00,980 --> 00:03:04,369
we had that if you look back in history

62
00:03:02,930 --> 00:03:08,350
that's something that's typically

63
00:03:04,370 --> 00:03:11,540
happened and as a reaction rightly so

64
00:03:08,350 --> 00:03:13,640
governments will do regulation like the

65
00:03:11,540 --> 00:03:16,730
GDP are that general data protection

66
00:03:13,640 --> 00:03:19,518
regulation and that will create a

67
00:03:16,730 --> 00:03:21,859
compliance burden for all the companies

68
00:03:19,519 --> 00:03:24,410
around the world even those dollar

69
00:03:21,860 --> 00:03:30,200
sometimes too small to follow these

70
00:03:24,410 --> 00:03:32,600
standards and that raises some question

71
00:03:30,200 --> 00:03:34,760
in terms of ethics ethics and

72
00:03:32,600 --> 00:03:39,769
technological development that we can

73
00:03:34,760 --> 00:03:43,010
call techno ethics so the Greek I used

74
00:03:39,769 --> 00:03:45,140
to refer to techno as techne and for

75
00:03:43,010 --> 00:03:47,720
them technology was supposed to be

76
00:03:45,140 --> 00:03:50,630
something that serves the natural world

77
00:03:47,720 --> 00:03:52,940
that supported and that raises the

78
00:03:50,630 --> 00:03:55,579
question of is this what we're doing

79
00:03:52,940 --> 00:03:58,820
today are we building technology to

80
00:03:55,579 --> 00:04:02,269
support the natural world or are we

81
00:03:58,820 --> 00:04:04,670
building technology that are ultimately

82
00:04:02,269 --> 00:04:07,970
not even good for the natural world

83
00:04:04,670 --> 00:04:10,670
and the natural world is you it's me and

84
00:04:07,970 --> 00:04:13,459
it's the planet it's our rights and

85
00:04:10,670 --> 00:04:16,820
freedom that's why we have technologies

86
00:04:13,459 --> 00:04:18,410
so we need sometimes to stop and say are

87
00:04:16,820 --> 00:04:20,779
we developing this in a sustainable

88
00:04:18,410 --> 00:04:23,050
manner are we developing it for the

89
00:04:20,779 --> 00:04:25,549
human being are we developing

90
00:04:23,050 --> 00:04:28,930
technologies for the entities are we

91
00:04:25,550 --> 00:04:33,290
developing edges for economical purposes

92
00:04:28,930 --> 00:04:36,290
and it's not gonna get better if you if

93
00:04:33,290 --> 00:04:38,810
we're asking these questions today we're

94
00:04:36,290 --> 00:04:42,620
asking them already late but at the same

95
00:04:38,810 --> 00:04:45,800
time the future is now look at this

96
00:04:42,620 --> 00:04:48,440
we have huge amount of information big

97
00:04:45,800 --> 00:04:51,200
data we have the Internet of Things it

98
00:04:48,440 --> 00:04:53,450
is just starting it's in your house it's

99
00:04:51,200 --> 00:04:54,700
a new city and it will be in your body

100
00:04:53,450 --> 00:04:57,409
soon

101
00:04:54,700 --> 00:05:00,229
we have blockchain technology that we're

102
00:04:57,410 --> 00:05:03,110
just beginning to understand so there's

103
00:05:00,230 --> 00:05:06,260
a big buzz around it but how many people

104
00:05:03,110 --> 00:05:09,710
really understand what it does how can

105
00:05:06,260 --> 00:05:12,950
it affect our privacy very few people I

106
00:05:09,710 --> 00:05:16,400
don't know many experts that can look

107
00:05:12,950 --> 00:05:19,400
into how blood chain complies with gdpr

108
00:05:16,400 --> 00:05:28,130
and come up with a useful answer to this

109
00:05:19,400 --> 00:05:31,400
and that raises a new to new areas of

110
00:05:28,130 --> 00:05:33,320
compliance we have data that is worth a

111
00:05:31,400 --> 00:05:35,570
lot of money we have these ethical

112
00:05:33,320 --> 00:05:38,570
questions so naturally people will come

113
00:05:35,570 --> 00:05:40,520
forward trying to protect it over the

114
00:05:38,570 --> 00:05:43,700
last years there have been different

115
00:05:40,520 --> 00:05:46,250
approach so we saw cybersecurity as a

116
00:05:43,700 --> 00:05:48,500
compliance field that emerged

117
00:05:46,250 --> 00:05:51,740
mostly out of economical reasons

118
00:05:48,500 --> 00:05:54,320
companies wanted to protect their assets

119
00:05:51,740 --> 00:05:58,090
they didn't want to be subject to

120
00:05:54,320 --> 00:06:01,969
intellectual property death and has they

121
00:05:58,090 --> 00:06:05,000
grew bigger they realized that these

122
00:06:01,970 --> 00:06:06,650
lawsuits could be very costly so now I

123
00:06:05,000 --> 00:06:09,410
was affecting their reputation or

124
00:06:06,650 --> 00:06:13,429
damages and it was going beyond the

125
00:06:09,410 --> 00:06:16,070
economical realm so today this company

126
00:06:13,430 --> 00:06:18,470
are addressing cyber security from a

127
00:06:16,070 --> 00:06:22,370
compliance and legal perspective but

128
00:06:18,470 --> 00:06:24,380
that's not where it started and there is

129
00:06:22,370 --> 00:06:28,460
another area of compliance that we know

130
00:06:24,380 --> 00:06:31,430
today as privacy so privacy and security

131
00:06:28,460 --> 00:06:33,760
are very similar they overlap in many

132
00:06:31,430 --> 00:06:36,800
respect but they are not the same

133
00:06:33,760 --> 00:06:40,130
privacy approaches the security of data

134
00:06:36,800 --> 00:06:41,490
not just any data that are about you

135
00:06:40,130 --> 00:06:44,430
that about me

136
00:06:41,490 --> 00:06:47,940
and it approaches it from a human right

137
00:06:44,430 --> 00:06:50,639
perspective so I asked the question of

138
00:06:47,940 --> 00:06:53,759
whether we are processing personal data

139
00:06:50,639 --> 00:06:56,759
in a way that protects our human right

140
00:06:53,759 --> 00:06:59,610
and does not endure our human right

141
00:06:56,759 --> 00:07:01,979
so they complement each other in many

142
00:06:59,610 --> 00:07:03,990
respect they overlap with each other but

143
00:07:01,979 --> 00:07:07,620
there are two different approach to a

144
00:07:03,990 --> 00:07:10,349
fairly similar problem and that is

145
00:07:07,620 --> 00:07:14,479
because processing personal information

146
00:07:10,349 --> 00:07:18,360
can lead to many problems discrimination

147
00:07:14,479 --> 00:07:20,818
profiling surveillance undemocratic

148
00:07:18,360 --> 00:07:23,520
control on freedom of speech these are

149
00:07:20,819 --> 00:07:27,030
just example of what you could see if

150
00:07:23,520 --> 00:07:29,669
you open the newspaper today it's

151
00:07:27,030 --> 00:07:32,789
interesting that Germany today is

152
00:07:29,669 --> 00:07:33,500
probably the most trenchant privacy laws

153
00:07:32,789 --> 00:07:36,229
in the world

154
00:07:33,500 --> 00:07:40,259
what do you why do you think that is

155
00:07:36,229 --> 00:07:42,318
because they grew out of a war where

156
00:07:40,259 --> 00:07:44,669
there was control over information

157
00:07:42,319 --> 00:07:46,560
surveillance and eventually was used

158
00:07:44,669 --> 00:07:48,840
against the people and they learned from

159
00:07:46,560 --> 00:07:51,990
that and they don't want that again so

160
00:07:48,840 --> 00:07:54,239
they have good privacy laws they have 13

161
00:07:51,990 --> 00:07:57,810
data protection authorities only in

162
00:07:54,240 --> 00:08:00,330
Germany so for any business I want to do

163
00:07:57,810 --> 00:08:03,630
and any enterprise I want to do business

164
00:08:00,330 --> 00:08:06,690
in Germany and in the European Union you

165
00:08:03,630 --> 00:08:11,490
need to approach not only security but

166
00:08:06,690 --> 00:08:13,949
privacy and in order to do this you will

167
00:08:11,490 --> 00:08:16,289
need a new critical set of skills that

168
00:08:13,949 --> 00:08:18,180
is called privacy by design you will

169
00:08:16,289 --> 00:08:20,759
need it to be able to speak legal

170
00:08:18,180 --> 00:08:23,310
technical and ethical and the same

171
00:08:20,759 --> 00:08:25,770
sentence if you want to conquer new

172
00:08:23,310 --> 00:08:28,440
markets if you want to have new business

173
00:08:25,770 --> 00:08:31,400
opportunities keep your customer and

174
00:08:28,440 --> 00:08:31,400
keep their trust

175
00:08:31,760 --> 00:08:38,479
so obviously the general data protection

176
00:08:35,279 --> 00:08:40,140
regulation is one of the example of

177
00:08:38,479 --> 00:08:44,099
privacy by design

178
00:08:40,140 --> 00:08:46,589
being part of a regulation it probably

179
00:08:44,099 --> 00:08:47,930
took the concept and made it extremely

180
00:08:46,589 --> 00:08:51,480
popular

181
00:08:47,930 --> 00:08:55,109
you have article 25 one that requires

182
00:08:51,480 --> 00:08:57,120
that an entity takes adequate measure

183
00:08:55,110 --> 00:08:59,730
such a risk brace approach you look at

184
00:08:57,120 --> 00:09:02,399
the cost you look at the state of the

185
00:08:59,730 --> 00:09:05,040
heart technology you look at the nature

186
00:09:02,399 --> 00:09:07,290
of your processing the type of data that

187
00:09:05,040 --> 00:09:09,420
you're processing and how much data

188
00:09:07,290 --> 00:09:12,719
you're processing and you need to come

189
00:09:09,420 --> 00:09:15,120
up with controls to ensure that you have

190
00:09:12,720 --> 00:09:19,440
built the system that by designed from

191
00:09:15,120 --> 00:09:23,550
the very start is privacy compliance and

192
00:09:19,440 --> 00:09:28,170
protects the individual 25/2 goes

193
00:09:23,550 --> 00:09:30,870
further and ask you that by default your

194
00:09:28,170 --> 00:09:36,060
application your software or your IT

195
00:09:30,870 --> 00:09:39,870
system as that privacy setting so for

196
00:09:36,060 --> 00:09:41,399
example if I open an application and

197
00:09:39,870 --> 00:09:43,980
it's ask Vanessa

198
00:09:41,399 --> 00:09:46,350
do you want to turn off data sharing

199
00:09:43,980 --> 00:09:48,690
that's not how it's supposed to be it's

200
00:09:46,350 --> 00:09:51,720
supposed to be off by default and if I

201
00:09:48,690 --> 00:09:55,260
want to share I have to go in and turn

202
00:09:51,720 --> 00:09:56,550
that on now I know how to do that I

203
00:09:55,260 --> 00:09:58,019
don't think my grandmother don't know

204
00:09:56,550 --> 00:10:00,410
how to do that I don't think my parents

205
00:09:58,019 --> 00:10:03,360
know how to do that and I don't think

206
00:10:00,410 --> 00:10:05,399
kids know how to do that actually I

207
00:10:03,360 --> 00:10:07,589
think the amount of people will know how

208
00:10:05,399 --> 00:10:10,920
to change their sitting it's actually

209
00:10:07,589 --> 00:10:13,470
very very small so we need to give these

210
00:10:10,920 --> 00:10:16,860
people some measure of protection that's

211
00:10:13,470 --> 00:10:19,769
why the law is asking businesses to do

212
00:10:16,860 --> 00:10:22,649
it by default so that's why the gdpr

213
00:10:19,769 --> 00:10:25,230
today it's a big compliance challenge

214
00:10:22,649 --> 00:10:30,810
and it brought privacy by design to the

215
00:10:25,230 --> 00:10:34,230
front line and when I talk about privacy

216
00:10:30,810 --> 00:10:38,729
by design I talk about making sure that

217
00:10:34,230 --> 00:10:40,649
your software allows for a lawful fair

218
00:10:38,730 --> 00:10:42,810
transparent processing these are all

219
00:10:40,649 --> 00:10:44,910
privacy principle you find in the gdpr

220
00:10:42,810 --> 00:10:48,390
and you tell me it's also common sense

221
00:10:44,910 --> 00:10:51,120
when you make sure that it's secure that

222
00:10:48,390 --> 00:10:53,310
you don't store that time bar longer

223
00:10:51,120 --> 00:10:55,199
than you need to why would you want to

224
00:10:53,310 --> 00:10:57,239
do that it's not good for you it's not

225
00:10:55,199 --> 00:10:58,609
good for your users if you don't need

226
00:10:57,240 --> 00:11:01,740
the data let it go

227
00:10:58,610 --> 00:11:05,069
accuracy if you're building a file about

228
00:11:01,740 --> 00:11:07,560
me about my medical history I would like

229
00:11:05,069 --> 00:11:08,849
you not to make a mistake what if it's a

230
00:11:07,560 --> 00:11:10,319
criminal file

231
00:11:08,850 --> 00:11:12,180
and I get sued on this because you're

232
00:11:10,319 --> 00:11:15,269
profiling on me but this is the wrong

233
00:11:12,180 --> 00:11:17,310
person accuracy is very important when

234
00:11:15,269 --> 00:11:20,880
you're doing big data and when you're

235
00:11:17,310 --> 00:11:23,008
doing profiling or monitoring so what we

236
00:11:20,880 --> 00:11:25,740
do as a business in a touchy system

237
00:11:23,009 --> 00:11:27,269
security we monitor employees to make

238
00:11:25,740 --> 00:11:29,579
sure that they don't create security

239
00:11:27,269 --> 00:11:32,009
incident imagine if we made an error and

240
00:11:29,579 --> 00:11:35,880
that person lost his job it's extremely

241
00:11:32,009 --> 00:11:37,860
important purpose limitation why am i

242
00:11:35,880 --> 00:11:40,500
collecting the data here's your answer

243
00:11:37,860 --> 00:11:43,259
stick to it if you don't have any reason

244
00:11:40,500 --> 00:11:45,269
to collect the data just don't because

245
00:11:43,259 --> 00:11:47,279
it's not good for your entity it's not

246
00:11:45,269 --> 00:11:49,949
good for your user the more data you

247
00:11:47,279 --> 00:11:54,389
have the more costly the data breach

248
00:11:49,949 --> 00:11:57,389
will be and ultimately your products

249
00:11:54,389 --> 00:12:00,480
needs to serve the rights and freedom of

250
00:11:57,389 --> 00:12:02,940
people so if they have the right to data

251
00:12:00,480 --> 00:12:04,889
portability if they have the right to

252
00:12:02,940 --> 00:12:07,380
consent you need to put some

253
00:12:04,889 --> 00:12:09,540
functionalities in there for them to be

254
00:12:07,380 --> 00:12:12,449
able to activate this right you can't

255
00:12:09,540 --> 00:12:14,069
expect people to call your company for

256
00:12:12,449 --> 00:12:15,389
example somebody would call it a chip

257
00:12:14,069 --> 00:12:17,430
tomorrow they probably would have a very

258
00:12:15,389 --> 00:12:19,769
hard time finding me a titter G&C

259
00:12:17,430 --> 00:12:22,170
Vanessa can you delete all my history it

260
00:12:19,769 --> 00:12:24,000
will be complicated where you have the

261
00:12:22,170 --> 00:12:26,069
opportunity of doing this directly in

262
00:12:24,000 --> 00:12:30,649
your application directly into your

263
00:12:26,069 --> 00:12:30,649
software and that is privacy by design

264
00:12:30,740 --> 00:12:35,310
so you're probably asking why is the

265
00:12:33,389 --> 00:12:36,620
Canadian coming here to talk to me about

266
00:12:35,310 --> 00:12:39,149
gdpr

267
00:12:36,620 --> 00:12:41,579
well you're certain privacy by design is

268
00:12:39,149 --> 00:12:44,100
actually Canadian it's a Canadian

269
00:12:41,579 --> 00:12:48,000
invention it was invented by Anne

270
00:12:44,100 --> 00:12:50,579
Kevorkian with a doctor she is the chair

271
00:12:48,000 --> 00:12:53,759
of the privacy by design foundation at

272
00:12:50,579 --> 00:12:56,219
Frierson University she was the

273
00:12:53,759 --> 00:13:00,449
information and Privacy Commissioner of

274
00:12:56,220 --> 00:13:02,670
Ontario Canada and she summed up privacy

275
00:13:00,449 --> 00:13:05,430
by design into seven foundational

276
00:13:02,670 --> 00:13:08,939
principle which I find are extremely

277
00:13:05,430 --> 00:13:11,189
clear to follow and make sense be

278
00:13:08,939 --> 00:13:13,050
proactive not reactive don't wait for

279
00:13:11,189 --> 00:13:16,410
something bad to happen make sure

280
00:13:13,050 --> 00:13:18,120
something that doesn't happen virus is

281
00:13:16,410 --> 00:13:22,079
the default setting we discussed this

282
00:13:18,120 --> 00:13:22,800
before privacy embedded into design so

283
00:13:22,079 --> 00:13:24,839
from the

284
00:13:22,800 --> 00:13:30,689
running face you need to think about

285
00:13:24,839 --> 00:13:33,360
privacy and full functionality obviously

286
00:13:30,690 --> 00:13:35,519
I'm not asking you to be a software that

287
00:13:33,360 --> 00:13:38,430
are inefficient I'm asking you to build

288
00:13:35,519 --> 00:13:40,709
a software that is efficient and privacy

289
00:13:38,430 --> 00:13:42,810
centric and by the end of this

290
00:13:40,709 --> 00:13:45,890
presentation I think I will give you

291
00:13:42,810 --> 00:13:49,439
tools so you are able to do that

292
00:13:45,890 --> 00:13:53,399
end-to-end security there is no privacy

293
00:13:49,440 --> 00:13:56,579
without security visibility and

294
00:13:53,399 --> 00:13:58,860
transparency when I'm using my app when

295
00:13:56,579 --> 00:14:02,010
I'm using your system or software

296
00:13:58,860 --> 00:14:03,600
I should be empowered to understand what

297
00:14:02,010 --> 00:14:06,470
is happening with my personal

298
00:14:03,600 --> 00:14:11,640
information they belong to me and

299
00:14:06,470 --> 00:14:13,980
respect for user privacy users are the

300
00:14:11,640 --> 00:14:17,569
people that keep your business alive you

301
00:14:13,980 --> 00:14:21,180
do product for them not to exploit them

302
00:14:17,570 --> 00:14:23,640
and that raises a lot of questions when

303
00:14:21,180 --> 00:14:26,279
you talk about privacy I know I'll have

304
00:14:23,640 --> 00:14:27,990
question maybe you have two and maybe by

305
00:14:26,279 --> 00:14:31,439
the end of this presentation you will

306
00:14:27,990 --> 00:14:33,810
have even more some of the question I

307
00:14:31,440 --> 00:14:37,500
asked myself when I think about privacy

308
00:14:33,810 --> 00:14:41,760
by design is is technology and trinsic

309
00:14:37,500 --> 00:14:46,220
illegal or bad are their technology they

310
00:14:41,760 --> 00:14:48,930
are intrinsically intrusive what are the

311
00:14:46,220 --> 00:14:51,839
responsibilities of tech company in

312
00:14:48,930 --> 00:14:53,849
developing services and product that

313
00:14:51,839 --> 00:14:55,399
respect the fundamental rights of

314
00:14:53,850 --> 00:14:58,410
individuals

315
00:14:55,399 --> 00:15:03,029
how can lawyers and technical people

316
00:14:58,410 --> 00:15:06,899
work together over this is there a

317
00:15:03,029 --> 00:15:08,760
demand for new critical skills it's

318
00:15:06,899 --> 00:15:11,550
privacy by design a compliance

319
00:15:08,760 --> 00:15:14,189
requirement or is it just an opportunity

320
00:15:11,550 --> 00:15:19,380
for innovative for competitive

321
00:15:14,190 --> 00:15:22,370
innovation who is to be accountable for

322
00:15:19,380 --> 00:15:26,250
privacy by design development companies

323
00:15:22,370 --> 00:15:29,459
developers lawyers and how will the

324
00:15:26,250 --> 00:15:34,709
court articulate liability if we do not

325
00:15:29,459 --> 00:15:36,569
follow that methodology but beyond that

326
00:15:34,709 --> 00:15:39,359
compliance requirement

327
00:15:36,570 --> 00:15:42,030
let's forget about privacy by design

328
00:15:39,360 --> 00:15:45,870
being a legal requirement a part of GDP

329
00:15:42,030 --> 00:15:48,600
are in itself it is extremely beneficial

330
00:15:45,870 --> 00:15:51,900
for your company to consider privacy by

331
00:15:48,600 --> 00:15:54,990
design for one thing it will allow you

332
00:15:51,900 --> 00:15:57,660
to have a methodology that will

333
00:15:54,990 --> 00:16:01,380
integrate security and privacy

334
00:15:57,660 --> 00:16:02,850
requirements or our if you talk to

335
00:16:01,380 --> 00:16:04,170
software developer you would say

336
00:16:02,850 --> 00:16:07,710
functional and non-functional

337
00:16:04,170 --> 00:16:10,170
requirement and that will allow you to

338
00:16:07,710 --> 00:16:13,700
have an approach to think take this

339
00:16:10,170 --> 00:16:15,569
requirement and put them into a logical

340
00:16:13,700 --> 00:16:18,000
methodology that will make you

341
00:16:15,570 --> 00:16:20,400
accountable for what you do so you will

342
00:16:18,000 --> 00:16:23,280
be able not only to do it but

343
00:16:20,400 --> 00:16:26,790
demonstrate that you're doing it to your

344
00:16:23,280 --> 00:16:28,819
users to the court to your bus make sure

345
00:16:26,790 --> 00:16:34,290
that what you are doing can be

346
00:16:28,820 --> 00:16:37,200
repeatable it will allow you to

347
00:16:34,290 --> 00:16:38,969
implement a risk-based approach that's

348
00:16:37,200 --> 00:16:42,050
not the first time you hear about this

349
00:16:38,970 --> 00:16:47,370
myth as a risk management framework

350
00:16:42,050 --> 00:16:49,319
almost any cybersecurity Association

351
00:16:47,370 --> 00:16:52,140
today is pushing for a risk-based

352
00:16:49,320 --> 00:16:54,810
approach there is no way you can decide

353
00:16:52,140 --> 00:16:56,699
which controls you need if you have not

354
00:16:54,810 --> 00:17:01,969
looked at the vulnerabilities and

355
00:16:56,700 --> 00:17:04,710
threats that your system is creating and

356
00:17:01,970 --> 00:17:07,350
lastly it will also give you the means

357
00:17:04,710 --> 00:17:10,860
to manage your platform on the long run

358
00:17:07,349 --> 00:17:13,919
so there will be no new vulnerabilities

359
00:17:10,859 --> 00:17:17,429
once your software is out there will be

360
00:17:13,920 --> 00:17:19,500
zero day exploit there will be new

361
00:17:17,430 --> 00:17:23,010
treads that were not there when it was

362
00:17:19,500 --> 00:17:25,470
created so once you software is out you

363
00:17:23,010 --> 00:17:28,500
still need to manage it you still need

364
00:17:25,470 --> 00:17:30,990
to make sure that it is secure and up to

365
00:17:28,500 --> 00:17:33,240
the end of street based standard use my

366
00:17:30,990 --> 00:17:35,970
personal advice don't just look at the

367
00:17:33,240 --> 00:17:38,730
law as a baseline the laws will change

368
00:17:35,970 --> 00:17:40,860
they will become more stringent look at

369
00:17:38,730 --> 00:17:43,290
the state of the art and see if you can

370
00:17:40,860 --> 00:17:47,820
afford that if the answer is yes go for

371
00:17:43,290 --> 00:17:50,530
it and the reason for that is that

372
00:17:47,820 --> 00:17:53,679
privacy by design is a come

373
00:17:50,530 --> 00:17:55,840
pitov edge it will allow you to go into

374
00:17:53,680 --> 00:17:58,900
the European market with your software

375
00:17:55,840 --> 00:18:01,449
sit down in front of a sizer and tell

376
00:17:58,900 --> 00:18:04,840
him this is a software that is gdpr

377
00:18:01,450 --> 00:18:05,590
compliant and certified as such this is

378
00:18:04,840 --> 00:18:09,340
hard to beat

379
00:18:05,590 --> 00:18:11,919
because there's not many out there so in

380
00:18:09,340 --> 00:18:14,770
itself it's also critical skills that is

381
00:18:11,920 --> 00:18:16,900
marketable as an individual you can go

382
00:18:14,770 --> 00:18:19,510
to a new company and say I know how to

383
00:18:16,900 --> 00:18:21,250
build software but also I know how to

384
00:18:19,510 --> 00:18:27,760
build software that are compliant with

385
00:18:21,250 --> 00:18:29,980
the law our privacy by design so there's

386
00:18:27,760 --> 00:18:33,430
a lot that in terms of privacy by design

387
00:18:29,980 --> 00:18:37,030
the software developers play a critical

388
00:18:33,430 --> 00:18:39,730
role they will make decision ethical

389
00:18:37,030 --> 00:18:44,170
decision that will affect all of us our

390
00:18:39,730 --> 00:18:47,350
children our society and do we do enough

391
00:18:44,170 --> 00:18:49,570
to explain to them what do we expect

392
00:18:47,350 --> 00:18:52,030
from a compliance perspective from a

393
00:18:49,570 --> 00:18:57,850
privacy perspective and from a security

394
00:18:52,030 --> 00:19:00,010
perspective there are success stories I

395
00:18:57,850 --> 00:19:03,340
am NOT preaching something that was

396
00:19:00,010 --> 00:19:05,470
never done before there our bronzer

397
00:19:03,340 --> 00:19:08,169
browser today like your popular browser

398
00:19:05,470 --> 00:19:11,770
like Google etc they allow you to

399
00:19:08,170 --> 00:19:13,680
activate do-not-track technology this is

400
00:19:11,770 --> 00:19:17,710
what we call a privacy enhancing

401
00:19:13,680 --> 00:19:21,730
technology these technologies were done

402
00:19:17,710 --> 00:19:24,880
were created before privacy by design so

403
00:19:21,730 --> 00:19:27,190
today they can be used by developers as

404
00:19:24,880 --> 00:19:30,580
building blocks that you can integrate

405
00:19:27,190 --> 00:19:34,210
into software development if that is

406
00:19:30,580 --> 00:19:37,060
aventuras to you Anisa has done in 2014

407
00:19:34,210 --> 00:19:40,290
a report of the best privacy enhancing

408
00:19:37,060 --> 00:19:42,700
technologies out there and has suggested

409
00:19:40,290 --> 00:19:44,950
methodologies of how we can evaluate

410
00:19:42,700 --> 00:19:46,900
whether they're good or not as stuff

411
00:19:44,950 --> 00:19:49,000
where developers you need to know like

412
00:19:46,900 --> 00:19:50,800
these are easy grabbing building blocks

413
00:19:49,000 --> 00:19:57,550
you don't need to start from scratch

414
00:19:50,800 --> 00:19:59,919
every time you build a software so the

415
00:19:57,550 --> 00:20:03,040
European Data Protection Board that is

416
00:19:59,920 --> 00:20:04,390
the entity that is in charge of applying

417
00:20:03,040 --> 00:20:07,470
the gdpr

418
00:20:04,390 --> 00:20:13,240
they said that to them privacy by design

419
00:20:07,470 --> 00:20:15,910
was first a good planning so it's all

420
00:20:13,240 --> 00:20:18,040
start with planning it means that you

421
00:20:15,910 --> 00:20:21,700
don't go into production with something

422
00:20:18,040 --> 00:20:25,360
you have not planned before second it

423
00:20:21,700 --> 00:20:26,980
means you need a risk-based approach why

424
00:20:25,360 --> 00:20:29,830
and that brings me to my third point

425
00:20:26,980 --> 00:20:34,480
because you need to identify controls

426
00:20:29,830 --> 00:20:35,949
that will address this risk those are

427
00:20:34,480 --> 00:20:37,960
familiar with security

428
00:20:35,950 --> 00:20:40,600
we use the term threats and

429
00:20:37,960 --> 00:20:44,470
vulnerabilities we can't use that with

430
00:20:40,600 --> 00:20:45,939
privacy because there's a lot of actions

431
00:20:44,470 --> 00:20:48,790
that are not necessarily consider

432
00:20:45,940 --> 00:20:52,690
threats but that are problematic from a

433
00:20:48,790 --> 00:20:55,060
privacy standpoint so a consent that is

434
00:20:52,690 --> 00:20:57,220
not informed is not really a threat from

435
00:20:55,060 --> 00:21:01,030
a security standpoint but it is a

436
00:20:57,220 --> 00:21:04,030
problematic data action so when you we

437
00:21:01,030 --> 00:21:07,840
approach privacy we approach it slightly

438
00:21:04,030 --> 00:21:09,760
different so the fact that privacy and

439
00:21:07,840 --> 00:21:12,730
security are similar does not mean that

440
00:21:09,760 --> 00:21:14,170
we need an indent achill approach this

441
00:21:12,730 --> 00:21:16,900
was recognized by NIST

442
00:21:14,170 --> 00:21:19,480
so they amended the risk management

443
00:21:16,900 --> 00:21:21,970
framework to include a privacy

444
00:21:19,480 --> 00:21:26,740
management framework and these suggested

445
00:21:21,970 --> 00:21:30,400
terms that were more adequate to them so

446
00:21:26,740 --> 00:21:32,350
iving do your planning having do your

447
00:21:30,400 --> 00:21:34,510
risk based approach and identify the

448
00:21:32,350 --> 00:21:36,580
controls you need to make sure they're

449
00:21:34,510 --> 00:21:39,910
implemented and you need to monitor this

450
00:21:36,580 --> 00:21:42,639
so this are these are the four principle

451
00:21:39,910 --> 00:21:46,360
privacy by design that I'm summarizing

452
00:21:42,640 --> 00:21:48,100
here about 100 pages in four words but

453
00:21:46,360 --> 00:21:52,449
you get the point it's a management

454
00:21:48,100 --> 00:21:54,459
approach and that is nothing different

455
00:21:52,450 --> 00:21:57,430
that what we know as software

456
00:21:54,460 --> 00:21:59,230
development lifecycle so for those of

457
00:21:57,430 --> 00:22:02,440
you that work in software engineering

458
00:21:59,230 --> 00:22:06,040
you know this the key point here is that

459
00:22:02,440 --> 00:22:09,850
you need phases you need an organized

460
00:22:06,040 --> 00:22:11,560
approach and I know a lot of people

461
00:22:09,850 --> 00:22:13,449
today a lot of software developers are

462
00:22:11,560 --> 00:22:16,090
working around with the agile

463
00:22:13,450 --> 00:22:18,010
methodology that doesn't mean you don't

464
00:22:16,090 --> 00:22:18,409
have phases that means that you're going

465
00:22:18,010 --> 00:22:20,600
back

466
00:22:18,410 --> 00:22:24,740
and forth between phases more often

467
00:22:20,600 --> 00:22:27,439
using cycles that's fine whether you use

468
00:22:24,740 --> 00:22:29,240
this or a waterfall methodology it's all

469
00:22:27,440 --> 00:22:31,460
fine but you need to make sure you have

470
00:22:29,240 --> 00:22:34,520
sufficient planning and sufficient

471
00:22:31,460 --> 00:22:36,950
iterations between the phases so that

472
00:22:34,520 --> 00:22:39,500
nothing goes into production without

473
00:22:36,950 --> 00:22:42,230
sufficient testing and all of this

474
00:22:39,500 --> 00:22:45,320
documented because if you get sued you

475
00:22:42,230 --> 00:22:47,750
need to be able to show this happen so

476
00:22:45,320 --> 00:22:50,179
that's why when I go to client place and

477
00:22:47,750 --> 00:22:54,350
say I do all of this Vanessa don't worry

478
00:22:50,180 --> 00:22:58,430
okay show me and that's usually where

479
00:22:54,350 --> 00:23:00,429
things start to crumble apart we have a

480
00:22:58,430 --> 00:23:03,140
lot of general policies and companies

481
00:23:00,430 --> 00:23:05,770
not so much interested into general

482
00:23:03,140 --> 00:23:08,510
policies I'm interested in two processes

483
00:23:05,770 --> 00:23:11,180
evidences that these processes are being

484
00:23:08,510 --> 00:23:13,460
followed that they are understood by

485
00:23:11,180 --> 00:23:18,350
everyone and in particular the

486
00:23:13,460 --> 00:23:23,090
developers at the Tai Chi system for

487
00:23:18,350 --> 00:23:25,909
security we follow these five phases we

488
00:23:23,090 --> 00:23:28,370
look at planning we look at encoding and

489
00:23:25,910 --> 00:23:30,950
when I talk about encoding is not just

490
00:23:28,370 --> 00:23:33,500
encode everything or just anything you

491
00:23:30,950 --> 00:23:36,380
have to do it in a secure manner in a

492
00:23:33,500 --> 00:23:39,200
way that is documented you have to do

493
00:23:36,380 --> 00:23:41,630
secure code reviews you have to look at

494
00:23:39,200 --> 00:23:44,540
your source code and make sure that what

495
00:23:41,630 --> 00:23:48,920
you have built what you have coded in

496
00:23:44,540 --> 00:23:51,440
there is actually secure so you don't

497
00:23:48,920 --> 00:23:54,740
just do anything just to follow the

498
00:23:51,440 --> 00:23:59,960
phases every phase come with its own set

499
00:23:54,740 --> 00:24:02,960
of processes then come testing this is

500
00:23:59,960 --> 00:24:04,610
not where you wanna go faster and taste

501
00:24:02,960 --> 00:24:08,110
test a little less I think we had that

502
00:24:04,610 --> 00:24:10,909
conversation with somebody yesterday

503
00:24:08,110 --> 00:24:12,469
somebody was telling to me my team was

504
00:24:10,910 --> 00:24:14,960
trying to save money so they were trying

505
00:24:12,470 --> 00:24:16,850
to bypass the testing phase it's not the

506
00:24:14,960 --> 00:24:20,570
face you want to bypass actually none of

507
00:24:16,850 --> 00:24:22,669
them you want to bypass you don't just

508
00:24:20,570 --> 00:24:25,270
let go of a software that was not tested

509
00:24:22,670 --> 00:24:27,650
that means to do intrusion detection

510
00:24:25,270 --> 00:24:30,590
that means to do vulnerability

511
00:24:27,650 --> 00:24:31,500
assessment to do it internally and if

512
00:24:30,590 --> 00:24:34,110
you can

513
00:24:31,500 --> 00:24:36,350
have the financial means to do so with a

514
00:24:34,110 --> 00:24:39,600
third party that isn't dependent you

515
00:24:36,350 --> 00:24:41,189
need segregation of duty the person who

516
00:24:39,600 --> 00:24:43,919
created the software is not the right

517
00:24:41,190 --> 00:24:46,170
person to test the software this person

518
00:24:43,920 --> 00:24:49,710
has too much in the game as too much

519
00:24:46,170 --> 00:24:51,840
skin in the game so we know human nature

520
00:24:49,710 --> 00:24:55,560
as it is you need to look for your

521
00:24:51,840 --> 00:24:58,919
quality assessment team and then you

522
00:24:55,560 --> 00:25:01,080
deploy again you don't just do it and

523
00:24:58,920 --> 00:25:03,810
hope for the best you do it in a

524
00:25:01,080 --> 00:25:06,689
systematic manner an organized manner

525
00:25:03,810 --> 00:25:09,780
and you measure the success of your

526
00:25:06,690 --> 00:25:12,030
deployment and then you manage your

527
00:25:09,780 --> 00:25:14,220
platform so when you're managing your

528
00:25:12,030 --> 00:25:17,280
platform you want to make sure that you

529
00:25:14,220 --> 00:25:20,130
have a systematic approach an organized

530
00:25:17,280 --> 00:25:22,440
approach to make sure that it is tested

531
00:25:20,130 --> 00:25:25,080
regularly reviewed regularly and not

532
00:25:22,440 --> 00:25:27,750
just when it's the end of the month or

533
00:25:25,080 --> 00:25:29,970
when it's you have an extra $10,000 in

534
00:25:27,750 --> 00:25:33,870
your budget it has to be planned for

535
00:25:29,970 --> 00:25:36,720
fiscal year 2019 here are the security

536
00:25:33,870 --> 00:25:39,870
measures that I will implement to make

537
00:25:36,720 --> 00:25:43,730
sure that my software remains secure

538
00:25:39,870 --> 00:25:53,790
given what we know this fiscal year 2019

539
00:25:43,730 --> 00:25:56,430
about new treads planning and design is

540
00:25:53,790 --> 00:25:59,909
probably one of the most important phase

541
00:25:56,430 --> 00:26:02,850
and overlooked phase this is where you

542
00:25:59,910 --> 00:26:05,040
need to go get your privacy expert your

543
00:26:02,850 --> 00:26:07,080
lawyers sit them in the room and say

544
00:26:05,040 --> 00:26:10,560
listen to what I want to do it what do

545
00:26:07,080 --> 00:26:13,139
you think about it typically we start

546
00:26:10,560 --> 00:26:16,620
that conversation around data mapping so

547
00:26:13,140 --> 00:26:18,840
I need to see on a map and it looks like

548
00:26:16,620 --> 00:26:21,570
this so obviously that's not a real case

549
00:26:18,840 --> 00:26:24,179
example but I need to see on a map

550
00:26:21,570 --> 00:26:26,850
where's my personal information going

551
00:26:24,180 --> 00:26:29,120
where is it at rest when where is it

552
00:26:26,850 --> 00:26:31,980
that used and where is it encrypted

553
00:26:29,120 --> 00:26:34,379
otherwise as a data protection officer

554
00:26:31,980 --> 00:26:35,760
it's very difficult for me to advise us

555
00:26:34,380 --> 00:26:38,220
to whether you have the right controls

556
00:26:35,760 --> 00:26:39,960
in place I need to see that road that

557
00:26:38,220 --> 00:26:43,730
you're taking and I want to make sure

558
00:26:39,960 --> 00:26:43,730
that there's no warning on that road

559
00:26:45,750 --> 00:26:50,919
once I have that word then we can look

560
00:26:48,640 --> 00:26:52,770
at the risk and when I look at the risk

561
00:26:50,919 --> 00:26:55,600
I look at the worst case scenario

562
00:26:52,770 --> 00:26:59,918
assuming you have zero control in place

563
00:26:55,600 --> 00:27:01,779
this is what could happen and then you

564
00:26:59,919 --> 00:27:04,450
say okay what control do I need to

565
00:27:01,779 --> 00:27:06,520
address that critical situation so you

566
00:27:04,450 --> 00:27:08,740
don't start from the assumption that you

567
00:27:06,520 --> 00:27:11,770
have controls you start from the

568
00:27:08,740 --> 00:27:13,630
assumption that this is what happens if

569
00:27:11,770 --> 00:27:16,929
I don't touch nothing this is my project

570
00:27:13,630 --> 00:27:19,929
I want to take all the health data from

571
00:27:16,929 --> 00:27:22,360
this population and process it what

572
00:27:19,929 --> 00:27:24,190
could happen well if there's a data

573
00:27:22,360 --> 00:27:26,500
breach it can be dangerous because

574
00:27:24,190 --> 00:27:29,080
people have a high expectation of

575
00:27:26,500 --> 00:27:31,390
privacy okay what do I need to address

576
00:27:29,080 --> 00:27:33,789
this this is the conversation you need

577
00:27:31,390 --> 00:27:35,260
to have with your lawyers it's a

578
00:27:33,789 --> 00:27:38,200
conversation you need to have with your

579
00:27:35,260 --> 00:27:41,080
privacy expert and this is why this is

580
00:27:38,200 --> 00:27:42,909
an interdisciplinary conversation where

581
00:27:41,080 --> 00:27:46,090
you will need to speak legal and they

582
00:27:42,909 --> 00:27:47,370
will need to speak technical and this is

583
00:27:46,090 --> 00:27:51,520
not easy

584
00:27:47,370 --> 00:27:55,570
actually NIST has conducted a study and

585
00:27:51,520 --> 00:27:59,168
they say one of the major problem they

586
00:27:55,570 --> 00:28:02,500
have with articulating privacy is the

587
00:27:59,169 --> 00:28:07,179
lack of communication between technical

588
00:28:02,500 --> 00:28:09,720
people and legal people I always say if

589
00:28:07,179 --> 00:28:11,919
I ask software developer to do a

590
00:28:09,720 --> 00:28:14,559
software that is transparent that means

591
00:28:11,919 --> 00:28:16,409
nothing to them so I need to find better

592
00:28:14,559 --> 00:28:20,020
words words that they can actually

593
00:28:16,409 --> 00:28:22,990
translate into binary codes words that

594
00:28:20,020 --> 00:28:25,299
translate into functionalities and as a

595
00:28:22,990 --> 00:28:27,309
data protection officer I have to make

596
00:28:25,299 --> 00:28:29,980
the sufficient research I have to turn

597
00:28:27,309 --> 00:28:34,600
myself into somebody technical if I want

598
00:28:29,980 --> 00:28:36,390
results and this is an example of how

599
00:28:34,600 --> 00:28:38,949
you can do it

600
00:28:36,390 --> 00:28:43,299
accountability can become predictability

601
00:28:38,950 --> 00:28:46,960
so predictability and accountability are

602
00:28:43,299 --> 00:28:48,820
both meta objective so objective that

603
00:28:46,960 --> 00:28:51,690
are kind of a background to all the

604
00:28:48,820 --> 00:28:53,740
other objective you want to be able to

605
00:28:51,690 --> 00:28:55,390
say you're doing something and

606
00:28:53,740 --> 00:28:57,429
demonstrate that you're doing something

607
00:28:55,390 --> 00:28:58,520
and make sure that it's always doing

608
00:28:57,429 --> 00:29:01,280
what you say you're doing

609
00:28:58,520 --> 00:29:03,530
so that's predictability which makes a

610
00:29:01,280 --> 00:29:06,110
lot more sense to software engineers

611
00:29:03,530 --> 00:29:09,350
than accountability that is not the

612
00:29:06,110 --> 00:29:13,040
technical term you can look at

613
00:29:09,350 --> 00:29:15,709
manageability and say that data

614
00:29:13,040 --> 00:29:18,649
minimization could be articulated

615
00:29:15,710 --> 00:29:23,320
through manageability that means don't

616
00:29:18,650 --> 00:29:26,090
over collect that's not manageable right

617
00:29:23,320 --> 00:29:27,129
so these are example of requirement we

618
00:29:26,090 --> 00:29:31,879
talked about predictability

619
00:29:27,130 --> 00:29:34,670
manageability dissociate bility and if

620
00:29:31,880 --> 00:29:37,550
you look into nist and you can look

621
00:29:34,670 --> 00:29:40,090
there many methodologies online that are

622
00:29:37,550 --> 00:29:43,700
suggesting some criterias that you can

623
00:29:40,090 --> 00:29:47,179
look into it like unlink ability for

624
00:29:43,700 --> 00:29:49,250
example what's important is to develop a

625
00:29:47,180 --> 00:29:52,850
glossary in your company to make sure

626
00:29:49,250 --> 00:29:55,340
that you are understood and that this

627
00:29:52,850 --> 00:29:57,409
verse as well right it goes both way so

628
00:29:55,340 --> 00:30:00,620
lawyers need to understand that but

629
00:29:57,410 --> 00:30:03,230
software engineers always have to do the

630
00:30:00,620 --> 00:30:09,229
extra step to explain what they do so

631
00:30:03,230 --> 00:30:12,050
that we can actually be useful so I'm

632
00:30:09,230 --> 00:30:15,140
very lucky because I was allowed to use

633
00:30:12,050 --> 00:30:18,440
our own software as a case study it's a

634
00:30:15,140 --> 00:30:21,200
software that is not well we are

635
00:30:18,440 --> 00:30:23,090
actually our control 5.0 software in the

636
00:30:21,200 --> 00:30:23,540
market and we're going to release next

637
00:30:23,090 --> 00:30:26,179
month

638
00:30:23,540 --> 00:30:28,850
archangels 6.0 which we like to call

639
00:30:26,180 --> 00:30:30,920
next-gen well we like to call it like

640
00:30:28,850 --> 00:30:33,469
that because instead of trying to do

641
00:30:30,920 --> 00:30:36,290
reverse engineering of our and giant to

642
00:30:33,470 --> 00:30:40,370
make sure if it's new legal requirements

643
00:30:36,290 --> 00:30:42,850
we basically built it from scratch so I

644
00:30:40,370 --> 00:30:45,830
was involved in every step of the way so

645
00:30:42,850 --> 00:30:49,520
this is how I can come up today with

646
00:30:45,830 --> 00:30:52,220
this methodology and this advice so in

647
00:30:49,520 --> 00:30:54,500
order for you to understand our control

648
00:30:52,220 --> 00:30:56,750
is that little logo you can see in the

649
00:30:54,500 --> 00:31:01,820
middle it's a software it's a low

650
00:30:56,750 --> 00:31:05,000
correlation software here how it works

651
00:31:01,820 --> 00:31:09,110
we have arc edge that are basically

652
00:31:05,000 --> 00:31:12,380
little sensors that connect lugs from

653
00:31:09,110 --> 00:31:16,580
various points so we are able with arc

654
00:31:12,380 --> 00:31:19,970
to collect logs from the clouds from ATM

655
00:31:16,580 --> 00:31:22,280
machine machines from the OT sector or

656
00:31:19,970 --> 00:31:25,280
most traditionally from our clients

657
00:31:22,280 --> 00:31:27,649
Network we take all that information and

658
00:31:25,280 --> 00:31:29,780
all these logs that we get are from

659
00:31:27,650 --> 00:31:33,650
controls that you have in place your

660
00:31:29,780 --> 00:31:35,990
antivirus your firewall they speak but

661
00:31:33,650 --> 00:31:39,560
they speak a lot and they have sometimes

662
00:31:35,990 --> 00:31:41,800
more than 1 million logs in a day so

663
00:31:39,560 --> 00:31:44,810
that's a lot of information to

664
00:31:41,800 --> 00:31:47,659
understand so that's why we built our

665
00:31:44,810 --> 00:31:51,980
control that information goes into our

666
00:31:47,660 --> 00:31:53,930
clique which is like a repository and it

667
00:31:51,980 --> 00:31:56,960
goes on in the Itachi correlation and

668
00:31:53,930 --> 00:31:59,450
giant which is next-gen next-gen takes

669
00:31:56,960 --> 00:32:02,120
all of this data about all the controls

670
00:31:59,450 --> 00:32:04,070
of all our client we have a big privacy

671
00:32:02,120 --> 00:32:06,560
problem here because all of these lugs

672
00:32:04,070 --> 00:32:08,389
have a lot of information that we don't

673
00:32:06,560 --> 00:32:10,490
have in control sometimes we tell our

674
00:32:08,390 --> 00:32:12,740
client why are you collecting this but

675
00:32:10,490 --> 00:32:15,920
we don't get to control what's in the

676
00:32:12,740 --> 00:32:17,930
logs we can have sometimes credit cards

677
00:32:15,920 --> 00:32:22,460
number Social Security number

678
00:32:17,930 --> 00:32:24,440
we definitely have IP o's names so

679
00:32:22,460 --> 00:32:26,360
that's a problem when we sat down we say

680
00:32:24,440 --> 00:32:28,940
how do we manage that extraordinary

681
00:32:26,360 --> 00:32:31,189
amount of personal information that we

682
00:32:28,940 --> 00:32:33,800
are collecting which we need to collect

683
00:32:31,190 --> 00:32:37,430
for security purposes right so managed

684
00:32:33,800 --> 00:32:39,440
security purposes the whole point is for

685
00:32:37,430 --> 00:32:42,560
that correlation in giant to come out

686
00:32:39,440 --> 00:32:46,070
and say oh I have an incident so that's

687
00:32:42,560 --> 00:32:48,290
a legitimate interest of a business and

688
00:32:46,070 --> 00:32:51,710
that incidents then we escalate to the

689
00:32:48,290 --> 00:32:55,280
clients but we want to make sure that

690
00:32:51,710 --> 00:32:57,560
we're doing this in the most respect of

691
00:32:55,280 --> 00:33:00,139
privacy as possible that we are not

692
00:32:57,560 --> 00:33:01,850
doing false judgment or inaccurate

693
00:33:00,140 --> 00:33:05,630
judgment about the employees that were

694
00:33:01,850 --> 00:33:07,310
monitoring and we want to make sure even

695
00:33:05,630 --> 00:33:07,730
though we have amazing employee we trust

696
00:33:07,310 --> 00:33:10,310
them

697
00:33:07,730 --> 00:33:12,560
we do background screening we want to

698
00:33:10,310 --> 00:33:14,120
make sure that the information that they

699
00:33:12,560 --> 00:33:17,629
get all of this information they don't

700
00:33:14,120 --> 00:33:19,489
get it in plain view in plain view so

701
00:33:17,630 --> 00:33:21,890
one of the challenge we face in doing

702
00:33:19,490 --> 00:33:24,860
this is that in order for us to be able

703
00:33:21,890 --> 00:33:25,789
to still do our job but a fist get the

704
00:33:24,860 --> 00:33:28,299
data we

705
00:33:25,789 --> 00:33:31,279
needed to do it at the cell level

706
00:33:28,299 --> 00:33:33,590
traditional database schema less

707
00:33:31,279 --> 00:33:37,190
database system allows you to do

708
00:33:33,590 --> 00:33:39,859
efficient encryption and the like but in

709
00:33:37,190 --> 00:33:42,019
a row level and a relational aspect so

710
00:33:39,859 --> 00:33:44,989
you can have let's see the whole file

711
00:33:42,019 --> 00:33:48,259
about Vanessa angry that is obfuscate it

712
00:33:44,989 --> 00:33:50,720
but you can't office Kate just off of my

713
00:33:48,259 --> 00:33:53,179
name and that's a problem because we

714
00:33:50,720 --> 00:33:55,429
needed to do that in order to be gdpr

715
00:33:53,179 --> 00:33:57,379
compliant and we want it to be not only

716
00:33:55,429 --> 00:34:00,919
to depower compliant we want it to be

717
00:33:57,379 --> 00:34:03,379
certified so we looked into a criminal

718
00:34:00,919 --> 00:34:06,590
which is another database that allowed

719
00:34:03,379 --> 00:34:10,399
us to do cell level security and cell

720
00:34:06,590 --> 00:34:14,480
level efficient so that's not easy to do

721
00:34:10,399 --> 00:34:17,299
because a human or it's more difficult

722
00:34:14,480 --> 00:34:18,710
to manage it took time and you don't you

723
00:34:17,299 --> 00:34:21,770
want to make sure you're not affecting

724
00:34:18,710 --> 00:34:25,339
the operational ability of your software

725
00:34:21,770 --> 00:34:27,199
either but we did it and that's what it

726
00:34:25,339 --> 00:34:30,049
looks like cell level security

727
00:34:27,199 --> 00:34:32,299
I can pick what I need to I which means

728
00:34:30,049 --> 00:34:35,059
that my analyst can still look at

729
00:34:32,299 --> 00:34:36,500
security incident escalate them but

730
00:34:35,059 --> 00:34:38,990
don't see things they don't need to see

731
00:34:36,500 --> 00:34:41,299
so if they need to see for example the

732
00:34:38,989 --> 00:34:42,469
IP address because they need to know

733
00:34:41,299 --> 00:34:44,599
where it's coming from

734
00:34:42,469 --> 00:34:48,558
they probably don't need to see the

735
00:34:44,599 --> 00:34:50,929
credit card number in there that allowed

736
00:34:48,559 --> 00:34:52,639
us to do data of doing permissions that

737
00:34:50,929 --> 00:34:55,399
we couldn't do before with our software

738
00:34:52,639 --> 00:34:58,760
so the data owner is the client and you

739
00:34:55,399 --> 00:35:00,680
have different security analyst level of

740
00:34:58,760 --> 00:35:04,549
permission that the client can freely

741
00:35:00,680 --> 00:35:06,440
assign and it looks like this when that

742
00:35:04,549 --> 00:35:09,770
leaves visible and clear they see all of

743
00:35:06,440 --> 00:35:13,700
this but then with the role based access

744
00:35:09,770 --> 00:35:16,599
control decisions just specific part of

745
00:35:13,700 --> 00:35:21,529
it and the client have control over this

746
00:35:16,599 --> 00:35:24,109
and we can do a data animation which

747
00:35:21,530 --> 00:35:29,180
allows us to be way more secure than we

748
00:35:24,109 --> 00:35:31,819
used to be so closing down on this I'd

749
00:35:29,180 --> 00:35:35,980
like us to reflect on how privacy is a

750
00:35:31,819 --> 00:35:39,290
multidisciplinary approach between law

751
00:35:35,980 --> 00:35:42,170
sociology and formation security at six

752
00:35:39,290 --> 00:35:44,750
and economics and our each of us with

753
00:35:42,170 --> 00:35:50,150
our different background can contribute

754
00:35:44,750 --> 00:35:53,180
to this because we need to let that sink

755
00:35:50,150 --> 00:35:54,890
in that we are building technologies

756
00:35:53,180 --> 00:35:57,319
that will affect our kids that will

757
00:35:54,890 --> 00:35:58,759
affect our future and we want to make

758
00:35:57,320 --> 00:36:00,980
sure that the technologies that were

759
00:35:58,760 --> 00:36:02,900
building we are building it for the

760
00:36:00,980 --> 00:36:04,880
users we are building it for the

761
00:36:02,900 --> 00:36:07,400
individuals for the rights and freedom

762
00:36:04,880 --> 00:36:08,410
and we are socially responsible in to

763
00:36:07,400 --> 00:36:11,560
what we do

764
00:36:08,410 --> 00:36:11,560
thank you

765
00:36:11,940 --> 00:36:16,670
[Applause]

