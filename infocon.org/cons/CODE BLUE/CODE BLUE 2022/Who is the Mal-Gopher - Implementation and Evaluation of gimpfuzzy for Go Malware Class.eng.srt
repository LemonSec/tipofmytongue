1
00:00:01,740 --> 00:00:02,879
So

2
00:00:02,879 --> 00:00:04,319


3
00:00:04,319 --> 00:00:07,580
let me start the presentation of Whoisthemalcorpher.

4
00:00:10,380 --> 00:00:14,400
First, let me briefly introduce ourselves. This

5
00:00:14,400 --> 00:00:16,560
lecture was given

6
00:00:16,560 --> 00:00:17,820


7
00:00:17,820 --> 00:00:20,580
by three people: Yuta Sawade, Nobuyuki Ugasa, and Kazuya Nomura.

8
00:00:20,580 --> 00:00:21,779
We are

9
00:00:21,779 --> 00:00:23,460


10
00:00:23,460 --> 00:00:24,300


11
00:00:24,300 --> 00:00:25,619
analysts at NTT Security Holdings.

12
00:00:25,619 --> 00:00:28,199
I belong to the same team as

13
00:00:28,199 --> 00:00:31,080
.In my daily work, I analyze and report on customer logs,

14
00:00:31,080 --> 00:00:33,960
as well as conduct malware analysis and research

15
00:00:33,960 --> 00:00:36,899
work to investigate the latest trends in threats

16
00:00:36,899 --> 00:00:39,360
.

17
00:00:39,360 --> 00:00:41,100


18
00:00:41,100 --> 00:00:44,719


19
00:00:47,100 --> 00:00:49,800
First of all, I will explain the motivation and goals

20
00:00:49,800 --> 00:00:51,840
of our school. In

21
00:00:51,840 --> 00:00:52,920
this presentation,

22
00:00:52,920 --> 00:00:54,480


23
00:00:54,480 --> 00:00:57,899
we will take up the classification of 50wares that have been increasing in recent years.

24
00:00:57,899 --> 00:01:00,600
Attackers are

25
00:01:00,600 --> 00:01:02,699
constantly seeking new attack methods and

26
00:01:02,699 --> 00:01:04,680
techniques to avoid detection of attacks

27
00:01:04,680 --> 00:01:06,420
.  One

28
00:01:06,420 --> 00:01:08,460
of them is to write malware in a new language

29
00:01:08,460 --> 00:01:10,740


30
00:01:10,740 --> 00:01:13,439
.

31
00:01:13,439 --> 00:01:15,960
Maruyama, written in the relatively new language GO, is difficult to analyze because of its unique structure

32
00:01:15,960 --> 00:01:18,240
that requires a different analysis method from existing ones.

33
00:01:18,240 --> 00:01:19,140


34
00:01:19,140 --> 00:01:22,560


35
00:01:22,560 --> 00:01:23,939
Therefore, there is a demand to classify

36
00:01:23,939 --> 00:01:26,100
many 50wares at high speed without incurring analysis costs,

37
00:01:26,100 --> 00:01:28,920
or

38
00:01:28,920 --> 00:01:31,500
to search for similar specimens.In

39
00:01:31,500 --> 00:01:33,299


40
00:01:33,299 --> 00:01:34,860
this presentation, we will introduce

41
00:01:34,860 --> 00:01:37,200


42
00:01:37,200 --> 00:01:37,920


43
00:01:37,920 --> 00:01:41,600
deep fuzzy, an index for efficiently classifying 50airs.  In

44
00:01:41,700 --> 00:01:43,020
the first half of the presentation, I

45
00:01:43,020 --> 00:01:44,939
will introduce the features of 504, and explain

46
00:01:44,939 --> 00:01:47,340
how the proposed method performs the quantification

47
00:01:47,340 --> 00:01:50,280


48
00:01:50,280 --> 00:01:52,560


49
00:01:52,560 --> 00:01:55,759
.

50
00:01:55,860 --> 00:01:57,119
In the second half of

51
00:01:57,119 --> 00:01:58,979


52
00:01:58,979 --> 00:01:59,880


53
00:01:59,880 --> 00:02:03,740
this article, I will introduce some examples of classification using deep fuzzy as case studies.

54
00:02:06,659 --> 00:02:08,160
First, let

55
00:02:08,160 --> 00:02:09,840
's look at the characteristics of malware written in GO.

56
00:02:09,840 --> 00:02:12,440


57
00:02:14,700 --> 00:02:17,520


58
00:02:17,520 --> 00:02:18,239


59
00:02:18,239 --> 00:02:19,940


60
00:02:19,940 --> 00:02:22,739
This language

61
00:02:22,739 --> 00:02:25,920
was developed to improve the shortcomings of the existing languages ​​C and C+.

62
00:02:25,920 --> 00:02:27,540


63
00:02:27,540 --> 00:02:29,819


64
00:02:29,819 --> 00:02:31,560
It supports the evolution of modern advanced networks and hardware,

65
00:02:31,560 --> 00:02:33,840
and supports efficient and safe equilibrium processing

66
00:02:33,840 --> 00:02:37,680
.  It

67
00:02:37,680 --> 00:02:38,640


68
00:02:38,640 --> 00:02:42,060
's one of the most widely used languages ​​because it works well and it's easy to describe behavior.

69
00:02:42,060 --> 00:02:43,680
One of its features is that it's

70
00:02:43,680 --> 00:02:46,379
cross-platform.

71
00:02:46,379 --> 00:02:48,420


72
00:02:48,420 --> 00:02:50,700
It makes it possible to build on the platform.This makes it possible

73
00:02:50,700 --> 00:02:51,420


74
00:02:51,420 --> 00:02:53,400


75
00:02:53,400 --> 00:02:54,900


76
00:02:54,900 --> 00:02:57,000


77
00:02:57,000 --> 00:02:59,040
to efficiently develop code that runs in a wide range of environments, from cos

78
00:02:59,040 --> 00:03:02,420


79
00:03:02,640 --> 00:03:04,500
such as Windows and

80
00:03:04,500 --> 00:03:06,180
MacLinux to web accents and Android.  Malware is

81
00:03:06,180 --> 00:03:07,680
increasing.

82
00:03:07,680 --> 00:03:08,519
For example, many samples of ransomware rats and botnets have

83
00:03:08,519 --> 00:03:10,440
been confirmed due to the extensive standard libraries for encryption and networks.

84
00:03:10,440 --> 00:03:11,819


85
00:03:11,819 --> 00:03:13,500


86
00:03:13,500 --> 00:03:15,420


87
00:03:15,420 --> 00:03:17,099


88
00:03:17,099 --> 00:03:17,940


89
00:03:17,940 --> 00:03:20,159


90
00:03:20,159 --> 00:03:21,599


91
00:03:21,599 --> 00:03:23,580


92
00:03:23,580 --> 00:03:25,980
50s are being used in Asian services.In addition, there are cases where

93
00:03:25,980 --> 00:03:27,000


94
00:03:27,000 --> 00:03:28,860
existing malware downloads and

95
00:03:28,860 --> 00:03:31,440
droppers are written in 5 and rewritten to 50ware with minimal

96
00:03:31,440 --> 00:03:33,360
rewriting.This

97
00:03:33,360 --> 00:03:35,959


98
00:03:38,099 --> 00:03:41,640
figure shows the 50air observed in recent years

99
00:03:41,640 --> 00:03:43,440
It is organized by series.

100
00:03:43,440 --> 00:03:46,140
After the first malware written in goal was observed in 2012, it

101
00:03:46,140 --> 00:03:49,260


102
00:03:49,260 --> 00:03:52,860
tends to increase by 50 years each year.At first, backdoors

103
00:03:52,860 --> 00:03:55,319
and botnets were common, but in

104
00:03:55,319 --> 00:03:56,220
recent years, the

105
00:03:56,220 --> 00:03:58,500
figure  As shown in red and green in ,

106
00:03:58,500 --> 00:04:00,840


107
00:04:00,840 --> 00:04:02,760
there are many

108
00:04:02,760 --> 00:04:04,500


109
00:04:04,500 --> 00:04:07,260
reports of ransomware and rats

110
00:04:07,260 --> 00:04:09,540


111
00:04:09,540 --> 00:04:12,360
written in GO.  The threat of Mario written in Chapter 5

112
00:04:12,360 --> 00:04:15,920
has become widely recognized.

113
00:04:16,798 --> 00:04:19,798
So why is malware written in

114
00:04:19,798 --> 00:04:21,959
this number increasing?

115
00:04:21,959 --> 00:04:24,660


116
00:04:24,660 --> 00:04:28,040
Let me start by introducing the

117
00:04:28,259 --> 00:04:29,699


118
00:04:29,699 --> 00:04:31,620
attacker's point of view.

119
00:04:31,620 --> 00:04:33,720
Until now, many ballets

120
00:04:33,720 --> 00:04:35,220


121
00:04:35,220 --> 00:04:37,259
have targeted the Windows environment, which has a large number of users, for reasons of cost versus cost.

122
00:04:37,259 --> 00:04:39,240


123
00:04:39,240 --> 00:04:40,380


124
00:04:40,380 --> 00:04:41,940


125
00:04:41,940 --> 00:04:44,160


126
00:04:44,160 --> 00:04:46,320
Targeted specimens

127
00:04:46,320 --> 00:04:47,160


128
00:04:47,160 --> 00:04:49,440
can be generated without the need for new creation

129
00:04:49,440 --> 00:04:51,000


130
00:04:51,000 --> 00:04:54,960
costs.In addition, since it operates at high speed and robust behavior can be easily described

131
00:04:54,960 --> 00:04:56,400


132
00:04:56,400 --> 00:04:59,280
, specimens can be reliably operated in the target environment.

133
00:04:59,280 --> 00:05:00,960


134
00:05:00,960 --> 00:05:01,979


135
00:05:01,979 --> 00:05:05,639
is a language that is easy to develop

136
00:05:05,639 --> 00:05:08,639


137
00:05:08,639 --> 00:05:09,720


138
00:05:09,720 --> 00:05:11,400
maruware, and 5 tends to increase the size of files due to sexual linking of

139
00:05:11,400 --> 00:05:12,600
libraries

140
00:05:12,600 --> 00:05:15,360
Minimum  However, on the numerical side and large ones, the

141
00:05:15,360 --> 00:05:18,000
size is close to 100 MB

142
00:05:18,000 --> 00:05:20,280
,

143
00:05:20,280 --> 00:05:24,080
so there is also the point that the samples are difficult to detect

144
00:05:27,479 --> 00:05:30,419


145
00:05:30,419 --> 00:05:32,759
by antiviruses and sandboxes.

146
00:05:32,759 --> 00:05:33,720


147
00:05:33,720 --> 00:05:35,639


148
00:05:35,639 --> 00:05:36,660


149
00:05:36,660 --> 00:05:39,720


150
00:05:39,720 --> 00:05:40,620


151
00:05:40,620 --> 00:05:43,080
Therefore, reverse engineering is relatively difficult and

152
00:05:43,080 --> 00:05:43,979


153
00:05:43,979 --> 00:05:46,620
analysis costs a lot

154
00:05:46,620 --> 00:05:48,360


155
00:05:48,360 --> 00:05:51,720
.  It

156
00:05:51,720 --> 00:05:52,800


157
00:05:52,800 --> 00:05:55,199
shows the functions created by both and confirmed by Research Central.By

158
00:05:55,199 --> 00:05:56,880


159
00:05:56,880 --> 00:05:59,639
comparing the sheets, you can see that the binary written in 5

160
00:05:59,639 --> 00:06:01,380
has many functions.It is

161
00:06:01,380 --> 00:06:03,360


162
00:06:03,360 --> 00:06:04,320
also

163
00:06:04,320 --> 00:06:06,360
common to malware written in a new language.

164
00:06:06,360 --> 00:06:08,039
As for the characteristics of the

165
00:06:08,039 --> 00:06:10,080
analysis, there are issues such as the lack of analysis tools

166
00:06:10,080 --> 00:06:12,419
and the high learning cost of

167
00:06:12,419 --> 00:06:15,198


168
00:06:15,419 --> 00:06:16,500


169
00:06:16,500 --> 00:06:17,460


170
00:06:17,460 --> 00:06:19,380


171
00:06:19,380 --> 00:06:20,880


172
00:06:20,880 --> 00:06:21,960


173
00:06:21,960 --> 00:06:23,280
the analyst.

174
00:06:23,280 --> 00:06:26,100


175
00:06:26,100 --> 00:06:29,639


176
00:06:29,639 --> 00:06:33,300
There is a need for a method that can quickly classify or search for similar morphologies without incurring analysis costs.In

177
00:06:33,300 --> 00:06:35,940
this presentation, we will discuss a new method to

178
00:06:35,940 --> 00:06:38,539


179
00:06:39,720 --> 00:06:42,539
achieve this.I will now

180
00:06:42,539 --> 00:06:44,280
explain the fuzzy algorithm for pregnant women that I will propose this time

181
00:06:44,280 --> 00:06:46,638
.

182
00:06:46,680 --> 00:06:49,080
and Malware Bazaar, etc.

183
00:06:49,080 --> 00:06:51,180


184
00:06:51,180 --> 00:06:53,580


185
00:06:53,580 --> 00:06:54,300


186
00:06:54,300 --> 00:06:57,060
Various indicators have been introduced to the common rock sample sharing platform for sample plyfiling and classification search.In

187
00:06:57,060 --> 00:07:00,300
addition, various indicators

188
00:07:00,300 --> 00:07:03,600
have been proposed for Maria classification.  There

189
00:07:03,600 --> 00:07:05,940
are ssdp and tlsh, which are Ajin hash algorithms, imp hash,

190
00:07:05,940 --> 00:07:09,539


191
00:07:09,539 --> 00:07:10,740
which focuses on the import table of PE Maruware,

192
00:07:10,740 --> 00:07:14,100
and

193
00:07:14,100 --> 00:07:16,020


194
00:07:16,020 --> 00:07:19,400
silver wave dispatch, which focuses on the properties of plywood

195
00:07:19,620 --> 00:07:21,300


196
00:07:21,300 --> 00:07:22,440


197
00:07:22,440 --> 00:07:25,199
.

198
00:07:25,199 --> 00:07:27,419
It

199
00:07:27,419 --> 00:07:30,120
has a structure called pcnn tab, and it is

200
00:07:30,120 --> 00:07:32,880


201
00:07:32,880 --> 00:07:34,500
possible to restore dependent package names, function names, etc. A

202
00:07:34,500 --> 00:07:37,020
[ __ ] hash is a part of the restored package names and

203
00:07:37,020 --> 00:07:38,400
function names

204
00:07:38,400 --> 00:07:40,380
that have been deleted with general names, and has been

205
00:07:40,380 --> 00:07:43,199
processed for 8 weeks with Shar Nikolo.

206
00:07:43,199 --> 00:07:43,919
In other words,

207
00:07:43,919 --> 00:07:45,120
limp hashing is

208
00:07:45,120 --> 00:07:47,099
a platform-independent goal that focuses on properties within gradients

209
00:07:47,099 --> 00:07:48,660
and

210
00:07:48,660 --> 00:07:50,520


211
00:07:50,520 --> 00:07:52,620
can capture

212
00:07:52,620 --> 00:07:55,740
It is possible, but it is possible to express the dependent function in the first place,

213
00:07:55,740 --> 00:07:57,060


214
00:07:57,060 --> 00:07:58,740


215
00:07:58,740 --> 00:07:59,699


216
00:07:59,699 --> 00:08:01,500
but when using a hash function such as Schernico Road, if the input differs even by a single bit,

217
00:08:01,500 --> 00:08:05,160
the value at 8 o'clock will differ greatly.

218
00:08:05,160 --> 00:08:09,259


219
00:08:12,180 --> 00:08:14,580
The [ __ ] fuzzy proposed here replaces the

220
00:08:14,580 --> 00:08:16,380
[ __ ] hash with a fuzzy hash

221
00:08:16,380 --> 00:08:18,599
.

222
00:08:18,599 --> 00:08:20,699
Algorithms that perform demi-human transmission start to produce

223
00:08:20,699 --> 00:08:23,400
almost the same output for similar inputs.

224
00:08:23,400 --> 00:08:24,599


225
00:08:24,599 --> 00:08:27,539
It

226
00:08:27,539 --> 00:08:30,840
is possible to measure the degree of similarity of fatigue In

227
00:08:30,840 --> 00:08:34,080
the example of this figure,

228
00:08:34,080 --> 00:08:36,659
when the function name and package name are restored from the pclu tab of two samples,

229
00:08:36,659 --> 00:08:38,940
almost the same function name is restored and a

230
00:08:38,940 --> 00:08:40,979
similar fuzzy hash is calculated

231
00:08:40,979 --> 00:08:42,779
.

232
00:08:42,779 --> 00:08:44,039
In the case of deep fuzzy,

233
00:08:44,039 --> 00:08:46,380
fuzzy hashes are similar to

234
00:08:46,380 --> 00:08:48,000
each

235
00:08:48,000 --> 00:08:49,019
other. On the other hand

236
00:08:49,019 --> 00:08:50,160


237
00:08:50,160 --> 00:08:51,839
, in the case of GIMP8, which was explained earlier,

238
00:08:51,839 --> 00:08:55,080
sharny earl orism calculates completely different legs due to its nature

239
00:08:55,080 --> 00:08:57,720


240
00:08:57,720 --> 00:08:58,680


241
00:08:58,680 --> 00:09:02,060
.

242
00:09:03,600 --> 00:09:06,240
In order to compare the damping of [ __ ] onset and [ __ ] fuzzy in samples,

243
00:09:06,240 --> 00:09:08,640


244
00:09:08,640 --> 00:09:11,640


245
00:09:11,640 --> 00:09:15,380
we used the classification list of 50 wears that Palo Alto Networks has

246
00:09:15,540 --> 00:09:16,500


247
00:09:16,500 --> 00:09:18,899
collapsed

248
00:09:18,899 --> 00:09:21,480
.  Classification of 50 air ranges is performed using ``Yara'', and the

249
00:09:21,480 --> 00:09:23,640


250
00:09:23,640 --> 00:09:26,700
family names indicated by the mountain classification results and a

251
00:09:26,700 --> 00:09:30,260
list of specimens ``Char Nigoro'' are shown.

252
00:09:30,540 --> 00:09:33,000
Based on this list,

253
00:09:33,000 --> 00:09:36,839
about 7,900 specimens from 53 families were collected.  Using the list classification

254
00:09:36,839 --> 00:09:38,580
results as the correct answer,

255
00:09:38,580 --> 00:09:40,380


256
00:09:40,380 --> 00:09:42,720


257
00:09:42,720 --> 00:09:46,220
we evaluated the discriminant system

258
00:09:48,120 --> 00:09:51,000
to determine whether

259
00:09:51,000 --> 00:09:52,920
samples in the same family can be classified as the same family.

260
00:09:52,920 --> 00:09:56,040
In

261
00:09:56,040 --> 00:09:57,240


262
00:09:57,240 --> 00:09:59,279


263
00:09:59,279 --> 00:10:00,839


264
00:10:00,839 --> 00:10:03,360


265
00:10:03,360 --> 00:10:05,040


266
00:10:05,040 --> 00:10:06,779


267
00:10:06,779 --> 00:10:09,240
the example shown in the figure, a family of 6 specimens consists

268
00:10:09,240 --> 00:10:11,279
of 2 specimens,

269
00:10:11,279 --> 00:10:12,240
AB and 2 specimens AB.

270
00:10:12,240 --> 00:10:15,000
This shows an example where two classes consisting of ES can be created. In the case of

271
00:10:15,000 --> 00:10:17,180


272
00:10:17,399 --> 00:10:20,100
silver

273
00:10:20,100 --> 00:10:22,680
waves

274
00:10:22,680 --> 00:10:25,380
, the score is either 0 or 100 because it is possible to evaluate whether or not the bridge calculated by grounding can be completely crossed.

275
00:10:25,380 --> 00:10:28,140


276
00:10:28,140 --> 00:10:30,540
These two  Considering the combinations

277
00:10:30,540 --> 00:10:34,019
, the combination probability is calculated according to this formula, and the

278
00:10:34,019 --> 00:10:34,980
discrimination rate

279
00:10:34,980 --> 00:10:37,560
is calculated as

280
00:10:37,560 --> 00:10:40,140


281
00:10:40,140 --> 00:10:40,860


282
00:10:40,860 --> 00:10:44,240
0.133.

283
00:10:45,600 --> 00:10:49,140


284
00:10:49,140 --> 00:10:51,839
An example of actual [ __ ] onset calculation is shown

285
00:10:51,839 --> 00:10:53,700


286
00:10:53,700 --> 00:10:56,760
. The example in the figure shows an example in which 45 specimens from one family

287
00:10:56,760 --> 00:11:00,079


288
00:11:00,079 --> 00:11:03,000


289
00:11:03,000 --> 00:11:05,040
were divided into cluster groups with 21, 14, and 1 identical silver wave fashions by Giphash

290
00:11:05,040 --> 00:11:06,839
.

291
00:11:06,839 --> 00:11:09,480


292
00:11:09,480 --> 00:11:10,560
When considering the discrimination rate from the combination of two specimens,

293
00:11:10,560 --> 00:11:12,959
the total number of trile combinations is the denominator of the specimens.

294
00:11:12,959 --> 00:11:16,560


295
00:11:16,560 --> 00:11:18,839


296
00:11:18,839 --> 00:11:20,880


297
00:11:20,880 --> 00:11:21,779


298
00:11:21,779 --> 00:11:23,880


299
00:11:23,880 --> 00:11:28,260
2 is 21C plus 14C2, which is 301.

300
00:11:28,260 --> 00:11:30,560


301
00:11:35,880 --> 00:11:36,480
Next, I

302
00:11:36,480 --> 00:11:38,940
will show an example of the calculation of the discrimination rate of deep fuzzy

303
00:11:38,940 --> 00:11:40,440
.

304
00:11:40,440 --> 00:11:41,760


305
00:11:41,760 --> 00:11:43,560


306
00:11:43,560 --> 00:11:46,140


307
00:11:46,140 --> 00:11:49,140
Based on the

308
00:11:49,140 --> 00:11:51,779
similarity score,

309
00:11:51,779 --> 00:11:53,779


310
00:11:54,060 --> 00:11:55,800
the similarity of the silver wave edge is

311
00:11:55,800 --> 00:11:59,399
calculated from 0 to 100 based on the edit distance. The

312
00:11:59,399 --> 00:12:02,760
higher the number, the higher the uniformity.

313
00:12:02,760 --> 00:12:05,040
In

314
00:12:05,040 --> 00:12:06,600


315
00:12:06,600 --> 00:12:09,240
the example of this figure,

316
00:12:09,240 --> 00:12:13,140
the similar color score of the two Gib fuzzy is 77. The result

317
00:12:13,140 --> 00:12:15,420
of calculating the deep fuzzy for the sample above

318
00:12:15,420 --> 00:12:18,000
here is the letter starting with 1536 here

319
00:12:18,000 --> 00:12:21,120
It's a column,

320
00:12:21,120 --> 00:12:24,300
and the result of calculating the gold for this other specimen is this

321
00:12:24,300 --> 00:12:27,300
character string, and when the similarity between these two character strings

322
00:12:27,300 --> 00:12:30,180
is calculated, the score is 77.

323
00:12:30,180 --> 00:12:32,899


324
00:12:33,360 --> 00:12:35,579
Similar score  If

325
00:12:35,579 --> 00:12:38,160
two samples are taken from the same family, we aim for

326
00:12:38,160 --> 00:12:39,120


327
00:12:39,120 --> 00:12:41,820
the discrimination rate by considering the probability that the similarity is higher than the site

328
00:12:41,820 --> 00:12:44,660
.

329
00:12:48,300 --> 00:12:50,579


330
00:12:50,579 --> 00:12:52,800


331
00:12:52,800 --> 00:12:54,839


332
00:12:54,839 --> 00:12:56,459
For example, the example in the figure shows a

333
00:12:56,459 --> 00:12:58,440
family of 6 specimens

334
00:12:58,440 --> 00:13:00,300
with 4 clusters, 4 specimens

335
00:13:00,300 --> 00:13:03,720
ABCD and

336
00:13:03,720 --> 00:13:04,800


337
00:13:04,800 --> 00:13:06,660
2 clusters each of 2 specimens ES

338
00:13:06,660 --> 00:13:09,540
.

339
00:13:09,540 --> 00:13:12,540


340
00:13:12,540 --> 00:13:14,760
A combination of four specimens  The probability of being above the site

341
00:13:14,760 --> 00:13:18,360
is calculated according to this formula.The denominator is

342
00:13:18,360 --> 00:13:21,720
6C, a combination of 6, and the numerator is 4,

343
00:13:21,720 --> 00:13:24,060
a combination of four

344
00:13:24,060 --> 00:13:27,300
.

345
00:13:27,300 --> 00:13:31,639
It is calculated as 0.466 Now

346
00:13:35,459 --> 00:13:36,660


347
00:13:36,660 --> 00:13:39,480


348
00:13:39,480 --> 00:13:41,339


349
00:13:41,339 --> 00:13:44,519
, we will show the results of actually classifying specimens with Ginthaus and silver wave fuzzy and calculating the discriminant rate.

350
00:13:44,519 --> 00:13:47,040
This graph is

351
00:13:47,040 --> 00:13:48,899


352
00:13:48,899 --> 00:13:50,880
for each family that has more specimens than the experimental specimen that produced silver wave deep fuzzy.  The

353
00:13:50,880 --> 00:13:54,420


354
00:13:54,420 --> 00:13:56,100
vertical axis indicates the classification rate, and the

355
00:13:56,100 --> 00:13:57,060
horizontal axis indicates

356
00:13:57,060 --> 00:13:59,220


357
00:13:59,220 --> 00:14:00,779


358
00:14:00,779 --> 00:14:02,820
the classification method by family.

359
00:14:02,820 --> 00:14:05,639


360
00:14:05,639 --> 00:14:08,839


361
00:14:09,899 --> 00:14:12,779
Looking at the graph, you can clearly see

362
00:14:12,779 --> 00:14:14,880


363
00:14:14,880 --> 00:14:15,660


364
00:14:15,660 --> 00:14:18,300
that the classification accuracy of deep

365
00:14:18,300 --> 00:14:20,479


366
00:14:21,120 --> 00:14:21,779


367
00:14:21,779 --> 00:14:23,040


368
00:14:23,040 --> 00:14:24,320


369
00:14:24,320 --> 00:14:26,940
fuzzy is higher than that of the bank-issued

370
00:14:26,940 --> 00:14:30,480
classification system shown in dark blue.  The table shows

371
00:14:30,480 --> 00:14:33,480
the precision when the threshold is set to 60 in deep fuzzy, which has the lowest site, and

372
00:14:33,480 --> 00:14:37,019
the precision of the colors in the right corner

373
00:14:37,019 --> 00:14:40,579
is high.

374
00:14:40,860 --> 00:14:42,959


375
00:14:42,959 --> 00:14:46,980
There is a

376
00:14:46,980 --> 00:14:50,220


377
00:14:50,220 --> 00:14:52,139


378
00:14:52,139 --> 00:14:55,019
family veil that can be

379
00:14:55,019 --> 00:14:57,480


380
00:14:57,480 --> 00:15:00,540
classified with fairly high accuracy by [ __ ] fuzzy, which will be introduced later

381
00:15:00,540 --> 00:15:02,540


382
00:15:06,300 --> 00:15:07,079


383
00:15:07,079 --> 00:15:08,940
in this article.  Compare the scores of

384
00:15:08,940 --> 00:15:12,360
all specimens belonging

385
00:15:12,360 --> 00:15:14,519
to the same family for the alpha-right specimen,

386
00:15:14,519 --> 00:15:17,040


387
00:15:17,040 --> 00:15:18,300


388
00:15:18,300 --> 00:15:20,639
and investigate the distribution of scores between specimens on

389
00:15:20,639 --> 00:15:21,899
the

390
00:15:21,899 --> 00:15:23,760
slide.  The figure is an image, but

391
00:15:23,760 --> 00:15:25,680
it shows that samples with the same color belong to the same family,

392
00:15:25,680 --> 00:15:27,180
and

393
00:15:27,180 --> 00:15:29,040
samples with different colors belong to different families. The graph on the right

394
00:15:29,040 --> 00:15:31,519


395
00:15:31,920 --> 00:15:34,139
shows the grammar of this score

396
00:15:34,139 --> 00:15:37,019
.

397
00:15:37,019 --> 00:15:39,180
indicates the score, and the

398
00:15:39,180 --> 00:15:42,120
vertical axis indicates the number of combinations of specimens distributed in that score

399
00:15:42,120 --> 00:15:45,139
.

400
00:15:45,139 --> 00:15:48,180
Looking at this graph, first of all

401
00:15:48,180 --> 00:15:50,519
, there are

402
00:15:50,519 --> 00:15:53,220
combinations of specimens with a score of 0 that have completely different hashes even within the same family.

403
00:15:53,220 --> 00:15:56,180
I understand, on the one

404
00:15:57,180 --> 00:15:58,380
hand,

405
00:15:58,380 --> 00:15:59,639
within the same family,

406
00:15:59,639 --> 00:16:00,839
I want to maintain

407
00:16:00,839 --> 00:16:02,519


408
00:16:02,519 --> 00:16:04,920


409
00:16:04,920 --> 00:16:07,040
You can also see that many combinations of samples are distributed over a score of 68 or

410
00:16:10,740 --> 00:16:11,940


411
00:16:11,940 --> 00:16:13,380


412
00:16:13,380 --> 00:16:15,660
higher.On the other hand, we will verify what kind of value the similarity of Kinfeng fuzzy

413
00:16:15,660 --> 00:16:17,760
takes in

414
00:16:17,760 --> 00:16:19,980
samples other than families.

415
00:16:19,980 --> 00:16:22,380


416
00:16:22,380 --> 00:16:25,079
Compare the scores with all specimens belonging to different families This figure is an image

417
00:16:25,079 --> 00:16:25,860


418
00:16:25,860 --> 00:16:27,660
, but it shows that specimens with different colors belong to different families.

419
00:16:27,660 --> 00:16:30,260


420
00:16:30,779 --> 00:16:32,579


421
00:16:32,579 --> 00:16:35,880
75% of the specimens outside the family run completely differently.

422
00:16:35,880 --> 00:16:38,940


423
00:16:38,940 --> 00:16:39,839


424
00:16:39,839 --> 00:16:41,579


425
00:16:41,579 --> 00:16:44,820
The grammar of this score is shown on the right side of this

426
00:16:44,820 --> 00:16:46,980
figure. The

427
00:16:46,980 --> 00:16:48,480


428
00:16:48,480 --> 00:16:49,620
horizontal axis is the score, and the

429
00:16:49,620 --> 00:16:52,079
vertical axis is the distribution of the score.

430
00:16:52,079 --> 00:16:54,600


431
00:16:54,600 --> 00:16:57,240
Also, due to the scale of the graph,

432
00:16:57,240 --> 00:17:00,660
the distribution of score = 0 to which 75% of the samples belong is omitted.From

433
00:17:00,660 --> 00:17:02,759


434
00:17:02,759 --> 00:17:04,319
this graph,

435
00:17:04,319 --> 00:17:06,839
many combinations of samples have scores less than 69

436
00:17:06,839 --> 00:17:09,859


437
00:17:13,199 --> 00:17:15,720
Clustering has various uses and concepts,

438
00:17:15,720 --> 00:17:18,299
and there are various methods such as which flow to create clusters of specimens

439
00:17:18,299 --> 00:17:18,959


440
00:17:18,959 --> 00:17:21,959
.

441
00:17:21,959 --> 00:17:23,339
For example

442
00:17:23,339 --> 00:17:25,079
, clustering malware with similar functions.

443
00:17:25,079 --> 00:17:26,400


444
00:17:26,400 --> 00:17:27,540


445
00:17:27,540 --> 00:17:30,780
Going further, we

446
00:17:30,780 --> 00:17:32,400


447
00:17:32,400 --> 00:17:36,059
can think of applications such as

448
00:17:36,059 --> 00:17:37,200


449
00:17:37,200 --> 00:17:39,299


450
00:17:39,299 --> 00:17:41,580


451
00:17:41,580 --> 00:17:43,559


452
00:17:43,559 --> 00:17:44,220


453
00:17:44,220 --> 00:17:46,020
classifying family version differences and subspecies.

454
00:17:46,020 --> 00:17:49,740
We will think about how to determine sites that will not be built.

455
00:17:49,740 --> 00:17:50,820
Here,

456
00:17:50,820 --> 00:17:53,400
out of the scores of all the sample combinations

457
00:17:53,400 --> 00:17:55,679
, those with a score higher than the site will be regarded as familia and

458
00:17:55,679 --> 00:17:58,620
evaluated. The site set by

459
00:17:58,620 --> 00:18:00,720
the blue dotted line in the graph on the right side of this picture

460
00:18:00,720 --> 00:18:04,500
Then

461
00:18:04,500 --> 00:18:05,460


462
00:18:05,460 --> 00:18:07,740
, the combination that is above the premises and is actually within the family The combination that is

463
00:18:07,740 --> 00:18:09,660


464
00:18:09,660 --> 00:18:11,520
actually a family town with the addition of the threshold

465
00:18:11,520 --> 00:18:14,520
is the correct answer.

466
00:18:14,520 --> 00:18:15,780


467
00:18:15,780 --> 00:18:17,640


468
00:18:17,640 --> 00:18:19,559


469
00:18:19,559 --> 00:18:20,340


470
00:18:20,340 --> 00:18:22,679


471
00:18:22,679 --> 00:18:23,640


472
00:18:23,640 --> 00:18:26,299


473
00:18:26,460 --> 00:18:30,299
Considering the world rate of this classification,

474
00:18:30,299 --> 00:18:31,380


475
00:18:31,380 --> 00:18:33,120
there are overwhelmingly more combinations outside the family than within Sammy,

476
00:18:33,120 --> 00:18:34,500
and a

477
00:18:34,500 --> 00:18:37,919
simple world student evaluation lacks accuracy,

478
00:18:37,919 --> 00:18:39,059
so it

479
00:18:39,059 --> 00:18:42,299
is incorrect.  As an indicator for equally evaluating

480
00:18:42,299 --> 00:18:45,918


481
00:18:47,580 --> 00:18:48,660


482
00:18:48,660 --> 00:18:51,600
the correct and correct answers within the small family shown earlier

483
00:18:51,600 --> 00:18:53,700
,

484
00:18:53,700 --> 00:18:58,460
Umezawa is calculated using the formula in this figure.

485
00:18:59,280 --> 00:19:01,020


486
00:19:01,020 --> 00:19:03,179
By calculating the F measure from the sample evaluation, we found that the

487
00:19:03,179 --> 00:19:06,360
speech setting of 68 was the most accurate.

488
00:19:06,360 --> 00:19:08,880


489
00:19:08,880 --> 00:19:12,120


490
00:19:12,120 --> 00:19:13,380


491
00:19:13,380 --> 00:19:15,780


492
00:19:15,780 --> 00:19:19,520


493
00:19:19,679 --> 00:19:22,500
Therefore,

494
00:19:22,500 --> 00:19:23,280


495
00:19:23,280 --> 00:19:24,539


496
00:19:24,539 --> 00:19:26,940


497
00:19:26,940 --> 00:19:29,940
it was concluded that the global value of about 68 is appropriate as a threshold for classifying the family in the data

498
00:19:29,940 --> 00:19:32,299
setting used

499
00:19:36,179 --> 00:19:38,460
in this layer.  From

500
00:19:38,460 --> 00:19:39,900


501
00:19:39,900 --> 00:19:42,240


502
00:19:42,240 --> 00:19:44,520


503
00:19:44,520 --> 00:19:46,580
here,

504
00:19:48,539 --> 00:19:51,120
we will introduce three cases as

505
00:19:51,120 --> 00:19:54,059
case studies of the results of classifying 50 people using deep fuzzy.

506
00:19:54,059 --> 00:19:55,980


507
00:19:55,980 --> 00:19:57,360


508
00:19:57,360 --> 00:19:59,340


509
00:19:59,340 --> 00:20:00,059


510
00:20:00,059 --> 00:20:02,460
can accurately classify samples that target different platforms. In

511
00:20:02,460 --> 00:20:06,120
this case, we use a P2P botnet malware sample called IP Storm that was discovered in May 2019.

512
00:20:06,120 --> 00:20:07,679


513
00:20:07,679 --> 00:20:09,900


514
00:20:09,900 --> 00:20:12,059


515
00:20:12,059 --> 00:20:13,559
Sample A in the figure is

516
00:20:13,559 --> 00:20:14,940
Linux environment

517
00:20:14,940 --> 00:20:15,660
B

518
00:20:15,660 --> 00:20:17,940
targets Mac environment For

519
00:20:17,940 --> 00:20:19,799
each sample,

520
00:20:19,799 --> 00:20:21,780
we calculated silver wave house and give fuzzy values ​​For

521
00:20:21,780 --> 00:20:23,880


522
00:20:23,880 --> 00:20:26,100


523
00:20:26,100 --> 00:20:28,320
samples that target multiple platforms from the same altitude

524
00:20:28,320 --> 00:20:30,600
In classification, the

525
00:20:30,600 --> 00:20:32,880
same hash is not generated, so

526
00:20:32,880 --> 00:20:35,340
correct classification is difficult.

527
00:20:35,340 --> 00:20:37,799
In contrast, in the case of classification using limp fuzzy,

528
00:20:37,799 --> 00:20:38,820


529
00:20:38,820 --> 00:20:41,880
the similarity of fatigue can be calculated.

530
00:20:41,880 --> 00:20:44,700


531
00:20:44,700 --> 00:20:46,679


532
00:20:46,679 --> 00:20:48,419
In

533
00:20:48,419 --> 00:20:51,299


534
00:20:51,299 --> 00:20:52,320
this way,

535
00:20:52,320 --> 00:20:53,760
deep fuzzy performs cross-

536
00:20:53,760 --> 00:20:55,860
platform sample classification accurately

537
00:20:55,860 --> 00:20:58,159


538
00:20:59,520 --> 00:21:01,980
To check the similarity between samples A and B,

539
00:21:01,980 --> 00:21:06,240
each main function  If

540
00:21:06,240 --> 00:21:08,039
you check the result of pretending to be happy in the main environment

541
00:21:08,039 --> 00:21:11,340
, both are almost the same code, and the behavior

542
00:21:11,340 --> 00:21:13,140
of calling the starter function of the Storm package

543
00:21:13,140 --> 00:21:15,120
matches.

544
00:21:15,120 --> 00:21:16,140


545
00:21:16,140 --> 00:21:18,600


546
00:21:18,600 --> 00:21:20,580
star  The main logic is implemented

547
00:21:20,580 --> 00:21:22,760
in the parameter function.

548
00:21:25,380 --> 00:21:26,220
And the same is true

549
00:21:26,220 --> 00:21:28,740
if we look at the entire function contained in the specimen

550
00:21:28,740 --> 00:21:30,780
. On the

551
00:21:30,780 --> 00:21:31,740
left side is the function that

552
00:21:31,740 --> 00:21:34,020
is extracted when calculating the lymph fuzzy

553
00:21:34,020 --> 00:21:35,640
.

554
00:21:35,640 --> 00:21:38,400
Extracted from specimens A and B.

555
00:21:38,400 --> 00:21:41,700
85% of the function names match

556
00:21:41,700 --> 00:21:44,039


557
00:21:44,039 --> 00:21:47,340
, which suggests that the similarity score obtained by deep fuzzy is a high value of 90.

558
00:21:47,340 --> 00:21:50,940
The right side shows the results of differential comparison of fatigue by democracy.

559
00:21:50,940 --> 00:21:53,039


560
00:21:53,039 --> 00:21:55,380
Many of the functions actually have a high degree of similarity As mentioned

561
00:21:55,380 --> 00:21:56,880


562
00:21:56,880 --> 00:21:57,900
above, the

563
00:21:57,900 --> 00:21:59,400
sample ab

564
00:21:59,400 --> 00:22:01,559


565
00:22:01,559 --> 00:22:03,480
has the same structure

566
00:22:03,480 --> 00:22:05,220
regardless

567
00:22:05,220 --> 00:22:08,220
of the target platform.

568
00:22:08,220 --> 00:22:09,299


569
00:22:09,299 --> 00:22:11,340
It is possible to classify specimens accurately regardless of the time

570
00:22:11,340 --> 00:22:13,399
.

571
00:22:16,620 --> 00:22:17,400
Next, in

572
00:22:17,400 --> 00:22:19,080
the second case study,

573
00:22:19,080 --> 00:22:21,000
the lymph fuzzy function is particularly effective

574
00:22:21,000 --> 00:22:24,500
.

575
00:22:24,539 --> 00:22:26,340


576
00:22:26,340 --> 00:22:28,860
There was a family called Vail, which had a high

577
00:22:28,860 --> 00:22:30,840


578
00:22:30,840 --> 00:22:34,260
stat, and this is a sample generated by the Valeruya authoring tool

579
00:22:34,260 --> 00:22:36,120
.

580
00:22:36,120 --> 00:22:37,860
Vail supports the creation of advanced malware,

581
00:22:37,860 --> 00:22:39,240


582
00:22:39,240 --> 00:22:40,799
supports metasploit payloads, is

583
00:22:40,799 --> 00:22:43,620
antivirus and evasive, and has

584
00:22:43,620 --> 00:22:46,080
many other features.  When

585
00:22:46,080 --> 00:22:48,000
the specimens of this family

586
00:22:48,000 --> 00:22:50,700
were classified according to the indices of each of the eight silver wave gimpagi

587
00:22:50,700 --> 00:22:52,020


588
00:22:52,020 --> 00:22:53,760
, the accuracy of deep fuzzy was extremely high

589
00:22:53,760 --> 00:22:55,500


590
00:22:55,500 --> 00:22:57,780


591
00:22:57,780 --> 00:23:00,620
.

592
00:23:02,940 --> 00:23:06,120


593
00:23:06,120 --> 00:23:06,780


594
00:23:06,780 --> 00:23:08,580
Elements for calculating [ __ ] fuzzy for two classified specimens are shown

595
00:23:08,580 --> 00:23:10,140


596
00:23:10,140 --> 00:23:13,080
Left and right show functions extracted from different specimens, which are

597
00:23:13,080 --> 00:23:16,140


598
00:23:16,140 --> 00:23:18,860
used as inputs for

599
00:23:18,960 --> 00:23:20,220


600
00:23:20,220 --> 00:23:22,380
fuzzy Hanshin.  Part of the function name of the package is

601
00:23:22,380 --> 00:23:25,260
obfuscated, and this obfuscated character

602
00:23:25,260 --> 00:23:27,480
string differs for each

603
00:23:27,480 --> 00:23:28,500


604
00:23:28,500 --> 00:23:29,880


605
00:23:29,880 --> 00:23:32,520
sample.

606
00:23:32,520 --> 00:23:35,039
The same paper

607
00:23:35,039 --> 00:23:38,580
cannot be generated, and the classification accuracy is greatly reduced.

608
00:23:38,580 --> 00:23:40,020


609
00:23:40,020 --> 00:23:42,840


610
00:23:42,840 --> 00:23:45,720


611
00:23:45,720 --> 00:23:46,320


612
00:23:46,320 --> 00:23:48,480


613
00:23:48,480 --> 00:23:49,440


614
00:23:49,440 --> 00:23:51,480
If this remaining function name

615
00:23:51,480 --> 00:23:52,980
is  By matching, the

616
00:23:52,980 --> 00:23:54,360
degree of similarity increases,

617
00:23:54,360 --> 00:23:56,100
making it possible to determine that they belong to the same valve or family

618
00:23:56,100 --> 00:23:58,380
. In

619
00:23:58,380 --> 00:23:59,460
this way,

620
00:23:59,460 --> 00:24:01,799


621
00:24:01,799 --> 00:24:02,520


622
00:24:02,520 --> 00:24:04,620
deep fuzzy is very effective for specimens whose function names are partly obfuscated.  It works,

623
00:24:04,620 --> 00:24:05,820
so when

624
00:24:05,820 --> 00:24:06,960


625
00:24:06,960 --> 00:24:09,419
fuzzy hashing works, it makes sense

626
00:24:09,419 --> 00:24:11,400
to use impfuzzy in particular

627
00:24:11,400 --> 00:24:13,400
. In our

628
00:24:15,720 --> 00:24:17,760
last case study,

629
00:24:17,760 --> 00:24:19,020


630
00:24:19,020 --> 00:24:21,360
we're going to look at clustering using deep fuzzy.

631
00:24:21,360 --> 00:24:23,159


632
00:24:23,159 --> 00:24:25,320
Here,

633
00:24:25,320 --> 00:24:27,480
we will consider the similarity of fatigue

634
00:24:27,480 --> 00:24:28,500


635
00:24:28,500 --> 00:24:31,140
using samples from the Marumi field called welms

636
00:24:31,140 --> 00:24:32,880


637
00:24:32,880 --> 00:24:34,919
.

638
00:24:34,919 --> 00:24:37,980
Wellness is

639
00:24:37,980 --> 00:24:39,480
a malware that was first observed by jpsert and rack in

640
00:24:39,480 --> 00:24:41,159
2018. In

641
00:24:41,159 --> 00:24:42,960
2020,

642
00:24:42,960 --> 00:24:45,900
apt29  has been confirmed to be used in attack campaigns targeting information on coronavirus vaccines

643
00:24:45,900 --> 00:24:47,520


644
00:24:47,520 --> 00:24:50,039
.

645
00:24:50,039 --> 00:24:51,179
This time, we classified

646
00:24:51,179 --> 00:24:53,880
the 15 forms of Welmes collected

647
00:24:53,880 --> 00:24:55,679
based on deep hash and

648
00:24:55,679 --> 00:24:57,120


649
00:24:57,120 --> 00:25:00,500
GIMPfau, and confirmed the similarity of fatigue.  In the

650
00:25:00,539 --> 00:25:02,400
classification by limp distribution, the

651
00:25:02,400 --> 00:25:03,780
calculated hashes were

652
00:25:03,780 --> 00:25:06,720
7 types, and we were able to classify the 15 samples into 7 types.

653
00:25:06,720 --> 00:25:08,460


654
00:25:08,460 --> 00:25:10,799


655
00:25:10,799 --> 00:25:14,280


656
00:25:14,280 --> 00:25:18,559


657
00:25:20,520 --> 00:25:23,580
This figure organizes 7 types of malware classified by deep transmission.

658
00:25:23,580 --> 00:25:26,520


659
00:25:26,520 --> 00:25:28,080
Of the 7 types of specimens

660
00:25:28,080 --> 00:25:30,000
, 4 types target Windows environments,

661
00:25:30,000 --> 00:25:30,960


662
00:25:30,960 --> 00:25:32,760
and 3 types target Linux environments.

663
00:25:32,760 --> 00:25:34,559


664
00:25:34,559 --> 00:25:37,799
In addition,

665
00:25:37,799 --> 00:25:40,679
the approximate time when the sample was observed for each representative sample is

666
00:25:40,679 --> 00:25:43,500
arranged in chronological order and

667
00:25:43,500 --> 00:25:45,900
assigned to 10 from A to G, starting with

668
00:25:45,900 --> 00:25:48,000


669
00:25:48,000 --> 00:25:49,559
the earliest time.  This is the result of

670
00:25:49,559 --> 00:25:51,240
clustering

671
00:25:51,240 --> 00:25:53,340


672
00:25:53,340 --> 00:25:55,699


673
00:25:58,200 --> 00:26:00,120
based on the classification by lymph fuzzy

674
00:26:00,120 --> 00:26:02,700
.

675
00:26:02,700 --> 00:26:05,340
The vertical axis of the graph represents the number of clusters, and

676
00:26:05,340 --> 00:26:07,980
all 15 samples are  It means the number of types that could be classified

677
00:26:07,980 --> 00:26:09,360
.

678
00:26:09,360 --> 00:26:10,679
If you look at this,

679
00:26:10,679 --> 00:26:12,960
15 samples were classified into 7 types by Lymph Hash,

680
00:26:12,960 --> 00:26:14,580
but

681
00:26:14,580 --> 00:26:16,200


682
00:26:16,200 --> 00:26:17,880
Lymph Fuzzy was able to classify them into even fewer classes.  You

683
00:26:17,880 --> 00:26:19,080
can also see

684
00:26:19,080 --> 00:26:20,159


685
00:26:20,159 --> 00:26:22,020
that by lowering the similarity of speech, the

686
00:26:22,020 --> 00:26:23,880
clusters will combine and the

687
00:26:23,880 --> 00:26:27,000
number of

688
00:26:27,000 --> 00:26:27,900


689
00:26:27,900 --> 00:26:30,480


690
00:26:30,480 --> 00:26:32,400


691
00:26:32,400 --> 00:26:34,620
clusters will decrease.  The number of clusters decreases accordingly,

692
00:26:34,620 --> 00:26:35,580
and by

693
00:26:35,580 --> 00:26:38,159
month 170, all samples are

694
00:26:38,159 --> 00:26:41,539
classified

695
00:26:43,500 --> 00:26:44,520


696
00:26:44,520 --> 00:26:46,260


697
00:26:46,260 --> 00:26:48,020
into one cluster.

698
00:26:48,020 --> 00:26:50,520


699
00:26:50,520 --> 00:26:53,039
Also,

700
00:26:53,039 --> 00:26:55,080
the numbers in the figure show the degree of similarity in deep fuzzy,

701
00:26:55,080 --> 00:26:56,159
and the

702
00:26:56,159 --> 00:26:58,140
higher you go, the lower the threshold, and the more

703
00:26:58,140 --> 00:27:01,640
clusters join together

704
00:27:01,679 --> 00:27:02,880


705
00:27:02,880 --> 00:27:05,820


706
00:27:05,820 --> 00:27:06,840
.  So, remembering that

707
00:27:06,840 --> 00:27:08,520
the alphabet of each specimen

708
00:27:08,520 --> 00:27:10,559
was assigned from the oldest one based on the time of

709
00:27:10,559 --> 00:27:12,299


710
00:27:12,299 --> 00:27:14,460


711
00:27:14,460 --> 00:27:17,580
observation, I think you can read that the specimens with the closest observation awareness will start binding

712
00:27:17,580 --> 00:27:20,720
first.For

713
00:27:21,299 --> 00:27:21,960
example, the

714
00:27:21,960 --> 00:27:24,600
ski value  When set to 80, they

715
00:27:24,600 --> 00:27:27,360
are classified into two clusters, one

716
00:27:27,360 --> 00:27:30,600
neatly bisected from A to B and the other from E to G.

717
00:27:30,600 --> 00:27:32,719


718
00:27:33,000 --> 00:27:33,840
Also

719
00:27:33,840 --> 00:27:35,880
, the first binding of each analyte

720
00:27:35,880 --> 00:27:38,820
is relative to A, CB, db, and G.

721
00:27:38,820 --> 00:27:41,880
In

722
00:27:41,880 --> 00:27:43,260


723
00:27:43,260 --> 00:27:45,480
this way, in this

724
00:27:45,480 --> 00:27:48,480
clustering

725
00:27:48,480 --> 00:27:51,299


726
00:27:51,299 --> 00:27:52,320


727
00:27:52,320 --> 00:27:54,059
by [ __ ] fuzzy, it was

728
00:27:54,059 --> 00:27:55,380
observed that the specimens that were closest in chronological order were

729
00:27:55,380 --> 00:27:56,640
bound first.  At first, the

730
00:27:56,640 --> 00:27:59,340
specimen binds to the same target environment, but as the

731
00:27:59,340 --> 00:28:01,860


732
00:28:01,860 --> 00:28:04,020
death penalty is lowered, the distinction

733
00:28:04,020 --> 00:28:07,260
gradually disappears

734
00:28:07,260 --> 00:28:09,960


735
00:28:09,960 --> 00:28:12,200
.

736
00:28:14,279 --> 00:28:15,179
Now, let's focus on the

737
00:28:15,179 --> 00:28:17,820
functions included in the main package of each sample.The

738
00:28:17,820 --> 00:28:20,159


739
00:28:20,159 --> 00:28:20,820
figure shows

740
00:28:20,820 --> 00:28:23,279


741
00:28:23,279 --> 00:28:25,620
the results of extracting the functions included in the four types of samples that target Windows environments.

742
00:28:25,620 --> 00:28:27,799


743
00:28:27,840 --> 00:28:31,020


744
00:28:31,020 --> 00:28:31,679


745
00:28:31,679 --> 00:28:32,220


746
00:28:32,220 --> 00:28:35,460
It can be read that the functions are increasing in the order of eg

747
00:28:35,460 --> 00:28:36,840
.

748
00:28:36,840 --> 00:28:37,679
Also, from the

749
00:28:37,679 --> 00:28:38,820
function names,

750
00:28:38,820 --> 00:28:40,919
it can be inferred that the attacker is adding sample functions

751
00:28:40,919 --> 00:28:43,620


752
00:28:43,620 --> 00:28:45,720


753
00:28:45,720 --> 00:28:46,919


754
00:28:46,919 --> 00:28:48,480
.  It can be classified into the Variware family

755
00:28:48,480 --> 00:28:50,220


756
00:28:50,220 --> 00:28:51,240
Furthermore,

757
00:28:51,240 --> 00:28:53,039
by changing the ski value, it is possible

758
00:28:53,039 --> 00:28:55,020
to focus on the function of the specimen and

759
00:28:55,020 --> 00:28:58,460
classify it

760
00:29:00,960 --> 00:29:03,600
in detail.In the case of specimens that target Linux environments,

761
00:29:03,600 --> 00:29:05,640


762
00:29:05,640 --> 00:29:08,820
functions increase in chronological order in the later specimens.

763
00:29:08,820 --> 00:29:09,779


764
00:29:09,779 --> 00:29:11,640
The name was basically the

765
00:29:11,640 --> 00:29:14,340
same as

766
00:29:14,340 --> 00:29:15,480


767
00:29:15,480 --> 00:29:17,880
the sample for Windows.However, only the sample for Linux has a function called GetIP.In

768
00:29:17,880 --> 00:29:19,980


769
00:29:19,980 --> 00:29:22,740
this way, there may be some differences in the function depending on the platform.Finally, in

770
00:29:22,740 --> 00:29:26,240


771
00:29:28,440 --> 00:29:29,340


772
00:29:29,340 --> 00:29:31,380
the calculation of deep fuzzy

773
00:29:31,380 --> 00:29:33,960
Check the functions used

774
00:29:33,960 --> 00:29:35,100
The pie chart in the figure is

775
00:29:35,100 --> 00:29:37,020


776
00:29:37,020 --> 00:29:39,779


777
00:29:39,779 --> 00:29:42,360


778
00:29:42,360 --> 00:29:44,779
the result of investigating how much the functions

779
00:29:44,880 --> 00:29:48,360
extracted from the 7 forms are in common with other samples when calculating deep fuzzy All 792 extracted functions  Of these,

780
00:29:48,360 --> 00:29:52,260
70% were common to all specimens.

781
00:29:52,260 --> 00:29:55,320
Therefore, by treating these functions

782
00:29:55,320 --> 00:29:57,000
as features of the wellness family of wares

783
00:29:57,000 --> 00:29:58,020


784
00:29:58,020 --> 00:30:00,120


785
00:30:00,120 --> 00:30:00,899


786
00:30:00,899 --> 00:30:02,880
,

787
00:30:02,880 --> 00:30:05,100
lymphfuzzy can accurately classify specimens that are different from the target platform or have altered functions.  So

788
00:30:05,100 --> 00:30:07,020


789
00:30:07,020 --> 00:30:08,520


790
00:30:08,520 --> 00:30:10,679
what are the rest of the functions

791
00:30:10,679 --> 00:30:12,480
?

792
00:30:12,480 --> 00:30:13,380
First,

793
00:30:13,380 --> 00:30:15,480


794
00:30:15,480 --> 00:30:17,700
there are functions that

795
00:30:17,700 --> 00:30:19,799
are common to the target platform.

796
00:30:19,799 --> 00:30:21,360


797
00:30:21,360 --> 00:30:23,340


798
00:30:23,340 --> 00:30:25,020


799
00:30:25,020 --> 00:30:26,580
These functions appear only in Linux-targeting samples.

800
00:30:26,580 --> 00:30:28,980
Like GetIP, there are a certain number of these functions,

801
00:30:28,980 --> 00:30:30,240
but they

802
00:30:30,240 --> 00:30:33,140
are small in proportion.

803
00:30:33,960 --> 00:30:34,679
Next, they

804
00:30:34,679 --> 00:30:36,960
are common depending on when the samples were confirmed

805
00:30:36,960 --> 00:30:38,820


806
00:30:38,820 --> 00:30:39,779
.

807
00:30:39,779 --> 00:30:42,020


808
00:30:42,020 --> 00:30:46,679
Divide the period when is observed into XYZ, then the

809
00:30:46,679 --> 00:30:49,620
function included only in the cell of the period X, the function included

810
00:30:49,620 --> 00:30:52,740
only in the sample of the period after y, the function included only in

811
00:30:52,740 --> 00:30:55,200
the sample of the period Z, etc.

812
00:30:55,200 --> 00:30:56,159


813
00:30:56,159 --> 00:30:58,500
This type of function name was confirmed in specimens from the period of 2009, and

814
00:30:58,500 --> 00:31:01,200
this accounted for nearly 20% of the former

815
00:31:01,200 --> 00:31:02,580


816
00:31:02,580 --> 00:31:03,779
. From this, it can be seen that

817
00:31:03,779 --> 00:31:05,940


818
00:31:05,940 --> 00:31:06,899


819
00:31:06,899 --> 00:31:09,779
the function of the specimen has a greater impact on classification than the platform targeted by the specimen.

820
00:31:09,779 --> 00:31:12,179


821
00:31:12,179 --> 00:31:14,880
This is

822
00:31:14,880 --> 00:31:18,299
in line with the results of the previous clustering, where samples are combined in time series

823
00:31:18,299 --> 00:31:21,679
.

824
00:31:22,679 --> 00:31:23,279


825
00:31:23,279 --> 00:31:25,080


826
00:31:25,080 --> 00:31:27,299


827
00:31:27,299 --> 00:31:29,360


828
00:31:32,580 --> 00:31:34,020


829
00:31:34,020 --> 00:31:35,880
In this section, we will introduce the issues in using the IMP fuzzy.In

830
00:31:35,880 --> 00:31:37,740


831
00:31:37,740 --> 00:31:38,520


832
00:31:38,520 --> 00:31:41,520
the verification using a large number of samples this time, it was confirmed that the

833
00:31:41,520 --> 00:31:43,799
bank fuzzy did not work well for some of the samples.

834
00:31:43,799 --> 00:31:46,620


835
00:31:46,620 --> 00:31:48,899


836
00:31:48,899 --> 00:31:50,959


837
00:31:52,980 --> 00:31:55,919
The first is a

838
00:31:55,919 --> 00:31:59,220
problem in the filtering process used when calculating

839
00:31:59,220 --> 00:32:01,919
deep fuzzy.In deep fuzzy, when calculating a value,

840
00:32:01,919 --> 00:32:04,440


841
00:32:04,440 --> 00:32:07,200
instead of using all the extracted function names as input, some functions

842
00:32:07,200 --> 00:32:08,700


843
00:32:08,700 --> 00:32:09,720
This is

844
00:32:09,720 --> 00:32:12,480


845
00:32:12,480 --> 00:32:15,120
to express the specificity of the specimen more by excluding general functions used in many specimens

846
00:32:15,120 --> 00:32:16,620
.

847
00:32:16,620 --> 00:32:19,559


848
00:32:19,559 --> 00:32:21,720


849
00:32:21,720 --> 00:32:25,039
The amount of information is reduced.

850
00:32:27,240 --> 00:32:28,559
This problem has been discussed

851
00:32:28,559 --> 00:32:30,720
in Ginpa Hanshi, which is the basis of the [ __ ] facsimile

852
00:32:30,720 --> 00:32:33,600
.

853
00:32:33,600 --> 00:32:34,679
Even in lymphoma, we

854
00:32:34,679 --> 00:32:37,860


855
00:32:37,860 --> 00:32:39,059


856
00:32:39,059 --> 00:32:41,399
tried which function should be filtered while verifying a large number of gradients.  Through repeated errors,

857
00:32:41,399 --> 00:32:43,919
we reached the current implementation.

858
00:32:43,919 --> 00:32:46,679
Which function should be filtered and which function

859
00:32:46,679 --> 00:32:48,539
should be used for terminal calculation is

860
00:32:48,539 --> 00:32:49,559


861
00:32:49,559 --> 00:32:52,380
a fundamental problem of limp hash deep fuzzy.

862
00:32:52,380 --> 00:32:55,559


863
00:32:55,559 --> 00:32:58,020
If such a technique becomes widespread, we

864
00:32:58,020 --> 00:32:59,760
will need to rethink the implementation of the filter. The

865
00:32:59,760 --> 00:33:01,879


866
00:33:04,980 --> 00:33:06,000
next challenge is

867
00:33:06,000 --> 00:33:08,880
when fuzzy hashing is not possible.

868
00:33:08,880 --> 00:33:10,559
Computation of fuzzy hash does not give favorable results

869
00:33:10,559 --> 00:33:12,600
when the size of the input is small.

870
00:33:12,600 --> 00:33:14,460


871
00:33:14,460 --> 00:33:17,640
1532 functions could

872
00:33:17,640 --> 00:33:20,760
be extracted from the sample, but the number of functions

873
00:33:20,760 --> 00:33:22,559
was

874
00:33:22,559 --> 00:33:24,779
reduced to 6 due to the filter processing

875
00:33:24,779 --> 00:33:26,220


876
00:33:26,220 --> 00:33:29,340


877
00:33:29,340 --> 00:33:31,740
.  In some cases, such problems

878
00:33:31,740 --> 00:33:33,919
occur, and the

879
00:33:34,320 --> 00:33:38,640
last is when the sample is sabotaged.

880
00:33:38,640 --> 00:33:40,919
Attackers

881
00:33:40,919 --> 00:33:42,740
have improved the detection rate of 50ware such as antivirus products, and

882
00:33:42,740 --> 00:33:45,299
further construction has started to use techniques of the day.

883
00:33:45,299 --> 00:33:47,159
If

884
00:33:47,159 --> 00:33:49,740
such analysis is obstructed, the

885
00:33:49,740 --> 00:33:53,220
function name may not be restored

886
00:33:53,220 --> 00:33:54,179
. In the example in the figure, the

887
00:33:54,179 --> 00:33:56,220
sample is supposed to be packed into upx,

888
00:33:56,220 --> 00:33:57,240
but in

889
00:33:57,240 --> 00:33:58,919
reality, the unpacking process fails In

890
00:33:58,919 --> 00:34:00,480


891
00:34:00,480 --> 00:34:03,000
such cases  Asking for deep fuzzing because the function name cannot be extracted

892
00:34:03,000 --> 00:34:03,960


893
00:34:03,960 --> 00:34:05,399


894
00:34:05,399 --> 00:34:07,399


895
00:34:09,359 --> 00:34:10,379
Also,

896
00:34:10,379 --> 00:34:12,839
if most of the function names consist of random strings,

897
00:34:12,839 --> 00:34:14,219


898
00:34:14,219 --> 00:34:16,260
classification by pregnant fuzzy does not work well.

899
00:34:16,260 --> 00:34:17,520


900
00:34:17,520 --> 00:34:18,480


901
00:34:18,480 --> 00:34:20,699


902
00:34:20,699 --> 00:34:21,780


903
00:34:21,780 --> 00:34:23,760
In this case,

904
00:34:23,760 --> 00:34:25,918
the similarity of the pregnant woman's fuzzy is greatly reduced,

905
00:34:25,918 --> 00:34:28,619
and the classification system is greatly

906
00:34:28,619 --> 00:34:31,159
reduced.

907
00:34:33,719 --> 00:34:36,659
This kind of analysis hindrance by obfuscating function names

908
00:34:36,659 --> 00:34:37,800


909
00:34:37,800 --> 00:34:40,260
can be easily realized by using an obfuscation tool

910
00:34:40,260 --> 00:34:41,879


911
00:34:41,879 --> 00:34:43,980
.  One of the famous obfuscation tools is

912
00:34:43,980 --> 00:34:46,739
Go-on

913
00:34:46,739 --> 00:34:48,119


914
00:34:48,119 --> 00:34:49,859


915
00:34:49,859 --> 00:34:52,440
Fastate, which has been widely used in actual attacks as a ransomware snake and a rat tool's chaotic backdoor Black

916
00:34:52,440 --> 00:34:53,280
Road

917
00:34:53,280 --> 00:34:55,980


918
00:34:55,980 --> 00:34:57,119
.

919
00:34:57,119 --> 00:34:59,220
In this case

920
00:34:59,220 --> 00:35:01,920
, the analyst does not know which function to analyze,

921
00:35:01,920 --> 00:35:02,880
and

922
00:35:02,880 --> 00:35:05,880
the analysis cost rises dramatically.

923
00:35:05,880 --> 00:35:08,040
By using such tools, the

924
00:35:08,040 --> 00:35:10,680
attacker can easily lower the analysis accuracy compared to deep fuzzing

925
00:35:10,680 --> 00:35:13,819
.

926
00:35:17,660 --> 00:35:19,200


927
00:35:19,200 --> 00:35:22,399
In

928
00:35:24,119 --> 00:35:25,200
this presentation, we proposed

929
00:35:25,200 --> 00:35:26,640


930
00:35:26,640 --> 00:35:28,800


931
00:35:28,800 --> 00:35:32,160
a new index called deep fuzzy to quickly classify malware written in GO, which has been rapidly increasing in recent years, without

932
00:35:32,160 --> 00:35:34,380


933
00:35:34,380 --> 00:35:35,400


934
00:35:35,400 --> 00:35:37,140
incurring analysis costs.

935
00:35:37,140 --> 00:35:39,180
It is possible to measure the degree of similarity of fatigue and

936
00:35:39,180 --> 00:35:42,300
classify students highly.

937
00:35:42,300 --> 00:35:44,460


938
00:35:44,460 --> 00:35:45,119


939
00:35:45,119 --> 00:35:48,060
We confirmed an accuracy improvement of more than 2.6 times that of existing methods in verification using date sets.In

940
00:35:48,060 --> 00:35:50,420


941
00:35:50,579 --> 00:35:52,260
the second half of this presentation,

942
00:35:52,260 --> 00:35:54,060
we use the proposed [ __ ] fuzzy.

943
00:35:54,060 --> 00:35:57,000


944
00:35:57,000 --> 00:35:58,220
By using [ __ ] Fazia, it is possible to determine that the

945
00:35:58,220 --> 00:36:00,420
malware belongs to the same family even if functions are added or the

946
00:36:00,420 --> 00:36:02,940
version is changed

947
00:36:02,940 --> 00:36:04,500


948
00:36:04,500 --> 00:36:06,660
.

949
00:36:06,660 --> 00:36:07,859


950
00:36:07,859 --> 00:36:09,960


951
00:36:09,960 --> 00:36:11,820
We can also classify specimens accurately.

952
00:36:11,820 --> 00:36:14,160
Finally, as a future task,

953
00:36:14,160 --> 00:36:16,020


954
00:36:16,020 --> 00:36:19,640
we also discussed the age of specimens where lymphophagy does not work well.

955
00:36:22,040 --> 00:36:26,839
This is the reference for this

956
00:36:28,800 --> 00:36:32,000
presentation.

