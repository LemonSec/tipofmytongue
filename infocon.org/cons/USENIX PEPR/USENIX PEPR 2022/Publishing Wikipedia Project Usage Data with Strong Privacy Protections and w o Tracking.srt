1
00:00:09,679 --> 00:00:12,240
hi everyone um it is really great to be

2
00:00:12,240 --> 00:00:14,240
here as damian said my name is hal

3
00:00:14,240 --> 00:00:16,160
treidman and i'm a privacy engineer at

4
00:00:16,160 --> 00:00:18,640
the wikimedia foundation today i will be

5
00:00:18,640 --> 00:00:20,240
delivering a talk about publishing

6
00:00:20,240 --> 00:00:22,560
wikipedia project usage data with strong

7
00:00:22,560 --> 00:00:25,359
privacy protections and without tracking

8
00:00:25,359 --> 00:00:27,279
so just a quick overview of what i'm

9
00:00:27,279 --> 00:00:29,439
going to be talking about today first

10
00:00:29,439 --> 00:00:31,039
i'm going to be giving some introduction

11
00:00:31,039 --> 00:00:33,200
in context uh then we'll be getting into

12
00:00:33,200 --> 00:00:34,719
the meat of the talk which is about our

13
00:00:34,719 --> 00:00:37,680
pilot project uh problem description uh

14
00:00:37,680 --> 00:00:39,680
some discussion of tensions between data

15
00:00:39,680 --> 00:00:42,079
minimization and differential privacy uh

16
00:00:42,079 --> 00:00:43,680
and then a proposed solution that we

17
00:00:43,680 --> 00:00:46,079
have uh which is anonymous client-side

18
00:00:46,079 --> 00:00:48,960
filtering um finally we'll be discussing

19
00:00:48,960 --> 00:00:51,039
some open questions i i really want this

20
00:00:51,039 --> 00:00:53,840
to be a discussion and i appreciate uh

21
00:00:53,840 --> 00:00:55,199
the questions that were asked last

22
00:00:55,199 --> 00:00:58,399
session i'm hoping to get some myself so

23
00:00:58,399 --> 00:01:00,719
let's start out here

24
00:01:00,719 --> 00:01:03,280
so the wikimedia foundation uh

25
00:01:03,280 --> 00:01:05,760
many of you probably have heard of us we

26
00:01:05,760 --> 00:01:07,439
are a non-profit

27
00:01:07,439 --> 00:01:10,000
and our most famous project that we host

28
00:01:10,000 --> 00:01:12,640
is wikipedia however we also host a

29
00:01:12,640 --> 00:01:14,880
whole bunch of other projects like the

30
00:01:14,880 --> 00:01:18,080
wikimedia commons mediawiki wikidata and

31
00:01:18,080 --> 00:01:20,400
we're a relatively large website uh the

32
00:01:20,400 --> 00:01:22,240
seventh most visited site in the world

33
00:01:22,240 --> 00:01:24,400
with around 22 billion page views per

34
00:01:24,400 --> 00:01:27,200
month now uh most people here will be

35
00:01:27,200 --> 00:01:29,680
familiar with english wikipedia but we

36
00:01:29,680 --> 00:01:32,159
actually have 803 active projects

37
00:01:32,159 --> 00:01:34,799
spanning 316 languages with visitors

38
00:01:34,799 --> 00:01:36,640
from every single country in the entire

39
00:01:36,640 --> 00:01:37,520
world

40
00:01:37,520 --> 00:01:38,400
um

41
00:01:38,400 --> 00:01:39,920
so that's a lot of data that we collect

42
00:01:39,920 --> 00:01:41,840
a lot of page view data a lot of editor

43
00:01:41,840 --> 00:01:42,799
data

44
00:01:42,799 --> 00:01:45,600
and that data is largely governed by a

45
00:01:45,600 --> 00:01:47,439
couple of different policies uh the

46
00:01:47,439 --> 00:01:48,720
first one i'm going to be talking about

47
00:01:48,720 --> 00:01:51,439
here is the open access policy

48
00:01:51,439 --> 00:01:53,600
and the open access policy

49
00:01:53,600 --> 00:01:56,640
uh basically states that our intention

50
00:01:56,640 --> 00:01:58,560
as an organization is to make as much

51
00:01:58,560 --> 00:02:01,200
data about what we're doing what users

52
00:02:01,200 --> 00:02:02,960
on our platforms are doing

53
00:02:02,960 --> 00:02:05,520
uh as publicly available as possible to

54
00:02:05,520 --> 00:02:08,399
researchers to editors to other users

55
00:02:08,399 --> 00:02:09,598
and that takes a couple of different

56
00:02:09,598 --> 00:02:11,920
forms the first one you may be familiar

57
00:02:11,920 --> 00:02:14,400
with this is a public

58
00:02:14,400 --> 00:02:15,760
edit history

59
00:02:15,760 --> 00:02:18,800
for the page on english wikipedia about

60
00:02:18,800 --> 00:02:20,560
differential privacy

61
00:02:20,560 --> 00:02:22,879
every single page on wikipedia has one

62
00:02:22,879 --> 00:02:25,520
of these revision histories um

63
00:02:25,520 --> 00:02:26,879
you can see

64
00:02:26,879 --> 00:02:28,879
all of the changes that have been made

65
00:02:28,879 --> 00:02:31,120
publicly there's discussions often times

66
00:02:31,120 --> 00:02:32,640
that are also happening about these

67
00:02:32,640 --> 00:02:34,080
changes as well

68
00:02:34,080 --> 00:02:35,360
we also publish other types of

69
00:02:35,360 --> 00:02:37,519
statistics though um we

70
00:02:37,519 --> 00:02:38,959
this is from a project that we have

71
00:02:38,959 --> 00:02:41,280
called wiki stats so we publish page

72
00:02:41,280 --> 00:02:44,480
views by country and by uh project which

73
00:02:44,480 --> 00:02:46,480
is roughly corresponding to language

74
00:02:46,480 --> 00:02:47,760
usually

75
00:02:47,760 --> 00:02:48,800
edits

76
00:02:48,800 --> 00:02:50,480
registered users

77
00:02:50,480 --> 00:02:53,519
and some stuff about content as well

78
00:02:53,519 --> 00:02:55,280
we also have a lot of this data

79
00:02:55,280 --> 00:02:57,440
accessible uh programmatically through a

80
00:02:57,440 --> 00:03:00,080
rest api you can see here there's page

81
00:03:00,080 --> 00:03:02,800
view data unique device data editor data

82
00:03:02,800 --> 00:03:05,519
edits data a whole bunch of other things

83
00:03:05,519 --> 00:03:07,840
and broadly speaking in the past we've

84
00:03:07,840 --> 00:03:09,200
been using

85
00:03:09,200 --> 00:03:11,760
what jerome called i think some informal

86
00:03:11,760 --> 00:03:13,280
privacy methods

87
00:03:13,280 --> 00:03:15,680
so we use filtering i.e

88
00:03:15,680 --> 00:03:17,599
you know not releasing

89
00:03:17,599 --> 00:03:19,680
page view data for countries

90
00:03:19,680 --> 00:03:22,239
where they have a history of restricting

91
00:03:22,239 --> 00:03:24,720
press freedoms for example thresholding

92
00:03:24,720 --> 00:03:27,280
so saying you know arbitrarily

93
00:03:27,280 --> 00:03:29,760
maybe a page with less than a thousand

94
00:03:29,760 --> 00:03:30,799
viewers

95
00:03:30,799 --> 00:03:32,959
should not be released and bucketing

96
00:03:32,959 --> 00:03:35,440
which is just you know our informal term

97
00:03:35,440 --> 00:03:38,239
for k anonymity

98
00:03:38,239 --> 00:03:40,720
now on the other side of the coin uh

99
00:03:40,720 --> 00:03:44,560
contrary to the open data values that we

100
00:03:44,560 --> 00:03:46,720
have we have something called a lean

101
00:03:46,720 --> 00:03:48,720
data diet which i believe was presented

102
00:03:48,720 --> 00:03:50,000
about

103
00:03:50,000 --> 00:03:51,760
a couple years ago at pepper

104
00:03:51,760 --> 00:03:53,519
and this is defined largely by our

105
00:03:53,519 --> 00:03:55,519
privacy policy and data retention

106
00:03:55,519 --> 00:03:56,879
guidelines

107
00:03:56,879 --> 00:03:59,040
broadly speaking what it says is that

108
00:03:59,040 --> 00:04:01,120
you don't need an account to read or

109
00:04:01,120 --> 00:04:02,720
edit wikipedia

110
00:04:02,720 --> 00:04:05,120
you can do anonymous ip editing is what

111
00:04:05,120 --> 00:04:07,760
we call it there's no tracking cookies

112
00:04:07,760 --> 00:04:10,159
and and we'll get a lot more into this

113
00:04:10,159 --> 00:04:11,280
later but

114
00:04:11,280 --> 00:04:12,959
what we do is we get something called an

115
00:04:12,959 --> 00:04:15,599
actor signature by hashing the device ip

116
00:04:15,599 --> 00:04:18,160
address and the user agent

117
00:04:18,160 --> 00:04:20,320
which is an imperfect metric

118
00:04:20,320 --> 00:04:22,320
but we'll be talking a lot about that

119
00:04:22,320 --> 00:04:24,160
further on in this presentation and

120
00:04:24,160 --> 00:04:26,800
finally we don't save data forever

121
00:04:26,800 --> 00:04:28,560
almost all of the data that we have is

122
00:04:28,560 --> 00:04:30,800
aggregated and anonymized and deleted

123
00:04:30,800 --> 00:04:33,680
within 90 days of its collection

124
00:04:33,680 --> 00:04:36,479
so between the lean data diet and the

125
00:04:36,479 --> 00:04:38,560
open access guidelines that we have

126
00:04:38,560 --> 00:04:40,639
there's a tension between privacy and

127
00:04:40,639 --> 00:04:42,560
transparency

128
00:04:42,560 --> 00:04:44,400
and into this tension

129
00:04:44,400 --> 00:04:46,400
our thesis as an organization is that

130
00:04:46,400 --> 00:04:48,479
differential privacy could be a useful

131
00:04:48,479 --> 00:04:49,919
tool so

132
00:04:49,919 --> 00:04:53,120
broadly speaking we are using dp to try

133
00:04:53,120 --> 00:04:55,040
and ease this tension and get a more

134
00:04:55,040 --> 00:04:57,680
specific privacy guarantee so let's get

135
00:04:57,680 --> 00:04:58,639
into the

136
00:04:58,639 --> 00:05:02,160
specific pilot that we've been doing

137
00:05:02,160 --> 00:05:04,720
so a problem statement as i mentioned

138
00:05:04,720 --> 00:05:06,400
briefly before

139
00:05:06,400 --> 00:05:09,440
we release page views by country

140
00:05:09,440 --> 00:05:11,759
and we also release page views by

141
00:05:11,759 --> 00:05:13,759
language

142
00:05:13,759 --> 00:05:15,759
the question that we want to ask here is

143
00:05:15,759 --> 00:05:17,600
can we use differential privacy to

144
00:05:17,600 --> 00:05:20,320
release page view counts by both project

145
00:05:20,320 --> 00:05:22,240
and country

146
00:05:22,240 --> 00:05:24,080
and this is a pretty basic approach

147
00:05:24,080 --> 00:05:26,320
algorithmically speaking um for each

148
00:05:26,320 --> 00:05:28,560
user you define the sensitivity by

149
00:05:28,560 --> 00:05:30,160
defining the number of views per page

150
00:05:30,160 --> 00:05:31,520
and the number of pages that they can

151
00:05:31,520 --> 00:05:34,479
view uh you truncate the data set to go

152
00:05:34,479 --> 00:05:36,479
to that sensitivity and you just do a

153
00:05:36,479 --> 00:05:39,360
simple group by country project and page

154
00:05:39,360 --> 00:05:41,840
and sum all of the counts there

155
00:05:41,840 --> 00:05:43,440
in order to

156
00:05:43,440 --> 00:05:45,440
do this project we've been working with

157
00:05:45,440 --> 00:05:47,199
tumult labs

158
00:05:47,199 --> 00:05:48,000
they

159
00:05:48,000 --> 00:05:50,000
are a great organization you'll be

160
00:05:50,000 --> 00:05:52,720
hearing much more about their platform

161
00:05:52,720 --> 00:05:56,240
uh i think later on today

162
00:05:56,240 --> 00:05:57,360
and

163
00:05:57,360 --> 00:05:58,880
you know we've been sort of implementing

164
00:05:58,880 --> 00:06:01,039
betas trying to think about this problem

165
00:06:01,039 --> 00:06:04,319
and specifically get into some of the

166
00:06:04,319 --> 00:06:07,600
more difficult uh project specific

167
00:06:07,600 --> 00:06:09,280
issues

168
00:06:09,280 --> 00:06:10,080
so

169
00:06:10,080 --> 00:06:12,560
why is this a useful project problem to

170
00:06:12,560 --> 00:06:13,680
solve

171
00:06:13,680 --> 00:06:16,240
uh it's useful for editors and for

172
00:06:16,240 --> 00:06:18,000
researchers because we can disaggregate

173
00:06:18,000 --> 00:06:20,160
trends within languages that are spoken

174
00:06:20,160 --> 00:06:22,560
across many countries um some examples

175
00:06:22,560 --> 00:06:24,400
here are spanish english arabic

176
00:06:24,400 --> 00:06:26,560
vietnamese chinese and a whole bunch of

177
00:06:26,560 --> 00:06:28,479
other languages and just to sort of give

178
00:06:28,479 --> 00:06:30,560
you a sense of what this looks like

179
00:06:30,560 --> 00:06:33,120
right now we only publish statistics for

180
00:06:33,120 --> 00:06:34,720
english wikipedia

181
00:06:34,720 --> 00:06:36,720
as a whole right and most english

182
00:06:36,720 --> 00:06:38,639
wikipedia users are based in the united

183
00:06:38,639 --> 00:06:39,520
states

184
00:06:39,520 --> 00:06:41,520
because of that uh english wikipedia

185
00:06:41,520 --> 00:06:43,280
browsers in nigeria who might have

186
00:06:43,280 --> 00:06:45,120
completely different interests and and

187
00:06:45,120 --> 00:06:47,039
be searching and looking at completely

188
00:06:47,039 --> 00:06:48,880
separate things their page views are

189
00:06:48,880 --> 00:06:51,360
getting completely clobbered

190
00:06:51,360 --> 00:06:53,199
so if we can disaggregate these trends

191
00:06:53,199 --> 00:06:55,360
we might be able to give editors and

192
00:06:55,360 --> 00:06:58,240
viewers in specific countries a more

193
00:06:58,240 --> 00:07:01,599
uh precise view of what their

194
00:07:01,599 --> 00:07:03,759
constituency is looking at

195
00:07:03,759 --> 00:07:05,680
secondly from a technical perspective

196
00:07:05,680 --> 00:07:07,599
this is the largest and the most

197
00:07:07,599 --> 00:07:09,759
unwieldy data set that we have

198
00:07:09,759 --> 00:07:11,199
it's around one and a half or two

199
00:07:11,199 --> 00:07:13,039
terabytes a day and if we can

200
00:07:13,039 --> 00:07:15,199
successfully do it here we can pretty

201
00:07:15,199 --> 00:07:18,080
much do it anywhere within our stack

202
00:07:18,080 --> 00:07:19,919
now on the flip side

203
00:07:19,919 --> 00:07:21,919
why is this a difficult problem to solve

204
00:07:21,919 --> 00:07:24,800
there's a pretty high cost of failure

205
00:07:24,800 --> 00:07:28,240
in the past wikipedia has been censored

206
00:07:28,240 --> 00:07:29,520
there are a whole bunch of sensitive

207
00:07:29,520 --> 00:07:32,000
topics that might be criminalized if

208
00:07:32,000 --> 00:07:34,319
people were found to be looking at them

209
00:07:34,319 --> 00:07:36,720
and then also most importantly as we've

210
00:07:36,720 --> 00:07:39,280
seen during the russia ukraine war

211
00:07:39,280 --> 00:07:41,680
unmasking of editors can have serious

212
00:07:41,680 --> 00:07:44,080
legal or sometimes physical consequences

213
00:07:44,080 --> 00:07:46,080
so there's a really high cost of failure

214
00:07:46,080 --> 00:07:47,280
here

215
00:07:47,280 --> 00:07:49,120
in addition to that there are many

216
00:07:49,120 --> 00:07:51,520
country project combinations that

217
00:07:51,520 --> 00:07:53,120
identify really small user groups so

218
00:07:53,120 --> 00:07:55,919
imagine uh people browsing malaysian

219
00:07:55,919 --> 00:07:57,919
wikipedia in luxembourg right there

220
00:07:57,919 --> 00:07:59,840
might only be one or two people and if

221
00:07:59,840 --> 00:08:03,039
we release that data that crosstab

222
00:08:03,039 --> 00:08:04,720
we might end up just completely

223
00:08:04,720 --> 00:08:07,280
releasing the information that those one

224
00:08:07,280 --> 00:08:09,199
or two people are looking at

225
00:08:09,199 --> 00:08:10,000
now

226
00:08:10,000 --> 00:08:11,759
a third problem that we have is

227
00:08:11,759 --> 00:08:13,440
minimizing data collection which

228
00:08:13,440 --> 00:08:17,120
conflicts with differential privacy um

229
00:08:17,120 --> 00:08:19,840
so i think about these problems in a

230
00:08:19,840 --> 00:08:22,160
couple of different buckets

231
00:08:22,160 --> 00:08:24,960
the first two problems are what jerome

232
00:08:24,960 --> 00:08:26,400
was talking about in the previous

233
00:08:26,400 --> 00:08:28,479
presentation and they mean that we need

234
00:08:28,479 --> 00:08:31,280
to do differential privacy carefully

235
00:08:31,280 --> 00:08:32,880
the third problem on the other hand

236
00:08:32,880 --> 00:08:34,880
means that we need to do differentially

237
00:08:34,880 --> 00:08:37,200
private aggregations differently and for

238
00:08:37,200 --> 00:08:38,799
that reason we're going to be focusing

239
00:08:38,799 --> 00:08:40,719
the rest of the presentation on this

240
00:08:40,719 --> 00:08:42,719
third problem

241
00:08:42,719 --> 00:08:44,480
there's a fundamental tension here

242
00:08:44,480 --> 00:08:46,080
between data minimization and

243
00:08:46,080 --> 00:08:48,399
differential privacy because minimizing

244
00:08:48,399 --> 00:08:50,720
data collection impedes defining a

245
00:08:50,720 --> 00:08:53,200
strong meaningful and explainable notion

246
00:08:53,200 --> 00:08:55,920
of privacy protection for use in dp

247
00:08:55,920 --> 00:08:57,920
um

248
00:08:57,920 --> 00:09:00,480
the real heart of this issue uh is what

249
00:09:00,480 --> 00:09:02,240
i was alluding to before when i was

250
00:09:02,240 --> 00:09:03,760
talking about the actor signature you

251
00:09:03,760 --> 00:09:06,560
know what is a user in our system

252
00:09:06,560 --> 00:09:09,040
so just to be uh sort of pseudo code

253
00:09:09,040 --> 00:09:11,360
specific uh an actor's signature is just

254
00:09:11,360 --> 00:09:13,680
the md5 hash of

255
00:09:13,680 --> 00:09:16,399
an ip address and a user agent

256
00:09:16,399 --> 00:09:18,000
and you know this is a

257
00:09:18,000 --> 00:09:20,399
completely imperfect metric

258
00:09:20,399 --> 00:09:21,600
there are a couple of different failure

259
00:09:21,600 --> 00:09:24,480
cases here two to be specific the first

260
00:09:24,480 --> 00:09:26,800
failure case is that one user could have

261
00:09:26,800 --> 00:09:30,000
many signatures so let's say someone is

262
00:09:30,000 --> 00:09:31,760
browsing on mobile

263
00:09:31,760 --> 00:09:33,680
they switch cell towers and their ip

264
00:09:33,680 --> 00:09:34,800
address could change while they're

265
00:09:34,800 --> 00:09:36,720
browsing that would mean their signature

266
00:09:36,720 --> 00:09:38,160
changes as well

267
00:09:38,160 --> 00:09:40,480
in that case they would be registered in

268
00:09:40,480 --> 00:09:43,200
our system as multiple people

269
00:09:43,200 --> 00:09:45,120
on the other hand failure case two is

270
00:09:45,120 --> 00:09:47,519
that the converse of that many users get

271
00:09:47,519 --> 00:09:49,200
hashed to one signature

272
00:09:49,200 --> 00:09:51,040
so many users could have the same ip

273
00:09:51,040 --> 00:09:52,959
address and user agent so they would all

274
00:09:52,959 --> 00:09:54,480
hash to the same thing

275
00:09:54,480 --> 00:09:56,000
that would mean all of their page views

276
00:09:56,000 --> 00:09:57,920
are registered in our system as one

277
00:09:57,920 --> 00:09:59,680
person

278
00:09:59,680 --> 00:10:01,279
so just to do a little bit of further

279
00:10:01,279 --> 00:10:03,519
analysis on these failure cases failure

280
00:10:03,519 --> 00:10:05,680
case one sort of linearly degate

281
00:10:05,680 --> 00:10:07,519
degrades the privacy guarantees of

282
00:10:07,519 --> 00:10:09,600
differential privacy to the extent that

283
00:10:09,600 --> 00:10:11,279
someone might be switching ip addresses

284
00:10:11,279 --> 00:10:13,200
or switching browsers

285
00:10:13,200 --> 00:10:15,600
this is a really meaningful issue for

286
00:10:15,600 --> 00:10:17,360
areas where most browsing happens on

287
00:10:17,360 --> 00:10:18,399
mobile

288
00:10:18,399 --> 00:10:20,160
particularly areas in the global south

289
00:10:20,160 --> 00:10:23,760
like india indonesia mexico and others

290
00:10:23,760 --> 00:10:26,160
in failure case two data that could be

291
00:10:26,160 --> 00:10:28,160
included in the account is unnecessarily

292
00:10:28,160 --> 00:10:30,160
dropped and this is a meaningful issue

293
00:10:30,160 --> 00:10:32,480
for browsing within institutions

294
00:10:32,480 --> 00:10:33,600
where people might all have the same

295
00:10:33,600 --> 00:10:37,440
devices or potentially the same wi-fi

296
00:10:37,440 --> 00:10:40,079
networks as well

297
00:10:40,079 --> 00:10:40,880
so

298
00:10:40,880 --> 00:10:42,399
a question that you might be asking

299
00:10:42,399 --> 00:10:44,480
yourself is why not just implement first

300
00:10:44,480 --> 00:10:46,880
party tracking cookies right we you know

301
00:10:46,880 --> 00:10:47,760
have

302
00:10:47,760 --> 00:10:49,760
that would be a simple solution to

303
00:10:49,760 --> 00:10:51,760
solving this problem

304
00:10:51,760 --> 00:10:54,320
we actually do not want to know that

305
00:10:54,320 --> 00:10:56,560
data from multiple distinct devices

306
00:10:56,560 --> 00:10:58,880
browsers or networks comes from the same

307
00:10:58,880 --> 00:11:01,200
user because

308
00:11:01,200 --> 00:11:03,200
knowing that

309
00:11:03,200 --> 00:11:05,920
would be fundamentally in tension with a

310
00:11:05,920 --> 00:11:06,880
sorry

311
00:11:06,880 --> 00:11:08,079
the principle

312
00:11:08,079 --> 00:11:09,920
of knowing that

313
00:11:09,920 --> 00:11:11,440
of not knowing that rather is

314
00:11:11,440 --> 00:11:13,360
fundamentally in tension with a system

315
00:11:13,360 --> 00:11:15,040
that bounds contributions from each

316
00:11:15,040 --> 00:11:17,680
users across all devices browsers and

317
00:11:17,680 --> 00:11:18,640
networks

318
00:11:18,640 --> 00:11:20,240
which you know i'm alluding to

319
00:11:20,240 --> 00:11:22,399
differential privacy here

320
00:11:22,399 --> 00:11:24,880
now cross device user matching and

321
00:11:24,880 --> 00:11:26,640
device fingerprinting are very well

322
00:11:26,640 --> 00:11:28,720
researched areas and we are deliberately

323
00:11:28,720 --> 00:11:32,720
choosing not to implement that research

324
00:11:32,959 --> 00:11:35,600
data releases like all code encode our

325
00:11:35,600 --> 00:11:38,560
values and the stated values of our lean

326
00:11:38,560 --> 00:11:40,640
data diet conflict with a system that

327
00:11:40,640 --> 00:11:43,760
provides precise privacy guarantees

328
00:11:43,760 --> 00:11:45,440
for the wikimedia foundation

329
00:11:45,440 --> 00:11:47,440
unlinkability and minimization of data

330
00:11:47,440 --> 00:11:49,440
collection are actually more important

331
00:11:49,440 --> 00:11:51,839
than precise privacy guarantees

332
00:11:51,839 --> 00:11:53,680
at the same time we can just still do

333
00:11:53,680 --> 00:11:55,600
better than just the actor signature

334
00:11:55,600 --> 00:11:56,800
though

335
00:11:56,800 --> 00:11:57,839
so

336
00:11:57,839 --> 00:11:59,440
i'll be talking a little bit now about

337
00:11:59,440 --> 00:12:01,760
anonymous client-side filtering

338
00:12:01,760 --> 00:12:04,000
the goal of this is that we have a

339
00:12:04,000 --> 00:12:06,480
cookie attached to each web request that

340
00:12:06,480 --> 00:12:09,120
tells us whether or not a certain page

341
00:12:09,120 --> 00:12:10,720
should be included in the differentially

342
00:12:10,720 --> 00:12:13,360
private aggregations for that day up to

343
00:12:13,360 --> 00:12:16,079
some threshold k

344
00:12:16,079 --> 00:12:18,399
why is this better and how does this

345
00:12:18,399 --> 00:12:20,560
address our two failure cases

346
00:12:20,560 --> 00:12:22,399
for failure case one one user many

347
00:12:22,399 --> 00:12:25,040
signatures the stability is better than

348
00:12:25,040 --> 00:12:27,040
actor signature because cookies are

349
00:12:27,040 --> 00:12:28,720
cleared and the browser changes much

350
00:12:28,720 --> 00:12:30,639
less than the ip address changes

351
00:12:30,639 --> 00:12:33,200
especially on mobile

352
00:12:33,200 --> 00:12:35,440
for failure case 2 disaggregation is

353
00:12:35,440 --> 00:12:37,360
possible because distinct devices will

354
00:12:37,360 --> 00:12:40,079
all say to include their first k pages

355
00:12:40,079 --> 00:12:42,800
so if you have 10 people browsing and k

356
00:12:42,800 --> 00:12:45,440
also equals 10 you would have 100 pages

357
00:12:45,440 --> 00:12:48,399
that are included rather than just 10.

358
00:12:48,399 --> 00:12:50,560
this is a pseudocode implementation

359
00:12:50,560 --> 00:12:52,320
sketch that we have here about how this

360
00:12:52,320 --> 00:12:53,360
might work

361
00:12:53,360 --> 00:12:54,639
so we have a cookie which we're

362
00:12:54,639 --> 00:12:56,720
representing as an array

363
00:12:56,720 --> 00:12:58,880
assault which is a global random string

364
00:12:58,880 --> 00:13:00,320
that's stored on the server and

365
00:13:00,320 --> 00:13:02,240
regenerated daily

366
00:13:02,240 --> 00:13:04,959
and upon each page view what we do is we

367
00:13:04,959 --> 00:13:08,000
get a hash the first three characters of

368
00:13:08,000 --> 00:13:11,040
a url plus the salt

369
00:13:11,040 --> 00:13:12,480
and then for

370
00:13:12,480 --> 00:13:14,160
uh each

371
00:13:14,160 --> 00:13:15,360
existing

372
00:13:15,360 --> 00:13:18,399
hash code within the cookie we rehash

373
00:13:18,399 --> 00:13:20,959
that same code

374
00:13:20,959 --> 00:13:23,920
and if code is not in the cookie then we

375
00:13:23,920 --> 00:13:25,760
rehash everything else and append it to

376
00:13:25,760 --> 00:13:27,440
the end

377
00:13:27,440 --> 00:13:30,079
it's sort of a

378
00:13:30,079 --> 00:13:32,160
it's a nuanced thing

379
00:13:32,160 --> 00:13:34,639
but at the same time we are confident

380
00:13:34,639 --> 00:13:37,519
that it will both not provide a unique

381
00:13:37,519 --> 00:13:40,480
identifying string for a given user

382
00:13:40,480 --> 00:13:43,279
and also because it changes every uh

383
00:13:43,279 --> 00:13:45,920
page view uh provides a certain measure

384
00:13:45,920 --> 00:13:49,279
of security so some strengths

385
00:13:49,279 --> 00:13:51,519
daily rotated global salts

386
00:13:51,519 --> 00:13:54,240
mean that server access is not the same

387
00:13:54,240 --> 00:13:56,480
as decoding page views and because the

388
00:13:56,480 --> 00:13:58,959
salt expires at midnight utc there's no

389
00:13:58,959 --> 00:14:00,959
connections across stays

390
00:14:00,959 --> 00:14:02,560
as i mentioned before

391
00:14:02,560 --> 00:14:04,959
rehashing cookies upon each page view

392
00:14:04,959 --> 00:14:06,800
means that there's no connection across

393
00:14:06,800 --> 00:14:08,079
fuse

394
00:14:08,079 --> 00:14:10,000
and then the reason why we chose a three

395
00:14:10,000 --> 00:14:12,320
character hexadecimal fingerprint for

396
00:14:12,320 --> 00:14:15,519
each page view is that there are 4096

397
00:14:15,519 --> 00:14:17,680
combinations um

398
00:14:17,680 --> 00:14:20,560
we're provisionally going with 10 page

399
00:14:20,560 --> 00:14:23,600
views to be included in a single user's

400
00:14:23,600 --> 00:14:24,880
contributions

401
00:14:24,880 --> 00:14:27,360
um for 10 page views there's only a 1.1

402
00:14:27,360 --> 00:14:29,279
chance of collisions within a cookie in

403
00:14:29,279 --> 00:14:30,800
reality this is probably actually even

404
00:14:30,800 --> 00:14:33,600
lower because most people i think 95

405
00:14:33,600 --> 00:14:35,600
percent of people don't get to 10 page

406
00:14:35,600 --> 00:14:38,160
views on wikipedia within a day

407
00:14:38,160 --> 00:14:40,720
and for english wikipedia any hash code

408
00:14:40,720 --> 00:14:43,279
could refer to 1500 separate distinct

409
00:14:43,279 --> 00:14:46,480
pages um that means even if an attacker

410
00:14:46,480 --> 00:14:47,920
was able to

411
00:14:47,920 --> 00:14:51,279
decode or find a specific they had the

412
00:14:51,279 --> 00:14:53,360
global salt and they were able to find a

413
00:14:53,360 --> 00:14:56,560
specific url that hashed to the same

414
00:14:56,560 --> 00:14:58,880
thing that they found in a cookie there

415
00:14:58,880 --> 00:15:01,600
are 1500 separate pages that also hash

416
00:15:01,600 --> 00:15:04,320
to the same thing which is a a fair uh

417
00:15:04,320 --> 00:15:07,360
definition of privacy in our question or

418
00:15:07,360 --> 00:15:08,480
in our

419
00:15:08,480 --> 00:15:10,240
system here

420
00:15:10,240 --> 00:15:12,480
so some open questions uh

421
00:15:12,480 --> 00:15:15,440
i'm gonna break them up into two broad

422
00:15:15,440 --> 00:15:16,560
tranches

423
00:15:16,560 --> 00:15:19,120
uh the first set are with regard to the

424
00:15:19,120 --> 00:15:22,160
anonymous client side filtering um

425
00:15:22,160 --> 00:15:24,079
how do we communicate these concepts

426
00:15:24,079 --> 00:15:26,160
with a wide audience that is highly

427
00:15:26,160 --> 00:15:28,399
privacy conscious um

428
00:15:28,399 --> 00:15:30,320
does this system of anonymous

429
00:15:30,320 --> 00:15:32,399
client-side filtering provide a strong

430
00:15:32,399 --> 00:15:34,480
enough privacy guarantee

431
00:15:34,480 --> 00:15:36,399
and then finally this is just a problem

432
00:15:36,399 --> 00:15:37,680
that we've been running into this is a

433
00:15:37,680 --> 00:15:40,000
difficult system to test the efficiency

434
00:15:40,000 --> 00:15:42,240
of without actually compromising user

435
00:15:42,240 --> 00:15:45,279
privacy more broadly

436
00:15:45,279 --> 00:15:47,040
with regard to differential privacy

437
00:15:47,040 --> 00:15:48,480
generally

438
00:15:48,480 --> 00:15:50,560
how do we continuously monitor pipeline

439
00:15:50,560 --> 00:15:52,480
output metrics and address data drift

440
00:15:52,480 --> 00:15:53,759
that occurs

441
00:15:53,759 --> 00:15:55,360
and finally how do we educate

442
00:15:55,360 --> 00:15:57,519
stakeholders and specifically editors

443
00:15:57,519 --> 00:15:59,279
which are our most outspoken and

444
00:15:59,279 --> 00:16:01,759
important community

445
00:16:01,759 --> 00:16:03,680
some of whom could be ostracized

446
00:16:03,680 --> 00:16:05,519
penalized or prosecuted even because of

447
00:16:05,519 --> 00:16:07,839
what they read and write on wikipedia on

448
00:16:07,839 --> 00:16:10,160
the purpose scope and protections of dp

449
00:16:10,160 --> 00:16:11,680
and given this context how do we

450
00:16:11,680 --> 00:16:14,000
configure our algorithms uh set epsilon

451
00:16:14,000 --> 00:16:16,079
delta sensitivity and release threshold

452
00:16:16,079 --> 00:16:17,120
correctly

453
00:16:17,120 --> 00:16:18,240
um

454
00:16:18,240 --> 00:16:19,279
and how do we configure them

455
00:16:19,279 --> 00:16:21,440
appropriately and with a formed informed

456
00:16:21,440 --> 00:16:23,759
community input

457
00:16:23,759 --> 00:16:25,040
thank you so much

458
00:16:25,040 --> 00:16:26,800
i will be going over to the slack and

459
00:16:26,800 --> 00:16:31,399
hopefully taking some questions now

460
00:16:37,040 --> 00:16:39,120
you

