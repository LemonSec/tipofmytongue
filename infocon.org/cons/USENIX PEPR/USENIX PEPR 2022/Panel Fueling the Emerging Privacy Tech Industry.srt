1
00:00:10,800 --> 00:00:13,920
hi everyone i'm lourdes torrecha i'm

2
00:00:13,920 --> 00:00:16,480
really excited to be here at pepper to

3
00:00:16,480 --> 00:00:18,000
talk about some of the work that we've

4
00:00:18,000 --> 00:00:20,000
been doing particularly one piece of

5
00:00:20,000 --> 00:00:22,880
work that the working group that we had

6
00:00:22,880 --> 00:00:26,240
at tripped with nashan and and

7
00:00:26,240 --> 00:00:29,599
about 20 other cross-functional

8
00:00:29,599 --> 00:00:31,519
privacy folks not just from legal and

9
00:00:31,519 --> 00:00:33,360
engineering but also founders and

10
00:00:33,360 --> 00:00:35,280
startup operators who are building in

11
00:00:35,280 --> 00:00:36,399
this space

12
00:00:36,399 --> 00:00:39,120
created or worked on drafted and

13
00:00:39,120 --> 00:00:41,920
published last year to help define this

14
00:00:41,920 --> 00:00:43,120
space

15
00:00:43,120 --> 00:00:44,960
i do want to take the time to

16
00:00:44,960 --> 00:00:48,239
acknowledge that uh beyond pepper and

17
00:00:48,239 --> 00:00:50,640
privacy tech the topic of discussion i i

18
00:00:50,640 --> 00:00:52,000
want to take time to acknowledge what

19
00:00:52,000 --> 00:00:54,239
happened today which is the supreme

20
00:00:54,239 --> 00:00:57,120
court over turning roe versus wade and

21
00:00:57,120 --> 00:00:59,520
um i know that it's been rough for many

22
00:00:59,520 --> 00:01:02,480
of us and i've seen folks in the chat um

23
00:01:02,480 --> 00:01:05,040
expressing their sentiments and so i i

24
00:01:05,040 --> 00:01:06,479
hear you and

25
00:01:06,479 --> 00:01:08,640
this is not the end we will all fight

26
00:01:08,640 --> 00:01:11,119
and respond it doesn't mean that we will

27
00:01:11,119 --> 00:01:12,880
just take this there there will there is

28
00:01:12,880 --> 00:01:15,759
a lot of work to be done um but having

29
00:01:15,759 --> 00:01:18,080
said that thank you for listening to us

30
00:01:18,080 --> 00:01:20,159
and i'm excited to be here to present

31
00:01:20,159 --> 00:01:21,680
about some of the work that we're doing

32
00:01:21,680 --> 00:01:23,840
defining this space this emerging

33
00:01:23,840 --> 00:01:26,640
privacy tech industry to help fuel this

34
00:01:26,640 --> 00:01:30,000
space and to make it more actionable and

35
00:01:30,000 --> 00:01:31,920
talk about how privacy engineers can

36
00:01:31,920 --> 00:01:34,560
help do that in their work capacities

37
00:01:34,560 --> 00:01:36,400
personal capacities in their capacities

38
00:01:36,400 --> 00:01:39,119
as buyers as as maybe perhaps angel

39
00:01:39,119 --> 00:01:41,040
investors or board advisors or some of

40
00:01:41,040 --> 00:01:44,079
you that i know are are already doing

41
00:01:44,079 --> 00:01:47,040
and so with that um nishant i'd love to

42
00:01:47,040 --> 00:01:48,720
turn it to you for your own personal

43
00:01:48,720 --> 00:01:49,920
intro

44
00:01:49,920 --> 00:01:51,360
thank you ladies my name is nishan

45
00:01:51,360 --> 00:01:52,960
bajaria i'm the director of privacy

46
00:01:52,960 --> 00:01:55,040
engineering at uber i've had similar

47
00:01:55,040 --> 00:01:56,960
roles before as was mentioned before at

48
00:01:56,960 --> 00:01:59,840
netflix and nike and google i'm so happy

49
00:01:59,840 --> 00:02:00,960
to be here

50
00:02:00,960 --> 00:02:02,719
and i'm so grateful to be on the panel

51
00:02:02,719 --> 00:02:04,719
with laura simply because there was a

52
00:02:04,719 --> 00:02:06,399
need for a conversation that includes

53
00:02:06,399 --> 00:02:08,479
people who actually action orchestrate

54
00:02:08,479 --> 00:02:09,758
and lead privacy in the background and

55
00:02:09,758 --> 00:02:11,200
some of us have risen through the ranks

56
00:02:11,200 --> 00:02:13,120
over the last decade as privacy and

57
00:02:13,120 --> 00:02:15,120
security went from being esoteric nice

58
00:02:15,120 --> 00:02:16,800
to haves to being something that is

59
00:02:16,800 --> 00:02:18,239
critical for a company in terms of

60
00:02:18,239 --> 00:02:20,319
building trust into the platform

61
00:02:20,319 --> 00:02:22,400
my approach to privacy engineering tends

62
00:02:22,400 --> 00:02:24,640
to be focused on how do we a automated

63
00:02:24,640 --> 00:02:27,040
be scaled and c make it available to all

64
00:02:27,040 --> 00:02:29,120
customers in a way that is intuitive not

65
00:02:29,120 --> 00:02:30,879
just for external customers but internal

66
00:02:30,879 --> 00:02:32,239
engineering customers as well because at

67
00:02:32,239 --> 00:02:34,080
the end of the day unless you think

68
00:02:34,080 --> 00:02:36,000
about privacy as a product and a feature

69
00:02:36,000 --> 00:02:38,319
and a capability that benefits customers

70
00:02:38,319 --> 00:02:39,840
it's going to be a rough code to make it

71
00:02:39,840 --> 00:02:41,440
work at companies organizations and

72
00:02:41,440 --> 00:02:43,200
governments alike so whether it's the

73
00:02:43,200 --> 00:02:44,879
larger existential challenges of the day

74
00:02:44,879 --> 00:02:46,400
or whether it's something about

75
00:02:46,400 --> 00:02:48,640
monetization privacy is a critical part

76
00:02:48,640 --> 00:02:50,640
of the conversation so i'm super happy

77
00:02:50,640 --> 00:02:52,160
that lourdes has led this initiative i'm

78
00:02:52,160 --> 00:02:53,599
happy to be a part of it happy to be

79
00:02:53,599 --> 00:02:56,080
with you today

80
00:02:56,080 --> 00:02:57,760
and i couldn't agree more nashant thank

81
00:02:57,760 --> 00:03:01,440
you for helping us fuel this space um i

82
00:03:01,440 --> 00:03:04,400
think there's this big gap of trying to

83
00:03:04,400 --> 00:03:07,280
bridge the bridge the silos and break

84
00:03:07,280 --> 00:03:08,560
down the silos and bridge the gaps

85
00:03:08,560 --> 00:03:10,000
between

86
00:03:10,000 --> 00:03:12,080
privacy engineers like you

87
00:03:12,080 --> 00:03:14,080
privacy lawyers that you work with

88
00:03:14,080 --> 00:03:16,159
privacy founders most of whom aren't

89
00:03:16,159 --> 00:03:18,159
actually from the privacy domain and the

90
00:03:18,159 --> 00:03:20,800
investors writing checks to build tools

91
00:03:20,800 --> 00:03:23,760
um today and so i think it might be

92
00:03:23,760 --> 00:03:26,159
helpful to give spend just maybe like

93
00:03:26,159 --> 00:03:27,519
three minutes

94
00:03:27,519 --> 00:03:28,879
setting up

95
00:03:28,879 --> 00:03:31,120
what the heck we're talking about so the

96
00:03:31,120 --> 00:03:32,879
rights of privacy tech or trope as you

97
00:03:32,879 --> 00:03:35,840
like to say is an initiative to

98
00:03:35,840 --> 00:03:37,280
kind of bridge those gaps i was talking

99
00:03:37,280 --> 00:03:38,720
about earlier and one of the first

100
00:03:38,720 --> 00:03:41,519
things that we did was to define the

101
00:03:41,519 --> 00:03:43,360
space in a white paper that we published

102
00:03:43,360 --> 00:03:45,200
last year and i'm happy to put a link in

103
00:03:45,200 --> 00:03:47,680
the slack shortly later to do that and

104
00:03:47,680 --> 00:03:49,040
we did this

105
00:03:49,040 --> 00:03:50,720
for several reasons we talked to

106
00:03:50,720 --> 00:03:52,400
cross-functional buyers private

107
00:03:52,400 --> 00:03:55,280
developers privacy engineers grc people

108
00:03:55,280 --> 00:03:59,040
and obviously lawyers dpos about

109
00:03:59,040 --> 00:04:01,280
about the confusion that they're getting

110
00:04:01,280 --> 00:04:02,799
from the market right like there's so

111
00:04:02,799 --> 00:04:04,879
much noise in the emerging privacy tech

112
00:04:04,879 --> 00:04:06,799
market and

113
00:04:06,799 --> 00:04:08,959
people were just talking past each other

114
00:04:08,959 --> 00:04:10,959
so there were a lot of things that we

115
00:04:10,959 --> 00:04:13,760
wanted to cover in this white paper

116
00:04:13,760 --> 00:04:14,560
and

117
00:04:14,560 --> 00:04:17,358
um you know thanks to the expertise of

118
00:04:17,358 --> 00:04:19,680
folks like nishan pajaria who talked

119
00:04:19,680 --> 00:04:21,839
about more some of the more technical

120
00:04:21,839 --> 00:04:23,680
privacy pain points we were able to come

121
00:04:23,680 --> 00:04:27,040
up with something that was

122
00:04:27,040 --> 00:04:29,040
foundational but also actionable and

123
00:04:29,040 --> 00:04:31,280
we'll cover some of those um

124
00:04:31,280 --> 00:04:33,759
later so trump is a privacy tech

125
00:04:33,759 --> 00:04:36,320
industry hub so if you're you know if

126
00:04:36,320 --> 00:04:37,680
you want to be an angel investor if you

127
00:04:37,680 --> 00:04:39,120
want to be a founder if you want if

128
00:04:39,120 --> 00:04:41,360
you're a buyer or if you just want to

129
00:04:41,360 --> 00:04:44,000
build privacy tech tools um

130
00:04:44,000 --> 00:04:45,600
this is our way of bringing together

131
00:04:45,600 --> 00:04:49,120
cross-functional folks to fuel uh the

132
00:04:49,120 --> 00:04:51,680
industry and that's the white um

133
00:04:51,680 --> 00:04:53,759
white paper that we published last year

134
00:04:53,759 --> 00:04:56,320
we'll we'll share more of that um in

135
00:04:56,320 --> 00:04:57,840
this slack

136
00:04:57,840 --> 00:05:00,160
the why you know why we did it as i said

137
00:05:00,160 --> 00:05:02,400
it was to avoid vaporware in this space

138
00:05:02,400 --> 00:05:04,080
and make sure the space actually

139
00:05:04,080 --> 00:05:06,400
succeeds right before it even takes off

140
00:05:06,400 --> 00:05:08,880
um avoid privacy washing avoid talking

141
00:05:08,880 --> 00:05:10,639
past each other

142
00:05:10,639 --> 00:05:13,919
guide privacy tech industry players and

143
00:05:13,919 --> 00:05:16,160
just do a lot of awareness and

144
00:05:16,160 --> 00:05:18,000
understanding when it comes to key

145
00:05:18,000 --> 00:05:21,120
engineering concepts um and defining the

146
00:05:21,120 --> 00:05:22,479
stack so one of the things that we did

147
00:05:22,479 --> 00:05:25,600
in the white paper was to define privacy

148
00:05:25,600 --> 00:05:26,960
tech which

149
00:05:26,960 --> 00:05:28,720
we came up with two definitions so there

150
00:05:28,720 --> 00:05:30,400
are technical solutions to privacy

151
00:05:30,400 --> 00:05:32,560
problems and then the second one is the

152
00:05:32,560 --> 00:05:34,400
emerging industry of tech companies

153
00:05:34,400 --> 00:05:37,280
building solutions to privacy problems

154
00:05:37,280 --> 00:05:38,639
pretty standard there's nothing

155
00:05:38,639 --> 00:05:41,919
mind-blowing about those definitions uh

156
00:05:41,919 --> 00:05:44,639
and then we came up with a stack that

157
00:05:44,639 --> 00:05:47,199
said it's not it's it's

158
00:05:47,199 --> 00:05:49,280
a living document it's we're actually in

159
00:05:49,280 --> 00:05:52,400
the process of updating it in 2022 we

160
00:05:52,400 --> 00:05:54,400
just had a working group meeting today

161
00:05:54,400 --> 00:05:57,759
to do that but i want to share

162
00:05:57,759 --> 00:05:59,919
the things that we that we took into

163
00:05:59,919 --> 00:06:02,319
account when creating the privacy tech

164
00:06:02,319 --> 00:06:04,639
stack so we thought about the business

165
00:06:04,639 --> 00:06:06,560
model most of the startups that we saw

166
00:06:06,560 --> 00:06:09,120
are in the b2b space so but we also saw

167
00:06:09,120 --> 00:06:12,720
b2btc and btc uh products popping up

168
00:06:12,720 --> 00:06:14,479
right like and it makes sense that there

169
00:06:14,479 --> 00:06:16,000
are consumer privacy tech products

170
00:06:16,000 --> 00:06:17,919
because privacy is about people after

171
00:06:17,919 --> 00:06:19,360
all

172
00:06:19,360 --> 00:06:21,039
other things that we took into account

173
00:06:21,039 --> 00:06:23,680
are the data life cycle um and then with

174
00:06:23,680 --> 00:06:26,560
nishant's input we shifted it further to

175
00:06:26,560 --> 00:06:28,400
the left and even and talked about the

176
00:06:28,400 --> 00:06:30,560
development life cycle because some of

177
00:06:30,560 --> 00:06:32,479
the privacy problems that we're seeing

178
00:06:32,479 --> 00:06:35,680
um are actually happening even before we

179
00:06:35,680 --> 00:06:38,240
collect data when we start developing

180
00:06:38,240 --> 00:06:40,400
products and systems and

181
00:06:40,400 --> 00:06:43,280
and um other technologies and then we

182
00:06:43,280 --> 00:06:46,319
start you know in addition to that we we

183
00:06:46,319 --> 00:06:49,759
look at the adjacent industry um

184
00:06:49,759 --> 00:06:53,280
like cyber security uh data legal tech

185
00:06:53,280 --> 00:06:56,319
and so on and so uh

186
00:06:56,319 --> 00:06:58,080
this these are just some of the headers

187
00:06:58,080 --> 00:07:00,319
of this stack i'm not sure if this if

188
00:07:00,319 --> 00:07:04,080
the slides are showing that and

189
00:07:04,720 --> 00:07:07,919
b to b b to b to c b to c

190
00:07:07,919 --> 00:07:09,919
in the b to b side we have the data life

191
00:07:09,919 --> 00:07:10,960
cycle

192
00:07:10,960 --> 00:07:12,880
products and the development life cycle

193
00:07:12,880 --> 00:07:13,919
products

194
00:07:13,919 --> 00:07:15,759
and then in the data lifecycle products

195
00:07:15,759 --> 00:07:18,960
we have tools throughout the data life

196
00:07:18,960 --> 00:07:19,840
cycle

197
00:07:19,840 --> 00:07:22,400
right we have tools at collection like

198
00:07:22,400 --> 00:07:25,919
the consent management tools um we have

199
00:07:25,919 --> 00:07:27,039
pets

200
00:07:27,039 --> 00:07:29,919
under use and sharing um and then

201
00:07:29,919 --> 00:07:31,360
throughout it and then in the

202
00:07:31,360 --> 00:07:33,360
development life cycle really are some

203
00:07:33,360 --> 00:07:35,520
of the more exciting startups that we're

204
00:07:35,520 --> 00:07:38,319
seeing that are doing work shifting

205
00:07:38,319 --> 00:07:40,080
privacy left and you probably heard

206
00:07:40,080 --> 00:07:41,919
about some of them

207
00:07:41,919 --> 00:07:44,240
they're doing privacy code scanners

208
00:07:44,240 --> 00:07:46,319
they're doing training

209
00:07:46,319 --> 00:07:48,479
they're doing requirements

210
00:07:48,479 --> 00:07:49,599
for

211
00:07:49,599 --> 00:07:52,240
privacy requirements for developers and

212
00:07:52,240 --> 00:07:53,599
those are just some of the things but

213
00:07:53,599 --> 00:07:54,879
we're actually in the process of

214
00:07:54,879 --> 00:07:57,120
updating this so one of the calls to

215
00:07:57,120 --> 00:07:58,800
action that we have later is for those

216
00:07:58,800 --> 00:08:00,479
who would like to get involved in this

217
00:08:00,479 --> 00:08:02,720
year's working group you know let's chat

218
00:08:02,720 --> 00:08:05,120
and let's update let help us

219
00:08:05,120 --> 00:08:08,720
define this space um nisha i want to ask

220
00:08:08,720 --> 00:08:10,319
a question about the development

221
00:08:10,319 --> 00:08:12,080
lifecycle you were one of the first

222
00:08:12,080 --> 00:08:12,960
people

223
00:08:12,960 --> 00:08:14,479
that i

224
00:08:14,479 --> 00:08:16,319
uh approached when we were starting to

225
00:08:16,319 --> 00:08:18,160
define the development life cycle and if

226
00:08:18,160 --> 00:08:19,280
you remember

227
00:08:19,280 --> 00:08:22,160
about a year ago today we sat down to

228
00:08:22,160 --> 00:08:24,080
really think through the privacy

229
00:08:24,080 --> 00:08:25,919
problems during the development life

230
00:08:25,919 --> 00:08:27,680
cycle and what products there could look

231
00:08:27,680 --> 00:08:28,479
like

232
00:08:28,479 --> 00:08:31,680
and maybe to refresh your memory

233
00:08:31,680 --> 00:08:32,799
this

234
00:08:32,799 --> 00:08:36,000
was like what we came up with um

235
00:08:36,000 --> 00:08:38,479
right it's not very clear but

236
00:08:38,479 --> 00:08:42,399
i'm curious like what is

237
00:08:42,399 --> 00:08:45,120
how do you feel about the the state of

238
00:08:45,120 --> 00:08:46,880
privacy tech when it comes to developer

239
00:08:46,880 --> 00:08:49,360
tools today like there's a lot of things

240
00:08:49,360 --> 00:08:51,440
to be done to update this and to also

241
00:08:51,440 --> 00:08:54,640
mature it i'm curious are there any

242
00:08:54,640 --> 00:08:56,800
promising privacy tech solutions out

243
00:08:56,800 --> 00:08:58,880
there um what are some of your advice

244
00:08:58,880 --> 00:09:01,200
when it comes to the founders that are

245
00:09:01,200 --> 00:09:02,640
coming to you who are building in the

246
00:09:02,640 --> 00:09:04,399
space because the right side when it

247
00:09:04,399 --> 00:09:06,560
comes to compliance and stuff are kind

248
00:09:06,560 --> 00:09:10,080
of saturated to be honest um i'm curious

249
00:09:10,080 --> 00:09:12,000
like what are some of the

250
00:09:12,000 --> 00:09:13,920
learnings and the takeaways that you're

251
00:09:13,920 --> 00:09:16,080
seeing just as an advisor as a buyer as

252
00:09:16,080 --> 00:09:17,839
an advisor

253
00:09:17,839 --> 00:09:19,680
of these tools

254
00:09:19,680 --> 00:09:21,519
advisor to these startups as a buyer as

255
00:09:21,519 --> 00:09:22,480
a user

256
00:09:22,480 --> 00:09:23,440
yeah

257
00:09:23,440 --> 00:09:24,720
i'm going to hold on to something you

258
00:09:24,720 --> 00:09:26,080
said lord this is the very beginning of

259
00:09:26,080 --> 00:09:27,519
your question about how

260
00:09:27,519 --> 00:09:29,200
the privacy challenge and the privacy

261
00:09:29,200 --> 00:09:30,560
tooling begins even before the

262
00:09:30,560 --> 00:09:32,560
collection of the data right so let

263
00:09:32,560 --> 00:09:34,959
let's work backwards my expectations if

264
00:09:34,959 --> 00:09:36,959
you are a founder if you are a vc or if

265
00:09:36,959 --> 00:09:38,640
you are somebody who's like putting out

266
00:09:38,640 --> 00:09:40,880
a product out there for monetization and

267
00:09:40,880 --> 00:09:42,800
growth purposes you are looking at it

268
00:09:42,800 --> 00:09:44,160
through the lens of growth you're

269
00:09:44,160 --> 00:09:46,000
looking at the lens of quick engagement

270
00:09:46,000 --> 00:09:47,440
because unless you get that initial

271
00:09:47,440 --> 00:09:49,519
start unless you capture the moment of

272
00:09:49,519 --> 00:09:51,040
truth as they used to say back in my

273
00:09:51,040 --> 00:09:53,120
netflix days uh you you're pretty much

274
00:09:53,120 --> 00:09:54,399
dead in the water or so you think

275
00:09:54,399 --> 00:09:55,839
because that you never get a second

276
00:09:55,839 --> 00:09:57,120
chance to make their initial first

277
00:09:57,120 --> 00:09:58,880
impression right and at the same time

278
00:09:58,880 --> 00:10:00,399
the customers are no picnic either they

279
00:10:00,399 --> 00:10:01,680
want stuff to work pretty quickly like

280
00:10:01,680 --> 00:10:02,880
when i

281
00:10:02,880 --> 00:10:04,160
get done with my work day i want to open

282
00:10:04,160 --> 00:10:05,680
netflix and i'm going to start to watch

283
00:10:05,680 --> 00:10:07,600
something and what do i want i want the

284
00:10:07,600 --> 00:10:09,279
login to work quickly i want my

285
00:10:09,279 --> 00:10:10,800
recommendations to come up quickly and i

286
00:10:10,800 --> 00:10:11,920
want to make sure that something is

287
00:10:11,920 --> 00:10:13,760
playing in the background before i start

288
00:10:13,760 --> 00:10:16,000
cooking there so everybody has optimized

289
00:10:16,000 --> 00:10:17,839
for speed which means the backend

290
00:10:17,839 --> 00:10:19,360
infrastructure which means the data

291
00:10:19,360 --> 00:10:21,120
collection mechanism which means the

292
00:10:21,120 --> 00:10:23,200
apis which means the internal queries

293
00:10:23,200 --> 00:10:24,880
they are all optimized for rapid

294
00:10:24,880 --> 00:10:26,720
movement that is eventual consistency to

295
00:10:26,720 --> 00:10:28,560
make sure that it will all work out in

296
00:10:28,560 --> 00:10:30,480
the end but initially the goal is to

297
00:10:30,480 --> 00:10:32,640
grow our data and grow our functionality

298
00:10:32,640 --> 00:10:34,640
as quickly as possible so it is

299
00:10:34,640 --> 00:10:36,240
extremely important when people say

300
00:10:36,240 --> 00:10:38,320
shift like from a security perspective

301
00:10:38,320 --> 00:10:39,760
what they're talking about is sketch

302
00:10:39,760 --> 00:10:42,320
threats early as they are materializing

303
00:10:42,320 --> 00:10:44,880
on the privacy use cases shift left left

304
00:10:44,880 --> 00:10:46,560
as i like to call it you got to go one

305
00:10:46,560 --> 00:10:48,480
step before security simply because

306
00:10:48,480 --> 00:10:50,320
security tools are built with a very

307
00:10:50,320 --> 00:10:52,240
binary adversarial mindset and there is

308
00:10:52,240 --> 00:10:54,079
a at least in most cases an

309
00:10:54,079 --> 00:10:55,600
understanding of the kinds of threats

310
00:10:55,600 --> 00:10:57,120
you eliminate but from a privacy

311
00:10:57,120 --> 00:10:59,600
perspective how many gps points exist in

312
00:10:59,600 --> 00:11:01,760
your location data how direct is the

313
00:11:01,760 --> 00:11:03,920
time how recent is the data how much

314
00:11:03,920 --> 00:11:05,600
different pieces are how many different

315
00:11:05,600 --> 00:11:06,880
pieces of data do we have across

316
00:11:06,880 --> 00:11:09,440
different databases all of those put

317
00:11:09,440 --> 00:11:11,040
together with the right metadata and the

318
00:11:11,040 --> 00:11:13,040
right third party context creates a

319
00:11:13,040 --> 00:11:15,360
different re-identification risk versus

320
00:11:15,360 --> 00:11:16,800
having them all disconnected from each

321
00:11:16,800 --> 00:11:18,480
other so i kind of feel like you need a

322
00:11:18,480 --> 00:11:21,040
lot of this tooling training in place

323
00:11:21,040 --> 00:11:22,399
well before data collection happens

324
00:11:22,399 --> 00:11:24,480
because it will guide a what you collect

325
00:11:24,480 --> 00:11:26,880
be who can access it see how does how do

326
00:11:26,880 --> 00:11:29,279
you map policy across the organization

327
00:11:29,279 --> 00:11:30,959
to the data as it travels down the pipe

328
00:11:30,959 --> 00:11:33,519
right and the reason this is important

329
00:11:33,519 --> 00:11:35,920
lodes is that engineers will do things

330
00:11:35,920 --> 00:11:37,600
that are intuitive in nature because

331
00:11:37,600 --> 00:11:39,040
they want to get from a to b quickly

332
00:11:39,040 --> 00:11:40,480
once they know what to build and

333
00:11:40,480 --> 00:11:42,079
everything else that is extraneous to

334
00:11:42,079 --> 00:11:43,920
their thinking almost seems like it

335
00:11:43,920 --> 00:11:45,360
should happen automatically or somebody

336
00:11:45,360 --> 00:11:46,320
else should take care of it and i know

337
00:11:46,320 --> 00:11:47,920
this because most engineers have been

338
00:11:47,920 --> 00:11:49,760
incentivized this way you get promoted

339
00:11:49,760 --> 00:11:51,920
based on getting an idea from zero to

340
00:11:51,920 --> 00:11:53,600
one owning a big chunk of it and

341
00:11:53,600 --> 00:11:55,040
sometimes time is your enemy in that

342
00:11:55,040 --> 00:11:56,959
regard so having all these checks and

343
00:11:56,959 --> 00:11:58,959
controls in place right across the

344
00:11:58,959 --> 00:12:00,480
pipeline is pretty critical before

345
00:12:00,480 --> 00:12:02,240
during and after the collection so let

346
00:12:02,240 --> 00:12:04,399
me give you a specific example when it

347
00:12:04,399 --> 00:12:06,480
comes to training our key stakeholders

348
00:12:06,480 --> 00:12:08,880
in the company executives or people who

349
00:12:08,880 --> 00:12:10,880
are busy all the time with malware and

350
00:12:10,880 --> 00:12:12,399
fishing we the way we do that is by

351
00:12:12,399 --> 00:12:14,320
sending people spoof emails and

352
00:12:14,320 --> 00:12:15,680
sometimes when i've done this myself

353
00:12:15,680 --> 00:12:17,279
they click on it and they're told this

354
00:12:17,279 --> 00:12:19,360
was a phishing simulation right we do

355
00:12:19,360 --> 00:12:21,760
that randomly to create conversation to

356
00:12:21,760 --> 00:12:22,560
create

357
00:12:22,560 --> 00:12:24,000
you know bring people's attention to the

358
00:12:24,000 --> 00:12:26,000
fact that this risk exists now that's

359
00:12:26,000 --> 00:12:28,240
for human beings privacy harms often

360
00:12:28,240 --> 00:12:29,680
happen not because human beings

361
00:12:29,680 --> 00:12:31,600
typically behave badly although that is

362
00:12:31,600 --> 00:12:34,000
true in some cases but in a lot of cases

363
00:12:34,000 --> 00:12:35,760
there's a service i wrote that you

364
00:12:35,760 --> 00:12:37,760
repurposed with data that somebody else

365
00:12:37,760 --> 00:12:39,120
collected it's the combination i keep

366
00:12:39,120 --> 00:12:40,240
saying over and over again is the

367
00:12:40,240 --> 00:12:42,399
combination of circumstances that grows

368
00:12:42,399 --> 00:12:44,079
privacy risks so rather than having

369
00:12:44,079 --> 00:12:45,519
random checks you want these checks

370
00:12:45,519 --> 00:12:47,600
scattered all over the infrastructure

371
00:12:47,600 --> 00:12:49,680
all over the data lifecycle to increase

372
00:12:49,680 --> 00:12:51,519
a the risk of catching these issues

373
00:12:51,519 --> 00:12:53,600
before they happen be to create training

374
00:12:53,600 --> 00:12:55,920
opportunities and see to identify a

375
00:12:55,920 --> 00:12:57,760
pattern of exactly the kind of data the

376
00:12:57,760 --> 00:12:59,760
kind of teams the kind of usages that

377
00:12:59,760 --> 00:13:01,600
create this risk and then repurposing

378
00:13:01,600 --> 00:13:03,120
the infrastructure so essentially you

379
00:13:03,120 --> 00:13:05,120
are building artificial intelligence to

380
00:13:05,120 --> 00:13:06,959
understand what the privacy risk is and

381
00:13:06,959 --> 00:13:08,800
using that to build privacy tech across

382
00:13:08,800 --> 00:13:09,920
the pipeline i know that's kind of a

383
00:13:09,920 --> 00:13:11,920
long answer but you have to think about

384
00:13:11,920 --> 00:13:13,360
this pretty early in the process and i

385
00:13:13,360 --> 00:13:15,440
especially aim this at founders because

386
00:13:15,440 --> 00:13:17,200
you have it far easier than the googles

387
00:13:17,200 --> 00:13:18,399
and the facebooks and the matters of the

388
00:13:18,399 --> 00:13:20,240
world because they have years and years

389
00:13:20,240 --> 00:13:22,480
of habits heck debt built up you have a

390
00:13:22,480 --> 00:13:24,160
chance to do this right because you

391
00:13:24,160 --> 00:13:25,760
don't have that kind of debt well guess

392
00:13:25,760 --> 00:13:26,880
what else you don't have you don't have

393
00:13:26,880 --> 00:13:28,160
that kind of cash on the talent they

394
00:13:28,160 --> 00:13:30,160
have at their disposal so doing this

395
00:13:30,160 --> 00:13:32,079
right is not just the right thing to do

396
00:13:32,079 --> 00:13:33,760
the future you will thank the present

397
00:13:33,760 --> 00:13:35,200
you if you do it right so very beginning

398
00:13:35,200 --> 00:13:36,560
right now

399
00:13:36,560 --> 00:13:38,639
that's i mean all great points and this

400
00:13:38,639 --> 00:13:41,120
is exactly why we want people like you

401
00:13:41,120 --> 00:13:43,600
and we approach uh people like you as

402
00:13:43,600 --> 00:13:45,760
who are domain experts but also buyers

403
00:13:45,760 --> 00:13:48,639
and users of these tools to get involved

404
00:13:48,639 --> 00:13:51,120
and get that feedback back to the

405
00:13:51,120 --> 00:13:52,720
founders right like those are very

406
00:13:52,720 --> 00:13:55,839
helpful um insights to give them and i

407
00:13:55,839 --> 00:13:58,000
want to quote one of the one of the

408
00:13:58,000 --> 00:14:00,160
first cpos in the world actually who who

409
00:14:00,160 --> 00:14:01,760
isn't a lawyer

410
00:14:01,760 --> 00:14:03,839
they're one of the technical cpos the

411
00:14:03,839 --> 00:14:06,000
first technical cpos and one of the

412
00:14:06,000 --> 00:14:08,240
comments that they made in a meeting

413
00:14:08,240 --> 00:14:10,560
that we had earlier this week was you

414
00:14:10,560 --> 00:14:13,279
know stop building us tools that you

415
00:14:13,279 --> 00:14:15,040
think we need like

416
00:14:15,040 --> 00:14:17,279
actually listen to us and

417
00:14:17,279 --> 00:14:18,880
and build us like what we need like

418
00:14:18,880 --> 00:14:21,040
instead of selling us things that you

419
00:14:21,040 --> 00:14:23,519
think we need so there there is that i

420
00:14:23,519 --> 00:14:24,800
want to highlight what you just said

421
00:14:24,800 --> 00:14:26,639
because it's very important feedback

422
00:14:26,639 --> 00:14:28,720
that i think many of the builders in the

423
00:14:28,720 --> 00:14:31,040
emerging privacy tech space need to hear

424
00:14:31,040 --> 00:14:33,199
and so with that in mind you've

425
00:14:33,199 --> 00:14:35,040
you've given me the perfect opportunity

426
00:14:35,040 --> 00:14:37,680
to transition to the meat of the

427
00:14:37,680 --> 00:14:40,959
discussion to make this actionable for

428
00:14:40,959 --> 00:14:43,760
the pepper community which is like why

429
00:14:43,760 --> 00:14:45,360
do you think nishan is a privacy

430
00:14:45,360 --> 00:14:46,639
engineer why do you think it's important

431
00:14:46,639 --> 00:14:48,240
for other privacy engineers to get

432
00:14:48,240 --> 00:14:50,880
involved in this emerging space in this

433
00:14:50,880 --> 00:14:53,199
nascent space like what has it what what

434
00:14:53,199 --> 00:14:54,560
has it been like

435
00:14:54,560 --> 00:14:57,760
for you like what's the benefit um for

436
00:14:57,760 --> 00:15:00,160
you to get involved this early on

437
00:15:00,160 --> 00:15:02,240
so two benefits and they both applied

438
00:15:02,240 --> 00:15:03,440
not just to the companies and the

439
00:15:03,440 --> 00:15:04,880
customers and the compliance end of the

440
00:15:04,880 --> 00:15:06,959
conversation but the engineers

441
00:15:06,959 --> 00:15:08,639
themselves as well and i think it's

442
00:15:08,639 --> 00:15:10,240
important for any appeal you make

443
00:15:10,240 --> 00:15:12,720
vis-a-vis privacy to work at a very

444
00:15:12,720 --> 00:15:14,480
cerebral level not just at the ethical

445
00:15:14,480 --> 00:15:16,399
level because too many privacy

446
00:15:16,399 --> 00:15:18,000
professionals attorneys engineers

447
00:15:18,000 --> 00:15:20,079
compliance experts make the mistake of

448
00:15:20,079 --> 00:15:22,320
treating privacy like a personal cause

449
00:15:22,320 --> 00:15:24,399
and the and good for you if you have

450
00:15:24,399 --> 00:15:25,920
that level of moral principle i

451
00:15:25,920 --> 00:15:28,000
generally support that but the problem

452
00:15:28,000 --> 00:15:29,199
is the board of directors and the

453
00:15:29,199 --> 00:15:30,800
c-suite has to make decisions based on

454
00:15:30,800 --> 00:15:32,639
financial risk so it's extremely

455
00:15:32,639 --> 00:15:34,560
important to frame the benefits of

456
00:15:34,560 --> 00:15:36,959
privacy in financial business efficiency

457
00:15:36,959 --> 00:15:39,519
terms otherwise you are going nowhere

458
00:15:39,519 --> 00:15:41,120
you will write the most beautiful memos

459
00:15:41,120 --> 00:15:42,240
you will come up with the most beautiful

460
00:15:42,240 --> 00:15:44,079
slides but that's all that will remain

461
00:15:44,079 --> 00:15:45,680
memos and slides so i would say there

462
00:15:45,680 --> 00:15:47,759
are two benefits the first is

463
00:15:47,759 --> 00:15:49,519
engineers like at least 11 hours when i

464
00:15:49,519 --> 00:15:51,199
wrote code back in the day and i just do

465
00:15:51,199 --> 00:15:53,040
on weekends they hate uncertainty what i

466
00:15:53,040 --> 00:15:55,600
mean is they hate the idea of building

467
00:15:55,600 --> 00:15:57,519
something and not knowing if that will

468
00:15:57,519 --> 00:15:59,199
shift because at the last moment is the

469
00:15:59,199 --> 00:16:01,199
dreaded pia privacy impact assessment

470
00:16:01,199 --> 00:16:03,440
process or the dpi that will identify a

471
00:16:03,440 --> 00:16:05,279
risk at which point you have two options

472
00:16:05,279 --> 00:16:07,519
sometimes nuke the project or delay it

473
00:16:07,519 --> 00:16:09,519
indefinitely and lose out on promotions

474
00:16:09,519 --> 00:16:11,600
market engagement what have you or go to

475
00:16:11,600 --> 00:16:13,519
market with the risk nobody wants to be

476
00:16:13,519 --> 00:16:16,240
making that call so the one key tactical

477
00:16:16,240 --> 00:16:17,920
benefit is that you avoid that

478
00:16:17,920 --> 00:16:19,440
conversation and building privacy

479
00:16:19,440 --> 00:16:21,600
engineering into the process getting

480
00:16:21,600 --> 00:16:23,199
involved in shaping privacy tech means

481
00:16:23,199 --> 00:16:25,440
that you are creating a more predictable

482
00:16:25,440 --> 00:16:27,600
dependable marketable cadence for the

483
00:16:27,600 --> 00:16:28,800
release of your products so at the end

484
00:16:28,800 --> 00:16:30,000
of the day i don't care whether you're a

485
00:16:30,000 --> 00:16:32,160
privacy engineer or a security engineer

486
00:16:32,160 --> 00:16:33,920
or just a regular engineer full stack

487
00:16:33,920 --> 00:16:35,199
back-end front end

488
00:16:35,199 --> 00:16:37,279
your job your efficiency will be judged

489
00:16:37,279 --> 00:16:39,600
based on how much you grow the company

490
00:16:39,600 --> 00:16:40,880
how much you reduce the risk like you

491
00:16:40,880 --> 00:16:42,720
have to map things to benefit to the

492
00:16:42,720 --> 00:16:44,320
company benefit to the customer so

493
00:16:44,320 --> 00:16:45,600
that's why it's extremely important for

494
00:16:45,600 --> 00:16:46,880
privacy engineers to get involved in

495
00:16:46,880 --> 00:16:48,639
privacy tech because there's a lot of

496
00:16:48,639 --> 00:16:49,519
tooling but there's a lot of

497
00:16:49,519 --> 00:16:51,600
disconnected conversations about what

498
00:16:51,600 --> 00:16:53,519
tooling will make what benefit the

499
00:16:53,519 --> 00:16:55,440
second thing is a lot of privacy tech

500
00:16:55,440 --> 00:16:57,920
has other uses as well so i often talk

501
00:16:57,920 --> 00:17:00,079
about how i was and i cut my teeth for

502
00:17:00,079 --> 00:17:01,440
all intents and purposes at night at

503
00:17:01,440 --> 00:17:04,160
netflix i did privacy engineering before

504
00:17:04,160 --> 00:17:06,000
netflix and i've done it since but some

505
00:17:06,000 --> 00:17:07,599
of the most seminal lessons in this

506
00:17:07,599 --> 00:17:09,199
domain i learned during my netflix days

507
00:17:09,199 --> 00:17:11,599
from neil hunt who was netflix's iconic

508
00:17:11,599 --> 00:17:13,439
legendary chief product officer it's

509
00:17:13,439 --> 00:17:14,720
kind enough to write the forward for my

510
00:17:14,720 --> 00:17:15,919
book i have to plug it at least once

511
00:17:15,919 --> 00:17:18,240
data privacy runbook for engineers the

512
00:17:18,240 --> 00:17:20,319
publisher gets mad if i don't mention it

513
00:17:20,319 --> 00:17:22,640
so the key benefit and i think you

514
00:17:22,640 --> 00:17:23,839
should listen to this carefully

515
00:17:23,839 --> 00:17:25,919
engineers on the phone is that we are at

516
00:17:25,919 --> 00:17:28,079
an important moment in the tech industry

517
00:17:28,079 --> 00:17:30,160
in the american economy as a society

518
00:17:30,160 --> 00:17:31,840
where we have built attorneys and

519
00:17:31,840 --> 00:17:33,200
engineers that are very very depth

520
00:17:33,200 --> 00:17:35,120
focused they understand their domain

521
00:17:35,120 --> 00:17:36,960
they understand their ci cd pipeline

522
00:17:36,960 --> 00:17:38,960
they understand their personalized

523
00:17:38,960 --> 00:17:40,960
cadence very very well and what that

524
00:17:40,960 --> 00:17:42,640
means is they can ship their products

525
00:17:42,640 --> 00:17:43,679
out almost

526
00:17:43,679 --> 00:17:45,600
on autopilot like there is no surprise

527
00:17:45,600 --> 00:17:47,919
left to have for them the problem is all

528
00:17:47,919 --> 00:17:49,840
the threats we encounter from privacy

529
00:17:49,840 --> 00:17:51,840
are contextual they are combination

530
00:17:51,840 --> 00:17:53,840
threats what that means is what you do

531
00:17:53,840 --> 00:17:55,200
today what i did yesterday and what

532
00:17:55,200 --> 00:17:57,280
somebody else does the day after creates

533
00:17:57,280 --> 00:17:59,600
a unique dynamic of privacy list and so

534
00:17:59,600 --> 00:18:01,280
when you start building tooling in

535
00:18:01,280 --> 00:18:03,280
privacy tech you start understanding

536
00:18:03,280 --> 00:18:05,200
things that are not just depth focused

537
00:18:05,200 --> 00:18:07,360
but breadth focused as well and when you

538
00:18:07,360 --> 00:18:08,720
come to the table with that level of

539
00:18:08,720 --> 00:18:10,480
expertise you find out that you can now

540
00:18:10,480 --> 00:18:12,080
talk intelligently about privacy with

541
00:18:12,080 --> 00:18:14,320
engineers across the company with

542
00:18:14,320 --> 00:18:16,240
experts in machine learning with people

543
00:18:16,240 --> 00:18:18,480
on the platform data side with people on

544
00:18:18,480 --> 00:18:20,559
the marketing personalization side

545
00:18:20,559 --> 00:18:22,080
people on the growth side attorneys

546
00:18:22,080 --> 00:18:23,280
board members

547
00:18:23,280 --> 00:18:25,039
i'm not sure how many engineers out

548
00:18:25,039 --> 00:18:27,440
there can have such a huge impact

549
00:18:27,440 --> 00:18:28,799
and this will help you build better

550
00:18:28,799 --> 00:18:30,559
tooling at your company this will help

551
00:18:30,559 --> 00:18:31,919
you market yourself and your cause

552
00:18:31,919 --> 00:18:33,600
better and this will help uplift your

553
00:18:33,600 --> 00:18:35,120
career in ways that you haven't even

554
00:18:35,120 --> 00:18:36,559
imagined if you are a great haskell

555
00:18:36,559 --> 00:18:38,240
engineer well there are other people who

556
00:18:38,240 --> 00:18:39,600
write haskell and you might not be the

557
00:18:39,600 --> 00:18:41,440
best engineer but if you can be somebody

558
00:18:41,440 --> 00:18:43,520
who can speak to so many audiences your

559
00:18:43,520 --> 00:18:45,200
ability to levitate across the company

560
00:18:45,200 --> 00:18:47,039
and try different kinds of jobs beyond

561
00:18:47,039 --> 00:18:49,039
privacy goes up significantly your

562
00:18:49,039 --> 00:18:50,799
ability to work on platform

563
00:18:50,799 --> 00:18:53,360
misinformation public safety fairness

564
00:18:53,360 --> 00:18:55,200
bias increases as well because all of

565
00:18:55,200 --> 00:18:57,200
these skills all of these challenges

566
00:18:57,200 --> 00:18:58,960
require something critical they require

567
00:18:58,960 --> 00:19:01,120
cross-platform experience the ability to

568
00:19:01,120 --> 00:19:02,480
talk to different stakeholders so if

569
00:19:02,480 --> 00:19:04,640
your goal is to become an architect a

570
00:19:04,640 --> 00:19:07,200
cto a cso or a chief privacy officer

571
00:19:07,200 --> 00:19:08,880
chief trust safety officer if you want

572
00:19:08,880 --> 00:19:10,960
those kinds of roles and fundamentally

573
00:19:10,960 --> 00:19:13,120
differentiate yourself from others and

574
00:19:13,120 --> 00:19:14,640
then differentiate your products as a

575
00:19:14,640 --> 00:19:16,640
company from the products made by other

576
00:19:16,640 --> 00:19:18,880
companies privacy engineering is a great

577
00:19:18,880 --> 00:19:21,039
skill set to have so it's about making

578
00:19:21,039 --> 00:19:23,120
not just yourself and your own career

579
00:19:23,120 --> 00:19:24,880
but your products and your company

580
00:19:24,880 --> 00:19:26,799
further differentiate it's a bit like

581
00:19:26,799 --> 00:19:28,400
when you come out as a privacy engineer

582
00:19:28,400 --> 00:19:30,320
with experience in privacy tech you are

583
00:19:30,320 --> 00:19:31,760
selling a car with seat belts and

584
00:19:31,760 --> 00:19:33,840
airbags versus somebody else down the

585
00:19:33,840 --> 00:19:35,039
street who might be selling a car

586
00:19:35,039 --> 00:19:36,880
without those features they have the

587
00:19:36,880 --> 00:19:39,280
first to first mover advantage but at

588
00:19:39,280 --> 00:19:41,520
some point your overall product quality

589
00:19:41,520 --> 00:19:43,600
from a safety and trust perspective will

590
00:19:43,600 --> 00:19:45,520
win the day because frankly the markets

591
00:19:45,520 --> 00:19:47,280
will expect more today nobody in their

592
00:19:47,280 --> 00:19:48,720
right mind will buy a car without those

593
00:19:48,720 --> 00:19:50,240
safety features right there will come a

594
00:19:50,240 --> 00:19:52,000
time soon but the combination of

595
00:19:52,000 --> 00:19:53,600
regulation the combination of public

596
00:19:53,600 --> 00:19:55,520
sentiment and media scrutiny will make

597
00:19:55,520 --> 00:19:57,600
privacy just as indispensable and you

598
00:19:57,600 --> 00:19:59,440
will be ready to cash in on that moment

599
00:19:59,440 --> 00:20:00,960
so it's again not just the right thing

600
00:20:00,960 --> 00:20:03,120
to do from an altruistic you know human

601
00:20:03,120 --> 00:20:05,600
rights perspective it's also good sound

602
00:20:05,600 --> 00:20:07,120
smart business

603
00:20:07,120 --> 00:20:09,919
i love how you've made the case for this

604
00:20:09,919 --> 00:20:10,720
um

605
00:20:10,720 --> 00:20:12,720
as a value space one and not compliance

606
00:20:12,720 --> 00:20:15,760
one base one because i i mean that that

607
00:20:15,760 --> 00:20:18,240
argument really resonates with folks who

608
00:20:18,240 --> 00:20:20,880
aren't legal or policy folks so the case

609
00:20:20,880 --> 00:20:23,280
for privacy and privacy tech as product

610
00:20:23,280 --> 00:20:26,559
excellence is something that i i think

611
00:20:26,559 --> 00:20:28,320
resonates better especially when i talk

612
00:20:28,320 --> 00:20:30,400
to developers and more technical teams

613
00:20:30,400 --> 00:20:32,799
and i love how uh i particularly love

614
00:20:32,799 --> 00:20:34,640
the point about um

615
00:20:34,640 --> 00:20:36,159
career development and professional

616
00:20:36,159 --> 00:20:37,440
development in general because i mean

617
00:20:37,440 --> 00:20:39,679
who doesn't want to succeed in their

618
00:20:39,679 --> 00:20:42,320
careers right so beyond doing the right

619
00:20:42,320 --> 00:20:45,200
thing beyond compliance there are clear

620
00:20:45,200 --> 00:20:48,720
values um and and and benefits to

621
00:20:48,720 --> 00:20:52,559
getting involved in this space um

622
00:20:52,559 --> 00:20:55,520
let's speak one more argument

623
00:20:55,520 --> 00:20:57,440
i think the other argument the word

624
00:20:57,440 --> 00:20:59,200
compliance often gets my antenna going

625
00:20:59,200 --> 00:21:02,000
up simply because compliance scares me a

626
00:21:02,000 --> 00:21:04,080
little bit in the sense where it creates

627
00:21:04,080 --> 00:21:05,360
the impression that all we are doing is

628
00:21:05,360 --> 00:21:06,960
checking the box and my former who were

629
00:21:06,960 --> 00:21:09,280
calling me ensign who is doing amazing

630
00:21:09,280 --> 00:21:10,480
work these days

631
00:21:10,480 --> 00:21:12,480
i was just on the phone like 30 minutes

632
00:21:12,480 --> 00:21:14,320
ago with her i love her anything she

633
00:21:14,320 --> 00:21:15,760
says i think people should listen to

634
00:21:15,760 --> 00:21:16,799
like she could read the script of the

635
00:21:16,799 --> 00:21:17,919
simpsons and i will listen to it

636
00:21:17,919 --> 00:21:20,720
carefully uh the compliance often evokes

637
00:21:20,720 --> 00:21:22,320
a check the box mentality where people

638
00:21:22,320 --> 00:21:24,320
think that's what you're doing and

639
00:21:24,320 --> 00:21:25,760
eventually that's what you end up doing

640
00:21:25,760 --> 00:21:27,120
because of compliance has been reduced

641
00:21:27,120 --> 00:21:28,559
to that but the real problem with

642
00:21:28,559 --> 00:21:31,280
compliance in my compliance-only mindset

643
00:21:31,280 --> 00:21:32,960
is that compliance keeps changing like

644
00:21:32,960 --> 00:21:34,640
we've gone as privacy professionals to

645
00:21:34,640 --> 00:21:36,240
engineers and told them

646
00:21:36,240 --> 00:21:38,400
drop everything do this because gdpr

647
00:21:38,400 --> 00:21:39,679
then we said drop everything do this

648
00:21:39,679 --> 00:21:41,440
because ccpa then drop everything

649
00:21:41,440 --> 00:21:43,760
because cpra it almost feels like we

650
00:21:43,760 --> 00:21:46,000
have been trying wolf a little too often

651
00:21:46,000 --> 00:21:48,080
so make a compliance-based argument but

652
00:21:48,080 --> 00:21:49,760
make that your second argument if that's

653
00:21:49,760 --> 00:21:51,520
your first argument some people will

654
00:21:51,520 --> 00:21:53,280
tune out because they think that you are

655
00:21:53,280 --> 00:21:55,200
raising hell all over again just like

656
00:21:55,200 --> 00:21:57,280
you raised her last last week and you

657
00:21:57,280 --> 00:21:58,799
will raise hell again next week and

658
00:21:58,799 --> 00:22:01,120
people will tune you out i've talked to

659
00:22:01,120 --> 00:22:02,400
many many engineers in the valley and

660
00:22:02,400 --> 00:22:03,840
that is where some of the fatigue comes

661
00:22:03,840 --> 00:22:05,600
in where you have an external brand

662
00:22:05,600 --> 00:22:07,600
perception that does not improve even as

663
00:22:07,600 --> 00:22:08,720
the company makes significant

664
00:22:08,720 --> 00:22:10,640
investments in compliance and engineers

665
00:22:10,640 --> 00:22:12,080
get bored and tired and they leave and

666
00:22:12,080 --> 00:22:13,760
the board of director wonders directors

667
00:22:13,760 --> 00:22:15,520
wonders why the company's reputation

668
00:22:15,520 --> 00:22:17,520
doesn't doesn't improve so you almost

669
00:22:17,520 --> 00:22:19,200
end up in a situation where companies

670
00:22:19,200 --> 00:22:21,280
don't pay a price for this commercially

671
00:22:21,280 --> 00:22:22,320
but

672
00:22:22,320 --> 00:22:23,520
they still

673
00:22:23,520 --> 00:22:25,360
don't quite meet the public trust mark

674
00:22:25,360 --> 00:22:27,600
so the compliance argument is important

675
00:22:27,600 --> 00:22:29,520
but in my opinion make it your second

676
00:22:29,520 --> 00:22:31,520
argument not your first one absolutely

677
00:22:31,520 --> 00:22:32,720
and there are two

678
00:22:32,720 --> 00:22:34,720
things that are that is wrong with

679
00:22:34,720 --> 00:22:36,320
making it your first argument first it's

680
00:22:36,320 --> 00:22:38,400
a stick not a carrot right and the

681
00:22:38,400 --> 00:22:40,400
second part is that despite the

682
00:22:40,400 --> 00:22:42,480
developments in global data protection

683
00:22:42,480 --> 00:22:43,360
laws

684
00:22:43,360 --> 00:22:45,120
you know compliance and laws in general

685
00:22:45,120 --> 00:22:47,360
will always still lag behind tech let's

686
00:22:47,360 --> 00:22:50,799
just face it like despite the pace of

687
00:22:50,799 --> 00:22:52,480
data protection laws are getting passed

688
00:22:52,480 --> 00:22:54,400
all over the world it's still not as

689
00:22:54,400 --> 00:22:56,640
fast when it comes to technological

690
00:22:56,640 --> 00:22:58,960
developments and so we really you know

691
00:22:58,960 --> 00:23:00,640
like it's a good second argument as you

692
00:23:00,640 --> 00:23:03,120
were saying um but i'm i'm right there

693
00:23:03,120 --> 00:23:06,080
with you in terms of making it a a

694
00:23:06,080 --> 00:23:08,240
backup argument especially when when

695
00:23:08,240 --> 00:23:10,320
you're talking to non-technical folks i

696
00:23:10,320 --> 00:23:12,159
do want to make this even more

697
00:23:12,159 --> 00:23:14,799
actionable like how what's your advice

698
00:23:14,799 --> 00:23:17,039
to other privacy interests how can they

699
00:23:17,039 --> 00:23:18,880
get involved in this space and they can

700
00:23:18,880 --> 00:23:20,960
do it in different capacities right like

701
00:23:20,960 --> 00:23:23,039
in my head they can do it as buyers and

702
00:23:23,039 --> 00:23:25,280
users of privacy tech they can do it if

703
00:23:25,280 --> 00:23:27,760
they can if they have the capacity as

704
00:23:27,760 --> 00:23:30,559
angel investors as board advisors as

705
00:23:30,559 --> 00:23:33,360
domain experts who want to share their

706
00:23:33,360 --> 00:23:35,520
insights and research and

707
00:23:35,520 --> 00:23:37,679
the innovations that they're doing

708
00:23:37,679 --> 00:23:39,600
themselves internally

709
00:23:39,600 --> 00:23:41,120
but i'm curious like what are some of

710
00:23:41,120 --> 00:23:42,159
the

711
00:23:42,159 --> 00:23:45,919
easy ways that they can do this

712
00:23:45,919 --> 00:23:47,760
start with um

713
00:23:47,760 --> 00:23:49,360
maybe let's start as domain experts

714
00:23:49,360 --> 00:23:51,600
because everyone here are privacy domain

715
00:23:51,600 --> 00:23:53,200
experts they're privacy engineers so

716
00:23:53,200 --> 00:23:54,080
let's

717
00:23:54,080 --> 00:23:56,640
let's maybe start with that

718
00:23:56,640 --> 00:23:58,159
yeah so i would basically i mean the

719
00:23:58,159 --> 00:24:00,320
slides you will pretty much spell it out

720
00:24:00,320 --> 00:24:02,080
but let me just say this way there is a

721
00:24:02,080 --> 00:24:03,840
lot of appetite for doing privacy right

722
00:24:03,840 --> 00:24:05,919
and i think historically we've had a

723
00:24:05,919 --> 00:24:07,520
challenge on the privacy and to extend

724
00:24:07,520 --> 00:24:09,520
the security side less on the security

725
00:24:09,520 --> 00:24:10,799
than the privacy side that we've

726
00:24:10,799 --> 00:24:12,799
dismissed privacy as primarily a legal

727
00:24:12,799 --> 00:24:14,559
construct which is only attorneys can

728
00:24:14,559 --> 00:24:16,559
take care of it right guess what i work

729
00:24:16,559 --> 00:24:18,640
with a lot of kick attorneys and they

730
00:24:18,640 --> 00:24:20,320
genuinely want engineering help like

731
00:24:20,320 --> 00:24:23,039
they want to decide do i buy tool x that

732
00:24:23,039 --> 00:24:25,360
is a platform solution or do i buy tool

733
00:24:25,360 --> 00:24:27,440
why that is more of a cms checklist type

734
00:24:27,440 --> 00:24:29,120
solution and you guys probably guess

735
00:24:29,120 --> 00:24:30,320
which tools i'm talking about but i'm

736
00:24:30,320 --> 00:24:31,679
not going to mention proper nouns here

737
00:24:31,679 --> 00:24:33,279
because we are we're all friends it's a

738
00:24:33,279 --> 00:24:36,080
small community here so how do you build

739
00:24:36,080 --> 00:24:37,760
the right solution so essentially

740
00:24:37,760 --> 00:24:39,440
explaining how privacy tooling works

741
00:24:39,440 --> 00:24:40,880
behind the scenes what lessons did you

742
00:24:40,880 --> 00:24:41,919
learn and that's part of the reason i

743
00:24:41,919 --> 00:24:44,240
wrote the book lord is the book is full

744
00:24:44,240 --> 00:24:46,000
of not just how to do things right how

745
00:24:46,000 --> 00:24:47,840
i've fixed some of these problems but

746
00:24:47,840 --> 00:24:48,720
i've been

747
00:24:48,720 --> 00:24:50,799
maybe to a fault reasonably candid about

748
00:24:50,799 --> 00:24:53,200
my own mistakes things that i did that

749
00:24:53,200 --> 00:24:54,640
seemed like a good idea back then that

750
00:24:54,640 --> 00:24:56,400
didn't work so essentially

751
00:24:56,400 --> 00:24:59,200
maybe um anonymizing your experiences

752
00:24:59,200 --> 00:25:00,799
coming up with amalgamations or

753
00:25:00,799 --> 00:25:03,039
anonymized examples would be helpful to

754
00:25:03,039 --> 00:25:04,640
say here's tooling that works and here's

755
00:25:04,640 --> 00:25:06,720
tooling that doesn't work coming just as

756
00:25:06,720 --> 00:25:08,640
engineers like if you youtube if you go

757
00:25:08,640 --> 00:25:10,320
to youtube and say facebook product

758
00:25:10,320 --> 00:25:11,760
management interviews you'll find tons

759
00:25:11,760 --> 00:25:13,120
of videos where people talk about how

760
00:25:13,120 --> 00:25:14,720
facebook does product interviews right

761
00:25:14,720 --> 00:25:16,080
and those are amazingly well short

762
00:25:16,080 --> 00:25:17,840
videos where people simulate it for you

763
00:25:17,840 --> 00:25:19,520
you can do the same thing from a privacy

764
00:25:19,520 --> 00:25:21,360
perspective as well so become a part of

765
00:25:21,360 --> 00:25:23,600
that conversation create a movement come

766
00:25:23,600 --> 00:25:25,840
up with ideas based on your past it's

767
00:25:25,840 --> 00:25:27,520
almost like you can either do things the

768
00:25:27,520 --> 00:25:29,679
way somebody else does things or you can

769
00:25:29,679 --> 00:25:31,279
have them do things your way or come up

770
00:25:31,279 --> 00:25:32,799
with a hybrid approach so the more

771
00:25:32,799 --> 00:25:34,559
conversation we have on this topic based

772
00:25:34,559 --> 00:25:36,400
on people that have done this before the

773
00:25:36,400 --> 00:25:38,080
better that's number one and also

774
00:25:38,080 --> 00:25:40,400
secondly uh explain to you know open

775
00:25:40,400 --> 00:25:41,760
source your code if you build out these

776
00:25:41,760 --> 00:25:43,679
solutions especially in the book and in

777
00:25:43,679 --> 00:25:45,120
the certification that is coming up on

778
00:25:45,120 --> 00:25:46,480
this topic i've come up with a lot of

779
00:25:46,480 --> 00:25:48,320
actual examples on here's how you build

780
00:25:48,320 --> 00:25:50,080
it here's how you measure success here's

781
00:25:50,080 --> 00:25:51,600
how you come up with the right metrics

782
00:25:51,600 --> 00:25:53,520
here's how you shape the message so come

783
00:25:53,520 --> 00:25:54,799
up with those and train people and

784
00:25:54,799 --> 00:25:56,320
honestly you don't have to be a privacy

785
00:25:56,320 --> 00:25:58,080
engineer to do it you can be somebody

786
00:25:58,080 --> 00:25:59,520
who helped with privacy engineering in

787
00:25:59,520 --> 00:26:00,799
your company because in a lot of small

788
00:26:00,799 --> 00:26:02,559
companies the security engineer the

789
00:26:02,559 --> 00:26:04,799
privacy engineer and the it engineer is

790
00:26:04,799 --> 00:26:07,039
one of the same engineer so explain how

791
00:26:07,039 --> 00:26:08,799
you do things in different scenarios so

792
00:26:08,799 --> 00:26:10,799
in my mind a privacy engineer who did

793
00:26:10,799 --> 00:26:12,720
this at google versus somebody who did

794
00:26:12,720 --> 00:26:14,559
this at pinterest versus somebody who

795
00:26:14,559 --> 00:26:16,799
did this at the federated store source

796
00:26:16,799 --> 00:26:18,720
company that owns macy's they all have

797
00:26:18,720 --> 00:26:20,080
equal value because we are talking about

798
00:26:20,080 --> 00:26:21,840
different business models here and the

799
00:26:21,840 --> 00:26:23,200
cumulative nature of this work can be

800
00:26:23,200 --> 00:26:24,720
very very instructive

801
00:26:24,720 --> 00:26:26,080
but the third thing you can do that is

802
00:26:26,080 --> 00:26:28,480
my personal favorite is to ensure that

803
00:26:28,480 --> 00:26:30,159
the people on the legal policy

804
00:26:30,159 --> 00:26:32,480
government relations side understand

805
00:26:32,480 --> 00:26:34,400
the choices that are made here they

806
00:26:34,400 --> 00:26:35,679
understand the implications so it's

807
00:26:35,679 --> 00:26:37,360
almost like if i could shape the world

808
00:26:37,360 --> 00:26:38,880
and my hope is we can still shape it i'm

809
00:26:38,880 --> 00:26:41,360
confident we can is that in a room where

810
00:26:41,360 --> 00:26:42,880
a conversation like this happens it's

811
00:26:42,880 --> 00:26:44,960
critical that the privacy attorneys the

812
00:26:44,960 --> 00:26:46,640
policy folks and the engineers talk

813
00:26:46,640 --> 00:26:49,279
together like i was on a forum hosted by

814
00:26:49,279 --> 00:26:50,880
the atlantic magazine a couple of months

815
00:26:50,880 --> 00:26:52,799
ago hosted by ron brown's team and it

816
00:26:52,799 --> 00:26:55,279
had a lot of policy folks you had people

817
00:26:55,279 --> 00:26:56,880
all the big names in washington dc some

818
00:26:56,880 --> 00:26:58,640
of them were on the call and i was the

819
00:26:58,640 --> 00:27:00,799
only engineer and i gently made fun of

820
00:27:00,799 --> 00:27:02,799
them saying that any privacy law that

821
00:27:02,799 --> 00:27:04,240
you pass right now should be renamed the

822
00:27:04,240 --> 00:27:06,240
nishan job security act because the

823
00:27:06,240 --> 00:27:07,840
conversation is so high level and so

824
00:27:07,840 --> 00:27:10,080
ambiguous that any law that emerges from

825
00:27:10,080 --> 00:27:11,600
this conversation will be by its very

826
00:27:11,600 --> 00:27:13,760
definition so ambiguous and so

827
00:27:13,760 --> 00:27:15,600
unactionable that people like me will

828
00:27:15,600 --> 00:27:18,000
have jobs forever so when i argue for

829
00:27:18,000 --> 00:27:19,600
more collaboration between privacy

830
00:27:19,600 --> 00:27:21,520
engineers and the policy shops i'm

831
00:27:21,520 --> 00:27:23,360
arguing against economic self-interest

832
00:27:23,360 --> 00:27:24,960
because that conversation will create

833
00:27:24,960 --> 00:27:27,360
clearer laws more measurable outcomes

834
00:27:27,360 --> 00:27:29,120
and a better way to judge customer

835
00:27:29,120 --> 00:27:30,960
benefits and they will put me out of

836
00:27:30,960 --> 00:27:32,559
business because frankly my biggest role

837
00:27:32,559 --> 00:27:34,559
right now is to make sure that the

838
00:27:34,559 --> 00:27:36,480
business arm the legal arm on the one

839
00:27:36,480 --> 00:27:38,159
side and the engineering arm on the

840
00:27:38,159 --> 00:27:39,520
other side actually talk to each other

841
00:27:39,520 --> 00:27:40,880
because they are part of the same body

842
00:27:40,880 --> 00:27:42,559
so i feel like privacy domain experts

843
00:27:42,559 --> 00:27:45,360
can use their bio use their work and use

844
00:27:45,360 --> 00:27:46,559
their background to shape the

845
00:27:46,559 --> 00:27:48,240
conversation and the actual quality of

846
00:27:48,240 --> 00:27:50,480
the work and also if you do that you are

847
00:27:50,480 --> 00:27:52,000
encouraging other companies to build

848
00:27:52,000 --> 00:27:54,240
better tooling which if enough companies

849
00:27:54,240 --> 00:27:56,240
start doing things the same correct way

850
00:27:56,240 --> 00:27:57,279
that will

851
00:27:57,279 --> 00:27:59,120
eventually shape the building of privacy

852
00:27:59,120 --> 00:28:00,720
regulations as well because we've made

853
00:28:00,720 --> 00:28:02,159
this mistake of thinking that we have to

854
00:28:02,159 --> 00:28:04,480
build privacy in response to regulation

855
00:28:04,480 --> 00:28:06,320
why not build privacy tooling and shape

856
00:28:06,320 --> 00:28:07,600
the regulation as well the traffic

857
00:28:07,600 --> 00:28:09,520
should go both ways the idea that

858
00:28:09,520 --> 00:28:11,120
engineers should be order takers from

859
00:28:11,120 --> 00:28:12,960
the policy folks is frankly an

860
00:28:12,960 --> 00:28:15,120
anti-delivery concept that needs to be

861
00:28:15,120 --> 00:28:16,880
thrown out the window because we've done

862
00:28:16,880 --> 00:28:18,240
that for the last four five years and

863
00:28:18,240 --> 00:28:20,000
where are we at right now where we have

864
00:28:20,000 --> 00:28:21,919
tons of awareness tons of detail a lot

865
00:28:21,919 --> 00:28:24,080
of experts but frankly i don't think the

866
00:28:24,080 --> 00:28:25,600
customer out there genuinely believes

867
00:28:25,600 --> 00:28:27,200
that big tech has gotten privacy right

868
00:28:27,200 --> 00:28:30,880
and i think that's what we need to fix

869
00:28:30,880 --> 00:28:34,080
absolutely i mean so i i heard so many

870
00:28:34,080 --> 00:28:36,880
um great nuggets there weigh in you know

871
00:28:36,880 --> 00:28:40,320
use your domain expertise especially

872
00:28:40,320 --> 00:28:42,399
because it's technical expertise that is

873
00:28:42,399 --> 00:28:44,880
sorely needed i'm not just in the policy

874
00:28:44,880 --> 00:28:46,799
side but the founders the builders the

875
00:28:46,799 --> 00:28:48,480
startups are building in the space most

876
00:28:48,480 --> 00:28:50,000
of the i probably talked to more than

877
00:28:50,000 --> 00:28:51,679
200 privacy tech founders i was

878
00:28:51,679 --> 00:28:54,159
surprised to find out that uh you know

879
00:28:54,159 --> 00:28:56,799
less than 10 of them have privacy domain

880
00:28:56,799 --> 00:29:00,320
expertise so they sorely need uh people

881
00:29:00,320 --> 00:29:01,919
like unisha and the privacy engineers

882
00:29:01,919 --> 00:29:04,480
here at pepper to get involved and share

883
00:29:04,480 --> 00:29:08,080
your experience you know become advisors

884
00:29:08,080 --> 00:29:10,320
help build privacy tech solutions join

885
00:29:10,320 --> 00:29:11,520
them

886
00:29:11,520 --> 00:29:13,760
better articulate the technical privacy

887
00:29:13,760 --> 00:29:15,360
problems that you're seeing in your

888
00:29:15,360 --> 00:29:16,720
careers

889
00:29:16,720 --> 00:29:18,960
and then be very frank about what's

890
00:29:18,960 --> 00:29:21,200
promising and what's not effective in

891
00:29:21,200 --> 00:29:22,559
terms of the products that you're seeing

892
00:29:22,559 --> 00:29:24,000
out there because the worst thing that

893
00:29:24,000 --> 00:29:25,679
we could do is just like keep talking

894
00:29:25,679 --> 00:29:26,399
about

895
00:29:26,399 --> 00:29:28,080
about some of these startups that are

896
00:29:28,080 --> 00:29:30,880
emerging and say oh you know like

897
00:29:30,880 --> 00:29:32,640
great marketing but when you look under

898
00:29:32,640 --> 00:29:34,480
the hood there's not much there and

899
00:29:34,480 --> 00:29:36,399
that's something that keeps coming up in

900
00:29:36,399 --> 00:29:38,799
conversations behind closed doors is you

901
00:29:38,799 --> 00:29:40,640
know are these actually are these tools

902
00:29:40,640 --> 00:29:42,640
actually solving problems and i feel

903
00:29:42,640 --> 00:29:45,360
like we could avoid that scenario that

904
00:29:45,360 --> 00:29:47,760
problem if we we bring in domain

905
00:29:47,760 --> 00:29:49,120
expertise especially from privacy

906
00:29:49,120 --> 00:29:52,960
engineers like you nashan um

907
00:29:52,960 --> 00:29:55,440
yeah provide feedback i'm curious like

908
00:29:55,440 --> 00:29:57,200
you've done more than that though beyond

909
00:29:57,200 --> 00:30:00,559
your domain expertise beyond your

910
00:30:00,559 --> 00:30:01,520
uh

911
00:30:01,520 --> 00:30:03,840
you know your status as a buyer user

912
00:30:03,840 --> 00:30:05,120
you've actually

913
00:30:05,120 --> 00:30:08,159
also gone beyond and started advising

914
00:30:08,159 --> 00:30:09,520
these startups and started angel

915
00:30:09,520 --> 00:30:11,840
investing in some of them um

916
00:30:11,840 --> 00:30:13,440
what are some advice that you might have

917
00:30:13,440 --> 00:30:15,200
i'm not i'm not sure if this resonates

918
00:30:15,200 --> 00:30:17,120
with this audience but to those who are

919
00:30:17,120 --> 00:30:18,559
in that position who might want to

920
00:30:18,559 --> 00:30:21,600
venture further and and do more not just

921
00:30:21,600 --> 00:30:24,799
as buyers and users or as domain experts

922
00:30:24,799 --> 00:30:26,480
may they may want to do more to really

923
00:30:26,480 --> 00:30:28,480
fuel this emerging industry what are

924
00:30:28,480 --> 00:30:30,559
some advice that you have uh based on

925
00:30:30,559 --> 00:30:32,399
your own practices and i'm happy to

926
00:30:32,399 --> 00:30:33,919
share some of mine to you as an angel

927
00:30:33,919 --> 00:30:35,840
investor and board advisor for some of

928
00:30:35,840 --> 00:30:38,159
these privacy tech startups totally so

929
00:30:38,159 --> 00:30:39,679
the reason unloaded as i started

930
00:30:39,679 --> 00:30:41,600
advising these startups is not

931
00:30:41,600 --> 00:30:43,279
necessarily because i had a lot of time

932
00:30:43,279 --> 00:30:45,279
on my hands or that i had friends for

933
00:30:45,279 --> 00:30:47,520
exactly after uh

934
00:30:47,520 --> 00:30:49,039
there's often been the situation where

935
00:30:49,039 --> 00:30:50,640
i'm literally on the buyer's side like i

936
00:30:50,640 --> 00:30:52,480
need a solution and i'm listening to the

937
00:30:52,480 --> 00:30:55,120
person building the tool and what often

938
00:30:55,120 --> 00:30:56,640
happens is that the product is worse in

939
00:30:56,640 --> 00:30:58,159
the pitch but in this specific case the

940
00:30:58,159 --> 00:30:59,519
pitch is worse than the product like if

941
00:30:59,519 --> 00:31:01,440
you set up an hour on my time my first

942
00:31:01,440 --> 00:31:02,799
question is why do you set up an hour

943
00:31:02,799 --> 00:31:04,640
with me 30 minutes is fine nothing

944
00:31:04,640 --> 00:31:06,000
useful happens in a meeting past the

945
00:31:06,000 --> 00:31:08,480
31st minute anyways so that was a little

946
00:31:08,480 --> 00:31:10,720
friday afternoon snark hopefully uh but

947
00:31:10,720 --> 00:31:12,159
what often happens is people set up

948
00:31:12,159 --> 00:31:13,519
times to talk to me to pitch me a

949
00:31:13,519 --> 00:31:15,200
product or get me advice and until

950
00:31:15,200 --> 00:31:17,600
minute 20 they go on about gdpr and ccp

951
00:31:17,600 --> 00:31:18,880
and customer trust and i have to tell

952
00:31:18,880 --> 00:31:20,399
them that

953
00:31:20,399 --> 00:31:21,840
in this age of attention deficit

954
00:31:21,840 --> 00:31:24,240
disorder and actually have add myself

955
00:31:24,240 --> 00:31:25,440
you want to get me to the value

956
00:31:25,440 --> 00:31:27,200
proposition as quickly as possible so we

957
00:31:27,200 --> 00:31:28,559
have this situation where a lot of

958
00:31:28,559 --> 00:31:30,080
people are building amazing privacy

959
00:31:30,080 --> 00:31:30,880
tools

960
00:31:30,880 --> 00:31:32,240
and that's the tragedy notice is that

961
00:31:32,240 --> 00:31:34,240
these people have amazing ideas in a lot

962
00:31:34,240 --> 00:31:36,240
of cases the tools are awesome but they

963
00:31:36,240 --> 00:31:38,320
have no idea how to sell it and they

964
00:31:38,320 --> 00:31:40,000
often make me a pitch that is very very

965
00:31:40,000 --> 00:31:41,600
legal specific that it belongs to the

966
00:31:41,600 --> 00:31:43,840
privacy attorney like i am deeply

967
00:31:43,840 --> 00:31:47,200
familiar with gdpr and ccp and iso 27701

968
00:31:47,200 --> 00:31:48,559
but i'm not an attorney and there is

969
00:31:48,559 --> 00:31:50,480
just no way i can make a legal argument

970
00:31:50,480 --> 00:31:52,080
and i tell my team of engineers very

971
00:31:52,080 --> 00:31:54,080
carefully expand your horizon make a

972
00:31:54,080 --> 00:31:56,159
bigger impact shape the conversation but

973
00:31:56,159 --> 00:31:58,240
do not do not do not offer legal advice

974
00:31:58,240 --> 00:32:00,240
so my the first mistake a lot of these

975
00:32:00,240 --> 00:32:01,760
founders are making on the privacy tech

976
00:32:01,760 --> 00:32:04,240
space is that they don't quite know how

977
00:32:04,240 --> 00:32:06,720
to sell their product yeah that that in

978
00:32:06,720 --> 00:32:08,080
turn makes it very hard for me to

979
00:32:08,080 --> 00:32:09,440
convince my internal stakeholders

980
00:32:09,440 --> 00:32:11,279
especially on the finance and legal side

981
00:32:11,279 --> 00:32:12,720
that this works well because i just

982
00:32:12,720 --> 00:32:15,600
don't have enough context so my first

983
00:32:15,600 --> 00:32:17,200
goal in advising these startups is to

984
00:32:17,200 --> 00:32:19,760
make sure that the pitch and the product

985
00:32:19,760 --> 00:32:21,279
don't pass each other by too big a

986
00:32:21,279 --> 00:32:22,880
margin there's always a case where the

987
00:32:22,880 --> 00:32:24,480
pitch has to catch up in some cases the

988
00:32:24,480 --> 00:32:26,399
sales folks get over excited and the

989
00:32:26,399 --> 00:32:28,559
product has to catch up but if the gap

990
00:32:28,559 --> 00:32:29,840
between the pitch and the product gets

991
00:32:29,840 --> 00:32:30,960
too wide

992
00:32:30,960 --> 00:32:32,240
that's a problem because either you'll

993
00:32:32,240 --> 00:32:33,760
end up selling stuff and not delivering

994
00:32:33,760 --> 00:32:35,440
it or you will fail to deliver stuff

995
00:32:35,440 --> 00:32:36,640
that is worth delivering because you

996
00:32:36,640 --> 00:32:38,000
don't know how to sell it right so my

997
00:32:38,000 --> 00:32:39,519
first goal was to make sure that the

998
00:32:39,519 --> 00:32:41,600
engineers who are selling this stuff get

999
00:32:41,600 --> 00:32:43,200
better and my goal is to create more

1000
00:32:43,200 --> 00:32:45,039
competition because frankly as a buyer i

1001
00:32:45,039 --> 00:32:46,960
want product a product management to

1002
00:32:46,960 --> 00:32:48,880
compete for my attention and competition

1003
00:32:48,880 --> 00:32:50,159
is always wonderful i'm a written

1004
00:32:50,159 --> 00:32:52,159
freeman free market kind of guy so i

1005
00:32:52,159 --> 00:32:53,840
want more competition in the market so i

1006
00:32:53,840 --> 00:32:56,399
want good hard-working engineers to

1007
00:32:56,399 --> 00:32:58,480
succeed and actually make good money and

1008
00:32:58,480 --> 00:33:00,240
solve the problem that we all care about

1009
00:33:00,240 --> 00:33:01,440
but i also want to make sure that there

1010
00:33:01,440 --> 00:33:03,120
are more options across the board right

1011
00:33:03,120 --> 00:33:05,279
that's number two the third reason i do

1012
00:33:05,279 --> 00:33:07,039
it is because it will force a better

1013
00:33:07,039 --> 00:33:08,880
conversation a lot of these companies on

1014
00:33:08,880 --> 00:33:11,200
the buyer's side need better privacy

1015
00:33:11,200 --> 00:33:12,640
tooling but they don't know how to start

1016
00:33:12,640 --> 00:33:13,760
because all of them have different

1017
00:33:13,760 --> 00:33:15,919
context right so advising these privacy

1018
00:33:15,919 --> 00:33:17,919
tech products mean companies means that

1019
00:33:17,919 --> 00:33:20,159
i can now give them a position of power

1020
00:33:20,159 --> 00:33:22,240
and confidence so that they can advise

1021
00:33:22,240 --> 00:33:24,000
their future buyers and when you have a

1022
00:33:24,000 --> 00:33:25,919
relationship coming in as equals just

1023
00:33:25,919 --> 00:33:27,120
because you are selling me something

1024
00:33:27,120 --> 00:33:28,880
doesn't mean i should have all the power

1025
00:33:28,880 --> 00:33:30,320
you should be able to bring something to

1026
00:33:30,320 --> 00:33:32,320
the table challenge me and force me to

1027
00:33:32,320 --> 00:33:33,679
think twice and i'm like oh this person

1028
00:33:33,679 --> 00:33:35,200
knows something i didn't let's do a

1029
00:33:35,200 --> 00:33:36,799
proof of concept then i can bring

1030
00:33:36,799 --> 00:33:38,399
engineering to the table and they see

1031
00:33:38,399 --> 00:33:40,000
the tool working they see relationships

1032
00:33:40,000 --> 00:33:41,519
forming across the board and then at

1033
00:33:41,519 --> 00:33:42,960
that point it feels like a bottom-up

1034
00:33:42,960 --> 00:33:44,799
conversation with the engineers who are

1035
00:33:44,799 --> 00:33:46,799
two three four five levels below me can

1036
00:33:46,799 --> 00:33:48,320
make the argument for me then it's not

1037
00:33:48,320 --> 00:33:49,919
just me going to the board of directors

1038
00:33:49,919 --> 00:33:51,679
and making the case to buy the tool it's

1039
00:33:51,679 --> 00:33:53,600
the engineers who are both the source of

1040
00:33:53,600 --> 00:33:55,279
growth and engagement on the one side

1041
00:33:55,279 --> 00:33:56,880
and frankly the source of privacy harm

1042
00:33:56,880 --> 00:33:58,799
on the other side i need those engineers

1043
00:33:58,799 --> 00:34:00,640
from the bottom up to make the case so i

1044
00:34:00,640 --> 00:34:02,399
do it not just because i'm a nice guy

1045
00:34:02,399 --> 00:34:03,519
although i feel we should hold on to

1046
00:34:03,519 --> 00:34:05,440
that thought for a second it's because i

1047
00:34:05,440 --> 00:34:06,960
want better tools and i want these

1048
00:34:06,960 --> 00:34:09,040
engineers to succeed and frankly i want

1049
00:34:09,040 --> 00:34:10,399
me to have more choices when i'm

1050
00:34:10,399 --> 00:34:12,239
spending money my shareholders money to

1051
00:34:12,239 --> 00:34:14,960
buy privacy solutions

1052
00:34:14,960 --> 00:34:17,199
thank you for sharing that and that's

1053
00:34:17,199 --> 00:34:18,879
you know that's certainly

1054
00:34:18,879 --> 00:34:21,520
a very good point to make especially

1055
00:34:21,520 --> 00:34:23,119
because we've been dealing with privacy

1056
00:34:23,119 --> 00:34:24,879
technical debt for decades right like

1057
00:34:24,879 --> 00:34:26,800
we've been building technologies with

1058
00:34:26,800 --> 00:34:28,719
without much regard for privacy and to

1059
00:34:28,719 --> 00:34:31,040
be able to be in a position where you

1060
00:34:31,040 --> 00:34:34,000
could impact the way

1061
00:34:34,000 --> 00:34:35,440
new builders are building their

1062
00:34:35,440 --> 00:34:37,679
technologies and and and get some of the

1063
00:34:37,679 --> 00:34:40,000
problems that you have your technical

1064
00:34:40,000 --> 00:34:43,040
privacy problems solved by them um by

1065
00:34:43,040 --> 00:34:45,359
advising them or investing in them or

1066
00:34:45,359 --> 00:34:48,079
just giving them feedback as a buyer um

1067
00:34:48,079 --> 00:34:51,599
is a complete 180 uh compared to where

1068
00:34:51,599 --> 00:34:54,159
we've been for decades so it's a good

1069
00:34:54,159 --> 00:34:57,359
time um for us in general and one of my

1070
00:34:57,359 --> 00:34:59,440
goals is to make sure that we set up

1071
00:34:59,440 --> 00:35:02,640
this industry for success uh

1072
00:35:02,640 --> 00:35:05,200
instead of uh you know uh

1073
00:35:05,200 --> 00:35:08,000
going with tools that may not be uh able

1074
00:35:08,000 --> 00:35:10,079
to deliver when it comes to their

1075
00:35:10,079 --> 00:35:13,359
promise of privacy solutions

1076
00:35:13,359 --> 00:35:15,520
we don't have a lot of time so i i bet

1077
00:35:15,520 --> 00:35:18,160
folks have questions so uh just to

1078
00:35:18,160 --> 00:35:19,280
summarize there are a lot of

1079
00:35:19,280 --> 00:35:21,200
opportunities out there there are

1080
00:35:21,200 --> 00:35:23,280
advisory roles that privacy tech starts

1081
00:35:23,280 --> 00:35:24,960
our consulting roles our in-house

1082
00:35:24,960 --> 00:35:27,440
privacy roles we know some cpos and

1083
00:35:27,440 --> 00:35:29,520
privacy engineers that are now working

1084
00:35:29,520 --> 00:35:31,920
for privacy tech startups not just

1085
00:35:31,920 --> 00:35:34,640
tech big tech companies in general um

1086
00:35:34,640 --> 00:35:36,480
and so you know we

1087
00:35:36,480 --> 00:35:39,119
you could demo these ones and i i know

1088
00:35:39,119 --> 00:35:40,880
nishant we've you've pocked some of

1089
00:35:40,880 --> 00:35:42,560
these startups through tropes and been

1090
00:35:42,560 --> 00:35:44,560
paid as a buyer to review some of these

1091
00:35:44,560 --> 00:35:47,119
startups so if folks there here are

1092
00:35:47,119 --> 00:35:48,960
interested let us know and then

1093
00:35:48,960 --> 00:35:51,280
obviously we also have um

1094
00:35:51,280 --> 00:35:53,200
angel investing opportunities in some of

1095
00:35:53,200 --> 00:35:55,200
these emerging privacy tech startups and

1096
00:35:55,200 --> 00:35:56,960
and i also know some engineers and

1097
00:35:56,960 --> 00:35:59,760
privacy domain experts uh who are now

1098
00:35:59,760 --> 00:36:01,359
co-founding their own privacy tech

1099
00:36:01,359 --> 00:36:03,760
startups so we we'd love to

1100
00:36:03,760 --> 00:36:05,599
we love to see that absolutely because

1101
00:36:05,599 --> 00:36:07,599
we want domain experts to help solve

1102
00:36:07,599 --> 00:36:10,160
these problems in an informed way

1103
00:36:10,160 --> 00:36:13,040
um with that in mind i do we have about

1104
00:36:13,040 --> 00:36:14,640
like five minutes so i want to give it

1105
00:36:14,640 --> 00:36:16,240
back to the moderator in case there are

1106
00:36:16,240 --> 00:36:17,839
questions yeah there have been a lot of

1107
00:36:17,839 --> 00:36:19,920
questions and discussion on slack really

1108
00:36:19,920 --> 00:36:21,920
the biggest theme is really around

1109
00:36:21,920 --> 00:36:23,440
arguments and morals and values

1110
00:36:23,440 --> 00:36:26,000
arguments for privacy of as people in

1111
00:36:26,000 --> 00:36:27,520
this room that care about privacy

1112
00:36:27,520 --> 00:36:28,960
there's sort of a lot of ways and

1113
00:36:28,960 --> 00:36:31,040
strategies that people use to advocate

1114
00:36:31,040 --> 00:36:32,320
and a lot of people i think from

1115
00:36:32,320 --> 00:36:34,560
discussion really see a lot of value in

1116
00:36:34,560 --> 00:36:36,160
the

1117
00:36:36,160 --> 00:36:38,000
morals and values based arguments for

1118
00:36:38,000 --> 00:36:39,280
privacy and also we're interested in

1119
00:36:39,280 --> 00:36:42,480
hearing about some of the strategies to

1120
00:36:42,480 --> 00:36:43,520
make

1121
00:36:43,520 --> 00:36:45,760
financial type value arguments and how

1122
00:36:45,760 --> 00:36:48,160
do you both navigate that space of

1123
00:36:48,160 --> 00:36:49,760
the moral and financial trade-offs and

1124
00:36:49,760 --> 00:36:51,119
sort of

1125
00:36:51,119 --> 00:36:53,119
bringing the right arguments to to

1126
00:36:53,119 --> 00:36:55,119
advocate for adoption of privacy

1127
00:36:55,119 --> 00:36:56,560
technologies

1128
00:36:56,560 --> 00:36:57,920
i'm not going to speak for nissan but

1129
00:36:57,920 --> 00:37:00,079
for me the moral arguments are paramount

1130
00:37:00,079 --> 00:37:02,320
and very important that's the reason why

1131
00:37:02,320 --> 00:37:05,200
i work in privacy but i also recognize

1132
00:37:05,200 --> 00:37:07,040
that they don't resonate with everyone

1133
00:37:07,040 --> 00:37:08,800
especially when you're

1134
00:37:08,800 --> 00:37:10,720
you know when you're in tech right like

1135
00:37:10,720 --> 00:37:14,079
so the way i look at it i make different

1136
00:37:14,079 --> 00:37:16,640
arguments based on my audience so if i'm

1137
00:37:16,640 --> 00:37:19,599
talking to engineers i'm gonna

1138
00:37:19,599 --> 00:37:22,320
make the business case for privacy from

1139
00:37:22,320 --> 00:37:24,320
a product excellence standpoint if i'm

1140
00:37:24,320 --> 00:37:27,119
talking to finance and business people

1141
00:37:27,119 --> 00:37:29,520
and vcs i'm going to make the case for

1142
00:37:29,520 --> 00:37:31,920
privacy from a value

1143
00:37:31,920 --> 00:37:34,640
roi financial standpoint if i'm talking

1144
00:37:34,640 --> 00:37:37,040
to regulators then we'll talk compliance

1145
00:37:37,040 --> 00:37:40,400
and societal good uh benefits and so on

1146
00:37:40,400 --> 00:37:42,640
and so i don't think

1147
00:37:42,640 --> 00:37:45,280
it's an either or thing i think

1148
00:37:45,280 --> 00:37:47,839
it's a good idea to diversify your

1149
00:37:47,839 --> 00:37:51,200
toolbox and have a bunch of privacy

1150
00:37:51,200 --> 00:37:53,599
carrots when you're you know so you can

1151
00:37:53,599 --> 00:37:55,440
pull one out and and just really get to

1152
00:37:55,440 --> 00:37:57,359
know who your audience is um but i'm i'm

1153
00:37:57,359 --> 00:37:59,839
with everyone i i'm i'm in privacy

1154
00:37:59,839 --> 00:38:02,480
because i care i mean it's it's what

1155
00:38:02,480 --> 00:38:05,119
keeps me up um you know in the morning

1156
00:38:05,119 --> 00:38:07,200
and to keep doing this type of work but

1157
00:38:07,200 --> 00:38:09,599
the you have to be practical and realize

1158
00:38:09,599 --> 00:38:11,359
that not everyone feels the same way not

1159
00:38:11,359 --> 00:38:13,920
everyone in tech or in the world cares

1160
00:38:13,920 --> 00:38:15,680
about privacy from a moral health

1161
00:38:15,680 --> 00:38:17,680
standpoint and so you kind of have to

1162
00:38:17,680 --> 00:38:19,680
meet them where they are

1163
00:38:19,680 --> 00:38:22,720
yeah so i began this call by saying that

1164
00:38:22,720 --> 00:38:24,960
make the compliance argument second and

1165
00:38:24,960 --> 00:38:26,560
when i usually do my presentation now i

1166
00:38:26,560 --> 00:38:28,800
used to be just full disclosure before i

1167
00:38:28,800 --> 00:38:30,480
used to be a debater in college i love

1168
00:38:30,480 --> 00:38:32,640
sort of saving the narrative the moral

1169
00:38:32,640 --> 00:38:34,320
narrative at the end to make sure people

1170
00:38:34,320 --> 00:38:36,560
remember because my belief is people

1171
00:38:36,560 --> 00:38:38,240
listen to you because of data people

1172
00:38:38,240 --> 00:38:40,079
follow you because of values

1173
00:38:40,079 --> 00:38:42,160
so i start with the data but then i give

1174
00:38:42,160 --> 00:38:44,320
people a specific example so i live in

1175
00:38:44,320 --> 00:38:46,480
mountain view california and i often

1176
00:38:46,480 --> 00:38:48,160
go to stanford to get my eyes checked

1177
00:38:48,160 --> 00:38:49,599
once every three months or once every

1178
00:38:49,599 --> 00:38:51,280
six months at the latest because as a

1179
00:38:51,280 --> 00:38:53,839
teenager 20 years some years ago i had

1180
00:38:53,839 --> 00:38:55,440
narrow angle glaucoma this is typically

1181
00:38:55,440 --> 00:38:57,200
a disease that hits people when they're

1182
00:38:57,200 --> 00:38:59,440
60 plus i'm one of the lucky ones i got

1183
00:38:59,440 --> 00:39:01,359
it when i was in my teens so if you were

1184
00:39:01,359 --> 00:39:03,839
to map if i were to say take a walk from

1185
00:39:03,839 --> 00:39:05,280
my house go on a bike from my house to

1186
00:39:05,280 --> 00:39:07,520
stanford and if you were to track my

1187
00:39:07,520 --> 00:39:10,160
movements right and if you were to get

1188
00:39:10,160 --> 00:39:12,240
gps coordinates with like or rather lat

1189
00:39:12,240 --> 00:39:13,680
long coordinates with like five decimal

1190
00:39:13,680 --> 00:39:14,400
points

1191
00:39:14,400 --> 00:39:16,079
you would know exactly where i went to

1192
00:39:16,079 --> 00:39:18,079
stanford and because the buildings are

1193
00:39:18,079 --> 00:39:20,320
so huge the facilities are so huge

1194
00:39:20,320 --> 00:39:22,079
depending upon where i park my bike you

1195
00:39:22,079 --> 00:39:23,839
could identify that i went to see the

1196
00:39:23,839 --> 00:39:25,599
eye doctor or i went to see the neuro

1197
00:39:25,599 --> 00:39:27,119
neurology doctor or i went to see some

1198
00:39:27,119 --> 00:39:28,960
other doctor bottom line is if you track

1199
00:39:28,960 --> 00:39:30,560
the fact that i go there once every x

1200
00:39:30,560 --> 00:39:31,760
months

1201
00:39:31,760 --> 00:39:33,200
then without following me once i get

1202
00:39:33,200 --> 00:39:34,560
this month get off the bike you could

1203
00:39:34,560 --> 00:39:35,920
know that i have one of three diseases

1204
00:39:35,920 --> 00:39:36,720
right

1205
00:39:36,720 --> 00:39:38,079
that's not a good idea i don't want you

1206
00:39:38,079 --> 00:39:39,359
to know that of course i've talked about

1207
00:39:39,359 --> 00:39:41,359
this publicly before as part of research

1208
00:39:41,359 --> 00:39:43,839
into my eye condition you know it but

1209
00:39:43,839 --> 00:39:45,359
you don't get to know it just by

1210
00:39:45,359 --> 00:39:46,640
tracking me without my permission so

1211
00:39:46,640 --> 00:39:48,320
there is a human connection but fine if

1212
00:39:48,320 --> 00:39:49,760
you find out that i have an eye

1213
00:39:49,760 --> 00:39:51,760
condition 20 years ago no biggie but

1214
00:39:51,760 --> 00:39:53,119
let's assume i'm a dissident in a

1215
00:39:53,119 --> 00:39:54,560
country that has a species human rights

1216
00:39:54,560 --> 00:39:56,880
record you tracking me having that

1217
00:39:56,880 --> 00:39:58,720
location live in your database some

1218
00:39:58,720 --> 00:40:00,000
place that then gets breached because

1219
00:40:00,000 --> 00:40:01,359
you weren't careful enough to encrypt it

1220
00:40:01,359 --> 00:40:03,200
or manage access control now the

1221
00:40:03,200 --> 00:40:04,880
government that i'm fighting against

1222
00:40:04,880 --> 00:40:06,640
knows exactly where i live or they know

1223
00:40:06,640 --> 00:40:07,920
exactly where i'm going to be next

1224
00:40:07,920 --> 00:40:09,680
friday morning at nine o'clock

1225
00:40:09,680 --> 00:40:11,680
your sloppiness with privacy could cost

1226
00:40:11,680 --> 00:40:13,920
me my life

1227
00:40:13,920 --> 00:40:15,680
what kind of growth is worth it if it

1228
00:40:15,680 --> 00:40:17,760
comes at the expense of my life

1229
00:40:17,760 --> 00:40:18,800
how is that going to look in the new

1230
00:40:18,800 --> 00:40:20,160
york times how would that how would that

1231
00:40:20,160 --> 00:40:22,079
make you feel if a friend of yours or a

1232
00:40:22,079 --> 00:40:24,000
family a friend family members of yours

1233
00:40:24,000 --> 00:40:26,160
were affected that way so my general

1234
00:40:26,160 --> 00:40:28,000
approach is to not do it too often

1235
00:40:28,000 --> 00:40:29,760
because it often feels like harmonizing

1236
00:40:29,760 --> 00:40:31,440
and if you do it over and over again

1237
00:40:31,440 --> 00:40:33,520
people lose the punch of it but it's

1238
00:40:33,520 --> 00:40:35,359
extremely important to remember that

1239
00:40:35,359 --> 00:40:37,119
when it comes to privacy your platform

1240
00:40:37,119 --> 00:40:38,800
your strategy is only as strong as your

1241
00:40:38,800 --> 00:40:40,480
weakest link and it's important to

1242
00:40:40,480 --> 00:40:41,920
remember that the person who doesn't

1243
00:40:41,920 --> 00:40:43,920
have the time to read the privacy policy

1244
00:40:43,920 --> 00:40:45,599
or the person that doesn't have all the

1245
00:40:45,599 --> 00:40:47,520
money to sue you in court often stands

1246
00:40:47,520 --> 00:40:50,319
to lose the most as a society we often

1247
00:40:50,319 --> 00:40:52,000
we rarely lose the chance to punish

1248
00:40:52,000 --> 00:40:53,280
people because they're poor and

1249
00:40:53,280 --> 00:40:54,960
powerless right that's who always

1250
00:40:54,960 --> 00:40:56,720
suffers when people make bad decisions

1251
00:40:56,720 --> 00:40:58,160
whether it's covered lockdowns whether

1252
00:40:58,160 --> 00:40:59,920
it's recessions the people who suffer

1253
00:40:59,920 --> 00:41:01,839
the most are the weakest and the poorest

1254
00:41:01,839 --> 00:41:03,440
and if we as an industry give up on

1255
00:41:03,440 --> 00:41:04,880
protecting them

1256
00:41:04,880 --> 00:41:06,560
what kind of a world are we creating

1257
00:41:06,560 --> 00:41:07,920
would this one would this be a world

1258
00:41:07,920 --> 00:41:09,599
that we want to raise our kids in so

1259
00:41:09,599 --> 00:41:11,280
it's important to remember that behind

1260
00:41:11,280 --> 00:41:13,200
all the tableau dashboards behind all

1261
00:41:13,200 --> 00:41:14,720
the alerts behind all the

1262
00:41:14,720 --> 00:41:16,960
personalization tools behind all the ml

1263
00:41:16,960 --> 00:41:18,800
models is a human being and their data

1264
00:41:18,800 --> 00:41:20,079
and that human being doesn't know that

1265
00:41:20,079 --> 00:41:22,480
you exist so remember that human being

1266
00:41:22,480 --> 00:41:24,160
when you build these tools and bring

1267
00:41:24,160 --> 00:41:25,920
that sensibility with you when you

1268
00:41:25,920 --> 00:41:27,599
showcase these tools to the engineers

1269
00:41:27,599 --> 00:41:28,880
that in your company might be a bit

1270
00:41:28,880 --> 00:41:31,040
skeptical so it's helpful to not

1271
00:41:31,040 --> 00:41:32,880
essentially lead with that argument but

1272
00:41:32,880 --> 00:41:34,400
not leave home without making that

1273
00:41:34,400 --> 00:41:37,040
argument so

1274
00:41:38,240 --> 00:41:40,160
yeah thank you and we don't have any

1275
00:41:40,160 --> 00:41:41,359
more time for questions but this

1276
00:41:41,359 --> 00:41:42,880
triggered a lot of really interesting

1277
00:41:42,880 --> 00:41:44,720
discussion on slack about

1278
00:41:44,720 --> 00:41:47,440
values and reasons to adopt privacy and

1279
00:41:47,440 --> 00:41:49,119
advocate for privacy so would recommend

1280
00:41:49,119 --> 00:41:50,480
continuing discussion on slack and

1281
00:41:50,480 --> 00:41:54,680
looking there for more information

1282
00:42:02,319 --> 00:42:04,400
you

