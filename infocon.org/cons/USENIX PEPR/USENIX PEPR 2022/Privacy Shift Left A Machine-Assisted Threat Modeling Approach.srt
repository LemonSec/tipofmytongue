1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:10,019 --> 00:00:11,820
hi everyone thank you so much for

3
00:00:11,820 --> 00:00:14,400
joining me here today for privacy shifts

4
00:00:14,400 --> 00:00:16,260
left a machine assisted threat modeling

5
00:00:16,260 --> 00:00:18,600
approach my name is Kristen tan and this

6
00:00:18,600 --> 00:00:20,699
project was a joint venture with my

7
00:00:20,699 --> 00:00:22,740
manager on my last for a patient by Bob

8
00:00:22,740 --> 00:00:24,600
Garg we're both coming to you from

9
00:00:24,600 --> 00:00:25,920
Comcast cable

10
00:00:25,920 --> 00:00:28,019
let's jump in with an exploration of

11
00:00:28,019 --> 00:00:30,000
what it means to shift security and

12
00:00:30,000 --> 00:00:32,340
privacy left within the name of the talk

13
00:00:32,340 --> 00:00:33,780
we should probably understand it before

14
00:00:33,780 --> 00:00:35,520
we go ahead and go on with the rest of

15
00:00:35,520 --> 00:00:37,440
the talk so what you're looking at here

16
00:00:37,440 --> 00:00:39,540
this blue diagram at the top is

17
00:00:39,540 --> 00:00:41,399
representation of the traditional

18
00:00:41,399 --> 00:00:43,980
software development process we start

19
00:00:43,980 --> 00:00:45,840
out on the left with requirements

20
00:00:45,840 --> 00:00:47,820
engineering this is the process of

21
00:00:47,820 --> 00:00:49,200
talking to our customers and

22
00:00:49,200 --> 00:00:50,879
understanding what their needs are as

23
00:00:50,879 --> 00:00:52,559
well as any constraints that we have

24
00:00:52,559 --> 00:00:54,960
when fulfilling those needs we take this

25
00:00:54,960 --> 00:00:56,280
conversation that we have with the

26
00:00:56,280 --> 00:00:58,260
customer and we attempt to turn it into

27
00:00:58,260 --> 00:01:00,539
technical requirements functional and

28
00:01:00,539 --> 00:01:02,160
non-functional requirements that dictate

29
00:01:02,160 --> 00:01:03,780
how our system will be built and

30
00:01:03,780 --> 00:01:06,360
performed we use those requirements then

31
00:01:06,360 --> 00:01:08,159
to guide our development of an

32
00:01:08,159 --> 00:01:10,260
architecture design the architecture

33
00:01:10,260 --> 00:01:11,640
design should be a high level

34
00:01:11,640 --> 00:01:13,560
description of what our system looks

35
00:01:13,560 --> 00:01:15,540
like what are the technical components

36
00:01:15,540 --> 00:01:17,159
in the system and how do they talk to

37
00:01:17,159 --> 00:01:18,900
one another what are the communication

38
00:01:18,900 --> 00:01:20,460
paths and what are the protocols in

39
00:01:20,460 --> 00:01:21,240
place

40
00:01:21,240 --> 00:01:23,640
this architecture design then dictates

41
00:01:23,640 --> 00:01:25,560
what we develop so that next phase of

42
00:01:25,560 --> 00:01:26,820
software development is actually

43
00:01:26,820 --> 00:01:28,860
building out that architecture

44
00:01:28,860 --> 00:01:31,200
it's a long process of coding and

45
00:01:31,200 --> 00:01:33,360
debugging and coding and debugging and

46
00:01:33,360 --> 00:01:35,400
so on and so on until we've built out

47
00:01:35,400 --> 00:01:37,079
all of the components that fulfill that

48
00:01:37,079 --> 00:01:38,820
architecture and and hook them all up to

49
00:01:38,820 --> 00:01:39,780
one another

50
00:01:39,780 --> 00:01:42,240
the next step is testing but it's

51
00:01:42,240 --> 00:01:44,460
important to take a step back here and

52
00:01:44,460 --> 00:01:46,439
understand that this is not truly a

53
00:01:46,439 --> 00:01:48,600
linear process this is actually a

54
00:01:48,600 --> 00:01:50,340
process that's quite cyclical and that

55
00:01:50,340 --> 00:01:51,899
involves some interplay between the

56
00:01:51,899 --> 00:01:53,399
phases that we see here they're not

57
00:01:53,399 --> 00:01:55,979
quite so cut and dry separate when we're

58
00:01:55,979 --> 00:01:57,899
testing we might test at a unit test

59
00:01:57,899 --> 00:02:00,119
level or all the way up at a system test

60
00:02:00,119 --> 00:02:02,340
level so this is not to say that we

61
00:02:02,340 --> 00:02:04,079
write all of our code and then hand it

62
00:02:04,079 --> 00:02:06,000
off to be tested because that would not

63
00:02:06,000 --> 00:02:08,940
be very practical but this diagram is a

64
00:02:08,940 --> 00:02:11,280
good a good way of understanding what

65
00:02:11,280 --> 00:02:13,440
the sequential steps are to get from

66
00:02:13,440 --> 00:02:16,319
nothing to complete system so during

67
00:02:16,319 --> 00:02:18,540
that testing phase we validate we make

68
00:02:18,540 --> 00:02:19,800
sure that the code does what we expect

69
00:02:19,800 --> 00:02:22,200
it to do then we hand over our finished

70
00:02:22,200 --> 00:02:24,120
product to the customer when we deploy

71
00:02:24,120 --> 00:02:26,400
it and finally we listen to customer bug

72
00:02:26,400 --> 00:02:28,200
reports or feature requests sharing this

73
00:02:28,200 --> 00:02:30,780
maintenance maintenance phase excuse me

74
00:02:30,780 --> 00:02:33,060
but security and privacy we didn't

75
00:02:33,060 --> 00:02:34,739
really mention them here traditionally

76
00:02:34,739 --> 00:02:37,440
they fit somewhere in between testing

77
00:02:37,440 --> 00:02:39,540
and deployment we build out our entire

78
00:02:39,540 --> 00:02:40,860
application we validate that

79
00:02:40,860 --> 00:02:43,319
functionality works and then we say wait

80
00:02:43,319 --> 00:02:45,000
are there any problems with the security

81
00:02:45,000 --> 00:02:47,220
of this application or is my customer's

82
00:02:47,220 --> 00:02:48,660
data actually being protected the way

83
00:02:48,660 --> 00:02:50,340
it's supposed to be and then we go ahead

84
00:02:50,340 --> 00:02:51,959
and we come up with Solutions and we

85
00:02:51,959 --> 00:02:53,940
retrofit those solutions to the

86
00:02:53,940 --> 00:02:56,280
application or to the system best

87
00:02:56,280 --> 00:02:57,900
practice dictates that that's not

88
00:02:57,900 --> 00:02:59,760
actually what we should be doing what we

89
00:02:59,760 --> 00:03:01,739
really want to do is take security and

90
00:03:01,739 --> 00:03:04,080
privacy and move them all the way to the

91
00:03:04,080 --> 00:03:05,340
beginning of that software development

92
00:03:05,340 --> 00:03:07,440
life cycle we want to have conversations

93
00:03:07,440 --> 00:03:09,480
about security and privacy with our

94
00:03:09,480 --> 00:03:11,220
customers during the requirements

95
00:03:11,220 --> 00:03:13,260
engineering phase and then carry those

96
00:03:13,260 --> 00:03:15,120
considerations with us all the way

97
00:03:15,120 --> 00:03:16,980
through maintenance so security and

98
00:03:16,980 --> 00:03:19,860
privacy need to be moved to the left

99
00:03:19,860 --> 00:03:21,840
how do we go about doing that though

100
00:03:21,840 --> 00:03:24,300
threat modeling is one way that we can

101
00:03:24,300 --> 00:03:26,280
start to introduce security and privacy

102
00:03:26,280 --> 00:03:27,840
earlier in the software development

103
00:03:27,840 --> 00:03:30,000
process threat modeling is a way of

104
00:03:30,000 --> 00:03:31,440
looking at the architecture of a system

105
00:03:31,440 --> 00:03:33,360
and trying to understand what the

106
00:03:33,360 --> 00:03:35,340
potential security and privacy flaws are

107
00:03:35,340 --> 00:03:37,500
before they have actually occurred

108
00:03:37,500 --> 00:03:39,599
before they've ideally even been built

109
00:03:39,599 --> 00:03:41,099
into the system

110
00:03:41,099 --> 00:03:43,140
threat modeling works as follows we

111
00:03:43,140 --> 00:03:44,640
start out with data flow diagram

112
00:03:44,640 --> 00:03:46,920
creation we ask the application or

113
00:03:46,920 --> 00:03:48,540
system owners to put together a

114
00:03:48,540 --> 00:03:49,980
representation of the technical

115
00:03:49,980 --> 00:03:52,379
technical components excuse me that make

116
00:03:52,379 --> 00:03:54,599
up a system as well as the data assets

117
00:03:54,599 --> 00:03:56,340
that are stored and passed around in

118
00:03:56,340 --> 00:03:58,560
that system that representation is then

119
00:03:58,560 --> 00:04:00,120
handed over to a threat modeling

120
00:04:00,120 --> 00:04:01,980
architect the threat modeling architect

121
00:04:01,980 --> 00:04:04,140
goes about analyzing the data flow

122
00:04:04,140 --> 00:04:06,599
diagram they look for any problem areas

123
00:04:06,599 --> 00:04:08,340
that they might be familiar with thanks

124
00:04:08,340 --> 00:04:09,959
to previous start models and thanks to

125
00:04:09,959 --> 00:04:11,640
knowledge of common threats they

126
00:04:11,640 --> 00:04:13,140
highlight these problem areas and they

127
00:04:13,140 --> 00:04:14,819
come up with a list of questions perhaps

128
00:04:14,819 --> 00:04:16,139
that they want to bring to the

129
00:04:16,139 --> 00:04:18,120
application team to under to get a

130
00:04:18,120 --> 00:04:19,620
better understanding of what protections

131
00:04:19,620 --> 00:04:20,880
they might have in place to prevent

132
00:04:20,880 --> 00:04:23,520
those threats then we transition to the

133
00:04:23,520 --> 00:04:25,500
threat modeling Workshop this is a

134
00:04:25,500 --> 00:04:27,180
conversation between the threat modeling

135
00:04:27,180 --> 00:04:29,880
Architects and the application team any

136
00:04:29,880 --> 00:04:31,320
stakeholders who might have information

137
00:04:31,320 --> 00:04:33,660
relevant to surfacing up threats are

138
00:04:33,660 --> 00:04:35,520
brought to this conversation such that

139
00:04:35,520 --> 00:04:37,380
we can get all the contacts possible or

140
00:04:37,380 --> 00:04:38,699
all the contacts needed to understand

141
00:04:38,699 --> 00:04:41,100
whether or not a threat is present by

142
00:04:41,100 --> 00:04:42,660
the end of this process ideally the

143
00:04:42,660 --> 00:04:44,040
threat modeling architect has been able

144
00:04:44,040 --> 00:04:45,840
to put together a list of all the

145
00:04:45,840 --> 00:04:47,460
threats that they've discovered to be

146
00:04:47,460 --> 00:04:49,740
present and can then hand that over to

147
00:04:49,740 --> 00:04:51,680
the application team for remediation

148
00:04:51,680 --> 00:04:54,300
ideally these threats are prioritized

149
00:04:54,300 --> 00:04:56,759
for mediation in order of risk so

150
00:04:56,759 --> 00:04:58,860
whatever threat introduces the most risk

151
00:04:58,860 --> 00:05:00,620
to the system should be addressed first

152
00:05:00,620 --> 00:05:03,300
this is the ideal workflow of a threat

153
00:05:03,300 --> 00:05:05,340
modeling process and it's quite often

154
00:05:05,340 --> 00:05:07,199
aided by the structure that might be

155
00:05:07,199 --> 00:05:09,360
lended by a threat modeling framework

156
00:05:09,360 --> 00:05:10,860
there are a number of different

157
00:05:10,860 --> 00:05:12,900
Frameworks out there so we're looking at

158
00:05:12,900 --> 00:05:14,220
two here on the screen right now but

159
00:05:14,220 --> 00:05:15,840
that's not to say that there aren't more

160
00:05:15,840 --> 00:05:17,460
but one of the the most common

161
00:05:17,460 --> 00:05:19,139
Frameworks for security threat modeling

162
00:05:19,139 --> 00:05:21,419
is called stride stride is an acronym

163
00:05:21,419 --> 00:05:23,460
for six key security threat categories

164
00:05:23,460 --> 00:05:25,500
that we see on the screen here and then

165
00:05:25,500 --> 00:05:27,180
a number of security threats fall within

166
00:05:27,180 --> 00:05:29,039
each of these categories so these are

167
00:05:29,039 --> 00:05:30,960
meant as a guideline or a quick way to

168
00:05:30,960 --> 00:05:32,699
remember a sort of mnemonic to remember

169
00:05:32,699 --> 00:05:34,500
what are some of the key areas that we

170
00:05:34,500 --> 00:05:36,840
need to pay attention to similarly as

171
00:05:36,840 --> 00:05:38,639
was discussed at a previous pepper

172
00:05:38,639 --> 00:05:40,740
conference Lyndon is a privacy threat

173
00:05:40,740 --> 00:05:42,720
modeling framework Linden identifies

174
00:05:42,720 --> 00:05:44,820
seven key privacy threat categories

175
00:05:44,820 --> 00:05:47,340
under which for each category there are

176
00:05:47,340 --> 00:05:48,960
a number of common privacy threats that

177
00:05:48,960 --> 00:05:50,699
fall so once again we can rely on

178
00:05:50,699 --> 00:05:52,560
something like Lyndon to guide our

179
00:05:52,560 --> 00:05:54,960
conversation about common violations of

180
00:05:54,960 --> 00:05:56,280
users privacy rights or common

181
00:05:56,280 --> 00:05:58,380
violations of data handling that result

182
00:05:58,380 --> 00:06:01,020
in privacy threats so thought modeling

183
00:06:01,020 --> 00:06:03,240
sounds like a promising way to introduce

184
00:06:03,240 --> 00:06:04,680
discussion of security and privacy

185
00:06:04,680 --> 00:06:06,120
earlier in the development life cycle

186
00:06:06,120 --> 00:06:07,919
such that we don't end up having to

187
00:06:07,919 --> 00:06:09,900
retrofit Solutions later on

188
00:06:09,900 --> 00:06:11,819
but of course there are going to be some

189
00:06:11,819 --> 00:06:13,800
problems that occur or really some

190
00:06:13,800 --> 00:06:15,840
challenges that we need to overcome

191
00:06:15,840 --> 00:06:18,240
these main challenges for us are time

192
00:06:18,240 --> 00:06:20,340
and resource constraints time

193
00:06:20,340 --> 00:06:22,139
constraints are fairly straightforward

194
00:06:22,139 --> 00:06:24,419
we're asking someone to give up their

195
00:06:24,419 --> 00:06:26,100
time to participate in a threat modeling

196
00:06:26,100 --> 00:06:27,539
Workshop we're asking the architect to

197
00:06:27,539 --> 00:06:29,160
give up their time to analyze

198
00:06:29,160 --> 00:06:30,840
information prior to the threat modeling

199
00:06:30,840 --> 00:06:32,759
Workshop that information that's going

200
00:06:32,759 --> 00:06:34,860
to be analyzed was someone had to put

201
00:06:34,860 --> 00:06:35,819
all of that together from the

202
00:06:35,819 --> 00:06:38,039
application side prior to that and

203
00:06:38,039 --> 00:06:39,600
during this art modeling Workshop itself

204
00:06:39,600 --> 00:06:41,880
we often take anywhere from half a day

205
00:06:41,880 --> 00:06:44,880
to a full day that's a lot of time to

206
00:06:44,880 --> 00:06:46,440
take away from other tasks that you

207
00:06:46,440 --> 00:06:47,699
might be involved in especially if

208
00:06:47,699 --> 00:06:49,199
you're a developer who has other tickets

209
00:06:49,199 --> 00:06:51,479
to fill the other main challenge is

210
00:06:51,479 --> 00:06:52,979
resource constraints

211
00:06:52,979 --> 00:06:55,500
within any given company you may only

212
00:06:55,500 --> 00:06:57,960
have one two three n

213
00:06:57,960 --> 00:06:59,819
thorough threat modeling Architects that

214
00:06:59,819 --> 00:07:01,259
know how to conduct a thorough threat

215
00:07:01,259 --> 00:07:02,039
model

216
00:07:02,039 --> 00:07:03,599
there are only ever going to be so many

217
00:07:03,599 --> 00:07:05,220
people who are skilled in one particular

218
00:07:05,220 --> 00:07:06,900
task and we need to make sure that we're

219
00:07:06,900 --> 00:07:08,639
able to roll out threat modeling at

220
00:07:08,639 --> 00:07:10,740
scale but if we don't have a number the

221
00:07:10,740 --> 00:07:11,880
the right number of fat modeling

222
00:07:11,880 --> 00:07:13,680
Architects to perform all of the threat

223
00:07:13,680 --> 00:07:14,819
models that are needed in our

224
00:07:14,819 --> 00:07:16,940
organization then that's going to fail

225
00:07:16,940 --> 00:07:20,340
so how can we actually help mitigate

226
00:07:20,340 --> 00:07:22,440
some of these issues that's where we

227
00:07:22,440 --> 00:07:24,120
think machine assisted dot modeling

228
00:07:24,120 --> 00:07:26,639
might come into play machine assisted is

229
00:07:26,639 --> 00:07:28,500
not the same as automated we're not

230
00:07:28,500 --> 00:07:30,180
saying that we want a robot or a

231
00:07:30,180 --> 00:07:31,919
computer to take the place of the threat

232
00:07:31,919 --> 00:07:33,960
modeling architect rather we want the

233
00:07:33,960 --> 00:07:35,759
machine to assist the third modeling

234
00:07:35,759 --> 00:07:38,099
Architects so imagine you hand an input

235
00:07:38,099 --> 00:07:40,139
that has a description of your system to

236
00:07:40,139 --> 00:07:42,360
be threat modeled to the computer the

237
00:07:42,360 --> 00:07:43,919
computer takes a look at that input and

238
00:07:43,919 --> 00:07:45,840
parses it and comes up with a list of

239
00:07:45,840 --> 00:07:48,180
threats that it believes to be present a

240
00:07:48,180 --> 00:07:50,460
suggested list of threats that suggested

241
00:07:50,460 --> 00:07:52,319
list of threats is then passed over to

242
00:07:52,319 --> 00:07:54,240
the threat modeling architect who can

243
00:07:54,240 --> 00:07:56,280
use that as a guideline to try and focus

244
00:07:56,280 --> 00:07:58,199
their conversation during the threat

245
00:07:58,199 --> 00:08:00,539
modeling Workshop so once again we're

246
00:08:00,539 --> 00:08:01,919
not taking away the agency of the

247
00:08:01,919 --> 00:08:03,660
thought modeling architect but we're

248
00:08:03,660 --> 00:08:05,580
helping hoping to help save them time

249
00:08:05,580 --> 00:08:07,379
they might see that there's a common

250
00:08:07,379 --> 00:08:09,539
threat that they hadn't really thought

251
00:08:09,539 --> 00:08:11,099
of or they might see that there's a

252
00:08:11,099 --> 00:08:12,840
threat that the they believe the machine

253
00:08:12,840 --> 00:08:14,699
should have missed and they said oh this

254
00:08:14,699 --> 00:08:16,379
is a Common Thread in this domain I

255
00:08:16,379 --> 00:08:18,000
wonder why it's not here maybe it's not

256
00:08:18,000 --> 00:08:19,800
actually present I should dig into that

257
00:08:19,800 --> 00:08:22,319
more during the workshop so the machine

258
00:08:22,319 --> 00:08:24,300
is meant to guide the threat modeling

259
00:08:24,300 --> 00:08:26,280
threat modeling architects

260
00:08:26,280 --> 00:08:28,199
but the question then becomes if we need

261
00:08:28,199 --> 00:08:29,759
a tool to help us with machine assisted

262
00:08:29,759 --> 00:08:32,279
threat modeling how do we pick a tool

263
00:08:32,279 --> 00:08:34,200
this is where we really dove into some

264
00:08:34,200 --> 00:08:36,179
research here we put together a list of

265
00:08:36,179 --> 00:08:38,219
inclusion criteria for our tools we

266
00:08:38,219 --> 00:08:39,719
first said that the tool had to be open

267
00:08:39,719 --> 00:08:41,820
source it had to be able to produce a

268
00:08:41,820 --> 00:08:44,099
threat report the repo for the tool had

269
00:08:44,099 --> 00:08:46,560
to consist of or had to contain commits

270
00:08:46,560 --> 00:08:48,180
from less than or equal to a year ago

271
00:08:48,180 --> 00:08:50,220
and finally the tool should be able to

272
00:08:50,220 --> 00:08:52,800
be applied to any type of system with

273
00:08:52,800 --> 00:08:54,660
these criteria in mind we then began to

274
00:08:54,660 --> 00:08:56,459
conduct some simple internet searches

275
00:08:56,459 --> 00:08:58,680
and we used just keywords like machine

276
00:08:58,680 --> 00:09:00,660
assisted threat modeling tools or threat

277
00:09:00,660 --> 00:09:03,180
modeling tools with this in mind we then

278
00:09:03,180 --> 00:09:05,700
transitioned to defining some evaluation

279
00:09:05,700 --> 00:09:07,920
criteria so once we had a list of tools

280
00:09:07,920 --> 00:09:09,600
we wanted to be able to compare them to

281
00:09:09,600 --> 00:09:10,920
one another by looking at certain

282
00:09:10,920 --> 00:09:13,080
factors the factors that we chose to

283
00:09:13,080 --> 00:09:15,720
evaluate are as follows the first is

284
00:09:15,720 --> 00:09:18,120
complexity of logic so how nuanced is

285
00:09:18,120 --> 00:09:19,800
the logic that we can use to detect

286
00:09:19,800 --> 00:09:22,440
whether or not a threat is present

287
00:09:22,440 --> 00:09:25,200
does the system say I see component a

288
00:09:25,200 --> 00:09:27,899
connected to component B by protocol C

289
00:09:27,899 --> 00:09:30,540
so automatically there's a threat or

290
00:09:30,540 --> 00:09:32,820
does the system say I see components A

291
00:09:32,820 --> 00:09:35,399
and B connected by protocol C but I also

292
00:09:35,399 --> 00:09:37,560
see that protection D is in place so

293
00:09:37,560 --> 00:09:39,660
therefore I know there's no threat so

294
00:09:39,660 --> 00:09:41,700
can we make those more complex decisions

295
00:09:41,700 --> 00:09:43,740
using this tool that's one of the main

296
00:09:43,740 --> 00:09:45,600
factors that we wanted to consider

297
00:09:45,600 --> 00:09:48,600
next was amen ability to custom threats

298
00:09:48,600 --> 00:09:50,459
every tool is going to natively support

299
00:09:50,459 --> 00:09:53,100
some number of threats and some type and

300
00:09:53,100 --> 00:09:55,620
scope of threats but what if they're if

301
00:09:55,620 --> 00:09:57,899
we want to apply that tool but there are

302
00:09:57,899 --> 00:09:59,940
threats that exist outside of that

303
00:09:59,940 --> 00:10:02,100
native library that we want to consider

304
00:10:02,100 --> 00:10:03,839
what if our application domain doesn't

305
00:10:03,839 --> 00:10:05,579
necessarily line up exactly with the

306
00:10:05,579 --> 00:10:07,200
domain of the threats covered by a

307
00:10:07,200 --> 00:10:10,079
particular tool can we write logic in or

308
00:10:10,079 --> 00:10:12,839
can we use a UI somehow to introduce our

309
00:10:12,839 --> 00:10:15,120
own threats to be detected by the tool

310
00:10:15,120 --> 00:10:17,940
third was operational usability here we

311
00:10:17,940 --> 00:10:19,800
turn from the tool itself to the use of

312
00:10:19,800 --> 00:10:21,839
the tool for anyone who's going to be

313
00:10:21,839 --> 00:10:23,040
interacting with the tool whether

314
00:10:23,040 --> 00:10:25,140
they're providing input or processing

315
00:10:25,140 --> 00:10:27,540
and receiving output how difficult is it

316
00:10:27,540 --> 00:10:29,100
for them to get onboarded to the tool

317
00:10:29,100 --> 00:10:30,600
how difficult is it for them to use it

318
00:10:30,600 --> 00:10:32,700
on a daily basis if the difficulty

319
00:10:32,700 --> 00:10:34,920
outweighs the the results the value of

320
00:10:34,920 --> 00:10:36,240
the results that the tool is producing

321
00:10:36,240 --> 00:10:37,860
then we didn't really solve any problems

322
00:10:37,860 --> 00:10:39,180
in the first place

323
00:10:39,180 --> 00:10:42,420
next is security functionality so can we

324
00:10:42,420 --> 00:10:44,220
successfully detect security threats

325
00:10:44,220 --> 00:10:46,200
using this tool and if we can are we

326
00:10:46,200 --> 00:10:48,180
able to classify them as needed using

327
00:10:48,180 --> 00:10:50,040
any given framework and finally

328
00:10:50,040 --> 00:10:52,260
extensibility for privacy

329
00:10:52,260 --> 00:10:54,240
threat modeling is traditionally focused

330
00:10:54,240 --> 00:10:56,459
on security it's only up and coming now

331
00:10:56,459 --> 00:10:58,680
in the world of privacy so a number of

332
00:10:58,680 --> 00:11:00,660
tools don't necessarily include privacy

333
00:11:00,660 --> 00:11:02,160
threats natively in their threat

334
00:11:02,160 --> 00:11:04,320
libraries so do we have the capability

335
00:11:04,320 --> 00:11:06,839
to introduce detection of privacy

336
00:11:06,839 --> 00:11:08,579
threats or is there actually needed

337
00:11:08,579 --> 00:11:10,140
support of it if if that does occur

338
00:11:10,140 --> 00:11:12,360
somewhere in any given tool so really do

339
00:11:12,360 --> 00:11:14,040
we have the capability to ensure that

340
00:11:14,040 --> 00:11:16,019
privacy threats can be detected in some

341
00:11:16,019 --> 00:11:16,740
way

342
00:11:16,740 --> 00:11:19,140
with these evaluation criteria we then

343
00:11:19,140 --> 00:11:20,700
went ahead and compared each of the

344
00:11:20,700 --> 00:11:22,440
tools that we that we found when we did

345
00:11:22,440 --> 00:11:24,540
those internet searches before the six

346
00:11:24,540 --> 00:11:26,279
tools that we analyzed are listed up at

347
00:11:26,279 --> 00:11:27,899
the top of the screen and then the

348
00:11:27,899 --> 00:11:29,279
factors that we analyzed are listed

349
00:11:29,279 --> 00:11:30,480
along the side of the screen in this

350
00:11:30,480 --> 00:11:31,500
chart

351
00:11:31,500 --> 00:11:33,839
the numbers that you see here are the

352
00:11:33,839 --> 00:11:35,940
results that we found for our threat

353
00:11:35,940 --> 00:11:37,740
modeling use case this is not to say

354
00:11:37,740 --> 00:11:39,420
right that Keras with a score of

355
00:11:39,420 --> 00:11:41,100
negative four is the worst threat

356
00:11:41,100 --> 00:11:42,540
modeling tool and this is not to say

357
00:11:42,540 --> 00:11:44,459
that fragile with a score of positive

358
00:11:44,459 --> 00:11:47,339
four is the best threat modeling tool

359
00:11:47,339 --> 00:11:49,680
really the the best or worst threat

360
00:11:49,680 --> 00:11:52,019
modeling tool depends on your use case

361
00:11:52,019 --> 00:11:54,300
at your organization so there's no one

362
00:11:54,300 --> 00:11:56,399
best or Worse tool across the world or

363
00:11:56,399 --> 00:11:59,160
across the the planet etc etc

364
00:11:59,160 --> 00:12:00,660
so really what we want to understand

365
00:12:00,660 --> 00:12:02,940
here is the process that we took to get

366
00:12:02,940 --> 00:12:04,740
to this point right we we took those

367
00:12:04,740 --> 00:12:07,019
steps of defining inclusion criteria

368
00:12:07,019 --> 00:12:09,120
defining evaluation criteria and then we

369
00:12:09,120 --> 00:12:11,100
got to this point in time what we can

370
00:12:11,100 --> 00:12:12,600
discuss here and what is interesting

371
00:12:12,600 --> 00:12:14,579
here rather than a prescription about

372
00:12:14,579 --> 00:12:17,519
which tools are useful is which factors

373
00:12:17,519 --> 00:12:18,959
really became important when we were

374
00:12:18,959 --> 00:12:21,120
looking at privacy threats specifically

375
00:12:21,120 --> 00:12:24,120
one of these was complexity of logic a

376
00:12:24,120 --> 00:12:25,920
privacy threat doesn't always take the

377
00:12:25,920 --> 00:12:27,839
same shape as a traditional security

378
00:12:27,839 --> 00:12:30,300
threat security threats often manifest

379
00:12:30,300 --> 00:12:33,060
themselves as a hacker committing an act

380
00:12:33,060 --> 00:12:35,459
on a system right so there's a person

381
00:12:35,459 --> 00:12:38,339
doing something to a machine privacy

382
00:12:38,339 --> 00:12:40,320
threats don't always look like that

383
00:12:40,320 --> 00:12:42,660
sometimes a privacy threat is did the

384
00:12:42,660 --> 00:12:44,880
company provide the notice to the user

385
00:12:44,880 --> 00:12:46,920
that their data is going to be used or

386
00:12:46,920 --> 00:12:48,660
did the company give the user the

387
00:12:48,660 --> 00:12:50,579
opportunity to consent to their usage of

388
00:12:50,579 --> 00:12:52,740
data in a certain way so all of a sudden

389
00:12:52,740 --> 00:12:55,680
it's not necessarily so cut and dry we

390
00:12:55,680 --> 00:12:57,060
don't always have the same action

391
00:12:57,060 --> 00:12:59,279
happening to same type of system

392
00:12:59,279 --> 00:13:02,459
so are we able to detect more complex

393
00:13:02,459 --> 00:13:04,260
threats that don't necessarily take the

394
00:13:04,260 --> 00:13:06,300
shape of the traditional type of threats

395
00:13:06,300 --> 00:13:07,800
that threat modeling tools have looked

396
00:13:07,800 --> 00:13:09,600
at and then one of the other important

397
00:13:09,600 --> 00:13:11,700
factors that we found was amenability to

398
00:13:11,700 --> 00:13:14,160
custom threats as we said security

399
00:13:14,160 --> 00:13:15,899
threat modeling has been going on for

400
00:13:15,899 --> 00:13:18,240
years and years and years privacy threat

401
00:13:18,240 --> 00:13:20,700
modeling is new so if we don't have

402
00:13:20,700 --> 00:13:22,440
native support for privacy threats we

403
00:13:22,440 --> 00:13:24,120
need to be able to introduce our own

404
00:13:24,120 --> 00:13:26,639
privacy threats so that ability to

405
00:13:26,639 --> 00:13:28,440
introduce new threats was one of the key

406
00:13:28,440 --> 00:13:30,660
factors to making a tool useful or for a

407
00:13:30,660 --> 00:13:32,700
tool making itself useful for privacy

408
00:13:32,700 --> 00:13:34,860
threat modeling

409
00:13:34,860 --> 00:13:37,019
now if you want to conduct privacy

410
00:13:37,019 --> 00:13:38,279
thought modeling using any of these

411
00:13:38,279 --> 00:13:39,720
tools and even using those custom

412
00:13:39,720 --> 00:13:41,459
threats it's important to have a good

413
00:13:41,459 --> 00:13:42,959
understanding of what threats you're

414
00:13:42,959 --> 00:13:45,240
hoping to detect with the tool for us

415
00:13:45,240 --> 00:13:47,519
that took the shape or took the form of

416
00:13:47,519 --> 00:13:50,279
defining a privacy threat Library these

417
00:13:50,279 --> 00:13:51,779
are some of the sources that we refer to

418
00:13:51,779 --> 00:13:53,459
when we were hoping to shape that

419
00:13:53,459 --> 00:13:56,399
Library Lyndon go the oauth top 10 and

420
00:13:56,399 --> 00:13:58,860
legal and Regulatory let's talk a little

421
00:13:58,860 --> 00:14:00,839
bit about Lyndon go we've already talked

422
00:14:00,839 --> 00:14:02,880
about Linden Linden is a privacy thought

423
00:14:02,880 --> 00:14:04,560
modeling framework it identifies seven

424
00:14:04,560 --> 00:14:07,139
key privacy threat categories Lyndon go

425
00:14:07,139 --> 00:14:09,060
is a practical implementation of the

426
00:14:09,060 --> 00:14:11,459
Linden framework there's a Lyndon go

427
00:14:11,459 --> 00:14:13,320
deck of cards in which each of the

428
00:14:13,320 --> 00:14:15,720
categories is represented by a series of

429
00:14:15,720 --> 00:14:17,519
colored cards where each category is

430
00:14:17,519 --> 00:14:20,579
delineated by color and then within each

431
00:14:20,579 --> 00:14:23,399
category of cards we have one card for

432
00:14:23,399 --> 00:14:25,260
each of the types of common threats that

433
00:14:25,260 --> 00:14:27,959
falls within that category if we go

434
00:14:27,959 --> 00:14:29,880
through that deck of cards we're able to

435
00:14:29,880 --> 00:14:31,560
pick out which facts we believe to be

436
00:14:31,560 --> 00:14:33,300
relevant to our particular organization

437
00:14:33,300 --> 00:14:36,300
domain or even specific application so

438
00:14:36,300 --> 00:14:38,160
this is one good way of finding common

439
00:14:38,160 --> 00:14:39,660
privacy threats that you might want to

440
00:14:39,660 --> 00:14:41,160
include in your library

441
00:14:41,160 --> 00:14:43,260
another source of common privacy threats

442
00:14:43,260 --> 00:14:46,079
is the owas top 10. oasp is the open web

443
00:14:46,079 --> 00:14:48,180
application security project you might

444
00:14:48,180 --> 00:14:49,980
be familiar with their list of top 10

445
00:14:49,980 --> 00:14:52,079
security effects they also produce a

446
00:14:52,079 --> 00:14:53,760
list of top 10 privacy threats so this

447
00:14:53,760 --> 00:14:55,980
can be another good reference point of a

448
00:14:55,980 --> 00:14:58,019
sort of vetted and compiled list of

449
00:14:58,019 --> 00:14:59,760
common privacy threats that you might

450
00:14:59,760 --> 00:15:01,740
want to consider and then finally we

451
00:15:01,740 --> 00:15:03,899
have legal and Regulatory depending on

452
00:15:03,899 --> 00:15:05,639
your location there are different

453
00:15:05,639 --> 00:15:07,440
regulations that are going to apply so

454
00:15:07,440 --> 00:15:10,139
we might think of the CCPA the gdpr etc

455
00:15:10,139 --> 00:15:12,420
etc and these are important right each

456
00:15:12,420 --> 00:15:15,180
of these legal regulations puts forth

457
00:15:15,180 --> 00:15:17,579
certain customer or user rights that we

458
00:15:17,579 --> 00:15:19,079
need to take into account when handling

459
00:15:19,079 --> 00:15:21,300
user data so it's important to turn to

460
00:15:21,300 --> 00:15:23,399
these sources based on our location and

461
00:15:23,399 --> 00:15:25,320
identify what rights the user has that

462
00:15:25,320 --> 00:15:26,779
we need to ensure that we're actually

463
00:15:26,779 --> 00:15:29,639
validating and protecting in the in our

464
00:15:29,639 --> 00:15:32,279
use of their data in our application

465
00:15:32,279 --> 00:15:34,259
so finally now that we understand the

466
00:15:34,259 --> 00:15:36,540
process of looking at machine assisted

467
00:15:36,540 --> 00:15:37,860
threat modeling tools looking at where

468
00:15:37,860 --> 00:15:39,600
we can build how we can build a privacy

469
00:15:39,600 --> 00:15:41,519
throughout Library how can we actually

470
00:15:41,519 --> 00:15:44,100
see how this looks in real life let's

471
00:15:44,100 --> 00:15:46,259
take a look at a quick demo of turning a

472
00:15:46,259 --> 00:15:47,579
privacy threat from one of these Library

473
00:15:47,579 --> 00:15:50,040
sources into code for one of the tools

474
00:15:50,040 --> 00:15:52,139
that we looked at called fragile

475
00:15:52,139 --> 00:15:53,699
this is the process that we're going to

476
00:15:53,699 --> 00:15:55,500
follow first we're going to select a

477
00:15:55,500 --> 00:15:57,000
threat then we're going to translate

478
00:15:57,000 --> 00:15:59,040
that throughout into logic and finally

479
00:15:59,040 --> 00:16:02,519
we'll translate that logic into code

480
00:16:02,519 --> 00:16:04,440
starting with threat selection we're

481
00:16:04,440 --> 00:16:06,360
going to pull for example a threat from

482
00:16:06,360 --> 00:16:08,940
the oauth's top 10. this threat is

483
00:16:08,940 --> 00:16:10,940
called operator-sided Data leakage

484
00:16:10,940 --> 00:16:13,079
operator-sided data leakage is defined

485
00:16:13,079 --> 00:16:15,420
as the failure to prevent the leakage of

486
00:16:15,420 --> 00:16:17,220
any information containing or related to

487
00:16:17,220 --> 00:16:20,399
user data or the data itself to any

488
00:16:20,399 --> 00:16:22,380
unauthorized party resulting in loss of

489
00:16:22,380 --> 00:16:24,720
data confidentiality introduced either

490
00:16:24,720 --> 00:16:28,019
due to intentional malicious breach or

491
00:16:28,019 --> 00:16:30,420
unintentional mistake caused by

492
00:16:30,420 --> 00:16:32,399
insufficient access management controls

493
00:16:32,399 --> 00:16:35,880
insecure storage duplication of data or

494
00:16:35,880 --> 00:16:38,100
a lack of awareness what we're really

495
00:16:38,100 --> 00:16:40,139
concerned with here is that caused by

496
00:16:40,139 --> 00:16:41,160
clause

497
00:16:41,160 --> 00:16:43,500
those three first causes insufficient

498
00:16:43,500 --> 00:16:45,060
access management controls insecure

499
00:16:45,060 --> 00:16:47,279
storage and duplication of data are

500
00:16:47,279 --> 00:16:49,440
technical causes if we see any of those

501
00:16:49,440 --> 00:16:51,240
conditions manifesting themselves in a

502
00:16:51,240 --> 00:16:53,339
system we might want to raise a red flag

503
00:16:53,339 --> 00:16:55,259
and say hey threat modeling architect

504
00:16:55,259 --> 00:16:57,240
you should look out for operator cited

505
00:16:57,240 --> 00:16:59,339
data leakage unfortunately lack of

506
00:16:59,339 --> 00:17:01,079
awareness is a human condition that we

507
00:17:01,079 --> 00:17:03,120
probably can't account for in terms of

508
00:17:03,120 --> 00:17:05,280
just a technical system description but

509
00:17:05,280 --> 00:17:07,679
what we can do is turn this threat into

510
00:17:07,679 --> 00:17:09,179
logic now

511
00:17:09,179 --> 00:17:11,039
so we've created flow charts that

512
00:17:11,039 --> 00:17:12,780
represent each of those three causes

513
00:17:12,780 --> 00:17:14,839
insufficient access management controls

514
00:17:14,839 --> 00:17:18,240
insecure storage and data duplication

515
00:17:18,240 --> 00:17:19,859
I'm going to go ahead and walk through

516
00:17:19,859 --> 00:17:21,480
the flow chart for insecure storage for

517
00:17:21,480 --> 00:17:22,980
the sake of time because it's the

518
00:17:22,980 --> 00:17:25,079
shortest each of the circular nodes

519
00:17:25,079 --> 00:17:26,640
represent a starting or ending point

520
00:17:26,640 --> 00:17:28,740
each of the rectangular nodes represents

521
00:17:28,740 --> 00:17:31,080
an assignment or process and each of the

522
00:17:31,080 --> 00:17:33,480
diamond nodes represent a decision so we

523
00:17:33,480 --> 00:17:35,580
start out and we create this empty list

524
00:17:35,580 --> 00:17:37,620
of all technical assets inside trust

525
00:17:37,620 --> 00:17:39,600
boundaries where a trust boundary is

526
00:17:39,600 --> 00:17:41,400
some form of protection some form of

527
00:17:41,400 --> 00:17:43,559
authentication or authorization that

528
00:17:43,559 --> 00:17:46,320
sits around some Technical Resources so

529
00:17:46,320 --> 00:17:48,000
we've created an empty list and then we

530
00:17:48,000 --> 00:17:49,980
look at every single trust boundary in

531
00:17:49,980 --> 00:17:52,500
our system and we get a list of all the

532
00:17:52,500 --> 00:17:54,360
technical components that sit behind

533
00:17:54,360 --> 00:17:55,980
that trust boundary or that are

534
00:17:55,980 --> 00:17:58,679
protected by it so we get a list of all

535
00:17:58,679 --> 00:18:00,780
of the protected components and then we

536
00:18:00,780 --> 00:18:02,940
end up looking at are there more

537
00:18:02,940 --> 00:18:04,799
technical assets to process

538
00:18:04,799 --> 00:18:06,900
if there are then we want to keep going

539
00:18:06,900 --> 00:18:08,760
and we asked is the current technical

540
00:18:08,760 --> 00:18:11,460
asset in scope or is it a data store so

541
00:18:11,460 --> 00:18:12,960
do we care about this technical asset

542
00:18:12,960 --> 00:18:14,700
right now for the scope of this analysis

543
00:18:14,700 --> 00:18:17,100
and is it a data store

544
00:18:17,100 --> 00:18:19,440
if it is and if we do care about it then

545
00:18:19,440 --> 00:18:21,120
we keep processing if it's not then we

546
00:18:21,120 --> 00:18:23,220
we keep going but if it is of

547
00:18:23,220 --> 00:18:25,080
consideration if it is a data store to

548
00:18:25,080 --> 00:18:27,240
look at then we look at

549
00:18:27,240 --> 00:18:29,640
is this current technical asset inside

550
00:18:29,640 --> 00:18:31,860
the list of all technical assets inside

551
00:18:31,860 --> 00:18:33,960
trust boundaries so essentially what

552
00:18:33,960 --> 00:18:36,059
we're asking here is is this data store

553
00:18:36,059 --> 00:18:38,400
protected or is our storage completely

554
00:18:38,400 --> 00:18:41,039
insecure right so if the data store is

555
00:18:41,039 --> 00:18:42,720
protected then we jump back up to the

556
00:18:42,720 --> 00:18:44,220
top of the slow chart and we have no

557
00:18:44,220 --> 00:18:46,679
problem if it's not if we have an

558
00:18:46,679 --> 00:18:48,480
unprotected data store then we have

559
00:18:48,480 --> 00:18:50,460
insecure storage in our system so we

560
00:18:50,460 --> 00:18:52,620
create a new risk and then we do this

561
00:18:52,620 --> 00:18:54,419
for every single technical asset we keep

562
00:18:54,419 --> 00:18:56,460
looping until we finish all of them and

563
00:18:56,460 --> 00:18:58,500
then finally we return an array of risks

564
00:18:58,500 --> 00:19:00,480
so you can see here that we translated

565
00:19:00,480 --> 00:19:02,820
that that verbal description of a cause

566
00:19:02,820 --> 00:19:05,760
of this threat into logic what we can

567
00:19:05,760 --> 00:19:08,400
finally do is turn that into code so

568
00:19:08,400 --> 00:19:09,900
this is some go Lane code that can be

569
00:19:09,900 --> 00:19:11,940
used by fragile to detect whether

570
00:19:11,940 --> 00:19:14,280
insecure storage is present in a system

571
00:19:14,280 --> 00:19:16,740
first we create that empty list of all

572
00:19:16,740 --> 00:19:18,299
technical acids inside trust boundaries

573
00:19:18,299 --> 00:19:19,980
and then we populate it with all the

574
00:19:19,980 --> 00:19:21,660
technical assets that do sit behind

575
00:19:21,660 --> 00:19:24,360
trust boundaries then we parse through

576
00:19:24,360 --> 00:19:26,520
all of the technical assets we check if

577
00:19:26,520 --> 00:19:28,260
they're out of scope or not a data store

578
00:19:28,260 --> 00:19:30,480
if they are we just keep going we jump

579
00:19:30,480 --> 00:19:32,520
back up to the top of this for Loop

580
00:19:32,520 --> 00:19:35,400
however if not we keep going and we say

581
00:19:35,400 --> 00:19:38,220
if this technical asset is not sitting

582
00:19:38,220 --> 00:19:40,140
behind a trust boundary then we have a

583
00:19:40,140 --> 00:19:42,240
risk we go ahead and we create a risk

584
00:19:42,240 --> 00:19:44,039
and we append it to our list of risks

585
00:19:44,039 --> 00:19:46,799
and finally we return that risk so

586
00:19:46,799 --> 00:19:48,419
hopefully this demonstration has shown

587
00:19:48,419 --> 00:19:50,580
you just how easy it is to turn a threat

588
00:19:50,580 --> 00:19:52,679
a verbal description of a threat into

589
00:19:52,679 --> 00:19:54,480
actual code and use it for for

590
00:19:54,480 --> 00:19:56,520
processing and detecting a threat thank

591
00:19:56,520 --> 00:19:57,780
you so much for listening and I

592
00:19:57,780 --> 00:19:59,700
encourage you to ask questions and reach

593
00:19:59,700 --> 00:20:01,500
out to us if you have any any further

594
00:20:01,500 --> 00:20:02,760
questions or would like to discuss more

595
00:20:02,760 --> 00:20:05,900
have a great day

