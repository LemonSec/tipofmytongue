1
00:00:10,240 --> 00:00:11,920
great thank you so

2
00:00:11,920 --> 00:00:14,320
yeah so in this talk um i'd like to tell

3
00:00:14,320 --> 00:00:17,199
you about the tumult platform

4
00:00:17,199 --> 00:00:19,199
so it's a system for releasing safely

5
00:00:19,199 --> 00:00:20,880
releasing aggregate information from

6
00:00:20,880 --> 00:00:23,359
sensitive data sets

7
00:00:23,359 --> 00:00:26,560
and it supports a variety of a workflow

8
00:00:26,560 --> 00:00:27,840
where you know you can take a source

9
00:00:27,840 --> 00:00:29,760
data set and transform it in various

10
00:00:29,760 --> 00:00:30,480
ways

11
00:00:30,480 --> 00:00:31,920
before

12
00:00:31,920 --> 00:00:34,000
taking that data and aggregating it to

13
00:00:34,000 --> 00:00:36,640
statistics that are safe to release

14
00:00:36,640 --> 00:00:38,320
so the platform

15
00:00:38,320 --> 00:00:40,960
will soon be available open source

16
00:00:40,960 --> 00:00:42,239
and it's currently in use of several

17
00:00:42,239 --> 00:00:43,680
organizations

18
00:00:43,680 --> 00:00:45,520
in fact as you heard in the first couple

19
00:00:45,520 --> 00:00:48,000
of speakers today about the deployments

20
00:00:48,000 --> 00:00:51,360
at irs and wikimedia it's also in use at

21
00:00:51,360 --> 00:00:53,039
the u.s census bureau

22
00:00:53,039 --> 00:00:54,559
and there's a talk tomorrow that's going

23
00:00:54,559 --> 00:00:55,920
to talk about one of the census use

24
00:00:55,920 --> 00:00:58,559
cases

25
00:00:58,559 --> 00:01:01,359
so in building this system we had four

26
00:01:01,359 --> 00:01:03,600
primary design goals and so in today's

27
00:01:03,600 --> 00:01:05,280
talk i'd like to tell you about those

28
00:01:05,280 --> 00:01:06,320
goals

29
00:01:06,320 --> 00:01:08,000
and then explain how we built the system

30
00:01:08,000 --> 00:01:10,240
to achieve them

31
00:01:10,240 --> 00:01:12,479
so the first goal is about usability so

32
00:01:12,479 --> 00:01:14,720
we want any data scientist or engineer

33
00:01:14,720 --> 00:01:16,400
to be able to successfully use the

34
00:01:16,400 --> 00:01:20,080
platform to solve real-world problems

35
00:01:20,080 --> 00:01:22,000
no expert level math knowledge or

36
00:01:22,000 --> 00:01:24,320
in-depth understanding of dp theory

37
00:01:24,320 --> 00:01:26,560
should ever be required

38
00:01:26,560 --> 00:01:28,720
we want the platform to be easy to use

39
00:01:28,720 --> 00:01:31,200
by non-experts but at the same time we

40
00:01:31,200 --> 00:01:33,040
want to we want the platform to empower

41
00:01:33,040 --> 00:01:34,079
them to

42
00:01:34,079 --> 00:01:38,240
you know build complex privacy solutions

43
00:01:38,240 --> 00:01:40,479
so the second goal is about privacy um

44
00:01:40,479 --> 00:01:42,240
so we want an analyst to be confident

45
00:01:42,240 --> 00:01:43,600
that the aggregates computed by the

46
00:01:43,600 --> 00:01:46,079
system are safe to release share

47
00:01:46,079 --> 00:01:47,840
whatever

48
00:01:47,840 --> 00:01:49,759
and so the system offers this insurance

49
00:01:49,759 --> 00:01:51,600
by providing a provable guarantee of

50
00:01:51,600 --> 00:01:53,119
differential privacy

51
00:01:53,119 --> 00:01:54,399
so you've already heard about that in a

52
00:01:54,399 --> 00:01:55,600
few different talks but you know it's a

53
00:01:55,600 --> 00:01:57,840
rigorous model of privacy protection

54
00:01:57,840 --> 00:02:00,079
these days it also comes in many sort of

55
00:02:00,079 --> 00:02:01,200
variants with different

56
00:02:01,200 --> 00:02:03,439
parameterizations and so the system

57
00:02:03,439 --> 00:02:05,040
should allow the user to select the

58
00:02:05,040 --> 00:02:07,439
appropriate variant of dp and parameter

59
00:02:07,439 --> 00:02:09,038
settings that make sense for their use

60
00:02:09,038 --> 00:02:10,399
case

61
00:02:10,399 --> 00:02:12,239
some scope clarification so we're in the

62
00:02:12,239 --> 00:02:14,640
kind of central dp model

63
00:02:14,640 --> 00:02:16,640
with an analyst who is trusted to use

64
00:02:16,640 --> 00:02:19,040
the tools as intended so things like

65
00:02:19,040 --> 00:02:22,239
local dp or adversarial analysts are out

66
00:02:22,239 --> 00:02:25,599
of scope at least at the moment

67
00:02:25,599 --> 00:02:27,599
the third goal is that the platform be

68
00:02:27,599 --> 00:02:29,440
extensible and i want to emphasize this

69
00:02:29,440 --> 00:02:31,599
point um you know so it should be

70
00:02:31,599 --> 00:02:34,879
possible to add new transformations

71
00:02:34,879 --> 00:02:36,480
or aggregation functions and even

72
00:02:36,480 --> 00:02:39,040
variants of differential privacy without

73
00:02:39,040 --> 00:02:41,840
requiring deep refactorings of the code

74
00:02:41,840 --> 00:02:43,040
and we felt that this was really

75
00:02:43,040 --> 00:02:44,319
important because we're really trying to

76
00:02:44,319 --> 00:02:46,959
build this platform with growth in mind

77
00:02:46,959 --> 00:02:48,720
and the users that we've worked with so

78
00:02:48,720 --> 00:02:50,160
far have actually surprised us with

79
00:02:50,160 --> 00:02:52,560
requests for features that sit right at

80
00:02:52,560 --> 00:02:55,040
the kind of frontier of dp research and

81
00:02:55,040 --> 00:02:56,400
of course that frontier is also

82
00:02:56,400 --> 00:02:59,040
expanding and so we want to be able to

83
00:02:59,040 --> 00:03:00,959
add to the platform you know new

84
00:03:00,959 --> 00:03:02,400
mechanisms that are developed in

85
00:03:02,400 --> 00:03:03,920
literature and new methods of privacy

86
00:03:03,920 --> 00:03:05,519
accounting you know as soon as they're

87
00:03:05,519 --> 00:03:07,680
developed

88
00:03:07,680 --> 00:03:09,200
and the final goal is about performance

89
00:03:09,200 --> 00:03:11,040
so we want the we designed the platform

90
00:03:11,040 --> 00:03:13,360
to scale to large inputs

91
00:03:13,360 --> 00:03:15,120
you know the computation needed for dp

92
00:03:15,120 --> 00:03:17,040
may introduce some overhead but we aim

93
00:03:17,040 --> 00:03:18,560
to have performance that's sort of on

94
00:03:18,560 --> 00:03:20,319
the same order of magnitude as what you

95
00:03:20,319 --> 00:03:22,560
might get if executing computations

96
00:03:22,560 --> 00:03:24,560
without the dp part you know say on

97
00:03:24,560 --> 00:03:26,000
spark

98
00:03:26,000 --> 00:03:27,840
so those are our design goals um i'll

99
00:03:27,840 --> 00:03:30,400
now talk about how we achieve them

100
00:03:30,400 --> 00:03:33,280
so our platform is composed of layers

101
00:03:33,280 --> 00:03:34,879
and with each layer focusing on a

102
00:03:34,879 --> 00:03:38,000
different subset of the design goals

103
00:03:38,000 --> 00:03:40,480
so the topmost layer is analytics which

104
00:03:40,480 --> 00:03:44,640
offers an easy to use but powerful api

105
00:03:44,799 --> 00:03:46,799
so analytics is intended for data

106
00:03:46,799 --> 00:03:48,640
scientists they don't need to be experts

107
00:03:48,640 --> 00:03:50,640
in dp and we hope that the python

108
00:03:50,640 --> 00:03:52,879
interface uh will be

109
00:03:52,879 --> 00:03:55,280
feel familiar to users of say pandas or

110
00:03:55,280 --> 00:03:56,239
spark

111
00:03:56,239 --> 00:03:58,400
because it has similar functionality

112
00:03:58,400 --> 00:04:00,159
and a similar programming style i'd like

113
00:04:00,159 --> 00:04:03,439
to show just a brief code snippet here

114
00:04:03,439 --> 00:04:06,000
so to use it um the analyst the data

115
00:04:06,000 --> 00:04:07,519
scientist first creates a session where

116
00:04:07,519 --> 00:04:08,959
all interactions with the data are

117
00:04:08,959 --> 00:04:10,959
guaranteed to be differentially private

118
00:04:10,959 --> 00:04:12,560
and not to exceed the privacy budget

119
00:04:12,560 --> 00:04:14,720
specified by the user

120
00:04:14,720 --> 00:04:16,320
the user can then write a query on this

121
00:04:16,320 --> 00:04:18,478
private source so this particular query

122
00:04:18,478 --> 00:04:20,320
filters the records to keep only

123
00:04:20,320 --> 00:04:22,800
individuals older than 42 groups the

124
00:04:22,800 --> 00:04:24,880
data by zip codes and computes a median

125
00:04:24,880 --> 00:04:27,280
for each zip code

126
00:04:27,280 --> 00:04:28,960
the query is evaluated by a dp

127
00:04:28,960 --> 00:04:30,479
computation engine

128
00:04:30,479 --> 00:04:33,440
using the user specified privacy budget

129
00:04:33,440 --> 00:04:35,360
and then the cumulative privacy loss is

130
00:04:35,360 --> 00:04:37,600
tracked by the session and the user the

131
00:04:37,600 --> 00:04:39,440
analyst can query at any time to find

132
00:04:39,440 --> 00:04:41,040
out how much budget is remaining in the

133
00:04:41,040 --> 00:04:43,840
session

134
00:04:44,000 --> 00:04:45,600
so that was a simple example of course

135
00:04:45,600 --> 00:04:47,280
real world use cases are often more

136
00:04:47,280 --> 00:04:49,520
complex and our platform has evolved

137
00:04:49,520 --> 00:04:51,120
rapidly to support the needs of our

138
00:04:51,120 --> 00:04:53,680
users so i can kind of categorize those

139
00:04:53,680 --> 00:04:56,240
needs into three broad themes

140
00:04:56,240 --> 00:04:58,000
so first you know users want to add the

141
00:04:58,000 --> 00:05:00,000
minimal amount of noise to

142
00:05:00,000 --> 00:05:02,720
ensure privacy and to minimize the noise

143
00:05:02,720 --> 00:05:04,960
you often have to do careful privacy

144
00:05:04,960 --> 00:05:06,560
accounting behind the scenes and so

145
00:05:06,560 --> 00:05:08,840
we've added some features to support

146
00:05:08,840 --> 00:05:12,080
that another aspect is data adaptivity

147
00:05:12,080 --> 00:05:14,080
so users often want the granularity of

148
00:05:14,080 --> 00:05:15,759
the statistics to be as detailed as

149
00:05:15,759 --> 00:05:18,000
possible but of course dp actually

150
00:05:18,000 --> 00:05:19,600
prevents you from publishing detailed

151
00:05:19,600 --> 00:05:21,360
statistics about small groups of people

152
00:05:21,360 --> 00:05:24,000
that's by design for privacy protection

153
00:05:24,000 --> 00:05:25,919
so data adaptive workflows the idea

154
00:05:25,919 --> 00:05:27,520
behind them is to sort of drill down in

155
00:05:27,520 --> 00:05:30,080
dense regions of the data but in areas

156
00:05:30,080 --> 00:05:31,520
that are sparse though there aren't many

157
00:05:31,520 --> 00:05:33,680
records maybe instead publish

158
00:05:33,680 --> 00:05:36,720
course or summary statistics

159
00:05:36,720 --> 00:05:39,680
and finally users want to perform data

160
00:05:39,680 --> 00:05:42,160
transformations that are complex in

161
00:05:42,160 --> 00:05:44,400
terms of the kind of privacy calculus

162
00:05:44,400 --> 00:05:47,199
needed to support them so just as an

163
00:05:47,199 --> 00:05:49,680
example you know a flat map takes a

164
00:05:49,680 --> 00:05:51,280
private one single private row and

165
00:05:51,280 --> 00:05:53,440
explodes it into multiple rows and so

166
00:05:53,440 --> 00:05:55,360
the system must somehow track this kind

167
00:05:55,360 --> 00:05:57,919
of explosion of private data in order to

168
00:05:57,919 --> 00:06:00,960
add the appropriate amount of noise

169
00:06:00,960 --> 00:06:03,199
so all the features shown on the on the

170
00:06:03,199 --> 00:06:05,199
right there have been added to analytics

171
00:06:05,199 --> 00:06:06,720
and one of the greatest challenges we've

172
00:06:06,720 --> 00:06:08,080
faced is how to incorporate all these

173
00:06:08,080 --> 00:06:10,319
sophisticated features and get them to

174
00:06:10,319 --> 00:06:12,560
kind of interoperate effectively

175
00:06:12,560 --> 00:06:14,240
and so to respond to this challenge we

176
00:06:14,240 --> 00:06:16,720
created tumult core

177
00:06:16,720 --> 00:06:18,479
so tumult core is the privacy framework

178
00:06:18,479 --> 00:06:20,800
that powers analytics it's designed to

179
00:06:20,800 --> 00:06:23,039
be to provide provable privacy

180
00:06:23,039 --> 00:06:26,800
guarantees and be easily extended

181
00:06:27,360 --> 00:06:29,600
so tumult core is so i'd like to tell

182
00:06:29,600 --> 00:06:31,360
you a little about tumblecore so it's a

183
00:06:31,360 --> 00:06:33,520
collection of composable components for

184
00:06:33,520 --> 00:06:35,680
implementing dp algorithms

185
00:06:35,680 --> 00:06:38,000
consists of transformations

186
00:06:38,000 --> 00:06:39,360
and measurements which you can think of

187
00:06:39,360 --> 00:06:41,440
as like you know basic dp

188
00:06:41,440 --> 00:06:44,960
mechanisms like the laplace mechanism

189
00:06:44,960 --> 00:06:47,280
each component explicitly encodes its

190
00:06:47,280 --> 00:06:49,039
privacy properties and i won't get into

191
00:06:49,039 --> 00:06:50,880
the details of what those properties are

192
00:06:50,880 --> 00:06:52,639
but really the point is that

193
00:06:52,639 --> 00:06:54,880
these properties are declared

194
00:06:54,880 --> 00:06:56,000
and then they're available for

195
00:06:56,000 --> 00:06:58,160
inspection say by a user or by other

196
00:06:58,160 --> 00:07:00,960
system components

197
00:07:00,960 --> 00:07:02,720
but really the power of core actually

198
00:07:02,720 --> 00:07:04,240
lies in its ability to combine these

199
00:07:04,240 --> 00:07:05,759
base components

200
00:07:05,759 --> 00:07:08,160
into more complex algorithms so think

201
00:07:08,160 --> 00:07:09,840
combinators like chaining and

202
00:07:09,840 --> 00:07:11,680
composition and others

203
00:07:11,680 --> 00:07:13,199
make it possible to derive new

204
00:07:13,199 --> 00:07:14,560
measurements and transformations from

205
00:07:14,560 --> 00:07:16,800
these base components

206
00:07:16,800 --> 00:07:20,000
and crucially the privacy properties of

207
00:07:20,000 --> 00:07:21,520
the new component is derived

208
00:07:21,520 --> 00:07:22,960
automatically

209
00:07:22,960 --> 00:07:24,639
from the properties of the components

210
00:07:24,639 --> 00:07:27,440
that are being combined

211
00:07:27,440 --> 00:07:29,440
one kind of final remark about sort of

212
00:07:29,440 --> 00:07:31,199
about core is that

213
00:07:31,199 --> 00:07:32,720
you know this is the like privacy

214
00:07:32,720 --> 00:07:34,800
critical code uh it's the really

215
00:07:34,800 --> 00:07:36,560
critical pieces and it's important to

216
00:07:36,560 --> 00:07:38,720
implement them carefully and scrutinize

217
00:07:38,720 --> 00:07:40,160
for potential bugs and that's one of the

218
00:07:40,160 --> 00:07:41,840
motivations for making this code open

219
00:07:41,840 --> 00:07:44,400
sources so that we can get many eyes

220
00:07:44,400 --> 00:07:46,080
looking at the code

221
00:07:46,080 --> 00:07:47,520
so i just mentioned that we have a paper

222
00:07:47,520 --> 00:07:49,680
at tpdp this year a differential privacy

223
00:07:49,680 --> 00:07:52,319
workshop describing our approach uh to

224
00:07:52,319 --> 00:07:53,919
handling floating point vulnerabilities

225
00:07:53,919 --> 00:07:56,160
which have vexed the dp community for

226
00:07:56,160 --> 00:07:57,440
quite a while

227
00:07:57,440 --> 00:07:59,360
and you know and this can help

228
00:07:59,360 --> 00:08:01,199
make safe versions of things like the

229
00:08:01,199 --> 00:08:04,080
laplace mechanism

230
00:08:04,400 --> 00:08:06,960
so that's core so it enables

231
00:08:06,960 --> 00:08:08,560
the creation of complex algorithms from

232
00:08:08,560 --> 00:08:10,879
basic building blocks

233
00:08:10,879 --> 00:08:12,560
everything in core and everything you

234
00:08:12,560 --> 00:08:14,400
can build with core comes with an

235
00:08:14,400 --> 00:08:16,800
explicit inspectable privacy guarantee

236
00:08:16,800 --> 00:08:18,879
and its modular architecture is highly

237
00:08:18,879 --> 00:08:20,319
extensible

238
00:08:20,319 --> 00:08:21,919
of course all this actually makes core

239
00:08:21,919 --> 00:08:23,919
pretty difficult to use on its own uh

240
00:08:23,919 --> 00:08:25,360
you know these explicitly encoded

241
00:08:25,360 --> 00:08:27,599
privacy properties

242
00:08:27,599 --> 00:08:28,879
it kind of only makes sense if you have

243
00:08:28,879 --> 00:08:31,280
a background in dp and this emphasis on

244
00:08:31,280 --> 00:08:33,440
kind of modularity and extensibility

245
00:08:33,440 --> 00:08:34,719
means that a lot of the components are

246
00:08:34,719 --> 00:08:36,479
fairly abstract and kind of awkward to

247
00:08:36,479 --> 00:08:38,320
use

248
00:08:38,320 --> 00:08:40,159
but in the analytics layer takes this

249
00:08:40,159 --> 00:08:42,799
functionality and kind of packages it uh

250
00:08:42,799 --> 00:08:45,680
to support common workflows that we see

251
00:08:45,680 --> 00:08:47,680
and and make it more usable

252
00:08:47,680 --> 00:08:49,600
so anal the analytics layer provides

253
00:08:49,600 --> 00:08:51,600
usability the core layer gets us

254
00:08:51,600 --> 00:08:54,399
provable privacy and extensibility and

255
00:08:54,399 --> 00:08:56,800
to achieve scalability the platform is

256
00:08:56,800 --> 00:08:59,839
integrated with spark

257
00:08:59,839 --> 00:09:02,480
and so i'll skip the kind of details of

258
00:09:02,480 --> 00:09:04,000
our scalability experiments but i'll

259
00:09:04,000 --> 00:09:06,000
just say that we can take complex

260
00:09:06,000 --> 00:09:08,399
iterative algorithms and scale them to

261
00:09:08,399 --> 00:09:10,160
inputs of say you know up to a billion

262
00:09:10,160 --> 00:09:12,320
rows and the runtime seems to scale

263
00:09:12,320 --> 00:09:14,320
linearly with the input size on a fixed

264
00:09:14,320 --> 00:09:16,800
cluster

265
00:09:17,760 --> 00:09:20,480
so that was a brief overview of the

266
00:09:20,480 --> 00:09:22,560
platform we think that the tumult

267
00:09:22,560 --> 00:09:24,000
platform is

268
00:09:24,000 --> 00:09:26,080
really i think the only dp platform out

269
00:09:26,080 --> 00:09:27,519
there that provides this particular

270
00:09:27,519 --> 00:09:29,680
combination of usability extensibility

271
00:09:29,680 --> 00:09:31,519
and scalability

272
00:09:31,519 --> 00:09:33,200
and we hope that a data scientist

273
00:09:33,200 --> 00:09:35,519
without dp expertise can confidently use

274
00:09:35,519 --> 00:09:36,560
the platform

275
00:09:36,560 --> 00:09:37,839
to compute differentially private

276
00:09:37,839 --> 00:09:40,000
statistics and that confidence comes

277
00:09:40,000 --> 00:09:41,600
from the kind of explicit privacy

278
00:09:41,600 --> 00:09:43,920
guarantees of core that are encapsulated

279
00:09:43,920 --> 00:09:45,279
in this kind of end-to-end privacy

280
00:09:45,279 --> 00:09:47,519
guarantee explicit in the session

281
00:09:47,519 --> 00:09:48,959
interface

282
00:09:48,959 --> 00:09:50,640
and the fact that the code will soon be

283
00:09:50,640 --> 00:09:52,480
available open source

284
00:09:52,480 --> 00:09:54,080
so actually brings me to my last point

285
00:09:54,080 --> 00:09:55,040
so

286
00:09:55,040 --> 00:09:57,200
if you're wondering um you know how soon

287
00:09:57,200 --> 00:09:59,200
you can get access to it and try it out

288
00:09:59,200 --> 00:10:01,440
i have some some good news so

289
00:10:01,440 --> 00:10:03,040
we're super excited to announce that

290
00:10:03,040 --> 00:10:05,920
we've released it open source so

291
00:10:05,920 --> 00:10:07,440
we pushed actually really hard to get

292
00:10:07,440 --> 00:10:08,880
this out in time for pepper because we

293
00:10:08,880 --> 00:10:10,320
think this is a you know great community

294
00:10:10,320 --> 00:10:12,000
to kind of share this code with and

295
00:10:12,000 --> 00:10:14,000
hopefully gather your feedback

296
00:10:14,000 --> 00:10:15,600
so we'd really love to hear from you you

297
00:10:15,600 --> 00:10:17,360
know if you're interested

298
00:10:17,360 --> 00:10:18,800
there are links here but we'll post some

299
00:10:18,800 --> 00:10:20,480
links in the pepper channel

300
00:10:20,480 --> 00:10:22,480
pepper slack channel as well so thank

301
00:10:22,480 --> 00:10:25,480
you

