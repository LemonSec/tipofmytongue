1
00:00:09,840 --> 00:00:12,320
hello i'm sebastian dental i'm

2
00:00:12,320 --> 00:00:14,719
presenting work with rachel cummings on

3
00:00:14,719 --> 00:00:17,279
integrated differential privacy and

4
00:00:17,279 --> 00:00:20,400
contextual integrity

5
00:00:21,039 --> 00:00:23,039
differential privacy as you

6
00:00:23,039 --> 00:00:25,439
likely know is an algorithmic privacy

7
00:00:25,439 --> 00:00:27,680
notion for databases it balance the

8
00:00:27,680 --> 00:00:29,760
impact of any one data entry on the

9
00:00:29,760 --> 00:00:31,920
result of analysis of the database and

10
00:00:31,920 --> 00:00:34,320
it has these parameters infamous

11
00:00:34,320 --> 00:00:36,559
parameters epsilon and delta that

12
00:00:36,559 --> 00:00:38,320
encapsulate the trade-offs between

13
00:00:38,320 --> 00:00:40,559
privacy and accuracy

14
00:00:40,559 --> 00:00:42,480
but the problem is that the theory of

15
00:00:42,480 --> 00:00:44,160
differential privacy provides no

16
00:00:44,160 --> 00:00:46,160
guidance about the choice of those

17
00:00:46,160 --> 00:00:48,320
parameters and that's emblematic of the

18
00:00:48,320 --> 00:00:50,239
state of privacy enhancing technologies

19
00:00:50,239 --> 00:00:52,239
more generally we've got great theory

20
00:00:52,239 --> 00:00:55,919
but what do we do in practice

21
00:00:56,239 --> 00:00:58,879
we're introducing into this world

22
00:00:58,879 --> 00:01:00,800
contextual integrity

23
00:01:00,800 --> 00:01:03,680
which is a social theory of privacy uh

24
00:01:03,680 --> 00:01:06,080
developed by helen missenbaum helen

25
00:01:06,080 --> 00:01:08,479
nissenbaum is a social theorist a

26
00:01:08,479 --> 00:01:11,119
philosopher something of a sociologist

27
00:01:11,119 --> 00:01:13,520
and she's not trying to capture a

28
00:01:13,520 --> 00:01:15,520
technical definition of privacy or

29
00:01:15,520 --> 00:01:17,520
compliance or any deposition of privacy

30
00:01:17,520 --> 00:01:20,000
though she is certainly influenced by

31
00:01:20,000 --> 00:01:23,360
legal scholarship rather she's uh

32
00:01:23,360 --> 00:01:26,759
looking at

33
00:01:27,200 --> 00:01:29,360
a social definition of privacy what do

34
00:01:29,360 --> 00:01:32,000
people really want from it

35
00:01:32,000 --> 00:01:34,079
and her theory is that privacy is about

36
00:01:34,079 --> 00:01:36,479
appropriate information flow

37
00:01:36,479 --> 00:01:38,960
where that means both the flow of

38
00:01:38,960 --> 00:01:41,280
information that we want

39
00:01:41,280 --> 00:01:43,360
to be known by certain actors for

40
00:01:43,360 --> 00:01:45,520
certain purposes about ourselves and

41
00:01:45,520 --> 00:01:47,280
also the prevention of inappropriate

42
00:01:47,280 --> 00:01:48,399
flow

43
00:01:48,399 --> 00:01:50,640
where appropriateness is defined in

44
00:01:50,640 --> 00:01:53,439
terms of information forms that adhere

45
00:01:53,439 --> 00:01:56,719
in a particular social context so

46
00:01:56,719 --> 00:01:59,360
a social context like health care or

47
00:01:59,360 --> 00:02:02,079
education or financial services these

48
00:02:02,079 --> 00:02:04,320
are what ground our social expectations

49
00:02:04,320 --> 00:02:07,398
of privacy

50
00:02:08,239 --> 00:02:11,520
and those expectations manifest in norms

51
00:02:11,520 --> 00:02:13,280
which according to the theory are

52
00:02:13,280 --> 00:02:15,520
parameterized in terms of a sender a

53
00:02:15,520 --> 00:02:19,680
receiver a subject a sensitive

54
00:02:19,680 --> 00:02:20,959
attribute

55
00:02:20,959 --> 00:02:22,560
about the subject

56
00:02:22,560 --> 00:02:25,200
and a transmission principle

57
00:02:25,200 --> 00:02:26,959
which is the hardest bit to understand

58
00:02:26,959 --> 00:02:28,480
about contextual integrity but it's

59
00:02:28,480 --> 00:02:30,800
something like an ethical rule

60
00:02:30,800 --> 00:02:32,800
governing that particular flow so for

61
00:02:32,800 --> 00:02:36,239
example a radiologist may send x-rays of

62
00:02:36,239 --> 00:02:38,800
a patient to a general doctor

63
00:02:38,800 --> 00:02:41,840
under conditions of confidentiality

64
00:02:41,840 --> 00:02:44,879
in the context of health

65
00:02:44,879 --> 00:02:46,400
and the question is well why is this

66
00:02:46,400 --> 00:02:48,400
norm the norm for the context of health

67
00:02:48,400 --> 00:02:50,560
and the answer is that well that the

68
00:02:50,560 --> 00:02:52,640
context of health has a purpose a

69
00:02:52,640 --> 00:02:55,519
healthy society and also the individuals

70
00:02:55,519 --> 00:02:57,840
within that purpose that participate in

71
00:02:57,840 --> 00:03:00,560
certain roles have particular ends

72
00:03:00,560 --> 00:03:03,280
doctors want to limit their liability so

73
00:03:03,280 --> 00:03:05,200
contextual integrity is used in legal

74
00:03:05,200 --> 00:03:07,040
and ethical analysis as well as in

75
00:03:07,040 --> 00:03:09,120
technical design to

76
00:03:09,120 --> 00:03:11,599
understand okay when information is

77
00:03:11,599 --> 00:03:15,280
flowing in a way that's unexpected

78
00:03:15,280 --> 00:03:16,640
is that

79
00:03:16,640 --> 00:03:18,560
is that good or bad is it violating a

80
00:03:18,560 --> 00:03:20,480
norm in a way that

81
00:03:20,480 --> 00:03:23,760
also it violates the purposes and ends

82
00:03:23,760 --> 00:03:25,840
of the people involved in that context

83
00:03:25,840 --> 00:03:28,879
it's a it's a much squishier theory than

84
00:03:28,879 --> 00:03:31,360
uh many of you might be used to but we

85
00:03:31,360 --> 00:03:33,200
think that we can use it to tune

86
00:03:33,200 --> 00:03:35,519
differential privacy parameters how bear

87
00:03:35,519 --> 00:03:37,120
with me

88
00:03:37,120 --> 00:03:38,239
so

89
00:03:38,239 --> 00:03:41,280
um contextual integrity is like a rubric

90
00:03:41,280 --> 00:03:44,000
for collecting information about context

91
00:03:44,000 --> 00:03:45,440
that's needed to make normative

92
00:03:45,440 --> 00:03:48,480
decisions about information flow so just

93
00:03:48,480 --> 00:03:50,000
you know collect information about the

94
00:03:50,000 --> 00:03:52,480
purpose of the context the roles of the

95
00:03:52,480 --> 00:03:55,360
people involved the their individual

96
00:03:55,360 --> 00:03:57,840
ends the kind of data attributes or

97
00:03:57,840 --> 00:04:00,400
topics involved and any existing

98
00:04:00,400 --> 00:04:02,400
societal norms

99
00:04:02,400 --> 00:04:04,480
which could be things like sectoral

100
00:04:04,480 --> 00:04:06,560
privacy laws for example

101
00:04:06,560 --> 00:04:07,840
hipaa is

102
00:04:07,840 --> 00:04:10,000
often elaborated with contextual

103
00:04:10,000 --> 00:04:11,680
integrity but we think that this

104
00:04:11,680 --> 00:04:13,760
information once collected can be used

105
00:04:13,760 --> 00:04:16,399
to tune differential privacy parameters

106
00:04:16,399 --> 00:04:18,639
in order to optimize appropriate

107
00:04:18,639 --> 00:04:20,478
information flow given contextual

108
00:04:20,478 --> 00:04:23,039
purposes

109
00:04:23,120 --> 00:04:25,199
and we think that if we do this research

110
00:04:25,199 --> 00:04:26,639
we can also contribute back to

111
00:04:26,639 --> 00:04:29,440
contextual integrity and get insights

112
00:04:29,440 --> 00:04:32,800
from pet practice like um

113
00:04:32,800 --> 00:04:34,880
understanding that information doesn't

114
00:04:34,880 --> 00:04:36,800
an information flow is not necessarily a

115
00:04:36,800 --> 00:04:39,280
single data about a single attribute

116
00:04:39,280 --> 00:04:42,000
about a single person to a single uh

117
00:04:42,000 --> 00:04:43,040
receiver

118
00:04:43,040 --> 00:04:44,720
it can be more subtle we can have

119
00:04:44,720 --> 00:04:46,320
partial information influence we can

120
00:04:46,320 --> 00:04:48,080
have the flow of information with

121
00:04:48,080 --> 00:04:51,039
gaussian noise

122
00:04:51,199 --> 00:04:52,479
or uh

123
00:04:52,479 --> 00:04:55,040
or in aggregate you know

124
00:04:55,040 --> 00:04:57,120
um

125
00:04:57,120 --> 00:04:59,199
so we're aiming to contribute to privacy

126
00:04:59,199 --> 00:05:02,080
theory and some of the contributions are

127
00:05:02,080 --> 00:05:05,039
are really in a sense building on on the

128
00:05:05,039 --> 00:05:07,039
work of production integrity saying well

129
00:05:07,039 --> 00:05:09,120
what's a new formalization of contextual

130
00:05:09,120 --> 00:05:11,759
integrity that responds to previous

131
00:05:11,759 --> 00:05:14,000
computer science implementations of it

132
00:05:14,000 --> 00:05:16,800
as well as our use case of tuning and

133
00:05:16,800 --> 00:05:19,280
communicating pet parameters such as

134
00:05:19,280 --> 00:05:22,320
those in differential privacy

135
00:05:22,320 --> 00:05:23,680
and we're also building kind of an

136
00:05:23,680 --> 00:05:26,160
integrated rubric for privacy analysis

137
00:05:26,160 --> 00:05:29,600
um this includes uh crucially both

138
00:05:29,600 --> 00:05:31,840
normative aspects of the context which

139
00:05:31,840 --> 00:05:34,080
contextual integrity is emphasized

140
00:05:34,080 --> 00:05:35,919
things like you know those are the

141
00:05:35,919 --> 00:05:37,520
questions like why

142
00:05:37,520 --> 00:05:40,400
why do we have this context

143
00:05:40,400 --> 00:05:42,080
why do we have the health care system

144
00:05:42,080 --> 00:05:44,400
the financial system and

145
00:05:44,400 --> 00:05:47,199
how do we want our information to flow

146
00:05:47,199 --> 00:05:49,360
is it with consent

147
00:05:49,360 --> 00:05:51,680
only with a warrant

148
00:05:51,680 --> 00:05:52,960
when it's progressive when it's

149
00:05:52,960 --> 00:05:54,960
reciprocal

150
00:05:54,960 --> 00:05:56,880
those are the normative acts best of the

151
00:05:56,880 --> 00:05:59,919
context but for descriptively we are

152
00:05:59,919 --> 00:06:01,199
also interested in the size of the

153
00:06:01,199 --> 00:06:02,479
population

154
00:06:02,479 --> 00:06:06,800
any balance on the adversary and um

155
00:06:06,800 --> 00:06:08,400
and the kind of technical architectures

156
00:06:08,400 --> 00:06:10,720
we're considering in the system uh such

157
00:06:10,720 --> 00:06:12,720
as the possibility of introducing noise

158
00:06:12,720 --> 00:06:15,199
or using encryption

159
00:06:15,199 --> 00:06:16,880
once we have this room

160
00:06:16,880 --> 00:06:20,160
we think we can develop a procedure for

161
00:06:20,160 --> 00:06:23,120
tuning differential privacy parameters

162
00:06:23,120 --> 00:06:25,440
where we get the information from that

163
00:06:25,440 --> 00:06:28,479
integrated privacy rubric and build a

164
00:06:28,479 --> 00:06:31,360
contextual model of information flows

165
00:06:31,360 --> 00:06:33,360
and threats

166
00:06:33,360 --> 00:06:36,000
where we represent the possible tunings

167
00:06:36,000 --> 00:06:38,720
of the technologies privacy technologies

168
00:06:38,720 --> 00:06:40,639
in the model and because we're

169
00:06:40,639 --> 00:06:43,759
interested in what agents want and the

170
00:06:43,759 --> 00:06:45,680
ends and purposes we think we can do

171
00:06:45,680 --> 00:06:48,479
this on a causal imports diagram which

172
00:06:48,479 --> 00:06:51,039
is like a bayesian network with utility

173
00:06:51,039 --> 00:06:52,080
loans

174
00:06:52,080 --> 00:06:53,759
and the possibility for agents to make

175
00:06:53,759 --> 00:06:55,360
strategic decisions and points of

176
00:06:55,360 --> 00:06:58,080
control so we might

177
00:06:58,080 --> 00:07:00,479
for example understand that if we

178
00:07:00,479 --> 00:07:02,960
increase the amount of noise then we

179
00:07:02,960 --> 00:07:04,800
might have more people willing to

180
00:07:04,800 --> 00:07:07,440
participate in a survey uh that they

181
00:07:07,440 --> 00:07:08,880
might otherwise

182
00:07:08,880 --> 00:07:10,880
be concerned would be

183
00:07:10,880 --> 00:07:12,560
privacy newsprint

184
00:07:12,560 --> 00:07:15,759
but that might also reduce the utility

185
00:07:15,759 --> 00:07:16,720
of

186
00:07:16,720 --> 00:07:20,720
the accuracy of the resulting database

187
00:07:20,800 --> 00:07:23,199
that's just one example we're hoping to

188
00:07:23,199 --> 00:07:25,199
elaborate this into a procedure where we

189
00:07:25,199 --> 00:07:27,199
can take this general rubric for

190
00:07:27,199 --> 00:07:29,039
understanding the context and turn it

191
00:07:29,039 --> 00:07:31,039
into an optimization problem where we

192
00:07:31,039 --> 00:07:32,880
can clearly operationalize what

193
00:07:32,880 --> 00:07:34,960
appropriate information flow means and

194
00:07:34,960 --> 00:07:36,400
what the best way to design the

195
00:07:36,400 --> 00:07:40,720
technology is to maximize that flow

196
00:07:40,720 --> 00:07:42,479
we are working with a number of case

197
00:07:42,479 --> 00:07:44,400
studies for example the very well

198
00:07:44,400 --> 00:07:47,120
publicized case of the us census which

199
00:07:47,120 --> 00:07:50,240
uh may also serve this audience as a way

200
00:07:50,240 --> 00:07:51,680
of understanding what contextual

201
00:07:51,680 --> 00:07:54,240
integrity is about the purpose of the us

202
00:07:54,240 --> 00:07:56,400
census is to allocate suits for congress

203
00:07:56,400 --> 00:07:58,400
to support social science research there

204
00:07:58,400 --> 00:08:00,879
are the roles of researchers and data

205
00:08:00,879 --> 00:08:03,680
collectors and the public and they've

206
00:08:03,680 --> 00:08:06,479
sliced up the data and the census they

207
00:08:06,479 --> 00:08:08,319
collected in various ways and some are

208
00:08:08,319 --> 00:08:10,160
more restricted than others but what's

209
00:08:10,160 --> 00:08:12,479
interesting for our case is that the new

210
00:08:12,479 --> 00:08:14,160
recent norms around the sense of

211
00:08:14,160 --> 00:08:16,160
statements enshrined by law and the

212
00:08:16,160 --> 00:08:18,560
practice of the census bureau itself

213
00:08:18,560 --> 00:08:20,720
include differential privacy

214
00:08:20,720 --> 00:08:22,720
and other privacy-enhancing technologies

215
00:08:22,720 --> 00:08:24,639
whereas before they did it and this

216
00:08:24,639 --> 00:08:26,960
seems to be you know due to a

217
00:08:26,960 --> 00:08:29,360
recognition that this is somehow more

218
00:08:29,360 --> 00:08:31,919
appropriate and that's something that

219
00:08:31,919 --> 00:08:34,320
contextual integrity is not yet adapted

220
00:08:34,320 --> 00:08:35,360
to

221
00:08:35,360 --> 00:08:37,519
but it's also something that we think we

222
00:08:37,519 --> 00:08:40,399
can help inform in a robust way

223
00:08:40,399 --> 00:08:43,039
by mapping out the context better thank

224
00:08:43,039 --> 00:08:44,560
you so much for your attention please

225
00:08:44,560 --> 00:08:46,800
feel free to reach out to either i or

226
00:08:46,800 --> 00:08:49,040
rachel these email addresses i'll be

227
00:08:49,040 --> 00:08:52,680
happy to take your questions

228
00:08:59,360 --> 00:09:01,440
you

