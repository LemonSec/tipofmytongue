1
00:00:09,280 --> 00:00:10,960
so welcome to this session on privacy

2
00:00:10,960 --> 00:00:12,400
threat modeling i'm really excited to

3
00:00:12,400 --> 00:00:13,840
kick us off

4
00:00:13,840 --> 00:00:15,440
with this talk on the privacy threat

5
00:00:15,440 --> 00:00:18,960
taxonomy that we've been developing

6
00:00:19,760 --> 00:00:21,600
so let's start off with the privacy risk

7
00:00:21,600 --> 00:00:23,359
equation because it's a great lens

8
00:00:23,359 --> 00:00:24,720
through which we can conceptualize

9
00:00:24,720 --> 00:00:27,039
privacy threat modeling privacy risks

10
00:00:27,039 --> 00:00:28,560
are a function of privacy threats

11
00:00:28,560 --> 00:00:31,279
vulnerabilities and consequences where

12
00:00:31,279 --> 00:00:33,680
privacy vulnerabilities are flaws in a

13
00:00:33,680 --> 00:00:35,360
system that can be exploited to cause

14
00:00:35,360 --> 00:00:38,559
privacy harms or consequences privacy

15
00:00:38,559 --> 00:00:40,800
threats are actions or inactions that

16
00:00:40,800 --> 00:00:43,360
exploit privacy vulnerabilities and

17
00:00:43,360 --> 00:00:45,360
privacy consequences are the harms to

18
00:00:45,360 --> 00:00:46,640
individuals that come from the

19
00:00:46,640 --> 00:00:50,320
exploitation of privacy vulnerabilities

20
00:00:50,320 --> 00:00:52,160
and when you want to model and manage

21
00:00:52,160 --> 00:00:53,920
your privacy risk there are a number of

22
00:00:53,920 --> 00:00:57,039
privacy risk models to choose from

23
00:00:57,039 --> 00:00:58,480
there are also models for privacy

24
00:00:58,480 --> 00:00:59,920
consequences and for privacy

25
00:00:59,920 --> 00:01:01,920
vulnerabilities many of them from the

26
00:01:01,920 --> 00:01:03,199
national institute of standards and

27
00:01:03,199 --> 00:01:04,959
technology nist but many of them also

28
00:01:04,959 --> 00:01:06,880
academic solves taxonomy kayla's

29
00:01:06,880 --> 00:01:09,920
objective subjective harms

30
00:01:09,920 --> 00:01:11,600
but when it comes to privacy threats

31
00:01:11,600 --> 00:01:13,280
there's only one model actually

32
00:01:13,280 --> 00:01:15,759
advertised as a privacy threat model the

33
00:01:15,759 --> 00:01:17,360
linden model was presented at pepper

34
00:01:17,360 --> 00:01:18,720
last year actually

35
00:01:18,720 --> 00:01:20,720
we would argue actually that linden is a

36
00:01:20,720 --> 00:01:22,640
crossover model between a vulnerability

37
00:01:22,640 --> 00:01:24,960
model and a threat model because it

38
00:01:24,960 --> 00:01:27,520
focuses on system flaws rather than the

39
00:01:27,520 --> 00:01:29,600
exploitation of those flaws i know

40
00:01:29,600 --> 00:01:31,439
that's a very fine distinction between

41
00:01:31,439 --> 00:01:33,439
the two and linden is also a very high

42
00:01:33,439 --> 00:01:34,720
level model

43
00:01:34,720 --> 00:01:36,720
so the motivation for this work is this

44
00:01:36,720 --> 00:01:39,840
gap in privacy risk modeling around

45
00:01:39,840 --> 00:01:42,159
privacy threat modeling we thought that

46
00:01:42,159 --> 00:01:44,000
there was an opportunity for a more data

47
00:01:44,000 --> 00:01:46,320
driven a more granular model that can be

48
00:01:46,320 --> 00:01:49,119
used to describe privacy attacks the

49
00:01:49,119 --> 00:01:51,040
actual steps that a threat actor goes

50
00:01:51,040 --> 00:01:53,360
through to carry out

51
00:01:53,360 --> 00:01:55,680
something that causes a privacy harm

52
00:01:55,680 --> 00:01:57,600
so what is a privacy attack though

53
00:01:57,600 --> 00:02:01,280
that's not a term that's often used

54
00:02:01,280 --> 00:02:04,240
so we define a privacy attack as actions

55
00:02:04,240 --> 00:02:06,159
or inactions that cause a perceived

56
00:02:06,159 --> 00:02:08,239
privacy harm as defined by solids

57
00:02:08,239 --> 00:02:10,878
taxonomy that do not solely involve

58
00:02:10,878 --> 00:02:13,599
cyber security violations and let's dive

59
00:02:13,599 --> 00:02:15,200
deeper into two of the components of

60
00:02:15,200 --> 00:02:17,520
this definition solves taxonomy and the

61
00:02:17,520 --> 00:02:19,920
cyber security violations

62
00:02:19,920 --> 00:02:22,000
so i'm sure many of you are familiar

63
00:02:22,000 --> 00:02:24,239
with saul's taxonomy it's an ontology

64
00:02:24,239 --> 00:02:26,080
for privacy harms that was developed in

65
00:02:26,080 --> 00:02:27,440
the mid-aughts

66
00:02:27,440 --> 00:02:29,440
it's held up to scrutiny it's used in

67
00:02:29,440 --> 00:02:31,760
many different research contexts and it

68
00:02:31,760 --> 00:02:33,599
divides privacy harms into four

69
00:02:33,599 --> 00:02:35,440
different categories information

70
00:02:35,440 --> 00:02:37,599
collection harms information processing

71
00:02:37,599 --> 00:02:39,920
harms information dissemination harms

72
00:02:39,920 --> 00:02:42,480
and invasions or invasive harms

73
00:02:42,480 --> 00:02:44,560
and what we say in our definition

74
00:02:44,560 --> 00:02:47,200
is that most actions or inactions that

75
00:02:47,200 --> 00:02:49,440
cause a privacy harm are actually

76
00:02:49,440 --> 00:02:52,560
privacy attacks

77
00:02:52,800 --> 00:02:55,599
except those that arrive exclusive that

78
00:02:55,599 --> 00:02:57,440
arise exclusively from cyber security

79
00:02:57,440 --> 00:02:59,519
violations so we're defining our scope

80
00:02:59,519 --> 00:03:01,760
as the yellow bubble not intersected by

81
00:03:01,760 --> 00:03:03,840
the blue bubble so

82
00:03:03,840 --> 00:03:06,000
there are fantastic granular cyber

83
00:03:06,000 --> 00:03:07,280
security threat models that cover the

84
00:03:07,280 --> 00:03:09,440
entire blue bubble

85
00:03:09,440 --> 00:03:10,959
which can be called cyber security

86
00:03:10,959 --> 00:03:13,120
related privacy events or

87
00:03:13,120 --> 00:03:14,879
confidentiality attacks involving

88
00:03:14,879 --> 00:03:16,640
personal information

89
00:03:16,640 --> 00:03:18,319
one example is the mitre attack

90
00:03:18,319 --> 00:03:19,760
framework which is a cyber security

91
00:03:19,760 --> 00:03:21,599
model that our privacy threat taxonomy

92
00:03:21,599 --> 00:03:24,159
is actually based on

93
00:03:24,159 --> 00:03:25,519
and we don't want to duplicate these

94
00:03:25,519 --> 00:03:27,360
cyber security efforts or focus solely

95
00:03:27,360 --> 00:03:29,120
on data breaches because when you start

96
00:03:29,120 --> 00:03:30,799
talking about data breaches as privacy

97
00:03:30,799 --> 00:03:32,400
attacks it just eats your whole threat

98
00:03:32,400 --> 00:03:35,440
model so our focus is on privacy attacks

99
00:03:35,440 --> 00:03:37,920
that do not arise from cyber security

100
00:03:37,920 --> 00:03:40,319
violations but the question can be like

101
00:03:40,319 --> 00:03:42,720
what actually exists in that yellow

102
00:03:42,720 --> 00:03:44,239
scope bubble

103
00:03:44,239 --> 00:03:45,440
we're going to ground ourselves with

104
00:03:45,440 --> 00:03:47,840
three examples

105
00:03:47,920 --> 00:03:49,680
so the first example of a privacy attack

106
00:03:49,680 --> 00:03:51,360
we'll discuss involves re-identification

107
00:03:51,360 --> 00:03:52,879
of health data

108
00:03:52,879 --> 00:03:54,239
which is

109
00:03:54,239 --> 00:03:56,799
very apt after the dp talks that we just

110
00:03:56,799 --> 00:03:58,159
heard

111
00:03:58,159 --> 00:03:58,959
so

112
00:03:58,959 --> 00:04:00,400
the state of washington maintained a

113
00:04:00,400 --> 00:04:02,080
database of patient-level health data

114
00:04:02,080 --> 00:04:04,239
containing almost all hospitalizations

115
00:04:04,239 --> 00:04:06,239
um the data set didn't include names or

116
00:04:06,239 --> 00:04:07,680
addresses

117
00:04:07,680 --> 00:04:09,840
but it included full demographics and

118
00:04:09,840 --> 00:04:11,840
zip codes so a researcher purchased the

119
00:04:11,840 --> 00:04:14,159
data set for 50 bucks and re-identified

120
00:04:14,159 --> 00:04:17,760
it with a 43 success rate

121
00:04:17,839 --> 00:04:19,519
so this attack clearly demonstrates the

122
00:04:19,519 --> 00:04:20,959
solids harm

123
00:04:20,959 --> 00:04:22,720
identification which represents harms

124
00:04:22,720 --> 00:04:25,520
from reduced anonymity

125
00:04:25,520 --> 00:04:27,040
so the next example we'll talk about is

126
00:04:27,040 --> 00:04:28,560
lenovo's superfish and you might say oh

127
00:04:28,560 --> 00:04:30,639
that was a cyber security attack uh wait

128
00:04:30,639 --> 00:04:32,880
a second in this attack lenovo

129
00:04:32,880 --> 00:04:34,720
pre-installed software onto its laptops

130
00:04:34,720 --> 00:04:36,160
that man in the middle packets being

131
00:04:36,160 --> 00:04:38,160
sent in and out of the computer so the

132
00:04:38,160 --> 00:04:39,600
software intercepted all the information

133
00:04:39,600 --> 00:04:41,199
coming in and out over the internet it

134
00:04:41,199 --> 00:04:43,600
decrypted the packets with its key and

135
00:04:43,600 --> 00:04:45,919
it read them so that it could

136
00:04:45,919 --> 00:04:48,800
target ads at the user with invasive

137
00:04:48,800 --> 00:04:51,360
pop-ups

138
00:04:51,440 --> 00:04:53,120
so the two harms from solos taxonomy

139
00:04:53,120 --> 00:04:55,600
demonstrated by this are insecurity and

140
00:04:55,600 --> 00:04:57,040
intrusion

141
00:04:57,040 --> 00:04:59,199
where insecurity because the attack

142
00:04:59,199 --> 00:05:01,120
caused the user's web traffic to be

143
00:05:01,120 --> 00:05:03,520
significantly less secure and intrusion

144
00:05:03,520 --> 00:05:05,520
because the pop-ups intruded onto the

145
00:05:05,520 --> 00:05:07,280
traditionally private domain of your

146
00:05:07,280 --> 00:05:11,360
experience on your device

147
00:05:11,360 --> 00:05:12,880
so the third and final example we'll

148
00:05:12,880 --> 00:05:15,440
talk about today is cambridge analytica

149
00:05:15,440 --> 00:05:17,600
a privacy attack not only on individuals

150
00:05:17,600 --> 00:05:19,360
but on our democracy in the united

151
00:05:19,360 --> 00:05:20,560
states

152
00:05:20,560 --> 00:05:22,440
and it demonstrates the power of

153
00:05:22,440 --> 00:05:24,800
non-cybersecurity attacks of privacy

154
00:05:24,800 --> 00:05:27,520
attacks so in cambridge analytica

155
00:05:27,520 --> 00:05:30,720
data was appropriated a saw of harm from

156
00:05:30,720 --> 00:05:34,560
a personality quiz and used to target

157
00:05:34,560 --> 00:05:36,880
political ads which amount to decisional

158
00:05:36,880 --> 00:05:39,120
interference because they invade on the

159
00:05:39,120 --> 00:05:40,639
political choices the citizens are

160
00:05:40,639 --> 00:05:42,800
making such data were also used during

161
00:05:42,800 --> 00:05:44,400
the election to cause chilling effects

162
00:05:44,400 --> 00:05:46,479
and cause people to actually not vote in

163
00:05:46,479 --> 00:05:48,000
the election which is another form of

164
00:05:48,000 --> 00:05:50,160
decisional interference

165
00:05:50,160 --> 00:05:50,960
where

166
00:05:50,960 --> 00:05:52,479
decisional interference is an invasive

167
00:05:52,479 --> 00:05:54,560
harm and appropriation is an information

168
00:05:54,560 --> 00:05:57,440
dissemination harm

169
00:05:57,440 --> 00:06:00,080
so we use solid taxonomy to classify

170
00:06:00,080 --> 00:06:02,000
these individual privacy attacks based

171
00:06:02,000 --> 00:06:04,160
on their privacy consequences or harms

172
00:06:04,160 --> 00:06:05,919
because they don't arise solely from

173
00:06:05,919 --> 00:06:07,680
cyber security violations so they fit

174
00:06:07,680 --> 00:06:10,400
our definition so they're they cause all

175
00:06:10,400 --> 00:06:12,240
of harms they're not just cyber security

176
00:06:12,240 --> 00:06:13,840
therefore they fit our definition of a

177
00:06:13,840 --> 00:06:16,319
privacy attack but solo's taxonomy is

178
00:06:16,319 --> 00:06:18,800
inherently a privacy consequence model

179
00:06:18,800 --> 00:06:20,639
what we want to do is describe the

180
00:06:20,639 --> 00:06:22,880
components of the attack so that we can

181
00:06:22,880 --> 00:06:24,639
better understand the privacy threats

182
00:06:24,639 --> 00:06:26,720
themselves we're building a privacy

183
00:06:26,720 --> 00:06:29,120
threat model we want to improve privacy

184
00:06:29,120 --> 00:06:30,880
risk management by making it threat

185
00:06:30,880 --> 00:06:33,039
informed targeting mitigation efforts at

186
00:06:33,039 --> 00:06:36,960
the most consequential or likely threats

187
00:06:36,960 --> 00:06:38,960
now unfortunately across

188
00:06:38,960 --> 00:06:41,120
most of the industry right now

189
00:06:41,120 --> 00:06:42,479
privacy risk management is still the

190
00:06:42,479 --> 00:06:44,240
exception not the rule

191
00:06:44,240 --> 00:06:47,199
this room obviously excluded

192
00:06:47,199 --> 00:06:49,199
whereas compliance-oriented privacy

193
00:06:49,199 --> 00:06:51,520
programs are pretty standard um so the

194
00:06:51,520 --> 00:06:52,960
focus is on compliance with rules and

195
00:06:52,960 --> 00:06:55,759
regulations or with policies not on

196
00:06:55,759 --> 00:06:58,880
managing the risks to individuals

197
00:06:58,880 --> 00:07:00,560
so privacy can also take a cyber

198
00:07:00,560 --> 00:07:02,319
security perspective and focus on data

199
00:07:02,319 --> 00:07:04,240
breaches which we discussed which misses

200
00:07:04,240 --> 00:07:05,599
the potential threats like the three

201
00:07:05,599 --> 00:07:07,440
that we just covered which are not data

202
00:07:07,440 --> 00:07:10,000
breaches so we hope that by developing a

203
00:07:10,000 --> 00:07:12,639
threat model that is granular and can be

204
00:07:12,639 --> 00:07:15,280
used to describe privacy attacks that we

205
00:07:15,280 --> 00:07:17,680
can actually change the narrative around

206
00:07:17,680 --> 00:07:20,240
privacy threats the privacy community is

207
00:07:20,240 --> 00:07:22,080
still without a descriptive threat model

208
00:07:22,080 --> 00:07:24,240
or even a kill chain model cyber

209
00:07:24,240 --> 00:07:25,440
security's had the lockheed martin's

210
00:07:25,440 --> 00:07:28,319
cyber kill chain for ages now

211
00:07:28,319 --> 00:07:30,400
we have the fips and privacy impact

212
00:07:30,400 --> 00:07:32,960
assessments we don't have a granular

213
00:07:32,960 --> 00:07:34,560
threat model

214
00:07:34,560 --> 00:07:36,639
which takes me to our work on the

215
00:07:36,639 --> 00:07:38,400
privacy threat taxonomy we're going to

216
00:07:38,400 --> 00:07:39,919
transition now to talking about this

217
00:07:39,919 --> 00:07:42,080
threat model that we are in the process

218
00:07:42,080 --> 00:07:43,440
of developing

219
00:07:43,440 --> 00:07:44,720
just know that you guys are seeing

220
00:07:44,720 --> 00:07:46,720
prototype today you are not seeing a

221
00:07:46,720 --> 00:07:49,440
final product

222
00:07:49,680 --> 00:07:51,440
so what we did was we started with a

223
00:07:51,440 --> 00:07:53,360
data set of known privacy attacks that

224
00:07:53,360 --> 00:07:55,280
occurred in the wild we followed a

225
00:07:55,280 --> 00:07:57,039
methodology from garfinkel and

226
00:07:57,039 --> 00:07:59,520
theophanos paper 44 non-breach privacy

227
00:07:59,520 --> 00:08:01,599
events which down selected from closed

228
00:08:01,599 --> 00:08:04,560
ftc and fcc cases to those that

229
00:08:04,560 --> 00:08:06,639
fulfilled their definition of a

230
00:08:06,639 --> 00:08:09,280
non-breach privacy event which is what

231
00:08:09,280 --> 00:08:11,039
our definition of a privacy attack is

232
00:08:11,039 --> 00:08:12,720
actually based on

233
00:08:12,720 --> 00:08:14,720
i want to note that neither definition

234
00:08:14,720 --> 00:08:16,960
requires malicious intent

235
00:08:16,960 --> 00:08:19,759
or any action whatsoever benign intent

236
00:08:19,759 --> 00:08:22,240
and inaction can be a privacy attack if

237
00:08:22,240 --> 00:08:26,599
it causes a privacy harm

238
00:08:26,800 --> 00:08:29,440
so we looked at all the ftc and fcc

239
00:08:29,440 --> 00:08:32,320
cases between 2000 and 2022 and we found

240
00:08:32,320 --> 00:08:35,039
that 146 involved privacy attacks based

241
00:08:35,039 --> 00:08:37,360
on our definition now we cataloged these

242
00:08:37,360 --> 00:08:39,360
attacks with metadata such as how many

243
00:08:39,360 --> 00:08:40,880
individuals were harmed and what data

244
00:08:40,880 --> 00:08:42,559
were involved

245
00:08:42,559 --> 00:08:44,720
and we used them to generate two

246
00:08:44,720 --> 00:08:46,640
prototypes so the privacy threat

247
00:08:46,640 --> 00:08:47,839
taxonomy

248
00:08:47,839 --> 00:08:50,320
is a privacy threat model it is a

249
00:08:50,320 --> 00:08:52,480
hierarchical ontology that describes the

250
00:08:52,480 --> 00:08:55,040
components of a privacy attack

251
00:08:55,040 --> 00:08:57,600
the privacy threat clusters are groups

252
00:08:57,600 --> 00:08:59,600
of attacks from our data set that share

253
00:08:59,600 --> 00:09:01,680
similar attack components

254
00:09:01,680 --> 00:09:05,920
is a typology of privacy attacks

255
00:09:06,080 --> 00:09:07,760
and each privacy threat cluster will

256
00:09:07,760 --> 00:09:10,080
have an associated privacy threat

257
00:09:10,080 --> 00:09:12,000
pattern so now we've got a taxonomy

258
00:09:12,000 --> 00:09:14,720
clusters and patterns um the privacy

259
00:09:14,720 --> 00:09:16,480
threat patterns are generic kill chains

260
00:09:16,480 --> 00:09:18,399
that describe the type of attacks within

261
00:09:18,399 --> 00:09:19,519
a cluster

262
00:09:19,519 --> 00:09:21,279
so the pattern was developed the

263
00:09:21,279 --> 00:09:23,760
patterns are developed by taking

264
00:09:23,760 --> 00:09:26,480
a privacy threat cluster

265
00:09:26,480 --> 00:09:27,920
mapping it to the privacy threat

266
00:09:27,920 --> 00:09:30,240
taxonomy and then taking the results of

267
00:09:30,240 --> 00:09:32,399
that mapping and assembling it into a

268
00:09:32,399 --> 00:09:34,800
linear or semi-linear kill chain so

269
00:09:34,800 --> 00:09:36,399
basically clusters can be mapped to the

270
00:09:36,399 --> 00:09:38,080
taxonomy and that mapping creates a

271
00:09:38,080 --> 00:09:40,080
privacy threat pattern

272
00:09:40,080 --> 00:09:42,240
which are similar to design patterns

273
00:09:42,240 --> 00:09:43,440
all this is going to make more sense in

274
00:09:43,440 --> 00:09:45,360
a moment when we go through an example i

275
00:09:45,360 --> 00:09:46,560
just wanted you to understand the

276
00:09:46,560 --> 00:09:48,959
interoperability of the two

277
00:09:48,959 --> 00:09:50,880
prototypes and how they relate to the

278
00:09:50,880 --> 00:09:54,000
privacy threat patterns

279
00:09:54,000 --> 00:09:54,720
so

280
00:09:54,720 --> 00:09:56,399
structuring was our first research

281
00:09:56,399 --> 00:09:58,800
effort to develop the privacy threat

282
00:09:58,800 --> 00:10:00,800
taxonomy

283
00:10:00,800 --> 00:10:02,640
so what we did first is we broke the

284
00:10:02,640 --> 00:10:05,120
attacks into individual threat actions

285
00:10:05,120 --> 00:10:07,279
taken by the potential threat actor or

286
00:10:07,279 --> 00:10:09,519
the potentially threatening system

287
00:10:09,519 --> 00:10:11,600
next we grouped the threat actions into

288
00:10:11,600 --> 00:10:14,079
domains of similar activities

289
00:10:14,079 --> 00:10:16,640
so that looks like this an activity is a

290
00:10:16,640 --> 00:10:18,959
group of threat actions and here we see

291
00:10:18,959 --> 00:10:21,279
the collection activity and the exposure

292
00:10:21,279 --> 00:10:23,760
threat action which is under the sharing

293
00:10:23,760 --> 00:10:26,319
activity

294
00:10:26,640 --> 00:10:28,880
it's a hierarchy

295
00:10:28,880 --> 00:10:31,120
so next we begin refining the threat

296
00:10:31,120 --> 00:10:32,880
actions and activities so that there

297
00:10:32,880 --> 00:10:34,880
would be few overlaps and gaps between

298
00:10:34,880 --> 00:10:36,959
them in the model so this involved

299
00:10:36,959 --> 00:10:38,720
taking individual attacks from our data

300
00:10:38,720 --> 00:10:40,720
set and mapping them to the taxonomy

301
00:10:40,720 --> 00:10:43,120
identifying where the taxonomy could not

302
00:10:43,120 --> 00:10:45,360
and could capture the nuances of the

303
00:10:45,360 --> 00:10:47,440
attack this is a process we're still

304
00:10:47,440 --> 00:10:50,160
engaged in it's quite difficult

305
00:10:50,160 --> 00:10:52,720
the taxonomy doesn't yet fit all attacks

306
00:10:52,720 --> 00:10:53,839
easily

307
00:10:53,839 --> 00:10:56,079
and identifying how to resolve gaps and

308
00:10:56,079 --> 00:10:58,560
overlaps and what things actually belong

309
00:10:58,560 --> 00:11:00,640
in the model for example does data bias

310
00:11:00,640 --> 00:11:03,040
belong in a privacy model

311
00:11:03,040 --> 00:11:04,640
we're also facing the challenge of how

312
00:11:04,640 --> 00:11:06,720
to clearly and concisely name the threat

313
00:11:06,720 --> 00:11:08,880
actions which is no small feat on its

314
00:11:08,880 --> 00:11:09,920
own

315
00:11:09,920 --> 00:11:11,680
so we will continue this process of

316
00:11:11,680 --> 00:11:13,519
mapping individual attacks to the

317
00:11:13,519 --> 00:11:17,279
taxonomy until it stabilizes

318
00:11:17,279 --> 00:11:19,519
and few to no changes occur when we map

319
00:11:19,519 --> 00:11:21,600
each new attack iteratively against the

320
00:11:21,600 --> 00:11:24,079
taxonomy

321
00:11:24,079 --> 00:11:26,000
so there are 13 activities currently in

322
00:11:26,000 --> 00:11:27,760
the in the privacy threat taxonomy i am

323
00:11:27,760 --> 00:11:29,440
going to read them i know they're small

324
00:11:29,440 --> 00:11:31,040
um

325
00:11:31,040 --> 00:11:33,200
these are the the different activities

326
00:11:33,200 --> 00:11:35,040
that a system or an organization can

327
00:11:35,040 --> 00:11:37,200
take in relation to personal information

328
00:11:37,200 --> 00:11:39,760
and data subjects so from left to right

329
00:11:39,760 --> 00:11:42,720
we've got notice and consent collection

330
00:11:42,720 --> 00:11:45,120
of information insecurity specifically

331
00:11:45,120 --> 00:11:47,440
related to privacy

332
00:11:47,440 --> 00:11:49,600
identification of data quality assurance

333
00:11:49,600 --> 00:11:52,160
not only of data but also data sources

334
00:11:52,160 --> 00:11:53,279
of

335
00:11:53,279 --> 00:11:55,040
different parts of your

336
00:11:55,040 --> 00:11:56,560
cycle model

337
00:11:56,560 --> 00:11:58,480
aggregation and processing oh

338
00:11:58,480 --> 00:12:00,079
manageability of data by the data

339
00:12:00,079 --> 00:12:01,440
subject

340
00:12:01,440 --> 00:12:04,720
sharing use against the data subject

341
00:12:04,720 --> 00:12:06,720
and retention and destruction and

342
00:12:06,720 --> 00:12:09,040
deviations for example deviations from

343
00:12:09,040 --> 00:12:11,839
stated policy

344
00:12:12,639 --> 00:12:14,480
so here are some examples of threat

345
00:12:14,480 --> 00:12:16,240
actions from the collection activity

346
00:12:16,240 --> 00:12:17,680
these describe different potentially

347
00:12:17,680 --> 00:12:19,279
threatening actions that an entity can

348
00:12:19,279 --> 00:12:21,760
take in relation to data collection so

349
00:12:21,760 --> 00:12:23,519
for example data collection can occur

350
00:12:23,519 --> 00:12:25,839
via tracking or by externally

351
00:12:25,839 --> 00:12:27,600
appropriating data collected for another

352
00:12:27,600 --> 00:12:28,720
purpose

353
00:12:28,720 --> 00:12:30,480
or intercepting it like in the lenovo

354
00:12:30,480 --> 00:12:33,200
superfish attack

355
00:12:33,200 --> 00:12:35,519
so our second research effort involved

356
00:12:35,519 --> 00:12:37,920
the clusters and clustering the attacks

357
00:12:37,920 --> 00:12:41,920
in our data set into a typology

358
00:12:45,440 --> 00:12:47,040
so similar to the taxonomy the first

359
00:12:47,040 --> 00:12:48,959
step is to break attacks into the threat

360
00:12:48,959 --> 00:12:50,480
actions

361
00:12:50,480 --> 00:12:52,079
but next instead of you know

362
00:12:52,079 --> 00:12:53,600
categorizing them in a hierarchical

363
00:12:53,600 --> 00:12:55,839
model we took attacks with similar

364
00:12:55,839 --> 00:12:57,040
threat actions and grouped them into

365
00:12:57,040 --> 00:12:59,920
threat clusters

366
00:13:00,160 --> 00:13:02,399
to verify the clusters

367
00:13:02,399 --> 00:13:04,560
sorry i woke up with a frog

368
00:13:04,560 --> 00:13:06,320
we mapped the entire data set to our

369
00:13:06,320 --> 00:13:08,880
cluster types um refining and renaming

370
00:13:08,880 --> 00:13:10,560
our clusters along the way merging them

371
00:13:10,560 --> 00:13:13,839
separating them killing some of them

372
00:13:13,839 --> 00:13:15,600
and so a single attack may map to

373
00:13:15,600 --> 00:13:17,200
multiple clusters based on its

374
00:13:17,200 --> 00:13:20,480
components and its complexity

375
00:13:20,480 --> 00:13:22,639
so once we actually stabilize the

376
00:13:22,639 --> 00:13:24,639
taxonomy which is not yet

377
00:13:24,639 --> 00:13:26,399
we will be able to map each of the

378
00:13:26,399 --> 00:13:28,800
clusters onto the taxonomy identifying

379
00:13:28,800 --> 00:13:30,880
which activities and threat actions

380
00:13:30,880 --> 00:13:33,440
define its generic kill chain

381
00:13:33,440 --> 00:13:35,040
this is going to be we already know a

382
00:13:35,040 --> 00:13:36,880
finicky and tricky process it's not

383
00:13:36,880 --> 00:13:39,040
going to be easily clear which threat

384
00:13:39,040 --> 00:13:41,360
actions and activities are necessary or

385
00:13:41,360 --> 00:13:43,120
optional because there can be many

386
00:13:43,120 --> 00:13:45,040
different types of attacks even within a

387
00:13:45,040 --> 00:13:46,160
cluster

388
00:13:46,160 --> 00:13:48,160
so what we need to do is what we will

389
00:13:48,160 --> 00:13:50,160
find exemplary attacks within the

390
00:13:50,160 --> 00:13:51,680
cluster and we'll select activities and

391
00:13:51,680 --> 00:13:53,120
threat actions that represent these

392
00:13:53,120 --> 00:13:55,600
exemplary attacks trying as best as we

393
00:13:55,600 --> 00:13:58,320
can to have the threat pattern represent

394
00:13:58,320 --> 00:14:01,199
as many attacks and as many exemplary

395
00:14:01,199 --> 00:14:04,800
attacks within a cluster as possible

396
00:14:04,800 --> 00:14:06,399
so after this mapping we're going to

397
00:14:06,399 --> 00:14:07,360
assemble

398
00:14:07,360 --> 00:14:09,440
all of these mappings into threat

399
00:14:09,440 --> 00:14:12,000
patterns the generic kill chains

400
00:14:12,000 --> 00:14:13,040
and this will make more sense we're

401
00:14:13,040 --> 00:14:14,959
going to go through an example

402
00:14:14,959 --> 00:14:16,639
so the example we're going to use is

403
00:14:16,639 --> 00:14:18,639
data de-identification

404
00:14:18,639 --> 00:14:20,880
whoever put us after the dp group is uh

405
00:14:20,880 --> 00:14:23,279
pretty good

406
00:14:24,720 --> 00:14:26,240
so here's what it looks like mapped onto

407
00:14:26,240 --> 00:14:28,480
the taxonomy so sometimes an activity is

408
00:14:28,480 --> 00:14:30,880
selected and sometimes a threat action

409
00:14:30,880 --> 00:14:33,040
within the activity is selected so when

410
00:14:33,040 --> 00:14:35,600
an activity is selected it means that

411
00:14:35,600 --> 00:14:37,040
it's essential

412
00:14:37,040 --> 00:14:38,800
to the pattern or the kill chain of the

413
00:14:38,800 --> 00:14:39,920
attack

414
00:14:39,920 --> 00:14:41,680
but that any threat action within the

415
00:14:41,680 --> 00:14:44,000
activity will do so for example in this

416
00:14:44,000 --> 00:14:45,839
threat pattern there needs to be some

417
00:14:45,839 --> 00:14:47,760
form of generation of a data set some

418
00:14:47,760 --> 00:14:50,240
form of maybe data collection

419
00:14:50,240 --> 00:14:52,560
but how the data are collected is not

420
00:14:52,560 --> 00:14:54,240
important to the pattern what's

421
00:14:54,240 --> 00:14:56,240
essential for this pattern is that the

422
00:14:56,240 --> 00:15:00,000
data are not de-identified properly

423
00:15:00,000 --> 00:15:01,680
so here's what the taxonomy activities

424
00:15:01,680 --> 00:15:03,279
and threat actions look like as a threat

425
00:15:03,279 --> 00:15:04,240
pattern

426
00:15:04,240 --> 00:15:06,639
so the collection identification and

427
00:15:06,639 --> 00:15:08,480
sharing activities do not have

428
00:15:08,480 --> 00:15:10,560
individual threat actions specified so

429
00:15:10,560 --> 00:15:12,639
they appear without any of the gray tile

430
00:15:12,639 --> 00:15:14,800
threat actions

431
00:15:14,800 --> 00:15:16,160
while the quality assurance and

432
00:15:16,160 --> 00:15:18,160
processing activities appear with their

433
00:15:18,160 --> 00:15:19,920
relevant threat actions data not

434
00:15:19,920 --> 00:15:21,519
de-identified and insufficient

435
00:15:21,519 --> 00:15:23,680
de-identification so these threat

436
00:15:23,680 --> 00:15:25,040
actions are what differentiate this

437
00:15:25,040 --> 00:15:27,279
pattern from other patterns

438
00:15:27,279 --> 00:15:28,959
aggregation is a common feature in this

439
00:15:28,959 --> 00:15:31,120
pattern but it's not actually essential

440
00:15:31,120 --> 00:15:32,800
to the kill chain

441
00:15:32,800 --> 00:15:34,880
the the data identification pattern can

442
00:15:34,880 --> 00:15:37,440
actually exist without aggregation

443
00:15:37,440 --> 00:15:39,199
for example one of the attacks in our

444
00:15:39,199 --> 00:15:41,360
data set involves a local news station

445
00:15:41,360 --> 00:15:44,399
which published a woman's full name and

446
00:15:44,399 --> 00:15:45,680
her phone number and the rest of her

447
00:15:45,680 --> 00:15:48,560
contact details on the local news

448
00:15:48,560 --> 00:15:51,040
so here is a chance where

449
00:15:51,040 --> 00:15:52,560
in in

450
00:15:52,560 --> 00:15:55,279
where lack of de-identification

451
00:15:55,279 --> 00:15:57,199
existed without aggregation actually so

452
00:15:57,199 --> 00:15:59,440
it was just a single record that was not

453
00:15:59,440 --> 00:16:02,720
properly de-identified

454
00:16:03,040 --> 00:16:05,680
so you can also map individual attacks

455
00:16:05,680 --> 00:16:08,560
from the data set onto both prototypes

456
00:16:08,560 --> 00:16:10,320
so here are the three threat clusters or

457
00:16:10,320 --> 00:16:11,680
threat patterns associated with the

458
00:16:11,680 --> 00:16:14,000
lenovo superfish attack preemption of

459
00:16:14,000 --> 00:16:16,399
privacy settings insecurity and

460
00:16:16,399 --> 00:16:18,639
behavioral advertising and each of these

461
00:16:18,639 --> 00:16:20,399
will eventually have a privacy threat

462
00:16:20,399 --> 00:16:21,360
pattern

463
00:16:21,360 --> 00:16:24,639
once we're done with the taxonomy

464
00:16:24,880 --> 00:16:26,639
so here's what lenovo's superfish looks

465
00:16:26,639 --> 00:16:29,040
like mapped onto the taxonomy itself so

466
00:16:29,040 --> 00:16:30,320
to give you a better understanding of

467
00:16:30,320 --> 00:16:32,399
the threat actions and how an attack can

468
00:16:32,399 --> 00:16:34,399
be described with the taxonomy we're

469
00:16:34,399 --> 00:16:35,519
going to go through this whole attack

470
00:16:35,519 --> 00:16:36,480
mapping

471
00:16:36,480 --> 00:16:38,560
so you can see here that lenovo provided

472
00:16:38,560 --> 00:16:40,959
neither notice nor consent any consent

473
00:16:40,959 --> 00:16:43,040
mechanism for users to understand and

474
00:16:43,040 --> 00:16:44,480
agree with the monitoring and the

475
00:16:44,480 --> 00:16:45,759
pop-ups

476
00:16:45,759 --> 00:16:47,519
the collection occurred via intercepting

477
00:16:47,519 --> 00:16:48,800
information

478
00:16:48,800 --> 00:16:51,600
lenovo caused privacy related insecurity

479
00:16:51,600 --> 00:16:53,040
through insufficient encryption and

480
00:16:53,040 --> 00:16:55,040
digital certificates and undermining

481
00:16:55,040 --> 00:16:56,399
authentication

482
00:16:56,399 --> 00:16:58,320
they identified the users using

483
00:16:58,320 --> 00:17:00,959
persistent identifiers there was no way

484
00:17:00,959 --> 00:17:02,880
for users to manage their own data or

485
00:17:02,880 --> 00:17:04,959
settings because the controls completely

486
00:17:04,959 --> 00:17:07,280
bypassed the user

487
00:17:07,280 --> 00:17:09,119
personally identifiable information was

488
00:17:09,119 --> 00:17:11,199
aggregated with web browsing history

489
00:17:11,199 --> 00:17:13,679
which is sensitive information

490
00:17:13,679 --> 00:17:16,160
and finally the data collected were used

491
00:17:16,160 --> 00:17:17,919
to actually intrude on the user's web

492
00:17:17,919 --> 00:17:22,319
experience via invasive pop-ups

493
00:17:22,480 --> 00:17:23,359
so

494
00:17:23,359 --> 00:17:25,599
we hope that the categorization and the

495
00:17:25,599 --> 00:17:28,079
naming of different threat actions

496
00:17:28,079 --> 00:17:29,919
and activities allows for a better

497
00:17:29,919 --> 00:17:32,640
understanding of privacy threats

498
00:17:32,640 --> 00:17:33,919
and we hope that it facilitates

499
00:17:33,919 --> 00:17:36,640
discussion about privacy attacks

500
00:17:36,640 --> 00:17:38,559
that's the goal

501
00:17:38,559 --> 00:17:40,880
so we want to create both a method for

502
00:17:40,880 --> 00:17:43,919
talking about privacy and a way to model

503
00:17:43,919 --> 00:17:46,240
privacy threats we've seen that similar

504
00:17:46,240 --> 00:17:48,000
models for cyber security threats have

505
00:17:48,000 --> 00:17:49,360
done both

506
00:17:49,360 --> 00:17:50,960
and we see the dramatic benefits in

507
00:17:50,960 --> 00:17:52,720
cyber security from each

508
00:17:52,720 --> 00:17:54,799
they're already on to threat informed

509
00:17:54,799 --> 00:17:56,799
cyber security defense we want to get to

510
00:17:56,799 --> 00:17:59,520
threat informed privacy defense

511
00:17:59,520 --> 00:18:00,960
so next i'm going to talk a little bit

512
00:18:00,960 --> 00:18:02,480
about how the privacy threat taxonomy

513
00:18:02,480 --> 00:18:04,160
and clusters can be used and our next

514
00:18:04,160 --> 00:18:06,240
steps

515
00:18:06,240 --> 00:18:07,840
so to use the taxonomy for threat

516
00:18:07,840 --> 00:18:09,440
modeling you can do one of two things

517
00:18:09,440 --> 00:18:11,360
you can assemble a data set of attacks

518
00:18:11,360 --> 00:18:14,799
associated with similar technologies and

519
00:18:14,799 --> 00:18:16,880
map those onto the taxonomy

520
00:18:16,880 --> 00:18:19,360
or you can map the system itself to the

521
00:18:19,360 --> 00:18:21,919
taxonomy asking could this action or be

522
00:18:21,919 --> 00:18:24,080
a threat action or an action

523
00:18:24,080 --> 00:18:25,840
for example are you de-identifying

524
00:18:25,840 --> 00:18:27,360
information are you vetting your

525
00:18:27,360 --> 00:18:29,679
information source

526
00:18:29,679 --> 00:18:32,400
you know these could be threat actions

527
00:18:32,400 --> 00:18:34,320
once you've mapped the taxonomy you

528
00:18:34,320 --> 00:18:36,080
identify which threat patterns might be

529
00:18:36,080 --> 00:18:37,919
relevant to the system and you disrupt

530
00:18:37,919 --> 00:18:40,799
those patterns with privacy medications

531
00:18:40,799 --> 00:18:42,720
now we plan on developing a web app tool

532
00:18:42,720 --> 00:18:44,240
that will help with these final steps so

533
00:18:44,240 --> 00:18:46,480
all a user will have to do is select the

534
00:18:46,480 --> 00:18:47,919
individual threat actions on the

535
00:18:47,919 --> 00:18:50,080
taxonomy and it will pre-populate with

536
00:18:50,080 --> 00:18:52,000
the associated clusters and each cluster

537
00:18:52,000 --> 00:18:54,880
will be will have associated mitigations

538
00:18:54,880 --> 00:18:56,720
so we're going to populate the web app

539
00:18:56,720 --> 00:18:58,160
with all of the different privacy

540
00:18:58,160 --> 00:18:59,600
patterns and what they look like on the

541
00:18:59,600 --> 00:19:01,840
taxonomy and how the taxonomy might get

542
00:19:01,840 --> 00:19:03,679
you to the threat patterns as well as of

543
00:19:03,679 --> 00:19:04,640
course

544
00:19:04,640 --> 00:19:06,960
a whole wiki of all of the definitions

545
00:19:06,960 --> 00:19:09,280
of everything in the taxonomy so you

546
00:19:09,280 --> 00:19:10,799
just select your threat actions the tool

547
00:19:10,799 --> 00:19:12,160
tells you which pattern your system

548
00:19:12,160 --> 00:19:14,000
might be causing and you can disrupt

549
00:19:14,000 --> 00:19:15,280
those patterns with mitigations that

550
00:19:15,280 --> 00:19:17,280
lower the privacy threat could think of

551
00:19:17,280 --> 00:19:20,160
this as a privacy threat assessment

552
00:19:20,160 --> 00:19:22,160
and as an added bonus you'll have a

553
00:19:22,160 --> 00:19:23,760
better understanding of privacy threats

554
00:19:23,760 --> 00:19:25,120
and ways of discussing threats with

555
00:19:25,120 --> 00:19:27,200
management and others using the taxonomy

556
00:19:27,200 --> 00:19:30,000
and clusters terminology

557
00:19:30,000 --> 00:19:32,000
so like other threat models we do hope

558
00:19:32,000 --> 00:19:33,600
that the privacy threat taxonomy will

559
00:19:33,600 --> 00:19:35,200
integrate with privacy risk models and

560
00:19:35,200 --> 00:19:36,880
risk management and

561
00:19:36,880 --> 00:19:39,520
so by analyzing systems and asking could

562
00:19:39,520 --> 00:19:41,360
this action or an action

563
00:19:41,360 --> 00:19:43,760
be a threat to the data subject system

564
00:19:43,760 --> 00:19:45,120
owners and operators will better

565
00:19:45,120 --> 00:19:47,200
understand how vulnerabilities and flaws

566
00:19:47,200 --> 00:19:48,880
can be exploited

567
00:19:48,880 --> 00:19:50,480
privacy threat assessments can become

568
00:19:50,480 --> 00:19:52,559
part of privacy risk management

569
00:19:52,559 --> 00:19:54,320
then system owners and operators can

570
00:19:54,320 --> 00:19:57,200
tailor their mitigation efforts to only

571
00:19:57,200 --> 00:19:58,799
to the vulnerabilities and flaws in

572
00:19:58,799 --> 00:20:00,559
their system that are most likely to be

573
00:20:00,559 --> 00:20:02,320
exploited those with the highest threat

574
00:20:02,320 --> 00:20:03,760
risk and they can do this in a

575
00:20:03,760 --> 00:20:05,760
data-driven way

576
00:20:05,760 --> 00:20:06,400
so

577
00:20:06,400 --> 00:20:08,799
like in cyber security we expect that

578
00:20:08,799 --> 00:20:10,400
threatened foreign privacy defense will

579
00:20:10,400 --> 00:20:11,919
be the next phase of privacy risk

580
00:20:11,919 --> 00:20:14,159
management

581
00:20:14,159 --> 00:20:16,320
so what's up um we're going to finish

582
00:20:16,320 --> 00:20:18,640
the first iteration of the taxonomy

583
00:20:18,640 --> 00:20:20,320
and the threat pattern generation we're

584
00:20:20,320 --> 00:20:22,720
generating a new data set not fdc and

585
00:20:22,720 --> 00:20:26,080
fcc cases but out of news publications

586
00:20:26,080 --> 00:20:28,720
we are going to map that new data set to

587
00:20:28,720 --> 00:20:32,080
our prototypes and we are going to

588
00:20:32,080 --> 00:20:33,919
adjust and stabilize them with this new

589
00:20:33,919 --> 00:20:36,240
data set of not just things that

590
00:20:36,240 --> 00:20:37,679
actually violate the law in the united

591
00:20:37,679 --> 00:20:39,360
states but things that cause privacy

592
00:20:39,360 --> 00:20:41,120
harm outside of things that violate the

593
00:20:41,120 --> 00:20:43,280
law

594
00:20:43,280 --> 00:20:44,080
so

595
00:20:44,080 --> 00:20:46,159
we're looking for people to get involved

596
00:20:46,159 --> 00:20:47,360
we're looking for data sets or

597
00:20:47,360 --> 00:20:49,200
information about privacy attacks we're

598
00:20:49,200 --> 00:20:51,200
looking for partners to beta test and we

599
00:20:51,200 --> 00:20:52,960
are looking for experts to give feedback

600
00:20:52,960 --> 00:20:55,919
on the taxonomy and the clusters

601
00:20:55,919 --> 00:20:57,679
and we're inviting everyone to join us

602
00:20:57,679 --> 00:20:59,440
at the privacy threat modeling workshop

603
00:20:59,440 --> 00:21:03,200
at soups this this august in boston

604
00:21:03,200 --> 00:21:05,360
so please go to our

605
00:21:05,360 --> 00:21:08,240
workshop website and register for soups

606
00:21:08,240 --> 00:21:10,159
and register for our workshop where we

607
00:21:10,159 --> 00:21:12,320
will be diving really deep into this

608
00:21:12,320 --> 00:21:14,240
work and into linden the other privacy

609
00:21:14,240 --> 00:21:16,240
threat model as well as hearing some

610
00:21:16,240 --> 00:21:19,600
really interesting papers presented

611
00:21:19,600 --> 00:21:23,639
so thank you guys all very much

