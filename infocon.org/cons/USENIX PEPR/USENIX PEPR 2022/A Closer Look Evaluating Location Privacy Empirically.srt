1
00:00:09,840 --> 00:00:10,559
hi

2
00:00:10,559 --> 00:00:12,240
this is olivia fan

3
00:00:12,240 --> 00:00:14,160
i am an assistant professor in computer

4
00:00:14,160 --> 00:00:17,119
science at unc charlotte

5
00:00:17,119 --> 00:00:19,039
today i'm going to talk about our

6
00:00:19,039 --> 00:00:23,359
evaluation of location privacy

7
00:00:26,560 --> 00:00:28,880
this talk is based on our recent paper

8
00:00:28,880 --> 00:00:32,238
at six spatial 2021.

9
00:00:32,238 --> 00:00:35,280
today i will also share new results

10
00:00:35,280 --> 00:00:39,440
generated after the paper's publication

11
00:00:41,360 --> 00:00:43,680
location data is critical to many

12
00:00:43,680 --> 00:00:46,399
applications and research studies

13
00:00:46,399 --> 00:00:47,680
for instance

14
00:00:47,680 --> 00:00:49,760
app users may receive recommendations

15
00:00:49,760 --> 00:00:52,879
based on their current location

16
00:00:52,879 --> 00:00:55,520
research studies may utilize gps traces

17
00:00:55,520 --> 00:00:57,440
collected from participants to

18
00:00:57,440 --> 00:01:00,960
understand their mental health

19
00:01:01,440 --> 00:01:04,400
while location data is extremely useful

20
00:01:04,400 --> 00:01:07,360
it is also personal and sensitive

21
00:01:07,360 --> 00:01:10,479
furthermore location data may be leaked

22
00:01:10,479 --> 00:01:12,640
a recent incident leaked data about

23
00:01:12,640 --> 00:01:16,720
consumers of all major cellular carriers

24
00:01:16,720 --> 00:01:19,280
therefore applications should pay close

25
00:01:19,280 --> 00:01:21,439
attention to the protection of consumer

26
00:01:21,439 --> 00:01:24,919
location privacy

27
00:01:26,080 --> 00:01:28,400
the research community has developed

28
00:01:28,400 --> 00:01:30,799
many location privacy methods

29
00:01:30,799 --> 00:01:33,040
a recent survey reviewed more than 60

30
00:01:33,040 --> 00:01:35,200
methods

31
00:01:35,200 --> 00:01:37,759
to ensure the depths of our study we

32
00:01:37,759 --> 00:01:40,000
focused on those methods that adopt a

33
00:01:40,000 --> 00:01:42,960
local privacy model and sanitize data in

34
00:01:42,960 --> 00:01:46,000
an online fashion

35
00:01:46,560 --> 00:01:48,960
the local model ensures the user relies

36
00:01:48,960 --> 00:01:51,680
on their own device to achieve privacy

37
00:01:51,680 --> 00:01:54,240
and send only sanitized locations out of

38
00:01:54,240 --> 00:01:56,560
their device

39
00:01:56,560 --> 00:01:58,960
users will have a great sense of control

40
00:01:58,960 --> 00:02:01,280
as they do not rely on any other parties

41
00:02:01,280 --> 00:02:04,479
to protect their privacy

42
00:02:05,119 --> 00:02:07,439
online privacy methods generate a

43
00:02:07,439 --> 00:02:09,758
sanitized location given the current

44
00:02:09,758 --> 00:02:11,200
location

45
00:02:11,200 --> 00:02:13,599
and or with historical data

46
00:02:13,599 --> 00:02:16,160
without knowing future places the user

47
00:02:16,160 --> 00:02:18,160
would visit

48
00:02:18,160 --> 00:02:20,879
the advantage of the online methods is

49
00:02:20,879 --> 00:02:23,200
that sanitized data can be shared with

50
00:02:23,200 --> 00:02:25,200
the server immediately

51
00:02:25,200 --> 00:02:26,959
which is helpful for real-time

52
00:02:26,959 --> 00:02:29,680
applications

53
00:02:30,400 --> 00:02:33,040
local online privacy methods hold great

54
00:02:33,040 --> 00:02:36,959
promises for practical deployment

55
00:02:36,959 --> 00:02:39,599
for one reason the setting is analogous

56
00:02:39,599 --> 00:02:42,160
to the local differential privacy model

57
00:02:42,160 --> 00:02:43,920
for non-location data

58
00:02:43,920 --> 00:02:47,599
adopted at google and apple

59
00:02:47,680 --> 00:02:50,480
in android users can choose to share

60
00:02:50,480 --> 00:02:53,519
less precise locations with apps

61
00:02:53,519 --> 00:02:55,680
which can be considered as a simplified

62
00:02:55,680 --> 00:02:59,599
approach to local online privacy

63
00:03:00,640 --> 00:03:02,879
lastly there have been research efforts

64
00:03:02,879 --> 00:03:04,879
to open source local online privacy

65
00:03:04,879 --> 00:03:07,599
methods to help developers integrate

66
00:03:07,599 --> 00:03:11,920
location privacy in their applications

67
00:03:14,720 --> 00:03:17,280
despite the promises and efforts

68
00:03:17,280 --> 00:03:19,360
there are significant challenges in

69
00:03:19,360 --> 00:03:22,319
adopting location privacy

70
00:03:22,319 --> 00:03:24,560
the first challenge is to understand the

71
00:03:24,560 --> 00:03:29,040
impact of location privacy on usefulness

72
00:03:29,040 --> 00:03:31,680
prior studies adopt simple utility

73
00:03:31,680 --> 00:03:32,959
measures

74
00:03:32,959 --> 00:03:34,799
such as distance between input and

75
00:03:34,799 --> 00:03:37,680
sanitized locations

76
00:03:37,680 --> 00:03:40,560
therefore it is not clear how location

77
00:03:40,560 --> 00:03:42,799
privacy may affect the usefulness of

78
00:03:42,799 --> 00:03:44,959
applications

79
00:03:44,959 --> 00:03:48,159
for example extracting mobility patterns

80
00:03:48,159 --> 00:03:51,440
from gps traces

81
00:03:52,319 --> 00:03:54,319
the second challenge is to understand

82
00:03:54,319 --> 00:03:57,599
the empirical privacy protection

83
00:03:57,599 --> 00:04:00,239
the privacy models of existing methods

84
00:04:00,239 --> 00:04:02,879
are not directly comparable

85
00:04:02,879 --> 00:04:05,519
for example data deletion

86
00:04:05,519 --> 00:04:07,599
versus adding dummies

87
00:04:07,599 --> 00:04:11,040
versus differential privacy based

88
00:04:11,040 --> 00:04:14,159
it is not yet clear how existing methods

89
00:04:14,159 --> 00:04:16,639
may mitigate practical attacks

90
00:04:16,639 --> 00:04:20,000
such as inference attacks

91
00:04:20,238 --> 00:04:22,320
the third challenge is to understand

92
00:04:22,320 --> 00:04:24,400
computational overheads of location

93
00:04:24,400 --> 00:04:26,000
privacy

94
00:04:26,000 --> 00:04:29,120
as privacy methods run on client devices

95
00:04:29,120 --> 00:04:31,440
overheads are very important factors for

96
00:04:31,440 --> 00:04:33,919
deployment but so far they are

97
00:04:33,919 --> 00:04:36,639
understudied

98
00:04:36,880 --> 00:04:38,880
the goals of our work is to address

99
00:04:38,880 --> 00:04:40,960
those challenges with an empirical

100
00:04:40,960 --> 00:04:45,440
evaluation of location privacy methods

101
00:04:47,680 --> 00:04:49,919
our study includes the following privacy

102
00:04:49,919 --> 00:04:52,320
methods that fit local and online

103
00:04:52,320 --> 00:04:54,160
criteria

104
00:04:54,160 --> 00:04:57,120
they fall under three categories

105
00:04:57,120 --> 00:04:59,440
first there are generalization based

106
00:04:59,440 --> 00:05:00,639
methods

107
00:05:00,639 --> 00:05:03,680
which report less accurate data

108
00:05:03,680 --> 00:05:05,440
one example method we show here is

109
00:05:05,440 --> 00:05:06,960
rounding

110
00:05:06,960 --> 00:05:09,360
every input data will be rounded to its

111
00:05:09,360 --> 00:05:12,560
nearest grid point

112
00:05:12,960 --> 00:05:14,880
the second category is perturbation

113
00:05:14,880 --> 00:05:16,320
based methods

114
00:05:16,320 --> 00:05:19,759
which introduce random noise in the data

115
00:05:19,759 --> 00:05:22,880
as an example the geo in notion is based

116
00:05:22,880 --> 00:05:24,880
on differential privacy and can be

117
00:05:24,880 --> 00:05:27,600
achieved with the laplace method showing

118
00:05:27,600 --> 00:05:29,280
this figure

119
00:05:29,280 --> 00:05:30,720
given an input

120
00:05:30,720 --> 00:05:33,520
a reported location can be drawn from

121
00:05:33,520 --> 00:05:37,198
the planar laplace distribution

122
00:05:37,440 --> 00:05:40,000
the third category is damien based

123
00:05:40,000 --> 00:05:42,400
where real location data is hidden among

124
00:05:42,400 --> 00:05:43,919
the dummies

125
00:05:43,919 --> 00:05:46,800
for example in the spot me method

126
00:05:46,800 --> 00:05:48,960
a user can claim to be at multiple

127
00:05:48,960 --> 00:05:52,160
locations simultaneously

128
00:05:52,160 --> 00:05:53,680
only one cell

129
00:05:53,680 --> 00:05:57,360
reflects the real location

130
00:06:00,400 --> 00:06:03,280
our empirical evaluation adopts two gps

131
00:06:03,280 --> 00:06:04,880
trace data sets

132
00:06:04,880 --> 00:06:07,120
generated via diverse transportation

133
00:06:07,120 --> 00:06:08,080
modes

134
00:06:08,080 --> 00:06:10,639
in order to evaluate location privacy

135
00:06:10,639 --> 00:06:14,400
in practical scenarios

136
00:06:14,639 --> 00:06:17,199
the geolife dataset includes data from

137
00:06:17,199 --> 00:06:19,520
participants in beijing

138
00:06:19,520 --> 00:06:21,840
where the real business dataset contains

139
00:06:21,840 --> 00:06:26,240
bus traces in rio de janeiro

140
00:06:26,240 --> 00:06:28,800
we perform spatial and temporal

141
00:06:28,800 --> 00:06:32,160
discretization in each dataset

142
00:06:32,160 --> 00:06:34,400
the two-dimensional geospace is

143
00:06:34,400 --> 00:06:37,520
partitioned into 300 meter by 300 meter

144
00:06:37,520 --> 00:06:39,120
grid cells

145
00:06:39,120 --> 00:06:42,000
and for each user we subsample their gps

146
00:06:42,000 --> 00:06:44,560
record for every five minutes

147
00:06:44,560 --> 00:06:46,800
and generate one trajectory for every

148
00:06:46,800 --> 00:06:48,560
day

149
00:06:48,560 --> 00:06:50,960
the number of trajectories per user

150
00:06:50,960 --> 00:06:53,360
and the number of unique locations that

151
00:06:53,360 --> 00:06:56,319
you each user visits very greatly as

152
00:06:56,319 --> 00:06:59,599
summarizing this table

153
00:06:59,599 --> 00:07:02,319
recently we evaluate the usefulness of

154
00:07:02,319 --> 00:07:04,639
location privacy methods in two new

155
00:07:04,639 --> 00:07:06,720
applications

156
00:07:06,720 --> 00:07:08,000
one

157
00:07:08,000 --> 00:07:10,319
detecting whether two users visit the

158
00:07:10,319 --> 00:07:12,800
same place at the same time

159
00:07:12,800 --> 00:07:15,360
which may benefit contact tracing and

160
00:07:15,360 --> 00:07:18,560
friendship discovery

161
00:07:18,800 --> 00:07:21,919
second measuring the user's exposure to

162
00:07:21,919 --> 00:07:24,400
air pollutants as the user travels in

163
00:07:24,400 --> 00:07:26,240
the space

164
00:07:26,240 --> 00:07:28,080
this may be extended to measure the

165
00:07:28,080 --> 00:07:30,479
user's exposure to neighborhood social

166
00:07:30,479 --> 00:07:35,120
disorder drug activities etc

167
00:07:35,599 --> 00:07:38,720
here we show the pm 2.5 levels for the

168
00:07:38,720 --> 00:07:40,479
city of beijing

169
00:07:40,479 --> 00:07:42,479
which will be used in conjunction with

170
00:07:42,479 --> 00:07:44,879
the geolife set

171
00:07:44,879 --> 00:07:47,520
we also collected air pollution data to

172
00:07:47,520 --> 00:07:51,359
use with real buses data set

173
00:07:54,560 --> 00:07:56,720
to evaluate the usefulness of location

174
00:07:56,720 --> 00:08:00,080
privacy we adopt generic record-level

175
00:08:00,080 --> 00:08:03,199
utility measures as well as task-based

176
00:08:03,199 --> 00:08:06,639
trace level utility measures

177
00:08:06,639 --> 00:08:09,360
first we include hamming distance and

178
00:08:09,360 --> 00:08:12,000
haverson distance between the input and

179
00:08:12,000 --> 00:08:15,199
sanitized locations

180
00:08:15,599 --> 00:08:18,800
also we extract seven trees level

181
00:08:18,800 --> 00:08:20,319
mobility patterns

182
00:08:20,319 --> 00:08:22,479
which were designed to predict mental

183
00:08:22,479 --> 00:08:23,759
health

184
00:08:23,759 --> 00:08:27,440
and we report their relative errors

185
00:08:27,440 --> 00:08:30,080
an average error among all the mobility

186
00:08:30,080 --> 00:08:33,679
patterns is also computed

187
00:08:34,479 --> 00:08:36,880
moreover we evaluated the usefulness of

188
00:08:36,880 --> 00:08:38,958
the sanitized location data for

189
00:08:38,958 --> 00:08:41,120
aggregated queries

190
00:08:41,120 --> 00:08:43,120
such as the visit frequency of each

191
00:08:43,120 --> 00:08:45,760
location and two-dimensional range

192
00:08:45,760 --> 00:08:48,240
queries

193
00:08:48,880 --> 00:08:51,519
in each experiment we vary the privacy

194
00:08:51,519 --> 00:08:54,000
parameter of every privacy method to

195
00:08:54,000 --> 00:08:58,320
observe its impact on utility

196
00:08:59,519 --> 00:09:02,080
based on the complete set of records we

197
00:09:02,080 --> 00:09:06,160
conclude that record level utility often

198
00:09:06,160 --> 00:09:07,839
but not always

199
00:09:07,839 --> 00:09:11,279
aligns with trace level utility

200
00:09:11,279 --> 00:09:13,680
we observe cases where a small

201
00:09:13,680 --> 00:09:16,320
distortion in each record may lead to a

202
00:09:16,320 --> 00:09:18,880
large distortion in trace level mobility

203
00:09:18,880 --> 00:09:21,880
patterns

204
00:09:24,720 --> 00:09:26,800
we evaluate the privacy methods on two

205
00:09:26,800 --> 00:09:29,920
new applications which represent a wider

206
00:09:29,920 --> 00:09:33,760
range of use cases for location data

207
00:09:33,760 --> 00:09:35,920
in the first application we detect

208
00:09:35,920 --> 00:09:38,959
co-locating users and report a number of

209
00:09:38,959 --> 00:09:40,959
accuracy measures

210
00:09:40,959 --> 00:09:43,600
one of them is false negative

211
00:09:43,600 --> 00:09:45,839
which counts those user pairs who

212
00:09:45,839 --> 00:09:47,040
co-locate

213
00:09:47,040 --> 00:09:48,959
but are missed by looking at their

214
00:09:48,959 --> 00:09:52,239
sanitized trajectories

215
00:09:52,480 --> 00:09:54,640
false negative errors are critical in

216
00:09:54,640 --> 00:09:56,880
context tracing

217
00:09:56,880 --> 00:09:59,760
and we can see most methods inflict

218
00:09:59,760 --> 00:10:01,360
false negatives

219
00:10:01,360 --> 00:10:05,279
except the rounding method

220
00:10:05,279 --> 00:10:07,279
in the second application we will

221
00:10:07,279 --> 00:10:09,839
measure the user's exposure to error

222
00:10:09,839 --> 00:10:10,959
pollutions

223
00:10:10,959 --> 00:10:13,360
and report errors for using sanitized

224
00:10:13,360 --> 00:10:17,760
trajectories as opposed to real data

225
00:10:17,760 --> 00:10:20,399
all methods inflict exposure azure

226
00:10:20,399 --> 00:10:24,079
errors to various extents

227
00:10:24,079 --> 00:10:26,720
the highest errors are observed in

228
00:10:26,720 --> 00:10:28,160
spatial cloaking

229
00:10:28,160 --> 00:10:30,240
which deletes real data for privacy

230
00:10:30,240 --> 00:10:33,240
protection

231
00:10:33,760 --> 00:10:36,079
from these results we observe that

232
00:10:36,079 --> 00:10:37,839
choosing the right methods and

233
00:10:37,839 --> 00:10:39,120
parameters

234
00:10:39,120 --> 00:10:44,120
is important for obtaining good utility

235
00:10:46,240 --> 00:10:48,959
we measure the empirical privacy risks

236
00:10:48,959 --> 00:10:51,760
with two privacy attacks

237
00:10:51,760 --> 00:10:54,640
one risk is re-identification

238
00:10:54,640 --> 00:10:56,720
where the attacker has some prior

239
00:10:56,720 --> 00:10:58,800
knowledge about a target and tries to

240
00:10:58,800 --> 00:11:01,200
re-identify the target in the sanitized

241
00:11:01,200 --> 00:11:03,279
data set

242
00:11:03,279 --> 00:11:06,640
specifically we check if a user can be

243
00:11:06,640 --> 00:11:08,480
uniquely re-identified

244
00:11:08,480 --> 00:11:10,560
when the attacker knows k of the

245
00:11:10,560 --> 00:11:13,600
target's location record

246
00:11:13,600 --> 00:11:16,079
and we find the smallest k to i

247
00:11:16,079 --> 00:11:19,279
re-identify each user

248
00:11:19,279 --> 00:11:22,160
in real data most of the users can be

249
00:11:22,160 --> 00:11:24,399
re-identified with no more than four

250
00:11:24,399 --> 00:11:26,160
locations

251
00:11:26,160 --> 00:11:29,600
some users are not unique labeled as

252
00:11:29,600 --> 00:11:31,920
nri

253
00:11:31,920 --> 00:11:34,079
in general after applying a location

254
00:11:34,079 --> 00:11:35,600
privacy method

255
00:11:35,600 --> 00:11:38,079
fewer users can be re-identified and

256
00:11:38,079 --> 00:11:42,760
more users become non-re-identifiable

257
00:11:43,440 --> 00:11:46,959
another risk is attribute inference

258
00:11:46,959 --> 00:11:49,519
here we assume a strong attacker

259
00:11:49,519 --> 00:11:50,720
who has

260
00:11:50,720 --> 00:11:52,959
all but one location

261
00:11:52,959 --> 00:11:55,279
of the target and tries to infer the

262
00:11:55,279 --> 00:11:58,560
last record from the data set

263
00:11:58,560 --> 00:12:01,760
in real data more than 90 of the users

264
00:12:01,760 --> 00:12:05,120
are susceptible to inference attacks

265
00:12:05,120 --> 00:12:08,399
after applying location privacy the risk

266
00:12:08,399 --> 00:12:13,040
can be reduced to various extents

267
00:12:14,560 --> 00:12:17,680
looking at our results we can conclude

268
00:12:17,680 --> 00:12:20,000
when configured properly

269
00:12:20,000 --> 00:12:22,959
both dp and traditional privacy methods

270
00:12:22,959 --> 00:12:25,920
can provide protection against privacy

271
00:12:25,920 --> 00:12:28,319
attacks

272
00:12:30,399 --> 00:12:32,399
when an anniversary has additional

273
00:12:32,399 --> 00:12:34,480
knowledge about the applied privacy

274
00:12:34,480 --> 00:12:37,200
method and parameter value

275
00:12:37,200 --> 00:12:38,560
it can launch

276
00:12:38,560 --> 00:12:40,639
improved attacks

277
00:12:40,639 --> 00:12:43,440
for example in re-identification the

278
00:12:43,440 --> 00:12:45,760
diversity can apply the same privacy

279
00:12:45,760 --> 00:12:47,760
method to the known locations of the

280
00:12:47,760 --> 00:12:49,200
target

281
00:12:49,200 --> 00:12:51,200
and they can match the sanitized

282
00:12:51,200 --> 00:12:53,519
locations

283
00:12:53,519 --> 00:12:54,880
from the results

284
00:12:54,880 --> 00:12:57,760
rounding is less effective against the

285
00:12:57,760 --> 00:12:59,760
improved attack

286
00:12:59,760 --> 00:13:02,639
the percentages of non-re-identifiable

287
00:13:02,639 --> 00:13:04,880
users is much lower

288
00:13:04,880 --> 00:13:07,200
and a significant amount of users can be

289
00:13:07,200 --> 00:13:10,000
re-identified at smaller k values

290
00:13:10,000 --> 00:13:13,600
compared to the basic attack

291
00:13:13,600 --> 00:13:15,040
we can conclude

292
00:13:15,040 --> 00:13:17,279
with an advanced adversary

293
00:13:17,279 --> 00:13:20,320
traditional deterministic methods may

294
00:13:20,320 --> 00:13:24,240
fail to protect user privacy

295
00:13:29,680 --> 00:13:31,760
to quantify the computational overheads

296
00:13:31,760 --> 00:13:34,399
of location privacy methods we measure

297
00:13:34,399 --> 00:13:37,519
the cpu time for sanitizing one location

298
00:13:37,519 --> 00:13:39,839
and the peak memory consumption by each

299
00:13:39,839 --> 00:13:41,519
method

300
00:13:41,519 --> 00:13:43,920
we show that all methods are very

301
00:13:43,920 --> 00:13:46,720
efficient in cpu time

302
00:13:46,720 --> 00:13:50,560
some methods such as spot me and vhc

303
00:13:50,560 --> 00:13:52,399
require larger memory

304
00:13:52,399 --> 00:13:54,240
as they maintain internal data

305
00:13:54,240 --> 00:13:56,800
structures

306
00:14:00,880 --> 00:14:02,480
the implementation of the studied

307
00:14:02,480 --> 00:14:05,440
privacy privacy methods is available in

308
00:14:05,440 --> 00:14:06,720
java

309
00:14:06,720 --> 00:14:08,880
application developers and researchers

310
00:14:08,880 --> 00:14:10,720
will find the complete set of results

311
00:14:10,720 --> 00:14:12,959
and discussions in the paper which will

312
00:14:12,959 --> 00:14:13,760
help

313
00:14:13,760 --> 00:14:16,000
comparatively evaluate those privacy

314
00:14:16,000 --> 00:14:18,399
methods

315
00:14:18,399 --> 00:14:19,760
to conclude

316
00:14:19,760 --> 00:14:23,120
our results show that generic utility

317
00:14:23,120 --> 00:14:25,440
often does not always aligns with

318
00:14:25,440 --> 00:14:28,079
task-based utility

319
00:14:28,079 --> 00:14:31,920
we find in basic attacks both dp methods

320
00:14:31,920 --> 00:14:34,160
and traditional privacy methods provide

321
00:14:34,160 --> 00:14:35,920
protection

322
00:14:35,920 --> 00:14:37,519
in approved attacks

323
00:14:37,519 --> 00:14:40,079
deterministic privacy methods may fail

324
00:14:40,079 --> 00:14:43,680
to provide adequate protection

325
00:14:43,680 --> 00:14:45,040
choosing the right methods and

326
00:14:45,040 --> 00:14:47,279
parameters is very important for

327
00:14:47,279 --> 00:14:49,600
reducing privacy risks as well as

328
00:14:49,600 --> 00:14:52,480
boosting utility

329
00:14:52,480 --> 00:14:55,040
many of the methods show low cpu and

330
00:14:55,040 --> 00:14:57,360
memory requirements which make them

331
00:14:57,360 --> 00:15:00,959
friendly to applications

332
00:15:01,920 --> 00:15:03,440
several students contributed to the

333
00:15:03,440 --> 00:15:05,519
project during their time at the

334
00:15:05,519 --> 00:15:07,680
research group

335
00:15:07,680 --> 00:15:09,600
this research has been supported in part

336
00:15:09,600 --> 00:15:12,639
by the national science foundation

337
00:15:12,639 --> 00:15:14,560
please feel free to reach out if you

338
00:15:14,560 --> 00:15:17,199
have any questions or comments

339
00:15:17,199 --> 00:15:20,439
thank you

340
00:15:26,800 --> 00:15:28,880
you

