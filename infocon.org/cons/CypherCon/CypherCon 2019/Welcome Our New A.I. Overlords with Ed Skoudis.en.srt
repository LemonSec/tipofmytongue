1
00:00:20,760 --> 00:00:30,020
Hello CypherCon. How's it going? It is wonderful to see you all here, what a great event this is. Thank

2
00:00:30,020 --> 00:00:32,659
you to the whole team that worked so
hard to put this together.

3
00:00:32,659 --> 00:00:36,919
Michel Goetzman who is in the back of the room not paying attention. And all the other folks,

4
00:00:36,920 --> 00:00:46,100
a round of applause, thank you. I would like
to present to you a talk, it's kind of a

5
00:00:46,100 --> 00:00:51,050
thick piece on kind of where things are
headed for our society. Where things are

6
00:00:51,050 --> 00:00:55,879
going headed for us as technologists. Some major changes that are going on. In this

7
00:00:55,880 --> 00:01:01,700
talk, there's stuff in here that's like from
every day news, just brand new things.

8
00:01:01,700 --> 00:01:07,399
It's called "I For One Welcome our New A.I.
Overlords: The Ultimate Insider in the

9
00:01:07,399 --> 00:01:11,600
Cloud". So how's that for a title? You're hitting all  these buzzwords right? You got A.I., insider,

10
00:01:11,600 --> 00:01:15,559
cloud. Oh yes,
that's where we're going. For those of you

11
00:01:15,560 --> 00:01:24,650
I haven't met, my name is Ed, I'm a hacker. (Hi Ed) I have a company called Counter Hack. Counter Hack does penetration

12
00:01:24,650 --> 00:01:28,909
testing, but we also build simulations.
Maybe you're familiar with some of them,

13
00:01:28,909 --> 00:01:32,540
we do Net Wars. Anybody here do Net Wars? As this my team they say.

14
00:01:32,540 --> 00:01:42,770
Cyber City? Well that's wonderful. That's
my team that builds all that stuff. I'm a

15
00:01:42,770 --> 00:01:46,670
pen tester, I'm an instructor with the
SANS Institute. I'm also heading up a new

16
00:01:46,670 --> 00:01:50,000
thing we're doing it SANS on
team-based training. Where people will

17
00:01:50,000 --> 00:01:54,049
learn how to participate in highly technical
things working as a team, because let's

18
00:01:54,049 --> 00:01:59,030
face it, you don't fight alone, we all fight
as part of our teams. And I'm a father

19
00:01:59,030 --> 00:02:03,770
and kind of a weirdo. So, does anybody
know where the title of this talk comes

20
00:02:03,770 --> 00:02:10,039
from? I for one... The Simpsons, yes. Do
you remember that?The Sim... I for one

21
00:02:10,039 --> 00:02:15,320
welcome our new robot overlords. Well
let's, let's take a look. I'll play

22
00:02:15,320 --> 00:02:19,579
this video for you and I hope we got the
audio up enough that you can hear it. So

23
00:02:19,580 --> 00:02:22,540
here we go. [Kent Brockman from the Simpsons talking] We're just about to get our first

24
00:02:22,540 --> 00:02:33,380
pictures from inside the spacecraft with
averagenot Homer Simpson. And we'd like,  AGGGGHHH. Ladies and gentlemen, we've just

25
00:02:33,390 --> 00:02:37,440
lost the picture. [Ed Skoudis] To give you some context, what happened is Homer Simpson

26
00:02:37,440 --> 00:02:43,020
goes up as a an average person on a
spaceship that's orbiting the planet and

27
00:02:43,020 --> 00:02:47,730
along with him are these, this colony of
tiny little ants. Now, Homer being Homer,

28
00:02:47,730 --> 00:02:52,649
wants these potato chips in zero gravity.
And he does, but he accidentally smashes

29
00:02:52,650 --> 00:02:58,050
into the tiny ant colony. So the ants start
floating around. And you just saw, an ant floated

30
00:02:58,050 --> 00:03:02,880
right up by the camera, causing Kent
Brockman to think it is a mutant race of

31
00:03:02,880 --> 00:03:09,320
giant ants. Mayhem ensues. [Kent Brockman] But what we've seen speaks for itself.

32
00:03:09,320 --> 00:03:13,299
The spacecraft has been apparently  taken over, conquered if you will

33
00:03:13,300 --> 00:03:17,280
by a master race of giant space ants.

34
00:03:17,280 --> 00:03:22,960
It's difficult to tell from this vantage point weather they will consume the captive  Earth men or merely enslave them.

35
00:03:22,960 --> 00:03:25,840
[Ed Skoudis] So this is a really, I have an amazing example now. If you

36
00:03:25,840 --> 00:03:28,800
consider all the stuff that comes out in
the news today, right? There'll be some

37
00:03:28,800 --> 00:03:32,220
sort of half story next thing you know
the news is doing all kinds of detailed

38
00:03:32,220 --> 00:03:35,489
analysis of where this is headed and all
this kind of stuff. The Simpsons had

39
00:03:35,489 --> 00:03:42,020
fake news 20 years ago. [Kent Brockman]  One thing is for certain, there is no stopping them, the ants will soon be here.

40
00:03:42,020 --> 00:03:49,320
And I for one welcome our new insect overlords. I'd like to remind them as a trusted TV personality

41
00:03:49,320 --> 00:03:54,220
I can be helpful in the running of others to toil around in their underground sugar caves.

42
00:03:55,340 --> 00:03:59,280
[Ed Skoudis] Seems legit, right? So I for one welcome our A.I. overlords.

43
00:03:59,280 --> 00:04:02,840
I know we're recording this and I just want
you to know I'm here for you. I can help

44
00:04:02,850 --> 00:04:07,220
round these people up so they can toil
for you in your underground sugar caves.

45
00:04:07,220 --> 00:04:13,950
So with that said, let's, let's start out
by talking about the cloud and cloud

46
00:04:13,950 --> 00:04:18,930
based data storage. I'll move into A.I. and
privacy applications. Building on top of

47
00:04:18,930 --> 00:04:23,440
this. So Amazon S3 buckets. Anybody here
using Amazon S3 buckets in

48
00:04:23,440 --> 00:04:29,410
their structure? Yeah a lot of people are. I imagined you would. Microsoft Azure cloud storage? Some folks too? Wow just as many.

49
00:04:29,410 --> 00:04:33,340
Interesting, interesting. Um and then Google Cloud Storage? Anybody using that?

50
00:04:33,340 --> 00:04:38,349
Okay yeah, very, very good. These are, these are amazing, amazing infrastructures.

51
00:04:38,350 --> 00:04:42,370
Really quite incredible. You could store
hundreds or thousands of terabytes quite

52
00:04:42,370 --> 00:04:48,700
affordably. What could possibly go wrong?
Well, in cloud based data breaches we've

53
00:04:48,700 --> 00:04:53,500
had some big issues. In the last two
years there's been a huge flurry of

54
00:04:53,500 --> 00:04:57,790
cloud based data breeches that are entirely
associated with just taking some sets of

55
00:04:57,790 --> 00:05:03,250
data, putting it into maybe say an S3
bucket and not properly marketing it as

56
00:05:03,250 --> 00:05:06,520
private, and exposing that to the entire
internet. So people are trolling around

57
00:05:06,520 --> 00:05:10,210
looking to find these kinds of things.
Back in October 2016 did you see this

58
00:05:10,210 --> 00:05:14,799
one it was a breach of Hoover so what
happened there is some attackers hacked

59
00:05:14,800 --> 00:05:19,930
into a github account associated with
some uber developers from there they

60
00:05:19,930 --> 00:05:24,880
grabbed some credentials that keep some
access to others s3 bucket and then from

61
00:05:24,880 --> 00:05:29,830
there they were able to access 5757
million records for passengers and

62
00:05:29,830 --> 00:05:34,270
drivers very next month in September
2017 United States Army exposed to 100

63
00:05:34,270 --> 00:05:38,169
gigabytes of very sensitive military
data just by putting it in a public

64
00:05:38,169 --> 00:05:43,570
Amazon s3 bucket and focused on Amazon
s3 buckets here because primarily the

65
00:05:43,570 --> 00:05:47,380
breach activity we see has been on that
in February 2018

66
00:05:47,380 --> 00:05:52,870
bombo's over by Federal Express expose
119,000 scanned drivers licenses oh

67
00:05:52,870 --> 00:05:56,770
that's interesting and then it was just
reported a couple days ago Facebook data

68
00:05:56,770 --> 00:06:01,060
from an organization called cultura
collective I had an s3 bucket it was

69
00:06:01,060 --> 00:06:06,610
marked as public for
540 million users exposed now this is

70
00:06:06,610 --> 00:06:10,750
stuff that was not sensitive it was just
in their normal Facebook beats but all

71
00:06:10,750 --> 00:06:15,460
of their comments all of their lights
all of their profiles right they're all

72
00:06:15,460 --> 00:06:19,630
sort of in
multi terabyte file for 550 million

73
00:06:19,630 --> 00:06:24,460
users I get access to it we just go to a
public s3 bucket and you could have been

74
00:06:24,460 --> 00:06:28,239
yours hmm
Wow so most of this like I said it is

75
00:06:28,240 --> 00:06:32,830
due to miss configuration that's it now
let's just say hypothetically speaking

76
00:06:32,830 --> 00:06:38,770
you're the richest person in the world
ok and a bunch of people are finding

77
00:06:38,770 --> 00:06:42,729
miss configurations associated with one
of the products that you offer that's

78
00:06:42,730 --> 00:06:45,910
kind of bad for your brand that kind of
hurts that doesn't look so good so we

79
00:06:45,910 --> 00:06:52,720
know anybody you spend money yes you
spend money to try to fix the problem so

80
00:06:52,720 --> 00:06:56,050
you buy other companies that are doing
kind of this kind of thing to help

81
00:06:56,050 --> 00:07:01,300
protect this stuff at scale security in
the hard security and security the cloud

82
00:07:01,300 --> 00:07:05,440
security is hard right I mean we know
that we all work trying as hard as we

83
00:07:05,440 --> 00:07:10,480
can to secure things and doing it at
cloud scale is really hard but there are

84
00:07:10,480 --> 00:07:15,610
some unique aspects of the cloud that we
might be able to leverage to actually

85
00:07:15,610 --> 00:07:21,550
turn the tide in the favor of cyber
defenders multi-tenancy specifically so

86
00:07:21,550 --> 00:07:26,110
an attack against your bucket might
actually be able to tip things off so

87
00:07:26,110 --> 00:07:29,830
that we can defend my bucket
appropriately you see there's lots of

88
00:07:29,830 --> 00:07:34,990
information to determine what normal
aspects of access are so we can look for

89
00:07:34,990 --> 00:07:41,560
deviations from the norm and the AV guy
370 I'm sorry I apologize all right so

90
00:07:41,560 --> 00:07:46,740
the point here is your detection of
anomalies in your environment becomes my

91
00:07:46,740 --> 00:07:50,950
prevention or at least it feeds my
prevention this is fantastic

92
00:07:50,950 --> 00:07:55,630
oh and we have a bunch of big very rich
companies I mean we live in a Gilded Age

93
00:07:55,630 --> 00:08:00,820
of high-tech companies right very rich
companies with lots of a guy's smarts

94
00:08:00,820 --> 00:08:04,090
artificial intelligence that they can
roll into helping us solve the problem

95
00:08:04,090 --> 00:08:09,280
so there are three specific cloud
providers I want to focus on for this

96
00:08:09,280 --> 00:08:11,739
time there are many other cloud
providers I understand if you work for

97
00:08:11,740 --> 00:08:14,560
one of them
I offend you but here are three of the

98
00:08:14,560 --> 00:08:18,669
biggest and these are the ones that are
spending some money on AI to try to

99
00:08:18,669 --> 00:08:21,820
defend in the cloud I'd like to go
through each of their offerings and kind

100
00:08:21,820 --> 00:08:25,930
of compare and contrast I'm gonna talk
about Amazon Macy Microsoft is your

101
00:08:25,930 --> 00:08:30,850
threat detection Google Google clouds a
data loss prevention API so let's look

102
00:08:30,850 --> 00:08:33,580
at each one of those three
the first examines I may see anybody

103
00:08:33,580 --> 00:08:36,490
here using Amazon may see many of you
said you're using this three buckets so

104
00:08:36,490 --> 00:08:40,390
you haven't put the switch on that one
yet well let's talk about what it is it

105
00:08:40,390 --> 00:08:45,580
goes through your native you configure
it in your Amazon account and it'll

106
00:08:45,580 --> 00:08:50,260
start combing through your data looking
for what it thinks is your most

107
00:08:50,260 --> 00:08:54,279
sensitive data it is applying machine
learning and AI to try to find way to

108
00:08:54,279 --> 00:08:58,450
things you should care most about and it
won't label it as such for you it's

109
00:08:58,450 --> 00:09:02,589
looking for PD is looking for
intellectual property that uses Amazon's

110
00:09:02,589 --> 00:09:08,560
Cloud Watch thank you for them amazon's
cloud watch to look for anomalous access

111
00:09:08,560 --> 00:09:13,119
to what your most sensitive data is
think about this our overlords they comb

112
00:09:13,120 --> 00:09:15,339
through your data because you can't comb
through it there's just way too much of

113
00:09:15,339 --> 00:09:19,720
it and tries to find was the most
sensitive data finger and it will

114
00:09:19,720 --> 00:09:24,520
monitor access of it for you I find the
pricing models of the three different

115
00:09:24,520 --> 00:09:28,660
offerings I'm going to describe to you
one for Amazon one for myself and one

116
00:09:28,660 --> 00:09:32,589
for Google are fascinating because they
illustrate the mindset of I think each

117
00:09:32,589 --> 00:09:37,779
of these companies for Amazon may see
the prices five dollars per gigabyte of

118
00:09:37,779 --> 00:09:43,300
data protected plus four dollars for
100,000 events analyzed so notice the

119
00:09:43,300 --> 00:09:49,180
pricing month is based on the Danian
you'll see that Microsoft and Google's

120
00:09:49,180 --> 00:09:52,239
are not based on the data it's based on
the day how much name you got how many

121
00:09:52,240 --> 00:09:55,930
events to be looking all right here's
some more on Amazon may see some of the

122
00:09:55,930 --> 00:10:00,640
logs and it generates you can see access
events and what is happening inside the

123
00:10:00,640 --> 00:10:04,180
environment also you see automated
alerts saying he's somebody granted

124
00:10:04,180 --> 00:10:09,209
rights to everyone on this you might not
want that right that kind of thing cool

125
00:10:09,209 --> 00:10:13,599
let's look at Microsoft in Microsoft
does your sequel database there at

126
00:10:13,600 --> 00:10:17,540
detection
it uses machine learning on cloud bases

127
00:10:17,540 --> 00:10:22,160
Microsoft sequel server instances to
look for anomalous access it's looking

128
00:10:22,160 --> 00:10:26,930
for things like the tags you know like a
sequel injection anomalous queries it

129
00:10:26,930 --> 00:10:30,199
determines what is normal access for
your given set of sequel server

130
00:10:30,200 --> 00:10:35,830
databases and looks for deviations from
that norm pretty cool the price is $15

131
00:10:35,830 --> 00:10:40,220
per database in other words this pricing
model looks like it came from a company

132
00:10:40,220 --> 00:10:44,840
that is used to writing software for
databases and selling software for

133
00:10:44,840 --> 00:10:48,680
databases so it charges you per database
not surprising comes from it--your

134
00:10:48,680 --> 00:10:53,810
something right there not and then we
have Google's data loss prevention API

135
00:10:53,810 --> 00:11:01,280
again using machine learning to look for
strange flows of data inside Google's

136
00:11:01,280 --> 00:11:05,569
own environment it looks for context
clues to identify 70 types of very

137
00:11:05,570 --> 00:11:08,960
specific kind of personally identifiable
information Social Security numbers

138
00:11:08,960 --> 00:11:13,730
driver's license numbers credit card
numbers and more you integrate it within

139
00:11:13,730 --> 00:11:19,940
your own applications that you build on
top of Google so the pricing model here

140
00:11:19,940 --> 00:11:25,340
is really complicated I don't have a
long time to do this talk here I think

141
00:11:25,340 --> 00:11:28,310
anybody half hour to go through their
pricing model which kind of like this

142
00:11:28,310 --> 00:11:31,400
has proved more anxious either they give
it away for free or so complicated you

143
00:11:31,400 --> 00:11:33,860
won't understand it but yokas cheap
enough so everything just works out

144
00:11:33,860 --> 00:11:39,680
right the pricing model is based on
inspection units and transformation

145
00:11:39,680 --> 00:11:46,310
units and you make API calls into them
they give you 10 DP units for free and

146
00:11:46,310 --> 00:11:50,630
after that it's 30 cents per keeping
unit so how often in calling the API

147
00:11:50,630 --> 00:11:55,970
this model looks like it was created by
a software as a service provider who

148
00:11:55,970 --> 00:12:00,410
wants you to use their API so they're
gonna charge you based on API calls so

149
00:12:00,410 --> 00:12:04,069
notice the three miles and the sign is
charging based on data

150
00:12:04,070 --> 00:12:08,960
Microsoft is charging your based on
database servers which is kind of

151
00:12:08,960 --> 00:12:12,770
interesting way to do it and then Google
space it on API calls that you make each

152
00:12:12,770 --> 00:12:16,189
kind of fits into where you think
they're coming from I mean with respect

153
00:12:16,190 --> 00:12:20,050
to what I think actually
what we're trying to protect I think

154
00:12:20,050 --> 00:12:23,560
Amazon smart donate interesting this but
I think Amazon smile try to protect data

155
00:12:23,560 --> 00:12:26,800
I mean also they didn't today I don't
care how many databases my data is in

156
00:12:26,800 --> 00:12:29,800
and we even want to think about
databases when I go to the cloud right

157
00:12:29,800 --> 00:12:33,400
I'm in the cloud for a reason but anyway
those are those three four months all

158
00:12:33,400 --> 00:12:38,410
apply machine learning all applying ai
to look for animals access notice though

159
00:12:38,410 --> 00:12:41,829
they've only Amazon's is focused on
helping you identify where your most

160
00:12:41,830 --> 00:12:46,570
sensitive data is it's crawling through
all of your data so let's think about

161
00:12:46,570 --> 00:12:50,830
that so anti tolls are analyzing your
data determine what should be important

162
00:12:50,830 --> 00:12:55,480
to you and they're helping monitoring to
see what support team getting visibility

163
00:12:55,480 --> 00:12:59,710
into whether the access is an element
that was but what if your business

164
00:12:59,710 --> 00:13:03,760
competes with Amazon and you might say
well we don't compete with Amazon

165
00:13:03,760 --> 00:13:10,270
are you sure and also you should say oh
we don't compete with Amazon yet right

166
00:13:10,270 --> 00:13:13,540
because and the Sun is moving here so
many business a look inside we've got

167
00:13:13,540 --> 00:13:17,800
Netflix right Netflix has built itself
they're increasing trying to wean

168
00:13:17,800 --> 00:13:23,199
themselves off of the AWS infrastructure
but Amazon Netflix built itself on the

169
00:13:23,200 --> 00:13:27,760
AWS infrastructure and we build stuff on
AWS in my own company and how they have

170
00:13:27,760 --> 00:13:32,290
Travis 2015 ethic is running on AWS it's
fantastic it's wonderful but do you

171
00:13:32,290 --> 00:13:36,640
compete with them if you're in the
retail space you compete with Amazon and

172
00:13:36,640 --> 00:13:41,439
thanks probably also use them as this
review distribution model too and if

173
00:13:41,440 --> 00:13:45,820
you're in other spaces I mean you see
Amazon's and Whole Foods right so

174
00:13:45,820 --> 00:13:48,640
there's a grocery that's a form of
retail but they're also getting

175
00:13:48,640 --> 00:13:53,410
increasingly into they're exploring
doing things like pharmaceuticals so

176
00:13:53,410 --> 00:13:55,780
that's interesting so if you do
pharmaceuticals they might get

177
00:13:55,780 --> 00:13:58,870
distribution channel for you and a
competitor at the same time and Sun is

178
00:13:58,870 --> 00:14:01,900
moving so aggressively to so many
different businesses who's to say

179
00:14:01,900 --> 00:14:04,839
whether you compete with them now or
you're going to compete with them in the

180
00:14:04,839 --> 00:14:07,000
future
if you're what my other probably pretty

181
00:14:07,000 --> 00:14:11,260
good and I'd like to show you this tweet
anybody here familiar with the Twitter

182
00:14:11,260 --> 00:14:16,850
account of Goldman Sachs elevator think
we've seen that it's it's a pain

183
00:14:16,850 --> 00:14:21,739
account of this person who he doesn't
really work the goldman sachs but he

184
00:14:21,739 --> 00:14:25,459
imagines if you're in the elevator a
goldman sachs is very big very rich

185
00:14:25,459 --> 00:14:29,388
coming what might you over here in the
other bin it's hilarious occasionally

186
00:14:29,389 --> 00:14:32,389
it's not safe for work so you know but
what i'm going to show you is it safe

187
00:14:32,389 --> 00:14:37,939
for life work on this tweet what i saw
them like yes exactly thinking about

188
00:14:37,939 --> 00:14:42,049
amazon where it's headed
you ready if Amazon is in your line of

189
00:14:42,049 --> 00:14:46,999
business sound now if Amazon it's not
your line of business sell now your

190
00:14:46,999 --> 00:14:51,559
business sucks there you go noise
Amazon's moving into everybody's

191
00:14:51,559 --> 00:14:56,569
business if it's any good if it's not
enjoy your 3% profit margins okay or if

192
00:14:56,569 --> 00:15:00,259
they do enter into your business they're
going to squeeze your profit margins

193
00:15:00,259 --> 00:15:06,559
down even further so a way to think
about the big four companies that are

194
00:15:06,559 --> 00:15:11,118
providing these machine language serve
the machine learning services along with

195
00:15:11,119 --> 00:15:15,379
a nine so forth mix thing I saw this
fantastic article I created this

196
00:15:15,379 --> 00:15:18,259
visualization of this article was
written by Scott Galloway who's a

197
00:15:18,259 --> 00:15:22,369
professor NYU and it helps me to think
about the different companies cuz

198
00:15:22,369 --> 00:15:25,729
there's the big four and I'll go for
what before are in just a minute but the

199
00:15:25,729 --> 00:15:29,959
big four companies that provide this
kind of stuff it helps you sort them out

200
00:15:29,959 --> 00:15:33,289
based on the different models that they
have and the different things that

201
00:15:33,289 --> 00:15:38,239
they're appealing to him so we'll start
with this Google Google's your brain or

202
00:15:38,239 --> 00:15:43,039
your mind is what you think about what
you want to learn about what where your

203
00:15:43,039 --> 00:15:46,639
kind of mind is going
that's that's Google right have you put

204
00:15:46,639 --> 00:15:52,489
that stuff into their search engine and
it learns about you and customizes its

205
00:15:52,489 --> 00:15:58,970
results based on what's in your mind
fair enough Facebook is your heart right

206
00:15:58,970 --> 00:16:02,779
it's how you communicate with your mom
or your dad or grandma or grandpa it's

207
00:16:02,779 --> 00:16:05,809
it's how you communicate maybe with your
siblings and certainly your friends want

208
00:16:05,809 --> 00:16:09,559
to see what they're up to
it's your heart Adamson's your belly

209
00:16:09,559 --> 00:16:12,829
it's the thing that you need the feeds
the things that's all we need as I would

210
00:16:12,829 --> 00:16:16,459
buy this and Amazon doesn't want put
anything between you and your ability to

211
00:16:16,459 --> 00:16:20,839
fill your belly or your desires
one-click shopping

212
00:16:20,839 --> 00:16:24,449
that's like crap right I would say we
had for so long around first

213
00:16:24,449 --> 00:16:28,378
you know they're like one thing shopping
seriously and that was like if you don't

214
00:16:28,379 --> 00:16:31,769
take one-click shopping you're you're
offended you go to some retailer that's

215
00:16:31,769 --> 00:16:35,819
not Amazon you say I gotta click a
couple of buttons or heaven forbid solve

216
00:16:35,819 --> 00:16:39,779
a CAPTCHA before I buy something
Japanese oh it's not gonna be you song

217
00:16:39,779 --> 00:16:43,350
captured before you buy something he
wants to be as close to your belly and

218
00:16:43,350 --> 00:16:48,720
your wallet as possible so these are
three of the big four Google is your

219
00:16:48,720 --> 00:16:52,199
brain
Facebook is your heart Amazon is your

220
00:16:52,199 --> 00:16:59,849
belly and who's the fourth just isolate
responding movies going Apple according

221
00:16:59,850 --> 00:17:05,309
to Scott Galloway is your sensuality
it's the thing that defines sexiness and

222
00:17:05,309 --> 00:17:10,260
technology for you guys I'll use another
say now maybe nobody down or I use some

223
00:17:10,260 --> 00:17:13,349
other event it's like that's fine in
other words you're buying the stuff that

224
00:17:13,349 --> 00:17:16,859
look like emilie's products did two
years ago right so it was apples

225
00:17:16,859 --> 00:17:20,250
defining what looks sexy from a
technology perspective you might not be

226
00:17:20,250 --> 00:17:24,119
paying the Apple tax but it used to
finding what that is in pushing that

227
00:17:24,119 --> 00:17:28,079
forward Jonathan I and in all the folks
doing that so it's a way to think about

228
00:17:28,079 --> 00:17:33,178
the big four and if you think about that
before each of these employees machine

229
00:17:33,179 --> 00:17:37,289
learning and artificial intelligence to
provide a series of services to you

230
00:17:37,289 --> 00:17:41,760
right I mean we obviously have Google
home Facebook it's analyzing everything

231
00:17:41,760 --> 00:17:46,710
you do to try to make sure you spend
more time on Facebook right Amazon

232
00:17:46,710 --> 00:17:50,309
analyzing everything that you purchase
and all your your activities there and

233
00:17:50,309 --> 00:17:55,649
then you have we called her Alice in my
office because if we say amvx eighty

234
00:17:55,649 --> 00:18:00,029
word we were spelling in themself the oh
hey Alexa I can say that right she she

235
00:18:00,029 --> 00:18:04,169
triggers so in my office because I have
some of these devices we always say

236
00:18:04,169 --> 00:18:09,510
Alice we were not trying to summon syrup
right just paid Alice Alice I think

237
00:18:09,510 --> 00:18:12,779
let's do a little survey here before you
to Apple Apple of course has its series

238
00:18:12,779 --> 00:18:17,340
technology but just seeing how many of
you guys have how many of these devices

239
00:18:17,340 --> 00:18:21,209
and beyond the spanis about this how
many people here have at least one

240
00:18:21,210 --> 00:18:25,500
google home device reject at one google
oh okay keep your hand up if this

241
00:18:25,500 --> 00:18:32,179
applies how many have at least two three
or

242
00:18:32,179 --> 00:18:37,350
okay if there's been enhanced level 5 so
5 so yeah there's couple that had three

243
00:18:37,350 --> 00:18:39,879
four
than 105 anybody more than okay let's

244
00:18:39,880 --> 00:18:47,260
let's pump up let's go to Alice Alexa
how many people have at least one echo

245
00:18:47,260 --> 00:18:51,340
device in their home I'm having him at
least two it looks like I might hand out

246
00:18:51,340 --> 00:19:02,980
this how many three or four or five or
more down a floor six seven all right so

247
00:19:02,980 --> 00:19:06,340
we got a couple of sixes in a seven you
wait Sarah where you lose it you see

248
00:19:06,340 --> 00:19:10,689
where this is going hi and now Siri this
thing is serious built-in to your

249
00:19:10,690 --> 00:19:14,710
phone's right they look like you have
Alice on my phone - I didn't count that

250
00:19:14,710 --> 00:19:19,330
but if you count Syria naval devices for
which you actually use Siri

251
00:19:19,330 --> 00:19:23,770
okay I'm not say oh you know my kids
have you know an iPad or something like

252
00:19:23,770 --> 00:19:27,250
that happen that they have a new serie
don't come back how many people actively

253
00:19:27,250 --> 00:19:38,230
Siri on at least one of us two three
four five yeah I'm about four or five on

254
00:19:38,230 --> 00:19:41,890
that whose name yeah okay go over so
we're into this we are we're

255
00:19:41,890 --> 00:19:45,010
technologists it's interesting
technology and it's way to think about

256
00:19:45,010 --> 00:19:50,680
the business for now do you trust these
companies and their artificial

257
00:19:50,680 --> 00:19:55,690
intelligence in their sleep oh no and
anyway here's the time okay so let me

258
00:19:55,690 --> 00:20:00,160
just show you some photos just random
photos I managed to collect here and

259
00:20:00,160 --> 00:20:05,370
there
ah this photo does they paid off this is

260
00:20:05,370 --> 00:20:13,360
sundar pichai yes and what is it I'm
sort of trying to do he's the CEO CEO of

261
00:20:13,360 --> 00:20:16,959
alphabet right we shan't have Chrome's
this little company called Google that's

262
00:20:16,960 --> 00:20:22,120
right does anybody know what this this
still is taken from this movie oh then

263
00:20:22,120 --> 00:20:26,050
leapt out of Google
yeah I was last year this video leaked

264
00:20:26,050 --> 00:20:29,460
that was put on a breadboard comment
but then it made its problems throughout

265
00:20:29,460 --> 00:20:34,049
everything this was some done within a
couple of days of the 2016 election it

266
00:20:34,049 --> 00:20:39,480
was Google's senior management talking
about what it is that happened how their

267
00:20:39,480 --> 00:20:44,700
platform was used how unhappy they were
with how their platform was used it

268
00:20:44,700 --> 00:20:47,370
association with the election and how
they said they're going to make sure

269
00:20:47,370 --> 00:20:54,600
that that will never happen again
interesting video next we know this

270
00:20:54,600 --> 00:21:03,870
person is it's not commander data
Australia this is mr. Mark Zuckerberg

271
00:21:03,870 --> 00:21:08,489
anybody know where this still is taken
from their congressional hearings which

272
00:21:08,490 --> 00:21:12,870
was right do you notice that every two
or three years sometimes even more often

273
00:21:12,870 --> 00:21:18,168
gets called up to testify for congress
and apologize that his entire career is

274
00:21:18,169 --> 00:21:23,340
apologizing for privacy violations from
the very start from before Facebook

275
00:21:23,340 --> 00:21:28,379
itself was created right so this is him
a year ago he was also up there couple

276
00:21:28,380 --> 00:21:33,980
weeks ago right but a year ago he was
apologizing for the Cambridge analytic

277
00:21:33,980 --> 00:21:40,020
disclosure that was only a year ago it
seems so long them do you remember what

278
00:21:40,020 --> 00:21:49,049
happened I'm gonna get into a little bit
more detail later yes there's old and

279
00:21:49,049 --> 00:21:54,450
all that but it was done I mean they so
apparently they tried according to the

280
00:21:54,450 --> 00:21:58,080
head of the the person who's in charge
the project at Cato gentleman ago they

281
00:21:58,080 --> 00:22:03,149
tried to shock their technology for
doing very detailed analysis of social

282
00:22:03,149 --> 00:22:06,539
networking graphs and likes and dislikes
all that kind of stuff

283
00:22:06,539 --> 00:22:11,580
they tried shopping around primarily to
Democrats in the 2016 election and

284
00:22:11,580 --> 00:22:14,490
Duncan said no we got this I mean we've
got a bunch engineers from Google that

285
00:22:14,490 --> 00:22:17,279
are helping us we don't need that your
small company you never heard of you and

286
00:22:17,279 --> 00:22:20,730
they're like okay so I went to the Trump
campaign and said you want us to use

287
00:22:20,730 --> 00:22:26,019
this they're like well how much okay
you never know if I'm any buzz let's try

288
00:22:26,019 --> 00:22:30,100
it so they tried it and they found all
kinds of very interesting correlations

289
00:22:30,100 --> 00:22:35,110
and analysis and so forth and this all
came out in March of 2018 just a little

290
00:22:35,110 --> 00:22:39,939
over a year ago of how they were able to
do data analytics based on likes and

291
00:22:39,940 --> 00:22:45,549
dislikes to be able to understand
correlations that maybe from a human

292
00:22:45,549 --> 00:22:51,190
perspective don't make sense but
politicians can use them they've got all

293
00:22:51,190 --> 00:22:55,929
kinds of weird stuff they found out that
you liked Nike shoes I'm just telling

294
00:22:55,929 --> 00:22:59,860
what their corner if you like Nike shoes
there was an increased possibility that

295
00:22:59,860 --> 00:23:06,279
you would have also liked the expression
I need Israel what why what is it and

296
00:23:06,279 --> 00:23:10,179
the positions don't care who cares
because all they care about is they

297
00:23:10,179 --> 00:23:12,970
might want you to know I'm gonna put
stuff in your timeline that says you

298
00:23:12,970 --> 00:23:16,330
should go up oh and if I don't watch it
because you disapprove under some new

299
00:23:16,330 --> 00:23:19,480
timeline says you should know another
correlation they found very similar one

300
00:23:19,480 --> 00:23:26,830
if you like KitKat bars you were more
likely to like the I hate Israel ie what

301
00:23:26,830 --> 00:23:31,000
what is it with KitKat bars all that
looking for is correlation they don't

302
00:23:31,000 --> 00:23:35,230
care why it doesn't have anything other
than they're trying to determine do we

303
00:23:35,230 --> 00:23:38,260
want these people who vote or do we not
about these people to vote and then

304
00:23:38,260 --> 00:23:42,340
we'll spend money trying to get people
to vote or not to vote it's crazy so

305
00:23:42,340 --> 00:23:48,340
he's up there trying to explain this to
our congressmen representatives Wow and

306
00:23:48,340 --> 00:23:52,389
then finally this one simply no
mismanage allude to earlier let's say

307
00:23:52,389 --> 00:23:56,889
you're the richest person in the world
yes this is Jeff Bezos

308
00:23:56,889 --> 00:24:00,939
showing up at a meeting about a year
year and a half ago of tech titans and

309
00:24:00,940 --> 00:24:05,529
it seems that Jeff has been bumping up a
little bit lately he's looking pretty

310
00:24:05,529 --> 00:24:09,909
fine there this is before the whole
divorce thing and messiness came out but

311
00:24:09,909 --> 00:24:16,380
it's how there is so we've got your
brain we've got I'm sorry but your heart

312
00:24:16,380 --> 00:24:23,529
seriously and and here we got your belly
what do we listen we're missing

313
00:24:23,529 --> 00:24:29,559
Tim Cook we're missing Apple where is
your sensuality it's interesting because

314
00:24:29,559 --> 00:24:33,290
it's different and I'm gonna talk about
why it might be different

315
00:24:33,290 --> 00:24:37,129
some ideas here but apples state and
approach and concerns with respect to

316
00:24:37,130 --> 00:24:40,910
privacy are different from the other
three of the big four the other three

317
00:24:40,910 --> 00:24:43,880
the before especially Facebook I
apologize

318
00:24:43,880 --> 00:24:48,230
right but here's what Tim Cook said back
in October so about six months ago our

319
00:24:48,230 --> 00:24:51,200
own information from the average age of
deeply person was being weaponized

320
00:24:51,200 --> 00:24:56,090
against notice the word weaponized
against us with military efficiency we

321
00:24:56,090 --> 00:25:02,209
should sugarcoat the consequences this
is surveillance Apple publicly at least

322
00:25:02,210 --> 00:25:07,160
is trying to differentiate itself from
what's happening in the other of the big

323
00:25:07,160 --> 00:25:10,310
four and in fact there was a hand that
just came up two weeks ago did you see

324
00:25:10,310 --> 00:25:13,100
this the privacy it's actually kind of
funny hat that says hey get privacy

325
00:25:13,100 --> 00:25:19,850
matters to you it matters to us to NH my
phone may be a complete cynic and look

326
00:25:19,850 --> 00:25:23,719
at this seriously you can be cynical
look at this and say the reason Apple is

327
00:25:23,720 --> 00:25:27,950
different from the other ones is because
they're trying to sell you phones and

328
00:25:27,950 --> 00:25:31,730
you say and I against Macintosh's but
they made their money on the phones and

329
00:25:31,730 --> 00:25:34,310
you look at it's the phones of all the
phones alright so they're trying to sell

330
00:25:34,310 --> 00:25:38,210
you guys say it's pumps and other stuff
too and you say well that's why I wish

331
00:25:38,210 --> 00:25:42,440
the other ones are actually trying to
make money off of your data their

332
00:25:42,440 --> 00:25:45,620
business models are just very different
so you can be a cynic and say well of

333
00:25:45,620 --> 00:25:48,800
course typical you can say that cuz
you're just driving cell phones in fact

334
00:25:48,800 --> 00:25:53,600
it's going to help you sell phones but
the other ones are actually in the data

335
00:25:53,600 --> 00:26:00,770
business Google Facebook right and
Amazon but you can also kind of counter

336
00:26:00,770 --> 00:26:05,629
cynic this you can also say well maybe
apples not in that business because they

337
00:26:05,630 --> 00:26:09,410
really don't want to be in that business
what they made much money on phones but

338
00:26:09,410 --> 00:26:14,300
they had a bunch of data services and
they haven't at least publicly had as

339
00:26:14,300 --> 00:26:18,950
much problem with sharing that data that
they're learning about from Siri and the

340
00:26:18,950 --> 00:26:22,640
other services that they provide right
so tech nice to look at this different

341
00:26:22,640 --> 00:26:25,460
forms of cynicism you could take but I'm
just here to say at least publicly

342
00:26:25,460 --> 00:26:28,870
speaking
Apple is different from the other three

343
00:26:28,870 --> 00:26:33,620
so the weaponization of a day let's
think more about that and I've had some

344
00:26:33,620 --> 00:26:36,860
specific examples here October 2018 so
six months ago

345
00:26:36,860 --> 00:26:40,260
Russian firms
who built facial recognition software

346
00:26:40,260 --> 00:26:45,530
this was reported both clean the press
crawled Facebook and took all your faces

347
00:26:45,530 --> 00:26:49,950
why we don't know but this is good for
publicly they want to be educational

348
00:26:49,950 --> 00:26:53,490
recognition that's what they do
so this Russian firm that does a lot of

349
00:26:53,490 --> 00:26:58,170
work with the Russian government now has
a whole bunch hundreds of millions maybe

350
00:26:58,170 --> 00:27:03,090
a billion or more faces that they can
use for something then of course it's at

351
00:27:03,090 --> 00:27:07,020
March 2018 announcement I mentioned this
earlier became rich analytic this self

352
00:27:07,020 --> 00:27:10,680
again they walked the social graph
downloaded that stuff and did

353
00:27:10,680 --> 00:27:17,820
correlations of all kinds of crazy weird
things 2017 the Equifax breach 145

354
00:27:17,820 --> 00:27:23,580
million records consumer David that's
this is big big data and the kinds of

355
00:27:23,580 --> 00:27:27,600
analysis and analytics you can do to
weaponize that to improve your own

356
00:27:27,600 --> 00:27:33,000
business or maybe from a national
security perspective go into another

357
00:27:33,000 --> 00:27:36,210
country is profound and that's why I put
this other one in here it's a little

358
00:27:36,210 --> 00:27:41,670
older 2015 OPM breach twenty two million
while opening I had a breach were over

359
00:27:41,670 --> 00:27:45,240
22 million government employees and
contractors records were stolen these

360
00:27:45,240 --> 00:27:49,290
are people who have clearance and they
stole not only information about their

361
00:27:49,290 --> 00:27:54,420
backgrounds and such which could be very
embarrassing but also fingerprints they

362
00:27:54,420 --> 00:27:57,810
so fake every day I got friends work
with government made some of you guys do

363
00:27:57,810 --> 00:28:03,600
too who are piece I mean see work as
security professionals to the United

364
00:28:03,600 --> 00:28:07,919
States government and then OPM leaked
their most sensitive stuff when they

365
00:28:07,920 --> 00:28:13,260
gave so they could have their jobs in a
verge crusted area and yet they can't

366
00:28:13,260 --> 00:28:17,700
trust the organization of Australian
data this is really bad news it's a

367
00:28:17,700 --> 00:28:23,430
wagon ization of big data that there is
another group of organizations that

368
00:28:23,430 --> 00:28:27,390
collect this kind of data that we don't
seem to be and these publicly is worried

369
00:28:27,390 --> 00:28:32,490
about you to rien press like every day
or two you read something about Google

370
00:28:32,490 --> 00:28:37,099
or specially Facebook or Amazon
privacy concerns here but in addition to

371
00:28:37,099 --> 00:28:40,759
those organizations government tax
agencies and credit card companies are

372
00:28:40,759 --> 00:28:44,839
also gathering and storing this kind of
data but why are we here to about too

373
00:28:44,839 --> 00:28:48,799
many abuses of these organizations or
concerns associated with them and I

374
00:28:48,799 --> 00:28:52,070
think it's just because we're used to
that we are in the midst of a

375
00:28:52,070 --> 00:28:57,829
technological revolution with the cloud
machine learning and AI and that right

376
00:28:57,829 --> 00:29:03,619
now for many of us me included is giving
us an 80 miss factors like whether the

377
00:29:03,619 --> 00:29:08,299
carbons have this data on your far right
tax agencies credit card companies think

378
00:29:08,299 --> 00:29:11,690
we should purchase for the last 20 30
years but now this is a new group of

379
00:29:11,690 --> 00:29:15,739
organizations the other big difference I
think is the new organizations that have

380
00:29:15,739 --> 00:29:20,659
access to this data oftentimes preach
that they are there to make the world a

381
00:29:20,659 --> 00:29:23,569
better place you see as Mark Zuckerberg
talk to us a lot

382
00:29:23,569 --> 00:29:27,949
how connecting people on Facebook is
actually going to result in a better

383
00:29:27,949 --> 00:29:33,349
world a better world so so I don't think
any tax agency is gonna say you we're

384
00:29:33,349 --> 00:29:36,589
trying to make the world a better place
make sure you give us your taxes or your

385
00:29:36,589 --> 00:29:40,609
credit card companies they're not trying
to transform humanity into the next

386
00:29:40,609 --> 00:29:44,928
level like Facebook is but that's what's
going to stay - they're trying to bring

387
00:29:44,929 --> 00:29:48,589
us to the next level whatever is that
we're going to be hmm interesting

388
00:29:48,589 --> 00:29:54,529
ah so that was a class that is taught at
Princeton every year and it's a

389
00:29:54,529 --> 00:29:59,329
fascinating class in CIBC it's wws 353
Princeton University it's usually

390
00:29:59,329 --> 00:30:02,989
juniors and seniors there in the class I
have gone there and done a guest lecture

391
00:30:02,989 --> 00:30:07,159
for the last three or four years and
what this is done on this class is crazy

392
00:30:07,159 --> 00:30:11,149
it's science and global security from
nuclear weapons to cyber warfare and

393
00:30:11,149 --> 00:30:14,809
artificial intelligence I do a guest
lecture each year on the cyber warfare

394
00:30:14,809 --> 00:30:19,158
market that's where I am right but
they've recently added just over the

395
00:30:19,159 --> 00:30:22,729
last two years
AI machine learning and super

396
00:30:22,729 --> 00:30:29,269
intelligence as a weaponry aspect that
is in this class so the weaponization of

397
00:30:29,269 --> 00:30:33,660
big data of machine learning I mean it's
their newest class as fascinating class

398
00:30:33,660 --> 00:30:37,860
really really quite interesting alright
so where does this all hand if you think

399
00:30:37,860 --> 00:30:41,729
about what does this mean to you as an
individual I'd like to make this more

400
00:30:41,730 --> 00:30:45,180
personal now let's think about this okay
I might ask you to raise your hand for

401
00:30:45,180 --> 00:30:49,860
this next section because it gets a
little weird okay what does your AI know

402
00:30:49,860 --> 00:30:52,979
about you so when I say you're a guy I
thought most people had their hands up

403
00:30:52,980 --> 00:30:57,030
earlier with Alice or if you prefer to
call her Alexa or you know we call

404
00:30:57,030 --> 00:31:00,330
steering in my office we call her Sally
because we want to trigger it constantly

405
00:31:00,330 --> 00:31:03,210
right
we don't have Google home office we just

406
00:31:03,210 --> 00:31:06,630
call Google all right so those people
raising it before door attorney and them

407
00:31:06,630 --> 00:31:12,330
okay but you know who you are and you
have a technology the jury I know when

408
00:31:12,330 --> 00:31:17,040
you wake up maybe you send an alarm
using it or can tell when you start

409
00:31:17,040 --> 00:31:19,860
doing your searches in the morning so we
kind of know is every day you wake up at

410
00:31:19,860 --> 00:31:23,479
7 a.m. or 8 or whatever it is
does it know what you like to eat

411
00:31:23,480 --> 00:31:27,570
because it sees that you're going to
these different restaurants and

412
00:31:27,570 --> 00:31:30,210
searching for it giggling some
restaurants maybe knows the kind of food

413
00:31:30,210 --> 00:31:34,290
that you like mine does oh my gosh how
the state has its own young yeah it must

414
00:31:34,290 --> 00:31:38,370
know it must know does it know where you
go to work maybe he's trying to run

415
00:31:38,370 --> 00:31:41,340
traffic or something like that does it
know where you go I have to work because

416
00:31:41,340 --> 00:31:43,980
you're looking it up in their maps
wherever that might be right

417
00:31:43,980 --> 00:31:48,870
or does it know you on vacation that you
should do a lot of research yeah there's

418
00:31:48,870 --> 00:31:52,560
a noise you like to watch on TV and in
your favorite movies I heard this

419
00:31:52,560 --> 00:31:55,980
analogy for YouTube the other day that I
thought was profound

420
00:31:55,980 --> 00:32:01,080
so what is YouTube first of all you guys
know who owns usually right yeah no okay

421
00:32:01,080 --> 00:32:04,740
alphabetic flash move oh right so
YouTube somebody described this to me

422
00:32:04,740 --> 00:32:07,770
this is about two years ago they said
you know YouTube is looks like what's

423
00:32:07,770 --> 00:32:13,260
place I don't watch videos well that's
part of it but YouTube watches you

424
00:32:13,260 --> 00:32:18,210
watching videos and tries to give you
more videos that will keep you watching

425
00:32:18,210 --> 00:32:23,990
it is an artificial intelligence whose
goal is to keep your eyes on that screen

426
00:32:23,990 --> 00:32:29,820
this is you this is not like TV of the
1950's 70s or 90s this is TV that

427
00:32:29,820 --> 00:32:34,590
watches you're watching it and when you
turn away it learns that it made a

428
00:32:34,590 --> 00:32:37,500
mistake and it won't make that mistake
again

429
00:32:37,500 --> 00:32:42,060
it is hot device to keep you sharing in
that damn screen for as long as possible

430
00:32:42,060 --> 00:32:44,859
so you
as possible and they can make money have

431
00:32:44,859 --> 00:32:48,519
a nice day hi so doesn't know what you
like to watch the TV in your favorite

432
00:32:48,519 --> 00:32:53,169
movies yeah it does does it know what
you search for oh I know you're gonna go

433
00:32:53,169 --> 00:32:55,619
in there but did you have to go yes I
went there all right

434
00:32:55,619 --> 00:32:59,590
does it know your maladies like me feel
kind of sick or you know this elbows

435
00:32:59,590 --> 00:33:03,879
always bothered me I kind of look that
up or your dreams and a dream about

436
00:33:03,879 --> 00:33:06,849
something you want to do a Google search
for century me am I really as weird as I

437
00:33:06,849 --> 00:33:11,918
think of him doesn't know your fears
which worried about this it doesn't know

438
00:33:11,919 --> 00:33:15,960
that you thought you had this horrible
disease you would die of two years ago

439
00:33:15,960 --> 00:33:21,159
you don't even remember that but it does
yeah does it no no not the best and the

440
00:33:21,159 --> 00:33:27,429
worst of what goes through your mind so
I decided to uh to go search on the most

441
00:33:27,429 --> 00:33:32,320
popular websites in the u.s. I limited
to the US you can look worldwide if you

442
00:33:32,320 --> 00:33:35,229
look worldwide there's of this bunch in
there from China and some from India to

443
00:33:35,229 --> 00:33:38,799
write very very large projects
I just focusing on the US we always talk

444
00:33:38,799 --> 00:33:43,869
here there's a company called similarweb
and you could go there they give you

445
00:33:43,869 --> 00:33:47,949
free stuff they want to sell you a
service so that you can do sort of micro

446
00:33:47,950 --> 00:33:51,429
analysis of sites that you've never
heard of it stuff like that but this is

447
00:33:51,429 --> 00:33:58,210
as of March 1st 2019 the 11 most popular
websites from nine States's perspective

448
00:33:58,210 --> 00:34:03,639
and accessing them and if you look the
first several of them let's just say n

449
00:34:03,639 --> 00:34:08,739
where we don't know exactly what n
equals but the first n are all search

450
00:34:08,739 --> 00:34:15,219
engine related and machine learning
AI systems so you got a Google everybody

451
00:34:15,219 --> 00:34:18,489
who's playing that's number one
you two search engine rights the second

452
00:34:18,489 --> 00:34:21,578
profile search engine in the world
YouTube is number two Facebook's number

453
00:34:21,579 --> 00:34:25,029
three Amazon that's number four
so notice here we've got three of the

454
00:34:25,029 --> 00:34:30,250
top four right there in fact of the big
four one of them is represented twice we

455
00:34:30,250 --> 00:34:32,668
got got

456
00:34:33,389 --> 00:34:39,030
number six is pornhub I wonder what kind
of machine learning and AI they might be

457
00:34:39,030 --> 00:34:43,919
applying to keep you focused on their
screams for as long as possible

458
00:34:43,918 --> 00:34:47,908
we got another adult sign another adult
sigh I didn't even know these existed

459
00:34:47,909 --> 00:34:52,530
well there you go number six seven and
eight then we got number nine is eBay

460
00:34:52,530 --> 00:34:56,520
number ten is Twitter exciting so just
doing top ten to go to 11 this one goes

461
00:34:56,520 --> 00:35:00,420
to 11 if they say explain that but I
wanted to get Wikipedia out there to

462
00:35:00,420 --> 00:35:06,869
show that pornhub dominates way
overweight that's that's what we are

463
00:35:06,869 --> 00:35:11,550
that's what we're as a society into
species and think about this each of

464
00:35:11,550 --> 00:35:16,470
these organizations is constantly
collecting more and more data about you

465
00:35:16,470 --> 00:35:20,578
and using it to further its business
interest okay so I add this up and what

466
00:35:20,579 --> 00:35:25,380
does it all mean think about it does
your AI know more about you than your

467
00:35:25,380 --> 00:35:34,619
friends to the sherry I know more about
you than your clergy does thank you it

468
00:35:34,619 --> 00:35:39,599
tells your Google search box maybe what
did you tell them and does your hangout

469
00:35:39,599 --> 00:35:46,349
know more about you than your spouse
does like yes yes okay does your aunt

470
00:35:46,349 --> 00:35:50,640
know more about you than you know about
yourself I would suggest

471
00:35:50,640 --> 00:35:55,290
abso-freakin'-lutely it knows it
remembers it knows that you thought you

472
00:35:55,290 --> 00:35:58,650
had that sickness a few years ago did
you see they that's this new feature

473
00:35:58,650 --> 00:36:04,260
they wanted to add to Alice Alexa Alexa
this new feature they want to add so

474
00:36:04,260 --> 00:36:06,930
that Jimmy could actually if you talk to
her

475
00:36:06,930 --> 00:36:11,578
sets to see that your voice isn't quite
right the sense that you might be sick

476
00:36:11,579 --> 00:36:17,460
you're catching a cold
and then as you use Amazon they'll put

477
00:36:17,460 --> 00:36:21,030
little things for different cold
remedies up on the screen for you isn't

478
00:36:21,030 --> 00:36:24,960
this wonderful
it's horrifying or mine so you just read

479
00:36:24,960 --> 00:36:27,860
I know more about you than you know by
let me think about the psychological

480
00:36:27,860 --> 00:36:31,970
studies I tell you I think 50 years from
now a hundred years from now 20 years

481
00:36:31,970 --> 00:36:36,049
from now they're going to date no mining
this stuff to try to understand the

482
00:36:36,050 --> 00:36:39,350
craziness that we're going through as a
society and all kinds of very

483
00:36:39,350 --> 00:36:43,130
interesting things are gonna come out of
this data regardless of how it is

484
00:36:43,130 --> 00:36:47,390
exposed but it's just going to come down
they finally do share more about

485
00:36:47,390 --> 00:36:53,660
yourself with your ki than you do with
your God mm baby

486
00:36:53,660 --> 00:37:00,710
ah so ubiquitous and throughout your
life dear me I throughout your house I

487
00:37:00,710 --> 00:37:03,920
think we got people here with four or
five six seven of these devices and then

488
00:37:03,920 --> 00:37:09,350
you can do the cumulative if you add up
my seer you enable devices with my Alexa

489
00:37:09,350 --> 00:37:13,670
enable devices it's all over the place
hey I in your car you better believe I

490
00:37:13,670 --> 00:37:19,250
mean Alba once AI in your car right and
of course if you see that's how Amazon's

491
00:37:19,250 --> 00:37:23,270
announced a whole bunch of car services
for Alexa they want to be in your car

492
00:37:23,270 --> 00:37:26,600
why because you're in your car spend a
lot of time there and that times not

493
00:37:26,600 --> 00:37:30,920
spent looking at an Amazon screen
darling we can fix that problem

494
00:37:30,920 --> 00:37:34,700
you're a out of your pocket you're
walking around I tell you I do think

495
00:37:34,700 --> 00:37:39,109
Apple has really dropped the ball with
Siri no offence something like I said

496
00:37:39,110 --> 00:37:43,040
nice things on hand earlier but a series
of big disappointment I look I did a

497
00:37:43,040 --> 00:37:45,740
whole bunch of development some of you
may have seen to talk about you know

498
00:37:45,740 --> 00:37:49,250
automating my office I don't like 30,000
lines of code a lot of it was Siri base

499
00:37:49,250 --> 00:37:54,500
and just kept screwing up too much so I
move over to Alexa and it is much

500
00:37:54,500 --> 00:37:58,610
tighter and much more optimized it just
gets stuff done in a way that Siri can't

501
00:37:58,610 --> 00:38:02,660
but I say that as a developer get both
Lascaux systems oh so you got your guy

502
00:38:02,660 --> 00:38:06,980
in your pocket at some point a guy
becomes effectively on the president

503
00:38:06,980 --> 00:38:10,760
doesn't it it's just everywhere around
you I tell you I can annoying when I

504
00:38:10,760 --> 00:38:13,740
walk into a hotel I almost said it good
night my first one

505
00:38:13,740 --> 00:38:21,419
across the street I wanted to say Alexa
turn the lights on but she wasn't there

506
00:38:21,420 --> 00:38:27,859
so I know I had that I didn't touch a
switch these things who discussed the

507
00:38:27,859 --> 00:38:38,580
switch before me it's terrible it's
terrible

508
00:38:38,580 --> 00:38:44,640
and as this AI learns more more about
you and the world around you in addition

509
00:38:44,640 --> 00:38:48,509
to being omnipresent it will seem
effectively cognition except for Siri

510
00:38:48,510 --> 00:38:54,839
she wasn't on our way there but Alice
you walk in say Alexa let there be light

511
00:38:54,839 --> 00:39:00,029
and there is well not the hotel across
the street but in my home there is scary

512
00:39:00,030 --> 00:39:05,160
isn't my buddy rod Natalie tweeted this
about six months ago I'll let you just

513
00:39:05,160 --> 00:39:07,609
check it out

514
00:39:07,640 --> 00:39:11,670
think about that infant for those who
can't see the battle arena my son said

515
00:39:11,670 --> 00:39:16,770
his first words today and they were he
Google I have an awful parent this is

516
00:39:16,770 --> 00:39:21,599
not our future this is our now that
child for that child

517
00:39:21,599 --> 00:39:27,030
Google is on the present and knows
everything from that child from the very

518
00:39:27,030 --> 00:39:31,230
start
this is the world we've created and

519
00:39:31,230 --> 00:39:35,369
notice I haven't been mentioned Elon
Musk or killer AI robots shooting things

520
00:39:35,369 --> 00:39:41,400
are the Terminator I'm talking about AI
machine learning they data and the rapid

521
00:39:41,400 --> 00:39:46,050
loss of privacy and the organization of
big data to turn you into a product

522
00:39:46,050 --> 00:39:50,010
there's a wonderful saying it's powerful
if you can't tell what the product is

523
00:39:50,010 --> 00:39:55,670
and if you're not paying for the product
the product is you the product is you

524
00:39:55,670 --> 00:40:01,260
all right so I want you to do about this
just a spare run move to okay now there

525
00:40:01,260 --> 00:40:04,220
are some things you need to be careful
when the data that you share my

526
00:40:04,220 --> 00:40:09,868
recommendation to you is and I try to
demonstrate his talk try to personify

527
00:40:09,869 --> 00:40:18,640
the a is that you interact with once
think of Alexa not as a machine

528
00:40:18,640 --> 00:40:22,779
as a person because maybe you'll be less
likely to tell her things you shouldn't

529
00:40:22,779 --> 00:40:28,059
tell her right or that Google search box
think of sundar Pichai on the other side

530
00:40:28,059 --> 00:40:31,750
and a Google search box trying to sell
you some services and things like that

531
00:40:31,750 --> 00:40:36,760
think of Mark Zuckerberg reading
everything you type in to Facebook and

532
00:40:36,760 --> 00:40:41,079
I'm trying to personify this with a hope
of it will make you a little more

533
00:40:41,079 --> 00:40:45,609
circumspect and a little more careful as
you interact with these services okay

534
00:40:45,609 --> 00:40:52,269
you can also use alternative providers
DuckDuckGo vein or other right I try

535
00:40:52,269 --> 00:40:57,009
this I tried to use DuckDuckGo which has
been the practice policies on my phone

536
00:40:57,010 --> 00:41:01,299
for I did it for about six months
thank you know my computer because on my

537
00:41:01,299 --> 00:41:06,220
computer I need professional-grade
search which means Google but I tried

538
00:41:06,220 --> 00:41:09,368
duck taco and he just wasn't giving me
what I needed on my home so I switched

539
00:41:09,369 --> 00:41:15,400
to babe yeah I switch today there you go
yeah yeah it's been another three four

540
00:41:15,400 --> 00:41:19,390
months on that little antsy oh but
there's other videos you could do video

541
00:41:19,390 --> 00:41:24,160
might show this presentation my son is
17 years old he's like that no the fact

542
00:41:24,160 --> 00:41:29,019
is penis doesn't have as much content as
YouTube on any male there's numerous

543
00:41:29,019 --> 00:41:33,220
providers for email that you could go to
but most organizations and a lot of

544
00:41:33,220 --> 00:41:35,319
individuals just go to Gmail because
it's convenient

545
00:41:35,319 --> 00:41:38,589
you should also support vendors who
respect to privacy and widows Adamo

546
00:41:38,589 --> 00:41:43,960
now what about unplugging from social
media you could try you could and I

547
00:41:43,960 --> 00:41:47,500
think some healthy things for kids
especially teenage kids to get off of

548
00:41:47,500 --> 00:41:51,630
social media every once in a while I
mean we grounded my son emissions

549
00:41:51,630 --> 00:41:56,130
we grounded my son once this was about
two years ago and we took this social me

550
00:41:56,130 --> 00:42:01,680
away from him he's 17 now so he's 15 at
the time for one week I have never seen

551
00:42:01,680 --> 00:42:04,259
somebody fall apart they have monitor
he's a wonderful boy

552
00:42:04,260 --> 00:42:09,060
he's amazing it's incredible but it was
like even then you do for us - just like

553
00:42:09,060 --> 00:42:15,750
punch him in the face really hard much
less painful so you see there's many

554
00:42:15,750 --> 00:42:20,130
American people who try to unplug from
Google just Google and all of its

555
00:42:20,130 --> 00:42:23,640
services to all this infrastructure that
I actually implement like DNS black hole

556
00:42:23,640 --> 00:42:27,120
inside should they try to block the 25
million IP addresses that are associated

557
00:42:27,120 --> 00:42:30,120
with Google and all all of its names
that are associated with this various

558
00:42:30,120 --> 00:42:35,279
products and they see the internet kind
of dissolve it's just like this messed

559
00:42:35,280 --> 00:42:39,120
up little kind of stuff internet thing
it's hard it's hard but build your

560
00:42:39,120 --> 00:42:43,200
awareness work for public discourse
channels make your voice known because

561
00:42:43,200 --> 00:42:47,279
things are changing they're changing
fast and one other thing I'd like to

562
00:42:47,280 --> 00:42:50,040
leave you with here many of you have
said that you've done how they have

563
00:42:50,040 --> 00:42:54,930
challenged in the past we work hard
thousands of hours every year to give

564
00:42:54,930 --> 00:42:58,259
away holiday hack job it's our gift to
the community we've been doing it now

565
00:42:58,260 --> 00:43:02,940
for 17 18 years please do plate it's
free we make no money on it we do it

566
00:43:02,940 --> 00:43:07,110
just for fun and with a hope to help
people and think on bridge the attention

567
00:43:07,110 --> 00:43:11,010
is we keep them all up I pay thousands
of thousands of dollars every year in

568
00:43:11,010 --> 00:43:15,520
hosting services to keep this there we
go

569
00:43:15,520 --> 00:43:23,380
yeah they hurt our AI overlords heard
when we were talking about Alexa turn

570
00:43:23,380 --> 00:43:32,080
the fire alarm off hi I'll let you guys
tell me what to do but it will you keep

571
00:43:32,080 --> 00:43:36,700
calm and so there's something to please
all right everything Hamburglar okay

572
00:43:36,700 --> 00:43:40,569
we're gonna cool anyway for holiday hat
please note these stay up all I get

573
00:43:40,570 --> 00:43:45,430
around so if you want to play gnome in
your home for 2015 it's about IOT and

574
00:43:45,430 --> 00:43:48,759
hacking IOT you can go there too that
anybody here ever hats an infrastructure

575
00:43:48,760 --> 00:43:54,160
there's based on nodejs raise your hand
if you have if you have not do how the

576
00:43:54,160 --> 00:43:58,690
heck times fifty it's up all the super
gnomes are based on no not chance how

577
00:43:58,690 --> 00:44:02,320
mad 2016 Santa gets kidnapped how many
people here if rescue Santa for being

578
00:44:02,320 --> 00:44:07,390
kidnapped you play the best if you
happen there you go 2017 you have to

579
00:44:07,390 --> 00:44:13,750
stop a civil war between us and the
North Pole why because a war profiteer

580
00:44:13,750 --> 00:44:18,610
is trying to make money off of the
Munchkins in the elves 2018 when hosting

581
00:44:18,610 --> 00:44:22,570
conference called Crapo calm anybody go
to cream looketh with 70,000 people

582
00:44:22,570 --> 00:44:26,500
attend this virtual conference I'm glad
you guys win it that's awesome and it's

583
00:44:26,500 --> 00:44:29,950
still all up so all the answers are
posted for all these things you could go

584
00:44:29,950 --> 00:44:33,279
you can play
there's no prizes for the past ones

585
00:44:33,280 --> 00:44:36,580
they're all done we should be still
played like say I need a sign for range

586
00:44:36,580 --> 00:44:40,090
I want to build my skills I want to
practice my team builds the best

587
00:44:40,090 --> 00:44:43,990
challenges we can and puts them out to
every year for you and people ask me

588
00:44:43,990 --> 00:44:48,810
what is 2019 going to be about and this
is the one in time travel

589
00:44:48,810 --> 00:44:59,920
2019 Casey I may be actually work very
careful we don't wanna collect more data

590
00:44:59,920 --> 00:45:03,340
than we need to
you play the pursuit on in we got an

591
00:45:03,340 --> 00:45:07,270
email dress that's all we got
oh well we also know every place that

592
00:45:07,270 --> 00:45:13,000
you walk in the game because there were
things that yeah that's right alright so

593
00:45:13,000 --> 00:45:19,380
Q&A we're good thank you guys so much
appreciate

594
00:46:12,210 --> 00:46:14,270
you

