1
00:00:20,350 --> 00:00:25,310
We're going to talk about here shifting
security left. And we're going to talk

2
00:00:25,310 --> 00:00:31,490
about what that means. What security
means in an age of agile methodologies

3
00:00:31,490 --> 00:00:38,059
and DevOps practices. So let me tell you a little bit about myself. My name is Chris Merkel.

4
00:00:38,059 --> 00:00:40,879
I do security stuff. I've been doing

5
00:00:40,879 --> 00:00:46,220
security stuff in a lot of areas for
quite some time. Right now I work down

6
00:00:46,220 --> 00:00:50,140
the street at Northwestern Mutual. And

7
00:00:50,320 --> 00:00:55,100
I've lived here in the Milwaukee area my
whole life. I really love it here.

8
00:00:55,100 --> 00:01:00,559
And I was thinking about what to put on
my, what would be relevant to put on m

9
00:01:00,559 --> 00:01:06,320
BIOS slide. And given the vintage hat
challenge, I figured I'd put up my first

10
00:01:06,320 --> 00:01:12,050
computer which was a Commodore 64.
Typical disclaimers,

11
00:01:12,050 --> 00:01:19,550
so these are, these are my opinions, my
opinions alone. These are the bad ones. I

12
00:01:19,550 --> 00:01:22,840
stole those from somebody else.

13
00:01:22,869 --> 00:01:27,740
And the third bullet point here is
something I really do want to stress, is

14
00:01:27,740 --> 00:01:31,689
that a lot of what I'm doing here is
highlighting the work of other people.

15
00:01:31,689 --> 00:01:38,509
What I'm trying to do is bring that
together in, in a cohesive way that helps

16
00:01:38,510 --> 00:01:44,990
us how to understand how to solve some
security challenges. And as a result, I

17
00:01:44,990 --> 00:01:54,439
try to do good attribution. I try to call
out people's contributions and if I don't

18
00:01:54,439 --> 00:02:00,169
do that at me, I didn't give you what it
like digitally at me. I mean, just come

19
00:02:00,170 --> 00:02:08,690
talk to me. So here's our agenda. You'll
notice across these bullet points that

20
00:02:08,690 --> 00:02:16,459
only one of them actually has to do with
technology. I really appreciated the, the

21
00:02:16,459 --> 00:02:21,470
keynote from from last night.
And if you were in the keynote last

22
00:02:21,470 --> 00:02:28,000
night, and you were paying
attention, you realize that there were

23
00:02:28,000 --> 00:02:32,620
really two things big talked about. The
first on the surface you might come away

24
00:02:32,620 --> 00:02:36,640
learning something about NAND flash
memory and translation layers and things

25
00:02:36,640 --> 00:02:41,890
like that. What was really being talked
about, was questioning our assumptions

26
00:02:41,890 --> 00:02:49,029
about what we do and why we do it. So I
really appreciated that, that kind of

27
00:02:49,030 --> 00:02:55,510
warm this up a little bit for m. Because
I'm going to kind of talk about that too.

28
00:02:55,510 --> 00:02:59,470
We're going to talk about what it means
to try harder, what it means to

29
00:02:59,470 --> 00:03:04,030
eventually fail when you've tried harder.
I'm going to try to provoke an

30
00:03:04,030 --> 00:03:14,739
existential crisis amongst all of you at
10:00 in the morning. Break down for a

31
00:03:14,739 --> 00:03:19,269
bill jump a little bit. Then we're going
to talk about giving up our desire for

32
00:03:19,269 --> 00:03:25,720
control. What it means to trust other
people, become an enabler, a healthy

33
00:03:25,720 --> 00:03:31,750
enabler. Not the kind of enabler I saw
at the Safe House last night. And then

34
00:03:31,750 --> 00:03:35,319
finally, we're going to talk about how
you make modest improvements to security

35
00:03:35,319 --> 00:03:42,638
through a couple of smart technology
decisions, okay? So first is clarify what

36
00:03:42,639 --> 00:03:46,180
we're talking about here. When we talk
about security failures. Typically

37
00:03:46,180 --> 00:03:49,930
security failures in my mind come
down to three basic problems: code,

38
00:03:49,930 --> 00:03:55,629
configuration, and people. What we're going to talk about first, is we're going to

39
00:03:55,629 --> 00:03:59,560
talk about people, not in the traditional
sense of you know, people clicking on

40
00:03:59,560 --> 00:04:02,410
phishing and things like that. But kind of
people you got to work with to actually

41
00:04:02,410 --> 00:04:07,239
achieve you know, good outcomes in
security. Then after that, once we get into

42
00:04:07,239 --> 00:04:09,959
technology, we'll talk a little bit about
code. We'll talk a little bit about

43
00:04:09,959 --> 00:04:18,548
configuration. So, as we start to talk
about people, we have to talk about the

44
00:04:18,548 --> 00:04:23,489
natural life cycle of information
security in the typical organization. And

45
00:04:23,490 --> 00:04:31,180
in most organizations when you get
started in security. So I try to be

46
00:04:31,180 --> 00:04:36,529
randomly interactive. How many of you are
working in security at a

47
00:04:36,529 --> 00:04:41,539
company where you are one of the first
people in security, doing security at

48
00:04:41,539 --> 00:04:46,599
your company? Just out of curiosity. [People raising hands] All right, all right. Cool.

49
00:04:46,599 --> 00:04:50,889
Congratulations and I'm sorry. [People laugh] Um...

50
00:04:52,179 --> 00:04:57,049
Depending on the, the situation and the
circumstances that brought you to that

51
00:04:57,049 --> 00:05:01,729
organization, you may or may not be
starting out with a good working

52
00:05:01,729 --> 00:05:07,008
relationship with the people you're, you're
working with. And so a lot of the first

53
00:05:07,009 --> 00:05:11,089
things you do in security is trying to
make sure that the rest of the

54
00:05:11,089 --> 00:05:17,089
organization actually understands why
you're there what value you bring to

55
00:05:17,089 --> 00:05:23,089
this conversation and the the thing that
we always talk about is being involved

56
00:05:23,089 --> 00:05:28,249
in the conversations getting a seat at
the table and if you're good at that if

57
00:05:28,249 --> 00:05:31,339
you're good at managing those
relationships and getting a couple of

58
00:05:31,339 --> 00:05:34,299
wins you are going to get a seat at the
table

59
00:05:34,299 --> 00:05:39,948
so congratulations this is how I feel
sometimes when I find myself having a

60
00:05:39,949 --> 00:05:44,860
seat at the table like you know I have
no idea what I'm doing

61
00:05:44,860 --> 00:05:50,809
so now that as security professionals we
come in and we look at a situation and

62
00:05:50,809 --> 00:05:55,789
we go all of this stuff is broke I we
have to fix it and so we're going to

63
00:05:55,789 --> 00:06:00,019
secure everything we will then all of
the systems and all the stepping out of

64
00:06:00,019 --> 00:06:05,089
my will I'm gonna be on every single
project because I am the security

65
00:06:05,089 --> 00:06:09,109
subject matter expert and I will be
there I will be at every project meeting

66
00:06:09,109 --> 00:06:14,419
every status update and I would make
sure this all happens and I'm also going

67
00:06:14,419 --> 00:06:18,829
to make sure that I don't have to sign
off on everything and I'm gonna weasel

68
00:06:18,829 --> 00:06:22,879
my way into the change management if you
got change management and I'm gonna make

69
00:06:22,879 --> 00:06:28,359
sure that I sign off and approve on
everything along

70
00:06:28,440 --> 00:06:31,719
I'm not really going to test a whole
long weeks that's what a penetration

71
00:06:31,720 --> 00:06:37,030
testing score will do that in the end
and don't change anything after you've

72
00:06:37,030 --> 00:06:43,690
built it because I got other projects
happening module okay that that's not

73
00:06:43,690 --> 00:06:48,850
gonna work in a lot of ways I'm
describing as I talk about project

74
00:06:48,850 --> 00:06:53,530
methodologies I'm talking about
waterfall methodology where you do

75
00:06:53,530 --> 00:07:01,479
things about set of sequential orders
until you reach your desired outcome so

76
00:07:01,479 --> 00:07:06,669
I'm going to say that in waterfall
security models things like angst cost

77
00:07:06,669 --> 00:07:12,580
and delay failure these are features
they're not bugs so in that that

78
00:07:12,580 --> 00:07:15,820
traditional security player you think
you can wrap your arms around all of

79
00:07:15,820 --> 00:07:19,900
this and actually secure all the things
this is this is what you come up with

80
00:07:19,900 --> 00:07:30,789
I'm doing human in the form of Gantt
chart I'm sorry I'm a little sorry

81
00:07:30,789 --> 00:07:35,620
because the text is a little small here
but basically what we find is that if

82
00:07:35,620 --> 00:07:41,680
you do get involved you know we make
these decisions on technology projects

83
00:07:41,680 --> 00:07:46,030
and you'll notice here that the time
that you develop it you know goes way

84
00:07:46,030 --> 00:07:49,388
past your goal line of tape so at the
point in time at once you actually want

85
00:07:49,389 --> 00:07:54,970
to put this this system into production
all your business holders they're

86
00:07:54,970 --> 00:07:57,760
they're upset you've missed your goal
life game at this point

87
00:07:57,760 --> 00:08:01,539
and then and then typically what happens
is they're going to quickly go and

88
00:08:01,539 --> 00:08:05,260
launch and then and then security you
come back and say okay cool I have to

89
00:08:05,260 --> 00:08:08,740
test it now you're ready live in your
production but you do it when your

90
00:08:08,740 --> 00:08:15,520
security test and you know a lot of
months and months of work you know they

91
00:08:15,520 --> 00:08:18,070
tell you you got exactly six days to
find out everything that's almost

92
00:08:18,070 --> 00:08:22,050
imperative is your product go

93
00:08:22,479 --> 00:08:26,469
so you do some security testing some
kind of penetration test or something

94
00:08:26,470 --> 00:08:32,169
like that where you're kind of working
from the outside in okay you can spend a

95
00:08:32,169 --> 00:08:35,710
little bit of time
agree about the actual findings they're

96
00:08:35,710 --> 00:08:40,060
gonna tell you that these aren't
problems I want to deal with them you

97
00:08:40,059 --> 00:08:45,880
know then they start to go through the
table full of six inches of grief you

98
00:08:45,880 --> 00:08:52,350
know so you get you know shot with the
arm now I'm not a trained psychologist

99
00:08:52,470 --> 00:08:55,660
you know we do a little bit of
bargaining and then eventually they

100
00:08:55,660 --> 00:08:59,319
decide they're gonna commit to this you
know they'd start doing all the

101
00:08:59,320 --> 00:09:04,890
remediation work and then somewhere
along the way you get breached and

102
00:09:04,890 --> 00:09:11,410
that's what happens and and part of the
root of this problem comes down to

103
00:09:11,410 --> 00:09:17,439
something that IBM pointed out is that
all bugs cost money some costs more than

104
00:09:17,440 --> 00:09:22,480
others so this is from a classic paper
that I be able to put out quite some

105
00:09:22,480 --> 00:09:26,980
time ago so when I screenshotted into
the super pixelated because I think it

106
00:09:26,980 --> 00:09:33,970
was made unlike WordPerfect or something
the cost to fix a bug in maintenance

107
00:09:33,970 --> 00:09:41,050
mode which we would say is beat the
production phase of the system costs a

108
00:09:41,050 --> 00:09:48,370
hundred times more than fixing or
avoiding the defect during the design

109
00:09:48,370 --> 00:09:56,860
phase of a system so the original name
of my talk is shifting security flaps of

110
00:09:56,860 --> 00:10:04,020
the natural question you might ask
yourself is left of what exactly okay so

111
00:10:04,020 --> 00:10:08,020
what I'm going to talk about is going to
presuppose a little bit of understanding

112
00:10:08,020 --> 00:10:15,610
on how software projects tend to be made
and built and things like that right so

113
00:10:15,610 --> 00:10:21,339
we've got all the left we have our code
we have two different pipelines we call

114
00:10:21,339 --> 00:10:26,589
this CI CD continuous integration
continuous delivery and I'm going to

115
00:10:26,589 --> 00:10:33,640
talk about this in terms of teams that
do this kind of work okay now I know as

116
00:10:33,640 --> 00:10:36,819
a security
for myself personally I come from a

117
00:10:36,820 --> 00:10:41,650
network and infrastructure background
I'm not used to actually dealing with

118
00:10:41,650 --> 00:10:47,620
what happens in a development lifecycle
you know developers go up and do stuff

119
00:10:47,620 --> 00:10:51,340
and then they have this big blob of
stuff called like code and then that

120
00:10:51,340 --> 00:10:55,330
cook goes on the server everything that
happens before that is either like black

121
00:10:55,330 --> 00:10:58,810
magic or doesn't really happen probably
understanding because I write that code

122
00:10:58,810 --> 00:11:02,500
I compile my backbone and then I just
like copy to server if I'm done right

123
00:11:02,500 --> 00:11:06,880
there's nothing else to talk about but
other than that right well not really

124
00:11:06,880 --> 00:11:14,860
so in a modern CICS system we we talk
about information or process moving from

125
00:11:14,860 --> 00:11:20,200
left to right and and typically speaking
most of the time that security is

126
00:11:20,200 --> 00:11:24,280
involved we're involved we were on the
right side of things we're dealing with

127
00:11:24,280 --> 00:11:28,480
things when they are about to go into
production

128
00:11:28,480 --> 00:11:32,920
we deal with things that are built so
let's say we get to catch up report goes

129
00:11:32,920 --> 00:11:37,120
to production typically security we want
to see a built rock we want to say I

130
00:11:37,120 --> 00:11:40,900
want to make sure that I can test a
built product call me what you have

131
00:11:40,900 --> 00:11:48,400
something I can actually do something
learn and it's too late at that point

132
00:11:48,400 --> 00:11:56,439
because again if you go back to this IBM
statistic at best you're doing a really

133
00:11:56,440 --> 00:12:02,140
good maybe you're only costing the
organization 15 times as much instead of

134
00:12:02,140 --> 00:12:10,660
a hundred times as much so I said I'd
talk a little bit about DevOps this is

135
00:12:10,660 --> 00:12:16,209
the basic operating model and really
really really oversimplifying us for the

136
00:12:16,210 --> 00:12:22,150
purpose of conversation and it's also
worth pointing out that when we talk

137
00:12:22,150 --> 00:12:28,750
about this bank automation in CIS EE
most of this is application designed to

138
00:12:28,750 --> 00:12:33,500
build and a lot of this is deployment
and

139
00:12:33,500 --> 00:12:38,390
structure and things like that it's also
worth pointing on this as we as we move

140
00:12:38,390 --> 00:12:44,840
into new operating models with flour and
and things like that this isn't just

141
00:12:44,840 --> 00:12:52,310
application code there were moving to a
place where code drives everything so if

142
00:12:52,310 --> 00:12:59,209
you've done any work in cloud spaces you
you realize that the basic model of

143
00:12:59,210 --> 00:13:05,150
being able to like point like to make a
server that's neat but that's not the

144
00:13:05,150 --> 00:13:08,780
that's not the future that's not the
operating model the the fact of the

145
00:13:08,780 --> 00:13:17,600
matter is I can build an entire data
center in code and I can push one Enter

146
00:13:17,600 --> 00:13:23,020
key on my keyboard and I can give you a
whole data center

147
00:13:23,020 --> 00:13:26,840
nobody's racking and stacking anything
nobody's plugging in wires

148
00:13:26,840 --> 00:13:32,810
nobody's manual installing operating
systems all of that is represented and

149
00:13:32,810 --> 00:13:38,540
it's an cheated by a code that's the
kind of environment we're talking about

150
00:13:38,540 --> 00:13:45,050
operator so let's talk a little bit
about DevOps what is DevOps and for

151
00:13:45,050 --> 00:13:52,060
those of you who you know flinch a
little bit when I use industry buzzwords

152
00:13:52,060 --> 00:13:59,719
sorry but I don't like the word cyber
but I'm stuck with it so we all have to

153
00:13:59,720 --> 00:14:03,740
have to deal with those kinds of things
just keep the Gantt charts coming we'll

154
00:14:03,740 --> 00:14:06,130
forgive you

155
00:14:07,540 --> 00:14:15,349
DevOps is a universe and foremost is a
cultural philosophy principle practice

156
00:14:15,350 --> 00:14:20,990
it has a set of tools but but this is
really important because anybody who

157
00:14:20,990 --> 00:14:27,560
says I have this tool therefore I'm
kebobs is doing it wrong if somebody

158
00:14:27,560 --> 00:14:31,239
says that the way I'm doing DevOps is
the right way

159
00:14:31,240 --> 00:14:37,300
doing it different therefore you're
wrong is also wrong because DevOps agile

160
00:14:37,300 --> 00:14:43,029
these are methodologies approaches and
ideas that need to be crafted and adapt

161
00:14:43,029 --> 00:14:47,820
to the way your project demands the way
your business operates the weed

162
00:14:47,820 --> 00:14:52,510
destruction routines and things like
that but the outcome the outcome is

163
00:14:52,510 --> 00:14:56,200
really the only way if you want to know
if you're successful or not the measure

164
00:14:56,200 --> 00:15:03,430
is high velocity can you deliver
applications and services at high

165
00:15:03,430 --> 00:15:08,500
velocity now wolf asked me can I keep
the Gantt charts coming I'll go back to

166
00:15:08,500 --> 00:15:14,320
this one I have so many more than that
this is not high velocity this is low

167
00:15:14,320 --> 00:15:22,870
velocity because in my in my fictitious
chart that basically sums up about every

168
00:15:22,870 --> 00:15:28,540
other press product I've worked on you
know if we can get a major enterprise

169
00:15:28,540 --> 00:15:37,089
system out in less than six months we're
awesome okay and this is again

170
00:15:37,089 --> 00:15:40,720
left-to-right is planned everything out
way at a time they're executing on it

171
00:15:40,720 --> 00:15:45,730
they're late it takes forever the the
time you actually realize value in this

172
00:15:45,730 --> 00:15:53,380
equation is here so the whole point of a
trial is actually getting to deliver

173
00:15:53,380 --> 00:16:00,760
systems and services quickly so what are
the cultural philosophies that are

174
00:16:00,760 --> 00:16:05,200
inherent inist first of all remin small
multi disciplinary teams who work

175
00:16:05,200 --> 00:16:11,140
autonomously they do everything in small
increments and they do this by getting

176
00:16:11,140 --> 00:16:19,600
continuous feedback and continuously
testing adapting and revising and in

177
00:16:19,600 --> 00:16:26,980
this idea with small interdisciplinary
team what's not stated is that this

178
00:16:26,980 --> 00:16:32,649
doesn't work in a large monolithic
technology organization where one team

179
00:16:32,649 --> 00:16:36,670
is responsible for their work
then they throw it over the wall to the

180
00:16:36,670 --> 00:16:41,290
next team throw it over the wall to the
next team that's that's how we deliver

181
00:16:41,290 --> 00:16:49,150
systems in the low velocity way so ITT
broadly has realized that this is a

182
00:16:49,150 --> 00:16:54,400
problem this is why we are moving to two
demos it's not just the the flavor of

183
00:16:54,400 --> 00:17:01,630
the week here so in terms of practices
as I indicated before we talk about

184
00:17:01,630 --> 00:17:08,890
everything as a code I was the fortunate
opportunity to take the SANS classes

185
00:17:08,890 --> 00:17:14,530
last year in cloud security and in it we
had one large confirmation template that

186
00:17:14,530 --> 00:17:21,000
built that will be PC and when we were
done I executed one script and I

187
00:17:21,000 --> 00:17:27,819
destroyed an entire data center with one
command that was pretty awesome as a

188
00:17:27,819 --> 00:17:32,740
security professional sauce little scary
we have talked about automated

189
00:17:32,740 --> 00:17:37,720
provisioning because as as we deliver
tools of functionality we have to

190
00:17:37,720 --> 00:17:44,890
deliver these to people in a way that
you know adapts to them that gets out of

191
00:17:44,890 --> 00:17:49,120
the way that delivers some of the
functionality they need without having

192
00:17:49,120 --> 00:17:55,919
to come and ask work to place an order a
lot of how we do it-- in general is

193
00:17:55,920 --> 00:18:00,640
order creation and order delivery you
have a ticketing system a self-service

194
00:18:00,640 --> 00:18:05,680
request system a paper form who knows
what and somebody somewhere fills out a

195
00:18:05,680 --> 00:18:09,220
form that gets routed to a person that
person who approves it and then it goes

196
00:18:09,220 --> 00:18:12,310
this other person who then approves it
and then it goes to this other person

197
00:18:12,310 --> 00:18:15,909
and this other person pushes a bunch of
buttons to to effect a change and then

198
00:18:15,910 --> 00:18:19,300
eventually somewhere along the way you
can deliver some sort of access to

199
00:18:19,300 --> 00:18:23,950
something and you know in a
high-performing organization you you

200
00:18:23,950 --> 00:18:29,290
know that could happen in a couple of
hours and I say this is this is where we

201
00:18:29,290 --> 00:18:32,680
have to have data central crisis don't
do The Tempest

202
00:18:32,680 --> 00:18:38,380
figure out how to give people what they
need based on who they are and have it

203
00:18:38,380 --> 00:18:42,330
ready that's it

204
00:18:44,120 --> 00:18:47,899
a lot of these practices also include
things like you know incremental testing

205
00:18:47,900 --> 00:18:52,010
the continuous moderate that's been
baked in security now as as a security

206
00:18:52,010 --> 00:18:59,870
professional if you find yourself in a
situation where you get dropped into

207
00:18:59,870 --> 00:19:08,379
some sort of agile or DevOps practice
this is essentially what tends to happen

208
00:19:08,380 --> 00:19:11,380
okay

209
00:19:11,409 --> 00:19:16,610
the security team doesn't quite get
what's going on here

210
00:19:16,610 --> 00:19:22,610
right they the the developers they see
that concept of a pipeline that I talked

211
00:19:22,610 --> 00:19:29,830
about they see it as an assembly line a
factory a way of moving things along to

212
00:19:29,830 --> 00:19:38,480
incremental to create and deliver
features functionality stuff security

213
00:19:38,480 --> 00:19:49,000
looks at all this and they see Jackson
public and that creates some problems

214
00:19:49,000 --> 00:19:55,309
soon as a security professional I think
sometimes it helps to talk a little bit

215
00:19:55,309 --> 00:20:00,860
about you know I talk about those things
engine kind of you know vague and

216
00:20:00,860 --> 00:20:05,740
abstract terms I want to talk a little
bit about a high-performing DevOps team

217
00:20:05,740 --> 00:20:10,909
so we're gonna do a little bit of a case
study here so got this company in comedy

218
00:20:10,909 --> 00:20:16,909
security their billion dollars in
revenues and thirty six hundred clients

219
00:20:16,909 --> 00:20:22,370
they've got unified cross-functional
DevOps teams they're investing in top

220
00:20:22,370 --> 00:20:28,250
talent they're using things like JIRA
HipChat Azure cloud and they're they're

221
00:20:28,250 --> 00:20:31,700
creating software and they're delivering
a software thousands and thousands of

222
00:20:31,700 --> 00:20:37,429
endpoints across the globe with release
cycles that are measured in two days if

223
00:20:37,429 --> 00:20:44,809
they need to add new functionality they
have the discipline as a team to write

224
00:20:44,809 --> 00:20:49,990
tests integrate and deploy that software

225
00:20:50,440 --> 00:20:56,870
thousands of endpoints and we're not
just talking about you know consumer

226
00:20:56,870 --> 00:21:00,080
great stuff we're talking about people
in food service hospitality healthcare

227
00:21:00,080 --> 00:21:05,059
and they managed to do that without
killing their employees their employees

228
00:21:05,059 --> 00:21:09,678
that awesome work-life balance they
rarely have to work nights and weekends

229
00:21:09,679 --> 00:21:17,420
this is what in high-performing agile
and DevOps team looks like they're all

230
00:21:17,420 --> 00:21:27,980
so excited friend Guinea okay fight you
know customer actually meant victims and

231
00:21:27,980 --> 00:21:32,540
I mean honestly what's the difference
between infection and deployment you're

232
00:21:32,540 --> 00:21:36,668
still just getting soccer or going into
point B right you gotta be good at it

233
00:21:36,669 --> 00:21:43,820
you both have a financial motive right
and and yes they've been plundering

234
00:21:43,820 --> 00:21:49,340
clients across food service hospitality
financial services gaming the list goes

235
00:21:49,340 --> 00:21:55,459
on and on and on and on and if you don't
get the Unicorn things you know Silicon

236
00:21:55,460 --> 00:22:05,120
Valley billion-dollar valuation but kind
of a thing so if we take a step back and

237
00:22:05,120 --> 00:22:11,928
we ask ourselves is this agilent devops
thing like a passing fad or what let's

238
00:22:11,929 --> 00:22:20,350
talk about the people who truly have the
purest of economic motives who are they

239
00:22:20,350 --> 00:22:27,879
criminals so if this works for them

240
00:22:28,210 --> 00:22:32,809
there's probably something to it
we should probably stand up and pay

241
00:22:32,809 --> 00:22:39,440
attention because if it didn't work they
might have to do it they don't have you

242
00:22:39,440 --> 00:22:44,210
know senior leaders who feel like they
want to get on the front

243
00:22:44,210 --> 00:22:50,639
InfoWorld with the cool thing they did
and sandbag their organization with a

244
00:22:50,639 --> 00:22:56,850
bunch of junk in technology process to
do so no their whole town is to make

245
00:22:56,850 --> 00:23:01,370
money and make money quick and
effectively okay

246
00:23:01,370 --> 00:23:10,049
and some misses the results is how I
felt because in you know one thin parts

247
00:23:10,049 --> 00:23:15,000
of the organization without responsible
for this is my atmosphere my adversary

248
00:23:15,000 --> 00:23:23,220
is more agile and can adapt better than
me the night I got my NV checked Donaghy

249
00:23:23,220 --> 00:23:32,669
and his seemingly miraculous it was
bottled whiskey the other thing that to

250
00:23:32,669 --> 00:23:38,879
keep in mind here is as I said before a
lot of people like to throw long throw

251
00:23:38,879 --> 00:23:44,850
around buzzwords and say that we are at
child say that we do Dow Bob said things

252
00:23:44,850 --> 00:23:51,658
like that and I did a little bit of
research into this and and basically a

253
00:23:51,659 --> 00:23:58,980
lot of teams that say they are agile
often don't really have the the

254
00:23:58,980 --> 00:24:05,039
technical practices that come along with
this so I took the question if everybody

255
00:24:05,039 --> 00:24:09,990
is as agile as they claim to be now as a
security professional that's actually

256
00:24:09,990 --> 00:24:15,090
partying a little bit because what it
means is that you you still have an

257
00:24:15,090 --> 00:24:24,059
opportunity to wrap your head around
what's going on here adapt and and start

258
00:24:24,059 --> 00:24:31,620
to start to help so this this kind of
concludes the part of my talk where I

259
00:24:31,620 --> 00:24:37,139
wanted to break you down a little bit
and and tell you that this is here it's

260
00:24:37,139 --> 00:24:42,500
here to stay it's going to require
significant amount of a mindset shift

261
00:24:42,500 --> 00:24:47,809
about changing the way that we think
about these things

262
00:24:47,809 --> 00:24:52,139
questioning
about how we do security when we deliver

263
00:24:52,139 --> 00:24:57,870
security who our customers are and
things like that so now I'm gonna I'm

264
00:24:57,870 --> 00:25:00,899
going to shift a bit into some of the
technical things and here's what we're

265
00:25:00,899 --> 00:25:04,768
going to is we're going to talk about we
want to talk about training threat

266
00:25:04,769 --> 00:25:09,299
modeling requirements architecture food
quality tools and why I make poor life

267
00:25:09,299 --> 00:25:25,379
decisions so I'm not going to get back
like ten slides but one of the things I

268
00:25:25,379 --> 00:25:32,840
had on that graph as we talked about the
left to right from creating to delivery

269
00:25:32,840 --> 00:25:37,379
the one thing I don't really have on
that slide because I didn't take that

270
00:25:37,379 --> 00:25:44,158
from somebody else is that before we do
any of this we have to make sure that

271
00:25:44,159 --> 00:25:50,279
everybody is capable of doing the job
they have in front of them okay so let's

272
00:25:50,279 --> 00:25:55,169
talk about training and I know a lot of
organizations training is it is a

273
00:25:55,169 --> 00:26:02,129
difficult thing and asked for but I'll
tell you that more I've been working in

274
00:26:02,129 --> 00:26:11,789
technology for over twenty years and
there is no time in history that I can

275
00:26:11,789 --> 00:26:18,509
recall where we have as much free
training resources available at our

276
00:26:18,509 --> 00:26:25,019
disposable disposal than we do right now
and on top of that the place where the

277
00:26:25,019 --> 00:26:31,769
best and large quantities of training is
in this space with the types of tools

278
00:26:31,769 --> 00:26:39,330
used in agile devops shops cloud
services continuous delivery integration

279
00:26:39,330 --> 00:26:44,340
and things like that
so you know first of all you know we

280
00:26:44,340 --> 00:26:47,428
need to make sure that that our
developers actually know how to write

281
00:26:47,429 --> 00:26:52,620
secure code you should you know start
with that they're fairly available if

282
00:26:52,620 --> 00:26:57,620
you don't understand you know if I say
you know we need to

283
00:26:57,620 --> 00:27:03,309
do something with AWS lambda and you
know what that is

284
00:27:03,309 --> 00:27:07,460
Amazon has a series of things that
explains to you what that is

285
00:27:07,460 --> 00:27:14,540
it's just as Deadpool in Calamba
Microsoft answer they've got a huge

286
00:27:14,540 --> 00:27:20,629
learning world there is so much good
stuff available that if somebody were to

287
00:27:20,630 --> 00:27:26,090
come to me and say well I'm sorry but my
my organization just does not send me to

288
00:27:26,090 --> 00:27:31,870
training I question whether you're
trying hard enough

289
00:27:31,870 --> 00:27:37,520
so when we talk about shifting left the
first part is long before we have a book

290
00:27:37,520 --> 00:27:42,679
yes I keep wording and start working
with technology the next thing is we

291
00:27:42,679 --> 00:27:46,670
need to start talking about threat
modeling because you know you know

292
00:27:46,670 --> 00:27:51,110
traditional software development
lifecycle we start with requirements

293
00:27:51,110 --> 00:27:59,600
definition and as security professionals
we are trying to tell people what types

294
00:27:59,600 --> 00:28:05,889
of risks they need to avoid what types
of negative outcomes they need to avoid

295
00:28:05,890 --> 00:28:12,530
and in order to do that we actually have
to construct a threat model if you have

296
00:28:12,530 --> 00:28:19,460
ever had this conversation and security
where you show up and you start with you

297
00:28:19,460 --> 00:28:26,210
need to use this technology and you get
pushed back in arguments and things like

298
00:28:26,210 --> 00:28:31,640
that as security professionals a lot of
times we say to ourselves well they just

299
00:28:31,640 --> 00:28:34,520
don't get it
no there's a good chance they actually

300
00:28:34,520 --> 00:28:39,200
do get it but they understand their data
they understand their business process

301
00:28:39,200 --> 00:28:44,210
and they're not convinced that the risk
that you're trying to get them to invest

302
00:28:44,210 --> 00:28:51,020
in is actually the biggest risk for
system bases that's what we start out

303
00:28:51,020 --> 00:28:59,900
with rahama and what I'm showing here on
the right-hand side of the screen is

304
00:28:59,900 --> 00:29:06,080
threat modeling as soon as a game I'm
read plenty of books on Drive

305
00:29:06,080 --> 00:29:12,050
back several years if you would have
asked me three to five years ago you

306
00:29:12,050 --> 00:29:16,310
know should we do you know threat
modeling with you know normal teams I

307
00:29:16,310 --> 00:29:20,690
would say no that's that's like an
exercise for like governments and

308
00:29:20,690 --> 00:29:24,560
militaries because it's going to take
you days of planning and things like

309
00:29:24,560 --> 00:29:27,470
that
um threat modeling can be lightweight

310
00:29:27,470 --> 00:29:32,150
one of the best lightweight ways to do
this is through gamification so

311
00:29:32,150 --> 00:29:38,320
Microsoft has their elevation of
privileged University of Washington as

312
00:29:38,320 --> 00:29:42,530
security parts of similarly
I love the Microsoft game because it's

313
00:29:42,530 --> 00:29:49,160
actually licensed three like really
really free so you can imprint cards if

314
00:29:49,160 --> 00:29:53,000
you want it to like sell these parts on
the internet and make money you can do

315
00:29:53,000 --> 00:29:59,120
it and it's and basically if you use it
the same suit as a normal debit cards

316
00:29:59,120 --> 00:30:03,800
but what you get into is everybody
looking at different ways that's

317
00:30:03,800 --> 00:30:08,060
something that fails so you start with a
real basic you know you pick some some

318
00:30:08,060 --> 00:30:12,110
key transactions Pyrus transaction that
this does and you play this in and it

319
00:30:12,110 --> 00:30:17,090
eventually help helps you to spawn
conversations around what you need to do

320
00:30:17,090 --> 00:30:24,080
to improve your security if you're
progressing from there you can start to

321
00:30:24,080 --> 00:30:29,480
actually build threat modeling into your
code there's an open source project out

322
00:30:29,480 --> 00:30:34,580
right now called threat spec that
actually allows you to document your

323
00:30:34,580 --> 00:30:39,740
code with security requirements and
allows you to create really cool graphs

324
00:30:39,740 --> 00:30:45,350
and things like that so now that you've
constructed your threat model now we

325
00:30:45,350 --> 00:30:49,459
need to actually translate that because
the threat model tells you what could go

326
00:30:49,460 --> 00:30:56,690
wrong the next thing is the question
what do I do about so this is where we

327
00:30:56,690 --> 00:31:02,000
have to start delivering requirements
now again that threat modeling game if

328
00:31:02,000 --> 00:31:07,910
you're good at it they play that without
you okay you do not need to be the

329
00:31:07,910 --> 00:31:11,920
dungeon master of threat modeling okay

330
00:31:12,690 --> 00:31:16,830
each time to play the game to build
their own threat models they can keep an

331
00:31:16,830 --> 00:31:22,199
eye on but you even Abel the next thing
you do is give them the ability to

332
00:31:22,200 --> 00:31:29,610
define their requirements in its
application development and I done a lot

333
00:31:29,610 --> 00:31:33,270
of work recently in apps X so I'm going
to lean on that a bit heavily in the

334
00:31:33,270 --> 00:31:37,680
first part of this I
Olaf has the application security

335
00:31:37,680 --> 00:31:44,370
verification standard that helps you
design requirements in software for how

336
00:31:44,370 --> 00:31:49,260
secure software is built slack releases
to another tool called OST else your

337
00:31:49,260 --> 00:31:56,730
develop lifecycle user customizable
systems that help you identify security

338
00:31:56,730 --> 00:32:02,460
requirements and guide people from
threat model to what they actually needs

339
00:32:02,460 --> 00:32:08,480
you to build out as stories and
requirements as the builder software

340
00:32:08,480 --> 00:32:13,590
where do we get some of this from well
you can go to you know all awesome

341
00:32:13,590 --> 00:32:17,280
everybody's you know off the top ten top
ten is great but it's a list of things

342
00:32:17,280 --> 00:32:20,730
you don't do
it's not a list of things to do right so

343
00:32:20,730 --> 00:32:24,390
listen next to do right it's in the
application security verification

344
00:32:24,390 --> 00:32:32,490
standard that will tell you you know
don't have path traversal esps will tell

345
00:32:32,490 --> 00:32:39,240
you how to avoid having a path traversal
which is a really important point if we

346
00:32:39,240 --> 00:32:44,880
take step back from the language of code
development as security professionals we

347
00:32:44,880 --> 00:32:50,760
can't show up to our customers and say
don't have this bad outcome we have to

348
00:32:50,760 --> 00:32:54,840
show up and say here's how you
appointment this bad outcome doesn't

349
00:32:54,840 --> 00:32:59,730
sound like a major shift but in terms of
how we talk with people it really does

350
00:32:59,730 --> 00:33:07,500
matter if we start to move into you know
platforms like services and things like

351
00:33:07,500 --> 00:33:14,100
that we can start by defining some
secure architecture standards so AWS you

352
00:33:14,100 --> 00:33:19,770
know a lot of people
well less no like a deter EWS they're

353
00:33:19,770 --> 00:33:24,000
doing a better job in helping
organizations understand how to do

354
00:33:24,000 --> 00:33:29,040
security than just about anybody else
right now and sure has that Microsoft

355
00:33:29,040 --> 00:33:34,860
has their best practices okay so that's
on our website now we're finally going

356
00:33:34,860 --> 00:33:39,120
to get to the point where somebody puts
their hands on keyboard and starts

357
00:33:39,120 --> 00:33:43,350
writing code because what you've done at
this point is you've trained them on how

358
00:33:43,350 --> 00:33:47,340
to write secure code or how to do cloud
security of platforms and operating

359
00:33:47,340 --> 00:33:51,419
systems you've helped them identify the
requirements which is the list of work

360
00:33:51,420 --> 00:33:55,850
of things they're gonna do to actually
do this you've done this based on

361
00:33:55,850 --> 00:34:01,740
standards benchmarks frameworks all
those kinds of things now the first

362
00:34:01,740 --> 00:34:08,580
thing we do is we have to help them
identify their bugs okay so we have to

363
00:34:08,580 --> 00:34:13,110
make this seamless so again I talked
about auto provisioning developers need

364
00:34:13,110 --> 00:34:18,140
to be able to just consume these kinds
of things and find their own bugs okay

365
00:34:18,139 --> 00:34:24,330
all the code quality stuff that goes
into app set that gets built into

366
00:34:24,330 --> 00:34:28,500
templates you can template these things
out they need to be able to find their

367
00:34:28,500 --> 00:34:32,820
bugs because developers are used so
working in an environment where they

368
00:34:32,820 --> 00:34:36,659
write code they see how they messed up
their code they go to stack overflow to

369
00:34:36,659 --> 00:34:39,899
ask other people have not mess with
their code they copy and paste that into

370
00:34:39,899 --> 00:34:46,399
their own stuff and then they try again
which is kind of cynical I'm sorry

371
00:34:46,399 --> 00:34:52,429
and and they learn by making these if

372
00:34:52,880 --> 00:34:58,740
failure fix over and over and over again
insecure we have to be able to do the

373
00:34:58,740 --> 00:35:03,439
same thing we have to give them the
ability to surface all of their own bugs

374
00:35:03,440 --> 00:35:11,640
so that they can figure out how to fix
their bucks so that means you know

375
00:35:11,640 --> 00:35:15,980
building this into those automation
processes continuous delivery

376
00:35:15,980 --> 00:35:20,060
situation that it stinks like Jenkins
Travis CI

377
00:35:20,060 --> 00:35:25,430
gitlab etcetera as a security
organization we still have to build a

378
00:35:25,430 --> 00:35:28,490
direct accountability so all that data
that comes out of these systems and

379
00:35:28,490 --> 00:35:33,049
tools we do need to kind of keep an eye
on there is an accountability aspect to

380
00:35:33,050 --> 00:35:39,380
this that we have to we have to maintain
and then finally we can get to a point

381
00:35:39,380 --> 00:35:44,600
where when we've got a lot of this built
into our development lifecycle we can

382
00:35:44,600 --> 00:35:49,509
start to warn people when they're when
they're proceeding towards production

383
00:35:49,510 --> 00:35:54,800
with something still being wrong whether
that's a code flaw it could be in this

384
00:35:54,800 --> 00:36:00,740
configuration in an easy-to instance or
an Amazon s3 bucket that's open list

385
00:36:00,740 --> 00:36:05,479
goes on and on none we can warn them so
that when they try to build and push

386
00:36:05,480 --> 00:36:09,470
their software into a test or push their
software through a production system and

387
00:36:09,470 --> 00:36:16,430
say hey just you know broke okay
that might be an approach with some

388
00:36:16,430 --> 00:36:22,069
organizations because if you go back to
your threat model and you look at your

389
00:36:22,070 --> 00:36:27,160
actual Boehner abilities you know the
business opportunity is such that you go

390
00:36:27,160 --> 00:36:31,549
yeah our local maturity we're going to
let some bucks go to production but at

391
00:36:31,550 --> 00:36:37,460
least you know about then as you mature
you start to break things

392
00:36:37,460 --> 00:36:42,619
oh I'm sorry this server is up spec this
code up spec you're not going to

393
00:36:42,619 --> 00:36:48,830
production we're gonna stop this from
happening along the way we've got some

394
00:36:48,830 --> 00:36:56,840
code quality tools we've got a you start
with the natural editor and then for

395
00:36:56,840 --> 00:37:00,050
your developers that you shouldn't
actual like ite isn't they're not just

396
00:37:00,050 --> 00:37:04,340
using light dimmer or something
things like sonar lint fortify security

397
00:37:04,340 --> 00:37:08,180
assessments there's a whole bunch of
tools that do static analysis so they're

398
00:37:08,180 --> 00:37:15,259
looking for you know patterns or we call
Manta cabins patterns of bad code so

399
00:37:15,260 --> 00:37:19,160
sequel injection cross-site scripting
cross-site request

400
00:37:19,160 --> 00:37:22,759
dynamic analysis of your security
professional you a little more or less

401
00:37:22,760 --> 00:37:27,230
this is when you're actually interacting
built application that can transact data

402
00:37:27,230 --> 00:37:33,740
with you and then finally and this is
this is I'm going to stop and focus on

403
00:37:33,740 --> 00:37:38,390
this the most in this because this is
overlooked is we also need to look at

404
00:37:38,390 --> 00:37:41,990
the competition of the software that
developers are writing because how many

405
00:37:41,990 --> 00:37:49,009
of you have written an application in
node in any way okay that's awesome

406
00:37:49,010 --> 00:37:55,850
we're people I expected the first thing
you do is you to NPM get and the package

407
00:37:55,850 --> 00:38:01,610
you want and then you use that package
and the actual code that you write is

408
00:38:01,610 --> 00:38:05,150
like usually like one or two lines
because you're just borrowing another

409
00:38:05,150 --> 00:38:10,850
package right so in a typical codebase
if you look at the code that you were

410
00:38:10,850 --> 00:38:16,490
actually write and all the lines of code
in the packages you import the most

411
00:38:16,490 --> 00:38:22,089
charitable estimate is that a node
project contains only 20%

412
00:38:22,090 --> 00:38:27,320
you know code that you wrote the other
80% is code that you brought in from

413
00:38:27,320 --> 00:38:33,830
somebody else and in the open source
world anybody can publish to NPM and the

414
00:38:33,830 --> 00:38:40,819
idea that many many is make all bugs
shallow I would argue that the 20 year

415
00:38:40,820 --> 00:38:45,350
old open SSL on our village we find
suggests that that's not actually true

416
00:38:45,350 --> 00:38:50,509
now that's open source it just doesn't
mean it's a panacea and it doesn't mean

417
00:38:50,510 --> 00:38:53,270
that you can just automatically trusted
so that means we actually have to verify

418
00:38:53,270 --> 00:38:57,020
the security these code packages we're
bringing in a lot of the way we have to

419
00:38:57,020 --> 00:39:02,540
check for these dependencies we talked
about delivering bulton images so AWS

420
00:39:02,540 --> 00:39:08,990
has this concept of golden emi pipelines
so you can actually configure your EWS

421
00:39:08,990 --> 00:39:15,259
accounts to have pre-built images that
are hardened for security that means C

422
00:39:15,260 --> 00:39:21,320
is security benchmarks things like that
and and you know in a more mature

423
00:39:21,320 --> 00:39:24,780
organization you actually stop
taxi

424
00:39:24,780 --> 00:39:29,100
Faith's it sounds kind of crazy you
don't actually pass running instances

425
00:39:29,100 --> 00:39:34,529
you patch your golden image and then
because you're so good at building and

426
00:39:34,530 --> 00:39:38,700
delivering that software or deploying it
out you literally like I said before I

427
00:39:38,700 --> 00:39:42,770
can take down an entire data center you
just destroy an application and you

428
00:39:42,770 --> 00:39:48,060
rebuild it deploy new servers and you
put your throw it on there and then

429
00:39:48,060 --> 00:39:51,930
everything works and that is grossly
oversimplifying how that works but

430
00:39:51,930 --> 00:39:58,830
that's the concept we also shouldn't
overlook containers so some how many of

431
00:39:58,830 --> 00:40:02,790
you have used a docker container or
vacant or or something like that

432
00:40:02,790 --> 00:40:08,580
cool all right I love dr. Wright docker
is so fantastic because no longer do I

433
00:40:08,580 --> 00:40:13,500
have to mess with dependencies and all
that junk i download one image file and

434
00:40:13,500 --> 00:40:19,380
I say dr. up and everything works is so
cool we have to scan these containers

435
00:40:19,380 --> 00:40:21,870
from all our villages we put these
things into production they have

436
00:40:21,870 --> 00:40:26,130
built-in libraries they're kind of an
abstraction of the operating system we

437
00:40:26,130 --> 00:40:35,160
need to make sure that what's running in
there is is is good vulnerability

438
00:40:35,160 --> 00:40:39,899
management so in this type of not have
an operating well but early management

439
00:40:39,900 --> 00:40:44,640
is more than just scanning your assets
typically servers and desktops and

440
00:40:44,640 --> 00:40:50,430
finding the same patches because if
you're if you're operating in this kind

441
00:40:50,430 --> 00:40:55,529
of a model you should actually know what
our abilities you have because you know

442
00:40:55,530 --> 00:41:01,980
the relative age of the of the templated
resource that golden ami that template

443
00:41:01,980 --> 00:41:05,670
container the template that came from
you know the security posture of that

444
00:41:05,670 --> 00:41:10,800
you can infer from that the rest of the
vulnerabilities that are instantiated

445
00:41:10,800 --> 00:41:16,140
from that so if you're golden image is
six months old heaven for bed you know

446
00:41:16,140 --> 00:41:20,520
that all your service that six months
worth of all our abilities so actually

447
00:41:20,520 --> 00:41:25,890
individual instances of servers but you
can also attach that gold am I the other

448
00:41:25,890 --> 00:41:32,310
thing is as we're giving away control
using things like cloud formation we're

449
00:41:32,310 --> 00:41:36,740
not just telling developers they can do
whatever they want

450
00:41:36,740 --> 00:41:40,850
we give templates and we have the
ability to inspect these templates

451
00:41:40,850 --> 00:41:46,890
templates in confirmation are just a
basic descriptive language and we can

452
00:41:46,890 --> 00:41:52,500
audit for obvious dumb stuff if you
should never have port 22 open to the

453
00:41:52,500 --> 00:41:59,010
Internet you can code lint
four or 22 in an in confirmation

454
00:41:59,010 --> 00:42:04,050
template if your confirmation template
is depending on ec2 instance you can say

455
00:42:04,050 --> 00:42:09,230
is it spinning out my ec2 instance or
just some Rando one from the AWS

456
00:42:09,230 --> 00:42:15,690
instance story is catered containers and
then of course the other thing you can

457
00:42:15,690 --> 00:42:20,070
do is if you use a modern owner
abilities can read your environment you

458
00:42:20,070 --> 00:42:24,420
know flawless tableau rapid7
all of those have api's so at every

459
00:42:24,420 --> 00:42:28,620
point when somebody is deployed onto
production you can interrogate the api

460
00:42:28,620 --> 00:42:33,180
of the vulnerability scanner you have in
your environment already and ask it is

461
00:42:33,180 --> 00:42:40,890
this environment still authorized to run
in you know based on current state and

462
00:42:40,890 --> 00:42:45,060
if it's not gradient because you want
your developers to force a conversation

463
00:42:45,060 --> 00:42:49,259
say why why should i am the language
market broken and then we can work

464
00:42:49,260 --> 00:42:56,820
together as that single cohesive team to
to go in and make things right we talk

465
00:42:56,820 --> 00:43:04,470
about instant response okay AWS new club
Trey loves plug try everything put it in

466
00:43:04,470 --> 00:43:09,930
the s3 buckets s3 bucket storage is
cheap okay there are scripts out there

467
00:43:09,930 --> 00:43:14,940
that allow you to do cleveland forensics
on in ec2 instance basically it's gonna

468
00:43:14,940 --> 00:43:19,980
isolate and copy off somewhere else
amazon guard duty allows you

469
00:43:19,980 --> 00:43:22,830
who will learn on bad behaviour and
things that go on in your environment

470
00:43:22,830 --> 00:43:28,730
and guard duty basically sends a
notification not in the sense of a push

471
00:43:28,730 --> 00:43:33,270
text message things like that that's the
eventual outcome it has a notification

472
00:43:33,270 --> 00:43:37,830
service that allows you to do something
based on a condition being true so if

473
00:43:37,830 --> 00:43:42,060
all the sudden guard you have guard a
new role that says you shouldn't have an

474
00:43:42,060 --> 00:43:46,259
any any firewall rule the second that
happens if triggers are caught trail

475
00:43:46,260 --> 00:43:50,610
events you can then script remediation
functions so if somebody just made a

476
00:43:50,610 --> 00:43:56,970
change to a fire mobile that says any
any the log fires the reactive action

477
00:43:56,970 --> 00:44:00,810
fires and you go ahead and roll back
that role you can do that or you can

478
00:44:00,810 --> 00:44:04,410
alert somebody who goes and slap
somebody hand depends on the maturity of

479
00:44:04,410 --> 00:44:08,279
your organization you can look for
obvious stuff who's clearing your logins

480
00:44:08,280 --> 00:44:12,570
who is logging in with you know root
account instead of your your I am

481
00:44:12,570 --> 00:44:19,410
accounts things like that so Incident
Response can also be done in a way that

482
00:44:19,410 --> 00:44:27,540
is and user facing first that puts this
warning this this message of something

483
00:44:27,540 --> 00:44:33,180
that happened into the hands of the the
developers first rather than an incident

484
00:44:33,180 --> 00:44:40,859
responder and then finally to be the
secret detection um if you have if you

485
00:44:40,860 --> 00:44:45,210
get in your organization you have
passwords sitting in those git repos

486
00:44:45,210 --> 00:44:53,160
they're all the scripts it's really ugly
it's bad you shouldn't do it you should

487
00:44:53,160 --> 00:44:58,950
scan your repos so there's tools that
are out there to do that there's better

488
00:44:58,950 --> 00:45:05,399
ways to store your keys that's kind of a
clock run thing Amazon an answer that's

489
00:45:05,400 --> 00:45:10,950
defaults and again this is self-service
right you come to your developer and you

490
00:45:10,950 --> 00:45:18,180
say you don't start with hey you checked
in a bunch of open SSH keys into your

491
00:45:18,180 --> 00:45:22,049
codebase
that's wrong don't do that because their

492
00:45:22,050 --> 00:45:27,440
next question is will power you're right
the solution is show up with solutions

493
00:45:27,440 --> 00:45:35,220
if you don't need a VIPs
things like that these are all patterns

494
00:45:35,220 --> 00:45:39,689
you can search for I mean I literally
went up to give up the other day and I

495
00:45:39,690 --> 00:45:46,130
googled for you know the the top line it
up in a Nova's an SSH private key and

496
00:45:46,130 --> 00:45:51,150
it's too small to see on the screen from
anywhere but there are a million

497
00:45:51,150 --> 00:45:57,150
instances of artists and private keys
and github right now so we've got a

498
00:45:57,150 --> 00:46:02,339
monitor for these things you can use DLP
on the desktop across the network things

499
00:46:02,339 --> 00:46:07,589
like that so the natural question is
where do we go from here

500
00:46:07,589 --> 00:46:11,990
because in a relatively short period of
time I gave you a whole bunch of ideas

501
00:46:11,990 --> 00:46:17,009
and what I'm not going to do is do
things I'm not going to say that you

502
00:46:17,010 --> 00:46:21,450
have to do all of these things and I'm
not going to say that if you do all

503
00:46:21,450 --> 00:46:24,410
these things everything's going to be
great

504
00:46:24,410 --> 00:46:31,920
instead what I'm saying is we have to
adapt we have to become me the service

505
00:46:31,920 --> 00:46:40,440
provider not a gatekeeper and enabler
and take stock of your own capabilities

506
00:46:40,440 --> 00:46:45,299
what you're capable of doing do you have
a strong infrastructure background cool

507
00:46:45,299 --> 00:46:49,470
good work on the ec2 stuff do have a
development background hopefully

508
00:46:49,470 --> 00:46:54,480
developers write better security write
better code security work on these

509
00:46:54,480 --> 00:46:59,190
things and small pieces incrementally
but fundamentally what I'm asking is as

510
00:46:59,190 --> 00:47:05,670
you do so do so with a new mindset a
mindset that says instead of saying no

511
00:47:05,670 --> 00:47:12,359
gives guide rails that drives
accountability without actually stopping

512
00:47:12,359 --> 00:47:18,299
progress that's that's what I mean
that's what I'm proposing that we do

513
00:47:18,299 --> 00:47:28,380
here and this is the evolving developer
mindset a security is everybody's job so

514
00:47:28,380 --> 00:47:32,730
developers now have to truly take
responsibility for their security

515
00:47:32,730 --> 00:47:38,339
outcomes and that it's nice to see but
that doesn't mean that we just put our

516
00:47:38,339 --> 00:47:41,279
hands up and walk away
it is our responsibility

517
00:47:41,280 --> 00:47:45,300
to bring them along on this journey it
has to be integrated into every step of

518
00:47:45,300 --> 00:47:50,940
the process and the earlier you do it
through training through checking for

519
00:47:50,940 --> 00:47:54,780
bugs
the sooner you do that as applications

520
00:47:54,780 --> 00:48:00,930
are being designed built and delivered
the easier it becomes the less it costs

521
00:48:00,930 --> 00:48:08,549
and the less impediment and delay you
impose on your software teams and your

522
00:48:08,550 --> 00:48:18,540
projects so with that I've got at about
two three minutes and I'll open it up to

523
00:48:18,540 --> 00:48:25,610
to see if if this is raised any
questions ready here

524
00:49:06,270 --> 00:49:37,840
I practice we have a set of controls we
are basically coming up with technology

525
00:49:37,840 --> 00:49:44,410
solutions to you know meet those
controls right so I can probably give an

526
00:49:44,410 --> 00:49:48,670
entire talk about how threat modeling
and risk management fit together or

527
00:49:48,670 --> 00:49:53,380
control management but basically if you
have a control that says you must do

528
00:49:53,380 --> 00:49:57,310
password handling safely you have a
bunch of technical solutions for doing

529
00:49:57,310 --> 00:50:02,170
that right and so if you have your your
actual risk management controls

530
00:50:02,170 --> 00:50:06,550
understood and you have a matching link
to your technology patterns then you can

531
00:50:06,550 --> 00:50:10,180
actually validate that as you do these
things they not back to each other

532
00:50:10,180 --> 00:50:19,299
that's my best shot and answer your
question awesome thank you all for your

533
00:50:19,300 --> 00:50:22,440
time I really appreciate it

534
00:51:14,540 --> 00:51:16,600
you

