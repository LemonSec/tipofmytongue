1
00:00:20,200 --> 00:00:26,180
My name is Jeff Man. This is contact
information if you care to contact me

2
00:00:26,180 --> 00:00:29,840
anytime. Happy to hear from you,. Happy to answer

3
00:00:29,840 --> 00:00:35,120
questions. Happy to discuss things. I
consider myself to be a teacher of some

4
00:00:35,120 --> 00:00:41,510
sorts. I am in the consulting world and
again after a brief hiatus in the

5
00:00:41,510 --> 00:00:46,400
meander land, this is my compulsory
company slide because they are paying my

6
00:00:46,400 --> 00:00:50,510
way to be here.
Pretty cool company, nobody's ever heard

7
00:00:50,510 --> 00:00:56,750
of it. And we have a very large and
growing consulting practice. We do you

8
00:00:56,750 --> 00:01:01,040
know, the security and compliance type
stuff. We have a pin testing group, so

9
00:01:01,040 --> 00:01:09,280
on and so forth. So that's enough about that. I do want to apologize ahead of time.

10
00:01:09,280 --> 00:01:15,590
Because the things that I describe in
this talk that are problems you know.

11
00:01:15,590 --> 00:01:21,979
I've been caught up in a, in a lot of it
over the years. As we talk about it,

12
00:01:21,979 --> 00:01:26,960
just keep that in the back of the mind. A
friend of mine named Paul Ascendorian.

13
00:01:26,960 --> 00:01:33,110
Anyone know who Paul Ascendorian is? He's given a couple talks. One is called everything

14
00:01:33,110 --> 00:01:37,250
that he learned about security, he
learned from kung-fu movies. And another

15
00:01:37,250 --> 00:01:44,869
one he gives is everything I learned
about security, gosh what was the second

16
00:01:44,869 --> 00:01:54,710
one he did? Kung-fu and Hip-hop I think is the second one. So, I thought I'd give a talk some day. I haven't put it together yet, but

17
00:01:54,710 --> 00:01:58,720
this is the one that I'm gonna give.
Some day. [People laugh].

18
00:01:59,450 --> 00:02:05,040
So, a little bit about me, just to give
a little bit of context of why I'm

19
00:02:05,040 --> 00:02:09,570
up here pontificating and talking about
what I think is wrong with the security

20
00:02:09,570 --> 00:02:15,350
world. Or are asking us essentially what are
we doing here?

21
00:02:15,350 --> 00:02:22,739
37 some odd years in the business.
Officially 35. I got my first start in

22
00:02:22,740 --> 00:02:28,620
1984 and I'll tell a little bit about
that. Most of my time in terms of my

23
00:02:28,620 --> 00:02:34,620
formative years, was spent at NSA. I
started there actually in 1986 and this was

24
00:02:34,620 --> 00:02:40,170
a popular t-shirt back then. And I think NSA
might still be behind schedule.

25
00:02:40,170 --> 00:02:46,500
While I was at NSA very briefly, I worked
on what was then called the InfoSec side

26
00:02:46,500 --> 00:02:50,100
of the house, the defensive side of the
house. And I was in what was called the

27
00:02:50,100 --> 00:02:55,730
manual cryptosystem shop. We dealt with
paper. One-time pads. Paper cipher systems.

28
00:02:55,730 --> 00:03:00,119
Things that we usually do in puzzles
these days. Go up to cypher village,

29
00:03:00,120 --> 00:03:04,350
you can probably find some upstairs. But
one of the first things I did when I was

30
00:03:04,350 --> 00:03:09,299
there 8687
was there was this newfangled thing

31
00:03:09,300 --> 00:03:13,050
called a desktop PC and we had customers
that said is there any way you could

32
00:03:13,050 --> 00:03:16,500
write a computer program to do this
encryption and decryption on the

33
00:03:16,500 --> 00:03:20,640
one-time pad because it takes hours
sometimes to do it and we're like yeah

34
00:03:20,640 --> 00:03:25,049
we can do that so I was actually
responsible for as near as I can tell

35
00:03:25,050 --> 00:03:32,070
the first quote-unquote software based
crypto system that NSA ever produced in

36
00:03:32,070 --> 00:03:35,130
the process of working with one-time
pads I came up with this little

37
00:03:35,130 --> 00:03:40,709
Cryptologic aid this little cycler wheel
here that does the algorithm for a

38
00:03:40,709 --> 00:03:45,630
particular type of one-time pad this was
used by the US Special Forces for quite

39
00:03:45,630 --> 00:03:50,670
a few years they called it the wizzy
wheel I called it the Visionaire wheel I

40
00:03:50,670 --> 00:03:54,809
got a cash award when I when I came up
with this and my boss wrote it up and it

41
00:03:54,810 --> 00:03:59,720
was titled man reinvents wheel

42
00:04:02,130 --> 00:04:05,070
I spent a little bit of time on the
operation side of the house when most

43
00:04:05,070 --> 00:04:09,390
people know about and I'd say what they
think of when they think of NSA is the

44
00:04:09,390 --> 00:04:14,880
operation side the offensive side and it
says the ears of the country listening

45
00:04:14,880 --> 00:04:18,480
to all of our adversaries and I happen
to be there during the time of the first

46
00:04:18,480 --> 00:04:23,400
Gulf engagement Desert shield/desert
storm which lasted Desert Shield was a

47
00:04:23,400 --> 00:04:27,450
series I guess a couple of weeks or
months and Desert Storm was over an

48
00:04:27,450 --> 00:04:33,240
hour's and then the last part of my NSA
career and I actually do another talk

49
00:04:33,240 --> 00:04:37,710
that goes more into detail of this but I
ended up being in an office back on

50
00:04:37,710 --> 00:04:42,239
InfoSec side at the beginnings of sort
of the popularity of the internet and

51
00:04:42,240 --> 00:04:47,640
everybody jumping on the internet and I
ended up being working for a group that

52
00:04:47,640 --> 00:04:53,610
started to learn how to do pen testing
and we did that for NSA this book came

53
00:04:53,610 --> 00:04:59,310
out a couple of years ago called dark
territory in that book chapter four is

54
00:04:59,310 --> 00:05:04,110
entitled eligible receivers anybody read
this book a couple people recommended

55
00:05:04,110 --> 00:05:10,860
reading in this book in this chapter
there's a paragraph here and I will read

56
00:05:10,860 --> 00:05:16,590
it dramatically to you if I'm an
indulgent per month starting founded in

57
00:05:16,590 --> 00:05:20,669
the middle during its most sensitive
drills the red team worked out of the

58
00:05:20,670 --> 00:05:27,090
chamber recalled the pit which is so
secret that few people at NSA knew it

59
00:05:27,090 --> 00:05:33,539
existed and even they could enter
without first passing through comedy

60
00:05:33,540 --> 00:05:39,180
booths that cool
I actually was part of the pit I was one

61
00:05:39,180 --> 00:05:43,380
of the founding members of the pit the
pit existed in a building this is an

62
00:05:43,380 --> 00:05:49,849
aerial shot of some buildings just south
just west BWI Airport fall it was

63
00:05:49,849 --> 00:05:54,589
this one and until it was dead actually
just a group of hackers group of guys

64
00:05:54,589 --> 00:06:01,669
working there were six of us oh and the
audio is there we used to play this when

65
00:06:01,669 --> 00:06:13,308
we were happy two of us still work at
NSA four of us around in the private

66
00:06:13,309 --> 00:06:17,509
sector out in the real world the only
other one that I have the permission to

67
00:06:17,509 --> 00:06:22,669
let you know who it is is Raoul you may
have heard of them he founded this

68
00:06:22,669 --> 00:06:28,818
company called tenable and which just
went public and some of my good friends

69
00:06:28,819 --> 00:06:32,629
are still working there it might be of
the audience and I wonder why they

70
00:06:32,629 --> 00:06:40,039
haven't retired that's another story
and I have to say this and is it too

71
00:06:40,039 --> 00:06:44,389
early to drink because when I say PCI
usually somebody puts a drink in my hand

72
00:06:44,389 --> 00:06:54,289
I am due but before you before you
dismiss me because the PCI and this is a

73
00:06:54,289 --> 00:06:59,990
list of the customers that I have I was
at USA for 10 years and I am allowed to

74
00:06:59,990 --> 00:07:04,249
say that I was the qsa for the TJX
companies they were breached and back in

75
00:07:04,249 --> 00:07:09,559
2008 I started with them after that but
I was Ark USA for six years up until the

76
00:07:09,559 --> 00:07:13,249
time when I stopped doing in Heartland
Payment Systems it's a matter of public

77
00:07:13,249 --> 00:07:18,289
record they were also reached back in
2008 in 2009 I was part of the team that

78
00:07:18,289 --> 00:07:23,899
went we sort of smoked jumped in and
helped him get back into compliance as

79
00:07:23,899 --> 00:07:31,579
it were back in the day so I wanted
there the diverse experience talking to

80
00:07:31,579 --> 00:07:35,119
lots and lots and lots of different
types of companies most of these

81
00:07:35,119 --> 00:07:40,309
companies security is not their core
competency never has been never probably

82
00:07:40,309 --> 00:07:46,699
never will be but I'll go down swinging
trauma one of my first lessons in

83
00:07:46,699 --> 00:07:51,709
security happened Ashley back when I
started working for the government which

84
00:07:51,709 --> 00:07:58,059
was summer of 1984 I got it
turn position working for a naval

85
00:07:58,059 --> 00:08:04,169
research facility and my job was simply
I was working for a physicist who was

86
00:08:04,169 --> 00:08:10,389
doing research and had been doing
research for many years in the area of

87
00:08:10,389 --> 00:08:16,029
what's called any submarine warfare and
he had collected all sorts of research

88
00:08:16,029 --> 00:08:20,860
information articles books and put it
and put it literally in this filing

89
00:08:20,860 --> 00:08:27,699
cabinet this lock safe and he had gotten
some money and was able to buy one of

90
00:08:27,699 --> 00:08:31,959
these newfangled desktop PCs and I'm
pretty sure that's the model that he had

91
00:08:31,959 --> 00:08:38,289
bought and he'd bought a database
program I think it was debates to if

92
00:08:38,289 --> 00:08:42,370
anybody remembers that and my job for
the summer was simply to go through the

93
00:08:42,370 --> 00:08:47,439
the filing cabinet and catalogue
everything that was in there and and

94
00:08:47,439 --> 00:08:52,920
produced some sort of rudimentary
database of everything in his holdings

95
00:08:52,920 --> 00:08:57,370
what I found amazing at one point when I
was going through this material some of

96
00:08:57,370 --> 00:09:00,309
the material he had had been checked out
of the research library at the

97
00:09:00,309 --> 00:09:04,930
organization and the date that it had
been checked out and had been sitting in

98
00:09:04,930 --> 00:09:09,279
this filing cabinet was before I was
born so there was a little and I was

99
00:09:09,279 --> 00:09:14,410
what 20 22 at the time so there's a lot
of information in this thing so the

100
00:09:14,410 --> 00:09:18,639
lesson that I learned about security and
I won't read it to you you can sort of

101
00:09:18,639 --> 00:09:24,430
read it while I'm talking yeah basically
I I committed a security violation and I

102
00:09:24,430 --> 00:09:32,859
left the safe unlocked one night and my
boss was nearly apoplectic because it

103
00:09:32,860 --> 00:09:36,910
was so inept enough for anybody to
violate the rules because they have all

104
00:09:36,910 --> 00:09:40,719
sorts of rules and procedures of how you
check out at the end of the night make

105
00:09:40,720 --> 00:09:44,529
sure that the safe is locked make sure
everything's put away and I was sort of

106
00:09:44,529 --> 00:09:49,360
a young careless college kid that didn't
think much of it and and quite honestly

107
00:09:49,360 --> 00:09:53,829
my thought was you know what's the big
deal I work in a facility that's

108
00:09:53,829 --> 00:10:00,969
protected by a wall barbed-wire fences
and perimeter protections to get into

109
00:10:00,970 --> 00:10:04,389
the building that I worked you had to go
past the security desk a security

110
00:10:04,389 --> 00:10:08,750
checkpoint to get into the office that I
worked

111
00:10:08,750 --> 00:10:12,380
to get through a locked door II had to
know the combination and they had guards

112
00:10:12,380 --> 00:10:15,140
all over the buildings that were
constantly walking around checking

113
00:10:15,140 --> 00:10:18,890
things in fact that's how I might
incident was discovered because they

114
00:10:18,890 --> 00:10:22,400
would come in in the offices in the
middle of the night and try all the

115
00:10:22,400 --> 00:10:27,260
safes and they if they found it open
they put this pink slip inside and that

116
00:10:27,260 --> 00:10:31,340
said come see us in security and would
lock it up and that was the beginning of

117
00:10:31,340 --> 00:10:35,360
the incident
so my first lesson in security just for

118
00:10:35,360 --> 00:10:37,970
business the context of this discussion
didn't have anything to do with

119
00:10:37,970 --> 00:10:41,900
computers and it didn't really I have to
do with any kind of a breach or

120
00:10:41,900 --> 00:10:47,209
disclosure or loss I simply didn't
follow the rules and I got into a

121
00:10:47,210 --> 00:10:52,490
significant amount of trouble for it and
you guys do lock-picking safecracking

122
00:10:52,490 --> 00:10:59,240
for fun or profit I thought my boss was
apoplectic the first time it happened

123
00:10:59,240 --> 00:11:03,770
the second time I happen in the lesson I
learned was that when you're locking one

124
00:11:03,770 --> 00:11:07,579
of these safes it's not good enough to
just kind of do a quick spin of the dial

125
00:11:07,580 --> 00:11:12,350
you have to turn in a couple times to
set all the tumblers so I had closed it

126
00:11:12,350 --> 00:11:17,930
thought it was locks on the dial tried
to handle thought I was good second time

127
00:11:17,930 --> 00:11:24,380
had happened if I thought my boss was
apoplectic the first time and I can't

128
00:11:24,380 --> 00:11:28,040
begin to describe how mad he wasn't me
the second time

129
00:11:28,040 --> 00:11:34,459
lesson learned so in the context of what
I'm trying to get at this morning and I

130
00:11:34,460 --> 00:11:39,770
really intend this to be a conversation
or at least get all of us thinking maybe

131
00:11:39,770 --> 00:11:44,480
perhaps a little bit differently about
this thing that we're doing that we call

132
00:11:44,480 --> 00:11:52,430
security I think we have a problem this
is one of the problems I think we have

133
00:11:52,430 --> 00:11:58,160
but the basic problem that I see
especially since I've been in this

134
00:11:58,160 --> 00:12:03,589
business so long I've seen this for so
many times is all the stuff that we do

135
00:12:03,589 --> 00:12:08,030
all the smart people that are trying to
solve security and do all the things

136
00:12:08,030 --> 00:12:11,779
that we do all the effort and all the
money that's in the

137
00:12:11,779 --> 00:12:16,970
industry and in the business they're
still breaches happening and I given up

138
00:12:16,970 --> 00:12:22,220
trying to keep this slide current it's
it's just too hard because every time I

139
00:12:22,220 --> 00:12:26,509
give a talk there's some variation of
this slide that I usually work into my

140
00:12:26,509 --> 00:12:32,720
talk it's just too hard you know just
this week there's in the last week or

141
00:12:32,720 --> 00:12:40,129
two I didn't try to get it a little bit
current Microsoft Patch Tuesday started

142
00:12:40,129 --> 00:12:44,360
breaking things so they had to kill the
patch it's not exactly a security issue

143
00:12:44,360 --> 00:12:50,839
or is it this one was really interesting
I think this just came out yesterday we

144
00:12:50,839 --> 00:12:55,100
talked about it I do a podcast by the
way called security weekly we were

145
00:12:55,100 --> 00:12:59,420
recording last night we were talking
about this you know who knew that

146
00:12:59,420 --> 00:13:04,399
something that was designed to be
perfectly secure WPA three fixing all

147
00:13:04,399 --> 00:13:10,339
the problems in WPA and wpa2 and then we
discovered that it's got problems and

148
00:13:10,339 --> 00:13:13,790
that's kind of the pattern of our whole
industry and that's been the way it's

149
00:13:13,790 --> 00:13:17,230
been for many many years
but then you have something like dips

150
00:13:17,230 --> 00:13:22,009
all the technical solutions that we
pursue all the research and all the

151
00:13:22,009 --> 00:13:26,360
smart people doing all the technology
stuff and then somebody's doing

152
00:13:26,360 --> 00:13:30,589
something with passwords and believe it
or not and if you've been in the

153
00:13:30,589 --> 00:13:34,250
business a while you might know this but
passwords are still kind of one of the

154
00:13:34,250 --> 00:13:38,360
big ways that most bad guys get in and
that's certainly the way that a lot of

155
00:13:38,360 --> 00:13:43,519
pen testers you know do the initial
breach getting the initial access so

156
00:13:43,519 --> 00:13:48,319
somehow we haven't fundamentally solved
some of the basic problems which is what

157
00:13:48,319 --> 00:13:55,670
frustrates me and makes me asked what
are we doing here we have we've invested

158
00:13:55,670 --> 00:13:59,240
so much in technology and trying to
solve the problems of security and

159
00:13:59,240 --> 00:14:03,769
there's so many aspects and elements and
things to do it you've gotten it and I

160
00:14:03,769 --> 00:14:08,300
apologize if you can't read the detail
of this search for this diagram that's

161
00:14:08,300 --> 00:14:12,949
out there it's on Google the sea so my
map but basically all the fine print is

162
00:14:12,949 --> 00:14:17,189
all the different things that a sea so
needs to worry about to secure there

163
00:14:17,190 --> 00:14:21,540
organization there's a lot up there I've
been in this business 37 years I know

164
00:14:21,540 --> 00:14:26,219
what most of that stuff is I I don't
claim to be an expert on all of it maybe

165
00:14:26,220 --> 00:14:32,010
some aspects here and there but I don't
know how anybody any human oughta make

166
00:14:32,010 --> 00:14:39,569
using automation or not can keep up with
all this so something's wrong so what I

167
00:14:39,570 --> 00:14:43,260
want us to try to do for a little bit
this morning is maybe think differently

168
00:14:43,260 --> 00:14:49,230
about security when I started at NSA one
of the lessons that I learned when I was

169
00:14:49,230 --> 00:14:54,690
Duke going through my training courses
is even something like the NSA the idea

170
00:14:54,690 --> 00:15:00,090
of encrypting communications protecting
communications was problematic

171
00:15:00,090 --> 00:15:03,990
throughout at least our country's
history there were people you know

172
00:15:03,990 --> 00:15:08,150
politicians people in government that
said why do we need to protect our

173
00:15:08,150 --> 00:15:14,189
messages and communications and there's
this quote that was that I learned early

174
00:15:14,190 --> 00:15:19,350
on at NSA the gentlemen don't read each
other's mail you know that's just not

175
00:15:19,350 --> 00:15:26,370
civilized well we know that that doesn't
work the basics of security and I would

176
00:15:26,370 --> 00:15:31,380
submit to you and I'm chuckling a little
bit because last night when we were

177
00:15:31,380 --> 00:15:35,370
recording our segment we interviewed a
guy that was talking about this new

178
00:15:35,370 --> 00:15:39,210
thing called the need to focus on data
and it's all about the data and I'm like

179
00:15:39,210 --> 00:15:45,120
no it's not that's not new that's how
it's been forever anybody ever hear of

180
00:15:45,120 --> 00:15:49,970
CIA the three aspects of data security
this is not new

181
00:15:49,970 --> 00:15:55,380
confidentiality keeping secrets you know
keeping your sensitive data protected so

182
00:15:55,380 --> 00:16:00,000
the people that shouldn't be reading it
can't read it integrity making sure that

183
00:16:00,000 --> 00:16:05,100
the data is real and availability making
sure you can get to the data these are

184
00:16:05,100 --> 00:16:09,360
the basic components of data security
and this has nothing to do with

185
00:16:09,360 --> 00:16:13,920
technology per se it has to do with
understanding what your data is that

186
00:16:13,920 --> 00:16:19,469
sensitive that you need to protect and
what in what way you need to protect it

187
00:16:19,470 --> 00:16:24,390
and then figuring out with the use of
the technology in your organization

188
00:16:24,390 --> 00:16:28,370
which of these things you need to focus
on

189
00:16:30,880 --> 00:16:34,970
did it do its thing okay I just throw
that in there because I think it's cool

190
00:16:34,970 --> 00:16:39,519
and I didn't make it I found it
anybody know what it is this is from

191
00:16:39,519 --> 00:16:47,269
sneakers there's a scene in sneakers
where the the two main characters the

192
00:16:47,269 --> 00:16:50,420
good guy in the back dad they're having
conversations anybody know what they're

193
00:16:50,420 --> 00:16:57,170
sitting on a crack very good the the bad
guy Ben Kingsley says to the good guy

194
00:16:57,170 --> 00:17:02,930
Robert Redford there's a war out there
old friend a world war and it's not

195
00:17:02,930 --> 00:17:08,659
about who's got the most bullets it's
about who controls the information what

196
00:17:08,660 --> 00:17:15,890
we see and hear how we work what we
think it's all about the information we

197
00:17:15,890 --> 00:17:19,360
all agree that that's kind of hid no
argument there

198
00:17:19,359 --> 00:17:26,059
1992 is when this movie came out and by
the way when I was at NSA I used to work

199
00:17:26,059 --> 00:17:31,070
on the grave that's where we did all of
our number crunching and the Cray that I

200
00:17:31,070 --> 00:17:35,059
worked on you could now see in the
National Cryptologic Museum and that

201
00:17:35,059 --> 00:17:40,820
makes me feel really old but if you're
ever in the Maryland area of highly

202
00:17:40,820 --> 00:17:44,540
recommend going the National Cryptologic
Museum if you're there hit me up if I

203
00:17:44,540 --> 00:17:46,940
happen to be around
I'll come give you a guided tour and

204
00:17:46,940 --> 00:17:52,480
I'll point all the things that I used to
work on that's now in a museum

205
00:18:00,170 --> 00:18:08,810
oh yeah no no sticker for you here's my
contention and this is my grumpy

206
00:18:08,810 --> 00:18:13,010
comments' me or you know old-timers kind
of approach to things because when I

207
00:18:13,010 --> 00:18:16,670
learned InfoSec it didn't have anything
to do with the computer some technology

208
00:18:16,670 --> 00:18:20,960
I really think technology is our problem
at the end of the day you can quote me

209
00:18:20,960 --> 00:18:26,240
on that but that's reinforced like when
I was at NSA he's starting to get into

210
00:18:26,240 --> 00:18:35,450
the - I need to learn how to you know
fight back the hecklers of the audience

211
00:18:35,450 --> 00:18:40,610
oh I haven't won that when I was at NSA
in the latter part when we were starting

212
00:18:40,610 --> 00:18:44,719
to do the red teaming and the pen
testing the office that I was in and

213
00:18:44,720 --> 00:18:49,340
initially was called fielding systems
evaluation so we were looking at the

214
00:18:49,340 --> 00:18:54,949
systems that we were designing trying to
make sure that they were as secure in

215
00:18:54,950 --> 00:18:59,120
use in input implementation is that they
had been designed because lo and behold

216
00:18:59,120 --> 00:19:06,620
the way NSA very often would break our
enemy's communications is we took

217
00:19:06,620 --> 00:19:10,850
advantage of the fact that they were
misused a one-time pad is the most

218
00:19:10,850 --> 00:19:16,969
secure cryptographic system in the world
it's cryptographically mathematically

219
00:19:16,970 --> 00:19:23,570
unbreakable if you use it correctly and
and the operative part of the name one

220
00:19:23,570 --> 00:19:28,429
time is what makes it unbreakable so if
you have a page of a key that you're

221
00:19:28,430 --> 00:19:33,590
using to do a message one time you're
good if you're trying to save paper and

222
00:19:33,590 --> 00:19:38,990
conserve resources and use that page for
a month or more and for multiple

223
00:19:38,990 --> 00:19:42,890
messages you've introduced a
vulnerability that can be exploited and

224
00:19:42,890 --> 00:19:49,000
it can be
can be read so there was a lot of

225
00:19:49,000 --> 00:19:54,429
reticence at the NSA at the time to do
anything in terms of migrating it over

226
00:19:54,429 --> 00:19:59,169
to software and there was also this
belief and when my early lessons was

227
00:19:59,169 --> 00:20:04,419
that if anything is created by man it
can be broken by man I've been thinking

228
00:20:04,419 --> 00:20:08,799
about it lately and I think as a society
we sort of checked out in terms of

229
00:20:08,799 --> 00:20:13,779
overall data security of privacy when we
decided to just put all online and

230
00:20:13,779 --> 00:20:19,389
digitized I mean if we're really honest
with ourselves we've already said we're

231
00:20:19,389 --> 00:20:23,678
willing to sacrifice the measure of
security of privacy because of the

232
00:20:23,679 --> 00:20:28,750
benefit we get at the speed and and all
the information sharing and everything

233
00:20:28,750 --> 00:20:33,460
that goes along with all the cool stuff
that technology brings us you can agree

234
00:20:33,460 --> 00:20:38,440
or disagree with me but what I want to
get to and what I want to you know sort

235
00:20:38,440 --> 00:20:42,130
of the make the main between what I'm
trying to talk about this morning is one

236
00:20:42,130 --> 00:20:44,860
of the things that I learned at NSA was
something that was called the risk

237
00:20:44,860 --> 00:20:50,799
equation let me show it to you this is
the way I learned it these are words

238
00:20:50,799 --> 00:20:55,990
that we all know these are words that we
all use in our in our in our daily lives

239
00:20:55,990 --> 00:21:01,000
and our work lives you go to a trade
show look at all that I haven't noticed

240
00:21:01,000 --> 00:21:05,380
so much out here but you go to the large
vendor areas very often you'll see

241
00:21:05,380 --> 00:21:10,510
variations of these words out here one
of my frustrations is because I go to a

242
00:21:10,510 --> 00:21:14,350
lot of shows and conferences and see
these words used in print all the time

243
00:21:14,350 --> 00:21:21,549
is it very quickly becomes clear to me
that people aren't using the words at

244
00:21:21,549 --> 00:21:25,539
least in the context of the way I
learned the words and that's a nice way

245
00:21:25,539 --> 00:21:32,230
of saying they don't know what they're
talking about so very basically I know

246
00:21:32,230 --> 00:21:35,740
there's lots of variations of actual
risk equations because people like

247
00:21:35,740 --> 00:21:39,820
mathematicians and accountants they
actually try to assign real values but

248
00:21:39,820 --> 00:21:45,939
just at a conceptual level at a high
level this thing that we call this is a

249
00:21:45,940 --> 00:21:51,370
function of three different things let's
call them variables vulnerabilities

250
00:21:51,370 --> 00:21:57,840
threats and countermeasures that's the
way I learned

251
00:22:00,930 --> 00:22:05,650
if you notice security isn't even
mentioned in this risk equation so hold

252
00:22:05,650 --> 00:22:10,720
that thought
the risk parameters at a high level

253
00:22:10,720 --> 00:22:14,920
again it's the way I learned it and I'm
sharing this with you because did you

254
00:22:14,920 --> 00:22:20,440
know it occurred to me at some point I
get sort of irritated when I hear the

255
00:22:20,440 --> 00:22:25,060
terms misused but then it occurs to me
people don't know because they haven't

256
00:22:25,060 --> 00:22:28,990
been taught so I'm trying to teach you
not necessarily the right way to think

257
00:22:28,990 --> 00:22:34,630
about this but the way it was learned
classically and we can decide later on

258
00:22:34,630 --> 00:22:39,010
if there's something to be learned here
if there's still a take away from

259
00:22:39,010 --> 00:22:43,330
learning the classic meanings of these
terms so your vulnerabilities are simply

260
00:22:43,330 --> 00:22:46,600
I'll ask people what is the
vulnerability and people struggle with

261
00:22:46,600 --> 00:22:52,959
giving me a definition think of it as a
weakness just a weakness one word a

262
00:22:52,960 --> 00:22:57,160
weakness threats the way I learned
number PT threats are the bad guys

263
00:22:57,160 --> 00:23:04,570
threats are the ones that want to do
harm to you and then countermeasures are

264
00:23:04,570 --> 00:23:09,970
the things that you do to try to protect
or minimize or reduce the likelihood of

265
00:23:09,970 --> 00:23:16,360
success of threats taking advantage of
the vulnerabilities to do something bad

266
00:23:16,360 --> 00:23:21,669
to you with me so far we'll go back into
we will drill down to this a little bit

267
00:23:21,670 --> 00:23:29,830
in the next couple slides my source by
the way is what use well it's still

268
00:23:29,830 --> 00:23:36,129
called the national information systems
security intersect glossary the version

269
00:23:36,130 --> 00:23:41,260
that I used came out probably in the 80s
it's been updated over time I believe

270
00:23:41,260 --> 00:23:45,670
it's available on the internet so search
for that you might be able to find a

271
00:23:45,670 --> 00:23:50,590
copy this is where I'm getting the
actual sort of dictionary definitions of

272
00:23:50,590 --> 00:23:55,750
these terms to share with you so the way
I learned at the InfoSec manual this is

273
00:23:55,750 --> 00:24:03,190
the definition of race okay see how the
words are in there but they mean

274
00:24:03,190 --> 00:24:07,630
different things like vulnerability and
threat I'm avoiding and reading it to

275
00:24:07,630 --> 00:24:09,600
you
as I hate it when people read slides I

276
00:24:09,600 --> 00:24:16,090
assume y'all can read this is the
definition of threatened this as far as

277
00:24:16,090 --> 00:24:20,020
I can remember and this just might be my
mind feeling and I should be in the

278
00:24:20,020 --> 00:24:24,908
museum the way I learned to threat as I
said was people the definition that

279
00:24:24,909 --> 00:24:29,080
shows up in the manual these days is
more like what I hear people talking

280
00:24:29,080 --> 00:24:34,510
about threats these these days which are
the bad things that happen to you the

281
00:24:34,510 --> 00:24:40,059
things that we use usually call threats
in this industry I call them a tax it

282
00:24:40,059 --> 00:24:44,350
makes more sense to me hopefully it'll
make more sense to you as we drill down

283
00:24:44,350 --> 00:24:50,830
on this this is a I pulled this slide
from a deck that's literally over 20

284
00:24:50,830 --> 00:24:55,090
years old this is when I first came out
into the private sector and was trying

285
00:24:55,090 --> 00:24:59,379
to teach companies that had never done
security before about security this is

286
00:24:59,380 --> 00:25:03,570
how we would describe threats and we
would talk about threats being

287
00:25:03,570 --> 00:25:08,230
essentially people but there's a there's
other things in there but most of that

288
00:25:08,230 --> 00:25:14,710
is people and then there was also the
motivation I'm open to suggestion but is

289
00:25:14,710 --> 00:25:19,029
there anything missing from this that
applies today that isn't up here has

290
00:25:19,029 --> 00:25:24,130
this changed the whole lot or is this
pretty much still to still the way

291
00:25:24,130 --> 00:25:29,010
things are anyone have a strong opinion
one way or the other

292
00:25:29,010 --> 00:25:37,960
somebody say something something thank
you no it hasn't changed but you'll hear

293
00:25:37,960 --> 00:25:40,990
a lot of conversations from a lot of
vendors and a lot of the and I'm not

294
00:25:40,990 --> 00:25:44,470
going to pick on the sales and marketing
people but they've got to find ways of

295
00:25:44,470 --> 00:25:48,520
spinning all this and make it sound new
you know I've seen in the last couple

296
00:25:48,520 --> 00:25:50,980
months
you know there's new idea that insider

297
00:25:50,980 --> 00:25:58,029
threat is something we need to worry
about anyway then we get to

298
00:25:58,029 --> 00:26:02,980
vulnerability and again vulnerability is
a weakness and it's a weakness in

299
00:26:02,980 --> 00:26:08,220
systems and systems are not just the
technology systems by definition or

300
00:26:08,220 --> 00:26:12,980
anything that goes in its the people
it's data flows it's the work flows

301
00:26:12,980 --> 00:26:19,080
again hard to keep the slide current but
it's particularly jaw-dropping to me

302
00:26:19,080 --> 00:26:23,850
when we find vulnerabilities that have
been there for 20 years especially in

303
00:26:23,850 --> 00:26:28,168
the things that hacker in the hacker
communities things that we value and

304
00:26:28,169 --> 00:26:32,940
still we think okay this is good this is
safe we can use this we it's protected

305
00:26:32,940 --> 00:26:35,580
and then lo and behold oh we've been
using something that's been vulnerable

306
00:26:35,580 --> 00:26:40,379
all this time and then finally the last
variable of the equation something

307
00:26:40,380 --> 00:26:46,309
that's called countermeasures the things
that are done to when you can't

308
00:26:46,309 --> 00:26:50,129
eliminate all the vulnerabilities and
you can't eliminate all the threats

309
00:26:50,130 --> 00:26:53,789
what's left you countermeasure if you do
something to mitigate you do something

310
00:26:53,789 --> 00:26:58,919
to minimize you do something to offset
the vulnerabilities and the threats and

311
00:26:58,919 --> 00:27:09,120
that all wraps up into this thing we
call risk so my question to you is what

312
00:27:09,120 --> 00:27:14,570
then is your hold that thought

313
00:27:16,370 --> 00:27:21,750
don't listen to me if you don't want to
but let's go back to the risk equation

314
00:27:21,750 --> 00:27:26,490
this is one's slightly different I added
one that I think is more applicable to

315
00:27:26,490 --> 00:27:32,130
the commercial world the private sector
that we live in and essentially the

316
00:27:32,130 --> 00:27:36,990
original risk equation that I showed you
the risk in terms of national security

317
00:27:36,990 --> 00:27:41,940
of the DoD the way I learned it the risk
was all about human life in one way

318
00:27:41,940 --> 00:27:46,010
shape or form protecting our troops
protecting our forces protecting our

319
00:27:46,010 --> 00:27:51,809
diplomatic corps in our citizens
traveling abroad but it all loosely had

320
00:27:51,809 --> 00:27:57,289
to do with protecting human life in the
commercial world I will submit to you

321
00:27:57,289 --> 00:28:03,629
that there are only two risks that
organizations face and that's the

322
00:28:03,630 --> 00:28:10,980
ability alternately to earn revenue to
make make a living and the second aspect

323
00:28:10,980 --> 00:28:16,409
is the cost of doing business the cost
of doing everything that they do to run

324
00:28:16,409 --> 00:28:20,220
the business or to make the
business quote unquote air-quote secure

325
00:28:20,220 --> 00:28:28,230
so what's missing from this equation man
which is what makes it hard is that

326
00:28:28,230 --> 00:28:34,670
every aspect of it has a price tag on it
and ultimately the risk that a

327
00:28:34,670 --> 00:28:40,440
organization is thinking about is how
much do they want to spend versus how

328
00:28:40,440 --> 00:28:46,890
much they think they're going to make
that's what it boils down to but as you

329
00:28:46,890 --> 00:28:50,850
look at this risk equation here's the
real question that I want to ask you to

330
00:28:50,850 --> 00:28:58,409
think about if you agree that there's
these four components or three

331
00:28:58,410 --> 00:29:02,790
components that produce a product in
this equation the math a little bit I'm

332
00:29:02,790 --> 00:29:06,659
not a mathematician and if there's this
thing called Vaughn abilities and

333
00:29:06,660 --> 00:29:10,350
there's the Saint called threats and
there's this thing called counter

334
00:29:10,350 --> 00:29:14,600
measures and for the sake of our
discussion let's say counter measure is

335
00:29:14,600 --> 00:29:19,350
synonymous with security which we
haven't figured out what it is yet but

336
00:29:19,350 --> 00:29:24,449
my question is think about this whole
industry and how so much of what we do

337
00:29:24,450 --> 00:29:29,280
revolves around discovering
vulnerabilities the conference here

338
00:29:29,280 --> 00:29:33,870
other conferences all the products that
are out there all the technologies out

339
00:29:33,870 --> 00:29:39,540
there how do you get 90% of this
industry in some way shape or form is

340
00:29:39,540 --> 00:29:45,330
focused on vulnerabilities okay but if
that's a component a variable in an

341
00:29:45,330 --> 00:29:49,889
equation where there's another variable
or component that is something that's

342
00:29:49,890 --> 00:29:55,080
called security then what if everything
that we're doing in terms of

343
00:29:55,080 --> 00:30:01,370
vulnerabilities isn't security at all
what if it's just our job

344
00:30:01,370 --> 00:30:06,090
we're admins we're supposed to keep
boxes secure we're supposed to update

345
00:30:06,090 --> 00:30:09,540
the cache we're supposed to have secure
configurations we're developers writing

346
00:30:09,540 --> 00:30:14,760
code that is supposed to be impervious
to attack what if all that isn't

347
00:30:14,760 --> 00:30:17,700
security I'm not saying it's not I'm
just saying this does that might want

348
00:30:17,700 --> 00:30:22,020
mind works think about it and the second
part of that question is if everything

349
00:30:22,020 --> 00:30:24,860
that we do
our industry and all these hacker

350
00:30:24,860 --> 00:30:28,790
conferences and all these measures that
focused on vulnerabilities and to some

351
00:30:28,790 --> 00:30:32,080
degree threats because insider threats
are a new thing we need to worry about

352
00:30:32,080 --> 00:30:36,409
what else is there
what if all all that we think about

353
00:30:36,410 --> 00:30:41,270
that's associated with all facilities
with threats isn't security what is

354
00:30:41,270 --> 00:30:49,270
security
that's the takeaway essentially and

355
00:30:49,630 --> 00:30:55,760
that's essentially the slide that's
talks about what is just and agree with

356
00:30:55,760 --> 00:31:00,680
me disagree with me all I'm asking is
think about it what is security if it's

357
00:31:00,680 --> 00:31:04,190
not everything we think of in terms of
vulnerabilities and everything that we

358
00:31:04,190 --> 00:31:07,940
everything we think of in terms of
threats what else is it I think there's

359
00:31:07,940 --> 00:31:12,590
an answer and I think it's something
that's worth discussing and I don't know

360
00:31:12,590 --> 00:31:17,600
that it ultimately helps us in the end
in the long run but I think defining and

361
00:31:17,600 --> 00:31:21,980
agreeing on our terminology and what
things are hopefully is something that

362
00:31:21,980 --> 00:31:26,540
we is a way to apply sort of the classic
thinking of information security and

363
00:31:26,540 --> 00:31:32,240
maybe that will help us to be a more
secure society moving forward because I

364
00:31:32,240 --> 00:31:43,210
don't know what else to try essentially
yes with me somebody laughs or something

365
00:31:43,660 --> 00:31:49,070
so if you're at all intrigued about what
I'm saying would love to talk to you

366
00:31:49,070 --> 00:31:54,139
please feel free to disagree with me
probe deeply if I defended your but

367
00:31:54,140 --> 00:31:58,370
that's what I do
I'm sorry but if you want to if you want

368
00:31:58,370 --> 00:32:02,060
to hear me talk more if you want to
continue continue the conversation I

369
00:32:02,060 --> 00:32:06,889
mentioned earlier I knew a podcast
called Paul security weekly we recorded

370
00:32:06,890 --> 00:32:13,620
our 600th episode last night

371
00:32:13,620 --> 00:32:18,449
I am known as a Jedi Master don't ask me
why it has something to do with

372
00:32:18,450 --> 00:32:22,980
communication skills I'm in a book that
was published a couple months ago if

373
00:32:22,980 --> 00:32:28,289
anybody happens to have a copy I'd be
happy to sign it for them I am a member

374
00:32:28,289 --> 00:32:32,908
of the of an austere group called the
Cabal of the curmudgeons which is mostly

375
00:32:32,909 --> 00:32:36,690
people that have dinner with jeans
Baffert once a year at the RSA

376
00:32:36,690 --> 00:32:43,799
Conference raise your hand if you don't
know who gene Spafford is okay I am

377
00:32:43,799 --> 00:32:48,779
failing as an educator and the people my
age are failing because there's

378
00:32:48,779 --> 00:32:52,980
something to be learned from the history
genes Baffert was one of the authors of

379
00:32:52,980 --> 00:32:56,880
what was I considered to be the Bible
back at the beginnings of this thing

380
00:32:56,880 --> 00:33:01,230
that we call cybersecurity but back in
the day we called it internet security

381
00:33:01,230 --> 00:33:06,870
so he was one of the authors of a book
called basic and I forget the title of

382
00:33:06,870 --> 00:33:12,178
that really basic UNIX and internet
security so big thick volume everything

383
00:33:12,179 --> 00:33:15,960
to do because everything was Unix back
then UNIX is the operating system that

384
00:33:15,960 --> 00:33:20,640
existed before Linux it was closed
source Linux was open source again it's

385
00:33:20,640 --> 00:33:25,500
a history lesson anyway G Stafford one
of the offers he's been in the business

386
00:33:25,500 --> 00:33:30,750
probably 50 years brilliant mind and we
get to hang out with them and they let

387
00:33:30,750 --> 00:33:37,200
me into the group a couple years ago
I'm also on a game called Freaker life

388
00:33:37,200 --> 00:33:44,149
one of the one of the in hacker anism
cars is me and this is a fundraiser for

389
00:33:44,149 --> 00:33:49,320
hack for kids they happen to be
downstairs and if you're interested they

390
00:33:49,320 --> 00:33:52,889
actually have a couple copies in my car
that I've autographed for and they're

391
00:33:52,890 --> 00:33:56,610
they're selling them in a silent auction
is again it's another form of the

392
00:33:56,610 --> 00:34:01,020
fundraiser so I'm saying downstairs go
upstairs I'm sorry we're in the basement

393
00:34:01,020 --> 00:34:05,279
find the cypher village it's in the room
of all the different villages find the

394
00:34:05,279 --> 00:34:10,050
hack for kids table and feel free to
sign up for the silent auction and raise

395
00:34:10,050 --> 00:34:14,460
a little bit of money to try to help
kids learn all about this thing that

396
00:34:14,460 --> 00:34:19,270
we're doing called hacking it's my
contact information if you're into

397
00:34:19,270 --> 00:34:32,469
and if I have any questions don't really
want to ever get in one my wife has a

398
00:34:32,469 --> 00:34:38,020
car that if you put on cruise control a
little like brake automatically if it

399
00:34:38,020 --> 00:34:43,060
gets too close I hated because you know
not that I'm a tailgater or a bad driver

400
00:34:43,060 --> 00:34:47,379
or an aggressive male driver or anything
but I hate that it slows down because I

401
00:34:47,379 --> 00:34:50,770
like the approaching a part of pass it
I'm like you know I was approaching that

402
00:34:50,770 --> 00:34:54,969
car and I'm not ever overtaking it it's
because I keep going slower and slower

403
00:34:54,969 --> 00:34:59,500
it also irritates you it like vibrates
that you start straining out of the lane

404
00:34:59,500 --> 00:35:05,470
I figured out how to turn that off and I
don't know what it's monitoring the

405
00:35:05,470 --> 00:35:09,399
occasional it'll pop up and say driver
needs coffee driver needs coffee and

406
00:35:09,400 --> 00:35:15,160
pull over take a break I'm not a big fan
of technology in general that's my true

407
00:35:15,160 --> 00:35:18,490
confession and self-driving cars being
one of them

408
00:35:18,490 --> 00:35:21,459
I'd rather take my it's gonna say I'd
rather take the bus but that'll be

409
00:35:21,460 --> 00:35:29,500
automated she's something yes sir
oh sure because we all know who Alberto

410
00:35:29,500 --> 00:35:41,320
has done is you're welcome that was an
easy one yes way in the back and I

411
00:35:41,320 --> 00:35:45,400
didn't do it the first time the question
is how do I feel about companies

412
00:35:45,400 --> 00:35:49,480
replacing security with automated
security not a big fan of that either

413
00:35:49,480 --> 00:35:54,280
although I understand that because of
the volume of data and traffic that's on

414
00:35:54,280 --> 00:35:57,730
networks today
we just sort of created this mess

415
00:35:57,730 --> 00:36:04,690
there's no way to handle it without
automation but I would my old way of

416
00:36:04,690 --> 00:36:08,109
thinking is you've still got to have
human eyes somewhere along the way use

417
00:36:08,109 --> 00:36:14,890
the automation to handle that handle the
volume of data and cull it down to

418
00:36:14,890 --> 00:36:21,279
something that's manageable but you need
you still need a set of eyes on over the

419
00:36:21,280 --> 00:36:23,750
years the organizations that I've worked
with

420
00:36:23,750 --> 00:36:29,420
the ones that I have found to be the
most pure went back when I did Pintrest

421
00:36:29,420 --> 00:36:33,470
penetration testing the ones that were
more difficult to break into or they

422
00:36:33,470 --> 00:36:39,319
detected you more early ultimately every
one of those companies that were sort of

423
00:36:39,320 --> 00:36:44,960
doing things right or doing things well
they had one person at least one person

424
00:36:44,960 --> 00:36:50,480
whose attitude was more or less not on
my box not on my watch so they kind of

425
00:36:50,480 --> 00:36:54,800
took it personally and what they did
ultimately was they knew everything

426
00:36:54,800 --> 00:36:57,890
about their box they knew what was
normal they knew what was normal

427
00:36:57,890 --> 00:37:01,609
behavior they knew what all the
different indicators of monitoring the

428
00:37:01,609 --> 00:37:05,779
same results would look like they knew
what the network traffic flow was

429
00:37:05,780 --> 00:37:10,700
supposed to look like and they had a
sense a knack for seeing the anomalies

430
00:37:10,700 --> 00:37:15,680
it wasn't always scientific but they
knew what was normal and so they were

431
00:37:15,680 --> 00:37:21,290
more likely to detect what was that more
automation takes you there to some

432
00:37:21,290 --> 00:37:26,450
degree but I don't know that it were
there yet in terms of automation it goes

433
00:37:26,450 --> 00:37:30,859
back to me to the old movie wargames
where if you actually remember the

434
00:37:30,859 --> 00:37:35,990
premise of the movie they were trying to
turn the missile defense system that had

435
00:37:35,990 --> 00:37:40,729
controlled all the nukes in America over
to a computer and let the computer

436
00:37:40,730 --> 00:37:44,780
decide when to fire the missile or not
because they were concerned that humans

437
00:37:44,780 --> 00:37:50,630
wouldn't pull the trigger because humans
would would be too illogical and be too

438
00:37:50,630 --> 00:37:54,950
emotional and not want to willfully kill
millions of people and destroy the world

439
00:37:54,950 --> 00:37:59,089
so they wanted to turn that
decision-making over to a machine and

440
00:37:59,089 --> 00:38:03,470
that's the whole a AI and machine
learning argument and all the fiction

441
00:38:03,470 --> 00:38:08,240
you know there's dozens of movies and
stories out there that sort of ask this

442
00:38:08,240 --> 00:38:13,220
whole question of you know when the
machines take over you know are other

443
00:38:13,220 --> 00:38:17,049
machines going to protect humans or
or the machines going to think that

444
00:38:17,049 --> 00:38:21,339
worth where the problem that is creating
all the problems in the world so we must

445
00:38:21,339 --> 00:38:29,589
be destroyed that's right
it was fighting I was driving around the

446
00:38:29,589 --> 00:38:34,930
other day and whoever the DJ was in the
radio station I was listening to he was

447
00:38:34,930 --> 00:38:39,759
talking about this Alexa his Alexa had
said happy birthday to him when he woke

448
00:38:39,760 --> 00:38:44,230
up that morning and he was kind of
freaked out that Alexa knew his birthday

449
00:38:44,230 --> 00:38:48,940
it's one of the other people in the
studio I told him about it and they went

450
00:38:48,940 --> 00:38:53,230
and asked Alexa Hey look so when's my
birthday and Alexa didn't know what was

451
00:38:53,230 --> 00:38:57,369
freaky about the conversation was she
was referring to Alexa as if Alexa was a

452
00:38:57,369 --> 00:39:01,869
person in the entire conversations I
thought was just amazing what Alexa

453
00:39:01,869 --> 00:39:05,500
notices like that's it it was just
disturbing on so many but that was cool

454
00:39:05,500 --> 00:39:10,690
it was me but also profoundly disturbing
at least to me any other questions I

455
00:39:10,690 --> 00:39:17,309
have no idea that we're doing on time
it's magical

456
00:39:47,570 --> 00:39:55,670
so a very long question and I'll try to
repeat it for posterity it's again in

457
00:39:55,670 --> 00:40:01,020
government terms the the risk equation
I'd said is in terms of human life the

458
00:40:01,020 --> 00:40:04,980
risk to human life I've been in
commercial terms it's really funny so

459
00:40:04,980 --> 00:40:09,000
the question was have I ever seen
organizations that do sort of take into

460
00:40:09,000 --> 00:40:13,590
account human life and care and do they
spend more or less money on that that

461
00:40:13,590 --> 00:40:19,910
pretty much it yeah I'm old and blind so
I think you were giving me a thumbs up

462
00:40:19,910 --> 00:40:25,560
now that I've repeated the question I
mean you can actually think about

463
00:40:25,560 --> 00:40:33,470
answering the question you know so my
initial statement both parts are

464
00:40:33,470 --> 00:40:37,439
generalizations I mean there's a
sections to everything

465
00:40:37,440 --> 00:40:42,599
there are certainly companies that are
more caring about humanitarian efforts

466
00:40:42,599 --> 00:40:47,250
and things like that or they're
improving over time I don't personally

467
00:40:47,250 --> 00:40:53,790
use Apple devices I don't have an iPhone
and I have two reasons the first of

468
00:40:53,790 --> 00:40:57,210
which is I'm sort of a militant
left-handed person and there was some

469
00:40:57,210 --> 00:40:59,460
iPhone
I forget which version it was they came

470
00:40:59,460 --> 00:41:04,380
out that didn't work for left-handed
people whose left-handed people who hold

471
00:41:04,380 --> 00:41:07,680
the phone in the right hand where's
everybody else hold it in their left

472
00:41:07,680 --> 00:41:11,879
hand and apparently however they put the
antenna in the phone it was covered up

473
00:41:11,880 --> 00:41:15,450
if you were holding it in your right
hand so I was like apples dead to me

474
00:41:15,450 --> 00:41:19,410
because they don't think about left
anything but the other reason more to

475
00:41:19,410 --> 00:41:26,910
your question is the use of conflict
minerals and how conflict minerals are

476
00:41:26,910 --> 00:41:33,118
attained and I have to go way off the
rails the conflict minerals are minerals

477
00:41:33,119 --> 00:41:37,560
that are basically either acquired
through slavery or some sort of illegal

478
00:41:37,560 --> 00:41:42,570
activity where humans aren't really
regarded too well and one of the key

479
00:41:42,570 --> 00:41:45,990
ingredients of the screens and your
phones that make them available make

480
00:41:45,990 --> 00:41:50,299
them able to be touched and
used as instead of you know in the old

481
00:41:50,300 --> 00:41:54,440
days where there used to be buttons is I
forget what the name of it is somebody

482
00:41:54,440 --> 00:42:00,190
shouted out no but it's a mineral that's
a conflict I know and they're sorry

483
00:42:00,190 --> 00:42:07,070
sapphire I think there's organizations
that track you know the major phone

484
00:42:07,070 --> 00:42:11,840
manufacturers and keep track of sort of
their record on how closely they pay

485
00:42:11,840 --> 00:42:15,860
attention to where they're getting their
materials from or who's assembling the

486
00:42:15,860 --> 00:42:21,710
phones for them you know in third world
countries and of course you know what do

487
00:42:21,710 --> 00:42:27,290
we do in our industry we do offshore
development in many cases because it's

488
00:42:27,290 --> 00:42:33,170
yeah it's cheaper not saying it's a
human rights abuse or anything but it's

489
00:42:33,170 --> 00:42:38,150
a complex question it's a complex world
we live in but you know the motivation

490
00:42:38,150 --> 00:42:42,470
at the end of the day very often this
money so thank you very much I'm around

491
00:42:42,470 --> 00:42:44,919
all day and

492
00:43:39,279 --> 00:43:45,059
you

