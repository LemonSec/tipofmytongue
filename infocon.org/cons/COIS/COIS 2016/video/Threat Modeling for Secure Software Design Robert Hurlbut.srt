1
00:00:00,000 --> 00:00:07,040
great great so whenever I talk about
threat modeling for secure software

2
00:00:07,040 --> 00:00:11,889
design and just a little bit about
myself my name is robert her butt and

3
00:00:11,889 --> 00:00:16,669
I'm actually coming in from connecticut
that's where I live is where I work but

4
00:00:16,670 --> 00:00:22,160
I also do a lot of work across the
country as well as here in Ohio I have

5
00:00:22,160 --> 00:00:27,349
some family in Cleveland on me in here
all the time and one of the things that

6
00:00:27,349 --> 00:00:34,280
I focus on is software security and as
you can see there I have my own company

7
00:00:34,280 --> 00:00:39,660
I'm independent but I helped a lot of
companies a lot of teams understand some

8
00:00:39,660 --> 00:00:45,718
of the issues with software security and
how best to address those issues that's

9
00:00:45,719 --> 00:00:49,739
my contact information at the bottom I
have my website Robert hope that dot com

10
00:00:49,739 --> 00:00:52,230
I'm also on Twitter if you're interested

11
00:00:52,230 --> 00:00:57,218
take a look and see what's going on that
I do talk about threat modeling and

12
00:00:57,219 --> 00:01:05,309
other security issues out there today on
Twitter so welcome to fall so the start

13
00:01:05,309 --> 00:01:09,399
off with today in talking about secure
software design just out of curiosity

14
00:01:09,400 --> 00:01:13,600
wanna have an understanding of my
audience how many of you are software

15
00:01:13,600 --> 00:01:19,630
developers by chance if you have you how
many of you perhaps managed a software

16
00:01:19,630 --> 00:01:26,330
development team a few of you how many
of you are in some way impacted by

17
00:01:26,330 --> 00:01:33,560
software in your company or security
with that software ok a lot of people a

18
00:01:33,560 --> 00:01:37,290
lot of people and I think that's true of
a lot of companies were we're really

19
00:01:37,290 --> 00:01:42,250
seeing it as an issue more and more you
know before we were developed software

20
00:01:42,250 --> 00:01:46,729
and security was more of a byproduct it
wasn't something we thought about from

21
00:01:46,729 --> 00:01:51,689
the get-go we added on later because we
said oh wow we probably do need a login

22
00:01:51,689 --> 00:01:57,750
form of some sort we do need a way to
check it all people have access or not

23
00:01:57,750 --> 00:02:01,570
and we did that after the fact you know
we said that was a lasting we're gonna

24
00:02:01,570 --> 00:02:05,809
do we're gonna run everything initially
most wide-open

25
00:02:05,810 --> 00:02:09,068
and so it became something we did later

26
00:02:09,068 --> 00:02:12,200
well it turns out you know we're
thinking about secure software design

27
00:02:12,200 --> 00:02:18,149
you find out very quickly building
security systems is difficult it's not

28
00:02:18,150 --> 00:02:23,670
easy you know we've been writing
software we've been building systems for

29
00:02:23,670 --> 00:02:28,599
a while and if you've been doing that
for a while you've also noticed thinking

30
00:02:28,599 --> 00:02:33,790
of all the potential issues within a
system from a security standpoint is not

31
00:02:33,790 --> 00:02:37,929
the easiest thing in the world but one
of the things that's key is design

32
00:02:37,930 --> 00:02:44,060
understanding your system and how it's
put together and designing it

33
00:02:44,060 --> 00:02:48,500
appropriately accordingly the way it
should be in terms of security and other

34
00:02:48,500 --> 00:02:50,790
features early on

35
00:02:50,790 --> 00:02:54,590
makes a difference and in fact one of
the things we're trying to do here is

36
00:02:54,590 --> 00:03:00,989
building appropriate security that means
secure but not hindering people from

37
00:03:00,989 --> 00:03:06,310
doing their work allowing people to be
able to use the system but not be so

38
00:03:06,310 --> 00:03:10,650
locked down that they can't do anything
but at the same time making sure that

39
00:03:10,650 --> 00:03:14,590
were checking things and where we have
the proper access control and so forth

40
00:03:14,590 --> 00:03:19,239
and the best way to do that is again
through secure design but then the

41
00:03:19,239 --> 00:03:24,030
question becomes what how do you do that
and maybe even some reasons that you

42
00:03:24,030 --> 00:03:28,769
might wonder today why even care what we
what we do that well let's look at some

43
00:03:28,769 --> 00:03:31,769
examples of breakdowns

44
00:03:32,989 --> 00:03:36,940
mass assignment this is saying something
that happened a few years ago I don't

45
00:03:36,940 --> 00:03:42,950
know if you know about this but get hub
you know you can have projects on their

46
00:03:42,950 --> 00:03:51,388
repositories and so forth where you can
store year your code and check it out

47
00:03:51,389 --> 00:03:55,959
and so forth well it turns out that
there was a particular developer few

48
00:03:55,959 --> 00:04:00,930
years ago who wanted to make some
changes but he didn't have admin

49
00:04:00,930 --> 00:04:07,380
privileges and he happened to notice and
get help is running on Ruby on Rails you

50
00:04:07,380 --> 00:04:11,920
happen to notice that he can actually
send code or a model if you will because

51
00:04:11,920 --> 00:04:13,630
you're using the MVC pattern

52
00:04:13,630 --> 00:04:19,779
model-view-controller pattern that he
could send in a model where with a flag

53
00:04:19,779 --> 00:04:25,070
that something on the lines up is admin
true or false you can actually raises

54
00:04:26,000 --> 00:04:31,900
elevated privileges so that's what he
did he simply set is that many true and

55
00:04:31,900 --> 00:04:37,729
lo and behold he's able to get in to
what he needed to do now he also did

56
00:04:37,730 --> 00:04:43,260
that with a few other accounts just out
of curiosity hey this is great I can

57
00:04:43,260 --> 00:04:47,469
actually elevate my privilege hey this
is bad I can elevate my privilege

58
00:04:47,470 --> 00:04:50,710
anybody can do this and in fact it was
found

59
00:04:50,710 --> 00:04:55,120
fortunately not a real attack that
happened but it was found that

60
00:04:55,120 --> 00:05:01,090
potentially a lots and lots thousands of
projects could be compromised the same

61
00:05:01,090 --> 00:05:08,840
way now that was a vulnerability but he
was also a design flaw as well that

62
00:05:08,840 --> 00:05:15,630
fiercest things in place we have binding
and by simply compromising this through

63
00:05:15,630 --> 00:05:21,060
an attack somebody could create all
kinds of havoc that vulnerability is

64
00:05:21,060 --> 00:05:22,200
still there

65
00:05:22,200 --> 00:05:29,539
whether you know you you know it or not
for example in asp.net MVC that's still

66
00:05:29,540 --> 00:05:34,250
there there's no way to protect against
it other than know it's there and

67
00:05:34,250 --> 00:05:37,530
designed for it and protect against it

68
00:05:37,530 --> 00:05:41,080
ok it's just just there so I can use
that to change

69
00:05:41,640 --> 00:05:47,370
payments or or you know prices on items
just sits there you have to protect

70
00:05:47,370 --> 00:05:53,440
against it since input validation it's a
design issue another one as we saw last

71
00:05:53,440 --> 00:05:58,950
summer was the Jeep Cherokee hack maybe
you know about that okay there was

72
00:05:58,950 --> 00:06:02,599
something I recently came out on Twitter
where one in four Americans have

73
00:06:02,600 --> 00:06:08,810
forgotten about this are only remember
it rather 3044 got it but believe me

74
00:06:08,810 --> 00:06:13,750
four out of four car makers still
remember it very well if you remember

75
00:06:13,750 --> 00:06:18,360
two guys found out that through the
entertainment system they are able to

76
00:06:18,360 --> 00:06:21,510
get out into the internet or vice versa

77
00:06:21,510 --> 00:06:22,630
the internet through

78
00:06:22,630 --> 00:06:26,690
having an employee and being able to
control through the entertainment center

79
00:06:26,690 --> 00:06:33,270
system the car itself which included you
know turning off the car speeding up the

80
00:06:33,270 --> 00:06:39,010
car and other things like that which of
course again is really bad but that's a

81
00:06:39,010 --> 00:06:45,650
design flaw somebody for whatever reason
hadn't thought through that oh if we

82
00:06:45,650 --> 00:06:51,020
allow that opening in it might
potentially turn into an attack now

83
00:06:51,020 --> 00:06:55,770
fortunately no one was harmed and
certainly affects came out very shortly

84
00:06:55,770 --> 00:07:01,549
after in fact I remember I was at black
hat and DEFCON this past year and I saw

85
00:07:01,550 --> 00:07:06,800
you know the presentations and shortly
after or before it came out with a fix

86
00:07:06,800 --> 00:07:08,200
but again

87
00:07:08,200 --> 00:07:12,150
design issues the last one to mention
his target now it's not software

88
00:07:12,150 --> 00:07:18,599
specific but it was a design issue you
know why do you give a company full

89
00:07:18,600 --> 00:07:23,170
access to your network and that's what
happened through HVAC system or through

90
00:07:23,170 --> 00:07:27,420
an HVAC company they have full access to
the network and then the attacker sent

91
00:07:27,420 --> 00:07:32,030
to come through that way and to the rest
of the system would look like their HVAC

92
00:07:32,030 --> 00:07:37,390
employees now again not software
specific but it is a design problem

93
00:07:37,390 --> 00:07:47,349
where we didn't localize the particular
access ok so lots of design issues but

94
00:07:47,350 --> 00:07:52,230
as I think about it and as I like to
talk about you know what we're missing

95
00:07:52,230 --> 00:07:57,160
here is we're thinking about security
sign is also thinking about the threat

96
00:07:57,160 --> 00:08:03,190
model that's attached to those things to
talk about threat modeling well you know

97
00:08:03,190 --> 00:08:05,540
from mine something we already do in our
lives

98
00:08:05,540 --> 00:08:11,580
you know any time we locked the doors to
our house or lock the windows or locked

99
00:08:11,580 --> 00:08:17,130
the door Sarkar you know we are thinking
about these things because why we

100
00:08:17,130 --> 00:08:22,040
already thinking about will potentially
if I leave my door open somebody might

101
00:08:22,040 --> 00:08:27,310
come in and get my things if I don't
lock my car door somebody might come in

102
00:08:27,310 --> 00:08:31,600
take my car or if I leave things sitting
in the car seat somebody might see it

103
00:08:31,600 --> 00:08:33,440
and take it if it looks valuable

104
00:08:33,440 --> 00:08:38,990
right so we already think about these
things in terms of what could happen

105
00:08:38,990 --> 00:08:47,210
right what can go wrong way the risks
and act accordingly and actually believe

106
00:08:47,210 --> 00:08:51,010
it or not when we're doing that we're
already doing that kind of modeling

107
00:08:51,010 --> 00:08:56,640
we're talking more about that today so
some things that I think threat modeling

108
00:08:56,640 --> 00:09:00,470
will help you do and this is in
particular especially with application

109
00:09:00,470 --> 00:09:06,420
security is it helps the builders the
breakers at the defenders Daniel you

110
00:09:06,420 --> 00:09:12,160
maybe put yourself in those categories
breakers builders and offenders the

111
00:09:12,160 --> 00:09:16,310
builders basically understand the
security features and be able to put

112
00:09:16,310 --> 00:09:22,579
those in place the Breakers know what
the critical attack surfaces are and the

113
00:09:22,580 --> 00:09:26,500
defenders to understand the critical
attack patterns that includes intrusion

114
00:09:26,500 --> 00:09:30,430
detection you know what is it that you
know its most critical in our system

115
00:09:31,310 --> 00:09:35,920
it also I believe helps with all kinds
of other areas and security and business

116
00:09:35,920 --> 00:09:42,400
you know this is really trying to solve
many many problems and ways to do it so

117
00:09:42,400 --> 00:09:46,880
where's the fit in well it's one of the
security tools in particular application

118
00:09:46,880 --> 00:09:51,560
security tools but it's also in many
other applications as well we already

119
00:09:51,560 --> 00:09:56,719
know about these tools and automated
testing causing an analysis detection

120
00:09:56,720 --> 00:10:02,520
and so on but threatening really is a
tool that's thinking tool if you will

121
00:10:02,520 --> 00:10:08,050
it's a process it's a tool as I
mentioned earlier that I believe can

122
00:10:08,050 --> 00:10:14,150
help with secure system and software
design and its not automated though

123
00:10:14,150 --> 00:10:20,050
there are some tools out there and we'll
talk about those but it really is a

124
00:10:20,050 --> 00:10:25,819
thinking tool a way of thinking about
your system so as I mentioned it's a

125
00:10:25,820 --> 00:10:29,730
process of understanding your system and
the potential threats against your

126
00:10:29,730 --> 00:10:30,690
system

127
00:10:30,690 --> 00:10:35,990
a typical threat model will include the
understanding of your system

128
00:10:35,990 --> 00:10:41,420
the threats have been identified the
probability of those threats other words

129
00:10:41,420 --> 00:10:43,209
you know how likely that happen

130
00:10:43,209 --> 00:10:50,888
the potential harm impact and then along
with that you should have a priority and

131
00:10:50,889 --> 00:10:59,529
plan for mitigating those threats based
on the risk that you identify a couple

132
00:10:59,529 --> 00:11:05,839
quotes here I I like talking about these
because I find this true it many times

133
00:11:05,839 --> 00:11:09,990
in my own experience of working with
software development teams but that he

134
00:11:09,990 --> 00:11:13,470
was an awesome incomplete inaccurate
threat model gets my admiration and not

135
00:11:13,470 --> 00:11:18,059
much of my time because they don't need
it and that's from Michael Howard who

136
00:11:18,059 --> 00:11:23,660
wrote secure CO two years ago works at
Microsoft another one from Brookstone

137
00:11:23,660 --> 00:11:28,399
field who wrote a great book contract
Milan last year came out last summer as

138
00:11:28,399 --> 00:11:34,189
I practice it cannot be the province of
a tech elite it really is best known by

139
00:11:34,189 --> 00:11:39,118
all the development team and that's how
I practice right moment as well I don't

140
00:11:39,119 --> 00:11:43,129
think of it as just something you know
the consultant only knows but when I

141
00:11:43,129 --> 00:11:48,079
come into a team and help the team I'm
trying to help everybody understand

142
00:11:48,079 --> 00:11:51,748
about threat modeling because I believe
it's something that we all need to think

143
00:11:51,749 --> 00:11:56,209
about and as I mentioned to you earlier
it's something we actually already do in

144
00:11:56,209 --> 00:12:02,939
our everyday life but how do you apply
that then to developing systems and

145
00:12:02,939 --> 00:12:04,368
securing systems

146
00:12:04,369 --> 00:12:10,249
we'll talk some more about that some
some quick definitions trade agent it's

147
00:12:10,249 --> 00:12:13,610
just someone or processing can do harm
your system

148
00:12:13,610 --> 00:12:20,119
a threat is essentially the goal you
know what is it that that adversary once

149
00:12:20,119 --> 00:12:25,329
what is it that they want to do now
that's different than a vulnerability of

150
00:12:25,329 --> 00:12:31,239
vulnerability is the flaw in the system
that allows the threat to be realized

151
00:12:31,240 --> 00:12:37,129
ok does that make sense so I may have
multiple vulnerabilities I may have a

152
00:12:37,129 --> 00:12:42,339
single injection vulnerability but
perhaps it's buried somewhere deep into

153
00:12:42,339 --> 00:12:46,429
my system that nobody actually has
access to what if that won't or Billy is

154
00:12:46,429 --> 00:12:49,429
actually available and accessible on my
website

155
00:12:50,940 --> 00:12:56,600
then what attacker can do is use that
vulnerability to access my database go

156
00:12:56,600 --> 00:12:59,630
all the way from the front end to the
database and perhaps collect credit card

157
00:12:59,630 --> 00:13:05,320
information or other kinds of the
database information that's a threat so

158
00:13:05,320 --> 00:13:06,420
that's the difference

159
00:13:06,420 --> 00:13:11,709
the vulnerability is order allows the
attacker to enact a threat so very

160
00:13:11,710 --> 00:13:16,800
different and we do focus a lot on
vulnerabilities in their analysis cancer

161
00:13:16,800 --> 00:13:22,030
so far but the threat is what actually
makes use of those vulnerabilities to

162
00:13:22,030 --> 00:13:28,140
then planned the attack and actually
carry out the attack and of course the

163
00:13:28,140 --> 00:13:32,240
attack motivated and skilled
sufficiently skilled trade agent takes

164
00:13:32,240 --> 00:13:35,680
advantage of the vulnerability and
that's kind of important because you

165
00:13:35,680 --> 00:13:39,150
know you have to think about the
motivations and also have to think about

166
00:13:39,150 --> 00:13:43,699
the skills and that kind of comes into
the attacker profile no years ago we

167
00:13:43,700 --> 00:13:47,980
talked about script kiddies and how they
would take things off the internet and

168
00:13:47,980 --> 00:13:52,590
run them and they have no idea what it
does but it sounds fun let's try it and

169
00:13:52,590 --> 00:13:57,500
all the way up to state sponsored
criminals who are using very

170
00:13:57,500 --> 00:14:03,010
sophisticated attacks against our our
systems you know various ways of

171
00:14:03,010 --> 00:14:09,340
compromising our systems and and taking
sensitive data so all of those things

172
00:14:09,340 --> 00:14:15,230
are still attacks but it's interesting
to see based on the motivation and how

173
00:14:15,230 --> 00:14:21,280
much skill they have how those attacks
change and that can also impact how we

174
00:14:21,280 --> 00:14:27,120
build our threat model as well as said
anything about you and maybe even

175
00:14:27,120 --> 00:14:30,360
further anything that you're worried
about losing you know that's a big thing

176
00:14:30,360 --> 00:14:36,220
they're so when you do it as well
threatening really should be your first

177
00:14:36,220 --> 00:14:41,180
priority I believe in STL see if you're
you're following any kind of software

178
00:14:41,180 --> 00:14:45,449
development lifecycle it should be one
of the first things that you do and

179
00:14:45,450 --> 00:14:50,000
that's where it really fits the
requirements and design phase you know

180
00:14:50,000 --> 00:14:54,300
when you're starting to build your
application and you know believe me I

181
00:14:54,300 --> 00:14:57,920
understand I've been doing this for 30
years I know what it is like to be

182
00:14:57,920 --> 00:15:01,740
sitting down and looking at a screen and
saying you know let's just build this

183
00:15:01,740 --> 00:15:03,250
and it's a prototype

184
00:15:03,250 --> 00:15:08,060
nobody will ever use it and guess what
that thing becomes what becomes the the

185
00:15:08,060 --> 00:15:13,199
the main application for the company and
you all you know we never really thought

186
00:15:13,200 --> 00:15:19,570
through it we never really well this is
where you need to take a step back and

187
00:15:19,570 --> 00:15:25,060
start looking at well how's this gonna
be designed and what are the security

188
00:15:25,060 --> 00:15:31,300
implications of this morning will also
help uncover requirements and that's

189
00:15:31,300 --> 00:15:35,130
actually what threat modeling is also
about is helping you understand security

190
00:15:35,130 --> 00:15:38,230
requirements that you have within your
system you know some people say well

191
00:15:38,230 --> 00:15:42,400
football is just the architecture part
that's only one part of it but it's not

192
00:15:42,400 --> 00:15:46,310
your architecture threat modeling
determines what your requirements are

193
00:15:46,310 --> 00:15:52,310
secured to us you can also make a party
gradual sprint planning how many of you

194
00:15:52,310 --> 00:15:58,130
are familiar with agile methodology and
following it currently excellent you can

195
00:15:58,130 --> 00:16:02,830
also do this in a sprint planning
session we're at the very beginning your

196
00:16:02,830 --> 00:16:05,280
building up your features and your
understanding

197
00:16:05,280 --> 00:16:09,770
you know what are the various pieces of
this you can also apply the question

198
00:16:09,770 --> 00:16:14,949
what's her threat model where the
security implications of this feature if

199
00:16:14,950 --> 00:16:21,820
we put in place so great place to do
that as well now what if we didn't and

200
00:16:21,820 --> 00:16:26,820
unfortunately I get more calls about
help for threat modeling not on the

201
00:16:26,820 --> 00:16:31,850
other slide behind this light what if we
didn't we built it we put it together

202
00:16:31,850 --> 00:16:36,850
it's running it's been out there and now
we're always sudden we're getting some

203
00:16:36,850 --> 00:16:39,850
some problems you know some security
issues

204
00:16:40,490 --> 00:16:44,240
indications that is going to be thought
or authorization because we thought what

205
00:16:44,240 --> 00:16:51,050
we do and always say you know it's not
too late to start but realize you know

206
00:16:51,050 --> 00:16:57,880
it has no some consequences with it for
for example it will be pretty difficult

207
00:16:57,880 --> 00:17:01,540
to change major design decisions you may
have made a decision

208
00:17:02,200 --> 00:17:07,620
way early on that just completely wrong
but at the time it made sense and then

209
00:17:07,619 --> 00:17:12,050
you get all the way down and say ok now
I gotta think about security now gotta

210
00:17:12,050 --> 00:17:16,649
do a few things and that's expensive so
ideally you want to do that

211
00:17:16,650 --> 00:17:21,160
getting but even if you didn't I always
say do it anyway

212
00:17:21,160 --> 00:17:26,330
always make it a part even if you're
starting from scratch and you've not

213
00:17:26,329 --> 00:17:29,429
done this before I say still do it think
about it

214
00:17:29,430 --> 00:17:37,270
plying threat modeling to your own
system so typical session I'm involved

215
00:17:37,270 --> 00:17:41,270
in it like to to help companies when
they start thinking about Fred modeling

216
00:17:41,270 --> 00:17:47,250
is first of all a typical session you
would gather some documentation you and

217
00:17:47,250 --> 00:17:53,950
gather the people that have knowledge
about your system you know this is your

218
00:17:53,950 --> 00:17:59,520
developers to QAR architects your
stakeholders your managers other people

219
00:17:59,520 --> 00:18:05,290
that have some investment in the system
has some knowledge in the system and

220
00:18:05,290 --> 00:18:09,250
just start asking questions and
understanding what are we doing what we

221
00:18:09,250 --> 00:18:17,120
built how does this work I find this is
great because not every are not just one

222
00:18:17,120 --> 00:18:21,199
person knows everything and certainly as
a security person within your own

223
00:18:21,200 --> 00:18:26,550
organization perhaps you may not know
all the ins and outs of how that system

224
00:18:26,550 --> 00:18:30,649
was bill so don't make it one person's
job that's you know don't see the threat

225
00:18:30,650 --> 00:18:34,410
Muller person that goes off and tries to
figure this all out you know as much as

226
00:18:34,410 --> 00:18:39,610
you can try to gather a team understand
the business goals and technical goals

227
00:18:39,610 --> 00:18:46,570
which may may may not be the security
goals I remember being in a situation

228
00:18:46,570 --> 00:18:51,460
where I was helping a financial company
and they had two sets of users are

229
00:18:51,460 --> 00:18:56,410
regular users in their managers and we
were talking about putting two FAA to

230
00:18:56,410 --> 00:19:01,400
factor in a nation in place and what
they said to me was that well you know

231
00:19:01,400 --> 00:19:05,870
that's a great idea but our users you
know we don't want them to be bothered

232
00:19:05,870 --> 00:19:10,000
with that but the managers because I
manage multiple accounts that makes more

233
00:19:10,000 --> 00:19:16,550
sense now my security goal was to have
everybody but for them at that time they

234
00:19:16,550 --> 00:19:20,940
said well that's not our goal our goal
is the managers are the ones we feel the

235
00:19:20,940 --> 00:19:26,660
most significant and critical let's get
a place for them and then we'll look at

236
00:19:26,660 --> 00:19:29,630
putting that in place for the users so

237
00:19:29,630 --> 00:19:33,820
a bit different goal but that's the key
understand your business what is it your

238
00:19:33,820 --> 00:19:38,470
business does what do they want to do
understand those goals and how that

239
00:19:38,470 --> 00:19:44,210
works and supporting that so we must
support those goals as well as opposed

240
00:19:44,210 --> 00:19:45,020
to other way around

241
00:19:45,020 --> 00:19:50,310
technical goals understand your
environment you know a job a system has

242
00:19:50,310 --> 00:19:55,879
its own set of security issues and
security environments a.net same way

243
00:19:55,880 --> 00:19:57,840
other systems as well

244
00:19:57,840 --> 00:20:01,209
all have certain environment
environmental things that are in place

245
00:20:01,210 --> 00:20:04,960
for security or not in place for
security to understand those and right

246
00:20:04,960 --> 00:20:09,060
we choose to run it on this system
versus another system in the cloud now

247
00:20:09,060 --> 00:20:13,740
versus not and so on so on they all
impact you know how we build our threat

248
00:20:13,740 --> 00:20:17,870
model and also as we talk about that
later about the risk that might be

249
00:20:17,870 --> 00:20:22,860
involved with those those decisions
agree on meeting dates and times and I

250
00:20:22,860 --> 00:20:26,100
usually say about one to two hours at a
time because if you try to do this for

251
00:20:26,100 --> 00:20:32,800
an entire day one you know your teams
gonna get just overwhelmed by I'd say

252
00:20:32,800 --> 00:20:40,620
have a focused I'm one to two hours and
then most important be honest leave ego

253
00:20:40,620 --> 00:20:45,070
at the door and not blaming you know
when you're looking at these things

254
00:20:45,070 --> 00:20:50,460
especially if it's after the fact it's
so easy to say oh you know why didn't we

255
00:20:50,460 --> 00:20:55,900
do that why did we miss that don't do
that because the point of all this is

256
00:20:55,900 --> 00:20:59,230
where almost same team we're all trying
to accomplish the same thing is to

257
00:20:59,230 --> 00:21:04,660
secure our system so please leave those
things to the side and get focused on

258
00:21:04,660 --> 00:21:09,850
you know where are we today let's figure
it out and how can we go forward and and

259
00:21:09,850 --> 00:21:14,909
make the secure so simple tools I like a
whiteboard

260
00:21:16,570 --> 00:21:22,260
document that you can use busy you know
or Word Excel and so on

261
00:21:22,260 --> 00:21:26,660
great great tools there are also a few
other tools out there you can use as

262
00:21:26,660 --> 00:21:30,570
well there's one for Microsoft which I
have a reference much later in the deck

263
00:21:30,570 --> 00:21:34,710
but I like to swing dance crews just
came out with a simple threat model

264
00:21:34,710 --> 00:21:39,110
one-page just to get you started an
unfortunate can't see that well but it

265
00:21:39,110 --> 00:21:41,959
just mentions you know what my diagram

266
00:21:41,960 --> 00:21:47,309
and threats and so on and so on I also
like this one but I've used with a few

267
00:21:47,309 --> 00:21:51,418
customers is just have an Excel
spreadsheet and just start documenting

268
00:21:51,419 --> 00:21:55,960
my risk level which will talk about
later threat description countermeasures

269
00:21:55,960 --> 00:22:01,419
and then the follow-up very very simple
you know getting together drawing on the

270
00:22:01,419 --> 00:22:08,450
whiteboard what's our system look like
where the issues and documenting it so

271
00:22:08,450 --> 00:22:12,309
to start off with with your team one of
the first things you want to do i think

272
00:22:12,309 --> 00:22:17,658
is to review your security principles
and this is important to make sure

273
00:22:17,659 --> 00:22:21,029
everybody's on the same page and
understands you know we're talking about

274
00:22:21,029 --> 00:22:25,710
a secure system here well how you gonna
be secure unless you know what it means

275
00:22:25,710 --> 00:22:30,000
to be secure what are the the baselines
where the the actual things that need to

276
00:22:30,000 --> 00:22:31,500
be in place

277
00:22:31,500 --> 00:22:38,809
secure weakest link to find in depth to
their few more do not share mechanisms

278
00:22:38,809 --> 00:22:46,110
assume secrets not safe from 0 privacy
news resources and these flights are

279
00:22:46,110 --> 00:22:49,620
available if you want to look at those
and I have a reference there another

280
00:22:49,620 --> 00:22:53,580
great resource i've seen over the last
couple of years a system that came out

281
00:22:53,580 --> 00:22:59,908
from the I Tripoli center for secure
design avoiding the top 10 software

282
00:22:59,909 --> 00:23:04,659
security design flaws and their approach
they're a bunch of companies got

283
00:23:04,659 --> 00:23:09,240
together and and put this together and
their approach was not just focus on on

284
00:23:09,240 --> 00:23:09,669
the bill

285
00:23:09,669 --> 00:23:13,799
vulnerabilities but focus on the flaw
that causes the vulnerabilities so this

286
00:23:13,799 --> 00:23:18,830
is another great short small book that
you can hand out your team to again

287
00:23:18,830 --> 00:23:21,908
understand some of the basic security
principles before you get started

288
00:23:21,909 --> 00:23:25,909
ok so here's the process that I follow
in or less

289
00:23:26,480 --> 00:23:31,919
others follow the same it breaks down
like I said very similar to what others

290
00:23:31,919 --> 00:23:35,899
are doing as well but essentially
drawing your picture drawing an

291
00:23:35,899 --> 00:23:40,779
understanding of what you have in your
system identifying those threats the

292
00:23:40,779 --> 00:23:43,020
term communications and the risks

293
00:23:43,020 --> 00:23:47,050
and then follow through and follow
through is an interesting point because

294
00:23:47,050 --> 00:23:52,639
I don't see everyone always doing that
and so I I like including that as well

295
00:23:52,640 --> 00:23:59,280
if if you can follow through after
you've done the work so dry picture now

296
00:23:59,280 --> 00:24:04,110
this one is just a typical web
application of browser web server it

297
00:24:04,110 --> 00:24:07,860
doesn't tell you a lot but it gets you
started it helps you start understanding

298
00:24:07,860 --> 00:24:12,689
what's in our system and obviously this
is a pretty simple one and you may have

299
00:24:12,690 --> 00:24:18,570
many many more things going on but the
first key thing is start drawing on the

300
00:24:18,570 --> 00:24:23,470
whiteboard what is that our system is
doing now another thing that you can use

301
00:24:23,470 --> 00:24:28,950
our data flow diagrams and these are
some nomenclature for it and some ways

302
00:24:28,950 --> 00:24:34,010
to to draw these things the entities a
process these stores and trust boundary

303
00:24:34,010 --> 00:24:39,230
but whatever you choose come up with a
way in a simple way that you can

304
00:24:39,230 --> 00:24:40,690
communicate with others

305
00:24:40,690 --> 00:24:44,690
here's what's going on here is how
things communicate with each other and

306
00:24:44,690 --> 00:24:49,330
the reason you focus on it typically
focus on data flows is it turns out that

307
00:24:49,330 --> 00:24:55,409
when data flows from one entity to
another or one process to another that's

308
00:24:55,410 --> 00:24:59,790
actually turns out to be one of our most
vulnerable places think about it when we

309
00:24:59,790 --> 00:25:06,020
are on a browser connecting to a web
server what are we sending we're sending

310
00:25:06,020 --> 00:25:12,320
credit card information we're retrieving
you know account information for making

311
00:25:12,320 --> 00:25:17,290
changes the browser by itself does
nothing the web server does nothing but

312
00:25:17,290 --> 00:25:20,010
its communication between the two

313
00:25:20,010 --> 00:25:23,990
the data that's going back and forth
that's pretty sensitive and also where

314
00:25:23,990 --> 00:25:28,970
that they get stored pretty sensitive so
those are some key areas and that's

315
00:25:28,970 --> 00:25:34,320
those are things that we need to be
aware of and be sure to secure so that's

316
00:25:34,320 --> 00:25:37,970
what we call data flow diagrams is to
try to understand the data flows between

317
00:25:37,970 --> 00:25:41,170
those systems so

318
00:25:41,170 --> 00:25:45,070
understand the system we want understand
the logical and component architectural

319
00:25:45,070 --> 00:25:50,020
architecture of the system and again as
I mentioned the communication flow

320
00:25:50,020 --> 00:25:57,010
between those systems so here's an
example of users I have a man in server

321
00:25:57,010 --> 00:26:03,400
now this is a very high level but you
know request response settings and

322
00:26:03,400 --> 00:26:08,840
logging data and then a trust boundary
for simple and again this is just a

323
00:26:08,840 --> 00:26:12,129
high-level view but what you'll probably
do is go a little further into the

324
00:26:12,130 --> 00:26:18,290
system and start breaking it out and now
I've got some user admin of course the

325
00:26:18,290 --> 00:26:23,350
web app audit service other services
that are their data files credentials

326
00:26:23,350 --> 00:26:28,929
and so on and then you start labeling
them well what's going on between us to

327
00:26:28,930 --> 00:26:36,170
how are they communicating and then also
you defined entrust boundaries and trust

328
00:26:36,170 --> 00:26:39,890
boundaries just simply mean that I'm
going from one state to another

329
00:26:40,410 --> 00:26:43,720
of trust so a user may be honest
indicated and now there are syndicated

330
00:26:43,720 --> 00:26:50,600
at once that has happened you know what
happens with inside that perimeter along

331
00:26:50,600 --> 00:26:54,760
with that you would identify you know
what am i into these you know what are

332
00:26:54,760 --> 00:26:59,710
my services that are running what
happens with this the data as ice as I

333
00:26:59,710 --> 00:27:04,320
store it you know what are the flows so
these are the same things that you want

334
00:27:04,320 --> 00:27:10,870
to think of as you're looking at your
system and understanding it and believe

335
00:27:10,870 --> 00:27:15,699
me you're not gonna catch everything you
know maybe the first pass and one thing

336
00:27:15,700 --> 00:27:21,070
I'd like to say to you know teams that
are trying to figure this out for a big

337
00:27:21,070 --> 00:27:25,129
big system is don't try to take it all
in one shot in fact I would say

338
00:27:25,130 --> 00:27:31,320
typically take one or two services and
figure out the threat model for that one

339
00:27:31,320 --> 00:27:35,590
service or to services and then take the
next one and see how that's connected

340
00:27:35,590 --> 00:27:41,340
and what you do is your building on and
kind of like an onion unfolding it and

341
00:27:41,340 --> 00:27:46,629
seeing how the whole system works rather
than try to take it all at one shot and

342
00:27:46,630 --> 00:27:49,200
and you'll see for example the
authentication service works with

343
00:27:49,200 --> 00:27:50,240
something else

344
00:27:50,240 --> 00:27:54,059
something else or something else and
eventually you will get most of the

345
00:27:54,059 --> 00:28:00,670
system and that's a great way to 22
digested so now your truck model

346
00:28:00,670 --> 00:28:05,580
consists of a diagram understanding your
system and the data flows

347
00:28:06,540 --> 00:28:11,399
next is the threats now it is the most
important part of this it is called

348
00:28:11,400 --> 00:28:16,780
threat modeling after all but it is also
the most difficult because how do you

349
00:28:16,780 --> 00:28:19,639
identify the threats in our system

350
00:28:19,640 --> 00:28:24,660
well there are some tools and I'll talk
about those attack trees brush fire has

351
00:28:24,660 --> 00:28:28,100
a pretty nice light that he wrote many
years ago

352
00:28:28,100 --> 00:28:34,949
attack trees essentially are just a way
of coming slow here is my goal how do I

353
00:28:34,950 --> 00:28:36,030
get there

354
00:28:36,030 --> 00:28:39,990
the various pass to get there and
they're all kinds of attack trees that

355
00:28:39,990 --> 00:28:44,850
have been created for websites and other
kinds of attacks that tucker might use

356
00:28:44,850 --> 00:28:48,199
to traverse to get to their goal

357
00:28:48,200 --> 00:28:53,990
hard to write which is why a lot of
already been made but that's one way to

358
00:28:53,990 --> 00:28:58,540
think about these things and understand
some of the potential threats there's

359
00:28:58,540 --> 00:29:03,110
some threat libraries like for example
Kappa can top 10 so on you can take a

360
00:29:03,110 --> 00:29:06,350
look at those are ways to kinda hope you
think about these things

361
00:29:07,820 --> 00:29:13,230
checklist checklists are not so bad at
least to get started I'm how many of you

362
00:29:13,230 --> 00:29:17,190
are glad that the the pilot has a
checklist before you take off a plane

363
00:29:17,190 --> 00:29:23,090
right they're not bad they they really
help you start thinking about things you

364
00:29:23,090 --> 00:29:27,990
may not have thought about regulating
right so don't throw out checklists and

365
00:29:27,990 --> 00:29:32,780
there's a few there I really like the
SPS from Oscar great tool of list of

366
00:29:32,780 --> 00:29:36,960
questions about what is it in our system
that we need to think about from a

367
00:29:36,960 --> 00:29:42,070
security standpoint we have in place and
then recently they just updated the pro

368
00:29:42,070 --> 00:29:47,300
ActiveX controls 10 things that answer
the top 10 hear the things that

369
00:29:47,300 --> 00:29:50,750
developers need to think about when
you're building systems so against

370
00:29:50,750 --> 00:29:56,330
checklist use cases misuse cases if
you've been in software or dining

371
00:29:56,330 --> 00:30:01,939
software development a lot of times
people will focus on use cases you know

372
00:30:01,940 --> 00:30:07,980
how do people use our system we don't
always think about misuse cases because

373
00:30:07,980 --> 00:30:11,700
we think you know I talk to teams they
say well you know what happens if this

374
00:30:11,700 --> 00:30:15,980
you know somebody does it well nobody
would ever do that you've heard that

375
00:30:15,980 --> 00:30:21,389
before why would anybody ever click on
that button labeled anybody ever do that

376
00:30:21,389 --> 00:30:25,418
well that's a misuse case and it's
important to look at those as well

377
00:30:25,419 --> 00:30:31,230
there's a couple games self their
elevation of privilege cornucopia we'll

378
00:30:31,230 --> 00:30:32,320
talk about that in a moment

379
00:30:32,320 --> 00:30:38,250
stride is another fantastic way to look
at that moment pasta actually came out

380
00:30:38,250 --> 00:30:44,080
the last few years it's an actual
seven-step process that includes not

381
00:30:44,080 --> 00:30:49,600
just stride and risk analysis but also
attacks they include within their threat

382
00:30:49,600 --> 00:30:54,719
model simulated attacks so it's not just
a theoretical thing about what might

383
00:30:54,720 --> 00:30:59,769
happen they also include an actual
attack that they've demonstrated that

384
00:30:59,769 --> 00:31:02,129
could happen if you're interested

385
00:31:02,129 --> 00:31:06,490
take a look at it pasta process for
attack simulation and threat analysis

386
00:31:06,490 --> 00:31:12,720
there's a nice book also that came out
last year on this as well so stride

387
00:31:12,720 --> 00:31:18,860
originally came from some guys that
Microsoft back in a bit of a scene i've

388
00:31:18,860 --> 00:31:26,158
seen the original paper round 1999 but
it really came into more I guess the

389
00:31:26,159 --> 00:31:27,470
public if you will

390
00:31:27,470 --> 00:31:34,419
around 2003 2004 when there was a book
that came out on threat modeling where

391
00:31:34,419 --> 00:31:39,750
they talked about stride stride is is
really a mnemonic it's not necessarily

392
00:31:39,750 --> 00:31:44,610
categories it Santa Monica way of
thinking about these things they're

393
00:31:44,610 --> 00:31:49,019
spoofing there's tampering repudiation
basically did I do what I you know you

394
00:31:49,019 --> 00:31:54,730
said I did information disclosure on all
service elevation of privilege the way

395
00:31:54,730 --> 00:32:00,070
to counter that is of course
authentication integrity non-repudiation

396
00:32:00,070 --> 00:32:04,700
which is usually done by logging
confidentiality availability and

397
00:32:04,700 --> 00:32:10,190
authorization now if you notice the
confidentiality integrity and

398
00:32:10,190 --> 00:32:12,240
availability that's the CIA

399
00:32:12,240 --> 00:32:15,929
of its security right to be heard that
before and then of course they get the

400
00:32:15,929 --> 00:32:20,110
two ASAP indication authorization that's
really all that strike is doing is just

401
00:32:20,110 --> 00:32:24,760
trying to help people who are new to
security or not that familiar with

402
00:32:24,760 --> 00:32:25,800
security

403
00:32:25,800 --> 00:32:31,210
try to understand some security concepts
here and ideally these apply to your

404
00:32:31,210 --> 00:32:36,570
data flow again a great tool to start
thinking about what the potential kinds

405
00:32:36,570 --> 00:32:43,500
of threats that might be in our system
there is also this OS cornucopia which

406
00:32:43,500 --> 00:32:49,340
is a game that focuses on a few areas
here and simply it's a game that you can

407
00:32:49,340 --> 00:32:54,959
play with around and everybody gets
about five or six cards and you have

408
00:32:54,960 --> 00:33:00,010
your diagram out there and someone picks
a card and say you know this is a you

409
00:33:00,010 --> 00:33:05,059
know to of authorization and they read
it and so does that apply to this

410
00:33:05,059 --> 00:33:10,920
situation yes put it down somebody says
hey I meet your two of authorization

411
00:33:10,920 --> 00:33:15,520
with a five of authorization oh you know
put it down whoever puts down the

412
00:33:15,520 --> 00:33:21,450
highest an astrologer wins now you can
she don't worry it's a game that's a fun

413
00:33:21,450 --> 00:33:25,040
game but it's a way of learning about
this as well because I at the bottom of

414
00:33:25,040 --> 00:33:31,190
each card it will tell you the perhaps
that particular threat of that

415
00:33:31,190 --> 00:33:35,540
particular issue where would you find it
no top 10 where would you find Capek

416
00:33:35,540 --> 00:33:39,129
where would you find a SBS so it's a
great way again

417
00:33:39,130 --> 00:33:42,120
of getting familiar with security topics
especially for those who are not

418
00:33:42,120 --> 00:33:48,129
familiar with security so it's cool game
other ways that you can think about

419
00:33:48,130 --> 00:33:53,470
threats in a functional way you know my
inputting data validation we aren't up

420
00:33:53,470 --> 00:33:57,330
to a configuration management I have
example here tomorrow that that's a

421
00:33:57,330 --> 00:34:03,580
pretty hot topic and doesn't get enough
attention I think some other things

422
00:34:03,580 --> 00:34:07,850
system management cryptography session
management auditing and logging

423
00:34:09,190 --> 00:34:14,780
what I like to do is ask questions when
I was a team I'm just asking questions

424
00:34:14,780 --> 00:34:18,790
they've got her diagram up there and
we've already talked about the security

425
00:34:18,790 --> 00:34:24,250
principles and I encourage people to ask
questions would be interested in this

426
00:34:24,250 --> 00:34:30,310
kind of attack her what kind of user
would be interested in and looking at

427
00:34:30,310 --> 00:34:35,549
what we have here and one of the goals
the assets you know what we try to

428
00:34:35,550 --> 00:34:42,250
protect what methods you know that they
might use and are there any attack

429
00:34:42,250 --> 00:34:46,480
services that we may have missed some
other questions that occasion

430
00:34:46,480 --> 00:34:54,460
authorization and so on and so on one of
the best questions there anything that's

431
00:34:54,460 --> 00:34:58,579
keeping you up at night you'd be
surprised the answers you get on this

432
00:34:58,579 --> 00:34:59,400
one

433
00:34:59,400 --> 00:35:03,550
oh yeah there was a button that we put
out there it's hidden when used it for

434
00:35:03,550 --> 00:35:09,849
development we forgot to remove it it
still there or there's that I D 53 don't

435
00:35:09,849 --> 00:35:15,540
ever ever ever put 53 as an idea because
you'll have keys of the kingdom we

436
00:35:15,540 --> 00:35:20,550
forgot about that when we kept that out
there all kinds of answers but it's an

437
00:35:20,550 --> 00:35:24,660
interesting telling question and answer
with it

438
00:35:25,210 --> 00:35:31,230
about what is going on our system or
what did we forget so let's talk about

439
00:35:31,230 --> 00:35:34,950
configuration management a particular
scenario this is my diagram I had

440
00:35:34,950 --> 00:35:42,879
earlier if we look at you know example
configuration management let's say here

441
00:35:42,880 --> 00:35:46,540
data files for the web configuration
files

442
00:35:47,240 --> 00:35:51,560
so our system is that we've diagrammed
is a web application that uses

443
00:35:51,560 --> 00:35:56,170
configuration files from some basic
security principles that we already

444
00:35:56,170 --> 00:36:02,240
should know about and be thinking about
is be reluctant to trust and assuming

445
00:36:02,240 --> 00:36:04,149
the secrets are not safe

446
00:36:04,150 --> 00:36:10,940
alright no questions yet use those
configuration files and I would

447
00:36:10,940 --> 00:36:17,510
curiosity and actually don't hold up
your hands but one of things I found is

448
00:36:17,510 --> 00:36:23,380
in a lot of systems everybody trusts the
configuration file right we do a really

449
00:36:23,380 --> 00:36:28,300
good job at least trying to validating
all the input that comes in through the

450
00:36:28,300 --> 00:36:32,410
site but we don't always check the
configuration file guess what it's still

451
00:36:32,410 --> 00:36:38,859
input is still in Puttur system what
would happen if somebody changed website

452
00:36:38,860 --> 00:36:40,660
the point somewhere else

453
00:36:40,660 --> 00:36:43,759
what would happen if they changed the
password what would happen if they

454
00:36:43,760 --> 00:36:47,369
change all kinds of other settings
within your configuration management

455
00:36:47,369 --> 00:36:52,850
what would your system do how would you
react how was it checking those things

456
00:36:52,850 --> 00:36:58,180
how was it testing those things you know
not everybody thinks about those things

457
00:36:59,990 --> 00:37:06,240
what validation supply is an implied
trust so possible controls and

458
00:37:06,240 --> 00:37:11,459
mitigation that you may come out of this
that come out of this set permissions on

459
00:37:11,460 --> 00:37:18,210
the configuration files again it matters
now and Balliol they didn't put from the

460
00:37:18,210 --> 00:37:21,210
files useless testing to ensure input
validation

461
00:37:21,820 --> 00:37:27,630
the other thing about this is will talk
about the moment is this also applies to

462
00:37:27,630 --> 00:37:32,810
where you know where does our web server
set to we only boxer to somebody else on

463
00:37:32,810 --> 00:37:39,660
the box so you identify threats to the
answers to questions let's talk about

464
00:37:39,660 --> 00:37:42,910
mitigation options and we look at our
time a couple minutes here

465
00:37:44,119 --> 00:37:47,440
leave as is just leave it

466
00:37:47,440 --> 00:37:52,520
we know it's a problem leaving remove it
from the product you know there's we

467
00:37:52,520 --> 00:37:55,920
know there's a problem there were going
to remove it and it's just not make it

468
00:37:55,920 --> 00:38:00,840
available this feature we remedy it with
a technology countermeasures which is

469
00:38:00,840 --> 00:38:06,120
the ideal thing if we found a probably
found a threat we need to put in place

470
00:38:06,120 --> 00:38:10,900
the countermeasures the other one is
just warn the user which is what I call

471
00:38:10,900 --> 00:38:15,680
or better known as passed the buck you
know just let somebody else deal with it

472
00:38:15,680 --> 00:38:19,660
you know will give us a note to say by
the way if you use our system your

473
00:38:19,660 --> 00:38:23,770
information may be compromised in
certain situations because we're not

474
00:38:23,770 --> 00:38:29,850
protecting whatever that's what you know
and that might be very deep deep deep

475
00:38:29,850 --> 00:38:35,640
into that you know the the agreement
that you clicked on remember when you

476
00:38:35,640 --> 00:38:39,680
install the software that everybody
reads right my biggest lies and security

477
00:38:39,680 --> 00:38:45,870
everybody reads agreements just warn the
user so as a few ways we can decide how

478
00:38:45,870 --> 00:38:51,750
to mitigate but we need to understand
the risk so talk about risk management

479
00:38:51,750 --> 00:38:58,430
there's a bug bar there's a fair
approach by Jack Jones in front of all

480
00:38:58,430 --> 00:39:03,210
these guys factor analysis and
information risk actually great book on

481
00:39:03,210 --> 00:39:08,660
that it's a more comprehensive risk
analysis and risk management and even

482
00:39:08,660 --> 00:39:12,060
some threat modeling and I know some
companies that will use this alone where

483
00:39:12,060 --> 00:39:16,850
a threat is only identified by the thing
that you lose if you don't lose it it's

484
00:39:16,850 --> 00:39:20,920
not a threat so it's an interesting way
of also managing this as well

485
00:39:21,630 --> 00:39:26,770
10 ways I like is is just you know use a
simple risk rating of higher elo which

486
00:39:26,770 --> 00:39:33,200
is based on the easel exploitation and
the business impact the ease of

487
00:39:33,200 --> 00:39:38,430
exploitation is anonymous users can
exploit the issue its high if you need

488
00:39:38,430 --> 00:39:43,850
to know things about the system you know
working tools and so on then it's

489
00:39:43,850 --> 00:39:50,509
probably low it's hard to do it's hard
but slow business impact if all users

490
00:39:50,510 --> 00:39:56,750
are impacted that's pretty high if
significantly low number of users are

491
00:39:56,750 --> 00:39:57,700
impacted

492
00:39:57,700 --> 00:40:03,629
or the possibility of you no harm here
is very low then it's a low and you put

493
00:40:03,630 --> 00:40:09,040
those together and you determine you
know what is our risk factor here at

494
00:40:09,040 --> 00:40:11,130
risk level this is an example

495
00:40:11,130 --> 00:40:18,520
medium threat risk arrest right whether
it's CSRF here's a description of it we

496
00:40:18,520 --> 00:40:22,320
need transaction codes thresholds have
been visibility and so on identifying

497
00:40:22,320 --> 00:40:27,480
the components are affected so that's
our threat model following up on our

498
00:40:27,480 --> 00:40:33,590
scenario with configuration management
the data files with high risk rating

499
00:40:33,590 --> 00:40:37,290
well again it depends on where we are
and that actually affects a threat model

500
00:40:37,290 --> 00:40:42,680
so if we on the box it might be
identified medium low we already we're

501
00:40:42,680 --> 00:40:46,700
monitoring it we're not worried as much
it was hosted in the cloud or somewhere

502
00:40:46,700 --> 00:40:52,210
else it may be a higher issue it may be
an issue that we we need to think more

503
00:40:52,210 --> 00:40:56,040
seriously about because we don't we
don't know who's changing these things

504
00:40:56,040 --> 00:40:59,000
we don't know who's looking at these
configurations and if they do change it

505
00:40:59,000 --> 00:41:03,320
and change the look out you know look
and feel of our site how would we know

506
00:41:03,320 --> 00:41:09,900
so that may be higher in the risk so
then this becomes a threat model that

507
00:41:09,900 --> 00:41:15,150
makes sense that's what we're looking at
as far as the principles the questions

508
00:41:15,150 --> 00:41:19,870
the mitigation and the risk and that can
then determine our priority what do we

509
00:41:19,870 --> 00:41:26,520
do with this next week so now we've
identified indications and and the risks

510
00:41:26,520 --> 00:41:27,340
involved

511
00:41:27,340 --> 00:41:35,010
finally we do follow through we document
what you found you by the bugs are new

512
00:41:35,010 --> 00:41:39,080
requirements if you find a problem is
you find a threat that's a bug in

513
00:41:39,080 --> 00:41:43,440
existing system if you've never
implemented that feature that's a

514
00:41:43,440 --> 00:41:49,720
requirement that's what helps you do and
then ultimately verify those are fixed

515
00:41:49,720 --> 00:41:55,140
or verify that requirement that feature
rather is now in place and mitigation is

516
00:41:55,140 --> 00:42:01,460
in place now you've gone through this
whole exercise when you're done

517
00:42:02,230 --> 00:42:07,670
that's always the question wow this is a
lot when you done what's the answer

518
00:42:07,670 --> 00:42:18,460
you're not you're not but at some point
you do have to say we've got as much as

519
00:42:18,460 --> 00:42:23,490
we know now and then make it something
that you continue to revisit time and

520
00:42:23,490 --> 00:42:27,339
time again for example in the Sprint
Planning and so far so if we miss

521
00:42:27,340 --> 00:42:27,930
anything

522
00:42:27,930 --> 00:42:34,799
review again and you update if there's
anything new to you again and update so

523
00:42:34,800 --> 00:42:39,600
yes we we may never be done because
there are always new features are solely

524
00:42:39,600 --> 00:42:43,680
news things out there there's always new
vulnerabilities that people are finding

525
00:42:43,680 --> 00:42:48,819
but the key is when you start this
process you'll find out as you go along

526
00:42:48,820 --> 00:42:53,390
it becomes easier easier and easier
threat modeling becomes not just a thing

527
00:42:53,390 --> 00:42:56,490
that we talked about it but the thing
that we do it's a thing that we think

528
00:42:56,490 --> 00:43:00,899
about all the time we're not just
looking at the system as well that's a

529
00:43:00,900 --> 00:43:04,650
big promise something I I don't know
what it does but instead looking at as

530
00:43:04,650 --> 00:43:09,369
hey there's a threat model issue there
there's something there and when you

531
00:43:09,369 --> 00:43:12,530
have a team that you're working with and
all of a sudden when they're looking at

532
00:43:12,530 --> 00:43:16,150
something and not use a security person
say to them what they say to you out

533
00:43:16,150 --> 00:43:20,920
there what's her threat model here and
you know you've done a fantastic job and

534
00:43:20,920 --> 00:43:23,859
they're getting it and it's a great
feeling and you know that's something I

535
00:43:23,859 --> 00:43:31,049
hope everybody so here are four things
ultimately we have a little threat model

536
00:43:31,050 --> 00:43:35,190
you know this is not something that just
you know do and throw away and go do

537
00:43:35,190 --> 00:43:39,250
something else but it's something that I
hope that you know you make it a part of

538
00:43:39,250 --> 00:43:44,090
what you're doing in your own work and
make this a tool that you know something

539
00:43:44,090 --> 00:43:49,150
that you use regularly and then
ultimately again following through and

540
00:43:49,150 --> 00:43:53,330
turning into something that that's a
live living it's it's you know

541
00:43:53,330 --> 00:43:58,340
continuing to evolve because you know as
others have said that I've talked to a

542
00:43:58,340 --> 00:44:02,190
strip mall as you know models
essentially are fractal we may not know

543
00:44:02,190 --> 00:44:07,670
everything at first but as we delve into
this thing will know more and more and

544
00:44:07,670 --> 00:44:12,690
ultimately it just helps us to be better
at security and an understanding our

545
00:44:12,690 --> 00:44:13,300
system

546
00:44:13,300 --> 00:44:20,840
so you're challenged you start modeling
for secure design before new features

547
00:44:20,840 --> 00:44:28,050
also let a driver testing to help it can
help you to know where you need to focus

548
00:44:28,050 --> 00:44:32,270
at test those tests and then it helps
you really understand the bigger picture

549
00:44:32,270 --> 00:44:37,320
because as you look at everything unfold
the onion you then have a much much

550
00:44:37,320 --> 00:44:42,480
better understanding of your system and
and what your building so some books

551
00:44:42,480 --> 00:44:50,110
more than welcome to take a look at
those I I recommend all of these are

552
00:44:50,110 --> 00:44:53,440
just fantastic they've come out the last
couple of years

553
00:44:53,440 --> 00:45:00,060
couple tools there's the one from
Microsoft there's another $1 they're not

554
00:45:00,060 --> 00:45:08,460
automated tools now threaten other real
you can put in a system that will get

555
00:45:08,460 --> 00:45:12,890
you started but ultimately what I said
at the beginning this is a shrinking

556
00:45:12,890 --> 00:45:17,910
tool these things won't just you know
magically produce something for you

557
00:45:17,910 --> 00:45:21,359
that's not what this is about every
company is different every scenario is

558
00:45:21,360 --> 00:45:24,940
different every application is different
so you really have to spend the time

559
00:45:24,940 --> 00:45:30,980
with is what it is yet to spend time and
think about your system but believe me

560
00:45:30,980 --> 00:45:35,470
by the end of it you know using whatever
tool you're using you'll you'll

561
00:45:35,470 --> 00:45:38,939
definitely know it better and you'll
have a lil bit more confidence about the

562
00:45:38,940 --> 00:45:46,460
security posture of your system so more
resources some links and so on so that's

563
00:45:46,460 --> 00:45:53,070
me and how are we on time we're actually
right there so if you have any questions

564
00:45:53,070 --> 00:45:56,680
you can email me Robert Robert Robert
dot com or go to my website or Twitter

565
00:45:56,680 --> 00:46:02,350
and I'll be around if you have any
questions certainly and thank you for

566
00:46:02,350 --> 00:46:02,420
attending

