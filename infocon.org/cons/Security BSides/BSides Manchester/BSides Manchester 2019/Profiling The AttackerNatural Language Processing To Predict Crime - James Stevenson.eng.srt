1
00:00:05,240 --> 00:00:14,929
so the question is what does Minority

2
00:00:09,019 --> 00:00:21,050
Report Black Mirror and 1984 all have

3
00:00:14,929 --> 00:00:23,150
income really cool it's not fat at the

4
00:00:21,050 --> 00:00:25,130
raw forms of media nor is it the fact

5
00:00:23,150 --> 00:00:27,979
that there are parts of dystopian

6
00:00:25,130 --> 00:00:30,380
features instead it's the fact that they

7
00:00:27,980 --> 00:00:33,440
each talked about predicting crime in

8
00:00:30,380 --> 00:00:34,129
one form or another whether it's the

9
00:00:33,440 --> 00:00:36,769
precogs

10
00:00:34,130 --> 00:00:40,520
the minority reports the Ricola in black

11
00:00:36,770 --> 00:00:42,950
mirror or the fort's police in 1984 each

12
00:00:40,520 --> 00:00:45,170
of these forms of media look at how we

13
00:00:42,950 --> 00:00:47,420
could predict crime but more

14
00:00:45,170 --> 00:00:50,000
specifically to have repercussions of

15
00:00:47,420 --> 00:00:52,370
doing so and that's what we're gonna be

16
00:00:50,000 --> 00:00:53,960
talking about today we're gonna be

17
00:00:52,370 --> 00:00:54,800
talking about how we can use natural

18
00:00:53,960 --> 00:00:57,140
language processing

19
00:00:54,800 --> 00:01:00,709
if one with machine learning to help us

20
00:00:57,140 --> 00:01:02,930
predict crime so for those of you that

21
00:01:00,710 --> 00:01:06,680
know me will know another mathematician

22
00:01:02,930 --> 00:01:08,480
and I'm also not a police officer so why

23
00:01:06,680 --> 00:01:10,610
are we talking about natural language

24
00:01:08,480 --> 00:01:12,890
processing which is quite lefty and

25
00:01:10,610 --> 00:01:15,260
predictive policing which has namely

26
00:01:12,890 --> 00:01:18,680
suggest is all about the law and crime

27
00:01:15,260 --> 00:01:20,800
and well it comes down to this quote the

28
00:01:18,680 --> 00:01:23,810
idea that intrusion analysis security

29
00:01:20,800 --> 00:01:27,259
analysis it's about far more than the

30
00:01:23,810 --> 00:01:28,340
tools we use it's about the victims and

31
00:01:27,260 --> 00:01:30,560
it's about looking at new ways that we

32
00:01:28,340 --> 00:01:33,380
can protect ourselves against attacks

33
00:01:30,560 --> 00:01:36,290
but also predict those attacks in the

34
00:01:33,380 --> 00:01:38,509
first place so are we actually gonna be

35
00:01:36,290 --> 00:01:40,340
talking about today well i'ma break it

36
00:01:38,510 --> 00:01:42,110
down into three areas I want to talk

37
00:01:40,340 --> 00:01:44,150
about what predictive policing actually

38
00:01:42,110 --> 00:01:46,700
is I want to talk about what natural

39
00:01:44,150 --> 00:01:48,380
language processing is and then finally

40
00:01:46,700 --> 00:01:51,260
goes about how we can engage these two

41
00:01:48,380 --> 00:01:55,699
ideas together how we can use natural

42
00:01:51,260 --> 00:01:57,590
language processing to predict crime Who

43
00:01:55,700 --> 00:01:59,810
am I well my name is James Stevenson and

44
00:01:57,590 --> 00:02:01,760
this time two years ago now as a student

45
00:01:59,810 --> 00:02:03,890
at University of South Wales studying

46
00:02:01,760 --> 00:02:04,280
commuter security before that I was an

47
00:02:03,890 --> 00:02:06,200
intern

48
00:02:04,280 --> 00:02:07,850
I thought logic a cloud security company

49
00:02:06,200 --> 00:02:10,580
and these days I'm a software engineer

50
00:02:07,850 --> 00:02:12,470
in security researcher

51
00:02:10,580 --> 00:02:14,480
but you're being strained to it what is

52
00:02:12,470 --> 00:02:17,330
predictive policing I keep talking about

53
00:02:14,480 --> 00:02:18,619
it but what actually is it because if

54
00:02:17,330 --> 00:02:20,870
we're going to use natural language

55
00:02:18,620 --> 00:02:22,430
processing to a pretty crime then we

56
00:02:20,870 --> 00:02:25,310
kind of need to know what predictive

57
00:02:22,430 --> 00:02:26,600
policing is in the first place and

58
00:02:25,310 --> 00:02:29,270
predictive policing comes down to two

59
00:02:26,600 --> 00:02:31,579
main areas location-based predictive

60
00:02:29,270 --> 00:02:33,740
policing and individual based predictive

61
00:02:31,580 --> 00:02:35,660
policing nothing we suggest

62
00:02:33,740 --> 00:02:37,460
location-based predictive policing is

63
00:02:35,660 --> 00:02:39,950
all about looking at an area it's about

64
00:02:37,460 --> 00:02:43,340
saying in this area in the future is a

65
00:02:39,950 --> 00:02:45,070
crime likely to occur now this is a map

66
00:02:43,340 --> 00:02:47,780
of London between a specific time period

67
00:02:45,070 --> 00:02:50,630
where the colors show where and when

68
00:02:47,780 --> 00:02:51,890
coins occurred and if they fell like

69
00:02:50,630 --> 00:02:53,660
this that's really useful for

70
00:02:51,890 --> 00:02:55,790
location-based predictive policing

71
00:02:53,660 --> 00:02:58,730
because we can use this data what we

72
00:02:55,790 --> 00:03:00,920
need okay if a crime is occurred under

73
00:02:58,730 --> 00:03:02,989
these specific circumstances in the past

74
00:03:00,920 --> 00:03:05,000
that it means that Chrome's likely to

75
00:03:02,990 --> 00:03:07,670
occur under these same circumstances

76
00:03:05,000 --> 00:03:09,470
again in the future now today we're

77
00:03:07,670 --> 00:03:11,179
going to be focusing on individual based

78
00:03:09,470 --> 00:03:13,550
predictive policing that you're looking

79
00:03:11,180 --> 00:03:15,920
at individual and saying how likely is

80
00:03:13,550 --> 00:03:18,680
this specific individual to commit a

81
00:03:15,920 --> 00:03:20,238
crime and when it comes to individual

82
00:03:18,680 --> 00:03:22,070
based predictive policing there's a

83
00:03:20,239 --> 00:03:24,470
whole array of approaches Furies and

84
00:03:22,070 --> 00:03:26,810
methodologies that we can use to help us

85
00:03:24,470 --> 00:03:29,120
for the crime and today we're gonna be

86
00:03:26,810 --> 00:03:30,890
focusing on three of these the first

87
00:03:29,120 --> 00:03:33,440
fury that we're looking at is called

88
00:03:30,890 --> 00:03:36,488
strain theory now strain theory is the

89
00:03:33,440 --> 00:03:39,250
idea that society puts pressure on

90
00:03:36,489 --> 00:03:42,290
individuals to achieve specific goals

91
00:03:39,250 --> 00:03:43,850
like the American dream but when

92
00:03:42,290 --> 00:03:46,370
individuals lack the means to achieve

93
00:03:43,850 --> 00:03:48,530
those goals they're more likely to

94
00:03:46,370 --> 00:03:51,110
commit crime so that they can achieve

95
00:03:48,530 --> 00:03:53,180
them the next ferry that we're going to

96
00:03:51,110 --> 00:03:55,880
be looking at is called social control

97
00:03:53,180 --> 00:03:57,770
theory now with this theory States is it

98
00:03:55,880 --> 00:03:59,780
six individuals who work close

99
00:03:57,770 --> 00:04:02,690
relationships commitments values or

100
00:03:59,780 --> 00:04:04,250
norms again are more likely to commit

101
00:04:02,690 --> 00:04:07,130
crime because they don't have those

102
00:04:04,250 --> 00:04:09,950
relationships or values as an anchor in

103
00:04:07,130 --> 00:04:11,690
society and then finally we're going to

104
00:04:09,950 --> 00:04:14,869
be looking at social disorganization

105
00:04:11,690 --> 00:04:18,140
theories now in this theory states as if

106
00:04:14,870 --> 00:04:20,478
that location is key if an individual

107
00:04:18,140 --> 00:04:22,650
lives or works in an area known for a

108
00:04:20,478 --> 00:04:24,990
specific type of crime this view

109
00:04:22,650 --> 00:04:28,159
States live intrinsically by just being

110
00:04:24,990 --> 00:04:30,540
that we're more likely to commit crime

111
00:04:28,160 --> 00:04:32,400
Susilo look at what predictive policing

112
00:04:30,540 --> 00:04:34,560
is different types of predictive

113
00:04:32,400 --> 00:04:37,948
policing and how we can use predictive

114
00:04:34,560 --> 00:04:38,970
policing approaches to predict crime for

115
00:04:37,949 --> 00:04:40,320
this talk here's all about natural

116
00:04:38,970 --> 00:04:41,520
language processing it's all about how

117
00:04:40,320 --> 00:04:45,000
we can use natural language processing

118
00:04:41,520 --> 00:04:47,190
to do just that before we dive into

119
00:04:45,000 --> 00:04:49,710
natural language processing however we

120
00:04:47,190 --> 00:04:52,889
need to understand what language is in

121
00:04:49,710 --> 00:04:55,409
the first place and thus as human beings

122
00:04:52,889 --> 00:04:58,889
language comes down to three main Aires

123
00:04:55,410 --> 00:05:02,370
speaking reading and writing things that

124
00:04:58,889 --> 00:05:03,330
we all do every day so because we do

125
00:05:02,370 --> 00:05:05,789
these things every day

126
00:05:03,330 --> 00:05:08,789
most of us or maybe some of us will be

127
00:05:05,789 --> 00:05:11,940
able to answer this next question and

128
00:05:08,789 --> 00:05:18,930
that's the question of Paris - products

129
00:05:11,940 --> 00:05:21,810
plus England equals what now the answer

130
00:05:18,930 --> 00:05:25,530
is London because Paris is - France as

131
00:05:21,810 --> 00:05:28,169
London is - England now if we knew that

132
00:05:25,530 --> 00:05:30,270
was the answer great but why did we know

133
00:05:28,169 --> 00:05:31,710
that was the answer well we would have

134
00:05:30,270 --> 00:05:33,419
known that that was the answer because

135
00:05:31,710 --> 00:05:35,190
the experiences we've had to a bread

136
00:05:33,419 --> 00:05:37,469
books gone an Internet spoken to people

137
00:05:35,190 --> 00:05:40,070
and this is all built but our knowledge

138
00:05:37,470 --> 00:05:43,620
base and our understanding of the world

139
00:05:40,070 --> 00:05:45,210
and so if we were to feed that question

140
00:05:43,620 --> 00:05:48,380
into our natural language processing

141
00:05:45,210 --> 00:05:50,849
machine would it be able to answer it

142
00:05:48,380 --> 00:05:53,159
well yes but only if we gave it the

143
00:05:50,849 --> 00:05:55,500
right context so this is the Wikipedia

144
00:05:53,159 --> 00:05:57,120
article for London and if we fed this

145
00:05:55,500 --> 00:05:59,400
into our natural language processing

146
00:05:57,120 --> 00:06:01,949
machine it would learn from the

147
00:05:59,400 --> 00:06:04,320
surrounding context noodlin that London

148
00:06:01,949 --> 00:06:07,320
is a city that London is in the UK of

149
00:06:04,320 --> 00:06:09,539
which England is as well again building

150
00:06:07,320 --> 00:06:13,110
on that understanding and building on

151
00:06:09,539 --> 00:06:15,539
that context and so if that's how

152
00:06:13,110 --> 00:06:17,880
natural language processing works had a

153
00:06:15,539 --> 00:06:20,610
sentiment analysis working because

154
00:06:17,880 --> 00:06:22,530
sentiment analysis is a form of natural

155
00:06:20,610 --> 00:06:24,720
language processing that allows us to

156
00:06:22,530 --> 00:06:25,739
look at a specific piece of text and say

157
00:06:24,720 --> 00:06:29,000
what's the emotion

158
00:06:25,740 --> 00:06:32,190
what is this sentiment behind that text

159
00:06:29,000 --> 00:06:34,830
and again when it comes to us as human

160
00:06:32,190 --> 00:06:35,590
beings we have 18 pillars to our

161
00:06:34,830 --> 00:06:38,139
emotions

162
00:06:35,590 --> 00:06:40,869
but for sentiment analysis who they

163
00:06:38,139 --> 00:06:44,680
really care about - that's positive

164
00:06:40,870 --> 00:06:46,950
emotions and negative emotions so how do

165
00:06:44,680 --> 00:06:49,060
we translate those eight down to two

166
00:06:46,950 --> 00:06:50,320
well what we're talking about positive

167
00:06:49,060 --> 00:06:52,570
emotions we're talking about this top

168
00:06:50,320 --> 00:06:55,030
broom just drawing anger and surprise

169
00:06:52,570 --> 00:06:56,469
with anger being the red herring

170
00:06:55,030 --> 00:06:58,479
and when we're talking about negative

171
00:06:56,470 --> 00:07:02,680
emotions we're talking about this bottle

172
00:06:58,480 --> 00:07:04,270
break and so if these are the emotions

173
00:07:02,680 --> 00:07:06,250
that we're talking about when we

174
00:07:04,270 --> 00:07:09,789
referred to sentiment analysis how to

175
00:07:06,250 --> 00:07:11,080
actually get that emotion from text well

176
00:07:09,790 --> 00:07:13,810
as the things and most machine learning

177
00:07:11,080 --> 00:07:15,010
approaches we take a massive dataset so

178
00:07:13,810 --> 00:07:17,139
for us that's going to be you brush one

179
00:07:15,010 --> 00:07:18,550
of these we're going to break each of

180
00:07:17,139 --> 00:07:20,800
those reviews down into two main

181
00:07:18,550 --> 00:07:23,800
elements the actual review and the

182
00:07:20,800 --> 00:07:25,960
sentiment of that review for example I

183
00:07:23,800 --> 00:07:27,639
love my local pizza restaurants positive

184
00:07:25,960 --> 00:07:30,760
sentiment or this place has really gone

185
00:07:27,639 --> 00:07:32,710
downhill negative sentiment we then

186
00:07:30,760 --> 00:07:35,440
break that dataset down to you we have

187
00:07:32,710 --> 00:07:37,090
our training set and our testing set but

188
00:07:35,440 --> 00:07:38,620
when it comes to training our natural

189
00:07:37,090 --> 00:07:40,419
language processing machine we look at

190
00:07:38,620 --> 00:07:42,010
the key words you say what key words are

191
00:07:40,419 --> 00:07:43,810
more prominent with a positive sentiment

192
00:07:42,010 --> 00:07:46,659
and what key words more pronounced a

193
00:07:43,810 --> 00:07:48,220
negative sentiment then when it comes to

194
00:07:46,660 --> 00:07:50,590
testing we look at the remaining

195
00:07:48,220 --> 00:07:52,720
entities and we have got an actual image

196
00:07:50,590 --> 00:07:55,119
processing machine to tell us what it

197
00:07:52,720 --> 00:07:56,530
thinks the sentiment is then if that

198
00:07:55,120 --> 00:07:59,530
matches the sentiment we know them to

199
00:07:56,530 --> 00:08:02,830
have great if it doesn't means that

200
00:07:59,530 --> 00:08:04,150
something has gone wrong and so if

201
00:08:02,830 --> 00:08:05,349
that's how the actual language

202
00:08:04,150 --> 00:08:07,810
processing works if that's have

203
00:08:05,350 --> 00:08:09,850
sentiment analysis works then what

204
00:08:07,810 --> 00:08:11,560
already exists what are some examples of

205
00:08:09,850 --> 00:08:14,229
natural language processing in the

206
00:08:11,560 --> 00:08:16,210
rivers well this is a double expression

207
00:08:14,229 --> 00:08:18,039
or specifically comprehend medical which

208
00:08:16,210 --> 00:08:19,659
is Amazon's approach to natural language

209
00:08:18,039 --> 00:08:22,389
processing when it comes to healthcare

210
00:08:19,660 --> 00:08:24,280
and medicine a doctor or healthcare

211
00:08:22,389 --> 00:08:24,789
professional will type in a patient's

212
00:08:24,280 --> 00:08:27,280
details

213
00:08:24,789 --> 00:08:28,990
symptoms information the natural

214
00:08:27,280 --> 00:08:29,380
language processing talk will go off do

215
00:08:28,990 --> 00:08:31,090
its thing

216
00:08:29,380 --> 00:08:32,830
and it will come back with key bits

217
00:08:31,090 --> 00:08:36,400
information it thinks that that health

218
00:08:32,830 --> 00:08:39,159
care professional needs to know yes we

219
00:08:36,400 --> 00:08:41,370
have Tado I know TOI was Microsoft's

220
00:08:39,159 --> 00:08:44,709
approach to natural language processing

221
00:08:41,370 --> 00:08:45,670
when it came to a Twitter chat BOTS say

222
00:08:44,709 --> 00:08:46,800
which Taylor which were supposed to

223
00:08:45,670 --> 00:08:49,649
people to

224
00:08:46,800 --> 00:08:51,839
how people smoked it now what's quite

225
00:08:49,649 --> 00:08:55,740
controversial they lasted just under 24

226
00:08:51,839 --> 00:08:57,600
hours nonetheless is a great example and

227
00:08:55,740 --> 00:09:00,750
then Pilate we have predictive text sir

228
00:08:57,600 --> 00:09:02,130
well Android or an iPhone the way that

229
00:09:00,750 --> 00:09:04,260
predictive text as probably works on

230
00:09:02,130 --> 00:09:07,980
your device is by using natural language

231
00:09:04,260 --> 00:09:09,630
processing so there we have three great

232
00:09:07,980 --> 00:09:11,820
natural language processing examples

233
00:09:09,630 --> 00:09:14,130
with healthcare communications and

234
00:09:11,820 --> 00:09:15,959
mobile phones but none of those examples

235
00:09:14,130 --> 00:09:17,820
look at how we could use natural

236
00:09:15,959 --> 00:09:21,869
language processing to predict crime

237
00:09:17,820 --> 00:09:24,029
which is what this talk is all about so

238
00:09:21,870 --> 00:09:26,610
this is Alice and it's Alice's job to do

239
00:09:24,029 --> 00:09:29,070
just that it's Alice's job to predict

240
00:09:26,610 --> 00:09:31,110
crime the way that Alex Carly does this

241
00:09:29,070 --> 00:09:32,940
is she individually and manually just

242
00:09:31,110 --> 00:09:35,490
different websites different chat forums

243
00:09:32,940 --> 00:09:38,100
different social media accounts and she

244
00:09:35,490 --> 00:09:40,800
profiles specific individuals on their

245
00:09:38,100 --> 00:09:42,600
likelihood of committing crime the

246
00:09:40,800 --> 00:09:45,689
problem with this is that it's slow and

247
00:09:42,600 --> 00:09:47,640
laborious so how can we take this for

248
00:09:45,690 --> 00:09:49,529
the next level well we could automate it

249
00:09:47,640 --> 00:09:51,089
we could describe these websites for

250
00:09:49,529 --> 00:09:53,579
information relating to specific

251
00:09:51,089 --> 00:09:55,170
individuals apply our natural image

252
00:09:53,579 --> 00:09:57,599
processing and predictive policing

253
00:09:55,170 --> 00:10:00,390
techniques and then return to Alice a

254
00:09:57,600 --> 00:10:02,670
risk a score a likelihood or how likely

255
00:10:00,390 --> 00:10:05,550
these specific individuals are of

256
00:10:02,670 --> 00:10:07,529
committing a crime and then of course

257
00:10:05,550 --> 00:10:11,699
Allison ot in connection as individuals

258
00:10:07,529 --> 00:10:13,350
accordingly so if we were to build a

259
00:10:11,700 --> 00:10:16,529
framework like this what would it look

260
00:10:13,350 --> 00:10:18,570
like well first of all Allison atif we

261
00:10:16,529 --> 00:10:21,209
need to sit down and decide on an impact

262
00:10:18,570 --> 00:10:23,339
for each of these individuals if this

263
00:10:21,209 --> 00:10:25,349
individual was to commit this crime or

264
00:10:23,339 --> 00:10:28,200
wants to perform this attack what would

265
00:10:25,350 --> 00:10:29,550
the impact be and this comes down to

266
00:10:28,200 --> 00:10:32,870
those three main areas of a loss of

267
00:10:29,550 --> 00:10:35,670
intentionality integrity and variability

268
00:10:32,870 --> 00:10:38,310
once we have an impact we can work out

269
00:10:35,670 --> 00:10:40,740
our likelihood what is the likelihood of

270
00:10:38,310 --> 00:10:42,930
this individual committing this crime or

271
00:10:40,740 --> 00:10:44,370
performing this attorney and this is

272
00:10:42,930 --> 00:10:46,349
what we look back to those predictive

273
00:10:44,370 --> 00:10:48,810
policing approaches that we mentioned

274
00:10:46,350 --> 00:10:50,790
earlier on we script these websites for

275
00:10:48,810 --> 00:10:52,649
text relating to a specific individual

276
00:10:50,790 --> 00:10:55,319
we apply our natural language processing

277
00:10:52,649 --> 00:10:58,110
techniques and then first of all we say

278
00:10:55,320 --> 00:10:59,180
does this tax cut in reference 20 goals

279
00:10:58,110 --> 00:11:03,350
or aspirations

280
00:10:59,180 --> 00:11:05,239
and if so what is the sentiment next we

281
00:11:03,350 --> 00:11:07,760
take that same bit of text but now we

282
00:11:05,240 --> 00:11:09,890
say does this text contain reference to

283
00:11:07,760 --> 00:11:13,220
any close relationships and individuals

284
00:11:09,890 --> 00:11:16,460
in groups any organizations and if so

285
00:11:13,220 --> 00:11:18,050
what is the sentiment finally we take

286
00:11:16,460 --> 00:11:20,210
that same bit of text but now we say

287
00:11:18,050 --> 00:11:22,670
does this text contain reference to the

288
00:11:20,210 --> 00:11:23,930
individuals location if so is that the

289
00:11:22,670 --> 00:11:27,199
location known for this type of crime

290
00:11:23,930 --> 00:11:28,329
and finally what is the sentiment we

291
00:11:27,200 --> 00:11:31,910
think of for each of these layers

292
00:11:28,330 --> 00:11:33,650
aggregating a score as weekend and this

293
00:11:31,910 --> 00:11:36,740
score defines the overall likelihood of

294
00:11:33,650 --> 00:11:39,709
this specific individual committing a

295
00:11:36,740 --> 00:11:41,240
crime now that we have our impact in our

296
00:11:39,710 --> 00:11:43,460
likelihoods we can work out our risk

297
00:11:41,240 --> 00:11:46,810
what is the overall risk of this

298
00:11:43,460 --> 00:11:49,010
specific individual committing a crime

299
00:11:46,810 --> 00:11:51,050
penultimately we can use natural

300
00:11:49,010 --> 00:11:53,720
language processing to pull additional

301
00:11:51,050 --> 00:11:56,150
information from this text information

302
00:11:53,720 --> 00:11:59,870
like common topics or trends age gender

303
00:11:56,150 --> 00:12:02,810
or race salary occupation religion any

304
00:11:59,870 --> 00:12:04,040
dates and times now the reason why we

305
00:12:02,810 --> 00:12:05,959
haven't focused on this information

306
00:12:04,040 --> 00:12:08,209
study was because this information has

307
00:12:05,960 --> 00:12:10,640
the scope are becoming significantly

308
00:12:08,210 --> 00:12:12,290
more bias and that's where you talk for

309
00:12:10,640 --> 00:12:16,220
another day but we will touch on it

310
00:12:12,290 --> 00:12:17,569
later on and then finally we just want a

311
00:12:16,220 --> 00:12:19,100
diamond convention and then we

312
00:12:17,570 --> 00:12:21,620
convention that we can use to instantly

313
00:12:19,100 --> 00:12:22,910
identify these individuals without

314
00:12:21,620 --> 00:12:25,520
including any of that personally

315
00:12:22,910 --> 00:12:26,959
identifiable information so here we

316
00:12:25,520 --> 00:12:29,150
could use a hash we could use an IP

317
00:12:26,960 --> 00:12:31,310
address we could use a random word this

318
00:12:29,150 --> 00:12:33,350
is just one example this is broken down

319
00:12:31,310 --> 00:12:36,079
into four areas the source of the data

320
00:12:33,350 --> 00:12:37,700
the detailed time records the risk level

321
00:12:36,080 --> 00:12:40,160
which is what we worked out earlier on

322
00:12:37,700 --> 00:12:43,220
and then a pseudo-random word to give

323
00:12:40,160 --> 00:12:45,829
the name some uniqueness and then we

324
00:12:43,220 --> 00:12:48,080
have it we've looked at what predictive

325
00:12:45,830 --> 00:12:50,510
policing is what natural language

326
00:12:48,080 --> 00:12:52,680
processing is and how we can merge these

327
00:12:50,510 --> 00:12:54,809
two ideas together

328
00:12:52,680 --> 00:12:56,248
what I do next is I'm going to go

329
00:12:54,809 --> 00:12:58,680
through some questions that I normally

330
00:12:56,249 --> 00:13:00,119
get I spoke this talk I'm going to wrap

331
00:12:58,680 --> 00:13:03,439
the talk up and if we have any

332
00:13:00,119 --> 00:13:06,059
additional questions we can go from them

333
00:13:03,439 --> 00:13:07,920
so the first question we have is is

334
00:13:06,059 --> 00:13:09,899
pretty clear placing better than are

335
00:13:07,920 --> 00:13:11,248
placing an answer is nil where

336
00:13:09,899 --> 00:13:12,869
predictive policing is a tool it's a

337
00:13:11,249 --> 00:13:15,059
supplement it's a fee that should be

338
00:13:12,869 --> 00:13:17,850
used in addiction to know what placing

339
00:13:15,059 --> 00:13:20,329
and isn't here to replace police nor is

340
00:13:17,850 --> 00:13:22,410
it here to replace police intuition

341
00:13:20,329 --> 00:13:24,709
second question we have is is predictive

342
00:13:22,410 --> 00:13:26,999
policing bias and insecurity yes

343
00:13:24,709 --> 00:13:29,160
prolific policing is quite biased the

344
00:13:26,999 --> 00:13:31,920
problem we have who predicted least is

345
00:13:29,160 --> 00:13:34,559
that it's garbage in garbage out if our

346
00:13:31,920 --> 00:13:37,529
data is bias then these are frameworks

347
00:13:34,559 --> 00:13:39,449
of bias also and the problem we have of

348
00:13:37,529 --> 00:13:41,579
crime data is that it's intrinsically

349
00:13:39,449 --> 00:13:43,829
bias because we have so many

350
00:13:41,579 --> 00:13:46,559
undocumented or less documented crimes

351
00:13:43,829 --> 00:13:48,959
like assault and is that the data we

352
00:13:46,559 --> 00:13:51,839
have isn't representative of the real

353
00:13:48,959 --> 00:13:53,729
world the second problem we have when it

354
00:13:51,839 --> 00:13:55,050
comes to machine learning and bias is

355
00:13:53,730 --> 00:13:57,139
that these tools these techniques these

356
00:13:55,050 --> 00:14:01,469
frameworks are created by human beings

357
00:13:57,139 --> 00:14:02,670
who again or intrinsic advice less

358
00:14:01,470 --> 00:14:05,129
question you have is this predictive

359
00:14:02,670 --> 00:14:06,269
policing used in the real world yes so

360
00:14:05,129 --> 00:14:08,040
there's an example of being used in a

361
00:14:06,269 --> 00:14:10,079
States there's a scheme run by the LAPD

362
00:14:08,040 --> 00:14:11,910
it's called laser but with their laser

363
00:14:10,079 --> 00:14:14,489
works is that sense of score to

364
00:14:11,910 --> 00:14:17,040
ex-offenders on their likelihood of

365
00:14:14,490 --> 00:14:19,139
repeat crime and if those individuals

366
00:14:17,040 --> 00:14:23,248
fall into a top bracket they receive a

367
00:14:19,139 --> 00:14:25,189
4-1 visit from police finally we have

368
00:14:23,249 --> 00:14:27,990
how good is natural language processing

369
00:14:25,189 --> 00:14:30,360
applicable nuances or differences in

370
00:14:27,990 --> 00:14:32,100
touched now there's an example like

371
00:14:30,360 --> 00:14:34,079
giving here which is a natural language

372
00:14:32,100 --> 00:14:37,230
processing tool that can simultaneously

373
00:14:34,079 --> 00:14:38,758
for the sent to different languages and

374
00:14:37,230 --> 00:14:40,040
I find this really interesting because

375
00:14:38,759 --> 00:14:41,879
it goes to show that in some cases

376
00:14:40,040 --> 00:14:44,339
natural language processing can be

377
00:14:41,879 --> 00:14:46,339
better than the same text and some of us

378
00:14:44,339 --> 00:14:49,049
as human beings

379
00:14:46,339 --> 00:14:51,029
so are they stage of the talk you might

380
00:14:49,049 --> 00:14:51,629
be thinking I think this is really

381
00:14:51,029 --> 00:14:53,549
interesting

382
00:14:51,629 --> 00:14:56,459
or you might be thinking oh James you're

383
00:14:53,549 --> 00:14:58,319
a terrible human being who's evil you

384
00:14:56,459 --> 00:15:00,138
might also be thinking why are we

385
00:14:58,319 --> 00:15:03,240
talking about predictive policing

386
00:15:00,139 --> 00:15:04,610
adekanbi describe competence and again

387
00:15:03,240 --> 00:15:06,679
it comes back to this quote

388
00:15:04,610 --> 00:15:08,239
the idea that intrusion analysis

389
00:15:06,679 --> 00:15:10,339
security analysis

390
00:15:08,239 --> 00:15:13,309
it's about far more than the tools we

391
00:15:10,339 --> 00:15:15,709
use it's about innovating but it's also

392
00:15:13,309 --> 00:15:16,879
about thinking outside the box and

393
00:15:15,709 --> 00:15:19,459
looking at new ways that we can protect

394
00:15:16,879 --> 00:15:21,769
ourselves against attacks but also

395
00:15:19,459 --> 00:15:24,859
protect ourselves from those attacks in

396
00:15:21,769 --> 00:15:26,779
the first place now for me I care less

397
00:15:24,860 --> 00:15:28,999
about natural image processing I can

398
00:15:26,779 --> 00:15:30,559
less about predictive policing like and

399
00:15:28,999 --> 00:15:33,679
more about how we can apply these areas

400
00:15:30,559 --> 00:15:35,689
to computer security in fact on this

401
00:15:33,679 --> 00:15:38,059
September of Steiner pitched in the UK

402
00:15:35,689 --> 00:15:41,929
with that question the question of can

403
00:15:38,059 --> 00:15:43,910
we predict malicious actors however for

404
00:15:41,929 --> 00:15:45,980
now that Ethan is talking into a closed

405
00:15:43,910 --> 00:15:48,469
if you have any questions feel free to

406
00:15:45,980 --> 00:15:49,730
ask me now come find me afterwards I'm

407
00:15:48,470 --> 00:15:51,920
also on Twitter this will change

408
00:15:49,730 --> 00:15:53,029
stephenson and if you're interested any

409
00:15:51,920 --> 00:15:55,128
of the research that's going to this

410
00:15:53,029 --> 00:15:57,139
talk today in find it on github and

411
00:15:55,129 --> 00:15:58,670
hunch once again thanks all for coming

412
00:15:57,139 --> 00:16:01,389
along and thank you for the organizers

413
00:15:58,670 --> 00:16:01,389
that evening

