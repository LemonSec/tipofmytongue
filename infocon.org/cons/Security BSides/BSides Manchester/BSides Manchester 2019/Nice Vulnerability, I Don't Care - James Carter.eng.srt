1
00:00:05,130 --> 00:00:10,799
good afternoon everyone

2
00:00:08,129 --> 00:00:14,440
yes my phone is working

3
00:00:10,799 --> 00:00:15,399
did you enjoy your lunch yes somebody's

4
00:00:14,440 --> 00:00:19,840
already probably already asked you this

5
00:00:15,400 --> 00:00:21,550
but I hope you did right okay

6
00:00:19,840 --> 00:00:23,410
there's lots of people here that can

7
00:00:21,550 --> 00:00:26,230
tell you lots of really scary things

8
00:00:23,410 --> 00:00:27,939
about deep technical problems and things

9
00:00:26,230 --> 00:00:31,300
they found out and how to break things

10
00:00:27,939 --> 00:00:34,289
at a really complex way this is not that

11
00:00:31,300 --> 00:00:37,960
talk this is something different

12
00:00:34,289 --> 00:00:42,760
okay so Who am I I'm Jeff Carter

13
00:00:37,960 --> 00:00:44,649
i work as a cyber risk manager so grand

14
00:00:42,760 --> 00:00:48,210
sounding job title for a large

15
00:00:44,649 --> 00:00:55,230
international engineering consultancy

16
00:00:48,210 --> 00:00:58,929
i'd be working in tech for 25 plus years

17
00:00:55,230 --> 00:01:02,379
love ten of them in security exclusively

18
00:00:58,929 --> 00:01:05,500
and i pretty much every job you can do

19
00:01:02,379 --> 00:01:08,080
an IT except for web design i start

20
00:01:05,500 --> 00:01:11,020
writing code for six 8:09 processors if

21
00:01:08,080 --> 00:01:12,840
anyone is that old in this room more

22
00:01:11,020 --> 00:01:18,100
importantly who are you

23
00:01:12,840 --> 00:01:20,829
who here identifies this blue what i

24
00:01:18,100 --> 00:01:22,419
mean by that is who the defender who

25
00:01:20,829 --> 00:01:28,000
works for IT team who tries to keep

26
00:01:22,420 --> 00:01:31,590
their organization safe hc' well 70 80

27
00:01:28,000 --> 00:01:37,780
percent of you please just get it going

28
00:01:31,590 --> 00:01:40,930
excellent right ok this is what your

29
00:01:37,780 --> 00:01:46,509
life looks like here on open VMs general

30
00:01:40,930 --> 00:01:49,149
messes wall is 5 424 is the Allred if

31
00:01:46,509 --> 00:01:53,680
they always always read is it always

32
00:01:49,149 --> 00:02:04,240
ready every month does your life feel

33
00:01:53,680 --> 00:02:10,980
more like this yeah probably

34
00:02:04,240 --> 00:02:15,459
why is this why are you always basically

35
00:02:10,979 --> 00:02:17,950
doing the same thing why can't you get

36
00:02:15,459 --> 00:02:22,450
any traction on changing that red to

37
00:02:17,950 --> 00:02:24,399
orange to yellow to green is it just

38
00:02:22,450 --> 00:02:27,310
organizational inertia is it just such a

39
00:02:24,400 --> 00:02:29,260
big organization it can't get changed is

40
00:02:27,310 --> 00:02:31,600
it nobody listens when you tell them

41
00:02:29,260 --> 00:02:34,179
about how bad stuff is you've been to

42
00:02:31,600 --> 00:02:35,859
all the technical talks here and you've

43
00:02:34,180 --> 00:02:38,370
learned all the technical stuff about

44
00:02:35,860 --> 00:02:41,380
really bad fun abilities and you've

45
00:02:38,370 --> 00:02:44,019
gotta say and said this bad stuff

46
00:02:41,380 --> 00:02:47,109
is happening and they've gone yeah right

47
00:02:44,019 --> 00:03:14,110
thanks and got on with it they just did

48
00:02:47,110 --> 00:03:16,269
it just not understand technology keep

49
00:03:14,110 --> 00:03:20,590
talking maybe by the minute

50
00:03:16,269 --> 00:03:22,570
absolutely round with us what are you

51
00:03:20,590 --> 00:03:27,760
basically stuck in the impresario

52
00:03:22,570 --> 00:03:31,480
chamber hmm are you actually talking the

53
00:03:27,760 --> 00:03:33,850
right language what by this I mean is as

54
00:03:31,480 --> 00:03:35,738
security professionals we have a really

55
00:03:33,850 --> 00:03:37,870
specific language we use we talk about

56
00:03:35,739 --> 00:03:41,470
zero days we talk about vulnerabilities

57
00:03:37,870 --> 00:03:43,209
we talk about malware and other things

58
00:03:41,470 --> 00:03:46,269
that's incredibly important to how we do

59
00:03:43,209 --> 00:03:49,000
our jobs but that's not the language

60
00:03:46,269 --> 00:03:51,299
that our organizations speak so we're

61
00:03:49,000 --> 00:03:51,299
not talking

62
00:04:14,090 --> 00:04:23,400
just to recap are we talking the dye

63
00:04:18,570 --> 00:04:27,990
language we actually not being

64
00:04:23,400 --> 00:04:31,020
understood by organizations which is not

65
00:04:27,990 --> 00:04:32,630
the right language what is what are the

66
00:04:31,020 --> 00:04:35,729
languages that are organized

67
00:04:32,630 --> 00:04:38,430
organizations is I work for a big

68
00:04:35,730 --> 00:04:40,590
private organization you don't all do

69
00:04:38,430 --> 00:04:43,320
that you'll work for public companies

70
00:04:40,590 --> 00:04:45,750
your work for local authorities you'll

71
00:04:43,320 --> 00:04:48,420
work for NGOs - what sorts of different

72
00:04:45,750 --> 00:04:50,460
organizations so forgive me if I use the

73
00:04:48,420 --> 00:04:52,830
language of the organization I work for

74
00:04:50,460 --> 00:04:54,810
and I'll talk about boards and things

75
00:04:52,830 --> 00:04:59,280
like that you'll just have to mentally

76
00:04:54,810 --> 00:05:00,840
translate how did your organisation what

77
00:04:59,280 --> 00:05:03,539
exercise whatever type it is make

78
00:05:00,840 --> 00:05:05,010
choices and prioritize what other teams

79
00:05:03,540 --> 00:05:07,320
are the groups within your organization

80
00:05:05,010 --> 00:05:10,800
organization do to make choices

81
00:05:07,320 --> 00:05:12,360
prioritize and also internally what gets

82
00:05:10,800 --> 00:05:14,250
the right attention at the right level

83
00:05:12,360 --> 00:05:15,480
if you want to effect a change if you

84
00:05:14,250 --> 00:05:18,720
think there is something particularly

85
00:05:15,480 --> 00:05:20,190
bad that needs to be done who do you

86
00:05:18,720 --> 00:05:23,370
need to talk to to get that done how do

87
00:05:20,190 --> 00:05:25,350
you get their attention you very guess

88
00:05:23,370 --> 00:05:29,970
from my job title what my answers going

89
00:05:25,350 --> 00:05:32,070
to be we're going to talk about risk I'm

90
00:05:29,970 --> 00:05:33,690
going to talk about risk and risk has a

91
00:05:32,070 --> 00:05:35,159
technical language of its own so I'm

92
00:05:33,690 --> 00:05:38,969
going to talk to you about the technical

93
00:05:35,160 --> 00:05:40,740
language of a risk and we are going to

94
00:05:38,970 --> 00:05:42,650
talk about a few few of the technical

95
00:05:40,740 --> 00:05:45,510
terms and then we're going to look at

96
00:05:42,650 --> 00:05:48,179
the structure i've actually how you can

97
00:05:45,510 --> 00:05:51,200
use risk to make your job easier and to

98
00:05:48,180 --> 00:05:54,900
communicate with your organization so

99
00:05:51,200 --> 00:05:57,560
fire who's seen this fire triangle that

100
00:05:54,900 --> 00:06:02,099
get fire you need fuel oxygen the heat

101
00:05:57,560 --> 00:06:05,309
seen this cool right take one away you

102
00:06:02,100 --> 00:06:08,279
get rid of the fire self-evident

103
00:06:05,309 --> 00:06:10,709
it's exactly the same as risk here is

104
00:06:08,279 --> 00:06:12,169
the risk triangle risk is made up of

105
00:06:10,709 --> 00:06:15,089
three things

106
00:06:12,169 --> 00:06:17,039
vulnerability of threat and I'll talk

107
00:06:15,089 --> 00:06:18,419
about a bit here this is not technical

108
00:06:17,039 --> 00:06:20,429
vulnerabilities although it might be

109
00:06:18,419 --> 00:06:22,198
it's any sort of vulnerability and we'll

110
00:06:20,429 --> 00:06:33,508
come on to what that is coming please

111
00:06:22,199 --> 00:06:35,999
have a seat exactly like fire you take

112
00:06:33,509 --> 00:06:40,079
one of those away you get rid of or

113
00:06:35,999 --> 00:06:43,229
you've modified the risk so far so good

114
00:06:40,079 --> 00:06:47,549
excellent I'll take complete silence as

115
00:06:43,229 --> 00:06:51,029
a confirmation right so the three parts

116
00:06:47,549 --> 00:06:56,188
of a value what has value information

117
00:06:51,029 --> 00:06:57,779
has value I'm sad to say unless you

118
00:06:56,189 --> 00:07:00,779
happen to be very lucky work for tech

119
00:06:57,779 --> 00:07:05,549
company the thing that your organization

120
00:07:00,779 --> 00:07:09,239
values is information we mostly work for

121
00:07:05,549 --> 00:07:12,149
IT departments we are so focused on the

122
00:07:09,239 --> 00:07:13,529
team because it's cool it's what we do

123
00:07:12,149 --> 00:07:15,899
it's what we like to do it's what you

124
00:07:13,529 --> 00:07:19,829
love doing that we often forget about

125
00:07:15,899 --> 00:07:21,809
the I actually our organizations really

126
00:07:19,829 --> 00:07:24,929
only care about the I and I'm sorry to

127
00:07:21,809 --> 00:07:28,229
say without the I the T it's just

128
00:07:24,929 --> 00:07:30,388
expensive Tim and services and frankly I

129
00:07:28,229 --> 00:07:32,308
suspect our organizations would probably

130
00:07:30,389 --> 00:07:35,519
live without it if they could but they

131
00:07:32,309 --> 00:07:38,449
can't because they need it so what makes

132
00:07:35,519 --> 00:07:40,829
information valuable lots of things

133
00:07:38,449 --> 00:07:42,599
sorry about the flaking on the slides

134
00:07:40,829 --> 00:07:46,469
thing is probably my machine but I'll

135
00:07:42,599 --> 00:07:48,058
play no young baby kid intellectually

136
00:07:46,469 --> 00:07:51,179
their information to lend intellectual

137
00:07:48,059 --> 00:07:52,860
property maybe which is valuable to your

138
00:07:51,179 --> 00:07:55,888
organization it actually attached a

139
00:07:52,860 --> 00:07:58,019
pounds value to the information maybe

140
00:07:55,889 --> 00:08:05,729
that information attracts regulatory or

141
00:07:58,019 --> 00:08:08,309
legal reasons GDP are a specific value

142
00:08:05,729 --> 00:08:11,039
to be for piece of information maybe

143
00:08:08,309 --> 00:08:14,219
it's nothing to do with pounds please

144
00:08:11,039 --> 00:08:16,159
set up safe and it's also reputation

145
00:08:14,219 --> 00:08:18,440
maybe it's a reputation

146
00:08:16,160 --> 00:08:22,850
many many other things to make

147
00:08:18,440 --> 00:08:25,130
information valuable okay

148
00:08:22,850 --> 00:08:27,110
the old-fashioned threat triad of

149
00:08:25,130 --> 00:08:29,510
information security confidentially and

150
00:08:27,110 --> 00:08:31,490
integrity availability think about these

151
00:08:29,510 --> 00:08:33,500
in terms of valuing your information and

152
00:08:31,490 --> 00:08:35,720
don't forget the information sits on top

153
00:08:33,500 --> 00:08:37,789
of a system that system sits in a

154
00:08:35,720 --> 00:08:39,530
building all those things attract value

155
00:08:37,789 --> 00:08:42,049
and have the value that they inherit

156
00:08:39,530 --> 00:08:43,579
their value through information most of

157
00:08:42,049 --> 00:08:48,260
them have no inherent value in their own

158
00:08:43,580 --> 00:08:49,970
right okay threat to many words mr.

159
00:08:48,260 --> 00:08:53,319
character you may read that the slide I

160
00:08:49,970 --> 00:08:56,090
will not read it to you but it's easy

161
00:08:53,320 --> 00:09:00,620
threat this is the what this is what is

162
00:08:56,090 --> 00:09:03,080
going to happen okay so we've got value

163
00:09:00,620 --> 00:09:05,510
we've got threat the final piece is

164
00:09:03,080 --> 00:09:07,520
vulnerability again this is about

165
00:09:05,510 --> 00:09:09,730
weaknesses now this has weaknesses in

166
00:09:07,520 --> 00:09:12,319
systems obviously it is technical

167
00:09:09,730 --> 00:09:13,940
weaknesses vulnerabilities the ones all

168
00:09:12,320 --> 00:09:16,010
the ones you found with a tenable necess

169
00:09:13,940 --> 00:09:18,980
or OpenVMS all of those but it could

170
00:09:16,010 --> 00:09:21,110
also be a weakness in design it could be

171
00:09:18,980 --> 00:09:26,810
weakness in process it can be a weakness

172
00:09:21,110 --> 00:09:29,630
in any way related to the system it

173
00:09:26,810 --> 00:09:31,010
could be a weakness in the entry systems

174
00:09:29,630 --> 00:09:33,080
the building that you can basically walk

175
00:09:31,010 --> 00:09:34,460
in you could have the most brilliant of

176
00:09:33,080 --> 00:09:37,000
cybersecurity but it's something you

177
00:09:34,460 --> 00:09:43,910
just walk into the building it's useless

178
00:09:37,000 --> 00:09:45,860
so vulnerability so we've talked about

179
00:09:43,910 --> 00:09:49,459
the technical language of risk in terms

180
00:09:45,860 --> 00:09:52,580
of value threat and vulnerability we put

181
00:09:49,460 --> 00:09:55,120
that together and interestingly that

182
00:09:52,580 --> 00:09:56,990
gives us a format for describing a risk

183
00:09:55,120 --> 00:09:59,270
what I mean by this

184
00:09:56,990 --> 00:10:03,830
here's quick example our threat is the

185
00:09:59,270 --> 00:10:07,130
loss of confidentiality the P part of a

186
00:10:03,830 --> 00:10:10,220
value is personal data held by HR

187
00:10:07,130 --> 00:10:12,980
something gdpr something a foreign

188
00:10:10,220 --> 00:10:15,950
Europe and the vulnerability is that we

189
00:10:12,980 --> 00:10:17,930
have uncontrolled use of USB media so

190
00:10:15,950 --> 00:10:20,810
therefore really in a very short

191
00:10:17,930 --> 00:10:24,109
sentence we have described a risk so

192
00:10:20,810 --> 00:10:25,790
we've gone from uncontrolled use of use

193
00:10:24,110 --> 00:10:27,920
of USB media it's really really bad

194
00:10:25,790 --> 00:10:29,870
because bad things will happen to having

195
00:10:27,920 --> 00:10:33,199
a

196
00:10:29,870 --> 00:10:36,830
formatted description of the risk so far

197
00:10:33,200 --> 00:10:38,589
so good okay you've got someone's

198
00:10:36,830 --> 00:10:41,029
attention you've gone to talk to your

199
00:10:38,589 --> 00:10:42,620
management team who you want to do

200
00:10:41,029 --> 00:10:44,240
something who won't persuade to do them

201
00:10:42,620 --> 00:10:47,330
and you've got their attention you've

202
00:10:44,240 --> 00:10:48,620
shown them a risk statement the first

203
00:10:47,330 --> 00:10:50,810
thing they're going to say is how bad is

204
00:10:48,620 --> 00:10:52,430
it can you quantify the risk there are

205
00:10:50,810 --> 00:10:55,910
multiple ways of quantifying a risk

206
00:10:52,430 --> 00:10:59,989
the simplest one it's like this mmm

207
00:10:55,910 --> 00:11:03,380
it feels quite risky to me it's okay it

208
00:10:59,990 --> 00:11:05,180
works it's just not the best there are

209
00:11:03,380 --> 00:11:07,700
many many good ways to calculating risk

210
00:11:05,180 --> 00:11:10,969
if your organisation already has a way

211
00:11:07,700 --> 00:11:12,529
of calculating risk use it if you can

212
00:11:10,970 --> 00:11:15,260
use it if you hook into it use it

213
00:11:12,529 --> 00:11:20,120
because they accept it already

214
00:11:15,260 --> 00:11:22,339
it's already used to calculate risks and

215
00:11:20,120 --> 00:11:24,529
make decisions if you've got a team

216
00:11:22,339 --> 00:11:28,010
through health and safety they certainly

217
00:11:24,529 --> 00:11:33,010
risk calculation methodology jump on the

218
00:11:28,010 --> 00:11:35,540
back of map use it adapt it steal it

219
00:11:33,010 --> 00:11:37,760
remember informational security is just

220
00:11:35,540 --> 00:11:38,949
health and safety for data nothing more

221
00:11:37,760 --> 00:11:41,450
nothing less

222
00:11:38,950 --> 00:11:45,350
you're gonna say why don't we just use

223
00:11:41,450 --> 00:11:48,320
CVS s and you can but CBS says is a

224
00:11:45,350 --> 00:11:50,209
technical and B has nothing to say about

225
00:11:48,320 --> 00:11:53,690
your organization unless you redo the

226
00:11:50,209 --> 00:11:56,869
calculation for who balkanization is you

227
00:11:53,690 --> 00:11:58,910
need an also see Vanessa again right

228
00:11:56,870 --> 00:12:00,890
back into the echo chamber we're talking

229
00:11:58,910 --> 00:12:04,400
our language of the language of our

230
00:12:00,890 --> 00:12:06,970
organization a common vulnerability

231
00:12:04,400 --> 00:12:09,650
scoring system you'll find that

232
00:12:06,970 --> 00:12:14,690
vulnerability will have a CBS s score

233
00:12:09,650 --> 00:12:17,319
from zero not point one to ten ten beep

234
00:12:14,690 --> 00:12:20,870
oh my god the world's going to end and

235
00:12:17,320 --> 00:12:26,000
working its way down critical is above

236
00:12:20,870 --> 00:12:28,010
seven for example okay so if we are

237
00:12:26,000 --> 00:12:29,480
going to quantify risk there are many

238
00:12:28,010 --> 00:12:31,610
ways of doing it you can find lots of

239
00:12:29,480 --> 00:12:33,740
them I'm going to show you one I'm going

240
00:12:31,610 --> 00:12:36,200
to show you a simple one and it's

241
00:12:33,740 --> 00:12:38,410
basically your risk the value of your

242
00:12:36,200 --> 00:12:40,490
risk is the impact of the risk

243
00:12:38,410 --> 00:12:41,870
multiplied by the likelihood of it

244
00:12:40,490 --> 00:12:43,910
happening and I'll show you how that

245
00:12:41,870 --> 00:12:49,550
works so let's to

246
00:12:43,910 --> 00:12:51,800
about impact first impact is based on

247
00:12:49,550 --> 00:12:55,880
the value of information plus all the

248
00:12:51,800 --> 00:12:57,469
supporting systems consider the loss of

249
00:12:55,880 --> 00:13:00,530
confidentiality integrity or

250
00:12:57,470 --> 00:13:02,630
availability impacts are not just

251
00:13:00,530 --> 00:13:04,970
financial so what I mean by this is

252
00:13:02,630 --> 00:13:09,500
let's have a look at a simple scale now

253
00:13:04,970 --> 00:13:11,480
this one's got three great load medium

254
00:13:09,500 --> 00:13:14,210
high the one the use for the

255
00:13:11,480 --> 00:13:16,400
organization I work for has five this

256
00:13:14,210 --> 00:13:17,690
one's got three so you've got some value

257
00:13:16,400 --> 00:13:19,610
you know I'm not going to read all of

258
00:13:17,690 --> 00:13:21,320
this but basically a low impact is you

259
00:13:19,610 --> 00:13:25,130
know plus a lots of money a bit more

260
00:13:21,320 --> 00:13:26,840
money quite a lot of money reputation

261
00:13:25,130 --> 00:13:28,730
reputational impact especially with

262
00:13:26,840 --> 00:13:31,820
larger organizations publicly traded

263
00:13:28,730 --> 00:13:33,950
organizations reputation they care about

264
00:13:31,820 --> 00:13:36,860
value a lot but they care about

265
00:13:33,950 --> 00:13:39,290
reputation more you can always make more

266
00:13:36,860 --> 00:13:42,020
money okay you make a mistake it costs

267
00:13:39,290 --> 00:13:44,540
you better money your company you can

268
00:13:42,020 --> 00:13:46,730
make more money it's hard work you can

269
00:13:44,540 --> 00:13:48,349
do it if you lose your reputation you

270
00:13:46,730 --> 00:13:50,120
lose your ability to trade if you lose

271
00:13:48,350 --> 00:13:53,390
your ability to trade you can never make

272
00:13:50,120 --> 00:13:58,400
more money so reputations often much

273
00:13:53,390 --> 00:13:59,840
more valuable than that than just value

274
00:13:58,400 --> 00:14:01,459
and you might have a regulatory impact

275
00:13:59,840 --> 00:14:02,570
you might get increased supervision or

276
00:14:01,460 --> 00:14:06,500
you may get fines or criminal

277
00:14:02,570 --> 00:14:09,080
proceedings there are many other types

278
00:14:06,500 --> 00:14:11,260
of impact you need to work out what this

279
00:14:09,080 --> 00:14:13,370
is for your organization this is

280
00:14:11,260 --> 00:14:16,010
specific to your organization there is

281
00:14:13,370 --> 00:14:18,820
not one size fits all if there was it

282
00:14:16,010 --> 00:14:18,819
would be easy okay

283
00:14:19,810 --> 00:14:25,449
likelihood what's the probability the

284
00:14:22,370 --> 00:14:27,770
risk occurring in has it happened before

285
00:14:25,450 --> 00:14:29,420
what have we done about it so far what's

286
00:14:27,770 --> 00:14:33,020
the maturity of our current

287
00:14:29,420 --> 00:14:36,469
implementation okay so example of that

288
00:14:33,020 --> 00:14:39,199
here is a simple three point scale of

289
00:14:36,470 --> 00:14:42,320
likelihood from low low probability may

290
00:14:39,200 --> 00:14:43,520
be less than 10% for example never

291
00:14:42,320 --> 00:14:46,400
happened before and you've got great

292
00:14:43,520 --> 00:14:49,730
controls through to high image is gonna

293
00:14:46,400 --> 00:14:53,449
happen maybe one out of two times have

294
00:14:49,730 --> 00:14:56,070
happened that's frequently all-time HR

295
00:14:53,450 --> 00:15:00,060
are always losing memory sticks

296
00:14:56,070 --> 00:15:03,420
and we've got no control on your you

297
00:15:00,060 --> 00:15:06,239
must be media so you gotta there is your

298
00:15:03,420 --> 00:15:09,240
high highlight yard again this is

299
00:15:06,240 --> 00:15:11,699
specific to your organization again the

300
00:15:09,240 --> 00:15:15,480
OPA note this organization I work this

301
00:15:11,699 --> 00:15:17,790
place for ho scale is five points and if

302
00:15:15,480 --> 00:15:19,610
you understand I tell you cannot do from

303
00:15:17,790 --> 00:15:22,560
the interesting which you can take the

304
00:15:19,610 --> 00:15:26,670
ITIL scale of maturity and invert it

305
00:15:22,560 --> 00:15:29,219
therefore a high maturity control these

306
00:15:26,670 --> 00:15:32,699
has a low likelihood of occurring

307
00:15:29,220 --> 00:15:34,589
whereas a very immature control ad hoc

308
00:15:32,699 --> 00:15:38,310
or on existing control has a high

309
00:15:34,589 --> 00:15:41,759
likelihood for failing okay make sense

310
00:15:38,310 --> 00:15:45,329
so far silence of great excellent you

311
00:15:41,759 --> 00:15:47,040
all agree with me so how do we then

312
00:15:45,329 --> 00:15:50,479
calculate the risk what's art survive

313
00:15:47,040 --> 00:15:53,819
said that risk quantify the risk is

314
00:15:50,480 --> 00:15:56,310
impact which we talked about the x

315
00:15:53,819 --> 00:15:59,130
likelihood which we talked about again

316
00:15:56,310 --> 00:16:01,290
this risk appetite is unique to your

317
00:15:59,130 --> 00:16:04,079
organization nobody else will have one

318
00:16:01,290 --> 00:16:06,930
just like yours and it defines how much

319
00:16:04,079 --> 00:16:12,089
risk you can afford to take and want to

320
00:16:06,930 --> 00:16:14,310
take so we use a simple heat map three

321
00:16:12,089 --> 00:16:16,199
by three five by five four by four

322
00:16:14,310 --> 00:16:18,479
whatever suits your organization

323
00:16:16,199 --> 00:16:21,930
whatever works a couple things you

324
00:16:18,480 --> 00:16:23,370
noticed one is it's asymmetric in this

325
00:16:21,930 --> 00:16:24,779
case it doesn't have to be you might

326
00:16:23,370 --> 00:16:26,639
have one that's perfectly symmetrical

327
00:16:24,779 --> 00:16:30,689
you might have the other down here that

328
00:16:26,639 --> 00:16:33,990
this organization has decided that no

329
00:16:30,690 --> 00:16:36,449
matter how unlikely is a how curry if

330
00:16:33,990 --> 00:16:38,160
you have a high risk we are going to

331
00:16:36,449 --> 00:16:41,550
call that red so I've just use a simple

332
00:16:38,160 --> 00:16:44,459
red and green more yellow than amber red

333
00:16:41,550 --> 00:16:45,959
amber green metric for this you might

334
00:16:44,459 --> 00:16:49,229
give them names you might be the numbers

335
00:16:45,959 --> 00:16:52,800
you might have five seven twenty grades

336
00:16:49,230 --> 00:16:55,290
it's up to you one that works simpler is

337
00:16:52,800 --> 00:16:59,219
better and I can say your organization's

338
00:16:55,290 --> 00:17:02,939
already got one use it this one my

339
00:16:59,220 --> 00:17:07,699
example we have anything that red fix

340
00:17:02,940 --> 00:17:14,010
now anything that's yellow fixes him

341
00:17:07,699 --> 00:17:15,569
anything that's green accept it and

342
00:17:14,010 --> 00:17:17,660
that's new because if we come from the

343
00:17:15,569 --> 00:17:20,159
IT break fix world

344
00:17:17,660 --> 00:17:24,870
we'll use the idea we have to fix

345
00:17:20,160 --> 00:17:27,300
everything all the time there's no

346
00:17:24,869 --> 00:17:28,979
there's no because if you don't fix it

347
00:17:27,300 --> 00:17:29,850
you don't get to close a service ticket

348
00:17:28,980 --> 00:17:32,220
ridiculous

349
00:17:29,850 --> 00:17:43,080
so the service desk ticket you fail your

350
00:17:32,220 --> 00:17:45,210
SLA exactly so but you don't have to fix

351
00:17:43,080 --> 00:17:47,340
it you can treat the risk this is what

352
00:17:45,210 --> 00:17:48,900
we used to do treating we take some

353
00:17:47,340 --> 00:17:51,929
action to mitigate the risk we can

354
00:17:48,900 --> 00:17:53,670
change something we can tolerate it we

355
00:17:51,930 --> 00:17:56,910
can accept the risk we can live with it

356
00:17:53,670 --> 00:18:01,710
now you might not be the person who is

357
00:17:56,910 --> 00:18:03,030
authorized to accept the risk but you

358
00:18:01,710 --> 00:18:04,680
could do the risk calculation and

359
00:18:03,030 --> 00:18:06,690
present an app to your management

360
00:18:04,680 --> 00:18:09,570
structure whatever flavor it is you

361
00:18:06,690 --> 00:18:11,760
might be the person to accept and they

362
00:18:09,570 --> 00:18:15,300
say they can accept it you should be

363
00:18:11,760 --> 00:18:17,820
very careful of accepting a risk which

364
00:18:15,300 --> 00:18:20,220
you are not authorized to accept there

365
00:18:17,820 --> 00:18:23,280
is a technical term use call Luc ultra

366
00:18:20,220 --> 00:18:25,500
Vera's it means you are accepting risks

367
00:18:23,280 --> 00:18:27,540
which are not yours to accept and if you

368
00:18:25,500 --> 00:18:29,730
do that you end up being somehow

369
00:18:27,540 --> 00:18:31,350
response for libel make sure the right

370
00:18:29,730 --> 00:18:34,290
people understand you should be

371
00:18:31,350 --> 00:18:36,240
accepting the risk transferring a risk

372
00:18:34,290 --> 00:18:38,159
now this is interesting not me but many

373
00:18:36,240 --> 00:18:40,500
people come across this one this is

374
00:18:38,160 --> 00:18:43,740
basically making the risk somebody

375
00:18:40,500 --> 00:18:45,900
else's problem fantastic you can buy

376
00:18:43,740 --> 00:18:47,400
some insurance of all of a sudden your

377
00:18:45,900 --> 00:18:48,270
assurance company is taking the risk

378
00:18:47,400 --> 00:18:50,070
because they're going to take the

379
00:18:48,270 --> 00:18:52,230
financial hit it happens and you're just

380
00:18:50,070 --> 00:18:54,179
going to pay them some money or you're

381
00:18:52,230 --> 00:18:55,860
gonna practice for the risk by buying a

382
00:18:54,180 --> 00:19:00,000
service and making that service

383
00:18:55,860 --> 00:19:01,500
responsible for the risk usually

384
00:19:00,000 --> 00:19:03,660
transferring a risk will involve you

385
00:19:01,500 --> 00:19:05,730
make paying some money for it or you can

386
00:19:03,660 --> 00:19:07,920
terminate risk you can just say you know

387
00:19:05,730 --> 00:19:10,830
what this is too risky we are going to

388
00:19:07,920 --> 00:19:14,490
stop doing it and you think about the

389
00:19:10,830 --> 00:19:15,908
risk triangle threat value vulnerability

390
00:19:14,490 --> 00:19:18,699
you might say

391
00:19:15,909 --> 00:19:20,769
this information no matter how we try to

392
00:19:18,699 --> 00:19:23,169
handle it is too risky too hot to handle

393
00:19:20,769 --> 00:19:25,359
we just don't don't want to be doing

394
00:19:23,169 --> 00:19:26,619
this anymore we're gonna stop which it's

395
00:19:25,359 --> 00:19:29,198
not going to do that anymore because

396
00:19:26,619 --> 00:19:34,869
it's actually the risk profile is wrong

397
00:19:29,199 --> 00:19:37,059
for us make sure you document and agree

398
00:19:34,869 --> 00:19:39,789
your decisions because especially if you

399
00:19:37,059 --> 00:19:40,569
accepted a risk and then something blows

400
00:19:39,789 --> 00:19:42,429
up later

401
00:19:40,569 --> 00:19:44,589
at least you can have you can show the

402
00:19:42,429 --> 00:19:46,089
piece of art oh yeah well we did we

403
00:19:44,589 --> 00:19:48,219
looked at this and we accepted it not

404
00:19:46,089 --> 00:19:49,329
great you don't want to have the slope

405
00:19:48,219 --> 00:19:51,009
your shoulders you take the

406
00:19:49,329 --> 00:19:55,029
responsibility for what you do do but

407
00:19:51,009 --> 00:19:56,919
also say we advise you to treat the risk

408
00:19:55,029 --> 00:19:58,829
and you decide it was financially too

409
00:19:56,919 --> 00:20:02,919
expensive and as a management team you

410
00:19:58,829 --> 00:20:05,759
chose to accept it as long as you've

411
00:20:02,919 --> 00:20:16,469
document your work you're fine

412
00:20:05,759 --> 00:20:16,469
yeah yes there's a written or

413
00:20:22,709 --> 00:20:36,249
technically ignore is taller also

414
00:20:31,029 --> 00:20:38,709
tolerate but if that's your organization

415
00:20:36,249 --> 00:20:40,269
doing that they are by Death tolerating

416
00:20:38,709 --> 00:20:43,149
it all you need to do is document that

417
00:20:40,269 --> 00:20:45,309
that's all they're doing you see now I

418
00:20:43,149 --> 00:20:46,029
reach this point now you've also come in

419
00:20:45,309 --> 00:20:48,309
through this door

420
00:20:46,029 --> 00:20:54,549
you've been taping out now over the next

421
00:20:48,309 --> 00:20:57,249
five minutes okay so using the risk you

422
00:20:54,549 --> 00:20:59,259
will now have a simple example of risk

423
00:20:57,249 --> 00:21:01,809
language this is the language your

424
00:20:59,259 --> 00:21:03,940
organization may already speak they will

425
00:21:01,809 --> 00:21:06,759
probably understand it understand it

426
00:21:03,940 --> 00:21:12,159
better than the language of zero-days

427
00:21:06,759 --> 00:21:14,049
and malware and other things to do with

428
00:21:12,159 --> 00:21:15,299
what we do and what we enjoy doing for

429
00:21:14,049 --> 00:21:18,069
our day job

430
00:21:15,299 --> 00:21:19,629
you have an ability to show them why

431
00:21:18,069 --> 00:21:21,609
something is important and when it's

432
00:21:19,629 --> 00:21:22,750
important and also when it's not

433
00:21:21,609 --> 00:21:25,750
important

434
00:21:22,750 --> 00:21:29,049
but you also have going back to our it's

435
00:21:25,750 --> 00:21:33,789
all red even the stuff that's read on

436
00:21:29,049 --> 00:21:35,950
CBS on the OpenVMS tenable scan you can

437
00:21:33,789 --> 00:21:38,200
now look at that and say it might be

438
00:21:35,950 --> 00:21:39,940
read from a tunnel point of view because

439
00:21:38,200 --> 00:21:42,549
they found this vulnerability but this

440
00:21:39,940 --> 00:21:46,360
vulnerability is in the system sort of

441
00:21:42,549 --> 00:21:49,120
such low value there I'm gonna risk

442
00:21:46,360 --> 00:21:52,030
assess that and say it's a low risk and

443
00:21:49,120 --> 00:21:53,500
my risk weight tricks my appetite says I

444
00:21:52,030 --> 00:21:54,490
don't need to do anything about that I

445
00:21:53,500 --> 00:21:57,580
can accept that

446
00:21:54,490 --> 00:22:03,780
so are all the actions required to be

447
00:21:57,580 --> 00:22:08,408
done or nice vulnerability I don't care

448
00:22:03,780 --> 00:22:12,039
so just to recap got a couple minutes

449
00:22:08,409 --> 00:22:15,030
left is the echo chamber really an ivory

450
00:22:12,039 --> 00:22:20,740
silo is it of our own making have we

451
00:22:15,030 --> 00:22:23,110
actually rather than of being the tabla

452
00:22:20,740 --> 00:22:25,120
misunderstood security people are we

453
00:22:23,110 --> 00:22:27,520
actually creating the problem part for

454
00:22:25,120 --> 00:22:29,350
ourselves by using language which is

455
00:22:27,520 --> 00:22:30,820
great for us and we have to have that

456
00:22:29,350 --> 00:22:32,049
language to do our jobs I'm not saying

457
00:22:30,820 --> 00:22:34,600
anything wrong with that language we

458
00:22:32,049 --> 00:22:39,789
also maybe not the language that our

459
00:22:34,600 --> 00:22:42,908
organization's speak risk is threat plus

460
00:22:39,789 --> 00:22:43,600
one berthsy plus value quantified risk

461
00:22:42,909 --> 00:22:47,289
is

462
00:22:43,600 --> 00:22:50,379
impact multiplied by likelihood protip

463
00:22:47,289 --> 00:22:53,260
by the way if your impact is greater

464
00:22:50,380 --> 00:22:55,179
than your value you've undervalued your

465
00:22:53,260 --> 00:23:00,879
asset you can never have and in fact

466
00:22:55,179 --> 00:23:03,220
greater than the value of your asset at

467
00:23:00,880 --> 00:23:08,049
the time an action aligned and agree

468
00:23:03,220 --> 00:23:10,120
with your organization so we have a

469
00:23:08,049 --> 00:23:11,918
technical language for security but

470
00:23:10,120 --> 00:23:14,500
there's also technical language for risk

471
00:23:11,919 --> 00:23:16,809
we need as security professionals I

472
00:23:14,500 --> 00:23:20,770
believe to speak both if we are going to

473
00:23:16,809 --> 00:23:22,330
make headway with making cyber Co cyber

474
00:23:20,770 --> 00:23:25,150
security IT security whatever you want

475
00:23:22,330 --> 00:23:26,470
to call it relevant and have meaning in

476
00:23:25,150 --> 00:23:30,400
our organizations and that be taken

477
00:23:26,470 --> 00:23:32,320
seriously with other organizations so on

478
00:23:30,400 --> 00:23:36,059
that basis I'm gonna say thank you very

479
00:23:32,320 --> 00:23:36,059
much and are there any questions

480
00:23:36,840 --> 00:23:48,070
yeah absolutely would I think I say well

481
00:23:44,710 --> 00:23:49,660
27001 'yes no matter whether the

482
00:23:48,070 --> 00:23:53,110
standard you want to layer on top of it

483
00:23:49,660 --> 00:23:55,299
I think ice 27001 is the best base

484
00:23:53,110 --> 00:23:57,428
standard because it's the most allistic

485
00:23:55,299 --> 00:24:00,700
and it's the least technical but it also

486
00:23:57,429 --> 00:24:04,270
covers all the other domains like

487
00:24:00,700 --> 00:24:07,059
physical security HR security governance

488
00:24:04,270 --> 00:24:09,639
of security so yeah take ISO 27001 is

489
00:24:07,059 --> 00:24:12,879
absolutely best because if you then have

490
00:24:09,640 --> 00:24:15,549
a requirement to deploy Mis or PCI DSS

491
00:24:12,880 --> 00:24:17,710
or anything like that you can always lay

492
00:24:15,549 --> 00:24:20,200
that on top of the ISO 27001 and map

493
00:24:17,710 --> 00:24:30,250
those controls down into the asset right

494
00:24:20,200 --> 00:25:05,040
into the 114 if you've got you can do

495
00:24:30,250 --> 00:25:09,059
that within yet without regular values

496
00:25:05,040 --> 00:25:12,639
has the potential to anybody at risk

497
00:25:09,059 --> 00:25:16,480
tolerate ease to something though any

498
00:25:12,640 --> 00:25:18,250
longer so somebody being on fire gets to

499
00:25:16,480 --> 00:25:20,470
replace their or replaces over the less

500
00:25:18,250 --> 00:25:22,480
functional model because of cost saving

501
00:25:20,470 --> 00:25:25,090
and so we end up with a whole bunch of

502
00:25:22,480 --> 00:25:27,640
stuff that was tolerated that we now

503
00:25:25,090 --> 00:25:32,620
have to emergency break lifts yep

504
00:25:27,640 --> 00:25:36,090
absolutely right and I have crammed what

505
00:25:32,620 --> 00:25:40,418
was a five-day 20 calls into 20 minutes

506
00:25:36,090 --> 00:25:42,760
so yes once you've done your risk

507
00:25:40,419 --> 00:25:44,530
assessment it's a living document you've

508
00:25:42,760 --> 00:25:47,049
got to come back to it you've got a set

509
00:25:44,530 --> 00:25:49,029
this is tolerated or this is accepted

510
00:25:47,049 --> 00:25:50,889
until this date and then we're

511
00:25:49,029 --> 00:25:52,419
reviewers received has changed so you're

512
00:25:50,889 --> 00:25:55,978
quite right there is a time cut

513
00:25:52,419 --> 00:25:59,469
component to that which I didn't mention

514
00:25:55,979 --> 00:26:01,719
so and also I'll be honest the I don't

515
00:25:59,469 --> 00:26:03,929
care actually I do care but it's a great

516
00:26:01,719 --> 00:26:03,929
title

517
00:26:19,859 --> 00:26:29,109
you don't okay the bosses well then if

518
00:26:27,219 --> 00:26:30,839
they're not responsible for it who is

519
00:26:29,109 --> 00:26:33,069
it's their business

520
00:26:30,839 --> 00:26:35,198
they're the ones who ultimately will

521
00:26:33,069 --> 00:26:37,539
take the financial hit they're paying us

522
00:26:35,199 --> 00:26:39,969
as security professionals to tell them

523
00:26:37,539 --> 00:26:44,499
what's wrong if they're not prepared to

524
00:26:39,969 --> 00:26:47,009
listen to that well you can't do much

525
00:26:44,499 --> 00:26:50,019
about it maybe we just need to keep

526
00:26:47,009 --> 00:26:51,669
drip-feeding this into them the

527
00:26:50,019 --> 00:26:53,829
important thing about also and this is

528
00:26:51,669 --> 00:26:55,119
why I suggest you use the same risk

529
00:26:53,829 --> 00:26:57,249
model that other parts of your

530
00:26:55,119 --> 00:26:59,619
organization use it means if you go to

531
00:26:57,249 --> 00:27:02,109
your management team your executive

532
00:26:59,619 --> 00:27:06,428
board your supervisor whatever it is and

533
00:27:02,109 --> 00:27:09,039
say we've got a high risk they're going

534
00:27:06,429 --> 00:27:11,939
to say well you take and there's a high

535
00:27:09,039 --> 00:27:14,079
risk on our organizational risk model

536
00:27:11,939 --> 00:27:18,489
they're going to set they should if

537
00:27:14,079 --> 00:27:20,408
we're lucky they take us seriously treat

538
00:27:18,489 --> 00:27:21,879
that as seriously as a high financial

539
00:27:20,409 --> 00:27:23,769
risk or a high health and safety risk

540
00:27:21,879 --> 00:27:26,289
because we're using the same model we're

541
00:27:23,769 --> 00:27:29,709
using the same scale of criteria if

542
00:27:26,289 --> 00:27:30,908
they're not listening to that I suggest

543
00:27:29,709 --> 00:27:34,569
you just have to keep saying it until

544
00:27:30,909 --> 00:27:36,969
they do you'll wait till the first thing

545
00:27:34,569 --> 00:27:39,188
goes wrong and then not suddenly gets a

546
00:27:36,969 --> 00:27:40,779
lot of attention but at least if you be

547
00:27:39,189 --> 00:27:42,849
talking about risk and even documenting

548
00:27:40,779 --> 00:27:45,029
your it's always good to start dress

549
00:27:42,849 --> 00:27:45,029
together

550
00:27:48,929 --> 00:27:53,559
iris model for personal risk model for

551
00:27:51,279 --> 00:27:58,179
people leapings is so it was great

552
00:27:53,559 --> 00:28:00,700
across the board if you'd actually

553
00:27:58,179 --> 00:28:02,440
documented it I don't want to be in the

554
00:28:00,700 --> 00:28:07,299
position of saying to someone I told you

555
00:28:02,440 --> 00:28:10,330
so but there probably is a nice way of

556
00:28:07,299 --> 00:28:12,519
saying we did warn you you chose to

557
00:28:10,330 --> 00:28:16,389
ignore it this is what's now happened

558
00:28:12,519 --> 00:28:18,340
however this we still have all what we

559
00:28:16,389 --> 00:28:20,168
do that we suggested you do to fix it

560
00:28:18,340 --> 00:28:22,539
let's get out of the box and try it

561
00:28:20,169 --> 00:28:24,190
again you're never going to fix your

562
00:28:22,539 --> 00:28:25,749
organization it's not your job to fix

563
00:28:24,190 --> 00:28:29,110
your organization it's your job to be a

564
00:28:25,749 --> 00:28:38,049
good selves to go to professional any

565
00:28:29,110 --> 00:28:40,418
other questions your take into account

566
00:28:38,049 --> 00:28:44,049
you need to balance her effort against

567
00:28:40,419 --> 00:28:49,389
the impact but again 20 minutes five

568
00:28:44,049 --> 00:28:50,980
days yeah you're gonna say this might be

569
00:28:49,389 --> 00:28:51,939
one of your reasons for tolerating risk

570
00:28:50,980 --> 00:28:55,360
you might say that

571
00:28:51,940 --> 00:28:57,749
the impact of this risk is 10,000 pounds

572
00:28:55,360 --> 00:28:59,860
the cost of fixing it is 500,000 pounds

573
00:28:57,749 --> 00:29:02,529
we're just gonna live with it

574
00:28:59,860 --> 00:29:05,498
but unless that highest baby maybe maybe

575
00:29:02,529 --> 00:29:06,999
it's fun 10,000 pounds financial but

576
00:29:05,499 --> 00:29:09,369
maybe the reputational damage will be

577
00:29:06,999 --> 00:29:12,279
enormous if you can get that message

578
00:29:09,369 --> 00:29:13,809
across to your budget holders you know

579
00:29:12,279 --> 00:29:15,220
sometimes you are the budget holders

580
00:29:13,809 --> 00:29:18,690
sometimes do all the people who make the

581
00:29:15,220 --> 00:29:18,690
best decisions so your depresses

582
00:29:21,030 --> 00:29:30,759
[Music]

583
00:29:22,169 --> 00:29:35,409
starting around any one of the depends

584
00:29:30,759 --> 00:29:38,580
on the challenges a lot of companies

585
00:29:35,409 --> 00:29:42,970
will face is discovery of what they have

586
00:29:38,580 --> 00:29:44,080
already yes there's an easy way there is

587
00:29:42,970 --> 00:29:46,690
an easy way of doing that

588
00:29:44,080 --> 00:29:49,678
that's scale of impact I gave you take

589
00:29:46,690 --> 00:29:53,710
that scale of impact and say to them

590
00:29:49,679 --> 00:29:55,299
identify your data sets and do it in big

591
00:29:53,710 --> 00:29:57,730
globs if you can don't do it in on

592
00:29:55,299 --> 00:29:59,680
individual files and say to them

593
00:29:57,730 --> 00:30:01,900
would be the true value on this scale

594
00:29:59,680 --> 00:30:04,810
low medium high want to find whatever it

595
00:30:01,900 --> 00:30:06,310
is of the loss of confidentiality of the

596
00:30:04,810 --> 00:30:09,010
loss of integrity of the loss of

597
00:30:06,310 --> 00:30:12,070
availability that gives you a model for

598
00:30:09,010 --> 00:30:18,030
assigning value which you can then plug

599
00:30:12,070 --> 00:30:18,030
into that formula you financials on them

600
00:30:22,920 --> 00:30:27,910
[Music]

601
00:30:24,270 --> 00:30:30,180
they by not being wasteful right

602
00:30:27,910 --> 00:30:37,420
they might not you can lose all this

603
00:30:30,180 --> 00:30:38,710
business but maybe lose the ability to

604
00:30:37,420 --> 00:30:42,730
do business is the thing that they'll

605
00:30:38,710 --> 00:30:44,970
they will they will value I would move

606
00:30:42,730 --> 00:30:44,970
time

607
00:30:48,820 --> 00:30:52,310
[Applause]

