1
00:00:00,299 --> 00:00:04,620
hi there everyone okay uh we are from

2
00:00:04,620 --> 00:00:08,480
RMS uh next slide

3
00:00:08,519 --> 00:00:11,280
um my name is Russell Thomas and I've

4
00:00:11,280 --> 00:00:13,799
been at RMS about uh three years give or

5
00:00:13,799 --> 00:00:16,740
take I come to the organization with the

6
00:00:16,740 --> 00:00:18,600
background in data science at a Regional

7
00:00:18,600 --> 00:00:22,380
Bank uh PhD work in computational social

8
00:00:22,380 --> 00:00:25,800
science and before that uh

9
00:00:25,800 --> 00:00:27,439
high-tech Enterprise

10
00:00:27,439 --> 00:00:31,279
r d marketing manufacturing

11
00:00:31,279 --> 00:00:34,500
Bachelors of Science in electrical

12
00:00:34,500 --> 00:00:37,200
engineering and management Chris my name

13
00:00:37,200 --> 00:00:39,719
is Chris Voss uh I've been at RMS for

14
00:00:39,719 --> 00:00:42,300
about seven years

15
00:00:42,300 --> 00:00:42,960
um

16
00:00:42,960 --> 00:00:45,719
bit sorry closer look at my head a bit

17
00:00:45,719 --> 00:00:47,760
of RMS about seven years

18
00:00:47,760 --> 00:00:48,780
um

19
00:00:48,780 --> 00:00:50,700
been working on our cyber rest models

20
00:00:50,700 --> 00:00:53,219
since since the outsets uh I have a

21
00:00:53,219 --> 00:00:54,660
background in mathematical modeling

22
00:00:54,660 --> 00:00:56,579
particularly in the context of natural

23
00:00:56,579 --> 00:01:00,120
catastrophes so I have a a masters in

24
00:01:00,120 --> 00:01:02,039
risk and environmental hazards and a

25
00:01:02,039 --> 00:01:04,080
Bachelors in physical geography both

26
00:01:04,080 --> 00:01:05,580
from universities in the UK as you can

27
00:01:05,580 --> 00:01:07,560
probably tell from my accent

28
00:01:07,560 --> 00:01:09,600
um

29
00:01:09,600 --> 00:01:11,820
so as Russell mentioned we do cat

30
00:01:11,820 --> 00:01:13,920
modeling and for many of you in the

31
00:01:13,920 --> 00:01:15,900
audience when we say those words this

32
00:01:15,900 --> 00:01:18,960
might be what comes to mind uh however

33
00:01:18,960 --> 00:01:20,520
unfortunately today we won't be spending

34
00:01:20,520 --> 00:01:22,080
the next 45 minutes checking out

35
00:01:22,080 --> 00:01:24,119
different designs of you know denim

36
00:01:24,119 --> 00:01:25,439
jackets for cats and that sort of stuff

37
00:01:25,439 --> 00:01:27,180
instead what we'll be talking about is

38
00:01:27,180 --> 00:01:30,299
catastrophe modeling which is a field

39
00:01:30,299 --> 00:01:32,579
within mathematical modeling focusing on

40
00:01:32,579 --> 00:01:35,360
quantifying the risk associated with

41
00:01:35,360 --> 00:01:37,740
rare severe phenomena things like

42
00:01:37,740 --> 00:01:41,040
hurricanes earthquakes floods pandemics

43
00:01:41,040 --> 00:01:43,560
and of course cyber attacks what we have

44
00:01:43,560 --> 00:01:45,659
on this lovely slide here that completes

45
00:01:45,659 --> 00:01:47,399
Russell

46
00:01:47,399 --> 00:01:49,439
it's just an example of

47
00:01:49,439 --> 00:01:53,340
some uh realistic but uh synthetic

48
00:01:53,340 --> 00:01:54,420
hurricane

49
00:01:54,420 --> 00:01:55,979
um tracks from our North Atlantic

50
00:01:55,979 --> 00:01:59,340
hurricane model so passovers Russell

51
00:01:59,340 --> 00:02:02,460
so when we say rare catastrophic events

52
00:02:02,460 --> 00:02:04,920
uh one of the features of this talk is

53
00:02:04,920 --> 00:02:07,439
going to be some Seinfeld memes I think

54
00:02:07,439 --> 00:02:09,300
we would all agree this particular

55
00:02:09,300 --> 00:02:11,400
episode where Frank Costanza fell

56
00:02:11,400 --> 00:02:14,220
backwards on a little few Sealy Jerry

57
00:02:14,220 --> 00:02:16,440
statue and it ended up in the

58
00:02:16,440 --> 00:02:19,440
proctologist's office as a very rare

59
00:02:19,440 --> 00:02:22,940
very catastrophic event

60
00:02:24,300 --> 00:02:25,920
so as we mentioned you know Russell and

61
00:02:25,920 --> 00:02:28,980
I focus on Cyber risk modeling but uh

62
00:02:28,980 --> 00:02:31,500
this is just this is just one of a whole

63
00:02:31,500 --> 00:02:33,480
Suite of different catastrophe models

64
00:02:33,480 --> 00:02:36,239
that RMS build our firm builds

65
00:02:36,239 --> 00:02:37,620
everything from North Atlantic hurricane

66
00:02:37,620 --> 00:02:40,560
models to European flood models Asian

67
00:02:40,560 --> 00:02:42,840
earthquake models and you know terrorism

68
00:02:42,840 --> 00:02:46,860
pandemic and of course cyber risk models

69
00:02:46,860 --> 00:02:49,500
so our primary clients sit within the

70
00:02:49,500 --> 00:02:52,440
insurance sphere uh this little slide

71
00:02:52,440 --> 00:02:53,760
here just kind of gives an overview of

72
00:02:53,760 --> 00:02:55,980
the insurance value chain starting from

73
00:02:55,980 --> 00:02:58,560
Individual companies who if they want to

74
00:02:58,560 --> 00:03:00,000
buy insurance will speak with insurance

75
00:03:00,000 --> 00:03:01,200
brokers

76
00:03:01,200 --> 00:03:02,700
they'll get a policy of an insurance

77
00:03:02,700 --> 00:03:04,379
company but those insurance companies

78
00:03:04,379 --> 00:03:07,459
typically don't want to

79
00:03:09,000 --> 00:03:10,980
those those companies

80
00:03:10,980 --> 00:03:12,599
um don't want to hold all the risk on

81
00:03:12,599 --> 00:03:14,220
their balance balance sheet so typically

82
00:03:14,220 --> 00:03:16,200
they interact with reinsurers to shift

83
00:03:16,200 --> 00:03:18,000
some of that off and you can see the

84
00:03:18,000 --> 00:03:20,099
flow of risk from left to right here now

85
00:03:20,099 --> 00:03:22,920
RMS is a company provides risk

86
00:03:22,920 --> 00:03:24,360
quantification tools and services

87
00:03:24,360 --> 00:03:27,299
throughout this value chain uh in the

88
00:03:27,299 --> 00:03:29,459
context of cyber risk we're primarily on

89
00:03:29,459 --> 00:03:31,739
the sort of right hand side insurers

90
00:03:31,739 --> 00:03:34,440
reinsurance Brokers and reinsurers

91
00:03:34,440 --> 00:03:36,840
themselves

92
00:03:36,840 --> 00:03:39,659
so what do we actually mean by risk well

93
00:03:39,659 --> 00:03:41,700
very simply risk is often defined as

94
00:03:41,700 --> 00:03:44,700
being the product of likelihood and

95
00:03:44,700 --> 00:03:48,180
impact now in our context impact

96
00:03:48,180 --> 00:03:50,580
actually means the direct Financial

97
00:03:50,580 --> 00:03:54,019
losses experienced by companies that

98
00:03:54,019 --> 00:03:56,400
unfortunately are on the the bad end or

99
00:03:56,400 --> 00:03:58,799
a cyber instance now on the right hand

100
00:03:58,799 --> 00:04:00,420
side here you can see some of the types

101
00:04:00,420 --> 00:04:01,980
of impacts that are considered by our

102
00:04:01,980 --> 00:04:03,659
modeling you can see everything from

103
00:04:03,659 --> 00:04:05,939
Lost Revenue that occurs during an

104
00:04:05,939 --> 00:04:07,739
incident so of course as we know when a

105
00:04:07,739 --> 00:04:09,840
bad ransomware incident occurs often

106
00:04:09,840 --> 00:04:11,340
that means a company can't operate at

107
00:04:11,340 --> 00:04:13,620
100 so we'll be quantifying that sort of

108
00:04:13,620 --> 00:04:14,299
thing

109
00:04:14,299 --> 00:04:16,858
quantifying forensics cost incident

110
00:04:16,858 --> 00:04:18,959
response costs some kinds of fines

111
00:04:18,959 --> 00:04:21,060
notification costs and Ransom payments

112
00:04:21,060 --> 00:04:22,800
and that sort of thing however we don't

113
00:04:22,800 --> 00:04:25,560
quantify is things like post-incident

114
00:04:25,560 --> 00:04:27,419
upgrades lost to Share value and this

115
00:04:27,419 --> 00:04:28,919
sort of thing and that's primarily

116
00:04:28,919 --> 00:04:30,419
because these are the sorts of losses

117
00:04:30,419 --> 00:04:32,400
that are not covered by insurance

118
00:04:32,400 --> 00:04:36,720
contracts in the Cyber Insurance sphere

119
00:04:36,720 --> 00:04:39,419
so as a result we really focus on

120
00:04:39,419 --> 00:04:40,919
incidents that

121
00:04:40,919 --> 00:04:43,380
are above a particular severity

122
00:04:43,380 --> 00:04:45,360
threshold we're really only interested

123
00:04:45,360 --> 00:04:47,639
in stuff that causes realized Financial

124
00:04:47,639 --> 00:04:49,860
pain to companies not so much about

125
00:04:49,860 --> 00:04:51,600
other kind of incidents that perhaps

126
00:04:51,600 --> 00:04:53,880
network security folks are concerned

127
00:04:53,880 --> 00:04:55,259
about intrusions that they want to

128
00:04:55,259 --> 00:04:56,520
follow up Etc but we're really

129
00:04:56,520 --> 00:04:59,040
interested in if it results in a

130
00:04:59,040 --> 00:05:01,139
financial loss we're interested if it

131
00:05:01,139 --> 00:05:04,560
doesn't not so much let's please and

132
00:05:04,560 --> 00:05:07,080
as part of this we model a diverse range

133
00:05:07,080 --> 00:05:09,060
of different types of cyber incidents

134
00:05:09,060 --> 00:05:10,560
everything from data breaches to

135
00:05:10,560 --> 00:05:13,500
ransomware attacks wipers Cloud outages

136
00:05:13,500 --> 00:05:15,300
and this sort of thing and each of those

137
00:05:15,300 --> 00:05:17,699
different what we would call sub Perils

138
00:05:17,699 --> 00:05:20,039
of cyber have different likelihoods and

139
00:05:20,039 --> 00:05:21,780
different Associated Financial losses

140
00:05:21,780 --> 00:05:23,759
and of course depending on what type of

141
00:05:23,759 --> 00:05:25,020
company we're talking about you know a

142
00:05:25,020 --> 00:05:26,759
small company versus a large company the

143
00:05:26,759 --> 00:05:28,320
likelihoods might be different to any

144
00:05:28,320 --> 00:05:29,880
industry we're talking about the

145
00:05:29,880 --> 00:05:32,340
likelihoods also might be different

146
00:05:32,340 --> 00:05:36,120
okay a quick show of hands anybody here

147
00:05:36,120 --> 00:05:39,060
work in the insurance industry cyber

148
00:05:39,060 --> 00:05:43,220
risk okay interesting uh anybody here do

149
00:05:43,220 --> 00:05:46,080
risk modeling as a business

150
00:05:46,080 --> 00:05:48,539
as opposed to

151
00:05:48,539 --> 00:05:51,539
okay so what I want to contrast here in

152
00:05:51,539 --> 00:05:54,240
this next series of slides is

153
00:05:54,240 --> 00:05:56,759
how these different perspectives of risk

154
00:05:56,759 --> 00:05:59,280
vary and overlap but are significantly

155
00:05:59,280 --> 00:06:01,440
different that's really critical to

156
00:06:01,440 --> 00:06:03,479
understand that how we approach modeling

157
00:06:03,479 --> 00:06:05,039
and how it may be different especially

158
00:06:05,039 --> 00:06:06,720
from the Enterprise

159
00:06:06,720 --> 00:06:09,300
so if you're a risk manager in an

160
00:06:09,300 --> 00:06:10,160
Enterprise

161
00:06:10,160 --> 00:06:12,840
essentially all risks all bad things

162
00:06:12,840 --> 00:06:14,699
that hap can happen your business are

163
00:06:14,699 --> 00:06:17,039
important

164
00:06:17,039 --> 00:06:19,080
so if you get hit with a really bad

165
00:06:19,080 --> 00:06:21,000
event

166
00:06:21,000 --> 00:06:23,400
causes big Financial losses or big

167
00:06:23,400 --> 00:06:25,800
reputation damage you've got to go in

168
00:06:25,800 --> 00:06:27,479
front of your board or something that

169
00:06:27,479 --> 00:06:30,660
could be a catastrophe as you define it

170
00:06:30,660 --> 00:06:33,300
but from a population standpoint if

171
00:06:33,300 --> 00:06:35,639
you're the only organization get hit by

172
00:06:35,639 --> 00:06:38,699
that the population or the people that

173
00:06:38,699 --> 00:06:41,300
look at populations like governments

174
00:06:41,300 --> 00:06:44,340
Regulators they may not see this as an

175
00:06:44,340 --> 00:06:47,039
extraordinary event it's bad for one but

176
00:06:47,039 --> 00:06:49,979
not necessarily for the population

177
00:06:49,979 --> 00:06:52,740
but if you start seeing events hitting

178
00:06:52,740 --> 00:06:55,440
many organizations essentially or

179
00:06:55,440 --> 00:06:57,960
roughly in the same time especially the

180
00:06:57,960 --> 00:07:00,919
same type of attack and attack severity

181
00:07:00,919 --> 00:07:05,580
now we've got a population level uh

182
00:07:05,580 --> 00:07:07,380
catastrophe

183
00:07:07,380 --> 00:07:09,900
now it's critical to understand that

184
00:07:09,900 --> 00:07:12,479
insurance companies View and manage

185
00:07:12,479 --> 00:07:16,259
cyber risk in the context of a portfolio

186
00:07:16,259 --> 00:07:19,979
that's how they decide what the premiums

187
00:07:19,979 --> 00:07:21,360
are going to be and what the rules for

188
00:07:21,360 --> 00:07:23,160
coverage are going to be how much

189
00:07:23,160 --> 00:07:26,280
Capital to allocate and how to even

190
00:07:26,280 --> 00:07:28,560
acquire reinsurance and report to

191
00:07:28,560 --> 00:07:29,819
regulators

192
00:07:29,819 --> 00:07:32,460
so portfolios have boundaries who's in

193
00:07:32,460 --> 00:07:35,580
and who's out portfolios have rules of

194
00:07:35,580 --> 00:07:38,819
coverage in terms of conditions and even

195
00:07:38,819 --> 00:07:40,860
every customer is going to buy different

196
00:07:40,860 --> 00:07:44,039
levels of coverage so while a single

197
00:07:44,039 --> 00:07:46,919
insurer may look at the population and

198
00:07:46,919 --> 00:07:49,080
sort of take that Advantage perspective

199
00:07:49,080 --> 00:07:51,900
they're always looking at a subset and a

200
00:07:51,900 --> 00:07:54,599
key part of the RMS product is to help

201
00:07:54,599 --> 00:07:57,060
Insurance customers go from the

202
00:07:57,060 --> 00:07:59,639
population or macro view down to their

203
00:07:59,639 --> 00:08:02,340
particular portfolio view and say what

204
00:08:02,340 --> 00:08:03,900
does this mean for the types of

205
00:08:03,900 --> 00:08:06,419
customers we cover

206
00:08:06,419 --> 00:08:11,580
so what RMS does in our model is in in

207
00:08:11,580 --> 00:08:13,379
this version six that we've just

208
00:08:13,379 --> 00:08:16,080
introduced we model a synthetic

209
00:08:16,080 --> 00:08:18,539
population of all firms above a certain

210
00:08:18,539 --> 00:08:20,639
size threshold

211
00:08:20,639 --> 00:08:24,539
and further we uh separate this

212
00:08:24,539 --> 00:08:27,900
synthetic population by the industrial

213
00:08:27,900 --> 00:08:31,080
sector as well as the geographic uh

214
00:08:31,080 --> 00:08:32,760
jurisdiction

215
00:08:32,760 --> 00:08:35,399
and critical to our modeling is what's

216
00:08:35,399 --> 00:08:38,279
the footprint of given attacks and we're

217
00:08:38,279 --> 00:08:40,260
concerned about how many threat actors

218
00:08:40,260 --> 00:08:42,059
there are and there are campaigns and

219
00:08:42,059 --> 00:08:43,679
what are their footprints

220
00:08:43,679 --> 00:08:45,660
and different campaigns can have

221
00:08:45,660 --> 00:08:47,700
different Footprints and that can affect

222
00:08:47,700 --> 00:08:51,420
who's uh who's affected and uh

223
00:08:51,420 --> 00:08:54,540
how many so some may be horizontal some

224
00:08:54,540 --> 00:08:56,580
may be vertical and in the worst case

225
00:08:56,580 --> 00:08:57,899
scenarios

226
00:08:57,899 --> 00:09:00,360
they may cover a very very large portion

227
00:09:00,360 --> 00:09:03,000
of the population and

228
00:09:03,000 --> 00:09:05,399
this is really a prime concern to our

229
00:09:05,399 --> 00:09:07,980
customers and to our models

230
00:09:07,980 --> 00:09:10,140
cool thanks Russell so to sort of

231
00:09:10,140 --> 00:09:12,200
formalize this I think it's helpful to

232
00:09:12,200 --> 00:09:15,120
sort of reiterate a couple of things so

233
00:09:15,120 --> 00:09:16,920
the first of which is that we can think

234
00:09:16,920 --> 00:09:19,680
about risk in two categories we can

235
00:09:19,680 --> 00:09:21,120
think about what's called attritional

236
00:09:21,120 --> 00:09:23,279
risk and essentially these are incidents

237
00:09:23,279 --> 00:09:24,420
like Russell mentioned at the very

238
00:09:24,420 --> 00:09:26,459
beginning which are sort of independent

239
00:09:26,459 --> 00:09:29,040
which can still be substantial in scale

240
00:09:29,040 --> 00:09:31,320
but are not associated with many many

241
00:09:31,320 --> 00:09:33,420
companies being hit so an example of

242
00:09:33,420 --> 00:09:34,740
that would be something like the 2017

243
00:09:34,740 --> 00:09:37,260
Equifax data breach which was brutal for

244
00:09:37,260 --> 00:09:39,240
Equifax but it's not like it hit

245
00:09:39,240 --> 00:09:40,620
thousands and thousands of companies

246
00:09:40,620 --> 00:09:42,180
simultaneously

247
00:09:42,180 --> 00:09:45,060
then we have tail risk which in our

248
00:09:45,060 --> 00:09:47,339
parlance is really focusing on low

249
00:09:47,339 --> 00:09:50,040
probability High severity events that

250
00:09:50,040 --> 00:09:52,680
hit many many companies simultaneously

251
00:09:52,680 --> 00:09:55,080
so these are things like Wanna Cry and

252
00:09:55,080 --> 00:09:57,060
not pettier might be examples of Terror

253
00:09:57,060 --> 00:09:58,500
risk and of course we can all imagine

254
00:09:58,500 --> 00:10:00,959
much more terrifying examples than any

255
00:10:00,959 --> 00:10:02,579
of those you know that might potentially

256
00:10:02,579 --> 00:10:04,380
occur

257
00:10:04,380 --> 00:10:07,260
so we wanted to sort of touch on how

258
00:10:07,260 --> 00:10:08,760
this influences insurance premium

259
00:10:08,760 --> 00:10:10,320
because that might be something that you

260
00:10:10,320 --> 00:10:12,120
know a touch point that you folks have

261
00:10:12,120 --> 00:10:13,620
you know directly with the insurance

262
00:10:13,620 --> 00:10:16,560
industry and so insurance premium really

263
00:10:16,560 --> 00:10:20,700
is covering the the average loss that or

264
00:10:20,700 --> 00:10:22,320
the mean loss that your company might

265
00:10:22,320 --> 00:10:24,060
experience in a given year and this

266
00:10:24,060 --> 00:10:26,700
includes both attritional and tail risk

267
00:10:26,700 --> 00:10:28,560
so on the right hand side I've got a

268
00:10:28,560 --> 00:10:30,300
very super simplified example of an

269
00:10:30,300 --> 00:10:32,339
imaginary company and let's say an

270
00:10:32,339 --> 00:10:34,920
insurance company comes up with a ten

271
00:10:34,920 --> 00:10:36,839
thousand dollar technical premium Now a

272
00:10:36,839 --> 00:10:38,279
technical premium essentially is defined

273
00:10:38,279 --> 00:10:39,560
as being

274
00:10:39,560 --> 00:10:43,440
the amount they're charging directly to

275
00:10:43,440 --> 00:10:46,200
cover the losses that you might the

276
00:10:46,200 --> 00:10:47,399
claims you might bring it doesn't

277
00:10:47,399 --> 00:10:51,000
include profit or other sorts of uh

278
00:10:51,000 --> 00:10:53,100
other sorts of costs so next one please

279
00:10:53,100 --> 00:10:55,740
also so again these numbers are made up

280
00:10:55,740 --> 00:10:58,019
but as hopefully it will help us follow

281
00:10:58,019 --> 00:11:00,360
through so the attritional component you

282
00:11:00,360 --> 00:11:01,920
can see here is about seven thousand

283
00:11:01,920 --> 00:11:03,660
five hundred dollars and the way that

284
00:11:03,660 --> 00:11:05,700
this might be computed again this is a

285
00:11:05,700 --> 00:11:08,100
simplification is that you might take

286
00:11:08,100 --> 00:11:10,380
the mean loss that the company might

287
00:11:10,380 --> 00:11:12,420
experience conditional on an incident so

288
00:11:12,420 --> 00:11:13,560
given that they've experienced an

289
00:11:13,560 --> 00:11:15,600
incident on average what's the dollar

290
00:11:15,600 --> 00:11:17,880
cost and then what you do is you combine

291
00:11:17,880 --> 00:11:19,140
that with information about the

292
00:11:19,140 --> 00:11:20,339
likelihood of that happening or the

293
00:11:20,339 --> 00:11:21,600
probability of that happening in this

294
00:11:21,600 --> 00:11:24,120
case five percent for easy numbers and

295
00:11:24,120 --> 00:11:25,560
then you get what's a probability

296
00:11:25,560 --> 00:11:27,180
weighted loss which in this case is

297
00:11:27,180 --> 00:11:29,160
seven thousand five hundred dollars but

298
00:11:29,160 --> 00:11:30,420
that only covers the attritional

299
00:11:30,420 --> 00:11:32,779
component those sort of independent

300
00:11:32,779 --> 00:11:35,880
events what you also need to consider is

301
00:11:35,880 --> 00:11:37,500
the tail component which is often called

302
00:11:37,500 --> 00:11:39,600
the catastrophe load and this is then

303
00:11:39,600 --> 00:11:41,820
considering okay what about all those

304
00:11:41,820 --> 00:11:43,500
events which might hit loads of

305
00:11:43,500 --> 00:11:45,660
companies simultaneously in this case

306
00:11:45,660 --> 00:11:47,160
here our example is saying that on

307
00:11:47,160 --> 00:11:49,380
average if our company gets caught up in

308
00:11:49,380 --> 00:11:51,300
one of those events that the loss is

309
00:11:51,300 --> 00:11:53,820
going to be 250 000 on average but

310
00:11:53,820 --> 00:11:54,959
there's only about a one percent chance

311
00:11:54,959 --> 00:11:56,760
in a given year that that this company

312
00:11:56,760 --> 00:11:58,920
gets caught up in this and when we do

313
00:11:58,920 --> 00:12:00,540
the probability weighted loss we get 2

314
00:12:00,540 --> 00:12:04,079
500 sum them and we get 10 000. um nice

315
00:12:04,079 --> 00:12:06,600
place so one thing that

316
00:12:06,600 --> 00:12:08,160
we thought is kind of useful to to

317
00:12:08,160 --> 00:12:09,060
mention

318
00:12:09,060 --> 00:12:11,220
is that you know Russell spoke about the

319
00:12:11,220 --> 00:12:13,139
different scales of risk and what what's

320
00:12:13,139 --> 00:12:14,940
catastrophic in in the eyes of an

321
00:12:14,940 --> 00:12:16,320
Enterprise versus the eyes of an

322
00:12:16,320 --> 00:12:17,760
insurance company or the eyes of a

323
00:12:17,760 --> 00:12:20,220
population and it's worth mentioning

324
00:12:20,220 --> 00:12:21,839
that you know for an individual company

325
00:12:21,839 --> 00:12:24,000
you could imagine that perhaps you know

326
00:12:24,000 --> 00:12:26,399
a brutal double extortion event might be

327
00:12:26,399 --> 00:12:28,320
the worst case scenario right where all

328
00:12:28,320 --> 00:12:29,940
of their commercially confidential

329
00:12:29,940 --> 00:12:31,680
information gets stolen you know

330
00:12:31,680 --> 00:12:32,880
personal information they have get

331
00:12:32,880 --> 00:12:34,560
stolen and leaked and at the same time

332
00:12:34,560 --> 00:12:36,540
their operations grind to a hole because

333
00:12:36,540 --> 00:12:38,100
everything's encrypted horrendous

334
00:12:38,100 --> 00:12:41,339
however due to the scaling properties of

335
00:12:41,339 --> 00:12:42,839
double extortion

336
00:12:42,839 --> 00:12:44,940
and those sorts of attacks might not be

337
00:12:44,940 --> 00:12:46,440
the drivers of population level

338
00:12:46,440 --> 00:12:48,600
catastrophe risk it might be something

339
00:12:48,600 --> 00:12:50,459
like a wiper that is just rolled out

340
00:12:50,459 --> 00:12:51,899
through a worm or something like that

341
00:12:51,899 --> 00:12:54,480
instead and ultimately

342
00:12:54,480 --> 00:12:56,279
depending on the angle at which you're

343
00:12:56,279 --> 00:12:58,579
approaching risk management you might be

344
00:12:58,579 --> 00:13:00,779
concerned about certain types of

345
00:13:00,779 --> 00:13:03,959
incidents over others

346
00:13:03,959 --> 00:13:05,940
so before we really get into the meat of

347
00:13:05,940 --> 00:13:07,620
the presentation we thought it'd be

348
00:13:07,620 --> 00:13:10,560
helpful to really spell out what

349
00:13:10,560 --> 00:13:12,540
catastrophe models in particular are

350
00:13:12,540 --> 00:13:14,579
cyberis model does and what it doesn't

351
00:13:14,579 --> 00:13:15,720
do

352
00:13:15,720 --> 00:13:18,899
what it does is assesses the likelihood

353
00:13:18,899 --> 00:13:22,019
of different loss outcomes we're not

354
00:13:22,019 --> 00:13:23,760
trying to make predictions of exactly

355
00:13:23,760 --> 00:13:25,920
what will happen now to use a simple

356
00:13:25,920 --> 00:13:28,380
maybe appropriate analogy in Las Vegas

357
00:13:28,380 --> 00:13:32,160
if we imagine a you know a dice what our

358
00:13:32,160 --> 00:13:33,720
model is saying is that the dice has six

359
00:13:33,720 --> 00:13:35,639
sides and each side has one over six

360
00:13:35,639 --> 00:13:37,800
probability of it of it being rolled

361
00:13:37,800 --> 00:13:39,360
what we're not saying is that the next

362
00:13:39,360 --> 00:13:41,160
roll is going to be a two

363
00:13:41,160 --> 00:13:42,779
um if we did know that then we wouldn't

364
00:13:42,779 --> 00:13:44,100
be here and we'd be in the casino

365
00:13:44,100 --> 00:13:45,600
instead

366
00:13:45,600 --> 00:13:46,440
um

367
00:13:46,440 --> 00:13:49,079
laughs what else what else does it do

368
00:13:49,079 --> 00:13:51,480
well what it really tries to aim it aim

369
00:13:51,480 --> 00:13:53,699
to do is to capture the key drivers of

370
00:13:53,699 --> 00:13:55,500
risk what we're not trying to do is

371
00:13:55,500 --> 00:13:57,839
reflect all of the complexity of the

372
00:13:57,839 --> 00:14:00,300
real world all of the you know huge

373
00:14:00,300 --> 00:14:01,860
depth of technical complexity that

374
00:14:01,860 --> 00:14:03,839
you're all super aware of and you know

375
00:14:03,839 --> 00:14:05,760
all the complexity of decision making of

376
00:14:05,760 --> 00:14:07,680
threat actors ultimately we're trying to

377
00:14:07,680 --> 00:14:11,100
identify what is really driving risk

378
00:14:11,100 --> 00:14:12,720
um and ultimately this comes back to the

379
00:14:12,720 --> 00:14:14,940
fact that all mathematical models are

380
00:14:14,940 --> 00:14:17,519
simplifications of the world they are

381
00:14:17,519 --> 00:14:19,680
helpful decision making tools but

382
00:14:19,680 --> 00:14:21,180
they're not supposed to you know reflect

383
00:14:21,180 --> 00:14:23,279
all of the ugly details of the real

384
00:14:23,279 --> 00:14:25,740
world and finally what our models do is

385
00:14:25,740 --> 00:14:28,320
they complement expert judgment as a

386
00:14:28,320 --> 00:14:29,940
decision-making tool they're not

387
00:14:29,940 --> 00:14:32,100
supposed to replace humans because as I

388
00:14:32,100 --> 00:14:33,540
mentioned before these models are

389
00:14:33,540 --> 00:14:35,579
simplifications so we need expert

390
00:14:35,579 --> 00:14:37,079
judgment on top of it you know some

391
00:14:37,079 --> 00:14:38,279
people might think that the output is

392
00:14:38,279 --> 00:14:39,839
too high too low

393
00:14:39,839 --> 00:14:41,519
etc etc so

394
00:14:41,519 --> 00:14:42,839
um now that we've sort of laid the

395
00:14:42,839 --> 00:14:44,820
groundwork of that we'll move on to our

396
00:14:44,820 --> 00:14:47,579
first lesson which is the benefits of

397
00:14:47,579 --> 00:14:50,399
causal risk modeling

398
00:14:50,399 --> 00:14:52,980
so a causal model is a model that

399
00:14:52,980 --> 00:14:55,019
represents the causal or mechanistic

400
00:14:55,019 --> 00:14:58,199
relationships in a system

401
00:14:58,199 --> 00:15:01,260
on the flip side statistical models are

402
00:15:01,260 --> 00:15:02,880
models that reflect the mathematical or

403
00:15:02,880 --> 00:15:04,199
statistical relationship between

404
00:15:04,199 --> 00:15:06,839
different variables next slide please so

405
00:15:06,839 --> 00:15:08,940
here we have a toy example of a

406
00:15:08,940 --> 00:15:10,440
statistical model that you might use in

407
00:15:10,440 --> 00:15:12,300
the context of cyber risk so this

408
00:15:12,300 --> 00:15:15,480
follows a very very popular framework

409
00:15:15,480 --> 00:15:18,180
the frequency severity framework so on

410
00:15:18,180 --> 00:15:19,620
the left hand side here we have a

411
00:15:19,620 --> 00:15:21,839
probability distribution showing the

412
00:15:21,839 --> 00:15:24,360
likelihood of a company experiencing an

413
00:15:24,360 --> 00:15:26,100
incident here you can see there's like a

414
00:15:26,100 --> 00:15:27,959
75 chance that it doesn't experience an

415
00:15:27,959 --> 00:15:30,120
incident just over 20 chance that it

416
00:15:30,120 --> 00:15:32,100
experiences one incident you know and a

417
00:15:32,100 --> 00:15:33,779
small percentage that hits two three or

418
00:15:33,779 --> 00:15:35,699
four incidents and then on the right

419
00:15:35,699 --> 00:15:37,380
hand side you have the severity side

420
00:15:37,380 --> 00:15:40,560
which basically says given that a

421
00:15:40,560 --> 00:15:43,019
company has experienced an incident what

422
00:15:43,019 --> 00:15:45,240
are the range of potential dollar loss

423
00:15:45,240 --> 00:15:46,500
outcomes and they're Associated

424
00:15:46,500 --> 00:15:48,240
likelihood so on the right hand side

425
00:15:48,240 --> 00:15:49,920
that's a probability density function so

426
00:15:49,920 --> 00:15:51,540
essentially where the the curve is

427
00:15:51,540 --> 00:15:53,459
highest you're sort of most likely to

428
00:15:53,459 --> 00:15:55,019
see an outcome but we can see that all

429
00:15:55,019 --> 00:15:56,639
the way down to very large numbers there

430
00:15:56,639 --> 00:15:58,800
are there's a chance that the loss plays

431
00:15:58,800 --> 00:16:00,839
out this way

432
00:16:00,839 --> 00:16:02,959
um

433
00:16:03,959 --> 00:16:05,880
one thing that those one thing that

434
00:16:05,880 --> 00:16:08,519
these kinds of models uh are good for is

435
00:16:08,519 --> 00:16:10,620
when you have a lot of data but what

436
00:16:10,620 --> 00:16:12,240
they're not very good for is trying to

437
00:16:12,240 --> 00:16:14,459
quantify very very extreme outcomes that

438
00:16:14,459 --> 00:16:16,139
you haven't observed if I want to ask

439
00:16:16,139 --> 00:16:18,180
the question what's the likelihood that

440
00:16:18,180 --> 00:16:20,940
next year 25 of companies get nailed

441
00:16:20,940 --> 00:16:23,220
with a wiper this sort of model can't

442
00:16:23,220 --> 00:16:25,019
help me because we haven't observed

443
00:16:25,019 --> 00:16:26,699
anything like that in the past we need

444
00:16:26,699 --> 00:16:29,759
to use different techniques so yeah so

445
00:16:29,759 --> 00:16:31,740
just to underline that last point I want

446
00:16:31,740 --> 00:16:33,959
to share a brief story conversation I

447
00:16:33,959 --> 00:16:39,180
had uh 2008 or 9 with a famous security

448
00:16:39,180 --> 00:16:43,440
consultant keynote speaker and he is

449
00:16:43,440 --> 00:16:45,779
that 15 minutes did you just wait 15

450
00:16:45,779 --> 00:16:48,139
minutes

451
00:16:48,779 --> 00:16:53,399
thank you scared me so anyway he was

452
00:16:53,399 --> 00:16:56,160
arguing against the possibility of ever

453
00:16:56,160 --> 00:16:59,639
quantifying low probability High

454
00:16:59,639 --> 00:17:02,880
magnitude loss his argument was if you

455
00:17:02,880 --> 00:17:05,359
take infinitesimal probabilities against

456
00:17:05,359 --> 00:17:07,799
incredibly large numbers your margin of

457
00:17:07,799 --> 00:17:10,380
error you can end up with any results

458
00:17:10,380 --> 00:17:13,980
so he was uh just trying to dissuade me

459
00:17:13,980 --> 00:17:15,900
and other people from going down that

460
00:17:15,900 --> 00:17:16,980
path

461
00:17:16,980 --> 00:17:20,039
so coming back to our Seinfeld meme

462
00:17:20,039 --> 00:17:21,720
how would you

463
00:17:21,720 --> 00:17:24,419
any of you estimate the likelihood

464
00:17:24,419 --> 00:17:26,339
probability

465
00:17:26,339 --> 00:17:28,679
the risk associated with this particular

466
00:17:28,679 --> 00:17:30,179
loss event

467
00:17:30,179 --> 00:17:34,080
well I would challenge you to take a

468
00:17:34,080 --> 00:17:36,360
standard statistical model of frequency

469
00:17:36,360 --> 00:17:38,460
and severity and apply it to this it's

470
00:17:38,460 --> 00:17:40,620
very hard to get off the ground and have

471
00:17:40,620 --> 00:17:42,480
any credible information

472
00:17:42,480 --> 00:17:46,320
so what we at RMS do in our version 6

473
00:17:46,320 --> 00:17:51,179
model is we model a synthetic world that

474
00:17:51,179 --> 00:17:54,299
has all of the key elements

475
00:17:54,299 --> 00:17:58,160
firms software vulnerabilities

476
00:17:58,160 --> 00:18:01,679
campaigns threat actors and we connect

477
00:18:01,679 --> 00:18:05,760
them in a mechanistic or causal chain

478
00:18:05,760 --> 00:18:08,100
so in this case if we wanted to include

479
00:18:08,100 --> 00:18:09,960
this we'd have to have a threat actor of

480
00:18:09,960 --> 00:18:12,360
the type Kramer and Kramer would have to

481
00:18:12,360 --> 00:18:14,760
have the capability of building weird

482
00:18:14,760 --> 00:18:16,919
things like little statues

483
00:18:16,919 --> 00:18:19,320
and his attack pattern would be leaving

484
00:18:19,320 --> 00:18:21,660
that statue on the ground where somebody

485
00:18:21,660 --> 00:18:23,880
might fall on it and then the causal

486
00:18:23,880 --> 00:18:26,280
mechanism is how is somebody like Frank

487
00:18:26,280 --> 00:18:28,380
the potential victim with vulnerability

488
00:18:28,380 --> 00:18:32,039
here likely to fall and if he falls

489
00:18:32,039 --> 00:18:34,020
what's the likelihood that he's going to

490
00:18:34,020 --> 00:18:35,880
fall in a particular way that he's going

491
00:18:35,880 --> 00:18:39,200
to have to visit a proctologist

492
00:18:41,039 --> 00:18:43,500
so to go a little bit deeper into this

493
00:18:43,500 --> 00:18:46,860
synthetic world as Russell described we

494
00:18:46,860 --> 00:18:48,840
here are really trying to call out as I

495
00:18:48,840 --> 00:18:50,820
mentioned earlier on the key drivers of

496
00:18:50,820 --> 00:18:54,299
risk in the Cyber kind of risk ecosystem

497
00:18:54,299 --> 00:18:56,700
so here what you'll see is components

498
00:18:56,700 --> 00:18:58,799
everything from Individual threat actors

499
00:18:58,799 --> 00:19:00,120
that we spawn that have various

500
00:19:00,120 --> 00:19:01,919
different characteristics size skill

501
00:19:01,919 --> 00:19:04,799
motivation Etc things like

502
00:19:04,799 --> 00:19:06,539
software different kinds of software

503
00:19:06,539 --> 00:19:07,799
that exists with different market share

504
00:19:07,799 --> 00:19:09,539
and what kinds of companies use those

505
00:19:09,539 --> 00:19:12,059
pieces of software vulnerabilities of

506
00:19:12,059 --> 00:19:13,500
course which are crucial to understand

507
00:19:13,500 --> 00:19:15,059
and that the rate at which those

508
00:19:15,059 --> 00:19:16,559
vulnerabilities spawn and their

509
00:19:16,559 --> 00:19:18,539
characteristics and of course you know

510
00:19:18,539 --> 00:19:20,280
what their exploitation kind of

511
00:19:20,280 --> 00:19:22,020
characteristics look like but then also

512
00:19:22,020 --> 00:19:23,880
things like the different ways in which

513
00:19:23,880 --> 00:19:25,440
threat actors can gain initial access

514
00:19:25,440 --> 00:19:28,860
into uh into corporates right things

515
00:19:28,860 --> 00:19:31,679
like social engineering have extremely

516
00:19:31,679 --> 00:19:33,660
different scaling characteristics to

517
00:19:33,660 --> 00:19:36,419
worms for example and modeling the

518
00:19:36,419 --> 00:19:38,520
specific ways in which those play out is

519
00:19:38,520 --> 00:19:41,520
super important

520
00:19:41,520 --> 00:19:42,780
so

521
00:19:42,780 --> 00:19:44,880
those of you kind of who

522
00:19:44,880 --> 00:19:46,740
work in a field a little bit closer to

523
00:19:46,740 --> 00:19:48,240
us might be wondering how on Earth do

524
00:19:48,240 --> 00:19:51,360
you operationalize all of that well so

525
00:19:51,360 --> 00:19:52,919
this is a bit of a simplification but

526
00:19:52,919 --> 00:19:54,480
ultimately the way that this works is

527
00:19:54,480 --> 00:19:57,660
for fifty thousand uh synthetic years

528
00:19:57,660 --> 00:20:00,539
what we do is we simulate

529
00:20:00,539 --> 00:20:03,179
we initialize a world in which you have

530
00:20:03,179 --> 00:20:04,919
software with different market share

531
00:20:04,919 --> 00:20:06,120
characteristics different

532
00:20:06,120 --> 00:20:08,039
vulnerabilities that have been spawned

533
00:20:08,039 --> 00:20:09,240
with with various different

534
00:20:09,240 --> 00:20:10,880
characteristics and then of course

535
00:20:10,880 --> 00:20:13,020
putting into place different ways in

536
00:20:13,020 --> 00:20:15,059
which threat actors can get into into

537
00:20:15,059 --> 00:20:17,159
companies and different bad things they

538
00:20:17,159 --> 00:20:20,039
can do once they're inside and then

539
00:20:20,039 --> 00:20:22,320
those threat actors essentially are able

540
00:20:22,320 --> 00:20:24,179
to evaluate their different options each

541
00:20:24,179 --> 00:20:26,100
of each year and Russell will talk a

542
00:20:26,100 --> 00:20:27,780
little bit later on about how we go

543
00:20:27,780 --> 00:20:29,580
about that and then these thread actors

544
00:20:29,580 --> 00:20:31,380
will choose what nefarious thing they

545
00:20:31,380 --> 00:20:33,840
decide to do and we essentially rinse

546
00:20:33,840 --> 00:20:36,000
and repeat this process exploring lots

547
00:20:36,000 --> 00:20:37,200
of different states of the world because

548
00:20:37,200 --> 00:20:39,299
none of us can you know write down on a

549
00:20:39,299 --> 00:20:40,620
piece of paper now exactly what's going

550
00:20:40,620 --> 00:20:41,580
to happen from a vulnerabilities

551
00:20:41,580 --> 00:20:43,260
perspective you know over the coming

552
00:20:43,260 --> 00:20:45,179
year so we need to explore a broad range

553
00:20:45,179 --> 00:20:47,640
of potential outcomes and once you

554
00:20:47,640 --> 00:20:49,080
repeat this process essentially what

555
00:20:49,080 --> 00:20:50,640
happens is you get

556
00:20:50,640 --> 00:20:52,679
synthetic attacks occurring some of

557
00:20:52,679 --> 00:20:54,059
which are much larger in scale than

558
00:20:54,059 --> 00:20:54,460
others

559
00:20:54,460 --> 00:20:55,919
[Music]

560
00:20:55,919 --> 00:20:58,559
yeah just uh those of you who might be

561
00:20:58,559 --> 00:21:00,140
familiar with

562
00:21:00,140 --> 00:21:02,340
epidemiological models of infectious

563
00:21:02,340 --> 00:21:05,940
disease especially across a network or a

564
00:21:05,940 --> 00:21:09,780
geography similar structure those models

565
00:21:09,780 --> 00:21:12,720
take the bacteria point of view or the

566
00:21:12,720 --> 00:21:15,960
virus point of view and the hosts the

567
00:21:15,960 --> 00:21:18,419
susceptible hosts are sort of provide

568
00:21:18,419 --> 00:21:20,640
the backdrop for the virus to move

569
00:21:20,640 --> 00:21:23,780
around so in this case the threat actors

570
00:21:23,780 --> 00:21:26,760
take the primary active role in decision

571
00:21:26,760 --> 00:21:28,559
making and determine what campaigns

572
00:21:28,559 --> 00:21:31,799
happen and firms at Enterprise by their

573
00:21:31,799 --> 00:21:33,600
policies and practices more or less

574
00:21:33,600 --> 00:21:35,880
determine the environment in which they

575
00:21:35,880 --> 00:21:38,280
operate

576
00:21:38,280 --> 00:21:40,740
cool so as you can imagine you know

577
00:21:40,740 --> 00:21:42,120
building this sort of model as opposed

578
00:21:42,120 --> 00:21:44,340
to a statistical model is a huge amount

579
00:21:44,340 --> 00:21:46,740
of work both from a Time effort and data

580
00:21:46,740 --> 00:21:48,419
requirements perspective so why on Earth

581
00:21:48,419 --> 00:21:50,100
do we you know pass out to all of that

582
00:21:50,100 --> 00:21:51,240
well

583
00:21:51,240 --> 00:21:53,760
as we mentioned earlier on it's our firm

584
00:21:53,760 --> 00:21:55,860
belief that you cannot

585
00:21:55,860 --> 00:21:58,679
robustly quantify extreme cyber risk

586
00:21:58,679 --> 00:22:01,020
through simple statistical models and

587
00:22:01,020 --> 00:22:02,100
through this kind of model that we've

588
00:22:02,100 --> 00:22:04,980
described extreme events are emergent

589
00:22:04,980 --> 00:22:07,559
from this particular model and the

590
00:22:07,559 --> 00:22:09,299
reason why that's the case is you will

591
00:22:09,299 --> 00:22:11,159
get years inside of this 50 000 year

592
00:22:11,159 --> 00:22:13,740
simulation where you might have an

593
00:22:13,740 --> 00:22:16,260
extremely large skilled and aggressive

594
00:22:16,260 --> 00:22:18,000
threat threat group

595
00:22:18,000 --> 00:22:20,100
who are operating in a year in which

596
00:22:20,100 --> 00:22:22,260
there are a slew of you know very very

597
00:22:22,260 --> 00:22:24,240
high severity broad reaching

598
00:22:24,240 --> 00:22:26,580
vulnerabilities and it's essentially the

599
00:22:26,580 --> 00:22:29,220
superposition of many bad things

600
00:22:29,220 --> 00:22:30,840
occurring at once that ultimately can

601
00:22:30,840 --> 00:22:33,600
result in catastrophic activity

602
00:22:33,600 --> 00:22:35,520
um there's also a bunch of other

603
00:22:35,520 --> 00:22:38,460
different uh benefits

604
00:22:38,460 --> 00:22:40,140
I think really importantly is that

605
00:22:40,140 --> 00:22:41,940
assumptions in this sort of model can be

606
00:22:41,940 --> 00:22:45,299
directly interrogated by domain experts

607
00:22:45,299 --> 00:22:47,940
if a domain expert wants to ask how do

608
00:22:47,940 --> 00:22:50,100
you consider patching and you know how

609
00:22:50,100 --> 00:22:51,360
do you consider that some companies are

610
00:22:51,360 --> 00:22:53,460
slower patching than others if you ask

611
00:22:53,460 --> 00:22:55,020
that question to the statistical model

612
00:22:55,020 --> 00:22:56,700
that we mentioned at the beginning that

613
00:22:56,700 --> 00:22:58,140
question doesn't make any sense there's

614
00:22:58,140 --> 00:22:59,640
no notion of patching inside of that

615
00:22:59,640 --> 00:23:01,860
model whatsoever whilst in the context

616
00:23:01,860 --> 00:23:03,900
of a causal model such as our own you

617
00:23:03,900 --> 00:23:05,340
have particular components that are

618
00:23:05,340 --> 00:23:07,500
directly addressing that sort of

619
00:23:07,500 --> 00:23:09,539
phenomenon real life and you can make

620
00:23:09,539 --> 00:23:12,240
sure that you are capturing the process

621
00:23:12,240 --> 00:23:14,700
in a robust manner both from a

622
00:23:14,700 --> 00:23:15,780
quantitative and a qualitative

623
00:23:15,780 --> 00:23:17,340
perspective

624
00:23:17,340 --> 00:23:17,900
um

625
00:23:17,900 --> 00:23:21,900
uh okay let's just move on next yeah

626
00:23:21,900 --> 00:23:23,760
um so yeah we're kind of taking a little

627
00:23:23,760 --> 00:23:25,620
longer than we'd hope but uh

628
00:23:25,620 --> 00:23:28,620
um so good news on empirical data so

629
00:23:28,620 --> 00:23:29,940
there's a lot of good news I think on

630
00:23:29,940 --> 00:23:32,039
the empirical data front I think it's

631
00:23:32,039 --> 00:23:34,799
things like the Frameworks that miter

632
00:23:34,799 --> 00:23:36,539
have produced things like the attack

633
00:23:36,539 --> 00:23:39,600
kpec and defend Frameworks for us have

634
00:23:39,600 --> 00:23:41,640
helped absolutely enormously in terms of

635
00:23:41,640 --> 00:23:43,559
providing a common language to describe

636
00:23:43,559 --> 00:23:45,480
different phenomena but also as a way to

637
00:23:45,480 --> 00:23:48,059
be able to homogenize uh data from

638
00:23:48,059 --> 00:23:49,860
different sources you know if you've got

639
00:23:49,860 --> 00:23:52,140
Source a and Source B both tracking

640
00:23:52,140 --> 00:23:53,520
thread actor activity and they're

641
00:23:53,520 --> 00:23:55,320
describing you know persistent

642
00:23:55,320 --> 00:23:57,480
techniques persistence technique lateral

643
00:23:57,480 --> 00:23:58,559
movement techniques all these sorts of

644
00:23:58,559 --> 00:24:00,539
things using the same language for us

645
00:24:00,539 --> 00:24:02,220
that makes things a million times easier

646
00:24:02,220 --> 00:24:04,200
so this is really great next

647
00:24:04,200 --> 00:24:06,539
I think incident data is becoming much

648
00:24:06,539 --> 00:24:08,460
more readily reported in the past things

649
00:24:08,460 --> 00:24:10,200
like data breaches were you know pretty

650
00:24:10,200 --> 00:24:11,700
commonly reported due to regulatory

651
00:24:11,700 --> 00:24:13,740
reasons but I think more and more

652
00:24:13,740 --> 00:24:15,299
companies are becoming less ashamed of

653
00:24:15,299 --> 00:24:17,100
of announcing that they've experienced a

654
00:24:17,100 --> 00:24:18,539
ransomware incident or other kinds of

655
00:24:18,539 --> 00:24:21,720
incidents like that and for us more data

656
00:24:21,720 --> 00:24:23,520
results in better models and just

657
00:24:23,520 --> 00:24:26,700
quickly regulatory influence

658
00:24:26,700 --> 00:24:28,679
Securities and Exchange Commission

659
00:24:28,679 --> 00:24:31,559
privacy reporting requirements are all

660
00:24:31,559 --> 00:24:34,559
and obviously the European requirements

661
00:24:34,559 --> 00:24:38,100
are all positive here and from our

662
00:24:38,100 --> 00:24:39,960
standpoint our customer standpoint we

663
00:24:39,960 --> 00:24:42,779
look forward to more of this uh being

664
00:24:42,779 --> 00:24:44,279
more comprehensive

665
00:24:44,279 --> 00:24:46,679
cool on top of that you know there's a

666
00:24:46,679 --> 00:24:48,419
whole series of uh

667
00:24:48,419 --> 00:24:50,220
publicly available and extremely well

668
00:24:50,220 --> 00:24:52,440
structured data on vulnerabilities so to

669
00:24:52,440 --> 00:24:54,539
some extent also on exploits I think you

670
00:24:54,539 --> 00:24:56,100
know there's still some uh perhaps some

671
00:24:56,100 --> 00:24:57,720
work to be done there but again that's

672
00:24:57,720 --> 00:25:00,720
incredibly useful from our perspective

673
00:25:00,720 --> 00:25:02,220
I think something else we really want to

674
00:25:02,220 --> 00:25:05,279
call out is the substantial body of

675
00:25:05,279 --> 00:25:07,559
really high quality statistically robust

676
00:25:07,559 --> 00:25:11,279
work that uh sort of is out in the

677
00:25:11,279 --> 00:25:13,260
literature big big shout out to the

678
00:25:13,260 --> 00:25:14,940
folks at scientia but also Folks at

679
00:25:14,940 --> 00:25:16,679
Verizon and various other different

680
00:25:16,679 --> 00:25:18,240
reports I think this sort of information

681
00:25:18,240 --> 00:25:22,020
you know really is positive for the the

682
00:25:22,020 --> 00:25:24,179
the discipline of cyber risk

683
00:25:24,179 --> 00:25:26,039
quantification in general just

684
00:25:26,039 --> 00:25:28,380
historical context some of you maybe

685
00:25:28,380 --> 00:25:29,940
have been around in the industry long

686
00:25:29,940 --> 00:25:33,299
enough to remember cost of a data breach

687
00:25:33,299 --> 00:25:35,100
reports by an organization beginning

688
00:25:35,100 --> 00:25:38,760
with the letter P so we have uh

689
00:25:38,760 --> 00:25:41,940
significantly Advanced beyond that

690
00:25:41,940 --> 00:25:43,740
and then finally you know there's some

691
00:25:43,740 --> 00:25:46,980
really great work that's going on in the

692
00:25:46,980 --> 00:25:48,419
broader Community

693
00:25:48,419 --> 00:25:51,240
um you know where there are very

694
00:25:51,240 --> 00:25:53,340
talented dedicated professionals putting

695
00:25:53,340 --> 00:25:55,140
their you know data science statistics

696
00:25:55,140 --> 00:25:58,020
and I guess cyber security knowledge

697
00:25:58,020 --> 00:26:00,600
together to put together products such

698
00:26:00,600 --> 00:26:02,940
as the epss which is the exploit

699
00:26:02,940 --> 00:26:04,980
prediction scoring system this is super

700
00:26:04,980 --> 00:26:06,600
interesting both from our perspective at

701
00:26:06,600 --> 00:26:08,760
the macro level but I think also for you

702
00:26:08,760 --> 00:26:11,279
know practitioners as providing you know

703
00:26:11,279 --> 00:26:13,200
valuable insights to the probability of

704
00:26:13,200 --> 00:26:16,260
individual exploits being of individual

705
00:26:16,260 --> 00:26:18,480
of individual vulnerabilities being

706
00:26:18,480 --> 00:26:19,679
exploited to help with things like

707
00:26:19,679 --> 00:26:21,659
prioritization a big improvement over

708
00:26:21,659 --> 00:26:25,260
their uh cbss severity system

709
00:26:25,260 --> 00:26:28,679
so all of this Foundation of data

710
00:26:28,679 --> 00:26:30,659
was really a prerequisite for us to even

711
00:26:30,659 --> 00:26:33,179
consider this sort of model certain

712
00:26:33,179 --> 00:26:35,640
areas we definitely feel you know are a

713
00:26:35,640 --> 00:26:36,779
little bit more tractable with current

714
00:26:36,779 --> 00:26:38,279
data than others I think we're very

715
00:26:38,279 --> 00:26:39,240
comfortable with where we are with

716
00:26:39,240 --> 00:26:40,919
things like software vulnerability

717
00:26:40,919 --> 00:26:43,580
spawning

718
00:26:43,799 --> 00:26:45,900
the cost of individual attacks as well

719
00:26:45,900 --> 00:26:48,299
as the mechanisms around initial access

720
00:26:48,299 --> 00:26:50,760
vectors

721
00:26:50,760 --> 00:26:53,159
and the flip side there's some not so

722
00:26:53,159 --> 00:26:55,260
good news

723
00:26:55,260 --> 00:26:57,900
so in general

724
00:26:57,900 --> 00:26:59,940
in this Arena we're always going to be

725
00:26:59,940 --> 00:27:01,799
suffering with relatively short time

726
00:27:01,799 --> 00:27:04,200
series compared to natural phenomenon

727
00:27:04,200 --> 00:27:07,020
like earthquakes and floods and so on so

728
00:27:07,020 --> 00:27:09,600
even if you can collect 20 or 30 years

729
00:27:09,600 --> 00:27:11,820
of data really only the last 10 years

730
00:27:11,820 --> 00:27:14,460
and sometimes five years is applicable

731
00:27:14,460 --> 00:27:16,799
because then you have an environment

732
00:27:16,799 --> 00:27:18,600
that's more or less consistent with

733
00:27:18,600 --> 00:27:21,179
where you're operating today so we are

734
00:27:21,179 --> 00:27:23,760
constantly having to go through data

735
00:27:23,760 --> 00:27:26,520
analysis and data evaluation process

736
00:27:26,520 --> 00:27:29,460
with any empirical data source as to how

737
00:27:29,460 --> 00:27:31,919
far back in time we go and how we make

738
00:27:31,919 --> 00:27:34,980
use of that and of course as we look

739
00:27:34,980 --> 00:27:38,159
forward the dynamic nature of what we're

740
00:27:38,159 --> 00:27:40,559
dealing with is crucial I'll just

741
00:27:40,559 --> 00:27:43,020
mention an area of my own work in

742
00:27:43,020 --> 00:27:46,140
modeling high-level Financial theft from

743
00:27:46,140 --> 00:27:49,200
Banks which was a very active area for

744
00:27:49,200 --> 00:27:51,960
certain nation states uh three to five

745
00:27:51,960 --> 00:27:54,360
years ago but those nation states have

746
00:27:54,360 --> 00:27:58,200
shifted to cryptocurrency thefts uh so

747
00:27:58,200 --> 00:27:59,880
one of the things we have to evaluate in

748
00:27:59,880 --> 00:28:01,559
a practical sense is if we're going to

749
00:28:01,559 --> 00:28:03,000
be putting out a model that our

750
00:28:03,000 --> 00:28:06,240
customers can be using for the next year

751
00:28:06,240 --> 00:28:08,460
how how much do we anticipate things

752
00:28:08,460 --> 00:28:10,460
that may be in the process of changing

753
00:28:10,460 --> 00:28:14,220
uh will the uh prevalence of ransomware

754
00:28:14,220 --> 00:28:16,740
continue for the next 12 to 18 to 24

755
00:28:16,740 --> 00:28:20,340
months is that the same as it has

756
00:28:20,340 --> 00:28:22,140
now

757
00:28:22,140 --> 00:28:25,080
crucially there's still struggling for

758
00:28:25,080 --> 00:28:27,720
information around incidents especially

759
00:28:27,720 --> 00:28:30,240
breaking down the loss event into

760
00:28:30,240 --> 00:28:32,520
categories that we can use what's

761
00:28:32,520 --> 00:28:35,520
publicized is not always uh the most

762
00:28:35,520 --> 00:28:38,100
important or the most useful and the

763
00:28:38,100 --> 00:28:40,440
biggest gap of all is information about

764
00:28:40,440 --> 00:28:43,200
threat actors and

765
00:28:43,200 --> 00:28:45,539
um I'll just give a shout out had some

766
00:28:45,539 --> 00:28:47,220
conversations over the last couple of

767
00:28:47,220 --> 00:28:50,520
days and put out over Twitter

768
00:28:50,520 --> 00:28:52,799
proposing a project collaborative

769
00:28:52,799 --> 00:28:55,860
project around modeling threat actor

770
00:28:55,860 --> 00:28:57,299
capability

771
00:28:57,299 --> 00:29:01,380
Evolution and change so if anybody is

772
00:29:01,380 --> 00:29:03,539
interested in getting involved with that

773
00:29:03,539 --> 00:29:05,520
think of it as sort of like an attack

774
00:29:05,520 --> 00:29:08,399
framework but focused on threat actors

775
00:29:08,399 --> 00:29:11,460
not from a threat Intel point of view

776
00:29:11,460 --> 00:29:14,279
that indicators of compromise and ttps

777
00:29:14,279 --> 00:29:16,919
but their organizational capabilities

778
00:29:16,919 --> 00:29:19,380
and their value chains so come up and

779
00:29:19,380 --> 00:29:22,220
see me afterward

780
00:29:23,039 --> 00:29:27,980
so this leaves us with the need to um

781
00:29:27,980 --> 00:29:30,960
evaluate uh excuse me fill in the gaps

782
00:29:30,960 --> 00:29:33,960
with data with expert knowledge so we

783
00:29:33,960 --> 00:29:35,640
mentioned here threat actors and one

784
00:29:35,640 --> 00:29:38,700
area I worked on was how do threat

785
00:29:38,700 --> 00:29:40,919
actors make decisions around campaigns

786
00:29:40,919 --> 00:29:43,260
given the options available I just got

787
00:29:43,260 --> 00:29:45,000
the 10 minute notice so I'm going to

788
00:29:45,000 --> 00:29:46,559
pick up the pace a little bit I hope

789
00:29:46,559 --> 00:29:48,899
that's okay

790
00:29:48,899 --> 00:29:50,760
so we're going to walk through a

791
00:29:50,760 --> 00:29:53,539
simplified example from the end result

792
00:29:53,539 --> 00:29:56,940
backwards so the end result we have in

793
00:29:56,940 --> 00:29:59,240
our choice model is Choice probabilities

794
00:29:59,240 --> 00:30:02,220
here six campaigns are available to this

795
00:30:02,220 --> 00:30:04,440
threat actor and what we end up here

796
00:30:04,440 --> 00:30:07,320
with Choice probability and a random

797
00:30:07,320 --> 00:30:08,880
draw is made based on those

798
00:30:08,880 --> 00:30:12,000
probabilities to the campaign Choice the

799
00:30:12,000 --> 00:30:13,980
choice probabilities here are simply the

800
00:30:13,980 --> 00:30:17,539
normalized outcome scores

801
00:30:18,000 --> 00:30:20,340
so how do we get the outcome scores and

802
00:30:20,340 --> 00:30:22,260
how do we come up with six campaigns

803
00:30:22,260 --> 00:30:25,500
well in this particular case it's three

804
00:30:25,500 --> 00:30:28,080
initial access excuse me three initial

805
00:30:28,080 --> 00:30:30,299
access vectors

806
00:30:30,299 --> 00:30:33,360
cross product with two particular attack

807
00:30:33,360 --> 00:30:36,659
types execution techniques so we've got

808
00:30:36,659 --> 00:30:40,080
ransomware the data exfiltration and

809
00:30:40,080 --> 00:30:42,480
three different ways of getting into the

810
00:30:42,480 --> 00:30:45,000
population and given their weighted

811
00:30:45,000 --> 00:30:47,460
attractiveness that determines the

812
00:30:47,460 --> 00:30:49,080
outcome score for each

813
00:30:49,080 --> 00:30:51,360
now weighted attractiveness is sort of

814
00:30:51,360 --> 00:30:54,779
where the magic happens here it we need

815
00:30:54,779 --> 00:30:57,299
to discern the relative attractiveness

816
00:30:57,299 --> 00:30:59,760
of the firms to these different types of

817
00:30:59,760 --> 00:31:01,919
an attack so a firm that's highly

818
00:31:01,919 --> 00:31:04,620
attractive to a ransomware person is not

819
00:31:04,620 --> 00:31:07,500
necessarily as attractive to the same to

820
00:31:07,500 --> 00:31:08,940
a different attack or even the same

821
00:31:08,940 --> 00:31:10,980
attacker if they're trying to exfiltrate

822
00:31:10,980 --> 00:31:12,720
a bunch of confidential health

823
00:31:12,720 --> 00:31:15,019
information

824
00:31:17,640 --> 00:31:20,039
a mission so we'll move on to the next

825
00:31:20,039 --> 00:31:21,419
thing

826
00:31:21,419 --> 00:31:24,120
so this next lesson is I guess a bit

827
00:31:24,120 --> 00:31:25,980
more of a tutorial for for those of you

828
00:31:25,980 --> 00:31:28,380
who are kind of interested in you know

829
00:31:28,380 --> 00:31:29,760
applying

830
00:31:29,760 --> 00:31:32,340
statistic simple statistical methods to

831
00:31:32,340 --> 00:31:36,360
your risk quantification work so we're

832
00:31:36,360 --> 00:31:37,260
going to talk about probability

833
00:31:37,260 --> 00:31:39,000
distribution so probability distribution

834
00:31:39,000 --> 00:31:40,700
is essentially a mathematical function

835
00:31:40,700 --> 00:31:43,320
listing a range of possible outcomes for

836
00:31:43,320 --> 00:31:45,840
a particular process and the

837
00:31:45,840 --> 00:31:47,460
corresponding likelihoods on the right

838
00:31:47,460 --> 00:31:49,440
hand side here we have a normal or a

839
00:31:49,440 --> 00:31:51,539
gaussian distribution bell-shaped curve

840
00:31:51,539 --> 00:31:53,700
for adult male height in the United

841
00:31:53,700 --> 00:31:56,120
States

842
00:31:56,340 --> 00:31:58,620
Now using observations we can actually

843
00:31:58,620 --> 00:32:00,720
come up with some reasonable parameters

844
00:32:00,720 --> 00:32:02,760
for what this mathematical function

845
00:32:02,760 --> 00:32:04,140
might look like

846
00:32:04,140 --> 00:32:06,299
and the benefits of fitting these

847
00:32:06,299 --> 00:32:08,580
functions are quite numerous actually

848
00:32:08,580 --> 00:32:10,860
the first of which is enables you to

849
00:32:10,860 --> 00:32:12,720
estimate the likelihood of different

850
00:32:12,720 --> 00:32:14,519
outcomes if you wanted to know what's

851
00:32:14,519 --> 00:32:16,140
the chance that someone is more than six

852
00:32:16,140 --> 00:32:18,059
foot three tall you can ask that to this

853
00:32:18,059 --> 00:32:19,919
mathematical function you can ask also

854
00:32:19,919 --> 00:32:21,000
what's the likelihood that they're

855
00:32:21,000 --> 00:32:22,320
between five foot and five foot five

856
00:32:22,320 --> 00:32:24,000
tall you can also ask that sort of thing

857
00:32:24,000 --> 00:32:27,240
it also enables you to determine the

858
00:32:27,240 --> 00:32:29,279
likelihood of unobserved outcomes and

859
00:32:29,279 --> 00:32:31,260
enables you to generate synthetic data

860
00:32:31,260 --> 00:32:32,820
through sampling in this case here

861
00:32:32,820 --> 00:32:35,100
Russell just showed you know if I ask

862
00:32:35,100 --> 00:32:37,740
this function give me five numbers it

863
00:32:37,740 --> 00:32:39,840
will draw in a way that's proportionate

864
00:32:39,840 --> 00:32:41,940
to the probability density now

865
00:32:41,940 --> 00:32:44,460
so how would you actually go about doing

866
00:32:44,460 --> 00:32:47,159
this in this imaginary example we're

867
00:32:47,159 --> 00:32:48,840
saying you know if I go around my local

868
00:32:48,840 --> 00:32:50,580
town and measure the height of 100

869
00:32:50,580 --> 00:32:53,460
different men I might get a histogram

870
00:32:53,460 --> 00:32:54,720
like you can see on the top right sorry

871
00:32:54,720 --> 00:32:55,980
it's a little bit small

872
00:32:55,980 --> 00:32:57,840
and if I was thinking okay what sort of

873
00:32:57,840 --> 00:32:59,159
probability distribution do I want to

874
00:32:59,159 --> 00:33:00,539
fit to this there's lots of different

875
00:33:00,539 --> 00:33:02,039
considerations that I might want to make

876
00:33:02,039 --> 00:33:04,620
but one of them should be what is my

877
00:33:04,620 --> 00:33:06,059
prior knowledge about this particular

878
00:33:06,059 --> 00:33:08,220
process you can see in the histogram

879
00:33:08,220 --> 00:33:10,260
it's bimodal meaning it has two humps

880
00:33:10,260 --> 00:33:13,380
however having lived as a human for a

881
00:33:13,380 --> 00:33:15,539
number of years I know that actually in

882
00:33:15,539 --> 00:33:16,799
general you know there's a sort of a

883
00:33:16,799 --> 00:33:18,179
smooth spectrum of heights and there's

884
00:33:18,179 --> 00:33:20,039
not a small there's not a valley of

885
00:33:20,039 --> 00:33:22,740
height in uh in the male population so

886
00:33:22,740 --> 00:33:24,059
we're going to choose a unimodal

887
00:33:24,059 --> 00:33:25,620
distribution next

888
00:33:25,620 --> 00:33:27,720
so in order to actually fit this there's

889
00:33:27,720 --> 00:33:29,159
a lot of different tools that can really

890
00:33:29,159 --> 00:33:31,140
make your life easy we use various

891
00:33:31,140 --> 00:33:32,580
different languages in our team I quite

892
00:33:32,580 --> 00:33:34,919
like Julia and what you can see here is

893
00:33:34,919 --> 00:33:36,899
you can fit that red line on the right

894
00:33:36,899 --> 00:33:38,880
hand side with just a single line of

895
00:33:38,880 --> 00:33:40,799
code it's not too terrifying you know

896
00:33:40,799 --> 00:33:42,720
there's of course a rabbit hole that you

897
00:33:42,720 --> 00:33:43,860
can go down from the statistics

898
00:33:43,860 --> 00:33:45,720
perspective but just to start getting

899
00:33:45,720 --> 00:33:47,279
familiar with this sort of stuff there

900
00:33:47,279 --> 00:33:48,480
are a lot of tools out there that can

901
00:33:48,480 --> 00:33:50,100
really help now there's a question of

902
00:33:50,100 --> 00:33:52,919
how good a job did I do and there are a

903
00:33:52,919 --> 00:33:54,720
whole bunch of diagnostic plots that you

904
00:33:54,720 --> 00:33:56,100
can do which are pretty straightforward

905
00:33:56,100 --> 00:33:58,740
to follow but uh I'm running out of time

906
00:33:58,740 --> 00:34:00,419
so I'll pass the button over to Russell

907
00:34:00,419 --> 00:34:01,500
again

908
00:34:01,500 --> 00:34:06,419
so a huge lesson that we learned through

909
00:34:06,419 --> 00:34:08,399
our experience in modeling the iterative

910
00:34:08,399 --> 00:34:10,199
process of looking at the data

911
00:34:10,199 --> 00:34:11,879
generating the model looking at the

912
00:34:11,879 --> 00:34:15,179
output is our definition of tail risk

913
00:34:15,179 --> 00:34:18,839
what drives that curve whether it's in

914
00:34:18,839 --> 00:34:20,760
the critical area or not so critical

915
00:34:20,760 --> 00:34:24,300
area is threat actor capabilities

916
00:34:24,300 --> 00:34:27,119
so I want to give you a window into into

917
00:34:27,119 --> 00:34:29,879
this process and how we arrive there and

918
00:34:29,879 --> 00:34:32,099
one critical factor in this tail risk is

919
00:34:32,099 --> 00:34:34,918
what is the addressable population for

920
00:34:34,918 --> 00:34:36,060
any attack

921
00:34:36,060 --> 00:34:38,460
so the addressable population for the

922
00:34:38,460 --> 00:34:40,679
not Petty attack was huge because it was

923
00:34:40,679 --> 00:34:45,960
a wormable uh Windows vulnerability and

924
00:34:45,960 --> 00:34:50,359
therefore it could spread very widely

925
00:34:51,060 --> 00:34:53,579
so what factors determine that

926
00:34:53,579 --> 00:34:55,619
addressable population

927
00:34:55,619 --> 00:34:58,200
so obviously attack a strategy exploit

928
00:34:58,200 --> 00:35:00,780
capability products they're going after

929
00:35:00,780 --> 00:35:03,599
and their coverage in the population

930
00:35:03,599 --> 00:35:04,859
uh

931
00:35:04,859 --> 00:35:06,599
and I'm going to skip to the bottom

932
00:35:06,599 --> 00:35:09,599
which are interdependencies between

933
00:35:09,599 --> 00:35:12,000
vulnerabilities if they exploit multiple

934
00:35:12,000 --> 00:35:13,380
vulnerabilities

935
00:35:13,380 --> 00:35:16,740
a given attack May exploit two three

936
00:35:16,740 --> 00:35:19,700
five maybe even more vulnerabilities

937
00:35:19,700 --> 00:35:22,560
conditional on the victim that they run

938
00:35:22,560 --> 00:35:25,880
into if those relationships are or

939
00:35:25,880 --> 00:35:29,160
logical relationships that expands their

940
00:35:29,160 --> 00:35:32,160
Market gives them options but if those

941
00:35:32,160 --> 00:35:34,740
are and relationships those are points

942
00:35:34,740 --> 00:35:37,320
of failure because if any vulnerability

943
00:35:37,320 --> 00:35:39,780
any exploit in that sequence of ands

944
00:35:39,780 --> 00:35:43,560
fails the whole sequence fails so we

945
00:35:43,560 --> 00:35:45,119
believe that attackers when they're

946
00:35:45,119 --> 00:35:47,339
defining their attack strategy either by

947
00:35:47,339 --> 00:35:51,079
conscious planning or by experience

948
00:35:51,079 --> 00:35:53,460
essentially assemble their attack

949
00:35:53,460 --> 00:35:55,800
strategy to try to come up with an

950
00:35:55,800 --> 00:35:58,020
addressable population which fits their

951
00:35:58,020 --> 00:36:01,560
goals and their capabilities

952
00:36:01,560 --> 00:36:05,339
so what one lens on this is the initial

953
00:36:05,339 --> 00:36:08,820
access Vector of worms so here we've

954
00:36:08,820 --> 00:36:12,540
modeled just the behavior of worms uh

955
00:36:12,540 --> 00:36:14,160
and What proportion of the population

956
00:36:14,160 --> 00:36:17,520
that they would be able to access

957
00:36:17,520 --> 00:36:19,859
and you can see in and this is an

958
00:36:19,859 --> 00:36:22,440
example of a sub analysis within our

959
00:36:22,440 --> 00:36:24,119
broader simulation

960
00:36:24,119 --> 00:36:26,520
you can see the vast majority of worms

961
00:36:26,520 --> 00:36:30,540
are down in the 20 range

962
00:36:30,540 --> 00:36:33,540
so what's interesting is this range

963
00:36:33,540 --> 00:36:36,720
above 50 percent this is the worst case

964
00:36:36,720 --> 00:36:38,280
of the worst case

965
00:36:38,280 --> 00:36:40,859
and this slide here it's a bit of an eye

966
00:36:40,859 --> 00:36:43,980
chart but this is a diagnostic output

967
00:36:43,980 --> 00:36:46,619
from our simulation where we look at in

968
00:36:46,619 --> 00:36:49,800
detail the characteristics of these

969
00:36:49,800 --> 00:36:52,800
simulated attacks in the far part of the

970
00:36:52,800 --> 00:36:54,060
tail

971
00:36:54,060 --> 00:36:57,359
so we went in and estimated well how

972
00:36:57,359 --> 00:37:00,540
prevalent are multiple uh

973
00:37:00,540 --> 00:37:03,320
vulnerabilities cross OS vulnerabilities

974
00:37:03,320 --> 00:37:06,660
uh are they wormable or not and we

975
00:37:06,660 --> 00:37:08,880
created our own simulated world of these

976
00:37:08,880 --> 00:37:12,180
and this helps us evaluate

977
00:37:12,180 --> 00:37:14,579
are these assumptions realistic does

978
00:37:14,579 --> 00:37:17,400
this correspond to what anybody is has

979
00:37:17,400 --> 00:37:19,380
said from an expert opinion and we can

980
00:37:19,380 --> 00:37:22,640
go back and refine that

981
00:37:22,920 --> 00:37:25,440
so I'm not going to read all of these

982
00:37:25,440 --> 00:37:29,460
points but this iterative process about

983
00:37:29,460 --> 00:37:31,980
well how bad can things get what does it

984
00:37:31,980 --> 00:37:35,160
take for an attacker to really attack a

985
00:37:35,160 --> 00:37:37,680
very high portion of the population led

986
00:37:37,680 --> 00:37:40,560
us to not only produce the quantitative

987
00:37:40,560 --> 00:37:43,380
output but the reasoning behind why this

988
00:37:43,380 --> 00:37:46,560
is relatively rare more rare than than

989
00:37:46,560 --> 00:37:51,359
some Cassandra's might be claiming

990
00:37:51,359 --> 00:37:53,579
cool so um

991
00:37:53,579 --> 00:37:55,740
almost wrapped up um we thought you know

992
00:37:55,740 --> 00:37:57,240
we've been speaking about Doom and Gloom

993
00:37:57,240 --> 00:37:58,859
so we thought we'd share what some of

994
00:37:58,859 --> 00:38:00,599
the output of our modeling is in terms

995
00:38:00,599 --> 00:38:03,660
of how bad can bad be so we can ask the

996
00:38:03,660 --> 00:38:05,220
question of our model

997
00:38:05,220 --> 00:38:06,180
you know

998
00:38:06,180 --> 00:38:08,160
what are the characteristics of the most

999
00:38:08,160 --> 00:38:10,020
rare and broadly hitting events so here

1000
00:38:10,020 --> 00:38:11,400
we're talking about stuff that we think

1001
00:38:11,400 --> 00:38:13,260
it has a less than a one percent chance

1002
00:38:13,260 --> 00:38:15,300
of happening next year you could also

1003
00:38:15,300 --> 00:38:16,500
say that's less than a one in a hundred

1004
00:38:16,500 --> 00:38:18,420
chance of happening next year so our

1005
00:38:18,420 --> 00:38:21,079
model suggests that about

1006
00:38:21,079 --> 00:38:25,380
9.4 or greater firms are likely to

1007
00:38:25,380 --> 00:38:27,000
experience an incident from a common

1008
00:38:27,000 --> 00:38:28,500
cause this is sort of in the realm of

1009
00:38:28,500 --> 00:38:30,480
our worst case and we think this is most

1010
00:38:30,480 --> 00:38:32,160
likely to be driven by worms there's

1011
00:38:32,160 --> 00:38:34,740
also a chance of supply chain attacks on

1012
00:38:34,740 --> 00:38:38,880
very very large vendors and we think the

1013
00:38:38,880 --> 00:38:41,400
uh the payload is very likely to be

1014
00:38:41,400 --> 00:38:42,960
wipers

1015
00:38:42,960 --> 00:38:45,420
partly because of the the threat Act of

1016
00:38:45,420 --> 00:38:46,980
motivation you know on the on the

1017
00:38:46,980 --> 00:38:50,040
state-sponsored side but also because

1018
00:38:50,040 --> 00:38:53,520
ransomware attacks typically have

1019
00:38:53,520 --> 00:38:55,079
on the sort of business side for the

1020
00:38:55,079 --> 00:38:56,460
threat actors they need to process a

1021
00:38:56,460 --> 00:38:59,040
large number of of transactions whilst a

1022
00:38:59,040 --> 00:39:00,420
wiper it's possible for you to just drop

1023
00:39:00,420 --> 00:39:02,099
it and walk away

1024
00:39:02,099 --> 00:39:03,480
um

1025
00:39:03,480 --> 00:39:06,660
and over back onto Russell last point so

1026
00:39:06,660 --> 00:39:08,579
I've been in this business for quite a

1027
00:39:08,579 --> 00:39:10,700
while

1028
00:39:10,820 --> 00:39:12,420
2007

1029
00:39:12,420 --> 00:39:16,140
I presented to uh angel investor group

1030
00:39:16,140 --> 00:39:17,460
incubator

1031
00:39:17,460 --> 00:39:20,940
with a bright idea of a research agenda

1032
00:39:20,940 --> 00:39:23,640
investment opportunity for quantifying

1033
00:39:23,640 --> 00:39:26,579
information security risk and making it

1034
00:39:26,579 --> 00:39:29,880
financially material to executives

1035
00:39:29,880 --> 00:39:34,640
and I got blank stares and polite

1036
00:39:34,640 --> 00:39:37,680
nods and then I invited myself back

1037
00:39:37,680 --> 00:39:39,060
again I said I want to give another

1038
00:39:39,060 --> 00:39:41,339
presentation because I want to get

1039
00:39:41,339 --> 00:39:43,619
something going and they said uh I think

1040
00:39:43,619 --> 00:39:46,680
our calendar is full here

1041
00:39:46,680 --> 00:39:49,440
um but I kept going and I know people in

1042
00:39:49,440 --> 00:39:51,180
this room and people in the audience

1043
00:39:51,180 --> 00:39:53,579
watching on YouTube have been on this

1044
00:39:53,579 --> 00:39:57,380
journey for a similar time periods

1045
00:39:57,680 --> 00:40:01,380
2022 is a different time uh we wanted to

1046
00:40:01,380 --> 00:40:03,359
have a whole bunch of corporate logos

1047
00:40:03,359 --> 00:40:05,760
and organization logos of all the people

1048
00:40:05,760 --> 00:40:08,460
participating in this world now some of

1049
00:40:08,460 --> 00:40:11,280
the people here in this room uh

1050
00:40:11,280 --> 00:40:13,260
I kind of feel like we're in a golden

1051
00:40:13,260 --> 00:40:16,079
age of risk quantification and

1052
00:40:16,079 --> 00:40:18,300
information security

1053
00:40:18,300 --> 00:40:20,700
there are so many more participants now

1054
00:40:20,700 --> 00:40:23,640
there are so many more good platforms

1055
00:40:23,640 --> 00:40:26,520
and initiatives academic conferences and

1056
00:40:26,520 --> 00:40:28,859
resources

1057
00:40:28,859 --> 00:40:31,319
so if anybody is interested in getting

1058
00:40:31,319 --> 00:40:33,660
involved with this for a start be happy

1059
00:40:33,660 --> 00:40:36,780
to talk with you uh if anybody's in it

1060
00:40:36,780 --> 00:40:39,359
been in it for a while and you want to

1061
00:40:39,359 --> 00:40:42,000
up your game or get more involved be

1062
00:40:42,000 --> 00:40:45,480
happy to talk last but not least this

1063
00:40:45,480 --> 00:40:49,619
event in the ground Truth uh track is

1064
00:40:49,619 --> 00:40:51,660
evidence of how far this community has

1065
00:40:51,660 --> 00:40:55,619
come in the past 15 or so years

1066
00:40:55,619 --> 00:41:00,300
so I uh told my UK colleague Chris that

1067
00:41:00,300 --> 00:41:04,680
the American audience was very active in

1068
00:41:04,680 --> 00:41:07,020
asking questions and engaging in

1069
00:41:07,020 --> 00:41:09,480
conversation so now is your opportunity

1070
00:41:09,480 --> 00:41:11,640
to do this as we get to our microphone

1071
00:41:11,640 --> 00:41:14,060
setup

1072
00:41:28,140 --> 00:41:30,240
hello Russ be close

1073
00:41:30,240 --> 00:41:34,260
hello Russ hi I I presume that that uh

1074
00:41:34,260 --> 00:41:37,140
slide at the beginning with your

1075
00:41:37,140 --> 00:41:39,960
modeling risk has a little closer as a

1076
00:41:39,960 --> 00:41:43,440
result of impact times probability was

1077
00:41:43,440 --> 00:41:45,839
just a straw man argument that you threw

1078
00:41:45,839 --> 00:41:48,180
out with the rest of your sides which

1079
00:41:48,180 --> 00:41:50,819
didn't back up that approach or am I

1080
00:41:50,819 --> 00:41:52,619
completely misreading what you guys have

1081
00:41:52,619 --> 00:41:55,140
done here because it doesn't thankfully

1082
00:41:55,140 --> 00:41:56,819
it doesn't seem like you've gone through

1083
00:41:56,819 --> 00:41:59,819
that dark Road into multiplying apples

1084
00:41:59,819 --> 00:42:02,460
to times oranges and you might want to

1085
00:42:02,460 --> 00:42:05,760
educate everybody on exactly uh the how

1086
00:42:05,760 --> 00:42:09,240
you are modeling risk there uh thank you

1087
00:42:09,240 --> 00:42:11,099
for that question uh so if everybody

1088
00:42:11,099 --> 00:42:13,619
understood it he he's saying we

1089
00:42:13,619 --> 00:42:16,079
introduced one of the early slides risk

1090
00:42:16,079 --> 00:42:18,740
is likelihood times impact or severity

1091
00:42:18,740 --> 00:42:21,720
and that seemed in contrast to the rest

1092
00:42:21,720 --> 00:42:23,220
of things we're doing

1093
00:42:23,220 --> 00:42:24,359
so

1094
00:42:24,359 --> 00:42:28,800
in the early 2000s

1095
00:42:28,800 --> 00:42:31,260
there was a lot of

1096
00:42:31,260 --> 00:42:32,280
um

1097
00:42:32,280 --> 00:42:35,760
I will say expert commentary

1098
00:42:35,760 --> 00:42:38,640
driving people to do quantitative risk

1099
00:42:38,640 --> 00:42:41,940
modeling using that simplistic formula

1100
00:42:41,940 --> 00:42:43,859
alone

1101
00:42:43,859 --> 00:42:45,960
and trying to get you to think about

1102
00:42:45,960 --> 00:42:48,480
every single asset and every single

1103
00:42:48,480 --> 00:42:51,180
vulnerability and applying that formula

1104
00:42:51,180 --> 00:42:53,700
to every single one

1105
00:42:53,700 --> 00:42:56,880
uh I was once at a conference where a

1106
00:42:56,880 --> 00:42:59,579
high-level person at a bank told a war

1107
00:42:59,579 --> 00:43:02,339
story of taking his team through such an

1108
00:43:02,339 --> 00:43:04,260
exercise

1109
00:43:04,260 --> 00:43:06,420
and after two weeks gave up in

1110
00:43:06,420 --> 00:43:09,240
exhaustion so they had carte blanche to

1111
00:43:09,240 --> 00:43:11,400
work on this until they got it done for

1112
00:43:11,400 --> 00:43:13,859
some Board review and they gave up

1113
00:43:13,859 --> 00:43:16,560
the trouble with that is it makes sense

1114
00:43:16,560 --> 00:43:18,540
at a conceptual level

1115
00:43:18,540 --> 00:43:21,020
so at a very broad definitional level

1116
00:43:21,020 --> 00:43:24,240
the definitions are consistent but how

1117
00:43:24,240 --> 00:43:26,880
you get there is crucial

1118
00:43:26,880 --> 00:43:29,460
and it's not the same

1119
00:43:29,460 --> 00:43:31,800
you know our whole presentation about

1120
00:43:31,800 --> 00:43:35,339
causal modeling and getting to the

1121
00:43:35,339 --> 00:43:37,020
probability of certain events happening

1122
00:43:37,020 --> 00:43:40,160
in their conditional severity

1123
00:43:40,160 --> 00:43:43,940
is we think we're arguing is a viable

1124
00:43:43,940 --> 00:43:47,520
supportable path to getting to that uh

1125
00:43:47,520 --> 00:43:50,420
risk definition

1126
00:43:52,079 --> 00:43:55,859
so closer closer so

1127
00:43:55,859 --> 00:43:56,460
um

1128
00:43:56,460 --> 00:43:58,200
there are lots of domains that are

1129
00:43:58,200 --> 00:44:01,260
modeling risk uh as you mentioned

1130
00:44:01,260 --> 00:44:03,599
earlier like finance and floods and et

1131
00:44:03,599 --> 00:44:05,700
cetera et cetera

1132
00:44:05,700 --> 00:44:06,599
um

1133
00:44:06,599 --> 00:44:09,240
are there similar uh approaches to

1134
00:44:09,240 --> 00:44:11,700
causal modeling in all of those domains

1135
00:44:11,700 --> 00:44:13,200
and is there a common methodology

1136
00:44:13,200 --> 00:44:15,980
between them

1137
00:44:16,319 --> 00:44:18,420
yeah I can try and talk to that a bit um

1138
00:44:18,420 --> 00:44:23,040
so I think there are certainly overlaps

1139
00:44:23,040 --> 00:44:25,380
um in that

1140
00:44:25,380 --> 00:44:28,619
the process of trying to

1141
00:44:28,619 --> 00:44:31,619
create a broad range or a broad catalog

1142
00:44:31,619 --> 00:44:33,540
of scenarios of bad things that could

1143
00:44:33,540 --> 00:44:36,119
happen and Associated likelihoods I

1144
00:44:36,119 --> 00:44:37,680
think is common across the board we

1145
00:44:37,680 --> 00:44:39,420
described you know our methodology here

1146
00:44:39,420 --> 00:44:40,980
for something like a hurricane model

1147
00:44:40,980 --> 00:44:44,280
what they do is they have a model that

1148
00:44:44,280 --> 00:44:46,680
spawns low pressure systems inside of

1149
00:44:46,680 --> 00:44:47,880
the North Atlantic and kind of track

1150
00:44:47,880 --> 00:44:50,640
tracks how they you know intensify for

1151
00:44:50,640 --> 00:44:53,040
earthquakes you know they have

1152
00:44:53,040 --> 00:44:54,240
um

1153
00:44:54,240 --> 00:44:56,099
models on you know for different fault

1154
00:44:56,099 --> 00:44:57,720
probabilities and these sorts of things

1155
00:44:57,720 --> 00:45:00,599
so there's I think at a very high level

1156
00:45:00,599 --> 00:45:02,579
you know this notion of having a catalog

1157
00:45:02,579 --> 00:45:04,380
of bad things that can happen and then

1158
00:45:04,380 --> 00:45:07,380
you combine that with the economy or an

1159
00:45:07,380 --> 00:45:09,780
insurance portfolio to see uh how it

1160
00:45:09,780 --> 00:45:11,819
comes out however of course you know in

1161
00:45:11,819 --> 00:45:13,440
the context of cyber what is very

1162
00:45:13,440 --> 00:45:15,300
different is where you've got the human

1163
00:45:15,300 --> 00:45:17,880
decision-making angle right we often

1164
00:45:17,880 --> 00:45:19,140
talk about how you know you could build

1165
00:45:19,140 --> 00:45:21,480
the most perfect synthetic world of

1166
00:45:21,480 --> 00:45:24,180
vulnerabilities and you know software

1167
00:45:24,180 --> 00:45:27,000
Etc but your assumptions about how

1168
00:45:27,000 --> 00:45:29,400
threat actors make decisions ultimately

1169
00:45:29,400 --> 00:45:31,319
is going to be what's driving you know

1170
00:45:31,319 --> 00:45:32,819
the likelihood of really bad things

1171
00:45:32,819 --> 00:45:35,160
happening so I think there are certainly

1172
00:45:35,160 --> 00:45:37,740
areas of commonality but having a

1173
00:45:37,740 --> 00:45:40,260
man-made risk I think adds an additional

1174
00:45:40,260 --> 00:45:43,680
level of uncertainty that is perhaps not

1175
00:45:43,680 --> 00:45:46,260
in place for those natural catastrophe

1176
00:45:46,260 --> 00:45:49,859
models anything else yeah uh terrorism

1177
00:45:49,859 --> 00:45:52,079
risk modeling which is something that

1178
00:45:52,079 --> 00:45:55,500
RMS does is the closest analog uh and

1179
00:45:55,500 --> 00:45:57,000
they use similar approaches not

1180
00:45:57,000 --> 00:46:00,079
identical but similar

1181
00:46:02,819 --> 00:46:04,980
hi there I work for a very small

1182
00:46:04,980 --> 00:46:08,579
precious startup and I would I'm in QA

1183
00:46:08,579 --> 00:46:10,200
I'm the closest thing they have to

1184
00:46:10,200 --> 00:46:14,220
security how do I get my very small very

1185
00:46:14,220 --> 00:46:16,319
new to the startup World very literally

1186
00:46:16,319 --> 00:46:18,240
young engineering team

1187
00:46:18,240 --> 00:46:21,200
thinking about these sort of War games

1188
00:46:21,200 --> 00:46:23,520
these possible things that could happen

1189
00:46:23,520 --> 00:46:26,520
how do we react to them without scaring

1190
00:46:26,520 --> 00:46:29,839
the pants off of them

1191
00:46:30,720 --> 00:46:35,040
that is a courageous huge incredibly

1192
00:46:35,040 --> 00:46:38,420
important question and Challenge and

1193
00:46:38,420 --> 00:46:41,400
anybody in this room who claims they

1194
00:46:41,400 --> 00:46:43,859
know the answer to that or there's a

1195
00:46:43,859 --> 00:46:45,780
foolproof path

1196
00:46:45,780 --> 00:46:47,819
I think you're kidding yourself so

1197
00:46:47,819 --> 00:46:50,339
everybody who Encounters this I mean

1198
00:46:50,339 --> 00:46:51,540
this is one of the most challenging

1199
00:46:51,540 --> 00:46:54,000
things in the whole security world and

1200
00:46:54,000 --> 00:46:55,260
Quant risk

1201
00:46:55,260 --> 00:46:57,359
so I'm I'm going to give a try to answer

1202
00:46:57,359 --> 00:46:59,819
but so it's such a big question it

1203
00:46:59,819 --> 00:47:03,240
deserves more time I invite you to join

1204
00:47:03,240 --> 00:47:06,900
the Society of information risk analysts

1205
00:47:06,900 --> 00:47:09,119
because I assume that you are interested

1206
00:47:09,119 --> 00:47:11,579
in a quantitative risk approach to this

1207
00:47:11,579 --> 00:47:15,599
question as opposed to hand waving or

1208
00:47:15,599 --> 00:47:19,260
framework bashing or please no jargon

1209
00:47:19,260 --> 00:47:22,920
hurling approaches okay Society of

1210
00:47:22,920 --> 00:47:25,859
information risk analysts is a community

1211
00:47:25,859 --> 00:47:28,559
of people pretty Grassroots and there's

1212
00:47:28,559 --> 00:47:31,099
lots of people and resources

1213
00:47:31,099 --> 00:47:34,380
who can you can connect to that will

1214
00:47:34,380 --> 00:47:36,300
help break that down and give you tools

1215
00:47:36,300 --> 00:47:40,760
to make progress on it awesome thank you

1216
00:47:43,200 --> 00:47:46,680
uh thank you for the presentation so

1217
00:47:46,680 --> 00:47:48,599
um you were mostly it looks like looking

1218
00:47:48,599 --> 00:47:49,500
at

1219
00:47:49,500 --> 00:47:51,540
um sort of a large population from the

1220
00:47:51,540 --> 00:47:53,339
perspective that insurers and things

1221
00:47:53,339 --> 00:47:57,000
like that uh I'm wondering if you've uh

1222
00:47:57,000 --> 00:47:58,800
had any experience with how well this

1223
00:47:58,800 --> 00:48:01,440
kind of causal modeling uh would or

1224
00:48:01,440 --> 00:48:03,359
wouldn't work for a company trying to

1225
00:48:03,359 --> 00:48:06,119
predict uh catastrophic events happening

1226
00:48:06,119 --> 00:48:08,819
specifically to them uh for instance to

1227
00:48:08,819 --> 00:48:10,980
decide whether or not to invest in some

1228
00:48:10,980 --> 00:48:13,619
sort of barrier to like or how much how

1229
00:48:13,619 --> 00:48:14,700
much they should be paying for insurance

1230
00:48:14,700 --> 00:48:16,020
things like that

1231
00:48:16,020 --> 00:48:18,660
very good question very forward-looking

1232
00:48:18,660 --> 00:48:21,599
because that's the next logical well I

1233
00:48:21,599 --> 00:48:23,760
won't say the next it is a logical

1234
00:48:23,760 --> 00:48:25,260
progression

1235
00:48:25,260 --> 00:48:28,200
for firms like ourselves and models like

1236
00:48:28,200 --> 00:48:29,400
this

1237
00:48:29,400 --> 00:48:31,440
uh

1238
00:48:31,440 --> 00:48:34,440
I will say the

1239
00:48:34,440 --> 00:48:36,780
transition between population

1240
00:48:36,780 --> 00:48:40,559
perspective and a firm specific or even

1241
00:48:40,559 --> 00:48:42,900
a value chain which is sort of an

1242
00:48:42,900 --> 00:48:44,520
in-between thing

1243
00:48:44,520 --> 00:48:47,760
is tricky from a technical an Evidence

1244
00:48:47,760 --> 00:48:51,140
how much granularity you notice in here

1245
00:48:51,140 --> 00:48:54,780
we abstract attacks into two two phases

1246
00:48:54,780 --> 00:48:57,599
initial access and everything else

1247
00:48:57,599 --> 00:49:00,240
firms care a lot about that everything

1248
00:49:00,240 --> 00:49:02,880
else that's the whole elevation of

1249
00:49:02,880 --> 00:49:05,040
privilege and horizontal movement and

1250
00:49:05,040 --> 00:49:09,259
partitioning your networks and so on

1251
00:49:09,839 --> 00:49:11,819
I would be very interested in talking to

1252
00:49:11,819 --> 00:49:15,720
anybody who's interested in that path uh

1253
00:49:15,720 --> 00:49:18,420
official announcement RMS has been

1254
00:49:18,420 --> 00:49:21,180
purchased by Moody's Analytics Moody's

1255
00:49:21,180 --> 00:49:24,540
Analytics is a famous publicly held

1256
00:49:24,540 --> 00:49:27,180
company modeling risk across a broad

1257
00:49:27,180 --> 00:49:29,280
portfolio and I know that they're

1258
00:49:29,280 --> 00:49:32,099
interested in this topic I will

1259
00:49:32,099 --> 00:49:33,180
definitely come and talk to you about

1260
00:49:33,180 --> 00:49:36,020
that afterwards thank you

1261
00:49:36,300 --> 00:49:37,920
hello thanks for the talk it was really

1262
00:49:37,920 --> 00:49:39,059
interesting

1263
00:49:39,059 --> 00:49:40,440
um you talked a lot about external

1264
00:49:40,440 --> 00:49:41,700
threat actors and I was just wondering

1265
00:49:41,700 --> 00:49:44,819
how do you quantify Insider attacks

1266
00:49:44,819 --> 00:49:46,500
um the likelihood and impact given that

1267
00:49:46,500 --> 00:49:48,359
the initial access is kind of taken care

1268
00:49:48,359 --> 00:49:50,940
of so the question is about Insider

1269
00:49:50,940 --> 00:49:53,400
attacks as threat actors

1270
00:49:53,400 --> 00:49:56,339
uh our current model does not include

1271
00:49:56,339 --> 00:49:59,940
Insider attacks uh maybe Chris can

1272
00:49:59,940 --> 00:50:01,559
comment it's my understanding that

1273
00:50:01,559 --> 00:50:04,140
Insider attacks are not normally covered

1274
00:50:04,140 --> 00:50:08,700
as part of normal cyber insurance

1275
00:50:08,700 --> 00:50:11,280
uh I mean that may that may well varied

1276
00:50:11,280 --> 00:50:13,619
from company to company but so what we

1277
00:50:13,619 --> 00:50:15,000
described just throughout this

1278
00:50:15,000 --> 00:50:16,859
presentation is our framework for trying

1279
00:50:16,859 --> 00:50:19,800
to quantify catastrophic cyber risk

1280
00:50:19,800 --> 00:50:22,559
right so it's our assessment that

1281
00:50:22,559 --> 00:50:24,780
although inside a threat is definitely a

1282
00:50:24,780 --> 00:50:27,180
big thing the likelihood of you know

1283
00:50:27,180 --> 00:50:30,000
armies of people simultaneously deciding

1284
00:50:30,000 --> 00:50:31,920
to you know take up the mantle against

1285
00:50:31,920 --> 00:50:34,800
their corporate oppressors uh is

1286
00:50:34,800 --> 00:50:37,559
extremely unlikely and that you know the

1287
00:50:37,559 --> 00:50:38,819
source of attacks that we're trying to

1288
00:50:38,819 --> 00:50:41,099
model here around big supply chain

1289
00:50:41,099 --> 00:50:44,160
attacks worms from malicious external

1290
00:50:44,160 --> 00:50:45,420
threat groups are likely to be the

1291
00:50:45,420 --> 00:50:46,980
drivers of things that's not to say that

1292
00:50:46,980 --> 00:50:50,880
we don't consider internal uh

1293
00:50:50,880 --> 00:50:54,960
uh Insider threat implicitly I mentioned

1294
00:50:54,960 --> 00:50:56,339
earlier on you know we have the this

1295
00:50:56,339 --> 00:50:57,720
kind of notion of a statistical model

1296
00:50:57,720 --> 00:50:59,040
where you have the likel of certain

1297
00:50:59,040 --> 00:51:01,319
things happening we actually model the

1298
00:51:01,319 --> 00:51:03,599
attritional risk uh through that sort of

1299
00:51:03,599 --> 00:51:05,099
method so we have quite a lot of data to

1300
00:51:05,099 --> 00:51:06,540
see that you know these sorts of attacks

1301
00:51:06,540 --> 00:51:08,819
do happen so inside of our model we sort

1302
00:51:08,819 --> 00:51:10,559
of are implicitly capturing this but

1303
00:51:10,559 --> 00:51:12,300
we're not you know Express you know

1304
00:51:12,300 --> 00:51:16,339
we're not calling it out uh so so

1305
00:51:16,940 --> 00:51:20,700
in principle we could add insiders as a

1306
00:51:20,700 --> 00:51:23,040
new attack category and I don't think

1307
00:51:23,040 --> 00:51:25,380
really anything in our framework would

1308
00:51:25,380 --> 00:51:28,280
fundamentally change we'd have to add

1309
00:51:28,280 --> 00:51:30,900
ttps that are appropriate to insiders

1310
00:51:30,900 --> 00:51:33,960
and so forth and but as Chris said it

1311
00:51:33,960 --> 00:51:35,460
probably wouldn't affect our overall

1312
00:51:35,460 --> 00:51:36,839
model output

1313
00:51:36,839 --> 00:51:38,480
now I will say

1314
00:51:38,480 --> 00:51:41,460
uh my own personal opinion to getting

1315
00:51:41,460 --> 00:51:43,260
back to this gentleman's question about

1316
00:51:43,260 --> 00:51:45,300
Enterprise level

1317
00:51:45,300 --> 00:51:48,300
I think potentially one of the most

1318
00:51:48,300 --> 00:51:50,700
catastrophic types of attacks for an

1319
00:51:50,700 --> 00:51:53,640
Enterprise would be executive level

1320
00:51:53,640 --> 00:51:55,559
Insider attack

1321
00:51:55,559 --> 00:51:57,540
Executives who have enough technical

1322
00:51:57,540 --> 00:52:00,599
Savvy to go back and change your

1323
00:52:00,599 --> 00:52:03,119
financial systems right so think of

1324
00:52:03,119 --> 00:52:06,420
Worldcom type scandals and so forth

1325
00:52:06,420 --> 00:52:09,420
uh if I were an Enterprise risk manager

1326
00:52:09,420 --> 00:52:13,559
I would have executive or privileged

1327
00:52:13,559 --> 00:52:16,500
access that causes major financial fraud

1328
00:52:16,500 --> 00:52:19,640
in your threat model

1329
00:52:21,900 --> 00:52:25,980
hi Steph I'm from STX I have a question

1330
00:52:25,980 --> 00:52:27,900
so we have create models in the past

1331
00:52:27,900 --> 00:52:30,480
like for hurricanes stock strong wind

1332
00:52:30,480 --> 00:52:31,559
and everything

1333
00:52:31,559 --> 00:52:34,140
with lots of experience this is all

1334
00:52:34,140 --> 00:52:36,660
natural science you can do controlled

1335
00:52:36,660 --> 00:52:38,700
experiments and so now with cyber we are

1336
00:52:38,700 --> 00:52:40,500
more in social science the environment

1337
00:52:40,500 --> 00:52:44,280
changes permanently now we know quoting

1338
00:52:44,280 --> 00:52:46,859
Nasim Talib the bigger the risk or the

1339
00:52:46,859 --> 00:52:48,740
bigger the event the less we have a clue

1340
00:52:48,740 --> 00:52:51,540
where or how do you draw the boundary

1341
00:52:51,540 --> 00:52:54,839
between stuff we can model and stuff we

1342
00:52:54,839 --> 00:52:58,140
fundamentally cannot model

1343
00:52:58,140 --> 00:53:00,480
uh so I'll give us both a chance to

1344
00:53:00,480 --> 00:53:02,220
answer this Chris can think about it

1345
00:53:02,220 --> 00:53:05,579
while I'm babbling on uh you've raised a

1346
00:53:05,579 --> 00:53:07,440
crucial point so I mentioned at the

1347
00:53:07,440 --> 00:53:09,660
start that my PhD work was in

1348
00:53:09,660 --> 00:53:13,079
computational social science

1349
00:53:13,079 --> 00:53:16,440
social science is a very broad loose not

1350
00:53:16,440 --> 00:53:19,020
tightly integrated set of theories and

1351
00:53:19,020 --> 00:53:21,240
methods compared to physics for example

1352
00:53:21,240 --> 00:53:23,059
or chemistry

1353
00:53:23,059 --> 00:53:25,980
but there is a lot of

1354
00:53:25,980 --> 00:53:28,500
things to draw on so I mentioned in the

1355
00:53:28,500 --> 00:53:31,500
model of threat actor decision making

1356
00:53:31,500 --> 00:53:35,040
that draws upon consumer Choice firm

1357
00:53:35,040 --> 00:53:36,680
investment

1358
00:53:36,680 --> 00:53:40,079
so-called maximization of subjective

1359
00:53:40,079 --> 00:53:43,859
expected utility and so forth so we can

1360
00:53:43,859 --> 00:53:46,500
apply these especially in narrow

1361
00:53:46,500 --> 00:53:47,940
contexts

1362
00:53:47,940 --> 00:53:49,859
Define a context of certain human

1363
00:53:49,859 --> 00:53:52,680
behavior for example peer influence to

1364
00:53:52,680 --> 00:53:54,780
what extent do threat actors think

1365
00:53:54,780 --> 00:53:56,940
through their own

1366
00:53:56,940 --> 00:54:00,240
Roi versus they just follow the crowd or

1367
00:54:00,240 --> 00:54:02,160
they've they follow on the habits of

1368
00:54:02,160 --> 00:54:03,000
what

1369
00:54:03,000 --> 00:54:05,760
somebody else does or they acquire a

1370
00:54:05,760 --> 00:54:08,160
tool set from the dark web and start

1371
00:54:08,160 --> 00:54:10,260
trying it until it doesn't work and they

1372
00:54:10,260 --> 00:54:12,720
do something else so there's a fairly

1373
00:54:12,720 --> 00:54:15,480
good body of knowledge and methods and

1374
00:54:15,480 --> 00:54:19,200
Theory to inform that now the trick is

1375
00:54:19,200 --> 00:54:21,300
as you said before and this is a matter

1376
00:54:21,300 --> 00:54:24,599
of expert professional Judgment at what

1377
00:54:24,599 --> 00:54:26,940
level do we apply this how granular do

1378
00:54:26,940 --> 00:54:29,339
we get is it better just to treat this

1379
00:54:29,339 --> 00:54:32,400
as a you know random dice throwing

1380
00:54:32,400 --> 00:54:34,260
because we don't know a lot of details

1381
00:54:34,260 --> 00:54:36,839
and there's so much uncertainty or can

1382
00:54:36,839 --> 00:54:39,420
we treat it as you know a rational

1383
00:54:39,420 --> 00:54:41,700
decision-making process where the agents

1384
00:54:41,700 --> 00:54:43,920
have a lot of information and they might

1385
00:54:43,920 --> 00:54:47,339
even make strategic choices in a game

1386
00:54:47,339 --> 00:54:49,079
theory sense I'm going to trick my

1387
00:54:49,079 --> 00:54:51,059
opponent and I'm going to fake this and

1388
00:54:51,059 --> 00:54:53,819
do that so uh

1389
00:54:53,819 --> 00:54:56,160
it's my answer Chris yeah

1390
00:54:56,160 --> 00:54:58,020
yeah I guess my I'll just give some

1391
00:54:58,020 --> 00:55:00,119
maybe a slightly broader comments which

1392
00:55:00,119 --> 00:55:03,559
I think that ultimately

1393
00:55:03,599 --> 00:55:06,119
however good your model is there needs

1394
00:55:06,119 --> 00:55:09,839
to be an acknowledgment I think of

1395
00:55:09,839 --> 00:55:13,380
the uncertainty in this field is likely

1396
00:55:13,380 --> 00:55:15,359
to always be greater than in the context

1397
00:55:15,359 --> 00:55:16,980
of a hurricane for example for many

1398
00:55:16,980 --> 00:55:18,059
reasons as we mentioned you know you've

1399
00:55:18,059 --> 00:55:19,799
got the whole human decision-making side

1400
00:55:19,799 --> 00:55:23,040
of things the threat landscape changing

1401
00:55:23,040 --> 00:55:25,740
far quicker than you know

1402
00:55:25,740 --> 00:55:27,420
than climate change is changing

1403
00:55:27,420 --> 00:55:29,640
hurricanes for example and then you've

1404
00:55:29,640 --> 00:55:31,140
also got I think the observability

1405
00:55:31,140 --> 00:55:33,059
challenge you know with a hurricane you

1406
00:55:33,059 --> 00:55:34,980
know you can use satellite imagery and

1407
00:55:34,980 --> 00:55:37,319
you know ground anemometers to measure

1408
00:55:37,319 --> 00:55:38,940
the wind speed to make sure that your

1409
00:55:38,940 --> 00:55:41,880
model is producing realistic output with

1410
00:55:41,880 --> 00:55:44,040
cyber it's extremely difficult for us to

1411
00:55:44,040 --> 00:55:46,559
at scale you know scan the internet to

1412
00:55:46,559 --> 00:55:48,540
see which companies actually had a

1413
00:55:48,540 --> 00:55:49,680
ransomware

1414
00:55:49,680 --> 00:55:52,319
strained successfully deployed on some

1415
00:55:52,319 --> 00:55:54,299
of their servers right so I think

1416
00:55:54,299 --> 00:55:56,040
it doesn't mean that this that

1417
00:55:56,040 --> 00:55:57,540
uncertainty does not mean in my view

1418
00:55:57,540 --> 00:55:59,400
that this Pursuit is not worth doing

1419
00:55:59,400 --> 00:56:00,599
because I think certainly from the

1420
00:56:00,599 --> 00:56:02,460
insurance perspective as soon as you

1421
00:56:02,460 --> 00:56:03,900
insure a company you need to start

1422
00:56:03,900 --> 00:56:05,460
thinking about this sort of thing and

1423
00:56:05,460 --> 00:56:07,380
either your sort of finger in the air or

1424
00:56:07,380 --> 00:56:09,059
you're trying to use techniques like

1425
00:56:09,059 --> 00:56:13,079
we're trying to use but um yeah I think

1426
00:56:13,079 --> 00:56:14,520
I would endorse what Russell was saying

1427
00:56:14,520 --> 00:56:16,140
but I think also yeah there needs to be

1428
00:56:16,140 --> 00:56:18,000
an acknowledgment of a greater

1429
00:56:18,000 --> 00:56:20,280
uncertainty in this sphere

1430
00:56:20,280 --> 00:56:22,700
thank you

1431
00:56:23,460 --> 00:56:25,799
uh hopefully just a quick one which was

1432
00:56:25,799 --> 00:56:27,780
one of your points was around the lack

1433
00:56:27,780 --> 00:56:30,299
of incident information one thing was

1434
00:56:30,299 --> 00:56:31,740
around the lack of incident information

1435
00:56:31,740 --> 00:56:33,299
you mentioned that internet information

1436
00:56:33,299 --> 00:56:35,520
is hard to come by I was just wondering

1437
00:56:35,520 --> 00:56:39,059
since you work so closely with insurers

1438
00:56:39,059 --> 00:56:40,619
um you know their clients of yours they

1439
00:56:40,619 --> 00:56:41,880
they've sort of received a lot of this

1440
00:56:41,880 --> 00:56:43,319
modeling wouldn't they have a lot of

1441
00:56:43,319 --> 00:56:44,640
incident information from where they're

1442
00:56:44,640 --> 00:56:46,680
paid out and have you been able to

1443
00:56:46,680 --> 00:56:48,359
leverage that

1444
00:56:48,359 --> 00:56:51,299
so the question is do we get information

1445
00:56:51,299 --> 00:56:53,400
from insurance from their claims

1446
00:56:53,400 --> 00:56:55,500
information and others that we make use

1447
00:56:55,500 --> 00:56:58,020
of so

1448
00:56:58,020 --> 00:57:00,180
it depends um I think for insurance

1449
00:57:00,180 --> 00:57:02,339
companies this is my personal take not

1450
00:57:02,339 --> 00:57:04,920
that of RMS uh is that you know

1451
00:57:04,920 --> 00:57:07,440
insurance companies you know they view

1452
00:57:07,440 --> 00:57:09,599
their claims data as being a form of

1453
00:57:09,599 --> 00:57:10,920
intellectual property especially if

1454
00:57:10,920 --> 00:57:12,720
you're a insurance company that ensures

1455
00:57:12,720 --> 00:57:15,299
many many companies that data on the

1456
00:57:15,299 --> 00:57:16,920
frequency and the types of events and

1457
00:57:16,920 --> 00:57:18,299
all these sorts of things is really

1458
00:57:18,299 --> 00:57:20,339
really valuable to you certain insurance

1459
00:57:20,339 --> 00:57:22,920
companies will view that actually they'd

1460
00:57:22,920 --> 00:57:24,420
rather not share that information with

1461
00:57:24,420 --> 00:57:25,799
vendors such as ourselves because they

1462
00:57:25,799 --> 00:57:27,180
don't want their competitors to benefit

1463
00:57:27,180 --> 00:57:29,040
from that intelligence whilst other

1464
00:57:29,040 --> 00:57:31,020
kinds of companies

1465
00:57:31,020 --> 00:57:33,180
um maybe take a longer view that they

1466
00:57:33,180 --> 00:57:35,160
want to actually having robust

1467
00:57:35,160 --> 00:57:38,160
quantitative methods is

1468
00:57:38,160 --> 00:57:41,040
necessary for a cyber insurance for a

1469
00:57:41,040 --> 00:57:43,740
healthy cyber insurance industry more

1470
00:57:43,740 --> 00:57:46,500
broadly so uh yeah we get we do have

1471
00:57:46,500 --> 00:57:48,240
some claims data from some of our

1472
00:57:48,240 --> 00:57:50,700
clients but we'd always like more but we

1473
00:57:50,700 --> 00:57:53,339
understand that actually it's a business

1474
00:57:53,339 --> 00:57:55,680
decision making a business decision as

1475
00:57:55,680 --> 00:57:59,640
well as uh other kinds of things

1476
00:57:59,640 --> 00:58:03,059
there is a informal process

1477
00:58:03,059 --> 00:58:05,400
where some of that information gets

1478
00:58:05,400 --> 00:58:08,700
exchanged implicitly it involves them

1479
00:58:08,700 --> 00:58:11,220
running the model and looking at their

1480
00:58:11,220 --> 00:58:13,740
own data you know wait a minute we don't

1481
00:58:13,740 --> 00:58:15,720
what you're saying this and we're we're

1482
00:58:15,720 --> 00:58:17,339
saying that

1483
00:58:17,339 --> 00:58:19,799
so whenever we get bones of contention

1484
00:58:19,799 --> 00:58:22,200
irritation we're too high compared to

1485
00:58:22,200 --> 00:58:24,900
what they think are too low that sort of

1486
00:58:24,900 --> 00:58:28,440
informs us indirectly about not the

1487
00:58:28,440 --> 00:58:30,720
details but the overall summary of where

1488
00:58:30,720 --> 00:58:32,700
they are in the risk curve

1489
00:58:32,700 --> 00:58:34,319
I think as well actually it's also worth

1490
00:58:34,319 --> 00:58:37,319
noting that some insurance companies do

1491
00:58:37,319 --> 00:58:40,740
release claims statistics reports which

1492
00:58:40,740 --> 00:58:42,480
are also pretty you know interesting

1493
00:58:42,480 --> 00:58:43,799
where they you know they're not

1494
00:58:43,799 --> 00:58:45,599
releasing the names of the companies

1495
00:58:45,599 --> 00:58:46,680
that were hit or anything but they're

1496
00:58:46,680 --> 00:58:49,140
saying that you know for companies with

1497
00:58:49,140 --> 00:58:50,339
less than five billion dollars of

1498
00:58:50,339 --> 00:58:52,680
Revenue you know two percent of them in

1499
00:58:52,680 --> 00:58:53,940
our portfolio took a claim or something

1500
00:58:53,940 --> 00:58:56,880
like that so I think yeah data is being

1501
00:58:56,880 --> 00:58:58,740
shared but not as openly as maybe some

1502
00:58:58,740 --> 00:59:01,939
of us would like yeah thank you

1503
00:59:05,160 --> 00:59:06,780
all right I think that's a wrap thanks

1504
00:59:06,780 --> 00:59:07,680
everybody

1505
00:59:07,680 --> 00:59:12,830
[Applause]

