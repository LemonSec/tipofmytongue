1
00:00:00,080 --> 00:00:01,839
all right hello everyone

2
00:00:01,839 --> 00:00:04,080
welcome back to the last set of talks

3
00:00:04,080 --> 00:00:07,200
for b-sides las vegas 2022.

4
00:00:07,200 --> 00:00:09,599
uh this is breaking ground uh one quick

5
00:00:09,599 --> 00:00:11,280
announcement though if you are looking

6
00:00:11,280 --> 00:00:13,200
for the exclave experience relocated to

7
00:00:13,200 --> 00:00:15,040
almost canada by t profit you are in the

8
00:00:15,040 --> 00:00:16,320
wrong room it is the move to the

9
00:00:16,320 --> 00:00:18,720
passwords con and the tuscany ballroom

10
00:00:18,720 --> 00:00:20,640
um and those are you online too make

11
00:00:20,640 --> 00:00:21,680
sure you're clicking on the right room

12
00:00:21,680 --> 00:00:23,519
it's the tuscany ballroom now with

13
00:00:23,519 --> 00:00:25,279
passwords con um the website has the

14
00:00:25,279 --> 00:00:27,039
most up-to-date link so just refer to

15
00:00:27,039 --> 00:00:28,480
that one but

16
00:00:28,480 --> 00:00:30,720
welcome this is uh again this is

17
00:00:30,720 --> 00:00:32,960
breaking ground we have uh shreyas and

18
00:00:32,960 --> 00:00:34,960
sean here they're the title of their

19
00:00:34,960 --> 00:00:37,840
talk is ransomware emulation done right

20
00:00:37,840 --> 00:00:39,440
uh a couple round monitors before we

21
00:00:39,440 --> 00:00:41,200
begin as always thank you so much to our

22
00:00:41,200 --> 00:00:42,960
diamond and gold sponsors without their

23
00:00:42,960 --> 00:00:44,719
assistance as well as all the volunteers

24
00:00:44,719 --> 00:00:46,480
staff and anyone who's involved with

25
00:00:46,480 --> 00:00:48,399
besides las vegas 2022 this event

26
00:00:48,399 --> 00:00:50,399
certainly would have been possible

27
00:00:50,399 --> 00:00:51,920
and i think i share the sentiment with a

28
00:00:51,920 --> 00:00:53,280
lot of you guys and a lot of other

29
00:00:53,280 --> 00:00:54,800
people here that i'm glad that this

30
00:00:54,800 --> 00:00:57,199
in-person event did indeed happen and

31
00:00:57,199 --> 00:00:59,199
hopefully it'll happen for you know

32
00:00:59,199 --> 00:01:00,559
the countless number of years down the

33
00:01:00,559 --> 00:01:01,600
road

34
00:01:01,600 --> 00:01:03,680
but out of respect for

35
00:01:03,680 --> 00:01:05,438
um the people on the livestream as well

36
00:01:05,438 --> 00:01:06,799
as for these speakers please do make

37
00:01:06,799 --> 00:01:08,400
sure that you're that your cell phones

38
00:01:08,400 --> 00:01:10,479
are at least silenced or ideally all the

39
00:01:10,479 --> 00:01:12,400
way turned off and a reminder of the

40
00:01:12,400 --> 00:01:15,040
photo policy you are not allowed to take

41
00:01:15,040 --> 00:01:16,560
photos without explicit permission of

42
00:01:16,560 --> 00:01:18,400
everyone in frame so if it's okay with

43
00:01:18,400 --> 00:01:20,479
them you can but

44
00:01:20,479 --> 00:01:22,080
wouldn't run that risk

45
00:01:22,080 --> 00:01:24,159
now one tiny change to how we've been

46
00:01:24,159 --> 00:01:26,320
doing things before during the q a

47
00:01:26,320 --> 00:01:27,280
session

48
00:01:27,280 --> 00:01:28,720
unfortunately now that we've we've run

49
00:01:28,720 --> 00:01:29,759
into a little bit of an issue with

50
00:01:29,759 --> 00:01:32,159
wireless mic problems um so if by the

51
00:01:32,159 --> 00:01:33,840
end you have a question

52
00:01:33,840 --> 00:01:36,000
you are probably going to have to shout

53
00:01:36,000 --> 00:01:37,439
it so for those of you in the back of

54
00:01:37,439 --> 00:01:38,960
the room i'm not saying you have to move

55
00:01:38,960 --> 00:01:40,960
forward but i would recommend it if you

56
00:01:40,960 --> 00:01:43,040
think you might have a question um and

57
00:01:43,040 --> 00:01:45,200
you guys by the end if like you guys

58
00:01:45,200 --> 00:01:46,720
could just repeat the question yeah that

59
00:01:46,720 --> 00:01:48,640
would be great for all those online um

60
00:01:48,640 --> 00:01:50,320
so without further ado here's dress and

61
00:01:50,320 --> 00:01:51,439
sean

62
00:01:51,439 --> 00:01:52,960
thank you

63
00:01:52,960 --> 00:01:55,759
hello thank you for coming i know it's

64
00:01:55,759 --> 00:01:57,840
the end of the day so let's get into it

65
00:01:57,840 --> 00:01:58,799
uh we're going to be talking about

66
00:01:58,799 --> 00:02:01,439
ransomware emulation and uh as always

67
00:02:01,439 --> 00:02:03,759
want to start off uh best defense is a

68
00:02:03,759 --> 00:02:06,320
good offense and it's worth knowing that

69
00:02:06,320 --> 00:02:07,119
like

70
00:02:07,119 --> 00:02:08,399
internal security

71
00:02:08,399 --> 00:02:10,000
using your red team and stuff has

72
00:02:10,000 --> 00:02:11,760
massive benefits so hopefully we could

73
00:02:11,760 --> 00:02:13,120
kind of like show you that with this

74
00:02:13,120 --> 00:02:14,080
talk

75
00:02:14,080 --> 00:02:16,319
um so my name is sean jones i'm a

76
00:02:16,319 --> 00:02:20,319
director at ebay we're both from ebay

77
00:02:20,319 --> 00:02:22,959
and i do a lot of kind of like more

78
00:02:22,959 --> 00:02:24,800
programs and projects stuff like

79
00:02:24,800 --> 00:02:28,640
ransomware program um and sure yes all

80
00:02:28,640 --> 00:02:29,440
right

81
00:02:29,440 --> 00:02:31,440
hey guys uh my name is shri ashrami i'm

82
00:02:31,440 --> 00:02:34,560
a senior detection engineer at ebay

83
00:02:34,560 --> 00:02:36,879
mostly on the blue team but i do a bunch

84
00:02:36,879 --> 00:02:39,519
of focal teaming as well with sean

85
00:02:39,519 --> 00:02:42,160
so with that let's kick this off

86
00:02:42,160 --> 00:02:44,000
all right so we know that ransomware is

87
00:02:44,000 --> 00:02:46,879
a problem it's a huge problem

88
00:02:46,879 --> 00:02:48,879
google released a report that it

89
00:02:48,879 --> 00:02:51,120
analyzed around 80 million ransomware

90
00:02:51,120 --> 00:02:52,560
samples

91
00:02:52,560 --> 00:02:55,599
let's look at five months in last

92
00:02:55,599 --> 00:02:58,800
let's look at five months in 2021

93
00:02:58,800 --> 00:03:00,159
there are several companies that were

94
00:03:00,159 --> 00:03:02,720
hit by ransomware and they paid tens and

95
00:03:02,720 --> 00:03:06,560
millions of dollars in ransomware um

96
00:03:06,560 --> 00:03:08,480
just look at colonial pipeline they they

97
00:03:08,480 --> 00:03:10,159
even made national news and that was

98
00:03:10,159 --> 00:03:12,480
huge

99
00:03:12,720 --> 00:03:15,200
so uh ebay like much like all the

100
00:03:15,200 --> 00:03:16,640
companies are kind of worried about this

101
00:03:16,640 --> 00:03:18,000
and we don't want to get impacted

102
00:03:18,000 --> 00:03:19,519
because you know lots of revenue and

103
00:03:19,519 --> 00:03:21,519
stuff like that we do get here and

104
00:03:21,519 --> 00:03:23,680
customer day are so whenever we kind of

105
00:03:23,680 --> 00:03:25,280
look at the program we just started with

106
00:03:25,280 --> 00:03:26,799
the idea of asking ourselves couple

107
00:03:26,799 --> 00:03:28,319
questions

108
00:03:28,319 --> 00:03:30,159
the first being are our employees

109
00:03:30,159 --> 00:03:32,799
susceptible do our controls and tools

110
00:03:32,799 --> 00:03:35,440
actually work and do we actually respond

111
00:03:35,440 --> 00:03:37,120
in the best way uh you don't want to be

112
00:03:37,120 --> 00:03:38,480
responding in the wrong way to

113
00:03:38,480 --> 00:03:39,599
ransomware

114
00:03:39,599 --> 00:03:41,360
so with that in mind we kind of started

115
00:03:41,360 --> 00:03:43,519
off with kind of like free tracks so

116
00:03:43,519 --> 00:03:45,599
track one is education

117
00:03:45,599 --> 00:03:47,280
with this we do a lot of tabletops with

118
00:03:47,280 --> 00:03:49,519
different teams and to secure awareness

119
00:03:49,519 --> 00:03:50,959
you know the phishing emails everyone

120
00:03:50,959 --> 00:03:52,799
gets and stuff like that and the annual

121
00:03:52,799 --> 00:03:54,480
training we're not really going to talk

122
00:03:54,480 --> 00:03:56,159
about track one because it's not the

123
00:03:56,159 --> 00:03:58,319
interesting stuff but track two was

124
00:03:58,319 --> 00:04:00,720
around controls and our visibility

125
00:04:00,720 --> 00:04:03,040
around our logs and alerting so with

126
00:04:03,040 --> 00:04:05,040
that we kind of do purple team exercises

127
00:04:05,040 --> 00:04:07,200
which is going to be kind of focused and

128
00:04:07,200 --> 00:04:09,599
red team exercises red tmi exercises

129
00:04:09,599 --> 00:04:12,239
also help us with track free but that

130
00:04:12,239 --> 00:04:15,680
which is response but they're less uh

131
00:04:15,680 --> 00:04:17,120
less to the same extent as our

132
00:04:17,120 --> 00:04:19,040
ransomware simulation because we only do

133
00:04:19,040 --> 00:04:22,240
a couple of boxes not an entire uh load

134
00:04:22,240 --> 00:04:24,479
of employees with this stuff so

135
00:04:24,479 --> 00:04:26,240
um ransomware simulation by the way is

136
00:04:26,240 --> 00:04:27,680
just where we kind of like simulate a

137
00:04:27,680 --> 00:04:29,040
ransomware attack within the

138
00:04:29,040 --> 00:04:30,320
organization

139
00:04:30,320 --> 00:04:33,600
um to see kind of what happens

140
00:04:33,600 --> 00:04:35,280
so staff we're going to talk about

141
00:04:35,280 --> 00:04:37,040
purple teaming um

142
00:04:37,040 --> 00:04:38,560
and i'm guessing everyone might know

143
00:04:38,560 --> 00:04:40,240
about it so we can rush through it uh

144
00:04:40,240 --> 00:04:42,080
this is basically blue team red team get

145
00:04:42,080 --> 00:04:43,600
together they plan on exercise they

146
00:04:43,600 --> 00:04:45,520
agree on ttps what fractals we're

147
00:04:45,520 --> 00:04:46,960
concerned about

148
00:04:46,960 --> 00:04:48,960
um and what kind of where we're gonna do

149
00:04:48,960 --> 00:04:51,840
it what's our focus of it um because we

150
00:04:51,840 --> 00:04:53,440
have so many different environments so

151
00:04:53,440 --> 00:04:56,000
we kind of tailor it to that

152
00:04:56,000 --> 00:04:57,600
next red team goes ahead and does the

153
00:04:57,600 --> 00:05:00,800
actual activities um hack some stuff

154
00:05:00,800 --> 00:05:02,639
break some stuff and then with that the

155
00:05:02,639 --> 00:05:04,720
blue team can then come along and

156
00:05:04,720 --> 00:05:06,880
examine our tooling on our telemetry

157
00:05:06,880 --> 00:05:08,720
like our logs and stuff see if

158
00:05:08,720 --> 00:05:10,800
ultimately giving us a proper

159
00:05:10,800 --> 00:05:13,360
understanding of how resilient we are to

160
00:05:13,360 --> 00:05:16,400
an attack and we do this um through kind

161
00:05:16,400 --> 00:05:18,400
of just checking out this continuous

162
00:05:18,400 --> 00:05:20,160
process so we'll red team might have to

163
00:05:20,160 --> 00:05:21,840
replay some stuff and blue team comes

164
00:05:21,840 --> 00:05:23,120
back to it

165
00:05:23,120 --> 00:05:25,280
so to start off with this what we did

166
00:05:25,280 --> 00:05:28,400
was uh a load of research on it um

167
00:05:28,400 --> 00:05:31,360
we did a lot of blogs read a lot of uh

168
00:05:31,360 --> 00:05:34,000
reports around stuff uh we even looked

169
00:05:34,000 --> 00:05:35,919
at twitter and telegram

170
00:05:35,919 --> 00:05:39,520
um as you can see this is uh scythe's uh

171
00:05:39,520 --> 00:05:41,919
github and honestly for any emulation

172
00:05:41,919 --> 00:05:43,680
stuff they actually have pretty good

173
00:05:43,680 --> 00:05:46,560
list of ttps for not just ransomware

174
00:05:46,560 --> 00:05:48,560
actors but like other threats as well so

175
00:05:48,560 --> 00:05:50,160
if you are doing kind of like emulation

176
00:05:50,160 --> 00:05:52,400
it's a good place there to go

177
00:05:52,400 --> 00:05:53,759
the next thing that we did was we

178
00:05:53,759 --> 00:05:56,080
acquired a large number of samples of

179
00:05:56,080 --> 00:05:58,319
ransomware uh we predominantly got them

180
00:05:58,319 --> 00:05:59,680
from like virustotal but there's a

181
00:05:59,680 --> 00:06:02,400
number of places you can get them the

182
00:06:02,400 --> 00:06:04,160
idea with this was we did some reverse

183
00:06:04,160 --> 00:06:05,919
engineering to actually kind of see how

184
00:06:05,919 --> 00:06:08,479
they work to figure out what exactly

185
00:06:08,479 --> 00:06:11,440
happens when these execute

186
00:06:11,440 --> 00:06:12,400
but you might not have like the

187
00:06:12,400 --> 00:06:13,759
capabilities to do like reverse

188
00:06:13,759 --> 00:06:15,120
engineering and malware you might not

189
00:06:15,120 --> 00:06:16,720
have like the team

190
00:06:16,720 --> 00:06:18,560
possible to do that so one thing you can

191
00:06:18,560 --> 00:06:21,039
also do is if you know hashes or

192
00:06:21,039 --> 00:06:22,639
specific kind of ones that you want to

193
00:06:22,639 --> 00:06:24,880
look at you can go to like any run or

194
00:06:24,880 --> 00:06:26,720
joke sandbox just google the hash

195
00:06:26,720 --> 00:06:28,319
typically you'll end up finding it and

196
00:06:28,319 --> 00:06:30,080
that way you get the dynamic analysis

197
00:06:30,080 --> 00:06:31,600
part done for you without the need in

198
00:06:31,600 --> 00:06:33,520
the kind of internal skills to help it

199
00:06:33,520 --> 00:06:34,560
out

200
00:06:34,560 --> 00:06:37,120
so like with any of this stuff we we set

201
00:06:37,120 --> 00:06:40,080
up our test environment just to be safe

202
00:06:40,080 --> 00:06:41,520
our test environment was basically a

203
00:06:41,520 --> 00:06:43,919
windows vm in my house at the time we

204
00:06:43,919 --> 00:06:45,919
actually moved it to azure announce uh

205
00:06:45,919 --> 00:06:47,199
to a standalone account so it's a bit

206
00:06:47,199 --> 00:06:49,919
more safer um basically with that what

207
00:06:49,919 --> 00:06:51,759
we did was install our edr tool and a

208
00:06:51,759 --> 00:06:53,520
load of other standard kind of build

209
00:06:53,520 --> 00:06:55,599
tools that we had along with our logging

210
00:06:55,599 --> 00:06:57,599
and telemetry kind of agents as well to

211
00:06:57,599 --> 00:06:59,520
pull that stuff back uh we did include

212
00:06:59,520 --> 00:07:02,800
our vpn uh this only allows us to do on

213
00:07:02,800 --> 00:07:04,560
off network testing so

214
00:07:04,560 --> 00:07:06,960
we might want to test like a laptop

215
00:07:06,960 --> 00:07:08,800
being off network because everyone's off

216
00:07:08,800 --> 00:07:11,919
the network now anyway uh we've covered

217
00:07:11,919 --> 00:07:13,759
or we might want to test like within our

218
00:07:13,759 --> 00:07:16,720
network to see if our actual

219
00:07:16,720 --> 00:07:19,120
our proxies and other controls actually

220
00:07:19,120 --> 00:07:21,199
work and detect stuff

221
00:07:21,199 --> 00:07:22,880
the other reason we did a vm is

222
00:07:22,880 --> 00:07:24,960
snapshots basically we can do a large

223
00:07:24,960 --> 00:07:26,800
amount of like adding additional tooling

224
00:07:26,800 --> 00:07:29,039
so for us we were doing a massive drive

225
00:07:29,039 --> 00:07:31,919
to push sysmon across the organization

226
00:07:31,919 --> 00:07:33,680
and we use this as a way of basically

227
00:07:33,680 --> 00:07:35,599
selling that that drive that we were

228
00:07:35,599 --> 00:07:37,039
going for and it worked quite well which

229
00:07:37,039 --> 00:07:38,960
we'll talk about later

230
00:07:38,960 --> 00:07:40,560
with that we've done all our research we

231
00:07:40,560 --> 00:07:41,759
went ahead and we started building

232
00:07:41,759 --> 00:07:43,280
around somewhere this is like the fun

233
00:07:43,280 --> 00:07:46,479
part so um i went ahead and i wrote

234
00:07:46,479 --> 00:07:48,879
basically a piece around c sharp uh

235
00:07:48,879 --> 00:07:51,440
included several ttps we added in some

236
00:07:51,440 --> 00:07:53,680
functionality like the ability to rotate

237
00:07:53,680 --> 00:07:55,759
ransomware noise and rotate the fire

238
00:07:55,759 --> 00:07:58,160
extensions uh when we actually ran this

239
00:07:58,160 --> 00:07:59,599
to make it be easier because we want to

240
00:07:59,599 --> 00:08:01,520
see what would happen for specific ones

241
00:08:01,520 --> 00:08:04,720
but not run actual ransomware at a time

242
00:08:04,720 --> 00:08:07,120
following that we actually wrote one and

243
00:08:07,120 --> 00:08:09,360
go because go was kind of getting a lot

244
00:08:09,360 --> 00:08:10,960
bigger back then and we hadn't done any

245
00:08:10,960 --> 00:08:13,599
of that in our exercises so um i'm not

246
00:08:13,599 --> 00:08:15,199
going it was like my first dive at

247
00:08:15,199 --> 00:08:16,800
writing guys so what i did was i used

248
00:08:16,800 --> 00:08:19,759
bad gopher by andy j smith on github and

249
00:08:19,759 --> 00:08:21,919
i basically modified the code to make it

250
00:08:21,919 --> 00:08:24,160
match what we wanted to do and for the

251
00:08:24,160 --> 00:08:26,319
ttps

252
00:08:26,319 --> 00:08:27,759
uh say another you might not you don't

253
00:08:27,759 --> 00:08:29,120
need to write your own ransomware

254
00:08:29,120 --> 00:08:30,240
there's a lot of tools out there that

255
00:08:30,240 --> 00:08:32,799
you can use for this um i haven't used

256
00:08:32,799 --> 00:08:34,559
these so i can't say if they're safe or

257
00:08:34,559 --> 00:08:36,640
not but you should probably test them or

258
00:08:36,640 --> 00:08:37,839
read them before you run them but

259
00:08:37,839 --> 00:08:39,360
there's there's a lot of options out

260
00:08:39,360 --> 00:08:40,479
there so you don't need to spend the

261
00:08:40,479 --> 00:08:42,559
time doing your development

262
00:08:42,559 --> 00:08:44,320
so let's get into it so round one what

263
00:08:44,320 --> 00:08:45,680
was uh what was one of the things we

264
00:08:45,680 --> 00:08:46,560
found

265
00:08:46,560 --> 00:08:48,640
sure so the first thing that we did was

266
00:08:48,640 --> 00:08:51,360
we went through uh the

267
00:08:51,360 --> 00:08:53,600
default ddbs that came with the adr tool

268
00:08:53,600 --> 00:08:55,600
and as you can see like there were

269
00:08:55,600 --> 00:08:57,680
almost 2 million results this is

270
00:08:57,680 --> 00:08:59,760
something that's not feasible to go

271
00:08:59,760 --> 00:09:01,360
through all of them so

272
00:09:01,360 --> 00:09:03,200
we basically wanted a purple team

273
00:09:03,200 --> 00:09:05,680
exercise and to identify a

274
00:09:05,680 --> 00:09:09,360
good high fidelity alerting around this

275
00:09:09,360 --> 00:09:12,080
so we went ahead and ran the binary

276
00:09:12,080 --> 00:09:14,160
which sean had just created

277
00:09:14,160 --> 00:09:16,399
which was customized and

278
00:09:16,399 --> 00:09:18,720
the edr system which was current black

279
00:09:18,720 --> 00:09:21,360
eventually detected after some time

280
00:09:21,360 --> 00:09:23,680
so that was awesome uh so the test was

281
00:09:23,680 --> 00:09:26,240
complete right sean uh yeah nice sadly

282
00:09:26,240 --> 00:09:28,880
it wasn't complete but as we know uh if

283
00:09:28,880 --> 00:09:30,560
anyone looked at the connie leagues a

284
00:09:30,560 --> 00:09:32,000
lot of these actors were actually

285
00:09:32,000 --> 00:09:34,640
purchasing valid edr tools

286
00:09:34,640 --> 00:09:36,399
and using them which means they could

287
00:09:36,399 --> 00:09:38,240
figure out potentially what is getting

288
00:09:38,240 --> 00:09:39,839
flagged on and why it's getting caught

289
00:09:39,839 --> 00:09:41,360
so we did a similar thing and we started

290
00:09:41,360 --> 00:09:43,440
looking into this and it turns out what

291
00:09:43,440 --> 00:09:45,920
was catching us was the canary files now

292
00:09:45,920 --> 00:09:48,000
these files lots of edr products do it's

293
00:09:48,000 --> 00:09:49,920
not just uh com back but lots of

294
00:09:49,920 --> 00:09:51,760
products do this and they basically have

295
00:09:51,760 --> 00:09:53,600
some files on the file system if they

296
00:09:53,600 --> 00:09:55,600
start getting modified and renamed

297
00:09:55,600 --> 00:09:57,200
they'll get flagged and they'll cause

298
00:09:57,200 --> 00:09:58,959
the basically the parent process that's

299
00:09:58,959 --> 00:10:00,560
doing that to get killed because they

300
00:10:00,560 --> 00:10:02,800
suspect this ransomware or some kind of

301
00:10:02,800 --> 00:10:05,120
malware so with that in mind we went and

302
00:10:05,120 --> 00:10:07,839
looked and uh what we realized was it

303
00:10:07,839 --> 00:10:10,399
actually did we we did we're able to

304
00:10:10,399 --> 00:10:11,920
encrypt a lot of files on the file

305
00:10:11,920 --> 00:10:13,680
system it was just when we hit a certain

306
00:10:13,680 --> 00:10:16,160
part this uh canary files got hit and

307
00:10:16,160 --> 00:10:19,200
then much like sad pikachu i ended up no

308
00:10:19,200 --> 00:10:20,880
longer being happy because my ransomware

309
00:10:20,880 --> 00:10:22,240
didn't work so

310
00:10:22,240 --> 00:10:24,000
so i guess 60 percent of the time canary

311
00:10:24,000 --> 00:10:27,200
files work every time right

312
00:10:27,200 --> 00:10:29,279
so following this we hit the

313
00:10:29,279 --> 00:10:31,200
we went back we made some modifications

314
00:10:31,200 --> 00:10:33,440
to our basically our payloads our

315
00:10:33,440 --> 00:10:36,000
ransomware and we come up with some

316
00:10:36,000 --> 00:10:38,880
canary file bypasses so the first one is

317
00:10:38,880 --> 00:10:40,720
really easy it's basically six lines of

318
00:10:40,720 --> 00:10:42,240
code you could probably put it in less

319
00:10:42,240 --> 00:10:43,920
lines of code if you wanted and this was

320
00:10:43,920 --> 00:10:45,839
basically if the file name starts with

321
00:10:45,839 --> 00:10:48,160
dollar sign or a hash symbol just skip

322
00:10:48,160 --> 00:10:50,079
the file don't encrypt it and this

323
00:10:50,079 --> 00:10:51,200
worked pretty well we were able to

324
00:10:51,200 --> 00:10:53,760
bypass the canary files um which was

325
00:10:53,760 --> 00:10:56,000
kind of fun the second bypass we found

326
00:10:56,000 --> 00:10:58,160
that was if we went into kind of a

327
00:10:58,160 --> 00:11:02,240
trusted process um so notepad.xe is kind

328
00:11:02,240 --> 00:11:04,160
of we we basically spawn notepad

329
00:11:04,160 --> 00:11:06,720
directly inject our ransomware into it

330
00:11:06,720 --> 00:11:09,040
and then we could basically even encrypt

331
00:11:09,040 --> 00:11:11,279
the canary files and for some reason

332
00:11:11,279 --> 00:11:12,560
that didn't get flagged and our

333
00:11:12,560 --> 00:11:14,480
ransomware worked was pretty cool

334
00:11:14,480 --> 00:11:17,040
uh we did report it

335
00:11:17,040 --> 00:11:19,519
so round three now this is something

336
00:11:19,519 --> 00:11:21,360
that we've been doing more and more of

337
00:11:21,360 --> 00:11:23,360
now and it isn't just for ransomware but

338
00:11:23,360 --> 00:11:25,440
it works pretty well and this is just

339
00:11:25,440 --> 00:11:27,760
sandboxing so what we do is we go to

340
00:11:27,760 --> 00:11:30,000
virustotal we get our ransomware samples

341
00:11:30,000 --> 00:11:31,839
or other malware

342
00:11:31,839 --> 00:11:34,000
we then run that in this in that test

343
00:11:34,000 --> 00:11:36,079
environment vm that i was talking about

344
00:11:36,079 --> 00:11:38,399
and then we basically get the idea to

345
00:11:38,399 --> 00:11:40,880
see if our controls uh block or detect

346
00:11:40,880 --> 00:11:43,360
these samples and if not we can then

347
00:11:43,360 --> 00:11:45,279
figure out what is doing it so the

348
00:11:45,279 --> 00:11:46,880
reason i love this is it's pretty safe

349
00:11:46,880 --> 00:11:48,560
because it's up in azure not connected

350
00:11:48,560 --> 00:11:49,600
to us

351
00:11:49,600 --> 00:11:51,839
i don't need to do any work which i love

352
00:11:51,839 --> 00:11:54,000
and our blue team do this all themselves

353
00:11:54,000 --> 00:11:56,399
so it allows us to do this continuously

354
00:11:56,399 --> 00:11:58,240
say like some intel comes in they go

355
00:11:58,240 --> 00:12:00,079
grab the sample they can go run it and

356
00:12:00,079 --> 00:12:02,560
write rules very quick around detection

357
00:12:02,560 --> 00:12:04,639
which is great

358
00:12:04,639 --> 00:12:07,839
sorry with detection dress this uh

359
00:12:07,839 --> 00:12:10,079
all right so with all the tdps that we

360
00:12:10,079 --> 00:12:12,000
emulated earlier and which sean talked

361
00:12:12,000 --> 00:12:13,680
about we are able to utilize a handful

362
00:12:13,680 --> 00:12:16,399
of them to build high fidelity

363
00:12:16,399 --> 00:12:18,160
detection rules so i'm going to go over

364
00:12:18,160 --> 00:12:20,000
a few of them to and

365
00:12:20,000 --> 00:12:21,839
which i can talk to you about so the

366
00:12:21,839 --> 00:12:25,440
first one is disabling of windows

367
00:12:25,440 --> 00:12:27,040
defenders so this is one of the most

368
00:12:27,040 --> 00:12:29,519
common uh techniques that the ransomware

369
00:12:29,519 --> 00:12:32,160
uses and has been used by many malware

370
00:12:32,160 --> 00:12:34,079
families so

371
00:12:34,079 --> 00:12:36,240
it's not a it's very

372
00:12:36,240 --> 00:12:39,279
basic and it it's a common behavior uh

373
00:12:39,279 --> 00:12:41,440
if you see it in your network then it

374
00:12:41,440 --> 00:12:44,480
certainly warrants an investigation

375
00:12:44,480 --> 00:12:46,880
uh it's worth building an alert even if

376
00:12:46,880 --> 00:12:49,519
you don't use uh windows defender

377
00:12:49,519 --> 00:12:52,079
as as i said like many malware families

378
00:12:52,079 --> 00:12:54,240
use this so

379
00:12:54,240 --> 00:12:56,560
uh the next one was to detect any

380
00:12:56,560 --> 00:12:59,519
process injection and uh

381
00:12:59,519 --> 00:13:01,519
this is another common technique used by

382
00:13:01,519 --> 00:13:03,839
uh malware families uh and as sean

383
00:13:03,839 --> 00:13:05,760
mentioned like you know we used notepad

384
00:13:05,760 --> 00:13:07,680
to inject another process

385
00:13:07,680 --> 00:13:09,839
and use that to emulate like you know

386
00:13:09,839 --> 00:13:12,000
some ransomware behaviors over there so

387
00:13:12,000 --> 00:13:13,600
in the screenshot over here what you see

388
00:13:13,600 --> 00:13:15,279
over there is

389
00:13:15,279 --> 00:13:17,120
the displayswitch.exe which was

390
00:13:17,120 --> 00:13:19,279
essentially to use

391
00:13:19,279 --> 00:13:22,079
the affected machines to change the

392
00:13:22,079 --> 00:13:24,240
ransom change it to the ransomware

393
00:13:24,240 --> 00:13:25,920
message on the

394
00:13:25,920 --> 00:13:28,720
users affected users

395
00:13:28,720 --> 00:13:31,279
the third one that we worked

396
00:13:31,279 --> 00:13:33,839
on was to detect malicious circuitry

397
00:13:33,839 --> 00:13:34,880
usage

398
00:13:34,880 --> 00:13:36,959
certutal is a standard binary that's

399
00:13:36,959 --> 00:13:39,440
available on windows os which is known

400
00:13:39,440 --> 00:13:41,600
to be maliciously used by various

401
00:13:41,600 --> 00:13:43,600
transfer actors

402
00:13:43,600 --> 00:13:46,079
during the test we did a couple of

403
00:13:46,079 --> 00:13:48,639
things firstly we renamed the original

404
00:13:48,639 --> 00:13:51,199
binary so that we can even detection and

405
00:13:51,199 --> 00:13:52,880
that's something that's very uncommon

406
00:13:52,880 --> 00:13:54,560
and you should be

407
00:13:54,560 --> 00:13:56,320
looking into that if that happens

408
00:13:56,320 --> 00:13:58,560
secondly we use the renamed binary to

409
00:13:58,560 --> 00:14:00,399
then decode another

410
00:14:00,399 --> 00:14:04,240
code uh which was then executed for uh

411
00:14:04,240 --> 00:14:07,240
malicious purpose on these systems

412
00:14:07,240 --> 00:14:08,560
[Music]

413
00:14:08,560 --> 00:14:10,880
and uh lastly uh this was something that

414
00:14:10,880 --> 00:14:13,680
we experimented with uh we wanted to see

415
00:14:13,680 --> 00:14:16,880
if we can use known ransomware extension

416
00:14:16,880 --> 00:14:18,959
threat intel that was available and

417
00:14:18,959 --> 00:14:20,639
build an alert around it

418
00:14:20,639 --> 00:14:22,240
so

419
00:14:22,240 --> 00:14:24,160
eventually um

420
00:14:24,160 --> 00:14:26,480
we are not using it but like at the

421
00:14:26,480 --> 00:14:29,120
start what we did was um we tested and

422
00:14:29,120 --> 00:14:32,160
it worked pretty fine there wasn't much

423
00:14:32,160 --> 00:14:34,480
uh noise around it and very low false

424
00:14:34,480 --> 00:14:36,240
positives but as we increased our

425
00:14:36,240 --> 00:14:38,240
logging coverage to different zones in

426
00:14:38,240 --> 00:14:39,920
that environment we started receiving a

427
00:14:39,920 --> 00:14:41,440
lot of benign and false positive

428
00:14:41,440 --> 00:14:43,199
activities so

429
00:14:43,199 --> 00:14:46,000
alone i wouldn't 100 recommend but

430
00:14:46,000 --> 00:14:48,800
by using it with another signal in your

431
00:14:48,800 --> 00:14:50,720
environment you might be able to

432
00:14:50,720 --> 00:14:53,760
use that scenario to identify ransomware

433
00:14:53,760 --> 00:14:56,240
behaviors

434
00:14:57,120 --> 00:15:00,959
finally we were able to uh use 21 we

435
00:15:00,959 --> 00:15:02,399
were able to

436
00:15:02,399 --> 00:15:04,959
uh emulate like 21 different attack

437
00:15:04,959 --> 00:15:06,880
techniques and six

438
00:15:06,880 --> 00:15:08,720
tactics some of the notable ones as you

439
00:15:08,720 --> 00:15:10,880
can see are like shadow file deletion

440
00:15:10,880 --> 00:15:13,839
and process injections

441
00:15:14,079 --> 00:15:15,680
all right and

442
00:15:15,680 --> 00:15:17,760
along with that we were even

443
00:15:17,760 --> 00:15:19,120
able to

444
00:15:19,120 --> 00:15:21,360
identify some logging gaps in our

445
00:15:21,360 --> 00:15:23,680
existing windows security logs like for

446
00:15:23,680 --> 00:15:25,680
example

447
00:15:25,680 --> 00:15:26,399
the

448
00:15:26,399 --> 00:15:28,160
four six eight and even code which is

449
00:15:28,160 --> 00:15:31,120
for process creations we we initially

450
00:15:31,120 --> 00:15:32,480
didn't have

451
00:15:32,480 --> 00:15:33,920
process command lines that were being

452
00:15:33,920 --> 00:15:36,320
locked and if you know windows logs this

453
00:15:36,320 --> 00:15:38,560
is very important to

454
00:15:38,560 --> 00:15:42,000
uh log as you can see a lot of

455
00:15:42,000 --> 00:15:43,680
malicious activity within the command

456
00:15:43,680 --> 00:15:46,240
lines over there so this was

457
00:15:46,240 --> 00:15:48,000
something that we had to go back and

458
00:15:48,000 --> 00:15:50,800
change the policies around the logging

459
00:15:50,800 --> 00:15:53,279
on this security logs and we were able

460
00:15:53,279 --> 00:15:55,519
to get everyone in line to approve it

461
00:15:55,519 --> 00:15:56,639
and

462
00:15:56,639 --> 00:15:58,160
you know get forward with it so that was

463
00:15:58,160 --> 00:16:01,279
pretty huge and secondly we were able to

464
00:16:01,279 --> 00:16:03,839
add a showcase

465
00:16:03,839 --> 00:16:07,360
value from the sysmon logs and as as it

466
00:16:07,360 --> 00:16:09,120
actually complemented the window

467
00:16:09,120 --> 00:16:11,120
security locks so

468
00:16:11,120 --> 00:16:12,320
this

469
00:16:12,320 --> 00:16:15,920
exercise was like a leverage for us to

470
00:16:15,920 --> 00:16:18,160
push forward the additional logging that

471
00:16:18,160 --> 00:16:20,160
we are requesting

472
00:16:20,160 --> 00:16:22,720
and overall it's a huge win for the team

473
00:16:22,720 --> 00:16:24,639
on the blue team over there all right

474
00:16:24,639 --> 00:16:26,399
yes i'm sean

475
00:16:26,399 --> 00:16:28,720
yeah um so we're going to talk about

476
00:16:28,720 --> 00:16:30,480
simulation now now simulation is

477
00:16:30,480 --> 00:16:32,480
something that basically

478
00:16:32,480 --> 00:16:34,800
i had this idea and i really wanted to

479
00:16:34,800 --> 00:16:37,440
do it and if you just go ask if you can

480
00:16:37,440 --> 00:16:39,600
kind of go ransomware the company uh

481
00:16:39,600 --> 00:16:41,279
you're probably gonna get told no

482
00:16:41,279 --> 00:16:42,720
so uh what i did was i go with the

483
00:16:42,720 --> 00:16:44,880
latest stakeovers at stakeholders so

484
00:16:44,880 --> 00:16:45,680
yeah

485
00:16:45,680 --> 00:16:48,399
um and this included like the head of it

486
00:16:48,399 --> 00:16:51,120
someone from legal and communications as

487
00:16:51,120 --> 00:16:53,040
well and what we did was we got together

488
00:16:53,040 --> 00:16:55,120
we planned it out we made sure we had a

489
00:16:55,120 --> 00:16:56,480
whole list of concerns which i'm going

490
00:16:56,480 --> 00:16:59,440
to talk about in a second and once we

491
00:16:59,440 --> 00:17:02,160
had that we kind of presented it to the

492
00:17:02,160 --> 00:17:03,759
cso and the cto around getting

493
00:17:03,759 --> 00:17:05,199
permission to do this they ended up

494
00:17:05,199 --> 00:17:06,959
having to go ask the ceo for the

495
00:17:06,959 --> 00:17:09,359
commission and so he approved it as well

496
00:17:09,359 --> 00:17:11,359
and basically once we got approvals it

497
00:17:11,359 --> 00:17:12,720
was a case of just executing the

498
00:17:12,720 --> 00:17:14,880
ransomware on our victims

499
00:17:14,880 --> 00:17:16,319
the whole point of this was to basically

500
00:17:16,319 --> 00:17:18,720
understand how as a company we would

501
00:17:18,720 --> 00:17:21,199
respond to a ransomware attack which is

502
00:17:21,199 --> 00:17:23,359
something that you is quite hard to

503
00:17:23,359 --> 00:17:25,199
emulate and as you will find out we

504
00:17:25,199 --> 00:17:28,160
learnt a lot from this

505
00:17:28,400 --> 00:17:30,960
so the concerns a couple of big concerns

506
00:17:30,960 --> 00:17:33,360
on this was uh someone taking a picture

507
00:17:33,360 --> 00:17:34,880
and tweeting it or something put on

508
00:17:34,880 --> 00:17:37,679
facebook uh again leaked the media that

509
00:17:37,679 --> 00:17:40,240
ebay got ransomware um that could have

510
00:17:40,240 --> 00:17:42,400
quite big effect on us so we didn't want

511
00:17:42,400 --> 00:17:44,240
that happening uh with that we kind of

512
00:17:44,240 --> 00:17:46,160
got some pre-planned communications

513
00:17:46,160 --> 00:17:49,200
written by our kind of marketing pr team

514
00:17:49,200 --> 00:17:51,120
the mental health of the victims

515
00:17:51,120 --> 00:17:52,880
people don't want to feel responsible

516
00:17:52,880 --> 00:17:55,280
for stuff especially ransomware

517
00:17:55,280 --> 00:17:56,799
and

518
00:17:56,799 --> 00:17:58,799
depending on who you targeted it could

519
00:17:58,799 --> 00:18:00,640
be quite bad so

520
00:18:00,640 --> 00:18:02,400
we made the decision to basically only

521
00:18:02,400 --> 00:18:04,559
target uh directors and above within the

522
00:18:04,559 --> 00:18:06,960
company um which quite high level people

523
00:18:06,960 --> 00:18:08,640
in there typically used to kind of

524
00:18:08,640 --> 00:18:09,760
stress and know to understand the

525
00:18:09,760 --> 00:18:11,039
situation

526
00:18:11,039 --> 00:18:12,799
uh the other thing we worried about was

527
00:18:12,799 --> 00:18:14,480
like disruption of work uh our

528
00:18:14,480 --> 00:18:16,160
leadership accepted that as a case they

529
00:18:16,160 --> 00:18:17,919
were like disruption of work we'll just

530
00:18:17,919 --> 00:18:19,760
do it for like four hours was the max we

531
00:18:19,760 --> 00:18:22,480
were allowed to block users basically

532
00:18:22,480 --> 00:18:24,640
and the fear of it kind of spreading

533
00:18:24,640 --> 00:18:26,320
around and infecting other people within

534
00:18:26,320 --> 00:18:29,120
our network as well as a concern

535
00:18:29,120 --> 00:18:30,880
so what i said there here's the message

536
00:18:30,880 --> 00:18:32,400
and i know a common question that i

537
00:18:32,400 --> 00:18:33,679
always get asked is did i actually get

538
00:18:33,679 --> 00:18:36,640
bitcoin i didn't sadly no one paid but

539
00:18:36,640 --> 00:18:39,679
um on a wednesday at like 905 this is

540
00:18:39,679 --> 00:18:41,200
what people saw on their screens on

541
00:18:41,200 --> 00:18:42,559
their desk and these are these are

542
00:18:42,559 --> 00:18:44,720
pictures taken that were sent to our

543
00:18:44,720 --> 00:18:46,160
kind of c cert team with people

544
00:18:46,160 --> 00:18:48,880
reporting it uh we had a lot of emails a

545
00:18:48,880 --> 00:18:50,559
lot of panic people around this it was

546
00:18:50,559 --> 00:18:51,440
kind of

547
00:18:51,440 --> 00:18:53,919
it was a high octane thing and i was on

548
00:18:53,919 --> 00:18:55,520
pto that day

549
00:18:55,520 --> 00:18:57,760
so no one could uh ask me if i was doing

550
00:18:57,760 --> 00:18:59,600
something which is fine

551
00:18:59,600 --> 00:19:01,760
so with that his kind of high level

552
00:19:01,760 --> 00:19:03,600
timeline of what this whole process

553
00:19:03,600 --> 00:19:04,799
looked like because you might want to do

554
00:19:04,799 --> 00:19:07,120
this in your own organization uh it

555
00:19:07,120 --> 00:19:08,480
started off with a lot of planning as

556
00:19:08,480 --> 00:19:10,960
already said uh we then went and did a

557
00:19:10,960 --> 00:19:13,360
slide deck to the cto and the cso asking

558
00:19:13,360 --> 00:19:15,440
permission uh this was

559
00:19:15,440 --> 00:19:16,960
originally we only asked to do it to

560
00:19:16,960 --> 00:19:19,039
around five to ten people and they were

561
00:19:19,039 --> 00:19:21,520
like let's do it to like 60 people well

562
00:19:21,520 --> 00:19:23,600
it's like more than 60 people across the

563
00:19:23,600 --> 00:19:25,039
organization

564
00:19:25,039 --> 00:19:27,600
uh which we were like oh okay this might

565
00:19:27,600 --> 00:19:28,720
get bad

566
00:19:28,720 --> 00:19:30,400
so with that we we agreed on like

567
00:19:30,400 --> 00:19:32,160
conditions like said like a four hour

568
00:19:32,160 --> 00:19:34,960
window and our targets and we ended up

569
00:19:34,960 --> 00:19:37,120
uh basically having to do the hard part

570
00:19:37,120 --> 00:19:38,720
after that and that was building the

571
00:19:38,720 --> 00:19:41,039
actual ransomware so for this i read in

572
00:19:41,039 --> 00:19:43,360
c sharp because i just like c sharp uh

573
00:19:43,360 --> 00:19:45,520
we decided to impersonate reeval because

574
00:19:45,520 --> 00:19:47,840
at the time they were very in the media

575
00:19:47,840 --> 00:19:50,080
very public and stuff so it was like a

576
00:19:50,080 --> 00:19:52,559
good thing to do uh to stop the kind of

577
00:19:52,559 --> 00:19:54,400
idea of it infecting other users and

578
00:19:54,400 --> 00:19:55,760
stuff what we did was we took the

579
00:19:55,760 --> 00:19:57,679
username the hostname we basically

580
00:19:57,679 --> 00:19:59,840
generated a hash from that and then we

581
00:19:59,840 --> 00:20:02,320
hard coded hash values into the payload

582
00:20:02,320 --> 00:20:04,240
the reason we did it like trying to copy

583
00:20:04,240 --> 00:20:05,440
it and we didn't just the username

584
00:20:05,440 --> 00:20:06,880
hostname was we wanted to see if our

585
00:20:06,880 --> 00:20:08,480
blue team actually got to the stage of

586
00:20:08,480 --> 00:20:10,559
reverse engineering the actual malware

587
00:20:10,559 --> 00:20:12,720
along with this we did hard code the

588
00:20:12,720 --> 00:20:15,280
actual execution times so start time was

589
00:20:15,280 --> 00:20:17,600
like 905 and then end time was in the

590
00:20:17,600 --> 00:20:19,440
afternoon

591
00:20:19,440 --> 00:20:21,039
we originally were trying to figure out

592
00:20:21,039 --> 00:20:22,960
how to deploy this and so what we did

593
00:20:22,960 --> 00:20:24,640
was we got something from our it team

594
00:20:24,640 --> 00:20:27,360
who runs sccm and we just asked them if

595
00:20:27,360 --> 00:20:29,120
they would run it for us and they were

596
00:20:29,120 --> 00:20:31,360
like well so they managed to they set

597
00:20:31,360 --> 00:20:32,640
out for us they got it basically

598
00:20:32,640 --> 00:20:34,080
deploying at nine o'clock and then we

599
00:20:34,080 --> 00:20:36,320
executed the attack

600
00:20:36,320 --> 00:20:38,000
that was the honestly executing the

601
00:20:38,000 --> 00:20:39,600
attack was the easiest part but it was

602
00:20:39,600 --> 00:20:41,600
very tense in the morning

603
00:20:41,600 --> 00:20:43,600
following that uh

604
00:20:43,600 --> 00:20:45,840
we had uh we basically called off the

605
00:20:45,840 --> 00:20:48,240
exercise and fair play to our blue team

606
00:20:48,240 --> 00:20:50,480
they were able to discover the payload

607
00:20:50,480 --> 00:20:53,520
and who made the sccm job which happened

608
00:20:53,520 --> 00:20:55,760
to be a friend in i.t

609
00:20:55,760 --> 00:20:57,840
and then they began taking action such

610
00:20:57,840 --> 00:21:00,000
as locking his account and talking to hr

611
00:21:00,000 --> 00:21:01,440
about it so as soon as that started

612
00:21:01,440 --> 00:21:03,280
happening we were like hey let's call

613
00:21:03,280 --> 00:21:05,520
the exercise off and it was like an hour

614
00:21:05,520 --> 00:21:07,440
and a half two hours into the exercise

615
00:21:07,440 --> 00:21:09,120
we decided to end it because this stuff

616
00:21:09,120 --> 00:21:10,720
was going on we didn't want to get in

617
00:21:10,720 --> 00:21:11,679
trouble

618
00:21:11,679 --> 00:21:13,200
so following that the most important

619
00:21:13,200 --> 00:21:14,559
part of this whole process was to

620
00:21:14,559 --> 00:21:16,159
perform an after-action review and this

621
00:21:16,159 --> 00:21:17,280
was where

622
00:21:17,280 --> 00:21:20,320
i i myself with our c-cert team lead

623
00:21:20,320 --> 00:21:22,400
basically got together and we we made an

624
00:21:22,400 --> 00:21:26,159
rca document uh root cause analysis

625
00:21:26,159 --> 00:21:28,000
and basically we went ahead and we

626
00:21:28,000 --> 00:21:29,840
interviewed the victims that's an

627
00:21:29,840 --> 00:21:31,120
important thing to do if you do this

628
00:21:31,120 --> 00:21:32,799
because you learn a lot about how they

629
00:21:32,799 --> 00:21:34,720
think and how they would go about

630
00:21:34,720 --> 00:21:36,640
reporting it what they are doing and you

631
00:21:36,640 --> 00:21:38,159
end up finding a lot of stuff that you

632
00:21:38,159 --> 00:21:40,000
wouldn't have normally because you think

633
00:21:40,000 --> 00:21:42,240
they'll call caesar they don't they call

634
00:21:42,240 --> 00:21:43,760
lots of other teams they call like help

635
00:21:43,760 --> 00:21:45,840
desk physical security and stuff they

636
00:21:45,840 --> 00:21:47,919
don't know what to what to do

637
00:21:47,919 --> 00:21:49,280
the next thing because we had a lot of

638
00:21:49,280 --> 00:21:51,200
calls go to our actual help desk and

639
00:21:51,200 --> 00:21:52,640
there were some issues with our help

640
00:21:52,640 --> 00:21:55,200
desk effect in our investigation process

641
00:21:55,200 --> 00:21:57,679
um basically we we interviewed them as

642
00:21:57,679 --> 00:21:59,200
well we found out what happened what

643
00:21:59,200 --> 00:22:00,960
their thing was and we ended up

644
00:22:00,960 --> 00:22:02,400
improving their which we'll talk about

645
00:22:02,400 --> 00:22:04,159
in a second we also interviewed the

646
00:22:04,159 --> 00:22:05,919
analysts not just the people who were

647
00:22:05,919 --> 00:22:07,600
looking into where the payload was and

648
00:22:07,600 --> 00:22:09,360
where i was coming from but the people

649
00:22:09,360 --> 00:22:10,960
taking the calls and dealing with the

650
00:22:10,960 --> 00:22:13,039
victims because it's

651
00:22:13,039 --> 00:22:14,960
very high stress and everyone's like

652
00:22:14,960 --> 00:22:16,880
running around ah kind of thing so it's

653
00:22:16,880 --> 00:22:18,799
like really good uh with all this stuff

654
00:22:18,799 --> 00:22:21,039
we then basically had to present the

655
00:22:21,039 --> 00:22:24,080
findings to our cso and our cto and uh

656
00:22:24,080 --> 00:22:25,919
this is some of the lessons we learned

657
00:22:25,919 --> 00:22:27,600
from it

658
00:22:27,600 --> 00:22:28,559
all right

659
00:22:28,559 --> 00:22:30,880
so what we learned uh out of these 60

660
00:22:30,880 --> 00:22:32,799
plus people that we targeted like 92

661
00:22:32,799 --> 00:22:35,440
percent of them reported back um which

662
00:22:35,440 --> 00:22:36,799
looks bad

663
00:22:36,799 --> 00:22:38,799
when you look at it but we later found

664
00:22:38,799 --> 00:22:40,080
out the remaining people who didn't

665
00:22:40,080 --> 00:22:42,159
respond like were on pto that day so

666
00:22:42,159 --> 00:22:43,200
hard luck

667
00:22:43,200 --> 00:22:46,320
uh the first report was uh reported back

668
00:22:46,320 --> 00:22:48,640
to the third team within within probably

669
00:22:48,640 --> 00:22:51,039
a minute under a minute because we had

670
00:22:51,039 --> 00:22:53,360
our senior director like in the office

671
00:22:53,360 --> 00:22:56,159
and uh when she was hit at nine nine am

672
00:22:56,159 --> 00:22:58,000
she would just go to the stock team and

673
00:22:58,000 --> 00:23:00,000
like you know get them into highland

674
00:23:00,000 --> 00:23:01,200
immediately

675
00:23:01,200 --> 00:23:04,159
uh lastly like um the blue team was able

676
00:23:04,159 --> 00:23:06,720
to identify the ransomware like almost

677
00:23:06,720 --> 00:23:09,120
like within an hour uh and then we were

678
00:23:09,120 --> 00:23:11,919
taking remediation steps after that so

679
00:23:11,919 --> 00:23:13,679
which is great uh we had like people

680
00:23:13,679 --> 00:23:16,320
come back from like their ptos just to

681
00:23:16,320 --> 00:23:18,480
help them out over there so that was

682
00:23:18,480 --> 00:23:21,840
pretty good engagement uh as uh the

683
00:23:21,840 --> 00:23:25,360
alert was pretty high severity

684
00:23:26,000 --> 00:23:27,520
secondly uh

685
00:23:27,520 --> 00:23:30,080
one thing that we didn't plan for was uh

686
00:23:30,080 --> 00:23:31,520
the number of phone calls that were

687
00:23:31,520 --> 00:23:33,520
reporting it back it turns out that we

688
00:23:33,520 --> 00:23:35,679
didn't have a system in place to handle

689
00:23:35,679 --> 00:23:37,919
like 60 plus calls

690
00:23:37,919 --> 00:23:40,640
to the third team and luckily we

691
00:23:40,640 --> 00:23:42,559
discovered it during the exercise and

692
00:23:42,559 --> 00:23:45,919
were able to remediate it by uh before

693
00:23:45,919 --> 00:23:48,720
we had a real one earlier so

694
00:23:48,720 --> 00:23:50,320
the second issue the next issue that we

695
00:23:50,320 --> 00:23:53,679
found was um that the help desk

696
00:23:53,679 --> 00:23:57,279
uh staff was asking the users to

697
00:23:57,279 --> 00:23:59,360
shut down their machines and hand over

698
00:23:59,360 --> 00:24:01,840
the machines for investigation but uh in

699
00:24:01,840 --> 00:24:03,440
reality like that's not the best

700
00:24:03,440 --> 00:24:05,200
practice

701
00:24:05,200 --> 00:24:06,880
you you could actually lose your

702
00:24:06,880 --> 00:24:09,679
evidence during that time frame and

703
00:24:09,679 --> 00:24:11,840
rather than you want to have the edr

704
00:24:11,840 --> 00:24:14,640
system isolate the system uh isolate the

705
00:24:14,640 --> 00:24:17,279
machines and do the investigative

706
00:24:17,279 --> 00:24:19,039
task after that

707
00:24:19,039 --> 00:24:21,520
and lastly

708
00:24:21,520 --> 00:24:24,000
during big incidents we tend to include

709
00:24:24,000 --> 00:24:27,039
a lot of smes from different areas

710
00:24:27,039 --> 00:24:29,919
to help them out to help us out and this

711
00:24:29,919 --> 00:24:31,679
was one of the case where one of the

712
00:24:31,679 --> 00:24:34,320
smes who was an admin

713
00:24:34,320 --> 00:24:37,120
and helped sean to deploy the ransomware

714
00:24:37,120 --> 00:24:38,240
across

715
00:24:38,240 --> 00:24:39,520
all the machines

716
00:24:39,520 --> 00:24:41,520
was present and as we found out that

717
00:24:41,520 --> 00:24:45,279
this was done using sccm

718
00:24:45,279 --> 00:24:47,039
we we actually

719
00:24:47,039 --> 00:24:49,279
had to create another bridge and

720
00:24:49,279 --> 00:24:50,320
let the

721
00:24:50,320 --> 00:24:53,279
uh the initial user on the older bridge

722
00:24:53,279 --> 00:24:55,200
so that you know keep up the appearance

723
00:24:55,200 --> 00:24:58,000
and uh make sure that the insider is not

724
00:24:58,000 --> 00:25:01,279
aware of what we are doing next

725
00:25:01,279 --> 00:25:03,120
all right with that shot yeah that's

726
00:25:03,120 --> 00:25:04,320
something you don't want by the way you

727
00:25:04,320 --> 00:25:05,760
don't want the person doing the attack

728
00:25:05,760 --> 00:25:08,400
on your bridge when you're investigating

729
00:25:08,400 --> 00:25:10,240
uh so we're going to talk about red team

730
00:25:10,240 --> 00:25:12,320
i'm not going to dive into any of the

731
00:25:12,320 --> 00:25:13,919
details of what we did but just at a

732
00:25:13,919 --> 00:25:15,919
high level this is basically where one

733
00:25:15,919 --> 00:25:17,679
of our red teamers will come along

734
00:25:17,679 --> 00:25:19,520
compromise some systems and if we're

735
00:25:19,520 --> 00:25:21,440
emulating a specific fret

736
00:25:21,440 --> 00:25:22,799
uh depending on that would end up

737
00:25:22,799 --> 00:25:24,720
deploying the ransomware

738
00:25:24,720 --> 00:25:26,480
and then this the idea being that we'd

739
00:25:26,480 --> 00:25:27,919
understand our detection and response

740
00:25:27,919 --> 00:25:29,120
these are

741
00:25:29,120 --> 00:25:31,679
more kind of isolated to like one or two

742
00:25:31,679 --> 00:25:33,760
boxes that aren't critical because we

743
00:25:33,760 --> 00:25:35,840
don't want to impact business and

744
00:25:35,840 --> 00:25:37,919
you know it's it's ransomware and people

745
00:25:37,919 --> 00:25:40,000
run around and be scared so we tend not

746
00:25:40,000 --> 00:25:41,039
to do that that's why we took the

747
00:25:41,039 --> 00:25:42,960
simulation approach because it was a lot

748
00:25:42,960 --> 00:25:44,960
safer

749
00:25:44,960 --> 00:25:46,880
following this uh we present our

750
00:25:46,880 --> 00:25:49,360
findings we do some remediation work

751
00:25:49,360 --> 00:25:51,279
so something that we've been doing and

752
00:25:51,279 --> 00:25:53,200
we've been like for new things and like

753
00:25:53,200 --> 00:25:55,919
log4j was kind of like an example of one

754
00:25:55,919 --> 00:25:56,880
of these

755
00:25:56,880 --> 00:25:58,000
and i'll give another example in a

756
00:25:58,000 --> 00:26:00,400
minute is this idea of using intel

757
00:26:00,400 --> 00:26:02,960
uh intel driven response uh and we ended

758
00:26:02,960 --> 00:26:04,960
up like having our own process around

759
00:26:04,960 --> 00:26:06,080
this so

760
00:26:06,080 --> 00:26:08,080
uh what typically would happen is we'll

761
00:26:08,080 --> 00:26:10,400
get fret intel or something will be like

762
00:26:10,400 --> 00:26:13,039
our news or trend and this will only be

763
00:26:13,039 --> 00:26:15,200
end up pointing to a new fret

764
00:26:15,200 --> 00:26:17,600
uh like you would expect we go we go and

765
00:26:17,600 --> 00:26:19,600
do our threat hunting for that we go to

766
00:26:19,600 --> 00:26:20,799
make sure we don't have it in our

767
00:26:20,799 --> 00:26:22,400
environment and we're not already

768
00:26:22,400 --> 00:26:24,799
affected by it then we end up like you

769
00:26:24,799 --> 00:26:27,440
know applying fixes trying to add blocks

770
00:26:27,440 --> 00:26:30,320
or ics taking those steps

771
00:26:30,320 --> 00:26:32,159
as well as looking at basically

772
00:26:32,159 --> 00:26:33,919
understanding if we already have rules

773
00:26:33,919 --> 00:26:35,279
in place to detect this and be able to

774
00:26:35,279 --> 00:26:36,240
block it

775
00:26:36,240 --> 00:26:39,120
now previously this was kind of just all

776
00:26:39,120 --> 00:26:40,880
blue team uh what we've been doing more

777
00:26:40,880 --> 00:26:43,039
and more now is including the red team

778
00:26:43,039 --> 00:26:44,720
in this process and so it's ended up

779
00:26:44,720 --> 00:26:46,400
being more focused powerful team

780
00:26:46,400 --> 00:26:49,200
exercises and now these are not not huge

781
00:26:49,200 --> 00:26:52,159
kind of uh like maybe a couple every day

782
00:26:52,159 --> 00:26:54,240
of work for the red team and stuff but

783
00:26:54,240 --> 00:26:56,480
the idea being that we can apply we can

784
00:26:56,480 --> 00:26:58,159
test things before they happen so we can

785
00:26:58,159 --> 00:27:00,559
test our rules test blocks are working

786
00:27:00,559 --> 00:27:02,720
as well as being able to test any fixes

787
00:27:02,720 --> 00:27:04,559
that we are deploying before they get

788
00:27:04,559 --> 00:27:06,240
pushed out because we're quite a big

789
00:27:06,240 --> 00:27:08,480
company so uh pushing out a fix that

790
00:27:08,480 --> 00:27:10,640
doesn't work or break something is kind

791
00:27:10,640 --> 00:27:11,600
of bad

792
00:27:11,600 --> 00:27:13,679
so with that in mind i'm gonna dive into

793
00:27:13,679 --> 00:27:16,240
an example of this and one of the more

794
00:27:16,240 --> 00:27:17,919
recent ones that we did was the uh

795
00:27:17,919 --> 00:27:19,520
microsoft

796
00:27:19,520 --> 00:27:22,640
diagnostic tool rcu fiona

797
00:27:22,640 --> 00:27:25,679
and basically this was a url handler bug

798
00:27:25,679 --> 00:27:27,279
that allowed you to remotely execute

799
00:27:27,279 --> 00:27:28,559
code so

800
00:27:28,559 --> 00:27:30,799
and was being exploited in the wild

801
00:27:30,799 --> 00:27:33,279
basically a word document you open it

802
00:27:33,279 --> 00:27:35,440
execute it calls that url handler uh

803
00:27:35,440 --> 00:27:38,240
through ole and you end up with rc

804
00:27:38,240 --> 00:27:40,640
another time there was no patch and it

805
00:27:40,640 --> 00:27:43,039
hadn't had gone public at this point um

806
00:27:43,039 --> 00:27:44,799
a friend of mine richard warren told me

807
00:27:44,799 --> 00:27:45,840
about it

808
00:27:45,840 --> 00:27:48,480
um following this uh with the hash we

809
00:27:48,480 --> 00:27:50,640
went off to virustoyo because we love

810
00:27:50,640 --> 00:27:52,640
virustotal uh and we managed to get

811
00:27:52,640 --> 00:27:54,960
ourselves a sample of this malware

812
00:27:54,960 --> 00:27:56,240
now

813
00:27:56,240 --> 00:27:58,480
i you can do this with like zip uh

814
00:27:58,480 --> 00:28:01,200
basically a docx is just a zip file so

815
00:28:01,200 --> 00:28:03,120
you can use that to kind of open them up

816
00:28:03,120 --> 00:28:05,279
but i love server suite it's really good

817
00:28:05,279 --> 00:28:07,440
and it has some stuff where it will like

818
00:28:07,440 --> 00:28:08,960
tell you if it's doing external

819
00:28:08,960 --> 00:28:11,200
references

820
00:28:11,200 --> 00:28:13,919
external calls to stuff and uh in this

821
00:28:13,919 --> 00:28:15,679
case you know you just end up clicking

822
00:28:15,679 --> 00:28:16,960
that rather than having to look through

823
00:28:16,960 --> 00:28:18,480
it but in this case there was an hourly

824
00:28:18,480 --> 00:28:20,480
pointing at this domain

825
00:28:20,480 --> 00:28:22,880
um so with that so now we kind of

826
00:28:22,880 --> 00:28:25,279
understood how it was being executed uh

827
00:28:25,279 --> 00:28:27,360
when you open the word document and

828
00:28:27,360 --> 00:28:28,880
basically we took that url went to

829
00:28:28,880 --> 00:28:30,720
virustotal and we were able to get the

830
00:28:30,720 --> 00:28:33,360
actual exploit uh from there so we

831
00:28:33,360 --> 00:28:34,880
basically decided to make our own

832
00:28:34,880 --> 00:28:36,399
version of this because we already had

833
00:28:36,399 --> 00:28:38,159
everything

834
00:28:38,159 --> 00:28:40,159
we went ahead changed out the urls to be

835
00:28:40,159 --> 00:28:41,600
ours because we didn't want to send it

836
00:28:41,600 --> 00:28:43,600
to the attacker and we ended up changing

837
00:28:43,600 --> 00:28:45,760
the actual uh execution from the

838
00:28:45,760 --> 00:28:48,000
powershell invoke expression to just

839
00:28:48,000 --> 00:28:50,320
beat calc because you know it's why it's

840
00:28:50,320 --> 00:28:52,559
app so we ended up running this and we

841
00:28:52,559 --> 00:28:54,640
found that we were vulnerable to it and

842
00:28:54,640 --> 00:28:57,279
it did execute perfectly so

843
00:28:57,279 --> 00:28:59,279
that in mind we went about writing some

844
00:28:59,279 --> 00:29:01,600
rules

845
00:29:02,640 --> 00:29:05,440
right thanks uh so as the red team was

846
00:29:05,440 --> 00:29:07,600
running the exploit and testing this out

847
00:29:07,600 --> 00:29:09,600
the blue team on the side was

848
00:29:09,600 --> 00:29:11,440
trying to find out all the iocs and we

849
00:29:11,440 --> 00:29:13,360
were able to find a bunch of them which

850
00:29:13,360 --> 00:29:16,080
we then used to develop watchlist on our

851
00:29:16,080 --> 00:29:18,080
adr system and use that watchlist to

852
00:29:18,080 --> 00:29:20,320
scan across the whole environment

853
00:29:20,320 --> 00:29:21,919
luckily there wasn't much uh there

854
00:29:21,919 --> 00:29:25,120
wasn't any uh results so we're pretty

855
00:29:25,120 --> 00:29:27,120
happy with that uh

856
00:29:27,120 --> 00:29:27,919
next

857
00:29:27,919 --> 00:29:29,520
so

858
00:29:29,520 --> 00:29:31,760
when we wanted to test this we we found

859
00:29:31,760 --> 00:29:33,520
out that this exploit could be tested

860
00:29:33,520 --> 00:29:36,240
using uh could be executed using a dot

861
00:29:36,240 --> 00:29:39,200
rtf file or a dot docx file hence uh we

862
00:29:39,200 --> 00:29:41,120
wanted to test them out so we started

863
00:29:41,120 --> 00:29:43,600
with a rdf file which

864
00:29:43,600 --> 00:29:47,039
got uh detected by our edr system carbon

865
00:29:47,039 --> 00:29:48,960
black and

866
00:29:48,960 --> 00:29:52,240
since this was like a very similar ioc

867
00:29:52,240 --> 00:29:56,480
from like a older cve from 2017 the

868
00:29:56,480 --> 00:29:58,880
edr system was able to block it

869
00:29:58,880 --> 00:30:02,159
secondly when we ran the docx file it

870
00:30:02,159 --> 00:30:04,880
did not block it and we had to create a

871
00:30:04,880 --> 00:30:06,960
rule around it to see if there was any

872
00:30:06,960 --> 00:30:09,919
hits around it and we even eventually

873
00:30:09,919 --> 00:30:12,240
reported it back to current black on

874
00:30:12,240 --> 00:30:14,080
that

875
00:30:14,080 --> 00:30:17,120
all right in some uh so uh we

876
00:30:17,120 --> 00:30:19,679
eventually also found out that microsoft

877
00:30:19,679 --> 00:30:21,520
had released a workaround which was

878
00:30:21,520 --> 00:30:23,200
essentially that they were recommending

879
00:30:23,200 --> 00:30:26,080
us to delete the registry file in order

880
00:30:26,080 --> 00:30:28,320
registry keef in order to

881
00:30:28,320 --> 00:30:32,000
block this exploit to be working so the

882
00:30:32,000 --> 00:30:35,120
red team wanted to test this out we

883
00:30:35,120 --> 00:30:36,640
deployed this on a bunch of test

884
00:30:36,640 --> 00:30:37,600
machines

885
00:30:37,600 --> 00:30:39,440
the team tested it out and made sure

886
00:30:39,440 --> 00:30:41,679
everything was working so once that was

887
00:30:41,679 --> 00:30:44,320
complete we then deployed the fix using

888
00:30:44,320 --> 00:30:47,120
sccm to more than 15 000 hosts in our

889
00:30:47,120 --> 00:30:49,039
environment

890
00:30:49,039 --> 00:30:51,360
so in summary uh we were able to utilize

891
00:30:51,360 --> 00:30:54,000
the workaround and build detections

892
00:30:54,000 --> 00:30:55,919
within the first 48 hours of it being

893
00:30:55,919 --> 00:30:58,880
publicly disclosed six people from four

894
00:30:58,880 --> 00:31:00,320
different teams were involved to get

895
00:31:00,320 --> 00:31:02,320
this work done and

896
00:31:02,320 --> 00:31:04,320
all of this was tested and validated by

897
00:31:04,320 --> 00:31:05,600
the dead team

898
00:31:05,600 --> 00:31:08,240
so uh sean you have any closing thoughts

899
00:31:08,240 --> 00:31:10,960
yeah um so one of the things that we

900
00:31:10,960 --> 00:31:12,960
kind of want to call out in this is the

901
00:31:12,960 --> 00:31:15,120
collaboration between your teams red and

902
00:31:15,120 --> 00:31:17,120
blue like i said the best defense is

903
00:31:17,120 --> 00:31:19,600
offense um collaboration between those

904
00:31:19,600 --> 00:31:21,519
team actually does have a significant

905
00:31:21,519 --> 00:31:23,840
impact and we're we're doing a lot of

906
00:31:23,840 --> 00:31:25,840
stuff within our ebay to make sure this

907
00:31:25,840 --> 00:31:27,360
is the case and we test a lot of things

908
00:31:27,360 --> 00:31:28,559
out so

909
00:31:28,559 --> 00:31:30,000
we see a lot of major benefits we're

910
00:31:30,000 --> 00:31:31,919
able to move faster as well with our

911
00:31:31,919 --> 00:31:33,919
detections and rules and blocking these

912
00:31:33,919 --> 00:31:36,720
threats as they come about like the

913
00:31:36,720 --> 00:31:40,080
uh cbu one we just gave

914
00:31:40,080 --> 00:31:42,399
next uh you might not have a red team

915
00:31:42,399 --> 00:31:43,440
you might not have people who can

916
00:31:43,440 --> 00:31:45,440
reverse engineer malware and stuff but

917
00:31:45,440 --> 00:31:48,159
sandboxing is very low cost and it's a

918
00:31:48,159 --> 00:31:50,480
really easy way to kind of test your

919
00:31:50,480 --> 00:31:52,640
controls and get that kind of insight

920
00:31:52,640 --> 00:31:54,559
into whether or not some tool that

921
00:31:54,559 --> 00:31:56,159
you're spending a lot of money to for

922
00:31:56,159 --> 00:31:58,799
actually works compared to not so i

923
00:31:58,799 --> 00:32:00,320
would highly recommend people do like

924
00:32:00,320 --> 00:32:02,480
sandboxing with their normal kind of edr

925
00:32:02,480 --> 00:32:04,320
solution and stuff in it and just get

926
00:32:04,320 --> 00:32:06,000
malware samples and drop them in and see

927
00:32:06,000 --> 00:32:07,039
what happens

928
00:32:07,039 --> 00:32:09,440
as a regular kind of thing

929
00:32:09,440 --> 00:32:10,320
next

930
00:32:10,320 --> 00:32:12,000
the simulation show is stuff that we

931
00:32:12,000 --> 00:32:14,399
would have never found normally or we

932
00:32:14,399 --> 00:32:16,080
would have only found out about when it

933
00:32:16,080 --> 00:32:18,480
was an actual incident

934
00:32:18,480 --> 00:32:19,440
which

935
00:32:19,440 --> 00:32:20,880
you know so it was kind of like really

936
00:32:20,880 --> 00:32:22,399
good on that side and it showed us a lot

937
00:32:22,399 --> 00:32:24,880
of gaps and we ended up improving quite

938
00:32:24,880 --> 00:32:26,240
a bit from that

939
00:32:26,240 --> 00:32:29,279
next um this kind of program overview

940
00:32:29,279 --> 00:32:30,559
that we're done with like the pulp

941
00:32:30,559 --> 00:32:32,480
teaming the simulation stuff and the red

942
00:32:32,480 --> 00:32:35,760
team uh it's safe it's meant as like a

943
00:32:35,760 --> 00:32:37,919
safe process to just like doing red

944
00:32:37,919 --> 00:32:40,000
teaming without doing red teaming to

945
00:32:40,000 --> 00:32:41,919
affect the organization especially like

946
00:32:41,919 --> 00:32:43,600
ransomware you can't deploy it across

947
00:32:43,600 --> 00:32:45,760
all your hosts so it would work with

948
00:32:45,760 --> 00:32:48,159
other frets like insider

949
00:32:48,159 --> 00:32:49,840
so we recommend like you know you could

950
00:32:49,840 --> 00:32:51,760
take that kind of format that we've got

951
00:32:51,760 --> 00:32:53,679
here and use it for anything so uh with

952
00:32:53,679 --> 00:32:55,679
that just want to say like thank you uh

953
00:32:55,679 --> 00:32:57,120
for coming to our talk i know it's the

954
00:32:57,120 --> 00:33:00,000
last one of the day so appreciate that

955
00:33:00,000 --> 00:33:02,399
and uh oh

956
00:33:02,399 --> 00:33:06,760
yeah and i guess uh questions

957
00:33:14,960 --> 00:33:18,200
any questions

958
00:33:24,559 --> 00:33:25,919
specifically

959
00:33:25,919 --> 00:33:28,080
did you have sort of a secondary

960
00:33:28,080 --> 00:33:30,320
objective of making it more difficult to

961
00:33:30,320 --> 00:33:33,279
be reversed or did you think oh you know

962
00:33:33,279 --> 00:33:34,799
that's the value of time we don't want

963
00:33:34,799 --> 00:33:38,960
our researchers doing that we want them

964
00:33:45,519 --> 00:33:47,519
sure so the question was did we do

965
00:33:47,519 --> 00:33:49,200
anything around the observation of our

966
00:33:49,200 --> 00:33:51,919
actual uh ransomware when we made it

967
00:33:51,919 --> 00:33:54,000
we when i made it i didn't i'd been

968
00:33:54,000 --> 00:33:56,720
running uh basically how to reverse.net

969
00:33:56,720 --> 00:33:58,880
applications with our blue team uh for a

970
00:33:58,880 --> 00:34:00,559
while so the idea was this was kind of

971
00:34:00,559 --> 00:34:02,480
like a live fire opportunity for them to

972
00:34:02,480 --> 00:34:04,559
actually learn and put those skills that

973
00:34:04,559 --> 00:34:06,960
they learned into kind of use uh this is

974
00:34:06,960 --> 00:34:08,320
the first time we kind of did it so we

975
00:34:08,320 --> 00:34:11,119
decided make it easy but like there was

976
00:34:11,119 --> 00:34:12,719
some like to get the username and the

977
00:34:12,719 --> 00:34:14,320
host name they'd have to look at what we

978
00:34:14,320 --> 00:34:16,079
were doing for hashing and reverse that

979
00:34:16,079 --> 00:34:18,800
so um it would have been good but yeah

980
00:34:18,800 --> 00:34:20,079
maybe next time we're going to make it a

981
00:34:20,079 --> 00:34:22,000
little bit difficult to see

982
00:34:22,000 --> 00:34:24,079
kind of if they have improved and make

983
00:34:24,079 --> 00:34:27,520
it harder but for this case no

984
00:34:27,800 --> 00:34:31,879
cool um

985
00:34:39,440 --> 00:34:41,760
yeah in this case it was more

986
00:34:41,760 --> 00:34:44,800
well sorry the question was

987
00:34:44,800 --> 00:34:47,520
was the focus around timing uh making it

988
00:34:47,520 --> 00:34:48,639
more difficult for them so they had to

989
00:34:48,639 --> 00:34:51,440
spend more time reversing it or not

990
00:34:51,440 --> 00:34:53,599
and what benefits and stuff would be so

991
00:34:53,599 --> 00:34:55,359
for us it was more

992
00:34:55,359 --> 00:34:57,280
we wanted to kind of see how fast they

993
00:34:57,280 --> 00:34:58,560
could get to it

994
00:34:58,560 --> 00:35:00,560
in this case the exercise was mainly

995
00:35:00,560 --> 00:35:03,680
focused around seeing that response

996
00:35:03,680 --> 00:35:06,640
um and we had like a short window and we

997
00:35:06,640 --> 00:35:08,400
did revisit the actual malware and we

998
00:35:08,400 --> 00:35:10,160
went through it with them as well after

999
00:35:10,160 --> 00:35:12,720
the exercise but they would have quickly

1000
00:35:12,720 --> 00:35:13,839
found out it was the red team because

1001
00:35:13,839 --> 00:35:15,920
there was some comments in the code that

1002
00:35:15,920 --> 00:35:17,760
said it was us and it was like congrats

1003
00:35:17,760 --> 00:35:19,839
kind of thing um but we didn't want to

1004
00:35:19,839 --> 00:35:22,240
like make it too hard for them and like

1005
00:35:22,240 --> 00:35:24,880
spend loads of time doing it all right

1006
00:35:24,880 --> 00:35:27,040
because you know we're a big company and

1007
00:35:27,040 --> 00:35:29,280
we have a lot of incidents so there's a

1008
00:35:29,280 --> 00:35:31,280
you gotta play the risk reward of

1009
00:35:31,280 --> 00:35:34,720
impacting your security team too

1010
00:35:42,839 --> 00:35:46,800
much did you discuss at all about

1011
00:35:46,800 --> 00:35:48,960
the pros and cons of paying a ransom as

1012
00:35:48,960 --> 00:35:50,480
opposed to

1013
00:35:50,480 --> 00:35:53,920
mitigating it or any other way

1014
00:35:53,920 --> 00:35:57,119
sure the question was around

1015
00:35:57,119 --> 00:35:58,560
during the process do we ever think

1016
00:35:58,560 --> 00:36:01,119
about like paying the ransom um in this

1017
00:36:01,119 --> 00:36:04,079
case uh we we typically have tabletops

1018
00:36:04,079 --> 00:36:06,000
know the education part and we do those

1019
00:36:06,000 --> 00:36:07,359
with our executive team and they go

1020
00:36:07,359 --> 00:36:09,839
through the whole process of what when

1021
00:36:09,839 --> 00:36:11,200
the incident would happen at a high

1022
00:36:11,200 --> 00:36:13,119
level this is what we would do and then

1023
00:36:13,119 --> 00:36:15,200
they're given like the option of like

1024
00:36:15,200 --> 00:36:16,800
you know pay or not and then they go

1025
00:36:16,800 --> 00:36:18,800
through the whole process and this is

1026
00:36:18,800 --> 00:36:19,839
kind of

1027
00:36:19,839 --> 00:36:21,680
more of a legal question

1028
00:36:21,680 --> 00:36:22,880
because you know with the whole

1029
00:36:22,880 --> 00:36:24,880
government uh regulations on it because

1030
00:36:24,880 --> 00:36:27,200
i think they class ransomware actors as

1031
00:36:27,200 --> 00:36:28,960
pretty much funding terrorism if you do

1032
00:36:28,960 --> 00:36:30,400
pay the ransom and stuff like that i

1033
00:36:30,400 --> 00:36:32,880
think um so that'd be that's more of our

1034
00:36:32,880 --> 00:36:34,960
legal team to cover that stuff than us

1035
00:36:34,960 --> 00:36:37,920
does that make sense that answer it cool

1036
00:36:37,920 --> 00:36:40,160
well i mean i realize it's it's more of

1037
00:36:40,160 --> 00:36:42,720
a legal question i'm just curious

1038
00:36:42,720 --> 00:36:44,480
what you came up with on that because

1039
00:36:44,480 --> 00:36:47,119
like jb for example last year their

1040
00:36:47,119 --> 00:36:49,760
ransomware attack

1041
00:36:49,760 --> 00:36:51,839
and there's like various cost

1042
00:36:51,839 --> 00:36:53,599
estimations as to

1043
00:36:53,599 --> 00:36:58,240
whether it's more prudent to do x and y

1044
00:36:58,320 --> 00:37:00,640
yeah there's there's companies that you

1045
00:37:00,640 --> 00:37:03,359
can hire to pay the ransom for you that

1046
00:37:03,359 --> 00:37:05,680
are not based in the us as i understand

1047
00:37:05,680 --> 00:37:07,359
it and that's how you can get past some

1048
00:37:07,359 --> 00:37:09,440
of that stuff but again it's like more

1049
00:37:09,440 --> 00:37:12,160
of a more of the executive leadership

1050
00:37:12,160 --> 00:37:14,079
legal counsel kind of decision to be

1051
00:37:14,079 --> 00:37:16,079
made on that front so

1052
00:37:16,079 --> 00:37:17,520
cool

1053
00:37:17,520 --> 00:37:21,160
any other questions

1054
00:37:22,400 --> 00:37:24,720
i can't see you

1055
00:37:24,720 --> 00:37:26,960
cool well awesome thank you everyone for

1056
00:37:26,960 --> 00:37:29,119
uh coming to our talk i know it's like

1057
00:37:29,119 --> 00:37:31,520
beer time now right so

1058
00:37:31,520 --> 00:37:35,720
thank you guys thank you

