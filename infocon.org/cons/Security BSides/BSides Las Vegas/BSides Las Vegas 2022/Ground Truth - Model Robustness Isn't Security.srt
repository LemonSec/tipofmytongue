1
00:00:00,840 --> 00:00:03,120
hey good afternoon welcome to b-sides

2
00:00:03,120 --> 00:00:07,680
Las Vegas ground truth this talk is

3
00:00:07,680 --> 00:00:10,500
right oh the slide

4
00:00:10,500 --> 00:00:13,559
model robustness isn't security by Sven

5
00:00:13,559 --> 00:00:16,020
cattle a few announcements before we

6
00:00:16,020 --> 00:00:17,880
begin we'd like to thank our sponsors

7
00:00:17,880 --> 00:00:20,279
especially our Diamond sponsors LastPass

8
00:00:20,279 --> 00:00:22,920
and Palo Alto networks and our gold

9
00:00:22,920 --> 00:00:26,340
sponsors Amazon Intel and Google it is

10
00:00:26,340 --> 00:00:27,720
their support along with our other

11
00:00:27,720 --> 00:00:29,699
sponsors donors and volunteers that make

12
00:00:29,699 --> 00:00:32,040
this event possible the talks are being

13
00:00:32,040 --> 00:00:33,840
live streamed except for underground

14
00:00:33,840 --> 00:00:35,880
track and as a courtesy to our speakers

15
00:00:35,880 --> 00:00:38,219
and audience we ask that you check to

16
00:00:38,219 --> 00:00:39,660
make sure your cell phones are set to

17
00:00:39,660 --> 00:00:42,120
silent or vibrate if you have a question

18
00:00:42,120 --> 00:00:45,120
raise your hand we currently don't have

19
00:00:45,120 --> 00:00:47,160
the wireless mics active so you will

20
00:00:47,160 --> 00:00:49,440
have to like speak kind of loud and

21
00:00:49,440 --> 00:00:50,820
we'll just have the speaker repeat your

22
00:00:50,820 --> 00:00:52,320
question

23
00:00:52,320 --> 00:00:54,420
um there's interference from the mics in

24
00:00:54,420 --> 00:00:57,840
another room so that's what we got to do

25
00:00:57,840 --> 00:00:59,840
um

26
00:01:00,000 --> 00:01:02,100
as a reminder the b-sides LV photo

27
00:01:02,100 --> 00:01:04,019
policy prohibits taking pictures without

28
00:01:04,019 --> 00:01:05,820
the explicit permission of everyone in

29
00:01:05,820 --> 00:01:08,159
frame these talks are all being recorded

30
00:01:08,159 --> 00:01:10,020
except of course in underground and will

31
00:01:10,020 --> 00:01:12,540
be available on YouTube in the future we

32
00:01:12,540 --> 00:01:14,159
would like you to please keep your masks

33
00:01:14,159 --> 00:01:16,080
on at all times and if you need to move

34
00:01:16,080 --> 00:01:18,960
closer to people to adjust your view or

35
00:01:18,960 --> 00:01:20,700
hearing please also respect social

36
00:01:20,700 --> 00:01:23,220
distancing with that let's get started

37
00:01:23,220 --> 00:01:25,939
welcome Sven

38
00:01:27,840 --> 00:01:30,799
thank you

39
00:01:31,079 --> 00:01:32,400
hi

40
00:01:32,400 --> 00:01:35,880
um so I'm sankatel and this is my talk

41
00:01:35,880 --> 00:01:38,579
on model robustness and security

42
00:01:38,579 --> 00:01:40,380
um

43
00:01:40,380 --> 00:01:41,460
okay

44
00:01:41,460 --> 00:01:44,280
uh so

45
00:01:44,280 --> 00:01:46,259
I'm giving this talk because there's

46
00:01:46,259 --> 00:01:49,439
some movements in the policy space and a

47
00:01:49,439 --> 00:01:52,079
lot of academic thing that is claiming

48
00:01:52,079 --> 00:01:53,880
that model robustness is absolutely

49
00:01:53,880 --> 00:01:57,479
essential for security and um I know of

50
00:01:57,479 --> 00:02:00,600
No One Security Company who actually

51
00:02:00,600 --> 00:02:02,579
thinks model robustness should be

52
00:02:02,579 --> 00:02:05,040
included in security and dozens that

53
00:02:05,040 --> 00:02:07,320
think but this is pointless

54
00:02:07,320 --> 00:02:09,538
um but because there's a lot of loud

55
00:02:09,538 --> 00:02:11,520
people that are arguing that this is

56
00:02:11,520 --> 00:02:14,580
security yeah this is a thing

57
00:02:14,580 --> 00:02:16,860
so about me

58
00:02:16,860 --> 00:02:18,599
um I founded a startup sort of in this

59
00:02:18,599 --> 00:02:20,160
space doesn't actually relate to model

60
00:02:20,160 --> 00:02:21,780
robustness

61
00:02:21,780 --> 00:02:23,459
um I've got a PhD in algebraic topology

62
00:02:23,459 --> 00:02:26,220
uh from Johns Hopkins and a postdoc in

63
00:02:26,220 --> 00:02:28,200
geometric machine learning

64
00:02:28,200 --> 00:02:31,440
um I founded the AI Village uh six years

65
00:02:31,440 --> 00:02:33,120
ago we're going to be at Defcon for the

66
00:02:33,120 --> 00:02:35,580
fifth time this year so

67
00:02:35,580 --> 00:02:37,800
um I used to work at endgame elastic on

68
00:02:37,800 --> 00:02:40,560
their large large malware models

69
00:02:40,560 --> 00:02:42,300
um like what Twitter is a kind of

70
00:02:42,300 --> 00:02:43,980
mathematician you can find the slides on

71
00:02:43,980 --> 00:02:45,360
GitHub

72
00:02:45,360 --> 00:02:47,519
so um

73
00:02:47,519 --> 00:02:50,220
because I'm making an argument that is a

74
00:02:50,220 --> 00:02:53,580
little thing here I have a lot of slides

75
00:02:53,580 --> 00:02:56,099
you can see there's uh 55 of them

76
00:02:56,099 --> 00:02:56,879
um

77
00:02:56,879 --> 00:02:58,920
so some of these slides that are here

78
00:02:58,920 --> 00:03:01,019
mostly to cover my ass in the argument

79
00:03:01,019 --> 00:03:04,560
space that aren't necessarily here for

80
00:03:04,560 --> 00:03:06,480
the narrative

81
00:03:06,480 --> 00:03:10,040
um so this is mainly a argument about

82
00:03:10,040 --> 00:03:13,379
definitions because things this is a

83
00:03:13,379 --> 00:03:15,480
there's a technical definition in the

84
00:03:15,480 --> 00:03:17,159
Layman's definition and they're a bit

85
00:03:17,159 --> 00:03:17,879
different

86
00:03:17,879 --> 00:03:20,819
so the Layman definition that is here

87
00:03:20,819 --> 00:03:22,620
for

88
00:03:22,620 --> 00:03:25,980
um everyone uh it is here

89
00:03:25,980 --> 00:03:28,319
open AI other serial examples are inputs

90
00:03:28,319 --> 00:03:30,299
between machine learning models that the

91
00:03:30,299 --> 00:03:31,980
attacker has intentionally designed to

92
00:03:31,980 --> 00:03:33,599
close the model to make a mistake

93
00:03:33,599 --> 00:03:35,280
they're like optical illusions for

94
00:03:35,280 --> 00:03:37,319
machines and adversarial examples are

95
00:03:37,319 --> 00:03:39,239
special for tensorflow adversarial

96
00:03:39,239 --> 00:03:41,340
examples they specialize inputs created

97
00:03:41,340 --> 00:03:42,900
with the purpose of confusing a neural

98
00:03:42,900 --> 00:03:44,580
network resulting in this classification

99
00:03:44,580 --> 00:03:46,799
of General input this sounds like a

100
00:03:46,799 --> 00:03:48,780
legit thing that we need to be worried

101
00:03:48,780 --> 00:03:50,280
about we need to worry about adversarial

102
00:03:50,280 --> 00:03:51,540
examples from these two definitions

103
00:03:51,540 --> 00:03:54,180
because specialized input to that causes

104
00:03:54,180 --> 00:03:57,599
misbehavior is sort of the key for a lot

105
00:03:57,599 --> 00:04:00,060
of security a stack Overflow or use

106
00:04:00,060 --> 00:04:01,920
after free bug that's specialized in you

107
00:04:01,920 --> 00:04:03,540
to actually take advantage of that that

108
00:04:03,540 --> 00:04:05,939
specialized input all the Metasploit is

109
00:04:05,939 --> 00:04:08,340
specialized employee so that sounds like

110
00:04:08,340 --> 00:04:11,459
a serious security vulnerability but

111
00:04:11,459 --> 00:04:12,239
um

112
00:04:12,239 --> 00:04:15,180
these are machine learning models so any

113
00:04:15,180 --> 00:04:16,978
model error because these are the

114
00:04:16,978 --> 00:04:19,199
statistical models they are not

115
00:04:19,199 --> 00:04:21,000
guaranteed any model can fit the

116
00:04:21,000 --> 00:04:22,560
definition if you've kind of squinted it

117
00:04:22,560 --> 00:04:25,080
uh this is not actually close to what

118
00:04:25,080 --> 00:04:26,759
the definition of a practitioner is who

119
00:04:26,759 --> 00:04:28,500
actually work in the space mean and if

120
00:04:28,500 --> 00:04:30,240
you use this definition people can sell

121
00:04:30,240 --> 00:04:31,740
you snake oil and even if you don't use

122
00:04:31,740 --> 00:04:33,360
this definition people can sell your

123
00:04:33,360 --> 00:04:36,120
snake oil and snake oil is being sold in

124
00:04:36,120 --> 00:04:38,220
this space

125
00:04:38,220 --> 00:04:40,560
um the definition for a robust model and

126
00:04:40,560 --> 00:04:41,639
the thing is there's two different

127
00:04:41,639 --> 00:04:43,560
meanings of the word robust but this is

128
00:04:43,560 --> 00:04:45,600
what uh gets thrown around for

129
00:04:45,600 --> 00:04:47,220
atmosphere robustness and the other

130
00:04:47,220 --> 00:04:48,960
robustness

131
00:04:48,960 --> 00:04:49,620
um

132
00:04:49,620 --> 00:04:53,699
so it's sort of your model is good and

133
00:04:53,699 --> 00:04:55,680
the problem with that definition is both

134
00:04:55,680 --> 00:04:57,900
of those definitions basically mean your

135
00:04:57,900 --> 00:04:59,460
model is good you haven't you trained it

136
00:04:59,460 --> 00:05:00,479
on enough data that it actually

137
00:05:00,479 --> 00:05:02,100
generalizes well

138
00:05:02,100 --> 00:05:04,080
um and but the problem with this model

139
00:05:04,080 --> 00:05:06,240
is they get to

140
00:05:06,240 --> 00:05:08,699
check that it's robust by wiggling some

141
00:05:08,699 --> 00:05:09,840
minor parameters and not actually

142
00:05:09,840 --> 00:05:12,120
testing on proper stuff

143
00:05:12,120 --> 00:05:14,039
so these are the definitions I'm hoping

144
00:05:14,039 --> 00:05:15,840
you walk away with at the end um and

145
00:05:15,840 --> 00:05:17,699
we're going to go through them Point by

146
00:05:17,699 --> 00:05:18,479
Point

147
00:05:18,479 --> 00:05:20,699
um so if you want go look at the slides

148
00:05:20,699 --> 00:05:21,479
online

149
00:05:21,479 --> 00:05:23,400
um but we're going to get started what

150
00:05:23,400 --> 00:05:24,600
is a neighborhood

151
00:05:24,600 --> 00:05:25,979
so

152
00:05:25,979 --> 00:05:27,240
um this is the definition of a

153
00:05:27,240 --> 00:05:28,620
neighborhood that I use as a

154
00:05:28,620 --> 00:05:31,800
mathematician the first one the so you

155
00:05:31,800 --> 00:05:33,180
see there's two different ones that look

156
00:05:33,180 --> 00:05:36,120
almost centrical one is the L2 Bull and

157
00:05:36,120 --> 00:05:38,639
the one is the L Infinity ball

158
00:05:38,639 --> 00:05:41,160
um and the L2 bull forms spheres that

159
00:05:41,160 --> 00:05:42,840
are nice and neat that you are familiar

160
00:05:42,840 --> 00:05:45,300
with and the L Infinity ball forms cubes

161
00:05:45,300 --> 00:05:47,580
and Hyper cubes and Sears and

162
00:05:47,580 --> 00:05:49,020
hyperspheres

163
00:05:49,020 --> 00:05:51,360
um but that's the definition that I look

164
00:05:51,360 --> 00:05:54,600
at and think Sears and cubes

165
00:05:54,600 --> 00:05:57,419
um but we can't show that to

166
00:05:57,419 --> 00:05:59,940
um executives

167
00:05:59,940 --> 00:06:00,600
um

168
00:06:00,600 --> 00:06:02,600
part of the thing is

169
00:06:02,600 --> 00:06:05,039
neighborhoods get really complicated in

170
00:06:05,039 --> 00:06:07,500
higher Dimensions so here there's a big

171
00:06:07,500 --> 00:06:10,259
sum over K elements and that K could be

172
00:06:10,259 --> 00:06:14,340
3 000 or more in the case of machine

173
00:06:14,340 --> 00:06:17,280
learning and that gets really funky so

174
00:06:17,280 --> 00:06:18,720
I'm going to show you why it gets so

175
00:06:18,720 --> 00:06:22,259
funky this is a classic problem that you

176
00:06:22,259 --> 00:06:24,780
give to little kids uh you know if you

177
00:06:24,780 --> 00:06:26,280
want a rope that goes around the earth

178
00:06:26,280 --> 00:06:28,440
how much longer than the circumference

179
00:06:28,440 --> 00:06:29,699
of the earth do you need to make it it

180
00:06:29,699 --> 00:06:32,460
turns out it's just 2 pi feet longer to

181
00:06:32,460 --> 00:06:35,039
make it sit one foot off the Earth and

182
00:06:35,039 --> 00:06:36,660
if you give this to a little kid they

183
00:06:36,660 --> 00:06:38,460
get confused and tell you it's going to

184
00:06:38,460 --> 00:06:40,500
have to be much longer than that

185
00:06:40,500 --> 00:06:41,340
um

186
00:06:41,340 --> 00:06:43,680
also with dimensionality

187
00:06:43,680 --> 00:06:46,440
um you've got the scaling laws um if you

188
00:06:46,440 --> 00:06:49,979
are the if the height of a 3D object

189
00:06:49,979 --> 00:06:50,639
um

190
00:06:50,639 --> 00:06:53,280
the volume of the 3D object grows with

191
00:06:53,280 --> 00:06:54,720
the height is the square of the height

192
00:06:54,720 --> 00:06:57,900
and the sorry the surface area of a 3D

193
00:06:57,900 --> 00:06:59,520
object grows with the square of a height

194
00:06:59,520 --> 00:07:01,020
and the volume grows with the cube

195
00:07:01,020 --> 00:07:03,479
because of that large mammals have

196
00:07:03,479 --> 00:07:06,120
difficulty with heat so elephants have

197
00:07:06,120 --> 00:07:08,940
big flappy ears to combat the squaring

198
00:07:08,940 --> 00:07:12,240
law in dimensions and it gets more much

199
00:07:12,240 --> 00:07:14,840
more complicated than this this is a a

200
00:07:14,840 --> 00:07:17,220
puzzle that if you ask at a math

201
00:07:17,220 --> 00:07:18,900
conference and people have done this and

202
00:07:18,900 --> 00:07:20,520
pulled the mathematicians of like what

203
00:07:20,520 --> 00:07:22,860
happens they get it wrong if you build

204
00:07:22,860 --> 00:07:24,900
this thing where you get a cube you put

205
00:07:24,900 --> 00:07:26,340
eight little spheres in each of the

206
00:07:26,340 --> 00:07:27,960
corners and then you embed a sphere in

207
00:07:27,960 --> 00:07:29,639
the middle that's just touching them

208
00:07:29,639 --> 00:07:31,979
like this 2D example and then you get a

209
00:07:31,979 --> 00:07:33,720
hypercube where you have 16 Series in

210
00:07:33,720 --> 00:07:34,979
the corner and the little guy's touching

211
00:07:34,979 --> 00:07:36,000
in the middle

212
00:07:36,000 --> 00:07:38,039
um at 10 Dimensions the little guy

213
00:07:38,039 --> 00:07:39,780
sticks out the sides of the of the

214
00:07:39,780 --> 00:07:42,780
actual Cube and in when you as you grow

215
00:07:42,780 --> 00:07:44,520
the size of it the little

216
00:07:44,520 --> 00:07:46,620
the circle in the middle eventually

217
00:07:46,620 --> 00:07:48,300
becomes infinite volume

218
00:07:48,300 --> 00:07:51,599
and get so dimensions and things get

219
00:07:51,599 --> 00:07:53,879
really weird and even mathematicians who

220
00:07:53,879 --> 00:07:55,800
are trying like we give each other

221
00:07:55,800 --> 00:07:58,500
dimension puzzles all the time and you

222
00:07:58,500 --> 00:07:59,879
can present this at a conference and

223
00:07:59,879 --> 00:08:01,620
you're going to get a lot of wrong

224
00:08:01,620 --> 00:08:04,099
answers

225
00:08:04,199 --> 00:08:07,560
um so dimensions are weird and here's

226
00:08:07,560 --> 00:08:09,180
how it kind of relates to the security

227
00:08:09,180 --> 00:08:11,520
space so

228
00:08:11,520 --> 00:08:15,120
mnist is a data set that everyone in

229
00:08:15,120 --> 00:08:17,520
their uh in machine learning tests their

230
00:08:17,520 --> 00:08:18,900
uh

231
00:08:18,900 --> 00:08:21,479
models against it's been sort of a

232
00:08:21,479 --> 00:08:24,360
benchmark data set for donkey's years

233
00:08:24,360 --> 00:08:28,919
Jan lacun released it in early 90s it's

234
00:08:28,919 --> 00:08:33,000
50 000 digits and it's each image of

235
00:08:33,000 --> 00:08:36,240
that is a 28 by 28 eight pick uh bit

236
00:08:36,240 --> 00:08:41,159
pixel image so each uh thing is 256

237
00:08:41,159 --> 00:08:44,580
values and there's 784 Dimensions

238
00:08:44,580 --> 00:08:48,240
because 24 squared and so you get that

239
00:08:48,240 --> 00:08:50,399
if you just bury the pixel value either

240
00:08:50,399 --> 00:08:52,800
up by one down by one or zero so you

241
00:08:52,800 --> 00:08:57,140
have three options so you can do change

242
00:08:57,140 --> 00:08:59,279
each pixel you can change is three

243
00:08:59,279 --> 00:09:01,920
things there's 784 so you get 3 to the

244
00:09:01,920 --> 00:09:04,440
power of 784 and that works out to be

245
00:09:04,440 --> 00:09:08,760
about uh 12 well 1200 bits of

246
00:09:08,760 --> 00:09:11,279
information in terms of like the bits

247
00:09:11,279 --> 00:09:12,720
information that where cryptographic key

248
00:09:12,720 --> 00:09:15,779
would be so Dimensions get really weird

249
00:09:15,779 --> 00:09:19,080
for even really small machine learning

250
00:09:19,080 --> 00:09:20,519
problems and this is like the tiniest

251
00:09:20,519 --> 00:09:22,860
the you know this was sold back in the

252
00:09:22,860 --> 00:09:24,899
night in the in the 90s

253
00:09:24,899 --> 00:09:27,720
this isn't a problem these days

254
00:09:27,720 --> 00:09:29,339
so

255
00:09:29,339 --> 00:09:31,019
what you really need to understand of

256
00:09:31,019 --> 00:09:32,880
like what is a neighborhood and what

257
00:09:32,880 --> 00:09:34,019
this power this relates to machine

258
00:09:34,019 --> 00:09:35,240
learning is

259
00:09:35,240 --> 00:09:37,260
machine learning operates in high

260
00:09:37,260 --> 00:09:39,899
dimensional space and the volume of the

261
00:09:39,899 --> 00:09:42,060
space grows exponentially with the

262
00:09:42,060 --> 00:09:43,320
mention

263
00:09:43,320 --> 00:09:44,100
um

264
00:09:44,100 --> 00:09:45,720
sort of

265
00:09:45,720 --> 00:09:47,160
um there's little white lies in

266
00:09:47,160 --> 00:09:49,260
everything I'm saying but it sort of

267
00:09:49,260 --> 00:09:52,019
grow it grows exponentially and this

268
00:09:52,019 --> 00:09:53,760
sort of shows up in machine learning

269
00:09:53,760 --> 00:09:55,500
over and over again in the cursor

270
00:09:55,500 --> 00:09:58,019
dimensionality if you have a clustering

271
00:09:58,019 --> 00:10:00,420
algorithm and you've got and you want to

272
00:10:00,420 --> 00:10:02,940
prove that it converges well

273
00:10:02,940 --> 00:10:05,040
pretty much always You're Gonna you're

274
00:10:05,040 --> 00:10:07,560
gonna say well I require 2 to the D

275
00:10:07,560 --> 00:10:12,660
amount of data in that scaling Factor to

276
00:10:12,660 --> 00:10:15,120
prove that this converges so that D is

277
00:10:15,120 --> 00:10:16,800
the dimension

278
00:10:16,800 --> 00:10:18,959
to converge you need an exponentially

279
00:10:18,959 --> 00:10:20,459
growing amount of data to actually get

280
00:10:20,459 --> 00:10:23,040
it to prove that it converges so that's

281
00:10:23,040 --> 00:10:24,899
the cursor dimensionality and you keep

282
00:10:24,899 --> 00:10:26,880
showing up and over again so this is one

283
00:10:26,880 --> 00:10:28,440
major problem that shows up all the time

284
00:10:28,440 --> 00:10:30,779
in traditional machine learning and

285
00:10:30,779 --> 00:10:33,360
since we don't make proofs about deep

286
00:10:33,360 --> 00:10:36,300
learning it doesn't really show up it's

287
00:10:36,300 --> 00:10:38,399
not really spoken about but it does show

288
00:10:38,399 --> 00:10:39,959
up in the stuff that we're talking about

289
00:10:39,959 --> 00:10:40,860
today

290
00:10:40,860 --> 00:10:42,240
so

291
00:10:42,240 --> 00:10:44,220
um now that you kind of get a bit of a

292
00:10:44,220 --> 00:10:45,540
idea of like

293
00:10:45,540 --> 00:10:47,459
something about the geometry of the

294
00:10:47,459 --> 00:10:48,779
space

295
00:10:48,779 --> 00:10:50,519
um we're going to talk about adversarial

296
00:10:50,519 --> 00:10:52,680
examples and how and you'll see why this

297
00:10:52,680 --> 00:10:55,140
relates to what a dimension is in a bit

298
00:10:55,140 --> 00:10:57,600
so this is the um I think legally

299
00:10:57,600 --> 00:11:00,180
required image for

300
00:11:00,180 --> 00:11:01,860
um adversarial examples this is the

301
00:11:01,860 --> 00:11:04,800
panda given image from the second major

302
00:11:04,800 --> 00:11:06,300
paper from

303
00:11:06,300 --> 00:11:08,820
Ian Goodfellow Christian strategy and a

304
00:11:08,820 --> 00:11:10,079
bunch of other authors that I do not

305
00:11:10,079 --> 00:11:11,579
remember the names of

306
00:11:11,579 --> 00:11:14,820
um and he built a cheap way of producing

307
00:11:14,820 --> 00:11:16,560
atmosphere examples that you could get a

308
00:11:16,560 --> 00:11:19,500
panda add this formula here that's

309
00:11:19,500 --> 00:11:21,660
designed to fit within the out of the

310
00:11:21,660 --> 00:11:24,180
Epsilon ball uh then a little ball

311
00:11:24,180 --> 00:11:27,240
around your point um and produces this

312
00:11:27,240 --> 00:11:29,820
way of confusing a neural network

313
00:11:29,820 --> 00:11:31,500
this is the actual definition that

314
00:11:31,500 --> 00:11:34,200
they're working with uh so if you have a

315
00:11:34,200 --> 00:11:36,480
point and you've got the you know in

316
00:11:36,480 --> 00:11:37,680
this

317
00:11:37,680 --> 00:11:39,240
you've got a decision boundary that

318
00:11:39,240 --> 00:11:40,740
comes down the thing you've got some

319
00:11:40,740 --> 00:11:42,260
green points you've got some blue points

320
00:11:42,260 --> 00:11:44,519
and you have

321
00:11:44,519 --> 00:11:47,339
uh this red area where this thing so

322
00:11:47,339 --> 00:11:49,620
that X is the point we care about that

323
00:11:49,620 --> 00:11:51,480
we put a little bowl around it and

324
00:11:51,480 --> 00:11:52,860
because the decision boundary is so

325
00:11:52,860 --> 00:11:54,899
close to X there's some points on the

326
00:11:54,899 --> 00:11:56,760
other side of it uh because the

327
00:11:56,760 --> 00:11:58,320
dimension a recursive dimensionality

328
00:11:58,320 --> 00:12:00,660
this is always true basically

329
00:12:00,660 --> 00:12:02,579
um so this is the definition that we

330
00:12:02,579 --> 00:12:03,480
work with

331
00:12:03,480 --> 00:12:04,800
the the

332
00:12:04,800 --> 00:12:07,260
adversary examples are things that are

333
00:12:07,260 --> 00:12:08,820
close to my point that are across the

334
00:12:08,820 --> 00:12:11,579
side the dimensionality thing uh

335
00:12:11,579 --> 00:12:13,500
decision boundary

336
00:12:13,500 --> 00:12:15,540
so the actual definition of adversial

337
00:12:15,540 --> 00:12:17,760
example that people work with is that

338
00:12:17,760 --> 00:12:19,980
and that's kind of complicated

339
00:12:19,980 --> 00:12:22,019
um basically it just means this it's

340
00:12:22,019 --> 00:12:25,019
like I want to there to be no point an

341
00:12:25,019 --> 00:12:26,579
adversarial Point example is a point

342
00:12:26,579 --> 00:12:27,720
that's on the other side of the decision

343
00:12:27,720 --> 00:12:31,500
boundary within my little Epsilon bulb

344
00:12:31,500 --> 00:12:33,839
so that looks all complicated but it's

345
00:12:33,839 --> 00:12:35,519
not that actually it's not complicated

346
00:12:35,519 --> 00:12:37,500
you can code up but what that means in

347
00:12:37,500 --> 00:12:39,660
Python but in math that's how we write

348
00:12:39,660 --> 00:12:41,100
it

349
00:12:41,100 --> 00:12:43,320
so for robustness

350
00:12:43,320 --> 00:12:45,240
um you have you use that definition and

351
00:12:45,240 --> 00:12:48,420
you sort of like ask that no points

352
00:12:48,420 --> 00:12:51,360
um there's no it's artificial examples

353
00:12:51,360 --> 00:12:53,100
within an Epsilon ball of any of my

354
00:12:53,100 --> 00:12:55,139
points so

355
00:12:55,139 --> 00:12:56,700
you see the math definition on the top

356
00:12:56,700 --> 00:13:00,000
and all that means is all my points are

357
00:13:00,000 --> 00:13:02,820
without outside of this circle so down

358
00:13:02,820 --> 00:13:05,820
here there's that red point that is the

359
00:13:05,820 --> 00:13:08,040
only point that violates this definition

360
00:13:08,040 --> 00:13:10,320
so if we didn't have that red point this

361
00:13:10,320 --> 00:13:12,060
model would be robust

362
00:13:12,060 --> 00:13:14,639
so that's all we all we're asking is

363
00:13:14,639 --> 00:13:16,260
like the decision boundary is just

364
00:13:16,260 --> 00:13:18,660
outside of this little circle around my

365
00:13:18,660 --> 00:13:20,040
stuff

366
00:13:20,040 --> 00:13:22,699
and now

367
00:13:22,980 --> 00:13:25,160
um

368
00:13:25,740 --> 00:13:27,240
so

369
00:13:27,240 --> 00:13:29,639
here I'm going to get into the issues

370
00:13:29,639 --> 00:13:31,740
so the first major issue is data just

371
00:13:31,740 --> 00:13:33,000
moves

372
00:13:33,000 --> 00:13:35,940
um so once you train a model you get

373
00:13:35,940 --> 00:13:38,220
this thing data moves

374
00:13:38,220 --> 00:13:41,040
um You release my data a while I think

375
00:13:41,040 --> 00:13:43,680
second issue is it's impossible to check

376
00:13:43,680 --> 00:13:45,540
because of the volume stuff it's you

377
00:13:45,540 --> 00:13:47,760
can't do it third issue it's impossible

378
00:13:47,760 --> 00:13:49,860
to make an adversarial robust model in

379
00:13:49,860 --> 00:13:52,019
most cases in the cases that we care

380
00:13:52,019 --> 00:13:54,600
about as security people third issue oh

381
00:13:54,600 --> 00:13:56,399
fourth issue

382
00:13:56,399 --> 00:13:58,139
as low as accuracy

383
00:13:58,139 --> 00:14:02,820
so first issue uh data just moves so I

384
00:14:02,820 --> 00:14:04,680
have a model here when I've trained it

385
00:14:04,680 --> 00:14:06,600
up and I've got a bunch of green points

386
00:14:06,600 --> 00:14:08,100
and a bunch of blue points and I trained

387
00:14:08,100 --> 00:14:10,019
up a model and it came the model came up

388
00:14:10,019 --> 00:14:11,699
with this decision boundary so

389
00:14:11,699 --> 00:14:14,279
everything on this side of that line is

390
00:14:14,279 --> 00:14:15,420
going to be classified as green

391
00:14:15,420 --> 00:14:17,100
everything on that side of the line is

392
00:14:17,100 --> 00:14:19,800
going to be classified as blue and you

393
00:14:19,800 --> 00:14:21,060
know that looks like a pretty good line

394
00:14:21,060 --> 00:14:22,800
and it's for some reason it's just kind

395
00:14:22,800 --> 00:14:25,040
of got gone this length up because

396
00:14:25,040 --> 00:14:27,300
models it doesn't really have data over

397
00:14:27,300 --> 00:14:29,519
here so it just made something up

398
00:14:29,519 --> 00:14:34,620
but um and at this point uh I needed I

399
00:14:34,620 --> 00:14:36,180
on the deadline I have to train up to

400
00:14:36,180 --> 00:14:38,040
this point and then I have to deploy and

401
00:14:38,040 --> 00:14:40,440
send this to my customers

402
00:14:40,440 --> 00:14:43,800
so I get points from a month later and

403
00:14:43,800 --> 00:14:45,899
these are my new points these are uh

404
00:14:45,899 --> 00:14:47,760
ones in these boxes

405
00:14:47,760 --> 00:14:50,040
and you can see the decision boundary is

406
00:14:50,040 --> 00:14:50,940
bad

407
00:14:50,940 --> 00:14:53,699
the the model didn't predict the model

408
00:14:53,699 --> 00:14:55,320
the data from later in the month is

409
00:14:55,320 --> 00:14:56,279
going to be

410
00:14:56,279 --> 00:14:59,699
uh over here it just kind of made it and

411
00:14:59,699 --> 00:15:01,500
it's got misclassifying all these green

412
00:15:01,500 --> 00:15:02,519
points

413
00:15:02,519 --> 00:15:06,000
so if your model was robust before you

414
00:15:06,000 --> 00:15:08,639
go you're good but your data moved and

415
00:15:08,639 --> 00:15:09,839
it moved in a way that your model

416
00:15:09,839 --> 00:15:11,519
couldn't predicted and doesn't know

417
00:15:11,519 --> 00:15:13,019
about

418
00:15:13,019 --> 00:15:14,399
so

419
00:15:14,399 --> 00:15:16,260
that didn't help you the robustness

420
00:15:16,260 --> 00:15:17,940
doesn't help you if the move data just

421
00:15:17,940 --> 00:15:21,779
moves in a way we have this problem so

422
00:15:21,779 --> 00:15:24,360
this is some data that I um from when I

423
00:15:24,360 --> 00:15:26,699
was working at elastic we published this

424
00:15:26,699 --> 00:15:29,639
at icml but you can see

425
00:15:29,639 --> 00:15:32,220
is a very interesting thing that happens

426
00:15:32,220 --> 00:15:35,100
um here so what what this model is

427
00:15:35,100 --> 00:15:37,980
I had trained up a the production model

428
00:15:37,980 --> 00:15:39,420
that we released

429
00:15:39,420 --> 00:15:41,339
um sort of a smaller version of it that

430
00:15:41,339 --> 00:15:43,500
for just testing purposes and I trained

431
00:15:43,500 --> 00:15:46,500
it on all data up to January 1st uh

432
00:15:46,500 --> 00:15:47,820
2019.

433
00:15:47,820 --> 00:15:49,320
so he doesn't know anything about the

434
00:15:49,320 --> 00:15:52,740
future it thinks uh the who it has only

435
00:15:52,740 --> 00:15:55,800
got data from the before the new year of

436
00:15:55,800 --> 00:16:00,420
2019. so it predicts well you can see

437
00:16:00,420 --> 00:16:02,339
the false positive rate as I do a

438
00:16:02,339 --> 00:16:04,560
historical analysis it's good

439
00:16:04,560 --> 00:16:07,620
it's very low it's really low for a

440
00:16:07,620 --> 00:16:09,600
model so and that's what I care about I

441
00:16:09,600 --> 00:16:11,220
don't I care about very low false

442
00:16:11,220 --> 00:16:12,959
positive very low false negatively

443
00:16:12,959 --> 00:16:15,180
that's my accuracy and then the very low

444
00:16:15,180 --> 00:16:16,740
error rate overall

445
00:16:16,740 --> 00:16:19,500
but as you can see about three months

446
00:16:19,500 --> 00:16:21,120
after I released the model

447
00:16:21,120 --> 00:16:22,980
uh three months after you know this one

448
00:16:22,980 --> 00:16:24,899
wasn't deployed but you know three

449
00:16:24,899 --> 00:16:26,940
months afterwards there's a spike in the

450
00:16:26,940 --> 00:16:28,500
false negative right what happened was

451
00:16:28,500 --> 00:16:30,600
uh there was some malware family that

452
00:16:30,600 --> 00:16:32,040
figured out a bypass that became

453
00:16:32,040 --> 00:16:34,740
prominent and uh showed up

454
00:16:34,740 --> 00:16:36,720
so there was a bypass for a malware

455
00:16:36,720 --> 00:16:38,759
family and in our case

456
00:16:38,759 --> 00:16:41,579
the ulcers know what the malware authors

457
00:16:41,579 --> 00:16:43,019
know what virus total is they can check

458
00:16:43,019 --> 00:16:44,820
if they're they have a bypass they can

459
00:16:44,820 --> 00:16:47,880
check if they've got um or if your data

460
00:16:47,880 --> 00:16:50,339
they their malware is correctly

461
00:16:50,339 --> 00:16:51,600
classified they can check if the AV

462
00:16:51,600 --> 00:16:53,279
vendors and the EDR vendors are going to

463
00:16:53,279 --> 00:16:54,720
catch them

464
00:16:54,720 --> 00:16:57,120
um and they do that and so

465
00:16:57,120 --> 00:17:00,180
they will look for areas that aren't in

466
00:17:00,180 --> 00:17:02,220
their space and they will find a bypass

467
00:17:02,220 --> 00:17:05,939
and you can see I later on

468
00:17:05,939 --> 00:17:09,480
uh in after over a year after a this

469
00:17:09,480 --> 00:17:11,280
thing models thing it's got this massive

470
00:17:11,280 --> 00:17:12,900
Spike which would be completely

471
00:17:12,900 --> 00:17:15,059
unacceptable

472
00:17:15,059 --> 00:17:17,459
um this is not percent this is a thing

473
00:17:17,459 --> 00:17:19,140
so this is a massive Spike that would be

474
00:17:19,140 --> 00:17:20,939
completely unacceptable

475
00:17:20,939 --> 00:17:22,439
um you you can't deploy a model that

476
00:17:22,439 --> 00:17:25,980
that's that bad but that robustness

477
00:17:25,980 --> 00:17:28,919
wouldn't have saved this the red line is

478
00:17:28,919 --> 00:17:32,100
the amount a measurement of the drift

479
00:17:32,100 --> 00:17:35,039
uh the green blue and orange lines are

480
00:17:35,039 --> 00:17:36,299
the ones that you really care about in

481
00:17:36,299 --> 00:17:38,900
this image

482
00:17:39,299 --> 00:17:41,580
um another thing issue with robustness

483
00:17:41,580 --> 00:17:43,440
it's impossible to check for robustness

484
00:17:43,440 --> 00:17:46,440
so getting back to the demand the thing

485
00:17:46,440 --> 00:17:50,100
if I'm uh if I want a robustness radius

486
00:17:50,100 --> 00:17:52,559
of one pixel

487
00:17:52,559 --> 00:17:55,100
uh

488
00:17:55,100 --> 00:17:57,660
my the number of bits of information for

489
00:17:57,660 --> 00:18:00,480
an L2 ball is 10 that means it's

490
00:18:00,480 --> 00:18:02,520
equivalent yeah you you've got to guess

491
00:18:02,520 --> 00:18:05,580
10 uh two to the 10 different things in

492
00:18:05,580 --> 00:18:07,140
order to test all the values you have to

493
00:18:07,140 --> 00:18:08,280
go through two to the ten different

494
00:18:08,280 --> 00:18:10,559
things to test all the value but when

495
00:18:10,559 --> 00:18:12,179
I've got an L Infinity ball which is a

496
00:18:12,179 --> 00:18:13,200
lot of these things are claiming a

497
00:18:13,200 --> 00:18:15,480
robustness to I have to check

498
00:18:15,480 --> 00:18:18,960
twelve hundred two to the 1200 and

499
00:18:18,960 --> 00:18:22,380
that's not you know the uh

500
00:18:22,380 --> 00:18:24,179
and this is just for emness this isn't

501
00:18:24,179 --> 00:18:26,160
for a real model this isn't for real

502
00:18:26,160 --> 00:18:28,980
images this is this is just emness

503
00:18:28,980 --> 00:18:31,799
um and when I put yeah increase the size

504
00:18:31,799 --> 00:18:33,600
of the bowl for L2 Bulls once I hit

505
00:18:33,600 --> 00:18:35,340
seven well that's

506
00:18:35,340 --> 00:18:39,360
that means this checking a L2 ball of

507
00:18:39,360 --> 00:18:42,480
seven pixels around a value of seven

508
00:18:42,480 --> 00:18:45,419
value values around a point

509
00:18:45,419 --> 00:18:48,720
in an emness model is

510
00:18:48,720 --> 00:18:52,500
takes more has much more bits than an a

511
00:18:52,500 --> 00:18:55,559
breaking a 256-bit encryption key

512
00:18:55,559 --> 00:18:57,480
so it's you

513
00:18:57,480 --> 00:19:00,780
have to Brute Force like AES 256-bit

514
00:19:00,780 --> 00:19:02,340
encryption

515
00:19:02,340 --> 00:19:04,080
and that's easier than checking seven

516
00:19:04,080 --> 00:19:07,500
pixels away from mnist

517
00:19:07,500 --> 00:19:09,240
um

518
00:19:09,240 --> 00:19:10,919
the radius is normally normal smaller

519
00:19:10,919 --> 00:19:13,980
than 70 not seven

520
00:19:13,980 --> 00:19:16,580
so

521
00:19:16,580 --> 00:19:19,260
here's that there's a line what I told

522
00:19:19,260 --> 00:19:20,400
you

523
00:19:20,400 --> 00:19:22,140
um this is a

524
00:19:22,140 --> 00:19:25,559
slice of a of how a neural network

525
00:19:25,559 --> 00:19:28,980
actually perceives data uh this comes

526
00:19:28,980 --> 00:19:30,840
the idea from this comes with the a

527
00:19:30,840 --> 00:19:32,160
field of math called the tropical

528
00:19:32,160 --> 00:19:34,500
tropical geometry

529
00:19:34,500 --> 00:19:36,240
um if you know your cryptography and

530
00:19:36,240 --> 00:19:39,480
your finite Fields this is the geometry

531
00:19:39,480 --> 00:19:42,380
of the field of one element

532
00:19:42,600 --> 00:19:47,039
um and it relates to neural networks

533
00:19:47,039 --> 00:19:49,500
um so this is actually sort of how what

534
00:19:49,500 --> 00:19:51,059
you have to check instead of the just

535
00:19:51,059 --> 00:19:54,179
the bit pixels and um what I care about

536
00:19:54,179 --> 00:19:57,480
is if I have my image my point is going

537
00:19:57,480 --> 00:20:00,600
to be in one of these uh sectors so if

538
00:20:00,600 --> 00:20:03,440
there's a solid solid color Polytech my

539
00:20:03,440 --> 00:20:05,640
example is going to be in one of those

540
00:20:05,640 --> 00:20:07,080
things

541
00:20:07,080 --> 00:20:09,600
and when I cross the boundary to another

542
00:20:09,600 --> 00:20:11,820
color image that that means that the

543
00:20:11,820 --> 00:20:13,679
classification could have changed so

544
00:20:13,679 --> 00:20:16,020
sort of the decision boundary of a

545
00:20:16,020 --> 00:20:17,820
neural network is going to be contained

546
00:20:17,820 --> 00:20:20,880
in the edges of this image

547
00:20:20,880 --> 00:20:24,179
and this is a slice of the emness of a

548
00:20:24,179 --> 00:20:26,640
neural network slight trained on mnist

549
00:20:26,640 --> 00:20:28,080
um and you this is just a

550
00:20:28,080 --> 00:20:31,320
two-dimensional slice of a 700 of a mini

551
00:20:31,320 --> 00:20:34,140
thousand-dimensional space

552
00:20:34,140 --> 00:20:36,299
um so it's much more complicated than

553
00:20:36,299 --> 00:20:38,340
this and if I want to be completely

554
00:20:38,340 --> 00:20:40,140
honest about my estimate for the number

555
00:20:40,140 --> 00:20:41,940
of bits I have to check using the

556
00:20:41,940 --> 00:20:43,140
geometry of the neural network

557
00:20:43,140 --> 00:20:45,120
information about the geometry of the

558
00:20:45,120 --> 00:20:46,799
neural network it's actually more like

559
00:20:46,799 --> 00:20:50,340
this so it means

560
00:20:50,340 --> 00:20:53,580
using all the math to reduce the problem

561
00:20:53,580 --> 00:20:56,159
space as much as possible to save

562
00:20:56,159 --> 00:20:57,900
yourself as much time which is what

563
00:20:57,900 --> 00:20:59,760
cryptographers would do if you have a

564
00:20:59,760 --> 00:21:01,860
really bad way of generating a key that

565
00:21:01,860 --> 00:21:04,140
actually doesn't have full the full

566
00:21:04,140 --> 00:21:07,820
256-bit encryption uh bits of

567
00:21:07,820 --> 00:21:09,659
entropy

568
00:21:09,659 --> 00:21:11,640
um it only has 90 bits of entropy then

569
00:21:11,640 --> 00:21:13,200
cryptographers can take advantage of

570
00:21:13,200 --> 00:21:15,960
that because they know math tricks well

571
00:21:15,960 --> 00:21:18,299
if for neural networks with you know the

572
00:21:18,299 --> 00:21:20,100
geometry of it you can take advantage of

573
00:21:20,100 --> 00:21:22,500
it to save yourself a lot of time and um

574
00:21:22,500 --> 00:21:25,620
with that with using all that well you

575
00:21:25,620 --> 00:21:28,320
don't get to Seven you get to 10.

576
00:21:28,320 --> 00:21:31,440
so even with the math tricks you don't

577
00:21:31,440 --> 00:21:34,080
you don't get much further

578
00:21:34,080 --> 00:21:36,960
so another way of making things uh

579
00:21:36,960 --> 00:21:38,460
robust is

580
00:21:38,460 --> 00:21:40,140
um adversarially training them and this

581
00:21:40,140 --> 00:21:42,299
is the algorithm basically the algorithm

582
00:21:42,299 --> 00:21:44,039
for making the adversarly training

583
00:21:44,039 --> 00:21:48,539
things so you build you can make

584
00:21:48,539 --> 00:21:50,159
adversarial examples in some really

585
00:21:50,159 --> 00:21:52,260
cheap ways and just include those in

586
00:21:52,260 --> 00:21:54,240
these training data like always train

587
00:21:54,240 --> 00:21:56,159
your network on adversarial examples so

588
00:21:56,159 --> 00:21:57,840
that it's always going to cut you know

589
00:21:57,840 --> 00:21:59,100
to make sure that it classifies the

590
00:21:59,100 --> 00:22:00,900
other serial examples correctly so

591
00:22:00,900 --> 00:22:02,580
you're going to use the fast gradient

592
00:22:02,580 --> 00:22:04,440
sign method just start tossing in fast

593
00:22:04,440 --> 00:22:05,880
screen inside method generated

594
00:22:05,880 --> 00:22:07,740
adversarial examples

595
00:22:07,740 --> 00:22:09,539
um so what you and that's what these are

596
00:22:09,539 --> 00:22:12,240
is R star is the adversarial example

597
00:22:12,240 --> 00:22:13,799
that you're going to generate and you're

598
00:22:13,799 --> 00:22:15,539
just going to toss it in there and train

599
00:22:15,539 --> 00:22:17,880
on both your normal samples and these

600
00:22:17,880 --> 00:22:20,340
adversarial examples so

601
00:22:20,340 --> 00:22:23,039
the probable problem with this is the

602
00:22:23,039 --> 00:22:25,799
first line uh is this line find an

603
00:22:25,799 --> 00:22:29,580
attack for permutation RF star well as

604
00:22:29,580 --> 00:22:31,679
we just said well there's that many

605
00:22:31,679 --> 00:22:33,720
attacker mutations yeah that's the space

606
00:22:33,720 --> 00:22:34,980
you have to search over to find a

607
00:22:34,980 --> 00:22:37,260
different attack Prem rotation

608
00:22:37,260 --> 00:22:40,740
so that is basically you're going to

609
00:22:40,740 --> 00:22:42,360
find one you're going to use your one

610
00:22:42,360 --> 00:22:44,460
you're going to use your maybe one maybe

611
00:22:44,460 --> 00:22:46,320
ten different ways of generating an

612
00:22:46,320 --> 00:22:47,820
adversarial example and you're going to

613
00:22:47,820 --> 00:22:49,440
train your neural network to correctly

614
00:22:49,440 --> 00:22:51,480
classify that type of adversarial

615
00:22:51,480 --> 00:22:53,700
example and there are many different

616
00:22:53,700 --> 00:22:55,380
ways to build an average real example it

617
00:22:55,380 --> 00:22:57,120
is not just one there are

618
00:22:57,120 --> 00:23:00,900
boatloads away so robustness training is

619
00:23:00,900 --> 00:23:03,780
a dead end and has been the dead end for

620
00:23:03,780 --> 00:23:05,640
a while but there are companies that'll

621
00:23:05,640 --> 00:23:07,500
sell you robustness training for making

622
00:23:07,500 --> 00:23:09,299
your model robust

623
00:23:09,299 --> 00:23:11,100
um

624
00:23:11,100 --> 00:23:12,539
and uh

625
00:23:12,539 --> 00:23:14,880
they are scamming you

626
00:23:14,880 --> 00:23:17,820
uh uh another issue with robustness this

627
00:23:17,820 --> 00:23:18,840
is another way you can make things

628
00:23:18,840 --> 00:23:21,960
robust this is a Lipschitz continuous

629
00:23:21,960 --> 00:23:25,640
thing so what this lip shits requires is

630
00:23:25,640 --> 00:23:29,340
I can't if I give a point I can make

631
00:23:29,340 --> 00:23:31,919
this like slash diagram and this like

632
00:23:31,919 --> 00:23:34,799
cone of light if you're familiar with

633
00:23:34,799 --> 00:23:36,860
um

634
00:23:37,380 --> 00:23:40,260
um special relativity so my function has

635
00:23:40,260 --> 00:23:42,419
to be within this

636
00:23:42,419 --> 00:23:44,820
uh this shaded area

637
00:23:44,820 --> 00:23:47,460
uh what this means is if I have a

638
00:23:47,460 --> 00:23:49,919
function my function spikes up

639
00:23:49,919 --> 00:23:51,720
goes from here and spikes up and goes

640
00:23:51,720 --> 00:23:55,380
there it's changing too quickly

641
00:23:55,380 --> 00:23:58,500
so I can make my constant small and say

642
00:23:58,500 --> 00:24:01,440
I can't with at this point I am

643
00:24:01,440 --> 00:24:04,140
robust is it's classifying these

644
00:24:04,140 --> 00:24:05,940
correctly and then if I move right next

645
00:24:05,940 --> 00:24:08,520
door I'm over here and I've changed too

646
00:24:08,520 --> 00:24:10,980
quickly so that's not good so I'm going

647
00:24:10,980 --> 00:24:12,900
to require that my function changes

648
00:24:12,900 --> 00:24:14,400
slowly

649
00:24:14,400 --> 00:24:16,200
and so for my neural network I'm going

650
00:24:16,200 --> 00:24:17,880
to require that it changes slowly and so

651
00:24:17,880 --> 00:24:20,580
I'm going to make things lip shits

652
00:24:20,580 --> 00:24:21,179
um

653
00:24:21,179 --> 00:24:24,840
named after all mathematician and um

654
00:24:24,840 --> 00:24:26,640
this isn't ready for production the way

655
00:24:26,640 --> 00:24:28,919
they do this is they require regulate or

656
00:24:28,919 --> 00:24:31,500
regularization and they put it toss in

657
00:24:31,500 --> 00:24:33,840
that your neural network can't do this

658
00:24:33,840 --> 00:24:36,240
and they require the the actual way to

659
00:24:36,240 --> 00:24:37,919
do this is wrong

660
00:24:37,919 --> 00:24:40,320
so this isn't ready for production this

661
00:24:40,320 --> 00:24:41,640
is another way

662
00:24:41,640 --> 00:24:43,799
if you have images you can make a thing

663
00:24:43,799 --> 00:24:46,620
robust what you do is because my neural

664
00:24:46,620 --> 00:24:48,480
network in my adversary example is sort

665
00:24:48,480 --> 00:24:51,720
of a noise isn't within the noise bounds

666
00:24:51,720 --> 00:24:54,720
I add some more noise and then I remove

667
00:24:54,720 --> 00:24:57,539
the noise using a for example diffusion

668
00:24:57,539 --> 00:25:00,299
model this is this model here is the

669
00:25:00,299 --> 00:25:02,760
latent diffusion model that it's

670
00:25:02,760 --> 00:25:04,919
available on hugging base and GitHub and

671
00:25:04,919 --> 00:25:06,480
what you can do is if you have an image

672
00:25:06,480 --> 00:25:08,039
model just add a little bit more noise

673
00:25:08,039 --> 00:25:10,799
and then remove the noise using your

674
00:25:10,799 --> 00:25:13,679
diffusion model uh you know add some

675
00:25:13,679 --> 00:25:15,659
noise remove it uh there's a bunch of

676
00:25:15,659 --> 00:25:17,820
other ways of doing this you can use

677
00:25:17,820 --> 00:25:20,400
um high frequency and things from image

678
00:25:20,400 --> 00:25:22,380
processing removal The High Frequency

679
00:25:22,380 --> 00:25:23,880
information because the adversarial

680
00:25:23,880 --> 00:25:25,200
examples tend to be high frequency

681
00:25:25,200 --> 00:25:26,760
information

682
00:25:26,760 --> 00:25:27,600
um

683
00:25:27,600 --> 00:25:30,539
most of the ways don't work this way

684
00:25:30,539 --> 00:25:32,640
probably works um the people didn't

685
00:25:32,640 --> 00:25:35,279
prove it but mathematically but it has

686
00:25:35,279 --> 00:25:37,200
some really good results and it you know

687
00:25:37,200 --> 00:25:38,340
that's

688
00:25:38,340 --> 00:25:39,539
um that's the best we can do in machine

689
00:25:39,539 --> 00:25:41,760
learning

690
00:25:41,760 --> 00:25:43,799
cool so

691
00:25:43,799 --> 00:25:45,840
here's the reason why you wouldn't want

692
00:25:45,840 --> 00:25:48,179
like you know the first two reasons were

693
00:25:48,179 --> 00:25:50,460
first couple reasons

694
00:25:50,460 --> 00:25:52,620
or you can't get it you can't make them

695
00:25:52,620 --> 00:25:54,840
all robust here's a reason why you don't

696
00:25:54,840 --> 00:25:56,520
want your model to be Rose you don't

697
00:25:56,520 --> 00:25:58,260
actually want this thing you it's

698
00:25:58,260 --> 00:26:01,679
actually a bad quality in many cases

699
00:26:01,679 --> 00:26:04,620
so I have my neural this is a diagram I

700
00:26:04,620 --> 00:26:06,659
stole from this paper over here

701
00:26:06,659 --> 00:26:07,440
um

702
00:26:07,440 --> 00:26:10,679
I have my my green points my blue points

703
00:26:10,679 --> 00:26:12,900
and my line separating them and I've

704
00:26:12,900 --> 00:26:14,460
classified in this line correctly

705
00:26:14,460 --> 00:26:17,640
classifies them all so I then put my

706
00:26:17,640 --> 00:26:20,400
little L Infinity spheres around spheres

707
00:26:20,400 --> 00:26:22,740
around them my cubes and I'm going to

708
00:26:22,740 --> 00:26:23,940
require that this model will be robust

709
00:26:23,940 --> 00:26:25,260
and you can see that the decision

710
00:26:25,260 --> 00:26:26,640
boundary goes through a bunch of those

711
00:26:26,640 --> 00:26:27,659
cubes

712
00:26:27,659 --> 00:26:30,419
so this model isn't robust by this

713
00:26:30,419 --> 00:26:32,400
definite but from this Epsilon these

714
00:26:32,400 --> 00:26:34,799
definitions so my model actually to be

715
00:26:34,799 --> 00:26:36,960
robust has to be this red wiggly line

716
00:26:36,960 --> 00:26:38,940
that

717
00:26:38,940 --> 00:26:41,460
is all it's you know wastes a lot of

718
00:26:41,460 --> 00:26:43,559
compute to actually make that red wiggly

719
00:26:43,559 --> 00:26:46,260
line is possible to do but you now have

720
00:26:46,260 --> 00:26:47,220
this thing where you have to make this

721
00:26:47,220 --> 00:26:48,600
red wiggly line

722
00:26:48,600 --> 00:26:50,340
what this means is your model actually

723
00:26:50,340 --> 00:26:52,919
beings more ends up being less accurate

724
00:26:52,919 --> 00:26:56,400
so this zero is the standard model this

725
00:26:56,400 --> 00:26:58,620
would be the uh the accuracy of the

726
00:26:58,620 --> 00:26:59,700
standard model

727
00:26:59,700 --> 00:27:04,500
something that is one pixel robust is

728
00:27:04,500 --> 00:27:07,440
a lot more it has got nearly

729
00:27:07,440 --> 00:27:10,200
um four times the error rate of one

730
00:27:10,200 --> 00:27:12,179
pixel you know three times the error

731
00:27:12,179 --> 00:27:13,620
rate

732
00:27:13,620 --> 00:27:15,179
of

733
00:27:15,179 --> 00:27:17,880
um a one of a thing when I have a small

734
00:27:17,880 --> 00:27:20,700
amount of data so this is three times

735
00:27:20,700 --> 00:27:22,919
the error rate for one pixel one pixel

736
00:27:22,919 --> 00:27:25,799
value robust two uh two pixels value

737
00:27:25,799 --> 00:27:27,600
robust and so on

738
00:27:27,600 --> 00:27:30,360
and as I add more data it becomes the

739
00:27:30,360 --> 00:27:33,059
error rate goes back down but I need a

740
00:27:33,059 --> 00:27:34,620
lot of you know what if you actually

741
00:27:34,620 --> 00:27:36,600
follow this through it's asymptotics

742
00:27:36,600 --> 00:27:37,919
you're always going to be making a

743
00:27:37,919 --> 00:27:40,500
Trader and this is for mnist for

744
00:27:40,500 --> 00:27:43,320
imagenet and cfarm

745
00:27:43,320 --> 00:27:46,380
it's worse you require much bigger

746
00:27:46,380 --> 00:27:48,899
robustness and um

747
00:27:48,899 --> 00:27:51,840
you get a lot you know with a re with an

748
00:27:51,840 --> 00:27:54,419
L2 ball of like a reasonable amount it

749
00:27:54,419 --> 00:27:57,240
drops off drastically

750
00:27:57,240 --> 00:28:00,120
so the accuracy is a huge title so

751
00:28:00,120 --> 00:28:02,399
do you want your model to be robust

752
00:28:02,399 --> 00:28:03,720
well

753
00:28:03,720 --> 00:28:06,120
Maybe not maybe you spend way too much

754
00:28:06,120 --> 00:28:08,039
inaccuracy

755
00:28:08,039 --> 00:28:10,500
um to actually make your model robust

756
00:28:10,500 --> 00:28:12,840
this is

757
00:28:12,840 --> 00:28:14,840
um

758
00:28:16,860 --> 00:28:20,700
it is in many cases it's probably much

759
00:28:20,700 --> 00:28:22,559
more secure to have an accurate model

760
00:28:22,559 --> 00:28:24,960
that generalizes well

761
00:28:24,960 --> 00:28:27,179
than to have a robust model

762
00:28:27,179 --> 00:28:31,220
because the accuracy is more important

763
00:28:31,220 --> 00:28:34,919
especially in malware models than the

764
00:28:34,919 --> 00:28:38,100
robot then the robustness because you

765
00:28:38,100 --> 00:28:40,140
want you need your false positive rate B

766
00:28:40,140 --> 00:28:43,620
to be below the annoyance threshold of

767
00:28:43,620 --> 00:28:44,940
your analysts

768
00:28:44,940 --> 00:28:46,740
and to accomplish that and their

769
00:28:46,740 --> 00:28:48,059
annoying threshold of your analyst

770
00:28:48,059 --> 00:28:49,559
because those how many binaries are

771
00:28:49,559 --> 00:28:51,360
passing through your network

772
00:28:51,360 --> 00:28:53,520
really low so you need a false positive

773
00:28:53,520 --> 00:28:55,100
rate of

774
00:28:55,100 --> 00:28:59,480
0.01 or something like that

775
00:28:59,760 --> 00:29:02,399
to get an accuracy rate of that low you

776
00:29:02,399 --> 00:29:05,220
can't make a trade-off of that much even

777
00:29:05,220 --> 00:29:07,140
in the tiny bit of robustness this

778
00:29:07,140 --> 00:29:08,940
trade-off would kill the performance of

779
00:29:08,940 --> 00:29:11,340
your normal of your malware model so you

780
00:29:11,340 --> 00:29:12,960
don't want to make this trade-off for

781
00:29:12,960 --> 00:29:16,140
security data and image data if you have

782
00:29:16,140 --> 00:29:17,640
a

783
00:29:17,640 --> 00:29:20,880
um you know a x-ray machine would you

784
00:29:20,880 --> 00:29:22,320
want your

785
00:29:22,320 --> 00:29:24,179
model you know would you feel comfort

786
00:29:24,179 --> 00:29:25,919
that your model made a mistake because

787
00:29:25,919 --> 00:29:28,260
they made it robust

788
00:29:28,260 --> 00:29:31,080
like oh no we could maybe get a

789
00:29:31,080 --> 00:29:33,659
challenge attacked by a hypothetical

790
00:29:33,659 --> 00:29:35,820
adversary if they got into my network

791
00:29:35,820 --> 00:29:38,700
and started messing with like image data

792
00:29:38,700 --> 00:29:40,440
instead of just ransomware in the

793
00:29:40,440 --> 00:29:41,880
hospital

794
00:29:41,880 --> 00:29:43,620
they could you know Ransom with a

795
00:29:43,620 --> 00:29:45,899
hospital or mess with image data in a

796
00:29:45,899 --> 00:29:47,580
very particular way that requires a lot

797
00:29:47,580 --> 00:29:49,140
of expertise

798
00:29:49,140 --> 00:29:52,679
well to guard against that weird Edge

799
00:29:52,679 --> 00:29:54,360
case some hospitals are spending money

800
00:29:54,360 --> 00:29:56,580
on robustness and not spending money on

801
00:29:56,580 --> 00:29:57,659
like

802
00:29:57,659 --> 00:30:00,380
improving the model thing

803
00:30:00,380 --> 00:30:03,779
there is other definitions of robust but

804
00:30:03,779 --> 00:30:05,940
the for security applications it is not

805
00:30:05,940 --> 00:30:07,740
the thing and there's other Definition

806
00:30:07,740 --> 00:30:09,860
of robust suffer from the same

807
00:30:09,860 --> 00:30:12,960
dimensionality problems as regular

808
00:30:12,960 --> 00:30:17,279
robustness you the only way to fight

809
00:30:17,279 --> 00:30:20,820
more robustness correctly is to get more

810
00:30:20,820 --> 00:30:23,580
data we'll get more data more high

811
00:30:23,580 --> 00:30:25,679
quality data there's no point in making

812
00:30:25,679 --> 00:30:29,460
spending money on an effort on

813
00:30:29,460 --> 00:30:31,799
fancy tricks to make your model robust

814
00:30:31,799 --> 00:30:34,799
is just get more data even if you have a

815
00:30:34,799 --> 00:30:37,740
robustness technique you want more data

816
00:30:37,740 --> 00:30:39,179
so

817
00:30:39,179 --> 00:30:41,399
don't invest in that invest in getting

818
00:30:41,399 --> 00:30:43,440
more data

819
00:30:43,440 --> 00:30:45,539
anyway so

820
00:30:45,539 --> 00:30:48,539
now that I've said that it's pointless

821
00:30:48,539 --> 00:30:50,820
thing let's talk about like the reason

822
00:30:50,820 --> 00:30:52,799
why you would want this is you have

823
00:30:52,799 --> 00:30:54,960
you're trying to prevent a bypass

824
00:30:54,960 --> 00:30:57,360
and now to tell you about how bypasses

825
00:30:57,360 --> 00:31:00,419
actually work so the first major machine

826
00:31:00,419 --> 00:31:02,519
learning attack is against spam

827
00:31:02,519 --> 00:31:04,799
filtering probably the first deployment

828
00:31:04,799 --> 00:31:06,840
of machine learning in security was in

829
00:31:06,840 --> 00:31:10,799
2002 and they deployed naive Bayes for a

830
00:31:10,799 --> 00:31:12,480
spam

831
00:31:12,480 --> 00:31:14,100
um if you want to learn what naivees are

832
00:31:14,100 --> 00:31:16,140
there's a workshop of the village that a

833
00:31:16,140 --> 00:31:18,740
friend of mine is giving

834
00:31:19,260 --> 00:31:23,820
um by 2004 uh Sophos who were was

835
00:31:23,820 --> 00:31:26,159
running one of these things commercially

836
00:31:26,159 --> 00:31:29,039
had seen these attacks so people were

837
00:31:29,039 --> 00:31:31,440
obfuscating the text they were using the

838
00:31:31,440 --> 00:31:34,919
normal thing of putting uh HTML percent

839
00:31:34,919 --> 00:31:36,480
characters instead of actually writing

840
00:31:36,480 --> 00:31:38,220
out the text so it would be rendered in

841
00:31:38,220 --> 00:31:40,799
the HTML engine as proper stuff but it

842
00:31:40,799 --> 00:31:43,320
was actually uh you know rendered as

843
00:31:43,320 --> 00:31:45,419
human legible but it was not legible to

844
00:31:45,419 --> 00:31:48,299
machine so they obfuscated the text

845
00:31:48,299 --> 00:31:51,260
um that's because they know that the the

846
00:31:51,260 --> 00:31:53,640
AI model is a machine thing so it's got

847
00:31:53,640 --> 00:31:55,919
to have to read the text

848
00:31:55,919 --> 00:31:57,720
um they would also put a small email

849
00:31:57,720 --> 00:32:00,000
with just a link like follow this link

850
00:32:00,000 --> 00:32:04,740
to your Viagra uh to my Viagra thing

851
00:32:04,740 --> 00:32:06,840
um and then they would another thing

852
00:32:06,840 --> 00:32:08,580
they would hide the emails in a

853
00:32:08,580 --> 00:32:10,019
non-deliverable because the way that was

854
00:32:10,019 --> 00:32:12,179
delivered it was sort of a payload

855
00:32:12,179 --> 00:32:15,179
inside the email so that the sca the the

856
00:32:15,179 --> 00:32:19,260
spam system didn't unopen the payload

857
00:32:19,260 --> 00:32:21,480
the same way as it opened the regular

858
00:32:21,480 --> 00:32:23,399
email so they would be able to get past

859
00:32:23,399 --> 00:32:25,799
the spam Meetup by basically packing the

860
00:32:25,799 --> 00:32:28,440
email which is a problem from machine

861
00:32:28,440 --> 00:32:31,140
learning models for malware as well and

862
00:32:31,140 --> 00:32:33,360
another the last thing the the most

863
00:32:33,360 --> 00:32:35,519
famous attack uh packing in good words

864
00:32:35,519 --> 00:32:37,860
so if you have a spam email that's

865
00:32:37,860 --> 00:32:39,480
trying to get you to you know give money

866
00:32:39,480 --> 00:32:41,820
to a

867
00:32:41,820 --> 00:32:44,220
um you know your cousin you know uh

868
00:32:44,220 --> 00:32:46,320
Prince

869
00:32:46,320 --> 00:32:48,480
um you would then just put a Wikipedia

870
00:32:48,480 --> 00:32:49,919
article at the bottom of that because

871
00:32:49,919 --> 00:32:52,320
the Wikipedia article is good and the

872
00:32:52,320 --> 00:32:54,659
Bayesian filter uh counted the number of

873
00:32:54,659 --> 00:32:56,880
good words and bad words and kind of

874
00:32:56,880 --> 00:32:59,399
checked on whether the thing checked on

875
00:32:59,399 --> 00:33:00,960
uh

876
00:33:00,960 --> 00:33:02,640
um how that worked

877
00:33:02,640 --> 00:33:04,860
these aren't the adversarial examples

878
00:33:04,860 --> 00:33:06,419
that academics are studying these are

879
00:33:06,419 --> 00:33:09,779
someone sat down read the paper on how

880
00:33:09,779 --> 00:33:12,659
the Bayesian filters work and had a good

881
00:33:12,659 --> 00:33:14,760
think and then made up this these

882
00:33:14,760 --> 00:33:16,679
strategies

883
00:33:16,679 --> 00:33:17,220
um

884
00:33:17,220 --> 00:33:18,659
and that says this is still what's

885
00:33:18,659 --> 00:33:22,200
happening today uh spammers uh who are

886
00:33:22,200 --> 00:33:23,340
spamming Facebook

887
00:33:23,340 --> 00:33:26,399
they every few days their Facebook

888
00:33:26,399 --> 00:33:28,320
deploys in the new spam model to prevent

889
00:33:28,320 --> 00:33:29,760
things from going through

890
00:33:29,760 --> 00:33:32,640
uh spammers get together try a bunch of

891
00:33:32,640 --> 00:33:34,620
stuff and then communicate uh figure out

892
00:33:34,620 --> 00:33:36,779
a bypass and then communicate it to each

893
00:33:36,779 --> 00:33:37,440
other

894
00:33:37,440 --> 00:33:39,240
it spreads quickly Facebook now has a

895
00:33:39,240 --> 00:33:40,440
model that's out of date they have to

896
00:33:40,440 --> 00:33:42,480
redeploy three days you know three or

897
00:33:42,480 --> 00:33:44,460
four days later because that's the value

898
00:33:44,460 --> 00:33:46,620
of getting spam on Facebook is that high

899
00:33:46,620 --> 00:33:48,120
that the spammers are going to put that

900
00:33:48,120 --> 00:33:50,640
much money into just getting

901
00:33:50,640 --> 00:33:53,519
5 000 people in a room that are very

902
00:33:53,519 --> 00:33:55,620
poorly paid to bypass the model and once

903
00:33:55,620 --> 00:33:56,760
one of them figures it out they

904
00:33:56,760 --> 00:33:58,679
communicate and uh they have a bypass

905
00:33:58,679 --> 00:34:01,080
they work like this they have guesses

906
00:34:01,080 --> 00:34:02,700
for how the spam model Works they have

907
00:34:02,700 --> 00:34:04,679
read some academic papers but they don't

908
00:34:04,679 --> 00:34:06,840
really understand them they are just

909
00:34:06,840 --> 00:34:09,659
trying to guess where it boxes

910
00:34:09,659 --> 00:34:11,099
so

911
00:34:11,099 --> 00:34:13,079
here's a machine learning attack against

912
00:34:13,079 --> 00:34:15,659
a malware model so if you want to learn

913
00:34:15,659 --> 00:34:17,399
about HAL malware models actually work

914
00:34:17,399 --> 00:34:19,139
you want to look up elastic Embers

915
00:34:19,139 --> 00:34:22,440
featurization system from

916
00:34:22,440 --> 00:34:26,699
uh piara Madison and Phil Roth and uh so

917
00:34:26,699 --> 00:34:28,500
you take a the idea how this works is

918
00:34:28,500 --> 00:34:30,540
you take a PE file and this is the

919
00:34:30,540 --> 00:34:32,159
plastic picture of what a PE file looks

920
00:34:32,159 --> 00:34:33,659
like from Wikipedia

921
00:34:33,659 --> 00:34:36,899
you featurize it into a like a Json bot

922
00:34:36,899 --> 00:34:38,699
that has all sorts of useful information

923
00:34:38,699 --> 00:34:41,579
like the size of sections the number of

924
00:34:41,579 --> 00:34:43,679
bytes the histogram of the bytes the

925
00:34:43,679 --> 00:34:47,639
entropy the number of strings the import

926
00:34:47,639 --> 00:34:50,940
list all sorts of stuff and then you put

927
00:34:50,940 --> 00:34:54,000
it in a high dimensional space so for

928
00:34:54,000 --> 00:34:58,260
Ember it puts it in a 2000 the 381

929
00:34:58,260 --> 00:35:00,740
dimensional space

930
00:35:00,740 --> 00:35:03,119
1024 impulse dimensions are just

931
00:35:03,119 --> 00:35:05,280
encoding your Imports table because

932
00:35:05,280 --> 00:35:06,960
Imports are really important for

933
00:35:06,960 --> 00:35:08,820
checking out whether we're doing a

934
00:35:08,820 --> 00:35:11,220
static analysis of binary

935
00:35:11,220 --> 00:35:13,200
um

936
00:35:13,200 --> 00:35:14,520
so

937
00:35:14,520 --> 00:35:19,020
uh in 2019

938
00:35:19,020 --> 00:35:22,079
um era researchers figured out a reverse

939
00:35:22,079 --> 00:35:24,060
engineered silence malware detection

940
00:35:24,060 --> 00:35:24,900
system

941
00:35:24,900 --> 00:35:28,140
so it works the same way so it's got

942
00:35:28,140 --> 00:35:31,200
your PE file injected into a 7 000

943
00:35:31,200 --> 00:35:32,700
dimensional space this time instead of

944
00:35:32,700 --> 00:35:34,920
three thousand uh 2 300 Dimension space

945
00:35:34,920 --> 00:35:36,780
but through the same intermediate the

946
00:35:36,780 --> 00:35:39,599
intermediary format and then to a deep

947
00:35:39,599 --> 00:35:41,460
learning model and the Deep learning

948
00:35:41,460 --> 00:35:42,780
model figures it out whether it's good

949
00:35:42,780 --> 00:35:43,980
or bad

950
00:35:43,980 --> 00:35:46,020
so that's how the machine learning model

951
00:35:46,020 --> 00:35:48,180
is supposed to work but problem that

952
00:35:48,180 --> 00:35:49,380
they were having

953
00:35:49,380 --> 00:35:52,560
was that

954
00:35:52,560 --> 00:35:55,500
fortnite does some shady shots Shady

955
00:35:55,500 --> 00:35:56,540
stuff

956
00:35:56,540 --> 00:35:58,859
to make sure that you're not cheating

957
00:35:58,859 --> 00:36:01,200
rocket League does the same thing these

958
00:36:01,200 --> 00:36:03,660
things that you know these are binaries

959
00:36:03,660 --> 00:36:05,339
that

960
00:36:05,339 --> 00:36:07,380
um you might not launch on your

961
00:36:07,380 --> 00:36:09,960
corporate network but Thailand sells to

962
00:36:09,960 --> 00:36:12,180
people and they've installed fortnite on

963
00:36:12,180 --> 00:36:13,640
their computer and fortnite should run

964
00:36:13,640 --> 00:36:16,320
and it's very easy for the machine

965
00:36:16,320 --> 00:36:19,020
learning model to confuse fortnite with

966
00:36:19,020 --> 00:36:21,540
malware because fortnite does some weird

967
00:36:21,540 --> 00:36:23,280
stuff with process injection to make

968
00:36:23,280 --> 00:36:26,040
sure that you're not cheating

969
00:36:26,040 --> 00:36:28,859
um what silence did to fight this

970
00:36:28,859 --> 00:36:30,500
instead of

971
00:36:30,500 --> 00:36:33,900
putting putting in fortnite and Rocket

972
00:36:33,900 --> 00:36:35,220
league and everything on an exception

973
00:36:35,220 --> 00:36:37,260
list which they'd have to update every

974
00:36:37,260 --> 00:36:40,140
single time that fortnite updates they

975
00:36:40,140 --> 00:36:41,820
use some machine learning

976
00:36:41,820 --> 00:36:44,760
so they normalize the features

977
00:36:44,760 --> 00:36:46,500
um and then put it into a centroid thing

978
00:36:46,500 --> 00:36:48,960
and they use the concepts from earlier

979
00:36:48,960 --> 00:36:51,060
they put a little neighborhood around

980
00:36:51,060 --> 00:36:54,060
the point that represents a fortnight

981
00:36:54,060 --> 00:36:55,380
that they thought

982
00:36:55,380 --> 00:36:59,160
and this and if you are a piece of if

983
00:36:59,160 --> 00:37:02,160
you're a binary who gets featurized from

984
00:37:02,160 --> 00:37:05,400
your PE space ends up in that centroid

985
00:37:05,400 --> 00:37:07,079
for fortnite

986
00:37:07,079 --> 00:37:09,780
they will let you run

987
00:37:09,780 --> 00:37:12,480
so instead of letting the machine

988
00:37:12,480 --> 00:37:14,220
learning model figure this out and then

989
00:37:14,220 --> 00:37:16,260
telling them like hey really don't

990
00:37:16,260 --> 00:37:18,540
misclassify fortnite they need to run on

991
00:37:18,540 --> 00:37:21,720
our customs machines they use this trick

992
00:37:21,720 --> 00:37:24,180
to sort of

993
00:37:24,180 --> 00:37:26,400
it's putting on all the Fortnight

994
00:37:26,400 --> 00:37:28,200
hopefully Forever on the exception list

995
00:37:28,200 --> 00:37:29,700
and they did this for a bunch of other

996
00:37:29,700 --> 00:37:31,200
games like rocket league and other

997
00:37:31,200 --> 00:37:33,119
things so

998
00:37:33,119 --> 00:37:36,720
adidan uh should I uh figure this out

999
00:37:36,720 --> 00:37:39,540
and they built a exploit for the machine

1000
00:37:39,540 --> 00:37:43,260
Air Model that is all over things uh X

1001
00:37:43,260 --> 00:37:45,300
Machining our model was an exploit this

1002
00:37:45,300 --> 00:37:48,180
is big news in the AI security space

1003
00:37:48,180 --> 00:37:51,000
this is a poster child for the miter

1004
00:37:51,000 --> 00:37:54,000
exception a minor thing and they didn't

1005
00:37:54,000 --> 00:37:56,940
build an A Serial example they exploited

1006
00:37:56,940 --> 00:37:59,339
this kind of stupid

1007
00:37:59,339 --> 00:38:00,119
um

1008
00:38:00,119 --> 00:38:03,540
centroid thing centroid white listing

1009
00:38:03,540 --> 00:38:06,540
system that silence had built

1010
00:38:06,540 --> 00:38:09,839
um it's not stupid but like you there

1011
00:38:09,839 --> 00:38:12,599
were probably better ways to do this

1012
00:38:12,599 --> 00:38:14,640
part of the reason why they had this

1013
00:38:14,640 --> 00:38:16,680
problem is they included a lot of string

1014
00:38:16,680 --> 00:38:18,420
data in their malware model and that's

1015
00:38:18,420 --> 00:38:21,240
not a really good idea as we've seen

1016
00:38:21,240 --> 00:38:22,920
that that's one of the oldest attacks

1017
00:38:22,920 --> 00:38:24,599
against machine learning models packing

1018
00:38:24,599 --> 00:38:27,480
good strings and that's how the

1019
00:38:27,480 --> 00:38:31,760
uh exploit worked out in this case

1020
00:38:31,859 --> 00:38:33,660
so

1021
00:38:33,660 --> 00:38:36,119
what would actual security from reducing

1022
00:38:36,119 --> 00:38:39,440
online models work at and here's my

1023
00:38:39,440 --> 00:38:43,520
opinions with some certificating

1024
00:38:45,359 --> 00:38:47,579
so first thing

1025
00:38:47,579 --> 00:38:50,220
um it's still software do the basics so

1026
00:38:50,220 --> 00:38:52,680
validate your inputs if you're taking in

1027
00:38:52,680 --> 00:38:55,920
a PNG file make sure that it hasn't got

1028
00:38:55,920 --> 00:39:00,180
a weird payload that pillow your python

1029
00:39:00,180 --> 00:39:02,820
library is going to uh

1030
00:39:02,820 --> 00:39:04,260
run

1031
00:39:04,260 --> 00:39:06,960
some old versions of pillow which is one

1032
00:39:06,960 --> 00:39:09,599
of the the biggest

1033
00:39:09,599 --> 00:39:11,520
things uh the biggest libraries for

1034
00:39:11,520 --> 00:39:15,000
handling images in Python had a remote

1035
00:39:15,000 --> 00:39:17,339
code execution exploit and if you're

1036
00:39:17,339 --> 00:39:19,619
using one of those old uh versions of

1037
00:39:19,619 --> 00:39:22,260
pillow you can get popped fairly easily

1038
00:39:22,260 --> 00:39:24,540
with someone sending a image file that's

1039
00:39:24,540 --> 00:39:27,119
got some issue double pick check your

1040
00:39:27,119 --> 00:39:30,000
pickles it's really easy to get a you

1041
00:39:30,000 --> 00:39:32,579
know pickles are pickles are rces

1042
00:39:32,579 --> 00:39:34,920
inherently and this is how a lot of

1043
00:39:34,920 --> 00:39:36,119
machine learning models are distributed

1044
00:39:36,119 --> 00:39:37,800
on the internet you want to download a

1045
00:39:37,800 --> 00:39:39,000
model from

1046
00:39:39,000 --> 00:39:41,160
arguing face it's entirely possible you

1047
00:39:41,160 --> 00:39:43,079
get there to pickle and the mo to open

1048
00:39:43,079 --> 00:39:44,880
that pickle you have to run remote

1049
00:39:44,880 --> 00:39:47,099
untrusted Co you know untrusted coat on

1050
00:39:47,099 --> 00:39:49,079
your machine but machine learning

1051
00:39:49,079 --> 00:39:51,180
machine learning people do this because

1052
00:39:51,180 --> 00:39:52,980
that is the normal way of Distributing a

1053
00:39:52,980 --> 00:39:54,960
model because models get complicated and

1054
00:39:54,960 --> 00:39:57,119
pickle is an easy way of doing this uh

1055
00:39:57,119 --> 00:40:00,440
check your deployments for cves

1056
00:40:00,540 --> 00:40:02,700
uh so you know scan your Docker

1057
00:40:02,700 --> 00:40:04,920
containers make sure all the packages

1058
00:40:04,920 --> 00:40:07,200
you're installing don't have a CV and

1059
00:40:07,200 --> 00:40:09,359
then check like for example the pillow

1060
00:40:09,359 --> 00:40:11,400
exploit that you have

1061
00:40:11,400 --> 00:40:13,920
um make sure you don't have that

1062
00:40:13,920 --> 00:40:15,720
um Harden everything so make sure you

1063
00:40:15,720 --> 00:40:17,520
know if you have a whole big complicated

1064
00:40:17,520 --> 00:40:18,900
machine learning pipeline for doing

1065
00:40:18,900 --> 00:40:22,140
inference put uh the make sure that all

1066
00:40:22,140 --> 00:40:23,880
of that's hidden and there's a one

1067
00:40:23,880 --> 00:40:25,800
hardened front end point

1068
00:40:25,800 --> 00:40:27,300
um that they go to and everything else

1069
00:40:27,300 --> 00:40:29,819
is hardened as much as you can

1070
00:40:29,819 --> 00:40:32,760
and the last one which is you know uh

1071
00:40:32,760 --> 00:40:34,680
refrain broken refrain and security is

1072
00:40:34,680 --> 00:40:37,740
uh secure your S3 buckets uh

1073
00:40:37,740 --> 00:40:39,720
that's happened

1074
00:40:39,720 --> 00:40:41,940
um there's been places that have had

1075
00:40:41,940 --> 00:40:43,980
people messing with their data sets on

1076
00:40:43,980 --> 00:40:47,520
S3 because they're messed up

1077
00:40:47,520 --> 00:40:49,079
um this is the institute for the

1078
00:40:49,079 --> 00:40:50,760
technical Ai and machine learning

1079
00:40:50,760 --> 00:40:53,579
recommendations these and you can see a

1080
00:40:53,579 --> 00:40:56,660
lot of these are

1081
00:40:56,760 --> 00:40:57,859
um

1082
00:40:57,859 --> 00:40:59,640
basically

1083
00:40:59,640 --> 00:41:01,920
um classic exploits just renamed for

1084
00:41:01,920 --> 00:41:04,380
machine learning stuff so uh artifact

1085
00:41:04,380 --> 00:41:07,380
exploit injection that's your file uh

1086
00:41:07,380 --> 00:41:09,420
server side request forgery all these

1087
00:41:09,420 --> 00:41:10,920
things are things that are normally like

1088
00:41:10,920 --> 00:41:13,560
normally happen in uh up you know an

1089
00:41:13,560 --> 00:41:15,900
opsec environment you know Cloud

1090
00:41:15,900 --> 00:41:17,520
deployment you can get all that sort of

1091
00:41:17,520 --> 00:41:19,200
stuff happening it's no different from

1092
00:41:19,200 --> 00:41:21,180
information models don't think you're

1093
00:41:21,180 --> 00:41:22,740
special because you're using deep

1094
00:41:22,740 --> 00:41:24,839
learning

1095
00:41:24,839 --> 00:41:28,260
okay so once you have done the basics

1096
00:41:28,260 --> 00:41:29,400
um

1097
00:41:29,400 --> 00:41:31,380
and only after you've done the basics to

1098
00:41:31,380 --> 00:41:33,359
make sure that your S3 bucket does thing

1099
00:41:33,359 --> 00:41:35,520
the next thing you should think about is

1100
00:41:35,520 --> 00:41:38,339
well this is probably yeah

1101
00:41:38,339 --> 00:41:40,380
before you start really start barking on

1102
00:41:40,380 --> 00:41:41,160
this

1103
00:41:41,160 --> 00:41:43,920
your data set is more valuable than any

1104
00:41:43,920 --> 00:41:46,440
model you ever deploy treat your models

1105
00:41:46,440 --> 00:41:49,079
are sort of disposable your data set

1106
00:41:49,079 --> 00:41:51,180
is sometimes irrecoverable if someone

1107
00:41:51,180 --> 00:41:54,240
deletes that permanently of your Cloud

1108
00:41:54,240 --> 00:41:56,460
bucket Cloud infrastructure you can

1109
00:41:56,460 --> 00:41:58,500
never get it back if you're

1110
00:41:58,500 --> 00:42:01,260
you know cluster FS messes up you're

1111
00:42:01,260 --> 00:42:03,839
messed your hose the attackers get hold

1112
00:42:03,839 --> 00:42:05,280
of your data set they can ransomware

1113
00:42:05,280 --> 00:42:07,500
this because it's worth more much more

1114
00:42:07,500 --> 00:42:10,680
than the thing uh you

1115
00:42:10,680 --> 00:42:13,380
a lot of companies are figuring this out

1116
00:42:13,380 --> 00:42:15,180
um they're investing in data engineers

1117
00:42:15,180 --> 00:42:17,880
and data quality is much much more

1118
00:42:17,880 --> 00:42:21,480
effective of an investment than

1119
00:42:21,480 --> 00:42:23,819
um investing in machine learning in more

1120
00:42:23,819 --> 00:42:27,780
data scientists but this doubly applies

1121
00:42:27,780 --> 00:42:29,819
to security make sure that like if

1122
00:42:29,819 --> 00:42:32,220
you're saving a data set write it to a

1123
00:42:32,220 --> 00:42:33,960
read a write only

1124
00:42:33,960 --> 00:42:36,540
S3 bucket that has no ability or to

1125
00:42:36,540 --> 00:42:38,339
overwrite data and then use a provision

1126
00:42:38,339 --> 00:42:41,099
a historical system so that you can't a

1127
00:42:41,099 --> 00:42:42,960
hacker cannot go along and delete all

1128
00:42:42,960 --> 00:42:45,420
data just have version you know versions

1129
00:42:45,420 --> 00:42:47,700
of stuff and then make a pipeline that

1130
00:42:47,700 --> 00:42:49,260
picks up the right version and does the

1131
00:42:49,260 --> 00:42:50,760
right thing

1132
00:42:50,760 --> 00:42:54,660
um don't you know if you if you can't if

1133
00:42:54,660 --> 00:42:56,040
they if they have the ability to delete

1134
00:42:56,040 --> 00:42:58,380
your data that is

1135
00:42:58,380 --> 00:43:01,619
or mess with it even subtly you can get

1136
00:43:01,619 --> 00:43:04,140
screwed

1137
00:43:04,140 --> 00:43:06,359
um another thing this is another thing

1138
00:43:06,359 --> 00:43:07,800
that machine learning security people

1139
00:43:07,800 --> 00:43:10,800
understand very intricately well but

1140
00:43:10,800 --> 00:43:13,740
um data scientists don't necessarily

1141
00:43:13,740 --> 00:43:15,240
um because they have it's not their

1142
00:43:15,240 --> 00:43:17,880
environment and they shouldn't have to

1143
00:43:17,880 --> 00:43:18,960
um

1144
00:43:18,960 --> 00:43:21,359
he needs layers in the security if you

1145
00:43:21,359 --> 00:43:22,819
just have a machine learning model

1146
00:43:22,819 --> 00:43:26,099
checking with your PE file is detonating

1147
00:43:26,099 --> 00:43:28,200
you're now vulnerable to living off the

1148
00:43:28,200 --> 00:43:30,420
land attacks or You're vulnerable to all

1149
00:43:30,420 --> 00:43:32,760
sorts of things you should have a dozen

1150
00:43:32,760 --> 00:43:37,020
things uh you know you know money layers

1151
00:43:37,020 --> 00:43:40,980
of security to prevent you know the you

1152
00:43:40,980 --> 00:43:43,680
phishing protection

1153
00:43:43,680 --> 00:43:45,780
um

1154
00:43:45,780 --> 00:43:47,880
fishing protection to prevent the PE

1155
00:43:47,880 --> 00:43:49,859
file from getting on your system uh

1156
00:43:49,859 --> 00:43:52,800
frequently uploaded uh things for that

1157
00:43:52,800 --> 00:43:55,800
own and signatures to make sure that you

1158
00:43:55,800 --> 00:43:57,599
are catching all the the stuff that's

1159
00:43:57,599 --> 00:43:58,980
really important

1160
00:43:58,980 --> 00:44:00,480
um that is recent so you don't even

1161
00:44:00,480 --> 00:44:02,940
bother your Machinery model if IMO text

1162
00:44:02,940 --> 00:44:04,980
dropped on your machine and you have the

1163
00:44:04,980 --> 00:44:06,660
hash for it and you're like okay cool

1164
00:44:06,660 --> 00:44:08,940
just don't run it don't even bother

1165
00:44:08,940 --> 00:44:12,780
wasting compute on this thing

1166
00:44:12,780 --> 00:44:16,020
um rules observability you know machine

1167
00:44:16,020 --> 00:44:17,460
learning con thing and if you're

1168
00:44:17,460 --> 00:44:20,760
deploying on a self-driving car well

1169
00:44:20,760 --> 00:44:22,619
well this is one of the classic examples

1170
00:44:22,619 --> 00:44:24,960
for adversarial examples well what if

1171
00:44:24,960 --> 00:44:27,000
they put a adversarial sticker on the

1172
00:44:27,000 --> 00:44:28,440
stop sign

1173
00:44:28,440 --> 00:44:30,599
okay what if they just took out the stop

1174
00:44:30,599 --> 00:44:31,560
sign

1175
00:44:31,560 --> 00:44:34,020
just removed it they don't need to make

1176
00:44:34,020 --> 00:44:37,500
up a very intricate difficult delicate

1177
00:44:37,500 --> 00:44:40,680
attack with a sticker on the stop sign

1178
00:44:40,680 --> 00:44:43,680
they could just take a hassle

1179
00:44:43,680 --> 00:44:45,720
uh and remove it

1180
00:44:45,720 --> 00:44:47,760
uh so you should be aware that stop

1181
00:44:47,760 --> 00:44:49,380
signs might not be there and maybe you

1182
00:44:49,380 --> 00:44:51,839
should have a database this would

1183
00:44:51,839 --> 00:44:53,940
require geofencing and things oh cool

1184
00:44:53,940 --> 00:44:55,920
here's all my stop signs of the entire

1185
00:44:55,920 --> 00:44:57,599
city and I have an agreement with the

1186
00:44:57,599 --> 00:44:58,859
city that they're going to tell me when

1187
00:44:58,859 --> 00:45:00,420
they install new stop signs and traffic

1188
00:45:00,420 --> 00:45:02,760
lights and they're going to communicate

1189
00:45:02,760 --> 00:45:05,160
between my car and the traffic lights

1190
00:45:05,160 --> 00:45:07,680
and we're gonna do double checks to make

1191
00:45:07,680 --> 00:45:09,540
sure that my

1192
00:45:09,540 --> 00:45:12,480
Tesla or to other self-driving car is

1193
00:45:12,480 --> 00:45:14,099
aware of how the traffic is going to be

1194
00:45:14,099 --> 00:45:16,020
thing independent of the road sign

1195
00:45:16,020 --> 00:45:18,300
conditions so that if there's snowing or

1196
00:45:18,300 --> 00:45:20,819
hail or a tree grew in the way you've

1197
00:45:20,819 --> 00:45:22,740
got a backup of a database that's a

1198
00:45:22,740 --> 00:45:24,839
layer of security in your machine in

1199
00:45:24,839 --> 00:45:27,060
your self-driving car that

1200
00:45:27,060 --> 00:45:30,420
is probably more important than serial

1201
00:45:30,420 --> 00:45:32,579
robustness and there's so many other

1202
00:45:32,579 --> 00:45:33,900
layers of security in your self-driving

1203
00:45:33,900 --> 00:45:35,400
car that you can probably put in there

1204
00:45:35,400 --> 00:45:36,780
other than

1205
00:45:36,780 --> 00:45:39,839
adversarial robustness

1206
00:45:39,839 --> 00:45:42,900
um last thing another thing don't deploy

1207
00:45:42,900 --> 00:45:44,819
and forget

1208
00:45:44,819 --> 00:45:48,300
they are models that are uh companies do

1209
00:45:48,300 --> 00:45:50,579
not like reach training very expensive

1210
00:45:50,579 --> 00:45:52,920
models

1211
00:45:52,920 --> 00:45:55,619
there is a you know if you have a large

1212
00:45:55,619 --> 00:45:56,940
language model and there's a

1213
00:45:56,940 --> 00:45:58,740
vulnerability that large language model

1214
00:45:58,740 --> 00:46:00,780
might have cost

1215
00:46:00,780 --> 00:46:04,500
a 20 million dollars to train and just

1216
00:46:04,500 --> 00:46:07,260
compute it might have cost the the

1217
00:46:07,260 --> 00:46:10,560
amount of the CO2 Vegas generates at six

1218
00:46:10,560 --> 00:46:13,319
months to train that model by itself

1219
00:46:13,319 --> 00:46:17,099
they don't want to redeploy that so they

1220
00:46:17,099 --> 00:46:18,960
don't thing and there a lot of companies

1221
00:46:18,960 --> 00:46:21,480
don't even think about it they train a

1222
00:46:21,480 --> 00:46:22,740
model deploy it and they're like cool

1223
00:46:22,740 --> 00:46:25,200
we're done we have solved

1224
00:46:25,200 --> 00:46:27,960
spam forever

1225
00:46:27,960 --> 00:46:31,020
uh and they have there's the bypasses or

1226
00:46:31,020 --> 00:46:34,020
they've sold La forever you can't just

1227
00:46:34,020 --> 00:46:35,700
sit there when you're deploying a

1228
00:46:35,700 --> 00:46:37,859
product you have a responsibility to

1229
00:46:37,859 --> 00:46:39,240
your customers you have a responsibility

1230
00:46:39,240 --> 00:46:40,980
to your people that you're going to

1231
00:46:40,980 --> 00:46:42,660
monitor it and make sure that it's still

1232
00:46:42,660 --> 00:46:43,560
working

1233
00:46:43,560 --> 00:46:45,599
that there isn't a bug and machine

1234
00:46:45,599 --> 00:46:47,940
learning models have a whole new range

1235
00:46:47,940 --> 00:46:49,560
of bugs that you think

1236
00:46:49,560 --> 00:46:51,660
back to the thing you could have a

1237
00:46:51,660 --> 00:46:53,640
bypass where like a new malware family

1238
00:46:53,640 --> 00:46:57,180
shows up or this new spam family or your

1239
00:46:57,180 --> 00:46:59,819
self-driving car doesn't recognize

1240
00:46:59,819 --> 00:47:02,819
that new other car because it looks kind

1241
00:47:02,819 --> 00:47:04,319
of funky

1242
00:47:04,319 --> 00:47:05,819
um it doesn't recognize that as a car

1243
00:47:05,819 --> 00:47:08,220
because it has weird tail lights and it

1244
00:47:08,220 --> 00:47:09,780
suddenly start you start start getting a

1245
00:47:09,780 --> 00:47:11,579
bunch of crashes into it

1246
00:47:11,579 --> 00:47:13,319
um you can't just sit there and like

1247
00:47:13,319 --> 00:47:15,660
think that you're my any model is going

1248
00:47:15,660 --> 00:47:18,540
to perform well over time you have to

1249
00:47:18,540 --> 00:47:19,740
monitor it

1250
00:47:19,740 --> 00:47:22,440
and this is really hard

1251
00:47:22,440 --> 00:47:26,220
you um in security you do not in in the

1252
00:47:26,220 --> 00:47:28,020
real world you do not have access to the

1253
00:47:28,020 --> 00:47:30,480
labels I made this graph knowing all the

1254
00:47:30,480 --> 00:47:33,839
labels uh post-purori at priori you have

1255
00:47:33,839 --> 00:47:36,119
no idea what the label is so how do you

1256
00:47:36,119 --> 00:47:37,980
know whether you're making an error if

1257
00:47:37,980 --> 00:47:40,380
you just have the estimate I have my

1258
00:47:40,380 --> 00:47:43,079
prediction I have a I don't I don't have

1259
00:47:43,079 --> 00:47:44,760
a label so I can't check whether I'm

1260
00:47:44,760 --> 00:47:47,819
right you have to build estimates and

1261
00:47:47,819 --> 00:47:50,280
complicated systems and

1262
00:47:50,280 --> 00:47:52,440
this is a huge investment to do

1263
00:47:52,440 --> 00:47:54,300
correctly

1264
00:47:54,300 --> 00:47:57,180
um but we need to make those Investments

1265
00:47:57,180 --> 00:47:59,819
um in the last

1266
00:47:59,819 --> 00:48:02,220
um well penultimate a point is you have

1267
00:48:02,220 --> 00:48:04,319
to understand your attackers

1268
00:48:04,319 --> 00:48:05,940
um so

1269
00:48:05,940 --> 00:48:08,339
attacking a self-driving car your

1270
00:48:08,339 --> 00:48:10,200
attackers might just want to embarrass

1271
00:48:10,200 --> 00:48:13,800
you or they might want to like

1272
00:48:13,800 --> 00:48:16,020
uh how you know find a bug and now

1273
00:48:16,020 --> 00:48:17,160
they've got a

1274
00:48:17,160 --> 00:48:19,140
you got to try to get a bounty out of

1275
00:48:19,140 --> 00:48:20,339
you

1276
00:48:20,339 --> 00:48:21,900
but they're just trying to embarrass you

1277
00:48:21,900 --> 00:48:23,880
and get a bounty there's not that much

1278
00:48:23,880 --> 00:48:26,520
value in confusing a car so it's not

1279
00:48:26,520 --> 00:48:28,020
going to be a widespread attack it's

1280
00:48:28,020 --> 00:48:29,819
going to happen because people if people

1281
00:48:29,819 --> 00:48:31,380
are going to want to embarrass you as a

1282
00:48:31,380 --> 00:48:33,059
software if you think

1283
00:48:33,059 --> 00:48:34,859
um but like it's not

1284
00:48:34,859 --> 00:48:36,500
as

1285
00:48:36,500 --> 00:48:39,119
valuable as detonating getting

1286
00:48:39,119 --> 00:48:41,819
ransomware on a Healthcare in a hospital

1287
00:48:41,819 --> 00:48:43,260
a hospital has to be running they're

1288
00:48:43,260 --> 00:48:44,579
going to give you the five million

1289
00:48:44,579 --> 00:48:46,980
dollars to unransomware the hospital you

1290
00:48:46,980 --> 00:48:49,260
go to immediate monetary value in

1291
00:48:49,260 --> 00:48:51,900
bypassing the other systems for the

1292
00:48:51,900 --> 00:48:54,960
security systems for that

1293
00:48:54,960 --> 00:48:56,819
you have to actually do the threat

1294
00:48:56,819 --> 00:48:58,380
modeling

1295
00:48:58,380 --> 00:49:01,500
you can't just assume that you're going

1296
00:49:01,500 --> 00:49:02,880
to be attacked in this one way because

1297
00:49:02,880 --> 00:49:04,980
it's a sexier way of because you really

1298
00:49:04,980 --> 00:49:06,599
want to do the math to defend yourself

1299
00:49:06,599 --> 00:49:09,480
because I want to do that research and

1300
00:49:09,480 --> 00:49:11,040
so I'm going to make up a threat model

1301
00:49:11,040 --> 00:49:13,680
so that I can do that research in the

1302
00:49:13,680 --> 00:49:15,780
industry you're in Academia

1303
00:49:15,780 --> 00:49:17,819
I think you should be doing

1304
00:49:17,819 --> 00:49:20,520
Research into model robustness is

1305
00:49:20,520 --> 00:49:24,059
important and wool is a

1306
00:49:24,059 --> 00:49:25,280
probably

1307
00:49:25,280 --> 00:49:28,619
a breakthrough in this thing might be

1308
00:49:28,619 --> 00:49:31,200
needed to bring the

1309
00:49:31,200 --> 00:49:33,720
machine learning model you know the

1310
00:49:33,720 --> 00:49:35,300
whole field of machine learning forward

1311
00:49:35,300 --> 00:49:39,380
but it's not a security problem

1312
00:49:39,380 --> 00:49:42,960
the last thing is be a moving Target and

1313
00:49:42,960 --> 00:49:44,579
this relates back to like

1314
00:49:44,579 --> 00:49:47,819
the drift uh but don't just retrain a

1315
00:49:47,819 --> 00:49:49,619
new model you have to make new features

1316
00:49:49,619 --> 00:49:51,720
you've got a security onion you have to

1317
00:49:51,720 --> 00:49:53,220
make new layers of that onion you can't

1318
00:49:53,220 --> 00:49:55,319
just sit there because the security

1319
00:49:55,319 --> 00:49:57,180
people are going to innovate

1320
00:49:57,180 --> 00:49:59,160
um but you make new features for your

1321
00:49:59,160 --> 00:50:01,920
model don't just sit there on the model

1322
00:50:01,920 --> 00:50:02,819
um

1323
00:50:02,819 --> 00:50:05,640
one company has a really nice way of

1324
00:50:05,640 --> 00:50:07,440
being a moving Target for their model

1325
00:50:07,440 --> 00:50:10,980
they have a bank of many many times more

1326
00:50:10,980 --> 00:50:12,960
features than they actually need

1327
00:50:12,960 --> 00:50:16,140
and they use a subset every month

1328
00:50:16,140 --> 00:50:18,180
um and they this is they do spam so they

1329
00:50:18,180 --> 00:50:19,980
have a lot of Behavioral data so they

1330
00:50:19,980 --> 00:50:22,500
use a subset of the data of the features

1331
00:50:22,500 --> 00:50:24,720
that they could use each month this

1332
00:50:24,720 --> 00:50:26,700
means each month's model is not as good

1333
00:50:26,700 --> 00:50:27,900
as it could be

1334
00:50:27,900 --> 00:50:30,180
so if you use more features you could

1335
00:50:30,180 --> 00:50:32,160
probably train up a better spam model

1336
00:50:32,160 --> 00:50:34,740
but this month's model and that's not

1337
00:50:34,740 --> 00:50:37,559
month it's week this week's model

1338
00:50:37,559 --> 00:50:39,420
homes and behaves fundamentally

1339
00:50:39,420 --> 00:50:41,220
different from next week's bottle so the

1340
00:50:41,220 --> 00:50:42,599
spammers might be figuring out how to

1341
00:50:42,599 --> 00:50:43,980
bypass this week's model and figure out

1342
00:50:43,980 --> 00:50:45,720
a bypass but it's definitely not going

1343
00:50:45,720 --> 00:50:47,579
to work next week because you just check

1344
00:50:47,579 --> 00:50:50,579
you just moving ahead you you you're

1345
00:50:50,579 --> 00:50:52,500
being a moving Target they're going to

1346
00:50:52,500 --> 00:50:54,900
figure out a bypass each

1347
00:50:54,900 --> 00:50:56,819
but if you can make sure that last

1348
00:50:56,819 --> 00:51:00,119
week's bypass will not work on this week

1349
00:51:00,119 --> 00:51:01,559
you're good

1350
00:51:01,559 --> 00:51:03,480
you might not be able to gather enough

1351
00:51:03,480 --> 00:51:06,599
data in that week for the bypass to

1352
00:51:06,599 --> 00:51:07,740
figure out things to make sure your

1353
00:51:07,740 --> 00:51:09,839
model is trained correctly to correctly

1354
00:51:09,839 --> 00:51:12,119
classified it but if you change the way

1355
00:51:12,119 --> 00:51:13,920
the model works you might not have to

1356
00:51:13,920 --> 00:51:15,119
worry about that bypass you have to

1357
00:51:15,119 --> 00:51:18,119
worry about a different one so they

1358
00:51:18,119 --> 00:51:19,920
've taken this concept of being a moving

1359
00:51:19,920 --> 00:51:22,319
Target to the next level which is

1360
00:51:22,319 --> 00:51:25,980
actually securing their way and it is

1361
00:51:25,980 --> 00:51:28,200
you know it is a drop in accuracy but

1362
00:51:28,200 --> 00:51:29,579
either the drop in accuracy that

1363
00:51:29,579 --> 00:51:31,619
actually gives up good cradle that they

1364
00:51:31,619 --> 00:51:33,599
have found that significantly improves

1365
00:51:33,599 --> 00:51:36,079
their stuff

1366
00:51:36,660 --> 00:51:39,900
um and finally um respond quickly uh

1367
00:51:39,900 --> 00:51:41,160
what's the turnaround for training a new

1368
00:51:41,160 --> 00:51:41,940
model

1369
00:51:41,940 --> 00:51:46,140
uh so what what Google did what one of

1370
00:51:46,140 --> 00:51:49,260
the embarrassing things that uh Google

1371
00:51:49,260 --> 00:51:54,300
had was in their uh pictures product

1372
00:51:54,300 --> 00:51:56,400
um they were misclassifying

1373
00:51:56,400 --> 00:51:59,220
black people as gorillas which is really

1374
00:51:59,220 --> 00:52:00,480
super racist

1375
00:52:00,480 --> 00:52:04,500
um and awful and they didn't do their

1376
00:52:04,500 --> 00:52:05,760
model correctly

1377
00:52:05,760 --> 00:52:07,619
the way they responded was they just

1378
00:52:07,619 --> 00:52:09,420
they removed all primates from their

1379
00:52:09,420 --> 00:52:11,040
data set so that the model can't

1380
00:52:11,040 --> 00:52:14,160
misclassify black people as

1381
00:52:14,160 --> 00:52:16,980
uh uh gorillas because the model doesn't

1382
00:52:16,980 --> 00:52:19,020
know what a gorilla is

1383
00:52:19,020 --> 00:52:21,180
that's how they responded

1384
00:52:21,180 --> 00:52:23,339
but the thing is they responded quickly

1385
00:52:23,339 --> 00:52:27,119
and that actually is not it's bad but

1386
00:52:27,119 --> 00:52:29,220
it's not the worst idea

1387
00:52:29,220 --> 00:52:31,260
if you need if you want to prevent this

1388
00:52:31,260 --> 00:52:33,359
from happening and you only have a few

1389
00:52:33,359 --> 00:52:35,760
days to figure out how to quickly get

1390
00:52:35,760 --> 00:52:38,099
your model to stop doing this

1391
00:52:38,099 --> 00:52:40,200
it might take you six more months to

1392
00:52:40,200 --> 00:52:41,640
gather the data to prevent this from

1393
00:52:41,640 --> 00:52:43,680
happening but you need to respond in

1394
00:52:43,680 --> 00:52:46,800
three days so quickly removing the

1395
00:52:46,800 --> 00:52:49,260
primates was a quick way for them to

1396
00:52:49,260 --> 00:52:51,839
respond to this one problem

1397
00:52:51,839 --> 00:52:54,599
and then they to buy them time to

1398
00:52:54,599 --> 00:52:56,640
actually invest and do it properly over

1399
00:52:56,640 --> 00:52:58,879
time

1400
00:52:59,460 --> 00:53:01,200
um they still have a little bit of

1401
00:53:01,200 --> 00:53:03,000
issues with this but this is one of the

1402
00:53:03,000 --> 00:53:05,099
you know the bias in machine learning

1403
00:53:05,099 --> 00:53:07,740
all sorts of papers not a talk about

1404
00:53:07,740 --> 00:53:11,640
that but they responded quickly in that

1405
00:53:11,640 --> 00:53:14,040
sort of shitty way but it was a response

1406
00:53:14,040 --> 00:53:16,980
that thing

1407
00:53:16,980 --> 00:53:19,500
um the code language model May generate

1408
00:53:19,500 --> 00:53:21,780
vulnerabilities you've got a you know

1409
00:53:21,780 --> 00:53:24,780
codex might suggest code for you that

1410
00:53:24,780 --> 00:53:26,640
has a vulnerability in it because it's

1411
00:53:26,640 --> 00:53:29,520
memorized the code from a stack Overflow

1412
00:53:29,520 --> 00:53:31,079
post

1413
00:53:31,079 --> 00:53:33,599
and that's bad like you're you know a

1414
00:53:33,599 --> 00:53:35,160
lot of people are gonna be oh cool codex

1415
00:53:35,160 --> 00:53:36,720
did this include it because I'm going to

1416
00:53:36,720 --> 00:53:40,099
trust the machine learning model and

1417
00:53:40,099 --> 00:53:42,420
well you've now got a vulnerability that

1418
00:53:42,420 --> 00:53:43,859
codex put there

1419
00:53:43,859 --> 00:53:45,720
that is bad

1420
00:53:45,720 --> 00:53:49,140
uh and we have found large language

1421
00:53:49,140 --> 00:53:50,300
models

1422
00:53:50,300 --> 00:53:52,980
suggesting vulnerabilities to include in

1423
00:53:52,980 --> 00:53:56,819
your uh code and Microsoft sat on their

1424
00:53:56,819 --> 00:53:58,380
ass for six months before they started

1425
00:53:58,380 --> 00:54:00,660
doing anything

1426
00:54:00,660 --> 00:54:02,700
um

1427
00:54:02,700 --> 00:54:06,240
other linters and um uh code editors

1428
00:54:06,240 --> 00:54:08,760
fixed it quickly because they are in the

1429
00:54:08,760 --> 00:54:09,960
security space and they understand that

1430
00:54:09,960 --> 00:54:11,640
they have to respond and the people in

1431
00:54:11,640 --> 00:54:13,140
the machine learning space

1432
00:54:13,140 --> 00:54:14,760
they sat on it for six months because

1433
00:54:14,760 --> 00:54:16,740
how do I solve this problem with

1434
00:54:16,740 --> 00:54:19,079
memorizing things it's so much harder

1435
00:54:19,079 --> 00:54:20,940
like you kind of have to do something

1436
00:54:20,940 --> 00:54:22,920
quickly Google by Microsoft you can't

1437
00:54:22,920 --> 00:54:25,319
just like sit on your ass for six months

1438
00:54:25,319 --> 00:54:27,000
um

1439
00:54:27,000 --> 00:54:28,140
so

1440
00:54:28,140 --> 00:54:29,819
I think machine learning should be held

1441
00:54:29,819 --> 00:54:32,040
to that standard anyway

1442
00:54:32,040 --> 00:54:33,359
um so

1443
00:54:33,359 --> 00:54:35,900
questions

1444
00:54:38,040 --> 00:54:40,680
I have if you want references you can

1445
00:54:40,680 --> 00:54:43,520
find them online

1446
00:54:43,680 --> 00:54:44,400
um

1447
00:54:44,400 --> 00:54:47,540
on the GitHub

1448
00:54:50,790 --> 00:54:53,869
[Music]

