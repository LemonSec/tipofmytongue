1
00:00:00,080 --> 00:00:02,080
the talk right now is that escalated

2
00:00:02,080 --> 00:00:04,400
quickly a system for alert prior

3
00:00:04,400 --> 00:00:06,960
prioritization and it's with ben gilman

4
00:00:06,960 --> 00:00:10,480
of sofos so please welcome him

5
00:00:14,799 --> 00:00:16,400
alrighty quick audio check hopefully

6
00:00:16,400 --> 00:00:18,560
everyone can hear me

7
00:00:18,560 --> 00:00:20,800
okay hi i'm ben gelman and i'm

8
00:00:20,800 --> 00:00:23,119
presenting that escalated quickly a

9
00:00:23,119 --> 00:00:25,680
system for alert prioritization

10
00:00:25,680 --> 00:00:27,359
uh we have plenty of time here together

11
00:00:27,359 --> 00:00:30,560
so take a seat sit back relax enjoy the

12
00:00:30,560 --> 00:00:32,558
show

13
00:00:32,558 --> 00:00:34,480
so first let me just acknowledge um all

14
00:00:34,480 --> 00:00:36,880
the people that worked on this project

15
00:00:36,880 --> 00:00:38,399
uh it takes a lot of people with a lot

16
00:00:38,399 --> 00:00:40,079
of different specialties

17
00:00:40,079 --> 00:00:41,600
to put together a project that has a lot

18
00:00:41,600 --> 00:00:43,840
of moving parts and get it working in a

19
00:00:43,840 --> 00:00:45,680
realistic scenario so thank you to

20
00:00:45,680 --> 00:00:47,760
everyone who worked on it

21
00:00:47,760 --> 00:00:49,760
and let me just start by talking a

22
00:00:49,760 --> 00:00:51,520
little bit about myself

23
00:00:51,520 --> 00:00:53,280
i've been a research sof research

24
00:00:53,280 --> 00:00:55,760
scientist at sofos for a little over the

25
00:00:55,760 --> 00:00:57,039
last year

26
00:00:57,039 --> 00:00:59,840
and most of my work has been focused on

27
00:00:59,840 --> 00:01:02,719
integrating machine learning

28
00:01:02,719 --> 00:01:04,239
in a way that

29
00:01:04,239 --> 00:01:06,880
analysts and real humans can utilize and

30
00:01:06,880 --> 00:01:08,640
improve the efficiency of security

31
00:01:08,640 --> 00:01:13,040
operations centers or socks for short

32
00:01:13,040 --> 00:01:14,560
and we want to see this machine learning

33
00:01:14,560 --> 00:01:15,920
really get used by real humans and

34
00:01:15,920 --> 00:01:17,520
that's kind of the goal of this research

35
00:01:17,520 --> 00:01:19,280
and i'm going to talk about a lot of

36
00:01:19,280 --> 00:01:21,040
that today

37
00:01:21,040 --> 00:01:22,320
but before that

38
00:01:22,320 --> 00:01:24,479
i did five years in government-funded

39
00:01:24,479 --> 00:01:26,400
research and development and this is

40
00:01:26,400 --> 00:01:27,920
kind of where i started in the

41
00:01:27,920 --> 00:01:29,520
intersection of machine learning and

42
00:01:29,520 --> 00:01:31,439
cyber security

43
00:01:31,439 --> 00:01:32,880
so the first things i kind of did here

44
00:01:32,880 --> 00:01:34,960
was using machine learning to analyze

45
00:01:34,960 --> 00:01:37,280
source code we attempted to categorize

46
00:01:37,280 --> 00:01:39,520
it explain it and segment it in logical

47
00:01:39,520 --> 00:01:41,040
ways

48
00:01:41,040 --> 00:01:42,560
and eventually we took those techniques

49
00:01:42,560 --> 00:01:44,560
which were pretty successful and started

50
00:01:44,560 --> 00:01:46,799
using them on binaries

51
00:01:46,799 --> 00:01:48,479
and then even further we started

52
00:01:48,479 --> 00:01:50,320
combining those two

53
00:01:50,320 --> 00:01:52,079
projects and using it for reverse

54
00:01:52,079 --> 00:01:54,159
engineering combining binaries and

55
00:01:54,159 --> 00:01:56,079
source code and creating an explainable

56
00:01:56,079 --> 00:01:59,119
system for reverse engineers to use

57
00:01:59,119 --> 00:02:00,240
i worked on a variety of other

58
00:02:00,240 --> 00:02:02,560
miscellaneous tasks there as well

59
00:02:02,560 --> 00:02:04,719
but before that i did two years of

60
00:02:04,719 --> 00:02:06,719
post-grad research at academic

61
00:02:06,719 --> 00:02:09,119
institutions i didn't do any cyber

62
00:02:09,119 --> 00:02:10,878
security here but some of you may

63
00:02:10,878 --> 00:02:12,560
recognize some of the labs that i worked

64
00:02:12,560 --> 00:02:13,520
at

65
00:02:13,520 --> 00:02:16,480
they looked kind of like this

66
00:02:16,480 --> 00:02:18,319
no offense to any academic researchers

67
00:02:18,319 --> 00:02:20,080
who are here

68
00:02:20,080 --> 00:02:20,800
so

69
00:02:20,800 --> 00:02:22,160
all of my schooling was in computer

70
00:02:22,160 --> 00:02:25,040
science with a focus in machine learning

71
00:02:25,040 --> 00:02:27,120
but anyways enough about me let's talk

72
00:02:27,120 --> 00:02:29,120
about the talk

73
00:02:29,120 --> 00:02:30,239
so

74
00:02:30,239 --> 00:02:31,920
i just want to go over everything i'm

75
00:02:31,920 --> 00:02:33,920
going to say today so you kind of get

76
00:02:33,920 --> 00:02:35,599
a general idea of where we are during

77
00:02:35,599 --> 00:02:37,840
the presentation at various times

78
00:02:37,840 --> 00:02:39,120
and so you can kind of keep everything

79
00:02:39,120 --> 00:02:40,480
in context because there is a lot of

80
00:02:40,480 --> 00:02:42,720
moving parts here

81
00:02:42,720 --> 00:02:44,080
so the first thing i'm going to do is

82
00:02:44,080 --> 00:02:46,720
talk about the problem context i'm going

83
00:02:46,720 --> 00:02:48,640
to tell you how our system that

84
00:02:48,640 --> 00:02:51,440
escalated quickly or tech for short

85
00:02:51,440 --> 00:02:52,239
uh

86
00:02:52,239 --> 00:02:54,959
operates in a real world sock

87
00:02:54,959 --> 00:02:57,040
just so you kind of see what it actually

88
00:02:57,040 --> 00:02:58,800
does

89
00:02:58,800 --> 00:03:01,920
and then we'll go back and describe um

90
00:03:01,920 --> 00:03:04,480
why we need this and what are the main

91
00:03:04,480 --> 00:03:06,080
problems that are affecting socks and

92
00:03:06,080 --> 00:03:08,560
why we need the solution

93
00:03:08,560 --> 00:03:10,480
after that i will go over the actual

94
00:03:10,480 --> 00:03:12,640
system and talk about its four main

95
00:03:12,640 --> 00:03:13,840
modules

96
00:03:13,840 --> 00:03:15,599
and how they solve those problems that

97
00:03:15,599 --> 00:03:18,319
we reference in the context

98
00:03:18,319 --> 00:03:19,760
after that we'll talk about experimental

99
00:03:19,760 --> 00:03:21,440
setup so how we actually got the system

100
00:03:21,440 --> 00:03:23,519
up and running the kind of data we used

101
00:03:23,519 --> 00:03:25,120
and how we plan to evaluate it in an

102
00:03:25,120 --> 00:03:27,440
effective way

103
00:03:27,440 --> 00:03:28,799
and finally we'll talk about the fun

104
00:03:28,799 --> 00:03:30,080
part which is the results on the key

105
00:03:30,080 --> 00:03:32,560
takeaways

106
00:03:32,560 --> 00:03:34,319
okay so let's jump in right to the

107
00:03:34,319 --> 00:03:36,480
problem context

108
00:03:36,480 --> 00:03:38,159
so many of you are probably already

109
00:03:38,159 --> 00:03:40,159
familiar with how a sock operates but

110
00:03:40,159 --> 00:03:42,640
i'll go over it from a high level

111
00:03:42,640 --> 00:03:45,519
so we at sofos operate a sock and we

112
00:03:45,519 --> 00:03:46,879
have a lot of customers that we're

113
00:03:46,879 --> 00:03:48,959
trying to protect

114
00:03:48,959 --> 00:03:51,519
and from those customers devices we're

115
00:03:51,519 --> 00:03:53,200
constantly collecting events using

116
00:03:53,200 --> 00:03:54,799
different sensors

117
00:03:54,799 --> 00:03:57,120
and those events go to a single central

118
00:03:57,120 --> 00:04:00,159
platform which we call sofo sofocentral

119
00:04:00,159 --> 00:04:02,000
so of course in its name this is where

120
00:04:02,000 --> 00:04:03,360
we collect all this information from the

121
00:04:03,360 --> 00:04:05,360
customer devices

122
00:04:05,360 --> 00:04:08,239
uh to perform analysis

123
00:04:08,239 --> 00:04:11,120
so sitting here in sofocentral

124
00:04:11,120 --> 00:04:14,400
is a whole array of handwritten rules

125
00:04:14,400 --> 00:04:17,120
that domain experts have used in order

126
00:04:17,120 --> 00:04:19,519
to determine how severe these events are

127
00:04:19,519 --> 00:04:21,358
that we're collecting

128
00:04:21,358 --> 00:04:23,360
from our customers

129
00:04:23,360 --> 00:04:24,400
so this is a little bit of a

130
00:04:24,400 --> 00:04:26,400
simplification but

131
00:04:26,400 --> 00:04:28,560
basically these rules these handwritten

132
00:04:28,560 --> 00:04:29,520
rules

133
00:04:29,520 --> 00:04:32,320
can assign a high medium or low severity

134
00:04:32,320 --> 00:04:33,840
to these events

135
00:04:33,840 --> 00:04:36,560
or in other words these alerts

136
00:04:36,560 --> 00:04:38,960
and what happens is that

137
00:04:38,960 --> 00:04:42,240
when a high severity alert occurs we

138
00:04:42,240 --> 00:04:43,919
open up this thing that we call an

139
00:04:43,919 --> 00:04:45,360
incident

140
00:04:45,360 --> 00:04:47,840
and an incident grabs all the alerts

141
00:04:47,840 --> 00:04:49,680
from around that time period and

142
00:04:49,680 --> 00:04:52,639
packages it up in one little box

143
00:04:52,639 --> 00:04:54,320
every single one of these incidents

144
00:04:54,320 --> 00:04:57,199
needs to be manually inspected by a

145
00:04:57,199 --> 00:05:00,080
cyber security analyst

146
00:05:00,080 --> 00:05:01,759
in order to resolve the potential

147
00:05:01,759 --> 00:05:03,680
malicious behavior that's happening on

148
00:05:03,680 --> 00:05:06,639
the customer's devices

149
00:05:06,639 --> 00:05:08,639
the main issue here

150
00:05:08,639 --> 00:05:11,280
is that the rules that assign these high

151
00:05:11,280 --> 00:05:12,960
severities

152
00:05:12,960 --> 00:05:14,639
are very generous with how they deal

153
00:05:14,639 --> 00:05:15,680
them out

154
00:05:15,680 --> 00:05:17,280
and the reason for that is we don't want

155
00:05:17,280 --> 00:05:19,759
to miss any actual malicious behavior

156
00:05:19,759 --> 00:05:21,360
that's happening on the customer's

157
00:05:21,360 --> 00:05:22,800
devices

158
00:05:22,800 --> 00:05:25,120
so we assign lots of high severities

159
00:05:25,120 --> 00:05:27,120
which opens up a lot of incidents and

160
00:05:27,120 --> 00:05:30,160
that leads to some busy analysts

161
00:05:30,160 --> 00:05:32,320
now what we're trying to do here is use

162
00:05:32,320 --> 00:05:34,960
our system data security quickly or tech

163
00:05:34,960 --> 00:05:39,360
to sit in this incident creation process

164
00:05:39,360 --> 00:05:41,120
and what tech does

165
00:05:41,120 --> 00:05:44,320
is it re-evaluates the severity of these

166
00:05:44,320 --> 00:05:46,320
alerts

167
00:05:46,320 --> 00:05:48,560
and just to give you an example here

168
00:05:48,560 --> 00:05:50,160
there may be a high severity alert that

169
00:05:50,160 --> 00:05:51,199
comes in

170
00:05:51,199 --> 00:05:52,960
tech looks at it and realizes this is

171
00:05:52,960 --> 00:05:56,479
not actually something important

172
00:05:56,560 --> 00:05:58,240
and that results in an incident that no

173
00:05:58,240 --> 00:06:00,639
longer has any high severity alerts

174
00:06:00,639 --> 00:06:02,319
and this means that the system can

175
00:06:02,319 --> 00:06:04,639
deprioritize this case heavily it might

176
00:06:04,639 --> 00:06:06,080
not even be worth it for the analysts to

177
00:06:06,080 --> 00:06:08,240
look at at all

178
00:06:08,240 --> 00:06:10,560
but not only that tech is also able to

179
00:06:10,560 --> 00:06:13,120
look within a single incident and help

180
00:06:13,120 --> 00:06:16,080
point an analyst to specific alerts that

181
00:06:16,080 --> 00:06:19,039
it thinks they should look at

182
00:06:19,039 --> 00:06:21,039
some incidents you just have to open

183
00:06:21,039 --> 00:06:22,319
there are actual threats that the

184
00:06:22,319 --> 00:06:24,319
analysts need to work through but even

185
00:06:24,319 --> 00:06:26,240
if that's the case even if they really

186
00:06:26,240 --> 00:06:27,919
have to look at this incident at least

187
00:06:27,919 --> 00:06:30,720
they can get through it faster

188
00:06:30,720 --> 00:06:32,400
overall this leads to some happier

189
00:06:32,400 --> 00:06:34,560
analysts and i don't want to spoil all

190
00:06:34,560 --> 00:06:36,880
of the results just yet

191
00:06:36,880 --> 00:06:37,600
but

192
00:06:37,600 --> 00:06:38,800
just to give you a reason to keep

193
00:06:38,800 --> 00:06:40,319
listening to the talk

194
00:06:40,319 --> 00:06:42,720
we see a reduction of about 47 percent

195
00:06:42,720 --> 00:06:44,560
on average in these false positive or

196
00:06:44,560 --> 00:06:47,360
useless cases

197
00:06:47,440 --> 00:06:50,240
okay so that's how the

198
00:06:50,240 --> 00:06:52,560
tech system fits into a real world sock

199
00:06:52,560 --> 00:06:54,880
now why does this matter

200
00:06:54,880 --> 00:06:56,720
some of the reasons are obvious right if

201
00:06:56,720 --> 00:06:58,160
your analysts are more efficient they

202
00:06:58,160 --> 00:06:59,520
don't waste their time on cases that

203
00:06:59,520 --> 00:07:01,199
don't need their attention that means

204
00:07:01,199 --> 00:07:03,039
you can have more customers and more

205
00:07:03,039 --> 00:07:05,120
customers means more money

206
00:07:05,120 --> 00:07:07,599
and by more money i mean

207
00:07:07,599 --> 00:07:09,759
the analysts can work to protect the

208
00:07:09,759 --> 00:07:11,520
world against cyber threats and help the

209
00:07:11,520 --> 00:07:14,240
people who need them

210
00:07:14,800 --> 00:07:16,720
so it's not just for business reasons

211
00:07:16,720 --> 00:07:17,919
but also

212
00:07:17,919 --> 00:07:20,000
the kind of work of having to go through

213
00:07:20,000 --> 00:07:22,240
cases that they've already seen before

214
00:07:22,240 --> 00:07:24,560
um is frustrating it's demotivating and

215
00:07:24,560 --> 00:07:26,000
it's tedious

216
00:07:26,000 --> 00:07:27,759
it's bad for job retention and it's bad

217
00:07:27,759 --> 00:07:29,919
for job satisfaction of these analysts

218
00:07:29,919 --> 00:07:32,160
so letting them do work on cases that

219
00:07:32,160 --> 00:07:34,080
really need their attention

220
00:07:34,080 --> 00:07:38,159
is important for their work life as well

221
00:07:39,199 --> 00:07:41,599
okay so now that we see where tech kind

222
00:07:41,599 --> 00:07:44,960
of fits in and why it matters

223
00:07:44,960 --> 00:07:47,120
we want to address four main problems

224
00:07:47,120 --> 00:07:50,479
that cause these inefficiencies in socks

225
00:07:50,479 --> 00:07:51,599
and there's four main issues that we

226
00:07:51,599 --> 00:07:54,319
identify that tech attempts to solve

227
00:07:54,319 --> 00:07:56,400
these are sensor diversity false

228
00:07:56,400 --> 00:07:59,039
positives evolving threats and human

229
00:07:59,039 --> 00:08:01,039
integration

230
00:08:01,039 --> 00:08:02,400
so i'm going to go through every single

231
00:08:02,400 --> 00:08:04,319
one of these in detail so that we really

232
00:08:04,319 --> 00:08:05,919
understand where the problems are coming

233
00:08:05,919 --> 00:08:06,960
from

234
00:08:06,960 --> 00:08:08,720
so the first issue here is sensor

235
00:08:08,720 --> 00:08:10,800
diversity

236
00:08:10,800 --> 00:08:12,960
so sensor diversity at first may not

237
00:08:12,960 --> 00:08:15,440
sound like a bad thing socks employ lots

238
00:08:15,440 --> 00:08:17,120
of different sensors they catch lots of

239
00:08:17,120 --> 00:08:19,120
different behaviors that's a good thing

240
00:08:19,120 --> 00:08:20,560
right

241
00:08:20,560 --> 00:08:22,800
um the problem is that these sensors are

242
00:08:22,800 --> 00:08:24,400
not standardized

243
00:08:24,400 --> 00:08:26,000
uh every sensor captures a different

244
00:08:26,000 --> 00:08:27,840
piece of information focuses on a

245
00:08:27,840 --> 00:08:30,160
different thing or outputs the data in a

246
00:08:30,160 --> 00:08:31,599
different way

247
00:08:31,599 --> 00:08:34,080
and that creates challenges both from an

248
00:08:34,080 --> 00:08:36,000
engineering perspective and a machine

249
00:08:36,000 --> 00:08:38,479
learning perspective

250
00:08:38,479 --> 00:08:40,559
every time you need to add a sensor that

251
00:08:40,559 --> 00:08:42,159
means you're going to get your data

252
00:08:42,159 --> 00:08:43,919
output to you in a new way

253
00:08:43,919 --> 00:08:45,680
um so somebody has to make sure to

254
00:08:45,680 --> 00:08:48,000
program that data so that it flows into

255
00:08:48,000 --> 00:08:50,000
a database and is tabulated in a way

256
00:08:50,000 --> 00:08:51,040
that

257
00:08:51,040 --> 00:08:52,839
a machine learning model can

258
00:08:52,839 --> 00:08:55,120
understand or even just for analysts to

259
00:08:55,120 --> 00:08:56,640
understand

260
00:08:56,640 --> 00:08:58,240
and also there can be lots of missing or

261
00:08:58,240 --> 00:09:00,160
changing information as you add new

262
00:09:00,160 --> 00:09:02,880
sensors remove sensors tune them

263
00:09:02,880 --> 00:09:04,320
or just the fact that sensors look at

264
00:09:04,320 --> 00:09:06,399
different things

265
00:09:06,399 --> 00:09:09,040
so this table is a subset of uh

266
00:09:09,040 --> 00:09:11,920
two fields from different alerts

267
00:09:11,920 --> 00:09:14,320
across two different alerts here

268
00:09:14,320 --> 00:09:15,680
uh just to kind of give an example of

269
00:09:15,680 --> 00:09:16,800
these issues

270
00:09:16,800 --> 00:09:18,880
so here in alert number one it's a

271
00:09:18,880 --> 00:09:20,480
sensor that picks up a powershell

272
00:09:20,480 --> 00:09:21,519
command

273
00:09:21,519 --> 00:09:22,959
and if you look at the command line

274
00:09:22,959 --> 00:09:25,519
field there is indeed a powershell line

275
00:09:25,519 --> 00:09:26,880
there is indeed a powershell command

276
00:09:26,880 --> 00:09:28,240
line here

277
00:09:28,240 --> 00:09:30,399
however for the file path feature which

278
00:09:30,399 --> 00:09:33,040
needs to exist because other sensors do

279
00:09:33,040 --> 00:09:35,360
look at file paths there actually is no

280
00:09:35,360 --> 00:09:37,600
information that the sensor picks up so

281
00:09:37,600 --> 00:09:40,160
it's just a piece of missing data

282
00:09:40,160 --> 00:09:41,760
and then an alert number two which is a

283
00:09:41,760 --> 00:09:43,839
sensor for mimikats

284
00:09:43,839 --> 00:09:45,279
it's not able to pick up any command

285
00:09:45,279 --> 00:09:47,519
line information but it is able to find

286
00:09:47,519 --> 00:09:49,560
a file path that points to a

287
00:09:49,560 --> 00:09:52,959
powercats.dll file

288
00:09:52,959 --> 00:09:54,640
so this missing data is going to be an

289
00:09:54,640 --> 00:09:56,240
issue if you want to actually train a

290
00:09:56,240 --> 00:09:57,839
machine learning model for this you're

291
00:09:57,839 --> 00:09:59,120
going to have to eventually deal with it

292
00:09:59,120 --> 00:10:01,120
somehow

293
00:10:01,120 --> 00:10:02,399
but that's not the only issue with

294
00:10:02,399 --> 00:10:04,160
stands for diversity the other problem

295
00:10:04,160 --> 00:10:05,440
is tuning

296
00:10:05,440 --> 00:10:06,399
so

297
00:10:06,399 --> 00:10:08,720
in this graph we have a

298
00:10:08,720 --> 00:10:11,040
set of our most active sensors

299
00:10:11,040 --> 00:10:12,880
and the proportion of alerts that they

300
00:10:12,880 --> 00:10:14,079
generate

301
00:10:14,079 --> 00:10:16,959
so the most active sensor generates 20

302
00:10:16,959 --> 00:10:20,000
of alerts now that's not necessarily

303
00:10:20,000 --> 00:10:21,279
good or bad

304
00:10:21,279 --> 00:10:23,040
it's just the way it is maybe all those

305
00:10:23,040 --> 00:10:25,440
alerts are really good

306
00:10:25,440 --> 00:10:27,120
but that's exactly the problem is that

307
00:10:27,120 --> 00:10:30,079
you don't know until you test it

308
00:10:30,079 --> 00:10:31,519
and what that means is that if you have

309
00:10:31,519 --> 00:10:32,720
customers that have different

310
00:10:32,720 --> 00:10:34,560
requirements or you just want your

311
00:10:34,560 --> 00:10:36,480
sensors to be in line with each other

312
00:10:36,480 --> 00:10:38,399
you have to constantly tune these

313
00:10:38,399 --> 00:10:40,720
sensors based on how things change and

314
00:10:40,720 --> 00:10:42,399
sometimes the cyber threat landscape

315
00:10:42,399 --> 00:10:44,000
changes and the sensor tuning you used

316
00:10:44,000 --> 00:10:46,880
before no longer works

317
00:10:46,880 --> 00:10:49,279
so this is a constant manual effort to

318
00:10:49,279 --> 00:10:50,399
battle with

319
00:10:50,399 --> 00:10:52,640
the threat landscape and your sensors

320
00:10:52,640 --> 00:10:55,680
it's an expensive process

321
00:10:55,680 --> 00:10:57,600
okay so the next issue is false

322
00:10:57,600 --> 00:11:00,000
positives

323
00:11:00,000 --> 00:11:01,760
so the best way to kind of understand

324
00:11:01,760 --> 00:11:03,519
this is through a little story

325
00:11:03,519 --> 00:11:06,399
let's imagine you've got an analyst and

326
00:11:06,399 --> 00:11:09,120
they see this very and this an alert

327
00:11:09,120 --> 00:11:10,800
generates this very first command that

328
00:11:10,800 --> 00:11:13,040
you see at the top here

329
00:11:13,040 --> 00:11:15,360
so the analyst looks at the command they

330
00:11:15,360 --> 00:11:17,519
go to the customer's devices and they

331
00:11:17,519 --> 00:11:20,720
realize oh this isn't actually a problem

332
00:11:20,720 --> 00:11:22,399
so what they do is they decide to

333
00:11:22,399 --> 00:11:24,160
whitelist the command there's no reason

334
00:11:24,160 --> 00:11:25,519
for them to ever look at it again it was

335
00:11:25,519 --> 00:11:28,000
just a waste of their time

336
00:11:28,000 --> 00:11:30,079
then over the next week

337
00:11:30,079 --> 00:11:32,800
you see these next five commands come in

338
00:11:32,800 --> 00:11:35,360
and these five commands are pretty close

339
00:11:35,360 --> 00:11:36,959
to that first command but it's not quite

340
00:11:36,959 --> 00:11:38,880
the same

341
00:11:38,880 --> 00:11:41,600
the analyst looks at the command they go

342
00:11:41,600 --> 00:11:43,440
to the customer devices

343
00:11:43,440 --> 00:11:45,120
realize it was the same issue they had

344
00:11:45,120 --> 00:11:46,320
before

345
00:11:46,320 --> 00:11:48,079
and say okay we actually need to expand

346
00:11:48,079 --> 00:11:49,440
the white list to capture lots of

347
00:11:49,440 --> 00:11:51,279
different near duplicates of this

348
00:11:51,279 --> 00:11:52,959
command

349
00:11:52,959 --> 00:11:54,800
so what they do is they write a regular

350
00:11:54,800 --> 00:11:56,399
expression on the white list and now

351
00:11:56,399 --> 00:11:58,320
that regular expression will catch all

352
00:11:58,320 --> 00:12:01,040
the similar commands right

353
00:12:01,040 --> 00:12:04,880
so weeks and weeks and weeks go by

354
00:12:04,880 --> 00:12:06,959
and everything's great the regex the

355
00:12:06,959 --> 00:12:09,040
regular expression is capturing all of

356
00:12:09,040 --> 00:12:11,839
the commands there are no issues

357
00:12:11,839 --> 00:12:13,440
things are good

358
00:12:13,440 --> 00:12:16,560
now weeks have gone by and the analyst

359
00:12:16,560 --> 00:12:18,000
has kind of forgotten that they even

360
00:12:18,000 --> 00:12:19,920
wrote this regular expression

361
00:12:19,920 --> 00:12:21,600
and they're not maybe they even forgot

362
00:12:21,600 --> 00:12:23,680
how they resolved the case in the first

363
00:12:23,680 --> 00:12:25,279
place

364
00:12:25,279 --> 00:12:27,200
and then finally this command down here

365
00:12:27,200 --> 00:12:28,320
comes in

366
00:12:28,320 --> 00:12:30,160
and it's just a little bit different

367
00:12:30,160 --> 00:12:33,040
than all the other ones that were around

368
00:12:33,040 --> 00:12:35,760
so the analyst looks at the command

369
00:12:35,760 --> 00:12:38,320
goes to the customer's devices and while

370
00:12:38,320 --> 00:12:39,519
they're resolving the incident they

371
00:12:39,519 --> 00:12:41,440
realize wait a second i've done this

372
00:12:41,440 --> 00:12:43,519
before in fact i even wrote a regular

373
00:12:43,519 --> 00:12:45,200
expression for this

374
00:12:45,200 --> 00:12:46,639
and then they realized that it wasn't

375
00:12:46,639 --> 00:12:48,160
enough to cover this near duplicate

376
00:12:48,160 --> 00:12:49,440
either

377
00:12:49,440 --> 00:12:51,040
so once again they have to rewrite the

378
00:12:51,040 --> 00:12:52,560
regular expression

379
00:12:52,560 --> 00:12:55,120
just to fix the white list

380
00:12:55,120 --> 00:12:58,639
now i uh flew in here from washington dc

381
00:12:58,639 --> 00:13:01,040
and if i had a dollar for every time i

382
00:13:01,040 --> 00:13:02,480
missed the backslash in a regular

383
00:13:02,480 --> 00:13:04,160
expression then i probably would have

384
00:13:04,160 --> 00:13:06,480
just kept flying to hawaii

385
00:13:06,480 --> 00:13:08,320
and that's to say that this is not a

386
00:13:08,320 --> 00:13:10,720
very fun task and it's extremely tedious

387
00:13:10,720 --> 00:13:12,959
to constantly have to update

388
00:13:12,959 --> 00:13:14,639
these kind of white lists

389
00:13:14,639 --> 00:13:16,320
and the reality is that it's not even

390
00:13:16,320 --> 00:13:18,320
feasible there's going to be tens of

391
00:13:18,320 --> 00:13:20,000
thousands hundreds of thousands of

392
00:13:20,000 --> 00:13:21,279
circumstances where you get near

393
00:13:21,279 --> 00:13:22,959
duplicates like this

394
00:13:22,959 --> 00:13:25,760
and maintaining this forever is going to

395
00:13:25,760 --> 00:13:29,360
become more and more costly

396
00:13:29,360 --> 00:13:30,639
and just to really hammer that point

397
00:13:30,639 --> 00:13:33,680
home here's a graph of our 20 most

398
00:13:33,680 --> 00:13:35,920
active sensors and how precise they are

399
00:13:35,920 --> 00:13:37,519
how often they actually generate true

400
00:13:37,519 --> 00:13:38,959
positive alerts

401
00:13:38,959 --> 00:13:41,120
as you can see the numbers are not 1.0

402
00:13:41,120 --> 00:13:44,399
which means that it's not good enough

403
00:13:44,399 --> 00:13:48,639
okay the next issue is evolving threats

404
00:13:48,639 --> 00:13:49,839
so

405
00:13:49,839 --> 00:13:52,399
this kind of command line at the top

406
00:13:52,399 --> 00:13:54,000
is kind of a good example of an evolving

407
00:13:54,000 --> 00:13:54,880
thread

408
00:13:54,880 --> 00:13:57,839
so what this is is a wall bin which is a

409
00:13:57,839 --> 00:14:00,240
living off the land binary

410
00:14:00,240 --> 00:14:02,720
which is a type of attack where

411
00:14:02,720 --> 00:14:05,760
the attacker uses a binary that's

412
00:14:05,760 --> 00:14:08,399
already on the system

413
00:14:08,399 --> 00:14:10,480
in order to do something malicious

414
00:14:10,480 --> 00:14:12,480
now i know that logans are not brand new

415
00:14:12,480 --> 00:14:13,760
they've been around for a little while

416
00:14:13,760 --> 00:14:14,720
now

417
00:14:14,720 --> 00:14:17,120
but at some point they were new

418
00:14:17,120 --> 00:14:19,120
and this caused an issue because a lot

419
00:14:19,120 --> 00:14:20,560
of the binaries you thought you could

420
00:14:20,560 --> 00:14:21,760
trust because they came with the

421
00:14:21,760 --> 00:14:23,760
operating system are now being used to

422
00:14:23,760 --> 00:14:25,760
perpetrate attacks

423
00:14:25,760 --> 00:14:27,279
and that can cause a significant shift

424
00:14:27,279 --> 00:14:29,760
in the landscape

425
00:14:29,760 --> 00:14:32,560
and down here is a graph of alerts for a

426
00:14:32,560 --> 00:14:33,920
customer

427
00:14:33,920 --> 00:14:35,839
over a variety of months

428
00:14:35,839 --> 00:14:37,199
so you can see that in november and

429
00:14:37,199 --> 00:14:39,040
december there's kind of like this

430
00:14:39,040 --> 00:14:41,120
baseline level of alerts which is very

431
00:14:41,120 --> 00:14:42,560
small

432
00:14:42,560 --> 00:14:44,560
and then in january february and march

433
00:14:44,560 --> 00:14:46,880
we see a giant spike in what we think is

434
00:14:46,880 --> 00:14:49,360
malicious behavior tons of sensors are

435
00:14:49,360 --> 00:14:50,800
firing there's new threats on this

436
00:14:50,800 --> 00:14:52,160
customer

437
00:14:52,160 --> 00:14:54,639
and then it dies down in april may we go

438
00:14:54,639 --> 00:14:56,560
back down to our base level

439
00:14:56,560 --> 00:14:58,240
these kind of things can happen

440
00:14:58,240 --> 00:14:59,519
unexpectedly

441
00:14:59,519 --> 00:15:00,959
and the landscape is always changing and

442
00:15:00,959 --> 00:15:01,839
that's something that needs to be

443
00:15:01,839 --> 00:15:03,360
accounted for

444
00:15:03,360 --> 00:15:05,920
in a sock

445
00:15:06,399 --> 00:15:08,480
okay the final issue is human

446
00:15:08,480 --> 00:15:10,839
integration

447
00:15:10,839 --> 00:15:14,560
so the reality is that people get used

448
00:15:14,560 --> 00:15:16,880
to working a certain way

449
00:15:16,880 --> 00:15:19,519
and for better or worse um they get good

450
00:15:19,519 --> 00:15:21,600
at it they get used to their workflows

451
00:15:21,600 --> 00:15:22,800
and they stick to them and they don't

452
00:15:22,800 --> 00:15:24,399
like to change

453
00:15:24,399 --> 00:15:27,360
uh you know i like to say that if

454
00:15:27,360 --> 00:15:29,120
the entire world only had computer

455
00:15:29,120 --> 00:15:30,560
scientists left

456
00:15:30,560 --> 00:15:32,000
then half of the world would be vim

457
00:15:32,000 --> 00:15:32,880
users

458
00:15:32,880 --> 00:15:35,120
the other half would be emax users

459
00:15:35,120 --> 00:15:36,639
and then the nano users would live on

460
00:15:36,639 --> 00:15:38,839
the north pole

461
00:15:38,839 --> 00:15:41,600
um but what i'm trying to say is that

462
00:15:41,600 --> 00:15:43,759
people don't like to change

463
00:15:43,759 --> 00:15:44,800
and

464
00:15:44,800 --> 00:15:46,560
when you try and enforce a change even

465
00:15:46,560 --> 00:15:48,720
it's even if it's likely to improve

466
00:15:48,720 --> 00:15:50,160
their efficiency

467
00:15:50,160 --> 00:15:52,639
it's not easy to integrate

468
00:15:52,639 --> 00:15:54,480
there's a lot of research on like active

469
00:15:54,480 --> 00:15:56,399
learning machine learning systems where

470
00:15:56,399 --> 00:15:58,320
there's this constant feedback between

471
00:15:58,320 --> 00:16:00,639
humans the machine learning models

472
00:16:00,639 --> 00:16:02,399
numbers statistics and their original

473
00:16:02,399 --> 00:16:03,920
workflows

474
00:16:03,920 --> 00:16:06,000
and the research shows it's great

475
00:16:06,000 --> 00:16:07,680
but if nobody adopts it then the

476
00:16:07,680 --> 00:16:09,120
benefits that you get out of it are

477
00:16:09,120 --> 00:16:12,000
exactly zero

478
00:16:12,240 --> 00:16:13,920
um so that's an issue that needs to be

479
00:16:13,920 --> 00:16:15,360
solved when you want to try and improve

480
00:16:15,360 --> 00:16:18,320
someone's workflow

481
00:16:18,880 --> 00:16:20,880
okay so those are the four main problems

482
00:16:20,880 --> 00:16:22,639
that we're facing and now let's talk

483
00:16:22,639 --> 00:16:25,279
about the system that escalated quickly

484
00:16:25,279 --> 00:16:27,120
and how we actually address all of those

485
00:16:27,120 --> 00:16:29,519
problems

486
00:16:29,759 --> 00:16:31,839
so here's an overview of the system and

487
00:16:31,839 --> 00:16:34,000
i know there's a lot going on here we're

488
00:16:34,000 --> 00:16:36,959
gonna break it down piece by piece

489
00:16:36,959 --> 00:16:38,240
but let me just start with kind of a

490
00:16:38,240 --> 00:16:39,920
high level overview

491
00:16:39,920 --> 00:16:41,360
you get alerts

492
00:16:41,360 --> 00:16:43,040
they go through a feature extraction

493
00:16:43,040 --> 00:16:44,160
process

494
00:16:44,160 --> 00:16:47,120
they go to machine learning for training

495
00:16:47,120 --> 00:16:49,759
they go to a triage system which

496
00:16:49,759 --> 00:16:50,880
presents

497
00:16:50,880 --> 00:16:53,360
that machine learning knowledge to

498
00:16:53,360 --> 00:16:55,360
analysts in a super lightweight and

499
00:16:55,360 --> 00:16:57,440
effective way that doesn't affect their

500
00:16:57,440 --> 00:16:58,880
workflows

501
00:16:58,880 --> 00:17:00,240
and then the analysts can use their

502
00:17:00,240 --> 00:17:03,759
actual workflows to resolve those cases

503
00:17:03,759 --> 00:17:05,919
and we use a very simple feedback loop

504
00:17:05,919 --> 00:17:07,679
to bring that new knowledge back to the

505
00:17:07,679 --> 00:17:08,959
alerts

506
00:17:08,959 --> 00:17:10,480
and then the process repeats again and

507
00:17:10,480 --> 00:17:12,079
again constantly improving the machine

508
00:17:12,079 --> 00:17:14,480
learning models

509
00:17:14,480 --> 00:17:16,480
okay so let's start breaking down what

510
00:17:16,480 --> 00:17:18,640
the system actually does and we'll start

511
00:17:18,640 --> 00:17:20,160
with this feature extraction module

512
00:17:20,160 --> 00:17:22,240
right here

513
00:17:22,240 --> 00:17:24,000
so the feature extraction module is

514
00:17:24,000 --> 00:17:25,520
designed to deal with the sensor

515
00:17:25,520 --> 00:17:27,520
diversity issue

516
00:17:27,520 --> 00:17:30,320
and it has two main components

517
00:17:30,320 --> 00:17:32,960
the first is the automatic featurization

518
00:17:32,960 --> 00:17:35,600
framework and what this does is it tries

519
00:17:35,600 --> 00:17:37,520
to turn

520
00:17:37,520 --> 00:17:39,600
the contents of the alerts that we saw a

521
00:17:39,600 --> 00:17:41,280
couple slides ago with those example

522
00:17:41,280 --> 00:17:42,400
alerts

523
00:17:42,400 --> 00:17:44,640
um into features for machine learning

524
00:17:44,640 --> 00:17:47,360
models

525
00:17:47,360 --> 00:17:48,720
and the way that it does this is through

526
00:17:48,720 --> 00:17:51,039
an automatic futurization framework that

527
00:17:51,039 --> 00:17:53,280
takes semi-structured data and

528
00:17:53,280 --> 00:17:56,080
automatically attempts to understand it

529
00:17:56,080 --> 00:17:58,080
so what i mentioned that was earlier was

530
00:17:58,080 --> 00:17:59,760
that one of the main challenges with

531
00:17:59,760 --> 00:18:01,919
having too many sensors is that you need

532
00:18:01,919 --> 00:18:03,360
to integrate them into some sort of

533
00:18:03,360 --> 00:18:04,880
database

534
00:18:04,880 --> 00:18:06,320
in order to avoid that challenge

535
00:18:06,320 --> 00:18:08,400
completely we just take sensors and

536
00:18:08,400 --> 00:18:10,240
whatever data they can possibly output

537
00:18:10,240 --> 00:18:12,720
and dump them into a json

538
00:18:12,720 --> 00:18:14,559
which may seem a little

539
00:18:14,559 --> 00:18:17,039
chaotic from a database perspective

540
00:18:17,039 --> 00:18:18,559
but it ends up really working well for

541
00:18:18,559 --> 00:18:19,840
this machine learning automatic

542
00:18:19,840 --> 00:18:21,200
featurization

543
00:18:21,200 --> 00:18:22,880
because what it does

544
00:18:22,880 --> 00:18:24,880
is it goes through these jsons just auto

545
00:18:24,880 --> 00:18:27,200
parses them and auto flattens them

546
00:18:27,200 --> 00:18:29,520
and just tries to deal with whatever it

547
00:18:29,520 --> 00:18:30,960
can find

548
00:18:30,960 --> 00:18:33,280
and it creates statistical distributions

549
00:18:33,280 --> 00:18:35,919
over what does exist so even if you have

550
00:18:35,919 --> 00:18:38,240
some missing data like these nulls here

551
00:18:38,240 --> 00:18:40,799
or if the keys from these json are

552
00:18:40,799 --> 00:18:43,600
missing entirely it doesn't matter

553
00:18:43,600 --> 00:18:44,960
it just creates statistical

554
00:18:44,960 --> 00:18:46,320
distributions over everything that's

555
00:18:46,320 --> 00:18:48,559
there

556
00:18:48,720 --> 00:18:50,480
and it uses those distributions to

557
00:18:50,480 --> 00:18:51,600
determine

558
00:18:51,600 --> 00:18:53,360
if those features will be good for

559
00:18:53,360 --> 00:18:55,120
machine learning

560
00:18:55,120 --> 00:18:57,760
it also deals with changing data types

561
00:18:57,760 --> 00:18:59,840
it deals with missing data and even

562
00:18:59,840 --> 00:19:02,480
things like long tail distributions

563
00:19:02,480 --> 00:19:04,240
so i won't go into all of the details of

564
00:19:04,240 --> 00:19:05,760
the algorithm here but we have a paper

565
00:19:05,760 --> 00:19:07,039
and submission that

566
00:19:07,039 --> 00:19:09,360
explains it all

567
00:19:09,360 --> 00:19:11,200
um the next component of this is the

568
00:19:11,200 --> 00:19:14,000
temporal feature computation

569
00:19:14,000 --> 00:19:15,760
and the best way to understand this is

570
00:19:15,760 --> 00:19:17,200
with an example

571
00:19:17,200 --> 00:19:19,039
so let's imagine you have two different

572
00:19:19,039 --> 00:19:20,640
customers

573
00:19:20,640 --> 00:19:22,640
uh and the first and these two customers

574
00:19:22,640 --> 00:19:25,280
get an alert that's basically the same

575
00:19:25,280 --> 00:19:26,559
it's basically the same alert for these

576
00:19:26,559 --> 00:19:28,480
two customers

577
00:19:28,480 --> 00:19:30,880
however customer number one has seen an

578
00:19:30,880 --> 00:19:32,640
alert that looks like this

579
00:19:32,640 --> 00:19:34,960
one thousand times

580
00:19:34,960 --> 00:19:37,760
and customer number two has never seen

581
00:19:37,760 --> 00:19:39,120
an alert that looks like this on their

582
00:19:39,120 --> 00:19:40,720
system

583
00:19:40,720 --> 00:19:42,799
so knowing that context about the

584
00:19:42,799 --> 00:19:44,000
customer

585
00:19:44,000 --> 00:19:46,240
changes the way you understand that new

586
00:19:46,240 --> 00:19:47,600
alert

587
00:19:47,600 --> 00:19:49,280
uh that alert for the customer that's

588
00:19:49,280 --> 00:19:51,280
seen a thousand times probably not an

589
00:19:51,280 --> 00:19:52,880
issue

590
00:19:52,880 --> 00:19:54,960
the customer that's never seen it before

591
00:19:54,960 --> 00:19:56,559
there may be a new attack vector that's

592
00:19:56,559 --> 00:19:58,080
being perpetrated on this customer and

593
00:19:58,080 --> 00:20:00,880
you may want to treat it seriously

594
00:20:00,880 --> 00:20:02,480
that's the main idea is to generate

595
00:20:02,480 --> 00:20:04,240
context and we use a lot of different

596
00:20:04,240 --> 00:20:06,240
predicates like customers machines

597
00:20:06,240 --> 00:20:07,679
sensor types

598
00:20:07,679 --> 00:20:09,520
etc again i won't go through all the

599
00:20:09,520 --> 00:20:13,039
details here but that's the idea

600
00:20:13,520 --> 00:20:15,360
okay so the next component of the text

601
00:20:15,360 --> 00:20:18,640
system is the machine learning module

602
00:20:18,640 --> 00:20:20,240
so we have two different models that

603
00:20:20,240 --> 00:20:21,200
deal with the two types of

604
00:20:21,200 --> 00:20:24,080
featurizations that we have

605
00:20:24,080 --> 00:20:25,840
the automatic featurization framework

606
00:20:25,840 --> 00:20:28,400
that grabs the contents of alerts

607
00:20:28,400 --> 00:20:29,520
goes straight to what we call the

608
00:20:29,520 --> 00:20:30,880
content model

609
00:20:30,880 --> 00:20:32,559
and that contextual data goes to the

610
00:20:32,559 --> 00:20:34,960
context model i know excellent naming

611
00:20:34,960 --> 00:20:36,559
here

612
00:20:36,559 --> 00:20:38,640
what we do is then take an ensemble

613
00:20:38,640 --> 00:20:40,480
which combines the scores from those two

614
00:20:40,480 --> 00:20:43,440
models to generate one final alert level

615
00:20:43,440 --> 00:20:44,640
score

616
00:20:44,640 --> 00:20:46,960
and this is that idea of re-evaluating

617
00:20:46,960 --> 00:20:50,240
the severity of the alerts

618
00:20:50,240 --> 00:20:52,320
and this helps deal with both false

619
00:20:52,320 --> 00:20:55,280
positives and with evolving threats

620
00:20:55,280 --> 00:20:56,799
one of the issues was with the false

621
00:20:56,799 --> 00:20:58,559
positives was all those near duplicate

622
00:20:58,559 --> 00:21:00,000
cases

623
00:21:00,000 --> 00:21:00,880
and

624
00:21:00,880 --> 00:21:02,720
machine learning is one of the perfect

625
00:21:02,720 --> 00:21:04,480
use cases for that

626
00:21:04,480 --> 00:21:06,480
because it doesn't require manual

627
00:21:06,480 --> 00:21:08,559
intervention to write rules that find

628
00:21:08,559 --> 00:21:10,159
near duplicates

629
00:21:10,159 --> 00:21:12,080
just using statistics and a large amount

630
00:21:12,080 --> 00:21:14,320
of data it will automatically generate

631
00:21:14,320 --> 00:21:16,240
that knowledge that will detect near

632
00:21:16,240 --> 00:21:18,880
duplicates

633
00:21:19,200 --> 00:21:21,360
and for the evolving threats

634
00:21:21,360 --> 00:21:23,039
this machine learning helps in multiple

635
00:21:23,039 --> 00:21:24,159
ways

636
00:21:24,159 --> 00:21:26,240
the first is machine learning models

637
00:21:26,240 --> 00:21:27,840
generalize at least a little bit for the

638
00:21:27,840 --> 00:21:29,360
most part

639
00:21:29,360 --> 00:21:30,880
and that means that certain threats will

640
00:21:30,880 --> 00:21:32,559
already be detected just by nature of

641
00:21:32,559 --> 00:21:34,320
that generalization

642
00:21:34,320 --> 00:21:36,240
but even if the models can't detect

643
00:21:36,240 --> 00:21:37,840
every single zero-day threat which they

644
00:21:37,840 --> 00:21:39,620
obviously won't

645
00:21:39,620 --> 00:21:41,440
[Music]

646
00:21:41,440 --> 00:21:44,720
we can get new data and train on it

647
00:21:44,720 --> 00:21:46,480
without any other human intervention

648
00:21:46,480 --> 00:21:49,280
just by re-running the pipeline and the

649
00:21:49,280 --> 00:21:50,880
machine learning modules will adapt to

650
00:21:50,880 --> 00:21:53,840
that new information as it comes

651
00:21:53,840 --> 00:21:55,440
so we take a lot of the manual effort

652
00:21:55,440 --> 00:21:57,280
out of evaluating these new evolving

653
00:21:57,280 --> 00:21:59,760
threats

654
00:21:59,760 --> 00:22:03,039
okay the next piece is the triage module

655
00:22:03,039 --> 00:22:04,640
and this is what attempts to present

656
00:22:04,640 --> 00:22:06,960
scores to human analysts in a really

657
00:22:06,960 --> 00:22:08,880
lightweight fashion

658
00:22:08,880 --> 00:22:10,559
so it takes the alert level scores from

659
00:22:10,559 --> 00:22:12,960
that model and computes incident level

660
00:22:12,960 --> 00:22:14,000
scores

661
00:22:14,000 --> 00:22:15,760
and then presents both of those in three

662
00:22:15,760 --> 00:22:17,520
main ways

663
00:22:17,520 --> 00:22:20,320
the first is suppression which just

664
00:22:20,320 --> 00:22:22,400
can which which can just block out cases

665
00:22:22,400 --> 00:22:26,000
that we don't want the analyst to see um

666
00:22:26,000 --> 00:22:27,360
the next system is incident

667
00:22:27,360 --> 00:22:28,960
prioritization

668
00:22:28,960 --> 00:22:31,360
which ranks all of the incidents that

669
00:22:31,360 --> 00:22:33,520
analysts need to look at and tells them

670
00:22:33,520 --> 00:22:36,400
which ones to look at first

671
00:22:36,400 --> 00:22:39,120
and then we also have within incident

672
00:22:39,120 --> 00:22:41,520
alert prioritization so even if you

673
00:22:41,520 --> 00:22:44,320
can't de-prioritize an incident you can

674
00:22:44,320 --> 00:22:46,880
look within it and point an analyst at

675
00:22:46,880 --> 00:22:48,559
certain pieces of information that they

676
00:22:48,559 --> 00:22:52,400
should look at to make their jobs faster

677
00:22:52,400 --> 00:22:53,840
because the system is so lightweight

678
00:22:53,840 --> 00:22:55,440
which you'll see later it deals with

679
00:22:55,440 --> 00:22:58,320
this human integration issue

680
00:22:58,320 --> 00:23:01,200
um and finally we have the feedback loop

681
00:23:01,200 --> 00:23:03,600
so we do ask the analysts to do one

682
00:23:03,600 --> 00:23:05,280
extra thing in addition to their

683
00:23:05,280 --> 00:23:07,600
day-to-day workflow and that is to

684
00:23:07,600 --> 00:23:10,000
basically just check a little box that

685
00:23:10,000 --> 00:23:12,880
says if the incident was worth their

686
00:23:12,880 --> 00:23:14,960
time

687
00:23:14,960 --> 00:23:18,480
and we call this the actionable label

688
00:23:18,480 --> 00:23:20,480
so the analysts as part of their normal

689
00:23:20,480 --> 00:23:22,080
jobs just need to mark whether the

690
00:23:22,080 --> 00:23:24,080
incident is worth their time

691
00:23:24,080 --> 00:23:27,200
and what we do is we propagate that

692
00:23:27,200 --> 00:23:28,240
label

693
00:23:28,240 --> 00:23:30,400
back to all of the alerts that make up

694
00:23:30,400 --> 00:23:31,840
the incident

695
00:23:31,840 --> 00:23:34,559
so all of these alerts now also get an

696
00:23:34,559 --> 00:23:37,120
actionable label and because the alerts

697
00:23:37,120 --> 00:23:39,520
have an actionable label

698
00:23:39,520 --> 00:23:41,279
we can now feed this new information

699
00:23:41,279 --> 00:23:43,360
back into the system and retrain the

700
00:23:43,360 --> 00:23:45,440
models to make them better

701
00:23:45,440 --> 00:23:46,880
and the system goes around and around

702
00:23:46,880 --> 00:23:48,320
and hopefully this diagram now makes a

703
00:23:48,320 --> 00:23:51,720
little more sense

704
00:23:51,760 --> 00:23:54,640
okay so that's the entire system now

705
00:23:54,640 --> 00:23:56,400
let's talk about how we actually get it

706
00:23:56,400 --> 00:23:58,400
running

707
00:23:58,400 --> 00:24:00,080
but before we do that i do just want to

708
00:24:00,080 --> 00:24:02,400
talk about this actionable label in a

709
00:24:02,400 --> 00:24:04,480
little more detail

710
00:24:04,480 --> 00:24:06,960
because it actually is extremely crucial

711
00:24:06,960 --> 00:24:10,240
to the functionality of the system

712
00:24:10,240 --> 00:24:12,000
again this actionable label is

713
00:24:12,000 --> 00:24:14,159
attempting to answer the question

714
00:24:14,159 --> 00:24:17,520
is an incident worth an analyst time

715
00:24:17,520 --> 00:24:21,279
and there's three main scenarios where

716
00:24:21,279 --> 00:24:24,000
we see if that's the case

717
00:24:24,000 --> 00:24:25,919
so the first one is incidents that

718
00:24:25,919 --> 00:24:28,880
require any kind of manual remediation

719
00:24:28,880 --> 00:24:31,279
if an analyst actually has to go through

720
00:24:31,279 --> 00:24:33,840
and manually fix something

721
00:24:33,840 --> 00:24:35,919
then we consider that an actionable

722
00:24:35,919 --> 00:24:37,039
incident

723
00:24:37,039 --> 00:24:39,039
and here's an example on the right

724
00:24:39,039 --> 00:24:40,960
from a real incident where the sock team

725
00:24:40,960 --> 00:24:43,279
investigated a detection on the host

726
00:24:43,279 --> 00:24:45,840
for proxy shell exploitation and lemon

727
00:24:45,840 --> 00:24:47,279
duck malware

728
00:24:47,279 --> 00:24:48,960
and they escalated to the client do the

729
00:24:48,960 --> 00:24:51,200
due to the persistence of the lemon duck

730
00:24:51,200 --> 00:24:52,720
malware

731
00:24:52,720 --> 00:24:54,080
and they got that incident resolved

732
00:24:54,080 --> 00:24:55,679
manually

733
00:24:55,679 --> 00:24:57,919
the next obvious case is incidents that

734
00:24:57,919 --> 00:25:00,799
are triggered by false alarms so there's

735
00:25:00,799 --> 00:25:02,880
not actually any malicious behavior

736
00:25:02,880 --> 00:25:04,960
happening at all

737
00:25:04,960 --> 00:25:07,039
that's going to be non-actionable it's

738
00:25:07,039 --> 00:25:09,279
just a waste of the analyst time here's

739
00:25:09,279 --> 00:25:11,039
an example where the sock team received

740
00:25:11,039 --> 00:25:13,679
a no vbs extension alert for the hosts

741
00:25:13,679 --> 00:25:15,520
and upon investigation it was just

742
00:25:15,520 --> 00:25:17,919
related to a pdf driver no action is

743
00:25:17,919 --> 00:25:19,120
required

744
00:25:19,120 --> 00:25:21,039
so this was just a waste of their time

745
00:25:21,039 --> 00:25:22,720
and cases like this happen very

746
00:25:22,720 --> 00:25:24,960
frequently

747
00:25:24,960 --> 00:25:26,880
now finally here's a kind of

748
00:25:26,880 --> 00:25:29,520
circumstance that you may not expect

749
00:25:29,520 --> 00:25:31,440
but we find is actually also important

750
00:25:31,440 --> 00:25:33,679
to the system

751
00:25:33,679 --> 00:25:35,520
these are incidents that are triggered

752
00:25:35,520 --> 00:25:38,240
by true positive alerts

753
00:25:38,240 --> 00:25:40,480
but they were successfully contained by

754
00:25:40,480 --> 00:25:43,200
an automated defense infrastructure

755
00:25:43,200 --> 00:25:45,039
so i know this might sound insane but

756
00:25:45,039 --> 00:25:46,880
human analysts don't have to resolve

757
00:25:46,880 --> 00:25:49,279
every single case manually

758
00:25:49,279 --> 00:25:51,200
we do have systems that automatically

759
00:25:51,200 --> 00:25:53,200
provide protection

760
00:25:53,200 --> 00:25:56,240
and here's an example on the right here

761
00:25:56,240 --> 00:25:57,840
the file for which the detection

762
00:25:57,840 --> 00:25:59,360
triggered has been cleaned by the

763
00:25:59,360 --> 00:26:02,080
antivirus solution and the file was not

764
00:26:02,080 --> 00:26:03,840
executed on the host

765
00:26:03,840 --> 00:26:06,799
so now no further actions are required

766
00:26:06,799 --> 00:26:09,039
clearly there was a malicious there was

767
00:26:09,039 --> 00:26:11,360
malicious activity but the analysts

768
00:26:11,360 --> 00:26:13,440
didn't have to do anything there's a

769
00:26:13,440 --> 00:26:15,120
reason we have automated defense

770
00:26:15,120 --> 00:26:16,480
infrastructure

771
00:26:16,480 --> 00:26:18,400
and that's to save analyst time it

772
00:26:18,400 --> 00:26:19,600
doesn't make sense if they have to

773
00:26:19,600 --> 00:26:21,200
constantly look at it over and over and

774
00:26:21,200 --> 00:26:22,720
over again

775
00:26:22,720 --> 00:26:24,880
so these kind of incidents are also not

776
00:26:24,880 --> 00:26:27,360
actionable

777
00:26:27,360 --> 00:26:29,520
okay and just as a reminder

778
00:26:29,520 --> 00:26:32,080
we take these incident level labels and

779
00:26:32,080 --> 00:26:34,799
propagate them to every single alert

780
00:26:34,799 --> 00:26:37,840
that makes up the incident

781
00:26:37,840 --> 00:26:39,279
that's going to matter for the results

782
00:26:39,279 --> 00:26:40,240
here

783
00:26:40,240 --> 00:26:41,919
but before that let's talk about the

784
00:26:41,919 --> 00:26:43,360
data

785
00:26:43,360 --> 00:26:45,440
um the data that we use to train our

786
00:26:45,440 --> 00:26:47,200
model in this prototype

787
00:26:47,200 --> 00:26:49,440
uh is a six month data set

788
00:26:49,440 --> 00:26:50,840
where we have over

789
00:26:50,840 --> 00:26:53,279
3170 customers

790
00:26:53,279 --> 00:26:59,600
over 14 600 endpoints and 2 400 sensors

791
00:26:59,760 --> 00:27:02,080
and it's really important to note here

792
00:27:02,080 --> 00:27:06,240
that we use a time split on our data so

793
00:27:06,240 --> 00:27:08,880
we use the first five months of data as

794
00:27:08,880 --> 00:27:11,200
training and then we use the last month

795
00:27:11,200 --> 00:27:12,240
of data

796
00:27:12,240 --> 00:27:14,880
as a held out test set

797
00:27:14,880 --> 00:27:16,960
it's really really important in these

798
00:27:16,960 --> 00:27:18,159
cyber

799
00:27:18,159 --> 00:27:20,799
situations to split out your your test

800
00:27:20,799 --> 00:27:22,399
set by time

801
00:27:22,399 --> 00:27:25,039
because you need to be able to measure

802
00:27:25,039 --> 00:27:27,840
um if there's new threats and the fact

803
00:27:27,840 --> 00:27:30,480
that you can only ever train a model

804
00:27:30,480 --> 00:27:32,559
onto the data you've seen before so if

805
00:27:32,559 --> 00:27:34,880
we wanted to deploy a model right now we

806
00:27:34,880 --> 00:27:37,279
can't train on data in the future so the

807
00:27:37,279 --> 00:27:38,880
con so the things in machine learning

808
00:27:38,880 --> 00:27:40,480
where you like shuffle your entire data

809
00:27:40,480 --> 00:27:42,399
set to create and train and test doesn't

810
00:27:42,399 --> 00:27:44,799
work here

811
00:27:44,799 --> 00:27:46,720
okay so what we end up getting is a

812
00:27:46,720 --> 00:27:48,799
label distribution that looks like this

813
00:27:48,799 --> 00:27:51,679
for alerts we have 250 000 alerts and

814
00:27:51,679 --> 00:27:53,360
for instance we have

815
00:27:53,360 --> 00:27:56,000
approximately 29 000 incidents

816
00:27:56,000 --> 00:27:58,000
the blue bars here are the amount of

817
00:27:58,000 --> 00:28:00,640
non-actionable items and the yellow bars

818
00:28:00,640 --> 00:28:02,559
are the amount of actionable items for

819
00:28:02,559 --> 00:28:05,279
the training and the test sets

820
00:28:05,279 --> 00:28:06,880
uh just the main thing to note here is

821
00:28:06,880 --> 00:28:08,640
that generally there are fewer

822
00:28:08,640 --> 00:28:10,159
actionable items than there are

823
00:28:10,159 --> 00:28:13,279
non-actionable items

824
00:28:13,440 --> 00:28:15,600
okay so now let's talk about what kind

825
00:28:15,600 --> 00:28:17,360
of machine learning strategies we have

826
00:28:17,360 --> 00:28:20,480
to actually utilize this data

827
00:28:20,480 --> 00:28:21,760
um

828
00:28:21,760 --> 00:28:24,399
for the machine learning module we use

829
00:28:24,399 --> 00:28:26,080
three main algorithms for both the

830
00:28:26,080 --> 00:28:28,720
content and the context models

831
00:28:28,720 --> 00:28:30,159
and these classifiers are logistic

832
00:28:30,159 --> 00:28:34,240
regression random forest and xg boosts

833
00:28:34,240 --> 00:28:36,799
and then for the ensemble model

834
00:28:36,799 --> 00:28:38,399
which combines the knowledge from these

835
00:28:38,399 --> 00:28:41,120
two models we use for we test out four

836
00:28:41,120 --> 00:28:42,960
different strategies

837
00:28:42,960 --> 00:28:45,120
the first one is called unified which is

838
00:28:45,120 --> 00:28:46,960
a term that we made up

839
00:28:46,960 --> 00:28:49,440
which is just a model that uses features

840
00:28:49,440 --> 00:28:52,000
from both of these models as additional

841
00:28:52,000 --> 00:28:53,279
input

842
00:28:53,279 --> 00:28:55,279
and these other three are just simple

843
00:28:55,279 --> 00:28:57,039
aggregations

844
00:28:57,039 --> 00:28:59,279
maximum medium and weighted sum so for

845
00:28:59,279 --> 00:29:00,880
example if the model if the content

846
00:29:00,880 --> 00:29:02,799
model outputs one score the context

847
00:29:02,799 --> 00:29:04,960
model outputs another the ensemble could

848
00:29:04,960 --> 00:29:07,039
just take the maximum of the two scores

849
00:29:07,039 --> 00:29:10,080
just a simple strategy

850
00:29:10,159 --> 00:29:12,000
and this ensemble model again outputs

851
00:29:12,000 --> 00:29:14,240
just the over level score

852
00:29:14,240 --> 00:29:17,200
but what we want is a score also for the

853
00:29:17,200 --> 00:29:19,360
entire incident remember that an

854
00:29:19,360 --> 00:29:21,600
incident is just a group of alerts so if

855
00:29:21,600 --> 00:29:23,279
you have 10 alerts within the incident

856
00:29:23,279 --> 00:29:25,760
you now have 10 scores

857
00:29:25,760 --> 00:29:27,200
and what we use here again is just

858
00:29:27,200 --> 00:29:29,279
simple aggregation maximum mean and

859
00:29:29,279 --> 00:29:30,640
median

860
00:29:30,640 --> 00:29:32,480
we just take the max for example of

861
00:29:32,480 --> 00:29:34,399
these 10 scores and that will become the

862
00:29:34,399 --> 00:29:37,200
score for the entire incident

863
00:29:37,200 --> 00:29:39,840
and finally for evaluation we use rock

864
00:29:39,840 --> 00:29:42,960
aucs precision recall auc's

865
00:29:42,960 --> 00:29:44,880
and then we develop a deployment

866
00:29:44,880 --> 00:29:46,399
situation

867
00:29:46,399 --> 00:29:47,200
where

868
00:29:47,200 --> 00:29:50,720
we're able to see the difference in what

869
00:29:50,720 --> 00:29:52,480
an analyst day-to-day work life would

870
00:29:52,480 --> 00:29:54,799
look like if the model were there the

871
00:29:54,799 --> 00:29:56,960
whole time

872
00:29:56,960 --> 00:29:58,799
and that's evaluated using these three

873
00:29:58,799 --> 00:30:02,000
triage capabilities

874
00:30:02,000 --> 00:30:03,360
okay so now let's get to the fun part

875
00:30:03,360 --> 00:30:06,159
and actually talk about these results

876
00:30:06,159 --> 00:30:08,640
so first i'll present the kind of

877
00:30:08,640 --> 00:30:10,480
machine learning numbers here but i'm

878
00:30:10,480 --> 00:30:11,760
just going to go over it at a really

879
00:30:11,760 --> 00:30:13,360
high level because it's hard to

880
00:30:13,360 --> 00:30:15,600
contextualize these numbers we mostly

881
00:30:15,600 --> 00:30:17,120
just use it for tuning the models and

882
00:30:17,120 --> 00:30:19,840
making sure that we output the best ones

883
00:30:19,840 --> 00:30:22,559
but basically at the alert level we find

884
00:30:22,559 --> 00:30:24,159
that the content model performs best

885
00:30:24,159 --> 00:30:26,000
with a logistic regression model the

886
00:30:26,000 --> 00:30:27,919
context model performs best with best

887
00:30:27,919 --> 00:30:30,240
with an xg boost model

888
00:30:30,240 --> 00:30:32,320
and that using the maximum ensemble

889
00:30:32,320 --> 00:30:34,320
strategy just taking the maximum score

890
00:30:34,320 --> 00:30:36,559
from each of these models

891
00:30:36,559 --> 00:30:38,720
is the best and outperforms each of the

892
00:30:38,720 --> 00:30:41,039
individual models

893
00:30:41,039 --> 00:30:42,960
so once we see that this ensemble model

894
00:30:42,960 --> 00:30:44,720
performs the best and we output these

895
00:30:44,720 --> 00:30:46,799
alert level scores we now need to see

896
00:30:46,799 --> 00:30:49,440
how the aggregated score performs

897
00:30:49,440 --> 00:30:51,919
so here the average and the maximum of

898
00:30:51,919 --> 00:30:53,520
the alert level scores perform

899
00:30:53,520 --> 00:30:55,440
approximately the same and they tend to

900
00:30:55,440 --> 00:30:56,960
be the best strategies for the incident

901
00:30:56,960 --> 00:30:58,799
level results

902
00:30:58,799 --> 00:31:00,559
again it's really hard to contextualize

903
00:31:00,559 --> 00:31:02,240
what these numbers mean so let's

904
00:31:02,240 --> 00:31:04,480
actually look at the triage

905
00:31:04,480 --> 00:31:06,000
let's look at the triage results so we

906
00:31:06,000 --> 00:31:08,080
can see how these numbers manifest in

907
00:31:08,080 --> 00:31:10,559
the real world

908
00:31:10,559 --> 00:31:12,640
and the first triage system that i want

909
00:31:12,640 --> 00:31:13,840
to present

910
00:31:13,840 --> 00:31:16,880
is this incident prioritization

911
00:31:16,880 --> 00:31:19,519
as we go by the name of the talk

912
00:31:19,519 --> 00:31:22,000
so the way this kind of works is that

913
00:31:22,000 --> 00:31:23,919
whenever an incident comes about

914
00:31:23,919 --> 00:31:25,760
whenever an incident is created

915
00:31:25,760 --> 00:31:29,039
it gets added to an analyst's work queue

916
00:31:29,039 --> 00:31:30,320
and the analyst needs to go through

917
00:31:30,320 --> 00:31:33,950
their queue and resolve their incidents

918
00:31:33,950 --> 00:31:35,279
[Music]

919
00:31:35,279 --> 00:31:36,399
and

920
00:31:36,399 --> 00:31:38,799
generally the analysts have discretion

921
00:31:38,799 --> 00:31:40,559
at which

922
00:31:40,559 --> 00:31:42,640
incidents they want to take but for the

923
00:31:42,640 --> 00:31:44,080
most part they just kind of take them as

924
00:31:44,080 --> 00:31:46,320
they come new incident comes in they

925
00:31:46,320 --> 00:31:48,720
take whatever was there

926
00:31:48,720 --> 00:31:51,679
now if oops now if we look at this graph

927
00:31:51,679 --> 00:31:53,600
this left side is this baseline where

928
00:31:53,600 --> 00:31:55,360
the analysts kind of just take the cases

929
00:31:55,360 --> 00:31:57,039
as they come

930
00:31:57,039 --> 00:32:00,110
this blue bar is the amount of time

931
00:32:00,110 --> 00:32:01,200
[Music]

932
00:32:01,200 --> 00:32:04,880
that non-actionable cases spend in queue

933
00:32:04,880 --> 00:32:07,200
and this orange bar is the amount of

934
00:32:07,200 --> 00:32:09,600
time that actionable cases spend in

935
00:32:09,600 --> 00:32:10,799
queue

936
00:32:10,799 --> 00:32:12,399
just to do a little math for you this is

937
00:32:12,399 --> 00:32:14,559
approximately 20 minutes

938
00:32:14,559 --> 00:32:17,440
so it takes about 20 minutes of a kind

939
00:32:17,440 --> 00:32:20,000
of actionable case just sitting there

940
00:32:20,000 --> 00:32:23,440
festering not being seen by an analyst

941
00:32:23,440 --> 00:32:25,760
until someone finally gets to it

942
00:32:25,760 --> 00:32:28,320
so every single one of these false

943
00:32:28,320 --> 00:32:31,440
positives comes at the expense of these

944
00:32:31,440 --> 00:32:34,720
real actionable cases sitting in queue

945
00:32:34,720 --> 00:32:36,640
so what we do is we take the tech

946
00:32:36,640 --> 00:32:39,679
incident level scores and we resort the

947
00:32:39,679 --> 00:32:41,519
analyst queues

948
00:32:41,519 --> 00:32:45,039
and what we see is a 36 reduction

949
00:32:45,039 --> 00:32:47,200
in the amount of time that actionable

950
00:32:47,200 --> 00:32:49,760
cases spend in that queue basically the

951
00:32:49,760 --> 00:32:52,000
orange bar goes down so what we see is

952
00:32:52,000 --> 00:32:53,440
that analysts are getting to those

953
00:32:53,440 --> 00:32:56,080
actionable cases 36 percent faster than

954
00:32:56,080 --> 00:32:57,519
they would have which means that

955
00:32:57,519 --> 00:32:59,120
customers get attention the attention

956
00:32:59,120 --> 00:33:02,080
that they need much faster

957
00:33:02,080 --> 00:33:05,679
now there's a natural extension to this

958
00:33:05,679 --> 00:33:08,000
incident prioritization which is

959
00:33:08,000 --> 00:33:09,519
if you really rank

960
00:33:09,519 --> 00:33:11,120
every single

961
00:33:11,120 --> 00:33:13,600
incident what happens if you just remove

962
00:33:13,600 --> 00:33:15,760
the least important ones

963
00:33:15,760 --> 00:33:17,760
and that's the basis for the suppression

964
00:33:17,760 --> 00:33:19,279
system

965
00:33:19,279 --> 00:33:21,200
now i know that there's a lot going on

966
00:33:21,200 --> 00:33:22,960
in this graph and it's super important

967
00:33:22,960 --> 00:33:24,720
and it's really cool so i'm going to go

968
00:33:24,720 --> 00:33:26,240
over it super slowly and every little

969
00:33:26,240 --> 00:33:29,279
piece so you can see how it works

970
00:33:29,279 --> 00:33:31,360
let's look at this very bottom left

971
00:33:31,360 --> 00:33:33,679
orange bar right here

972
00:33:33,679 --> 00:33:36,080
this dark orange bar

973
00:33:36,080 --> 00:33:39,519
is the amount of actionable incidents

974
00:33:39,519 --> 00:33:40,480
that

975
00:33:40,480 --> 00:33:42,640
the analyst had to deal with on a single

976
00:33:42,640 --> 00:33:44,240
day

977
00:33:44,240 --> 00:33:46,240
this light orange bar

978
00:33:46,240 --> 00:33:48,320
is the amount of false positive

979
00:33:48,320 --> 00:33:49,519
incidents

980
00:33:49,519 --> 00:33:50,720
that the

981
00:33:50,720 --> 00:33:53,919
analysts had to deal with on that day

982
00:33:53,919 --> 00:33:56,240
and now these blue bars are comparisons

983
00:33:56,240 --> 00:33:57,679
with what would happen if you use the

984
00:33:57,679 --> 00:34:01,039
suppression system with the tech model

985
00:34:01,039 --> 00:34:03,679
so this dark blue bar is the amount of

986
00:34:03,679 --> 00:34:06,399
actionable cases that are left that day

987
00:34:06,399 --> 00:34:08,399
after using the suppression

988
00:34:08,399 --> 00:34:10,719
and the light blue bar is the amount of

989
00:34:10,719 --> 00:34:13,359
false positive cases that are left after

990
00:34:13,359 --> 00:34:14,960
using the suppression

991
00:34:14,960 --> 00:34:16,480
so the really striking thing you'll

992
00:34:16,480 --> 00:34:18,079
notice here is that there's a huge

993
00:34:18,079 --> 00:34:19,839
difference between the light orange and

994
00:34:19,839 --> 00:34:21,440
the light blue bars

995
00:34:21,440 --> 00:34:23,760
this is the reduction in false positive

996
00:34:23,760 --> 00:34:26,560
incidents that day

997
00:34:26,560 --> 00:34:28,079
and as you can see this trend kind of

998
00:34:28,079 --> 00:34:30,159
continues throughout the month so like

999
00:34:30,159 --> 00:34:32,879
on this third day there's no reduction

1000
00:34:32,879 --> 00:34:34,719
in actionable cases we don't miss any

1001
00:34:34,719 --> 00:34:36,480
but we still see a tremendous reduction

1002
00:34:36,480 --> 00:34:38,399
in the amount of false positives

1003
00:34:38,399 --> 00:34:40,079
if you average this over the entire

1004
00:34:40,079 --> 00:34:43,359
month you see a 47 reduction in false

1005
00:34:43,359 --> 00:34:46,040
positives while still retaining

1006
00:34:46,040 --> 00:34:51,520
97.5 percent of the actionable incidents

1007
00:34:52,480 --> 00:34:54,719
uh yeah

1008
00:34:54,719 --> 00:34:57,200
so the final piece of triage

1009
00:34:57,200 --> 00:35:00,720
is within incident over prioritization

1010
00:35:00,720 --> 00:35:02,800
so in order to test this

1011
00:35:02,800 --> 00:35:05,359
what we did was we took four incidents

1012
00:35:05,359 --> 00:35:07,760
three of which were actionable and one

1013
00:35:07,760 --> 00:35:09,680
of which was not actionable

1014
00:35:09,680 --> 00:35:11,599
and we provided two

1015
00:35:11,599 --> 00:35:14,720
orderings anonymously to actual cyber

1016
00:35:14,720 --> 00:35:16,480
security analysts

1017
00:35:16,480 --> 00:35:18,480
and the two orderings were chronological

1018
00:35:18,480 --> 00:35:19,440
which is

1019
00:35:19,440 --> 00:35:21,280
just the alerts in the order in which

1020
00:35:21,280 --> 00:35:22,560
they came which is how it's normally

1021
00:35:22,560 --> 00:35:23,599
done

1022
00:35:23,599 --> 00:35:25,680
and then the alerts ordered by the text

1023
00:35:25,680 --> 00:35:26,960
score

1024
00:35:26,960 --> 00:35:29,200
and we asked the domain experts to

1025
00:35:29,200 --> 00:35:31,119
take a look at these cases and we didn't

1026
00:35:31,119 --> 00:35:32,400
tell them which ordering that they were

1027
00:35:32,400 --> 00:35:34,160
seeing

1028
00:35:34,160 --> 00:35:36,240
what we found or what the analysts found

1029
00:35:36,240 --> 00:35:38,800
was that with the tech ordering they had

1030
00:35:38,800 --> 00:35:42,720
to look through 14 percent fewer alerts

1031
00:35:42,720 --> 00:35:45,119
to determine whether the case was even

1032
00:35:45,119 --> 00:35:48,240
worth their time

1033
00:35:48,800 --> 00:35:50,480
of course in order to resolve the case

1034
00:35:50,480 --> 00:35:52,160
the chronological ordering is still

1035
00:35:52,160 --> 00:35:53,680
useful and this doesn't account for that

1036
00:35:53,680 --> 00:35:54,480
time

1037
00:35:54,480 --> 00:35:56,000
but just to determine if they should

1038
00:35:56,000 --> 00:35:58,079
even bother taking the case they could

1039
00:35:58,079 --> 00:36:02,079
look at 14 fewer alerts

1040
00:36:02,160 --> 00:36:04,079
um okay so that's the last piece of

1041
00:36:04,079 --> 00:36:05,119
triage

1042
00:36:05,119 --> 00:36:06,640
um and here's just a couple examples

1043
00:36:06,640 --> 00:36:08,000
that i like to go over with what the

1044
00:36:08,000 --> 00:36:10,000
model scores actually look like just for

1045
00:36:10,000 --> 00:36:12,240
a little fun so we can see what cases

1046
00:36:12,240 --> 00:36:14,160
look like in practice

1047
00:36:14,160 --> 00:36:16,880
so this top case over here the model

1048
00:36:16,880 --> 00:36:17,960
scores a

1049
00:36:17,960 --> 00:36:20,640
0.99336 whatever

1050
00:36:20,640 --> 00:36:22,000
and i'm not going to read over all the

1051
00:36:22,000 --> 00:36:24,720
analyst notes but i'll just summarize it

1052
00:36:24,720 --> 00:36:26,560
basically what we found is that there's

1053
00:36:26,560 --> 00:36:28,000
this

1054
00:36:28,000 --> 00:36:29,560
metasploit

1055
00:36:29,560 --> 00:36:31,440
framework.latest.msi file that was

1056
00:36:31,440 --> 00:36:33,280
constantly run on the customers on the

1057
00:36:33,280 --> 00:36:35,280
customer's device and the analyst had to

1058
00:36:35,280 --> 00:36:38,640
go through and manually fix the issue

1059
00:36:38,640 --> 00:36:41,040
here are some of the role model scores

1060
00:36:41,040 --> 00:36:43,440
um and the analysts obviously were kind

1061
00:36:43,440 --> 00:36:45,760
of fed up with these cases because the

1062
00:36:45,760 --> 00:36:47,119
only things that they wrote about them

1063
00:36:47,119 --> 00:36:49,520
was benign activity

1064
00:36:49,520 --> 00:36:51,599
known false positive known false

1065
00:36:51,599 --> 00:36:53,839
positive there was nothing to do there

1066
00:36:53,839 --> 00:36:54,600
etcetera

1067
00:36:54,600 --> 00:36:56,800
[Music]

1068
00:36:56,800 --> 00:36:58,960
now it's worth noting that of course the

1069
00:36:58,960 --> 00:37:00,640
model is not perfect

1070
00:37:00,640 --> 00:37:02,000
this is a machine learning system

1071
00:37:02,000 --> 00:37:04,160
there's always going to be errors

1072
00:37:04,160 --> 00:37:06,000
and there are some false negatives like

1073
00:37:06,000 --> 00:37:07,359
you saw from the suppression graph we

1074
00:37:07,359 --> 00:37:09,119
still missed a couple percent of

1075
00:37:09,119 --> 00:37:11,280
actionable cases

1076
00:37:11,280 --> 00:37:13,040
and in these instances we have the model

1077
00:37:13,040 --> 00:37:15,200
scores are relatively low but not low

1078
00:37:15,200 --> 00:37:16,640
enough

1079
00:37:16,640 --> 00:37:17,760
and that's why i don't know if you were

1080
00:37:17,760 --> 00:37:19,760
here this morning but my colleague josh

1081
00:37:19,760 --> 00:37:22,160
talked about machine learning itself is

1082
00:37:22,160 --> 00:37:24,800
not enough to operate in the real world

1083
00:37:24,800 --> 00:37:26,560
you need to constantly have guardrails

1084
00:37:26,560 --> 00:37:28,640
and humans and other techniques that

1085
00:37:28,640 --> 00:37:31,119
adjust for the inadequacies of machine

1086
00:37:31,119 --> 00:37:32,079
learning

1087
00:37:32,079 --> 00:37:33,680
so even though you the machine learning

1088
00:37:33,680 --> 00:37:36,079
may miss certain incidents we make sure

1089
00:37:36,079 --> 00:37:39,680
that we don't using other guardrails

1090
00:37:40,560 --> 00:37:43,760
okay so the key takeaways here are that

1091
00:37:43,760 --> 00:37:45,680
tech is designed to fight alert fatigues

1092
00:37:45,680 --> 00:37:47,040
root causes

1093
00:37:47,040 --> 00:37:50,079
we had sensor diversity false positives

1094
00:37:50,079 --> 00:37:53,520
evolving threats and human integration

1095
00:37:53,520 --> 00:37:54,320
and

1096
00:37:54,320 --> 00:37:55,839
we think that the system delivers on

1097
00:37:55,839 --> 00:37:57,760
that promise

1098
00:37:57,760 --> 00:37:59,920
we see 47 percent of false positive

1099
00:37:59,920 --> 00:38:01,520
incidents that are suppressed while

1100
00:38:01,520 --> 00:38:03,599
maintaining high detection rates

1101
00:38:03,599 --> 00:38:06,160
we see incidents spending 30 percent 36

1102
00:38:06,160 --> 00:38:08,560
percent less time in queue

1103
00:38:08,560 --> 00:38:10,320
for actionable incidents

1104
00:38:10,320 --> 00:38:12,400
and we see that analysts have to look at

1105
00:38:12,400 --> 00:38:14,400
14 fewer

1106
00:38:14,400 --> 00:38:16,240
alerts in order to determine if a case

1107
00:38:16,240 --> 00:38:19,799
is worth their time

1108
00:38:19,839 --> 00:38:22,880
and that's all i have for today

1109
00:38:22,880 --> 00:38:25,359
thanks for listening and open to any

1110
00:38:25,359 --> 00:38:27,680
questions comments discussion

1111
00:38:27,680 --> 00:38:30,680
etc

1112
00:38:31,770 --> 00:38:36,710
[Laughter]

1113
00:38:37,920 --> 00:38:39,680
uh yes over there

1114
00:38:39,680 --> 00:38:42,560
i might have trouble hearing you so

1115
00:38:42,560 --> 00:38:46,520
oh we have a microphone i think

1116
00:38:48,400 --> 00:38:51,400
yes

1117
00:39:26,960 --> 00:39:29,920
i have a yeah about this

1118
00:39:29,920 --> 00:39:32,920
process

1119
00:39:35,400 --> 00:39:38,519
[Music]

1120
00:39:50,640 --> 00:39:51,440
and

1121
00:39:51,440 --> 00:39:54,640
i was wondering if that results in some

1122
00:39:54,640 --> 00:39:57,040
sort of

1123
00:40:03,440 --> 00:40:04,640
yes

1124
00:40:04,640 --> 00:40:07,680
okay so let me rephrase the question

1125
00:40:07,680 --> 00:40:08,560
so

1126
00:40:08,560 --> 00:40:09,520
uh

1127
00:40:09,520 --> 00:40:11,680
colleague here was asking about the

1128
00:40:11,680 --> 00:40:13,520
feedback loop system

1129
00:40:13,520 --> 00:40:15,680
which says um

1130
00:40:15,680 --> 00:40:17,440
which could and he was asking if it's

1131
00:40:17,440 --> 00:40:19,280
potentially biased

1132
00:40:19,280 --> 00:40:20,400
because

1133
00:40:20,400 --> 00:40:22,000
cases that are suppressed or that don't

1134
00:40:22,000 --> 00:40:24,720
make it to the analysts are not going to

1135
00:40:24,720 --> 00:40:26,319
be re-reviewed

1136
00:40:26,319 --> 00:40:28,160
and therefore only a biased sample of

1137
00:40:28,160 --> 00:40:30,319
cases are coming into the very end in

1138
00:40:30,319 --> 00:40:33,200
that feedback loop

1139
00:40:33,200 --> 00:40:35,920
that's a good question thank you and

1140
00:40:35,920 --> 00:40:37,760
the answer to that is

1141
00:40:37,760 --> 00:40:39,359
that alert data doesn't actually

1142
00:40:39,359 --> 00:40:41,520
disappear so it stays in the alert

1143
00:40:41,520 --> 00:40:43,200
database and it is continuously

1144
00:40:43,200 --> 00:40:44,720
retrained on

1145
00:40:44,720 --> 00:40:46,880
um but generally this doesn't cause an

1146
00:40:46,880 --> 00:40:48,319
issue because

1147
00:40:48,319 --> 00:40:50,960
if we really determine that those cases

1148
00:40:50,960 --> 00:40:52,240
are false positives and they never

1149
00:40:52,240 --> 00:40:55,520
really need to be looked at again

1150
00:40:55,520 --> 00:40:57,280
then it's worth it to just keep the

1151
00:40:57,280 --> 00:40:59,280
labels that we already have

1152
00:40:59,280 --> 00:41:01,440
on those alerts

1153
00:41:01,440 --> 00:41:05,040
changing the label back to actionable

1154
00:41:05,040 --> 00:41:06,720
is possible if you want to manually

1155
00:41:06,720 --> 00:41:08,400
adjust them but is generally not

1156
00:41:08,400 --> 00:41:10,240
necessary because

1157
00:41:10,240 --> 00:41:12,400
a confident false positive usually stays

1158
00:41:12,400 --> 00:41:15,520
a confident false positive

1159
00:41:16,000 --> 00:41:19,800
hopefully that answers your question

1160
00:41:20,000 --> 00:41:21,820
oh the false negatives

1161
00:41:21,820 --> 00:41:24,480
[Music]

1162
00:41:24,480 --> 00:41:28,720
oh oh yes okay i'm sorry i misunderstood

1163
00:41:28,720 --> 00:41:30,400
okay so you're asking about these false

1164
00:41:30,400 --> 00:41:32,079
negatives yes

1165
00:41:32,079 --> 00:41:35,200
okay okay my bad let me rephrase the

1166
00:41:35,200 --> 00:41:36,560
question again

1167
00:41:36,560 --> 00:41:39,119
what he was asking was uh

1168
00:41:39,119 --> 00:41:40,960
what happens with these

1169
00:41:40,960 --> 00:41:42,800
um false negatives like if you decide to

1170
00:41:42,800 --> 00:41:45,359
suppress the model or if you decide to

1171
00:41:45,359 --> 00:41:46,800
use the suppression system and these

1172
00:41:46,800 --> 00:41:48,800
cases never make it to the analysts then

1173
00:41:48,800 --> 00:41:50,640
the labels don't get fixed

1174
00:41:50,640 --> 00:41:52,240
and the answer to that is

1175
00:41:52,240 --> 00:41:54,480
the reality is that we mostly focus on

1176
00:41:54,480 --> 00:41:56,880
this incident prioritization system

1177
00:41:56,880 --> 00:41:58,720
rather than the suppression

1178
00:41:58,720 --> 00:42:00,400
so we actually try not to use the

1179
00:42:00,400 --> 00:42:01,599
suppression at all

1180
00:42:01,599 --> 00:42:03,200
and currently it's still in a prototype

1181
00:42:03,200 --> 00:42:06,640
and it's not being used in the real sock

1182
00:42:06,640 --> 00:42:07,760
but basically when you have the

1183
00:42:07,760 --> 00:42:09,050
prioritization system

1184
00:42:09,050 --> 00:42:10,240
[Music]

1185
00:42:10,240 --> 00:42:13,200
the cases that are deep prioritized as

1186
00:42:13,200 --> 00:42:15,680
if they would be suppressed the analysts

1187
00:42:15,680 --> 00:42:17,599
still actually get to see at the end of

1188
00:42:17,599 --> 00:42:19,760
their day

1189
00:42:19,760 --> 00:42:21,520
so those particular cases do have a

1190
00:42:21,520 --> 00:42:23,680
slightly longer queue time but we do

1191
00:42:23,680 --> 00:42:25,359
make sure to have a guard rail over

1192
00:42:25,359 --> 00:42:26,880
those false negatives

1193
00:42:26,880 --> 00:42:28,240
so that there is actually a person still

1194
00:42:28,240 --> 00:42:30,560
looking at them

1195
00:42:30,560 --> 00:42:31,839
yep

1196
00:42:31,839 --> 00:42:34,480
yes right here

1197
00:42:44,480 --> 00:42:46,800
oh sure so you're asking about the uh

1198
00:42:46,800 --> 00:42:48,400
okay yeah so

1199
00:42:48,400 --> 00:42:50,800
the question was how are we featurizing

1200
00:42:50,800 --> 00:42:52,240
these different things like command

1201
00:42:52,240 --> 00:42:54,079
lines and file paths

1202
00:42:54,079 --> 00:42:56,240
uh and right now um there's a couple of

1203
00:42:56,240 --> 00:42:58,640
different different strategies

1204
00:42:58,640 --> 00:42:59,359
so

1205
00:42:59,359 --> 00:43:01,920
the first easiest way and the first kind

1206
00:43:01,920 --> 00:43:04,079
of attempt at this was to treat

1207
00:43:04,079 --> 00:43:06,960
everything as a categorical feature

1208
00:43:06,960 --> 00:43:09,200
so basically just check the uniqueness

1209
00:43:09,200 --> 00:43:11,440
of the strings

1210
00:43:11,440 --> 00:43:12,480
but something that we're actually

1211
00:43:12,480 --> 00:43:14,800
prototyping and working on now is an

1212
00:43:14,800 --> 00:43:17,040
automated natural language processing

1213
00:43:17,040 --> 00:43:19,760
module for determining which natural

1214
00:43:19,760 --> 00:43:21,760
language processing techniques

1215
00:43:21,760 --> 00:43:24,000
are best for each type of string because

1216
00:43:24,000 --> 00:43:25,599
the amount of diversity in the strings

1217
00:43:25,599 --> 00:43:27,520
is immense there's hundreds of different

1218
00:43:27,520 --> 00:43:29,599
fields some of them look like actual

1219
00:43:29,599 --> 00:43:32,000
text some of them look like command

1220
00:43:32,000 --> 00:43:34,640
lines and file paths so we have the so

1221
00:43:34,640 --> 00:43:36,720
we have different parsers

1222
00:43:36,720 --> 00:43:38,319
for things like command lines to deal

1223
00:43:38,319 --> 00:43:40,400
with slashes whereas for text you would

1224
00:43:40,400 --> 00:43:42,480
use a normal text processor and that's

1225
00:43:42,480 --> 00:43:43,599
actually some of the research that we're

1226
00:43:43,599 --> 00:43:45,760
working on now is to do this without

1227
00:43:45,760 --> 00:43:48,079
having any sort of intervention just

1228
00:43:48,079 --> 00:43:49,520
have a system that figures it out on its

1229
00:43:49,520 --> 00:43:50,960
own

1230
00:43:50,960 --> 00:43:53,960
yep

1231
00:43:57,839 --> 00:44:01,078
uh yeah

1232
00:44:06,470 --> 00:44:09,200
[Music]

1233
00:44:09,200 --> 00:44:12,200
um

1234
00:44:14,180 --> 00:44:17,350
[Music]

1235
00:44:25,520 --> 00:44:27,920
right okay so to rephrase the question

1236
00:44:27,920 --> 00:44:28,310
um

1237
00:44:28,310 --> 00:44:30,960
[Music]

1238
00:44:30,960 --> 00:44:32,079
sorry let me let me just think about how

1239
00:44:32,079 --> 00:44:33,680
to rephrase that

1240
00:44:33,680 --> 00:44:35,119
um

1241
00:44:35,119 --> 00:44:37,280
what you're saying was that the alerting

1242
00:44:37,280 --> 00:44:39,119
the alerting rules

1243
00:44:39,119 --> 00:44:40,480
uh i'm sorry can you actually just

1244
00:44:40,480 --> 00:44:43,119
repeat the question

1245
00:44:48,400 --> 00:44:50,960
uh okay uh yeah the question is is there

1246
00:44:50,960 --> 00:44:52,960
a lack of expressivity

1247
00:44:52,960 --> 00:44:56,000
in the alerting rules themselves um and

1248
00:44:56,000 --> 00:44:58,000
the answer is yes that's fundamentally

1249
00:44:58,000 --> 00:44:59,680
one of the problems with

1250
00:44:59,680 --> 00:45:01,359
uh the sensors

1251
00:45:01,359 --> 00:45:03,839
is that the sensors are written by

1252
00:45:03,839 --> 00:45:06,720
people who are looking at very specific

1253
00:45:06,720 --> 00:45:08,800
things and they're trying their best to

1254
00:45:08,800 --> 00:45:10,880
use their domain expertise

1255
00:45:10,880 --> 00:45:13,200
in order to capture malicious behavior

1256
00:45:13,200 --> 00:45:15,520
that's kind of how the sensors are built

1257
00:45:15,520 --> 00:45:17,280
but there's a limitation to what humans

1258
00:45:17,280 --> 00:45:19,680
can find

1259
00:45:19,680 --> 00:45:21,520
the reason this feed and the reason the

1260
00:45:21,520 --> 00:45:23,599
feedback system works even though the

1261
00:45:23,599 --> 00:45:25,520
sensors and the alerting rules don't

1262
00:45:25,520 --> 00:45:26,720
change

1263
00:45:26,720 --> 00:45:28,880
is that the machine learning

1264
00:45:28,880 --> 00:45:32,880
is able to work at a more complex level

1265
00:45:32,880 --> 00:45:35,760
than specific human decisions on certain

1266
00:45:35,760 --> 00:45:37,119
fields

1267
00:45:37,119 --> 00:45:39,599
because maybe

1268
00:45:39,599 --> 00:45:40,960
you can look at

1269
00:45:40,960 --> 00:45:43,280
10 or 11 or 30

1270
00:45:43,280 --> 00:45:45,839
different human written fields and the

1271
00:45:45,839 --> 00:45:48,480
combination of those fields can uniquely

1272
00:45:48,480 --> 00:45:50,480
identify a new threat

1273
00:45:50,480 --> 00:45:52,720
this is one of the reasons that manually

1274
00:45:52,720 --> 00:45:55,359
adjusting all the sensors is infeasible

1275
00:45:55,359 --> 00:45:58,400
a human can't really take into account a

1276
00:45:58,400 --> 00:46:00,319
hundred different features and write a

1277
00:46:00,319 --> 00:46:02,400
specific alerting role that's really

1278
00:46:02,400 --> 00:46:04,480
that focused or if they can it's going

1279
00:46:04,480 --> 00:46:06,800
to be extremely expensive whereas the

1280
00:46:06,800 --> 00:46:08,319
machine learning learns that kind of

1281
00:46:08,319 --> 00:46:10,480
stuff statistically through just a lot

1282
00:46:10,480 --> 00:46:14,560
of data and that feedback loop

1283
00:46:14,560 --> 00:46:17,839
yeah thank you great question

1284
00:46:21,599 --> 00:46:23,680
um okay if there are no more questions

1285
00:46:23,680 --> 00:46:26,919
thanks again

1286
00:46:28,160 --> 00:46:30,240
you

