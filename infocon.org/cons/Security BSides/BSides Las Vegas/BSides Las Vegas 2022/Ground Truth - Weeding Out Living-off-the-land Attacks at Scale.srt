1
00:00:00,000 --> 00:00:02,820
good afternoon welcome to besides Las

2
00:00:02,820 --> 00:00:05,400
Vegas ground truth track

3
00:00:05,400 --> 00:00:07,740
this talk is weeding out living off the

4
00:00:07,740 --> 00:00:12,179
land attacks at scale given by oh God I

5
00:00:12,179 --> 00:00:14,160
forgot your name

6
00:00:14,160 --> 00:00:16,560
by adarsh

7
00:00:16,560 --> 00:00:17,340
um

8
00:00:17,340 --> 00:00:20,039
a few announcements before we begin uh

9
00:00:20,039 --> 00:00:21,359
we'd like to thank our sponsors

10
00:00:21,359 --> 00:00:24,000
especially our Diamond sponsors LastPass

11
00:00:24,000 --> 00:00:26,460
and Palo Alto networks our gold sponsors

12
00:00:26,460 --> 00:00:29,340
Amazon and vizium and Google is their

13
00:00:29,340 --> 00:00:30,960
support along with our other sponsors

14
00:00:30,960 --> 00:00:33,059
donors and volunteers that make this

15
00:00:33,059 --> 00:00:34,320
event possible

16
00:00:34,320 --> 00:00:36,420
these talks are being streamed live

17
00:00:36,420 --> 00:00:39,000
except in underground track and as a

18
00:00:39,000 --> 00:00:40,800
courtesy to our speakers and audience we

19
00:00:40,800 --> 00:00:42,480
ask that you check to make sure that

20
00:00:42,480 --> 00:00:44,579
your cell phones are sent to silent or

21
00:00:44,579 --> 00:00:47,940
vibrate if you have a question uh we're

22
00:00:47,940 --> 00:00:50,340
actually doing questions at the end if

23
00:00:50,340 --> 00:00:52,680
you do have one use this microphone that

24
00:00:52,680 --> 00:00:54,000
I'm standing at in the middle of the

25
00:00:54,000 --> 00:00:56,879
room so YouTube can hear you

26
00:00:56,879 --> 00:00:57,840
um

27
00:00:57,840 --> 00:01:00,899
as a reminder the B size LV photo policy

28
00:01:00,899 --> 00:01:02,699
prohibits taking pictures without the

29
00:01:02,699 --> 00:01:04,619
explicit permission of everyone in frame

30
00:01:04,619 --> 00:01:06,900
these talks are all being recorded and

31
00:01:06,900 --> 00:01:08,640
will be available on YouTube in the

32
00:01:08,640 --> 00:01:10,020
future again with the exception of

33
00:01:10,020 --> 00:01:11,040
underground

34
00:01:11,040 --> 00:01:12,960
of course please keep your mask on at

35
00:01:12,960 --> 00:01:14,820
all times

36
00:01:14,820 --> 00:01:17,159
um if you want to move closer to the

37
00:01:17,159 --> 00:01:18,720
middle of the room please keep social

38
00:01:18,720 --> 00:01:21,840
distancing in mind as well

39
00:01:21,840 --> 00:01:24,119
um with that let's get started welcome a

40
00:01:24,119 --> 00:01:25,500
darsh

41
00:01:25,500 --> 00:01:30,119
[Applause]

42
00:01:30,119 --> 00:01:31,500
thank you

43
00:01:31,500 --> 00:01:33,360
um can everyone hear me okay all the way

44
00:01:33,360 --> 00:01:36,479
at the back all right sounds good

45
00:01:36,479 --> 00:01:39,840
um so hi everyone I'm adarsh I'm a

46
00:01:39,840 --> 00:01:42,659
resource manager at surface Ai and today

47
00:01:42,659 --> 00:01:45,560
I'll be talking about weeding out living

48
00:01:45,560 --> 00:01:48,180
attacks Escape

49
00:01:48,180 --> 00:01:49,200
um

50
00:01:49,200 --> 00:01:51,540
so a little bit about me

51
00:01:51,540 --> 00:01:53,340
um I have been working at the

52
00:01:53,340 --> 00:01:54,780
intersection of security and machine

53
00:01:54,780 --> 00:01:56,460
learning for

54
00:01:56,460 --> 00:01:58,140
is it cutting out I feel like it's

55
00:01:58,140 --> 00:01:59,759
cutting out

56
00:01:59,759 --> 00:02:02,299
okay

57
00:02:06,850 --> 00:02:09,780
[Music]

58
00:02:09,780 --> 00:02:11,580
sorry about that

59
00:02:11,580 --> 00:02:13,020
um so I've been working at the

60
00:02:13,020 --> 00:02:14,700
intersection of data science and machine

61
00:02:14,700 --> 00:02:17,160
learning for four and a half years all

62
00:02:17,160 --> 00:02:20,700
of that has been at surface AI I joined

63
00:02:20,700 --> 00:02:22,980
right out of grad school I completed a

64
00:02:22,980 --> 00:02:24,840
master's degree in computer science with

65
00:02:24,840 --> 00:02:26,340
a specialization in artificial

66
00:02:26,340 --> 00:02:28,800
intelligence and machine learning at UC

67
00:02:28,800 --> 00:02:31,019
San Diego currently I live in Denver

68
00:02:31,019 --> 00:02:33,720
with my dog and I'm originally from

69
00:02:33,720 --> 00:02:36,360
India I grew up in Bangalore and moved

70
00:02:36,360 --> 00:02:37,980
to the U.S

71
00:02:37,980 --> 00:02:40,200
for grad school

72
00:02:40,200 --> 00:02:43,500
so before I begin uh talking about the

73
00:02:43,500 --> 00:02:45,360
technical details of this talk I'd like

74
00:02:45,360 --> 00:02:48,180
to mention that this uh the work that

75
00:02:48,180 --> 00:02:49,800
went behind this talk is a huge

76
00:02:49,800 --> 00:02:51,780
collaborative effort across several

77
00:02:51,780 --> 00:02:54,840
teams in Sophos AI uh this involves data

78
00:02:54,840 --> 00:02:56,340
scientists data Engineers threat

79
00:02:56,340 --> 00:02:58,080
analysts software engineers and program

80
00:02:58,080 --> 00:03:00,300
managers and I'd like to take a minute

81
00:03:00,300 --> 00:03:03,060
to uh

82
00:03:03,060 --> 00:03:05,340
to acknowledge their contributions and

83
00:03:05,340 --> 00:03:07,760
thank you for

84
00:03:07,860 --> 00:03:10,620
anyway now let's get to the technical

85
00:03:10,620 --> 00:03:12,780
specifics uh what is this talk about

86
00:03:12,780 --> 00:03:15,900
this talk details the development of a

87
00:03:15,900 --> 00:03:18,360
machine Learning System that detects

88
00:03:18,360 --> 00:03:21,239
living off the land binary attacks the

89
00:03:21,239 --> 00:03:22,500
system is supposed to be another

90
00:03:22,500 --> 00:03:25,260
detector or sensor that feeds alerts

91
00:03:25,260 --> 00:03:27,720
into the security Operation Center if

92
00:03:27,720 --> 00:03:30,000
you attended Ben's talk yesterday uh Ben

93
00:03:30,000 --> 00:03:32,760
Gillman from sofas AI uh you got some

94
00:03:32,760 --> 00:03:34,680
context on how we have different sensors

95
00:03:34,680 --> 00:03:37,500
that feed into our feed alerts into our

96
00:03:37,500 --> 00:03:39,659
security operations center and how these

97
00:03:39,659 --> 00:03:42,540
alerts are manually then reviewed by uh

98
00:03:42,540 --> 00:03:45,239
our sock analysts so we look into the

99
00:03:45,239 --> 00:03:47,220
technical details of how we designed the

100
00:03:47,220 --> 00:03:49,920
system that surfaces living off the land

101
00:03:49,920 --> 00:03:52,260
binary attack alerts

102
00:03:52,260 --> 00:03:53,879
um the challenges we face during the

103
00:03:53,879 --> 00:03:55,500
development of the system

104
00:03:55,500 --> 00:03:57,480
the strategies we use to mitigate them

105
00:03:57,480 --> 00:04:00,120
and finally the generic lessons that we

106
00:04:00,120 --> 00:04:02,159
learned along the way

107
00:04:02,159 --> 00:04:04,739
if you attended Josh's talk yesterday uh

108
00:04:04,739 --> 00:04:07,019
you'll remember this slide

109
00:04:07,019 --> 00:04:09,420
um spoiler alert I come to pretty much

110
00:04:09,420 --> 00:04:11,519
uh the same conclusion at the end of

111
00:04:11,519 --> 00:04:13,620
this talk uh but I just take a different

112
00:04:13,620 --> 00:04:15,180
path

113
00:04:15,180 --> 00:04:19,380
um I use this uh project as kind of a

114
00:04:19,380 --> 00:04:22,259
case study to demonstrate uh each of

115
00:04:22,259 --> 00:04:25,340
these points that he made yesterday

116
00:04:25,440 --> 00:04:28,259
okay so what are the goals of this

117
00:04:28,259 --> 00:04:29,759
system because it's important to define

118
00:04:29,759 --> 00:04:32,580
the goals before we start working on it

119
00:04:32,580 --> 00:04:35,520
um so the first goal is to surface

120
00:04:35,520 --> 00:04:37,199
surface additional living off the land

121
00:04:37,199 --> 00:04:39,660
attacks to the security Operation Center

122
00:04:39,660 --> 00:04:43,560
uh that are not yet uh being detected by

123
00:04:43,560 --> 00:04:45,360
existing methodologies

124
00:04:45,360 --> 00:04:49,740
but more importantly the second goal is

125
00:04:49,740 --> 00:04:52,199
since this system is going to surface

126
00:04:52,199 --> 00:04:55,020
alerts to a security Operation Center

127
00:04:55,020 --> 00:04:57,780
it's not supposed to be flooding the

128
00:04:57,780 --> 00:04:59,759
stock with alerts especially not false

129
00:04:59,759 --> 00:05:02,539
positive alerts

130
00:05:03,960 --> 00:05:06,360
now that we have the goals squared away

131
00:05:06,360 --> 00:05:08,160
let's move on to understanding the

132
00:05:08,160 --> 00:05:10,380
actual problem what are living of land

133
00:05:10,380 --> 00:05:11,820
binary attacks

134
00:05:11,820 --> 00:05:14,220
living off the land attacks or Urban

135
00:05:14,220 --> 00:05:16,440
attacks in short are attacks that

136
00:05:16,440 --> 00:05:19,979
involve the use of binaries that are

137
00:05:19,979 --> 00:05:22,080
either pre-installed by the user in a

138
00:05:22,080 --> 00:05:24,840
system or existing system binaries uh

139
00:05:24,840 --> 00:05:26,820
these binaries are used in a malicious

140
00:05:26,820 --> 00:05:29,699
way uh and that's what constitutes a

141
00:05:29,699 --> 00:05:31,620
urban attack and in general the attack

142
00:05:31,620 --> 00:05:34,139
Vector for this attack

143
00:05:34,139 --> 00:05:36,180
um is a command line that is executed

144
00:05:36,180 --> 00:05:39,720
against set binary these attacks tend to

145
00:05:39,720 --> 00:05:42,360
be extremely hard to detect uh and

146
00:05:42,360 --> 00:05:46,979
defend against for many reasons uh some

147
00:05:46,979 --> 00:05:49,080
of which are that they have a very small

148
00:05:49,080 --> 00:05:51,240
footprint on the user system sometimes

149
00:05:51,240 --> 00:05:52,800
it's really hard to differentiate

150
00:05:52,800 --> 00:05:55,020
between like legitimate this admin

151
00:05:55,020 --> 00:05:57,300
activity and love win attacks and

152
00:05:57,300 --> 00:06:00,560
several other reasons

153
00:06:01,259 --> 00:06:02,460
so

154
00:06:02,460 --> 00:06:04,860
um our problem is that we want to detect

155
00:06:04,860 --> 00:06:06,780
uh loving attacks with machine learning

156
00:06:06,780 --> 00:06:11,699
so is this uh a good nail for the hammer

157
00:06:11,699 --> 00:06:13,800
of machine learning

158
00:06:13,800 --> 00:06:16,259
um in order to determine whether this is

159
00:06:16,259 --> 00:06:18,840
a good candidate solution to be solved

160
00:06:18,840 --> 00:06:20,759
by Machine learning uh we need a couple

161
00:06:20,759 --> 00:06:22,319
of things

162
00:06:22,319 --> 00:06:24,360
um we've established that the artifact

163
00:06:24,360 --> 00:06:27,120
that we can use to detect a lulman

164
00:06:27,120 --> 00:06:28,860
attack is usually the command line that

165
00:06:28,860 --> 00:06:31,680
is executed so we need a lot of

166
00:06:31,680 --> 00:06:35,340
Representative command line data that is

167
00:06:35,340 --> 00:06:37,560
very similar in distribution to the

168
00:06:37,560 --> 00:06:39,120
actual command line data that we'll be

169
00:06:39,120 --> 00:06:42,360
predicting against second we need a lot

170
00:06:42,360 --> 00:06:44,460
of good labels for this data in order to

171
00:06:44,460 --> 00:06:46,080
teach a machine learning model what is a

172
00:06:46,080 --> 00:06:47,580
malicious command and what is a benign

173
00:06:47,580 --> 00:06:49,440
command we need to have plenty of

174
00:06:49,440 --> 00:06:52,979
examples that span a wide variety of use

175
00:06:52,979 --> 00:06:55,280
cases

176
00:06:57,120 --> 00:06:59,340
well the first problem is not really an

177
00:06:59,340 --> 00:07:02,039
issue because uh working at a large

178
00:07:02,039 --> 00:07:04,020
security vendor we have plenty of access

179
00:07:04,020 --> 00:07:06,539
to the actual distribution of command

180
00:07:06,539 --> 00:07:07,979
line data that we'll be predicting

181
00:07:07,979 --> 00:07:09,599
against

182
00:07:09,599 --> 00:07:13,560
um we in this work we limit our uh we

183
00:07:13,560 --> 00:07:17,340
mainly focus on uh detecting

184
00:07:17,340 --> 00:07:21,660
and surfacing alerts to the MDR to

185
00:07:21,660 --> 00:07:23,880
manage detection and response system and

186
00:07:23,880 --> 00:07:26,580
there we have about a 1.5 billion

187
00:07:26,580 --> 00:07:29,340
command line invocations per day across

188
00:07:29,340 --> 00:07:31,440
all our customers which feed into the

189
00:07:31,440 --> 00:07:33,240
existing detection and alerting system

190
00:07:33,240 --> 00:07:35,280
so this is the data that we actually

191
00:07:35,280 --> 00:07:38,580
want to plug our model into and surface

192
00:07:38,580 --> 00:07:40,560
additional alerts

193
00:07:40,560 --> 00:07:43,199
um a machine learning based detector is

194
00:07:43,199 --> 00:07:45,060
actually the perfect addition here

195
00:07:45,060 --> 00:07:46,620
considering the incoming data volume

196
00:07:46,620 --> 00:07:49,139
because invariably when you have one and

197
00:07:49,139 --> 00:07:51,120
a half billion command lines there are a

198
00:07:51,120 --> 00:07:52,860
few attacks that are like getting

199
00:07:52,860 --> 00:07:53,879
through

200
00:07:53,879 --> 00:07:56,230
that are probably being missed right now

201
00:07:56,230 --> 00:07:58,199
[Music]

202
00:07:58,199 --> 00:08:01,680
so having data is not an issue but

203
00:08:01,680 --> 00:08:05,340
but often we run into snags when uh uh

204
00:08:05,340 --> 00:08:07,680
we need to have enough labels

205
00:08:07,680 --> 00:08:09,740
um

206
00:08:10,199 --> 00:08:13,560
finding labels for command line data can

207
00:08:13,560 --> 00:08:16,560
be a little harder and it also often

208
00:08:16,560 --> 00:08:19,560
becomes a catch-22 problem where you

209
00:08:19,560 --> 00:08:21,060
know if you have a reliable quick and

210
00:08:21,060 --> 00:08:22,860
accurate way to label

211
00:08:22,860 --> 00:08:25,500
your command lines then why do you need

212
00:08:25,500 --> 00:08:27,720
a machine learning model

213
00:08:27,720 --> 00:08:30,780
um to detect little bins however uh we

214
00:08:30,780 --> 00:08:32,519
don't have any such quick reliable

215
00:08:32,519 --> 00:08:36,659
systems so we have to resort to uh three

216
00:08:36,659 --> 00:08:39,059
prong strategy to label the command line

217
00:08:39,059 --> 00:08:41,958
data that we've got

218
00:08:47,160 --> 00:08:48,240
um so here are the three different

219
00:08:48,240 --> 00:08:50,519
strategies that we use uh to label our

220
00:08:50,519 --> 00:08:52,920
data the simplest source of labels for

221
00:08:52,920 --> 00:08:55,800
our problems this lies in past data some

222
00:08:55,800 --> 00:08:57,839
LOL bin attacks have already been seen

223
00:08:57,839 --> 00:08:59,220
and investigated by the security

224
00:08:59,220 --> 00:09:01,920
Operation Center and we have that

225
00:09:01,920 --> 00:09:03,540
information stored so you can just

226
00:09:03,540 --> 00:09:04,980
directly use it

227
00:09:04,980 --> 00:09:07,620
the Second Source uh where we got really

228
00:09:07,620 --> 00:09:11,880
creative is uh indirect labels sofas has

229
00:09:11,880 --> 00:09:13,920
a lot of different products and across

230
00:09:13,920 --> 00:09:15,899
all these products we have labeled data

231
00:09:15,899 --> 00:09:18,060
for several artifacts like files and

232
00:09:18,060 --> 00:09:19,800
URLs

233
00:09:19,800 --> 00:09:22,380
um and we can use this information to

234
00:09:22,380 --> 00:09:24,660
indirectly label command lines for

235
00:09:24,660 --> 00:09:26,760
example if a malicious file in a user

236
00:09:26,760 --> 00:09:28,980
system also triggers the execution of a

237
00:09:28,980 --> 00:09:30,600
malicious command line there we have an

238
00:09:30,600 --> 00:09:33,000
example of a known malicious command

239
00:09:33,000 --> 00:09:35,459
line that we can use to augment our

240
00:09:35,459 --> 00:09:37,980
training data

241
00:09:37,980 --> 00:09:40,339
um and the third strategy that we used

242
00:09:40,339 --> 00:09:44,279
uh is that we now have a dedicated group

243
00:09:44,279 --> 00:09:45,899
of threat analysts that are part of

244
00:09:45,899 --> 00:09:48,779
sofas AI who distill all the information

245
00:09:48,779 --> 00:09:51,360
from like the first two sources and all

246
00:09:51,360 --> 00:09:53,820
the knowledge that they have uh and

247
00:09:53,820 --> 00:09:56,399
create roles these rules can be used for

248
00:09:56,399 --> 00:09:59,480
labeling our data

249
00:09:59,519 --> 00:10:01,500
so here's an example of the indirect

250
00:10:01,500 --> 00:10:03,120
labeling through a surface product that

251
00:10:03,120 --> 00:10:04,560
I talked about

252
00:10:04,560 --> 00:10:07,079
um intercept X has something called root

253
00:10:07,079 --> 00:10:10,260
cause analysis where

254
00:10:10,260 --> 00:10:13,140
um when it finds a malicious file it

255
00:10:13,140 --> 00:10:14,820
constructs a graph of all operations

256
00:10:14,820 --> 00:10:17,160
that a triggered a triggering file

257
00:10:17,160 --> 00:10:19,019
performs on the user system so this

258
00:10:19,019 --> 00:10:20,760
involves like touching files deleting

259
00:10:20,760 --> 00:10:24,899
files creating processes and more

260
00:10:24,899 --> 00:10:27,660
importantly uh running command lines so

261
00:10:27,660 --> 00:10:29,640
we collect a lot of potentially

262
00:10:29,640 --> 00:10:32,480
malicious command lines from this data

263
00:10:32,480 --> 00:10:35,279
and here on the slide you can see an

264
00:10:35,279 --> 00:10:37,200
example of like a root cause analysis

265
00:10:37,200 --> 00:10:39,300
graph and a command line that we

266
00:10:39,300 --> 00:10:41,940
obtained from their uh that could

267
00:10:41,940 --> 00:10:45,500
potentially be malicious

268
00:10:46,380 --> 00:10:47,760
um some other sources for indirect

269
00:10:47,760 --> 00:10:50,339
labeling uh we use sandbox Behavior

270
00:10:50,339 --> 00:10:53,279
reports uh one good thing about sandbox

271
00:10:53,279 --> 00:10:56,579
to behavior reports is that the

272
00:10:56,579 --> 00:10:59,100
detection engine hooks into Windows

273
00:10:59,100 --> 00:11:01,620
anti-malware scan interface which means

274
00:11:01,620 --> 00:11:05,399
that it gets access to the actual blob

275
00:11:05,399 --> 00:11:08,160
of code that is executing when a command

276
00:11:08,160 --> 00:11:11,100
line invocation happens which means it

277
00:11:11,100 --> 00:11:12,779
can get through a lot of issues that

278
00:11:12,779 --> 00:11:15,480
obfuscation or like when you're trying

279
00:11:15,480 --> 00:11:18,720
to execute code from PS1 file uh we

280
00:11:18,720 --> 00:11:20,459
can't see what the contents of the PS1

281
00:11:20,459 --> 00:11:22,860
file are from the command line itself so

282
00:11:22,860 --> 00:11:25,260
we get a lot of uh indirect labels from

283
00:11:25,260 --> 00:11:28,620
that Source we also do URL lookups where

284
00:11:28,620 --> 00:11:32,399
through the Mexican web uh product we

285
00:11:32,399 --> 00:11:35,399
have like a repository of URLs that are

286
00:11:35,399 --> 00:11:37,860
labeled to be malicious of benign and if

287
00:11:37,860 --> 00:11:39,120
there is an embedded command line

288
00:11:39,120 --> 00:11:41,880
embedded URL within a command line then

289
00:11:41,880 --> 00:11:45,660
we can look up that embedded URL and see

290
00:11:45,660 --> 00:11:48,060
if it's something malicious so like if a

291
00:11:48,060 --> 00:11:49,560
command line is operating on a malicious

292
00:11:49,560 --> 00:11:51,060
URL it's more likely that it's going to

293
00:11:51,060 --> 00:11:53,170
be malicious

294
00:11:53,170 --> 00:11:54,420
[Music]

295
00:11:54,420 --> 00:11:57,720
and then uh the Final Approach uh which

296
00:11:57,720 --> 00:11:59,639
is like manual review and labeling

297
00:11:59,639 --> 00:12:04,700
through uh incident investigation data

298
00:12:04,860 --> 00:12:07,200
um so here we have our and let's go

299
00:12:07,200 --> 00:12:08,880
through instant investigation reports

300
00:12:08,880 --> 00:12:11,339
and manually review whether the case was

301
00:12:11,339 --> 00:12:13,260
actionable whether there are associated

302
00:12:13,260 --> 00:12:15,720
Global command lines in the incident and

303
00:12:15,720 --> 00:12:17,220
then they create rules using regular

304
00:12:17,220 --> 00:12:19,079
Expressions to capture future

305
00:12:19,079 --> 00:12:21,660
occurrences of such commands and these

306
00:12:21,660 --> 00:12:24,000
rules are categorized into four

307
00:12:24,000 --> 00:12:25,620
different types

308
00:12:25,620 --> 00:12:29,339
so there are strong malicious rules a

309
00:12:29,339 --> 00:12:31,440
malicious rule is given to like a known

310
00:12:31,440 --> 00:12:34,139
malicious command line uh or a known

311
00:12:34,139 --> 00:12:36,720
attack and is given only in cases of

312
00:12:36,720 --> 00:12:38,279
really high confidence right you can

313
00:12:38,279 --> 00:12:41,399
treat this as basically a block list

314
00:12:41,399 --> 00:12:43,500
um an example is when yeah we have a

315
00:12:43,500 --> 00:12:46,019
known attack pattern uh like a partial

316
00:12:46,019 --> 00:12:48,839
command is performing an unsecured

317
00:12:48,839 --> 00:12:51,540
download through a very specific Port so

318
00:12:51,540 --> 00:12:53,579
that's a good way to like identify that

319
00:12:53,579 --> 00:12:55,380
something that we've already seen before

320
00:12:55,380 --> 00:12:58,760
is happening on a user system

321
00:13:01,079 --> 00:13:04,200
and then there are suspicious uh rules

322
00:13:04,200 --> 00:13:06,540
uh so if command line activity is seen

323
00:13:06,540 --> 00:13:09,120
as potentially malicious but we don't

324
00:13:09,120 --> 00:13:10,740
have high enough confidence to

325
00:13:10,740 --> 00:13:12,779
completely convict it

326
00:13:12,779 --> 00:13:14,639
um then it receives a suspicious label

327
00:13:14,639 --> 00:13:16,680
it's an example like listing credentials

328
00:13:16,680 --> 00:13:19,019
which is suspicious Behavior but could

329
00:13:19,019 --> 00:13:20,519
also be legitimate in a different

330
00:13:20,519 --> 00:13:22,380
context such as Vanessa's admin is

331
00:13:22,380 --> 00:13:24,660
trying to like look at credentials or

332
00:13:24,660 --> 00:13:25,920
something

333
00:13:25,920 --> 00:13:28,620
then we have uh the other side of the

334
00:13:28,620 --> 00:13:31,320
coin where we have uh weak benign labels

335
00:13:31,320 --> 00:13:33,899
or debatable labels uh potentially

336
00:13:33,899 --> 00:13:35,820
benign activity is given this week the

337
00:13:35,820 --> 00:13:38,399
nine label and we think this activity is

338
00:13:38,399 --> 00:13:41,579
more likely to be benign but a machine

339
00:13:41,579 --> 00:13:43,560
Learning System could potentially appear

340
00:13:43,560 --> 00:13:44,880
on it because it's doing something

341
00:13:44,880 --> 00:13:47,639
strange like you know it has a big

342
00:13:47,639 --> 00:13:50,459
basics for encoded Chunk in it uh that

343
00:13:50,459 --> 00:13:52,260
could that a model could see as

344
00:13:52,260 --> 00:13:53,760
potentially malicious

345
00:13:53,760 --> 00:13:56,760
and then we have a strong benign labels

346
00:13:56,760 --> 00:13:58,680
which is basically known benign activity

347
00:13:58,680 --> 00:14:00,839
and

348
00:14:00,839 --> 00:14:03,660
for our machine learning experiments we

349
00:14:03,660 --> 00:14:05,100
basically take the first and last

350
00:14:05,100 --> 00:14:08,160
category of rules uh the block list and

351
00:14:08,160 --> 00:14:10,980
allow list and augment our labels

352
00:14:10,980 --> 00:14:13,260
um using these rules

353
00:14:13,260 --> 00:14:15,360
um and the suspicious and debatable

354
00:14:15,360 --> 00:14:17,100
rules are used in a different way which

355
00:14:17,100 --> 00:14:20,459
I will get to in a different section

356
00:14:20,459 --> 00:14:22,980
so in a nutshell uh here's the entire

357
00:14:22,980 --> 00:14:24,899
labeling strategy there are two label

358
00:14:24,899 --> 00:14:27,480
sources that are indirect labels that

359
00:14:27,480 --> 00:14:28,800
are obtained by cross referencing

360
00:14:28,800 --> 00:14:30,440
command lines

361
00:14:30,440 --> 00:14:32,820
and then there are command lines that

362
00:14:32,820 --> 00:14:35,339
are found in malicious based on incident

363
00:14:35,339 --> 00:14:37,320
investigation reports

364
00:14:37,320 --> 00:14:39,480
um and then there are human analysts who

365
00:14:39,480 --> 00:14:41,040
are looking at both these data sources

366
00:14:41,040 --> 00:14:44,279
and creating rules uh which are also

367
00:14:44,279 --> 00:14:47,100
then used uh to augment the the labels

368
00:14:47,100 --> 00:14:48,420
that we have

369
00:14:48,420 --> 00:14:50,639
um at the end of this um labeling

370
00:14:50,639 --> 00:14:54,300
strategy we end up with a labeled data

371
00:14:54,300 --> 00:14:57,540
set which we can finally use to

372
00:14:57,540 --> 00:14:59,100
experiment with different machine

373
00:14:59,100 --> 00:15:01,940
learning models

374
00:15:03,360 --> 00:15:07,079
so here are some data statistics for the

375
00:15:07,079 --> 00:15:09,480
data sets we used to train our machine

376
00:15:09,480 --> 00:15:13,500
learning model we have about 76 million

377
00:15:13,500 --> 00:15:17,100
uh samples in our training set out of

378
00:15:17,100 --> 00:15:20,060
which about 1.6 million are malicious

379
00:15:20,060 --> 00:15:22,980
7 million samples in the validation set

380
00:15:22,980 --> 00:15:25,199
or with 70 000 are malicious and then

381
00:15:25,199 --> 00:15:27,500
about 12 million samples in our test set

382
00:15:27,500 --> 00:15:30,660
so importantly here we use time

383
00:15:30,660 --> 00:15:33,120
splitting and I think my colleague Ben

384
00:15:33,120 --> 00:15:35,459
talked about this too in his talk about

385
00:15:35,459 --> 00:15:37,320
how it's really important time split

386
00:15:37,320 --> 00:15:39,959
where you're essentially simulating uh

387
00:15:39,959 --> 00:15:43,560
new data so your model has seen for

388
00:15:43,560 --> 00:15:45,300
example in this case the model has seen

389
00:15:45,300 --> 00:15:48,060
data until first April 2022 in the

390
00:15:48,060 --> 00:15:49,980
training set so when you're trying to

391
00:15:49,980 --> 00:15:51,959
validate the model when you're trying to

392
00:15:51,959 --> 00:15:54,120
test its performance you're not giving

393
00:15:54,120 --> 00:15:56,040
it any command lines that it has already

394
00:15:56,040 --> 00:16:00,540
seen so it the validation set is created

395
00:16:00,540 --> 00:16:01,980
in such a way that there is no

396
00:16:01,980 --> 00:16:04,920
overlapping commands uh and it com it

397
00:16:04,920 --> 00:16:06,899
contains only the command lines that are

398
00:16:06,899 --> 00:16:09,540
seen after first April 2022 in our

399
00:16:09,540 --> 00:16:11,639
systems uh is the same with the test set

400
00:16:11,639 --> 00:16:14,639
where uh we collect data from the first

401
00:16:14,639 --> 00:16:20,060
May of 2022 to the first July of 2022.

402
00:16:24,060 --> 00:16:26,759
um and then we first train a baseline

403
00:16:26,759 --> 00:16:27,660
model

404
00:16:27,660 --> 00:16:30,779
on this data we use Baseline models as a

405
00:16:30,779 --> 00:16:33,600
simple Benchmark before uh training on

406
00:16:33,600 --> 00:16:37,139
more complicated models so that we keep

407
00:16:37,139 --> 00:16:39,720
track of how well the actual models are

408
00:16:39,720 --> 00:16:42,180
doing and that they're not uh performing

409
00:16:42,180 --> 00:16:43,860
worse than the simplest possible model

410
00:16:43,860 --> 00:16:45,720
that we could use

411
00:16:45,720 --> 00:16:48,420
um so for this Baseline model we

412
00:16:48,420 --> 00:16:50,040
pre-process the command lines remove

413
00:16:50,040 --> 00:16:53,639
white space uh decode any basics for

414
00:16:53,639 --> 00:16:56,160
encoded chunks and then develop a

415
00:16:56,160 --> 00:16:58,440
feature representation

416
00:16:58,440 --> 00:17:01,100
foreign

417
00:17:01,339 --> 00:17:05,459
consists of like three different parts

418
00:17:05,459 --> 00:17:08,459
um we we generate summary statistics uh

419
00:17:08,459 --> 00:17:10,439
for the number of transitions between

420
00:17:10,439 --> 00:17:12,660
six different character classes we have

421
00:17:12,660 --> 00:17:15,299
digits white space uppercase vowels

422
00:17:15,299 --> 00:17:18,000
lowercase vowels uppercase consonants

423
00:17:18,000 --> 00:17:19,919
and lowercase consonants and we count

424
00:17:19,919 --> 00:17:21,839
the number of times in a command line we

425
00:17:21,839 --> 00:17:23,640
have transitions between those character

426
00:17:23,640 --> 00:17:25,980
classes so

427
00:17:25,980 --> 00:17:28,740
we basically get a six by six grid of

428
00:17:28,740 --> 00:17:30,960
counts which we then flatten into 36

429
00:17:30,960 --> 00:17:33,900
different features we also count the

430
00:17:33,900 --> 00:17:35,940
number of occurrences of special tokens

431
00:17:35,940 --> 00:17:39,780
like a Powershell invoke expression or a

432
00:17:39,780 --> 00:17:42,240
dollar sign that could indicate like the

433
00:17:42,240 --> 00:17:44,340
that you're trying to use a variable

434
00:17:44,340 --> 00:17:46,799
inside a command line

435
00:17:46,799 --> 00:17:49,080
um and then the final kind of features

436
00:17:49,080 --> 00:17:51,000
is like the number of special symbols

437
00:17:51,000 --> 00:17:54,299
that are used uh in the which in the

438
00:17:54,299 --> 00:17:56,640
command line like opening and closing

439
00:17:56,640 --> 00:17:59,580
braces but there are any URLs used and

440
00:17:59,580 --> 00:18:02,039
also uh we ultimately use the length of

441
00:18:02,039 --> 00:18:03,840
the command line

442
00:18:03,840 --> 00:18:06,299
and uh for the machine learning model we

443
00:18:06,299 --> 00:18:08,700
use a simple XC boost model for our

444
00:18:08,700 --> 00:18:10,980
experiments

445
00:18:10,980 --> 00:18:13,080
so that was the Baseline model and then

446
00:18:13,080 --> 00:18:15,179
we also conduct our experiments against

447
00:18:15,179 --> 00:18:18,780
two convolutional neural networks in

448
00:18:18,780 --> 00:18:20,760
order to provide the command line as an

449
00:18:20,760 --> 00:18:22,860
input to these models though we need a

450
00:18:22,860 --> 00:18:25,100
different kind of feature representation

451
00:18:25,100 --> 00:18:27,360
we first need to convert these

452
00:18:27,360 --> 00:18:31,380
characters into integers as a way that

453
00:18:31,380 --> 00:18:34,380
the model can consume it so on the slide

454
00:18:34,380 --> 00:18:37,380
I have a simple example of how we do

455
00:18:37,380 --> 00:18:41,580
this with just uh uppercase alphabets so

456
00:18:41,580 --> 00:18:45,120
if I created if I created an integer

457
00:18:45,120 --> 00:18:47,520
representation for

458
00:18:47,520 --> 00:18:48,179
um

459
00:18:48,179 --> 00:18:50,940
alphabets A to Z where I give them like

460
00:18:50,940 --> 00:18:54,059
numbers starting from 1 to 26 uh then if

461
00:18:54,059 --> 00:18:56,160
I have a string called string that says

462
00:18:56,160 --> 00:18:58,380
b side to Las Vegas I can replace all

463
00:18:58,380 --> 00:18:59,580
the characters with the associated

464
00:18:59,580 --> 00:19:01,799
integers replace white space with zero

465
00:19:01,799 --> 00:19:04,020
and then I have a list of numbers that

466
00:19:04,020 --> 00:19:06,360
represent that string

467
00:19:06,360 --> 00:19:09,600
um the only difference between uh the

468
00:19:09,600 --> 00:19:10,919
feature representation that we develop

469
00:19:10,919 --> 00:19:15,480
and the example here is that the size of

470
00:19:15,480 --> 00:19:16,980
the vocabulary or the number of

471
00:19:16,980 --> 00:19:18,720
characters we consider is a lot higher

472
00:19:18,720 --> 00:19:20,820
uh and for the command lines we

473
00:19:20,820 --> 00:19:24,600
basically consider all all printable

474
00:19:24,600 --> 00:19:26,959
characters

475
00:19:28,200 --> 00:19:31,020
and um these are the two neural network

476
00:19:31,020 --> 00:19:32,940
models the convolutional neural network

477
00:19:32,940 --> 00:19:36,480
models that we experiment against the

478
00:19:36,480 --> 00:19:38,100
one on the left is a simpler

479
00:19:38,100 --> 00:19:40,320
architecture with a single conversion

480
00:19:40,320 --> 00:19:44,820
layer and a small dense layer and the

481
00:19:44,820 --> 00:19:46,220
one on the right

482
00:19:46,220 --> 00:19:48,840
is actually a neural network

483
00:19:48,840 --> 00:19:51,720
architecture that we have used in the

484
00:19:51,720 --> 00:19:54,480
past to detect many different string

485
00:19:54,480 --> 00:19:59,900
artifacts like URLs or file paths or

486
00:19:59,940 --> 00:20:00,600
um

487
00:20:00,600 --> 00:20:03,659
yeah registry keys any any string

488
00:20:03,659 --> 00:20:05,640
artifact basically

489
00:20:05,640 --> 00:20:09,179
um so you can read about this this uh

490
00:20:09,179 --> 00:20:12,179
model architecture on our site uh where

491
00:20:12,179 --> 00:20:14,280
one of our data scientists sarnath has

492
00:20:14,280 --> 00:20:16,620
written a great explainer blog post uh

493
00:20:16,620 --> 00:20:18,240
so I won't go into details of the

494
00:20:18,240 --> 00:20:20,159
network architecture here in the

495
00:20:20,159 --> 00:20:22,880
interest of time

496
00:20:22,980 --> 00:20:24,720
so

497
00:20:24,720 --> 00:20:26,940
um these are the model results that we

498
00:20:26,940 --> 00:20:29,340
got for the three different models these

499
00:20:29,340 --> 00:20:30,780
are the best results that we've obtained

500
00:20:30,780 --> 00:20:34,320
after hyper parameter optimization

501
00:20:34,320 --> 00:20:36,179
um if you're unfamiliar with this plot

502
00:20:36,179 --> 00:20:38,539
let me take a quick aside to explain

503
00:20:38,539 --> 00:20:40,700
it's called the receiver operating

504
00:20:40,700 --> 00:20:44,039
characteristic curve or the rock curve

505
00:20:44,039 --> 00:20:47,100
for short it basically plots the true

506
00:20:47,100 --> 00:20:50,640
positive rate on the y-axis against the

507
00:20:50,640 --> 00:20:53,100
false positive rate on the x-axis for

508
00:20:53,100 --> 00:20:56,039
different thresholds of model score

509
00:20:56,039 --> 00:20:57,900
um let me break that break that down a

510
00:20:57,900 --> 00:21:00,000
little bit so the true positive rate is

511
00:21:00,000 --> 00:21:01,320
the number of correct malicious

512
00:21:01,320 --> 00:21:04,320
predictions of a model against the total

513
00:21:04,320 --> 00:21:06,000
number of true malicious commands in the

514
00:21:06,000 --> 00:21:08,340
data the false positive rate is the

515
00:21:08,340 --> 00:21:10,799
number of false positives as a fraction

516
00:21:10,799 --> 00:21:13,200
of the total number of benign samples in

517
00:21:13,200 --> 00:21:15,000
the data

518
00:21:15,000 --> 00:21:17,400
so the machine learning models that we

519
00:21:17,400 --> 00:21:19,500
train here basically output a score

520
00:21:19,500 --> 00:21:22,380
between 0 and 1 with a higher score

521
00:21:22,380 --> 00:21:24,299
denoting a greater chance of a command

522
00:21:24,299 --> 00:21:26,039
line to be malicious so when I talk

523
00:21:26,039 --> 00:21:28,200
about deciding what threshold to use

524
00:21:28,200 --> 00:21:30,200
that's the value that I'm talking about

525
00:21:30,200 --> 00:21:34,260
where if I decide that anything above

526
00:21:34,260 --> 00:21:36,179
0.5 is what I'm going to consider as

527
00:21:36,179 --> 00:21:37,679
malicious then I'm gonna get a different

528
00:21:37,679 --> 00:21:40,740
subset of malicious commands detected by

529
00:21:40,740 --> 00:21:43,740
the model as opposed to if I used 0.6 so

530
00:21:43,740 --> 00:21:46,500
that's my threshold

531
00:21:46,500 --> 00:21:50,220
so why do false positives happen and why

532
00:21:50,220 --> 00:21:51,900
do the true positive and false positive

533
00:21:51,900 --> 00:21:53,820
rates change based on the thresholds

534
00:21:53,820 --> 00:21:55,980
that we use for a model

535
00:21:55,980 --> 00:21:57,299
um when we train a machine learning

536
00:21:57,299 --> 00:22:00,360
model what it is doing is learning an

537
00:22:00,360 --> 00:22:03,059
association between the inputs and the

538
00:22:03,059 --> 00:22:05,940
outputs as we saw in the case of command

539
00:22:05,940 --> 00:22:08,220
lines a machine learning models can

540
00:22:08,220 --> 00:22:12,179
consume numeric uh inputs so we need to

541
00:22:12,179 --> 00:22:14,460
create numeric representations for the

542
00:22:14,460 --> 00:22:16,679
artifacts that we want the model to

543
00:22:16,679 --> 00:22:18,539
predict on so we can't just like Supply

544
00:22:18,539 --> 00:22:20,100
it with a command line we need to create

545
00:22:20,100 --> 00:22:23,400
a representation for that command line

546
00:22:23,400 --> 00:22:24,620
um

547
00:22:24,620 --> 00:22:28,200
and in an ideal case uh just like on the

548
00:22:28,200 --> 00:22:30,299
left the representation that we chose

549
00:22:30,299 --> 00:22:34,679
for our data uh might make it easy for

550
00:22:34,679 --> 00:22:36,360
the model to separate out the good from

551
00:22:36,360 --> 00:22:39,120
the bad like instead of uh coming up

552
00:22:39,120 --> 00:22:41,520
with like 50 numbers if you came up with

553
00:22:41,520 --> 00:22:43,799
two numbers that represented your data

554
00:22:43,799 --> 00:22:45,960
and plotted it on a scatter plot like

555
00:22:45,960 --> 00:22:48,360
that uh then if you chose your two

556
00:22:48,360 --> 00:22:51,360
numbers correctly ideally you sh you

557
00:22:51,360 --> 00:22:54,419
should be able to like separate out your

558
00:22:54,419 --> 00:22:56,520
good from your bad samples but

559
00:22:56,520 --> 00:22:58,380
unfortunately this is only an ideal case

560
00:22:58,380 --> 00:23:01,080
and in a real case uh the nature of the

561
00:23:01,080 --> 00:23:03,240
data itself often does not let you do

562
00:23:03,240 --> 00:23:06,059
this uh so the real case is much closer

563
00:23:06,059 --> 00:23:08,460
to something on the right uh which is

564
00:23:08,460 --> 00:23:10,500
why if you change your threshold and if

565
00:23:10,500 --> 00:23:12,059
you change the location where you draw

566
00:23:12,059 --> 00:23:13,799
the line you get a different false

567
00:23:13,799 --> 00:23:15,299
positive rate and you get a different

568
00:23:15,299 --> 00:23:18,240
true positive rate like you and you're

569
00:23:18,240 --> 00:23:20,220
basically uh the problem that the

570
00:23:20,220 --> 00:23:21,539
optimization problem that you're trying

571
00:23:21,539 --> 00:23:25,500
to solve here is whether you are going

572
00:23:25,500 --> 00:23:27,299
to bias towards creating more false

573
00:23:27,299 --> 00:23:30,059
positives or false negatives and like I

574
00:23:30,059 --> 00:23:32,640
mentioned in our uh

575
00:23:32,640 --> 00:23:35,640
in the cold section before uh we

576
00:23:35,640 --> 00:23:37,380
definitely do not want to create a lot

577
00:23:37,380 --> 00:23:40,679
of false positives and uh even if it is

578
00:23:40,679 --> 00:23:44,220
at the cost of a few false negatives we

579
00:23:44,220 --> 00:23:46,200
want the system to be more usable and

580
00:23:46,200 --> 00:23:47,940
creating a lot of false positives this

581
00:23:47,940 --> 00:23:51,240
makes the whole system useless

582
00:23:51,240 --> 00:23:54,179
so that was a lot of information so I'm

583
00:23:54,179 --> 00:23:56,659
just gonna pause here for a few seconds

584
00:23:56,659 --> 00:24:00,600
uh this is my dog his name is Hobbs I

585
00:24:00,600 --> 00:24:04,559
named him after my favorite character my

586
00:24:04,559 --> 00:24:07,740
favorite comic book Calvin and Hobbes

587
00:24:07,740 --> 00:24:10,320
um when I got him he

588
00:24:10,320 --> 00:24:12,659
was supposed to be five years old and a

589
00:24:12,659 --> 00:24:16,440
lab puppy uh but turns out the rescue

590
00:24:16,440 --> 00:24:18,419
made a mistake and he's actually a lab

591
00:24:18,419 --> 00:24:20,880
beagle mix so he's actually an adult and

592
00:24:20,880 --> 00:24:23,220
looks like a lab puppy now that's a

593
00:24:23,220 --> 00:24:26,419
false positive I don't mind

594
00:24:29,580 --> 00:24:32,000
people

595
00:24:33,840 --> 00:24:35,279
okay

596
00:24:35,279 --> 00:24:37,080
um so we described the machine learning

597
00:24:37,080 --> 00:24:38,580
model that we trained we described the

598
00:24:38,580 --> 00:24:40,799
results that we got

599
00:24:40,799 --> 00:24:43,500
um a simple question is this Deployable

600
00:24:43,500 --> 00:24:46,020
so what we did was we looked at the

601
00:24:46,020 --> 00:24:49,020
output of this model when we plugged it

602
00:24:49,020 --> 00:24:51,840
into a one percent sample of our one and

603
00:24:51,840 --> 00:24:54,419
a half billion command line event stream

604
00:24:54,419 --> 00:24:56,760
and this is what happened this plot

605
00:24:56,760 --> 00:24:58,140
basically tells us the number of

606
00:24:58,140 --> 00:25:00,059
detections by the machine learning model

607
00:25:00,059 --> 00:25:02,760
on a daily basis for like the past three

608
00:25:02,760 --> 00:25:04,799
weeks you can see that it's creating

609
00:25:04,799 --> 00:25:07,620
hundreds of alerts which practically

610
00:25:07,620 --> 00:25:10,260
makes it unusable because

611
00:25:10,260 --> 00:25:12,000
it's very unlikely that there are

612
00:25:12,000 --> 00:25:13,860
actually hundreds of living off the land

613
00:25:13,860 --> 00:25:16,980
binary attacks happening so

614
00:25:16,980 --> 00:25:19,799
we had a model with a reasonably good

615
00:25:19,799 --> 00:25:21,600
accuracy

616
00:25:21,600 --> 00:25:24,419
um that is doing really poorly why is

617
00:25:24,419 --> 00:25:27,059
this happening this doesn't seem like

618
00:25:27,059 --> 00:25:30,240
expected Behavior right

619
00:25:30,240 --> 00:25:33,179
um well this is known as the false

620
00:25:33,179 --> 00:25:35,340
positive Paradox or the base rate

621
00:25:35,340 --> 00:25:37,919
fallacy and this is commonly seen in a

622
00:25:37,919 --> 00:25:39,240
lot of uh

623
00:25:39,240 --> 00:25:41,100
machine learning applications especially

624
00:25:41,100 --> 00:25:44,340
in security let's say that we have uh

625
00:25:44,340 --> 00:25:46,020
let's understand this with an example

626
00:25:46,020 --> 00:25:47,940
let's say that we have a near perfect ml

627
00:25:47,940 --> 00:25:50,100
model even better than the ml models

628
00:25:50,100 --> 00:25:51,600
that I've trained so far like I could

629
00:25:51,600 --> 00:25:53,279
read I could conduct research for

630
00:25:53,279 --> 00:25:55,320
another like five years and get the best

631
00:25:55,320 --> 00:25:58,080
possible model out there and

632
00:25:58,080 --> 00:26:00,900
let's say it has a true positive rate of

633
00:26:00,900 --> 00:26:03,480
100 which means that if it ever sees a

634
00:26:03,480 --> 00:26:05,159
malicious command it's always going to

635
00:26:05,159 --> 00:26:07,980
detect it as malicious and the only

636
00:26:07,980 --> 00:26:10,380
downside is that out of every 10 000

637
00:26:10,380 --> 00:26:12,419
command lines that it sees it's going to

638
00:26:12,419 --> 00:26:15,600
say that one of them uh 10 000 benign

639
00:26:15,600 --> 00:26:17,400
command lines it sees it's going to say

640
00:26:17,400 --> 00:26:20,640
that one of them is actually uh positive

641
00:26:20,640 --> 00:26:23,340
so it's gonna make one false positive

642
00:26:23,340 --> 00:26:25,919
out of every 10 000 samples this is a

643
00:26:25,919 --> 00:26:28,860
really good model right uh but somehow

644
00:26:28,860 --> 00:26:31,740
if you actually compute the math uh when

645
00:26:31,740 --> 00:26:33,900
plugging into our event stream it turns

646
00:26:33,900 --> 00:26:37,500
out that this model creates uh so if we

647
00:26:37,500 --> 00:26:39,179
plug into an event stream and assume

648
00:26:39,179 --> 00:26:40,740
that there are 150 malicious command

649
00:26:40,740 --> 00:26:43,320
lines a day and one and a half billion

650
00:26:43,320 --> 00:26:45,179
benign command lines a day which is

651
00:26:45,179 --> 00:26:48,179
probably close to the real number uh and

652
00:26:48,179 --> 00:26:50,700
it generates 150 true positives it has a

653
00:26:50,700 --> 00:26:52,140
hundred percent true positive rate so

654
00:26:52,140 --> 00:26:53,940
it's going to detect every one of those

655
00:26:53,940 --> 00:26:56,159
malicious commands but what happens to

656
00:26:56,159 --> 00:26:58,500
the false positives since we have one a

657
00:26:58,500 --> 00:27:00,840
half billion benign commands even a

658
00:27:00,840 --> 00:27:03,960
model that can create only one false

659
00:27:03,960 --> 00:27:06,360
positive for every 10 000 samples it

660
00:27:06,360 --> 00:27:07,679
still creates a hundred and fifty

661
00:27:07,679 --> 00:27:09,779
thousand false positives and at that

662
00:27:09,779 --> 00:27:12,059
point like the machine learning model is

663
00:27:12,059 --> 00:27:13,860
really not helping the stock analyst and

664
00:27:13,860 --> 00:27:15,659
the stock analyst is just going to drown

665
00:27:15,659 --> 00:27:17,820
in alerts and if you do the math that is

666
00:27:17,820 --> 00:27:19,440
one

667
00:27:19,440 --> 00:27:22,620
true positive per like 1001 false

668
00:27:22,620 --> 00:27:24,600
positives which is a terrible model

669
00:27:24,600 --> 00:27:26,700
accuracy number

670
00:27:26,700 --> 00:27:29,640
um so why does this actually happen uh

671
00:27:29,640 --> 00:27:30,779
if you notice if you look at the

672
00:27:30,779 --> 00:27:32,340
distribution of malicious versus benign

673
00:27:32,340 --> 00:27:34,740
that is the main culprit here we have

674
00:27:34,740 --> 00:27:37,080
very few malicious commands or a very

675
00:27:37,080 --> 00:27:39,960
low base rate of malicious commands uh

676
00:27:39,960 --> 00:27:41,100
compared to the number of benign

677
00:27:41,100 --> 00:27:43,559
commands so hypothetically if you had a

678
00:27:43,559 --> 00:27:46,320
50 50 distribution if you had 750

679
00:27:46,320 --> 00:27:48,779
million malicious commands and 750

680
00:27:48,779 --> 00:27:51,720
million benign commands and you ran them

681
00:27:51,720 --> 00:27:54,059
through the same model that model would

682
00:27:54,059 --> 00:27:57,000
produce 750 million malicious detections

683
00:27:57,000 --> 00:28:00,120
for 75 000 benign detections which is

684
00:28:00,120 --> 00:28:03,000
which is really great it's like 10 000

685
00:28:03,000 --> 00:28:07,020
true positives for every false positive

686
00:28:07,020 --> 00:28:09,120
um so yeah this this is uh the main

687
00:28:09,120 --> 00:28:12,000
problem that we face when trying to

688
00:28:12,000 --> 00:28:14,700
apply machine learning to this uh to

689
00:28:14,700 --> 00:28:16,320
this use case

690
00:28:16,320 --> 00:28:18,419
so how do we work around this problem

691
00:28:18,419 --> 00:28:20,220
what is the solution is the system

692
00:28:20,220 --> 00:28:21,960
completely useless have we failed our

693
00:28:21,960 --> 00:28:24,360
goals well not quite uh there are

694
00:28:24,360 --> 00:28:26,039
options as Josh and others have

695
00:28:26,039 --> 00:28:28,380
mentioned before in their talks uh

696
00:28:28,380 --> 00:28:30,059
deploying ml is a standalone system

697
00:28:30,059 --> 00:28:31,799
almost never works especially in

698
00:28:31,799 --> 00:28:34,919
security and because we always have this

699
00:28:34,919 --> 00:28:37,380
kind of skewed data distribution

700
00:28:37,380 --> 00:28:39,600
um so what we need are guard rails we

701
00:28:39,600 --> 00:28:41,100
need to control when the machine

702
00:28:41,100 --> 00:28:42,779
learning model actually comes into play

703
00:28:42,779 --> 00:28:45,000
so that it can contribute where it

704
00:28:45,000 --> 00:28:47,580
performs best so we don't apply to every

705
00:28:47,580 --> 00:28:49,679
single command line that we see we apply

706
00:28:49,679 --> 00:28:51,480
it selectively

707
00:28:51,480 --> 00:28:54,539
what guardrails should we use uh earlier

708
00:28:54,539 --> 00:28:56,399
we talked about using analyst defined

709
00:28:56,399 --> 00:28:58,919
regex rules to augment our labeling and

710
00:28:58,919 --> 00:29:00,840
I alluded to this that we also have

711
00:29:00,840 --> 00:29:02,880
suspicious and debatable labels that we

712
00:29:02,880 --> 00:29:07,919
use uh which is exactly what we use for

713
00:29:07,919 --> 00:29:10,620
gut records in this case

714
00:29:10,620 --> 00:29:14,220
um so just to detail the system a little

715
00:29:14,220 --> 00:29:15,539
bit here

716
00:29:15,539 --> 00:29:18,299
um if we have

717
00:29:18,299 --> 00:29:20,220
no rules matching

718
00:29:20,220 --> 00:29:22,740
for a given command line then it doesn't

719
00:29:22,740 --> 00:29:24,779
matter what the MS code is we are just

720
00:29:24,779 --> 00:29:26,940
not going to create an alert here are

721
00:29:26,940 --> 00:29:28,799
some examples where the machine learning

722
00:29:28,799 --> 00:29:30,799
model thinks that something is malicious

723
00:29:30,799 --> 00:29:33,480
but there are no regex matches so we're

724
00:29:33,480 --> 00:29:36,179
not going to alert and if as you can see

725
00:29:36,179 --> 00:29:38,460
it seems like these are not actual

726
00:29:38,460 --> 00:29:41,220
malicious commands but we also notice

727
00:29:41,220 --> 00:29:42,840
that our machine learning model has a

728
00:29:42,840 --> 00:29:45,480
bias towards detecting smaller commands

729
00:29:45,480 --> 00:29:47,580
as malicious because it has very little

730
00:29:47,580 --> 00:29:49,200
information so it's behaving in an

731
00:29:49,200 --> 00:29:51,360
unstable way

732
00:29:51,360 --> 00:29:54,480
and then if any of our strong Rules

733
00:29:54,480 --> 00:29:56,460
matches uh any of our high confidence

734
00:29:56,460 --> 00:29:58,799
roles matches then we don't feel the

735
00:29:58,799 --> 00:30:00,320
need to go to the machine learning model

736
00:30:00,320 --> 00:30:02,460
uh to tell us whether something is

737
00:30:02,460 --> 00:30:04,799
malicious or benign we just directly

738
00:30:04,799 --> 00:30:07,200
take the output of the rule and we

739
00:30:07,200 --> 00:30:09,659
decide whether to surface an alert or

740
00:30:09,659 --> 00:30:10,559
not

741
00:30:10,559 --> 00:30:13,200
but the real contribution of the machine

742
00:30:13,200 --> 00:30:16,799
learning model comes when there is a

743
00:30:16,799 --> 00:30:19,140
suspicious rule that is triggered so if

744
00:30:19,140 --> 00:30:22,500
you remember a suspicious rule is when

745
00:30:22,500 --> 00:30:24,299
there is potentially malicious activity

746
00:30:24,299 --> 00:30:26,399
but we are not entirely sure because in

747
00:30:26,399 --> 00:30:28,020
some contexts it could be used in number

748
00:30:28,020 --> 00:30:31,260
nine way so here we use the model to say

749
00:30:31,260 --> 00:30:34,919
that if the model scores highly on uh

750
00:30:34,919 --> 00:30:37,140
command line that triggers a suspicious

751
00:30:37,140 --> 00:30:39,659
rule then we generate an alert and if

752
00:30:39,659 --> 00:30:41,940
not then we don't generate an alert we

753
00:30:41,940 --> 00:30:44,100
actually create uh something called a

754
00:30:44,100 --> 00:30:46,260
silent detection where we want to review

755
00:30:46,260 --> 00:30:48,059
it later

756
00:30:48,059 --> 00:30:51,240
um and so uh keyboard surface and alert

757
00:30:51,240 --> 00:30:53,760
but we'll store it in our Telemetry uh

758
00:30:53,760 --> 00:30:55,260
for further review

759
00:30:55,260 --> 00:30:59,940
and then we have a debatable rules

760
00:30:59,940 --> 00:31:01,799
um and again we do something similar

761
00:31:01,799 --> 00:31:04,620
where if there is a debatable rule that

762
00:31:04,620 --> 00:31:07,500
is triggered then we look at the ml

763
00:31:07,500 --> 00:31:09,720
verdict uh if the ml if the machine

764
00:31:09,720 --> 00:31:11,580
learning model says that a debutable

765
00:31:11,580 --> 00:31:13,559
rule is

766
00:31:13,559 --> 00:31:16,200
um sorry is is a command line that

767
00:31:16,200 --> 00:31:18,480
triggers a debatable rule is malicious

768
00:31:18,480 --> 00:31:20,760
then we create a silent detection and

769
00:31:20,760 --> 00:31:22,980
wait for further review uh but if the

770
00:31:22,980 --> 00:31:24,240
machine learning model says that

771
00:31:24,240 --> 00:31:26,279
something is benign and it triggers a

772
00:31:26,279 --> 00:31:28,559
debatable role then we don't surface an

773
00:31:28,559 --> 00:31:30,799
alert

774
00:31:31,919 --> 00:31:34,679
so there was a lot of information and I

775
00:31:34,679 --> 00:31:36,960
want to put it all together and

776
00:31:36,960 --> 00:31:39,539
um provide sort of high level context uh

777
00:31:39,539 --> 00:31:41,299
just to reiterate just so you understand

778
00:31:41,299 --> 00:31:45,240
all the pieces that go into the system

779
00:31:45,240 --> 00:31:47,340
um so during machine learning training

780
00:31:47,340 --> 00:31:50,460
we collect data from the event stream uh

781
00:31:50,460 --> 00:31:53,039
we clean and Sample it and then Source

782
00:31:53,039 --> 00:31:55,559
labels from three different locations we

783
00:31:55,559 --> 00:31:58,500
have indirect labels we have pass data

784
00:31:58,500 --> 00:32:00,659
and then we have allow list and block

785
00:32:00,659 --> 00:32:04,440
list rules that analysts have created

786
00:32:04,440 --> 00:32:07,260
um using this label data set we then

787
00:32:07,260 --> 00:32:09,480
train a machine learning model

788
00:32:09,480 --> 00:32:12,120
and then when it comes to prediction we

789
00:32:12,120 --> 00:32:14,700
plug both the machine learning model and

790
00:32:14,700 --> 00:32:16,799
the analyst created rules into our

791
00:32:16,799 --> 00:32:21,419
system and we only create alerts in two

792
00:32:21,419 --> 00:32:24,600
separate scenarios one of them is if a

793
00:32:24,600 --> 00:32:26,640
block list rule is triggered and the

794
00:32:26,640 --> 00:32:28,980
other is if suspicious activity is

795
00:32:28,980 --> 00:32:31,380
detected and the Machine learning model

796
00:32:31,380 --> 00:32:33,419
also detects the same suspicious command

797
00:32:33,419 --> 00:32:35,600
line

798
00:32:37,799 --> 00:32:39,299
so

799
00:32:39,299 --> 00:32:41,340
um we started off saying that we wanted

800
00:32:41,340 --> 00:32:43,980
to surface additional alerts into the

801
00:32:43,980 --> 00:32:46,799
system while not flooding the sock uh

802
00:32:46,799 --> 00:32:48,899
did we actually meet this goal uh this

803
00:32:48,899 --> 00:32:50,760
part plot shows us the total number of

804
00:32:50,760 --> 00:32:52,760
unique alerts that we generated per day

805
00:32:52,760 --> 00:32:57,000
when the system is deployed and uh

806
00:32:57,000 --> 00:32:58,799
looks like we certainly create a

807
00:32:58,799 --> 00:33:00,779
manageable number of alerts now at least

808
00:33:00,779 --> 00:33:02,940
compared to the previous system the blue

809
00:33:02,940 --> 00:33:05,100
bars here denote the number of alerts

810
00:33:05,100 --> 00:33:07,919
that are generated by the block lists

811
00:33:07,919 --> 00:33:11,100
and the orange bars denote the number of

812
00:33:11,100 --> 00:33:13,380
command alerts that are created by

813
00:33:13,380 --> 00:33:15,360
suspicious command lines that are

814
00:33:15,360 --> 00:33:16,799
detected by the machine learning model

815
00:33:16,799 --> 00:33:19,620
so it looks like on most days the system

816
00:33:19,620 --> 00:33:24,299
does not create more than 50 alerts

817
00:33:24,299 --> 00:33:26,340
a manageable number of alerts is well

818
00:33:26,340 --> 00:33:28,620
and good but how good are the alerts

819
00:33:28,620 --> 00:33:30,240
actually

820
00:33:30,240 --> 00:33:32,220
um so it's important to create alerts

821
00:33:32,220 --> 00:33:33,720
that are very likely to be malicious

822
00:33:33,720 --> 00:33:36,840
because we want to build a stock analyst

823
00:33:36,840 --> 00:33:39,600
trust in our detector so we want it to

824
00:33:39,600 --> 00:33:40,679
be

825
00:33:40,679 --> 00:33:43,500
um as precise as possible this plot

826
00:33:43,500 --> 00:33:45,179
shows the true positive rate and the

827
00:33:45,179 --> 00:33:47,399
false positive rate for the alerts

828
00:33:47,399 --> 00:33:50,940
generated by the entire system when

829
00:33:50,940 --> 00:33:53,640
plugged into the event stream uh

830
00:33:53,640 --> 00:33:55,380
computed on a weekly basis for the past

831
00:33:55,380 --> 00:33:57,659
four weeks we see that the true positive

832
00:33:57,659 --> 00:34:00,480
rate hovers between 0.9 and 1 which is a

833
00:34:00,480 --> 00:34:03,419
pretty good rate of

834
00:34:03,419 --> 00:34:05,460
um you know detections of a pretty good

835
00:34:05,460 --> 00:34:07,620
Precision uh combine this with a

836
00:34:07,620 --> 00:34:09,540
manageable number of alerts and we think

837
00:34:09,540 --> 00:34:13,099
we have a very Deployable system

838
00:34:14,280 --> 00:34:16,320
um the second question did we actually

839
00:34:16,320 --> 00:34:18,418
add value

840
00:34:18,418 --> 00:34:20,159
um the plot here shows the number of

841
00:34:20,159 --> 00:34:22,440
alerts that were seen in the entire

842
00:34:22,440 --> 00:34:25,320
system on a weekly basis for the past

843
00:34:25,320 --> 00:34:27,899
three weeks uh the teal block basically

844
00:34:27,899 --> 00:34:29,820
shows the number of alerts that were

845
00:34:29,820 --> 00:34:32,520
created by the existing system uh The

846
00:34:32,520 --> 00:34:34,440
yellow section shows the intersection

847
00:34:34,440 --> 00:34:37,139
which is like the existing system also

848
00:34:37,139 --> 00:34:39,300
detected these attacks and our system

849
00:34:39,300 --> 00:34:41,520
also detected these attacks and the blue

850
00:34:41,520 --> 00:34:45,119
section which is the most encouraging is

851
00:34:45,119 --> 00:34:48,000
the new alerts that were surfaced by

852
00:34:48,000 --> 00:34:50,699
just our system and burnt Surface by the

853
00:34:50,699 --> 00:34:52,739
existing system

854
00:34:52,739 --> 00:34:54,599
um and although this number is small

855
00:34:54,599 --> 00:34:57,420
right now we have nowhere to go but up

856
00:34:57,420 --> 00:34:59,940
and over time we think that our system

857
00:34:59,940 --> 00:35:01,980
should improve significantly and produce

858
00:35:01,980 --> 00:35:04,920
more actionable alerts

859
00:35:04,920 --> 00:35:07,800
a big part of our system is the

860
00:35:07,800 --> 00:35:10,320
involvement of surface the surface AI

861
00:35:10,320 --> 00:35:12,540
analyst team who have created dashboards

862
00:35:12,540 --> 00:35:15,060
that consistently continuously monitor

863
00:35:15,060 --> 00:35:18,180
the performance of the system uh they

864
00:35:18,180 --> 00:35:21,240
then use this uh information to tweak

865
00:35:21,240 --> 00:35:23,400
their rules catch false positives and

866
00:35:23,400 --> 00:35:25,560
improve the guard rails as a continuous

867
00:35:25,560 --> 00:35:28,619
process and again this is uh

868
00:35:28,619 --> 00:35:31,800
in line with what Josh talked about and

869
00:35:31,800 --> 00:35:34,020
what Ben talked about it's in involving

870
00:35:34,020 --> 00:35:36,599
humans in a feedback loop in order to

871
00:35:36,599 --> 00:35:37,980
improve the continuously improved

872
00:35:37,980 --> 00:35:41,300
performance of our systems

873
00:35:41,880 --> 00:35:44,220
so a quick summary of everything that we

874
00:35:44,220 --> 00:35:45,480
talked about

875
00:35:45,480 --> 00:35:49,140
um in this talk Lil win Attack detection

876
00:35:49,140 --> 00:35:51,000
is a hard problem with several

877
00:35:51,000 --> 00:35:53,220
challenges there is a large data volume

878
00:35:53,220 --> 00:35:55,380
there is a low base rate of malicious

879
00:35:55,380 --> 00:35:58,520
activity and labels are hard to combine

880
00:35:58,520 --> 00:36:01,500
we've demonstrated some strategies that

881
00:36:01,500 --> 00:36:04,020
we've used to mitigate these problems

882
00:36:04,020 --> 00:36:07,440
and work around them

883
00:36:07,440 --> 00:36:09,480
um another important lesson that we

884
00:36:09,480 --> 00:36:11,160
learned here is that good data

885
00:36:11,160 --> 00:36:14,220
engineering really pays off dividends we

886
00:36:14,220 --> 00:36:16,500
basically went fishing through our data

887
00:36:16,500 --> 00:36:19,680
Lake and got as much data as possible uh

888
00:36:19,680 --> 00:36:22,740
in order to label our Command lines and

889
00:36:22,740 --> 00:36:24,900
increase label coverage

890
00:36:24,900 --> 00:36:27,000
um we got yeah we got representative

891
00:36:27,000 --> 00:36:30,000
data we had a good labeling strategy and

892
00:36:30,000 --> 00:36:33,540
we also created dashboards

893
00:36:33,540 --> 00:36:34,320
um

894
00:36:34,320 --> 00:36:36,300
perform transferred validation and

895
00:36:36,300 --> 00:36:38,339
Analysis to ensure continuous

896
00:36:38,339 --> 00:36:40,020
Improvement of our

897
00:36:40,020 --> 00:36:41,300
system

898
00:36:41,300 --> 00:36:43,680
another lesson that we learned here is

899
00:36:43,680 --> 00:36:45,660
that the best machine learning models

900
00:36:45,660 --> 00:36:47,520
cannot perform well as a standalone

901
00:36:47,520 --> 00:36:50,579
system they need guardrails uh and the

902
00:36:50,579 --> 00:36:52,320
way forward basically is to integrate

903
00:36:52,320 --> 00:36:54,540
rule-based detection and human analysts

904
00:36:54,540 --> 00:36:56,640
into the machine Learning System and

905
00:36:56,640 --> 00:36:58,079
create continuous Improvement and

906
00:36:58,079 --> 00:37:00,240
feedback loops

907
00:37:00,240 --> 00:37:02,280
and that's all I've got for today thank

908
00:37:02,280 --> 00:37:05,099
you any questions

909
00:37:05,099 --> 00:37:06,650
foreign

910
00:37:06,650 --> 00:37:10,989
[Applause]

911
00:37:22,640 --> 00:37:25,260
I'll be around in the room if you have

912
00:37:25,260 --> 00:37:26,640
any questions you can come up to me and

913
00:37:26,640 --> 00:37:29,118
ask me more

914
00:37:30,560 --> 00:37:33,619
thank you

