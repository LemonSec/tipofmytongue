1
00:00:00,000 --> 00:00:04,259
<font color="#E5E5E5">all right apologies</font><font color="#CCCCCC"> for the technical</font>

2
00:00:02,100 --> 00:00:06,420
<font color="#E5E5E5">difficulties my name is Heather Lawrence</font>

3
00:00:04,259 --> 00:00:09,480
I'm presenting<font color="#E5E5E5"> on adversarial example</font>

4
00:00:06,420 --> 00:00:12,900
witchcraft<font color="#CCCCCC"> or how</font><font color="#E5E5E5"> to use alchemy to turn</font>

5
00:00:09,480 --> 00:00:16,980
<font color="#E5E5E5">turtles into rifles there are a lot of</font>

6
00:00:12,900 --> 00:00:19,170
<font color="#E5E5E5">details nuances on the slide deck if you</font>

7
00:00:16,980 --> 00:00:20,160
want the resources and it's in<font color="#CCCCCC"> nine font</font>

8
00:00:19,170 --> 00:00:22,590
you're never gonna be able to<font color="#E5E5E5"> read it</font>

9
00:00:20,160 --> 00:00:25,710
please<font color="#E5E5E5"> access the slides at this link</font>

10
00:00:22,590 --> 00:00:27,269
<font color="#E5E5E5">hopefully you can read that and I will</font>

11
00:00:25,710 --> 00:00:29,099
also<font color="#E5E5E5"> have it on</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> end slide</font><font color="#CCCCCC"> too if you</font>

12
00:00:27,269 --> 00:00:40,230
need it sorry about<font color="#CCCCCC"> that</font>

13
00:00:29,099 --> 00:00:42,000
<font color="#E5E5E5">all right cool cool cool</font><font color="#CCCCCC"> alright</font><font color="#E5E5E5"> again</font><font color="#CCCCCC"> I</font>

14
00:00:40,230 --> 00:00:43,980
do data science<font color="#E5E5E5"> at the Nebraska Applied</font>

15
00:00:42,000 --> 00:00:45,660
Research Institute or out of the

16
00:00:43,980 --> 00:00:47,370
University of<font color="#E5E5E5"> Nebraska system you can</font>

17
00:00:45,660 --> 00:00:50,419
also find me on<font color="#E5E5E5"> twitter under info</font>

18
00:00:47,370 --> 00:00:58,680
<font color="#CCCCCC">second on or snark victory let's</font><font color="#E5E5E5"> also I</font>

19
00:00:50,420 --> 00:01:01,469
know<font color="#CCCCCC"> we're</font><font color="#E5E5E5"> maybe okay so I'm about to</font>

20
00:00:58,680 --> 00:01:02,489
play<font color="#E5E5E5"> a video for you this is Google's</font>

21
00:01:01,469 --> 00:01:06,200
<font color="#CCCCCC">state-of-the-art</font>

22
00:01:02,489 --> 00:01:08,548
inception<font color="#E5E5E5"> three model</font><font color="#CCCCCC"> you'll</font><font color="#E5E5E5"> notice that</font>

23
00:01:06,200 --> 00:01:11,460
it's a<font color="#E5E5E5"> turtle right you and I can</font>

24
00:01:08,549 --> 00:01:13,439
identify that<font color="#CCCCCC"> it's a turtle and the</font>

25
00:01:11,460 --> 00:01:16,229
classifier can<font color="#E5E5E5"> identify that it's a</font>

26
00:01:13,439 --> 00:01:18,539
turtle<font color="#E5E5E5"> however once you perturb the</font>

27
00:01:16,229 --> 00:01:20,400
texture map<font color="#CCCCCC"> I'm gonna go</font><font color="#E5E5E5"> over perturbing</font>

28
00:01:18,540 --> 00:01:22,860
here in a second basically<font color="#E5E5E5"> adding noise</font>

29
00:01:20,400 --> 00:01:26,180
to<font color="#CCCCCC"> the texture</font><font color="#E5E5E5"> map now it believes it's</font>

30
00:01:22,860 --> 00:01:26,179
a rifle<font color="#E5E5E5"> from every angle</font>

31
00:01:26,600 --> 00:01:30,960
<font color="#E5E5E5">so what happens when an autonomous</font>

32
00:01:29,250 --> 00:01:34,049
system<font color="#E5E5E5"> cannot tell the difference</font>

33
00:01:30,960 --> 00:01:36,479
<font color="#CCCCCC">between a turtle</font><font color="#E5E5E5"> and a rifle</font><font color="#CCCCCC"> in a</font>

34
00:01:34,049 --> 00:01:42,479
surveillance state what<font color="#E5E5E5"> you</font><font color="#CCCCCC"> think is</font>

35
00:01:36,479 --> 00:01:44,579
gonna happen<font color="#E5E5E5"> a lot of dead turtles so a</font>

36
00:01:42,479 --> 00:01:46,950
lot of<font color="#E5E5E5"> the research in this space has</font>

37
00:01:44,579 --> 00:01:48,389
focused on image classifiers right so we

38
00:01:46,950 --> 00:01:49,439
could visually see<font color="#E5E5E5"> what was going on</font>

39
00:01:48,390 --> 00:01:51,479
<font color="#CCCCCC">that</font><font color="#E5E5E5"> things were being misclassified</font>

40
00:01:49,439 --> 00:01:53,008
<font color="#CCCCCC">it's obviously</font><font color="#E5E5E5"> a lot harder in some of</font>

41
00:01:51,479 --> 00:01:55,110
the other areas<font color="#E5E5E5"> that machine</font><font color="#CCCCCC"> learning</font>

42
00:01:53,009 --> 00:01:57,420
<font color="#CCCCCC">has been applied to right it's harder to</font>

43
00:01:55,110 --> 00:01:59,460
see<font color="#CCCCCC"> that effect is happening but here</font>

44
00:01:57,420 --> 00:02:03,329
<font color="#E5E5E5">and visual like you can visualize what's</font>

45
00:01:59,460 --> 00:02:05,070
actually happening<font color="#CCCCCC"> alright</font><font color="#E5E5E5"> so</font><font color="#CCCCCC"> some</font>

46
00:02:03,329 --> 00:02:06,658
terminology I realized that<font color="#E5E5E5"> everybody</font>

47
00:02:05,070 --> 00:02:09,359
here<font color="#E5E5E5"> is not a data scientist and that's</font>

48
00:02:06,659 --> 00:02:11,039
for the better<font color="#CCCCCC"> a classifier is a style</font>

49
00:02:09,360 --> 00:02:12,420
of a machine learning algorithm I'm

50
00:02:11,038 --> 00:02:12,549
going to talk<font color="#CCCCCC"> about a lot and it's</font><font color="#E5E5E5"> going</font>

51
00:02:12,420 --> 00:02:15,459
<font color="#E5E5E5">to</font>

52
00:02:12,550 --> 00:02:18,910
determine a class<font color="#CCCCCC"> so yes it's a turtle</font>

53
00:02:15,460 --> 00:02:20,620
<font color="#E5E5E5">no it's not a turtle yes it's a rifle no</font>

54
00:02:18,910 --> 00:02:23,260
it's not<font color="#E5E5E5"> a rifle this</font><font color="#CCCCCC"> is a classifier</font>

55
00:02:20,620 --> 00:02:24,760
<font color="#CCCCCC">I'm</font><font color="#E5E5E5"> gonna say SVM a lot that means it's</font>

56
00:02:23,260 --> 00:02:27,250
a support vector<font color="#E5E5E5"> machine it's a type of</font>

57
00:02:24,760 --> 00:02:29,019
<font color="#E5E5E5">algorithm how it works is</font><font color="#CCCCCC"> not important</font>

58
00:02:27,250 --> 00:02:29,920
<font color="#CCCCCC">for this discussion</font><font color="#E5E5E5"> when I say</font>

59
00:02:29,020 --> 00:02:32,230
perturbation

60
00:02:29,920 --> 00:02:34,440
I mean I'm adding noise<font color="#CCCCCC"> that's</font><font color="#E5E5E5"> it it's a</font>

61
00:02:32,230 --> 00:02:37,149
<font color="#E5E5E5">fancy word for adding some special noise</font>

62
00:02:34,440 --> 00:02:39,850
and then when I say adversarial example

63
00:02:37,150 --> 00:02:42,040
this is a<font color="#E5E5E5"> worst case example for an</font>

64
00:02:39,850 --> 00:02:46,299
algorithm<font color="#E5E5E5"> right it's specially crafted</font>

65
00:02:42,040 --> 00:02:48,370
that way so an outline<font color="#E5E5E5"> I'm gonna go over</font>

66
00:02:46,300 --> 00:02:50,710
<font color="#CCCCCC">a slight history</font><font color="#E5E5E5"> we're in talks about</font>

67
00:02:48,370 --> 00:02:53,440
the types of<font color="#CCCCCC"> attacks</font><font color="#E5E5E5"> what a blind spot</font>

68
00:02:50,710 --> 00:02:56,350
is what's why that's important what an

69
00:02:53,440 --> 00:02:58,810
adversarial example is defense against

70
00:02:56,350 --> 00:03:00,579
adversarial examples some<font color="#E5E5E5"> of the black</font>

71
00:02:58,810 --> 00:03:03,460
box and white<font color="#E5E5E5"> box research in this area</font>

72
00:03:00,580 --> 00:03:07,180
<font color="#CCCCCC">a flight demo and the</font><font color="#E5E5E5"> resources are</font><font color="#CCCCCC"> all</font>

73
00:03:03,460 --> 00:03:10,690
at<font color="#E5E5E5"> the end so</font><font color="#CCCCCC"> timeline</font><font color="#E5E5E5"> started out in</font>

74
00:03:07,180 --> 00:03:14,350
2004<font color="#E5E5E5"> obviously machine learning research</font>

75
00:03:10,690 --> 00:03:17,980
has been long long established<font color="#E5E5E5"> but in</font>

76
00:03:14,350 --> 00:03:20,079
2004 we had<font color="#CCCCCC"> delvia al and I'm this is</font>

77
00:03:17,980 --> 00:03:22,600
<font color="#E5E5E5">more of the academia of academia side</font>

78
00:03:20,080 --> 00:03:25,120
because this is really Rick grounded in

79
00:03:22,600 --> 00:03:27,070
academia<font color="#E5E5E5"> right now proof of concepts for</font>

80
00:03:25,120 --> 00:03:28,270
<font color="#E5E5E5">InfoSec aren't there yet but we're</font>

81
00:03:27,070 --> 00:03:30,640
getting<font color="#CCCCCC"> there and</font><font color="#E5E5E5"> I'll get to</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> in a</font>

82
00:03:28,270 --> 00:03:31,810
minute<font color="#CCCCCC"> so 2004 they came out</font><font color="#E5E5E5"> with</font>

83
00:03:30,640 --> 00:03:34,320
<font color="#CCCCCC">something called adversarial</font>

84
00:03:31,810 --> 00:03:36,880
classification<font color="#E5E5E5"> and it was basically</font>

85
00:03:34,320 --> 00:03:39,430
<font color="#E5E5E5">looking at the spam detection domain you</font>

86
00:03:36,880 --> 00:03:41,079
had a<font color="#E5E5E5"> a victim and an attacking</font>

87
00:03:39,430 --> 00:03:42,940
classifier and<font color="#E5E5E5"> they're trying to fool</font>

88
00:03:41,080 --> 00:03:46,060
each other in this game to<font color="#E5E5E5"> figure out</font>

89
00:03:42,940 --> 00:03:48,579
<font color="#E5E5E5">like if I do this will it detect it well</font>

90
00:03:46,060 --> 00:03:51,850
the other classifier detect it<font color="#CCCCCC"> and then</font>

91
00:03:48,580 --> 00:03:54,520
we move on to<font color="#E5E5E5"> like who hang at all</font><font color="#CCCCCC"> they</font>

92
00:03:51,850 --> 00:03:58,989
define like a formal taxonomy behind all

93
00:03:54,520 --> 00:04:01,000
of<font color="#CCCCCC"> these attack possibilities there are</font>

94
00:03:58,989 --> 00:04:03,640
<font color="#E5E5E5">other notable contributions this is not</font>

95
00:04:01,000 --> 00:04:06,010
an exhaustive list<font color="#E5E5E5"> by any means of the</font>

96
00:04:03,640 --> 00:04:07,540
imagination<font color="#CCCCCC"> but I'm trying to hit on</font>

97
00:04:06,010 --> 00:04:13,660
<font color="#CCCCCC">some of</font><font color="#E5E5E5"> the really high points that have</font>

98
00:04:07,540 --> 00:04:16,029
developed this research area let's see

99
00:04:13,660 --> 00:04:18,488
in 2012 Biggio at all they kind<font color="#E5E5E5"> of</font>

100
00:04:16,029 --> 00:04:21,429
discussed the consequences<font color="#CCCCCC"> of injecting</font>

101
00:04:18,488 --> 00:04:24,520
specially crafted attack data<font color="#E5E5E5"> they call</font>

102
00:04:21,430 --> 00:04:26,000
this a data poisoning and they<font color="#E5E5E5"> they test</font>

103
00:04:24,520 --> 00:04:28,250
it on an SVM

104
00:04:26,000 --> 00:04:29,720
at this point<font color="#E5E5E5"> SVM is like the</font><font color="#CCCCCC"> the model</font>

105
00:04:28,250 --> 00:04:31,190
they all start with<font color="#E5E5E5"> and then they start</font>

106
00:04:29,720 --> 00:04:32,810
going<font color="#E5E5E5"> into like deep</font><font color="#CCCCCC"> neural network some</font>

107
00:04:31,190 --> 00:04:36,950
of the more advanced machine<font color="#CCCCCC"> learning</font>

108
00:04:32,810 --> 00:04:39,710
algorithms out<font color="#CCCCCC"> there</font><font color="#E5E5E5"> Shogun II was the</font>

109
00:04:36,950 --> 00:04:41,810
first<font color="#CCCCCC"> group to</font><font color="#E5E5E5"> start retraining their</font>

110
00:04:39,710 --> 00:04:43,430
classifiers with these adversarial

111
00:04:41,810 --> 00:04:48,230
examples to<font color="#E5E5E5"> kind of see what happened</font>

112
00:04:43,430 --> 00:04:51,230
and then we start<font color="#CCCCCC"> doing</font><font color="#E5E5E5"> black box</font><font color="#CCCCCC"> black</font>

113
00:04:48,230 --> 00:04:54,470
box attacks on like<font color="#E5E5E5"> a DB AWS classifiers</font>

114
00:04:51,230 --> 00:04:55,670
<font color="#E5E5E5">in Google Cloud and 2016 there are some</font>

115
00:04:54,470 --> 00:04:57,320
really<font color="#CCCCCC"> interesting</font>

116
00:04:55,670 --> 00:05:01,420
current research<font color="#E5E5E5"> I'll get to that in a</font>

117
00:04:57,320 --> 00:05:04,040
second<font color="#E5E5E5"> so poisoning versus evasion</font>

118
00:05:01,420 --> 00:05:07,280
poisoning<font color="#CCCCCC"> attacks happen before training</font>

119
00:05:04,040 --> 00:05:09,370
<font color="#E5E5E5">you'll notice that you have us a part of</font>

120
00:05:07,280 --> 00:05:11,299
the<font color="#CCCCCC"> EM nough Stata set which is</font>

121
00:05:09,370 --> 00:05:12,680
basically a<font color="#E5E5E5"> bunch of pictures</font><font color="#CCCCCC"> of</font>

122
00:05:11,300 --> 00:05:15,080
handwriting<font color="#CCCCCC"> and the idea is the</font>

123
00:05:12,680 --> 00:05:19,130
classifier<font color="#CCCCCC"> can determine what digit that</font>

124
00:05:15,080 --> 00:05:21,590
<font color="#E5E5E5">is so the first image</font><font color="#CCCCCC"> you see is a 7</font><font color="#E5E5E5"> the</font>

125
00:05:19,130 --> 00:05:23,840
after the attack<font color="#E5E5E5"> look at the all the</font>

126
00:05:21,590 --> 00:05:25,489
<font color="#CCCCCC">noise that's</font><font color="#E5E5E5"> been added</font><font color="#CCCCCC"> and you'll</font>

127
00:05:23,840 --> 00:05:27,619
<font color="#E5E5E5">notice</font><font color="#CCCCCC"> that the validation error</font><font color="#E5E5E5"> kind of</font>

128
00:05:25,490 --> 00:05:30,500
goes<font color="#CCCCCC"> through the roof</font><font color="#E5E5E5"> this is the same</font>

129
00:05:27,620 --> 00:05:33,470
<font color="#E5E5E5">idea</font><font color="#CCCCCC"> for evasion</font><font color="#E5E5E5"> you have a bus</font><font color="#CCCCCC"> you add</font>

130
00:05:30,500 --> 00:05:36,290
noise now it's an ostrich<font color="#CCCCCC"> does</font><font color="#E5E5E5"> that look</font>

131
00:05:33,470 --> 00:05:39,020
like<font color="#E5E5E5"> an ostrich to you it doesn't</font><font color="#CCCCCC"> look</font>

132
00:05:36,290 --> 00:05:41,270
<font color="#CCCCCC">like enough if but we have</font><font color="#E5E5E5"> right that</font>

133
00:05:39,020 --> 00:05:43,640
context right<font color="#E5E5E5"> we're humans we know what</font>

134
00:05:41,270 --> 00:05:48,530
things<font color="#E5E5E5"> are</font><font color="#CCCCCC"> and are not classifier has</font><font color="#E5E5E5"> no</font>

135
00:05:43,640 --> 00:05:50,960
idea so the kind of attacks<font color="#E5E5E5"> look like</font>

136
00:05:48,530 --> 00:05:53,299
this there's causative attacks right

137
00:05:50,960 --> 00:05:56,090
manipulation of the training data<font color="#CCCCCC"> before</font>

138
00:05:53,300 --> 00:05:58,280
the classifiers trained data poisoning

139
00:05:56,090 --> 00:06:01,030
adding that specially crafted<font color="#E5E5E5"> attack</font>

140
00:05:58,280 --> 00:06:04,070
training examples before<font color="#E5E5E5"> it's trained</font>

141
00:06:01,030 --> 00:06:06,830
exploratory the classifier<font color="#CCCCCC"> has been</font>

142
00:06:04,070 --> 00:06:09,080
trained and we're attacking<font color="#E5E5E5"> the already</font>

143
00:06:06,830 --> 00:06:14,750
trained classifier and then a hybrid is

144
00:06:09,080 --> 00:06:16,159
a mix of those attack techniques now I

145
00:06:14,750 --> 00:06:18,110
get into<font color="#E5E5E5"> something called blind spot so</font>

146
00:06:16,160 --> 00:06:20,840
you're<font color="#E5E5E5"> probably</font><font color="#CCCCCC"> asking yourself like why</font>

147
00:06:18,110 --> 00:06:22,790
are<font color="#E5E5E5"> we seeing like what what</font><font color="#CCCCCC"> what is</font>

148
00:06:20,840 --> 00:06:27,130
causing these adversarial examples to

149
00:06:22,790 --> 00:06:29,600
have such an<font color="#CCCCCC"> impact</font><font color="#E5E5E5"> and the idea is that</font>

150
00:06:27,130 --> 00:06:33,680
noise right this noise<font color="#CCCCCC"> that we talked</font>

151
00:06:29,600 --> 00:06:36,680
about<font color="#E5E5E5"> these</font><font color="#CCCCCC"> perturbations they can mess</font>

152
00:06:33,680 --> 00:06:39,030
with<font color="#E5E5E5"> the classifiers decisions regions</font>

153
00:06:36,680 --> 00:06:42,330
and the models decision space can

154
00:06:39,030 --> 00:06:45,090
be poorly<font color="#E5E5E5"> defined and the example I like</font>

155
00:06:42,330 --> 00:06:46,500
<font color="#CCCCCC">to</font><font color="#E5E5E5"> use is pandas</font><font color="#CCCCCC"> so let's say we're</font>

156
00:06:45,090 --> 00:06:48,419
training our classifier an image

157
00:06:46,500 --> 00:06:50,340
classifier<font color="#E5E5E5"> and we give</font><font color="#CCCCCC"> it a whole bunch</font>

158
00:06:48,420 --> 00:06:53,640
<font color="#CCCCCC">of pictures of what pandas are and what</font>

159
00:06:50,340 --> 00:06:55,859
are<font color="#E5E5E5"> not pandas</font><font color="#CCCCCC"> I want you to think about</font>

160
00:06:53,640 --> 00:06:58,710
the entire space of<font color="#E5E5E5"> all the things that</font>

161
00:06:55,860 --> 00:07:01,590
are not pandas imagine trying<font color="#E5E5E5"> to provide</font>

162
00:06:58,710 --> 00:07:04,020
the classifier with every example<font color="#E5E5E5"> of</font>

163
00:07:01,590 --> 00:07:05,609
what a not<font color="#CCCCCC"> panda is</font><font color="#E5E5E5"> it's hard right</font>

164
00:07:04,020 --> 00:07:09,180
there's a lot of overhead<font color="#CCCCCC"> in that it's</font>

165
00:07:05,610 --> 00:07:11,340
kind<font color="#CCCCCC"> of impossible and this is like an</font>

166
00:07:09,180 --> 00:07:14,010
ongoing research area<font color="#E5E5E5"> nobody</font><font color="#CCCCCC"> has</font><font color="#E5E5E5"> been</font>

167
00:07:11,340 --> 00:07:15,810
<font color="#E5E5E5">able yet to definitively approve where</font>

168
00:07:14,010 --> 00:07:18,780
these come<font color="#CCCCCC"> from why they exist</font><font color="#E5E5E5"> and how</font>

169
00:07:15,810 --> 00:07:20,550
to solve<font color="#E5E5E5"> them but adversarial examples</font>

170
00:07:18,780 --> 00:07:22,500
are kind of going<font color="#CCCCCC"> towards that</font><font color="#E5E5E5"> route</font>

171
00:07:20,550 --> 00:07:24,420
<font color="#E5E5E5">trying to identify what blind spots are</font>

172
00:07:22,500 --> 00:07:34,760
and<font color="#E5E5E5"> why they exist and how to get rid of</font>

173
00:07:24,420 --> 00:07:36,390
them okay<font color="#E5E5E5"> so here be bugs as</font>

174
00:07:34,760 --> 00:07:38,250
introspection into<font color="#E5E5E5"> these algorithms</font>

175
00:07:36,390 --> 00:07:40,409
increase<font color="#CCCCCC"> obviously we're going</font><font color="#E5E5E5"> to get</font>

176
00:07:38,250 --> 00:07:41,880
<font color="#E5E5E5">some more bugs right so much like bug</font>

177
00:07:40,410 --> 00:07:44,160
bounty programs where you're starting<font color="#CCCCCC"> to</font>

178
00:07:41,880 --> 00:07:45,960
get more eyes<font color="#CCCCCC"> on a line of code we're</font>

179
00:07:44,160 --> 00:07:49,130
getting more eyes on<font color="#CCCCCC"> our algorithms and</font>

180
00:07:45,960 --> 00:07:49,130
trying to<font color="#E5E5E5"> figure out how to break them</font>

181
00:07:49,850 --> 00:07:53,520
<font color="#CCCCCC">remember that we have a talent shortage</font>

182
00:07:52,080 --> 00:07:55,349
right<font color="#E5E5E5"> of information security</font>

183
00:07:53,520 --> 00:07:57,210
<font color="#CCCCCC">professionals</font><font color="#E5E5E5"> it's estimated there's</font>

184
00:07:55,350 --> 00:08:00,900
like a hundred<font color="#CCCCCC"> and</font><font color="#E5E5E5"> five thousand in the</font>

185
00:07:57,210 --> 00:08:03,210
US alone<font color="#E5E5E5"> but think about</font><font color="#CCCCCC"> 22,000 experts</font>

186
00:08:00,900 --> 00:08:05,280
looking at machine learning like

187
00:08:03,210 --> 00:08:07,799
algorithms<font color="#CCCCCC"> and trying to break them</font>

188
00:08:05,280 --> 00:08:10,679
<font color="#CCCCCC">right</font><font color="#E5E5E5"> that's a factor</font><font color="#CCCCCC"> of five and</font><font color="#E5E5E5"> then</font>

189
00:08:07,800 --> 00:08:12,720
in the US alone so we as we start

190
00:08:10,680 --> 00:08:14,460
training<font color="#E5E5E5"> up more people who are fluent</font>

191
00:08:12,720 --> 00:08:16,290
<font color="#E5E5E5">in machine learning</font><font color="#CCCCCC"> algorithm</font><font color="#E5E5E5"> so we're</font>

192
00:08:14,460 --> 00:08:21,539
going<font color="#E5E5E5"> to start to see</font><font color="#CCCCCC"> more ways that we</font>

193
00:08:16,290 --> 00:08:23,790
can break the classifiers so<font color="#CCCCCC"> what our</font>

194
00:08:21,540 --> 00:08:25,050
adversarial examples<font color="#E5E5E5"> right data that</font>

195
00:08:23,790 --> 00:08:27,780
<font color="#CCCCCC">presents</font><font color="#E5E5E5"> the worst case to the</font>

196
00:08:25,050 --> 00:08:29,700
classifier intentionally designed to

197
00:08:27,780 --> 00:08:33,510
make the classifier<font color="#E5E5E5"> make the wrong</font>

198
00:08:29,700 --> 00:08:36,480
decision right examples for us right

199
00:08:33,510 --> 00:08:39,059
<font color="#E5E5E5">information security is detecting domain</font>

200
00:08:36,480 --> 00:08:42,030
<font color="#E5E5E5">generic generation algorithms in command</font>

201
00:08:39,059 --> 00:08:44,310
control<font color="#E5E5E5"> infrastructure or my favorite</font>

202
00:08:42,030 --> 00:08:47,550
how about generating malicious portable

203
00:08:44,310 --> 00:08:49,560
executables<font color="#CCCCCC"> that are still malicious but</font>

204
00:08:47,550 --> 00:08:52,319
<font color="#CCCCCC">they get by the classifier and are</font>

205
00:08:49,560 --> 00:08:52,959
<font color="#CCCCCC">classified as benign there is an</font>

206
00:08:52,320 --> 00:08:54,580
interesting

207
00:08:52,960 --> 00:08:56,710
or an interesting<font color="#CCCCCC"> paper in this</font><font color="#E5E5E5"> area</font>

208
00:08:54,580 --> 00:08:59,710
where they reserved parts of the

209
00:08:56,710 --> 00:09:01,660
executable<font color="#CCCCCC"> that were essential for it to</font>

210
00:08:59,710 --> 00:09:04,140
<font color="#E5E5E5">execute right to work and then they</font>

211
00:09:01,660 --> 00:09:06,490
<font color="#E5E5E5">perturbed everything else and remember</font>

212
00:09:04,140 --> 00:09:09,540
<font color="#CCCCCC">remember like 10 years ago</font><font color="#E5E5E5"> or like</font>

213
00:09:06,490 --> 00:09:12,700
signatures are bad don't<font color="#E5E5E5"> do signatures</font>

214
00:09:09,540 --> 00:09:16,719
<font color="#E5E5E5">we have machine learning for this guess</font>

215
00:09:12,700 --> 00:09:19,930
what<font color="#E5E5E5"> we're back here</font><font color="#CCCCCC"> again so now we</font>

216
00:09:16,720 --> 00:09:23,709
have machine learning trying to detect

217
00:09:19,930 --> 00:09:26,560
these attacks<font color="#E5E5E5"> and now we can subvert the</font>

218
00:09:23,709 --> 00:09:30,399
machine learning<font color="#E5E5E5"> algorithm</font><font color="#CCCCCC"> right</font><font color="#E5E5E5"> adding</font>

219
00:09:26,560 --> 00:09:33,279
on to that<font color="#E5E5E5"> attack defense paradigm so</font>

220
00:09:30,399 --> 00:09:33,940
some<font color="#E5E5E5"> real-world examples of research</font>

221
00:09:33,279 --> 00:09:36,760
<font color="#CCCCCC">that</font><font color="#E5E5E5"> are out there</font>

222
00:09:33,940 --> 00:09:41,260
<font color="#E5E5E5">adding the stickers to the stop</font><font color="#CCCCCC"> sign for</font>

223
00:09:36,760 --> 00:09:43,980
<font color="#E5E5E5">self-driving cars using eyeglass frames</font>

224
00:09:41,260 --> 00:09:47,680
to subvert facial recognition systems<font color="#E5E5E5"> or</font>

225
00:09:43,980 --> 00:09:50,410
adding noise to<font color="#E5E5E5"> verbal like</font><font color="#CCCCCC"> okay Google</font>

226
00:09:47,680 --> 00:09:53,279
to make<font color="#E5E5E5"> it completely not register what</font>

227
00:09:50,410 --> 00:09:56,319
<font color="#E5E5E5">you said to it these are kind of scary</font>

228
00:09:53,279 --> 00:09:59,370
but remember when you used<font color="#CCCCCC"> to throw</font><font color="#E5E5E5"> the</font>

229
00:09:56,320 --> 00:10:02,110
salt over<font color="#CCCCCC"> your</font><font color="#E5E5E5"> shoulder for</font><font color="#CCCCCC"> good</font><font color="#E5E5E5"> luck</font>

230
00:09:59,370 --> 00:10:04,860
how about salt circles to trap

231
00:10:02,110 --> 00:10:07,779
self-driving cars

232
00:10:04,860 --> 00:10:12,060
we're like using alchemy<font color="#CCCCCC"> to fool AI</font>

233
00:10:07,779 --> 00:10:12,060
systems now this is a thing

234
00:10:12,209 --> 00:10:17,650
so generating adversarial examples again

235
00:10:16,209 --> 00:10:21,959
we're at which is adding specially

236
00:10:17,650 --> 00:10:25,390
crafted noise<font color="#E5E5E5"> and we do this by using</font>

237
00:10:21,959 --> 00:10:27,459
gradient ascent<font color="#CCCCCC"> or creating</font><font color="#E5E5E5"> descent</font><font color="#CCCCCC"> and</font>

238
00:10:25,390 --> 00:10:29,560
<font color="#E5E5E5">one of the methods underneath that it's</font>

239
00:10:27,459 --> 00:10:31,119
called fast gradient<font color="#CCCCCC"> sign method I'm not</font>

240
00:10:29,560 --> 00:10:31,779
going<font color="#E5E5E5"> to get into math it's</font><font color="#CCCCCC"> really not</font>

241
00:10:31,120 --> 00:10:34,180
important

242
00:10:31,779 --> 00:10:36,820
basically you take<font color="#CCCCCC"> each pixel you</font>

243
00:10:34,180 --> 00:10:39,579
perturb it<font color="#CCCCCC"> tour the the direction where</font>

244
00:10:36,820 --> 00:10:44,140
you're<font color="#E5E5E5"> gonna get the most error and you</font>

245
00:10:39,579 --> 00:10:47,709
do that<font color="#CCCCCC"> for the entire image or in case</font>

246
00:10:44,140 --> 00:10:52,300
<font color="#CCCCCC">of video</font><font color="#E5E5E5"> do it for the video</font><font color="#CCCCCC"> so what</font><font color="#E5E5E5"> can</font>

247
00:10:47,709 --> 00:10:55,119
<font color="#CCCCCC">we do about adversarial examples</font><font color="#E5E5E5"> we want</font>

248
00:10:52,300 --> 00:10:57,670
robust algorithms<font color="#E5E5E5"> we know that</font>

249
00:10:55,120 --> 00:10:58,930
retraining from scratch increases

250
00:10:57,670 --> 00:11:00,819
misclassifications

251
00:10:58,930 --> 00:11:03,359
we know that retraining with a disjoint

252
00:11:00,820 --> 00:11:06,130
data set increases misclassifications

253
00:11:03,360 --> 00:11:06,610
<font color="#CCCCCC">however we also know that training with</font>

254
00:11:06,130 --> 00:11:08,620
<font color="#CCCCCC">AD</font>

255
00:11:06,610 --> 00:11:11,370
several examples<font color="#CCCCCC"> reduces the</font>

256
00:11:08,620 --> 00:11:11,370
misclassifications

257
00:11:11,490 --> 00:11:16,990
so<font color="#E5E5E5"> if we took</font><font color="#CCCCCC"> that into into</font>

258
00:11:14,680 --> 00:11:19,479
consideration<font color="#E5E5E5"> if we reduce the</font>

259
00:11:16,990 --> 00:11:20,019
activation<font color="#E5E5E5"> given two inputs that can be</font>

260
00:11:19,480 --> 00:11:22,899
tricked

261
00:11:20,019 --> 00:11:25,140
right we're reducing our the amount of

262
00:11:22,899 --> 00:11:27,310
exposure<font color="#E5E5E5"> we have for that algorithm</font>

263
00:11:25,140 --> 00:11:29,260
<font color="#E5E5E5">another way we could do it is keeping a</font>

264
00:11:27,310 --> 00:11:31,089
human in the loop<font color="#CCCCCC"> making sure it's not</font>

265
00:11:29,260 --> 00:11:34,480
<font color="#E5E5E5">completely autonomous right it doesn't</font>

266
00:11:31,089 --> 00:11:36,130
<font color="#E5E5E5">just do its own thing</font><font color="#CCCCCC"> it got the the QA</font>

267
00:11:34,480 --> 00:11:37,750
approval<font color="#E5E5E5"> buck checkbox right and we're</font>

268
00:11:36,130 --> 00:11:40,930
just<font color="#CCCCCC"> letting it go and do its automation</font>

269
00:11:37,750 --> 00:11:42,310
<font color="#E5E5E5">keep a</font><font color="#CCCCCC"> human looking at it making sure</font>

270
00:11:40,930 --> 00:11:45,670
<font color="#E5E5E5">that it's doing</font><font color="#CCCCCC"> what it's supposed</font><font color="#E5E5E5"> to be</font>

271
00:11:42,310 --> 00:11:48,069
<font color="#CCCCCC">doing and then another version</font><font color="#E5E5E5"> is adding</font>

272
00:11:45,670 --> 00:11:50,410
consensus now instead of<font color="#E5E5E5"> having one</font>

273
00:11:48,070 --> 00:11:52,300
classifier<font color="#E5E5E5"> to rule them all we have</font>

274
00:11:50,410 --> 00:11:54,610
three classifiers<font color="#E5E5E5"> that must come to a</font>

275
00:11:52,300 --> 00:11:59,410
consensus about<font color="#E5E5E5"> whether that</font><font color="#CCCCCC"> input</font>

276
00:11:54,610 --> 00:12:01,329
should be believed or<font color="#CCCCCC"> not our training</font>

277
00:11:59,410 --> 00:12:03,850
life cycle is probably going<font color="#E5E5E5"> to</font><font color="#CCCCCC"> change</font>

278
00:12:01,329 --> 00:12:06,310
<font color="#E5E5E5">right if you're a data scientist maybe</font>

279
00:12:03,850 --> 00:12:09,579
you work with this<font color="#E5E5E5"> you'll recognize the</font>

280
00:12:06,310 --> 00:12:12,609
import clean test test train split and

281
00:12:09,579 --> 00:12:15,279
<font color="#E5E5E5">then deploy with adversarial examples</font>

282
00:12:12,610 --> 00:12:18,220
were increasing that training<font color="#CCCCCC"> lifecycle</font>

283
00:12:15,279 --> 00:12:20,320
<font color="#E5E5E5">we're generating adversarial examples</font>

284
00:12:18,220 --> 00:12:21,940
<font color="#E5E5E5">we're testing with adversarial examples</font>

285
00:12:20,320 --> 00:12:24,310
and we're repeating<font color="#E5E5E5"> that until we get</font>

286
00:12:21,940 --> 00:12:25,750
more<font color="#CCCCCC"> coverage</font><font color="#E5E5E5"> over that negative space</font>

287
00:12:24,310 --> 00:12:27,939
that<font color="#E5E5E5"> we were talking</font><font color="#CCCCCC"> about earlier right</font>

288
00:12:25,750 --> 00:12:29,560
providing all<font color="#CCCCCC"> of those examples that</font><font color="#E5E5E5"> we</font>

289
00:12:27,940 --> 00:12:36,060
<font color="#E5E5E5">couldn't provide to the classifier and</font>

290
00:12:29,560 --> 00:12:40,390
then deploying research in this area

291
00:12:36,060 --> 00:12:42,219
<font color="#E5E5E5">traditionally</font><font color="#CCCCCC"> was kind of lackluster a</font>

292
00:12:40,390 --> 00:12:44,740
lot of the earlier papers assumed

293
00:12:42,220 --> 00:12:46,540
<font color="#E5E5E5">easy-mode right the attacker has full</font>

294
00:12:44,740 --> 00:12:48,519
<font color="#E5E5E5">access to the classifier and all the</font>

295
00:12:46,540 --> 00:12:50,140
<font color="#E5E5E5">training data</font><font color="#CCCCCC"> and all the test data</font>

296
00:12:48,519 --> 00:12:51,490
right that's not<font color="#E5E5E5"> realistic nobody's</font>

297
00:12:50,140 --> 00:12:54,670
going<font color="#CCCCCC"> to</font><font color="#E5E5E5"> have that kind of access unless</font>

298
00:12:51,490 --> 00:12:56,980
you have an insider threat<font color="#CCCCCC"> and several</font>

299
00:12:54,670 --> 00:12:59,019
of the papers<font color="#E5E5E5"> reference the</font><font color="#CCCCCC"> information</font>

300
00:12:56,980 --> 00:13:00,820
<font color="#CCCCCC">security community</font><font color="#E5E5E5"> like look</font><font color="#CCCCCC"> to them</font><font color="#E5E5E5"> so</font>

301
00:12:59,019 --> 00:13:03,120
we can have<font color="#CCCCCC"> more robust attacks because</font>

302
00:13:00,820 --> 00:13:06,160
we're<font color="#E5E5E5"> really good</font><font color="#CCCCCC"> at attacking</font><font color="#E5E5E5"> things</font>

303
00:13:03,120 --> 00:13:10,209
but<font color="#CCCCCC"> blackbox research and I say that as</font>

304
00:13:06,160 --> 00:13:13,029
in a recent less than five<font color="#E5E5E5"> years</font><font color="#CCCCCC"> time</font>

305
00:13:10,209 --> 00:13:15,699
<font color="#E5E5E5">frame attacks can now be transferred</font>

306
00:13:13,029 --> 00:13:17,410
<font color="#CCCCCC">between classifiers</font><font color="#E5E5E5"> so before when I</font>

307
00:13:15,699 --> 00:13:19,839
said<font color="#CCCCCC"> white box like you had access</font><font color="#E5E5E5"> to</font>

308
00:13:17,410 --> 00:13:20,560
<font color="#E5E5E5">everything</font><font color="#CCCCCC"> I don't need access</font><font color="#E5E5E5"> to</font><font color="#CCCCCC"> your</font>

309
00:13:19,839 --> 00:13:23,260
<font color="#E5E5E5">classifier</font>

310
00:13:20,560 --> 00:13:26,199
anymore<font color="#CCCCCC"> I can attack your classifier</font>

311
00:13:23,260 --> 00:13:30,160
with my classifier<font color="#E5E5E5"> without touching your</font>

312
00:13:26,200 --> 00:13:31,570
training data<font color="#CCCCCC"> your attack your Viktor</font>

313
00:13:30,160 --> 00:13:34,329
model your victim model becomes an

314
00:13:31,570 --> 00:13:36,730
Oracle<font color="#CCCCCC"> so I can ask your victim</font><font color="#E5E5E5"> a whole</font>

315
00:13:34,330 --> 00:13:39,490
bunch of stuff how does this classify

316
00:13:36,730 --> 00:13:41,680
<font color="#E5E5E5">how does this classify and then use the</font>

317
00:13:39,490 --> 00:13:44,770
examples that<font color="#E5E5E5"> it gives me to train my</font>

318
00:13:41,680 --> 00:13:46,689
own classifier<font color="#E5E5E5"> after that classifiers</font>

319
00:13:44,770 --> 00:13:49,240
been trained<font color="#CCCCCC"> I can</font><font color="#E5E5E5"> generate adversarial</font>

320
00:13:46,690 --> 00:13:51,730
examples on my classifier<font color="#CCCCCC"> that work on</font>

321
00:13:49,240 --> 00:13:53,350
<font color="#E5E5E5">your classifier which that's that's kind</font>

322
00:13:51,730 --> 00:13:54,730
of scary<font color="#E5E5E5"> I don't need to touch your</font>

323
00:13:53,350 --> 00:13:56,170
classifier I don't need to touch<font color="#E5E5E5"> its</font>

324
00:13:54,730 --> 00:14:00,720
code<font color="#CCCCCC"> I don't need to touches training</font>

325
00:13:56,170 --> 00:14:02,740
data<font color="#CCCCCC"> but I can still</font><font color="#E5E5E5"> affect it and so</font>

326
00:14:00,720 --> 00:14:05,100
here's like more of<font color="#E5E5E5"> a visual</font>

327
00:14:02,740 --> 00:14:09,490
<font color="#E5E5E5">understanding right an attacker has</font>

328
00:14:05,100 --> 00:14:12,040
<font color="#CCCCCC">access to query or classifier</font><font color="#E5E5E5"> the Oracle</font>

329
00:14:09,490 --> 00:14:14,710
<font color="#E5E5E5">it tells me what it classifies certain</font>

330
00:14:12,040 --> 00:14:16,540
things as I<font color="#CCCCCC"> train it</font><font color="#E5E5E5"> into class of the</font>

331
00:14:14,710 --> 00:14:18,130
classifier<font color="#E5E5E5"> B and then I use those</font>

332
00:14:16,540 --> 00:14:21,790
adversarial examples that<font color="#E5E5E5"> I generate</font>

333
00:14:18,130 --> 00:14:24,880
against the first classifier what was

334
00:14:21,790 --> 00:14:27,880
interesting is that this image<font color="#CCCCCC"> that you</font>

335
00:14:24,880 --> 00:14:30,760
<font color="#E5E5E5">see to your</font><font color="#CCCCCC"> right is directly</font><font color="#E5E5E5"> from the</font>

336
00:14:27,880 --> 00:14:32,710
paper<font color="#E5E5E5"> and what it shows is</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> it's the</font>

337
00:14:30,760 --> 00:14:34,360
source machine<font color="#E5E5E5"> learning technique is on</font>

338
00:14:32,710 --> 00:14:35,700
the<font color="#E5E5E5"> vertical and</font><font color="#CCCCCC"> the target machine</font>

339
00:14:34,360 --> 00:14:39,310
<font color="#E5E5E5">learning technique is on the horizontal</font>

340
00:14:35,700 --> 00:14:41,920
<font color="#E5E5E5">so if I took</font><font color="#CCCCCC"> my deep neural network</font>

341
00:14:39,310 --> 00:14:44,949
right up there<font color="#CCCCCC"> on the top and I trained</font>

342
00:14:41,920 --> 00:14:48,310
it<font color="#CCCCCC"> to attack your let's say decision</font>

343
00:14:44,950 --> 00:14:50,440
tree anything that black column shows

344
00:14:48,310 --> 00:14:53,890
the<font color="#E5E5E5"> increased</font><font color="#CCCCCC"> miss classification rate</font>

345
00:14:50,440 --> 00:14:56,260
<font color="#E5E5E5">so we're looking at 87 percent or if I</font>

346
00:14:53,890 --> 00:14:58,300
took<font color="#E5E5E5"> the SVM and trained it against</font>

347
00:14:56,260 --> 00:15:01,420
<font color="#CCCCCC">another SVM that's a hundred</font><font color="#E5E5E5"> percent</font>

348
00:14:58,300 --> 00:15:03,819
<font color="#CCCCCC">that's</font><font color="#E5E5E5"> how accurate I my adversarial</font>

349
00:15:01,420 --> 00:15:06,130
examples that<font color="#E5E5E5"> I generated are at</font>

350
00:15:03,820 --> 00:15:12,940
<font color="#E5E5E5">attacking your classifier and making it</font>

351
00:15:06,130 --> 00:15:15,010
<font color="#CCCCCC">miss classify so if you didn't notice</font>

352
00:15:12,940 --> 00:15:18,339
from<font color="#E5E5E5"> here right that</font><font color="#CCCCCC"> hero's huge black</font>

353
00:15:15,010 --> 00:15:20,470
columns for SVM logistic regression<font color="#E5E5E5"> and</font>

354
00:15:18,339 --> 00:15:23,020
decision tree<font color="#E5E5E5"> models you don't need to</font>

355
00:15:20,470 --> 00:15:24,459
know really<font color="#E5E5E5"> how they work</font><font color="#CCCCCC"> just that they</font>

356
00:15:23,020 --> 00:15:27,640
are<font color="#E5E5E5"> more affected because they're</font>

357
00:15:24,459 --> 00:15:30,359
differentiable<font color="#CCCCCC"> deep neural</font><font color="#E5E5E5"> networks are</font>

358
00:15:27,640 --> 00:15:32,380
less affected by<font color="#E5E5E5"> this phenomenon and</font>

359
00:15:30,360 --> 00:15:34,360
they use<font color="#E5E5E5"> something called reservoir</font>

360
00:15:32,380 --> 00:15:35,829
sampling so remember<font color="#CCCCCC"> I</font><font color="#E5E5E5"> was talking</font>

361
00:15:34,360 --> 00:15:38,320
about the<font color="#CCCCCC"> Oracle and</font><font color="#E5E5E5"> I have to query it</font>

362
00:15:35,829 --> 00:15:40,269
<font color="#E5E5E5">I don't have to query it exhaustively</font><font color="#CCCCCC"> in</font>

363
00:15:38,320 --> 00:15:43,269
order to get the<font color="#CCCCCC"> amount of training that</font>

364
00:15:40,269 --> 00:15:44,680
<font color="#CCCCCC">I need to attack your classifier</font><font color="#E5E5E5"> you</font>

365
00:15:43,269 --> 00:15:46,540
would think that would I would need

366
00:15:44,680 --> 00:15:49,239
<font color="#E5E5E5">thousands right thousands of data points</font>

367
00:15:46,540 --> 00:15:52,149
<font color="#CCCCCC">to figure out how it was</font><font color="#E5E5E5"> classified but</font>

368
00:15:49,240 --> 00:15:54,250
<font color="#E5E5E5">using reservoir sampling I take a random</font>

369
00:15:52,149 --> 00:15:57,040
mix of those and I can<font color="#CCCCCC"> reduce that</font>

370
00:15:54,250 --> 00:16:02,500
querying<font color="#E5E5E5"> amount down to</font><font color="#CCCCCC"> the hundreds</font>

371
00:15:57,040 --> 00:16:04,089
instead of the thousands notable

372
00:16:02,500 --> 00:16:07,660
research in this area

373
00:16:04,089 --> 00:16:10,660
notice<font color="#E5E5E5"> notice</font><font color="#CCCCCC"> the date</font><font color="#E5E5E5"> June 22 2018</font>

374
00:16:07,660 --> 00:16:12,699
<font color="#CCCCCC">alright more researchers are</font><font color="#E5E5E5"> starting to</font>

375
00:16:10,660 --> 00:16:14,439
use the limited information<font color="#E5E5E5"> approach and</font>

376
00:16:12,700 --> 00:16:16,930
they're taking their stuff<font color="#CCCCCC"> and testing</font>

377
00:16:14,440 --> 00:16:20,290
it against Google Cloud and<font color="#E5E5E5"> AWS so</font>

378
00:16:16,930 --> 00:16:22,719
they're taking<font color="#CCCCCC"> Google clouds classifiers</font>

379
00:16:20,290 --> 00:16:25,599
and<font color="#E5E5E5"> trying to subvert them so if you're</font>

380
00:16:22,720 --> 00:16:28,660
using Google<font color="#CCCCCC"> cloud or AWS for their</font>

381
00:16:25,600 --> 00:16:31,690
machine learning capabilities and I can

382
00:16:28,660 --> 00:16:33,519
subvert them what do you<font color="#E5E5E5"> think that</font>

383
00:16:31,690 --> 00:16:38,440
<font color="#E5E5E5">means</font><font color="#CCCCCC"> for the greater community who's</font>

384
00:16:33,519 --> 00:16:40,029
<font color="#E5E5E5">looking</font><font color="#CCCCCC"> for this alright so demo in the</font>

385
00:16:38,440 --> 00:16:42,910
event that<font color="#E5E5E5"> you</font><font color="#CCCCCC"> actually want to try</font><font color="#E5E5E5"> this</font>

386
00:16:40,029 --> 00:16:45,360
out<font color="#CCCCCC"> on</font><font color="#E5E5E5"> your own to the left is a QR</font><font color="#CCCCCC"> code</font>

387
00:16:42,910 --> 00:16:50,260
for TF classify which is an<font color="#CCCCCC"> android app</font>

388
00:16:45,360 --> 00:16:54,610
to the right is something is a it's an

389
00:16:50,260 --> 00:16:57,339
adversarial patch<font color="#CCCCCC"> it has been formulated</font>

390
00:16:54,610 --> 00:17:00,339
specifically to be<font color="#E5E5E5"> registered as a</font>

391
00:16:57,339 --> 00:17:02,890
toaster<font color="#CCCCCC"> does</font><font color="#E5E5E5"> that look like a toaster to</font>

392
00:17:00,339 --> 00:17:05,049
you<font color="#CCCCCC"> a little bit a little</font><font color="#E5E5E5"> bit like a</font>

393
00:17:02,890 --> 00:17:06,879
toaster not completely like a toaster I

394
00:17:05,049 --> 00:17:14,530
wouldn't<font color="#CCCCCC"> recognize</font><font color="#E5E5E5"> that as a toaster</font>

395
00:17:06,880 --> 00:17:18,370
I like that sir<font color="#CCCCCC"> alright so demo right we</font>

396
00:17:14,530 --> 00:17:23,859
have<font color="#CCCCCC"> TF classify pair of glasses</font><font color="#E5E5E5"> that's</font>

397
00:17:18,369 --> 00:17:27,609
about<font color="#CCCCCC"> 60 percent 60 to 70%</font><font color="#E5E5E5"> we have the</font>

398
00:17:23,859 --> 00:17:33,040
patch the<font color="#CCCCCC"> patch is a toaster at about</font>

399
00:17:27,609 --> 00:17:35,290
<font color="#CCCCCC">30% that's</font><font color="#E5E5E5"> not a toaster and then</font><font color="#CCCCCC"> I have</font>

400
00:17:33,040 --> 00:17:38,260
a duo souvenir and<font color="#E5E5E5"> that's a granny smith</font>

401
00:17:35,290 --> 00:17:41,379
apple<font color="#E5E5E5"> right</font><font color="#CCCCCC"> EF this was kind of like</font><font color="#E5E5E5"> a</font>

402
00:17:38,260 --> 00:17:43,300
remark<font color="#E5E5E5"> about TF classify it was a it was</font>

403
00:17:41,380 --> 00:17:45,090
trained<font color="#E5E5E5"> on very</font><font color="#CCCCCC"> limited data so some</font>

404
00:17:43,300 --> 00:17:47,158
things<font color="#E5E5E5"> that it may recognize</font>

405
00:17:45,090 --> 00:17:51,139
<font color="#CCCCCC">our may or may not be actually accurate</font>

406
00:17:47,159 --> 00:17:51,140
<font color="#E5E5E5">but it does</font><font color="#CCCCCC"> recognize the toaster</font>

407
00:17:53,210 --> 00:17:58,559
references<font color="#CCCCCC"> I pulled a bunch of papers</font>

408
00:17:56,460 --> 00:18:00,570
academic papers for this if there was

409
00:17:58,559 --> 00:18:03,000
something that I didn't go<font color="#E5E5E5"> into depth</font>

410
00:18:00,570 --> 00:18:04,740
enough about that's why I have these

411
00:18:03,000 --> 00:18:06,270
references here so that you<font color="#E5E5E5"> can go and</font>

412
00:18:04,740 --> 00:18:08,220
pull these papers and read them for

413
00:18:06,270 --> 00:18:09,990
yourself<font color="#CCCCCC"> to</font><font color="#E5E5E5"> see I like how important</font>

414
00:18:08,220 --> 00:18:12,270
these are<font color="#CCCCCC"> right cuz it's really</font><font color="#E5E5E5"> hard to</font>

415
00:18:09,990 --> 00:18:17,520
hit on all of the nuances<font color="#CCCCCC"> in</font><font color="#E5E5E5"> 25 minutes</font>

416
00:18:12,270 --> 00:18:19,080
<font color="#E5E5E5">there if you like machine learning</font><font color="#CCCCCC"> and</font>

417
00:18:17,520 --> 00:18:21,539
you're in<font color="#E5E5E5"> cybersecurity and you have no</font>

418
00:18:19,080 --> 00:18:23,939
idea<font color="#CCCCCC"> where to get started I really love</font>

419
00:18:21,539 --> 00:18:26,070
this<font color="#CCCCCC"> github page because it includes so</font>

420
00:18:23,940 --> 00:18:30,090
<font color="#CCCCCC">many resources</font><font color="#E5E5E5"> of machine learning</font><font color="#CCCCCC"> for</font>

421
00:18:26,070 --> 00:18:31,200
<font color="#E5E5E5">cybersecurity</font><font color="#CCCCCC"> data</font><font color="#E5E5E5"> science in a box if</font>

422
00:18:30,090 --> 00:18:33,750
you just want to<font color="#E5E5E5"> learn about data</font>

423
00:18:31,200 --> 00:18:37,049
science<font color="#CCCCCC"> and then and rue-ing's machine</font>

424
00:18:33,750 --> 00:18:39,149
learning course<font color="#E5E5E5"> is like the</font><font color="#CCCCCC"> go-to</font><font color="#E5E5E5"> course</font>

425
00:18:37,049 --> 00:18:40,799
for machine learning<font color="#CCCCCC"> right from Stanford</font>

426
00:18:39,149 --> 00:18:49,139
<font color="#CCCCCC">a little dated</font>

427
00:18:40,799 --> 00:18:51,510
still<font color="#E5E5E5"> great information</font><font color="#CCCCCC"> so takeaway it's</font>

428
00:18:49,140 --> 00:18:53,029
right came in late machine learning

429
00:18:51,510 --> 00:18:56,600
algorithms can be<font color="#E5E5E5"> attacked and</font>

430
00:18:53,029 --> 00:18:59,490
algorithms like humans<font color="#E5E5E5"> have blind spots</font>

431
00:18:56,600 --> 00:19:01,139
<font color="#CCCCCC">Red</font><font color="#E5E5E5"> Team your algorithms to increase</font>

432
00:18:59,490 --> 00:19:03,419
robustness<font color="#E5E5E5"> right we want to be strong</font>

433
00:19:01,140 --> 00:19:05,370
<font color="#E5E5E5">against possible attackers we don't want</font>

434
00:19:03,419 --> 00:19:06,840
them<font color="#E5E5E5"> reprogram our reprogramming our</font>

435
00:19:05,370 --> 00:19:09,678
machine learning<font color="#E5E5E5"> algorithms that's kind</font>

436
00:19:06,840 --> 00:19:12,449
of<font color="#E5E5E5"> dangerous</font><font color="#CCCCCC"> so like sequel injection</font>

437
00:19:09,679 --> 00:19:14,399
<font color="#E5E5E5">classifiers require input validation</font>

438
00:19:12,450 --> 00:19:16,110
right<font color="#E5E5E5"> don't trust your user to just give</font>

439
00:19:14,399 --> 00:19:18,989
information the<font color="#E5E5E5"> classifier is going to</font>

440
00:19:16,110 --> 00:19:20,580
use to continue<font color="#E5E5E5"> to update make sure that</font>

441
00:19:18,990 --> 00:19:23,850
<font color="#E5E5E5">you have some kind of input validation</font>

442
00:19:20,580 --> 00:19:26,970
or some kind<font color="#CCCCCC"> of defense mechanism in an</font>

443
00:19:23,850 --> 00:19:29,070
adversarial environment and again<font color="#CCCCCC"> my</font>

444
00:19:26,970 --> 00:19:30,659
<font color="#E5E5E5">name</font><font color="#CCCCCC"> is Heather Lawrence</font><font color="#E5E5E5"> I do data</font>

445
00:19:29,070 --> 00:19:33,539
science at<font color="#CCCCCC"> nari and you could get</font><font color="#E5E5E5"> these</font>

446
00:19:30,659 --> 00:19:35,070
slides<font color="#E5E5E5"> at this link right here if there</font>

447
00:19:33,539 --> 00:19:38,850
are<font color="#CCCCCC"> any questions</font><font color="#E5E5E5"> I would love to take</font>

448
00:19:35,070 --> 00:19:40,870
them at this<font color="#E5E5E5"> time all right</font><font color="#CCCCCC"> let me work</font>

449
00:19:38,850 --> 00:19:43,370
from<font color="#E5E5E5"> the back forward</font>

450
00:19:40,870 --> 00:19:45,620
so you mentioned<font color="#E5E5E5"> current research</font>

451
00:19:43,370 --> 00:19:47,389
<font color="#E5E5E5">they're testing against AWS and Google</font>

452
00:19:45,620 --> 00:19:48,739
<font color="#CCCCCC">cloud</font><font color="#E5E5E5"> and stuff like that and I think</font>

453
00:19:47,390 --> 00:19:51,049
<font color="#E5E5E5">everybody in here</font><font color="#CCCCCC"> probably knows the new</font>

454
00:19:48,740 --> 00:19:52,940
hotness on<font color="#E5E5E5"> the end point is your machine</font>

455
00:19:51,049 --> 00:19:56,030
learning algorithms abandoning signature

456
00:19:52,940 --> 00:19:57,049
your crowd strikes<font color="#E5E5E5"> silence and game do</font>

457
00:19:56,030 --> 00:19:58,190
you know of any<font color="#E5E5E5"> research that's</font>

458
00:19:57,049 --> 00:20:00,590
currently<font color="#E5E5E5"> going</font><font color="#CCCCCC"> on</font><font color="#E5E5E5"> that's kind of</font>

459
00:19:58,190 --> 00:20:02,690
targeting kind of circumventing that

460
00:20:00,590 --> 00:20:04,340
<font color="#E5E5E5">endpoint protection or were those</font>

461
00:20:02,690 --> 00:20:08,270
<font color="#E5E5E5">machine learning algorithms or using it</font>

462
00:20:04,340 --> 00:20:12,590
kind<font color="#E5E5E5"> of I guess</font><font color="#CCCCCC"> attack that stuff so I</font>

463
00:20:08,270 --> 00:20:15,020
can't speak<font color="#CCCCCC"> definitively on how they</font>

464
00:20:12,590 --> 00:20:17,480
work<font color="#E5E5E5"> mostly because the how they work is</font>

465
00:20:15,020 --> 00:20:20,870
the<font color="#E5E5E5"> bread and</font><font color="#CCCCCC"> butter</font><font color="#E5E5E5"> crown jewels</font>

466
00:20:17,480 --> 00:20:24,410
you know IP that they protect right how

467
00:20:20,870 --> 00:20:27,139
they do it<font color="#CCCCCC"> I do know that I am</font><font color="#E5E5E5"> currently</font>

468
00:20:24,410 --> 00:20:29,860
<font color="#CCCCCC">working on research in</font><font color="#E5E5E5"> this</font><font color="#CCCCCC"> area for</font>

469
00:20:27,140 --> 00:20:32,780
information<font color="#E5E5E5"> security I just got a</font>

470
00:20:29,860 --> 00:20:35,600
$100,000 grant from Cisco in order to

471
00:20:32,780 --> 00:20:38,660
complete this research<font color="#CCCCCC"> what were the the</font>

472
00:20:35,600 --> 00:20:40,070
premise<font color="#CCCCCC"> behind</font><font color="#E5E5E5"> it is</font><font color="#CCCCCC"> that we are</font><font color="#E5E5E5"> we</font><font color="#CCCCCC"> have</font>

473
00:20:38,660 --> 00:20:42,799
an enterprise<font color="#E5E5E5"> network set up through</font>

474
00:20:40,070 --> 00:20:44,240
docker<font color="#E5E5E5"> and a VPN</font><font color="#CCCCCC"> connection and we're</font>

475
00:20:42,799 --> 00:20:47,600
trying to figure<font color="#CCCCCC"> out if you</font><font color="#E5E5E5"> can use</font><font color="#CCCCCC"> a</font>

476
00:20:44,240 --> 00:20:49,790
classifier to<font color="#E5E5E5"> fool the machine learning</font>

477
00:20:47,600 --> 00:20:53,510
algorithm on the inside<font color="#E5E5E5"> / that's using</font>

478
00:20:49,790 --> 00:20:55,370
an<font color="#E5E5E5"> NG</font><font color="#CCCCCC"> FW</font><font color="#E5E5E5"> to block IP addresses</font><font color="#CCCCCC"> so</font><font color="#E5E5E5"> we are</font>

479
00:20:53,510 --> 00:20:57,110
<font color="#E5E5E5">trying to like there is movement in this</font>

480
00:20:55,370 --> 00:21:03,678
area to apply<font color="#CCCCCC"> it directly</font><font color="#E5E5E5"> to information</font>

481
00:20:57,110 --> 00:21:05,990
<font color="#CCCCCC">security yes sir so on the research</font><font color="#E5E5E5"> that</font>

482
00:21:03,679 --> 00:21:08,390
<font color="#E5E5E5">you've</font><font color="#CCCCCC"> done so far the wiggly reporting</font>

483
00:21:05,990 --> 00:21:09,890
on<font color="#E5E5E5"> is this basically poisoning the</font>

484
00:21:08,390 --> 00:21:10,970
original data<font color="#E5E5E5"> set or could have any of</font>

485
00:21:09,890 --> 00:21:15,140
this be applied<font color="#E5E5E5"> as a</font><font color="#CCCCCC"> man-in-the-middle</font>

486
00:21:10,970 --> 00:21:18,140
<font color="#CCCCCC">and doing this in real time pausing the</font>

487
00:21:15,140 --> 00:21:20,120
results in a sense<font color="#E5E5E5"> so it is kind of</font>

488
00:21:18,140 --> 00:21:22,400
fuzzing<font color="#CCCCCC"> the results right</font><font color="#E5E5E5"> when you're</font>

489
00:21:20,120 --> 00:21:24,770
clear querying the<font color="#E5E5E5"> Oracle you're kind of</font>

490
00:21:22,400 --> 00:21:26,360
trying<font color="#CCCCCC"> to determine how the classifier</font>

491
00:21:24,770 --> 00:21:28,610
is going to react<font color="#CCCCCC"> so you're giving it</font>

492
00:21:26,360 --> 00:21:31,459
data and it's like is it<font color="#CCCCCC"> a</font><font color="#E5E5E5"> panda is it</font>

493
00:21:28,610 --> 00:21:33,830
not a panda<font color="#CCCCCC"> so it is kind of like</font>

494
00:21:31,460 --> 00:21:37,790
fuzzing in real time but it depends on

495
00:21:33,830 --> 00:21:41,178
<font color="#E5E5E5">how the algorithm is implemented right</font>

496
00:21:37,790 --> 00:21:43,070
so some algorithms do batch so it's<font color="#E5E5E5"> it</font>

497
00:21:41,179 --> 00:21:45,049
<font color="#E5E5E5">gets like five minutes of data updates</font>

498
00:21:43,070 --> 00:21:47,840
the algorithm and<font color="#E5E5E5"> then goes on that and</font>

499
00:21:45,049 --> 00:21:50,090
<font color="#CCCCCC">sometimes it's on-the-fly instantaneous</font>

500
00:21:47,840 --> 00:21:52,159
so it kind of<font color="#E5E5E5"> matters on how</font><font color="#CCCCCC"> it's set up</font>

501
00:21:50,090 --> 00:21:53,740
<font color="#E5E5E5">in the</font><font color="#CCCCCC"> backend</font><font color="#E5E5E5"> yes sir</font>

502
00:21:52,160 --> 00:21:55,029
all right<font color="#E5E5E5"> Heather thank you</font>

503
00:21:53,740 --> 00:21:57,010
<font color="#CCCCCC">we got to</font><font color="#E5E5E5"> get the next speaker in here</font>

504
00:21:55,029 --> 00:22:01,080
<font color="#E5E5E5">I'm sure</font><font color="#CCCCCC"> you'll be around answering your</font>

505
00:21:57,010 --> 00:22:01,080
questions outside the<font color="#CCCCCC"> ring</font><font color="#E5E5E5"> thank you</font>

506
00:22:01,290 --> 00:22:06,849
[Applause]

