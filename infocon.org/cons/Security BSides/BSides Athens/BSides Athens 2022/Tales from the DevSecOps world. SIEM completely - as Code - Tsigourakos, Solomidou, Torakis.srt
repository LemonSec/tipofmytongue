1
00:00:06,960 --> 00:00:08,400
hello people

2
00:00:08,400 --> 00:00:10,080
i'm gender rocky security engineer at

3
00:00:10,080 --> 00:00:11,519
scrooge

4
00:00:11,519 --> 00:00:13,440
in this presentation we're gonna talk

5
00:00:13,440 --> 00:00:16,320
about provisioning a cm with com and

6
00:00:16,320 --> 00:00:17,760
about the whole thing with our

7
00:00:17,760 --> 00:00:19,520
infrastructure is called trend and the

8
00:00:19,520 --> 00:00:21,039
workloads it suggests sometimes the

9
00:00:21,039 --> 00:00:23,760
securities

10
00:00:24,080 --> 00:00:26,560
basically to introduce the concept of cm

11
00:00:26,560 --> 00:00:28,800
is the thing that might inform us if

12
00:00:28,800 --> 00:00:31,119
we're getting hacked and consists of

13
00:00:31,119 --> 00:00:33,920
four basic components

14
00:00:33,920 --> 00:00:35,760
first of all the search engine that

15
00:00:35,760 --> 00:00:37,760
stores and searches the logs and

16
00:00:37,760 --> 00:00:40,000
generally does the heavy lifting

17
00:00:40,000 --> 00:00:41,760
the various data shippers and the other

18
00:00:41,760 --> 00:00:43,920
collectors that deliver the logs to the

19
00:00:43,920 --> 00:00:45,360
system

20
00:00:45,360 --> 00:00:47,520
an engine that does log correlations

21
00:00:47,520 --> 00:00:51,199
depending on specific rules exceptions

22
00:00:51,199 --> 00:00:52,559
and finally

23
00:00:52,559 --> 00:00:54,480
a system that

24
00:00:54,480 --> 00:00:56,960
alerts us on successful correlations in

25
00:00:56,960 --> 00:01:00,239
various ways like emails or slack

26
00:01:00,239 --> 00:01:02,800
or whatever

27
00:01:03,600 --> 00:01:06,640
at scrooge we use an elastic sim

28
00:01:06,640 --> 00:01:09,119
with kibana elastic agents and that's a

29
00:01:09,119 --> 00:01:11,680
kind of stuff our data sources vary from

30
00:01:11,680 --> 00:01:14,880
aws to openlda so it contains all kinds

31
00:01:14,880 --> 00:01:15,920
of things

32
00:01:15,920 --> 00:01:18,400
finally we use a very small project

33
00:01:18,400 --> 00:01:20,080
priacl

34
00:01:20,080 --> 00:01:21,200
which has

35
00:01:21,200 --> 00:01:25,479
alerts and command triggers

36
00:01:26,000 --> 00:01:27,840
so here we play a c completely from

37
00:01:27,840 --> 00:01:31,600
scratch but in our brains

38
00:01:32,320 --> 00:01:34,000
at scrooge we use kubernetes with a

39
00:01:34,000 --> 00:01:36,479
pretty standard open source setup like

40
00:01:36,479 --> 00:01:39,680
nginx asset manager where with let's

41
00:01:39,680 --> 00:01:42,799
certificates external dns

42
00:01:42,799 --> 00:01:44,720
generally that kind of stuff

43
00:01:44,720 --> 00:01:46,640
generally

44
00:01:46,640 --> 00:01:49,119
we use heavily tested stuff that work

45
00:01:49,119 --> 00:01:52,960
well both on premise and on cloud

46
00:01:53,200 --> 00:01:56,240
so to deploy the sim we use an open

47
00:01:56,240 --> 00:01:58,960
source project called blue bar created a

48
00:01:58,960 --> 00:02:01,200
while ago by calligram

49
00:02:01,200 --> 00:02:03,520
the repository consists of teraform

50
00:02:03,520 --> 00:02:05,680
modules and examples that deploy

51
00:02:05,680 --> 00:02:07,759
elasticsearch kibana and the rest using

52
00:02:07,759 --> 00:02:09,440
help

53
00:02:09,440 --> 00:02:11,360
the project is inspired from redbarn

54
00:02:11,360 --> 00:02:14,000
another terraform level for offensive

55
00:02:14,000 --> 00:02:17,360
cloud infrastructure such as c2 systems

56
00:02:17,360 --> 00:02:20,640
early directors bailout servers and such

57
00:02:20,640 --> 00:02:23,280
and it works on all kinds of branded

58
00:02:23,280 --> 00:02:24,959
clusters like from minicube to cloud

59
00:02:24,959 --> 00:02:26,400
miner services

60
00:02:26,400 --> 00:02:28,879
anything goes

61
00:02:28,879 --> 00:02:30,480
this is how the empty bed where

62
00:02:30,480 --> 00:02:33,200
everything will get blown looks like

63
00:02:33,200 --> 00:02:34,959
and this is uh

64
00:02:34,959 --> 00:02:36,800
how the complete picture

65
00:02:36,800 --> 00:02:39,680
looks like and the deployed services

66
00:02:39,680 --> 00:02:41,280
that get there

67
00:02:41,280 --> 00:02:42,319
so

68
00:02:42,319 --> 00:02:45,440
all these services get a tls enabled

69
00:02:45,440 --> 00:02:46,800
endpoint

70
00:02:46,800 --> 00:02:48,720
for us to reach and

71
00:02:48,720 --> 00:02:51,440
consume and also they their

72
00:02:51,440 --> 00:02:53,200
interconnections between them

73
00:02:53,200 --> 00:02:56,480
are all tier less enabled

74
00:02:57,040 --> 00:02:59,120
finally

75
00:02:59,120 --> 00:03:01,519
this way we end up with a default cm

76
00:03:01,519 --> 00:03:03,440
deployment that has a learning command

77
00:03:03,440 --> 00:03:05,680
triggering dashboards and exotic load

78
00:03:05,680 --> 00:03:07,120
connection

79
00:03:07,120 --> 00:03:07,840
so

80
00:03:07,840 --> 00:03:09,920
now george will explain to you how to

81
00:03:09,920 --> 00:03:12,640
configure the elastic stack as code

82
00:03:12,640 --> 00:03:13,360
hi

83
00:03:13,360 --> 00:03:14,959
this is george

84
00:03:14,959 --> 00:03:16,879
i'm a security engineer at scrooge and

85
00:03:16,879 --> 00:03:18,800
we're gonna talk about configuring the

86
00:03:18,800 --> 00:03:22,480
elastic stack as code

87
00:03:22,640 --> 00:03:24,319
logs

88
00:03:24,319 --> 00:03:26,400
logs are important

89
00:03:26,400 --> 00:03:28,400
they are generated by services and

90
00:03:28,400 --> 00:03:29,680
applications

91
00:03:29,680 --> 00:03:31,920
these logs provide information for what

92
00:03:31,920 --> 00:03:33,840
is happening right now and this kind of

93
00:03:33,840 --> 00:03:35,680
information needs to be transformed to

94
00:03:35,680 --> 00:03:37,440
provide a value to us

95
00:03:37,440 --> 00:03:39,920
or an administrator

96
00:03:39,920 --> 00:03:41,599
bits and fluency

97
00:03:41,599 --> 00:03:44,159
data shippers and data collectors are

98
00:03:44,159 --> 00:03:46,480
used to gather and push this logs

99
00:03:46,480 --> 00:03:48,560
these sets of data are simple elastic

100
00:03:48,560 --> 00:03:51,200
indices or indexes

101
00:03:51,200 --> 00:03:53,519
an index has a structure predefined by

102
00:03:53,519 --> 00:03:55,760
an index template and the incoming data

103
00:03:55,760 --> 00:03:57,920
are enforced much destruction

104
00:03:57,920 --> 00:03:59,640
the incoming data might need some

105
00:03:59,640 --> 00:04:01,840
transformations and this is achieved by

106
00:04:01,840 --> 00:04:04,080
ingest pipelines in steps using

107
00:04:04,080 --> 00:04:05,519
processors

108
00:04:05,519 --> 00:04:07,680
a processor might be a simple addition

109
00:04:07,680 --> 00:04:08,799
of a field

110
00:04:08,799 --> 00:04:11,680
or a deletion or a modification or a

111
00:04:11,680 --> 00:04:13,120
calculator

112
00:04:13,120 --> 00:04:15,040
our indexes can include data retention

113
00:04:15,040 --> 00:04:17,839
policies in defined phases

114
00:04:17,839 --> 00:04:21,040
the faces are hot warm cold and then

115
00:04:21,040 --> 00:04:22,960
delicious

116
00:04:22,960 --> 00:04:26,320
finally snapshots are taken regularly as

117
00:04:26,320 --> 00:04:27,759
daily backups

118
00:04:27,759 --> 00:04:29,680
and all of these components

119
00:04:29,680 --> 00:04:32,160
of course can be configured from kibana

120
00:04:32,160 --> 00:04:34,639
but it has to be done every time a new

121
00:04:34,639 --> 00:04:37,280
setup is deployed so we create a

122
00:04:37,280 --> 00:04:39,840
structured portable and auditable way to

123
00:04:39,840 --> 00:04:42,000
maintain these configurations as code

124
00:04:42,000 --> 00:04:45,120
and do it only once

125
00:04:46,639 --> 00:04:49,440
alright the same applies for users roles

126
00:04:49,440 --> 00:04:50,880
and privileges

127
00:04:50,880 --> 00:04:55,280
for the cluster and kibana dashboards

128
00:04:55,280 --> 00:04:59,360
rows have specific and can have multiple

129
00:04:59,360 --> 00:05:01,039
privileges

130
00:05:01,039 --> 00:05:04,720
a user might also hold multiple rows to

131
00:05:04,720 --> 00:05:06,880
perform its action

132
00:05:06,880 --> 00:05:08,000
everything

133
00:05:08,000 --> 00:05:10,560
can be configured of course by clicking

134
00:05:10,560 --> 00:05:13,039
and dragging dragging and dropping and

135
00:05:13,039 --> 00:05:14,880
huffing from gibbana

136
00:05:14,880 --> 00:05:16,880
but

137
00:05:16,880 --> 00:05:19,600
if you do it as code you do it only once

138
00:05:19,600 --> 00:05:21,440
and you have the ability to make to

139
00:05:21,440 --> 00:05:25,280
maintain it to review it and to monitor

140
00:05:25,280 --> 00:05:27,919
any change

141
00:05:29,120 --> 00:05:32,080
the elastic stack has multiple moving

142
00:05:32,080 --> 00:05:34,400
parts and its deployment includes

143
00:05:34,400 --> 00:05:36,400
organization specifics

144
00:05:36,400 --> 00:05:39,440
so you have to set up something

145
00:05:39,440 --> 00:05:43,440
according to each organization's needs

146
00:05:43,440 --> 00:05:45,600
these questions might look familiar to

147
00:05:45,600 --> 00:05:46,639
you

148
00:05:46,639 --> 00:05:49,199
tracking rolling back changes

149
00:05:49,199 --> 00:05:52,000
maintaining backing up logs mounting

150
00:05:52,000 --> 00:05:55,360
users adding removing whatever clicking

151
00:05:55,360 --> 00:05:57,360
around banana can be from tedious

152
00:05:57,360 --> 00:05:58,560
impossible

153
00:05:58,560 --> 00:06:01,039
so we try to solve all of them with the

154
00:06:01,039 --> 00:06:04,159
s code approach

155
00:06:05,280 --> 00:06:08,319
now for a real example

156
00:06:08,319 --> 00:06:10,319
this is an actual module

157
00:06:10,319 --> 00:06:12,639
created to define a composable index

158
00:06:12,639 --> 00:06:14,000
template

159
00:06:14,000 --> 00:06:17,759
or a legacy one you can set up its type

160
00:06:17,759 --> 00:06:18,560
name

161
00:06:18,560 --> 00:06:22,720
and policy the alias the intervals and

162
00:06:22,720 --> 00:06:24,080
the charts

163
00:06:24,080 --> 00:06:26,720
and patterns shown on kibana dashboards

164
00:06:26,720 --> 00:06:30,080
even the pipeline and the mappings

165
00:06:30,080 --> 00:06:34,960
of special fields such as an ip address

166
00:06:34,960 --> 00:06:37,440
some fields such as the final pipeline

167
00:06:37,440 --> 00:06:40,080
and the static template mappings are of

168
00:06:40,080 --> 00:06:42,400
course optional

169
00:06:42,400 --> 00:06:44,080
this way you can

170
00:06:44,080 --> 00:06:48,400
configure and create a new template only

171
00:06:48,400 --> 00:06:50,080
as code

172
00:06:50,080 --> 00:06:52,160
down below you can find an open source

173
00:06:52,160 --> 00:06:53,440
telephone provider for these

174
00:06:53,440 --> 00:06:55,759
configurations from field baker and we

175
00:06:55,759 --> 00:07:00,160
created modules based on this provider

176
00:07:00,240 --> 00:07:03,520
the snapshot module the snapshot module

177
00:07:03,520 --> 00:07:06,080
defines the chrome format schedule

178
00:07:06,080 --> 00:07:08,400
that the snapshot name where to store

179
00:07:08,400 --> 00:07:10,080
the backup and the indices that need to

180
00:07:10,080 --> 00:07:11,840
be backed up

181
00:07:11,840 --> 00:07:14,479
the index lifecycle management module

182
00:07:14,479 --> 00:07:19,199
defines or ilm defines the faces the hot

183
00:07:19,199 --> 00:07:22,240
wormhole and deletion alongside the max

184
00:07:22,240 --> 00:07:23,440
size

185
00:07:23,440 --> 00:07:26,319
and the days passed for its phase

186
00:07:26,319 --> 00:07:29,840
that means if we reach a threshold of

187
00:07:29,840 --> 00:07:32,080
gigabytes or

188
00:07:32,080 --> 00:07:34,080
a date

189
00:07:34,080 --> 00:07:37,280
we can move on to the next phase the ilm

190
00:07:37,280 --> 00:07:41,359
module might need to wait for a snapshot

191
00:07:41,520 --> 00:07:43,840
pipeline the pipeline module specifies

192
00:07:43,840 --> 00:07:45,599
some basic fields such as name

193
00:07:45,599 --> 00:07:47,440
description

194
00:07:47,440 --> 00:07:50,479
the time is the type is a custom field

195
00:07:50,479 --> 00:07:52,560
because or module can accept a json

196
00:07:52,560 --> 00:07:56,000
structure or an inline penis script as a

197
00:07:56,000 --> 00:07:57,360
processor

198
00:07:57,360 --> 00:08:00,000
some new lines and double slashes need

199
00:08:00,000 --> 00:08:03,280
escaping to work their magic with both

200
00:08:03,280 --> 00:08:05,360
processors and it's not the most

201
00:08:05,360 --> 00:08:07,759
beautiful thing i know but at the moment

202
00:08:07,759 --> 00:08:11,520
it does a job and it does it pretty well

203
00:08:11,520 --> 00:08:12,800
finally

204
00:08:12,800 --> 00:08:15,120
the actual processor

205
00:08:15,120 --> 00:08:18,160
this is uh the heart of the pipeline

206
00:08:18,160 --> 00:08:20,960
this processor uses both a json and a

207
00:08:20,960 --> 00:08:23,520
painless script in two separate files

208
00:08:23,520 --> 00:08:25,520
for cleaner code

209
00:08:25,520 --> 00:08:28,639
and better reviews probably we could

210
00:08:28,639 --> 00:08:31,599
just output a whole script in one line

211
00:08:31,599 --> 00:08:34,240
but this is more readable this processor

212
00:08:34,240 --> 00:08:36,719
for example includes a group pattern

213
00:08:36,719 --> 00:08:39,839
that maps open adapt log fields to

214
00:08:39,839 --> 00:08:41,839
and a payload script that adds and

215
00:08:41,839 --> 00:08:43,919
calculates a new field if the event was

216
00:08:43,919 --> 00:08:46,480
captured in companies of hours

217
00:08:46,480 --> 00:08:50,240
so with this script you can catch actors

218
00:08:50,240 --> 00:08:52,240
if they work

219
00:08:52,240 --> 00:08:52,839
at

220
00:08:52,839 --> 00:08:56,560
midnight thank you now is kiki

221
00:08:56,560 --> 00:08:58,720
hello i'm kj

222
00:08:58,720 --> 00:09:00,720
and i work as a security engineer at

223
00:09:00,720 --> 00:09:02,000
schools

224
00:09:02,000 --> 00:09:04,320
and in this part i'm going to explain to

225
00:09:04,320 --> 00:09:06,560
you how we manage to keep elastic cm

226
00:09:06,560 --> 00:09:11,439
runes exceptions and lists as follows

227
00:09:11,519 --> 00:09:13,440
let me give you an example to explain

228
00:09:13,440 --> 00:09:16,080
how exactly they work

229
00:09:16,080 --> 00:09:18,480
let's say that we want to create a rule

230
00:09:18,480 --> 00:09:20,959
to catch any dns that is not the

231
00:09:20,959 --> 00:09:22,480
cloudflare

232
00:09:22,480 --> 00:09:25,839
and the exception container contains

233
00:09:25,839 --> 00:09:29,360
two items so as not to trigger the rule

234
00:09:29,360 --> 00:09:32,880
only when a chromecast device is going

235
00:09:32,880 --> 00:09:34,399
to google dns

236
00:09:34,399 --> 00:09:37,200
and also when the traffic is coming from

237
00:09:37,200 --> 00:09:39,519
guest wi-fi network

238
00:09:39,519 --> 00:09:43,040
the ips of chromecast devices are passed

239
00:09:43,040 --> 00:09:47,040
as values in the list item

240
00:09:47,200 --> 00:09:50,560
structure of elastic rules is as defined

241
00:09:50,560 --> 00:09:53,839
by official record of elastic detection

242
00:09:53,839 --> 00:09:55,120
rules

243
00:09:55,120 --> 00:09:58,399
rules are expressed as target files

244
00:09:58,399 --> 00:10:00,480
describing the rule giving some

245
00:10:00,480 --> 00:10:02,880
necessary properties such as the name of

246
00:10:02,880 --> 00:10:06,880
the rule a time range from one two sides

247
00:10:06,880 --> 00:10:09,120
indices for example five million

248
00:10:09,120 --> 00:10:11,760
patentee and the type of the rule that

249
00:10:11,760 --> 00:10:15,120
can be either a queen a threshold rule

250
00:10:15,120 --> 00:10:18,560
or an eql rule

251
00:10:18,560 --> 00:10:21,920
and here a very interesting thing is the

252
00:10:21,920 --> 00:10:25,200
reference of exception containers

253
00:10:25,200 --> 00:10:27,519
keep in mind that in this way we cannot

254
00:10:27,519 --> 00:10:30,240
create exceptions or lists with this in

255
00:10:30,240 --> 00:10:31,279
this

256
00:10:31,279 --> 00:10:33,680
so the way to overcome this is by

257
00:10:33,680 --> 00:10:35,920
creating exceptions as defined by

258
00:10:35,920 --> 00:10:38,320
elastic exception api which can be

259
00:10:38,320 --> 00:10:41,040
expressed as jamming files the yummy

260
00:10:41,040 --> 00:10:43,279
file contains the part of the exception

261
00:10:43,279 --> 00:10:46,160
container in which simply we describe

262
00:10:46,160 --> 00:10:47,519
the items

263
00:10:47,519 --> 00:10:50,560
where every entry does have a log field

264
00:10:50,560 --> 00:10:53,200
and a value or a list to get it set

265
00:10:53,200 --> 00:10:55,680
against

266
00:10:55,760 --> 00:10:58,240
finishing the s-code part the lists

267
00:10:58,240 --> 00:11:00,000
don't innovate they are defined by

268
00:11:00,000 --> 00:11:02,560
elastic session api and expressed as

269
00:11:02,560 --> 00:11:05,360
yummy files likewise the exceptions

270
00:11:05,360 --> 00:11:07,279
the structure of the list

271
00:11:07,279 --> 00:11:10,640
consists of list containers and items a

272
00:11:10,640 --> 00:11:14,000
list container describes the list items

273
00:11:14,000 --> 00:11:16,399
actually and the list items include the

274
00:11:16,399 --> 00:11:18,000
values of the container

275
00:11:18,000 --> 00:11:20,160
that is the eyepiece of the broadcast

276
00:11:20,160 --> 00:11:22,320
devices in the example

277
00:11:22,320 --> 00:11:24,240
good to mention that the interconnection

278
00:11:24,240 --> 00:11:27,200
between the item container and lists

279
00:11:27,200 --> 00:11:30,880
happen through directory structures

280
00:11:31,680 --> 00:11:34,320
as anyone could imagine maintaining such

281
00:11:34,320 --> 00:11:36,880
a complex structure for each cm rule is

282
00:11:36,880 --> 00:11:39,440
not used okay that's why infrastructure

283
00:11:39,440 --> 00:11:41,839
is one way so every scene rule is

284
00:11:41,839 --> 00:11:44,240
implemented by a terrifier provided

285
00:11:44,240 --> 00:11:46,959
abstracted by a repository template that

286
00:11:46,959 --> 00:11:49,600
manages the yaml and thumb files of

287
00:11:49,600 --> 00:11:52,079
rubrics exceptions and items

288
00:11:52,079 --> 00:11:53,920
hence the only thing you have to do is

289
00:11:53,920 --> 00:11:57,040
to write your own dom file and jump file

290
00:11:57,040 --> 00:11:59,440
all this code is open source

291
00:11:59,440 --> 00:12:01,600
managed with github workflows for

292
00:12:01,600 --> 00:12:04,720
automatic terraform plan and applying

293
00:12:04,720 --> 00:12:06,880
integrating with the official elastic

294
00:12:06,880 --> 00:12:08,839
detection rules

295
00:12:08,839 --> 00:12:11,440
depository is of course our best friend

296
00:12:11,440 --> 00:12:14,399
to review saints management this way no

297
00:12:14,399 --> 00:12:16,160
one is able to make a change on the

298
00:12:16,160 --> 00:12:18,320
repository without being firstly

299
00:12:18,320 --> 00:12:20,800
included by the teammates

300
00:12:20,800 --> 00:12:22,800
thank you very much feel free to ask and

301
00:12:22,800 --> 00:12:25,800
canvas

