1
00:00:08,058 --> 00:00:15,030
my name is David Bianco's

2
00:00:11,099 --> 00:00:18,210
vej is a secret vote before I've done

3
00:00:15,030 --> 00:00:20,009
incident response and into detection for

4
00:00:18,210 --> 00:00:22,500
a long time and so I kind of tell the

5
00:00:20,009 --> 00:00:25,230
company how to do it how the product to

6
00:00:22,500 --> 00:00:27,240
do it Chris here is our director of data

7
00:00:25,230 --> 00:00:29,670
science would say something about

8
00:00:27,240 --> 00:00:39,300
yourself yeah I have a background in

9
00:00:29,670 --> 00:00:48,510
computer science and I doing social

10
00:00:39,300 --> 00:00:53,010
network analysis so I'm like super chill

11
00:00:48,510 --> 00:00:56,519
is way possible people yeah so I want to

12
00:00:53,010 --> 00:00:57,750
study first of all as a security subject

13
00:00:56,520 --> 00:01:01,170
matter experts like an incident

14
00:00:57,750 --> 00:01:04,319
detection guy right I never really

15
00:01:01,170 --> 00:01:06,330
before in this world got that much into

16
00:01:04,319 --> 00:01:08,758
the data science aspects of it it was

17
00:01:06,330 --> 00:01:10,649
like always like you know write new

18
00:01:08,759 --> 00:01:13,080
signatures or you follow new growth

19
00:01:10,649 --> 00:01:14,820
policies or something like that to some

20
00:01:13,080 --> 00:01:17,130
network forensics and post forensics

21
00:01:14,820 --> 00:01:19,470
traced bad things but when I came to

22
00:01:17,130 --> 00:01:23,250
squirrel we do big data security

23
00:01:19,470 --> 00:01:26,548
analytics and now I make our marketing

24
00:01:23,250 --> 00:01:29,280
people very happy so I started learning

25
00:01:26,549 --> 00:01:33,960
more about the data science aspects of

26
00:01:29,280 --> 00:01:36,390
it especially the machine learning piece

27
00:01:33,960 --> 00:01:37,589
and I think the machine learning is

28
00:01:36,390 --> 00:01:39,180
actually something that I was really

29
00:01:37,590 --> 00:01:40,530
excited to be able to come and talk to

30
00:01:39,180 --> 00:01:43,680
you guys today's the thing it's a tool

31
00:01:40,530 --> 00:01:46,409
that probably most of us probably don't

32
00:01:43,680 --> 00:01:48,689
think that we are ready to use but in

33
00:01:46,409 --> 00:01:50,970
fact it is so super simple to get

34
00:01:48,689 --> 00:01:53,908
started and you can start thinking your

35
00:01:50,970 --> 00:01:56,298
computers actually give you some

36
00:01:53,909 --> 00:01:59,490
intelligent results I will say this is a

37
00:01:56,299 --> 00:02:01,860
something that crystal meat machine

38
00:01:59,490 --> 00:02:03,839
learning might seem like magic to you

39
00:02:01,860 --> 00:02:06,689
but guess what somebody else has already

40
00:02:03,840 --> 00:02:10,250
cast that spell that's all you have to

41
00:02:06,689 --> 00:02:14,190
do is use it there is machine learning

42
00:02:10,250 --> 00:02:16,680
for Python or Ruby or whatever your

43
00:02:14,190 --> 00:02:18,269
favorite languages are all that stuff is

44
00:02:16,680 --> 00:02:20,280
there and ready to go and that's what

45
00:02:18,269 --> 00:02:23,830
we're going to talk about today how you

46
00:02:20,280 --> 00:02:27,100
as a possible non probable Tom mission

47
00:02:23,830 --> 00:02:29,260
expert can actually get started apply ug

48
00:02:27,100 --> 00:02:33,100
turning to the job since we do every day

49
00:02:29,260 --> 00:02:35,200
to help you become more effective so

50
00:02:33,100 --> 00:02:37,570
that's we're going to talk about a lot

51
00:02:35,200 --> 00:02:39,310
of this is it's a combination of urban

52
00:02:37,570 --> 00:02:40,780
talking about the process of machine

53
00:02:39,310 --> 00:02:44,470
learning for incident detection we're

54
00:02:40,780 --> 00:02:47,110
also releasing into a demo tool that you

55
00:02:44,470 --> 00:02:49,780
will be able to go and say either I run

56
00:02:47,110 --> 00:02:52,180
it as is to do some machine learning it

57
00:02:49,780 --> 00:02:55,510
gets your HTTP proxy logs to find evil

58
00:02:52,180 --> 00:02:58,030
or possibly adapt it to some other logs

59
00:02:55,510 --> 00:03:01,570
or even other processes that you have

60
00:02:58,030 --> 00:03:06,670
where you want to do some binary

61
00:03:01,570 --> 00:03:09,790
classification so when's the last time

62
00:03:06,670 --> 00:03:11,470
you heard this it's best practice to

63
00:03:09,790 --> 00:03:14,170
review your logs every day who's ever

64
00:03:11,470 --> 00:03:17,050
heard that raise your hand all right

65
00:03:14,170 --> 00:03:19,839
raise a paw and keep up it's mine he

66
00:03:17,050 --> 00:03:23,860
loves come on all right now take your

67
00:03:19,840 --> 00:03:28,870
hands down if you are still able to do

68
00:03:23,860 --> 00:03:30,370
that today in review all your logs every

69
00:03:28,870 --> 00:03:33,430
day there's only there's a lot fewer

70
00:03:30,370 --> 00:03:35,920
ends up now right and why is that well

71
00:03:33,430 --> 00:03:38,700
of course we have too many logs today

72
00:03:35,920 --> 00:03:41,018
too many different types too many

73
00:03:38,700 --> 00:03:43,570
instances of the same log type is just

74
00:03:41,019 --> 00:03:46,060
not a feasible thing to do although it

75
00:03:43,570 --> 00:03:48,250
really is good advice if you were able

76
00:03:46,060 --> 00:03:50,200
to view all your logs put a human in

77
00:03:48,250 --> 00:03:52,840
front of them it could actually pay

78
00:03:50,200 --> 00:03:54,850
attention and concentrate enough to see

79
00:03:52,840 --> 00:03:57,010
them all the logs in the head and find

80
00:03:54,850 --> 00:04:00,120
evil things in them you probably would

81
00:03:57,010 --> 00:04:02,980
get pretty good results but you can't

82
00:04:00,120 --> 00:04:05,530
that's where this idea of the machine

83
00:04:02,980 --> 00:04:06,970
assisted analysis comes in or probably

84
00:04:05,530 --> 00:04:09,730
what I should have called this up

85
00:04:06,970 --> 00:04:12,700
practical side work isn't for security

86
00:04:09,730 --> 00:04:14,140
operations computers are really good at

87
00:04:12,700 --> 00:04:15,810
some things and humans are really good

88
00:04:14,140 --> 00:04:21,608
at others this is almost cliche right

89
00:04:15,810 --> 00:04:23,680
computers are good at repetition tasks

90
00:04:21,608 --> 00:04:26,200
large-scale test to the same thing a

91
00:04:23,680 --> 00:04:28,600
hundred thousand or a million times they

92
00:04:26,200 --> 00:04:30,250
do it quickly the algorithms I say

93
00:04:28,600 --> 00:04:33,400
algorithms work achieve you know pay

94
00:04:30,250 --> 00:04:35,650
them take six days whatever but they are

95
00:04:33,400 --> 00:04:36,729
terrible at the things that we're good

96
00:04:35,650 --> 00:04:39,580
at which is

97
00:04:36,730 --> 00:04:42,850
context and understanding humans are so

98
00:04:39,580 --> 00:04:44,560
good at finding patterns in data that we

99
00:04:42,850 --> 00:04:47,350
are even a little bit too sensitive and

100
00:04:44,560 --> 00:04:49,240
we trying to Elvis on post like where

101
00:04:47,350 --> 00:04:52,000
that pattern does not actually exist we

102
00:04:49,240 --> 00:04:54,850
actually can find it but we can take

103
00:04:52,000 --> 00:04:56,470
advantage of that we also have curiosity

104
00:04:54,850 --> 00:04:59,350
and intuition that says you know this

105
00:04:56,470 --> 00:05:01,270
isn't writing this let's follow this up

106
00:04:59,350 --> 00:05:03,880
and we have the course business

107
00:05:01,270 --> 00:05:05,650
knowledge to know hey you know these

108
00:05:03,880 --> 00:05:07,830
serve maybe two business units that

109
00:05:05,650 --> 00:05:11,229
don't ever talk they should the song

110
00:05:07,830 --> 00:05:14,260
required why are they talking right

111
00:05:11,230 --> 00:05:16,660
won't you put those together you can

112
00:05:14,260 --> 00:05:18,940
have that that's cyborg piece the

113
00:05:16,660 --> 00:05:21,430
analyst and the human acting together

114
00:05:18,940 --> 00:05:23,200
more like once you get good results from

115
00:05:21,430 --> 00:05:25,500
a massive amount of data and you can do

116
00:05:23,200 --> 00:05:28,510
it really quickly

117
00:05:25,500 --> 00:05:35,920
so here's a practical example of this of

118
00:05:28,510 --> 00:05:41,400
row HTTP log in this case this is HTTP

119
00:05:35,920 --> 00:05:41,400
log from outgoing like innovative

120
00:05:42,150 --> 00:05:46,030
analysts in this room probably already

121
00:05:44,590 --> 00:05:48,969
found out that they think this is

122
00:05:46,030 --> 00:05:51,760
probably a suspicious or malicious

123
00:05:48,970 --> 00:05:53,920
traffic because they probably looked

124
00:05:51,760 --> 00:05:56,440
just my guest they probably looked at

125
00:05:53,920 --> 00:05:58,960
post and then this domain name that

126
00:05:56,440 --> 00:06:00,730
nobody can remember or type I always

127
00:05:58,960 --> 00:06:03,090
training my new analysts that if you see

128
00:06:00,730 --> 00:06:06,430
a domain you can't remember it tightly

129
00:06:03,090 --> 00:06:09,609
it is suspicious with a few examples of

130
00:06:06,430 --> 00:06:12,190
few exceptions of like and totally

131
00:06:09,610 --> 00:06:13,840
internal things like country content

132
00:06:12,190 --> 00:06:14,620
distribution networks or something like

133
00:06:13,840 --> 00:06:16,479
that

134
00:06:14,620 --> 00:06:19,390
these shorter domains though are

135
00:06:16,480 --> 00:06:21,180
supposed to be things people remember

136
00:06:19,390 --> 00:06:23,830
and tightly equipment ads or they

137
00:06:21,180 --> 00:06:26,170
whatever clearly no one's gonna remember

138
00:06:23,830 --> 00:06:28,270
or field at pegleg right so it makes it

139
00:06:26,170 --> 00:06:29,830
a little bit suspicious it's easy

140
00:06:28,270 --> 00:06:32,440
it took me far longer to tell you about

141
00:06:29,830 --> 00:06:35,310
why I got that and it took me pretty bad

142
00:06:32,440 --> 00:06:38,590
and decided it was bad on the other hand

143
00:06:35,310 --> 00:06:40,780
what happens if you're like this you get

144
00:06:38,590 --> 00:06:44,440
this many this is only one screen how

145
00:06:40,780 --> 00:06:46,878
the whole day's worth of data you can't

146
00:06:44,440 --> 00:06:49,849
really do that it's hard

147
00:06:46,879 --> 00:06:52,520
get too many logs so the solution is to

148
00:06:49,849 --> 00:06:54,378
get rid of some of the logs so that's

149
00:06:52,520 --> 00:06:58,128
why we call art our solution is called

150
00:06:54,379 --> 00:06:59,830
clear-cut because we we got rid of a lot

151
00:06:58,129 --> 00:07:06,889
of the logs and we found the bad logs

152
00:06:59,830 --> 00:07:09,859
right here and I'm gonna turn it over

153
00:07:06,889 --> 00:07:12,319
here to Chris to talk about this the

154
00:07:09,860 --> 00:07:14,119
background and the data science pieces

155
00:07:12,319 --> 00:07:19,490
inside their bed and then I'll be

156
00:07:14,119 --> 00:07:21,499
vacuuming all right stated so I'm gonna

157
00:07:19,490 --> 00:07:24,259
talk a little bit about how we're doing

158
00:07:21,499 --> 00:07:25,999
some of the machine learning stuff again

159
00:07:24,259 --> 00:07:28,159
like all these things are built into

160
00:07:25,999 --> 00:07:29,839
libraries and we're just using them I'm

161
00:07:28,159 --> 00:07:32,779
pulling the covers a little bit back on

162
00:07:29,839 --> 00:07:35,469
the algorithms mainly to show you how to

163
00:07:32,779 --> 00:07:35,469
use them

164
00:07:40,009 --> 00:07:44,749
so what we're using here is something

165
00:07:42,289 --> 00:07:47,839
called a binary classifier which is a

166
00:07:44,749 --> 00:07:50,599
subclass supervised learning algorithm

167
00:07:47,839 --> 00:07:55,610
so supervised learning algorithm what it

168
00:07:50,599 --> 00:07:58,240
what it's trying to do is so you're

169
00:07:55,610 --> 00:08:00,379
gonna have a bunch of data does the dots

170
00:07:58,240 --> 00:08:02,379
and you're gonna have some dots that are

171
00:08:00,379 --> 00:08:05,300
warrant and some dots out of blue and

172
00:08:02,379 --> 00:08:06,860
you know those in advance those that's

173
00:08:05,300 --> 00:08:09,709
your label data set these are things

174
00:08:06,860 --> 00:08:14,329
that you know are orange and if you want

175
00:08:09,709 --> 00:08:16,789
to try to make an algorithm make a model

176
00:08:14,329 --> 00:08:19,669
that can tell you if some gray dot that

177
00:08:16,789 --> 00:08:22,219
comes in is probably orange probably

178
00:08:19,669 --> 00:08:23,748
glue and that's why it's about a binary

179
00:08:22,219 --> 00:08:26,569
classifier because there's two classes

180
00:08:23,749 --> 00:08:29,149
weren't you loop or in our case may be

181
00:08:26,569 --> 00:08:30,860
malicious and normal a lot of times

182
00:08:29,149 --> 00:08:32,990
people call these positives and

183
00:08:30,860 --> 00:08:37,310
negatives depending on the problems

184
00:08:32,990 --> 00:08:39,740
levels so we have here you know one way

185
00:08:37,309 --> 00:08:41,989
to do this in two dimensions is to just

186
00:08:39,740 --> 00:08:44,240
draw a line between the two sets and

187
00:08:41,990 --> 00:08:47,089
that's one type of classifier it's a

188
00:08:44,240 --> 00:08:49,040
linear classifier so some very

189
00:08:47,089 --> 00:08:50,880
well-known classifiers are basically

190
00:08:49,040 --> 00:08:52,529
drawing a line between your juice

191
00:08:50,880 --> 00:08:58,139
in some space you know there's

192
00:08:52,529 --> 00:09:02,399
information so you know the machine can

193
00:08:58,139 --> 00:09:04,500
learn of the function and basically

194
00:09:02,399 --> 00:09:06,300
there's this is like a recipe for doing

195
00:09:04,500 --> 00:09:09,300
machine learning right like this is kind

196
00:09:06,300 --> 00:09:10,649
of this isn't she learning itself but

197
00:09:09,300 --> 00:09:12,508
it's like what you do when you want to

198
00:09:10,649 --> 00:09:14,399
do machine learning on the set you know

199
00:09:12,509 --> 00:09:16,440
the first want to identify those

200
00:09:14,399 --> 00:09:18,420
positive and negative sample data sets

201
00:09:16,440 --> 00:09:22,050
you wanted to get a set of stuff that's

202
00:09:18,420 --> 00:09:23,880
blue and orange right you want to nina

203
00:09:22,050 --> 00:09:25,349
normalize the data you know data is

204
00:09:23,880 --> 00:09:26,670
always messy you look at this as the

205
00:09:25,350 --> 00:09:28,649
data scientist if you ever work with

206
00:09:26,670 --> 00:09:31,560
real data there's some data that you

207
00:09:28,649 --> 00:09:33,899
just want to roll by and you might want

208
00:09:31,560 --> 00:09:35,339
to add some things to the data that are

209
00:09:33,899 --> 00:09:38,069
helpful for doing this classification

210
00:09:35,339 --> 00:09:39,690
we'll talk about that a little bit so we

211
00:09:38,069 --> 00:09:41,910
want to after that we'll take those

212
00:09:39,690 --> 00:09:44,130
those dots that we know the color of

213
00:09:41,910 --> 00:09:46,639
we're going to partition those thoughts

214
00:09:44,130 --> 00:09:51,180
into two sets the training set and the

215
00:09:46,639 --> 00:09:52,139
testing set and after we do that you

216
00:09:51,180 --> 00:09:54,209
know we're going to compute some

217
00:09:52,139 --> 00:09:56,069
features on this data set to be machine

218
00:09:54,209 --> 00:09:58,229
learning we're going to train the model

219
00:09:56,069 --> 00:10:00,089
so like you know computing the features

220
00:09:58,230 --> 00:10:00,990
is a little bit of the stuff that you

221
00:10:00,089 --> 00:10:03,980
have to do yourself

222
00:10:00,990 --> 00:10:06,329
we've done it for you and this in this

223
00:10:03,980 --> 00:10:08,759
if you want to do on your own logs might

224
00:10:06,329 --> 00:10:11,579
have to do some of that training a model

225
00:10:08,759 --> 00:10:13,170
some online a Python test the model

226
00:10:11,579 --> 00:10:19,550
against the test data set to see how

227
00:10:13,170 --> 00:10:19,550
good it is that's also one line up

228
00:10:29,329 --> 00:10:40,618
the stuff the machine does not watching

229
00:10:31,829 --> 00:10:42,569
about and having all pain you know yeah

230
00:10:40,619 --> 00:10:44,189
it's expecting that you'll sign into

231
00:10:42,569 --> 00:10:50,639
Google to be able to do that but you

232
00:10:44,189 --> 00:10:58,769
know we just wanted to be like if people

233
00:10:50,639 --> 00:11:00,569
were shy about asking questions so China

234
00:10:58,769 --> 00:11:02,819
model one-line a five-month Tesla Model

235
00:11:00,569 --> 00:11:13,229
online of Python evaluate the results

236
00:11:02,819 --> 00:11:15,809
one line of Python and then you're done

237
00:11:13,230 --> 00:11:19,049
and you can go use that train model on

238
00:11:15,809 --> 00:11:20,519
real data and start classifiers so this

239
00:11:19,049 --> 00:11:22,230
is just a picture of one of those steps

240
00:11:20,519 --> 00:11:25,589
we're gonna take our data so the data

241
00:11:22,230 --> 00:11:28,259
that we've taken thank you and some

242
00:11:25,589 --> 00:11:31,079
other sources malicious data we're gonna

243
00:11:28,259 --> 00:11:32,670
get to pro HTTP log version of that for

244
00:11:31,079 --> 00:11:38,008
the normal data we've taken some data in

245
00:11:32,670 --> 00:11:39,269
our network for our examples and get all

246
00:11:38,009 --> 00:11:42,059
the labels there now we're gonna split

247
00:11:39,269 --> 00:11:45,720
it split it into a bigger training set a

248
00:11:42,059 --> 00:11:47,490
smaller test set so the feature

249
00:11:45,720 --> 00:11:49,470
extraction so that this where it starts

250
00:11:47,490 --> 00:11:53,160
getting interesting for some for you

251
00:11:49,470 --> 00:11:55,350
guys we want to give the machine as much

252
00:11:53,160 --> 00:11:57,990
of a chance as a kid to figure things

253
00:11:55,350 --> 00:11:59,549
out now we don't have to be perfect I

254
00:11:57,990 --> 00:12:01,319
think David mentioned before that you

255
00:11:59,549 --> 00:12:03,689
looked at that top-level domain or that

256
00:12:01,319 --> 00:12:05,729
domain and said this looks weird why

257
00:12:03,689 --> 00:12:08,368
does that look weird so we can use art

258
00:12:05,730 --> 00:12:10,110
our domain knowledge to help out the

259
00:12:08,369 --> 00:12:12,389
Machine a little bit a little bit markup

260
00:12:10,110 --> 00:12:13,529
machine that just take things as is boil

261
00:12:12,389 --> 00:12:14,459
the ocean and be like yeah that's

262
00:12:13,529 --> 00:12:15,929
delicious

263
00:12:14,459 --> 00:12:19,018
we're gonna give it a little bit of help

264
00:12:15,929 --> 00:12:21,269
by computing some features on the data

265
00:12:19,019 --> 00:12:23,699
that can help it out so we're going to

266
00:12:21,269 --> 00:12:26,100
do things like take that domain name

267
00:12:23,699 --> 00:12:30,889
compute how likely it is that it's

268
00:12:26,100 --> 00:12:34,949
English just call that the entropy so

269
00:12:30,889 --> 00:12:36,749
these these machine learning algorithms

270
00:12:34,949 --> 00:12:38,910
especially the the random force are

271
00:12:36,749 --> 00:12:40,030
going to use it wants everything to be a

272
00:12:38,910 --> 00:12:43,270
numeric form

273
00:12:40,030 --> 00:12:45,670
right and you saw that the record was

274
00:12:43,270 --> 00:12:49,240
not numeric in general you know there's

275
00:12:45,670 --> 00:12:52,360
the strings ATP strings there's things

276
00:12:49,240 --> 00:12:54,040
like HTTP codes which are numeric but

277
00:12:52,360 --> 00:12:56,260
they're not really American the way that

278
00:12:54,040 --> 00:13:00,069
the tree algorithm wants it to be and

279
00:12:56,260 --> 00:13:01,990
that like code 400 is not twice as much

280
00:13:00,070 --> 00:13:03,330
just go to Mars right that doesn't make

281
00:13:01,990 --> 00:13:06,460
sense

282
00:13:03,330 --> 00:13:09,340
so those are really great entities right

283
00:13:06,460 --> 00:13:11,260
so we want to renew merit types and

284
00:13:09,340 --> 00:13:14,830
strengths we're going to use this method

285
00:13:11,260 --> 00:13:18,040
that's widely used in natural language

286
00:13:14,830 --> 00:13:18,960
processing called bags bag of words bag

287
00:13:18,040 --> 00:13:21,550
of engrams

288
00:13:18,960 --> 00:13:23,620
what we're going to do is take these

289
00:13:21,550 --> 00:13:27,069
string features and enumerated type

290
00:13:23,620 --> 00:13:29,560
features and form a bag of all of them

291
00:13:27,070 --> 00:13:33,430
so the bag it is has a column of data

292
00:13:29,560 --> 00:13:36,550
and the column is okay this record was

293
00:13:33,430 --> 00:13:38,800
code 400 or it wasn't so let's go to 400

294
00:13:36,550 --> 00:13:41,290
it's a one go for this not go for

295
00:13:38,800 --> 00:13:43,569
hundreds of 0 so that's the bag and

296
00:13:41,290 --> 00:13:45,699
there's one for each code in a speedboat

297
00:13:43,570 --> 00:13:51,700
and we're going to convert have one

298
00:13:45,700 --> 00:13:53,890
column in the original data to the same

299
00:13:51,700 --> 00:13:55,780
thing with string dinner we're going to

300
00:13:53,890 --> 00:13:57,550
use this name brands things so we're

301
00:13:55,780 --> 00:14:00,280
going to pass a window over the string

302
00:13:57,550 --> 00:14:01,990
and for example if you're the picture on

303
00:14:00,280 --> 00:14:03,550
the right there's five grams so every

304
00:14:01,990 --> 00:14:06,760
five characters it's going to be a

305
00:14:03,550 --> 00:14:09,189
different bag so the th each space

306
00:14:06,760 --> 00:14:11,770
cue is present in our string we're gonna

307
00:14:09,190 --> 00:14:13,180
have a 1 in that bag and if that happens

308
00:14:11,770 --> 00:14:18,670
again and the same string maybe be

309
00:14:13,180 --> 00:14:20,920
counting up to it so this actually

310
00:14:18,670 --> 00:14:24,280
produces quite a few columns if you just

311
00:14:20,920 --> 00:14:26,829
do it for every single bag right we want

312
00:14:24,280 --> 00:14:28,689
to have a way to like maybe reduce it

313
00:14:26,830 --> 00:14:30,550
because the running time of the

314
00:14:28,690 --> 00:14:32,500
algorithm is proportional to the number

315
00:14:30,550 --> 00:14:34,839
of problems we have so we're going to

316
00:14:32,500 --> 00:14:36,640
use this technique called tf-idf to

317
00:14:34,839 --> 00:14:38,830
determine which of these columns we

318
00:14:36,640 --> 00:14:40,360
really do care about and when it but

319
00:14:38,830 --> 00:14:43,750
that's that's another text processing

320
00:14:40,360 --> 00:14:45,820
technique that says okay so it's one of

321
00:14:43,750 --> 00:14:47,080
the most rarest things that have the

322
00:14:45,820 --> 00:14:48,880
most information

323
00:14:47,080 --> 00:14:52,330
you can determine that from the training

324
00:14:48,880 --> 00:14:55,150
data and only keep those columns later

325
00:14:52,330 --> 00:14:56,380
on when we pass the test data or

326
00:14:55,150 --> 00:14:58,240
production data

327
00:14:56,380 --> 00:15:01,750
it'll only look for those banks and all

328
00:14:58,240 --> 00:15:04,000
the other bags of the program so we kind

329
00:15:01,750 --> 00:15:06,160
of want to get the Machine an idea of

330
00:15:04,000 --> 00:15:08,020
the things that could be important and

331
00:15:06,160 --> 00:15:10,439
we think that none of the different

332
00:15:08,020 --> 00:15:13,060
codes the engrams and the strings

333
00:15:10,440 --> 00:15:15,850
entropy things like the number of dots

334
00:15:13,060 --> 00:15:17,410
and the domain name these are all

335
00:15:15,850 --> 00:15:19,420
important things we don't know for sure

336
00:15:17,410 --> 00:15:21,520
we have hints we want to give them the

337
00:15:19,420 --> 00:15:27,819
machine those hints and the Machine can

338
00:15:21,520 --> 00:15:28,420
then work it out so we're using random

339
00:15:27,820 --> 00:15:30,070
for us

340
00:15:28,420 --> 00:15:32,740
I'm going to have two slides and random

341
00:15:30,070 --> 00:15:34,330
force try I hope I don't put you guys to

342
00:15:32,740 --> 00:15:35,920
sleep or anything this is the magic part

343
00:15:34,330 --> 00:15:37,840
right like you won't have the program

344
00:15:35,920 --> 00:15:40,750
this is already done but just to show

345
00:15:37,840 --> 00:15:42,130
you what's happening a random force is a

346
00:15:40,750 --> 00:15:44,530
bunch of decision trees put together

347
00:15:42,130 --> 00:15:48,250
what's a decision tree a decision tree

348
00:15:44,530 --> 00:15:51,160
is take a law and you ask a bunch of

349
00:15:48,250 --> 00:15:52,930
questions about it at each point it's a

350
00:15:51,160 --> 00:15:56,439
yes or no question or maybe a greater

351
00:15:52,930 --> 00:15:57,760
than less than question and depending on

352
00:15:56,440 --> 00:15:59,710
that you answer that question you did go

353
00:15:57,760 --> 00:16:03,160
left or right in the tree and the leaves

354
00:15:59,710 --> 00:16:11,620
are predictions so in this decision tree

355
00:16:03,160 --> 00:16:14,819
on the left here so that data that

356
00:16:11,620 --> 00:16:18,580
decision tree that you saw a second ago

357
00:16:14,820 --> 00:16:21,040
well it's based on titanic survivor data

358
00:16:18,580 --> 00:16:23,470
so the first question asked was are you

359
00:16:21,040 --> 00:16:25,240
man are you woman if you're a woman you

360
00:16:23,470 --> 00:16:28,690
have a high probability of survival so

361
00:16:25,240 --> 00:16:31,120
at that point figures out that no other

362
00:16:28,690 --> 00:16:34,990
column has enough information to give

363
00:16:31,120 --> 00:16:36,780
you any better answer than survive but

364
00:16:34,990 --> 00:16:39,010
if you're on you're on the male side

365
00:16:36,780 --> 00:16:42,400
some of other questions could provide

366
00:16:39,010 --> 00:16:45,250
more information after that decision so

367
00:16:42,400 --> 00:16:47,770
like whether young male or older male

368
00:16:45,250 --> 00:16:49,600
over eight nine and a half I could give

369
00:16:47,770 --> 00:16:52,630
a little bit more information and give

370
00:16:49,600 --> 00:16:55,660
you a better answer so that's how they

371
00:16:52,630 --> 00:16:58,750
work once you have them there's various

372
00:16:55,660 --> 00:17:00,520
techniques to create them pretty much

373
00:16:58,750 --> 00:17:01,900
that there's like a green

374
00:17:00,520 --> 00:17:05,160
the greedy method is like the most

375
00:17:01,900 --> 00:17:09,849
widely used you take your corpus of data

376
00:17:05,160 --> 00:17:11,890
you try to find the column that gives

377
00:17:09,849 --> 00:17:13,679
you the most informational content for

378
00:17:11,890 --> 00:17:16,780
the answer that you're looking for and

379
00:17:13,680 --> 00:17:19,360
you make that your first question so

380
00:17:16,780 --> 00:17:24,389
it's sort of a greedy way and then you

381
00:17:19,359 --> 00:17:27,369
slip it slip a data set on that question

382
00:17:24,390 --> 00:17:31,980
you know and then you do the same thing

383
00:17:27,369 --> 00:17:31,979
over and we'll you meet some threshold

384
00:17:36,030 --> 00:17:42,370
this can be very good at fitting fitting

385
00:17:39,190 --> 00:17:44,980
a model to a particular set of data but

386
00:17:42,370 --> 00:17:46,600
it has a problem that it could be it

387
00:17:44,980 --> 00:17:48,430
could fit it too well and that's what we

388
00:17:46,600 --> 00:17:50,169
called overfitting so if we try to apply

389
00:17:48,430 --> 00:17:53,320
this model to another set of data that

390
00:17:50,170 --> 00:17:55,900
puts great odds it might have asked

391
00:17:53,320 --> 00:17:57,610
questions that maybe are meaningful

392
00:17:55,900 --> 00:17:59,170
proof like a real data set because we

393
00:17:57,610 --> 00:18:03,399
just didn't have enough there so that's

394
00:17:59,170 --> 00:18:06,490
fitting it'll give you answers so one

395
00:18:03,400 --> 00:18:10,570
way we mitigate this is technical random

396
00:18:06,490 --> 00:18:13,240
for us so basically we build a bunch of

397
00:18:10,570 --> 00:18:16,149
these trees and then ask them to vote

398
00:18:13,240 --> 00:18:18,370
and the boat is a better answer than any

399
00:18:16,150 --> 00:18:20,800
individual tree what's random about them

400
00:18:18,370 --> 00:18:23,770
it's really pretty simple there's two

401
00:18:20,800 --> 00:18:25,840
random things you train each individual

402
00:18:23,770 --> 00:18:28,350
tree on a random subset of the data that

403
00:18:25,840 --> 00:18:30,760
you select the hot with replacement and

404
00:18:28,350 --> 00:18:32,709
for each individual tree that you train

405
00:18:30,760 --> 00:18:35,020
you select a random subset of the

406
00:18:32,710 --> 00:18:37,720
columns so you make more maybe most of

407
00:18:35,020 --> 00:18:39,610
the copies in each individual tree and

408
00:18:37,720 --> 00:18:43,450
you do that n times and you form a

409
00:18:39,610 --> 00:18:45,909
classifier by averaging or you know you

410
00:18:43,450 --> 00:18:49,810
can also have voting it turns out this

411
00:18:45,910 --> 00:18:58,240
is really good classifier that's called

412
00:18:49,810 --> 00:19:01,570
a bagging technique so we've written we

413
00:18:58,240 --> 00:19:04,690
bring some scripts to do this on HTTP

414
00:19:01,570 --> 00:19:07,030
log data and I let David describe how

415
00:19:04,690 --> 00:19:08,660
they run actually I'd also like to just

416
00:19:07,030 --> 00:19:10,670
point out we chose random forests

417
00:19:08,660 --> 00:19:12,230
it's probably the best one if you don't

418
00:19:10,670 --> 00:19:13,640
know what algorithm you should use

419
00:19:12,230 --> 00:19:15,950
because there's a ton of other ones

420
00:19:13,640 --> 00:19:20,440
because it's really super good at just

421
00:19:15,950 --> 00:19:20,440
figuring out based on all the features

422
00:19:20,710 --> 00:19:36,620
and it's also probably the most we're

423
00:19:33,380 --> 00:19:39,110
going to talk about trading testing the

424
00:19:36,620 --> 00:19:42,649
model and then right here in your own

425
00:19:39,110 --> 00:19:45,080
data through it we're also going to talk

426
00:19:42,650 --> 00:19:47,660
about that in terms of like how you do

427
00:19:45,080 --> 00:19:50,179
it in theory in general but also at the

428
00:19:47,660 --> 00:19:53,510
same time how our tool how you use our

429
00:19:50,180 --> 00:19:56,510
so here you see the first step is we

430
00:19:53,510 --> 00:20:00,200
have to train so we have our tool

431
00:19:56,510 --> 00:20:01,910
consuming throw format HTTP logs right

432
00:20:00,200 --> 00:20:03,530
nothing magic about that you could

433
00:20:01,910 --> 00:20:07,330
change that if you wanted to but that's

434
00:20:03,530 --> 00:20:10,550
what we do because we have a lot of data

435
00:20:07,330 --> 00:20:13,149
the first step is to just run the

436
00:20:10,550 --> 00:20:17,090
training algorithm with a sample of

437
00:20:13,150 --> 00:20:20,420
malware HTTP logs in a sample of our

438
00:20:17,090 --> 00:20:25,310
production presumably but not entirely

439
00:20:20,420 --> 00:20:27,440
verified good lungs and I think this you

440
00:20:25,310 --> 00:20:30,830
know we might look like - oh so - oh

441
00:20:27,440 --> 00:20:33,650
means this is the bad stuff and this is

442
00:20:30,830 --> 00:20:37,159
the good stuff the good stuff I think we

443
00:20:33,650 --> 00:20:41,030
had about one week we stood one sample

444
00:20:37,160 --> 00:20:46,940
week of our blogs and then thank you not

445
00:20:41,030 --> 00:20:50,930
to be some large number of the malware

446
00:20:46,940 --> 00:20:52,820
sample is roughly thirty seven thousand

447
00:20:50,930 --> 00:20:57,740
examples I think that's actually in the

448
00:20:52,820 --> 00:21:01,879
github repo I didn't provide our malware

449
00:20:57,740 --> 00:21:05,540
samples and there's probably 37 so we

450
00:21:01,880 --> 00:21:07,190
kind of read amended this way it when

451
00:21:05,540 --> 00:21:08,629
it's us building vectorizer x' it's

452
00:21:07,190 --> 00:21:10,640
actually creating all those features

453
00:21:08,630 --> 00:21:12,830
that Chris was just talking about the

454
00:21:10,640 --> 00:21:15,320
bags of words and things like that and

455
00:21:12,830 --> 00:21:17,240
then it does the training as you just

456
00:21:15,320 --> 00:21:18,909
described creates that random forest

457
00:21:17,240 --> 00:21:24,940
creates a bunch of

458
00:21:18,910 --> 00:21:29,680
and then it actually spits out what

459
00:21:24,940 --> 00:21:31,930
getting in for testing so read the pros

460
00:21:29,680 --> 00:21:33,910
data independence data frame by the way

461
00:21:31,930 --> 00:21:36,310
each one of those has a label on it

462
00:21:33,910 --> 00:21:37,960
we depending on which file it came from

463
00:21:36,310 --> 00:21:41,080
we we say it's either benign or

464
00:21:37,960 --> 00:21:43,870
malicious we convert all the strings

465
00:21:41,080 --> 00:21:45,939
using bags of words you can see bag of

466
00:21:43,870 --> 00:21:49,000
word we do things like method and status

467
00:21:45,940 --> 00:21:50,760
code because those are like the status

468
00:21:49,000 --> 00:21:54,640
code like Chris was saying is basically

469
00:21:50,760 --> 00:21:58,810
enumerated type the HTTP method is also

470
00:21:54,640 --> 00:22:01,300
another enumerated type and then engrams

471
00:21:58,810 --> 00:22:06,790
for other things like demands in his

472
00:22:01,300 --> 00:22:09,399
rages we split it into about 80%

473
00:22:06,790 --> 00:22:11,980
training data and 20% test data and

474
00:22:09,400 --> 00:22:14,500
vetted through their metaphors at this

475
00:22:11,980 --> 00:22:15,880
point it's notice that we haven't really

476
00:22:14,500 --> 00:22:21,250
done anything with the test day dates

477
00:22:15,880 --> 00:22:23,950
but that 20% that we reserved but this

478
00:22:21,250 --> 00:22:26,140
is where it came in now we need the

479
00:22:23,950 --> 00:22:28,570
Treaty model we want to see how good our

480
00:22:26,140 --> 00:22:30,970
training is so we took that test data

481
00:22:28,570 --> 00:22:34,480
which is still labeled each day is still

482
00:22:30,970 --> 00:22:36,070
able to put nine or malicious and that

483
00:22:34,480 --> 00:22:37,810
way we note what the answer should be

484
00:22:36,070 --> 00:22:41,110
for each one of those and we run them

485
00:22:37,810 --> 00:22:44,080
all through the trained model to see how

486
00:22:41,110 --> 00:22:45,939
good we are and you can see here just a

487
00:22:44,080 --> 00:22:50,919
little table that says this is really

488
00:22:45,940 --> 00:22:55,450
class zero so good sorry bad and we

489
00:22:50,920 --> 00:22:58,180
predicted bad 12400 28 times so we gave

490
00:22:55,450 --> 00:23:01,750
us we predicted it was good only 15

491
00:22:58,180 --> 00:23:03,160
times be good right we made we said it's

492
00:23:01,750 --> 00:23:05,080
not gonna be perfect but it'll be in the

493
00:23:03,160 --> 00:23:07,810
ballpark and we did the opposite it was

494
00:23:05,080 --> 00:23:10,510
known bad we predicted it to be good

495
00:23:07,810 --> 00:23:16,929
only 19 times and we predicted it to be

496
00:23:10,510 --> 00:23:19,660
bad 9564 so great is this a good model

497
00:23:16,930 --> 00:23:22,210
though I mean you can kind of look at it

498
00:23:19,660 --> 00:23:25,980
with these numbers and say yeah this is

499
00:23:22,210 --> 00:23:29,080
a good model but when you're trying to

500
00:23:25,980 --> 00:23:31,350
run this in your own environment your

501
00:23:29,080 --> 00:23:35,159
numbers may not have come out

502
00:23:31,350 --> 00:23:36,870
so here also if you want to experiment

503
00:23:35,160 --> 00:23:38,460
with some additional features or

504
00:23:36,870 --> 00:23:39,989
whatever that you might want to have and

505
00:23:38,460 --> 00:23:42,450
you want to compare multiple runs it's

506
00:23:39,990 --> 00:23:46,950
hard to compare a whole table so what

507
00:23:42,450 --> 00:23:50,970
we've done is kind of a slide on this

508
00:23:46,950 --> 00:23:53,460
yes we have also computed this thing

509
00:23:50,970 --> 00:23:56,190
called the f1 score this is a standard

510
00:23:53,460 --> 00:23:58,169
kind of statistical score you can see it

511
00:23:56,190 --> 00:23:59,880
in Wikipedia if you want but it's it's a

512
00:23:58,169 --> 00:24:01,559
mathematical combination of things like

513
00:23:59,880 --> 00:24:03,539
true positive rates and false positive

514
00:24:01,559 --> 00:24:08,908
rates and all these things to kind of

515
00:24:03,539 --> 00:24:11,700
give you a 1 number from 0 to 1 how good

516
00:24:08,909 --> 00:24:13,730
you think your model is anything over

517
00:24:11,700 --> 00:24:18,049
like point nine is considered to be good

518
00:24:13,730 --> 00:24:21,299
ours is actually suspiciously too good

519
00:24:18,049 --> 00:24:23,940
as Chris was mentioning we might have

520
00:24:21,299 --> 00:24:28,289
some overfitting there we'll talk about

521
00:24:23,940 --> 00:24:30,690
that but technically we're over point

522
00:24:28,289 --> 00:24:34,110
nine so we might consider this to be a

523
00:24:30,690 --> 00:24:36,630
pretty good now bonus if you do the same

524
00:24:34,110 --> 00:24:38,729
thing and you add HB well take a little

525
00:24:36,630 --> 00:24:40,830
bit longer but it will actually tell you

526
00:24:38,730 --> 00:24:43,860
the features that the random forest

527
00:24:40,830 --> 00:24:45,750
thinks are the most indicative of either

528
00:24:43,860 --> 00:24:47,309
way it doesn't label them like this is

529
00:24:45,750 --> 00:24:50,400
more indicative of malicious of this

530
00:24:47,309 --> 00:24:54,809
morning it just says these are the ones

531
00:24:50,400 --> 00:24:56,820
that count more and so in this would be

532
00:24:54,809 --> 00:24:59,940
not surprise the malware analyst among

533
00:24:56,820 --> 00:25:03,510
you user agents are often really

534
00:24:59,940 --> 00:25:06,120
influential because malware it screws up

535
00:25:03,510 --> 00:25:07,980
the user agent a lot or they might get a

536
00:25:06,120 --> 00:25:10,469
user agents totally legitimate but maybe

537
00:25:07,980 --> 00:25:12,150
not in your environment but we also have

538
00:25:10,470 --> 00:25:14,520
other things like they use your agent

539
00:25:12,150 --> 00:25:18,630
entropy the sub that interviewed the

540
00:25:14,520 --> 00:25:19,980
subdomain the body length of their

541
00:25:18,630 --> 00:25:21,900
response and their requests are the

542
00:25:19,980 --> 00:25:27,780
number of demean or adopts intervene

543
00:25:21,900 --> 00:25:30,000
things like that and these are ranked so

544
00:25:27,780 --> 00:25:33,059
these are named like the feature type

545
00:25:30,000 --> 00:25:41,070
and then could say back upwards or after

546
00:25:33,059 --> 00:25:42,870
the actual graph and also this is that

547
00:25:41,070 --> 00:25:43,908
this is the top 50 out of something like

548
00:25:42,870 --> 00:25:49,099
3000

549
00:25:43,909 --> 00:25:50,859
these would give you pretty good so the

550
00:25:49,099 --> 00:25:54,289
next thing is in this will write a

551
00:25:50,859 --> 00:25:56,418
trained classifier out into by default

552
00:25:54,289 --> 00:26:00,199
your temp directory if you actually go

553
00:25:56,419 --> 00:26:05,419
in the code like given Sh tell you how

554
00:26:00,199 --> 00:26:07,789
to put that somewhere more stable but

555
00:26:05,419 --> 00:26:09,349
here we actually the next step is just

556
00:26:07,789 --> 00:26:12,229
how do you think we got a good model

557
00:26:09,349 --> 00:26:14,239
we've trained it and test it so and

558
00:26:12,229 --> 00:26:16,599
evaluated it now let's run it with some

559
00:26:14,239 --> 00:26:20,059
carbonyl data and see what we get so

560
00:26:16,599 --> 00:26:23,208
that's what analyze flows does just give

561
00:26:20,059 --> 00:26:26,869
it the name of another a bro HT compete

562
00:26:23,209 --> 00:26:28,429
log I I designed this so you could

563
00:26:26,869 --> 00:26:31,129
basically do this every day with the

564
00:26:28,429 --> 00:26:34,089
previous days with the logs or you could

565
00:26:31,129 --> 00:26:36,678
do something fancier and it basically

566
00:26:34,089 --> 00:26:38,329
you know loads it up calculates the

567
00:26:36,679 --> 00:26:40,190
features on the new log because it

568
00:26:38,329 --> 00:26:41,658
obviously needs those features to run

569
00:26:40,190 --> 00:26:43,599
the machine learning and then it

570
00:26:41,659 --> 00:26:48,139
analyzes it it'll go for a little while

571
00:26:43,599 --> 00:26:49,939
and then they'll say here detected 298

572
00:26:48,139 --> 00:26:53,748
anomalies out of a hundred and eighty

573
00:26:49,940 --> 00:26:55,399
thousand audiences so I'm only having to

574
00:26:53,749 --> 00:26:58,899
the machine that's telling me I don't

575
00:26:55,399 --> 00:26:58,899
have to look at 0.17%

576
00:27:01,929 --> 00:27:07,399
which is really good now who thinks that

577
00:27:05,929 --> 00:27:12,849
they can look at a hundred eighty

578
00:27:07,399 --> 00:27:16,339
thousand who thinks they can look at 298

579
00:27:12,849 --> 00:27:19,299
yeah so now we're back hopefully into

580
00:27:16,339 --> 00:27:23,658
the realm where an analyst looking at

581
00:27:19,299 --> 00:27:27,889
the logs that they need to may again be

582
00:27:23,659 --> 00:27:31,489
possible it was sorry is it tonighti per

583
00:27:27,889 --> 00:27:34,879
hour for five minutes where they this

584
00:27:31,489 --> 00:27:38,709
this isn't age love so it was twenty

585
00:27:34,879 --> 00:27:38,708
eight log entries for the previous day

586
00:27:39,429 --> 00:27:43,459
yeah it depends on the size of your

587
00:27:41,359 --> 00:27:46,009
network bug but it says well my network

588
00:27:43,459 --> 00:27:49,069
bug had 180,000 in it in the day we have

589
00:27:46,009 --> 00:27:50,569
a small office here a larger company

590
00:27:49,069 --> 00:27:52,219
you're gonna have a lot more and

591
00:27:50,569 --> 00:27:56,239
probably you will also have a lot more

592
00:27:52,219 --> 00:27:57,140
things to review but hopefully it will

593
00:27:56,239 --> 00:27:59,120
still be

594
00:27:57,140 --> 00:28:01,130
in the ballpark's of things that you can

595
00:27:59,120 --> 00:28:03,020
do and if it's not you can tinker with

596
00:28:01,130 --> 00:28:05,470
the food add some more features or

597
00:28:03,020 --> 00:28:05,470
anything like that

598
00:28:07,610 --> 00:28:11,810
also bonus this will take a lot longer

599
00:28:09,890 --> 00:28:13,880
if you run it but it's kind of

600
00:28:11,810 --> 00:28:16,010
instructive to try it once or twice if

601
00:28:13,880 --> 00:28:18,620
you run the same thing with - beat it

602
00:28:16,010 --> 00:28:25,670
will tell you for each each of the

603
00:28:18,620 --> 00:28:28,040
outputs why it thought that like what

604
00:28:25,670 --> 00:28:29,870
were the most influential features so

605
00:28:28,040 --> 00:28:31,850
this is actually telling you these are

606
00:28:29,870 --> 00:28:33,860
the features that we took out of the

607
00:28:31,850 --> 00:28:35,419
prologue or part of the way if you want

608
00:28:33,860 --> 00:28:38,899
to go back to the original prologue

609
00:28:35,420 --> 00:28:42,650
that's line 431 in marriage hope you

610
00:28:38,900 --> 00:28:44,540
find it but then we said this is

611
00:28:42,650 --> 00:28:46,300
something you should look at because

612
00:28:44,540 --> 00:28:49,670
it's different than most of your lives

613
00:28:46,300 --> 00:28:53,870
and it says okay user agent length was

614
00:28:49,670 --> 00:28:56,120
the most influential feature this is the

615
00:28:53,870 --> 00:28:57,889
user agent link that's the is rate right

616
00:28:56,120 --> 00:29:00,050
there

617
00:28:57,890 --> 00:29:02,900
so yeah clearly that's a lot smaller

618
00:29:00,050 --> 00:29:04,760
than most earlier versions of the

619
00:29:02,900 --> 00:29:08,150
response body length the domain name

620
00:29:04,760 --> 00:29:10,730
link the user agent these are all things

621
00:29:08,150 --> 00:29:13,190
like as you might imagine most of our

622
00:29:10,730 --> 00:29:16,310
office runs Mac OS and most the is err

623
00:29:13,190 --> 00:29:18,320
agents have Mac OS in it and this didn't

624
00:29:16,310 --> 00:29:23,350
have any of it so it's saying I expected

625
00:29:18,320 --> 00:29:23,350
to see these see

626
00:29:26,390 --> 00:29:29,780
but it's kind of interesting just rent

627
00:29:28,340 --> 00:29:35,810
once or twice it does take a little

628
00:29:29,780 --> 00:29:37,310
substantially longer time and I'm gonna

629
00:29:35,810 --> 00:29:39,740
turn it over back to press here for a

630
00:29:37,310 --> 00:29:41,629
few more what yeah so that that's

631
00:29:39,740 --> 00:29:45,890
actually one of the pretty cool things

632
00:29:41,630 --> 00:29:48,460
about random decision trees is that they

633
00:29:45,890 --> 00:29:51,500
are one of the more explainable types

634
00:29:48,460 --> 00:29:58,340
some are just like deep learning it's

635
00:29:51,500 --> 00:29:59,600
like so there's one one feature that I

636
00:29:58,340 --> 00:30:02,540
VI know about how much I want to go

637
00:29:59,600 --> 00:30:04,580
through this like in detail but um so if

638
00:30:02,540 --> 00:30:07,340
you don't have malware samples so you

639
00:30:04,580 --> 00:30:11,960
don't trust our malware samples you can

640
00:30:07,340 --> 00:30:14,330
you can also run a binary classifier

641
00:30:11,960 --> 00:30:15,680
with just one class of data it looks

642
00:30:14,330 --> 00:30:17,629
various ways to do that

643
00:30:15,680 --> 00:30:19,130
and so we called this one class

644
00:30:17,630 --> 00:30:21,260
classification because you're trying to

645
00:30:19,130 --> 00:30:23,510
fit a model just to the normal data and

646
00:30:21,260 --> 00:30:24,920
trying to consider like other abnormal

647
00:30:23,510 --> 00:30:27,980
I'm one way to do that just like

648
00:30:24,920 --> 00:30:30,290
generate gibberish that's generally not

649
00:30:27,980 --> 00:30:32,540
as good as doing this other medical

650
00:30:30,290 --> 00:30:34,430
waste that's the best the patient so

651
00:30:32,540 --> 00:30:37,010
what we're going to do is create fake

652
00:30:34,430 --> 00:30:38,900
data and called malicious and that fake

653
00:30:37,010 --> 00:30:41,150
data is going to be generated from the

654
00:30:38,900 --> 00:30:43,760
real data but have certain properties

655
00:30:41,150 --> 00:30:45,680
that make it look not realistic so like

656
00:30:43,760 --> 00:30:47,360
the examples here over here I have a

657
00:30:45,680 --> 00:30:49,790
customer that's trying to classify

658
00:30:47,360 --> 00:30:52,899
animals I'm gonna like generate this

659
00:30:49,790 --> 00:30:55,430
thing as a lion toy the snake's tail and

660
00:30:52,900 --> 00:30:56,870
MCE is actually pretty much like this

661
00:30:55,430 --> 00:30:57,590
with blogs I might guarantee different

662
00:30:56,870 --> 00:30:59,689
pieces of logs

663
00:30:57,590 --> 00:31:02,120
real logs together and say this is

664
00:30:59,690 --> 00:31:06,190
malicious but it'll it'll end up being

665
00:31:02,120 --> 00:31:08,689
able to classify your mobile data better

666
00:31:06,190 --> 00:31:11,150
so we have this if you don't pass in a

667
00:31:08,690 --> 00:31:13,490
wire file on the command line

668
00:31:11,150 --> 00:31:14,990
that's an option it had that - no option

669
00:31:13,490 --> 00:31:17,660
it'll do this automatically so you can

670
00:31:14,990 --> 00:31:24,470
see how that marks the source but it'll

671
00:31:17,660 --> 00:31:27,440
just produce a classifier the the normal

672
00:31:24,470 --> 00:31:33,830
data file is not optional so it doesn't

673
00:31:27,440 --> 00:31:35,240
have applying so obviously like you know

674
00:31:33,830 --> 00:31:38,060
this is something that we made for you

675
00:31:35,240 --> 00:31:38,960
guys to show you know how sort of easy

676
00:31:38,060 --> 00:31:40,730
it is to

677
00:31:38,960 --> 00:31:42,170
something like this it's not perfect

678
00:31:40,730 --> 00:31:45,200
there's some things that could

679
00:31:42,170 --> 00:31:47,360
definitely be improved about it you know

680
00:31:45,200 --> 00:31:49,250
more diverse and our samples is better

681
00:31:47,360 --> 00:31:51,409
data that you have to start out with the

682
00:31:49,250 --> 00:31:53,180
very morning gene blue data the better

683
00:31:51,410 --> 00:32:00,200
your classifier is going to be so that's

684
00:31:53,180 --> 00:32:01,370
almost always true so you know yeah what

685
00:32:00,200 --> 00:32:04,460
I said that we might have had a

686
00:32:01,370 --> 00:32:06,139
suspiciously high at one score all of

687
00:32:04,460 --> 00:32:08,090
our malware samples mostly were Windows

688
00:32:06,140 --> 00:32:12,320
malware samples in our office being

689
00:32:08,090 --> 00:32:13,699
mostly max it was pretty easy for the

690
00:32:12,320 --> 00:32:16,189
classifier to tell the difference

691
00:32:13,700 --> 00:32:18,050
between those two when I say more

692
00:32:16,190 --> 00:32:20,930
diverse malware samples I really mean we

693
00:32:18,050 --> 00:32:23,060
need to get some oh s X malware in there

694
00:32:20,930 --> 00:32:25,480
which we didn't have that sack wasn't

695
00:32:23,060 --> 00:32:29,179
wasn't a lot of it in those archives

696
00:32:25,480 --> 00:32:34,130
yeah there's a very old story may be

697
00:32:29,180 --> 00:32:35,540
apocryphal about you know about binary

698
00:32:34,130 --> 00:32:37,790
classifiers but they were trying to

699
00:32:35,540 --> 00:32:39,860
train digital classifier to find

700
00:32:37,790 --> 00:32:42,200
pictures of tanks and it was very good

701
00:32:39,860 --> 00:32:44,330
on their test set but it turned out that

702
00:32:42,200 --> 00:32:46,250
like bullet pictures of tanks were taken

703
00:32:44,330 --> 00:32:48,439
on a cloudy day and all the pictures of

704
00:32:46,250 --> 00:32:49,970
not tanks on a sunny day so it's really

705
00:32:48,440 --> 00:32:51,530
like looking at the sky and say oh

706
00:32:49,970 --> 00:32:53,210
that's a blue sky so you made a blue sky

707
00:32:51,530 --> 00:32:55,700
classifier and that's maybe kind of what

708
00:32:53,210 --> 00:32:58,750
we did we made a blue sky mac OS class

709
00:32:55,700 --> 00:33:01,310
player so you have to be careful about

710
00:32:58,750 --> 00:33:07,760
that's data and not even really the code

711
00:33:01,310 --> 00:33:10,100
yeah so there's some Sun malware dust

712
00:33:07,760 --> 00:33:12,440
things that it's pretty normal like

713
00:33:10,100 --> 00:33:15,500
checking new ball checking baby like a

714
00:33:12,440 --> 00:33:17,330
time server out things like that that

715
00:33:15,500 --> 00:33:18,800
could throw off a classifier so you

716
00:33:17,330 --> 00:33:21,740
could pre-filter this as part of the

717
00:33:18,800 --> 00:33:24,230
data cleaning check you could pre-filter

718
00:33:21,740 --> 00:33:25,910
rows like that to make it effective

719
00:33:24,230 --> 00:33:28,010
classifier has much because it's going

720
00:33:25,910 --> 00:33:31,040
to look to normal things like that so

721
00:33:28,010 --> 00:33:33,080
you could be planning slips there's

722
00:33:31,040 --> 00:33:36,440
actually uh like in scikit-learn the

723
00:33:33,080 --> 00:33:38,210
random source code allows for retraining

724
00:33:36,440 --> 00:33:41,540
the forests and it's called mourn

725
00:33:38,210 --> 00:33:43,670
started but what you can do is like you

726
00:33:41,540 --> 00:33:45,860
know your your training model is on old

727
00:33:43,670 --> 00:33:47,930
malware data old normal data that

728
00:33:45,860 --> 00:33:50,899
eventually will become stale like in our

729
00:33:47,930 --> 00:33:51,530
dynamic environment so there's ways to

730
00:33:50,900 --> 00:33:53,570
like

731
00:33:51,530 --> 00:33:55,340
take new normal data new malware data

732
00:33:53,570 --> 00:33:57,020
you could just like combine it with your

733
00:33:55,340 --> 00:33:59,139
old data and retrain or something from

734
00:33:57,020 --> 00:34:01,970
scratch we could do any one from scratch

735
00:33:59,140 --> 00:34:04,220
but it could be helpful to take the old

736
00:34:01,970 --> 00:34:06,200
trading model and use that as a warm

737
00:34:04,220 --> 00:34:11,120
start to your new trick so there's ways

738
00:34:06,200 --> 00:34:13,340
to do that inside it and it'd be nice to

739
00:34:11,120 --> 00:34:14,600
have you know plugins for different bulk

740
00:34:13,340 --> 00:34:16,520
types we're kind of like a little bit

741
00:34:14,600 --> 00:34:23,500
hard-coded to do HTTP robots right now

742
00:34:16,520 --> 00:34:28,610
it would be nice to kind of have your

743
00:34:23,500 --> 00:34:29,840
logs things like some things like these

744
00:34:28,610 --> 00:34:31,190
things to not just do binary

745
00:34:29,840 --> 00:34:33,620
classification boss a cake boss

746
00:34:31,190 --> 00:34:35,090
specification which means like it would

747
00:34:33,620 --> 00:34:44,929
be able to maybe guess what kind of

748
00:34:35,090 --> 00:34:46,520
malware it is really like gotta the main

749
00:34:44,929 --> 00:34:48,440
thing that would be nice to have this

750
00:34:46,520 --> 00:34:50,239
you know different mod types in this

751
00:34:48,440 --> 00:34:53,179
kind of bleep like I said fix fix

752
00:34:50,239 --> 00:34:55,520
row box I've kind of put a little recipe

753
00:34:53,179 --> 00:34:57,230
in here for anybody that wants to tinker

754
00:34:55,520 --> 00:34:59,300
with the code if you wanted to do

755
00:34:57,230 --> 00:35:01,280
different log types these are the four

756
00:34:59,300 --> 00:35:03,170
steps and you have to take there's like

757
00:35:01,280 --> 00:35:06,140
three files three files that you have to

758
00:35:03,170 --> 00:35:07,580
change and four steps basically like you

759
00:35:06,140 --> 00:35:09,890
have to read it in differently and you

760
00:35:07,580 --> 00:35:18,350
have to generate features differently so

761
00:35:09,890 --> 00:35:19,970
if you do this it should work on like if

762
00:35:18,350 --> 00:35:22,930
you want to that wanted to ask us any

763
00:35:19,970 --> 00:35:22,930
other questions about that

764
00:35:25,730 --> 00:35:33,220
no just say that there are twitter I'll

765
00:35:30,740 --> 00:35:37,790
be tweeting out the link to the slides

766
00:35:33,220 --> 00:35:40,339
certainly and also the URL that's on

767
00:35:37,790 --> 00:35:42,500
here it is I'll be flipping it over to a

768
00:35:40,340 --> 00:35:46,760
public repo probably a few minutes after

769
00:35:42,500 --> 00:35:49,220
we're done here so you know within sane

770
00:35:46,760 --> 00:35:56,030
hours both of those things will be

771
00:35:49,220 --> 00:35:57,589
available also we do there are maybe

772
00:35:56,030 --> 00:35:59,780
difficulties we've lost all the

773
00:35:57,590 --> 00:36:02,990
questions anybody submitted something to

774
00:35:59,780 --> 00:36:06,280
Google so I guess we're ready to take

775
00:36:02,990 --> 00:36:06,279
all of our questions and

776
00:36:07,520 --> 00:36:16,020
it could be a pistol question like that

777
00:36:12,619 --> 00:36:18,960
so it's on the Reedy use and the side

778
00:36:16,020 --> 00:36:20,400
kit there's a couple of random podrace

779
00:36:18,960 --> 00:36:22,680
but they're doing like top-level domain

780
00:36:20,400 --> 00:36:31,890
extraction and stuff in the reading it

781
00:36:22,680 --> 00:36:34,290
has a couple of questions - the first

782
00:36:31,890 --> 00:36:35,848
question has to do with correlating the

783
00:36:34,290 --> 00:36:38,060
anomaly that's your classifier produces

784
00:36:35,849 --> 00:36:41,220
so let's say you have one anomaly

785
00:36:38,060 --> 00:36:44,970
anomaly have you looked into how they

786
00:36:41,220 --> 00:36:48,899
can be correlated in terms of them doing

787
00:36:44,970 --> 00:36:51,240
to it - the same attack yeah we did try

788
00:36:48,900 --> 00:36:55,619
to do that on this we're trying to keep

789
00:36:51,240 --> 00:36:57,149
it to like a one job kind of thing in

790
00:36:55,619 --> 00:36:59,040
fact you will notice that we actually

791
00:36:57,150 --> 00:37:01,200
wouldn't we display it back to you

792
00:36:59,040 --> 00:37:04,609
through our tool we don't actually tell

793
00:37:01,200 --> 00:37:07,348
you the addresses or on either side

794
00:37:04,609 --> 00:37:09,119
because for the most part and unless

795
00:37:07,349 --> 00:37:11,130
you're super home

796
00:37:09,119 --> 00:37:15,420
most of these still probably going to be

797
00:37:11,130 --> 00:37:17,310
false positive but the ones that do look

798
00:37:15,420 --> 00:37:18,869
like the true positives should be pretty

799
00:37:17,310 --> 00:37:22,680
obvious and then you could look those up

800
00:37:18,869 --> 00:37:23,760
if you want to if you want to do that

801
00:37:22,680 --> 00:37:27,270
kind of correlation

802
00:37:23,760 --> 00:37:28,800
I'm afraid by squirrels product yeah I

803
00:37:27,270 --> 00:37:32,089
expect there's gonna be a lot of answers

804
00:37:28,800 --> 00:37:35,099
like that but second question is about

805
00:37:32,089 --> 00:37:37,310
advanced or certain rather adversarial

806
00:37:35,099 --> 00:37:40,500
machine learning they looked at the the

807
00:37:37,310 --> 00:37:42,240
mortal drift aspect of training training

808
00:37:40,500 --> 00:37:46,650
across fire and the Tigers who are

809
00:37:42,240 --> 00:37:49,259
adapting to to your your machine

810
00:37:46,650 --> 00:37:51,210
learning code yeah it's a very

811
00:37:49,260 --> 00:37:54,030
interesting question of you know the

812
00:37:51,210 --> 00:37:56,609
this like retraining can come up but

813
00:37:54,030 --> 00:37:58,530
yeah it's definitely like one of the if

814
00:37:56,609 --> 00:38:00,210
not the most challenging problems in

815
00:37:58,530 --> 00:38:02,010
machine learning today because of that

816
00:38:00,210 --> 00:38:04,920
reason and because of other reasons we

817
00:38:02,010 --> 00:38:07,470
know if you try to classify the type of

818
00:38:04,920 --> 00:38:10,290
an iris or whatever the classic problems

819
00:38:07,470 --> 00:38:12,390
the iris is not trying to look like okay

820
00:38:10,290 --> 00:38:15,349
like and that's not true here so this is

821
00:38:12,390 --> 00:38:15,348
it's a very challenging

822
00:38:15,730 --> 00:38:50,650
Thank You life force has the nine

823
00:38:46,190 --> 00:38:50,650
perfect orders of magnitude more than

824
00:38:53,050 --> 00:38:59,750
the Nikki knows the safest thing to say

825
00:38:56,230 --> 00:39:01,220
right so I mean you can always expect

826
00:38:59,750 --> 00:39:03,800
that that's my reasoning what I kept

827
00:39:01,220 --> 00:39:05,600
once were to evaluation partially

828
00:39:03,800 --> 00:39:08,240
because you know if you just use

829
00:39:05,600 --> 00:39:10,160
something like accuracy accuracy it's

830
00:39:08,240 --> 00:39:12,830
going to be very high you just say no

831
00:39:10,160 --> 00:39:14,450
which is bad okay like so you really

832
00:39:12,830 --> 00:39:17,270
want to use something like f1 that takes

833
00:39:14,450 --> 00:39:21,770
the percentage of yards it's actually

834
00:39:17,270 --> 00:39:23,870
the mean of so that takes that anyway

835
00:39:21,770 --> 00:39:28,040
count it's going to be low if you're

836
00:39:23,870 --> 00:39:30,109
doing things like saying yes but yeah

837
00:39:28,040 --> 00:39:31,970
like it there's various ways to mitigate

838
00:39:30,110 --> 00:39:35,930
like want to collect as much malicious

839
00:39:31,970 --> 00:39:41,060
traffic as you can use a combination of

840
00:39:35,930 --> 00:39:47,029
something like this fascination with you

841
00:39:41,060 --> 00:39:53,029
can you can do both so you can try to

842
00:39:47,030 --> 00:39:54,740
make the possible so I think it's you

843
00:39:53,030 --> 00:39:57,530
know Melissa's traffic drip slide

844
00:39:54,740 --> 00:39:59,330
there's a lot of variety in it but um I

845
00:39:57,530 --> 00:40:01,670
think generally normal traffic is not

846
00:39:59,330 --> 00:40:06,410
like that right like you know you go to

847
00:40:01,670 --> 00:40:13,520
Facebook you saw sex a lot so I mean

848
00:40:06,410 --> 00:40:15,200
those signals are in there like so I

849
00:40:13,520 --> 00:40:17,840
don't think you're exempt you folks a

850
00:40:15,200 --> 00:40:20,419
lot on Fox in traffic but these whatever

851
00:40:17,840 --> 00:40:22,490
kind of log folks not anything trying to

852
00:40:20,420 --> 00:40:23,900
let see cross Worley different logs

853
00:40:22,490 --> 00:40:26,850
things to get let's see a higher

854
00:40:23,900 --> 00:40:30,480
positive room yeah we have actual

855
00:40:26,850 --> 00:40:34,470
look at for this the correlation of the

856
00:40:30,480 --> 00:40:38,730
logs we're again like we're trying to be

857
00:40:34,470 --> 00:40:40,470
a demo cross with their real so we kind

858
00:40:38,730 --> 00:40:42,630
of scoped it down to like you're gonna

859
00:40:40,470 --> 00:40:44,640
look at eight eight log although it's

860
00:40:42,630 --> 00:40:47,310
it's perfectly possible that you might

861
00:40:44,640 --> 00:40:49,740
take like with bread data a lot of those

862
00:40:47,310 --> 00:40:52,620
things in bro are explicitly linked but

863
00:40:49,740 --> 00:40:55,049
their IDs so if you actually looked at

864
00:40:52,620 --> 00:40:58,470
the brewery logs they actually have like

865
00:40:55,050 --> 00:41:00,960
file IDs that correspond the files that

866
00:40:58,470 --> 00:41:02,910
were uploaded or downloaded you could

867
00:41:00,960 --> 00:41:05,700
think of pasting those two together and

868
00:41:02,910 --> 00:41:07,500
saying I'm going to admin the HTTP log

869
00:41:05,700 --> 00:41:10,919
with the information about the files

870
00:41:07,500 --> 00:41:13,830
that went on that that connection and

871
00:41:10,920 --> 00:41:17,640
then see how that affected it so for

872
00:41:13,830 --> 00:41:19,610
example if I'm downloading an exe file

873
00:41:17,640 --> 00:41:23,279
maybe that's a little bit more malicious

874
00:41:19,610 --> 00:41:25,800
than or maybe you would find like the

875
00:41:23,280 --> 00:41:28,320
JPEG that says dot JPEG but the mine

876
00:41:25,800 --> 00:41:34,590
type that wrote assigned to it actually

877
00:41:28,320 --> 00:41:38,790
said like dot DLL and that might be a

878
00:41:34,590 --> 00:41:40,320
useful feature well we just did not do

879
00:41:38,790 --> 00:41:42,360
that because we were trying to keep it

880
00:41:40,320 --> 00:41:44,520
more straightforward and simple to make

881
00:41:42,360 --> 00:41:47,310
it easier to understand but it's getting

882
00:41:44,520 --> 00:41:58,170
started with so this is the kind of

883
00:41:47,310 --> 00:41:59,640
thing I guess a good observation like

884
00:41:58,170 --> 00:42:01,380
these this is log at a time

885
00:41:59,640 --> 00:42:04,410
and we're trying to classify logs and

886
00:42:01,380 --> 00:42:08,210
really what I think you're asking is we

887
00:42:04,410 --> 00:42:08,210
really want to try to classify behavior

888
00:42:28,400 --> 00:42:36,680
that's a tricks world not getting up

889
00:42:32,369 --> 00:42:36,680
worst world we have the gate horn that's

890
00:42:42,980 --> 00:42:45,980
also

