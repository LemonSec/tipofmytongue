1
00:00:04,670 --> 00:00:06,650
so happy to introduce our next speaker

2
00:00:06,650 --> 00:00:08,389
in the black track Matt Trevor's he'll

3
00:00:08,389 --> 00:00:09,980
be presenting on threat modeling for

4
00:00:09,980 --> 00:00:12,080
security professionals a little bit

5
00:00:12,080 --> 00:00:13,940
about Matt Matt Trevor's is a technical

6
00:00:13,940 --> 00:00:15,740
manager for Carnegie Mellon's software

7
00:00:15,740 --> 00:00:18,110
engineering institute matt has more than

8
00:00:18,110 --> 00:00:19,580
15 years of experience in information

9
00:00:19,580 --> 00:00:22,220
technology information security and

10
00:00:22,220 --> 00:00:24,019
secure software development strategies

11
00:00:24,019 --> 00:00:26,269
matt obtained his master's in computer

12
00:00:26,269 --> 00:00:27,949
information systems from Boston

13
00:00:27,949 --> 00:00:29,539
University and his bachelor's in

14
00:00:29,539 --> 00:00:31,099
computer science from the University of

15
00:00:31,099 --> 00:00:31,910
New Brunswick

16
00:00:31,910 --> 00:00:36,260
Matt also holds the CISM cissp and C CSP

17
00:00:36,260 --> 00:00:38,629
professional credentials with that like

18
00:00:38,629 --> 00:00:46,449
to welcome at Trevor's Thank You Ryan

19
00:00:46,449 --> 00:00:49,340
all right so he stole one of my slides

20
00:00:49,340 --> 00:00:51,140
which is good because I have too many

21
00:00:51,140 --> 00:00:55,430
for 30 minutes the obligatory SDI

22
00:00:55,430 --> 00:00:59,000
disclaimer so we'll go through that so

23
00:00:59,000 --> 00:01:00,170
what we're gonna talk about today a

24
00:01:00,170 --> 00:01:01,850
little bit about me I'll go over some

25
00:01:01,850 --> 00:01:03,920
terms so when I say things you'll know

26
00:01:03,920 --> 00:01:06,740
what I what I mean may be different than

27
00:01:06,740 --> 00:01:10,159
what you interpret we'll go over when we

28
00:01:10,159 --> 00:01:11,900
should do this exercise what the

29
00:01:11,900 --> 00:01:14,540
exercise is and why we're doing it I'll

30
00:01:14,540 --> 00:01:16,460
review the OWASP top 10 pretty quickly

31
00:01:16,460 --> 00:01:18,799
then the meet the stride threat modeling

32
00:01:18,799 --> 00:01:20,990
then I'll throw in some octave Allegro

33
00:01:20,990 --> 00:01:24,280
some mitigation strategies you can use

34
00:01:24,280 --> 00:01:26,570
alternate sources of threats and then

35
00:01:26,570 --> 00:01:29,750
obviously a summary so Matt Trevor's

36
00:01:29,750 --> 00:01:31,100
this is always the most complicated

37
00:01:31,100 --> 00:01:33,649
slide in my deck because our company has

38
00:01:33,649 --> 00:01:36,590
an identity crisis so depending on where

39
00:01:36,590 --> 00:01:39,500
you are some people know search division

40
00:01:39,500 --> 00:01:42,020
some people know the sei and some people

41
00:01:42,020 --> 00:01:45,920
know Carnegie Mellon so I work for the

42
00:01:45,920 --> 00:01:47,869
search division at the software

43
00:01:47,869 --> 00:01:49,909
engineering Institute which is attached

44
00:01:49,909 --> 00:01:52,909
to Carnegie Mellon we are an FFRDC which

45
00:01:52,909 --> 00:01:54,320
is a federally funded research and

46
00:01:54,320 --> 00:01:56,780
development center we do lost lots of

47
00:01:56,780 --> 00:02:00,380
awesome stuff we are hiring this

48
00:02:00,380 --> 00:02:01,759
gentleman in the front right here is

49
00:02:01,759 --> 00:02:05,000
looking for a pen tester so one quick

50
00:02:05,000 --> 00:02:06,630
reminder that we

51
00:02:06,630 --> 00:02:09,270
have lightning talk tracks going over

52
00:02:09,270 --> 00:02:12,750
during lunch so if you'd like to go to

53
00:02:12,750 --> 00:02:15,750
either the gold or black track we do

54
00:02:15,750 --> 00:02:18,739
have some 30 minute talks lined up

55
00:02:18,739 --> 00:02:21,239
otherwise feel free to continue of your

56
00:02:21,239 --> 00:02:24,000
lunch we do have beverages that are

57
00:02:24,000 --> 00:02:25,709
being served including of the adult

58
00:02:25,709 --> 00:02:29,160
variety so if you would like to join

59
00:02:29,160 --> 00:02:30,870
those talks though please start making

60
00:02:30,870 --> 00:02:32,310
your way there we'll give you about five

61
00:02:32,310 --> 00:02:38,090
minutes or we'll just continue along so

62
00:02:38,090 --> 00:02:40,950
some terms and these look pretty obvious

63
00:02:40,950 --> 00:02:42,330
but I just want to make sure that we're

64
00:02:42,330 --> 00:02:43,620
all on the same page when I say things

65
00:02:43,620 --> 00:02:46,830
so a threat when I say threat I think of

66
00:02:46,830 --> 00:02:48,600
anything that negatively impacts your

67
00:02:48,600 --> 00:02:50,550
business right it can be an advanced

68
00:02:50,550 --> 00:02:52,680
persistent threat such as a nation state

69
00:02:52,680 --> 00:02:54,239
it could be a script kitty who just

70
00:02:54,239 --> 00:02:56,819
found this super new tool and starts

71
00:02:56,819 --> 00:02:59,310
banging on your website can also be an

72
00:02:59,310 --> 00:03:01,739
insider right an insider threat or a

73
00:03:01,739 --> 00:03:03,900
disgruntled employee it could also be

74
00:03:03,900 --> 00:03:06,510
the backhoe operator about to put their

75
00:03:06,510 --> 00:03:08,130
bucket through your internet line right

76
00:03:08,130 --> 00:03:10,100
that's also a threat to your business a

77
00:03:10,100 --> 00:03:13,410
vulnerability unknown or unknown

78
00:03:13,410 --> 00:03:15,810
weakness so the most popular would be

79
00:03:15,810 --> 00:03:17,790
zero days right that's what we all hear

80
00:03:17,790 --> 00:03:19,980
about in the news is zero day this zero

81
00:03:19,980 --> 00:03:23,600
day that vulnerabilities can also be

82
00:03:23,600 --> 00:03:25,799
propping your door open so if you have

83
00:03:25,799 --> 00:03:28,549
access control at your organization and

84
00:03:28,549 --> 00:03:31,739
somebody's moving stuff and they put a a

85
00:03:31,739 --> 00:03:33,390
door blocker in there that's also a

86
00:03:33,390 --> 00:03:36,680
vulnerability asset

87
00:03:36,680 --> 00:03:41,180
assets so there are four types of assets

88
00:03:41,180 --> 00:03:45,090
when I talk about them so information so

89
00:03:45,090 --> 00:03:47,220
any information created by your system

90
00:03:47,220 --> 00:03:49,410
so if you have a customer relation

91
00:03:49,410 --> 00:03:51,450
management system the data created by

92
00:03:51,450 --> 00:03:54,090
the CRM would be an information asset

93
00:03:54,090 --> 00:03:56,310
log files can also vote also be

94
00:03:56,310 --> 00:03:58,680
information assets then we have

95
00:03:58,680 --> 00:04:00,269
technology which are just the hardware

96
00:04:00,269 --> 00:04:02,090
and software that drive your business

97
00:04:02,090 --> 00:04:04,859
people we also consider people assets

98
00:04:04,859 --> 00:04:06,359
the people that operate your critical

99
00:04:06,359 --> 00:04:08,459
service and then facilities the

100
00:04:08,459 --> 00:04:09,660
facilities would be the the

101
00:04:09,660 --> 00:04:11,190
brick-and-mortar buildings where any of

102
00:04:11,190 --> 00:04:16,620
the other asset types reside risk so if

103
00:04:16,620 --> 00:04:18,690
you've taken your cissp you're probably

104
00:04:18,690 --> 00:04:20,519
thinking threat times

105
00:04:20,519 --> 00:04:23,580
that's the the base one right if you

106
00:04:23,580 --> 00:04:26,310
come from different lines of business

107
00:04:26,310 --> 00:04:27,870
you may be thinking probability and

108
00:04:27,870 --> 00:04:30,990
severity or impact and likelihood when I

109
00:04:30,990 --> 00:04:34,500
talk about risk I talk about the the

110
00:04:34,500 --> 00:04:37,290
likelihood of a threat exploiting a

111
00:04:37,290 --> 00:04:38,910
vulnerability and the severity of that

112
00:04:38,910 --> 00:04:41,420
exploitation that is how I typically

113
00:04:41,420 --> 00:04:45,330
define risk we have qualitative and

114
00:04:45,330 --> 00:04:47,070
quantitative which which are both two

115
00:04:47,070 --> 00:04:50,040
different types of risks for us non

116
00:04:50,040 --> 00:04:52,710
experts in risk qualitative is usually

117
00:04:52,710 --> 00:04:54,330
where we start that'll be where you see

118
00:04:54,330 --> 00:04:56,490
a matrix where you'll have low moderate

119
00:04:56,490 --> 00:04:58,070
and high and then maybe different

120
00:04:58,070 --> 00:05:00,950
different items so two popular

121
00:05:00,950 --> 00:05:05,250
qualitative risk analysis are Dredd

122
00:05:05,250 --> 00:05:07,770
which is made by Microsoft and then

123
00:05:07,770 --> 00:05:11,030
octave which is Carnegie Mellon product

124
00:05:11,030 --> 00:05:14,460
quantitative is for professionals this

125
00:05:14,460 --> 00:05:16,590
is where youyou speak in terms of

126
00:05:16,590 --> 00:05:21,360
finances or percentages a really good

127
00:05:21,360 --> 00:05:23,550
example is fare factor analysis or

128
00:05:23,550 --> 00:05:25,890
information risk they fancy themselves a

129
00:05:25,890 --> 00:05:28,230
quantitative risk analysis also if you

130
00:05:28,230 --> 00:05:30,330
read the book how to measure anything in

131
00:05:30,330 --> 00:05:32,610
cybersecurity risk they will talk about

132
00:05:32,610 --> 00:05:36,600
using confidence intervals in Monte

133
00:05:36,600 --> 00:05:38,760
Carlo simulations to be able to make a

134
00:05:38,760 --> 00:05:40,920
statement such as I can state with 90

135
00:05:40,920 --> 00:05:42,930
percent confidence that if you don't

136
00:05:42,930 --> 00:05:45,000
install this control you will have a

137
00:05:45,000 --> 00:05:47,070
twenty to twenty-five percent of data

138
00:05:47,070 --> 00:05:48,810
breach in the next six months that's

139
00:05:48,810 --> 00:05:52,320
very complicated and not the subject of

140
00:05:52,320 --> 00:05:55,260
today's talk but that is where people

141
00:05:55,260 --> 00:05:56,760
want to go they want to be able to

142
00:05:56,760 --> 00:06:00,540
quantify their risks and then two of the

143
00:06:00,540 --> 00:06:02,190
topics we'll talk about today stride and

144
00:06:02,190 --> 00:06:04,560
octave stride is a threat modeling

145
00:06:04,560 --> 00:06:06,360
framework created by Microsoft in their

146
00:06:06,360 --> 00:06:08,880
late 90s that stands for spoofing

147
00:06:08,880 --> 00:06:10,710
tampering repudiation information

148
00:06:10,710 --> 00:06:12,090
disclosure denial of service and

149
00:06:12,090 --> 00:06:13,770
elevation of privilege we'll get into

150
00:06:13,770 --> 00:06:16,290
that and what it actually means and then

151
00:06:16,290 --> 00:06:19,100
octave is a risk analysis framework

152
00:06:19,100 --> 00:06:21,510
operationally critical threat asset and

153
00:06:21,510 --> 00:06:23,670
vulnerability evaluation so we'll talk a

154
00:06:23,670 --> 00:06:25,830
little bit about that and you'll see why

155
00:06:25,830 --> 00:06:26,990
in a moment

156
00:06:26,990 --> 00:06:30,450
okay so what exactly is this and when

157
00:06:30,450 --> 00:06:32,910
what and why should we do this so you

158
00:06:32,910 --> 00:06:33,780
want to do

159
00:06:33,780 --> 00:06:36,120
the threat modeling as early in your

160
00:06:36,120 --> 00:06:38,850
development lifecycle as possible so if

161
00:06:38,850 --> 00:06:41,310
you think of discover design develop

162
00:06:41,310 --> 00:06:44,600
debug deploy maintain dispose as as the

163
00:06:44,600 --> 00:06:46,440
system development or software

164
00:06:46,440 --> 00:06:47,910
development lifecycle you want to move

165
00:06:47,910 --> 00:06:50,400
this as far left because this is going

166
00:06:50,400 --> 00:06:52,380
to help you with your testing and I

167
00:06:52,380 --> 00:06:54,630
think we've all seen that when you do

168
00:06:54,630 --> 00:06:57,540
testing or have your requirements

169
00:06:57,540 --> 00:06:59,370
defined you are going to save your

170
00:06:59,370 --> 00:07:01,230
company money because you're gonna find

171
00:07:01,230 --> 00:07:03,840
vulnerabilities or issues with your

172
00:07:03,840 --> 00:07:06,540
product much quicker so if you don't

173
00:07:06,540 --> 00:07:07,919
find it until it's published to the

174
00:07:07,919 --> 00:07:09,990
field you have to get your helpdesk

175
00:07:09,990 --> 00:07:12,060
involved and then somebody has to triage

176
00:07:12,060 --> 00:07:14,330
it and it goes to level two and then

177
00:07:14,330 --> 00:07:16,500
developers have to be assigned to it and

178
00:07:16,500 --> 00:07:18,419
management has to get involved so it

179
00:07:18,419 --> 00:07:20,340
gets very costly very quickly the

180
00:07:20,340 --> 00:07:24,440
further down the pipeline you find a bug

181
00:07:24,440 --> 00:07:26,880
functional versus security testing so

182
00:07:26,880 --> 00:07:29,070
I'm going to just use login a login page

183
00:07:29,070 --> 00:07:32,400
as an example so functional testing on a

184
00:07:32,400 --> 00:07:34,710
login page would basically be putting

185
00:07:34,710 --> 00:07:36,000
the right username with the right

186
00:07:36,000 --> 00:07:37,680
password in and it logs you into the

187
00:07:37,680 --> 00:07:39,500
system right so that would be a check

188
00:07:39,500 --> 00:07:42,210
also you would check for a login with a

189
00:07:42,210 --> 00:07:43,860
bad password and it would say invalid

190
00:07:43,860 --> 00:07:45,660
username or password that was would be

191
00:07:45,660 --> 00:07:47,430
typical tests that you would run against

192
00:07:47,430 --> 00:07:50,130
a login page security testing or

193
00:07:50,130 --> 00:07:51,930
negative testing is where you hit it

194
00:07:51,930 --> 00:07:54,300
with special characters so first thing I

195
00:07:54,300 --> 00:07:56,220
would try on a login page is maybe some

196
00:07:56,220 --> 00:07:57,660
sequel injection right so I'm going to

197
00:07:57,660 --> 00:08:00,479
throw some single quotes or some other

198
00:08:00,479 --> 00:08:03,060
characters that may cause the system to

199
00:08:03,060 --> 00:08:07,710
deviate from its normal process flow or

200
00:08:07,710 --> 00:08:09,419
I'm going to fuzz the field and try to

201
00:08:09,419 --> 00:08:11,490
put 10,000 characters in it anything I

202
00:08:11,490 --> 00:08:15,900
can do to deviate so that's great for

203
00:08:15,900 --> 00:08:17,640
technical folks but business folks are

204
00:08:17,640 --> 00:08:19,410
gonna say why the hell am i spending

205
00:08:19,410 --> 00:08:21,950
money on this right it's it's added cost

206
00:08:21,950 --> 00:08:25,460
so what your business speak you're gonna

207
00:08:25,460 --> 00:08:27,180
increase the return on investment

208
00:08:27,180 --> 00:08:30,240
because you're going to move the the

209
00:08:30,240 --> 00:08:31,650
finding of the vulnerabilities of the

210
00:08:31,650 --> 00:08:33,839
bugs to the left of your process which

211
00:08:33,839 --> 00:08:35,520
is going to decrease your total cost of

212
00:08:35,520 --> 00:08:37,860
ownership it's also going to save you a

213
00:08:37,860 --> 00:08:39,479
little bit of embarrassment because if

214
00:08:39,479 --> 00:08:41,280
you don't find something until it gets

215
00:08:41,280 --> 00:08:43,530
in the news or it gets in the public it

216
00:08:43,530 --> 00:08:45,720
will make its way to the news and then

217
00:08:45,720 --> 00:08:46,690
you will have

218
00:08:46,690 --> 00:08:50,410
on your face so increase ROI decreased

219
00:08:50,410 --> 00:08:55,330
TCO okay so one of the I'm assuming

220
00:08:55,330 --> 00:08:57,040
everybody in here is familiar with our

221
00:08:57,040 --> 00:09:01,900
wasp right right great great yeah great

222
00:09:01,900 --> 00:09:04,090
company international right security

223
00:09:04,090 --> 00:09:05,200
professionals all over the world

224
00:09:05,200 --> 00:09:07,870
participate they have many top-10 lists

225
00:09:07,870 --> 00:09:09,340
including the one we'll talk about today

226
00:09:09,340 --> 00:09:11,950
in addition to mobile and proactive

227
00:09:11,950 --> 00:09:15,700
controls is that a jet attack proxy is a

228
00:09:15,700 --> 00:09:19,240
really good open source tool you can use

229
00:09:19,240 --> 00:09:21,640
to test your application and then Sam

230
00:09:21,640 --> 00:09:23,820
for those that would like to

231
00:09:23,820 --> 00:09:27,100
institutionalize the practices that help

232
00:09:27,100 --> 00:09:30,610
build better software Sam so as you'll

233
00:09:30,610 --> 00:09:33,430
see there are two lists up here I have

234
00:09:33,430 --> 00:09:36,850
the 2013 in the 2017 there was some

235
00:09:36,850 --> 00:09:38,800
movement but not a great deal they

236
00:09:38,800 --> 00:09:42,150
changed some top and some titles

237
00:09:42,150 --> 00:09:45,040
injection is still at the top I would

238
00:09:45,040 --> 00:09:46,060
have thought we would have fixed that

239
00:09:46,060 --> 00:09:48,780
since 2003 but apparently we have not

240
00:09:48,780 --> 00:09:51,160
cross site scripting sensitive data

241
00:09:51,160 --> 00:09:53,620
exposure two of the big ones that don't

242
00:09:53,620 --> 00:09:55,180
get a lot of love are Security

243
00:09:55,180 --> 00:09:57,460
misconfigurations and using components

244
00:09:57,460 --> 00:09:59,380
with known vulnerabilities software

245
00:09:59,380 --> 00:10:00,760
supply chain is becoming one of the

246
00:10:00,760 --> 00:10:03,070
biggest problems we have because as

247
00:10:03,070 --> 00:10:06,370
people just adopts code off github and

248
00:10:06,370 --> 00:10:08,530
don't really run it through code

249
00:10:08,530 --> 00:10:10,500
analyzer you're introducing

250
00:10:10,500 --> 00:10:12,640
vulnerabilities your your solution and

251
00:10:12,640 --> 00:10:17,290
you may not even realize all right so a

252
00:10:17,290 --> 00:10:18,640
threat modeling with stride it's

253
00:10:18,640 --> 00:10:20,250
actually pretty easy

254
00:10:20,250 --> 00:10:24,100
so we have our spoofing tampering

255
00:10:24,100 --> 00:10:26,890
repudiation so on and so forth they are

256
00:10:26,890 --> 00:10:29,890
each associated with a security

257
00:10:29,890 --> 00:10:31,150
principle that you should be familiar

258
00:10:31,150 --> 00:10:33,460
with so the reason why they called it

259
00:10:33,460 --> 00:10:35,050
stride is because they couldn't come up

260
00:10:35,050 --> 00:10:38,710
with a good acronym using CI a and the

261
00:10:38,710 --> 00:10:40,720
other term so that was why they came up

262
00:10:40,720 --> 00:10:42,600
with stride because it sounded cool

263
00:10:42,600 --> 00:10:45,910
anyways what they've decided is you have

264
00:10:45,910 --> 00:10:48,640
the vi threat categories and you have

265
00:10:48,640 --> 00:10:52,080
four different

266
00:10:53,120 --> 00:10:55,440
depictions that are part of your data

267
00:10:55,440 --> 00:10:57,240
flow diagram so you're going to talk

268
00:10:57,240 --> 00:10:59,130
about external entities which would be

269
00:10:59,130 --> 00:11:01,950
web browsers or third-party integrations

270
00:11:01,950 --> 00:11:04,380
so if you're using Open ID Connect or an

271
00:11:04,380 --> 00:11:06,600
OAuth and you're sending it off to have

272
00:11:06,600 --> 00:11:09,690
somebody else authenticate your users

273
00:11:09,690 --> 00:11:12,180
that would be considered an external

274
00:11:12,180 --> 00:11:14,940
entity and if you look in the top left

275
00:11:14,940 --> 00:11:17,640
corner you'll see that you don't execute

276
00:11:17,640 --> 00:11:21,029
every element of Stride against every

277
00:11:21,029 --> 00:11:22,980
type of entity right so they've gone

278
00:11:22,980 --> 00:11:26,459
through and and made it this is where

279
00:11:26,459 --> 00:11:27,930
you should start now if you feel that

280
00:11:27,930 --> 00:11:30,930
something else needs to be evaluated

281
00:11:30,930 --> 00:11:33,709
feel free this was just their starting

282
00:11:33,709 --> 00:11:37,220
point any questions so far

283
00:11:37,220 --> 00:11:42,269
nope yep right all right so what you do

284
00:11:42,269 --> 00:11:44,579
is you draw a data flow diagram in a

285
00:11:44,579 --> 00:11:45,870
large system this can get pretty

286
00:11:45,870 --> 00:11:49,110
unwieldly so if you're doing a

287
00:11:49,110 --> 00:11:50,930
brownfield so an existing situation

288
00:11:50,930 --> 00:11:54,810
maybe break it up into blocks if this is

289
00:11:54,810 --> 00:11:57,570
greenfield maybe do the same thing as

290
00:11:57,570 --> 00:11:59,370
you can see I have all four asset types

291
00:11:59,370 --> 00:12:02,070
but then I also have dashed lines the

292
00:12:02,070 --> 00:12:04,079
dashed lines to me just represent

293
00:12:04,079 --> 00:12:06,990
network enclaves so we may have DMZ s

294
00:12:06,990 --> 00:12:10,500
you may have extra secure storage in the

295
00:12:10,500 --> 00:12:11,940
in the back because you have your

296
00:12:11,940 --> 00:12:14,790
databases and just want to talk a little

297
00:12:14,790 --> 00:12:17,010
bit about the various data stores I have

298
00:12:17,010 --> 00:12:19,649
so if you look over here I have customer

299
00:12:19,649 --> 00:12:21,990
data but I also have the database backup

300
00:12:21,990 --> 00:12:23,730
right a lot of people will backup the

301
00:12:23,730 --> 00:12:26,130
database with sensitive data and then

302
00:12:26,130 --> 00:12:28,320
forget they did it and now you have

303
00:12:28,320 --> 00:12:29,880
access to your system so it doesn't do a

304
00:12:29,880 --> 00:12:31,140
lot of good to have sensitive

305
00:12:31,140 --> 00:12:33,720
information backed up to a login and not

306
00:12:33,720 --> 00:12:35,880
pay attention to the database backup

307
00:12:35,880 --> 00:12:37,980
you'll also see that I have a process

308
00:12:37,980 --> 00:12:41,100
here for our DBMS right that's your

309
00:12:41,100 --> 00:12:43,529
relational database management system so

310
00:12:43,529 --> 00:12:45,240
when you when you evaluate a database

311
00:12:45,240 --> 00:12:47,760
you have to evaluate the data store and

312
00:12:47,760 --> 00:12:51,230
the process by which you're evaluating

313
00:12:51,230 --> 00:12:53,519
again for reference we have in the

314
00:12:53,519 --> 00:12:55,649
bottom left corner the stride matrix and

315
00:12:55,649 --> 00:12:59,610
then this is a term a sentence that I I

316
00:12:59,610 --> 00:13:03,500
created to help make sure that you you

317
00:13:03,500 --> 00:13:05,360
classify it is

318
00:13:05,360 --> 00:13:07,970
threat of a threat actor using one of

319
00:13:07,970 --> 00:13:11,540
the stride executing against one a year

320
00:13:11,540 --> 00:13:13,640
your your data flow diagrams by

321
00:13:13,640 --> 00:13:16,700
exploiting a no hospital 10 so is there

322
00:13:16,700 --> 00:13:18,589
a threat of a threat act a threat actor

323
00:13:18,589 --> 00:13:21,350
spoofing an external entity by

324
00:13:21,350 --> 00:13:24,920
exploiting sequel objection right and

325
00:13:24,920 --> 00:13:26,720
then you can make a quick snap decision

326
00:13:26,720 --> 00:13:28,790
yes that sounds like something I should

327
00:13:28,790 --> 00:13:30,470
pursue and now I'm not going to worry

328
00:13:30,470 --> 00:13:33,040
about it because it doesn't seem likely

329
00:13:33,040 --> 00:13:40,970
okay so that can get really complicated

330
00:13:40,970 --> 00:13:43,640
to to go through all 10 for all the time

331
00:13:43,640 --> 00:13:45,740
so what I would encourage you to do and

332
00:13:45,740 --> 00:13:48,230
this slide deck will be available for

333
00:13:48,230 --> 00:13:52,670
download after the conference go through

334
00:13:52,670 --> 00:13:56,269
and just Mark X's in a bigger matrix so

335
00:13:56,269 --> 00:13:59,410
I pick spoofing external entity

336
00:13:59,410 --> 00:14:02,920
injection broken authentication

337
00:14:02,920 --> 00:14:06,260
sensitive data exposure and you go down

338
00:14:06,260 --> 00:14:09,230
and this is again just but something to

339
00:14:09,230 --> 00:14:11,089
start with so it may be different for

340
00:14:11,089 --> 00:14:13,910
your system but this is these are the

341
00:14:13,910 --> 00:14:17,360
different lost popped ends that you

342
00:14:17,360 --> 00:14:20,660
would evaluate her combination if you'll

343
00:14:20,660 --> 00:14:23,870
notice as I mentioned earlier a 6 and a

344
00:14:23,870 --> 00:14:27,290
9 are completely checked right because

345
00:14:27,290 --> 00:14:28,820
you should be checking for known

346
00:14:28,820 --> 00:14:31,070
components known vulnerable components

347
00:14:31,070 --> 00:14:33,769
and miss configurations at every step of

348
00:14:33,769 --> 00:14:40,310
the way so imagine you do this against

349
00:14:40,310 --> 00:14:43,040
your system you're going to have a large

350
00:14:43,040 --> 00:14:44,570
number of things that you're going to

351
00:14:44,570 --> 00:14:46,670
want to check right and if this is the

352
00:14:46,670 --> 00:14:48,260
first time you're doing a threat model

353
00:14:48,260 --> 00:14:50,269
you're gonna be overwhelmed because

354
00:14:50,269 --> 00:14:52,339
there's going to be 400 things for you

355
00:14:52,339 --> 00:14:54,920
to check on right and you're gonna panic

356
00:14:54,920 --> 00:14:56,630
and throw in the garbage and say just

357
00:14:56,630 --> 00:14:58,940
stick your head in the sand so what you

358
00:14:58,940 --> 00:15:01,880
can do is use a risk analysis such as

359
00:15:01,880 --> 00:15:05,810
octave Allegro to help you order the

360
00:15:05,810 --> 00:15:10,730
important risks near the top so it's a

361
00:15:10,730 --> 00:15:13,279
qualitative risk analysis framework and

362
00:15:13,279 --> 00:15:14,899
it's going to help you prioritize the

363
00:15:14,899 --> 00:15:17,319
work and it does it in 8 steps

364
00:15:17,319 --> 00:15:19,940
the first step is defining your risk

365
00:15:19,940 --> 00:15:22,310
measurement criteria and don't do this

366
00:15:22,310 --> 00:15:24,139
by yourself go find your business folks

367
00:15:24,139 --> 00:15:26,240
right you are in business you're doing

368
00:15:26,240 --> 00:15:28,759
security to help the business move at

369
00:15:28,759 --> 00:15:30,980
the speed as fast as it can

370
00:15:30,980 --> 00:15:33,199
okay so don't try to make the risk

371
00:15:33,199 --> 00:15:35,290
measurement criteria by yourself go find

372
00:15:35,290 --> 00:15:38,120
some some business focus um risk risk

373
00:15:38,120 --> 00:15:41,569
folks so I come from health care so

374
00:15:41,569 --> 00:15:43,220
obviously my example is going to be

375
00:15:43,220 --> 00:15:44,990
healthcare base so the most important

376
00:15:44,990 --> 00:15:47,000
thing in medical device manufacturing is

377
00:15:47,000 --> 00:15:50,509
do no harm to the patient so that is the

378
00:15:50,509 --> 00:15:52,600
number one priority we have when we did

379
00:15:52,600 --> 00:15:55,639
risk analysis so near the top I have

380
00:15:55,639 --> 00:15:57,620
patient safety and then I have low

381
00:15:57,620 --> 00:16:00,139
moderate and high so low no are

382
00:16:00,139 --> 00:16:03,949
negligible delay in treatment a couple

383
00:16:03,949 --> 00:16:07,550
hours maybe for moderate and then much

384
00:16:07,550 --> 00:16:09,139
longer delayed or even death would be

385
00:16:09,139 --> 00:16:12,470
considered high right that's and then

386
00:16:12,470 --> 00:16:14,480
even if you don't hurt the patient you

387
00:16:14,480 --> 00:16:16,910
can't run afoul of the regulator's right

388
00:16:16,910 --> 00:16:19,550
you can't run afoul of Health and Human

389
00:16:19,550 --> 00:16:24,410
Services or any other entity that is

390
00:16:24,410 --> 00:16:26,689
paying attention so that would be the

391
00:16:26,689 --> 00:16:29,180
second highest risk for the organization

392
00:16:29,180 --> 00:16:31,430
then we have brand damage loss of

393
00:16:31,430 --> 00:16:32,959
productivity and customer confidence

394
00:16:32,959 --> 00:16:35,630
right so you define your risk matrix I

395
00:16:35,630 --> 00:16:38,360
pick five as a good starting place you

396
00:16:38,360 --> 00:16:41,000
can do for you can do twenty obviously

397
00:16:41,000 --> 00:16:42,439
if you do 20 it's going to take you a

398
00:16:42,439 --> 00:16:45,170
much greater amount of time to do the

399
00:16:45,170 --> 00:16:51,680
risk analysis so we've defined the the

400
00:16:51,680 --> 00:16:55,130
risk measurement criteria we kind of got

401
00:16:55,130 --> 00:16:58,009
these next to the information asset

402
00:16:58,009 --> 00:17:00,139
profile in the containers for free with

403
00:17:00,139 --> 00:17:02,300
our data flow diagram because we've

404
00:17:02,300 --> 00:17:04,250
defined where the data resides and we

405
00:17:04,250 --> 00:17:06,650
define what our network looks like or

406
00:17:06,650 --> 00:17:10,270
what our components look like together

407
00:17:10,869 --> 00:17:14,089
our areas of concern and threat scenario

408
00:17:14,089 --> 00:17:16,730
scenarios we already did

409
00:17:16,730 --> 00:17:19,789
using our stride analysis is there a

410
00:17:19,789 --> 00:17:23,770
threat of a threat actor kind of

411
00:17:24,220 --> 00:17:26,419
activity all right so all we have left

412
00:17:26,419 --> 00:17:30,309
now is to identify and mitigate risks

413
00:17:30,309 --> 00:17:33,980
so here's an example right we're gonna

414
00:17:33,980 --> 00:17:36,220
talk about spoofing and external entity

415
00:17:36,220 --> 00:17:38,779
so remember when I said Patient Safety

416
00:17:38,779 --> 00:17:41,000
is the highest it gets weighted as a

417
00:17:41,000 --> 00:17:45,590
five right so let's say I'm spoofing an

418
00:17:45,590 --> 00:17:47,240
external entity and I'm evaluating

419
00:17:47,240 --> 00:17:49,639
sequel injection right well typically

420
00:17:49,639 --> 00:17:51,169
when people do sequel injection they're

421
00:17:51,169 --> 00:17:52,789
not going in to change data they're just

422
00:17:52,789 --> 00:17:55,190
going in to exfiltrate the data from the

423
00:17:55,190 --> 00:17:58,909
network right so patient safety not

424
00:17:58,909 --> 00:18:01,149
really there it's not going to delay

425
00:18:01,149 --> 00:18:04,010
diagnosis it's just the data is going to

426
00:18:04,010 --> 00:18:07,100
go away right so it gets a low but since

427
00:18:07,100 --> 00:18:09,320
it's already waited as their highest it

428
00:18:09,320 --> 00:18:11,450
gets a five so we get five points for

429
00:18:11,450 --> 00:18:12,350
patient safety

430
00:18:12,350 --> 00:18:15,289
it may not negatively impact the safety

431
00:18:15,289 --> 00:18:17,419
of the patient but you're gonna hear

432
00:18:17,419 --> 00:18:19,850
from your regulator right if you have if

433
00:18:19,850 --> 00:18:22,700
you disclose more than 500 records in a

434
00:18:22,700 --> 00:18:24,740
geographical area you have to report it

435
00:18:24,740 --> 00:18:27,169
to Health and Human Services so that

436
00:18:27,169 --> 00:18:28,639
would mean that would be a high and

437
00:18:28,639 --> 00:18:31,190
since it was rated second highest

438
00:18:31,190 --> 00:18:31,850
priority

439
00:18:31,850 --> 00:18:35,809
it gets four so four times three is 12

440
00:18:35,809 --> 00:18:37,909
so regulatory legal gets a score of 12

441
00:18:37,909 --> 00:18:39,440
and then we have brand damage

442
00:18:39,440 --> 00:18:41,269
productivity and confidence they have

443
00:18:41,269 --> 00:18:43,549
their own scores we get a risk score of

444
00:18:43,549 --> 00:18:45,919
28 we move on to the next one right so

445
00:18:45,919 --> 00:18:48,049
you can do this in Excel in an Excel

446
00:18:48,049 --> 00:18:50,809
spreadsheet with dropdowns it's pretty

447
00:18:50,809 --> 00:18:54,470
easy but you're gonna do it for all of

448
00:18:54,470 --> 00:18:56,090
the various threats that you went

449
00:18:56,090 --> 00:18:58,100
through so every time you did is there a

450
00:18:58,100 --> 00:19:00,169
threat of a threat actor doing this side

451
00:19:00,169 --> 00:19:01,429
or the other thing each one of those

452
00:19:01,429 --> 00:19:03,440
would get a line and you're in your

453
00:19:03,440 --> 00:19:06,649
Excel spreadsheet now something you'll

454
00:19:06,649 --> 00:19:08,210
come to realize for those that

455
00:19:08,210 --> 00:19:09,710
participate in agile software

456
00:19:09,710 --> 00:19:13,730
development is this isn't going to fit

457
00:19:13,730 --> 00:19:16,519
neatly into a sprint right so you may

458
00:19:16,519 --> 00:19:19,429
have some risks that are off the charts

459
00:19:19,429 --> 00:19:22,880
high but are gonna take six eight ten

460
00:19:22,880 --> 00:19:26,000
twelve sprints so you're going to take

461
00:19:26,000 --> 00:19:27,440
those epics and break them down into

462
00:19:27,440 --> 00:19:31,100
smaller components of work but at least

463
00:19:31,100 --> 00:19:32,809
when you go to do that your product

464
00:19:32,809 --> 00:19:34,039
owner is going to be able to look at

465
00:19:34,039 --> 00:19:35,750
this justification as to why it's

466
00:19:35,750 --> 00:19:37,610
important that it's scheduled in your

467
00:19:37,610 --> 00:19:39,879
release

468
00:19:40,560 --> 00:19:45,480
so we've identified all these issues we

469
00:19:45,480 --> 00:19:48,120
have a couple hundred to fix where do we

470
00:19:48,120 --> 00:19:51,300
go to look for help so the Cloud

471
00:19:51,300 --> 00:19:53,040
Security Alliance cloud control matrix

472
00:19:53,040 --> 00:19:56,220
has a lot of really good ways to secure

473
00:19:56,220 --> 00:19:58,620
your cloud installation Internet

474
00:19:58,620 --> 00:20:00,270
engineering engineering task force

475
00:20:00,270 --> 00:20:02,490
standards o auth to transport layers

476
00:20:02,490 --> 00:20:04,980
acute security password-based key

477
00:20:04,980 --> 00:20:07,620
derivation functions all of that stuff

478
00:20:07,620 --> 00:20:09,240
is already done for you there's no sense

479
00:20:09,240 --> 00:20:11,550
rolling your own many of the frameworks

480
00:20:11,550 --> 00:20:14,400
such as the dinette framework has PD KDF

481
00:20:14,400 --> 00:20:16,410
built right in so you don't even have to

482
00:20:16,410 --> 00:20:18,660
to write those Center for Internet

483
00:20:18,660 --> 00:20:20,220
Security critical security controls

484
00:20:20,220 --> 00:20:22,380
they've just released version 7 one

485
00:20:22,380 --> 00:20:24,720
another great resource for determining

486
00:20:24,720 --> 00:20:28,790
how to mitigate risks 853 if your FISMA

487
00:20:28,790 --> 00:20:33,750
governed by government physical

488
00:20:33,750 --> 00:20:39,530
requirements you can use 853 or 171

489
00:20:39,530 --> 00:20:41,930
controlled unclassified information

490
00:20:41,930 --> 00:20:44,940
largely in line with 853 and then

491
00:20:44,940 --> 00:20:46,830
obviously international standards ISO

492
00:20:46,830 --> 00:20:49,050
27000 you're going to say wait Matt

493
00:20:49,050 --> 00:20:52,770
where's 27001 27001 is like a three-page

494
00:20:52,770 --> 00:20:56,280
document with just titles the the meet

495
00:20:56,280 --> 00:20:58,010
is all in twenty seven thousand two

496
00:20:58,010 --> 00:21:00,710
twenty seven thousand eighteen is

497
00:21:00,710 --> 00:21:04,410
privacy in the cloud if you come out of

498
00:21:04,410 --> 00:21:07,500
this with anything do not make your own

499
00:21:07,500 --> 00:21:10,800
you are not smarter than the entirety of

500
00:21:10,800 --> 00:21:13,290
the the international security community

501
00:21:13,290 --> 00:21:17,570
you are you will you just don't do it

502
00:21:17,570 --> 00:21:20,190
there's a lot of good stuff Oh wasp is

503
00:21:20,190 --> 00:21:21,990
also another really good place so I

504
00:21:21,990 --> 00:21:23,850
can't believe I took that bullet out but

505
00:21:23,850 --> 00:21:25,650
OS would be a good place to go because

506
00:21:25,650 --> 00:21:30,510
they have their proactive controls so

507
00:21:30,510 --> 00:21:33,480
when I gave this talk before people

508
00:21:33,480 --> 00:21:36,420
would say well I don't have a web app so

509
00:21:36,420 --> 00:21:38,240
what where do I go to find my threats

510
00:21:38,240 --> 00:21:43,610
well there's a really really really good

511
00:21:43,610 --> 00:21:46,350
document that is published I will have

512
00:21:46,350 --> 00:21:48,990
the resources and the in the last slide

513
00:21:48,990 --> 00:21:51,540
it's called Dodd car which is the DoD

514
00:21:51,540 --> 00:21:54,100
cybersecurity architecture review

515
00:21:54,100 --> 00:21:56,260
and they've worked with the mitre attack

516
00:21:56,260 --> 00:22:00,429
framework and basically given you a the

517
00:22:00,429 --> 00:22:03,510
landscape of what they consider the most

518
00:22:03,510 --> 00:22:07,120
prolific threat sources available today

519
00:22:07,120 --> 00:22:09,789
for your advanced persistent threats so

520
00:22:09,789 --> 00:22:12,280
it's broken down into stages objectives

521
00:22:12,280 --> 00:22:15,070
and actions and as you can see there

522
00:22:15,070 --> 00:22:20,590
quite a number of threats or ways folks

523
00:22:20,590 --> 00:22:24,640
can can external trade data or do other

524
00:22:24,640 --> 00:22:29,110
demand damage so in that document you'll

525
00:22:29,110 --> 00:22:31,090
see they'll have what they have a heat

526
00:22:31,090 --> 00:22:33,970
map and a coverage map so the the heat

527
00:22:33,970 --> 00:22:38,340
map is actually based on observed

528
00:22:38,340 --> 00:22:42,159
activities by it the NSA so the darker

529
00:22:42,159 --> 00:22:44,770
the color the more prevalent they've

530
00:22:44,770 --> 00:22:47,409
seen it in the wild so if you look up

531
00:22:47,409 --> 00:22:51,940
here for engage phase two spear phishing

532
00:22:51,940 --> 00:22:56,260
emails those never work right so that

533
00:22:56,260 --> 00:22:58,450
obviously they do work because they see

534
00:22:58,450 --> 00:23:01,539
them all the time I also see web sites

535
00:23:01,539 --> 00:23:03,880
vulnerabilities and your web sites right

536
00:23:03,880 --> 00:23:05,919
so these are the the things that if

537
00:23:05,919 --> 00:23:07,809
maybe you're not developing software but

538
00:23:07,809 --> 00:23:11,799
rather you're a systems engineer or an

539
00:23:11,799 --> 00:23:14,049
architect you could use this as your

540
00:23:14,049 --> 00:23:16,059
source of threat for what things you

541
00:23:16,059 --> 00:23:24,250
need to mitigate so and then we have the

542
00:23:24,250 --> 00:23:27,669
coverage map so that was observed this

543
00:23:27,669 --> 00:23:30,000
is based on a bunch of smees in a room

544
00:23:30,000 --> 00:23:32,169
evaluating against protect detect

545
00:23:32,169 --> 00:23:33,640
respond from the cyber security

546
00:23:33,640 --> 00:23:35,350
framework so they'll go through the

547
00:23:35,350 --> 00:23:38,909
exact same boxes as you saw on the other

548
00:23:38,909 --> 00:23:42,940
page but they will bunch of smart people

549
00:23:42,940 --> 00:23:44,559
got in a room and threw numbers out

550
00:23:44,559 --> 00:23:47,289
basically what happened right and now

551
00:23:47,289 --> 00:23:50,289
the the higher the numbers so obviously

552
00:23:50,289 --> 00:23:51,669
right is something you should consider

553
00:23:51,669 --> 00:23:53,919
and green may be something you can push

554
00:23:53,919 --> 00:24:00,620
off to later so in summary

555
00:24:00,620 --> 00:24:02,900
familiarize yourself threat sources you

556
00:24:02,900 --> 00:24:05,240
can either use the OAuth top 10 you can

557
00:24:05,240 --> 00:24:07,159
use Dodd car you can use a combination

558
00:24:07,159 --> 00:24:10,460
of both create your data flow diagram

559
00:24:10,460 --> 00:24:14,270
using the four shapes of stride define

560
00:24:14,270 --> 00:24:16,190
your risk measurement criteria from from

561
00:24:16,190 --> 00:24:17,690
octave Allegro so that you can

562
00:24:17,690 --> 00:24:20,690
prioritize them properly complete your

563
00:24:20,690 --> 00:24:24,039
worksheets again I just used Excel

564
00:24:24,039 --> 00:24:28,070
calculate your scores sort rank identify

565
00:24:28,070 --> 00:24:30,080
industry standard mitigations do not

566
00:24:30,080 --> 00:24:32,240
roll your own and then practice it's

567
00:24:32,240 --> 00:24:34,940
going to take you a while to get good at

568
00:24:34,940 --> 00:24:38,929
this I mean it is difficult when you

569
00:24:38,929 --> 00:24:40,460
just first come in and look at a data

570
00:24:40,460 --> 00:24:43,100
flow diagram and try to make sense of

571
00:24:43,100 --> 00:24:44,570
all the threats that is partially why I

572
00:24:44,570 --> 00:24:46,730
have that statement is there a threat of

573
00:24:46,730 --> 00:24:48,049
a threat actor because that will help

574
00:24:48,049 --> 00:24:51,559
you scope your work and with that I

575
00:24:51,559 --> 00:24:54,110
think that is it so there here are the

576
00:24:54,110 --> 00:24:56,840
resources so obviously OWASP Dodd Khan

577
00:24:56,840 --> 00:24:58,820
and NSA threat framework v2 or at the

578
00:24:58,820 --> 00:25:00,980
bottom there they're pretty good reads

579
00:25:00,980 --> 00:25:03,890
especially for technical folks you may

580
00:25:03,890 --> 00:25:06,649
consider things that you hadn't

581
00:25:06,649 --> 00:25:07,789
considered before when you're writing

582
00:25:07,789 --> 00:25:12,559
software or building out your cloud is

583
00:25:12,559 --> 00:25:16,340
or what have you and with that any

584
00:25:16,340 --> 00:25:21,250
questions no I'll be walking around

585
00:25:21,250 --> 00:25:23,390
around so if you have any questions you

586
00:25:23,390 --> 00:25:25,370
want to do one on one that's fine again

587
00:25:25,370 --> 00:25:27,380
I encourage you at 4 o'clock to go to

588
00:25:27,380 --> 00:25:29,870
Justin Forbes talk on how to frustrate a

589
00:25:29,870 --> 00:25:33,320
pen tester he's pretty good at it so I

590
00:25:33,320 --> 00:25:35,600
think you'll enjoy that as well so thank

591
00:25:35,600 --> 00:25:36,670
you very much

592
00:25:36,670 --> 00:25:41,119
[Applause]

