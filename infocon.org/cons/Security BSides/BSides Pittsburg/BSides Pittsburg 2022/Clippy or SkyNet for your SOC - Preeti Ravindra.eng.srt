1
00:00:00,000 --> 00:00:02,460
good evening everyone thank you very

2
00:00:02,460 --> 00:00:05,879
much for sticking around for the for

3
00:00:05,879 --> 00:00:06,960
this talk

4
00:00:06,960 --> 00:00:10,500
I'm really excited to talk about Clippy

5
00:00:10,500 --> 00:00:12,960
or Skynet for your security operations

6
00:00:12,960 --> 00:00:15,380
center

7
00:00:16,619 --> 00:00:18,439
a little bit about me

8
00:00:18,439 --> 00:00:21,840
I don't I mean I love solving security

9
00:00:21,840 --> 00:00:26,699
problems with data and when I say I love

10
00:00:26,699 --> 00:00:28,380
solving security problems with data I

11
00:00:28,380 --> 00:00:30,480
don't mean just machine learning or

12
00:00:30,480 --> 00:00:33,120
fancy deep learning I mean

13
00:00:33,120 --> 00:00:35,520
everything rules

14
00:00:35,520 --> 00:00:37,079
Analytics

15
00:00:37,079 --> 00:00:39,239
statistics

16
00:00:39,239 --> 00:00:41,780
machine learning and deep learning

17
00:00:41,780 --> 00:00:44,940
what I have done so far I've delivered a

18
00:00:44,940 --> 00:00:46,920
couple of analytics Ai and ml solutions

19
00:00:46,920 --> 00:00:50,539
for both security vendors as well as

20
00:00:50,539 --> 00:00:54,059
Enterprise security teams so I've had a

21
00:00:54,059 --> 00:00:56,239
perspective from both sides

22
00:00:56,239 --> 00:00:59,340
what I really like doing is helping

23
00:00:59,340 --> 00:01:03,120
security teams succeed in adopting

24
00:01:03,120 --> 00:01:05,220
uh data-driven approaches in their

25
00:01:05,220 --> 00:01:07,140
security operations center

26
00:01:07,140 --> 00:01:10,500
I advocate for risk driven security

27
00:01:10,500 --> 00:01:12,720
approaches I know a lot of focus goes on

28
00:01:12,720 --> 00:01:14,939
threats but I really like concentrating

29
00:01:14,939 --> 00:01:17,340
on the risks and what makes sense to

30
00:01:17,340 --> 00:01:18,960
mitigate those risks

31
00:01:18,960 --> 00:01:21,360
and finally I mean inventor on three

32
00:01:21,360 --> 00:01:23,759
patterns and I'm still a novice open

33
00:01:23,759 --> 00:01:27,180
source contributor and just fun fact I

34
00:01:27,180 --> 00:01:29,759
started my journey in Pittsburgh my

35
00:01:29,759 --> 00:01:30,960
security journey in Pittsburgh so I'm

36
00:01:30,960 --> 00:01:33,180
really happy to be here speaking at

37
00:01:33,180 --> 00:01:35,280
besides Pittsburgh I met a Carnegie

38
00:01:35,280 --> 00:01:37,439
Mellon did my internship here of course

39
00:01:37,439 --> 00:01:39,720
I love dark teens as evident from my

40
00:01:39,720 --> 00:01:41,880
slides

41
00:01:41,880 --> 00:01:46,158
uh so a quick show of hands

42
00:01:46,320 --> 00:01:50,280
how many people have dabbled with data

43
00:01:50,280 --> 00:01:53,399
science here or statistics

44
00:01:53,399 --> 00:01:56,640
okay good I have the amazing right kind

45
00:01:56,640 --> 00:01:59,520
of audience and how many people have

46
00:01:59,520 --> 00:02:02,579
actually implemented uh machine learning

47
00:02:02,579 --> 00:02:04,680
Solutions in your Security operation

48
00:02:04,680 --> 00:02:05,759
centers

49
00:02:05,759 --> 00:02:08,399
great uh I definitely see one for one

50
00:02:08,399 --> 00:02:11,038
hand there that's that's amazing and was

51
00:02:11,038 --> 00:02:13,640
it successful

52
00:02:15,239 --> 00:02:18,260
oh okay

53
00:02:20,400 --> 00:02:23,400
cool very cool uh it's always good to

54
00:02:23,400 --> 00:02:24,599
know

55
00:02:24,599 --> 00:02:26,879
um that people have at least tried to

56
00:02:26,879 --> 00:02:31,140
dabble with it and play with it and I'm

57
00:02:31,140 --> 00:02:33,480
just maybe the other question makes more

58
00:02:33,480 --> 00:02:37,080
sense how many people have seen failed

59
00:02:37,080 --> 00:02:39,379
machine learning projects

60
00:02:39,379 --> 00:02:41,940
great okay that's that's also great we

61
00:02:41,940 --> 00:02:45,319
have all the right kind of audience here

62
00:02:46,620 --> 00:02:49,440
um I think everybody has seen this

63
00:02:49,440 --> 00:02:53,400
statistic 85 percent of AI projects will

64
00:02:53,400 --> 00:02:55,200
fail through 2022. this was something

65
00:02:55,200 --> 00:03:00,300
that was told in 2018 and this has been

66
00:03:00,300 --> 00:03:02,400
the case so far

67
00:03:02,400 --> 00:03:06,300
um and this is not necessarily uh just

68
00:03:06,300 --> 00:03:10,140
limited to security operations but also

69
00:03:10,140 --> 00:03:14,040
across all domains

70
00:03:14,040 --> 00:03:17,340
but still already makes it even harder

71
00:03:17,340 --> 00:03:19,620
and that's because of the adversarial

72
00:03:19,620 --> 00:03:23,720
nature of our domain and 90 percent

73
00:03:23,720 --> 00:03:27,540
fail before they're even started and one

74
00:03:27,540 --> 00:03:31,860
of the reasons why they fail is because

75
00:03:31,860 --> 00:03:34,319
most of the times there is a mismatch in

76
00:03:34,319 --> 00:03:36,239
the problem that we choose as well as

77
00:03:36,239 --> 00:03:38,220
the approach that we choose to try and

78
00:03:38,220 --> 00:03:40,799
solve that problem

79
00:03:40,799 --> 00:03:42,959
and

80
00:03:42,959 --> 00:03:45,180
just like any other learning curve I

81
00:03:45,180 --> 00:03:46,920
think one thing that I have found in my

82
00:03:46,920 --> 00:03:48,420
experience is that the moment you get

83
00:03:48,420 --> 00:03:50,220
your first

84
00:03:50,220 --> 00:03:54,480
machine learning solution working and

85
00:03:54,480 --> 00:03:56,220
deployed

86
00:03:56,220 --> 00:03:59,700
it becomes much easier to deploy more

87
00:03:59,700 --> 00:04:02,400
solutions and you kind of get a feel or

88
00:04:02,400 --> 00:04:04,920
hang of what would work and what would

89
00:04:04,920 --> 00:04:07,339
not work

90
00:04:10,080 --> 00:04:12,720
yeah so today I'll talk about all the

91
00:04:12,720 --> 00:04:15,720
experiments that I have done in my

92
00:04:15,720 --> 00:04:17,600
career Journey so far

93
00:04:17,600 --> 00:04:22,280
and this is all specific to security

94
00:04:22,280 --> 00:04:26,040
security operations uh

95
00:04:26,040 --> 00:04:28,620
all the experiments are either decision

96
00:04:28,620 --> 00:04:30,419
support related or threat detection

97
00:04:30,419 --> 00:04:32,820
related and what I mean by decision

98
00:04:32,820 --> 00:04:36,600
support is where you use analytics

99
00:04:36,600 --> 00:04:42,060
machine learning solutions to help Drive

100
00:04:42,060 --> 00:04:44,759
to help Drive operational efficiency and

101
00:04:44,759 --> 00:04:47,940
to help the analysts make a decision as

102
00:04:47,940 --> 00:04:51,540
opposed to making a decision for them

103
00:04:51,540 --> 00:04:54,000
I'll also be talking or touching briefly

104
00:04:54,000 --> 00:04:55,440
upon the different kinds of solution

105
00:04:55,440 --> 00:04:58,020
complexities and you know why I thought

106
00:04:58,020 --> 00:05:00,180
one approach would work better than the

107
00:05:00,180 --> 00:05:03,720
other and in what circumstances

108
00:05:03,720 --> 00:05:07,020
and then later switch gears a bit uh to

109
00:05:07,020 --> 00:05:10,320
talk about what it takes to build a

110
00:05:10,320 --> 00:05:13,699
successful data science program

111
00:05:13,740 --> 00:05:15,479
and then finally

112
00:05:15,479 --> 00:05:18,720
wrap it up with certain takeaways like

113
00:05:18,720 --> 00:05:20,460
what what are some of the good bad and

114
00:05:20,460 --> 00:05:22,020
ugly things that I have seen so I think

115
00:05:22,020 --> 00:05:26,039
that's that's what I'll wrap up with

116
00:05:26,039 --> 00:05:27,539
another interesting thing that I wanted

117
00:05:27,539 --> 00:05:31,560
to touch upon in this talk is

118
00:05:31,560 --> 00:05:34,919
uh return on investment

119
00:05:34,919 --> 00:05:38,340
security operations as a whole

120
00:05:38,340 --> 00:05:42,240
has multiple moving components and one

121
00:05:42,240 --> 00:05:46,380
such moving component is

122
00:05:46,380 --> 00:05:49,620
the the risk appetite of a given

123
00:05:49,620 --> 00:05:51,840
organization what amount of risk are we

124
00:05:51,840 --> 00:05:53,639
willing to take and what amount of risk

125
00:05:53,639 --> 00:05:56,160
are we not willing to take and how does

126
00:05:56,160 --> 00:05:57,960
that drive the bottom line for the

127
00:05:57,960 --> 00:05:59,639
operations as well and what does it mean

128
00:05:59,639 --> 00:06:02,699
from a Security Act or threat efficacy

129
00:06:02,699 --> 00:06:05,060
purpose

130
00:06:06,000 --> 00:06:09,120
so coming back to the title of the talk

131
00:06:09,120 --> 00:06:12,780
um this is uh this is a slide where I

132
00:06:12,780 --> 00:06:15,360
have charted the complexity of the

133
00:06:15,360 --> 00:06:18,780
solutions along with the guidance that

134
00:06:18,780 --> 00:06:20,819
these different machine learning or

135
00:06:20,819 --> 00:06:22,979
analytics or any data-driven solution

136
00:06:22,979 --> 00:06:25,758
provides

137
00:06:27,840 --> 00:06:31,199
so why I wanted to point out here is

138
00:06:31,199 --> 00:06:34,139
that all right I've charted this

139
00:06:34,139 --> 00:06:36,419
um guidance is increasing from left to

140
00:06:36,419 --> 00:06:37,800
right and complexity is increasing from

141
00:06:37,800 --> 00:06:40,020
top to bottom

142
00:06:40,020 --> 00:06:42,180
um the image themselves I wanted to

143
00:06:42,180 --> 00:06:44,520
bring your attention to the images the

144
00:06:44,520 --> 00:06:46,860
image themselves uh they are generated

145
00:06:46,860 --> 00:06:51,000
by a recent advancement uh in

146
00:06:51,000 --> 00:06:52,620
um Ai and machine learning this is

147
00:06:52,620 --> 00:06:55,440
called the doll e model uh the doll e

148
00:06:55,440 --> 00:06:58,979
model basically takes a language input

149
00:06:58,979 --> 00:07:03,180
prompt and generates uh

150
00:07:03,180 --> 00:07:07,440
an image so of all the things that we

151
00:07:07,440 --> 00:07:10,080
thought would that AI would replace I

152
00:07:10,080 --> 00:07:12,240
never thought artists would be one of it

153
00:07:12,240 --> 00:07:14,639
one of them or meme creators maybe our

154
00:07:14,639 --> 00:07:18,360
AIS will be creating memes as well

155
00:07:18,360 --> 00:07:21,000
so the first image

156
00:07:21,000 --> 00:07:24,199
The Prompt that I gave for Dolly was

157
00:07:24,199 --> 00:07:26,639
clippy and clearly it doesn't look like

158
00:07:26,639 --> 00:07:28,560
clippy I mean it's there the outline is

159
00:07:28,560 --> 00:07:30,599
there but for me I don't know it looks

160
00:07:30,599 --> 00:07:31,740
more like

161
00:07:31,740 --> 00:07:35,220
a stethoscope or again with some missing

162
00:07:35,220 --> 00:07:37,139
components it definitely doesn't look

163
00:07:37,139 --> 00:07:39,660
like clippy to me

164
00:07:39,660 --> 00:07:42,720
and then I gave Dolly the prompt of

165
00:07:42,720 --> 00:07:46,860
Skynet and Skynet

166
00:07:46,860 --> 00:07:49,740
this was an interesting picture at least

167
00:07:49,740 --> 00:07:52,080
it was related

168
00:07:52,080 --> 00:07:54,180
um this is a picture of Terminator I was

169
00:07:54,180 --> 00:07:55,319
expecting to see something else for

170
00:07:55,319 --> 00:07:57,479
Skynet like I was expecting to see the

171
00:07:57,479 --> 00:08:00,360
logo of Skynet come up as shown in the

172
00:08:00,360 --> 00:08:03,539
Terminator franchisee uh so if anybody

173
00:08:03,539 --> 00:08:05,280
wants to play around with these prompts

174
00:08:05,280 --> 00:08:08,039
you can visit crayon.com and that's

175
00:08:08,039 --> 00:08:11,520
where uh the dolly creators have a

176
00:08:11,520 --> 00:08:13,379
back-end provided so you can just play

177
00:08:13,379 --> 00:08:17,340
with these uh prompts

178
00:08:17,340 --> 00:08:20,160
a fun fact here as well or just another

179
00:08:20,160 --> 00:08:22,379
thing that I was playing around so when

180
00:08:22,379 --> 00:08:24,120
I gave

181
00:08:24,120 --> 00:08:27,120
Skynet Helena Bonham Carter it actually

182
00:08:27,120 --> 00:08:29,460
showed me a picture of Helena Bonham

183
00:08:29,460 --> 00:08:33,240
Carter with a cyborg-like image and I

184
00:08:33,240 --> 00:08:34,919
thought that was funny but I didn't want

185
00:08:34,919 --> 00:08:36,958
to put it here it was not it was an

186
00:08:36,958 --> 00:08:39,319
eyesore

187
00:08:43,380 --> 00:08:46,140
just just coming back here

188
00:08:46,140 --> 00:08:47,820
um so I think I'm kind of foreshadowing

189
00:08:47,820 --> 00:08:50,820
already clippy or Skynet so this dolly

190
00:08:50,820 --> 00:08:54,060
model is state of the art it has 16

191
00:08:54,060 --> 00:08:56,279
billion parameters so if you think about

192
00:08:56,279 --> 00:08:57,779
a straight line a linear regression line

193
00:08:57,779 --> 00:08:59,760
that's y equals MX plus C that's just

194
00:08:59,760 --> 00:09:01,860
like one parameter but this dolly model

195
00:09:01,860 --> 00:09:04,980
is 16 billion parameters and when I gave

196
00:09:04,980 --> 00:09:08,339
clippy uh despite seeing a lot of words

197
00:09:08,339 --> 00:09:10,260
to image translations I think this was

198
00:09:10,260 --> 00:09:13,279
the best it could come up with

199
00:09:15,300 --> 00:09:17,820
so

200
00:09:17,820 --> 00:09:21,120
let's talk about The Usual Suspects I

201
00:09:21,120 --> 00:09:22,680
like to call these The Usual Suspects

202
00:09:22,680 --> 00:09:24,240
because

203
00:09:24,240 --> 00:09:25,920
um because you must have seen a lot of

204
00:09:25,920 --> 00:09:29,339
these things in Vendor talks so what are

205
00:09:29,339 --> 00:09:31,140
some of the most common

206
00:09:31,140 --> 00:09:34,500
applications where you we could leverage

207
00:09:34,500 --> 00:09:36,660
data to solve the problems in security

208
00:09:36,660 --> 00:09:38,339
operations there are multiple problems

209
00:09:38,339 --> 00:09:39,600
here so the first one is threat

210
00:09:39,600 --> 00:09:43,260
detection again here a huge umbrella

211
00:09:43,260 --> 00:09:45,300
under uh threat detection so you can

212
00:09:45,300 --> 00:09:47,060
have malware detection

213
00:09:47,060 --> 00:09:50,700
and outliers or user entity behavioral

214
00:09:50,700 --> 00:09:53,640
analytics I think more recently the

215
00:09:53,640 --> 00:09:58,440
trend is to collect micro detections and

216
00:09:58,440 --> 00:10:01,140
chain them up into an attack sequence

217
00:10:01,140 --> 00:10:02,640
because we all love miter attack

218
00:10:02,640 --> 00:10:04,200
framework

219
00:10:04,200 --> 00:10:06,240
uh so that's with the malware detection

220
00:10:06,240 --> 00:10:09,660
aspect the other data-driven Solutions

221
00:10:09,660 --> 00:10:11,519
are

222
00:10:11,519 --> 00:10:12,899
decision support and operational

223
00:10:12,899 --> 00:10:15,120
efficiency I think this is one of my

224
00:10:15,120 --> 00:10:16,880
personal favorites because this is again

225
00:10:16,880 --> 00:10:21,480
helping uh drill down on the actual

226
00:10:21,480 --> 00:10:24,240
volume of data and alerts that an

227
00:10:24,240 --> 00:10:26,399
analyst has to weed through as opposed

228
00:10:26,399 --> 00:10:27,140
to

229
00:10:27,140 --> 00:10:30,000
as opposed to just coming up with cool

230
00:10:30,000 --> 00:10:32,940
detection cool or and more detections

231
00:10:32,940 --> 00:10:34,740
which may or may not necessarily be

232
00:10:34,740 --> 00:10:35,940
useful

233
00:10:35,940 --> 00:10:39,060
so I think there are some really

234
00:10:39,060 --> 00:10:40,920
interesting

235
00:10:40,920 --> 00:10:43,019
um use cases around the decision support

236
00:10:43,019 --> 00:10:44,579
and then there's workflow in

237
00:10:44,579 --> 00:10:47,880
improvements workflow improvements are

238
00:10:47,880 --> 00:10:50,120
typically trying to

239
00:10:50,120 --> 00:10:52,440
integrate all these data driven

240
00:10:52,440 --> 00:10:54,779
Solutions better with the tool chain

241
00:10:54,779 --> 00:10:56,640
that is in a security Operation Center

242
00:10:56,640 --> 00:10:58,860
and there are a lot of playbooks that

243
00:10:58,860 --> 00:11:01,200
could be automated and all of these are

244
00:11:01,200 --> 00:11:02,399
data driven approaches you don't

245
00:11:02,399 --> 00:11:03,899
necessarily need fancy machine learning

246
00:11:03,899 --> 00:11:06,060
you can just look at some of the

247
00:11:06,060 --> 00:11:07,579
previous statistical

248
00:11:07,579 --> 00:11:09,899
dispositions and you could come up with

249
00:11:09,899 --> 00:11:13,920
some good workflow improvements

250
00:11:16,440 --> 00:11:19,680
yeah so uh Game of Thrones Game of

251
00:11:19,680 --> 00:11:21,899
Thrones fans would probably know uh

252
00:11:21,899 --> 00:11:23,760
trial by dead trial by combat and this

253
00:11:23,760 --> 00:11:26,940
trial by fire and uh I think I have done

254
00:11:26,940 --> 00:11:30,480
the trial by fire which is mostly uh

255
00:11:30,480 --> 00:11:32,820
diving deep into a lot of these

256
00:11:32,820 --> 00:11:35,700
experiments and sometimes coming out

257
00:11:35,700 --> 00:11:40,980
unscathed and sometimes being burnt so

258
00:11:41,279 --> 00:11:43,500
I'll briefly touch upon each of these

259
00:11:43,500 --> 00:11:45,360
quadrants like the first quadrant threat

260
00:11:45,360 --> 00:11:46,980
detection like what were some of the

261
00:11:46,980 --> 00:11:48,240
experiments that I did with thread

262
00:11:48,240 --> 00:11:50,519
digestion at a very high level and then

263
00:11:50,519 --> 00:11:52,680
I'll touch upon

264
00:11:52,680 --> 00:11:55,440
um how do we automate some of the most

265
00:11:55,440 --> 00:11:58,560
common triage processes I think earlier

266
00:11:58,560 --> 00:12:00,000
during the day

267
00:12:00,000 --> 00:12:03,480
um Aaron and another gentleman was

268
00:12:03,480 --> 00:12:04,860
talking about

269
00:12:04,860 --> 00:12:07,620
um how there are like so many alerts and

270
00:12:07,620 --> 00:12:09,660
events that somebody has to go through

271
00:12:09,660 --> 00:12:12,540
so definitely

272
00:12:12,540 --> 00:12:14,940
um I'll talk about how do we commonly I

273
00:12:14,940 --> 00:12:17,399
mean how do we tackle some of the triage

274
00:12:17,399 --> 00:12:20,760
processes and then

275
00:12:20,760 --> 00:12:22,980
the third one which is presenting the

276
00:12:22,980 --> 00:12:24,839
right kind of evidence so

277
00:12:24,839 --> 00:12:26,940
this is the critical part and I don't

278
00:12:26,940 --> 00:12:28,980
think a lot of us have gotten this right

279
00:12:28,980 --> 00:12:30,240
yet

280
00:12:30,240 --> 00:12:32,760
um most of the times I do see incident

281
00:12:32,760 --> 00:12:35,279
responders constantly trying to get the

282
00:12:35,279 --> 00:12:37,500
right kind of data when they need to

283
00:12:37,500 --> 00:12:39,240
make that decision and they don't have

284
00:12:39,240 --> 00:12:41,880
that information

285
00:12:41,880 --> 00:12:44,459
and I think that's what analytics or any

286
00:12:44,459 --> 00:12:47,100
data driven solution should address

287
00:12:47,100 --> 00:12:50,399
provide the right kind of

288
00:12:50,399 --> 00:12:52,980
incident response evidence like just

289
00:12:52,980 --> 00:12:54,420
provide the evidence that is timely

290
00:12:54,420 --> 00:12:56,599
enough

291
00:12:56,880 --> 00:12:58,680
and then I think there's like this

292
00:12:58,680 --> 00:13:00,779
common decision support theme so I can

293
00:13:00,779 --> 00:13:02,940
definitely cover that as well

294
00:13:02,940 --> 00:13:04,680
all right so the first one the thread

295
00:13:04,680 --> 00:13:07,500
detection aspect uh yes another ISO

296
00:13:07,500 --> 00:13:11,339
slide uh but this is pretty old uh this

297
00:13:11,339 --> 00:13:14,459
is a very simple

298
00:13:14,459 --> 00:13:17,220
uh obfuscation script and this was when

299
00:13:17,220 --> 00:13:18,540
I was

300
00:13:18,540 --> 00:13:21,240
beginning my career around like 2016

301
00:13:21,240 --> 00:13:23,880
2017 when expert kits were all the rage

302
00:13:23,880 --> 00:13:28,019
for uh the initial access as part of

303
00:13:28,019 --> 00:13:30,720
um and delivering uh ransomware payloads

304
00:13:30,720 --> 00:13:33,660
so expert kits would typically break the

305
00:13:33,660 --> 00:13:35,700
browser system sandbox

306
00:13:35,700 --> 00:13:39,000
um or Escape that sandbox and try to try

307
00:13:39,000 --> 00:13:42,060
to launch malware and most often that

308
00:13:42,060 --> 00:13:43,500
led to

309
00:13:43,500 --> 00:13:45,300
um ransomware

310
00:13:45,300 --> 00:13:47,399
so the first image here is just an

311
00:13:47,399 --> 00:13:49,380
obfuscated script and the second image

312
00:13:49,380 --> 00:13:50,820
here is actually what it looked like the

313
00:13:50,820 --> 00:13:52,860
obfuscated so I was doing a lot of this

314
00:13:52,860 --> 00:13:54,779
manually and obviously nobody likes to

315
00:13:54,779 --> 00:13:56,100
do a lot of

316
00:13:56,100 --> 00:13:59,940
manual vulnerability research or expert

317
00:13:59,940 --> 00:14:02,279
development uh one of the things that I

318
00:14:02,279 --> 00:14:05,459
came up with was to see if I could sure

319
00:14:05,459 --> 00:14:07,079
I understand what the exploit looks like

320
00:14:07,079 --> 00:14:08,940
I understand what the obfuscation looks

321
00:14:08,940 --> 00:14:10,380
like but it's really hard to catch all

322
00:14:10,380 --> 00:14:12,120
of these things with

323
00:14:12,120 --> 00:14:15,420
um very specific rules especially when

324
00:14:15,420 --> 00:14:18,000
they're changing all the time and they

325
00:14:18,000 --> 00:14:19,800
make very slight changes like for

326
00:14:19,800 --> 00:14:23,279
example you can see parent n plus

327
00:14:23,279 --> 00:14:23,839
ode

328
00:14:23,839 --> 00:14:26,940
next to the script zero on in about the

329
00:14:26,940 --> 00:14:30,720
fifth line and the first image

330
00:14:30,720 --> 00:14:32,339
um some other time they'll probably

331
00:14:32,339 --> 00:14:35,339
change that into a different kind of

332
00:14:35,339 --> 00:14:37,620
um string and that makes it a little

333
00:14:37,620 --> 00:14:40,260
difficult to catch these things so this

334
00:14:40,260 --> 00:14:43,320
is one uh example and

335
00:14:43,320 --> 00:14:46,440
expert kits May are gone now but I can

336
00:14:46,440 --> 00:14:49,079
assure you that very similar tactics are

337
00:14:49,079 --> 00:14:51,180
still being used especially when it

338
00:14:51,180 --> 00:14:52,860
comes to

339
00:14:52,860 --> 00:14:57,420
um fishing and when it comes to comes to

340
00:14:57,420 --> 00:15:01,019
a lot of Powershell or ramse script or

341
00:15:01,019 --> 00:15:02,579
first question so obfuscation is a

342
00:15:02,579 --> 00:15:04,500
fairly common technique

343
00:15:04,500 --> 00:15:05,699
um

344
00:15:05,699 --> 00:15:07,800
so what are some of the experiments like

345
00:15:07,800 --> 00:15:10,440
I think it's really critical to bring it

346
00:15:10,440 --> 00:15:12,720
down to a simple

347
00:15:12,720 --> 00:15:14,699
hypothesis or a simple problem statement

348
00:15:14,699 --> 00:15:16,560
and the problem statement was is this

349
00:15:16,560 --> 00:15:18,660
obfuscated or not

350
00:15:18,660 --> 00:15:20,160
and

351
00:15:20,160 --> 00:15:22,199
in terms of gathering the data we

352
00:15:22,199 --> 00:15:25,380
gathered a lot of benign data malicious

353
00:15:25,380 --> 00:15:28,199
data as well so we gathered some

354
00:15:28,199 --> 00:15:30,240
Mauritius landing pages they were all

355
00:15:30,240 --> 00:15:33,180
labeled fortunately which is a boon and

356
00:15:33,180 --> 00:15:35,279
that's typically does not happen in the

357
00:15:35,279 --> 00:15:36,480
security space

358
00:15:36,480 --> 00:15:39,060
uh we also gathered some full P caps

359
00:15:39,060 --> 00:15:40,860
just to look at what we can extract out

360
00:15:40,860 --> 00:15:42,899
of it and how that could help augment

361
00:15:42,899 --> 00:15:44,759
our models

362
00:15:44,759 --> 00:15:46,980
the modeling was a supervised approach

363
00:15:46,980 --> 00:15:48,180
because this was the first way to start

364
00:15:48,180 --> 00:15:50,279
we had the luxury of having label data

365
00:15:50,279 --> 00:15:53,699
again it was a luxury so really happy

366
00:15:53,699 --> 00:15:57,859
that we had the label data

367
00:15:58,199 --> 00:16:01,740
challenges that that we had was

368
00:16:01,740 --> 00:16:03,360
um what we call in machine learning as

369
00:16:03,360 --> 00:16:07,259
class imbalance which is a lot of data

370
00:16:07,259 --> 00:16:09,300
of one particular type which tends to be

371
00:16:09,300 --> 00:16:11,820
benign and a very small rate of

372
00:16:11,820 --> 00:16:13,519
malicious

373
00:16:13,519 --> 00:16:16,620
Mauritius data samples because the base

374
00:16:16,620 --> 00:16:19,940
rate of malware or malicious activity

375
00:16:19,940 --> 00:16:22,740
it's less than one percent in fact I

376
00:16:22,740 --> 00:16:24,180
want to go out on a limb and say it's

377
00:16:24,180 --> 00:16:26,639
like around point zero five percent uh

378
00:16:26,639 --> 00:16:30,320
so that's what the base rate is

379
00:16:30,600 --> 00:16:32,759
we had different approaches to address

380
00:16:32,759 --> 00:16:34,920
this so we thought let's try and

381
00:16:34,920 --> 00:16:37,199
generate data because

382
00:16:37,199 --> 00:16:40,259
um that could help us uh make a better

383
00:16:40,259 --> 00:16:41,880
model because machine learning models

384
00:16:41,880 --> 00:16:43,680
typically do well only when they have

385
00:16:43,680 --> 00:16:46,199
and they see equal sample so cat or a

386
00:16:46,199 --> 00:16:48,120
dog equals samples of cat equal samples

387
00:16:48,120 --> 00:16:50,820
of dog and they work brilliant but in

388
00:16:50,820 --> 00:16:53,100
security they don't because we have this

389
00:16:53,100 --> 00:16:55,920
class and balance problem

390
00:16:55,920 --> 00:16:58,199
um false positive reduction this was

391
00:16:58,199 --> 00:16:59,279
something that was not a machine

392
00:16:59,279 --> 00:17:02,399
learning approach actually we used

393
00:17:02,399 --> 00:17:05,280
standard software engineering computer

394
00:17:05,280 --> 00:17:08,099
uh algorithms that could just help us

395
00:17:08,099 --> 00:17:10,319
reduce the false positives and a lot of

396
00:17:10,319 --> 00:17:12,660
domain knowledge went into this uh in

397
00:17:12,660 --> 00:17:14,039
order to identify what could be a

398
00:17:14,039 --> 00:17:16,160
potentially malicious

399
00:17:16,160 --> 00:17:18,539
Landing landing page

400
00:17:18,539 --> 00:17:21,119
in a way it's very similar to spam or no

401
00:17:21,119 --> 00:17:24,000
spam because that's the kind of data

402
00:17:24,000 --> 00:17:25,980
sets that we're all used to and that's

403
00:17:25,980 --> 00:17:28,140
the kind of data set that let us think

404
00:17:28,140 --> 00:17:30,419
that okay we can do more of machine

405
00:17:30,419 --> 00:17:33,320
learning in security

406
00:17:35,100 --> 00:17:37,559
so if you're keeping score the score

407
00:17:37,559 --> 00:17:40,140
here is clippy ones kind of zero because

408
00:17:40,140 --> 00:17:42,539
we chose a very simple supervised

409
00:17:42,539 --> 00:17:43,799
machine learning traditional machine

410
00:17:43,799 --> 00:17:47,280
learning model and complemented that or

411
00:17:47,280 --> 00:17:50,039
augmented that with

412
00:17:50,039 --> 00:17:51,840
with

413
00:17:51,840 --> 00:17:55,559
um just basic traditional algorithms so

414
00:17:55,559 --> 00:17:59,280
why why were we successful I think we

415
00:17:59,280 --> 00:18:01,620
were successful because the hypothesis

416
00:18:01,620 --> 00:18:03,960
was simple and it was specific so it's

417
00:18:03,960 --> 00:18:06,299
really important to get that and then

418
00:18:06,299 --> 00:18:08,340
the data is labeled and it's in the

419
00:18:08,340 --> 00:18:10,620
order of millions so that was another

420
00:18:10,620 --> 00:18:13,820
reason why we were successful

421
00:18:16,320 --> 00:18:17,580
and

422
00:18:17,580 --> 00:18:21,419
coming back to the other

423
00:18:21,419 --> 00:18:23,880
um other quadrant in my slide which was

424
00:18:23,880 --> 00:18:26,280
how do we provide the most relevant

425
00:18:26,280 --> 00:18:28,919
information for a stock analyst who's

426
00:18:28,919 --> 00:18:30,360
doing the triage of the incidents and

427
00:18:30,360 --> 00:18:32,880
how do we automate this process

428
00:18:32,880 --> 00:18:34,320
um

429
00:18:34,320 --> 00:18:37,740
even here the automation of this was uh

430
00:18:37,740 --> 00:18:40,620
it was a data mining approach which is

431
00:18:40,620 --> 00:18:42,000
um which has been there for a long time

432
00:18:42,000 --> 00:18:43,440
ever since the invention of search

433
00:18:43,440 --> 00:18:46,020
engines so we mine information from

434
00:18:46,020 --> 00:18:49,140
different logs and event telemetry

435
00:18:49,140 --> 00:18:52,140
and we also used statistical approaches

436
00:18:52,140 --> 00:18:54,960
based uh that were

437
00:18:54,960 --> 00:18:56,820
um that were leveraged as part of the

438
00:18:56,820 --> 00:18:58,620
rules in the past searches that a lot of

439
00:18:58,620 --> 00:19:00,840
these analysts who triage did so this

440
00:19:00,840 --> 00:19:02,820
was one way in which we

441
00:19:02,820 --> 00:19:05,220
um monetary in which we gathered or

442
00:19:05,220 --> 00:19:07,080
mined all the locally available

443
00:19:07,080 --> 00:19:09,678
information

444
00:19:09,960 --> 00:19:11,400
there were also a lot of other things

445
00:19:11,400 --> 00:19:13,140
that we can extract from logs this is

446
00:19:13,140 --> 00:19:15,059
very traditional computer programming

447
00:19:15,059 --> 00:19:18,360
just get information about what was

448
00:19:18,360 --> 00:19:20,039
blocked whether there were like some

449
00:19:20,039 --> 00:19:23,940
Canary fights that were changed whether

450
00:19:23,940 --> 00:19:26,520
a process actually ran so so these are

451
00:19:26,520 --> 00:19:29,120
some of the things

452
00:19:29,400 --> 00:19:32,400
this is still a data driven data-driven

453
00:19:32,400 --> 00:19:34,500
approach because you're still using the

454
00:19:34,500 --> 00:19:36,720
statistical aspects not necessarily

455
00:19:36,720 --> 00:19:39,780
machine learning and deep learning

456
00:19:39,780 --> 00:19:41,160
um and I think this is where the machine

457
00:19:41,160 --> 00:19:43,080
learning and the Deep learning component

458
00:19:43,080 --> 00:19:46,740
comes into place so this is kind of a

459
00:19:46,740 --> 00:19:48,720
moonshot idea where

460
00:19:48,720 --> 00:19:51,120
with heart let's take this to another

461
00:19:51,120 --> 00:19:53,160
level we have a lot of information

462
00:19:53,160 --> 00:19:54,799
that's available in the form of

463
00:19:54,799 --> 00:19:57,900
structured data that's in databases that

464
00:19:57,900 --> 00:20:00,120
we get in for in from scissor bulletins

465
00:20:00,120 --> 00:20:02,460
or DHS bulletins we get a lot of that

466
00:20:02,460 --> 00:20:05,640
data we have a lot of other local

467
00:20:05,640 --> 00:20:09,000
telemetries it's also completely

468
00:20:09,000 --> 00:20:11,159
um it's also completely structured

469
00:20:11,159 --> 00:20:14,039
but a lot of the time stock analysts

470
00:20:14,039 --> 00:20:16,919
also go look up blog articles they look

471
00:20:16,919 --> 00:20:19,140
up a lot of they read a lot they do a

472
00:20:19,140 --> 00:20:20,220
lot of unstructured data so we thought

473
00:20:20,220 --> 00:20:21,840
let's take it one step further and

474
00:20:21,840 --> 00:20:24,179
automate this as well

475
00:20:24,179 --> 00:20:27,539
um and and as you can see this is like a

476
00:20:27,539 --> 00:20:30,480
Blog I served during the wannacry

477
00:20:30,480 --> 00:20:33,419
um attacks that were happening and we

478
00:20:33,419 --> 00:20:35,820
didn't I mean we implemented some sort

479
00:20:35,820 --> 00:20:38,880
of a machine learning uh model that

480
00:20:38,880 --> 00:20:41,280
could help extract all these security

481
00:20:41,280 --> 00:20:43,500
entities uh what I call a security

482
00:20:43,500 --> 00:20:45,600
entities are things that are that

483
00:20:45,600 --> 00:20:47,880
remotely look like security words

484
00:20:47,880 --> 00:20:50,159
um nothing like

485
00:20:50,159 --> 00:20:53,220
um Associated uh it should mostly look

486
00:20:53,220 --> 00:20:56,700
like Eternal blue SMB exploits so these

487
00:20:56,700 --> 00:20:58,679
are some of the security entities

488
00:20:58,679 --> 00:21:01,020
and then

489
00:21:01,020 --> 00:21:03,299
there were also

490
00:21:03,299 --> 00:21:06,659
um some timestamps and the the

491
00:21:06,659 --> 00:21:08,460
relationship so we wanted to extract all

492
00:21:08,460 --> 00:21:10,020
of this in an automated way using

493
00:21:10,020 --> 00:21:12,140
natural language processing

494
00:21:12,140 --> 00:21:14,820
so as an example here this is one

495
00:21:14,820 --> 00:21:17,400
successful example so you can see that

496
00:21:17,400 --> 00:21:21,659
on June 27 uh 2017 uh the patriarch may

497
00:21:21,659 --> 00:21:23,340
be spreading by the Eternal blue exploit

498
00:21:23,340 --> 00:21:25,980
that that was used in wannacry attack

499
00:21:25,980 --> 00:21:28,500
from last month and we wanted to present

500
00:21:28,500 --> 00:21:31,919
this evidence and how did we do that so

501
00:21:31,919 --> 00:21:33,960
we presented this evidence so obviously

502
00:21:33,960 --> 00:21:36,120
the ones that are explicitly provided in

503
00:21:36,120 --> 00:21:38,100
the blog article makes sense it's

504
00:21:38,100 --> 00:21:39,419
directly extracted using natural

505
00:21:39,419 --> 00:21:42,240
language processing but there are some

506
00:21:42,240 --> 00:21:45,120
interesting statements there that said

507
00:21:45,120 --> 00:21:47,100
um patio ransomware may be spreading by

508
00:21:47,100 --> 00:21:48,840
the Eternal blue exploit used in the

509
00:21:48,840 --> 00:21:51,360
wannacry attack from last month and if

510
00:21:51,360 --> 00:21:53,880
you look at the timestamp that we

511
00:21:53,880 --> 00:21:56,280
provide it actually goes back one month

512
00:21:56,280 --> 00:21:58,679
for the appropriate

513
00:21:58,679 --> 00:22:01,080
um security entity and the relationship

514
00:22:01,080 --> 00:22:04,799
so this is named entity recognition uh

515
00:22:04,799 --> 00:22:07,919
standard uh procedure but

516
00:22:07,919 --> 00:22:10,440
but but this was very interesting

517
00:22:10,440 --> 00:22:12,000
because this is one of the few

518
00:22:12,000 --> 00:22:14,480
successful cases where this this worked

519
00:22:14,480 --> 00:22:18,720
and it almost felt like leveraging this

520
00:22:18,720 --> 00:22:20,880
in order to

521
00:22:20,880 --> 00:22:23,760
in order to make the automated triage

522
00:22:23,760 --> 00:22:26,460
process much efficient uh it seemed like

523
00:22:26,460 --> 00:22:29,520
a huge operational burden

524
00:22:29,520 --> 00:22:31,799
so

525
00:22:31,799 --> 00:22:33,720
these were I mean as I mentioned like

526
00:22:33,720 --> 00:22:35,640
these were some of the

527
00:22:35,640 --> 00:22:37,320
um experiments that I did and how did we

528
00:22:37,320 --> 00:22:39,539
do this we annotated a lot of blog

529
00:22:39,539 --> 00:22:42,419
articles uh we did statistical modeling

530
00:22:42,419 --> 00:22:44,640
which is expectation maximization based

531
00:22:44,640 --> 00:22:46,980
and then we also tried deep learning and

532
00:22:46,980 --> 00:22:49,919
deep learning was mostly used to to uh

533
00:22:49,919 --> 00:22:51,659
what was mostly used to generate summary

534
00:22:51,659 --> 00:22:53,039
outcomes

535
00:22:53,039 --> 00:22:54,659
um I'm not sure if people are here are

536
00:22:54,659 --> 00:22:59,039
familiar but gpd3 is one of those open

537
00:22:59,039 --> 00:23:00,960
AI recent models that can actually

538
00:23:00,960 --> 00:23:03,780
generate a summary based on a dialogue

539
00:23:03,780 --> 00:23:07,980
or based on a textbook so we tried some

540
00:23:07,980 --> 00:23:09,539
of these approaches to see if this can

541
00:23:09,539 --> 00:23:11,100
actually help

542
00:23:11,100 --> 00:23:13,260
uh one of the challenges that we faced

543
00:23:13,260 --> 00:23:15,240
was that we wanted to evaluate the

544
00:23:15,240 --> 00:23:17,220
efficacy of the information extraction

545
00:23:17,220 --> 00:23:19,679
and it was very complicated

546
00:23:19,679 --> 00:23:21,840
um I think blue score is the standard

547
00:23:21,840 --> 00:23:23,220
where everybody uses the number of

548
00:23:23,220 --> 00:23:24,960
unique things that the machine learning

549
00:23:24,960 --> 00:23:26,520
model extracted and how a human

550
00:23:26,520 --> 00:23:29,280
annotated it but

551
00:23:29,280 --> 00:23:30,840
um overall

552
00:23:30,840 --> 00:23:33,240
the blue score was something that we

553
00:23:33,240 --> 00:23:35,340
definitely used but it was from a domain

554
00:23:35,340 --> 00:23:36,600
perspective it was very challenging

555
00:23:36,600 --> 00:23:40,500
because we did not know

556
00:23:40,500 --> 00:23:44,700
how to evaluate the outcome should we

557
00:23:44,700 --> 00:23:46,740
consider it a success if the model was

558
00:23:46,740 --> 00:23:48,120
able to extract everything from a given

559
00:23:48,120 --> 00:23:49,860
document or should we consider it a

560
00:23:49,860 --> 00:23:52,260
success if the model was able to extract

561
00:23:52,260 --> 00:23:54,299
it from exactly that given sentence

562
00:23:54,299 --> 00:23:55,559
where

563
00:23:55,559 --> 00:23:57,720
um the human also annotated so we had to

564
00:23:57,720 --> 00:23:58,799
come up with a bunch of custom

565
00:23:58,799 --> 00:24:02,059
evaluations as well

566
00:24:03,720 --> 00:24:07,080
so with all of this we actually had an

567
00:24:07,080 --> 00:24:09,720
interesting approach of coming up with

568
00:24:09,720 --> 00:24:11,880
the unstructured data or extracting

569
00:24:11,880 --> 00:24:14,820
information from unstructured data

570
00:24:14,820 --> 00:24:19,440
and I think the score now is

571
00:24:19,440 --> 00:24:21,720
um oh sorry clippy's already won my bad

572
00:24:21,720 --> 00:24:24,419
uh Skynet minus one and oh that's fine

573
00:24:24,419 --> 00:24:26,340
but but this case

574
00:24:26,340 --> 00:24:28,919
um clippy was Zero because the

575
00:24:28,919 --> 00:24:30,480
traditional statistical models did not

576
00:24:30,480 --> 00:24:32,820
do well at all

577
00:24:32,820 --> 00:24:34,860
um this kind of model which is or the

578
00:24:34,860 --> 00:24:37,080
one that we really thought would do very

579
00:24:37,080 --> 00:24:38,640
well in terms of extracting all the

580
00:24:38,640 --> 00:24:41,279
entities and relationships

581
00:24:41,279 --> 00:24:46,799
it was it was not that efficient for

582
00:24:46,799 --> 00:24:48,740
that particular purpose but however

583
00:24:48,740 --> 00:24:52,140
generating summaries so the Deep

584
00:24:52,140 --> 00:24:53,460
learning model was really good at

585
00:24:53,460 --> 00:24:55,620
generating summaries so I give a plus

586
00:24:55,620 --> 00:24:57,360
0.5 for that just because it can

587
00:24:57,360 --> 00:24:59,400
generate good summaries so just in case

588
00:24:59,400 --> 00:25:03,539
you want a quick uh glimpse into what

589
00:25:03,539 --> 00:25:05,400
the alert looked like if you're an

590
00:25:05,400 --> 00:25:06,960
analyst and you just want to triage that

591
00:25:06,960 --> 00:25:08,880
if you read that summary okay if that

592
00:25:08,880 --> 00:25:10,380
worked great

593
00:25:10,380 --> 00:25:12,360
um so for this particular instance the

594
00:25:12,360 --> 00:25:14,640
simpler models did not work

595
00:25:14,640 --> 00:25:17,039
um the more complicated models were kind

596
00:25:17,039 --> 00:25:18,539
of we were asking Beyond state of the

597
00:25:18,539 --> 00:25:22,380
art at that point and then we got a

598
00:25:22,380 --> 00:25:26,820
a good summary so plus 0.5 for that

599
00:25:26,820 --> 00:25:28,500
um I think as you can see in the slide I

600
00:25:28,500 --> 00:25:31,320
mentioned like it is difficult for the

601
00:25:31,320 --> 00:25:33,960
model to disambiguate between you know a

602
00:25:33,960 --> 00:25:35,940
Honeypot these are the language models

603
00:25:35,940 --> 00:25:37,740
that are trained on Wikipedia articles

604
00:25:37,740 --> 00:25:39,900
textbooks all these are huge models that

605
00:25:39,900 --> 00:25:42,000
are trained so

606
00:25:42,000 --> 00:25:43,740
it was difficult for the model to figure

607
00:25:43,740 --> 00:25:46,020
out a Honeypot from Winnie the Pooh and

608
00:25:46,020 --> 00:25:48,240
in the context of a Honeypot that's

609
00:25:48,240 --> 00:25:50,100
found in a security blog so that was

610
00:25:50,100 --> 00:25:52,140
really a challenge

611
00:25:52,140 --> 00:25:53,820
and of course from an operational

612
00:25:53,820 --> 00:25:55,440
perspective the amount of engineering

613
00:25:55,440 --> 00:25:56,880
that's needed to bring in these large

614
00:25:56,880 --> 00:25:59,279
models the cost the Costa obviously is

615
00:25:59,279 --> 00:26:00,659
one of the huge uh one of the biggest

616
00:26:00,659 --> 00:26:02,100
considerations in a security operations

617
00:26:02,100 --> 00:26:03,120
center

618
00:26:03,120 --> 00:26:05,760
um how much does it cost what would it

619
00:26:05,760 --> 00:26:08,760
how much would it uh cost to you know

620
00:26:08,760 --> 00:26:10,740
train these models maintain these models

621
00:26:10,740 --> 00:26:12,480
so these are other engineering aspects

622
00:26:12,480 --> 00:26:13,679
that I'm not even touching in the stock

623
00:26:13,679 --> 00:26:15,960
but that is definitely one other thing

624
00:26:15,960 --> 00:26:18,900
and is it really adding value is it

625
00:26:18,900 --> 00:26:21,000
incremental value is it not incremental

626
00:26:21,000 --> 00:26:22,860
value is it really worth it can't we

627
00:26:22,860 --> 00:26:24,360
just solve this with a simpler solution

628
00:26:24,360 --> 00:26:26,640
can we just do regex so I think all of

629
00:26:26,640 --> 00:26:29,480
those are valid here

630
00:26:30,720 --> 00:26:34,880
um I think oops

631
00:26:34,980 --> 00:26:38,520
all right did I get the right one

632
00:26:38,520 --> 00:26:41,820
okay yeah yeah and I think now we're

633
00:26:41,820 --> 00:26:43,679
coming to the part where we wanted to

634
00:26:43,679 --> 00:26:45,840
talk about or where I want to talk more

635
00:26:45,840 --> 00:26:48,020
about

636
00:26:48,539 --> 00:26:50,400
how

637
00:26:50,400 --> 00:26:52,799
um you know how we can improve some of

638
00:26:52,799 --> 00:26:56,039
the um operational efficacy aspects so

639
00:26:56,039 --> 00:26:58,380
this is an example where

640
00:26:58,380 --> 00:27:00,299
um we can actually help with threat

641
00:27:00,299 --> 00:27:03,240
hunting by dwindling down the data

642
00:27:03,240 --> 00:27:05,340
um so here we're trying to hunt for the

643
00:27:05,340 --> 00:27:07,799
malicious Powershell commands in an

644
00:27:07,799 --> 00:27:11,159
ocean of Powershell commands and this

645
00:27:11,159 --> 00:27:13,260
was an unsupervised approach this is

646
00:27:13,260 --> 00:27:14,520
slightly different from everything that

647
00:27:14,520 --> 00:27:16,020
we've seen so far which are supervised

648
00:27:16,020 --> 00:27:17,460
approaches this was an unsupervised

649
00:27:17,460 --> 00:27:19,440
approach

650
00:27:19,440 --> 00:27:22,440
um and the challenge here was that no

651
00:27:22,440 --> 00:27:24,840
analyst would go and label a Powershell

652
00:27:24,840 --> 00:27:27,539
command and say that this was

653
00:27:27,539 --> 00:27:29,520
a malicious Powershell command that was

654
00:27:29,520 --> 00:27:32,340
running nobody would do that so we did

655
00:27:32,340 --> 00:27:34,559
not have a lot of label data

656
00:27:34,559 --> 00:27:36,240
however

657
00:27:36,240 --> 00:27:37,679
the unsupervised machine learning

658
00:27:37,679 --> 00:27:39,360
approaches that we used were still very

659
00:27:39,360 --> 00:27:40,860
relevant especially when it came to

660
00:27:40,860 --> 00:27:43,320
clustering what it did was it would

661
00:27:43,320 --> 00:27:45,299
definitely cluster

662
00:27:45,299 --> 00:27:47,340
a lot of similar looking Powershell

663
00:27:47,340 --> 00:27:50,820
commands and the pattern that emerged

664
00:27:50,820 --> 00:27:54,360
here was that we saw a pattern with a

665
00:27:54,360 --> 00:27:55,500
lot of

666
00:27:55,500 --> 00:27:57,480
partial commands that you would

667
00:27:57,480 --> 00:27:59,220
typically expect to see in your network

668
00:27:59,220 --> 00:28:01,500
and in your environment again here the

669
00:28:01,500 --> 00:28:04,980
knowledge of what you have or what you

670
00:28:04,980 --> 00:28:06,179
would consider normal in your

671
00:28:06,179 --> 00:28:08,340
environment becomes critical

672
00:28:08,340 --> 00:28:10,620
but this can definitely help someone in

673
00:28:10,620 --> 00:28:12,480
threat hunting right because you know

674
00:28:12,480 --> 00:28:15,120
that once these Powershell commands get

675
00:28:15,120 --> 00:28:18,480
clustered you can probably see that

676
00:28:18,480 --> 00:28:20,340
some some of these clusters are

677
00:28:20,340 --> 00:28:22,260
completely legitimate that these are

678
00:28:22,260 --> 00:28:23,580
something that you would expect to see

679
00:28:23,580 --> 00:28:27,000
and some of these are simply not and a

680
00:28:27,000 --> 00:28:29,279
lot of these things were are really

681
00:28:29,279 --> 00:28:30,960
helpful in

682
00:28:30,960 --> 00:28:32,520
pivoting when you're doing threat

683
00:28:32,520 --> 00:28:35,580
hunting as well as trying to reduce the

684
00:28:35,580 --> 00:28:38,178
amount of data

685
00:28:42,720 --> 00:28:45,539
the other one is I think this everybody

686
00:28:45,539 --> 00:28:47,100
is

687
00:28:47,100 --> 00:28:48,779
um or has heard of it at least once

688
00:28:48,779 --> 00:28:50,820
because everybody talks about alert

689
00:28:50,820 --> 00:28:52,440
fatigue for the sock analyst and

690
00:28:52,440 --> 00:28:55,500
everybody would like to reduce the uh

691
00:28:55,500 --> 00:28:57,960
priorities or like bubble down the low

692
00:28:57,960 --> 00:29:00,240
priority alerts

693
00:29:00,240 --> 00:29:03,360
for this experiment we had alert data

694
00:29:03,360 --> 00:29:04,980
with labels we had alerts from different

695
00:29:04,980 --> 00:29:09,059
uh vendors different data types and we

696
00:29:09,059 --> 00:29:11,580
used both supervised and semi-supervised

697
00:29:11,580 --> 00:29:13,740
machine learning the challenges here

698
00:29:13,740 --> 00:29:15,899
were also you know the lack of label

699
00:29:15,899 --> 00:29:18,840
data and identifying the drift in

700
00:29:18,840 --> 00:29:21,960
priority so for example today a

701
00:29:21,960 --> 00:29:24,179
particular alert type with a particular

702
00:29:24,179 --> 00:29:28,399
number or sorry with a particular event

703
00:29:28,399 --> 00:29:31,200
was high priority but three months down

704
00:29:31,200 --> 00:29:33,299
the line that was not and I think a lot

705
00:29:33,299 --> 00:29:36,299
of this boils down again to the policies

706
00:29:36,299 --> 00:29:38,520
that are very specific to a given

707
00:29:38,520 --> 00:29:41,880
organization as well as the risk

708
00:29:41,880 --> 00:29:44,700
so how do we typically solve these

709
00:29:44,700 --> 00:29:46,919
problems right like when we don't have

710
00:29:46,919 --> 00:29:50,039
labeled data we try and get proxy label

711
00:29:50,039 --> 00:29:51,960
data and how do we do this we try to get

712
00:29:51,960 --> 00:29:54,539
these labels from the actions in the

713
00:29:54,539 --> 00:29:56,640
workflows uh that the sock analysts

714
00:29:56,640 --> 00:29:58,500
takes so in the end if they close it or

715
00:29:58,500 --> 00:30:00,419
in the end if they

716
00:30:00,419 --> 00:30:02,700
um ssoc analyst says that this is

717
00:30:02,700 --> 00:30:04,799
something that I escalated further then

718
00:30:04,799 --> 00:30:06,360
it's perhaps investigation worthy

719
00:30:06,360 --> 00:30:07,860
perhaps something that needs to be

720
00:30:07,860 --> 00:30:10,140
bubbled up and not bubbled on so these

721
00:30:10,140 --> 00:30:11,520
are some of the proxy labels that we

722
00:30:11,520 --> 00:30:13,919
could get and

723
00:30:13,919 --> 00:30:15,899
um another challenge was

724
00:30:15,899 --> 00:30:20,220
how do we how does the model remember

725
00:30:20,220 --> 00:30:22,559
um is it memorizing

726
00:30:22,559 --> 00:30:24,779
what the analyst is saying or is it

727
00:30:24,779 --> 00:30:27,419
actually objectively

728
00:30:27,419 --> 00:30:28,860
um telling whether something is a threat

729
00:30:28,860 --> 00:30:30,720
or whether something is a priority or

730
00:30:30,720 --> 00:30:32,460
not and I think that's a very difficult

731
00:30:32,460 --> 00:30:35,880
question to answer uh and most of the

732
00:30:35,880 --> 00:30:38,159
current models they typically learn from

733
00:30:38,159 --> 00:30:41,940
the humans so they can do as good as the

734
00:30:41,940 --> 00:30:44,340
humans do and if in order to go beyond

735
00:30:44,340 --> 00:30:45,659
that

736
00:30:45,659 --> 00:30:47,580
um there needs to be other ways in which

737
00:30:47,580 --> 00:30:51,199
we have to approach this problem

738
00:30:52,559 --> 00:30:55,260
so another interesting part here was

739
00:30:55,260 --> 00:30:57,539
that we tried to do a lot of gamifying

740
00:30:57,539 --> 00:31:00,480
also to kind of get uh labels

741
00:31:00,480 --> 00:31:03,299
um we had some interesting

742
00:31:03,299 --> 00:31:05,100
um interesting pop-ups that came up here

743
00:31:05,100 --> 00:31:08,880
uh that said uh you're only like 10

744
00:31:08,880 --> 00:31:10,559
points away this is like the Uber ride

745
00:31:10,559 --> 00:31:12,299
level so we kind of have something

746
00:31:12,299 --> 00:31:14,039
similar to that uh as part of the

747
00:31:14,039 --> 00:31:15,840
gamification experience for the stock

748
00:31:15,840 --> 00:31:18,379
analysts

749
00:31:19,039 --> 00:31:22,980
so over here both of the models that we

750
00:31:22,980 --> 00:31:24,600
used as part of the Powershell

751
00:31:24,600 --> 00:31:26,279
clustering as well as for the alert

752
00:31:26,279 --> 00:31:28,500
prioritization both the models were we

753
00:31:28,500 --> 00:31:29,820
used were very simple traditional

754
00:31:29,820 --> 00:31:31,260
machine learning models you know deep

755
00:31:31,260 --> 00:31:34,679
learning so clippy gets two again and

756
00:31:34,679 --> 00:31:38,220
um Skynet minus 0.5 here because we did

757
00:31:38,220 --> 00:31:39,899
try one of those

758
00:31:39,899 --> 00:31:41,340
um word emitting models that are

759
00:31:41,340 --> 00:31:43,799
commonly used in deep learning

760
00:31:43,799 --> 00:31:45,779
um where we try and train the model

761
00:31:45,779 --> 00:31:48,120
based on what are things are similar and

762
00:31:48,120 --> 00:31:50,340
it provides the score and this was very

763
00:31:50,340 --> 00:31:52,559
interesting so the similarity of say

764
00:31:52,559 --> 00:31:54,299
something that was virus detected and

765
00:31:54,299 --> 00:31:56,220
virus blocked the semantics of them is

766
00:31:56,220 --> 00:31:59,519
completely different one A virus

767
00:31:59,519 --> 00:32:01,799
detected means okay you have detected it

768
00:32:01,799 --> 00:32:04,500
and virus blocked means um okay you have

769
00:32:04,500 --> 00:32:08,220
detected and blocked it so the action

770
00:32:08,220 --> 00:32:09,419
that somebody would take would be

771
00:32:09,419 --> 00:32:11,700
completely different here and in this

772
00:32:11,700 --> 00:32:14,279
case it was very interesting to see that

773
00:32:14,279 --> 00:32:16,019
it was the exact same similarity so

774
00:32:16,019 --> 00:32:19,700
probably did not quite learn much

775
00:32:22,200 --> 00:32:24,779
so now let's shift gears a bit so we saw

776
00:32:24,779 --> 00:32:26,580
that most of the times clippy is good

777
00:32:26,580 --> 00:32:28,320
enough for the current use cases that

778
00:32:28,320 --> 00:32:31,260
we're targeting uh and what what do we

779
00:32:31,260 --> 00:32:34,220
really need in order to

780
00:32:34,220 --> 00:32:37,500
successfully deploy or successfully

781
00:32:37,500 --> 00:32:41,159
bring any data-driven solution uh for

782
00:32:41,159 --> 00:32:43,200
security

783
00:32:43,200 --> 00:32:46,019
obviously the people

784
00:32:46,019 --> 00:32:48,720
um one of the things that I noticed when

785
00:32:48,720 --> 00:32:50,820
when I'm interviewing others also or

786
00:32:50,820 --> 00:32:53,460
when I'm getting job description uh job

787
00:32:53,460 --> 00:32:57,120
requisition descriptions I noticed that

788
00:32:57,120 --> 00:32:59,580
the description requirement or the job

789
00:32:59,580 --> 00:33:01,620
requirement for somebody who's a data

790
00:33:01,620 --> 00:33:03,600
scientist is

791
00:33:03,600 --> 00:33:07,919
um security is

792
00:33:07,919 --> 00:33:10,679
um is a bonus Point uh you need to know

793
00:33:10,679 --> 00:33:13,140
how to engineer mine large-scale data

794
00:33:13,140 --> 00:33:15,960
and you need to write production code so

795
00:33:15,960 --> 00:33:18,240
this is one set of job descriptions that

796
00:33:18,240 --> 00:33:19,200
I've seen the other set of job

797
00:33:19,200 --> 00:33:21,539
descriptions that I've seen is you need

798
00:33:21,539 --> 00:33:25,080
to do data science figure out how the

799
00:33:25,080 --> 00:33:27,299
cost supports the product management as

800
00:33:27,299 --> 00:33:29,519
well as the customer success teams to

801
00:33:29,519 --> 00:33:31,679
figure out how much of these models are

802
00:33:31,679 --> 00:33:34,700
being adopted so it looks like

803
00:33:34,700 --> 00:33:37,080
there's a lot of us there's a huge ask

804
00:33:37,080 --> 00:33:38,519
you know

805
00:33:38,519 --> 00:33:40,620
um and I think I'd like to borrow one of

806
00:33:40,620 --> 00:33:42,480
the

807
00:33:42,480 --> 00:33:44,880
um one of the lines from Joshua Neil

808
00:33:44,880 --> 00:33:48,179
from uh from secure Onyx and he says

809
00:33:48,179 --> 00:33:50,700
build full stack teams not full stack

810
00:33:50,700 --> 00:33:53,399
data scientists it's extremely difficult

811
00:33:53,399 --> 00:33:57,659
to become a full stack data scientist so

812
00:33:57,659 --> 00:33:59,700
another aspect is if you are looking to

813
00:33:59,700 --> 00:34:01,019
start a security machine learning

814
00:34:01,019 --> 00:34:04,740
program a statistician or an ml engineer

815
00:34:04,740 --> 00:34:06,059
shouldn't be your first hire your first

816
00:34:06,059 --> 00:34:09,300
hire should be somebody who is a data

817
00:34:09,300 --> 00:34:11,219
architect who can work with the security

818
00:34:11,219 --> 00:34:13,679
teams to identify what exactly what kind

819
00:34:13,679 --> 00:34:16,739
of data sets need to be curated how to

820
00:34:16,739 --> 00:34:18,480
govern those data sets I think those are

821
00:34:18,480 --> 00:34:19,679
some of the things that we really need

822
00:34:19,679 --> 00:34:22,560
to really need to look into

823
00:34:22,560 --> 00:34:25,320
and then cross-train your statisticians

824
00:34:25,320 --> 00:34:27,060
and security practitioners I can give

825
00:34:27,060 --> 00:34:29,099
you an example so when training one of

826
00:34:29,099 --> 00:34:31,020
these models the data scientists totally

827
00:34:31,020 --> 00:34:33,000
as part of the feature Engineering

828
00:34:33,000 --> 00:34:34,440
Process

829
00:34:34,440 --> 00:34:37,679
um they completely omitted or basically

830
00:34:37,679 --> 00:34:40,500
gave a wild card for the IP address and

831
00:34:40,500 --> 00:34:42,599
everything else was modeled

832
00:34:42,599 --> 00:34:44,899
um if a security professional was there

833
00:34:44,899 --> 00:34:48,000
and was advising the data scientist then

834
00:34:48,000 --> 00:34:49,139
the security practitioner would have

835
00:34:49,139 --> 00:34:51,300
immediately said that this will not work

836
00:34:51,300 --> 00:34:52,739
this is exactly the kind of loophole

837
00:34:52,739 --> 00:34:55,500
that somebody in that an attacker would

838
00:34:55,500 --> 00:34:57,540
leverage to change the decision of the

839
00:34:57,540 --> 00:35:01,380
model so try to cross-train

840
00:35:01,380 --> 00:35:03,960
and then processes I cannot emphasize

841
00:35:03,960 --> 00:35:06,540
this much I think the first a lot of

842
00:35:06,540 --> 00:35:07,980
places where I've been the first things

843
00:35:07,980 --> 00:35:10,320
that I get asked is

844
00:35:10,320 --> 00:35:11,520
um we want you to build that machine

845
00:35:11,520 --> 00:35:12,960
learning model that will help us catch

846
00:35:12,960 --> 00:35:15,960
apt-28 and I think we're far away from

847
00:35:15,960 --> 00:35:17,940
that I don't think we want to build a

848
00:35:17,940 --> 00:35:19,079
machine learning model that will catch

849
00:35:19,079 --> 00:35:21,000
AP to 28 right off the bat I think

850
00:35:21,000 --> 00:35:24,240
that's not a realistic ask

851
00:35:24,240 --> 00:35:25,680
um so

852
00:35:25,680 --> 00:35:28,859
definitely try and work with your

853
00:35:28,859 --> 00:35:31,220
security teams work with your leaders

854
00:35:31,220 --> 00:35:33,800
set expectations

855
00:35:33,800 --> 00:35:36,599
and if you are an Enterprise security

856
00:35:36,599 --> 00:35:39,200
team try to

857
00:35:39,200 --> 00:35:42,240
use the data that you already have try

858
00:35:42,240 --> 00:35:44,400
to Leverage The workflows and the

859
00:35:44,400 --> 00:35:46,440
process that you do try to leverage that

860
00:35:46,440 --> 00:35:49,260
for data-driven approaches instead of

861
00:35:49,260 --> 00:35:50,820
starting new tools instead of starting

862
00:35:50,820 --> 00:35:52,200
new

863
00:35:52,200 --> 00:35:53,760
um new processes try to leverage the

864
00:35:53,760 --> 00:35:56,099
existing ones

865
00:35:56,099 --> 00:35:58,380
and I think another point that I noticed

866
00:35:58,380 --> 00:36:00,780
in a lot of data science teams is that

867
00:36:00,780 --> 00:36:03,359
data science teams

868
00:36:03,359 --> 00:36:05,160
um are sometimes forced to fit into an

869
00:36:05,160 --> 00:36:08,400
agile framework and it works in software

870
00:36:08,400 --> 00:36:10,980
engineering because you know the kind of

871
00:36:10,980 --> 00:36:12,720
problem you want to solve you know what

872
00:36:12,720 --> 00:36:14,220
kind of solution there is so you can

873
00:36:14,220 --> 00:36:17,280
work work on it that way but with data

874
00:36:17,280 --> 00:36:20,460
science I noticed that people say oh I

875
00:36:20,460 --> 00:36:22,380
want to solve this problem I want to

876
00:36:22,380 --> 00:36:24,900
catch apt-29 maybe your data does not

877
00:36:24,900 --> 00:36:26,280
support it you cannot really catch

878
00:36:26,280 --> 00:36:28,800
apt-29 I want to solve user behavioral

879
00:36:28,800 --> 00:36:31,140
analytics or I want to detect Insider

880
00:36:31,140 --> 00:36:34,079
threats for you know trading my stocks I

881
00:36:34,079 --> 00:36:35,820
think that is something

882
00:36:35,820 --> 00:36:38,220
you'll have to look into and set

883
00:36:38,220 --> 00:36:39,900
expectations only after looking at and

884
00:36:39,900 --> 00:36:42,800
exploring the data

885
00:36:43,200 --> 00:36:45,359
from a technology perspective I think

886
00:36:45,359 --> 00:36:47,040
it's again

887
00:36:47,040 --> 00:36:48,780
um one of the things that's often

888
00:36:48,780 --> 00:36:52,859
overlooked is the mlops practices how do

889
00:36:52,859 --> 00:36:54,420
we Harden the systems how do we make

890
00:36:54,420 --> 00:36:55,760
them robust

891
00:36:55,760 --> 00:36:59,880
and data scientists often forget their

892
00:36:59,880 --> 00:37:02,099
baselines they try to go for the moon

893
00:37:02,099 --> 00:37:04,079
shots let's use the latest Cutting Edge

894
00:37:04,079 --> 00:37:07,140
but we totally forget our bass lines can

895
00:37:07,140 --> 00:37:09,060
we really improve on these baselines

896
00:37:09,060 --> 00:37:12,180
whether these are rules based or or

897
00:37:12,180 --> 00:37:14,099
statistics based can we really improve

898
00:37:14,099 --> 00:37:16,260
these

899
00:37:16,260 --> 00:37:18,359
and lastly

900
00:37:18,359 --> 00:37:20,700
um this is the Good Bad and the Ugly so

901
00:37:20,700 --> 00:37:22,859
just summarizing everything that I

902
00:37:22,859 --> 00:37:24,300
mentioned here

903
00:37:24,300 --> 00:37:26,220
um I think the good part is I think more

904
00:37:26,220 --> 00:37:29,220
uh mature uh security teams and data

905
00:37:29,220 --> 00:37:30,839
science teams they actually work

906
00:37:30,839 --> 00:37:32,579
together and they're trying to find find

907
00:37:32,579 --> 00:37:35,220
that problem and solution match quality

908
00:37:35,220 --> 00:37:37,500
they're trying to find that fit

909
00:37:37,500 --> 00:37:39,720
and Occam's razor actually works start

910
00:37:39,720 --> 00:37:41,460
with the simplest problem for which you

911
00:37:41,460 --> 00:37:44,060
have the data

912
00:37:45,900 --> 00:37:48,060
there are some really cool advancements

913
00:37:48,060 --> 00:37:49,800
also that are happening so I think the

914
00:37:49,800 --> 00:37:51,359
security Community has to keep an eye

915
00:37:51,359 --> 00:37:52,859
out on all the advancements that is

916
00:37:52,859 --> 00:37:54,960
happening in the AI and machine learning

917
00:37:54,960 --> 00:37:55,800
space

918
00:37:55,800 --> 00:37:57,599
maybe now is not the right time to try

919
00:37:57,599 --> 00:37:59,460
them and try to bring them into

920
00:37:59,460 --> 00:38:01,079
production because they're definitely

921
00:38:01,079 --> 00:38:04,200
not battle ready or battle tested uh so

922
00:38:04,200 --> 00:38:06,960
it's important there is a lot of

923
00:38:06,960 --> 00:38:09,119
interesting work that's going on there

924
00:38:09,119 --> 00:38:11,940
and with a lot of research and proper

925
00:38:11,940 --> 00:38:13,260
development and the right guidance I

926
00:38:13,260 --> 00:38:14,880
think there is a lot of potential to use

927
00:38:14,880 --> 00:38:16,859
these Advanced machine learning and deep

928
00:38:16,859 --> 00:38:19,640
learning models

929
00:38:20,040 --> 00:38:21,900
and another thing is in general we're

930
00:38:21,900 --> 00:38:23,220
always focused on finding the threat

931
00:38:23,220 --> 00:38:25,619
which is the needle and we really don't

932
00:38:25,619 --> 00:38:27,480
have that magnet so instead maybe the

933
00:38:27,480 --> 00:38:29,400
approach should be let's eliminate all

934
00:38:29,400 --> 00:38:31,380
the noise like let's remove the haste

935
00:38:31,380 --> 00:38:32,280
tag and then the needle will

936
00:38:32,280 --> 00:38:34,980
automatically reveal itself so maybe we

937
00:38:34,980 --> 00:38:36,660
have the tools to get the haystack not

938
00:38:36,660 --> 00:38:39,900
the needle so let's remove the haystack

939
00:38:39,900 --> 00:38:42,119
um the bad the bad parts that I've

940
00:38:42,119 --> 00:38:44,099
noticed is the return on investment is

941
00:38:44,099 --> 00:38:45,300
inversely proportional to the model

942
00:38:45,300 --> 00:38:47,160
complexity and this is an engineering

943
00:38:47,160 --> 00:38:50,820
challenge that needs more

944
00:38:50,820 --> 00:38:53,040
um more resources I think most most

945
00:38:53,040 --> 00:38:54,900
folks are interested in trying to build

946
00:38:54,900 --> 00:38:56,940
the latest models and not quite as

947
00:38:56,940 --> 00:38:59,820
interested as getting the engineering

948
00:38:59,820 --> 00:39:01,500
effort in place so that's definitely one

949
00:39:01,500 --> 00:39:03,240
thing and the mismatched expectations

950
00:39:03,240 --> 00:39:04,740
right everybody wants to work on the

951
00:39:04,740 --> 00:39:06,420
latest and greatest but

952
00:39:06,420 --> 00:39:08,400
very few things would actually work so

953
00:39:08,400 --> 00:39:10,320
it's really hard to retain those data

954
00:39:10,320 --> 00:39:12,119
scientists who can work in security they

955
00:39:12,119 --> 00:39:13,680
all want to go build recommendation

956
00:39:13,680 --> 00:39:15,720
engines and generate ads so that people

957
00:39:15,720 --> 00:39:17,520
can click on the ads

958
00:39:17,520 --> 00:39:19,200
um and I think the other bad thing is

959
00:39:19,200 --> 00:39:21,900
again let's focus on hardening

960
00:39:21,900 --> 00:39:23,640
uh this is one of my pet peeves the ugly

961
00:39:23,640 --> 00:39:24,480
part

962
00:39:24,480 --> 00:39:25,740
um

963
00:39:25,740 --> 00:39:28,260
there's not a lot of open research I

964
00:39:28,260 --> 00:39:30,000
wish the community does more open

965
00:39:30,000 --> 00:39:31,859
research share more data sets share more

966
00:39:31,859 --> 00:39:35,280
code and that way we can all test each

967
00:39:35,280 --> 00:39:37,020
other's models determine what is

968
00:39:37,020 --> 00:39:39,540
actually valuable what can be improved

969
00:39:39,540 --> 00:39:41,400
how it can be improved I think that

970
00:39:41,400 --> 00:39:43,380
there's there needs to be more push

971
00:39:43,380 --> 00:39:46,800
towards open sourcing the models as well

972
00:39:46,800 --> 00:39:48,180
as the data sets within the security

973
00:39:48,180 --> 00:39:51,119
community that works for security

974
00:39:51,119 --> 00:39:54,900
uh yeah that's it for me and uh I think

975
00:39:54,900 --> 00:39:57,720
Now's the Time For questions

976
00:39:57,720 --> 00:40:00,439
if any

977
00:40:09,540 --> 00:40:11,819
uh sorry the question was uh do we see

978
00:40:11,819 --> 00:40:15,500
adversaries using machine learning and

979
00:40:16,740 --> 00:40:19,800
oh great question uh yes adversarial

980
00:40:19,800 --> 00:40:21,300
machine learning is a whole space in

981
00:40:21,300 --> 00:40:23,099
itself and that is something that I

982
00:40:23,099 --> 00:40:24,540
definitely did not touch today I only

983
00:40:24,540 --> 00:40:27,359
spoke about the defensive aspect uh

984
00:40:27,359 --> 00:40:29,520
adversarial machine learning is a thing

985
00:40:29,520 --> 00:40:31,920
this is where there are a lot of

986
00:40:31,920 --> 00:40:33,900
different kinds of attacks so for

987
00:40:33,900 --> 00:40:35,460
example

988
00:40:35,460 --> 00:40:37,680
um I think in the news most prominently

989
00:40:37,680 --> 00:40:40,859
you see uh you know autonomous cars

990
00:40:40,859 --> 00:40:42,720
there are misreading some signs because

991
00:40:42,720 --> 00:40:44,280
the machine learning decision boundaries

992
00:40:44,280 --> 00:40:47,220
are different you also see data

993
00:40:47,220 --> 00:40:48,960
poisoning right how somebody could

994
00:40:48,960 --> 00:40:50,880
actually poison the data on which the

995
00:40:50,880 --> 00:40:54,119
model is trained so you're uh poisoning

996
00:40:54,119 --> 00:40:56,099
it from the in the initial part this is

997
00:40:56,099 --> 00:40:58,319
akin to the supply chain attacks that we

998
00:40:58,319 --> 00:40:59,579
see

999
00:40:59,579 --> 00:41:01,680
um can we detect it

1000
00:41:01,680 --> 00:41:03,780
there are a couple of tools that are

1001
00:41:03,780 --> 00:41:06,839
being developed uh this is mostly for

1002
00:41:06,839 --> 00:41:09,119
data scientists to make their models

1003
00:41:09,119 --> 00:41:10,859
more robust so that they don't get

1004
00:41:10,859 --> 00:41:12,839
attacked this way so this is we're

1005
00:41:12,839 --> 00:41:16,920
trying to be more proactive uh in terms

1006
00:41:16,920 --> 00:41:19,260
of detection

1007
00:41:19,260 --> 00:41:21,359
um it's really difficult to say whether

1008
00:41:21,359 --> 00:41:23,940
something looks like a normal request to

1009
00:41:23,940 --> 00:41:25,859
a machine learning model that is hosted

1010
00:41:25,859 --> 00:41:27,839
in the cloud you could just send an API

1011
00:41:27,839 --> 00:41:29,579
and you can get a response and it's

1012
00:41:29,579 --> 00:41:30,599
really difficult to know whether

1013
00:41:30,599 --> 00:41:32,040
somebody is actually trying to trick the

1014
00:41:32,040 --> 00:41:33,180
model

1015
00:41:33,180 --> 00:41:35,220
um and traditional detection approaches

1016
00:41:35,220 --> 00:41:37,020
would apply here as well look at the

1017
00:41:37,020 --> 00:41:38,819
rates at which they're requesting for

1018
00:41:38,819 --> 00:41:41,819
these predictions and look at the kind

1019
00:41:41,819 --> 00:41:43,200
of

1020
00:41:43,200 --> 00:41:45,359
um look at the kind of data points that

1021
00:41:45,359 --> 00:41:46,380
they're requesting it for are they

1022
00:41:46,380 --> 00:41:47,579
within each other because that's when

1023
00:41:47,579 --> 00:41:49,020
you can infer that they are trying to

1024
00:41:49,020 --> 00:41:52,200
infer the decision boundary of the model

1025
00:41:52,200 --> 00:41:55,819
yeah does that answer your question

1026
00:42:02,880 --> 00:42:05,440
any other questions

1027
00:42:05,440 --> 00:42:10,639
[Applause]

