1
00:00:00,680 --> 00:00:02,520
alright ladies and gentlemen we are

2
00:00:02,520 --> 00:00:04,650
going to get started again this is talk

3
00:00:04,650 --> 00:00:07,500
number 2 a unique approach to threat

4
00:00:07,500 --> 00:00:10,950
analysis mapping and our presenters now

5
00:00:10,950 --> 00:00:14,190
are on the threat Intel team with cert

6
00:00:14,190 --> 00:00:17,190
right up over the hill here I introduced

7
00:00:17,190 --> 00:00:19,740
to you Dena Schick and Kyle O'Meara

8
00:00:19,740 --> 00:00:21,570
they're gonna do a full introduction of

9
00:00:21,570 --> 00:00:25,800
themselves hello

10
00:00:25,800 --> 00:00:31,980
I will make sure to avoid that how's

11
00:00:31,980 --> 00:00:43,410
everybody doing all right so we are here

12
00:00:43,410 --> 00:00:45,270
today because we are presenting on a

13
00:00:45,270 --> 00:00:47,520
paper that Kyle and I wrote and

14
00:00:47,520 --> 00:00:48,899
published about a month ago so

15
00:00:48,899 --> 00:00:50,700
everything that we are going to talk

16
00:00:50,700 --> 00:00:54,180
about today is available to you because

17
00:00:54,180 --> 00:00:56,520
our goal in this was to create something

18
00:00:56,520 --> 00:00:59,399
that was actionable so other people can

19
00:00:59,399 --> 00:01:03,660
take it with them and use it so I just

20
00:01:03,660 --> 00:01:05,430
want to ask a question to everybody in

21
00:01:05,430 --> 00:01:08,010
the audience and so how many of you guys

22
00:01:08,010 --> 00:01:11,520
reverse engineer malware raise your can

23
00:01:11,520 --> 00:01:13,950
I get a show of hands okay how many of

24
00:01:13,950 --> 00:01:16,259
you guys do incident response or a part

25
00:01:16,259 --> 00:01:19,979
of a sock okay how many of you guys do

26
00:01:19,979 --> 00:01:24,030
both anybody one person excellent

27
00:01:24,030 --> 00:01:31,829
few people I'll get back to that in a

28
00:01:31,829 --> 00:01:34,829
minute so um my name is Tina chick and I

29
00:01:34,829 --> 00:01:36,840
work at the software engineering

30
00:01:36,840 --> 00:01:38,670
software engineering Institute cert

31
00:01:38,670 --> 00:01:41,220
Coordination Center I am on the threat

32
00:01:41,220 --> 00:01:42,990
intelligence team with Kyle O'Meara and

33
00:01:42,990 --> 00:01:45,659
I've been working at cert now for about

34
00:01:45,659 --> 00:01:49,409
three years prior to this I did export

35
00:01:49,409 --> 00:01:51,630
compliance and ITAR regulations stuff

36
00:01:51,630 --> 00:01:53,579
before I got my masters at Carnegie

37
00:01:53,579 --> 00:01:56,659
Mellon and I've been there ever since

38
00:01:56,659 --> 00:02:00,119
Dina said I'm Kyle I've been at certain

39
00:02:00,119 --> 00:02:02,009
up a little over a year and before that

40
00:02:02,009 --> 00:02:05,399
I was a with fireEye and if anybody

41
00:02:05,399 --> 00:02:06,220
there any gummies

42
00:02:06,220 --> 00:02:07,570
here I work in the Sharks air program

43
00:02:07,570 --> 00:02:10,479
basically ran that and then before that

44
00:02:10,479 --> 00:02:12,790
I was at NSA full-time after before that

45
00:02:12,790 --> 00:02:16,060
so but it's exciting to be here at Sur

46
00:02:16,060 --> 00:02:18,250
I'm back in Pittsburgh I'd once school

47
00:02:18,250 --> 00:02:19,510
this area so it's good to be back in

48
00:02:19,510 --> 00:02:22,090
this area so we were on the threat

49
00:02:22,090 --> 00:02:24,100
intelligence team and our overall

50
00:02:24,100 --> 00:02:27,330
Directorate consists of some malware

51
00:02:27,330 --> 00:02:31,480
reverse engineers some network engineers

52
00:02:31,480 --> 00:02:33,670
and then the threat intelligence team

53
00:02:33,670 --> 00:02:35,920
that puts it all together we recently

54
00:02:35,920 --> 00:02:38,110
merged with our vulnerability team so

55
00:02:38,110 --> 00:02:40,360
Dan who just spoke and a couple of our

56
00:02:40,360 --> 00:02:42,160
vulnerability researchers are out there

57
00:02:42,160 --> 00:02:44,980
in the crowd so now we have real a

58
00:02:44,980 --> 00:02:46,630
really interesting access to different

59
00:02:46,630 --> 00:02:47,740
types of data that we didn't necessarily

60
00:02:47,740 --> 00:02:51,730
have before and that's kind of how this

61
00:02:51,730 --> 00:02:55,240
all started um we do produce a whole lot

62
00:02:55,240 --> 00:02:57,760
of tools our malware team produces

63
00:02:57,760 --> 00:02:59,350
reverse engineering tools and other

64
00:02:59,350 --> 00:03:01,630
static analysis tools and these are

65
00:03:01,630 --> 00:03:03,940
available on our github site and you

66
00:03:03,940 --> 00:03:05,980
guys can use them and you can always ask

67
00:03:05,980 --> 00:03:07,870
us any questions we might not be able to

68
00:03:07,870 --> 00:03:09,730
answer them but we can certainly feel

69
00:03:09,730 --> 00:03:12,130
them the right people and that's off

70
00:03:12,130 --> 00:03:14,440
there because someone told yous to do

71
00:03:14,440 --> 00:03:22,660
our analysis okay so I asked you guys a

72
00:03:22,660 --> 00:03:24,970
question of what you guys do so we we

73
00:03:24,970 --> 00:03:27,430
have our and people that do malware

74
00:03:27,430 --> 00:03:28,810
analysis people that do incident

75
00:03:28,810 --> 00:03:31,209
response and then you have people that

76
00:03:31,209 --> 00:03:33,310
are doing network analysis but rarely do

77
00:03:33,310 --> 00:03:35,560
people kind of put them all together and

78
00:03:35,560 --> 00:03:38,709
in the industry right now you can go out

79
00:03:38,709 --> 00:03:40,630
you can read CrowdStrike reports or

80
00:03:40,630 --> 00:03:42,549
fireEye reports or what have you and

81
00:03:42,549 --> 00:03:45,489
typically these take and inside-out

82
00:03:45,489 --> 00:03:48,250
approach to understanding the adversary

83
00:03:48,250 --> 00:03:51,820
so what that means is um I have a

84
00:03:51,820 --> 00:03:54,370
network that network has been hosed by a

85
00:03:54,370 --> 00:03:57,640
bad guy and I start my analysis with

86
00:03:57,640 --> 00:04:02,680
that data our team does not do infinite

87
00:04:02,680 --> 00:04:04,750
response but we have a really good idea

88
00:04:04,750 --> 00:04:06,910
of what type of malware is out there so

89
00:04:06,910 --> 00:04:09,130
we wanted to flip this on its head a

90
00:04:09,130 --> 00:04:11,320
little bit and start with the tools that

91
00:04:11,320 --> 00:04:14,870
adversaries are using instead of

92
00:04:14,870 --> 00:04:17,000
fragile indicators are compromised like

93
00:04:17,000 --> 00:04:20,180
domain names IP addresses and so forth

94
00:04:20,180 --> 00:04:22,850
we do have a malware artifact catalog

95
00:04:22,850 --> 00:04:25,250
that has about 200 million pieces of

96
00:04:25,250 --> 00:04:26,990
malware in it and we've been looking at

97
00:04:26,990 --> 00:04:30,800
trends across that now for the last 10

98
00:04:30,800 --> 00:04:34,880
to 12 years minimum we also have what's

99
00:04:34,880 --> 00:04:37,520
called our knowns process so our reverse

100
00:04:37,520 --> 00:04:40,580
engineers will get an exemplar of

101
00:04:40,580 --> 00:04:43,220
malware they will reverse engineer it

102
00:04:43,220 --> 00:04:46,880
and they will find all of the related

103
00:04:46,880 --> 00:04:48,860
pieces of malware we call that a family

104
00:04:48,860 --> 00:04:51,289
so our analysis is really going to start

105
00:04:51,289 --> 00:04:53,960
with how we understand a malware family

106
00:04:53,960 --> 00:04:57,380
and what we have is a configuration

107
00:04:57,380 --> 00:05:00,020
jumper a bunch of yarrow signatures the

108
00:05:00,020 --> 00:05:01,699
configuration tupper will then give us

109
00:05:01,699 --> 00:05:03,020
all of the other indicators of

110
00:05:03,020 --> 00:05:04,970
compromise so we can put together the

111
00:05:04,970 --> 00:05:07,430
entire picture or I guess a more

112
00:05:07,430 --> 00:05:09,320
complete picture of an intrusion instead

113
00:05:09,320 --> 00:05:14,030
of just one piece of it um the other

114
00:05:14,030 --> 00:05:15,710
challenge problem that we have in the

115
00:05:15,710 --> 00:05:18,169
industry is that different security

116
00:05:18,169 --> 00:05:20,090
vendors like to name things differently

117
00:05:20,090 --> 00:05:23,000
so you have people calling different

118
00:05:23,000 --> 00:05:23,950
groups

119
00:05:23,950 --> 00:05:26,810
ABCDEF and there's nobody putting them

120
00:05:26,810 --> 00:05:28,490
together nor is anybody really

121
00:05:28,490 --> 00:05:30,800
confirming the findings there's a lot of

122
00:05:30,800 --> 00:05:33,229
circular reporting and frankly we just

123
00:05:33,229 --> 00:05:35,139
got kind of annoyed with that and

124
00:05:35,139 --> 00:05:37,669
decided that we were going to tackle

125
00:05:37,669 --> 00:05:42,039
this at least tackle it in terms of if

126
00:05:42,039 --> 00:05:46,039
tackle it in terms of malware and all of

127
00:05:46,039 --> 00:05:49,880
this spurred this paper and the goal of

128
00:05:49,880 --> 00:05:52,250
it is to just put all of the different

129
00:05:52,250 --> 00:05:53,690
types of indicators together to tell a

130
00:05:53,690 --> 00:05:56,330
more complete picture using an

131
00:05:56,330 --> 00:05:58,250
outside-in methodology instead of an

132
00:05:58,250 --> 00:06:00,729
inside-out

133
00:06:03,520 --> 00:06:05,650
so I guess kind of talking about what

134
00:06:05,650 --> 00:06:08,110
that really means so our goal was to

135
00:06:08,110 --> 00:06:09,490
utilize the data that we have in-house

136
00:06:09,490 --> 00:06:11,410
so our vulnerability stuff we have an

137
00:06:11,410 --> 00:06:15,340
exploit catalog malware catalog and a

138
00:06:15,340 --> 00:06:18,039
whole bunch of networking stuff to help

139
00:06:18,039 --> 00:06:20,139
net defenders and those of the

140
00:06:20,139 --> 00:06:21,550
intelligence community so everything

141
00:06:21,550 --> 00:06:24,160
that we've produced in this report is

142
00:06:24,160 --> 00:06:26,110
public to you but also we want to teach

143
00:06:26,110 --> 00:06:28,630
you how to fish to some degree so you

144
00:06:28,630 --> 00:06:30,759
can take anything that you might find

145
00:06:30,759 --> 00:06:34,710
and reapply it back into your network

146
00:06:35,039 --> 00:06:37,690
and I think I kind of went over a lot of

147
00:06:37,690 --> 00:06:40,210
this we do utilize indicator expansion

148
00:06:40,210 --> 00:06:42,220
and I just want to explain that really

149
00:06:42,220 --> 00:06:44,759
quickly and that is the process of going

150
00:06:44,759 --> 00:06:49,030
from IP address to domain name or domain

151
00:06:49,030 --> 00:06:52,389
name back to IP address or anything

152
00:06:52,389 --> 00:06:54,009
along this line so any of those steps

153
00:06:54,009 --> 00:06:55,659
that you take we call indicator

154
00:06:55,659 --> 00:07:03,130
expansion so the data that we use or we

155
00:07:03,130 --> 00:07:07,000
tried to used so we certainly scoured

156
00:07:07,000 --> 00:07:11,080
the internet for any of for all of the

157
00:07:11,080 --> 00:07:13,120
case studies that we were going to talk

158
00:07:13,120 --> 00:07:15,300
about we're going to talk about one but

159
00:07:15,300 --> 00:07:20,469
first we used all our Maori analysis of

160
00:07:20,469 --> 00:07:22,360
course and then the second biggest piece

161
00:07:22,360 --> 00:07:24,099
of data that we used was far sites

162
00:07:24,099 --> 00:07:26,139
passive DNS database has anybody used

163
00:07:26,139 --> 00:07:28,539
that here anybody use pasa

164
00:07:28,539 --> 00:07:32,740
okay Evan excellent there's one um and

165
00:07:32,740 --> 00:07:37,090
we attempted to use blacklist so again

166
00:07:37,090 --> 00:07:38,409
there are a lot of security vendors that

167
00:07:38,409 --> 00:07:41,490
produce a whole bunch of blacklist and

168
00:07:41,490 --> 00:07:44,830
we intersected all of our IO C's for

169
00:07:44,830 --> 00:07:46,479
them our families that we looked at and

170
00:07:46,479 --> 00:07:48,759
we found that there was little to no

171
00:07:48,759 --> 00:07:50,710
overlap on any of the blacklist

172
00:07:50,710 --> 00:07:54,400
says to me that unless you have that

173
00:07:54,400 --> 00:07:57,610
blacklist at a particular time you might

174
00:07:57,610 --> 00:07:59,050
have some coverage if you're

175
00:07:59,050 --> 00:08:00,789
implementing them but you probably won't

176
00:08:00,789 --> 00:08:05,050
when it comes to I guess when it comes

177
00:08:05,050 --> 00:08:06,909
to adversary tooling and that was just

178
00:08:06,909 --> 00:08:10,270
not helpful at all we also use the miter

179
00:08:10,270 --> 00:08:13,000
CV database to identify those and CB

180
00:08:13,000 --> 00:08:15,320
details as well

181
00:08:15,320 --> 00:08:17,180
exploit Eevee obviously and in other

182
00:08:17,180 --> 00:08:20,150
open-source information such as you know

183
00:08:20,150 --> 00:08:23,030
Twitter blogs and articles and uh you

184
00:08:23,030 --> 00:08:25,040
guys haven't checked out the circle that

185
00:08:25,040 --> 00:08:27,200
L you miss you know malware information

186
00:08:27,200 --> 00:08:28,910
sharing platform it's pretty useful Lots

187
00:08:28,910 --> 00:08:30,740
information there you can kind of get an

188
00:08:30,740 --> 00:08:33,919
account if you're a cert or a vendor and

189
00:08:33,919 --> 00:08:35,210
you don't really have to contribute but

190
00:08:35,210 --> 00:08:36,530
you can't contribute but there's a lot

191
00:08:36,530 --> 00:08:40,220
of good information in there some of the

192
00:08:40,220 --> 00:08:42,979
tools we use obviously were Yarra wanted

193
00:08:42,979 --> 00:08:44,420
tools that was developed in-house by our

194
00:08:44,420 --> 00:08:46,010
developers as function the yard I'll

195
00:08:46,010 --> 00:08:47,420
talk a little bit more about that later

196
00:08:47,420 --> 00:08:49,940
when I talk about the code comparison

197
00:08:49,940 --> 00:08:54,530
section silk which I if you know anybody

198
00:08:54,530 --> 00:08:56,270
not know what silk is and it was

199
00:08:56,270 --> 00:08:59,780
developed in-house years ago alladhina

200
00:08:59,780 --> 00:09:01,730
talk she knows more about it does

201
00:09:01,730 --> 00:09:04,520
anybody here not know what silk is okay

202
00:09:04,520 --> 00:09:08,660
so silk is a network monitoring tool for

203
00:09:08,660 --> 00:09:13,280
very very large networks and I think

204
00:09:13,280 --> 00:09:15,110
George could probably explain it better

205
00:09:15,110 --> 00:09:17,560
than I can

206
00:09:21,670 --> 00:09:23,810
yeah you can find it online it's

207
00:09:23,810 --> 00:09:25,520
downloadable to search for silk and you

208
00:09:25,520 --> 00:09:28,190
download it so instead of keeping a

209
00:09:28,190 --> 00:09:31,340
whole bunch of pcap you would then you

210
00:09:31,340 --> 00:09:33,920
would use silk to analyze your network

211
00:09:33,920 --> 00:09:37,550
flow um we use silicon a little bit of a

212
00:09:37,550 --> 00:09:39,710
different way because you can make

213
00:09:39,710 --> 00:09:42,590
what's called prefix maps so that would

214
00:09:42,590 --> 00:09:45,920
map like an IP address to an a s for

215
00:09:45,920 --> 00:09:49,070
example like in any SN and I'm doing

216
00:09:49,070 --> 00:09:51,650
really really fast analysis it also

217
00:09:51,650 --> 00:09:55,690
builds IP sense which is helpful if a

218
00:09:55,690 --> 00:09:58,700
client or sponsor gives you a bunch of

219
00:09:58,700 --> 00:10:00,080
net blocks and you have to build them

220
00:10:00,080 --> 00:10:02,540
yourself and there's some scripts for

221
00:10:02,540 --> 00:10:08,720
automation purposes so we're gonna go

222
00:10:08,720 --> 00:10:10,550
over a methodology a little bit and in

223
00:10:10,550 --> 00:10:14,000
our paper we went through three

224
00:10:14,000 --> 00:10:15,800
different case studies of actor tools

225
00:10:15,800 --> 00:10:18,830
the first was the small case malware the

226
00:10:18,830 --> 00:10:21,860
second was Giroux speed and the third

227
00:10:21,860 --> 00:10:27,430
was sekolah so

228
00:10:27,430 --> 00:10:29,020
like I said a lot of it a lot of

229
00:10:29,020 --> 00:10:30,790
reporting that you'll read and Osen

230
00:10:30,790 --> 00:10:32,470
we'll start with the incident data and

231
00:10:32,470 --> 00:10:34,330
you'll work your way out to try and

232
00:10:34,330 --> 00:10:36,760
understand how an intrusion works so we

233
00:10:36,760 --> 00:10:39,460
are starting with our knowns and in

234
00:10:39,460 --> 00:10:41,860
particular with the data that comes from

235
00:10:41,860 --> 00:10:44,110
our configuration numbers and this gives

236
00:10:44,110 --> 00:10:46,750
us an md5 of all of the files IP

237
00:10:46,750 --> 00:10:51,420
addresses domain name any strings port

238
00:10:51,420 --> 00:10:58,420
remote files etc we then after starting

239
00:10:58,420 --> 00:11:00,730
here you then map out to all of the

240
00:11:00,730 --> 00:11:02,920
other data sets so you can find

241
00:11:02,920 --> 00:11:05,820
additional c2 infrastructure by using

242
00:11:05,820 --> 00:11:08,830
Farsight passive passive DNS database

243
00:11:08,830 --> 00:11:11,380
you can search OSINT

244
00:11:11,380 --> 00:11:14,890
for incident data which is helpful at

245
00:11:14,890 --> 00:11:17,770
least so it can tell you that a piece of

246
00:11:17,770 --> 00:11:19,420
Power has been involved in an incident

247
00:11:19,420 --> 00:11:23,440
and then you can move you can pivot to

248
00:11:23,440 --> 00:11:25,810
the vulnerability that was used in the

249
00:11:25,810 --> 00:11:29,200
exploit these are in no particular order

250
00:11:29,200 --> 00:11:32,080
and the only thing that we chose to

251
00:11:32,080 --> 00:11:35,500
start with where our knowns but

252
00:11:35,500 --> 00:11:37,630
everything else you can kind of do it's

253
00:11:37,630 --> 00:11:40,900
more circular so you can use one of the

254
00:11:40,900 --> 00:11:42,850
pieces one of the data sets to inform

255
00:11:42,850 --> 00:11:46,570
the others the one circle that we left

256
00:11:46,570 --> 00:11:50,170
oughta here was the XO going from

257
00:11:50,170 --> 00:11:52,959
exploit to exploit kit we did not look

258
00:11:52,959 --> 00:11:54,550
at it for these case studies but it's

259
00:11:54,550 --> 00:11:57,250
certainly a future work a future work

260
00:11:57,250 --> 00:11:58,690
area so does that make sense to

261
00:11:58,690 --> 00:11:59,110
everybody

262
00:11:59,110 --> 00:12:05,560
are we all on board here excellent so

263
00:12:05,560 --> 00:12:10,650
what were some of our results so um

264
00:12:10,650 --> 00:12:15,360
again this is an example of jerusaiem

265
00:12:15,360 --> 00:12:18,520
figuration jumper using the farside

266
00:12:18,520 --> 00:12:21,089
passive DNS database to find additional

267
00:12:21,089 --> 00:12:23,830
c2 infrastructure so IP addresses domain

268
00:12:23,830 --> 00:12:28,570
names we then used the md5 hashes of the

269
00:12:28,570 --> 00:12:30,370
DeRussy malware to find infinite data

270
00:12:30,370 --> 00:12:32,770
which there was a lot of thankfully well

271
00:12:32,770 --> 00:12:34,510
maybe not thankfully but at least for my

272
00:12:34,510 --> 00:12:38,910
purposes we then found certain cv ease

273
00:12:38,910 --> 00:12:41,090
and that work similar similar

274
00:12:41,090 --> 00:12:44,430
vulnerabilities were used and then of

275
00:12:44,430 --> 00:12:46,230
course you found the exploit that was

276
00:12:46,230 --> 00:12:47,370
taking advantage of the vulnerability

277
00:12:47,370 --> 00:12:50,370
what's kind of a the highlight here is

278
00:12:50,370 --> 00:12:52,800
that we're not just saying like oh this

279
00:12:52,800 --> 00:12:54,390
is the exploit use like I actually like

280
00:12:54,390 --> 00:12:56,970
dug around until I actually found the

281
00:12:56,970 --> 00:12:59,130
exploit itself or like you know if it

282
00:12:59,130 --> 00:13:01,050
was already on exploit vbe as a proof of

283
00:13:01,050 --> 00:13:02,340
concept or something like that so it's

284
00:13:02,340 --> 00:13:04,530
we actually have the exploits themselves

285
00:13:04,530 --> 00:13:09,060
or supposedly right but it's also

286
00:13:09,060 --> 00:13:11,040
interesting because the exploit piece is

287
00:13:11,040 --> 00:13:12,930
actually the hardest piece and I think

288
00:13:12,930 --> 00:13:15,030
that this is a community gap area that I

289
00:13:15,030 --> 00:13:17,010
think that we can work on I'm not sure

290
00:13:17,010 --> 00:13:19,230
many people are really collecting and

291
00:13:19,230 --> 00:13:21,060
looking at exploits but we are certainly

292
00:13:21,060 --> 00:13:22,500
trying to okay

293
00:13:22,500 --> 00:13:25,710
so what is Giroux see so this is and

294
00:13:25,710 --> 00:13:30,440
used by certain apt actors that

295
00:13:30,440 --> 00:13:33,720
compromised OPM anthem health

296
00:13:33,720 --> 00:13:48,420
forbes.com we assert that the attacker

297
00:13:48,420 --> 00:13:51,090
tool was created in 2006 and there was a

298
00:13:51,090 --> 00:13:56,070
major rewrite in the code um I think I'm

299
00:13:56,070 --> 00:13:58,350
not sure when that happened but in a

300
00:13:58,350 --> 00:13:59,730
couple slides will show you that there

301
00:13:59,730 --> 00:14:01,830
was a pretty big spike in the

302
00:14:01,830 --> 00:14:06,510
collections of jerusaiem malware so

303
00:14:06,510 --> 00:14:10,170
what's really important is in Osen some

304
00:14:10,170 --> 00:14:12,750
people have claimed that guru C is

305
00:14:12,750 --> 00:14:15,540
another malware family called kiddo so

306
00:14:15,540 --> 00:14:19,770
and beyond that some have asserted that

307
00:14:19,770 --> 00:14:23,580
guru Sri is also prima and what has

308
00:14:23,580 --> 00:14:26,220
happened is once one person says these

309
00:14:26,220 --> 00:14:28,350
things other people pick up on it and

310
00:14:28,350 --> 00:14:30,060
they're like yeah yeah definitely like

311
00:14:30,060 --> 00:14:33,030
this is definitely kiddo so um I think

312
00:14:33,030 --> 00:14:36,780
Palo Alto went as far as to call the

313
00:14:36,780 --> 00:14:40,110
actor group using Reba the canosa group

314
00:14:40,110 --> 00:14:41,700
and that was only because there was a

315
00:14:41,700 --> 00:14:43,710
string in the Mauer that said kid oh so

316
00:14:43,710 --> 00:14:47,790
it was not the same hour but we wanted

317
00:14:47,790 --> 00:14:50,490
to look into that to verify some some

318
00:14:50,490 --> 00:14:52,890
are some of those claims because I we

319
00:14:52,890 --> 00:14:53,970
weren't finding people that we're

320
00:14:53,970 --> 00:14:57,810
actually doing that so for the code can

321
00:14:57,810 --> 00:14:59,970
spare comparison time ago like it I'm

322
00:14:59,970 --> 00:15:00,930
gonna talk a little more about our

323
00:15:00,930 --> 00:15:03,029
function ero tools on how that works and

324
00:15:03,029 --> 00:15:04,980
that's what I use to do a lot of this so

325
00:15:04,980 --> 00:15:06,270
the tool that's available out there on

326
00:15:06,270 --> 00:15:12,510
the GFCI github is under the Pharos tool

327
00:15:12,510 --> 00:15:14,550
is function of Y R so how it works is

328
00:15:14,550 --> 00:15:16,790
that it creates a function for any

329
00:15:16,790 --> 00:15:20,970
executable or creates a yars rule for

330
00:15:20,970 --> 00:15:22,709
every function in an executable now you

331
00:15:22,709 --> 00:15:23,850
might say well that's going to give you

332
00:15:23,850 --> 00:15:25,920
good functions bad functions right then

333
00:15:25,920 --> 00:15:28,290
you kind of bang it against a known

334
00:15:28,290 --> 00:15:29,700
clean directory so I would bang it

335
00:15:29,700 --> 00:15:32,250
against a known clean system32 directory

336
00:15:32,250 --> 00:15:34,260
and then remove any hit to occur and

337
00:15:34,260 --> 00:15:36,600
then I have been a subset of rules after

338
00:15:36,600 --> 00:15:39,690
I do some frequency analysis that I can

339
00:15:39,690 --> 00:15:41,730
say that all these rules from this

340
00:15:41,730 --> 00:15:44,399
specific malware that we know is to be

341
00:15:44,399 --> 00:15:46,320
this malware that these rules are

342
00:15:46,320 --> 00:15:48,420
malicious rules what I did then and was

343
00:15:48,420 --> 00:15:49,560
then I'm like well then I want to

344
00:15:49,560 --> 00:15:53,339
compare the rucifee to breva and and

345
00:15:53,339 --> 00:15:56,870
rucifee to Godot so and by doing that

346
00:15:56,870 --> 00:16:00,209
determine like how common are these are

347
00:16:00,209 --> 00:16:02,850
these malware families that supposedly

348
00:16:02,850 --> 00:16:05,670
and open-source are saying that they're

349
00:16:05,670 --> 00:16:07,350
all equal they're all the same whatever

350
00:16:07,350 --> 00:16:09,510
well based on doing this analysis and

351
00:16:09,510 --> 00:16:11,040
looking at these collection numbers of

352
00:16:11,040 --> 00:16:12,540
what we have in house right

353
00:16:12,540 --> 00:16:15,270
but based on starting with cadeau so and

354
00:16:15,270 --> 00:16:17,250
doing the frequency analysis I came with

355
00:16:17,250 --> 00:16:20,520
a rule set that I had then I would when

356
00:16:20,520 --> 00:16:22,560
I compared those rules and how many

357
00:16:22,560 --> 00:16:25,560
rules actually hit on the roost be I

358
00:16:25,560 --> 00:16:27,180
found only one function in common with

359
00:16:27,180 --> 00:16:29,880
four files and another function was

360
00:16:29,880 --> 00:16:31,290
common with eleven so that's showing you

361
00:16:31,290 --> 00:16:33,029
that only two functions of this huge

362
00:16:33,029 --> 00:16:35,820
rulest I had were found to be common in

363
00:16:35,820 --> 00:16:38,040
both malware sets you know similarly

364
00:16:38,040 --> 00:16:39,990
with it the ruse beat and the breva

365
00:16:39,990 --> 00:16:41,640
there's a only share of seven functions

366
00:16:41,640 --> 00:16:44,370
right so you can see how based on doing

367
00:16:44,370 --> 00:16:45,660
further analysis and looking at the code

368
00:16:45,660 --> 00:16:47,579
itself that these files are not the same

369
00:16:47,579 --> 00:16:50,720
this malware is not the same and that

370
00:16:50,720 --> 00:16:56,910
angle so that's why and then one of the

371
00:16:56,910 --> 00:16:57,870
other things is that you don't see a

372
00:16:57,870 --> 00:16:59,760
comparison to breve in credo so that's

373
00:16:59,760 --> 00:17:01,440
in the paper itself but that's different

374
00:17:01,440 --> 00:17:02,579
so

375
00:17:02,579 --> 00:17:04,890
because this is as we talked about we're

376
00:17:04,890 --> 00:17:06,779
only gonna give you one of the three use

377
00:17:06,779 --> 00:17:08,069
cases that we did and this is to talk

378
00:17:08,069 --> 00:17:10,230
about the roots beat that kind of makes

379
00:17:10,230 --> 00:17:11,640
sense so like you know function yours

380
00:17:11,640 --> 00:17:13,230
out there you can use it it's kind of a

381
00:17:13,230 --> 00:17:15,959
good for socks or into responders when

382
00:17:15,959 --> 00:17:16,980
they're trying to get quick hits on

383
00:17:16,980 --> 00:17:19,019
things but like I said you have to take

384
00:17:19,019 --> 00:17:20,819
it and pare down your set before you can

385
00:17:20,819 --> 00:17:22,319
actually have a good a high confidence

386
00:17:22,319 --> 00:17:24,569
that that set you have is a good yard

387
00:17:24,569 --> 00:17:27,659
set too that will hit and only fire on

388
00:17:27,659 --> 00:17:33,029
malicious rules so what were some of our

389
00:17:33,029 --> 00:17:35,159
findings so we're gonna go through each

390
00:17:35,159 --> 00:17:37,169
piece and then kind of put it together

391
00:17:37,169 --> 00:17:42,809
to derive some conclusions so we had 112

392
00:17:42,809 --> 00:17:47,909
files of Jerusalem's of January 2016 we

393
00:17:47,909 --> 00:17:51,120
have not collected any more Duras being

394
00:17:51,120 --> 00:17:54,330
census date as of yesterday rather a

395
00:17:54,330 --> 00:17:56,519
report that we put up within the

396
00:17:56,519 --> 00:17:58,500
configuration jumpa there were 58 unique

397
00:17:58,500 --> 00:18:01,260
domain names used for c2 and only five

398
00:18:01,260 --> 00:18:06,690
IP addresses the malware is

399
00:18:06,690 --> 00:18:09,570
communicating over some pretty common

400
00:18:09,570 --> 00:18:12,450
ports so that's not really too

401
00:18:12,450 --> 00:18:14,460
interesting I guess it's just an extra

402
00:18:14,460 --> 00:18:19,139
data point um and it did have some

403
00:18:19,139 --> 00:18:21,029
remote files and some interesting

404
00:18:21,029 --> 00:18:25,649
strings including CI a dot exe m game

405
00:18:25,649 --> 00:18:30,179
route print pom JPEG none of this is

406
00:18:30,179 --> 00:18:32,370
super interesting but the this is the

407
00:18:32,370 --> 00:18:34,350
kind of information that you can find if

408
00:18:34,350 --> 00:18:36,090
you are looking at a piece of our and

409
00:18:36,090 --> 00:18:38,549
you are writing the configuration dumper

410
00:18:38,549 --> 00:18:41,669
to understand understand the malware

411
00:18:41,669 --> 00:18:44,100
which is cool and I'm not sure most

412
00:18:44,100 --> 00:18:46,320
incident responders are taking this in

413
00:18:46,320 --> 00:18:49,080
implementing implementing it well

414
00:18:49,080 --> 00:18:52,649
network defenders I'm gonna game so we

415
00:18:52,649 --> 00:18:54,779
saw a huge spike in the compile times in

416
00:18:54,779 --> 00:18:57,809
2012 and as a lot of us know these

417
00:18:57,809 --> 00:19:00,600
things can be easily changed again this

418
00:19:00,600 --> 00:19:03,240
is just a data point that take these

419
00:19:03,240 --> 00:19:05,269
types of things with a grain of salt um

420
00:19:05,269 --> 00:19:08,669
I'm not sure what accounts for the spike

421
00:19:08,669 --> 00:19:11,460
from 2011 to 2012 so if anybody has any

422
00:19:11,460 --> 00:19:14,010
ideas please see me later

423
00:19:14,010 --> 00:19:19,640
talk about it so after doing um after

424
00:19:19,640 --> 00:19:22,920
doing some indicator expansion we found

425
00:19:22,920 --> 00:19:27,780
60 more domain names associated with the

426
00:19:27,780 --> 00:19:30,510
malware 50 IP addresses but the

427
00:19:30,510 --> 00:19:32,730
interesting thing is that we found that

428
00:19:32,730 --> 00:19:35,520
all of the infrastructure only used 12

429
00:19:35,520 --> 00:19:39,570
different name servers we also looked

430
00:19:39,570 --> 00:19:41,460
into different records like the SOA

431
00:19:41,460 --> 00:19:43,800
record which might be able to tell which

432
00:19:43,800 --> 00:19:46,380
could tell you more about the person

433
00:19:46,380 --> 00:19:48,090
that was registering the domain among

434
00:19:48,090 --> 00:19:50,400
other details we didn't find any

435
00:19:50,400 --> 00:19:52,890
information the SOA records and we found

436
00:19:52,890 --> 00:19:57,030
that the only MX records were variants

437
00:19:57,030 --> 00:20:01,770
of Yahoo JP which is different not

438
00:20:01,770 --> 00:20:06,150
necessarily expecting that so who owns

439
00:20:06,150 --> 00:20:11,340
or who is responsible for these IP

440
00:20:11,340 --> 00:20:14,760
addresses so these are the the

441
00:20:14,760 --> 00:20:17,580
organizations and the way that we got to

442
00:20:17,580 --> 00:20:20,820
this data was we took the IP addresses

443
00:20:20,820 --> 00:20:23,970
found the autonomous system numbers and

444
00:20:23,970 --> 00:20:25,350
then found the organizations that have

445
00:20:25,350 --> 00:20:30,180
the autonomous systems so Unicom china

446
00:20:30,180 --> 00:20:35,340
was had the most IP addresses and you

447
00:20:35,340 --> 00:20:37,290
see some others sprinkled in here

448
00:20:37,290 --> 00:20:39,090
including confluence which comes up

449
00:20:39,090 --> 00:20:42,870
quite a few times Amazon which is not

450
00:20:42,870 --> 00:20:44,850
terribly surprising because it's pretty

451
00:20:44,850 --> 00:20:46,710
big but the interesting thing is that

452
00:20:46,710 --> 00:20:49,440
Jo's data center came up and one of our

453
00:20:49,440 --> 00:20:51,990
colleagues at cert is presenting at

454
00:20:51,990 --> 00:20:54,330
first I think next week or whenever

455
00:20:54,330 --> 00:20:57,300
first is about identifying public

456
00:20:57,300 --> 00:21:00,090
sinkholes so we know that Jo's data

457
00:21:00,090 --> 00:21:03,870
center is running they are running

458
00:21:03,870 --> 00:21:06,690
sinkholes there for certain types of

459
00:21:06,690 --> 00:21:09,900
malware this is what the network looks

460
00:21:09,900 --> 00:21:13,260
like so the other data point we're

461
00:21:13,260 --> 00:21:14,910
talking about sinsa data so think of

462
00:21:14,910 --> 00:21:17,040
that as public reporting in itself you

463
00:21:17,040 --> 00:21:20,460
know you have your Hutu of doing the

464
00:21:20,460 --> 00:21:22,160
reporting sprouts right you know

465
00:21:22,160 --> 00:21:27,470
Symantec Cisco and so forth right so

466
00:21:27,470 --> 00:21:29,809
tied to these different names it was

467
00:21:29,809 --> 00:21:32,419
tied to deep and outside all hung coup

468
00:21:32,419 --> 00:21:34,669
kitten you know it was involved with the

469
00:21:34,669 --> 00:21:37,490
breach you know supposedly too tied to

470
00:21:37,490 --> 00:21:41,240
the breach of OPM the Rubies only one

471
00:21:41,240 --> 00:21:43,429
part of this rat itself it's actually

472
00:21:43,429 --> 00:21:46,370
the kernel level tool and you know

473
00:21:46,370 --> 00:21:48,260
CrowdStrike also ties it to defense

474
00:21:48,260 --> 00:21:51,919
industrial base you know attacks as well

475
00:21:51,919 --> 00:21:54,159
and what's interesting is that it also

476
00:21:54,159 --> 00:21:56,539
aligned with one of the other use case

477
00:21:56,539 --> 00:21:58,640
that we had ironically is to kula but

478
00:21:58,640 --> 00:22:00,350
they're actually not similar in the self

479
00:22:00,350 --> 00:22:02,120
as well but even though that there's

480
00:22:02,120 --> 00:22:03,740
some sometimes I tie them to the same

481
00:22:03,740 --> 00:22:05,990
way so that's why we say like it's our

482
00:22:05,990 --> 00:22:07,460
approaches that start from malware

483
00:22:07,460 --> 00:22:10,159
itself not really trust out sort out you

484
00:22:10,159 --> 00:22:12,590
know open source reporting as like the

485
00:22:12,590 --> 00:22:18,200
main key area to start from it the other

486
00:22:18,200 --> 00:22:20,559
data point that we mentioned in our

487
00:22:20,559 --> 00:22:23,390
nonlinear sort of circle thing was

488
00:22:23,390 --> 00:22:24,950
vulnerabilities right so it's a ruse be

489
00:22:24,950 --> 00:22:32,179
it was known to link you had the was

490
00:22:32,179 --> 00:22:35,500
linked to these three different CVS and

491
00:22:35,500 --> 00:22:38,210
you know what what was important for me

492
00:22:38,210 --> 00:22:40,520
was actually just find these CV so what

493
00:22:40,520 --> 00:22:42,409
kind of happens or find the exploits

494
00:22:42,409 --> 00:22:45,020
tied to CDs but lucky with time and some

495
00:22:45,020 --> 00:22:46,640
of these were older it makes it easier

496
00:22:46,640 --> 00:22:47,900
to find the exploits out there if I

497
00:22:47,900 --> 00:22:49,909
still took a lot of digging and you have

498
00:22:49,909 --> 00:22:51,740
to kind of trust what you're reading and

499
00:22:51,740 --> 00:22:54,140
that's actually gonna go and dive into

500
00:22:54,140 --> 00:22:55,970
my next slide but like it sort of trust

501
00:22:55,970 --> 00:22:57,500
what you're reading and assume that that

502
00:22:57,500 --> 00:22:58,850
the export that you found is actually

503
00:22:58,850 --> 00:23:00,770
exploit that's tied to that specific CV

504
00:23:00,770 --> 00:23:03,559
and sometimes it's a case and sometimes

505
00:23:03,559 --> 00:23:06,740
it's not I think the other thing to know

506
00:23:06,740 --> 00:23:08,960
is just because the CBE is old doesn't

507
00:23:08,960 --> 00:23:13,250
mean that it's not relevant and I I

508
00:23:13,250 --> 00:23:15,020
think the industry as a whole likes to

509
00:23:15,020 --> 00:23:17,030
chase the shiny penny so you're looking

510
00:23:17,030 --> 00:23:18,950
at oh this year today and that's zero

511
00:23:18,950 --> 00:23:22,400
day but the truth is that the older see

512
00:23:22,400 --> 00:23:24,500
bees are being exploited constantly by

513
00:23:24,500 --> 00:23:27,980
exploit kids and that kind of plays into

514
00:23:27,980 --> 00:23:29,510
this analysis too so just because

515
00:23:29,510 --> 00:23:30,890
they're old doesn't mean that they're

516
00:23:30,890 --> 00:23:33,260
not relevant which ties into the whole

517
00:23:33,260 --> 00:23:35,390
patches and updating your systems and so

518
00:23:35,390 --> 00:23:39,740
forth so this next slide was sort of you

519
00:23:39,740 --> 00:23:40,090
know give

520
00:23:40,090 --> 00:23:42,370
time that's elapsed since our report was

521
00:23:42,370 --> 00:23:44,049
completed well you won't find this

522
00:23:44,049 --> 00:23:46,299
information here however we're working

523
00:23:46,299 --> 00:23:47,289
on putting together a different

524
00:23:47,289 --> 00:23:49,559
technical report and looking at Flash

525
00:23:49,559 --> 00:23:52,809
exploits themselves but so here the you

526
00:23:52,809 --> 00:23:54,010
know it some of the tools I used to do

527
00:23:54,010 --> 00:23:56,130
this so I what I dig into this because

528
00:23:56,130 --> 00:23:58,029
it was something of interest I was

529
00:23:58,029 --> 00:23:59,440
working on different paths but I was

530
00:23:59,440 --> 00:24:01,690
looking at sort of the same CVEs that

531
00:24:01,690 --> 00:24:03,549
were found in our report and then I was

532
00:24:03,549 --> 00:24:05,559
you know doing them through kind of

533
00:24:05,559 --> 00:24:08,590
decompressing them and running a couple

534
00:24:08,590 --> 00:24:12,070
these tools I am visual so I kept seeing

535
00:24:12,070 --> 00:24:15,990
the same I hash appear for a underlying

536
00:24:15,990 --> 00:24:18,159
exploit I'm like well that's time for

537
00:24:18,159 --> 00:24:20,740
the you know it was tied to this CV why

538
00:24:20,740 --> 00:24:22,960
is it showing up in this one right so

539
00:24:22,960 --> 00:24:24,760
that that's sort of where I kind of led

540
00:24:24,760 --> 00:24:26,320
to so it's kind of like why is this

541
00:24:26,320 --> 00:24:27,940
important right so we're certain here

542
00:24:27,940 --> 00:24:30,549
trusting what vendors are saying about

543
00:24:30,549 --> 00:24:32,799
or open sources saying about different

544
00:24:32,799 --> 00:24:34,960
exploits but when you're looking the

545
00:24:34,960 --> 00:24:37,210
actual code I can 100 cent tell you

546
00:24:37,210 --> 00:24:39,070
based on this example I had that's not

547
00:24:39,070 --> 00:24:41,950
the case right so the exploit that came

548
00:24:41,950 --> 00:24:48,039
out for the 2015 86 51 which came out

549
00:24:48,039 --> 00:24:50,049
the end of December which is a zero day

550
00:24:50,049 --> 00:24:51,490
when it came out it was targeting flash

551
00:24:51,490 --> 00:24:55,210
obviously but what was interesting is

552
00:24:55,210 --> 00:24:58,929
that that exact same hash was listed to

553
00:24:58,929 --> 00:25:01,750
be targeted and the attacks that were

554
00:25:01,750 --> 00:25:04,690
going against like this specific hash

555
00:25:04,690 --> 00:25:06,159
but that specific hash once you broke it

556
00:25:06,159 --> 00:25:08,020
down with an actual code was the exact

557
00:25:08,020 --> 00:25:10,570
same exploit that was used a year

558
00:25:10,570 --> 00:25:14,620
earlier and it was tied to the 2014 CV

559
00:25:14,620 --> 00:25:20,890
right so like when looking at it and the

560
00:25:20,890 --> 00:25:23,260
fact that like we trusted the fact that

561
00:25:23,260 --> 00:25:25,720
it was a zero day it wasn't the case

562
00:25:25,720 --> 00:25:27,909
because then the other exploit hashes

563
00:25:27,909 --> 00:25:29,770
that I had for that one didn't match at

564
00:25:29,770 --> 00:25:31,899
all is either so kind of like inclusion

565
00:25:31,899 --> 00:25:33,429
is like what do you trust who do you

566
00:25:33,429 --> 00:25:35,020
trust like what do you believe when it

567
00:25:35,020 --> 00:25:37,890
comes like these exploits in the CVS and

568
00:25:37,890 --> 00:25:39,640
you know like I said we're doing further

569
00:25:39,640 --> 00:25:42,039
analysis in it I only kind of the tip of

570
00:25:42,039 --> 00:25:44,260
the iceberg here when looking at the

571
00:25:44,260 --> 00:25:45,460
stuff but it was sort of an interesting

572
00:25:45,460 --> 00:25:52,340
finding that I had so the TLDR here

573
00:25:52,340 --> 00:25:55,880
is that guru speed was used by apt

574
00:25:55,880 --> 00:25:59,330
actors named de panda shell crew

575
00:25:59,330 --> 00:26:01,400
what have you there are thousands of

576
00:26:01,400 --> 00:26:04,039
names that drive me nuts

577
00:26:04,039 --> 00:26:07,370
Giroux speed is not kiddo so orb Reba

578
00:26:07,370 --> 00:26:10,789
which is very important um is important

579
00:26:10,789 --> 00:26:12,289
for a couple reasons because if it was

580
00:26:12,289 --> 00:26:14,900
kiddo so orb Reba then that would have

581
00:26:14,900 --> 00:26:16,909
added back into our analysis set we

582
00:26:16,909 --> 00:26:18,590
would have had more Maur to look at but

583
00:26:18,590 --> 00:26:21,110
it is not so please do not believe

584
00:26:21,110 --> 00:26:24,260
everything that you read the actors use

585
00:26:24,260 --> 00:26:27,559
a very small Network compared to some of

586
00:26:27,559 --> 00:26:29,360
the other networks that I've looked at

587
00:26:29,360 --> 00:26:34,730
um they also and I think I forgot to

588
00:26:34,730 --> 00:26:39,110
bring this up so one of the a SS um one

589
00:26:39,110 --> 00:26:40,580
of the organizations was actually the

590
00:26:40,580 --> 00:26:42,980
Taiwanese academic network that was used

591
00:26:42,980 --> 00:26:44,360
during so you know which I thought was

592
00:26:44,360 --> 00:26:45,919
kind of interesting so we can say that

593
00:26:45,919 --> 00:26:48,020
at least in some degree the actors were

594
00:26:48,020 --> 00:26:51,140
probably targeting that that

595
00:26:51,140 --> 00:26:53,510
organization in some way the

596
00:26:53,510 --> 00:26:55,309
infrastructure uses only twelve name

597
00:26:55,309 --> 00:27:01,279
servers and in at least two cases the

598
00:27:01,279 --> 00:27:04,299
group exploited zero-day vulnerabilities

599
00:27:04,299 --> 00:27:10,399
what I want for for those of you guys

600
00:27:10,399 --> 00:27:12,740
listening is that if you guys are

601
00:27:12,740 --> 00:27:16,279
network defenders please take to do this

602
00:27:16,279 --> 00:27:18,649
analysis take the data that you find so

603
00:27:18,649 --> 00:27:20,809
the extra domain names IP addresses

604
00:27:20,809 --> 00:27:22,970
what-have-you and implement them to

605
00:27:22,970 --> 00:27:26,929
protect yourself the malware is like we

606
00:27:26,929 --> 00:27:29,659
can say with certainty what the actors

607
00:27:29,659 --> 00:27:31,820
are using in terms of c2 infrastructure

608
00:27:31,820 --> 00:27:35,960
and I'm just you don't typically see

609
00:27:35,960 --> 00:27:41,480
this type of analysis out there yeah

610
00:27:41,480 --> 00:27:44,120
this you know the three CDs that were

611
00:27:44,120 --> 00:27:46,580
used and exploits themselves you can

612
00:27:46,580 --> 00:27:48,049
find the actual hashes for the exploits

613
00:27:48,049 --> 00:27:52,370
and they are paper and you know you know

614
00:27:52,370 --> 00:27:53,630
it's important to see you know that the

615
00:27:53,630 --> 00:27:56,240
focus on what you actually know before

616
00:27:56,240 --> 00:27:57,860
you and that you actually trust someone

617
00:27:57,860 --> 00:27:59,799
going forward

618
00:27:59,799 --> 00:28:02,059
some of the future work you know this is

619
00:28:02,059 --> 00:28:03,590
just one methodology right so there's

620
00:28:03,590 --> 00:28:05,040
just a methodology that we use

621
00:28:05,040 --> 00:28:07,050
it's important that you can also kind of

622
00:28:07,050 --> 00:28:08,400
pivot your different ways from there

623
00:28:08,400 --> 00:28:09,570
we're just saying that start with that

624
00:28:09,570 --> 00:28:11,190
malware that you know that you malware

625
00:28:11,190 --> 00:28:13,800
you understand and it's been from there

626
00:28:13,800 --> 00:28:16,830
a couple of the community gap areas

627
00:28:16,830 --> 00:28:20,580
themselves is that is in exploits right

628
00:28:20,580 --> 00:28:22,170
so it's very retroactive unless you're

629
00:28:22,170 --> 00:28:23,520
developing the exploit right like you

630
00:28:23,520 --> 00:28:24,570
don't know about an exploit till

631
00:28:24,570 --> 00:28:26,340
actually happens if that's not the case

632
00:28:26,340 --> 00:28:28,170
I'd love to talk to you more because how

633
00:28:28,170 --> 00:28:31,740
do you find out we actually developed an

634
00:28:31,740 --> 00:28:33,570
exploit catalog itself so we're kind of

635
00:28:33,570 --> 00:28:36,870
cataloging exploits the actual files or

636
00:28:36,870 --> 00:28:39,690
hashes or proof of concepts I tied to

637
00:28:39,690 --> 00:28:41,700
CVS and like I said we're doing the

638
00:28:41,700 --> 00:28:44,310
preacher analysis on like flash exploits

639
00:28:44,310 --> 00:28:46,410
which we can actually that can expand

640
00:28:46,410 --> 00:28:48,750
into other application exploits

641
00:28:48,750 --> 00:28:50,520
themselves and we can happy to talk

642
00:28:50,520 --> 00:28:55,980
about any that offline ok so the

643
00:28:55,980 --> 00:28:58,500
takeaways for you are that this is an

644
00:28:58,500 --> 00:29:00,600
outside-in approach instead of an

645
00:29:00,600 --> 00:29:04,380
inside-out approach that allows you to

646
00:29:04,380 --> 00:29:06,180
see just more than one aspect of an

647
00:29:06,180 --> 00:29:07,470
intrusion so we talked about

648
00:29:07,470 --> 00:29:10,740
vulnerabilities exploits malware situ

649
00:29:10,740 --> 00:29:12,750
infrastructure and a little bit about

650
00:29:12,750 --> 00:29:16,320
the actors this is important for those

651
00:29:16,320 --> 00:29:17,760
of us in the threat intelligence

652
00:29:17,760 --> 00:29:19,980
communities too because we're not

653
00:29:19,980 --> 00:29:22,380
necessarily focusing on just one piece

654
00:29:22,380 --> 00:29:26,120
you really wanted to put it together um

655
00:29:26,120 --> 00:29:29,220
put the I guess a more complete story

656
00:29:29,220 --> 00:29:31,470
together for everybody what this means

657
00:29:31,470 --> 00:29:33,630
for network defenders is that if you go

658
00:29:33,630 --> 00:29:35,310
through this methodology and you pivot

659
00:29:35,310 --> 00:29:37,320
from one data set to the next you can

660
00:29:37,320 --> 00:29:41,040
then deploy whatever IO sees you find to

661
00:29:41,040 --> 00:29:45,930
protect your networks this also kind of

662
00:29:45,930 --> 00:29:48,270
helps us create an adversary profile too

663
00:29:48,270 --> 00:29:51,060
so if we understand that an adversary is

664
00:29:51,060 --> 00:29:53,460
using a particular tool then we can take

665
00:29:53,460 --> 00:29:54,660
a look at that and see if there are

666
00:29:54,660 --> 00:29:56,430
other tools that they might be using if

667
00:29:56,430 --> 00:30:00,450
there is similar code and so forth so

668
00:30:00,450 --> 00:30:03,090
our goal was to really start with the

669
00:30:03,090 --> 00:30:05,580
tools instead of with incident data and

670
00:30:05,580 --> 00:30:08,910
separately to confirm or deny what you

671
00:30:08,910 --> 00:30:11,370
are finding in osun's

672
00:30:11,370 --> 00:30:13,950
um please don't believe everything you

673
00:30:13,950 --> 00:30:17,430
read um and think a little bit harder

674
00:30:17,430 --> 00:30:20,910
about how we as a community want to

675
00:30:20,910 --> 00:30:29,280
approach the adversary so we're open for

676
00:30:29,280 --> 00:30:33,290
questions by link to our paper their

677
00:30:36,260 --> 00:30:38,630
adversary

678
00:30:38,630 --> 00:30:42,800
hash functions

679
00:30:48,960 --> 00:30:52,369
in other words you distract that

680
00:30:53,070 --> 00:30:56,320
so the thing is about tracking malware

681
00:30:56,320 --> 00:30:59,409
itself is that unfortunately we in the

682
00:30:59,409 --> 00:31:01,899
world people are really lazy so I guess

683
00:31:01,899 --> 00:31:04,149
she could have an adversary that changes

684
00:31:04,149 --> 00:31:06,370
the code every time it it deploys

685
00:31:06,370 --> 00:31:09,159
something but what we found is even like

686
00:31:09,159 --> 00:31:11,440
the really advanced actors only change a

687
00:31:11,440 --> 00:31:13,779
little bit of the code which is why we

688
00:31:13,779 --> 00:31:16,870
can group malware families because

689
00:31:16,870 --> 00:31:18,940
ultimately people are really lazy

690
00:31:18,940 --> 00:31:21,820
now you're right though that we probably

691
00:31:21,820 --> 00:31:24,880
aren't tracking the 1% of the people of

692
00:31:24,880 --> 00:31:26,950
the a PT's that are doing like some

693
00:31:26,950 --> 00:31:29,350
really really bad things but I think

694
00:31:29,350 --> 00:31:30,669
that's a really hard problem I'm not

695
00:31:30,669 --> 00:31:33,640
sure that anybody really has like a

696
00:31:33,640 --> 00:31:35,950
really good solution but like I said

697
00:31:35,950 --> 00:31:38,860
this is just one methodology not the

698
00:31:38,860 --> 00:31:41,969
methodology to use

699
00:31:52,420 --> 00:31:56,690
so we are we have a collection of

700
00:31:56,690 --> 00:31:58,550
different feeds that we've been

701
00:31:58,550 --> 00:32:01,010
analyzing now for like 10 to 12 years so

702
00:32:01,010 --> 00:32:04,880
we have a bunch of files that we've

703
00:32:04,880 --> 00:32:07,220
looked at just from collection so we

704
00:32:07,220 --> 00:32:09,470
didn't have the incident if that like it

705
00:32:09,470 --> 00:32:11,210
wasn't like we collected it because we

706
00:32:11,210 --> 00:32:13,570
were hosed

707
00:32:14,110 --> 00:32:18,020
yeah yeah yeah we we just kind of have a

708
00:32:18,020 --> 00:32:19,520
malware set and it kinda came in through

709
00:32:19,520 --> 00:32:21,950
an RFI to say hey we found this can you

710
00:32:21,950 --> 00:32:23,480
look at this for us and then that's

711
00:32:23,480 --> 00:32:24,890
where we develop and you know we find

712
00:32:24,890 --> 00:32:27,170
out we have oh we start with five but

713
00:32:27,170 --> 00:32:28,880
now we have you know a hundred because

714
00:32:28,880 --> 00:32:31,550
they soon our reverse engineer is based

715
00:32:31,550 --> 00:32:32,750
in doing their analysis and how they

716
00:32:32,750 --> 00:32:34,010
develop it they're able to develop and

717
00:32:34,010 --> 00:32:36,650
find more samples and our huge bucket of

718
00:32:36,650 --> 00:32:39,670
two hundred fifty million samples

719
00:32:46,230 --> 00:32:49,570
the first question I mean doesn't this

720
00:32:49,570 --> 00:32:51,570
53 automated

721
00:32:51,570 --> 00:32:55,070
I mean yes if you

722
00:32:55,070 --> 00:32:59,000
by indicators or particular actor but in

723
00:32:59,000 --> 00:33:01,340
large I mean look at this groove I'm

724
00:33:01,340 --> 00:33:03,500
like we're all not going to be able to

725
00:33:03,500 --> 00:33:06,679
do this work and do and do it this

726
00:33:06,679 --> 00:33:08,690
problem is we don't know but

727
00:33:08,690 --> 00:33:11,900
together because my attachment to Diego

728
00:33:11,900 --> 00:33:14,450
or whatever out so I mean isn't it

729
00:33:14,450 --> 00:33:19,220
really in the Hobby only it wasn't you

730
00:33:19,220 --> 00:33:20,930
know to be really oughta even only

731
00:33:20,930 --> 00:33:23,210
automate parts that do the university

732
00:33:23,210 --> 00:33:26,360
years because you can't automate it

733
00:33:26,360 --> 00:33:30,230
I mean in other words like obviously the

734
00:33:30,230 --> 00:33:34,220
process of their intelligence do

735
00:33:34,220 --> 00:33:38,790
in part because obviously to identify an

736
00:33:38,790 --> 00:33:41,370
entire grouping I mean there are a lot

737
00:33:41,370 --> 00:33:43,809
of threat after

738
00:33:43,809 --> 00:33:52,149
in this field I mean I'm not a I'm just

739
00:33:52,149 --> 00:33:54,969
saying that I mean it very hard to get

740
00:33:54,969 --> 00:33:55,869
in

741
00:33:55,869 --> 00:34:02,139
yeah or pretty much too I mean in in

742
00:34:02,139 --> 00:34:04,419
sense we're saying be careful with you

743
00:34:04,419 --> 00:34:05,739
know trust and right yeah I mean you

744
00:34:05,739 --> 00:34:06,999
could you have to sort of trust right

745
00:34:06,999 --> 00:34:08,109
because you're paying for these reports

746
00:34:08,109 --> 00:34:10,359
from whomever right that develops the

747
00:34:10,359 --> 00:34:11,799
reports and that you know you're paying

748
00:34:11,799 --> 00:34:14,589
to get this feed and it has md5 and you

749
00:34:14,589 --> 00:34:16,750
know IP so you have to sort of trust it

750
00:34:16,750 --> 00:34:19,449
right but like if you it's more like if

751
00:34:19,449 --> 00:34:20,799
you have your in-house shop and you're

752
00:34:20,799 --> 00:34:22,690
developing out like this is a sort of

753
00:34:22,690 --> 00:34:23,949
approach that I would take if I was

754
00:34:23,949 --> 00:34:25,869
developing my shop inside out which is

755
00:34:25,869 --> 00:34:28,179
sort of how we do it sir right but we're

756
00:34:28,179 --> 00:34:30,299
not

757
00:34:41,089 --> 00:34:45,480
anyway exorcism anyone doing cleaning of

758
00:34:45,480 --> 00:34:54,000
the CBE database no no I mean I think

759
00:34:54,000 --> 00:34:56,429
it's a lot of trusting and then like how

760
00:34:56,429 --> 00:34:58,589
ABS and if I understand how most IVs

761
00:34:58,589 --> 00:35:00,240
work they like to look at a hash because

762
00:35:00,240 --> 00:35:02,190
like once I ran these files back through

763
00:35:02,190 --> 00:35:04,260
say virustotal right I upload them back

764
00:35:04,260 --> 00:35:07,410
up they hit on what they said they were

765
00:35:07,410 --> 00:35:08,730
supposed to hit on right and then it's

766
00:35:08,730 --> 00:35:10,770
like that's not the case and especially

767
00:35:10,770 --> 00:35:12,510
if it's compressed right like so you you

768
00:35:12,510 --> 00:35:14,280
throw the original file out it says it's

769
00:35:14,280 --> 00:35:15,960
this CVE you know once you you know

770
00:35:15,960 --> 00:35:18,450
decompress it and then it's a no it's

771
00:35:18,450 --> 00:35:19,830
this CV you're like well then you're

772
00:35:19,830 --> 00:35:22,349
just going on a hash alone I don't know

773
00:35:22,349 --> 00:35:29,460
if anybody scraping it furthering the

774
00:35:29,460 --> 00:35:32,220
automation needs developing a tool that

775
00:35:32,220 --> 00:35:33,430
goes from a coach

776
00:35:33,430 --> 00:35:36,610
the RF converter one

777
00:35:36,610 --> 00:35:40,090
out there we can share our signature

778
00:35:40,090 --> 00:35:41,950
that's certainly a step into the

779
00:35:41,950 --> 00:35:43,840
automation process so there is some

780
00:35:43,840 --> 00:35:46,270
contribution there so the actual

781
00:35:46,270 --> 00:35:49,660
question I had was to so when you are

782
00:35:49,660 --> 00:35:51,610
doing your comparison sort of convincing

783
00:35:51,610 --> 00:35:52,120
me that

784
00:35:52,120 --> 00:35:54,520
brueski is not these other families the

785
00:35:54,520 --> 00:35:59,110
kind of missing convincing piece I would

786
00:35:59,110 --> 00:36:00,580
have liked to see an imperious have

787
00:36:00,580 --> 00:36:04,570
you've done is if you sort of overlap

788
00:36:04,570 --> 00:36:07,000
those few functions by Authority or

789
00:36:07,000 --> 00:36:10,480
whatever that overlap there is being

790
00:36:10,480 --> 00:36:11,980
those other families where those

791
00:36:11,980 --> 00:36:15,040
overlapping functions found in malware

792
00:36:15,040 --> 00:36:17,530
families all across the board right

793
00:36:17,530 --> 00:36:19,690
never convince me more that make sense

794
00:36:19,690 --> 00:36:23,440
yeah no we did not do that you know we

795
00:36:23,440 --> 00:36:24,670
did it for like these sets we have

796
00:36:24,670 --> 00:36:26,470
that's something that could go up on I

797
00:36:26,470 --> 00:36:27,820
mean you kind of have a little more

798
00:36:27,820 --> 00:36:29,680
insight to how we work but it explains

799
00:36:29,680 --> 00:36:31,750
everybody else how how we started with

800
00:36:31,750 --> 00:36:33,250
these sets and how we were competency

801
00:36:33,250 --> 00:36:34,720
sets that we have reverse engineers

802
00:36:34,720 --> 00:36:37,210
actually get sample sets that reverse it

803
00:36:37,210 --> 00:36:38,410
great functions

804
00:36:38,410 --> 00:36:39,940
or sorry create yard signatures and

805
00:36:39,940 --> 00:36:41,530
identify other things and they also can

806
00:36:41,530 --> 00:36:43,660
great compete Gompers identify you know

807
00:36:43,660 --> 00:36:46,300
other fakes for those same malware

808
00:36:46,300 --> 00:36:47,590
family so that's sort of where we start

809
00:36:47,590 --> 00:36:49,960
with but looking at that overlap of

810
00:36:49,960 --> 00:36:51,760
other functions that hit everywhere else

811
00:36:51,760 --> 00:36:53,830
no but I mean that's something should be

812
00:36:53,830 --> 00:36:55,300
done right I mean because you you know

813
00:36:55,300 --> 00:36:58,720
how many common non-associated malware

814
00:36:58,720 --> 00:37:00,190
families are using similar functions

815
00:37:00,190 --> 00:37:01,990
right I mean you know code reuse is very

816
00:37:01,990 --> 00:37:03,490
common you know why reinvent the wheel

817
00:37:03,490 --> 00:37:06,370
so so the other thing just to address

818
00:37:06,370 --> 00:37:09,550
your your question of n is we did take a

819
00:37:09,550 --> 00:37:12,970
look we we worked with well Casey to do

820
00:37:12,970 --> 00:37:15,610
his suffix tree analysis to which

821
00:37:15,610 --> 00:37:19,600
confirmed so one of our data scientists

822
00:37:19,600 --> 00:37:21,970
will take the binaries and compare the

823
00:37:21,970 --> 00:37:23,770
binaries between different malware

824
00:37:23,770 --> 00:37:26,860
families in we did that so we did it at

825
00:37:26,860 --> 00:37:28,270
the function D our level and then we did

826
00:37:28,270 --> 00:37:31,000
it like at like a lower level if you

827
00:37:31,000 --> 00:37:33,280
will and we it confirmed our findings

828
00:37:33,280 --> 00:37:36,330
that they were very very different

829
00:37:36,330 --> 00:37:39,010
that's in the paper we just didn't

830
00:37:39,010 --> 00:37:40,600
present about it it's kind of a tricky

831
00:37:40,600 --> 00:37:42,460
it's not necessarily the easiest thing

832
00:37:42,460 --> 00:37:44,550
to discuss

833
00:37:44,550 --> 00:37:47,080
contacts them what other families were

834
00:37:47,080 --> 00:37:49,150
looked at because I think you're doing a

835
00:37:49,150 --> 00:37:50,830
suffix tree comparison it is sort of

836
00:37:50,830 --> 00:37:54,220
looking at what parts of the web

837
00:37:54,220 --> 00:37:57,060
overlapping chunks of the code are

838
00:37:57,060 --> 00:37:59,740
coming but we're in a question with the

839
00:37:59,740 --> 00:38:01,330
suffix trees thank you

840
00:38:01,330 --> 00:38:02,620
part of the question with the sub

841
00:38:02,620 --> 00:38:06,160
extreme is this what I'm saying with the

842
00:38:06,160 --> 00:38:08,260
suffix tree analysis is you may have

843
00:38:08,260 --> 00:38:10,150
looked at a few other families I guess

844
00:38:10,150 --> 00:38:12,340
isn't suggesting that like broadening

845
00:38:12,340 --> 00:38:18,640
the scope I think there's like a lot of

846
00:38:18,640 --> 00:38:20,560
auxiliary things that we can do and I

847
00:38:20,560 --> 00:38:22,090
think you bring up a good point so this

848
00:38:22,090 --> 00:38:23,560
was just kind of the beginning not

849
00:38:23,560 --> 00:38:26,290
necessarily the end right and kind of

850
00:38:26,290 --> 00:38:28,180
like how we got down this path as well -

851
00:38:28,180 --> 00:38:30,640
right so like the other use cases aren't

852
00:38:30,640 --> 00:38:32,320
like this they're more they're actually

853
00:38:32,320 --> 00:38:34,270
more simple it's just that when we were

854
00:38:34,270 --> 00:38:36,700
doing like you know researching that we

855
00:38:36,700 --> 00:38:38,530
refine it open source was calling the

856
00:38:38,530 --> 00:38:40,120
rucifee and kudos oh and breve of the

857
00:38:40,120 --> 00:38:42,370
same that's sort of why we chose it does

858
00:38:42,370 --> 00:38:44,020
explain this one right and then go down

859
00:38:44,020 --> 00:38:45,280
that path but the other two use case is

860
00:38:45,280 --> 00:38:47,260
in our paper a little more simplistic

861
00:38:47,260 --> 00:38:51,310
than this is I know you had mentioned

862
00:38:51,310 --> 00:38:53,770
that people are kind of lazy so they

863
00:38:53,770 --> 00:38:56,680
tend to reuse code but isn't it simple

864
00:38:56,680 --> 00:38:58,540
enough for people just to throw like an

865
00:38:58,540 --> 00:39:00,400
opcode randomization step into their

866
00:39:00,400 --> 00:39:02,290
bill when you see that in the wild at

867
00:39:02,290 --> 00:39:04,440
all

868
00:39:04,590 --> 00:39:07,350
I mean not for these specific examples

869
00:39:07,350 --> 00:39:09,270
but I mean I mean that's not something

870
00:39:09,270 --> 00:39:12,840
that's uncommon right I mean what you

871
00:39:12,840 --> 00:39:15,570
know based on you know once you reverse

872
00:39:15,570 --> 00:39:16,890
and understand that right you're gonna

873
00:39:16,890 --> 00:39:19,130
kind of know what to look for and I

874
00:39:19,130 --> 00:39:21,420
think you know that's something that's

875
00:39:21,420 --> 00:39:23,790
it does anything that's polymorphic it's

876
00:39:23,790 --> 00:39:27,990
gonna cause you know harder analysis

877
00:39:27,990 --> 00:39:36,840
right so anybody thanks all right cool

878
00:39:36,840 --> 00:39:45,360
thanks yes once more thank you very much

879
00:39:45,360 --> 00:39:47,910
Dina and Kyle will give them speaker

880
00:39:47,910 --> 00:39:50,610
gifts they're wonderful if you would

881
00:39:50,610 --> 00:39:52,260
like a speaker gift yourself you have to

882
00:39:52,260 --> 00:39:55,560
be a speaker all right there you go

883
00:39:55,560 --> 00:39:57,090
thanks you getting round of applause

884
00:39:57,090 --> 00:39:59,300
please

