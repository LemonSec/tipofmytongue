1
00:00:01,570 --> 00:00:09,860
all right welcome back for this next

2
00:00:07,549 --> 00:00:13,630
talk we've got Alyssa Miller and that is

3
00:00:09,860 --> 00:00:14,919
the the coolest most awesome stylize

4
00:00:13,630 --> 00:00:18,470
[Music]

5
00:00:14,920 --> 00:00:21,529
like beginning to a slide deck that I've

6
00:00:18,470 --> 00:00:23,329
seen that is that is awesome I love how

7
00:00:21,529 --> 00:00:24,890
it looks embossed like it looks it looks

8
00:00:23,329 --> 00:00:29,359
raised like it was stamped out like a

9
00:00:24,890 --> 00:00:33,399
license plate that is super cool can I

10
00:00:29,359 --> 00:00:33,399
say stupid PowerPoint tricks you know

11
00:00:33,910 --> 00:00:39,468
[Laughter]

12
00:00:36,250 --> 00:00:41,899
yes so this is I think there's a really

13
00:00:39,469 --> 00:00:43,190
interesting one I'm glad we got a talk

14
00:00:41,899 --> 00:00:45,980
like this that you submitted something

15
00:00:43,190 --> 00:00:48,589
like this you know I think we've seen a

16
00:00:45,980 --> 00:00:51,559
lot of fraudulent stuff in the years but

17
00:00:48,589 --> 00:00:53,510
but very few that like viscerally

18
00:00:51,559 --> 00:00:55,129
physically give you chills when you see

19
00:00:53,510 --> 00:00:58,309
them in action

20
00:00:55,129 --> 00:01:03,949
and deep fakes are are super creepy I

21
00:00:58,309 --> 00:01:05,899
think most people will agree so yeah if

22
00:01:03,949 --> 00:01:08,390
you're well we're one minute away I

23
00:01:05,899 --> 00:01:11,329
think we should wait until 3 o'clock

24
00:01:08,390 --> 00:01:14,119
just uh just to be fair okay you know

25
00:01:11,329 --> 00:01:15,710
we've been bang on starting right on

26
00:01:14,119 --> 00:01:18,560
time throughout this so I don't I don't

27
00:01:15,710 --> 00:01:24,850
want to start one early and somebody

28
00:01:18,560 --> 00:01:27,530
that might miss something but yeah

29
00:01:24,850 --> 00:01:29,630
thanks for coming to talk at I believe

30
00:01:27,530 --> 00:01:33,530
you you're not oh man look at the guitar

31
00:01:29,630 --> 00:01:36,110
collection in the background alright we

32
00:01:33,530 --> 00:01:38,149
if we were super early we'd have all

33
00:01:36,110 --> 00:01:40,070
kinds of stuff to talk about I've I've

34
00:01:38,149 --> 00:01:46,909
actually been playing guitar and bass in

35
00:01:40,070 --> 00:01:50,419
between presenting people here well it

36
00:01:46,909 --> 00:01:53,409
is three o'clock and if you're all ready

37
00:01:50,420 --> 00:01:57,009
to go I will turn it over I am all set

38
00:01:53,409 --> 00:01:57,009
take it away Alyssa

39
00:01:59,680 --> 00:02:02,680
you

40
00:02:02,820 --> 00:02:09,788
all right well welcome everybody my name

41
00:02:06,670 --> 00:02:11,830
is Alyssa Miller and you have joined me

42
00:02:09,788 --> 00:02:15,279
and the rest of the folks here for

43
00:02:11,830 --> 00:02:19,150
losing our reality deep fakes changing

44
00:02:15,280 --> 00:02:20,590
the face of attacks so if we've not met

45
00:02:19,150 --> 00:02:22,900
before let me tell you a little bit

46
00:02:20,590 --> 00:02:25,959
about myself first

47
00:02:22,900 --> 00:02:28,239
first of all foremost I am a hacker and

48
00:02:25,959 --> 00:02:30,430
a researcher I have been a hacker all my

49
00:02:28,239 --> 00:02:31,660
life I bought my first computer when I

50
00:02:30,430 --> 00:02:34,440
was 12

51
00:02:31,660 --> 00:02:38,260
taught myself how to program in basic

52
00:02:34,440 --> 00:02:40,540
quickly learned asynchronous modem

53
00:02:38,260 --> 00:02:43,420
communications and started playing

54
00:02:40,540 --> 00:02:44,980
around with a service that unless you're

55
00:02:43,420 --> 00:02:49,030
old like me you might not have even

56
00:02:44,980 --> 00:02:51,040
heard of prodigy before so yeah I've

57
00:02:49,030 --> 00:02:51,760
been doing this pretty much my whole

58
00:02:51,040 --> 00:02:53,829
life

59
00:02:51,760 --> 00:02:56,380
I'm also an application security

60
00:02:53,830 --> 00:02:57,910
advocate for a company called sneak if

61
00:02:56,380 --> 00:02:59,470
you haven't heard of us I can talk to

62
00:02:57,910 --> 00:03:01,390
you about that some other time you'll

63
00:02:59,470 --> 00:03:04,180
have all sorts of contact information

64
00:03:01,390 --> 00:03:06,458
for me later I'm also an author and a

65
00:03:04,180 --> 00:03:07,690
blogger so I do have my website I'll

66
00:03:06,459 --> 00:03:11,110
give you the link to that where I keep

67
00:03:07,690 --> 00:03:15,370
my blog I'm currently working on a book

68
00:03:11,110 --> 00:03:19,720
that will be released in preview form

69
00:03:15,370 --> 00:03:22,090
fairly shortly a guide on helping people

70
00:03:19,720 --> 00:03:24,430
start their career in information

71
00:03:22,090 --> 00:03:27,910
security so kind of goes along with our

72
00:03:24,430 --> 00:03:30,760
last talk a little bit and then finally

73
00:03:27,910 --> 00:03:32,769
I'm also speaking of our last talk

74
00:03:30,760 --> 00:03:35,260
you've met one of my co-hosts from the

75
00:03:32,769 --> 00:03:38,410
uncommon journey Colima stodgy is

76
00:03:35,260 --> 00:03:42,910
another so we do host that podcast and

77
00:03:38,410 --> 00:03:45,549
itsp magazine so today I want to take

78
00:03:42,910 --> 00:03:48,880
you guys on a journey and it's a journey

79
00:03:45,549 --> 00:03:52,420
of sight and sound and I want to begin

80
00:03:48,880 --> 00:03:55,239
by asking you to take just a moment and

81
00:03:52,420 --> 00:03:57,640
look around you you might be sitting at

82
00:03:55,239 --> 00:04:00,880
a desk watching this you might be on a

83
00:03:57,640 --> 00:04:04,328
couch just notice the things that you

84
00:04:00,880 --> 00:04:07,450
see around you take a deep breath in

85
00:04:04,329 --> 00:04:09,330
what do you smell what sense are

86
00:04:07,450 --> 00:04:13,589
floating in the air right now

87
00:04:09,330 --> 00:04:15,569
what do you hear what sounds are around

88
00:04:13,590 --> 00:04:18,720
when we perceive

89
00:04:15,569 --> 00:04:21,238
the world around us we use our five

90
00:04:18,720 --> 00:04:23,720
senses everything that we know

91
00:04:21,238 --> 00:04:26,758
everything we've based science off of

92
00:04:23,720 --> 00:04:29,780
everything that we understand about this

93
00:04:26,759 --> 00:04:32,250
world is based on our five senses but

94
00:04:29,780 --> 00:04:35,280
what I'm here to talk to you about today

95
00:04:32,250 --> 00:04:38,910
is the fact that attackers now have the

96
00:04:35,280 --> 00:04:41,849
ability to attack those very senses that

97
00:04:38,910 --> 00:04:45,120
we use to perceive the world around us

98
00:04:41,850 --> 00:04:48,570
and this is the new attack paradigm of

99
00:04:45,120 --> 00:04:51,300
deep fakes so when I talk about deep

100
00:04:48,570 --> 00:04:53,370
fakes let let's discuss really briefly

101
00:04:51,300 --> 00:04:57,000
what it is that I'm actually referring

102
00:04:53,370 --> 00:04:59,849
to when I talk about deep fakes I'm

103
00:04:57,000 --> 00:05:02,820
talking about any form of artificial

104
00:04:59,849 --> 00:05:05,639
media that's created using deep learning

105
00:05:02,820 --> 00:05:07,500
neural networks now it might come in the

106
00:05:05,639 --> 00:05:10,259
form of still images as you see in the

107
00:05:07,500 --> 00:05:15,090
upper right it could come in the form of

108
00:05:10,259 --> 00:05:16,979
audio or as most of us who are who ever

109
00:05:15,090 --> 00:05:19,440
ever heard of defects before probably

110
00:05:16,979 --> 00:05:22,289
what you've seen our videos like this

111
00:05:19,440 --> 00:05:25,080
one of Steve Buscemi at the Golden Globe

112
00:05:22,289 --> 00:05:26,699
Awards only that's not Steve Buscemi

113
00:05:25,080 --> 00:05:31,139
wearing a dress I'm sorry

114
00:05:26,699 --> 00:05:34,349
so we you may have seen some of this

115
00:05:31,139 --> 00:05:36,449
media before ultra-realistic very

116
00:05:34,349 --> 00:05:38,520
difficult to tell that it's fake other

117
00:05:36,449 --> 00:05:42,780
than clearly that's not Steve Buscemi's

118
00:05:38,520 --> 00:05:45,870
body but these are all created using

119
00:05:42,780 --> 00:05:48,719
deep learning neural networks now deep

120
00:05:45,870 --> 00:05:52,289
fakes began as a research project back

121
00:05:48,720 --> 00:05:54,330
in 2017 a paper was released detailing

122
00:05:52,289 --> 00:05:57,030
how researchers were able to create this

123
00:05:54,330 --> 00:06:01,320
type of media using these deep learning

124
00:05:57,030 --> 00:06:03,869
neural networks and you know where most

125
00:06:01,320 --> 00:06:07,020
promising technology seems to take its

126
00:06:03,870 --> 00:06:09,690
foothold first the porn industry jumped

127
00:06:07,020 --> 00:06:11,820
all over this they realized that they

128
00:06:09,690 --> 00:06:14,699
could use this technology to take the

129
00:06:11,820 --> 00:06:17,639
faces of popular celebrities and place

130
00:06:14,699 --> 00:06:21,300
them on the bodies of the actresses in

131
00:06:17,639 --> 00:06:24,360
their porn videos so you see images here

132
00:06:21,300 --> 00:06:27,270
of women like Natalie Portman or gal

133
00:06:24,360 --> 00:06:29,510
gadot or Emma Watson and Natalie Dormer

134
00:06:27,270 --> 00:06:31,159
who are just some of the many

135
00:06:29,510 --> 00:06:33,380
celebrities who have been subject to

136
00:06:31,160 --> 00:06:36,800
this in fact there are websites now

137
00:06:33,380 --> 00:06:40,040
where you can go and for a fee you can

138
00:06:36,800 --> 00:06:43,790
actually request videos with your

139
00:06:40,040 --> 00:06:45,580
favorite celebrities in them but of

140
00:06:43,790 --> 00:06:48,710
course that wasn't where things stopped

141
00:06:45,580 --> 00:06:50,690
and it wasn't too long after that point

142
00:06:48,710 --> 00:06:53,690
that people started to realize we could

143
00:06:50,690 --> 00:06:55,910
leverage this in politics and we could

144
00:06:53,690 --> 00:06:58,130
start to manipulate the political

145
00:06:55,910 --> 00:07:02,240
discourse in countries around the globe

146
00:06:58,130 --> 00:07:04,190
by making phony videos sure some of them

147
00:07:02,240 --> 00:07:07,250
are sad tires some are meant to be a

148
00:07:04,190 --> 00:07:10,310
little more damaging you see a few of

149
00:07:07,250 --> 00:07:13,490
them here another example you may be

150
00:07:10,310 --> 00:07:15,950
aware of from 2018 was a video that

151
00:07:13,490 --> 00:07:19,300
surfaced of Barack Obama giving an

152
00:07:15,950 --> 00:07:22,159
address from his office and saying some

153
00:07:19,300 --> 00:07:25,100
less than complimentary things about

154
00:07:22,160 --> 00:07:27,140
then president-elect Trump your problem

155
00:07:25,100 --> 00:07:29,150
was it wasn't Barack Obama saying those

156
00:07:27,140 --> 00:07:31,400
things it was actually comedian Jordan

157
00:07:29,150 --> 00:07:36,200
Peele who had created this video and had

158
00:07:31,400 --> 00:07:39,140
deep faked Barack Obama and so these are

159
00:07:36,200 --> 00:07:41,390
some of the things that have been talked

160
00:07:39,140 --> 00:07:44,750
about in the media have been talked

161
00:07:41,390 --> 00:07:48,500
about indeed amongst politicians about

162
00:07:44,750 --> 00:07:50,990
the threat of deep fake but deep fakes

163
00:07:48,500 --> 00:07:54,400
go further and the threats that they

164
00:07:50,990 --> 00:07:57,710
present are far more right wide-ranging

165
00:07:54,400 --> 00:07:59,929
one of the areas that we don't hear as

166
00:07:57,710 --> 00:08:01,520
much about is where deep fakes can be

167
00:07:59,930 --> 00:08:03,800
leveraged for social engineering a

168
00:08:01,520 --> 00:08:06,469
terrific example of this comes to us

169
00:08:03,800 --> 00:08:08,720
from the UK where the CEO of a large

170
00:08:06,470 --> 00:08:12,110
Energy Corporation was duped into

171
00:08:08,720 --> 00:08:15,500
transferring 200 million euros to

172
00:08:12,110 --> 00:08:18,410
attackers now how did they do it well

173
00:08:15,500 --> 00:08:21,700
they created deep fake audio of the

174
00:08:18,410 --> 00:08:24,860
president of the parent company

175
00:08:21,700 --> 00:08:27,770
instructing the CEO to make this wire

176
00:08:24,860 --> 00:08:29,240
transfer and the CEO fell for it in fact

177
00:08:27,770 --> 00:08:31,280
they came back a second time and tried

178
00:08:29,240 --> 00:08:32,690
to do it again thankfully the CEO

179
00:08:31,280 --> 00:08:34,579
learned his lesson and the second time

180
00:08:32,690 --> 00:08:37,130
that came around at least he picked up

181
00:08:34,580 --> 00:08:39,380
on it pretty quick and realized ok this

182
00:08:37,130 --> 00:08:41,900
is not the president that I'm talking to

183
00:08:39,380 --> 00:08:43,730
and this is abnormal behavior for him to

184
00:08:41,900 --> 00:08:44,840
be requesting

185
00:08:43,730 --> 00:08:46,670
but the fact of the matter is the

186
00:08:44,840 --> 00:08:52,280
attackers were successful and they made

187
00:08:46,670 --> 00:08:55,579
off with over 200 million euros we talk

188
00:08:52,280 --> 00:08:58,010
about pornography well there's also this

189
00:08:55,580 --> 00:08:59,870
idea of revenge porn and if you're not

190
00:08:58,010 --> 00:09:02,689
familiar with this term typically where

191
00:08:59,870 --> 00:09:07,550
this term is leveraged is when we talk

192
00:09:02,690 --> 00:09:10,790
about people who have shared nude photos

193
00:09:07,550 --> 00:09:12,530
selfies whatever with a partner or they

194
00:09:10,790 --> 00:09:15,170
below their partner to take such photos

195
00:09:12,530 --> 00:09:17,060
or video of themselves and then after

196
00:09:15,170 --> 00:09:20,300
the relationship ends for whatever

197
00:09:17,060 --> 00:09:22,699
reason that partner decides to get

198
00:09:20,300 --> 00:09:28,040
revenge on them and releases those video

199
00:09:22,700 --> 00:09:30,260
images to the web well now we have the

200
00:09:28,040 --> 00:09:32,990
case where that video or those still

201
00:09:30,260 --> 00:09:36,319
images don't even have to exist where

202
00:09:32,990 --> 00:09:38,600
potentially a disgruntled partner or

203
00:09:36,320 --> 00:09:41,360
ex-partner could create this type of

204
00:09:38,600 --> 00:09:45,500
media and release that to the Internet

205
00:09:41,360 --> 00:09:48,170
and while it's not real it could still

206
00:09:45,500 --> 00:09:50,840
be just as embarrassing just as damning

207
00:09:48,170 --> 00:09:54,550
or even worse because it could present

208
00:09:50,840 --> 00:09:56,900
scenarios that never actually occurred

209
00:09:54,550 --> 00:09:58,640
but what about the business world I

210
00:09:56,900 --> 00:10:00,860
mentioned that social engineering

211
00:09:58,640 --> 00:10:02,840
approach before what about some other

212
00:10:00,860 --> 00:10:05,540
threats against business what about

213
00:10:02,840 --> 00:10:08,810
using deep fakes to extort high-profile

214
00:10:05,540 --> 00:10:13,699
business leaders now I show the the

215
00:10:08,810 --> 00:10:17,780
example here okay Jeff Bezos has not

216
00:10:13,700 --> 00:10:19,190
denied the real nature of any of the

217
00:10:17,780 --> 00:10:23,510
images and videos that were used to

218
00:10:19,190 --> 00:10:26,540
extort him but do those videos do those

219
00:10:23,510 --> 00:10:29,240
images does that media have to be real

220
00:10:26,540 --> 00:10:32,170
in order to have potential threat to a

221
00:10:29,240 --> 00:10:34,750
high-ranking CEO

222
00:10:32,170 --> 00:10:36,490
it only has to be believed long enough

223
00:10:34,750 --> 00:10:39,850
for it to have a negative impact on that

224
00:10:36,490 --> 00:10:42,760
organization or on that CEO or on that

225
00:10:39,850 --> 00:10:45,100
high-profile business leader to have a

226
00:10:42,760 --> 00:10:49,389
damaging and lasting impact on their

227
00:10:45,100 --> 00:10:52,209
marriage this is a real threat this is

228
00:10:49,389 --> 00:10:53,889
something that we face today with

229
00:10:52,209 --> 00:10:55,449
high-profile business leaders around the

230
00:10:53,889 --> 00:10:58,540
globe we've all you may have already

231
00:10:55,449 --> 00:11:02,139
seen videos of Elon Musk's face being

232
00:10:58,540 --> 00:11:05,920
put on the body of a baby now yeah

233
00:11:02,139 --> 00:11:08,320
that's that's pretty innocuous but it

234
00:11:05,920 --> 00:11:11,199
wouldn't take really much additional

235
00:11:08,320 --> 00:11:14,070
effort to create more damning video of

236
00:11:11,199 --> 00:11:17,319
him in other compromising situations

237
00:11:14,070 --> 00:11:19,089
speaking of Elon Musk what about this

238
00:11:17,320 --> 00:11:21,430
concept I like to introduce called

239
00:11:19,089 --> 00:11:23,290
outsider trading so if you're familiar

240
00:11:21,430 --> 00:11:25,870
with insider trading it's when people

241
00:11:23,290 --> 00:11:28,360
with insider knowledge of the inner

242
00:11:25,870 --> 00:11:31,209
workings of an organization use that

243
00:11:28,360 --> 00:11:33,209
sensitive information to profit and to

244
00:11:31,209 --> 00:11:36,069
bolster their their stock portfolios

245
00:11:33,209 --> 00:11:37,869
they may know that there's bad news on

246
00:11:36,070 --> 00:11:40,630
the horizon and so they sell off their

247
00:11:37,870 --> 00:11:44,370
stock in advance or they know that an

248
00:11:40,630 --> 00:11:46,420
upcoming development is going to cause a

249
00:11:44,370 --> 00:11:49,630
significant stock increase and they

250
00:11:46,420 --> 00:11:52,959
might buy up that stock knowing that

251
00:11:49,630 --> 00:11:54,579
it's about to increase in price well

252
00:11:52,959 --> 00:11:58,089
consider this scenario since I have my

253
00:11:54,579 --> 00:12:00,160
my friend Elan up here at the moment I

254
00:11:58,089 --> 00:12:02,890
consider Tesla's getting ready to launch

255
00:12:00,160 --> 00:12:05,469
their next model call it the Model Q and

256
00:12:02,890 --> 00:12:07,180
the night before Elan is all set to go

257
00:12:05,470 --> 00:12:09,430
on stage and have his big launch and

258
00:12:07,180 --> 00:12:11,529
he's gonna you know smash windows with

259
00:12:09,430 --> 00:12:15,880
sledgehammers or whatever he chooses to

260
00:12:11,529 --> 00:12:18,880
do this time video surfaces of him in a

261
00:12:15,880 --> 00:12:21,339
meeting with stockholders sharing

262
00:12:18,880 --> 00:12:24,220
information about problems that exist

263
00:12:21,339 --> 00:12:25,660
with the line or you know something

264
00:12:24,220 --> 00:12:28,480
that's going to cause a delay in the

265
00:12:25,660 --> 00:12:30,130
launch or cause problems or delays of

266
00:12:28,480 --> 00:12:32,170
backlogs in and delivery of these

267
00:12:30,130 --> 00:12:33,880
vehicles well what's going to happen to

268
00:12:32,170 --> 00:12:36,149
that stock naturally it's going to

269
00:12:33,880 --> 00:12:36,149
plummet

270
00:12:36,840 --> 00:12:41,250
that's a deep fake video released by an

271
00:12:38,700 --> 00:12:44,100
attacker they could make use of this

272
00:12:41,250 --> 00:12:46,380
situation they could plan this situation

273
00:12:44,100 --> 00:12:48,510
short that stock buying it up while it's

274
00:12:46,380 --> 00:12:51,450
depressed and then when it recovers

275
00:12:48,510 --> 00:12:54,210
after news of the deep fake surfaces and

276
00:12:51,450 --> 00:12:57,270
the launch goes as expected they sell

277
00:12:54,210 --> 00:12:59,070
off those stocks this is a real threat

278
00:12:57,270 --> 00:13:04,829
that exists today that could easily be

279
00:12:59,070 --> 00:13:07,920
exploited by attackers so if I can

280
00:13:04,830 --> 00:13:09,990
manipulate a large organization like

281
00:13:07,920 --> 00:13:12,959
Tesla and and manipulate their stock

282
00:13:09,990 --> 00:13:15,870
prices such to my own benefit what about

283
00:13:12,960 --> 00:13:18,900
entire markets could I manipulate the

284
00:13:15,870 --> 00:13:20,040
entire automotive market with just a few

285
00:13:18,900 --> 00:13:23,220
well-placed

286
00:13:20,040 --> 00:13:25,980
deep fake videos and if I could

287
00:13:23,220 --> 00:13:29,990
manipulate a market what about the

288
00:13:25,980 --> 00:13:29,990
entire economy of a small nation

289
00:13:30,329 --> 00:13:37,329
so as I said before everything we know

290
00:13:34,450 --> 00:13:38,890
about the world around us comes from

291
00:13:37,329 --> 00:13:41,560
what we're able to perceive with our

292
00:13:38,890 --> 00:13:43,959
five senses

293
00:13:41,560 --> 00:13:48,670
but how do we define reality when we

294
00:13:43,959 --> 00:13:50,290
can't trust those five senses this is

295
00:13:48,670 --> 00:13:54,699
the paradigm of attack that deep fakes

296
00:13:50,290 --> 00:13:56,740
have opened for attackers now how do we

297
00:13:54,699 --> 00:14:01,569
create these deep base how our attackers

298
00:13:56,740 --> 00:14:04,180
creating such convincing video well I

299
00:14:01,569 --> 00:14:05,920
told you it all begins with neural

300
00:14:04,180 --> 00:14:08,258
networks deep learning neural networks

301
00:14:05,920 --> 00:14:10,839
that we call Gans Gans stands for

302
00:14:08,259 --> 00:14:12,699
generative adversarial network if you

303
00:14:10,839 --> 00:14:14,529
break that down the name it actually

304
00:14:12,699 --> 00:14:16,508
describes exactly what they do they're

305
00:14:14,529 --> 00:14:20,529
generative they're going to create

306
00:14:16,509 --> 00:14:22,870
something their adversarial in the sense

307
00:14:20,529 --> 00:14:25,269
that there are actually two neural

308
00:14:22,870 --> 00:14:26,740
networks that operate within again there

309
00:14:25,269 --> 00:14:28,720
is what we call the generator which is

310
00:14:26,740 --> 00:14:30,970
responsible for creating content and

311
00:14:28,720 --> 00:14:33,790
then there's the discriminator which is

312
00:14:30,970 --> 00:14:37,949
responsible for assessing that content

313
00:14:33,790 --> 00:14:37,949
as to how real it appears

314
00:14:38,070 --> 00:14:42,860
now we train both sides of the scan with

315
00:14:40,649 --> 00:14:47,550
a training set and this training set

316
00:14:42,860 --> 00:14:50,519
typically is a set of still images a

317
00:14:47,550 --> 00:14:52,529
large number often times but not always

318
00:14:50,519 --> 00:14:54,750
and we're seeing increasingly fewer

319
00:14:52,529 --> 00:14:58,709
number of still images needed in order

320
00:14:54,750 --> 00:15:00,720
to properly train these scans we then

321
00:14:58,709 --> 00:15:02,758
feed the generator the target media so

322
00:15:00,720 --> 00:15:05,250
the target media is the video we create

323
00:15:02,759 --> 00:15:09,420
that has an actor that we want to

324
00:15:05,250 --> 00:15:10,860
replace in that video with our subject

325
00:15:09,420 --> 00:15:12,389
and the generators going to take that

326
00:15:10,860 --> 00:15:14,910
video and frame by frame it's going to

327
00:15:12,389 --> 00:15:17,519
attempt to replace that actors face with

328
00:15:14,910 --> 00:15:19,050
that of our subject the discriminator

329
00:15:17,519 --> 00:15:21,630
then takes a look at those images and

330
00:15:19,050 --> 00:15:24,240
says yeah either these are a very good

331
00:15:21,630 --> 00:15:26,550
representation or no I can detect that

332
00:15:24,240 --> 00:15:28,620
that's fake when the discriminator

333
00:15:26,550 --> 00:15:31,170
detects that they're fake it sends it

334
00:15:28,620 --> 00:15:32,730
back to the generator and it updates the

335
00:15:31,170 --> 00:15:35,399
generator and we're gonna see more how

336
00:15:32,730 --> 00:15:38,310
that works in just a moment the first

337
00:15:35,399 --> 00:15:41,880
step in creating a deep fake however is

338
00:15:38,310 --> 00:15:43,829
that that training that I mentioned and

339
00:15:41,880 --> 00:15:47,189
in order to do the training we first

340
00:15:43,829 --> 00:15:48,899
need that set of training images and to

341
00:15:47,190 --> 00:15:51,209
get those training images I have to

342
00:15:48,899 --> 00:15:54,269
normalize them through a process we call

343
00:15:51,209 --> 00:15:57,479
extraction and the extraction is

344
00:15:54,269 --> 00:15:59,579
literally taking each image and they

345
00:15:57,480 --> 00:16:01,889
could be still images like this pulled

346
00:15:59,579 --> 00:16:05,310
from a video they could be still images

347
00:16:01,889 --> 00:16:08,639
found on the web and using facial

348
00:16:05,310 --> 00:16:10,859
detection algorithms it detects and maps

349
00:16:08,639 --> 00:16:12,630
out the face so you see 68 points of

350
00:16:10,860 --> 00:16:16,260
facial recognition being mapped out here

351
00:16:12,630 --> 00:16:20,310
those landmarks are studied by the GAM

352
00:16:16,260 --> 00:16:23,760
and you also see the green box which is

353
00:16:20,310 --> 00:16:26,760
the alignment that is this particular

354
00:16:23,760 --> 00:16:29,819
algorithm aligning the face determining

355
00:16:26,760 --> 00:16:33,329
what direction the face is facing if you

356
00:16:29,819 --> 00:16:35,069
will how its oriented to the screen but

357
00:16:33,329 --> 00:16:36,989
it's not enough just to identify it we

358
00:16:35,069 --> 00:16:39,899
then have to normalize it in terms of

359
00:16:36,990 --> 00:16:41,819
size and resolution so what we see is

360
00:16:39,899 --> 00:16:47,250
that these algorithms will then take

361
00:16:41,819 --> 00:16:49,529
that image take a fixed square around

362
00:16:47,250 --> 00:16:51,370
that face region that it's recognized

363
00:16:49,529 --> 00:16:55,240
and reduce that

364
00:16:51,370 --> 00:16:57,070
to a specific resolution or in some

365
00:16:55,240 --> 00:17:00,430
cases if it has to would increase it in

366
00:16:57,070 --> 00:17:03,490
this case you see 254 by 254 pixels and

367
00:17:00,430 --> 00:17:04,899
that is the standard training set image

368
00:17:03,490 --> 00:17:06,730
that we're going to work from so the

369
00:17:04,900 --> 00:17:10,180
entire training is based off of that

370
00:17:06,730 --> 00:17:11,740
standardized image size and shape and

371
00:17:10,180 --> 00:17:14,200
we'll see a little bit later why that

372
00:17:11,740 --> 00:17:17,099
becomes important but so now when we go

373
00:17:14,200 --> 00:17:19,990
into training what we're going to do is

374
00:17:17,099 --> 00:17:22,089
we are ultimately feeding those images

375
00:17:19,990 --> 00:17:24,460
to a two part system within the

376
00:17:22,089 --> 00:17:27,540
generator the first part is this encoder

377
00:17:24,460 --> 00:17:31,270
and what the encoder attempts to do is

378
00:17:27,540 --> 00:17:33,610
take those images and represent them in

379
00:17:31,270 --> 00:17:37,389
what we call just a model and that model

380
00:17:33,610 --> 00:17:39,820
is nothing more than a a numeric way to

381
00:17:37,390 --> 00:17:41,590
represent all the aspects of that face

382
00:17:39,820 --> 00:17:44,560
that we need to capture in order to

383
00:17:41,590 --> 00:17:46,780
recreate a face so the encoder writes

384
00:17:44,560 --> 00:17:48,850
that to our model it then passes it to a

385
00:17:46,780 --> 00:17:50,230
decoder and what the decoder is going to

386
00:17:48,850 --> 00:17:52,659
attempt to do is the decoder is just

387
00:17:50,230 --> 00:17:54,970
going to attempt to recreate that face

388
00:17:52,660 --> 00:17:57,930
from no information other one than

389
00:17:54,970 --> 00:18:02,560
what's include encompassed in that model

390
00:17:57,930 --> 00:18:04,300
so it creates this new image that's an

391
00:18:02,560 --> 00:18:05,679
attempt to recreate the original image

392
00:18:04,300 --> 00:18:08,110
and then it passes it to the

393
00:18:05,680 --> 00:18:11,290
discriminator the discriminator looks at

394
00:18:08,110 --> 00:18:13,990
that and says how good or bad a job it's

395
00:18:11,290 --> 00:18:16,840
done in recreating that face and it

396
00:18:13,990 --> 00:18:19,330
expresses that value in terms of what we

397
00:18:16,840 --> 00:18:22,060
call loss so loss is really just how

398
00:18:19,330 --> 00:18:25,570
well did the decoder do in creating that

399
00:18:22,060 --> 00:18:28,000
image it then updates the model that the

400
00:18:25,570 --> 00:18:29,409
encoder is using it updates what we call

401
00:18:28,000 --> 00:18:30,760
the weights and I'm not going to get

402
00:18:29,410 --> 00:18:32,920
into all the inner workings of how

403
00:18:30,760 --> 00:18:35,260
neural network models work but just know

404
00:18:32,920 --> 00:18:38,530
that the weights are how the model

405
00:18:35,260 --> 00:18:40,120
adjusts itself and continues to get

406
00:18:38,530 --> 00:18:43,060
better and better so the discriminator

407
00:18:40,120 --> 00:18:45,459
updates those weights constantly making

408
00:18:43,060 --> 00:18:48,129
the encoder better and better and so

409
00:18:45,460 --> 00:18:50,950
this process runs in what we call the

410
00:18:48,130 --> 00:18:54,490
trainee and so in the training now this

411
00:18:50,950 --> 00:18:57,880
is a process that can take 24-48 even up

412
00:18:54,490 --> 00:19:01,090
to a 22 24 48 hours even up to a week

413
00:18:57,880 --> 00:19:03,400
and what we're doing in that process was

414
00:19:01,090 --> 00:19:04,840
were actually training two sets of

415
00:19:03,400 --> 00:19:07,419
images the first

416
00:19:04,840 --> 00:19:11,830
is our target the face that we want to

417
00:19:07,419 --> 00:19:14,289
replace in the video the second is the

418
00:19:11,830 --> 00:19:16,418
subject or the person whose face we want

419
00:19:14,289 --> 00:19:17,950
to insert into the video so here you're

420
00:19:16,419 --> 00:19:20,200
seeing images from a project that I

421
00:19:17,950 --> 00:19:22,559
worked on where I was simply replacing

422
00:19:20,200 --> 00:19:25,210
myself with Alyssa Milano

423
00:19:22,559 --> 00:19:26,950
now I take those two sets of training

424
00:19:25,210 --> 00:19:30,220
images and I actually pass them to the

425
00:19:26,950 --> 00:19:33,330
same encoder so now that encoders trying

426
00:19:30,220 --> 00:19:35,679
to build a model that not only

427
00:19:33,330 --> 00:19:39,519
mathematically represents my face but

428
00:19:35,679 --> 00:19:41,919
also represents Alyssa Milano's face so

429
00:19:39,519 --> 00:19:44,200
it's it's more generalized and it's able

430
00:19:41,919 --> 00:19:47,499
to represent the aspects of either of

431
00:19:44,200 --> 00:19:50,169
our faces then that model it it creates

432
00:19:47,499 --> 00:19:51,820
is used by two decoders decoder a is

433
00:19:50,169 --> 00:19:53,440
going to try to recreate my face decoder

434
00:19:51,820 --> 00:19:56,259
B is going to try to recreate Alyssa

435
00:19:53,440 --> 00:19:58,029
Milano's face and in that process we're

436
00:19:56,259 --> 00:20:00,789
constantly improving that model and

437
00:19:58,029 --> 00:20:02,919
generalized generalizing it to recognize

438
00:20:00,789 --> 00:20:06,908
both our faces and to be able to

439
00:20:02,919 --> 00:20:08,830
recreate them reliably when that

440
00:20:06,909 --> 00:20:10,389
training is done we now move into

441
00:20:08,830 --> 00:20:13,539
conversion this is where we actually

442
00:20:10,389 --> 00:20:15,729
create the video frame by frame I'm

443
00:20:13,539 --> 00:20:18,789
going to take that video or those images

444
00:20:15,730 --> 00:20:20,499
of me and I'm going to pass them to the

445
00:20:18,789 --> 00:20:22,210
encoder so the encoder is now going to

446
00:20:20,499 --> 00:20:25,360
take those images represent them in the

447
00:20:22,210 --> 00:20:28,419
model but now we're going to pass them

448
00:20:25,360 --> 00:20:30,189
to decoder be so decoder B just knows it

449
00:20:28,419 --> 00:20:31,809
has this generalized model and it's got

450
00:20:30,190 --> 00:20:34,210
to try to create Alyssa Milano from that

451
00:20:31,809 --> 00:20:36,879
and that's exactly what it does and the

452
00:20:34,210 --> 00:20:40,539
end result is my head with Alyssa

453
00:20:36,879 --> 00:20:44,230
Milano's face this is the traditional

454
00:20:40,539 --> 00:20:47,320
process for creating deep fakes now 48

455
00:20:44,230 --> 00:20:52,559
hours 72 hours a week to do training may

456
00:20:47,320 --> 00:20:55,539
sound a little onerous it can be and

457
00:20:52,559 --> 00:20:56,710
indeed it takes some powerful GPUs to be

458
00:20:55,539 --> 00:21:00,039
able to do that if you're trying to do

459
00:20:56,710 --> 00:21:01,809
it on a CPU can take even longer with

460
00:21:00,039 --> 00:21:03,580
our apps out there that help with us the

461
00:21:01,809 --> 00:21:05,200
one that I've been using and is most

462
00:21:03,580 --> 00:21:08,918
commonly seen these days is one called

463
00:21:05,200 --> 00:21:10,809
face swap it it's a GUI interface it's

464
00:21:08,919 --> 00:21:13,809
super easy to use its built-in cut and

465
00:21:10,809 --> 00:21:16,000
Python makes the whole process a lot

466
00:21:13,809 --> 00:21:17,590
simpler

467
00:21:16,000 --> 00:21:21,330
but it can be made even simpler still

468
00:21:17,590 --> 00:21:23,649
with this website called deep fakes web

469
00:21:21,330 --> 00:21:26,679
deep fake swipe you just upload some

470
00:21:23,650 --> 00:21:29,080
training images a video a training video

471
00:21:26,680 --> 00:21:30,550
as well and it will generate a video for

472
00:21:29,080 --> 00:21:32,230
you now I can tell you I've tried that I

473
00:21:30,550 --> 00:21:34,000
paid for it it is there is a cost

474
00:21:32,230 --> 00:21:36,670
associated with it the results weren't

475
00:21:34,000 --> 00:21:40,480
great I gave them very good training

476
00:21:36,670 --> 00:21:42,070
material and it took them about I think

477
00:21:40,480 --> 00:21:45,550
six or eight hours to create the video

478
00:21:42,070 --> 00:21:47,560
back and it wasn't very convincing but

479
00:21:45,550 --> 00:21:48,820
it's there and you can create some if

480
00:21:47,560 --> 00:21:50,350
you're not looking for something to try

481
00:21:48,820 --> 00:21:52,570
to fool somebody if you're looking more

482
00:21:50,350 --> 00:21:58,090
to do something satirical it's great for

483
00:21:52,570 --> 00:22:00,280
that you know another application that

484
00:21:58,090 --> 00:22:01,949
was built a while back called fake app

485
00:22:00,280 --> 00:22:04,389
is the the blue icon here

486
00:22:01,950 --> 00:22:06,850
that one's kind of disappeared from the

487
00:22:04,390 --> 00:22:08,980
market you can still find github repos

488
00:22:06,850 --> 00:22:10,090
that claim to have the original source

489
00:22:08,980 --> 00:22:11,650
code although I wouldn't trust them

490
00:22:10,090 --> 00:22:14,530
because most have been found to contain

491
00:22:11,650 --> 00:22:16,090
different forms of malware and other

492
00:22:14,530 --> 00:22:17,620
nastiness you probably don't want to

493
00:22:16,090 --> 00:22:20,379
mess with so I really wouldn't trust

494
00:22:17,620 --> 00:22:22,840
that one the final one I mentioned here

495
00:22:20,380 --> 00:22:25,780
is this app that was released last year

496
00:22:22,840 --> 00:22:27,850
called deep nude deep nudes whole

497
00:22:25,780 --> 00:22:31,180
purpose was to take still images of

498
00:22:27,850 --> 00:22:35,250
women and supposedly show you what they

499
00:22:31,180 --> 00:22:37,750
looked like undressed now the reality is

500
00:22:35,250 --> 00:22:39,730
those images it was creating were just

501
00:22:37,750 --> 00:22:42,970
deep fakes where they took the face from

502
00:22:39,730 --> 00:22:45,100
the image you provided and they deep

503
00:22:42,970 --> 00:22:49,270
faked it on top of the picture of a

504
00:22:45,100 --> 00:22:51,760
naked woman that thankfully that app

505
00:22:49,270 --> 00:22:53,290
only lasted a week as you can imagine

506
00:22:51,760 --> 00:22:56,100
there was a lot of backlash to something

507
00:22:53,290 --> 00:22:58,540
like that and the author pulled it from

508
00:22:56,100 --> 00:22:59,919
availability very quickly some people

509
00:22:58,540 --> 00:23:02,200
again claimed to still have the original

510
00:22:59,920 --> 00:23:04,870
apks for it I would be really careful if

511
00:23:02,200 --> 00:23:06,700
you'd go pursuing those because again

512
00:23:04,870 --> 00:23:07,750
they're typically filled with malware

513
00:23:06,700 --> 00:23:10,300
and other nasty things you probably

514
00:23:07,750 --> 00:23:12,010
don't want to put on your phone but

515
00:23:10,300 --> 00:23:13,510
defect technology is getting better some

516
00:23:12,010 --> 00:23:15,040
of you may have seen a recent article

517
00:23:13,510 --> 00:23:18,490
where people are talking about how

518
00:23:15,040 --> 00:23:22,060
somebody created basically real-time

519
00:23:18,490 --> 00:23:24,160
deep fake of Elon Musk within their zoom

520
00:23:22,060 --> 00:23:26,820
session and indeed there is a zoom

521
00:23:24,160 --> 00:23:29,650
plugin now that can create almost

522
00:23:26,820 --> 00:23:32,800
real-time deep fake images

523
00:23:29,650 --> 00:23:34,570
you can replace your face in your zoo

524
00:23:32,800 --> 00:23:36,669
meeting with pretty much anybody you

525
00:23:34,570 --> 00:23:39,460
want how is it doing this

526
00:23:36,670 --> 00:23:41,140
well it's using a different approach so

527
00:23:39,460 --> 00:23:42,580
instead of mapping out all these

528
00:23:41,140 --> 00:23:46,240
landmarks and doing all this training

529
00:23:42,580 --> 00:23:48,639
and trying to create a model specific to

530
00:23:46,240 --> 00:23:51,070
a particular face it's taken that idea

531
00:23:48,640 --> 00:23:53,830
of a generalized model up another level

532
00:23:51,070 --> 00:23:55,629
and it's really tried to create this

533
00:23:53,830 --> 00:23:59,530
very generalized model that you can see

534
00:23:55,630 --> 00:24:01,750
third from the left here of just how to

535
00:23:59,530 --> 00:24:04,930
detect a face in general and create a

536
00:24:01,750 --> 00:24:07,450
deep fake from it now the results right

537
00:24:04,930 --> 00:24:10,720
now not terribly convincing there's a

538
00:24:07,450 --> 00:24:13,120
lot of visual artifacts that you can

539
00:24:10,720 --> 00:24:15,670
tell it was deep faked lots of

540
00:24:13,120 --> 00:24:18,699
distortions and things but it is

541
00:24:15,670 --> 00:24:23,850
bringing us one step closer to the point

542
00:24:18,700 --> 00:24:26,520
where we can create real time deep fakes

543
00:24:23,850 --> 00:24:28,260
so

544
00:24:26,520 --> 00:24:30,629
how do we even tell what's real and fake

545
00:24:28,260 --> 00:24:32,220
anymore well researchers have been doing

546
00:24:30,630 --> 00:24:35,010
a lot of work on how do we detect deep

547
00:24:32,220 --> 00:24:37,170
face and I'm going to share with you

548
00:24:35,010 --> 00:24:41,820
just some of the methodologies that

549
00:24:37,170 --> 00:24:45,929
they've been using the first that was

550
00:24:41,820 --> 00:24:49,770
looked at quite a bit were just very

551
00:24:45,929 --> 00:24:52,170
obvious visual artifacts that were part

552
00:24:49,770 --> 00:24:53,670
of a deep fake so remember I mentioned

553
00:24:52,170 --> 00:24:55,860
that whole idea of using these

554
00:24:53,670 --> 00:24:59,070
normalized images that are sized to have

555
00:24:55,860 --> 00:25:00,809
specific size and shape early on gans

556
00:24:59,070 --> 00:25:03,000
weren't really good with applying those

557
00:25:00,809 --> 00:25:05,910
images when the face shapes didn't match

558
00:25:03,000 --> 00:25:12,240
and as you can see here that red arrow

559
00:25:05,910 --> 00:25:14,820
on the right hand side points to some of

560
00:25:12,240 --> 00:25:17,640
that visual distortion that occurs near

561
00:25:14,820 --> 00:25:20,129
the eyes when Nicolas Cage's face is put

562
00:25:17,640 --> 00:25:22,260
on top of Elon Musk's head so this is a

563
00:25:20,130 --> 00:25:24,179
case where just simply the Gann and some

564
00:25:22,260 --> 00:25:26,700
of the image processing behind the

565
00:25:24,179 --> 00:25:29,010
scenes that were used just made some

566
00:25:26,700 --> 00:25:31,740
errors and they resulted in visual

567
00:25:29,010 --> 00:25:35,100
distortions and these artifacts were

568
00:25:31,740 --> 00:25:37,470
easily detected by ganz even of course

569
00:25:35,100 --> 00:25:40,709
your eyes could detect this sort of

570
00:25:37,470 --> 00:25:42,660
thing but it didn't take long ganz have

571
00:25:40,710 --> 00:25:45,720
gotten better and better their use of

572
00:25:42,660 --> 00:25:47,940
different imaging techniques in order to

573
00:25:45,720 --> 00:25:51,750
place faces and them ask them off and to

574
00:25:47,940 --> 00:25:54,450
to blur transitions so that things fit

575
00:25:51,750 --> 00:25:56,790
better have gotten considerably better

576
00:25:54,450 --> 00:26:01,179
over time and in a very short amount of

577
00:25:56,790 --> 00:26:04,599
time I might add so researchers moved on

578
00:26:01,179 --> 00:26:07,690
in 2018 in June of 2018 researchers at

579
00:26:04,599 --> 00:26:11,070
University at Albany State University of

580
00:26:07,690 --> 00:26:13,179
New York released a research paper

581
00:26:11,070 --> 00:26:16,229
discussing how they had done studies

582
00:26:13,179 --> 00:26:18,700
where they found that blinking was not

583
00:26:16,229 --> 00:26:22,539
appropriately replicated in deep fake

584
00:26:18,700 --> 00:26:24,070
videos and so by analyzing the rate at

585
00:26:22,539 --> 00:26:26,589
which people blanked the number of

586
00:26:24,070 --> 00:26:30,009
blinks per minute they could accurately

587
00:26:26,589 --> 00:26:32,469
identify deep fakes and there are a lot

588
00:26:30,009 --> 00:26:35,440
of reasons for this and in part because

589
00:26:32,469 --> 00:26:37,509
training sets typically didn't include

590
00:26:35,440 --> 00:26:43,029
pictures of people with their eyes

591
00:26:37,509 --> 00:26:45,219
closed but within two months of the

592
00:26:43,029 --> 00:26:47,379
release of that paper we started seeing

593
00:26:45,219 --> 00:26:51,009
deep fakes coming out where I blinking

594
00:26:47,379 --> 00:26:54,218
was being addressed more realistically

595
00:26:51,009 --> 00:26:56,379
within the videos research continue to

596
00:26:54,219 --> 00:27:01,149
look at it they're now studying the rate

597
00:26:56,379 --> 00:27:03,759
of blink the so both the velocity of how

598
00:27:01,149 --> 00:27:05,649
fast the eyelids move and the direction

599
00:27:03,759 --> 00:27:09,580
in which the eyelids move things like

600
00:27:05,649 --> 00:27:11,559
that to still detect but of course every

601
00:27:09,580 --> 00:27:16,408
time our detection techniques get better

602
00:27:11,559 --> 00:27:16,408
so do the gans that produce these images

603
00:27:17,849 --> 00:27:22,089
another issue that comes up and this

604
00:27:20,259 --> 00:27:26,039
again is related to those standardized

605
00:27:22,089 --> 00:27:30,129
imaging is this idea of warping and

606
00:27:26,039 --> 00:27:31,960
again those same researchers at SU NY

607
00:27:30,129 --> 00:27:35,199
released another paper this time in May

608
00:27:31,960 --> 00:27:37,769
of 2019 where they started looking at

609
00:27:35,200 --> 00:27:40,269
the problem of warping as it pertains to

610
00:27:37,769 --> 00:27:45,129
physical facial characteristics as well

611
00:27:40,269 --> 00:27:47,919
as the issues of resolution so remember

612
00:27:45,129 --> 00:27:53,738
I talked about having you know images

613
00:27:47,919 --> 00:27:56,979
that are 256 pixels square so in a 1080p

614
00:27:53,739 --> 00:27:58,749
image like this it works well if the

615
00:27:56,979 --> 00:28:00,580
subject is far away so we see Sharon

616
00:27:58,749 --> 00:28:02,169
Stone here with deeps again Steve

617
00:28:00,580 --> 00:28:03,789
Buscemi's face I don't know why he's so

618
00:28:02,169 --> 00:28:07,089
popular to be inserted into these videos

619
00:28:03,789 --> 00:28:10,419
but he is and from far away it looks

620
00:28:07,089 --> 00:28:12,908
quite realistic but later in this same

621
00:28:10,419 --> 00:28:14,950
scene when the camera zooms in on her

622
00:28:12,909 --> 00:28:17,470
face and suddenly

623
00:28:14,950 --> 00:28:20,139
that Gann has to apply a small image to

624
00:28:17,470 --> 00:28:22,299
a much larger region we see the issues

625
00:28:20,139 --> 00:28:24,610
you can see the difference in resolution

626
00:28:22,299 --> 00:28:27,519
between the facial region and other

627
00:28:24,610 --> 00:28:31,299
areas of this frame her hair her

628
00:28:27,519 --> 00:28:33,929
shoulders her blouse you also see if you

629
00:28:31,299 --> 00:28:37,240
look at the left cheek some very obvious

630
00:28:33,929 --> 00:28:39,820
distortion in the shadows and the shape

631
00:28:37,240 --> 00:28:43,149
of that cheek these are things that

632
00:28:39,820 --> 00:28:45,908
again gans are very easily able to

633
00:28:43,149 --> 00:28:49,719
detect and so researchers have been able

634
00:28:45,909 --> 00:28:53,019
to do this with fair accuracy but again

635
00:28:49,720 --> 00:28:55,539
as these models improve and they use

636
00:28:53,019 --> 00:28:59,309
larger and larger training sets I've

637
00:28:55,539 --> 00:29:03,639
seen training plugins now that go up to

638
00:28:59,309 --> 00:29:05,918
512 pixels by 512 pixels if you think

639
00:29:03,639 --> 00:29:10,449
about that in terms of an HD frame set

640
00:29:05,919 --> 00:29:13,929
the 1920 by 1080 that's that's a

641
00:29:10,450 --> 00:29:16,059
considerable amount of sizes for a

642
00:29:13,929 --> 00:29:19,570
facial region if we're talking 512

643
00:29:16,059 --> 00:29:22,990
pixels so we're going to continue to see

644
00:29:19,570 --> 00:29:24,820
that get better and better researchers

645
00:29:22,990 --> 00:29:26,409
know this so they've continued looking

646
00:29:24,820 --> 00:29:29,918
at things they're now looking at this

647
00:29:26,409 --> 00:29:32,380
idea of behavioral analytics and in this

648
00:29:29,919 --> 00:29:35,529
case they're not looking for visual

649
00:29:32,380 --> 00:29:37,510
technical issues or artifacts instead

650
00:29:35,529 --> 00:29:40,990
they're actually looking at the facial

651
00:29:37,510 --> 00:29:43,769
expressions and different facial

652
00:29:40,990 --> 00:29:46,929
characteristics of the speaker in

653
00:29:43,769 --> 00:29:50,169
context of the the content that's being

654
00:29:46,929 --> 00:29:53,620
delivered so researchers combined at

655
00:29:50,169 --> 00:29:58,000
Berkeley and USC release this research

656
00:29:53,620 --> 00:30:00,939
in the latter half of 2019 and if you

657
00:29:58,000 --> 00:30:02,679
look what they're taking a look at is

658
00:30:00,940 --> 00:30:05,500
this first row of pictures of Barack

659
00:30:02,679 --> 00:30:08,019
Obama still images from a talk that he

660
00:30:05,500 --> 00:30:10,450
gave this was a case where he was

661
00:30:08,019 --> 00:30:12,580
delivering a very gentle and caring

662
00:30:10,450 --> 00:30:15,940
message he was trying to appear very

663
00:30:12,580 --> 00:30:17,860
empathetic and as a result you see his

664
00:30:15,940 --> 00:30:20,380
eyebrows are raised his eyes are very

665
00:30:17,860 --> 00:30:25,029
open he has a very soft overall

666
00:30:20,380 --> 00:30:28,059
appearance he seems very caring the next

667
00:30:25,029 --> 00:30:28,870
row down however was Barack Obama

668
00:30:28,059 --> 00:30:32,980
delivering

669
00:30:28,870 --> 00:30:35,649
a stern warning to North Korea and there

670
00:30:32,980 --> 00:30:39,090
you see his eyebrows furrow a lot his

671
00:30:35,650 --> 00:30:42,010
eyes are more focused and angry looking

672
00:30:39,090 --> 00:30:44,350
over all his face you see more of the

673
00:30:42,010 --> 00:30:48,000
lines around his mouth because of the

674
00:30:44,350 --> 00:30:49,689
serious message that he's delivering

675
00:30:48,000 --> 00:30:52,590
initially when they released this

676
00:30:49,690 --> 00:30:56,440
researcher this research the researchers

677
00:30:52,590 --> 00:30:59,800
reported a 95 percent accuracy rate they

678
00:30:56,440 --> 00:31:02,140
expect that to be 99 percent accurate by

679
00:30:59,800 --> 00:31:05,470
the time the political season rolls

680
00:31:02,140 --> 00:31:08,440
around this year in the US so that's

681
00:31:05,470 --> 00:31:11,320
great when we're talking high profile

682
00:31:08,440 --> 00:31:14,860
individuals but what about somebody for

683
00:31:11,320 --> 00:31:18,159
whom we can't build that big behavioral

684
00:31:14,860 --> 00:31:20,350
analytics model for because there's just

685
00:31:18,160 --> 00:31:24,190
simply not that much material it doesn't

686
00:31:20,350 --> 00:31:25,600
work so some other researchers at

687
00:31:24,190 --> 00:31:27,309
Cornell University are looking at how

688
00:31:25,600 --> 00:31:29,590
can we prevent deep fakes from being

689
00:31:27,309 --> 00:31:32,139
created at all and they've leveraged

690
00:31:29,590 --> 00:31:35,379
this idea of adversarial perturbations

691
00:31:32,140 --> 00:31:38,140
and what this is is it simply noise

692
00:31:35,380 --> 00:31:40,150
that's visually in detectable to the

693
00:31:38,140 --> 00:31:44,830
human eye that they insert into images

694
00:31:40,150 --> 00:31:47,470
that actually can can wreak havoc on

695
00:31:44,830 --> 00:31:50,889
those facial recognition algorithms that

696
00:31:47,470 --> 00:31:52,630
deep fake generation relies on so the

697
00:31:50,890 --> 00:31:54,580
first role you see images that are

698
00:31:52,630 --> 00:31:57,700
untreated and you see from the green box

699
00:31:54,580 --> 00:32:01,090
that the facial recognition is easily

700
00:31:57,700 --> 00:32:02,860
able to detect the faces here in the

701
00:32:01,090 --> 00:32:06,120
second role you see what happens after

702
00:32:02,860 --> 00:32:08,830
they insert that noise suddenly there's

703
00:32:06,120 --> 00:32:10,209
numerous faces being detected and none

704
00:32:08,830 --> 00:32:12,129
of them are actually accurate to the

705
00:32:10,210 --> 00:32:13,690
face that appears in those frames and

706
00:32:12,130 --> 00:32:15,400
then of course that bottom row is you

707
00:32:13,690 --> 00:32:20,679
can see that's the actual noise that was

708
00:32:15,400 --> 00:32:23,020
inserted into each of these images now

709
00:32:20,679 --> 00:32:25,660
this is promising technology but again

710
00:32:23,020 --> 00:32:28,690
it's not realistic to think that we can

711
00:32:25,660 --> 00:32:30,580
go out there and for every person in the

712
00:32:28,690 --> 00:32:33,070
world take their images that are on the

713
00:32:30,580 --> 00:32:36,040
internet and replace them with images

714
00:32:33,070 --> 00:32:37,629
that are so treated this is long term

715
00:32:36,040 --> 00:32:40,000
maybe it's something we can do at the

716
00:32:37,630 --> 00:32:41,530
camera level but it's not realistic to

717
00:32:40,000 --> 00:32:42,730
think we're going to get there anytime

718
00:32:41,530 --> 00:32:44,740
soon

719
00:32:42,730 --> 00:32:46,929
and indeed there's already research

720
00:32:44,740 --> 00:32:49,570
being done into how to improve those

721
00:32:46,929 --> 00:32:52,780
facial recognition algorithms to get

722
00:32:49,570 --> 00:32:54,760
around this so it's great that we're

723
00:32:52,780 --> 00:32:56,290
focusing our research on all these

724
00:32:54,760 --> 00:32:59,140
technological innovations that can

725
00:32:56,290 --> 00:33:01,360
detect deep fakes but the fact of the

726
00:32:59,140 --> 00:33:03,850
matter is deep fakes are not a

727
00:33:01,360 --> 00:33:06,668
technological problem at all deep fakes

728
00:33:03,850 --> 00:33:08,980
are misinformation and the reality my

729
00:33:06,669 --> 00:33:12,760
friends is that misinformation is a

730
00:33:08,980 --> 00:33:14,350
human problem misinformation is a human

731
00:33:12,760 --> 00:33:19,120
problem we've been dealing with for

732
00:33:14,350 --> 00:33:23,139
decades for centuries even in human

733
00:33:19,120 --> 00:33:25,090
problems require human solutions how do

734
00:33:23,140 --> 00:33:30,090
we go about addressing misinformation

735
00:33:25,090 --> 00:33:33,399
that's the key to combating deep fakes

736
00:33:30,090 --> 00:33:35,740
the problems with misinformation if you

737
00:33:33,400 --> 00:33:40,650
followed misinformation in terms of

738
00:33:35,740 --> 00:33:44,380
politics or in terms of yo cold war-era

739
00:33:40,650 --> 00:33:47,200
attempts at propaganda the biggest issue

740
00:33:44,380 --> 00:33:49,929
with misinformation is that it tends to

741
00:33:47,200 --> 00:33:50,650
be very sticky and what do I mean by

742
00:33:49,929 --> 00:33:54,940
sticky

743
00:33:50,650 --> 00:33:57,190
well misinformation is designed to play

744
00:33:54,940 --> 00:34:01,240
off of our existing thoughts beliefs and

745
00:33:57,190 --> 00:34:04,090
perceptions it uses our current

746
00:34:01,240 --> 00:34:08,790
prejudices our current perception of the

747
00:34:04,090 --> 00:34:11,619
world to tell a story that we're already

748
00:34:08,790 --> 00:34:15,219
happy to believe we almost want to

749
00:34:11,619 --> 00:34:17,950
believe it and for that reason when we

750
00:34:15,219 --> 00:34:20,799
perceive that misinformation our minds

751
00:34:17,949 --> 00:34:23,649
do this incredible thing they build this

752
00:34:20,800 --> 00:34:25,179
logic map and they insert that

753
00:34:23,649 --> 00:34:26,799
misinformation into that logic map

754
00:34:25,179 --> 00:34:30,460
because it just matches up to the things

755
00:34:26,800 --> 00:34:32,679
we already know and so it just fills a

756
00:34:30,460 --> 00:34:37,929
point in this logic map of how we get

757
00:34:32,679 --> 00:34:41,649
from evidence a to conclusion B and so

758
00:34:37,929 --> 00:34:43,210
it's embedded it fills those gaps it

759
00:34:41,649 --> 00:34:45,279
gives us that evidence to support

760
00:34:43,210 --> 00:34:46,870
conclusions that we already wanted to

761
00:34:45,280 --> 00:34:49,810
make

762
00:34:46,870 --> 00:34:53,370
as a result it is exceptionally

763
00:34:49,810 --> 00:34:56,310
difficult to remove that information

764
00:34:53,370 --> 00:34:58,990
once it's there in somebody's mind and

765
00:34:56,310 --> 00:35:00,310
this is the struggle of propaganda this

766
00:34:58,990 --> 00:35:02,410
is the struggle struggle of

767
00:35:00,310 --> 00:35:04,420
misinformation this is the struggle when

768
00:35:02,410 --> 00:35:07,120
we try to undo the effects of

769
00:35:04,420 --> 00:35:10,090
brainwashing which when we talk about

770
00:35:07,120 --> 00:35:14,310
misinformation yeah that's not an

771
00:35:10,090 --> 00:35:16,240
exaggeration it does go to that level so

772
00:35:14,310 --> 00:35:18,870
what do we do to debunk this

773
00:35:16,240 --> 00:35:18,870
misinformation

774
00:35:19,900 --> 00:35:24,099
for starters we need to put the

775
00:35:22,839 --> 00:35:27,640
awareness out there that this

776
00:35:24,099 --> 00:35:30,119
misinformation exists at a macro level

777
00:35:27,640 --> 00:35:34,089
it's just awareness that deep fakes are

778
00:35:30,119 --> 00:35:36,160
thing and we see the media doing that

779
00:35:34,089 --> 00:35:37,900
today I'm giving this talk today April

780
00:35:36,160 --> 00:35:39,609
Wright is another person who gives us a

781
00:35:37,900 --> 00:35:41,890
talk about a lot of the threats around

782
00:35:39,609 --> 00:35:45,549
deep fix it's getting attention from

783
00:35:41,890 --> 00:35:49,420
researchers we see researchers doing all

784
00:35:45,549 --> 00:35:53,440
this work to produce different detection

785
00:35:49,420 --> 00:35:56,259
capabilities we see social media outlets

786
00:35:53,440 --> 00:35:58,420
like Facebook working with Microsoft and

787
00:35:56,259 --> 00:36:00,390
Amazon to create million-dollar

788
00:35:58,420 --> 00:36:03,099
challenges for researchers to produce

789
00:36:00,390 --> 00:36:04,420
detection techniques so we're starting

790
00:36:03,099 --> 00:36:06,539
to understand that this is the

791
00:36:04,420 --> 00:36:10,630
capability and that's what we need and

792
00:36:06,539 --> 00:36:12,460
more specifically when deep fake videos

793
00:36:10,630 --> 00:36:15,599
surface we need to get that information

794
00:36:12,460 --> 00:36:19,029
out there as well the second key is

795
00:36:15,599 --> 00:36:22,749
repetition those messages need to be

796
00:36:19,029 --> 00:36:25,599
repeated over and over and over again it

797
00:36:22,749 --> 00:36:30,098
needs to be something that is culturally

798
00:36:25,599 --> 00:36:32,890
aware throughout our entire society we

799
00:36:30,099 --> 00:36:36,279
need that ability that awareness to

800
00:36:32,890 --> 00:36:38,440
recognize that there are things that we

801
00:36:36,279 --> 00:36:41,559
used to trust that we can't trust

802
00:36:38,440 --> 00:36:43,749
anymore our standard of evidence has

803
00:36:41,559 --> 00:36:47,230
gone up we used to look at video

804
00:36:43,749 --> 00:36:49,779
evidence as kind of the gold standard if

805
00:36:47,230 --> 00:36:51,789
you will if it was on video we knew it

806
00:36:49,779 --> 00:36:54,220
to be real that's why we have so many

807
00:36:51,789 --> 00:36:57,819
surveillance cameras that's why we see

808
00:36:54,220 --> 00:37:00,509
video evidence used in courtrooms being

809
00:36:57,819 --> 00:37:04,089
used to such a strong powerful degree

810
00:37:00,509 --> 00:37:06,160
deep fakes threaten all of that and we

811
00:37:04,089 --> 00:37:08,710
need people to be aware of that we need

812
00:37:06,160 --> 00:37:10,180
to make people aware and repeat it over

813
00:37:08,710 --> 00:37:12,519
and over again that they have to

814
00:37:10,180 --> 00:37:17,720
question the things that they're seeing

815
00:37:12,519 --> 00:37:19,160
the things that they're hearing the

816
00:37:17,720 --> 00:37:24,020
step is the part that often gets missed

817
00:37:19,160 --> 00:37:27,170
and that is we have to take that

818
00:37:24,020 --> 00:37:30,200
truthful narrative and use it in a way

819
00:37:27,170 --> 00:37:33,980
that we can replace that misinformation

820
00:37:30,200 --> 00:37:36,770
in that logic chain in the person's

821
00:37:33,980 --> 00:37:41,240
brain so what that means is we have to

822
00:37:36,770 --> 00:37:44,000
understand how that propaganda how that

823
00:37:41,240 --> 00:37:48,319
misinformation was constructed to play

824
00:37:44,000 --> 00:37:52,730
off of specific prejudices specific

825
00:37:48,320 --> 00:37:56,660
beliefs specific value sets and we have

826
00:37:52,730 --> 00:37:59,570
to craft our truthful narrative in a way

827
00:37:56,660 --> 00:38:01,368
that plays to that so when we think

828
00:37:59,570 --> 00:38:04,010
about what I talked about in terms of

829
00:38:01,369 --> 00:38:07,119
the threats to businesses business has

830
00:38:04,010 --> 00:38:10,520
to start looking at misinformation as

831
00:38:07,119 --> 00:38:13,790
another incident it should be part of

832
00:38:10,520 --> 00:38:15,410
our instant response plan we should have

833
00:38:13,790 --> 00:38:17,990
those strategies in place for how we

834
00:38:15,410 --> 00:38:22,390
become aware of it how we respond to it

835
00:38:17,990 --> 00:38:25,549
how we work with the media to get that

836
00:38:22,390 --> 00:38:27,650
truthful narrative out there to replace

837
00:38:25,550 --> 00:38:29,470
the mythical narrative that's been

838
00:38:27,650 --> 00:38:31,760
injected into the minds of those who

839
00:38:29,470 --> 00:38:33,919
already we're set to believe because

840
00:38:31,760 --> 00:38:36,500
maybe they weren't real happy with our

841
00:38:33,920 --> 00:38:38,660
company or they they're just looking for

842
00:38:36,500 --> 00:38:40,550
a reason to believe that corporate

843
00:38:38,660 --> 00:38:42,950
America did something terrible

844
00:38:40,550 --> 00:38:46,790
or that our high-ranking officials did

845
00:38:42,950 --> 00:38:48,770
something terrible so that is the lesson

846
00:38:46,790 --> 00:38:51,560
to be learned here from a business

847
00:38:48,770 --> 00:38:53,750
perspective start looking at how you can

848
00:38:51,560 --> 00:38:57,230
build this into your incident response

849
00:38:53,750 --> 00:39:02,270
plan and treat misinformation as an

850
00:38:57,230 --> 00:39:04,770
incident the good news is it's there are

851
00:39:02,270 --> 00:39:06,000
some positive intentions

852
00:39:04,770 --> 00:39:08,580
there are positive uses for this

853
00:39:06,000 --> 00:39:10,320
technology and in fact many people have

854
00:39:08,580 --> 00:39:11,790
questioned why did researchers ever

855
00:39:10,320 --> 00:39:15,020
create this in the first place how could

856
00:39:11,790 --> 00:39:18,450
this have ever been a good thing well

857
00:39:15,020 --> 00:39:21,270
despite or in addition to rather the

858
00:39:18,450 --> 00:39:23,930
fuehrer lot the feel theoretical let's

859
00:39:21,270 --> 00:39:26,250
try that again the theoretical

860
00:39:23,930 --> 00:39:30,230
improvements in deep learning overall

861
00:39:26,250 --> 00:39:32,670
some of that idealistic academic sense

862
00:39:30,230 --> 00:39:34,920
there are real-world applications where

863
00:39:32,670 --> 00:39:38,100
we've already seen the use of this

864
00:39:34,920 --> 00:39:43,010
technology why having Star Wars fans out

865
00:39:38,100 --> 00:39:45,240
there and betting I do see Rob one

866
00:39:43,010 --> 00:39:46,800
remember grand moff tarkin making a

867
00:39:45,240 --> 00:39:49,830
return appearance even though the actors

868
00:39:46,800 --> 00:39:53,580
dead remember a young Princess Leia

869
00:39:49,830 --> 00:39:56,910
showing up yeah that was deep fake

870
00:39:53,580 --> 00:39:58,319
technology that made that possible now

871
00:39:56,910 --> 00:40:00,299
there are ethical concerns here of

872
00:39:58,320 --> 00:40:02,250
course the good news from a Hollywood

873
00:40:00,300 --> 00:40:04,980
perspective is Hollywood actually seems

874
00:40:02,250 --> 00:40:07,440
to be taking those ethical concerns into

875
00:40:04,980 --> 00:40:08,880
consideration they spoke to Carrie

876
00:40:07,440 --> 00:40:12,300
Fisher before her death and got her

877
00:40:08,880 --> 00:40:13,710
permission to create this in fact Carrie

878
00:40:12,300 --> 00:40:16,110
Fisher was really excited that they

879
00:40:13,710 --> 00:40:18,270
would be able to create this video of

880
00:40:16,110 --> 00:40:20,640
her and her younger days and make it

881
00:40:18,270 --> 00:40:22,590
more consistent in the movie they also

882
00:40:20,640 --> 00:40:24,240
went to the actor and I apologize I

883
00:40:22,590 --> 00:40:27,150
always forget his name who played Grand

884
00:40:24,240 --> 00:40:30,330
Moff Tarkin and they did get permission

885
00:40:27,150 --> 00:40:34,380
from his estate from his family to use

886
00:40:30,330 --> 00:40:35,670
his likeness in the movie but this isn't

887
00:40:34,380 --> 00:40:39,570
the only place where we're seeing it

888
00:40:35,670 --> 00:40:43,400
used Ganz the technology behind deface

889
00:40:39,570 --> 00:40:43,400
are being leveraged in medical imaging

890
00:40:43,670 --> 00:40:51,990
recent studies have shown that Ganz can

891
00:40:47,400 --> 00:40:55,440
more accurately detect tumors at a far

892
00:40:51,990 --> 00:40:59,569
earlier stage than doctors better still

893
00:40:55,440 --> 00:41:02,460
they can predict with amazing accuracy

894
00:40:59,570 --> 00:41:04,590
what the growth of that tumor will be

895
00:41:02,460 --> 00:41:06,810
again far exceeding the capabilities of

896
00:41:04,590 --> 00:41:11,150
even the best cancer specialists out

897
00:41:06,810 --> 00:41:12,450
there today so this is really promising

898
00:41:11,150 --> 00:41:14,599
because

899
00:41:12,450 --> 00:41:18,839
this is something that can help inform

900
00:41:14,599 --> 00:41:20,849
better treatment options less of the you

901
00:41:18,839 --> 00:41:22,890
know try it and phrase sort of approach

902
00:41:20,849 --> 00:41:24,300
that sometimes is still a reality when

903
00:41:22,890 --> 00:41:27,690
we think about cancer treatments today

904
00:41:24,300 --> 00:41:29,760
and we're starting to see other research

905
00:41:27,690 --> 00:41:33,260
being done around this to even expand

906
00:41:29,760 --> 00:41:37,010
the usage beyond just tumor detection

907
00:41:33,260 --> 00:41:38,750
medical imaging will improve

908
00:41:37,010 --> 00:41:40,880
but it's not just medical imaging there

909
00:41:38,750 --> 00:41:43,250
are other cases in health care space

910
00:41:40,880 --> 00:41:47,060
where we're seeing this used we're

911
00:41:43,250 --> 00:41:51,590
seeing augmented reality start to grow

912
00:41:47,060 --> 00:41:54,380
in terms of telehealth options and what

913
00:41:51,590 --> 00:41:58,070
you see here is an augmented reality

914
00:41:54,380 --> 00:42:01,730
based telehealth solution that uses deep

915
00:41:58,070 --> 00:42:03,770
fake generated video of a doctor that

916
00:42:01,730 --> 00:42:05,810
doctor that this person is looking at

917
00:42:03,770 --> 00:42:07,880
doesn't even exist that's not even a

918
00:42:05,810 --> 00:42:10,790
real person

919
00:42:07,880 --> 00:42:16,520
but it's a doctor's image that was

920
00:42:10,790 --> 00:42:19,190
constructed by again to maximize the the

921
00:42:16,520 --> 00:42:22,310
friendly nature the inviting nature of

922
00:42:19,190 --> 00:42:24,920
that doctor's face the goal here being

923
00:42:22,310 --> 00:42:28,190
that people will be more apt to open up

924
00:42:24,920 --> 00:42:30,830
and to more openly share information

925
00:42:28,190 --> 00:42:35,270
about their current health situation by

926
00:42:30,830 --> 00:42:36,890
a telehealth that's important if we

927
00:42:35,270 --> 00:42:38,540
think about the current situation we're

928
00:42:36,890 --> 00:42:40,220
in right now with COBIT and the number

929
00:42:38,540 --> 00:42:42,259
of us who are having to to use

930
00:42:40,220 --> 00:42:44,779
telehealth options today to speak with

931
00:42:42,260 --> 00:42:46,580
our doctors making people more

932
00:42:44,780 --> 00:42:48,470
comfortable in those situations and more

933
00:42:46,580 --> 00:42:53,000
able to accurately Express to their

934
00:42:48,470 --> 00:42:54,950
doctors what's going on is crucial then

935
00:42:53,000 --> 00:42:57,020
finally we've seen political application

936
00:42:54,950 --> 00:42:59,240
now you could argue and there is

937
00:42:57,020 --> 00:43:00,680
discussion for sure about the ethics

938
00:42:59,240 --> 00:43:02,569
behind this and whether this is really a

939
00:43:00,680 --> 00:43:04,040
good thing I look at it and I think it's

940
00:43:02,570 --> 00:43:06,560
very innovative at minimum and I

941
00:43:04,040 --> 00:43:08,420
actually think it's a good idea this is

942
00:43:06,560 --> 00:43:12,799
a politician from the country of India

943
00:43:08,420 --> 00:43:17,000
and in his district he represents a

944
00:43:12,800 --> 00:43:19,340
constituency of people that span twelve

945
00:43:17,000 --> 00:43:21,500
different languages if you know anything

946
00:43:19,340 --> 00:43:23,900
about India there are numerous numerous

947
00:43:21,500 --> 00:43:27,620
dialects that are spoken across the

948
00:43:23,900 --> 00:43:30,260
country so he doesn't speak all 12 of

949
00:43:27,620 --> 00:43:34,190
those dialects so he created an address

950
00:43:30,260 --> 00:43:35,330
to reach out to his people he then had

951
00:43:34,190 --> 00:43:39,800
that address

952
00:43:35,330 --> 00:43:41,779
deep faked both audio and video to make

953
00:43:39,800 --> 00:43:43,820
it appear as though he were delivering

954
00:43:41,780 --> 00:43:45,950
that same address in each of those 12

955
00:43:43,820 --> 00:43:49,670
different languages that make up his

956
00:43:45,950 --> 00:43:53,450
constituency he was widely popular as a

957
00:43:49,670 --> 00:43:55,820
result people were very excited to hear

958
00:43:53,450 --> 00:43:57,859
one of their leaders expressing a

959
00:43:55,820 --> 00:43:59,210
message in their natives tongues

960
00:43:57,860 --> 00:44:02,270
something many of them had never

961
00:43:59,210 --> 00:44:04,880
witnessed before this was truly

962
00:44:02,270 --> 00:44:07,640
groundbreaking and I think we'll see

963
00:44:04,880 --> 00:44:10,010
more of that that's to me that's a

964
00:44:07,640 --> 00:44:11,750
positive use because it's it there was

965
00:44:10,010 --> 00:44:14,589
nothing dishonest about it he didn't

966
00:44:11,750 --> 00:44:17,200
suggest for a moment

967
00:44:14,589 --> 00:44:18,910
that you know he was speaking in all

968
00:44:17,200 --> 00:44:20,799
these other languages it was it was made

969
00:44:18,910 --> 00:44:22,960
known that this was how this was created

970
00:44:20,799 --> 00:44:28,599
but it was just a way for him to more

971
00:44:22,960 --> 00:44:30,729
directly connect to his people so as I

972
00:44:28,599 --> 00:44:32,589
start to wrap up here we're just about

973
00:44:30,729 --> 00:44:34,419
out of time I want to leave you with

974
00:44:32,589 --> 00:44:36,759
this quote this quote is from Yuri

975
00:44:34,420 --> 00:44:39,940
basmanov he's a former KGB agent and

976
00:44:36,759 --> 00:44:41,890
this was him discussing the mass

977
00:44:39,940 --> 00:44:45,609
brainwashing techniques of the former

978
00:44:41,890 --> 00:44:48,098
Soviet Union back in 1984 they called it

979
00:44:45,609 --> 00:44:51,038
their ideological subversion program and

980
00:44:48,099 --> 00:44:53,499
this goes to the heart of the problem

981
00:44:51,039 --> 00:44:55,539
with misinformation when we can no

982
00:44:53,499 --> 00:44:59,410
longer trust the information around us

983
00:44:55,539 --> 00:45:02,499
and we don't trust our own senses we

984
00:44:59,410 --> 00:45:05,259
start to make decisions that no longer

985
00:45:02,499 --> 00:45:08,410
are in our own best interests that is

986
00:45:05,259 --> 00:45:11,499
the breakdown of so many systems that

987
00:45:08,410 --> 00:45:13,509
our society is built on so it's

988
00:45:11,499 --> 00:45:15,879
important that we be aware of this it's

989
00:45:13,509 --> 00:45:20,339
important that we focus on the human

990
00:45:15,880 --> 00:45:22,599
solutions to how we combat deep fakes

991
00:45:20,339 --> 00:45:25,180
some other materials for you really

992
00:45:22,599 --> 00:45:27,309
quickly a hashtag project deep fake if

993
00:45:25,180 --> 00:45:29,319
you follow that on Twitter or LinkedIn

994
00:45:27,309 --> 00:45:31,989
you can see some of the results of the

995
00:45:29,319 --> 00:45:34,420
projects I've been working on I do have

996
00:45:31,989 --> 00:45:35,769
a system here with some dedicated GPUs

997
00:45:34,420 --> 00:45:38,259
that I have been doing some deep fake

998
00:45:35,769 --> 00:45:40,479
work with seeing just how realistic I

999
00:45:38,259 --> 00:45:43,420
could get those videos to be you can see

1000
00:45:40,479 --> 00:45:45,430
some early results that Alyssa Milano

1001
00:45:43,420 --> 00:45:47,950
video that I created if you go to that

1002
00:45:45,430 --> 00:45:50,319
youtube link I also have a link to these

1003
00:45:47,950 --> 00:45:52,718
slides they're available both in sked

1004
00:45:50,319 --> 00:45:54,430
for this conference but also if you'd

1005
00:45:52,719 --> 00:45:56,049
rather you can use that link to go get

1006
00:45:54,430 --> 00:45:58,149
them from github they're available to

1007
00:45:56,049 --> 00:46:00,489
you I'm happy to share those if those

1008
00:45:58,150 --> 00:46:02,650
are at all helpful to you additionally

1009
00:46:00,489 --> 00:46:04,839
some references for you all the

1010
00:46:02,650 --> 00:46:08,559
different studies that I have cited in

1011
00:46:04,839 --> 00:46:13,140
this talk today if those are useful to

1012
00:46:08,559 --> 00:46:15,940
you by all means please go ahead and

1013
00:46:13,140 --> 00:46:18,460
check those out as well a lot of great

1014
00:46:15,940 --> 00:46:20,440
reading some of it gets pretty deep into

1015
00:46:18,460 --> 00:46:22,779
some machine learning concepts so I will

1016
00:46:20,440 --> 00:46:26,690
warn you it can get kind of dry just be

1017
00:46:22,779 --> 00:46:29,750
aware of that as well and then finally

1018
00:46:26,690 --> 00:46:32,690
I open invitation to continue the

1019
00:46:29,750 --> 00:46:34,849
conversation I love the reason I get out

1020
00:46:32,690 --> 00:46:36,980
and I speak at conferences like this the

1021
00:46:34,849 --> 00:46:39,319
reason I work as an advocate is because

1022
00:46:36,980 --> 00:46:41,329
I love sharing ideas and hearing other

1023
00:46:39,319 --> 00:46:43,970
people's ideas I love to have my ideas

1024
00:46:41,329 --> 00:46:46,089
challenged to challenge yours if there's

1025
00:46:43,970 --> 00:46:48,589
knowledge that I have that I can help

1026
00:46:46,089 --> 00:46:50,210
you know you with things that you're

1027
00:46:48,589 --> 00:46:53,509
working on please feel free to reach out

1028
00:46:50,210 --> 00:46:57,560
my twitter handle is up there my DMS are

1029
00:46:53,510 --> 00:46:59,599
always open my LinkedIn if you'd rather

1030
00:46:57,560 --> 00:47:03,980
address me there that's fine too and a

1031
00:46:59,599 --> 00:47:06,170
link to my website as promised and then

1032
00:47:03,980 --> 00:47:08,900
finally on behalf of my employer myself

1033
00:47:06,170 --> 00:47:11,150
and besides Knoxville just a great big

1034
00:47:08,900 --> 00:47:14,210
thank you all I really appreciate your

1035
00:47:11,150 --> 00:47:17,000
time and attention today with that if

1036
00:47:14,210 --> 00:47:20,510
there are any questions I think we're

1037
00:47:17,000 --> 00:47:23,810
happy to take those at this time

1038
00:47:20,510 --> 00:47:26,570
ya know like almost down to the second

1039
00:47:23,810 --> 00:47:30,410
timing there that's that's perfect and I

1040
00:47:26,570 --> 00:47:32,960
think we do have some questions I I had

1041
00:47:30,410 --> 00:47:34,520
one just off the top of my head I think

1042
00:47:32,960 --> 00:47:36,619
one of my biggest concerns especially

1043
00:47:34,520 --> 00:47:40,970
talking about you know using this

1044
00:47:36,619 --> 00:47:43,369
technology for manipulation the media

1045
00:47:40,970 --> 00:47:45,109
game is all about exclusives and

1046
00:47:43,369 --> 00:47:48,530
scooping and getting it out there as

1047
00:47:45,109 --> 00:47:51,380
quickly as possible like how how could

1048
00:47:48,530 --> 00:47:53,240
we ever pump the brakes on that kind of

1049
00:47:51,380 --> 00:47:55,339
thing or educate them to the point to

1050
00:47:53,240 --> 00:47:57,649
where they can they can not be fooled by

1051
00:47:55,339 --> 00:48:00,650
this I mean already with the amount of

1052
00:47:57,650 --> 00:48:02,599
media that exists out there that intends

1053
00:48:00,650 --> 00:48:05,510
to be fake in the first place

1054
00:48:02,599 --> 00:48:07,520
posing as real media now we got to worry

1055
00:48:05,510 --> 00:48:10,040
about the real media getting getting

1056
00:48:07,520 --> 00:48:12,020
duped what are your thoughts there so

1057
00:48:10,040 --> 00:48:13,820
yeah so it's twofold right you've got

1058
00:48:12,020 --> 00:48:16,450
the first of all there's the media who

1059
00:48:13,820 --> 00:48:19,070
wants to do a good job and you know

1060
00:48:16,450 --> 00:48:20,390
their problems there they're the ones

1061
00:48:19,070 --> 00:48:23,990
that are being addressed right now in

1062
00:48:20,390 --> 00:48:25,368
part by different research like I

1063
00:48:23,990 --> 00:48:28,189
mentioned the challenge at Facebook

1064
00:48:25,369 --> 00:48:29,960
Microsoft and Amazon are doing part of

1065
00:48:28,190 --> 00:48:32,180
their goal there is to release that not

1066
00:48:29,960 --> 00:48:34,579
only just for social media but to the

1067
00:48:32,180 --> 00:48:36,589
greater media community as a whole so

1068
00:48:34,579 --> 00:48:40,790
they can authenticate videos and things

1069
00:48:36,589 --> 00:48:42,680
before running with a news story you

1070
00:48:40,790 --> 00:48:44,810
know I think the media is also already

1071
00:48:42,680 --> 00:48:46,399
kind of gotten the message that they're

1072
00:48:44,810 --> 00:48:46,819
going to be you need to do even more

1073
00:48:46,400 --> 00:48:48,890
than that

1074
00:48:46,819 --> 00:48:50,960
though and really authenticate the

1075
00:48:48,890 --> 00:48:53,598
source of videos authenticate the story

1076
00:48:50,960 --> 00:48:56,930
through other means as well before they

1077
00:48:53,599 --> 00:48:59,510
just go and run with it now the media

1078
00:48:56,930 --> 00:49:01,910
that doesn't care if it's real or not

1079
00:48:59,510 --> 00:49:05,480
and we can all think of a few examples

1080
00:49:01,910 --> 00:49:07,399
I'm sure the best example of that is the

1081
00:49:05,480 --> 00:49:08,750
Nancy Pelosi video all right that wasn't

1082
00:49:07,400 --> 00:49:11,240
even a deep fake that was just

1083
00:49:08,750 --> 00:49:13,490
manipulated to slow it down but even

1084
00:49:11,240 --> 00:49:16,689
after news came out that that was fake

1085
00:49:13,490 --> 00:49:18,979
we saw multiple right-wing news sources

1086
00:49:16,690 --> 00:49:20,450
releasing that video claiming it to be

1087
00:49:18,980 --> 00:49:23,390
true

1088
00:49:20,450 --> 00:49:26,629
you know countless millions of people in

1089
00:49:23,390 --> 00:49:28,879
their audience rishe airing that content

1090
00:49:26,630 --> 00:49:31,310
claiming it to be true and believing

1091
00:49:28,880 --> 00:49:33,260
that it was true so that becomes the

1092
00:49:31,310 --> 00:49:35,000
harder issue and that's where

1093
00:49:33,260 --> 00:49:36,650
you know some of the greater aspects of

1094
00:49:35,000 --> 00:49:39,530
trying to fight misinformation in

1095
00:49:36,650 --> 00:49:41,420
general where social media is now taking

1096
00:49:39,530 --> 00:49:43,730
and sometimes removing that media and so

1097
00:49:41,420 --> 00:49:46,610
forth that's gonna have to continue to

1098
00:49:43,730 --> 00:49:49,010
accelerate the other challenge we have

1099
00:49:46,610 --> 00:49:51,740
though honestly is that there's some

1100
00:49:49,010 --> 00:49:54,200
gray area here that social media is

1101
00:49:51,740 --> 00:49:57,589
struggling with where is that line

1102
00:49:54,200 --> 00:50:00,020
between free speech and acceptable you

1103
00:49:57,590 --> 00:50:03,680
know use of these different videos to

1104
00:50:00,020 --> 00:50:06,590
create satire versus what violates

1105
00:50:03,680 --> 00:50:08,390
copyrights and privacy laws

1106
00:50:06,590 --> 00:50:11,180
there's definitely legislation needed

1107
00:50:08,390 --> 00:50:12,589
here unfortunately lawmakers right now

1108
00:50:11,180 --> 00:50:14,540
are only focused on election security

1109
00:50:12,590 --> 00:50:16,430
there nothing can be on that and so

1110
00:50:14,540 --> 00:50:21,950
there's a lot of work to be done there

1111
00:50:16,430 --> 00:50:24,890
as well yeah definitely it's and just

1112
00:50:21,950 --> 00:50:26,330
let you know and in the the discord is

1113
00:50:24,890 --> 00:50:27,920
having a great time with this but I'm

1114
00:50:26,330 --> 00:50:30,049
gonna have steve buscemi nightmares

1115
00:50:27,920 --> 00:50:31,460
tonight I know I keep seeing that if

1116
00:50:30,050 --> 00:50:33,230
that's like the third time now it's

1117
00:50:31,460 --> 00:50:35,840
passed by in my peripheral vision I've

1118
00:50:33,230 --> 00:50:38,750
seen that that that one in particular is

1119
00:50:35,840 --> 00:50:40,850
horrible I don't know why he's such a

1120
00:50:38,750 --> 00:50:42,890
popular subject for deep face it just

1121
00:50:40,850 --> 00:50:44,810
everybody liked him and Nicolas Cage

1122
00:50:42,890 --> 00:50:48,049
there that one looks like him he's just

1123
00:50:44,810 --> 00:50:50,900
it's he's just has a very unique like

1124
00:50:48,050 --> 00:50:55,960
quirky look which is why I get so much

1125
00:50:50,900 --> 00:50:59,210
work in Hollywood right I guess yeah so

1126
00:50:55,960 --> 00:51:00,890
yeah I think we had some other questions

1127
00:50:59,210 --> 00:51:03,950
here let me see what I've got somebody

1128
00:51:00,890 --> 00:51:06,440
asking how many covered 19 related fakes

1129
00:51:03,950 --> 00:51:08,450
have you found you know honestly I

1130
00:51:06,440 --> 00:51:09,800
haven't seen a deep fake yet from that

1131
00:51:08,450 --> 00:51:12,080
and I'm actually surprised like I've

1132
00:51:09,800 --> 00:51:14,750
been kind of watching for like dr. Fauci

1133
00:51:12,080 --> 00:51:16,250
to show up somewhere deep fake like you

1134
00:51:14,750 --> 00:51:17,630
know saying some nasty stuff about the

1135
00:51:16,250 --> 00:51:18,980
president or something like that but

1136
00:51:17,630 --> 00:51:22,550
surprisingly there hasn't been as much

1137
00:51:18,980 --> 00:51:26,750
lately I don't know what's kind of toned

1138
00:51:22,550 --> 00:51:28,220
that down but yeah I haven't it's please

1139
00:51:26,750 --> 00:51:29,510
let me know if someone sees some because

1140
00:51:28,220 --> 00:51:31,450
I would definitely be interested in

1141
00:51:29,510 --> 00:51:35,120
knowing about that

1142
00:51:31,450 --> 00:51:37,069
so somebody's asking they're interested

1143
00:51:35,120 --> 00:51:41,000
in how the noise is applied to live

1144
00:51:37,070 --> 00:51:43,910
images in order to prevent faking so

1145
00:51:41,000 --> 00:51:46,130
it's basically like a summation so if

1146
00:51:43,910 --> 00:51:47,930
you take the you're taking two images

1147
00:51:46,130 --> 00:51:49,790
you layer them together and you apply it

1148
00:51:47,930 --> 00:51:51,379
and if you got down to if you were like

1149
00:51:49,790 --> 00:51:54,670
so say you were gonna do it in Photoshop

1150
00:51:51,380 --> 00:51:58,760
you would literally take two layers and

1151
00:51:54,670 --> 00:52:01,850
just by applying I'm trying to think all

1152
00:51:58,760 --> 00:52:04,190
the mask works exactly I apologize but

1153
00:52:01,850 --> 00:52:06,740
it's basically a max masking technique

1154
00:52:04,190 --> 00:52:09,830
where those pixels that aren't that

1155
00:52:06,740 --> 00:52:11,359
static gray in that you saw that was the

1156
00:52:09,830 --> 00:52:14,990
static gray is added just to make them

1157
00:52:11,360 --> 00:52:16,820
more visible but the way they're at it

1158
00:52:14,990 --> 00:52:20,540
is it's it's just individual adjustments

1159
00:52:16,820 --> 00:52:23,930
to those pixels it's it's a slight

1160
00:52:20,540 --> 00:52:26,270
change in coloration and in I believe

1161
00:52:23,930 --> 00:52:28,490
it's if you're taught if the parents are

1162
00:52:26,270 --> 00:52:31,490
you talking RGB or CMYK as to how

1163
00:52:28,490 --> 00:52:33,259
exactly that that gets adjusted but yeah

1164
00:52:31,490 --> 00:52:37,279
they it's just taking that and applying

1165
00:52:33,260 --> 00:52:39,650
it over top so I think the follow-up

1166
00:52:37,280 --> 00:52:40,910
question to this and I think I know the

1167
00:52:39,650 --> 00:52:43,070
answer the answer is probably going to

1168
00:52:40,910 --> 00:52:46,250
be yes is whether or not like major

1169
00:52:43,070 --> 00:52:49,880
social media you know services can apply

1170
00:52:46,250 --> 00:52:53,630
that as you upload that's what they're

1171
00:52:49,880 --> 00:52:57,050
talking about doing the research on it

1172
00:52:53,630 --> 00:52:59,300
is still not complete but I think that's

1173
00:52:57,050 --> 00:53:01,310
yeah as you read through some of the

1174
00:52:59,300 --> 00:53:04,370
follow ups to the study that was one of

1175
00:53:01,310 --> 00:53:08,000
the suggestions and I know you know

1176
00:53:04,370 --> 00:53:10,670
Facebook at least had uh released some

1177
00:53:08,000 --> 00:53:14,240
commentary about the possibility of

1178
00:53:10,670 --> 00:53:17,420
doing exactly that that's the hope the

1179
00:53:14,240 --> 00:53:19,609
issue comes in to you would also have to

1180
00:53:17,420 --> 00:53:21,170
do it with video and that's where it

1181
00:53:19,610 --> 00:53:23,210
becomes a little more difficult because

1182
00:53:21,170 --> 00:53:27,260
a lot of the training right now like

1183
00:53:23,210 --> 00:53:29,750
when I did mine for in Face Swap I used

1184
00:53:27,260 --> 00:53:31,520
video and I just I had it extract still

1185
00:53:29,750 --> 00:53:33,980
images from video for the training set

1186
00:53:31,520 --> 00:53:36,620
and so you know in that case you would

1187
00:53:33,980 --> 00:53:39,920
have to have every frame at 30 frames a

1188
00:53:36,620 --> 00:53:41,720
second or 60 frames a second apply that

1189
00:53:39,920 --> 00:53:44,050
to it and I that could get pretty

1190
00:53:41,720 --> 00:53:44,049
time-consuming

1191
00:53:44,349 --> 00:53:51,880
yeah and I it sounds a lot like we're

1192
00:53:49,839 --> 00:53:55,749
getting started in a game of leapfrog

1193
00:53:51,880 --> 00:53:58,539
and like like techniques to prevent it

1194
00:53:55,749 --> 00:54:00,660
you know like very similar to what we've

1195
00:53:58,539 --> 00:54:03,880
seen with malware and other stuff where

1196
00:54:00,660 --> 00:54:06,759
like it takes them takes us six months

1197
00:54:03,880 --> 00:54:09,489
to come up with a defense and a day for

1198
00:54:06,759 --> 00:54:11,289
them to figure out a way around it yeah

1199
00:54:09,489 --> 00:54:12,670
well and the worst thing here is when

1200
00:54:11,289 --> 00:54:15,430
you think about how Gans work where you

1201
00:54:12,670 --> 00:54:17,499
have kind of that the detector if you

1202
00:54:15,430 --> 00:54:19,899
will that that discriminator network

1203
00:54:17,499 --> 00:54:21,430
it's already making the attackers better

1204
00:54:19,900 --> 00:54:23,710
because it's doing that instantly as

1205
00:54:21,430 --> 00:54:26,470
part of that training so a lot of the

1206
00:54:23,710 --> 00:54:28,269
techniques as you build those into you

1207
00:54:26,470 --> 00:54:29,558
know we build these detection techniques

1208
00:54:28,269 --> 00:54:31,660
well people take those they build them

1209
00:54:29,559 --> 00:54:34,329
into the discriminators and now that

1210
00:54:31,660 --> 00:54:36,700
just updates the generators model to

1211
00:54:34,329 --> 00:54:39,819
account for those additional elements

1212
00:54:36,700 --> 00:54:43,359
and so that's you know you're right it's

1213
00:54:39,819 --> 00:54:44,769
a constant cycle of attackers making the

1214
00:54:43,359 --> 00:54:46,538
defenders better and the defenders

1215
00:54:44,769 --> 00:54:48,430
making the attackers better and it just

1216
00:54:46,539 --> 00:54:53,349
happens at a faster pace now because

1217
00:54:48,430 --> 00:54:58,719
we're talking machine learning yeah all

1218
00:54:53,349 --> 00:55:00,369
right looking for other questions here I

1219
00:54:58,719 --> 00:55:02,559
don't think we have any more I think

1220
00:55:00,369 --> 00:55:05,799
that's it definitely a great

1221
00:55:02,559 --> 00:55:09,880
conversation in the in track one on that

1222
00:55:05,799 --> 00:55:12,910
and if you want to check that out later

1223
00:55:09,880 --> 00:55:14,200
it's it's there's a lot well maybe I

1224
00:55:12,910 --> 00:55:19,989
don't know if there's a way to turn off

1225
00:55:14,200 --> 00:55:21,999
the images as you browse it skip the

1226
00:55:19,989 --> 00:55:28,630
skip the doubled-up steve buscemi eyes

1227
00:55:21,999 --> 00:55:30,459
and mouth one yeah yes yeah all right

1228
00:55:28,630 --> 00:55:32,109
that that was awesome I appreciate it

1229
00:55:30,460 --> 00:55:35,109
thanks for bringing such an awesome talk

1230
00:55:32,109 --> 00:55:36,788
and excellent delivery and we've got

1231
00:55:35,109 --> 00:55:38,920
plenty of time before the the next

1232
00:55:36,789 --> 00:55:43,859
speaker here all right I appreciate it

1233
00:55:38,920 --> 00:55:43,859
thanks again everybody so much thank you

