1
00:00:00,399 --> 00:00:02,560
our next talk is avoiding insidious

2
00:00:02,560 --> 00:00:04,400
points of compromise in infrastructure

3
00:00:04,400 --> 00:00:05,920
access systems

4
00:00:05,920 --> 00:00:08,639
our speaker is sharon goldberg sharon

5
00:00:08,639 --> 00:00:10,480
goldberg is the ceo co-founder of

6
00:00:10,480 --> 00:00:12,320
bastian xero a startup that is

7
00:00:12,320 --> 00:00:14,320
reimagining the tools that engineers use

8
00:00:14,320 --> 00:00:15,440
to secure remote access to

9
00:00:15,440 --> 00:00:16,720
infrastructure

10
00:00:16,720 --> 00:00:18,640
she is also a tenured professor at the

11
00:00:18,640 --> 00:00:20,080
community science department at boston

12
00:00:20,080 --> 00:00:21,359
university

13
00:00:21,359 --> 00:00:23,279
uh if you want to submit questions you

14
00:00:23,279 --> 00:00:25,960
can go to slido.com hashtag besides

15
00:00:25,960 --> 00:00:29,279
sf2022 thank you take it away

16
00:00:29,279 --> 00:00:31,760
hi everyone i'm really honored and happy

17
00:00:31,760 --> 00:00:33,600
to be speaking to such a great group of

18
00:00:33,600 --> 00:00:36,399
people so um you know please if this

19
00:00:36,399 --> 00:00:37,600
what we're talking about is interesting

20
00:00:37,600 --> 00:00:39,200
please come see me or my colleague and

21
00:00:39,200 --> 00:00:40,960
ming who's sitting right here and tell

22
00:00:40,960 --> 00:00:42,480
us your war stories about your

23
00:00:42,480 --> 00:00:44,399
infrastructure access systems we'd love

24
00:00:44,399 --> 00:00:46,320
to hear it it's super helpful for us

25
00:00:46,320 --> 00:00:47,600
so um

26
00:00:47,600 --> 00:00:49,600
this talk is going to be mostly war

27
00:00:49,600 --> 00:00:51,360
stories so i'm going to tell five

28
00:00:51,360 --> 00:00:53,520
different incidents some of which

29
00:00:53,520 --> 00:00:55,760
so i've got not pecha and solar winds up

30
00:00:55,760 --> 00:00:57,440
there how many people

31
00:00:57,440 --> 00:00:59,600
know in grand detail what happened and

32
00:00:59,600 --> 00:01:01,920
not pecha for example in this room how

33
00:01:01,920 --> 00:01:04,319
many know like sort of every detail

34
00:01:04,319 --> 00:01:05,360
okay

35
00:01:05,360 --> 00:01:06,880
um and how many people know every detail

36
00:01:06,880 --> 00:01:09,280
of what happened with solarwinds

37
00:01:09,280 --> 00:01:11,280
okay so i'm gonna go into like specific

38
00:01:11,280 --> 00:01:12,799
pieces of this that are relevant to kind

39
00:01:12,799 --> 00:01:14,000
of the point i'm trying to make about

40
00:01:14,000 --> 00:01:15,200
how to think about these types of

41
00:01:15,200 --> 00:01:16,560
systems so some of this stuff is a

42
00:01:16,560 --> 00:01:18,080
little bit more obscure

43
00:01:18,080 --> 00:01:19,439
and some of these are really random like

44
00:01:19,439 --> 00:01:21,600
fluffy bunny from 2001 is basically a

45
00:01:21,600 --> 00:01:23,520
story that was told to me by andy ellis

46
00:01:23,520 --> 00:01:25,360
who's the cso of akamai so this is an

47
00:01:25,360 --> 00:01:27,680
akamai hack story from the dinosaur

48
00:01:27,680 --> 00:01:29,280
years and andy was actually supposed to

49
00:01:29,280 --> 00:01:30,880
be here giving this talk with me but he

50
00:01:30,880 --> 00:01:31,840
couldn't make it because of the date

51
00:01:31,840 --> 00:01:34,720
change so you just get me instead um so

52
00:01:34,720 --> 00:01:36,159
yeah so let's get into it so basically

53
00:01:36,159 --> 00:01:38,240
i'm going to have three acts the first

54
00:01:38,240 --> 00:01:39,520
one is

55
00:01:39,520 --> 00:01:41,200
sort of the the standing credential

56
00:01:41,200 --> 00:01:42,960
approach to infrastructure access so let

57
00:01:42,960 --> 00:01:44,560
me back up for a second i'm specifically

58
00:01:44,560 --> 00:01:47,119
talking about you have cloud or data

59
00:01:47,119 --> 00:01:48,799
center infrastructure you have engineers

60
00:01:48,799 --> 00:01:51,040
that need to access that infrastructure

61
00:01:51,040 --> 00:01:53,360
that used to be just ssh now it's more

62
00:01:53,360 --> 00:01:55,680
it can be coupe control it can be access

63
00:01:55,680 --> 00:01:57,360
to databases it can be accessed to

64
00:01:57,360 --> 00:01:59,360
windows servers it can be rdp all of

65
00:01:59,360 --> 00:02:00,960
these different systems that engineers

66
00:02:00,960 --> 00:02:03,119
use to access their systems how do you

67
00:02:03,119 --> 00:02:04,560
make sure that that doesn't become a

68
00:02:04,560 --> 00:02:06,479
point of compromise right and i have the

69
00:02:06,479 --> 00:02:08,239
picture on the right with the the bunch

70
00:02:08,239 --> 00:02:10,080
of squares around the cloud right the

71
00:02:10,080 --> 00:02:12,720
idea is like we put so much security in

72
00:02:12,720 --> 00:02:14,720
to keep outsiders out of our system

73
00:02:14,720 --> 00:02:16,879
which is great but then the engineers do

74
00:02:16,879 --> 00:02:18,800
need to get in at some point at least in

75
00:02:18,800 --> 00:02:21,200
most places and so how do you avoid

76
00:02:21,200 --> 00:02:22,800
having that become a big issue so i'm

77
00:02:22,800 --> 00:02:24,160
going to look at all of these incidents

78
00:02:24,160 --> 00:02:25,599
and see what they can teach us about how

79
00:02:25,599 --> 00:02:27,760
to build these kinds of systems properly

80
00:02:27,760 --> 00:02:29,360
um okay

81
00:02:29,360 --> 00:02:31,040
so i'm going to start and so in each one

82
00:02:31,040 --> 00:02:33,120
i'm going to start with a different

83
00:02:33,120 --> 00:02:34,879
sort of approach

84
00:02:34,879 --> 00:02:37,120
and um and and talk about sort of issues

85
00:02:37,120 --> 00:02:38,239
here

86
00:02:38,239 --> 00:02:40,319
so this is a picture of a bastion host

87
00:02:40,319 --> 00:02:41,840
i'm obviously very obsessed with

88
00:02:41,840 --> 00:02:43,840
bastions as the ceo of bastian zero what

89
00:02:43,840 --> 00:02:46,160
a bastion is is a box that sits in front

90
00:02:46,160 --> 00:02:48,560
of other boxes and the idea is you don't

91
00:02:48,560 --> 00:02:50,720
want your um your people to access the

92
00:02:50,720 --> 00:02:52,080
boxes directly you want to have

93
00:02:52,080 --> 00:02:53,599
something in the middle that you can use

94
00:02:53,599 --> 00:02:56,720
to aggregate that access to avoid um

95
00:02:56,720 --> 00:02:58,480
you know to to avoid them all being

96
00:02:58,480 --> 00:03:00,319
exposed to the internet or to even just

97
00:03:00,319 --> 00:03:01,680
have a way of like filtering the

98
00:03:01,680 --> 00:03:03,280
connections and seeing who's going in

99
00:03:03,280 --> 00:03:04,640
and things like this

100
00:03:04,640 --> 00:03:05,519
right

101
00:03:05,519 --> 00:03:07,120
and so in this picture i've got a very

102
00:03:07,120 --> 00:03:08,959
particular kind of bastion architecture

103
00:03:08,959 --> 00:03:11,200
where what i have is i have the user has

104
00:03:11,200 --> 00:03:13,200
some key that would allow her to log

105
00:03:13,200 --> 00:03:15,280
into the bastion and then there are some

106
00:03:15,280 --> 00:03:16,720
other keys on this bastion that are

107
00:03:16,720 --> 00:03:18,640
allowing you to access other types of

108
00:03:18,640 --> 00:03:19,920
targets that are behind it in this

109
00:03:19,920 --> 00:03:22,800
picture it's just a bunch of servers

110
00:03:22,800 --> 00:03:24,400
so this is a fluffy bunny incident that

111
00:03:24,400 --> 00:03:25,760
you've probably never heard of but this

112
00:03:25,760 --> 00:03:27,519
happened to andy ellis and and when i

113
00:03:27,519 --> 00:03:29,120
talk about bastions this is the story he

114
00:03:29,120 --> 00:03:31,840
tells me so i'll just channel andy um

115
00:03:31,840 --> 00:03:34,720
and so in 2001 there was this hacker um

116
00:03:34,720 --> 00:03:36,080
and this was like the old days where

117
00:03:36,080 --> 00:03:38,560
there was like sort of just like

118
00:03:38,560 --> 00:03:40,560
malice for fun you know

119
00:03:40,560 --> 00:03:42,560
this was before the ransomware days so

120
00:03:42,560 --> 00:03:44,319
what this guy did what this group of

121
00:03:44,319 --> 00:03:46,640
people did was they hacked into some

122
00:03:46,640 --> 00:03:48,560
users machines and they replaced their

123
00:03:48,560 --> 00:03:51,599
ssh client with a new client that was

124
00:03:51,599 --> 00:03:54,799
exfiltrating ssh passwords so basically

125
00:03:54,799 --> 00:03:56,959
instead of running a proper ssh client

126
00:03:56,959 --> 00:03:59,280
you ran this adversary's client

127
00:03:59,280 --> 00:04:00,640
and it would steal your passwords and

128
00:04:00,640 --> 00:04:02,400
send it to the adversary and so what

129
00:04:02,400 --> 00:04:05,040
they did was they compromised the users

130
00:04:05,040 --> 00:04:06,319
and then from there because they had

131
00:04:06,319 --> 00:04:07,920
stolen this key they could then log into

132
00:04:07,920 --> 00:04:09,360
the bastion

133
00:04:09,360 --> 00:04:11,120
and so what they then did was they sat

134
00:04:11,120 --> 00:04:13,439
on this bastion which was now owned by

135
00:04:13,439 --> 00:04:16,000
them they also ripped out the existing

136
00:04:16,000 --> 00:04:17,839
ssh client and put in their adversarial

137
00:04:17,839 --> 00:04:19,680
ssh client and then they were starting

138
00:04:19,680 --> 00:04:21,120
to exfiltrate all the passwords that

139
00:04:21,120 --> 00:04:22,560
were coming in through that client so

140
00:04:22,560 --> 00:04:24,160
you can imagine like they were just

141
00:04:24,160 --> 00:04:25,360
sitting here

142
00:04:25,360 --> 00:04:26,960
in the bastion and just collecting

143
00:04:26,960 --> 00:04:29,120
passwords as users were appearing

144
00:04:29,120 --> 00:04:30,160
logging in and putting in their

145
00:04:30,160 --> 00:04:31,759
passwords to access the next target and

146
00:04:31,759 --> 00:04:32,960
they were just collecting all of those

147
00:04:32,960 --> 00:04:35,680
passwords right um and so you know when

148
00:04:35,680 --> 00:04:37,520
andy tells the story he actually says

149
00:04:37,520 --> 00:04:40,160
that they were not as affected because

150
00:04:40,160 --> 00:04:42,960
this adversary luckily did not decide to

151
00:04:42,960 --> 00:04:45,280
exfiltrate the s the past phrases that

152
00:04:45,280 --> 00:04:47,600
were used to unlock ssh keys so they

153
00:04:47,600 --> 00:04:50,479
were not as hacked as others could have

154
00:04:50,479 --> 00:04:51,360
been

155
00:04:51,360 --> 00:04:53,680
but this was sort of a moment that

156
00:04:53,680 --> 00:04:55,120
caused them to change the way they think

157
00:04:55,120 --> 00:04:56,960
about credentials

158
00:04:56,960 --> 00:04:57,840
and so

159
00:04:57,840 --> 00:04:59,440
this is this is like the classic

160
00:04:59,440 --> 00:05:01,120
incident that everyone who anyone who

161
00:05:01,120 --> 00:05:02,639
runs a bastion host worries about like

162
00:05:02,639 --> 00:05:04,240
if an adversary gets into your bastion

163
00:05:04,240 --> 00:05:05,840
host what kind of damage can they cause

164
00:05:05,840 --> 00:05:07,440
because it's such a point of aggregation

165
00:05:07,440 --> 00:05:09,680
for your infrastructure um so a couple

166
00:05:09,680 --> 00:05:12,080
of lessons to take from this

167
00:05:12,080 --> 00:05:12,960
um

168
00:05:12,960 --> 00:05:15,039
is this this is like sort of the classic

169
00:05:15,039 --> 00:05:16,639
story that we've all been hearing and

170
00:05:16,639 --> 00:05:18,000
i'm going to talk about this notion of

171
00:05:18,000 --> 00:05:20,080
zero trust in a couple slides don't give

172
00:05:20,080 --> 00:05:22,160
your users standing credentials um and

173
00:05:22,160 --> 00:05:24,320
the issue here right was that when the

174
00:05:24,320 --> 00:05:25,919
adversary actually exfiltrated the

175
00:05:25,919 --> 00:05:27,520
credentials those credentials were good

176
00:05:27,520 --> 00:05:30,080
for a really long time so when you steal

177
00:05:30,080 --> 00:05:31,039
them

178
00:05:31,039 --> 00:05:32,560
you don't necessarily even have to use

179
00:05:32,560 --> 00:05:34,400
them right away you can use them later

180
00:05:34,400 --> 00:05:36,000
and the victim doesn't know what

181
00:05:36,000 --> 00:05:37,440
happened because these credentials may

182
00:05:37,440 --> 00:05:39,360
have been stolen six months before and

183
00:05:39,360 --> 00:05:41,759
now the adversary is using them

184
00:05:41,759 --> 00:05:43,280
another thing that i think that a lot of

185
00:05:43,280 --> 00:05:44,639
people are familiar with like if you

186
00:05:44,639 --> 00:05:46,000
have a bastion host it's a very

187
00:05:46,000 --> 00:05:48,080
sensitive place in your infrastructure

188
00:05:48,080 --> 00:05:49,520
so it's really important to think about

189
00:05:49,520 --> 00:05:51,520
like how do you make sure that this

190
00:05:51,520 --> 00:05:53,039
thing is not

191
00:05:53,039 --> 00:05:53,919
um

192
00:05:53,919 --> 00:05:56,080
you know not unpatched it's not running

193
00:05:56,080 --> 00:05:57,680
some old software like you have to sort

194
00:05:57,680 --> 00:05:59,280
of stay on top of this because it's a

195
00:05:59,280 --> 00:06:01,199
place where if people get in there's a

196
00:06:01,199 --> 00:06:02,720
lot of information that can be pulled

197
00:06:02,720 --> 00:06:03,680
out of it

198
00:06:03,680 --> 00:06:06,400
and the last lesson is is use mfa

199
00:06:06,400 --> 00:06:08,400
so i'm a professor by the way so if i

200
00:06:08,400 --> 00:06:09,759
want to just turn this into like my

201
00:06:09,759 --> 00:06:12,720
infosec 101 class so why would mfa help

202
00:06:12,720 --> 00:06:15,280
with this um any thoughts on how mfa

203
00:06:15,280 --> 00:06:16,639
could have potentially helped with this

204
00:06:16,639 --> 00:06:20,039
with this attack

205
00:06:25,600 --> 00:06:27,280
they couldn't steal your mfa right so

206
00:06:27,280 --> 00:06:29,280
like we're talking about 2001 i'm not

207
00:06:29,280 --> 00:06:31,840
even sure that there was mfa in 2001 i'm

208
00:06:31,840 --> 00:06:33,680
having trouble remembering i actually

209
00:06:33,680 --> 00:06:35,919
i'm fairly old but i wasn't in infosec

210
00:06:35,919 --> 00:06:38,000
in 2001. um

211
00:06:38,000 --> 00:06:40,639
there was yeah so so this was another

212
00:06:40,639 --> 00:06:42,960
way right because stealing ssh passwords

213
00:06:42,960 --> 00:06:44,880
stealing ssh keys doesn't have to be so

214
00:06:44,880 --> 00:06:46,639
deadly if there's an additional form of

215
00:06:46,639 --> 00:06:48,160
authentication that's not the key right

216
00:06:48,160 --> 00:06:49,840
so that's another good reason to use mfa

217
00:06:49,840 --> 00:06:52,080
so this is a very old example but it

218
00:06:52,080 --> 00:06:53,840
gives you a good sense of like why it's

219
00:06:53,840 --> 00:06:54,880
important to think about like what

220
00:06:54,880 --> 00:06:56,800
credentials are long-lived and what

221
00:06:56,800 --> 00:06:58,080
you're doing to actually authenticate

222
00:06:58,080 --> 00:06:59,520
your users

223
00:06:59,520 --> 00:07:00,840
okay

224
00:07:00,840 --> 00:07:03,280
great all right so here's another

225
00:07:03,280 --> 00:07:04,639
architecture that everyone in the room

226
00:07:04,639 --> 00:07:07,840
is familiar so in this architecture

227
00:07:07,840 --> 00:07:09,919
you know instead of having your targets

228
00:07:09,919 --> 00:07:11,759
exposed to the internet you put your

229
00:07:11,759 --> 00:07:14,160
your targets behind a vpn so when the

230
00:07:14,160 --> 00:07:16,080
user wants to access something they have

231
00:07:16,080 --> 00:07:18,160
to first log into the vpn with their vpn

232
00:07:18,160 --> 00:07:20,240
credential and then when they do that

233
00:07:20,240 --> 00:07:21,919
they can they can go to the specific

234
00:07:21,919 --> 00:07:24,639
target okay

235
00:07:24,639 --> 00:07:25,440
um

236
00:07:25,440 --> 00:07:27,520
so i'll tell you a story of operation

237
00:07:27,520 --> 00:07:29,919
aurora how many people are familiar with

238
00:07:29,919 --> 00:07:31,599
this incident

239
00:07:31,599 --> 00:07:32,639
a little bit

240
00:07:32,639 --> 00:07:34,080
okay

241
00:07:34,080 --> 00:07:36,560
so this was an early apt

242
00:07:36,560 --> 00:07:39,919
um believed to be a chinese apt

243
00:07:39,919 --> 00:07:40,880
and

244
00:07:40,880 --> 00:07:42,800
what i what i recall happening here was

245
00:07:42,800 --> 00:07:44,560
there was a microsoft

246
00:07:44,560 --> 00:07:46,800
internet explorer zero day that they

247
00:07:46,800 --> 00:07:48,160
that they found

248
00:07:48,160 --> 00:07:50,160
and effectively what happened was when a

249
00:07:50,160 --> 00:07:52,560
user and and um when a user clicked

250
00:07:52,560 --> 00:07:53,599
something

251
00:07:53,599 --> 00:07:55,599
there um

252
00:07:55,599 --> 00:07:57,039
there was this vulnerability the zero

253
00:07:57,039 --> 00:07:58,479
day an internet explorer that was

254
00:07:58,479 --> 00:08:00,080
exploited and then that machine was

255
00:08:00,080 --> 00:08:02,319
owned so this is another story i got

256
00:08:02,319 --> 00:08:04,800
from andy because akamai was actually

257
00:08:04,800 --> 00:08:06,800
affected by this and if you hear it so

258
00:08:06,800 --> 00:08:08,960
i'm going to channel andy here

259
00:08:08,960 --> 00:08:11,120
if you if you hear him tell the story he

260
00:08:11,120 --> 00:08:12,800
actually said that the dwell time of

261
00:08:12,800 --> 00:08:14,639
this adversary was so long that they

262
00:08:14,639 --> 00:08:17,120
didn't know it was in the network

263
00:08:17,120 --> 00:08:18,400
and they didn't actually know when they

264
00:08:18,400 --> 00:08:20,000
were compromised and they don't know who

265
00:08:20,000 --> 00:08:22,319
was initially compromised so and if you

266
00:08:22,319 --> 00:08:23,919
go back and read

267
00:08:23,919 --> 00:08:26,240
the stuff from a decade ago about this

268
00:08:26,240 --> 00:08:28,240
incident it's all about the internet

269
00:08:28,240 --> 00:08:29,840
explorer vulnerability it's super

270
00:08:29,840 --> 00:08:32,080
interesting you don't really see much

271
00:08:32,080 --> 00:08:34,080
about what happened next so what

272
00:08:34,080 --> 00:08:35,919
happened next

273
00:08:35,919 --> 00:08:37,599
was that the end is so relevant because

274
00:08:37,599 --> 00:08:39,200
the talk we had before was supply chain

275
00:08:39,200 --> 00:08:41,200
attacks right what happened next was

276
00:08:41,200 --> 00:08:43,519
that the adversary was moving quoting

277
00:08:43,519 --> 00:08:46,080
andy in this the soft sticky inside of

278
00:08:46,080 --> 00:08:48,720
this uh of this squishy inside of this

279
00:08:48,720 --> 00:08:50,160
network right and sort of moving

280
00:08:50,160 --> 00:08:53,519
laterally across across these machines

281
00:08:53,519 --> 00:08:55,120
and then what it ended up doing was it

282
00:08:55,120 --> 00:08:56,320
ended up

283
00:08:56,320 --> 00:08:58,640
going to the perforce software which is

284
00:08:58,640 --> 00:08:59,920
the um

285
00:08:59,920 --> 00:09:01,760
version control software that they had

286
00:09:01,760 --> 00:09:04,480
for for their for their code

287
00:09:04,480 --> 00:09:07,120
and they were trying to sort of get

288
00:09:07,120 --> 00:09:08,880
information steal source code from all

289
00:09:08,880 --> 00:09:10,880
of these companies um so this was

290
00:09:10,880 --> 00:09:12,880
actually an early software supply chain

291
00:09:12,880 --> 00:09:14,320
attack that's what they were after they

292
00:09:14,320 --> 00:09:15,760
were after the um

293
00:09:15,760 --> 00:09:18,240
the source code and the way they did it

294
00:09:18,240 --> 00:09:20,640
was through um through lateral movement

295
00:09:20,640 --> 00:09:22,959
through this network so um if you hear

296
00:09:22,959 --> 00:09:24,560
the way that andy describes this this

297
00:09:24,560 --> 00:09:26,959
story he actually did not know that they

298
00:09:26,959 --> 00:09:28,640
were even compromised because they were

299
00:09:28,640 --> 00:09:30,959
being so quiet about it that the way

300
00:09:30,959 --> 00:09:33,360
they found out was because google had

301
00:09:33,360 --> 00:09:36,000
this these these targets the ones in red

302
00:09:36,000 --> 00:09:37,519
they were being controlled by a command

303
00:09:37,519 --> 00:09:39,360
and control server that was i believe in

304
00:09:39,360 --> 00:09:40,399
taiwan

305
00:09:40,399 --> 00:09:42,080
and um

306
00:09:42,080 --> 00:09:43,279
they didn't know that this was happening

307
00:09:43,279 --> 00:09:45,600
so at some point um they were able to

308
00:09:45,600 --> 00:09:47,519
take the adversaries command and control

309
00:09:47,519 --> 00:09:49,120
server over i believe it was google and

310
00:09:49,120 --> 00:09:50,720
then google called akamai and said hey

311
00:09:50,720 --> 00:09:52,000
guys like do you realize some of your

312
00:09:52,000 --> 00:09:53,200
machines are talking to this command and

313
00:09:53,200 --> 00:09:55,040
control server so they didn't even know

314
00:09:55,040 --> 00:09:56,399
they were inside because they were doing

315
00:09:56,399 --> 00:09:58,320
such a sort of quiet

316
00:09:58,320 --> 00:09:59,839
motion around because if you think about

317
00:09:59,839 --> 00:10:00,959
what they're trying to do which was just

318
00:10:00,959 --> 00:10:02,800
steel code you don't really want to

319
00:10:02,800 --> 00:10:04,800
expose that that's happening

320
00:10:04,800 --> 00:10:07,440
so this was um

321
00:10:07,440 --> 00:10:09,760
this was a this was a sort of very early

322
00:10:09,760 --> 00:10:11,839
example of the issue with trusting

323
00:10:11,839 --> 00:10:13,760
perimeter vpns too much so just

324
00:10:13,760 --> 00:10:16,480
believing that people are behind the vpn

325
00:10:16,480 --> 00:10:18,240
is it good enough or people not people

326
00:10:18,240 --> 00:10:20,640
machines or whatever flows of data are

327
00:10:20,640 --> 00:10:22,959
behind the vpn is not a good enough

328
00:10:22,959 --> 00:10:25,760
reason to let them access certain things

329
00:10:25,760 --> 00:10:27,440
and this is where a lot of the

330
00:10:27,440 --> 00:10:29,279
movement to like this idea of xero trust

331
00:10:29,279 --> 00:10:31,360
like don't trust people based on their

332
00:10:31,360 --> 00:10:33,839
network location um you need to trust

333
00:10:33,839 --> 00:10:35,920
them you know trust them to you need to

334
00:10:35,920 --> 00:10:37,519
actually ask them ask them to log into

335
00:10:37,519 --> 00:10:38,560
the exact

336
00:10:38,560 --> 00:10:39,760
part of the network that they're that

337
00:10:39,760 --> 00:10:41,519
they're needing to logging into

338
00:10:41,519 --> 00:10:43,760
um the other thing about this

339
00:10:43,760 --> 00:10:46,160
was that at the time andy describes

340
00:10:46,160 --> 00:10:48,079
akamai as not being a very segmented

341
00:10:48,079 --> 00:10:50,800
infrastructure so again this is 2009. so

342
00:10:50,800 --> 00:10:53,600
there was sort of this whole array of

343
00:10:53,600 --> 00:10:55,600
machines that were behind one vpn and

344
00:10:55,600 --> 00:10:57,519
you could kind of move across these

345
00:10:57,519 --> 00:10:59,600
machines so the vpn itself was not well

346
00:10:59,600 --> 00:11:01,120
segmented right so when you think about

347
00:11:01,120 --> 00:11:02,880
these types of systems and for any sort

348
00:11:02,880 --> 00:11:05,040
of access system it's important to kind

349
00:11:05,040 --> 00:11:07,600
of break up your infrastructure into

350
00:11:07,600 --> 00:11:08,560
different

351
00:11:08,560 --> 00:11:09,600
groups

352
00:11:09,600 --> 00:11:12,399
of you know sensitivity or type and make

353
00:11:12,399 --> 00:11:14,320
sure that access is not granted from one

354
00:11:14,320 --> 00:11:15,760
group to the other if it doesn't need to

355
00:11:15,760 --> 00:11:17,360
be right so this was one of the things

356
00:11:17,360 --> 00:11:19,600
that that andy describes akamai spending

357
00:11:19,600 --> 00:11:21,360
like basically 10 years doing after this

358
00:11:21,360 --> 00:11:22,800
incident

359
00:11:22,800 --> 00:11:23,760
okay

360
00:11:23,760 --> 00:11:25,040
um

361
00:11:25,040 --> 00:11:27,279
all right great

362
00:11:27,279 --> 00:11:29,839
okay this one is uh this one is is

363
00:11:29,839 --> 00:11:32,720
really interesting so um

364
00:11:32,720 --> 00:11:34,959
so has um okay so let me start with the

365
00:11:34,959 --> 00:11:37,600
the the the tool first

366
00:11:37,600 --> 00:11:41,279
so um the way that um ad administration

367
00:11:41,279 --> 00:11:45,040
works it looks a lot like a bastion host

368
00:11:45,040 --> 00:11:45,839
what

369
00:11:45,839 --> 00:11:48,000
commonly happens is you have it

370
00:11:48,000 --> 00:11:49,680
administrators that need to administrate

371
00:11:49,680 --> 00:11:51,519
a bunch of servers or laptops or

372
00:11:51,519 --> 00:11:52,720
whatever it is

373
00:11:52,720 --> 00:11:54,800
and what they typically do is they log

374
00:11:54,800 --> 00:11:56,399
into an admin server with their

375
00:11:56,399 --> 00:11:58,639
credential and then they get

376
00:11:58,639 --> 00:12:00,160
and their admin credential is then used

377
00:12:00,160 --> 00:12:01,920
to log into the actual machines that

378
00:12:01,920 --> 00:12:03,920
they're trying to um

379
00:12:03,920 --> 00:12:05,519
you know they're trying to to manage or

380
00:12:05,519 --> 00:12:07,680
do whatever they're trying to do to um

381
00:12:07,680 --> 00:12:08,480
and

382
00:12:08,480 --> 00:12:10,160
this is again this is really surprising

383
00:12:10,160 --> 00:12:11,519
to me because before i started this

384
00:12:11,519 --> 00:12:13,279
company actually a professor like i did

385
00:12:13,279 --> 00:12:14,959
never i've never done admin so i'm going

386
00:12:14,959 --> 00:12:17,519
to again channel andy here um

387
00:12:17,519 --> 00:12:19,279
a lot of organizations

388
00:12:19,279 --> 00:12:21,839
even in 2017 were using a single admin

389
00:12:21,839 --> 00:12:23,360
credential across a lot of their

390
00:12:23,360 --> 00:12:24,399
infrastructure

391
00:12:24,399 --> 00:12:26,399
so just one admin construct credential

392
00:12:26,399 --> 00:12:28,320
would control access to a lot of their

393
00:12:28,320 --> 00:12:30,320
uh of their machines

394
00:12:30,320 --> 00:12:32,720
and so um there's an article in wired

395
00:12:32,720 --> 00:12:34,800
which everyone should go read it's super

396
00:12:34,800 --> 00:12:37,120
super super uh good read like just a

397
00:12:37,120 --> 00:12:39,279
great story um the story of what

398
00:12:39,279 --> 00:12:40,800
happened at merck

399
00:12:40,800 --> 00:12:42,480
um has anyone read that wired article

400
00:12:42,480 --> 00:12:44,000
about what happened at mark during not

401
00:12:44,000 --> 00:12:45,279
petcha

402
00:12:45,279 --> 00:12:46,800
you should go read it's really it's

403
00:12:46,800 --> 00:12:48,560
really interesting so like they describe

404
00:12:48,560 --> 00:12:50,160
like people running through the halls

405
00:12:50,160 --> 00:12:52,320
like pulling machines out of the wall

406
00:12:52,320 --> 00:12:54,560
you know because in the course of an

407
00:12:54,560 --> 00:12:56,560
hour or two or three

408
00:12:56,560 --> 00:12:58,240
all of their machines were bricked by

409
00:12:58,240 --> 00:12:59,839
ransomware

410
00:12:59,839 --> 00:13:00,800
um

411
00:13:00,800 --> 00:13:03,200
and um the story starts and it's even

412
00:13:03,200 --> 00:13:04,880
more relevant today sometimes revisiting

413
00:13:04,880 --> 00:13:06,639
these things is so interesting you know

414
00:13:06,639 --> 00:13:08,000
later because

415
00:13:08,000 --> 00:13:10,720
this was there was one machine this is

416
00:13:10,720 --> 00:13:12,480
an early this is a watering hole attack

417
00:13:12,480 --> 00:13:13,839
is people familiar with the notion of

418
00:13:13,839 --> 00:13:15,839
watering hall attack okay so watering

419
00:13:15,839 --> 00:13:17,760
hole attack for those who don't know is

420
00:13:17,760 --> 00:13:20,720
when you hack something right in this

421
00:13:20,720 --> 00:13:23,200
case it's a ukrainian tax software

422
00:13:23,200 --> 00:13:25,680
and you wait for people to interact with

423
00:13:25,680 --> 00:13:27,839
that thing that you've hacked and once

424
00:13:27,839 --> 00:13:29,519
you interact with it you get hit by

425
00:13:29,519 --> 00:13:31,839
malware right so what happened here was

426
00:13:31,839 --> 00:13:32,720
there

427
00:13:32,720 --> 00:13:34,480
according to the wired story which talks

428
00:13:34,480 --> 00:13:36,399
about merck and how merck was hit by

429
00:13:36,399 --> 00:13:37,519
this

430
00:13:37,519 --> 00:13:39,440
they had one server that was interacting

431
00:13:39,440 --> 00:13:42,399
with this ukrainian accounting software

432
00:13:42,399 --> 00:13:45,440
and when it did the software update

433
00:13:45,440 --> 00:13:46,839
that software was a

434
00:13:46,839 --> 00:13:50,000
malware and what happened what that

435
00:13:50,000 --> 00:13:52,320
malware appears to have done

436
00:13:52,320 --> 00:13:56,160
is stolen the admin credential

437
00:13:56,160 --> 00:13:58,240
okay so now um

438
00:13:58,240 --> 00:14:01,040
this one basically they talk about one

439
00:14:01,040 --> 00:14:03,600
machine in in ukraine

440
00:14:03,600 --> 00:14:06,000
that was compromised and

441
00:14:06,000 --> 00:14:08,480
this credential was then stolen and then

442
00:14:08,480 --> 00:14:10,560
it was used to basically log into all of

443
00:14:10,560 --> 00:14:11,440
these

444
00:14:11,440 --> 00:14:14,000
machines with administrative access

445
00:14:14,000 --> 00:14:16,560
and it was all done very very quickly so

446
00:14:16,560 --> 00:14:18,720
um so so you get the story of like all

447
00:14:18,720 --> 00:14:20,160
the machines getting pulled out of the

448
00:14:20,160 --> 00:14:22,800
walls um and people just like throwing

449
00:14:22,800 --> 00:14:24,399
their laptops away or turning them off

450
00:14:24,399 --> 00:14:27,040
so that this would stop propagating

451
00:14:27,040 --> 00:14:29,440
um and it took them like two

452
00:14:29,440 --> 00:14:32,399
like two weeks to sort of re reissue

453
00:14:32,399 --> 00:14:33,920
computers to everyone in the company

454
00:14:33,920 --> 00:14:35,279
because all the computers were basically

455
00:14:35,279 --> 00:14:36,959
bricked in this way um and it was

456
00:14:36,959 --> 00:14:39,040
because the ad credential is so powerful

457
00:14:39,040 --> 00:14:42,160
so this is like um

458
00:14:42,160 --> 00:14:44,399
okay so this is this is why i like i

459
00:14:44,399 --> 00:14:47,120
really think about this a lot because um

460
00:14:47,120 --> 00:14:48,560
we have a tendency in the security

461
00:14:48,560 --> 00:14:50,480
industry to like

462
00:14:50,480 --> 00:14:53,040
solve problems that when we worry about

463
00:14:53,040 --> 00:14:54,880
our users getting hacked right we worry

464
00:14:54,880 --> 00:14:56,160
about our users getting hacked so we

465
00:14:56,160 --> 00:14:57,600
solve the problem by putting in some

466
00:14:57,600 --> 00:15:00,320
kind of trusted system that's going to

467
00:15:00,320 --> 00:15:01,519
eliminate

468
00:15:01,519 --> 00:15:03,519
the risk of the users getting hacked

469
00:15:03,519 --> 00:15:06,320
right but the system itself may be

470
00:15:06,320 --> 00:15:07,920
extremely overprivileged right the

471
00:15:07,920 --> 00:15:09,440
system itself may have really really

472
00:15:09,440 --> 00:15:11,760
deep privileges into your infrastructure

473
00:15:11,760 --> 00:15:13,760
and so if someone actually compromises

474
00:15:13,760 --> 00:15:15,920
that system then the impact is really

475
00:15:15,920 --> 00:15:17,519
big so that's why i bring this example

476
00:15:17,519 --> 00:15:19,600
up specifically like i'm just giving my

477
00:15:19,600 --> 00:15:21,519
spin on it is that like it's crazy that

478
00:15:21,519 --> 00:15:22,880
there was one admin credential here and

479
00:15:22,880 --> 00:15:24,320
it was used across the board to attack

480
00:15:24,320 --> 00:15:25,600
everything

481
00:15:25,600 --> 00:15:28,000
but it's something to think about so

482
00:15:28,000 --> 00:15:28,959
um

483
00:15:28,959 --> 00:15:30,639
so admin credentials with over broad

484
00:15:30,639 --> 00:15:31,920
scope danger

485
00:15:31,920 --> 00:15:33,759
segment your infrastructure

486
00:15:33,759 --> 00:15:36,079
admin is a single point of compromise um

487
00:15:36,079 --> 00:15:37,519
and you know we already talked about

488
00:15:37,519 --> 00:15:38,880
software supply chain i actually didn't

489
00:15:38,880 --> 00:15:40,079
realize i was going to be talking right

490
00:15:40,079 --> 00:15:42,720
after a software supply chain talk

491
00:15:42,720 --> 00:15:44,800
but that's other another important thing

492
00:15:44,800 --> 00:15:46,639
so i think one thing to take out of this

493
00:15:46,639 --> 00:15:48,399
is like when you think about what you've

494
00:15:48,399 --> 00:15:50,480
built or what your systems look like

495
00:15:50,480 --> 00:15:52,240
like try to think if there's one master

496
00:15:52,240 --> 00:15:53,839
credential in there somewhere that if

497
00:15:53,839 --> 00:15:55,680
hacked like terrible things happen a lot

498
00:15:55,680 --> 00:15:57,199
of times these things exist and nobody

499
00:15:57,199 --> 00:15:59,519
notices um and this this but not pecha

500
00:15:59,519 --> 00:16:01,600
incident is a good example of like

501
00:16:01,600 --> 00:16:03,279
terrible things that can happen if you

502
00:16:03,279 --> 00:16:05,199
do that and and so for example with ad

503
00:16:05,199 --> 00:16:07,440
administration you want to have you know

504
00:16:07,440 --> 00:16:08,880
tiered administration you want to have

505
00:16:08,880 --> 00:16:09,920
different credentials for different

506
00:16:09,920 --> 00:16:11,120
parts of the network and things like

507
00:16:11,120 --> 00:16:12,880
that but that wasn't necessarily done

508
00:16:12,880 --> 00:16:14,639
and actually was surprised to see this

509
00:16:14,639 --> 00:16:16,399
but this was 2017. so it wasn't really

510
00:16:16,399 --> 00:16:18,320
that long ago that people still had

511
00:16:18,320 --> 00:16:20,480
architectures like this

512
00:16:20,480 --> 00:16:21,360
okay

513
00:16:21,360 --> 00:16:24,880
any um okay so i'll keep going

514
00:16:24,880 --> 00:16:26,959
great

515
00:16:26,959 --> 00:16:29,040
all right so so enter zero trust right

516
00:16:29,040 --> 00:16:31,440
so like three incidents to set us up to

517
00:16:31,440 --> 00:16:32,880
to look at why these zero trust

518
00:16:32,880 --> 00:16:35,440
approaches um are are important how many

519
00:16:35,440 --> 00:16:36,800
people are rolling their eyes when i say

520
00:16:36,800 --> 00:16:39,359
zero trust

521
00:16:39,600 --> 00:16:41,120
okay so everyone's rolling their eyes it

522
00:16:41,120 --> 00:16:42,720
has it has meaning so i'm gonna put my

523
00:16:42,720 --> 00:16:44,720
professor hat on it actually has meaning

524
00:16:44,720 --> 00:16:46,320
it has real meaning to me and by the way

525
00:16:46,320 --> 00:16:47,759
when we started bastion zero and that

526
00:16:47,759 --> 00:16:49,440
zero was partly zero trust and partly

527
00:16:49,440 --> 00:16:51,680
zero bastions when we started

528
00:16:51,680 --> 00:16:53,600
bastion zero we were like talking about

529
00:16:53,600 --> 00:16:54,959
zero testing we didn't understand what

530
00:16:54,959 --> 00:16:55,920
it meant

531
00:16:55,920 --> 00:16:57,279
so i'll tell you what i think it means

532
00:16:57,279 --> 00:16:58,639
for access

533
00:16:58,639 --> 00:17:00,880
for this specific problem space which is

534
00:17:00,880 --> 00:17:02,720
access remote access what does zero

535
00:17:02,720 --> 00:17:05,599
trust mean it means don't trust the user

536
00:17:05,599 --> 00:17:07,439
with long live credentials don't trust

537
00:17:07,439 --> 00:17:09,520
the user because of their ip address

538
00:17:09,520 --> 00:17:11,439
that's what it means so it's all about

539
00:17:11,439 --> 00:17:13,839
the user right make sure that you're not

540
00:17:13,839 --> 00:17:16,079
assuming that just because someone

541
00:17:16,079 --> 00:17:18,319
has a particular network address they

542
00:17:18,319 --> 00:17:20,880
should be good to access something make

543
00:17:20,880 --> 00:17:22,640
sure you're not giving them a long-lived

544
00:17:22,640 --> 00:17:24,319
credential so that it doesn't get stolen

545
00:17:24,319 --> 00:17:26,160
like it did with fluffy bunny right that

546
00:17:26,160 --> 00:17:27,679
that's what that's what zero trust tends

547
00:17:27,679 --> 00:17:29,679
to mean um and that those are like

548
00:17:29,679 --> 00:17:31,120
despite you rolling your eyes those are

549
00:17:31,120 --> 00:17:32,799
like legitimately worthy goals that i

550
00:17:32,799 --> 00:17:35,039
think people could agree to do right and

551
00:17:35,039 --> 00:17:37,679
i know that the term is highly used but

552
00:17:37,679 --> 00:17:39,440
that's what it means right so this is a

553
00:17:39,440 --> 00:17:41,120
picture of a way to build a zero trust

554
00:17:41,120 --> 00:17:42,320
system

555
00:17:42,320 --> 00:17:45,120
how do we actually implement this

556
00:17:45,120 --> 00:17:47,200
there's a lot of different ways um so

557
00:17:47,200 --> 00:17:48,960
you can you can build different kinds of

558
00:17:48,960 --> 00:17:50,799
authentication systems that will provide

559
00:17:50,799 --> 00:17:53,440
this type of zero trust system right so

560
00:17:53,440 --> 00:17:55,440
you can build a certificate authority

561
00:17:55,440 --> 00:17:56,640
that would issue short-lived

562
00:17:56,640 --> 00:17:58,400
certificates to the user whenever they

563
00:17:58,400 --> 00:18:00,559
log in right so they authenticate to the

564
00:18:00,559 --> 00:18:02,160
certificate authority imagine the yellow

565
00:18:02,160 --> 00:18:03,919
box is a certificate authority they

566
00:18:03,919 --> 00:18:05,760
authenticate to that thing they get a

567
00:18:05,760 --> 00:18:08,000
short-lived certificate and that lets

568
00:18:08,000 --> 00:18:09,520
them access the target that they want to

569
00:18:09,520 --> 00:18:11,120
access and then the certificate expires

570
00:18:11,120 --> 00:18:12,799
after an hour or five minutes and then

571
00:18:12,799 --> 00:18:14,000
they can't get access until they

572
00:18:14,000 --> 00:18:15,440
authenticate again so that's a great

573
00:18:15,440 --> 00:18:17,120
example of zero trust access with a

574
00:18:17,120 --> 00:18:18,720
certificate authority you can do the

575
00:18:18,720 --> 00:18:20,160
same thing with a single sign-on right

576
00:18:20,160 --> 00:18:21,600
you can log into your g suite or your

577
00:18:21,600 --> 00:18:23,600
octa and then you can get a short-lived

578
00:18:23,600 --> 00:18:24,960
token that would give you access to the

579
00:18:24,960 --> 00:18:26,160
targets

580
00:18:26,160 --> 00:18:27,600
so there's lots of different ways to do

581
00:18:27,600 --> 00:18:28,400
this

582
00:18:28,400 --> 00:18:30,880
um and

583
00:18:30,880 --> 00:18:33,360
um you know this is a picture of uh zero

584
00:18:33,360 --> 00:18:34,799
trust with a certificate authority right

585
00:18:34,799 --> 00:18:36,720
so so alice over here

586
00:18:36,720 --> 00:18:39,440
is um is is getting access from the ca

587
00:18:39,440 --> 00:18:41,200
to a particular um

588
00:18:41,200 --> 00:18:43,840
to a particular target and and um that's

589
00:18:43,840 --> 00:18:46,320
the example of the certificate

590
00:18:46,320 --> 00:18:47,840
um if you do it with an sso what you

591
00:18:47,840 --> 00:18:49,760
might get is something like a saml token

592
00:18:49,760 --> 00:18:51,840
or an open id connect

593
00:18:51,840 --> 00:18:52,960
you know

594
00:18:52,960 --> 00:18:54,960
jot but anything like this it's a

595
00:18:54,960 --> 00:18:56,240
short-lived token a short-lived

596
00:18:56,240 --> 00:18:57,919
credential that the target uses to

597
00:18:57,919 --> 00:19:00,799
determine if the user should have access

598
00:19:00,799 --> 00:19:01,760
okay

599
00:19:01,760 --> 00:19:04,720
so so this is cool so so like i'll just

600
00:19:04,720 --> 00:19:06,240
tell a personal story when we started

601
00:19:06,240 --> 00:19:08,559
bastion zero um we looked at zero trust

602
00:19:08,559 --> 00:19:10,080
and we realized what zero trust means is

603
00:19:10,080 --> 00:19:11,280
like basically one of these things that

604
00:19:11,280 --> 00:19:13,840
i showed you and then i said wait a

605
00:19:13,840 --> 00:19:15,760
minute certificates like

606
00:19:15,760 --> 00:19:17,039
here's something that i've been teaching

607
00:19:17,039 --> 00:19:19,120
in my class since it happened and i will

608
00:19:19,120 --> 00:19:20,799
say that this incident for me is in my

609
00:19:20,799 --> 00:19:22,720
list of top five security incidents for

610
00:19:22,720 --> 00:19:23,919
me personally and i think it's because

611
00:19:23,919 --> 00:19:25,280
it happened in the in the second year

612
00:19:25,280 --> 00:19:26,720
that i was a professor so it was like in

613
00:19:26,720 --> 00:19:29,600
my formative formative youth this

614
00:19:29,600 --> 00:19:31,919
happened um so how many people know the

615
00:19:31,919 --> 00:19:34,960
digi notar incident

616
00:19:35,440 --> 00:19:38,640
so not everyone have you heard of it

617
00:19:38,640 --> 00:19:39,840
heard of it okay so a lot of people

618
00:19:39,840 --> 00:19:41,039
haven't heard of it this is like

619
00:19:41,039 --> 00:19:43,120
watershed security incident but it's not

620
00:19:43,120 --> 00:19:45,840
in um cloud it's in tls but here's what

621
00:19:45,840 --> 00:19:48,799
happened so there was a ca um in the

622
00:19:48,799 --> 00:19:51,280
netherlands called diginotar and what it

623
00:19:51,280 --> 00:19:54,960
does is it provides access to

624
00:19:54,960 --> 00:19:56,880
sites in the netherlands like the dmv

625
00:19:56,880 --> 00:19:58,240
and things like this

626
00:19:58,240 --> 00:20:01,440
it got hacked and the key was stolen

627
00:20:01,440 --> 00:20:03,039
and so the adversary actually had the

628
00:20:03,039 --> 00:20:04,400
signing key for the certificate

629
00:20:04,400 --> 00:20:06,799
authority and it was able to issue

630
00:20:06,799 --> 00:20:08,799
certificates for whatever it wanted what

631
00:20:08,799 --> 00:20:10,720
it decided to do was issue certificates

632
00:20:10,720 --> 00:20:11,760
for google

633
00:20:11,760 --> 00:20:13,520
and hijack google traffic and it was

634
00:20:13,520 --> 00:20:15,200
actually able to introspect on tls

635
00:20:15,200 --> 00:20:17,600
traffic for google this incident

636
00:20:17,600 --> 00:20:18,880
highlighted

637
00:20:18,880 --> 00:20:20,400
a couple of things it highlighted that

638
00:20:20,400 --> 00:20:22,559
cas are a single point of compromise if

639
00:20:22,559 --> 00:20:24,799
trusted blindly and they get compromised

640
00:20:24,799 --> 00:20:26,320
it's super bad it's very similar to the

641
00:20:26,320 --> 00:20:28,480
idea of the ad credential

642
00:20:28,480 --> 00:20:30,240
and um and this is actually what

643
00:20:30,240 --> 00:20:32,000
happened in the tls world as the tls

644
00:20:32,000 --> 00:20:33,760
world moved on from cas and started

645
00:20:33,760 --> 00:20:34,720
doing things like certificate

646
00:20:34,720 --> 00:20:36,320
transparency and certificate pinning and

647
00:20:36,320 --> 00:20:37,520
all these other really great things to

648
00:20:37,520 --> 00:20:39,760
like lessen the risk from cas

649
00:20:39,760 --> 00:20:41,919
um

650
00:20:41,919 --> 00:20:44,080
okay solar winds so everyone or wind

651
00:20:44,080 --> 00:20:46,320
incident do people know about the saml

652
00:20:46,320 --> 00:20:48,480
part of the solarwinds incident the

653
00:20:48,480 --> 00:20:49,679
sample part okay so everyone knows the

654
00:20:49,679 --> 00:20:51,200
sample part so just really quickly one

655
00:20:51,200 --> 00:20:52,320
of the things that happened with

656
00:20:52,320 --> 00:20:54,320
solarwinds after the adversary

657
00:20:54,320 --> 00:20:55,679
compromised all the things that they

658
00:20:55,679 --> 00:20:57,280
compromised they actually went after the

659
00:20:57,280 --> 00:20:59,760
adfs server for their victims and they

660
00:20:59,760 --> 00:21:02,000
stole the adfs server signing key so

661
00:21:02,000 --> 00:21:03,919
they were able to create their own sso

662
00:21:03,919 --> 00:21:05,679
tokens for anything they wanted and once

663
00:21:05,679 --> 00:21:06,960
they did that they could log into

664
00:21:06,960 --> 00:21:09,039
anything they wanted so they're all the

665
00:21:09,039 --> 00:21:10,320
things that happened in solarwinds but

666
00:21:10,320 --> 00:21:11,600
this was the ultimate thing that they

667
00:21:11,600 --> 00:21:12,880
hacked and from there they owned the

668
00:21:12,880 --> 00:21:14,960
entire network for their victims right

669
00:21:14,960 --> 00:21:16,480
so again another example of like

670
00:21:16,480 --> 00:21:20,080
trusting sso too much dangerous right um

671
00:21:20,080 --> 00:21:21,600
okay question for you in my remaining

672
00:21:21,600 --> 00:21:23,918
time

673
00:21:24,000 --> 00:21:25,840
so you get my point um question for you

674
00:21:25,840 --> 00:21:27,840
in my remaining time if we had mfa would

675
00:21:27,840 --> 00:21:28,960
that have stopped the solarwinds

676
00:21:28,960 --> 00:21:31,840
incident

677
00:21:33,679 --> 00:21:36,559
it depends awesome yes so if we had mfa

678
00:21:36,559 --> 00:21:37,760
like in my picture would have stopped

679
00:21:37,760 --> 00:21:40,080
the solarwinds incident

680
00:21:40,080 --> 00:21:42,080
no right because who cares right because

681
00:21:42,080 --> 00:21:43,520
the adversary would have still stolen

682
00:21:43,520 --> 00:21:45,440
this key and walked away with the key

683
00:21:45,440 --> 00:21:47,120
and made tamil tokens for itself right

684
00:21:47,120 --> 00:21:49,280
if mfa goes to the sso provider then

685
00:21:49,280 --> 00:21:51,679
it's no good to stop attacks on the sso

686
00:21:51,679 --> 00:21:54,320
provider right so here's an alternative

687
00:21:54,320 --> 00:21:56,320
architecture and then i'm done right

688
00:21:56,320 --> 00:21:57,919
another way if we actually used if they

689
00:21:57,919 --> 00:22:00,159
had used mfa in this way then it

690
00:22:00,159 --> 00:22:01,280
wouldn't have it would have actually

691
00:22:01,280 --> 00:22:02,960
been able to stop the attack right if

692
00:22:02,960 --> 00:22:05,039
the mfa was a separate

693
00:22:05,039 --> 00:22:06,960
component in the system and the mfa

694
00:22:06,960 --> 00:22:08,720
wasn't going to the sso provider then

695
00:22:08,720 --> 00:22:10,080
the adversary would then need to

696
00:22:10,080 --> 00:22:13,120
compromise both the sso and the mfa in

697
00:22:13,120 --> 00:22:14,880
order to access the targets right do you

698
00:22:14,880 --> 00:22:17,039
see the difference right because the sso

699
00:22:17,039 --> 00:22:18,880
is you know the targets are validating

700
00:22:18,880 --> 00:22:20,480
token from the mfa you can see the

701
00:22:20,480 --> 00:22:22,480
orange token and they're also validating

702
00:22:22,480 --> 00:22:24,720
the yellow token both of them separately

703
00:22:24,720 --> 00:22:26,159
and that's what's required to access the

704
00:22:26,159 --> 00:22:27,600
target so if you think about the way you

705
00:22:27,600 --> 00:22:29,919
build access systems a better way to do

706
00:22:29,919 --> 00:22:31,200
it is if you're going to put something

707
00:22:31,200 --> 00:22:33,120
behind an sso you should have an

708
00:22:33,120 --> 00:22:34,720
independent mfa as well that you don't

709
00:22:34,720 --> 00:22:36,960
have to risk the sso getting compromised

710
00:22:36,960 --> 00:22:38,559
so spoiler this is basically what our

711
00:22:38,559 --> 00:22:40,400
architecture looks like right so the

712
00:22:40,400 --> 00:22:41,919
idea is when you think about zero trust

713
00:22:41,919 --> 00:22:43,120
and you think about access it's

714
00:22:43,120 --> 00:22:44,400
important to think about the users

715
00:22:44,400 --> 00:22:46,400
getting hacked super important right

716
00:22:46,400 --> 00:22:47,919
like the first three stories that i told

717
00:22:47,919 --> 00:22:49,760
you but then also think about your

718
00:22:49,760 --> 00:22:51,440
access system getting hacked and how do

719
00:22:51,440 --> 00:22:52,880
you actually stop that from happening

720
00:22:52,880 --> 00:22:54,320
and that's really where our focus is in

721
00:22:54,320 --> 00:22:55,360
the company

722
00:22:55,360 --> 00:22:56,640
and i'm happy to tell you more but i

723
00:22:56,640 --> 00:22:58,159
don't have any more time

724
00:22:58,159 --> 00:23:00,240
so this is okay this is a picture

725
00:23:00,240 --> 00:23:02,960
basically of how we do it

726
00:23:02,960 --> 00:23:06,080
and i can tell you more about that later

727
00:23:06,080 --> 00:23:08,559
but this is the bottom line right so we

728
00:23:08,559 --> 00:23:10,559
think about securing the users we don't

729
00:23:10,559 --> 00:23:11,840
want the users to have standing

730
00:23:11,840 --> 00:23:13,520
credentials we don't want to trust a

731
00:23:13,520 --> 00:23:14,799
user just because of their network

732
00:23:14,799 --> 00:23:16,480
location those are the two tenants of

733
00:23:16,480 --> 00:23:18,640
zero trust segment your infrastructure

734
00:23:18,640 --> 00:23:21,200
also arguably a tenant of zero trust but

735
00:23:21,200 --> 00:23:23,440
then in building such a system be

736
00:23:23,440 --> 00:23:24,960
careful that you don't put a giant

737
00:23:24,960 --> 00:23:26,640
credential in there a giant ca or

738
00:23:26,640 --> 00:23:28,240
something like this that controls access

739
00:23:28,240 --> 00:23:30,159
to everything because if you do that is

740
00:23:30,159 --> 00:23:31,520
where the adversary will go and we've

741
00:23:31,520 --> 00:23:33,280
seen the adversary go there right so

742
00:23:33,280 --> 00:23:36,080
it's another thing to think about

743
00:23:36,080 --> 00:23:38,480
and with that i will be done

744
00:23:38,480 --> 00:23:40,240
the slides are available on our website

745
00:23:40,240 --> 00:23:42,400
i'm on twitter as well so you know

746
00:23:42,400 --> 00:23:43,760
please reach out and let me know your

747
00:23:43,760 --> 00:23:45,039
thoughts about this talk i'd love to

748
00:23:45,039 --> 00:23:46,159
hear about kind of what you've been

749
00:23:46,159 --> 00:23:47,679
thinking about with regards to this

750
00:23:47,679 --> 00:23:48,559
problem

751
00:23:48,559 --> 00:23:50,060
so yeah thanks

752
00:23:50,060 --> 00:23:55,389
[Applause]

753
00:23:57,039 --> 00:23:58,159
okay

754
00:23:58,159 --> 00:24:00,000
okay we have one minute for questions if

755
00:24:00,000 --> 00:24:03,799
anybody has any questions

756
00:24:05,679 --> 00:24:07,600
questions questions okay i'll just say

757
00:24:07,600 --> 00:24:09,360
recommended reading that article about

758
00:24:09,360 --> 00:24:11,039
merck getting hacked

759
00:24:11,039 --> 00:24:12,400
everybody read the did you know tar

760
00:24:12,400 --> 00:24:13,679
incident everyone needs to know about

761
00:24:13,679 --> 00:24:16,240
that yeah

762
00:24:16,320 --> 00:24:18,559
sand worm that's so if you don't want to

763
00:24:18,559 --> 00:24:20,000
buy the book you can read the article in

764
00:24:20,000 --> 00:24:22,000
wired which is an excerpt from the book

765
00:24:22,000 --> 00:24:24,240
yeah

766
00:24:24,880 --> 00:24:26,240
your question

767
00:24:26,240 --> 00:24:29,200
okay awesome thank you everyone

768
00:24:29,200 --> 00:24:32,320
thank you

769
00:24:32,320 --> 00:24:34,399
you

