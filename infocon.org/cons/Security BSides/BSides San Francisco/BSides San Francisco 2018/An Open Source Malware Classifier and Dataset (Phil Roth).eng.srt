1
00:00:03,620 --> 00:00:06,740
[Music]

2
00:00:19,600 --> 00:00:27,160
<font color="#E5E5E5">all right thanks so yeah my name is Phil</font>

3
00:00:24,310 --> 00:00:29,500
Roth<font color="#E5E5E5"> I'm a data scientist at endgame and</font>

4
00:00:27,160 --> 00:00:31,690
along with<font color="#E5E5E5"> my colleague</font><font color="#CCCCCC"> Hyrum we've</font>

5
00:00:29,500 --> 00:00:35,260
released<font color="#E5E5E5"> amber which</font><font color="#CCCCCC"> is an open-source</font>

6
00:00:31,690 --> 00:00:37,809
malware classifier and<font color="#E5E5E5"> dataset so first</font>

7
00:00:35,260 --> 00:00:39,670
I want<font color="#E5E5E5"> to talk a little bit</font><font color="#CCCCCC"> about why we</font>

8
00:00:37,809 --> 00:00:43,330
<font color="#CCCCCC">would want</font><font color="#E5E5E5"> to do this and what motivated</font>

9
00:00:39,670 --> 00:00:45,910
us so open<font color="#CCCCCC"> datasets</font><font color="#E5E5E5"> push machine</font>

10
00:00:43,330 --> 00:00:47,920
<font color="#E5E5E5">learning research forward</font><font color="#CCCCCC"> so there's</font>

11
00:00:45,910 --> 00:00:49,300
<font color="#E5E5E5">been a lot of advances in machine</font>

12
00:00:47,920 --> 00:00:51,449
<font color="#CCCCCC">learning in general</font><font color="#E5E5E5"> in a lot of</font>

13
00:00:49,300 --> 00:00:54,239
different areas over the<font color="#E5E5E5"> last</font><font color="#CCCCCC"> ten years</font>

14
00:00:51,449 --> 00:00:57,070
<font color="#CCCCCC">areas like optical character recognition</font>

15
00:00:54,239 --> 00:00:59,409
<font color="#E5E5E5">and</font><font color="#CCCCCC"> you know machine translation and</font>

16
00:00:57,070 --> 00:01:01,809
<font color="#E5E5E5">also identifying objects and images</font><font color="#CCCCCC"> and</font>

17
00:00:59,409 --> 00:01:03,729
there's a lot<font color="#E5E5E5"> of reasons</font><font color="#CCCCCC"> for that</font>

18
00:01:01,809 --> 00:01:06,460
you know<font color="#CCCCCC"> hardware there's been a lot of</font>

19
00:01:03,729 --> 00:01:08,320
advances<font color="#CCCCCC"> in</font><font color="#E5E5E5"> Hardware datasets are</font>

20
00:01:06,460 --> 00:01:10,658
getting much larger<font color="#E5E5E5"> but an important</font>

21
00:01:08,320 --> 00:01:12,850
<font color="#CCCCCC">reason I believe</font><font color="#E5E5E5"> is the presence of open</font>

22
00:01:10,659 --> 00:01:16,360
benchmark<font color="#E5E5E5"> datasets for researchers to</font>

23
00:01:12,850 --> 00:01:18,250
<font color="#CCCCCC">use so</font><font color="#E5E5E5"> what you're seeing here is a this</font>

24
00:01:16,360 --> 00:01:20,620
<font color="#E5E5E5">is a plot</font><font color="#CCCCCC"> of like 20 different open</font>

25
00:01:18,250 --> 00:01:22,750
benchmark<font color="#CCCCCC"> datasets</font><font color="#E5E5E5"> in the machine</font>

26
00:01:20,620 --> 00:01:24,009
<font color="#E5E5E5">learning research community and this is</font>

27
00:01:22,750 --> 00:01:26,530
<font color="#E5E5E5">just the number of times that they're</font>

28
00:01:24,009 --> 00:01:28,659
cited at a large machine<font color="#E5E5E5"> learning</font>

29
00:01:26,530 --> 00:01:30,399
conference called<font color="#E5E5E5"> nits and you can see</font>

30
00:01:28,659 --> 00:01:32,350
that<font color="#CCCCCC"> benchmark data</font><font color="#E5E5E5"> sets have been</font>

31
00:01:30,399 --> 00:01:33,880
<font color="#E5E5E5">around for a long long</font><font color="#CCCCCC"> time</font><font color="#E5E5E5"> but it's</font>

32
00:01:32,350 --> 00:01:39,130
really<font color="#CCCCCC"> been in</font><font color="#E5E5E5"> the last</font><font color="#CCCCCC"> 10 years that</font>

33
00:01:33,880 --> 00:01:43,600
their use has taken off<font color="#CCCCCC"> one example from</font>

34
00:01:39,130 --> 00:01:46,359
<font color="#E5E5E5">that previous slide was</font><font color="#CCCCCC"> Amnesty</font><font color="#E5E5E5"> this is</font>

35
00:01:43,600 --> 00:01:49,000
<font color="#E5E5E5">a open data set of like 70,000 images of</font>

36
00:01:46,359 --> 00:01:51,908
handwritten digits<font color="#E5E5E5"> you can see some</font>

37
00:01:49,000 --> 00:01:53,880
<font color="#CCCCCC">examples there so what researchers can</font>

38
00:01:51,909 --> 00:01:57,460
do then<font color="#E5E5E5"> is just train their model on</font>

39
00:01:53,880 --> 00:01:59,589
<font color="#E5E5E5">60,000 of those images</font><font color="#CCCCCC"> and you know then</font>

40
00:01:57,460 --> 00:02:02,859
test how<font color="#CCCCCC"> well their model identifies the</font>

41
00:01:59,590 --> 00:02:06,340
correct digit in the left over 10,000

42
00:02:02,859 --> 00:02:07,600
<font color="#CCCCCC">images so it's become very</font><font color="#E5E5E5"> important to</font>

43
00:02:06,340 --> 00:02:09,759
the community<font color="#E5E5E5"> and one of the leading</font>

44
00:02:07,600 --> 00:02:12,519
researchers has said<font color="#E5E5E5"> amnesty is the neat</font>

45
00:02:09,758 --> 00:02:14,619
new unit test<font color="#CCCCCC"> and kind of</font><font color="#E5E5E5"> what he meant</font>

46
00:02:12,520 --> 00:02:16,960
there is that the algorithms<font color="#E5E5E5"> have gone</font>

47
00:02:14,620 --> 00:02:19,300
even<font color="#E5E5E5"> beyond the point where M NIST can</font>

48
00:02:16,960 --> 00:02:21,580
measure how well they're doing<font color="#E5E5E5"> but even</font>

49
00:02:19,300 --> 00:02:23,650
in that<font color="#E5E5E5"> case amnesty is still important</font>

50
00:02:21,580 --> 00:02:26,350
as kind of<font color="#E5E5E5"> like</font><font color="#CCCCCC"> a sanity check</font><font color="#E5E5E5"> on to</font>

51
00:02:23,650 --> 00:02:30,550
make<font color="#E5E5E5"> sure that the algorithms are doing</font>

52
00:02:26,350 --> 00:02:31,960
<font color="#E5E5E5">what you</font><font color="#CCCCCC"> expect</font><font color="#E5E5E5"> them to do so security</font>

53
00:02:30,550 --> 00:02:33,400
<font color="#CCCCCC">locks these datasets and</font><font color="#E5E5E5"> this is</font>

54
00:02:31,960 --> 00:02:35,200
<font color="#E5E5E5">something I've been saying ever since</font>

55
00:02:33,400 --> 00:02:38,379
kind of<font color="#E5E5E5"> joined the security industry</font>

56
00:02:35,200 --> 00:02:40,000
<font color="#CCCCCC">four or</font><font color="#E5E5E5"> five years ago</font><font color="#CCCCCC"> yeah you can see</font>

57
00:02:38,379 --> 00:02:42,909
some examples<font color="#CCCCCC"> of</font><font color="#E5E5E5"> me talking about</font><font color="#CCCCCC"> this</font>

58
00:02:40,000 --> 00:02:45,159
<font color="#CCCCCC">there</font><font color="#E5E5E5"> over the years but there's a lot</font>

59
00:02:42,909 --> 00:02:46,120
<font color="#E5E5E5">of good reasons for why why security</font>

60
00:02:45,159 --> 00:02:48,040
locks these<font color="#CCCCCC"> datasets</font>

61
00:02:46,120 --> 00:02:50,829
there's personally identifiable

62
00:02:48,040 --> 00:02:52,599
<font color="#CCCCCC">information in them companies might not</font>

63
00:02:50,829 --> 00:02:54,609
want<font color="#E5E5E5"> to release you know network logs or</font>

64
00:02:52,599 --> 00:02:56,349
network infrastructure<font color="#CCCCCC"> yeah</font><font color="#E5E5E5"> because</font>

65
00:02:54,609 --> 00:02:58,870
<font color="#CCCCCC">they're afraid that attackers</font><font color="#E5E5E5"> would get</font>

66
00:02:56,349 --> 00:03:01,060
too much<font color="#CCCCCC"> information from that and</font><font color="#E5E5E5"> also</font>

67
00:02:58,870 --> 00:03:03,879
you know<font color="#E5E5E5"> companies don't want to release</font>

68
00:03:01,060 --> 00:03:07,180
their<font color="#CCCCCC"> own intellectual</font><font color="#E5E5E5"> property that</font>

69
00:03:03,879 --> 00:03:09,548
last reason is a good<font color="#E5E5E5"> reason why open</font>

70
00:03:07,180 --> 00:03:11,470
<font color="#E5E5E5">datasets don't exist in the field that</font>

71
00:03:09,549 --> 00:03:13,450
I'm in which<font color="#CCCCCC"> is</font><font color="#E5E5E5"> kind of static</font>

72
00:03:11,470 --> 00:03:16,359
classification of malware<font color="#CCCCCC"> this is just a</font>

73
00:03:13,450 --> 00:03:18,250
one application<font color="#CCCCCC"> of machine learning in</font>

74
00:03:16,359 --> 00:03:21,700
the security industry<font color="#E5E5E5"> but it's the one</font>

75
00:03:18,250 --> 00:03:23,829
I'm gonna focus on on this talk<font color="#E5E5E5"> so what</font>

76
00:03:21,700 --> 00:03:25,929
are<font color="#E5E5E5"> we trying to do it pretty much it's</font>

77
00:03:23,829 --> 00:03:27,909
<font color="#E5E5E5">just the antivirus problem it's you have</font>

78
00:03:25,930 --> 00:03:30,220
a new Windows PE file that you haven't

79
00:03:27,909 --> 00:03:33,638
seen before<font color="#E5E5E5"> and you want to know is it</font>

80
00:03:30,220 --> 00:03:35,379
benign or<font color="#E5E5E5"> malicious so there's a lot of</font>

81
00:03:33,639 --> 00:03:37,239
ways to solve<font color="#E5E5E5"> this problem we're coming</font>

82
00:03:35,379 --> 00:03:39,429
at the problem with machine learning<font color="#E5E5E5"> so</font>

83
00:03:37,239 --> 00:03:42,160
we're extracting all kinds of<font color="#CCCCCC"> features</font>

84
00:03:39,430 --> 00:03:44,620
from these files<font color="#E5E5E5"> you know as many as</font>

85
00:03:42,160 --> 00:03:46,629
<font color="#CCCCCC">2000 or so but in</font><font color="#E5E5E5"> this simple example</font>

86
00:03:44,620 --> 00:03:49,629
<font color="#E5E5E5">let's imagine we're just using two</font>

87
00:03:46,629 --> 00:03:51,970
features<font color="#CCCCCC"> maybe</font><font color="#E5E5E5"> like file size and number</font>

88
00:03:49,629 --> 00:03:53,319
of imports if you take those features

89
00:03:51,970 --> 00:03:55,329
from all these different<font color="#E5E5E5"> files you can</font>

90
00:03:53,319 --> 00:03:58,119
<font color="#E5E5E5">then plot it in a two dimensional</font><font color="#CCCCCC"> space</font>

91
00:03:55,329 --> 00:04:00,699
<font color="#CCCCCC">and the colors don't</font><font color="#E5E5E5"> show up very well</font>

92
00:03:58,120 --> 00:04:02,379
<font color="#E5E5E5">but</font><font color="#CCCCCC"> you</font><font color="#E5E5E5"> have</font><font color="#CCCCCC"> like a red bunch that</font><font color="#E5E5E5"> you</font>

93
00:04:00,699 --> 00:04:03,970
can<font color="#E5E5E5"> call malicious and a blue bunch that</font>

94
00:04:02,379 --> 00:04:06,010
you can call benign and then what you

95
00:04:03,970 --> 00:04:07,989
want to<font color="#E5E5E5"> do is classify a new dot as it</font>

96
00:04:06,010 --> 00:04:09,280
comes in or<font color="#E5E5E5"> kind of divide that space up</font>

97
00:04:07,989 --> 00:04:10,750
<font color="#E5E5E5">into what you think is the malicious</font>

98
00:04:09,280 --> 00:04:15,069
space and what you think<font color="#E5E5E5"> is that benign</font>

99
00:04:10,750 --> 00:04:15,400
space<font color="#CCCCCC"> simple rules can</font><font color="#E5E5E5"> allow you to do</font>

100
00:04:15,069 --> 00:04:17,829
this

101
00:04:15,400 --> 00:04:19,690
but it's<font color="#E5E5E5"> just not very effectively you</font>

102
00:04:17,829 --> 00:04:22,030
can<font color="#E5E5E5"> see you know the red space here now</font>

103
00:04:19,690 --> 00:04:24,300
doesn't define<font color="#E5E5E5"> those blobs</font><font color="#CCCCCC"> and there's</font>

104
00:04:22,029 --> 00:04:26,500
some<font color="#E5E5E5"> outliers that get misclassified</font>

105
00:04:24,300 --> 00:04:28,720
<font color="#CCCCCC">machine</font><font color="#E5E5E5"> learning can really help by</font>

106
00:04:26,500 --> 00:04:32,260
defining<font color="#E5E5E5"> better boundaries and giving</font>

107
00:04:28,720 --> 00:04:33,610
you better performance<font color="#CCCCCC"> but there's so</font>

108
00:04:32,260 --> 00:04:35,020
many options<font color="#CCCCCC"> for machine learning</font>

109
00:04:33,610 --> 00:04:38,099
algorithms<font color="#E5E5E5"> how do we know which</font><font color="#CCCCCC"> ones</font>

110
00:04:35,020 --> 00:04:41,289
best<font color="#E5E5E5"> and that's where ember can come in</font>

111
00:04:38,099 --> 00:04:43,750
and<font color="#CCCCCC"> Ember stands for</font><font color="#E5E5E5"> endgame malware</font>

112
00:04:41,289 --> 00:04:46,310
benchmark for research<font color="#E5E5E5"> we want</font><font color="#CCCCCC"> it to be</font>

113
00:04:43,750 --> 00:04:51,120
known as kind of<font color="#E5E5E5"> amnesty for malware</font>

114
00:04:46,310 --> 00:04:53,160
so the name uh the letters<font color="#E5E5E5"> match up</font>

115
00:04:51,120 --> 00:04:54,990
<font color="#CCCCCC">I</font><font color="#E5E5E5"> really like it</font><font color="#CCCCCC"> it's a</font><font color="#E5E5E5"> great name and</font>

116
00:04:53,160 --> 00:04:57,390
it also gives<font color="#E5E5E5"> me</font><font color="#CCCCCC"> the opportunity to say</font>

117
00:04:54,990 --> 00:04:59,430
<font color="#CCCCCC">this joke</font><font color="#E5E5E5"> as often as possible</font><font color="#CCCCCC"> I'm not</font>

118
00:04:57,390 --> 00:05:03,330
<font color="#E5E5E5">gonna get tired of</font><font color="#CCCCCC"> it and so you better</font>

119
00:04:59,430 --> 00:05:06,300
not either<font color="#CCCCCC"> alright so what are the</font>

120
00:05:03,330 --> 00:05:09,240
<font color="#CCCCCC">details what is in</font><font color="#E5E5E5"> ember</font><font color="#CCCCCC"> it's an</font><font color="#E5E5E5"> open</font>

121
00:05:06,300 --> 00:05:11,610
<font color="#E5E5E5">source collection of 1.1 million PE file</font>

122
00:05:09,240 --> 00:05:15,180
hashes<font color="#CCCCCC"> that were scanned by virustotal</font>

123
00:05:11,610 --> 00:05:18,030
sometime in 2017<font color="#CCCCCC"> the dataset includes</font>

124
00:05:15,180 --> 00:05:19,380
metadata<font color="#E5E5E5"> derived</font><font color="#CCCCCC"> features</font><font color="#E5E5E5"> a model</font>

125
00:05:18,030 --> 00:05:21,239
trained on those<font color="#E5E5E5"> features and also</font>

126
00:05:19,380 --> 00:05:22,680
<font color="#E5E5E5">there's a github repository with code</font>

127
00:05:21,240 --> 00:05:25,590
that<font color="#CCCCCC"> allows you to work with</font><font color="#E5E5E5"> the data</font>

128
00:05:22,680 --> 00:05:27,330
really easily<font color="#CCCCCC"> but</font><font color="#E5E5E5"> importantly it does</font>

129
00:05:25,590 --> 00:05:29,520
not<font color="#E5E5E5"> include the files themselves</font><font color="#CCCCCC"> and</font>

130
00:05:27,330 --> 00:05:32,550
that's just because<font color="#E5E5E5"> you</font><font color="#CCCCCC"> know the benign</font>

131
00:05:29,520 --> 00:05:35,130
files<font color="#E5E5E5"> are company's intellectual</font>

132
00:05:32,550 --> 00:05:37,560
property<font color="#E5E5E5"> we don't own those files and we</font>

133
00:05:35,130 --> 00:05:39,330
we can't release<font color="#E5E5E5"> that inside</font><font color="#CCCCCC"> information</font>

134
00:05:37,560 --> 00:05:44,040
<font color="#CCCCCC">to the whole world and so we're only</font>

135
00:05:39,330 --> 00:05:46,710
releasing like derived<font color="#CCCCCC"> information so</font>

136
00:05:44,040 --> 00:05:49,320
the data set is divided into<font color="#CCCCCC"> 900,000</font>

137
00:05:46,710 --> 00:05:52,560
training set a smaller testing set

138
00:05:49,320 --> 00:05:54,630
<font color="#CCCCCC">they're the training set is divided</font>

139
00:05:52,560 --> 00:05:58,410
evenly between<font color="#E5E5E5"> benign malicious and</font>

140
00:05:54,630 --> 00:06:00,570
unlabeled samples<font color="#E5E5E5"> and the training set</font>

141
00:05:58,410 --> 00:06:02,940
appears chronologically prior to the

142
00:06:00,570 --> 00:06:05,460
test<font color="#E5E5E5"> data</font><font color="#CCCCCC"> you can see this is</font><font color="#E5E5E5"> kind of a</font>

143
00:06:02,940 --> 00:06:08,670
date histogram of the month<font color="#E5E5E5"> that each</font>

144
00:06:05,460 --> 00:06:10,590
each sample first appeared<font color="#CCCCCC"> we're</font>

145
00:06:08,670 --> 00:06:12,870
releasing<font color="#E5E5E5"> that month data with each</font>

146
00:06:10,590 --> 00:06:14,849
sample<font color="#CCCCCC"> you know it's not totally</font>

147
00:06:12,870 --> 00:06:18,090
<font color="#CCCCCC">accurate</font><font color="#E5E5E5"> it's the month but it should</font>

148
00:06:14,850 --> 00:06:19,350
allow you<font color="#E5E5E5"> to do a lot</font><font color="#CCCCCC"> with that and it's</font>

149
00:06:18,090 --> 00:06:21,000
important to<font color="#E5E5E5"> make</font><font color="#CCCCCC"> the training</font><font color="#E5E5E5"> set</font>

150
00:06:19,350 --> 00:06:22,590
appear<font color="#E5E5E5"> before the test data because it</font>

151
00:06:21,000 --> 00:06:25,530
kind of reflects the<font color="#CCCCCC"> nature of the</font>

152
00:06:22,590 --> 00:06:27,690
problem of antivirus is you want to

153
00:06:25,530 --> 00:06:30,030
train your<font color="#E5E5E5"> model at one point and</font><font color="#CCCCCC"> you</font>

154
00:06:27,690 --> 00:06:31,920
certainly<font color="#CCCCCC"> want to</font><font color="#E5E5E5"> get all the samples</font>

155
00:06:30,030 --> 00:06:33,659
<font color="#CCCCCC">that you trained it on correct but you</font>

156
00:06:31,920 --> 00:06:36,240
also want it<font color="#CCCCCC"> to</font><font color="#E5E5E5"> get all</font><font color="#CCCCCC"> new samples</font>

157
00:06:33,660 --> 00:06:38,400
correct you want to correctly predict

158
00:06:36,240 --> 00:06:40,260
whether samples benign or malicious that

159
00:06:38,400 --> 00:06:41,909
<font color="#E5E5E5">you haven't seen</font><font color="#CCCCCC"> before</font><font color="#E5E5E5"> that malware</font>

160
00:06:40,260 --> 00:06:45,000
authors are you know currently writing

161
00:06:41,910 --> 00:06:47,280
<font color="#E5E5E5">or will write in the future so that's</font>

162
00:06:45,000 --> 00:06:50,040
why<font color="#CCCCCC"> the test data shows up in November</font>

163
00:06:47,280 --> 00:06:53,909
<font color="#E5E5E5">and December</font><font color="#CCCCCC"> of 2017</font><font color="#E5E5E5"> and the training</font>

164
00:06:50,040 --> 00:06:56,550
<font color="#E5E5E5">data</font><font color="#CCCCCC"> is all prior to that oh and then</font>

165
00:06:53,910 --> 00:06:58,070
also by releasing the month<font color="#E5E5E5"> we're also</font>

166
00:06:56,550 --> 00:06:59,950
allowing<font color="#E5E5E5"> you to do kind</font><font color="#CCCCCC"> of</font><font color="#E5E5E5"> across</font>

167
00:06:58,070 --> 00:07:02,260
chronological<font color="#CCCCCC"> cross validation</font>

168
00:06:59,950 --> 00:07:04,900
and<font color="#E5E5E5"> also you can quantify how</font><font color="#CCCCCC"> quickly</font>

169
00:07:02,260 --> 00:07:06,820
your model becomes<font color="#CCCCCC"> out-of-date you can</font>

170
00:07:04,900 --> 00:07:08,919
train a model<font color="#CCCCCC"> say through all the data</font>

171
00:07:06,820 --> 00:07:11,950
<font color="#E5E5E5">through May and then say well how well</font>

172
00:07:08,920 --> 00:07:14,140
is it<font color="#E5E5E5"> doing on data in August and</font>

173
00:07:11,950 --> 00:07:18,159
September<font color="#E5E5E5"> and October</font><font color="#CCCCCC"> and</font><font color="#E5E5E5"> you can see</font>

174
00:07:14,140 --> 00:07:19,900
how much worse it<font color="#CCCCCC"> gets</font><font color="#E5E5E5"> over time so this</font>

175
00:07:18,160 --> 00:07:22,900
<font color="#CCCCCC">is what the data actually</font><font color="#E5E5E5"> actually looks</font>

176
00:07:19,900 --> 00:07:26,109
<font color="#E5E5E5">like you can go grab</font><font color="#CCCCCC"> it now</font><font color="#E5E5E5"> it's a 1.6</font>

177
00:07:22,900 --> 00:07:29,349
gigabyte<font color="#E5E5E5"> tarball</font><font color="#CCCCCC"> there on disk</font><font color="#E5E5E5"> once you</font>

178
00:07:26,110 --> 00:07:33,760
extract<font color="#E5E5E5"> it there's a</font><font color="#CCCCCC"> 7</font><font color="#E5E5E5"> JSON files in</font>

179
00:07:29,350 --> 00:07:36,550
there<font color="#E5E5E5"> when you look into each file each</font>

180
00:07:33,760 --> 00:07:39,340
line is a JSON blob<font color="#E5E5E5"> and so here we're</font>

181
00:07:36,550 --> 00:07:43,420
just looking at<font color="#E5E5E5"> the first three keys of</font>

182
00:07:39,340 --> 00:07:45,369
that<font color="#CCCCCC"> first line</font><font color="#E5E5E5"> and so that each JSON</font>

183
00:07:43,420 --> 00:07:48,010
blob has<font color="#E5E5E5"> these first three keys which is</font>

184
00:07:45,370 --> 00:07:50,740
kind of<font color="#E5E5E5"> metadata about</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> sample it's</font>

185
00:07:48,010 --> 00:07:53,320
the hash<font color="#CCCCCC"> the month that appeared and</font>

186
00:07:50,740 --> 00:07:55,060
then<font color="#E5E5E5"> also the label</font><font color="#CCCCCC"> zero for benign</font><font color="#E5E5E5"> one</font>

187
00:07:53,320 --> 00:07:59,170
for malicious<font color="#E5E5E5"> and negative 1 for</font>

188
00:07:55,060 --> 00:08:01,510
unlabeled<font color="#CCCCCC"> there's a lot</font><font color="#E5E5E5"> more keys than</font>

189
00:07:59,170 --> 00:08:04,180
after that which<font color="#E5E5E5"> kind of show you the</font>

190
00:08:01,510 --> 00:08:05,800
extracted features from<font color="#E5E5E5"> each sample</font><font color="#CCCCCC"> and</font>

191
00:08:04,180 --> 00:08:08,080
<font color="#E5E5E5">I'll get into more detail about what</font>

192
00:08:05,800 --> 00:08:10,600
<font color="#E5E5E5">those</font><font color="#CCCCCC"> features are later but</font><font color="#E5E5E5"> yeah right</font>

193
00:08:08,080 --> 00:08:12,700
now so there's two kinds<font color="#CCCCCC"> of</font><font color="#E5E5E5"> features</font>

194
00:08:10,600 --> 00:08:14,680
<font color="#CCCCCC">there's those that can be calculated</font>

195
00:08:12,700 --> 00:08:17,830
<font color="#E5E5E5">directly</font><font color="#CCCCCC"> from the raw bytes</font><font color="#E5E5E5"> of the file</font>

196
00:08:14,680 --> 00:08:19,390
<font color="#E5E5E5">that's like byte entropy byte histogram</font>

197
00:08:17,830 --> 00:08:20,830
and strings<font color="#E5E5E5"> but then there's also</font>

198
00:08:19,390 --> 00:08:23,110
features that<font color="#CCCCCC"> we're extracting from</font><font color="#E5E5E5"> the</font>

199
00:08:20,830 --> 00:08:25,510
files that<font color="#E5E5E5"> need that require</font><font color="#CCCCCC"> us to kind</font>

200
00:08:23,110 --> 00:08:27,730
of parse the PE header<font color="#E5E5E5"> and in order to</font>

201
00:08:25,510 --> 00:08:29,980
<font color="#E5E5E5">do that and to understand the PE header</font>

202
00:08:27,730 --> 00:08:32,020
<font color="#E5E5E5">format the PE file format we're using a</font>

203
00:08:29,980 --> 00:08:34,810
<font color="#CCCCCC">library called</font><font color="#E5E5E5"> the library to instrument</font>

204
00:08:32,020 --> 00:08:36,728
executable formats<font color="#E5E5E5"> or leaf and we</font><font color="#CCCCCC"> got to</font>

205
00:08:34,809 --> 00:08:40,709
give a big<font color="#CCCCCC"> shout-out to</font><font color="#E5E5E5"> quarks lab for</font>

206
00:08:36,729 --> 00:08:43,780
open sourcing this very<font color="#E5E5E5"> useful library</font>

207
00:08:40,710 --> 00:08:46,390
so calculating the features is kind<font color="#CCCCCC"> of a</font>

208
00:08:43,780 --> 00:08:49,230
<font color="#E5E5E5">two-step process</font><font color="#CCCCCC"> this code</font><font color="#E5E5E5"> you can't</font>

209
00:08:46,390 --> 00:08:52,240
really<font color="#E5E5E5"> read the details but it's just</font>

210
00:08:49,230 --> 00:08:53,620
this is just<font color="#E5E5E5"> one one feature and the</font>

211
00:08:52,240 --> 00:08:55,810
important point<font color="#CCCCCC"> is that there's two</font>

212
00:08:53,620 --> 00:08:58,930
<font color="#CCCCCC">different functions</font><font color="#E5E5E5"> to calculate</font>

213
00:08:55,810 --> 00:09:01,060
features the first<font color="#E5E5E5"> accepts the raw</font>

214
00:08:58,930 --> 00:09:03,489
binary<font color="#CCCCCC"> the PE file</font><font color="#E5E5E5"> itself and it</font>

215
00:09:01,060 --> 00:09:04,750
generates that JSON blob and that JSON

216
00:09:03,490 --> 00:09:07,540
blob is kind of what we're calling the

217
00:09:04,750 --> 00:09:09,730
raw features the second function takes

218
00:09:07,540 --> 00:09:13,150
that JSON blob and<font color="#CCCCCC"> then vector eise's it</font>

219
00:09:09,730 --> 00:09:13,750
into just<font color="#E5E5E5"> a list of</font><font color="#CCCCCC"> like</font><font color="#E5E5E5"> float</font><font color="#CCCCCC"> 32 s</font><font color="#E5E5E5"> and</font>

220
00:09:13,150 --> 00:09:16,270
that's a

221
00:09:13,750 --> 00:09:20,110
<font color="#CCCCCC">you're vector</font><font color="#E5E5E5"> that you can then feed to</font>

222
00:09:16,270 --> 00:09:22,840
a<font color="#E5E5E5"> machine learning model so the data</font>

223
00:09:20,110 --> 00:09:23,290
<font color="#E5E5E5">that</font><font color="#CCCCCC"> were distributing that</font><font color="#E5E5E5"> shows JSON</font>

224
00:09:22,840 --> 00:09:25,150
blobs

225
00:09:23,290 --> 00:09:27,189
they need to be vectorized<font color="#E5E5E5"> before you</font>

226
00:09:25,150 --> 00:09:30,730
can train<font color="#E5E5E5"> machine learning model</font><font color="#CCCCCC"> it's an</font>

227
00:09:27,190 --> 00:09:33,220
important<font color="#E5E5E5"> step and the code we're</font>

228
00:09:30,730 --> 00:09:35,710
releasing allows you to to vectorize all

229
00:09:33,220 --> 00:09:37,330
those<font color="#E5E5E5"> features with</font><font color="#CCCCCC"> without</font><font color="#E5E5E5"> really you</font>

230
00:09:35,710 --> 00:09:38,460
know without doing<font color="#E5E5E5"> any more work we've</font>

231
00:09:37,330 --> 00:09:40,990
defined that<font color="#E5E5E5"> for</font><font color="#CCCCCC"> you</font>

232
00:09:38,460 --> 00:09:44,080
so yeah let's go through the<font color="#CCCCCC"> categories</font>

233
00:09:40,990 --> 00:09:45,700
of<font color="#E5E5E5"> features that we kind of chose white</font>

234
00:09:44,080 --> 00:09:48,310
histogram is a simple<font color="#CCCCCC"> count of how many</font>

235
00:09:45,700 --> 00:09:49,870
<font color="#CCCCCC">times each byte occurs in the file</font><font color="#E5E5E5"> the</font>

236
00:09:48,310 --> 00:09:52,359
<font color="#E5E5E5">byte entropy histogram is kind of a</font>

237
00:09:49,870 --> 00:09:54,730
sliding entropy<font color="#CCCCCC"> calculation that</font><font color="#E5E5E5"> then</font>

238
00:09:52,360 --> 00:09:57,280
kind of benchmarks<font color="#E5E5E5"> each entropy</font>

239
00:09:54,730 --> 00:09:58,900
calculation back to each byte<font color="#CCCCCC"> that</font>

240
00:09:57,280 --> 00:10:00,939
occurs there's more details in that

241
00:09:58,900 --> 00:10:02,260
<font color="#E5E5E5">paper that</font><font color="#CCCCCC"> I</font><font color="#E5E5E5"> linked</font><font color="#CCCCCC"> to there and we've</font>

242
00:10:00,940 --> 00:10:05,560
also<font color="#E5E5E5"> written a paper there's there's</font>

243
00:10:02,260 --> 00:10:07,510
<font color="#E5E5E5">more details about it in</font><font color="#CCCCCC"> there section</font>

244
00:10:05,560 --> 00:10:09,310
information so this this<font color="#E5E5E5"> is an</font><font color="#CCCCCC"> example</font>

245
00:10:07,510 --> 00:10:12,970
<font color="#E5E5E5">of a feature that</font><font color="#CCCCCC"> requires you to</font><font color="#E5E5E5"> read</font>

246
00:10:09,310 --> 00:10:15,099
the PE PE file header<font color="#CCCCCC"> so we list all the</font>

247
00:10:12,970 --> 00:10:16,810
<font color="#E5E5E5">sections and all you know the entropy</font>

248
00:10:15,100 --> 00:10:19,300
<font color="#CCCCCC">the virtual size kind of other</font>

249
00:10:16,810 --> 00:10:23,250
information<font color="#CCCCCC"> about each section and then</font>

250
00:10:19,300 --> 00:10:23,250
<font color="#CCCCCC">also which section is the entry section</font>

251
00:10:23,430 --> 00:10:27,670
<font color="#CCCCCC">import information</font><font color="#E5E5E5"> export</font><font color="#CCCCCC"> information we</font>

252
00:10:26,050 --> 00:10:29,890
<font color="#CCCCCC">just have a list</font><font color="#E5E5E5"> of all the imports from</font>

253
00:10:27,670 --> 00:10:32,219
<font color="#E5E5E5">each file and a list of all the exports</font>

254
00:10:29,890 --> 00:10:37,300
<font color="#E5E5E5">and for the imports we have what library</font>

255
00:10:32,220 --> 00:10:38,920
those functions were from strings<font color="#E5E5E5"> we</font>

256
00:10:37,300 --> 00:10:40,420
can't<font color="#E5E5E5"> just extract the strings and hand</font>

257
00:10:38,920 --> 00:10:41,890
<font color="#E5E5E5">them over to you we were a little</font>

258
00:10:40,420 --> 00:10:44,290
worried about<font color="#E5E5E5"> personally identifiable</font>

259
00:10:41,890 --> 00:10:47,290
information<font color="#E5E5E5"> or divulging intellectual</font>

260
00:10:44,290 --> 00:10:49,209
property but we were able<font color="#E5E5E5"> to find all</font>

261
00:10:47,290 --> 00:10:51,790
<font color="#E5E5E5">the strings</font><font color="#CCCCCC"> tell you how many there are</font>

262
00:10:49,210 --> 00:10:53,740
<font color="#E5E5E5">what their average length is a histogram</font>

263
00:10:51,790 --> 00:10:55,030
<font color="#E5E5E5">of the characters that appear and some</font>

264
00:10:53,740 --> 00:10:57,460
other things we've also done some

265
00:10:55,030 --> 00:11:00,160
<font color="#E5E5E5">pattern matching so the strings that we</font>

266
00:10:57,460 --> 00:11:01,600
think look like URLs<font color="#E5E5E5"> or registry keys we</font>

267
00:11:00,160 --> 00:11:05,800
count those<font color="#CCCCCC"> up and we give that</font>

268
00:11:01,600 --> 00:11:07,930
information<font color="#E5E5E5"> to</font><font color="#CCCCCC"> you</font><font color="#E5E5E5"> there's also more</font>

269
00:11:05,800 --> 00:11:10,630
general<font color="#CCCCCC"> information</font><font color="#E5E5E5"> just about the file</font>

270
00:11:07,930 --> 00:11:13,120
its size its virtual size and so<font color="#E5E5E5"> on and</font>

271
00:11:10,630 --> 00:11:15,370
also<font color="#E5E5E5"> header</font><font color="#CCCCCC"> information directly</font><font color="#E5E5E5"> from</font>

272
00:11:13,120 --> 00:11:18,700
<font color="#E5E5E5">the PE header that talks</font><font color="#CCCCCC"> about where the</font>

273
00:11:15,370 --> 00:11:20,380
file was compiled and kind<font color="#E5E5E5"> of the</font>

274
00:11:18,700 --> 00:11:24,550
compiler information and that<font color="#CCCCCC"> sort of</font>

275
00:11:20,380 --> 00:11:28,180
thing yeah so I kind of mentioned<font color="#CCCCCC"> this</font>

276
00:11:24,550 --> 00:11:29,439
but after downloading the<font color="#E5E5E5"> data set</font>

277
00:11:28,180 --> 00:11:31,420
you need to do feature vector is<font color="#E5E5E5"> a</font>

278
00:11:29,440 --> 00:11:34,210
vector ization before you do model

279
00:11:31,420 --> 00:11:36,849
training<font color="#E5E5E5"> the</font><font color="#CCCCCC"> amber code based</font><font color="#E5E5E5"> defines</font>

280
00:11:34,210 --> 00:11:38,740
that feature of vectorization after<font color="#E5E5E5"> I</font>

281
00:11:36,850 --> 00:11:39,730
downloaded the data<font color="#E5E5E5"> set</font><font color="#CCCCCC"> onto this</font>

282
00:11:38,740 --> 00:11:42,040
<font color="#E5E5E5">computer right</font><font color="#CCCCCC"> here</font>

283
00:11:39,730 --> 00:11:44,860
it took about 20 hours<font color="#CCCCCC"> on this machine</font>

284
00:11:42,040 --> 00:11:47,349
<font color="#E5E5E5">we have</font><font color="#CCCCCC"> a server</font><font color="#E5E5E5"> of it does better</font>

285
00:11:44,860 --> 00:11:52,540
parallelization<font color="#E5E5E5"> and it can take as</font>

286
00:11:47,350 --> 00:11:54,220
quickly as like 10 or 30 minutes so

287
00:11:52,540 --> 00:11:57,310
after<font color="#CCCCCC"> you've done that you can train a</font>

288
00:11:54,220 --> 00:11:59,860
model<font color="#E5E5E5"> we've trained a model for you</font><font color="#CCCCCC"> we</font>

289
00:11:57,310 --> 00:12:01,660
didn't make any special decisions on

290
00:11:59,860 --> 00:12:03,700
this<font color="#E5E5E5"> model this is a very generic model</font>

291
00:12:01,660 --> 00:12:05,680
but we wanted<font color="#CCCCCC"> to</font><font color="#E5E5E5"> train it and distribute</font>

292
00:12:03,700 --> 00:12:08,200
it for example<font color="#E5E5E5"> purposes</font><font color="#CCCCCC"> so</font><font color="#E5E5E5"> that it can</font>

293
00:12:05,680 --> 00:12:10,359
serve as a benchmark<font color="#E5E5E5"> it's a gradient</font>

294
00:12:08,200 --> 00:12:12,970
boosted decision tree model<font color="#E5E5E5"> that's</font>

295
00:12:10,360 --> 00:12:15,490
trained with like GBM and<font color="#E5E5E5"> that's an</font><font color="#CCCCCC"> open</font>

296
00:12:12,970 --> 00:12:18,580
source<font color="#CCCCCC"> implementation of that</font><font color="#E5E5E5"> gradient</font>

297
00:12:15,490 --> 00:12:20,260
boosted decision tree algorithm<font color="#CCCCCC"> it took</font>

298
00:12:18,580 --> 00:12:23,140
<font color="#E5E5E5">about</font><font color="#CCCCCC"> three hours again</font><font color="#E5E5E5"> three hours on</font>

299
00:12:20,260 --> 00:12:25,029
this machine<font color="#E5E5E5"> here so it that was you</font>

300
00:12:23,140 --> 00:12:26,439
know<font color="#E5E5E5"> that's pretty easy and then once</font>

301
00:12:25,029 --> 00:12:29,110
you have<font color="#CCCCCC"> that model you</font><font color="#E5E5E5"> can make</font>

302
00:12:26,440 --> 00:12:31,600
predictions<font color="#CCCCCC"> on every sample</font><font color="#E5E5E5"> in the test</font>

303
00:12:29,110 --> 00:12:35,920
set<font color="#E5E5E5"> and it's going</font><font color="#CCCCCC"> to that models going</font>

304
00:12:31,600 --> 00:12:37,750
<font color="#E5E5E5">to spit out a</font><font color="#CCCCCC"> number between 0 & 1 if it</font>

305
00:12:35,920 --> 00:12:40,120
spits out a<font color="#CCCCCC"> number closer to 1 it thinks</font>

306
00:12:37,750 --> 00:12:41,830
that the<font color="#E5E5E5"> file is more malicious if it if</font>

307
00:12:40,120 --> 00:12:43,540
it spits out a lower<font color="#E5E5E5"> number it thinks</font>

308
00:12:41,830 --> 00:12:46,060
it's more benign and then what I'm

309
00:12:43,540 --> 00:12:49,449
showing<font color="#E5E5E5"> here</font><font color="#CCCCCC"> is a histogram</font><font color="#E5E5E5"> of those</font>

310
00:12:46,060 --> 00:12:51,160
predictions<font color="#CCCCCC"> on</font><font color="#E5E5E5"> the test set again</font><font color="#CCCCCC"> red</font>

311
00:12:49,450 --> 00:12:52,450
for malicious blue for benign<font color="#CCCCCC"> so you can</font>

312
00:12:51,160 --> 00:12:54,610
see it's doing<font color="#E5E5E5"> a pretty good job of</font>

313
00:12:52,450 --> 00:12:59,080
separating the two classes<font color="#E5E5E5"> but</font><font color="#CCCCCC"> there is</font>

314
00:12:54,610 --> 00:13:00,430
some overlap<font color="#CCCCCC"> once you've made</font><font color="#E5E5E5"> all those</font>

315
00:12:59,080 --> 00:13:02,140
<font color="#E5E5E5">predictions you can kind of make some</font>

316
00:13:00,430 --> 00:13:04,390
statements about<font color="#E5E5E5"> how well</font><font color="#CCCCCC"> you think the</font>

317
00:13:02,140 --> 00:13:07,000
model<font color="#E5E5E5"> is doing we do that with a</font>

318
00:13:04,390 --> 00:13:10,390
receiver operator characteristic curve

319
00:13:07,000 --> 00:13:12,940
<font color="#E5E5E5">and the area under</font><font color="#CCCCCC"> that curve it's so we</font>

320
00:13:10,390 --> 00:13:15,250
get this score<font color="#CCCCCC"> and then like I said you</font>

321
00:13:12,940 --> 00:13:17,680
you you get<font color="#E5E5E5"> a number</font><font color="#CCCCCC"> a score between 0 &</font>

322
00:13:15,250 --> 00:13:20,050
1<font color="#CCCCCC"> and then you want to pick a threshold</font>

323
00:13:17,680 --> 00:13:21,339
<font color="#E5E5E5">and say</font><font color="#CCCCCC"> okay anything that scores above</font>

324
00:13:20,050 --> 00:13:23,109
<font color="#E5E5E5">this we're gonna define that as</font>

325
00:13:21,339 --> 00:13:25,420
malicious<font color="#E5E5E5"> anything below that we're</font>

326
00:13:23,110 --> 00:13:27,730
<font color="#E5E5E5">gonna define</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> as benign and if we do</font>

327
00:13:25,420 --> 00:13:29,860
<font color="#E5E5E5">that how many do we get wrong how many</font>

328
00:13:27,730 --> 00:13:31,540
false positives<font color="#CCCCCC"> do we have</font><font color="#E5E5E5"> well I chose</font>

329
00:13:29,860 --> 00:13:33,910
<font color="#E5E5E5">that threshold</font><font color="#CCCCCC"> in</font><font color="#E5E5E5"> order to get a point</font><font color="#CCCCCC"> 1</font>

330
00:13:31,540 --> 00:13:35,890
percent<font color="#E5E5E5"> false positive rate and at that</font>

331
00:13:33,910 --> 00:13:40,699
false positive rate we get<font color="#E5E5E5"> a 93 percent</font>

332
00:13:35,890 --> 00:13:43,250
<font color="#E5E5E5">detection rate so</font>

333
00:13:40,700 --> 00:13:46,340
<font color="#CCCCCC">a huge disclaimer</font><font color="#E5E5E5"> this model is not</font>

334
00:13:43,250 --> 00:13:47,960
malware score on a<font color="#CCCCCC"> 10-game we</font><font color="#E5E5E5"> train</font>

335
00:13:46,340 --> 00:13:49,880
malware score and distribute it as

336
00:13:47,960 --> 00:13:52,160
<font color="#CCCCCC">production</font><font color="#E5E5E5"> model it's protecting</font>

337
00:13:49,880 --> 00:13:55,850
customer machines now it's great<font color="#E5E5E5"> in my</font>

338
00:13:52,160 --> 00:13:57,709
totally biased opinion<font color="#E5E5E5"> but this</font><font color="#CCCCCC"> ember</font>

339
00:13:55,850 --> 00:14:00,110
model<font color="#E5E5E5"> it just doesn't perform as</font><font color="#CCCCCC"> well</font>

340
00:13:57,710 --> 00:14:02,420
<font color="#CCCCCC">it's malware score is better optimized</font>

341
00:14:00,110 --> 00:14:04,880
has better features it's constantly

342
00:14:02,420 --> 00:14:06,829
<font color="#CCCCCC">updated with new data the purpose</font><font color="#E5E5E5"> of the</font>

343
00:14:04,880 --> 00:14:09,200
Ember model is not like to protect your

344
00:14:06,830 --> 00:14:11,450
machine<font color="#E5E5E5"> it's definitely to just serve as</font>

345
00:14:09,200 --> 00:14:12,680
a<font color="#E5E5E5"> benchmark to say</font><font color="#CCCCCC"> ok the researchers</font>

346
00:14:11,450 --> 00:14:13,970
out there<font color="#CCCCCC"> can choose a</font><font color="#E5E5E5"> different machine</font>

347
00:14:12,680 --> 00:14:16,579
<font color="#CCCCCC">learning model</font><font color="#E5E5E5"> choose a different</font>

348
00:14:13,970 --> 00:14:18,200
<font color="#E5E5E5">technique for classifying benign and</font>

349
00:14:16,580 --> 00:14:19,700
malicious samples and how does<font color="#E5E5E5"> it</font>

350
00:14:18,200 --> 00:14:21,650
<font color="#E5E5E5">compare to this you know common</font>

351
00:14:19,700 --> 00:14:24,530
<font color="#CCCCCC">benchmark that everybody has access</font><font color="#E5E5E5"> to</font>

352
00:14:21,650 --> 00:14:28,640
so yeah<font color="#CCCCCC"> I would not suggest</font><font color="#E5E5E5"> using this</font>

353
00:14:24,530 --> 00:14:30,860
model to protect your<font color="#CCCCCC"> own machines along</font>

354
00:14:28,640 --> 00:14:33,560
<font color="#E5E5E5">with the data</font><font color="#CCCCCC"> we're releasing a</font><font color="#E5E5E5"> code</font>

355
00:14:30,860 --> 00:14:35,300
<font color="#E5E5E5">base it makes it very</font><font color="#CCCCCC"> easy to vectorize</font>

356
00:14:33,560 --> 00:14:37,670
the features train the models and<font color="#E5E5E5"> then</font>

357
00:14:35,300 --> 00:14:39,530
importantly make predictions on new PE

358
00:14:37,670 --> 00:14:41,240
files given the model<font color="#E5E5E5"> that we're</font>

359
00:14:39,530 --> 00:14:46,939
distributing<font color="#E5E5E5"> and all I'll</font><font color="#CCCCCC"> show you that</font>

360
00:14:41,240 --> 00:14:49,430
<font color="#E5E5E5">in</font><font color="#CCCCCC"> just a second I</font><font color="#E5E5E5"> what something I'm</font>

361
00:14:46,940 --> 00:14:51,140
<font color="#E5E5E5">really proud</font><font color="#CCCCCC"> of is the the code</font>

362
00:14:49,430 --> 00:14:54,109
repository has<font color="#E5E5E5"> a</font><font color="#CCCCCC"> jupiter notebook in the</font>

363
00:14:51,140 --> 00:14:56,270
<font color="#E5E5E5">resources directory and</font><font color="#CCCCCC"> i've</font><font color="#E5E5E5"> kind of</font>

364
00:14:54,110 --> 00:14:59,030
defined the environment that<font color="#CCCCCC"> I ran that</font>

365
00:14:56,270 --> 00:15:01,699
<font color="#E5E5E5">I train the model in with what Python</font>

366
00:14:59,030 --> 00:15:03,589
packages I used what versions and<font color="#CCCCCC"> so you</font>

367
00:15:01,700 --> 00:15:05,090
<font color="#E5E5E5">yourself can run this notebook you</font><font color="#CCCCCC"> can</font>

368
00:15:03,590 --> 00:15:07,040
train the model<font color="#E5E5E5"> yourself</font><font color="#CCCCCC"> given that</font>

369
00:15:05,090 --> 00:15:08,750
environment and<font color="#E5E5E5"> this notebook will</font>

370
00:15:07,040 --> 00:15:11,750
<font color="#E5E5E5">reproduce all the graphics</font><font color="#CCCCCC"> that are in</font>

371
00:15:08,750 --> 00:15:13,850
this talk that<font color="#CCCCCC"> are in the paper and it's</font>

372
00:15:11,750 --> 00:15:18,350
a very<font color="#E5E5E5"> good</font><font color="#CCCCCC"> explanation of</font><font color="#E5E5E5"> how to do</font>

373
00:15:13,850 --> 00:15:20,630
that in code so<font color="#CCCCCC"> yeah I I hope</font>

374
00:15:18,350 --> 00:15:22,310
researchers in this<font color="#CCCCCC"> area you</font><font color="#E5E5E5"> know pick</font>

375
00:15:20,630 --> 00:15:24,020
<font color="#CCCCCC">up this model</font><font color="#E5E5E5"> and they run</font><font color="#CCCCCC"> with it pick</font>

376
00:15:22,310 --> 00:15:25,250
<font color="#E5E5E5">up this data and run with it</font><font color="#CCCCCC"> there's a</font>

377
00:15:24,020 --> 00:15:27,650
bunch<font color="#CCCCCC"> of</font><font color="#E5E5E5"> different things we're</font><font color="#CCCCCC"> hoping</font>

378
00:15:25,250 --> 00:15:29,420
<font color="#E5E5E5">people do with it this first category is</font>

379
00:15:27,650 --> 00:15:31,699
like we hope<font color="#CCCCCC"> people beat the benchmark</font>

380
00:15:29,420 --> 00:15:34,339
you know this was a pretty<font color="#E5E5E5"> easy model I</font>

381
00:15:31,700 --> 00:15:36,200
we didn't<font color="#E5E5E5"> make many customizations to it</font>

382
00:15:34,340 --> 00:15:37,910
and there's a lot<font color="#CCCCCC"> of things researchers</font>

383
00:15:36,200 --> 00:15:40,810
can do to improve the performance<font color="#E5E5E5"> like</font>

384
00:15:37,910 --> 00:15:43,160
immediately<font color="#CCCCCC"> you can you can throw out</font>

385
00:15:40,810 --> 00:15:44,989
<font color="#E5E5E5">features that</font><font color="#CCCCCC"> were distributing that</font>

386
00:15:43,160 --> 00:15:46,850
<font color="#E5E5E5">aren't very interesting</font><font color="#CCCCCC"> you can</font><font color="#E5E5E5"> do</font>

387
00:15:44,990 --> 00:15:50,090
feature engineering<font color="#CCCCCC"> come up</font><font color="#E5E5E5"> with better</font>

388
00:15:46,850 --> 00:15:52,070
<font color="#CCCCCC">features you can do</font><font color="#E5E5E5"> you can optimize the</font>

389
00:15:50,090 --> 00:15:53,660
<font color="#E5E5E5">like GBM model parameters with grid</font>

390
00:15:52,070 --> 00:15:54,450
search<font color="#E5E5E5"> that's going to immediately get</font>

391
00:15:53,660 --> 00:15:56,850
you better perform

392
00:15:54,450 --> 00:15:59,010
or the last one is kind<font color="#CCCCCC"> of</font><font color="#E5E5E5"> like</font>

393
00:15:56,850 --> 00:16:00,540
semi-supervised learning<font color="#E5E5E5"> you can bring</font>

394
00:15:59,010 --> 00:16:03,480
in information<font color="#CCCCCC"> from the unlabeled</font>

395
00:16:00,540 --> 00:16:05,279
samples<font color="#E5E5E5"> to hopefully help you you know</font>

396
00:16:03,480 --> 00:16:09,240
learn some more<font color="#E5E5E5"> about</font><font color="#CCCCCC"> the structure of</font>

397
00:16:05,279 --> 00:16:11,010
PE files if the if the<font color="#E5E5E5"> labeled benign</font>

398
00:16:09,240 --> 00:16:13,649
and labeled malicious data isn't<font color="#E5E5E5"> enough</font>

399
00:16:11,010 --> 00:16:15,480
<font color="#CCCCCC">and we're because there</font><font color="#E5E5E5"> isn't much about</font>

400
00:16:13,649 --> 00:16:16,889
semi-supervised learning in the academic

401
00:16:15,480 --> 00:16:21,029
<font color="#E5E5E5">literature and we're hoping this kind of</font>

402
00:16:16,889 --> 00:16:22,889
<font color="#CCCCCC">Spurs that the second category of things</font>

403
00:16:21,029 --> 00:16:25,130
you<font color="#E5E5E5"> could do is</font><font color="#CCCCCC"> kind of going</font><font color="#E5E5E5"> beyond</font>

404
00:16:22,889 --> 00:16:27,720
just gradient boosted decision trees and

405
00:16:25,130 --> 00:16:29,699
well I've<font color="#E5E5E5"> already mentioned quanta you</font>

406
00:16:27,720 --> 00:16:31,110
know how quickly do these models go out

407
00:16:29,699 --> 00:16:33,329
of date<font color="#E5E5E5"> we can definitely define that</font>

408
00:16:31,110 --> 00:16:34,860
with this data set<font color="#E5E5E5"> but then also you can</font>

409
00:16:33,329 --> 00:16:37,260
go beyond gradient boosted decision

410
00:16:34,860 --> 00:16:39,449
trees and look at featureless<font color="#E5E5E5"> neural</font>

411
00:16:37,260 --> 00:16:41,670
network based models<font color="#E5E5E5"> and and for that</font>

412
00:16:39,449 --> 00:16:43,949
<font color="#E5E5E5">you would need independent access</font><font color="#CCCCCC"> to the</font>

413
00:16:41,670 --> 00:16:45,719
samples<font color="#CCCCCC"> themselves</font><font color="#E5E5E5"> we can't provide</font><font color="#CCCCCC"> that</font>

414
00:16:43,949 --> 00:16:47,639
<font color="#E5E5E5">but I'm hoping there's research</font>

415
00:16:45,720 --> 00:16:50,040
institutions that have access<font color="#E5E5E5"> to</font>

416
00:16:47,639 --> 00:16:54,269
virustotal<font color="#E5E5E5"> any of these files can be</font>

417
00:16:50,040 --> 00:16:56,939
<font color="#E5E5E5">gained with a subscription to virustotal</font>

418
00:16:54,269 --> 00:16:58,620
or some agreement with them<font color="#E5E5E5"> so hopefully</font>

419
00:16:56,940 --> 00:17:00,959
researchers with that kind of access can

420
00:16:58,620 --> 00:17:02,940
release neural network type approaches

421
00:17:00,959 --> 00:17:06,418
to this problem<font color="#CCCCCC"> and</font><font color="#E5E5E5"> you know kind</font><font color="#CCCCCC"> of</font>

422
00:17:02,940 --> 00:17:08,069
show how they compare<font color="#CCCCCC"> also you could</font>

423
00:17:06,419 --> 00:17:11,339
<font color="#E5E5E5">kind of take the offensive</font><font color="#CCCCCC"> side and</font><font color="#E5E5E5"> say</font>

424
00:17:08,069 --> 00:17:14,069
how<font color="#CCCCCC"> can</font><font color="#E5E5E5"> we use machine</font><font color="#CCCCCC"> learning to from</font>

425
00:17:11,339 --> 00:17:15,688
an attacker standpoint and so you can

426
00:17:14,069 --> 00:17:17,579
use the<font color="#CCCCCC"> ember' model as kind</font><font color="#E5E5E5"> of like we</font>

427
00:17:15,689 --> 00:17:20,189
want to<font color="#E5E5E5"> beat the ember' model</font><font color="#CCCCCC"> have a</font>

428
00:17:17,579 --> 00:17:22,290
<font color="#E5E5E5">malicious sample that</font><font color="#CCCCCC"> ember the Ember</font>

429
00:17:20,189 --> 00:17:24,689
model classifies correctly<font color="#E5E5E5"> how can I</font>

430
00:17:22,290 --> 00:17:27,359
change that<font color="#E5E5E5"> it could bypass the</font>

431
00:17:24,689 --> 00:17:29,429
detection<font color="#E5E5E5"> and</font><font color="#CCCCCC"> I just want</font><font color="#E5E5E5"> to make a note</font>

432
00:17:27,359 --> 00:17:31,678
you<font color="#E5E5E5"> know offensive research is very</font>

433
00:17:29,429 --> 00:17:33,030
important to defenders as well<font color="#E5E5E5"> because</font>

434
00:17:31,679 --> 00:17:34,590
we<font color="#E5E5E5"> want to learn more about that</font><font color="#CCCCCC"> and</font>

435
00:17:33,030 --> 00:17:38,910
<font color="#E5E5E5">it's it's going to help defenders in the</font>

436
00:17:34,590 --> 00:17:42,000
<font color="#E5E5E5">end all right demo time</font><font color="#CCCCCC"> this is where</font>

437
00:17:38,910 --> 00:17:44,520
talks are won<font color="#CCCCCC"> and lost</font><font color="#E5E5E5"> so I wanted to</font>

438
00:17:42,000 --> 00:17:46,799
<font color="#E5E5E5">bring a little hat from a winning team</font>

439
00:17:44,520 --> 00:17:48,900
that I know of the 76ers<font color="#E5E5E5"> and so</font>

440
00:17:46,799 --> 00:17:55,740
hopefully<font color="#E5E5E5"> this will help me a lot</font>

441
00:17:48,900 --> 00:17:58,590
yeah trust<font color="#CCCCCC"> the</font><font color="#E5E5E5"> process all right can we</font>

442
00:17:55,740 --> 00:18:01,320
<font color="#E5E5E5">see that yes all right so I want to</font>

443
00:17:58,590 --> 00:18:03,389
download<font color="#E5E5E5"> some of</font><font color="#CCCCCC"> the most</font><font color="#E5E5E5"> recent benign</font>

444
00:18:01,320 --> 00:18:05,668
files that are on<font color="#E5E5E5"> virustotal and the</font>

445
00:18:03,390 --> 00:18:07,830
<font color="#E5E5E5">most recent malicious files and I want</font>

446
00:18:05,669 --> 00:18:09,929
to just<font color="#E5E5E5"> want</font><font color="#CCCCCC"> to</font><font color="#E5E5E5"> see if the ember model</font>

447
00:18:07,830 --> 00:18:12,539
<font color="#CCCCCC">fyz them correctly so keep in mind this</font>

448
00:18:09,929 --> 00:18:15,120
is<font color="#E5E5E5"> data that has just been seen by</font>

449
00:18:12,539 --> 00:18:17,730
<font color="#CCCCCC">people you know right now</font><font color="#E5E5E5"> and so that</font>

450
00:18:15,120 --> 00:18:19,620
<font color="#E5E5E5">means the</font><font color="#CCCCCC"> ember model which was trained</font>

451
00:18:17,730 --> 00:18:22,350
on data through<font color="#E5E5E5"> October you know it's</font>

452
00:18:19,620 --> 00:18:24,059
going to<font color="#E5E5E5"> be very out of date but when</font>

453
00:18:22,350 --> 00:18:25,408
I've<font color="#E5E5E5"> done this demo myself the Ember</font>

454
00:18:24,059 --> 00:18:26,970
model has been you know<font color="#E5E5E5"> as a pretty good</font>

455
00:18:25,409 --> 00:18:30,510
<font color="#CCCCCC">winning percentage just like the 76ers</font>

456
00:18:26,970 --> 00:18:32,490
<font color="#CCCCCC">so we should</font><font color="#E5E5E5"> be good all right</font><font color="#CCCCCC"> let's see</font>

457
00:18:30,510 --> 00:18:34,049
<font color="#E5E5E5">I'm running</font><font color="#CCCCCC"> this</font><font color="#E5E5E5"> through my phone so I'm</font>

458
00:18:32,490 --> 00:18:36,149
<font color="#CCCCCC">going to skip</font><font color="#E5E5E5"> the</font><font color="#CCCCCC"> five megabyte</font><font color="#E5E5E5"> and take</font>

459
00:18:34,049 --> 00:18:37,889
a smaller one<font color="#E5E5E5"> I'm going</font><font color="#CCCCCC"> to</font><font color="#E5E5E5"> download the</font>

460
00:18:36,149 --> 00:18:39,389
malware directly to my computer<font color="#E5E5E5"> I'm a</font>

461
00:18:37,890 --> 00:18:42,870
trained<font color="#CCCCCC"> professional don't worry</font><font color="#E5E5E5"> I can</font>

462
00:18:39,390 --> 00:18:46,980
<font color="#E5E5E5">do this</font><font color="#CCCCCC"> let's see this is a smaller</font>

463
00:18:42,870 --> 00:18:49,739
benign file download all<font color="#E5E5E5"> right sweet got</font>

464
00:18:46,980 --> 00:18:52,019
those so<font color="#E5E5E5"> now let's go over so I've</font>

465
00:18:49,740 --> 00:18:56,370
<font color="#E5E5E5">already downloaded the</font><font color="#CCCCCC"> Ember model and</font>

466
00:18:52,019 --> 00:18:58,350
<font color="#E5E5E5">data and you</font><font color="#CCCCCC"> can</font><font color="#E5E5E5"> see that here yeah</font>

467
00:18:56,370 --> 00:19:00,418
that's<font color="#E5E5E5"> the tar ball right</font><font color="#CCCCCC"> there I've</font>

468
00:18:58,350 --> 00:19:04,320
already<font color="#E5E5E5"> extracted it these are the JSON</font>

469
00:19:00,419 --> 00:19:06,149
features<font color="#E5E5E5"> the cool thing about like GBM</font>

470
00:19:04,320 --> 00:19:08,309
<font color="#E5E5E5">is the model is like kind of</font><font color="#CCCCCC"> it's</font>

471
00:19:06,149 --> 00:19:11,279
inspectable<font color="#E5E5E5"> it's it's just in text and</font>

472
00:19:08,309 --> 00:19:12,658
so you know you have decision trees you

473
00:19:11,279 --> 00:19:15,000
have<font color="#CCCCCC"> a bunch of decision trees</font><font color="#E5E5E5"> and you</font>

474
00:19:12,659 --> 00:19:17,639
can inspect what decisions the<font color="#CCCCCC"> like GBM</font>

475
00:19:15,000 --> 00:19:20,100
model is making<font color="#E5E5E5"> so that's pretty cool</font>

476
00:19:17,639 --> 00:19:23,000
so we downloads<font color="#E5E5E5"> we got our two downloads</font>

477
00:19:20,100 --> 00:19:25,769
there so this<font color="#CCCCCC"> is</font><font color="#E5E5E5"> the repo right here</font>

478
00:19:23,000 --> 00:19:28,289
<font color="#E5E5E5">I've already installed it but you can</font>

479
00:19:25,769 --> 00:19:30,090
just<font color="#CCCCCC"> run it</font><font color="#E5E5E5"> again there's some</font>

480
00:19:28,289 --> 00:19:33,570
instructions<font color="#CCCCCC"> in the repository itself</font>

481
00:19:30,090 --> 00:19:35,039
<font color="#E5E5E5">about what you know what requirements</font>

482
00:19:33,570 --> 00:19:36,450
you need<font color="#CCCCCC"> to install what kind of Python</font>

483
00:19:35,039 --> 00:19:38,730
packages you need to install<font color="#E5E5E5"> I've</font>

484
00:19:36,450 --> 00:19:44,240
<font color="#E5E5E5">already done</font><font color="#CCCCCC"> all of</font><font color="#E5E5E5"> that so</font>

485
00:19:38,730 --> 00:19:47,760
scripts so we give<font color="#CCCCCC"> you a</font><font color="#E5E5E5"> very nice</font>

486
00:19:44,240 --> 00:19:49,740
<font color="#E5E5E5">classified binaries</font><font color="#CCCCCC"> script that</font><font color="#E5E5E5"> will</font>

487
00:19:47,760 --> 00:19:53,158
just<font color="#CCCCCC"> help you you know make predictions</font>

488
00:19:49,740 --> 00:19:58,980
on<font color="#E5E5E5"> new PE files once you have a model so</font>

489
00:19:53,159 --> 00:20:04,649
let's specify the model<font color="#CCCCCC"> ADA amber model</font>

490
00:19:58,980 --> 00:20:07,710
<font color="#E5E5E5">and downloads</font><font color="#CCCCCC"> all</font><font color="#E5E5E5"> right we're making</font>

491
00:20:04,649 --> 00:20:11,309
predictions<font color="#E5E5E5"> all right we did</font><font color="#CCCCCC"> all right</font>

492
00:20:07,710 --> 00:20:13,950
maybe I hope<font color="#E5E5E5"> so it the model loads very</font>

493
00:20:11,309 --> 00:20:15,840
quickly<font color="#CCCCCC"> and you see this one got a very</font>

494
00:20:13,950 --> 00:20:17,950
high score that's<font color="#CCCCCC"> f82 let's hope that's</font>

495
00:20:15,840 --> 00:20:21,490
the malicious one

496
00:20:17,950 --> 00:20:22,810
yes it was and the benign one scored

497
00:20:21,490 --> 00:20:24,220
<font color="#E5E5E5">pretty high that's actually in all my</font>

498
00:20:22,810 --> 00:20:28,200
<font color="#E5E5E5">tests</font><font color="#CCCCCC"> it's kind</font><font color="#E5E5E5"> of the highest that a</font>

499
00:20:24,220 --> 00:20:30,730
benign file has scored so<font color="#E5E5E5"> one four nine</font>

500
00:20:28,200 --> 00:20:31,930
yep that was<font color="#E5E5E5"> the one</font><font color="#CCCCCC"> we done found on it</font>

501
00:20:30,730 --> 00:20:36,030
so victory

502
00:20:31,930 --> 00:20:36,030
just like the Sixers<font color="#CCCCCC"> yeah nice</font><font color="#E5E5E5"> all right</font>

503
00:20:40,050 --> 00:20:46,990
all right<font color="#E5E5E5"> so this is</font><font color="#CCCCCC"> all available the</font>

504
00:20:44,710 --> 00:20:48,580
<font color="#E5E5E5">links the presentation is in sched</font><font color="#CCCCCC"> so</font>

505
00:20:46,990 --> 00:20:50,770
these links<font color="#CCCCCC"> you know you should be</font><font color="#E5E5E5"> able</font>

506
00:20:48,580 --> 00:20:52,990
to<font color="#E5E5E5"> get them but we've we've released a</font>

507
00:20:50,770 --> 00:20:53,290
paper<font color="#E5E5E5"> this is</font><font color="#CCCCCC"> the highlight sentence for</font>

508
00:20:52,990 --> 00:20:57,070
me

509
00:20:53,290 --> 00:21:00,370
evidently<font color="#E5E5E5"> well so in the paper</font><font color="#CCCCCC"> Hiram was</font>

510
00:20:57,070 --> 00:21:02,800
gracious enough<font color="#E5E5E5"> to train a neural</font>

511
00:21:00,370 --> 00:21:04,600
network<font color="#E5E5E5"> based model himself based on</font>

512
00:21:02,800 --> 00:21:06,610
some recent literature<font color="#CCCCCC"> and we kind of</font>

513
00:21:04,600 --> 00:21:08,560
compared that performance to creating

514
00:21:06,610 --> 00:21:10,419
this simple gradient boosted decision

515
00:21:08,560 --> 00:21:12,159
tree model<font color="#CCCCCC"> the</font><font color="#E5E5E5"> gradient boosted</font><font color="#CCCCCC"> decision</font>

516
00:21:10,420 --> 00:21:12,640
trees did you know slightly slightly

517
00:21:12,160 --> 00:21:15,220
<font color="#E5E5E5">better</font>

518
00:21:12,640 --> 00:21:16,570
so we're saying you know you know at the

519
00:21:15,220 --> 00:21:18,520
current state of<font color="#E5E5E5"> the art these</font>

520
00:21:16,570 --> 00:21:21,490
featureless models are not you know<font color="#E5E5E5"> up</font>

521
00:21:18,520 --> 00:21:23,950
<font color="#CCCCCC">to snuff from the from these older type</font>

522
00:21:21,490 --> 00:21:26,020
models<font color="#E5E5E5"> so you know we think there's</font>

523
00:21:23,950 --> 00:21:28,840
potential in<font color="#E5E5E5"> the field and we hope this</font>

524
00:21:26,020 --> 00:21:32,230
<font color="#E5E5E5">kind of data set kind of</font><font color="#CCCCCC"> Spurs that</font><font color="#E5E5E5"> kind</font>

525
00:21:28,840 --> 00:21:34,810
<font color="#CCCCCC">of research in</font><font color="#E5E5E5"> on two featureless neural</font>

526
00:21:32,230 --> 00:21:37,150
network models<font color="#E5E5E5"> and so I just want to say</font>

527
00:21:34,810 --> 00:21:39,129
bring<font color="#E5E5E5"> it all right</font>

528
00:21:37,150 --> 00:21:41,940
download the data<font color="#E5E5E5"> download the code</font>

529
00:21:39,130 --> 00:21:41,940
thanks a lot

530
00:21:44,640 --> 00:21:54,720
how did I do do I have time for

531
00:21:46,500 --> 00:21:56,580
<font color="#E5E5E5">questions okay do you want to bring the</font>

532
00:21:54,720 --> 00:22:07,860
microphone<font color="#E5E5E5"> or you guys can just yell it</font>

533
00:21:56,580 --> 00:22:10,110
<font color="#E5E5E5">out if you want yep</font>

534
00:22:07,860 --> 00:22:12,029
secondly have you looked at<font color="#E5E5E5"> packed</font>

535
00:22:10,110 --> 00:22:18,750
samples and the entropy features of

536
00:22:12,029 --> 00:22:21,750
obfuscated code yeah as<font color="#E5E5E5"> an if I give you</font>

537
00:22:18,750 --> 00:22:24,360
a packed<font color="#E5E5E5"> wimpy sample how is your model</font>

538
00:22:21,750 --> 00:22:26,580
gonna detect it<font color="#E5E5E5"> yeah packed samples are</font>

539
00:22:24,360 --> 00:22:30,090
definitely hard<font color="#E5E5E5"> I haven't looked at them</font>

540
00:22:26,580 --> 00:22:31,789
<font color="#E5E5E5">in the Ember</font><font color="#CCCCCC"> dataset specifically but</font><font color="#E5E5E5"> we</font>

541
00:22:30,090 --> 00:22:37,709
deal with<font color="#E5E5E5"> them all the time</font><font color="#CCCCCC"> when</font>

542
00:22:31,789 --> 00:22:39,000
<font color="#E5E5E5">training malware score</font><font color="#CCCCCC"> and yeah</font><font color="#E5E5E5"> we can</font>

543
00:22:37,710 --> 00:22:41,519
definitely detect them like you<font color="#CCCCCC"> said</font>

544
00:22:39,000 --> 00:22:42,809
with entropy<font color="#E5E5E5"> base features and</font>

545
00:22:41,519 --> 00:22:46,769
<font color="#CCCCCC">everything so the model knows that they</font>

546
00:22:42,809 --> 00:22:48,149
it's just<font color="#E5E5E5"> hard at</font><font color="#CCCCCC"> to to make a good</font>

547
00:22:46,769 --> 00:22:49,710
<font color="#CCCCCC">decision because you</font><font color="#E5E5E5"> can't learn very</font>

548
00:22:48,149 --> 00:22:52,860
<font color="#CCCCCC">much about what's</font><font color="#E5E5E5"> actually in like a</font>

549
00:22:49,710 --> 00:22:54,929
packed file<font color="#E5E5E5"> but so far we've done pretty</font>

550
00:22:52,860 --> 00:22:57,059
well good performance<font color="#E5E5E5"> and you know maybe</font>

551
00:22:54,929 --> 00:22:59,639
people<font color="#E5E5E5"> can take this</font><font color="#CCCCCC"> and find</font><font color="#E5E5E5"> even</font>

552
00:22:57,059 --> 00:23:03,059
<font color="#CCCCCC">better ways to get features from ops II</font>

553
00:22:59,639 --> 00:23:07,320
but<font color="#E5E5E5"> I skated files</font><font color="#CCCCCC"> and how do</font><font color="#E5E5E5"> you watch</font>

554
00:23:03,059 --> 00:23:10,860
the score variance between two malware<font color="#E5E5E5"> I</font>

555
00:23:07,320 --> 00:23:13,799
mean a malware belonging to family one

556
00:23:10,860 --> 00:23:16,590
but<font color="#E5E5E5"> its variant a and variant be so Yara</font>

557
00:23:13,799 --> 00:23:18,269
catches those<font color="#E5E5E5"> pretty well because apart</font>

558
00:23:16,590 --> 00:23:21,629
<font color="#CCCCCC">from</font><font color="#E5E5E5"> the shy you have different variants</font>

559
00:23:18,269 --> 00:23:25,789
<font color="#CCCCCC">that</font><font color="#E5E5E5"> you can code up in a Yara rule</font><font color="#CCCCCC"> how</font>

560
00:23:21,630 --> 00:23:29,100
do we do that how will<font color="#CCCCCC"> amber detect</font>

561
00:23:25,789 --> 00:23:31,408
<font color="#E5E5E5">variants which are very similar but at</font>

562
00:23:29,100 --> 00:23:34,980
the<font color="#E5E5E5"> different sample I have</font><font color="#CCCCCC"> different</font>

563
00:23:31,409 --> 00:23:37,860
<font color="#E5E5E5">shots so you're saying if there's a</font>

564
00:23:34,980 --> 00:23:39,510
common<font color="#CCCCCC"> family and there's just a little</font>

565
00:23:37,860 --> 00:23:43,439
little difference between<font color="#E5E5E5"> something that</font>

566
00:23:39,510 --> 00:23:44,580
<font color="#E5E5E5">might exist</font><font color="#CCCCCC"> yes</font><font color="#E5E5E5"> yes oh I mean you would</font>

567
00:23:43,440 --> 00:23:46,860
hope that the machine<font color="#E5E5E5"> learning model</font>

568
00:23:44,580 --> 00:23:49,019
would would find features that exist<font color="#CCCCCC"> in</font>

569
00:23:46,860 --> 00:23:51,029
all the different in all the different

570
00:23:49,019 --> 00:23:53,789
samples of<font color="#E5E5E5"> the same family and</font><font color="#CCCCCC"> would be</font>

571
00:23:51,029 --> 00:23:56,070
able<font color="#CCCCCC"> to you</font><font color="#E5E5E5"> know make decisions based on</font>

572
00:23:53,789 --> 00:23:58,330
<font color="#E5E5E5">the</font><font color="#CCCCCC"> ones</font><font color="#E5E5E5"> that it has seen and make an</font>

573
00:23:56,070 --> 00:24:00,908
accurate<font color="#CCCCCC"> decision on something</font>

574
00:23:58,330 --> 00:24:02,350
family that<font color="#E5E5E5"> hasn't seen</font><font color="#CCCCCC"> before did that</font>

575
00:24:00,909 --> 00:24:03,970
answer<font color="#E5E5E5"> your question yeah yeah okay good</font>

576
00:24:02,350 --> 00:24:14,199
<font color="#E5E5E5">but great initiative thank you okay</font>

577
00:24:03,970 --> 00:24:15,429
<font color="#CCCCCC">thanks yeah I'd liked your talk I had so</font>

578
00:24:14,200 --> 00:24:16,809
many questions<font color="#CCCCCC"> while</font><font color="#E5E5E5"> you're giving</font><font color="#CCCCCC"> the</font>

579
00:24:15,429 --> 00:24:20,649
talk but you<font color="#CCCCCC"> actually answered quite a</font>

580
00:24:16,809 --> 00:24:24,820
few<font color="#E5E5E5"> toward the end</font><font color="#CCCCCC"> I guess I'm a little</font>

581
00:24:20,649 --> 00:24:27,330
<font color="#E5E5E5">bit new enough to ml and deep learning</font>

582
00:24:24,820 --> 00:24:30,070
to be dangerous it's<font color="#CCCCCC"> not my original</font>

583
00:24:27,330 --> 00:24:33,189
<font color="#E5E5E5">technical expertise</font><font color="#CCCCCC"> but I was a little</font>

584
00:24:30,070 --> 00:24:34,809
<font color="#CCCCCC">confused about</font><font color="#E5E5E5"> sha-1 using it because I</font>

585
00:24:33,190 --> 00:24:37,480
mean sha-1 unless<font color="#E5E5E5"> you have an exact</font>

586
00:24:34,809 --> 00:24:39,549
match<font color="#CCCCCC"> it's just gonna</font><font color="#E5E5E5"> be different for</font>

587
00:24:37,480 --> 00:24:41,559
everything it and<font color="#CCCCCC"> it's in theory a</font>

588
00:24:39,549 --> 00:24:43,480
uniform<font color="#CCCCCC"> distribution - yeah definitely</font>

589
00:24:41,559 --> 00:24:45,899
<font color="#E5E5E5">advise you nothing is wrong I should</font>

590
00:24:43,480 --> 00:24:48,130
have been<font color="#E5E5E5"> maybe more explicit that we're</font>

591
00:24:45,899 --> 00:24:50,949
distributing the<font color="#CCCCCC"> Shaw's</font><font color="#E5E5E5"> of all the files</font>

592
00:24:48,130 --> 00:24:53,169
<font color="#CCCCCC">the</font><font color="#E5E5E5"> sha-256 but it's not meant</font><font color="#CCCCCC"> to be</font>

593
00:24:50,950 --> 00:24:55,690
<font color="#E5E5E5">used</font><font color="#CCCCCC"> as</font><font color="#E5E5E5"> a feature that you would train</font>

594
00:24:53,169 --> 00:24:58,059
on it's definitely<font color="#CCCCCC"> meant to be like</font><font color="#E5E5E5"> if</font>

595
00:24:55,690 --> 00:25:00,130
you have access<font color="#CCCCCC"> to these files then you</font>

596
00:24:58,059 --> 00:25:03,129
need this shot and<font color="#E5E5E5"> you can</font><font color="#CCCCCC"> go and</font><font color="#E5E5E5"> get</font>

597
00:25:00,130 --> 00:25:05,350
<font color="#E5E5E5">the file yourself so it's more metadata</font>

598
00:25:03,130 --> 00:25:08,679
<font color="#E5E5E5">and not data that's meant</font><font color="#CCCCCC"> to be trained</font>

599
00:25:05,350 --> 00:25:09,639
on doctrine<font color="#CCCCCC"> now</font><font color="#E5E5E5"> I think you had</font>

600
00:25:08,679 --> 00:25:12,519
information<font color="#CCCCCC"> in here</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> I could</font>

601
00:25:09,639 --> 00:25:15,189
distinguish by operating system somehow

602
00:25:12,519 --> 00:25:17,230
<font color="#E5E5E5">I mean I think you had some metadata in</font>

603
00:25:15,190 --> 00:25:19,120
there that made<font color="#E5E5E5"> because like in my</font>

604
00:25:17,230 --> 00:25:20,559
<font color="#CCCCCC">environment I'm</font><font color="#E5E5E5"> almost all Linux and I I</font>

605
00:25:19,120 --> 00:25:23,260
could care less about<font color="#E5E5E5"> Windows for</font>

606
00:25:20,559 --> 00:25:25,470
<font color="#CCCCCC">example you know malware for</font><font color="#E5E5E5"> Linux</font>

607
00:25:23,260 --> 00:25:27,970
<font color="#CCCCCC">windows you're talking about</font>

608
00:25:25,470 --> 00:25:30,010
<font color="#CCCCCC">can run this</font><font color="#E5E5E5"> no other features</font><font color="#CCCCCC"> of</font>

609
00:25:27,970 --> 00:25:32,169
features<font color="#CCCCCC"> oh okay</font><font color="#E5E5E5"> yeah</font><font color="#CCCCCC"> I mean we're just</font>

610
00:25:30,010 --> 00:25:34,269
<font color="#CCCCCC">grabbing whatever is in the PE header</font>

611
00:25:32,169 --> 00:25:37,019
there<font color="#E5E5E5"> okay but</font><font color="#CCCCCC"> I can separate</font><font color="#E5E5E5"> them all</font>

612
00:25:34,269 --> 00:25:39,340
<font color="#CCCCCC">defined they do when I'm training oh</font>

613
00:25:37,019 --> 00:25:41,950
<font color="#E5E5E5">okay like a different kind of like yeah</font>

614
00:25:39,340 --> 00:25:43,418
you could do<font color="#E5E5E5"> that I mean combining</font>

615
00:25:41,950 --> 00:25:45,309
different<font color="#E5E5E5"> models like training separate</font>

616
00:25:43,419 --> 00:25:48,130
models for different<font color="#E5E5E5"> subsets like that's</font>

617
00:25:45,309 --> 00:25:51,779
definitely<font color="#CCCCCC"> something you</font><font color="#E5E5E5"> can do and then</font>

618
00:25:48,130 --> 00:25:51,779
now I've lost<font color="#E5E5E5"> track of my third question</font>

619
00:25:52,409 --> 00:25:57,120
<font color="#E5E5E5">sounds good thank you</font><font color="#CCCCCC"> very much very</font>

620
00:25:54,370 --> 00:25:57,120
<font color="#CCCCCC">appreciate it</font>

621
00:26:02,900 --> 00:26:07,350
you still have<font color="#E5E5E5"> like five minutes</font><font color="#CCCCCC"> of for</font>

622
00:26:05,430 --> 00:26:14,430
questions of you if anyone in the

623
00:26:07,350 --> 00:26:17,219
audience I wants to ask questions now I

624
00:26:14,430 --> 00:26:20,130
<font color="#CCCCCC">remember my third question</font><font color="#E5E5E5"> one of the</font>

625
00:26:17,220 --> 00:26:22,350
<font color="#E5E5E5">things is I'm getting other data like if</font>

626
00:26:20,130 --> 00:26:23,190
<font color="#E5E5E5">malware comes in I'm gonna have bait I'm</font>

627
00:26:22,350 --> 00:26:25,230
<font color="#E5E5E5">gonna have logs</font>

628
00:26:23,190 --> 00:26:28,080
<font color="#E5E5E5">Splunk logs which will tell me the</font>

629
00:26:25,230 --> 00:26:30,360
behavior of something<font color="#CCCCCC"> coming in and I</font>

630
00:26:28,080 --> 00:26:32,850
was<font color="#CCCCCC"> wondering in the features</font><font color="#E5E5E5"> I you said</font>

631
00:26:30,360 --> 00:26:35,459
you<font color="#CCCCCC"> just had really</font><font color="#E5E5E5"> three labels</font><font color="#CCCCCC"> no you</font>

632
00:26:32,850 --> 00:26:37,889
<font color="#E5E5E5">know malware not malware or unknown yeah</font>

633
00:26:35,460 --> 00:26:40,860
and in the<font color="#E5E5E5"> future</font><font color="#CCCCCC"> you have</font><font color="#E5E5E5"> more</font>

634
00:26:37,890 --> 00:26:42,060
distinction<font color="#CCCCCC"> like you know like I know</font>

635
00:26:40,860 --> 00:26:43,649
there's a lot<font color="#CCCCCC"> of different distinctions</font>

636
00:26:42,060 --> 00:26:46,500
well<font color="#E5E5E5"> yes it sounds</font><font color="#CCCCCC"> like you're getting</font>

637
00:26:43,650 --> 00:26:48,420
into<font color="#E5E5E5"> like behavior and like what it when</font>

638
00:26:46,500 --> 00:26:50,370
<font color="#E5E5E5">this was downloaded when this ran what</font>

639
00:26:48,420 --> 00:26:51,750
did it do beyond<font color="#E5E5E5"> this right and that's</font>

640
00:26:50,370 --> 00:26:53,729
<font color="#E5E5E5">definitely something you can</font><font color="#CCCCCC"> do that's</font>

641
00:26:51,750 --> 00:26:55,710
<font color="#CCCCCC">kind of like out of</font><font color="#E5E5E5"> the scope of just</font>

642
00:26:53,730 --> 00:26:57,540
static malware detection where you<font color="#E5E5E5"> just</font>

643
00:26:55,710 --> 00:27:00,690
want to use the data without<font color="#E5E5E5"> running it</font>

644
00:26:57,540 --> 00:27:02,460
and make a<font color="#CCCCCC"> decision just with</font><font color="#E5E5E5"> only that</font>

645
00:27:00,690 --> 00:27:04,620
<font color="#CCCCCC">information well I like</font><font color="#E5E5E5"> to combine it</font>

646
00:27:02,460 --> 00:27:08,040
with the<font color="#E5E5E5"> executive data yes yeah and</font>

647
00:27:04,620 --> 00:27:10,020
<font color="#E5E5E5">there's more opportunities for that yeah</font>

648
00:27:08,040 --> 00:27:12,300
<font color="#CCCCCC">we're</font><font color="#E5E5E5"> not including information about</font>

649
00:27:10,020 --> 00:27:14,820
what these<font color="#CCCCCC"> files</font><font color="#E5E5E5"> would do if they were</font>

650
00:27:12,300 --> 00:27:16,590
run<font color="#CCCCCC"> it's kind of out of</font><font color="#E5E5E5"> the scope but</font>

651
00:27:14,820 --> 00:27:19,230
but yeah that's<font color="#E5E5E5"> definitely you would</font>

652
00:27:16,590 --> 00:27:20,939
want<font color="#E5E5E5"> to move beyond that and and make</font>

653
00:27:19,230 --> 00:27:22,080
more<font color="#E5E5E5"> complicated models with all the</font>

654
00:27:20,940 --> 00:27:23,250
information<font color="#CCCCCC"> these are in the public</font>

655
00:27:22,080 --> 00:27:24,960
<font color="#E5E5E5">domain</font><font color="#CCCCCC"> so they probably</font><font color="#E5E5E5"> have</font>

656
00:27:23,250 --> 00:27:28,560
descriptions associated with them right

657
00:27:24,960 --> 00:27:30,180
how do you<font color="#E5E5E5"> operate</font><font color="#CCCCCC"> what they what's in</font>

658
00:27:28,560 --> 00:27:32,460
public I<font color="#E5E5E5"> mean that all the data is out</font>

659
00:27:30,180 --> 00:27:34,350
<font color="#E5E5E5">there now no but I mean the the</font><font color="#CCCCCC"> malware</font>

660
00:27:32,460 --> 00:27:36,750
<font color="#E5E5E5">that you've done the</font><font color="#CCCCCC"> SHA</font><font color="#E5E5E5"> ones on and</font>

661
00:27:34,350 --> 00:27:38,429
everything<font color="#E5E5E5"> they're well</font><font color="#CCCCCC"> known they have</font>

662
00:27:36,750 --> 00:27:42,180
behaviors associated with them

663
00:27:38,430 --> 00:27:44,520
yeah yeah<font color="#CCCCCC"> it</font><font color="#E5E5E5"> probably a lot of it it</font>

664
00:27:42,180 --> 00:27:46,890
<font color="#CCCCCC">probably is commodity malware we didn't</font>

665
00:27:44,520 --> 00:27:48,389
pick<font color="#CCCCCC"> it to be you know to be from</font>

666
00:27:46,890 --> 00:27:51,330
certain families or anything<font color="#E5E5E5"> it's kind</font>

667
00:27:48,390 --> 00:27:52,650
of a uniform<font color="#E5E5E5"> just</font><font color="#CCCCCC"> not good random so</font>

668
00:27:51,330 --> 00:27:54,659
yeah there<font color="#CCCCCC"> probably are very well-known</font>

669
00:27:52,650 --> 00:27:58,190
things in the<font color="#E5E5E5"> data set so I can dig them</font>

670
00:27:54,660 --> 00:27:58,190
<font color="#E5E5E5">out yeah okay</font><font color="#CCCCCC"> great</font><font color="#E5E5E5"> yeah thank you</font>

671
00:28:03,790 --> 00:28:07,970
if there are no more<font color="#E5E5E5"> questions</font><font color="#CCCCCC"> let's</font>

672
00:28:06,560 --> 00:28:10,510
<font color="#CCCCCC">take the opportunity to thank our</font>

673
00:28:07,970 --> 00:28:10,510
speaker again

