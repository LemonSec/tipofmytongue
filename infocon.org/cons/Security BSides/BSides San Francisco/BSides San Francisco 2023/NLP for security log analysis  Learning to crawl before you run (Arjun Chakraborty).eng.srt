1
00:00:00,000 --> 00:00:03,000
hey everyone uh my name is Arjun and

2
00:00:03,000 --> 00:00:05,040
welcome to my talk titled NLP for

3
00:00:05,040 --> 00:00:07,440
security log analysis uh learning to

4
00:00:07,440 --> 00:00:09,960
crawl before you run

5
00:00:09,960 --> 00:00:12,360
um so let's just start off with a sort

6
00:00:12,360 --> 00:00:15,000
of a brief introduction to myself uh I'm

7
00:00:15,000 --> 00:00:17,220
a detection engineer at databricks

8
00:00:17,220 --> 00:00:19,859
I've been kind of in the ml security

9
00:00:19,859 --> 00:00:21,660
domain for a while

10
00:00:21,660 --> 00:00:24,359
uh and some people would call it a

11
00:00:24,359 --> 00:00:26,340
specialized skill I'm having a

12
00:00:26,340 --> 00:00:28,320
full-blown existential crisis that's me

13
00:00:28,320 --> 00:00:30,300
on the side not part of any of these

14
00:00:30,300 --> 00:00:33,180
groups so hope you'll get some at some

15
00:00:33,180 --> 00:00:34,500
point I'll be there somewhere in the

16
00:00:34,500 --> 00:00:35,399
middle

17
00:00:35,399 --> 00:00:37,620
but yeah that's kind of been like my

18
00:00:37,620 --> 00:00:39,719
whole career basically so I thought this

19
00:00:39,719 --> 00:00:41,640
was an appropriate way to sort of put

20
00:00:41,640 --> 00:00:44,360
myself out there

21
00:00:44,520 --> 00:00:46,320
uh so we have quite a few things on the

22
00:00:46,320 --> 00:00:47,700
agenda so

23
00:00:47,700 --> 00:00:49,200
um most of my talk is focused on

24
00:00:49,200 --> 00:00:52,860
embeddings and I will talk uh about what

25
00:00:52,860 --> 00:00:54,360
embeddings are and what they sort of

26
00:00:54,360 --> 00:00:55,260
represent

27
00:00:55,260 --> 00:00:58,140
but the idea is like uh can we actually

28
00:00:58,140 --> 00:01:00,780
use NLP models to sort of build out

29
00:01:00,780 --> 00:01:02,820
embeddings and then sort of use them

30
00:01:02,820 --> 00:01:04,860
Downstream for detection engineering

31
00:01:04,860 --> 00:01:07,220
tasks

32
00:01:08,520 --> 00:01:11,760
so I think this particular sort of

33
00:01:11,760 --> 00:01:14,040
diagram or or chart is like very

34
00:01:14,040 --> 00:01:15,840
familiar to a lot of people who work on

35
00:01:15,840 --> 00:01:17,280
the detection engineering side of things

36
00:01:17,280 --> 00:01:19,200
uh you know you have like a bunch of

37
00:01:19,200 --> 00:01:20,880
data that sort of comes in you're trying

38
00:01:20,880 --> 00:01:22,080
to do detection you're trying to do

39
00:01:22,080 --> 00:01:24,420
correlation uh and then you're sort of

40
00:01:24,420 --> 00:01:26,580
feeding in alerts to the sort of the IR

41
00:01:26,580 --> 00:01:27,540
team

42
00:01:27,540 --> 00:01:30,119
uh now the sort of the idea is like this

43
00:01:30,119 --> 00:01:32,280
is not sort of restricted to just

44
00:01:32,280 --> 00:01:35,100
security you know I feel like the idea

45
00:01:35,100 --> 00:01:37,820
of extracting sort of signal from noise

46
00:01:37,820 --> 00:01:40,920
uh is sort of relevant across a lot of

47
00:01:40,920 --> 00:01:42,600
different domains and that's kind of

48
00:01:42,600 --> 00:01:44,700
what I was thinking when I was thinking

49
00:01:44,700 --> 00:01:47,159
about using NLP techniques like it's it

50
00:01:47,159 --> 00:01:48,720
shouldn't be just restricted to security

51
00:01:48,720 --> 00:01:50,880
it shouldn't just be restricted to other

52
00:01:50,880 --> 00:01:53,460
fields so why not security because the

53
00:01:53,460 --> 00:01:56,159
problems are the same security logs I

54
00:01:56,159 --> 00:01:58,220
believe are a language of Their Own

55
00:01:58,220 --> 00:02:00,659
uh probably harder than a lot of other

56
00:02:00,659 --> 00:02:04,460
languages and NLP I feel like has been

57
00:02:04,460 --> 00:02:06,600
specifically designed to help with

58
00:02:06,600 --> 00:02:09,419
context and I do believe context is very

59
00:02:09,419 --> 00:02:11,099
important in security so that's kind of

60
00:02:11,099 --> 00:02:12,660
where

61
00:02:12,660 --> 00:02:14,580
um sort of things built up for me when I

62
00:02:14,580 --> 00:02:16,200
was sort of thinking about this and when

63
00:02:16,200 --> 00:02:17,640
I was working on the project associated

64
00:02:17,640 --> 00:02:20,420
with it as well

65
00:02:21,300 --> 00:02:22,680
um we'll now sort of get into the

66
00:02:22,680 --> 00:02:24,920
detection engineering side of things

67
00:02:24,920 --> 00:02:29,340
on the left here are sort of um

68
00:02:29,340 --> 00:02:32,459
examples of kubernetes audit logs I took

69
00:02:32,459 --> 00:02:35,520
like kubernetes as an example because I

70
00:02:35,520 --> 00:02:36,959
feel like I spend a disproportionate

71
00:02:36,959 --> 00:02:38,760
amount of time staring at them and they

72
00:02:38,760 --> 00:02:40,620
are my favorite logs I feel like by now

73
00:02:40,620 --> 00:02:42,480
so the idea is like when I'm building

74
00:02:42,480 --> 00:02:44,280
out detections like how do I go about

75
00:02:44,280 --> 00:02:45,780
doing it like

76
00:02:45,780 --> 00:02:47,879
I do believe like static rules are very

77
00:02:47,879 --> 00:02:49,620
important so you know you're looking at

78
00:02:49,620 --> 00:02:51,900
maybe user agents maybe you're looking

79
00:02:51,900 --> 00:02:53,700
at resources looking at a bunch of

80
00:02:53,700 --> 00:02:56,099
different fields uh the problem with

81
00:02:56,099 --> 00:02:59,580
these sort of logs sort of arises is the

82
00:02:59,580 --> 00:03:01,440
fact that

83
00:03:01,440 --> 00:03:03,780
um schemas become very complicated uh

84
00:03:03,780 --> 00:03:06,060
cardinality of certain features becomes

85
00:03:06,060 --> 00:03:08,220
really difficult to manage so that point

86
00:03:08,220 --> 00:03:10,260
of time you know you're kind of playing

87
00:03:10,260 --> 00:03:12,180
whack-a-mole with your your static

88
00:03:12,180 --> 00:03:14,459
detection rules and most of the times

89
00:03:14,459 --> 00:03:16,440
you know if you just have those rules

90
00:03:16,440 --> 00:03:17,519
you're going to miss out on something

91
00:03:17,519 --> 00:03:20,940
not to say that they're not important so

92
00:03:20,940 --> 00:03:22,739
having sort of worked on sort of the ml

93
00:03:22,739 --> 00:03:24,480
detection side of things I do believe

94
00:03:24,480 --> 00:03:25,560
that

95
00:03:25,560 --> 00:03:27,900
sort of there is a lot of

96
00:03:27,900 --> 00:03:30,360
um uh I would say there's a lot of

97
00:03:30,360 --> 00:03:32,580
advantages to using sort of a narrow

98
00:03:32,580 --> 00:03:34,260
approach which is sort of associated

99
00:03:34,260 --> 00:03:37,140
with static rules and then there is

100
00:03:37,140 --> 00:03:38,519
um you know you have sort of umbrella

101
00:03:38,519 --> 00:03:40,019
models as I like to call it with with

102
00:03:40,019 --> 00:03:41,879
either you're using machine learning or

103
00:03:41,879 --> 00:03:43,739
you're using other techniques to sort of

104
00:03:43,739 --> 00:03:45,540
get like a more holistic view of your

105
00:03:45,540 --> 00:03:47,299
detection sort of engineering use case

106
00:03:47,299 --> 00:03:49,560
uh which is kind of why I have these

107
00:03:49,560 --> 00:03:51,360
options here so you know your option one

108
00:03:51,360 --> 00:03:53,519
is your static rules then you have your

109
00:03:53,519 --> 00:03:55,920
embedding or other ml techniques but the

110
00:03:55,920 --> 00:03:57,420
best way to sort of use them I believe

111
00:03:57,420 --> 00:03:59,340
is using a combination of all these

112
00:03:59,340 --> 00:04:01,080
options

113
00:04:01,080 --> 00:04:02,819
um

114
00:04:02,819 --> 00:04:04,860
so what are our embeddings and this is

115
00:04:04,860 --> 00:04:07,319
kind of like the core of my talk

116
00:04:07,319 --> 00:04:09,239
um embeddings are nothing but numerical

117
00:04:09,239 --> 00:04:12,299
representations of a word or a phrase

118
00:04:12,299 --> 00:04:15,540
um they're widely used in uh pretty much

119
00:04:15,540 --> 00:04:17,279
every other field that has text

120
00:04:17,279 --> 00:04:18,899
associated with it you know

121
00:04:18,899 --> 00:04:20,940
recommendation systems are something

122
00:04:20,940 --> 00:04:23,880
that pops out that you know use a lot of

123
00:04:23,880 --> 00:04:25,560
a lot of embeddings very very

124
00:04:25,560 --> 00:04:27,419
successfully so it's basically you know

125
00:04:27,419 --> 00:04:29,639
the ability to sort of map this word or

126
00:04:29,639 --> 00:04:31,919
phrase or in this case a security log

127
00:04:31,919 --> 00:04:36,300
to a vector of numbers this could mostly

128
00:04:36,300 --> 00:04:39,300
be in a higher dimensional space so what

129
00:04:39,300 --> 00:04:41,460
it basically means is you know you have

130
00:04:41,460 --> 00:04:43,440
your audit logs which are mostly and

131
00:04:43,440 --> 00:04:45,060
completely just text

132
00:04:45,060 --> 00:04:47,280
uh you have like an embedding model and

133
00:04:47,280 --> 00:04:48,720
then you end up building these features

134
00:04:48,720 --> 00:04:50,940
which you can then use Downstream so

135
00:04:50,940 --> 00:04:52,800
embeddings are basically your core of

136
00:04:52,800 --> 00:04:54,540
all the other Downstream tasks that

137
00:04:54,540 --> 00:04:56,340
you're sort of trying to build out but

138
00:04:56,340 --> 00:04:58,440
what I really like to call it is it's

139
00:04:58,440 --> 00:05:00,360
essentially essentially building a

140
00:05:00,360 --> 00:05:03,300
representation of logs so it's trying to

141
00:05:03,300 --> 00:05:05,340
incorporate context as well and which

142
00:05:05,340 --> 00:05:07,380
I'll talk about later but the fact that

143
00:05:07,380 --> 00:05:08,759
this representation can be really

144
00:05:08,759 --> 00:05:10,979
powerful in terms of doing a bunch of

145
00:05:10,979 --> 00:05:12,840
other Downstream tasks I think that's

146
00:05:12,840 --> 00:05:16,320
where sort of the the core of uh the

147
00:05:16,320 --> 00:05:18,180
embedding side of things uh sort of lie

148
00:05:18,180 --> 00:05:19,800
in

149
00:05:19,800 --> 00:05:21,720
um just a quick pointer to like sort of

150
00:05:21,720 --> 00:05:23,160
this um

151
00:05:23,160 --> 00:05:25,740
uh this diagram here

152
00:05:25,740 --> 00:05:27,180
um you know I wanted to take an example

153
00:05:27,180 --> 00:05:29,759
of like two different user agents and I

154
00:05:29,759 --> 00:05:31,259
wanted to point them out that you know

155
00:05:31,259 --> 00:05:32,699
if you actually sort of build out the

156
00:05:32,699 --> 00:05:34,919
embeddings associated with them and sort

157
00:05:34,919 --> 00:05:36,539
of uh display them on a

158
00:05:36,539 --> 00:05:38,400
three-dimensional plane you'll see that

159
00:05:38,400 --> 00:05:39,900
the distance between them is not just

160
00:05:39,900 --> 00:05:40,979
the fact that you know they have

161
00:05:40,979 --> 00:05:42,479
different strings associated with them

162
00:05:42,479 --> 00:05:44,960
embeddings actually help you sort of

163
00:05:44,960 --> 00:05:47,039
differentiate between logs which is

164
00:05:47,039 --> 00:05:48,600
which is so important when I believe

165
00:05:48,600 --> 00:05:50,400
like when you're sort of dealing with

166
00:05:50,400 --> 00:05:51,840
detection engineering tasks because

167
00:05:51,840 --> 00:05:53,820
you're trying to sort of you're spending

168
00:05:53,820 --> 00:05:55,620
a lot of time sort of trying to

169
00:05:55,620 --> 00:05:57,660
um like kind of find the needle in the

170
00:05:57,660 --> 00:06:00,000
haystack so it's a really important to

171
00:06:00,000 --> 00:06:01,560
figure out methodologies that would help

172
00:06:01,560 --> 00:06:04,100
you do that

173
00:06:05,520 --> 00:06:08,580
so I've kind of mentioned uh context a

174
00:06:08,580 --> 00:06:09,960
couple of times and I wanted to sort of

175
00:06:09,960 --> 00:06:12,720
elaborate a little bit on that uh

176
00:06:12,720 --> 00:06:14,759
on the left is a completely fake user

177
00:06:14,759 --> 00:06:16,620
agent I'm pretty sure this doesn't exist

178
00:06:16,620 --> 00:06:19,320
but uh I wanted to point out the word

179
00:06:19,320 --> 00:06:21,120
Linux right because it's that's really

180
00:06:21,120 --> 00:06:22,560
common

181
00:06:22,560 --> 00:06:24,960
um as detection Engineers we spend a lot

182
00:06:24,960 --> 00:06:26,940
of time you know building out

183
00:06:26,940 --> 00:06:29,580
uh parsing agents or writing complex

184
00:06:29,580 --> 00:06:31,560
regex is sort of to build out these

185
00:06:31,560 --> 00:06:34,199
features or detection rules now the idea

186
00:06:34,199 --> 00:06:36,539
is that when you have this word Linux

187
00:06:36,539 --> 00:06:39,479
the strings around it matter as much as

188
00:06:39,479 --> 00:06:41,400
Linux itself

189
00:06:41,400 --> 00:06:43,979
you may have many Linux based user

190
00:06:43,979 --> 00:06:45,720
agents so how are you going to

191
00:06:45,720 --> 00:06:48,660
differentiate between those so the idea

192
00:06:48,660 --> 00:06:51,120
is yes you can write

193
00:06:51,120 --> 00:06:54,479
a lot of regaxes you can write a lot of

194
00:06:54,479 --> 00:06:56,520
complex projects as well

195
00:06:56,520 --> 00:07:00,479
or you could use something on the or you

196
00:07:00,479 --> 00:07:01,919
could use something on the NLP side of

197
00:07:01,919 --> 00:07:03,240
things that will help you differentiate

198
00:07:03,240 --> 00:07:06,600
uh sort of between them the idea is like

199
00:07:06,600 --> 00:07:08,960
there are a lot of

200
00:07:08,960 --> 00:07:11,639
modern NLP techniques and models that

201
00:07:11,639 --> 00:07:14,400
have come up but as an example for this

202
00:07:14,400 --> 00:07:17,100
talk that do help sort of

203
00:07:17,100 --> 00:07:19,139
figure out the contextual part of it

204
00:07:19,139 --> 00:07:22,440
it's called attention or self-attention

205
00:07:22,440 --> 00:07:25,020
in this case for for Bert and the idea

206
00:07:25,020 --> 00:07:27,000
is you can use these techniques to

207
00:07:27,000 --> 00:07:29,099
figure out like if there was another

208
00:07:29,099 --> 00:07:31,380
user agent with maybe like a different

209
00:07:31,380 --> 00:07:34,020
version name or a different string that

210
00:07:34,020 --> 00:07:36,060
follows Linux the fact is that context

211
00:07:36,060 --> 00:07:37,919
is incorporated and you could use

212
00:07:37,919 --> 00:07:39,360
embeddings to sort of differentiate

213
00:07:39,360 --> 00:07:41,099
between them or you can just keep

214
00:07:41,099 --> 00:07:44,340
writing reg access that's all up to you

215
00:07:44,340 --> 00:07:45,599
um

216
00:07:45,599 --> 00:07:47,400
so

217
00:07:47,400 --> 00:07:48,599
um

218
00:07:48,599 --> 00:07:51,120
yeah welcome to the AI hype cycle of our

219
00:07:51,120 --> 00:07:52,020
times

220
00:07:52,020 --> 00:07:54,000
um I felt like I had to put this you

221
00:07:54,000 --> 00:07:55,380
know after a conversation with my

222
00:07:55,380 --> 00:07:57,780
manager and

223
00:07:57,780 --> 00:08:00,060
I couldn't fit in all the models so

224
00:08:00,060 --> 00:08:02,460
there are like four of them but you know

225
00:08:02,460 --> 00:08:04,740
a few hundred probably came in the last

226
00:08:04,740 --> 00:08:07,740
month as well but the idea is uh you

227
00:08:07,740 --> 00:08:10,440
know the model that I use is sort of

228
00:08:10,440 --> 00:08:12,199
right down at the bottom the first one

229
00:08:12,199 --> 00:08:16,620
uh Bert which sort of came in in 2018.

230
00:08:16,620 --> 00:08:17,400
um

231
00:08:17,400 --> 00:08:20,220
needless to say I you know llms are

232
00:08:20,220 --> 00:08:22,860
obviously the in thing right now and you

233
00:08:22,860 --> 00:08:25,139
know everyone's building one and not to

234
00:08:25,139 --> 00:08:27,479
say that they're not important uh but I

235
00:08:27,479 --> 00:08:28,860
do believe that there is a lot of value

236
00:08:28,860 --> 00:08:31,740
in smaller models as well especially

237
00:08:31,740 --> 00:08:34,679
because security is such a

238
00:08:34,679 --> 00:08:37,440
such a closed domain uh you know every

239
00:08:37,440 --> 00:08:39,779
Enterprise has a certain set of logs

240
00:08:39,779 --> 00:08:41,820
every Enterprise has

241
00:08:41,820 --> 00:08:43,919
uh subtle differences in the way they

242
00:08:43,919 --> 00:08:45,959
have their logs and

243
00:08:45,959 --> 00:08:48,779
it's very hard to find a one model that

244
00:08:48,779 --> 00:08:51,720
beats them all in an insecurity unlike

245
00:08:51,720 --> 00:08:54,060
unlike other use cases where you know

246
00:08:54,060 --> 00:08:55,200
you're just talking about text

247
00:08:55,200 --> 00:08:56,459
generation or you're talking about

248
00:08:56,459 --> 00:08:58,080
chatbots or

249
00:08:58,080 --> 00:08:59,519
I don't know you're trying to make ice

250
00:08:59,519 --> 00:09:01,440
cream uh you know all the other things

251
00:09:01,440 --> 00:09:03,120
that are associated with it you can have

252
00:09:03,120 --> 00:09:06,120
one big model but uh but with security I

253
00:09:06,120 --> 00:09:07,800
feel like because it's so constrained

254
00:09:07,800 --> 00:09:09,660
and because Enterprise has differentiate

255
00:09:09,660 --> 00:09:12,420
so much from from one to the other you

256
00:09:12,420 --> 00:09:14,160
know you'll end up having to make uh

257
00:09:14,160 --> 00:09:16,140
make custom models

258
00:09:16,140 --> 00:09:20,040
uh the fact is llms haven't just come in

259
00:09:20,040 --> 00:09:23,640
since November of 2022 they have been in

260
00:09:23,640 --> 00:09:25,500
use for a while now

261
00:09:25,500 --> 00:09:27,300
um you know I bring up the point of

262
00:09:27,300 --> 00:09:30,240
distilled models because digital models

263
00:09:30,240 --> 00:09:33,180
are the models that are sort of smaller

264
00:09:33,180 --> 00:09:35,580
in size but have comparable performance

265
00:09:35,580 --> 00:09:37,080
that have been used across the open

266
00:09:37,080 --> 00:09:39,540
source Community for a while now so you

267
00:09:39,540 --> 00:09:41,700
know one of my favorite bird models is

268
00:09:41,700 --> 00:09:44,459
distilbert which is basically using

269
00:09:44,459 --> 00:09:46,680
maybe 60 of the parameters that that

270
00:09:46,680 --> 00:09:49,140
bird uses or more optimized models such

271
00:09:49,140 --> 00:09:51,480
as Roberta as well and they become very

272
00:09:51,480 --> 00:09:53,220
popular they they work really well

273
00:09:53,220 --> 00:09:57,060
they're not as uh compute heavy so I do

274
00:09:57,060 --> 00:09:59,940
feel like there is a lot of scope for

275
00:09:59,940 --> 00:10:02,940
using such models within security and

276
00:10:02,940 --> 00:10:04,800
and not just

277
00:10:04,800 --> 00:10:06,779
uh not just bird models you know

278
00:10:06,779 --> 00:10:08,220
classical machine learning I do believe

279
00:10:08,220 --> 00:10:11,160
still has a place in insecurity

280
00:10:11,160 --> 00:10:13,620
but um you know we live in the times

281
00:10:13,620 --> 00:10:15,000
where we're talking about bigger and

282
00:10:15,000 --> 00:10:17,279
bigger models so uh I think there's

283
00:10:17,279 --> 00:10:20,300
something to be said there

284
00:10:22,380 --> 00:10:24,120
so come on to like the security

285
00:10:24,120 --> 00:10:26,040
detection side of things

286
00:10:26,040 --> 00:10:29,519
um and I wanted to sort of walk everyone

287
00:10:29,519 --> 00:10:32,220
kind of like through the process of of

288
00:10:32,220 --> 00:10:34,740
security detection itself

289
00:10:34,740 --> 00:10:36,480
um I picked kubernetes logs again

290
00:10:36,480 --> 00:10:39,420
because uh they're right now they're my

291
00:10:39,420 --> 00:10:41,339
favorite log Source but as you can see

292
00:10:41,339 --> 00:10:43,920
uh on the left that uh they are pretty

293
00:10:43,920 --> 00:10:45,600
complicated

294
00:10:45,600 --> 00:10:48,720
um I'm not a kubernetes expert by by any

295
00:10:48,720 --> 00:10:51,300
stretch of imagination but the idea is

296
00:10:51,300 --> 00:10:54,899
that when it's sort of providing you uh

297
00:10:54,899 --> 00:10:57,720
sort of very detailed information about

298
00:10:57,720 --> 00:11:00,540
uh whatever sort of happening on your on

299
00:11:00,540 --> 00:11:02,100
your control plane and that is very

300
00:11:02,100 --> 00:11:04,380
important for detection engineers

301
00:11:04,380 --> 00:11:08,160
in most cases uh you know uh Whenever

302
00:11:08,160 --> 00:11:09,720
there are services that are sort of

303
00:11:09,720 --> 00:11:12,480
associated with with kubernetes you can

304
00:11:12,480 --> 00:11:14,700
have like a bunch of different logs but

305
00:11:14,700 --> 00:11:16,500
audit logs are generally the one that

306
00:11:16,500 --> 00:11:18,959
people sort of sort of walk in and on

307
00:11:18,959 --> 00:11:21,899
and try and build our detections they're

308
00:11:21,899 --> 00:11:24,120
also very useful for for like

309
00:11:24,120 --> 00:11:27,060
operationalizing things

310
00:11:27,060 --> 00:11:28,200
um in most cases when you're building

311
00:11:28,200 --> 00:11:30,899
out these detections uh It's associated

312
00:11:30,899 --> 00:11:33,240
with with static rules right uh you'll

313
00:11:33,240 --> 00:11:35,100
probably end up

314
00:11:35,100 --> 00:11:36,959
uh maybe looking at the user agent

315
00:11:36,959 --> 00:11:38,760
you'll try and figure out whether there

316
00:11:38,760 --> 00:11:41,279
are user agents that that haven't sort

317
00:11:41,279 --> 00:11:43,320
of been part of the system for x amount

318
00:11:43,320 --> 00:11:45,300
of time

319
00:11:45,300 --> 00:11:47,100
um you'll probably end up excluding a

320
00:11:47,100 --> 00:11:49,260
bunch of usernames uh and you'll

321
00:11:49,260 --> 00:11:50,279
probably reach the point where you've

322
00:11:50,279 --> 00:11:51,779
excluded everyone so that your rules

323
00:11:51,779 --> 00:11:53,519
don't generate any noise

324
00:11:53,519 --> 00:11:55,620
and that can get frustrating right

325
00:11:55,620 --> 00:11:57,180
because if you go on the other end of

326
00:11:57,180 --> 00:11:59,339
the spectrum uh you're flooding your IR

327
00:11:59,339 --> 00:12:02,220
team team with alerts so

328
00:12:02,220 --> 00:12:05,640
while static rules can be used precisely

329
00:12:05,640 --> 00:12:08,279
for certain use cases I do believe that

330
00:12:08,279 --> 00:12:09,600
you need something

331
00:12:09,600 --> 00:12:13,680
um that is sort of uh wider or like or

332
00:12:13,680 --> 00:12:15,420
sort of a more umbrella based approach

333
00:12:15,420 --> 00:12:16,620
as well

334
00:12:16,620 --> 00:12:19,260
so the idea here is uh you know we're

335
00:12:19,260 --> 00:12:21,240
going to be using embeddings to generate

336
00:12:21,240 --> 00:12:23,940
like what is a representation of of logs

337
00:12:23,940 --> 00:12:26,480
such as this

338
00:12:28,440 --> 00:12:30,779
okay so

339
00:12:30,779 --> 00:12:32,640
um before we just go on to the previous

340
00:12:32,640 --> 00:12:34,620
slide itself

341
00:12:34,620 --> 00:12:36,600
um I do put in Step One is figure out

342
00:12:36,600 --> 00:12:38,700
your data which is at a minimum

343
00:12:38,700 --> 00:12:41,100
understand what each of the fields mean

344
00:12:41,100 --> 00:12:42,720
at least

345
00:12:42,720 --> 00:12:45,480
um you also need to be understanding uh

346
00:12:45,480 --> 00:12:47,040
sort of how it sort of fits in within

347
00:12:47,040 --> 00:12:49,079
your system

348
00:12:49,079 --> 00:12:51,180
when you're sort of using NLP based

349
00:12:51,180 --> 00:12:53,100
techniques I feel like the second step

350
00:12:53,100 --> 00:12:54,360
is

351
00:12:54,360 --> 00:12:56,339
um kind of like the most important one

352
00:12:56,339 --> 00:12:58,200
so this is called like the tokenization

353
00:12:58,200 --> 00:13:00,899
process so you have like a bunch of text

354
00:13:00,899 --> 00:13:03,360
and you are converting them into a bunch

355
00:13:03,360 --> 00:13:04,800
of numbers

356
00:13:04,800 --> 00:13:07,440
uh this is because neural networks do

357
00:13:07,440 --> 00:13:09,180
not understand anything but numbers as

358
00:13:09,180 --> 00:13:11,820
inputs now the process of tokenizing

359
00:13:11,820 --> 00:13:15,000
itself is can get very complicated

360
00:13:15,000 --> 00:13:17,279
um you could sort of build your own

361
00:13:17,279 --> 00:13:19,260
tokenizer but building your own

362
00:13:19,260 --> 00:13:22,200
tokenizer also requires you to build

363
00:13:22,200 --> 00:13:24,480
your own vocabulary and then build out a

364
00:13:24,480 --> 00:13:26,639
tokenizer on top of that and building

365
00:13:26,639 --> 00:13:29,459
out a vocabulary is is difficult

366
00:13:29,459 --> 00:13:30,899
um

367
00:13:30,899 --> 00:13:33,540
there are a lot of sort of pre-built

368
00:13:33,540 --> 00:13:35,279
vocabularies available and free build

369
00:13:35,279 --> 00:13:37,079
tokenizers available which you can use

370
00:13:37,079 --> 00:13:40,620
to sort of convert text into the

371
00:13:40,620 --> 00:13:42,200
tokenized values

372
00:13:42,200 --> 00:13:45,839
in most cases you know even with the

373
00:13:45,839 --> 00:13:47,399
smaller models

374
00:13:47,399 --> 00:13:50,160
and I say small sort of very lightly but

375
00:13:50,160 --> 00:13:53,399
a bird model with say 300 million

376
00:13:53,399 --> 00:13:54,600
parameters

377
00:13:54,600 --> 00:13:57,420
which is by comparison nothing compared

378
00:13:57,420 --> 00:14:01,079
to maybe charge GPT or GPD 3.5 which is

379
00:14:01,079 --> 00:14:03,360
like 170 billion

380
00:14:03,360 --> 00:14:05,279
training those models from scratch is

381
00:14:05,279 --> 00:14:07,920
hard so you know I would advise anyone

382
00:14:07,920 --> 00:14:10,260
who's sort of looking at Text data for

383
00:14:10,260 --> 00:14:12,300
security and trying to build their own

384
00:14:12,300 --> 00:14:14,940
tokenizer uh good luck that'll take a

385
00:14:14,940 --> 00:14:17,399
lot of time so I would say you know use

386
00:14:17,399 --> 00:14:19,380
the pre-built once because pre-built

387
00:14:19,380 --> 00:14:20,700
ones have

388
00:14:20,700 --> 00:14:22,980
enough information within the Corpus to

389
00:14:22,980 --> 00:14:25,079
sort of incorporate uh the things that

390
00:14:25,079 --> 00:14:27,319
you need

391
00:14:28,740 --> 00:14:31,500
the third step is sort of trying to

392
00:14:31,500 --> 00:14:33,660
figure out your your embedding model

393
00:14:33,660 --> 00:14:37,200
itself now I have this example here as

394
00:14:37,200 --> 00:14:40,380
the bird model itself so

395
00:14:40,380 --> 00:14:42,540
sort of going into like the like the

396
00:14:42,540 --> 00:14:45,180
specifications of the bird model is sort

397
00:14:45,180 --> 00:14:48,360
of beyond the scope but the idea of of

398
00:14:48,360 --> 00:14:51,000
sort of these these powerful NLP models

399
00:14:51,000 --> 00:14:53,760
is sort of twofold you could you could

400
00:14:53,760 --> 00:14:55,980
either pre-train the models or you can

401
00:14:55,980 --> 00:14:58,260
find you in the models now the

402
00:14:58,260 --> 00:15:00,779
pre-training part is sort of an

403
00:15:00,779 --> 00:15:03,600
unsupervised uh semi-supervised way of

404
00:15:03,600 --> 00:15:04,500
sort of learning the language

405
00:15:04,500 --> 00:15:06,120
representation

406
00:15:06,120 --> 00:15:08,399
when you're pre-training about model you

407
00:15:08,399 --> 00:15:11,459
are going to take like a bunch of logs a

408
00:15:11,459 --> 00:15:15,480
lot of logs and you're trying to sort of

409
00:15:15,480 --> 00:15:18,060
and to some degree tree in the Train the

410
00:15:18,060 --> 00:15:20,100
bird model from scratch and then you're

411
00:15:20,100 --> 00:15:21,839
going to find your net on a specific

412
00:15:21,839 --> 00:15:22,920
task

413
00:15:22,920 --> 00:15:25,800
uh in a lot of cases and in this case as

414
00:15:25,800 --> 00:15:27,779
well you know I used a pre-trained bird

415
00:15:27,779 --> 00:15:29,399
model there was that was already

416
00:15:29,399 --> 00:15:31,620
available that had been using the

417
00:15:31,620 --> 00:15:34,260
English language Corpus and then I sort

418
00:15:34,260 --> 00:15:36,839
of fine-tuned it on a specific task so

419
00:15:36,839 --> 00:15:38,519
in this case my task was as you can see

420
00:15:38,519 --> 00:15:40,620
it's a classifier up there and I was

421
00:15:40,620 --> 00:15:42,899
trying to predict for each each specific

422
00:15:42,899 --> 00:15:46,019
set of logs like what the verb type is

423
00:15:46,019 --> 00:15:48,779
uh the idea was I would take this

424
00:15:48,779 --> 00:15:50,880
embedding model have it predict what the

425
00:15:50,880 --> 00:15:52,980
verb type is and then sort of extract

426
00:15:52,980 --> 00:15:55,139
the embeddings out those embeddings

427
00:15:55,139 --> 00:15:57,360
would be my representation of the logs

428
00:15:57,360 --> 00:15:58,380
itself

429
00:15:58,380 --> 00:15:59,820
now of course like I said you're welcome

430
00:15:59,820 --> 00:16:02,820
to sort of uh pre-train your bird model

431
00:16:02,820 --> 00:16:04,920
and then find tune it on your on your

432
00:16:04,920 --> 00:16:07,560
son on your own objective

433
00:16:07,560 --> 00:16:09,420
um but from what I've seen that haven't

434
00:16:09,420 --> 00:16:12,120
been too many pre-trained cyber security

435
00:16:12,120 --> 00:16:15,060
specific models I think maybe a couple

436
00:16:15,060 --> 00:16:17,880
of them but on the other hand if you see

437
00:16:17,880 --> 00:16:19,740
a lot of other fields you'll see a lot

438
00:16:19,740 --> 00:16:21,899
more because just sort of more viable to

439
00:16:21,899 --> 00:16:23,699
sort of build them out

440
00:16:23,699 --> 00:16:25,620
but so this is kind of like the story

441
00:16:25,620 --> 00:16:28,019
for now in the sense that you know I

442
00:16:28,019 --> 00:16:29,639
have a model I'll be predicting the verb

443
00:16:29,639 --> 00:16:31,199
types and I'll be extracting the

444
00:16:31,199 --> 00:16:33,420
embeddings and seeing sort of what comes

445
00:16:33,420 --> 00:16:35,820
out of it

446
00:16:35,820 --> 00:16:37,440
and

447
00:16:37,440 --> 00:16:39,420
this slide sort of talks about the

448
00:16:39,420 --> 00:16:41,820
embedding results themselves

449
00:16:41,820 --> 00:16:44,160
um I have a point there about

450
00:16:44,160 --> 00:16:46,620
embedding sort of evaluating your

451
00:16:46,620 --> 00:16:48,420
embedding results aren't the same as

452
00:16:48,420 --> 00:16:50,100
evaluating your model

453
00:16:50,100 --> 00:16:51,360
um you know it's sort of a little bit

454
00:16:51,360 --> 00:16:53,519
more ambivalent when you're trying to

455
00:16:53,519 --> 00:16:55,259
figure out how to evaluate your

456
00:16:55,259 --> 00:16:56,579
embedding results

457
00:16:56,579 --> 00:16:59,579
what I did was I trained the model on

458
00:16:59,579 --> 00:17:01,160
approximately

459
00:17:01,160 --> 00:17:04,559
7500 K8 log samples and they aren't that

460
00:17:04,559 --> 00:17:06,000
many but you can always you can always

461
00:17:06,000 --> 00:17:10,319
expand them but my idea was to sort of

462
00:17:10,319 --> 00:17:12,599
take the embeddings generated by the

463
00:17:12,599 --> 00:17:15,839
training set and then sort of display

464
00:17:15,839 --> 00:17:18,679
them on a two-dimensional representation

465
00:17:18,679 --> 00:17:22,679
and as you can see uh sort of each each

466
00:17:22,679 --> 00:17:25,559
particular verb type has a sort of

467
00:17:25,559 --> 00:17:27,720
specific spot in the cluster which kind

468
00:17:27,720 --> 00:17:29,640
of shows that the embeddings were

469
00:17:29,640 --> 00:17:31,620
successful in sort of breaking each of

470
00:17:31,620 --> 00:17:33,059
these verb types into like these

471
00:17:33,059 --> 00:17:35,460
separate clusters and that's kind of

472
00:17:35,460 --> 00:17:37,980
like an indication that hey you know

473
00:17:37,980 --> 00:17:40,200
what like these embeddings worked these

474
00:17:40,200 --> 00:17:42,600
are a representation of your logs uh

475
00:17:42,600 --> 00:17:44,280
based on based on your sort of your

476
00:17:44,280 --> 00:17:45,720
objective function

477
00:17:45,720 --> 00:17:47,280
when you're training the model itself

478
00:17:47,280 --> 00:17:49,440
it's uh it's sort of a more

479
00:17:49,440 --> 00:17:52,260
straightforward sort of multi-label uh

480
00:17:52,260 --> 00:17:54,480
multi-label classification model so you

481
00:17:54,480 --> 00:17:55,620
know you're just going to use something

482
00:17:55,620 --> 00:17:57,419
uh sort of more traditional like an F1

483
00:17:57,419 --> 00:17:59,220
score or something of that sort

484
00:17:59,220 --> 00:18:00,960
so we're going to take these embeddings

485
00:18:00,960 --> 00:18:03,419
and then use them Downstream so the idea

486
00:18:03,419 --> 00:18:06,000
is I've trained all these uh trained on

487
00:18:06,000 --> 00:18:07,559
all these logs I have a good

488
00:18:07,559 --> 00:18:10,620
representation of my logs which is based

489
00:18:10,620 --> 00:18:12,480
on this particular plot and now I'm

490
00:18:12,480 --> 00:18:15,559
going to use it Downstream

491
00:18:16,919 --> 00:18:19,200
um so um credit to the stratus rat team

492
00:18:19,200 --> 00:18:21,960
who sort of um have excellent

493
00:18:21,960 --> 00:18:24,299
documentation on a lot of red team use

494
00:18:24,299 --> 00:18:25,140
cases

495
00:18:25,140 --> 00:18:27,960
so I picked up one of their use cases

496
00:18:27,960 --> 00:18:30,059
which is you know can we detect if

497
00:18:30,059 --> 00:18:33,179
within a K8 cluster if an attacker tries

498
00:18:33,179 --> 00:18:36,179
to dump all the secrets uh within the

499
00:18:36,179 --> 00:18:38,940
within the K8 cluster itself now ideally

500
00:18:38,940 --> 00:18:42,299
would you have a rule for it yes

501
00:18:42,299 --> 00:18:44,960
uh

502
00:18:45,059 --> 00:18:46,679
uh there are there is a very high

503
00:18:46,679 --> 00:18:48,720
possibility you don't as well because

504
00:18:48,720 --> 00:18:50,820
hey that's just the way things work and

505
00:18:50,820 --> 00:18:53,580
the detection engineering world

506
00:18:53,580 --> 00:18:54,840
um should you have our back control

507
00:18:54,840 --> 00:18:57,240
probably but again you may not have it

508
00:18:57,240 --> 00:19:00,120
but the goal of uh but the goal of this

509
00:19:00,120 --> 00:19:01,500
thing is you know not to sort of point

510
00:19:01,500 --> 00:19:03,299
out who's going where on the detection

511
00:19:03,299 --> 00:19:06,179
engineering side of things it's about me

512
00:19:06,179 --> 00:19:08,460
sort of taking this this log and

513
00:19:08,460 --> 00:19:11,580
simulating this on my sort of tester

514
00:19:11,580 --> 00:19:13,799
validation data set and seeing if like

515
00:19:13,799 --> 00:19:16,020
my embedding model can sort of find this

516
00:19:16,020 --> 00:19:18,360
particular log

517
00:19:18,360 --> 00:19:20,580
um so that's kind of what I did I had a

518
00:19:20,580 --> 00:19:23,640
bunch of uh validation data I simulated

519
00:19:23,640 --> 00:19:26,460
the presence of this particular log

520
00:19:26,460 --> 00:19:28,860
uh sort of the main parts are you know

521
00:19:28,860 --> 00:19:31,020
if you can see like uh like the

522
00:19:31,020 --> 00:19:33,179
attributes and the objective resource

523
00:19:33,179 --> 00:19:34,980
you know there are secrets and that

524
00:19:34,980 --> 00:19:38,280
person is basically asking to kind of

525
00:19:38,280 --> 00:19:41,280
dump all the secrets and list them all

526
00:19:41,280 --> 00:19:44,580
the method does become does become

527
00:19:44,580 --> 00:19:45,900
pretty relevant because what I'm going

528
00:19:45,900 --> 00:19:49,620
to do is I'm going to take all the verb

529
00:19:49,620 --> 00:19:53,280
list types and sort of see if I can find

530
00:19:53,280 --> 00:19:55,559
this particular log within uh sort of my

531
00:19:55,559 --> 00:19:58,280
embedding process

532
00:19:59,039 --> 00:20:01,620
so that's kind of what I did

533
00:20:01,620 --> 00:20:03,780
um and as you can see what I did was I

534
00:20:03,780 --> 00:20:06,840
generated like the embeddings for the

535
00:20:06,840 --> 00:20:09,780
verb type list in for the malicious and

536
00:20:09,780 --> 00:20:11,700
that single benign

537
00:20:11,700 --> 00:20:13,679
uh data point

538
00:20:13,679 --> 00:20:15,960
um the blue data points out here

539
00:20:15,960 --> 00:20:18,539
indicate benign data points and that

540
00:20:18,539 --> 00:20:21,419
single one gigantic orange data point

541
00:20:21,419 --> 00:20:23,280
indicates the log which was used to list

542
00:20:23,280 --> 00:20:25,200
all secrets

543
00:20:25,200 --> 00:20:26,100
um

544
00:20:26,100 --> 00:20:28,500
my hypothesis was that it would be

545
00:20:28,500 --> 00:20:31,020
isolated to some degree and it does work

546
00:20:31,020 --> 00:20:32,240
like that

547
00:20:32,240 --> 00:20:35,880
of course certain caveats are the fact

548
00:20:35,880 --> 00:20:38,880
that the model itself was trained on not

549
00:20:38,880 --> 00:20:41,039
too many logs so I would say that you

550
00:20:41,039 --> 00:20:42,960
know I would have needed sort of more

551
00:20:42,960 --> 00:20:45,600
examples of the warp type list to have

552
00:20:45,600 --> 00:20:47,760
like a better representation but the

553
00:20:47,760 --> 00:20:49,500
idea was that

554
00:20:49,500 --> 00:20:51,419
machine learning models that are using

555
00:20:51,419 --> 00:20:53,100
that you're sort of using for cyber

556
00:20:53,100 --> 00:20:55,980
security are not meant to find

557
00:20:55,980 --> 00:20:57,059
um

558
00:20:57,059 --> 00:20:59,100
or sometimes are not meant to find like

559
00:20:59,100 --> 00:21:01,260
specific instances of this going wrong

560
00:21:01,260 --> 00:21:03,179
or that going wrong right it's supposed

561
00:21:03,179 --> 00:21:05,220
to be used in correlation with your

562
00:21:05,220 --> 00:21:07,440
detection rules so that if you can see

563
00:21:07,440 --> 00:21:09,960
with even if even if you did not have

564
00:21:09,960 --> 00:21:12,600
this rule if you had that particular set

565
00:21:12,600 --> 00:21:14,280
of points that was sort of a more

566
00:21:14,280 --> 00:21:16,260
isolated you could at least sort of be

567
00:21:16,260 --> 00:21:18,360
like okay you know what this is isolated

568
00:21:18,360 --> 00:21:20,400
this particular data point is something

569
00:21:20,400 --> 00:21:23,760
that we should uh we should investigate

570
00:21:23,760 --> 00:21:24,299
um

571
00:21:24,299 --> 00:21:27,360
this exercise in itself was more of a

572
00:21:27,360 --> 00:21:29,159
validation process where I could be like

573
00:21:29,159 --> 00:21:31,740
okay if we have if we simulate this will

574
00:21:31,740 --> 00:21:35,600
this be caught by the model and it does

575
00:21:37,440 --> 00:21:39,900
uh challenges in looking ahead I think

576
00:21:39,900 --> 00:21:40,919
is

577
00:21:40,919 --> 00:21:41,760
um

578
00:21:41,760 --> 00:21:44,280
uh pre-standard I would think

579
00:21:44,280 --> 00:21:46,799
um you know ml is is most definitely not

580
00:21:46,799 --> 00:21:48,780
a silver bullet uh to the security

581
00:21:48,780 --> 00:21:52,080
problem uh I'm sort of a strong believer

582
00:21:52,080 --> 00:21:55,020
of of sort of going wide and then going

583
00:21:55,020 --> 00:21:57,059
deep as well and I think ml does help

584
00:21:57,059 --> 00:21:59,400
you sort of go very wide but you still

585
00:21:59,400 --> 00:22:01,559
have like a bunch of rules uh that would

586
00:22:01,559 --> 00:22:03,659
help you sort of go deep and then you'd

587
00:22:03,659 --> 00:22:05,280
have like a bunch of correlation efforts

588
00:22:05,280 --> 00:22:07,500
as well which can sort of help you face

589
00:22:07,500 --> 00:22:09,960
that problem uh another point is an

590
00:22:09,960 --> 00:22:11,900
anomalous event is not always malicious

591
00:22:11,900 --> 00:22:15,059
uh so you know in the real world the way

592
00:22:15,059 --> 00:22:17,039
things work that orange data point won't

593
00:22:17,039 --> 00:22:18,960
be visible to you that may or may not

594
00:22:18,960 --> 00:22:20,880
have been malicious

595
00:22:20,880 --> 00:22:23,400
maybe someone's your maybe your system

596
00:22:23,400 --> 00:22:25,380
is okay with someone dumping all your

597
00:22:25,380 --> 00:22:27,360
secrets in a K8 cluster I'm not sure

598
00:22:27,360 --> 00:22:30,559
about that but but maybe uh

599
00:22:30,559 --> 00:22:32,700
interpretability is a definite problem

600
00:22:32,700 --> 00:22:35,820
especially with embeddings uh but I

601
00:22:35,820 --> 00:22:39,600
think a lot of that sort of comes up to

602
00:22:39,600 --> 00:22:41,400
um you know working with your IR team

603
00:22:41,400 --> 00:22:44,220
you know I think a lot of cases are

604
00:22:44,220 --> 00:22:46,200
where we struggle to

605
00:22:46,200 --> 00:22:48,240
sort of give the right information to IR

606
00:22:48,240 --> 00:22:50,640
so it's not so much about embeddings or

607
00:22:50,640 --> 00:22:52,500
numerical Vector representations it's

608
00:22:52,500 --> 00:22:54,179
it's just about answering the right

609
00:22:54,179 --> 00:22:56,220
questions when it comes to ir and giving

610
00:22:56,220 --> 00:22:58,380
them the right information to sort of

611
00:22:58,380 --> 00:23:02,280
operate when you're using uh ml models

612
00:23:02,280 --> 00:23:04,880
uh looking ahead I think

613
00:23:04,880 --> 00:23:07,320
within security

614
00:23:07,320 --> 00:23:10,440
I don't see one model sort of ruling

615
00:23:10,440 --> 00:23:13,140
them all anytime soon

616
00:23:13,140 --> 00:23:14,700
um so I'll talk to you guys next year

617
00:23:14,700 --> 00:23:16,140
maybe

618
00:23:16,140 --> 00:23:19,140
um but I do see like a lot of fine-tuned

619
00:23:19,140 --> 00:23:21,120
bird models can be very useful because

620
00:23:21,120 --> 00:23:23,400
of just the fact that security is no

621
00:23:23,400 --> 00:23:25,320
different I believe from like any other

622
00:23:25,320 --> 00:23:27,960
field which is like very tax driven so

623
00:23:27,960 --> 00:23:30,600
we should be sort of using

624
00:23:30,600 --> 00:23:31,440
um

625
00:23:31,440 --> 00:23:33,539
uh you know bird-based models a lot more

626
00:23:33,539 --> 00:23:35,940
than we actually end up doing I think

627
00:23:35,940 --> 00:23:38,520
and the third part is of course you know

628
00:23:38,520 --> 00:23:40,020
um you know I work on the on the blue

629
00:23:40,020 --> 00:23:42,419
team side of things when it comes to

630
00:23:42,419 --> 00:23:44,880
using machine learning and security but

631
00:23:44,880 --> 00:23:46,140
you know you should be using the right

632
00:23:46,140 --> 00:23:48,960
platform you should be making sure that

633
00:23:48,960 --> 00:23:51,059
uh you know the packages that you use or

634
00:23:51,059 --> 00:23:52,919
or the platform that you use is

635
00:23:52,919 --> 00:23:54,840
trustworthy and you know I know there

636
00:23:54,840 --> 00:23:57,900
are a lot of talks here associated with

637
00:23:57,900 --> 00:24:00,000
um sort of attacking AI models as well

638
00:24:00,000 --> 00:24:01,620
so you know I do believe like that's

639
00:24:01,620 --> 00:24:03,059
something that should be

640
00:24:03,059 --> 00:24:07,700
uh kept under consideration as well

641
00:24:07,860 --> 00:24:11,039
and lastly shout out to my detection and

642
00:24:11,039 --> 00:24:13,760
response teams who sort of uh

643
00:24:13,760 --> 00:24:16,799
knowingly and unknowingly have sort of

644
00:24:16,799 --> 00:24:19,440
helped a lot with this talk

645
00:24:19,440 --> 00:24:21,720
and questions

646
00:24:21,720 --> 00:24:26,589
[Applause]

647
00:24:27,720 --> 00:24:31,080
you know so what mode of these large

648
00:24:31,080 --> 00:24:33,840
language models

649
00:24:33,840 --> 00:24:36,500
very important

650
00:24:41,220 --> 00:24:43,500
yeah distal bird was is just trained on

651
00:24:43,500 --> 00:24:45,600
mlab so I was using just a mass language

652
00:24:45,600 --> 00:24:48,500
model yeah yeah

653
00:24:52,200 --> 00:24:53,940
I think you can do a lot of different

654
00:24:53,940 --> 00:24:55,860
things initially I wanted to just shove

655
00:24:55,860 --> 00:24:57,539
a isolation Forest onto it and be like

656
00:24:57,539 --> 00:24:59,039
okay you know what we can just have a

657
00:24:59,039 --> 00:25:00,840
contamination and see what sort of comes

658
00:25:00,840 --> 00:25:02,940
out yeah yeah uh you can use a cosine

659
00:25:02,940 --> 00:25:04,140
metric as well I think that's a really

660
00:25:04,140 --> 00:25:06,600
good idea you can I certainly believe

661
00:25:06,600 --> 00:25:07,980
like

662
00:25:07,980 --> 00:25:10,380
it's kind of hard to do that with uh

663
00:25:10,380 --> 00:25:12,179
clustering is great for visualization

664
00:25:12,179 --> 00:25:13,620
where I don't think it can be used as an

665
00:25:13,620 --> 00:25:16,260
anomaly detection tool so I do believe

666
00:25:16,260 --> 00:25:20,240
like a similarity metric like a science

667
00:25:20,700 --> 00:25:23,280
yeah

668
00:25:23,280 --> 00:25:25,200
let's give her a round of applause for a

669
00:25:25,200 --> 00:25:26,580
presenter

670
00:25:26,580 --> 00:25:28,200
if you have any questions you can ask

671
00:25:28,200 --> 00:25:31,100
him any questions outside

