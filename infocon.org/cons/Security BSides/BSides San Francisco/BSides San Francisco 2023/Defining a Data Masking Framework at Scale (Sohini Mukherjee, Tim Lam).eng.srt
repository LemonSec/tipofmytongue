1
00:00:00,060 --> 00:00:02,700
so our next talk will be defining a data

2
00:00:02,700 --> 00:00:05,100
masking framework at scale in this talk

3
00:00:05,100 --> 00:00:07,440
Works explore tokenization and of

4
00:00:07,440 --> 00:00:09,540
specification as alternate data security

5
00:00:09,540 --> 00:00:11,540
techniques in addition to Conventional

6
00:00:11,540 --> 00:00:13,679
methodologies like encryption and the

7
00:00:13,679 --> 00:00:14,940
challenges that needs to be addressed

8
00:00:14,940 --> 00:00:16,560
like implementing a data security

9
00:00:16,560 --> 00:00:18,420
framework at scale

10
00:00:18,420 --> 00:00:21,180
we have sohini on the left so he needs

11
00:00:21,180 --> 00:00:23,160
as a senior security departure at

12
00:00:23,160 --> 00:00:25,320
LinkedIn so he needs a purple team

13
00:00:25,320 --> 00:00:27,180
evangelist and is also passionate about

14
00:00:27,180 --> 00:00:30,119
data security and Cloud security she has

15
00:00:30,119 --> 00:00:31,560
been a speaker at B-side San Francisco

16
00:00:31,560 --> 00:00:34,380
2020 and I was also spoken in several

17
00:00:34,380 --> 00:00:36,960
other conferences I'll now passes out to

18
00:00:36,960 --> 00:00:37,920
Tim

19
00:00:37,920 --> 00:00:39,480
thank you

20
00:00:39,480 --> 00:00:41,520
I'm Tim I'm a data security architect

21
00:00:41,520 --> 00:00:44,040
and I haven't done this before so all

22
00:00:44,040 --> 00:00:46,160
right

23
00:00:47,940 --> 00:00:50,280
hey everyone I hope you are doing well

24
00:00:50,280 --> 00:00:52,680
and enjoying the b-sides conference

25
00:00:52,680 --> 00:00:55,260
today we will be talking about defining

26
00:00:55,260 --> 00:00:58,379
a data masking framework at scale I am

27
00:00:58,379 --> 00:01:00,360
sohini and with me I have my

28
00:01:00,360 --> 00:01:03,260
co-presenter Tim

29
00:01:03,899 --> 00:01:05,400
So today we're going to walk you through

30
00:01:05,400 --> 00:01:07,619
an example of data security over time

31
00:01:07,619 --> 00:01:10,140
how it evolves how the needs and the

32
00:01:10,140 --> 00:01:12,659
usage of the data change and we'll be

33
00:01:12,659 --> 00:01:14,400
going through data privacy and how that

34
00:01:14,400 --> 00:01:17,100
interacts with data security and we'll

35
00:01:17,100 --> 00:01:18,479
go over some strategies that we didn't

36
00:01:18,479 --> 00:01:20,340
touch upon during our example Evolution

37
00:01:20,340 --> 00:01:22,979
and then go through some gotchas that

38
00:01:22,979 --> 00:01:24,420
kind of apply to all the strategies

39
00:01:24,420 --> 00:01:27,200
we've outlined

40
00:01:28,020 --> 00:01:32,100
okay so the year is 2015 our example

41
00:01:32,100 --> 00:01:34,860
company real Corp is collecting various

42
00:01:34,860 --> 00:01:37,799
information about the global Workforce

43
00:01:37,799 --> 00:01:40,500
now this sensitive data is being used in

44
00:01:40,500 --> 00:01:43,439
a variety of jobs and workflows to party

45
00:01:43,439 --> 00:01:46,020
platform

46
00:01:46,020 --> 00:01:47,640
it's stored internally and it's made

47
00:01:47,640 --> 00:01:50,340
accessible to all Engineers because it's

48
00:01:50,340 --> 00:01:52,439
faster to develop that way and as far as

49
00:01:52,439 --> 00:01:54,000
the company knows there are no legal

50
00:01:54,000 --> 00:01:56,280
regulations that restrict handling of

51
00:01:56,280 --> 00:01:58,380
the data

52
00:01:58,380 --> 00:02:00,920
fast forward

53
00:02:03,479 --> 00:02:05,700
the companies Implement strict technical

54
00:02:05,700 --> 00:02:08,399
controls to protect personal data

55
00:02:08,399 --> 00:02:11,640
Now using this as an opportunity to

56
00:02:11,640 --> 00:02:14,400
re-evaluate data protections real curves

57
00:02:14,400 --> 00:02:17,280
legal team a certain stat salary is

58
00:02:17,280 --> 00:02:19,980
indeed super sensitive and that it might

59
00:02:19,980 --> 00:02:22,260
need more protection

60
00:02:22,260 --> 00:02:25,200
after careful consideration they decide

61
00:02:25,200 --> 00:02:28,379
to encrypt the entire data set now this

62
00:02:28,379 --> 00:02:30,840
is easier than doing targeted or field

63
00:02:30,840 --> 00:02:33,720
level encryption and offer a similar

64
00:02:33,720 --> 00:02:36,980
level of protections

65
00:02:37,920 --> 00:02:39,959
a feature team wants to start running

66
00:02:39,959 --> 00:02:42,720
analytics on this data they want to see

67
00:02:42,720 --> 00:02:45,180
future engagement in regions a versus B

68
00:02:45,180 --> 00:02:47,099
but they don't care who the users are or

69
00:02:47,099 --> 00:02:49,440
what their salaries are

70
00:02:49,440 --> 00:02:52,080
so our previously selected protection of

71
00:02:52,080 --> 00:02:55,319
encryption Falls a bit short here while

72
00:02:55,319 --> 00:02:57,000
the data is protected against

73
00:02:57,000 --> 00:03:00,180
unauthorized access we do have a very

74
00:03:00,180 --> 00:03:02,580
valid use case that is the one running

75
00:03:02,580 --> 00:03:05,700
analytics that doesn't need access to

76
00:03:05,700 --> 00:03:08,760
the raw data and has the ability to leak

77
00:03:08,760 --> 00:03:11,580
keys for the entire data set

78
00:03:11,580 --> 00:03:14,459
so to help show up protection a real

79
00:03:14,459 --> 00:03:17,700
Corp makes a copy of the data and hash

80
00:03:17,700 --> 00:03:21,200
certain Fields like user ID and name

81
00:03:21,200 --> 00:03:23,879
this maintains uniqueness without

82
00:03:23,879 --> 00:03:26,220
providing the ability to read the raw

83
00:03:26,220 --> 00:03:28,019
data

84
00:03:28,019 --> 00:03:30,000
eventually though someone discovers that

85
00:03:30,000 --> 00:03:31,860
we've got two copies of the same data

86
00:03:31,860 --> 00:03:34,319
and says man we could definitely do

87
00:03:34,319 --> 00:03:36,239
better we need to tear that down to one

88
00:03:36,239 --> 00:03:38,760
so we reevaluate our protection

89
00:03:38,760 --> 00:03:40,620
mechanisms

90
00:03:40,620 --> 00:03:42,900
encryption has been useful in stopping

91
00:03:42,900 --> 00:03:45,180
unauthorized access but it doesn't allow

92
00:03:45,180 --> 00:03:46,799
you to run analytics without access to

93
00:03:46,799 --> 00:03:50,340
the raw data and hashing allows you to

94
00:03:50,340 --> 00:03:52,200
run analytics but transforms the data

95
00:03:52,200 --> 00:03:55,980
making those analytics fairly Limited

96
00:03:55,980 --> 00:03:59,220
now also hashing is vulnerable to many

97
00:03:59,220 --> 00:04:01,080
known attacks right

98
00:04:01,080 --> 00:04:04,739
so by adding a record with known input

99
00:04:04,739 --> 00:04:07,319
such as creating a fake profile with the

100
00:04:07,319 --> 00:04:10,080
name sohini and finding that entry

101
00:04:10,080 --> 00:04:12,720
somewhere in the resulting output it's

102
00:04:12,720 --> 00:04:16,019
possible to de-anonymize the data

103
00:04:16,019 --> 00:04:18,899
additionally if the hashing algorithm is

104
00:04:18,899 --> 00:04:20,820
known and the input space is small

105
00:04:20,820 --> 00:04:23,460
enough you could potentially create or

106
00:04:23,460 --> 00:04:26,000
use an existing rainbow table and

107
00:04:26,000 --> 00:04:28,919
de-anonymize the data additionally when

108
00:04:28,919 --> 00:04:30,720
you hash data at scale it typically

109
00:04:30,720 --> 00:04:32,460
introduces a really large time delay

110
00:04:32,460 --> 00:04:35,840
which is rarely acceptable

111
00:04:36,000 --> 00:04:37,860
Okay so

112
00:04:37,860 --> 00:04:39,060
a combination

113
00:04:39,060 --> 00:04:43,080
hashing and encrypting isn't ideal so a

114
00:04:43,080 --> 00:04:45,720
real Corp settles for a special type of

115
00:04:45,720 --> 00:04:47,759
encryption called format preserving

116
00:04:47,759 --> 00:04:49,139
encryption

117
00:04:49,139 --> 00:04:52,259
now if P encrypts the data that is it

118
00:04:52,259 --> 00:04:55,259
prevents unauthorized access to it and

119
00:04:55,259 --> 00:04:58,020
retains the format of the data in terms

120
00:04:58,020 --> 00:05:00,720
of its length and character positions

121
00:05:00,720 --> 00:05:03,180
and what it does is that it enables

122
00:05:03,180 --> 00:05:05,880
analytics to be run on it without the

123
00:05:05,880 --> 00:05:08,300
need to decrypt the data

124
00:05:08,300 --> 00:05:10,800
at this

125
00:05:10,800 --> 00:05:13,440
by by using this method we can

126
00:05:13,440 --> 00:05:16,080
potentially eliminate the Redundant

127
00:05:16,080 --> 00:05:18,840
second copy of data that we were

128
00:05:18,840 --> 00:05:21,120
referring couple of slides back

129
00:05:21,120 --> 00:05:23,759
and it also comes with an added benefit

130
00:05:23,759 --> 00:05:26,039
that we can implement it fairly

131
00:05:26,039 --> 00:05:28,580
seamlessly on Legacy systems like

132
00:05:28,580 --> 00:05:31,259
databases or applications without the

133
00:05:31,259 --> 00:05:35,940
need for changing field sizes or formats

134
00:05:35,940 --> 00:05:38,160
so we've got a lovely picture here of

135
00:05:38,160 --> 00:05:40,199
some of the more well-known sensitive

136
00:05:40,199 --> 00:05:42,300
Fields like Social Security numbers or

137
00:05:42,300 --> 00:05:44,220
credit card numbers but format

138
00:05:44,220 --> 00:05:45,600
preserving encryption can be done on

139
00:05:45,600 --> 00:05:49,580
other things like IP addresses as well

140
00:05:49,919 --> 00:05:52,139
okay so fast forward a couple of years

141
00:05:52,139 --> 00:05:53,160
again

142
00:05:53,160 --> 00:05:55,620
and we've discovered that this encrypted

143
00:05:55,620 --> 00:05:57,600
data has been actually written in clear

144
00:05:57,600 --> 00:06:00,060
text the incident response team does an

145
00:06:00,060 --> 00:06:02,580
investigation and finds that authorized

146
00:06:02,580 --> 00:06:04,500
users have written that data by mistake

147
00:06:04,500 --> 00:06:06,120
in clear text because the encryption

148
00:06:06,120 --> 00:06:08,460
wasn't done automatically for them

149
00:06:08,460 --> 00:06:12,680
so let's go looking for another solution

150
00:06:13,139 --> 00:06:15,960
we settle on tokenization and this usage

151
00:06:15,960 --> 00:06:18,240
tokenization involves sending data to a

152
00:06:18,240 --> 00:06:20,280
server which generates a random

153
00:06:20,280 --> 00:06:22,560
placeholder value optionally sharing the

154
00:06:22,560 --> 00:06:24,660
format and returns that value back to

155
00:06:24,660 --> 00:06:27,259
the caller

156
00:06:27,539 --> 00:06:29,460
this data can be used to perform

157
00:06:29,460 --> 00:06:32,280
specific operations but because it's

158
00:06:32,280 --> 00:06:34,440
random data linked back to the original

159
00:06:34,440 --> 00:06:36,720
data there's no way for anyone to be

160
00:06:36,720 --> 00:06:39,000
able to operate on that data outside of

161
00:06:39,000 --> 00:06:41,460
the context that we deem acceptable we

162
00:06:41,460 --> 00:06:42,780
can also

163
00:06:42,780 --> 00:06:44,520
essentially

164
00:06:44,520 --> 00:06:47,280
monitor all usage of that data since it

165
00:06:47,280 --> 00:06:51,138
requires accessing the mapping table

166
00:06:54,419 --> 00:06:56,819
management has struck up a deal with a

167
00:06:56,819 --> 00:06:59,759
third-party ad provider in order for

168
00:06:59,759 --> 00:07:02,759
them to serve ads accurately we need to

169
00:07:02,759 --> 00:07:05,880
permit analysis on our sensitive Global

170
00:07:05,880 --> 00:07:07,440
Workforce data

171
00:07:07,440 --> 00:07:12,060
but we shouldn't be sharing a raw data

172
00:07:12,060 --> 00:07:14,100
with the third party just like that

173
00:07:14,100 --> 00:07:15,240
right

174
00:07:15,240 --> 00:07:17,220
so let's walk through some of the

175
00:07:17,220 --> 00:07:19,380
attributes that we want our system to

176
00:07:19,380 --> 00:07:21,660
have when we are sharing sensitive data

177
00:07:21,660 --> 00:07:23,699
with an untrusted partner

178
00:07:23,699 --> 00:07:26,580
now this isn't really limited to

179
00:07:26,580 --> 00:07:28,919
third-party data sharing and can be

180
00:07:28,919 --> 00:07:32,039
extrapolated to minimize unintended

181
00:07:32,039 --> 00:07:35,160
exposure or sensitive data each time it

182
00:07:35,160 --> 00:07:37,800
crosses trust boundary say for example

183
00:07:37,800 --> 00:07:40,080
to a lower security domain even within

184
00:07:40,080 --> 00:07:42,120
the same organization

185
00:07:42,120 --> 00:07:44,699
we want a solution which is one way such

186
00:07:44,699 --> 00:07:47,099
that the shared data doesn't get leaked

187
00:07:47,099 --> 00:07:49,560
even if the keys used to protect that

188
00:07:49,560 --> 00:07:51,840
data were linked leaked compromised or

189
00:07:51,840 --> 00:07:54,479
otherwise shared additionally since our

190
00:07:54,479 --> 00:07:57,120
example here is for ads we need to

191
00:07:57,120 --> 00:07:59,099
ensure referential Integrity which means

192
00:07:59,099 --> 00:08:01,259
when the same input is provided we need

193
00:08:01,259 --> 00:08:03,599
to provide the same output

194
00:08:03,599 --> 00:08:06,060
and lastly we need ongoing key rotation

195
00:08:06,060 --> 00:08:07,979
in short in order to ensure ongoing

196
00:08:07,979 --> 00:08:10,560
protection of that data

197
00:08:10,560 --> 00:08:13,139
so key rotation poses its own challenges

198
00:08:13,139 --> 00:08:15,599
right only being done for the most

199
00:08:15,599 --> 00:08:18,840
sensitive of data or when a breach is

200
00:08:18,840 --> 00:08:20,639
clearingly obvious

201
00:08:20,639 --> 00:08:23,099
and this is due to the associated cost

202
00:08:23,099 --> 00:08:25,680
and complexity which really scales with

203
00:08:25,680 --> 00:08:27,240
the volume of data that's being

204
00:08:27,240 --> 00:08:28,440
protected

205
00:08:28,440 --> 00:08:30,840
now if you combine this with referential

206
00:08:30,840 --> 00:08:32,760
Integrity that is the need for the same

207
00:08:32,760 --> 00:08:36,719
input to map to the same output and you

208
00:08:36,719 --> 00:08:39,539
have a very large sphere of compromise

209
00:08:39,539 --> 00:08:42,719
if any key is ever leaked

210
00:08:42,719 --> 00:08:45,060
now a key update must maintain

211
00:08:45,060 --> 00:08:47,220
consistency with respect to the data

212
00:08:47,220 --> 00:08:50,220
being masked by the new key and the data

213
00:08:50,220 --> 00:08:52,140
that has been already masked by the

214
00:08:52,140 --> 00:08:54,420
previous key right

215
00:08:54,420 --> 00:08:57,899
now really a key update might be easily

216
00:08:57,899 --> 00:09:01,560
done by simply re-king the entire data

217
00:09:01,560 --> 00:09:04,500
set at once but that really doesn't work

218
00:09:04,500 --> 00:09:06,660
in a real life scenario as that will

219
00:09:06,660 --> 00:09:09,420
pose data usability or availability

220
00:09:09,420 --> 00:09:12,380
issues

221
00:09:12,540 --> 00:09:15,600
so let's see if we can push the the need

222
00:09:15,600 --> 00:09:17,580
to re-key onto the destination rather

223
00:09:17,580 --> 00:09:19,800
than doing it ourselves we're going to

224
00:09:19,800 --> 00:09:21,899
look at a paper authored by some people

225
00:09:21,899 --> 00:09:24,600
over at IBM where they describe a set of

226
00:09:24,600 --> 00:09:26,040
algorithms that use encryption and

227
00:09:26,040 --> 00:09:28,620
hashing in order to dynamically update

228
00:09:28,620 --> 00:09:31,880
the protection of data

229
00:09:34,680 --> 00:09:37,500
to know as Tim mentioned the setup

230
00:09:37,500 --> 00:09:40,200
considers a data owner producing data

231
00:09:40,200 --> 00:09:43,260
and tokenizing it the one that we refer

232
00:09:43,260 --> 00:09:46,680
here as a source and an untrusted host

233
00:09:46,680 --> 00:09:49,920
that is destination storing the devalued

234
00:09:49,920 --> 00:09:51,600
data only

235
00:09:51,600 --> 00:09:54,779
so the scheme operates in epochs

236
00:09:54,779 --> 00:09:56,880
starting with e0

237
00:09:56,880 --> 00:09:59,459
as a first step the owner generates a

238
00:09:59,459 --> 00:10:01,980
new tokenization key for e0 referred

239
00:10:01,980 --> 00:10:05,220
here as key zero and it uses it to

240
00:10:05,220 --> 00:10:07,920
tokenize any new values that's added to

241
00:10:07,920 --> 00:10:09,720
the data set

242
00:10:09,720 --> 00:10:12,360
the owner then sends the devalued data

243
00:10:12,360 --> 00:10:14,339
to The untrusted Host

244
00:10:14,339 --> 00:10:17,880
and now it it repeats it for for the

245
00:10:17,880 --> 00:10:21,300
next Epoch that is E1 and so on

246
00:10:21,300 --> 00:10:24,540
uh the owner at this stage also sends an

247
00:10:24,540 --> 00:10:27,300
update tweak to the host thereby rolling

248
00:10:27,300 --> 00:10:29,459
forward the values tokenized for the

249
00:10:29,459 --> 00:10:32,640
previous Epoch to the current debug

250
00:10:32,640 --> 00:10:35,339
now it's really a very complex set of

251
00:10:35,339 --> 00:10:37,620
algorithms that we have tried to

252
00:10:37,620 --> 00:10:39,899
represent on a high level in this slide

253
00:10:39,899 --> 00:10:42,660
because of time constraints but if

254
00:10:42,660 --> 00:10:44,760
you're looking to solve similar problem

255
00:10:44,760 --> 00:10:47,459
statements in your organization we

256
00:10:47,459 --> 00:10:49,740
highly recommend you to refer the paper

257
00:10:49,740 --> 00:10:51,899
the link to which has been linked at the

258
00:10:51,899 --> 00:10:54,959
bottom of the slide and explore it

259
00:10:54,959 --> 00:10:56,220
further

260
00:10:56,220 --> 00:10:58,800
now before we move on a point to be

261
00:10:58,800 --> 00:11:01,500
noted in this context is that the

262
00:11:01,500 --> 00:11:04,260
correctness condition of the algorithms

263
00:11:04,260 --> 00:11:08,760
is such that any newly devalued data

264
00:11:08,760 --> 00:11:11,459
from the owner in a particular Epoch

265
00:11:11,459 --> 00:11:13,920
must be same as the tokenized value

266
00:11:13,920 --> 00:11:16,320
produced by the host using the update

267
00:11:16,320 --> 00:11:19,500
tweak thereby ensuring referential

268
00:11:19,500 --> 00:11:21,600
integrity

269
00:11:21,600 --> 00:11:23,640
okay let's switch it up a bit now and

270
00:11:23,640 --> 00:11:25,980
talk about privacy for the context of

271
00:11:25,980 --> 00:11:27,959
the next few slides we're going to refer

272
00:11:27,959 --> 00:11:31,079
to security as stopping unauthorized

273
00:11:31,079 --> 00:11:33,180
actions and privacy is stopping

274
00:11:33,180 --> 00:11:36,560
unauthorized use cases

275
00:11:41,100 --> 00:11:43,140
on back-end jobs

276
00:11:43,140 --> 00:11:45,600
let's take an example of salary

277
00:11:45,600 --> 00:11:48,420
forecasting as depicted by this awesome

278
00:11:48,420 --> 00:11:50,220
looking bar diagram

279
00:11:50,220 --> 00:11:52,800
now due to privacy requirements the

280
00:11:52,800 --> 00:11:55,500
salary modeling system has access only

281
00:11:55,500 --> 00:11:58,040
to cohort level data containing

282
00:11:58,040 --> 00:12:01,560
anonymized compensation submissions for

283
00:12:01,560 --> 00:12:03,540
example salaries for security engineers

284
00:12:03,540 --> 00:12:05,880
in the San Francisco Bay Area

285
00:12:05,880 --> 00:12:08,760
let me try to elaborate a little more

286
00:12:08,760 --> 00:12:11,339
now I might be very interested in having

287
00:12:11,339 --> 00:12:14,100
salary forecasting as a critical data

288
00:12:14,100 --> 00:12:17,339
point while zeroing in on my next job

289
00:12:17,339 --> 00:12:20,640
now the gentleman sitting over here and

290
00:12:20,640 --> 00:12:22,560
the person over there they might have

291
00:12:22,560 --> 00:12:24,600
been generous enough to provide their

292
00:12:24,600 --> 00:12:27,000
compensation details to this salary

293
00:12:27,000 --> 00:12:31,079
modeling system and for us to be able to

294
00:12:31,079 --> 00:12:33,480
gain that Insight but of course they

295
00:12:33,480 --> 00:12:35,480
wouldn't be

296
00:12:35,480 --> 00:12:39,360
wouldn't be comfortable being attributed

297
00:12:39,360 --> 00:12:42,959
directly or or categorized specifically

298
00:12:42,959 --> 00:12:46,740
with their data as per attributable to

299
00:12:46,740 --> 00:12:50,220
that particular individual right so yeah

300
00:12:50,220 --> 00:12:52,800
let's let's try to elaborate more on

301
00:12:52,800 --> 00:12:55,560
what we can do about that so in this

302
00:12:55,560 --> 00:12:58,079
case ID is attributable to the user are

303
00:12:58,079 --> 00:13:00,420
hashed hashing in this instance can be

304
00:13:00,420 --> 00:13:02,459
used as both a security and a privacy

305
00:13:02,459 --> 00:13:03,360
control

306
00:13:03,360 --> 00:13:05,760
and indeed often security and privacy

307
00:13:05,760 --> 00:13:07,740
controls have overlapping needs and

308
00:13:07,740 --> 00:13:09,839
requirements which means that when you

309
00:13:09,839 --> 00:13:12,420
select a control for one the other needs

310
00:13:12,420 --> 00:13:15,420
to be in your mind or you may end up in

311
00:13:15,420 --> 00:13:16,920
a case where you select a security

312
00:13:16,920 --> 00:13:19,560
control and the organization is unable

313
00:13:19,560 --> 00:13:22,380
or unwilling to implement the matching

314
00:13:22,380 --> 00:13:25,040
privacy control

315
00:13:27,420 --> 00:13:30,120
so next we'll cover one more example of

316
00:13:30,120 --> 00:13:33,779
privacy control on facing applications

317
00:13:33,779 --> 00:13:36,720
so user facing privacy controls are

318
00:13:36,720 --> 00:13:38,940
relevant to protect certain categories

319
00:13:38,940 --> 00:13:42,660
of private actions a user can take such

320
00:13:42,660 --> 00:13:45,180
as clicking on an ad or reading an

321
00:13:45,180 --> 00:13:47,820
article now this is very different from

322
00:13:47,820 --> 00:13:51,660
a social action like posting an article

323
00:13:51,660 --> 00:13:54,420
or sharing a certain article

324
00:13:54,420 --> 00:13:58,100
uh let's try to elaborate a little more

325
00:13:58,100 --> 00:14:01,620
let's say I have a startup which has a

326
00:14:01,620 --> 00:14:05,519
next-gen AI security solution I post an

327
00:14:05,519 --> 00:14:07,860
article about this somewhere say on

328
00:14:07,860 --> 00:14:10,079
Hacker News and I want to see if it's

329
00:14:10,079 --> 00:14:12,779
resonating well with leaders in this

330
00:14:12,779 --> 00:14:13,740
space

331
00:14:13,740 --> 00:14:16,560
uh so I go on looking if

332
00:14:16,560 --> 00:14:18,899
um how many scissors have read this

333
00:14:18,899 --> 00:14:21,360
article in the last couple of months

334
00:14:21,360 --> 00:14:24,420
now let's say my good friend John Doe at

335
00:14:24,420 --> 00:14:28,380
ciso at real Corp reads this article now

336
00:14:28,380 --> 00:14:30,839
John reading this article should

337
00:14:30,839 --> 00:14:33,420
definitely contribute towards the stats

338
00:14:33,420 --> 00:14:37,019
right but again because of privacy

339
00:14:37,019 --> 00:14:38,880
concerns I shouldn't be able to

340
00:14:38,880 --> 00:14:41,519
explicitly figure out that it is indeed

341
00:14:41,519 --> 00:14:44,699
John who has read this article so how do

342
00:14:44,699 --> 00:14:46,440
we ensure this

343
00:14:46,440 --> 00:14:49,199
to ensure this the platform prevents me

344
00:14:49,199 --> 00:14:51,300
from creating a filter for csos who have

345
00:14:51,300 --> 00:14:53,459
read your article if the results of that

346
00:14:53,459 --> 00:14:56,599
filter are too few

347
00:14:57,600 --> 00:14:59,639
I could still however set up a filter

348
00:14:59,639 --> 00:15:02,880
for people who work at realcorp and

349
00:15:02,880 --> 00:15:04,139
people who live in San Francisco

350
00:15:04,139 --> 00:15:06,480
California and people who have

351
00:15:06,480 --> 00:15:07,800
previously worked at another real

352
00:15:07,800 --> 00:15:10,680
Corporation and combine those despite

353
00:15:10,680 --> 00:15:12,779
the platform's efforts I can still view

354
00:15:12,779 --> 00:15:15,959
I can still attribute this action to an

355
00:15:15,959 --> 00:15:17,160
individual

356
00:15:17,160 --> 00:15:19,320
so the way to protect against that is

357
00:15:19,320 --> 00:15:21,000
generally called differential privacy

358
00:15:21,000 --> 00:15:23,699
and it works by adding a random amount

359
00:15:23,699 --> 00:15:26,459
of noise to the results of these queries

360
00:15:26,459 --> 00:15:29,339
now you can also attack that by issuing

361
00:15:29,339 --> 00:15:31,920
the same query repeatedly and averaging

362
00:15:31,920 --> 00:15:34,980
out the results to remove the noise

363
00:15:34,980 --> 00:15:37,440
to protect against this you can use a

364
00:15:37,440 --> 00:15:39,420
pseudorandom noise generation Raider

365
00:15:39,420 --> 00:15:42,180
where you add a predetermined amount of

366
00:15:42,180 --> 00:15:44,699
noise to the query which gets redone

367
00:15:44,699 --> 00:15:47,899
each time the query is run

368
00:15:49,740 --> 00:15:51,540
about some common data protection

369
00:15:51,540 --> 00:15:54,920
techniques like encryption FB

370
00:15:54,920 --> 00:15:58,380
tokenization hashing and so on so let's

371
00:15:58,380 --> 00:16:00,360
quickly glance through some of the other

372
00:16:00,360 --> 00:16:03,980
options we might have

373
00:16:04,139 --> 00:16:06,600
now homomorphic encryption allows

374
00:16:06,600 --> 00:16:08,699
computations to be performed on

375
00:16:08,699 --> 00:16:11,399
encrypted data without first having to

376
00:16:11,399 --> 00:16:14,399
decrypt it sounds promising right so

377
00:16:14,399 --> 00:16:17,399
this picture shows one such additive

378
00:16:17,399 --> 00:16:20,639
operation for homomorphic encryption

379
00:16:20,639 --> 00:16:22,740
however this technique has some

380
00:16:22,740 --> 00:16:25,320
significant limitations in terms of the

381
00:16:25,320 --> 00:16:27,959
operations that can be performed and

382
00:16:27,959 --> 00:16:30,779
also has latency concerns and high

383
00:16:30,779 --> 00:16:32,880
storage requirements

384
00:16:32,880 --> 00:16:36,540
so because of obvious reasons it's not

385
00:16:36,540 --> 00:16:38,639
mainstream but that being said it's

386
00:16:38,639 --> 00:16:41,579
still an emerging solution especially in

387
00:16:41,579 --> 00:16:45,000
high security Cloud use cases

388
00:16:45,000 --> 00:16:47,759
AI has been exploding recently in

389
00:16:47,759 --> 00:16:50,820
popularity in places such as chat gbt

390
00:16:50,820 --> 00:16:54,600
and Tesla and Uber and typically models

391
00:16:54,600 --> 00:16:56,639
like those are trained while they're

392
00:16:56,639 --> 00:16:59,279
being developed on real data in some

393
00:16:59,279 --> 00:17:01,440
cases it may be possible to build those

394
00:17:01,440 --> 00:17:03,839
models on synthetic or completely fake

395
00:17:03,839 --> 00:17:06,419
data and then when the developers have

396
00:17:06,419 --> 00:17:08,220
some level of confidence in their models

397
00:17:08,220 --> 00:17:12,319
move it over to real data

398
00:17:13,619 --> 00:17:15,480
masking is another commonly used

399
00:17:15,480 --> 00:17:18,059
technique to protect data it involves

400
00:17:18,059 --> 00:17:19,919
replacing characters of the data with

401
00:17:19,919 --> 00:17:22,980
random value with a placeholder value

402
00:17:22,980 --> 00:17:25,559
it's very easy to do and can be done on

403
00:17:25,559 --> 00:17:27,240
the Fly rather than needing to be done

404
00:17:27,240 --> 00:17:30,000
at the data at rest making it a very

405
00:17:30,000 --> 00:17:32,840
lightweight option

406
00:17:33,960 --> 00:17:37,380
okay so Mr Cat Here agrees that data

407
00:17:37,380 --> 00:17:40,140
protection and data security is indeed a

408
00:17:40,140 --> 00:17:41,640
big deal right

409
00:17:41,640 --> 00:17:43,860
so we talked about quite a few options

410
00:17:43,860 --> 00:17:47,760
each with its own security properties so

411
00:17:47,760 --> 00:17:50,460
how do we rationally categorize which

412
00:17:50,460 --> 00:17:53,039
data security strategy aligns better

413
00:17:53,039 --> 00:17:57,179
with certain specific use cases

414
00:17:57,179 --> 00:17:59,760
so since there are so many options out

415
00:17:59,760 --> 00:18:01,919
there with different security properties

416
00:18:01,919 --> 00:18:03,960
and each with their own caveats and

417
00:18:03,960 --> 00:18:07,020
nuances we tried creating a flowchart to

418
00:18:07,020 --> 00:18:08,340
help decide

419
00:18:08,340 --> 00:18:11,760
we focused on a combination of data

420
00:18:11,760 --> 00:18:14,520
properties and security needs note that

421
00:18:14,520 --> 00:18:16,980
the Green Arrow represents a yes to the

422
00:18:16,980 --> 00:18:20,100
question and rate is obviously a no the

423
00:18:20,100 --> 00:18:23,460
blue boxes denote runtime protections as

424
00:18:23,460 --> 00:18:25,440
opposed to protections applied to the

425
00:18:25,440 --> 00:18:27,960
data as it's written to the store

426
00:18:27,960 --> 00:18:30,360
the two key points about this flowchart

427
00:18:30,360 --> 00:18:32,400
first it does not take into account

428
00:18:32,400 --> 00:18:34,860
business needs beyond the need to

429
00:18:34,860 --> 00:18:37,620
reverse the data and second it doesn't

430
00:18:37,620 --> 00:18:41,340
handle layering options for example if

431
00:18:41,340 --> 00:18:42,679
you have

432
00:18:42,679 --> 00:18:45,179
unstructured data that needs to be

433
00:18:45,179 --> 00:18:47,760
reversed as well we could enable

434
00:18:47,760 --> 00:18:50,460
encryption to protect the data at rest

435
00:18:50,460 --> 00:18:54,240
and mask all data from any reads to the

436
00:18:54,240 --> 00:18:58,260
data set to protect it in use

437
00:18:58,260 --> 00:19:01,020
so let's take an example of data which

438
00:19:01,020 --> 00:19:02,700
is structured that we need to be able to

439
00:19:02,700 --> 00:19:04,799
reverse and we want to protect both in

440
00:19:04,799 --> 00:19:06,419
use and at rest

441
00:19:06,419 --> 00:19:08,700
we can see that we say yes to is it

442
00:19:08,700 --> 00:19:11,400
structured and uh

443
00:19:11,400 --> 00:19:14,900
yes to it is reversible that immediately

444
00:19:14,900 --> 00:19:17,940
immediately eliminates the options of

445
00:19:17,940 --> 00:19:20,760
hashing synthetic and tokenized data

446
00:19:20,760 --> 00:19:22,980
we've said that the data needs to be

447
00:19:22,980 --> 00:19:24,780
protected at rest so we can eliminate

448
00:19:24,780 --> 00:19:28,559
masking and adding noise lastly because

449
00:19:28,559 --> 00:19:31,559
it needs to be protected in use we can't

450
00:19:31,559 --> 00:19:33,539
use traditional encryption or format

451
00:19:33,539 --> 00:19:35,460
preserving encryption

452
00:19:35,460 --> 00:19:37,740
our vision with this chart is to codify

453
00:19:37,740 --> 00:19:39,299
it into something that engineering can

454
00:19:39,299 --> 00:19:41,640
use to get some idea of what protections

455
00:19:41,640 --> 00:19:43,860
they can use without the delays that are

456
00:19:43,860 --> 00:19:45,539
typically involved in talking to

457
00:19:45,539 --> 00:19:49,340
security about pretty much anything

458
00:19:51,179 --> 00:19:53,880
okay so through this present ation we

459
00:19:53,880 --> 00:19:56,760
have alluded to gotchas in in several of

460
00:19:56,760 --> 00:19:59,220
the techniques we'll now try cover some

461
00:19:59,220 --> 00:20:00,179
of these

462
00:20:00,179 --> 00:20:03,840
let's talk about hashing now hashing is

463
00:20:03,840 --> 00:20:06,120
only really helpful if the data domain

464
00:20:06,120 --> 00:20:09,539
size is significantly large enough for

465
00:20:09,539 --> 00:20:12,120
example hashing cities isn't a good idea

466
00:20:12,120 --> 00:20:14,880
because an attacker can very easily and

467
00:20:14,880 --> 00:20:17,520
effectively use rainbow tables to bypass

468
00:20:17,520 --> 00:20:19,260
the protection

469
00:20:19,260 --> 00:20:21,840
format preserving encryption May leak

470
00:20:21,840 --> 00:20:24,539
data types like IP addresses and may

471
00:20:24,539 --> 00:20:27,720
even allow attackers to infer the values

472
00:20:27,720 --> 00:20:30,360
based on the surrounding data

473
00:20:30,360 --> 00:20:32,760
tokenization has few weaknesses other

474
00:20:32,760 --> 00:20:34,500
than the limitations around when it can

475
00:20:34,500 --> 00:20:36,840
be used but if you can successfully

476
00:20:36,840 --> 00:20:39,480
attack the token mapping table it fails

477
00:20:39,480 --> 00:20:41,580
catastrophically

478
00:20:41,580 --> 00:20:43,860
masking is tough to do if you're not

479
00:20:43,860 --> 00:20:46,500
doing it to the entire field for example

480
00:20:46,500 --> 00:20:49,380
it's common to mask email addresses by

481
00:20:49,380 --> 00:20:51,240
masking the user alias

482
00:20:51,240 --> 00:20:53,640
if my email address was Tim at

483
00:20:53,640 --> 00:20:56,280
timsdomain.com and we masked the user

484
00:20:56,280 --> 00:20:58,260
Alias we'd be left with star star

485
00:20:58,260 --> 00:21:00,720
tim'sdomain.com

486
00:21:00,720 --> 00:21:02,760
and that assumes we do the entire user

487
00:21:02,760 --> 00:21:06,600
Alias which isn't always the case either

488
00:21:06,600 --> 00:21:08,820
lastly our threat models so far have

489
00:21:08,820 --> 00:21:11,640
really described problems one at a time

490
00:21:11,640 --> 00:21:13,919
with a single database in mind but it's

491
00:21:13,919 --> 00:21:15,660
conceivable that an attacker could gain

492
00:21:15,660 --> 00:21:18,360
access to multiple data sets and join

493
00:21:18,360 --> 00:21:20,340
those data sets on unique data that

494
00:21:20,340 --> 00:21:22,740
isn't protected so the bigger picture is

495
00:21:22,740 --> 00:21:26,299
important to keep in mind as well

496
00:21:27,720 --> 00:21:30,360
data security is tough there are legal

497
00:21:30,360 --> 00:21:32,100
requirements to do it there are lots of

498
00:21:32,100 --> 00:21:33,780
options to do it and each of those

499
00:21:33,780 --> 00:21:36,000
options has a lot of nuances and

500
00:21:36,000 --> 00:21:37,200
limitations

501
00:21:37,200 --> 00:21:39,179
but hopefully we've given you some ideas

502
00:21:39,179 --> 00:21:43,340
around what you can do and when

503
00:21:45,659 --> 00:21:47,460
thanks

504
00:21:47,460 --> 00:21:50,240
any questions

505
00:21:59,520 --> 00:22:01,380
so the question was homomorphic

506
00:22:01,380 --> 00:22:02,820
encryption can you explain it a little

507
00:22:02,820 --> 00:22:05,760
more uh the questioner has heard about

508
00:22:05,760 --> 00:22:10,580
it but not seen it in in use

509
00:22:15,360 --> 00:22:17,880
so there's like additive operation the

510
00:22:17,880 --> 00:22:19,679
one that we had in the screenshot and

511
00:22:19,679 --> 00:22:21,780
there's multiplicative operation as well

512
00:22:21,780 --> 00:22:24,480
and by virtue of certain algorithms

513
00:22:24,480 --> 00:22:26,460
there's no need to decrypt the data and

514
00:22:26,460 --> 00:22:29,460
you can directly perform it on the the

515
00:22:29,460 --> 00:22:32,600
resulting output

516
00:22:43,320 --> 00:22:45,240
what does it actually mean is the

517
00:22:45,240 --> 00:22:47,539
question

518
00:22:51,120 --> 00:22:53,760
yeah so it enables you to do

519
00:22:53,760 --> 00:22:55,559
computations on the data without knowing

520
00:22:55,559 --> 00:22:58,500
what that data is the slide that was up

521
00:22:58,500 --> 00:23:00,360
for it kind of went into the math behind

522
00:23:00,360 --> 00:23:02,220
it I'm not a mathematician I can't

523
00:23:02,220 --> 00:23:06,320
explain to you how the math Works sorry

524
00:23:06,900 --> 00:23:10,500
cool uh one other question you mentioned

525
00:23:10,500 --> 00:23:13,080
some of the pitfalls with the different

526
00:23:13,080 --> 00:23:15,600
methods and some of them are format

527
00:23:15,600 --> 00:23:17,760
preserving and that was listed as a

528
00:23:17,760 --> 00:23:19,919
pitfall for example for IP addresses

529
00:23:19,919 --> 00:23:22,500
there's algorithms like cryptopan where

530
00:23:22,500 --> 00:23:24,780
you you know can still perform top K

531
00:23:24,780 --> 00:23:27,539
prefix searches on the anonymized or to

532
00:23:27,539 --> 00:23:30,600
normalized data points but that isn't

533
00:23:30,600 --> 00:23:33,780
that precisely the trade-off because you

534
00:23:33,780 --> 00:23:35,580
want to be somewhere in the middle of

535
00:23:35,580 --> 00:23:37,740
the spectrum of

536
00:23:37,740 --> 00:23:41,159
full privacy and nothing at all so I

537
00:23:41,159 --> 00:23:43,260
think I would have questions you know

538
00:23:43,260 --> 00:23:46,380
even after the flowchart as when I'm not

539
00:23:46,380 --> 00:23:47,820
at the two ends of the spectrum but

540
00:23:47,820 --> 00:23:50,039
rather somewhere in the middle like what

541
00:23:50,039 --> 00:23:52,500
do I get when I get any of these things

542
00:23:52,500 --> 00:23:54,000
like

543
00:23:54,000 --> 00:23:56,340
um because I do want some extra utility

544
00:23:56,340 --> 00:23:59,039
from say the structure preservation what

545
00:23:59,039 --> 00:24:01,260
do I give away and like to me that

546
00:24:01,260 --> 00:24:04,320
navigating that space is uh would be

547
00:24:04,320 --> 00:24:06,000
like the next thing I'd have to do after

548
00:24:06,000 --> 00:24:08,280
having heard your talk yeah I think the

549
00:24:08,280 --> 00:24:10,080
flowchart really should be two flow

550
00:24:10,080 --> 00:24:11,880
charts one where we walk through the

551
00:24:11,880 --> 00:24:14,700
data use needs and one where we walk

552
00:24:14,700 --> 00:24:16,559
through the desired security attributes

553
00:24:16,559 --> 00:24:18,840
being applied to that but we didn't have

554
00:24:18,840 --> 00:24:20,760
time to break the flowchart into before

555
00:24:20,760 --> 00:24:24,179
this talk I have to talk about the isn't

556
00:24:24,179 --> 00:24:25,860
that a plus a format preserving

557
00:24:25,860 --> 00:24:29,220
encryption yes it is but only if you are

558
00:24:29,220 --> 00:24:31,500
knowingly taking that on sure and that

559
00:24:31,500 --> 00:24:33,720
you say I'm okay with people being able

560
00:24:33,720 --> 00:24:36,120
to do to deduce information about this

561
00:24:36,120 --> 00:24:39,799
for that particular data thank you

562
00:24:45,299 --> 00:24:48,320
any other questions

563
00:24:52,980 --> 00:24:56,360
I'm sorry I couldn't hear you

564
00:24:58,020 --> 00:24:59,820
which of the masking techniques do we

565
00:24:59,820 --> 00:25:02,539
wet the most

566
00:25:05,340 --> 00:25:07,080
which of the mat of the masking

567
00:25:07,080 --> 00:25:08,520
techniques to the developers like the

568
00:25:08,520 --> 00:25:11,760
most probably what we have described is

569
00:25:11,760 --> 00:25:15,559
masking because it is the easiest

570
00:25:22,020 --> 00:25:25,039
any other questions

571
00:25:43,460 --> 00:25:46,380
not just ipv4

572
00:25:46,380 --> 00:25:49,140
yeah that goes more into how we make

573
00:25:49,140 --> 00:25:51,120
certain libraries available to the

574
00:25:51,120 --> 00:25:53,279
developers to handle that and I don't

575
00:25:53,279 --> 00:25:56,600
have a good answer for you right now

576
00:25:57,960 --> 00:26:00,659
let's actually end the Q a right now if

577
00:26:00,659 --> 00:26:02,340
you have any other questions you can go

578
00:26:02,340 --> 00:26:04,620
ask them outside let's give a round of

579
00:26:04,620 --> 00:26:07,210
applause for him

580
00:26:07,210 --> 00:26:09,660
[Applause]

