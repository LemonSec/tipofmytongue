1
00:00:00,000 --> 00:00:04,019
like most good hopefully good facial

2
00:00:04,019 --> 00:00:05,759
recognition talks

3
00:00:05,759 --> 00:00:07,919
this one starts

4
00:00:07,919 --> 00:00:10,080
with Naval Warfare

5
00:00:10,080 --> 00:00:11,280
now

6
00:00:11,280 --> 00:00:13,559
this is how Naval battles used to be

7
00:00:13,559 --> 00:00:17,160
fought two fleets across from each other

8
00:00:17,160 --> 00:00:19,859
in two lines attacking each other at

9
00:00:19,859 --> 00:00:22,199
near Point Blank Range until one gives

10
00:00:22,199 --> 00:00:23,039
up

11
00:00:23,039 --> 00:00:25,859
or sinks

12
00:00:25,859 --> 00:00:27,720
in 1805

13
00:00:27,720 --> 00:00:30,300
Lord Admiral Nelson changed this with a

14
00:00:30,300 --> 00:00:33,480
new Naval Warfare tactic basically just

15
00:00:33,480 --> 00:00:35,640
consisted of going straight at the enemy

16
00:00:35,640 --> 00:00:37,260
as you can see here

17
00:00:37,260 --> 00:00:39,000
what do you think happens when you take

18
00:00:39,000 --> 00:00:41,399
one huge Fleet of ships and fling them

19
00:00:41,399 --> 00:00:45,480
directly at another huge Fleet of ships

20
00:00:45,480 --> 00:00:48,420
yeah that's right a hot mess right

21
00:00:48,420 --> 00:00:50,760
friend and foe mixed together close

22
00:00:50,760 --> 00:00:52,680
range fog of four really hard to

23
00:00:52,680 --> 00:00:56,219
identify who is who identify friend and

24
00:00:56,219 --> 00:00:59,640
Foe and else Nelson knew this and so

25
00:00:59,640 --> 00:01:01,500
Legend has it that he painted all of his

26
00:01:01,500 --> 00:01:04,260
ships in this particular color scheme

27
00:01:04,260 --> 00:01:07,619
now known as a Nelson checker and this

28
00:01:07,619 --> 00:01:10,380
as an authentication scheme was nearly

29
00:01:10,380 --> 00:01:13,020
perfect at least in the first battle why

30
00:01:13,020 --> 00:01:15,780
because it was accurate only his ships

31
00:01:15,780 --> 00:01:18,060
were painted in this scheme and it was

32
00:01:18,060 --> 00:01:20,640
easy to use right at a single glance

33
00:01:20,640 --> 00:01:23,759
every ship every gun crew every

34
00:01:23,759 --> 00:01:25,560
individual sailor could look up and say

35
00:01:25,560 --> 00:01:28,080
a friend or Foe and take immediate

36
00:01:28,080 --> 00:01:29,700
action

37
00:01:29,700 --> 00:01:33,000
as you might imagine it led him to

38
00:01:33,000 --> 00:01:35,400
actually hoist his message to his Fleet

39
00:01:35,400 --> 00:01:37,320
and instead of giving directions you

40
00:01:37,320 --> 00:01:39,180
should go there go here as you normally

41
00:01:39,180 --> 00:01:41,820
would he just lifted a message to his

42
00:01:41,820 --> 00:01:43,439
entire fleet and said look

43
00:01:43,439 --> 00:01:46,020
do your job like take responsibility

44
00:01:46,020 --> 00:01:49,560
I've enabled you take action

45
00:01:49,560 --> 00:01:51,540
after that first battle however which

46
00:01:51,540 --> 00:01:53,340
was a success even though he died we'll

47
00:01:53,340 --> 00:01:56,340
gloss over that part

48
00:01:56,340 --> 00:01:58,979
um this scheme faltered a bit why for

49
00:01:58,979 --> 00:02:00,540
the same reasons it suffered problems

50
00:02:00,540 --> 00:02:03,659
with accuracy and ease of use accuracy

51
00:02:03,659 --> 00:02:06,719
because people aren't stupid right they

52
00:02:06,719 --> 00:02:08,098
immediately the other Fleet started

53
00:02:08,098 --> 00:02:10,139
paying themselves to mimic

54
00:02:10,139 --> 00:02:13,620
Nelson's Fleet and then secondarily ease

55
00:02:13,620 --> 00:02:16,319
of use it doesn't take a genius but

56
00:02:16,319 --> 00:02:18,720
about 10 minutes to realize oh look all

57
00:02:18,720 --> 00:02:20,280
the enemy ships are painted a particular

58
00:02:20,280 --> 00:02:23,040
way and they could use the same scheme

59
00:02:23,040 --> 00:02:24,480
as well

60
00:02:24,480 --> 00:02:28,920
facial recognition has the same give and

61
00:02:28,920 --> 00:02:30,060
take

62
00:02:30,060 --> 00:02:33,120
when it works well and by that I mean

63
00:02:33,120 --> 00:02:35,760
more of a one-to-one scenario classic

64
00:02:35,760 --> 00:02:38,819
example think of facial recognition on

65
00:02:38,819 --> 00:02:40,620
your mobile device where it's it's

66
00:02:40,620 --> 00:02:42,540
comparing it to your image that you

67
00:02:42,540 --> 00:02:45,300
voluntarily recorded a secure Enclave

68
00:02:45,300 --> 00:02:47,640
pretty great right

69
00:02:47,640 --> 00:02:50,700
it's accurate and it's easy to use it

70
00:02:50,700 --> 00:02:52,680
identifies you gives you some strong off

71
00:02:52,680 --> 00:02:54,300
and you're going to look at your phone

72
00:02:54,300 --> 00:02:56,519
anyway you're not going out of your way

73
00:02:56,519 --> 00:02:58,140
to do anything

74
00:02:58,140 --> 00:03:00,780
but just like Nelson scheme it ran into

75
00:03:00,780 --> 00:03:02,220
problems

76
00:03:02,220 --> 00:03:04,920
as soon as the ball game changed a bit

77
00:03:04,920 --> 00:03:07,200
when it went from one to one

78
00:03:07,200 --> 00:03:10,379
to one to n now instead of comparing

79
00:03:10,379 --> 00:03:12,420
single photos there would be a still

80
00:03:12,420 --> 00:03:14,280
from a video or from a surveillance

81
00:03:14,280 --> 00:03:16,920
camera or some such and it'd be compared

82
00:03:16,920 --> 00:03:19,800
to a database and that would return a

83
00:03:19,800 --> 00:03:23,220
top n number of suspects or possible

84
00:03:23,220 --> 00:03:25,860
candidates if you will

85
00:03:25,860 --> 00:03:29,099
and just like Nelson it ran into issues

86
00:03:29,099 --> 00:03:31,800
as soon as it started using this scheme

87
00:03:31,800 --> 00:03:35,280
issues with accuracy and ease of use

88
00:03:35,280 --> 00:03:40,200
first accuracy in 2018 Dr Joy boulemwini

89
00:03:40,200 --> 00:03:42,540
at MIT realized official recognition

90
00:03:42,540 --> 00:03:45,420
systems could not identify her own face

91
00:03:45,420 --> 00:03:47,780
because she was a dark-skinned female

92
00:03:47,780 --> 00:03:50,940
that led to lots of research by her

93
00:03:50,940 --> 00:03:53,280
algorithmic justice league and

94
00:03:53,280 --> 00:03:56,340
documentation of false arrests three or

95
00:03:56,340 --> 00:03:58,560
four men in Detroit were falsely

96
00:03:58,560 --> 00:04:01,140
arrested based off of video facial

97
00:04:01,140 --> 00:04:02,940
recognition systems because what was

98
00:04:02,940 --> 00:04:05,099
happening was these systems were being

99
00:04:05,099 --> 00:04:08,760
sold to law enforcement to agencies to

100
00:04:08,760 --> 00:04:11,280
kind of identify suspects leading to

101
00:04:11,280 --> 00:04:13,980
potential false arrests the work of the

102
00:04:13,980 --> 00:04:15,840
algorithmic Justice League and

103
00:04:15,840 --> 00:04:18,600
adversarial research like Dr bulumlini's

104
00:04:18,600 --> 00:04:21,779
improved the bias scores and the bias

105
00:04:21,779 --> 00:04:23,340
issues with some of these major

106
00:04:23,340 --> 00:04:25,020
Enterprises and some Enterprises like

107
00:04:25,020 --> 00:04:28,199
IBM decided to leave the technology all

108
00:04:28,199 --> 00:04:30,360
together

109
00:04:30,360 --> 00:04:32,400
but it wasn't just bias and accuracy it

110
00:04:32,400 --> 00:04:34,320
was also ease of use that presented a

111
00:04:34,320 --> 00:04:35,220
challenge

112
00:04:35,220 --> 00:04:37,620
and that's because think of all the

113
00:04:37,620 --> 00:04:41,280
photos of you or people you love out on

114
00:04:41,280 --> 00:04:43,680
social media pretty soon companies like

115
00:04:43,680 --> 00:04:47,160
Clearview Ai and pemas started farming

116
00:04:47,160 --> 00:04:49,800
all of these photographs building a

117
00:04:49,800 --> 00:04:51,780
massive database and then in turn

118
00:04:51,780 --> 00:04:54,120
selling it to law enforcement agencies

119
00:04:54,120 --> 00:04:57,479
or neighborhood associations or

120
00:04:57,479 --> 00:05:00,120
on pemas you could go out and search for

121
00:05:00,120 --> 00:05:02,340
yourself for people you know right now

122
00:05:02,340 --> 00:05:04,860
and see where they've been on the

123
00:05:04,860 --> 00:05:08,580
internet and in real in the real world

124
00:05:08,580 --> 00:05:10,800
um the database was 20 billion for

125
00:05:10,800 --> 00:05:12,419
Clearview and this is like two or three

126
00:05:12,419 --> 00:05:15,900
years old it's much larger now so the

127
00:05:15,900 --> 00:05:18,540
issue is that it was too easy to use in

128
00:05:18,540 --> 00:05:20,699
a way right photos that were uploaded

129
00:05:20,699 --> 00:05:22,979
for personal or private use were now

130
00:05:22,979 --> 00:05:25,199
being weaponized against the very people

131
00:05:25,199 --> 00:05:28,440
that uploaded them so accuracy and ease

132
00:05:28,440 --> 00:05:32,580
of use and and we saw examples of the of

133
00:05:32,580 --> 00:05:34,560
Enterprises realizing the danger and

134
00:05:34,560 --> 00:05:36,840
trying to address bias and taking care

135
00:05:36,840 --> 00:05:38,520
of some of their facial data and

136
00:05:38,520 --> 00:05:40,259
biometric data and we've seen the

137
00:05:40,259 --> 00:05:42,240
government try and step in in Illinois

138
00:05:42,240 --> 00:05:45,240
with bypoc and gdpr and the artificial

139
00:05:45,240 --> 00:05:47,039
intelligence act in Europe was just

140
00:05:47,039 --> 00:05:49,680
trying to limit sharing a facial data

141
00:05:49,680 --> 00:05:53,100
between nation states in Europe but we

142
00:05:53,100 --> 00:05:56,280
can't rely just on Enterprises and the

143
00:05:56,280 --> 00:05:58,620
government to protect or help people

144
00:05:58,620 --> 00:06:00,840
protect their privacy right we need to

145
00:06:00,840 --> 00:06:03,600
enable individuals to play an active

146
00:06:03,600 --> 00:06:06,600
role because privacy is a team sport

147
00:06:06,600 --> 00:06:08,580
adversarial research has been moving

148
00:06:08,580 --> 00:06:11,340
from bias addressing bias like I talked

149
00:06:11,340 --> 00:06:13,919
about before and to trying to deal with

150
00:06:13,919 --> 00:06:16,080
that ease of use that universal access

151
00:06:16,080 --> 00:06:19,860
of photographic data online basically

152
00:06:19,860 --> 00:06:22,259
saying how can we give people tools to

153
00:06:22,259 --> 00:06:24,419
protect themselves that kind of can be

154
00:06:24,419 --> 00:06:26,580
used in normal flow

155
00:06:26,580 --> 00:06:29,100
I'll go cover five or six different

156
00:06:29,100 --> 00:06:32,280
approaches that have emerged since 2001

157
00:06:32,280 --> 00:06:34,979
most of them in the last year and we're

158
00:06:34,979 --> 00:06:36,479
going to start with one that I ran into

159
00:06:36,479 --> 00:06:40,500
in 2019. I wrote a Spartacus app that

160
00:06:40,500 --> 00:06:42,960
tried to protect privacy of your social

161
00:06:42,960 --> 00:06:45,919
media Accounts at Defcon Blackheart 2019

162
00:06:45,919 --> 00:06:48,000
and as part of that I needed a fake

163
00:06:48,000 --> 00:06:51,120
identity so I I made one wholesale and I

164
00:06:51,120 --> 00:06:53,400
needed a photo for my fake identity to

165
00:06:53,400 --> 00:06:55,500
give her authenticity online this is the

166
00:06:55,500 --> 00:06:57,060
photo I chose

167
00:06:57,060 --> 00:06:59,220
after I did this a couple days later my

168
00:06:59,220 --> 00:07:00,539
friend called me up and said Mike you

169
00:07:00,539 --> 00:07:03,660
can't use this woman I was like why not

170
00:07:03,660 --> 00:07:07,020
she was openstock photography that you

171
00:07:07,020 --> 00:07:09,960
know she's cautious domain public domain

172
00:07:09,960 --> 00:07:11,699
he said have you done a reverse image

173
00:07:11,699 --> 00:07:15,539
search on her and I said no

174
00:07:15,539 --> 00:07:18,120
how how you know how many sites is she

175
00:07:18,120 --> 00:07:19,919
on ten thousand

176
00:07:19,919 --> 00:07:21,660
four thousand

177
00:07:21,660 --> 00:07:23,280
no

178
00:07:23,280 --> 00:07:26,759
25 billion hits

179
00:07:26,759 --> 00:07:30,120
right she was everywhere she was a

180
00:07:30,120 --> 00:07:32,759
mystery novel writer in Des Moines she

181
00:07:32,759 --> 00:07:35,940
was a lawmaker in DC she was a diplomat

182
00:07:35,940 --> 00:07:38,699
in Amsterdam she was a sex worker in

183
00:07:38,699 --> 00:07:40,080
Vegas

184
00:07:40,080 --> 00:07:42,780
she had she was everywhere and she was

185
00:07:42,780 --> 00:07:44,099
nowhere

186
00:07:44,099 --> 00:07:45,599
at the same time

187
00:07:45,599 --> 00:07:48,360
so one potential approach if you chose

188
00:07:48,360 --> 00:07:51,840
to take it to protect your facial data

189
00:07:51,840 --> 00:07:54,360
would be to put yourself in every stock

190
00:07:54,360 --> 00:07:56,639
photography you can find

191
00:07:56,639 --> 00:07:58,319
I'm not saying it's recommended but

192
00:07:58,319 --> 00:07:59,699
again like her you would be everywhere

193
00:07:59,699 --> 00:08:01,319
in nowhere

194
00:08:01,319 --> 00:08:03,599
onward to Academia the more realistic

195
00:08:03,599 --> 00:08:05,780
approaches 2001

196
00:08:05,780 --> 00:08:08,340
researchers started to experiment with

197
00:08:08,340 --> 00:08:10,800
pixel modification basically finding the

198
00:08:10,800 --> 00:08:13,620
gradient in changes in images and facial

199
00:08:13,620 --> 00:08:16,199
data inserting geometric patterns or

200
00:08:16,199 --> 00:08:19,319
even single pixels in key areas throwing

201
00:08:19,319 --> 00:08:20,220
off

202
00:08:20,220 --> 00:08:22,860
uh facial recognition systems facial

203
00:08:22,860 --> 00:08:24,300
recognition systems caught on very

204
00:08:24,300 --> 00:08:26,940
quickly as the cat and mouse game goes

205
00:08:26,940 --> 00:08:29,639
on but it was an interesting start and

206
00:08:29,639 --> 00:08:31,680
what I'll do is we go through these and

207
00:08:31,680 --> 00:08:33,958
these slides will be available later I'm

208
00:08:33,958 --> 00:08:36,620
kind of categorizing these in five areas

209
00:08:36,620 --> 00:08:39,599
for example this pixel modification is

210
00:08:39,599 --> 00:08:40,679
it fast

211
00:08:40,679 --> 00:08:42,899
sure is inserting a pixel is pretty

212
00:08:42,899 --> 00:08:45,839
pretty darn quick is it on mobile it was

213
00:08:45,839 --> 00:08:48,839
not at the time in 2001 is it Dynamic

214
00:08:48,839 --> 00:08:51,360
meaning is it per image

215
00:08:51,360 --> 00:08:53,940
that checks that box as well is it

216
00:08:53,940 --> 00:08:55,800
transparent in other words have I

217
00:08:55,800 --> 00:08:57,480
modified this photo so much that I

218
00:08:57,480 --> 00:08:58,920
wouldn't want to share it with family

219
00:08:58,920 --> 00:09:01,500
and friends and my own mother no it's

220
00:09:01,500 --> 00:09:03,420
pretty pretty transparent and then

221
00:09:03,420 --> 00:09:05,580
protective there are two phases for

222
00:09:05,580 --> 00:09:08,519
facial recognition face detection and

223
00:09:08,519 --> 00:09:10,920
face matching or classification and so

224
00:09:10,920 --> 00:09:13,440
this one basically messes up the ability

225
00:09:13,440 --> 00:09:16,680
of the system to detect faces so far so

226
00:09:16,680 --> 00:09:18,959
good we'll build up this graph next up

227
00:09:18,959 --> 00:09:21,779
is generative adversarial networks most

228
00:09:21,779 --> 00:09:23,940
people have seen this in the this person

229
00:09:23,940 --> 00:09:26,700
does not exist.com website that's the

230
00:09:26,700 --> 00:09:28,620
technology it's using behind the scenes

231
00:09:28,620 --> 00:09:30,839
it keeps your high level attributes

232
00:09:30,839 --> 00:09:32,940
modifies things so it doesn't quite look

233
00:09:32,940 --> 00:09:35,820
like you and the issue here is that it's

234
00:09:35,820 --> 00:09:38,279
basically your avatar it's not you but

235
00:09:38,279 --> 00:09:39,959
it a lot of people would use it one

236
00:09:39,959 --> 00:09:42,480
place everywhere and it's fairly

237
00:09:42,480 --> 00:09:45,600
expensive it has come to mobile everyone

238
00:09:45,600 --> 00:09:49,080
who's used tunify or anything else the

239
00:09:49,080 --> 00:09:50,459
the recent app I can't remember the name

240
00:09:50,459 --> 00:09:51,959
of it at this point face app there are

241
00:09:51,959 --> 00:09:53,459
others that made your own little Avatar

242
00:09:53,459 --> 00:09:55,740
that everybody used same kind of thing

243
00:09:55,740 --> 00:09:58,920
here is it fast it can be but in the

244
00:09:58,920 --> 00:10:01,080
past it's not been when it's done to

245
00:10:01,080 --> 00:10:03,600
photorealism standards

246
00:10:03,600 --> 00:10:05,399
um it's not dynamic because it's just

247
00:10:05,399 --> 00:10:07,580
this one image emulator review

248
00:10:07,580 --> 00:10:09,959
transparent certainly not because again

249
00:10:09,959 --> 00:10:12,420
it's not you really at all and then

250
00:10:12,420 --> 00:10:14,640
really it's still identifiable as a face

251
00:10:14,640 --> 00:10:17,820
it's just not recognizable as you if you

252
00:10:17,820 --> 00:10:19,880
put it out there

253
00:10:19,880 --> 00:10:22,019
2020. now we're going to start to get

254
00:10:22,019 --> 00:10:24,180
interesting there's a paper and a

255
00:10:24,180 --> 00:10:26,519
demonstration Android app that's a

256
00:10:26,519 --> 00:10:27,720
little wonky but you can still get to

257
00:10:27,720 --> 00:10:29,820
run on today's devices called camera

258
00:10:29,820 --> 00:10:32,580
adversaria what this does is it takes

259
00:10:32,580 --> 00:10:34,440
your default image and then places

260
00:10:34,440 --> 00:10:37,740
procedural noise on top of it fancy word

261
00:10:37,740 --> 00:10:41,339
for random noise in the over top of the

262
00:10:41,339 --> 00:10:43,560
image lightning and darkening pixel by

263
00:10:43,560 --> 00:10:45,899
pixel same kind of technique is used to

264
00:10:45,899 --> 00:10:48,660
create landscapes for video games

265
00:10:48,660 --> 00:10:50,339
is adjustable you can see that

266
00:10:50,339 --> 00:10:52,500
originally the system identified it as a

267
00:10:52,500 --> 00:10:54,420
screwdriver once the noise was created

268
00:10:54,420 --> 00:10:56,519
and injected and identified it as a

269
00:10:56,519 --> 00:10:59,339
quill which isn't that impressive

270
00:10:59,339 --> 00:11:01,860
until you see it in real life

271
00:11:01,860 --> 00:11:04,980
obviously far left this is not my faith

272
00:11:04,980 --> 00:11:07,620
this is me it's identifying that it's a

273
00:11:07,620 --> 00:11:10,019
suit right not a face but we'll we'll

274
00:11:10,019 --> 00:11:12,060
just use that as a placeholder and then

275
00:11:12,060 --> 00:11:13,800
as I increase because you can increase

276
00:11:13,800 --> 00:11:16,380
the protection I I've been identified as

277
00:11:16,380 --> 00:11:20,040
wearing chain mail possibly corn and my

278
00:11:20,040 --> 00:11:22,019
personal favorite I like to think it's

279
00:11:22,019 --> 00:11:24,000
that I'm wearing a turtle but maybe you

280
00:11:24,000 --> 00:11:26,579
thought it was a turtle either way as

281
00:11:26,579 --> 00:11:29,220
you can see it becomes less usable over

282
00:11:29,220 --> 00:11:32,579
time right still fascinating and it's

283
00:11:32,579 --> 00:11:34,560
kind of nice because it's super fast

284
00:11:34,560 --> 00:11:37,260
you're just laying noise over top

285
00:11:37,260 --> 00:11:39,660
um it's already in a mobile format so

286
00:11:39,660 --> 00:11:41,820
easily corruptable Open Source by the

287
00:11:41,820 --> 00:11:44,339
way is it Dynamic yeah you can do it

288
00:11:44,339 --> 00:11:46,079
picture by picture you can generate new

289
00:11:46,079 --> 00:11:49,140
noise for every photo is it transparent

290
00:11:49,140 --> 00:11:51,959
sort of I put yes if you don't dial it

291
00:11:51,959 --> 00:11:53,339
way up and make me look like a turtle

292
00:11:53,339 --> 00:11:55,980
then you're probably in business and

293
00:11:55,980 --> 00:11:57,600
again it's that detection is there a

294
00:11:57,600 --> 00:11:59,579
face is there not a face not so much the

295
00:11:59,579 --> 00:12:03,180
matching matchy face to face technique

296
00:12:03,180 --> 00:12:05,040
now we're into the more sophisticated

297
00:12:05,040 --> 00:12:08,160
stuff uh I call this cloaked poisoning

298
00:12:08,160 --> 00:12:10,079
because it's easier to understand if I

299
00:12:10,079 --> 00:12:12,899
use that phrasing there were two uh

300
00:12:12,899 --> 00:12:14,940
academic papers and pieces that came out

301
00:12:14,940 --> 00:12:18,000
near about the same time uh in 2020 Fox

302
00:12:18,000 --> 00:12:20,339
and Loki at a different academic

303
00:12:20,339 --> 00:12:22,620
institutions the idea here is you would

304
00:12:22,620 --> 00:12:25,440
take your original photo take a stock of

305
00:12:25,440 --> 00:12:27,180
photos and pick the one that doesn't

306
00:12:27,180 --> 00:12:30,660
look like you uh mathematically and then

307
00:12:30,660 --> 00:12:32,880
it would kind of combine the feature set

308
00:12:32,880 --> 00:12:35,839
so that your original photo was modified

309
00:12:35,839 --> 00:12:39,240
slightly but hopefully not enough that

310
00:12:39,240 --> 00:12:41,519
enough to thwart facial recognition but

311
00:12:41,519 --> 00:12:43,079
not enough that it didn't look like you

312
00:12:43,079 --> 00:12:45,540
and then it would be put out into the

313
00:12:45,540 --> 00:12:47,399
wild the idea being these commercial

314
00:12:47,399 --> 00:12:49,500
systems would pick it up enter their

315
00:12:49,500 --> 00:12:52,500
database and be poisoned by their

316
00:12:52,500 --> 00:12:54,720
training data and as a result when the

317
00:12:54,720 --> 00:12:57,120
original say a video whatever else came

318
00:12:57,120 --> 00:12:59,339
back out it would do recognition on you

319
00:12:59,339 --> 00:13:01,380
and it would still identify your face

320
00:13:01,380 --> 00:13:04,860
but it would misidentify who you were

321
00:13:04,860 --> 00:13:07,320
sounds kind of starting to be a little

322
00:13:07,320 --> 00:13:09,300
more ideal what we're looking for

323
00:13:09,300 --> 00:13:11,700
a couple things this is the more you

324
00:13:11,700 --> 00:13:12,300
know

325
00:13:12,300 --> 00:13:14,220
the piece the graphic from the academic

326
00:13:14,220 --> 00:13:16,440
paper they used a loss function

327
00:13:16,440 --> 00:13:19,079
called structural dissimilarity index

328
00:13:19,079 --> 00:13:22,380
basically it's trying to minimize uh how

329
00:13:22,380 --> 00:13:23,720
how

330
00:13:23,720 --> 00:13:26,399
the minimize the amount it can recognize

331
00:13:26,399 --> 00:13:29,459
you with a commercial system but make it

332
00:13:29,459 --> 00:13:31,980
maximally usable things you would show

333
00:13:31,980 --> 00:13:34,200
other people it was a Mac and Windows

334
00:13:34,200 --> 00:13:36,180
application it was open source they have

335
00:13:36,180 --> 00:13:39,240
it for M1 Mac silicon at this point it's

336
00:13:39,240 --> 00:13:42,060
pretty great but to run it on a couple

337
00:13:42,060 --> 00:13:44,579
images took on the order of two to five

338
00:13:44,579 --> 00:13:47,100
minutes so if our goal is to give people

339
00:13:47,100 --> 00:13:49,560
the same experience as face ID

340
00:13:49,560 --> 00:13:51,240
how do you take pictures do you take a

341
00:13:51,240 --> 00:13:52,560
picture and then wait five minutes

342
00:13:52,560 --> 00:13:56,760
before you upload it certainly not right

343
00:13:56,760 --> 00:13:58,200
um

344
00:13:58,200 --> 00:14:02,160
Loki very similar different loss

345
00:14:02,160 --> 00:14:03,959
function this one's learn perceptual

346
00:14:03,959 --> 00:14:06,240
image patch similarity which is why you

347
00:14:06,240 --> 00:14:07,860
see why they abbreviate to lips because

348
00:14:07,860 --> 00:14:09,540
that's just fun

349
00:14:09,540 --> 00:14:11,700
um it comes it comprehends the entire

350
00:14:11,700 --> 00:14:13,560
pipeline which is slightly different

351
00:14:13,560 --> 00:14:15,839
than Fox Fox was doing mainly just

352
00:14:15,839 --> 00:14:18,480
classification this one the way the math

353
00:14:18,480 --> 00:14:20,579
works out it takes in to both of those

354
00:14:20,579 --> 00:14:22,680
detection and classification

355
00:14:22,680 --> 00:14:25,079
think about this one it's a hosted web

356
00:14:25,079 --> 00:14:27,540
service it's not open source you submit

357
00:14:27,540 --> 00:14:30,480
your picture you submit your pictures to

358
00:14:30,480 --> 00:14:32,940
a web service and then they email you

359
00:14:32,940 --> 00:14:33,899
back

360
00:14:33,899 --> 00:14:35,519
the results

361
00:14:35,519 --> 00:14:38,160
so there's something there what does it

362
00:14:38,160 --> 00:14:39,180
look like

363
00:14:39,180 --> 00:14:42,839
again using this person as a sample far

364
00:14:42,839 --> 00:14:44,880
left you can see that my original photo

365
00:14:44,880 --> 00:14:46,800
is there in the same park same outfit

366
00:14:46,800 --> 00:14:49,260
conveniently as we dial up the

367
00:14:49,260 --> 00:14:50,279
protection

368
00:14:50,279 --> 00:14:52,560
I start to see some artifacts but by the

369
00:14:52,560 --> 00:14:55,500
time you get to the high protection over

370
00:14:55,500 --> 00:14:57,540
here it kind of starts to look like

371
00:14:57,540 --> 00:14:59,279
someone has beaten me about The Head and

372
00:14:59,279 --> 00:15:01,740
Shoulders with the lead pipe right if I

373
00:15:01,740 --> 00:15:03,300
put this out on social media I'm going

374
00:15:03,300 --> 00:15:05,160
to get a phone call from my mother with

375
00:15:05,160 --> 00:15:07,860
about seven minutes asking me if I'm

376
00:15:07,860 --> 00:15:08,820
okay

377
00:15:08,820 --> 00:15:11,420
so there's a balance to be had here

378
00:15:11,420 --> 00:15:13,680
Effectiveness which we haven't done as

379
00:15:13,680 --> 00:15:15,660
much of or talked about but it's also

380
00:15:15,660 --> 00:15:17,100
important right because one of the

381
00:15:17,100 --> 00:15:18,540
things you want to know is if I'm

382
00:15:18,540 --> 00:15:21,300
applying these protections how much am I

383
00:15:21,300 --> 00:15:23,399
really protected at least in the moment

384
00:15:23,399 --> 00:15:26,339
right so you can see the fox protection

385
00:15:26,339 --> 00:15:27,959
scheme right there as reported by

386
00:15:27,959 --> 00:15:30,120
authors themselves they test against the

387
00:15:30,120 --> 00:15:32,040
commercially available systems

388
00:15:32,040 --> 00:15:33,660
you know that they did really well

389
00:15:33,660 --> 00:15:37,079
against Azure until they didn't in

390
00:15:37,079 --> 00:15:39,480
January of 2021 Azure did something

391
00:15:39,480 --> 00:15:40,920
they're not really sure what that

392
00:15:40,920 --> 00:15:43,199
improved how Azure performed against

393
00:15:43,199 --> 00:15:45,180
their protection system so they went

394
00:15:45,180 --> 00:15:46,800
back and rewrote some algorithms and and

395
00:15:46,800 --> 00:15:49,380
got a lot of that protection back uh

396
00:15:49,380 --> 00:15:51,420
Loki I like their reporting better

397
00:15:51,420 --> 00:15:53,279
because the reporting against the top

398
00:15:53,279 --> 00:15:55,500
end results remember I said the name of

399
00:15:55,500 --> 00:15:57,180
the game is to not be in that top five

400
00:15:57,180 --> 00:16:00,300
top ten top 50 results that's what's

401
00:16:00,300 --> 00:16:02,699
going on here now you also note that

402
00:16:02,699 --> 00:16:04,199
Loki is throwing a little bit of shade

403
00:16:04,199 --> 00:16:07,560
on Fox here saying that well they did an

404
00:16:07,560 --> 00:16:11,040
okay job but Loki does a lot better

405
00:16:11,040 --> 00:16:12,360
if you're thinking about these

406
00:16:12,360 --> 00:16:15,420
approaches they're not fast I it's

407
00:16:15,420 --> 00:16:17,279
really hard to tell how long Loki takes

408
00:16:17,279 --> 00:16:19,019
but the email doesn't come back

409
00:16:19,019 --> 00:16:22,019
you know in a 30 seconds time frame

410
00:16:22,019 --> 00:16:24,060
they're not on mobile

411
00:16:24,060 --> 00:16:25,800
they are Dynamic they're picture by

412
00:16:25,800 --> 00:16:28,320
picture uh they're transparent for the

413
00:16:28,320 --> 00:16:29,699
most part as long as you don't turn the

414
00:16:29,699 --> 00:16:32,880
protection up to high and depending on

415
00:16:32,880 --> 00:16:34,380
which one they're protective with both

416
00:16:34,380 --> 00:16:37,620
or just classification both of these had

417
00:16:37,620 --> 00:16:40,019
a lot of publicity New York Times wired

418
00:16:40,019 --> 00:16:43,740
all that kind of stuff back in 2020.

419
00:16:43,740 --> 00:16:47,639
uh there's a one last uh uh research

420
00:16:47,639 --> 00:16:50,100
paper of note and this was called one

421
00:16:50,100 --> 00:16:52,380
person one mask it's come out in this

422
00:16:52,380 --> 00:16:55,259
last year or so this is actually pretty

423
00:16:55,259 --> 00:16:57,180
fascinating it's kind of using that

424
00:16:57,180 --> 00:17:01,440
procedural noise concept except uh

425
00:17:01,440 --> 00:17:03,300
uh running some training on it so that's

426
00:17:03,300 --> 00:17:07,020
customized for your face and so it's a

427
00:17:07,020 --> 00:17:09,179
procedural noise that shifts the feature

428
00:17:09,179 --> 00:17:11,939
set away from you specifically and then

429
00:17:11,939 --> 00:17:13,619
you would just apply that mask to any

430
00:17:13,619 --> 00:17:16,020
photo after that and without any

431
00:17:16,020 --> 00:17:17,819
training or poisoning or anything else

432
00:17:17,819 --> 00:17:19,980
of these commercial systems the idea is

433
00:17:19,980 --> 00:17:23,160
it would misidentify you this is more of

434
00:17:23,160 --> 00:17:26,520
a class wise protection and you can see

435
00:17:26,520 --> 00:17:27,900
them call that out in other words

436
00:17:27,900 --> 00:17:30,840
instead of image by image protection

437
00:17:30,840 --> 00:17:34,020
this is just a a set of noise you would

438
00:17:34,020 --> 00:17:36,120
put over any picture that you put out

439
00:17:36,120 --> 00:17:36,900
there

440
00:17:36,900 --> 00:17:39,539
advantages and disadvantages right as

441
00:17:39,539 --> 00:17:41,160
always if you're being pursued by a

442
00:17:41,160 --> 00:17:42,419
nation state

443
00:17:42,419 --> 00:17:44,880
I wouldn't trust any of this right

444
00:17:44,880 --> 00:17:47,160
um your mileage may vary if you're a

445
00:17:47,160 --> 00:17:49,919
normal person ish you're going to get

446
00:17:49,919 --> 00:17:53,100
some routine 33 to 66 percent depending

447
00:17:53,100 --> 00:17:55,559
on the day and the picture and and these

448
00:17:55,559 --> 00:17:58,740
types of things the cool part about this

449
00:17:58,740 --> 00:18:01,880
uh approach is it starts to use Pi torch

450
00:18:01,880 --> 00:18:04,919
which means you can actually do it

451
00:18:04,919 --> 00:18:06,960
quickly enough and apply this procedural

452
00:18:06,960 --> 00:18:09,960
noise mask quickly enough to inject in

453
00:18:09,960 --> 00:18:12,480
front of your face in video on a frame

454
00:18:12,480 --> 00:18:14,400
by frame in a near real-time approach

455
00:18:14,400 --> 00:18:16,380
because that's going to be the next step

456
00:18:16,380 --> 00:18:19,020
going back to our chart

457
00:18:19,020 --> 00:18:22,200
um yes it's fast uh no it's not on

458
00:18:22,200 --> 00:18:25,200
mobile I'm working on that part it's

459
00:18:25,200 --> 00:18:27,480
dynamic in a way it's class wise not

460
00:18:27,480 --> 00:18:31,260
image by image it is transparent it's

461
00:18:31,260 --> 00:18:34,440
not really as even half as intrusive as

462
00:18:34,440 --> 00:18:36,480
what we saw with Fox and low-key it's

463
00:18:36,480 --> 00:18:38,220
also not quite as protective as we saw

464
00:18:38,220 --> 00:18:40,679
on the stats but it does try to disturb

465
00:18:40,679 --> 00:18:44,220
uh the pathways the detection and the

466
00:18:44,220 --> 00:18:46,140
classification

467
00:18:46,140 --> 00:18:48,660
you'll note there's one more column and

468
00:18:48,660 --> 00:18:50,520
you'll note that most leads don't have

469
00:18:50,520 --> 00:18:54,480
mobile options in 2019 I started playing

470
00:18:54,480 --> 00:18:57,600
with this stuff and in 2028 Fox and Loki

471
00:18:57,600 --> 00:19:00,120
came about and so I tried to incorporate

472
00:19:00,120 --> 00:19:03,000
those into a mobile app kind of proof of

473
00:19:03,000 --> 00:19:05,120
concept just to see what was possible

474
00:19:05,120 --> 00:19:07,919
limited by a couple things there is no

475
00:19:07,919 --> 00:19:10,500
training for tensorflow Lite or Pi torch

476
00:19:10,500 --> 00:19:12,059
equivalent machine Learning Systems

477
00:19:12,059 --> 00:19:14,880
there's no training on device or at

478
00:19:14,880 --> 00:19:16,740
least it wasn't at that point with

479
00:19:16,740 --> 00:19:18,720
tensorflow you can now do it on device

480
00:19:18,720 --> 00:19:21,120
which means any training any protection

481
00:19:21,120 --> 00:19:23,340
generation those types of things would

482
00:19:23,340 --> 00:19:26,520
have to be done off the device so I did

483
00:19:26,520 --> 00:19:28,919
kind of what I could with the technology

484
00:19:28,919 --> 00:19:30,840
we had which was

485
00:19:30,840 --> 00:19:32,700
um two things one was fast style

486
00:19:32,700 --> 00:19:34,140
transfer which you see here at the top

487
00:19:34,140 --> 00:19:37,200
basically you take an image and then you

488
00:19:37,200 --> 00:19:38,940
take a style you want to modify your

489
00:19:38,940 --> 00:19:40,980
image into and then you decide how much

490
00:19:40,980 --> 00:19:42,360
influence you want for the original

491
00:19:42,360 --> 00:19:45,179
content versus the style to have again

492
00:19:45,179 --> 00:19:49,080
if you look at some of these uh these uh

493
00:19:49,080 --> 00:19:51,419
examples they get kind of horrific as

494
00:19:51,419 --> 00:19:53,700
well and unusable the other one that was

495
00:19:53,700 --> 00:19:55,200
more interesting was the procedural

496
00:19:55,200 --> 00:19:56,220
noise

497
00:19:56,220 --> 00:19:58,620
generating that and placing it over top

498
00:19:58,620 --> 00:20:01,140
and so this is what the general flow of

499
00:20:01,140 --> 00:20:02,520
that open source app that's out on

500
00:20:02,520 --> 00:20:06,720
GitHub still basically applies a style

501
00:20:06,720 --> 00:20:09,299
change to your image puts procedural

502
00:20:09,299 --> 00:20:11,880
noise over top of that and then checks

503
00:20:11,880 --> 00:20:15,120
to see if it can detect a face or not I

504
00:20:15,120 --> 00:20:16,580
didn't have time to put in

505
00:20:16,580 --> 00:20:18,960
classification comparison against a

506
00:20:18,960 --> 00:20:21,240
known face on the mobile device itself

507
00:20:21,240 --> 00:20:23,340
but after it does that check to say do I

508
00:20:23,340 --> 00:20:25,200
see a face or not it goes back and

509
00:20:25,200 --> 00:20:28,740
allows you to to modify your approach

510
00:20:28,740 --> 00:20:31,080
more or less protection and then saves

511
00:20:31,080 --> 00:20:33,000
to a dedicated album so they can upload

512
00:20:33,000 --> 00:20:35,520
it later on the whole idea here is to

513
00:20:35,520 --> 00:20:38,640
give people agency and to make it in as

514
00:20:38,640 --> 00:20:40,679
much of the normal process that they go

515
00:20:40,679 --> 00:20:43,380
through as possible

516
00:20:43,380 --> 00:20:45,720
um there's a demo I can show you some

517
00:20:45,720 --> 00:20:47,220
screenshots I'll blow through this demo

518
00:20:47,220 --> 00:20:49,559
it's an area demo and nobody has time

519
00:20:49,559 --> 00:20:51,840
for that

520
00:20:51,840 --> 00:20:55,620
so like I said I'm not a designer and if

521
00:20:55,620 --> 00:20:56,700
you notice that

522
00:20:56,700 --> 00:20:58,799
um but basically either from the camera

523
00:20:58,799 --> 00:21:01,799
roll or in this case from an image you

524
00:21:01,799 --> 00:21:04,500
take oh look it was the same day

525
00:21:04,500 --> 00:21:06,840
um it takes the picture

526
00:21:06,840 --> 00:21:10,699
then after you choose to use it

527
00:21:10,860 --> 00:21:13,260
it shrinks it down into a slightly

528
00:21:13,260 --> 00:21:15,000
smaller format most of these approaches

529
00:21:15,000 --> 00:21:18,900
uh need a 384 by 384 image before it can

530
00:21:18,900 --> 00:21:21,679
scale it back up

531
00:21:21,900 --> 00:21:23,820
yeah and this is why you don't do this

532
00:21:23,820 --> 00:21:26,000
part

533
00:21:30,840 --> 00:21:33,480
okay and then you choose the style

534
00:21:33,480 --> 00:21:36,720
classic art examples here

535
00:21:36,720 --> 00:21:38,760
once you apply it well actually before

536
00:21:38,760 --> 00:21:40,919
you apply it you can do a detect face on

537
00:21:40,919 --> 00:21:42,780
the mobile app you can see whether or

538
00:21:42,780 --> 00:21:44,640
not it identifies a face and some of the

539
00:21:44,640 --> 00:21:46,740
features

540
00:21:46,740 --> 00:21:49,140
and then after you apply

541
00:21:49,140 --> 00:21:51,179
obviously if you jack it way up it's not

542
00:21:51,179 --> 00:21:52,740
going to find a face at all but you can

543
00:21:52,740 --> 00:21:55,380
manipulate it until it's an appropriate

544
00:21:55,380 --> 00:21:57,659
level of protection and then you can

545
00:21:57,659 --> 00:21:59,580
save it off

546
00:21:59,580 --> 00:22:02,460
to a dedicated photo album that on the

547
00:22:02,460 --> 00:22:06,299
device and so that's the general idea

548
00:22:06,299 --> 00:22:09,600
so ideally all yeses in this last hem

549
00:22:09,600 --> 00:22:11,159
column I'm kind of hesitant to say that

550
00:22:11,159 --> 00:22:13,860
I think once uh one person one Mass gets

551
00:22:13,860 --> 00:22:16,559
in I think it would be a lot more viable

552
00:22:16,559 --> 00:22:19,020
you should be asking yourself this at

553
00:22:19,020 --> 00:22:20,880
this point right is this practical would

554
00:22:20,880 --> 00:22:22,860
anybody really use this

555
00:22:22,860 --> 00:22:26,520
I'd say yeah no one yes yes and no like

556
00:22:26,520 --> 00:22:27,960
in other words I've got lots of friends

557
00:22:27,960 --> 00:22:29,340
if you ever ask them do you want

558
00:22:29,340 --> 00:22:31,740
something like this they say you bet I

559
00:22:31,740 --> 00:22:34,440
do right but they're not going to go out

560
00:22:34,440 --> 00:22:37,200
of their way to take extra steps

561
00:22:37,200 --> 00:22:39,539
and as well the technology only is just

562
00:22:39,539 --> 00:22:41,280
arriving on mobile to do things like Fox

563
00:22:41,280 --> 00:22:44,820
and Loki and one person one mask

564
00:22:44,820 --> 00:22:46,919
um so I think it's coming but I think

565
00:22:46,919 --> 00:22:49,080
it's more to raise awareness and to

566
00:22:49,080 --> 00:22:51,000
Grant people agency and that's what this

567
00:22:51,000 --> 00:22:53,520
is all about right protecting privacy

568
00:22:53,520 --> 00:22:55,620
especially a biometric information is a

569
00:22:55,620 --> 00:22:58,740
team sport Enterprises governments and

570
00:22:58,740 --> 00:23:01,200
individuals have a role to play and it's

571
00:23:01,200 --> 00:23:03,299
when we all play that together

572
00:23:03,299 --> 00:23:06,059
that we can be like Nelson to throw back

573
00:23:06,059 --> 00:23:07,919
from the beginning we can raise our flag

574
00:23:07,919 --> 00:23:09,659
and say look everyone has a

575
00:23:09,659 --> 00:23:12,360
responsibility in this process

576
00:23:12,360 --> 00:23:14,600
thank you

577
00:23:14,600 --> 00:23:16,919
[Applause]

578
00:23:16,919 --> 00:23:18,360
questions

579
00:23:18,360 --> 00:23:21,799
concerns complaints

580
00:23:25,880 --> 00:23:28,679
the photos that we've seen so far from

581
00:23:28,679 --> 00:23:30,900
your slides they looked very artifacty

582
00:23:30,900 --> 00:23:34,260
even with the lowest settings and I know

583
00:23:34,260 --> 00:23:36,720
normal people don't want to appear like

584
00:23:36,720 --> 00:23:38,280
it on social media they want to look

585
00:23:38,280 --> 00:23:40,980
good to their friends and family and so

586
00:23:40,980 --> 00:23:43,260
it makes the the usability of a platform

587
00:23:43,260 --> 00:23:44,580
like this questionable for the General

588
00:23:44,580 --> 00:23:46,260
Public

589
00:23:46,260 --> 00:23:48,600
my concern is do you think it will ever

590
00:23:48,600 --> 00:23:50,700
become usable for the general public who

591
00:23:50,700 --> 00:23:53,400
do want to preserve their looks while

592
00:23:53,400 --> 00:23:56,640
also having some privacy and agency

593
00:23:56,640 --> 00:23:58,919
I think as a technology I think it'll be

594
00:23:58,919 --> 00:24:00,900
a cat and mouse kind of thing in other

595
00:24:00,900 --> 00:24:02,880
words I think that what I've seen is

596
00:24:02,880 --> 00:24:04,440
they get better the algorithms get

597
00:24:04,440 --> 00:24:06,659
better and as a technology especially on

598
00:24:06,659 --> 00:24:08,460
device gets better I think that one

599
00:24:08,460 --> 00:24:10,440
person one mask those types of

600
00:24:10,440 --> 00:24:11,940
techniques where it's protecting you as

601
00:24:11,940 --> 00:24:14,820
a class will be better I think it's too

602
00:24:14,820 --> 00:24:17,299
costly to to be

603
00:24:17,299 --> 00:24:20,700
more refined in terms of I agree with

604
00:24:20,700 --> 00:24:22,080
you if you look really closely you can

605
00:24:22,080 --> 00:24:23,940
see artifacts right it depends on what

606
00:24:23,940 --> 00:24:26,760
the use case is right especially I think

607
00:24:26,760 --> 00:24:28,020
these days with the trending to video

608
00:24:28,020 --> 00:24:29,880
that's going to be especially key and

609
00:24:29,880 --> 00:24:33,440
we're not we're not quite there yet

610
00:24:40,440 --> 00:24:42,299
hi there thank you for the talk

611
00:24:42,299 --> 00:24:44,460
um are there any retroactive steps you

612
00:24:44,460 --> 00:24:46,080
can take if your facial data has already

613
00:24:46,080 --> 00:24:48,840
been scraped

614
00:24:48,840 --> 00:24:52,760
everyone in this room is in trouble

615
00:24:53,520 --> 00:24:56,340
um no not particularly right what you're

616
00:24:56,340 --> 00:24:58,799
trying to do is you could poison the

617
00:24:58,799 --> 00:25:01,380
cash of the data it has on you but it

618
00:25:01,380 --> 00:25:03,000
depends on how much is already out there

619
00:25:03,000 --> 00:25:06,000
right you are already most likely you

620
00:25:06,000 --> 00:25:07,260
were already in a clear view database

621
00:25:07,260 --> 00:25:09,539
and you're already in a pemize I know I

622
00:25:09,539 --> 00:25:11,700
am Pima is database

623
00:25:11,700 --> 00:25:14,400
um so that that's that's an ongoing

624
00:25:14,400 --> 00:25:16,740
challenge right now there's also the

625
00:25:16,740 --> 00:25:18,240
side effect that if I take a picture or

626
00:25:18,240 --> 00:25:20,880
a video and I put it up on someplace

627
00:25:20,880 --> 00:25:22,620
online

628
00:25:22,620 --> 00:25:25,679
you saw the local park behind me if you

629
00:25:25,679 --> 00:25:27,000
were good enough at open source

630
00:25:27,000 --> 00:25:29,279
intelligence you would know where I live

631
00:25:29,279 --> 00:25:31,140
even if you didn't know me right so

632
00:25:31,140 --> 00:25:32,700
there's a there are side applications

633
00:25:32,700 --> 00:25:34,620
besides just not being identified with

634
00:25:34,620 --> 00:25:36,840
the law enforcement if you're if you're

635
00:25:36,840 --> 00:25:38,400
being stalked or being pursued or

636
00:25:38,400 --> 00:25:40,020
otherwise harassed there may be side

637
00:25:40,020 --> 00:25:42,000
benefits as well to privacy in the

638
00:25:42,000 --> 00:25:44,340
moment or as you upload new content it's

639
00:25:44,340 --> 00:25:47,059
a great question though

640
00:25:51,000 --> 00:25:52,980
you don't have any more time yeah well

641
00:25:52,980 --> 00:25:55,679
I'll be around uh so thanks y'all have a

642
00:25:55,679 --> 00:25:57,919
good day

