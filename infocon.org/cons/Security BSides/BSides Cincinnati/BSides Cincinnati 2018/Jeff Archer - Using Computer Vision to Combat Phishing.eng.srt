1
00:00:00,000 --> 00:00:05,759
join the conversation tweet us at b-side

2
00:00:02,639 --> 00:00:08,150
cincy the presentation will begin

3
00:00:05,759 --> 00:00:08,150
shortly

4
00:00:12,110 --> 00:00:24,920
besides Cincinnati 2018 is sponsored by

5
00:00:16,079 --> 00:00:27,919
GE Aviation no starch press CBTs

6
00:00:24,920 --> 00:00:27,920
cyber-ark

7
00:00:29,170 --> 00:00:41,610
Booz Allen Hamilton Darkrai no security

8
00:00:34,650 --> 00:00:41,610
and the game RSA

9
00:00:41,840 --> 00:00:49,730
and US Bank join the conversation

10
00:00:46,640 --> 00:00:53,500
tweet us at b-side cincy the

11
00:00:49,730 --> 00:00:53,500
presentation will begin shortly

12
00:00:57,460 --> 00:01:10,270
besides Cincinnati 2018 is sponsored by

13
00:01:01,430 --> 00:01:13,270
GE Aviation no starch press CBTs

14
00:01:10,270 --> 00:01:13,270
cyber-ark

15
00:01:14,560 --> 00:01:26,940
Booz Allen Hamilton dark rhino security

16
00:01:19,920 --> 00:01:26,940
and the game RSA

17
00:01:27,260 --> 00:01:35,060
and US Bank join the conversation

18
00:01:32,000 --> 00:01:38,830
tweet us at b-side cincy the

19
00:01:35,060 --> 00:01:38,830
presentation will begin shortly

20
00:01:42,820 --> 00:01:55,630
besides Cincinnati 2018 is sponsored by

21
00:01:46,760 --> 00:01:58,630
GE Aviation no starch press CBTs

22
00:01:55,630 --> 00:01:58,630
cyber-ark

23
00:01:59,860 --> 00:02:12,300
Booz Allen Hamilton Darkrai no security

24
00:02:05,280 --> 00:02:12,300
and the game RSA

25
00:02:12,550 --> 00:02:21,490
and US Bank join the conversation tweet

26
00:02:17,680 --> 00:02:24,180
us at b-side cincy the presentation will

27
00:02:21,490 --> 00:02:24,180
begin shortly

28
00:02:28,170 --> 00:02:40,980
besides Cincinnati 2018 is sponsored by

29
00:02:32,110 --> 00:02:43,980
GE Aviation no starch press CBTs

30
00:02:40,980 --> 00:02:43,980
cyber-ark

31
00:02:45,200 --> 00:02:57,640
Booz Allen Hamilton Darkrai no security

32
00:02:50,590 --> 00:02:57,640
and the game RSA

33
00:02:57,930 --> 00:03:09,689
and US bank all right everybody we get

34
00:03:08,159 --> 00:03:11,939
started with the three o'clock talk here

35
00:03:09,689 --> 00:03:13,890
so I'd like to welcome Jeff Archer to

36
00:03:11,939 --> 00:03:16,469
the stage talk to us about officialized

37
00:03:13,890 --> 00:03:21,298
and some computer vision software he's

38
00:03:16,469 --> 00:03:26,129
been working on so take away Jeff thank

39
00:03:21,299 --> 00:03:27,209
you thank you guys so much and the first

40
00:03:26,129 --> 00:03:28,590
thing I want to do when I come up here

41
00:03:27,209 --> 00:03:30,269
thank you guys so much for coming out

42
00:03:28,590 --> 00:03:32,340
here as you know it's our five-year

43
00:03:30,269 --> 00:03:34,590
anniversary this is a fantastic turnout

44
00:03:32,340 --> 00:03:36,299
for the five-year anniversary the

45
00:03:34,590 --> 00:03:40,159
speakers we've had today have been

46
00:03:36,299 --> 00:03:42,299
phenomenal right up to about now and I

47
00:03:40,159 --> 00:03:43,620
really really appreciate you guys coming

48
00:03:42,299 --> 00:03:45,989
out and supporting this it's always

49
00:03:43,620 --> 00:03:48,419
great to get the community out here so

50
00:03:45,989 --> 00:03:52,049
as mr. Omer said my name is Jeff Archer

51
00:03:48,419 --> 00:03:54,870
I work for I work for a GE Aviation's

52
00:03:52,049 --> 00:03:56,489
cyber Intel team don't have an about me

53
00:03:54,870 --> 00:03:58,349
slide because honestly it probably

54
00:03:56,489 --> 00:04:00,689
wouldn't amount to a large slide I've

55
00:03:58,349 --> 00:04:02,698
been with GE cyber Intel for about two

56
00:04:00,689 --> 00:04:05,790
years now three years if you count a

57
00:04:02,699 --> 00:04:07,650
contracting year and been in security in

58
00:04:05,790 --> 00:04:09,388
general for about five years on the

59
00:04:07,650 --> 00:04:10,979
military side I've been in signal and

60
00:04:09,389 --> 00:04:13,409
cyber and that's pretty much all you

61
00:04:10,979 --> 00:04:14,819
need to know about me today though I

62
00:04:13,409 --> 00:04:16,168
want to talk about one of the more

63
00:04:14,819 --> 00:04:19,199
recent projects we've been working on

64
00:04:16,168 --> 00:04:22,889
called visualize like Danny we also like

65
00:04:19,199 --> 00:04:24,270
to make up fun words visualizes a

66
00:04:22,889 --> 00:04:26,909
computer like Joshua it's a computer

67
00:04:24,270 --> 00:04:29,008
vision tool that were I hesitate to even

68
00:04:26,909 --> 00:04:31,440
call it a beta at this point because we

69
00:04:29,009 --> 00:04:34,050
just began hard core development on it

70
00:04:31,440 --> 00:04:35,580
at the beginning of this year so take

71
00:04:34,050 --> 00:04:37,080
that caveat throughout this talk this is

72
00:04:35,580 --> 00:04:39,960
something that we're working on we have

73
00:04:37,080 --> 00:04:41,400
a long road ahead down the road this is

74
00:04:39,960 --> 00:04:43,229
something we definitely want to if

75
00:04:41,400 --> 00:04:44,698
possible still going through the legal

76
00:04:43,229 --> 00:04:46,830
proceedings and getting the blessing

77
00:04:44,699 --> 00:04:48,479
from them open source to the community

78
00:04:46,830 --> 00:04:51,210
and open it up to well there's a couple

79
00:04:48,479 --> 00:04:52,349
startups doing this kind of thing where

80
00:04:51,210 --> 00:04:54,750
we build this from the ground up and

81
00:04:52,349 --> 00:04:56,599
we'd really like to get feedback and

82
00:04:54,750 --> 00:04:58,800
other people working on it as well

83
00:04:56,599 --> 00:05:00,539
before I get into the details of the

84
00:04:58,800 --> 00:05:03,090
tool though I wanted to kind of talk

85
00:05:00,539 --> 00:05:06,120
about the impetus of this idea this is

86
00:05:03,090 --> 00:05:08,489
one of those rare times as a developer a

87
00:05:06,120 --> 00:05:11,070
rare awesome times they have this crazy

88
00:05:08,490 --> 00:05:12,860
idea and it turns into a reality

89
00:05:11,070 --> 00:05:15,990
and sometimes it's beyond what you ever

90
00:05:12,860 --> 00:05:17,970
imagined it would be so talking about

91
00:05:15,990 --> 00:05:19,950
the impetus for this idea where this

92
00:05:17,970 --> 00:05:22,350
came from there are two primary sources

93
00:05:19,950 --> 00:05:25,500
of inspiration and the first one was

94
00:05:22,350 --> 00:05:27,720
this graph here now I've read acted a

95
00:05:25,500 --> 00:05:30,120
lot in this graph but to give you some

96
00:05:27,720 --> 00:05:32,220
context to color this in a bit you're

97
00:05:30,120 --> 00:05:34,590
gonna see a percentage of fishing events

98
00:05:32,220 --> 00:05:36,660
over a year-long period I won't say

99
00:05:34,590 --> 00:05:38,849
which year and this is not just de

100
00:05:36,660 --> 00:05:41,790
aviación but this is GE all the

101
00:05:38,850 --> 00:05:43,620
businesses and this is not all the

102
00:05:41,790 --> 00:05:45,120
emails and fish we have coming in but

103
00:05:43,620 --> 00:05:47,220
this is what made it through the first

104
00:05:45,120 --> 00:05:49,560
layer defense into our detect and

105
00:05:47,220 --> 00:05:51,740
incident response team who have - it's

106
00:05:49,560 --> 00:05:54,840
humans actually analyzing these alerts

107
00:05:51,740 --> 00:05:58,530
so to give you an idea of our volume

108
00:05:54,840 --> 00:06:00,570
here number one that says geo-targeting

109
00:05:58,530 --> 00:06:02,099
so fish that are targeting employees in

110
00:06:00,570 --> 00:06:06,349
the specific region of the world

111
00:06:02,100 --> 00:06:10,470
that's a small point zero six percent

112
00:06:06,350 --> 00:06:14,970
office macros point zero nine malware

113
00:06:10,470 --> 00:06:17,670
droppers spam java malware crime where b

114
00:06:14,970 --> 00:06:20,610
ec or business email kept compromised

115
00:06:17,670 --> 00:06:22,800
that's where you have a supplier or a

116
00:06:20,610 --> 00:06:25,200
customer who either gets compromised or

117
00:06:22,800 --> 00:06:27,120
they get spoofed and they email your

118
00:06:25,200 --> 00:06:29,219
finance department and they say hey our

119
00:06:27,120 --> 00:06:30,990
bank account has changed all of a sudden

120
00:06:29,220 --> 00:06:32,910
- this bank in nigeria can you please

121
00:06:30,990 --> 00:06:35,400
send that $90,000 to this bank in

122
00:06:32,910 --> 00:06:40,290
nigeria instead and your finance account

123
00:06:35,400 --> 00:06:44,429
does it that's be easy and up to now now

124
00:06:40,290 --> 00:06:46,790
we're up to maybe 1% social engineering

125
00:06:44,430 --> 00:06:48,990
that bumps us up another 2% the volume

126
00:06:46,790 --> 00:06:52,170
malware we do get a lot of malware so

127
00:06:48,990 --> 00:06:54,030
that brings us a 20% but there's the

128
00:06:52,170 --> 00:06:55,740
rest of that hundred percent and that

129
00:06:54,030 --> 00:06:56,969
says right there credential harvesters

130
00:06:55,740 --> 00:06:59,790
for those of you who don't know I'm sure

131
00:06:56,970 --> 00:07:02,430
most everyone in this room does those

132
00:06:59,790 --> 00:07:04,710
are your fake login pages which you know

133
00:07:02,430 --> 00:07:08,310
they try to spoof the Gmail login or the

134
00:07:04,710 --> 00:07:10,469
Adobe login and the users the untrained

135
00:07:08,310 --> 00:07:11,820
eye it's very easy b2c they put their

136
00:07:10,470 --> 00:07:14,820
credentials in and now the attackers

137
00:07:11,820 --> 00:07:18,150
have them it's really frustrating to see

138
00:07:14,820 --> 00:07:20,400
metrics like these working in our room

139
00:07:18,150 --> 00:07:22,169
because for us we have the trained eye

140
00:07:20,400 --> 00:07:23,510
we can spot it a mile away it's very

141
00:07:22,169 --> 00:07:25,039
easy for incident

142
00:07:23,510 --> 00:07:26,930
spots and detecting us to look at these

143
00:07:25,040 --> 00:07:29,030
alerts and see you right off the bat

144
00:07:26,930 --> 00:07:30,710
this is a credential harvester and yet

145
00:07:29,030 --> 00:07:32,960
this is what they're spending all of

146
00:07:30,710 --> 00:07:35,270
their time and energy on when they could

147
00:07:32,960 --> 00:07:38,140
be working on these events over here

148
00:07:35,270 --> 00:07:40,490
which arguably could be more serious

149
00:07:38,140 --> 00:07:42,349
potential harvesters they can be serious

150
00:07:40,490 --> 00:07:43,670
they're the path of least resistance for

151
00:07:42,350 --> 00:07:47,630
a lot of attackers from your script

152
00:07:43,670 --> 00:07:49,730
Kitty's here apts but we knew we needed

153
00:07:47,630 --> 00:07:52,550
a solution because having this talk with

154
00:07:49,730 --> 00:07:53,990
leadership it's not a good talk because

155
00:07:52,550 --> 00:07:56,690
what they hear is we're spending all

156
00:07:53,990 --> 00:07:58,520
this time on these low-level attacks and

157
00:07:56,690 --> 00:08:01,580
any time an executive hears the word

158
00:07:58,520 --> 00:08:03,740
time that immediately equates to money

159
00:08:01,580 --> 00:08:05,240
and then our only solution at that point

160
00:08:03,740 --> 00:08:07,630
when we're having these conversations is

161
00:08:05,240 --> 00:08:09,860
well we could use more headcount and

162
00:08:07,630 --> 00:08:11,120
again all they hear is money and I don't

163
00:08:09,860 --> 00:08:13,070
know if you've seen GE stock price

164
00:08:11,120 --> 00:08:18,050
lately but we don't have either of those

165
00:08:13,070 --> 00:08:20,810
things right now so this list left us in

166
00:08:18,050 --> 00:08:23,480
a little bit of a conundrum we started

167
00:08:20,810 --> 00:08:25,160
exploring some solutions for example you

168
00:08:23,480 --> 00:08:26,360
can take a look at the source code for a

169
00:08:25,160 --> 00:08:28,520
credential reversing paid it's going to

170
00:08:26,360 --> 00:08:30,170
be obviously different than the Gmail

171
00:08:28,520 --> 00:08:31,159
source code sometimes they spoof bits

172
00:08:30,170 --> 00:08:33,440
and pieces but there's gonna be

173
00:08:31,160 --> 00:08:36,229
something in those different the trouble

174
00:08:33,440 --> 00:08:38,270
we ran into it that is stuff like basics

175
00:08:36,229 --> 00:08:40,700
T for encoding the entire page or little

176
00:08:38,270 --> 00:08:42,140
JavaScript tricks for a bunch of

177
00:08:40,700 --> 00:08:43,400
redirects there's a lot of little things

178
00:08:42,140 --> 00:08:45,380
that can interrupt your automated

179
00:08:43,400 --> 00:08:49,220
analysis if you're just pulling the

180
00:08:45,380 --> 00:08:51,380
source code for the page so at this time

181
00:08:49,220 --> 00:08:52,520
we didn't have a solution that comes

182
00:08:51,380 --> 00:08:55,160
with the second source of inspiration

183
00:08:52,520 --> 00:08:57,050
which came a little bit later from a hit

184
00:08:55,160 --> 00:08:59,810
HBO series that I think most people in

185
00:08:57,050 --> 00:09:05,000
this room will be familiar with it's

186
00:08:59,810 --> 00:09:07,670
ready what do what you say if I tell you

187
00:09:05,000 --> 00:09:11,750
there is an app on the mind pass that

188
00:09:07,670 --> 00:09:14,290
part just demo it okay let's start with

189
00:09:11,750 --> 00:09:14,290
a hot dog

190
00:09:18,400 --> 00:09:28,449
[Music]

191
00:09:24,280 --> 00:09:31,100
for the Azad jinyang my beautiful little

192
00:09:28,450 --> 00:09:33,500
Asiatic friend I'm going to buy you the

193
00:09:31,100 --> 00:09:36,380
palapa of your life we will have twelve

194
00:09:33,500 --> 00:09:39,040
posts braided palm leaves you'll never

195
00:09:36,380 --> 00:09:45,460
feel exposed again I'm gonna be rich

196
00:09:39,040 --> 00:09:45,459
Gilfoyle do pizza yes to pizza yeah hey

197
00:09:46,440 --> 00:09:51,670
[Music]

198
00:09:49,500 --> 00:09:56,140
not a hot dog

199
00:09:51,670 --> 00:09:59,020
wait what it's that's it it only does

200
00:09:56,140 --> 00:10:03,520
hot dogs no and a not hot dog

201
00:09:59,020 --> 00:10:06,010
I promise our idea is a little better

202
00:10:03,520 --> 00:10:07,870
than that a little bit but that was good

203
00:10:06,010 --> 00:10:09,010
inspiration so that kind of kicked out

204
00:10:07,870 --> 00:10:11,050
the idea that we're gonna need something

205
00:10:09,010 --> 00:10:12,760
that we can emulate that analysts eyes

206
00:10:11,050 --> 00:10:14,079
those analysts like I said they can see

207
00:10:12,760 --> 00:10:16,360
that from a mile away they can easily

208
00:10:14,080 --> 00:10:18,250
look at a credit officer and know what

209
00:10:16,360 --> 00:10:21,370
they're looking at and so then I started

210
00:10:18,250 --> 00:10:23,830
digging back into open CV Docs and

211
00:10:21,370 --> 00:10:26,320
computer vision research documents I

212
00:10:23,830 --> 00:10:28,180
reached out to dr. Adrian Rose brach you

213
00:10:26,320 --> 00:10:31,690
know him he's on Twitter as a PI image

214
00:10:28,180 --> 00:10:32,979
search written two great books on Python

215
00:10:31,690 --> 00:10:35,170
and computer vision and the machine

216
00:10:32,980 --> 00:10:37,990
learning so digging into all that stuff

217
00:10:35,170 --> 00:10:40,120
I knew that we had a chance of a good

218
00:10:37,990 --> 00:10:43,209
solution if we started working with some

219
00:10:40,120 --> 00:10:44,860
of this computer vision stuff so in

220
00:10:43,209 --> 00:10:46,719
summary visualizes a service that

221
00:10:44,860 --> 00:10:48,790
renders websites through some kind of

222
00:10:46,720 --> 00:10:50,740
anonymization service and we do that

223
00:10:48,790 --> 00:10:52,839
just to prevent any IP leakage for those

224
00:10:50,740 --> 00:10:55,570
who don't know GE owns an entire Class A

225
00:10:52,839 --> 00:10:56,740
so it's very easy to tell when GE is

226
00:10:55,570 --> 00:10:59,380
looking at your stuff

227
00:10:56,740 --> 00:11:01,209
so in order to avoid that we run the

228
00:10:59,380 --> 00:11:03,820
URLs through an anonymous Asian service

229
00:11:01,209 --> 00:11:05,410
we pull back a screenshot and then we

230
00:11:03,820 --> 00:11:07,839
run some computer vision algorithms on

231
00:11:05,410 --> 00:11:09,640
them and make some assessments within

232
00:11:07,839 --> 00:11:10,600
this module automatically to determine

233
00:11:09,640 --> 00:11:15,120
whether the site is going to be

234
00:11:10,600 --> 00:11:15,120
malicious spoofs or benign

235
00:11:15,190 --> 00:11:18,970
and when we came up with this idea we

236
00:11:16,990 --> 00:11:20,889
wanted to make it accessible to the

237
00:11:18,970 --> 00:11:23,199
small companies the companies like GE

238
00:11:20,889 --> 00:11:25,269
the larger companies we wanted to make

239
00:11:23,199 --> 00:11:27,609
something that would stand alone by

240
00:11:25,269 --> 00:11:29,949
itself and also plug in to existing

241
00:11:27,610 --> 00:11:31,810
pipelines for example we already have an

242
00:11:29,949 --> 00:11:33,639
existing pipeline for doing email

243
00:11:31,810 --> 00:11:35,680
detection it's a tool called fish finder

244
00:11:33,639 --> 00:11:37,600
a little hard to see but in a nutshell

245
00:11:35,680 --> 00:11:40,719
what fish finder does is we essentially

246
00:11:37,600 --> 00:11:42,850
start with a network tap that reads all

247
00:11:40,720 --> 00:11:46,899
the external the internal emails coming

248
00:11:42,850 --> 00:11:49,509
in and we run those messages against our

249
00:11:46,899 --> 00:11:52,389
internal Intel set and within that Intel

250
00:11:49,509 --> 00:11:54,189
say each of those rules gets a score so

251
00:11:52,389 --> 00:11:56,889
if there's a score above a predefined

252
00:11:54,189 --> 00:11:59,050
threshold that gets sent off to the fish

253
00:11:56,889 --> 00:12:01,360
finder queue where our human incident

254
00:11:59,050 --> 00:12:02,410
response analyst will triage that alert

255
00:12:01,360 --> 00:12:06,279
and determine whether it's an actual

256
00:12:02,410 --> 00:12:08,500
false positive or too positive if it's a

257
00:12:06,279 --> 00:12:09,910
false positive nothing much happens we

258
00:12:08,500 --> 00:12:12,189
just market our metrics it helps us

259
00:12:09,910 --> 00:12:13,870
refine our intelligence a little bit but

260
00:12:12,189 --> 00:12:16,389
if it's a true positive we can

261
00:12:13,870 --> 00:12:19,660
automatically scrape intelligence from

262
00:12:16,389 --> 00:12:21,880
that like sender's IP addresses common

263
00:12:19,660 --> 00:12:23,259
subject lines stuff like that and then

264
00:12:21,880 --> 00:12:25,540
we can remove the fish from the users

265
00:12:23,259 --> 00:12:28,689
inbox so the end result of the fish

266
00:12:25,540 --> 00:12:30,370
finder pipeline here is that we're doing

267
00:12:28,689 --> 00:12:32,079
a kind of Mannie Matic process where the

268
00:12:30,370 --> 00:12:34,120
incident analyst has to go in and triage

269
00:12:32,079 --> 00:12:35,829
it but once they do if they escalate

270
00:12:34,120 --> 00:12:37,389
something on the backend we can

271
00:12:35,829 --> 00:12:39,638
automatically document that fishing

272
00:12:37,389 --> 00:12:42,880
isn't collect the Intel and deploy that

273
00:12:39,639 --> 00:12:46,139
Intel and remove the threat from the

274
00:12:42,880 --> 00:12:47,920
environment so right now we're thinking

275
00:12:46,139 --> 00:12:50,560
visualizable fits somewhere between

276
00:12:47,920 --> 00:12:53,019
these two steps where we didn't want to

277
00:12:50,560 --> 00:12:54,849
put it for all of the emails coming in

278
00:12:53,019 --> 00:12:56,529
to GE that's a massive amount of emails

279
00:12:54,850 --> 00:12:59,559
and a massive amount of processing to

280
00:12:56,529 --> 00:13:02,079
run a computer vision tool against but

281
00:12:59,559 --> 00:13:04,120
if we have a message coming in and it's

282
00:13:02,079 --> 00:13:06,519
already hitting some piece of other

283
00:13:04,120 --> 00:13:08,230
Intel we have we might as well throw it

284
00:13:06,519 --> 00:13:09,880
through visualize and see if we can make

285
00:13:08,230 --> 00:13:11,649
an automated determination about whether

286
00:13:09,880 --> 00:13:14,620
or not it's malicious save our analysts

287
00:13:11,649 --> 00:13:17,500
sometimes cut down a little bit on the

288
00:13:14,620 --> 00:13:19,059
false positives so this is just a

289
00:13:17,500 --> 00:13:21,639
high-level overview of the technologies

290
00:13:19,059 --> 00:13:24,670
we're using here the input of course is

291
00:13:21,639 --> 00:13:26,279
our URL we're using Khoa middleware what

292
00:13:24,670 --> 00:13:27,949
that does it just kind of does the

293
00:13:26,279 --> 00:13:29,270
routing and mounting

294
00:13:27,950 --> 00:13:31,430
between the back end in the front end

295
00:13:29,270 --> 00:13:32,829
soko is going to take that URL and it's

296
00:13:31,430 --> 00:13:34,939
going to send it over to puppeteer

297
00:13:32,830 --> 00:13:36,890
puppeteer for those who aren't familiar

298
00:13:34,940 --> 00:13:39,170
it's headless Chrome or Chrome without

299
00:13:36,890 --> 00:13:41,120
Chrome basically you can feed a URL and

300
00:13:39,170 --> 00:13:42,890
it will grab that URL throw it through

301
00:13:41,120 --> 00:13:45,620
the annihilation service and bring us

302
00:13:42,890 --> 00:13:47,900
back the screenshot screenshot arrives

303
00:13:45,620 --> 00:13:49,670
coop routes that through to the

304
00:13:47,900 --> 00:13:52,280
classifying module and that's written in

305
00:13:49,670 --> 00:13:55,099
Python the classification modules were

306
00:13:52,280 --> 00:13:56,900
the computer vision magic happens and

307
00:13:55,100 --> 00:13:59,510
then that the output from that process

308
00:13:56,900 --> 00:14:01,069
is given to the analyst so that they can

309
00:13:59,510 --> 00:14:04,130
make a better determination on this

310
00:14:01,070 --> 00:14:05,510
message now eventually once we train

311
00:14:04,130 --> 00:14:07,700
this thing more and once we build out

312
00:14:05,510 --> 00:14:09,439
our libraries we could potentially start

313
00:14:07,700 --> 00:14:10,820
just making that a completely automatic

314
00:14:09,440 --> 00:14:12,530
process where it will automatically

315
00:14:10,820 --> 00:14:14,780
triage these alerts we're still long way

316
00:14:12,530 --> 00:14:17,959
off from that but that's the end goal in

317
00:14:14,780 --> 00:14:20,900
mind so taking this one level deeper at

318
00:14:17,960 --> 00:14:22,160
the actual breakdown of this project the

319
00:14:20,900 --> 00:14:25,579
way we structured it we have a cache

320
00:14:22,160 --> 00:14:27,740
here and that's going to store our URL

321
00:14:25,580 --> 00:14:30,020
screenshots and it's also going to store

322
00:14:27,740 --> 00:14:32,630
a second screenshot with any templates

323
00:14:30,020 --> 00:14:35,180
that get matched circled in a red line

324
00:14:32,630 --> 00:14:37,850
and there's also a JSON file it gets

325
00:14:35,180 --> 00:14:40,069
stored in here that more structure

326
00:14:37,850 --> 00:14:44,000
structurally describes that data whether

327
00:14:40,070 --> 00:14:45,830
it found something malicious or you know

328
00:14:44,000 --> 00:14:47,810
the basic question is asking is does it

329
00:14:45,830 --> 00:14:50,960
make sense that we're seeing this set of

330
00:14:47,810 --> 00:14:52,640
logos on this URL and it's going to

331
00:14:50,960 --> 00:14:54,380
capture that in JSON and that's what's

332
00:14:52,640 --> 00:14:57,080
going to kind of feedback through to the

333
00:14:54,380 --> 00:14:59,180
analyst view and the way we're storing

334
00:14:57,080 --> 00:15:01,910
these by the way is we're gonna take an

335
00:14:59,180 --> 00:15:03,829
md5 hash of the URL that way if we get

336
00:15:01,910 --> 00:15:06,680
the same URL coming through multiple

337
00:15:03,830 --> 00:15:08,120
times we don't have to keep classifying

338
00:15:06,680 --> 00:15:10,579
it because we don't want to waste too

339
00:15:08,120 --> 00:15:11,420
many cycles so if the hash already

340
00:15:10,580 --> 00:15:13,550
exists in the cache

341
00:15:11,420 --> 00:15:16,160
it'll just pool the data already has and

342
00:15:13,550 --> 00:15:18,079
it saves us a lot of time then we have

343
00:15:16,160 --> 00:15:20,270
the classification module itself again

344
00:15:18,080 --> 00:15:21,890
written in Python underneath that folder

345
00:15:20,270 --> 00:15:23,569
there we also have this template library

346
00:15:21,890 --> 00:15:24,790
you know hear me talk about templates a

347
00:15:23,570 --> 00:15:27,320
lot I kind of use that word

348
00:15:24,790 --> 00:15:29,689
interchangeably with logos these are the

349
00:15:27,320 --> 00:15:30,650
things we're basically looking for so

350
00:15:29,690 --> 00:15:33,530
you can see we have all these different

351
00:15:30,650 --> 00:15:36,410
I called tags or different services

352
00:15:33,530 --> 00:15:37,180
microsoft office 365 onedrive outlook

353
00:15:36,410 --> 00:15:39,189
Yahoo

354
00:15:37,180 --> 00:15:42,130
each of these services has their own

355
00:15:39,190 --> 00:15:44,470
kind of logos so what visualize is gonna

356
00:15:42,130 --> 00:15:46,720
do is say okay I found logos for this

357
00:15:44,470 --> 00:15:48,250
this and this service and then it's

358
00:15:46,720 --> 00:15:50,140
gonna look at that URL and ask the

359
00:15:48,250 --> 00:15:53,620
question does it make sense that these

360
00:15:50,140 --> 00:15:56,230
logos appear on this URL and that's how

361
00:15:53,620 --> 00:15:57,880
it's going to in a very simple way make

362
00:15:56,230 --> 00:16:01,450
that determination about maliciousness

363
00:15:57,880 --> 00:16:03,340
or spoofing now along with each of these

364
00:16:01,450 --> 00:16:05,470
template sets we have a metadata file

365
00:16:03,340 --> 00:16:06,970
here also in JSON and I'll show you an

366
00:16:05,470 --> 00:16:10,330
example of that at the end of this

367
00:16:06,970 --> 00:16:12,250
presentation in that metadata file we

368
00:16:10,330 --> 00:16:14,020
can tweak these as much as we like we

369
00:16:12,250 --> 00:16:15,760
can set different thresholds for each

370
00:16:14,020 --> 00:16:18,640
template so if you have a template like

371
00:16:15,760 --> 00:16:20,170
the gmail logos a good example that

372
00:16:18,640 --> 00:16:22,449
envelope can look like a lot of things

373
00:16:20,170 --> 00:16:24,280
you can look like a wide letter M it can

374
00:16:22,450 --> 00:16:27,580
look like a lot and so we have to set a

375
00:16:24,280 --> 00:16:28,780
highly a slightly higher threshold for

376
00:16:27,580 --> 00:16:31,390
that logo compared to the other

377
00:16:28,780 --> 00:16:33,040
templates we have other things you can

378
00:16:31,390 --> 00:16:35,020
tweak with this is the white list of

379
00:16:33,040 --> 00:16:36,610
course so with each logo you're gonna

380
00:16:35,020 --> 00:16:38,860
have a set of white lists obviously if

381
00:16:36,610 --> 00:16:40,720
we find the Outlook logo on the outlook

382
00:16:38,860 --> 00:16:42,580
website we don't want to classify that

383
00:16:40,720 --> 00:16:45,550
as malicious or suspicious that makes

384
00:16:42,580 --> 00:16:46,660
complete sense and then of course you

385
00:16:45,550 --> 00:16:49,060
can designate whether you want to turn

386
00:16:46,660 --> 00:16:50,079
the template on or off and you can so

387
00:16:49,060 --> 00:16:51,699
you can there's a lot of room for

388
00:16:50,080 --> 00:16:55,340
customization and tweaking with your own

389
00:16:51,700 --> 00:16:57,230
internal Intel set and observations here

390
00:16:55,340 --> 00:16:59,360
and then of course we have the source

391
00:16:57,230 --> 00:17:04,220
the front end for this proof of concept

392
00:16:59,360 --> 00:17:05,720
which is written in JavaScript so we dig

393
00:17:04,220 --> 00:17:06,829
a little deeper into the magic that's

394
00:17:05,720 --> 00:17:08,720
happening underneath the hood of this

395
00:17:06,829 --> 00:17:10,698
classification module we're using a

396
00:17:08,720 --> 00:17:12,980
classic computer vision method called

397
00:17:10,699 --> 00:17:15,290
template matching and it's a super

398
00:17:12,980 --> 00:17:17,540
simple concept on paper essentially we

399
00:17:15,290 --> 00:17:20,060
have an input image and we have all

400
00:17:17,540 --> 00:17:21,709
these logos and we're gonna see all the

401
00:17:20,060 --> 00:17:24,948
places in this input image where that

402
00:17:21,709 --> 00:17:26,930
logo appears very simple concept you

403
00:17:24,949 --> 00:17:29,240
probably do it you do do it I'm telling

404
00:17:26,930 --> 00:17:31,400
you you do do it every day if you have

405
00:17:29,240 --> 00:17:32,960
you know a nice pie book or Where's

406
00:17:31,400 --> 00:17:34,700
Waldo book that you take from your kid

407
00:17:32,960 --> 00:17:35,480
or someone else's kid and you're trying

408
00:17:34,700 --> 00:17:37,220
to show them how it's done

409
00:17:35,480 --> 00:17:39,860
where you gonna do you know your brain

410
00:17:37,220 --> 00:17:41,990
knows what Walter looks like and what

411
00:17:39,860 --> 00:17:45,620
your eyes are gonna do is scan across

412
00:17:41,990 --> 00:17:48,560
those pages and look trying to find

413
00:17:45,620 --> 00:17:51,169
where Waldo is and this is exactly what

414
00:17:48,560 --> 00:17:53,360
we wanted to emulate with visualize now

415
00:17:51,170 --> 00:17:56,110
to simplify it animation but the idea is

416
00:17:53,360 --> 00:17:59,439
there

417
00:17:56,110 --> 00:18:01,000
now we get to the complex part because

418
00:17:59,440 --> 00:18:03,220
for us it's really easy to say hey

419
00:18:01,000 --> 00:18:06,820
that's Waldo I can see him he's right

420
00:18:03,220 --> 00:18:09,010
there but how do we teach a machine what

421
00:18:06,820 --> 00:18:10,990
similarity looks like and so without

422
00:18:09,010 --> 00:18:13,419
getting too deep into the mathematics

423
00:18:10,990 --> 00:18:15,700
and the theory here I want to talk about

424
00:18:13,419 --> 00:18:19,539
this value called the cross correlation

425
00:18:15,700 --> 00:18:22,360
value to put it as simply as I can it's

426
00:18:19,539 --> 00:18:24,970
essentially a sum of products so we

427
00:18:22,360 --> 00:18:27,399
start we have our input image we have

428
00:18:24,970 --> 00:18:28,870
our logo just like you saw on that

429
00:18:27,399 --> 00:18:31,090
animation we're gonna start with that

430
00:18:28,870 --> 00:18:34,000
logo in the top left corner and now we

431
00:18:31,090 --> 00:18:36,459
have an overlapping region of pixels so

432
00:18:34,000 --> 00:18:38,649
if I take this pixel on the logo let's

433
00:18:36,460 --> 00:18:41,919
say X Y position X Y take that same

434
00:18:38,649 --> 00:18:44,199
position in the input image and multiply

435
00:18:41,919 --> 00:18:45,970
them together that's going to give me

436
00:18:44,200 --> 00:18:48,820
the cross correlation value and you do

437
00:18:45,970 --> 00:18:50,649
that for that entire region and you do

438
00:18:48,820 --> 00:18:52,418
that you slide the logo across the

439
00:18:50,649 --> 00:18:55,149
entire image and you go back and you see

440
00:18:52,419 --> 00:18:56,289
where's the highest correlation value

441
00:18:55,149 --> 00:18:59,080
and that's going to give you your best

442
00:18:56,289 --> 00:19:00,850
match it's a little hard to picture how

443
00:18:59,080 --> 00:19:01,960
this works especially for you know if

444
00:19:00,850 --> 00:19:03,580
you have a development background we

445
00:19:01,960 --> 00:19:07,480
tend to think of like pixel intensities

446
00:19:03,580 --> 00:19:09,460
we think RGB and 0 to 255 I think it's

447
00:19:07,480 --> 00:19:12,610
easier to understand this concept if you

448
00:19:09,460 --> 00:19:15,789
think ok 0 is absolutely neutral and

449
00:19:12,610 --> 00:19:17,590
then if a pixel is darker you go

450
00:19:15,789 --> 00:19:19,629
negative the more dark it is the more

451
00:19:17,590 --> 00:19:21,279
negative the number is if it's lighter

452
00:19:19,630 --> 00:19:24,940
it goes positive or you can do

453
00:19:21,279 --> 00:19:27,519
vice-versa even so when we have a logo

454
00:19:24,940 --> 00:19:29,320
we have a pixel here if that pixel is

455
00:19:27,519 --> 00:19:31,809
light it's going to be a positive number

456
00:19:29,320 --> 00:19:33,250
same thing if the input image is also

457
00:19:31,809 --> 00:19:35,110
light that's going to be a positive

458
00:19:33,250 --> 00:19:37,840
number we multiply those two together we

459
00:19:35,110 --> 00:19:41,408
get a larger positive number on the

460
00:19:37,840 --> 00:19:44,049
other side if the pixel is dark and the

461
00:19:41,409 --> 00:19:46,059
input pixel is dark that's going to be

462
00:19:44,049 --> 00:19:47,889
two negatives multiplied together that's

463
00:19:46,059 --> 00:19:51,129
going to be another positive so that's

464
00:19:47,889 --> 00:19:52,750
how we get the end result that the

465
00:19:51,130 --> 00:19:55,029
cross-correlation value wherever that's

466
00:19:52,750 --> 00:19:58,029
highest in the image is going to be the

467
00:19:55,029 --> 00:20:00,159
region of highest matching we actually

468
00:19:58,029 --> 00:20:01,389
tweaked this even a little bit more by

469
00:20:00,159 --> 00:20:03,730
using what's called the normalized

470
00:20:01,389 --> 00:20:05,740
cross-correlation value and what that

471
00:20:03,730 --> 00:20:07,630
does is we're simply just subtracting

472
00:20:05,740 --> 00:20:09,630
the average brightness of the entire

473
00:20:07,630 --> 00:20:12,330
picture from each of these

474
00:20:09,630 --> 00:20:14,280
and what that handles is a case where if

475
00:20:12,330 --> 00:20:17,280
an attacker slightly brightens or

476
00:20:14,280 --> 00:20:19,590
darkens their credential horror or spoof

477
00:20:17,280 --> 00:20:21,210
site that won't mess with our matching

478
00:20:19,590 --> 00:20:23,490
say that we have you know the original

479
00:20:21,210 --> 00:20:26,220
red Adobe logo and they have a slightly

480
00:20:23,490 --> 00:20:27,510
Pinker Adobe logo our matching will

481
00:20:26,220 --> 00:20:34,470
still work using the normalized

482
00:20:27,510 --> 00:20:35,700
cross-correlation so that's it that's

483
00:20:34,470 --> 00:20:37,200
the magic that goes into template

484
00:20:35,700 --> 00:20:39,330
matching it's not all that complicated

485
00:20:37,200 --> 00:20:41,820
it's just complicated to get the

486
00:20:39,330 --> 00:20:44,399
concepts down we're actually going to

487
00:20:41,820 --> 00:20:46,289
twist this a little bit more because

488
00:20:44,400 --> 00:20:49,380
with template matching you can either

489
00:20:46,289 --> 00:20:52,500
get a bunch of different size templates

490
00:20:49,380 --> 00:20:56,400
of the same you know logo like a hundred

491
00:20:52,500 --> 00:20:58,020
different sizes of the Adobe logo or you

492
00:20:56,400 --> 00:21:00,179
can scale down the input image so we

493
00:20:58,020 --> 00:21:02,549
decided to scale down or go across

494
00:21:00,179 --> 00:21:04,710
scales of the input image so we're gonna

495
00:21:02,549 --> 00:21:06,450
do is use a process called scale

496
00:21:04,710 --> 00:21:08,220
invariant template matching which is

497
00:21:06,450 --> 00:21:10,289
just a fancy way of saying we're gonna

498
00:21:08,220 --> 00:21:11,610
take that input image we're gonna blow

499
00:21:10,289 --> 00:21:14,129
it up to maybe two hundred three hundred

500
00:21:11,610 --> 00:21:15,840
percent and start there run that logo

501
00:21:14,130 --> 00:21:17,299
across and look for matches and then

502
00:21:15,840 --> 00:21:20,399
we're gonna do that again and again just

503
00:21:17,299 --> 00:21:23,010
scaling down that input image that way

504
00:21:20,400 --> 00:21:25,230
we only have to keep one Adobe logo

505
00:21:23,010 --> 00:21:26,850
template and we can use that to match

506
00:21:25,230 --> 00:21:28,919
across multiple sides of the same image

507
00:21:26,850 --> 00:21:30,360
just in case they blow it up the logo on

508
00:21:28,919 --> 00:21:34,200
their page or they make it smaller or

509
00:21:30,360 --> 00:21:36,870
whatever we can actually speed this up

510
00:21:34,200 --> 00:21:39,809
even more if we make a couple of tweaks

511
00:21:36,870 --> 00:21:42,090
our goal here is to scale this obviously

512
00:21:39,809 --> 00:21:43,649
to the amount of email that we're

513
00:21:42,090 --> 00:21:45,240
getting in which is quite a large amount

514
00:21:43,650 --> 00:21:47,880
so we want to be as efficient as

515
00:21:45,240 --> 00:21:49,650
possible now we can save ourselves a few

516
00:21:47,880 --> 00:21:51,450
calculations going back to talking about

517
00:21:49,650 --> 00:21:54,289
that cross correlation value with the

518
00:21:51,450 --> 00:21:57,510
multiply the pixel intensities together

519
00:21:54,289 --> 00:22:00,570
well we could do that for two color

520
00:21:57,510 --> 00:22:03,450
images but you have to take that product

521
00:22:00,570 --> 00:22:07,590
for the red Channel the blue channel and

522
00:22:03,450 --> 00:22:09,120
in the green Channel but if we greyscale

523
00:22:07,590 --> 00:22:10,799
both the images now we're down to one

524
00:22:09,120 --> 00:22:12,389
channel that's it it's a couple

525
00:22:10,799 --> 00:22:16,590
calculations and now we just have to do

526
00:22:12,390 --> 00:22:18,929
multiplication one to one other thing we

527
00:22:16,590 --> 00:22:20,830
can do is use a technique called edging

528
00:22:18,929 --> 00:22:23,140
and all we're doing there

529
00:22:20,830 --> 00:22:25,090
is taking the edges of both images if

530
00:22:23,140 --> 00:22:27,220
you think about it anything you're

531
00:22:25,090 --> 00:22:29,620
looking at it's mostly made up of its

532
00:22:27,220 --> 00:22:31,299
edges and these shapes you look at is

533
00:22:29,620 --> 00:22:33,850
the same thing for the machine what it's

534
00:22:31,299 --> 00:22:35,559
seeing so this reduces it down for our

535
00:22:33,850 --> 00:22:38,500
classifier so that a classifier going to

536
00:22:35,559 --> 00:22:40,720
say okay I'm looking at this pixel is it

537
00:22:38,500 --> 00:22:42,399
an edge or is it not an edge it's a very

538
00:22:40,720 --> 00:22:44,890
easy determination to make and it saves

539
00:22:42,399 --> 00:22:48,029
us a lot of cycles so it's gonna look

540
00:22:44,890 --> 00:22:50,820
something like this this is slightly

541
00:22:48,029 --> 00:22:53,320
deceiving animation because in actuality

542
00:22:50,820 --> 00:22:55,299
it's not gonna stop at the match there

543
00:22:53,320 --> 00:22:57,158
it's actually going to go through scan

544
00:22:55,299 --> 00:22:58,840
through the entire image and then go

545
00:22:57,159 --> 00:23:00,340
back at the data it's collected see

546
00:22:58,840 --> 00:23:02,889
where the highest correlation value is

547
00:23:00,340 --> 00:23:05,049
and then say hey if that meets the

548
00:23:02,889 --> 00:23:07,149
threshold for this template I'm gonna

549
00:23:05,049 --> 00:23:08,168
say that's a match so that's how we're

550
00:23:07,149 --> 00:23:10,689
doing the matching for the different

551
00:23:08,169 --> 00:23:12,940
logos right here we have it the

552
00:23:10,690 --> 00:23:14,500
definition or the criteria for the canny

553
00:23:12,940 --> 00:23:16,049
edging algorithm that's just the

554
00:23:14,500 --> 00:23:19,330
particular algorithm we're using to

555
00:23:16,049 --> 00:23:21,820
extract these edges very reliable

556
00:23:19,330 --> 00:23:23,559
algorithm and very efficient that's why

557
00:23:21,820 --> 00:23:25,620
we made that design decision in case you

558
00:23:23,559 --> 00:23:28,990
were wondering

559
00:23:25,620 --> 00:23:31,059
so to cap this all off this is the short

560
00:23:28,990 --> 00:23:32,289
version of the scale and very timid

561
00:23:31,059 --> 00:23:33,879
matching algorithm we're using we're

562
00:23:32,289 --> 00:23:35,740
gonna load in the input image that's

563
00:23:33,880 --> 00:23:38,409
going to be the URL screenshot that we

564
00:23:35,740 --> 00:23:41,169
took we're going to grayscale that we're

565
00:23:38,409 --> 00:23:43,240
gonna take the edges of that and then

566
00:23:41,169 --> 00:23:44,289
with our template library which we'll

567
00:23:43,240 --> 00:23:46,960
have to build up with all these

568
00:23:44,289 --> 00:23:49,210
different logos and services we're gonna

569
00:23:46,960 --> 00:23:51,039
do loop through the all those templates

570
00:23:49,210 --> 00:23:52,450
check the white list if the site's white

571
00:23:51,039 --> 00:23:55,690
listed if we're looking at you know

572
00:23:52,450 --> 00:23:57,070
Microsoft comm or Gmail comm we're

573
00:23:55,690 --> 00:23:58,330
obviously not going to want to continue

574
00:23:57,070 --> 00:24:00,070
classification so we'll stop

575
00:23:58,330 --> 00:24:01,720
classification there and just output to

576
00:24:00,070 --> 00:24:04,539
the analyst that this site is white

577
00:24:01,720 --> 00:24:07,059
listed this is probably the JIT on the

578
00:24:04,539 --> 00:24:09,580
other hand if there's excuse me if

579
00:24:07,059 --> 00:24:10,870
there's no white list found we're going

580
00:24:09,580 --> 00:24:13,149
to grayscale the template take that

581
00:24:10,870 --> 00:24:14,649
edges as well and then perform the

582
00:24:13,149 --> 00:24:16,760
template matching capturing the highest

583
00:24:14,649 --> 00:24:19,159
correlation coefficient

584
00:24:16,760 --> 00:24:21,049
and if that value Beach meets our

585
00:24:19,160 --> 00:24:22,640
templates threshold for a true positive

586
00:24:21,049 --> 00:24:24,860
we're gonna mark that as true positive

587
00:24:22,640 --> 00:24:26,240
we're gonna check that and then we're

588
00:24:24,860 --> 00:24:28,340
going to send that back to the analyst

589
00:24:26,240 --> 00:24:29,780
and let them know hey I found this logo

590
00:24:28,340 --> 00:24:31,790
but it doesn't make sense that this

591
00:24:29,780 --> 00:24:33,230
logos on this page so you may want to

592
00:24:31,790 --> 00:24:36,320
look a little closer at this alert

593
00:24:33,230 --> 00:24:37,730
because it's probably malicious and like

594
00:24:36,320 --> 00:24:39,649
I said for the scale-invariant piece

595
00:24:37,730 --> 00:24:41,419
we're gonna repeat this process of a

596
00:24:39,650 --> 00:24:44,120
regular interval scale so you could take

597
00:24:41,419 --> 00:24:46,010
you know 20 scale starting at 200% of

598
00:24:44,120 --> 00:24:47,780
the input image all the way down to 10%

599
00:24:46,010 --> 00:24:50,840
just to make sure we're covered in case

600
00:24:47,780 --> 00:24:52,460
they modify the size of the logo we're

601
00:24:50,840 --> 00:24:54,409
ready to build those results and write

602
00:24:52,460 --> 00:24:57,679
them to our cache result directory it's

603
00:24:54,410 --> 00:24:59,590
pretty simple alright let's talk about

604
00:24:57,679 --> 00:25:01,730
the theory we're gonna try for a demo

605
00:24:59,590 --> 00:25:06,370
we've seen how that's gone today so

606
00:25:01,730 --> 00:25:06,370
hopefully go well here

607
00:25:08,310 --> 00:25:11,280
so I want to give a shout out to Michael

608
00:25:09,990 --> 00:25:13,770
charities here I won't point him out but

609
00:25:11,280 --> 00:25:15,960
he's here he's the one who designed the

610
00:25:13,770 --> 00:25:21,389
lovely proof of concept you're seeing

611
00:25:15,960 --> 00:25:23,760
now so let's strike google.com all right

612
00:25:21,390 --> 00:25:25,650
so this came up as a legitimate site

613
00:25:23,760 --> 00:25:28,080
obviously because it's Google it's white

614
00:25:25,650 --> 00:25:29,910
listed but you can see over here we're

615
00:25:28,080 --> 00:25:31,860
actually still getting feedback from

616
00:25:29,910 --> 00:25:34,440
those template images then that's why

617
00:25:31,860 --> 00:25:36,629
it's important to set your thresholds at

618
00:25:34,440 --> 00:25:38,250
that certain level because again that

619
00:25:36,630 --> 00:25:40,110
gmail logo it can look like a lot of

620
00:25:38,250 --> 00:25:41,820
things it can look like you know any

621
00:25:40,110 --> 00:25:44,520
kind of M that's on this page it might

622
00:25:41,820 --> 00:25:47,580
match up to that logo so we have to set

623
00:25:44,520 --> 00:25:50,810
a higher threshold for that we could do

624
00:25:47,580 --> 00:25:50,810
it for the b-side site

625
00:25:52,500 --> 00:25:57,360
alright legitimate society because it

626
00:25:54,360 --> 00:26:00,510
didn't find any logos also I'll say you

627
00:25:57,360 --> 00:26:02,610
have to be careful because these logos

628
00:26:00,510 --> 00:26:04,289
alone can be tricky there's a lot of

629
00:26:02,610 --> 00:26:06,030
websites that aren't Facebook or Twitter

630
00:26:04,289 --> 00:26:07,379
that will have those logos in there

631
00:26:06,030 --> 00:26:10,740
because people like to show off their

632
00:26:07,380 --> 00:26:12,330
social media now let's try an actual

633
00:26:10,740 --> 00:26:16,039
credit hour store I have a few samples

634
00:26:12,330 --> 00:26:16,039
loaded on here that we can try it out on

635
00:26:18,599 --> 00:26:23,249
this first one's gonna be a Dobby login

636
00:26:21,009 --> 00:26:23,249
page

637
00:26:24,170 --> 00:26:29,100
now we see the bread-and-butter of

638
00:26:26,610 --> 00:26:31,350
visualize here so we have pretty

639
00:26:29,100 --> 00:26:33,510
positive matching up in the 90s and 80s

640
00:26:31,350 --> 00:26:35,429
for these logos we have the Gmail logo

641
00:26:33,510 --> 00:26:38,250
the Outlook logo the Yahoo logo the

642
00:26:35,430 --> 00:26:40,350
Adobe logo it doesn't make much sense

643
00:26:38,250 --> 00:26:42,350
that all of those show up on the same

644
00:26:40,350 --> 00:26:44,370
login page even though there's

645
00:26:42,350 --> 00:26:47,550
definitely users who would still fall

646
00:26:44,370 --> 00:26:50,070
for this one so we're going to classify

647
00:26:47,550 --> 00:26:52,620
that as a potentially malicious site or

648
00:26:50,070 --> 00:26:59,419
a malicious site we do it again for

649
00:26:52,620 --> 00:26:59,419
let's say office 365 oops

650
00:26:59,760 --> 00:27:04,460
is the or Dropbox

651
00:27:05,810 --> 00:27:11,030
same thing we're going through Dropbox

652
00:27:08,480 --> 00:27:12,860
isn't going to ask you for all of your

653
00:27:11,030 --> 00:27:14,450
email credentials it's going to ask you

654
00:27:12,860 --> 00:27:16,250
you know simple login screen for your

655
00:27:14,450 --> 00:27:17,600
email address and whatever password you

656
00:27:16,250 --> 00:27:19,430
have so it doesn't make sense that we're

657
00:27:17,600 --> 00:27:23,149
seeing all these different services

658
00:27:19,430 --> 00:27:26,290
represented on this page and then one

659
00:27:23,150 --> 00:27:26,290
more 403 65

660
00:27:33,450 --> 00:27:39,090
there you go once again Microsoft Office

661
00:27:36,240 --> 00:27:41,130
365 logo but the site itself the URL is

662
00:27:39,090 --> 00:27:45,110
not a lead in a Microsoft site so we're

663
00:27:41,130 --> 00:27:45,110
going to classify that as malicious

664
00:27:48,670 --> 00:27:53,200
so good nothing you know super amazing

665
00:27:51,370 --> 00:27:55,209
about it as long as you have the

666
00:27:53,200 --> 00:27:57,160
algorithms at hand the template matching

667
00:27:55,210 --> 00:28:00,610
algorithms you can implement this pretty

668
00:27:57,160 --> 00:28:01,990
easily in your own environment and you

669
00:28:00,610 --> 00:28:02,889
know you take a tool like visualize you

670
00:28:01,990 --> 00:28:05,320
can plug it right into your existing

671
00:28:02,890 --> 00:28:07,360
pipelines there's a couple of startups

672
00:28:05,320 --> 00:28:09,189
that are like just getting started and

673
00:28:07,360 --> 00:28:11,320
doing this kind of thing as a service

674
00:28:09,190 --> 00:28:13,420
but I would say if you have the

675
00:28:11,320 --> 00:28:15,189
development strength to develop this

676
00:28:13,420 --> 00:28:19,030
yourself you should definitely go after

677
00:28:15,190 --> 00:28:22,210
it now looking forward again this is a

678
00:28:19,030 --> 00:28:23,889
very young project and obviously we need

679
00:28:22,210 --> 00:28:25,450
to scale it quite a bit if we're going

680
00:28:23,890 --> 00:28:27,340
to keep up with the amount of email

681
00:28:25,450 --> 00:28:28,840
that's coming in so we're trying to

682
00:28:27,340 --> 00:28:30,730
explore different ways we can speed this

683
00:28:28,840 --> 00:28:33,220
up even more than the adjustments we've

684
00:28:30,730 --> 00:28:35,350
already made one of those ways it's

685
00:28:33,220 --> 00:28:36,190
exploring key point matching now for

686
00:28:35,350 --> 00:28:40,270
those who are not familiar with key

687
00:28:36,190 --> 00:28:42,190
point matching just a separate method

688
00:28:40,270 --> 00:28:43,540
for matching rather than template

689
00:28:42,190 --> 00:28:45,760
matching we can do key point matching

690
00:28:43,540 --> 00:28:47,670
instead of having a hole template to

691
00:28:45,760 --> 00:28:51,070
match against you can select these

692
00:28:47,670 --> 00:28:53,320
interesting areas called key points what

693
00:28:51,070 --> 00:28:55,810
makes them interesting well to a machine

694
00:28:53,320 --> 00:28:58,240
what makes a key point interesting is

695
00:28:55,810 --> 00:29:01,240
the fact that it can be detected whether

696
00:28:58,240 --> 00:29:03,670
we rotate this image or scale this image

697
00:29:01,240 --> 00:29:04,810
or turn it black and white or decrease

698
00:29:03,670 --> 00:29:07,180
the brightness or increase the

699
00:29:04,810 --> 00:29:09,879
brightness so it's nice about key point

700
00:29:07,180 --> 00:29:11,350
matching versus template matching is if

701
00:29:09,880 --> 00:29:12,610
an attacker were to catch on to how

702
00:29:11,350 --> 00:29:14,740
we're detecting their credential

703
00:29:12,610 --> 00:29:16,750
harvesters all they would really need to

704
00:29:14,740 --> 00:29:18,760
do to defeat this visualize module is

705
00:29:16,750 --> 00:29:21,040
rotate their logo just a little bit

706
00:29:18,760 --> 00:29:24,070
enough to throw off our template

707
00:29:21,040 --> 00:29:26,080
matching algorithm now it's unlikely

708
00:29:24,070 --> 00:29:27,879
that they would do this you know in a

709
00:29:26,080 --> 00:29:29,379
large degree because if they rotate

710
00:29:27,880 --> 00:29:30,910
anything any kind of logo on that page

711
00:29:29,380 --> 00:29:32,080
it's going to tip off the human user

712
00:29:30,910 --> 00:29:33,820
who's looking at that page that

713
00:29:32,080 --> 00:29:35,639
something's weird why would they you

714
00:29:33,820 --> 00:29:38,470
know rotate their logo all of a sudden

715
00:29:35,640 --> 00:29:40,270
but if they did it you know just enough

716
00:29:38,470 --> 00:29:41,560
just a couple pixels just enough to

717
00:29:40,270 --> 00:29:45,129
throw the algorithm off it's a

718
00:29:41,560 --> 00:29:46,570
potentially defeating move that they're

719
00:29:45,130 --> 00:29:48,400
making so we wanted to be prepared for

720
00:29:46,570 --> 00:29:51,360
that so we've been exploring key point

721
00:29:48,400 --> 00:29:54,880
matching the problem we run into is that

722
00:29:51,360 --> 00:29:56,889
to do pretty good key point matching you

723
00:29:54,880 --> 00:29:58,180
need very good descriptors and those are

724
00:29:56,890 --> 00:30:00,040
the things that describe all these

725
00:29:58,180 --> 00:30:01,710
little points the scale the orientation

726
00:30:00,040 --> 00:30:03,779
that point and intensity

727
00:30:01,710 --> 00:30:06,179
things that remain consistent no matter

728
00:30:03,779 --> 00:30:09,809
how you blow up this image or rotate the

729
00:30:06,179 --> 00:30:12,539
logo whatever and when you're working

730
00:30:09,809 --> 00:30:17,129
with all these tiny logos it's really

731
00:30:12,539 --> 00:30:19,950
hard to get a good robust set up key

732
00:30:17,130 --> 00:30:22,049
points and descriptors so doing some

733
00:30:19,950 --> 00:30:23,460
additional tests we're using the brisk

734
00:30:22,049 --> 00:30:25,620
algorithm if you're familiar with like

735
00:30:23,460 --> 00:30:28,590
sift or surf those are actually patented

736
00:30:25,620 --> 00:30:33,029
algorithms and brisk is an unpatented

737
00:30:28,590 --> 00:30:35,580
version of sift I believe so we tried

738
00:30:33,029 --> 00:30:40,649
using brisk and what we found is that

739
00:30:35,580 --> 00:30:43,799
yes it's a lot more it's a lot faster to

740
00:30:40,649 --> 00:30:49,139
use key point matching but you sacrifice

741
00:30:43,799 --> 00:30:52,020
the fidelity of your detection there

742
00:30:49,140 --> 00:30:53,820
because with these small logos having

743
00:30:52,020 --> 00:30:56,360
you know maybe one or two key points

744
00:30:53,820 --> 00:30:58,740
that stand out in like the Gmail logo

745
00:30:56,360 --> 00:31:00,120
you're not going to get the same results

746
00:30:58,740 --> 00:31:01,260
you live with template matching so for

747
00:31:00,120 --> 00:31:02,928
now we're sticking with the good

748
00:31:01,260 --> 00:31:06,059
old-fashioned template matching method

749
00:31:02,929 --> 00:31:07,470
but we have introduced multi-threading

750
00:31:06,059 --> 00:31:09,990
which I sped us up quite a bit we

751
00:31:07,470 --> 00:31:11,669
basically spin up another thread for

752
00:31:09,990 --> 00:31:12,809
each template and that sped it up so

753
00:31:11,669 --> 00:31:15,570
that we could scale it at least a little

754
00:31:12,809 --> 00:31:17,340
bit and again the end goal is that we

755
00:31:15,570 --> 00:31:21,520
can take this tool we can plug it into

756
00:31:17,340 --> 00:31:24,250
our pipeline and you see where it goes

757
00:31:21,520 --> 00:31:26,800
and that's really it I'd like to give a

758
00:31:24,250 --> 00:31:28,540
special shout out to Michael show he put

759
00:31:26,800 --> 00:31:30,669
so much work in this product project

760
00:31:28,540 --> 00:31:31,809
like I just approached him like at

761
00:31:30,670 --> 00:31:33,760
beginning of this year and said hey man

762
00:31:31,809 --> 00:31:35,740
I need help with this thing like I had

763
00:31:33,760 --> 00:31:38,080
this idea and we went with it we just

764
00:31:35,740 --> 00:31:40,480
roll with it so I went I also want to

765
00:31:38,080 --> 00:31:42,100
thank Adrian Rose Brock again he he

766
00:31:40,480 --> 00:31:43,900
provided not only did he write two

767
00:31:42,100 --> 00:31:46,659
excellent books which I dug into and

768
00:31:43,900 --> 00:31:47,679
kind of got an idea of where I wanted to

769
00:31:46,660 --> 00:31:49,420
go with this project but I actually

770
00:31:47,679 --> 00:31:52,780
emailed him and we talked back and forth

771
00:31:49,420 --> 00:31:55,990
and he provided a lot of code and advice

772
00:31:52,780 --> 00:31:57,940
on how to make this thing faster so yeah

773
00:31:55,990 --> 00:31:59,590
a pretty short talk but if you want to

774
00:31:57,940 --> 00:32:01,570
stay tuned for like you know the status

775
00:31:59,590 --> 00:32:03,040
on open sourcing this thing if you have

776
00:32:01,570 --> 00:32:05,439
any questions for me afterwards feel

777
00:32:03,040 --> 00:32:08,770
free to come up or send me a message on

778
00:32:05,440 --> 00:32:10,570
Twitter or to my email account and yeah

779
00:32:08,770 --> 00:32:12,929
thank you guys for attending and thank

780
00:32:10,570 --> 00:32:12,928
you for listening

781
00:32:16,650 --> 00:32:20,480
you

782
00:32:17,310 --> 00:32:20,480
[Music]

783
00:32:26,119 --> 00:32:28,178
you

