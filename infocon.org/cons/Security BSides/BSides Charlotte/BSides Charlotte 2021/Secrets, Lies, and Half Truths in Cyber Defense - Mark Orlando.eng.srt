1
00:00:03,080 --> 00:00:06,299
hello everyone and welcome to my talk

2
00:00:06,299 --> 00:00:09,720
secrets lies and half truths in cyber

3
00:00:09,720 --> 00:00:12,599
defense my name is Mark Orlando and I'm

4
00:00:12,599 --> 00:00:14,880
thrilled to be here with you all

5
00:00:14,880 --> 00:00:17,220
virtually at B-side Charlotte to give a

6
00:00:17,220 --> 00:00:19,020
talk that I'm quite passionate about

7
00:00:19,020 --> 00:00:21,420
hopefully that'll come through we have a

8
00:00:21,420 --> 00:00:22,800
lot to discuss

9
00:00:22,800 --> 00:00:24,960
really quick about me

10
00:00:24,960 --> 00:00:28,920
I have uh 21 years experience give or

11
00:00:28,920 --> 00:00:32,159
take in cyber defense who's counting uh

12
00:00:32,159 --> 00:00:35,880
I've been a sock analyst I've been a

13
00:00:35,880 --> 00:00:37,880
security manager I've been an executive

14
00:00:37,880 --> 00:00:41,399
today I'm the co-founder and CEO of a

15
00:00:41,399 --> 00:00:44,820
cyber defense company called Bionic I'm

16
00:00:44,820 --> 00:00:47,340
also a certified instructor and course

17
00:00:47,340 --> 00:00:49,680
author at the Sans Institute I teach SEC

18
00:00:49,680 --> 00:00:52,500
450 which is blue team fundamentals and

19
00:00:52,500 --> 00:00:55,620
security operations and I co-authored

20
00:00:55,620 --> 00:00:59,219
management 551 which is a class on

21
00:00:59,219 --> 00:01:01,440
building and leading sock teams

22
00:01:01,440 --> 00:01:03,799
so working in security operations

23
00:01:03,799 --> 00:01:07,260
supporting cyber defense as an executive

24
00:01:07,260 --> 00:01:09,780
a manager as an analyst as a Defender

25
00:01:09,780 --> 00:01:11,700
something that I've done for many years

26
00:01:11,700 --> 00:01:12,600
now

27
00:01:12,600 --> 00:01:17,820
and I wanted to give this talk

28
00:01:17,820 --> 00:01:20,280
um at what I believe is a fantastic

29
00:01:20,280 --> 00:01:23,280
event for Defenders and security folks

30
00:01:23,280 --> 00:01:25,860
uh you know of all uh different

31
00:01:25,860 --> 00:01:29,820
disciplines is I feel like as

32
00:01:29,820 --> 00:01:32,520
a manager as a consultant

33
00:01:32,520 --> 00:01:34,439
as a practitioner

34
00:01:34,439 --> 00:01:36,360
we're investing a lot

35
00:01:36,360 --> 00:01:38,880
arguably more than we ever have in cyber

36
00:01:38,880 --> 00:01:39,900
defense

37
00:01:39,900 --> 00:01:42,659
but I don't feel like we're improving at

38
00:01:42,659 --> 00:01:45,479
the rate that we're making Investments

39
00:01:45,479 --> 00:01:47,340
and I think there are a lot of reasons

40
00:01:47,340 --> 00:01:50,040
for that I think we are getting better

41
00:01:50,040 --> 00:01:52,020
but I think we still have a long ways to

42
00:01:52,020 --> 00:01:54,960
go so I wanted to give this talk

43
00:01:54,960 --> 00:01:57,899
basically because I wanted to be

44
00:01:57,899 --> 00:02:00,240
the well actually guy who just sits in a

45
00:02:00,240 --> 00:02:01,439
meeting

46
00:02:01,439 --> 00:02:03,479
and trolls everybody else

47
00:02:03,479 --> 00:02:05,939
and tries to tear down the lies and the

48
00:02:05,939 --> 00:02:07,920
half truths that we often tell ourselves

49
00:02:07,920 --> 00:02:10,679
to make ourselves feel better I wanted

50
00:02:10,679 --> 00:02:12,720
to take all of those things really

51
00:02:12,720 --> 00:02:15,780
annoying things put them into a talk

52
00:02:15,780 --> 00:02:17,940
give it virtually where no one can throw

53
00:02:17,940 --> 00:02:19,680
things at me or punch me in the face for

54
00:02:19,680 --> 00:02:22,560
being annoying and you know really try

55
00:02:22,560 --> 00:02:24,480
to be honest with ourselves about you

56
00:02:24,480 --> 00:02:26,220
know some of these lies and and some of

57
00:02:26,220 --> 00:02:28,440
these things that we tell ourselves to

58
00:02:28,440 --> 00:02:30,780
to make ourselves feel better

59
00:02:30,780 --> 00:02:33,599
but which are quite as effective as we

60
00:02:33,599 --> 00:02:35,160
like to believe they are I don't know

61
00:02:35,160 --> 00:02:37,440
how I got hacked I had my risk Matrix

62
00:02:37,440 --> 00:02:40,680
fully completed and fully color coded I

63
00:02:40,680 --> 00:02:42,120
have no idea why we could have been

64
00:02:42,120 --> 00:02:44,040
breached right we're going to tear some

65
00:02:44,040 --> 00:02:45,840
of those things down just a tiny little

66
00:02:45,840 --> 00:02:49,019
bit in this talk more specifically what

67
00:02:49,019 --> 00:02:51,920
we'll cover some common myths truths

68
00:02:51,920 --> 00:02:54,239
insecurity mostly in operations because

69
00:02:54,239 --> 00:02:55,980
that's my background

70
00:02:55,980 --> 00:02:58,379
reasons why we get some of these things

71
00:02:58,379 --> 00:03:01,620
wrong even when we feel like we're doing

72
00:03:01,620 --> 00:03:03,300
them right and we're doing the right

73
00:03:03,300 --> 00:03:04,800
things

74
00:03:04,800 --> 00:03:06,959
we'll talk about some ways to get to

75
00:03:06,959 --> 00:03:08,580
ground truth

76
00:03:08,580 --> 00:03:10,620
we don't want to throw all of these

77
00:03:10,620 --> 00:03:13,260
things out entirely there may be some

78
00:03:13,260 --> 00:03:15,540
more effective ways that we can look at

79
00:03:15,540 --> 00:03:17,459
what we're doing we can improve the

80
00:03:17,459 --> 00:03:19,739
things that we're doing do new things

81
00:03:19,739 --> 00:03:23,580
right in a better way to get to some

82
00:03:23,580 --> 00:03:26,159
measurable and repeatable results for

83
00:03:26,159 --> 00:03:29,879
building out executing and managing

84
00:03:29,879 --> 00:03:31,560
our cyber defense

85
00:03:31,560 --> 00:03:34,700
so that's what we're going to talk about

86
00:03:35,519 --> 00:03:38,220
so let's start off by going over some of

87
00:03:38,220 --> 00:03:41,400
The Lies We Tell and secrets we keep and

88
00:03:41,400 --> 00:03:43,080
I think to some extent these aren't

89
00:03:43,080 --> 00:03:45,120
necessarily Secrets or rather they're

90
00:03:45,120 --> 00:03:48,420
poorly kept secrets in our industry

91
00:03:48,420 --> 00:03:50,519
the first

92
00:03:50,519 --> 00:03:53,280
deals with teamwork we have an effective

93
00:03:53,280 --> 00:03:54,239
team

94
00:03:54,239 --> 00:03:57,000
I've hired really smart people

95
00:03:57,000 --> 00:03:58,739
so obviously they're making the right

96
00:03:58,739 --> 00:04:02,159
decisions they're doing the right things

97
00:04:02,159 --> 00:04:04,319
when it comes to technology

98
00:04:04,319 --> 00:04:07,739
we've spent so much in fact I made it a

99
00:04:07,739 --> 00:04:10,260
point to walk the Expo floor at RSA and

100
00:04:10,260 --> 00:04:12,480
I bought one of every single shiny

101
00:04:12,480 --> 00:04:15,120
Blinky box they have so surely

102
00:04:15,120 --> 00:04:16,620
we're in a good shape from a technology

103
00:04:16,620 --> 00:04:17,760
perspective

104
00:04:17,760 --> 00:04:21,358
right and surely those things work

105
00:04:21,358 --> 00:04:23,400
from my metrics perspective

106
00:04:23,400 --> 00:04:25,800
well I have comprehensive metrics that

107
00:04:25,800 --> 00:04:28,560
I'm tracking I'm measuring my security

108
00:04:28,560 --> 00:04:31,380
I'm doing assessments on a regular basis

109
00:04:31,380 --> 00:04:34,620
I'm collecting numbers and figures and

110
00:04:34,620 --> 00:04:36,240
charts

111
00:04:36,240 --> 00:04:37,979
so I'll know when security is not

112
00:04:37,979 --> 00:04:42,660
working as I intend for it to work oh

113
00:04:42,660 --> 00:04:45,540
those alerts yeah that's just noise we

114
00:04:45,540 --> 00:04:46,919
just acknowledge those and move on we

115
00:04:46,919 --> 00:04:48,479
don't really pay attention to those but

116
00:04:48,479 --> 00:04:51,240
otherwise I will know

117
00:04:51,240 --> 00:04:53,040
when I miss something or something isn't

118
00:04:53,040 --> 00:04:56,400
working as it should right

119
00:04:56,400 --> 00:04:58,020
so in case you haven't picked up on my

120
00:04:58,020 --> 00:05:00,000
sarcasm there are some issues here in

121
00:05:00,000 --> 00:05:02,400
how we think about technology in cyber

122
00:05:02,400 --> 00:05:04,199
defense how we think about

123
00:05:04,199 --> 00:05:06,240
our teams and how they collaborate and

124
00:05:06,240 --> 00:05:08,400
work together how we measure and track

125
00:05:08,400 --> 00:05:10,680
the work that we're doing on a daily

126
00:05:10,680 --> 00:05:12,360
basis so let's dig into some of those

127
00:05:12,360 --> 00:05:14,699
starting with teamwork are you an

128
00:05:14,699 --> 00:05:16,860
effective team does anyone get this meme

129
00:05:16,860 --> 00:05:19,259
one of my favorite Sci-Fi movies of all

130
00:05:19,259 --> 00:05:21,120
time Oblivion it's awesome you should

131
00:05:21,120 --> 00:05:22,680
check it out but

132
00:05:22,680 --> 00:05:26,340
are we truly an effective team

133
00:05:26,340 --> 00:05:29,280
having an effective team

134
00:05:29,280 --> 00:05:32,100
doesn't start and end with having smart

135
00:05:32,100 --> 00:05:34,500
capable people throwing them together

136
00:05:34,500 --> 00:05:36,419
and just kind of hoping that teamwork

137
00:05:36,419 --> 00:05:39,360
happens in a lot of cases it does happen

138
00:05:39,360 --> 00:05:41,039
because we're all relatively smart

139
00:05:41,039 --> 00:05:43,500
capable individuals at least all of us

140
00:05:43,500 --> 00:05:45,060
here are right I don't know about other

141
00:05:45,060 --> 00:05:48,060
people but we definitely are

142
00:05:48,060 --> 00:05:51,419
having really solid teamwork

143
00:05:51,419 --> 00:05:55,560
having spaces where we can share ideas

144
00:05:55,560 --> 00:05:58,199
and we can share skills kind of freely

145
00:05:58,199 --> 00:06:01,139
we can address gaps in each other's

146
00:06:01,139 --> 00:06:03,060
knowledge right that kind of effective

147
00:06:03,060 --> 00:06:05,400
collaboration it requires deliberate

148
00:06:05,400 --> 00:06:06,860
effort it doesn't just happen

149
00:06:06,860 --> 00:06:09,240
organically on its own

150
00:06:09,240 --> 00:06:12,660
or rather those team relationships

151
00:06:12,660 --> 00:06:15,180
don't form in a way that maximizes

152
00:06:15,180 --> 00:06:16,740
what's possible

153
00:06:16,740 --> 00:06:19,080
so just because I'm smart and you're

154
00:06:19,080 --> 00:06:20,639
smart and maybe we're doing good work

155
00:06:20,639 --> 00:06:23,039
individually doesn't necessarily mean

156
00:06:23,039 --> 00:06:25,800
that our team is effective as it could

157
00:06:25,800 --> 00:06:29,039
be in fact we're much more likely to go

158
00:06:29,039 --> 00:06:30,479
off track

159
00:06:30,479 --> 00:06:32,759
unless there is some deliberate effort

160
00:06:32,759 --> 00:06:36,120
and some intentionality in how our

161
00:06:36,120 --> 00:06:38,220
working relationships how our teams are

162
00:06:38,220 --> 00:06:40,800
built and cultivated meaning how we

163
00:06:40,800 --> 00:06:44,039
train together how we track

164
00:06:44,039 --> 00:06:46,560
our interactions how we govern our

165
00:06:46,560 --> 00:06:48,539
Communications these things have to be

166
00:06:48,539 --> 00:06:52,620
deliberate it requires work

167
00:06:52,620 --> 00:06:55,020
teamwork must be measured

168
00:06:55,020 --> 00:06:56,940
and we have to measure teamwork how do

169
00:06:56,940 --> 00:06:58,380
you measure teamwork it seems kind of

170
00:06:58,380 --> 00:07:00,240
weird

171
00:07:00,240 --> 00:07:03,000
just as we would capture metrics on the

172
00:07:03,000 --> 00:07:05,460
alerts that we're investigating on the

173
00:07:05,460 --> 00:07:08,340
cases we're opening uh on the response

174
00:07:08,340 --> 00:07:10,139
that we're executing we need to capture

175
00:07:10,139 --> 00:07:13,440
metrics on team interactions remember

176
00:07:13,440 --> 00:07:16,560
incident response cyber defense it's

177
00:07:16,560 --> 00:07:19,259
very much a team sport and I could be

178
00:07:19,259 --> 00:07:21,360
the most capable responder capable

179
00:07:21,360 --> 00:07:22,680
analyst

180
00:07:22,680 --> 00:07:25,259
in the entire organization

181
00:07:25,259 --> 00:07:28,139
I'm still not going to be able to fully

182
00:07:28,139 --> 00:07:30,060
contain eradicate recover from an

183
00:07:30,060 --> 00:07:32,099
incident all by myself

184
00:07:32,099 --> 00:07:34,139
I'm going to rely on other members of my

185
00:07:34,139 --> 00:07:34,860
team

186
00:07:34,860 --> 00:07:37,560
my team is going to rely on other groups

187
00:07:37,560 --> 00:07:38,759
and other functions within the

188
00:07:38,759 --> 00:07:41,699
organization to make changes right

189
00:07:41,699 --> 00:07:44,160
contain the damage

190
00:07:44,160 --> 00:07:46,139
recover those systems to normal working

191
00:07:46,139 --> 00:07:47,160
order

192
00:07:47,160 --> 00:07:49,620
so we have to track

193
00:07:49,620 --> 00:07:51,840
plan track and measure those

194
00:07:51,840 --> 00:07:53,940
interactions in that collaboration to

195
00:07:53,940 --> 00:07:55,080
make sure that it's happening as

196
00:07:55,080 --> 00:07:57,240
smoothly as it needs to in those crisis

197
00:07:57,240 --> 00:07:59,039
situations

198
00:07:59,039 --> 00:08:02,639
finally remember teamwork is a task work

199
00:08:02,639 --> 00:08:06,060
just because individuals are really good

200
00:08:06,060 --> 00:08:08,960
at doing certain tasks by themselves

201
00:08:08,960 --> 00:08:11,460
again doesn't mean that the team is

202
00:08:11,460 --> 00:08:14,280
going to come together in gel

203
00:08:14,280 --> 00:08:16,620
and that those individuals who are great

204
00:08:16,620 --> 00:08:19,139
individual contributors are also going

205
00:08:19,139 --> 00:08:21,960
to be good teammates I know this comes

206
00:08:21,960 --> 00:08:23,340
as a shock

207
00:08:23,340 --> 00:08:25,620
to all of you that really smart capable

208
00:08:25,620 --> 00:08:28,259
technical people don't always work

209
00:08:28,259 --> 00:08:30,479
really well as part of a group I know

210
00:08:30,479 --> 00:08:33,779
talking about other people not us okay

211
00:08:33,779 --> 00:08:36,179
certainly other people

212
00:08:36,179 --> 00:08:39,000
why does this happen why does this

213
00:08:39,000 --> 00:08:41,120
require deliverable deliberate Focus

214
00:08:41,120 --> 00:08:43,979
especially in cyber security and cyber

215
00:08:43,979 --> 00:08:46,980
defense let me clue you in on kind of a

216
00:08:46,980 --> 00:08:50,700
not so secret secret in security teams

217
00:08:50,700 --> 00:08:52,880
one there's a lot of what we call

218
00:08:52,880 --> 00:08:55,920
egocentrism in cyber security

219
00:08:55,920 --> 00:08:58,920
okay not talking about being egotistical

220
00:08:58,920 --> 00:09:00,839
that's a different thing

221
00:09:00,839 --> 00:09:02,760
surely not a problem in our industry

222
00:09:02,760 --> 00:09:05,940
right but egocentrism this feeling that

223
00:09:05,940 --> 00:09:08,640
I'm capable I'm smart I can handle this

224
00:09:08,640 --> 00:09:10,740
on my own I'm going to tackle this

225
00:09:10,740 --> 00:09:12,899
investigation by myself I'm going to

226
00:09:12,899 --> 00:09:17,100
respond to this incident by myself

227
00:09:17,100 --> 00:09:19,200
there's a lot of that going on

228
00:09:19,200 --> 00:09:21,240
and oftentimes our teams are kind of set

229
00:09:21,240 --> 00:09:24,000
up to encourage that mentality how many

230
00:09:24,000 --> 00:09:26,220
times have you been in an investigation

231
00:09:26,220 --> 00:09:28,019
or an instant response and you've got

232
00:09:28,019 --> 00:09:30,200
that really capable really knowledgeable

233
00:09:30,200 --> 00:09:33,420
teammate that jumps in and starts

234
00:09:33,420 --> 00:09:36,540
running the entire effort

235
00:09:36,540 --> 00:09:38,399
do you find that you're able to keep up

236
00:09:38,399 --> 00:09:39,959
and collaborate effectively with that

237
00:09:39,959 --> 00:09:42,120
person or do you kind of step away say

238
00:09:42,120 --> 00:09:44,640
oh so-and-so has got it they're always

239
00:09:44,640 --> 00:09:46,019
the one that kind of drives these things

240
00:09:46,019 --> 00:09:48,120
so I'm just going to step back I don't

241
00:09:48,120 --> 00:09:50,279
know as much as they do I can't do what

242
00:09:50,279 --> 00:09:52,500
they can do and we're just gonna let

243
00:09:52,500 --> 00:09:53,700
them kind of run with it because they're

244
00:09:53,700 --> 00:09:55,560
the loudest voice in the room okay a lot

245
00:09:55,560 --> 00:09:58,440
of egocentrism and security

246
00:09:58,440 --> 00:10:00,899
cyber security is a complex set of

247
00:10:00,899 --> 00:10:03,420
problems really complex ecosystem

248
00:10:03,420 --> 00:10:07,019
complex set of problems no one person

249
00:10:07,019 --> 00:10:08,640
is going to have all of the the

250
00:10:08,640 --> 00:10:10,320
knowledge share the Mind share required

251
00:10:10,320 --> 00:10:13,740
to solve all elements of those problems

252
00:10:13,740 --> 00:10:15,420
okay if I have a problem in my cloud

253
00:10:15,420 --> 00:10:18,779
environment I as a security analyst or

254
00:10:18,779 --> 00:10:21,360
as a system administrator or as a

255
00:10:21,360 --> 00:10:23,899
responder or an engineer

256
00:10:23,899 --> 00:10:26,940
requires a team coming together in order

257
00:10:26,940 --> 00:10:29,580
to effectively remediate that issue and

258
00:10:29,580 --> 00:10:30,959
to that point

259
00:10:30,959 --> 00:10:32,940
incident response cyber security

260
00:10:32,940 --> 00:10:35,820
consists of these multi-team systems

261
00:10:35,820 --> 00:10:38,580
it's not just one team

262
00:10:38,580 --> 00:10:40,560
it's multiple different teams that have

263
00:10:40,560 --> 00:10:43,380
to work together effectively

264
00:10:43,380 --> 00:10:46,920
to execute that effective defense

265
00:10:46,920 --> 00:10:49,860
okay these different issues these

266
00:10:49,860 --> 00:10:52,320
different problems intersect

267
00:10:52,320 --> 00:10:54,959
and result in ineffective teams

268
00:10:54,959 --> 00:10:57,480
ineffective teams

269
00:10:57,480 --> 00:10:59,519
so we have to address these issues we

270
00:10:59,519 --> 00:11:01,920
want to incentivize and motivate

271
00:11:01,920 --> 00:11:04,860
solid effective teamwork

272
00:11:04,860 --> 00:11:06,779
we want to create psychological safety

273
00:11:06,779 --> 00:11:08,399
within our teams

274
00:11:08,399 --> 00:11:10,140
someone disagrees with the way we're

275
00:11:10,140 --> 00:11:12,240
doing something as something to bring

276
00:11:12,240 --> 00:11:14,399
into the process we want to create an

277
00:11:14,399 --> 00:11:16,380
environment where those new ideas and

278
00:11:16,380 --> 00:11:18,800
those sometimes conflicting perspectives

279
00:11:18,800 --> 00:11:21,300
are welcome and they're part of the

280
00:11:21,300 --> 00:11:22,260
process

281
00:11:22,260 --> 00:11:23,940
in doing that we want to cultivate

282
00:11:23,940 --> 00:11:26,519
autonomy belonging

283
00:11:26,519 --> 00:11:29,760
competence people want to feel confident

284
00:11:29,760 --> 00:11:31,740
that they're able to add to the

285
00:11:31,740 --> 00:11:33,720
discussion Be an Effective and

286
00:11:33,720 --> 00:11:35,820
productive part of the team

287
00:11:35,820 --> 00:11:38,820
so how can we do this

288
00:11:38,820 --> 00:11:41,160
one of the things that we can do

289
00:11:41,160 --> 00:11:43,320
in a very tactical sort of way

290
00:11:43,320 --> 00:11:46,320
to track and measure the collaboration

291
00:11:46,320 --> 00:11:48,320
that's happening is putting together

292
00:11:48,320 --> 00:11:50,940
something like this this is a multi-team

293
00:11:50,940 --> 00:11:53,700
system diagram it's how we can plan and

294
00:11:53,700 --> 00:11:55,560
track collaboration not only within our

295
00:11:55,560 --> 00:11:57,959
own team but between our teams and other

296
00:11:57,959 --> 00:11:59,940
teams in our instant response

297
00:11:59,940 --> 00:12:01,740
organization this comes from some

298
00:12:01,740 --> 00:12:04,860
research done by Dr Daniel Shore

299
00:12:04,860 --> 00:12:07,920
who's a behavioral scientist and a

300
00:12:07,920 --> 00:12:10,980
founding member member of a firm called

301
00:12:10,980 --> 00:12:14,220
let's we can they're focused on teamwork

302
00:12:14,220 --> 00:12:15,540
and training and a lot of the things

303
00:12:15,540 --> 00:12:18,300
that I'm talking about here right but Dr

304
00:12:18,300 --> 00:12:20,060
Short and his team created this model

305
00:12:20,060 --> 00:12:23,100
essentially as a very simple way

306
00:12:23,100 --> 00:12:25,980
to identify and track relationships and

307
00:12:25,980 --> 00:12:28,560
team interaction in this case during

308
00:12:28,560 --> 00:12:30,839
security incidents so you can see here

309
00:12:30,839 --> 00:12:33,360
in this diagram we have a few different

310
00:12:33,360 --> 00:12:35,519
functional groups we have our Watch Team

311
00:12:35,519 --> 00:12:37,800
our threat intelligence team engineering

312
00:12:37,800 --> 00:12:40,140
team and so forth and we're using these

313
00:12:40,140 --> 00:12:41,279
arrows

314
00:12:41,279 --> 00:12:43,320
to track how much interaction happens

315
00:12:43,320 --> 00:12:45,839
between these teams in these crisis

316
00:12:45,839 --> 00:12:48,540
scenarios so for example here the watch

317
00:12:48,540 --> 00:12:50,579
team in the engineering team always work

318
00:12:50,579 --> 00:12:52,620
together very closely and very often

319
00:12:52,620 --> 00:12:55,139
during incidents the watch team and the

320
00:12:55,139 --> 00:12:58,620
Intel team and the IR team also work

321
00:12:58,620 --> 00:13:01,139
pretty often together

322
00:13:01,139 --> 00:13:03,660
the Intel team and the pr Communications

323
00:13:03,660 --> 00:13:06,120
team maybe not so much but there needs

324
00:13:06,120 --> 00:13:07,980
to be some kind of relationship some

325
00:13:07,980 --> 00:13:09,959
kind of contact there

326
00:13:09,959 --> 00:13:12,779
so we can map out these relationships

327
00:13:12,779 --> 00:13:15,180
and these interactions and we can use

328
00:13:15,180 --> 00:13:17,339
this to guide how often these teams

329
00:13:17,339 --> 00:13:19,139
train together

330
00:13:19,139 --> 00:13:21,600
what kind of trust needs to be built

331
00:13:21,600 --> 00:13:23,040
within these teams what kind of cross

332
00:13:23,040 --> 00:13:25,260
training we need to do maybe what kind

333
00:13:25,260 --> 00:13:27,300
of shadowing we need to do between these

334
00:13:27,300 --> 00:13:28,200
teams

335
00:13:28,200 --> 00:13:31,639
do our processes and our tools support

336
00:13:31,639 --> 00:13:34,560
this really busy high level of

337
00:13:34,560 --> 00:13:36,060
interaction between these teams that

338
00:13:36,060 --> 00:13:39,180
we've mapped out here so again just a

339
00:13:39,180 --> 00:13:42,000
simple useful way to deliberately plan

340
00:13:42,000 --> 00:13:45,120
out collaboration and not just tell

341
00:13:45,120 --> 00:13:47,339
yourself that you think the teams are

342
00:13:47,339 --> 00:13:49,079
working well together when the reality

343
00:13:49,079 --> 00:13:51,300
you have no idea right we want to get to

344
00:13:51,300 --> 00:13:53,940
ground truth on that this is a good way

345
00:13:53,940 --> 00:13:57,000
to start down that path

346
00:13:57,000 --> 00:14:01,019
we can also use Frameworks like the nice

347
00:14:01,019 --> 00:14:02,360
framework

348
00:14:02,360 --> 00:14:05,880
developed by nist and

349
00:14:05,880 --> 00:14:07,320
constituents of the the federal

350
00:14:07,320 --> 00:14:10,320
government to Define job roles Define

351
00:14:10,320 --> 00:14:12,839
competencies tasks

352
00:14:12,839 --> 00:14:15,360
Knowledge and Skills required for those

353
00:14:15,360 --> 00:14:16,860
job roles

354
00:14:16,860 --> 00:14:18,899
essentially coming up with a set of

355
00:14:18,899 --> 00:14:20,399
building blocks to say you know what

356
00:14:20,399 --> 00:14:22,079
it's not enough just to hire really

357
00:14:22,079 --> 00:14:25,380
smart capable people I've seen way too

358
00:14:25,380 --> 00:14:28,139
many really smart capable people put

359
00:14:28,139 --> 00:14:30,720
into roles that don't match their skill

360
00:14:30,720 --> 00:14:32,940
set don't match their

361
00:14:32,940 --> 00:14:35,160
career goals right what they're

362
00:14:35,160 --> 00:14:38,420
interested in what they want to do

363
00:14:38,700 --> 00:14:40,440
so we can use

364
00:14:40,440 --> 00:14:43,579
models like the nice framework to write

365
00:14:43,579 --> 00:14:48,060
specific objective repeatable

366
00:14:48,060 --> 00:14:50,040
role descriptions with very clear

367
00:14:50,040 --> 00:14:51,600
knowledge and skill statements you have

368
00:14:51,600 --> 00:14:53,399
to know the you have to be able to do

369
00:14:53,399 --> 00:14:55,380
these things here's how it's going to

370
00:14:55,380 --> 00:14:58,019
translate into doing the actual work to

371
00:14:58,019 --> 00:15:00,180
make sure that our candidates our people

372
00:15:00,180 --> 00:15:02,459
our talent and the roles that they're

373
00:15:02,459 --> 00:15:04,500
filling the work that they're doing are

374
00:15:04,500 --> 00:15:07,079
well aligned nice framework if you're

375
00:15:07,079 --> 00:15:09,300
less familiar with it I put a link in

376
00:15:09,300 --> 00:15:10,980
this slide to the nist publication that

377
00:15:10,980 --> 00:15:13,079
describes it really really great

378
00:15:13,079 --> 00:15:15,500
resource not only for writing those

379
00:15:15,500 --> 00:15:18,000
objective comprehensive role

380
00:15:18,000 --> 00:15:20,220
descriptions also really good for

381
00:15:20,220 --> 00:15:21,959
building training plans

382
00:15:21,959 --> 00:15:24,540
so if you have folks on your team or you

383
00:15:24,540 --> 00:15:26,579
yourself feel like you're lacking

384
00:15:26,579 --> 00:15:28,800
specific knowledge

385
00:15:28,800 --> 00:15:31,380
or certain skills technical skills to do

386
00:15:31,380 --> 00:15:33,480
the job effectively we can identify

387
00:15:33,480 --> 00:15:35,339
those gaps come up with training

388
00:15:35,339 --> 00:15:38,519
Solutions or training plans to help

389
00:15:38,519 --> 00:15:42,000
as opposed to simply saying I mean I'm

390
00:15:42,000 --> 00:15:44,699
an okay analyst but you know I think I

391
00:15:44,699 --> 00:15:46,320
could really be a much better sock

392
00:15:46,320 --> 00:15:49,560
analyst if I you know take that

393
00:15:49,560 --> 00:15:51,839
underwater basket weaving training class

394
00:15:51,839 --> 00:15:53,579
you know because that really interests

395
00:15:53,579 --> 00:15:56,220
me uh maybe maybe not

396
00:15:56,220 --> 00:15:58,139
but by using standard Frameworks like

397
00:15:58,139 --> 00:15:59,760
nice we can make sure that those

398
00:15:59,760 --> 00:16:01,740
requirements and the requirements of the

399
00:16:01,740 --> 00:16:05,160
job what you really want to do what the

400
00:16:05,160 --> 00:16:07,260
job requires you to do that those are

401
00:16:07,260 --> 00:16:09,240
all lined up and again we're not just

402
00:16:09,240 --> 00:16:10,740
hoping that by throwing smart people at

403
00:16:10,740 --> 00:16:12,360
the problem things will magically get

404
00:16:12,360 --> 00:16:14,699
solved and our cyber defense

405
00:16:14,699 --> 00:16:17,339
ultimately becomes more effective

406
00:16:17,339 --> 00:16:19,980
very little deliberate effort

407
00:16:19,980 --> 00:16:21,839
so let's talk truth here about some

408
00:16:21,839 --> 00:16:24,839
technology right technology surely there

409
00:16:24,839 --> 00:16:26,459
are no half truths or lies about

410
00:16:26,459 --> 00:16:28,560
technology in our sector right or in our

411
00:16:28,560 --> 00:16:30,300
industry

412
00:16:30,300 --> 00:16:32,339
the truth about technology

413
00:16:32,339 --> 00:16:35,279
is that tools won't stop a skilled

414
00:16:35,279 --> 00:16:39,180
adversary if you think Uber did not

415
00:16:39,180 --> 00:16:41,399
purchase any security infrastructure or

416
00:16:41,399 --> 00:16:43,440
security tools

417
00:16:43,440 --> 00:16:45,120
probably wouldn't want to place money on

418
00:16:45,120 --> 00:16:46,860
that bet

419
00:16:46,860 --> 00:16:50,040
your security much like their security

420
00:16:50,040 --> 00:16:54,300
will be defeated by poor I.T governance

421
00:16:54,300 --> 00:16:55,920
creative adversaries who have

422
00:16:55,920 --> 00:16:57,779
anticipated how you're defending the

423
00:16:57,779 --> 00:16:59,279
environment or not defending it and

424
00:16:59,279 --> 00:17:01,320
they're going to exploit those

425
00:17:01,320 --> 00:17:03,420
weaknesses right it's not just about

426
00:17:03,420 --> 00:17:06,000
having that fancy Blinky box in fact

427
00:17:06,000 --> 00:17:08,760
sometimes having the fancy Blinky box

428
00:17:08,760 --> 00:17:12,720
can put you in a really bad spot where

429
00:17:12,720 --> 00:17:14,040
you think your security is a lot better

430
00:17:14,040 --> 00:17:17,400
than it really is we invest in tools

431
00:17:17,400 --> 00:17:20,160
because it's easier than i t governance

432
00:17:20,160 --> 00:17:21,959
Real Talk folks

433
00:17:21,959 --> 00:17:27,319
eliminating Rogue I.T or Shadow tea

434
00:17:27,799 --> 00:17:31,080
buying that stuff's hard

435
00:17:31,080 --> 00:17:33,600
can't I just buy a security tool instead

436
00:17:33,600 --> 00:17:35,160
right

437
00:17:35,160 --> 00:17:37,440
now maybe that's a little bit unfair but

438
00:17:37,440 --> 00:17:39,120
that is the prevailing mindset in a lot

439
00:17:39,120 --> 00:17:40,620
of organizations that haven't yet

440
00:17:40,620 --> 00:17:42,660
tackled many of these fundamental

441
00:17:42,660 --> 00:17:45,299
governance issues but think that because

442
00:17:45,299 --> 00:17:46,380
they've invested in security

443
00:17:46,380 --> 00:17:48,059
infrastructure and security tools

444
00:17:48,059 --> 00:17:50,100
they're solving a lot of their problems

445
00:17:50,100 --> 00:17:52,500
and as we know as we've recently seen

446
00:17:52,500 --> 00:17:55,080
that just isn't the case so what do we

447
00:17:55,080 --> 00:17:57,539
do about that how can we be a little bit

448
00:17:57,539 --> 00:17:59,580
more honest with ourselves

449
00:17:59,580 --> 00:18:01,860
cut through some of those half truths

450
00:18:01,860 --> 00:18:04,740
get technology that really works for us

451
00:18:04,740 --> 00:18:06,240
well first off

452
00:18:06,240 --> 00:18:07,799
technology starts and ends with

453
00:18:07,799 --> 00:18:09,660
requirements right we want to have a

454
00:18:09,660 --> 00:18:11,820
plan for our technology

455
00:18:11,820 --> 00:18:14,400
our tools should enable our teams to

456
00:18:14,400 --> 00:18:16,440
fulfill their Charter meet the

457
00:18:16,440 --> 00:18:18,240
requirements of the organization

458
00:18:18,240 --> 00:18:20,760
we don't start with a fancy tool

459
00:18:20,760 --> 00:18:22,740
and then figure out how we can use it

460
00:18:22,740 --> 00:18:25,440
build our processes around that no

461
00:18:25,440 --> 00:18:28,140
we have a need we have a thing that

462
00:18:28,140 --> 00:18:30,299
we're trying to do right detect threats

463
00:18:30,299 --> 00:18:33,240
at the network layer detect threats you

464
00:18:33,240 --> 00:18:34,980
know post exploitation activities at the

465
00:18:34,980 --> 00:18:37,620
endpoint what technology lets us do that

466
00:18:37,620 --> 00:18:40,740
more effectively and in a scalable way

467
00:18:40,740 --> 00:18:42,600
we have to keep an eye on our capacity

468
00:18:42,600 --> 00:18:45,780
you can have 10 of the best tools in the

469
00:18:45,780 --> 00:18:48,840
world if you only have staff

470
00:18:48,840 --> 00:18:51,360
to Monitor and manage three of those

471
00:18:51,360 --> 00:18:52,320
tools

472
00:18:52,320 --> 00:18:54,000
you're over subscribed you have a

473
00:18:54,000 --> 00:18:56,039
capacity problem you're not going to be

474
00:18:56,039 --> 00:18:57,840
able to take full advantage of the

475
00:18:57,840 --> 00:18:59,700
technology that you're buying if you

476
00:18:59,700 --> 00:19:02,460
don't have the capacity to operate it

477
00:19:02,460 --> 00:19:05,039
finally when it comes to introducing new

478
00:19:05,039 --> 00:19:06,539
technology

479
00:19:06,539 --> 00:19:09,059
I'm a huge fan of Frameworks and

480
00:19:09,059 --> 00:19:13,140
processes I mean I'm a manager after all

481
00:19:13,140 --> 00:19:15,539
we want to adopt a repeatable process

482
00:19:15,539 --> 00:19:17,700
for introducing new technology miter's

483
00:19:17,700 --> 00:19:20,400
analysis of Alternatives or AOA process

484
00:19:20,400 --> 00:19:21,840
I've put a link here in this slide

485
00:19:21,840 --> 00:19:23,940
really really great process for that

486
00:19:23,940 --> 00:19:25,559
comes down to identifying your

487
00:19:25,559 --> 00:19:28,820
requirements or the opportunity

488
00:19:28,860 --> 00:19:30,780
I know what are the things that my tools

489
00:19:30,780 --> 00:19:33,240
need to do to meet those requirements

490
00:19:33,240 --> 00:19:35,700
let me look at multiple different tools

491
00:19:35,700 --> 00:19:38,340
that potentially check the boxes on that

492
00:19:38,340 --> 00:19:40,799
criteria compare pick the best one

493
00:19:40,799 --> 00:19:42,539
that's it

494
00:19:42,539 --> 00:19:45,179
that's it

495
00:19:45,179 --> 00:19:48,419
we can also

496
00:19:48,419 --> 00:19:50,400
take some lessons from other disciplines

497
00:19:50,400 --> 00:19:52,620
into security love doing this there's

498
00:19:52,620 --> 00:19:54,539
been some really great writing in the

499
00:19:54,539 --> 00:19:57,240
last couple of years by Anton Chewbacca

500
00:19:57,240 --> 00:19:59,220
and some other folks at Google and other

501
00:19:59,220 --> 00:20:00,539
places

502
00:20:00,539 --> 00:20:01,260
um

503
00:20:01,260 --> 00:20:03,780
about taking lessons and approaches from

504
00:20:03,780 --> 00:20:05,460
site reliability engineering SRE

505
00:20:05,460 --> 00:20:07,320
applying some of those principles and

506
00:20:07,320 --> 00:20:09,059
some of those techniques in cyber

507
00:20:09,059 --> 00:20:10,020
security

508
00:20:10,020 --> 00:20:12,360
a lot of this comes down to adopting an

509
00:20:12,360 --> 00:20:13,980
engineering first

510
00:20:13,980 --> 00:20:17,100
mindset insecurity with an eye towards

511
00:20:17,100 --> 00:20:19,380
making permanent improvements so tell me

512
00:20:19,380 --> 00:20:21,000
if you've heard this one before I stand

513
00:20:21,000 --> 00:20:23,460
up a sock I buy a bunch of tools I slam

514
00:20:23,460 --> 00:20:25,799
them in there I hire a bunch of people

515
00:20:25,799 --> 00:20:27,539
tools make noise

516
00:20:27,539 --> 00:20:29,880
people handle the noise and that just

517
00:20:29,880 --> 00:20:32,820
goes on in perpetuity

518
00:20:32,820 --> 00:20:34,559
and the people get burned out along the

519
00:20:34,559 --> 00:20:36,539
way and guess what I do

520
00:20:36,539 --> 00:20:39,120
I bring in more people they get burned

521
00:20:39,120 --> 00:20:41,160
out guess what I do then

522
00:20:41,160 --> 00:20:43,200
bring in more people you see where I'm

523
00:20:43,200 --> 00:20:45,299
going with this we want to think about

524
00:20:45,299 --> 00:20:49,260
what kind of improvements we can make

525
00:20:49,260 --> 00:20:51,919
hello

526
00:20:52,380 --> 00:20:55,500
and solvable

527
00:20:55,500 --> 00:20:59,160
reduce those male operations uh there's

528
00:20:59,160 --> 00:21:03,179
some really great there Google if you

529
00:21:03,179 --> 00:21:06,120
Google if you search for Google SRE if

530
00:21:06,120 --> 00:21:07,559
you're looking at Anton Chewbacca's blog

531
00:21:07,559 --> 00:21:09,059
posts on this topic there's lots of

532
00:21:09,059 --> 00:21:12,000
really good write-ups there on

533
00:21:12,000 --> 00:21:13,620
kind of the life cycle of automation

534
00:21:13,620 --> 00:21:16,919
which I've shown here in this slide and

535
00:21:16,919 --> 00:21:18,900
some of those SRE principles that we can

536
00:21:18,900 --> 00:21:20,400
bring into

537
00:21:20,400 --> 00:21:23,280
cyber Security apply with our technology

538
00:21:23,280 --> 00:21:24,900
eliminate some of that burnout

539
00:21:24,900 --> 00:21:26,520
repetitive work some of the things that

540
00:21:26,520 --> 00:21:28,860
we all kind of know our problems with

541
00:21:28,860 --> 00:21:30,840
some of our technology but we just sort

542
00:21:30,840 --> 00:21:33,299
of accept it we accept that we're just

543
00:21:33,299 --> 00:21:35,220
going to have to look at the same alerts

544
00:21:35,220 --> 00:21:38,280
ad nauseum to Infinity forever until we

545
00:21:38,280 --> 00:21:39,780
leave that job or get promoted out

546
00:21:39,780 --> 00:21:43,100
that's really not the way it should be

547
00:21:44,280 --> 00:21:46,919
let's talk about metrics for a bit

548
00:21:46,919 --> 00:21:48,780
I'll be kind and say there are some half

549
00:21:48,780 --> 00:21:51,600
truths and security metrics and I want

550
00:21:51,600 --> 00:21:54,840
you to take a look at these and let me

551
00:21:54,840 --> 00:21:56,520
know if any of these look familiar right

552
00:21:56,520 --> 00:21:57,960
that's rhetorical because this is a

553
00:21:57,960 --> 00:21:59,820
pre-recorded Talk and of course you can

554
00:21:59,820 --> 00:22:02,940
let me know in the Discord where

555
00:22:02,940 --> 00:22:05,640
present Mark is currently monitoring and

556
00:22:05,640 --> 00:22:07,620
answering questions I'm past Mark

557
00:22:07,620 --> 00:22:10,080
speaking to you now okay look at these

558
00:22:10,080 --> 00:22:12,240
metrics see if any of them look familiar

559
00:22:12,240 --> 00:22:14,520
for detected attacks

560
00:22:14,520 --> 00:22:16,679
we're tracking how many alerts our tools

561
00:22:16,679 --> 00:22:19,559
are generated how many uh incidents or

562
00:22:19,559 --> 00:22:21,240
tools have detected

563
00:22:21,240 --> 00:22:23,100
when it comes to analyst productivity

564
00:22:23,100 --> 00:22:24,600
we're looking at number of tickets

565
00:22:24,600 --> 00:22:27,120
opened how fast those tickets get closed

566
00:22:27,120 --> 00:22:28,860
the number of projects that we're

567
00:22:28,860 --> 00:22:30,659
working on it kind of shows our

568
00:22:30,659 --> 00:22:32,760
productivity level when it comes to

569
00:22:32,760 --> 00:22:34,559
vulnerabilities we're prioritizing

570
00:22:34,559 --> 00:22:36,559
patches

571
00:22:36,559 --> 00:22:40,980
based on CVSs score

572
00:22:40,980 --> 00:22:43,140
of those vulnerabilities

573
00:22:43,140 --> 00:22:46,020
when it comes to risk measurement

574
00:22:46,020 --> 00:22:48,539
we've got risk matrices where we're

575
00:22:48,539 --> 00:22:53,340
tracking attack Impact versus likelihood

576
00:22:53,340 --> 00:22:55,020
coming up with some calculations there

577
00:22:55,020 --> 00:22:57,380
well this all seems fine right

578
00:22:57,380 --> 00:23:01,140
maybe maybe not

579
00:23:01,140 --> 00:23:02,880
bottom line is security metrics are hard

580
00:23:02,880 --> 00:23:04,740
who knew

581
00:23:04,740 --> 00:23:07,200
think about our good friend the risk

582
00:23:07,200 --> 00:23:08,820
Matrix which I'm going to beat up on a

583
00:23:08,820 --> 00:23:11,039
little bit right now fair warning common

584
00:23:11,039 --> 00:23:13,559
mistakes here that we're making

585
00:23:13,559 --> 00:23:16,020
type errors right and that is something

586
00:23:16,020 --> 00:23:18,780
that is specific to the risk Matrix

587
00:23:18,780 --> 00:23:20,580
I want you all to come along on a

588
00:23:20,580 --> 00:23:23,640
journey with me as we walk through these

589
00:23:23,640 --> 00:23:27,539
values we express likelihood as a scale

590
00:23:27,539 --> 00:23:30,240
of very likely likely possible unlikely

591
00:23:30,240 --> 00:23:33,900
Etc and we express impact as

592
00:23:33,900 --> 00:23:36,780
non or negligible minor moderate severe

593
00:23:36,780 --> 00:23:39,840
significant Etc right

594
00:23:39,840 --> 00:23:43,320
so these are qualitative measures

595
00:23:43,320 --> 00:23:47,520
and we gauge these measures

596
00:23:47,520 --> 00:23:52,200
as low moderate high red yellow green

597
00:23:52,200 --> 00:23:55,380
these are not quantitative measures

598
00:23:55,380 --> 00:23:58,919
these are labels

599
00:23:58,919 --> 00:24:01,500
they're ordinals and nominals that we're

600
00:24:01,500 --> 00:24:04,320
using to basically sort things into

601
00:24:04,320 --> 00:24:08,039
buckets it's not true quantitative risk

602
00:24:08,039 --> 00:24:10,380
measurement we're saying well this thing

603
00:24:10,380 --> 00:24:13,919
is less likely to happen and if it does

604
00:24:13,919 --> 00:24:16,740
it's majorly impactful what even does

605
00:24:16,740 --> 00:24:18,240
that mean

606
00:24:18,240 --> 00:24:20,220
the way that I assess that is going to

607
00:24:20,220 --> 00:24:21,539
be different than the way you obsess

608
00:24:21,539 --> 00:24:24,539
that assess that excuse me it's not very

609
00:24:24,539 --> 00:24:27,480
objective and the problem really comes

610
00:24:27,480 --> 00:24:30,419
into play when we take what we assess

611
00:24:30,419 --> 00:24:32,039
for severe

612
00:24:32,039 --> 00:24:35,220
and we multiply that by very likely to

613
00:24:35,220 --> 00:24:37,980
get a overall an overall risk of high so

614
00:24:37,980 --> 00:24:40,860
we've basically taken

615
00:24:40,860 --> 00:24:44,820
an ordinal low medium high and we've

616
00:24:44,820 --> 00:24:47,460
multiplied that by another ordinal

617
00:24:47,460 --> 00:24:50,159
what is a High Times a low I don't know

618
00:24:50,159 --> 00:24:53,400
what's a yellow times a green

619
00:24:53,400 --> 00:24:56,400
that math can't meaningfully be done so

620
00:24:56,400 --> 00:24:57,720
the bottom line here is we're taking

621
00:24:57,720 --> 00:25:00,419
highly subjective measures highly

622
00:25:00,419 --> 00:25:02,700
subjective classifications we're doing

623
00:25:02,700 --> 00:25:04,919
meaningless math with them and we think

624
00:25:04,919 --> 00:25:07,640
that that gets us to a meaningful

625
00:25:07,640 --> 00:25:09,539
designation for what the risk is

626
00:25:09,539 --> 00:25:11,159
unfortunately things just don't really

627
00:25:11,159 --> 00:25:13,740
work that way

628
00:25:13,740 --> 00:25:15,720
so this is what's called a type error

629
00:25:15,720 --> 00:25:18,059
we're applying numeric labels we're just

630
00:25:18,059 --> 00:25:21,179
assigning numbers randomly to nominal or

631
00:25:21,179 --> 00:25:22,980
ordinal classifications and then we're

632
00:25:22,980 --> 00:25:24,659
trying to do computations based on that

633
00:25:24,659 --> 00:25:26,580
it can't be meaningfully be done

634
00:25:26,580 --> 00:25:28,620
another challenge that we often have

635
00:25:28,620 --> 00:25:30,600
when it comes to security metrics is

636
00:25:30,600 --> 00:25:32,460
this phenomenon called metrics fixation

637
00:25:32,460 --> 00:25:35,039
where we use metrics and numbers and

638
00:25:35,039 --> 00:25:36,360
data

639
00:25:36,360 --> 00:25:39,539
as a replacement for judgment

640
00:25:39,539 --> 00:25:41,340
an experience

641
00:25:41,340 --> 00:25:43,620
Talent

642
00:25:43,620 --> 00:25:45,900
we'll talk about why this happens here

643
00:25:45,900 --> 00:25:47,880
how we can avoid those type errors that

644
00:25:47,880 --> 00:25:49,919
I just described using the risk Matrix

645
00:25:49,919 --> 00:25:53,340
one use the right measurement scale

646
00:25:53,340 --> 00:25:55,919
if you want to have data if you want to

647
00:25:55,919 --> 00:25:57,840
have interval or ratio values you know

648
00:25:57,840 --> 00:25:59,760
zero one two three Etc

649
00:25:59,760 --> 00:26:01,620
design your metric that way from the

650
00:26:01,620 --> 00:26:03,659
beginning don't simply assign numbers

651
00:26:03,659 --> 00:26:05,940
because you think that it makes the

652
00:26:05,940 --> 00:26:08,279
metric sound more scientific it doesn't

653
00:26:08,279 --> 00:26:09,840
doesn't work

654
00:26:09,840 --> 00:26:12,299
if you are using ordinals like high

655
00:26:12,299 --> 00:26:15,120
medium low red yellow green whatever red

656
00:26:15,120 --> 00:26:17,220
yellow green would be a

657
00:26:17,220 --> 00:26:18,779
um

658
00:26:18,779 --> 00:26:19,919
nominal

659
00:26:19,919 --> 00:26:22,080
right if you're using those kinds of

660
00:26:22,080 --> 00:26:23,100
measures

661
00:26:23,100 --> 00:26:24,900
where there aren't numbers involved

662
00:26:24,900 --> 00:26:27,419
that's fine drop the numbers

663
00:26:27,419 --> 00:26:30,299
maybe create a mapping that says if this

664
00:26:30,299 --> 00:26:33,900
is a low likelihood right then do this

665
00:26:33,900 --> 00:26:35,700
don't throw numbers in there and

666
00:26:35,700 --> 00:26:38,059
complicate things and try to add math

667
00:26:38,059 --> 00:26:40,740
which doesn't work

668
00:26:40,740 --> 00:26:43,740
option three shift to True quantitative

669
00:26:43,740 --> 00:26:46,200
analysis there's a fantastic book which

670
00:26:46,200 --> 00:26:48,000
I'll reference at the end of the slide

671
00:26:48,000 --> 00:26:49,919
presentation how to measure

672
00:26:49,919 --> 00:26:51,600
anything in cyber security risk or

673
00:26:51,600 --> 00:26:53,760
everything in cyber security risk uh

674
00:26:53,760 --> 00:26:55,980
really fantastic reference for doing

675
00:26:55,980 --> 00:26:59,039
true quantitative analysis of cyber

676
00:26:59,039 --> 00:27:00,600
security risk highly recommend you check

677
00:27:00,600 --> 00:27:01,740
that out

678
00:27:01,740 --> 00:27:03,900
can we avoid this concept of metrics

679
00:27:03,900 --> 00:27:05,640
fixation where we essentially use

680
00:27:05,640 --> 00:27:08,039
numbers as a replacement for judgment

681
00:27:08,039 --> 00:27:10,440
you know everything has to satisfy the

682
00:27:10,440 --> 00:27:12,539
numbers it's a replacement for

683
00:27:12,539 --> 00:27:16,140
essentially effective management

684
00:27:16,140 --> 00:27:18,000
think about how you're using metrics in

685
00:27:18,000 --> 00:27:19,200
your teams today

686
00:27:19,200 --> 00:27:21,480
are those metrics how many alerts you

687
00:27:21,480 --> 00:27:24,960
looked at how fast you were how fast you

688
00:27:24,960 --> 00:27:26,880
were on your instant response okay are

689
00:27:26,880 --> 00:27:29,220
those being used

690
00:27:29,220 --> 00:27:31,559
as a diagnostic tool for practitioners

691
00:27:31,559 --> 00:27:33,299
or

692
00:27:33,299 --> 00:27:36,500
are they being used to assess penalties

693
00:27:36,500 --> 00:27:40,980
or incentives there are reams

694
00:27:40,980 --> 00:27:43,140
of research

695
00:27:43,140 --> 00:27:47,039
that point to any time

696
00:27:47,039 --> 00:27:49,559
metrics are used as the basis for a

697
00:27:49,559 --> 00:27:51,779
penalty or incentive guess what's going

698
00:27:51,779 --> 00:27:53,159
to happen people are going to game the

699
00:27:53,159 --> 00:27:54,840
system and there are countless examples

700
00:27:54,840 --> 00:27:58,200
of this from higher education to law

701
00:27:58,200 --> 00:28:00,960
enforcement to cyber security absolutely

702
00:28:00,960 --> 00:28:03,539
there's a great book on this which I'll

703
00:28:03,539 --> 00:28:05,520
reference at the end of the deck at the

704
00:28:05,520 --> 00:28:07,679
end of the talk here get inputs from the

705
00:28:07,679 --> 00:28:08,760
right people

706
00:28:08,760 --> 00:28:11,220
your practitioners your Defenders are

707
00:28:11,220 --> 00:28:13,260
only going to be on board

708
00:28:13,260 --> 00:28:15,419
they're going to be open to feedback if

709
00:28:15,419 --> 00:28:17,100
they really believe in the metrics how

710
00:28:17,100 --> 00:28:19,020
they're being measured and then finally

711
00:28:19,020 --> 00:28:21,179
recognize the limits of data we can't

712
00:28:21,179 --> 00:28:23,640
use metrics and data for everything

713
00:28:23,640 --> 00:28:27,419
okay so metrics should inform judgment

714
00:28:27,419 --> 00:28:29,039
they should demand judgment they

715
00:28:29,039 --> 00:28:32,480
shouldn't replace judgment

716
00:28:33,120 --> 00:28:35,039
why do we keep making these mistakes if

717
00:28:35,039 --> 00:28:37,260
these are you know not so secret secrets

718
00:28:37,260 --> 00:28:40,320
in cyber security why do we keep doing

719
00:28:40,320 --> 00:28:42,240
these things over and over and over

720
00:28:42,240 --> 00:28:44,640
again in some cases for over a decade

721
00:28:44,640 --> 00:28:47,279
we've been doing these things in cyber

722
00:28:47,279 --> 00:28:48,840
defense

723
00:28:48,840 --> 00:28:50,760
well first off

724
00:28:50,760 --> 00:28:53,640
it's easy to assume that correlation is

725
00:28:53,640 --> 00:28:54,840
causation

726
00:28:54,840 --> 00:28:57,240
if there are two things that

727
00:28:57,240 --> 00:29:00,179
seem kind of related may or may not be

728
00:29:00,179 --> 00:29:01,500
related

729
00:29:01,500 --> 00:29:03,840
we have what sounds like a really bad

730
00:29:03,840 --> 00:29:06,360
you know vulnerability and it's got a

731
00:29:06,360 --> 00:29:09,360
high cvsf score we automatically assume

732
00:29:09,360 --> 00:29:11,279
that maybe we have to prioritize that

733
00:29:11,279 --> 00:29:12,480
for patching

734
00:29:12,480 --> 00:29:14,640
before everything else

735
00:29:14,640 --> 00:29:16,620
and we assume that there's a causal

736
00:29:16,620 --> 00:29:18,600
relationship there

737
00:29:18,600 --> 00:29:19,440
um

738
00:29:19,440 --> 00:29:21,600
where maybe there isn't one

739
00:29:21,600 --> 00:29:23,880
the mere exposure effect

740
00:29:23,880 --> 00:29:25,679
wrist Matrix

741
00:29:25,679 --> 00:29:28,200
we see something over and over again we

742
00:29:28,200 --> 00:29:29,640
assume that that is just the right way

743
00:29:29,640 --> 00:29:32,340
to do it when really maybe not quite as

744
00:29:32,340 --> 00:29:35,520
meaningful as we think it is numbers

745
00:29:35,520 --> 00:29:37,799
make us feel safe and scientific they

746
00:29:37,799 --> 00:29:40,440
imply objectivity

747
00:29:40,440 --> 00:29:43,080
when maybe there isn't any

748
00:29:43,080 --> 00:29:46,260
finally data can sometimes be metrics

749
00:29:46,260 --> 00:29:48,419
can sometimes be an easy button in

750
00:29:48,419 --> 00:29:50,520
situations where we don't have domain

751
00:29:50,520 --> 00:29:52,320
expertise or we don't have a lot of

752
00:29:52,320 --> 00:29:54,360
experience

753
00:29:54,360 --> 00:29:56,640
has anyone ever been in a situation

754
00:29:56,640 --> 00:29:58,980
where you have a manager or an executive

755
00:29:58,980 --> 00:30:01,679
who's brand new doesn't have a lot of

756
00:30:01,679 --> 00:30:03,240
history or background maybe doesn't have

757
00:30:03,240 --> 00:30:05,279
domain expertise

758
00:30:05,279 --> 00:30:06,840
what's the first thing they want to do

759
00:30:06,840 --> 00:30:08,159
well I want to look at the numbers I

760
00:30:08,159 --> 00:30:09,539
want to make some decisions change some

761
00:30:09,539 --> 00:30:10,380
things

762
00:30:10,380 --> 00:30:11,940
show me you know how many incidents

763
00:30:11,940 --> 00:30:13,620
we've opened or

764
00:30:13,620 --> 00:30:15,059
how many vulnerabilities that we've

765
00:30:15,059 --> 00:30:16,620
patched right I just want to see the

766
00:30:16,620 --> 00:30:18,000
numbers I'll make decisions based on

767
00:30:18,000 --> 00:30:21,059
that that is an easy button

768
00:30:21,059 --> 00:30:23,460
and cognitively challenging situations

769
00:30:23,460 --> 00:30:26,520
where it's really tough to get up to

770
00:30:26,520 --> 00:30:29,299
speed or to get all the insights we need

771
00:30:29,299 --> 00:30:31,559
sometimes metrics unfortunately become

772
00:30:31,559 --> 00:30:33,840
that easy button and it's not just for

773
00:30:33,840 --> 00:30:36,240
managers and Executives right we all do

774
00:30:36,240 --> 00:30:38,880
it but we should

775
00:30:38,880 --> 00:30:41,760
so how do we get on a path to more

776
00:30:41,760 --> 00:30:44,340
honest measurement

777
00:30:44,340 --> 00:30:47,220
first we start with top down alignment

778
00:30:47,220 --> 00:30:49,740
so think about our goals and our

779
00:30:49,740 --> 00:30:52,260
objectives for the security team

780
00:30:52,260 --> 00:30:53,940
what services are we offering to the

781
00:30:53,940 --> 00:30:55,260
organization

782
00:30:55,260 --> 00:30:57,840
what results do we need to see

783
00:30:57,840 --> 00:30:59,460
to know whether or not we're successful

784
00:30:59,460 --> 00:31:01,500
as a security team

785
00:31:01,500 --> 00:31:04,620
are we meeting our commitments

786
00:31:04,620 --> 00:31:07,520
We Gather our metrics using consistent

787
00:31:07,520 --> 00:31:11,240
measurement without subjective criteria

788
00:31:11,240 --> 00:31:13,799
preferably in some cheap you know

789
00:31:13,799 --> 00:31:17,340
automated or semi-automated way

790
00:31:17,340 --> 00:31:20,580
use that data as an indicator of how

791
00:31:20,580 --> 00:31:22,740
things are working not as a method of

792
00:31:22,740 --> 00:31:23,700
control

793
00:31:23,700 --> 00:31:25,679
unfortunately we're gonna have to use

794
00:31:25,679 --> 00:31:27,720
judgment we're gonna have to manage

795
00:31:27,720 --> 00:31:28,620
things

796
00:31:28,620 --> 00:31:30,960
you can't just rely only on the data

797
00:31:30,960 --> 00:31:33,000
doesn't tell the entire story in all

798
00:31:33,000 --> 00:31:34,020
cases

799
00:31:34,020 --> 00:31:36,059
finally any metrics that we're using

800
00:31:36,059 --> 00:31:38,220
that we're tracking for our teams have

801
00:31:38,220 --> 00:31:39,840
to be expressed with at least one unit

802
00:31:39,840 --> 00:31:41,240
of measure

803
00:31:41,240 --> 00:31:44,100
percentage hours dollars that is the

804
00:31:44,100 --> 00:31:45,840
path to True quantitative risk

805
00:31:45,840 --> 00:31:47,600
assessment and not just

806
00:31:47,600 --> 00:31:51,120
feels like that's a high feels like it's

807
00:31:51,120 --> 00:31:52,860
moderately likely

808
00:31:52,860 --> 00:31:55,320
may be kind of impactful right that's

809
00:31:55,320 --> 00:31:58,520
not particularly useful

810
00:31:58,919 --> 00:32:01,320
one example of coming up with meaningful

811
00:32:01,320 --> 00:32:03,600
metrics or one approach is the goal

812
00:32:03,600 --> 00:32:06,840
question metric processor gqms pioneered

813
00:32:06,840 --> 00:32:08,640
originally in software development

814
00:32:08,640 --> 00:32:09,840
projects

815
00:32:09,840 --> 00:32:11,340
essentially

816
00:32:11,340 --> 00:32:14,700
it is a way to come up with

817
00:32:14,700 --> 00:32:17,580
useful metrics that are traceable to

818
00:32:17,580 --> 00:32:19,080
high level goals or objectives and

819
00:32:19,080 --> 00:32:20,760
here's how this works

820
00:32:20,760 --> 00:32:22,320
let's say one of the goals of your

821
00:32:22,320 --> 00:32:24,120
security team is minimizing the impacts

822
00:32:24,120 --> 00:32:26,220
of supply chain attacks so we want to

823
00:32:26,220 --> 00:32:28,020
come up with metrics that tell us

824
00:32:28,020 --> 00:32:30,539
whether or not we are in fact minimizing

825
00:32:30,539 --> 00:32:32,820
the impact of supply chain attacks

826
00:32:32,820 --> 00:32:35,460
so how do we do that first we take that

827
00:32:35,460 --> 00:32:39,059
goal we ask clarifying questions

828
00:32:39,059 --> 00:32:40,919
about that goal try to get to something

829
00:32:40,919 --> 00:32:42,720
very specific and measurable first off

830
00:32:42,720 --> 00:32:45,299
how do we Define supply chain attack are

831
00:32:45,299 --> 00:32:47,520
we talking about alerts of a certain

832
00:32:47,520 --> 00:32:50,399
type are we talking about

833
00:32:50,399 --> 00:32:53,460
new vulnerabilities or weaknesses that

834
00:32:53,460 --> 00:32:54,840
fall within a certain kind of

835
00:32:54,840 --> 00:32:56,159
classification

836
00:32:56,159 --> 00:32:58,260
do we have Telemetry do we have data and

837
00:32:58,260 --> 00:33:00,659
visibility to monitor for these kinds of

838
00:33:00,659 --> 00:33:02,159
threats

839
00:33:02,159 --> 00:33:04,500
what does that look like

840
00:33:04,500 --> 00:33:07,200
when we fail to minimize the impact of

841
00:33:07,200 --> 00:33:09,179
supply chain attacks what does that look

842
00:33:09,179 --> 00:33:10,620
like

843
00:33:10,620 --> 00:33:12,960
is there data or is there some tool or

844
00:33:12,960 --> 00:33:14,340
some report

845
00:33:14,340 --> 00:33:16,919
or I can identify those failures measure

846
00:33:16,919 --> 00:33:19,380
how often those occur

847
00:33:19,380 --> 00:33:21,600
so some metrics that answer these

848
00:33:21,600 --> 00:33:23,159
questions

849
00:33:23,159 --> 00:33:25,140
number of a search insertion attacks

850
00:33:25,140 --> 00:33:27,779
third party compromises right those are

851
00:33:27,779 --> 00:33:30,600
supply chain attack types tracked in our

852
00:33:30,600 --> 00:33:32,760
Incident Management System that is a

853
00:33:32,760 --> 00:33:35,279
measurable specific data point that I

854
00:33:35,279 --> 00:33:36,840
can capture

855
00:33:36,840 --> 00:33:38,460
what is the completion rate of my

856
00:33:38,460 --> 00:33:41,220
third-party attestations so it's not

857
00:33:41,220 --> 00:33:43,679
just about technical data Maybe I track

858
00:33:43,679 --> 00:33:45,720
third party you know questionnaires how

859
00:33:45,720 --> 00:33:47,460
I'm kind of tracking that that

860
00:33:47,460 --> 00:33:49,799
third-party supply chain risk the time

861
00:33:49,799 --> 00:33:52,200
to contain

862
00:33:52,200 --> 00:33:54,240
supply chain attacks third party

863
00:33:54,240 --> 00:33:56,399
compromises based on what's In My

864
00:33:56,399 --> 00:33:57,899
Incident Management System so now I've

865
00:33:57,899 --> 00:34:00,059
got three data points three metrics I

866
00:34:00,059 --> 00:34:02,399
can use answer my follow-up questions

867
00:34:02,399 --> 00:34:04,260
that tell me whether or not I'm

868
00:34:04,260 --> 00:34:06,120
achieving that goal minimizing the

869
00:34:06,120 --> 00:34:09,558
impacts of supply chain attacks

870
00:34:09,679 --> 00:34:12,899
taking this a little bit further

871
00:34:12,899 --> 00:34:15,659
do we have roles on our team think about

872
00:34:15,659 --> 00:34:17,760
the teamwork that we talked about right

873
00:34:17,760 --> 00:34:19,980
the Staffing we talked about

874
00:34:19,980 --> 00:34:22,080
cutting through some of that noise do we

875
00:34:22,080 --> 00:34:26,879
have roles skills knowledge required

876
00:34:26,879 --> 00:34:28,859
to identify and investigate those supply

877
00:34:28,859 --> 00:34:30,540
chain attacks do we even know a supply

878
00:34:30,540 --> 00:34:32,940
chain attack when we see it

879
00:34:32,940 --> 00:34:34,679
do we require some additional training

880
00:34:34,679 --> 00:34:36,418
to fill those gaps make sure we know

881
00:34:36,418 --> 00:34:39,618
what we're looking at looking for

882
00:34:40,020 --> 00:34:42,480
do our tools and our Telemetry enable us

883
00:34:42,480 --> 00:34:45,060
to identify and investigate these kinds

884
00:34:45,060 --> 00:34:46,918
of compromises

885
00:34:46,918 --> 00:34:48,960
are we using those supply chain metrics

886
00:34:48,960 --> 00:34:51,839
to support our judgment

887
00:34:51,839 --> 00:34:53,339
or are we using them as a replacement

888
00:34:53,339 --> 00:34:55,199
for our judgment are they helping us

889
00:34:55,199 --> 00:34:56,760
actually improve that's really the

890
00:34:56,760 --> 00:34:59,520
fundamental question here

891
00:34:59,520 --> 00:35:01,740
again this is the path to more honest

892
00:35:01,740 --> 00:35:03,960
metrics

893
00:35:03,960 --> 00:35:07,339
tying it all together

894
00:35:07,440 --> 00:35:08,880
think about why your security team

895
00:35:08,880 --> 00:35:10,200
exists

896
00:35:10,200 --> 00:35:12,480
start with those high-level goals and by

897
00:35:12,480 --> 00:35:14,700
the way the goals are not operate our

898
00:35:14,700 --> 00:35:18,060
sin Open tickets those are not goals

899
00:35:18,060 --> 00:35:19,740
what are you doing for the organization

900
00:35:19,740 --> 00:35:24,300
to enable it to operate free from Cyber

901
00:35:24,300 --> 00:35:26,700
attack or major outages due to Cyber

902
00:35:26,700 --> 00:35:28,560
attack right start with those high level

903
00:35:28,560 --> 00:35:30,480
security goals

904
00:35:30,480 --> 00:35:32,640
ask clarifying questions to understand

905
00:35:32,640 --> 00:35:35,099
what success looks like

906
00:35:35,099 --> 00:35:36,839
and then make sure that the roles of

907
00:35:36,839 --> 00:35:38,640
your team the tools you have the

908
00:35:38,640 --> 00:35:40,500
processes that you've developed make

909
00:35:40,500 --> 00:35:43,980
sure those all support those objectives

910
00:35:43,980 --> 00:35:45,780
make sure the team is working together

911
00:35:45,780 --> 00:35:48,900
effectively map out and track how your

912
00:35:48,900 --> 00:35:51,000
team works together internally and with

913
00:35:51,000 --> 00:35:52,920
other teams in this larger multi-team

914
00:35:52,920 --> 00:35:55,260
system create one of those MTS

915
00:35:55,260 --> 00:35:57,720
interaction diagrams

916
00:35:57,720 --> 00:36:00,359
use those maps to train to communicate

917
00:36:00,359 --> 00:36:02,339
build trust

918
00:36:02,339 --> 00:36:04,140
make sure that teamwork is happening

919
00:36:04,140 --> 00:36:05,640
effectively

920
00:36:05,640 --> 00:36:07,859
do your tools meet your requirements are

921
00:36:07,859 --> 00:36:09,900
they really doing the thing that you

922
00:36:09,900 --> 00:36:11,940
need that tool to do for you

923
00:36:11,940 --> 00:36:13,800
or are they just creating more busy work

924
00:36:13,800 --> 00:36:15,839
eating up your capacity

925
00:36:15,839 --> 00:36:19,800
Without Really solving any problems

926
00:36:19,800 --> 00:36:22,400
finally in your metrics for those of you

927
00:36:22,400 --> 00:36:25,020
manager leader types out there

928
00:36:25,020 --> 00:36:26,700
do you have the right metrics are you

929
00:36:26,700 --> 00:36:29,099
using them to diagnose problems to drive

930
00:36:29,099 --> 00:36:31,800
improvements or are you simply racking

931
00:36:31,800 --> 00:36:35,339
up a bunch of meaningless data

932
00:36:35,339 --> 00:36:36,839
to use as a replacement for good

933
00:36:36,839 --> 00:36:39,060
judgment good management

934
00:36:39,060 --> 00:36:40,200
that's how we bring some of these things

935
00:36:40,200 --> 00:36:42,359
together

936
00:36:42,359 --> 00:36:43,859
in summary

937
00:36:43,859 --> 00:36:45,660
look we're getting much better at Cyber

938
00:36:45,660 --> 00:36:46,800
defense

939
00:36:46,800 --> 00:36:49,380
by any number of measures we're getting

940
00:36:49,380 --> 00:36:51,960
better but we still have to be honest

941
00:36:51,960 --> 00:36:54,900
about systemic failures ineffective

942
00:36:54,900 --> 00:36:56,099
approaches things that aren't really

943
00:36:56,099 --> 00:36:57,660
working for us

944
00:36:57,660 --> 00:36:59,940
keeping requirements in mind starting

945
00:36:59,940 --> 00:37:02,280
and ending with requirements when your

946
00:37:02,280 --> 00:37:03,839
Staffing security when you're

947
00:37:03,839 --> 00:37:05,700
implementing new technology when you're

948
00:37:05,700 --> 00:37:07,619
measuring success it's absolutely

949
00:37:07,619 --> 00:37:09,839
critical

950
00:37:09,839 --> 00:37:13,140
do use existing models and Frameworks

951
00:37:13,140 --> 00:37:15,660
and processes to add transparency and

952
00:37:15,660 --> 00:37:19,640
consistency but don't rely on faulty

953
00:37:19,640 --> 00:37:22,920
deceptive less than honest approaches

954
00:37:22,920 --> 00:37:25,140
that obscure

955
00:37:25,140 --> 00:37:26,820
hide

956
00:37:26,820 --> 00:37:28,440
those systemic issues or those

957
00:37:28,440 --> 00:37:31,040
bottlenecks

958
00:37:31,680 --> 00:37:33,839
some references for some of the things

959
00:37:33,839 --> 00:37:36,119
that I've covered in this talk

960
00:37:36,119 --> 00:37:37,980
again how to measure anything in cyber

961
00:37:37,980 --> 00:37:39,540
security risk

962
00:37:39,540 --> 00:37:42,420
fantastic book by Douglas Hubbard

963
00:37:42,420 --> 00:37:44,839
Richard syerson the tyranny of metrics

964
00:37:44,839 --> 00:37:47,400
uh really short kind of quick read by

965
00:37:47,400 --> 00:37:49,740
Jerry Mueller a really great book on

966
00:37:49,740 --> 00:37:51,599
kind of misuses and unintended

967
00:37:51,599 --> 00:37:54,540
consequences of using data not specific

968
00:37:54,540 --> 00:37:56,339
to security but I think is very relevant

969
00:37:56,339 --> 00:37:58,200
for security and of course I'd be remiss

970
00:37:58,200 --> 00:38:00,780
if I didn't plug management 551 which

971
00:38:00,780 --> 00:38:02,460
goes into a lot of these Topics in far

972
00:38:02,460 --> 00:38:04,800
more detail than I've done here written

973
00:38:04,800 --> 00:38:06,780
by myself and John Hubbard

974
00:38:06,780 --> 00:38:08,579
with that

975
00:38:08,579 --> 00:38:10,079
I want to thank you all very much for

976
00:38:10,079 --> 00:38:11,700
attending my talk of course I want to

977
00:38:11,700 --> 00:38:13,200
thank the b-sides team for having me

978
00:38:13,200 --> 00:38:15,839
back again to do this talk if you have

979
00:38:15,839 --> 00:38:17,640
any questions or any comments I've been

980
00:38:17,640 --> 00:38:19,560
in the Discord Channel hopefully

981
00:38:19,560 --> 00:38:21,839
responding to those by now but uh

982
00:38:21,839 --> 00:38:23,820
certainly willing and happy to talk

983
00:38:23,820 --> 00:38:26,339
about more of this stuff in detail there

984
00:38:26,339 --> 00:38:28,920
so please feel free to reach out and

985
00:38:28,920 --> 00:38:30,540
thank you very much enjoy the rest of

986
00:38:30,540 --> 00:38:32,779
the show

987
00:48:05,700 --> 00:48:08,419
foreign

