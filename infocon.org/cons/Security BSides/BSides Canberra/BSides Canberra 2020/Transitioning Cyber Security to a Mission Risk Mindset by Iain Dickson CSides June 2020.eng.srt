1
00:00:02,179 --> 00:00:14,460
so our next talk tonight is in I just so

2
00:00:12,900 --> 00:00:21,470
you know the host may not amuse me

3
00:00:14,460 --> 00:00:23,689
Oh God we're being on the other side I

4
00:00:21,470 --> 00:00:27,710
think

5
00:00:23,689 --> 00:00:30,539
Sileo in was introducing Silvio for a

6
00:00:27,710 --> 00:00:32,759
comfy con right now but now Ann's

7
00:00:30,539 --> 00:00:34,620
presenting so ian is a data scientist

8
00:00:32,759 --> 00:00:36,510
who has fallen into the cyber profession

9
00:00:34,620 --> 00:00:39,059
he has previously worked as a

10
00:00:36,510 --> 00:00:41,579
cybersecurity research engineer and as a

11
00:00:39,059 --> 00:00:43,649
cyber threat intelligence technical lead

12
00:00:41,579 --> 00:00:45,300
for the Austrian government he is

13
00:00:43,649 --> 00:00:47,670
currently the cyber technical lead for

14
00:00:45,300 --> 00:00:50,459
Latos Australia leading cybersecurity

15
00:00:47,670 --> 00:00:53,210
projects across the organisation and

16
00:00:50,460 --> 00:00:56,760
he's also the founder and organizer of

17
00:00:53,210 --> 00:00:59,640
comfy con tonight he's going to talk to

18
00:00:56,760 --> 00:01:03,780
us about transitioning cyber security to

19
00:00:59,640 --> 00:01:06,540
a risk mission risk mindset also known

20
00:01:03,780 --> 00:01:10,310
as why the new is M is that are so a

21
00:01:06,540 --> 00:01:10,310
little bit of controversy in this talk

22
00:01:22,250 --> 00:01:26,030
[Laughter]

23
00:01:31,460 --> 00:01:35,630
so hopefully you guys can see my screen

24
00:01:36,590 --> 00:01:42,360
can someone confirm they can see my

25
00:01:38,759 --> 00:01:43,200
screen fantastic all right good evening

26
00:01:42,360 --> 00:01:45,299
everyone

27
00:01:43,200 --> 00:01:47,820
I'm gonna say a couple of things to

28
00:01:45,299 --> 00:01:51,659
start off with one as many blue team

29
00:01:47,820 --> 00:01:53,729
people are I'm sure I I'm very tired

30
00:01:51,659 --> 00:01:57,390
it's been a very busy day as I'm sure

31
00:01:53,729 --> 00:01:58,799
your day has also been but in in in some

32
00:01:57,390 --> 00:02:00,420
ways it's been a good day because the

33
00:01:58,799 --> 00:02:03,119
Australian Government has just given me

34
00:02:00,420 --> 00:02:05,579
quite a good use case for the talk that

35
00:02:03,119 --> 00:02:08,580
I'm just about to give the other thing

36
00:02:05,579 --> 00:02:10,500
I'll say is I'm not a GRC governance

37
00:02:08,580 --> 00:02:12,000
risk and compliance person by trade I'm

38
00:02:10,500 --> 00:02:15,210
a technical

39
00:02:12,000 --> 00:02:16,560
so feel free to say that you don't agree

40
00:02:15,210 --> 00:02:18,840
with something I'm always willing to

41
00:02:16,560 --> 00:02:22,320
hear but essentially what my talk today

42
00:02:18,840 --> 00:02:24,240
is about is to talk about the the new is

43
00:02:22,320 --> 00:02:26,970
n so the information security manual for

44
00:02:24,240 --> 00:02:30,870
those who aren't aware and what's change

45
00:02:26,970 --> 00:02:31,980
with it so to to go into some content so

46
00:02:30,870 --> 00:02:33,360
we'll start off with some definitions

47
00:02:31,980 --> 00:02:35,399
because we always need to make sure

48
00:02:33,360 --> 00:02:36,600
we're talking about the same thing for

49
00:02:35,400 --> 00:02:37,950
those who aren't aware we'll talk about

50
00:02:36,600 --> 00:02:40,500
what the information security manual

51
00:02:37,950 --> 00:02:41,940
actually is because I'm sure a lot of

52
00:02:40,500 --> 00:02:43,530
you who don't deal with federal

53
00:02:41,940 --> 00:02:46,200
government or state government aren't

54
00:02:43,530 --> 00:02:48,240
necessarily aware of it what's changed

55
00:02:46,200 --> 00:02:49,920
with it and why a risk management

56
00:02:48,240 --> 00:02:52,500
approach which is sort of what I'm

57
00:02:49,920 --> 00:02:54,750
hinting at here is is a bit better than

58
00:02:52,500 --> 00:02:56,760
the previous approach which is more of a

59
00:02:54,750 --> 00:03:00,660
compliance approach and supporting that

60
00:02:56,760 --> 00:03:02,519
I've got a nice little allegory as

61
00:03:00,660 --> 00:03:04,170
discussed before I don't think I need to

62
00:03:02,520 --> 00:03:08,040
go through all this but yeah I've done a

63
00:03:04,170 --> 00:03:10,049
lot of stuff and I still do stuff it's

64
00:03:08,040 --> 00:03:11,700
probably accurate so for some

65
00:03:10,050 --> 00:03:13,110
definitions for anyone who's been to one

66
00:03:11,700 --> 00:03:15,119
of my talks before this slide will

67
00:03:13,110 --> 00:03:18,720
always be in it we start off by talking

68
00:03:15,120 --> 00:03:20,220
what what risk actually is so risk is a

69
00:03:18,720 --> 00:03:21,480
measure of the extent to which an entity

70
00:03:20,220 --> 00:03:22,950
is threatened by a potential

71
00:03:21,480 --> 00:03:25,049
circumstance or event so it's the

72
00:03:22,950 --> 00:03:27,329
potential for something bad to happen

73
00:03:25,050 --> 00:03:29,820
and within cyber security we talk about

74
00:03:27,330 --> 00:03:31,830
this as being a combination of threat

75
00:03:29,820 --> 00:03:33,420
and vulnerability so threat is any

76
00:03:31,830 --> 00:03:36,210
circumstance or event with the potential

77
00:03:33,420 --> 00:03:38,070
to adversely impact organizational

78
00:03:36,210 --> 00:03:40,860
operations assets or individuals these

79
00:03:38,070 --> 00:03:42,989
are definitions from the NIST standard

80
00:03:40,860 --> 00:03:45,150
if anybody wants to see it I'm more than

81
00:03:42,990 --> 00:03:46,440
happy to send it to them but essentially

82
00:03:45,150 --> 00:03:48,120
when we talk about threat we generally

83
00:03:46,440 --> 00:03:51,420
talk about threat actors so we talk

84
00:03:48,120 --> 00:03:55,280
about groups of people who are targeting

85
00:03:51,420 --> 00:03:59,489
a certain grocer tynin a certain a

86
00:03:55,280 --> 00:04:03,390
certain network a certain system with a

87
00:03:59,490 --> 00:04:05,070
given intent for vulnerability we talk

88
00:04:03,390 --> 00:04:07,260
about a weakness you know that's pretty

89
00:04:05,070 --> 00:04:09,090
much a given one we I think the

90
00:04:07,260 --> 00:04:12,420
information security community has

91
00:04:09,090 --> 00:04:13,709
gotten variability quite well down and

92
00:04:12,420 --> 00:04:14,850
it's the threat piece that needs some

93
00:04:13,709 --> 00:04:17,160
work but hopefully I'll be highlighting

94
00:04:14,850 --> 00:04:20,459
where that comes in in the next few

95
00:04:17,160 --> 00:04:21,780
slides some more definitions to risk

96
00:04:20,459 --> 00:04:23,599
management's we talked about what risk

97
00:04:21,779 --> 00:04:25,460
is but risk management is use

98
00:04:23,600 --> 00:04:28,610
that risk to determine what actions to

99
00:04:25,460 --> 00:04:30,710
take both on a network so in simple

100
00:04:28,610 --> 00:04:33,590
terms what control should I put in place

101
00:04:30,710 --> 00:04:35,599
on a network to defend the network now

102
00:04:33,590 --> 00:04:39,320
obviously we know that no network is

103
00:04:35,600 --> 00:04:41,300
going is unhackable but we decide based

104
00:04:39,320 --> 00:04:43,310
on some methodology what controls to

105
00:04:41,300 --> 00:04:46,030
implement and so risk management is a

106
00:04:43,310 --> 00:04:48,710
tool that you can use to decide what

107
00:04:46,030 --> 00:04:50,210
controls to implement so the nist risk

108
00:04:48,710 --> 00:04:52,489
management framework is a really good

109
00:04:50,210 --> 00:04:55,810
example and as you find out rather than

110
00:04:52,490 --> 00:04:59,510
invent the wheel the australians have

111
00:04:55,810 --> 00:05:01,900
taken that onboard a risk I know someone

112
00:04:59,510 --> 00:05:04,520
who's accountable for a risk so

113
00:05:01,900 --> 00:05:07,219
traditionally this is your siz oh this

114
00:05:04,520 --> 00:05:09,770
is the system owner these are both terms

115
00:05:07,220 --> 00:05:11,450
that are defined in the information

116
00:05:09,770 --> 00:05:15,349
security manual as well

117
00:05:11,450 --> 00:05:17,180
every federal government agency is

118
00:05:15,350 --> 00:05:18,890
responsible for having a scissor it's

119
00:05:17,180 --> 00:05:20,210
responsible for having an it sir and

120
00:05:18,890 --> 00:05:23,240
it's responsible for having system

121
00:05:20,210 --> 00:05:24,620
owners finally accreditation so for

122
00:05:23,240 --> 00:05:26,270
those who haven't worked in a federal

123
00:05:24,620 --> 00:05:28,280
space or a state government space there

124
00:05:26,270 --> 00:05:29,539
is a process known as accreditation and

125
00:05:28,280 --> 00:05:31,669
this is the process of achieving

126
00:05:29,540 --> 00:05:32,960
approval to use the network it's not

127
00:05:31,670 --> 00:05:35,060
necessarily about just plugging

128
00:05:32,960 --> 00:05:37,039
everything in and making sure that

129
00:05:35,060 --> 00:05:39,590
everything will work you actually have

130
00:05:37,040 --> 00:05:41,570
to go through a very structured process

131
00:05:39,590 --> 00:05:43,820
to assess the network assess the

132
00:05:41,570 --> 00:05:47,080
security controls of the network to gain

133
00:05:43,820 --> 00:05:49,400
what is known as authority to operate

134
00:05:47,080 --> 00:05:51,169
and then this one in here which is quite

135
00:05:49,400 --> 00:05:53,599
relevant for today and when I talk about

136
00:05:51,170 --> 00:05:55,520
thread act two tiers this is what I'm

137
00:05:53,600 --> 00:05:58,190
talking about so this is a great slide

138
00:05:55,520 --> 00:06:01,669
that Sam from some department of defense

139
00:05:58,190 --> 00:06:03,410
that's with an S in the US which talks

140
00:06:01,670 --> 00:06:05,300
about the different types of thread

141
00:06:03,410 --> 00:06:07,490
actors so we start from script kiddies

142
00:06:05,300 --> 00:06:09,590
non-malicious access on tier one and we

143
00:06:07,490 --> 00:06:11,360
go out to tier six and the way this

144
00:06:09,590 --> 00:06:13,340
diagram works as it shows you that as

145
00:06:11,360 --> 00:06:15,110
you go up the tiers the resources

146
00:06:13,340 --> 00:06:17,929
increase but the number of actors

147
00:06:15,110 --> 00:06:21,290
decreases the right-hand side also talks

148
00:06:17,930 --> 00:06:23,810
about how thread actors the defining

149
00:06:21,290 --> 00:06:25,250
characteristics so tier 1 tier 2 they'll

150
00:06:23,810 --> 00:06:27,590
download something from the internet and

151
00:06:25,250 --> 00:06:29,600
use that tier 3 tier 4 they'll discover

152
00:06:27,590 --> 00:06:32,270
something that's a vulnerability in a

153
00:06:29,600 --> 00:06:34,130
system until 5 and tier 6 by actually

154
00:06:32,270 --> 00:06:36,639
create vulnerabilities and when I say

155
00:06:34,130 --> 00:06:39,189
full-spectrum they actually mean

156
00:06:36,639 --> 00:06:42,159
just using cyber but using espionage

157
00:06:39,189 --> 00:06:43,749
physical event effects and when they're

158
00:06:42,159 --> 00:06:45,490
actually using cyber we're also talking

159
00:06:43,749 --> 00:06:48,039
about kinetic effects which is quite an

160
00:06:45,490 --> 00:06:49,240
interesting role if if anybody's

161
00:06:48,039 --> 00:06:53,770
interested and I'd love to talk to them

162
00:06:49,240 --> 00:06:55,240
about so a bit of a tldr upfront because

163
00:06:53,770 --> 00:06:58,539
I know some people will want to know

164
00:06:55,240 --> 00:07:00,509
that and I just want to make clear so

165
00:06:58,539 --> 00:07:03,460
the new iam allows resourced

166
00:07:00,509 --> 00:07:04,810
organizations to exercise mature risk

167
00:07:03,460 --> 00:07:06,128
management approaches to enable their

168
00:07:04,810 --> 00:07:08,289
business operations through careful

169
00:07:06,129 --> 00:07:12,039
selection of security controls couple of

170
00:07:08,289 --> 00:07:14,500
important points that resourced so we

171
00:07:12,039 --> 00:07:16,750
talk about security operations teams and

172
00:07:14,500 --> 00:07:19,599
one of the things that I hear in regards

173
00:07:16,750 --> 00:07:20,919
to taking on a risk management

174
00:07:19,599 --> 00:07:22,750
approaches we don't have enough people

175
00:07:20,919 --> 00:07:24,128
well arguably you don't have enough

176
00:07:22,750 --> 00:07:25,360
people because you don't have enough

177
00:07:24,129 --> 00:07:27,250
people it's not because you're using a

178
00:07:25,360 --> 00:07:29,529
risk management approach it's that you

179
00:07:27,250 --> 00:07:31,330
don't have the right people in the right

180
00:07:29,529 --> 00:07:38,110
place to do the right thing

181
00:07:31,330 --> 00:07:39,938
maturity there is an amount of making

182
00:07:38,110 --> 00:07:41,800
the model work for you understanding

183
00:07:39,939 --> 00:07:44,319
your environment understanding how you

184
00:07:41,800 --> 00:07:45,879
fit within a business process you know

185
00:07:44,319 --> 00:07:47,680
the organization's business processes

186
00:07:45,879 --> 00:07:50,469
sorry and how they work around you and

187
00:07:47,680 --> 00:07:53,439
then careful selection it's not a matter

188
00:07:50,469 --> 00:07:55,839
of a checklist and if I can get anybody

189
00:07:53,439 --> 00:07:58,449
to walk away from this is if you use a

190
00:07:55,839 --> 00:08:01,449
checklist to say your network is secure

191
00:07:58,449 --> 00:08:03,430
you are probably lying to yourself or

192
00:08:01,449 --> 00:08:09,779
you're not actually getting a good

193
00:08:03,430 --> 00:08:12,460
security outcome so what is the I sent

194
00:08:09,779 --> 00:08:13,839
for those of you who work in again

195
00:08:12,460 --> 00:08:15,549
federal government state government

196
00:08:13,839 --> 00:08:17,560
potentially those who do business with

197
00:08:15,550 --> 00:08:18,879
them you've probably seen this document

198
00:08:17,560 --> 00:08:19,479
and you've probably read it

199
00:08:18,879 --> 00:08:21,399
cover-to-cover

200
00:08:19,479 --> 00:08:22,839
I know I have on a number of occasions

201
00:08:21,399 --> 00:08:24,789
it's a great read you should read

202
00:08:22,839 --> 00:08:26,589
through the Australian government

203
00:08:24,789 --> 00:08:28,688
information security manual made by AST

204
00:08:26,589 --> 00:08:31,330
and the ACS see important things aren't

205
00:08:28,689 --> 00:08:34,240
there it's the 19th of June 2020 right

206
00:08:31,330 --> 00:08:36,819
now and this was updated in 2020 in June

207
00:08:34,240 --> 00:08:38,198
so this is the latest version now this

208
00:08:36,820 --> 00:08:40,180
is something that wasn't generally done

209
00:08:38,198 --> 00:08:41,769
previously and for those who are aware

210
00:08:40,179 --> 00:08:44,920
the is M was generally updated on a

211
00:08:41,769 --> 00:08:47,890
yearly or six monthly basis so this is

212
00:08:44,920 --> 00:08:49,300
one of the changes what is it that

213
00:08:47,890 --> 00:08:50,529
actually contained so it contains

214
00:08:49,300 --> 00:08:52,839
information on suggesting

215
00:08:50,529 --> 00:08:55,749
Charles for classified networks as well

216
00:08:52,839 --> 00:08:57,970
as dlm networks for those who don't know

217
00:08:55,749 --> 00:09:01,689
what a DLM is it's like a classification

218
00:08:57,970 --> 00:09:04,329
but light kind of thing it forms the

219
00:09:01,689 --> 00:09:05,740
basis to develop those security controls

220
00:09:04,329 --> 00:09:08,709
so it provides you a giant list of

221
00:09:05,740 --> 00:09:10,029
controls that you can then pick from and

222
00:09:08,709 --> 00:09:11,378
pick and choose and say I'm going to

223
00:09:10,029 --> 00:09:13,509
implement these controls on my network

224
00:09:11,379 --> 00:09:16,509
so it's a good guide so you do be able

225
00:09:13,509 --> 00:09:17,980
to start developing the security around

226
00:09:16,509 --> 00:09:19,870
your network now the important thing is

227
00:09:17,980 --> 00:09:21,100
and I noticed some of these mentioned in

228
00:09:19,870 --> 00:09:22,990
the slack and I'll get to you later

229
00:09:21,100 --> 00:09:24,910
it doesn't contain every single control

230
00:09:22,990 --> 00:09:28,209
it's a list of controls that have been

231
00:09:24,910 --> 00:09:29,769
evaluated by ASD in a CSC it's not the

232
00:09:28,209 --> 00:09:31,839
be-all and end-all you always have that

233
00:09:29,769 --> 00:09:34,749
option to actually talk about to

234
00:09:31,839 --> 00:09:37,180
introduce other controls later on and

235
00:09:34,749 --> 00:09:39,670
you go through this process with the the

236
00:09:37,180 --> 00:09:41,949
documentation and then you your assess

237
00:09:39,670 --> 00:09:45,699
for accreditation by a member of what's

238
00:09:41,949 --> 00:09:47,229
called the I rap program so the there's

239
00:09:45,699 --> 00:09:48,339
a whole list of I rap Assessors if

240
00:09:47,230 --> 00:09:49,569
you've gone through this process you

241
00:09:48,339 --> 00:09:50,980
know it is but essentially they'll come

242
00:09:49,569 --> 00:09:52,870
in they'll understand your system and

243
00:09:50,980 --> 00:09:55,300
the control you've put in place and say

244
00:09:52,870 --> 00:09:57,189
yep this is probably okay send it off to

245
00:09:55,300 --> 00:09:58,389
the next person and so the next person

246
00:09:57,189 --> 00:10:00,790
is actually the accreditation authority

247
00:09:58,389 --> 00:10:03,040
slash the risk owner for the

248
00:10:00,790 --> 00:10:06,490
organization Oh everyone's joining

249
00:10:03,040 --> 00:10:08,050
Seaside's the the accreditation

250
00:10:06,490 --> 00:10:09,490
authority risk owner of the organization

251
00:10:08,050 --> 00:10:12,189
is generally this is oh but basically

252
00:10:09,490 --> 00:10:13,930
that is where the buck stops that is the

253
00:10:12,189 --> 00:10:15,670
person who has a cannibal leader if

254
00:10:13,930 --> 00:10:17,680
something goes wrong on that network

255
00:10:15,670 --> 00:10:19,290
they are the person who has to accept

256
00:10:17,680 --> 00:10:21,399
the risk that that will go wrong

257
00:10:19,290 --> 00:10:22,959
important point and it's called out in

258
00:10:21,399 --> 00:10:24,939
the is em and I'm sure there's not many

259
00:10:22,959 --> 00:10:28,300
people who are affected by this unless

260
00:10:24,939 --> 00:10:29,920
it's the top-secret network the risk is

261
00:10:28,300 --> 00:10:31,420
generally owned by someone within the

262
00:10:29,920 --> 00:10:33,399
organization if it's a top-secret

263
00:10:31,420 --> 00:10:35,529
network it's owned by director general

264
00:10:33,399 --> 00:10:39,040
ASD it's an interesting fact if you ever

265
00:10:35,529 --> 00:10:41,319
work on top-secret networks it also

266
00:10:39,040 --> 00:10:43,449
contains the essential 8 topic of the

267
00:10:41,319 --> 00:10:45,339
day the essentially it provides a

268
00:10:43,449 --> 00:10:46,809
baseline of controls now the important

269
00:10:45,339 --> 00:10:50,740
thing is it's a baseline of controls

270
00:10:46,809 --> 00:10:54,850
based on what ASD and a CSC think our

271
00:10:50,740 --> 00:10:57,129
likely right a Sdn a CSC may not know

272
00:10:54,850 --> 00:11:01,179
your environment in fact they probably

273
00:10:57,129 --> 00:11:03,459
don't they have made a judgement call of

274
00:11:01,179 --> 00:11:04,220
risk management call and that these are

275
00:11:03,459 --> 00:11:05,420
the controls

276
00:11:04,220 --> 00:11:08,150
you should be implementing in your

277
00:11:05,420 --> 00:11:10,579
environment the problem with this is

278
00:11:08,150 --> 00:11:12,020
it's it is a it is only a reporting

279
00:11:10,580 --> 00:11:13,910
requirement for government agencies as

280
00:11:12,020 --> 00:11:16,010
far as I'm aware but at the moment it's

281
00:11:13,910 --> 00:11:17,930
become a pseudo compliance requirement

282
00:11:16,010 --> 00:11:19,939
people are being held to account for the

283
00:11:17,930 --> 00:11:21,829
essential aid and as you'll see later on

284
00:11:19,940 --> 00:11:23,320
sometimes the essentially controls don't

285
00:11:21,830 --> 00:11:26,450
make sense within an environment

286
00:11:23,320 --> 00:11:28,820
sometimes you can have particular

287
00:11:26,450 --> 00:11:30,440
systems particular ways of working that

288
00:11:28,820 --> 00:11:32,150
implementing the essentially controls

289
00:11:30,440 --> 00:11:34,910
will actually cause a problem with your

290
00:11:32,150 --> 00:11:36,890
business processes arguably it's also

291
00:11:34,910 --> 00:11:39,319
proven not to be working and this is a

292
00:11:36,890 --> 00:11:42,760
article that came out last week week

293
00:11:39,320 --> 00:11:45,680
before from IIT News talking about top

294
00:11:42,760 --> 00:11:48,290
18 government agencies and if you can

295
00:11:45,680 --> 00:11:50,540
see the graph there's a very distinct

296
00:11:48,290 --> 00:11:54,380
lack of agencies compliance of those

297
00:11:50,540 --> 00:11:55,910
controls this is why I think we need a

298
00:11:54,380 --> 00:11:57,830
different way of looking at things and

299
00:11:55,910 --> 00:12:00,260
unfortunately compliance is not really

300
00:11:57,830 --> 00:12:01,880
the answer with needs to start looking

301
00:12:00,260 --> 00:12:04,130
at these systems individually as they

302
00:12:01,880 --> 00:12:06,890
should be and start applying security

303
00:12:04,130 --> 00:12:09,560
controls that make sense for them and in

304
00:12:06,890 --> 00:12:13,100
my opinion that's what a Sdn a CSC did

305
00:12:09,560 --> 00:12:15,170
so what changed well very simply here's

306
00:12:13,100 --> 00:12:18,230
an old version of the a CSC oh sorry the

307
00:12:15,170 --> 00:12:20,300
the RSM so it says this document is not

308
00:12:18,230 --> 00:12:21,620
a compliance based standard and it says

309
00:12:20,300 --> 00:12:25,189
you need to pick your own risk

310
00:12:21,620 --> 00:12:27,320
management framework which is great now

311
00:12:25,190 --> 00:12:29,420
it then also lists underneath these are

312
00:12:27,320 --> 00:12:31,100
the controls so for example on an

313
00:12:29,420 --> 00:12:34,040
official protected secret or top secret

314
00:12:31,100 --> 00:12:35,990
network you should for those who've

315
00:12:34,040 --> 00:12:38,449
studied systems engineering should is

316
00:12:35,990 --> 00:12:40,790
not a requirement it is a you can do

317
00:12:38,450 --> 00:12:43,610
this a Hipps is implemented on

318
00:12:40,790 --> 00:12:45,829
workstations now another requirement

319
00:12:43,610 --> 00:12:48,830
sorry another control says

320
00:12:45,830 --> 00:12:51,800
1:03 for official protected secret top

321
00:12:48,830 --> 00:12:53,960
secret networks you must must means as

322
00:12:51,800 --> 00:12:56,420
Alan said in a call we had the other

323
00:12:53,960 --> 00:12:56,960
week must means you absolutely have to

324
00:12:56,420 --> 00:12:58,849
do this

325
00:12:56,960 --> 00:13:00,890
so a Hipps is implemented on high-value

326
00:12:58,850 --> 00:13:02,930
services she's authentication servers -

327
00:13:00,890 --> 00:13:04,880
main name servers web servers blah blah

328
00:13:02,930 --> 00:13:09,079
blah now there's a slight contradiction

329
00:13:04,880 --> 00:13:11,540
here it says it's not a compliance based

330
00:13:09,080 --> 00:13:15,650
standard but there are things you need

331
00:13:11,540 --> 00:13:17,779
to comply with okay I'm sure this has

332
00:13:15,650 --> 00:13:19,910
been commented on a number of times

333
00:13:17,779 --> 00:13:21,860
and in my opinion this is something this

334
00:13:19,910 --> 00:13:24,079
is one of the reasons why this has

335
00:13:21,860 --> 00:13:25,879
changed but realistically you say your

336
00:13:24,079 --> 00:13:27,050
normal components based standard but you

337
00:13:25,879 --> 00:13:30,350
are a compliance based standard you must

338
00:13:27,050 --> 00:13:33,859
do these things so what did they do so

339
00:13:30,350 --> 00:13:35,420
this is November 2019 so this is let's

340
00:13:33,860 --> 00:13:37,399
have a look eight months ago all an

341
00:13:35,420 --> 00:13:40,009
eternity if you consider the way this

342
00:13:37,399 --> 00:13:43,309
year is gone this is what they've

343
00:13:40,009 --> 00:13:44,629
changed so using a risk management

344
00:13:43,309 --> 00:13:45,920
framework so the difference here is

345
00:13:44,629 --> 00:13:47,269
they've actually given you a risk

346
00:13:45,920 --> 00:13:49,160
management framework to use they've

347
00:13:47,269 --> 00:13:51,470
given you they're not giving you a

348
00:13:49,160 --> 00:13:52,639
choice in it which is arguably a good

349
00:13:51,470 --> 00:13:54,290
thing it means you don't have to sort of

350
00:13:52,639 --> 00:13:57,110
wonder which one to use and they've

351
00:13:54,290 --> 00:13:58,699
chosen RMF which is a risk management

352
00:13:57,110 --> 00:14:00,410
framework that has been established by

353
00:13:58,699 --> 00:14:01,878
nist in the u.s. or the National

354
00:14:00,410 --> 00:14:04,819
Institute of Standards and Technology in

355
00:14:01,879 --> 00:14:06,499
the u.s. it has six steps you define the

356
00:14:04,819 --> 00:14:07,998
system you select the SCOOTER controls

357
00:14:06,499 --> 00:14:09,670
you implement them you assess them you

358
00:14:07,999 --> 00:14:11,870
authorize the system and you keep going

359
00:14:09,670 --> 00:14:13,370
and then you monitor the system sorry

360
00:14:11,870 --> 00:14:16,249
and then it loops Fran and it goes

361
00:14:13,370 --> 00:14:17,870
ranked and so they've defined this to

362
00:14:16,249 --> 00:14:19,759
make it easier to get into risk

363
00:14:17,870 --> 00:14:21,620
management but the other change they've

364
00:14:19,759 --> 00:14:23,750
made is they've removed the shoulds and

365
00:14:21,620 --> 00:14:26,059
musts so Hipps is implement on

366
00:14:23,750 --> 00:14:28,009
workstations no longer I should hips is

367
00:14:26,059 --> 00:14:29,569
implemented on high-value servers such

368
00:14:28,009 --> 00:14:33,470
as authentication service domain name

369
00:14:29,569 --> 00:14:36,019
servers etc etc no longer a must so the

370
00:14:33,470 --> 00:14:40,129
question that gets asked does that mean

371
00:14:36,019 --> 00:14:43,220
you can now ignore the I sent no it

372
00:14:40,129 --> 00:14:44,779
doesn't mean you can ignore the I am the

373
00:14:43,220 --> 00:14:47,180
I ascend the way that it's next

374
00:14:44,779 --> 00:14:50,509
structured means that system there is an

375
00:14:47,180 --> 00:14:52,309
understanding from asdf CC that system

376
00:14:50,509 --> 00:14:54,620
owners are the only people who can

377
00:14:52,309 --> 00:14:56,689
adequately identify the risks and as we

378
00:14:54,620 --> 00:14:58,370
discussed before that is dependent on

379
00:14:56,689 --> 00:15:01,040
your threats and your vulnerabilities

380
00:14:58,370 --> 00:15:03,670
that your system has and to therefore

381
00:15:01,040 --> 00:15:06,769
implement the controls to defend those

382
00:15:03,670 --> 00:15:09,229
those risks or to mitigate those risks

383
00:15:06,769 --> 00:15:11,360
so rather than a blanket approach to

384
00:15:09,230 --> 00:15:12,920
security it puts the onus on government

385
00:15:11,360 --> 00:15:15,980
agencies to identify what is relevant to

386
00:15:12,920 --> 00:15:17,990
them and as a bonus to the

387
00:15:15,980 --> 00:15:20,720
organization's it allows you to choose

388
00:15:17,990 --> 00:15:22,970
the controls that make sense for your

389
00:15:20,720 --> 00:15:24,559
organization based on those risks and

390
00:15:22,970 --> 00:15:25,910
threats that's the important point it

391
00:15:24,559 --> 00:15:26,719
doesn't mean you can just choose the

392
00:15:25,910 --> 00:15:28,219
easy ones

393
00:15:26,720 --> 00:15:29,390
it means you choose the ones that are

394
00:15:28,220 --> 00:15:32,030
relevant

395
00:15:29,390 --> 00:15:35,420
and not use the controls that are either

396
00:15:32,030 --> 00:15:37,069
too onerous or disabled business because

397
00:15:35,420 --> 00:15:40,370
the important thing as I'll say later on

398
00:15:37,070 --> 00:15:42,230
we as an as a as a group of people

399
00:15:40,370 --> 00:15:43,910
within an organization federal

400
00:15:42,230 --> 00:15:45,530
government state government what have

401
00:15:43,910 --> 00:15:46,939
you need to make sure that we're

402
00:15:45,530 --> 00:15:54,620
enabling the business in a secure

403
00:15:46,940 --> 00:15:56,570
fashion so why is this better risk

404
00:15:54,620 --> 00:16:00,950
management is the language of executives

405
00:15:56,570 --> 00:16:03,590
so risk is not it's not a it's not a

406
00:16:00,950 --> 00:16:05,480
it's not a cyber only thing it applies

407
00:16:03,590 --> 00:16:07,280
to all of these things on this screen we

408
00:16:05,480 --> 00:16:08,750
talk about business risks we talk about

409
00:16:07,280 --> 00:16:10,939
financial risk we talk about safety

410
00:16:08,750 --> 00:16:14,710
protection control strategy analysis and

411
00:16:10,940 --> 00:16:16,730
of course cyber with the wonderful fund

412
00:16:14,710 --> 00:16:20,450
risk is something that leaders

413
00:16:16,730 --> 00:16:21,530
understand and even if you are doing a

414
00:16:20,450 --> 00:16:23,690
compliance approach I would have

415
00:16:21,530 --> 00:16:25,699
strongly suggest that you understand how

416
00:16:23,690 --> 00:16:27,380
risk works and how you can engage with

417
00:16:25,700 --> 00:16:30,020
risk to be able to provide that back to

418
00:16:27,380 --> 00:16:31,720
your managers but in this case because

419
00:16:30,020 --> 00:16:35,329
you're using a risk management approach

420
00:16:31,720 --> 00:16:36,830
engineers sorry not engineers managers

421
00:16:35,330 --> 00:16:38,600
and leaders understand what you're

422
00:16:36,830 --> 00:16:40,850
talking about you're engaging with risk

423
00:16:38,600 --> 00:16:43,910
and that's an important thing

424
00:16:40,850 --> 00:16:48,940
risk is not a bad thing we engage with

425
00:16:43,910 --> 00:16:54,260
risk all the time this is about

426
00:16:48,940 --> 00:16:57,320
constructively engaging with risk and as

427
00:16:54,260 --> 00:17:00,410
I promised so here is my fun allegory to

428
00:16:57,320 --> 00:17:04,190
also highlight some more points so for

429
00:17:00,410 --> 00:17:07,909
those who are of a oil Air Force or RAAF

430
00:17:04,190 --> 00:17:08,959
or what have you bent this is the f-104

431
00:17:07,910 --> 00:17:11,240
starfighter

432
00:17:08,959 --> 00:17:13,760
so this aircraft was designed by Kelly

433
00:17:11,240 --> 00:17:15,560
Johnson who if you don't know was the

434
00:17:13,760 --> 00:17:17,449
gentleman who invented the skunk works

435
00:17:15,560 --> 00:17:19,639
at Lockheed Martin that amazing place

436
00:17:17,449 --> 00:17:22,130
that all the aircraft engineers want to

437
00:17:19,640 --> 00:17:23,930
go to so it was invented in the 60s and

438
00:17:22,130 --> 00:17:26,530
70s as a replacement to some of the

439
00:17:23,930 --> 00:17:29,450
aging aircraft that was within the US

440
00:17:26,530 --> 00:17:30,590
military after World War two it was

441
00:17:29,450 --> 00:17:32,960
designed to be what they call a

442
00:17:30,590 --> 00:17:34,760
fair-weather fighter which means that it

443
00:17:32,960 --> 00:17:38,030
can basically take off during you know a

444
00:17:34,760 --> 00:17:40,460
normal day it can then land under a

445
00:17:38,030 --> 00:17:42,320
normal day if it was raining or if it's

446
00:17:40,460 --> 00:17:46,789
stormy it's probably less of a you

447
00:17:42,320 --> 00:17:49,759
not as able to do it and the story goes

448
00:17:46,789 --> 00:17:52,610
that the the German air force sorry the

449
00:17:49,759 --> 00:17:57,130
West German air force specifically we're

450
00:17:52,610 --> 00:18:00,139
looking to rebuild their their Luftwaffe

451
00:17:57,130 --> 00:18:02,210
during the 60s and 70s after it had been

452
00:18:00,139 --> 00:18:04,039
obviously decimated during World War two

453
00:18:02,210 --> 00:18:06,830
and they were looking for a new aircraft

454
00:18:04,039 --> 00:18:08,929
and the story is told through this it's

455
00:18:06,830 --> 00:18:11,418
an album actually by a gentleman called

456
00:18:08,929 --> 00:18:13,789
Robert Calvert who was in a band called

457
00:18:11,419 --> 00:18:14,360
Hawkwind during the 70s but the story

458
00:18:13,789 --> 00:18:16,669
goes like this

459
00:18:14,360 --> 00:18:17,809
the salesman says yes it's a

460
00:18:16,669 --> 00:18:20,120
fair-weather fire you won't find

461
00:18:17,809 --> 00:18:22,340
anything better and the Germans say yes

462
00:18:20,120 --> 00:18:24,350
but that's great but we want bombing

463
00:18:22,340 --> 00:18:25,580
strafing assault battery interception

464
00:18:24,350 --> 00:18:27,918
ground support reconnaissance we want

465
00:18:25,580 --> 00:18:29,418
this thing to do everything basically

466
00:18:27,919 --> 00:18:30,500
and the salesman goes yeah that's fine

467
00:18:29,419 --> 00:18:32,559
we'll just make some modifications

468
00:18:30,500 --> 00:18:38,600
nothing could possibly go wrong

469
00:18:32,559 --> 00:18:41,080
and they ended up with the f-104 G G for

470
00:18:38,600 --> 00:18:45,939
Germany as they say in the in the album

471
00:18:41,080 --> 00:18:48,949
there was one slight problem the f-104 G

472
00:18:45,940 --> 00:18:52,190
what had the highest fatality rate of

473
00:18:48,950 --> 00:18:54,139
any modern aircraft so the f-104 in

474
00:18:52,190 --> 00:18:57,649
particular did not exactly have a great

475
00:18:54,139 --> 00:18:59,479
record I'll say that now but the f-104 G

476
00:18:57,649 --> 00:19:01,309
had an even worse record and that's

477
00:18:59,480 --> 00:19:03,379
partly down to the fact that they tried

478
00:19:01,309 --> 00:19:06,019
to build too much into the aircraft at

479
00:19:03,379 --> 00:19:08,750
once the aircraft couldn't handle

480
00:19:06,019 --> 00:19:11,990
dealing with all the air the equipment

481
00:19:08,750 --> 00:19:16,909
all the different features and basically

482
00:19:11,990 --> 00:19:19,309
was quite difficult to fly and also you

483
00:19:16,909 --> 00:19:21,110
know it just would randomly crash the

484
00:19:19,309 --> 00:19:22,399
German Air Force and the pilots of the

485
00:19:21,110 --> 00:19:28,820
German air force used to call it the

486
00:19:22,399 --> 00:19:32,689
Widowmaker and so this allegory for me

487
00:19:28,820 --> 00:19:34,759
teaches a couple of different things so

488
00:19:32,690 --> 00:19:36,379
systems should and cannot be designed

489
00:19:34,759 --> 00:19:38,480
can every threat imaginable without

490
00:19:36,379 --> 00:19:41,090
using him impacting usability so this

491
00:19:38,480 --> 00:19:43,009
this aircraft was designed to counter

492
00:19:41,090 --> 00:19:45,320
any sort of threat it was designed to

493
00:19:43,009 --> 00:19:47,750
counter air it was designs canceled and

494
00:19:45,320 --> 00:19:48,710
it was designs do everything but the

495
00:19:47,750 --> 00:19:50,779
problem was you ended up with an

496
00:19:48,710 --> 00:19:52,370
unusable system and this goes to the

497
00:19:50,779 --> 00:19:54,649
story we often tell a lot which is the

498
00:19:52,370 --> 00:19:55,260
most secure system is a system that's

499
00:19:54,649 --> 00:19:56,429
turned

500
00:19:55,260 --> 00:19:58,170
disconnected from the internet and

501
00:19:56,430 --> 00:19:59,640
thrown into a river you know it's the

502
00:19:58,170 --> 00:20:04,230
most secure system but it's also not

503
00:19:59,640 --> 00:20:05,520
actually a usable system a follow-on

504
00:20:04,230 --> 00:20:06,630
from that is cybersecurity is there to

505
00:20:05,520 --> 00:20:09,150
enable a business to do its work

506
00:20:06,630 --> 00:20:10,800
securely not to inhibit it so the point

507
00:20:09,150 --> 00:20:13,920
of cybersecurity is the businesses to

508
00:20:10,800 --> 00:20:15,600
function we are only here at the at the

509
00:20:13,920 --> 00:20:17,430
whim of the business the business needs

510
00:20:15,600 --> 00:20:19,649
to do what it does we need to secure the

511
00:20:17,430 --> 00:20:21,330
business that means whatever we do we

512
00:20:19,650 --> 00:20:26,730
need to make sure that the business is

513
00:20:21,330 --> 00:20:29,879
secure and so linking back to my

514
00:20:26,730 --> 00:20:31,740
original statement a risk approach takes

515
00:20:29,880 --> 00:20:35,180
into account those relevant threats ie

516
00:20:31,740 --> 00:20:37,860
it understands in the aircraft what

517
00:20:35,180 --> 00:20:40,170
particular things the aircraft needs to

518
00:20:37,860 --> 00:20:42,000
be designed to do and not everything but

519
00:20:40,170 --> 00:20:45,030
the very specific things

520
00:20:42,000 --> 00:20:46,290
if the Germans are at the time had

521
00:20:45,030 --> 00:20:47,700
thought well we're actually going to be

522
00:20:46,290 --> 00:20:49,620
against tanks therefore we need to

523
00:20:47,700 --> 00:20:51,090
target this thing but we're not going to

524
00:20:49,620 --> 00:20:52,709
be against fighters therefore we don't

525
00:20:51,090 --> 00:20:55,260
need this thing they might have had a

526
00:20:52,710 --> 00:20:58,470
more successful aircraft and the

527
00:20:55,260 --> 00:21:00,360
vulnerabilities as well so less of less

528
00:20:58,470 --> 00:21:03,720
of mentioned in the aircraft analogy but

529
00:21:00,360 --> 00:21:05,580
within a cyber analogy you know there's

530
00:21:03,720 --> 00:21:08,010
no point putting a laughing if you don't

531
00:21:05,580 --> 00:21:10,020
have any web applications like we know

532
00:21:08,010 --> 00:21:11,879
that that's a given let's take that a

533
00:21:10,020 --> 00:21:13,590
step further let's understand

534
00:21:11,880 --> 00:21:15,150
specifically what vulnerabilities are on

535
00:21:13,590 --> 00:21:18,419
our systems and therefore put the

536
00:21:15,150 --> 00:21:20,490
controls in only to defend against those

537
00:21:18,420 --> 00:21:21,660
vulnerabilities rather than putting

538
00:21:20,490 --> 00:21:24,930
controls in for the sake of putting

539
00:21:21,660 --> 00:21:28,260
controls in which arguably if we're

540
00:21:24,930 --> 00:21:30,660
being honest can happen a lot if you

541
00:21:28,260 --> 00:21:36,690
just implement the essential 8 or you

542
00:21:30,660 --> 00:21:39,270
use the old approach the RSM and in my

543
00:21:36,690 --> 00:21:40,440
opinion this is a big one mature risk

544
00:21:39,270 --> 00:21:41,820
management approaches provide better

545
00:21:40,440 --> 00:21:44,610
security outcomes and business outcomes

546
00:21:41,820 --> 00:21:46,350
so how many times have we been you know

547
00:21:44,610 --> 00:21:47,490
you might have put in a request I want

548
00:21:46,350 --> 00:21:52,350
to use a piece of software and the

549
00:21:47,490 --> 00:21:54,480
automatic response pack is no no because

550
00:21:52,350 --> 00:21:55,879
of some reason because of oh it's not on

551
00:21:54,480 --> 00:21:58,470
our list or what-have-you

552
00:21:55,880 --> 00:21:59,760
mature as management strategies allow

553
00:21:58,470 --> 00:22:02,010
you to look at that application

554
00:21:59,760 --> 00:22:03,390
understand what it actually does what is

555
00:22:02,010 --> 00:22:07,290
it within the context of your

556
00:22:03,390 --> 00:22:08,669
environment how can it affect you it's

557
00:22:07,290 --> 00:22:10,350
really important to it

558
00:22:08,669 --> 00:22:11,909
that the problem I find with people who

559
00:22:10,350 --> 00:22:13,889
say you can't actually do this in real

560
00:22:11,909 --> 00:22:15,239
life it's not that the risk management

561
00:22:13,889 --> 00:22:16,559
piece is difficult but it's

562
00:22:15,239 --> 00:22:18,809
understanding your network that's

563
00:22:16,559 --> 00:22:20,220
difficult arguably that's something we

564
00:22:18,809 --> 00:22:22,710
need to do anyway we always need to

565
00:22:20,220 --> 00:22:26,190
understand what our network is because

566
00:22:22,710 --> 00:22:28,139
otherwise how do we defend it and again

567
00:22:26,190 --> 00:22:29,850
my argument there is well obviously the

568
00:22:28,139 --> 00:22:31,168
current approach isn't working where we

569
00:22:29,850 --> 00:22:33,090
kind of know what's on our network and

570
00:22:31,169 --> 00:22:37,999
we just Chuck controls in for the sake

571
00:22:33,090 --> 00:22:41,869
of it let's try this new one

572
00:22:37,999 --> 00:22:44,850
thank you IT girl for also pointing out

573
00:22:41,869 --> 00:22:46,439
this risk management is also a process

574
00:22:44,850 --> 00:22:48,330
that keeps going on and on and on it's

575
00:22:46,440 --> 00:22:50,879
meant to be this thing where you know

576
00:22:48,330 --> 00:22:52,139
threat changes on a daily basis your

577
00:22:50,879 --> 00:22:52,619
threat can change from one day to

578
00:22:52,139 --> 00:22:56,248
another

579
00:22:52,619 --> 00:22:58,439
today is a great example of that today

580
00:22:56,249 --> 00:22:59,759
Linda Reynolds and Scott Morrison stood

581
00:22:58,440 --> 00:23:02,070
up and said there are threat actors

582
00:22:59,759 --> 00:23:05,700
targeting Australia you should use these

583
00:23:02,070 --> 00:23:07,918
two controls now for those who have been

584
00:23:05,700 --> 00:23:09,450
listening to the presentation and know

585
00:23:07,919 --> 00:23:11,369
me that's an important breakthrough

586
00:23:09,450 --> 00:23:13,980
further the government that didn't say

587
00:23:11,369 --> 00:23:17,428
implement the essential 8 they said

588
00:23:13,980 --> 00:23:19,859
implement these two specific controls

589
00:23:17,429 --> 00:23:20,730
they said these two controls out of the

590
00:23:19,859 --> 00:23:22,529
essential like they're essentially

591
00:23:20,730 --> 00:23:24,779
controls for doesn't matter they're

592
00:23:22,529 --> 00:23:26,519
essentially controls that were told to

593
00:23:24,779 --> 00:23:28,379
be implemented to defend this threat

594
00:23:26,519 --> 00:23:29,999
that is exactly what this approach will

595
00:23:28,379 --> 00:23:32,369
give you at the end this approach will

596
00:23:29,999 --> 00:23:35,489
tell you this threat can be determined

597
00:23:32,369 --> 00:23:37,080
defended sorry defeated by these

598
00:23:35,489 --> 00:23:40,909
controls implement these controls

599
00:23:37,080 --> 00:23:40,908
because this threat is relevant to you

600
00:23:41,090 --> 00:23:48,389
in essence oh no the right security

601
00:23:46,559 --> 00:23:49,590
control in the wrong place for a fraud

602
00:23:48,389 --> 00:23:51,748
actor can make all the difference in the

603
00:23:49,590 --> 00:23:54,418
world it's not about just putting up

604
00:23:51,749 --> 00:23:56,489
patrols everywhere obviously we can't do

605
00:23:54,419 --> 00:23:58,499
this like we don't have enough money we

606
00:23:56,489 --> 00:24:03,119
do have enough resources so pick your

607
00:23:58,499 --> 00:24:05,369
controls carefully and make sure that

608
00:24:03,119 --> 00:24:08,639
you can you understand your networking

609
00:24:05,369 --> 00:24:10,168
you understand your threats a few

610
00:24:08,639 --> 00:24:12,629
examples I wanted to include these

611
00:24:10,169 --> 00:24:14,190
because some people you know tell me

612
00:24:12,629 --> 00:24:15,238
that oh we've ascent implemented

613
00:24:14,190 --> 00:24:19,619
application whitelisting @courtney

614
00:24:15,239 --> 00:24:22,560
across our entire environment and I'll

615
00:24:19,619 --> 00:24:25,820
be brutally honest you have

616
00:24:22,560 --> 00:24:30,800
it's not possible if someone has a

617
00:24:25,820 --> 00:24:30,800
proper application whitelisting system

618
00:24:30,860 --> 00:24:35,639
across our environment without weird

619
00:24:33,900 --> 00:24:37,050
exceptions like you can run apps from

620
00:24:35,640 --> 00:24:39,870
this folder or you can run apps from

621
00:24:37,050 --> 00:24:41,490
this folder I'll buy a bit like I'm

622
00:24:39,870 --> 00:24:44,040
happy I'm happy to be proven wrong

623
00:24:41,490 --> 00:24:47,160
but most organizations do not have that

624
00:24:44,040 --> 00:24:50,190
level of control and so some really good

625
00:24:47,160 --> 00:24:51,840
examples here the is M says you must

626
00:24:50,190 --> 00:24:53,940
patch within 48 hours which a lot of

627
00:24:51,840 --> 00:24:55,860
people complained about today for

628
00:24:53,940 --> 00:24:57,630
operating systems for those who work

629
00:24:55,860 --> 00:25:00,120
with industrial control systems

630
00:24:57,630 --> 00:25:03,530
you do not patch industrial control

631
00:25:00,120 --> 00:25:06,149
systems within 48 hours that is a no-no

632
00:25:03,530 --> 00:25:08,550
you will break the system if you don't

633
00:25:06,150 --> 00:25:09,930
do testing application whitelisting for

634
00:25:08,550 --> 00:25:11,280
software developers again I've never

635
00:25:09,930 --> 00:25:14,670
seen a solution that actually works well

636
00:25:11,280 --> 00:25:15,899
for software developers again the only

637
00:25:14,670 --> 00:25:18,510
solution that I've generally ever seen

638
00:25:15,900 --> 00:25:19,890
is you either give the software

639
00:25:18,510 --> 00:25:21,870
developers the ability to sign

640
00:25:19,890 --> 00:25:23,610
themselves in which case that kind of

641
00:25:21,870 --> 00:25:26,159
defeats the point of having signing or

642
00:25:23,610 --> 00:25:27,719
you whitelist a folder in which case

643
00:25:26,160 --> 00:25:29,450
again mint defeats the point of

644
00:25:27,720 --> 00:25:32,700
application whitelisting

645
00:25:29,450 --> 00:25:34,410
macros for finance personnel I know of a

646
00:25:32,700 --> 00:25:35,850
number of different organizations that

647
00:25:34,410 --> 00:25:38,040
if you disabled macros in them the

648
00:25:35,850 --> 00:25:40,439
entire organization would stop that's

649
00:25:38,040 --> 00:25:41,909
the business process they've built so

650
00:25:40,440 --> 00:25:44,190
you find other controls to defend

651
00:25:41,910 --> 00:25:46,470
against those things av if you're a

652
00:25:44,190 --> 00:25:48,270
penetration tester I'm sure if you're a

653
00:25:46,470 --> 00:25:49,500
red team you've you've disabled AV on

654
00:25:48,270 --> 00:25:52,200
your system therefore you're not

655
00:25:49,500 --> 00:25:54,950
compliant with that control like that's

656
00:25:52,200 --> 00:25:54,950
that's the way it is

657
00:25:56,930 --> 00:26:04,830
so I've talked about where where things

658
00:26:02,430 --> 00:26:07,710
are right now with the item a couple of

659
00:26:04,830 --> 00:26:10,740
tips just to sort of help people who may

660
00:26:07,710 --> 00:26:14,100
be at that point but also need to be -

661
00:26:10,740 --> 00:26:15,540
what is the next step of this so risk as

662
00:26:14,100 --> 00:26:17,760
I said earlier it's not this single

663
00:26:15,540 --> 00:26:21,300
thing risk is a it's a concept of lots

664
00:26:17,760 --> 00:26:24,840
of businesses applied to is applied to

665
00:26:21,300 --> 00:26:27,030
finance and so why do we treat cyber

666
00:26:24,840 --> 00:26:28,350
risk differently cyber risk is just

667
00:26:27,030 --> 00:26:30,540
another part of risk within an

668
00:26:28,350 --> 00:26:31,980
organization so realistically you should

669
00:26:30,540 --> 00:26:34,039
end up with this integrated risk

670
00:26:31,980 --> 00:26:36,860
management model

671
00:26:34,039 --> 00:26:38,600
the impacts of risk are calculated in

672
00:26:36,860 --> 00:26:40,639
the risk therefore you can compare a

673
00:26:38,600 --> 00:26:42,709
cyber risk versus a financial risk

674
00:26:40,640 --> 00:26:44,419
because they both have an impact on the

675
00:26:42,710 --> 00:26:48,529
business we shouldn't be treating them

676
00:26:44,419 --> 00:26:50,659
separately a great way of looking at

677
00:26:48,529 --> 00:26:53,179
this if you have worked in a military

678
00:26:50,659 --> 00:26:54,770
context or you've or you have the

679
00:26:53,179 --> 00:26:56,120
ability to see some sort of military

680
00:26:54,770 --> 00:26:58,460
doctrine is looking at military risk

681
00:26:56,120 --> 00:26:59,479
management models and mission risk which

682
00:26:58,460 --> 00:27:01,610
is what I talked about at the beginning

683
00:26:59,480 --> 00:27:03,110
mission risk is understanding all the

684
00:27:01,610 --> 00:27:04,879
risks to my operation within a given

685
00:27:03,110 --> 00:27:06,709
area of operations

686
00:27:04,880 --> 00:27:08,990
they could be cyber risks they could be

687
00:27:06,710 --> 00:27:10,549
shooting risks they could be health

688
00:27:08,990 --> 00:27:11,899
risks they could be I don't have the

689
00:27:10,549 --> 00:27:13,850
logistics in this place

690
00:27:11,899 --> 00:27:15,678
so transition to that point where you

691
00:27:13,850 --> 00:27:17,570
understand what will stop you doing your

692
00:27:15,679 --> 00:27:19,940
mission what will stop you from

693
00:27:17,570 --> 00:27:22,070
achieving your goals at a bigger picture

694
00:27:19,940 --> 00:27:24,260
level rather than focusing down on the

695
00:27:22,070 --> 00:27:25,580
lower level because arguably cyber might

696
00:27:24,260 --> 00:27:31,250
not actually be the most important thing

697
00:27:25,580 --> 00:27:32,449
for you to consider and that's it I know

698
00:27:31,250 --> 00:27:34,490
this has probably rubbed a few people

699
00:27:32,450 --> 00:27:35,750
the wrong way and I am somewhat

700
00:27:34,490 --> 00:27:39,169
apologetic but I'm not entirely

701
00:27:35,750 --> 00:27:40,640
apologetic I am one of those people I'm

702
00:27:39,169 --> 00:27:42,440
a techie I know that we should implement

703
00:27:40,640 --> 00:27:44,659
controls but I think the best option for

704
00:27:42,440 --> 00:27:47,929
the user is this sort of model moving

705
00:27:44,659 --> 00:27:49,760
forward so thank you very much for for

706
00:27:47,929 --> 00:27:51,950
listening and I know there's a few

707
00:27:49,760 --> 00:27:53,919
questions which I am trying to work out

708
00:27:51,950 --> 00:27:56,299
the answers to in the comments I've

709
00:27:53,919 --> 00:28:03,020
copied down some other questions there

710
00:27:56,299 --> 00:28:04,490
are a ton of questions I think question

711
00:28:03,020 --> 00:28:07,750
time for you maybe you can watch the

712
00:28:04,490 --> 00:28:07,750
slack because I'm pretty sure as you

713
00:28:10,929 --> 00:28:15,950
yeah okay so as I ask the questions if

714
00:28:13,700 --> 00:28:18,799
people generate more questions from your

715
00:28:15,950 --> 00:28:21,740
answers yeah because I think I missed a

716
00:28:18,799 --> 00:28:23,389
question with Eleanor but the first

717
00:28:21,740 --> 00:28:26,059
question came from Dave Dave right at

718
00:28:23,390 --> 00:28:28,159
the side of your talk sure he said so

719
00:28:26,059 --> 00:28:30,740
how do we assess hardening options that

720
00:28:28,159 --> 00:28:34,549
are not mentioned in the is M good

721
00:28:30,740 --> 00:28:37,070
question so this is a problem this is an

722
00:28:34,549 --> 00:28:38,240
interesting one because so obviously not

723
00:28:37,070 --> 00:28:40,189
I'm gonna go on about it but obviously I

724
00:28:38,240 --> 00:28:41,840
work in a vendor space right and so the

725
00:28:40,190 --> 00:28:42,980
moment you mention a control that's not

726
00:28:41,840 --> 00:28:44,510
on the ice M I know there are some

727
00:28:42,980 --> 00:28:46,309
customers that go it's on the ice and we

728
00:28:44,510 --> 00:28:47,030
don't care so how do you actually prove

729
00:28:46,309 --> 00:28:48,830
the value

730
00:28:47,030 --> 00:28:50,120
and realistically it goes back to that

731
00:28:48,830 --> 00:28:51,830
risk management approach so if you can

732
00:28:50,120 --> 00:28:54,080
demonstrate the value of how your

733
00:28:51,830 --> 00:28:56,840
technology or this hardening option

734
00:28:54,080 --> 00:28:58,040
defends against a given threat and the

735
00:28:56,840 --> 00:28:59,959
organization agrees that that's

736
00:28:58,040 --> 00:29:02,210
irrelevant threats of their systems then

737
00:28:59,960 --> 00:29:04,130
you should be good the problem I think

738
00:29:02,210 --> 00:29:05,360
in that space is not necessarily how do

739
00:29:04,130 --> 00:29:06,770
you demonstrate it it's how do you

740
00:29:05,360 --> 00:29:07,760
actually get to that conversation where

741
00:29:06,770 --> 00:29:12,200
you're having a risk management approach

742
00:29:07,760 --> 00:29:13,610
conversation in the first place now one

743
00:29:12,200 --> 00:29:15,110
of the things that came out of this I am

744
00:29:13,610 --> 00:29:17,389
and I was having lots of discussions at

745
00:29:15,110 --> 00:29:20,419
the time when this happened and the ccsl

746
00:29:17,390 --> 00:29:22,400
changes came out as well was you know

747
00:29:20,420 --> 00:29:23,900
it's probably not a great move for small

748
00:29:22,400 --> 00:29:25,340
organizations and small government at

749
00:29:23,900 --> 00:29:27,740
the moment because they're not really at

750
00:29:25,340 --> 00:29:29,780
this level the longer-term picture is

751
00:29:27,740 --> 00:29:31,010
this will help to bring in those

752
00:29:29,780 --> 00:29:36,980
controls to understand how those

753
00:29:31,010 --> 00:29:40,850
controls to impact your systems so the

754
00:29:36,980 --> 00:29:44,630
next question was from Craig small he

755
00:29:40,850 --> 00:29:47,360
said how does the new Isum help

756
00:29:44,630 --> 00:29:49,700
implementers in a project before if my

757
00:29:47,360 --> 00:29:51,290
widget had a desktop and a name server

758
00:29:49,700 --> 00:29:55,310
I knew the former didn't really need it

759
00:29:51,290 --> 00:29:59,389
and the latter did I have a definite

760
00:29:55,310 --> 00:30:00,860
goal now what's my target who decides so

761
00:29:59,390 --> 00:30:03,230
realistically again this comes down to

762
00:30:00,860 --> 00:30:05,570
my statement about resourcing and so

763
00:30:03,230 --> 00:30:07,310
organizations generally have some form

764
00:30:05,570 --> 00:30:08,659
of vulnerability assessment team and so

765
00:30:07,310 --> 00:30:09,889
that run nessus on the system so you

766
00:30:08,660 --> 00:30:12,260
understand the vulnerabilities on the

767
00:30:09,890 --> 00:30:13,550
organization the corollary to that is

768
00:30:12,260 --> 00:30:14,930
you need to actually have some kind of

769
00:30:13,550 --> 00:30:16,370
threat team so you need to understand

770
00:30:14,930 --> 00:30:20,150
the threats the organization the threats

771
00:30:16,370 --> 00:30:22,189
of the systems so so realistically in my

772
00:30:20,150 --> 00:30:23,600
opinion again you would go talk to your

773
00:30:22,190 --> 00:30:25,430
threat team you'd say okay I'm building

774
00:30:23,600 --> 00:30:26,959
this system it's gonna have these

775
00:30:25,430 --> 00:30:29,000
components it's gonna have this way of

776
00:30:26,960 --> 00:30:30,470
working who are the likely threats that

777
00:30:29,000 --> 00:30:32,240
are going to target that system if they

778
00:30:30,470 --> 00:30:33,350
have access to it also what data is

779
00:30:32,240 --> 00:30:34,640
stored in it because that's the

780
00:30:33,350 --> 00:30:37,040
important thing it's always about the

781
00:30:34,640 --> 00:30:39,710
outcome and they should be able to come

782
00:30:37,040 --> 00:30:40,940
back to you and say you know it's this

783
00:30:39,710 --> 00:30:43,040
threat or it's this threat and these are

784
00:30:40,940 --> 00:30:44,300
the controls you put in place now I

785
00:30:43,040 --> 00:30:47,720
understand that most people don't have

786
00:30:44,300 --> 00:30:53,360
the resources for that so realistically

787
00:30:47,720 --> 00:30:55,190
in those circumstances you should try

788
00:30:53,360 --> 00:30:56,060
and do that research yourself so I

789
00:30:55,190 --> 00:30:57,530
understand what you're building

790
00:30:56,060 --> 00:30:59,649
understand the context of the

791
00:30:57,530 --> 00:31:00,809
organization you're building it for

792
00:30:59,650 --> 00:31:03,720
understand

793
00:31:00,809 --> 00:31:05,158
who's likely to target you and therefore

794
00:31:03,720 --> 00:31:06,299
implement those controls based on that

795
00:31:05,159 --> 00:31:08,879
there's a lot of open source

796
00:31:06,299 --> 00:31:11,100
intelligence information that allows you

797
00:31:08,879 --> 00:31:12,990
to you know mitre attack is a great

798
00:31:11,100 --> 00:31:14,879
example of something that nowadays has a

799
00:31:12,990 --> 00:31:17,970
great there's a database on the model

800
00:31:14,879 --> 00:31:19,649
tank webpage toast about all the um all

801
00:31:17,970 --> 00:31:20,519
the threat actors they can think of and

802
00:31:19,649 --> 00:31:22,498
that it tells you about all the

803
00:31:20,519 --> 00:31:23,940
techniques they use and therefore it

804
00:31:22,499 --> 00:31:25,860
tells you how to defend against those

805
00:31:23,940 --> 00:31:27,870
techniques so you find out who's

806
00:31:25,860 --> 00:31:29,668
relevant to you you find the techniques

807
00:31:27,870 --> 00:31:34,018
you build the controls to defeat the

808
00:31:29,669 --> 00:31:44,639
techniques just mesmerized by all your

809
00:31:34,019 --> 00:31:52,200
discord chat by the way I think Benzies

810
00:31:44,639 --> 00:31:53,699
gave you ten out of ten actually maybe

811
00:31:52,200 --> 00:32:01,200
I'll turn that off I think Sylvia is

812
00:31:53,700 --> 00:32:06,590
gonna ask a question on oversight think

813
00:32:01,200 --> 00:32:06,590
to add to this as well but familiar with

814
00:32:07,850 --> 00:32:13,590
maybe doesn't take security as as

815
00:32:11,460 --> 00:32:15,570
importantly is that the organization

816
00:32:13,590 --> 00:32:16,830
tell you how do you mean sure sort of

817
00:32:15,570 --> 00:32:19,080
Poland you how can you have a motorcycle

818
00:32:16,830 --> 00:32:21,590
if they aren't implementing you know

819
00:32:19,080 --> 00:32:23,759
controls and mediations

820
00:32:21,590 --> 00:32:29,189
like previously you could just say well

821
00:32:23,759 --> 00:32:31,799
networks unaccredited because yeah but

822
00:32:29,190 --> 00:32:33,210
even then like they would still run that

823
00:32:31,799 --> 00:32:34,440
because you would find some opera like

824
00:32:33,210 --> 00:32:36,749
again this is speaking from experience

825
00:32:34,440 --> 00:32:37,860
there would be an operational reason why

826
00:32:36,749 --> 00:32:39,509
their network had to continue or

827
00:32:37,860 --> 00:32:43,439
something else and and arguably the only

828
00:32:39,509 --> 00:32:45,840
way is to hold to hold people to account

829
00:32:43,440 --> 00:32:47,279
for these things I was listening to a

830
00:32:45,840 --> 00:32:48,539
presentation by a vendor the other week

831
00:32:47,279 --> 00:32:50,940
and they talked about the target breach

832
00:32:48,539 --> 00:32:52,499
in 2013 and the important thing about

833
00:32:50,940 --> 00:32:55,100
target breach was it was the first time

834
00:32:52,499 --> 00:32:57,299
that a CEO got fired because of a breach

835
00:32:55,100 --> 00:32:59,129
and I think there's a there's a lesson

836
00:32:57,299 --> 00:33:02,700
in there which is breaches are in our

837
00:32:59,129 --> 00:33:05,549
visible yes but if you don't do

838
00:33:02,700 --> 00:33:06,409
everything you can to stop a breach then

839
00:33:05,549 --> 00:33:08,220
you should be held accountable

840
00:33:06,409 --> 00:33:09,840
ultimately until we see that

841
00:33:08,220 --> 00:33:12,179
accountability being held against people

842
00:33:09,840 --> 00:33:14,009
nothing's really going to change now

843
00:33:12,179 --> 00:33:14,560
there is the coral I keep saying that

844
00:33:14,009 --> 00:33:16,480
word but

845
00:33:14,560 --> 00:33:18,700
say it there is the opposite to that

846
00:33:16,480 --> 00:33:20,260
which is you did everything you could

847
00:33:18,700 --> 00:33:22,270
and you super hacked well that should be

848
00:33:20,260 --> 00:33:23,770
evidence through what you did there

849
00:33:22,270 --> 00:33:25,480
should be evidence through a clear chain

850
00:33:23,770 --> 00:33:27,730
of understanding of yet we found these

851
00:33:25,480 --> 00:33:29,020
threats we know these risks we did

852
00:33:27,730 --> 00:33:30,970
everything we could and something came

853
00:33:29,020 --> 00:33:33,100
out of nowhere so you have the pokerface

854
00:33:30,970 --> 00:33:34,810
evidence to join that and as I said

855
00:33:33,100 --> 00:33:37,929
until accountability comes in for these

856
00:33:34,810 --> 00:33:39,250
things it's it's not gonna change it

857
00:33:37,930 --> 00:33:41,020
doesn't matter whether you have a

858
00:33:39,250 --> 00:33:42,220
compliance based approach where you say

859
00:33:41,020 --> 00:33:44,830
you must implement the essential eight

860
00:33:42,220 --> 00:33:48,010
because it doesn't work like we've seen

861
00:33:44,830 --> 00:33:48,939
the chance we know the AMA reports they

862
00:33:48,010 --> 00:33:50,500
keep coming out and they're saying

863
00:33:48,940 --> 00:33:55,150
you're not complying about compliant and

864
00:33:50,500 --> 00:34:00,220
people just shrug there was one more

865
00:33:55,150 --> 00:34:02,920
question from maybe he was asking he was

866
00:34:00,220 --> 00:34:05,230
asking do you think there's a

867
00:34:02,920 --> 00:34:08,050
scalability problem for expertise in

868
00:34:05,230 --> 00:34:11,110
this space I assume there's gonna be

869
00:34:08,050 --> 00:34:15,159
more expertise needed to assess those

870
00:34:11,110 --> 00:34:16,560
risks yes well yes but that's kind of a

871
00:34:15,159 --> 00:34:19,899
given

872
00:34:16,560 --> 00:34:22,330
let's be I'm very much of the opinion we

873
00:34:19,899 --> 00:34:24,730
need to sort of stop lying to ourselves

874
00:34:22,330 --> 00:34:26,319
about some of these things our socks and

875
00:34:24,730 --> 00:34:28,179
security teams are not resourced the way

876
00:34:26,320 --> 00:34:29,500
they should be arguably we should have

877
00:34:28,179 --> 00:34:31,149
been doing things like vulnerability

878
00:34:29,500 --> 00:34:32,918
assessments thrown in towel before the

879
00:34:31,149 --> 00:34:34,418
eyes have changed however with the ice

880
00:34:32,918 --> 00:34:38,139
and changes it's just made it even more

881
00:34:34,418 --> 00:34:39,158
relevant realistically it's put the onus

882
00:34:38,139 --> 00:34:40,870
back on

883
00:34:39,159 --> 00:34:42,429
it's almost provided a carrot and a

884
00:34:40,870 --> 00:34:43,870
stick for these government organizations

885
00:34:42,429 --> 00:34:46,870
the carrot being okay you can choose

886
00:34:43,870 --> 00:34:48,250
your own controls now awesome the stick

887
00:34:46,870 --> 00:34:50,049
is you need to make sure you don't get

888
00:34:48,250 --> 00:34:54,219
hacked and you need to make you need to

889
00:34:50,050 --> 00:34:56,010
take the the the role of being the

890
00:34:54,219 --> 00:34:58,959
person who understands your systems and

891
00:34:56,010 --> 00:35:00,550
maybe that will work this approach has

892
00:34:58,960 --> 00:35:04,260
only been in for six months and and I'm

893
00:35:00,550 --> 00:35:06,280
seeing some changes but I I won't say

894
00:35:04,260 --> 00:35:08,350
this is why I said at the beginning

895
00:35:06,280 --> 00:35:09,670
there's a resourcing problem so sorry

896
00:35:08,350 --> 00:35:11,259
you need to be well resourced

897
00:35:09,670 --> 00:35:12,670
the argument is we don't have enough

898
00:35:11,260 --> 00:35:13,660
people well the argument is we don't

899
00:35:12,670 --> 00:35:14,950
have enough people because we don't have

900
00:35:13,660 --> 00:35:16,330
enough people it's not because we're not

901
00:35:14,950 --> 00:35:18,069
doing a risk management approach we're

902
00:35:16,330 --> 00:35:20,470
doing a compliance approach it doesn't

903
00:35:18,070 --> 00:35:22,300
matter we still need more people we

904
00:35:20,470 --> 00:35:23,919
still need to fix that problem which is

905
00:35:22,300 --> 00:35:25,270
why we do things like C size which is

906
00:35:23,920 --> 00:35:26,680
why we do all these things to bring

907
00:35:25,270 --> 00:35:27,860
people on to try and get them interested

908
00:35:26,680 --> 00:35:31,490
to get them in the

909
00:35:27,860 --> 00:35:34,400
yeah and he sort of followed up with and

910
00:35:31,490 --> 00:35:37,669
should some sister some system along the

911
00:35:34,400 --> 00:35:40,490
lines of SSL lab test be constructed by

912
00:35:37,670 --> 00:35:43,880
maybe a a steal a CSC to help system

913
00:35:40,490 --> 00:35:45,500
implementers self assess other than you

914
00:35:43,880 --> 00:35:49,400
don't think so nice because it's that's

915
00:35:45,500 --> 00:35:51,230
compliance yeah some tool is not going

916
00:35:49,400 --> 00:35:52,970
to understand the specifics of your

917
00:35:51,230 --> 00:35:54,860
environment it's not going to understand

918
00:35:52,970 --> 00:35:58,459
that you haven't implemented that

919
00:35:54,860 --> 00:36:02,330
control for a given reason I don't like

920
00:35:58,460 --> 00:36:04,760
as a maybe as a non-binding thing

921
00:36:02,330 --> 00:36:05,840
potentially but like to actually ensure

922
00:36:04,760 --> 00:36:07,220
they were getting good security outcomes

923
00:36:05,840 --> 00:36:09,620
it's got to be driven by humans

924
00:36:07,220 --> 00:36:10,910
unfortunately that's you know we have

925
00:36:09,620 --> 00:36:12,680
that problem and we have the resourcing

926
00:36:10,910 --> 00:36:16,359
problem well we have both but we can't I

927
00:36:12,680 --> 00:36:19,419
have to deal with it at this point I

928
00:36:16,360 --> 00:36:22,150
think maybes typing I don't know he's

929
00:36:19,420 --> 00:36:24,590
commenting on that but why I'm waiting

930
00:36:22,150 --> 00:36:26,660
maybe do um do you have any questions oh

931
00:36:24,590 --> 00:36:31,670
mighty ones questions maybe you could

932
00:36:26,660 --> 00:36:36,440
jump into the to the slide they all want

933
00:36:31,670 --> 00:36:38,750
to talk a little bit more about say he

934
00:36:36,440 --> 00:36:43,520
did say good insight Thanks so there you

935
00:36:38,750 --> 00:36:45,770
go you've convinced him great all right

936
00:36:43,520 --> 00:36:46,460
thanks again and that's great to hear

937
00:36:45,770 --> 00:36:50,620
from you

938
00:36:46,460 --> 00:36:50,620
Norris thank you very much guys yeah

939
00:36:50,860 --> 00:36:56,950
right which brings us to our final I did

940
00:36:54,590 --> 00:36:56,950
get tall

