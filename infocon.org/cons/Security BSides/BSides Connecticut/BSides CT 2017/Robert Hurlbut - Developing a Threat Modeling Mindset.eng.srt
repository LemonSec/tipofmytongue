1
00:00:00,030 --> 00:00:04,950
okay let's let's welcome our next

2
00:00:02,250 --> 00:00:06,750
speaker robber Hurlbutt and he's talking

3
00:00:04,950 --> 00:00:08,280
about developing a threat modeling

4
00:00:06,750 --> 00:00:15,800
mindset give him a warm welcome thank

5
00:00:08,280 --> 00:00:18,420
you good morning

6
00:00:15,800 --> 00:00:21,720
I've been travelling quite a bit across

7
00:00:18,420 --> 00:00:24,990
country seems like a lot of times I just

8
00:00:21,720 --> 00:00:26,970
drive the airport and I'd fly 500 miles

9
00:00:24,990 --> 00:00:28,619
and then come back that's one of the few

10
00:00:26,970 --> 00:00:31,650
times that I'm actually in my own state

11
00:00:28,619 --> 00:00:34,590
giving a talk in my own place so I'm

12
00:00:31,650 --> 00:00:36,120
living in Enfield Connecticut so it was

13
00:00:34,590 --> 00:00:37,440
actually an easier Drive this morning

14
00:00:36,120 --> 00:00:40,589
than getting on a plane and flying

15
00:00:37,440 --> 00:00:41,629
somewhere to do this so glad to be with

16
00:00:40,590 --> 00:00:44,489
you this morning

17
00:00:41,629 --> 00:00:47,839
so a little bit about myself I am a

18
00:00:44,489 --> 00:00:50,190
longtime software developer architect

19
00:00:47,840 --> 00:00:53,399
worked with a lot of teams over the

20
00:00:50,190 --> 00:00:55,649
years a lot of as an independent

21
00:00:53,399 --> 00:00:57,870
consultant working with a lot of

22
00:00:55,649 --> 00:01:00,840
projects finance healthcare government

23
00:00:57,870 --> 00:01:03,120
many other industries and just recently

24
00:01:00,840 --> 00:01:05,220
though I years of being independent I'm

25
00:01:03,120 --> 00:01:08,450
now working for another company or and

26
00:01:05,220 --> 00:01:11,939
so I'm no longer independent but

27
00:01:08,450 --> 00:01:13,830
finishing out a set of talks that I'm

28
00:01:11,939 --> 00:01:18,059
giving at various places on threatened

29
00:01:13,830 --> 00:01:20,460
modeling and so welcome here today again

30
00:01:18,060 --> 00:01:22,350
about me I also am a co-host of the

31
00:01:20,460 --> 00:01:23,729
application security podcast I'm not

32
00:01:22,350 --> 00:01:25,740
sure if you've heard of it or seen

33
00:01:23,729 --> 00:01:27,570
anything about it but it's something

34
00:01:25,740 --> 00:01:30,119
we've been doing for now over a year and

35
00:01:27,570 --> 00:01:32,158
we've had a - a couple seasons and some

36
00:01:30,119 --> 00:01:34,200
really interesting podcast interviews

37
00:01:32,159 --> 00:01:38,040
out there so I welcome you to check it

38
00:01:34,200 --> 00:01:41,130
out just out of curiosity how many of

39
00:01:38,040 --> 00:01:44,520
you have heard of threat modeling before

40
00:01:41,130 --> 00:01:46,649
you came here today okay how many of you

41
00:01:44,520 --> 00:01:50,460
it that's a very new concept you don't

42
00:01:46,649 --> 00:01:53,250
know much about it today okay a couple

43
00:01:50,460 --> 00:01:56,189
of you great how many of you are using

44
00:01:53,250 --> 00:02:01,380
it today in your day to day work or

45
00:01:56,189 --> 00:02:03,329
often in your own work now let's say

46
00:02:01,380 --> 00:02:04,979
often because to me if you're going to

47
00:02:03,329 --> 00:02:07,860
do threat modeling you need to do it a

48
00:02:04,979 --> 00:02:11,370
lot in in terms of how you think and how

49
00:02:07,860 --> 00:02:13,140
you you go about your your work you need

50
00:02:11,370 --> 00:02:13,590
to be thinking about threat modeling or

51
00:02:13,140 --> 00:02:15,750
at least the

52
00:02:13,590 --> 00:02:18,540
the potential threats are coming into

53
00:02:15,750 --> 00:02:21,030
your system quite often and also maybe

54
00:02:18,540 --> 00:02:24,150
how many have you an actual program of

55
00:02:21,030 --> 00:02:26,970
threat modeling in your okay excellent

56
00:02:24,150 --> 00:02:32,340
yeah of course do you do in the back

57
00:02:26,970 --> 00:02:34,109
there Brian so great I hope that at the

58
00:02:32,340 --> 00:02:34,920
end of this and certainly going forward

59
00:02:34,110 --> 00:02:37,410
this is something you're going to

60
00:02:34,920 --> 00:02:40,309
consider more in putting in place into

61
00:02:37,410 --> 00:02:45,150
your own organization into your own

62
00:02:40,310 --> 00:02:47,660
programs and teams and so on so this is

63
00:02:45,150 --> 00:02:51,450
a something I saw on Twitter recently

64
00:02:47,660 --> 00:02:54,060
from Miko - and who is the CTO of F

65
00:02:51,450 --> 00:02:55,920
secure and he spent it's funny he's been

66
00:02:54,060 --> 00:02:58,349
treat weeding things that he wrote in

67
00:02:55,920 --> 00:03:00,660
2012 five years later and they all seem

68
00:02:58,349 --> 00:03:02,819
to be very relevant but this one in

69
00:03:00,660 --> 00:03:04,980
particular it's just not fair when the

70
00:03:02,819 --> 00:03:08,280
attackers cheat they really should be

71
00:03:04,980 --> 00:03:11,819
regulated to attack our defense is only

72
00:03:08,280 --> 00:03:14,910
the way we want them to anybody ever

73
00:03:11,819 --> 00:03:16,950
felt that way you know what is the deal

74
00:03:14,910 --> 00:03:18,209
why do they keep doing things we don't

75
00:03:16,950 --> 00:03:20,690
want them to do why aren't they playing

76
00:03:18,209 --> 00:03:23,579
by the rules why aren't they following

77
00:03:20,690 --> 00:03:24,900
some kind of guideline that we put out

78
00:03:23,579 --> 00:03:27,049
there instead of doing something

79
00:03:24,900 --> 00:03:30,180
different or trying something different

80
00:03:27,049 --> 00:03:32,880
but you know the reality is they're not

81
00:03:30,180 --> 00:03:35,880
there they're thinking of other ways of

82
00:03:32,880 --> 00:03:37,769
new ways to try it again get in now the

83
00:03:35,880 --> 00:03:39,840
reality is there's a lot of attacks that

84
00:03:37,769 --> 00:03:41,459
are just the basic stuff right we're not

85
00:03:39,840 --> 00:03:44,010
patching so they figure out what the

86
00:03:41,459 --> 00:03:46,799
patch is or the opposite and do that to

87
00:03:44,010 --> 00:03:49,048
get in very simple stuff but there are

88
00:03:46,799 --> 00:03:53,190
things that we find that are really

89
00:03:49,049 --> 00:03:55,500
clever and interesting and so in terms

90
00:03:53,190 --> 00:03:57,840
of trying to defend our systems we have

91
00:03:55,500 --> 00:04:01,650
to think differently in order to try to

92
00:03:57,840 --> 00:04:03,810
defend and so that's where I think about

93
00:04:01,650 --> 00:04:06,359
you know this this idea of a security

94
00:04:03,810 --> 00:04:08,459
mindset or as we'll go further into a

95
00:04:06,359 --> 00:04:09,930
threat modeling mindset and in

96
00:04:08,459 --> 00:04:14,220
particular Bruce Schneier wrote about

97
00:04:09,930 --> 00:04:16,380
this back in 2008 in a post everybody

98
00:04:14,220 --> 00:04:18,720
familiar with Bruce Schneier heard the

99
00:04:16,380 --> 00:04:20,399
name he say well-known cryptographer

100
00:04:18,720 --> 00:04:23,460
many years ago he's written a lot of

101
00:04:20,399 --> 00:04:26,909
good books on cryptography be tall but

102
00:04:23,460 --> 00:04:27,510
also more recently more popular security

103
00:04:26,909 --> 00:04:29,520
books out

104
00:04:27,510 --> 00:04:33,270
they're on data and other kinds of

105
00:04:29,520 --> 00:04:34,919
things and in particular he wrote this

106
00:04:33,270 --> 00:04:38,430
that security requires a particular

107
00:04:34,920 --> 00:04:40,080
mindset professional security

108
00:04:38,430 --> 00:04:42,840
professional is at least the good ones

109
00:04:40,080 --> 00:04:45,180
see the world differently how many of

110
00:04:42,840 --> 00:04:47,130
you can relate to that that once you got

111
00:04:45,180 --> 00:04:48,780
into security maybe you were before

112
00:04:47,130 --> 00:04:51,150
doing something else but once you got

113
00:04:48,780 --> 00:04:53,880
into security and the more you're into

114
00:04:51,150 --> 00:04:56,280
security you see things differently you

115
00:04:53,880 --> 00:04:58,230
see an open door and you know what's

116
00:04:56,280 --> 00:05:01,140
going on there maybe that's something we

117
00:04:58,230 --> 00:05:02,670
need to take care of or you see certain

118
00:05:01,140 --> 00:05:04,260
ports open and say well we know why are

119
00:05:02,670 --> 00:05:05,880
they open that doesn't make sense

120
00:05:04,260 --> 00:05:08,370
so you think of things and you see

121
00:05:05,880 --> 00:05:12,000
things very differently a little bit

122
00:05:08,370 --> 00:05:15,060
later he wrote another blog post in 2012

123
00:05:12,000 --> 00:05:16,740
about teaching that to others so we in

124
00:05:15,060 --> 00:05:18,960
the security field if you've been there

125
00:05:16,740 --> 00:05:20,910
for a little while at some point you

126
00:05:18,960 --> 00:05:23,010
realize that there's others that need to

127
00:05:20,910 --> 00:05:24,870
know this as well it can't be just a few

128
00:05:23,010 --> 00:05:26,580
of us that have this knowledge in this

129
00:05:24,870 --> 00:05:30,120
understanding we got to teach others and

130
00:05:26,580 --> 00:05:32,539
he pointed to a story about our in a

131
00:05:30,120 --> 00:05:35,940
paper actually about a couple of

132
00:05:32,540 --> 00:05:39,000
instructors at a Naval Academy that had

133
00:05:35,940 --> 00:05:41,490
a class of teaching cybersecurity to

134
00:05:39,000 --> 00:05:43,950
students and one of the things that they

135
00:05:41,490 --> 00:05:45,330
did was they came to the class they said

136
00:05:43,950 --> 00:05:48,630
alright tomorrow we're going to have a

137
00:05:45,330 --> 00:05:49,680
pop quiz or a test and what it is is

138
00:05:48,630 --> 00:05:54,090
we're going to tell you what it is and

139
00:05:49,680 --> 00:05:57,120
we want you to pass however you do it

140
00:05:54,090 --> 00:06:02,039
whatever you need to do pass it but the

141
00:05:57,120 --> 00:06:05,100
the test is right pi 3.14159265 all the

142
00:06:02,040 --> 00:06:09,480
way down to 100 decimal places on the

143
00:06:05,100 --> 00:06:12,050
test and we want you to cheat we want

144
00:06:09,480 --> 00:06:15,180
you to come in and figure out a way to

145
00:06:12,050 --> 00:06:17,400
get a hundred on this test and so the

146
00:06:15,180 --> 00:06:19,980
next day they gave the tests and and

147
00:06:17,400 --> 00:06:21,960
sure enough everybody passed but the

148
00:06:19,980 --> 00:06:23,760
ways that they figured out how to pass

149
00:06:21,960 --> 00:06:26,370
were really interesting for example

150
00:06:23,760 --> 00:06:28,560
somebody had on the ceiling tile written

151
00:06:26,370 --> 00:06:30,900
out pi so they just looked up and wrote

152
00:06:28,560 --> 00:06:32,790
it somebody else had a little plate with

153
00:06:30,900 --> 00:06:34,409
a doughnut or something and then you

154
00:06:32,790 --> 00:06:36,990
lift the doughnut and there was pie

155
00:06:34,410 --> 00:06:39,570
written on the plate in a little sheet

156
00:06:36,990 --> 00:06:41,009
of paper somebody brought a book with

157
00:06:39,570 --> 00:06:42,960
the back cover

158
00:06:41,009 --> 00:06:44,669
it was a book by the author and they

159
00:06:42,960 --> 00:06:47,609
said oh there's my book except on the

160
00:06:44,669 --> 00:06:49,049
back cover they had written out pie and

161
00:06:47,610 --> 00:06:51,479
so you couldn't really tell that it was

162
00:06:49,050 --> 00:06:53,879
actually part of the book cover and all

163
00:06:51,479 --> 00:06:58,020
kinds of other creative ways in order to

164
00:06:53,879 --> 00:07:00,479
cheat and pass this test not the normal

165
00:06:58,020 --> 00:07:03,299
way of doing things and one of the

166
00:07:00,479 --> 00:07:05,909
quotes that Bruce cher pointed to from

167
00:07:03,300 --> 00:07:07,860
that paper was this one to teach your

168
00:07:05,909 --> 00:07:09,629
students yourself and your students to

169
00:07:07,860 --> 00:07:12,539
cheat we've always been taught to color

170
00:07:09,629 --> 00:07:15,569
inside the lines stick to the rules and

171
00:07:12,539 --> 00:07:17,509
never ever cheat in seeking

172
00:07:15,569 --> 00:07:19,979
cybersecurity you must drop that mindset

173
00:07:17,509 --> 00:07:22,349
and so that's what I'm talking about is

174
00:07:19,979 --> 00:07:23,699
that we already know the attackers we

175
00:07:22,349 --> 00:07:25,498
already know they're trying to cheat

176
00:07:23,699 --> 00:07:27,210
they're trying to circumvent the

177
00:07:25,499 --> 00:07:29,099
controls we have in place they're trying

178
00:07:27,210 --> 00:07:31,620
to get around the things that we're

179
00:07:29,099 --> 00:07:34,889
doing to try to protect our systems in

180
00:07:31,620 --> 00:07:38,249
order to circumvent that or in order to

181
00:07:34,889 --> 00:07:39,930
deal with that we have to also think in

182
00:07:38,249 --> 00:07:43,439
a similar way and I believe you know

183
00:07:39,930 --> 00:07:44,879
think outside of the box essentially so

184
00:07:43,439 --> 00:07:46,919
that's what I'm thinking about is that

185
00:07:44,879 --> 00:07:48,809
you know that security mindset that

186
00:07:46,919 --> 00:07:51,149
thinking outside the box thinking

187
00:07:48,809 --> 00:07:52,620
differently than we normally do and I

188
00:07:51,149 --> 00:07:55,550
think that's really again where threat

189
00:07:52,620 --> 00:07:59,069
modeling comes in is helping us to think

190
00:07:55,550 --> 00:08:02,669
in a bigger picture about our system

191
00:07:59,069 --> 00:08:04,319
what are the potential threats and how

192
00:08:02,669 --> 00:08:06,448
are some ways that we can deal with it

193
00:08:04,319 --> 00:08:09,029
and again think about you know maybe how

194
00:08:06,449 --> 00:08:10,949
an attacker would look at this maybe

195
00:08:09,029 --> 00:08:12,479
some ways that our defenses are not set

196
00:08:10,949 --> 00:08:15,839
up correctly that we need to think a

197
00:08:12,479 --> 00:08:16,769
little bit better about and so on so

198
00:08:15,839 --> 00:08:18,209
what is threat Mollie

199
00:08:16,769 --> 00:08:20,580
well threat mulling it to me is

200
00:08:18,209 --> 00:08:23,069
something we already do if you're

201
00:08:20,580 --> 00:08:25,830
locking the door to your house you're

202
00:08:23,069 --> 00:08:27,779
putting down the windows you're locking

203
00:08:25,830 --> 00:08:29,758
the doors to your car you're already

204
00:08:27,779 --> 00:08:32,010
thinking about these things because as

205
00:08:29,759 --> 00:08:33,449
you move away from those places you know

206
00:08:32,010 --> 00:08:35,338
you leave your house you leave your car

207
00:08:33,448 --> 00:08:38,399
you're already thinking about well what

208
00:08:35,339 --> 00:08:40,289
could somebody do if they came upon my

209
00:08:38,399 --> 00:08:42,899
house or my car and see that I've got

210
00:08:40,289 --> 00:08:45,209
belongings in my car and so on you're

211
00:08:42,899 --> 00:08:47,639
already thinking about some things and

212
00:08:45,209 --> 00:08:51,149
in particular you're thinking about you

213
00:08:47,639 --> 00:08:53,370
know what could go wrong what are the

214
00:08:51,149 --> 00:08:54,720
risks here of leaving things out in the

215
00:08:53,370 --> 00:08:56,310
open and so on

216
00:08:54,720 --> 00:08:58,110
acting accordingly and we again we do

217
00:08:56,310 --> 00:09:01,050
this a lot throughout our personal lives

218
00:08:58,110 --> 00:09:02,220
we we think about ways that something

219
00:09:01,050 --> 00:09:03,779
could happen something could go wrong

220
00:09:02,220 --> 00:09:06,000
and that's essentially what threat

221
00:09:03,779 --> 00:09:08,579
modeling is you're thinking about what

222
00:09:06,000 --> 00:09:09,959
could go wrong and now what do I do now

223
00:09:08,579 --> 00:09:12,258
that I know that information or have

224
00:09:09,959 --> 00:09:16,109
that information

225
00:09:12,259 --> 00:09:17,759
you're probably hopefully already doing

226
00:09:16,110 --> 00:09:20,100
these things in your security strategy

227
00:09:17,759 --> 00:09:20,990
how about pin testing you have those

228
00:09:20,100 --> 00:09:23,670
okay

229
00:09:20,990 --> 00:09:27,029
vulnerability assessments something like

230
00:09:23,670 --> 00:09:29,189
that - tools sass tools running those

231
00:09:27,029 --> 00:09:31,529
kinds of things against source code and

232
00:09:29,189 --> 00:09:33,060
running systems and so on and then a lot

233
00:09:31,529 --> 00:09:34,350
of other automated tools hopefully

234
00:09:33,060 --> 00:09:36,119
you're doing a lot of those logging we

235
00:09:34,350 --> 00:09:38,459
talked about a little bit earlier in the

236
00:09:36,120 --> 00:09:40,920
in the previous session if you're not

237
00:09:38,459 --> 00:09:43,349
doing threat modeling though you're

238
00:09:40,920 --> 00:09:45,689
missing a lot and I can say that with

239
00:09:43,350 --> 00:09:47,670
confidence because guess what your pen

240
00:09:45,689 --> 00:09:50,399
test is never really going to understand

241
00:09:47,670 --> 00:09:51,990
fully your business process all that's

242
00:09:50,399 --> 00:09:54,480
going to ever really find are the things

243
00:09:51,990 --> 00:09:55,680
on the outside and test a few things but

244
00:09:54,480 --> 00:09:57,629
it's not going to really know for

245
00:09:55,680 --> 00:10:01,258
example that your password is stored

246
00:09:57,629 --> 00:10:04,379
with an md5 or a sha-1 it won't know

247
00:10:01,259 --> 00:10:05,970
that has no clue it won't know certain

248
00:10:04,379 --> 00:10:08,939
things and decisions that you made

249
00:10:05,970 --> 00:10:10,769
inside your system just well same thing

250
00:10:08,939 --> 00:10:12,750
with vulnerability assessments it may

251
00:10:10,769 --> 00:10:15,329
find a few vulnerabilities and certainly

252
00:10:12,750 --> 00:10:17,309
that can maybe give it a clue about the

253
00:10:15,329 --> 00:10:18,870
kinds of threats that might be in your

254
00:10:17,309 --> 00:10:21,059
system but it won't know all the

255
00:10:18,870 --> 00:10:22,889
business processes it won't know all the

256
00:10:21,059 --> 00:10:24,870
decisions that you made underneath and

257
00:10:22,889 --> 00:10:27,750
the same thing with you know checking

258
00:10:24,870 --> 00:10:29,579
your code you'll find some things but it

259
00:10:27,750 --> 00:10:31,350
won't tell you everything and that's

260
00:10:29,579 --> 00:10:34,529
again where threat modeling comes in

261
00:10:31,350 --> 00:10:37,740
where you're giving a more holistic view

262
00:10:34,529 --> 00:10:39,389
of what's my secure design not at the

263
00:10:37,740 --> 00:10:41,339
code level but at the bigger picture

264
00:10:39,389 --> 00:10:43,110
what are some things that we have made

265
00:10:41,339 --> 00:10:45,660
decisions about or will be making

266
00:10:43,110 --> 00:10:50,100
decisions about in how we build out our

267
00:10:45,660 --> 00:10:52,379
application or our system and so by

268
00:10:50,100 --> 00:10:54,420
definition it's essentially that process

269
00:10:52,379 --> 00:10:56,779
of understanding your system and the

270
00:10:54,420 --> 00:10:59,849
potential threats against your system I

271
00:10:56,779 --> 00:11:00,839
like to think of it as critical thinking

272
00:10:59,850 --> 00:11:04,019
about security

273
00:11:00,839 --> 00:11:06,959
a typical threat model includes these

274
00:11:04,019 --> 00:11:08,700
four things you can see variations of

275
00:11:06,959 --> 00:11:10,469
them but this is what I liked

276
00:11:08,700 --> 00:11:12,900
includ if I if I can if I'm working with

277
00:11:10,470 --> 00:11:14,580
a team is that understanding of the

278
00:11:12,900 --> 00:11:16,740
system that may include a drawing of

279
00:11:14,580 --> 00:11:18,120
some sort a diagram of some sort or at

280
00:11:16,740 --> 00:11:19,380
least an understanding of what is it

281
00:11:18,120 --> 00:11:22,110
that we're building what is it that

282
00:11:19,380 --> 00:11:24,750
we're trying to protect any identified

283
00:11:22,110 --> 00:11:27,390
threats that are we might find in the

284
00:11:24,750 --> 00:11:29,730
system any mitigations countermeasures

285
00:11:27,390 --> 00:11:31,650
and so on and then also any risks

286
00:11:29,730 --> 00:11:33,630
associated with all those things we've

287
00:11:31,650 --> 00:11:35,610
found and the priorities associated with

288
00:11:33,630 --> 00:11:37,500
those so for example if I find a hundred

289
00:11:35,610 --> 00:11:39,660
threats I'm not going to fix all hundred

290
00:11:37,500 --> 00:11:42,290
necessarily maybe some things are more

291
00:11:39,660 --> 00:11:44,520
critical than others and so the risk

292
00:11:42,290 --> 00:11:46,620
managing that and understanding that

293
00:11:44,520 --> 00:11:50,040
helps you in terms of prioritizing work

294
00:11:46,620 --> 00:11:51,030
later on quick definitions assets are

295
00:11:50,040 --> 00:11:52,620
the things we're trying to protect

296
00:11:51,030 --> 00:11:55,020
usually that's what a lot of people

297
00:11:52,620 --> 00:11:56,250
focus on when they're doing threat

298
00:11:55,020 --> 00:11:57,569
modeling sometimes as they think about

299
00:11:56,250 --> 00:11:59,400
okay what am i protecting what are the

300
00:11:57,570 --> 00:12:02,490
things that are important to to me into

301
00:11:59,400 --> 00:12:04,410
others we also think about the agent you

302
00:12:02,490 --> 00:12:07,050
know who is it that once to get in and

303
00:12:04,410 --> 00:12:09,630
who is it that wants to do something to

304
00:12:07,050 --> 00:12:11,160
our system and so that could be a person

305
00:12:09,630 --> 00:12:13,050
it could be a process that's that's

306
00:12:11,160 --> 00:12:16,260
trying to get in and by the way they all

307
00:12:13,050 --> 00:12:17,760
look like that so you have to have that

308
00:12:16,260 --> 00:12:19,230
in every you know at least in somewhere

309
00:12:17,760 --> 00:12:21,420
in the slide deck some somebody with

310
00:12:19,230 --> 00:12:23,880
that or the other one which I have in a

311
00:12:21,420 --> 00:12:25,380
moment you'll see the threat is anything

312
00:12:23,880 --> 00:12:28,140
that's going to exploit the

313
00:12:25,380 --> 00:12:29,430
vulnerability and intentionally or

314
00:12:28,140 --> 00:12:30,930
accidentally and that's kind of funny in

315
00:12:29,430 --> 00:12:33,089
a way because a lot of times we think

316
00:12:30,930 --> 00:12:34,140
about the intentional attacks and the

317
00:12:33,090 --> 00:12:36,090
attentional threats but they're also

318
00:12:34,140 --> 00:12:37,980
accidental ones I mean we saw that a

319
00:12:36,090 --> 00:12:39,960
couple of days ago I saw an article

320
00:12:37,980 --> 00:12:41,880
about I think there was a problem with a

321
00:12:39,960 --> 00:12:43,950
fire extinguisher that that took as

322
00:12:41,880 --> 00:12:46,560
you're down in Europe like what

323
00:12:43,950 --> 00:12:49,110
and then AWS I've seen that go down

324
00:12:46,560 --> 00:12:50,160
because of somebody hitting a server or

325
00:12:49,110 --> 00:12:52,680
doing something with a server

326
00:12:50,160 --> 00:12:55,469
incorrectly and it took down AWS in a

327
00:12:52,680 --> 00:12:56,729
certain large area and there are all

328
00:12:55,470 --> 00:12:58,890
kinds of things that can happen

329
00:12:56,730 --> 00:12:59,940
accidentally that actually can become

330
00:12:58,890 --> 00:13:01,770
threats and you're like well what

331
00:12:59,940 --> 00:13:04,890
happens if somebody does this do I ever

332
00:13:01,770 --> 00:13:07,079
think about that and ultimately again

333
00:13:04,890 --> 00:13:09,710
they can you know the threat itself can

334
00:13:07,080 --> 00:13:12,120
obtain a damage or destroy an asset

335
00:13:09,710 --> 00:13:15,590
vulnerability is the flaw in the system

336
00:13:12,120 --> 00:13:18,060
that X lets you realize the threat so I

337
00:13:15,590 --> 00:13:19,560
like to think that you know there some

338
00:13:18,060 --> 00:13:22,050
people use them interchangeably but to

339
00:13:19,560 --> 00:13:24,000
me they're not you know the threat

340
00:13:22,050 --> 00:13:25,949
is realized because the vulnerability is

341
00:13:24,000 --> 00:13:27,420
present if I'm able to mitigate the

342
00:13:25,950 --> 00:13:30,180
vulnerability then the threat is also

343
00:13:27,420 --> 00:13:32,880
minimized and so just understand that

344
00:13:30,180 --> 00:13:34,560
you know that we look at vulnerabilities

345
00:13:32,880 --> 00:13:36,360
but in terms of threat modeling we want

346
00:13:34,560 --> 00:13:38,989
to try to understand what is the threat

347
00:13:36,360 --> 00:13:40,920
so I might have a sequel injection

348
00:13:38,990 --> 00:13:43,649
vulnerability in an application and

349
00:13:40,920 --> 00:13:45,719
website well what's the threat here well

350
00:13:43,649 --> 00:13:47,519
be by using the sequel injection

351
00:13:45,720 --> 00:13:49,350
vulnerability I'm able to get to the

352
00:13:47,519 --> 00:13:51,510
database and I'm able to retrieve data

353
00:13:49,350 --> 00:13:53,730
I'm able to change tables I'm able to do

354
00:13:51,510 --> 00:13:57,029
all kinds of things if I'm able to

355
00:13:53,730 --> 00:14:00,180
mitigate a sequel injection problem then

356
00:13:57,029 --> 00:14:01,529
I minimize the threat and so those two

357
00:14:00,180 --> 00:14:04,829
kind of work together but they're not

358
00:14:01,529 --> 00:14:07,560
the same thing the other thing that also

359
00:14:04,829 --> 00:14:09,089
helps drive your threat modeling is risk

360
00:14:07,560 --> 00:14:11,819
and understanding risk and that

361
00:14:09,089 --> 00:14:15,000
potential of the of the loss damage

362
00:14:11,820 --> 00:14:17,420
destruction of that asset and in the

363
00:14:15,000 --> 00:14:19,440
threat realizing the the vulnerability

364
00:14:17,420 --> 00:14:21,089
and so that's very important is

365
00:14:19,440 --> 00:14:22,680
understanding risk and that helps drive

366
00:14:21,089 --> 00:14:24,779
a lot of things that we do in security

367
00:14:22,680 --> 00:14:26,339
anyway I don't know about you but I

368
00:14:24,779 --> 00:14:29,820
think the mouse has a chance how about

369
00:14:26,339 --> 00:14:30,839
you he does and this is the other the

370
00:14:29,820 --> 00:14:32,940
other thing you have to have in a slide

371
00:14:30,839 --> 00:14:36,240
is is this guy with the you know the

372
00:14:32,940 --> 00:14:37,740
cowl and everything and the attack is a

373
00:14:36,240 --> 00:14:39,930
motivator sufficiently skilled trade

374
00:14:37,740 --> 00:14:42,620
agent and I like to think about this in

375
00:14:39,930 --> 00:14:44,939
terms of that can vary among different

376
00:14:42,620 --> 00:14:45,480
areas the motivations can be very

377
00:14:44,940 --> 00:14:47,220
different

378
00:14:45,480 --> 00:14:49,290
you know the nation-state hacker can be

379
00:14:47,220 --> 00:14:51,480
very different than the the hacktivists

380
00:14:49,290 --> 00:14:54,420
the the person who's trying to make a

381
00:14:51,480 --> 00:14:56,120
point with your site and changing it and

382
00:14:54,420 --> 00:14:58,529
then of course the sufficiently skilled

383
00:14:56,120 --> 00:15:00,180
threat agent you know that can vary as

384
00:14:58,529 --> 00:15:02,070
well they can be a script kitty that we

385
00:15:00,180 --> 00:15:04,680
ought used to hear about years ago all

386
00:15:02,070 --> 00:15:06,660
the way up into the nation-state hackers

387
00:15:04,680 --> 00:15:08,790
and attackers that are essentially on a

388
00:15:06,660 --> 00:15:11,069
job I mean they're paid a salary they

389
00:15:08,790 --> 00:15:13,680
have you know if you ever watch they say

390
00:15:11,070 --> 00:15:15,449
that in some places if you watch where

391
00:15:13,680 --> 00:15:17,310
the attackers are come coming from they

392
00:15:15,449 --> 00:15:18,839
have certain hours just like we do eight

393
00:15:17,310 --> 00:15:20,969
hours that they're working and doing

394
00:15:18,839 --> 00:15:23,130
their job because they have a job they

395
00:15:20,970 --> 00:15:24,480
go in they attack they go home and they

396
00:15:23,130 --> 00:15:27,839
get their paycheck or something like

397
00:15:24,480 --> 00:15:29,190
that very funny and interesting but all

398
00:15:27,839 --> 00:15:31,470
of these again taking advantage of a

399
00:15:29,190 --> 00:15:34,949
vulnerability in terms of vocabulary

400
00:15:31,470 --> 00:15:36,029
this is something that John Steven put

401
00:15:34,949 --> 00:15:37,709
together

402
00:15:36,029 --> 00:15:39,389
some time ago it just shows you how

403
00:15:37,709 --> 00:15:40,768
everything's gonna related to each other

404
00:15:39,389 --> 00:15:42,929
and that's important just to understand

405
00:15:40,769 --> 00:15:45,869
in terms of this this whole idea of

406
00:15:42,929 --> 00:15:47,759
threat modeling a few approaches to

407
00:15:45,869 --> 00:15:49,470
threat modeling one is the software

408
00:15:47,759 --> 00:15:51,689
centric which is the one I focus mostly

409
00:15:49,470 --> 00:15:55,079
on I work with developer teams a lot and

410
00:15:51,689 --> 00:15:57,959
trying to help them understand the the

411
00:15:55,079 --> 00:16:00,358
process understand okay what is it that

412
00:15:57,959 --> 00:16:02,699
we're doing in the system how does it

413
00:16:00,359 --> 00:16:04,889
interact with other things and then

414
00:16:02,699 --> 00:16:06,809
build our our threat model from that and

415
00:16:04,889 --> 00:16:09,359
it's focused again on secure design it's

416
00:16:06,809 --> 00:16:11,639
focused on data flow diagrams which

417
00:16:09,359 --> 00:16:14,489
we'll see in a moment another way is

418
00:16:11,639 --> 00:16:17,279
this asset centric way a lot of times

419
00:16:14,489 --> 00:16:19,499
people use asset are very attacked trees

420
00:16:17,279 --> 00:16:21,539
to try to figure out how do I get from

421
00:16:19,499 --> 00:16:23,669
point A to point B to finally get to my

422
00:16:21,539 --> 00:16:26,699
goal and kind of a decision tree to get

423
00:16:23,669 --> 00:16:28,709
there I will see that some people say

424
00:16:26,699 --> 00:16:31,949
well I that's how I start with an asset

425
00:16:28,709 --> 00:16:33,268
and that's okay and certain in certain

426
00:16:31,949 --> 00:16:34,919
cases it makes a lot of sense especially

427
00:16:33,269 --> 00:16:37,199
if you have a system that's already been

428
00:16:34,919 --> 00:16:39,359
built but if you have nothing built yet

429
00:16:37,199 --> 00:16:41,219
and you're starting from scratch you may

430
00:16:39,359 --> 00:16:44,549
say for example I want to build an

431
00:16:41,220 --> 00:16:45,869
e-commerce site well okay what are you

432
00:16:44,549 --> 00:16:47,429
going to do with that well I'm gonna

433
00:16:45,869 --> 00:16:49,619
have credit cards want to take credit

434
00:16:47,429 --> 00:16:51,209
cards I'm going to take payments well

435
00:16:49,619 --> 00:16:53,159
where are you gonna store it well I may

436
00:16:51,209 --> 00:16:55,319
either store it in a database that I own

437
00:16:53,159 --> 00:16:56,819
and then I'm going to do my own PCI

438
00:16:55,319 --> 00:16:59,459
compliance and all those kinds of things

439
00:16:56,819 --> 00:17:00,628
or I may say I don't want to manage that

440
00:16:59,459 --> 00:17:02,549
I want to move it off to somewhere else

441
00:17:00,629 --> 00:17:05,490
and now those assets are somewhere else

442
00:17:02,549 --> 00:17:07,740
and it's somebody else is handling that

443
00:17:05,490 --> 00:17:09,839
so then your threat model can be very

444
00:17:07,740 --> 00:17:12,419
different depending on if you host the

445
00:17:09,839 --> 00:17:15,168
asset or you let somebody else host the

446
00:17:12,419 --> 00:17:18,029
asset so I'd like to say that for asset

447
00:17:15,169 --> 00:17:19,709
centric threat modeling it's I think it

448
00:17:18,029 --> 00:17:21,720
more in line if you already have

449
00:17:19,709 --> 00:17:23,759
something but if you're designing from

450
00:17:21,720 --> 00:17:25,620
scratch I'd like to look at the process

451
00:17:23,759 --> 00:17:28,649
first and then you'll uncover where the

452
00:17:25,619 --> 00:17:31,379
assets go and then finally another way

453
00:17:28,649 --> 00:17:34,168
is the attacker centric method which is

454
00:17:31,379 --> 00:17:36,570
basically focusing on the profile of the

455
00:17:34,169 --> 00:17:39,029
attacker the different patterns that

456
00:17:36,570 --> 00:17:41,039
they're using sometimes I'll use this as

457
00:17:39,029 --> 00:17:42,299
well but I use it at the very end I like

458
00:17:41,039 --> 00:17:44,429
to try to figure out all the other

459
00:17:42,299 --> 00:17:46,679
things first and then figure out okay

460
00:17:44,429 --> 00:17:48,720
who's interested in this and see if that

461
00:17:46,679 --> 00:17:49,299
might filter out my threat model too

462
00:17:48,720 --> 00:17:51,039
maybe

463
00:17:49,299 --> 00:17:55,809
point to some things that are more

464
00:17:51,039 --> 00:17:57,279
likely in this particular system this is

465
00:17:55,809 --> 00:18:00,158
something that I've been thinking about

466
00:17:57,279 --> 00:18:01,299
for a little while is teach threat

467
00:18:00,159 --> 00:18:03,850
modeling to your teams

468
00:18:01,299 --> 00:18:06,158
you know conduct training in your

469
00:18:03,850 --> 00:18:09,399
companies like like what we're doing

470
00:18:06,159 --> 00:18:12,879
here help teams threat model their own

471
00:18:09,399 --> 00:18:15,639
projects work with them if you haven't

472
00:18:12,879 --> 00:18:18,070
done this before just sitting down with

473
00:18:15,639 --> 00:18:20,498
a group of developers or engineers other

474
00:18:18,070 --> 00:18:22,178
engineers system engineers and thinking

475
00:18:20,499 --> 00:18:24,609
through a lot of these things I find

476
00:18:22,179 --> 00:18:26,230
that it's really beneficial there are

477
00:18:24,609 --> 00:18:28,239
some things that maybe they didn't even

478
00:18:26,230 --> 00:18:30,279
realize about the entire system yeah

479
00:18:28,239 --> 00:18:31,659
maybe for a developer they are working

480
00:18:30,279 --> 00:18:34,600
on the UI they don't know how the

481
00:18:31,659 --> 00:18:36,369
database works the middle tier doesn't

482
00:18:34,600 --> 00:18:38,619
know how the UI and the and the database

483
00:18:36,369 --> 00:18:40,509
necessarily works or at least fully and

484
00:18:38,619 --> 00:18:43,149
how it maybe interact with other parts

485
00:18:40,509 --> 00:18:45,220
of the system but if you have a team and

486
00:18:43,149 --> 00:18:46,959
put them together and and try to build a

487
00:18:45,220 --> 00:18:48,279
threat model you'll find that there's a

488
00:18:46,960 --> 00:18:51,789
lot of things that they learn really

489
00:18:48,279 --> 00:18:53,590
well and then encourage beginning threat

490
00:18:51,789 --> 00:18:56,200
modeling with each project each new

491
00:18:53,590 --> 00:18:57,639
feature so you may have never done this

492
00:18:56,200 --> 00:19:00,609
and teams may never have done this

493
00:18:57,639 --> 00:19:01,959
before but if you encourage them that

494
00:19:00,609 --> 00:19:03,820
now okay now you know something about

495
00:19:01,960 --> 00:19:06,580
threat modeling now let's continue to do

496
00:19:03,820 --> 00:19:10,269
this and add it to every new thing that

497
00:19:06,580 --> 00:19:12,220
you do that's also another way of making

498
00:19:10,269 --> 00:19:14,019
sure that threat modeling is integrated

499
00:19:12,220 --> 00:19:15,820
throughout your system and then follow

500
00:19:14,019 --> 00:19:17,710
up make sure that they they understand

501
00:19:15,820 --> 00:19:20,049
it make sure they're working with it I'm

502
00:19:17,710 --> 00:19:22,179
working with some teams that have made

503
00:19:20,049 --> 00:19:23,918
commitments to say that now every team

504
00:19:22,179 --> 00:19:26,350
must have a threat model every project

505
00:19:23,919 --> 00:19:28,509
must have a threat model and it must be

506
00:19:26,350 --> 00:19:30,279
reviewed and and so on so it's that

507
00:19:28,509 --> 00:19:31,659
encouragement that you know it's not

508
00:19:30,279 --> 00:19:35,379
just something we talk about but it's

509
00:19:31,659 --> 00:19:37,330
something that we do so a typical threat

510
00:19:35,379 --> 00:19:40,509
modeling session like if I was doing a

511
00:19:37,330 --> 00:19:41,949
workshop and you know it's a hands-on

512
00:19:40,509 --> 00:19:44,619
what we usually do is we try to figure

513
00:19:41,950 --> 00:19:46,119
out what's the domain who knows what's

514
00:19:44,619 --> 00:19:49,959
going on in the system get the team

515
00:19:46,119 --> 00:19:51,699
together not just one person's job how

516
00:19:49,960 --> 00:19:54,909
many of it's just one person's job to do

517
00:19:51,700 --> 00:19:56,409
security today that's all you know

518
00:19:54,909 --> 00:19:57,659
there's one person doing everything go

519
00:19:56,409 --> 00:20:02,409
figure out the rest of our system

520
00:19:57,659 --> 00:20:03,100
anybody doing that probably my goal is

521
00:20:02,409 --> 00:20:04,570
not to

522
00:20:03,100 --> 00:20:06,939
that my goal is to try to get people

523
00:20:04,570 --> 00:20:07,570
together and because they know it better

524
00:20:06,940 --> 00:20:09,549
than you do

525
00:20:07,570 --> 00:20:11,139
typically you know the developers know

526
00:20:09,549 --> 00:20:12,520
something and when you do that and you

527
00:20:11,140 --> 00:20:15,610
get a team together and you ask to see

528
00:20:12,520 --> 00:20:18,129
the architect how's this set up what's

529
00:20:15,610 --> 00:20:19,629
your system look like and the architect

530
00:20:18,130 --> 00:20:23,020
says well it does this and does that and

531
00:20:19,630 --> 00:20:24,490
the developers say no doesn't not really

532
00:20:23,020 --> 00:20:26,620
there are a couple things that we change

533
00:20:24,490 --> 00:20:30,010
or a couple shortcuts that we took that

534
00:20:26,620 --> 00:20:32,889
we're not so obvious and so everybody

535
00:20:30,010 --> 00:20:34,900
learned something from that also focus

536
00:20:32,890 --> 00:20:36,909
on business and technical goals the

537
00:20:34,900 --> 00:20:39,039
business goals may be different than

538
00:20:36,909 --> 00:20:41,020
your security goals for example I

539
00:20:39,039 --> 00:20:42,570
remember working with a financial

540
00:20:41,020 --> 00:20:44,470
company where we talked about

541
00:20:42,570 --> 00:20:46,780
implementing some kind of two-factor

542
00:20:44,470 --> 00:20:48,640
authentication for their users and they

543
00:20:46,780 --> 00:20:51,789
had two sets of users the admin or

544
00:20:48,640 --> 00:20:52,990
managers and regular users and we talked

545
00:20:51,789 --> 00:20:54,700
about that I said you need to have that

546
00:20:52,990 --> 00:20:56,520
for everybody I mean this is a financial

547
00:20:54,700 --> 00:20:59,650
company why don't you have it already

548
00:20:56,520 --> 00:21:02,289
that's my goal they said to me that you

549
00:20:59,650 --> 00:21:04,000
know we have different schedules what

550
00:21:02,289 --> 00:21:06,030
we'd like to do is try to put two-factor

551
00:21:04,000 --> 00:21:08,590
authentication in for the managers first

552
00:21:06,030 --> 00:21:10,389
get that in place see how that works and

553
00:21:08,590 --> 00:21:12,100
then eventually get the users because

554
00:21:10,390 --> 00:21:14,100
you know we just want to gradually get

555
00:21:12,100 --> 00:21:16,149
them there that was their business goal

556
00:21:14,100 --> 00:21:17,889
slightly different than my security goal

557
00:21:16,150 --> 00:21:19,659
but that's okay and that you know we

558
00:21:17,890 --> 00:21:21,730
built a threat model around that that

559
00:21:19,659 --> 00:21:23,260
okay here's our time period here and

560
00:21:21,730 --> 00:21:26,580
here's our time period here that our

561
00:21:23,260 --> 00:21:29,080
threat model may change as a as a result

562
00:21:26,580 --> 00:21:31,570
technical goals you know everybody makes

563
00:21:29,080 --> 00:21:33,340
a decision about platforms about

564
00:21:31,570 --> 00:21:36,129
products that they're using about

565
00:21:33,340 --> 00:21:37,840
third-party libraries for example struts

566
00:21:36,130 --> 00:21:39,580
I know there's a company that we hear

567
00:21:37,840 --> 00:21:41,918
about the news lately that you know made

568
00:21:39,580 --> 00:21:44,139
a decision about struts whatever you

569
00:21:41,919 --> 00:21:47,440
know third-party library that you select

570
00:21:44,140 --> 00:21:49,630
it impacts your threat model it impacts

571
00:21:47,440 --> 00:21:51,250
what you're doing because every

572
00:21:49,630 --> 00:21:54,070
third-party library or anything else

573
00:21:51,250 --> 00:21:56,380
that you bring in they now become your

574
00:21:54,070 --> 00:21:58,539
responsibility and they change your

575
00:21:56,380 --> 00:22:01,179
threat model they change the things that

576
00:21:58,539 --> 00:22:03,280
potentially could make you vulnerable in

577
00:22:01,179 --> 00:22:05,049
your system based on the fact that you

578
00:22:03,280 --> 00:22:07,178
made a decision of bringing that in and

579
00:22:05,049 --> 00:22:09,879
so now you need to understand how does

580
00:22:07,179 --> 00:22:11,500
that impact your threat model for your

581
00:22:09,880 --> 00:22:14,559
particular application or your

582
00:22:11,500 --> 00:22:17,020
particular system and so really threat

583
00:22:14,559 --> 00:22:18,970
modeling must support all these goals

584
00:22:17,020 --> 00:22:21,070
not the other way around you don't come

585
00:22:18,970 --> 00:22:22,870
in and say well you know I who cares

586
00:22:21,070 --> 00:22:24,510
what you want to do let's do it this way

587
00:22:22,870 --> 00:22:26,649
no you need to understand where

588
00:22:24,510 --> 00:22:28,480
everybody else is coming from and then

589
00:22:26,650 --> 00:22:30,790
understand okay can we meet somewhere

590
00:22:28,480 --> 00:22:33,360
where security is important but it also

591
00:22:30,790 --> 00:22:36,399
helps support what you're doing as well

592
00:22:33,360 --> 00:22:39,250
meeting dates and times pretty focused

593
00:22:36,400 --> 00:22:41,050
sessions I like to do and then very

594
00:22:39,250 --> 00:22:43,360
important I've learned this over time is

595
00:22:41,050 --> 00:22:46,928
you know be honest leave ego at the door

596
00:22:43,360 --> 00:22:49,840
and no blaming because when you're doing

597
00:22:46,929 --> 00:22:51,610
this discovery situation or session you

598
00:22:49,840 --> 00:22:54,610
you want to make sure that people are

599
00:22:51,610 --> 00:22:56,260
not feeling I can't talk about this I

600
00:22:54,610 --> 00:22:57,790
can't say it because then everybody will

601
00:22:56,260 --> 00:22:59,379
point at me and say you know why did you

602
00:22:57,790 --> 00:23:01,120
mess that up why did you not do it right

603
00:22:59,380 --> 00:23:02,980
or what you know it's really about

604
00:23:01,120 --> 00:23:05,020
discovery so I always say you know be

605
00:23:02,980 --> 00:23:07,420
honest and and you know if it's

606
00:23:05,020 --> 00:23:10,750
something that was wrong say it and now

607
00:23:07,420 --> 00:23:13,230
you know and now you can go fix it so

608
00:23:10,750 --> 00:23:17,950
very simple tools to start with really

609
00:23:13,230 --> 00:23:20,020
there is no tool today an automated tool

610
00:23:17,950 --> 00:23:22,240
of some sort that I can fire up and

611
00:23:20,020 --> 00:23:24,400
point to my system and and push a button

612
00:23:22,240 --> 00:23:27,190
say build me a threat model it doesn't

613
00:23:24,400 --> 00:23:29,080
happen instead you you really need to

614
00:23:27,190 --> 00:23:30,370
understand the process and even the

615
00:23:29,080 --> 00:23:31,750
tools that are out there you need to

616
00:23:30,370 --> 00:23:33,939
understand something about the process

617
00:23:31,750 --> 00:23:36,100
to use them and I always say the

618
00:23:33,940 --> 00:23:39,100
simplest thing is the simplest thing

619
00:23:36,100 --> 00:23:41,260
white board some kind of graphing tool

620
00:23:39,100 --> 00:23:43,899
to record what you what you drew and

621
00:23:41,260 --> 00:23:45,160
what you came up with Word or Excel or

622
00:23:43,900 --> 00:23:49,059
something like that to record your

623
00:23:45,160 --> 00:23:50,770
findings there's a great resource from

624
00:23:49,059 --> 00:23:54,960
Dennis Cruz that's out there it's this

625
00:23:50,770 --> 00:23:57,280
page simple page to record your drawing

626
00:23:54,960 --> 00:23:59,380
record some information threats and so

627
00:23:57,280 --> 00:24:02,139
on and then on the back some information

628
00:23:59,380 --> 00:24:04,030
about you know basic threat modeling and

629
00:24:02,140 --> 00:24:06,250
and for example stride which we'll talk

630
00:24:04,030 --> 00:24:07,960
about a little bit and different things

631
00:24:06,250 --> 00:24:09,970
like that and I like to hand these out

632
00:24:07,960 --> 00:24:12,130
when I do a workshop a training workshop

633
00:24:09,970 --> 00:24:13,480
where people are doing hands-on I just

634
00:24:12,130 --> 00:24:15,370
hand this out so they can look at this

635
00:24:13,480 --> 00:24:18,190
and it helps them understand the

636
00:24:15,370 --> 00:24:20,709
concepts you can record things in a

637
00:24:18,190 --> 00:24:22,270
simple way as I said this is an example

638
00:24:20,710 --> 00:24:24,880
worksheet that I've used where you

639
00:24:22,270 --> 00:24:27,580
record the threats the countermeasures

640
00:24:24,880 --> 00:24:30,309
that you find some follow-up and this ID

641
00:24:27,580 --> 00:24:30,790
I like to record just to relate back to

642
00:24:30,309 --> 00:24:32,740
if

643
00:24:30,790 --> 00:24:34,360
wanted to to JIRA or something like that

644
00:24:32,740 --> 00:24:37,840
where you're tracking these kinds of

645
00:24:34,360 --> 00:24:39,850
things several tools out there there's

646
00:24:37,840 --> 00:24:42,129
the most famous I guess are well known

647
00:24:39,850 --> 00:24:44,530
as the Microsoft rep modeling tool which

648
00:24:42,130 --> 00:24:46,770
is a windows-based tool but there's some

649
00:24:44,530 --> 00:24:50,080
others the threat mauler the iris risk

650
00:24:46,770 --> 00:24:52,030
tools are paid tools threat money tool

651
00:24:50,080 --> 00:24:54,010
is free but these other two are not and

652
00:24:52,030 --> 00:24:55,240
then the latest one is this Oh a threat

653
00:24:54,010 --> 00:24:56,050
dragon which is a really interesting

654
00:24:55,240 --> 00:24:58,900
project

655
00:24:56,050 --> 00:25:00,909
a wasp project it's a free tool that's

656
00:24:58,900 --> 00:25:05,320
in progress right now that's out there

657
00:25:00,910 --> 00:25:06,790
so to get started when I'm working with

658
00:25:05,320 --> 00:25:08,169
a team and helping them understand

659
00:25:06,790 --> 00:25:10,710
threat modeling I like to go over the

660
00:25:08,170 --> 00:25:14,230
security principles defend in depth and

661
00:25:10,710 --> 00:25:16,300
least privilege and so on being

662
00:25:14,230 --> 00:25:17,740
reluctant to trust and so on just to

663
00:25:16,300 --> 00:25:20,889
make sure that there have some kind of

664
00:25:17,740 --> 00:25:23,110
ground grounding a great paper I like to

665
00:25:20,890 --> 00:25:24,990
point to is this I Triple E Computer

666
00:25:23,110 --> 00:25:27,550
Society Center for secure design

667
00:25:24,990 --> 00:25:29,140
avoiding the top 10 software security

668
00:25:27,550 --> 00:25:32,490
design flaws a lot of people have heard

669
00:25:29,140 --> 00:25:35,050
about oh wasps top-10 this one kind of

670
00:25:32,490 --> 00:25:37,360
looks at that in a similar way in terms

671
00:25:35,050 --> 00:25:40,570
of top 10 something but in this case its

672
00:25:37,360 --> 00:25:43,030
security flaws design flaws so for

673
00:25:40,570 --> 00:25:45,550
example not getting cryptography correct

674
00:25:43,030 --> 00:25:47,050
and you know mixing up a ten ocation

675
00:25:45,550 --> 00:25:49,180
authorization a lot of people do that

676
00:25:47,050 --> 00:25:51,040
where they'll reverse them or they'll

677
00:25:49,180 --> 00:25:52,690
think that their authentication is the

678
00:25:51,040 --> 00:25:56,260
same thing as the authorization it's not

679
00:25:52,690 --> 00:25:57,970
and so it talks about that a lot but

680
00:25:56,260 --> 00:25:59,470
mainly what is was doing is trying to

681
00:25:57,970 --> 00:26:01,720
point out the difference between a bug

682
00:25:59,470 --> 00:26:04,300
and a flaw a bugs and implementation

683
00:26:01,720 --> 00:26:06,640
level software problems so there's a

684
00:26:04,300 --> 00:26:09,159
mistake that's been made an imp one type

685
00:26:06,640 --> 00:26:12,540
of problem versus a flaw where you've

686
00:26:09,160 --> 00:26:17,440
made a decision at some point that has

687
00:26:12,540 --> 00:26:19,270
impacted your design so for example as I

688
00:26:17,440 --> 00:26:21,310
mentioned before a common when I see is

689
00:26:19,270 --> 00:26:22,930
and I ask this of all teams what are you

690
00:26:21,310 --> 00:26:25,720
doing to store passwords what are you

691
00:26:22,930 --> 00:26:27,190
using and many times I'll see a company

692
00:26:25,720 --> 00:26:30,580
that's been around for 10 years or more

693
00:26:27,190 --> 00:26:33,130
and they tell me I'm using md5 I'm using

694
00:26:30,580 --> 00:26:34,780
sha-1 and and does anybody ever know

695
00:26:33,130 --> 00:26:36,910
that did anybody know actually nobody

696
00:26:34,780 --> 00:26:39,430
really knew that except for you know the

697
00:26:36,910 --> 00:26:42,640
people that are using it in developers

698
00:26:39,430 --> 00:26:43,780
and so on and so that again is a flaw in

699
00:26:42,640 --> 00:26:46,120
your design

700
00:26:43,780 --> 00:26:47,649
made some time ago and now you've got to

701
00:26:46,120 --> 00:26:50,620
think about well how does that impact my

702
00:26:47,650 --> 00:26:55,270
design and my application are my system

703
00:26:50,620 --> 00:26:56,830
today and so now we get into the actual

704
00:26:55,270 --> 00:26:59,050
process itself the threat mounting

705
00:26:56,830 --> 00:27:02,080
process itself and the way I like to do

706
00:26:59,050 --> 00:27:04,360
this again I'm a software person and I

707
00:27:02,080 --> 00:27:09,159
focus a lot on software applications and

708
00:27:04,360 --> 00:27:10,689
design for secure systems but this is

709
00:27:09,160 --> 00:27:12,580
the way I followed it follows a lot of

710
00:27:10,690 --> 00:27:14,310
others that have said the same thing or

711
00:27:12,580 --> 00:27:16,990
the way they've done this essentially is

712
00:27:14,310 --> 00:27:18,610
understand your system you know what are

713
00:27:16,990 --> 00:27:21,340
you building what is that that's out

714
00:27:18,610 --> 00:27:23,560
there the threats and I like to use

715
00:27:21,340 --> 00:27:26,230
these questions and answers just ask

716
00:27:23,560 --> 00:27:28,780
questions probing questions at times and

717
00:27:26,230 --> 00:27:30,850
then determine the mitigations the

718
00:27:28,780 --> 00:27:32,350
countermeasures and the risks and then

719
00:27:30,850 --> 00:27:33,879
some kind of follow-through so don't

720
00:27:32,350 --> 00:27:35,860
just go through the exercise but

721
00:27:33,880 --> 00:27:41,580
actually you know have a follow up for

722
00:27:35,860 --> 00:27:41,580
it anybody you have a guess what this is

723
00:27:45,660 --> 00:27:50,740
yeah sure it's a website anybody ever

724
00:27:49,270 --> 00:27:52,990
seen where these been handed one of

725
00:27:50,740 --> 00:27:55,180
these and say this is our system yeah

726
00:27:52,990 --> 00:27:57,940
the three layer tier three tiered layers

727
00:27:55,180 --> 00:28:03,100
great yeah how much do I know about the

728
00:27:57,940 --> 00:28:05,950
security of the system though one thing

729
00:28:03,100 --> 00:28:08,169
I do know it's got HTTPS that's all I

730
00:28:05,950 --> 00:28:12,640
need to know right I'm good

731
00:28:08,170 --> 00:28:16,450
oh that's true that's true very good so

732
00:28:12,640 --> 00:28:17,650
now I know a little bit more right now I

733
00:28:16,450 --> 00:28:20,590
know a little bit more about the

734
00:28:17,650 --> 00:28:23,970
security of the system now you know we

735
00:28:20,590 --> 00:28:26,500
have roams I may have more than that but

736
00:28:23,970 --> 00:28:27,790
well the reality is as I said you're not

737
00:28:26,500 --> 00:28:29,920
going to know much about this at all and

738
00:28:27,790 --> 00:28:31,180
if somebody gives you this you know from

739
00:28:29,920 --> 00:28:33,970
a team and says hey this is our

740
00:28:31,180 --> 00:28:35,170
application that's not enough you need

741
00:28:33,970 --> 00:28:36,910
to understand a little bit more about

742
00:28:35,170 --> 00:28:38,560
the different decisions that are made

743
00:28:36,910 --> 00:28:40,990
inside the system the different business

744
00:28:38,560 --> 00:28:44,110
processes and how they're impacted by

745
00:28:40,990 --> 00:28:46,600
security or impacting security one way

746
00:28:44,110 --> 00:28:49,209
to do that and this is a method that's

747
00:28:46,600 --> 00:28:50,709
come out a number of years ago and and

748
00:28:49,210 --> 00:28:52,420
people still talk about the data flow

749
00:28:50,710 --> 00:28:56,110
diagrams but the reality is you can use

750
00:28:52,420 --> 00:28:57,549
whatever I don't really care if I'm

751
00:28:56,110 --> 00:28:59,738
working with a team and I ask

752
00:28:57,549 --> 00:29:01,239
so give me a diagram of something show

753
00:28:59,739 --> 00:29:03,970
me something go you know show me a

754
00:29:01,239 --> 00:29:05,830
firewall show me you know network

755
00:29:03,970 --> 00:29:08,169
devices or whatever I don't care how you

756
00:29:05,830 --> 00:29:09,879
do it doesn't matter to me but show me

757
00:29:08,169 --> 00:29:12,369
something so that we can at least have a

758
00:29:09,879 --> 00:29:14,408
discussion about what's there and see

759
00:29:12,369 --> 00:29:16,389
how things move across the system and

760
00:29:14,409 --> 00:29:18,549
then we can ask some questions about it

761
00:29:16,389 --> 00:29:22,269
but this is one way especially for

762
00:29:18,549 --> 00:29:24,369
software applications you'll see is this

763
00:29:22,269 --> 00:29:27,669
data flow diagram and the idea being

764
00:29:24,369 --> 00:29:31,418
that the somin klaich err we use

765
00:29:27,669 --> 00:29:33,220
external entity represent a user or some

766
00:29:31,419 --> 00:29:36,869
kind of somebody using the system in

767
00:29:33,220 --> 00:29:39,759
some way a process or multi processes so

768
00:29:36,869 --> 00:29:42,459
let's say send email okay that's a

769
00:29:39,759 --> 00:29:45,059
process and how is that done datastore

770
00:29:42,460 --> 00:29:47,529
two lines some kind of straight line

771
00:29:45,059 --> 00:29:48,970
with an arrow of some sort porting where

772
00:29:47,529 --> 00:29:51,190
the data flows through the system

773
00:29:48,970 --> 00:29:54,129
and then there's also this concept of a

774
00:29:51,190 --> 00:29:57,999
trust boundary which is an interesting

775
00:29:54,129 --> 00:30:00,009
thing it represents the idea that on one

776
00:29:57,999 --> 00:30:01,869
part of my system it's untrusted in

777
00:30:00,009 --> 00:30:04,059
another part of my system it's trusted

778
00:30:01,869 --> 00:30:06,220
maybe there's a authentication happening

779
00:30:04,059 --> 00:30:09,158
across the system maybe there's a some

780
00:30:06,220 --> 00:30:12,730
access control of some sort others can

781
00:30:09,159 --> 00:30:15,220
also have said that's kind of a a act so

782
00:30:12,730 --> 00:30:17,169
sorry attack surface it represents

783
00:30:15,220 --> 00:30:19,600
something that where you're more

784
00:30:17,169 --> 00:30:21,669
vulnerable for example you know what's

785
00:30:19,600 --> 00:30:25,209
your what's your attack service of a

786
00:30:21,669 --> 00:30:27,009
submarine well it's the outside right

787
00:30:25,210 --> 00:30:29,379
it's the whole but is that the only

788
00:30:27,009 --> 00:30:31,720
attack surface no there are many inside

789
00:30:29,379 --> 00:30:33,488
for example the captain's safe and so

790
00:30:31,720 --> 00:30:35,019
you can identify many different places

791
00:30:33,489 --> 00:30:38,350
in your system where you're more

792
00:30:35,019 --> 00:30:41,470
vulnerable where you're exposing systems

793
00:30:38,350 --> 00:30:43,840
exposing through you know ports and so

794
00:30:41,470 --> 00:30:45,639
on and things like that and so this

795
00:30:43,840 --> 00:30:47,439
dotted line kind of helps you understand

796
00:30:45,639 --> 00:30:51,209
and identify some areas that are more

797
00:30:47,440 --> 00:30:54,029
sensitive than other places so as I said

798
00:30:51,210 --> 00:30:57,220
drawing this kind of stuff helps you

799
00:30:54,029 --> 00:30:59,830
understand a bits of your system and

800
00:30:57,220 --> 00:31:01,539
where the data is flowing so you get

801
00:30:59,830 --> 00:31:05,769
started you say okay let's let's start

802
00:31:01,539 --> 00:31:07,149
at a high level view is I've got users

803
00:31:05,769 --> 00:31:08,889
and I've got admins okay there was a

804
00:31:07,149 --> 00:31:10,299
couple users or interactors within our

805
00:31:08,889 --> 00:31:11,229
system entities if you will in our

806
00:31:10,299 --> 00:31:13,000
system

807
00:31:11,230 --> 00:31:16,240
I have a server that represents a lot of

808
00:31:13,000 --> 00:31:17,860
processes that are happening inside and

809
00:31:16,240 --> 00:31:19,960
I've got data flow that's moving around

810
00:31:17,860 --> 00:31:23,110
in the system and some boundaries here

811
00:31:19,960 --> 00:31:25,330
as well that's a high level view ideally

812
00:31:23,110 --> 00:31:27,399
you want to move in a little further and

813
00:31:25,330 --> 00:31:30,580
so going back to that idea of the the

814
00:31:27,400 --> 00:31:32,290
web application more likely there's

815
00:31:30,580 --> 00:31:34,270
other things going on there's a lot of

816
00:31:32,290 --> 00:31:37,299
services that are being called there's a

817
00:31:34,270 --> 00:31:40,049
lot of databases or files and so on that

818
00:31:37,299 --> 00:31:42,220
may be involved inside the application

819
00:31:40,049 --> 00:31:43,750
and so you want to try to draw some of

820
00:31:42,220 --> 00:31:45,250
that and ideally when I'm working with a

821
00:31:43,750 --> 00:31:46,720
team I may even go a little further than

822
00:31:45,250 --> 00:31:49,030
this and I might say let's look at the

823
00:31:46,720 --> 00:31:50,410
authentication service there may be five

824
00:31:49,030 --> 00:31:52,270
other things they're going on there and

825
00:31:50,410 --> 00:31:54,610
let's drill into that and see what's

826
00:31:52,270 --> 00:31:56,080
going on there and so on but at some

827
00:31:54,610 --> 00:31:58,178
point you start with a high level and

828
00:31:56,080 --> 00:32:00,939
then you drill a little further in and

829
00:31:58,179 --> 00:32:02,590
so once you start to draw your your

830
00:32:00,940 --> 00:32:04,780
diagram the next thing you want to do is

831
00:32:02,590 --> 00:32:06,040
label some of these things about what is

832
00:32:04,780 --> 00:32:08,470
happening you know there's a request

833
00:32:06,040 --> 00:32:10,480
going on here there's some audit data

834
00:32:08,470 --> 00:32:12,309
being saved to the from the audit

835
00:32:10,480 --> 00:32:14,410
service to the the database where the

836
00:32:12,309 --> 00:32:16,990
audit tables are and so on and those

837
00:32:14,410 --> 00:32:18,690
kinds of things may be happening and

838
00:32:16,990 --> 00:32:20,919
then you want to decide or determine

839
00:32:18,690 --> 00:32:23,590
where are some boundaries where are some

840
00:32:20,919 --> 00:32:26,470
places that were more vulnerable or tax

841
00:32:23,590 --> 00:32:28,240
surface is more prominent and then you

842
00:32:26,470 --> 00:32:29,650
might also identify and numerate those

843
00:32:28,240 --> 00:32:32,590
kinds of things especially if you have a

844
00:32:29,650 --> 00:32:34,059
larger model where it continues to have

845
00:32:32,590 --> 00:32:36,129
a lot of things added to it and if

846
00:32:34,059 --> 00:32:38,230
you're diagramming this stuff you might

847
00:32:36,130 --> 00:32:39,880
have numbers that represent things and

848
00:32:38,230 --> 00:32:42,130
then on the side you might say okay this

849
00:32:39,880 --> 00:32:44,020
is these are the users these are this

850
00:32:42,130 --> 00:32:46,900
process and so on so you do that sort of

851
00:32:44,020 --> 00:32:48,549
thing as well and so at that point you

852
00:32:46,900 --> 00:32:50,049
know what we have there was just a

853
00:32:48,549 --> 00:32:51,429
diagram not much different than an

854
00:32:50,049 --> 00:32:54,850
architecture diagram that you might

855
00:32:51,429 --> 00:32:56,980
receive you know from a group great but

856
00:32:54,850 --> 00:32:58,840
it but it helps you at least to get

857
00:32:56,980 --> 00:33:00,490
started it's not your threat model yet

858
00:32:58,840 --> 00:33:01,780
you know some people will say well I got

859
00:33:00,490 --> 00:33:04,090
a data flow diagram therefore I got a

860
00:33:01,780 --> 00:33:06,129
threat model know you've got a data flow

861
00:33:04,090 --> 00:33:09,100
diagram or you've got a some kind of

862
00:33:06,130 --> 00:33:11,380
representation of your system that's all

863
00:33:09,100 --> 00:33:13,000
you have next step is really to

864
00:33:11,380 --> 00:33:15,190
understand what the threats are which of

865
00:33:13,000 --> 00:33:17,770
course is the most important part of

866
00:33:15,190 --> 00:33:20,440
threat modeling it's also most difficult

867
00:33:17,770 --> 00:33:22,570
and many ways to do this one way as I

868
00:33:20,440 --> 00:33:24,999
mentioned earlier is the attack trees is

869
00:33:22,570 --> 00:33:27,009
to figure out a decision tree

870
00:33:24,999 --> 00:33:29,399
you know I want to get to something and

871
00:33:27,009 --> 00:33:32,829
how do I get there if I want to do a

872
00:33:29,399 --> 00:33:35,018
CSRF attack what needs to be in place in

873
00:33:32,829 --> 00:33:37,839
order to get there and be able to

874
00:33:35,019 --> 00:33:39,369
execute it as an example you can look at

875
00:33:37,839 --> 00:33:40,688
some threat libraries to help you think

876
00:33:39,369 --> 00:33:43,178
about the kinds of threats that you

877
00:33:40,689 --> 00:33:44,499
might have in a system different

878
00:33:43,179 --> 00:33:46,959
checklists that are available out there

879
00:33:44,499 --> 00:33:50,769
you can also use use cases and misuse

880
00:33:46,959 --> 00:33:52,479
cases for example a use case would be as

881
00:33:50,769 --> 00:33:55,599
a user I want to be able to log into the

882
00:33:52,479 --> 00:33:58,269
system a misuse case as a user I should

883
00:33:55,599 --> 00:33:59,739
not be able to log in as an admin or

884
00:33:58,269 --> 00:34:03,729
should not be able to have access to

885
00:33:59,739 --> 00:34:05,769
admin pages if I'm not logged in I like

886
00:34:03,729 --> 00:34:10,539
to say that misuse cases really help you

887
00:34:05,769 --> 00:34:12,399
with this you ever heard that before if

888
00:34:10,539 --> 00:34:14,019
you're you're mentioning a scenario and

889
00:34:12,399 --> 00:34:15,699
they come back and say well no one would

890
00:34:14,018 --> 00:34:17,049
ever do that right and who would ever do

891
00:34:15,699 --> 00:34:18,788
that and why would they ever do that

892
00:34:17,049 --> 00:34:21,489
nobody would ever think about doing that

893
00:34:18,789 --> 00:34:22,720
well that helps you in terms of again

894
00:34:21,489 --> 00:34:24,729
developing your threat model to

895
00:34:22,719 --> 00:34:26,768
understand what it's maybe possible and

896
00:34:24,730 --> 00:34:28,149
also what's plausible I mean those are

897
00:34:26,768 --> 00:34:31,018
there's some differences between the two

898
00:34:28,149 --> 00:34:34,239
do you know that possible and plausible

899
00:34:31,018 --> 00:34:35,229
possible that on Mars I might be

900
00:34:34,239 --> 00:34:39,428
attacked by a bear

901
00:34:35,230 --> 00:34:40,990
is it possible probably not you know

902
00:34:39,429 --> 00:34:43,029
there are not very many bears as far as

903
00:34:40,989 --> 00:34:45,549
I know on Mars if I go to Mars but

904
00:34:43,029 --> 00:34:47,529
there's a possibility there is one but

905
00:34:45,549 --> 00:34:49,750
the plausibility of it is probably not

906
00:34:47,529 --> 00:34:51,369
likely and so it kind of helps you with

907
00:34:49,750 --> 00:34:53,529
that to think about you know what could

908
00:34:51,369 --> 00:34:57,759
happen and what's really likely to

909
00:34:53,529 --> 00:35:00,460
happen most well-known in threat

910
00:34:57,759 --> 00:35:04,269
modeling is this use this this mnemonic

911
00:35:00,460 --> 00:35:06,940
called stride that helps you think about

912
00:35:04,269 --> 00:35:09,879
threats essentially so spoofing

913
00:35:06,940 --> 00:35:12,460
pretending to be somebody else tampering

914
00:35:09,880 --> 00:35:14,109
is really dealing with data that's been

915
00:35:12,460 --> 00:35:16,539
modified in some way repudiation

916
00:35:14,109 --> 00:35:18,640
somebody claiming or claiming they

917
00:35:16,539 --> 00:35:20,349
haven't done something that they have or

918
00:35:18,640 --> 00:35:22,029
haven't done something information

919
00:35:20,349 --> 00:35:24,460
disclosure exposing that information

920
00:35:22,029 --> 00:35:26,650
denial of service of course affecting

921
00:35:24,460 --> 00:35:28,329
availability and an elevation of

922
00:35:26,650 --> 00:35:30,819
privilege which is the most dangerous

923
00:35:28,329 --> 00:35:32,230
one which is somebody being able to do

924
00:35:30,819 --> 00:35:34,569
things that they're not supposed to be

925
00:35:32,230 --> 00:35:36,190
able to do and really the opposite of

926
00:35:34,569 --> 00:35:37,599
that is what we want you know that's

927
00:35:36,190 --> 00:35:39,610
what we're trying to deal with and when

928
00:35:37,599 --> 00:35:41,680
we're doing straw

929
00:35:39,610 --> 00:35:43,690
method is is to try to figure out the

930
00:35:41,680 --> 00:35:45,960
opposite things that are missing which

931
00:35:43,690 --> 00:35:48,040
are for spoofing authentication

932
00:35:45,960 --> 00:35:50,890
tampering we we need to have some

933
00:35:48,040 --> 00:35:53,140
integrity data integrity repudiation non

934
00:35:50,890 --> 00:35:53,640
repudiation or auditing and logging if

935
00:35:53,140 --> 00:35:55,750
you will

936
00:35:53,640 --> 00:35:57,790
information disclosure we want some

937
00:35:55,750 --> 00:35:59,860
confidentiality in place that may not be

938
00:35:57,790 --> 00:36:02,140
there then all the service of course

939
00:35:59,860 --> 00:36:04,030
availability we want elevation of

940
00:36:02,140 --> 00:36:06,609
privileges authorization or access

941
00:36:04,030 --> 00:36:08,380
control and if you've been in security a

942
00:36:06,610 --> 00:36:10,690
while hope you recognize these things or

943
00:36:08,380 --> 00:36:13,060
the CIA right the confidentiality

944
00:36:10,690 --> 00:36:15,250
integrity and availability the two A's

945
00:36:13,060 --> 00:36:17,380
the authentication and authorization and

946
00:36:15,250 --> 00:36:19,270
then finally the non repudiation or

947
00:36:17,380 --> 00:36:21,490
somebody some people call it auditing so

948
00:36:19,270 --> 00:36:22,630
maybe three days there and so that's

949
00:36:21,490 --> 00:36:24,609
really what we're trying to help people

950
00:36:22,630 --> 00:36:26,260
understand and so when when you teach

951
00:36:24,610 --> 00:36:28,420
stride to somebody who may not know

952
00:36:26,260 --> 00:36:30,280
security very well what you're trying to

953
00:36:28,420 --> 00:36:32,710
do is help them understand the opposite

954
00:36:30,280 --> 00:36:34,090
of these things that might mean that I

955
00:36:32,710 --> 00:36:36,580
need to put these things in place to

956
00:36:34,090 --> 00:36:40,180
make sure that I've you know been able

957
00:36:36,580 --> 00:36:41,860
to deal with the threats another way is

958
00:36:40,180 --> 00:36:43,600
to use this pasta method which is

959
00:36:41,860 --> 00:36:45,460
combining stride attacks and a lot of

960
00:36:43,600 --> 00:36:48,819
risk analysis it's out there there's a

961
00:36:45,460 --> 00:36:50,650
good book on that the other thing I like

962
00:36:48,820 --> 00:36:52,390
to do when I'm doing a threat model with

963
00:36:50,650 --> 00:36:53,980
a team is just ask a lot of functional

964
00:36:52,390 --> 00:36:55,240
questions around these kinds of things

965
00:36:53,980 --> 00:36:58,060
as well especially for example

966
00:36:55,240 --> 00:37:00,160
configuration management I asked

967
00:36:58,060 --> 00:37:01,779
questions about cryptography as I said I

968
00:37:00,160 --> 00:37:03,790
always ask about passwords and

969
00:37:01,780 --> 00:37:06,190
encryption and key management and how

970
00:37:03,790 --> 00:37:08,590
are they doing those things that are

971
00:37:06,190 --> 00:37:09,880
hidden really from the outside world you

972
00:37:08,590 --> 00:37:11,980
may not know that these things are

973
00:37:09,880 --> 00:37:14,260
happening but they're they're inside the

974
00:37:11,980 --> 00:37:18,400
secure design so I asked about those

975
00:37:14,260 --> 00:37:20,020
things I asked about for example going

976
00:37:18,400 --> 00:37:22,630
back to the attacker who would be

977
00:37:20,020 --> 00:37:25,030
interested in these things what kind of

978
00:37:22,630 --> 00:37:27,220
goals do they might have assets and so

979
00:37:25,030 --> 00:37:29,800
on that are that are available different

980
00:37:27,220 --> 00:37:31,450
methods they might use and then also are

981
00:37:29,800 --> 00:37:32,980
there any attack surfaces anything that

982
00:37:31,450 --> 00:37:35,350
we missed as we're going through a

983
00:37:32,980 --> 00:37:37,240
threat model I asked about

984
00:37:35,350 --> 00:37:40,420
authentication between callers and

985
00:37:37,240 --> 00:37:42,609
services you know again authorization so

986
00:37:40,420 --> 00:37:45,369
I may ask so specifically cryptography

987
00:37:42,609 --> 00:37:47,470
and so on one of the best questions that

988
00:37:45,369 --> 00:37:48,640
I heard this yesterday I was at a couple

989
00:37:47,470 --> 00:37:51,430
days at a conference and this kept

990
00:37:48,640 --> 00:37:52,359
coming up but is there anything keeping

991
00:37:51,430 --> 00:37:55,210
you up at night

992
00:37:52,360 --> 00:37:56,170
and this person was giving a keynote and

993
00:37:55,210 --> 00:37:57,610
they kept saying these are the things

994
00:37:56,170 --> 00:37:59,080
that keep me up at night these are the

995
00:37:57,610 --> 00:38:01,390
things that keep me up at night so I

996
00:37:59,080 --> 00:38:03,940
kind of knew what what was keeping her

997
00:38:01,390 --> 00:38:05,740
up at night but you know that's an

998
00:38:03,940 --> 00:38:07,150
interesting question to ask a team you

999
00:38:05,740 --> 00:38:09,549
know is there something that you're not

1000
00:38:07,150 --> 00:38:11,260
telling us it's here something that we

1001
00:38:09,550 --> 00:38:13,480
need to know about for example a back

1002
00:38:11,260 --> 00:38:15,310
door that's in the system a test button

1003
00:38:13,480 --> 00:38:17,410
that's still there you know a debug

1004
00:38:15,310 --> 00:38:19,330
setting that you just didn't realize was

1005
00:38:17,410 --> 00:38:20,920
there I remember working with a team and

1006
00:38:19,330 --> 00:38:24,400
they told me that you know actually we

1007
00:38:20,920 --> 00:38:26,410
have this way of testing our site that

1008
00:38:24,400 --> 00:38:27,940
we keep live all the time because it's

1009
00:38:26,410 --> 00:38:30,549
really easier to have it out there in

1010
00:38:27,940 --> 00:38:32,500
production so that we can test all these

1011
00:38:30,550 --> 00:38:35,560
things about our site but oh yeah that's

1012
00:38:32,500 --> 00:38:37,750
right it's in production yeah well we

1013
00:38:35,560 --> 00:38:39,759
don't have a link to it what do you mean

1014
00:38:37,750 --> 00:38:41,860
okay but it's still there I mean does it

1015
00:38:39,760 --> 00:38:44,920
need to be there I mean really

1016
00:38:41,860 --> 00:38:48,790
so that can impact your threat model as

1017
00:38:44,920 --> 00:38:50,890
well here's an example I like to when

1018
00:38:48,790 --> 00:38:52,720
I'm talking with teams that are their

1019
00:38:50,890 --> 00:38:55,779
focus so much on micro services these

1020
00:38:52,720 --> 00:38:58,859
days is this idea of the confused deputy

1021
00:38:55,780 --> 00:39:01,630
problem everybody recognize this guy

1022
00:38:58,860 --> 00:39:05,770
okay remember how with sometimes he

1023
00:39:01,630 --> 00:39:08,110
would be somebody's in the jail cell and

1024
00:39:05,770 --> 00:39:10,000
and hey can you help me out can you give

1025
00:39:08,110 --> 00:39:11,380
me the key I need to go to the bathroom

1026
00:39:10,000 --> 00:39:13,120
or something yeah sure here you go go

1027
00:39:11,380 --> 00:39:16,060
ahead and then somehow another Barney

1028
00:39:13,120 --> 00:39:18,040
gets locked in the jail right that

1029
00:39:16,060 --> 00:39:19,330
happens quite often in the episodes well

1030
00:39:18,040 --> 00:39:21,550
the idea behind the confused deputy

1031
00:39:19,330 --> 00:39:23,470
problem is that you have a lot of

1032
00:39:21,550 --> 00:39:26,020
services that are out in the system and

1033
00:39:23,470 --> 00:39:27,580
some that are doing one thing and

1034
00:39:26,020 --> 00:39:29,259
anonymous essentially and then others

1035
00:39:27,580 --> 00:39:30,340
that are more secure they at least they

1036
00:39:29,260 --> 00:39:33,130
should be and they're doing more

1037
00:39:30,340 --> 00:39:35,800
privileged operations and the idea being

1038
00:39:33,130 --> 00:39:38,590
that if I can say a calls B call C and

1039
00:39:35,800 --> 00:39:41,410
sees the the secure operation what's to

1040
00:39:38,590 --> 00:39:43,690
prevent me from a calling C or you know

1041
00:39:41,410 --> 00:39:45,640
making B do something that it shouldn't

1042
00:39:43,690 --> 00:39:48,400
do and call D or something like that and

1043
00:39:45,640 --> 00:39:50,650
so there's some interesting things about

1044
00:39:48,400 --> 00:39:53,200
that and and we've seen this a few times

1045
00:39:50,650 --> 00:39:55,290
and examples and the way to deal with

1046
00:39:53,200 --> 00:39:57,339
that is you know through acts

1047
00:39:55,290 --> 00:39:59,259
permissions and capabilities and so

1048
00:39:57,340 --> 00:40:01,300
forth but the idea is that there's some

1049
00:39:59,260 --> 00:40:03,310
potential implied trust that's in the

1050
00:40:01,300 --> 00:40:05,410
system that we may not realize this

1051
00:40:03,310 --> 00:40:07,620
there and so it's something that comes

1052
00:40:05,410 --> 00:40:09,850
up quite often

1053
00:40:07,620 --> 00:40:13,660
talking about configuration management

1054
00:40:09,850 --> 00:40:16,180
if we look back at my web dfd that I put

1055
00:40:13,660 --> 00:40:17,980
together if you look at and think about

1056
00:40:16,180 --> 00:40:19,810
where the configuration

1057
00:40:17,980 --> 00:40:21,430
where's configuration happening for a

1058
00:40:19,810 --> 00:40:23,830
website typically it's in data files

1059
00:40:21,430 --> 00:40:27,839
config files of some sort what's

1060
00:40:23,830 --> 00:40:30,640
contained in those files typically

1061
00:40:27,840 --> 00:40:31,870
secrets passwords web services other

1062
00:40:30,640 --> 00:40:34,450
kinds of things that they're calling

1063
00:40:31,870 --> 00:40:37,720
right and so if I wanted to do a threat

1064
00:40:34,450 --> 00:40:39,490
model against that I would ask or first

1065
00:40:37,720 --> 00:40:41,140
of all you know identify you have

1066
00:40:39,490 --> 00:40:43,870
configuration files in your system and

1067
00:40:41,140 --> 00:40:46,299
then I would review okay what are some

1068
00:40:43,870 --> 00:40:48,910
security principles here be reluctant to

1069
00:40:46,300 --> 00:40:50,410
trust assume secrets not safe and with

1070
00:40:48,910 --> 00:40:52,990
that in mind and I asked some questions

1071
00:40:50,410 --> 00:40:54,310
how does the app handle those files and

1072
00:40:52,990 --> 00:40:56,919
do what do they do with those files

1073
00:40:54,310 --> 00:40:58,840
because it's still data input you know

1074
00:40:56,920 --> 00:41:00,880
we think a lot about the input that

1075
00:40:58,840 --> 00:41:02,320
comes from the outside but we don't

1076
00:41:00,880 --> 00:41:04,960
always think about the input that comes

1077
00:41:02,320 --> 00:41:07,180
from the inside you know from our files

1078
00:41:04,960 --> 00:41:10,000
and from our databases you know if

1079
00:41:07,180 --> 00:41:12,819
you've heard of reflective or stored

1080
00:41:10,000 --> 00:41:15,100
rather XSS right being able to store an

1081
00:41:12,820 --> 00:41:17,440
XSS attack in the database and then

1082
00:41:15,100 --> 00:41:20,140
simply pulling that data back into the

1083
00:41:17,440 --> 00:41:24,070
website and then and then acted on the

1084
00:41:20,140 --> 00:41:25,960
website so it's all data input so how

1085
00:41:24,070 --> 00:41:27,520
does it use those configuration files

1086
00:41:25,960 --> 00:41:29,350
and what would happen if somebody

1087
00:41:27,520 --> 00:41:31,330
changed something in those files you

1088
00:41:29,350 --> 00:41:33,100
know change to point to a different

1089
00:41:31,330 --> 00:41:34,810
database or change the password or

1090
00:41:33,100 --> 00:41:37,660
change to point to a different service

1091
00:41:34,810 --> 00:41:39,640
what would happen how do we know is

1092
00:41:37,660 --> 00:41:42,460
there some kind of implied trust usually

1093
00:41:39,640 --> 00:41:43,870
there is possible controls and

1094
00:41:42,460 --> 00:41:44,260
mitigation kind of jumping ahead a

1095
00:41:43,870 --> 00:41:45,640
little bit

1096
00:41:44,260 --> 00:41:48,250
you'd set permissions on those

1097
00:41:45,640 --> 00:41:51,520
configuration files we was changing them

1098
00:41:48,250 --> 00:41:54,040
perhaps and then validate all the data

1099
00:41:51,520 --> 00:41:56,470
that goes into those files to make sure

1100
00:41:54,040 --> 00:41:59,710
that you know it's valid and so forth

1101
00:41:56,470 --> 00:42:01,470
using tests fuzz testing and so on so

1102
00:41:59,710 --> 00:42:04,450
like I said a lot of different ways to

1103
00:42:01,470 --> 00:42:06,160
identify threats and like I said I like

1104
00:42:04,450 --> 00:42:07,660
to use these answers to questions and

1105
00:42:06,160 --> 00:42:11,379
try to you know the probe and what's

1106
00:42:07,660 --> 00:42:13,029
going on with your system once you've

1107
00:42:11,380 --> 00:42:14,890
figured out the opposite of these things

1108
00:42:13,030 --> 00:42:16,360
as I said spoofing you may say well well

1109
00:42:14,890 --> 00:42:18,310
now we need to know or we need to put in

1110
00:42:16,360 --> 00:42:19,900
some authentication and so on you have a

1111
00:42:18,310 --> 00:42:23,259
few options what

1112
00:42:19,900 --> 00:42:25,359
to do and these are pretty well known

1113
00:42:23,260 --> 00:42:27,849
the four options leave it as is you

1114
00:42:25,359 --> 00:42:30,089
found some problems leave it as is we

1115
00:42:27,849 --> 00:42:33,400
know it's broken leave it it's okay

1116
00:42:30,089 --> 00:42:34,839
remove it you know we know there's a

1117
00:42:33,400 --> 00:42:37,059
problem here we're just going to remove

1118
00:42:34,839 --> 00:42:38,950
that particular feature so that it's not

1119
00:42:37,059 --> 00:42:41,680
available yet until we fix it

1120
00:42:38,950 --> 00:42:43,450
you can remedy with a countermeasure you

1121
00:42:41,680 --> 00:42:46,180
can put something in place to deal with

1122
00:42:43,450 --> 00:42:48,250
the issue that's ideal and then finally

1123
00:42:46,180 --> 00:42:49,328
there's the warn user which I call the

1124
00:42:48,250 --> 00:42:52,720
pass the buck

1125
00:42:49,329 --> 00:42:54,339
method which is to give some kind of

1126
00:42:52,720 --> 00:42:57,609
disclaimer and say look we know it's a

1127
00:42:54,339 --> 00:43:00,069
problem use at your own risk if you go

1128
00:42:57,609 --> 00:43:02,710
into a coffee shop with a Wi-Fi

1129
00:43:00,069 --> 00:43:04,210
completely wide open there's again you

1130
00:43:02,710 --> 00:43:06,730
might see sometimes a disclaimer that

1131
00:43:04,210 --> 00:43:09,190
says by the way use at your own risk

1132
00:43:06,730 --> 00:43:10,510
anybody can sniff the the connection

1133
00:43:09,190 --> 00:43:12,130
that you're making out there in the

1134
00:43:10,510 --> 00:43:16,869
world when you're using our free Wi-Fi

1135
00:43:12,130 --> 00:43:17,920
so that's a warn user method so then you

1136
00:43:16,869 --> 00:43:19,180
want in trying to figure out you know

1137
00:43:17,920 --> 00:43:20,500
where the risk associated with the

1138
00:43:19,180 --> 00:43:22,839
vulnerabilities and threats that you

1139
00:43:20,500 --> 00:43:24,760
found and sometimes you will kind of

1140
00:43:22,839 --> 00:43:25,990
reverse you'll find the risk first of

1141
00:43:24,760 --> 00:43:27,720
the threat to then determine the

1142
00:43:25,990 --> 00:43:30,368
mitigation or maybe the other way around

1143
00:43:27,720 --> 00:43:31,990
to define or to determine risk

1144
00:43:30,369 --> 00:43:33,760
essentially you would apply some kind of

1145
00:43:31,990 --> 00:43:36,098
risk management and I said very early on

1146
00:43:33,760 --> 00:43:38,710
you want to think about how risk drives

1147
00:43:36,099 --> 00:43:41,529
a lot of your threat modeling different

1148
00:43:38,710 --> 00:43:43,569
ways to do this one is that's actually

1149
00:43:41,529 --> 00:43:46,380
becoming more and more popular as to use

1150
00:43:43,569 --> 00:43:50,319
the fair approach anybody heard of that

1151
00:43:46,380 --> 00:43:52,180
okay a few certainly more prevalent

1152
00:43:50,319 --> 00:43:54,630
nowadays in the financial industry I

1153
00:43:52,180 --> 00:43:59,078
keep seeing it there but it's a very

1154
00:43:54,630 --> 00:44:02,109
analytical way of determining risks some

1155
00:43:59,079 --> 00:44:05,859
other ways are cbss another way of

1156
00:44:02,109 --> 00:44:07,630
scoring a risk rating and then Dredd is

1157
00:44:05,859 --> 00:44:09,460
one that used to be around with

1158
00:44:07,630 --> 00:44:12,539
Microsoft but they've dropped it lately

1159
00:44:09,460 --> 00:44:15,250
where try to figure out risk that way

1160
00:44:12,539 --> 00:44:17,020
the simplest way is really just high

1161
00:44:15,250 --> 00:44:19,029
medium low and you'll see a lot of tools

1162
00:44:17,020 --> 00:44:22,210
that use that it's not very complicated

1163
00:44:19,029 --> 00:44:23,619
but it's definitely more subjective I

1164
00:44:22,210 --> 00:44:25,750
mean really all you're doing there is

1165
00:44:23,619 --> 00:44:28,180
you're trying to determine how easy is

1166
00:44:25,750 --> 00:44:31,150
it to exploit this threat and then also

1167
00:44:28,180 --> 00:44:33,580
the business impact as a result so the

1168
00:44:31,150 --> 00:44:37,360
ease of exploitation high is if a lot of

1169
00:44:33,580 --> 00:44:40,000
users can be able to do this thing and

1170
00:44:37,360 --> 00:44:42,040
lo is if they need special skills the

1171
00:44:40,000 --> 00:44:44,140
business impact of a lot of users for

1172
00:44:42,040 --> 00:44:48,190
example are impacted and your reputation

1173
00:44:44,140 --> 00:44:50,200
and so on very high and versus low that

1174
00:44:48,190 --> 00:44:52,990
not very many users and your reputation

1175
00:44:50,200 --> 00:44:55,629
and so on is they may not be impacted to

1176
00:44:52,990 --> 00:44:57,399
to a high degree you put those two

1177
00:44:55,630 --> 00:44:59,740
together and you can come up with at

1178
00:44:57,400 --> 00:45:01,930
least again subjectively somewhat but

1179
00:44:59,740 --> 00:45:04,750
you know what does we feel as the risk

1180
00:45:01,930 --> 00:45:09,190
here in in terms of our rating here's an

1181
00:45:04,750 --> 00:45:12,220
example of a CSRF attack or threat and

1182
00:45:09,190 --> 00:45:14,110
we say okay you know here's our the

1183
00:45:12,220 --> 00:45:16,029
threat here the the description of it

1184
00:45:14,110 --> 00:45:18,910
and some countermeasures some things as

1185
00:45:16,030 --> 00:45:20,740
affecting we consider to be a medium and

1186
00:45:18,910 --> 00:45:23,319
so that's again a threat model of that

1187
00:45:20,740 --> 00:45:27,339
particular situation going back to our

1188
00:45:23,320 --> 00:45:29,050
configuration management issue you might

1189
00:45:27,340 --> 00:45:30,790
think about the risk rating of this

1190
00:45:29,050 --> 00:45:34,000
thing I like to say that you know if we

1191
00:45:30,790 --> 00:45:36,160
own the box we're in control of it the

1192
00:45:34,000 --> 00:45:38,830
risk may be actually more medium or low

1193
00:45:36,160 --> 00:45:40,450
if we're not in control of that file in

1194
00:45:38,830 --> 00:45:42,730
the configuration that we're setting I

1195
00:45:40,450 --> 00:45:45,220
would say like for example on a cloud or

1196
00:45:42,730 --> 00:45:47,470
some other service that we don't own we

1197
00:45:45,220 --> 00:45:49,209
don't manage somebody else does that I

1198
00:45:47,470 --> 00:45:52,060
would say the risk rating on this

1199
00:45:49,210 --> 00:45:54,700
particular situation is higher because

1200
00:45:52,060 --> 00:45:56,590
we need to make sure that we protect the

1201
00:45:54,700 --> 00:45:58,450
data and and make sure we know who

1202
00:45:56,590 --> 00:45:58,890
changes the configuration files and so

1203
00:45:58,450 --> 00:46:01,120
on

1204
00:45:58,890 --> 00:46:03,700
and so that's a threat model right there

1205
00:46:01,120 --> 00:46:05,859
of all the things we know about the

1206
00:46:03,700 --> 00:46:07,330
system we know some principles we've

1207
00:46:05,860 --> 00:46:08,890
asked some questions we have a denim a/b

1208
00:46:07,330 --> 00:46:10,330
identify maybe some threats that could

1209
00:46:08,890 --> 00:46:12,850
happen if somebody changes the file

1210
00:46:10,330 --> 00:46:14,410
we've identified some mitigations and

1211
00:46:12,850 --> 00:46:16,420
we've also determined the risk and that

1212
00:46:14,410 --> 00:46:18,490
helps us drive what we're gonna do next

1213
00:46:16,420 --> 00:46:20,110
do we put these kind of things in place

1214
00:46:18,490 --> 00:46:22,000
or do we say it's okay we understand

1215
00:46:20,110 --> 00:46:24,490
it's a risk but we'll live with it we're

1216
00:46:22,000 --> 00:46:27,780
not gonna do anything more so that's

1217
00:46:24,490 --> 00:46:29,859
another part of our threat model here

1218
00:46:27,780 --> 00:46:32,560
finally the follow-through is

1219
00:46:29,860 --> 00:46:35,980
documenting what you found filing bugs

1220
00:46:32,560 --> 00:46:39,370
or requirements verifying they're fixed

1221
00:46:35,980 --> 00:46:41,380
and then also if we miss anything review

1222
00:46:39,370 --> 00:46:44,950
again now what are you done with threat

1223
00:46:41,380 --> 00:46:46,390
modeling never yeah you need to keep

1224
00:46:44,950 --> 00:46:47,410
going you keep doing this you keep

1225
00:46:46,390 --> 00:46:50,140
thinking

1226
00:46:47,410 --> 00:46:52,480
anytime you add something new you need

1227
00:46:50,140 --> 00:46:54,220
to review it again you need to look at

1228
00:46:52,480 --> 00:46:56,799
your threat model it changes your threat

1229
00:46:54,220 --> 00:47:01,209
model if you add a new library if you

1230
00:46:56,799 --> 00:47:03,339
add new devices if you you expand ports

1231
00:47:01,210 --> 00:47:05,140
or whatever your threat model has

1232
00:47:03,339 --> 00:47:08,589
changed and you need to update it and

1233
00:47:05,140 --> 00:47:11,049
keep it going and so what I like to say

1234
00:47:08,589 --> 00:47:12,880
is that as you do that ultimately what

1235
00:47:11,049 --> 00:47:14,470
you have is what I call this living

1236
00:47:12,880 --> 00:47:16,270
threat model it's not something an

1237
00:47:14,470 --> 00:47:17,470
exercise that you did one time and

1238
00:47:16,270 --> 00:47:20,020
you're done but it's something that you

1239
00:47:17,470 --> 00:47:22,390
should be thinking about quite often and

1240
00:47:20,020 --> 00:47:24,609
again as we said it the title of this is

1241
00:47:22,390 --> 00:47:25,990
that threat modeling mindset this is

1242
00:47:24,609 --> 00:47:27,910
something you need to be thinking about

1243
00:47:25,990 --> 00:47:30,578
just like you do on a personal basis

1244
00:47:27,910 --> 00:47:31,660
every day about your own systems you

1245
00:47:30,579 --> 00:47:34,329
need to be thinking about these things

1246
00:47:31,660 --> 00:47:36,940
and helping to integrate it within your

1247
00:47:34,329 --> 00:47:38,500
own system your own company and with a

1248
00:47:36,940 --> 00:47:40,780
lot of people not just the security

1249
00:47:38,500 --> 00:47:43,359
people I think but also developers and

1250
00:47:40,780 --> 00:47:46,299
others that should be understanding

1251
00:47:43,359 --> 00:47:48,160
about these principles finally I want to

1252
00:47:46,299 --> 00:47:51,038
leave this with you this is really an

1253
00:47:48,160 --> 00:47:52,720
interesting article I saw last year that

1254
00:47:51,039 --> 00:47:56,920
came out from John Lambert works at

1255
00:47:52,720 --> 00:47:58,868
Microsoft but in particular he wrote

1256
00:47:56,920 --> 00:48:01,559
this article pointing to the fact that

1257
00:47:58,869 --> 00:48:04,359
the security controls themselves

1258
00:48:01,559 --> 00:48:08,529
actually can create vulnerability and

1259
00:48:04,359 --> 00:48:11,500
why because it gives a clue to attackers

1260
00:48:08,529 --> 00:48:13,779
what is important to you and so what he

1261
00:48:11,500 --> 00:48:15,579
wrote in this article and I very much

1262
00:48:13,779 --> 00:48:17,529
encourage you to go read it it's it's

1263
00:48:15,579 --> 00:48:18,460
just pretty eye-opening especially

1264
00:48:17,529 --> 00:48:20,410
having thought about some of these

1265
00:48:18,460 --> 00:48:23,140
things because a lot of times we think

1266
00:48:20,410 --> 00:48:25,868
about as security people we think about

1267
00:48:23,140 --> 00:48:27,129
lists right we got a checklist and we

1268
00:48:25,869 --> 00:48:29,380
add this control and we have that

1269
00:48:27,130 --> 00:48:31,960
control attacker doesn't think that way

1270
00:48:29,380 --> 00:48:33,309
an attacker thinks and graphs they're

1271
00:48:31,960 --> 00:48:35,230
trying to figure out from point A to

1272
00:48:33,309 --> 00:48:36,819
point B to Point C to figure out what's

1273
00:48:35,230 --> 00:48:38,829
your system they don't know everything

1274
00:48:36,819 --> 00:48:40,960
in your system so they've got to graph

1275
00:48:38,829 --> 00:48:42,520
it out and figure it out right well how

1276
00:48:40,960 --> 00:48:46,210
are they going to do that well one way

1277
00:48:42,520 --> 00:48:48,220
is to look at your controls to figure

1278
00:48:46,210 --> 00:48:50,710
out what is important to you that you

1279
00:48:48,220 --> 00:48:53,319
now have a control protecting it because

1280
00:48:50,710 --> 00:48:55,480
it's important to you and so what he was

1281
00:48:53,319 --> 00:48:58,869
saying in this article is that you know

1282
00:48:55,480 --> 00:49:00,520
the selection of controls just saying I

1283
00:48:58,869 --> 00:49:01,240
have a control is not enough now I need

1284
00:49:00,520 --> 00:49:02,890
to understand

1285
00:49:01,240 --> 00:49:05,109
what happens if somebody circumvents

1286
00:49:02,890 --> 00:49:07,660
that control what's next where do they

1287
00:49:05,110 --> 00:49:09,730
go next are you slowing them down are

1288
00:49:07,660 --> 00:49:11,859
you monitoring them are you doing other

1289
00:49:09,730 --> 00:49:13,990
things to think about how the threat

1290
00:49:11,860 --> 00:49:15,820
model changes once that control has been

1291
00:49:13,990 --> 00:49:19,930
circumvented where do they go next

1292
00:49:15,820 --> 00:49:22,480
what's next in the graph and so again

1293
00:49:19,930 --> 00:49:25,629
just a interesting article interesting

1294
00:49:22,480 --> 00:49:27,250
thoughts about this idea of recursive

1295
00:49:25,630 --> 00:49:29,710
threat modeling not just doing this once

1296
00:49:27,250 --> 00:49:32,320
but thinking it various levels and

1297
00:49:29,710 --> 00:49:33,910
layers in our system about how does my

1298
00:49:32,320 --> 00:49:35,980
threat model change now that that

1299
00:49:33,910 --> 00:49:39,310
particular control has been circumvented

1300
00:49:35,980 --> 00:49:41,830
where do they go next what could happen

1301
00:49:39,310 --> 00:49:43,330
next what could go wrong and as he said

1302
00:49:41,830 --> 00:49:45,759
you know controls come with risks and

1303
00:49:43,330 --> 00:49:47,049
must be treated accordingly so again I

1304
00:49:45,760 --> 00:49:48,340
encourage you to take a look at that

1305
00:49:47,050 --> 00:49:49,570
article and other things that John

1306
00:49:48,340 --> 00:49:51,580
Lambert has been writing about just

1307
00:49:49,570 --> 00:49:53,220
really fascinating stuff about some

1308
00:49:51,580 --> 00:49:55,600
things that he's thinking about and

1309
00:49:53,220 --> 00:49:59,799
analyzing about what is going on with

1310
00:49:55,600 --> 00:50:01,390
attackers today so to wrap up you know

1311
00:49:59,800 --> 00:50:03,700
your challenge pursue this threat

1312
00:50:01,390 --> 00:50:05,680
modeling mindset don't just let it be

1313
00:50:03,700 --> 00:50:07,779
something you heard about but actually

1314
00:50:05,680 --> 00:50:10,419
something you continue to do secure

1315
00:50:07,780 --> 00:50:12,970
design before new features also let it

1316
00:50:10,420 --> 00:50:16,030
drive your testing I find that

1317
00:50:12,970 --> 00:50:18,310
especially for testers for red teams for

1318
00:50:16,030 --> 00:50:21,369
others threat modeling is absolutely a

1319
00:50:18,310 --> 00:50:23,560
useful tool to think about the system

1320
00:50:21,369 --> 00:50:25,180
and how can we now that we know a better

1321
00:50:23,560 --> 00:50:27,520
threat model how can we then test

1322
00:50:25,180 --> 00:50:29,049
accordingly to find out is this really

1323
00:50:27,520 --> 00:50:30,310
true or do we have these particular

1324
00:50:29,050 --> 00:50:32,109
vulnerabilities do we have these

1325
00:50:30,310 --> 00:50:34,869
particular issues in our system that we

1326
00:50:32,109 --> 00:50:36,340
may never even thought about and then

1327
00:50:34,869 --> 00:50:37,630
also threat modeling is going to help

1328
00:50:36,340 --> 00:50:39,670
you with understanding the bigger

1329
00:50:37,630 --> 00:50:41,530
picture and I it's why I like to to

1330
00:50:39,670 --> 00:50:44,440
teach it and help others know about it

1331
00:50:41,530 --> 00:50:46,090
is because I think there's some value in

1332
00:50:44,440 --> 00:50:48,000
understanding the bigger picture and how

1333
00:50:46,090 --> 00:50:51,609
things fit together

1334
00:50:48,000 --> 00:50:55,119
lots of resources out there tools other

1335
00:50:51,609 --> 00:50:56,740
tools and that's my contact info I have

1336
00:50:55,119 --> 00:50:58,210
made slides available already they're

1337
00:50:56,740 --> 00:51:01,629
available out there so if you're

1338
00:50:58,210 --> 00:51:03,820
interested go ahead and pick those up my

1339
00:51:01,630 --> 00:51:05,470
contact info I'm on Twitter I'm also on

1340
00:51:03,820 --> 00:51:06,790
LinkedIn if you want to you know connect

1341
00:51:05,470 --> 00:51:08,649
with me on LinkedIn just let me know

1342
00:51:06,790 --> 00:51:12,279
that you you know saw the presentation

1343
00:51:08,650 --> 00:51:14,710
at Abby sides and you know be happy to

1344
00:51:12,280 --> 00:51:25,540
connect any questions yeah

1345
00:51:14,710 --> 00:51:27,580
oh yeah absolutely absolutely sure well

1346
00:51:25,540 --> 00:51:28,930
I mean ideally you know to start slow

1347
00:51:27,580 --> 00:51:30,580
you want to do you want to do an easy

1348
00:51:28,930 --> 00:51:33,339
thing first you don't want to overwhelm

1349
00:51:30,580 --> 00:51:35,799
but as your threat model matures as you

1350
00:51:33,339 --> 00:51:37,690
get more information what I find is that

1351
00:51:35,800 --> 00:51:40,480
kind of information can come in and help

1352
00:51:37,690 --> 00:51:42,580
refine your threat model it can

1353
00:51:40,480 --> 00:51:44,170
certainly help refine the risk you know

1354
00:51:42,580 --> 00:51:45,819
how do I determine risk well I don't

1355
00:51:44,170 --> 00:51:47,200
know what could happen here so how do I

1356
00:51:45,820 --> 00:51:49,300
determine with that you know I don't

1357
00:51:47,200 --> 00:51:51,939
know but your your information like that

1358
00:51:49,300 --> 00:51:53,170
coming in from those teams and say you

1359
00:51:51,940 --> 00:51:55,270
know this is what we are thinking this

1360
00:51:53,170 --> 00:51:57,430
is what we're we know is happening or it

1361
00:51:55,270 --> 00:51:59,500
could happen I think can help refine

1362
00:51:57,430 --> 00:52:01,540
your threat model another good thing I

1363
00:51:59,500 --> 00:52:03,250
would mention is there are some work or

1364
00:52:01,540 --> 00:52:06,430
is some work rather being done right now

1365
00:52:03,250 --> 00:52:09,609
on some tools that allow you to take

1366
00:52:06,430 --> 00:52:11,140
threat intelligence and plug it into

1367
00:52:09,609 --> 00:52:13,060
your threat model so you can build a

1368
00:52:11,140 --> 00:52:14,529
threat model and then allow some of that

1369
00:52:13,060 --> 00:52:16,599
threat intelligence to come back and

1370
00:52:14,530 --> 00:52:19,000
validate what threats we identified to

1371
00:52:16,599 --> 00:52:20,410
say are they really true or not and so

1372
00:52:19,000 --> 00:52:22,420
that's a really nice way of refining

1373
00:52:20,410 --> 00:52:23,859
that kind of a completing the circle so

1374
00:52:22,420 --> 00:52:25,320
that's another thing I've seen as well

1375
00:52:23,859 --> 00:52:30,190
yes

1376
00:52:25,320 --> 00:52:33,760
how does work come back and yeah sure

1377
00:52:30,190 --> 00:52:35,470
there's a if you look up I'll tell you

1378
00:52:33,760 --> 00:52:38,050
where it first came out at least I heard

1379
00:52:35,470 --> 00:52:40,240
about it was dev set con in Boston Kevin

1380
00:52:38,050 --> 00:52:43,540
Green look up Kevin Green look up his

1381
00:52:40,240 --> 00:52:45,279
particular keynote but he pointed to

1382
00:52:43,540 --> 00:52:47,859
some tools that he's working on but

1383
00:52:45,280 --> 00:52:49,630
essentially as I understand it they go

1384
00:52:47,859 --> 00:52:51,160
out and look at your system and try to

1385
00:52:49,630 --> 00:52:53,890
do at least a mapping of what you have

1386
00:52:51,160 --> 00:52:55,629
and then you can refine it and then you

1387
00:52:53,890 --> 00:52:56,830
plug in to you know any of the threat

1388
00:52:55,630 --> 00:52:58,960
intelligence tools that are out there

1389
00:52:56,830 --> 00:53:02,250
and get some data and then they try to

1390
00:52:58,960 --> 00:53:05,349
map what they find oK you've identified

1391
00:53:02,250 --> 00:53:07,240
this firewall or something and we've

1392
00:53:05,349 --> 00:53:08,680
identified there's a lot of things that

1393
00:53:07,240 --> 00:53:10,118
are coming against that firewall we've

1394
00:53:08,680 --> 00:53:12,220
identified some things that are real

1395
00:53:10,119 --> 00:53:14,650
threats and others that are just you

1396
00:53:12,220 --> 00:53:16,240
know negatives or whatever and then try

1397
00:53:14,650 --> 00:53:19,450
to do that mapping now it's a work in

1398
00:53:16,240 --> 00:53:21,368
progress you know I don't know all the

1399
00:53:19,450 --> 00:53:22,930
details but that's what I understand for

1400
00:53:21,369 --> 00:53:25,359
what he described how they're trying to

1401
00:53:22,930 --> 00:53:26,890
to put it together and it should be

1402
00:53:25,359 --> 00:53:27,819
interesting to see as they move along

1403
00:53:26,890 --> 00:53:35,640
and that

1404
00:53:27,820 --> 00:53:35,640
comes out yes the question yep

1405
00:53:36,060 --> 00:53:49,540
sure right yeah mine doesn't include

1406
00:53:47,260 --> 00:53:51,400
that but I have done that with teams in

1407
00:53:49,540 --> 00:53:53,140
terms of thinking about deployment and

1408
00:53:51,400 --> 00:53:55,300
what does that mean so I just draw a

1409
00:53:53,140 --> 00:53:58,270
different kind of model or a different

1410
00:53:55,300 --> 00:54:00,760
type of diagram I'll point to you that

1411
00:53:58,270 --> 00:54:03,880
there is a I can't remember the NIST

1412
00:54:00,760 --> 00:54:05,650
number but there's a new NIST document

1413
00:54:03,880 --> 00:54:08,020
out there on security of containers and

1414
00:54:05,650 --> 00:54:10,840
they actually use what's called a data

1415
00:54:08,020 --> 00:54:13,120
centric threat modeling process and then

1416
00:54:10,840 --> 00:54:14,860
there's also another NIST a document

1417
00:54:13,120 --> 00:54:16,390
that covers that as well and it's really

1418
00:54:14,860 --> 00:54:18,730
interesting so they considered that

1419
00:54:16,390 --> 00:54:21,190
containers are essentially data it's

1420
00:54:18,730 --> 00:54:23,830
holding data it's holding assets and so

1421
00:54:21,190 --> 00:54:26,320
I would I would follow some of that

1422
00:54:23,830 --> 00:54:28,920
methodology in terms of maybe looking at

1423
00:54:26,320 --> 00:54:32,380
assets looking at data is handled and

1424
00:54:28,920 --> 00:54:34,780
and and go from there so that may be

1425
00:54:32,380 --> 00:54:36,280
helpful to see how you could actually do

1426
00:54:34,780 --> 00:54:41,490
a threat model against containers and

1427
00:54:36,280 --> 00:54:41,490
deployment and so on yes to mess okay

1428
00:54:48,670 --> 00:54:52,359
there's some differences I mean like for

1429
00:54:50,980 --> 00:54:53,859
example the fair approach

1430
00:54:52,359 --> 00:54:56,348
some people do threat modeling through

1431
00:54:53,859 --> 00:54:58,480
using fair basically because in that

1432
00:54:56,349 --> 00:55:01,000
case in their situation a threat is

1433
00:54:58,480 --> 00:55:03,809
considered to be anything I may have

1434
00:55:01,000 --> 00:55:07,029
value that I can lose those saw like a

1435
00:55:03,809 --> 00:55:08,799
numerical value associated with it so in

1436
00:55:07,029 --> 00:55:11,619
that case for example if I determine

1437
00:55:08,799 --> 00:55:13,990
that I have a $10,000 threat but it's a

1438
00:55:11,619 --> 00:55:15,279
hundred thousand dollars to fix it well

1439
00:55:13,990 --> 00:55:17,799
then I may not do it you know so

1440
00:55:15,279 --> 00:55:20,200
everything has a dollar value so as I

1441
00:55:17,799 --> 00:55:22,029
see it I think threat modeling and and

1442
00:55:20,200 --> 00:55:24,549
risk management can complement each

1443
00:55:22,029 --> 00:55:27,279
other but risk management usually is not

1444
00:55:24,549 --> 00:55:30,279
focused on applications not focus focus

1445
00:55:27,279 --> 00:55:31,809
on more you know if I do something what

1446
00:55:30,279 --> 00:55:35,019
happens as a result whereas threat

1447
00:55:31,809 --> 00:55:37,420
modeling is more the system but you need

1448
00:55:35,019 --> 00:55:41,609
to I think you need the two in order to

1449
00:55:37,420 --> 00:55:41,609
help inform each other yes

1450
00:55:48,860 --> 00:55:58,960
quite a bit I mean how is it or how

1451
00:55:51,320 --> 00:56:01,910
could it be or oh absolutely yeah

1452
00:55:58,960 --> 00:56:03,110
absolutely and I do that all often I've

1453
00:56:01,910 --> 00:56:05,149
worked in health care I worked in

1454
00:56:03,110 --> 00:56:07,880
finance and I've worked with these

1455
00:56:05,150 --> 00:56:09,950
different companies and teams to look

1456
00:56:07,880 --> 00:56:13,700
for the things that make sense for their

1457
00:56:09,950 --> 00:56:15,109
particular organization and for example

1458
00:56:13,700 --> 00:56:16,810
I've used the microsoft threat modeling

1459
00:56:15,110 --> 00:56:19,130
tool which you can customize for

1460
00:56:16,810 --> 00:56:21,020
stencils that make sense in the finance

1461
00:56:19,130 --> 00:56:22,580
that makes sense in the healthcare and

1462
00:56:21,020 --> 00:56:23,900
use that and the same thing with if

1463
00:56:22,580 --> 00:56:26,330
you're just drawing out things there are

1464
00:56:23,900 --> 00:56:28,240
certain things that make more sense in

1465
00:56:26,330 --> 00:56:30,440
that industry and that helps everybody

1466
00:56:28,240 --> 00:56:33,319
get a hold of it too if that makes sense

1467
00:56:30,440 --> 00:56:34,670
so absolutely I think that's it

1468
00:56:33,320 --> 00:56:36,680
we're gonna have lunch here in a moment

1469
00:56:34,670 --> 00:56:38,630
so I'll be around for a little bit I'll

1470
00:56:36,680 --> 00:56:40,310
be here after lunch for a little while

1471
00:56:38,630 --> 00:56:43,130
but then I need to head out but if you

1472
00:56:40,310 --> 00:56:44,580
have any questions feel free come I'm

1473
00:56:43,130 --> 00:56:47,230
farming thank you

1474
00:56:44,580 --> 00:56:47,230
[Applause]

