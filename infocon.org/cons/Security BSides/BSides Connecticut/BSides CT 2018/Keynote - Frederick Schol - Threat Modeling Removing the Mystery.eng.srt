1
00:00:00,000 --> 00:00:03,560
and let's get started I'm gonna

2
00:00:01,380 --> 00:00:05,819
introduce our keynote speaker dr.

3
00:00:03,560 --> 00:00:08,130
Frederick Scholl here

4
00:00:05,819 --> 00:00:09,870
Frederick shoal is a program director

5
00:00:08,130 --> 00:00:13,049
and associate professor of Quinnipiac

6
00:00:09,870 --> 00:00:15,719
snoo master's of cybersecurity program

7
00:00:13,049 --> 00:00:17,490
and prior to this position he started

8
00:00:15,719 --> 00:00:18,779
the cybersecurity program at Lipscomb

9
00:00:17,490 --> 00:00:21,538
University in Nashville

10
00:00:18,779 --> 00:00:23,519
he taught information security at

11
00:00:21,539 --> 00:00:25,590
Vanderbilt University and managed

12
00:00:23,519 --> 00:00:27,750
enterprise security for Nissan Americas

13
00:00:25,590 --> 00:00:29,939
he has also consulted on information

14
00:00:27,750 --> 00:00:33,390
security since 1991 and he is a senior

15
00:00:29,939 --> 00:00:34,890
member of I used to say and ie so put

16
00:00:33,390 --> 00:00:45,360
your hands together and welcome dr.

17
00:00:34,890 --> 00:00:48,780
Frederick show thank you can you guys

18
00:00:45,360 --> 00:00:50,789
hear me okay if anybody wants to move up

19
00:00:48,780 --> 00:00:54,059
I won't be I think it might be a good

20
00:00:50,789 --> 00:00:56,370
idea I made the slides big but not so

21
00:00:54,059 --> 00:00:57,780
big for the back of the room but aren't

22
00:00:56,370 --> 00:01:00,269
these things cool these are the best

23
00:00:57,780 --> 00:01:03,480
badges I've ever seen at any Security

24
00:01:00,270 --> 00:01:05,010
Conference right you all agree how many

25
00:01:03,480 --> 00:01:07,500
people are new here just out of

26
00:01:05,010 --> 00:01:10,830
curiosity - besides CT how many new

27
00:01:07,500 --> 00:01:13,500
attendees Wow quite a few right holy cow

28
00:01:10,830 --> 00:01:15,270
plus I saw it was sold out I'm so happy

29
00:01:13,500 --> 00:01:16,770
you guys invited me to be a keynote

30
00:01:15,270 --> 00:01:22,320
speaker it's almost impossible to get

31
00:01:16,770 --> 00:01:24,179
into any of these besides so so my my

32
00:01:22,320 --> 00:01:27,630
talk is gonna be about threat modeling

33
00:01:24,180 --> 00:01:29,400
but then I remembered this is supposed

34
00:01:27,630 --> 00:01:31,380
to be a keynote speech this is only my

35
00:01:29,400 --> 00:01:32,909
second keynote speech so I had to try it

36
00:01:31,380 --> 00:01:36,298
you know figure out what should I do for

37
00:01:32,909 --> 00:01:38,250
a keynote speech so I I texted Jack

38
00:01:36,299 --> 00:01:40,860
Daniel right you all know him he kind of

39
00:01:38,250 --> 00:01:42,659
started besides and he said well don't

40
00:01:40,860 --> 00:01:43,500
make it too technical so I said alright

41
00:01:42,659 --> 00:01:47,310
that's a good idea

42
00:01:43,500 --> 00:01:49,020
then I texted wind swart ow I'm actually

43
00:01:47,310 --> 00:01:51,360
based in Nashville now and he's in

44
00:01:49,020 --> 00:01:53,429
Nashville and he gives like keynote

45
00:01:51,360 --> 00:01:57,539
speeches every week and he said well try

46
00:01:53,430 --> 00:02:01,560
to be a little controversial then how

47
00:01:57,540 --> 00:02:03,090
many people went to der beek on one way

48
00:02:01,560 --> 00:02:05,549
in the back anyway there was the keynote

49
00:02:03,090 --> 00:02:08,910
speaker there gave the presentation in

50
00:02:05,549 --> 00:02:11,099
his underwear so I'm not gonna do that I

51
00:02:08,910 --> 00:02:13,920
can't I can't go that far I'm in

52
00:02:11,099 --> 00:02:18,480
academia I have to be a straight forward

53
00:02:13,920 --> 00:02:19,980
so but I am gonna try to think it slides

54
00:02:18,480 --> 00:02:22,140
to work I am going to talk about threat

55
00:02:19,980 --> 00:02:25,530
modeling which is some work that I've

56
00:02:22,140 --> 00:02:27,208
done for two agencies when I was doing

57
00:02:25,530 --> 00:02:29,310
consulting for Center for Medicare and

58
00:02:27,209 --> 00:02:31,830
Medicaid and also Vanderbilt University

59
00:02:29,310 --> 00:02:34,080
now I'm in academia but I have to have a

60
00:02:31,830 --> 00:02:35,640
word from my sponsor and actually I'm

61
00:02:34,080 --> 00:02:37,890
pretty excited about that so in

62
00:02:35,640 --> 00:02:39,630
September I started a new position I'm

63
00:02:37,890 --> 00:02:42,540
actually moving from Nashville to

64
00:02:39,630 --> 00:02:44,370
Connecticut so if you know anything bad

65
00:02:42,540 --> 00:02:46,100
about Connecticut don't tell me okay I'm

66
00:02:44,370 --> 00:02:48,360
already here it's too late I know about

67
00:02:46,100 --> 00:02:49,380
i-95 and I know about the Merritt

68
00:02:48,360 --> 00:02:53,250
Parkway I don't want to hear about

69
00:02:49,380 --> 00:02:55,650
anything else so so we are starting a

70
00:02:53,250 --> 00:02:57,510
new online cybersecurity master's degree

71
00:02:55,650 --> 00:02:59,310
program it started in September I'm

72
00:02:57,510 --> 00:03:00,600
excited about it for some reasons I'm

73
00:02:59,310 --> 00:03:06,200
not gonna spend a lot of time on this

74
00:03:00,600 --> 00:03:09,480
but we are we are focusing on NSA nice

75
00:03:06,200 --> 00:03:10,709
cyber defender compliance but that's not

76
00:03:09,480 --> 00:03:14,488
all we're doing I mean that's kind of

77
00:03:10,709 --> 00:03:17,400
the minimum I'm really focusing on cloud

78
00:03:14,489 --> 00:03:18,989
security I'm I just see so many things

79
00:03:17,400 --> 00:03:23,640
going into the cloud so we've got to get

80
00:03:18,989 --> 00:03:25,860
people practicing security sort of as

81
00:03:23,640 --> 00:03:27,208
well in the cloud as they do on Prem and

82
00:03:25,860 --> 00:03:28,440
then the same thing with software

83
00:03:27,209 --> 00:03:30,209
security I have an electrical

84
00:03:28,440 --> 00:03:31,709
engineering background unfortunately so

85
00:03:30,209 --> 00:03:34,049
I don't have a really good software

86
00:03:31,709 --> 00:03:35,670
background but I have been really trying

87
00:03:34,049 --> 00:03:38,040
to learn this stuff and I see so much

88
00:03:35,670 --> 00:03:40,140
pretty much everything in security is

89
00:03:38,040 --> 00:03:44,250
going into software so I'm emphasizing

90
00:03:40,140 --> 00:03:46,200
that it's fully online and we have

91
00:03:44,250 --> 00:03:48,209
enrollment in fall spring and summer so

92
00:03:46,200 --> 00:03:50,670
if you're interested in a master's

93
00:03:48,209 --> 00:03:53,160
degree obviously reach out to me you

94
00:03:50,670 --> 00:03:56,910
know we have our next classes starting

95
00:03:53,160 --> 00:03:58,769
in January on the other hand if you're

96
00:03:56,910 --> 00:04:00,870
interested in teaching one of these

97
00:03:58,769 --> 00:04:03,239
courses reach out to me to our courses

98
00:04:00,870 --> 00:04:05,040
our one credit hour courses so we

99
00:04:03,239 --> 00:04:07,079
purposely divided it up into really

100
00:04:05,040 --> 00:04:09,179
small bite-size chunks so we can get

101
00:04:07,079 --> 00:04:12,019
outside industry experts to teach a

102
00:04:09,180 --> 00:04:16,350
specific area that they know well and

103
00:04:12,019 --> 00:04:18,450
also if you if you're from the vendor

104
00:04:16,350 --> 00:04:20,340
side or even user side and you want to

105
00:04:18,450 --> 00:04:23,969
do a guest lecture I can easily bring

106
00:04:20,339 --> 00:04:25,679
you in as a guest lecturer using zoom

107
00:04:23,970 --> 00:04:27,000
and then the last thing is if you're a

108
00:04:25,680 --> 00:04:29,040
vendor

109
00:04:27,000 --> 00:04:31,380
and you have products you want to sell

110
00:04:29,040 --> 00:04:33,240
I'm happy to consider those two you know

111
00:04:31,380 --> 00:04:35,909
we can incorporate them into our class

112
00:04:33,240 --> 00:04:41,280
as long as they're free I'm happy to use

113
00:04:35,910 --> 00:04:43,590
them so so the agenda for today I wanted

114
00:04:41,280 --> 00:04:46,619
to throw in a little about where do I

115
00:04:43,590 --> 00:04:48,330
what are the big picture topics that I

116
00:04:46,620 --> 00:04:49,800
see insecurity and then relate that to

117
00:04:48,330 --> 00:04:52,289
threat modeling tool so I'm going to

118
00:04:49,800 --> 00:04:53,880
spend a few minutes on that then talk

119
00:04:52,290 --> 00:04:57,540
about what is threat modeling it's

120
00:04:53,880 --> 00:05:00,060
something that I see sort of coming up

121
00:04:57,540 --> 00:05:03,510
in the world or people are becoming more

122
00:05:00,060 --> 00:05:05,460
aware of it then I heard this good talk

123
00:05:03,510 --> 00:05:08,580
by wind swart ow my mentioned he said

124
00:05:05,460 --> 00:05:10,229
he's had this awareness training company

125
00:05:08,580 --> 00:05:11,940
in Nashville for many years and then so

126
00:05:10,230 --> 00:05:13,350
he gave a good talk on how to fail at

127
00:05:11,940 --> 00:05:17,130
awareness training so I'm kind of

128
00:05:13,350 --> 00:05:18,480
copying his idea and then I will go back

129
00:05:17,130 --> 00:05:21,000
and talk a little bit about how to

130
00:05:18,480 --> 00:05:23,100
succeed at threat modeling I want this

131
00:05:21,000 --> 00:05:24,690
about eight different tools that you can

132
00:05:23,100 --> 00:05:27,419
use you don't really need any tool you

133
00:05:24,690 --> 00:05:30,090
can use a spreadsheet but I want to talk

134
00:05:27,419 --> 00:05:32,219
about some of the tools that are out

135
00:05:30,090 --> 00:05:34,770
there and then one of the big challenges

136
00:05:32,220 --> 00:05:37,650
where do you get good baseline threat

137
00:05:34,770 --> 00:05:39,210
libraries and then I want to talk about

138
00:05:37,650 --> 00:05:42,599
some of the use cases where I've used

139
00:05:39,210 --> 00:05:44,580
threat modeling as I mentioned that CMS

140
00:05:42,600 --> 00:05:46,380
in Baltimore and then Vanderbilt medical

141
00:05:44,580 --> 00:05:52,830
in Nashville and then some of the

142
00:05:46,380 --> 00:05:54,830
opportunities in the future so this is

143
00:05:52,830 --> 00:06:00,780
the one continent that I see in our

144
00:05:54,830 --> 00:06:02,760
industry right now everything seems to

145
00:06:00,780 --> 00:06:15,419
be changing I what what do you guys

146
00:06:02,760 --> 00:06:18,479
think what what is what I have to turn

147
00:06:15,419 --> 00:06:21,780
the mic I have to stand in front of the

148
00:06:18,479 --> 00:06:24,900
mic okay so repeat the question which is

149
00:06:21,780 --> 00:06:27,840
what what is this group seeing in terms

150
00:06:24,900 --> 00:06:30,090
of changes in the field or changes in

151
00:06:27,840 --> 00:06:34,669
your job and security I specifically in

152
00:06:30,090 --> 00:06:34,669
the last like 12 to 24 months anything

153
00:06:35,060 --> 00:06:46,080
more mobile device use or okay

154
00:06:40,139 --> 00:06:53,830
what's that crypto jackin ya pardon a

155
00:06:46,080 --> 00:06:55,680
PT's okay I haven't seen that one okay

156
00:06:53,830 --> 00:06:58,590
that must be pretty new okay

157
00:06:55,680 --> 00:07:07,090
ransomware is a cloud service all right

158
00:06:58,590 --> 00:07:10,239
what else in the back exactly mass yeah

159
00:07:07,090 --> 00:07:11,560
like lemmings yeah mass mass rush to the

160
00:07:10,240 --> 00:07:17,169
cloud that's hard to pronounce yeah

161
00:07:11,560 --> 00:07:19,979
anything else has got to be more exactly

162
00:07:17,169 --> 00:07:22,889
privacy standards yep that's another one

163
00:07:19,979 --> 00:07:30,310
yes sir

164
00:07:22,889 --> 00:07:31,840
okay how about IOT exploits right

165
00:07:30,310 --> 00:07:35,319
they're coming how about in terms of

166
00:07:31,840 --> 00:07:39,940
your jobs or positions or roles our

167
00:07:35,319 --> 00:07:41,740
company's more open to security

168
00:07:39,940 --> 00:07:49,349
initiatives or spending more money or

169
00:07:41,740 --> 00:07:49,349
less open or about the same same okay

170
00:07:56,250 --> 00:08:06,190
yes sir they want to spend more on

171
00:08:04,539 --> 00:08:08,289
products and professionals yeah what

172
00:08:06,190 --> 00:08:10,389
could we do about that that's a problem

173
00:08:08,289 --> 00:08:12,900
we're perfect we're not products here

174
00:08:10,389 --> 00:08:12,900
right so

175
00:08:18,400 --> 00:08:23,739
so I think these are all good points

176
00:08:20,380 --> 00:08:27,729
this is somehow I see the field is like

177
00:08:23,740 --> 00:08:30,669
in the last 24 months it's partly

178
00:08:27,729 --> 00:08:32,860
because of the cloud or other newer

179
00:08:30,669 --> 00:08:35,559
kinds of things that we have to do right

180
00:08:32,860 --> 00:08:37,409
one gentleman mentioned privacy fake

181
00:08:35,559 --> 00:08:40,059
news is another one

182
00:08:37,409 --> 00:08:43,620
IOT so we're being given new things that

183
00:08:40,059 --> 00:08:46,569
we have to do and so I've been tracking

184
00:08:43,620 --> 00:08:48,160
this I should have tracked more of these

185
00:08:46,570 --> 00:08:51,510
things then I could be in the recruiting

186
00:08:48,160 --> 00:08:54,339
business but I tracked one job trend

187
00:08:51,510 --> 00:08:57,130
since 2012 so I started teaching

188
00:08:54,339 --> 00:08:59,380
security in 2012 and I always like to

189
00:08:57,130 --> 00:09:01,029
look at what do people need to know when

190
00:08:59,380 --> 00:09:03,960
they get out of the program right so I

191
00:09:01,029 --> 00:09:06,730
started looking at this and I saw I

192
00:09:03,960 --> 00:09:08,350
can't move here cloud cloud jobs were

193
00:09:06,730 --> 00:09:10,060
going up a little bit right didn't

194
00:09:08,350 --> 00:09:11,589
nothing too exciting but I did include

195
00:09:10,060 --> 00:09:16,150
cloud in some of the courses I was

196
00:09:11,589 --> 00:09:19,930
teaching 2012 then at 2013 a small

197
00:09:16,150 --> 00:09:27,819
increase didn't go up too much then 2014

198
00:09:19,930 --> 00:09:29,969
wow it really started to go up wave is

199
00:09:27,820 --> 00:09:32,080
kind of stopping right it's sort of

200
00:09:29,970 --> 00:09:35,490
leveling off there and then look what

201
00:09:32,080 --> 00:09:38,260
happened in 17 18 19

202
00:09:35,490 --> 00:09:42,580
we're not up to 19 yet right was up to

203
00:09:38,260 --> 00:09:45,430
18 anyway I just did that last data

204
00:09:42,580 --> 00:09:48,400
point yesterday 114,000 cloud jobs now

205
00:09:45,430 --> 00:09:50,260
this isn't a scientific survey I am an

206
00:09:48,400 --> 00:09:53,140
electrical engineer but this is I didn't

207
00:09:50,260 --> 00:09:56,740
use data analytics because this includes

208
00:09:53,140 --> 00:09:58,000
jobs in st. Cloud Minnesota and Kate you

209
00:09:56,740 --> 00:09:59,740
know if they're I don't think they're

210
00:09:58,000 --> 00:10:01,779
growing that fast though right so I

211
00:09:59,740 --> 00:10:06,160
think it's you know I'll stand by these

212
00:10:01,779 --> 00:10:09,910
numbers so this is kind of how many

213
00:10:06,160 --> 00:10:14,500
people are working in the cloud now in

214
00:10:09,910 --> 00:10:15,730
their in their current job well not that

215
00:10:14,500 --> 00:10:17,740
many so there's still a lot there's

216
00:10:15,730 --> 00:10:19,810
still a lot of room for growth right so

217
00:10:17,740 --> 00:10:21,400
this curves gonna keep going up that's

218
00:10:19,810 --> 00:10:26,890
what this quick poll shows me Wow

219
00:10:21,400 --> 00:10:28,360
exciting okay but I think this is

220
00:10:26,890 --> 00:10:31,120
changing everything because so many of

221
00:10:28,360 --> 00:10:31,990
the tools are in the cloud you need you

222
00:10:31,120 --> 00:10:34,510
need to set up

223
00:10:31,990 --> 00:10:38,020
networks at the same time you hear them

224
00:10:34,510 --> 00:10:40,720
as well as securing your on-prem data's

225
00:10:38,020 --> 00:10:42,699
your traditional network so this is a

226
00:10:40,720 --> 00:10:44,230
huge driver and then here's another one

227
00:10:42,700 --> 00:10:46,150
I don't know has anybody read this book

228
00:10:44,230 --> 00:10:53,020
by Mark Schwartz it came out last year

229
00:10:46,150 --> 00:10:55,689
seat at the table nobody so it's this I

230
00:10:53,020 --> 00:10:58,510
I was in this area lived in this area

231
00:10:55,690 --> 00:11:00,970
for about 25 years moved to Tennessee

232
00:10:58,510 --> 00:11:03,160
for 12 years sent two kids to college

233
00:11:00,970 --> 00:11:05,590
they're still there thank goodness and

234
00:11:03,160 --> 00:11:10,180
so now we're moving back but I was a

235
00:11:05,590 --> 00:11:11,620
member of the Fairfield Westchester sim

236
00:11:10,180 --> 00:11:13,599
chapter Society for information

237
00:11:11,620 --> 00:11:15,640
management and the reason I stayed in

238
00:11:13,600 --> 00:11:18,520
that chapter it was a an organization of

239
00:11:15,640 --> 00:11:21,340
CIOs and I always wanted to know what

240
00:11:18,520 --> 00:11:24,480
our CIO is thinking and this guy mark

241
00:11:21,340 --> 00:11:28,660
Schwartz was a CIO of the US Immigration

242
00:11:24,480 --> 00:11:30,820
Society and in in DC and you can imagine

243
00:11:28,660 --> 00:11:32,650
what a tough job that is right so I

244
00:11:30,820 --> 00:11:36,040
guess he left now he's working for

245
00:11:32,650 --> 00:11:39,670
Amazon but he wrote this book talking

246
00:11:36,040 --> 00:11:41,829
about the the trends in IT and the trend

247
00:11:39,670 --> 00:11:43,870
he highlights was simply that the

248
00:11:41,830 --> 00:11:45,850
business people are taking over more and

249
00:11:43,870 --> 00:11:48,100
more of the technology function right

250
00:11:45,850 --> 00:11:49,630
it's not just standing in the CIO world

251
00:11:48,100 --> 00:11:51,100
and he said well you if you want a seat

252
00:11:49,630 --> 00:11:53,890
at the table this is what you have to do

253
00:11:51,100 --> 00:11:55,990
and so for example when I did this

254
00:11:53,890 --> 00:11:58,840
threat modeling work at Center for

255
00:11:55,990 --> 00:12:00,250
Medicare and Medicaid in Baltimore it's

256
00:11:58,840 --> 00:12:03,430
a very interesting project we were

257
00:12:00,250 --> 00:12:05,860
developing the next generation Medicare

258
00:12:03,430 --> 00:12:07,569
and Medicaid payment systems and guess

259
00:12:05,860 --> 00:12:09,220
where the developers and technology

260
00:12:07,570 --> 00:12:11,380
people were they were not in the office

261
00:12:09,220 --> 00:12:14,470
of the CIO they were out in an agent in

262
00:12:11,380 --> 00:12:18,010
a sub division of CMS that's they were

263
00:12:14,470 --> 00:12:20,020
all there so we in the I was consulting

264
00:12:18,010 --> 00:12:21,640
in the central security group we had to

265
00:12:20,020 --> 00:12:25,030
influence them they weren't even in the

266
00:12:21,640 --> 00:12:27,010
same department that we were and so this

267
00:12:25,030 --> 00:12:30,010
is what he's saying CIOs need to make

268
00:12:27,010 --> 00:12:31,930
this transition from running everything

269
00:12:30,010 --> 00:12:33,760
to kind of setting standards and being

270
00:12:31,930 --> 00:12:35,880
influencers and I see the same thing

271
00:12:33,760 --> 00:12:38,580
could happen to security I know some

272
00:12:35,880 --> 00:12:41,530
organizations that have very strong

273
00:12:38,580 --> 00:12:44,380
security folks out in the business units

274
00:12:41,530 --> 00:12:45,379
and so security could follow I think it

275
00:12:44,380 --> 00:12:46,939
will follow get

276
00:12:45,379 --> 00:12:49,220
we're engaged with the business so just

277
00:12:46,939 --> 00:12:52,759
out of curiosity how many people here in

278
00:12:49,220 --> 00:12:55,399
their organization see the security team

279
00:12:52,759 --> 00:12:57,799
are parts of the security team directly

280
00:12:55,399 --> 00:13:02,409
in the business units themselves in any

281
00:12:57,799 --> 00:13:05,598
of your organization's they are okay and

282
00:13:02,409 --> 00:13:08,509
anybody else so in the back also Oh

283
00:13:05,599 --> 00:13:10,970
quite a few people then right so that's

284
00:13:08,509 --> 00:13:12,979
not a mega trend yet but it's kind of an

285
00:13:10,970 --> 00:13:14,689
initial trend that you know more of us

286
00:13:12,979 --> 00:13:16,809
need to learn more about the business

287
00:13:14,689 --> 00:13:21,228
and so that's what this book was about

288
00:13:16,809 --> 00:13:27,009
about a year old he switched to Amazon

289
00:13:21,229 --> 00:13:29,749
but I still think it's worth reading so

290
00:13:27,009 --> 00:13:32,809
I'm gonna propose threat modeling as a

291
00:13:29,749 --> 00:13:34,609
way it's a tool it's a technology but

292
00:13:32,809 --> 00:13:37,339
it's a way to engage that it's a way to

293
00:13:34,609 --> 00:13:41,449
manage risk and to engage the business

294
00:13:37,339 --> 00:13:44,329
because it looks at risks values threats

295
00:13:41,449 --> 00:13:46,209
vulnerabilities all in one screen and

296
00:13:44,329 --> 00:13:48,409
that's kind of the holy grail of

297
00:13:46,209 --> 00:13:50,748
security right if you can connect your

298
00:13:48,409 --> 00:13:53,029
threats to your risk to your assets and

299
00:13:50,749 --> 00:13:55,149
you can make a gazillion dollars if you

300
00:13:53,029 --> 00:14:01,369
know how to do that so this is one

301
00:13:55,149 --> 00:14:03,829
possible way of doing that so so I as I

302
00:14:01,369 --> 00:14:05,720
said I did I don't claim to be an expert

303
00:14:03,829 --> 00:14:07,309
in threat modeling I'm I'm a change

304
00:14:05,720 --> 00:14:09,499
agent now I'm really trying to help

305
00:14:07,309 --> 00:14:11,659
working professionals make as one

306
00:14:09,499 --> 00:14:13,369
student said 90 degree changes in their

307
00:14:11,659 --> 00:14:15,169
career path to get into security

308
00:14:13,369 --> 00:14:17,029
hopefully not a hundred and eighty

309
00:14:15,169 --> 00:14:20,239
degree changes right I'm glad he just

310
00:14:17,029 --> 00:14:21,769
said 90 degree changes but anyway so the

311
00:14:20,239 --> 00:14:26,509
work I've done over the last few years

312
00:14:21,769 --> 00:14:28,970
was for CMS and Vanderbilt health and

313
00:14:26,509 --> 00:14:31,459
I'd played with threat modeling and it

314
00:14:28,970 --> 00:14:33,229
was kind of frustrating because what is

315
00:14:31,459 --> 00:14:35,599
threat modeling this is such a dumb term

316
00:14:33,229 --> 00:14:37,489
what does this mean and then finally I

317
00:14:35,600 --> 00:14:39,499
figured out that it's really just risk

318
00:14:37,489 --> 00:14:42,649
analysis for applications and systems

319
00:14:39,499 --> 00:14:44,449
and this guy Richard bate leaked he's

320
00:14:42,649 --> 00:14:46,759
pretty famous right I forgot exactly

321
00:14:44,449 --> 00:14:48,409
what he did but he's like a household

322
00:14:46,759 --> 00:14:51,409
world in security and he wrote this very

323
00:14:48,409 --> 00:14:54,829
good blog post back in 2007 talking

324
00:14:51,409 --> 00:14:57,049
about hey this really isn't threat

325
00:14:54,829 --> 00:14:58,549
modeling per se it's just risk analysis

326
00:14:57,049 --> 00:14:59,100
that we're doing it's a risk analysis

327
00:14:58,549 --> 00:15:01,740
method

328
00:14:59,100 --> 00:15:02,760
the term threat modeling came about from

329
00:15:01,740 --> 00:15:04,710
Microsoft

330
00:15:02,760 --> 00:15:08,100
back when they came up with this right

331
00:15:04,710 --> 00:15:11,700
early 2000s so all you're really doing

332
00:15:08,100 --> 00:15:13,680
is looking at risk and you're starting

333
00:15:11,700 --> 00:15:15,540
with your threats usually we do

334
00:15:13,680 --> 00:15:18,000
vulnerability management we start with

335
00:15:15,540 --> 00:15:21,360
vulnerabilities or we look at asset

336
00:15:18,000 --> 00:15:22,950
values in the case of modeling you're

337
00:15:21,360 --> 00:15:25,130
looking at what are the threats that are

338
00:15:22,950 --> 00:15:29,040
out there so it forces you to go through

339
00:15:25,130 --> 00:15:31,200
catalog your threats and understand what

340
00:15:29,040 --> 00:15:32,730
the impact or the tool helps you figure

341
00:15:31,200 --> 00:15:36,150
out what the impact could be on the

342
00:15:32,730 --> 00:15:39,660
business as I said it's a process and a

343
00:15:36,150 --> 00:15:41,550
tool so why bother to do this so I'm

344
00:15:39,660 --> 00:15:42,810
going to throw in some compliance stuff

345
00:15:41,550 --> 00:15:46,370
of course we have to start with

346
00:15:42,810 --> 00:15:49,829
compliance so if you are working with

347
00:15:46,370 --> 00:15:51,630
853 you're not required to do threat

348
00:15:49,830 --> 00:15:55,470
modeling but there is something called a

349
00:15:51,630 --> 00:15:58,590
control enhancement sa 15 control

350
00:15:55,470 --> 00:16:02,400
enhancement how many people do work with

351
00:15:58,590 --> 00:16:04,380
853 anybody quite a few right it's sort

352
00:16:02,400 --> 00:16:06,360
of pervasive if are you guys government

353
00:16:04,380 --> 00:16:13,470
contractors or part of the federal

354
00:16:06,360 --> 00:16:16,050
government or both both okay so 853 is

355
00:16:13,470 --> 00:16:19,710
kind of complicated right but if you if

356
00:16:16,050 --> 00:16:21,089
you have a sensitive system you can put

357
00:16:19,710 --> 00:16:24,060
in place what's called a control

358
00:16:21,090 --> 00:16:25,860
enhancement and threat modeling is one

359
00:16:24,060 --> 00:16:29,099
of those control enhancements if you

360
00:16:25,860 --> 00:16:31,440
work for DoD they have something called

361
00:16:29,100 --> 00:16:35,550
the DISA stick anybody working for DoD

362
00:16:31,440 --> 00:16:37,110
here one in the back okay so you guys

363
00:16:35,550 --> 00:16:41,910
you raise your hand for a lot of stuff

364
00:16:37,110 --> 00:16:43,680
right good they have the DISA stick for

365
00:16:41,910 --> 00:16:45,990
application security and development

366
00:16:43,680 --> 00:16:50,430
does require threat modeling for level 2

367
00:16:45,990 --> 00:16:57,200
applications and what else do we have so

368
00:16:50,430 --> 00:16:59,459
good practice under a wasp Sam security

369
00:16:57,200 --> 00:17:01,590
application security maturity model I

370
00:16:59,460 --> 00:17:05,970
think that stands for it is required for

371
00:17:01,590 --> 00:17:07,950
maturity level 1 safe code safe code was

372
00:17:05,970 --> 00:17:09,780
kind of started by Microsoft by the way

373
00:17:07,950 --> 00:17:10,670
safe code how many people go to safe

374
00:17:09,780 --> 00:17:14,420
code or

375
00:17:10,670 --> 00:17:16,339
scan that site anybody one or two that's

376
00:17:14,420 --> 00:17:18,200
a really good site to understand

377
00:17:16,339 --> 00:17:19,849
application security they have a lot of

378
00:17:18,200 --> 00:17:23,390
good training videos and things there

379
00:17:19,849 --> 00:17:24,889
they have stuff on how to use threat

380
00:17:23,390 --> 00:17:26,990
modeling and it sort they have a desert

381
00:17:24,890 --> 00:17:29,950
best practice of application security

382
00:17:26,990 --> 00:17:33,140
and they do require threat modeling also

383
00:17:29,950 --> 00:17:35,380
and now that I'm in the education

384
00:17:33,140 --> 00:17:38,090
business we're using the nice NSA

385
00:17:35,380 --> 00:17:39,890
knowledge units and they do they have it

386
00:17:38,090 --> 00:17:41,689
in their lifecycle security knowledge

387
00:17:39,890 --> 00:17:45,200
unit so I thought that was interesting

388
00:17:41,690 --> 00:17:47,330
what else so it simply a means to

389
00:17:45,200 --> 00:17:48,950
facilitate conversation with business

390
00:17:47,330 --> 00:17:50,899
and security if you're in security you

391
00:17:48,950 --> 00:17:52,610
want to get out of the security silo and

392
00:17:50,900 --> 00:17:54,770
get out and collaborate with your

393
00:17:52,610 --> 00:17:58,219
developers how many people are

394
00:17:54,770 --> 00:18:00,400
developers here all right I hope I can

395
00:17:58,220 --> 00:18:03,680
talk to you guys because that's that's a

396
00:18:00,400 --> 00:18:05,600
challenge for the they speak different

397
00:18:03,680 --> 00:18:07,460
language than the business guys do so

398
00:18:05,600 --> 00:18:10,070
I'm trying to learn the application

399
00:18:07,460 --> 00:18:12,200
development this is a tool to get your

400
00:18:10,070 --> 00:18:17,020
developers and your security people in

401
00:18:12,200 --> 00:18:21,920
the same room so also Gartner I just saw

402
00:18:17,020 --> 00:18:23,840
anybody from Gartner here nope okay well

403
00:18:21,920 --> 00:18:26,990
I guess I can say whatever I want but

404
00:18:23,840 --> 00:18:29,629
anyhow they they we're pretty close to

405
00:18:26,990 --> 00:18:31,850
Gartner they might be right outside

406
00:18:29,630 --> 00:18:35,090
they do have this hype cycle right

407
00:18:31,850 --> 00:18:36,949
you've seen the hype cycle and this is

408
00:18:35,090 --> 00:18:38,320
for applications security I thought this

409
00:18:36,950 --> 00:18:41,840
was pretty interesting because they do

410
00:18:38,320 --> 00:18:45,020
when something becomes almost mainstream

411
00:18:41,840 --> 00:18:48,280
they give it an acronym and so they've

412
00:18:45,020 --> 00:18:51,650
given threat modeling and applications

413
00:18:48,280 --> 00:18:53,629
ASTM now that's their acronym so I don't

414
00:18:51,650 --> 00:18:55,430
know if that means that the whole field

415
00:18:53,630 --> 00:18:58,550
is gonna collapse in two years or it's

416
00:18:55,430 --> 00:19:02,360
gonna grow one or the other right but

417
00:18:58,550 --> 00:19:06,770
it's it's interesting it's on the rising

418
00:19:02,360 --> 00:19:09,949
this is the expectations up at the top

419
00:19:06,770 --> 00:19:12,920
as they call it so modeling is trying to

420
00:19:09,950 --> 00:19:18,260
get up to that area we'll see if it gets

421
00:19:12,920 --> 00:19:19,370
there okay so what are the goals of

422
00:19:18,260 --> 00:19:23,879
threat modeling you want to add

423
00:19:19,370 --> 00:19:26,639
everything in security I had the good

424
00:19:23,879 --> 00:19:29,549
opportunity to meet Ron Ross the head of

425
00:19:26,639 --> 00:19:32,008
the cyber program at NIST when I was

426
00:19:29,549 --> 00:19:34,019
working for CMS so he's really big on

427
00:19:32,009 --> 00:19:37,739
and everybody's big on let's identify

428
00:19:34,019 --> 00:19:39,719
risks upfront identify risks up front

429
00:19:37,739 --> 00:19:43,079
that's his mantra and I make so much

430
00:19:39,719 --> 00:19:46,259
sense because we in security it's

431
00:19:43,079 --> 00:19:48,569
amazing that we accept the idea that

432
00:19:46,259 --> 00:19:50,219
well we're gonna have to do static

433
00:19:48,569 --> 00:19:51,719
testing dynamic testing we have to do

434
00:19:50,219 --> 00:19:55,019
pen testing we're gonna have to fix

435
00:19:51,719 --> 00:19:56,849
things after they're built imagine I

436
00:19:55,019 --> 00:19:59,039
used to work for Nissan imagine you know

437
00:19:56,849 --> 00:20:01,289
cars coming off the production line

438
00:19:59,039 --> 00:20:03,839
people testing them allows this car

439
00:20:01,289 --> 00:20:05,219
working or not working you know nobody

440
00:20:03,839 --> 00:20:06,809
would do that right people would get

441
00:20:05,219 --> 00:20:09,059
fired when those cars come off the

442
00:20:06,809 --> 00:20:10,799
production line they work and they work

443
00:20:09,059 --> 00:20:14,339
for a hundred thousand miles but in this

444
00:20:10,799 --> 00:20:16,918
field security systems development we

445
00:20:14,339 --> 00:20:18,839
accept the fact that they're going to be

446
00:20:16,919 --> 00:20:20,669
errors in the system and then we'll fix

447
00:20:18,839 --> 00:20:23,519
them later and hopefully before the

448
00:20:20,669 --> 00:20:25,409
hackers do so one of the goals of threat

449
00:20:23,519 --> 00:20:28,829
modeling is especially identify your

450
00:20:25,409 --> 00:20:31,799
architectural risk for new systems it

451
00:20:28,829 --> 00:20:34,499
doesn't find code flaws it finds design

452
00:20:31,799 --> 00:20:37,019
flaws and I think right now we have

453
00:20:34,499 --> 00:20:38,579
enough code flaws and design flaws I

454
00:20:37,019 --> 00:20:40,709
think some of the code flaws are gonna

455
00:20:38,579 --> 00:20:43,168
get fixed as people use more standard

456
00:20:40,709 --> 00:20:46,099
libraries you know I'm an electrical

457
00:20:43,169 --> 00:20:48,809
engineer you wouldn't go build you know

458
00:20:46,099 --> 00:20:50,999
create your own chip if you're building

459
00:20:48,809 --> 00:20:53,129
an integrated circuit board right you

460
00:20:50,999 --> 00:20:55,289
just buy standard parts that had

461
00:20:53,129 --> 00:20:56,968
standard test and I think that's I see

462
00:20:55,289 --> 00:20:58,319
that kind of happening in the software

463
00:20:56,969 --> 00:21:00,329
world I don't know if the developers

464
00:20:58,319 --> 00:21:02,549
here would agree but more and more

465
00:21:00,329 --> 00:21:05,749
available libraries are going to be used

466
00:21:02,549 --> 00:21:09,119
instead of creating your own code and

467
00:21:05,749 --> 00:21:10,829
then neutral platforms so not all the

468
00:21:09,119 --> 00:21:12,718
tools I'm talking about or neutral

469
00:21:10,829 --> 00:21:14,369
something like that Microsoft has a

470
00:21:12,719 --> 00:21:18,299
threat modeling tool I'm calling that

471
00:21:14,369 --> 00:21:20,339
sort of neutral maybe not right if

472
00:21:18,299 --> 00:21:23,729
you're working at Amazon but you want

473
00:21:20,339 --> 00:21:26,059
some kind of a neutral tool that enables

474
00:21:23,729 --> 00:21:28,879
collaboration of security and

475
00:21:26,059 --> 00:21:31,168
development and the business people and

476
00:21:28,879 --> 00:21:32,939
you want to get a different point of

477
00:21:31,169 --> 00:21:34,259
view as I said looking at things from

478
00:21:32,940 --> 00:21:36,599
the point of view of threats not

479
00:21:34,259 --> 00:21:37,680
vulnerabilities so a different point of

480
00:21:36,599 --> 00:21:41,159
view I pulled that couple

481
00:21:37,680 --> 00:21:42,930
slides here so the trick about risk is

482
00:21:41,160 --> 00:21:44,670
always what point of view do you have

483
00:21:42,930 --> 00:21:46,440
right are you looking down in the weeds

484
00:21:44,670 --> 00:21:48,240
are you looking up at you know ten

485
00:21:46,440 --> 00:21:51,870
thousand feet up in the air neither one

486
00:21:48,240 --> 00:21:53,640
of them gets all the risks right so you

487
00:21:51,870 --> 00:21:54,300
want to look at both I saw this mouse

488
00:21:53,640 --> 00:21:59,310
here

489
00:21:54,300 --> 00:22:02,520
I guess he missed the risks from up

490
00:21:59,310 --> 00:22:04,470
above and this mouse missed the risks

491
00:22:02,520 --> 00:22:08,450
down below right so there's risks at all

492
00:22:04,470 --> 00:22:10,260
levels and as part of for security

493
00:22:08,450 --> 00:22:14,010
professionals we really need to be

494
00:22:10,260 --> 00:22:17,670
looking at all different levels and how

495
00:22:14,010 --> 00:22:19,170
to fail at threat modeling and it's

496
00:22:17,670 --> 00:22:22,350
pretty easy to fail at threat modeling

497
00:22:19,170 --> 00:22:24,090
so one thing is so you have these tools

498
00:22:22,350 --> 00:22:29,129
whether it's Microsoft or some other

499
00:22:24,090 --> 00:22:31,080
tool and they have the ability to suck

500
00:22:29,130 --> 00:22:33,090
in a lot of data and a lot of

501
00:22:31,080 --> 00:22:36,360
information about systems so if you pick

502
00:22:33,090 --> 00:22:37,620
the scope too big guess what you're

503
00:22:36,360 --> 00:22:41,040
going to get you're gonna get hundreds

504
00:22:37,620 --> 00:22:42,090
of threats and your developers aren't

505
00:22:41,040 --> 00:22:43,889
gonna be nobody's gonna be able to

506
00:22:42,090 --> 00:22:46,020
handle it it's like vona it's kind of

507
00:22:43,890 --> 00:22:49,410
like vulnerability scanning right so if

508
00:22:46,020 --> 00:22:51,650
you scan your whole system and just look

509
00:22:49,410 --> 00:22:54,810
at all the threats without any kind of

510
00:22:51,650 --> 00:22:56,310
way of prioritizing them you're not

511
00:22:54,810 --> 00:22:57,690
gonna be able to do anything so the same

512
00:22:56,310 --> 00:22:59,879
thing with threat modeling you have to

513
00:22:57,690 --> 00:23:02,880
come up with a scope the scope could be

514
00:22:59,880 --> 00:23:05,400
a system it could be a switch it could

515
00:23:02,880 --> 00:23:07,530
be a new cloud application you have to

516
00:23:05,400 --> 00:23:09,900
look at it at the right level too and

517
00:23:07,530 --> 00:23:13,290
have some agreement with your business

518
00:23:09,900 --> 00:23:16,080
folks this has anybody seen this movie

519
00:23:13,290 --> 00:23:19,110
the birds maybe I'm too old a few people

520
00:23:16,080 --> 00:23:21,090
have seen it I kind of like this movie

521
00:23:19,110 --> 00:23:23,429
so this is where the birds are chasing

522
00:23:21,090 --> 00:23:25,230
the kids out of the school so this this

523
00:23:23,430 --> 00:23:27,240
will be your developers you know if you

524
00:23:25,230 --> 00:23:28,800
don't have a well-chosen scope and you

525
00:23:27,240 --> 00:23:34,200
run one of the threat modeling tools

526
00:23:28,800 --> 00:23:37,110
they'll just head for the hills so you

527
00:23:34,200 --> 00:23:38,880
have to really pick the scope correctly

528
00:23:37,110 --> 00:23:41,310
it needs to be you know the Goldilocks

529
00:23:38,880 --> 00:23:46,320
here not too big not too small just

530
00:23:41,310 --> 00:23:50,429
right so what about what other ways are

531
00:23:46,320 --> 00:23:51,659
there so one way is to think you're

532
00:23:50,430 --> 00:23:53,580
modeling the kill chain

533
00:23:51,660 --> 00:23:56,670
do people use the kill chain here the

534
00:23:53,580 --> 00:23:58,740
mitre kill chain a couple people use it

535
00:23:56,670 --> 00:24:00,690
three four I don't know if everybody

536
00:23:58,740 --> 00:24:03,810
else is just not paying attention or

537
00:24:00,690 --> 00:24:06,120
tired or whatever but you're not really

538
00:24:03,810 --> 00:24:16,429
modeling the kill chain I wish I could

539
00:24:06,120 --> 00:24:16,429
see my I can't I'm back

540
00:24:16,610 --> 00:24:23,010
so the kill the kill chain so just as an

541
00:24:21,360 --> 00:24:24,990
example the beginning of the kill chain

542
00:24:23,010 --> 00:24:28,129
has reconnaissance right you're looking

543
00:24:24,990 --> 00:24:30,750
to see what holes does the system have

544
00:24:28,130 --> 00:24:34,380
then your weaponizing you're delivering

545
00:24:30,750 --> 00:24:36,630
so fit modeling doesn't model this whole

546
00:24:34,380 --> 00:24:40,290
thing you're not modeling reconnaissance

547
00:24:36,630 --> 00:24:42,030
for example you're not modeling maintain

548
00:24:40,290 --> 00:24:47,010
persistence on the right you're only

549
00:24:42,030 --> 00:24:49,980
modeling one piece which is when the

550
00:24:47,010 --> 00:24:51,870
person breaks into the system you're not

551
00:24:49,980 --> 00:24:53,400
so it's not perfect it has a lot of

552
00:24:51,870 --> 00:24:55,229
things it doesn't do it doesn't model

553
00:24:53,400 --> 00:24:58,260
lateral movement so if somebody breaks

554
00:24:55,230 --> 00:25:00,270
into a system we don't have good enough

555
00:24:58,260 --> 00:25:02,040
threat modeling tools so you can model

556
00:25:00,270 --> 00:25:04,980
how you hop around from one system to

557
00:25:02,040 --> 00:25:07,080
the next that's what we'd like to have

558
00:25:04,980 --> 00:25:16,440
but the tools don't do that yet they

559
00:25:07,080 --> 00:25:19,669
just say they do which one a tivo are

560
00:25:16,440 --> 00:25:22,740
you a vendor are you here

561
00:25:19,670 --> 00:25:23,600
outstanding okay I'm gonna talk to you

562
00:25:22,740 --> 00:25:29,730
afterwards

563
00:25:23,600 --> 00:25:31,530
very good so most vendors do not allow

564
00:25:29,730 --> 00:25:35,010
you to do that put it that way

565
00:25:31,530 --> 00:25:37,610
I don't mind being corrected so that's

566
00:25:35,010 --> 00:25:37,610
very interesting

567
00:25:38,960 --> 00:25:45,260
so in general yeah you have to be sure

568
00:25:42,600 --> 00:25:49,439
what what what are you modeling and

569
00:25:45,260 --> 00:25:52,230
there's also the the mitre attack

570
00:25:49,440 --> 00:25:54,420
framework you're not modeling all the

571
00:25:52,230 --> 00:25:55,830
steps except for maybe the gentleman in

572
00:25:54,420 --> 00:25:59,910
the back you're not modeling all the

573
00:25:55,830 --> 00:26:02,389
steps in the in the mitre attack

574
00:25:59,910 --> 00:26:02,390
framework

575
00:26:02,990 --> 00:26:10,940
I tried to me I tried to do a tool

576
00:26:09,020 --> 00:26:17,030
comparison can anybody in the back see

577
00:26:10,940 --> 00:26:19,250
this you can like so exciting art I

578
00:26:17,030 --> 00:26:21,710
tried to do this last night so people

579
00:26:19,250 --> 00:26:23,510
like 20 feet away could see this but and

580
00:26:21,710 --> 00:26:25,070
I guess the slides are gonna be

581
00:26:23,510 --> 00:26:26,660
available right so if you want any

582
00:26:25,070 --> 00:26:29,149
follow-up information I assume you can

583
00:26:26,660 --> 00:26:31,670
get these slides so I just did a super

584
00:26:29,150 --> 00:26:33,140
quick evaluation of the different tools

585
00:26:31,670 --> 00:26:36,020
that are out there the only ones I've

586
00:26:33,140 --> 00:26:38,090
really used in depth are the first two

587
00:26:36,020 --> 00:26:39,980
microsoft threat model err I mean

588
00:26:38,090 --> 00:26:41,720
Microsoft threat modeling tool and then

589
00:26:39,980 --> 00:26:44,380
threat model or the second one the

590
00:26:41,720 --> 00:26:50,120
others I've looked at a little bit so

591
00:26:44,380 --> 00:26:51,830
Microsoft TMT whatsits I put strengths

592
00:26:50,120 --> 00:26:53,209
and cautions that's what Gartner does

593
00:26:51,830 --> 00:26:54,830
right I wasn't going to put strengths

594
00:26:53,210 --> 00:26:57,679
and weaknesses I thought he might get in

595
00:26:54,830 --> 00:26:59,240
trouble so I put strengths and cautions

596
00:26:57,679 --> 00:27:00,800
so one strengths is it's free you can

597
00:26:59,240 --> 00:27:04,280
download it and start running it I think

598
00:27:00,800 --> 00:27:06,050
it's very cool and it has really added

599
00:27:04,280 --> 00:27:08,030
in the last I'm not working for

600
00:27:06,050 --> 00:27:16,340
Microsoft but they've added a tremendous

601
00:27:08,030 --> 00:27:18,559
number of new icons based on Azure so

602
00:27:16,340 --> 00:27:20,360
and they've also probably tripled the

603
00:27:18,559 --> 00:27:24,710
number of threats that are in there in

604
00:27:20,360 --> 00:27:27,169
the last 18 months or so so it's it's a

605
00:27:24,710 --> 00:27:29,330
great way to get started it's free one

606
00:27:27,170 --> 00:27:31,370
caution is they don't have a lot of

607
00:27:29,330 --> 00:27:34,309
information on how to fix things so you

608
00:27:31,370 --> 00:27:35,719
find okay here's a threat they don't

609
00:27:34,309 --> 00:27:38,840
really give a lot of information on what

610
00:27:35,720 --> 00:27:40,820
to do now this next tool threat and it's

611
00:27:38,840 --> 00:27:43,250
also as I've seen it it's more of a

612
00:27:40,820 --> 00:27:45,110
one-person tool one person use it maybe

613
00:27:43,250 --> 00:27:46,520
you have a group sitting in a room but

614
00:27:45,110 --> 00:27:48,169
it's not an enterprise shared

615
00:27:46,520 --> 00:27:51,020
application this next to a threat

616
00:27:48,170 --> 00:27:53,900
modeler is a commercial tool it's

617
00:27:51,020 --> 00:27:56,450
web-based software as a service multiple

618
00:27:53,900 --> 00:27:58,700
people can use it at the same time it's

619
00:27:56,450 --> 00:28:01,130
so commercial it's enterprise strapped

620
00:27:58,700 --> 00:28:02,809
modeling tool it's not free it has a

621
00:28:01,130 --> 00:28:06,320
built in it does have a very good

622
00:28:02,809 --> 00:28:08,450
built-in knowledge base of threats it

623
00:28:06,320 --> 00:28:10,580
has I don't know four or five hundred

624
00:28:08,450 --> 00:28:11,929
different kinds of threats associated

625
00:28:10,580 --> 00:28:14,449
with different components so it's very

626
00:28:11,929 --> 00:28:15,710
good caution it's a smaller company with

627
00:28:14,450 --> 00:28:18,590
seven kind of deliver

628
00:28:15,710 --> 00:28:20,570
partners and another company that I

629
00:28:18,590 --> 00:28:23,809
learned about his continuum security

630
00:28:20,570 --> 00:28:27,439
they have a product called arias there

631
00:28:23,809 --> 00:28:29,059
in Spain the strength of this product is

632
00:28:27,440 --> 00:28:30,890
very closely aligned with the

633
00:28:29,059 --> 00:28:33,320
development process the guy who's

634
00:28:30,890 --> 00:28:35,090
running it I'm blanking on his name now

635
00:28:33,320 --> 00:28:36,889
but he's been in application security

636
00:28:35,090 --> 00:28:39,500
for many years he's like a real guru in

637
00:28:36,890 --> 00:28:42,500
that area so that's good if you want to

638
00:28:39,500 --> 00:28:44,990
use this specifically for doing threat

639
00:28:42,500 --> 00:28:48,020
modeling with the developers so it ties

640
00:28:44,990 --> 00:28:50,630
into things like JIRA then fair is

641
00:28:48,020 --> 00:28:52,970
another one has anybody used fair in

642
00:28:50,630 --> 00:28:56,860
their company you have how is it working

643
00:28:52,970 --> 00:28:56,860
out + - no comment

644
00:29:11,260 --> 00:29:17,830
yeah yeah that sounds fair so yeah I

645
00:29:15,790 --> 00:29:19,480
described it as an I have not personally

646
00:29:17,830 --> 00:29:21,668
used it I've seen demos it's an

647
00:29:19,480 --> 00:29:24,790
enterprise tool it may not be suitable

648
00:29:21,669 --> 00:29:27,070
for some fur it's great for enterprise I

649
00:29:24,790 --> 00:29:29,830
think but it might not be so good for

650
00:29:27,070 --> 00:29:31,570
fast-moving agile development to

651
00:29:29,830 --> 00:29:33,909
development teams it might you know it

652
00:29:31,570 --> 00:29:35,799
might be really hard to implement and

653
00:29:33,910 --> 00:29:38,410
then another one security compass up in

654
00:29:35,799 --> 00:29:40,690
Canada they use a simple questionnaire

655
00:29:38,410 --> 00:29:42,610
approach so the team fills out a

656
00:29:40,690 --> 00:29:45,490
questionnaire and then from that they're

657
00:29:42,610 --> 00:29:48,189
able to do analyze threats that might be

658
00:29:45,490 --> 00:29:52,090
out there there's some other open source

659
00:29:48,190 --> 00:29:54,160
ones oh wasps threat dragon so I think

660
00:29:52,090 --> 00:29:55,840
I've seen a number of these open-source

661
00:29:54,160 --> 00:29:57,580
projects get going they don't seem to

662
00:29:55,840 --> 00:30:00,520
have gotten traction this one only has

663
00:29:57,580 --> 00:30:02,710
four contributors sea sponge is another

664
00:30:00,520 --> 00:30:05,410
one last commit a couple years ago and

665
00:30:02,710 --> 00:30:08,530
then the newest one is two to Mantic has

666
00:30:05,410 --> 00:30:11,290
anyone tried that by any chance er it's

667
00:30:08,530 --> 00:30:13,090
it's a startup company and they're their

668
00:30:11,290 --> 00:30:15,580
premises they want to take a Visio

669
00:30:13,090 --> 00:30:18,428
diagram of your network and applications

670
00:30:15,580 --> 00:30:23,290
you feed it into them and then they'll

671
00:30:18,429 --> 00:30:25,270
generate a threat model I haven't acted

672
00:30:23,290 --> 00:30:28,389
done a lot with it but it seems like a

673
00:30:25,270 --> 00:30:30,549
good idea cuz with these other tools you

674
00:30:28,390 --> 00:30:31,900
sort of have to create your own diagram

675
00:30:30,549 --> 00:30:34,540
just for the tool which is pretty

676
00:30:31,900 --> 00:30:38,559
horrible you should be able to get some

677
00:30:34,540 --> 00:30:40,299
from your CMDB or some other tool should

678
00:30:38,559 --> 00:30:41,710
be able to import information into

679
00:30:40,299 --> 00:30:44,740
threat modeling but I haven't seen that

680
00:30:41,710 --> 00:30:47,140
yet so those are quick comparison the

681
00:30:44,740 --> 00:30:48,880
tools so this is going to be hard to see

682
00:30:47,140 --> 00:30:51,940
I'm sorry so I'm illustrating some

683
00:30:48,880 --> 00:30:55,210
things that I did with threat modeling

684
00:30:51,940 --> 00:30:57,460
this was for Center for Medicare

685
00:30:55,210 --> 00:31:00,549
Medicaid and so I picked the scope as a

686
00:30:57,460 --> 00:31:02,350
single transaction going from an

687
00:31:00,549 --> 00:31:05,830
authentication service back to a

688
00:31:02,350 --> 00:31:08,020
key-value database request response I

689
00:31:05,830 --> 00:31:10,120
put one machine trust boundary in there

690
00:31:08,020 --> 00:31:13,000
this was an AWS so this prints out a

691
00:31:10,120 --> 00:31:16,600
list of threats associated just with

692
00:31:13,000 --> 00:31:18,250
this this would be connected with or in

693
00:31:16,600 --> 00:31:22,178
this case I'd be collaborating with a

694
00:31:18,250 --> 00:31:24,429
specific development team for

695
00:31:22,179 --> 00:31:27,159
implementing a use case around

696
00:31:24,429 --> 00:31:30,100
dedication so I picked a really simple

697
00:31:27,159 --> 00:31:34,330
scope here's another one in this case

698
00:31:30,100 --> 00:31:35,998
this was also a CMS system but I took

699
00:31:34,330 --> 00:31:38,918
out a lot of the stuff for the details

700
00:31:35,999 --> 00:31:41,289
here I was using the tool Thor third

701
00:31:38,919 --> 00:31:46,690
party risk modeling this particular

702
00:31:41,289 --> 00:31:53,889
application had many partners and you

703
00:31:46,690 --> 00:31:57,759
can see in each one of these end-users

704
00:31:53,889 --> 00:31:59,860
so by running a model like this you get

705
00:31:57,759 --> 00:32:01,480
a list of threats for each one of these

706
00:31:59,860 --> 00:32:03,820
interactions with the different third

707
00:32:01,480 --> 00:32:05,470
parties and everybody knows how

708
00:32:03,820 --> 00:32:07,928
important third-party risk is I'm not

709
00:32:05,470 --> 00:32:09,940
showing the results of this but when you

710
00:32:07,929 --> 00:32:12,059
run this you get a list you kind of get

711
00:32:09,940 --> 00:32:14,889
a checklist here are all the threats you

712
00:32:12,059 --> 00:32:17,799
sit down with the systems engineers you

713
00:32:14,889 --> 00:32:19,629
say did you address this did you address

714
00:32:17,799 --> 00:32:21,220
this if you say if the answer is yes

715
00:32:19,629 --> 00:32:26,049
then you check that off so it raises

716
00:32:21,220 --> 00:32:27,460
issues in an organized hopefully not not

717
00:32:26,049 --> 00:32:30,789
confrontational or not too

718
00:32:27,460 --> 00:32:32,289
confrontational way and again this is

719
00:32:30,789 --> 00:32:35,169
not going to be possible to see in the

720
00:32:32,289 --> 00:32:37,600
back but this is the output of the

721
00:32:35,169 --> 00:32:39,519
threat modeling tool so here it comes

722
00:32:37,600 --> 00:32:41,799
out with the Microsoft threat modeling

723
00:32:39,519 --> 00:32:44,139
tool here it says are you doing enough

724
00:32:41,799 --> 00:32:46,840
auditing are you collecting logs for

725
00:32:44,139 --> 00:32:51,039
this particular process and the other

726
00:32:46,840 --> 00:32:53,230
fun thing about it is additional fields

727
00:32:51,039 --> 00:32:57,940
in there I did some customization how

728
00:32:53,230 --> 00:33:01,360
does this threat relate to 853 or how

729
00:32:57,940 --> 00:33:03,519
does it relate to cwe can you put in a

730
00:33:01,360 --> 00:33:05,379
user story I was working with developers

731
00:33:03,519 --> 00:33:10,299
so I wanted to put in a security user

732
00:33:05,379 --> 00:33:12,580
story so you can add in a lot of custom

733
00:33:10,299 --> 00:33:14,470
features into this tool and that's true

734
00:33:12,580 --> 00:33:16,389
of the other ones I've looked at too and

735
00:33:14,470 --> 00:33:19,779
here's another one that's going to be

736
00:33:16,389 --> 00:33:21,610
not recognizable this is threat modeler

737
00:33:19,779 --> 00:33:23,980
the commercial tool I talked about the

738
00:33:21,610 --> 00:33:28,498
enterprise tool that enables multiple

739
00:33:23,980 --> 00:33:30,879
users the good thing is it has a ton of

740
00:33:28,499 --> 00:33:32,710
components that you can just click and

741
00:33:30,879 --> 00:33:35,500
drag into your model so if you want to

742
00:33:32,710 --> 00:33:39,340
use as your traffic

743
00:33:35,500 --> 00:33:43,270
into your model it has built-in threats

744
00:33:39,340 --> 00:33:45,010
and remediations so these guys go a lot

745
00:33:43,270 --> 00:33:47,260
further than Microsoft in terms of

746
00:33:45,010 --> 00:33:49,420
built-in threats and remediations and

747
00:33:47,260 --> 00:33:51,820
they had this probably four or five

748
00:33:49,420 --> 00:33:53,800
hundred different things in their

749
00:33:51,820 --> 00:33:58,330
toolkit so you're basically paying them

750
00:33:53,800 --> 00:34:00,220
for their knowledge base and this is

751
00:33:58,330 --> 00:34:13,210
another one you can't see so the output

752
00:34:00,220 --> 00:34:16,629
of threat modeler so you create the

753
00:34:13,210 --> 00:34:18,820
diagram and then it will output a threat

754
00:34:16,629 --> 00:34:21,069
and it says this is where this threat is

755
00:34:18,820 --> 00:34:22,659
coming from so then it enables you to go

756
00:34:21,070 --> 00:34:25,030
back you can't just deal with the whole

757
00:34:22,659 --> 00:34:27,850
system at once so it'll tell you where

758
00:34:25,030 --> 00:34:31,629
the threats are where they originate

759
00:34:27,850 --> 00:34:34,799
from which is important this is Arius

760
00:34:31,629 --> 00:34:37,389
risk I won't spend too much time on this

761
00:34:34,800 --> 00:34:40,300
they go through another interview

762
00:34:37,389 --> 00:34:42,520
process with developers they have a

763
00:34:40,300 --> 00:34:46,060
rules engine and then they output

764
00:34:42,520 --> 00:34:48,730
different kinds of threats so one of the

765
00:34:46,060 --> 00:34:53,739
big kind of missing links is where do

766
00:34:48,730 --> 00:34:55,300
you get a baseline of threats because

767
00:34:53,739 --> 00:34:57,220
your business is going to be different

768
00:34:55,300 --> 00:34:58,810
now you just if you use any of these

769
00:34:57,220 --> 00:35:00,730
tools you just can't use them out of the

770
00:34:58,810 --> 00:35:01,990
box right that's not due diligence you

771
00:35:00,730 --> 00:35:04,150
just you know I'm gonna buy this tool

772
00:35:01,990 --> 00:35:07,899
start running it you have to make sure

773
00:35:04,150 --> 00:35:09,850
that it's incorporating the threats that

774
00:35:07,900 --> 00:35:11,980
you have for your business so where do

775
00:35:09,850 --> 00:35:14,160
you get a library of threats that's one

776
00:35:11,980 --> 00:35:17,080
of the challenges so you can start with

777
00:35:14,160 --> 00:35:19,509
kind of a baseline that maybe comes with

778
00:35:17,080 --> 00:35:22,299
the tool and the big plus of this is

779
00:35:19,510 --> 00:35:24,610
once you create that library you can use

780
00:35:22,300 --> 00:35:26,890
it for other projects in your company

781
00:35:24,610 --> 00:35:30,010
you're not reinventing the wheel all the

782
00:35:26,890 --> 00:35:34,720
time you have to keep it up to date so

783
00:35:30,010 --> 00:35:37,710
libraries that I've seen or Capek it's

784
00:35:34,720 --> 00:35:40,180
almost got too many attack patterns like

785
00:35:37,710 --> 00:35:42,580
517 attack patterns can you manage that

786
00:35:40,180 --> 00:35:44,740
Microsoft the threat modeling tool I

787
00:35:42,580 --> 00:35:46,690
think I just counted last night a

788
00:35:44,740 --> 00:35:49,180
hundred and seventy seven threats built

789
00:35:46,690 --> 00:35:49,329
into that and I'm excited because they

790
00:35:49,180 --> 00:35:51,279
were

791
00:35:49,329 --> 00:35:52,900
eighteen months ago there are only 41

792
00:35:51,279 --> 00:35:56,170
threats so they're really keeping it up

793
00:35:52,900 --> 00:35:58,479
to date with as your threats threat

794
00:35:56,170 --> 00:36:00,839
modeler the commercial tool is for five

795
00:35:58,479 --> 00:36:04,089
six hundred threats built into that tool

796
00:36:00,839 --> 00:36:05,769
the latest one was high trust has

797
00:36:04,089 --> 00:36:08,650
anybody seen the high trust threat

798
00:36:05,769 --> 00:36:12,538
catalog yes a couple of people have seen

799
00:36:08,650 --> 00:36:16,509
it so I just got an email about that I

800
00:36:12,539 --> 00:36:17,829
not being being an academic I downloaded

801
00:36:16,509 --> 00:36:19,390
I looked at it it seems pretty

802
00:36:17,829 --> 00:36:21,999
interesting it seems like it has about a

803
00:36:19,390 --> 00:36:24,308
hundred and fifty threats so it's not

804
00:36:21,999 --> 00:36:25,359
too many not too few pretty

805
00:36:24,309 --> 00:36:27,039
well-documented

806
00:36:25,359 --> 00:36:30,160
the only bad news is you can't use it

807
00:36:27,039 --> 00:36:31,450
unless you subscribe to high trust I

808
00:36:30,160 --> 00:36:36,098
guess right so I don't know how much

809
00:36:31,450 --> 00:36:38,769
that is so but it's nice to look at so

810
00:36:36,099 --> 00:36:41,109
if you could work out a way to use that

811
00:36:38,769 --> 00:36:43,598
that might be good so I like that the

812
00:36:41,109 --> 00:36:48,119
other ones I put in need of work your

813
00:36:43,599 --> 00:36:53,999
Google cloud platform just a curiosity

814
00:36:48,119 --> 00:36:58,390
one two three a few verses about AWS or

815
00:36:53,999 --> 00:37:00,459
how about a sure I think Azure and AWS

816
00:36:58,390 --> 00:37:02,949
are kind of tied and GCP is kind of

817
00:37:00,459 --> 00:37:05,529
behind so I didn't see a lot of threat

818
00:37:02,949 --> 00:37:07,029
modeling work on GCP I used it a little

819
00:37:05,529 --> 00:37:10,329
bit they were using it at Vanderbilt

820
00:37:07,029 --> 00:37:13,299
Medical I sure I put in need of work on

821
00:37:10,329 --> 00:37:15,029
the other hand it's in need of work in

822
00:37:13,299 --> 00:37:17,529
the sense that they don't have a lot of

823
00:37:15,029 --> 00:37:19,299
remediations in the Microsoft threat

824
00:37:17,529 --> 00:37:22,119
modeling tool they do they have been

825
00:37:19,299 --> 00:37:24,219
doing a really good job on putting more

826
00:37:22,119 --> 00:37:27,279
threats into the into the modeling tool

827
00:37:24,219 --> 00:37:29,349
which I'm impressed with so some

828
00:37:27,279 --> 00:37:31,690
application development use cases this

829
00:37:29,349 --> 00:37:36,749
is some other work I did for CMS it's

830
00:37:31,690 --> 00:37:40,390
kind of related but while I was at CMS

831
00:37:36,749 --> 00:37:42,218
Trump said everybody has to follow the

832
00:37:40,390 --> 00:37:43,868
NIST cybersecurity framework in the

833
00:37:42,219 --> 00:37:46,569
federal government right they already

834
00:37:43,869 --> 00:37:48,430
have to follow 800-53 now they all have

835
00:37:46,569 --> 00:37:51,009
to follow the cybersecurity framework so

836
00:37:48,430 --> 00:37:52,299
I was kind of excited about that I was

837
00:37:51,009 --> 00:37:55,329
working with these application

838
00:37:52,299 --> 00:37:57,459
developers so I said how can we use the

839
00:37:55,329 --> 00:37:59,499
cybersecurity framework in the

840
00:37:57,459 --> 00:38:01,808
application development lifecycle so

841
00:37:59,499 --> 00:38:03,230
this is kind of what I came up with I

842
00:38:01,809 --> 00:38:05,210
said you know

843
00:38:03,230 --> 00:38:06,530
got identified protect detect respond

844
00:38:05,210 --> 00:38:08,510
recover we're going to identify

845
00:38:06,530 --> 00:38:11,060
vulnerabilities we're gonna protect the

846
00:38:08,510 --> 00:38:13,790
codebase from those we're gonna detect

847
00:38:11,060 --> 00:38:16,549
vulnerabilities that get through respond

848
00:38:13,790 --> 00:38:19,430
to issues and then recover so that was

849
00:38:16,550 --> 00:38:20,990
my idea and then threat modeling I put

850
00:38:19,430 --> 00:38:23,390
in the identify it's not going to

851
00:38:20,990 --> 00:38:25,399
identify coding errors but it can

852
00:38:23,390 --> 00:38:27,230
identify architectural errors you know

853
00:38:25,400 --> 00:38:29,000
the big the big picture of things that

854
00:38:27,230 --> 00:38:32,990
can cause huge failure so I put it over

855
00:38:29,000 --> 00:38:36,080
there then down in the bottom I put this

856
00:38:32,990 --> 00:38:40,339
relative mitigation cost this is if you

857
00:38:36,080 --> 00:38:43,100
look at software development you know

858
00:38:40,340 --> 00:38:46,580
cost studies they'll say that if you fix

859
00:38:43,100 --> 00:38:49,850
a bug in the you know at the developer

860
00:38:46,580 --> 00:38:51,710
desktop it may cost $1 if you fix it

861
00:38:49,850 --> 00:38:53,450
when in production it's a hundred and we

862
00:38:51,710 --> 00:38:54,980
I feel we don't put enough emphasis on

863
00:38:53,450 --> 00:38:56,480
that in the security field because our

864
00:38:54,980 --> 00:38:59,060
bugs are the same kind of bugs as

865
00:38:56,480 --> 00:39:00,920
functional bugs right so this should

866
00:38:59,060 --> 00:39:04,029
really Drive this curve should really

867
00:39:00,920 --> 00:39:07,040
Drive more emphasis on getting stuff

868
00:39:04,030 --> 00:39:10,730
right before it even goes further down

869
00:39:07,040 --> 00:39:13,279
the pipeline and this is also too hard

870
00:39:10,730 --> 00:39:14,690
to read but this was just you could you

871
00:39:13,280 --> 00:39:16,340
can look at it in the slides afterwards

872
00:39:14,690 --> 00:39:21,109
this is how to incorporate threat

873
00:39:16,340 --> 00:39:22,700
modeling in an agile devops process so

874
00:39:21,109 --> 00:39:25,400
what are some of the opportunities so

875
00:39:22,700 --> 00:39:28,279
move the security conversation to the

876
00:39:25,400 --> 00:39:29,750
front end and it's I haven't had a

877
00:39:28,280 --> 00:39:31,940
hundred percent success getting

878
00:39:29,750 --> 00:39:34,070
developers engaged but I think it's the

879
00:39:31,940 --> 00:39:35,780
the goal not to make them security

880
00:39:34,070 --> 00:39:39,080
professionals but use these kind of

881
00:39:35,780 --> 00:39:42,290
tools to have more conversations at the

882
00:39:39,080 --> 00:39:46,220
beginning enable a smarter risk analysis

883
00:39:42,290 --> 00:39:48,320
so if you have the tools built out then

884
00:39:46,220 --> 00:39:51,709
you can apply them to the next project

885
00:39:48,320 --> 00:39:55,310
without reinventing the wheel what else

886
00:39:51,710 --> 00:39:59,180
find new threats to code architecture

887
00:39:55,310 --> 00:40:02,240
and reusability I already mentioned that

888
00:39:59,180 --> 00:40:04,310
reusability of analysis and then this is

889
00:40:02,240 --> 00:40:06,649
another thing that Ron Ross emphasizes

890
00:40:04,310 --> 00:40:09,740
that NIST take the system's point of

891
00:40:06,650 --> 00:40:11,750
view take a systems point of view so if

892
00:40:09,740 --> 00:40:13,669
you use the model that I built with all

893
00:40:11,750 --> 00:40:16,250
the third parties in there then you can

894
00:40:13,670 --> 00:40:16,880
in that context you can definitely take

895
00:40:16,250 --> 00:40:20,060
a systems

896
00:40:16,880 --> 00:40:22,910
point of view so I hope that these tools

897
00:40:20,060 --> 00:40:26,150
enable people to translate between

898
00:40:22,910 --> 00:40:29,299
DevOps business and security and come up

899
00:40:26,150 --> 00:40:32,690
with a more resilient system in the

900
00:40:29,300 --> 00:40:36,620
beginning so I started out talking about

901
00:40:32,690 --> 00:40:38,060
change I think the field is changing

902
00:40:36,620 --> 00:40:40,609
it's just unbelievable how much it's

903
00:40:38,060 --> 00:40:46,100
changing I think the opportunities are

904
00:40:40,610 --> 00:40:47,360
for us to help create that change and if

905
00:40:46,100 --> 00:40:49,069
it you know it's gonna mean

906
00:40:47,360 --> 00:40:54,110
collaborating more with the business for

907
00:40:49,070 --> 00:40:56,980
sure taking new taking new courses on

908
00:40:54,110 --> 00:40:59,420
some online courses getting new degrees

909
00:40:56,980 --> 00:41:01,190
the whole the whole field is just

910
00:40:59,420 --> 00:41:03,860
incredibly exciting these days with all

911
00:41:01,190 --> 00:41:06,050
the new opportunities so let's all

912
00:41:03,860 --> 00:41:09,110
create change I have a couple of

913
00:41:06,050 --> 00:41:11,150
references Adams Shostak is the Guru in

914
00:41:09,110 --> 00:41:13,970
threat modeling he kind of really

915
00:41:11,150 --> 00:41:15,830
popularized it at Microsoft and he gave

916
00:41:13,970 --> 00:41:17,629
a very good presentation at the last

917
00:41:15,830 --> 00:41:20,029
blackhat I wasn't there but it's online

918
00:41:17,630 --> 00:41:22,370
I definitely recommend that and then

919
00:41:20,030 --> 00:41:24,350
there's also an OU wasp threat modeling

920
00:41:22,370 --> 00:41:27,319
slack Channel I think it has like 500

921
00:41:24,350 --> 00:41:30,319
people in it now so this field could be

922
00:41:27,320 --> 00:41:31,670
growing and it might be good to just

923
00:41:30,320 --> 00:41:34,520
connect with people in that slack

924
00:41:31,670 --> 00:41:36,290
Channel and you can reach me if you have

925
00:41:34,520 --> 00:41:39,009
more questions or don't get the slides

926
00:41:36,290 --> 00:41:41,630
or have any other thoughts or comments

927
00:41:39,010 --> 00:41:43,610
and that's about it anybody have any any

928
00:41:41,630 --> 00:41:45,910
comments they want to make on anything I

929
00:41:43,610 --> 00:41:45,910
said or

930
00:41:55,020 --> 00:42:12,840
yes sir yeah that is what I have done

931
00:42:09,090 --> 00:42:15,210
and that's not the that's like at a low

932
00:42:12,840 --> 00:42:16,680
maturity well that's maturity level one

933
00:42:15,210 --> 00:42:19,440
and that's about as far as I've gotten

934
00:42:16,680 --> 00:42:22,080
it should be that you're kind of sitting

935
00:42:19,440 --> 00:42:24,000
around the you know you're part of the

936
00:42:22,080 --> 00:42:25,259
sprint and working together and one of

937
00:42:24,000 --> 00:42:28,560
the things I've found that's difficult

938
00:42:25,260 --> 00:42:31,440
is like if I was using when I was using

939
00:42:28,560 --> 00:42:33,090
the threat modeling tool the Microsoft

940
00:42:31,440 --> 00:42:35,910
threat modeling tool it deals with data

941
00:42:33,090 --> 00:42:39,240
flow it wants to know data is flowing

942
00:42:35,910 --> 00:42:41,850
from this node to this node and it was

943
00:42:39,240 --> 00:42:43,200
it was difficult to have that I found it

944
00:42:41,850 --> 00:42:45,000
hard to have that conversation with the

945
00:42:43,200 --> 00:42:46,230
developers because they weren't thinking

946
00:42:45,000 --> 00:42:50,100
about that they were thinking about

947
00:42:46,230 --> 00:42:53,190
api's they're connecting you know only

948
00:42:50,100 --> 00:42:54,569
after a lot of the project development

949
00:42:53,190 --> 00:42:57,000
work had been done then they would

950
00:42:54,570 --> 00:42:59,540
document it so that was the challenge I

951
00:42:57,000 --> 00:43:03,270
faced yes this is the way I did it as I

952
00:42:59,540 --> 00:43:05,009
gleaned I had to wait until they'd kind

953
00:43:03,270 --> 00:43:06,869
of documented a lot of the project and

954
00:43:05,010 --> 00:43:09,109
then run the threat model and that's not

955
00:43:06,869 --> 00:43:12,420
the right way to do it so there's still

956
00:43:09,109 --> 00:43:14,640
more work so we have several programming

957
00:43:12,420 --> 00:43:16,800
courses in our curriculum I'm hoping we

958
00:43:14,640 --> 00:43:18,900
can you know get more conversation going

959
00:43:16,800 --> 00:43:21,119
with developers and figure out what

960
00:43:18,900 --> 00:43:23,280
information can they give us that we can

961
00:43:21,119 --> 00:43:25,440
put into that threat modeling tool or

962
00:43:23,280 --> 00:43:29,160
the other one so it's it's an open area

963
00:43:25,440 --> 00:43:37,980
for work in my opinion three minutes

964
00:43:29,160 --> 00:43:40,710
left yes yes sir open source libraries

965
00:43:37,980 --> 00:43:42,900
it makes me really nervous I'm sort of a

966
00:43:40,710 --> 00:43:46,140
traditional engineer we you know you you

967
00:43:42,900 --> 00:43:48,690
know what's in your system they were

968
00:43:46,140 --> 00:43:50,040
doing this at CMS they had so many open

969
00:43:48,690 --> 00:43:52,440
source libraries coming into these

970
00:43:50,040 --> 00:43:54,720
systems and they you know they used

971
00:43:52,440 --> 00:43:57,869
black duck I think to look for

972
00:43:54,720 --> 00:44:00,990
vulnerabilities so it's an area that

973
00:43:57,869 --> 00:44:04,260
makes me nervous and I'm not sure who's

974
00:44:00,990 --> 00:44:06,930
solved the problem how do we do we have

975
00:44:04,260 --> 00:44:07,920
the assurance that these libraries are

976
00:44:06,930 --> 00:44:09,419
going to not

977
00:44:07,920 --> 00:44:11,040
work today but then they're gonna keep

978
00:44:09,420 --> 00:44:12,810
on working and some of these you know

979
00:44:11,040 --> 00:44:14,759
that people do things like looking at

980
00:44:12,810 --> 00:44:16,560
how many developers are there like I

981
00:44:14,760 --> 00:44:17,910
wouldn't use sea sponge there's only

982
00:44:16,560 --> 00:44:20,940
four developers they haven't made any

983
00:44:17,910 --> 00:44:22,649
recent commits but so I think it's an

984
00:44:20,940 --> 00:44:24,180
area that more work is needed I don't

985
00:44:22,650 --> 00:44:31,440
have good answers for that that's a good

986
00:44:24,180 --> 00:44:34,410
question any other questions I got one

987
00:44:31,440 --> 00:44:35,850
minute so anyway thanks for having me

988
00:44:34,410 --> 00:44:37,379
and I look forward to hearing all the

989
00:44:35,850 --> 00:44:39,330
other talks and you know if you have

990
00:44:37,380 --> 00:44:41,400
comments the things that we shouldn't

991
00:44:39,330 --> 00:44:43,529
put in our masters degree program or

992
00:44:41,400 --> 00:44:47,900
want to be part of it in any way shape

993
00:44:43,530 --> 00:44:47,900
or form let me know so thanks very much

994
00:44:49,330 --> 00:44:53,090
[Applause]

