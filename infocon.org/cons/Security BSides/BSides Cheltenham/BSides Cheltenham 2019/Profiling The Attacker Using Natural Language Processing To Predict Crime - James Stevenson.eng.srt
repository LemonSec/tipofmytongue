1
00:00:04,250 --> 00:00:08,160
so the question we have is what does

2
00:00:08,160 --> 00:00:12,240
Minority Report Black Mirror and 1984

3
00:00:12,240 --> 00:00:19,140
all have in common many ideas yeah so

4
00:00:19,140 --> 00:00:21,119
it's not the fact that they're all forms

5
00:00:21,119 --> 00:00:23,240
of media you know films books TV shows

6
00:00:23,240 --> 00:00:25,439
nor is it the fact that they're all

7
00:00:25,439 --> 00:00:27,150
forms of the Stowe pian future

8
00:00:27,150 --> 00:00:29,249
instead it's the fact that they each

9
00:00:29,249 --> 00:00:31,859
talk about predicting crime in one form

10
00:00:31,859 --> 00:00:34,470
or another whether that's the precogs in

11
00:00:34,470 --> 00:00:36,630
minority reports the Ricola in black

12
00:00:36,630 --> 00:00:40,200
mirror or the fort police in 1984 each

13
00:00:40,200 --> 00:00:42,360
of these forms of media look at how we

14
00:00:42,360 --> 00:00:44,160
could predict crime but more

15
00:00:44,160 --> 00:00:46,890
specifically the repercussions of doing

16
00:00:46,890 --> 00:00:49,500
so and that's all we're gonna be talking

17
00:00:49,500 --> 00:00:51,510
about today we're gonna be talking about

18
00:00:51,510 --> 00:00:52,830
how we can use natural language

19
00:00:52,830 --> 00:00:55,110
processing a form of machine learning to

20
00:00:55,110 --> 00:00:58,470
help us predict crime so for those of

21
00:00:58,470 --> 00:00:58,980
you that know me

22
00:00:58,980 --> 00:01:01,140
we'll know I'm not a mathematician and

23
00:01:01,140 --> 00:01:04,349
I'm also not a police officer so why am

24
00:01:04,349 --> 00:01:05,909
I talking about natural language

25
00:01:05,909 --> 00:01:07,590
processing which is quite mathy and

26
00:01:07,590 --> 00:01:09,719
predictive policing which hasn't only

27
00:01:09,719 --> 00:01:12,329
suggests is all about law and crime and

28
00:01:12,329 --> 00:01:15,479
well it comes down to this quote the

29
00:01:15,479 --> 00:01:17,840
idea that intrusion analysis security

30
00:01:17,840 --> 00:01:20,729
analysis it's about far more than the

31
00:01:20,729 --> 00:01:23,130
tools we use it's about innovating and

32
00:01:23,130 --> 00:01:24,960
looking at new ways that we can protect

33
00:01:24,960 --> 00:01:27,119
ourselves against attacks but also

34
00:01:27,119 --> 00:01:29,600
predict those attacks in the first place

35
00:01:29,600 --> 00:01:31,469
so what are we actually going to be

36
00:01:31,469 --> 00:01:33,329
talking about today well I want to break

37
00:01:33,329 --> 00:01:35,609
it down into three main areas I want to

38
00:01:35,609 --> 00:01:36,929
talk about what predictive policing and

39
00:01:36,929 --> 00:01:39,060
natural language processing actually are

40
00:01:39,060 --> 00:01:40,679
I want to talk about a proof-of-concept

41
00:01:40,679 --> 00:01:43,289
tool I've created that implements these

42
00:01:43,289 --> 00:01:45,990
techniques and then finally I want to

43
00:01:45,990 --> 00:01:47,729
talk about why this tool doesn't

44
00:01:47,729 --> 00:01:49,469
actually work and what we need to be

45
00:01:49,469 --> 00:01:51,689
doing in addition to it if we want to be

46
00:01:51,689 --> 00:01:54,479
predicting cybercrime before I begin

47
00:01:54,479 --> 00:01:55,920
though Who am I well my name is Jim

48
00:01:55,920 --> 00:01:57,600
Stevenson and this time three years ago

49
00:01:57,600 --> 00:01:59,609
now as a student I had the University of

50
00:01:59,609 --> 00:02:01,770
South Wales studying computer security

51
00:02:01,770 --> 00:02:04,079
before that I was Newton little at logic

52
00:02:04,079 --> 00:02:06,359
a cloud security company and these days

53
00:02:06,359 --> 00:02:08,220
I'm a software engineer and security

54
00:02:08,220 --> 00:02:11,189
researcher I'm also currently doing PhD

55
00:02:11,189 --> 00:02:13,349
looking at how we can detect hacktivism

56
00:02:13,349 --> 00:02:14,069
and

57
00:02:14,069 --> 00:02:17,489
terrorism online so jumping straight

58
00:02:17,489 --> 00:02:18,120
into it

59
00:02:18,120 --> 00:02:20,519
what is predictive policing I keep

60
00:02:20,519 --> 00:02:22,739
talking about it but what actually is it

61
00:02:22,739 --> 00:02:24,569
because if we're going to use natural

62
00:02:24,569 --> 00:02:26,639
language processing to predict crime and

63
00:02:26,639 --> 00:02:28,349
we kind of need to know what predictive

64
00:02:28,349 --> 00:02:30,120
policing is in the first place

65
00:02:30,120 --> 00:02:32,639
and predictive policing comes down to

66
00:02:32,639 --> 00:02:34,409
two main areas we have location-based

67
00:02:34,409 --> 00:02:36,359
predictive policing and we have

68
00:02:36,359 --> 00:02:38,000
individual based predictive policing

69
00:02:38,000 --> 00:02:39,900
when it comes to location-based

70
00:02:39,900 --> 00:02:41,730
predictive policing we're looking at an

71
00:02:41,730 --> 00:02:44,549
area we're saying in this area has a

72
00:02:44,549 --> 00:02:49,349
crime is a crime likely to occur so this

73
00:02:49,349 --> 00:02:51,419
is a map of London was in a certain time

74
00:02:51,419 --> 00:02:53,280
period and the colors show where and

75
00:02:53,280 --> 00:02:56,099
when crime is a kid and I stay to like

76
00:02:56,099 --> 00:02:57,120
this that's really useful for

77
00:02:57,120 --> 00:02:59,510
location-based predictive policing

78
00:02:59,510 --> 00:03:01,769
because we can look at this data and say

79
00:03:01,769 --> 00:03:04,379
okay if a crime is a kid under these

80
00:03:04,379 --> 00:03:06,299
specific circumstances in the past

81
00:03:06,299 --> 00:03:09,120
looking that comes likely to occur under

82
00:03:09,120 --> 00:03:11,250
these same circumstances again in the

83
00:03:11,250 --> 00:03:13,409
future now today we're going to be

84
00:03:13,409 --> 00:03:15,510
focusing on individual based predictive

85
00:03:15,510 --> 00:03:17,669
policing now individual base prediction

86
00:03:17,669 --> 00:03:19,650
closing is about looking as an

87
00:03:19,650 --> 00:03:21,569
individual and it's about saying how

88
00:03:21,569 --> 00:03:24,449
likely is this specific individual to

89
00:03:24,449 --> 00:03:27,419
commit a crime and when it comes to

90
00:03:27,419 --> 00:03:28,560
individual based predictive policing

91
00:03:28,560 --> 00:03:30,659
there's a whole array of approaches

92
00:03:30,659 --> 00:03:32,849
various and methodologies that we can

93
00:03:32,849 --> 00:03:35,280
use to help us predict crime and today

94
00:03:35,280 --> 00:03:36,780
we're gonna be focusing on three of

95
00:03:36,780 --> 00:03:38,729
these the first theory that we can be

96
00:03:38,729 --> 00:03:40,979
looking at is called strain theory now

97
00:03:40,979 --> 00:03:43,250
strain theory is the idea that society

98
00:03:43,250 --> 00:03:46,470
puts pressure on individuals to achieve

99
00:03:46,470 --> 00:03:49,169
specific goals like the American dream

100
00:03:49,169 --> 00:03:51,509
but when individuals lack the means to

101
00:03:51,509 --> 00:03:53,849
achieve those goals they're more likely

102
00:03:53,849 --> 00:03:56,400
to commit crime so that they can achieve

103
00:03:56,400 --> 00:03:58,889
them the next very that we're gonna be

104
00:03:58,889 --> 00:04:00,959
looking at is social control theory now

105
00:04:00,959 --> 00:04:02,969
at this very states is it states that

106
00:04:02,969 --> 00:04:03,959
individuals who lack

107
00:04:03,959 --> 00:04:06,180
close relationships commitments values

108
00:04:06,180 --> 00:04:09,060
or norms again are more likely to commit

109
00:04:09,060 --> 00:04:10,859
crime because they don't have those

110
00:04:10,859 --> 00:04:13,979
relationships or values as an anchor in

111
00:04:13,979 --> 00:04:16,560
society and then finally we're gonna be

112
00:04:16,560 --> 00:04:18,630
looking at social disorganization theory

113
00:04:18,630 --> 00:04:20,789
and what this furious States is it's

114
00:04:20,789 --> 00:04:23,760
that location is key if an individual

115
00:04:23,760 --> 00:04:25,710
lives or works in an area known for a

116
00:04:25,710 --> 00:04:27,480
specific type of crime the

117
00:04:27,480 --> 00:04:29,400
theory states that intrinsically we're

118
00:04:29,400 --> 00:04:32,100
just being that more likely to commit

119
00:04:32,100 --> 00:04:35,460
crime so so far we've looked at what

120
00:04:35,460 --> 00:04:37,290
predictive policing is different types

121
00:04:37,290 --> 00:04:39,270
of predictive policing and how we can

122
00:04:39,270 --> 00:04:41,430
use predictive policing approaches to

123
00:04:41,430 --> 00:04:43,890
predict crime but this talk is all about

124
00:04:43,890 --> 00:04:45,900
natural language processing so about how

125
00:04:45,900 --> 00:04:47,100
we can use natural language processing

126
00:04:47,100 --> 00:04:49,310
to do just that

127
00:04:49,310 --> 00:04:52,170
however before we dive into natural

128
00:04:52,170 --> 00:04:53,910
language processing we need to

129
00:04:53,910 --> 00:04:55,950
understand what language is in the first

130
00:04:55,950 --> 00:04:58,310
place and for us as human beings

131
00:04:58,310 --> 00:05:00,570
language comes down into three main

132
00:05:00,570 --> 00:05:03,170
areas speaking reading and writing

133
00:05:03,170 --> 00:05:06,570
things that we will do every day so

134
00:05:06,570 --> 00:05:07,770
because we do these things every day

135
00:05:07,770 --> 00:05:10,320
most of us or maybe some of us will be

136
00:05:10,320 --> 00:05:12,390
able to answer this next question and

137
00:05:12,390 --> 00:05:15,630
that's Paris - France plus England

138
00:05:15,630 --> 00:05:21,500
equals what so don't have any ideas so

139
00:05:21,500 --> 00:05:24,780
the answer is London because Paris is -

140
00:05:24,780 --> 00:05:28,560
France has London is - England no and I

141
00:05:28,560 --> 00:05:32,850
think the laptop has crashed so yeah the

142
00:05:32,850 --> 00:05:35,340
answer is London because Paris is -

143
00:05:35,340 --> 00:05:39,030
France as London is - England so if we

144
00:05:39,030 --> 00:05:39,870
know that was the answer

145
00:05:39,870 --> 00:05:42,450
great but why did we know that that was

146
00:05:42,450 --> 00:05:44,220
the answer well we would have known that

147
00:05:44,220 --> 00:05:45,630
that was the answer because of the

148
00:05:45,630 --> 00:05:47,250
experiences with hat right word read

149
00:05:47,250 --> 00:05:48,450
books we've gone on the internet who

150
00:05:48,450 --> 00:05:50,220
have spoken to people and this is all

151
00:05:50,220 --> 00:05:52,080
built on our knowledge base and our

152
00:05:52,080 --> 00:05:55,890
understanding of the world and so if we

153
00:05:55,890 --> 00:05:57,780
were to feed that question into our

154
00:05:57,780 --> 00:05:59,160
natural language processing machine

155
00:05:59,160 --> 00:06:02,310
would it be able to answer it well yes

156
00:06:02,310 --> 00:06:03,750
but only if we gave it the right

157
00:06:03,750 --> 00:06:05,970
knowledge base so this is the Wikipedia

158
00:06:05,970 --> 00:06:07,950
article for London and if we fed this

159
00:06:07,950 --> 00:06:09,300
into our natural language processing

160
00:06:09,300 --> 00:06:11,370
machine it would learn from the

161
00:06:11,370 --> 00:06:13,590
surrounding context it would learn that

162
00:06:13,590 --> 00:06:15,420
London is a city that London is in the

163
00:06:15,420 --> 00:06:18,450
UK of which England is as well building

164
00:06:18,450 --> 00:06:20,430
on that knowledge base and building on

165
00:06:20,430 --> 00:06:23,550
that understanding and so if that's how

166
00:06:23,550 --> 00:06:25,470
natural language processing works had a

167
00:06:25,470 --> 00:06:28,020
sentiment analysis work because

168
00:06:28,020 --> 00:06:30,150
sentiment analysis is a form of natural

169
00:06:30,150 --> 00:06:32,010
language processing that allows us to

170
00:06:32,010 --> 00:06:34,020
look at a specific piece of text and to

171
00:06:34,020 --> 00:06:35,850
say what is the emotion what is the

172
00:06:35,850 --> 00:06:38,580
sentiment behind that text and again

173
00:06:38,580 --> 00:06:40,800
when it comes to us as human beings

174
00:06:40,800 --> 00:06:42,270
we have eight two main pillars to our

175
00:06:42,270 --> 00:06:44,849
emotions but for sentiment analysis we

176
00:06:44,849 --> 00:06:46,979
really care about to write we care about

177
00:06:46,979 --> 00:06:49,080
positive emotions we care about negative

178
00:06:49,080 --> 00:06:51,479
emotions when it comes to the positive

179
00:06:51,479 --> 00:06:52,650
emotions we're talking about this top

180
00:06:52,650 --> 00:06:54,690
row when it comes to negative emotions

181
00:06:54,690 --> 00:06:56,659
we're talking about this bottom room and

182
00:06:56,659 --> 00:06:59,669
so if these are the emotions that we're

183
00:06:59,669 --> 00:07:00,569
talking about when you're a fit a

184
00:07:00,569 --> 00:07:02,550
sentiment analysis how to actually get

185
00:07:02,550 --> 00:07:05,430
that emotion from text well at a very

186
00:07:05,430 --> 00:07:07,319
high level it's the same as most machine

187
00:07:07,319 --> 00:07:09,360
learning approaches we take a massive

188
00:07:09,360 --> 00:07:11,879
data set for this example let's say it's

189
00:07:11,879 --> 00:07:13,889
of restaurant reviews we break each of

190
00:07:13,889 --> 00:07:15,360
those reviews down into two main

191
00:07:15,360 --> 00:07:18,030
elements the actual review and then the

192
00:07:18,030 --> 00:07:20,849
sentiment of that review for example I

193
00:07:20,849 --> 00:07:22,830
love my local pizza restaurant positive

194
00:07:22,830 --> 00:07:24,960
sentiment or hmm this place has really

195
00:07:24,960 --> 00:07:28,139
gone downhill negative sentiment we then

196
00:07:28,139 --> 00:07:30,300
break that data set down into two we

197
00:07:30,300 --> 00:07:31,979
have our training set and we have our

198
00:07:31,979 --> 00:07:34,289
testing set when it comes to training

199
00:07:34,289 --> 00:07:36,090
our natural language processing machine

200
00:07:36,090 --> 00:07:37,889
we look at the keywords we say what

201
00:07:37,889 --> 00:07:39,509
keywords are more problem with a

202
00:07:39,509 --> 00:07:41,819
positive sentiment and what keywords are

203
00:07:41,819 --> 00:07:44,270
more prominent with negative sentiment

204
00:07:44,270 --> 00:07:46,800
then when it comes to testing we look at

205
00:07:46,800 --> 00:07:48,779
the remaining entities and we ask our

206
00:07:48,779 --> 00:07:50,039
natural language processing machine to

207
00:07:50,039 --> 00:07:52,050
tell us what it thinks the sentiment is

208
00:07:52,050 --> 00:07:54,180
so if that matches the segments we know

209
00:07:54,180 --> 00:07:56,310
them to have great and if it doesn't

210
00:07:56,310 --> 00:07:58,430
mean is that something is going wrong

211
00:07:58,430 --> 00:08:01,319
and so if that's how natural language

212
00:08:01,319 --> 00:08:02,909
processing works if that's how sentiment

213
00:08:02,909 --> 00:08:04,889
analysis works then what already exists

214
00:08:04,889 --> 00:08:06,870
what are some examples of natural

215
00:08:06,870 --> 00:08:08,460
language processing in the real world

216
00:08:08,460 --> 00:08:11,039
well this is AWS comprehend or

217
00:08:11,039 --> 00:08:13,050
specifically comprehend Medical which is

218
00:08:13,050 --> 00:08:14,669
Amazon's approach to natural language

219
00:08:14,669 --> 00:08:16,469
processing when it comes to healthcare

220
00:08:16,469 --> 00:08:18,840
and medicine a doctor or healthcare

221
00:08:18,840 --> 00:08:20,520
professional will type in the patient's

222
00:08:20,520 --> 00:08:23,129
details symptoms information the natural

223
00:08:23,129 --> 00:08:24,840
language processing tool will go off do

224
00:08:24,840 --> 00:08:26,669
its thing and it will come back with key

225
00:08:26,669 --> 00:08:28,379
bits information it thinks that that

226
00:08:28,379 --> 00:08:30,949
healthcare professional news to name

227
00:08:30,949 --> 00:08:34,320
next we have Taylor AI now ta da di was

228
00:08:34,320 --> 00:08:36,208
Microsoft's approach to natural language

229
00:08:36,208 --> 00:08:38,039
processing when it came to a Twitter

230
00:08:38,039 --> 00:08:40,500
chat wat teh would tailor its response

231
00:08:40,500 --> 00:08:42,929
to people depending on how people spoke

232
00:08:42,929 --> 00:08:46,589
to it now it was quite controversial it

233
00:08:46,589 --> 00:08:48,660
lasted just under 24 hours but

234
00:08:48,660 --> 00:08:51,420
nonetheless is a great example and then

235
00:08:51,420 --> 00:08:53,250
finally we have predictive text so

236
00:08:53,250 --> 00:08:54,570
Evernote you're on an Android

237
00:08:54,570 --> 00:08:57,000
or an iPhone or a predictive taxes but

238
00:08:57,000 --> 00:08:59,310
probably working on your device is by

239
00:08:59,310 --> 00:09:01,079
using natural language processing in

240
00:09:01,079 --> 00:09:03,899
some form or another so that we have

241
00:09:03,899 --> 00:09:05,579
free great examples of healthcare

242
00:09:05,579 --> 00:09:08,610
communications and mobile phones but

243
00:09:08,610 --> 00:09:10,199
none of those examples look at how we

244
00:09:10,199 --> 00:09:12,240
could use natural language processing to

245
00:09:12,240 --> 00:09:14,459
predict crime which is what this talk is

246
00:09:14,459 --> 00:09:17,910
all about so this is Alice and it's

247
00:09:17,910 --> 00:09:19,440
Alice's job to do just that

248
00:09:19,440 --> 00:09:22,410
it's Alice's job to predict crime the

249
00:09:22,410 --> 00:09:23,819
way that Alice currently does this is

250
00:09:23,819 --> 00:09:25,889
she individually and manually goes to

251
00:09:25,889 --> 00:09:27,870
different web sites chat forums social

252
00:09:27,870 --> 00:09:30,420
media accounts and she profiles specific

253
00:09:30,420 --> 00:09:32,399
individuals on their likelihood of

254
00:09:32,399 --> 00:09:34,980
committing crime the problem with this

255
00:09:34,980 --> 00:09:37,649
is that it's slow and laborious so how

256
00:09:37,649 --> 00:09:39,899
can we take this to the next level well

257
00:09:39,899 --> 00:09:41,819
we can automate it we can scrape these

258
00:09:41,819 --> 00:09:43,410
websites for specific information on

259
00:09:43,410 --> 00:09:45,660
specific individuals apply our natural

260
00:09:45,660 --> 00:09:47,670
language processing techniques and then

261
00:09:47,670 --> 00:09:49,709
retain to Alice a risk a score a

262
00:09:49,709 --> 00:09:52,110
likelihood of how likely these specific

263
00:09:52,110 --> 00:09:54,300
individuals are to commit a crime and

264
00:09:54,300 --> 00:09:56,490
then how a sinner team can action those

265
00:09:56,490 --> 00:10:00,480
individuals accordingly so if we were to

266
00:10:00,480 --> 00:10:02,339
build a framework like this what would

267
00:10:02,339 --> 00:10:04,680
it look like well first of all Alice in

268
00:10:04,680 --> 00:10:06,149
a tea will need to sit down and look at

269
00:10:06,149 --> 00:10:08,040
each of these individuals and decide on

270
00:10:08,040 --> 00:10:10,290
the impact if this individual was to

271
00:10:10,290 --> 00:10:12,269
commit this crime or was to perform this

272
00:10:12,269 --> 00:10:15,240
attack what would the impact be and this

273
00:10:15,240 --> 00:10:16,290
really comes down to those three main

274
00:10:16,290 --> 00:10:17,790
areas the lots of confidentiality

275
00:10:17,790 --> 00:10:20,910
integrity and availability once we have

276
00:10:20,910 --> 00:10:22,529
an impact we need to work out our

277
00:10:22,529 --> 00:10:24,839
likelihood what is the likelihood of

278
00:10:24,839 --> 00:10:26,730
this individual committing this crime or

279
00:10:26,730 --> 00:10:28,860
performing this attack and this is where

280
00:10:28,860 --> 00:10:30,449
we look back at those predictive

281
00:10:30,449 --> 00:10:32,430
policing approaches that we mentioned

282
00:10:32,430 --> 00:10:35,160
earlier on we script these websites for

283
00:10:35,160 --> 00:10:36,630
text relating to a specific individual

284
00:10:36,630 --> 00:10:38,310
we apply our natural language processing

285
00:10:38,310 --> 00:10:40,680
techniques and then first of all we say

286
00:10:40,680 --> 00:10:43,350
does this tax contain reference 20 goals

287
00:10:43,350 --> 00:10:46,350
or aspirations and if so what is the

288
00:10:46,350 --> 00:10:48,600
sentiment next we take that same bit of

289
00:10:48,600 --> 00:10:50,699
text but now we say does this text

290
00:10:50,699 --> 00:10:52,079
container efference to any close

291
00:10:52,079 --> 00:10:54,389
relationships any individuals any groups

292
00:10:54,389 --> 00:10:57,449
any organizations and if so what is the

293
00:10:57,449 --> 00:10:59,579
sentiment and then finally we take that

294
00:10:59,579 --> 00:11:01,470
same bit of text but now we say does

295
00:11:01,470 --> 00:11:03,209
that text container efference to the

296
00:11:03,209 --> 00:11:05,310
individuals location if so is the

297
00:11:05,310 --> 00:11:06,660
location known for this type of crime

298
00:11:06,660 --> 00:11:09,410
and finally what is this

299
00:11:09,410 --> 00:11:11,370
we think of for each of these layers

300
00:11:11,370 --> 00:11:14,370
aggregating a score as we go and that

301
00:11:14,370 --> 00:11:16,110
score defines the overall likelihood or

302
00:11:16,110 --> 00:11:18,300
that specific individual committing a

303
00:11:18,300 --> 00:11:20,940
crime now that we have our likelihood

304
00:11:20,940 --> 00:11:23,070
and our impact we can wait out our

305
00:11:23,070 --> 00:11:25,230
overall risk the overall risk of the

306
00:11:25,230 --> 00:11:27,690
specific individual poses to Alice and

307
00:11:27,690 --> 00:11:31,080
her team so as I'm saying earlier I've

308
00:11:31,080 --> 00:11:32,580
created a proof of concept particular

309
00:11:32,580 --> 00:11:34,230
prove a concept that implements all the

310
00:11:34,230 --> 00:11:36,420
techniques we've mentioned up to now

311
00:11:36,420 --> 00:11:38,070
it's called hunch and it's available on

312
00:11:38,070 --> 00:11:40,080
github as I said it implements

313
00:11:40,080 --> 00:11:41,880
everything we've mentioned so it

314
00:11:41,880 --> 00:11:43,380
collects information from sources like

315
00:11:43,380 --> 00:11:45,780
Twitter Instagram and reddit it applies

316
00:11:45,780 --> 00:11:47,340
natural language processing techniques

317
00:11:47,340 --> 00:11:50,010
using AWS comprehend and then finally it

318
00:11:50,010 --> 00:11:52,940
does that predictive policing analysis

319
00:11:52,940 --> 00:11:55,500
there is one small problem with

320
00:11:55,500 --> 00:12:00,420
hunched-over unless it doesn't work in

321
00:12:00,420 --> 00:12:02,040
other way for a few reasons but

322
00:12:02,040 --> 00:12:04,080
primarily it comes down to the fact that

323
00:12:04,080 --> 00:12:06,300
it makes so many assumptions it assumes

324
00:12:06,300 --> 00:12:08,100
that if you live in these areas if you

325
00:12:08,100 --> 00:12:09,450
speak to these people if you say these

326
00:12:09,450 --> 00:12:11,400
things then you're likely to commit

327
00:12:11,400 --> 00:12:13,320
crime and that's just not true is it the

328
00:12:13,320 --> 00:12:16,590
world isn't as cut and dry as that so if

329
00:12:16,590 --> 00:12:19,620
the goal is still to predict online

330
00:12:19,620 --> 00:12:21,660
cybercrime what else could we be doing

331
00:12:21,660 --> 00:12:23,760
what additional techniques could be

332
00:12:23,760 --> 00:12:27,090
putting into place for this skull well

333
00:12:27,090 --> 00:12:28,680
we can be taking inspiration from other

334
00:12:28,680 --> 00:12:30,630
detection techniques things like

335
00:12:30,630 --> 00:12:33,030
radicalization detection deceitful text

336
00:12:33,030 --> 00:12:35,490
detection hate speech detection we can

337
00:12:35,490 --> 00:12:37,050
take inspiration from these areas and

338
00:12:37,050 --> 00:12:40,680
apply them to predicting cybercrime so

339
00:12:40,680 --> 00:12:41,520
what are some of these techniques look

340
00:12:41,520 --> 00:12:43,620
like well at a high level when it comes

341
00:12:43,620 --> 00:12:45,480
to radicalization detection we can use

342
00:12:45,480 --> 00:12:46,320
something called link based

343
00:12:46,320 --> 00:12:48,330
bootstrapping the way that this works is

344
00:12:48,330 --> 00:12:50,130
it takes some seed data may be a

345
00:12:50,130 --> 00:12:52,560
radicalized foreign facebook page or

346
00:12:52,560 --> 00:12:54,660
you-tube video and it then spiders off

347
00:12:54,660 --> 00:12:57,690
that content using hyperlinks or social

348
00:12:57,690 --> 00:12:59,700
connections building a network of

349
00:12:59,700 --> 00:13:02,340
radicalized content the assumption being

350
00:13:02,340 --> 00:13:04,500
that radicalized content will link to

351
00:13:04,500 --> 00:13:07,800
other radicalized content when it comes

352
00:13:07,800 --> 00:13:09,600
to deceptive text detection that seems

353
00:13:09,600 --> 00:13:11,670
like fraud and phishing we're looking at

354
00:13:11,670 --> 00:13:13,830
linguistic features so we're saying how

355
00:13:13,830 --> 00:13:15,930
long is this piece of text how many

356
00:13:15,930 --> 00:13:17,700
words on average range sentence and what

357
00:13:17,700 --> 00:13:19,980
tense is it written in this information

358
00:13:19,980 --> 00:13:21,990
allowing us to build profiles

359
00:13:21,990 --> 00:13:23,360
are there specific types of people

360
00:13:23,360 --> 00:13:26,490
performing this type of crime and then

361
00:13:26,490 --> 00:13:27,450
finally when it comes to hate speech

362
00:13:27,450 --> 00:13:29,279
detection we're looking at things like

363
00:13:29,279 --> 00:13:31,620
uttering language are we they and us

364
00:13:31,620 --> 00:13:34,020
then terminology we're looking at things

365
00:13:34,020 --> 00:13:35,670
like sentiment analysis because

366
00:13:35,670 --> 00:13:36,630
generally hate speech will have a

367
00:13:36,630 --> 00:13:40,110
negative sentiment and again here we

368
00:13:40,110 --> 00:13:42,120
have three great examples of detection

369
00:13:42,120 --> 00:13:44,850
techniques used detection techniques

370
00:13:44,850 --> 00:13:46,950
that we can be implementing in detecting

371
00:13:46,950 --> 00:13:49,800
cyber crime online and as I said I'm

372
00:13:49,800 --> 00:13:51,300
currently well it just started to prefer

373
00:13:51,300 --> 00:13:54,720
the PhD that looks at detecting activism

374
00:13:54,720 --> 00:13:57,899
and cyber terrorism online and the

375
00:13:57,899 --> 00:13:59,130
research that that's doing is it's

376
00:13:59,130 --> 00:14:01,200
moving away from this catch-all it's

377
00:14:01,200 --> 00:14:02,850
moving away from this generic let's

378
00:14:02,850 --> 00:14:05,670
detect crime and it's moving mortals how

379
00:14:05,670 --> 00:14:08,070
do we detect specific types of crime how

380
00:14:08,070 --> 00:14:09,720
do we detect activism how do we detect

381
00:14:09,720 --> 00:14:11,880
cyber terrorism and how do we detect

382
00:14:11,880 --> 00:14:15,120
these nuanced approaches instead however

383
00:14:15,120 --> 00:14:16,740
at this stage in the talk coming towards

384
00:14:16,740 --> 00:14:18,630
its end you might still be thinking well

385
00:14:18,630 --> 00:14:20,430
things this is this is great and all but

386
00:14:20,430 --> 00:14:22,740
why are we talking about predictive

387
00:14:22,740 --> 00:14:24,209
policing and it can be the security

388
00:14:24,209 --> 00:14:26,820
confidence and well it comes back to

389
00:14:26,820 --> 00:14:28,649
this quote the idea that intrusion

390
00:14:28,649 --> 00:14:32,010
analysis security analysis is about far

391
00:14:32,010 --> 00:14:33,959
more than the tools we use right it's

392
00:14:33,959 --> 00:14:36,029
about innovating but it's also about

393
00:14:36,029 --> 00:14:38,339
thinking outside the box and looking at

394
00:14:38,339 --> 00:14:39,480
new ways that we can protect ourselves

395
00:14:39,480 --> 00:14:42,149
against the tanks but also predict those

396
00:14:42,149 --> 00:14:45,300
attacks in the first place so that is

397
00:14:45,300 --> 00:14:46,380
the toe cracking up if you've any

398
00:14:46,380 --> 00:14:48,120
questions feel free to ask me now come

399
00:14:48,120 --> 00:14:49,529
find me afterwards I'm also on Twitter

400
00:14:49,529 --> 00:14:51,690
and underscore James Stevenson once

401
00:14:51,690 --> 00:14:52,920
again thanks all for coming along and

402
00:14:52,920 --> 00:14:55,360
thank you for organizing that me thanks

403
00:14:55,360 --> 00:14:59,190
[Applause]

404
00:15:02,279 --> 00:15:10,529
all right any questions and say ya know

405
00:15:14,590 --> 00:15:17,669
[Music]

406
00:15:22,800 --> 00:15:37,149
like native language yeah yeah okay yeah

407
00:15:37,149 --> 00:15:38,889
so I used to have this slide where I

408
00:15:38,889 --> 00:15:40,000
used to go through some cogent Eric

409
00:15:40,000 --> 00:15:41,620
questions to ask and that kind of falls

410
00:15:41,620 --> 00:15:44,500
into the bias question and what I always

411
00:15:44,500 --> 00:15:46,209
used to say for that is I used to say

412
00:15:46,209 --> 00:15:48,850
that really these tools shouldn't be a

413
00:15:48,850 --> 00:15:50,680
hundred percent automated right these

414
00:15:50,680 --> 00:15:52,230
tools should always have a human being

415
00:15:52,230 --> 00:15:55,260
supporting them so in in that regard

416
00:15:55,260 --> 00:15:57,750
you're having kind of a human person

417
00:15:57,750 --> 00:16:00,339
that is using that content that is

418
00:16:00,339 --> 00:16:03,220
training that content so that should be

419
00:16:03,220 --> 00:16:06,160
able to support any biases or kind of

420
00:16:06,160 --> 00:16:44,709
terminology used any questions okay so

421
00:16:44,709 --> 00:16:47,050
the question is kind of both machines

422
00:16:47,050 --> 00:16:48,730
and humans are gonna have a bias how

423
00:16:48,730 --> 00:16:51,579
would you account for that yeah well I

424
00:16:51,579 --> 00:16:53,680
think I think you can't right I think it

425
00:16:53,680 --> 00:16:54,699
was the talk this morning that said

426
00:16:54,699 --> 00:16:56,620
everyone has bias and it comes down to

427
00:16:56,620 --> 00:16:59,230
managing that bias I don't think we're

428
00:16:59,230 --> 00:17:00,519
gonna completely get rid of bias as a

429
00:17:00,519 --> 00:17:02,260
whole pretty comes down to again

430
00:17:02,260 --> 00:17:03,069
managing it

431
00:17:03,069 --> 00:17:04,839
great any questions

432
00:17:04,839 --> 00:17:08,029
[Music]

433
00:17:14,049 --> 00:17:22,069
what years old fish is awfully like what

434
00:17:22,069 --> 00:17:26,709
the model there it's making precision

435
00:17:30,190 --> 00:17:33,230
how to use from a human point

436
00:17:33,230 --> 00:17:39,650
controlling this thing hmm yeah so he

437
00:17:39,650 --> 00:17:43,549
loaded up yeah something comes out yeah

438
00:17:43,549 --> 00:17:44,299
okay

439
00:17:44,299 --> 00:17:46,039
yes it's okay the question is kind of

440
00:17:46,039 --> 00:17:47,809
how'd you manage the data in the data

441
00:17:47,809 --> 00:17:50,659
out that kind of stuff so what I used to

442
00:17:50,659 --> 00:17:53,360
say with this I used to say this is

443
00:17:53,360 --> 00:17:55,280
super bias right superb eyes for a few

444
00:17:55,280 --> 00:17:57,860
reasons but primarily because it's

445
00:17:57,860 --> 00:17:59,750
garbage in garbage out right if we give

446
00:17:59,750 --> 00:18:02,360
it bias data the framework is going to

447
00:18:02,360 --> 00:18:04,909
be bias the second reason why it's

448
00:18:04,909 --> 00:18:06,289
biased again I think it you mention is

449
00:18:06,289 --> 00:18:07,429
because it's made by human beings and

450
00:18:07,429 --> 00:18:09,679
human beings are intrinsically bias so

451
00:18:09,679 --> 00:18:11,510
the frameworks we create are going to be

452
00:18:11,510 --> 00:18:13,549
biased as well and I think it's going to

453
00:18:13,549 --> 00:18:16,010
be the same responses it's if we know

454
00:18:16,010 --> 00:18:17,000
it's going to be biased we know it's

455
00:18:17,000 --> 00:18:18,620
going to be biased off the offset then

456
00:18:18,620 --> 00:18:20,659
we need to manage that and it's ok what

457
00:18:20,659 --> 00:18:22,789
will these biases that could be created

458
00:18:22,789 --> 00:18:24,770
okay well let's bear those in mind with

459
00:18:24,770 --> 00:18:28,270
the outputs we have great any questions

460
00:18:28,270 --> 00:18:31,130
great thanks

461
00:18:31,130 --> 00:18:34,299
[Applause]

