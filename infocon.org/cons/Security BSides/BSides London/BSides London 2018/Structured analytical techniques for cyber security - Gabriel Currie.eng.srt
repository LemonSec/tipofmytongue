1
00:00:00,410 --> 00:00:05,069
okay hi everyone thanks very much for

2
00:00:02,790 --> 00:00:07,350
coming on so as mentioned my name is

3
00:00:05,069 --> 00:00:09,240
Gabriel curry I work for PwC in the

4
00:00:07,350 --> 00:00:11,219
cyber internal response team and I'm

5
00:00:09,240 --> 00:00:12,719
here to give you a brief rundown of some

6
00:00:11,219 --> 00:00:14,849
structured analytical techniques for

7
00:00:12,719 --> 00:00:16,259
cyber security so he structured

8
00:00:14,849 --> 00:00:17,910
analytical techniques or something it's

9
00:00:16,260 --> 00:00:19,890
relatively commonplace in there in the

10
00:00:17,910 --> 00:00:21,539
intelligence community as a whole and

11
00:00:19,890 --> 00:00:22,650
it's something that's kind of coming to

12
00:00:21,539 --> 00:00:25,619
prominence in the cyber threat

13
00:00:22,650 --> 00:00:27,150
intelligence community and as kind of it

14
00:00:25,619 --> 00:00:28,619
matures a little bit and what I'm hoping

15
00:00:27,150 --> 00:00:30,330
to do is give you a little bit of some

16
00:00:28,619 --> 00:00:33,210
of my experience of applying some of

17
00:00:30,330 --> 00:00:34,890
these techniques and in cyber threat

18
00:00:33,210 --> 00:00:37,110
intelligence in Incident Response and

19
00:00:34,890 --> 00:00:39,660
hopefully giving you the tools to walk

20
00:00:37,110 --> 00:00:42,180
away and do the same so first of all

21
00:00:39,660 --> 00:00:43,919
like why do we actually want to use

22
00:00:42,180 --> 00:00:45,809
structured analytical techniques what's

23
00:00:43,920 --> 00:00:47,280
the point so the idea is that when we're

24
00:00:45,809 --> 00:00:49,440
doing any kind of analysis there's

25
00:00:47,280 --> 00:00:52,140
always some level of bias in there and

26
00:00:49,440 --> 00:00:54,059
and we call these generally like

27
00:00:52,140 --> 00:00:56,010
cognitive biases so as it says on the

28
00:00:54,059 --> 00:00:58,289
slide a cognitive bias is a mistake in

29
00:00:56,010 --> 00:01:00,089
reasoning or analysis often as a result

30
00:00:58,289 --> 00:01:02,250
of an analysts personal experiences or

31
00:01:00,090 --> 00:01:04,799
beliefs it's basically the point is that

32
00:01:02,250 --> 00:01:06,210
when I do some form of analysis that's

33
00:01:04,799 --> 00:01:07,799
always going to be colored by my own

34
00:01:06,210 --> 00:01:08,939
personal experiences and the way that

35
00:01:07,799 --> 00:01:10,950
I've approached the world in the past

36
00:01:08,939 --> 00:01:12,750
and the way the world has been to me and

37
00:01:10,950 --> 00:01:14,790
so if another person was going to go

38
00:01:12,750 --> 00:01:16,350
away and do that and our system so they

39
00:01:14,790 --> 00:01:19,229
might come up with an entirely separate

40
00:01:16,350 --> 00:01:20,640
separate conclusion because they've got

41
00:01:19,229 --> 00:01:22,500
different experiences and the world has

42
00:01:20,640 --> 00:01:23,909
treated them in a different way and so

43
00:01:22,500 --> 00:01:25,560
there are some examples of some common

44
00:01:23,909 --> 00:01:27,810
perceptual and cognitive biases there I

45
00:01:25,560 --> 00:01:31,290
won't run through them today and but you

46
00:01:27,810 --> 00:01:32,700
can review them later so what we want to

47
00:01:31,290 --> 00:01:34,619
do is try and fix the problem of

48
00:01:32,700 --> 00:01:36,360
cognitive bias and I'm going to talk

49
00:01:34,619 --> 00:01:38,280
through kind of two broad ways that we

50
00:01:36,360 --> 00:01:40,049
can do that so the first of those is

51
00:01:38,280 --> 00:01:41,640
using analytical frameworks so we want

52
00:01:40,049 --> 00:01:43,920
to properly think through the exam

53
00:01:41,640 --> 00:01:45,420
question so try and remove some of those

54
00:01:43,920 --> 00:01:47,490
cognitive biases when we're actually

55
00:01:45,420 --> 00:01:49,860
performing our analysis and coming to an

56
00:01:47,490 --> 00:01:51,240
assessment and then second of all once

57
00:01:49,860 --> 00:01:52,799
we've come to that assessment what we

58
00:01:51,240 --> 00:01:54,329
want to do is be able to clearly

59
00:01:52,799 --> 00:01:56,880
communicate the answers that we've come

60
00:01:54,329 --> 00:01:58,979
up with our assessments in a way that

61
00:01:56,880 --> 00:02:00,179
means the same to me as it means to you

62
00:01:58,979 --> 00:02:03,960
and so that's when we use something

63
00:02:00,180 --> 00:02:05,969
called estimate of language so diving

64
00:02:03,960 --> 00:02:07,350
straight into kind of the first area

65
00:02:05,969 --> 00:02:10,649
that we're going to look at analytical

66
00:02:07,350 --> 00:02:11,910
frameworks so these are relatively

67
00:02:10,649 --> 00:02:13,370
commonplace and some of you might have

68
00:02:11,910 --> 00:02:15,140
come across these in your

69
00:02:13,370 --> 00:02:17,780
it's privacy so perhaps the most basic

70
00:02:15,140 --> 00:02:19,549
example is the is the SWOT analysis

71
00:02:17,780 --> 00:02:22,040
strengths weaknesses opportunities and

72
00:02:19,550 --> 00:02:23,390
threats so want to go through all of

73
00:02:22,040 --> 00:02:24,769
these examples what I'm going to do is

74
00:02:23,390 --> 00:02:26,299
think about how we've related them in

75
00:02:24,769 --> 00:02:28,610
the past to cyber threat intelligence or

76
00:02:26,300 --> 00:02:30,379
or thinking about threat actors so for

77
00:02:28,610 --> 00:02:32,480
example we've used SWOT analyses to try

78
00:02:30,379 --> 00:02:34,700
and to try and prompt us to kind of

79
00:02:32,480 --> 00:02:36,048
critically evaluate a threat actor to

80
00:02:34,700 --> 00:02:37,458
think about you you know what are they

81
00:02:36,049 --> 00:02:38,900
good at what are they bad at and for

82
00:02:37,459 --> 00:02:40,040
them you know and the environment that

83
00:02:38,900 --> 00:02:42,080
surround them what are the opportunities

84
00:02:40,040 --> 00:02:43,489
that they have on what are the threats

85
00:02:42,080 --> 00:02:44,239
that are out there for them and that's

86
00:02:43,489 --> 00:02:46,370
something that's relatively

87
00:02:44,239 --> 00:02:48,140
well-established in business the other

88
00:02:46,370 --> 00:02:49,430
one is called a stemple's analysis you

89
00:02:48,140 --> 00:02:51,828
might have seen this come across in

90
00:02:49,430 --> 00:02:52,970
stuff like and so you might have also

91
00:02:51,829 --> 00:02:55,400
seen it referred to something like

92
00:02:52,970 --> 00:02:57,319
pestle which is more widely used in

93
00:02:55,400 --> 00:02:58,670
business stempel's just takes the same

94
00:02:57,319 --> 00:03:01,069
thing and just adds a couple of letters

95
00:02:58,670 --> 00:03:03,708
on and effectively that's a framework

96
00:03:01,069 --> 00:03:05,569
for considering how an environment might

97
00:03:03,709 --> 00:03:08,900
affect your threat actor or might affect

98
00:03:05,569 --> 00:03:10,670
something so you might want to consider

99
00:03:08,900 --> 00:03:12,470
based on what we know about a threat

100
00:03:10,670 --> 00:03:14,000
actor how is that how are the various

101
00:03:12,470 --> 00:03:15,980
elements of the environment can affect

102
00:03:14,000 --> 00:03:17,870
them or if we don't know anything about

103
00:03:15,980 --> 00:03:19,310
a threat actor how might the environment

104
00:03:17,870 --> 00:03:21,350
mean that they were going to behave so

105
00:03:19,310 --> 00:03:22,940
it's just just a way to kind of prompt

106
00:03:21,350 --> 00:03:24,138
us to think about think about the

107
00:03:22,940 --> 00:03:26,510
question and think about threat up

108
00:03:24,139 --> 00:03:27,859
during a reasoned way the one that I'm

109
00:03:26,510 --> 00:03:31,099
going to focus on for next couple of

110
00:03:27,859 --> 00:03:33,019
minutes is more more deeply around

111
00:03:31,099 --> 00:03:36,410
actually kind of analyzing threat actor

112
00:03:33,019 --> 00:03:38,569
capability and so it kind of becomes

113
00:03:36,410 --> 00:03:41,180
useful to think about this in just kind

114
00:03:38,569 --> 00:03:43,060
of an easy way right guns and tanks and

115
00:03:41,180 --> 00:03:46,579
whatever in traditional military

116
00:03:43,060 --> 00:03:47,329
intelligence analysis so on the side

117
00:03:46,579 --> 00:03:49,370
we've got a tank

118
00:03:47,329 --> 00:03:52,700
it's a t-34 tank from the Soviet Union

119
00:03:49,370 --> 00:03:54,919
and the point is that when we're

120
00:03:52,700 --> 00:03:57,589
analyzing this tank the threat that that

121
00:03:54,919 --> 00:03:59,060
tank poses to us the threat out there is

122
00:03:57,590 --> 00:04:00,889
more than just the weapons that are on

123
00:03:59,060 --> 00:04:02,239
that tank there's a load of other things

124
00:04:00,889 --> 00:04:03,799
that we need to think about when we're

125
00:04:02,239 --> 00:04:06,650
trying to analyze the capability of that

126
00:04:03,799 --> 00:04:07,880
tank cards so some of the other things

127
00:04:06,650 --> 00:04:09,739
that you might want to think about is

128
00:04:07,880 --> 00:04:12,049
well you know what's the current morale

129
00:04:09,739 --> 00:04:12,829
of the crew like you know people need to

130
00:04:12,049 --> 00:04:14,780
run that tank

131
00:04:12,829 --> 00:04:16,910
what's the organizational hierarchy of

132
00:04:14,780 --> 00:04:18,680
that vehicle and the crew and where does

133
00:04:16,910 --> 00:04:20,329
it fit within the wider kind of army

134
00:04:18,680 --> 00:04:21,709
where does it get its orders from how

135
00:04:20,329 --> 00:04:23,810
does it make decisions when it doesn't

136
00:04:21,709 --> 00:04:26,120
have orders where is the fuel how does

137
00:04:23,810 --> 00:04:26,680
it kind of maintain itself is it well is

138
00:04:26,120 --> 00:04:28,150
it

139
00:04:26,680 --> 00:04:29,800
well essentially exception there's all

140
00:04:28,150 --> 00:04:31,599
those different kind of questions which

141
00:04:29,800 --> 00:04:34,150
are more which allow us to evaluate the

142
00:04:31,600 --> 00:04:35,590
threat of that tank poses by thinking

143
00:04:34,150 --> 00:04:38,440
about more than just the gun that it

144
00:04:35,590 --> 00:04:39,758
might have on it so we can take exactly

145
00:04:38,440 --> 00:04:42,180
the same principle and we can apply that

146
00:04:39,759 --> 00:04:44,800
to kind of cyber threat intelligence so

147
00:04:42,180 --> 00:04:47,130
normally we might look at some we might

148
00:04:44,800 --> 00:04:49,509
look at malware from a threat actor and

149
00:04:47,130 --> 00:04:51,070
you know the nature of the threat that

150
00:04:49,509 --> 00:04:52,539
that malware poses to us as an

151
00:04:51,070 --> 00:04:54,370
organization is more than just the

152
00:04:52,539 --> 00:04:56,979
threat of that malware itself so this is

153
00:04:54,370 --> 00:04:58,389
in effect the weapon right so there are

154
00:04:56,979 --> 00:05:02,110
loads of other things that we might want

155
00:04:58,389 --> 00:05:03,490
to think about so returning to the tank

156
00:05:02,110 --> 00:05:05,289
and returning to our analytical

157
00:05:03,490 --> 00:05:08,470
frameworks one of the frameworks that we

158
00:05:05,289 --> 00:05:10,330
can borrow out there is called the tepid

159
00:05:08,470 --> 00:05:12,099
oil framework or the defense lines of

160
00:05:10,330 --> 00:05:14,560
development and effectively this is a

161
00:05:12,099 --> 00:05:16,690
way that the administrative Ministry of

162
00:05:14,560 --> 00:05:19,570
Defense users to think about threats or

163
00:05:16,690 --> 00:05:21,099
to think about capability and what it

164
00:05:19,570 --> 00:05:22,659
encourages you to do is just like in

165
00:05:21,099 --> 00:05:24,130
stempel's to go through a structured

166
00:05:22,660 --> 00:05:26,080
list of all the different things that we

167
00:05:24,130 --> 00:05:27,669
might want to consider but the problem

168
00:05:26,080 --> 00:05:29,830
with that list is that when we're

169
00:05:27,669 --> 00:05:31,120
looking at a tank that's kind of all

170
00:05:29,830 --> 00:05:32,260
makes sense right we're talking about

171
00:05:31,120 --> 00:05:33,880
armies when we're talking about war

172
00:05:32,260 --> 00:05:35,500
we're talking about malware

173
00:05:33,880 --> 00:05:37,570
perhaps doesn't quite make as much sense

174
00:05:35,500 --> 00:05:40,389
so what we need to do is change it

175
00:05:37,570 --> 00:05:42,639
around a little bit so I had a go at you

176
00:05:40,389 --> 00:05:44,820
know trying to still keep Shepherd oil

177
00:05:42,639 --> 00:05:47,289
which is hotter than you might think and

178
00:05:44,820 --> 00:05:49,810
trying to kind of make it so that it

179
00:05:47,289 --> 00:05:52,510
actually fits to the to the cyber domain

180
00:05:49,810 --> 00:05:54,070
so a lot of those are similar but some

181
00:05:52,510 --> 00:05:55,210
of those might be slightly different and

182
00:05:54,070 --> 00:05:56,979
you can think about how all of those

183
00:05:55,210 --> 00:05:59,198
different elements might be applied into

184
00:05:56,979 --> 00:06:00,940
the cyber domain and how they might kind

185
00:05:59,199 --> 00:06:03,159
of prompt you to think about all of the

186
00:06:00,940 --> 00:06:04,750
different aspects of a threat actor and

187
00:06:03,159 --> 00:06:07,810
the impact that that threat might have

188
00:06:04,750 --> 00:06:10,090
on you so that's that's the end of our

189
00:06:07,810 --> 00:06:11,740
really quick run through my analytical

190
00:06:10,090 --> 00:06:13,508
frameworks so next we're going to look

191
00:06:11,740 --> 00:06:15,130
at the second question which is all

192
00:06:13,509 --> 00:06:17,380
around understanding and communicating

193
00:06:15,130 --> 00:06:18,969
uncertainty so I've come up with some

194
00:06:17,380 --> 00:06:20,229
assessments around my thrill actor I've

195
00:06:18,970 --> 00:06:21,789
come up with some ideas about how I

196
00:06:20,229 --> 00:06:23,770
think they might operate and how I think

197
00:06:21,789 --> 00:06:25,560
they might work and what I want to do

198
00:06:23,770 --> 00:06:28,719
now is tell everyone about my

199
00:06:25,560 --> 00:06:30,190
assessments that I've made so the

200
00:06:28,720 --> 00:06:33,220
problem is that when I say something

201
00:06:30,190 --> 00:06:34,659
about my assessment that might mean a

202
00:06:33,220 --> 00:06:37,270
very different thing to you than it

203
00:06:34,659 --> 00:06:39,099
means to me so this is an example of a

204
00:06:37,270 --> 00:06:40,030
study that CIA did a couple of years ago

205
00:06:39,099 --> 00:06:43,090
well

206
00:06:40,030 --> 00:06:45,070
sixty years ago and effectively what

207
00:06:43,090 --> 00:06:47,590
they did was take took a load of terms

208
00:06:45,070 --> 00:06:49,630
so almost certainly highly likely very

209
00:06:47,590 --> 00:06:52,000
good chance etcetera etcetera and they

210
00:06:49,630 --> 00:06:55,330
asked a load of people what percentage

211
00:06:52,000 --> 00:06:58,810
likelihood those those terms referred to

212
00:06:55,330 --> 00:07:01,510
so you can see that in the example of

213
00:06:58,810 --> 00:07:04,750
probable some people thought that meant

214
00:07:01,510 --> 00:07:08,080
a 25% likelihood that that thing was

215
00:07:04,750 --> 00:07:10,240
correct whereas to others that meant 90%

216
00:07:08,080 --> 00:07:11,740
as that's a really broad range of thing

217
00:07:10,240 --> 00:07:13,060
so when I've made an assessment I'm

218
00:07:11,740 --> 00:07:14,890
trying to communicate that to someone

219
00:07:13,060 --> 00:07:16,780
what that means is that if I say

220
00:07:14,890 --> 00:07:19,719
something's probable and I mean that

221
00:07:16,780 --> 00:07:21,969
that is 90% likely they might think that

222
00:07:19,720 --> 00:07:24,400
that means it's 25% likely and that's

223
00:07:21,970 --> 00:07:25,750
obviously a real issue and that those

224
00:07:24,400 --> 00:07:27,909
kind of issues are kind of cropped up

225
00:07:25,750 --> 00:07:31,300
all you know all throughout history so

226
00:07:27,910 --> 00:07:33,850
look at 2003 and the dodgy dossier from

227
00:07:31,300 --> 00:07:36,160
tony blair that was used to kind of

228
00:07:33,850 --> 00:07:37,630
justify the invasion of iraq and that

229
00:07:36,160 --> 00:07:39,760
perhaps didn't have great intelligence

230
00:07:37,630 --> 00:07:41,560
analysis behind it and perhaps that

231
00:07:39,760 --> 00:07:42,940
didn't understand and communicate the

232
00:07:41,560 --> 00:07:46,240
uncertainty that was behind those

233
00:07:42,940 --> 00:07:48,010
assessments very effectively so the way

234
00:07:46,240 --> 00:07:49,900
that we can fix that is by actually

235
00:07:48,010 --> 00:07:52,180
being really clear about what we mean

236
00:07:49,900 --> 00:07:55,570
when we're when we're expressing that

237
00:07:52,180 --> 00:07:58,140
level of uncertainty so this is the this

238
00:07:55,570 --> 00:08:00,370
is the framework that we use at pwc and

239
00:07:58,140 --> 00:08:02,020
we try and incorporate into all of our

240
00:08:00,370 --> 00:08:04,390
reporting where there's some some degree

241
00:08:02,020 --> 00:08:07,659
of assessment so what we do is we make

242
00:08:04,390 --> 00:08:10,210
clear for every single term that we use

243
00:08:07,660 --> 00:08:12,700
what are the what are the probability

244
00:08:10,210 --> 00:08:14,620
ranges that that refers to so highly

245
00:08:12,700 --> 00:08:16,630
unlikely means it's between zero and ten

246
00:08:14,620 --> 00:08:19,300
percent unlikely between ten and twenty

247
00:08:16,630 --> 00:08:21,030
five and so on and so on and so what

248
00:08:19,300 --> 00:08:23,680
that means is that when I say something

249
00:08:21,030 --> 00:08:26,169
the reader also understands what I'm

250
00:08:23,680 --> 00:08:28,150
saying in the same way as I mean it and

251
00:08:26,169 --> 00:08:30,729
then when we actually use that in

252
00:08:28,150 --> 00:08:31,870
reporting what we do is two things so

253
00:08:30,729 --> 00:08:33,819
you can see an example down on the

254
00:08:31,870 --> 00:08:36,400
bottom so PDV see you can be a systems

255
00:08:33,820 --> 00:08:37,599
assess it is highly likely that Flora so

256
00:08:36,400 --> 00:08:39,309
effective you're doing two things like I

257
00:08:37,599 --> 00:08:40,450
said first of all were being really

258
00:08:39,309 --> 00:08:42,130
clear about the fact that what we're

259
00:08:40,450 --> 00:08:45,400
saying is an assessment so it's not fact

260
00:08:42,130 --> 00:08:47,530
and then secondly we're adding a term

261
00:08:45,400 --> 00:08:49,120
after our assessment to show how

262
00:08:47,530 --> 00:08:51,010
confident we actually are in that

263
00:08:49,120 --> 00:08:53,110
assessment so we say we assess it's

264
00:08:51,010 --> 00:08:53,730
highly likely so that means we think

265
00:08:53,110 --> 00:08:55,560
it's between

266
00:08:53,730 --> 00:08:59,930
seventy-five and a 90 percent chance and

267
00:08:55,560 --> 00:09:02,279
then we go on to talk about stuff so

268
00:08:59,930 --> 00:09:03,870
that's a really quick run through all of

269
00:09:02,279 --> 00:09:06,449
my things I'm sure I've been way too

270
00:09:03,870 --> 00:09:09,930
quick for time and so we can return have

271
00:09:06,449 --> 00:09:11,490
you got any questions I've personally

272
00:09:09,930 --> 00:09:14,099
found all of those intelligence

273
00:09:11,490 --> 00:09:15,389
techniques really useful when we've been

274
00:09:14,100 --> 00:09:17,220
doing our reporting we're trying to kind

275
00:09:15,389 --> 00:09:18,510
of bring these techniques more to the

276
00:09:17,220 --> 00:09:19,860
forefront and the rest of the reporting

277
00:09:18,510 --> 00:09:21,089
that the team is doing

278
00:09:19,860 --> 00:09:22,709
we found them really useful for

279
00:09:21,089 --> 00:09:24,120
analyzing threat actors but also just

280
00:09:22,709 --> 00:09:26,790
for talking about you know when we're

281
00:09:24,120 --> 00:09:28,230
looking at analyzing intrusions or when

282
00:09:26,790 --> 00:09:30,329
we're doing any kind of subjective

283
00:09:28,230 --> 00:09:32,130
analysis where they're we're not 100

284
00:09:30,329 --> 00:09:33,449
cent talking about facts trying to make

285
00:09:32,130 --> 00:09:35,670
sure that the analysis that we're doing

286
00:09:33,449 --> 00:09:39,359
is as rigorous and as rigorous as

287
00:09:35,670 --> 00:09:42,800
rigorous as possible so that's it for me

288
00:09:39,360 --> 00:09:42,800
and does anyone have any questions

