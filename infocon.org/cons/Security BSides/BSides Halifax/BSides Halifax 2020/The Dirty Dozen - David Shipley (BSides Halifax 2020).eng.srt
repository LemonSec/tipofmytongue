1
00:00:06,049 --> 00:00:11,120
thank you so much to the organizers of

2
00:00:08,240 --> 00:00:12,410
this event fantastic initiative thanks

3
00:00:11,120 --> 00:00:17,000
so much of the community for the chance

4
00:00:12,410 --> 00:00:19,580
to talk to you today for those who don't

5
00:00:17,000 --> 00:00:22,279
know me I am the co-founder of beauceron

6
00:00:19,580 --> 00:00:25,339
bodhrán is focused on the human side of

7
00:00:22,279 --> 00:00:27,920
cybersecurity and we really are

8
00:00:25,340 --> 00:00:30,198
fascinated with how we can reduce risk

9
00:00:27,920 --> 00:00:33,199
in in really interesting and fascinating

10
00:00:30,199 --> 00:00:35,870
ways around data around human behavior

11
00:00:33,199 --> 00:00:38,390
it is part of our research and part of

12
00:00:35,870 --> 00:00:41,959
the learnings that I've done with some

13
00:00:38,390 --> 00:00:45,559
of my amazing colleagues both at boson

14
00:00:41,960 --> 00:00:47,809
at organizations frankly at the national

15
00:00:45,559 --> 00:00:49,400
and global level we've really been

16
00:00:47,809 --> 00:00:51,379
focusing on some lessons that we can

17
00:00:49,400 --> 00:00:53,269
learn from the aviation industry and I

18
00:00:51,379 --> 00:00:55,610
do want to give a shout-out to my good

19
00:00:53,269 --> 00:00:58,129
friend Musa down who was the one that

20
00:00:55,610 --> 00:00:59,960
started me thinking about the lessons we

21
00:00:58,129 --> 00:01:04,250
can learn from the aviation sector and

22
00:00:59,960 --> 00:01:06,650
started me down this road just advance

23
00:01:04,250 --> 00:01:08,990
my slide here so I am the CEO and

24
00:01:06,650 --> 00:01:11,030
co-founder of beauceron boaster owns a

25
00:01:08,990 --> 00:01:14,780
fast-growing Fredericton based startup

26
00:01:11,030 --> 00:01:17,119
22 plus employees now 200 plus customers

27
00:01:14,780 --> 00:01:19,219
around the world prior to founding

28
00:01:17,119 --> 00:01:23,090
beauceron I led the cyber security

29
00:01:19,219 --> 00:01:24,890
practice at UNB and I cut my teeth on

30
00:01:23,090 --> 00:01:29,210
the technological side thinking about

31
00:01:24,890 --> 00:01:31,189
security analytics q radar automation

32
00:01:29,210 --> 00:01:32,419
and really realized how much the human

33
00:01:31,189 --> 00:01:36,380
side mattered

34
00:01:32,420 --> 00:01:38,869
and as super super supreme thank you to

35
00:01:36,380 --> 00:01:40,490
the community particularly the Atlantic

36
00:01:38,869 --> 00:01:43,189
security conference community Halifax

37
00:01:40,490 --> 00:01:45,949
because you helped me learn so much over

38
00:01:43,189 --> 00:01:48,318
the last eight years so gained a lot of

39
00:01:45,950 --> 00:01:54,799
experience at UNB I am also a proud

40
00:01:48,319 --> 00:01:57,770
Canadian Forces veteran beauceron exists

41
00:01:54,799 --> 00:02:01,130
we founded it and we grow it around the

42
00:01:57,770 --> 00:02:03,259
world our mission is to create a better

43
00:02:01,130 --> 00:02:07,458
world by helping people feel empowered

44
00:02:03,259 --> 00:02:09,740
and in control of technology that's

45
00:02:07,459 --> 00:02:13,100
never been more important than it is

46
00:02:09,740 --> 00:02:15,950
today and and the mission of putting

47
00:02:13,100 --> 00:02:19,040
people in control of technology is tied

48
00:02:15,950 --> 00:02:21,320
to the very meaning of the word cyber

49
00:02:19,040 --> 00:02:23,690
now for those who have heard me give

50
00:02:21,320 --> 00:02:24,410
some past talks you know I play this car

51
00:02:23,690 --> 00:02:26,750
you

52
00:02:24,410 --> 00:02:28,720
very often but it's worth talking about

53
00:02:26,750 --> 00:02:32,120
for those who haven't heard about cyber

54
00:02:28,720 --> 00:02:33,770
it's not just a simple term that that

55
00:02:32,120 --> 00:02:35,930
vaguely describes what we do in

56
00:02:33,770 --> 00:02:38,570
information security it's a word with

57
00:02:35,930 --> 00:02:41,630
intent meaning and power that we should

58
00:02:38,570 --> 00:02:43,239
consider and you know as we dive into

59
00:02:41,630 --> 00:02:45,190
what that word means

60
00:02:43,240 --> 00:02:48,050
cyber comes from the Greek word

61
00:02:45,190 --> 00:02:50,300
kubernetes kubernetes was chosen by

62
00:02:48,050 --> 00:02:52,610
Norbert Wiener the father of the the

63
00:02:50,300 --> 00:02:55,160
field of cybernetics and of automation

64
00:02:52,610 --> 00:02:57,500
because the greek word kubernetes means

65
00:02:55,160 --> 00:03:00,440
the helmsman or the steersman of a ship

66
00:02:57,500 --> 00:03:02,810
and he chose the word deliberately he

67
00:03:00,440 --> 00:03:04,850
chose the word because if you picture an

68
00:03:02,810 --> 00:03:07,160
ancient Greek ship at the back of the

69
00:03:04,850 --> 00:03:09,890
ship you have a person that's the first

70
00:03:07,160 --> 00:03:12,290
element the human element of cyber the

71
00:03:09,890 --> 00:03:14,480
second element is the or the rudder the

72
00:03:12,290 --> 00:03:17,450
steering wheel in their hand that's the

73
00:03:14,480 --> 00:03:19,519
technological element of cyber and the

74
00:03:17,450 --> 00:03:23,149
third element you can't see but is

75
00:03:19,520 --> 00:03:25,130
critically important is control now

76
00:03:23,150 --> 00:03:27,260
Winer is fascinated with this story of

77
00:03:25,130 --> 00:03:29,030
people technology and control and the

78
00:03:27,260 --> 00:03:32,179
interplay and the animal and the machine

79
00:03:29,030 --> 00:03:35,330
and a boson we firmly believe there is

80
00:03:32,180 --> 00:03:38,300
always a positive story when people are

81
00:03:35,330 --> 00:03:41,300
in control of technology there is a less

82
00:03:38,300 --> 00:03:43,610
positive story when technology is in

83
00:03:41,300 --> 00:03:46,520
control of people whether that's science

84
00:03:43,610 --> 00:03:48,709
fiction like the Terminator or in the

85
00:03:46,520 --> 00:03:51,560
sad reality most recently of the Boeing

86
00:03:48,709 --> 00:03:53,750
Max eight airplanes where automated

87
00:03:51,560 --> 00:03:55,489
systems based on flawed data took

88
00:03:53,750 --> 00:04:02,090
control of planes and caused fatal

89
00:03:55,489 --> 00:04:04,370
crashes so why a VA ssin why are there

90
00:04:02,090 --> 00:04:07,340
lessons from aviation that are important

91
00:04:04,370 --> 00:04:10,070
to cyber and this story of of the human

92
00:04:07,340 --> 00:04:13,760
factor and the the person in control of

93
00:04:10,070 --> 00:04:16,250
technology and there's some important

94
00:04:13,760 --> 00:04:19,130
data to consider in this so this is a

95
00:04:16,250 --> 00:04:22,160
graph that shows airliner accidents per

96
00:04:19,130 --> 00:04:26,330
million flight departures between 1977

97
00:04:22,160 --> 00:04:30,350
and 2017 and it's really really

98
00:04:26,330 --> 00:04:34,490
interesting in the period between 1977

99
00:04:30,350 --> 00:04:37,400
and 1989 for 87 you see there's a

100
00:04:34,490 --> 00:04:37,940
reduction in risk and a lot of this risk

101
00:04:37,400 --> 00:04:40,520
is

102
00:04:37,940 --> 00:04:42,530
further improvements improvements that

103
00:04:40,520 --> 00:04:44,690
have been going on since the 1940s in

104
00:04:42,530 --> 00:04:47,539
the technological aspects and

105
00:04:44,690 --> 00:04:49,940
technological controls and there was a

106
00:04:47,540 --> 00:04:52,460
result of those technological controls

107
00:04:49,940 --> 00:04:55,310
there was a 48 percent reduction in risk

108
00:04:52,460 --> 00:04:57,560
as measured by this metric that's great

109
00:04:55,310 --> 00:05:01,310
but as you can notice where the arrow is

110
00:04:57,560 --> 00:05:04,280
it starts to plateau and actually things

111
00:05:01,310 --> 00:05:07,460
start to get slightly worse and in the

112
00:05:04,280 --> 00:05:10,640
period of the late 80s Early 90s the

113
00:05:07,460 --> 00:05:13,940
airline industry adopted an airport

114
00:05:10,640 --> 00:05:16,760
regulators a significant focus on what

115
00:05:13,940 --> 00:05:18,500
they called the human factors and as

116
00:05:16,760 --> 00:05:20,480
part of human factors they were looking

117
00:05:18,500 --> 00:05:23,630
at what are the things that result in

118
00:05:20,480 --> 00:05:25,910
pilot error crew errors what's the

119
00:05:23,630 --> 00:05:29,150
culture in the airplanes control in the

120
00:05:25,910 --> 00:05:30,920
cockpit in the flight deck how do people

121
00:05:29,150 --> 00:05:33,950
do maintenance what are the human errors

122
00:05:30,920 --> 00:05:36,200
associated with that and by relentlessly

123
00:05:33,950 --> 00:05:39,110
focusing and building frameworks around

124
00:05:36,200 --> 00:05:41,539
the human factors and taking a broad

125
00:05:39,110 --> 00:05:43,850
approach on it you see the massive

126
00:05:41,540 --> 00:05:48,080
reduction in risk that occurs in the

127
00:05:43,850 --> 00:05:51,530
period of 1989 to 2017 and you see it go

128
00:05:48,080 --> 00:05:56,200
from just over two and a half fatal

129
00:05:51,530 --> 00:05:59,330
accidents per 1 million flights to 0.36%

130
00:05:56,200 --> 00:06:02,539
3 6 fatal accidents per million flights

131
00:05:59,330 --> 00:06:05,719
that's an 88% reduction in risk

132
00:06:02,540 --> 00:06:07,460
so remember technology got us a 48

133
00:06:05,720 --> 00:06:11,980
percent reduction in risk in the period

134
00:06:07,460 --> 00:06:18,140
between 77 and 87 focusing on the humans

135
00:06:11,980 --> 00:06:20,120
yielded huge benefits and what is the

136
00:06:18,140 --> 00:06:23,120
human factors in the context of the

137
00:06:20,120 --> 00:06:26,030
aviation industry and they bolded two

138
00:06:23,120 --> 00:06:29,690
important parts it's a term that covers

139
00:06:26,030 --> 00:06:31,969
the science and there is hard provable

140
00:06:29,690 --> 00:06:33,980
science as Jean chrétien once said my

141
00:06:31,970 --> 00:06:36,770
favorite quote from a proof is a proof

142
00:06:33,980 --> 00:06:38,690
because it's proven there's science and

143
00:06:36,770 --> 00:06:42,320
the understanding of the properties of

144
00:06:38,690 --> 00:06:44,570
human capability and limitations and the

145
00:06:42,320 --> 00:06:46,729
application of this understanding to the

146
00:06:44,570 --> 00:06:50,330
design development and deployment of

147
00:06:46,729 --> 00:06:51,030
systems and services thinking about the

148
00:06:50,330 --> 00:06:54,490
person

149
00:06:51,030 --> 00:06:57,940
and then it's less about science and

150
00:06:54,490 --> 00:07:00,070
it's actually about the art how do we

151
00:06:57,940 --> 00:07:03,370
use the art of insuring and applying

152
00:07:00,070 --> 00:07:05,500
these principles to the organizations

153
00:07:03,370 --> 00:07:09,070
and to the context that they make sense

154
00:07:05,500 --> 00:07:10,720
so it's a science and it's an art and

155
00:07:09,070 --> 00:07:13,690
that's a place where I live I'm a

156
00:07:10,720 --> 00:07:17,410
liberal arts graduate with a BA and an

157
00:07:13,690 --> 00:07:19,660
MBA and of a super nerd I exist at the

158
00:07:17,410 --> 00:07:21,370
intersection of science and art and I

159
00:07:19,660 --> 00:07:24,400
believe that's the place that can help

160
00:07:21,370 --> 00:07:29,050
us advance the state of cybersecurity

161
00:07:24,400 --> 00:07:31,900
and cyber risk reduction and we need a

162
00:07:29,050 --> 00:07:34,590
new and broader multidisciplinary

163
00:07:31,900 --> 00:07:38,280
approach to the human factors of cyber

164
00:07:34,590 --> 00:07:40,989
there is absolutely a role for clinical

165
00:07:38,280 --> 00:07:43,359
experimental and educational psychology

166
00:07:40,990 --> 00:07:45,520
as well as computer science and

167
00:07:43,360 --> 00:07:48,220
cognitive science there are plenty of

168
00:07:45,520 --> 00:07:51,039
roles for workplace sociology medical

169
00:07:48,220 --> 00:07:53,650
science or biology in the aviation

170
00:07:51,040 --> 00:07:55,480
industry they're human factors approach

171
00:07:53,650 --> 00:07:57,880
included clinical psychology

172
00:07:55,480 --> 00:07:58,750
experimental psychology and throw

173
00:07:57,880 --> 00:08:00,130
prometrics

174
00:07:58,750 --> 00:08:02,440
I don't know if sure I pronounced that

175
00:08:00,130 --> 00:08:04,570
correctly I have so the mechanics of the

176
00:08:02,440 --> 00:08:06,490
body computer science

177
00:08:04,570 --> 00:08:09,820
cognitive science safety engineering

178
00:08:06,490 --> 00:08:11,470
medical science and more including

179
00:08:09,820 --> 00:08:14,110
Industrial Engineering and so by looking

180
00:08:11,470 --> 00:08:17,710
at this broad approach they really

181
00:08:14,110 --> 00:08:21,850
started to dive into how do we deal with

182
00:08:17,710 --> 00:08:25,210
the human factor and one of the things

183
00:08:21,850 --> 00:08:27,550
that came out of the human factors focus

184
00:08:25,210 --> 00:08:30,909
is something that I absolutely love and

185
00:08:27,550 --> 00:08:34,330
it's called the pair model so there are

186
00:08:30,910 --> 00:08:37,360
four components to this model people

187
00:08:34,330 --> 00:08:41,170
actions environments and resources

188
00:08:37,360 --> 00:08:43,210
people who is doing the work what's

189
00:08:41,169 --> 00:08:45,729
their educational background what's

190
00:08:43,210 --> 00:08:47,560
their cognitive background what stresses

191
00:08:45,730 --> 00:08:50,920
are they under what are the things

192
00:08:47,560 --> 00:08:53,650
happening for them the actions they

193
00:08:50,920 --> 00:08:55,449
perform who has access to critical IT

194
00:08:53,650 --> 00:08:57,699
systems privileged access management

195
00:08:55,450 --> 00:09:00,520
who's a frontline worker who's in the

196
00:08:57,700 --> 00:09:02,590
finance team understanding the actions

197
00:09:00,520 --> 00:09:05,279
that they do every day that are critical

198
00:09:02,590 --> 00:09:08,769
to the business or organization

199
00:09:05,279 --> 00:09:10,480
environments in which they work Wow you

200
00:09:08,769 --> 00:09:12,670
know this pandemic has made really clear

201
00:09:10,480 --> 00:09:15,190
that when you dramatically change the

202
00:09:12,670 --> 00:09:19,089
environments where people work there's

203
00:09:15,190 --> 00:09:22,779
dramatic new risks and benefits that

204
00:09:19,089 --> 00:09:26,170
have to be considered and resources to

205
00:09:22,779 --> 00:09:29,170
complete the job did we have the right

206
00:09:26,170 --> 00:09:31,089
tools in place for people to do the work

207
00:09:29,170 --> 00:09:34,000
they need to do for our organizations

208
00:09:31,089 --> 00:09:38,709
inside in cyberspace in ways that are

209
00:09:34,000 --> 00:09:41,379
efficient effective and secure and one

210
00:09:38,709 --> 00:09:42,969
example I want to cite about applying

211
00:09:41,379 --> 00:09:45,220
the pair model and this comes from

212
00:09:42,970 --> 00:09:48,639
actually the Royal Bank of Canada and a

213
00:09:45,220 --> 00:09:50,800
really smart innovation they did they

214
00:09:48,639 --> 00:09:52,509
were noticing that a lot of clients

215
00:09:50,800 --> 00:09:54,699
would come to their front line to ask

216
00:09:52,509 --> 00:09:57,540
for a critical cybersecurity advice

217
00:09:54,699 --> 00:10:00,639
they've been fished there's a fraud etc

218
00:09:57,540 --> 00:10:02,560
and they considered the people on the

219
00:10:00,639 --> 00:10:05,230
front line these were non IT experts

220
00:10:02,560 --> 00:10:06,878
they needed quick information they

221
00:10:05,230 --> 00:10:09,189
considered the way to deliver that

222
00:10:06,879 --> 00:10:11,139
resource to them they can't access their

223
00:10:09,189 --> 00:10:13,180
smartphones while they're working at the

224
00:10:11,139 --> 00:10:15,399
front counter the intranet could be

225
00:10:13,180 --> 00:10:17,258
cumbersome or slow to to access the

226
00:10:15,399 --> 00:10:19,930
information speed and accuracy were

227
00:10:17,259 --> 00:10:23,319
important and they created these really

228
00:10:19,930 --> 00:10:25,329
cool desktop calendar flips kind of

229
00:10:23,319 --> 00:10:27,279
looking like your desktop calendar that

230
00:10:25,329 --> 00:10:29,880
was a based on ideas from nursing

231
00:10:27,279 --> 00:10:32,829
stations where nurses had critical

232
00:10:29,880 --> 00:10:34,839
response functions separated by tab for

233
00:10:32,829 --> 00:10:37,089
steps or checklists they could perform

234
00:10:34,839 --> 00:10:39,880
and they created that and that's a

235
00:10:37,089 --> 00:10:41,889
that's a perfect example of how we could

236
00:10:39,880 --> 00:10:44,529
use the pair model to provide better

237
00:10:41,889 --> 00:10:48,449
information about cybersecurity to a

238
00:10:44,529 --> 00:10:52,300
particular person in their role now

239
00:10:48,449 --> 00:10:56,620
moving on from pair I'm particularly

240
00:10:52,300 --> 00:10:58,899
proud to acknowledge and cite that the

241
00:10:56,620 --> 00:11:02,220
the dirty dozen that we're about to talk

242
00:10:58,899 --> 00:11:06,220
to talk about and engage in is a

243
00:11:02,220 --> 00:11:08,980
Canadian innovation now used around the

244
00:11:06,220 --> 00:11:11,350
world as the global standard for

245
00:11:08,980 --> 00:11:13,240
aircraft maintenance safety and it was

246
00:11:11,350 --> 00:11:15,670
developed by Gordon DuPont of Transport

247
00:11:13,240 --> 00:11:17,350
Canada and it came at a result of

248
00:11:15,670 --> 00:11:19,689
evaluating the large

249
00:11:17,350 --> 00:11:21,940
maintenance related aviation accidents

250
00:11:19,690 --> 00:11:25,660
and incidents and so this has been

251
00:11:21,940 --> 00:11:27,880
refined and improved and I believe and

252
00:11:25,660 --> 00:11:29,800
I'll try to demonstrate has broad

253
00:11:27,880 --> 00:11:32,890
applicability to the work we're doing

254
00:11:29,800 --> 00:11:38,530
with our organizations and our

255
00:11:32,890 --> 00:11:40,110
organizational team members so let's

256
00:11:38,530 --> 00:11:42,910
recap the Dirty Dozen

257
00:11:40,110 --> 00:11:45,400
none of these are probably a massive

258
00:11:42,910 --> 00:11:47,680
shock to to everyone but it's

259
00:11:45,400 --> 00:11:51,840
interesting to see them presented in

260
00:11:47,680 --> 00:11:56,520
this in this way distraction stress

261
00:11:51,840 --> 00:11:59,910
pressure fatigue lack of communication

262
00:11:56,520 --> 00:12:05,110
lack of awareness lack of assertiveness

263
00:11:59,910 --> 00:12:07,870
lack of resources lack of teamwork lack

264
00:12:05,110 --> 00:12:10,950
of knowledge norms within the workplace

265
00:12:07,870 --> 00:12:15,250
last but not least my personal favorite

266
00:12:10,950 --> 00:12:17,260
complacency no no factor that I just

267
00:12:15,250 --> 00:12:19,810
listed out is is greater than the others

268
00:12:17,260 --> 00:12:22,210
they're all there and in accidents or

269
00:12:19,810 --> 00:12:24,400
incidents there's likely the presence of

270
00:12:22,210 --> 00:12:27,060
multiple and relationships between them

271
00:12:24,400 --> 00:12:30,689
particularly stress pressure and fatigue

272
00:12:27,060 --> 00:12:33,430
have an interesting interrelationship

273
00:12:30,690 --> 00:12:37,770
and we'll dive into some more of the

274
00:12:33,430 --> 00:12:40,479
specifics so when we talk about

275
00:12:37,770 --> 00:12:42,010
distraction and trying to find icons for

276
00:12:40,480 --> 00:12:43,840
some of the things was hilarious and all

277
00:12:42,010 --> 00:12:46,060
I could think of was the the movie up

278
00:12:43,840 --> 00:12:49,630
and the dog every time you saw a

279
00:12:46,060 --> 00:12:51,099
squirrel but distraction is anything

280
00:12:49,630 --> 00:12:53,020
that draws a person's attention away

281
00:12:51,100 --> 00:12:55,000
from the tasks in which they're engaged

282
00:12:53,020 --> 00:12:56,079
in and actually just before my

283
00:12:55,000 --> 00:12:57,250
presentation we were talking about the

284
00:12:56,080 --> 00:12:59,470
distractions that come from smart

285
00:12:57,250 --> 00:13:01,240
watches and notifications now that can

286
00:12:59,470 --> 00:13:04,840
interrupt conversation or thought flow

287
00:13:01,240 --> 00:13:06,910
and when you're distracted of course

288
00:13:04,840 --> 00:13:09,130
when you get back to a task you can a

289
00:13:06,910 --> 00:13:13,000
result and result in errors or mistakes

290
00:13:09,130 --> 00:13:14,620
as you resume attention and with every

291
00:13:13,000 --> 00:13:16,510
one of these human factors I'm going to

292
00:13:14,620 --> 00:13:19,690
present today I'm going to talk a lot

293
00:13:16,510 --> 00:13:21,069
about possible countermeasures things

294
00:13:19,690 --> 00:13:23,170
that we could be thinking about within

295
00:13:21,070 --> 00:13:25,030
the organization some of these and a lot

296
00:13:23,170 --> 00:13:25,959
of them are not technological

297
00:13:25,030 --> 00:13:28,300
countermeasures

298
00:13:25,960 --> 00:13:29,510
there are organizational process and

299
00:13:28,300 --> 00:13:31,819
culture countermeasures

300
00:13:29,510 --> 00:13:33,620
for example distraction and being pulled

301
00:13:31,820 --> 00:13:35,600
off tasks with the email back and forth

302
00:13:33,620 --> 00:13:38,329
one of the things I've looked at doing

303
00:13:35,600 --> 00:13:40,760
is carving off dedicated time for when

304
00:13:38,329 --> 00:13:43,250
I'm in my own email inbox and I'm paying

305
00:13:40,760 --> 00:13:45,709
attention to it and I'm being very

306
00:13:43,250 --> 00:13:48,529
vigilant about what I'm working on and

307
00:13:45,709 --> 00:13:51,469
then I close my email inbox and I use

308
00:13:48,529 --> 00:13:53,360
other tools like teams or slack and

309
00:13:51,470 --> 00:13:55,639
that's my ongoing internal

310
00:13:53,360 --> 00:13:58,220
communications tool for my team that I

311
00:13:55,639 --> 00:13:59,990
can mute if I don't need it but because

312
00:13:58,220 --> 00:14:02,480
email is a source of information where

313
00:13:59,990 --> 00:14:04,820
external folks can reach out to me and

314
00:14:02,480 --> 00:14:07,190
in key in specific cases external threat

315
00:14:04,820 --> 00:14:09,230
actors through phishing maybe I want to

316
00:14:07,190 --> 00:14:10,639
make sure I'm on my a-game when I'm

317
00:14:09,230 --> 00:14:12,380
replying to emails particularly

318
00:14:10,639 --> 00:14:14,810
depending on the sensitivity or role

319
00:14:12,380 --> 00:14:17,990
that I'm in and we should talk about

320
00:14:14,810 --> 00:14:19,399
reducing multitasking maybe it's not as

321
00:14:17,990 --> 00:14:21,010
productive in fact there are some really

322
00:14:19,399 --> 00:14:22,970
good studies at showing multitasking

323
00:14:21,010 --> 00:14:26,389
particularly in the context of

324
00:14:22,970 --> 00:14:32,870
particular roles or activities may be a

325
00:14:26,389 --> 00:14:35,930
significant risk stress I can't I don't

326
00:14:32,870 --> 00:14:37,880
think there's a person certainly in

327
00:14:35,930 --> 00:14:39,769
Canada or on the planet right now who's

328
00:14:37,880 --> 00:14:43,220
not under some aspect of stress and

329
00:14:39,769 --> 00:14:45,709
stress can be both situational so like

330
00:14:43,220 --> 00:14:48,829
an urgent situation looming deadlines

331
00:14:45,709 --> 00:14:50,899
sort of an acute stress or stress can be

332
00:14:48,829 --> 00:14:52,849
from chronic issues that have been been

333
00:14:50,899 --> 00:14:55,790
sort of building for a long time family

334
00:14:52,850 --> 00:14:58,550
pressures finances other situations ie

335
00:14:55,790 --> 00:15:00,800
pandemics that have placed long-term

336
00:14:58,550 --> 00:15:05,329
demands on our minds and body are very

337
00:15:00,800 --> 00:15:07,939
human physiology individuals under acute

338
00:15:05,329 --> 00:15:12,050
or chronic stress it says may react

339
00:15:07,940 --> 00:15:12,980
often react inappropriately too often or

340
00:15:12,050 --> 00:15:15,380
too easily

341
00:15:12,980 --> 00:15:18,339
and that's a field day for social

342
00:15:15,380 --> 00:15:20,810
engineers there are some countermeasures

343
00:15:18,339 --> 00:15:23,480
how do we talk about our workplace

344
00:15:20,810 --> 00:15:26,510
wellness programs not just from the it's

345
00:15:23,480 --> 00:15:28,899
a great HR move it's a benefit move but

346
00:15:26,510 --> 00:15:32,750
actually it's part of your cybersecurity

347
00:15:28,899 --> 00:15:34,550
resiliency it's important into that how

348
00:15:32,750 --> 00:15:37,100
do we provide improved training for

349
00:15:34,550 --> 00:15:38,930
leaders and supervisors to spot stress

350
00:15:37,100 --> 00:15:40,579
particularly in the context of knowing

351
00:15:38,930 --> 00:15:41,620
that employees under stress or pressure

352
00:15:40,579 --> 00:15:46,260
are

353
00:15:41,620 --> 00:15:46,260
more prone to error and that adds risk

354
00:15:46,529 --> 00:15:53,620
pressure pressure can occur you know

355
00:15:51,370 --> 00:15:56,620
we've got a deadline to meet it can be

356
00:15:53,620 --> 00:15:58,650
imposed by yourself or others like your

357
00:15:56,620 --> 00:16:01,990
supervisor your organizational culture

358
00:15:58,650 --> 00:16:04,750
colleagues or even clients the most

359
00:16:01,990 --> 00:16:07,480
common source for many people is

360
00:16:04,750 --> 00:16:10,150
yourself often people can feel more

361
00:16:07,480 --> 00:16:11,290
pressure on themselves by taking on more

362
00:16:10,150 --> 00:16:13,900
work than they can handle

363
00:16:11,290 --> 00:16:16,150
and often times they do that based on

364
00:16:13,900 --> 00:16:17,620
increases in correct assumptions about

365
00:16:16,150 --> 00:16:22,120
what's expected on them

366
00:16:17,620 --> 00:16:23,980
and this is really important employee

367
00:16:22,120 --> 00:16:26,110
and assertiveness is going to come up in

368
00:16:23,980 --> 00:16:28,690
a couple of these different dirty dozen

369
00:16:26,110 --> 00:16:31,720
factors but employees should be

370
00:16:28,690 --> 00:16:34,120
empowered and enabled to say no stop and

371
00:16:31,720 --> 00:16:37,120
to ask for the resources or help needed

372
00:16:34,120 --> 00:16:39,130
to do the work properly or safely and we

373
00:16:37,120 --> 00:16:42,070
think about the development context of

374
00:16:39,130 --> 00:16:42,490
creating code this is an area we could

375
00:16:42,070 --> 00:16:45,339
do better

376
00:16:42,490 --> 00:16:47,890
culturally how do we make sure we aren't

377
00:16:45,339 --> 00:16:50,320
over stressing and over pressuring our

378
00:16:47,890 --> 00:16:52,300
developers building products and making

379
00:16:50,320 --> 00:16:55,510
sure that that's a risk factor we

380
00:16:52,300 --> 00:17:00,329
consider in the safe execution of jobs

381
00:16:55,510 --> 00:17:02,860
and businesses and organizations fatigue

382
00:17:00,330 --> 00:17:05,699
or fatigue is a natural physiological

383
00:17:02,860 --> 00:17:08,050
reaction to intense periods of hard work

384
00:17:05,699 --> 00:17:10,780
yesterday was a long day it goes up to

385
00:17:08,050 --> 00:17:14,290
11 o'clock last night or prolonged work

386
00:17:10,780 --> 00:17:17,559
periods so working really long shifts as

387
00:17:14,290 --> 00:17:20,230
we become fatigued scientifically proven

388
00:17:17,559 --> 00:17:23,879
our ability to concentrate remember and

389
00:17:20,230 --> 00:17:26,170
make decisions declined declines and

390
00:17:23,880 --> 00:17:28,059
there are countermeasures that we need

391
00:17:26,170 --> 00:17:30,190
to be talking about in our cybersecurity

392
00:17:28,059 --> 00:17:31,720
programs we need to ensure

393
00:17:30,190 --> 00:17:34,650
organizational members are employing

394
00:17:31,720 --> 00:17:37,390
effective fatigue management programs

395
00:17:34,650 --> 00:17:39,700
sounds fancy but to get enough sleep

396
00:17:37,390 --> 00:17:42,700
they're eating a healthy diet they're

397
00:17:39,700 --> 00:17:44,770
exercising and if you've got a community

398
00:17:42,700 --> 00:17:46,870
inside your organization of users who

399
00:17:44,770 --> 00:17:50,740
are not getting enough sleep or not

400
00:17:46,870 --> 00:17:54,360
exercising who are unwell your chance of

401
00:17:50,740 --> 00:17:55,510
having incidents is significantly higher

402
00:17:54,360 --> 00:17:57,129
interesting

403
00:17:55,510 --> 00:17:59,260
enough there's a note in the aviation

404
00:17:57,130 --> 00:18:00,580
sector and something I hadn't really

405
00:17:59,260 --> 00:18:02,860
thought about and I want to do more

406
00:18:00,580 --> 00:18:05,020
analysis on and we look at real

407
00:18:02,860 --> 00:18:08,350
incidents inside organizations involving

408
00:18:05,020 --> 00:18:09,610
human factors is what is the amount of

409
00:18:08,350 --> 00:18:11,530
these activities that are happening with

410
00:18:09,610 --> 00:18:13,719
people's body circadian rhythm is low

411
00:18:11,530 --> 00:18:15,550
for example in a period of 3 a.m. to 5

412
00:18:13,720 --> 00:18:17,860
a.m. if you've got someone pulling an

413
00:18:15,550 --> 00:18:19,300
all-nighter to get ready for work how

414
00:18:17,860 --> 00:18:26,409
many times does that result in an

415
00:18:19,300 --> 00:18:30,010
incident lack of communication we can do

416
00:18:26,410 --> 00:18:31,510
much better in our field communicating

417
00:18:30,010 --> 00:18:33,400
through our communities about cyber

418
00:18:31,510 --> 00:18:36,190
security incidents risks and best

419
00:18:33,400 --> 00:18:38,080
practices you know when we deliver

420
00:18:36,190 --> 00:18:40,660
written communications those big long

421
00:18:38,080 --> 00:18:43,179
emails warning people about phishing etc

422
00:18:40,660 --> 00:18:45,180
a lot of people don't absorb that

423
00:18:43,180 --> 00:18:47,530
information there are opportunities for

424
00:18:45,180 --> 00:18:49,090
misinterpretation or assumptions in

425
00:18:47,530 --> 00:18:50,379
verbal communications even when we're

426
00:18:49,090 --> 00:18:51,580
having one-on-one and we're trying to

427
00:18:50,380 --> 00:18:54,310
coach people about cyber security

428
00:18:51,580 --> 00:18:56,169
there's a high degree of error with only

429
00:18:54,310 --> 00:18:58,450
about a third of the actual message

430
00:18:56,170 --> 00:18:59,950
being clearly understood in the

431
00:18:58,450 --> 00:19:01,500
transmission between the sender and the

432
00:18:59,950 --> 00:19:04,270
receiver

433
00:19:01,500 --> 00:19:07,210
there are countermeasures to improve our

434
00:19:04,270 --> 00:19:09,430
lack of communications making sure we

435
00:19:07,210 --> 00:19:12,610
leverage multiple formats for delivering

436
00:19:09,430 --> 00:19:16,360
key security information the RBC flip

437
00:19:12,610 --> 00:19:19,510
chart example is a fantastic one don't

438
00:19:16,360 --> 00:19:21,429
just use computer-based training and

439
00:19:19,510 --> 00:19:23,290
phishing I say that as a person that

440
00:19:21,430 --> 00:19:25,480
provides a platform that yes provides

441
00:19:23,290 --> 00:19:28,420
these and they're wonderful they're part

442
00:19:25,480 --> 00:19:31,180
of a balanced diet leverage posters

443
00:19:28,420 --> 00:19:33,550
physical checklists magnets flip chart

444
00:19:31,180 --> 00:19:35,320
guides as well as in-person Town Hall's

445
00:19:33,550 --> 00:19:37,960
or one-to-one conversations as

446
00:19:35,320 --> 00:19:40,629
appropriate and scalable and as you find

447
00:19:37,960 --> 00:19:42,370
ways to automate the the compliance

448
00:19:40,630 --> 00:19:44,020
driven security awareness activities

449
00:19:42,370 --> 00:19:47,199
that many have to do the training the

450
00:19:44,020 --> 00:19:49,350
fishing the surveys as you find ways to

451
00:19:47,200 --> 00:19:55,180
improve that you get to spend more time

452
00:19:49,350 --> 00:19:59,459
improving your communications lack of

453
00:19:55,180 --> 00:20:01,630
assertiveness now what is assertiveness

454
00:19:59,460 --> 00:20:03,460
assertiveness is a communication and

455
00:20:01,630 --> 00:20:05,380
behavioral style that allows individuals

456
00:20:03,460 --> 00:20:08,020
to express feelings opinions concerns

457
00:20:05,380 --> 00:20:09,280
beliefs or needs in a productive and

458
00:20:08,020 --> 00:20:11,920
positive way

459
00:20:09,280 --> 00:20:15,570
it can be done in a direct but non

460
00:20:11,920 --> 00:20:15,570
aggressive and respectful way

461
00:20:16,890 --> 00:20:22,240
countermeasures to help people become

462
00:20:20,410 --> 00:20:25,090
assertive to deal with lack of

463
00:20:22,240 --> 00:20:28,420
assertiveness teach and encourage the

464
00:20:25,090 --> 00:20:31,149
use of assertiveness techniques it's

465
00:20:28,420 --> 00:20:33,940
important that people feel like they can

466
00:20:31,150 --> 00:20:36,070
say I have a concern and in

467
00:20:33,940 --> 00:20:39,640
cybersecurity a more tactical and

468
00:20:36,070 --> 00:20:40,600
practical example is making it easier

469
00:20:39,640 --> 00:20:43,390
for people to speak up and share

470
00:20:40,600 --> 00:20:45,219
concerns with fishing reports a lot of

471
00:20:43,390 --> 00:20:47,260
organizations still send their phishing

472
00:20:45,220 --> 00:20:49,030
emails to the help desk the help desk

473
00:20:47,260 --> 00:20:50,530
may or may not get around to it may say

474
00:20:49,030 --> 00:20:51,879
hey someone else is already reported

475
00:20:50,530 --> 00:20:54,280
about this it doesn't matter stop

476
00:20:51,880 --> 00:20:55,870
bothering us create better processes

477
00:20:54,280 --> 00:20:57,760
that can recognize when people are doing

478
00:20:55,870 --> 00:21:00,370
the right thing and celebrate it it's

479
00:20:57,760 --> 00:21:02,080
critical and it enables people to feel

480
00:21:00,370 --> 00:21:05,110
like being assertive and raising

481
00:21:02,080 --> 00:21:11,830
concerns is a good part of the

482
00:21:05,110 --> 00:21:13,719
organization lack of resources when we

483
00:21:11,830 --> 00:21:16,600
don't provide the tools people need to

484
00:21:13,720 --> 00:21:18,850
do their job safely online they'll find

485
00:21:16,600 --> 00:21:20,770
other potentially unsafe ways to get the

486
00:21:18,850 --> 00:21:23,919
tasks done particularly if they're under

487
00:21:20,770 --> 00:21:26,020
pressure or stressed we need to do a

488
00:21:23,920 --> 00:21:27,280
better job of regularly assessing the

489
00:21:26,020 --> 00:21:29,740
needs for your people in your

490
00:21:27,280 --> 00:21:32,950
organization and you can use models like

491
00:21:29,740 --> 00:21:34,930
pair and we need to conduct two surveys

492
00:21:32,950 --> 00:21:36,970
to assess risky behaviors and get

493
00:21:34,930 --> 00:21:39,640
feedback from your community on their

494
00:21:36,970 --> 00:21:41,470
needs now we've done surveys involving

495
00:21:39,640 --> 00:21:43,450
tens of thousands of individuals and

496
00:21:41,470 --> 00:21:45,310
getting great insights about who's

497
00:21:43,450 --> 00:21:47,290
storing information in the cloud and you

498
00:21:45,310 --> 00:21:49,000
realize that was a bad thing in their

499
00:21:47,290 --> 00:21:51,310
personal cloud accounts or who's sharing

500
00:21:49,000 --> 00:21:54,510
passwords or who's using unauthorized

501
00:21:51,310 --> 00:21:57,370
apps that might have security concerns

502
00:21:54,510 --> 00:21:59,860
making sure that our people see our

503
00:21:57,370 --> 00:22:01,449
security and IT teams as the Department

504
00:21:59,860 --> 00:22:03,669
of yes and here's how we're going to do

505
00:22:01,450 --> 00:22:10,120
it securely instead of the Department of

506
00:22:03,670 --> 00:22:12,760
no lack of teamwork in our research at

507
00:22:10,120 --> 00:22:15,399
Bose Arun nearly a third of all

508
00:22:12,760 --> 00:22:19,120
employees see cyber security that's

509
00:22:15,400 --> 00:22:21,910
mostly I t's problem cyber security is a

510
00:22:19,120 --> 00:22:23,199
team sport that requires all aspects of

511
00:22:21,910 --> 00:22:25,450
an organization or business

512
00:22:23,200 --> 00:22:30,720
from senior leadership to the front line

513
00:22:25,450 --> 00:22:30,720
to be active and empowered participants

514
00:22:30,990 --> 00:22:34,659
countermeasures to the sense of lack of

515
00:22:32,950 --> 00:22:36,909
teamwork in your awareness campaign

516
00:22:34,659 --> 00:22:38,350
stress the importance of all individuals

517
00:22:36,909 --> 00:22:41,230
in the collective defense of your

518
00:22:38,350 --> 00:22:44,500
organization talk about the Dirty Dozen

519
00:22:41,230 --> 00:22:46,210
and how it might be used to increase

520
00:22:44,500 --> 00:22:48,940
awareness of individual and

521
00:22:46,210 --> 00:22:51,190
organizational cyber risk as related to

522
00:22:48,940 --> 00:22:53,409
the human factors and particularly talk

523
00:22:51,190 --> 00:22:56,169
about how the Dirty Dozen are the

524
00:22:53,409 --> 00:23:02,019
favorite tactics or leverage points for

525
00:22:56,169 --> 00:23:04,120
social engineers hum as a maritime ER I

526
00:23:02,019 --> 00:23:06,370
love the lighthouse icon so I was

527
00:23:04,120 --> 00:23:09,070
looking for an excuse to use one so they

528
00:23:06,370 --> 00:23:10,658
used it for lack of awareness and I want

529
00:23:09,070 --> 00:23:12,760
to be clear that when I'm talking about

530
00:23:10,659 --> 00:23:14,559
lack of awareness in this context it's

531
00:23:12,760 --> 00:23:17,019
not general awareness about

532
00:23:14,559 --> 00:23:18,820
cybersecurity or awareness of the

533
00:23:17,019 --> 00:23:21,549
important role people will play in our

534
00:23:18,820 --> 00:23:23,350
research 93% of employees generally

535
00:23:21,549 --> 00:23:25,870
indicate that they understand they play

536
00:23:23,350 --> 00:23:28,360
an important role but when you drill

537
00:23:25,870 --> 00:23:30,820
down and find specific areas they don't

538
00:23:28,360 --> 00:23:32,949
necessarily understand all of the

539
00:23:30,820 --> 00:23:34,899
connections the the situational

540
00:23:32,950 --> 00:23:36,610
awareness between activities like remote

541
00:23:34,899 --> 00:23:39,129
work storage of organizational

542
00:23:36,610 --> 00:23:41,320
information in personal cloud password

543
00:23:39,130 --> 00:23:44,019
reuse or even posting too much social

544
00:23:41,320 --> 00:23:46,809
media information and how that creates

545
00:23:44,019 --> 00:23:51,100
new risks and issues for them and for

546
00:23:46,809 --> 00:23:54,340
the organization to address that lack of

547
00:23:51,100 --> 00:23:56,260
situational specific awareness we need

548
00:23:54,340 --> 00:23:58,990
to move awareness and training to be

549
00:23:56,260 --> 00:24:01,210
about more than just passwords to FA and

550
00:23:58,990 --> 00:24:03,370
phishing yes we've got to talk about

551
00:24:01,210 --> 00:24:05,230
that or there's other mandatory topics

552
00:24:03,370 --> 00:24:07,209
we have to discuss but we need to

553
00:24:05,230 --> 00:24:09,279
provide more contextual information that

554
00:24:07,210 --> 00:24:12,549
explains the connection between common

555
00:24:09,279 --> 00:24:14,669
activities and risks and the more

556
00:24:12,549 --> 00:24:17,500
contextual and specific and

557
00:24:14,669 --> 00:24:20,799
organization's awareness information is

558
00:24:17,500 --> 00:24:23,620
to their industry their policies your

559
00:24:20,799 --> 00:24:25,570
security approach and the role of the

560
00:24:23,620 --> 00:24:31,899
group or individual you're targeting the

561
00:24:25,570 --> 00:24:33,439
better lack of knowledge now this is

562
00:24:31,899 --> 00:24:35,389
different than

563
00:24:33,440 --> 00:24:37,940
lack of awareness and lack of knowledge

564
00:24:35,390 --> 00:24:40,160
is domain or topical specific

565
00:24:37,940 --> 00:24:41,780
information and a third of employees say

566
00:24:40,160 --> 00:24:43,820
they still aren't getting enough

567
00:24:41,780 --> 00:24:47,270
specific education and that builds on my

568
00:24:43,820 --> 00:24:49,790
previous point countermeasures to the

569
00:24:47,270 --> 00:24:52,040
lack of knowledge enhance your education

570
00:24:49,790 --> 00:24:55,790
program with more specific and relevant

571
00:24:52,040 --> 00:24:58,540
content please don't overly rely on

572
00:24:55,790 --> 00:25:01,159
generic cybersecurity awareness content

573
00:24:58,540 --> 00:25:02,840
it's incredibly frustrating for me that

574
00:25:01,160 --> 00:25:04,460
one of the criterias in the awareness

575
00:25:02,840 --> 00:25:07,070
and training industry is we've got a

576
00:25:04,460 --> 00:25:11,270
thousand modules thousand generic

577
00:25:07,070 --> 00:25:13,879
modules content about your organization

578
00:25:11,270 --> 00:25:16,610
quickly created that talks about how to

579
00:25:13,880 --> 00:25:19,280
do things right within your context is

580
00:25:16,610 --> 00:25:22,939
orders of magnitude more impactful than

581
00:25:19,280 --> 00:25:25,129
flashy videos support organizational

582
00:25:22,940 --> 00:25:27,500
member knowledge development I've seen a

583
00:25:25,130 --> 00:25:30,410
number of clients cleverly use the

584
00:25:27,500 --> 00:25:33,320
technology we provided to actually build

585
00:25:30,410 --> 00:25:35,720
knowledge pass to fill cybersecurity

586
00:25:33,320 --> 00:25:37,700
privacy or other skill gaps they have in

587
00:25:35,720 --> 00:25:43,520
their organization by providing that

588
00:25:37,700 --> 00:25:45,950
knowledge norms speaking of finding

589
00:25:43,520 --> 00:25:47,810
icons that can be challenging a farmer

590
00:25:45,950 --> 00:25:52,220
nor my guess here is going to be my my

591
00:25:47,810 --> 00:25:54,649
icon norms are and I always hated this

592
00:25:52,220 --> 00:25:56,930
thing the way we always do it here or

593
00:25:54,650 --> 00:25:58,970
the way we do things though the practice

594
00:25:56,930 --> 00:26:01,430
is undertaking in an organization that

595
00:25:58,970 --> 00:26:05,450
are shared or sometimes reinforced by

596
00:26:01,430 --> 00:26:07,220
its workplace culture often workplace

597
00:26:05,450 --> 00:26:09,070
norms can deviate from established

598
00:26:07,220 --> 00:26:11,240
organizational processes or policies

599
00:26:09,070 --> 00:26:13,340
yeah we've got a clean desk for a

600
00:26:11,240 --> 00:26:15,290
process or policy we've all been

601
00:26:13,340 --> 00:26:18,320
educated on it but everyone leaves their

602
00:26:15,290 --> 00:26:20,480
desk messy and our business peer

603
00:26:18,320 --> 00:26:22,879
pressure and bad habits can enforce

604
00:26:20,480 --> 00:26:25,070
these kinds of bad practices it's

605
00:26:22,880 --> 00:26:27,590
important to understand what the norms

606
00:26:25,070 --> 00:26:29,780
are in your organization when you

607
00:26:27,590 --> 00:26:31,879
regularly review key organizational

608
00:26:29,780 --> 00:26:33,590
policies and procedures and conduct

609
00:26:31,880 --> 00:26:35,300
compliance assessments against those

610
00:26:33,590 --> 00:26:37,899
that can be done with individuals self

611
00:26:35,300 --> 00:26:40,580
assessment surveys post incident reviews

612
00:26:37,900 --> 00:26:44,270
walk-around through the office you can

613
00:26:40,580 --> 00:26:46,460
actually help understand where people's

614
00:26:44,270 --> 00:26:47,450
norms are conflicting with your

615
00:26:46,460 --> 00:26:51,049
objective

616
00:26:47,450 --> 00:26:54,620
for reducing cyber risk and you can use

617
00:26:51,049 --> 00:26:57,139
new tools and new ways of signaling good

618
00:26:54,620 --> 00:27:00,350
norms good cybersecurity behaviors to

619
00:26:57,139 --> 00:27:01,580
reinforce behaviors in the context of

620
00:27:00,350 --> 00:27:04,879
what we do a boats around we've got this

621
00:27:01,580 --> 00:27:06,620
dashboard the dashboard has a score and

622
00:27:04,880 --> 00:27:08,450
in that score people can see how they're

623
00:27:06,620 --> 00:27:10,489
doing and it nudges them to good

624
00:27:08,450 --> 00:27:13,279
behaviors while showing them that

625
00:27:10,490 --> 00:27:23,059
negative behaviors have an impact on

626
00:27:13,279 --> 00:27:24,740
their risk complacency my favorite this

627
00:27:23,059 --> 00:27:26,389
can occur when conducting routine

628
00:27:24,740 --> 00:27:28,399
activities they become a habitual and

629
00:27:26,389 --> 00:27:30,408
which may be considered by an individual

630
00:27:28,399 --> 00:27:35,029
or the whole organization as easy and

631
00:27:30,409 --> 00:27:37,820
safe email is a great example I used

632
00:27:35,029 --> 00:27:40,190
email every day and say it's easy got it

633
00:27:37,820 --> 00:27:42,950
emails incredibly dangerous I mean

634
00:27:40,190 --> 00:27:44,570
stepping aside from phishing and Malware

635
00:27:42,950 --> 00:27:46,730
and all that fun stuff the amount of

636
00:27:44,570 --> 00:27:48,168
incidents caused by people BC seeing or

637
00:27:46,730 --> 00:27:50,179
see seeing when they should have been BC

638
00:27:48,169 --> 00:27:54,350
seeing or attaching files or sending out

639
00:27:50,179 --> 00:27:57,139
documents the wrong person email and

640
00:27:54,350 --> 00:27:59,779
email complacency results in a decline

641
00:27:57,139 --> 00:28:00,139
in vigilance and important signals get

642
00:27:59,779 --> 00:28:02,269
missed

643
00:28:00,139 --> 00:28:03,649
particularly hey this was a real

644
00:28:02,269 --> 00:28:05,990
phishing attack bad we don't bother

645
00:28:03,649 --> 00:28:07,908
reporting out here emails safe I don't

646
00:28:05,990 --> 00:28:10,130
need to worry about that and the

647
00:28:07,909 --> 00:28:13,909
individual only sees what they expect to

648
00:28:10,130 --> 00:28:16,510
see no how do we deal with complacency

649
00:28:13,909 --> 00:28:19,190
specifically in the example of email

650
00:28:16,510 --> 00:28:22,549
implement a fully randomized phishing

651
00:28:19,190 --> 00:28:24,230
campaign why because it keeps people on

652
00:28:22,549 --> 00:28:24,590
their toes they don't know when it's

653
00:28:24,230 --> 00:28:26,990
coming

654
00:28:24,590 --> 00:28:28,490
do it monthly I can't tell you the

655
00:28:26,990 --> 00:28:30,139
number of times you run into clients and

656
00:28:28,490 --> 00:28:31,970
they'll tell us what we do an annual

657
00:28:30,139 --> 00:28:34,539
fishing exercise it's next to useless

658
00:28:31,970 --> 00:28:36,740
it's not a baseline it's not helping

659
00:28:34,539 --> 00:28:38,240
educate folks as effectively as it could

660
00:28:36,740 --> 00:28:39,529
be and it's certainly not combating

661
00:28:38,240 --> 00:28:41,330
complacency now

662
00:28:39,529 --> 00:28:43,130
phishing everyone every week you're

663
00:28:41,330 --> 00:28:44,990
probably going to annoy everybody but

664
00:28:43,130 --> 00:28:47,419
monthly randomly will give you some

665
00:28:44,990 --> 00:28:49,309
great data will help people enter you up

666
00:28:47,419 --> 00:28:50,600
keep you on our toll tones and when you

667
00:28:49,309 --> 00:28:53,000
tell them you're doing this on a regular

668
00:28:50,600 --> 00:28:58,709
random basis monthly you're helping

669
00:28:53,000 --> 00:29:01,499
combat complacency all right

670
00:28:58,710 --> 00:29:04,419
implementing the Dirty Dozen in cyber

671
00:29:01,499 --> 00:29:06,039
leverage technology and platforms to

672
00:29:04,419 --> 00:29:08,309
automate as much of the routine

673
00:29:06,039 --> 00:29:11,740
cybersecurity awareness activities and

674
00:29:08,309 --> 00:29:14,350
get out of the compliance game really

675
00:29:11,740 --> 00:29:16,269
grow and you grow by transforming your

676
00:29:14,350 --> 00:29:19,769
programs focus from awareness training

677
00:29:16,269 --> 00:29:22,960
to human factors based behavior change

678
00:29:19,769 --> 00:29:24,850
and and think about adopting black box

679
00:29:22,960 --> 00:29:27,429
thinking on cyber in sense now

680
00:29:24,850 --> 00:29:30,129
black box thinking is a fantastic book

681
00:29:27,429 --> 00:29:32,320
by Matthew Syed and in the book they

682
00:29:30,129 --> 00:29:34,178
talk about the aviation industry and the

683
00:29:32,320 --> 00:29:36,668
culture they've created because when

684
00:29:34,179 --> 00:29:39,549
accidents happen in aviation they

685
00:29:36,669 --> 00:29:42,129
usually come at a high cost in blood and

686
00:29:39,549 --> 00:29:43,899
they view that the lessons to be learned

687
00:29:42,129 --> 00:29:46,299
have been paid with a high price and the

688
00:29:43,899 --> 00:29:47,949
knowledge is shared broadly and there's

689
00:29:46,299 --> 00:29:50,320
not a blame culture but when things go

690
00:29:47,950 --> 00:29:52,179
wrong it's what went wrong how did it go

691
00:29:50,320 --> 00:29:54,039
wrong where do we collect the data what

692
00:29:52,179 --> 00:29:57,100
do we learn for this how do we share

693
00:29:54,039 --> 00:29:59,408
those learnings and you have to gather

694
00:29:57,100 --> 00:30:01,059
data on your real incidents we need to

695
00:29:59,409 --> 00:30:03,429
do a better job in our instant response

696
00:30:01,059 --> 00:30:05,139
perhaps even creating a checklist using

697
00:30:03,429 --> 00:30:07,029
the Dirty Dozen as a foundation to

698
00:30:05,139 --> 00:30:09,668
evaluate the presence of one or more

699
00:30:07,029 --> 00:30:12,399
human factors track that data report

700
00:30:09,669 --> 00:30:14,019
back on it and use that as the buy-in to

701
00:30:12,399 --> 00:30:15,729
potentially support some of the

702
00:30:14,019 --> 00:30:20,440
countermeasures we've discussed today

703
00:30:15,730 --> 00:30:22,840
and you can put all of this activity in

704
00:30:20,440 --> 00:30:25,600
a framework that we've talked about

705
00:30:22,840 --> 00:30:28,330
before and it's a framework for success

706
00:30:25,600 --> 00:30:30,879
and the framework is a human factors

707
00:30:28,330 --> 00:30:34,539
focus security awareness behavior change

708
00:30:30,879 --> 00:30:36,879
program that creates real measurable

709
00:30:34,539 --> 00:30:39,039
metrics and data points by collecting

710
00:30:36,879 --> 00:30:41,980
good data analyzing good data and

711
00:30:39,039 --> 00:30:44,110
leveraging automation to focus more on

712
00:30:41,980 --> 00:30:46,869
the content and quality of our programs

713
00:30:44,110 --> 00:30:48,129
and strategies than just all the

714
00:30:46,869 --> 00:30:51,249
day-to-day activities of getting this

715
00:30:48,129 --> 00:30:53,918
compliance activity up and running I'll

716
00:30:51,249 --> 00:30:56,350
leave with one final pitch pandemic a

717
00:30:53,919 --> 00:30:58,210
lot of people are reading and there's

718
00:30:56,350 --> 00:31:01,719
Heather's pics I think four chapters are

719
00:30:58,210 --> 00:31:03,639
indigo and these are my picks nudge is a

720
00:31:01,720 --> 00:31:06,249
phenomenal book about behavioral science

721
00:31:03,639 --> 00:31:07,899
the human use of human beings is Norbert

722
00:31:06,249 --> 00:31:10,450
whiner the father of automation and

723
00:31:07,899 --> 00:31:11,229
cyber Security's readable book I don't

724
00:31:10,450 --> 00:31:13,210
recommend

725
00:31:11,230 --> 00:31:16,540
reading his book cybernetics unless

726
00:31:13,210 --> 00:31:18,580
you're hardcore into math not this is

727
00:31:16,540 --> 00:31:21,760
the the human one to read and there's

728
00:31:18,580 --> 00:31:23,710
some really key insights you know we're

729
00:31:21,760 --> 00:31:26,290
talking fifty years ago actually seventy

730
00:31:23,710 --> 00:31:28,510
years ago in some cases that are so

731
00:31:26,290 --> 00:31:30,428
applicable today Dan are really

732
00:31:28,510 --> 00:31:32,590
predictably irrational talking about the

733
00:31:30,429 --> 00:31:35,230
in rationality and then decision-making

734
00:31:32,590 --> 00:31:38,740
in humans and Matthew Said's black box

735
00:31:35,230 --> 00:31:42,340
thinking that is my presentation I will

736
00:31:38,740 --> 00:31:52,840
pause it is 135 so I'm on time happy to

737
00:31:42,340 --> 00:31:55,209
take any questions awesome dude thank

738
00:31:52,840 --> 00:31:59,080
you so much for that that was excellent

739
00:31:55,210 --> 00:32:08,350
that really was and we have two

740
00:31:59,080 --> 00:32:11,740
questions up right now see the first one

741
00:32:08,350 --> 00:32:14,709
is referring back to the start of the

742
00:32:11,740 --> 00:32:17,110
slide and it was the talk about pressure

743
00:32:14,710 --> 00:32:19,419
and it the question is isn't pressure a

744
00:32:17,110 --> 00:32:22,059
problem of not having clear priorities

745
00:32:19,419 --> 00:32:26,640
and the ability to let less urgent

746
00:32:22,059 --> 00:32:29,049
things slide huh interesting

747
00:32:26,640 --> 00:32:32,110
from from the reading and research and

748
00:32:29,049 --> 00:32:33,940
personal experience I've had yeah there

749
00:32:32,110 --> 00:32:36,370
is the there is definitely a case to me

750
00:32:33,940 --> 00:32:38,559
about prioritization and about about

751
00:32:36,370 --> 00:32:39,459
closing that loop back so there's

752
00:32:38,559 --> 00:32:41,649
there's there's a story about

753
00:32:39,460 --> 00:32:43,179
assertiveness like the ability and

754
00:32:41,650 --> 00:32:45,429
willingness for the individual and the

755
00:32:43,179 --> 00:32:47,320
psychological safety to feel like they

756
00:32:45,429 --> 00:32:50,049
can talk to their boss supervisor or

757
00:32:47,320 --> 00:32:52,629
leader saying listen like I can only do

758
00:32:50,049 --> 00:32:56,799
so much that the quality and the safety

759
00:32:52,630 --> 00:32:58,510
required to do X tasks here's what I

760
00:32:56,799 --> 00:33:01,210
think is the priorities based on my

761
00:32:58,510 --> 00:33:03,610
understanding can you clarify but people

762
00:33:01,210 --> 00:33:07,360
are terrified in many cases in many

763
00:33:03,610 --> 00:33:09,129
organizations to say no they just pile

764
00:33:07,360 --> 00:33:10,479
the work on they work the long hours and

765
00:33:09,130 --> 00:33:13,000
they work the long hours they get that

766
00:33:10,480 --> 00:33:16,270
email it looks like the CEO needs that

767
00:33:13,000 --> 00:33:17,890
wire transfer click yeah sure here's

768
00:33:16,270 --> 00:33:21,010
your money and away they go

769
00:33:17,890 --> 00:33:22,210
right so this is where we can we talk

770
00:33:21,010 --> 00:33:23,650
about cyber and we talk about a

771
00:33:22,210 --> 00:33:24,210
multidisciplinary approach and why it

772
00:33:23,650 --> 00:33:26,520
has to be

773
00:33:24,210 --> 00:33:28,530
more than just the IT team is that we

774
00:33:26,520 --> 00:33:32,430
need to create the systems processes and

775
00:33:28,530 --> 00:33:35,160
conversations in HR in leadership

776
00:33:32,430 --> 00:33:37,790
development and in management to reduce

777
00:33:35,160 --> 00:33:40,530
these risks because I believe

778
00:33:37,790 --> 00:33:42,870
technologically we are in a pretty

779
00:33:40,530 --> 00:33:44,820
advanced state with various security

780
00:33:42,870 --> 00:33:47,429
controls and the biggest barriers in

781
00:33:44,820 --> 00:33:49,409
most organizations is budget IT time etc

782
00:33:47,430 --> 00:33:49,740
I don't think there's a lot more to be

783
00:33:49,410 --> 00:33:51,150
gained

784
00:33:49,740 --> 00:33:53,430
technologically just like there wasn't

785
00:33:51,150 --> 00:33:55,830
more to be gained Aviation wise we're

786
00:33:53,430 --> 00:33:57,600
gonna have to dig deeper on the culture

787
00:33:55,830 --> 00:33:59,340
and people side if we're going to change

788
00:33:57,600 --> 00:34:01,909
the story of social engineering cyber

789
00:33:59,340 --> 00:34:06,300
risk and other things

790
00:34:01,910 --> 00:34:07,740
nice another question that came in here

791
00:34:06,300 --> 00:34:10,020
do you have any advice for getting

792
00:34:07,740 --> 00:34:12,620
management to buy-in for adopting a

793
00:34:10,020 --> 00:34:15,929
fishing / training testing environment

794
00:34:12,620 --> 00:34:20,639
when they feel it would make IT the bad

795
00:34:15,929 --> 00:34:22,710
guys control the users yeah yeah no well

796
00:34:20,639 --> 00:34:25,620
so the first off is is about creating a

797
00:34:22,710 --> 00:34:27,360
culture of that black box thinking like

798
00:34:25,620 --> 00:34:29,009
it's not about first of all when you

799
00:34:27,360 --> 00:34:30,870
create a fishing campaign be very

800
00:34:29,010 --> 00:34:33,960
transparent with management end-users

801
00:34:30,870 --> 00:34:35,880
no one's getting fired because this okay

802
00:34:33,960 --> 00:34:37,920
so it's not us versus them so I'm at

803
00:34:35,880 --> 00:34:40,410
Rick you know and talk about it in

804
00:34:37,920 --> 00:34:43,409
medical terms and in fact now more than

805
00:34:40,409 --> 00:34:45,899
ever those terms are more irrelevant hey

806
00:34:43,409 --> 00:34:47,730
when we do fishing it's like a vaccine

807
00:34:45,900 --> 00:34:49,860
it's like an inoculation you'd rather

808
00:34:47,730 --> 00:34:52,110
get it from us in a safe way then I have

809
00:34:49,860 --> 00:34:54,000
a real one hit you and learn the painful

810
00:34:52,110 --> 00:34:55,800
way and so that's what this is about

811
00:34:54,000 --> 00:34:57,750
it's about creating interative learning

812
00:34:55,800 --> 00:34:59,460
opportunities and a chance for you to

813
00:34:57,750 --> 00:35:00,720
learn and grow now if you demonstrate

814
00:34:59,460 --> 00:35:01,920
that you just want to click on

815
00:35:00,720 --> 00:35:03,209
everything and you never want to change

816
00:35:01,920 --> 00:35:06,030
your behavior that's a different

817
00:35:03,210 --> 00:35:09,030
conversation but most people want to do

818
00:35:06,030 --> 00:35:11,340
the right thing and I would say it's

819
00:35:09,030 --> 00:35:14,340
it's super cute they worry about the IT

820
00:35:11,340 --> 00:35:15,690
team being the bad cats but right now

821
00:35:14,340 --> 00:35:17,340
the real bad cats don't care about all

822
00:35:15,690 --> 00:35:19,470
that and they're not stopping their

823
00:35:17,340 --> 00:35:21,810
fishing it's the same conversation I

824
00:35:19,470 --> 00:35:23,370
often have when they're like we the

825
00:35:21,810 --> 00:35:24,779
senior management will only let us fish

826
00:35:23,370 --> 00:35:26,400
quarterly and like really criminal is

827
00:35:24,780 --> 00:35:29,700
not accommodating they only pick one

828
00:35:26,400 --> 00:35:30,660
campaign no okay you need to if your

829
00:35:29,700 --> 00:35:34,100
simulations are going to mean anything

830
00:35:30,660 --> 00:35:34,100
it has to look like real world

831
00:35:36,350 --> 00:35:42,299
nice another one here if 80% of the

832
00:35:40,080 --> 00:35:44,730
breaches are a result of using easily

833
00:35:42,300 --> 00:35:46,800
guessed stolen lost passwords what

834
00:35:44,730 --> 00:35:48,900
specifically do you see companies doing

835
00:35:46,800 --> 00:35:50,720
about this corporate password managers

836
00:35:48,900 --> 00:35:55,470
two-factor authentication awareness

837
00:35:50,720 --> 00:35:57,209
stuff like that oh yeah so so number one

838
00:35:55,470 --> 00:36:00,720
I am a huge fan of two of thing

839
00:35:57,210 --> 00:36:03,720
Microsoft's got massive research huge

840
00:36:00,720 --> 00:36:06,509
data set you put two FA in place you cut

841
00:36:03,720 --> 00:36:09,600
brute force password guessing password

842
00:36:06,510 --> 00:36:12,750
reuse by 99.9% period end of story

843
00:36:09,600 --> 00:36:14,580
done now implementing two of a complex

844
00:36:12,750 --> 00:36:15,410
organizational environments not for the

845
00:36:14,580 --> 00:36:18,150
faint of heart

846
00:36:15,410 --> 00:36:20,819
understood but so the solutions their

847
00:36:18,150 --> 00:36:24,450
ease of implementation not and I think

848
00:36:20,820 --> 00:36:26,010
two F a password manager tools with sort

849
00:36:24,450 --> 00:36:27,810
of an understanding about what may or

850
00:36:26,010 --> 00:36:29,370
may not belong in the password manager

851
00:36:27,810 --> 00:36:31,049
so you can encourage people to avoid

852
00:36:29,370 --> 00:36:34,560
password reuse but they actually can

853
00:36:31,050 --> 00:36:36,840
create a significant you know unique

854
00:36:34,560 --> 00:36:39,090
password for work but the rest of their

855
00:36:36,840 --> 00:36:40,610
stuff is managed and different can be

856
00:36:39,090 --> 00:36:43,380
ways of mitigating some of those risks

857
00:36:40,610 --> 00:36:45,480
and it is an attitude thing we've done

858
00:36:43,380 --> 00:36:47,250
some really interesting research you

859
00:36:45,480 --> 00:36:49,830
know most people want to do the right

860
00:36:47,250 --> 00:36:52,500
things with passwords but didn't know

861
00:36:49,830 --> 00:36:55,920
what to do to manage that guy ain't I've

862
00:36:52,500 --> 00:36:58,860
got 400 passwords now I use a password

863
00:36:55,920 --> 00:37:00,360
manager because I know the risk of my

864
00:36:58,860 --> 00:37:02,100
password manager getting breached so a

865
00:37:00,360 --> 00:37:04,440
lot less than one of them 400 sites

866
00:37:02,100 --> 00:37:06,450
getting popped not telling me about it

867
00:37:04,440 --> 00:37:08,340
we use my creds getting reused and

868
00:37:06,450 --> 00:37:16,200
getting blown wide open by a pattern

869
00:37:08,340 --> 00:37:18,420
match so that's my view on that next

870
00:37:16,200 --> 00:37:21,089
question do you have any advice for

871
00:37:18,420 --> 00:37:25,200
getting management buy-in for adopting

872
00:37:21,090 --> 00:37:27,540
phishing training or testing when second

873
00:37:25,200 --> 00:37:31,620
part is when they feel it would make the

874
00:37:27,540 --> 00:37:32,880
IT the bad guys so so we we capped on

875
00:37:31,620 --> 00:37:35,370
the bad guy thing although I will build

876
00:37:32,880 --> 00:37:38,610
on that one of the things is that you

877
00:37:35,370 --> 00:37:40,140
can do and I did this at UNB is we were

878
00:37:38,610 --> 00:37:41,790
getting fished and we were dealing with

879
00:37:40,140 --> 00:37:45,299
the real incidents so sometimes in

880
00:37:41,790 --> 00:37:48,779
cybersecurity never waste a crisis and

881
00:37:45,300 --> 00:37:49,540
in our case what happened was we had

882
00:37:48,780 --> 00:37:51,430
fish by

883
00:37:49,540 --> 00:37:53,440
Southeast Asian gang and they targeted

884
00:37:51,430 --> 00:37:55,060
the athletics department they got a

885
00:37:53,440 --> 00:37:57,040
bunch of creds from there they waited

886
00:37:55,060 --> 00:37:58,779
till two o'clock in the morning we

887
00:37:57,040 --> 00:38:00,930
didn't have outgoing email controls in

888
00:37:58,780 --> 00:38:02,830
place so they puked out a million

889
00:38:00,930 --> 00:38:04,960
malicious messages around the world

890
00:38:02,830 --> 00:38:07,360
which got us on everybody's blacklist

891
00:38:04,960 --> 00:38:09,730
and and eunb couldn't communicate to the

892
00:38:07,360 --> 00:38:11,470
government in New Brunswick to Google to

893
00:38:09,730 --> 00:38:14,680
a bunch place so business impact and

894
00:38:11,470 --> 00:38:17,109
pain was real and then after the cleanup

895
00:38:14,680 --> 00:38:18,759
of that particular incident which I used

896
00:38:17,110 --> 00:38:21,280
to put a bunch of new policies in place

897
00:38:18,760 --> 00:38:22,840
we were then you know how to have runway

898
00:38:21,280 --> 00:38:24,250
and buy-in to start building towards

899
00:38:22,840 --> 00:38:26,830
okay well maybe we need to understand

900
00:38:24,250 --> 00:38:28,330
how vulnerable we are to phishing and so

901
00:38:26,830 --> 00:38:30,850
sometimes phrasing it as an experiment

902
00:38:28,330 --> 00:38:33,009
can can help you get that in and then

903
00:38:30,850 --> 00:38:35,650
you show some results and like this is

904
00:38:33,010 --> 00:38:37,750
how about it is and then they they buy

905
00:38:35,650 --> 00:38:40,030
in and sometimes they buy in a big way

906
00:38:37,750 --> 00:38:42,010
when I showed that we had a 35% click

907
00:38:40,030 --> 00:38:44,740
rate on a well-crafted spearfishing

908
00:38:42,010 --> 00:38:46,840
campaign for password capture executives

909
00:38:44,740 --> 00:38:48,970
were so bought in that when lower-level

910
00:38:46,840 --> 00:38:50,230
folks were complaining why is IT

911
00:38:48,970 --> 00:38:52,089
phishing us it's a waste of time

912
00:38:50,230 --> 00:38:54,460
they're like until we get the click rate

913
00:38:52,090 --> 00:38:57,550
below 5% we're going to keep fishing

914
00:38:54,460 --> 00:38:57,550
[Music]

915
00:39:06,230 --> 00:39:10,100
what are your suggestions for easy or

916
00:39:08,060 --> 00:39:14,080
cheap victories for organizations that

917
00:39:10,100 --> 00:39:17,029
don't have dedicated tech people Oh

918
00:39:14,080 --> 00:39:18,080
easier cheap victories for organizations

919
00:39:17,030 --> 00:39:21,859
that don't have tech people with respect

920
00:39:18,080 --> 00:39:24,799
to the human side of cyber and getting

921
00:39:21,859 --> 00:39:27,500
getting a platform in place to start

922
00:39:24,800 --> 00:39:29,210
gathering data educating and working the

923
00:39:27,500 --> 00:39:30,710
human side can have a huge reduction

924
00:39:29,210 --> 00:39:32,510
risk in it and I'll give you a tangible

925
00:39:30,710 --> 00:39:34,190
example when the University of Calgary

926
00:39:32,510 --> 00:39:37,180
got hit back when I was running security

927
00:39:34,190 --> 00:39:40,460
for UNB we were typically getting about

928
00:39:37,180 --> 00:39:42,440
125,000 140,000 malicious attachment

929
00:39:40,460 --> 00:39:45,020
email attacks per month after calgary

930
00:39:42,440 --> 00:39:47,869
got hit that surged to 1.25 million and

931
00:39:45,020 --> 00:39:50,600
our security tools were only 97%

932
00:39:47,869 --> 00:39:52,670
effective in both cases and 3% getting

933
00:39:50,600 --> 00:39:55,730
through at 1.25 million s bigger number

934
00:39:52,670 --> 00:39:57,500
than 3% of 125,000 and what was

935
00:39:55,730 --> 00:39:59,359
interesting was because we had worked

936
00:39:57,500 --> 00:40:01,760
the human side we'd had that phishing

937
00:39:59,359 --> 00:40:03,590
campaign we'd lowered that click rate we

938
00:40:01,760 --> 00:40:05,900
didn't get a you sunk my battleship

939
00:40:03,590 --> 00:40:07,430
moment where someone where a bunch of

940
00:40:05,900 --> 00:40:10,340
folks had clicked to that particular

941
00:40:07,430 --> 00:40:12,919
campaign so so the human side can often

942
00:40:10,340 --> 00:40:15,560
drive really quick gains and reduction

943
00:40:12,920 --> 00:40:17,510
of risk and any if you do it right and

944
00:40:15,560 --> 00:40:19,549
you gather data from the campaigns and

945
00:40:17,510 --> 00:40:21,920
we do that when our and our approach

946
00:40:19,550 --> 00:40:24,530
through automated surveys you get all

947
00:40:21,920 --> 00:40:27,200
kinds of new ammunition to win political

948
00:40:24,530 --> 00:40:29,960
or budget from senior decision-makers to

949
00:40:27,200 --> 00:40:38,868
start whittling down your your security

950
00:40:29,960 --> 00:40:42,950
debt awesome one more question and this

951
00:40:38,869 --> 00:40:46,490
was actually one from me when you doing

952
00:40:42,950 --> 00:40:49,359
phishing campaigns in an organization do

953
00:40:46,490 --> 00:40:51,799
you as and now this is you yourself

954
00:40:49,359 --> 00:40:54,080
generally have any boundaries or any

955
00:40:51,800 --> 00:40:56,810
lines that you won't cross for the types

956
00:40:54,080 --> 00:40:59,660
of questions because there's lots of

957
00:40:56,810 --> 00:41:02,359
questions that there's lots of good you

958
00:40:59,660 --> 00:41:05,359
know good as an effective phishing

959
00:41:02,359 --> 00:41:07,670
campaigns real ones yeah you know taking

960
00:41:05,359 --> 00:41:10,580
Ashley Madison and things like that

961
00:41:07,670 --> 00:41:14,180
but these are very unprofessional yeah

962
00:41:10,580 --> 00:41:17,869
you never want to do that no I so I view

963
00:41:14,180 --> 00:41:19,368
using sex and romance scams as the cyber

964
00:41:17,869 --> 00:41:19,860
security simulation equivalent of

965
00:41:19,369 --> 00:41:23,550
throwing

966
00:41:19,860 --> 00:41:25,530
in a fishpond yeah you're gonna be super

967
00:41:23,550 --> 00:41:29,760
successful and it's going to be an awful

968
00:41:25,530 --> 00:41:32,550
awful mess you have to clean up so don't

969
00:41:29,760 --> 00:41:34,860
do it we know that we mean there's

970
00:41:32,550 --> 00:41:36,360
enough cognitive science that people in

971
00:41:34,860 --> 00:41:38,160
an emotionally or sexually around the

972
00:41:36,360 --> 00:41:40,740
state their judgement and information

973
00:41:38,160 --> 00:41:42,299
processing capability is declined you're

974
00:41:40,740 --> 00:41:46,020
not teaching them anything that way

975
00:41:42,300 --> 00:41:47,730
there are other ways gentler kinder HR

976
00:41:46,020 --> 00:41:49,740
and legal respecting ways to teach

977
00:41:47,730 --> 00:41:51,780
people about sextortion scams and other

978
00:41:49,740 --> 00:41:54,770
things you know it kind of need to be

979
00:41:51,780 --> 00:41:58,050
the doctor Ruth right scientific clear

980
00:41:54,770 --> 00:42:00,990
language about safe cyber particularly

981
00:41:58,050 --> 00:42:02,250
the safe cyber romance aspects but not

982
00:42:00,990 --> 00:42:06,629
putting people through that particular

983
00:42:02,250 --> 00:42:08,130
trauma so there are lines that need to

984
00:42:06,630 --> 00:42:10,260
be established and boundaries that can't

985
00:42:08,130 --> 00:42:12,870
be crossed and each organizational

986
00:42:10,260 --> 00:42:15,240
culture less severe than say sex like

987
00:42:12,870 --> 00:42:17,220
the use or not use of branded fishes I

988
00:42:15,240 --> 00:42:18,419
used to believe that branded fish has

989
00:42:17,220 --> 00:42:20,279
made a huge difference we've

990
00:42:18,420 --> 00:42:22,290
scientifically or at least statistically

991
00:42:20,280 --> 00:42:23,850
proven that there is no difference

992
00:42:22,290 --> 00:42:27,930
between branded and really good

993
00:42:23,850 --> 00:42:30,180
unbranded so what I can tell you one

994
00:42:27,930 --> 00:42:32,700
lesson though about a perfectly ethical

995
00:42:30,180 --> 00:42:34,200
fish and it was a brilliant team I'm not

996
00:42:32,700 --> 00:42:36,930
allowed to say which financial

997
00:42:34,200 --> 00:42:39,689
institution they work for but they had

998
00:42:36,930 --> 00:42:43,230
some smart smart people and it was just

999
00:42:39,690 --> 00:42:46,260
a single line you've received a calendar

1000
00:42:43,230 --> 00:42:49,860
invite with a with an iCal icon and that

1001
00:42:46,260 --> 00:42:52,860
sucker was dynamite and we're talking

1002
00:42:49,860 --> 00:42:58,920
high double-digit click rate because it

1003
00:42:52,860 --> 00:43:01,680
was simple fast and effective all for

1004
00:42:58,920 --> 00:43:04,950
one once my company and I was so close

1005
00:43:01,680 --> 00:43:07,200
to falling for it and it was a survey

1006
00:43:04,950 --> 00:43:11,609
asking what flavor chips you want to

1007
00:43:07,200 --> 00:43:15,230
have in the break rooms delivered oh I'm

1008
00:43:11,610 --> 00:43:19,350
stealing that idea that survey

1009
00:43:15,230 --> 00:43:20,760
interesting thank you all for the great

1010
00:43:19,350 --> 00:43:22,620
questions for making me feel welcome

1011
00:43:20,760 --> 00:43:24,390
it's it's digitally intimidating or

1012
00:43:22,620 --> 00:43:25,950
intimidating to us digitally the

1013
00:43:24,390 --> 00:43:27,900
organized committee has done a fantastic

1014
00:43:25,950 --> 00:43:29,669
job with this thanks for all the tech

1015
00:43:27,900 --> 00:43:31,269
support getting set up and the chance to

1016
00:43:29,670 --> 00:43:33,969
do the beta run

1017
00:43:31,269 --> 00:43:35,468
this talk I'd welcome any feedback you

1018
00:43:33,969 --> 00:43:38,949
can reach out to me David at Bose around

1019
00:43:35,469 --> 00:43:40,599
security calm my on Twitter would love

1020
00:43:38,949 --> 00:43:43,359
thoughts how can I make this better

1021
00:43:40,599 --> 00:43:44,769
nice actually uh it seemed to go very

1022
00:43:43,359 --> 00:43:46,538
well we asked them even more questions

1023
00:43:44,769 --> 00:43:48,549
that come in so if you got another few

1024
00:43:46,539 --> 00:43:50,709
seconds we can answer a couple more well

1025
00:43:48,549 --> 00:43:53,589
if that works for you guys perfect okay

1026
00:43:50,709 --> 00:43:56,019
so as an external consultant how do you

1027
00:43:53,589 --> 00:43:57,459
convince an organization to focus on the

1028
00:43:56,019 --> 00:44:00,189
people and strategies before

1029
00:43:57,459 --> 00:44:03,848
implementing technological solutions or

1030
00:44:00,189 --> 00:44:06,759
controls storytelling and when when we

1031
00:44:03,849 --> 00:44:08,349
start highlighting what cyber is what it

1032
00:44:06,759 --> 00:44:09,729
means that it's people in control of

1033
00:44:08,349 --> 00:44:11,319
technology when we go back to the

1034
00:44:09,729 --> 00:44:13,749
fundamentals of business you look at any

1035
00:44:11,319 --> 00:44:14,919
business day and most executives will

1036
00:44:13,749 --> 00:44:17,468
admit well our people are our most

1037
00:44:14,919 --> 00:44:18,669
valuable asset they are and they're

1038
00:44:17,469 --> 00:44:21,519
where you should be starting your

1039
00:44:18,669 --> 00:44:23,769
defensive approach because they can be a

1040
00:44:21,519 --> 00:44:26,078
huge benefit know the downside in our

1041
00:44:23,769 --> 00:44:28,359
industry is way too often I was guilty

1042
00:44:26,079 --> 00:44:30,399
of this at one point we all say it

1043
00:44:28,359 --> 00:44:33,848
warmer in our IT crew all the users are

1044
00:44:30,399 --> 00:44:35,739
stupid now they're not stupid we've got

1045
00:44:33,849 --> 00:44:37,719
gaps in the pair model where we haven't

1046
00:44:35,739 --> 00:44:39,639
addressed and we can address those

1047
00:44:37,719 --> 00:44:41,319
dramatically impact the number one

1048
00:44:39,639 --> 00:44:44,979
source of malicious attacks which is

1049
00:44:41,319 --> 00:44:46,599
scientifically proven and reduce cost in

1050
00:44:44,979 --> 00:44:48,459
it in one of the most cost-effective

1051
00:44:46,599 --> 00:44:50,649
ways like I can tell you for large

1052
00:44:48,459 --> 00:44:52,209
organizations we work with the

1053
00:44:50,649 --> 00:44:54,069
technology we've implemented is a

1054
00:44:52,209 --> 00:44:56,439
rounding cost on their security budget

1055
00:44:54,069 --> 00:45:00,339
like a small percentage rounding us and

1056
00:44:56,439 --> 00:45:01,868
its impact is so disproportionate so in

1057
00:45:00,339 --> 00:45:04,630
many cases like listen we have a huge

1058
00:45:01,869 --> 00:45:06,459
impact fast give you data help you make

1059
00:45:04,630 --> 00:45:09,009
better decisions and help you drive

1060
00:45:06,459 --> 00:45:11,009
better budget spent and that's the

1061
00:45:09,009 --> 00:45:13,359
conversation you should be having

1062
00:45:11,009 --> 00:45:15,099
perfect and then I think this will be

1063
00:45:13,359 --> 00:45:18,279
our last question just for the sake of

1064
00:45:15,099 --> 00:45:22,779
time kind of talking about those smart

1065
00:45:18,279 --> 00:45:24,849
employees you know let's see staff can

1066
00:45:22,779 --> 00:45:27,369
be smart and lazy enough to create rules

1067
00:45:24,849 --> 00:45:31,359
to filter simulated phishing emails so

1068
00:45:27,369 --> 00:45:33,099
they won't be hit so so they will be hit

1069
00:45:31,359 --> 00:45:34,209
by the real ones not the fake ones any

1070
00:45:33,099 --> 00:45:36,179
thoughts on that

1071
00:45:34,209 --> 00:45:39,788
teaching them why that's

1072
00:45:36,179 --> 00:45:42,189
counterproductive to them learning and

1073
00:45:39,789 --> 00:45:44,619
benefiting scanning to see who's got

1074
00:45:42,189 --> 00:45:45,328
those rules set up and about it like

1075
00:45:44,619 --> 00:45:47,489
listen

1076
00:45:45,329 --> 00:45:50,400
you know it's like you skipping out on

1077
00:45:47,489 --> 00:45:52,049
your your vaccine and your your

1078
00:45:50,400 --> 00:45:53,400
necessary medicine I don't get Indiana

1079
00:45:52,049 --> 00:45:54,690
backs your thing that's over beer

1080
00:45:53,400 --> 00:45:56,660
sometime

1081
00:45:54,690 --> 00:45:59,039
but but point being like it's a

1082
00:45:56,660 --> 00:46:01,739
reinforcing the educational importance

1083
00:45:59,039 --> 00:46:03,390
of what you're trying to do and also the

1084
00:46:01,739 --> 00:46:05,789
most powerful thing I ever unleashed in

1085
00:46:03,390 --> 00:46:07,440
IT the very first time work in an alpha

1086
00:46:05,789 --> 00:46:08,759
project on beauceron like the training

1087
00:46:07,440 --> 00:46:10,789
and the survey and it was completely

1088
00:46:08,759 --> 00:46:15,119
voluntary with the IT department was

1089
00:46:10,789 --> 00:46:18,150
convincing hey I want to be affectionate

1090
00:46:15,119 --> 00:46:20,880
the longest service Krusty assisted man

1091
00:46:18,150 --> 00:46:22,349
had been around since UNIX was a baby he

1092
00:46:20,880 --> 00:46:24,029
went and did it he got the best score

1093
00:46:22,349 --> 00:46:25,499
and then he would not stop bragging

1094
00:46:24,029 --> 00:46:28,380
about that score to everybody else and

1095
00:46:25,499 --> 00:46:29,939
so creating new ways of game of fiying

1096
00:46:28,380 --> 00:46:30,959
not to say well if you're not getting

1097
00:46:29,940 --> 00:46:32,579
them you're just getting deleted then

1098
00:46:30,959 --> 00:46:34,078
you're not reporting them which is one

1099
00:46:32,579 --> 00:46:37,289
of the metrics we actually measure you

1100
00:46:34,079 --> 00:46:40,680
on and you know you could actually show

1101
00:46:37,289 --> 00:46:42,329
how how good you are at this and that

1102
00:46:40,680 --> 00:46:43,769
would be my thoughts on that is is

1103
00:46:42,329 --> 00:46:45,329
teaching people why the games being

1104
00:46:43,769 --> 00:46:47,819
played and why they shouldn't just opt

1105
00:46:45,329 --> 00:46:49,140
out of it nice I actually consulted with

1106
00:46:47,819 --> 00:46:50,819
a company in the past that did something

1107
00:46:49,140 --> 00:46:52,469
very similar with the gamification and

1108
00:46:50,819 --> 00:46:55,349
they actually went as far as making

1109
00:46:52,469 --> 00:46:56,969
these little fish trophies so no the

1110
00:46:55,349 --> 00:46:58,319
ploy with the most reported fish it's

1111
00:46:56,969 --> 00:47:00,989
actually got a trophy to put on their

1112
00:46:58,319 --> 00:47:02,819
desk to say I caught them yeah well in

1113
00:47:00,989 --> 00:47:05,249
moussa my friend he was the one that

1114
00:47:02,819 --> 00:47:07,380
taught me about the scarf model so the

1115
00:47:05,249 --> 00:47:08,788
status and recognition and I knew who

1116
00:47:07,380 --> 00:47:10,529
some of these things intuitively and it

1117
00:47:08,789 --> 00:47:12,349
taught some of my MBA but the way that

1118
00:47:10,529 --> 00:47:15,359
he powerfully explained it to me was

1119
00:47:12,349 --> 00:47:16,920
status and recognition are huge

1120
00:47:15,359 --> 00:47:18,959
a simple thank you a simple

1121
00:47:16,920 --> 00:47:20,670
acknowledgement and a UK firm I know

1122
00:47:18,959 --> 00:47:22,769
we're short for time a UK firm I love

1123
00:47:20,670 --> 00:47:23,729
this they had a clean desk competition

1124
00:47:22,769 --> 00:47:26,368
to keep mind they've got the whole

1125
00:47:23,729 --> 00:47:28,348
culture of houses and and sort of all

1126
00:47:26,369 --> 00:47:30,569
those things there and so the cleanest

1127
00:47:28,349 --> 00:47:33,299
Department got the house trophy for a

1128
00:47:30,569 --> 00:47:35,699
clean desk drop a policy and a party

1129
00:47:33,299 --> 00:47:40,049
with a cake and they loved it everyone

1130
00:47:35,699 --> 00:47:41,640
who loves cakes nice again we can't

1131
00:47:40,049 --> 00:47:43,440
thank you enough for taking part in this

1132
00:47:41,640 --> 00:47:45,479
event and helping us make it happen and

1133
00:47:43,440 --> 00:47:47,339
again it was a great presentation thank

1134
00:47:45,479 --> 00:47:50,779
you very much thanks so much everyone

1135
00:47:47,339 --> 00:47:50,779
take care of stay safe and stay healthy

