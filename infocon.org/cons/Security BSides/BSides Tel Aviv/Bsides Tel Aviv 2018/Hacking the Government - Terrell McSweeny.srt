1
00:00:00,000 --> 00:00:02,429
very good okay now now now we're on oh

2
00:00:02,429 --> 00:00:04,110
now I don't know which one it is the red

3
00:00:04,110 --> 00:00:06,839
one okay that's because there's just

4
00:00:06,839 --> 00:00:08,519
entirely too much drinking involved in

5
00:00:08,519 --> 00:00:11,070
this talk so hi I'm Terrell McSweeney I

6
00:00:11,070 --> 00:00:14,670
am your mystery speaker tonight I am

7
00:00:14,670 --> 00:00:16,770
going to make a presentation about how

8
00:00:16,770 --> 00:00:19,140
to hack government I am NOT a

9
00:00:19,140 --> 00:00:20,910
technologist I'm not a researcher and

10
00:00:20,910 --> 00:00:24,330
I'm definitely not a hacker so just a

11
00:00:24,330 --> 00:00:26,010
little bit about what this talk is

12
00:00:26,010 --> 00:00:28,859
actually about why am I here gonna start

13
00:00:28,859 --> 00:00:31,710
with the disclaimers it's not a Tech

14
00:00:31,710 --> 00:00:35,250
Talk I'm not dropping any exploits or

15
00:00:35,250 --> 00:00:37,710
providing you any useful knowledge about

16
00:00:37,710 --> 00:00:41,730
technology and I'm I'm not a hacker or

17
00:00:41,730 --> 00:00:44,190
researcher but I am a former government

18
00:00:44,190 --> 00:00:47,340
regulator so I recently was serving on

19
00:00:47,340 --> 00:00:49,260
the US Federal Trade Commission which is

20
00:00:49,260 --> 00:00:50,789
essentially the Data Protection

21
00:00:50,789 --> 00:00:52,949
Authority for the United States it's

22
00:00:52,949 --> 00:00:54,829
also an antitrust competition

23
00:00:54,829 --> 00:00:57,750
enforcement agency and has been in the

24
00:00:57,750 --> 00:00:59,579
news a lot lately because it has a lot

25
00:00:59,579 --> 00:01:01,739
of the major US tech companies under

26
00:01:01,739 --> 00:01:04,409
orders for previous privacy or data

27
00:01:04,409 --> 00:01:07,080
security violations and I'm also a

28
00:01:07,080 --> 00:01:09,600
policy person and a lawyer but one of

29
00:01:09,600 --> 00:01:11,010
the things I've really been working on

30
00:01:11,010 --> 00:01:13,590
in the u.s. is incorporating more

31
00:01:13,590 --> 00:01:16,409
hackers into policymaking

32
00:01:16,409 --> 00:01:18,600
I think the hacker community has

33
00:01:18,600 --> 00:01:20,850
incredibly important knowledge that

34
00:01:20,850 --> 00:01:23,340
needs to be brought to bear on policy

35
00:01:23,340 --> 00:01:24,840
makers so what I wanted to talk about

36
00:01:24,840 --> 00:01:27,090
today with some of the ways we've been

37
00:01:27,090 --> 00:01:29,909
doing that and try to convince you that

38
00:01:29,909 --> 00:01:32,250
you have a meaningful role to play in

39
00:01:32,250 --> 00:01:34,320
helping policymakers understand

40
00:01:34,320 --> 00:01:39,750
technology read one okay I'm going to be

41
00:01:39,750 --> 00:01:41,850
using a lot of Star Wars analogies

42
00:01:41,850 --> 00:01:43,560
because of the theme of today but also

43
00:01:43,560 --> 00:01:46,520
because of course I'm a Star Wars fan so

44
00:01:46,520 --> 00:01:49,770
this is actually an important quote from

45
00:01:49,770 --> 00:01:54,689
one of the original human to cyborg

46
00:01:54,689 --> 00:01:57,869
relation specialist c-3po remember that

47
00:01:57,869 --> 00:02:00,210
of course and these are actually some of

48
00:02:00,210 --> 00:02:02,310
the questions that were asked by United

49
00:02:02,310 --> 00:02:04,350
States senators recently in hearings

50
00:02:04,350 --> 00:02:07,530
that were on the Facebook Cambridge

51
00:02:07,530 --> 00:02:10,709
analytical scandal this was when Mark

52
00:02:10,709 --> 00:02:12,599
Zuckerberg famously was invited to

53
00:02:12,599 --> 00:02:13,950
testify before

54
00:02:13,950 --> 00:02:16,890
before the Senate and you know so

55
00:02:16,890 --> 00:02:18,959
there's some interesting knowledge gaps

56
00:02:18,959 --> 00:02:20,760
here if you're emailing within whatsapp

57
00:02:20,760 --> 00:02:24,020
for example so okay maybe just misspoke

58
00:02:24,020 --> 00:02:27,060
Facemash which was actually well there's

59
00:02:27,060 --> 00:02:30,060
like a mic now cool which was actually a

60
00:02:30,060 --> 00:02:32,489
joke saying that Mark Zuckerberg Giggs

61
00:02:32,489 --> 00:02:34,890
invented while he was in college no

62
00:02:34,890 --> 00:02:37,200
longer exists and this is my favorite

63
00:02:37,200 --> 00:02:38,700
question which was actually by Senator

64
00:02:38,700 --> 00:02:41,100
hatch and this is literally Mark

65
00:02:41,100 --> 00:02:43,160
Zuckerberg expression when it was asked

66
00:02:43,160 --> 00:02:45,959
how do you sustain a business model and

67
00:02:45,959 --> 00:02:47,910
which users do not pay for your service

68
00:02:47,910 --> 00:02:50,220
and there's this like pause if you watch

69
00:02:50,220 --> 00:02:52,049
the video of it and Zuckerberg kind of

70
00:02:52,049 --> 00:02:54,239
looks it in with this face as like is it

71
00:02:54,239 --> 00:02:56,870
a trick question

72
00:02:56,959 --> 00:03:00,390
it's like ads is that the answer yes of

73
00:03:00,390 --> 00:03:01,920
course it's the answer so yeah this is

74
00:03:01,920 --> 00:03:02,489
funny

75
00:03:02,489 --> 00:03:04,290
and I can and I've actually done

76
00:03:04,290 --> 00:03:06,299
versions of this talk before where I had

77
00:03:06,299 --> 00:03:09,480
different silly things politicians had

78
00:03:09,480 --> 00:03:11,640
said and political leaders had said

79
00:03:11,640 --> 00:03:13,620
about technology it's pretty easy to

80
00:03:13,620 --> 00:03:15,600
find it's a target-rich environment and

81
00:03:15,600 --> 00:03:18,000
it's easy to laugh at it and I think we

82
00:03:18,000 --> 00:03:19,739
should laugh at it a little bit but

83
00:03:19,739 --> 00:03:21,269
what's important to remember is that a

84
00:03:21,269 --> 00:03:22,890
lot of our elected officials it's

85
00:03:22,890 --> 00:03:24,269
certainly true in the US government but

86
00:03:24,269 --> 00:03:26,130
I suspect it's true in most governments

87
00:03:26,130 --> 00:03:28,530
around the world are basically normal

88
00:03:28,530 --> 00:03:30,540
people who are elected to represent

89
00:03:30,540 --> 00:03:32,730
their constituents and most of their

90
00:03:32,730 --> 00:03:34,049
constituents don't know very much about

91
00:03:34,049 --> 00:03:36,420
technology either so none of this should

92
00:03:36,420 --> 00:03:38,820
be very surprising to us but what is

93
00:03:38,820 --> 00:03:41,160
really important I think is to remember

94
00:03:41,160 --> 00:03:43,019
that even though it's a little bit funny

95
00:03:43,019 --> 00:03:45,150
that they don't know these things they

96
00:03:45,150 --> 00:03:47,609
are also in the position of writing the

97
00:03:47,609 --> 00:03:50,100
laws about them and the laws that not

98
00:03:50,100 --> 00:03:51,810
only govern the technology that is

99
00:03:51,810 --> 00:03:53,910
everywhere in our lives but also can

100
00:03:53,910 --> 00:03:56,370
have a direct impact on the kind of

101
00:03:56,370 --> 00:03:59,040
research and other work that you all are

102
00:03:59,040 --> 00:04:01,590
doing in this space so I think it's

103
00:04:01,590 --> 00:04:04,290
important to remember that they have a

104
00:04:04,290 --> 00:04:06,810
kind of power and we need to help them

105
00:04:06,810 --> 00:04:09,540
use it responsibly so how do we do that

106
00:04:09,540 --> 00:04:13,799
this is my my approximation of the point

107
00:04:13,799 --> 00:04:15,630
I was just making he's holding a thermal

108
00:04:15,630 --> 00:04:17,160
detonator you can imagine it's senator

109
00:04:17,160 --> 00:04:18,779
hatch who's holding a thermal detonator

110
00:04:18,779 --> 00:04:20,970
because he can write a law that could

111
00:04:20,970 --> 00:04:23,280
affect just about everything on the

112
00:04:23,280 --> 00:04:25,140
internet so this is a word cloud I love

113
00:04:25,140 --> 00:04:26,669
word clouds because there are a lot of

114
00:04:26,669 --> 00:04:27,630
words on this page

115
00:04:27,630 --> 00:04:29,610
it's a funnier way to look at them but

116
00:04:29,610 --> 00:04:32,250
it represents a number of the technology

117
00:04:32,250 --> 00:04:34,500
policy issues that were hotly debating

118
00:04:34,500 --> 00:04:36,180
at least in the United States but that

119
00:04:36,180 --> 00:04:38,220
are being debated around the world as

120
00:04:38,220 --> 00:04:38,640
well

121
00:04:38,640 --> 00:04:40,920
these include of course privacy and data

122
00:04:40,920 --> 00:04:44,550
security cross border data flow control

123
00:04:44,550 --> 00:04:47,400
choice transparency data portability

124
00:04:47,400 --> 00:04:50,640
interoperability the security of the IOT

125
00:04:50,640 --> 00:04:54,170
the security of stuff that some of some

126
00:04:54,170 --> 00:04:56,700
scholars and others and the u.s. have

127
00:04:56,700 --> 00:04:58,170
started calling the Internet of bodies

128
00:04:58,170 --> 00:04:59,630
which i think is a really good

129
00:04:59,630 --> 00:05:02,250
terminology for medical devices but also

130
00:05:02,250 --> 00:05:04,560
implants and other enhancements that are

131
00:05:04,560 --> 00:05:07,350
coming online soon government access to

132
00:05:07,350 --> 00:05:10,560
data surveillance encryption backdoors

133
00:05:10,560 --> 00:05:12,540
whether those are a good idea I think

134
00:05:12,540 --> 00:05:14,580
the hacker community has a huge role to

135
00:05:14,580 --> 00:05:17,250
play in explaining the risks of those

136
00:05:17,250 --> 00:05:19,830
kinds of technologies and those kinds of

137
00:05:19,830 --> 00:05:22,800
mandates from governments intellectual

138
00:05:22,800 --> 00:05:24,630
property and copyright which have

139
00:05:24,630 --> 00:05:26,460
everything to do with the kind of

140
00:05:26,460 --> 00:05:28,890
research that can be done on code and

141
00:05:28,890 --> 00:05:31,500
exceptions to those kinds of laws can be

142
00:05:31,500 --> 00:05:34,010
incredibly valuable for doing research

143
00:05:34,010 --> 00:05:36,780
the right to break things and and

144
00:05:36,780 --> 00:05:39,690
probably just as importantly the future

145
00:05:39,690 --> 00:05:42,630
technologies cryptocurrency not so

146
00:05:42,630 --> 00:05:44,730
futuristic at this point blockchain

147
00:05:44,730 --> 00:05:47,790
increasingly autonomous technology

148
00:05:47,790 --> 00:05:50,100
machine learning and AI whether it's

149
00:05:50,100 --> 00:05:51,930
specialized or generalized or however

150
00:05:51,930 --> 00:05:54,000
you want to think about it and of course

151
00:05:54,000 --> 00:05:57,030
really importantly how computer crimes

152
00:05:57,030 --> 00:05:59,880
are prosecuted and who gets thrown in

153
00:05:59,880 --> 00:06:02,340
prison for doing things on computers

154
00:06:02,340 --> 00:06:05,040
with code so these are all really

155
00:06:05,040 --> 00:06:08,040
important policy areas I suspect that

156
00:06:08,040 --> 00:06:10,560
they touch on almost everybody's work in

157
00:06:10,560 --> 00:06:12,360
the room and the people who are in

158
00:06:12,360 --> 00:06:13,980
charge of thinking about how to write

159
00:06:13,980 --> 00:06:16,050
the laws about them are the people who

160
00:06:16,050 --> 00:06:17,670
are asking those questions of Mark

161
00:06:17,670 --> 00:06:19,320
Zuckerberg so if that doesn't sell you

162
00:06:19,320 --> 00:06:21,780
on the need to integrate what you know

163
00:06:21,780 --> 00:06:24,180
into the policy conversation I'm gonna

164
00:06:24,180 --> 00:06:31,890
keep going so ok you can you can argue

165
00:06:31,890 --> 00:06:34,650
that ok fine we need to help the

166
00:06:34,650 --> 00:06:35,820
government understand these things

167
00:06:35,820 --> 00:06:37,440
because the government doesn't really

168
00:06:37,440 --> 00:06:39,659
understand them and

169
00:06:39,659 --> 00:06:41,610
in G&I here I am telling you to engage

170
00:06:41,610 --> 00:06:43,469
with policymakers and find people who

171
00:06:43,469 --> 00:06:46,679
will listen and whatever but but you may

172
00:06:46,679 --> 00:06:48,179
feel that this is more or less an

173
00:06:48,179 --> 00:06:51,889
impossible assignment and that in truth

174
00:06:51,889 --> 00:06:54,990
it it won't really make any kind of

175
00:06:54,990 --> 00:06:58,349
difference so I wanted to offer a little

176
00:06:58,349 --> 00:07:01,919
bit of important hacker history that

177
00:07:01,919 --> 00:07:05,729
that sort of makes two points one for

178
00:07:05,729 --> 00:07:06,899
those of you who aren't familiar this is

179
00:07:06,899 --> 00:07:10,319
a photo from May of 1998 this is a time

180
00:07:10,319 --> 00:07:12,990
in which the world wide web was some

181
00:07:12,990 --> 00:07:15,180
something people surfed mostly on

182
00:07:15,180 --> 00:07:17,520
America Online right so it's a very

183
00:07:17,520 --> 00:07:20,969
different time in in history and this is

184
00:07:20,969 --> 00:07:22,770
the loft group so this is Mudge and

185
00:07:22,770 --> 00:07:24,839
Brian oblivion well Pond space rogue

186
00:07:24,839 --> 00:07:28,559
kingpin and others who were thinking and

187
00:07:28,559 --> 00:07:30,629
working on vulnerabilities at the time

188
00:07:30,629 --> 00:07:32,309
and they were invited to testify they

189
00:07:32,309 --> 00:07:33,869
use their hacker names which was pretty

190
00:07:33,869 --> 00:07:35,699
cool there's much in the middle who is

191
00:07:35,699 --> 00:07:37,949
looking looking like the Dark Angel or

192
00:07:37,949 --> 00:07:40,080
something and in this and there's some

193
00:07:40,080 --> 00:07:42,209
great video of this hearing in which

194
00:07:42,209 --> 00:07:44,099
senator Thompson who is also a movie

195
00:07:44,099 --> 00:07:46,349
star so he sounds great as the senator

196
00:07:46,349 --> 00:07:49,529
is told like by much like almost

197
00:07:49,529 --> 00:07:51,449
everything that is connected on the

198
00:07:51,449 --> 00:07:54,629
Internet we can break and we can totally

199
00:07:54,629 --> 00:07:56,699
take everything offline and like about

200
00:07:56,699 --> 00:07:58,800
30 kliks or something I read some I'm

201
00:07:58,800 --> 00:08:01,229
making it up and Senator Thompson goes

202
00:08:01,229 --> 00:08:04,969
well we should fix that

203
00:08:04,969 --> 00:08:08,009
like that's it that's the rejoinder okay

204
00:08:08,009 --> 00:08:10,740
so so so Congress didn't fix it

205
00:08:10,740 --> 00:08:12,329
obviously I don't have to tell anybody

206
00:08:12,329 --> 00:08:13,589
in the room that we have massive

207
00:08:13,589 --> 00:08:15,599
security problems that's what this

208
00:08:15,599 --> 00:08:17,579
entire day is about and all of all of

209
00:08:17,579 --> 00:08:19,110
the conference's around these issues are

210
00:08:19,110 --> 00:08:21,360
about and certainly we're continuing

211
00:08:21,360 --> 00:08:23,189
debate how to fix fix all of the

212
00:08:23,189 --> 00:08:25,709
security problems and in the US but what

213
00:08:25,709 --> 00:08:28,349
did happen after this was the laughs

214
00:08:28,349 --> 00:08:29,459
group decided to start publishing

215
00:08:29,459 --> 00:08:31,860
vulnerabilities and if you think about

216
00:08:31,860 --> 00:08:33,809
it as we fast-forward 20 years later

217
00:08:33,809 --> 00:08:36,059
it's now well-established that

218
00:08:36,059 --> 00:08:38,659
responsible disclosure programs and

219
00:08:38,659 --> 00:08:41,309
having an ability to respond to Vons

220
00:08:41,309 --> 00:08:42,839
when they're disclosed to your

221
00:08:42,839 --> 00:08:45,089
organization is a part of good security

222
00:08:45,089 --> 00:08:47,279
practice and in fact it's a part of good

223
00:08:47,279 --> 00:08:49,439
security practice that my former agency

224
00:08:49,439 --> 00:08:50,519
the Federal Trade Commission has

225
00:08:50,519 --> 00:08:52,710
incorporated into its guide

226
00:08:52,710 --> 00:08:55,050
for what constitutes reasonable security

227
00:08:55,050 --> 00:08:58,650
and all of that comes out of this effort

228
00:08:58,650 --> 00:09:02,400
to make previously relatively invisible

229
00:09:02,400 --> 00:09:05,400
world more visible to the people who are

230
00:09:05,400 --> 00:09:07,680
thinking about writing laws and making

231
00:09:07,680 --> 00:09:10,590
policy so I I like this example because

232
00:09:10,590 --> 00:09:12,960
I think it shows that of course

233
00:09:12,960 --> 00:09:15,000
government moves slowly and of course

234
00:09:15,000 --> 00:09:18,440
technology outpaces it but in fact

235
00:09:18,440 --> 00:09:21,990
getting involved and and starting to

236
00:09:21,990 --> 00:09:24,060
surface some of the issues and being

237
00:09:24,060 --> 00:09:26,460
vocal about them can in fact change

238
00:09:26,460 --> 00:09:28,920
industry practice and change best

239
00:09:28,920 --> 00:09:31,260
practices even when whole new laws

240
00:09:31,260 --> 00:09:39,380
aren't written so it's important ok so

241
00:09:39,980 --> 00:09:42,480
that but I wanted to talk about with

242
00:09:42,480 --> 00:09:45,750
this slide was essentially the ways in

243
00:09:45,750 --> 00:09:48,420
which I've seen really good engagement

244
00:09:48,420 --> 00:09:50,070
from the government again I'm using a

245
00:09:50,070 --> 00:09:53,010
lot of us examples because I'm the most

246
00:09:53,010 --> 00:09:55,500
familiar with them but I suspect that

247
00:09:55,500 --> 00:09:58,020
for a lot of folks it is possible to

248
00:09:58,020 --> 00:09:59,910
identify the parts of the government

249
00:09:59,910 --> 00:10:02,610
that are interested in hearing from you

250
00:10:02,610 --> 00:10:04,710
and I suspect those are the parts of the

251
00:10:04,710 --> 00:10:06,330
government that look very much like a

252
00:10:06,330 --> 00:10:08,640
consumer protection agency or that have

253
00:10:08,640 --> 00:10:11,490
a mission that is sort of aligned so my

254
00:10:11,490 --> 00:10:13,320
former agency the Federal Trade

255
00:10:13,320 --> 00:10:15,570
Commission for example is again

256
00:10:15,570 --> 00:10:17,400
primarily a privacy data security

257
00:10:17,400 --> 00:10:19,080
enforcement agency also competition

258
00:10:19,080 --> 00:10:21,150
enforcement agency it's an agency that

259
00:10:21,150 --> 00:10:23,880
protects consumers from unfair deceptive

260
00:10:23,880 --> 00:10:25,680
acts and practices in the marketplace

261
00:10:25,680 --> 00:10:28,050
which is a relatively broad mandate but

262
00:10:28,050 --> 00:10:30,810
it has over time started to form closer

263
00:10:30,810 --> 00:10:32,130
relationships with the research

264
00:10:32,130 --> 00:10:34,380
community and with technologists because

265
00:10:34,380 --> 00:10:36,210
consumers are using technology in their

266
00:10:36,210 --> 00:10:38,670
daily lives and the security of it or

267
00:10:38,670 --> 00:10:40,950
the settings that allow them to navigate

268
00:10:40,950 --> 00:10:44,160
the privacy on it very much matter in

269
00:10:44,160 --> 00:10:45,300
their daily lives

270
00:10:45,300 --> 00:10:48,500
so the FTC for example has hired

271
00:10:48,500 --> 00:10:50,370
technologists it also has established

272
00:10:50,370 --> 00:10:53,040
its own in-house research shop ootek

273
00:10:53,040 --> 00:10:55,800
which can create its own research but

274
00:10:55,800 --> 00:10:57,960
importantly recreate research if it is

275
00:10:57,960 --> 00:11:00,450
given information about research or see

276
00:11:00,450 --> 00:11:02,190
as a presentation at a conference like

277
00:11:02,190 --> 00:11:04,590
this so that can be very valuable for

278
00:11:04,590 --> 00:11:05,400
bringing case

279
00:11:05,400 --> 00:11:07,200
against companies that have insecure

280
00:11:07,200 --> 00:11:09,210
practices or are not doing what they

281
00:11:09,210 --> 00:11:11,990
purport to be doing with people's data

282
00:11:11,990 --> 00:11:15,480
but it also has been holding conferences

283
00:11:15,480 --> 00:11:17,460
there's an annual conference called

284
00:11:17,460 --> 00:11:20,010
privacy con which invites researchers to

285
00:11:20,010 --> 00:11:21,990
come and present new research on both

286
00:11:21,990 --> 00:11:24,780
privacy and security and it's been very

287
00:11:24,780 --> 00:11:26,670
successful the last three years we've

288
00:11:26,670 --> 00:11:28,440
added an element to it which is also

289
00:11:28,440 --> 00:11:30,570
bringing in US government agencies that

290
00:11:30,570 --> 00:11:32,970
have research funding to do brown bags

291
00:11:32,970 --> 00:11:34,980
with researchers so that they can

292
00:11:34,980 --> 00:11:36,600
connect directly with folks who can help

293
00:11:36,600 --> 00:11:38,160
fund research and I think that's an

294
00:11:38,160 --> 00:11:41,250
important area as well there's also

295
00:11:41,250 --> 00:11:43,440
around the US government been a variety

296
00:11:43,440 --> 00:11:45,600
of different ways that the government

297
00:11:45,600 --> 00:11:48,000
has gotten creative with engaging with

298
00:11:48,000 --> 00:11:50,640
hackers the digital service which was

299
00:11:50,640 --> 00:11:52,200
started in the Obama administration

300
00:11:52,200 --> 00:11:53,790
which is about bringing technologists

301
00:11:53,790 --> 00:11:55,140
into the work of the government in a

302
00:11:55,140 --> 00:11:57,720
meaningful way there was the office of

303
00:11:57,720 --> 00:12:00,780
Technology Science in the White House

304
00:12:00,780 --> 00:12:02,190
which actually started having its first

305
00:12:02,190 --> 00:12:04,470
chief technology officers its first

306
00:12:04,470 --> 00:12:07,080
chief data scientists and bringing those

307
00:12:07,080 --> 00:12:11,580
kinds of real experts in technology not

308
00:12:11,580 --> 00:12:13,140
in not just into the White House but

309
00:12:13,140 --> 00:12:15,180
into every different government agency

310
00:12:15,180 --> 00:12:17,130
there have been challenges that have

311
00:12:17,130 --> 00:12:19,590
been run by DARPA but also the FTC and

312
00:12:19,590 --> 00:12:22,290
other agencies the FTC for example ran

313
00:12:22,290 --> 00:12:24,510
to towns as DEFCON to create better

314
00:12:24,510 --> 00:12:26,700
tools to fight robo calls which are

315
00:12:26,700 --> 00:12:28,560
those annoying telemarketing calls that

316
00:12:28,560 --> 00:12:32,880
bother you all the time and DARPA ran

317
00:12:32,880 --> 00:12:34,500
the cyber Grand Challenge a couple of

318
00:12:34,500 --> 00:12:36,990
years ago which was a cyber autonomous

319
00:12:36,990 --> 00:12:39,420
capture the flag game at DARPA which was

320
00:12:39,420 --> 00:12:40,950
terrific

321
00:12:40,950 --> 00:12:45,450
I also just wanted to mention that their

322
00:12:45,450 --> 00:12:47,550
fellowships and now there's a new call

323
00:12:47,550 --> 00:12:50,520
to bring tech advisory group back into

324
00:12:50,520 --> 00:12:52,320
Congress especially following the

325
00:12:52,320 --> 00:12:53,790
performance of a lot of the members of

326
00:12:53,790 --> 00:12:55,350
Congress during the Facebook hearings

327
00:12:55,350 --> 00:12:57,720
there was a real recognition for the

328
00:12:57,720 --> 00:13:00,390
need to bring technological in expertise

329
00:13:00,390 --> 00:13:02,700
into that part of the government as well

330
00:13:02,700 --> 00:13:04,920
so what we see in the United States is

331
00:13:04,920 --> 00:13:07,020
recognition across the government about

332
00:13:07,020 --> 00:13:09,210
the role that technologists need to play

333
00:13:09,210 --> 00:13:11,730
and really new models of trying to

334
00:13:11,730 --> 00:13:14,490
engage even the the grey hat hacker

335
00:13:14,490 --> 00:13:17,010
community even the Pentagon now the

336
00:13:17,010 --> 00:13:18,240
Department of Defense

337
00:13:18,240 --> 00:13:20,700
is running in hack the Pentagon and

338
00:13:20,700 --> 00:13:23,339
other challenges as well so I think

339
00:13:23,339 --> 00:13:26,250
these are really promising developments

340
00:13:26,250 --> 00:13:29,370
and recognitions that we're seeing that

341
00:13:29,370 --> 00:13:30,779
seen in the US and I suspect we're

342
00:13:30,779 --> 00:13:36,230
seeing them in other places as well so I

343
00:13:36,230 --> 00:13:38,940
wanted to make sure that I ended with

344
00:13:38,940 --> 00:13:42,029
some really clear takeaways because

345
00:13:42,029 --> 00:13:45,810
we've been covering a lot of ground the

346
00:13:45,810 --> 00:13:48,149
first one is you know I think an

347
00:13:48,149 --> 00:13:50,640
important one which is find a way to

348
00:13:50,640 --> 00:13:52,980
present your research to policy makers

349
00:13:52,980 --> 00:13:55,470
and enforcers and again I but say we're

350
00:13:55,470 --> 00:13:58,230
responsibly here because I think all the

351
00:13:58,230 --> 00:13:59,370
laws are different we want to make sure

352
00:13:59,370 --> 00:14:01,950
people are not putting themselves in

353
00:14:01,950 --> 00:14:05,520
legal jeopardy but also find the parts

354
00:14:05,520 --> 00:14:07,290
of the government that are interested in

355
00:14:07,290 --> 00:14:09,360
this information and develop

356
00:14:09,360 --> 00:14:11,250
relationships with people in those parts

357
00:14:11,250 --> 00:14:13,680
of the government form partnerships with

358
00:14:13,680 --> 00:14:15,000
consumer protection and data protection

359
00:14:15,000 --> 00:14:18,240
agencies and help them understand what

360
00:14:18,240 --> 00:14:20,370
you know I think that's a really

361
00:14:20,370 --> 00:14:22,410
important element I suspect you'll find

362
00:14:22,410 --> 00:14:24,839
a lot of people who are public servants

363
00:14:24,839 --> 00:14:27,000
are deeply interested in these areas and

364
00:14:27,000 --> 00:14:30,209
a lot of them are in regulatory agencies

365
00:14:30,209 --> 00:14:32,190
that are dealing with industries that

366
00:14:32,190 --> 00:14:34,620
haven't previously experienced a lot of

367
00:14:34,620 --> 00:14:37,500
these problems so if you think about in

368
00:14:37,500 --> 00:14:40,380
the US for example the Safety

369
00:14:40,380 --> 00:14:42,209
Administration that regulates vehicles

370
00:14:42,209 --> 00:14:43,770
is now thinking about autonomous

371
00:14:43,770 --> 00:14:46,110
vehicles the Aviation Administration

372
00:14:46,110 --> 00:14:47,640
that does planes is thinking about

373
00:14:47,640 --> 00:14:50,279
drones the FDA which does medical

374
00:14:50,279 --> 00:14:53,010
devices is thinking about IOT so we see

375
00:14:53,010 --> 00:14:54,720
a range of these government agencies

376
00:14:54,720 --> 00:14:56,790
that don't have a lot of technological

377
00:14:56,790 --> 00:14:59,459
expertise that really need it and they

378
00:14:59,459 --> 00:15:00,839
need it quickly and they have to get up

379
00:15:00,839 --> 00:15:03,630
to speed so a lot of them are looking

380
00:15:03,630 --> 00:15:07,260
for ways to engage become a tech

381
00:15:07,260 --> 00:15:09,480
translator okay I can't emphasize this

382
00:15:09,480 --> 00:15:11,070
enough now that might not be the right

383
00:15:11,070 --> 00:15:14,459
role for everybody in the room but if if

384
00:15:14,459 --> 00:15:16,920
you can explain to your mom what you're

385
00:15:16,920 --> 00:15:19,200
working on then you are qualified to be

386
00:15:19,200 --> 00:15:22,649
a tech translator okay now this is a

387
00:15:22,649 --> 00:15:26,370
challenge but but a lot of us myself

388
00:15:26,370 --> 00:15:29,459
included who you know either have been

389
00:15:29,459 --> 00:15:30,870
in positions to

390
00:15:30,870 --> 00:15:34,290
it's laws or enforce the laws don't

391
00:15:34,290 --> 00:15:37,080
really know all of the codes and

392
00:15:37,080 --> 00:15:40,080
buzzwords of the hacker community and I

393
00:15:40,080 --> 00:15:41,700
think it's awesome to have your own

394
00:15:41,700 --> 00:15:44,160
vocabulary and your own language and I

395
00:15:44,160 --> 00:15:46,529
think it's powerful and cool and have

396
00:15:46,529 --> 00:15:48,690
your own community I think that is also

397
00:15:48,690 --> 00:15:50,880
awesome but remember if you're trying to

398
00:15:50,880 --> 00:15:52,770
explain someone something to someone who

399
00:15:52,770 --> 00:15:55,020
is not in that community help them

400
00:15:55,020 --> 00:15:57,000
understand it if you want to have an

401
00:15:57,000 --> 00:15:59,279
impact and if translation is not your

402
00:15:59,279 --> 00:16:01,830
thing then find someone who is a

403
00:16:01,830 --> 00:16:04,350
translator and see if you can tell a

404
00:16:04,350 --> 00:16:06,750
story about the technology or help them

405
00:16:06,750 --> 00:16:09,000
tell that story in a way that people can

406
00:16:09,000 --> 00:16:09,839
understand it

407
00:16:09,839 --> 00:16:13,470
examples are great real-world

408
00:16:13,470 --> 00:16:16,230
translations like I'd loved the the talk

409
00:16:16,230 --> 00:16:18,870
just now about I was thinking like in my

410
00:16:18,870 --> 00:16:20,250
head the Internet of yacht's

411
00:16:20,250 --> 00:16:22,520
oh my god rich people problems like

412
00:16:22,520 --> 00:16:25,170
which was great but you know as you're

413
00:16:25,170 --> 00:16:26,400
sitting there thinking about it the way

414
00:16:26,400 --> 00:16:29,640
to translate it as like hey of all these

415
00:16:29,640 --> 00:16:31,860
routers and satellite links on these

416
00:16:31,860 --> 00:16:34,140
boats are like super insecure like

417
00:16:34,140 --> 00:16:36,180
they're running like really really bad

418
00:16:36,180 --> 00:16:38,850
security policies and there have got you

419
00:16:38,850 --> 00:16:41,130
know stuff coded into them that you cant

420
00:16:41,130 --> 00:16:43,410
encode and passwords in plain English

421
00:16:43,410 --> 00:16:45,930
like things mom you wouldn't do yourself

422
00:16:45,930 --> 00:16:49,410
at home anymore so just having an

423
00:16:49,410 --> 00:16:51,209
ability to kind of explain some of those

424
00:16:51,209 --> 00:16:53,040
things sometimes really matters I've

425
00:16:53,040 --> 00:16:55,020
seen this matter also operationally when

426
00:16:55,020 --> 00:16:56,490
I've been reviewing companies who have

427
00:16:56,490 --> 00:16:58,770
gotten run into problems with the law

428
00:16:58,770 --> 00:17:00,740
around their data security practices

429
00:17:00,740 --> 00:17:05,010
very often some cyber security personnel

430
00:17:05,010 --> 00:17:07,949
or even a CSO explained to relatively

431
00:17:07,949 --> 00:17:09,329
high level executives that there was a

432
00:17:09,329 --> 00:17:11,099
vulnerability that needed to be patched

433
00:17:11,099 --> 00:17:14,730
like it was on the a wasp list and then

434
00:17:14,730 --> 00:17:17,339
the executive was like okay cool you

435
00:17:17,339 --> 00:17:19,319
know I just didn't do anything with that

436
00:17:19,319 --> 00:17:21,630
information that resulted ultimately in

437
00:17:21,630 --> 00:17:24,660
a fine from from an enforcer problem so

438
00:17:24,660 --> 00:17:25,859
they should have and they should have

439
00:17:25,859 --> 00:17:27,720
known better but part of the problem

440
00:17:27,720 --> 00:17:29,309
part of the problem right there was just

441
00:17:29,309 --> 00:17:31,580
the translation out of very specialized

442
00:17:31,580 --> 00:17:34,470
information into into more generalized

443
00:17:34,470 --> 00:17:37,230
information so this is a vital role and

444
00:17:37,230 --> 00:17:38,670
we need to find people who are good at

445
00:17:38,670 --> 00:17:41,630
this and deploy them everywhere and

446
00:17:41,630 --> 00:17:44,850
lastly if that fails you can always rely

447
00:17:44,850 --> 00:17:48,600
on using the force so I see my time is

448
00:17:48,600 --> 00:17:51,059
up and I wanted to of course leave you

449
00:17:51,059 --> 00:17:54,059
with the parting wisdom that the laws

450
00:17:54,059 --> 00:17:56,549
and regulations and agencies that are

451
00:17:56,549 --> 00:17:58,679
enforcing these laws are having a global

452
00:17:58,679 --> 00:18:01,019
impact because the Internet is a medium

453
00:18:01,019 --> 00:18:03,870
that connects us all globally our

454
00:18:03,870 --> 00:18:07,409
connectedness is growing you all have

455
00:18:07,409 --> 00:18:10,049
specialized knowledge and skills that

456
00:18:10,049 --> 00:18:12,690
are vitally important to protecting

457
00:18:12,690 --> 00:18:16,889
consumers individuals privacy data all

458
00:18:16,889 --> 00:18:18,240
of these things that are going to matter

459
00:18:18,240 --> 00:18:21,000
to us as human beings and we need to get

460
00:18:21,000 --> 00:18:24,389
you into the mix fine parts of the

461
00:18:24,389 --> 00:18:26,070
government that you can work with help

462
00:18:26,070 --> 00:18:27,750
people who are policy makers make

463
00:18:27,750 --> 00:18:30,240
decisions and and speak up as much as

464
00:18:30,240 --> 00:18:32,460
possible thank you very much

465
00:18:32,460 --> 00:18:36,789
[Applause]

