1
00:00:06,080 --> 00:00:07,359
um

2
00:00:07,359 --> 00:00:09,679
great to be here uh as besides dublin

3
00:00:09,679 --> 00:00:11,360
thanks for having me so

4
00:00:11,360 --> 00:00:14,639
a little bit about myself um i'm the

5
00:00:14,639 --> 00:00:16,560
co-founder and the chief specialist at

6
00:00:16,560 --> 00:00:18,880
b45 uh we're an application security

7
00:00:18,880 --> 00:00:19,600
company and

8
00:00:19,600 --> 00:00:21,920
pretty much um helping product teams

9
00:00:21,920 --> 00:00:23,600
kind of implement a lot of abstract uh

10
00:00:23,600 --> 00:00:24,240
solutions

11
00:00:24,240 --> 00:00:25,519
and helping them scale and things like

12
00:00:25,519 --> 00:00:27,519
that um today however

13
00:00:27,519 --> 00:00:28,800
we're gonna be talking about one of the

14
00:00:28,800 --> 00:00:30,960
things that keep me up at night which is

15
00:00:30,960 --> 00:00:32,558
that of stress modeling but

16
00:00:32,558 --> 00:00:35,360
um really my interests are largely from

17
00:00:35,360 --> 00:00:36,320
a perspective

18
00:00:36,320 --> 00:00:37,600
from a different spectrum from a

19
00:00:37,600 --> 00:00:39,760
difficult standpoint

20
00:00:39,760 --> 00:00:42,480
um very happy security fantastic 2.0 and

21
00:00:42,480 --> 00:00:44,480
things like that so um

22
00:00:44,480 --> 00:00:46,079
happy to kind of chat and network with

23
00:00:46,079 --> 00:00:47,920
anybody else who has similar interests

24
00:00:47,920 --> 00:00:48,320
uh

25
00:00:48,320 --> 00:00:52,320
once the program is done okay um

26
00:00:52,320 --> 00:00:54,800
over the next 45 minutes or so uh the

27
00:00:54,800 --> 00:00:56,640
core of today's

28
00:00:56,640 --> 00:00:59,039
presentation i've been kind of looking

29
00:00:59,039 --> 00:01:01,199
at another presentation so probably for

30
00:01:01,199 --> 00:01:03,680
those who are expecting a very deep down

31
00:01:03,680 --> 00:01:07,520
technology a technical presentation this

32
00:01:07,520 --> 00:01:08,159
might be

33
00:01:08,159 --> 00:01:10,240
a slight deviation because this is more

34
00:01:10,240 --> 00:01:11,600
exploratory from that perspective

35
00:01:11,600 --> 00:01:13,360
because of the fact that threat modeling

36
00:01:13,360 --> 00:01:14,960
as a domain itself

37
00:01:14,960 --> 00:01:18,320
um is is quite fluid so

38
00:01:18,320 --> 00:01:19,680
this is one of those presentations that

39
00:01:19,680 --> 00:01:21,600
i've intended to kind of keep a little

40
00:01:21,600 --> 00:01:22,560
bit more

41
00:01:22,560 --> 00:01:26,400
uh you know fluid if you will

42
00:01:26,400 --> 00:01:27,600
and essentially you're going to be kind

43
00:01:27,600 --> 00:01:30,720
of presenting uh some schools of thought

44
00:01:30,720 --> 00:01:33,759
of why threat modeling uh

45
00:01:33,759 --> 00:01:36,799
possibly fails in um

46
00:01:36,799 --> 00:01:40,000
really large scale aspects in terms

47
00:01:40,000 --> 00:01:42,399
of security programs that have a lot of

48
00:01:42,399 --> 00:01:43,840
uh uh

49
00:01:43,840 --> 00:01:46,240
i traded processes and also kind of

50
00:01:46,240 --> 00:01:47,520
looking at uh two

51
00:01:47,520 --> 00:01:50,479
uh potential possibilities of trying to

52
00:01:50,479 --> 00:01:52,799
kind of

53
00:01:52,799 --> 00:01:55,119
see uh what potential opportunities

54
00:01:55,119 --> 00:01:56,560
exist within the threat modeling space

55
00:01:56,560 --> 00:01:57,439
for us to kind of

56
00:01:57,439 --> 00:01:59,439
have the capabilities to scale it at the

57
00:01:59,439 --> 00:02:00,799
speed of product engineering

58
00:02:00,799 --> 00:02:04,320
um so that's really uh the crux of the

59
00:02:04,320 --> 00:02:05,280
presentation

60
00:02:05,280 --> 00:02:07,759
um and and and we're going to probably

61
00:02:07,759 --> 00:02:09,919
end the presentation with a small demo

62
00:02:09,919 --> 00:02:10,160
of

63
00:02:10,160 --> 00:02:11,680
a thread playbook which is our open

64
00:02:11,680 --> 00:02:13,680
source uh security

65
00:02:13,680 --> 00:02:16,000
uh tech modeling that's called a fabric

66
00:02:16,000 --> 00:02:17,360
that we put out there on git

67
00:02:17,360 --> 00:02:18,400
and we're going to kind of show you in

68
00:02:18,400 --> 00:02:19,690
terms of how we fly

69
00:02:19,690 --> 00:02:22,780
[Music]

70
00:02:22,879 --> 00:02:25,920
so let's start off with um a really

71
00:02:25,920 --> 00:02:27,760
uh the state of application security

72
00:02:27,760 --> 00:02:29,760
today right so we're largely looking at

73
00:02:29,760 --> 00:02:32,239
um an increase in a tool adoption be

74
00:02:32,239 --> 00:02:33,360
fast dashed

75
00:02:33,360 --> 00:02:34,959
sda so whatever it is right so you're

76
00:02:34,959 --> 00:02:36,720
kind of seeing a large

77
00:02:36,720 --> 00:02:40,080
uh adaptation of two way

78
00:02:40,080 --> 00:02:42,879
in which obviously needs or is intended

79
00:02:42,879 --> 00:02:44,080
for uh higher

80
00:02:44,080 --> 00:02:47,120
uh test titrations uh and thanks to the

81
00:02:47,120 --> 00:02:48,879
holden seconds model we're also seeing a

82
00:02:48,879 --> 00:02:49,519
lot of

83
00:02:49,519 --> 00:02:51,840
feedback loops not just shifting left as

84
00:02:51,840 --> 00:02:53,440
probably speaking but also seeing a lot

85
00:02:53,440 --> 00:02:54,400
of shift right

86
00:02:54,400 --> 00:02:56,400
in terms of adoption of automation and

87
00:02:56,400 --> 00:03:00,159
feedback loops at a hrd monitoring

88
00:03:00,239 --> 00:03:02,800
phase as well and you're also seeing a

89
00:03:02,800 --> 00:03:05,200
lot of as a code execution model it

90
00:03:05,200 --> 00:03:06,800
started off with securities code

91
00:03:06,800 --> 00:03:08,400
invented infrastructure scope

92
00:03:08,400 --> 00:03:09,599
and today what we're going to be talking

93
00:03:09,599 --> 00:03:11,840
about is threat modeling this code

94
00:03:11,840 --> 00:03:16,560
because code as a fundamental piece of

95
00:03:16,560 --> 00:03:18,640
element is something that's really kind

96
00:03:18,640 --> 00:03:20,560
of um

97
00:03:20,560 --> 00:03:22,480
being the catalyst if you will in terms

98
00:03:22,480 --> 00:03:24,239
of uh the whole application security

99
00:03:24,239 --> 00:03:25,599
automation space or in the

100
00:03:25,599 --> 00:03:26,879
that's the top space you're gonna kind

101
00:03:26,879 --> 00:03:28,879
of see today in terms of how the azure

102
00:03:28,879 --> 00:03:29,920
code model

103
00:03:29,920 --> 00:03:31,360
fits in within the threat marketing

104
00:03:31,360 --> 00:03:33,599
space and obviously

105
00:03:33,599 --> 00:03:35,760
um there's a lot of impetus today in

106
00:03:35,760 --> 00:03:37,760
terms of metrics and metadata

107
00:03:37,760 --> 00:03:39,440
and and and one of the things that i

108
00:03:39,440 --> 00:03:40,959
personally like to follow is in terms of

109
00:03:40,959 --> 00:03:42,560
metadata or vulnerabilities because

110
00:03:42,560 --> 00:03:43,040
today

111
00:03:43,040 --> 00:03:46,159
uh not only are we kind of

112
00:03:46,159 --> 00:03:47,760
attracting vulnerabilities from a high

113
00:03:47,760 --> 00:03:49,760
medium low severity perspective

114
00:03:49,760 --> 00:03:51,840
we're also trying to understand in terms

115
00:03:51,840 --> 00:03:53,760
of what the potential story

116
00:03:53,760 --> 00:03:56,239
uh behind a vulnerability is because

117
00:03:56,239 --> 00:03:57,760
obviously every vulnerability has a

118
00:03:57,760 --> 00:03:58,400
story

119
00:03:58,400 --> 00:03:59,920
and if you start to look at really

120
00:03:59,920 --> 00:04:01,519
metadata that vulnerabilities

121
00:04:01,519 --> 00:04:03,519
give out beyond just the traffic light

122
00:04:03,519 --> 00:04:05,439
indicators there's a lot of interesting

123
00:04:05,439 --> 00:04:06,720
uh kind of things that could come up

124
00:04:06,720 --> 00:04:08,879
there but that's for another day uh but

125
00:04:08,879 --> 00:04:11,519
uh really to kind of look at threat

126
00:04:11,519 --> 00:04:13,200
modeling and this is this is the same

127
00:04:13,200 --> 00:04:14,159
that i really love

128
00:04:14,159 --> 00:04:15,840
and something that i put together you

129
00:04:15,840 --> 00:04:17,199
know if threat modeling if

130
00:04:17,199 --> 00:04:19,519
if applicant security was a website uh

131
00:04:19,519 --> 00:04:20,880
threat modeling would be the page with

132
00:04:20,880 --> 00:04:22,240
the highest bound rate

133
00:04:22,240 --> 00:04:23,600
because that's simply because of the

134
00:04:23,600 --> 00:04:25,440
fact that there's a lot of things

135
00:04:25,440 --> 00:04:28,160
said about threat modeling in terms of

136
00:04:28,160 --> 00:04:29,520
channels in the air they're saying that

137
00:04:29,520 --> 00:04:30,639
you know you could fix

138
00:04:30,639 --> 00:04:32,639
a significant amount of issues even

139
00:04:32,639 --> 00:04:34,240
before they're recorded or

140
00:04:34,240 --> 00:04:36,800
in terms of saying that uh you know pet

141
00:04:36,800 --> 00:04:38,560
modeling

142
00:04:38,560 --> 00:04:41,600
um you know without faith modding up

143
00:04:41,600 --> 00:04:42,400
against hrd

144
00:04:42,400 --> 00:04:44,240
nothing so you know there's a lot of a

145
00:04:44,240 --> 00:04:45,440
lot of things that said about

146
00:04:45,440 --> 00:04:47,520
modeling and this is over the last four

147
00:04:47,520 --> 00:04:50,719
or five years before that

148
00:04:51,199 --> 00:04:54,880
sort of um uh noise uh in the apathy

149
00:04:54,880 --> 00:04:56,479
security world as foster smalling is

150
00:04:56,479 --> 00:04:57,600
concerned in terms of things that

151
00:04:57,600 --> 00:04:58,960
chesmar we can achieve

152
00:04:58,960 --> 00:05:00,960
and and how is it going to help i think

153
00:05:00,960 --> 00:05:02,720
it's a query programs

154
00:05:02,720 --> 00:05:05,840
but really at ground zero uh

155
00:05:05,840 --> 00:05:07,759
this is not necessarily happening

156
00:05:07,759 --> 00:05:08,960
because one of the things that i've

157
00:05:08,960 --> 00:05:10,000
personally seen

158
00:05:10,000 --> 00:05:12,000
in the last decade of working with apple

159
00:05:12,000 --> 00:05:13,440
security teams is the fact that

160
00:05:13,440 --> 00:05:14,960
that necessarily doesn't really

161
00:05:14,960 --> 00:05:16,880
translate to real world implementation

162
00:05:16,880 --> 00:05:18,720
of that modeling and more so

163
00:05:18,720 --> 00:05:20,000
in terms of implementation of trade

164
00:05:20,000 --> 00:05:21,840
modeling especially in organizations

165
00:05:21,840 --> 00:05:23,919
where we see product deployments and

166
00:05:23,919 --> 00:05:26,320
applications

167
00:05:26,800 --> 00:05:28,960
iterations at scales we're talking about

168
00:05:28,960 --> 00:05:29,919
people deploying

169
00:05:29,919 --> 00:05:32,880
uh every a minute or every hour and how

170
00:05:32,880 --> 00:05:33,600
do you kind of

171
00:05:33,600 --> 00:05:35,280
see the same concepts of this model

172
00:05:35,280 --> 00:05:38,560
really kind of fit in those kind of uh

173
00:05:38,560 --> 00:05:41,440
infrastructures so one of the things

174
00:05:41,440 --> 00:05:42,960
that we'd like to talk about in terms of

175
00:05:42,960 --> 00:05:44,720
why do threat models fail but before

176
00:05:44,720 --> 00:05:46,400
that i think it's quite essential

177
00:05:46,400 --> 00:05:51,120
for us to really understand um what's a

178
00:05:51,120 --> 00:05:52,880
definition of threat modeling is and i

179
00:05:52,880 --> 00:05:54,639
think that's really the fundamental

180
00:05:54,639 --> 00:05:55,919
building block

181
00:05:55,919 --> 00:05:58,400
of looking at responding scale and one

182
00:05:58,400 --> 00:05:59,680
of the things that i really like to

183
00:05:59,680 --> 00:06:01,120
kind of compare threat modeling is

184
00:06:01,120 --> 00:06:02,639
really uh with the blind man and the

185
00:06:02,639 --> 00:06:04,240
elephant right because

186
00:06:04,240 --> 00:06:07,120
you have multiple viewpoints in terms of

187
00:06:07,120 --> 00:06:08,400
what threat modeling is

188
00:06:08,400 --> 00:06:12,400
back to the old problem

189
00:06:12,960 --> 00:06:15,120
for fuel threat modeling could be

190
00:06:15,120 --> 00:06:16,319
getting issues in design and

191
00:06:16,319 --> 00:06:17,919
architecture

192
00:06:17,919 --> 00:06:19,680
for certain others in the in the

193
00:06:19,680 --> 00:06:21,199
developer space it could be about

194
00:06:21,199 --> 00:06:21,840
certainly

195
00:06:21,840 --> 00:06:24,639
what the countermeasures retreats are um

196
00:06:24,639 --> 00:06:24,960
for

197
00:06:24,960 --> 00:06:26,560
us in the security domain it could be an

198
00:06:26,560 --> 00:06:28,160
efficient reverse to simulate attack

199
00:06:28,160 --> 00:06:28,800
vectors

200
00:06:28,800 --> 00:06:30,080
it could be a way for us to choose

201
00:06:30,080 --> 00:06:32,160
technology components better testing

202
00:06:32,160 --> 00:06:33,360
coverage

203
00:06:33,360 --> 00:06:35,360
anticipate security incidents and things

204
00:06:35,360 --> 00:06:36,560
like that but

205
00:06:36,560 --> 00:06:38,960
really the definition of threat modeling

206
00:06:38,960 --> 00:06:40,319
is really coming

207
00:06:40,319 --> 00:06:42,160
from a perspective of what is your

208
00:06:42,160 --> 00:06:43,840
motivation to print model

209
00:06:43,840 --> 00:06:45,520
right it doesn't really matter in terms

210
00:06:45,520 --> 00:06:47,039
of what the definition is because i

211
00:06:47,039 --> 00:06:48,639
think that's where we're getting really

212
00:06:48,639 --> 00:06:49,599
caught up

213
00:06:49,599 --> 00:06:50,880
and product teams today are really

214
00:06:50,880 --> 00:06:52,720
getting caught up in terms of really

215
00:06:52,720 --> 00:06:54,080
finding the sweet spot of what the

216
00:06:54,080 --> 00:06:55,840
definition of technology is

217
00:06:55,840 --> 00:06:57,520
as opposed to really understanding what

218
00:06:57,520 --> 00:06:59,440
your motivational technology is

219
00:06:59,440 --> 00:07:01,360
and as you've seen before uh one of the

220
00:07:01,360 --> 00:07:04,160
things that the whole shift left model

221
00:07:04,160 --> 00:07:05,680
uh is kind of bringing into up against

222
00:07:05,680 --> 00:07:07,360
the charity is the fact that

223
00:07:07,360 --> 00:07:10,639
as as much we're talking about or

224
00:07:10,639 --> 00:07:12,800
breaking the silos between teams they're

225
00:07:12,800 --> 00:07:14,479
also seeing that the silos there's also

226
00:07:14,479 --> 00:07:16,160
a shared sense of responsibility

227
00:07:16,160 --> 00:07:17,759
in terms of potential activities like

228
00:07:17,759 --> 00:07:20,000
threat modeling that spread across the

229
00:07:20,000 --> 00:07:21,599
cardboard engineering flight cycle so

230
00:07:21,599 --> 00:07:24,400
obviously trademark plumbing is not

231
00:07:24,400 --> 00:07:26,080
something that was only done with

232
00:07:26,080 --> 00:07:27,680
architecture teams to make a monitoring

233
00:07:27,680 --> 00:07:29,360
something like that security teams with

234
00:07:29,360 --> 00:07:30,800
devops teams to start with

235
00:07:30,800 --> 00:07:32,479
developer teams so each of them have

236
00:07:32,479 --> 00:07:34,400
their own motivations in terms of what

237
00:07:34,400 --> 00:07:35,680
they're planning to achieve

238
00:07:35,680 --> 00:07:39,120
or express model so i think the primary

239
00:07:39,120 --> 00:07:39,840
objective

240
00:07:39,840 --> 00:07:41,680
uh before we start looking at the look

241
00:07:41,680 --> 00:07:42,960
at that model is really what the

242
00:07:42,960 --> 00:07:44,960
motivations are

243
00:07:44,960 --> 00:07:46,560
and one of the one of the primary

244
00:07:46,560 --> 00:07:48,879
reasons in terms of why that models fail

245
00:07:48,879 --> 00:07:51,759
is really not is really understanding or

246
00:07:51,759 --> 00:07:52,319
not

247
00:07:52,319 --> 00:07:54,720
understanding why we do test modeling

248
00:07:54,720 --> 00:07:55,440
right

249
00:07:55,440 --> 00:07:58,319
and like we see in the previous uh slide

250
00:07:58,319 --> 00:07:59,759
there there are multiple reasons why you

251
00:07:59,759 --> 00:08:01,360
could do threat modeling the fundamental

252
00:08:01,360 --> 00:08:02,879
reasons why people started doing such

253
00:08:02,879 --> 00:08:05,520
modeling was really to kind of look at

254
00:08:05,520 --> 00:08:08,400
potential issues at an architectural or

255
00:08:08,400 --> 00:08:10,160
at a blueprint level even before you

256
00:08:10,160 --> 00:08:11,759
started writing your first line of code

257
00:08:11,759 --> 00:08:12,240
which is

258
00:08:12,240 --> 00:08:14,479
great which is still valid but today

259
00:08:14,479 --> 00:08:16,160
it's gone much beyond that

260
00:08:16,160 --> 00:08:18,879
there are multiple reasons or multiple

261
00:08:18,879 --> 00:08:20,479
use cases of potentially

262
00:08:20,479 --> 00:08:22,240
uh performing threat modeling one of the

263
00:08:22,240 --> 00:08:24,080
things that we're going to see today

264
00:08:24,080 --> 00:08:25,830
is in terms of the

265
00:08:25,830 --> 00:08:28,400
[Music]

266
00:08:28,400 --> 00:08:29,919
because usually threat model is

267
00:08:29,919 --> 00:08:31,039
something that's usually done from a

268
00:08:31,039 --> 00:08:32,719
component or a defender's perspective

269
00:08:32,719 --> 00:08:33,760
but we're also going to see

270
00:08:33,760 --> 00:08:36,080
in terms of how stretch modeling can be

271
00:08:36,080 --> 00:08:38,000
used uh from an attack uh

272
00:08:38,000 --> 00:08:39,360
from an attack perspective what we'd

273
00:08:39,360 --> 00:08:41,839
like to call uh uh

274
00:08:41,839 --> 00:08:44,080
driven test marketing so that's one view

275
00:08:44,080 --> 00:08:45,360
of the world in terms of why you would

276
00:08:45,360 --> 00:08:46,160
do click market

277
00:08:46,160 --> 00:08:47,519
and like you've seen earlier there are

278
00:08:47,519 --> 00:08:48,720
other views of the world as well you

279
00:08:48,720 --> 00:08:50,080
could do it from an architecture

280
00:08:50,080 --> 00:08:52,560
perspective you could do it from just

281
00:08:52,560 --> 00:08:54,720
just try and understand what the test

282
00:08:54,720 --> 00:08:56,959
coverage of your security testing is

283
00:08:56,959 --> 00:08:59,360
so there are multiple reasons um in

284
00:08:59,360 --> 00:09:00,480
terms of why

285
00:09:00,480 --> 00:09:02,160
um you would need to do threat modeling

286
00:09:02,160 --> 00:09:04,560
so before we start talking about test

287
00:09:04,560 --> 00:09:06,560
modeling before teams is really go ahead

288
00:09:06,560 --> 00:09:07,360
and start

289
00:09:07,360 --> 00:09:08,720
implementing threat modeling i think

290
00:09:08,720 --> 00:09:10,320
that needs to be a very fundamental

291
00:09:10,320 --> 00:09:11,600
understanding

292
00:09:11,600 --> 00:09:14,000
of why is it that that model is being

293
00:09:14,000 --> 00:09:14,800
done

294
00:09:14,800 --> 00:09:17,519
not just by that organization but also

295
00:09:17,519 --> 00:09:18,800
in terms of why do we need to do clip

296
00:09:18,800 --> 00:09:19,360
modeling

297
00:09:19,360 --> 00:09:23,839
from that team's perspective as well

298
00:09:24,000 --> 00:09:26,399
so obviously just like with anything in

299
00:09:26,399 --> 00:09:28,200
application security there is no

300
00:09:28,200 --> 00:09:29,360
one-size-fits-all

301
00:09:29,360 --> 00:09:31,040
and that's the beauty of absolute right

302
00:09:31,040 --> 00:09:32,640
uh and that's also the beauty about

303
00:09:32,640 --> 00:09:34,720
abstract modeling uh there is no

304
00:09:34,720 --> 00:09:36,959
one-size-fits-all from a from a smalling

305
00:09:36,959 --> 00:09:39,120
motivation perspective

306
00:09:39,120 --> 00:09:40,720
so one of the second reasons why a

307
00:09:40,720 --> 00:09:42,800
threat model in my opinion we've seen

308
00:09:42,800 --> 00:09:45,200
fails is really because of an over

309
00:09:45,200 --> 00:09:46,080
emphasis

310
00:09:46,080 --> 00:09:49,600
of how good brutality should i you

311
00:09:49,600 --> 00:09:50,880
should i use a pasta

312
00:09:50,880 --> 00:09:53,519
uh framework do i need to do venus do i

313
00:09:53,519 --> 00:09:55,279
use octave do i use

314
00:09:55,279 --> 00:09:58,399
a stride uh you know it which really

315
00:09:58,399 --> 00:09:59,519
start getting

316
00:09:59,519 --> 00:10:01,680
uh bogged up down in terms of what

317
00:10:01,680 --> 00:10:03,200
methodologies to be used

318
00:10:03,200 --> 00:10:05,120
uh or we start talking about what two

319
00:10:05,120 --> 00:10:06,640
squared is can use an open source tool

320
00:10:06,640 --> 00:10:08,160
and i use a commercial tool

321
00:10:08,160 --> 00:10:10,079
in terms of even before we start

322
00:10:10,079 --> 00:10:11,519
understanding how to frequently be

323
00:10:11,519 --> 00:10:12,480
talking about

324
00:10:12,480 --> 00:10:16,399
uh tools and things like that and

325
00:10:16,399 --> 00:10:20,720
the biggest and documentation

326
00:10:20,720 --> 00:10:23,920
uh is really one of the biggest reasons

327
00:10:23,920 --> 00:10:25,440
uh for our failures of threat model

328
00:10:25,440 --> 00:10:27,680
because uh you've already made it this

329
00:10:27,680 --> 00:10:28,560
huge

330
00:10:28,560 --> 00:10:31,519
uh mountain if you will of that that

331
00:10:31,519 --> 00:10:33,120
needs to be caused or climbed

332
00:10:33,120 --> 00:10:34,560
uh before you can then start getting to

333
00:10:34,560 --> 00:10:36,640
the other side of realizing the benefits

334
00:10:36,640 --> 00:10:37,760
of checkpointing right

335
00:10:37,760 --> 00:10:39,920
and and and for others it's also a

336
00:10:39,920 --> 00:10:41,279
matter of self-doubt

337
00:10:41,279 --> 00:10:46,079
uh is it complex enough right i think uh

338
00:10:46,079 --> 00:10:47,600
the image that's been built around this

339
00:10:47,600 --> 00:10:50,320
modeling is that it needs to be complex

340
00:10:50,320 --> 00:10:52,079
right and i was like at least what is

341
00:10:52,079 --> 00:10:53,519
being said and said and done

342
00:10:53,519 --> 00:10:55,680
so so once you feel once you take you've

343
00:10:55,680 --> 00:10:58,720
done a test modeling you start

344
00:10:58,720 --> 00:11:01,440
so is this good enough is this something

345
00:11:01,440 --> 00:11:02,800
that's complex enough

346
00:11:02,800 --> 00:11:04,399
uh from an expectation of what a tech

347
00:11:04,399 --> 00:11:06,320
model is right

348
00:11:06,320 --> 00:11:07,680
so one of the one of the things that i

349
00:11:07,680 --> 00:11:09,760
like to say is document what you do and

350
00:11:09,760 --> 00:11:11,200
not the other way around

351
00:11:11,200 --> 00:11:13,920
right so let's see what works from this

352
00:11:13,920 --> 00:11:15,040
morning perspective

353
00:11:15,040 --> 00:11:18,880
and then let's look at formalizing that

354
00:11:20,720 --> 00:11:22,880
so uh talking about schools of threat

355
00:11:22,880 --> 00:11:23,920
modeling uh

356
00:11:23,920 --> 00:11:26,399
this is purely from my perspective uh i

357
00:11:26,399 --> 00:11:27,200
see that there are

358
00:11:27,200 --> 00:11:28,800
really kind of two major schools of

359
00:11:28,800 --> 00:11:30,720
thought you have the story-driven trick

360
00:11:30,720 --> 00:11:31,519
modeling

361
00:11:31,519 --> 00:11:33,839
and then you have the competency module

362
00:11:33,839 --> 00:11:35,279
and let's look at what each of these

363
00:11:35,279 --> 00:11:35,920
things

364
00:11:35,920 --> 00:11:40,000
mean from a storyteller

365
00:11:40,480 --> 00:11:42,399
you're always asking the question of

366
00:11:42,399 --> 00:11:44,320
what if and this is what is the attack

367
00:11:44,320 --> 00:11:46,000
student threat modeling the abuser case

368
00:11:46,000 --> 00:11:47,040
demonstrate modeling

369
00:11:47,040 --> 00:11:48,480
and so on so but you have multiple names

370
00:11:48,480 --> 00:11:49,360
for it but you're going to call it the

371
00:11:49,360 --> 00:11:51,440
storytelling for this presentation right

372
00:11:51,440 --> 00:11:53,760
so in a story-driven threat modeling

373
00:11:53,760 --> 00:11:54,560
scenario

374
00:11:54,560 --> 00:11:56,160
most of your threat models start off

375
00:11:56,160 --> 00:11:57,839
from a water scenario what if this were

376
00:11:57,839 --> 00:11:59,930
to happen to your application

377
00:11:59,930 --> 00:12:02,720
[Music]

378
00:12:02,720 --> 00:12:04,320
from a component of infect modeling it's

379
00:12:04,320 --> 00:12:06,000
more inside out you're essentially kind

380
00:12:06,000 --> 00:12:06,240
of

381
00:12:06,240 --> 00:12:08,720
really breaking down the architecture

382
00:12:08,720 --> 00:12:10,000
and you're kind of seeing in terms

383
00:12:10,000 --> 00:12:11,760
of what are all the various components

384
00:12:11,760 --> 00:12:13,360
in my application and

385
00:12:13,360 --> 00:12:14,800
what are the inherent threats and

386
00:12:14,800 --> 00:12:17,120
vulnerabilities that those components

387
00:12:17,120 --> 00:12:19,120
might have so it's more an inside out

388
00:12:19,120 --> 00:12:20,959
perspective whereas the attack table is

389
00:12:20,959 --> 00:12:22,800
more and outside at that point

390
00:12:22,800 --> 00:12:24,399
the fundamental building block of the

391
00:12:24,399 --> 00:12:26,480
storage and threat model are abuse cases

392
00:12:26,480 --> 00:12:28,560
um suggest you have use cases for

393
00:12:28,560 --> 00:12:30,959
application

394
00:12:30,959 --> 00:12:33,600
uh have one or more abuse cases right so

395
00:12:33,600 --> 00:12:35,040
abuse cases are

396
00:12:35,040 --> 00:12:38,320
one of the more important uh almost like

397
00:12:38,320 --> 00:12:38,800
the

398
00:12:38,800 --> 00:12:41,680
keystones of uh of the threat modeling

399
00:12:41,680 --> 00:12:42,079
uh

400
00:12:42,079 --> 00:12:45,920
uh for storytelling threat model uh

401
00:12:45,920 --> 00:12:47,920
competent events modeling you're always

402
00:12:47,920 --> 00:12:50,000
kind of looking at known issues

403
00:12:50,000 --> 00:12:52,000
right it's always those known issues

404
00:12:52,000 --> 00:12:54,240
those publicly disclosed vulnerabilities

405
00:12:54,240 --> 00:12:56,240
uh uh uh which has been loaded up and

406
00:12:56,240 --> 00:12:57,760
you know for a fact that a particular

407
00:12:57,760 --> 00:12:58,399
component

408
00:12:58,399 --> 00:12:59,680
has these kind of issues like for

409
00:12:59,680 --> 00:13:01,519
example you're going to take an apache

410
00:13:01,519 --> 00:13:04,639
server if you're going to take a uh you

411
00:13:04,639 --> 00:13:06,720
know a protect a particular library

412
00:13:06,720 --> 00:13:09,680
that's been used uh uh extensively you

413
00:13:09,680 --> 00:13:11,200
know what those known issues are so

414
00:13:11,200 --> 00:13:11,920
that's what

415
00:13:11,920 --> 00:13:13,519
a competitive technology is largely

416
00:13:13,519 --> 00:13:15,279
going to be used for

417
00:13:15,279 --> 00:13:18,000
a stoichiometric model is used to force

418
00:13:18,000 --> 00:13:18,480
design

419
00:13:18,480 --> 00:13:20,639
and giving development in most cases as

420
00:13:20,639 --> 00:13:22,480
opposed to the traditional component of

421
00:13:22,480 --> 00:13:24,240
threat modeling which is usually used

422
00:13:24,240 --> 00:13:26,880
pre-designed

423
00:13:27,279 --> 00:13:30,320
and that's the world view that you know

424
00:13:30,320 --> 00:13:31,600
often because

425
00:13:31,600 --> 00:13:33,040
like we said one of the motivations of

426
00:13:33,040 --> 00:13:34,240
threat modeling was first to kind of

427
00:13:34,240 --> 00:13:35,519
look at what the issues are from an

428
00:13:35,519 --> 00:13:37,279
architecture perspective so therefore

429
00:13:37,279 --> 00:13:38,639
from a content different set module

430
00:13:38,639 --> 00:13:40,079
perspective we are largely looking at

431
00:13:40,079 --> 00:13:41,360
threat models that are used as a

432
00:13:41,360 --> 00:13:44,160
pre-design or a design perspective

433
00:13:44,160 --> 00:13:46,720
who uses storytelling technology

434
00:13:46,720 --> 00:13:48,560
security professionals and developers

435
00:13:48,560 --> 00:13:49,440
and automation

436
00:13:49,440 --> 00:13:51,680
engineers and we see why automation

437
00:13:51,680 --> 00:13:53,519
engineers connect and use

438
00:13:53,519 --> 00:13:55,680
uh storytelling but the competent

439
00:13:55,680 --> 00:13:56,639
technology

440
00:13:56,639 --> 00:13:58,160
is also used by architects because

441
00:13:58,160 --> 00:13:59,519
obviously uh you know you're kind of

442
00:13:59,519 --> 00:14:01,199
looking at a

443
00:14:01,199 --> 00:14:02,639
really kind of treadmill at the

444
00:14:02,639 --> 00:14:04,560
blueprint level so you have that

445
00:14:04,560 --> 00:14:05,920
additional persona

446
00:14:05,920 --> 00:14:08,079
of an architect uh coming again from the

447
00:14:08,079 --> 00:14:11,040
stronghold model

448
00:14:11,760 --> 00:14:13,680
the crux of the storytelling threat

449
00:14:13,680 --> 00:14:15,040
modeling is on

450
00:14:15,040 --> 00:14:16,959
depth and and and i want to draw a

451
00:14:16,959 --> 00:14:18,160
little bit of parallel in terms of pen

452
00:14:18,160 --> 00:14:19,600
testing here as well so look at an

453
00:14:19,600 --> 00:14:20,240
application

454
00:14:20,240 --> 00:14:21,600
especially in terms of applications that

455
00:14:21,600 --> 00:14:23,760
have complexities in terms of workflows

456
00:14:23,760 --> 00:14:25,279
they're trying to draw a balance in

457
00:14:25,279 --> 00:14:27,519
terms of finding out deep-rooted

458
00:14:27,519 --> 00:14:29,199
security vulnerabilities that could

459
00:14:29,199 --> 00:14:32,959
actually be found by manual exploits and

460
00:14:32,959 --> 00:14:33,760
whatnot

461
00:14:33,760 --> 00:14:36,320
but you're also looking at an angle of

462
00:14:36,320 --> 00:14:36,959
scale

463
00:14:36,959 --> 00:14:38,720
which is in terms of how well is your

464
00:14:38,720 --> 00:14:40,240
coverage so that's the same school of

465
00:14:40,240 --> 00:14:41,360
thought when you get into threat

466
00:14:41,360 --> 00:14:42,720
modeling because our story is even

467
00:14:42,720 --> 00:14:43,519
threatening

468
00:14:43,519 --> 00:14:45,760
focuses on depth because remember it

469
00:14:45,760 --> 00:14:46,720
asks you the question

470
00:14:46,720 --> 00:14:48,880
what if what if this were to happen what

471
00:14:48,880 --> 00:14:49,760
if

472
00:14:49,760 --> 00:14:51,279
you know there was an attack a vector

473
00:14:51,279 --> 00:14:53,199
that did or weaponized a particular

474
00:14:53,199 --> 00:14:55,360
boundary would be displayed

475
00:14:55,360 --> 00:14:58,399
but in terms of the competent on scale

476
00:14:58,399 --> 00:14:59,440
because you're trying to ensure that you

477
00:14:59,440 --> 00:15:02,320
have as many components asserted

478
00:15:02,320 --> 00:15:04,560
for the potential security issues or

479
00:15:04,560 --> 00:15:05,920
known security issues

480
00:15:05,920 --> 00:15:08,000
so uh there's a fundamental difference

481
00:15:08,000 --> 00:15:09,519
between soil even and complementary

482
00:15:09,519 --> 00:15:11,279
which is that of depth versus scale

483
00:15:11,279 --> 00:15:12,480
and we'll see in the next couple of

484
00:15:12,480 --> 00:15:13,920
slides in terms of how you could kind of

485
00:15:13,920 --> 00:15:16,079
bring both of these together

486
00:15:16,079 --> 00:15:18,320
uh from a sorry different smalling

487
00:15:18,320 --> 00:15:20,639
perspective

488
00:15:20,639 --> 00:15:22,240
to use there but then that's one of the

489
00:15:22,240 --> 00:15:23,519
reasons you want to talk about the open

490
00:15:23,519 --> 00:15:24,079
source

491
00:15:24,079 --> 00:15:26,320
trek playbook platform between them and

492
00:15:26,320 --> 00:15:27,519
a lot of them use a lot of

493
00:15:27,519 --> 00:15:30,880
manual uh kind of uh uh methodologies to

494
00:15:30,880 --> 00:15:32,320
do a story differentiate modeling

495
00:15:32,320 --> 00:15:34,160
uh but you have a lot of commercial

496
00:15:34,160 --> 00:15:35,519
variants from a conference inside

497
00:15:35,519 --> 00:15:36,880
modeling and because we don't want to be

498
00:15:36,880 --> 00:15:38,880
talking about any specific brands here

499
00:15:38,880 --> 00:15:41,920
we're just going to kind of leave you

500
00:15:41,920 --> 00:15:44,720
with you know what those could be and uh

501
00:15:44,720 --> 00:15:46,160
happy to chat about it later

502
00:15:46,160 --> 00:15:48,079
uh but you do have a lot of commercial

503
00:15:48,079 --> 00:15:49,519
platforms in the components of the

504
00:15:49,519 --> 00:15:50,240
technology

505
00:15:50,240 --> 00:15:53,279
space um but not so much modern

506
00:15:53,279 --> 00:15:54,079
perspective right

507
00:15:54,079 --> 00:15:56,160
so that's really a compare and contrast

508
00:15:56,160 --> 00:15:57,440
if you will between the stoichiometrism

509
00:15:57,440 --> 00:15:58,320
and the competency

510
00:15:58,320 --> 00:16:00,560
smart so let's look at how what a

511
00:16:00,560 --> 00:16:02,639
complementary technology

512
00:16:02,639 --> 00:16:05,360
is usually kind of look like and and for

513
00:16:05,360 --> 00:16:07,440
people who use technology platforms

514
00:16:07,440 --> 00:16:09,040
especially in larger enterprises i think

515
00:16:09,040 --> 00:16:09,839
this is something that you would

516
00:16:09,839 --> 00:16:10,480
probably

517
00:16:10,480 --> 00:16:12,880
uh relate to easier because this is what

518
00:16:12,880 --> 00:16:15,600
most commercial trip market platforms do

519
00:16:15,600 --> 00:16:17,199
you usually start with a questionnaire

520
00:16:17,199 --> 00:16:19,199
that kind of talks to you about

521
00:16:19,199 --> 00:16:21,519
what the technology stack is uh then

522
00:16:21,519 --> 00:16:22,639
that's where you kind of load up things

523
00:16:22,639 --> 00:16:23,920
like what programming language is your

524
00:16:23,920 --> 00:16:25,360
application developed on what are the

525
00:16:25,360 --> 00:16:26,720
various components that you have who's

526
00:16:26,720 --> 00:16:28,480
your cloud provider and so on and so

527
00:16:28,480 --> 00:16:29,839
forth and what domain does your

528
00:16:29,839 --> 00:16:30,560
application

529
00:16:30,560 --> 00:16:32,399
work is it in the financial sector is it

530
00:16:32,399 --> 00:16:33,600
in the healthcare is it retail and

531
00:16:33,600 --> 00:16:34,560
things like that so that

532
00:16:34,560 --> 00:16:38,399
the the the associated signatures

533
00:16:38,399 --> 00:16:39,839
are kind of loaded on from the

534
00:16:39,839 --> 00:16:41,440
background and you have uh

535
00:16:41,440 --> 00:16:43,519
you have like a correlation between

536
00:16:43,519 --> 00:16:45,440
potential threat potential impact

537
00:16:45,440 --> 00:16:47,120
of that application to your business and

538
00:16:47,120 --> 00:16:48,240
the vulnerability that it could be

539
00:16:48,240 --> 00:16:49,440
subjected to

540
00:16:49,440 --> 00:16:51,519
and then you have a lot of compliance

541
00:16:51,519 --> 00:16:52,959
and now you subjected to pci

542
00:16:52,959 --> 00:16:54,800
are you in under hipaa are you under

543
00:16:54,800 --> 00:16:57,279
stock and so on and so forth so you you

544
00:16:57,279 --> 00:16:58,880
flush that question and then it kind of

545
00:16:58,880 --> 00:16:59,600
gives you

546
00:16:59,600 --> 00:17:01,759
like a map or a diagram where it tells

547
00:17:01,759 --> 00:17:03,279
you here's your process flow here's your

548
00:17:03,279 --> 00:17:04,319
data flow

549
00:17:04,319 --> 00:17:05,599
this is how your users kind of

550
00:17:05,599 --> 00:17:06,640
potentially interact with your

551
00:17:06,640 --> 00:17:07,599
application

552
00:17:07,599 --> 00:17:08,720
and things like that and this is where

553
00:17:08,720 --> 00:17:10,240
you'll probably be able to move around

554
00:17:10,240 --> 00:17:10,720
those

555
00:17:10,720 --> 00:17:12,559
bits and pieces uh to make it more

556
00:17:12,559 --> 00:17:14,559
customized and then once you've done

557
00:17:14,559 --> 00:17:15,039
that

558
00:17:15,039 --> 00:17:17,679
you have a potential list of threads and

559
00:17:17,679 --> 00:17:19,280
associated vulnerabilities and this is

560
00:17:19,280 --> 00:17:20,319
where we go back

561
00:17:20,319 --> 00:17:22,640
in terms of these platforms being able

562
00:17:22,640 --> 00:17:23,599
to work

563
00:17:23,599 --> 00:17:26,880
on known issues so based on the based on

564
00:17:26,880 --> 00:17:31,360
uh the components that you've loaded on

565
00:17:31,360 --> 00:17:33,120
in the initial questionnaire you

566
00:17:33,120 --> 00:17:36,000
automatically have a list of threads

567
00:17:36,000 --> 00:17:37,760
and associated vulnerabilities and

568
00:17:37,760 --> 00:17:39,520
countermeasures

569
00:17:39,520 --> 00:17:41,360
for those known components and this is

570
00:17:41,360 --> 00:17:43,039
where you're also looking at scale

571
00:17:43,039 --> 00:17:45,760
because remember let's assume that your

572
00:17:45,760 --> 00:17:47,039
application uses

573
00:17:47,039 --> 00:17:50,000
you know for lack of a better number 250

574
00:17:50,000 --> 00:17:51,440
per capita application

575
00:17:51,440 --> 00:17:53,039
you load up all your 250 components and

576
00:17:53,039 --> 00:17:54,480
then you already have

577
00:17:54,480 --> 00:17:56,640
a fundamental podium on which you're

578
00:17:56,640 --> 00:17:58,400
starting off

579
00:17:58,400 --> 00:17:59,760
your threat modeling exercise because

580
00:17:59,760 --> 00:18:01,440
you have those two group d components

581
00:18:01,440 --> 00:18:03,600
and if those are pretty known components

582
00:18:03,600 --> 00:18:04,880
you're going to have 250

583
00:18:04,880 --> 00:18:06,799
uh competences uh threats and

584
00:18:06,799 --> 00:18:07,840
vulnerabilities so you're already

585
00:18:07,840 --> 00:18:09,840
starting off with a place

586
00:18:09,840 --> 00:18:13,200
and then once you've done that

587
00:18:13,200 --> 00:18:14,640
you get to the countermeasure in terms

588
00:18:14,640 --> 00:18:16,480
of each of those threats

589
00:18:16,480 --> 00:18:18,400
and potential vulnerabilities then you

590
00:18:18,400 --> 00:18:20,640
have uh your remediation strategies and

591
00:18:20,640 --> 00:18:22,080
your validation strategies for each of

592
00:18:22,080 --> 00:18:23,120
those vulnerabilities

593
00:18:23,120 --> 00:18:25,200
right so this is really like a very

594
00:18:25,200 --> 00:18:26,559
bird's-eye view of what

595
00:18:26,559 --> 00:18:28,799
a genetic workflow from a component

596
00:18:28,799 --> 00:18:30,480
driven threshold kind of looks like so

597
00:18:30,480 --> 00:18:33,039
let's now look at what is

598
00:18:33,039 --> 00:18:34,480
this modeling which is something that we

599
00:18:34,480 --> 00:18:36,240
usually work on because uh uh

600
00:18:36,240 --> 00:18:38,799
you know we predominantly started off uh

601
00:18:38,799 --> 00:18:39,919
from from from

602
00:18:39,919 --> 00:18:41,039
a testing perspective from an

603
00:18:41,039 --> 00:18:43,039
applicative chariot perspective uh so

604
00:18:43,039 --> 00:18:44,400
therefore our technology that we do with

605
00:18:44,400 --> 00:18:46,240
d45 is largely story driven

606
00:18:46,240 --> 00:18:48,720
uh and one of one of the most easiest

607
00:18:48,720 --> 00:18:50,000
way for us to do throughout even

608
00:18:50,000 --> 00:18:51,520
threat modeling is when we give an

609
00:18:51,520 --> 00:18:53,919
application to pentest for example

610
00:18:53,919 --> 00:18:57,679
we start off with something as simple as

611
00:18:57,679 --> 00:19:00,320
a scribe on a piece of paper that says

612
00:19:00,320 --> 00:19:01,840
okay this is the application this is the

613
00:19:01,840 --> 00:19:03,039
kind of workflow that the application

614
00:19:03,039 --> 00:19:03,440
has

615
00:19:03,440 --> 00:19:05,200
so let me just draw a quick attack trick

616
00:19:05,200 --> 00:19:06,799
right so so that's how we started off

617
00:19:06,799 --> 00:19:07,280
between

618
00:19:07,280 --> 00:19:09,520
check modeling but then over the last

619
00:19:09,520 --> 00:19:10,799
three or four years we've been able to

620
00:19:10,799 --> 00:19:12,080
kind of formalize that

621
00:19:12,080 --> 00:19:13,520
into something very interesting that

622
00:19:13,520 --> 00:19:15,280
kind of feeds into the security

623
00:19:15,280 --> 00:19:16,559
animation systems as well so we'll talk

624
00:19:16,559 --> 00:19:17,280
about that

625
00:19:17,280 --> 00:19:19,520
so from a storyline technology

626
00:19:19,520 --> 00:19:21,360
perspective you're not immediately this

627
00:19:21,360 --> 00:19:23,039
you have a use case every application

628
00:19:23,039 --> 00:19:24,559
has

629
00:19:24,559 --> 00:19:28,640
multiple it's just kind of breakdown a

630
00:19:28,640 --> 00:19:31,200
use case which definitely talks about

631
00:19:31,200 --> 00:19:32,480
what the functionality of the

632
00:19:32,480 --> 00:19:33,520
application is

633
00:19:33,520 --> 00:19:35,919
into an abusive case or an abuse case

634
00:19:35,919 --> 00:19:36,559
which means

635
00:19:36,559 --> 00:19:38,480
what can all what could go wrong with

636
00:19:38,480 --> 00:19:40,640
that application so every use case

637
00:19:40,640 --> 00:19:44,080
would have multiple abuse cases

638
00:19:44,080 --> 00:19:47,360
and each of the use cases

639
00:19:47,360 --> 00:19:49,440
have something called an attack model

640
00:19:49,440 --> 00:19:50,720
which essentially says

641
00:19:50,720 --> 00:19:53,039
how can that abuse case come to life

642
00:19:53,039 --> 00:19:53,760
which in

643
00:19:53,760 --> 00:19:55,360
the security engineering world would

644
00:19:55,360 --> 00:19:56,880
potentially mean something like how can

645
00:19:56,880 --> 00:19:58,320
you weaponize that particular

646
00:19:58,320 --> 00:19:59,360
vulnerability

647
00:19:59,360 --> 00:20:02,159
so the the anatomy of of of the

648
00:20:02,159 --> 00:20:03,280
stoichiometric model

649
00:20:03,280 --> 00:20:05,840
is a use case drilling down into one or

650
00:20:05,840 --> 00:20:06,720
more abuse

651
00:20:06,720 --> 00:20:10,159
cases and then

652
00:20:10,159 --> 00:20:13,600
into more than one attack models

653
00:20:13,600 --> 00:20:15,520
let's look at an example here right uh

654
00:20:15,520 --> 00:20:16,799
let's assume there's a there's an

655
00:20:16,799 --> 00:20:18,480
application where the user story says

656
00:20:18,480 --> 00:20:18,880
this

657
00:20:18,880 --> 00:20:21,039
as a user i want to be able to search

658
00:20:21,039 --> 00:20:22,480
for my nodes using the search

659
00:20:22,480 --> 00:20:23,679
functionality let's assume there's a

660
00:20:23,679 --> 00:20:25,039
search functionality

661
00:20:25,039 --> 00:20:27,600
in that application and this is just

662
00:20:27,600 --> 00:20:30,959
going ahead and searching for your notes

663
00:20:33,360 --> 00:20:35,520
just use case for the hdb as an abuser i

664
00:20:35,520 --> 00:20:36,880
would like to search for notes that do

665
00:20:36,880 --> 00:20:37,840
not belong to me

666
00:20:37,840 --> 00:20:40,240
which means you're kind of looking at uh

667
00:20:40,240 --> 00:20:41,840
elevation of privileges they're kind of

668
00:20:41,840 --> 00:20:43,520
looking at bridge of confidentiality and

669
00:20:43,520 --> 00:20:44,240
things like that

670
00:20:44,240 --> 00:20:46,559
so that could be one use abuse case the

671
00:20:46,559 --> 00:20:48,400
other abuse case could be as in a

672
00:20:48,400 --> 00:20:52,240
as an abuser i would like to share

673
00:20:52,400 --> 00:20:54,799
notes that would steal the victims uh

674
00:20:54,799 --> 00:20:56,400
account details you're talking about

675
00:20:56,400 --> 00:20:58,559
more integrity based attacks there as

676
00:20:58,559 --> 00:20:59,520
well so just a

677
00:20:59,520 --> 00:21:02,159
just a very very uh novice kind of

678
00:21:02,159 --> 00:21:03,520
abuser case just for us to get an

679
00:21:03,520 --> 00:21:05,120
understanding of how this works

680
00:21:05,120 --> 00:21:07,039
so how do you escape those use cases in

681
00:21:07,039 --> 00:21:08,960
this example trickle down to two abuse

682
00:21:08,960 --> 00:21:09,840
cases

683
00:21:09,840 --> 00:21:11,760
now for the first abuse case you could

684
00:21:11,760 --> 00:21:13,039
potentially have

685
00:21:13,039 --> 00:21:15,760
three attack models so how would you

686
00:21:15,760 --> 00:21:16,640
potentially

687
00:21:16,640 --> 00:21:19,200
weaponize the first abuser case you

688
00:21:19,200 --> 00:21:20,400
could do that using manual middle

689
00:21:20,400 --> 00:21:21,200
attacks

690
00:21:21,200 --> 00:21:24,480
you could do that using injection

691
00:21:24,480 --> 00:21:25,200
attacks

692
00:21:25,200 --> 00:21:28,320
command os equalize if it's possible

693
00:21:28,320 --> 00:21:29,600
and then you probably do something like

694
00:21:29,600 --> 00:21:31,760
the ur redirection and you would kind of

695
00:21:31,760 --> 00:21:32,720
take that user

696
00:21:32,720 --> 00:21:35,120
somewhere else and then you know be able

697
00:21:35,120 --> 00:21:36,400
to kind of steal those

698
00:21:36,400 --> 00:21:37,919
credentials and things like that right

699
00:21:37,919 --> 00:21:40,320
so let's assume you have three of those

700
00:21:40,320 --> 00:21:43,600
uh attack uh models so what you see here

701
00:21:43,600 --> 00:21:44,080
is that

702
00:21:44,080 --> 00:21:47,760
one user story now has potentially

703
00:21:47,760 --> 00:21:50,960
three potential attack vectors now this

704
00:21:50,960 --> 00:21:53,120
is really how a story differences model

705
00:21:53,120 --> 00:21:55,039
kind of drips down

706
00:21:55,039 --> 00:21:57,600
and this is a great way a segue for us

707
00:21:57,600 --> 00:21:59,120
to kind of really look at

708
00:21:59,120 --> 00:22:01,679
um a playbook now those who are

709
00:22:01,679 --> 00:22:03,360
interested that's the github

710
00:22:03,360 --> 00:22:05,120
link there for the third playbook

711
00:22:05,120 --> 00:22:06,640
platform this was something that we open

712
00:22:06,640 --> 00:22:07,039
source

713
00:22:07,039 --> 00:22:10,240
almost three or four years ago um and a

714
00:22:10,240 --> 00:22:11,679
lot of people have done different things

715
00:22:11,679 --> 00:22:13,120
with it uh what i'm going to show you

716
00:22:13,120 --> 00:22:15,039
today is a very simple demo that my

717
00:22:15,039 --> 00:22:16,400
colleague and i put together

718
00:22:16,400 --> 00:22:18,000
i think in a very raw format because we

719
00:22:18,000 --> 00:22:19,440
just took a couple of hours and just put

720
00:22:19,440 --> 00:22:20,960
this together but there's really more

721
00:22:20,960 --> 00:22:22,799
fluid in terms of what the possibilities

722
00:22:22,799 --> 00:22:25,200
are of it so let's kind of

723
00:22:25,200 --> 00:22:29,039
look at i still hope

724
00:22:29,039 --> 00:22:31,600
you're able to see uh so paul and adam

725
00:22:31,600 --> 00:22:32,880
can you just give me a quick

726
00:22:32,880 --> 00:22:34,240
thumbs up in case you'll be able to see

727
00:22:34,240 --> 00:22:36,320
the browser here because i'm sharing

728
00:22:36,320 --> 00:22:41,840
two windows

729
00:22:43,840 --> 00:22:47,120
thank you okay so this is the uh let me

730
00:22:47,120 --> 00:22:47,520
just

731
00:22:47,520 --> 00:22:50,240
okay so this is the uh thread modeling

732
00:22:50,240 --> 00:22:50,960
uh

733
00:22:50,960 --> 00:22:54,320
checkplaybook interface and what you see

734
00:22:54,320 --> 00:22:54,960
here

735
00:22:54,960 --> 00:22:57,039
is that you essentially and like i said

736
00:22:57,039 --> 00:22:58,640
you could download this from the git and

737
00:22:58,640 --> 00:22:59,440
you could kind of

738
00:22:59,440 --> 00:23:01,760
uh do what you want with it so what

739
00:23:01,760 --> 00:23:02,880
we've done here

740
00:23:02,880 --> 00:23:05,360
is that we've just loaded up something

741
00:23:05,360 --> 00:23:07,280
called an expenser project

742
00:23:07,280 --> 00:23:08,880
and if you look at the expensive project

743
00:23:08,880 --> 00:23:10,720
it would i just for the for sake of the

744
00:23:10,720 --> 00:23:13,200
demo here i have one user story

745
00:23:13,200 --> 00:23:14,880
that breaks my thread scenarios and

746
00:23:14,880 --> 00:23:16,159
vulnerabilities i'll take you through

747
00:23:16,159 --> 00:23:16,640
that

748
00:23:16,640 --> 00:23:19,360
for example if you look at the user

749
00:23:19,360 --> 00:23:21,600
story i've created one user story called

750
00:23:21,600 --> 00:23:24,240
create upload expense right so this is a

751
00:23:24,240 --> 00:23:25,919
this is an expensive project essentially

752
00:23:25,919 --> 00:23:27,840
means imagine this is a platform

753
00:23:27,840 --> 00:23:30,000
where employees would essentially upload

754
00:23:30,000 --> 00:23:31,200
their expenses

755
00:23:31,200 --> 00:23:33,039
uh and for them to kind of get

756
00:23:33,039 --> 00:23:35,360
reimbursed uh from the accounting or the

757
00:23:35,360 --> 00:23:36,159
financial department

758
00:23:36,159 --> 00:23:38,080
right so imagine it's that kind of an

759
00:23:38,080 --> 00:23:39,919
application here so

760
00:23:39,919 --> 00:23:41,520
one of the user stories here is for you

761
00:23:41,520 --> 00:23:44,320
to be able to kind of create

762
00:23:44,320 --> 00:23:46,960
your experience

763
00:23:48,480 --> 00:23:50,400
user is as a user i'm able to create and

764
00:23:50,400 --> 00:23:51,919
upload expenses and project limits that

765
00:23:51,919 --> 00:23:53,840
have been incurred by me for processing

766
00:23:53,840 --> 00:23:55,840
and payment analytics right so any just

767
00:23:55,840 --> 00:23:56,880
any

768
00:23:56,880 --> 00:23:58,720
descriptions here not really the point

769
00:23:58,720 --> 00:24:00,720
um so if you look at that user story

770
00:24:00,720 --> 00:24:01,919
we've kind of created

771
00:24:01,919 --> 00:24:03,840
three abuser stories and the way we've

772
00:24:03,840 --> 00:24:04,960
been able to create this

773
00:24:04,960 --> 00:24:06,960
primarily they want to talk to you is by

774
00:24:06,960 --> 00:24:08,159
yaml files

775
00:24:08,159 --> 00:24:10,799
so thread playbook uh in the backend

776
00:24:10,799 --> 00:24:11,679
really is

777
00:24:11,679 --> 00:24:15,840
uh really our

778
00:24:16,880 --> 00:24:19,120
facebook files which is really the uh

779
00:24:19,120 --> 00:24:20,559
fabric that drives them

780
00:24:20,559 --> 00:24:22,000
and for automation engineers if you're

781
00:24:22,000 --> 00:24:24,240
interested uh we use a lot of robot

782
00:24:24,240 --> 00:24:25,120
framework

783
00:24:25,120 --> 00:24:26,720
uh so what we've done is we've been able

784
00:24:26,720 --> 00:24:28,240
to kind of develop a lot of robot

785
00:24:28,240 --> 00:24:29,919
frameworks for popularly used open

786
00:24:29,919 --> 00:24:30,720
source

787
00:24:30,720 --> 00:24:33,279
tools like that we have it for wiper as

788
00:24:33,279 --> 00:24:34,880
well because that we've got npm on it

789
00:24:34,880 --> 00:24:36,320
we've got a lot of these things i can

790
00:24:36,320 --> 00:24:37,200
send you the link

791
00:24:37,200 --> 00:24:38,880
in terms of being able to download those

792
00:24:38,880 --> 00:24:40,400
robot scripts

793
00:24:40,400 --> 00:24:43,679
so what you have here is you have this

794
00:24:43,679 --> 00:24:44,720
yaml file

795
00:24:44,720 --> 00:24:46,320
in which you would be able to kind of

796
00:24:46,320 --> 00:24:48,559
create a user

797
00:24:48,559 --> 00:24:50,880
a use case here if you see the use cases

798
00:24:50,880 --> 00:24:52,640
to create upload expense

799
00:24:52,640 --> 00:24:54,880
and then you give a description here and

800
00:24:54,880 --> 00:24:56,480
then you could have multiple use cases

801
00:24:56,480 --> 00:24:58,320
here for example one of these case

802
00:24:58,320 --> 00:25:00,400
could be manipulated expense information

803
00:25:00,400 --> 00:25:01,840
give a description here

804
00:25:01,840 --> 00:25:04,080
and then you could essentially say how

805
00:25:04,080 --> 00:25:06,320
you will recognize that so one you you

806
00:25:06,320 --> 00:25:08,080
could do that with equal injection

807
00:25:08,080 --> 00:25:10,080
so if you give something called the repo

808
00:25:10,080 --> 00:25:11,919
here so what you've done is that

809
00:25:11,919 --> 00:25:13,679
playbook also has a repository in the

810
00:25:13,679 --> 00:25:15,679
background in terms of our instance here

811
00:25:15,679 --> 00:25:17,200
and we've connected that to a database

812
00:25:17,200 --> 00:25:19,679
base which has all the cwe ids that are

813
00:25:19,679 --> 00:25:21,440
associated with a particular

814
00:25:21,440 --> 00:25:24,480
vulnerability for example if i just say

815
00:25:24,480 --> 00:25:26,880
a reference as sql injection and

816
00:25:26,880 --> 00:25:28,320
security three which means

817
00:25:28,320 --> 00:25:29,840
it's a high serious vulnerability

818
00:25:29,840 --> 00:25:31,840
automatically the repo would pull in the

819
00:25:31,840 --> 00:25:33,120
cwe ids

820
00:25:33,120 --> 00:25:35,120
of sql injection and their associated

821
00:25:35,120 --> 00:25:36,400
vulnerabilities

822
00:25:36,400 --> 00:25:38,000
so similarly you can actually go ahead

823
00:25:38,000 --> 00:25:40,159
and create as many abuser cases as you

824
00:25:40,159 --> 00:25:41,039
would want

825
00:25:41,039 --> 00:25:42,400
so one of the questions that we get

826
00:25:42,400 --> 00:25:44,320
asked a lot is hey do i need to create

827
00:25:44,320 --> 00:25:46,400
these abuser stories

828
00:25:46,400 --> 00:25:49,360
every time i have a particular use case

829
00:25:49,360 --> 00:25:51,440
so the answer to that is yes and no

830
00:25:51,440 --> 00:25:53,760
you would have to create it once but one

831
00:25:53,760 --> 00:25:54,720
of the things they always

832
00:25:54,720 --> 00:25:56,960
counter that is you could do something

833
00:25:56,960 --> 00:25:57,840
very simple

834
00:25:57,840 --> 00:26:00,640
because you are already documenting your

835
00:26:00,640 --> 00:26:02,000
user stories today

836
00:26:02,000 --> 00:26:04,240
as part of agile apps like uh uh

837
00:26:04,240 --> 00:26:06,240
documenting user stories in jera

838
00:26:06,240 --> 00:26:08,559
or a confidence is already a thing so

839
00:26:08,559 --> 00:26:09,520
all know

840
00:26:09,520 --> 00:26:11,440
all that you need to do is have your

841
00:26:11,440 --> 00:26:13,440
user cases kind of documented at the

842
00:26:13,440 --> 00:26:14,320
same time

843
00:26:14,320 --> 00:26:15,760
and once you have your user bases

844
00:26:15,760 --> 00:26:17,360
documented once

845
00:26:17,360 --> 00:26:19,120
the people who do been testing uh you

846
00:26:19,120 --> 00:26:20,480
know this is that a lot of these

847
00:26:20,480 --> 00:26:21,440
security cases

848
00:26:21,440 --> 00:26:24,640
a lot of these abuser cases are reusable

849
00:26:24,640 --> 00:26:26,480
so what you're doing is you're creating

850
00:26:26,480 --> 00:26:29,200
these smaller abusers cases

851
00:26:29,200 --> 00:26:30,960
uh uh components that you can

852
00:26:30,960 --> 00:26:32,559
essentially kind of mix and match

853
00:26:32,559 --> 00:26:34,720
to any application at any given point in

854
00:26:34,720 --> 00:26:36,080
time to create these

855
00:26:36,080 --> 00:26:37,840
abusive cases once you'll be then able

856
00:26:37,840 --> 00:26:39,600
to move them around into multiple

857
00:26:39,600 --> 00:26:41,039
applications as well

858
00:26:41,039 --> 00:26:42,480
so this is how you would actually go

859
00:26:42,480 --> 00:26:44,240
ahead and create

860
00:26:44,240 --> 00:26:47,679
uh your yaml spec in terms of use cases

861
00:26:47,679 --> 00:26:49,279
to abuse your cases

862
00:26:49,279 --> 00:26:51,039
and the key here is really kind of being

863
00:26:51,039 --> 00:26:53,120
able to give that reference here

864
00:26:53,120 --> 00:26:55,440
in terms of how you would weaponize that

865
00:26:55,440 --> 00:26:56,240
vulnerability

866
00:26:56,240 --> 00:26:58,159
so let's go back into the into the ui

867
00:26:58,159 --> 00:27:00,320
here so we have this use case

868
00:27:00,320 --> 00:27:03,440
and we have these three aggregate cases

869
00:27:03,440 --> 00:27:05,279
now if you click on the abuser case here

870
00:27:05,279 --> 00:27:06,720
you'll be able to expand

871
00:27:06,720 --> 00:27:08,799
on what that particular user case is

872
00:27:08,799 --> 00:27:10,400
like we saw in the previous example but

873
00:27:10,400 --> 00:27:11,200
if you actually

874
00:27:11,200 --> 00:27:13,760
go drill down here here's where it tells

875
00:27:13,760 --> 00:27:15,679
you how you plan to weaponize this

876
00:27:15,679 --> 00:27:17,360
particular case you could do this using

877
00:27:17,360 --> 00:27:18,559
sql transaction

878
00:27:18,559 --> 00:27:20,960
you could using compromise manage your

879
00:27:20,960 --> 00:27:22,799
password compromise manage your arts

880
00:27:22,799 --> 00:27:23,520
tokens

881
00:27:23,520 --> 00:27:26,799
and now you drill down one level below

882
00:27:26,799 --> 00:27:28,720
in terms of the various ways in which

883
00:27:28,720 --> 00:27:29,919
you could uh

884
00:27:29,919 --> 00:27:32,720
even various ways of weaponization right

885
00:27:32,720 --> 00:27:34,399
for example you could

886
00:27:34,399 --> 00:27:35,760
see if there's a sequel injection

887
00:27:35,760 --> 00:27:36,799
possibility using an automated

888
00:27:36,799 --> 00:27:38,640
vulnerability scan

889
00:27:38,640 --> 00:27:40,080
you could check this using a manual

890
00:27:40,080 --> 00:27:42,000
exploit uh you could run

891
00:27:42,000 --> 00:27:43,600
an exploit script which we'll talk about

892
00:27:43,600 --> 00:27:46,000
a little later you could run an sca scan

893
00:27:46,000 --> 00:27:49,600
or you could do a static another

894
00:27:49,600 --> 00:27:51,679
so these are the various ways in which

895
00:27:51,679 --> 00:27:52,960
you could potentially

896
00:27:52,960 --> 00:27:55,200
uh find that particular sequence section

897
00:27:55,200 --> 00:27:56,559
uh bypass limit

898
00:27:56,559 --> 00:27:57,840
so if you just click on this rms

899
00:27:57,840 --> 00:27:59,679
vulnerability scanning so here we've

900
00:27:59,679 --> 00:28:01,200
talked about what are the various tools

901
00:28:01,200 --> 00:28:03,919
that you could potentially

902
00:28:03,919 --> 00:28:05,520
run that tool you'll actually see that

903
00:28:05,520 --> 00:28:07,200
the test case has been executed so i'm

904
00:28:07,200 --> 00:28:08,880
just going to go back here

905
00:28:08,880 --> 00:28:12,080
to the dashboard real quick

906
00:28:12,080 --> 00:28:14,840
and then i'm going to show you in terms

907
00:28:14,840 --> 00:28:17,600
of

908
00:28:17,600 --> 00:28:19,760
so if you look expensive project here

909
00:28:19,760 --> 00:28:20,880
you'll see the number of

910
00:28:20,880 --> 00:28:22,960
scans that you've done so for this

911
00:28:22,960 --> 00:28:24,240
particular project what i've done

912
00:28:24,240 --> 00:28:27,120
is i've run a zap scan i've run an npm

913
00:28:27,120 --> 00:28:28,159
audit scan

914
00:28:28,159 --> 00:28:30,159
and i've also done a manual assessment

915
00:28:30,159 --> 00:28:32,320
here

916
00:28:32,559 --> 00:28:35,440
so when you look at the scan results

917
00:28:35,440 --> 00:28:37,679
from the node.js scan for example

918
00:28:37,679 --> 00:28:40,880
you would see that the node.js found

919
00:28:40,880 --> 00:28:42,640
four vulnerabilities out of which one of

920
00:28:42,640 --> 00:28:44,960
them was sql injection

921
00:28:44,960 --> 00:28:48,159
right you found the cw 89 right so

922
00:28:48,159 --> 00:28:50,720
similarly

923
00:28:51,840 --> 00:28:54,799
you would find that found a sql

924
00:28:54,799 --> 00:28:56,960
injection as well

925
00:28:56,960 --> 00:28:58,720
so you can essentially what you could do

926
00:28:58,720 --> 00:29:00,080
with thread playbook is

927
00:29:00,080 --> 00:29:03,440
you would uh

928
00:29:03,440 --> 00:29:05,520
so it's the thread model that comes from

929
00:29:05,520 --> 00:29:07,039
the left to right perspective just

930
00:29:07,039 --> 00:29:09,039
logically speaking and then you have the

931
00:29:09,039 --> 00:29:10,240
scanners that

932
00:29:10,240 --> 00:29:12,960
run on the application and they give you

933
00:29:12,960 --> 00:29:13,440
uh

934
00:29:13,440 --> 00:29:16,080
vulnerabilities uh that they find and

935
00:29:16,080 --> 00:29:17,600
now what you're able to essentially do

936
00:29:17,600 --> 00:29:19,039
is you're able to kind of map your

937
00:29:19,039 --> 00:29:21,840
threat models to your vulnerabilities

938
00:29:21,840 --> 00:29:23,760
so you can now say how many of your

939
00:29:23,760 --> 00:29:26,000
threat models have actually found

940
00:29:26,000 --> 00:29:29,200
a world kind of were realized by

941
00:29:29,200 --> 00:29:30,720
actually scanners finding them

942
00:29:30,720 --> 00:29:32,080
which means that if you found a threat

943
00:29:32,080 --> 00:29:34,159
model now you know for a fact that that

944
00:29:34,159 --> 00:29:35,039
threat model

945
00:29:35,039 --> 00:29:37,360
was eventually uh it was kind of the

946
00:29:37,360 --> 00:29:39,039
same vulnerability was formed by scanner

947
00:29:39,039 --> 00:29:40,320
so there's that mapping between the

948
00:29:40,320 --> 00:29:41,679
thresh model to a scan

949
00:29:41,679 --> 00:29:43,760
and on the on the on on the other side

950
00:29:43,760 --> 00:29:44,960
of it is what are all the

951
00:29:44,960 --> 00:29:47,840
vulnerabilities and

952
00:29:47,840 --> 00:29:49,520
vulnerabilities that you never thought

953
00:29:49,520 --> 00:29:51,520
existed which means that now you found a

954
00:29:51,520 --> 00:29:53,279
vulnerability and there's no associated

955
00:29:53,279 --> 00:29:54,000
trick model to

956
00:29:54,000 --> 00:29:55,360
it it tells you that your threat

957
00:29:55,360 --> 00:29:57,279
modelling can be done better

958
00:29:57,279 --> 00:30:00,399
right so that's just to uh one of the

959
00:30:00,399 --> 00:30:02,080
byproducts if you will of using

960
00:30:02,080 --> 00:30:03,760
something like that playbook like i said

961
00:30:03,760 --> 00:30:06,159
uh go on to the git live there's a lot

962
00:30:06,159 --> 00:30:07,840
of videos there's a lot of materials

963
00:30:07,840 --> 00:30:09,039
that you put out there in terms of

964
00:30:09,039 --> 00:30:10,399
various ways and you could use

965
00:30:10,399 --> 00:30:12,559
modeling and it's completely open source

966
00:30:12,559 --> 00:30:14,080
so you could kind of just

967
00:30:14,080 --> 00:30:17,279
use it the way you would want to use uh

968
00:30:17,279 --> 00:30:20,720
let me just quickly go back to the

969
00:30:20,840 --> 00:30:22,960
presentation

970
00:30:22,960 --> 00:30:26,399
um and it's largely used um using

971
00:30:26,399 --> 00:30:29,679
uh frameworks like uh the mongodb uh

972
00:30:29,679 --> 00:30:32,799
a graphql and python um and it

973
00:30:32,799 --> 00:30:34,880
is largely used from a story

974
00:30:34,880 --> 00:30:36,640
story-driven set modeling perspective

975
00:30:36,640 --> 00:30:38,559
and we said it's a great way for us to

976
00:30:38,559 --> 00:30:40,000
kind of map

977
00:30:40,000 --> 00:30:43,840
threats to vulnerabilities as well

978
00:30:46,000 --> 00:30:47,679
if you kind of look back to the original

979
00:30:47,679 --> 00:30:49,279
use case abuse case attack model

980
00:30:49,279 --> 00:30:50,159
perspective

981
00:30:50,159 --> 00:30:52,000
what we've been able to do now with red

982
00:30:52,000 --> 00:30:53,840
playbook is actually drill down into

983
00:30:53,840 --> 00:30:54,880
test cases

984
00:30:54,880 --> 00:30:57,039
so which now tells you how plausible are

985
00:30:57,039 --> 00:30:58,720
they right so you start off with you

986
00:30:58,720 --> 00:31:02,159
this case the attack model and now you

987
00:31:02,159 --> 00:31:03,360
have the test case

988
00:31:03,360 --> 00:31:04,720
level as well so if you what i'm trying

989
00:31:04,720 --> 00:31:07,440
to get here is now stress modeling

990
00:31:07,440 --> 00:31:09,919
can be used as a way to effectively

991
00:31:09,919 --> 00:31:10,880
generate

992
00:31:10,880 --> 00:31:14,080
security test cases as well so if you

993
00:31:14,080 --> 00:31:16,159
look at it here you start

994
00:31:16,159 --> 00:31:19,039
to use the

995
00:31:19,840 --> 00:31:22,080
come back um to a security test case

996
00:31:22,080 --> 00:31:23,360
potentially means

997
00:31:23,360 --> 00:31:24,480
just look at the man in the middle

998
00:31:24,480 --> 00:31:26,320
attack for example you now have three

999
00:31:26,320 --> 00:31:27,679
security test cases for

1000
00:31:27,679 --> 00:31:29,679
the middle attack you have three more

1001
00:31:29,679 --> 00:31:31,360
for injection attacks so

1002
00:31:31,360 --> 00:31:33,039
going back to our previous example one

1003
00:31:33,039 --> 00:31:34,720
of the byproducts of stress modeling is

1004
00:31:34,720 --> 00:31:35,840
for you to potentially be able to

1005
00:31:35,840 --> 00:31:36,480
generate

1006
00:31:36,480 --> 00:31:39,919
effective security cases

1007
00:31:39,919 --> 00:31:42,320
now let's talk about how automation

1008
00:31:42,320 --> 00:31:44,159
comes in here so now that we have test

1009
00:31:44,159 --> 00:31:45,600
cases

1010
00:31:45,600 --> 00:31:47,919
there are various ways in which you can

1011
00:31:47,919 --> 00:31:49,760
automate these databases right

1012
00:31:49,760 --> 00:31:51,360
so if you look at a test case there are

1013
00:31:51,360 --> 00:31:52,799
three things that are possible a test

1014
00:31:52,799 --> 00:31:55,000
case is either completely

1015
00:31:55,000 --> 00:31:58,080
experienced by a rule which means that

1016
00:31:58,080 --> 00:31:59,120
that word

1017
00:31:59,120 --> 00:32:01,120
nmap genetics whatever it is that

1018
00:32:01,120 --> 00:32:02,240
particular test case

1019
00:32:02,240 --> 00:32:05,120
can be completely executed by a dash

1020
00:32:05,120 --> 00:32:06,240
faster than c2

1021
00:32:06,240 --> 00:32:09,840
that's a tool uh driven trip a test case

1022
00:32:09,840 --> 00:32:12,159
on the other side you have completely

1023
00:32:12,159 --> 00:32:13,440
manual vulnerabilities

1024
00:32:13,440 --> 00:32:14,720
vulnerabilities that could never be

1025
00:32:14,720 --> 00:32:16,799
found by a tool either because they have

1026
00:32:16,799 --> 00:32:20,519
very deep subject

1027
00:32:20,519 --> 00:32:23,279
capations or they could be hidden behind

1028
00:32:23,279 --> 00:32:24,559
authentication

1029
00:32:24,559 --> 00:32:26,559
mechanisms that scanners may not be able

1030
00:32:26,559 --> 00:32:28,320
to go in so you can potentially do

1031
00:32:28,320 --> 00:32:31,200
a parameterized dash scan using proxy

1032
00:32:31,200 --> 00:32:33,039
but let's assume that there are

1033
00:32:33,039 --> 00:32:34,399
vulnerabilities that are completely

1034
00:32:34,399 --> 00:32:36,960
manual so those you can actually use

1035
00:32:36,960 --> 00:32:40,080
scripts um you can actually use the same

1036
00:32:40,080 --> 00:32:43,039
automation fabrics

1037
00:32:43,039 --> 00:32:46,159
robot etc for us to build security

1038
00:32:46,159 --> 00:32:47,840
exploits tips so just like you have

1039
00:32:47,840 --> 00:32:49,679
functional testers build security

1040
00:32:49,679 --> 00:32:50,320
regression

1041
00:32:50,320 --> 00:32:53,519
uh build functional regression scripts

1042
00:32:53,519 --> 00:32:55,919
using selenium robot and things like

1043
00:32:55,919 --> 00:32:57,200
that you could now

1044
00:32:57,200 --> 00:33:00,000
use the same automation frameworks to

1045
00:33:00,000 --> 00:33:00,320
build

1046
00:33:00,320 --> 00:33:02,799
security exploit scripts so if you find

1047
00:33:02,799 --> 00:33:04,240
a manual vulnerability

1048
00:33:04,240 --> 00:33:05,679
all that you need to do is write an

1049
00:33:05,679 --> 00:33:07,279
automation script

1050
00:33:07,279 --> 00:33:10,640
that mimics the things it took

1051
00:33:10,640 --> 00:33:12,640
uh to actually find that vulnerability

1052
00:33:12,640 --> 00:33:14,080
so that's a completely

1053
00:33:14,080 --> 00:33:17,120
manual driven uh security test case and

1054
00:33:17,120 --> 00:33:18,559
then you have the hybrid with the same

1055
00:33:18,559 --> 00:33:19,760
name it's a combination of tool and

1056
00:33:19,760 --> 00:33:21,600
script for example there are test cases

1057
00:33:21,600 --> 00:33:24,399
where the tool takes you to a certain

1058
00:33:24,399 --> 00:33:25,919
level

1059
00:33:25,919 --> 00:33:28,240
and then you so you could you could

1060
00:33:28,240 --> 00:33:30,000
mimic that using the platform

1061
00:33:30,000 --> 00:33:31,679
uh using the tool as well uh the

1062
00:33:31,679 --> 00:33:33,200
framework as well you could first run

1063
00:33:33,200 --> 00:33:34,960
your tool results you can assert

1064
00:33:34,960 --> 00:33:36,720
a particular value that comes out of the

1065
00:33:36,720 --> 00:33:38,080
tool and then you could

1066
00:33:38,080 --> 00:33:41,200
have your selenium script for example

1067
00:33:41,200 --> 00:33:42,799
pick up from where the tool left off and

1068
00:33:42,799 --> 00:33:45,679
then carry out that entire

1069
00:33:45,679 --> 00:33:47,760
sequence of steps so that's the hybrid

1070
00:33:47,760 --> 00:33:49,679
kind of a model so

1071
00:33:49,679 --> 00:33:51,519
once you have your test cases in place

1072
00:33:51,519 --> 00:33:52,720
you can figure out

1073
00:33:52,720 --> 00:33:55,120
which of those test cases is catered to

1074
00:33:55,120 --> 00:33:56,960
by which of these three kinds of

1075
00:33:56,960 --> 00:33:58,480
uh building blocks this is the tool

1076
00:33:58,480 --> 00:34:00,480
related test case is it a

1077
00:34:00,480 --> 00:34:02,880
script or a completely manual test case

1078
00:34:02,880 --> 00:34:04,159
or is it something that's between the

1079
00:34:04,159 --> 00:34:07,120
two which is more of a hybrid mod

1080
00:34:07,120 --> 00:34:09,359
and this is really the whole nine yards

1081
00:34:09,359 --> 00:34:10,239
if you will

1082
00:34:10,239 --> 00:34:13,599
from a uh from an automation perspective

1083
00:34:13,599 --> 00:34:15,280
this is where i'd like to go back into

1084
00:34:15,280 --> 00:34:16,719
how threat modeling kind of

1085
00:34:16,719 --> 00:34:18,719
fits in within the potential product

1086
00:34:18,719 --> 00:34:20,560
development right so let's say there's a

1087
00:34:20,560 --> 00:34:22,719
new feature development that's coming in

1088
00:34:22,719 --> 00:34:24,639
you first ask yourself the question has

1089
00:34:24,639 --> 00:34:26,639
technology being done on that product

1090
00:34:26,639 --> 00:34:29,839
yes or no if it said yes you're existing

1091
00:34:29,839 --> 00:34:31,359
you go back to your existing thread

1092
00:34:31,359 --> 00:34:33,679
libraries and then you pick up

1093
00:34:33,679 --> 00:34:35,599
those threat libraries run those test

1094
00:34:35,599 --> 00:34:36,719
status on it and say

1095
00:34:36,719 --> 00:34:39,040
if all of this case is enough or have

1096
00:34:39,040 --> 00:34:41,119
that has that component kind of grown

1097
00:34:41,119 --> 00:34:43,440
beyond that earlier version if that's a

1098
00:34:43,440 --> 00:34:45,040
component if those set of cases are

1099
00:34:45,040 --> 00:34:45,520
enough

1100
00:34:45,520 --> 00:34:47,119
you essentially kind of just map those

1101
00:34:47,119 --> 00:34:48,560
strip models and then you

1102
00:34:48,560 --> 00:34:50,079
drive down to your test cases because

1103
00:34:50,079 --> 00:34:51,760
you already have those strict monitors

1104
00:34:51,760 --> 00:34:54,320
now in case if those threat modeling in

1105
00:34:54,320 --> 00:34:55,839
case it is a component for which strip

1106
00:34:55,839 --> 00:34:57,760
mining has not been done

1107
00:34:57,760 --> 00:34:59,599
earlier on this is where it gets

1108
00:34:59,599 --> 00:35:01,040
interesting because here

1109
00:35:01,040 --> 00:35:02,800
going back to our original slide we want

1110
00:35:02,800 --> 00:35:04,800
to be able to maintain a balance between

1111
00:35:04,800 --> 00:35:05,520
depth

1112
00:35:05,520 --> 00:35:09,440
and scale that we've done

1113
00:35:09,440 --> 00:35:12,240
is in case if it's a fresh thread model

1114
00:35:12,240 --> 00:35:13,760
especially in larger enterprises where

1115
00:35:13,760 --> 00:35:15,520
you have the problem of achieving depth

1116
00:35:15,520 --> 00:35:16,400
landscape

1117
00:35:16,400 --> 00:35:18,240
we first run the threat model through

1118
00:35:18,240 --> 00:35:19,520
the copper intervention

1119
00:35:19,520 --> 00:35:21,520
so you use one of your commercial tools

1120
00:35:21,520 --> 00:35:22,880
that gives you a

1121
00:35:22,880 --> 00:35:24,960
fundamental analysis of what the various

1122
00:35:24,960 --> 00:35:27,040
components are then you have your

1123
00:35:27,040 --> 00:35:29,280
you have all of your security all of

1124
00:35:29,280 --> 00:35:30,400
your thread cases

1125
00:35:30,400 --> 00:35:31,599
coming from a component given

1126
00:35:31,599 --> 00:35:33,599
perspective then

1127
00:35:33,599 --> 00:35:35,359
you would run the abuser case stress

1128
00:35:35,359 --> 00:35:37,200
model on that same component

1129
00:35:37,200 --> 00:35:39,280
so the component driven technology now

1130
00:35:39,280 --> 00:35:40,960
gives use k

1131
00:35:40,960 --> 00:35:44,800
and then the abuse is driven that model

1132
00:35:44,800 --> 00:35:47,280
now gives you depth and now you take

1133
00:35:47,280 --> 00:35:49,119
this combined thread model

1134
00:35:49,119 --> 00:35:52,240
uh which is that of depth and scale and

1135
00:35:52,240 --> 00:35:52,640
then

1136
00:35:52,640 --> 00:35:54,320
you loop that back into your test cases

1137
00:35:54,320 --> 00:35:56,079
so now what you're able to do

1138
00:35:56,079 --> 00:36:00,079
is that every iteration you have

1139
00:36:00,079 --> 00:36:03,599
the aspect of scale model combine that

1140
00:36:03,599 --> 00:36:04,160
with

1141
00:36:04,160 --> 00:36:06,320
efficiencies of depth and then you root

1142
00:36:06,320 --> 00:36:07,920
that through the same automation

1143
00:36:07,920 --> 00:36:08,640
pipeline

1144
00:36:08,640 --> 00:36:11,200
which is that of either hybrid tool are

1145
00:36:11,200 --> 00:36:12,560
completely manual

1146
00:36:12,560 --> 00:36:15,359
right and in this way what you could do

1147
00:36:15,359 --> 00:36:17,200
is that you could maintain that whole

1148
00:36:17,200 --> 00:36:20,000
uh it's one way i'm not saying it's the

1149
00:36:20,000 --> 00:36:21,119
only way but this is

1150
00:36:21,119 --> 00:36:23,520
one way for us to potentially kind of

1151
00:36:23,520 --> 00:36:25,119
keep up with the speed

1152
00:36:25,119 --> 00:36:28,560
uh of um of of product deployments

1153
00:36:28,560 --> 00:36:29,760
because every time there's a new product

1154
00:36:29,760 --> 00:36:30,720
department coming

1155
00:36:30,720 --> 00:36:32,000
if you have so one of the things that we

1156
00:36:32,000 --> 00:36:33,839
do is in some organizations they even

1157
00:36:33,839 --> 00:36:34,880
have a small

1158
00:36:34,880 --> 00:36:39,119
jita plugin or a confluence plugin

1159
00:36:39,119 --> 00:36:41,359
that does not allow you to commit a user

1160
00:36:41,359 --> 00:36:43,440
story until you write the association of

1161
00:36:43,440 --> 00:36:43,920
uh

1162
00:36:43,920 --> 00:36:46,560
user stories right so while while

1163
00:36:46,560 --> 00:36:47,359
architects or

1164
00:36:47,359 --> 00:36:49,119
business cases analysts are actually

1165
00:36:49,119 --> 00:36:51,440
writing the user stories you have

1166
00:36:51,440 --> 00:36:54,000
almost like a mandatory form field that

1167
00:36:54,000 --> 00:36:54,720
makes you

1168
00:36:54,720 --> 00:36:58,319
uh that prompts you to write

1169
00:36:59,520 --> 00:37:01,920
so cases from that level and start

1170
00:37:01,920 --> 00:37:03,440
tricking them downwards as well so

1171
00:37:03,440 --> 00:37:06,400
that's one way to do it

1172
00:37:07,040 --> 00:37:09,040
how does threat modeling fit in back to

1173
00:37:09,040 --> 00:37:10,480
the agile uh uh

1174
00:37:10,480 --> 00:37:12,400
or the whole best cost model uh this is

1175
00:37:12,400 --> 00:37:14,240
one view of the world that i love

1176
00:37:14,240 --> 00:37:15,680
um what you see on the top are the

1177
00:37:15,680 --> 00:37:17,280
traditional building blocks of product

1178
00:37:17,280 --> 00:37:19,119
development plant code will test release

1179
00:37:19,119 --> 00:37:20,640
deploy operate monitor

1180
00:37:20,640 --> 00:37:23,440
and what you have at the bottom are the

1181
00:37:23,440 --> 00:37:24,960
building blocks of security engineering

1182
00:37:24,960 --> 00:37:28,240
which i can see stress modeling

1183
00:37:28,960 --> 00:37:33,599
fast marking and electrical detection

1184
00:37:33,599 --> 00:37:35,200
and what i love about this is that the

1185
00:37:35,200 --> 00:37:36,880
color code here keeps changing as and

1186
00:37:36,880 --> 00:37:38,079
when you keep moving forward

1187
00:37:38,079 --> 00:37:39,680
a couple of years ago the color code was

1188
00:37:39,680 --> 00:37:41,440
very different so now

1189
00:37:41,440 --> 00:37:42,800
if you look at thread modeling that

1190
00:37:42,800 --> 00:37:44,560
modeling is something that not just fits

1191
00:37:44,560 --> 00:37:45,760
in within the plan

1192
00:37:45,760 --> 00:37:47,520
phase of the protein string lifecycle

1193
00:37:47,520 --> 00:37:49,520
it's now moved into code as well

1194
00:37:49,520 --> 00:37:51,359
fast for example which was now which was

1195
00:37:51,359 --> 00:37:52,800
always largely in code

1196
00:37:52,800 --> 00:37:54,960
has now moved from code to building and

1197
00:37:54,960 --> 00:37:56,160
testing that's

1198
00:37:56,160 --> 00:37:59,599
because of our animation problems

1199
00:37:59,599 --> 00:38:01,920
have moved from test into release as

1200
00:38:01,920 --> 00:38:03,359
well and so on and so forth

1201
00:38:03,359 --> 00:38:07,119
so threat modeling uh so i i

1202
00:38:07,119 --> 00:38:08,480
one of the things that i love is that

1203
00:38:08,480 --> 00:38:10,480
threat modeling today has its place in

1204
00:38:10,480 --> 00:38:14,160
multiple spaces as well for example just

1205
00:38:15,359 --> 00:38:18,240
used to model stories at an initial as a

1206
00:38:18,240 --> 00:38:20,560
plan and a court phase for example

1207
00:38:20,560 --> 00:38:22,240
uh you could use threat modeling to

1208
00:38:22,240 --> 00:38:24,079
write security test cases which means

1209
00:38:24,079 --> 00:38:25,680
that you are kind of using thread

1210
00:38:25,680 --> 00:38:27,359
modeling or the output reflect modeling

1211
00:38:27,359 --> 00:38:28,800
into the code and build space a little

1212
00:38:28,800 --> 00:38:30,320
bit

1213
00:38:30,320 --> 00:38:31,920
because the fact that threat modeling

1214
00:38:31,920 --> 00:38:33,760
also helps you trickle down into

1215
00:38:33,760 --> 00:38:35,760
security test case automation you're now

1216
00:38:35,760 --> 00:38:37,040
seeing the threat modeling's

1217
00:38:37,040 --> 00:38:38,960
benefits are now being trickled down

1218
00:38:38,960 --> 00:38:40,320
into the test

1219
00:38:40,320 --> 00:38:43,359
deploy as well and finally uh

1220
00:38:43,359 --> 00:38:45,920
we if you're able to kind of map the

1221
00:38:45,920 --> 00:38:46,720
potential

1222
00:38:46,720 --> 00:38:49,200
the vulnerabilities the scanners find

1223
00:38:49,200 --> 00:38:50,880
and then if you're able to kind of map

1224
00:38:50,880 --> 00:38:53,760
that back to your thread models you

1225
00:38:53,760 --> 00:38:55,200
effectively what you've done is that

1226
00:38:55,200 --> 00:38:57,919
you've built that

1227
00:38:59,520 --> 00:39:01,920
you know one of the benefits of threat

1228
00:39:01,920 --> 00:39:02,720
modeling

1229
00:39:02,720 --> 00:39:06,400
in the uh security monitoring uh

1230
00:39:06,400 --> 00:39:08,480
space as well because now you're kind of

1231
00:39:08,480 --> 00:39:10,000
using the threats that you

1232
00:39:10,000 --> 00:39:12,880
uh that you modeled way up in front and

1233
00:39:12,880 --> 00:39:14,240
now you're looking at vulnerabilities

1234
00:39:14,240 --> 00:39:14,960
that have come

1235
00:39:14,960 --> 00:39:16,560
now and then you're kind of mapping both

1236
00:39:16,560 --> 00:39:18,720
of them to say how many of my threads

1237
00:39:18,720 --> 00:39:20,720
were actually validated by my scanners

1238
00:39:20,720 --> 00:39:21,839
and how many new

1239
00:39:21,839 --> 00:39:24,320
standard please that my scanner

1240
00:39:24,320 --> 00:39:26,079
something that my thread model

1241
00:39:26,079 --> 00:39:28,400
uh architects were able to uh kind of

1242
00:39:28,400 --> 00:39:29,680
comprehend back then so you're

1243
00:39:29,680 --> 00:39:31,440
constantly kind of improving your threat

1244
00:39:31,440 --> 00:39:32,000
models

1245
00:39:32,000 --> 00:39:33,760
based on what the scanners are finding

1246
00:39:33,760 --> 00:39:35,280
and then you're validating your threat

1247
00:39:35,280 --> 00:39:35,920
models

1248
00:39:35,920 --> 00:39:37,040
based on the vulnerabilities that the

1249
00:39:37,040 --> 00:39:39,359
scanners are fine so this is one way

1250
00:39:39,359 --> 00:39:40,800
in which you could kind of ensure that

1251
00:39:40,800 --> 00:39:43,680
model uh one benefit of threat model

1252
00:39:43,680 --> 00:39:44,400
kind of

1253
00:39:44,400 --> 00:39:46,640
trickling down into multiple personas of

1254
00:39:46,640 --> 00:39:48,480
product engineering

1255
00:39:48,480 --> 00:39:50,000
uh i think i have five more minutes i'm

1256
00:39:50,000 --> 00:39:51,839
almost at the end of my

1257
00:39:51,839 --> 00:39:54,880
presentation here so in summary one of

1258
00:39:54,880 --> 00:39:57,040
the things that i like to say is when

1259
00:39:57,040 --> 00:39:58,160
you talk about threat modeling

1260
00:39:58,160 --> 00:40:00,240
especially in agile applicant security

1261
00:40:00,240 --> 00:40:02,000
know what works best for you because

1262
00:40:02,000 --> 00:40:04,640
it's not just a one-size-fits-all

1263
00:40:04,640 --> 00:40:06,560
figure out what are you trying to

1264
00:40:06,560 --> 00:40:08,240
achieve from a technology perspective

1265
00:40:08,240 --> 00:40:09,680
are you trying to achieve

1266
00:40:09,680 --> 00:40:12,560
efficiencies of

1267
00:40:12,720 --> 00:40:14,880
efficiencies of depth are you trying to

1268
00:40:14,880 --> 00:40:16,240
ensure that there is some level of

1269
00:40:16,240 --> 00:40:17,760
threat model that every persona and

1270
00:40:17,760 --> 00:40:19,520
private engineers can achieve so really

1271
00:40:19,520 --> 00:40:20,560
kind of figure out

1272
00:40:20,560 --> 00:40:22,319
what is it that you would want to

1273
00:40:22,319 --> 00:40:24,560
achieve using test modeling

1274
00:40:24,560 --> 00:40:26,400
and always understand there is a

1275
00:40:26,400 --> 00:40:28,079
potential balance between death and

1276
00:40:28,079 --> 00:40:29,119
skill then

1277
00:40:29,119 --> 00:40:30,720
you have to do that because people have

1278
00:40:30,720 --> 00:40:32,240
gone down the route of using just

1279
00:40:32,240 --> 00:40:33,440
commercial platforms

1280
00:40:33,440 --> 00:40:35,599
have figured out that there is no depth

1281
00:40:35,599 --> 00:40:36,960
because commercial

1282
00:40:36,960 --> 00:40:39,440
platforms or confidence modeling need

1283
00:40:39,440 --> 00:40:40,960
will not always be best because they

1284
00:40:40,960 --> 00:40:42,160
have no way to a certain

1285
00:40:42,160 --> 00:40:44,240
uh threats that are more christmas

1286
00:40:44,240 --> 00:40:45,200
largest driven

1287
00:40:45,200 --> 00:40:46,960
such that are more exploratory test

1288
00:40:46,960 --> 00:40:48,400
driven uh uh

1289
00:40:48,400 --> 00:40:50,160
and things like that right and people

1290
00:40:50,160 --> 00:40:51,680
have gone down that route

1291
00:40:51,680 --> 00:40:54,000
of only doing threat models based on

1292
00:40:54,000 --> 00:40:54,800
that

1293
00:40:54,800 --> 00:40:59,280
have often come back and realized that

1294
00:40:59,359 --> 00:41:01,119
especially in larger organizations

1295
00:41:01,119 --> 00:41:02,880
especially in product teams

1296
00:41:02,880 --> 00:41:04,400
where you have multiple iterations of

1297
00:41:04,400 --> 00:41:06,560
the product going so there's always a

1298
00:41:06,560 --> 00:41:08,000
balance between threat modelling for

1299
00:41:08,000 --> 00:41:09,680
depth and with molecular scale and it's

1300
00:41:09,680 --> 00:41:10,880
very essential for us to really find

1301
00:41:10,880 --> 00:41:13,440
that manual balance between the two

1302
00:41:13,440 --> 00:41:15,119
the other thing is about making threat

1303
00:41:15,119 --> 00:41:16,640
modeling more accessible

1304
00:41:16,640 --> 00:41:20,160
uh we're talking about uh devsecops2.

1305
00:41:20,160 --> 00:41:22,000
we're talking about breaking silos we're

1306
00:41:22,000 --> 00:41:23,520
talking about breaking barriers for

1307
00:41:23,520 --> 00:41:24,720
technical and cultural

1308
00:41:24,720 --> 00:41:26,480
uh so therefore it's only essential that

1309
00:41:26,480 --> 00:41:27,920
we see that threat modeling is made more

1310
00:41:27,920 --> 00:41:28,720
accessible

1311
00:41:28,720 --> 00:41:31,200
and and and we're big suckers for core

1312
00:41:31,200 --> 00:41:33,359
here at v45 we love doing things in the

1313
00:41:33,359 --> 00:41:36,160
as a code model

1314
00:41:37,200 --> 00:41:39,359
think of getting more accessible

1315
00:41:39,359 --> 00:41:40,720
especially if the developer

1316
00:41:40,720 --> 00:41:42,560
community uh without any product

1317
00:41:42,560 --> 00:41:43,760
engineering community is trying to

1318
00:41:43,760 --> 00:41:45,680
expose threat modeling in a codified

1319
00:41:45,680 --> 00:41:47,119
manner as possible right

1320
00:41:47,119 --> 00:41:49,040
so developers love code so make set

1321
00:41:49,040 --> 00:41:50,160
modeling as

1322
00:41:50,160 --> 00:41:51,760
a code something that they can kind of

1323
00:41:51,760 --> 00:41:54,400
imbibe uh you probably have a lot of

1324
00:41:54,400 --> 00:41:57,760
non-co professionals within product

1325
00:41:57,760 --> 00:41:58,400
engineering

1326
00:41:58,400 --> 00:42:00,079
and that's where you use if you look at

1327
00:42:00,079 --> 00:42:01,760
robot chamber for example they're almost

1328
00:42:01,760 --> 00:42:03,200
developed in natural language you can

1329
00:42:03,200 --> 00:42:04,800
actually write abusive cases

1330
00:42:04,800 --> 00:42:06,960
in simple uh almost conversational

1331
00:42:06,960 --> 00:42:08,240
english and they can essentially be

1332
00:42:08,240 --> 00:42:09,920
translated into

1333
00:42:09,920 --> 00:42:13,520
uh you know what what you do with bdd

1334
00:42:13,520 --> 00:42:14,880
for example right you can actually

1335
00:42:14,880 --> 00:42:16,880
translate that into effective uh test

1336
00:42:16,880 --> 00:42:18,400
cases as well so

1337
00:42:18,400 --> 00:42:19,760
in one way or the other if you're gonna

1338
00:42:19,760 --> 00:42:21,280
make this money more accessible across

1339
00:42:21,280 --> 00:42:23,280
properties that would be great

1340
00:42:23,280 --> 00:42:26,400
especially to do it because

1341
00:42:26,400 --> 00:42:29,119
it already has the where we call to use

1342
00:42:29,119 --> 00:42:30,720
automation engines and automation

1343
00:42:30,720 --> 00:42:31,839
fabrics

1344
00:42:31,839 --> 00:42:34,480
for their gatekeeper functionalities to

1345
00:42:34,480 --> 00:42:35,440
ensure that

1346
00:42:35,440 --> 00:42:37,680
validations on an application are done

1347
00:42:37,680 --> 00:42:39,520
so there's a very real possibility for

1348
00:42:39,520 --> 00:42:40,480
us to equip

1349
00:42:40,480 --> 00:42:44,160
qa for them to use security regressions

1350
00:42:44,160 --> 00:42:44,960
as well

1351
00:42:44,960 --> 00:42:47,599
and that's a great way for us to ensure

1352
00:42:47,599 --> 00:42:49,599
that you have the same gatekeeper

1353
00:42:49,599 --> 00:42:51,920
making you know checks and balances of

1354
00:42:51,920 --> 00:42:52,880
non-functional

1355
00:42:52,880 --> 00:42:55,520
and functional requirements and

1356
00:42:55,520 --> 00:42:56,720
frequencies modeling

1357
00:42:56,720 --> 00:42:59,599
is not always equal to sprint so it it

1358
00:42:59,599 --> 00:43:00,560
if it's possible

1359
00:43:00,560 --> 00:43:01,839
but don't make that mistake of saying

1360
00:43:01,839 --> 00:43:05,200
that you want to be able to

1361
00:43:05,520 --> 00:43:07,760
spread you would present it all right so

1362
00:43:07,760 --> 00:43:10,240
we can please get started somewhere

1363
00:43:10,240 --> 00:43:13,359
and finally uh the wings of effect

1364
00:43:13,359 --> 00:43:15,280
modeling is has to be it needs to be

1365
00:43:15,280 --> 00:43:16,400
incremental

1366
00:43:16,400 --> 00:43:18,160
it needs to be consistent and it has to

1367
00:43:18,160 --> 00:43:20,720
be collaborative because that's really

1368
00:43:20,720 --> 00:43:24,160
uh what will kind of give you that

1369
00:43:24,160 --> 00:43:27,200
that that

1370
00:43:27,200 --> 00:43:30,240
uh depth scale and

1371
00:43:30,240 --> 00:43:32,240
value in terms of being is able to

1372
00:43:32,240 --> 00:43:33,440
realize something with threat margin

1373
00:43:33,440 --> 00:43:34,560
because we've seen enough

1374
00:43:34,560 --> 00:43:36,079
offset money largely failing because

1375
00:43:36,079 --> 00:43:37,200
you're kind of using one of the two

1376
00:43:37,200 --> 00:43:38,240
other schools in fact

1377
00:43:38,240 --> 00:43:41,920
uh so with that i will end my talk here

1378
00:43:41,920 --> 00:43:43,680
uh thank you once again for giving me an

1379
00:43:43,680 --> 00:43:54,000
opportunity and if are you happy

1380
00:43:54,000 --> 00:43:56,240
hey

1381
00:43:58,480 --> 00:44:00,640
sorry one question there quickly um i

1382
00:44:00,640 --> 00:44:01,760
think we have time for

1383
00:44:01,760 --> 00:44:04,160
have you seen models and their creation

1384
00:44:04,160 --> 00:44:04,800
management

1385
00:44:04,800 --> 00:44:06,640
integrated within existing tool sets

1386
00:44:06,640 --> 00:44:10,240
today and any examples

1387
00:44:10,400 --> 00:44:12,240
yeah i mean we've seen these models and

1388
00:44:12,240 --> 00:44:15,520
one of the examples here is writing

1389
00:44:15,520 --> 00:44:17,920
this so we've seen thread playbook test

1390
00:44:17,920 --> 00:44:19,280
cases

1391
00:44:19,280 --> 00:44:21,200
using fabrics like that playbook

1392
00:44:21,200 --> 00:44:22,640
integrate with a commercial

1393
00:44:22,640 --> 00:44:24,720
tool um a commercial threat modeling

1394
00:44:24,720 --> 00:44:25,920
platform and both of them have

1395
00:44:25,920 --> 00:44:26,560
integrated

1396
00:44:26,560 --> 00:44:29,119
very well into automation uh framework

1397
00:44:29,119 --> 00:44:29,599
so

1398
00:44:29,599 --> 00:44:32,079
uh maybe uh what i can do is i can point

1399
00:44:32,079 --> 00:44:33,280
i can point you to

1400
00:44:33,280 --> 00:44:34,960
the github link where we actually have

1401
00:44:34,960 --> 00:44:36,880
one example uh where you just kind of

1402
00:44:36,880 --> 00:44:38,640
have these modules linked directly into

1403
00:44:38,640 --> 00:44:40,560
a tool chip so i can i can probably

1404
00:44:40,560 --> 00:44:43,759
hunt that down into the key

1405
00:44:45,280 --> 00:44:47,280
sorry with that on you shame thank you

1406
00:44:47,280 --> 00:44:49,119
very much for that emma we're up on time

1407
00:44:49,119 --> 00:44:51,599
unfortunately so and that was a great

1408
00:44:51,599 --> 00:45:01,599
talk and thanks for your time

