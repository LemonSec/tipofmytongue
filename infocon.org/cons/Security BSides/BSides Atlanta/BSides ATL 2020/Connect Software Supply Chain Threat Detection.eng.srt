1
00:00:02,800 --> 00:00:09,910
hey bees Atlanta this is Mike Doyle I am

2
00:00:06,399 --> 00:00:12,219
a principal consultant with synopsis um

3
00:00:09,910 --> 00:00:15,369
I guess a little quick introduction of a

4
00:00:12,219 --> 00:00:17,020
synopsis synopsis is a big software

5
00:00:15,369 --> 00:00:21,640
company they make software for people

6
00:00:17,020 --> 00:00:22,930
who make hardware but we are security

7
00:00:21,640 --> 00:00:24,970
consultants um they acquired our

8
00:00:22,930 --> 00:00:27,460
company's digital about three s years

9
00:00:24,970 --> 00:00:33,219
ago so we still do the same work that we

10
00:00:27,460 --> 00:00:36,220
did before I guess yep yes hi everybody

11
00:00:33,219 --> 00:00:40,239
I'm the Istana Josh I work as a security

12
00:00:36,220 --> 00:00:42,460
consultant at synopsis Atlanta and being

13
00:00:40,239 --> 00:00:44,828
a technical consultant I worked on

14
00:00:42,460 --> 00:00:49,300
various application security projects

15
00:00:44,829 --> 00:00:51,120
that include source code review web app

16
00:00:49,300 --> 00:00:54,699
and network penetration testing

17
00:00:51,120 --> 00:00:56,769
malicious code detection part of which

18
00:00:54,700 --> 00:00:59,380
we are going to talk about today so

19
00:00:56,770 --> 00:01:05,770
without further ado let's begin our

20
00:00:59,380 --> 00:01:08,590
presentation right so this morning if

21
00:01:05,770 --> 00:01:11,439
you were in this track and you saw Eddie

22
00:01:08,590 --> 00:01:13,569
Glenn's talk one of the things that he

23
00:01:11,439 --> 00:01:16,899
said is that like nearly every business

24
00:01:13,569 --> 00:01:19,439
nowadays seems to be a software business

25
00:01:16,900 --> 00:01:21,759
[Music]

26
00:01:19,439 --> 00:01:24,339
certainly the case already was talking

27
00:01:21,759 --> 00:01:27,520
about a rather similar topic he was

28
00:01:24,340 --> 00:01:31,779
coming at securing software supply

29
00:01:27,520 --> 00:01:33,699
chains from a code signing perspective

30
00:01:31,779 --> 00:01:38,259
we're gonna talk about it a little bit

31
00:01:33,700 --> 00:01:40,209
different we work with lots of

32
00:01:38,259 --> 00:01:41,590
organizations that make software and

33
00:01:40,209 --> 00:01:45,569
like Sean Marshall said in just the

34
00:01:41,590 --> 00:01:49,719
previous tract here or the previous of

35
00:01:45,569 --> 00:01:51,279
the time period almost all of your code

36
00:01:49,719 --> 00:01:56,829
was written by somebody else somewhere

37
00:01:51,279 --> 00:01:59,859
else so when it comes to the software

38
00:01:56,829 --> 00:02:01,988
that's getting made um

39
00:01:59,859 --> 00:02:03,789
how trustworthy are the people in the

40
00:02:01,989 --> 00:02:05,289
organizations that make it what we're

41
00:02:03,789 --> 00:02:07,259
concerned ourselves with so we're gonna

42
00:02:05,289 --> 00:02:10,869
describe the problem a little more depth

43
00:02:07,259 --> 00:02:13,750
examine the motives that malicious

44
00:02:10,869 --> 00:02:14,650
software developers might have

45
00:02:13,750 --> 00:02:16,120
and then we're gonna take you through

46
00:02:14,650 --> 00:02:18,670
our process for discovering attack

47
00:02:16,120 --> 00:02:20,830
vectors I'll tell you how to take action

48
00:02:18,670 --> 00:02:23,049
for these sort of things and then we

49
00:02:20,830 --> 00:02:29,650
want to wrap up by talking about who can

50
00:02:23,050 --> 00:02:37,170
detect these sort of threats all right

51
00:02:29,650 --> 00:02:43,420
so I've got some new stories here on the

52
00:02:37,170 --> 00:02:44,769
on the screen if you take a look at and

53
00:02:43,420 --> 00:02:45,940
you know but feel free to like you know

54
00:02:44,770 --> 00:02:47,890
google these later or something like

55
00:02:45,940 --> 00:02:51,310
that but the the one in the upper right

56
00:02:47,890 --> 00:02:54,760
you see from security week is a story

57
00:02:51,310 --> 00:02:56,770
about a contractor who developed a set

58
00:02:54,760 --> 00:03:01,630
of Excel spreadsheets with like you know

59
00:02:56,770 --> 00:03:04,180
fancy macros and stuff for his his

60
00:03:01,630 --> 00:03:07,540
employer was Siemens a big manufacturing

61
00:03:04,180 --> 00:03:09,250
firm out of Germany so he built these

62
00:03:07,540 --> 00:03:10,570
macros in such a way since he was going

63
00:03:09,250 --> 00:03:12,970
to be the person responsible for

64
00:03:10,570 --> 00:03:16,870
maintaining them on a contract basis he

65
00:03:12,970 --> 00:03:18,400
actually put like logic bombs inside of

66
00:03:16,870 --> 00:03:21,190
the Excel macros so that they would

67
00:03:18,400 --> 00:03:22,420
break themselves every so often just to

68
00:03:21,190 --> 00:03:24,390
give him a chance to come in and make

69
00:03:22,420 --> 00:03:28,988
some recurring revenue often

70
00:03:24,390 --> 00:03:33,850
down in the lower left is a story from

71
00:03:28,989 --> 00:03:36,040
the register um about a land of these

72
00:03:33,850 --> 00:03:39,250
contractors a based right here in our

73
00:03:36,040 --> 00:03:42,100
city who attacked the United States Army

74
00:03:39,250 --> 00:03:45,250
to to the tune of 2.6 million dollars in

75
00:03:42,100 --> 00:03:51,370
damages and the story down in the lower

76
00:03:45,250 --> 00:03:55,870
right is about a direct employee for you

77
00:03:51,370 --> 00:03:59,079
yes he was disgruntled over a lower than

78
00:03:55,870 --> 00:04:02,769
expected bonus check he only got thirty

79
00:03:59,079 --> 00:04:05,170
six thousand dollars in his bonus so he

80
00:04:02,769 --> 00:04:08,620
develops a set of logic bombs that he

81
00:04:05,170 --> 00:04:11,260
had deployed to over 2,000 servers he

82
00:04:08,620 --> 00:04:16,168
left the company went right to his

83
00:04:11,260 --> 00:04:20,140
broker and then shorted their stock so

84
00:04:16,168 --> 00:04:21,608
the the gist here is that we we placed a

85
00:04:20,140 --> 00:04:23,110
lot of trust in the folks that make our

86
00:04:21,608 --> 00:04:24,789
software certainly besides al-qaeda

87
00:04:23,110 --> 00:04:27,160
would not be a conference today we

88
00:04:24,789 --> 00:04:27,630
wouldn't be conferring without software

89
00:04:27,160 --> 00:04:29,550
we're very

90
00:04:27,630 --> 00:04:31,320
dependent on it but the trust we put

91
00:04:29,550 --> 00:04:34,910
into the people that make it could very

92
00:04:31,320 --> 00:04:34,909
well be misplaced

93
00:04:37,910 --> 00:04:44,360
so what is software supply chain threat

94
00:04:40,830 --> 00:04:47,969
detection firstly it is not same as

95
00:04:44,360 --> 00:04:51,060
malware detection traditional malware is

96
00:04:47,970 --> 00:04:54,780
built by an outside attacker to

97
00:04:51,060 --> 00:04:59,310
compromise systems this is an emerging

98
00:04:54,780 --> 00:05:02,340
science to identify groups of suspicious

99
00:04:59,310 --> 00:05:05,280
functionalities and mal code that looks

100
00:05:02,340 --> 00:05:09,539
like regular code but it is built and

101
00:05:05,280 --> 00:05:12,150
inserted by developers or an insider who

102
00:05:09,540 --> 00:05:15,930
is internal to the surface applied chain

103
00:05:12,150 --> 00:05:20,520
we could also take this as a spinoff

104
00:05:15,930 --> 00:05:22,830
from regular source code review but the

105
00:05:20,520 --> 00:05:25,229
main difference is that the focus is not

106
00:05:22,830 --> 00:05:29,150
to just identify implementation bugs and

107
00:05:25,230 --> 00:05:31,620
design flaws rather the focus is to

108
00:05:29,150 --> 00:05:34,200
analyze the business logic from the

109
00:05:31,620 --> 00:05:37,470
perspective that is my production

110
00:05:34,200 --> 00:05:40,560
deployed source code secured from an

111
00:05:37,470 --> 00:05:44,610
insider threat another main difference

112
00:05:40,560 --> 00:05:47,790
is that we do not just analyze source

113
00:05:44,610 --> 00:05:52,140
code files the input we consider for

114
00:05:47,790 --> 00:05:54,750
this kind of section is a binaries from

115
00:05:52,140 --> 00:05:57,990
the production environment and why do we

116
00:05:54,750 --> 00:06:00,690
do that let's take an example there is

117
00:05:57,990 --> 00:06:03,060
an acting which is built a source code

118
00:06:00,690 --> 00:06:05,190
it has undergone a source code reviewing

119
00:06:03,060 --> 00:06:07,740
the development cycle there were bugs

120
00:06:05,190 --> 00:06:10,410
that were fixed in the development cycle

121
00:06:07,740 --> 00:06:14,190
itself and there was a green signal

122
00:06:10,410 --> 00:06:16,290
given for releasing the source code to

123
00:06:14,190 --> 00:06:18,030
production from the security team and

124
00:06:16,290 --> 00:06:21,390
the production and from the senior

125
00:06:18,030 --> 00:06:23,219
management but a couple of weeks after

126
00:06:21,390 --> 00:06:25,950
the production release somebody

127
00:06:23,220 --> 00:06:28,920
identified a backdoor from a bug bounty

128
00:06:25,950 --> 00:06:32,940
program this is not very uncommon and

129
00:06:28,920 --> 00:06:37,169
this is because malicious code can be

130
00:06:32,940 --> 00:06:40,110
injected in the executive as late as the

131
00:06:37,169 --> 00:06:41,219
final production build so it could be

132
00:06:40,110 --> 00:06:44,730
anybody in

133
00:06:41,220 --> 00:06:47,580
the internal surface applied chain who

134
00:06:44,730 --> 00:06:51,020
could possibly be a threat in this case

135
00:06:47,580 --> 00:06:55,469
we are focusing on the software acting

136
00:06:51,020 --> 00:06:58,770
the next question is that of mostly for

137
00:06:55,470 --> 00:07:01,770
people you know party can app team or an

138
00:06:58,770 --> 00:07:03,900
organization already so could reviews

139
00:07:01,770 --> 00:07:07,469
our perform vulnerability assessments

140
00:07:03,900 --> 00:07:09,179
are being done do we need another shred

141
00:07:07,470 --> 00:07:12,660
detection as a part of the pre

142
00:07:09,180 --> 00:07:15,630
deployment process and to answer this

143
00:07:12,660 --> 00:07:19,410
question we can ask us as a few

144
00:07:15,630 --> 00:07:22,860
follow-up questions starting with is the

145
00:07:19,410 --> 00:07:25,440
software outsourced if I have acquired

146
00:07:22,860 --> 00:07:28,680
the software through a merger and

147
00:07:25,440 --> 00:07:32,280
acquisition kind of an activity do I

148
00:07:28,680 --> 00:07:34,740
know if my software is healthy or not if

149
00:07:32,280 --> 00:07:39,900
it's outdoors and if the development

150
00:07:34,740 --> 00:07:41,430
team on site or is it offshore and what

151
00:07:39,900 --> 00:07:43,859
are the rights do I have on the binary

152
00:07:41,430 --> 00:07:48,450
packages so all these questions

153
00:07:43,860 --> 00:07:51,900
basically give us clues on what could be

154
00:07:48,450 --> 00:07:57,380
the motive behind such tricks in the

155
00:07:51,900 --> 00:08:01,049
software supply chain so a couple of

156
00:07:57,380 --> 00:08:07,590
aspects about about this first when it

157
00:08:01,050 --> 00:08:11,970
comes to attribution more times than not

158
00:08:07,590 --> 00:08:14,150
when these sort of problem literacy

159
00:08:11,970 --> 00:08:17,000
constructs find their way into software

160
00:08:14,150 --> 00:08:19,590
into source code it comes from

161
00:08:17,000 --> 00:08:24,960
outsourced contractors more typically

162
00:08:19,590 --> 00:08:26,190
than disgruntled employees the examples

163
00:08:24,960 --> 00:08:28,650
that we gave at the beginning of the

164
00:08:26,190 --> 00:08:31,460
presentation you know the three examples

165
00:08:28,650 --> 00:08:34,679
two of which were were contractors

166
00:08:31,460 --> 00:08:36,449
furthermore the more socially distant

167
00:08:34,679 --> 00:08:37,949
those contractors are which is to say

168
00:08:36,450 --> 00:08:43,280
like you know the longer the supply

169
00:08:37,950 --> 00:08:46,740
chain the the more likely it is for a

170
00:08:43,280 --> 00:08:49,860
for development for a dev to uh I guess

171
00:08:46,740 --> 00:08:54,310
go rogue and be compelled to make these

172
00:08:49,860 --> 00:08:55,779
sort of problem areas uh

173
00:08:54,310 --> 00:08:57,969
something else I want to talk about

174
00:08:55,779 --> 00:09:02,259
those that we can't prove intent just by

175
00:08:57,970 --> 00:09:05,019
looking at the source code a construct

176
00:09:02,259 --> 00:09:07,750
could come to us we can find it it could

177
00:09:05,019 --> 00:09:10,600
be it could block accidental it could

178
00:09:07,750 --> 00:09:13,360
actually be an accident it might be a

179
00:09:10,600 --> 00:09:16,120
lapse of training or it adherence to

180
00:09:13,360 --> 00:09:18,870
standards like coding standards a lack

181
00:09:16,120 --> 00:09:21,420
of business knowledge that sort of thing

182
00:09:18,870 --> 00:09:25,889
[Music]

183
00:09:21,420 --> 00:09:29,500
also a developer who wants to evade

184
00:09:25,889 --> 00:09:31,209
punishment could set something up to

185
00:09:29,500 --> 00:09:33,040
make it look very accidental even though

186
00:09:31,209 --> 00:09:35,079
it was actually malicious now when we

187
00:09:33,040 --> 00:09:36,449
get to one of our later slides when we

188
00:09:35,079 --> 00:09:39,310
talk about what to do with the results

189
00:09:36,449 --> 00:09:43,139
we can talk about additional steps that

190
00:09:39,310 --> 00:09:45,869
you can take to sort of who doubt intent

191
00:09:43,139 --> 00:09:48,939
but we're typically talking about

192
00:09:45,870 --> 00:09:53,439
developers or IT folks or you know now

193
00:09:48,939 --> 00:09:57,009
that uh you know like your network is

194
00:09:53,439 --> 00:09:58,899
code your network of software on anybody

195
00:09:57,009 --> 00:10:01,360
with access to configuration design and

196
00:09:58,899 --> 00:10:08,199
build files would would fall in line for

197
00:10:01,360 --> 00:10:11,579
something about this analysis so the

198
00:10:08,199 --> 00:10:16,599
next section will be taking examples of

199
00:10:11,579 --> 00:10:21,430
real-time disassembled packages which we

200
00:10:16,600 --> 00:10:24,639
all know show up to the met words and so

201
00:10:21,430 --> 00:10:29,199
the source code files so this is an

202
00:10:24,639 --> 00:10:32,410
example send email classifying and here

203
00:10:29,199 --> 00:10:35,649
there is a regular email method for

204
00:10:32,410 --> 00:10:39,430
sending out an a new PR total is falling

205
00:10:35,649 --> 00:10:42,279
out it's calling networks for adding

206
00:10:39,430 --> 00:10:45,910
senders for adding the recipients as

207
00:10:42,279 --> 00:10:49,300
well as setting the subject and finally

208
00:10:45,910 --> 00:10:53,439
sending the email so as I said it looks

209
00:10:49,300 --> 00:10:57,639
regular but something is a little

210
00:10:53,439 --> 00:11:02,529
suspicious about the construct and the

211
00:10:57,639 --> 00:11:05,819
method here and that is a hard-coded

212
00:11:02,529 --> 00:11:07,870
email ID is added in the recipients so

213
00:11:05,819 --> 00:11:10,510
this leads to

214
00:11:07,870 --> 00:11:12,940
few more questions that why is there a

215
00:11:10,510 --> 00:11:15,010
hard-coded email ID in the recipe is

216
00:11:12,940 --> 00:11:18,070
this an automated email ID or does it

217
00:11:15,010 --> 00:11:20,470
belong to you know is it a personal

218
00:11:18,070 --> 00:11:22,990
email ID and if it is personal is it

219
00:11:20,470 --> 00:11:26,890
somebody internal to the organization or

220
00:11:22,990 --> 00:11:29,020
external to the organization what are

221
00:11:26,890 --> 00:11:32,439
the contents of the email that is being

222
00:11:29,020 --> 00:11:35,680
sent out and what is the purpose

223
00:11:32,440 --> 00:11:39,670
so just by identifying one hard-coded

224
00:11:35,680 --> 00:11:41,500
value we can build up a case and do a

225
00:11:39,670 --> 00:11:43,779
dataflow analysis to see if there is

226
00:11:41,500 --> 00:11:49,180
something for the malicious or North or

227
00:11:43,779 --> 00:11:53,680
maybe just bad coding practices there is

228
00:11:49,180 --> 00:11:56,050
another example in this particular file

229
00:11:53,680 --> 00:11:59,859
it's called normal Java the name itself

230
00:11:56,050 --> 00:12:04,599
looks like something is not correct or

231
00:11:59,860 --> 00:12:07,930
probably we could sign it off as a dummy

232
00:12:04,600 --> 00:12:11,310
files that not called but it's just

233
00:12:07,930 --> 00:12:15,250
added in them in the binary package and

234
00:12:11,310 --> 00:12:17,140
honestly this kind of finding can be

235
00:12:15,250 --> 00:12:20,320
identified in a regular source code

236
00:12:17,140 --> 00:12:23,050
review so we have highlighted the

237
00:12:20,320 --> 00:12:27,610
username and password that is hard-coded

238
00:12:23,050 --> 00:12:30,310
here but just looking at the source code

239
00:12:27,610 --> 00:12:34,690
we could just qualified a qualified is

240
00:12:30,310 --> 00:12:39,209
finding as hard-coded credentials in the

241
00:12:34,690 --> 00:12:41,440
source code file when we perform

242
00:12:39,209 --> 00:12:43,839
something like a malicious code

243
00:12:41,440 --> 00:12:45,670
detection on some supply chain thread

244
00:12:43,839 --> 00:12:48,459
detection we need to go one step further

245
00:12:45,670 --> 00:12:52,150
and investigate the config and the

246
00:12:48,459 --> 00:12:55,420
deployment files as well to build up our

247
00:12:52,150 --> 00:12:58,089
cases to make it stronger and here we

248
00:12:55,420 --> 00:13:02,170
see in the web deployment files web dot

249
00:12:58,089 --> 00:13:06,279
XML the method that is used here the

250
00:13:02,170 --> 00:13:09,760
class know auth filter it is defined in

251
00:13:06,279 --> 00:13:15,100
the deployment file in the bed dot XML

252
00:13:09,760 --> 00:13:18,540
file so we know for sure that anybody

253
00:13:15,100 --> 00:13:20,980
who is using these credentials username

254
00:13:18,540 --> 00:13:25,140
as user name and the past

255
00:13:20,980 --> 00:13:27,790
default password they can bypass the

256
00:13:25,140 --> 00:13:37,630
regular authentication method and

257
00:13:27,790 --> 00:13:41,740
entrance to an application this next

258
00:13:37,630 --> 00:13:45,100
example the malicious construct is right

259
00:13:41,740 --> 00:13:49,870
at the top it's actually pretty easy to

260
00:13:45,100 --> 00:13:54,360
spot and it is basically a form of

261
00:13:49,870 --> 00:13:58,630
command injection we take a get request

262
00:13:54,360 --> 00:14:01,660
parameter name folder and then just

263
00:13:58,630 --> 00:14:03,730
execute it on like a Windows system this

264
00:14:01,660 --> 00:14:05,650
might open up a directory or something

265
00:14:03,730 --> 00:14:06,700
like that but of course if you put in a

266
00:14:05,650 --> 00:14:09,120
directory name that doesn't actually

267
00:14:06,700 --> 00:14:12,490
exist on the directory name that is a

268
00:14:09,120 --> 00:14:13,900
operating system command then we'll just

269
00:14:12,490 --> 00:14:15,790
run whatever command you want delete all

270
00:14:13,900 --> 00:14:17,829
your files copy files crossed with

271
00:14:15,790 --> 00:14:20,260
another system you know Bob is your

272
00:14:17,830 --> 00:14:21,760
uncle in this case this is something

273
00:14:20,260 --> 00:14:23,860
that definitely would come up through a

274
00:14:21,760 --> 00:14:25,689
normal static analysis or just a normal

275
00:14:23,860 --> 00:14:29,590
color view or even a penetration test

276
00:14:25,690 --> 00:14:33,310
probably even a dynamic scan or

277
00:14:29,590 --> 00:14:36,340
something like that but what is of

278
00:14:33,310 --> 00:14:37,630
interest here is this based off of the

279
00:14:36,340 --> 00:14:41,230
real finding that we had on them

280
00:14:37,630 --> 00:14:46,030
assessment was a problem that we found

281
00:14:41,230 --> 00:14:47,590
built in into a separate jar file so

282
00:14:46,030 --> 00:14:52,720
sometimes you know developers have

283
00:14:47,590 --> 00:14:55,660
access to code bases late in the process

284
00:14:52,720 --> 00:15:01,780
later than 10 should typically happen in

285
00:14:55,660 --> 00:15:03,819
SDLC or you know a developer will

286
00:15:01,780 --> 00:15:05,620
include something else from somewhere

287
00:15:03,820 --> 00:15:08,350
else like Oh Shawn Marshall said in the

288
00:15:05,620 --> 00:15:11,560
last session almost all of your code is

289
00:15:08,350 --> 00:15:13,030
written by somebody else so our analyses

290
00:15:11,560 --> 00:15:14,560
will be able to find these sort of

291
00:15:13,030 --> 00:15:16,930
mistakes that are basically have

292
00:15:14,560 --> 00:15:24,969
propagated through the supply chain to

293
00:15:16,930 --> 00:15:27,370
you and we have a last example for code

294
00:15:24,970 --> 00:15:31,060
snippet and this is from a manager

295
00:15:27,370 --> 00:15:34,750
payment class file this method is for

296
00:15:31,060 --> 00:15:36,729
basically processing the pavement for

297
00:15:34,750 --> 00:15:40,300
Account Managers who basically one of

298
00:15:36,730 --> 00:15:44,500
the senior managers and a simple code

299
00:15:40,300 --> 00:15:47,560
again which includes the branch number

300
00:15:44,500 --> 00:15:49,390
where the payment should be processed

301
00:15:47,560 --> 00:15:54,189
for the account manager and the payment

302
00:15:49,390 --> 00:15:58,000
date typically we get a get out payment

303
00:15:54,190 --> 00:16:00,310
after every 10 business days and that is

304
00:15:58,000 --> 00:16:05,050
what the second last line here set

305
00:16:00,310 --> 00:16:08,859
payment date is used for for setting the

306
00:16:05,050 --> 00:16:11,319
payment after every 10 days but as I

307
00:16:08,860 --> 00:16:15,940
said it looks regular and at first

308
00:16:11,320 --> 00:16:21,000
glance it is not that easy to catch this

309
00:16:15,940 --> 00:16:27,220
finding but if we take a closer look

310
00:16:21,000 --> 00:16:29,500
something is not correct and a taxi also

311
00:16:27,220 --> 00:16:30,880
when we do these kind of stretch

312
00:16:29,500 --> 00:16:34,480
attentions and it's on the production

313
00:16:30,880 --> 00:16:38,740
packages we may also have a background

314
00:16:34,480 --> 00:16:42,070
story on whether something is wrong in

315
00:16:38,740 --> 00:16:44,230
the in the payment systems and just

316
00:16:42,070 --> 00:16:47,560
looking at the source code here we see

317
00:16:44,230 --> 00:16:53,320
that this is not right this is not for

318
00:16:47,560 --> 00:16:56,280
10 business days there's a Tilly in the

319
00:16:53,320 --> 00:17:01,870
payment processing so just to explain

320
00:16:56,280 --> 00:17:03,640
one day has 86,400 seconds so ideally

321
00:17:01,870 --> 00:17:07,000
there should be three zeros for 10 days

322
00:17:03,640 --> 00:17:09,939
but there are four zero so it is 8

323
00:17:07,000 --> 00:17:13,540
million six hundred and forty thousand

324
00:17:09,939 --> 00:17:15,760
that's added so there are some

325
00:17:13,540 --> 00:17:18,609
suspicious intense traffic and build

326
00:17:15,760 --> 00:17:22,240
from here one that it's done

327
00:17:18,609 --> 00:17:24,429
intentionally maybe a disgruntled

328
00:17:22,240 --> 00:17:26,890
employee who does not want his manager

329
00:17:24,430 --> 00:17:30,490
to get his payment on time and it's

330
00:17:26,890 --> 00:17:32,620
delayed up 200 days or secondly or it

331
00:17:30,490 --> 00:17:36,430
could be an it could be accidental a

332
00:17:32,620 --> 00:17:39,489
typo an additional zero and it was not

333
00:17:36,430 --> 00:17:41,650
checked correctly and third would be

334
00:17:39,490 --> 00:17:45,490
that it is accident it's a combination

335
00:17:41,650 --> 00:17:48,490
of accidental and intentional so first

336
00:17:45,490 --> 00:17:50,230
glance accidental seconds or manager

337
00:17:48,490 --> 00:17:56,740
complained that he does not receive the

338
00:17:50,230 --> 00:17:58,210
payment on time and so he gets a payment

339
00:17:56,740 --> 00:18:00,610
after every 10 days from the finance

340
00:17:58,210 --> 00:18:03,760
system but we using the logic from tow

341
00:18:00,610 --> 00:18:05,439
from the from the source code on the

342
00:18:03,760 --> 00:18:08,620
binary package he also receives the

343
00:18:05,440 --> 00:18:11,530
payment after 100 days so basically he's

344
00:18:08,620 --> 00:18:16,689
not reporting that he's getting paid 2

345
00:18:11,530 --> 00:18:20,080
times for every pay cycle so these are

346
00:18:16,690 --> 00:18:24,340
some examples from from your attempts of

347
00:18:20,080 --> 00:18:26,770
binary packages that we've seen now

348
00:18:24,340 --> 00:18:30,580
let's look at the methodology how do we

349
00:18:26,770 --> 00:18:32,559
go about identifying insider trades in

350
00:18:30,580 --> 00:18:34,870
the software supply chain just looking

351
00:18:32,559 --> 00:18:36,250
at the source code this is more like

352
00:18:34,870 --> 00:18:39,250
building up a story

353
00:18:36,250 --> 00:18:42,520
we know that subset here is the software

354
00:18:39,250 --> 00:18:45,240
acting who has access to the source code

355
00:18:42,520 --> 00:18:48,460
file they are building the logic and

356
00:18:45,240 --> 00:18:50,590
knowing the thread the first area would

357
00:18:48,460 --> 00:18:53,530
be identifying key points of interest

358
00:18:50,590 --> 00:18:55,600
which are basically atomic elements that

359
00:18:53,530 --> 00:18:58,480
people also seen in the code could be

360
00:18:55,600 --> 00:19:02,379
hard-coded values like a hard-coded date

361
00:18:58,480 --> 00:19:06,100
hard-coded email ID a URL or it could be

362
00:19:02,380 --> 00:19:08,140
using stealth methods which ideally

363
00:19:06,100 --> 00:19:10,719
should not be included in a source code

364
00:19:08,140 --> 00:19:13,210
file so we identify those key points of

365
00:19:10,720 --> 00:19:16,870
interest next from the point of interest

366
00:19:13,210 --> 00:19:19,540
we check if there is obey that we can

367
00:19:16,870 --> 00:19:23,439
flow from those elements to a method

368
00:19:19,540 --> 00:19:25,840
that is being called for building out

369
00:19:23,440 --> 00:19:28,120
some suspicious methods some suspicious

370
00:19:25,840 --> 00:19:30,459
constructs so join the dots between the

371
00:19:28,120 --> 00:19:33,850
point of interest to the methods that

372
00:19:30,460 --> 00:19:36,790
are being called if we can join the dots

373
00:19:33,850 --> 00:19:38,830
then let's go one step further and build

374
00:19:36,790 --> 00:19:40,770
out it intent that here there is

375
00:19:38,830 --> 00:19:43,750
something suspicious it looks suspicious

376
00:19:40,770 --> 00:19:47,980
but is this intentional or is this

377
00:19:43,750 --> 00:19:49,780
accidental it could be that the business

378
00:19:47,980 --> 00:19:52,240
it that there is a business

379
00:19:49,780 --> 00:19:56,740
justification so it's not actually

380
00:19:52,240 --> 00:19:59,580
suspicious and it won't qualify to be an

381
00:19:56,740 --> 00:20:02,410
internal thread or a malicious code and

382
00:19:59,580 --> 00:20:05,649
finally if we know that it is malicious

383
00:20:02,410 --> 00:20:08,020
then we take an action which is which

384
00:20:05,650 --> 00:20:11,620
she'll be calm except but it's it's the

385
00:20:08,020 --> 00:20:19,300
final step in this methodology so this

386
00:20:11,620 --> 00:20:21,100
is manual and performing detection would

387
00:20:19,300 --> 00:20:23,919
stay man you know doing something

388
00:20:21,100 --> 00:20:26,230
manually will always take time so we

389
00:20:23,920 --> 00:20:29,260
need to automate and we have automated

390
00:20:26,230 --> 00:20:32,410
the first two steps that is by building

391
00:20:29,260 --> 00:20:33,879
out signatures to join the dots from

392
00:20:32,410 --> 00:20:36,340
point of interest to suspicious

393
00:20:33,880 --> 00:20:39,100
construct we can write automation

394
00:20:36,340 --> 00:20:42,220
scripts to in terms of regular

395
00:20:39,100 --> 00:20:51,100
expressions and custom rules to refine

396
00:20:42,220 --> 00:20:55,120
the dataflow analysis and here we have

397
00:20:51,100 --> 00:20:59,100
an example of classic malicious code

398
00:20:55,120 --> 00:21:03,219
that is inserted by a development in a

399
00:20:59,100 --> 00:21:06,870
backdoor and in simple terms backdoor is

400
00:21:03,220 --> 00:21:10,390
nothing but an alternative non-standard

401
00:21:06,870 --> 00:21:14,560
way of entering an app or an

402
00:21:10,390 --> 00:21:16,750
infrastructure and organization let's

403
00:21:14,560 --> 00:21:19,270
take it as somebody entering our house

404
00:21:16,750 --> 00:21:21,670
not from the main door but from a window

405
00:21:19,270 --> 00:21:25,660
that is kept open so same thing happens

406
00:21:21,670 --> 00:21:29,410
in applications and IT infrastructure as

407
00:21:25,660 --> 00:21:34,650
well so a developer could use a stealth

408
00:21:29,410 --> 00:21:37,270
test utility to enter an application

409
00:21:34,650 --> 00:21:40,540
through using a communication channel

410
00:21:37,270 --> 00:21:44,200
which gives way to and inversion of

411
00:21:40,540 --> 00:21:47,290
control operation it looks like he is

412
00:21:44,200 --> 00:21:51,120
that regulation it could be he or she so

413
00:21:47,290 --> 00:21:54,760
basically developers using a

414
00:21:51,120 --> 00:21:58,209
functionality to build a command which

415
00:21:54,760 --> 00:22:00,820
looks like a which looks like a fan

416
00:21:58,210 --> 00:22:03,670
commanded paying bills using static

417
00:22:00,820 --> 00:22:06,100
parameters because many sub methods are

418
00:22:03,670 --> 00:22:08,080
being called and it looks until most

419
00:22:06,100 --> 00:22:11,669
surreptitious because of the way it's

420
00:22:08,080 --> 00:22:15,010
written but actually he is building a

421
00:22:11,670 --> 00:22:16,360
command dynamically which can be

422
00:22:15,010 --> 00:22:20,080
executed on run

423
00:22:16,360 --> 00:22:22,678
and that could open up sham axes and we

424
00:22:20,080 --> 00:22:28,418
all know if there's a knack to that open

425
00:22:22,679 --> 00:22:35,740
any malicious attacker could get

426
00:22:28,419 --> 00:22:39,010
complete control on system so what do we

427
00:22:35,740 --> 00:22:53,019
do next once we know that there is a

428
00:22:39,010 --> 00:22:57,960
malicious intent in the system here are

429
00:22:53,019 --> 00:23:00,820
some examples take no action delegated

430
00:22:57,960 --> 00:23:05,110
passive monitoring active monitoring and

431
00:23:00,820 --> 00:23:08,789
take immediate response we would rather

432
00:23:05,110 --> 00:23:12,789
have this as an interactive session but

433
00:23:08,789 --> 00:23:17,169
since we cannot interact right now we

434
00:23:12,789 --> 00:23:19,899
can just go over what what should be the

435
00:23:17,169 --> 00:23:24,010
steps and there is no wrong answer for

436
00:23:19,899 --> 00:23:28,418
this all all these steps to be taken but

437
00:23:24,010 --> 00:23:31,389
it depends on the scenario so first

438
00:23:28,419 --> 00:23:35,889
thing is that we do not take any steps

439
00:23:31,389 --> 00:23:38,799
that is it could be a false positive

440
00:23:35,889 --> 00:23:42,219
there could be a business justification

441
00:23:38,799 --> 00:23:44,590
as I've mentioned earlier so it's not a

442
00:23:42,220 --> 00:23:46,809
malicious code it's not an insider

443
00:23:44,590 --> 00:23:50,889
threat in the surface of blanching the

444
00:23:46,809 --> 00:23:52,899
next is it it's not a malicious code but

445
00:23:50,889 --> 00:23:54,850
because we review source code files we

446
00:23:52,899 --> 00:23:56,439
do often find implementation valve is

447
00:23:54,850 --> 00:24:00,070
designed close the typical source code

448
00:23:56,440 --> 00:24:04,480
will be finding so instead of taking it

449
00:24:00,070 --> 00:24:07,629
further to to the next escalation point

450
00:24:04,480 --> 00:24:09,669
we'd redirected so you give it back to

451
00:24:07,630 --> 00:24:12,820
the source code review team and say what

452
00:24:09,669 --> 00:24:18,429
we have identified the second and third

453
00:24:12,820 --> 00:24:21,428
step would be for for finding out for

454
00:24:18,429 --> 00:24:24,149
finding out actual malicious intent so

455
00:24:21,429 --> 00:24:27,429
let's say that there is a possibility of

456
00:24:24,149 --> 00:24:30,189
exfiltrating data to an unwanted system

457
00:24:27,429 --> 00:24:32,950
or unauthorized system

458
00:24:30,190 --> 00:24:35,290
but the data may not be extremely

459
00:24:32,950 --> 00:24:37,540
sensitive or critical so we could have

460
00:24:35,290 --> 00:24:40,120
passive production monitoring by

461
00:24:37,540 --> 00:24:42,430
implementing some web application

462
00:24:40,120 --> 00:24:45,189
firewall rule adding some sensor and

463
00:24:42,430 --> 00:24:46,810
production logs to check whether data is

464
00:24:45,190 --> 00:24:50,020
actually being exfiltrated

465
00:24:46,810 --> 00:24:52,149
or not and if at all to whom it is being

466
00:24:50,020 --> 00:24:54,090
sent and accordingly take actions

467
00:24:52,150 --> 00:24:57,820
whether to for the block this

468
00:24:54,090 --> 00:25:01,389
exfiltration or not if there's a

469
00:24:57,820 --> 00:25:06,370
possibility of sending out or somebody

470
00:25:01,390 --> 00:25:10,510
being able to access in some sensitive

471
00:25:06,370 --> 00:25:13,780
information then best is to take the

472
00:25:10,510 --> 00:25:17,260
active approach and have a compensating

473
00:25:13,780 --> 00:25:21,000
library in place or an active bathroom

474
00:25:17,260 --> 00:25:24,700
to block the access at the source and

475
00:25:21,000 --> 00:25:27,310
final would be to take an immediate

476
00:25:24,700 --> 00:25:29,040
response in terms of escalation and

477
00:25:27,310 --> 00:25:31,629
getting the legal and the HR team

478
00:25:29,040 --> 00:25:35,379
involved that is this we can identify

479
00:25:31,630 --> 00:25:37,630
the culprit and it could also and it's

480
00:25:35,380 --> 00:25:40,210
genuinely there is an you know there's

481
00:25:37,630 --> 00:25:42,760
an internal culprit and disgruntled

482
00:25:40,210 --> 00:25:45,390
developer who is who is probably

483
00:25:42,760 --> 00:25:49,270
inserting a logic poem or your backdoor

484
00:25:45,390 --> 00:25:54,520
it could also lead to his work

485
00:25:49,270 --> 00:25:56,500
domination of domination of contract so

486
00:25:54,520 --> 00:25:59,020
we have the results we have gone through

487
00:25:56,500 --> 00:26:02,500
the methodology let's see who could

488
00:25:59,020 --> 00:26:07,690
perform this kind of detection method on

489
00:26:02,500 --> 00:26:10,150
this third detection here we have a

490
00:26:07,690 --> 00:26:13,150
developer a hacker and a security

491
00:26:10,150 --> 00:26:17,650
engineer again I would have loved to

492
00:26:13,150 --> 00:26:22,270
have this as an interactive session but

493
00:26:17,650 --> 00:26:24,970
there is no wrong answer again at the

494
00:26:22,270 --> 00:26:28,360
end the basic skills needed is you

495
00:26:24,970 --> 00:26:30,970
should be able to read source code the

496
00:26:28,360 --> 00:26:33,580
programming languages and a developer

497
00:26:30,970 --> 00:26:36,730
hacker security engineer would all fit

498
00:26:33,580 --> 00:26:39,070
into this bucket but a developer or

499
00:26:36,730 --> 00:26:42,340
typical developer would rather spend his

500
00:26:39,070 --> 00:26:43,540
time developing his application not too

501
00:26:42,340 --> 00:26:45,820
worried about the

502
00:26:43,540 --> 00:26:49,180
security inflicted implications while

503
00:26:45,820 --> 00:26:52,419
developing this office he has a timeline

504
00:26:49,180 --> 00:26:55,200
to complete and have the production have

505
00:26:52,420 --> 00:26:58,810
to app up and running hacker

506
00:26:55,200 --> 00:27:00,970
hmm always busy you know adding

507
00:26:58,810 --> 00:27:03,550
something malicious or you know an

508
00:27:00,970 --> 00:27:05,590
offensive attack so you may or may not

509
00:27:03,550 --> 00:27:08,850
want to consider security I am an

510
00:27:05,590 --> 00:27:11,679
engineer it is a part of his job to

511
00:27:08,850 --> 00:27:14,560
identifying something something

512
00:27:11,680 --> 00:27:17,170
malicious but oftentimes security

513
00:27:14,560 --> 00:27:20,460
engineers work looking at or you know

514
00:27:17,170 --> 00:27:22,900
just just walk out of a checklist and if

515
00:27:20,460 --> 00:27:26,620
the complete our checklist we may not

516
00:27:22,900 --> 00:27:28,990
consider a lot of custom activities so

517
00:27:26,620 --> 00:27:35,290
again as I says no right or wrong answer

518
00:27:28,990 --> 00:27:39,370
but we would like somebody like a deaf

519
00:27:35,290 --> 00:27:41,620
actor to perform this cancer detection

520
00:27:39,370 --> 00:27:44,379
so a combination of a developer and

521
00:27:41,620 --> 00:27:47,590
attacker as efficient a smart developer

522
00:27:44,380 --> 00:28:02,710
with secure coding skills and mind up an

523
00:27:47,590 --> 00:28:04,480
attacker with this and try to answer

524
00:28:02,710 --> 00:28:07,519
some questions

525
00:28:04,480 --> 00:28:07,519
[Music]

526
00:28:07,800 --> 00:28:17,440
minutes if you see any questions Oh

527
00:28:15,150 --> 00:28:21,010
everybody's asking for your slides which

528
00:28:17,440 --> 00:28:23,980
that's pretty normal so if you guys want

529
00:28:21,010 --> 00:28:26,980
to provide your slides everybody always

530
00:28:23,980 --> 00:28:28,900
wants that and then note to all future

531
00:28:26,980 --> 00:28:35,140
talks don't meet yourself on June

532
00:28:28,900 --> 00:28:44,590
because every time I touch software

533
00:28:35,140 --> 00:28:48,970
embrace because something was funky on

534
00:28:44,590 --> 00:28:53,790
on said that like only affected me

535
00:28:48,970 --> 00:28:57,309
because I put the other way or something

536
00:28:53,790 --> 00:29:02,408
it happens like

537
00:28:57,309 --> 00:29:03,999
when he says I hate computers all right

538
00:29:02,409 --> 00:29:05,799
well thank you we appreciate your

539
00:29:03,999 --> 00:29:08,799
presentation today it was great

540
00:29:05,799 --> 00:29:11,200
information thanks for supporting

541
00:29:08,799 --> 00:29:12,610
besides with Nana and if you guys have

542
00:29:11,200 --> 00:29:15,399
if anybody has questions for them

543
00:29:12,610 --> 00:29:19,209
they'll be in the connect tract or you

544
00:29:15,399 --> 00:29:22,959
can message them directly and talk more

545
00:29:19,210 --> 00:29:25,499
so thank you again all right thanks for

546
00:29:22,960 --> 00:29:25,499
that thank you

