1
00:00:15,700 --> 00:00:17,640
[John L. Whitman:] Okay, as you heard my name
is John L. Whiteman.

2
00:00:17,640 --> 00:00:19,610
I always put the 'L' in there.

3
00:00:19,610 --> 00:00:24,250
And I'm a web application security engineer
at Oregon Health and Science University and

4
00:00:24,250 --> 00:00:28,640
today I'm going to be talking about Static
Application Security Testing, or SAST and

5
00:00:28,640 --> 00:00:31,000
the Bad Human Code Project.

6
00:00:31,000 --> 00:00:34,260
And today, I think it's National Cyber Awareness
Month?

7
00:00:34,260 --> 00:00:36,610
So, today I'm gonna call this SASTer day.

8
00:00:36,610 --> 00:00:37,610
[ audience laughter ]

9
00:00:37,610 --> 00:00:40,720
Okay, and there's still room on 'A' if you
don't want to continue here.

10
00:00:40,720 --> 00:00:42,390
[ audience laughter ]

11
00:00:42,390 --> 00:00:43,500
So what is Bad Human?

12
00:00:43,500 --> 00:00:48,140
Well, this started for me 26 years ago; 1992
in Japan.

13
00:00:48,140 --> 00:00:52,110
I lived in a very small apartment there, which
goes without saying.

14
00:00:52,110 --> 00:00:54,589
And I played this game called Aces of the
Pacific.

15
00:00:54,590 --> 00:00:55,840
Anybody heard of that one before?

16
00:00:55,840 --> 00:00:56,840
Yeah?

17
00:00:56,840 --> 00:00:57,840
Cool.

18
00:00:57,840 --> 00:00:58,840
Awesome.

19
00:00:58,840 --> 00:00:59,840
And I found out...

20
00:00:59,840 --> 00:01:02,670
Well, it's a DOS space World War II flight
simulator, and I found out that the creator

21
00:01:02,670 --> 00:01:04,420
is this company called Dynamix.

22
00:01:04,420 --> 00:01:05,650
Which is out or from Eugene.

23
00:01:05,650 --> 00:01:07,210
Which is awesome.

24
00:01:07,210 --> 00:01:09,490
So, this is a great game.

25
00:01:09,490 --> 00:01:11,330
You could fly on either side of the war.

26
00:01:11,330 --> 00:01:14,000
You can fly as the Americans and you can fly
as a Japanese.

27
00:01:14,000 --> 00:01:16,690
So, one day I was on a mission.

28
00:01:16,690 --> 00:01:19,610
I'm flying around, coming close to the ship.

29
00:01:19,610 --> 00:01:20,859
Came in too close.

30
00:01:20,859 --> 00:01:23,169
I crashed and exploded.

31
00:01:23,170 --> 00:01:28,490
The software crashed and exploded and these
words appeared out of nowhere.

32
00:01:28,490 --> 00:01:29,490
And I'm not kidding.

33
00:01:29,490 --> 00:01:30,789
'Bad Human.'

34
00:01:30,789 --> 00:01:33,990
Now this is the early 90s, right?

35
00:01:33,990 --> 00:01:37,999
And I like.. it's like 'Bad Human' and I cried.

36
00:01:37,999 --> 00:01:42,420
I thought I was being punished by the game
developers or something and I couldn't remember.

37
00:01:42,420 --> 00:01:45,189
Was I friendly flying into a friendly?

38
00:01:45,189 --> 00:01:46,458
Or something of that nature?

39
00:01:46,459 --> 00:01:50,060
Something with my behavior caused a developer
to write that message.

40
00:01:50,060 --> 00:01:53,549
And the thing is, I couldn't reproduce it
for however I tried.

41
00:01:53,549 --> 00:01:58,060
In fact, I probably spent more time trying
to be a Bad Human than an Ace.

42
00:01:58,060 --> 00:02:00,569
So, that's where Bad Human comes.

43
00:02:00,569 --> 00:02:05,619
And think of every time I mention this from
now on, is about behavior.

44
00:02:05,619 --> 00:02:07,590
Particularly when we're talking about coding.

45
00:02:07,590 --> 00:02:08,590
So what is SAST?

46
00:02:08,590 --> 00:02:11,140
Has anybody never heard of SAST in here?

47
00:02:11,140 --> 00:02:12,279
At all, never?

48
00:02:12,280 --> 00:02:13,280
Cool.

49
00:02:13,280 --> 00:02:14,599
Now I'm gonna talk to you.

50
00:02:14,599 --> 00:02:17,929
[ laughs ]
But it's basically the analysis of source code.

51
00:02:17,930 --> 00:02:19,970
So, we have programming code.

52
00:02:19,970 --> 00:02:23,150
And what you're doing is you're trying to
find security flaws, bugs, whatever.

53
00:02:23,150 --> 00:02:26,360
In our case we're talking about security vulnerabilities.

54
00:02:26,360 --> 00:02:27,360
And it could be automated.

55
00:02:27,360 --> 00:02:28,489
There's open source tools.

56
00:02:28,489 --> 00:02:29,959
And it could be manual.

57
00:02:29,959 --> 00:02:31,890
Which I call, 'People made it.'

58
00:02:31,890 --> 00:02:36,170
And we're going to talk about automation tools
particularly here.

59
00:02:36,170 --> 00:02:37,708
And why it's called SAST?

60
00:02:37,709 --> 00:02:38,709
Why it's static?

61
00:02:38,709 --> 00:02:41,370
Is because the source code itself is never
executed.

62
00:02:41,370 --> 00:02:45,239
So, there's a DAST version where they're doing
dynamic execution.

63
00:02:45,239 --> 00:02:50,040
But I'm here to tell you that source code
is not static, but it's a living thing based

64
00:02:50,040 --> 00:02:51,980
on human behavior.

65
00:02:51,980 --> 00:02:56,609
It could be good human behavior or bad human
behavior.

66
00:02:56,610 --> 00:02:59,890
And, this is a lesson that I learned at OHSU.

67
00:02:59,890 --> 00:03:05,059
You know, kind of coming back and looking
in context of what I'm trying to talk about

68
00:03:05,059 --> 00:03:10,970
... OHSU is a university, it's a hospital,
and it's a research center.

69
00:03:10,970 --> 00:03:11,970
And it's a target.

70
00:03:11,970 --> 00:03:16,430
We've got a lot of high valuable data and
a lot of people want to get that data.

71
00:03:16,430 --> 00:03:19,659
And so one of the attack surfaces, of course,
are web applications.

72
00:03:19,659 --> 00:03:24,590
So, when you think about web applications
-- OWASP's Top 10, it's an organization that

73
00:03:24,590 --> 00:03:27,969
does a great job, kind of spelling out what
these vulnerabilities are.

74
00:03:27,969 --> 00:03:32,430
Could be XSS, SQL injection and even vulnerable
third-party software.

75
00:03:32,430 --> 00:03:36,379
Those are the ones with the CVEs as non-custom
code, stuff that we look at.

76
00:03:36,379 --> 00:03:37,920
So, our security team...

77
00:03:37,920 --> 00:03:39,708
We've got two people.

78
00:03:39,709 --> 00:03:42,480
And we're focused on web application security.

79
00:03:42,480 --> 00:03:46,730
And we started about two years, in fact, one
month from now, it's two years, ago.

80
00:03:46,730 --> 00:03:48,709
And we started everything from scratch there.

81
00:03:48,709 --> 00:03:53,150
But, we're really part of a much larger effort
to secure data at the institution.

82
00:03:53,150 --> 00:03:55,220
There's obviously a bigger data team.

83
00:03:55,220 --> 00:03:57,349
So, what makes us different?

84
00:03:57,349 --> 00:04:01,709
Well, a typical shop might have ... Maybe
it's a company, they might have one or two

85
00:04:01,709 --> 00:04:03,069
web applications.

86
00:04:03,069 --> 00:04:07,238
And one of them might be the corporate website,
the other might be something for micro services.

87
00:04:07,239 --> 00:04:11,420
We have hundreds of web apps at OHSU.

88
00:04:11,420 --> 00:04:16,238
They, the typical company, may have dedicated
dev teams.

89
00:04:16,238 --> 00:04:19,209
We define dedicated with a question mark.

90
00:04:19,209 --> 00:04:21,519
Usually when you walk in there's that team.

91
00:04:21,519 --> 00:04:24,389
And we have some of them but not always.

92
00:04:24,389 --> 00:04:25,830
And there's an expected skillset.

93
00:04:25,830 --> 00:04:29,530
Particularly, if you are a commercial company,
you're gonna hire people.

94
00:04:29,530 --> 00:04:33,080
Maybe they're a Drupal developer, but there's
some sort of level of expertise in the hiring

95
00:04:33,080 --> 00:04:35,919
process that you have when they're developing
these web apps.

96
00:04:35,920 --> 00:04:41,070
For us, it's an eclectic mix of developers,
hobbyists, and PhDs.

97
00:04:41,070 --> 00:04:45,840
And if you look at the code from a hobbyist
to a PhD it's about the same.

98
00:04:45,840 --> 00:04:49,869
The only difference is that the PhD person
is trying to cure cancer.

99
00:04:49,870 --> 00:04:51,910
So, this is a human issue.

100
00:04:51,910 --> 00:04:56,200
Because I would come in and maybe they're
at the cusp of finding a cure for cancer and

101
00:04:56,200 --> 00:04:59,530
they're gonna announce it on their web app
and I tell them they have to shut it down

102
00:04:59,530 --> 00:05:02,669
because they have a DOM based XSS error.

103
00:05:02,670 --> 00:05:03,670
They're not gonna like that.

104
00:05:03,670 --> 00:05:06,730
So, we have to deal with human as well, interactions
from here.

105
00:05:06,730 --> 00:05:11,400
The only thing that's the same between us,
is that both of us have one to two dedicated

106
00:05:11,400 --> 00:05:13,849
people to handle these web apps.

107
00:05:13,850 --> 00:05:17,380
So, some of the early challenges...

108
00:05:17,380 --> 00:05:22,659
When I first started, we knew a lot of where
these apps were, but we didn't know all of them.

109
00:05:22,660 --> 00:05:24,000
We just didn't know.

110
00:05:24,000 --> 00:05:25,970
That's been worked out.

111
00:05:25,970 --> 00:05:27,840
Also orphan projects that were still running.

112
00:05:27,840 --> 00:05:31,030
Now this is common, especially for research
places.

113
00:05:31,030 --> 00:05:35,429
They may get some funding and that funding
is, like "Okay, here's a project."

114
00:05:35,430 --> 00:05:36,660
"Here's the deliverable and you're done."

115
00:05:36,660 --> 00:05:37,660
And they move on.

116
00:05:37,660 --> 00:05:39,500
Like some grant money, like that.

117
00:05:39,500 --> 00:05:42,440
And here's this project running since the
Civil War.

118
00:05:42,440 --> 00:05:43,440
And we don't know.

119
00:05:43,440 --> 00:05:46,950
And it looks like 'people,' according to the
Apache logs, are using it, but we're not sure.

120
00:05:46,950 --> 00:05:49,180
We don't know how critical it is, and all
these people are gone.

121
00:05:49,180 --> 00:05:52,610
Oh, and, by the way, there's a huge vulnerability
that was discovered on it.

122
00:05:52,610 --> 00:05:55,430
So, that was a common thing, as well.

123
00:05:55,430 --> 00:05:59,550
But the thing that really challenged us, and
this is sort of the bulk of today's presentation,

124
00:05:59,550 --> 00:06:03,660
is we really had limited knowledge of the
people who built the projects.

125
00:06:03,660 --> 00:06:04,660
We just didn't know.

126
00:06:04,660 --> 00:06:08,520
We knew some but we didn't have that insight
like you would have at a normal company.

127
00:06:08,520 --> 00:06:12,469
So, what we had to become, were web app whispers.

128
00:06:12,470 --> 00:06:15,900
And what we needed is to get as much information
about the app as possible.

129
00:06:15,900 --> 00:06:18,400
We listened, we collected the data.

130
00:06:18,400 --> 00:06:20,609
We use open source tools to do this.

131
00:06:20,610 --> 00:06:24,950
We put the data into a SIEM, and then from
there the SIEM will have it's dashboard.

132
00:06:24,950 --> 00:06:26,680
This is the goal.

133
00:06:26,680 --> 00:06:30,620
And we could actually profile the web app
security from there in addition to all this

134
00:06:30,620 --> 00:06:32,260
other information that we got.

135
00:06:32,260 --> 00:06:36,690
Because, just imagine us getting just a URL
of the repo, and that's it.

136
00:06:36,690 --> 00:06:38,150
It's cool.

137
00:06:38,150 --> 00:06:40,159
So, here's our security tool chain.

138
00:06:40,160 --> 00:06:44,630
Nothing spectacular, but probably additional
scanning things are taking place.

139
00:06:44,630 --> 00:06:46,040
And our projects are in Bitbucket.

140
00:06:46,040 --> 00:06:48,140
We're using Git, and we're using Jenkins.

141
00:06:48,140 --> 00:06:51,919
So, we have these customers come in, they
do their commits, and push.

142
00:06:51,920 --> 00:06:56,060
Jenkins can fire off on-demand a scan through
this whole chain.

143
00:06:56,060 --> 00:06:59,520
And we also do offline scans, as well, like,
on the weekend.

144
00:06:59,520 --> 00:07:03,601
And you'll see that it's divided into three
components: One is the non-SAST guide, which

145
00:07:03,601 --> 00:07:05,040
is in green here.

146
00:07:05,040 --> 00:07:07,230
And this is like, Git, Cloc, Lizard, custom.

147
00:07:07,230 --> 00:07:10,020
I'll talk a little bit more about what those
are, specifically.

148
00:07:10,020 --> 00:07:13,400
But these are what we call 'features,' and
we're collecting these data points, and we

149
00:07:13,400 --> 00:07:19,200
have about 80 some data points now that we
collect.The third-party stuff is like third-party

150
00:07:19,200 --> 00:07:20,270
vulnerable components.

151
00:07:20,270 --> 00:07:26,700
This is the non-custom code: OWASP dependency
checker, Retire, and Drush for Drupal applications.

152
00:07:26,700 --> 00:07:28,770
We also use those tools.

153
00:07:28,770 --> 00:07:30,060
And then finally, the SAST itself.

154
00:07:30,060 --> 00:07:33,520
And again the SAST was the tools that we use
to find the vulnerabilities.

155
00:07:33,520 --> 00:07:34,810
We call these 'labels.'

156
00:07:34,810 --> 00:07:36,710
And why do we have multiple ones?

157
00:07:36,710 --> 00:07:39,349
One, we have SonarQube there, which we used
early on.

158
00:07:39,350 --> 00:07:42,100
But, we also have a couple of commercial SAST
tools.

159
00:07:42,100 --> 00:07:43,740
And the commercial - why we do all these?

160
00:07:43,740 --> 00:07:46,520
It's because there's not one tool to handle
everything.

161
00:07:46,520 --> 00:07:47,520
There's gaps.

162
00:07:47,520 --> 00:07:48,740
I wish there was.

163
00:07:48,740 --> 00:07:50,990
You'd be a rich person.

164
00:07:50,990 --> 00:07:53,270
And then we dump it into the SIEM.

165
00:07:53,270 --> 00:07:56,260
And also, you notice below: students.

166
00:07:56,260 --> 00:08:01,370
We teach a one-day course that we built, and
we track the students who attended this class.

167
00:08:01,370 --> 00:08:05,310
This class is for web application coding;
Secure coding for web applications.

168
00:08:05,310 --> 00:08:07,330
Which is awesome, and we track that.

169
00:08:07,330 --> 00:08:11,280
I'll show you what we do with that data later
on.

170
00:08:11,280 --> 00:08:14,780
Not all SASTs are standardized, if you will.

171
00:08:14,780 --> 00:08:18,840
Some will look at a vulnerability, they may
call the severity, they may call it a risk.

172
00:08:18,840 --> 00:08:20,549
Some may say high, medium, low.

173
00:08:20,550 --> 00:08:23,910
Some other ones might say, 'Really bad, Really
Really Bad,' whatever they say.

174
00:08:23,910 --> 00:08:28,460
But, the ones that we use for this classification
system is: Critical, high, medium, low, and

175
00:08:28,460 --> 00:08:29,460
none.

176
00:08:29,460 --> 00:08:32,279
And there's a numeric that's given with it.

177
00:08:32,279 --> 00:08:36,620
But, typically, what we've sort of adopted
is: at least the same tier "tier-ing" of the

178
00:08:36,620 --> 00:08:38,140
CVSS version 3.0.

179
00:08:38,140 --> 00:08:41,220
If you look at here, it's usually a float
especially when we're starting to take averages

180
00:08:41,220 --> 00:08:42,220
here.

181
00:08:42,220 --> 00:08:43,220
And that's what we're using.

182
00:08:43,220 --> 00:08:47,420
So, at the end of the scan for a given project,
we sum up the scores, and then we divide them

183
00:08:47,420 --> 00:08:51,219
by the number of vulnerabilities to get the
average severity for each project.

184
00:08:51,220 --> 00:08:54,150
So, you may be wondering why we do that.

185
00:08:54,150 --> 00:08:56,990
It's time for machine learning.

186
00:08:56,990 --> 00:08:59,640
I'm getting a drink.

187
00:08:59,640 --> 00:09:02,410
I get excited when this comes on.

188
00:09:02,410 --> 00:09:07,469
So, in machine learning it always starts with
a question.

189
00:09:07,470 --> 00:09:13,260
And our question today is: Can we predict
a project's average severity score based upon

190
00:09:13,260 --> 00:09:15,390
data from non-SAST tools.

191
00:09:15,390 --> 00:09:16,569
Can we make that prediction?

192
00:09:16,570 --> 00:09:18,500
So, if you remember that tool chain that we
had?

193
00:09:18,500 --> 00:09:23,590
If I took that out, all of those SAST tools
on the right side and they were giving me

194
00:09:23,590 --> 00:09:28,450
those average severities, can I do it with
all the stuff on the left hand side?

195
00:09:28,450 --> 00:09:29,450
That's it.

196
00:09:29,450 --> 00:09:32,780
We're not going to know what the big names
of the specific vulnerabilities are.

197
00:09:32,780 --> 00:09:35,689
We're just looking at those averages.

198
00:09:35,690 --> 00:09:39,400
And just a caveat here: This is something
we didn't start out to do.

199
00:09:39,400 --> 00:09:42,040
This isn't, "Let's make a machine learning
model for this stuff!"

200
00:09:42,040 --> 00:09:43,870
We were just desperate to get the information.

201
00:09:43,870 --> 00:09:46,810
But then later would say, "Hey, this looks
like something that could be fun."

202
00:09:46,810 --> 00:09:48,599
So, can we do this?

203
00:09:48,600 --> 00:09:49,600
Maybe.

204
00:09:49,600 --> 00:09:54,180
We decided to use supervised machine learning
to find out.

205
00:09:54,180 --> 00:09:58,319
And the process for that, real quick, is,
you take your whole data set and you divide

206
00:09:58,320 --> 00:10:01,750
it into what they call 'training' and 'testing'
segments from there.

207
00:10:01,750 --> 00:10:03,370
And you use 'labels' and 'features.'

208
00:10:03,370 --> 00:10:06,900
'Labels,' as I mentioned before, is going
to be our SAST data.

209
00:10:06,900 --> 00:10:08,880
That's going to be the answer to our question.

210
00:10:08,880 --> 00:10:14,000
That's the average severity scores and the
'features' are going to consist of our non-SAST data.

211
00:10:14,000 --> 00:10:20,090
So, here's an example of a 'training' data
set: We call it 'the truth,' and each row

212
00:10:20,090 --> 00:10:24,740
represents an instance of a web application
that we just ran a scan with.

213
00:10:24,740 --> 00:10:28,890
And you'll see that the red, that's the SAST
'label'; That's the question we're trying

214
00:10:28,890 --> 00:10:29,890
to answer.

215
00:10:29,890 --> 00:10:32,580
And then everything here's our non-SAST, our
'features.'

216
00:10:32,580 --> 00:10:36,710
And we're taking all this data and we're shoving
it into machine learning algorithms, and they're

217
00:10:36,710 --> 00:10:40,110
trying to figure out, "How can I make this
prediction?"

218
00:10:40,110 --> 00:10:41,570
That's it.

219
00:10:41,570 --> 00:10:43,020
That's all it is.

220
00:10:43,020 --> 00:10:44,840
And this is where we create our machine learning.

221
00:10:44,840 --> 00:10:47,480
But, we have to test to see if it's good,
as well.

222
00:10:47,480 --> 00:10:49,090
So, this is our 'testing' data set.

223
00:10:49,090 --> 00:10:51,260
And we call this the 'unseen data.'

224
00:10:51,260 --> 00:10:56,630
Now remember, we divided this existing corpus
of information and we take this other piece,

225
00:10:56,630 --> 00:11:02,400
which is our test data, usually a smaller
piece, and we take the actual scores out.

226
00:11:02,400 --> 00:11:05,780
And we just put these things in and see how
well they score.

227
00:11:05,780 --> 00:11:09,050
And we kind of, you know, compare because
we actually know the scores.

228
00:11:09,050 --> 00:11:12,750
And that does very well, we're doing very
well.

229
00:11:12,750 --> 00:11:16,000
We do something called K-Fold Cross-Validation.

230
00:11:16,000 --> 00:11:20,760
And what it is, we take that data set and
we set a value for 'K.'

231
00:11:20,760 --> 00:11:22,000
We just set it for 10.

232
00:11:22,000 --> 00:11:25,930
We tried different ones but 10 seems to be
the one that people recommend.

233
00:11:25,930 --> 00:11:28,420
And we do this 'train' 'test' thing that I
just mentioned.

234
00:11:28,420 --> 00:11:33,079
But what we do is take that whole data set,
divide it in 10, and go ten iterations until

235
00:11:33,080 --> 00:11:34,080
we got everything.

236
00:11:34,080 --> 00:11:35,221
And the reason why we do that ...

237
00:11:35,221 --> 00:11:39,670
Oh, and by the way, when we load the data
set up, we shuffle it; We randomize it.

238
00:11:39,670 --> 00:11:43,199
That makes sure that we're being honest; Making
sure that there are no clusters of data that

239
00:11:43,200 --> 00:11:45,220
might give us some false readings.

240
00:11:45,220 --> 00:11:46,380
Whether good or bad.

241
00:11:46,380 --> 00:11:50,550
And I'll also show you why we do that, in
a bit, to determine the health, if you will,

242
00:11:50,550 --> 00:11:52,870
how good your accuracy is.

243
00:11:52,870 --> 00:11:56,850
So, we had to pick some algorithms.

244
00:11:56,850 --> 00:12:02,380
And we did things like Linear Support Vector
Machines (SVM), Naive Bayes, Neural Networks,

245
00:12:02,380 --> 00:12:04,170
Random Forests, Stochastic Gradient.

246
00:12:04,170 --> 00:12:05,790
These are great kids' names.

247
00:12:05,790 --> 00:12:07,029
[ audience laughter ]

248
00:12:07,029 --> 00:12:12,910
And we said, "We use the the Scikit-learn
from Python," which is so easy to do, and

249
00:12:12,910 --> 00:12:17,360
even if you don't, exactly, know how the algorithms
are working behind the scenes, they're great

250
00:12:17,360 --> 00:12:20,720
literature, basically to show how they run.

251
00:12:20,720 --> 00:12:26,920
But the reason why I picked these, was that
they're very different in how they make that model.

252
00:12:26,920 --> 00:12:30,099
Some are based, like Naive Bayes, it's a probabilistic
thing.

253
00:12:30,100 --> 00:12:34,209
The other one like Neural Networks, Perceptrons,
and so forth, Random Forests as decision trees

254
00:12:34,209 --> 00:12:40,060
... Other things like Euclidean distances
from some point, they're all very different

255
00:12:40,060 --> 00:12:41,790
and that's why they were chosen.

256
00:12:41,790 --> 00:12:44,099
So, how did we score?

257
00:12:44,100 --> 00:12:48,980
Well, first after this break, we'll talk about
the non-SAST data.

258
00:12:48,980 --> 00:12:50,470
Because, I think this is interesting.

259
00:12:50,470 --> 00:12:52,850
This is how you have to choose your 'features.'

260
00:12:52,850 --> 00:12:56,630
And we have 80 of them, so, I'll go through
all 80 in 20 minutes -- Just kidding!

261
00:12:56,630 --> 00:12:58,950
Cloc, I think, maybe most people have heard
of Cloc.

262
00:12:58,950 --> 00:13:01,490
It's a simple tool that counts lines of code.

263
00:13:01,490 --> 00:13:06,050
And you'll see the output here: it gives you
'the language,' 'the files,' 'blank,' 'comments,'

264
00:13:06,050 --> 00:13:07,500
'codes per file,' that type of thing.

265
00:13:07,500 --> 00:13:11,860
But, it's pretty cool too because, again,
we're looking for Bad Human behavior or some

266
00:13:11,860 --> 00:13:14,950
kind of smoke here.

267
00:13:14,950 --> 00:13:18,820
Most languages, like, a website probably has
less than 10 different languages associated.

268
00:13:18,820 --> 00:13:23,840
It could be HTML -- HTML, accounting even
non-programming languages; But maybe PHP,

269
00:13:23,840 --> 00:13:27,600
there might be some XML in there, JSON, that
kind of stuff.

270
00:13:27,600 --> 00:13:32,010
But if we're seeing a website that has, or
a project that has, 300 different language

271
00:13:32,010 --> 00:13:37,339
types, this is probably indicative of somebody's
development environment in a production environment.

272
00:13:37,339 --> 00:13:38,360
Something -- We've seen that.

273
00:13:38,360 --> 00:13:41,680
'Lines of code comments' and' lines of code
per comment.'

274
00:13:41,680 --> 00:13:43,920
That big argument: Should you comment your
code?

275
00:13:43,920 --> 00:13:45,120
Should you not comment your code?

276
00:13:45,120 --> 00:13:50,830
What we're asking, the question is: more comments
means less vulnerabilities or vice-versa?

277
00:13:50,830 --> 00:13:52,930
We might be able to answer that question.

278
00:13:52,930 --> 00:13:56,170
And my favorite: The unnatural server-side
bedfellows.

279
00:13:56,170 --> 00:14:01,380
We have seen a mix of NET and PHP and sometimes
ColdFusion in some applications.

280
00:14:01,380 --> 00:14:03,240
You say, "What the heck?"

281
00:14:03,240 --> 00:14:06,589
A lot of times, that's about transitioning
from maybe one language to the other.

282
00:14:06,589 --> 00:14:09,440
And it's, "Well we better keep this up there."

283
00:14:09,440 --> 00:14:12,970
I'm not saying it's more vulnerable or not,
but that's, kind of, something we're monitoring.

284
00:14:12,970 --> 00:14:17,160
And remember, we're looking at this data without
any sort of bias.

285
00:14:17,160 --> 00:14:19,380
We're just putting these data points in there.

286
00:14:19,380 --> 00:14:20,980
Anybody heard of Lizard?

287
00:14:20,980 --> 00:14:21,980
Yeah?

288
00:14:21,980 --> 00:14:22,980
Cool!

289
00:14:22,980 --> 00:14:23,980
Nobody?

290
00:14:23,980 --> 00:14:24,980
Oh, one?

291
00:14:24,980 --> 00:14:25,980
Oh, maybe not.

292
00:14:25,980 --> 00:14:27,670
Well, that's a camera guy.

293
00:14:27,670 --> 00:14:33,099
Lizard's about code complexity and I love
this tool because it looks -- And I'm when

294
00:14:33,100 --> 00:14:36,510
I'm talking about complexity, I'm not talking
about it's doing nuclear physics or something

295
00:14:36,510 --> 00:14:37,510
of that nature.

296
00:14:37,510 --> 00:14:42,029
It's looking at things like -- a nice word
here -- Cyclomatic Complexity Number.

297
00:14:42,029 --> 00:14:44,910
To explain what that is: That's linearly independent
paths.

298
00:14:44,910 --> 00:14:48,010
Which is equally ... But think about if/and
statements.

299
00:14:48,010 --> 00:14:53,000
If you're doing something like 15 or greater,
starts to throw out a flag.

300
00:14:53,000 --> 00:14:56,690
Function token and parameter counts: If you've
ever been in, like, a compiler class and you

301
00:14:56,690 --> 00:15:01,770
had to make a parser, for example, you know
how you'd parse the actual language, right?

302
00:15:01,770 --> 00:15:06,360
Well if you have larger function token count,
like a thousand, that's really just a really

303
00:15:06,360 --> 00:15:07,360
big function.

304
00:15:07,360 --> 00:15:08,670
A really long one.

305
00:15:08,670 --> 00:15:11,839
Smaller functions might be looked on more
favorable.

306
00:15:11,839 --> 00:15:13,490
Again, we're not making a decision here.

307
00:15:13,490 --> 00:15:14,820
But, that's usually what we hear.

308
00:15:14,820 --> 00:15:18,760
Parameter counts: if you have a function that's
taken over a hundred parameters, you might

309
00:15:18,760 --> 00:15:20,510
want to take a data structure class.

310
00:15:20,510 --> 00:15:21,930
[ audience laughter ]

311
00:15:21,930 --> 00:15:24,149
And finally, duplicate code: even 0%.

312
00:15:24,149 --> 00:15:28,260
You say, "Well, maybe that's not bad, maybe
it's not great," but this is -- What we think

313
00:15:28,260 --> 00:15:30,590
about is more of cut and paste code.

314
00:15:30,590 --> 00:15:33,270
Sometimes, people cut and paste and there's
a lot of problems with that.

315
00:15:33,270 --> 00:15:38,360
So, the question is, again: Do lower scores
suggest less vulnerabilities?

316
00:15:38,360 --> 00:15:39,839
I'm not going to answer that yet.

317
00:15:39,839 --> 00:15:41,730
Git 'Features': This one's my favorite.

318
00:15:41,730 --> 00:15:43,360
So, Git we need, of course.

319
00:15:43,360 --> 00:15:47,940
But we look at things like project lifetime,
number of commits, last time the project,

320
00:15:47,940 --> 00:15:48,940
it's activities.

321
00:15:48,940 --> 00:15:53,900
One thing we do too is: We check the emails
of the Git committers and we determine whether,

322
00:15:53,900 --> 00:15:55,860
or not, that committer had taken the class.

323
00:15:55,860 --> 00:15:56,860
Right?

324
00:15:56,860 --> 00:15:57,860
Now we have this class.

325
00:15:57,860 --> 00:16:03,860
So, imagine a metric where you have 10 developers
and all 10 took the class, that's 100%.

326
00:16:03,860 --> 00:16:08,010
Or one that has nobody taking the class and
it's a really bad app.

327
00:16:08,010 --> 00:16:09,779
That could be a good indicator.

328
00:16:09,779 --> 00:16:12,731
Also, signed off count: Sometimes, have you
ever used Gerrit?

329
00:16:12,731 --> 00:16:14,970
There's some other ones where they have a
signed off in there.

330
00:16:14,970 --> 00:16:19,180
That usually indicates that somebody else,
instead of just one person, looked at the code.

331
00:16:19,180 --> 00:16:20,300
So, like a manual code review.

332
00:16:20,300 --> 00:16:21,579
That might be good as well.

333
00:16:21,580 --> 00:16:27,140
And my favorite -- and my boss looked at me
kind of strange about this one: Natural Language

334
00:16:27,140 --> 00:16:31,330
Processing: I look at the messages themselves.

335
00:16:31,330 --> 00:16:34,350
And I do things like -- and there's great
libraries out there.

336
00:16:34,350 --> 00:16:36,180
And they're like, within seconds, I mean they're
fast.

337
00:16:36,180 --> 00:16:38,459
It's not taking a lot of the time.

338
00:16:38,459 --> 00:16:40,569
But of course, we look at blanks.

339
00:16:40,570 --> 00:16:45,080
But we look at misspelled words, but more
importantly, There's an indicator called polarity.

340
00:16:45,080 --> 00:16:47,860
Anybody know what polarity is?

341
00:16:47,860 --> 00:16:52,070
If the developers were depressed, are they
making more vulnerability things?

342
00:16:52,070 --> 00:16:54,220
From the language, it looks like that.

343
00:16:54,220 --> 00:16:58,120
And Subjectivity: Are they subjective or objective?

344
00:16:58,120 --> 00:16:59,120
I don't know.

345
00:16:59,120 --> 00:17:00,640
Let's track it and see.

346
00:17:00,640 --> 00:17:02,990
So, now it's time for our results.

347
00:17:02,990 --> 00:17:07,440
Anybody want to guess the best number, talking
from 0 to 100%?

348
00:17:07,440 --> 00:17:08,620
Give me a number.

349
00:17:10,660 --> 00:17:11,660
[Audience:] 60

350
00:17:11,800 --> 00:17:12,800
[Audience:] 82

351
00:17:12,859 --> 00:17:13,859
[John L. Whiteman:] 82?

352
00:17:13,900 --> 00:17:14,900
[Audience:] 40

353
00:17:14,900 --> 00:17:15,900
[John L. Whiteman:] 40?

354
00:17:16,119 --> 00:17:16,719
[Audience:] Are these Price is Right jokes?

355
00:17:16,720 --> 00:17:17,940
[ Laughter ]

356
00:17:18,200 --> 00:17:19,200
So what else?

357
00:17:19,460 --> 00:17:20,120
[ Inaudible audience comment ]

358
00:17:20,119 --> 00:17:21,119
[Audience:] One dollar?

359
00:17:21,400 --> 00:17:23,540
Ooh, and you're the one that didn't know SAST?

360
00:17:23,540 --> 00:17:25,339
Well, you're the closest.

361
00:17:26,880 --> 00:17:27,920
Yeah.

362
00:17:27,920 --> 00:17:29,060
86.

363
00:17:29,060 --> 00:17:29,570
Good job!

364
00:17:29,570 --> 00:17:35,830
Okay, so, again, what we've done is we took
hundreds of samples ... We didn't use all

365
00:17:35,830 --> 00:17:36,830
the 'features.'

366
00:17:36,830 --> 00:17:37,899
We did about 50 of them.

367
00:17:37,900 --> 00:17:40,419
The K-Fold that I've already described, we
picked ten.

368
00:17:40,419 --> 00:17:43,119
And I did it a hundred times just to make
myself honest.

369
00:17:43,119 --> 00:17:46,480
And remember, every time, it's randomized
the data that goes through there.

370
00:17:46,480 --> 00:17:48,840
So, random forest came out first.

371
00:17:48,840 --> 00:17:50,610
And that was around 86%.

372
00:17:50,610 --> 00:17:55,379
And then, the next three: The linear SVM,
Stochastic Gradient, and Neural Nets.

373
00:17:55,379 --> 00:17:58,490
All of them around 80%, which is still pretty
good.

374
00:17:58,490 --> 00:18:00,669
And the Naive Bayes was down there at 46%.

375
00:18:00,669 --> 00:18:07,720
So, another way of looking at this is that,
if you, as a person, were given this web application,

376
00:18:07,720 --> 00:18:11,330
that's the first time you saw it, you have
a one in five chance of determining whether

377
00:18:11,330 --> 00:18:14,259
or not it was 'critical,' 'high,''medium,'
'low,' or 'none.'

378
00:18:14,259 --> 00:18:15,259
Right?

379
00:18:15,259 --> 00:18:16,539
You have one in five chance.

380
00:18:16,539 --> 00:18:20,679
But if we're using Random Forests, for example,
you have an 86% chance of doing it.

381
00:18:20,679 --> 00:18:22,159
So, that's not bad.

382
00:18:22,160 --> 00:18:28,429
And here's a caveat for the Naive Bayes: These
other four classifiers are really good at classification.

383
00:18:28,429 --> 00:18:33,060
They're all supervised learning algorithms,
but they're really good for these multi-label things.

384
00:18:33,060 --> 00:18:36,280
Or what I just described: The 'critical,'
'high,' 'medium,' 'low.'

385
00:18:36,289 --> 00:18:38,169
This Naive Bayes is not really for that.

386
00:18:38,169 --> 00:18:42,470
It's a little bit more probabilistic and not
really suited for it.

387
00:18:42,470 --> 00:18:47,990
It did, you know, less than a coin flip, I
guess, and I was expecting that.

388
00:18:47,990 --> 00:18:51,399
I kind of wanted to see if there was some
sort of difference between these algorithms.

389
00:18:51,399 --> 00:18:55,428
So, yeah, 80%, it's time to quit my job.

390
00:18:55,429 --> 00:19:01,350
I can build an AI security company, go on
Joe Rogan, and laugh, and get rich.

391
00:19:01,350 --> 00:19:03,928
But, not yet.

392
00:19:03,929 --> 00:19:05,340
There were some issues.

393
00:19:05,340 --> 00:19:07,470
There WERE some issues.

394
00:19:07,470 --> 00:19:10,159
So, let's look at this.

395
00:19:10,159 --> 00:19:13,049
How many ... Okay, you already know how many
there are ... Here's a thousand points.

396
00:19:13,049 --> 00:19:14,080
Remember my K values?

397
00:19:14,080 --> 00:19:17,110
And I multiply it by 100 times 10?

398
00:19:17,110 --> 00:19:18,928
That's why I like this this K-Fold stuff.

399
00:19:18,929 --> 00:19:21,879
Because I can keep track of each one of these.

400
00:19:21,879 --> 00:19:24,908
And down below in red is, of course, our Naive
Bayes.

401
00:19:24,909 --> 00:19:26,159
But look at the spread!

402
00:19:26,159 --> 00:19:31,549
I'm talking about things as low as 20% accuracy
to, maybe, up to 70%?

403
00:19:31,549 --> 00:19:32,850
And I'm being generous there.

404
00:19:32,850 --> 00:19:34,649
That's a 50% spread.

405
00:19:34,649 --> 00:19:37,428
You're going to want to reject that one.

406
00:19:37,429 --> 00:19:40,179
Or let's go the other side: We'll take our
Random Forests up here.

407
00:19:40,180 --> 00:19:41,600
Yeah, I got a thing here, yeah!

408
00:19:41,600 --> 00:19:42,600
Here we go.

409
00:19:42,840 --> 00:19:45,080
Yeah, we get some hundred percents up here.

410
00:19:45,280 --> 00:19:46,279
That's awesome.

411
00:19:46,279 --> 00:19:47,690
But we still see a spread.

412
00:19:47,690 --> 00:19:51,129
Maybe 15-20 percent, right?

413
00:19:51,129 --> 00:19:54,149
So the question is, from here: is that acceptable?

414
00:19:54,150 --> 00:20:00,130
Well, if you have an application that determines
whether someone lives or dies on these labels?

415
00:20:00,130 --> 00:20:02,200
No, absolutely not.

416
00:20:02,200 --> 00:20:06,169
But in our case, remember in the beginning
... Well, maybe I didn't say, but in the beginning

417
00:20:06,169 --> 00:20:09,460
we didn't have really good commercial tools
in place, yet.

418
00:20:09,460 --> 00:20:13,889
We had all these websites and we wanted a
way if we had to go in and do some sort of

419
00:20:13,889 --> 00:20:18,979
triaging, without knowing what the websites
were, and maybe that's okay.

420
00:20:18,980 --> 00:20:20,129
It might be right on.

421
00:20:20,129 --> 00:20:21,519
Because we already have that data.

422
00:20:21,519 --> 00:20:22,999
It's already there.

423
00:20:22,999 --> 00:20:24,869
But, we're not giving up.

424
00:20:24,869 --> 00:20:29,649
So, what's happening is something called overfitting,
probably, and that occurs when we don't have

425
00:20:29,649 --> 00:20:30,649
enough data.

426
00:20:30,649 --> 00:20:31,649
I said hundreds of samples.

427
00:20:31,649 --> 00:20:35,209
That may sound like a lot, but we probably
need thousands of samples.

428
00:20:35,210 --> 00:20:37,070
Or tens of thousands, or millions.

429
00:20:37,070 --> 00:20:42,720
So, we're telling the web app teams across
the organization to build more web apps.

430
00:20:42,720 --> 00:20:47,399
On the underfitting side -- This is what I
call the buzzkiller.

431
00:20:47,399 --> 00:20:50,789
It could be that our algorithms are not right.

432
00:20:50,789 --> 00:20:54,879
But we did try a good set of algorithms and
they all showed reasonably consistent.

433
00:20:54,879 --> 00:20:56,279
Except Naive Bayes.

434
00:20:56,279 --> 00:20:58,139
So, they may be wrong.

435
00:20:58,139 --> 00:21:01,949
Or it may be that we have the wrong 'features,'
we have these 80's.

436
00:21:01,950 --> 00:21:02,950
Maybe we have too many in there.

437
00:21:02,950 --> 00:21:07,529
I mean, you could go in and do this permutation
combination, whatever of all these 'features'

438
00:21:07,529 --> 00:21:09,059
and maybe that's not right.

439
00:21:09,059 --> 00:21:12,770
But the buzz kill is, maybe this is not going
to work no matter what.

440
00:21:12,770 --> 00:21:15,139
And you have to walk away.

441
00:21:15,139 --> 00:21:17,590
But, we don't walk away.

442
00:21:17,590 --> 00:21:20,620
Because, we're looking for the 'Goldilocks
Fit.'

443
00:21:20,620 --> 00:21:24,469
And at the time when I first ran the first
set, I thought I was going to walk away.

444
00:21:24,470 --> 00:21:29,169
But what we need is lots of data and the right
set of 'features' to get this curve.

445
00:21:29,169 --> 00:21:33,900
So, how are we going to get more data?

446
00:21:33,900 --> 00:21:36,289
I think of code as a bunch of babies in a
crib.

447
00:21:36,289 --> 00:21:39,480
I took this picture ten years ago, I can finally
use it now.

448
00:21:39,480 --> 00:21:42,049
Imagine the crib is BitBucket.

449
00:21:42,049 --> 00:21:43,820
And each baby is a repo.

450
00:21:43,820 --> 00:21:45,519
I like that.

451
00:21:45,519 --> 00:21:48,080
Now, they all grow up.

452
00:21:48,080 --> 00:21:53,129
Each commit, every time there is a push, it's
a new incidence of the web app.

453
00:21:53,129 --> 00:21:54,129
Right?

454
00:21:54,129 --> 00:21:55,129
The code is changed.

455
00:21:55,129 --> 00:21:56,949
Something has changed in that web app.

456
00:21:56,950 --> 00:21:58,090
Something is evolved.

457
00:21:58,090 --> 00:21:59,449
So we treat it as a new sample.

458
00:21:59,450 --> 00:22:02,929
We're collecting it anyway, well let's treat
it as such.

459
00:22:02,929 --> 00:22:06,570
Another thing is, the SAST tools themselves
change.

460
00:22:06,570 --> 00:22:09,909
So you may get a new version of a SAST tool
and hopefully it's going to be better than

461
00:22:09,910 --> 00:22:10,910
the last.

462
00:22:10,910 --> 00:22:11,910
Right?

463
00:22:11,910 --> 00:22:13,369
That's another thing.

464
00:22:13,369 --> 00:22:14,840
They get updated as well.

465
00:22:14,840 --> 00:22:20,830
The big one here, where people get involved,
is that the false positives will go away.

466
00:22:20,830 --> 00:22:24,480
This data that you saw, there was absolutely
no triaging whatsoever.

467
00:22:24,480 --> 00:22:25,480
Nothing.

468
00:22:25,480 --> 00:22:26,590
We didn't talk to developers.

469
00:22:26,590 --> 00:22:29,379
We didn't go through and say, "Yeah these
are all false positives."

470
00:22:29,380 --> 00:22:30,889
I'm sure there are.

471
00:22:30,889 --> 00:22:32,340
And there's probably false negatives too.

472
00:22:32,340 --> 00:22:33,939
Which are harder to find.

473
00:22:33,940 --> 00:22:36,970
But maybe as a tool progresses they will be
found as well.

474
00:22:36,970 --> 00:22:39,409
So these are the three things that are always
changing.

475
00:22:39,409 --> 00:22:43,809
So we treat it as a new web app every time
and we just keep collecting that accordingly.

476
00:22:43,809 --> 00:22:50,168
So, for us we wanna keep collecting the data
and we want to be 'Good Humans' as well.

477
00:22:50,169 --> 00:22:56,029
And before I stop ... Way early in this project
I was trying to ... We were characterizing

478
00:22:56,029 --> 00:23:00,720
and comparing different commercial tools,
commercial SAST scanners out there.

479
00:23:00,720 --> 00:23:04,230
And there's a lot of stuff on GitHub that
has, like, vulnerable web apps and stuff.

480
00:23:04,230 --> 00:23:09,389
But one of the things I found challenging
was just finding pieces of just snippets of

481
00:23:09,389 --> 00:23:11,479
code that were vulnerable for a given language.

482
00:23:11,480 --> 00:23:16,359
So, if you have really a corpus of crappy
code somewhere, and you want to put it in

483
00:23:16,359 --> 00:23:17,710
to here, go for it.

484
00:23:17,710 --> 00:23:21,899
What I'm looking for, though, is if people
do want to run their scanner, try their scanner

485
00:23:21,899 --> 00:23:25,969
or maybe they're building something on their
own, they can download this project, run it

486
00:23:25,970 --> 00:23:30,049
and if you are so kind, maybe you want to
upload your SAST results as well.

487
00:23:30,049 --> 00:23:33,990
Because we're trying to ... All these commercial
SAST scanners are very expensive.

488
00:23:33,990 --> 00:23:36,039
But this would be a good thing to do.

489
00:23:36,039 --> 00:23:37,259
Or at least a good thing to try.

490
00:23:37,259 --> 00:23:39,460
There's some code up there now but just feel
free to add it.

491
00:23:39,460 --> 00:23:41,980
Anyway, thank you very much.

492
00:23:42,020 --> 00:23:44,420
And, any questions?

493
00:23:48,200 --> 00:23:52,640
[Audience:] Did you attempt to list the prediction,
like the continuous, were you predicting the

494
00:23:52,640 --> 00:23:57,000
slope or is it predicting like a whole new
class problem where you predict the float?

495
00:23:57,000 --> 00:24:01,500
[John L. Whiteman:] Yeah, so, you get the
float from the average and then you put it

496
00:24:01,509 --> 00:24:03,659
into that tiering system.

497
00:24:03,659 --> 00:24:08,470
It's like that CVSS v.3, if it falls into
there, it's a '4' it's a '2' ... So it becomes

498
00:24:08,470 --> 00:24:09,470
an integer.

499
00:24:09,470 --> 00:24:10,470
Yeah.

500
00:24:10,470 --> 00:24:11,470
Yes.

501
00:24:11,470 --> 00:24:14,180
[Audience:] So you mentioned you had some
issues with falsing.

502
00:24:14,180 --> 00:24:19,520
Do you have the link to your [inaudible] analysis
or any descriptors of the statistic of your model?

503
00:24:19,660 --> 00:24:22,380
[John L. Whiteman:] I have the code I can
push up.

504
00:24:22,560 --> 00:24:31,159
So there's the one that I had before, uh let's
see ... There's another one called '/tools.' Right afterwards.

505
00:24:31,360 --> 00:24:34,258
I have one more commit to put up there but
you'll see what I did.

506
00:24:34,259 --> 00:24:35,259
[Audience:] Cool.

507
00:24:35,259 --> 00:24:36,399
[John L. Whiteman:] So everything is up there.

508
00:24:36,399 --> 00:24:37,928
The data is not up there.

509
00:24:37,929 --> 00:24:40,580
I can't but I can show you what the results
were.

510
00:24:40,580 --> 00:24:42,529
But the data has to be redacted, obviously.

511
00:24:42,529 --> 00:24:44,190
Yeah, take a look.

512
00:24:44,190 --> 00:24:45,899
I'm not a machine learning expert.

513
00:24:45,899 --> 00:24:50,120
But, I call myself a doctor, so that's good,
right?

514
00:24:50,120 --> 00:24:51,199
Anybody else?

515
00:24:51,320 --> 00:24:52,060
Yeah.

516
00:24:52,240 --> 00:24:57,200
[Audience:] So, some of the numbers you mentioned
during the presentation >100 parameters, greater

517
00:24:57,200 --> 00:25:01,920
than, you know, ten languages in a single
project, I've never seen those in the real world.

518
00:25:02,060 --> 00:25:04,100
Am I just missing something?

519
00:25:04,200 --> 00:25:05,100
Are you seeing any machine generated code
whatsoever?

520
00:25:05,280 --> 00:25:11,980
[John L. Whiteman:] No, so, the code complexity
tool, the Lizard tool, this is how they do

521
00:25:12,100 --> 00:25:13,100
it out of the box.

522
00:25:13,100 --> 00:25:16,100
So, they look at code complexity as those
types of things.

523
00:25:16,100 --> 00:25:17,580
And for them ... And it's set-able.

524
00:25:17,580 --> 00:25:18,580
Right?

525
00:25:18,580 --> 00:25:22,580
You can set these values, but by default,
they're saying if you have ...

526
00:25:22,580 --> 00:25:26,100
It's going through the code, it's reviewing
that source code and saying, "Hey, you have

527
00:25:26,100 --> 00:25:29,139
a 'function' here with a hundred parameters,
we're going to set a 'flag' to that."

528
00:25:29,140 --> 00:25:30,140
[Audience:] Is that literally a hundred?

529
00:25:30,140 --> 00:25:31,140
I mean ...

530
00:25:31,140 --> 00:25:32,889
[John L. Whiteman:] No no, it could be whatever
value.

531
00:25:32,889 --> 00:25:33,879
Yeah, so that's the threshold.

532
00:25:33,880 --> 00:25:35,720
It's a threshold.

533
00:25:35,720 --> 00:25:37,240
[Audience:] So, is that threshold set?

534
00:25:37,240 --> 00:25:39,100
Did you guys set it manually?

535
00:25:39,240 --> 00:25:39,920
How does it?

536
00:25:40,040 --> 00:25:43,240
[John L. Whiteman:] No, so that was it's out
of the box default.

537
00:25:43,240 --> 00:25:44,220
In fact, we don't even look at the threshold.

538
00:25:44,220 --> 00:25:47,639
We look at warnings, but we also just look
at the number.

539
00:25:47,639 --> 00:25:52,590
Like I said before, I don't make any decision
before and I just said, "Okay, that's a point

540
00:25:52,590 --> 00:25:53,590
and I just want to check."

541
00:25:53,590 --> 00:25:54,830
Let the machine learning figure that out.

542
00:25:54,830 --> 00:25:55,830
Yeah.

543
00:25:55,830 --> 00:25:56,820
Anybody else?

544
00:25:57,860 --> 00:25:58,860
Yes, sir.

545
00:25:58,860 --> 00:26:00,860
[Audience:] What SAST tools are you using?

546
00:26:00,860 --> 00:26:03,139
[John L. Whiteman:] I can't tell you that.

547
00:26:03,140 --> 00:26:04,580
But they're very expensive.

548
00:26:04,590 --> 00:26:05,590
[ audience laughter ]

549
00:26:05,590 --> 00:26:06,590
Huh?

550
00:26:06,590 --> 00:26:09,300
[Audience:] Were you using two tools?

551
00:26:09,300 --> 00:26:11,739
[John L. Whiteman:] We had two commercial
tools, and SonarQube.

552
00:26:11,739 --> 00:26:14,220
And SonarQube, it's not great.

553
00:26:14,220 --> 00:26:18,879
There's some good things about it, but when
you start looking at the, like, PHP in the

554
00:26:18,879 --> 00:26:20,908
security rules, it's hideous.

555
00:26:20,909 --> 00:26:23,090
It just looks at .inc files and stuff.

556
00:26:23,090 --> 00:26:24,738
But there were other things that we looked
at with SonarQube.

557
00:26:24,739 --> 00:26:29,639
And that was in the early days before we could
get those good tools.

558
00:26:29,639 --> 00:26:33,168
And again, it was mostly because one tool
didn't have a language and the other did.

559
00:26:33,169 --> 00:26:34,389
That's what we're looking for.

560
00:26:34,389 --> 00:26:35,389
Language coverage.

561
00:26:35,389 --> 00:26:36,389
[Audience:] Open Source alternative?

562
00:26:36,389 --> 00:26:39,988
[John L. Whiteman:] There's tons and it depends
on what your language is, but if you want

563
00:26:39,989 --> 00:26:43,409
to make a lot of money, build your own.

564
00:26:43,409 --> 00:26:48,090
Yeah, you know, there's like, I think, a group
out of Germany that did some PHP.

565
00:26:48,090 --> 00:26:52,359
It's not bad but they started Open-Source
and then eventually ... I think even SonarQube

566
00:26:52,359 --> 00:26:54,908
started that way.

567
00:26:54,909 --> 00:26:58,320
[ audience comment inaudible ]

568
00:26:58,320 --> 00:26:59,320
That's right.

569
00:26:59,320 --> 00:27:03,189
That was one issue collecting the lines of
code and Cloc and all of that is, they say,

570
00:27:03,190 --> 00:27:04,590
"Well how much data are you going to do?"

571
00:27:04,590 --> 00:27:09,601
So sometimes, the SAST tool will say how many
lines of code or how the file sizes are and

572
00:27:09,602 --> 00:27:10,602
all this stuff.

573
00:27:10,602 --> 00:27:13,520
Some go by number of users, some go by number
of projects.

574
00:27:13,520 --> 00:27:17,100
They were pretty surprised by, "Well how many
projects are you going to have? Ten?"

575
00:27:17,140 --> 00:27:18,700
No, we've got hundreds.

576
00:27:18,700 --> 00:27:21,359
So they had to change their model for that.

577
00:27:21,359 --> 00:27:22,399
Anybody else?

578
00:27:22,399 --> 00:27:24,589
Okay, thank you!

579
00:27:24,589 --> 00:27:28,860
[ audience applause ]

