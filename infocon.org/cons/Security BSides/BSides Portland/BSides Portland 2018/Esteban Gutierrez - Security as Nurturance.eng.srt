1
00:00:15,130 --> 00:00:21,340
and hop in and introduce him mrs.

2
00:00:19,150 --> 00:00:25,299
Esteban I think that I first met Esteban

3
00:00:21,340 --> 00:00:27,640
at the very first besides Portland which

4
00:00:25,300 --> 00:00:30,240
you know he's one of the several who cop

5
00:00:27,640 --> 00:00:32,290
Depp's ball rolling to the the you know

6
00:00:30,240 --> 00:00:35,890
Sisyphean Boulder that it is rolling

7
00:00:32,290 --> 00:00:38,920
down the hill right now and when he

8
00:00:35,890 --> 00:00:41,230
submitted this presentation it was

9
00:00:38,920 --> 00:00:44,589
obviously great so we accepted it but he

10
00:00:41,230 --> 00:00:46,809
asked for in the the speaker notes like

11
00:00:44,589 --> 00:00:48,339
special requests he asked for therapy

12
00:00:46,809 --> 00:00:52,180
therapy puppies to hand out to the

13
00:00:48,340 --> 00:00:56,110
audience so I have a bag of therapy

14
00:00:52,180 --> 00:00:59,320
puppies that I'm gonna put up here and

15
00:00:56,110 --> 00:01:02,890
he can give out to you if he decides

16
00:00:59,320 --> 00:01:05,019
that you need therapy puppy they are not

17
00:01:02,890 --> 00:01:08,890
live puppies they were never live

18
00:01:05,019 --> 00:01:10,869
puppies but they're their little soft

19
00:01:08,890 --> 00:01:21,720
puppies on little blankets and if you

20
00:01:10,869 --> 00:01:24,520
press here so thank you for presenting

21
00:01:21,720 --> 00:01:27,220
do what you think needs to happen with

22
00:01:24,520 --> 00:01:43,199
these therapy dogs and take a care of

23
00:01:27,220 --> 00:01:48,490
them this microphone setup is awkward

24
00:01:43,200 --> 00:01:50,140
hello my name is Esteban Gutierrez I I'm

25
00:01:48,490 --> 00:01:51,610
the director of information security at

26
00:01:50,140 --> 00:01:54,130
a company called New Relic that's a

27
00:01:51,610 --> 00:01:57,759
local software application performance

28
00:01:54,130 --> 00:02:00,820
analytics digital analytics company and

29
00:01:57,759 --> 00:02:04,119
I really like working there I've given

30
00:02:00,820 --> 00:02:10,539
this talk a couple times before and can

31
00:02:04,119 --> 00:02:12,989
you all hear me okay no all right I'm

32
00:02:10,539 --> 00:02:12,989
going to do this

33
00:02:15,640 --> 00:02:20,959
it means I can't really move very much

34
00:02:17,870 --> 00:02:24,110
so yeah that's better let me start over

35
00:02:20,960 --> 00:02:26,150
so my name is Esteban Gutierrez I'm the

36
00:02:24,110 --> 00:02:30,170
director of information security at New

37
00:02:26,150 --> 00:02:34,040
Relic we love this conference we think

38
00:02:30,170 --> 00:02:38,170
it it makes life better for everybody my

39
00:02:34,040 --> 00:02:41,329
talk is about security as nurturance

40
00:02:38,170 --> 00:02:44,299
I've been with New Relic for about two

41
00:02:41,330 --> 00:02:47,860
and a half almost three years and I work

42
00:02:44,300 --> 00:02:49,880
as part of a pretty great team of people

43
00:02:47,860 --> 00:02:52,000
we've got product security

44
00:02:49,880 --> 00:02:55,370
infrastructure and operations security

45
00:02:52,000 --> 00:02:59,170
building a program they're not entirely

46
00:02:55,370 --> 00:03:02,060
from scratch but building a program that

47
00:02:59,170 --> 00:03:05,140
takes a lot of learnings from how things

48
00:03:02,060 --> 00:03:07,220
have not gone well in other companies I

49
00:03:05,140 --> 00:03:08,589
kind of feel like sometimes the people

50
00:03:07,220 --> 00:03:11,330
that come to work at New Relic are

51
00:03:08,590 --> 00:03:14,600
getting over PTSD from working at other

52
00:03:11,330 --> 00:03:16,580
companies and they spend like a good

53
00:03:14,600 --> 00:03:20,180
month and a half or sometimes a year

54
00:03:16,580 --> 00:03:22,820
going what is this place why is everyone

55
00:03:20,180 --> 00:03:26,450
so nice what do you mean I don't have to

56
00:03:22,820 --> 00:03:27,859
work after five and it's sort of one of

57
00:03:26,450 --> 00:03:30,859
the first companies I've worked at that

58
00:03:27,860 --> 00:03:33,620
takes the human part of work very

59
00:03:30,860 --> 00:03:35,990
seriously because we recognize that it's

60
00:03:33,620 --> 00:03:37,310
not possible to get your best work

61
00:03:35,990 --> 00:03:41,270
unless you're living your best life

62
00:03:37,310 --> 00:03:42,800
which doesn't involve you know peeing

63
00:03:41,270 --> 00:03:43,880
into a cup at 4:00 in the morning as

64
00:03:42,800 --> 00:03:45,020
you're trying to reboot a bunch of

65
00:03:43,880 --> 00:03:47,980
servers or something like that because

66
00:03:45,020 --> 00:03:47,980
you can't get away from your monitor

67
00:03:49,210 --> 00:03:56,330
before New Relic I was at Intel for 10

68
00:03:52,760 --> 00:03:57,500
years and was the cloud security person

69
00:03:56,330 --> 00:03:59,420
there for a while did some IT security

70
00:03:57,500 --> 00:04:01,520
work there as part of the risk

71
00:03:59,420 --> 00:04:04,369
management program learned a lot of

72
00:04:01,520 --> 00:04:05,750
stuff there and before that I ran a

73
00:04:04,370 --> 00:04:07,250
security operations center for the US

74
00:04:05,750 --> 00:04:10,760
Army Corps of Engineers based here at a

75
00:04:07,250 --> 00:04:14,060
Portland that was a very very

76
00:04:10,760 --> 00:04:15,560
interesting time I was there for a good

77
00:04:14,060 --> 00:04:20,630
number of years probably about 15 and

78
00:04:15,560 --> 00:04:23,630
with a quick stint doing start-up stuff

79
00:04:20,630 --> 00:04:26,120
during the dot-com bubble days I worked

80
00:04:23,630 --> 00:04:28,680
for a company called web man how many of

81
00:04:26,120 --> 00:04:33,240
you have heard web man

82
00:04:28,680 --> 00:04:33,240
I've got some swag later on maybe so

83
00:04:34,500 --> 00:04:40,569
definitely not the expired stock

84
00:04:37,150 --> 00:04:42,669
certificates that are worth like 0.003

85
00:04:40,569 --> 00:04:44,349
cents or something like that so but

86
00:04:42,669 --> 00:04:47,590
there was the biggest dot-com failure it

87
00:04:44,349 --> 00:04:49,389
was an incredible experience there we

88
00:04:47,590 --> 00:04:50,530
built a lot of stuff out really fast it

89
00:04:49,389 --> 00:04:54,219
was the first company that was really

90
00:04:50,530 --> 00:04:57,340
really focused on doing online food

91
00:04:54,219 --> 00:04:58,840
grocery deliveries and it was started by

92
00:04:57,340 --> 00:05:00,128
John borders of borders books of music

93
00:04:58,840 --> 00:05:03,460
so a lot of people thought it was pretty

94
00:05:00,129 --> 00:05:07,120
good bet but it kind of died under the

95
00:05:03,460 --> 00:05:10,448
weight of real estate and I turned off

96
00:05:07,120 --> 00:05:15,099
the lights there basically so I got my

97
00:05:10,449 --> 00:05:16,210
start doing linguistics in college I was

98
00:05:15,099 --> 00:05:17,710
just thinking about the keynote this

99
00:05:16,210 --> 00:05:19,599
morning and how wonderful that talk was

100
00:05:17,710 --> 00:05:24,789
and how a lot of the people that I know

101
00:05:19,599 --> 00:05:27,009
have come up in the ranks by not through

102
00:05:24,789 --> 00:05:28,779
traditional means and I'm a big big

103
00:05:27,009 --> 00:05:30,969
proponent of that stuff and I think she

104
00:05:28,779 --> 00:05:32,379
really helped to clarify some things

105
00:05:30,969 --> 00:05:34,180
that I really believe strongly about

106
00:05:32,379 --> 00:05:36,969
I've generally referred to it as

107
00:05:34,180 --> 00:05:40,029
aptitude like this desire the knowledge

108
00:05:36,969 --> 00:05:42,219
the desire to get knowledge the desire

109
00:05:40,029 --> 00:05:46,089
to figure stuff out not leave stuff

110
00:05:42,219 --> 00:05:48,460
alone because you know it's it's it's a

111
00:05:46,089 --> 00:05:51,310
challenge it's a puzzle but I really

112
00:05:48,460 --> 00:05:53,169
really like the way that she couched a

113
00:05:51,310 --> 00:05:54,699
lot of those concepts and specific items

114
00:05:53,169 --> 00:05:56,650
around what those things are and the

115
00:05:54,699 --> 00:05:57,940
examples that she gave if you didn't

116
00:05:56,650 --> 00:06:02,620
catch the keynote I'm pretty sure it'll

117
00:05:57,940 --> 00:06:05,080
be a recording of it so so my talk is

118
00:06:02,620 --> 00:06:09,339
about how metaphors we use in security

119
00:06:05,080 --> 00:06:11,139
culture specifically about how a change

120
00:06:09,339 --> 00:06:13,169
in these metaphors that we as security

121
00:06:11,139 --> 00:06:15,879
practice or practitioners commonly used

122
00:06:13,169 --> 00:06:18,339
to frame our approach to information

123
00:06:15,879 --> 00:06:21,279
security can result in changes about

124
00:06:18,339 --> 00:06:23,169
what we can accomplish and this talk is

125
00:06:21,279 --> 00:06:25,479
definitely based on my my 20 whatever

126
00:06:23,169 --> 00:06:28,990
years of doing information security I

127
00:06:25,479 --> 00:06:31,659
think we've been doing things really

128
00:06:28,990 --> 00:06:33,190
poorly but there's a lot of things that

129
00:06:31,659 --> 00:06:34,889
happen well but there's a lot of stuff

130
00:06:33,190 --> 00:06:37,180
that doesn't happen very well at all and

131
00:06:34,889 --> 00:06:39,509
mostly we end up just making people feel

132
00:06:37,180 --> 00:06:39,509
shitty

133
00:06:40,169 --> 00:06:44,789
I think we need to change all that and

134
00:06:42,960 --> 00:06:46,438
this change needs to happen in the

135
00:06:44,789 --> 00:06:48,120
security industry and perhaps in the

136
00:06:46,439 --> 00:06:49,020
tech culture in general and I think

137
00:06:48,120 --> 00:06:51,900
we're starting to see some of those

138
00:06:49,020 --> 00:06:54,659
changes occur we need to change how we

139
00:06:51,900 --> 00:06:56,818
connect to our work to the organizations

140
00:06:54,659 --> 00:06:59,699
we work for and to the people we're

141
00:06:56,819 --> 00:07:00,539
trying to help and the change that

142
00:06:59,699 --> 00:07:04,439
changed the way we use our knowledge

143
00:07:00,539 --> 00:07:06,779
values skills and tools to address the

144
00:07:04,439 --> 00:07:09,990
risks and dangers that keep people from

145
00:07:06,779 --> 00:07:11,580
being both safe and successful in their

146
00:07:09,990 --> 00:07:14,490
work and their business in their lives

147
00:07:11,580 --> 00:07:16,198
and changes that sustain a culture that

148
00:07:14,490 --> 00:07:17,699
helps people do the things that are

149
00:07:16,199 --> 00:07:19,740
important to them instead of having a

150
00:07:17,699 --> 00:07:22,219
culture that penalizes and shames them

151
00:07:19,740 --> 00:07:22,219
into compliance

152
00:07:22,460 --> 00:07:27,508
in my experience InfoSec really isn't

153
00:07:25,259 --> 00:07:29,909
seen as an enabler and it's not very

154
00:07:27,509 --> 00:07:33,029
connected to the business or to what

155
00:07:29,909 --> 00:07:35,479
people are doing the way they're trying

156
00:07:33,029 --> 00:07:37,650
to work the things they're working on

157
00:07:35,479 --> 00:07:40,378
security teams are often described as

158
00:07:37,650 --> 00:07:43,409
obstacles hard to work with adversarial

159
00:07:40,379 --> 00:07:45,860
dogmatic they work in a culture that's

160
00:07:43,409 --> 00:07:48,680
often cold secretive and paranoid

161
00:07:45,860 --> 00:07:50,969
culture that I think is unsustainable I

162
00:07:48,680 --> 00:07:52,710
think there's a lot of us working to

163
00:07:50,969 --> 00:07:55,649
bring the importance of connection to

164
00:07:52,710 --> 00:07:57,989
our industry as some of the talks that

165
00:07:55,649 --> 00:08:03,449
we've already heard today pointed out

166
00:07:57,990 --> 00:08:04,800
and being doing a better job of

167
00:08:03,449 --> 00:08:07,319
addressing the challenges that are

168
00:08:04,800 --> 00:08:09,599
relevant to enabling our own and the

169
00:08:07,319 --> 00:08:11,279
success of the companies we work for and

170
00:08:09,599 --> 00:08:13,319
hopefully to sustain to sustain a

171
00:08:11,279 --> 00:08:14,430
culture that truly protects people

172
00:08:13,319 --> 00:08:17,879
safely and do the things that are

173
00:08:14,430 --> 00:08:21,120
important to them many security

174
00:08:17,879 --> 00:08:22,469
departments practice a culture that

175
00:08:21,120 --> 00:08:26,759
could be described using the metaphor

176
00:08:22,469 --> 00:08:28,339
information security as warfare I posit

177
00:08:26,759 --> 00:08:31,620
that that's actually a big reason why

178
00:08:28,339 --> 00:08:33,269
things are going so poorly and why

179
00:08:31,620 --> 00:08:35,429
security teams are often seen negatively

180
00:08:33,269 --> 00:08:38,459
and people run away or say things like

181
00:08:35,429 --> 00:08:40,799
oh gosh I hope I never see you when they

182
00:08:38,458 --> 00:08:42,000
walk through pasture area during their

183
00:08:40,799 --> 00:08:45,389
first day in the office

184
00:08:42,000 --> 00:08:46,410
and I also think that's one of the

185
00:08:45,389 --> 00:08:51,329
reasons why the industry so

186
00:08:46,410 --> 00:08:54,130
self-defeating teams are seen as

187
00:08:51,329 --> 00:08:56,370
adversarial rigid and

188
00:08:54,130 --> 00:08:59,350
so I offer a different metaphor

189
00:08:56,370 --> 00:09:00,940
information securities nurturance which

190
00:08:59,350 --> 00:09:03,100
I believe leads to more successful

191
00:09:00,940 --> 00:09:04,450
outcomes and to doing things in ways

192
00:09:03,100 --> 00:09:09,190
that are probably even more

193
00:09:04,450 --> 00:09:12,190
comprehensive and take can't take

194
00:09:09,190 --> 00:09:16,210
advantage of more of what people have to

195
00:09:12,190 --> 00:09:18,580
offer and what people can do before we

196
00:09:16,210 --> 00:09:21,820
get to nurturance let's talk about

197
00:09:18,580 --> 00:09:24,040
metaphors why do I believe metaphors are

198
00:09:21,820 --> 00:09:25,330
so important before I came into my

199
00:09:24,040 --> 00:09:27,849
career in information security

200
00:09:25,330 --> 00:09:29,830
I studied cognitive linguistics here at

201
00:09:27,850 --> 00:09:31,720
Reed College and some of that work

202
00:09:29,830 --> 00:09:34,000
involved how language its structure and

203
00:09:31,720 --> 00:09:36,850
use influenced our conceptualization of

204
00:09:34,000 --> 00:09:39,190
the world some of you may have heard or

205
00:09:36,850 --> 00:09:40,839
read a book by George Lakoff and Mark

206
00:09:39,190 --> 00:09:42,750
Johnson called metaphors we live by it's

207
00:09:40,839 --> 00:09:46,029
a fantastic read it's pretty quick and

208
00:09:42,750 --> 00:09:47,740
it's got some age behind it now so I

209
00:09:46,029 --> 00:09:49,510
think in the 80s and George Lakoff has

210
00:09:47,740 --> 00:09:51,850
since gone on to do a bunch of writing

211
00:09:49,510 --> 00:09:55,180
based on this work in political

212
00:09:51,850 --> 00:09:57,339
discourse he's written extensively over

213
00:09:55,180 --> 00:09:58,709
the last 25 years about metaphors and

214
00:09:57,339 --> 00:10:01,680
the influence they have on everyday life

215
00:09:58,710 --> 00:10:04,480
this book explores how everyday language

216
00:10:01,680 --> 00:10:06,130
is filled with conceptual metaphors that

217
00:10:04,480 --> 00:10:07,780
we often don't even notice we're using

218
00:10:06,130 --> 00:10:09,700
we can't avoid using metaphor

219
00:10:07,780 --> 00:10:12,760
metaphorical ideas in both our language

220
00:10:09,700 --> 00:10:14,410
and thinking it is deeply ingrained a

221
00:10:12,760 --> 00:10:17,740
deeply ingrained part of how we

222
00:10:14,410 --> 00:10:19,300
communicate conceptual metaphors help

223
00:10:17,740 --> 00:10:22,810
our understanding and experience of one

224
00:10:19,300 --> 00:10:24,160
idea or domain in terms of another so we

225
00:10:22,810 --> 00:10:25,869
not only borrow words from one domain

226
00:10:24,160 --> 00:10:28,209
and apply it to the other we often bring

227
00:10:25,870 --> 00:10:30,240
the attitudes and the ideals both

228
00:10:28,210 --> 00:10:33,280
positive and negative along with them

229
00:10:30,240 --> 00:10:35,620
metaphors frame how we think communicate

230
00:10:33,280 --> 00:10:39,250
learn discover and understand ourselves

231
00:10:35,620 --> 00:10:42,070
on each other so the metaphors we use

232
00:10:39,250 --> 00:10:43,839
consciously and subconsciously or

233
00:10:42,070 --> 00:10:46,630
unconsciously drive culture and

234
00:10:43,839 --> 00:10:50,680
practices arising from that culture and

235
00:10:46,630 --> 00:10:54,100
in short metaphors influence culture and

236
00:10:50,680 --> 00:10:59,099
culture defines practice so let's take a

237
00:10:54,100 --> 00:10:59,100
used metaphor like time is money

238
00:10:59,490 --> 00:11:05,050
we often say things like don't waste my

239
00:11:02,440 --> 00:11:07,300
time or I've invested a lot of time in

240
00:11:05,050 --> 00:11:09,130
this project we spent a lot of time fake

241
00:11:07,300 --> 00:11:12,609
seeing security bugs so why do I want to

242
00:11:09,130 --> 00:11:14,140
do more we tend to value saving money so

243
00:11:12,610 --> 00:11:15,940
we tend to be pretty stingy with our

244
00:11:14,140 --> 00:11:17,470
time and that has an impact on how we

245
00:11:15,940 --> 00:11:21,730
behave with respect to ideas like

246
00:11:17,470 --> 00:11:25,510
downtime and rest self-care as versus

247
00:11:21,730 --> 00:11:27,250
work like work-life balance quality time

248
00:11:25,510 --> 00:11:28,959
I have a hard time feeling good about

249
00:11:27,250 --> 00:11:31,420
downtime and it's something I've been

250
00:11:28,959 --> 00:11:32,939
striving to fix in myself many of us

251
00:11:31,420 --> 00:11:35,199
find it hard not to do work from home

252
00:11:32,940 --> 00:11:37,240
even when we encourage people not to do

253
00:11:35,200 --> 00:11:39,880
so and we end up in a culture that

254
00:11:37,240 --> 00:11:43,240
prioritizes productivity and profit over

255
00:11:39,880 --> 00:11:45,370
self-care and rest and so now back to

256
00:11:43,240 --> 00:11:47,980
information security the goal of

257
00:11:45,370 --> 00:11:49,480
information security as you all know is

258
00:11:47,980 --> 00:11:52,269
to protect an organization's systems

259
00:11:49,480 --> 00:11:54,730
software and data but most of all to

260
00:11:52,269 --> 00:11:56,380
protect the business and the people

261
00:11:54,730 --> 00:11:59,560
involved with it and the goals of the

262
00:11:56,380 --> 00:12:02,050
business I think that's an important

263
00:11:59,560 --> 00:12:03,250
point that's often lost on people doing

264
00:12:02,050 --> 00:12:05,170
the work of information security is

265
00:12:03,250 --> 00:12:07,269
obviously really challenging I mean

266
00:12:05,170 --> 00:12:10,839
there's a lot of people here who want to

267
00:12:07,269 --> 00:12:12,430
learn how to do it better and business

268
00:12:10,839 --> 00:12:14,560
wants to move fast and technology

269
00:12:12,430 --> 00:12:16,329
constantly evolves and changes so it's

270
00:12:14,560 --> 00:12:18,279
not enough to just learn one aspect of

271
00:12:16,329 --> 00:12:20,410
security and and call it good you

272
00:12:18,279 --> 00:12:22,450
actually have to be learning things all

273
00:12:20,410 --> 00:12:24,010
the time the scale and speed of

274
00:12:22,450 --> 00:12:25,750
development leaves little time to check

275
00:12:24,010 --> 00:12:28,209
every configuration of file access

276
00:12:25,750 --> 00:12:32,950
listen default password and bit of

277
00:12:28,209 --> 00:12:36,819
insecure code software code hardware age

278
00:12:32,950 --> 00:12:39,760
and gain technical debt which I know

279
00:12:36,820 --> 00:12:41,470
probably a lot of you have similar

280
00:12:39,760 --> 00:12:43,209
experience to me like technical debt is

281
00:12:41,470 --> 00:12:45,820
one of the worst security issues that's

282
00:12:43,209 --> 00:12:48,520
out there that's hard to solve and some

283
00:12:45,820 --> 00:12:51,790
of this debt requires a lot of toil like

284
00:12:48,520 --> 00:12:53,290
security patching and reboots and

285
00:12:51,790 --> 00:12:56,079
there's a lot of examples of how

286
00:12:53,290 --> 00:12:58,420
companies fail to to meet their goals to

287
00:12:56,079 --> 00:13:00,130
secure and protect the company just

288
00:12:58,420 --> 00:13:03,670
everyday in the news there's more

289
00:13:00,130 --> 00:13:06,430
incidents more breaches malware

290
00:13:03,670 --> 00:13:08,800
infections more deployments of Windows

291
00:13:06,430 --> 00:13:13,359
and breaches are routinely reported in

292
00:13:08,800 --> 00:13:15,339
news in my role now as a director I'm

293
00:13:13,360 --> 00:13:17,199
spending a lot more time talking to like

294
00:13:15,339 --> 00:13:18,930
other companies General Counsel's and

295
00:13:17,199 --> 00:13:22,140
that kind of stuff and

296
00:13:18,930 --> 00:13:23,849
it's it's incredible it's incredible the

297
00:13:22,140 --> 00:13:25,800
questions that come from people when

298
00:13:23,850 --> 00:13:27,720
they suspect something is wrong and so

299
00:13:25,800 --> 00:13:29,609
and I think that's the thing like

300
00:13:27,720 --> 00:13:30,779
there's always something wrong and so

301
00:13:29,610 --> 00:13:33,330
while in for the SEC teams try to

302
00:13:30,779 --> 00:13:35,910
educate review scan and monitor and do

303
00:13:33,330 --> 00:13:38,430
all the work of risk management from the

304
00:13:35,910 --> 00:13:41,040
trenches every day as we watch defenses

305
00:13:38,430 --> 00:13:42,859
are breached credentials are stolen data

306
00:13:41,040 --> 00:13:44,969
is leaked and businesses are compromised

307
00:13:42,860 --> 00:13:46,290
and while there are other metaphors that

308
00:13:44,970 --> 00:13:48,180
can be used to describe information

309
00:13:46,290 --> 00:13:50,550
security such as hygiene or health care

310
00:13:48,180 --> 00:13:52,140
our firefighting a some there's actually

311
00:13:50,550 --> 00:13:54,420
an interesting paper by NIST done about

312
00:13:52,140 --> 00:13:56,250
ten years ago that actually I found

313
00:13:54,420 --> 00:13:58,439
after putting this talk together that

314
00:13:56,250 --> 00:14:02,940
goes over different metaphors that are

315
00:13:58,440 --> 00:14:05,790
used in security specifically the

316
00:14:02,940 --> 00:14:08,010
paradigm represented by information

317
00:14:05,790 --> 00:14:10,079
security as warfare seems to dominate

318
00:14:08,010 --> 00:14:11,970
the industry and when we frame

319
00:14:10,080 --> 00:14:13,890
information security by borrowing the

320
00:14:11,970 --> 00:14:16,740
words of warfare the attitudes and ideas

321
00:14:13,890 --> 00:14:18,420
that come with them create and

322
00:14:16,740 --> 00:14:23,550
perpetuate practices that make it even

323
00:14:18,420 --> 00:14:25,260
more challenging to meet our goals if

324
00:14:23,550 --> 00:14:28,020
information security is warfare we're

325
00:14:25,260 --> 00:14:29,790
not winning and I would argue that it's

326
00:14:28,020 --> 00:14:31,709
not something you can win it's not about

327
00:14:29,790 --> 00:14:34,079
winning we see it as metaphors influence

328
00:14:31,709 --> 00:14:36,689
in the language of our practices we talk

329
00:14:34,080 --> 00:14:38,640
about deep militarized zones Bastion

330
00:14:36,690 --> 00:14:40,500
servers we practice defense and death we

331
00:14:38,640 --> 00:14:44,310
collect and monitor intelligence streams

332
00:14:40,500 --> 00:14:46,920
we do intrusion monitoring protect

333
00:14:44,310 --> 00:14:50,910
against dos attacks we worry about

334
00:14:46,920 --> 00:14:52,229
spyware and can we detect that command

335
00:14:50,910 --> 00:14:54,420
and control channel that's controlling

336
00:14:52,230 --> 00:14:56,580
the botnet that's you know doing who

337
00:14:54,420 --> 00:15:00,810
knows what to our finance systems we

338
00:14:56,580 --> 00:15:02,790
worried about we worried about advanced

339
00:15:00,810 --> 00:15:05,010
persistent threats I was trying to hold

340
00:15:02,790 --> 00:15:07,829
myself not making a joke about advanced

341
00:15:05,010 --> 00:15:09,510
apt threats we work on threat models and

342
00:15:07,830 --> 00:15:11,580
attack simulations we secure the

343
00:15:09,510 --> 00:15:13,980
perimeter we do red teaming and we

344
00:15:11,580 --> 00:15:16,500
explore kill chains even casual

345
00:15:13,980 --> 00:15:18,360
reporting on information security uses

346
00:15:16,500 --> 00:15:20,339
terms like cyber war in their headlines

347
00:15:18,360 --> 00:15:23,640
to fluff stuff up and many security

348
00:15:20,339 --> 00:15:25,410
vendors use their use the fear of losing

349
00:15:23,640 --> 00:15:28,110
the war as a reason to give them lots of

350
00:15:25,410 --> 00:15:30,600
money a culture of warfare is one of

351
00:15:28,110 --> 00:15:32,040
secrecy adversaries and it drives the

352
00:15:30,600 --> 00:15:34,500
need for urgent action

353
00:15:32,040 --> 00:15:35,670
against enemies adversarial thinking

354
00:15:34,500 --> 00:15:38,089
leads to treating everyone as a

355
00:15:35,670 --> 00:15:43,019
potential enemy locked in a conflict

356
00:15:38,089 --> 00:15:44,730
that needs to be won and that's a kind

357
00:15:43,019 --> 00:15:48,930
of zero-sum thinking that leads to

358
00:15:44,730 --> 00:15:50,490
security becoming a means to an end it

359
00:15:48,930 --> 00:15:51,959
perpetuates the idea that security not

360
00:15:50,490 --> 00:15:54,029
something that everyone everyone needs

361
00:15:51,959 --> 00:15:57,149
to practice but something that's left to

362
00:15:54,029 --> 00:15:59,370
cyber warriors cyber ninjas that can

363
00:15:57,149 --> 00:16:03,870
deploy expensive security tools and come

364
00:15:59,370 --> 00:16:05,430
out on top all of this became apparent

365
00:16:03,870 --> 00:16:07,199
to me one day when I heard a fellow

366
00:16:05,430 --> 00:16:09,599
security professional exclaim exclaiming

367
00:16:07,199 --> 00:16:11,250
only we didn't have to deal with stupid

368
00:16:09,600 --> 00:16:15,240
users we wouldn't have to put in so many

369
00:16:11,250 --> 00:16:16,680
controls I've also heard things like if

370
00:16:15,240 --> 00:16:19,350
only people didn't click on links we

371
00:16:16,680 --> 00:16:21,569
would be safe if we're setting ourselves

372
00:16:19,350 --> 00:16:23,490
up to fight against basic human

373
00:16:21,569 --> 00:16:25,529
curiosity we're picking the losing side

374
00:16:23,490 --> 00:16:27,750
right from the start if we're focused

375
00:16:25,529 --> 00:16:29,670
entirely on blocking intercepting and

376
00:16:27,750 --> 00:16:31,350
negating behavior that is critical to so

377
00:16:29,670 --> 00:16:33,630
much of the work that people do today we

378
00:16:31,350 --> 00:16:35,519
situate ourselves as an obstacle and not

379
00:16:33,630 --> 00:16:37,889
as a resource and it's fair to say that

380
00:16:35,519 --> 00:16:41,760
clicking on links is critical to much of

381
00:16:37,889 --> 00:16:43,829
the work that people do online today and

382
00:16:41,760 --> 00:16:44,970
not to mention how many quotes I've seen

383
00:16:43,829 --> 00:16:47,069
from Sun Tzu's Art of War

384
00:16:44,970 --> 00:16:49,260
at hacker conferences where we often see

385
00:16:47,069 --> 00:16:50,969
dudes dressed in camos and tactical

386
00:16:49,260 --> 00:16:53,310
vests and other aspects of everyday

387
00:16:50,970 --> 00:16:55,500
carry but this isn't the world that I

388
00:16:53,310 --> 00:16:56,729
want to live in and I don't think we're

389
00:16:55,500 --> 00:17:00,029
going to make a difference if we

390
00:16:56,730 --> 00:17:02,250
continue to think this way and I'm

391
00:17:00,029 --> 00:17:04,530
thankful to say that I think a lot of us

392
00:17:02,250 --> 00:17:06,689
are thinking this way as well we're

393
00:17:04,530 --> 00:17:08,339
trying to change stuff I would rather

394
00:17:06,689 --> 00:17:08,990
take care of people and the things they

395
00:17:08,339 --> 00:17:11,549
care about

396
00:17:08,990 --> 00:17:13,679
using a different metaphor we changed

397
00:17:11,549 --> 00:17:14,908
the rules for how we do our work by

398
00:17:13,679 --> 00:17:17,510
framing things with a focus on what's

399
00:17:14,909 --> 00:17:19,919
important the activities of people value

400
00:17:17,510 --> 00:17:21,510
like the things people do to build a

401
00:17:19,919 --> 00:17:24,659
successful company or grow an

402
00:17:21,510 --> 00:17:25,500
organization or build a business and

403
00:17:24,659 --> 00:17:27,059
this is why I think the metaphor

404
00:17:25,500 --> 00:17:28,710
information security is inert trance is

405
00:17:27,059 --> 00:17:31,200
important it also describes how New

406
00:17:28,710 --> 00:17:32,340
Relic security approaches its work and

407
00:17:31,200 --> 00:17:34,799
it's largely the reason why I came to

408
00:17:32,340 --> 00:17:38,309
work there I'm a father of a 14 year old

409
00:17:34,799 --> 00:17:39,418
girl is my daughter Ella she just got

410
00:17:38,309 --> 00:17:40,530
her braces off she's pretty happy about

411
00:17:39,419 --> 00:17:43,410
that

412
00:17:40,530 --> 00:17:44,910
I want to protect her right what father

413
00:17:43,410 --> 00:17:47,250
doesn't want you but I don't think the

414
00:17:44,910 --> 00:17:49,410
best way to do this is to make war with

415
00:17:47,250 --> 00:17:50,160
the rest of the world to sit on a porch

416
00:17:49,410 --> 00:17:52,410
with a shotgun

417
00:17:50,160 --> 00:17:54,330
I would rather help her learn the skills

418
00:17:52,410 --> 00:17:56,940
knowledge and confidence to grow in the

419
00:17:54,330 --> 00:17:58,080
safest way possible and as any parent

420
00:17:56,940 --> 00:18:01,140
can tell you this requires a lot of

421
00:17:58,080 --> 00:18:02,460
letting go of the need to win battles to

422
00:18:01,140 --> 00:18:05,160
meet those goals I need to be connected

423
00:18:02,460 --> 00:18:07,050
with my daughter spend time with her so

424
00:18:05,160 --> 00:18:08,370
that when I so that I can leverage my

425
00:18:07,050 --> 00:18:10,800
experience and knowledge to provide her

426
00:18:08,370 --> 00:18:12,030
guidance and I can speak to her interest

427
00:18:10,800 --> 00:18:14,730
in the things that she wants to do and

428
00:18:12,030 --> 00:18:16,170
what she values with the long-term goal

429
00:18:14,730 --> 00:18:17,970
of empowering her to build healthy

430
00:18:16,170 --> 00:18:20,490
patterns of both dependent independence

431
00:18:17,970 --> 00:18:22,410
and interdependence hopefully she'll

432
00:18:20,490 --> 00:18:24,750
develop fluency and being responsible

433
00:18:22,410 --> 00:18:28,500
and practicing accountability both for

434
00:18:24,750 --> 00:18:30,090
herself and for others as she grows so

435
00:18:28,500 --> 00:18:31,920
what is nurturance and how do we

436
00:18:30,090 --> 00:18:34,169
practice it in information security a

437
00:18:31,920 --> 00:18:36,000
standard definition of nurturance is

438
00:18:34,170 --> 00:18:38,910
attention to nourishment protection and

439
00:18:36,000 --> 00:18:40,200
guidance to maturity nurture a

440
00:18:38,910 --> 00:18:42,960
nurturance culture is a culture of

441
00:18:40,200 --> 00:18:45,360
connection communication mutual support

442
00:18:42,960 --> 00:18:47,100
care it's an active demonstration of

443
00:18:45,360 --> 00:18:50,639
being aware of what people want to do

444
00:18:47,100 --> 00:18:51,899
and accomplish be that my daughter or an

445
00:18:50,640 --> 00:18:54,750
engineering team that's trying to do

446
00:18:51,900 --> 00:18:57,000
some deployments or a customer now what

447
00:18:54,750 --> 00:18:58,710
does it look like for us a New Relic as

448
00:18:57,000 --> 00:19:00,780
a culture and as a practice what things

449
00:18:58,710 --> 00:19:04,410
do we do to build this out what does it

450
00:19:00,780 --> 00:19:06,060
look like there's three themes that I'm

451
00:19:04,410 --> 00:19:08,580
going to focus on in talking about this

452
00:19:06,060 --> 00:19:11,010
stuff we do this by focusing on what's

453
00:19:08,580 --> 00:19:14,610
really important not not on the controls

454
00:19:11,010 --> 00:19:17,280
we're deploying or you know our KPIs or

455
00:19:14,610 --> 00:19:19,290
any of that kind of stuff we focus on

456
00:19:17,280 --> 00:19:20,370
the things that people want to do when

457
00:19:19,290 --> 00:19:21,720
people come to join the New York

458
00:19:20,370 --> 00:19:23,760
security team the first thing I tell

459
00:19:21,720 --> 00:19:27,210
them is your first job is relationship

460
00:19:23,760 --> 00:19:28,710
management so the focus isn't

461
00:19:27,210 --> 00:19:30,420
necessarily on the data itself or the

462
00:19:28,710 --> 00:19:33,750
systems the controls we used to secure

463
00:19:30,420 --> 00:19:36,720
them but the goals that people in an

464
00:19:33,750 --> 00:19:37,740
organization find valuable and so we

465
00:19:36,720 --> 00:19:39,900
provide nurturance through our

466
00:19:37,740 --> 00:19:41,250
interactions and demonstrate active

467
00:19:39,900 --> 00:19:44,190
support of what the teams are trying to

468
00:19:41,250 --> 00:19:46,110
do so it's a quality in the way of the

469
00:19:44,190 --> 00:19:47,730
way in which InfoSec information

470
00:19:46,110 --> 00:19:49,800
security can engage with others and

471
00:19:47,730 --> 00:19:51,450
respond to the needs of the business so

472
00:19:49,800 --> 00:19:54,299
we do this through communication

473
00:19:51,450 --> 00:19:56,759
connection and accountability

474
00:19:54,299 --> 00:20:01,529
which in turn allows us to inform and

475
00:19:56,759 --> 00:20:03,299
empower and trust and build trust so we

476
00:20:01,529 --> 00:20:06,379
inform through communication we

477
00:20:03,299 --> 00:20:08,519
communicate things like context matrix

478
00:20:06,379 --> 00:20:11,968
dashboards and any data that's relevant

479
00:20:08,519 --> 00:20:13,589
to allowing folks to understand what

480
00:20:11,969 --> 00:20:15,929
information security risks are affecting

481
00:20:13,589 --> 00:20:17,299
them and their projects we do the work

482
00:20:15,929 --> 00:20:19,649
to understand what the teams are doing

483
00:20:17,299 --> 00:20:20,700
and what's important to them because we

484
00:20:19,649 --> 00:20:22,859
want to provide useful information

485
00:20:20,700 --> 00:20:26,249
relevant information and data to those

486
00:20:22,859 --> 00:20:30,570
teams to help show them the context of

487
00:20:26,249 --> 00:20:32,399
what their what might endanger them so

488
00:20:30,570 --> 00:20:33,450
we have a slack bot that automatically

489
00:20:32,399 --> 00:20:35,158
tells people about security

490
00:20:33,450 --> 00:20:37,229
vulnerabilities and teams so it'll just

491
00:20:35,159 --> 00:20:38,639
automatically do that for us so we

492
00:20:37,229 --> 00:20:41,429
leverage a lot of automation for that

493
00:20:38,639 --> 00:20:44,928
our security folks often walk over to

494
00:20:41,429 --> 00:20:47,369
teams to sit down and talk with them to

495
00:20:44,929 --> 00:20:48,839
see hey what's up with that team what

496
00:20:47,369 --> 00:20:50,189
are they doing but also to talk to them

497
00:20:48,839 --> 00:20:52,019
about any sort of issues that are

498
00:20:50,190 --> 00:20:55,259
ongoing or maybe in the pipe coming down

499
00:20:52,019 --> 00:20:57,779
the line or to help them plan out

500
00:20:55,259 --> 00:20:58,950
security features or upgrades in their

501
00:20:57,779 --> 00:21:03,719
products or the services or the

502
00:20:58,950 --> 00:21:09,359
deployments recently we also do a lot of

503
00:21:03,719 --> 00:21:12,329
transparency so we we tend to hold lots

504
00:21:09,359 --> 00:21:15,928
of not as many demos as I'd like but we

505
00:21:12,329 --> 00:21:17,579
do demos for our teams we tend to talk

506
00:21:15,929 --> 00:21:20,309
very openly about vulnerabilities that

507
00:21:17,579 --> 00:21:21,779
we find we don't we don't secret them we

508
00:21:20,309 --> 00:21:23,219
don't treat them as a need-to-know we

509
00:21:21,779 --> 00:21:25,799
actually try to demonstrate how they

510
00:21:23,219 --> 00:21:28,440
work and we try to encourage teams to to

511
00:21:25,799 --> 00:21:29,879
exploit them themselves because we find

512
00:21:28,440 --> 00:21:33,379
that the more knowledge we give folks

513
00:21:29,879 --> 00:21:35,968
the more understanding that they have

514
00:21:33,379 --> 00:21:40,468
when we do attack simulations or pen

515
00:21:35,969 --> 00:21:42,779
tests or when we have deep pen tests

516
00:21:40,469 --> 00:21:44,309
that are done by third parties we take

517
00:21:42,779 --> 00:21:45,869
the results and obviously we address

518
00:21:44,309 --> 00:21:48,299
those issues but then we turn around and

519
00:21:45,869 --> 00:21:51,149
we do a pretty lengthy demonstration or

520
00:21:48,299 --> 00:21:52,469
talk on those results so it's not we

521
00:21:51,149 --> 00:21:55,949
don't we don't hide stuff which is

522
00:21:52,469 --> 00:21:57,359
really important to us so we connect we

523
00:21:55,950 --> 00:22:00,029
communicate with things like context

524
00:21:57,359 --> 00:22:05,549
information data through dashboards as

525
00:22:00,029 --> 00:22:07,680
well and this helps us really learn what

526
00:22:05,549 --> 00:22:11,250
they do so that we can understand the

527
00:22:07,680 --> 00:22:13,560
what they do let's see what else was

528
00:22:11,250 --> 00:22:14,970
gonna mention I think so this is an

529
00:22:13,560 --> 00:22:19,050
example of some of the dashboards we see

530
00:22:14,970 --> 00:22:20,670
hopefully I did something - office gate

531
00:22:19,050 --> 00:22:21,180
things but there's some names I didn't

532
00:22:20,670 --> 00:22:24,000
oh well

533
00:22:21,180 --> 00:22:25,530
so who so we explained things like when

534
00:22:24,000 --> 00:22:26,820
do our security scans run we actually

535
00:22:25,530 --> 00:22:28,740
have dashboards that are open to

536
00:22:26,820 --> 00:22:30,840
everybody saying hey you think someone

537
00:22:28,740 --> 00:22:31,860
something is attacking your stuff you

538
00:22:30,840 --> 00:22:33,330
want to make sure it's not one of our

539
00:22:31,860 --> 00:22:34,740
scanners go to this dashboard take a

540
00:22:33,330 --> 00:22:36,929
look at it and it'll tell you when

541
00:22:34,740 --> 00:22:38,430
they're running how often and then we do

542
00:22:36,930 --> 00:22:39,600
a lot of explanation like here's all the

543
00:22:38,430 --> 00:22:42,090
IPS that are doing and we're pretty open

544
00:22:39,600 --> 00:22:44,070
about that stuff because we want people

545
00:22:42,090 --> 00:22:45,570
to know about that stuff because we want

546
00:22:44,070 --> 00:22:48,320
them to know when something is scanning

547
00:22:45,570 --> 00:22:51,270
them that isn't us and they can tell us

548
00:22:48,320 --> 00:22:52,860
so we we do a lot of metrics gathering

549
00:22:51,270 --> 00:22:55,500
and present and presenting that metrics

550
00:22:52,860 --> 00:22:56,669
to the people who are probably the ones

551
00:22:55,500 --> 00:22:59,240
who are going to understand the dangers

552
00:22:56,670 --> 00:23:04,050
to their stuff more than we are

553
00:22:59,240 --> 00:23:07,260
so by communicating and informing we

554
00:23:04,050 --> 00:23:09,510
empower and we build that connection

555
00:23:07,260 --> 00:23:10,770
just as we make it a priority to share

556
00:23:09,510 --> 00:23:12,930
what we see through presentations

557
00:23:10,770 --> 00:23:14,580
insights dashboards which is a product

558
00:23:12,930 --> 00:23:17,940
that we use in-house that our own

559
00:23:14,580 --> 00:23:20,460
product blog posts and other channels we

560
00:23:17,940 --> 00:23:22,110
we make it a point to connect with those

561
00:23:20,460 --> 00:23:25,590
teams and to build that connection even

562
00:23:22,110 --> 00:23:27,209
more deeply we host hackathons and we

563
00:23:25,590 --> 00:23:29,429
encourage people to get together with

564
00:23:27,210 --> 00:23:31,200
our teams and actually do kind of an

565
00:23:29,430 --> 00:23:32,910
informal pen test against things that

566
00:23:31,200 --> 00:23:35,760
they think might be worth pen testing in

567
00:23:32,910 --> 00:23:39,630
the company we hold on comps where we

568
00:23:35,760 --> 00:23:42,060
minh where we try to get people to give

569
00:23:39,630 --> 00:23:43,680
presentations the people who are not on

570
00:23:42,060 --> 00:23:45,149
the security to get presentations we had

571
00:23:43,680 --> 00:23:49,230
a pretty successful and recently at the

572
00:23:45,150 --> 00:23:52,680
Kennedy School and it was awesome to

573
00:23:49,230 --> 00:23:53,910
hear like the people not on the security

574
00:23:52,680 --> 00:23:55,500
team talked about all sorts of really

575
00:23:53,910 --> 00:23:57,300
great security topics that are

576
00:23:55,500 --> 00:23:59,370
interesting to them or about the stuff

577
00:23:57,300 --> 00:24:00,780
that they're working on and we find that

578
00:23:59,370 --> 00:24:01,939
encouraging that kind of work and

579
00:24:00,780 --> 00:24:06,260
encouraging that kind of connection

580
00:24:01,940 --> 00:24:06,260
strengths and strengthens this culture

581
00:24:11,600 --> 00:24:16,469
our security teams also spend time to

582
00:24:13,980 --> 00:24:18,240
explain why why we're asking them to do

583
00:24:16,470 --> 00:24:19,919
things rather than dictating what people

584
00:24:18,240 --> 00:24:23,669
should do so we focused on those desired

585
00:24:19,919 --> 00:24:28,649
outcomes and goals we do stuff like host

586
00:24:23,669 --> 00:24:32,100
this besides we also host and support

587
00:24:28,649 --> 00:24:34,199
things like RSA other conferences or or

588
00:24:32,100 --> 00:24:35,879
work that's going on in the community

589
00:24:34,200 --> 00:24:39,299
that is aligned with these goals that we

590
00:24:35,879 --> 00:24:41,340
have my experience with traditional

591
00:24:39,299 --> 00:24:44,580
security teams like those I've been on

592
00:24:41,340 --> 00:24:47,279
in the past mm-hmm apologies to people I

593
00:24:44,580 --> 00:24:49,110
used to work with at Intel is to hoard

594
00:24:47,279 --> 00:24:51,360
data in secret away the information they

595
00:24:49,110 --> 00:24:53,129
collect you know we have security

596
00:24:51,360 --> 00:24:54,658
operations center rooms that are filled

597
00:24:53,129 --> 00:24:56,340
with people in a dark little room with a

598
00:24:54,659 --> 00:24:57,539
bunch of monitors clicking like ignore

599
00:24:56,340 --> 00:25:00,178
ignore ignore

600
00:24:57,539 --> 00:25:02,990
and they only show up when they perceive

601
00:25:00,179 --> 00:25:02,990
that something has gone wrong

602
00:25:03,289 --> 00:25:12,710
so we communicate we connect and then we

603
00:25:08,789 --> 00:25:15,570
use that connection to empower and

604
00:25:12,710 --> 00:25:19,500
through that knowledge and through that

605
00:25:15,570 --> 00:25:22,139
work it allows people to practice

606
00:25:19,500 --> 00:25:23,850
accountability and so through this

607
00:25:22,139 --> 00:25:25,289
culture of transparency and the work we

608
00:25:23,850 --> 00:25:27,029
do with people were able to focus on the

609
00:25:25,289 --> 00:25:29,158
tangible and real technical risk to our

610
00:25:27,029 --> 00:25:30,809
business and getting people to

611
00:25:29,159 --> 00:25:34,559
understand that stuff and making it

612
00:25:30,809 --> 00:25:36,360
possible to for folks who want to be

613
00:25:34,559 --> 00:25:38,250
secure who want to know they want to do

614
00:25:36,360 --> 00:25:39,809
the right thing they just don't really

615
00:25:38,250 --> 00:25:41,970
know what it is they know about the

616
00:25:39,809 --> 00:25:44,220
dangers to their to their servers and

617
00:25:41,970 --> 00:25:47,940
their services but they need us to

618
00:25:44,220 --> 00:25:50,639
translate the technical issues into a

619
00:25:47,940 --> 00:25:52,110
relevant set of data that they can use

620
00:25:50,639 --> 00:25:54,090
to make decisions about what's actually

621
00:25:52,110 --> 00:25:55,918
happening as opposed to relying on a

622
00:25:54,090 --> 00:25:59,759
security team to make those decisions

623
00:25:55,919 --> 00:26:01,679
for them and that I think helps our

624
00:25:59,759 --> 00:26:03,990
security obligations to our customers

625
00:26:01,679 --> 00:26:06,480
and to each other and it allows people

626
00:26:03,990 --> 00:26:10,649
to hold accountability with themselves

627
00:26:06,480 --> 00:26:13,529
and with other teams as well and it

628
00:26:10,649 --> 00:26:16,350
allows us to better practice holding

629
00:26:13,529 --> 00:26:18,120
people to our s la's the results of our

630
00:26:16,350 --> 00:26:22,799
security reviews and the requirements we

631
00:26:18,120 --> 00:26:24,320
give them yeah so I think we're running

632
00:26:22,799 --> 00:26:28,879
out of time so I got to move fast

633
00:26:24,320 --> 00:26:30,559
I saw leis some more examples of how

634
00:26:28,880 --> 00:26:32,090
stuff that we we do we've got this

635
00:26:30,559 --> 00:26:35,600
project in-house called security karma

636
00:26:32,090 --> 00:26:40,309
that is a takes this output of a

637
00:26:35,600 --> 00:26:44,830
vulnerability scan and puts it into team

638
00:26:40,309 --> 00:26:47,809
focused dashboards that allow us to

639
00:26:44,830 --> 00:26:50,269
prioritize what we think the risk is to

640
00:26:47,809 --> 00:26:53,629
them and it allows them to prioritize

641
00:26:50,269 --> 00:26:55,759
their work as they move forward to to

642
00:26:53,630 --> 00:26:57,529
patch right as they go through their

643
00:26:55,759 --> 00:26:58,850
sprints and MMS it allows them to do a

644
00:26:57,529 --> 00:27:00,080
better job of understanding what

645
00:26:58,850 --> 00:27:04,490
security work they do and what the

646
00:27:00,080 --> 00:27:07,908
priority for that work is so the

647
00:27:04,490 --> 00:27:10,970
evidence that this culture works I'm

648
00:27:07,909 --> 00:27:13,009
still collecting the data I our security

649
00:27:10,970 --> 00:27:14,720
team is pretty young but I think some of

650
00:27:13,009 --> 00:27:16,279
the things that speak strongly is how

651
00:27:14,720 --> 00:27:18,679
strong the culture is at New Relic for

652
00:27:16,279 --> 00:27:19,879
security we have like I mentioned

653
00:27:18,679 --> 00:27:21,980
earlier that a first day in the office

654
00:27:19,879 --> 00:27:24,259
people will walk by and say oh I hope I

655
00:27:21,980 --> 00:27:25,850
never have to talk to you usually those

656
00:27:24,259 --> 00:27:28,429
folks come back a couple weeks later and

657
00:27:25,850 --> 00:27:30,379
say I love talking to you and we have

658
00:27:28,429 --> 00:27:32,990
people come by our desks area all the

659
00:27:30,379 --> 00:27:35,719
time about whatever issues or questions

660
00:27:32,990 --> 00:27:37,789
or projects they're working on and it's

661
00:27:35,720 --> 00:27:39,409
it's great people seek us out they don't

662
00:27:37,789 --> 00:27:41,990
run away from the security team which is

663
00:27:39,409 --> 00:27:44,360
fantastic so nurturance is a full life

664
00:27:41,990 --> 00:27:49,519
cycle process that continues and doesn't

665
00:27:44,360 --> 00:27:51,379
necessarily end with a win and I just

666
00:27:49,519 --> 00:27:54,470
want to repeat the things that we do or

667
00:27:51,379 --> 00:27:57,199
communicate connect and help people

668
00:27:54,470 --> 00:27:58,850
practice accountability and with that

669
00:27:57,200 --> 00:28:01,129
accountability it builds that trust so

670
00:27:58,850 --> 00:28:03,889
it's important to me I want the industry

671
00:28:01,129 --> 00:28:05,928
to change I wanted to align with the

672
00:28:03,889 --> 00:28:07,189
kind of world I want to live in this is

673
00:28:05,929 --> 00:28:08,899
the thing I want for my daughter who's

674
00:28:07,190 --> 00:28:10,399
sadly at 14 shows no interest of going

675
00:28:08,899 --> 00:28:13,789
into InfoSec but it is really good at

676
00:28:10,399 --> 00:28:15,139
fortnight I think setting an intention

677
00:28:13,789 --> 00:28:18,200
with our language and metaphors is

678
00:28:15,139 --> 00:28:20,629
necessary and I want people to feel like

679
00:28:18,200 --> 00:28:22,340
security is not an obstacle or that

680
00:28:20,629 --> 00:28:24,230
security practices this trench warfare

681
00:28:22,340 --> 00:28:26,178
but something that is deeply a part of

682
00:28:24,230 --> 00:28:28,220
the fabric of doing what we do to make

683
00:28:26,179 --> 00:28:32,510
great software products services and

684
00:28:28,220 --> 00:28:33,830
what not so my call to you is this talk

685
00:28:32,510 --> 00:28:35,299
to me about this stuff talk to each

686
00:28:33,830 --> 00:28:36,710
other about this stuff communicate with

687
00:28:35,299 --> 00:28:38,250
each other connect with your teams go

688
00:28:36,710 --> 00:28:40,230
figure out what's important to them

689
00:28:38,250 --> 00:28:44,100
give them the data that they actually

690
00:28:40,230 --> 00:28:45,360
might be able to use and yeah others are

691
00:28:44,100 --> 00:28:48,330
thinking about this so I'm gonna wrap up

692
00:28:45,360 --> 00:28:49,229
because I'm being told to go away some

693
00:28:48,330 --> 00:28:51,629
other things we're checking out

694
00:28:49,230 --> 00:28:55,879
stethoscope which is based on OS query

695
00:28:51,629 --> 00:28:57,928
which is a user focused security project

696
00:28:55,879 --> 00:28:59,459
Etsy's practices are really good at that

697
00:28:57,929 --> 00:29:00,929
where they do user focused design as

698
00:28:59,460 --> 00:29:03,990
well Kelly Shortridge has a great blog

699
00:29:00,929 --> 00:29:06,389
post called Security's product that has

700
00:29:03,990 --> 00:29:08,190
some parallel ideas and thank you very

701
00:29:06,389 --> 00:29:14,199
much I appreciate your time

702
00:29:08,190 --> 00:29:14,200
[Applause]

703
00:29:20,179 --> 00:29:22,240
you

