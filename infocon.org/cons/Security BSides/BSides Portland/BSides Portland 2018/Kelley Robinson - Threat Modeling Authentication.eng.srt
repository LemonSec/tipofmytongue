1
00:00:16,250 --> 00:00:20,099
everyone thank you for having me so I'm

2
00:00:19,199 --> 00:00:21,630
gonna be talking about authentication

3
00:00:20,099 --> 00:00:24,300
today this is a lot of the stuff that I

4
00:00:21,630 --> 00:00:25,680
deal with in my day to day work but the

5
00:00:24,300 --> 00:00:27,210
way that I wanted to approach this is

6
00:00:25,680 --> 00:00:28,890
from some of the the research papers

7
00:00:27,210 --> 00:00:30,960
that I've been reading about this and in

8
00:00:28,890 --> 00:00:33,989
2014 there was a research paper from

9
00:00:30,960 --> 00:00:35,610
Microsoft from a guy named James Mickens

10
00:00:33,989 --> 00:00:37,110
that he called this world of ours does

11
00:00:35,610 --> 00:00:39,739
anybody read this it's a very

12
00:00:37,110 --> 00:00:42,989
entertaining like short paper that I

13
00:00:39,739 --> 00:00:44,550
suggest that you go check out but like a

14
00:00:42,989 --> 00:00:47,370
lot of security research is incredibly

15
00:00:44,550 --> 00:00:49,468
morbid so in it he boils down our threat

16
00:00:47,370 --> 00:00:51,419
model to to potential adversaries so we

17
00:00:49,469 --> 00:00:55,050
have Mossad as the Israeli intelligence

18
00:00:51,420 --> 00:00:57,300
group and not Mossad so his idea is that

19
00:00:55,050 --> 00:00:59,218
if you're dealing with not Mossad you're

20
00:00:57,300 --> 00:01:01,409
probably okay to go about your life

21
00:00:59,219 --> 00:01:03,179
using strong passwords as your defense

22
00:01:01,409 --> 00:01:05,190
mechanism but if you're dealing with

23
00:01:03,179 --> 00:01:06,570
Mossad well you're gonna have to go fake

24
00:01:05,190 --> 00:01:07,979
your own death and live in the submarine

25
00:01:06,570 --> 00:01:10,800
because there's not a lot that you can

26
00:01:07,979 --> 00:01:12,270
do so I think this is an

27
00:01:10,800 --> 00:01:15,000
oversimplification of the reality that

28
00:01:12,270 --> 00:01:16,289
we live in but as security professionals

29
00:01:15,000 --> 00:01:17,520
I think a lot of what we have to

30
00:01:16,290 --> 00:01:19,950
struggle with is how we find the balance

31
00:01:17,520 --> 00:01:22,619
and how much we want to complicate this

32
00:01:19,950 --> 00:01:24,120
type of simplification so we have to

33
00:01:22,620 --> 00:01:25,890
figure out where on this spectrum we

34
00:01:24,120 --> 00:01:27,840
want to be between simpler solutions

35
00:01:25,890 --> 00:01:29,790
like passwords and more complex

36
00:01:27,840 --> 00:01:31,260
solutions like this this is something

37
00:01:29,790 --> 00:01:33,930
that he mentions in the paper and I hope

38
00:01:31,260 --> 00:01:35,880
it's still fictional but anyway

39
00:01:33,930 --> 00:01:37,500
Bojangles faces you know maybe that

40
00:01:35,880 --> 00:01:39,210
exists if somebody invented that come

41
00:01:37,500 --> 00:01:40,770
talk to me about it I'd love to hear

42
00:01:39,210 --> 00:01:44,220
what problem you think you're trying to

43
00:01:40,770 --> 00:01:45,780
solve but a more interesting paper in my

44
00:01:44,220 --> 00:01:48,450
opinion came from another Microsoft

45
00:01:45,780 --> 00:01:50,460
researcher in 2009 and this is a Hurley

46
00:01:48,450 --> 00:01:53,750
and the rationale rejection of security

47
00:01:50,460 --> 00:01:54,929
advice by users and he argues that when

48
00:01:53,750 --> 00:01:57,300
non-experts

49
00:01:54,930 --> 00:02:00,360
reject security advice they're often

50
00:01:57,300 --> 00:02:03,030
doing it for incredibly reasonable and

51
00:02:00,360 --> 00:02:05,610
rational reasons so how do we as

52
00:02:03,030 --> 00:02:07,410
security professionals help users avoid

53
00:02:05,610 --> 00:02:09,508
harm and I think this is the question

54
00:02:07,410 --> 00:02:11,640
that I want to try to answer today I

55
00:02:09,508 --> 00:02:13,619
wrapped us into what I'm calling threat

56
00:02:11,640 --> 00:02:15,540
model II and authentication we're gonna

57
00:02:13,620 --> 00:02:17,489
talk about why this is hard why Identity

58
00:02:15,540 --> 00:02:19,260
Management is a challenge that we have

59
00:02:17,489 --> 00:02:21,420
and why authentication is so difficult

60
00:02:19,260 --> 00:02:23,250
how you can evaluate you the risk for

61
00:02:21,420 --> 00:02:24,600
your users and some of the actions that

62
00:02:23,250 --> 00:02:27,150
you might want to take to keep your

63
00:02:24,600 --> 00:02:27,870
users safe so once again my name is

64
00:02:27,150 --> 00:02:30,299
Kelly

65
00:02:27,870 --> 00:02:31,980
I work at Twilio Twilio is a

66
00:02:30,299 --> 00:02:33,120
communications company so we have api's

67
00:02:31,980 --> 00:02:35,640
for doing things like studying and

68
00:02:33,120 --> 00:02:38,220
receiving text messages voice calls and

69
00:02:35,640 --> 00:02:40,679
authentication I work specifically on

70
00:02:38,220 --> 00:02:42,120
our account security products so if

71
00:02:40,680 --> 00:02:43,680
there's any author users here totally

72
00:02:42,120 --> 00:02:45,299
acquired them about five years ago and

73
00:02:43,680 --> 00:02:47,010
so I work on the api's for doing things

74
00:02:45,299 --> 00:02:49,650
like phone verification and multi-factor

75
00:02:47,010 --> 00:02:52,200
authentication and I also spend a lot of

76
00:02:49,650 --> 00:02:53,760
time in my job doing security education

77
00:02:52,200 --> 00:02:55,470
especially for developers

78
00:02:53,760 --> 00:02:57,450
my background is all in software

79
00:02:55,470 --> 00:02:59,430
engineering and so a lot of the the

80
00:02:57,450 --> 00:03:01,738
audiences that I speak to and work with

81
00:02:59,430 --> 00:03:03,810
our developers that I'm trying to get to

82
00:03:01,739 --> 00:03:05,099
care about security so this talk is

83
00:03:03,810 --> 00:03:06,540
going to incorporate a lot of the things

84
00:03:05,099 --> 00:03:09,179
that I have learned from talking to

85
00:03:06,540 --> 00:03:12,000
developers about authentication in my

86
00:03:09,180 --> 00:03:13,590
time at well yeah so let's talk about

87
00:03:12,000 --> 00:03:15,060
threat modeling especially for the

88
00:03:13,590 --> 00:03:16,799
applications that were working with I

89
00:03:15,060 --> 00:03:19,680
want to talk about what we're building

90
00:03:16,799 --> 00:03:21,540
the risks to the things that we're going

91
00:03:19,680 --> 00:03:24,000
to be building how we can evaluate those

92
00:03:21,540 --> 00:03:25,650
risks and mitigate them and then finally

93
00:03:24,000 --> 00:03:28,379
some way to measure whether or not we

94
00:03:25,650 --> 00:03:30,870
did a good job a lot of this talk is

95
00:03:28,379 --> 00:03:32,310
going to focus on consumer or public

96
00:03:30,870 --> 00:03:35,370
facing accounts mostly because that's

97
00:03:32,310 --> 00:03:37,319
what I know and deal with if there's an

98
00:03:35,370 --> 00:03:38,910
area of authentication that's missing

99
00:03:37,319 --> 00:03:41,668
please come talk to me after this this

100
00:03:38,910 --> 00:03:43,440
is you know a 25 minute talk so we're

101
00:03:41,669 --> 00:03:44,940
not gonna be able to cover everything so

102
00:03:43,440 --> 00:03:47,220
we're also not gonna be talking about

103
00:03:44,940 --> 00:03:49,139
things like session hacking JSON web

104
00:03:47,220 --> 00:03:51,000
tokens cookie stealing and that kind of

105
00:03:49,139 --> 00:03:52,349
stuff so just so you know we're gonna be

106
00:03:51,000 --> 00:03:53,879
talking a lot about the process of

107
00:03:52,349 --> 00:03:57,149
authentication when things like sign up

108
00:03:53,879 --> 00:03:58,620
and login so the problem with threat

109
00:03:57,150 --> 00:04:01,019
models is that it's very specific to

110
00:03:58,620 --> 00:04:02,459
whatever your business is so you're

111
00:04:01,019 --> 00:04:03,449
going to have to be thinking about the

112
00:04:02,459 --> 00:04:05,069
businesses and the things that you're

113
00:04:03,449 --> 00:04:06,569
going to be securing under this so I

114
00:04:05,069 --> 00:04:08,250
want to talk about the commonalities of

115
00:04:06,569 --> 00:04:11,069
the the solutions that we're going to be

116
00:04:08,250 --> 00:04:13,769
building and let's walk through a few

117
00:04:11,069 --> 00:04:14,849
assumptions with that so the first

118
00:04:13,769 --> 00:04:17,280
assumption that I want to make is that

119
00:04:14,849 --> 00:04:20,389
your users have something of value that

120
00:04:17,279 --> 00:04:22,739
is connected to a personal account and

121
00:04:20,389 --> 00:04:25,229
this is going to be the main assumption

122
00:04:22,740 --> 00:04:26,580
for our authenticated system the second

123
00:04:25,229 --> 00:04:28,560
assumption is that the user can only

124
00:04:26,580 --> 00:04:30,330
access that value once they are

125
00:04:28,560 --> 00:04:32,310
authenticated so we want to have some

126
00:04:30,330 --> 00:04:34,800
kind of way to tie them to their account

127
00:04:32,310 --> 00:04:37,500
in a way that they can access that value

128
00:04:34,800 --> 00:04:39,630
and finally the third assumption is that

129
00:04:37,500 --> 00:04:41,040
if a success or if the

130
00:04:39,630 --> 00:04:43,560
Nader is successful they could also

131
00:04:41,040 --> 00:04:44,940
access that users value and a lot of

132
00:04:43,560 --> 00:04:47,460
what we're going to be talking about is

133
00:04:44,940 --> 00:04:49,980
how to make this step complicated and

134
00:04:47,460 --> 00:04:53,400
tedious enough for the hacker so it's

135
00:04:49,980 --> 00:04:55,740
not worth their time so how common is

136
00:04:53,400 --> 00:04:58,289
this this is a huge problem it dropped

137
00:04:55,740 --> 00:05:01,370
off in 2015 when credit card chips were

138
00:04:58,290 --> 00:05:04,110
introduced but account takeovers cost

139
00:05:01,370 --> 00:05:06,540
are back up to costing us about 5.1

140
00:05:04,110 --> 00:05:07,890
billion dollars every year this may be

141
00:05:06,540 --> 00:05:09,630
different depending on the business that

142
00:05:07,890 --> 00:05:11,760
you're in a lot of the fraud that we see

143
00:05:09,630 --> 00:05:13,260
is related to banking financial

144
00:05:11,760 --> 00:05:15,960
institutions and other type of

145
00:05:13,260 --> 00:05:18,120
businesses but the value that you people

146
00:05:15,960 --> 00:05:21,150
might get from hacking your accounts is

147
00:05:18,120 --> 00:05:22,560
not always related to money but a lot of

148
00:05:21,150 --> 00:05:24,750
this is happening because online

149
00:05:22,560 --> 00:05:26,250
identity is fallible and we'd like to

150
00:05:24,750 --> 00:05:29,400
believe that we have these perfect

151
00:05:26,250 --> 00:05:31,380
systems for convincing computers that we

152
00:05:29,400 --> 00:05:34,229
are who we say we are well that's all

153
00:05:31,380 --> 00:05:36,360
baked into trust systems of trust

154
00:05:34,230 --> 00:05:37,560
somebody mentioned in the in the keynote

155
00:05:36,360 --> 00:05:40,290
I hadn't heard that term before but

156
00:05:37,560 --> 00:05:42,330
trust anchors I really like that idea of

157
00:05:40,290 --> 00:05:44,460
having a trust anchor for something that

158
00:05:42,330 --> 00:05:46,409
we're dealing with and identity is

159
00:05:44,460 --> 00:05:48,659
incredibly baked into these trust

160
00:05:46,410 --> 00:05:51,260
anchors of different systems that we

161
00:05:48,660 --> 00:05:53,070
have decided that we want to believe

162
00:05:51,260 --> 00:05:56,099
that they know what they're talking

163
00:05:53,070 --> 00:05:57,750
about and how we design those systems

164
00:05:56,100 --> 00:05:59,190
and establish that trust as part of this

165
00:05:57,750 --> 00:06:01,590
exercise that we want to walk through

166
00:05:59,190 --> 00:06:03,060
today so I want to break down the

167
00:06:01,590 --> 00:06:04,200
different types of identities that we

168
00:06:03,060 --> 00:06:05,760
have and kind of go through this

169
00:06:04,200 --> 00:06:07,710
waterfall of the different trust anchors

170
00:06:05,760 --> 00:06:09,830
that we are we're creating and the

171
00:06:07,710 --> 00:06:11,909
different ways that we're basically

172
00:06:09,830 --> 00:06:13,440
knowing the identities of the people

173
00:06:11,910 --> 00:06:15,510
that we're dealing with and so the first

174
00:06:13,440 --> 00:06:16,890
category this is really going to be

175
00:06:15,510 --> 00:06:18,180
physical identities and these are things

176
00:06:16,890 --> 00:06:19,969
like biometrics and these are things

177
00:06:18,180 --> 00:06:23,100
that we can't change about ourselves

178
00:06:19,970 --> 00:06:25,530
the second is government identities so

179
00:06:23,100 --> 00:06:28,860
these are things that are validated or

180
00:06:25,530 --> 00:06:30,900
issued by the state so passports Social

181
00:06:28,860 --> 00:06:31,530
Security numbers and the u.s. things

182
00:06:30,900 --> 00:06:33,750
like that

183
00:06:31,530 --> 00:06:35,340
and finally what I'm calling contextual

184
00:06:33,750 --> 00:06:38,790
identities and so this is something that

185
00:06:35,340 --> 00:06:41,250
is going to be established with you know

186
00:06:38,790 --> 00:06:42,750
individual accounts this is the types of

187
00:06:41,250 --> 00:06:44,490
identities that were established a lot

188
00:06:42,750 --> 00:06:47,190
of times since the internet became a

189
00:06:44,490 --> 00:06:48,930
thing these are not these are easier to

190
00:06:47,190 --> 00:06:49,500
change about yourself they're not

191
00:06:48,930 --> 00:06:51,030
necessary

192
00:06:49,500 --> 00:06:53,850
really tied to something like biometrics

193
00:06:51,030 --> 00:06:55,950
specifically so if you're verifying

194
00:06:53,850 --> 00:06:58,400
identity with any kind of trusted

195
00:06:55,950 --> 00:07:00,930
contact especially in the real world

196
00:06:58,400 --> 00:07:02,640
physical identity is the way that you

197
00:07:00,930 --> 00:07:05,340
want to do that there's a huge amount of

198
00:07:02,640 --> 00:07:08,039
power in somebody saying I recognize

199
00:07:05,340 --> 00:07:09,750
that person and this is a lot of the

200
00:07:08,040 --> 00:07:11,760
trust anchors that we have in our

201
00:07:09,750 --> 00:07:13,800
systems and this is how we built

202
00:07:11,760 --> 00:07:16,650
identities through most of the history

203
00:07:13,800 --> 00:07:19,590
until we started dealing in such scope

204
00:07:16,650 --> 00:07:21,479
with the people that we don't know over

205
00:07:19,590 --> 00:07:22,919
the Internet and so this is you know the

206
00:07:21,480 --> 00:07:24,930
the systems that we have in place now

207
00:07:22,919 --> 00:07:26,099
are largely because we don't trust the

208
00:07:24,930 --> 00:07:28,790
other people that we're dealing with and

209
00:07:26,100 --> 00:07:31,710
we've never met them in person

210
00:07:28,790 --> 00:07:33,060
government identities are one of the

211
00:07:31,710 --> 00:07:35,370
ways that we deal with untrusted

212
00:07:33,060 --> 00:07:37,080
contacts and in that sense we're passing

213
00:07:35,370 --> 00:07:39,180
the trust on to another body that we do

214
00:07:37,080 --> 00:07:41,310
trust this of course falls apart if we

215
00:07:39,180 --> 00:07:42,300
don't trust our government but right now

216
00:07:41,310 --> 00:07:44,040
I think one of the things that we're

217
00:07:42,300 --> 00:07:45,720
able to do is you know you check into a

218
00:07:44,040 --> 00:07:47,580
hotel you give them your ID and your

219
00:07:45,720 --> 00:07:49,680
credit card and they're saying cool I

220
00:07:47,580 --> 00:07:51,330
trust the government and this bank that

221
00:07:49,680 --> 00:07:52,770
this person is who they say they are

222
00:07:51,330 --> 00:07:55,500
that they're checking into the secod

223
00:07:52,770 --> 00:07:56,880
into this hotel room and so in this type

224
00:07:55,500 --> 00:07:58,260
of situation we're essentially saying I

225
00:07:56,880 --> 00:08:01,290
trust that the government knows this

226
00:07:58,260 --> 00:08:03,450
person and finally we end up with these

227
00:08:01,290 --> 00:08:05,610
contextual identities that may not

228
00:08:03,450 --> 00:08:07,469
guarantee much of anything so a lot of

229
00:08:05,610 --> 00:08:09,540
online accounts fall back to identities

230
00:08:07,470 --> 00:08:10,740
other identities for validation um you

231
00:08:09,540 --> 00:08:12,180
know if you are opening up something

232
00:08:10,740 --> 00:08:14,910
like a bank account or something that

233
00:08:12,180 --> 00:08:16,590
needs to be overly secure like that

234
00:08:14,910 --> 00:08:18,479
you're going to have to give up your

235
00:08:16,590 --> 00:08:19,650
social security number at some point you

236
00:08:18,479 --> 00:08:21,030
might have to send a copy of your

237
00:08:19,650 --> 00:08:22,500
driver's license and so you're getting

238
00:08:21,030 --> 00:08:25,770
back to those government identities that

239
00:08:22,500 --> 00:08:27,419
people need to start to validate so

240
00:08:25,770 --> 00:08:28,680
Trust is a waterfowl and at the end of

241
00:08:27,419 --> 00:08:32,250
the day we're just going back on

242
00:08:28,680 --> 00:08:33,659
someone's word and this is hard because

243
00:08:32,250 --> 00:08:34,979
we're all just trying to prove to some

244
00:08:33,659 --> 00:08:36,510
system that we are who we say we are

245
00:08:34,979 --> 00:08:38,669
we're doing this is a lot of different

246
00:08:36,510 --> 00:08:39,838
methods clicking in stop signs was

247
00:08:38,669 --> 00:08:41,750
really good a bit from John Mulaney

248
00:08:39,839 --> 00:08:44,010
about this definitely go check that out

249
00:08:41,750 --> 00:08:45,240
and we also want to prove that we're not

250
00:08:44,010 --> 00:08:47,160
a robot we want to prove that were re

251
00:08:45,240 --> 00:08:48,750
real human and there's a variety of ways

252
00:08:47,160 --> 00:08:50,910
that we're doing this but the systems

253
00:08:48,750 --> 00:08:52,620
are imperfect and one of the most

254
00:08:50,910 --> 00:08:54,810
challenging things about this is that we

255
00:08:52,620 --> 00:08:56,850
may never know if we got it right

256
00:08:54,810 --> 00:08:58,410
you're not often going to meet the

257
00:08:56,850 --> 00:09:00,270
people that you're authenticating in

258
00:08:58,410 --> 00:09:02,430
your online systems through your website

259
00:09:00,270 --> 00:09:03,130
you may never know if somebody actually

260
00:09:02,430 --> 00:09:04,780
is who they say

261
00:09:03,130 --> 00:09:06,580
they are and we're just going to have to

262
00:09:04,780 --> 00:09:09,850
build our systems in a way that that

263
00:09:06,580 --> 00:09:10,840
part doesn't really matter so of course

264
00:09:09,850 --> 00:09:13,090
there are a lot of things that can go

265
00:09:10,840 --> 00:09:15,460
wrong with this this is another quote

266
00:09:13,090 --> 00:09:18,370
from the paper on rational advice for

267
00:09:15,460 --> 00:09:20,050
security users and I like what he does

268
00:09:18,370 --> 00:09:22,630
with this analysis because he takes a

269
00:09:20,050 --> 00:09:25,719
very calculation driven approach to the

270
00:09:22,630 --> 00:09:27,670
usefulness of security advice and this

271
00:09:25,720 --> 00:09:30,190
is I think interesting because a lot of

272
00:09:27,670 --> 00:09:31,270
what we're asking of the users when

273
00:09:30,190 --> 00:09:34,570
we're asking them to take security

274
00:09:31,270 --> 00:09:36,189
advice is for their time but it's also a

275
00:09:34,570 --> 00:09:37,990
lot of things that they use if they get

276
00:09:36,190 --> 00:09:40,270
compromised it's not necessarily money

277
00:09:37,990 --> 00:09:42,070
like that might be part of it but you

278
00:09:40,270 --> 00:09:43,980
know it's relatively easy to fight a

279
00:09:42,070 --> 00:09:47,350
bank charge but then you're going to

280
00:09:43,980 --> 00:09:48,910
have to spend all this time revalidating

281
00:09:47,350 --> 00:09:50,200
that you are who you say you are a lot

282
00:09:48,910 --> 00:09:56,140
of time on the phone with somebody like

283
00:09:50,200 --> 00:09:58,690
to regain control of your account and he

284
00:09:56,140 --> 00:10:00,130
goes on to say that like the worst-case

285
00:09:58,690 --> 00:10:02,490
scenario is generally what we as

286
00:10:00,130 --> 00:10:04,689
security researchers often think about

287
00:10:02,490 --> 00:10:05,770
there's a lot of security advice out

288
00:10:04,690 --> 00:10:07,960
there that talks about the worst case

289
00:10:05,770 --> 00:10:09,400
and the reason for that is that's more

290
00:10:07,960 --> 00:10:11,740
exciting the average case is not as

291
00:10:09,400 --> 00:10:13,360
exciting to deal with but we need to

292
00:10:11,740 --> 00:10:14,770
estimate the victimization rate for a

293
00:10:13,360 --> 00:10:17,410
lot of these things because if we don't

294
00:10:14,770 --> 00:10:18,850
the worst case analysis is going to lull

295
00:10:17,410 --> 00:10:21,790
us into this false sense that we're

296
00:10:18,850 --> 00:10:26,380
doing a lot more good with our security

297
00:10:21,790 --> 00:10:27,490
mitigations than we actually are so some

298
00:10:26,380 --> 00:10:30,220
of the things that can go wrong with

299
00:10:27,490 --> 00:10:32,020
authentication processes and this is

300
00:10:30,220 --> 00:10:33,220
definitely not an exhaustive list by any

301
00:10:32,020 --> 00:10:36,100
means but the two things I want to talk

302
00:10:33,220 --> 00:10:37,480
about our compromise factors so these

303
00:10:36,100 --> 00:10:39,490
are if your credentials can get hacked

304
00:10:37,480 --> 00:10:42,640
guess phished brute force

305
00:10:39,490 --> 00:10:44,680
a lot of the risk that we come up with

306
00:10:42,640 --> 00:10:46,840
in these situations happens to do with

307
00:10:44,680 --> 00:10:49,089
somehow your factors getting compromised

308
00:10:46,840 --> 00:10:51,760
I included links there at the bottom for

309
00:10:49,090 --> 00:10:53,710
the threat model research for the OAuth

310
00:10:51,760 --> 00:10:55,300
2 protocol and the open ID connect

311
00:10:53,710 --> 00:10:57,040
protocol and I think those are good

312
00:10:55,300 --> 00:10:58,540
things to go reference if you want to

313
00:10:57,040 --> 00:11:01,599
learn more about this because for

314
00:10:58,540 --> 00:11:03,490
specific SSO implementations those gave

315
00:11:01,600 --> 00:11:05,050
a really good different approaches to

316
00:11:03,490 --> 00:11:08,890
how they thought about the the risks of

317
00:11:05,050 --> 00:11:10,240
their systems there's also some known

318
00:11:08,890 --> 00:11:12,699
weak points in these authentication

319
00:11:10,240 --> 00:11:14,800
systems and I want to talk about two of

320
00:11:12,700 --> 00:11:16,279
them because these are things that a lot

321
00:11:14,800 --> 00:11:18,319
of companies if you have any

322
00:11:16,279 --> 00:11:20,360
system any kind of contact center or

323
00:11:18,319 --> 00:11:22,449
account recovery process you're going to

324
00:11:20,360 --> 00:11:25,850
have to deal with at some point

325
00:11:22,449 --> 00:11:27,079
so first request via contact center if

326
00:11:25,850 --> 00:11:29,060
anybody has ever been to a social

327
00:11:27,079 --> 00:11:30,829
engineering CTF those things are

328
00:11:29,060 --> 00:11:33,709
fascinating and it's really interesting

329
00:11:30,829 --> 00:11:36,170
to see the people how successful people

330
00:11:33,709 --> 00:11:37,550
are at fishing people on the other end

331
00:11:36,170 --> 00:11:39,050
of the line and a lot of that is because

332
00:11:37,550 --> 00:11:41,719
we're all human humans are fallible

333
00:11:39,050 --> 00:11:45,410
we're trustworthy people that we want to

334
00:11:41,720 --> 00:11:47,180
help out at the end of the day but most

335
00:11:45,410 --> 00:11:50,059
contact centers don't have the same

336
00:11:47,180 --> 00:11:52,758
security rigor that you might have in

337
00:11:50,059 --> 00:11:54,469
your online education processes it's not

338
00:11:52,759 --> 00:11:56,540
as easy to put like a form on your

339
00:11:54,470 --> 00:11:59,439
weapon through a contact center as it is

340
00:11:56,540 --> 00:12:01,699
to put in a on a phone or on a computer

341
00:11:59,439 --> 00:12:03,800
but it's also interesting because a lot

342
00:12:01,699 --> 00:12:05,569
of times there's really high-risk

343
00:12:03,800 --> 00:12:08,180
activities that are happening through a

344
00:12:05,569 --> 00:12:09,769
contact center so you might have in a

345
00:12:08,180 --> 00:12:12,109
situation where you can only cancel your

346
00:12:09,769 --> 00:12:13,490
account create a new account change

347
00:12:12,110 --> 00:12:15,499
certain personally identifiable

348
00:12:13,490 --> 00:12:17,329
information so there's some companies

349
00:12:15,499 --> 00:12:18,470
that only allow you to do that through

350
00:12:17,329 --> 00:12:19,729
the contact center and so you're

351
00:12:18,470 --> 00:12:23,329
creating a lot of risk in these

352
00:12:19,730 --> 00:12:25,519
situations other things that can go

353
00:12:23,329 --> 00:12:26,839
wrong with account recovery a lot of

354
00:12:25,519 --> 00:12:28,129
this has to do with how strict do you

355
00:12:26,839 --> 00:12:29,600
want to make the process because you're

356
00:12:28,129 --> 00:12:31,540
essentially restarting this entire

357
00:12:29,600 --> 00:12:33,709
process and saying okay we're gonna

358
00:12:31,540 --> 00:12:34,910
reestablish your identity and like hope

359
00:12:33,709 --> 00:12:36,439
that your identity that your

360
00:12:34,910 --> 00:12:39,469
reestablishing is the same as the one we

361
00:12:36,439 --> 00:12:42,319
were using before so account recovery

362
00:12:39,470 --> 00:12:44,660
gets into all of these edge cases and it

363
00:12:42,319 --> 00:12:47,300
is one of those more obvious examples of

364
00:12:44,660 --> 00:12:49,250
the trade-offs between how rigorous you

365
00:12:47,300 --> 00:12:51,319
want to make the process for the user

366
00:12:49,250 --> 00:12:53,629
and the level of security that you want

367
00:12:51,319 --> 00:12:57,889
to achieve how many hoops do you want to

368
00:12:53,629 --> 00:12:59,360
make your users jump through so finally

369
00:12:57,889 --> 00:13:01,160
I think we can think about what goes

370
00:12:59,360 --> 00:13:02,689
wrong in terms of the value of what's

371
00:13:01,160 --> 00:13:04,939
being protected and one of the things

372
00:13:02,689 --> 00:13:06,349
that I think is important is yes like

373
00:13:04,939 --> 00:13:07,819
this is going to depend on the business

374
00:13:06,350 --> 00:13:09,860
that you're in but this is also going to

375
00:13:07,819 --> 00:13:11,779
depend on the individual user accounts

376
00:13:09,860 --> 00:13:15,199
and so there's a lot more value in

377
00:13:11,779 --> 00:13:17,389
hacking higher value targets than there

378
00:13:15,199 --> 00:13:18,410
is to the lower value targets as you can

379
00:13:17,389 --> 00:13:21,319
see in this very official risk

380
00:13:18,410 --> 00:13:23,800
assessment so I mentioned that the goal

381
00:13:21,319 --> 00:13:26,269
of this is not to make is to make it the

382
00:13:23,800 --> 00:13:27,130
impersonators time not worth it for them

383
00:13:26,269 --> 00:13:29,290
to try to have

384
00:13:27,130 --> 00:13:32,740
this and so naturally there's more

385
00:13:29,290 --> 00:13:34,180
incentive for higher value accounts and

386
00:13:32,740 --> 00:13:36,130
this applies not just to the business

387
00:13:34,180 --> 00:13:38,439
you're in like I said it also applies to

388
00:13:36,130 --> 00:13:40,600
the types of customers and value in this

389
00:13:38,440 --> 00:13:42,430
case doesn't just have to be money so

390
00:13:40,600 --> 00:13:45,520
you can be hacking people's accounts for

391
00:13:42,430 --> 00:13:46,719
information power and control as well so

392
00:13:45,520 --> 00:13:48,310
you think about this there's a lot more

393
00:13:46,720 --> 00:13:50,230
value in hacking Barack Obama's Twitter

394
00:13:48,310 --> 00:13:51,640
account and then there is to hack my

395
00:13:50,230 --> 00:13:55,680
Twitter account because he has a lot

396
00:13:51,640 --> 00:13:57,880
more power associated with that platform

397
00:13:55,680 --> 00:14:00,130
and this is where our strategies for

398
00:13:57,880 --> 00:14:02,100
authentication come in how are we going

399
00:14:00,130 --> 00:14:04,810
to mitigate these risks that we see

400
00:14:02,100 --> 00:14:06,100
first we have to prioritize this and one

401
00:14:04,810 --> 00:14:08,349
of the things that I think we need to

402
00:14:06,100 --> 00:14:10,630
remember is that users are inundated

403
00:14:08,350 --> 00:14:12,070
with security advice all the time and

404
00:14:10,630 --> 00:14:13,570
the more advice that we give them and

405
00:14:12,070 --> 00:14:15,790
the more conflicting advice that we give

406
00:14:13,570 --> 00:14:18,130
them they're just gonna start ignoring

407
00:14:15,790 --> 00:14:19,780
that advice and so we have to prioritize

408
00:14:18,130 --> 00:14:22,270
the advice that we're giving them and

409
00:14:19,780 --> 00:14:24,300
make it reasonable for them to to follow

410
00:14:22,270 --> 00:14:26,860
the advice that we have so better yet

411
00:14:24,300 --> 00:14:28,390
we're going to design our systems in a

412
00:14:26,860 --> 00:14:30,910
way so the users don't have to think

413
00:14:28,390 --> 00:14:33,460
about this one option that you have is

414
00:14:30,910 --> 00:14:35,589
SSO this is an example of passing the

415
00:14:33,460 --> 00:14:37,480
trust you're going to be saying that

416
00:14:35,590 --> 00:14:39,480
instead I trust Google I trust Facebook

417
00:14:37,480 --> 00:14:41,620
to handle this authentication process

418
00:14:39,480 --> 00:14:43,090
also like in the keynote this morning I

419
00:14:41,620 --> 00:14:44,170
think you know if you're moving all of

420
00:14:43,090 --> 00:14:45,730
your hardware to the cloud you're

421
00:14:44,170 --> 00:14:48,490
passing that trust onto saying that I

422
00:14:45,730 --> 00:14:50,410
trust Amazon and AWS to be able to

423
00:14:48,490 --> 00:14:52,590
secure my hardware better than I'm gonna

424
00:14:50,410 --> 00:14:55,390
do it myself it's also there's a lot of

425
00:14:52,590 --> 00:14:57,430
usability reasons that you might do this

426
00:14:55,390 --> 00:14:59,680
it's easier for people to log on but

427
00:14:57,430 --> 00:15:01,599
like it's it's convenient but you're

428
00:14:59,680 --> 00:15:03,939
also opening yourself up to a new

429
00:15:01,600 --> 00:15:06,100
category of vulnerabilities specifically

430
00:15:03,940 --> 00:15:08,590
a lot of dating apps had to reevaluate

431
00:15:06,100 --> 00:15:10,050
this when there was so much backlash

432
00:15:08,590 --> 00:15:12,400
against Facebook earlier this year

433
00:15:10,050 --> 00:15:15,370
dating apps had to move to things like

434
00:15:12,400 --> 00:15:17,530
phone verification and first party login

435
00:15:15,370 --> 00:15:19,660
systems because they were all on the

436
00:15:17,530 --> 00:15:21,010
system of only using Facebook to log in

437
00:15:19,660 --> 00:15:23,199
and all the sudden people didn't want to

438
00:15:21,010 --> 00:15:24,400
do that anymore so like everything your

439
00:15:23,200 --> 00:15:27,460
mileage may vary it was something like

440
00:15:24,400 --> 00:15:29,170
this and so the other method that you

441
00:15:27,460 --> 00:15:30,700
have is these different factors for

442
00:15:29,170 --> 00:15:32,229
authentication and generally we break

443
00:15:30,700 --> 00:15:33,790
these into something that you know like

444
00:15:32,230 --> 00:15:35,950
a password something that you have like

445
00:15:33,790 --> 00:15:38,930
a phone and something that you are like

446
00:15:35,950 --> 00:15:40,430
biometric data your fingerprint

447
00:15:38,930 --> 00:15:42,079
so the example of this that we usually

448
00:15:40,430 --> 00:15:43,339
give is something like a debit card and

449
00:15:42,080 --> 00:15:45,560
a PIN number that's something that you

450
00:15:43,339 --> 00:15:48,740
have and something that you know in this

451
00:15:45,560 --> 00:15:50,660
case you know you're kind of ignoring

452
00:15:48,740 --> 00:15:52,700
all security advice and going back to

453
00:15:50,660 --> 00:15:56,540
zero factors if you're both giving out

454
00:15:52,700 --> 00:15:57,770
the something that you know so the

455
00:15:56,540 --> 00:15:59,750
biggest way that we've done something

456
00:15:57,770 --> 00:16:01,160
with passwords is something with

457
00:15:59,750 --> 00:16:03,680
something we know as passwords and so

458
00:16:01,160 --> 00:16:05,000
for online authentication systems a lot

459
00:16:03,680 --> 00:16:06,399
of a lot of the ways that we

460
00:16:05,000 --> 00:16:10,250
authenticate things are with passwords

461
00:16:06,399 --> 00:16:12,410
so this is from a app from Samantha B

462
00:16:10,250 --> 00:16:14,510
they they basically it's like

463
00:16:12,410 --> 00:16:16,550
get-out-the-vote app but they give the

464
00:16:14,510 --> 00:16:18,020
very rational security advice to just

465
00:16:16,550 --> 00:16:19,490
don't use the same password that you're

466
00:16:18,020 --> 00:16:20,899
using for your banking app and I

467
00:16:19,490 --> 00:16:23,240
actually love this because it's telling

468
00:16:20,899 --> 00:16:25,250
people something very straightforward

469
00:16:23,240 --> 00:16:27,740
you know it's obviously snarky about the

470
00:16:25,250 --> 00:16:29,450
security aspect of it but you know users

471
00:16:27,740 --> 00:16:30,620
can resonate with this and it's also

472
00:16:29,450 --> 00:16:34,880
reaching an audience that it makes sense

473
00:16:30,620 --> 00:16:36,529
for but passwords are fallible and it's

474
00:16:34,880 --> 00:16:38,990
one of the worst ways that we can ask

475
00:16:36,529 --> 00:16:40,310
users to be secure because it's one of

476
00:16:38,990 --> 00:16:42,770
the only ways that we're making users

477
00:16:40,310 --> 00:16:44,300
think and thinking is exhausting

478
00:16:42,770 --> 00:16:46,610
we don't want to have to make users

479
00:16:44,300 --> 00:16:48,260
think but until we all become cyborgs

480
00:16:46,610 --> 00:16:50,329
and implant chips and ourselves and the

481
00:16:48,260 --> 00:16:51,910
robots take over we're probably going to

482
00:16:50,329 --> 00:16:53,540
have to keep supporting passwords

483
00:16:51,910 --> 00:16:54,890
dealing with a lot of people on

484
00:16:53,540 --> 00:16:55,910
authentication I hear a lot of people

485
00:16:54,890 --> 00:16:57,709
being like we're gonna get rid of

486
00:16:55,910 --> 00:16:59,360
passwords forever and I think there's

487
00:16:57,709 --> 00:17:00,890
ways that we might be able to do that

488
00:16:59,360 --> 00:17:01,339
but it's definitely not gonna be in my

489
00:17:00,890 --> 00:17:03,170
lifetime

490
00:17:01,339 --> 00:17:04,970
we're definitely gonna see passwords

491
00:17:03,170 --> 00:17:06,079
stick around for awhile and so it is

492
00:17:04,970 --> 00:17:09,050
something that we're going to have to

493
00:17:06,079 --> 00:17:10,849
keep supporting one way to make this

494
00:17:09,050 --> 00:17:13,790
easier for your customers is to set

495
00:17:10,849 --> 00:17:15,438
sensible password requirements minimum

496
00:17:13,790 --> 00:17:18,438
length of like 8 characters it's better

497
00:17:15,439 --> 00:17:20,390
than 6 but not too many and let them set

498
00:17:18,439 --> 00:17:21,770
their passwords but also alert them if

499
00:17:20,390 --> 00:17:24,230
the password that they're trying to set

500
00:17:21,770 --> 00:17:26,089
has been known to be compromised and one

501
00:17:24,230 --> 00:17:28,250
really great way to do this is through

502
00:17:26,089 --> 00:17:30,919
the own passwords API how many people

503
00:17:28,250 --> 00:17:32,270
have heard of this so about half of you

504
00:17:30,920 --> 00:17:34,700
so Troy hunt who is a security

505
00:17:32,270 --> 00:17:37,429
researcher also at Microsoft all the

506
00:17:34,700 --> 00:17:38,840
good people are Microsoft and so they he

507
00:17:37,429 --> 00:17:40,820
has this website that's called have I

508
00:17:38,840 --> 00:17:43,040
been owned com it's great you can go

509
00:17:40,820 --> 00:17:44,659
type in your email and say if your email

510
00:17:43,040 --> 00:17:46,790
address has come up in any data breaches

511
00:17:44,660 --> 00:17:48,530
he also has an API for typing in your

512
00:17:46,790 --> 00:17:49,470
password to see if your password has

513
00:17:48,530 --> 00:17:51,600
come up in any data

514
00:17:49,470 --> 00:17:53,490
reaches the way that he stores that data

515
00:17:51,600 --> 00:17:55,770
is actually really interesting and in

516
00:17:53,490 --> 00:17:57,780
the more recent versions of the API he

517
00:17:55,770 --> 00:17:59,250
has a way that you can submit your

518
00:17:57,780 --> 00:18:00,629
password and see if your password has

519
00:17:59,250 --> 00:18:02,400
been compromised without actually giving

520
00:18:00,630 --> 00:18:04,190
him your password and so you can do a

521
00:18:02,400 --> 00:18:06,090
basic sha-1 hash in your password

522
00:18:04,190 --> 00:18:07,919
truncate that to the first five

523
00:18:06,090 --> 00:18:09,418
characters send the first five

524
00:18:07,919 --> 00:18:12,179
characters to him and he'll return a

525
00:18:09,419 --> 00:18:14,159
list of all the suffixes that match that

526
00:18:12,179 --> 00:18:16,770
prefix and so then you get a shortened

527
00:18:14,159 --> 00:18:18,000
list of maybe like 30 to 100 things and

528
00:18:16,770 --> 00:18:19,650
you can search through that list to see

529
00:18:18,000 --> 00:18:21,900
if your suffix is there so it's a really

530
00:18:19,650 --> 00:18:24,090
creative way to check if your password

531
00:18:21,900 --> 00:18:26,250
has been owned without actually giving

532
00:18:24,090 --> 00:18:27,600
him your password because as much as

533
00:18:26,250 --> 00:18:29,130
we'd like to think that you know he's

534
00:18:27,600 --> 00:18:30,928
not doing anything nefarious with that

535
00:18:29,130 --> 00:18:32,490
that is definitely a way that people

536
00:18:30,929 --> 00:18:33,870
might be able to then log all the

537
00:18:32,490 --> 00:18:36,600
credentials that you're worried about

538
00:18:33,870 --> 00:18:37,860
giving up and so one of the things

539
00:18:36,600 --> 00:18:39,299
that's interesting about this is that

540
00:18:37,860 --> 00:18:41,039
this approach is also going to cover a

541
00:18:39,299 --> 00:18:43,830
lot of guessable or brute forcible

542
00:18:41,039 --> 00:18:45,510
passwords because the own passwords list

543
00:18:43,830 --> 00:18:49,350
has a lot of the most common passwords

544
00:18:45,510 --> 00:18:50,789
in it you could also expand this to do

545
00:18:49,350 --> 00:18:52,350
things like not include common

546
00:18:50,789 --> 00:18:54,600
dictionary words I don't know how many

547
00:18:52,350 --> 00:18:56,039
of those are included in his list but

548
00:18:54,600 --> 00:18:57,539
you could build out a system like this

549
00:18:56,039 --> 00:19:00,480
that is pretty quick to implement

550
00:18:57,539 --> 00:19:03,690
alright pretty quick to query that

551
00:19:00,480 --> 00:19:05,400
allows you to let your users use

552
00:19:03,690 --> 00:19:07,440
passwords that aren't as easy to guess

553
00:19:05,400 --> 00:19:09,030
and so github is a service that

554
00:19:07,440 --> 00:19:11,159
implemented this and so now when you set

555
00:19:09,030 --> 00:19:14,158
your password on github they do check it

556
00:19:11,159 --> 00:19:15,659
against this known breached passwords

557
00:19:14,159 --> 00:19:17,309
list and they won't let you set it if

558
00:19:15,659 --> 00:19:20,190
it's been something that has been seen

559
00:19:17,309 --> 00:19:21,418
in a previous data breach and if

560
00:19:20,190 --> 00:19:23,400
passwords aren't enough then you can

561
00:19:21,419 --> 00:19:24,630
start to add other layers there are a

562
00:19:23,400 --> 00:19:26,669
lot of ways that you can add additional

563
00:19:24,630 --> 00:19:29,370
factors for something like multi-factor

564
00:19:26,669 --> 00:19:31,049
authentication but once you do this it's

565
00:19:29,370 --> 00:19:32,549
not enough to just make an option for

566
00:19:31,049 --> 00:19:35,460
your users you actually have to get your

567
00:19:32,549 --> 00:19:37,500
users to turn it on and so you can make

568
00:19:35,460 --> 00:19:38,490
it mandatory but if you don't want to do

569
00:19:37,500 --> 00:19:39,929
that here are some of the strategies

570
00:19:38,490 --> 00:19:42,299
that we've seen that make it a bit

571
00:19:39,929 --> 00:19:43,950
easier for people to enable multi-factor

572
00:19:42,299 --> 00:19:45,750
authentication so if you put it in

573
00:19:43,950 --> 00:19:47,490
profile settings you're gonna see about

574
00:19:45,750 --> 00:19:49,440
two percent of users actually find that

575
00:19:47,490 --> 00:19:51,210
setting and turn it on if you make it

576
00:19:49,440 --> 00:19:53,190
part of the onboarding process and so

577
00:19:51,210 --> 00:19:54,900
maybe this is part of the login flow and

578
00:19:53,190 --> 00:19:56,429
you prompt them if they don't have MFA

579
00:19:54,900 --> 00:19:58,440
turned on just say hey do you want to

580
00:19:56,429 --> 00:20:00,210
turn on two-factor authentication then

581
00:19:58,440 --> 00:20:02,100
you see about 40 percent of users turn

582
00:20:00,210 --> 00:20:03,330
it on and of course if your company has

583
00:20:02,100 --> 00:20:06,000
see oh then you're getting a hundred

584
00:20:03,330 --> 00:20:07,889
percent of adoption but that's another

585
00:20:06,000 --> 00:20:09,360
example of like a situation where you're

586
00:20:07,890 --> 00:20:12,450
probably going to have more security

587
00:20:09,360 --> 00:20:14,550
conscious users anyway and you're making

588
00:20:12,450 --> 00:20:17,850
the value of them doing that we're worth

589
00:20:14,550 --> 00:20:19,740
their time um one thing that I do want

590
00:20:17,850 --> 00:20:21,389
to mention is that SMS 2fa gets a lot of

591
00:20:19,740 --> 00:20:24,270
crap but it's still a lot better than

592
00:20:21,390 --> 00:20:26,400
having no 2fa at all so this is another

593
00:20:24,270 --> 00:20:28,889
great example of the average case versus

594
00:20:26,400 --> 00:20:30,300
the worst case and talking about the

595
00:20:28,890 --> 00:20:33,090
different form factors of multi-factor

596
00:20:30,300 --> 00:20:35,600
authentication so we've heard these

597
00:20:33,090 --> 00:20:38,010
articles about how SMS is less secure

598
00:20:35,600 --> 00:20:40,860
but talking about the dangers of sim

599
00:20:38,010 --> 00:20:42,600
swapping and the ss7 vulnerabilities to

600
00:20:40,860 --> 00:20:44,159
the average user they're not gonna

601
00:20:42,600 --> 00:20:45,750
really understand what any of that means

602
00:20:44,160 --> 00:20:47,820
and that's just going to be another part

603
00:20:45,750 --> 00:20:51,300
of that you know security advice fatigue

604
00:20:47,820 --> 00:20:53,340
that people are facing so it probably

605
00:20:51,300 --> 00:20:55,169
doesn't matter to a lot of people so I

606
00:20:53,340 --> 00:20:57,120
wanted to talk about reddit in this

607
00:20:55,170 --> 00:20:58,770
context for a minute and so reddit had a

608
00:20:57,120 --> 00:21:01,320
security incident in August and they

609
00:20:58,770 --> 00:21:02,610
published this really nice report on

610
00:21:01,320 --> 00:21:03,929
what happened and basically what

611
00:21:02,610 --> 00:21:08,070
happened is that their employees

612
00:21:03,930 --> 00:21:11,430
accounts got compromised via an SMS to F

613
00:21:08,070 --> 00:21:13,379
a breach and so the solution that they

614
00:21:11,430 --> 00:21:15,420
had for this too is to require employees

615
00:21:13,380 --> 00:21:16,770
to have token-based authentication so

616
00:21:15,420 --> 00:21:18,480
just a more secure form of

617
00:21:16,770 --> 00:21:20,430
authentication and I think this is a

618
00:21:18,480 --> 00:21:23,340
great solution for them because one

619
00:21:20,430 --> 00:21:25,560
thing with employee accounts is that you

620
00:21:23,340 --> 00:21:29,040
can enforce that type of authentication

621
00:21:25,560 --> 00:21:30,780
it's easier to require a token base to

622
00:21:29,040 --> 00:21:32,790
FA for employees because you have an IT

623
00:21:30,780 --> 00:21:35,129
department that can physically hand them

624
00:21:32,790 --> 00:21:36,450
there you Baqi you are paying them and

625
00:21:35,130 --> 00:21:38,840
so they kind of have to do what you want

626
00:21:36,450 --> 00:21:40,800
them to do it's a different model of a

627
00:21:38,840 --> 00:21:43,560
relationship than you have with some of

628
00:21:40,800 --> 00:21:46,050
your customers and so that that makes it

629
00:21:43,560 --> 00:21:49,080
easier to require this stronger form of

630
00:21:46,050 --> 00:21:50,490
authentication moderators on reddit you

631
00:21:49,080 --> 00:21:52,320
might be thinking about how you could

632
00:21:50,490 --> 00:21:53,970
secure them there's somebody that spends

633
00:21:52,320 --> 00:21:56,189
a lot more time on the service and so

634
00:21:53,970 --> 00:21:57,930
they might see the value of turning

635
00:21:56,190 --> 00:21:58,920
something like this on again this is

636
00:21:57,930 --> 00:22:03,450
something that's gonna be a little bit

637
00:21:58,920 --> 00:22:04,680
more worth their time and finally for

638
00:22:03,450 --> 00:22:06,870
everyone else you might just make it an

639
00:22:04,680 --> 00:22:08,340
option for lurkers on the site or people

640
00:22:06,870 --> 00:22:11,399
that just casually comment you might not

641
00:22:08,340 --> 00:22:12,870
care if they actually enable 2fa and you

642
00:22:11,400 --> 00:22:14,520
can take this model and apply it to

643
00:22:12,870 --> 00:22:15,489
other industries and so if you work in

644
00:22:14,520 --> 00:22:16,720
banking you can start

645
00:22:15,490 --> 00:22:18,400
to think about how you might break this

646
00:22:16,720 --> 00:22:20,400
up with your customers by the level of

647
00:22:18,400 --> 00:22:22,150
money that they have in their account

648
00:22:20,400 --> 00:22:23,800
similarly you could do this for

649
00:22:22,150 --> 00:22:25,570
something like Twitter with verified

650
00:22:23,800 --> 00:22:28,360
accounts making token-based to FA

651
00:22:25,570 --> 00:22:29,740
required and then break it down by

652
00:22:28,360 --> 00:22:31,659
follower accounts if you have over a

653
00:22:29,740 --> 00:22:33,790
certain number of followers then make

654
00:22:31,660 --> 00:22:39,010
any kind of to FA required and for

655
00:22:33,790 --> 00:22:40,000
everyone else make it optional let's

656
00:22:39,010 --> 00:22:42,460
talk about some of those known weak

657
00:22:40,000 --> 00:22:44,620
points and how we can address them first

658
00:22:42,460 --> 00:22:46,300
for requests via a contact center so

659
00:22:44,620 --> 00:22:47,979
Patrick Mackenzie works at stripe and

660
00:22:46,300 --> 00:22:51,010
last week he had this great tweet about

661
00:22:47,980 --> 00:22:52,720
how stripe is using a new method of

662
00:22:51,010 --> 00:22:55,030
authentication and contact centers and

663
00:22:52,720 --> 00:22:56,530
so one of the problems with contact

664
00:22:55,030 --> 00:22:58,540
centers is that were often asking for

665
00:22:56,530 --> 00:23:00,879
identifiers x' instead of authenticators

666
00:22:58,540 --> 00:23:03,129
in that process and so you're always

667
00:23:00,880 --> 00:23:05,170
going to be asked or not always but

668
00:23:03,130 --> 00:23:06,400
surprising a number of times you're

669
00:23:05,170 --> 00:23:08,110
going to be asked for your social

670
00:23:06,400 --> 00:23:09,940
security number over the phone and that

671
00:23:08,110 --> 00:23:11,559
makes nobody happy you don't want to

672
00:23:09,940 --> 00:23:12,940
have to give that and so the solution

673
00:23:11,559 --> 00:23:14,800
that stripe came up with which i think

674
00:23:12,940 --> 00:23:16,780
is really clever is if you're on an

675
00:23:14,800 --> 00:23:19,090
authenticated web session you can

676
00:23:16,780 --> 00:23:21,399
basically pop up a token on that session

677
00:23:19,090 --> 00:23:23,320
and say hey if you want to try to call

678
00:23:21,400 --> 00:23:25,450
our customer support hotline here's the

679
00:23:23,320 --> 00:23:26,800
token that we're here we're going to be

680
00:23:25,450 --> 00:23:28,090
using the stripe agent we'll give you

681
00:23:26,800 --> 00:23:29,830
the first four numbers you'll give them

682
00:23:28,090 --> 00:23:32,110
the second four numbers and now you both

683
00:23:29,830 --> 00:23:33,820
have this understanding that you are who

684
00:23:32,110 --> 00:23:35,740
you say you are and that's a really a

685
00:23:33,820 --> 00:23:37,928
great way to do it it does require that

686
00:23:35,740 --> 00:23:40,360
the support agent and the customer both

687
00:23:37,929 --> 00:23:41,590
have authenticated the sessions so again

688
00:23:40,360 --> 00:23:43,209
it's like the trust waterfall that

689
00:23:41,590 --> 00:23:45,370
you're a hoping that somebody has that

690
00:23:43,210 --> 00:23:47,559
type of a that type of authenticated

691
00:23:45,370 --> 00:23:51,100
system available to them and you do have

692
00:23:47,559 --> 00:23:52,840
to do some coordination there and when

693
00:23:51,100 --> 00:23:56,409
it comes to account recovery the same

694
00:23:52,840 --> 00:23:58,570
idea applies so security questions are

695
00:23:56,410 --> 00:24:00,640
often a way that we do this for account

696
00:23:58,570 --> 00:24:02,409
recovery if you you know don't have

697
00:24:00,640 --> 00:24:03,160
access to the email or maybe your phone

698
00:24:02,410 --> 00:24:04,900
number anymore

699
00:24:03,160 --> 00:24:07,510
then you fall back to these ideas of

700
00:24:04,900 --> 00:24:09,130
these these security questions but you

701
00:24:07,510 --> 00:24:10,690
don't want to make these things that are

702
00:24:09,130 --> 00:24:12,910
identifiable you don't want to make

703
00:24:10,690 --> 00:24:15,670
these things that are available via open

704
00:24:12,910 --> 00:24:17,230
source intelligence so it's really easy

705
00:24:15,670 --> 00:24:19,660
for people to Google these things about

706
00:24:17,230 --> 00:24:21,040
you and so your Instagram account is

707
00:24:19,660 --> 00:24:23,410
giving away a lot more information than

708
00:24:21,040 --> 00:24:24,909
you realize especially if it's public so

709
00:24:23,410 --> 00:24:26,700
some of the better security questions

710
00:24:24,910 --> 00:24:28,470
that we have get into these various sip

711
00:24:26,700 --> 00:24:31,200
that aren't questions that are as easy

712
00:24:28,470 --> 00:24:33,360
to look up about a person so these can

713
00:24:31,200 --> 00:24:34,680
be things like what was the the name of

714
00:24:33,360 --> 00:24:37,679
the teacher who gave you your first

715
00:24:34,680 --> 00:24:39,240
failing grade so if you do have a

716
00:24:37,680 --> 00:24:40,440
situation where you need to use security

717
00:24:39,240 --> 00:24:42,390
questions and I know we all have

718
00:24:40,440 --> 00:24:43,590
different ideas about the usefulness of

719
00:24:42,390 --> 00:24:45,720
security questions but in large

720
00:24:43,590 --> 00:24:47,760
organizations these are often still a

721
00:24:45,720 --> 00:24:49,140
requirement but we want to be able to

722
00:24:47,760 --> 00:24:50,370
make the security questions that aren't

723
00:24:49,140 --> 00:24:54,090
something that we can easily Google

724
00:24:50,370 --> 00:24:55,469
about a person and finally we want to

725
00:24:54,090 --> 00:24:56,820
know if we did a good job this will be

726
00:24:55,470 --> 00:24:58,290
easier if you had these metrics at the

727
00:24:56,820 --> 00:24:59,820
beginning so make sure that you're

728
00:24:58,290 --> 00:25:02,010
setting your goals for yourself before

729
00:24:59,820 --> 00:25:03,810
you take on a project like this and

730
00:25:02,010 --> 00:25:07,110
examples of things that you might care

731
00:25:03,810 --> 00:25:09,090
about overall money loss due to account

732
00:25:07,110 --> 00:25:11,280
takeovers the number of compromised

733
00:25:09,090 --> 00:25:14,550
accounts that you're seeing support

734
00:25:11,280 --> 00:25:16,350
costs relative to the to account

735
00:25:14,550 --> 00:25:18,360
takeover losses you might not care about

736
00:25:16,350 --> 00:25:19,980
the total number of support tickets that

737
00:25:18,360 --> 00:25:22,169
are coming in if you're measuring the

738
00:25:19,980 --> 00:25:24,150
absolute value there because it might

739
00:25:22,170 --> 00:25:26,010
actually make more sense for you to have

740
00:25:24,150 --> 00:25:28,320
a higher number of support tickets if

741
00:25:26,010 --> 00:25:31,590
that's lowering your overall accounts

742
00:25:28,320 --> 00:25:33,510
account takeover losses and finally

743
00:25:31,590 --> 00:25:35,129
customer satisfaction I think you want

744
00:25:33,510 --> 00:25:36,690
to have a way of measuring this that

745
00:25:35,130 --> 00:25:40,920
also takes into account how annoyed

746
00:25:36,690 --> 00:25:42,090
customers are with this process so it's

747
00:25:40,920 --> 00:25:45,960
really easy to get depressed about this

748
00:25:42,090 --> 00:25:47,189
stuff I think as security people a lot

749
00:25:45,960 --> 00:25:49,980
of times we're dealing with this every

750
00:25:47,190 --> 00:25:51,720
day this is literally our livelihood so

751
00:25:49,980 --> 00:25:53,190
the time investment for us and thinking

752
00:25:51,720 --> 00:25:55,050
about this worst case scenario makes a

753
00:25:53,190 --> 00:25:56,640
lot more sense because one working in

754
00:25:55,050 --> 00:25:58,860
security we are inherently slightly

755
00:25:56,640 --> 00:26:01,200
higher targets but we also have this

756
00:25:58,860 --> 00:26:03,449
paranoia and sometimes doing all these

757
00:26:01,200 --> 00:26:04,950
things helps calm us helps calm her

758
00:26:03,450 --> 00:26:06,750
anxieties but that's one of the things

759
00:26:04,950 --> 00:26:08,550
that is a little bit more rational for

760
00:26:06,750 --> 00:26:10,380
us to deal with this and have all these

761
00:26:08,550 --> 00:26:12,090
security measures than it is for the

762
00:26:10,380 --> 00:26:13,290
average person so for somebody that's

763
00:26:12,090 --> 00:26:13,919
not always thinking about this stuff

764
00:26:13,290 --> 00:26:15,629
every day

765
00:26:13,920 --> 00:26:17,760
we don't want necessarily want to take

766
00:26:15,630 --> 00:26:20,910
all of our paranoia's and project it on

767
00:26:17,760 --> 00:26:22,140
to our friends and family so this is a

768
00:26:20,910 --> 00:26:24,960
story that has always stuck with me

769
00:26:22,140 --> 00:26:27,300
Kevin Roose is a tech reporter who asked

770
00:26:24,960 --> 00:26:29,160
two different hacking groups to attack

771
00:26:27,300 --> 00:26:31,320
him and they were incredibly successful

772
00:26:29,160 --> 00:26:33,150
and so he had somebody that was able to

773
00:26:31,320 --> 00:26:34,800
install malware on his system

774
00:26:33,150 --> 00:26:35,760
spyware on his system and then he had

775
00:26:34,800 --> 00:26:36,930
somebody that was able to really

776
00:26:35,760 --> 00:26:40,080
effectively attack him via social

777
00:26:36,930 --> 00:26:41,850
engineering but the conclusion of this

778
00:26:40,080 --> 00:26:44,250
story which I appreciated wasn't that

779
00:26:41,850 --> 00:26:45,840
we're all screwed it was that you know

780
00:26:44,250 --> 00:26:47,910
we have this idea of security through

781
00:26:45,840 --> 00:26:51,659
obscurity even a tech journalist like

782
00:26:47,910 --> 00:26:52,980
Kevin ruse the experts that he got to

783
00:26:51,660 --> 00:26:55,500
attack him aren't going to go through

784
00:26:52,980 --> 00:26:57,180
those measures for most people a lot of

785
00:26:55,500 --> 00:26:58,740
us are going to be in this situation

786
00:26:57,180 --> 00:27:00,900
when we're not going to necessarily have

787
00:26:58,740 --> 00:27:03,809
these types of sophisticated attacks

788
00:27:00,900 --> 00:27:05,520
employed against us if we always believe

789
00:27:03,809 --> 00:27:06,809
that Mossad was after us then we'd have

790
00:27:05,520 --> 00:27:09,059
to go back and live in that submarine

791
00:27:06,809 --> 00:27:12,000
and nobody would be happy and we'd all

792
00:27:09,059 --> 00:27:13,200
just you know be very miserable so

793
00:27:12,000 --> 00:27:15,420
finally the thing that I want to point

794
00:27:13,200 --> 00:27:17,670
out is just don't blame users try to

795
00:27:15,420 --> 00:27:18,660
avoid victim blaming and instead think

796
00:27:17,670 --> 00:27:20,010
about some of the tools that we

797
00:27:18,660 --> 00:27:21,870
discussed and the others that apply to

798
00:27:20,010 --> 00:27:23,850
your specific industries to make it

799
00:27:21,870 --> 00:27:26,939
easier for your customers to have good

800
00:27:23,850 --> 00:27:28,439
security hygiene I hope I've given you

801
00:27:26,940 --> 00:27:30,690
some inspiration for how to think about

802
00:27:28,440 --> 00:27:32,550
your authentication systems come find me

803
00:27:30,690 --> 00:27:34,440
after this if you have any questions my

804
00:27:32,550 --> 00:27:35,820
slides are available at that link once

805
00:27:34,440 --> 00:27:38,270
again my name is Kelly Robinson and

806
00:27:35,820 --> 00:27:38,270
thank you for listening

807
00:27:39,200 --> 00:27:42,469
[Applause]

808
00:27:49,299 --> 00:27:51,360
you

