1
00:00:00,880 --> 00:00:03,120
my name is thoma tofi i'm a senior data

2
00:00:03,120 --> 00:00:06,000
scientist uh with sofos and i'm here

3
00:00:06,000 --> 00:00:07,919
today to present to you one of the

4
00:00:07,919 --> 00:00:09,519
projects we've been working on within

5
00:00:09,519 --> 00:00:12,639
the soho ci group and that is automating

6
00:00:12,639 --> 00:00:15,040
false positive wacom mall with real-time

7
00:00:15,040 --> 00:00:17,199
behavioral analytics

8
00:00:17,199 --> 00:00:19,920
so before we jump into the presentation

9
00:00:19,920 --> 00:00:21,520
i would like to give a shout out to all

10
00:00:21,520 --> 00:00:23,279
my colleagues who have

11
00:00:23,279 --> 00:00:25,279
worked on the bigger effort that this

12
00:00:25,279 --> 00:00:27,599
project is part of

13
00:00:27,599 --> 00:00:30,640
involving data cleaning pre-processing

14
00:00:30,640 --> 00:00:32,320
labeling as well as

15
00:00:32,320 --> 00:00:34,559
research and anyways brainstorming ideas

16
00:00:34,559 --> 00:00:35,520
and such

17
00:00:35,520 --> 00:00:37,600
um so we have ben gellman

18
00:00:37,600 --> 00:00:40,399
denis vosnyuk dora sabo constantine

19
00:00:40,399 --> 00:00:41,440
berlin

20
00:00:41,440 --> 00:00:43,200
tamash varus who will actually be

21
00:00:43,200 --> 00:00:44,879
presenting another project this

22
00:00:44,879 --> 00:00:47,760
afternoon and uh last but not least

23
00:00:47,760 --> 00:00:50,559
victor hollow

24
00:00:50,559 --> 00:00:53,280
so before we dig into any details here's

25
00:00:53,280 --> 00:00:55,199
an outline so you have an idea about

26
00:00:55,199 --> 00:00:57,120
what we're going to be talking about

27
00:00:57,120 --> 00:00:58,960
so first we will go over the problem

28
00:00:58,960 --> 00:01:00,879
statement so what is it that we're

29
00:01:00,879 --> 00:01:02,800
trying to solve

30
00:01:02,800 --> 00:01:04,879
so we will explain briefly what a

31
00:01:04,879 --> 00:01:07,439
security operations center is sock for

32
00:01:07,439 --> 00:01:08,960
short

33
00:01:08,960 --> 00:01:11,040
as well as the problem of alert fatigue

34
00:01:11,040 --> 00:01:12,960
which is exactly what we set out to

35
00:01:12,960 --> 00:01:13,920
solve

36
00:01:13,920 --> 00:01:16,240
then we will go over our proposed

37
00:01:16,240 --> 00:01:18,159
solution which comes in the form of a

38
00:01:18,159 --> 00:01:19,759
machine learning model that uses

39
00:01:19,759 --> 00:01:22,000
historical contextual features to solve

40
00:01:22,000 --> 00:01:24,560
this problem and finally we will go over

41
00:01:24,560 --> 00:01:26,720
our evaluation setup and the results

42
00:01:26,720 --> 00:01:28,320
we've obtained

43
00:01:28,320 --> 00:01:30,400
so yeah what is

44
00:01:30,400 --> 00:01:32,159
the problem that we're trying to solve

45
00:01:32,159 --> 00:01:33,920
so first of all it's important to

46
00:01:33,920 --> 00:01:36,000
understand what a security operations

47
00:01:36,000 --> 00:01:38,640
center is that would be a stock

48
00:01:38,640 --> 00:01:40,960
so it's a unit that employs three main

49
00:01:40,960 --> 00:01:42,960
building blocks people processes and

50
00:01:42,960 --> 00:01:44,240
technology

51
00:01:44,240 --> 00:01:46,560
with the objective of defunding

52
00:01:46,560 --> 00:01:49,680
defending an organization from any cyber

53
00:01:49,680 --> 00:01:51,439
security threats and incidents that

54
00:01:51,439 --> 00:01:53,520
might be out there

55
00:01:53,520 --> 00:01:55,520
it's also worth mentioning that the saw

56
00:01:55,520 --> 00:01:57,840
can be tasked and concerned

57
00:01:57,840 --> 00:02:00,079
with defending the organization that it

58
00:02:00,079 --> 00:02:02,320
is part of or it can be offered as a

59
00:02:02,320 --> 00:02:04,560
service by one company to many other

60
00:02:04,560 --> 00:02:06,960
customer organizations that subscribe to

61
00:02:06,960 --> 00:02:08,959
this service so the soccer has to defend

62
00:02:08,959 --> 00:02:10,080
all of them

63
00:02:10,080 --> 00:02:12,160
um so just to give like a very generic

64
00:02:12,160 --> 00:02:15,120
um workflow of the sock first there are

65
00:02:15,120 --> 00:02:16,720
the customer endpoints so those are

66
00:02:16,720 --> 00:02:18,720
their machines desktops laptops

67
00:02:18,720 --> 00:02:21,280
everything and the stock works to

68
00:02:21,280 --> 00:02:23,920
collect that data so every single event

69
00:02:23,920 --> 00:02:25,920
that happens on those endpoints all the

70
00:02:25,920 --> 00:02:28,480
processes that are running everything

71
00:02:28,480 --> 00:02:31,680
is logged and um usually at the level of

72
00:02:31,680 --> 00:02:34,160
the data collection step they also unify

73
00:02:34,160 --> 00:02:37,200
that log the formats of these logs

74
00:02:37,200 --> 00:02:39,599
for easier processing down the line

75
00:02:39,599 --> 00:02:41,840
after that every single event that was

76
00:02:41,840 --> 00:02:44,959
locked now has to go through a phase of

77
00:02:44,959 --> 00:02:47,680
monitoring via security sensors or

78
00:02:47,680 --> 00:02:50,080
detectors and that's a layer of

79
00:02:50,080 --> 00:02:52,560
detectors those are usually

80
00:02:52,560 --> 00:02:55,440
rule-based or heuristic-based and

81
00:02:55,440 --> 00:02:57,360
they have been engineered to leverage

82
00:02:57,360 --> 00:02:59,519
the domain expertise of the security

83
00:02:59,519 --> 00:03:00,800
analysts

84
00:03:00,800 --> 00:03:04,159
in capturing what might be malicious

85
00:03:04,159 --> 00:03:06,400
now every single event that comes in has

86
00:03:06,400 --> 00:03:08,560
to go through these detectors and these

87
00:03:08,560 --> 00:03:10,560
detectors can be as simple as a rule

88
00:03:10,560 --> 00:03:11,599
that says

89
00:03:11,599 --> 00:03:13,680
if there's a process that is writing to

90
00:03:13,680 --> 00:03:15,920
multiple files within a very short time

91
00:03:15,920 --> 00:03:18,319
span then notify on that maybe there's a

92
00:03:18,319 --> 00:03:20,000
problem underway

93
00:03:20,000 --> 00:03:22,080
it can be so if maybe like there's a

94
00:03:22,080 --> 00:03:24,239
ransomware that's running or it can be

95
00:03:24,239 --> 00:03:26,319
just some network administrator who's

96
00:03:26,319 --> 00:03:28,959
trying to modify multiple uh files very

97
00:03:28,959 --> 00:03:32,000
quickly so these detectors really try to

98
00:03:32,000 --> 00:03:34,560
cast a wide net to capture even needle

99
00:03:34,560 --> 00:03:36,480
in the haystack attacks

100
00:03:36,480 --> 00:03:38,720
so after our locked events go through

101
00:03:38,720 --> 00:03:41,440
the security sensors we get alerts those

102
00:03:41,440 --> 00:03:43,120
are our events with some added

103
00:03:43,120 --> 00:03:45,360
information from the detectors and one

104
00:03:45,360 --> 00:03:46,959
of the most important things is the

105
00:03:46,959 --> 00:03:48,720
severity score

106
00:03:48,720 --> 00:03:50,640
that's a value given

107
00:03:50,640 --> 00:03:53,439
by the detector to the event saying that

108
00:03:53,439 --> 00:03:55,840
this is how bad i think this might be it

109
00:03:55,840 --> 00:03:57,599
can be a value from one to five one to

110
00:03:57,599 --> 00:03:58,640
ten

111
00:03:58,640 --> 00:04:01,519
whatever really the stock picks

112
00:04:01,519 --> 00:04:03,200
now once we have these alerts there's

113
00:04:03,200 --> 00:04:05,840
usually a thresholding step and that is

114
00:04:05,840 --> 00:04:08,159
where um this stock uses some

115
00:04:08,159 --> 00:04:10,640
empirically found threshold for instance

116
00:04:10,640 --> 00:04:12,319
if they have severity scores ranging

117
00:04:12,319 --> 00:04:14,879
from one to five they may pick three and

118
00:04:14,879 --> 00:04:17,040
so anything that gets the score that's

119
00:04:17,040 --> 00:04:19,199
higher than three requires analysts

120
00:04:19,199 --> 00:04:22,079
attention so after this thresholding we

121
00:04:22,079 --> 00:04:24,880
just keep those severe scores so for

122
00:04:24,880 --> 00:04:27,040
instance higher than three uh severe

123
00:04:27,040 --> 00:04:30,639
alerts and those are the ones that now

124
00:04:30,639 --> 00:04:32,560
the security analyst those are like

125
00:04:32,560 --> 00:04:34,479
humans it's their job to sit down and

126
00:04:34,479 --> 00:04:37,440
look at these to investigate um what

127
00:04:37,440 --> 00:04:39,280
happened before this event after this

128
00:04:39,280 --> 00:04:42,479
event is this really something bad or

129
00:04:42,479 --> 00:04:45,840
is it actually just legitimate activity

130
00:04:45,840 --> 00:04:46,960
now

131
00:04:46,960 --> 00:04:47,840
um

132
00:04:47,840 --> 00:04:49,600
it's important to think about the amount

133
00:04:49,600 --> 00:04:51,680
of data that the sock has to deal with

134
00:04:51,680 --> 00:04:54,160
so on any given day they get millions of

135
00:04:54,160 --> 00:04:55,440
events

136
00:04:55,440 --> 00:04:57,199
that they collect those come from all

137
00:04:57,199 --> 00:04:59,440
the endpoints of all their customers all

138
00:04:59,440 --> 00:05:00,960
around the world

139
00:05:00,960 --> 00:05:03,039
possibly and those might end up

140
00:05:03,039 --> 00:05:05,120
triggering tens of thousands of rules

141
00:05:05,120 --> 00:05:07,280
from the detectors and finally that

142
00:05:07,280 --> 00:05:08,720
leads to

143
00:05:08,720 --> 00:05:11,039
hundreds of to be inspected

144
00:05:11,039 --> 00:05:14,320
alerts with more than 50 of them being

145
00:05:14,320 --> 00:05:16,960
false alarms meaning that this is well

146
00:05:16,960 --> 00:05:18,800
documented by multiple studies and

147
00:05:18,800 --> 00:05:21,520
surveys that were done regarding socks

148
00:05:21,520 --> 00:05:23,759
and it means that

149
00:05:23,759 --> 00:05:25,919
because those detectors are cast in very

150
00:05:25,919 --> 00:05:27,680
wide nets even with the severity

151
00:05:27,680 --> 00:05:29,840
thresholding we end up with a lot of

152
00:05:29,840 --> 00:05:31,360
severe alerts

153
00:05:31,360 --> 00:05:33,600
that are actually nothing it was just

154
00:05:33,600 --> 00:05:35,759
someone doing their normal functions on

155
00:05:35,759 --> 00:05:37,680
the endpoints and nothing bad was

156
00:05:37,680 --> 00:05:40,560
happening there

157
00:05:40,960 --> 00:05:43,360
so this is precisely the issue here so

158
00:05:43,360 --> 00:05:45,280
that's what we call alert fatigue it's

159
00:05:45,280 --> 00:05:46,960
that the number of alerts that are

160
00:05:46,960 --> 00:05:49,600
generated far exceeds security analyst

161
00:05:49,600 --> 00:05:51,680
capacity to deal with them and that

162
00:05:51,680 --> 00:05:53,759
makes their job absolutely exhausting

163
00:05:53,759 --> 00:05:56,160
and demotivating

164
00:05:56,160 --> 00:05:59,440
so in order to illustrate this here's um

165
00:05:59,440 --> 00:06:01,919
over a one-month period from march 2022

166
00:06:01,919 --> 00:06:05,120
to april 2022 and every single bar here

167
00:06:05,120 --> 00:06:07,600
represents the alert uh count for that

168
00:06:07,600 --> 00:06:10,319
day um we are not disclosing the exact

169
00:06:10,319 --> 00:06:11,919
values because we consider that

170
00:06:11,919 --> 00:06:14,240
sensitive data but the most important

171
00:06:14,240 --> 00:06:16,560
takeaway from this plot is as you can

172
00:06:16,560 --> 00:06:18,880
see for from each bar for every single

173
00:06:18,880 --> 00:06:22,479
day the dark orange part is very tiny

174
00:06:22,479 --> 00:06:24,240
compared to the light orange part and

175
00:06:24,240 --> 00:06:26,560
the light orange are those false alarms

176
00:06:26,560 --> 00:06:29,039
so all of these the height of these bars

177
00:06:29,039 --> 00:06:30,960
is the amount of work that the analysts

178
00:06:30,960 --> 00:06:32,240
have to put

179
00:06:32,240 --> 00:06:34,000
that's the amount of alert counts that

180
00:06:34,000 --> 00:06:35,440
they get

181
00:06:35,440 --> 00:06:38,240
but only a small proportion of those are

182
00:06:38,240 --> 00:06:40,000
actually um

183
00:06:40,000 --> 00:06:42,479
real threats that they should be looking

184
00:06:42,479 --> 00:06:45,280
into so analysts time and energy is

185
00:06:45,280 --> 00:06:47,280
actually wasted on this deluge of

186
00:06:47,280 --> 00:06:51,120
irrelevant noise and that leaves uh that

187
00:06:51,120 --> 00:06:53,759
that runs the risk of actual threats

188
00:06:53,759 --> 00:06:55,360
going unnoticed

189
00:06:55,360 --> 00:06:57,919
and for us we think that determining

190
00:06:57,919 --> 00:07:00,080
which alerts and incidents can be

191
00:07:00,080 --> 00:07:02,880
ignored so reducing that light shaded

192
00:07:02,880 --> 00:07:05,520
area is as crucial as deciding which

193
00:07:05,520 --> 00:07:07,759
ones are actually important and worth

194
00:07:07,759 --> 00:07:09,919
investigating

195
00:07:09,919 --> 00:07:11,759
so our proposed solution comes in the

196
00:07:11,759 --> 00:07:14,000
form of an intelligent safeguard system

197
00:07:14,000 --> 00:07:16,560
a temporal model that uses machine

198
00:07:16,560 --> 00:07:17,919
learning

199
00:07:17,919 --> 00:07:20,240
to really distill the critical alerts

200
00:07:20,240 --> 00:07:23,599
and suppress the false alarms and

201
00:07:23,599 --> 00:07:24,800
this

202
00:07:24,800 --> 00:07:27,440
this model can be implemented on top of

203
00:07:27,440 --> 00:07:29,680
existing detection pipelines because it

204
00:07:29,680 --> 00:07:32,080
acts on alerts so regardless of what

205
00:07:32,080 --> 00:07:34,560
detectors asoc may have they can benefit

206
00:07:34,560 --> 00:07:36,319
from such a solution

207
00:07:36,319 --> 00:07:38,000
and this

208
00:07:38,000 --> 00:07:40,800
model is supposed to act as a shield so

209
00:07:40,800 --> 00:07:41,919
it acts

210
00:07:41,919 --> 00:07:44,000
it comes between the severe incoming

211
00:07:44,000 --> 00:07:46,000
alerts and the analysts and is supposed

212
00:07:46,000 --> 00:07:48,560
to really act as a filtering funnel

213
00:07:48,560 --> 00:07:50,479
where we get all of that

214
00:07:50,479 --> 00:07:52,319
all of the incoming alerts with the

215
00:07:52,319 --> 00:07:54,240
noise that's there and the false alarms

216
00:07:54,240 --> 00:07:55,919
and everything and we really try to

217
00:07:55,919 --> 00:07:59,840
bubble up those interesting cases

218
00:08:01,520 --> 00:08:03,680
so the pipeline is very simple like i

219
00:08:03,680 --> 00:08:06,400
say we are acting on severe alerts so

220
00:08:06,400 --> 00:08:09,280
that's that's our starting point after

221
00:08:09,280 --> 00:08:11,599
that we extract some features build our

222
00:08:11,599 --> 00:08:13,840
feature vectors pass them through an

223
00:08:13,840 --> 00:08:16,560
extreme boost model which scores them

224
00:08:16,560 --> 00:08:18,800
and those scores can be later used

225
00:08:18,800 --> 00:08:20,879
either to eliminate false positives if

226
00:08:20,879 --> 00:08:23,599
we find a good threshold for that or to

227
00:08:23,599 --> 00:08:26,400
prioritize alerts

228
00:08:26,400 --> 00:08:28,960
by importance so that analysts know that

229
00:08:28,960 --> 00:08:30,879
what's on top what they see at the top

230
00:08:30,879 --> 00:08:32,880
are actually the important alerts and

231
00:08:32,880 --> 00:08:35,120
what's at the bottom is actually quite

232
00:08:35,120 --> 00:08:37,360
low priority

233
00:08:37,360 --> 00:08:39,200
so the most important step here is the

234
00:08:39,200 --> 00:08:41,360
feature extraction part so

235
00:08:41,360 --> 00:08:43,839
we are computing features over different

236
00:08:43,839 --> 00:08:46,240
time windows so ranging from one second

237
00:08:46,240 --> 00:08:47,600
up to a week

238
00:08:47,600 --> 00:08:50,240
we also do we also compute them on the

239
00:08:50,240 --> 00:08:52,320
basis of a variety of predicates so we

240
00:08:52,320 --> 00:08:54,399
have features that are computed on a

241
00:08:54,399 --> 00:08:57,839
customer base or an endpoint base or a

242
00:08:57,839 --> 00:08:59,519
detector base

243
00:08:59,519 --> 00:09:02,320
as an example here are some like two of

244
00:09:02,320 --> 00:09:05,120
the many features we compute so we can

245
00:09:05,120 --> 00:09:07,120
capture the number of customers for

246
00:09:07,120 --> 00:09:09,519
which a given detector has fired over

247
00:09:09,519 --> 00:09:12,240
the previous hour or minute or whatever

248
00:09:12,240 --> 00:09:14,160
time window and

249
00:09:14,160 --> 00:09:15,120
as well

250
00:09:15,120 --> 00:09:17,200
as the for example the number of alerts

251
00:09:17,200 --> 00:09:19,200
that were encountered on a given

252
00:09:19,200 --> 00:09:21,680
endpoint over the previous day

253
00:09:21,680 --> 00:09:24,080
so we are trying to design these

254
00:09:24,080 --> 00:09:26,160
features such that they can capture

255
00:09:26,160 --> 00:09:29,200
signals like the endpoint vulnerability

256
00:09:29,200 --> 00:09:31,519
uh the customary state size and detector

257
00:09:31,519 --> 00:09:34,080
firing behavior patterns so i don't know

258
00:09:34,080 --> 00:09:36,080
for instance there's like a new detector

259
00:09:36,080 --> 00:09:38,080
that was added to the appliances that

260
00:09:38,080 --> 00:09:39,920
are already there it can happen that

261
00:09:39,920 --> 00:09:42,720
this detector was too broad of a rule or

262
00:09:42,720 --> 00:09:45,440
just poorly tuned human error these

263
00:09:45,440 --> 00:09:48,000
things happen and so as soon as that

264
00:09:48,000 --> 00:09:51,040
detector is uh deployed it just starts

265
00:09:51,040 --> 00:09:52,880
firing across all of the customer

266
00:09:52,880 --> 00:09:54,640
estates

267
00:09:54,640 --> 00:09:56,560
across all the customer base all around

268
00:09:56,560 --> 00:09:58,560
the world so we are it's really

269
00:09:58,560 --> 00:10:00,560
important for us to capture these things

270
00:10:00,560 --> 00:10:03,600
to be able to tell whether um after

271
00:10:03,600 --> 00:10:05,200
anchoring this alert in the global

272
00:10:05,200 --> 00:10:08,959
context is it actually important or not

273
00:10:08,959 --> 00:10:09,760
and

274
00:10:09,760 --> 00:10:12,079
in order to evaluate how

275
00:10:12,079 --> 00:10:14,800
how this system fares we have taken a

276
00:10:14,800 --> 00:10:16,399
data set of

277
00:10:16,399 --> 00:10:19,360
real enterprise alerts uh from

278
00:10:19,360 --> 00:10:21,440
sofos and we collected those in

279
00:10:21,440 --> 00:10:23,200
collaboration with security and data

280
00:10:23,200 --> 00:10:25,920
analysts to really inline the labeling

281
00:10:25,920 --> 00:10:29,200
and have a clean data set

282
00:10:29,200 --> 00:10:31,680
and the data set ranges over a six month

283
00:10:31,680 --> 00:10:34,079
period and we do a time split so we take

284
00:10:34,079 --> 00:10:36,160
the five first months of that data and

285
00:10:36,160 --> 00:10:38,320
that would be our training set so it

286
00:10:38,320 --> 00:10:39,680
ranges from

287
00:10:39,680 --> 00:10:43,040
october 2021 to march 2022 and then we

288
00:10:43,040 --> 00:10:46,720
have our test set from march 2022 uh to

289
00:10:46,720 --> 00:10:49,839
april 2022 and these alerts come from

290
00:10:49,839 --> 00:10:53,760
over 3 000 customers uh and over 15 000

291
00:10:53,760 --> 00:10:56,160
endpoints or hosts

292
00:10:56,160 --> 00:10:58,160
on the left-hand side we can look at the

293
00:10:58,160 --> 00:11:00,800
labor label distribution for the two

294
00:11:00,800 --> 00:11:03,200
sets so for the training and the test uh

295
00:11:03,200 --> 00:11:05,279
we can readily see that there the

296
00:11:05,279 --> 00:11:09,040
positives are a smaller proportion um

297
00:11:09,040 --> 00:11:11,120
than the negatives meaning this also

298
00:11:11,120 --> 00:11:12,640
points out to the problem that we were

299
00:11:12,640 --> 00:11:14,720
talking about that these severe alerts

300
00:11:14,720 --> 00:11:15,760
that the

301
00:11:15,760 --> 00:11:17,519
analysts have to look through most of

302
00:11:17,519 --> 00:11:21,519
them are actually uh nothing

303
00:11:22,000 --> 00:11:24,240
and in order for us to evaluate this

304
00:11:24,240 --> 00:11:26,640
model we look at uh two we try to look

305
00:11:26,640 --> 00:11:28,240
at two different aspects so we try to

306
00:11:28,240 --> 00:11:30,000
look at the classification performance

307
00:11:30,000 --> 00:11:32,399
using metrics such as the receiver

308
00:11:32,399 --> 00:11:35,920
operating uh characteristics or rock auc

309
00:11:35,920 --> 00:11:38,320
area under curve precision recall as

310
00:11:38,320 --> 00:11:40,240
well as we try to simulate the

311
00:11:40,240 --> 00:11:43,279
deployment of this system to see how it

312
00:11:43,279 --> 00:11:45,519
would impact that workload

313
00:11:45,519 --> 00:11:47,279
of analysts

314
00:11:47,279 --> 00:11:49,680
so first looking at the rock curve so

315
00:11:49,680 --> 00:11:52,480
the raw curve plots the true positive

316
00:11:52,480 --> 00:11:55,519
rate versus the false positive rate and

317
00:11:55,519 --> 00:11:57,040
it does so at different decision

318
00:11:57,040 --> 00:11:59,839
thresholds so what that means is so our

319
00:11:59,839 --> 00:12:03,920
model so our temporal model outputs um

320
00:12:03,920 --> 00:12:05,839
prediction probabilities so values from

321
00:12:05,839 --> 00:12:08,639
zero to one that capture how

322
00:12:08,639 --> 00:12:09,519
what the

323
00:12:09,519 --> 00:12:11,440
how probable the model thinks a

324
00:12:11,440 --> 00:12:13,680
particular severe alert is worth an

325
00:12:13,680 --> 00:12:15,200
analyst time

326
00:12:15,200 --> 00:12:16,560
and

327
00:12:16,560 --> 00:12:17,920
you can pick different decision

328
00:12:17,920 --> 00:12:20,880
thresholds to say to to translate that

329
00:12:20,880 --> 00:12:22,639
prediction probability value to a

330
00:12:22,639 --> 00:12:24,800
decision that yes this is important or

331
00:12:24,800 --> 00:12:27,360
no this is not important

332
00:12:27,360 --> 00:12:29,920
so with the raw curve we can plot at

333
00:12:29,920 --> 00:12:32,480
every single possible decision threshold

334
00:12:32,480 --> 00:12:34,800
value our true positive rate and false

335
00:12:34,800 --> 00:12:37,920
positive rate and the summary or the

336
00:12:37,920 --> 00:12:39,839
most important one of the most important

337
00:12:39,839 --> 00:12:41,760
measures within the raw curve is what we

338
00:12:41,760 --> 00:12:44,399
call the auc that's the area under curve

339
00:12:44,399 --> 00:12:47,200
literally the area between the curve and

340
00:12:47,200 --> 00:12:50,079
the x-axis and the closer to when we are

341
00:12:50,079 --> 00:12:52,480
the better we're doing now in the in

342
00:12:52,480 --> 00:12:54,800
purple in the diagonal line we have the

343
00:12:54,800 --> 00:12:57,200
current situation where there is no

344
00:12:57,200 --> 00:12:59,040
model that's deployed and every single

345
00:12:59,040 --> 00:13:01,680
severe alert analysts have to look at it

346
00:13:01,680 --> 00:13:04,240
and that's a 50 auc

347
00:13:04,240 --> 00:13:06,240
as opposed to that with our temporal

348
00:13:06,240 --> 00:13:09,440
model we are able to reach a an 81 on

349
00:13:09,440 --> 00:13:12,720
this particular data set um auc so we're

350
00:13:12,720 --> 00:13:14,959
doing like much better and we this model

351
00:13:14,959 --> 00:13:18,480
is able to really um um

352
00:13:18,480 --> 00:13:20,160
to really distinguish between the

353
00:13:20,160 --> 00:13:23,040
positives and the negatives

354
00:13:23,040 --> 00:13:25,360
the other plot is also a rock curve but

355
00:13:25,360 --> 00:13:27,200
it's a precision recall curve so it

356
00:13:27,200 --> 00:13:28,639
plots precision

357
00:13:28,639 --> 00:13:31,760
versus recall precision is the positive

358
00:13:31,760 --> 00:13:33,920
predictive value and it basically tells

359
00:13:33,920 --> 00:13:36,160
us out of everything that the model

360
00:13:36,160 --> 00:13:38,480
thought was a positive

361
00:13:38,480 --> 00:13:40,320
how many of those were correct so it

362
00:13:40,320 --> 00:13:42,720
captures this measure and recall is

363
00:13:42,720 --> 00:13:44,560
essentially the same as true positive

364
00:13:44,560 --> 00:13:45,760
rate

365
00:13:45,760 --> 00:13:47,920
and here we can see that we are able to

366
00:13:47,920 --> 00:13:51,920
reach an auc of 0.63 and at any even

367
00:13:51,920 --> 00:13:53,839
higher recall values we are able to

368
00:13:53,839 --> 00:13:55,760
reach a precision that is much higher

369
00:13:55,760 --> 00:13:58,959
than the current uh situation with its

370
00:13:58,959 --> 00:14:02,800
baseline precision being just 30 percent

371
00:14:02,800 --> 00:14:06,000
now in order to look at this in a more

372
00:14:06,000 --> 00:14:08,320
tangible way to illustrate what we are

373
00:14:08,320 --> 00:14:10,959
doing here's a similar plot to the one

374
00:14:10,959 --> 00:14:13,199
we've seen earlier earlier we've seen

375
00:14:13,199 --> 00:14:15,519
without the model what the daily life of

376
00:14:15,519 --> 00:14:18,399
analysts look like and that's the orange

377
00:14:18,399 --> 00:14:21,360
scenario here and in blue we have with

378
00:14:21,360 --> 00:14:23,920
our model implemented what the reality

379
00:14:23,920 --> 00:14:26,320
would look like so we can see the first

380
00:14:26,320 --> 00:14:28,399
striking thing is that on that one month

381
00:14:28,399 --> 00:14:30,959
of data the alert volume for every

382
00:14:30,959 --> 00:14:33,120
single day is much

383
00:14:33,120 --> 00:14:36,399
lower with our model deployed so

384
00:14:36,399 --> 00:14:39,040
we can say undoubtedly that yes we are

385
00:14:39,040 --> 00:14:41,040
able to reduce the amount of work that

386
00:14:41,040 --> 00:14:42,720
analysts have to do

387
00:14:42,720 --> 00:14:45,760
but the striking thing is that we are

388
00:14:45,760 --> 00:14:48,399
able to do that while capturing most of

389
00:14:48,399 --> 00:14:50,560
the relevant alerts so whatever we do to

390
00:14:50,560 --> 00:14:53,760
reduce the alert volume comes at the

391
00:14:53,760 --> 00:14:56,160
expense of default alarms and that can

392
00:14:56,160 --> 00:14:58,959
be seen here by comparing the dark

393
00:14:58,959 --> 00:15:01,120
orange and the dark blue so those on

394
00:15:01,120 --> 00:15:02,720
most days meet

395
00:15:02,720 --> 00:15:04,160
and that means that those are the

396
00:15:04,160 --> 00:15:05,839
critical alerts and we are able to

397
00:15:05,839 --> 00:15:08,160
capture them as opposed to that for the

398
00:15:08,160 --> 00:15:10,240
lighter orange and lighter blue those

399
00:15:10,240 --> 00:15:12,800
are the false alarms so we are able with

400
00:15:12,800 --> 00:15:14,160
our model to

401
00:15:14,160 --> 00:15:16,560
to reduce those significantly

402
00:15:16,560 --> 00:15:19,040
uh especially on days like the fourth

403
00:15:19,040 --> 00:15:20,880
from there from the left and the fourth

404
00:15:20,880 --> 00:15:23,040
from the right as well where we can see

405
00:15:23,040 --> 00:15:25,360
that those were days where there was

406
00:15:25,360 --> 00:15:27,279
catastrophic false positives so there

407
00:15:27,279 --> 00:15:29,279
are some extremely high peaks of false

408
00:15:29,279 --> 00:15:31,040
alarms upon

409
00:15:31,040 --> 00:15:33,519
analyzing such days we found that

410
00:15:33,519 --> 00:15:36,079
usually it's indeed a poorly tuned

411
00:15:36,079 --> 00:15:38,880
detector that just starts firing over

412
00:15:38,880 --> 00:15:41,279
many customers estates or one specific

413
00:15:41,279 --> 00:15:43,759
customer or maybe there was some network

414
00:15:43,759 --> 00:15:45,839
administrator who was doing some tasks

415
00:15:45,839 --> 00:15:47,839
on that particular day and just the

416
00:15:47,839 --> 00:15:50,240
detectors may have gone crazy

417
00:15:50,240 --> 00:15:52,160
on it and we can see that on those

418
00:15:52,160 --> 00:15:54,320
particular day where it's very crucial

419
00:15:54,320 --> 00:15:56,639
to reduce the alert volume our model is

420
00:15:56,639 --> 00:15:59,199
really able to do that

421
00:15:59,199 --> 00:16:01,519
to have a slightly different perspective

422
00:16:01,519 --> 00:16:02,800
on the same

423
00:16:02,800 --> 00:16:05,279
points on the same data points we can

424
00:16:05,279 --> 00:16:08,639
look at specifically the percentage of

425
00:16:08,639 --> 00:16:10,399
false alarms that we're reducing that's

426
00:16:10,399 --> 00:16:13,040
the gray bars and on average every day

427
00:16:13,040 --> 00:16:15,440
we remove about 40 percent of the false

428
00:16:15,440 --> 00:16:16,560
alarms

429
00:16:16,560 --> 00:16:18,320
at the same time we can look at the blue

430
00:16:18,320 --> 00:16:20,079
bars and that would be

431
00:16:20,079 --> 00:16:22,480
the recall or the detection rate or the

432
00:16:22,480 --> 00:16:24,560
true positive rate and it's quite high

433
00:16:24,560 --> 00:16:27,360
on every day and we are able to tune uh

434
00:16:27,360 --> 00:16:30,079
the threshold that we pick for our model

435
00:16:30,079 --> 00:16:34,240
to be able to improve upon this recall

436
00:16:34,240 --> 00:16:36,959
now to take a look at what these the

437
00:16:36,959 --> 00:16:40,160
model scores mean when taken in contrast

438
00:16:40,160 --> 00:16:40,880
to

439
00:16:40,880 --> 00:16:45,199
analysts notes we can we have ranked by

440
00:16:45,199 --> 00:16:47,519
the prediction probabilities of the

441
00:16:47,519 --> 00:16:48,959
model

442
00:16:48,959 --> 00:16:51,360
the alerts that we've uh that were on

443
00:16:51,360 --> 00:16:54,240
our test set and if we take the top we

444
00:16:54,240 --> 00:16:56,480
see those are the the alerts that the

445
00:16:56,480 --> 00:16:58,480
model is quite confident that those are

446
00:16:58,480 --> 00:17:00,320
important those are relevant and should

447
00:17:00,320 --> 00:17:01,600
be looked at

448
00:17:01,600 --> 00:17:04,000
and we can compare them to the analyst

449
00:17:04,000 --> 00:17:06,079
notes and here we see just from the

450
00:17:06,079 --> 00:17:08,000
sheer length of these notes that there

451
00:17:08,000 --> 00:17:08,959
has

452
00:17:08,959 --> 00:17:10,720
there was some work done by analysts

453
00:17:10,720 --> 00:17:12,880
they had to do an investigation and then

454
00:17:12,880 --> 00:17:16,640
analysis to really look at this data

455
00:17:16,640 --> 00:17:19,599
as opposed to that we can look at the lo

456
00:17:19,599 --> 00:17:21,520
the ones that got a very very low

457
00:17:21,520 --> 00:17:24,400
probability uh from the model and those

458
00:17:24,400 --> 00:17:27,039
are actually the true negatives those

459
00:17:27,039 --> 00:17:29,360
are truly things that are just noise and

460
00:17:29,360 --> 00:17:31,520
if we look at here the analyst notes we

461
00:17:31,520 --> 00:17:33,600
can see that they just write oh this is

462
00:17:33,600 --> 00:17:36,080
benign activity or wait this is known fp

463
00:17:36,080 --> 00:17:38,160
we've seen this before it's a false

464
00:17:38,160 --> 00:17:40,720
positive we know it so they had to do

465
00:17:40,720 --> 00:17:42,799
some looking into this alert but then

466
00:17:42,799 --> 00:17:44,799
they realized okay there's nothing here

467
00:17:44,799 --> 00:17:47,760
so the model is able to find those um in

468
00:17:47,760 --> 00:17:50,559
the third um in the third alert here we

469
00:17:50,559 --> 00:17:52,720
can see that although they had to do

470
00:17:52,720 --> 00:17:54,640
they were not sure they they hadn't seen

471
00:17:54,640 --> 00:17:56,320
this before and they have to do some

472
00:17:56,320 --> 00:17:59,280
investigation it said um it says then

473
00:17:59,280 --> 00:18:01,200
that based on this evidence we believe

474
00:18:01,200 --> 00:18:03,919
this to be a false positive so the model

475
00:18:03,919 --> 00:18:07,440
was able to also capture this one

476
00:18:07,440 --> 00:18:10,240
now in order to look at those critical

477
00:18:10,240 --> 00:18:12,559
cases the uh the critical alerts that we

478
00:18:12,559 --> 00:18:14,240
are missing

479
00:18:14,240 --> 00:18:15,919
because maybe we need to tune the

480
00:18:15,919 --> 00:18:18,720
threshold higher and such

481
00:18:18,720 --> 00:18:20,400
we can look at these and these are the

482
00:18:20,400 --> 00:18:22,400
false negatives so these are

483
00:18:22,400 --> 00:18:24,320
things that are critical but the model

484
00:18:24,320 --> 00:18:26,160
is not so confident in that they are

485
00:18:26,160 --> 00:18:27,440
critical

486
00:18:27,440 --> 00:18:30,240
and if we look at the notes here so yes

487
00:18:30,240 --> 00:18:32,559
analysts had to do some investigation

488
00:18:32,559 --> 00:18:34,480
but for most of the notes from our

489
00:18:34,480 --> 00:18:36,320
analysis of these

490
00:18:36,320 --> 00:18:38,240
they contacted the customer to double

491
00:18:38,240 --> 00:18:40,160
check that it wasn't some pen testing

492
00:18:40,160 --> 00:18:42,400
that they were doing or anything but the

493
00:18:42,400 --> 00:18:44,559
customer never responded so we couldn't

494
00:18:44,559 --> 00:18:46,320
really say whether these were bad or

495
00:18:46,320 --> 00:18:48,000
good so we just

496
00:18:48,000 --> 00:18:50,640
so the model was also a bit

497
00:18:50,640 --> 00:18:52,720
doubtful for these ones

498
00:18:52,720 --> 00:18:55,200
but in order for us to close the gap on

499
00:18:55,200 --> 00:18:57,840
these false negatives we are working on

500
00:18:57,840 --> 00:19:00,640
tuning this model on monitoring it uh

501
00:19:00,640 --> 00:19:02,720
every single week and retraining it on

502
00:19:02,720 --> 00:19:05,760
new data but we are also working on a

503
00:19:05,760 --> 00:19:08,240
different model and that's actually one

504
00:19:08,240 --> 00:19:10,559
of the next steps that we are

505
00:19:10,559 --> 00:19:12,880
actually already started doing so we are

506
00:19:12,880 --> 00:19:14,960
looking to take this model that takes

507
00:19:14,960 --> 00:19:16,720
contextual data

508
00:19:16,720 --> 00:19:19,440
and fuse it or combine it with a model

509
00:19:19,440 --> 00:19:21,520
that actually looks as looks at the

510
00:19:21,520 --> 00:19:23,679
alert themselves so then we have two

511
00:19:23,679 --> 00:19:26,240
orthogonal models using orthogonal

512
00:19:26,240 --> 00:19:28,640
signals and maybe we by combining them

513
00:19:28,640 --> 00:19:31,600
we are able to reach even to get even

514
00:19:31,600 --> 00:19:34,080
better results and actually so far our

515
00:19:34,080 --> 00:19:36,000
results our experimental results have

516
00:19:36,000 --> 00:19:38,240
shown that we are able to have a much

517
00:19:38,240 --> 00:19:40,720
higher rock auc with this ensemble

518
00:19:40,720 --> 00:19:44,240
sometimes by plus uh seven percent

519
00:19:44,240 --> 00:19:47,039
and like i said uh this is a an ongoing

520
00:19:47,039 --> 00:19:48,960
project so we are continuously

521
00:19:48,960 --> 00:19:52,000
monitoring the results uh week by week

522
00:19:52,000 --> 00:19:54,240
because we are also working on inline in

523
00:19:54,240 --> 00:19:56,480
the labeling and such so we really want

524
00:19:56,480 --> 00:19:58,720
to we really want to keep monitoring how

525
00:19:58,720 --> 00:20:00,640
the model is doing as the detector

526
00:20:00,640 --> 00:20:03,840
technology evolves and changes over time

527
00:20:03,840 --> 00:20:06,799
and finally we are working on a research

528
00:20:06,799 --> 00:20:10,000
paper that we want to publish

529
00:20:10,000 --> 00:20:12,080
this year hopefully that would summarize

530
00:20:12,080 --> 00:20:14,000
all of our results with the stateful

531
00:20:14,000 --> 00:20:16,240
model that uses information from the

532
00:20:16,240 --> 00:20:18,320
alerts and this model that uses

533
00:20:18,320 --> 00:20:21,280
information from the context

534
00:20:21,280 --> 00:20:24,400
so yeah finally to conclude um the the

535
00:20:24,400 --> 00:20:26,640
current detector technology appliances

536
00:20:26,640 --> 00:20:28,799
are rule-based and heuristic based as

537
00:20:28,799 --> 00:20:30,559
we've said earlier so they are

538
00:20:30,559 --> 00:20:33,039
notoriously error-prone so

539
00:20:33,039 --> 00:20:35,280
the consequence of this is that it ends

540
00:20:35,280 --> 00:20:38,080
up being super time consuming exhausting

541
00:20:38,080 --> 00:20:40,000
and very expensive for security

542
00:20:40,000 --> 00:20:42,640
operators to manually investigate every

543
00:20:42,640 --> 00:20:44,480
single incoming alert

544
00:20:44,480 --> 00:20:46,799
so we propose a system that can be

545
00:20:46,799 --> 00:20:49,280
implemented agnostically and regardless

546
00:20:49,280 --> 00:20:52,240
of the existing detection workflows and

547
00:20:52,240 --> 00:20:54,640
uh can automatically reduce the amount

548
00:20:54,640 --> 00:20:57,760
of to be inspected alerts while ensuring

549
00:20:57,760 --> 00:20:59,600
that the really critical ones are

550
00:20:59,600 --> 00:21:01,520
brought to analysts attention and are

551
00:21:01,520 --> 00:21:02,880
bubbled up

552
00:21:02,880 --> 00:21:05,679
and while doing so it ensures that a

553
00:21:05,679 --> 00:21:08,000
significant portion of the time wasting

554
00:21:08,000 --> 00:21:10,559
for false alarms are actually

555
00:21:10,559 --> 00:21:12,960
eliminated

556
00:21:12,960 --> 00:21:15,840
um so yeah that was that was that uh

557
00:21:15,840 --> 00:21:17,840
thank you very much and yeah if you have

558
00:21:17,840 --> 00:21:19,360
any questions or want to learn more

559
00:21:19,360 --> 00:21:22,240
about what we do at sophos ai please

560
00:21:22,240 --> 00:21:25,280
ping me or yeah check out our micro site

561
00:21:25,280 --> 00:21:27,210
so thank you very much

562
00:21:27,210 --> 00:21:36,500
[Applause]

563
00:21:39,360 --> 00:21:42,678
many thanks

564
00:21:52,400 --> 00:21:53,760
anybody with

565
00:21:53,760 --> 00:21:55,039
any

566
00:21:55,039 --> 00:21:57,360
question at this time

567
00:21:57,360 --> 00:21:59,600
the contact information is up on the

568
00:21:59,600 --> 00:22:01,280
screen we have a question there just a

569
00:22:01,280 --> 00:22:04,600
moment please

570
00:22:12,559 --> 00:22:15,440
um i really enjoyed your presentation

571
00:22:15,440 --> 00:22:17,039
and i have a question

572
00:22:17,039 --> 00:22:19,760
that what's the trait or what's that

573
00:22:19,760 --> 00:22:22,720
point where you say that this model can

574
00:22:22,720 --> 00:22:25,600
be applied and

575
00:22:25,600 --> 00:22:29,600
used to reduce the false positives

576
00:22:29,600 --> 00:22:31,760
and grant that

577
00:22:31,760 --> 00:22:32,640
the

578
00:22:32,640 --> 00:22:33,840
possible

579
00:22:33,840 --> 00:22:37,039
false negatives

580
00:22:37,039 --> 00:22:41,840
yes the post negatives are

581
00:22:41,919 --> 00:22:43,039
biased

582
00:22:43,039 --> 00:22:44,640
and

583
00:22:44,640 --> 00:22:46,880
take that

584
00:22:46,880 --> 00:22:49,600
risk to

585
00:22:52,799 --> 00:22:56,880
to reduce the fatigue for the employees

586
00:22:56,880 --> 00:22:58,480
um so

587
00:22:58,480 --> 00:23:00,080
that's a great question because that's

588
00:23:00,080 --> 00:23:02,960
something we're thinking about like um

589
00:23:02,960 --> 00:23:04,000
at

590
00:23:04,000 --> 00:23:06,240
what's like what are we risking by

591
00:23:06,240 --> 00:23:08,640
missing some of the actual critical

592
00:23:08,640 --> 00:23:11,280
alerts versus reducing false of the

593
00:23:11,280 --> 00:23:13,520
alert fatigue so what we're trying to

594
00:23:13,520 --> 00:23:15,520
think now because this is still in the

595
00:23:15,520 --> 00:23:17,760
development phase like i said we are

596
00:23:17,760 --> 00:23:19,520
trying to use another model that would

597
00:23:19,520 --> 00:23:21,919
bring this new signals completely that

598
00:23:21,919 --> 00:23:23,840
are not seen by this model and we've

599
00:23:23,840 --> 00:23:25,760
already found that it's able to really

600
00:23:25,760 --> 00:23:28,799
improve uh the the model's results we're

601
00:23:28,799 --> 00:23:32,320
also trying if i just go back quickly to

602
00:23:32,320 --> 00:23:33,200
this

603
00:23:33,200 --> 00:23:37,360
plot um so we can tune which decision

604
00:23:37,360 --> 00:23:40,080
threshold we use and we can just pick

605
00:23:40,080 --> 00:23:42,880
one that is at a very very high recall

606
00:23:42,880 --> 00:23:45,279
to be able to say that um because the

607
00:23:45,279 --> 00:23:47,919
recall means what what percent what

608
00:23:47,919 --> 00:23:50,880
percent percentage of the critical

609
00:23:50,880 --> 00:23:53,120
alerts are we catching so if we for

610
00:23:53,120 --> 00:23:56,480
example pick the threshold at one so 100

611
00:23:56,480 --> 00:23:58,240
percent of them then we are sure that

612
00:23:58,240 --> 00:24:00,159
we're not missing ones but at the same

613
00:24:00,159 --> 00:24:02,559
time if we pick that 100 percent recall

614
00:24:02,559 --> 00:24:04,400
then we're also letting in

615
00:24:04,400 --> 00:24:07,520
many of the false positives as well so

616
00:24:07,520 --> 00:24:09,919
like i said our approach is first to try

617
00:24:09,919 --> 00:24:12,320
to improve on these models results and

618
00:24:12,320 --> 00:24:15,400
also that maybe we can frame this as a

619
00:24:15,400 --> 00:24:17,279
prioritization

620
00:24:17,279 --> 00:24:19,279
system and not as a system that

621
00:24:19,279 --> 00:24:22,000
suppresses alerts so it would just maybe

622
00:24:22,000 --> 00:24:23,840
rank them so they still have to look at

623
00:24:23,840 --> 00:24:25,760
all of them but it's easier because then

624
00:24:25,760 --> 00:24:28,000
they know that okay at the top these are

625
00:24:28,000 --> 00:24:29,840
some that we think confidently are bad

626
00:24:29,840 --> 00:24:31,200
but they still have to look at the other

627
00:24:31,200 --> 00:24:32,640
ones

628
00:24:32,640 --> 00:24:34,240
um yeah

629
00:24:34,240 --> 00:24:37,840
awesome thank you for sure

630
00:24:41,600 --> 00:24:43,279
is there

631
00:24:43,279 --> 00:24:47,840
anything else from anybody this time

632
00:24:50,559 --> 00:24:52,240
it would appear not

633
00:24:52,240 --> 00:24:55,120
selma so once again thank you thanks

634
00:24:55,120 --> 00:24:56,990
everyone

635
00:24:56,990 --> 00:25:03,120
[Applause]

636
00:25:03,120 --> 00:25:05,199
you

