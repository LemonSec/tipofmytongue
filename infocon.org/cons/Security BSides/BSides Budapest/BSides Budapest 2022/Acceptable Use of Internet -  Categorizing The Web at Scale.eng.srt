1
00:00:01,360 --> 00:00:03,600
okay wait ladies and gentlemen we

2
00:00:03,600 --> 00:00:05,920
continue in the afternoon with

3
00:00:05,920 --> 00:00:07,680
boris tomasz

4
00:00:07,680 --> 00:00:09,760
on the acceptable use of internet

5
00:00:09,760 --> 00:00:12,480
and categorizing the web at scale thank

6
00:00:12,480 --> 00:00:14,719
you

7
00:00:14,799 --> 00:00:16,480
yeah hey everyone thank you very much

8
00:00:16,480 --> 00:00:18,640
for attending our talk acceptable use of

9
00:00:18,640 --> 00:00:22,160
the internet categorizing the valetsky

10
00:00:22,160 --> 00:00:23,840
my name is tameshwaresh and i'm a data

11
00:00:23,840 --> 00:00:27,039
scientist with surface ai

12
00:00:27,039 --> 00:00:28,960
first let's go through the agenda of the

13
00:00:28,960 --> 00:00:30,640
talk it will have me

14
00:00:30,640 --> 00:00:32,479
four main components first we will go

15
00:00:32,479 --> 00:00:34,719
through the motivation

16
00:00:34,719 --> 00:00:36,800
why we are doing this project uh within

17
00:00:36,800 --> 00:00:38,719
sofa ci

18
00:00:38,719 --> 00:00:41,040
in a nutshell we think that the

19
00:00:41,040 --> 00:00:43,040
security profile of our organization is

20
00:00:43,040 --> 00:00:46,000
heavily dependent of the content

21
00:00:46,000 --> 00:00:48,800
their employees browse so we find it

22
00:00:48,800 --> 00:00:50,879
really important to understand that

23
00:00:50,879 --> 00:00:54,879
content to best of our capabilities

24
00:00:54,879 --> 00:00:57,360
to do this we propose a machine learning

25
00:00:57,360 --> 00:01:00,000
model for url classification for

26
00:01:00,000 --> 00:01:01,359
downstream

27
00:01:01,359 --> 00:01:04,000
systems so this will be a defensive

28
00:01:04,000 --> 00:01:06,960
application of emma

29
00:01:06,960 --> 00:01:09,520
we we propose to use amazon to do this

30
00:01:09,520 --> 00:01:11,840
because the internet is huge and highly

31
00:01:11,840 --> 00:01:13,680
volatile so

32
00:01:13,680 --> 00:01:16,320
it will be a invisible task for a human

33
00:01:16,320 --> 00:01:18,720
to to do

34
00:01:18,720 --> 00:01:20,960
also even though

35
00:01:20,960 --> 00:01:22,560
the

36
00:01:22,560 --> 00:01:25,119
url is not tightly

37
00:01:25,119 --> 00:01:27,520
related to the content the page is

38
00:01:27,520 --> 00:01:30,799
serving it still holds valuable signal

39
00:01:30,799 --> 00:01:33,360
and it's a very lightweight artifact

40
00:01:33,360 --> 00:01:36,240
that can be used more easily than a html

41
00:01:36,240 --> 00:01:39,759
or a portable executable file

42
00:01:39,759 --> 00:01:41,439
then we will go through the model that

43
00:01:41,439 --> 00:01:43,920
we are proposing to solve this problem

44
00:01:43,920 --> 00:01:45,439
and we will go through the architecture

45
00:01:45,439 --> 00:01:47,040
of the model and the intuition why we

46
00:01:47,040 --> 00:01:49,280
propose to use this and finally we will

47
00:01:49,280 --> 00:01:51,040
go through the is that

48
00:01:51,040 --> 00:01:53,520
in terms of accuracy and coverage

49
00:01:53,520 --> 00:01:55,200
and finally we will hand inspect some of

50
00:01:55,200 --> 00:01:57,840
the samples

51
00:01:58,159 --> 00:02:00,000
let's look at the problem

52
00:02:00,000 --> 00:02:01,360
more closely

53
00:02:01,360 --> 00:02:03,600
let's say i'm a sys admin at my

54
00:02:03,600 --> 00:02:05,840
organization and i go in monday

55
00:02:05,840 --> 00:02:07,200
and i see

56
00:02:07,200 --> 00:02:09,360
three urls in the telemetry of my

57
00:02:09,360 --> 00:02:11,280
organization so i essentially realized

58
00:02:11,280 --> 00:02:13,120
that my colleagues looked up so on the

59
00:02:13,120 --> 00:02:15,360
x-axis we have the urs that my

60
00:02:15,360 --> 00:02:17,520
colleagues looked up and y-axis we have

61
00:02:17,520 --> 00:02:20,000
my happiness level about those urs

62
00:02:20,000 --> 00:02:22,239
so when i see the first url it's a

63
00:02:22,239 --> 00:02:25,280
security playbook pdf from microsoft.com

64
00:02:25,280 --> 00:02:27,920
so that's like fantastic kudos to my

65
00:02:27,920 --> 00:02:29,680
colleague

66
00:02:29,680 --> 00:02:31,760
i'm over the top happy about that the

67
00:02:31,760 --> 00:02:33,120
second one is

68
00:02:33,120 --> 00:02:35,519
less known domain it's called

69
00:02:35,519 --> 00:02:38,800
tricks for winning the lottery pdf like

70
00:02:38,800 --> 00:02:40,959
i'm not that happy like i guess i'm not

71
00:02:40,959 --> 00:02:42,080
judging

72
00:02:42,080 --> 00:02:45,120
but whatever and finally i can see in

73
00:02:45,120 --> 00:02:47,760
the logs that someone looked at pirate

74
00:02:47,760 --> 00:02:50,480
bay and downloading uh or trying to

75
00:02:50,480 --> 00:02:52,800
download the pdf

76
00:02:52,800 --> 00:02:53,519
now

77
00:02:53,519 --> 00:02:55,120
parity is a

78
00:02:55,120 --> 00:02:58,239
torrent site so that's intellectual

79
00:02:58,239 --> 00:03:00,319
theft at best or maybe that's not even a

80
00:03:00,319 --> 00:03:03,040
pdf so that's how i get run somewhere

81
00:03:03,040 --> 00:03:05,360
so it's just me but what will i do i

82
00:03:05,360 --> 00:03:07,120
will just simply bloat that url in my

83
00:03:07,120 --> 00:03:10,319
firewall or my utm

84
00:03:10,319 --> 00:03:13,200
now next day i go in again

85
00:03:13,200 --> 00:03:16,239
i see the winning the lottery pdf so

86
00:03:16,239 --> 00:03:19,200
it might not work uh but more

87
00:03:19,200 --> 00:03:20,560
importantly

88
00:03:20,560 --> 00:03:21,920
i can see that

89
00:03:21,920 --> 00:03:24,159
same pdf is still being still being

90
00:03:24,159 --> 00:03:26,239
downloaded from piratebay except it's

91
00:03:26,239 --> 00:03:28,640
from a slightly different url

92
00:03:28,640 --> 00:03:30,879
so this is an issue

93
00:03:30,879 --> 00:03:32,640
so that's it i had it i blocked the

94
00:03:32,640 --> 00:03:36,000
whole domain the pirate bay

95
00:03:36,000 --> 00:03:38,239
next day i go in again and i can see

96
00:03:38,239 --> 00:03:40,000
that it is being downloaded from a

97
00:03:40,000 --> 00:03:42,080
different torrent site so it looks like

98
00:03:42,080 --> 00:03:43,200
with a

99
00:03:43,200 --> 00:03:45,760
bit of a cat and mouse game on our hands

100
00:03:45,760 --> 00:03:47,519
and the question that we are trying to

101
00:03:47,519 --> 00:03:49,040
answer is that

102
00:03:49,040 --> 00:03:50,959
is this a game that we can win or is

103
00:03:50,959 --> 00:03:52,640
this a game that we should be playing at

104
00:03:52,640 --> 00:03:54,640
all

105
00:03:54,640 --> 00:03:57,920
so let's do one more exercise um

106
00:03:57,920 --> 00:03:59,519
here we have a plot which says bin

107
00:03:59,519 --> 00:04:01,599
domains by lookup count on the x-axis

108
00:04:01,599 --> 00:04:03,599
and on the y-axis we have lookups

109
00:04:03,599 --> 00:04:05,439
covered in telemetry so let's unfold

110
00:04:05,439 --> 00:04:06,640
what this means

111
00:04:06,640 --> 00:04:09,280
this is a bar plot it has bars so if we

112
00:04:09,280 --> 00:04:11,040
look at the very first bar it's produced

113
00:04:11,040 --> 00:04:13,519
by taking a sample from our customer

114
00:04:13,519 --> 00:04:15,439
telemetry

115
00:04:15,439 --> 00:04:17,680
uh taking all the url all the lookups

116
00:04:17,680 --> 00:04:19,680
from the customer telemetry grouping the

117
00:04:19,680 --> 00:04:21,519
lookups by the domain and taking the

118
00:04:21,519 --> 00:04:23,120
first

119
00:04:23,120 --> 00:04:25,040
100 domain by this

120
00:04:25,040 --> 00:04:27,600
kind of popularity so if we sum up other

121
00:04:27,600 --> 00:04:29,759
lookups from the top 100 most popular

122
00:04:29,759 --> 00:04:30,720
domains

123
00:04:30,720 --> 00:04:32,560
and if i have some kind of information

124
00:04:32,560 --> 00:04:34,960
about those domains it will and

125
00:04:34,960 --> 00:04:36,880
and i block it in the utm allowance

126
00:04:36,880 --> 00:04:39,199
block list in the utm then i'm it's

127
00:04:39,199 --> 00:04:41,360
really good news i covered a lot really

128
00:04:41,360 --> 00:04:43,919
a lot of of the telemetry of my customer

129
00:04:43,919 --> 00:04:45,680
base

130
00:04:45,680 --> 00:04:48,080
so if i do this exercise for the next

131
00:04:48,080 --> 00:04:49,280
next

132
00:04:49,280 --> 00:04:52,000
bin or next bar

133
00:04:52,000 --> 00:04:53,520
for the same amount of work hand

134
00:04:53,520 --> 00:04:55,199
labeling 100

135
00:04:55,199 --> 00:04:57,759
domains or urls i get significantly

136
00:04:57,759 --> 00:05:00,400
lower return of investment and we can

137
00:05:00,400 --> 00:05:02,400
see there is an exponential decay so at

138
00:05:02,400 --> 00:05:04,880
one point i will just simply

139
00:05:04,880 --> 00:05:06,639
run out of time or permissions i will

140
00:05:06,639 --> 00:05:08,639
just give this process up because it's

141
00:05:08,639 --> 00:05:10,560
simply not worth it to

142
00:05:10,560 --> 00:05:11,919
unlabel stuff

143
00:05:11,919 --> 00:05:14,400
so let's say i i give up and labeling or

144
00:05:14,400 --> 00:05:16,639
blocking stuff in my firewall after the

145
00:05:16,639 --> 00:05:18,720
first i believe these are for

146
00:05:18,720 --> 00:05:22,320
40 bars so that's 4 000 domains most

147
00:05:22,320 --> 00:05:24,639
popular domains

148
00:05:24,639 --> 00:05:26,000
is that

149
00:05:26,000 --> 00:05:26,960
yeah

150
00:05:26,960 --> 00:05:28,800
and the question is will i be surprised

151
00:05:28,800 --> 00:05:31,840
the next day i i go into the office will

152
00:05:31,840 --> 00:05:34,800
i see any other funky uh passing this

153
00:05:34,800 --> 00:05:38,400
kind of block list like this approach

154
00:05:38,400 --> 00:05:40,800
now the answer to that is that probably

155
00:05:40,800 --> 00:05:42,240
yes

156
00:05:42,240 --> 00:05:44,000
because if i take the rest of the

157
00:05:44,000 --> 00:05:46,479
telemetry and sum it up as the last

158
00:05:46,479 --> 00:05:48,400
column there it turns out that the long

159
00:05:48,400 --> 00:05:50,639
tail of the url lookup distribution is

160
00:05:50,639 --> 00:05:52,479
actually really long

161
00:05:52,479 --> 00:05:54,880
so it's simply infeasible to take the

162
00:05:54,880 --> 00:05:57,440
most popular domains and and just assign

163
00:05:57,440 --> 00:06:01,680
some kind of label or knowledge to them

164
00:06:02,639 --> 00:06:04,560
how does it translate to our actual

165
00:06:04,560 --> 00:06:07,039
coverage this exercise um

166
00:06:07,039 --> 00:06:08,479
this will be a plot that you will be

167
00:06:08,479 --> 00:06:09,600
seeing

168
00:06:09,600 --> 00:06:11,840
more after this but on the x-axis it has

169
00:06:11,840 --> 00:06:14,479
the time so for every day this plot

170
00:06:14,479 --> 00:06:16,960
represents for every day how many unique

171
00:06:16,960 --> 00:06:20,160
urs were looked at by our customers

172
00:06:20,160 --> 00:06:22,479
for for this 100k sample

173
00:06:22,479 --> 00:06:24,800
and the solid range color means that

174
00:06:24,800 --> 00:06:26,400
that we had some kind of information

175
00:06:26,400 --> 00:06:28,000
about those urls and the dashed one

176
00:06:28,000 --> 00:06:29,759
means that we we have no clue what the

177
00:06:29,759 --> 00:06:31,840
customers are browsing which is clearly

178
00:06:31,840 --> 00:06:35,840
not good so that's a blind spot

179
00:06:35,840 --> 00:06:38,240
so this is this is not as not

180
00:06:38,240 --> 00:06:40,560
necessarily one to one map to the

181
00:06:40,560 --> 00:06:42,720
top and domains but it's not a bad

182
00:06:42,720 --> 00:06:45,360
strategy after all

183
00:06:45,360 --> 00:06:46,240
so

184
00:06:46,240 --> 00:06:48,880
what do we mean by labels uh internally

185
00:06:48,880 --> 00:06:51,840
with suppose we track 80 labels um i

186
00:06:51,840 --> 00:06:54,720
track i i show nine examples of that

187
00:06:54,720 --> 00:06:57,680
eight labels here

188
00:06:58,080 --> 00:07:00,160
these labels or urls belonging to these

189
00:07:00,160 --> 00:07:02,639
classes could have impact on the

190
00:07:02,639 --> 00:07:05,599
organization along multiple dimensions

191
00:07:05,599 --> 00:07:07,360
or aspects so there is one important

192
00:07:07,360 --> 00:07:09,599
which is the security aspect so there

193
00:07:09,599 --> 00:07:10,400
are

194
00:07:10,400 --> 00:07:12,880
trusted at this sites like microsoft.com

195
00:07:12,880 --> 00:07:16,759
or search engines google

196
00:07:16,960 --> 00:07:19,120
or there is stack overflow which is

197
00:07:19,120 --> 00:07:20,560
something that

198
00:07:20,560 --> 00:07:22,000
probably you are not going to get

199
00:07:22,000 --> 00:07:24,319
infected from or less likely

200
00:07:24,319 --> 00:07:26,160
and to the bit right of that there are

201
00:07:26,160 --> 00:07:28,000
the social networking sites you can

202
00:07:28,000 --> 00:07:30,720
argue how risky it is but it's more

203
00:07:30,720 --> 00:07:32,479
likely that you will get infected from a

204
00:07:32,479 --> 00:07:34,960
facebook link or a dropbox link

205
00:07:34,960 --> 00:07:37,039
than uh

206
00:07:37,039 --> 00:07:40,000
then from a trusted update site and then

207
00:07:40,000 --> 00:07:41,759
on the far right we have the

208
00:07:41,759 --> 00:07:43,520
extreme categories which is pornography

209
00:07:43,520 --> 00:07:45,599
or drugs so

210
00:07:45,599 --> 00:07:47,120
those are just simply infested with

211
00:07:47,120 --> 00:07:49,440
malicious content so you might want to

212
00:07:49,440 --> 00:07:50,720
pay

213
00:07:50,720 --> 00:07:53,360
more attention to those urs

214
00:07:53,360 --> 00:07:55,680
and then there is the other aspect of

215
00:07:55,680 --> 00:07:57,599
all this which is called which is we

216
00:07:57,599 --> 00:07:58,639
call the

217
00:07:58,639 --> 00:08:01,599
negative impact of productivity or

218
00:08:01,599 --> 00:08:03,039
negative legal

219
00:08:03,039 --> 00:08:05,599
impact or ethical impact

220
00:08:05,599 --> 00:08:08,400
so there are these law sites which have

221
00:08:08,400 --> 00:08:10,400
no product negative productive impact

222
00:08:10,400 --> 00:08:13,120
because we need to need those to do our

223
00:08:13,120 --> 00:08:15,680
everyday job but then it's up to an

224
00:08:15,680 --> 00:08:18,319
organization whether it wants to allow

225
00:08:18,319 --> 00:08:20,800
its employees to browse social network

226
00:08:20,800 --> 00:08:21,680
sites

227
00:08:21,680 --> 00:08:24,319
during workouts or dating sites and for

228
00:08:24,319 --> 00:08:26,800
sure no company wants to allow employees

229
00:08:26,800 --> 00:08:28,720
to browse pornography or or buying

230
00:08:28,720 --> 00:08:31,120
village drugs during work hours so

231
00:08:31,120 --> 00:08:34,000
this is sort of the motivation but

232
00:08:34,000 --> 00:08:36,799
why we are tracking these classes

233
00:08:36,799 --> 00:08:38,640
so just to recap the motivation part

234
00:08:38,640 --> 00:08:40,399
what we are

235
00:08:40,399 --> 00:08:42,000
trying to do is we want to use our

236
00:08:42,000 --> 00:08:43,679
machine learning in contrast to the

237
00:08:43,679 --> 00:08:45,920
standard approach which is having

238
00:08:45,920 --> 00:08:47,920
analysts hand labeling a few sites that

239
00:08:47,920 --> 00:08:50,080
cover a good chunk of the telemetry but

240
00:08:50,080 --> 00:08:52,480
not all because it leaves a lot of

241
00:08:52,480 --> 00:08:55,839
unknown data

242
00:08:59,040 --> 00:09:01,680
this this manual labeling approach we

243
00:09:01,680 --> 00:09:03,200
want to replace it because it's really

244
00:09:03,200 --> 00:09:04,800
slow it's expensive

245
00:09:04,800 --> 00:09:06,640
manual work doesn't scale at all and we

246
00:09:06,640 --> 00:09:09,600
want to use a ml instead of that

247
00:09:09,600 --> 00:09:12,720
specifically to provide extra labels for

248
00:09:12,720 --> 00:09:14,560
our long tear that manual labelers

249
00:09:14,560 --> 00:09:15,519
couldn't

250
00:09:15,519 --> 00:09:16,800
cover

251
00:09:16,800 --> 00:09:18,000
this project

252
00:09:18,000 --> 00:09:20,480
has additional like side effects but it

253
00:09:20,480 --> 00:09:22,800
reduces time for about new sites i i

254
00:09:22,800 --> 00:09:24,959
mean whenever you deploy the model it

255
00:09:24,959 --> 00:09:26,560
will be instantly there

256
00:09:26,560 --> 00:09:28,240
so you don't have to wait for the whole

257
00:09:28,240 --> 00:09:30,800
pipeline to get to the analysts and

258
00:09:30,800 --> 00:09:32,720
it could also highlight conflicting

259
00:09:32,720 --> 00:09:33,920
labels but

260
00:09:33,920 --> 00:09:37,719
that's for another day

261
00:09:38,720 --> 00:09:40,880
generally if you use emma you would want

262
00:09:40,880 --> 00:09:42,720
to split your data into two or three

263
00:09:42,720 --> 00:09:44,880
groups

264
00:09:44,880 --> 00:09:46,720
the first group being the training data

265
00:09:46,720 --> 00:09:48,480
that will be used to

266
00:09:48,480 --> 00:09:50,480
train your machine learning model

267
00:09:50,480 --> 00:09:51,600
and the other

268
00:09:51,600 --> 00:09:53,440
two or three is the test of validation

269
00:09:53,440 --> 00:09:55,360
data where you will evaluate your model

270
00:09:55,360 --> 00:09:56,320
how well

271
00:09:56,320 --> 00:09:57,760
it was trained

272
00:09:57,760 --> 00:10:00,800
we use the so-called time split

273
00:10:00,800 --> 00:10:02,800
with which we want to emulate the

274
00:10:02,800 --> 00:10:05,120
deployment scenario meaning that we

275
00:10:05,120 --> 00:10:07,279
pick a point in time which is roughly

276
00:10:07,279 --> 00:10:09,839
end of january for this scenario

277
00:10:09,839 --> 00:10:11,440
and we take everything before that time

278
00:10:11,440 --> 00:10:13,680
as training data and everything after

279
00:10:13,680 --> 00:10:16,800
that has test data

280
00:10:17,360 --> 00:10:19,680
we use 200 million urs is our training

281
00:10:19,680 --> 00:10:21,839
data

282
00:10:21,839 --> 00:10:23,120
and one

283
00:10:23,120 --> 00:10:25,279
one detail to highlight is that there

284
00:10:25,279 --> 00:10:27,120
are no duplications between the training

285
00:10:27,120 --> 00:10:28,560
and test data which will be still a

286
00:10:28,560 --> 00:10:31,200
realistic scenario because people still

287
00:10:31,200 --> 00:10:33,200
can look up urls from the past but we

288
00:10:33,200 --> 00:10:35,040
are not really interested in

289
00:10:35,040 --> 00:10:37,680
how well the model can generalize

290
00:10:37,680 --> 00:10:39,920
between url caps but

291
00:10:39,920 --> 00:10:41,680
sorry not interested how well it can

292
00:10:41,680 --> 00:10:43,200
memorize but we are interested how well

293
00:10:43,200 --> 00:10:46,880
it can generalize for new caps

294
00:10:46,880 --> 00:10:49,680
but domain revisions are allowed but not

295
00:10:49,680 --> 00:10:52,560
not for urs

296
00:10:55,519 --> 00:10:57,839
so

297
00:10:58,320 --> 00:11:00,480
now that we have our data and our labels

298
00:11:00,480 --> 00:11:03,120
the only thing we need is our model

299
00:11:03,120 --> 00:11:05,680
uh we propose to use a 1d convolutional

300
00:11:05,680 --> 00:11:07,279
neural network

301
00:11:07,279 --> 00:11:09,279
for this task

302
00:11:09,279 --> 00:11:10,640
there is the on the left we have the

303
00:11:10,640 --> 00:11:12,839
architecture of the model it has

304
00:11:12,839 --> 00:11:15,680
fundamentally three main blocks one is

305
00:11:15,680 --> 00:11:17,519
the character embedding then the feature

306
00:11:17,519 --> 00:11:19,360
detection part

307
00:11:19,360 --> 00:11:21,760
and finally the classification so just a

308
00:11:21,760 --> 00:11:24,160
few quick words about it

309
00:11:24,160 --> 00:11:26,399
the input to the model is a url as a

310
00:11:26,399 --> 00:11:28,399
string so

311
00:11:28,399 --> 00:11:30,720
it needs to be the ml operates over

312
00:11:30,720 --> 00:11:32,800
numbers not on strings

313
00:11:32,800 --> 00:11:35,680
so we need to convert that in strings

314
00:11:35,680 --> 00:11:38,240
into numeric representation

315
00:11:38,240 --> 00:11:40,240
we choose a 1d

316
00:11:40,240 --> 00:11:43,360
character level embedding to do this um

317
00:11:43,360 --> 00:11:44,959
it's a it's an existing concept there

318
00:11:44,959 --> 00:11:46,560
are many ways to do this we choose to go

319
00:11:46,560 --> 00:11:48,480
with that so what that does it takes

320
00:11:48,480 --> 00:11:50,639
every character of the input url and it

321
00:11:50,639 --> 00:11:53,200
maps it to a numeric vector

322
00:11:53,200 --> 00:11:55,839
every every character to a about numeric

323
00:11:55,839 --> 00:11:58,480
vector in a way that

324
00:11:58,480 --> 00:12:02,000
characters that occur in a replaceable

325
00:12:02,000 --> 00:12:03,360
fashion so like

326
00:12:03,360 --> 00:12:05,760
numbers are like in a url so it's not

327
00:12:05,760 --> 00:12:07,279
necessarily changing the number it's not

328
00:12:07,279 --> 00:12:08,839
necessarily changing the meaning of the

329
00:12:08,839 --> 00:12:10,480
url

330
00:12:10,480 --> 00:12:12,240
and then then those

331
00:12:12,240 --> 00:12:14,560
similar characters similar characters

332
00:12:14,560 --> 00:12:17,040
with similar rows would be mapped to

333
00:12:17,040 --> 00:12:19,760
similar numeric representations so

334
00:12:19,760 --> 00:12:21,600
that's probably enough about the input

335
00:12:21,600 --> 00:12:22,560
part

336
00:12:22,560 --> 00:12:24,560
but this this makes it

337
00:12:24,560 --> 00:12:26,880
makes this more robust to obfuscation

338
00:12:26,880 --> 00:12:29,360
attempts if you just want to type more

339
00:12:29,360 --> 00:12:32,480
and more numbers at the end of the url

340
00:12:32,480 --> 00:12:34,959
and and then the most interesting part

341
00:12:34,959 --> 00:12:36,399
of the key part of the model is the

342
00:12:36,399 --> 00:12:39,120
feature detection part which consists of

343
00:12:39,120 --> 00:12:41,360
1d convolutional layers

344
00:12:41,360 --> 00:12:43,279
what convolutional layer does on a high

345
00:12:43,279 --> 00:12:45,200
level it operates a sliding window on

346
00:12:45,200 --> 00:12:47,519
top of input

347
00:12:47,519 --> 00:12:49,120
strings are fundamentally one

348
00:12:49,120 --> 00:12:51,360
dimensional so there is an example on

349
00:12:51,360 --> 00:12:52,720
the right for that

350
00:12:52,720 --> 00:12:55,519
we have the casino bethlehem.net

351
00:12:55,519 --> 00:12:57,440
as a input url

352
00:12:57,440 --> 00:12:59,200
it is converted into its numeric

353
00:12:59,200 --> 00:13:01,120
representation by the embedding layer

354
00:13:01,120 --> 00:13:02,720
and then we set a

355
00:13:02,720 --> 00:13:05,120
we pick a convolutional window that we

356
00:13:05,120 --> 00:13:08,399
slide over this string so essentially if

357
00:13:08,399 --> 00:13:11,040
we set out the key equals three so a

358
00:13:11,040 --> 00:13:13,120
three line convolutional window it from

359
00:13:13,120 --> 00:13:14,880
the beginning with the step size when it

360
00:13:14,880 --> 00:13:16,160
will slide over

361
00:13:16,160 --> 00:13:18,320
the url so it will capture the numeric

362
00:13:18,320 --> 00:13:22,720
representation of class rc c and so on

363
00:13:22,720 --> 00:13:24,959
so essentially it will capture all the

364
00:13:24,959 --> 00:13:28,719
three length substrings of the url

365
00:13:29,920 --> 00:13:31,120
now

366
00:13:31,120 --> 00:13:32,880
we do this with

367
00:13:32,880 --> 00:13:35,519
window lines two three four five so for

368
00:13:35,519 --> 00:13:37,440
example window length four it will

369
00:13:37,440 --> 00:13:38,880
capture

370
00:13:38,880 --> 00:13:40,639
the every four length substring of the

371
00:13:40,639 --> 00:13:42,160
url

372
00:13:42,160 --> 00:13:44,480
but with that rank three it will capture

373
00:13:44,480 --> 00:13:46,399
bat and with length four it will also

374
00:13:46,399 --> 00:13:49,120
capture game so these are important

375
00:13:49,120 --> 00:13:51,360
because with the human eye these are the

376
00:13:51,360 --> 00:13:53,440
very birds or subwords that drive the

377
00:13:53,440 --> 00:13:54,880
human eye that's saying hey this is a

378
00:13:54,880 --> 00:13:57,440
gambling site so among the other

379
00:13:57,440 --> 00:13:59,680
substrings these will be captured too

380
00:13:59,680 --> 00:14:01,360
and all these features will be fed into

381
00:14:01,360 --> 00:14:03,440
the classification layer

382
00:14:03,440 --> 00:14:06,560
and it will assign baits to these

383
00:14:06,560 --> 00:14:10,319
specific features in a way so it

384
00:14:10,480 --> 00:14:12,959
it gets the best possible probability or

385
00:14:12,959 --> 00:14:16,000
accuracy at the end

386
00:14:16,000 --> 00:14:19,279
so how to evaluate the model as such um

387
00:14:19,279 --> 00:14:21,120
there are many ways to do that i'm

388
00:14:21,120 --> 00:14:24,160
showing one this is called rap curve

389
00:14:24,160 --> 00:14:28,079
uh recur shows a trade-off between

390
00:14:28,079 --> 00:14:29,600
between the first positive rate and the

391
00:14:29,600 --> 00:14:32,560
true positive rate

392
00:14:33,120 --> 00:14:35,199
this plot has three lines on it

393
00:14:35,199 --> 00:14:36,800
three curves

394
00:14:36,800 --> 00:14:38,800
so for example if we look at

395
00:14:38,800 --> 00:14:41,360
the orange line

396
00:14:41,360 --> 00:14:43,199
there is a dot at 10 to the minus third

397
00:14:43,199 --> 00:14:45,040
false positive rate

398
00:14:45,040 --> 00:14:47,120
what it means that for every one in a

399
00:14:47,120 --> 00:14:49,199
thousand urs that are not in the

400
00:14:49,199 --> 00:14:50,880
healthcare side we will make a mistake

401
00:14:50,880 --> 00:14:52,399
and say it's a

402
00:14:52,399 --> 00:14:53,600
healthcare

403
00:14:53,600 --> 00:14:55,199
healthcare site

404
00:14:55,199 --> 00:14:56,880
which is not good but it is a price that

405
00:14:56,880 --> 00:14:59,600
we have to pay that we get a decent true

406
00:14:59,600 --> 00:15:02,720
positive rate uh roughly on

407
00:15:02,720 --> 00:15:05,279
roughly on the 90 percent mark

408
00:15:05,279 --> 00:15:07,199
which is a pretty good result

409
00:15:07,199 --> 00:15:09,440
uh we are doing well for example with

410
00:15:09,440 --> 00:15:11,440
the pornograph pornography

411
00:15:11,440 --> 00:15:14,160
category as well so these urls turns out

412
00:15:14,160 --> 00:15:15,760
they have current pornography something

413
00:15:15,760 --> 00:15:18,560
that are really explicit even in the url

414
00:15:18,560 --> 00:15:20,399
but but but they will be hosting and of

415
00:15:20,399 --> 00:15:21,920
course there are more generic categories

416
00:15:21,920 --> 00:15:24,160
like personal cloud apps which is

417
00:15:24,160 --> 00:15:25,360
hard to

418
00:15:25,360 --> 00:15:27,839
hard to decide what they are about but

419
00:15:27,839 --> 00:15:31,120
it's still a okay result

420
00:15:31,120 --> 00:15:34,079
but how does this uh translate into into

421
00:15:34,079 --> 00:15:36,240
the actual deployment so we had this uh

422
00:15:36,240 --> 00:15:38,079
plot before

423
00:15:38,079 --> 00:15:40,320
with the covered and uncovered data so

424
00:15:40,320 --> 00:15:41,839
first let's see how the tracker

425
00:15:41,839 --> 00:15:43,360
translates to the

426
00:15:43,360 --> 00:15:45,199
labeled part

427
00:15:45,199 --> 00:15:48,320
so it turns out if we apply our model

428
00:15:48,320 --> 00:15:50,639
uh for each

429
00:15:50,639 --> 00:15:52,000
each label for

430
00:15:52,000 --> 00:15:53,360
each labeled part we get the

431
00:15:53,360 --> 00:15:56,000
corresponding model predictions but we

432
00:15:56,000 --> 00:15:58,320
can evaluate our model

433
00:15:58,320 --> 00:16:00,720
the solid blue is the urls that we got

434
00:16:00,720 --> 00:16:03,120
correctly and the libraries that we got

435
00:16:03,120 --> 00:16:05,199
incorrectly which is

436
00:16:05,199 --> 00:16:07,440
this this is our right reset

437
00:16:07,440 --> 00:16:09,519
but this is not where the that we would

438
00:16:09,519 --> 00:16:12,160
expect this model to gain value from

439
00:16:12,160 --> 00:16:13,440
because this is something that we

440
00:16:13,440 --> 00:16:14,800
already knew

441
00:16:14,800 --> 00:16:17,759
so let's see how we do on the

442
00:16:17,759 --> 00:16:20,160
on the unknown part

443
00:16:20,160 --> 00:16:22,480
and it turns out we can

444
00:16:22,480 --> 00:16:24,079
roughly have

445
00:16:24,079 --> 00:16:25,600
the amount of

446
00:16:25,600 --> 00:16:26,959
unknown data that we had in our

447
00:16:26,959 --> 00:16:28,800
telemetry before just by deploying this

448
00:16:28,800 --> 00:16:29,759
model

449
00:16:29,759 --> 00:16:32,880
and it picking up specific

450
00:16:32,880 --> 00:16:35,880
subwords

451
00:16:36,240 --> 00:16:38,079
looking at the ratio with which the

452
00:16:38,079 --> 00:16:40,639
model got the urs right

453
00:16:40,639 --> 00:16:42,480
it kind of gives hope that the pink one

454
00:16:42,480 --> 00:16:44,480
the additional again from this model

455
00:16:44,480 --> 00:16:45,600
will be

456
00:16:45,600 --> 00:16:46,480
also

457
00:16:46,480 --> 00:16:49,199
uh could a bit good good accuracy even

458
00:16:49,199 --> 00:16:52,319
though it's a harder problem

459
00:16:57,279 --> 00:16:59,199
these deep learning models are

460
00:16:59,199 --> 00:17:01,600
fundamentally black box so as of now we

461
00:17:01,600 --> 00:17:03,120
don't really know why they make the

462
00:17:03,120 --> 00:17:05,679
decisions that they make

463
00:17:05,679 --> 00:17:07,679
there are multiple tools to

464
00:17:07,679 --> 00:17:09,280
post-op models

465
00:17:09,280 --> 00:17:10,400
that

466
00:17:10,400 --> 00:17:12,720
are used after the model training to

467
00:17:12,720 --> 00:17:15,199
explain the first modals these decision

468
00:17:15,199 --> 00:17:16,799
decisions

469
00:17:16,799 --> 00:17:19,439
one is called lime so we are showing

470
00:17:19,439 --> 00:17:22,000
results here from uh from a positive

471
00:17:22,000 --> 00:17:24,720
mode called lime

472
00:17:24,720 --> 00:17:25,599
um

473
00:17:25,599 --> 00:17:28,160
on this plot we have two set of urls one

474
00:17:28,160 --> 00:17:28,470
is the

475
00:17:28,470 --> 00:17:29,520
[Music]

476
00:17:29,520 --> 00:17:31,760
high scoring previously unknown examples

477
00:17:31,760 --> 00:17:33,520
so that's that's the net gain from this

478
00:17:33,520 --> 00:17:35,120
model and then the high scoring missed

479
00:17:35,120 --> 00:17:36,799
labels which is the failure mode of this

480
00:17:36,799 --> 00:17:38,960
model

481
00:17:38,960 --> 00:17:40,559
first let's go with the high scoring

482
00:17:40,559 --> 00:17:43,679
unknown examples so

483
00:17:43,679 --> 00:17:46,400
the first url is movie 7.8

484
00:17:46,400 --> 00:17:48,960
series and it was predicted by the model

485
00:17:48,960 --> 00:17:51,760
to be an intellectual piracy site

486
00:17:51,760 --> 00:17:54,559
now with lime if we feed this url into

487
00:17:54,559 --> 00:17:56,799
lime with our model and its predictions

488
00:17:56,799 --> 00:17:58,240
what lime

489
00:17:58,240 --> 00:17:59,679
high level does

490
00:17:59,679 --> 00:18:02,160
it splits the input into tokens

491
00:18:02,160 --> 00:18:04,080
permutes the tokens and it assigns

492
00:18:04,080 --> 00:18:06,000
probabilities for

493
00:18:06,000 --> 00:18:08,960
to each token like how

494
00:18:08,960 --> 00:18:10,240
how much the contribution of that

495
00:18:10,240 --> 00:18:12,880
specific token is to a specific class so

496
00:18:12,880 --> 00:18:16,240
the deeper the color is on on that uh

497
00:18:16,240 --> 00:18:18,160
right picture

498
00:18:18,160 --> 00:18:20,000
uh the tokens

499
00:18:20,000 --> 00:18:22,000
contribution to the class intellectual

500
00:18:22,000 --> 00:18:24,240
paradise is higher so

501
00:18:24,240 --> 00:18:26,160
the highest contribution is that movie

502
00:18:26,160 --> 00:18:28,320
samantha cam which is i would say it's a

503
00:18:28,320 --> 00:18:29,840
fair fair

504
00:18:29,840 --> 00:18:31,600
token to pick up as a

505
00:18:31,600 --> 00:18:34,240
marker of the intellectual piracy side

506
00:18:34,240 --> 00:18:37,919
also the series one is highlighted so

507
00:18:37,919 --> 00:18:40,799
it seems like this convolutional concept

508
00:18:40,799 --> 00:18:43,120
is working out and then we have the

509
00:18:43,120 --> 00:18:45,840
democratic strategy.org which is likely

510
00:18:45,840 --> 00:18:47,720
to be politics and finally the

511
00:18:47,720 --> 00:18:49,600
pokerstars.tm which is obviously a

512
00:18:49,600 --> 00:18:51,440
gambling site

513
00:18:51,440 --> 00:18:52,799
and

514
00:18:52,799 --> 00:18:54,880
there we have the other set where where

515
00:18:54,880 --> 00:18:56,960
we made the mistakes with the mother so

516
00:18:56,960 --> 00:19:00,240
the first url is for solarknives.net

517
00:19:00,240 --> 00:19:02,080
so on the right we can see that the

518
00:19:02,080 --> 00:19:03,919
model looked at the burn knives and

519
00:19:03,919 --> 00:19:06,400
immediately said it was a weapons site

520
00:19:06,400 --> 00:19:08,559
whereas in in reality it was food and

521
00:19:08,559 --> 00:19:10,240
dining so i would say this is a fair

522
00:19:10,240 --> 00:19:12,400
mistake to make

523
00:19:12,400 --> 00:19:14,720
then we have the word cancer day

524
00:19:14,720 --> 00:19:17,520
which was uh predicted to be ngos

525
00:19:17,520 --> 00:19:19,919
in truth it was a healthcare site so

526
00:19:19,919 --> 00:19:21,679
this should have been caught sometimes

527
00:19:21,679 --> 00:19:25,360
it it just not capturing the proper uh

528
00:19:25,360 --> 00:19:26,720
subwords

529
00:19:26,720 --> 00:19:30,320
and finally this is the

530
00:19:31,039 --> 00:19:33,039
mode where you would expect a url based

531
00:19:33,039 --> 00:19:35,280
mode and not perform so well is the

532
00:19:35,280 --> 00:19:39,280
study.com where the url has not no

533
00:19:39,280 --> 00:19:40,320
no

534
00:19:40,320 --> 00:19:42,559
no signal whatsoever but it will host so

535
00:19:42,559 --> 00:19:44,640
unless you knew that study.com was a

536
00:19:44,640 --> 00:19:46,880
hosting site you you stood no chance

537
00:19:46,880 --> 00:19:49,120
with this modal predict that it was a

538
00:19:49,120 --> 00:19:51,120
hosting site

539
00:19:51,120 --> 00:19:54,000
so that would probably explain why we

540
00:19:54,000 --> 00:19:56,320
still have uncovered data in our

541
00:19:56,320 --> 00:19:58,320
telemetry even after

542
00:19:58,320 --> 00:20:00,960
uh utilizing the moda but even with that

543
00:20:00,960 --> 00:20:03,120
we we get

544
00:20:03,120 --> 00:20:07,840
we get nice looking urs extra coverage

545
00:20:08,720 --> 00:20:09,520
yeah

546
00:20:09,520 --> 00:20:10,640
and with that

547
00:20:10,640 --> 00:20:12,720
thank you for your attention and please

548
00:20:12,720 --> 00:20:15,660
if you have questions asked

549
00:20:15,660 --> 00:20:21,360
[Applause]

550
00:20:21,360 --> 00:20:24,320
do we have any

551
00:20:32,840 --> 00:20:36,480
yep so i was thinking what is the next

552
00:20:36,480 --> 00:20:37,440
step

553
00:20:37,440 --> 00:20:39,840
to fine-tune this

554
00:20:39,840 --> 00:20:40,799
what

555
00:20:40,799 --> 00:20:42,960
how would you be able to fine-tune

556
00:20:42,960 --> 00:20:44,640
because you are focusing now only on the

557
00:20:44,640 --> 00:20:46,080
urls

558
00:20:46,080 --> 00:20:48,559
do you want to focus or or add more

559
00:20:48,559 --> 00:20:50,480
content based on the

560
00:20:50,480 --> 00:20:53,039
words pictures on the

561
00:20:53,039 --> 00:20:55,280
web pages or so the main next step is

562
00:20:55,280 --> 00:20:57,520
that

563
00:20:57,520 --> 00:20:59,440
this system access every filter so

564
00:20:59,440 --> 00:21:00,840
obviously there

565
00:21:00,840 --> 00:21:03,760
are methods that we won't try want to

566
00:21:03,760 --> 00:21:05,600
try like different models but i would

567
00:21:05,600 --> 00:21:07,440
say if we are looking at that as a

568
00:21:07,440 --> 00:21:10,159
system as a whole the next step would be

569
00:21:10,159 --> 00:21:12,480
implementing a model that takes in html

570
00:21:12,480 --> 00:21:14,880
from the url then that would provide

571
00:21:14,880 --> 00:21:17,440
more so that's the trade-off so

572
00:21:17,440 --> 00:21:19,280
downloading and scanning on the html and

573
00:21:19,280 --> 00:21:21,360
predicting on the html it's way more

574
00:21:21,360 --> 00:21:22,799
pricey

575
00:21:22,799 --> 00:21:23,520
but

576
00:21:23,520 --> 00:21:25,440
uh using this model as a pre-filter then

577
00:21:25,440 --> 00:21:27,840
feeding that to an html

578
00:21:27,840 --> 00:21:29,840
that's the next step for this project

579
00:21:29,840 --> 00:21:32,158
thank you

580
00:21:41,280 --> 00:21:44,080
so thank you for the presentation i

581
00:21:44,080 --> 00:21:46,320
would like to ask a quite practical

582
00:21:46,320 --> 00:21:48,400
question because

583
00:21:48,400 --> 00:21:51,120
i'm working with content filtering

584
00:21:51,120 --> 00:21:53,520
softwares and testing it and so on and

585
00:21:53,520 --> 00:21:56,640
what i see so far that even with this

586
00:21:56,640 --> 00:21:58,880
kind of ai introduction

587
00:21:58,880 --> 00:22:02,400
it is still not real still not near how

588
00:22:02,400 --> 00:22:03,360
the

589
00:22:03,360 --> 00:22:04,880
human people

590
00:22:04,880 --> 00:22:07,280
trying to interpret the page so i would

591
00:22:07,280 --> 00:22:08,559
like to ask

592
00:22:08,559 --> 00:22:10,880
your opinion when we will get to the

593
00:22:10,880 --> 00:22:13,760
point that instead of classifying

594
00:22:13,760 --> 00:22:16,240
any domain saying this is a

595
00:22:16,240 --> 00:22:18,720
nature side this is a gambling site

596
00:22:18,720 --> 00:22:20,799
instead of that the classification

597
00:22:20,799 --> 00:22:22,720
software downloads the page

598
00:22:22,720 --> 00:22:25,120
interprets the text with machine

599
00:22:25,120 --> 00:22:26,799
learning

600
00:22:26,799 --> 00:22:28,559
interprets the pictures

601
00:22:28,559 --> 00:22:31,520
audio files video files on the page and

602
00:22:31,520 --> 00:22:34,080
it actually you can say that for example

603
00:22:34,080 --> 00:22:37,360
this download this part of the the

604
00:22:37,360 --> 00:22:39,679
of the parent-based site is a free

605
00:22:39,679 --> 00:22:41,840
textbook therefore you can download it

606
00:22:41,840 --> 00:22:44,799
and it's it's a completely fine but for

607
00:22:44,799 --> 00:22:48,080
what is content it says it's highly uh

608
00:22:48,080 --> 00:22:51,200
inoperate therefore it is classified as

609
00:22:51,200 --> 00:22:54,559
a torrent side so you are not allowed to

610
00:22:54,559 --> 00:22:57,679
open this url in your browser when you

611
00:22:57,679 --> 00:23:01,679
are working in a corporate environment

612
00:23:01,679 --> 00:23:04,080
thank you

613
00:23:05,760 --> 00:23:07,440
so i would say

614
00:23:07,440 --> 00:23:09,200
machine learning is there but there are

615
00:23:09,200 --> 00:23:10,640
more aspects to machine learning than

616
00:23:10,640 --> 00:23:12,400
just the model

617
00:23:12,400 --> 00:23:13,280
so

618
00:23:13,280 --> 00:23:15,280
there are two key other aspects so one

619
00:23:15,280 --> 00:23:18,559
is the data that you use to classify

620
00:23:18,559 --> 00:23:21,120
so my answer would be first that if you

621
00:23:21,120 --> 00:23:23,760
think as an model as a compiler and the

622
00:23:23,760 --> 00:23:26,000
data as the code the compiler executes

623
00:23:26,000 --> 00:23:27,679
then then we need better code we need

624
00:23:27,679 --> 00:23:30,480
better data

625
00:23:30,880 --> 00:23:33,039
so that's one part and the other part is

626
00:23:33,039 --> 00:23:36,039
that

627
00:23:36,159 --> 00:23:38,159
the hardware is not there

628
00:23:38,159 --> 00:23:40,400
yet so there are models that are pretty

629
00:23:40,400 --> 00:23:43,039
good at uh

630
00:23:43,039 --> 00:23:45,679
at uh at classifying all these things

631
00:23:45,679 --> 00:23:46,880
that you asked

632
00:23:46,880 --> 00:23:49,360
it's just pricey to get the data for it

633
00:23:49,360 --> 00:23:51,760
and to run it for everything but i would

634
00:23:51,760 --> 00:23:53,679
say the argo is there

635
00:23:53,679 --> 00:23:55,600
and i think

636
00:23:55,600 --> 00:23:57,440
maybe 10 years

637
00:23:57,440 --> 00:23:59,279
but it's not really for me to say that's

638
00:23:59,279 --> 00:24:03,320
just my personal i guess

639
00:24:05,520 --> 00:24:06,320
uh

640
00:24:06,320 --> 00:24:09,039
i have a simple practical question why

641
00:24:09,039 --> 00:24:10,960
three is the magic number because i

642
00:24:10,960 --> 00:24:12,799
realized that in another product they

643
00:24:12,799 --> 00:24:13,760
also

644
00:24:13,760 --> 00:24:16,640
took every three consecutive characters

645
00:24:16,640 --> 00:24:18,960
and and build their model based on that

646
00:24:18,960 --> 00:24:22,000
why not four characters no uh we

647
00:24:22,000 --> 00:24:24,400
we have uh actually four four of those

648
00:24:24,400 --> 00:24:26,960
layers so we take every two three four

649
00:24:26,960 --> 00:24:29,360
and five substrings

650
00:24:29,360 --> 00:24:32,240
and by that it's empirically so someone

651
00:24:32,240 --> 00:24:35,440
tried six and someone tried one and we

652
00:24:35,440 --> 00:24:37,120
arrived at the solution okay this this

653
00:24:37,120 --> 00:24:38,880
is where it made sense

654
00:24:38,880 --> 00:24:40,080
but no

655
00:24:40,080 --> 00:24:45,080
practical reasoning just we tried it all

656
00:24:47,440 --> 00:24:51,520
okay that seems to be it thomas again

657
00:24:51,520 --> 00:24:53,650
thank you very much

658
00:24:53,650 --> 00:25:00,400
[Applause]

659
00:25:00,400 --> 00:25:02,480
you

