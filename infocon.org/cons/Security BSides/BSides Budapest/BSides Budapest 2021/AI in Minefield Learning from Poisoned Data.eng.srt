1
00:00:00,080 --> 00:00:02,000
hi everyone thanks for joining us in

2
00:00:02,000 --> 00:00:04,720
this stock ai in a minefield learning

3
00:00:04,720 --> 00:00:06,480
from poison data

4
00:00:06,480 --> 00:00:08,160
my name is jonathan ozaria and i'm a

5
00:00:08,160 --> 00:00:10,559
data scientist at imperfe for the past

6
00:00:10,559 --> 00:00:12,320
few years i've been creating ai-based

7
00:00:12,320 --> 00:00:13,840
algorithms to protect against web

8
00:00:13,840 --> 00:00:16,079
attacks in my previous role i was a

9
00:00:16,079 --> 00:00:17,680
security researcher

10
00:00:17,680 --> 00:00:19,359
here joining me in this talk is it

11
00:00:19,359 --> 00:00:20,480
sequential

12
00:00:20,480 --> 00:00:23,519
lead scientist at imperva

13
00:00:23,519 --> 00:00:25,599
i'm mitch mantin a lead scientist at

14
00:00:25,599 --> 00:00:26,720
imperva

15
00:00:26,720 --> 00:00:29,279
in the last 21 years i've been

16
00:00:29,279 --> 00:00:32,079
innovating in security algorithms and

17
00:00:32,079 --> 00:00:33,840
their intersection

18
00:00:33,840 --> 00:00:36,880
i love math i love algorithms and i

19
00:00:36,880 --> 00:00:38,719
really enjoy the game of understanding

20
00:00:38,719 --> 00:00:42,800
threats and designing mitigation

21
00:00:42,960 --> 00:00:45,280
we start with speaking

22
00:00:45,280 --> 00:00:47,520
very quickly about ai and all the risks

23
00:00:47,520 --> 00:00:50,000
that are coming with ai and then we'll

24
00:00:50,000 --> 00:00:52,879
uh dive into the the threat landscape of

25
00:00:52,879 --> 00:00:54,000
ai

26
00:00:54,000 --> 00:00:56,800
uh then we'll zoom in to uh data

27
00:00:56,800 --> 00:00:58,399
poisoning threats

28
00:00:58,399 --> 00:01:01,359
why how and when is this threat

29
00:01:01,359 --> 00:01:04,720
applicable and what can we do about it

30
00:01:04,720 --> 00:01:06,799
then we

31
00:01:06,799 --> 00:01:09,439
will talk about how the data poisoning

32
00:01:09,439 --> 00:01:11,520
threat is is effective

33
00:01:11,520 --> 00:01:14,080
and is meeting can be mitigated in the

34
00:01:14,080 --> 00:01:17,680
world of web or api uh security uh and

35
00:01:17,680 --> 00:01:19,360
we end up with uh summary and

36
00:01:19,360 --> 00:01:22,000
conclusions

37
00:01:22,720 --> 00:01:25,280
uh no doubt we are in the ai era

38
00:01:25,280 --> 00:01:27,520
artificial intelligence systems are

39
00:01:27,520 --> 00:01:30,079
everywhere ai technology is changing

40
00:01:30,079 --> 00:01:32,720
almost every domain of our lives

41
00:01:32,720 --> 00:01:35,600
and ai era is in fact also the data era

42
00:01:35,600 --> 00:01:37,759
because the data is the fuel that that

43
00:01:37,759 --> 00:01:40,799
fuels that makes this ai systems ai

44
00:01:40,799 --> 00:01:42,479
technology work

45
00:01:42,479 --> 00:01:45,360
and both ai era and data era they have

46
00:01:45,360 --> 00:01:47,360
great contribution however this

47
00:01:47,360 --> 00:01:50,320
contribution comes with several caveats

48
00:01:50,320 --> 00:01:52,640
which we usually tend to ignore or at

49
00:01:52,640 --> 00:01:53,520
least

50
00:01:53,520 --> 00:01:56,399
to underestimate and uh in this talk

51
00:01:56,399 --> 00:01:58,399
we'll we will dive we

52
00:01:58,399 --> 00:02:02,159
will discuss at least some of them

53
00:02:02,159 --> 00:02:04,960
um we start with speaking about the

54
00:02:04,960 --> 00:02:08,318
risks of ai so ai well it's a new attack

55
00:02:08,318 --> 00:02:10,160
surface we'll talk about it it also

56
00:02:10,160 --> 00:02:11,200
provides

57
00:02:11,200 --> 00:02:13,920
uh tools new tools not only for for the

58
00:02:13,920 --> 00:02:15,760
good guys but also for the bad guys for

59
00:02:15,760 --> 00:02:17,760
automation data mining and attacker

60
00:02:17,760 --> 00:02:19,520
insight but i think there are two

61
00:02:19,520 --> 00:02:22,720
significant risks that are really uh

62
00:02:22,720 --> 00:02:24,879
important and should be

63
00:02:24,879 --> 00:02:26,800
at least mentioned in every discussion

64
00:02:26,800 --> 00:02:29,040
on on ai

65
00:02:29,040 --> 00:02:32,160
first one is a deep fake the ability of

66
00:02:32,160 --> 00:02:34,239
actors let's uh soon for the sake of

67
00:02:34,239 --> 00:02:37,040
this discussion malicious actors to

68
00:02:37,040 --> 00:02:39,840
synthesize

69
00:02:41,360 --> 00:02:43,920
images or audio

70
00:02:43,920 --> 00:02:44,879
or

71
00:02:44,879 --> 00:02:47,840
or video scenes that look very very

72
00:02:47,840 --> 00:02:48,959
authentic

73
00:02:48,959 --> 00:02:51,440
uh which can include of course uh

74
00:02:51,440 --> 00:02:53,599
politicians or uh

75
00:02:53,599 --> 00:02:56,160
other people that uh whose opinion uh

76
00:02:56,160 --> 00:02:59,120
matters and i think that uh

77
00:02:59,120 --> 00:03:00,239
today

78
00:03:00,239 --> 00:03:02,400
we only see we're stuck we are only

79
00:03:02,400 --> 00:03:04,400
starting to see

80
00:03:04,400 --> 00:03:06,640
the the impact the potential impact of

81
00:03:06,640 --> 00:03:08,400
this uh

82
00:03:08,400 --> 00:03:10,400
potential attackers technology and it

83
00:03:10,400 --> 00:03:12,400
will only get a

84
00:03:12,400 --> 00:03:15,440
get worth in the future i i'm confident

85
00:03:15,440 --> 00:03:16,480
about that

86
00:03:16,480 --> 00:03:20,319
the second one is a idea discrimination

87
00:03:20,319 --> 00:03:23,440
or actually discrimination by ai

88
00:03:23,440 --> 00:03:25,440
and ai technology

89
00:03:25,440 --> 00:03:28,480
usually uh takes data from the past and

90
00:03:28,480 --> 00:03:30,239
wants to predict the future so it

91
00:03:30,239 --> 00:03:31,360
assumes that

92
00:03:31,360 --> 00:03:33,840
the future in the past are alike but if

93
00:03:33,840 --> 00:03:36,239
we had anything uh bad or incorrect in

94
00:03:36,239 --> 00:03:37,680
the in the past

95
00:03:37,680 --> 00:03:41,680
uh like uh biases uh for minorities uh

96
00:03:41,680 --> 00:03:42,560
or

97
00:03:42,560 --> 00:03:45,519
uh racism and and stuff like that then

98
00:03:45,519 --> 00:03:48,319
ai has the tendency to perpetuate these

99
00:03:48,319 --> 00:03:49,360
biases

100
00:03:49,360 --> 00:03:52,239
and uh for example if there is a certain

101
00:03:52,239 --> 00:03:54,400
neighborhood where people took loans and

102
00:03:54,400 --> 00:03:57,120
didn't return it then uh

103
00:03:57,120 --> 00:03:59,040
new people from this neighborhood that

104
00:03:59,040 --> 00:04:01,920
we want to take loan

105
00:04:01,920 --> 00:04:03,519
will

106
00:04:03,519 --> 00:04:05,519
will probably get a higher interest

107
00:04:05,519 --> 00:04:07,200
because they will be marked as a high

108
00:04:07,200 --> 00:04:08,879
risk regardless of

109
00:04:08,879 --> 00:04:11,280
what is the actual thing or the profile

110
00:04:11,280 --> 00:04:13,680
of this particular person itself this is

111
00:04:13,680 --> 00:04:17,680
kind of a of a discriminating profiling

112
00:04:17,680 --> 00:04:20,079
system

113
00:04:21,040 --> 00:04:23,520
most of you are probably familiar with

114
00:04:23,520 --> 00:04:25,199
the gartner hype cycle for a new

115
00:04:25,199 --> 00:04:26,960
technologies

116
00:04:26,960 --> 00:04:28,720
and you can think also of the security

117
00:04:28,720 --> 00:04:31,840
life cycle for new technologies um at

118
00:04:31,840 --> 00:04:34,080
the beginning there is uh technology is

119
00:04:34,080 --> 00:04:36,000
being developed and all the developers

120
00:04:36,000 --> 00:04:37,440
are

121
00:04:37,440 --> 00:04:40,400
are very excited with the opportunities

122
00:04:40,400 --> 00:04:42,400
and the applications and they focus on

123
00:04:42,400 --> 00:04:43,919
all the technical obstacles that they

124
00:04:43,919 --> 00:04:46,880
have in order to make this work and they

125
00:04:46,880 --> 00:04:48,800
pay only little attention or no

126
00:04:48,800 --> 00:04:51,919
attention at all for security and

127
00:04:51,919 --> 00:04:53,120
at some point

128
00:04:53,120 --> 00:04:55,280
someone discovers that in some cases

129
00:04:55,280 --> 00:04:57,919
with particular inputs this technology

130
00:04:57,919 --> 00:05:01,039
behaves in an odd way

131
00:05:01,039 --> 00:05:03,199
and then another vulnerability is being

132
00:05:03,199 --> 00:05:05,840
discovered another one and at some point

133
00:05:05,840 --> 00:05:08,000
sometimes uh people start to ask

134
00:05:08,000 --> 00:05:09,600
themselves whether this technology will

135
00:05:09,600 --> 00:05:10,639
ever be

136
00:05:10,639 --> 00:05:14,560
a usable in a safe manner

137
00:05:14,639 --> 00:05:16,000
and then we

138
00:05:16,000 --> 00:05:18,639
we get to once we are in the in the

139
00:05:18,639 --> 00:05:21,520
bottom of the curve

140
00:05:21,520 --> 00:05:24,000
security researchers and domain experts

141
00:05:24,000 --> 00:05:26,639
start to work together or alone to and

142
00:05:26,639 --> 00:05:28,800
develop methodology to give

143
00:05:28,800 --> 00:05:30,479
to understand what are the attacks to

144
00:05:30,479 --> 00:05:32,160
model them to give them names to develop

145
00:05:32,160 --> 00:05:34,960
mitigations and we get to this into the

146
00:05:34,960 --> 00:05:37,440
the healthy slope of uh

147
00:05:37,440 --> 00:05:39,120
development uh

148
00:05:39,120 --> 00:05:41,520
until the uh

149
00:05:41,520 --> 00:05:43,759
technology becomes uh usable in in a

150
00:05:43,759 --> 00:05:46,000
safe manner and then still there are

151
00:05:46,000 --> 00:05:47,840
there is dynamics of new threats new

152
00:05:47,840 --> 00:05:50,639
mitigations etc etc uh but but

153
00:05:50,639 --> 00:05:53,440
essentially the the technology is um is

154
00:05:53,440 --> 00:05:54,960
a safe and stable

155
00:05:54,960 --> 00:05:57,600
uh and we've seen that uh for web in the

156
00:05:57,600 --> 00:06:00,720
80s and for mobile in the 90s and and we

157
00:06:00,720 --> 00:06:03,919
have it in ai today uh we are only now

158
00:06:03,919 --> 00:06:04,880
seeing

159
00:06:04,880 --> 00:06:08,720
uh we started starting to see um

160
00:06:08,720 --> 00:06:10,080
more and more discussion about the

161
00:06:10,080 --> 00:06:14,400
threats that our ai systems are um

162
00:06:14,400 --> 00:06:16,560
are exposed to uh and this is a healthy

163
00:06:16,560 --> 00:06:18,560
discussion that i think will bring us to

164
00:06:18,560 --> 00:06:21,520
uh better better understanding of the

165
00:06:21,520 --> 00:06:24,080
threat and mitigation

166
00:06:24,080 --> 00:06:26,080
so this is a typical

167
00:06:26,080 --> 00:06:28,800
machine learning system uh it has uh in

168
00:06:28,800 --> 00:06:30,800
the training phase training data is fed

169
00:06:30,800 --> 00:06:32,000
into

170
00:06:32,000 --> 00:06:34,319
an algorithm that builds a model this

171
00:06:34,319 --> 00:06:36,800
can be a classification model regression

172
00:06:36,800 --> 00:06:39,120
model it can be trees forest a neural

173
00:06:39,120 --> 00:06:40,800
network whatever

174
00:06:40,800 --> 00:06:42,960
and then in the inference phase input

175
00:06:42,960 --> 00:06:44,560
data is being fed to the model and the

176
00:06:44,560 --> 00:06:46,720
model makes decisions on it

177
00:06:46,720 --> 00:06:49,840
class a class b dog cat

178
00:06:49,840 --> 00:06:51,360
etc

179
00:06:51,360 --> 00:06:53,520
in some cases the the prediction that

180
00:06:53,520 --> 00:06:55,919
the outcome of the model is being uh

181
00:06:55,919 --> 00:06:57,599
evaluated in order to continue and

182
00:06:57,599 --> 00:06:59,199
improve the uh

183
00:06:59,199 --> 00:07:01,280
improve the model

184
00:07:01,280 --> 00:07:04,400
now looking at this uh uh system from an

185
00:07:04,400 --> 00:07:06,960
attacker perspective now if the attacker

186
00:07:06,960 --> 00:07:09,680
is an insider or if he is an

187
00:07:09,680 --> 00:07:11,440
outsider that found his way in by

188
00:07:11,440 --> 00:07:14,560
fishing a malware infection whatever

189
00:07:14,560 --> 00:07:16,080
then the sky's the limit you can do

190
00:07:16,080 --> 00:07:18,000
whatever he likes he can steal the model

191
00:07:18,000 --> 00:07:19,599
you can temper the model you can temper

192
00:07:19,599 --> 00:07:21,039
every particular

193
00:07:21,039 --> 00:07:23,120
decision that the model tries to make uh

194
00:07:23,120 --> 00:07:24,720
he can steal the data he can temper the

195
00:07:24,720 --> 00:07:26,720
data he can do whatever he likes

196
00:07:26,720 --> 00:07:29,199
however even when the attacker isn't is

197
00:07:29,199 --> 00:07:31,759
not an insider still there are

198
00:07:31,759 --> 00:07:34,000
pretty many things he can do

199
00:07:34,000 --> 00:07:36,080
uh it can do a

200
00:07:36,080 --> 00:07:38,479
ml invasion sometimes called deception

201
00:07:38,479 --> 00:07:42,160
sometimes adversarial examples

202
00:07:42,160 --> 00:07:43,759
many of you probably are familiar with

203
00:07:43,759 --> 00:07:46,000
this example a very concerning example

204
00:07:46,000 --> 00:07:46,720
of

205
00:07:46,720 --> 00:07:49,840
a traffic sign a stop sign that when um

206
00:07:49,840 --> 00:07:51,440
when someone adds a couple of stickers

207
00:07:51,440 --> 00:07:54,960
to it then suddenly the uh the ai engine

208
00:07:54,960 --> 00:07:56,720
of an autonomous car

209
00:07:56,720 --> 00:07:58,879
looks at this stop sign and he says okay

210
00:07:58,879 --> 00:08:00,800
this is um a

211
00:08:00,800 --> 00:08:02,639
speed limit sign which of course can

212
00:08:02,639 --> 00:08:04,960
have devastating consequences

213
00:08:04,960 --> 00:08:09,280
and uh from what i i looked every time

214
00:08:09,280 --> 00:08:12,080
the researchers tried to to build

215
00:08:12,080 --> 00:08:14,000
adversarial examples for a machine

216
00:08:14,000 --> 00:08:16,560
learning system it was it was pretty

217
00:08:16,560 --> 00:08:18,960
easy uh thing to do

218
00:08:18,960 --> 00:08:21,280
uh the second threat is training data

219
00:08:21,280 --> 00:08:23,039
poisoning we'll speak about that in in

220
00:08:23,039 --> 00:08:26,479
more depth later on uh the third one uh

221
00:08:26,479 --> 00:08:28,319
training data leakage it's slightly more

222
00:08:28,319 --> 00:08:29,520
esoteric

223
00:08:29,520 --> 00:08:30,639
threat

224
00:08:30,639 --> 00:08:33,440
but it is still applicable uh during the

225
00:08:33,440 --> 00:08:34,479
training

226
00:08:34,479 --> 00:08:36,958
uh data from the training data

227
00:08:36,958 --> 00:08:39,120
is sometimes embedded somehow into the

228
00:08:39,120 --> 00:08:42,799
model and there are ways to uh

229
00:08:42,799 --> 00:08:46,640
to extract this uh this data that left

230
00:08:46,640 --> 00:08:49,760
that linked to the model and recover it

231
00:08:49,760 --> 00:08:52,000
and when you use the sensitive data for

232
00:08:52,000 --> 00:08:53,360
the training

233
00:08:53,360 --> 00:08:56,480
health records pii things like that then

234
00:08:56,480 --> 00:08:58,959
this risk should be considered and uh

235
00:08:58,959 --> 00:09:02,000
and addressed properly

236
00:09:02,000 --> 00:09:04,480
and so how does data poisoning work on

237
00:09:04,480 --> 00:09:07,279
the left side you see a typical um

238
00:09:07,279 --> 00:09:10,800
a linear uh classifier it aims to

239
00:09:10,800 --> 00:09:11,920
separate

240
00:09:11,920 --> 00:09:13,839
in in the best way possible between the

241
00:09:13,839 --> 00:09:15,920
the red triangles and the blues and

242
00:09:15,920 --> 00:09:18,880
circles and it does that uh pretty well

243
00:09:18,880 --> 00:09:21,440
however um you can see that even if you

244
00:09:21,440 --> 00:09:23,120
change a single point then you get a

245
00:09:23,120 --> 00:09:26,080
completely uh a different classifier it

246
00:09:26,080 --> 00:09:28,080
still does pretty good job

247
00:09:28,080 --> 00:09:30,000
but it is very different and indeed i

248
00:09:30,000 --> 00:09:31,200
think one of the things that

249
00:09:31,200 --> 00:09:33,120
characterizes the machine learning

250
00:09:33,120 --> 00:09:35,839
system that sometimes very small number

251
00:09:35,839 --> 00:09:38,800
of data points uh can have great impact

252
00:09:38,800 --> 00:09:42,720
on the on the model and if uh the these

253
00:09:42,720 --> 00:09:45,120
data points are added deliberately and

254
00:09:45,120 --> 00:09:47,040
now look at the on the right side on

255
00:09:47,040 --> 00:09:49,279
this uh again linear classifier between

256
00:09:49,279 --> 00:09:50,560
the red and the blue

257
00:09:50,560 --> 00:09:51,279
then

258
00:09:51,279 --> 00:09:54,240
an attacker will want to to put to

259
00:09:54,240 --> 00:09:57,839
create new data points in a place that

260
00:09:57,839 --> 00:09:58,720
we

261
00:09:58,720 --> 00:10:00,240
will confuse the model as much as

262
00:10:00,240 --> 00:10:01,279
possible

263
00:10:01,279 --> 00:10:03,440
and and indeed on the right side what

264
00:10:03,440 --> 00:10:07,120
you see is uh that with these new uh red

265
00:10:07,120 --> 00:10:09,440
dots right there data points then the

266
00:10:09,440 --> 00:10:12,880
model is completely useless it does

267
00:10:12,880 --> 00:10:15,760
pretty lousy job uh separating the

268
00:10:15,760 --> 00:10:18,880
uh the blue from the from the red

269
00:10:18,880 --> 00:10:21,760
now data poisoning is uh it's pretty new

270
00:10:21,760 --> 00:10:25,120
methodology and i i mean i only uh

271
00:10:25,120 --> 00:10:27,279
heard about this notion a couple of

272
00:10:27,279 --> 00:10:29,440
years ago but i think

273
00:10:29,440 --> 00:10:31,040
this is not really

274
00:10:31,040 --> 00:10:33,839
a new threat

275
00:10:35,200 --> 00:10:37,519
this is very old threat almost as old as

276
00:10:37,519 --> 00:10:39,839
the internet because i'm i i'm i believe

277
00:10:39,839 --> 00:10:43,360
that like myself when you look at um

278
00:10:43,360 --> 00:10:45,120
at a review a trip advice or a high

279
00:10:45,120 --> 00:10:47,600
review then you ask yourself is this a

280
00:10:47,600 --> 00:10:50,240
real review or is this fake review by

281
00:10:50,240 --> 00:10:52,800
the hotel owner and tripadvisor ask

282
00:10:52,800 --> 00:10:55,120
himself the same thing and take action

283
00:10:55,120 --> 00:10:57,120
in order to try to minimize the impact

284
00:10:57,120 --> 00:10:57,760
of

285
00:10:57,760 --> 00:10:59,600
such a fake reviews

286
00:10:59,600 --> 00:11:02,480
and in every rating system it can be a

287
00:11:02,480 --> 00:11:05,040
travel rating system like um a trip

288
00:11:05,040 --> 00:11:08,000
advisor booking or google uh it can be

289
00:11:08,000 --> 00:11:10,640
e-commerce rating system like amazon it

290
00:11:10,640 --> 00:11:11,760
can be

291
00:11:11,760 --> 00:11:14,880
even movie rating system like netflix or

292
00:11:14,880 --> 00:11:17,839
or imdb it is subject to data poisoning

293
00:11:17,839 --> 00:11:20,079
and and people understand that and the

294
00:11:20,079 --> 00:11:21,680
owners of these systems

295
00:11:21,680 --> 00:11:24,240
and understand that whenever you have

296
00:11:24,240 --> 00:11:26,079
data coming from outside and whenever

297
00:11:26,079 --> 00:11:27,120
there is

298
00:11:27,120 --> 00:11:29,200
a motivation for someone and if you're

299
00:11:29,200 --> 00:11:30,720
doing something significant then there

300
00:11:30,720 --> 00:11:33,600
is motivation for someone uh to uh to

301
00:11:33,600 --> 00:11:36,480
change your decisions then uh the threat

302
00:11:36,480 --> 00:11:38,399
of data poisoning is there and is

303
00:11:38,399 --> 00:11:41,440
probably being realized

304
00:11:41,440 --> 00:11:44,160
uh one of the first battlefield of uh

305
00:11:44,160 --> 00:11:47,440
of data poisoning is the area of uh spam

306
00:11:47,440 --> 00:11:49,440
filters maybe probably one of the

307
00:11:49,440 --> 00:11:51,279
reasons for that is that this is one of

308
00:11:51,279 --> 00:11:54,240
the first places where cyber security

309
00:11:54,240 --> 00:11:56,079
technology

310
00:11:56,079 --> 00:11:58,160
based on machine learning was proven

311
00:11:58,160 --> 00:11:59,519
effective

312
00:11:59,519 --> 00:12:01,360
so what you see here is a model skewing

313
00:12:01,360 --> 00:12:04,000
attack on a gmail spam filter

314
00:12:04,000 --> 00:12:06,639
the attack include the attack included

315
00:12:06,639 --> 00:12:08,800
massive amounts of spam emails

316
00:12:08,800 --> 00:12:10,720
all of them labeled as benign by the

317
00:12:10,720 --> 00:12:14,959
attackers and uh they included patterns

318
00:12:14,959 --> 00:12:17,120
words that um

319
00:12:17,120 --> 00:12:19,680
were later probably planned to be

320
00:12:19,680 --> 00:12:21,120
included in a

321
00:12:21,120 --> 00:12:23,279
in a spam campaign

322
00:12:23,279 --> 00:12:25,680
later on and what the attackers wanted

323
00:12:25,680 --> 00:12:28,320
to uh to obtain is to make the uh the

324
00:12:28,320 --> 00:12:30,079
spam filter the

325
00:12:30,079 --> 00:12:33,440
classification model uh to misclassify

326
00:12:33,440 --> 00:12:36,800
all this uh struck this sort of messages

327
00:12:36,800 --> 00:12:41,760
as a legitimate as benign uh and to pass

328
00:12:42,160 --> 00:12:44,320
so that the the spam attack will be

329
00:12:44,320 --> 00:12:46,800
successful so this is

330
00:12:46,800 --> 00:12:48,720
you can think of that that's a sort of a

331
00:12:48,720 --> 00:12:50,079
backdoors

332
00:12:50,079 --> 00:12:52,480
uh uh in the model that was their uh

333
00:12:52,480 --> 00:12:54,399
their intention this is why the bay was

334
00:12:54,399 --> 00:12:57,279
in 2017 2018.

335
00:12:57,279 --> 00:12:59,839
uh another example another attack this

336
00:12:59,839 --> 00:13:02,320
time is this is a a

337
00:13:02,320 --> 00:13:05,040
research paper on the spam based

338
00:13:05,040 --> 00:13:07,120
spam filter

339
00:13:07,120 --> 00:13:08,880
this time that the researchers took

340
00:13:08,880 --> 00:13:10,720
slightly different approach

341
00:13:10,720 --> 00:13:13,200
they decided to try this

342
00:13:13,200 --> 00:13:13,920
they

343
00:13:13,920 --> 00:13:16,480
carried out an availability attack they

344
00:13:16,480 --> 00:13:17,760
wanted to make the model learn

345
00:13:17,760 --> 00:13:20,320
incorrectly so they took a collection of

346
00:13:20,320 --> 00:13:22,800
words probably very popular words that

347
00:13:22,800 --> 00:13:25,680
are uh characterized many many uh

348
00:13:25,680 --> 00:13:27,760
legitimate email messages and they

349
00:13:27,760 --> 00:13:30,000
created many emails that were classified

350
00:13:30,000 --> 00:13:31,279
as spam

351
00:13:31,279 --> 00:13:35,920
and pushed these uh emails uh to the

352
00:13:35,920 --> 00:13:38,880
to the spam base spam filter

353
00:13:38,880 --> 00:13:41,040
and uh the impact of this attack was

354
00:13:41,040 --> 00:13:43,920
that uh even with control of one percent

355
00:13:43,920 --> 00:13:45,680
of the messages and used for the

356
00:13:45,680 --> 00:13:48,079
training then

357
00:13:48,079 --> 00:13:50,000
the researchers were able to make the

358
00:13:50,000 --> 00:13:53,040
model uh classify 80 of the benign

359
00:13:53,040 --> 00:13:56,240
messages as spam and 95

360
00:13:56,240 --> 00:13:58,639
of the benign messages as unsure

361
00:13:58,639 --> 00:14:00,639
both numbers that

362
00:14:00,639 --> 00:14:03,839
rendered this uh model completely uh uh

363
00:14:03,839 --> 00:14:04,880
useless

364
00:14:04,880 --> 00:14:07,120
uh and whatsoever

365
00:14:07,120 --> 00:14:08,480
uh so

366
00:14:08,480 --> 00:14:10,240
now probably like uh

367
00:14:10,240 --> 00:14:12,480
i was in in the past you're you're

368
00:14:12,480 --> 00:14:14,240
saying this and you're saying okay so

369
00:14:14,240 --> 00:14:16,480
the problem is that we gave the attacker

370
00:14:16,480 --> 00:14:18,800
the opportunity to do the labeling this

371
00:14:18,800 --> 00:14:21,279
is untrusted labeling if we make sure

372
00:14:21,279 --> 00:14:23,920
that the labeling is done in a trusted

373
00:14:23,920 --> 00:14:27,519
environment then we're good right

374
00:14:27,519 --> 00:14:28,399
wrong

375
00:14:28,399 --> 00:14:30,639
in this version of uh data poisoning

376
00:14:30,639 --> 00:14:33,199
attack called clean label attack

377
00:14:33,199 --> 00:14:34,639
uh

378
00:14:34,639 --> 00:14:38,320
here the attacker does not have any uh

379
00:14:38,320 --> 00:14:41,040
uh any control over the labeling process

380
00:14:41,040 --> 00:14:43,120
but only on the on the data generation

381
00:14:43,120 --> 00:14:45,519
process the victim here is an image

382
00:14:45,519 --> 00:14:48,480
classification uh algorithm

383
00:14:48,480 --> 00:14:50,480
what the attacker wants to achieve he

384
00:14:50,480 --> 00:14:52,959
wants images of fish to be classified as

385
00:14:52,959 --> 00:14:55,920
dogs and the way to achieve that uh he

386
00:14:55,920 --> 00:14:58,160
takes an image of a dog and now he he

387
00:14:58,160 --> 00:15:01,199
crafts invisible noise invisible for us

388
00:15:01,199 --> 00:15:04,160
of course and adds to this image of of a

389
00:15:04,160 --> 00:15:06,240
dog

390
00:15:06,240 --> 00:15:08,720
for us this as you can see the images

391
00:15:08,720 --> 00:15:10,480
still are

392
00:15:10,480 --> 00:15:13,199
look exactly like a dogs all these

393
00:15:13,199 --> 00:15:14,240
images

394
00:15:14,240 --> 00:15:17,120
however this noise that was added uh

395
00:15:17,120 --> 00:15:19,279
actually is being used by the model to

396
00:15:19,279 --> 00:15:21,680
um

397
00:15:21,680 --> 00:15:23,839
is considered by the model in a way that

398
00:15:23,839 --> 00:15:25,680
makes the model later classify these

399
00:15:25,680 --> 00:15:27,199
image images

400
00:15:27,199 --> 00:15:30,240
on the top of fish he will classify them

401
00:15:30,240 --> 00:15:33,120
also as dogs

402
00:15:33,839 --> 00:15:35,920
and

403
00:15:35,920 --> 00:15:38,560
here even if we have the labeling

404
00:15:38,560 --> 00:15:41,040
happening in a secure environment by

405
00:15:41,040 --> 00:15:43,120
someone we trust then what you will see

406
00:15:43,120 --> 00:15:44,800
in all these images is

407
00:15:44,800 --> 00:15:45,920
is a dog

408
00:15:45,920 --> 00:15:48,399
and the attackers need zeroing to have

409
00:15:48,399 --> 00:15:50,079
zero intervention

410
00:15:50,079 --> 00:15:52,160
in the labeling process and this attack

411
00:15:52,160 --> 00:15:53,120
is still

412
00:15:53,120 --> 00:15:55,519
very effective uh it was

413
00:15:55,519 --> 00:15:58,079
succeeding in more than 95 percent of

414
00:15:58,079 --> 00:15:59,040
the uh

415
00:15:59,040 --> 00:16:01,199
of the cases with and the classification

416
00:16:01,199 --> 00:16:03,600
was done with very very high confidence

417
00:16:03,600 --> 00:16:07,040
which is also concerning

418
00:16:07,040 --> 00:16:09,360
so uh we understand the threat uh what

419
00:16:09,360 --> 00:16:12,560
about mitigation so uh there are several

420
00:16:12,560 --> 00:16:15,120
pretty straightforward natural uh uh

421
00:16:15,120 --> 00:16:16,560
means to uh

422
00:16:16,560 --> 00:16:19,360
uh to limit the the risk of data

423
00:16:19,360 --> 00:16:22,000
poisoning one of them is to filter a

424
00:16:22,000 --> 00:16:24,399
suspicious data uh for example data

425
00:16:24,399 --> 00:16:26,959
coming from suspicious origins or ip

426
00:16:26,959 --> 00:16:28,240
addresses or

427
00:16:28,240 --> 00:16:30,959
from uh as suspicious say users when you

428
00:16:30,959 --> 00:16:33,199
have users and authenticated users in

429
00:16:33,199 --> 00:16:34,320
the system

430
00:16:34,320 --> 00:16:36,880
uh when the the the when the data comes

431
00:16:36,880 --> 00:16:39,120
from suspicious clients maybe from from

432
00:16:39,120 --> 00:16:40,079
bots

433
00:16:40,079 --> 00:16:41,920
um

434
00:16:41,920 --> 00:16:44,800
and also and another uh a mitigation

435
00:16:44,800 --> 00:16:46,560
technique can be to

436
00:16:46,560 --> 00:16:49,199
do fault tolerant data sampling to limit

437
00:16:49,199 --> 00:16:51,120
the impact of data points that are

438
00:16:51,120 --> 00:16:53,120
arriving from a single entity

439
00:16:53,120 --> 00:16:55,759
uh limited impact means maybe

440
00:16:55,759 --> 00:16:57,680
take only few

441
00:16:57,680 --> 00:17:00,079
data points from there or

442
00:17:00,079 --> 00:17:01,120
somehow

443
00:17:01,120 --> 00:17:03,360
lower the weight that it can or limit

444
00:17:03,360 --> 00:17:08,319
the weight a single uh entity can uh

445
00:17:08,319 --> 00:17:10,079
uh can create

446
00:17:10,079 --> 00:17:13,039
uh now what exactly is entity is is that

447
00:17:13,039 --> 00:17:14,880
that depends really on on the problem on

448
00:17:14,880 --> 00:17:16,640
the domain on the algorithm on the model

449
00:17:16,640 --> 00:17:19,039
on on many things for example in the

450
00:17:19,039 --> 00:17:21,520
tripadvisor case it can be a user it can

451
00:17:21,520 --> 00:17:23,599
be ip address uh

452
00:17:23,599 --> 00:17:26,079
it can be something like that

453
00:17:26,079 --> 00:17:26,959
other

454
00:17:26,959 --> 00:17:29,919
less effective mitigation techniques

455
00:17:29,919 --> 00:17:31,600
diff tracking

456
00:17:31,600 --> 00:17:33,360
look for significant difference between

457
00:17:33,360 --> 00:17:36,160
the new model that is was just generated

458
00:17:36,160 --> 00:17:40,080
and previous model and if there is

459
00:17:40,080 --> 00:17:42,000
a a high

460
00:17:42,000 --> 00:17:44,240
difference high distance then we can

461
00:17:44,240 --> 00:17:45,919
assume that we are under data poisoning

462
00:17:45,919 --> 00:17:48,880
attack or using a golden dataset as a

463
00:17:48,880 --> 00:17:51,200
reliable benchmark data set that we know

464
00:17:51,200 --> 00:17:53,280
for sure what is the right prediction

465
00:17:53,280 --> 00:17:55,120
classification for it and then we assume

466
00:17:55,120 --> 00:17:55,840
that

467
00:17:55,840 --> 00:17:58,799
whenever there is a mistake there uh

468
00:17:58,799 --> 00:18:01,520
then the model was

469
00:18:01,520 --> 00:18:03,760
we are under data poisoning attack uh of

470
00:18:03,760 --> 00:18:05,039
course when you have detection you still

471
00:18:05,039 --> 00:18:06,080
have

472
00:18:06,080 --> 00:18:09,520
you have to do something with it uh

473
00:18:09,520 --> 00:18:11,679
another uh i call this a

474
00:18:11,679 --> 00:18:13,200
pseudo-mitigation

475
00:18:13,200 --> 00:18:16,320
is to assume that uh the attacker does

476
00:18:16,320 --> 00:18:18,320
not know what we do he does not know the

477
00:18:18,320 --> 00:18:20,400
model he doesn't know the algorithm then

478
00:18:20,400 --> 00:18:22,559
he will not know exactly how to uh how

479
00:18:22,559 --> 00:18:25,440
to attack us what the so-called

480
00:18:25,440 --> 00:18:27,280
security by obscurity

481
00:18:27,280 --> 00:18:29,520
hearing besides

482
00:18:29,520 --> 00:18:31,840
we know we know that security by

483
00:18:31,840 --> 00:18:35,200
obscurity is very very rarely proved

484
00:18:35,200 --> 00:18:37,679
itself as an effective uh security

485
00:18:37,679 --> 00:18:42,240
mechanism so um i really recommend uh as

486
00:18:42,240 --> 00:18:45,360
not to rely on on security biosecurity

487
00:18:45,360 --> 00:18:48,639
to to protect your systems

488
00:18:49,039 --> 00:18:51,600
so what we had so far so data poisoning

489
00:18:51,600 --> 00:18:53,280
is a significant threat on learning

490
00:18:53,280 --> 00:18:54,320
mechanism

491
00:18:54,320 --> 00:18:56,240
and the third is critical when using

492
00:18:56,240 --> 00:18:58,640
data from untrusted sources only some of

493
00:18:58,640 --> 00:19:00,720
the domains are cyber domains cyber

494
00:19:00,720 --> 00:19:02,880
security domains like a firewall spam

495
00:19:02,880 --> 00:19:06,240
and malware detection that use ai

496
00:19:06,240 --> 00:19:08,640
and rating systems like travel systems

497
00:19:08,640 --> 00:19:11,440
and e-commerce uh are subject to data

498
00:19:11,440 --> 00:19:14,240
poisoning uh threats uh and

499
00:19:14,240 --> 00:19:16,320
unfortunately there is no silver wolf

500
00:19:16,320 --> 00:19:18,480
mitigation there are collection of

501
00:19:18,480 --> 00:19:20,559
of mitigation techniques that when used

502
00:19:20,559 --> 00:19:22,880
together can uh throttle the attacker to

503
00:19:22,880 --> 00:19:25,840
to a reasonable uh

504
00:19:25,840 --> 00:19:29,600
uh to reasonable extent

505
00:19:29,600 --> 00:19:32,240
thanks etique okay so how do we secure

506
00:19:32,240 --> 00:19:34,720
web applications and apis well here on

507
00:19:34,720 --> 00:19:36,320
the left you can see the outside the

508
00:19:36,320 --> 00:19:38,799
threads along with the rest of the users

509
00:19:38,799 --> 00:19:39,760
on the right you can see the

510
00:19:39,760 --> 00:19:42,320
applications and apis and in between we

511
00:19:42,320 --> 00:19:44,080
have the wef the web application

512
00:19:44,080 --> 00:19:46,720
firewall this component looks at the

513
00:19:46,720 --> 00:19:47,919
traffic and it knows how to

514
00:19:47,919 --> 00:19:49,360
differentiate between malicious and

515
00:19:49,360 --> 00:19:51,520
benign traffic and it knows also how to

516
00:19:51,520 --> 00:19:53,919
block the malicious traffic so how does

517
00:19:53,919 --> 00:19:56,400
it do that well that's two approaches we

518
00:19:56,400 --> 00:19:58,559
can either use a negative security model

519
00:19:58,559 --> 00:20:00,640
or a positive security model obviously

520
00:20:00,640 --> 00:20:02,080
we can also combine both of them

521
00:20:02,080 --> 00:20:04,720
together so a negative security model is

522
00:20:04,720 --> 00:20:07,039
a rule based or signature based model

523
00:20:07,039 --> 00:20:09,679
the idea here is to say

524
00:20:09,679 --> 00:20:11,760
we're going to create a rule or a

525
00:20:11,760 --> 00:20:13,760
signature for each attack and then if

526
00:20:13,760 --> 00:20:16,640
the weft detects an attack using these

527
00:20:16,640 --> 00:20:18,799
rules or signatures it knows how to

528
00:20:18,799 --> 00:20:20,720
block them so basically you can say

529
00:20:20,720 --> 00:20:22,559
everything is good except for what is

530
00:20:22,559 --> 00:20:24,559
bad the good thing about it is that it's

531
00:20:24,559 --> 00:20:26,480
accurate and it's precise because we

532
00:20:26,480 --> 00:20:28,000
know which attack we're trying to block

533
00:20:28,000 --> 00:20:29,520
and we're writing a rule specifically

534
00:20:29,520 --> 00:20:31,440
for it however if you don't know what

535
00:20:31,440 --> 00:20:33,280
the attack looks like like in the case

536
00:20:33,280 --> 00:20:35,520
of zero days we cannot write a rule and

537
00:20:35,520 --> 00:20:37,039
also we have to continuously write new

538
00:20:37,039 --> 00:20:38,799
rules for new attacks

539
00:20:38,799 --> 00:20:40,960
positive security model is kind of an

540
00:20:40,960 --> 00:20:42,880
anomaly detection model the idea here is

541
00:20:42,880 --> 00:20:46,080
that we create a baseline profile

542
00:20:46,080 --> 00:20:49,120
for our website or for our api

543
00:20:49,120 --> 00:20:50,640
and then we say okay this is what we

544
00:20:50,640 --> 00:20:52,400
expect the traffic to look like and

545
00:20:52,400 --> 00:20:54,960
everything that is different from that

546
00:20:54,960 --> 00:20:56,880
is an attack okay so the good thing

547
00:20:56,880 --> 00:20:59,600
about it is that we can detect zero days

548
00:20:59,600 --> 00:21:00,799
because

549
00:21:00,799 --> 00:21:02,320
zero days are going to look different

550
00:21:02,320 --> 00:21:04,880
from the normal traffic the problem is

551
00:21:04,880 --> 00:21:06,240
that we are always in the risk of

552
00:21:06,240 --> 00:21:08,880
introducing false positives

553
00:21:08,880 --> 00:21:09,679
okay

554
00:21:09,679 --> 00:21:11,760
so basically everything is bad except

555
00:21:11,760 --> 00:21:14,400
for what is good except for what matches

556
00:21:14,400 --> 00:21:17,280
the traffic now there's an additional

557
00:21:17,280 --> 00:21:19,520
problem and that is that we need to

558
00:21:19,520 --> 00:21:23,120
learn this baseline profile using the

559
00:21:23,120 --> 00:21:25,200
traffic that we see coming to the

560
00:21:25,200 --> 00:21:26,400
website

561
00:21:26,400 --> 00:21:29,760
to the api the problem here is that the

562
00:21:29,760 --> 00:21:32,320
people generating this traffic can be

563
00:21:32,320 --> 00:21:34,240
normal users but also attackers and

564
00:21:34,240 --> 00:21:36,559
hackers this might lead to a case where

565
00:21:36,559 --> 00:21:39,360
we experience data poisoning

566
00:21:39,360 --> 00:21:40,799
and we end up creating a baseline

567
00:21:40,799 --> 00:21:43,679
profile based on attacks which

568
00:21:43,679 --> 00:21:45,520
completely collapses the whole idea of a

569
00:21:45,520 --> 00:21:48,000
positive security model

570
00:21:48,000 --> 00:21:48,880
now

571
00:21:48,880 --> 00:21:51,200
how do we actually create a traffic

572
00:21:51,200 --> 00:21:52,960
profile well

573
00:21:52,960 --> 00:21:55,280
let's start with the object an object is

574
00:21:55,280 --> 00:21:57,520
a carrier of traffic

575
00:21:57,520 --> 00:21:58,559
for example

576
00:21:58,559 --> 00:22:00,559
questing parameters body parameters

577
00:22:00,559 --> 00:22:01,760
cookies

578
00:22:01,760 --> 00:22:04,400
and so on okay that's what actually

579
00:22:04,400 --> 00:22:07,120
carries the traffic itself

580
00:22:07,120 --> 00:22:09,200
a container is something that is

581
00:22:09,200 --> 00:22:12,640
associated with an object so for example

582
00:22:12,640 --> 00:22:14,960
a question parameter is associated with

583
00:22:14,960 --> 00:22:17,200
specific url right

584
00:22:17,200 --> 00:22:19,760
a body parameter is associated with a

585
00:22:19,760 --> 00:22:22,720
specific method and a specific url a

586
00:22:22,720 --> 00:22:27,520
cookie is associated with a website and

587
00:22:27,520 --> 00:22:32,159
so on and so on so a container can be a

588
00:22:32,159 --> 00:22:35,840
url host method or a combination of all

589
00:22:35,840 --> 00:22:37,440
of the above

590
00:22:37,440 --> 00:22:39,840
now in this specific model we're talking

591
00:22:39,840 --> 00:22:42,080
about a case where each object checked

592
00:22:42,080 --> 00:22:45,200
has a single container and a single

593
00:22:45,200 --> 00:22:47,760
traffic profile so what is the traffic

594
00:22:47,760 --> 00:22:49,440
profile that's

595
00:22:49,440 --> 00:22:51,520
a one actually

596
00:22:51,520 --> 00:22:53,039
in

597
00:22:53,039 --> 00:22:55,039
it actually represents the parameter

598
00:22:55,039 --> 00:22:57,840
itself so we have things like type

599
00:22:57,840 --> 00:22:59,840
can describe meter repeat itself is it

600
00:22:59,840 --> 00:23:02,880
optional mandatory its size charset

601
00:23:02,880 --> 00:23:03,679
and

602
00:23:03,679 --> 00:23:06,240
so on

603
00:23:07,360 --> 00:23:10,240
finally how do we deal with the threat

604
00:23:10,240 --> 00:23:11,600
of

605
00:23:11,600 --> 00:23:13,440
data poisoning

606
00:23:13,440 --> 00:23:15,600
where we're not trying to create a web

607
00:23:15,600 --> 00:23:19,440
profile or an api profile well first

608
00:23:19,440 --> 00:23:21,760
let's start with cleaning the data so

609
00:23:21,760 --> 00:23:24,880
anything coming from suspicious ips any

610
00:23:24,880 --> 00:23:26,559
suspicious events anything that you

611
00:23:26,559 --> 00:23:28,000
don't trust for any reason which is

612
00:23:28,000 --> 00:23:29,840
gonna throw out completely

613
00:23:29,840 --> 00:23:31,679
once you're done with that we're gonna

614
00:23:31,679 --> 00:23:33,200
do something that's called threshold

615
00:23:33,200 --> 00:23:34,320
learning

616
00:23:34,320 --> 00:23:36,799
we say we trust something only if we see

617
00:23:36,799 --> 00:23:38,559
that it's coming from a lot of different

618
00:23:38,559 --> 00:23:41,120
places okay so we can be sure it's not

619
00:23:41,120 --> 00:23:43,120
this one single attacker that is trying

620
00:23:43,120 --> 00:23:43,840
to

621
00:23:43,840 --> 00:23:46,640
you know to create an impact

622
00:23:46,640 --> 00:23:48,640
so i say okay

623
00:23:48,640 --> 00:23:50,400
in order to learn something we must see

624
00:23:50,400 --> 00:23:52,720
requests from a lot of different ips a

625
00:23:52,720 --> 00:23:54,480
lot of different user agents geo

626
00:23:54,480 --> 00:23:55,600
locations

627
00:23:55,600 --> 00:23:57,919
and so on and so on

628
00:23:57,919 --> 00:24:00,640
okay so basically saying if we see that

629
00:24:00,640 --> 00:24:03,360
many ips and many user agents access a

630
00:24:03,360 --> 00:24:05,840
specific url then that increases the

631
00:24:05,840 --> 00:24:08,960
chance that that url is legit

632
00:24:08,960 --> 00:24:10,559
now once we're done with that we move

633
00:24:10,559 --> 00:24:12,640
into enforcement we can say anything

634
00:24:12,640 --> 00:24:14,159
that deviates from this profile that we

635
00:24:14,159 --> 00:24:15,520
created

636
00:24:15,520 --> 00:24:17,600
is an attack

637
00:24:17,600 --> 00:24:19,520
however this is easy to do in batch

638
00:24:19,520 --> 00:24:21,440
processing okay just have all the data

639
00:24:21,440 --> 00:24:23,440
and you go over it and you know you

640
00:24:23,440 --> 00:24:25,520
create you group it

641
00:24:25,520 --> 00:24:27,279
and you know how to extract all these

642
00:24:27,279 --> 00:24:29,919
different counters however it consumes a

643
00:24:29,919 --> 00:24:31,840
huge amount of memory and it's not

644
00:24:31,840 --> 00:24:33,919
always a viable solution for example

645
00:24:33,919 --> 00:24:35,679
here at imperfect we deal with 400

646
00:24:35,679 --> 00:24:38,400
billion requests every day so it's not

647
00:24:38,400 --> 00:24:41,039
that easy to do batch processing for so

648
00:24:41,039 --> 00:24:42,960
much data so i'm going to hand it over

649
00:24:42,960 --> 00:24:45,120
to izik to explain about his solution to

650
00:24:45,120 --> 00:24:47,039
this problem

651
00:24:47,039 --> 00:24:49,440
thank you johnny uh we go now into a

652
00:24:49,440 --> 00:24:50,640
completely different world and

653
00:24:50,640 --> 00:24:52,880
completely different example

654
00:24:52,880 --> 00:24:56,400
uh a dog food tastiness uh challenge uh

655
00:24:56,400 --> 00:24:59,279
here we want to uh we have two brands of

656
00:24:59,279 --> 00:25:02,080
dog food pedigree and thero he wants to

657
00:25:02,080 --> 00:25:04,559
uh to make a poll to know which one of

658
00:25:04,559 --> 00:25:07,679
them is uh is good and tasty

659
00:25:07,679 --> 00:25:11,520
uh and we are running a poll we have 20

660
00:25:11,520 --> 00:25:14,640
participants and we got 12 likes for uh

661
00:25:14,640 --> 00:25:18,159
theo and six likes only for a pedigree

662
00:25:18,159 --> 00:25:20,720
however we we don't want to we want to

663
00:25:20,720 --> 00:25:23,039
do a robust learning threshold learning

664
00:25:23,039 --> 00:25:23,760
so

665
00:25:23,760 --> 00:25:26,799
we define uh two thresholds three uh

666
00:25:26,799 --> 00:25:30,480
cities and three breeds and here only uh

667
00:25:30,480 --> 00:25:32,000
pedigree passes

668
00:25:32,000 --> 00:25:34,480
and the reason that only pedigree passes

669
00:25:34,480 --> 00:25:36,320
is that

670
00:25:36,320 --> 00:25:38,159
what you can see here uh in the in the

671
00:25:38,159 --> 00:25:39,760
red part of the table

672
00:25:39,760 --> 00:25:41,840
is that uh teo

673
00:25:41,840 --> 00:25:43,919
doesn't have any votes from sun bernard

674
00:25:43,919 --> 00:25:46,640
and any vote from san francisco

675
00:25:46,640 --> 00:25:49,279
uh however uh pedigree has actually

676
00:25:49,279 --> 00:25:51,039
votes from all the three cities and all

677
00:25:51,039 --> 00:25:55,279
the three uh breeds of uh of dogs now uh

678
00:25:55,279 --> 00:25:57,279
the reason for this bias

679
00:25:57,279 --> 00:25:59,679
is that uh in the blue part uh of the

680
00:25:59,679 --> 00:26:02,320
table you can see that uh we had pretty

681
00:26:02,320 --> 00:26:04,480
many pomeranians and we had pretty many

682
00:26:04,480 --> 00:26:07,200
new yorkers ten and nine

683
00:26:07,200 --> 00:26:08,960
and uh

684
00:26:08,960 --> 00:26:10,960
all the people that were from new york

685
00:26:10,960 --> 00:26:13,919
and had pomeranians actually liked theo

686
00:26:13,919 --> 00:26:16,400
uh and we have one two three four five

687
00:26:16,400 --> 00:26:17,200
six

688
00:26:17,200 --> 00:26:19,760
uh voters that created uh this bias

689
00:26:19,760 --> 00:26:21,679
which is exactly the the thing that we

690
00:26:21,679 --> 00:26:23,520
wanted to uh

691
00:26:23,520 --> 00:26:25,600
the phenomenon phenomenon phenomena that

692
00:26:25,600 --> 00:26:28,559
we wanted to limit its uh impact on our

693
00:26:28,559 --> 00:26:30,159
learning system

694
00:26:30,159 --> 00:26:32,480
uh so how will we run the threshold

695
00:26:32,480 --> 00:26:35,440
learning on on this data so we have a

696
00:26:35,440 --> 00:26:38,240
pedigree this is an object you want to

697
00:26:38,240 --> 00:26:39,360
learn about

698
00:26:39,360 --> 00:26:40,400
tasty

699
00:26:40,400 --> 00:26:42,400
tastiness is a fact you want to learn

700
00:26:42,400 --> 00:26:44,400
about the object

701
00:26:44,400 --> 00:26:46,400
city and breed are two attributes and

702
00:26:46,400 --> 00:26:48,880
three are is the number of um at the

703
00:26:48,880 --> 00:26:51,520
threshold that we are using for them and

704
00:26:51,520 --> 00:26:53,760
in the bottom we have the sets of all

705
00:26:53,760 --> 00:26:56,000
the cities from which we've seen

706
00:26:56,000 --> 00:26:58,320
indications for tastiness for a pedigree

707
00:26:58,320 --> 00:26:59,840
which at the beginning is of course

708
00:26:59,840 --> 00:27:01,279
empty so

709
00:27:01,279 --> 00:27:03,679
uh we don't have any data so

710
00:27:03,679 --> 00:27:04,799
we don't

711
00:27:04,799 --> 00:27:08,080
accept the tastiness of of pedigree

712
00:27:08,080 --> 00:27:09,919
same thing for teo

713
00:27:09,919 --> 00:27:12,880
same structure and no data and and

714
00:27:12,880 --> 00:27:15,039
nothing is is known

715
00:27:15,039 --> 00:27:17,039
by now and the same thing for a new

716
00:27:17,039 --> 00:27:19,120
another fact whether

717
00:27:19,120 --> 00:27:21,600
the dog food is nutritious

718
00:27:21,600 --> 00:27:23,279
now the data comes in

719
00:27:23,279 --> 00:27:26,320
and now uh we are seeing that um

720
00:27:26,320 --> 00:27:28,240
we have uh

721
00:27:28,240 --> 00:27:31,120
three cities and three uh breeds

722
00:27:31,120 --> 00:27:33,039
uh that are suggesting that they like

723
00:27:33,039 --> 00:27:34,480
the tastiness of

724
00:27:34,480 --> 00:27:36,799
pedigree and then

725
00:27:36,799 --> 00:27:38,799
a pedigree passes the two

726
00:27:38,799 --> 00:27:41,120
tests for a tastiness and you know we

727
00:27:41,120 --> 00:27:43,919
decided now that pedigree is tasty

728
00:27:43,919 --> 00:27:46,080
however for teo it doesn't work because

729
00:27:46,080 --> 00:27:47,919
they have only two cities and only two

730
00:27:47,919 --> 00:27:49,520
breeds so they didn't pass any of the

731
00:27:49,520 --> 00:27:52,159
tests and they are not approved as

732
00:27:52,159 --> 00:27:53,440
tasty

733
00:27:53,440 --> 00:27:55,600
so this is the data structure that

734
00:27:55,600 --> 00:27:58,720
we use and now um if we are looking at

735
00:27:58,720 --> 00:28:00,000
that from a memory consumption

736
00:28:00,000 --> 00:28:02,159
perspective then the memory consumption

737
00:28:02,159 --> 00:28:04,320
is proportional to the number of objects

738
00:28:04,320 --> 00:28:06,720
that we have uh to the facts or the

739
00:28:06,720 --> 00:28:09,760
properties that we want to to measure

740
00:28:09,760 --> 00:28:12,000
to the number of attributes that we want

741
00:28:12,000 --> 00:28:14,960
to to apply threshold to them and to the

742
00:28:14,960 --> 00:28:16,799
thresholds themselves because they they

743
00:28:16,799 --> 00:28:19,279
and they have an in an impact on the the

744
00:28:19,279 --> 00:28:21,360
size of the sets however the important

745
00:28:21,360 --> 00:28:23,120
thing is that they are independent of

746
00:28:23,120 --> 00:28:25,360
the size of the data which is what we

747
00:28:25,360 --> 00:28:27,919
wanted to achieve in the first place uh

748
00:28:27,919 --> 00:28:29,520
and what we can learn here using this

749
00:28:29,520 --> 00:28:32,159
approach is actually uh boolean facts

750
00:28:32,159 --> 00:28:34,480
that in object x in this case a dog food

751
00:28:34,480 --> 00:28:37,120
brand has a property y which that is

752
00:28:37,120 --> 00:28:40,559
tasty uh it can either have or and not

753
00:28:40,559 --> 00:28:42,480
have

754
00:28:42,480 --> 00:28:44,640
now using this uh framework of boolean

755
00:28:44,640 --> 00:28:47,120
facts uh it goes

756
00:28:47,120 --> 00:28:48,880
it's pretty straightforward

757
00:28:48,880 --> 00:28:52,559
very natural for our profiling system uh

758
00:28:52,559 --> 00:28:54,559
what you do during the training you take

759
00:28:54,559 --> 00:28:56,880
every data point you extract uh for a

760
00:28:56,880 --> 00:28:58,720
fact uh

761
00:28:58,720 --> 00:29:01,039
whether this fact was seen

762
00:29:01,039 --> 00:29:03,440
and then you take all these fact x scene

763
00:29:03,440 --> 00:29:06,240
flags and uh together you decide if you

764
00:29:06,240 --> 00:29:08,720
pass all the thresholds that fact x is

765
00:29:08,720 --> 00:29:10,480
allowed in the profile

766
00:29:10,480 --> 00:29:13,120
and if fact x is not allowed then you

767
00:29:13,120 --> 00:29:16,480
add to the profile effect x prohibited

768
00:29:16,480 --> 00:29:18,240
during the inference and now you have a

769
00:29:18,240 --> 00:29:21,120
profile set um what you can do is for

770
00:29:21,120 --> 00:29:22,159
any

771
00:29:22,159 --> 00:29:25,840
new http uh request uh you can

772
00:29:25,840 --> 00:29:28,480
extract again the flag whether fact x is

773
00:29:28,480 --> 00:29:30,799
seen and if you have a fact that is seen

774
00:29:30,799 --> 00:29:33,520
but is prohibited then there you go you

775
00:29:33,520 --> 00:29:35,600
have a violation you have an anomaly and

776
00:29:35,600 --> 00:29:37,679
then you can do whatever you do with uh

777
00:29:37,679 --> 00:29:40,399
with violations

778
00:29:40,399 --> 00:29:43,919
uh the question is is this enough uh can

779
00:29:43,919 --> 00:29:45,360
you really

780
00:29:45,360 --> 00:29:47,440
what can you really express with with

781
00:29:47,440 --> 00:29:49,039
the boolean flags

782
00:29:49,039 --> 00:29:53,559
and for that johnny will elaborate

783
00:29:55,120 --> 00:29:57,279
thanks etic i'm going to explain how we

784
00:29:57,279 --> 00:29:59,279
can express profile features with

785
00:29:59,279 --> 00:30:00,640
boolean facts

786
00:30:00,640 --> 00:30:03,279
okay so the first and easiest things to

787
00:30:03,279 --> 00:30:06,000
express are objects and containers so

788
00:30:06,000 --> 00:30:08,799
talk about things like digital locations

789
00:30:08,799 --> 00:30:12,000
urls endpoints hosts methods and

790
00:30:12,000 --> 00:30:14,880
so on so how can you do that well quite

791
00:30:14,880 --> 00:30:16,080
simply

792
00:30:16,080 --> 00:30:18,960
just simply say if

793
00:30:18,960 --> 00:30:21,520
urls and if methods

794
00:30:21,520 --> 00:30:25,600
actually exists okay so you can say

795
00:30:25,600 --> 00:30:28,640
is a certain url accessible

796
00:30:28,640 --> 00:30:30,559
does a certain

797
00:30:30,559 --> 00:30:34,320
url expect to see a cookie

798
00:30:34,320 --> 00:30:37,039
is a certain method allowed

799
00:30:37,039 --> 00:30:40,559
in the context of a specific url

800
00:30:40,559 --> 00:30:44,000
given a url and a method do we expect to

801
00:30:44,000 --> 00:30:46,399
see a specific parameter

802
00:30:46,399 --> 00:30:48,960
okay and so on and so on so i basically

803
00:30:48,960 --> 00:30:50,960
just profiling the site itself we're

804
00:30:50,960 --> 00:30:51,919
saying

805
00:30:51,919 --> 00:30:53,600
which urls

806
00:30:53,600 --> 00:30:55,039
are

807
00:30:55,039 --> 00:30:57,519
available within the website which

808
00:30:57,519 --> 00:30:59,600
headers are available which methods are

809
00:30:59,600 --> 00:31:01,679
available for each url and which

810
00:31:01,679 --> 00:31:04,080
parameters do we expect to see for each

811
00:31:04,080 --> 00:31:05,919
url and method

812
00:31:05,919 --> 00:31:07,519
and so on

813
00:31:07,519 --> 00:31:09,519
okay

814
00:31:09,519 --> 00:31:12,159
now that's quite easy but what about the

815
00:31:12,159 --> 00:31:13,600
data types

816
00:31:13,600 --> 00:31:16,000
the ranges char sets regular expressions

817
00:31:16,000 --> 00:31:19,200
and so on you know the interesting stuff

818
00:31:19,200 --> 00:31:20,480
okay

819
00:31:20,480 --> 00:31:23,039
let's talk about type

820
00:31:23,039 --> 00:31:24,799
by using boolean

821
00:31:24,799 --> 00:31:28,000
facts we can quite easily decide the

822
00:31:28,000 --> 00:31:31,679
parameters type we can say

823
00:31:31,679 --> 00:31:32,480
if

824
00:31:32,480 --> 00:31:35,039
this parameter is a number okay if this

825
00:31:35,039 --> 00:31:37,360
parameter is a string if it's none if

826
00:31:37,360 --> 00:31:40,080
it's boolean and so on

827
00:31:40,080 --> 00:31:41,919
now

828
00:31:41,919 --> 00:31:43,919
because we know

829
00:31:43,919 --> 00:31:46,559
that let's say a specific parameter

830
00:31:46,559 --> 00:31:48,159
is a number

831
00:31:48,159 --> 00:31:49,120
and

832
00:31:49,120 --> 00:31:50,480
we didn't see

833
00:31:50,480 --> 00:31:52,880
examples of anything else or we barely

834
00:31:52,880 --> 00:31:55,200
sign examples of anything else we can

835
00:31:55,200 --> 00:31:57,279
reach a conclusion that not only is it a

836
00:31:57,279 --> 00:31:58,159
number

837
00:31:58,159 --> 00:32:01,440
it's also a

838
00:32:01,440 --> 00:32:02,799
not

839
00:32:02,799 --> 00:32:04,159
a non-number

840
00:32:04,159 --> 00:32:06,320
in other words we can say that none

841
00:32:06,320 --> 00:32:10,000
numbers are prohibited okay so

842
00:32:10,000 --> 00:32:11,760
that was a bit confusing so let me

843
00:32:11,760 --> 00:32:13,440
explain

844
00:32:13,440 --> 00:32:14,880
let's say if we're trying to figure out

845
00:32:14,880 --> 00:32:17,360
that a certain parameter is of type

846
00:32:17,360 --> 00:32:19,760
string well by looking at traffic we end

847
00:32:19,760 --> 00:32:21,919
up reaching conclusion that

848
00:32:21,919 --> 00:32:23,919
string type is allowed

849
00:32:23,919 --> 00:32:26,960
however as time goes by and because we

850
00:32:26,960 --> 00:32:28,480
didn't see anything that isn't a string

851
00:32:28,480 --> 00:32:30,480
or we barely sign anything that isn't a

852
00:32:30,480 --> 00:32:32,720
string remember we're dealing with

853
00:32:32,720 --> 00:32:34,960
threshold learning we can reach the

854
00:32:34,960 --> 00:32:36,880
conclusion that

855
00:32:36,880 --> 00:32:39,200
num types for example are prohibited and

856
00:32:39,200 --> 00:32:41,919
that non-string types are prohibited

857
00:32:41,919 --> 00:32:42,799
okay

858
00:32:42,799 --> 00:32:45,120
now that's the actual enforcement that's

859
00:32:45,120 --> 00:32:47,120
the actual mitigation itself now if

860
00:32:47,120 --> 00:32:48,640
let's say we see

861
00:32:48,640 --> 00:32:50,240
a parameter

862
00:32:50,240 --> 00:32:52,799
that contains in

863
00:32:52,799 --> 00:32:53,600
the

864
00:32:53,600 --> 00:32:55,519
number 23

865
00:32:55,519 --> 00:32:57,360
we are not going to let it through we

866
00:32:57,360 --> 00:32:58,720
are going to block it

867
00:32:58,720 --> 00:33:01,440
because as we said num types are

868
00:33:01,440 --> 00:33:03,039
prohibited

869
00:33:03,039 --> 00:33:05,120
any other string is going to go through

870
00:33:05,120 --> 00:33:06,080
because

871
00:33:06,080 --> 00:33:08,240
we did not prohibit

872
00:33:08,240 --> 00:33:09,360
strings

873
00:33:09,360 --> 00:33:12,159
okay another example is let's say if we

874
00:33:12,159 --> 00:33:14,559
figure out that a certain parameter

875
00:33:14,559 --> 00:33:16,240
never has

876
00:33:16,240 --> 00:33:19,279
a value okay so what we end up learning

877
00:33:19,279 --> 00:33:21,840
or the important part for us to learn

878
00:33:21,840 --> 00:33:22,880
is that

879
00:33:22,880 --> 00:33:25,039
none nones

880
00:33:25,039 --> 00:33:27,840
are prohibited in other words we learn

881
00:33:27,840 --> 00:33:30,720
that it's prohibited for this parameter

882
00:33:30,720 --> 00:33:33,200
to carry any sort of value and so if it

883
00:33:33,200 --> 00:33:35,679
does we can block it

884
00:33:35,679 --> 00:33:38,159
now let's move on to regular expressions

885
00:33:38,159 --> 00:33:40,240
the idea here is quite simple

886
00:33:40,240 --> 00:33:42,799
you create a bunch of regular expression

887
00:33:42,799 --> 00:33:45,200
facts such as male regular expressions

888
00:33:45,200 --> 00:33:47,519
an ip address regular expression and so

889
00:33:47,519 --> 00:33:48,480
on

890
00:33:48,480 --> 00:33:50,240
and then by looking the traffic you can

891
00:33:50,240 --> 00:33:52,399
learn if a male regular expression is

892
00:33:52,399 --> 00:33:55,440
allowed or prohibited if an ip address

893
00:33:55,440 --> 00:33:58,080
is allowed or prohibited

894
00:33:58,080 --> 00:34:00,880
and so on so for example

895
00:34:00,880 --> 00:34:03,120
if a certain parameter is of type mail

896
00:34:03,120 --> 00:34:05,360
address we learned that string type are

897
00:34:05,360 --> 00:34:07,679
allowed and male regular expression is

898
00:34:07,679 --> 00:34:09,679
allowed but the important thing

899
00:34:09,679 --> 00:34:11,760
is that we'll end up understanding that

900
00:34:11,760 --> 00:34:14,320
non-male regular expressions are

901
00:34:14,320 --> 00:34:17,520
prohibited because we we didn't see any

902
00:34:17,520 --> 00:34:19,679
traffic containing any traffic that

903
00:34:19,679 --> 00:34:21,520
matches the male regular expression or

904
00:34:21,520 --> 00:34:23,119
we didn't see enough

905
00:34:23,119 --> 00:34:24,639
in order to decide that we are learning

906
00:34:24,639 --> 00:34:25,520
it

907
00:34:25,520 --> 00:34:26,560
okay

908
00:34:26,560 --> 00:34:28,639
and that will lead us to a conclusion

909
00:34:28,639 --> 00:34:29,520
that

910
00:34:29,520 --> 00:34:31,599
if we receive

911
00:34:31,599 --> 00:34:34,320
a value that doesn't match the male

912
00:34:34,320 --> 00:34:35,760
regular expression we're going to block

913
00:34:35,760 --> 00:34:38,079
it so things like abc or just a number

914
00:34:38,079 --> 00:34:40,159
are going to be blocked

915
00:34:40,159 --> 00:34:41,119
okay

916
00:34:41,119 --> 00:34:43,679
what about multiple occurrences

917
00:34:43,679 --> 00:34:45,679
optional parameters mandatory parameters

918
00:34:45,679 --> 00:34:48,480
well the idea is again the same

919
00:34:48,480 --> 00:34:50,960
you can create a boolean facts for these

920
00:34:50,960 --> 00:34:52,239
things

921
00:34:52,239 --> 00:34:54,639
so if it's mandatory param we'll end up

922
00:34:54,639 --> 00:34:56,960
learning that

923
00:34:56,960 --> 00:34:57,839
the

924
00:34:57,839 --> 00:35:00,480
parameter cannot be missing and so if it

925
00:35:00,480 --> 00:35:02,640
won't exist within a request we're gonna

926
00:35:02,640 --> 00:35:04,720
just block it

927
00:35:04,720 --> 00:35:06,320
okay finally

928
00:35:06,320 --> 00:35:08,800
let's talk about char sets well the idea

929
00:35:08,800 --> 00:35:09,920
here

930
00:35:09,920 --> 00:35:12,240
is that we can say

931
00:35:12,240 --> 00:35:13,760
that

932
00:35:13,760 --> 00:35:15,760
let's say a certain type

933
00:35:15,760 --> 00:35:18,320
of character is allowed or prohibited

934
00:35:18,320 --> 00:35:20,160
for example you can say

935
00:35:20,160 --> 00:35:23,760
none letters are allowed okay non-digits

936
00:35:23,760 --> 00:35:26,000
are allowed and so on we can even talk

937
00:35:26,000 --> 00:35:28,839
about complete char sets we can say

938
00:35:28,839 --> 00:35:32,400
non-base64 are allowed or in other words

939
00:35:32,400 --> 00:35:35,760
we don't expect any of the characters

940
00:35:35,760 --> 00:35:39,599
to not match the base 64 chorus it

941
00:35:39,599 --> 00:35:41,839
okay we can even focus on very specific

942
00:35:41,839 --> 00:35:44,560
ascii characters we can say ascii 21 is

943
00:35:44,560 --> 00:35:47,680
allowed or prohibited ascii 23

944
00:35:47,680 --> 00:35:51,440
and so on okay so let's show an example

945
00:35:51,440 --> 00:35:52,800
let's say if you reach in conclusion

946
00:35:52,800 --> 00:35:55,040
that base 64

947
00:35:55,040 --> 00:35:58,640
is the charset of a specific parameter

948
00:35:58,640 --> 00:36:01,599
we can end up learning that none base64

949
00:36:01,599 --> 00:36:03,839
is prohibited and so

950
00:36:03,839 --> 00:36:05,280
if a certain

951
00:36:05,280 --> 00:36:07,599
parameter value will contain a character

952
00:36:07,599 --> 00:36:10,320
that isn't part of the base64 charset

953
00:36:10,320 --> 00:36:12,720
for example asterix we're going to block

954
00:36:12,720 --> 00:36:13,520
it

955
00:36:13,520 --> 00:36:15,520
we can also be a bit more specific we

956
00:36:15,520 --> 00:36:16,720
can

957
00:36:16,720 --> 00:36:18,880
learn that a parameter is always

958
00:36:18,880 --> 00:36:21,359
composed of the alphanumeric character

959
00:36:21,359 --> 00:36:25,359
set and also semicolon and column so

960
00:36:25,359 --> 00:36:27,440
we learn a few things which on that

961
00:36:27,440 --> 00:36:29,760
relevant what's important is that we'll

962
00:36:29,760 --> 00:36:32,079
understand that non-strings are

963
00:36:32,079 --> 00:36:34,720
prohibited and that all these other

964
00:36:34,720 --> 00:36:36,560
ascii characters that aren't part of the

965
00:36:36,560 --> 00:36:38,960
alphanumeric charset and on the

966
00:36:38,960 --> 00:36:41,760
semicolon or a colon they're all

967
00:36:41,760 --> 00:36:43,359
prohibited

968
00:36:43,359 --> 00:36:45,520
that will lead us to conclude that if

969
00:36:45,520 --> 00:36:46,640
let's say

970
00:36:46,640 --> 00:36:49,040
the parameter contains a double hyphen

971
00:36:49,040 --> 00:36:50,480
or something like that we're going to

972
00:36:50,480 --> 00:36:53,520
block it because hyphens are prohibited

973
00:36:53,520 --> 00:36:55,839
in this case

974
00:36:56,640 --> 00:36:57,680
so

975
00:36:57,680 --> 00:37:02,480
finally we reach this a very interesting

976
00:37:02,480 --> 00:37:04,480
boolean fact that we can learn talking

977
00:37:04,480 --> 00:37:05,680
about

978
00:37:05,680 --> 00:37:08,720
param sizes for numbers

979
00:37:08,720 --> 00:37:11,760
and length for string okay so obviously

980
00:37:11,760 --> 00:37:13,040
because we're talking about boolean

981
00:37:13,040 --> 00:37:15,119
facts it's very problematic to use

982
00:37:15,119 --> 00:37:16,320
continuous

983
00:37:16,320 --> 00:37:18,000
values because we're going to have to

984
00:37:18,000 --> 00:37:20,640
create you know an endless amount

985
00:37:20,640 --> 00:37:22,960
of a boolean facts however we can

986
00:37:22,960 --> 00:37:24,800
discriticize them

987
00:37:24,800 --> 00:37:27,839
and work you know with a a

988
00:37:27,839 --> 00:37:29,280
small

989
00:37:29,280 --> 00:37:31,680
in numbers okay

990
00:37:31,680 --> 00:37:33,599
work with very specific numbers so in

991
00:37:33,599 --> 00:37:35,839
this case we can say

992
00:37:35,839 --> 00:37:37,280
for strings

993
00:37:37,280 --> 00:37:39,280
instead of going all the way you know

994
00:37:39,280 --> 00:37:42,560
from a minus infinity to a positive

995
00:37:42,560 --> 00:37:44,640
infinity you can say okay let's talk

996
00:37:44,640 --> 00:37:45,760
about

997
00:37:45,760 --> 00:37:48,000
is some values that are good enough

998
00:37:48,000 --> 00:37:49,520
okay so when you're talking about

999
00:37:49,520 --> 00:37:51,359
strings let's say we're talking about

1000
00:37:51,359 --> 00:37:52,720
comment

1001
00:37:52,720 --> 00:37:54,800
we expect the comment to be you know at

1002
00:37:54,800 --> 00:37:58,560
least five or ten characters of length

1003
00:37:58,560 --> 00:38:00,320
and it can't be longer than i don't know

1004
00:38:00,320 --> 00:38:02,800
a few thousand characters

1005
00:38:02,800 --> 00:38:05,040
now usually the attacks

1006
00:38:05,040 --> 00:38:05,920
uh

1007
00:38:05,920 --> 00:38:08,160
in this these domains for example maybe

1008
00:38:08,160 --> 00:38:10,240
someone will send way more characters

1009
00:38:10,240 --> 00:38:12,320
than expected ukraine's to create some

1010
00:38:12,320 --> 00:38:14,960
kind of an overflow okay

1011
00:38:14,960 --> 00:38:16,720
if let's say we're talking about

1012
00:38:16,720 --> 00:38:18,880
ids so maybe the ids have a certain

1013
00:38:18,880 --> 00:38:20,720
range they start from i don't know a few

1014
00:38:20,720 --> 00:38:22,320
thousands and

1015
00:38:22,320 --> 00:38:25,119
go up a few hundred more than that and

1016
00:38:25,119 --> 00:38:26,800
maybe someone will try to attack it by

1017
00:38:26,800 --> 00:38:29,359
maybe sending a negative id or a very

1018
00:38:29,359 --> 00:38:31,680
small number a very large number

1019
00:38:31,680 --> 00:38:34,000
so as long as we can create some kind of

1020
00:38:34,000 --> 00:38:35,040
a range

1021
00:38:35,040 --> 00:38:36,720
it's good enough and it doesn't really

1022
00:38:36,720 --> 00:38:39,440
matter if you know if we are

1023
00:38:39,440 --> 00:38:42,160
off by one one or two digits

1024
00:38:42,160 --> 00:38:45,440
okay so how do we actually apply that

1025
00:38:45,440 --> 00:38:47,839
for example if a certain parameter

1026
00:38:47,839 --> 00:38:53,200
length is between 34 and 345 well we can

1027
00:38:53,200 --> 00:38:54,400
learn

1028
00:38:54,400 --> 00:38:55,440
that

1029
00:38:55,440 --> 00:38:57,920
the character the parameter can be

1030
00:38:57,920 --> 00:38:59,760
greater than 5 characters and greater

1031
00:38:59,760 --> 00:39:02,000
than 50 characters

1032
00:39:02,000 --> 00:39:04,880
and we can also learn that it cannot be

1033
00:39:04,880 --> 00:39:06,960
greater than 500 that if it's greater

1034
00:39:06,960 --> 00:39:09,680
than 500 than it is prohibited and if

1035
00:39:09,680 --> 00:39:13,680
it's less than 10 then it is prohibited

1036
00:39:13,680 --> 00:39:16,160
we're going to effectively create an

1037
00:39:16,160 --> 00:39:20,079
allowed range of between 10 to 500 which

1038
00:39:20,079 --> 00:39:21,680
is close enough

1039
00:39:21,680 --> 00:39:23,119
to a

1040
00:39:23,119 --> 00:39:26,400
these values of 34 to 345

1041
00:39:26,400 --> 00:39:28,720
this means that if someone is going to

1042
00:39:28,720 --> 00:39:30,960
send a string that is less than 10

1043
00:39:30,960 --> 00:39:32,960
characters or a string that is greater

1044
00:39:32,960 --> 00:39:34,720
than 500 characters

1045
00:39:34,720 --> 00:39:36,880
it's gonna get blocked

1046
00:39:36,880 --> 00:39:39,440
now finally what do we do when boolean

1047
00:39:39,440 --> 00:39:41,520
facts are just not enough so when can

1048
00:39:41,520 --> 00:39:43,839
that happen well for example maybe

1049
00:39:43,839 --> 00:39:46,079
parameter isn't it isn't behaving the

1050
00:39:46,079 --> 00:39:48,400
way we expect it to so for example maybe

1051
00:39:48,400 --> 00:39:50,960
a parameter matches both male regular

1052
00:39:50,960 --> 00:39:53,680
expression and ip address mail

1053
00:39:53,680 --> 00:39:56,560
ip address regular expression how can

1054
00:39:56,560 --> 00:39:59,599
that happen no idea but if it does

1055
00:39:59,599 --> 00:40:01,760
we're going to want to make sure

1056
00:40:01,760 --> 00:40:03,839
why we're going to want to figure it out

1057
00:40:03,839 --> 00:40:06,079
okay another example is that maybe the

1058
00:40:06,079 --> 00:40:08,000
parameter is very sensitive for some

1059
00:40:08,000 --> 00:40:10,160
reason okay and then we're gonna want to

1060
00:40:10,160 --> 00:40:13,040
make sure that it's 100 secure so how do

1061
00:40:13,040 --> 00:40:15,520
you do that using this system

1062
00:40:15,520 --> 00:40:17,839
well in this case we have a very simple

1063
00:40:17,839 --> 00:40:19,040
site it has

1064
00:40:19,040 --> 00:40:22,720
four urls info about login and contact

1065
00:40:22,720 --> 00:40:24,720
us okay we managed to create a traffic

1066
00:40:24,720 --> 00:40:27,280
profile for info and about and contact

1067
00:40:27,280 --> 00:40:29,599
us has one query string parameter which

1068
00:40:29,599 --> 00:40:31,599
you manage to create a traffic profile

1069
00:40:31,599 --> 00:40:32,960
for too

1070
00:40:32,960 --> 00:40:34,079
however

1071
00:40:34,079 --> 00:40:37,200
the login url has two methods get and

1072
00:40:37,200 --> 00:40:39,440
post get has a question parameter which

1073
00:40:39,440 --> 00:40:41,359
we manage to profile

1074
00:40:41,359 --> 00:40:42,960
but post

1075
00:40:42,960 --> 00:40:44,960
well in post there's a body parameter

1076
00:40:44,960 --> 00:40:46,800
that's very important that body

1077
00:40:46,800 --> 00:40:48,720
parameter is the username and the

1078
00:40:48,720 --> 00:40:50,319
password and we want to make sure that

1079
00:40:50,319 --> 00:40:53,119
everything is nice and tight okay so how

1080
00:40:53,119 --> 00:40:55,119
can you do that well

1081
00:40:55,119 --> 00:40:57,040
using this system you can already know

1082
00:40:57,040 --> 00:40:58,800
what the traffic distribution looks like

1083
00:40:58,800 --> 00:41:00,319
and we know that let's say we get 200

1084
00:41:00,319 --> 00:41:01,680
requests

1085
00:41:01,680 --> 00:41:04,720
and they are distributed as following 50

1086
00:41:04,720 --> 00:41:08,800
40 80 and 30. so login gets 80 requests

1087
00:41:08,800 --> 00:41:11,359
and they split evenly between the query

1088
00:41:11,359 --> 00:41:14,160
string parameter and the body parameter

1089
00:41:14,160 --> 00:41:16,640
so we can say okay we know that we

1090
00:41:16,640 --> 00:41:18,000
receive

1091
00:41:18,000 --> 00:41:20,720
40 login requests with username and

1092
00:41:20,720 --> 00:41:22,079
password

1093
00:41:22,079 --> 00:41:24,880
and 40 is a small enough number for us

1094
00:41:24,880 --> 00:41:27,280
to deal with you know cpu wise and

1095
00:41:27,280 --> 00:41:30,240
memory consumption wise so we can decide

1096
00:41:30,240 --> 00:41:31,280
to

1097
00:41:31,280 --> 00:41:33,200
log all the traffic

1098
00:41:33,200 --> 00:41:35,839
all these different login requests

1099
00:41:35,839 --> 00:41:38,240
and then just analyze them offline you

1100
00:41:38,240 --> 00:41:40,000
know do the batch processing and all

1101
00:41:40,000 --> 00:41:41,920
this say

1102
00:41:41,920 --> 00:41:44,079
you know all this traditional way of

1103
00:41:44,079 --> 00:41:45,760
extracting information

1104
00:41:45,760 --> 00:41:47,599
and then we can end up creating a

1105
00:41:47,599 --> 00:41:50,480
profile very specifically you know for

1106
00:41:50,480 --> 00:41:51,839
this method and for these body

1107
00:41:51,839 --> 00:41:54,160
parameters and we can use it as part of

1108
00:41:54,160 --> 00:41:57,200
our defense mechanism

1109
00:41:57,200 --> 00:41:58,640
thank you johnny

1110
00:41:58,640 --> 00:42:00,720
so summary and conclusions data

1111
00:42:00,720 --> 00:42:02,319
positioning is a significant threat on

1112
00:42:02,319 --> 00:42:03,920
learning mechanisms

1113
00:42:03,920 --> 00:42:05,839
uh threshold-based learning may provide

1114
00:42:05,839 --> 00:42:08,319
an adequate robust learning solution

1115
00:42:08,319 --> 00:42:10,240
the boolean facts framework that we

1116
00:42:10,240 --> 00:42:11,280
presented

1117
00:42:11,280 --> 00:42:13,119
provides a streaming friendly

1118
00:42:13,119 --> 00:42:15,520
implementation for threshold-based

1119
00:42:15,520 --> 00:42:16,400
learning

1120
00:42:16,400 --> 00:42:17,200
and

1121
00:42:17,200 --> 00:42:19,599
although this framework at the beginning

1122
00:42:19,599 --> 00:42:22,480
looks uh very limited and many features

1123
00:42:22,480 --> 00:42:25,040
can be expressed with uh brilliant facts

1124
00:42:25,040 --> 00:42:27,280
and now we have uh a couple of minutes

1125
00:42:27,280 --> 00:42:31,079
for uh questions

