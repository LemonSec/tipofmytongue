1
00:00:00,330 --> 00:00:07,820
[Music]

2
00:00:07,820 --> 00:00:10,410
very much and welcome to the spot-on

3
00:00:10,410 --> 00:00:11,070
panel

4
00:00:11,070 --> 00:00:13,170
I've been moderating the spot-on panel

5
00:00:13,170 --> 00:00:14,910
for a few years and I just realized it's

6
00:00:14,910 --> 00:00:17,039
my first spot-on panel without Eugene

7
00:00:17,039 --> 00:00:20,910
Kaspersky so he will be he will be

8
00:00:20,910 --> 00:00:23,130
deeply missed but we have stellar

9
00:00:23,130 --> 00:00:25,260
replacements here we have Bruce of

10
00:00:25,260 --> 00:00:27,539
course from the Belfer Center at Harvard

11
00:00:27,539 --> 00:00:31,590
University I attended the Kenny school

12
00:00:31,590 --> 00:00:34,050
myself and during my time as a student

13
00:00:34,050 --> 00:00:35,579
there was always instructed never to

14
00:00:35,579 --> 00:00:37,200
challenge the guy from Bell fair because

15
00:00:37,200 --> 00:00:39,059
they literally think about nuclear

16
00:00:39,059 --> 00:00:41,570
counter strikes every single day so

17
00:00:41,570 --> 00:00:45,059
looking forward they are scary people

18
00:00:45,059 --> 00:00:46,710
and of course we have Bruno from the

19
00:00:46,710 --> 00:00:48,420
Vulcan anomic forum who has been working

20
00:00:48,420 --> 00:00:51,360
on IT infrastructure and challenges in

21
00:00:51,360 --> 00:00:54,600
the 2d IT infrastructure for more than

22
00:00:54,600 --> 00:00:56,809
20 years and is also the graduate of an

23
00:00:56,809 --> 00:00:59,399
equally scary institutions that I called

24
00:00:59,399 --> 00:01:03,000
a gear economic so on Bruce we want to

25
00:01:03,000 --> 00:01:05,129
start with you I mean the people here

26
00:01:05,129 --> 00:01:07,200
the organizer of the conference told me

27
00:01:07,200 --> 00:01:09,210
not to be too gloomy and then I came

28
00:01:09,210 --> 00:01:11,460
across one of your latest publications

29
00:01:11,460 --> 00:01:13,530
and the title is click here to kill

30
00:01:13,530 --> 00:01:16,080
everybody security and survival in a

31
00:01:16,080 --> 00:01:18,119
hyper-connected world are we going to

32
00:01:18,119 --> 00:01:20,240
wipe our civilization with a few clicks

33
00:01:20,240 --> 00:01:23,880
hopes not I mean but the title does

34
00:01:23,880 --> 00:01:25,530
speak to something that we are all

35
00:01:25,530 --> 00:01:28,350
talking about here that in fact as we

36
00:01:28,350 --> 00:01:30,060
become more computerized as we become

37
00:01:30,060 --> 00:01:32,180
more interconnected that these

38
00:01:32,180 --> 00:01:35,820
catastrophic failures will happen and

39
00:01:35,820 --> 00:01:37,890
we're talking here about how to deal

40
00:01:37,890 --> 00:01:39,659
with that and I like hearing the

41
00:01:39,659 --> 00:01:41,909
discussions about supply chain because

42
00:01:41,909 --> 00:01:43,920
that is truly an insurmountable hard

43
00:01:43,920 --> 00:01:47,159
problem we even get into the how hard it

44
00:01:47,159 --> 00:01:49,350
was I like talking about incentives and

45
00:01:49,350 --> 00:01:53,399
regulations and ways we can improve

46
00:01:53,399 --> 00:01:57,000
hygiene about users because we are

47
00:01:57,000 --> 00:01:59,009
moving into a world where everything is

48
00:01:59,009 --> 00:02:01,380
interconnected everything is vulnerable

49
00:02:01,380 --> 00:02:04,170
in ways that we are not expecting the

50
00:02:04,170 --> 00:02:06,479
failures we we think are not what are

51
00:02:06,479 --> 00:02:07,649
not what's gonna happen but does that

52
00:02:07,649 --> 00:02:09,479
mean that the line between online and

53
00:02:09,479 --> 00:02:11,790
offline is becoming increasingly blurry

54
00:02:11,790 --> 00:02:12,569
I

55
00:02:12,569 --> 00:02:15,450
don't think there is a line anymore so

56
00:02:15,450 --> 00:02:18,299
we kind of cross one line when we move

57
00:02:18,299 --> 00:02:20,609
to these things remember when you used

58
00:02:20,609 --> 00:02:24,269
to like enter a chatroom and upload and

59
00:02:24,269 --> 00:02:26,489
download and go online it was something

60
00:02:26,489 --> 00:02:29,879
you did now it's something you are doing

61
00:02:29,879 --> 00:02:32,010
all the time and then this is gonna

62
00:02:32,010 --> 00:02:34,590
change because this is still something I

63
00:02:34,590 --> 00:02:36,269
go to it's got a screen it's got a

64
00:02:36,269 --> 00:02:39,989
keyboard but the computers of tomorrow

65
00:02:39,989 --> 00:02:41,430
to relieve today and tomorrow the IOT

66
00:02:41,430 --> 00:02:43,230
computers are something that's in our

67
00:02:43,230 --> 00:02:45,720
environment there are thermostats our

68
00:02:45,720 --> 00:02:49,290
appliances the the lights here and so

69
00:02:49,290 --> 00:02:51,959
and it's fully immersive so it's not a

70
00:02:51,959 --> 00:02:54,689
place we go to anymore it's a place

71
00:02:54,689 --> 00:02:56,760
where in so that that line is already

72
00:02:56,760 --> 00:02:59,669
blurred would you agree bro I mean you

73
00:02:59,669 --> 00:03:01,109
have been working on infrastructure for

74
00:03:01,109 --> 00:03:01,739
a long time

75
00:03:01,739 --> 00:03:04,859
yes if a connectivity bill dependents

76
00:03:04,859 --> 00:03:09,629
for societies on this device and data

77
00:03:09,629 --> 00:03:13,409
are dependents but today is if you

78
00:03:13,409 --> 00:03:15,150
remember the theme of Davos this year

79
00:03:15,150 --> 00:03:17,370
globalization for the 0 building new

80
00:03:17,370 --> 00:03:18,750
architecture I do believe that

81
00:03:18,750 --> 00:03:21,810
cybersecurity is a good topic where we

82
00:03:21,810 --> 00:03:25,290
need to refocus on a new path and we

83
00:03:25,290 --> 00:03:27,599
need to change a culture on security and

84
00:03:27,599 --> 00:03:32,040
and to embodies a culture from H but to

85
00:03:32,040 --> 00:03:33,419
change that culture do you have the

86
00:03:33,419 --> 00:03:35,459
impression that people even use the same

87
00:03:35,459 --> 00:03:37,739
language that table for example policy

88
00:03:37,739 --> 00:03:40,500
makers and techies like you can even

89
00:03:40,500 --> 00:03:42,209
talk to each other this is actually

90
00:03:42,209 --> 00:03:43,109
something I've been thinking about a lot

91
00:03:43,109 --> 00:03:45,750
this is this this idea that we actually

92
00:03:45,750 --> 00:03:47,250
need tech and policy to talk to each

93
00:03:47,250 --> 00:03:49,889
other and you'll see this that if you

94
00:03:49,889 --> 00:03:51,720
watch the u.s. face book hearings it's a

95
00:03:51,720 --> 00:03:53,729
great example of policy makers having no

96
00:03:53,729 --> 00:03:55,500
idea one didn't have them person up

97
00:03:55,500 --> 00:03:58,139
there understood yet they are expected

98
00:03:58,139 --> 00:04:01,290
to effectively regulate this platform we

99
00:04:01,290 --> 00:04:03,389
see this in the debate about backdoors

100
00:04:03,389 --> 00:04:05,280
the going dark debates where

101
00:04:05,280 --> 00:04:07,560
regularities where government people say

102
00:04:07,560 --> 00:04:09,269
we want this and techie say well that's

103
00:04:09,269 --> 00:04:11,340
just not possible and they say well try

104
00:04:11,340 --> 00:04:14,090
harder say well that's not how it works

105
00:04:14,090 --> 00:04:17,750
so we are seeing a lot of these debates

106
00:04:17,750 --> 00:04:20,130
in cybersecurity so actually in

107
00:04:20,130 --> 00:04:22,560
technology at large bridge tech and

108
00:04:22,560 --> 00:04:24,930
policy and we need

109
00:04:24,930 --> 00:04:26,400
them together I'll talk about that more

110
00:04:26,400 --> 00:04:28,290
later near the end but then is really

111
00:04:28,290 --> 00:04:30,330
important and I want is I like to come

112
00:04:30,330 --> 00:04:32,850
to forums like this like to see techies

113
00:04:32,850 --> 00:04:35,699
at forums like this because we have to

114
00:04:35,699 --> 00:04:37,500
be here well that's why we are here yeah

115
00:04:37,500 --> 00:04:38,850
but I wanted to bring in Bruno because

116
00:04:38,850 --> 00:04:41,130
you started a year ago with the World

117
00:04:41,130 --> 00:04:42,539
Economic Forum you built this new

118
00:04:42,539 --> 00:04:45,960
platform there I think we to around 20

119
00:04:45,960 --> 00:04:47,880
people now and isn't that what you have

120
00:04:47,880 --> 00:04:49,949
focused on to change the dialogue yes

121
00:04:49,949 --> 00:04:52,740
not only not only for policy making is

122
00:04:52,740 --> 00:04:55,289
we need meaningful information that can

123
00:04:55,289 --> 00:04:57,449
be understood from decision maker which

124
00:04:57,449 --> 00:05:01,740
is what leaders see suit of bots they do

125
00:05:01,740 --> 00:05:04,139
not understand fully what cyber risk are

126
00:05:04,139 --> 00:05:06,300
and what could be the impact on the

127
00:05:06,300 --> 00:05:08,940
organization's on this stage so we need

128
00:05:08,940 --> 00:05:10,919
to be able to change the narrative how

129
00:05:10,919 --> 00:05:12,900
those people talk especially as you said

130
00:05:12,900 --> 00:05:19,020
take ease and the organization and if

131
00:05:19,020 --> 00:05:21,810
you look at the Missis straight

132
00:05:21,810 --> 00:05:24,570
landscape reports of this year this is

133
00:05:24,570 --> 00:05:26,699
one of the points so it cyber threat

134
00:05:26,699 --> 00:05:28,740
intelligence cannot be understood by

135
00:05:28,740 --> 00:05:30,449
decision-makers so how can you make a

136
00:05:30,449 --> 00:05:33,120
decision if you don't understand mmm you

137
00:05:33,120 --> 00:05:34,620
mentioned the face book here and I think

138
00:05:34,620 --> 00:05:35,849
we all realize that we are not

139
00:05:35,849 --> 00:05:37,460
particularly competent on that issue but

140
00:05:37,460 --> 00:05:41,310
isn't there a bigger dial armor that the

141
00:05:41,310 --> 00:05:43,199
government doesn't want the internet

142
00:05:43,199 --> 00:05:44,909
really to be secure because it makes it

143
00:05:44,909 --> 00:05:47,510
much easier to supervisor or to snoop

144
00:05:47,510 --> 00:05:49,530
isn't that one of the problems or the

145
00:05:49,530 --> 00:05:50,940
national problems in the dialogue

146
00:05:50,940 --> 00:05:52,830
between techies and government I think

147
00:05:52,830 --> 00:05:54,659
this is a huge problem you saw some of

148
00:05:54,659 --> 00:05:58,380
it in that opening talk by the UK

149
00:05:58,380 --> 00:06:00,990
diplomat who talked all about how we

150
00:06:00,990 --> 00:06:03,720
need to design security in and how

151
00:06:03,720 --> 00:06:05,220
important it is to make sure things are

152
00:06:05,220 --> 00:06:08,159
designed securely at the same time the

153
00:06:08,159 --> 00:06:09,570
government that same government is

154
00:06:09,570 --> 00:06:11,099
trying to make sure that things are not

155
00:06:11,099 --> 00:06:12,780
designed securely that they can be

156
00:06:12,780 --> 00:06:16,099
eavesdropped on now these are both

157
00:06:16,099 --> 00:06:19,620
important equities but the debate is not

158
00:06:19,620 --> 00:06:23,970
happening at that policy level and so I

159
00:06:23,970 --> 00:06:25,919
mean I'll describe it is you've got one

160
00:06:25,919 --> 00:06:28,050
world one infrastructure may you can

161
00:06:28,050 --> 00:06:31,050
choose when you build the 5g network to

162
00:06:31,050 --> 00:06:33,330
make it secure so that nobody can

163
00:06:33,330 --> 00:06:35,460
eavesdrop or you can make it insecure so

164
00:06:35,460 --> 00:06:37,320
that everybody can use drop I get that

165
00:06:37,320 --> 00:06:39,000
you want to eavesdrop and then you

166
00:06:39,000 --> 00:06:40,590
don't want anyone else to but that's not

167
00:06:40,590 --> 00:06:43,280
an option so when we talk about

168
00:06:43,280 --> 00:06:46,470
designing security in we need to

169
00:06:46,470 --> 00:06:48,780
understand what that means that means

170
00:06:48,780 --> 00:06:51,240
yes we will lose intelligence

171
00:06:51,240 --> 00:06:54,000
capabilities now you have to decide

172
00:06:54,000 --> 00:06:58,020
that's worth it because right you know

173
00:06:58,020 --> 00:07:00,390
every one of my legislators carries one

174
00:07:00,390 --> 00:07:02,220
of these and it's kind of scary that

175
00:07:02,220 --> 00:07:03,540
lots of people are you dropping on it

176
00:07:03,540 --> 00:07:06,020
now I'm are we willing to give up

177
00:07:06,020 --> 00:07:09,000
eavesdropping on the bad guys so this is

178
00:07:09,000 --> 00:07:12,030
a policy debate informed by tech that is

179
00:07:12,030 --> 00:07:13,410
the correct debate to have I can't

180
00:07:13,410 --> 00:07:15,450
answer it and we need to have this

181
00:07:15,450 --> 00:07:16,800
conversation but do you have the

182
00:07:16,800 --> 00:07:18,090
impression because you have these

183
00:07:18,090 --> 00:07:20,760
discussions do people talk past each

184
00:07:20,760 --> 00:07:23,310
other do we increasingly talk with each

185
00:07:23,310 --> 00:07:25,430
other on that issue

186
00:07:25,430 --> 00:07:28,290
totally past each other maybe this very

187
00:07:28,290 --> 00:07:32,430
little tech informed policy dialogue in

188
00:07:32,430 --> 00:07:34,410
my space come change my vulnerabilities

189
00:07:34,410 --> 00:07:37,050
do you think it's better in Europe no

190
00:07:37,050 --> 00:07:39,090
it's just two completely what people

191
00:07:39,090 --> 00:07:41,490
started for me estates what they want

192
00:07:41,490 --> 00:07:44,250
they want prosperity economic prosperity

193
00:07:44,250 --> 00:07:46,940
and stability in for their country so

194
00:07:46,940 --> 00:07:49,140
building back doors is going against

195
00:07:49,140 --> 00:07:54,390
arts so I don't believe that country

196
00:07:54,390 --> 00:07:57,020
which is democratic and advanced would

197
00:07:57,020 --> 00:08:06,150
push Australia UK so you want to keep

198
00:08:06,150 --> 00:08:10,110
going the u.s. yes so more and more the

199
00:08:10,110 --> 00:08:13,350
cities and we put pressure on being sure

200
00:08:13,350 --> 00:08:16,110
that those infrastructure are secure

201
00:08:16,110 --> 00:08:19,350
no bad rules and we should advocate for

202
00:08:19,350 --> 00:08:23,490
this and in Europe we do that but when

203
00:08:23,490 --> 00:08:24,990
you discuss that with people in Europe

204
00:08:24,990 --> 00:08:25,950
you have the impression that they are

205
00:08:25,950 --> 00:08:28,080
more receptive than for example US

206
00:08:28,080 --> 00:08:31,500
policymakers yes and this affects

207
00:08:31,500 --> 00:08:33,240
everything so here's two stories in the

208
00:08:33,240 --> 00:08:35,969
news last four days so you can hack

209
00:08:35,969 --> 00:08:38,669
construction cranes right those giant

210
00:08:38,669 --> 00:08:40,620
things that move tons of heavy stuff

211
00:08:40,620 --> 00:08:43,140
around you can hack those and like fling

212
00:08:43,140 --> 00:08:46,440
those about two days ago I learned you

213
00:08:46,440 --> 00:08:50,089
can hack refrigerators in supermarkets

214
00:08:50,089 --> 00:08:53,270
turn off you know make them go hot

215
00:08:53,270 --> 00:08:57,200
so here's two random IOT things which

216
00:08:57,200 --> 00:09:00,800
are like stupidly insecure easily

217
00:09:00,800 --> 00:09:02,960
hackable they're gonna be around for

218
00:09:02,960 --> 00:09:06,260
decades and then this is the kind of

219
00:09:06,260 --> 00:09:08,210
vulnerability we're living in and those

220
00:09:08,210 --> 00:09:09,860
aren't exceptions those happen to be the

221
00:09:09,860 --> 00:09:11,710
two that researchers looked at last week

222
00:09:11,710 --> 00:09:13,490
it's not gonna not gonna be any

223
00:09:13,490 --> 00:09:18,260
different for anything else but you we

224
00:09:18,260 --> 00:09:19,520
mentioned the role of government but

225
00:09:19,520 --> 00:09:21,470
then we have these huge institutions

226
00:09:21,470 --> 00:09:24,020
private institutions like Facebook and

227
00:09:24,020 --> 00:09:25,730
we were supposed to have Alex Thomas

228
00:09:25,730 --> 00:09:27,140
here on the panel who fell sick

229
00:09:27,140 --> 00:09:30,050
unfortunately but who left Facebook

230
00:09:30,050 --> 00:09:32,030
because he was not convinced that they

231
00:09:32,030 --> 00:09:33,320
really wanted to clean up their act I

232
00:09:33,320 --> 00:09:41,420
mean Facebook you didn't leave because

233
00:09:41,420 --> 00:09:45,860
they were incompetent ok interstate most

234
00:09:45,860 --> 00:09:48,290
a little bit here ok well but you want

235
00:09:48,290 --> 00:09:50,090
to maybe elaborate on the role of these

236
00:09:50,090 --> 00:09:51,920
institutions together I think you call

237
00:09:51,920 --> 00:09:53,780
that the surveillance capital

238
00:09:53,780 --> 00:09:55,520
surveillance capitalism is a term by

239
00:09:55,520 --> 00:09:57,980
Shoshanna Zubov she teaches at Harvard

240
00:09:57,980 --> 00:10:00,710
Business School her book is fantastic I

241
00:10:00,710 --> 00:10:02,870
recommend that everybody go by and read

242
00:10:02,870 --> 00:10:05,300
it and use the term constantly and she's

243
00:10:05,300 --> 00:10:08,630
talking about really a new market driven

244
00:10:08,630 --> 00:10:12,860
force based on collecting and using our

245
00:10:12,860 --> 00:10:17,410
data and it's permeating every industry

246
00:10:17,410 --> 00:10:20,240
you know not just Facebook when Facebook

247
00:10:20,240 --> 00:10:21,590
and Google are the poster children for

248
00:10:21,590 --> 00:10:23,960
surveillance capitalism but you know

249
00:10:23,960 --> 00:10:26,570
when you buy your connected refrigerator

250
00:10:26,570 --> 00:10:29,240
it's collecting data on what you're

251
00:10:29,240 --> 00:10:31,250
doing with it and it's gonna use that to

252
00:10:31,250 --> 00:10:34,370
try to upsell you to try to and I'm

253
00:10:34,370 --> 00:10:36,500
gonna sell that day to third parties is

254
00:10:36,500 --> 00:10:37,970
that a term you would use at the World

255
00:10:37,970 --> 00:10:39,980
Economic Forum so variants capitalism I

256
00:10:39,980 --> 00:10:45,800
hope so yes no to build on security by

257
00:10:45,800 --> 00:10:48,260
design is never ending story that we

258
00:10:48,260 --> 00:10:50,200
want to push for better design

259
00:10:50,200 --> 00:10:53,630
especially better cybersecurity from the

260
00:10:53,630 --> 00:10:56,930
early design but this is still not there

261
00:10:56,930 --> 00:10:58,460
and we need to transform cybersecurity

262
00:10:58,460 --> 00:10:59,990
into a competitive advantage for

263
00:10:59,990 --> 00:11:03,080
organizations so if you look at the the

264
00:11:03,080 --> 00:11:05,070
new cybersecurity Act

265
00:11:05,070 --> 00:11:08,470
cybersecurity framework from last year

266
00:11:08,470 --> 00:11:11,110
yes yeah that is going to it's going to

267
00:11:11,110 --> 00:11:12,790
be developed so this is a very strong

268
00:11:12,790 --> 00:11:15,940
incentive for organizations to to add a

269
00:11:15,940 --> 00:11:18,490
and to to go through a certification

270
00:11:18,490 --> 00:11:19,900
that would demonstrate that their

271
00:11:19,900 --> 00:11:23,470
product is better to another one and

272
00:11:23,470 --> 00:11:25,180
this is hard I mean for facebook

273
00:11:25,180 --> 00:11:26,890
security kind of isn't a competitive

274
00:11:26,890 --> 00:11:29,320
advantage I mean being able to spy on

275
00:11:29,320 --> 00:11:30,640
their users as a competitive advantage

276
00:11:30,640 --> 00:11:31,990
that's how they make money

277
00:11:31,990 --> 00:11:34,240
Equifax right the big data broker hack

278
00:11:34,240 --> 00:11:35,920
the United States couldn't care less

279
00:11:35,920 --> 00:11:39,190
about the security of its users because

280
00:11:39,190 --> 00:11:41,860
I can't fire Equifax I mean they'd

281
00:11:41,860 --> 00:11:43,060
collect my data that my knowledge or

282
00:11:43,060 --> 00:11:43,480
consent

283
00:11:43,480 --> 00:11:45,550
all right Siemens sitting in this chair

284
00:11:45,550 --> 00:11:47,830
I mean it would make sense to say right

285
00:11:47,830 --> 00:11:49,870
Romania our new industrial controllers

286
00:11:49,870 --> 00:11:51,820
the Americans can't destroy your

287
00:11:51,820 --> 00:11:53,860
centrifuges now right that is a

288
00:11:53,860 --> 00:11:56,380
competitive advantage and if they say

289
00:11:56,380 --> 00:11:59,350
that that's gonna be worth something but

290
00:11:59,350 --> 00:12:02,080
but but by and large we've been trying

291
00:12:02,080 --> 00:12:03,310
to make security competitive ants for a

292
00:12:03,310 --> 00:12:05,380
bunch of decades and we've been failing

293
00:12:05,380 --> 00:12:08,260
I liked all the talk up here about

294
00:12:08,260 --> 00:12:11,020
regulation it's all about incentives and

295
00:12:11,020 --> 00:12:13,480
if there isn't gonna be a rate you the

296
00:12:13,480 --> 00:12:16,210
market this is what you got you can hack

297
00:12:16,210 --> 00:12:18,130
the construction cranes that's the

298
00:12:18,130 --> 00:12:20,740
market solution you don't like it we

299
00:12:20,740 --> 00:12:22,780
need to raise the cost of insecurity

300
00:12:22,780 --> 00:12:24,550
you're a bunch of ideas up there about

301
00:12:24,550 --> 00:12:27,840
liabilities and regulations standards

302
00:12:27,840 --> 00:12:30,490
those are all but if you work if you're

303
00:12:30,490 --> 00:12:32,230
a skeptical of regulation what can be

304
00:12:32,230 --> 00:12:33,610
done I mean do we have our only

305
00:12:33,610 --> 00:12:35,230
ourselves to blame eventually them

306
00:12:35,230 --> 00:12:36,970
because we as consumers except that they

307
00:12:36,970 --> 00:12:39,010
are so I mean I tend to think people

308
00:12:39,010 --> 00:12:41,920
scapel relations just like to pretend

309
00:12:41,920 --> 00:12:42,790
but they still go out to eat at

310
00:12:42,790 --> 00:12:45,310
restaurants right they still fly in

311
00:12:45,310 --> 00:12:47,490
airplanes they still drive in cars

312
00:12:47,490 --> 00:12:49,330
they're not actually worried this

313
00:12:49,330 --> 00:12:51,390
building will collapse on their heads

314
00:12:51,390 --> 00:12:53,050
regulations are gonna come house

315
00:12:53,050 --> 00:12:56,280
societal the crane times right yeah

316
00:12:56,280 --> 00:13:00,690
regulations are how society functions

317
00:13:00,690 --> 00:13:05,290
when we can't ourselves be experts right

318
00:13:05,290 --> 00:13:08,230
I boarded a Lufthansa plane yesterday

319
00:13:08,230 --> 00:13:11,380
and I did not check the engines I

320
00:13:11,380 --> 00:13:14,830
wouldn't even know how to write I relied

321
00:13:14,830 --> 00:13:18,180
on both German and US regulations

322
00:13:18,180 --> 00:13:19,680
ensure that I would have a nice safe

323
00:13:19,680 --> 00:13:21,450
comfortable flight and the pilot be

324
00:13:21,450 --> 00:13:23,460
trained and rested and all of those

325
00:13:23,460 --> 00:13:26,460
things so there really isn't any

326
00:13:26,460 --> 00:13:28,290
solution other than regulations and that

327
00:13:28,290 --> 00:13:30,960
doesn't mean you must do this you can't

328
00:13:30,960 --> 00:13:32,910
do that it's flexible standards it's

329
00:13:32,910 --> 00:13:34,800
much more complex it's liabilities and

330
00:13:34,800 --> 00:13:36,810
for airline security it's a competitive

331
00:13:36,810 --> 00:13:39,540
advantage actually it is not you you

332
00:13:39,540 --> 00:13:41,100
never seek Airlines competing on

333
00:13:41,100 --> 00:13:43,529
security rightfully right fly our

334
00:13:43,529 --> 00:13:45,570
airline we do full body searches on

335
00:13:45,570 --> 00:13:48,120
everybody right fly our airline

336
00:13:48,120 --> 00:13:49,620
everybody carries a gun so you don't

337
00:13:49,620 --> 00:13:52,700
worry right you never see those slogans

338
00:13:52,700 --> 00:13:55,529
security and air and Airlines want this

339
00:13:55,529 --> 00:13:57,899
they want it not to be their problem

340
00:13:57,899 --> 00:14:01,140
when something happens they do not want

341
00:14:01,140 --> 00:14:02,339
to be blamed

342
00:14:02,339 --> 00:14:04,560
they want the sided blame the country

343
00:14:04,560 --> 00:14:06,899
blamed but not the airline not the

344
00:14:06,899 --> 00:14:08,910
aircraft we had the Airbus person here

345
00:14:08,910 --> 00:14:13,020
mate they're not competing on security

346
00:14:13,020 --> 00:14:16,950
of a flight they are totally pushing

347
00:14:16,950 --> 00:14:20,940
that to the government sorry yes to go

348
00:14:20,940 --> 00:14:23,339
in that direction is we have to simplify

349
00:14:23,339 --> 00:14:28,040
cyber security for consumer on customers

350
00:14:28,040 --> 00:14:30,570
that's a fact is the same as as you said

351
00:14:30,570 --> 00:14:32,310
for taking a plane I will not check the

352
00:14:32,310 --> 00:14:36,839
engine so it's always a user ability

353
00:14:36,839 --> 00:14:38,610
versus server security why do we use

354
00:14:38,610 --> 00:14:42,000
still password today 2019 why do we

355
00:14:42,000 --> 00:14:44,760
still design system whose password we

356
00:14:44,760 --> 00:14:47,520
keep saying password is not safe and

357
00:14:47,520 --> 00:14:52,080
we're still building systems and this is

358
00:14:52,080 --> 00:14:54,360
hard we talked about on stage about

359
00:14:54,360 --> 00:14:56,700
educating the user users are hard to

360
00:14:56,700 --> 00:14:59,540
educate and and it's a couple of things

361
00:14:59,540 --> 00:15:03,000
if you look at real education first for

362
00:15:03,000 --> 00:15:05,310
people it's simple things that are

363
00:15:05,310 --> 00:15:08,970
actionable wash your hands all right I

364
00:15:08,970 --> 00:15:10,770
can do it it works

365
00:15:10,770 --> 00:15:13,500
it can't be complex it can't be subtle

366
00:15:13,500 --> 00:15:16,170
and a lot of times certainly in the tech

367
00:15:16,170 --> 00:15:19,110
industry we blame the user so think of

368
00:15:19,110 --> 00:15:21,750
the kind of advice we give users don't

369
00:15:21,750 --> 00:15:25,140
plug in a strange USB stick kind of dumb

370
00:15:25,140 --> 00:15:26,850
advice of that it's a USB stick what am

371
00:15:26,850 --> 00:15:29,310
I gonna do with it don't click on a link

372
00:15:29,310 --> 00:15:31,190
there links

373
00:15:31,190 --> 00:15:34,879
don't open an attachment but it's an

374
00:15:34,879 --> 00:15:37,790
attachment I mean these are all failures

375
00:15:37,790 --> 00:15:40,399
of the tech system why in the world

376
00:15:40,399 --> 00:15:42,199
should plugging a USB stick be a

377
00:15:42,199 --> 00:15:44,269
vulnerability because USB was designed

378
00:15:44,269 --> 00:15:46,370
and securely why should it be that

379
00:15:46,370 --> 00:15:48,290
clicking on a link are opening an

380
00:15:48,290 --> 00:15:50,540
attachment isn't in security because the

381
00:15:50,540 --> 00:15:53,420
operating system is designed badly don't

382
00:15:53,420 --> 00:15:57,259
blame the user for bad tech decisions in

383
00:15:57,259 --> 00:15:58,930
your writings you are pretty down on

384
00:15:58,930 --> 00:16:02,290
technologies such as cryptocurrency

385
00:16:02,290 --> 00:16:04,819
blockchain as well pretty much because

386
00:16:04,819 --> 00:16:07,699
you think that you can have trust in

387
00:16:07,699 --> 00:16:10,939
tech and institutions only in people or

388
00:16:10,939 --> 00:16:14,060
supply chains complicated but I just

389
00:16:14,060 --> 00:16:16,129
wrote an essay appearing wired last week

390
00:16:16,129 --> 00:16:17,540
where I kind of said that is like

391
00:16:17,540 --> 00:16:19,610
absolutely nothing here there's no value

392
00:16:19,610 --> 00:16:21,500
here so all the people who have been

393
00:16:21,500 --> 00:16:23,389
sold a bill of goods you can relax for

394
00:16:23,389 --> 00:16:25,250
the neurons Bateman yes it is a bill of

395
00:16:25,250 --> 00:16:27,350
goods and it'll go away soon don't worry

396
00:16:27,350 --> 00:16:29,889
about it and it's a complicated

397
00:16:29,889 --> 00:16:32,379
discussion of how you really can't

398
00:16:32,379 --> 00:16:35,600
replace trust with verification and you

399
00:16:35,600 --> 00:16:38,839
can't replace institutions with code and

400
00:16:38,839 --> 00:16:41,029
any system where if you make a mistake

401
00:16:41,029 --> 00:16:42,819
you lose your life savings is

402
00:16:42,819 --> 00:16:45,500
fundamentally not trustworthy it doesn't

403
00:16:45,500 --> 00:16:52,459
matter how good the encryption is I have

404
00:16:52,459 --> 00:16:58,880
to be there's no choice I'm dead surely

405
00:16:58,880 --> 00:17:02,380
that in the industry we try to develop

406
00:17:02,380 --> 00:17:05,990
solutions which are secure for the

407
00:17:05,990 --> 00:17:08,449
people etc but at some point that's true

408
00:17:08,449 --> 00:17:13,189
that it can be broken it can be obsolete

409
00:17:13,189 --> 00:17:17,809
etc but what is important is to design

410
00:17:17,809 --> 00:17:21,770
it from the from the beginning right

411
00:17:21,770 --> 00:17:23,859
from the design phase

412
00:17:23,859 --> 00:17:27,829
obviously innovation has to go fast and

413
00:17:27,829 --> 00:17:30,679
many steps taking into account

414
00:17:30,679 --> 00:17:32,600
cybersecurity is not taken into account

415
00:17:32,600 --> 00:17:36,530
still today so this is the main issue I

416
00:17:36,530 --> 00:17:38,630
want to come back to that dialogue that

417
00:17:38,630 --> 00:17:39,799
you mentioned when you look at

418
00:17:39,799 --> 00:17:41,929
institutions like Harvard Law School so

419
00:17:41,929 --> 00:17:43,399
twenty thirty percent of the graduates

420
00:17:43,399 --> 00:17:45,070
go into public

421
00:17:45,070 --> 00:17:48,010
service law because even though it's I

422
00:17:48,010 --> 00:17:50,410
mean they make much less money but they

423
00:17:50,410 --> 00:17:52,690
think it's worth it and they are doing

424
00:17:52,690 --> 00:17:54,670
something meaningful is also encouraged

425
00:17:54,670 --> 00:17:57,610
by the professor's so the number of tech

426
00:17:57,610 --> 00:18:02,280
people going into pro bono work is lower

427
00:18:02,280 --> 00:18:04,960
so this is hard right and if you think

428
00:18:04,960 --> 00:18:07,540
about public interest law it is a thing

429
00:18:07,540 --> 00:18:10,270
if you're a public interest lawyer your

430
00:18:10,270 --> 00:18:12,880
mother is proud of you and you go work

431
00:18:12,880 --> 00:18:14,740
for an institution working for the

432
00:18:14,740 --> 00:18:16,960
government you're working for the people

433
00:18:16,960 --> 00:18:19,570
and you're making less money and he's

434
00:18:19,570 --> 00:18:21,580
right right now 20% of the graduating

435
00:18:21,580 --> 00:18:23,500
Harvard Law School class doesn't go work

436
00:18:23,500 --> 00:18:25,390
for a corporation or a law firm goes to

437
00:18:25,390 --> 00:18:28,630
work for public interest law and last

438
00:18:28,630 --> 00:18:31,030
year Harvard had a seminar because that

439
00:18:31,030 --> 00:18:34,450
number is so low the number of computer

440
00:18:34,450 --> 00:18:35,950
science graduates who do this is

441
00:18:35,950 --> 00:18:38,920
basically zero and yes there's certainly

442
00:18:38,920 --> 00:18:40,600
because let me go off first though

443
00:18:40,600 --> 00:18:42,070
because they don't want he's a couple of

444
00:18:42,070 --> 00:18:44,080
things I mean I I think there's there's

445
00:18:44,080 --> 00:18:46,720
not a lot of demand you know right now

446
00:18:46,720 --> 00:18:48,490
the number of technologists on

447
00:18:48,490 --> 00:18:50,770
congressional staffs is extraordinarily

448
00:18:50,770 --> 00:18:52,780
small the United States I mean I don't

449
00:18:52,780 --> 00:18:54,220
think it's better in any European

450
00:18:54,220 --> 00:18:56,470
country that the number of technologists

451
00:18:56,470 --> 00:18:58,840
working at some of these NGOs is very

452
00:18:58,840 --> 00:19:00,940
small there are the opportunities and

453
00:19:00,940 --> 00:19:04,240
also there isn't this the supply there's

454
00:19:04,240 --> 00:19:06,190
this there's isolated instances but not

455
00:19:06,190 --> 00:19:10,030
enough people and this feels important

456
00:19:10,030 --> 00:19:12,430
so here's the way I so I now teach to

457
00:19:12,430 --> 00:19:13,810
the Kennedy School which is kind of kind

458
00:19:13,810 --> 00:19:15,340
of neat or I'm a techie teaching public

459
00:19:15,340 --> 00:19:19,960
policy the Kennedy School in the 20th

460
00:19:19,960 --> 00:19:22,360
century the fundamental question of

461
00:19:22,360 --> 00:19:24,700
society was how much of our lives should

462
00:19:24,700 --> 00:19:26,710
be governed by the market and how much

463
00:19:26,710 --> 00:19:30,280
by the state that define second of 20th

464
00:19:30,280 --> 00:19:32,020
century and that's why the Harvard

465
00:19:32,020 --> 00:19:33,010
Kennedy School was populated with

466
00:19:33,010 --> 00:19:34,210
economists because they could answer

467
00:19:34,210 --> 00:19:35,980
those sorts of questions

468
00:19:35,980 --> 00:19:38,260
I think the defining question of this

469
00:19:38,260 --> 00:19:40,690
century is how much of our lives should

470
00:19:40,690 --> 00:19:42,850
be governed by technology and under what

471
00:19:42,850 --> 00:19:46,600
rules so you need more technologists

472
00:19:46,600 --> 00:19:49,960
doing public policy to answer that

473
00:19:49,960 --> 00:19:52,690
question and if cybersecurity an AI and

474
00:19:52,690 --> 00:19:54,940
future of work and climate change and

475
00:19:54,940 --> 00:19:57,970
bioengineering and food safety we can go

476
00:19:57,970 --> 00:19:58,870
on and on

477
00:19:58,870 --> 00:20:01,300
these are all deeply technical issues

478
00:20:01,300 --> 00:20:04,720
but do the techies understand to the

479
00:20:04,720 --> 00:20:07,180
same extent that politics is difficult

480
00:20:07,180 --> 00:20:09,910
no I mean it's gotta go both ways right

481
00:20:09,910 --> 00:20:11,200
I mean why we have this disconnect in

482
00:20:11,200 --> 00:20:13,810
both directions right techies I mean you

483
00:20:13,810 --> 00:20:15,280
heard the media heard the techie answer

484
00:20:15,280 --> 00:20:17,890
to solving cybersecurity more bug bounty

485
00:20:17,890 --> 00:20:21,340
programs and that's a great techy answer

486
00:20:21,340 --> 00:20:25,000
it fails in policy but as a techie

487
00:20:25,000 --> 00:20:27,910
that's a perfect answer sorry if you

488
00:20:27,910 --> 00:20:30,610
stole in the room you work for an

489
00:20:30,610 --> 00:20:32,800
institution that is basically trying to

490
00:20:32,800 --> 00:20:35,080
change that I mean when you started your

491
00:20:35,080 --> 00:20:37,620
institution or not but your Center

492
00:20:37,620 --> 00:20:40,540
how did you attract people to work for

493
00:20:40,540 --> 00:20:43,840
the forum on this issue man there's a

494
00:20:43,840 --> 00:20:47,320
wider issue in cybersecurity skill

495
00:20:47,320 --> 00:20:49,690
shortage as a whole in general so I

496
00:20:49,690 --> 00:20:52,500
believe that around 3 million by 2021

497
00:20:52,500 --> 00:20:56,410
in a skill shortage and this is not only

498
00:20:56,410 --> 00:20:59,290
in Europe or North America but it's also

499
00:20:59,290 --> 00:21:01,660
across the planet in Africa in Latin

500
00:21:01,660 --> 00:21:04,900
America in Asia and and the problem is

501
00:21:04,900 --> 00:21:07,840
how we build programs which are in

502
00:21:07,840 --> 00:21:10,420
university program which are flexible

503
00:21:10,420 --> 00:21:13,390
enough and close enough to the private

504
00:21:13,390 --> 00:21:15,730
the mountain profit sector demand and

505
00:21:15,730 --> 00:21:18,280
how we attract those people to to follow

506
00:21:18,280 --> 00:21:19,720
those course and engage into carriers

507
00:21:19,720 --> 00:21:22,660
into what could help me say is worth is

508
00:21:22,660 --> 00:21:28,210
cool I thought that's a given yeah but

509
00:21:28,210 --> 00:21:29,260
that's how are you gonna get people

510
00:21:29,260 --> 00:21:31,210
right yeah but I mean what else could be

511
00:21:31,210 --> 00:21:32,890
done I mean can we bring in foundations

512
00:21:32,890 --> 00:21:34,930
can we bring in technology related

513
00:21:34,930 --> 00:21:38,470
journalism or what what what are all the

514
00:21:38,470 --> 00:21:40,690
options to thank change thank you in the

515
00:21:40,690 --> 00:21:41,950
u.s. at least think foundations will

516
00:21:41,950 --> 00:21:43,870
play a big part I think for a nation

517
00:21:43,870 --> 00:21:45,460
Ford Foundation I mean right now I'm

518
00:21:45,460 --> 00:21:47,050
people gonna go to the RSA conference

519
00:21:47,050 --> 00:21:48,190
next month in California

520
00:21:48,190 --> 00:21:51,580
I am the RSA is letting you a one-day

521
00:21:51,580 --> 00:21:53,800
mini track and Public Interest tech that

522
00:21:53,800 --> 00:21:55,930
Ford Foundation is funding we have six

523
00:21:55,930 --> 00:21:58,690
panels and bring in people from academia

524
00:21:58,690 --> 00:22:01,240
from industry from NGOs from government

525
00:22:01,240 --> 00:22:03,690
to talk about different ways that

526
00:22:03,690 --> 00:22:06,850
technologists are changing the world not

527
00:22:06,850 --> 00:22:09,370
by building a new tech tool but by

528
00:22:09,370 --> 00:22:11,710
affecting public policy have you met in

529
00:22:11,710 --> 00:22:12,340
u.s. Paul

530
00:22:12,340 --> 00:22:18,340
Jamaica was really tech savvy yes know

531
00:22:18,340 --> 00:22:22,720
him or yeah not a lot of them okay what

532
00:22:22,720 --> 00:22:24,520
about you you European politicians that

533
00:22:24,520 --> 00:22:26,529
you met that are really I've networked X

534
00:22:26,529 --> 00:22:29,440
out of European politicians it's not the

535
00:22:29,440 --> 00:22:31,510
firm has developed the first Industrial

536
00:22:31,510 --> 00:22:34,779
Revolution Center in San Francisco and

537
00:22:34,779 --> 00:22:37,900
the idea is to to bring the tech side to

538
00:22:37,900 --> 00:22:42,070
the policy-making so the from steering

539
00:22:42,070 --> 00:22:45,399
projects around that mobility future of

540
00:22:45,399 --> 00:22:49,960
healthcare blockchain drones etc so

541
00:22:49,960 --> 00:22:52,960
there are the influx of people from the

542
00:22:52,960 --> 00:22:56,830
tech side going to the policy making but

543
00:22:56,830 --> 00:23:02,080
it takes time are there jobs are there

544
00:23:02,080 --> 00:23:05,049
jobs for them in government in the in

545
00:23:05,049 --> 00:23:07,360
the agencies in the legislators this

546
00:23:07,360 --> 00:23:09,370
morning in term of discussion bringing

547
00:23:09,370 --> 00:23:11,320
people together on the table and making

548
00:23:11,320 --> 00:23:13,809
sure that they understand each other and

549
00:23:13,809 --> 00:23:15,940
the understand where they have to go so

550
00:23:15,940 --> 00:23:17,289
if you say we need more techies in

551
00:23:17,289 --> 00:23:18,640
government it would be a good idea if

552
00:23:18,640 --> 00:23:22,179
Zuckerberg ran for president I'm not

553
00:23:22,179 --> 00:23:26,610
sure that's related where he's at

554
00:23:26,610 --> 00:23:30,880
something to do okay thanks so much for

555
00:23:30,880 --> 00:23:33,640
the dialogue and good luck with the next

556
00:23:33,640 --> 00:23:36,470
panel thank you all

557
00:23:36,470 --> 00:23:45,130
[Music]

