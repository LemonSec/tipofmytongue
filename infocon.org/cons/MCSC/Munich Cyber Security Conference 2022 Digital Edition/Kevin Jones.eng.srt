1
00:00:00,160 --> 00:00:00,950
put it there

2
00:00:00,950 --> 00:00:03,760
[Music]

3
00:00:03,760 --> 00:00:05,440
yes ladies and gentlemen

4
00:00:05,440 --> 00:00:08,480
welcome to our uh interview here with

5
00:00:08,480 --> 00:00:11,360
kevin jones the cso from

6
00:00:11,360 --> 00:00:14,000
airbus but also chief digital

7
00:00:14,000 --> 00:00:17,520
group officer in in one person that is

8
00:00:17,520 --> 00:00:19,680
that is i think a very good idea when we

9
00:00:19,680 --> 00:00:22,160
talk about information in cyber security

10
00:00:22,160 --> 00:00:23,279
uh

11
00:00:23,279 --> 00:00:25,359
he will be speaking here in our series

12
00:00:25,359 --> 00:00:27,279
for the munich cyber security conference

13
00:00:27,279 --> 00:00:28,840
edition

14
00:00:28,840 --> 00:00:30,800
2022

15
00:00:30,800 --> 00:00:34,239
we conduct a number of expert interviews

16
00:00:34,239 --> 00:00:37,200
as part of the program and kevin was

17
00:00:37,200 --> 00:00:39,920
kind enough to make time in his agenda

18
00:00:39,920 --> 00:00:42,160
in his very busy agenda i must say

19
00:00:42,160 --> 00:00:45,520
to talk to us today and to offer his

20
00:00:45,520 --> 00:00:48,960
perspectives uh at this conference which

21
00:00:48,960 --> 00:00:51,520
is called drifting clouds leadership

22
00:00:51,520 --> 00:00:53,600
perspectives on addressing evolving

23
00:00:53,600 --> 00:00:55,199
cyber threats

24
00:00:55,199 --> 00:00:57,840
at the beginning a few words about kevin

25
00:00:57,840 --> 00:01:01,440
he is of course responsible for

26
00:01:01,440 --> 00:01:03,440
everything related to information

27
00:01:03,440 --> 00:01:05,600
security in a technology group like

28
00:01:05,600 --> 00:01:07,680
airbus but this

29
00:01:07,680 --> 00:01:11,520
is really a wide range of functions

30
00:01:11,520 --> 00:01:14,320
you know starting from risk management

31
00:01:14,320 --> 00:01:17,360
design architecture detection response

32
00:01:17,360 --> 00:01:19,840
but also and that i think we will talk

33
00:01:19,840 --> 00:01:21,920
about later as well as cyber security

34
00:01:21,920 --> 00:01:25,040
research and innovation across all the

35
00:01:25,040 --> 00:01:26,960
divisions of the group

36
00:01:26,960 --> 00:01:27,840
and

37
00:01:27,840 --> 00:01:30,240
this includes of course

38
00:01:30,240 --> 00:01:33,119
information technology security

39
00:01:33,119 --> 00:01:35,680
industrial control system technology

40
00:01:35,680 --> 00:01:36,479
and

41
00:01:36,479 --> 00:01:38,159
never never

42
00:01:38,159 --> 00:01:40,560
last but never least the security of

43
00:01:40,560 --> 00:01:43,119
people and the products themselves the

44
00:01:43,119 --> 00:01:44,960
product security domains

45
00:01:44,960 --> 00:01:47,520
um he of course is um

46
00:01:47,520 --> 00:01:49,680
you know he studied computer science and

47
00:01:49,680 --> 00:01:53,360
has his phd also already uh in in in the

48
00:01:53,360 --> 00:01:55,520
field so he's been faithful since

49
00:01:55,520 --> 00:01:58,240
studying and working on his phd in

50
00:01:58,240 --> 00:02:01,680
information and cyber security um he is

51
00:02:01,680 --> 00:02:04,000
also a founding member of cyber wales

52
00:02:04,000 --> 00:02:06,159
because he's originally from wales and i

53
00:02:06,159 --> 00:02:08,560
understand kevin that you are now

54
00:02:08,560 --> 00:02:11,440
sitting actually uh in wales uh thank

55
00:02:11,440 --> 00:02:15,280
you for for for connecting and um

56
00:02:15,280 --> 00:02:18,239
what i also like he is an advocate uh

57
00:02:18,239 --> 00:02:20,080
and champion for cyber security in

58
00:02:20,080 --> 00:02:21,599
academia

59
00:02:21,599 --> 00:02:23,200
especially for the development of cyber

60
00:02:23,200 --> 00:02:24,400
skills

61
00:02:24,400 --> 00:02:27,760
and for multi-disciplinary research so

62
00:02:27,760 --> 00:02:28,800
um

63
00:02:28,800 --> 00:02:31,200
if you google him you will find many

64
00:02:31,200 --> 00:02:34,400
articles um he is very engaged in and of

65
00:02:34,400 --> 00:02:37,360
course um in the security

66
00:02:37,360 --> 00:02:40,080
uh research community and has published

67
00:02:40,080 --> 00:02:42,879
over 50 articles and holds multiple

68
00:02:42,879 --> 00:02:44,080
patterns

69
00:02:44,080 --> 00:02:46,720
well i think i tried to condense it in a

70
00:02:46,720 --> 00:02:48,640
couple of sentences we could talk the

71
00:02:48,640 --> 00:02:51,280
whole the whole interview time about all

72
00:02:51,280 --> 00:02:54,080
your achievements and activities must be

73
00:02:54,080 --> 00:02:56,480
busy man thank you for joining uh kevin

74
00:02:56,480 --> 00:02:58,080
it's an honor and a privilege to have

75
00:02:58,080 --> 00:02:59,280
you today

76
00:02:59,280 --> 00:03:02,080
that's quite an introduction

77
00:03:02,080 --> 00:03:03,360
absolute pleasure to be with you all

78
00:03:03,360 --> 00:03:04,640
today as well

79
00:03:04,640 --> 00:03:06,400
let's start we have this leadership

80
00:03:06,400 --> 00:03:08,159
perspective on addressing evolving cyber

81
00:03:08,159 --> 00:03:10,000
threats what keeps you up at night if

82
00:03:10,000 --> 00:03:11,519
there's something that keeps you up at

83
00:03:11,519 --> 00:03:13,120
night at all

84
00:03:13,120 --> 00:03:15,680
so i think it's an in joke within ceso

85
00:03:15,680 --> 00:03:16,959
is that you

86
00:03:16,959 --> 00:03:18,720
you're always forever awake at night and

87
00:03:18,720 --> 00:03:21,200
you're always one phone call away from

88
00:03:21,200 --> 00:03:22,959
all the fires that are everywhere else

89
00:03:22,959 --> 00:03:25,920
um i have to say for me i look at it in

90
00:03:25,920 --> 00:03:27,680
completely the opposite way

91
00:03:27,680 --> 00:03:30,480
uh being a ceso in the industry that i

92
00:03:30,480 --> 00:03:32,400
love and i'm passionate about especially

93
00:03:32,400 --> 00:03:33,599
for a company

94
00:03:33,599 --> 00:03:34,959
like airbus where there's always

95
00:03:34,959 --> 00:03:37,200
something new and exciting and the

96
00:03:37,200 --> 00:03:38,879
breadth of what we do

97
00:03:38,879 --> 00:03:41,680
i really love that challenge

98
00:03:41,680 --> 00:03:43,360
and

99
00:03:43,360 --> 00:03:45,040
certainly looking at

100
00:03:45,040 --> 00:03:47,599
how we deploy new technologies

101
00:03:47,599 --> 00:03:50,319
our entire landscape changes the threat

102
00:03:50,319 --> 00:03:52,959
landscape the technology landscape

103
00:03:52,959 --> 00:03:54,799
changes every six months

104
00:03:54,799 --> 00:03:56,480
and that's always new and innovative for

105
00:03:56,480 --> 00:03:57,360
me

106
00:03:57,360 --> 00:03:59,519
so i always actually go to bed pretty

107
00:03:59,519 --> 00:04:01,040
happy

108
00:04:01,040 --> 00:04:02,480
especially on the days when there hasn't

109
00:04:02,480 --> 00:04:04,720
been a cyber crisis

110
00:04:04,720 --> 00:04:06,319
with with where we are as an industry

111
00:04:06,319 --> 00:04:08,080
where we are with devils and i

112
00:04:08,080 --> 00:04:09,760
absolutely love

113
00:04:09,760 --> 00:04:11,120
that challenge

114
00:04:11,120 --> 00:04:12,959
that that intellectual challenge as well

115
00:04:12,959 --> 00:04:15,840
that we face as an industry

116
00:04:15,840 --> 00:04:19,040
ah very good so um if if you know you

117
00:04:19,040 --> 00:04:21,519
would look a little bit um what what's

118
00:04:21,519 --> 00:04:24,800
happening now at the you know

119
00:04:24,800 --> 00:04:28,080
threat landscape as we call it um are

120
00:04:28,080 --> 00:04:30,400
there any developments that that you

121
00:04:30,400 --> 00:04:32,639
know that you're expecting and how would

122
00:04:32,639 --> 00:04:33,919
you

123
00:04:33,919 --> 00:04:36,320
answer to those developments in in your

124
00:04:36,320 --> 00:04:38,240
strategy is is there something that you

125
00:04:38,240 --> 00:04:40,560
want to highlight or you point out

126
00:04:40,560 --> 00:04:43,040
yeah the strategy for substituted airbus

127
00:04:43,040 --> 00:04:45,040
is an interesting one actually

128
00:04:45,040 --> 00:04:47,199
like most companies we obviously have

129
00:04:47,199 --> 00:04:49,680
compliance and regulation based

130
00:04:49,680 --> 00:04:51,840
but we're also risk-based

131
00:04:51,840 --> 00:04:53,280
and that gives you a little bit more

132
00:04:53,280 --> 00:04:55,120
flexibility it's not quite so black and

133
00:04:55,120 --> 00:04:57,280
white depending on where you are in our

134
00:04:57,280 --> 00:04:58,720
business

135
00:04:58,720 --> 00:05:00,880
so

136
00:05:00,880 --> 00:05:03,199
we also have four very distinct pillars

137
00:05:03,199 --> 00:05:04,800
as you said in your introduction

138
00:05:04,800 --> 00:05:06,240
obviously i.t

139
00:05:06,240 --> 00:05:08,960
but industrial product and people

140
00:05:08,960 --> 00:05:11,039
domains have to form part of that

141
00:05:11,039 --> 00:05:13,199
strategy

142
00:05:13,199 --> 00:05:15,520
we have a federated model

143
00:05:15,520 --> 00:05:17,199
which i think is a little bit unique

144
00:05:17,199 --> 00:05:18,639
most people will have their cyber

145
00:05:18,639 --> 00:05:21,520
security embedded in it

146
00:05:21,520 --> 00:05:24,560
and see it as an i.t problem now

147
00:05:24,560 --> 00:05:26,000
obviously for us

148
00:05:26,000 --> 00:05:28,560
we have a huge amount of

149
00:05:28,560 --> 00:05:31,520
expert skills within rit

150
00:05:31,520 --> 00:05:33,759
domain to be able to provide security

151
00:05:33,759 --> 00:05:36,080
architecture for example

152
00:05:36,080 --> 00:05:38,320
run our tools and capabilities that we'd

153
00:05:38,320 --> 00:05:39,520
have there

154
00:05:39,520 --> 00:05:42,000
but equally we then have the same level

155
00:05:42,000 --> 00:05:43,840
of capability within our product in our

156
00:05:43,840 --> 00:05:45,600
engineering domains whether they're

157
00:05:45,600 --> 00:05:47,120
designing the security architecture of

158
00:05:47,120 --> 00:05:49,680
an airplane or a satellite or a

159
00:05:49,680 --> 00:05:51,759
helicopter for example

160
00:05:51,759 --> 00:05:53,440
but it's federated so then we have

161
00:05:53,440 --> 00:05:56,160
corporate capabilities that allow for

162
00:05:56,160 --> 00:05:58,800
that localized accountability but a very

163
00:05:58,800 --> 00:06:02,240
centralized coordination and strategy

164
00:06:02,240 --> 00:06:04,880
around what we do and that makes very

165
00:06:04,880 --> 00:06:07,600
very agile to be able to respond to that

166
00:06:07,600 --> 00:06:10,319
threat landscape as it evolves because

167
00:06:10,319 --> 00:06:12,319
for example some of the corporate

168
00:06:12,319 --> 00:06:15,199
capabilities such as the cert

169
00:06:15,199 --> 00:06:17,199
when there is an incident

170
00:06:17,199 --> 00:06:18,240
or something that needs to be

171
00:06:18,240 --> 00:06:20,000
investigated that has been escalated

172
00:06:20,000 --> 00:06:21,600
from our security operation centers we

173
00:06:21,600 --> 00:06:23,840
can do that wherever it may sit in the

174
00:06:23,840 --> 00:06:26,400
business or whichever domain it may sit

175
00:06:26,400 --> 00:06:27,840
in

176
00:06:27,840 --> 00:06:29,039
the same in terms of things like

177
00:06:29,039 --> 00:06:30,400
vulnerability management which we can

178
00:06:30,400 --> 00:06:32,400
talk about later on

179
00:06:32,400 --> 00:06:34,560
very hot topic for organizations right

180
00:06:34,560 --> 00:06:37,039
now especially given the prevalence of

181
00:06:37,039 --> 00:06:39,199
vulnerabilities during last year and log

182
00:06:39,199 --> 00:06:40,960
four shell or log4j

183
00:06:40,960 --> 00:06:42,319
just before christmas and that

184
00:06:42,319 --> 00:06:44,639
vulnerability management capability

185
00:06:44,639 --> 00:06:47,039
for us uh is centralized in the way that

186
00:06:47,039 --> 00:06:48,800
we coordinate it because it makes us

187
00:06:48,800 --> 00:06:51,120
very quick very agile to be able to

188
00:06:51,120 --> 00:06:54,160
respond to those kind of emerging

189
00:06:54,160 --> 00:06:56,000
incidents and vulnerabilities that occur

190
00:06:56,000 --> 00:06:57,039
so

191
00:06:57,039 --> 00:06:58,000
as a

192
00:06:58,000 --> 00:07:00,160
as a in a nutshell if you like our

193
00:07:00,160 --> 00:07:02,400
strategy for airbus

194
00:07:02,400 --> 00:07:03,759
is to manage

195
00:07:03,759 --> 00:07:06,319
at a risk acceptance level for the

196
00:07:06,319 --> 00:07:08,080
company and that's risk acceptance

197
00:07:08,080 --> 00:07:09,759
levels it's plural because different

198
00:07:09,759 --> 00:07:10,880
parts of the business will have

199
00:07:10,880 --> 00:07:12,800
different levels

200
00:07:12,800 --> 00:07:15,120
to have leading capabilities

201
00:07:15,120 --> 00:07:16,720
and we've really invested with our cyber

202
00:07:16,720 --> 00:07:18,880
security transformation in those

203
00:07:18,880 --> 00:07:20,560
capability development and that means

204
00:07:20,560 --> 00:07:22,639
skills it means tools and technologies

205
00:07:22,639 --> 00:07:24,720
as well

206
00:07:24,720 --> 00:07:26,479
and then bringing all that together in a

207
00:07:26,479 --> 00:07:28,400
really coordinated way i think is the

208
00:07:28,400 --> 00:07:30,639
only way for certainly large enterprises

209
00:07:30,639 --> 00:07:31,759
like ours

210
00:07:31,759 --> 00:07:33,840
to be able to operate because that means

211
00:07:33,840 --> 00:07:35,759
that we can be very much on the

212
00:07:35,759 --> 00:07:37,759
defensive side and we have the right

213
00:07:37,759 --> 00:07:40,400
level of defense technologies

214
00:07:40,400 --> 00:07:42,400
we then have the monitoring side

215
00:07:42,400 --> 00:07:44,879
and finally our ability to

216
00:07:44,879 --> 00:07:47,120
react in the event of something that

217
00:07:47,120 --> 00:07:48,639
occurs

218
00:07:48,639 --> 00:07:49,680
well

219
00:07:49,680 --> 00:07:52,400
that sounds uh extremely complex i must

220
00:07:52,400 --> 00:07:54,479
say i mean

221
00:07:54,479 --> 00:07:57,039
at one of course the the good

222
00:07:57,039 --> 00:07:58,560
uh what i like about it is that

223
00:07:58,560 --> 00:08:00,240
everything is integrated and connected

224
00:08:00,240 --> 00:08:02,240
so you don't isolate

225
00:08:02,240 --> 00:08:04,400
those different tasks which i think is

226
00:08:04,400 --> 00:08:06,080
part of the success

227
00:08:06,080 --> 00:08:08,479
and i like the term risk acceptance

228
00:08:08,479 --> 00:08:09,759
levels so that

229
00:08:09,759 --> 00:08:12,160
maybe is also

230
00:08:12,160 --> 00:08:15,039
a very um clever way of

231
00:08:15,039 --> 00:08:18,000
directing your your strategy or defining

232
00:08:18,000 --> 00:08:19,919
your strategy and and the measures

233
00:08:19,919 --> 00:08:20,879
behind

234
00:08:20,879 --> 00:08:22,080
um

235
00:08:22,080 --> 00:08:24,879
we always come across the how do you how

236
00:08:24,879 --> 00:08:27,120
do you actually

237
00:08:27,120 --> 00:08:29,440
sort of determine those risks if you

238
00:08:29,440 --> 00:08:31,840
have what is the risk acceptable because

239
00:08:31,840 --> 00:08:33,120
people always

240
00:08:33,120 --> 00:08:35,120
have a little bit

241
00:08:35,120 --> 00:08:36,399
problems with

242
00:08:36,399 --> 00:08:39,279
determining what what how much what risk

243
00:08:39,279 --> 00:08:41,679
really would there be so how does there

244
00:08:41,679 --> 00:08:43,440
anything that you can recommend that you

245
00:08:43,440 --> 00:08:45,839
or how do you do this

246
00:08:45,839 --> 00:08:48,640
so how long have you got um yeah

247
00:08:48,640 --> 00:08:51,120
here we go well you start and i

248
00:08:51,120 --> 00:08:53,600
say stop

249
00:08:53,600 --> 00:08:54,959
first thing you've picked up on the on

250
00:08:54,959 --> 00:08:56,800
the wonderful point we often in the

251
00:08:56,800 --> 00:08:59,120
industry talk about risk tolerance

252
00:08:59,120 --> 00:08:59,839
um

253
00:08:59,839 --> 00:09:00,560
and

254
00:09:00,560 --> 00:09:02,000
if you take that from perspective it's

255
00:09:02,000 --> 00:09:03,920
quite negative it's i've got to be

256
00:09:03,920 --> 00:09:06,640
absolutely perfect everywhere

257
00:09:06,640 --> 00:09:08,560
and that's not how businesses work

258
00:09:08,560 --> 00:09:11,040
businesses take risks and cyber security

259
00:09:11,040 --> 00:09:14,000
cannot fix all of our risks

260
00:09:14,000 --> 00:09:16,000
so to open up that discussion with the

261
00:09:16,000 --> 00:09:17,519
business you have to start with this

262
00:09:17,519 --> 00:09:19,279
this discussion about risk acceptance

263
00:09:19,279 --> 00:09:21,279
and um i have a very technical

264
00:09:21,279 --> 00:09:23,600
background and i'm one of those people

265
00:09:23,600 --> 00:09:25,519
who if you give me a system

266
00:09:25,519 --> 00:09:27,360
or an environment i will always find a

267
00:09:27,360 --> 00:09:29,279
way given enough time that i can find a

268
00:09:29,279 --> 00:09:30,640
new vulnerability i can break it i can

269
00:09:30,640 --> 00:09:32,720
do this i can do that

270
00:09:32,720 --> 00:09:34,720
risk tolerance would say

271
00:09:34,720 --> 00:09:36,480
do you know what i've got this one

272
00:09:36,480 --> 00:09:38,399
wonderful attack that means that if i

273
00:09:38,399 --> 00:09:40,160
daisy chain these three vulnerabilities

274
00:09:40,160 --> 00:09:41,279
and do this

275
00:09:41,279 --> 00:09:43,200
i can own and pawn that system the

276
00:09:43,200 --> 00:09:44,880
reality is that's probably something

277
00:09:44,880 --> 00:09:45,680
that's

278
00:09:45,680 --> 00:09:47,360
not really

279
00:09:47,360 --> 00:09:49,440
bothering a business it's too difficult

280
00:09:49,440 --> 00:09:50,880
to execute and that would be within our

281
00:09:50,880 --> 00:09:52,160
risk acceptance so changing that

282
00:09:52,160 --> 00:09:53,680
language actually has been a very good

283
00:09:53,680 --> 00:09:55,040
start for

284
00:09:55,040 --> 00:09:57,440
our entire cyber security teams to start

285
00:09:57,440 --> 00:09:59,519
thinking differently and change their

286
00:09:59,519 --> 00:10:01,040
mindset

287
00:10:01,040 --> 00:10:02,399
the second thing i think about risk that

288
00:10:02,399 --> 00:10:04,640
makes it so difficult

289
00:10:04,640 --> 00:10:09,120
is quantifying that risk because

290
00:10:09,120 --> 00:10:10,480
you often say

291
00:10:10,480 --> 00:10:12,880
in cyber security well this technology

292
00:10:12,880 --> 00:10:14,399
or this tool

293
00:10:14,399 --> 00:10:15,200
or

294
00:10:15,200 --> 00:10:16,640
maybe this vulnerability leads us to

295
00:10:16,640 --> 00:10:18,800
have that risk but the landscape then

296
00:10:18,800 --> 00:10:20,079
changes

297
00:10:20,079 --> 00:10:22,000
very quickly and within a few months

298
00:10:22,000 --> 00:10:24,160
your entire risk landscape is at a out

299
00:10:24,160 --> 00:10:25,440
of date so

300
00:10:25,440 --> 00:10:27,279
um the way i'm trying to do it in airbus

301
00:10:27,279 --> 00:10:28,880
is to say okay

302
00:10:28,880 --> 00:10:30,880
we have our risk

303
00:10:30,880 --> 00:10:32,959
dashboards risk frameworks they're

304
00:10:32,959 --> 00:10:34,640
aggregated it's part of our federated

305
00:10:34,640 --> 00:10:36,560
model which really helps as well because

306
00:10:36,560 --> 00:10:37,760
it means we can

307
00:10:37,760 --> 00:10:40,720
really look into the detail of risk

308
00:10:40,720 --> 00:10:42,720
um and we say okay we obviously then

309
00:10:42,720 --> 00:10:43,680
have a risk

310
00:10:43,680 --> 00:10:45,839
reduction plan to get us down to that

311
00:10:45,839 --> 00:10:47,279
risk acceptance level and we're going to

312
00:10:47,279 --> 00:10:49,360
invest in maybe new technologies or

313
00:10:49,360 --> 00:10:51,360
maybe new processes or we're going to

314
00:10:51,360 --> 00:10:53,360
enhance the capabilities in certain

315
00:10:53,360 --> 00:10:56,000
parts of the group to be able to do that

316
00:10:56,000 --> 00:10:57,839
the problem is and one of the biggest

317
00:10:57,839 --> 00:11:00,880
mistakes i see people make especially in

318
00:11:00,880 --> 00:11:02,320
the industry when it's about risk is we

319
00:11:02,320 --> 00:11:03,680
then say right we're going to aggregate

320
00:11:03,680 --> 00:11:06,240
that to a single risk dashboard with low

321
00:11:06,240 --> 00:11:07,920
medium and high

322
00:11:07,920 --> 00:11:08,959
the problem you've got in an

323
00:11:08,959 --> 00:11:11,200
organization is actually if i then start

324
00:11:11,200 --> 00:11:13,360
aggregating risks well it's always high

325
00:11:13,360 --> 00:11:14,959
so you spent all this money you come

326
00:11:14,959 --> 00:11:16,320
back to me six months later and it's

327
00:11:16,320 --> 00:11:18,800
still high and you have to explain then

328
00:11:18,800 --> 00:11:20,320
well yes but

329
00:11:20,320 --> 00:11:22,640
and maybe uh so what we do actually is

330
00:11:22,640 --> 00:11:23,680
say

331
00:11:23,680 --> 00:11:25,760
okay this is where we are in our risk

332
00:11:25,760 --> 00:11:28,240
dashboard based on the baseline of risk

333
00:11:28,240 --> 00:11:29,279
that we took

334
00:11:29,279 --> 00:11:31,040
whether it's six months 12 months or a

335
00:11:31,040 --> 00:11:33,360
year ago three years ago

336
00:11:33,360 --> 00:11:35,279
but here's what's changed since so the

337
00:11:35,279 --> 00:11:36,800
company's maybe done new digital

338
00:11:36,800 --> 00:11:39,680
transformation we've got new platforms

339
00:11:39,680 --> 00:11:41,440
the threat landscape externally so

340
00:11:41,440 --> 00:11:43,200
things we cannot

341
00:11:43,200 --> 00:11:45,519
have all changed and this is where this

342
00:11:45,519 --> 00:11:48,399
is driving risks up so i've often now

343
00:11:48,399 --> 00:11:50,399
shown this as almost as scales we say

344
00:11:50,399 --> 00:11:51,920
well this is where we're getting better

345
00:11:51,920 --> 00:11:54,399
this is what's changed

346
00:11:54,399 --> 00:11:55,360
some things that are completely

347
00:11:55,360 --> 00:11:57,680
non-controllable to us and that enables

348
00:11:57,680 --> 00:11:59,600
us to have a very sensible conversation

349
00:11:59,600 --> 00:12:01,519
about managing risk

350
00:12:01,519 --> 00:12:03,040
and the final piece of advice i would

351
00:12:03,040 --> 00:12:05,760
say is we often look for averages and

352
00:12:05,760 --> 00:12:08,320
averages can absolutely

353
00:12:08,320 --> 00:12:11,360
sink and kill a cyber security program

354
00:12:11,360 --> 00:12:12,800
because if you're starting to say well

355
00:12:12,800 --> 00:12:14,320
everybody has to hit this average

356
00:12:14,320 --> 00:12:17,200
baseline that means inside that average

357
00:12:17,200 --> 00:12:18,399
some things are very good some things

358
00:12:18,399 --> 00:12:20,639
are very bad you completely lose

359
00:12:20,639 --> 00:12:23,040
visibility of what's really important

360
00:12:23,040 --> 00:12:25,200
and you lose that ability to deep dive

361
00:12:25,200 --> 00:12:27,040
into some of the data so what we've done

362
00:12:27,040 --> 00:12:29,839
in airbus is i'll be very kind of short

363
00:12:29,839 --> 00:12:31,519
on this but

364
00:12:31,519 --> 00:12:32,639
in the

365
00:12:32,639 --> 00:12:34,320
enterprise risk management side we

366
00:12:34,320 --> 00:12:35,760
present obviously the top risks to the

367
00:12:35,760 --> 00:12:38,480
company in the context of business and

368
00:12:38,480 --> 00:12:40,720
business risk for cyber security

369
00:12:40,720 --> 00:12:42,959
then we have a dedicated team which is

370
00:12:42,959 --> 00:12:45,360
cyber security risk management where we

371
00:12:45,360 --> 00:12:47,440
pull together all of the data about our

372
00:12:47,440 --> 00:12:49,519
controls our operations

373
00:12:49,519 --> 00:12:51,200
it actually sits very right next to our

374
00:12:51,200 --> 00:12:53,279
vulnerability management team

375
00:12:53,279 --> 00:12:54,639
so that enables us to have sensible

376
00:12:54,639 --> 00:12:56,959
conversations at ceso level

377
00:12:56,959 --> 00:12:59,040
for how i manage the cyber security

378
00:12:59,040 --> 00:13:01,360
strategy the program and the risks and

379
00:13:01,360 --> 00:13:03,040
then we translate that into business

380
00:13:03,040 --> 00:13:04,639
risk to be presented to the executive

381
00:13:04,639 --> 00:13:06,480
level and executive committee so

382
00:13:06,480 --> 00:13:08,480
those are some of the

383
00:13:08,480 --> 00:13:10,320
tips and tricks that i think that we've

384
00:13:10,320 --> 00:13:12,160
developed probably over the last two two

385
00:13:12,160 --> 00:13:13,680
and a half years of our own

386
00:13:13,680 --> 00:13:15,760
transformation journey and some of our

387
00:13:15,760 --> 00:13:17,360
great lessons that i think we've been

388
00:13:17,360 --> 00:13:18,880
being learned

389
00:13:18,880 --> 00:13:20,160
the next question i know you're going to

390
00:13:20,160 --> 00:13:22,160
ask me is is it working well

391
00:13:22,160 --> 00:13:23,760
it is

392
00:13:23,760 --> 00:13:25,519
i i'm still looking for industry best

393
00:13:25,519 --> 00:13:27,279
practice and i'm still very much open to

394
00:13:27,279 --> 00:13:29,279
ideas from other places but certainly

395
00:13:29,279 --> 00:13:30,639
those are some of the things i've i

396
00:13:30,639 --> 00:13:32,959
found to work very well for our company

397
00:13:32,959 --> 00:13:34,880
very good um you mentioned it in the

398
00:13:34,880 --> 00:13:37,040
beginning vulnerability management is

399
00:13:37,040 --> 00:13:40,160
maybe a point we should look at um

400
00:13:40,160 --> 00:13:41,519
of course

401
00:13:41,519 --> 00:13:43,760
one thing is your own organization and

402
00:13:43,760 --> 00:13:46,240
your own you know domains of control

403
00:13:46,240 --> 00:13:48,480
but then you have of course a whole

404
00:13:48,480 --> 00:13:51,120
ecosystem of providers suppliers and

405
00:13:51,120 --> 00:13:52,160
partners

406
00:13:52,160 --> 00:13:53,920
um and i think

407
00:13:53,920 --> 00:13:55,519
they also um

408
00:13:55,519 --> 00:13:58,160
you know contribute to the vulnerability

409
00:13:58,160 --> 00:14:00,800
uh picture um how do you

410
00:14:00,800 --> 00:14:02,639
how do you deal with that kind of

411
00:14:02,639 --> 00:14:05,199
vulnerability situation

412
00:14:05,199 --> 00:14:06,880
i think vulnerability management for

413
00:14:06,880 --> 00:14:09,279
obvious reasons is an absolutely hot

414
00:14:09,279 --> 00:14:11,920
topic for for our industry and for us as

415
00:14:11,920 --> 00:14:14,240
a company right now

416
00:14:14,240 --> 00:14:17,199
so in in terms of how we manage that um

417
00:14:17,199 --> 00:14:18,240
firstly

418
00:14:18,240 --> 00:14:20,880
in inside our own organization

419
00:14:20,880 --> 00:14:24,959
we actually have vulnerability feeds

420
00:14:25,120 --> 00:14:28,000
from uh the normal suppliers and third

421
00:14:28,000 --> 00:14:29,920
parties that we have those standard

422
00:14:29,920 --> 00:14:31,519
industry feeds

423
00:14:31,519 --> 00:14:33,360
with cvss scores and various things like

424
00:14:33,360 --> 00:14:34,240
that

425
00:14:34,240 --> 00:14:36,079
what we then do actually is a little bit

426
00:14:36,079 --> 00:14:37,760
different is we translate that into a

427
00:14:37,760 --> 00:14:39,360
business impact

428
00:14:39,360 --> 00:14:41,040
assessment or business impact value

429
00:14:41,040 --> 00:14:43,920
because a high vulnerability if actually

430
00:14:43,920 --> 00:14:46,480
you're not using it or it's within an

431
00:14:46,480 --> 00:14:47,760
enclave of the business that's highly

432
00:14:47,760 --> 00:14:50,480
well protected might not be a priority

433
00:14:50,480 --> 00:14:52,240
one critical patch it might be a high

434
00:14:52,240 --> 00:14:54,240
patch so you buy yourself some more time

435
00:14:54,240 --> 00:14:57,519
so we definitely go through that process

436
00:14:57,519 --> 00:14:58,880
and then you have to be able to patch

437
00:14:58,880 --> 00:15:00,480
things very very quickly across all of

438
00:15:00,480 --> 00:15:03,120
your systems which means you need

439
00:15:03,120 --> 00:15:04,000
good

440
00:15:04,000 --> 00:15:05,600
asset databases and good asset

441
00:15:05,600 --> 00:15:07,600
inventories so that's why again we try

442
00:15:07,600 --> 00:15:09,040
and bring all of those things together

443
00:15:09,040 --> 00:15:13,279
to make that vulnerability piece work

444
00:15:13,279 --> 00:15:14,800
the supply chain part i think is the

445
00:15:14,800 --> 00:15:16,079
final bit

446
00:15:16,079 --> 00:15:18,800
which is exceptionally difficult to do

447
00:15:18,800 --> 00:15:20,959
and it only works through good

448
00:15:20,959 --> 00:15:23,040
engagement with your suppliers

449
00:15:23,040 --> 00:15:24,560
they've got to be able to inform you

450
00:15:24,560 --> 00:15:27,120
when they have an incident for example

451
00:15:27,120 --> 00:15:28,959
and we have information sharing

452
00:15:28,959 --> 00:15:31,360
partnerships with our suppliers

453
00:15:31,360 --> 00:15:33,600
we share through

454
00:15:33,600 --> 00:15:36,240
threat intelligence the the iocs or the

455
00:15:36,240 --> 00:15:38,639
ttps throughout our business and we

456
00:15:38,639 --> 00:15:41,360
generally pull hashes or ap addresses

457
00:15:41,360 --> 00:15:43,680
into those very quickly and all of that

458
00:15:43,680 --> 00:15:45,199
as an ecosystem

459
00:15:45,199 --> 00:15:47,920
really enables you to respond quickly

460
00:15:47,920 --> 00:15:50,000
the problem is it's not cheap to do it

461
00:15:50,000 --> 00:15:51,440
it's a lot of effort

462
00:15:51,440 --> 00:15:53,839
um and i think for organizations like

463
00:15:53,839 --> 00:15:55,680
ours that are doing it right now we're

464
00:15:55,680 --> 00:15:57,440
doing it reasonably well but i'd

465
00:15:57,440 --> 00:15:58,720
definitely like to make that whole

466
00:15:58,720 --> 00:16:00,720
process more efficient

467
00:16:00,720 --> 00:16:03,600
is there a way to incentivize

468
00:16:03,600 --> 00:16:06,399
providers to you know follow the

469
00:16:06,399 --> 00:16:09,680
philosophy of uh you know the the the

470
00:16:09,680 --> 00:16:12,959
customer in that case uh your group um

471
00:16:12,959 --> 00:16:14,399
to to live

472
00:16:14,399 --> 00:16:16,399
really not only to to provide the

473
00:16:16,399 --> 00:16:18,720
certification or you know

474
00:16:18,720 --> 00:16:21,839
but to really sort of um be motivated to

475
00:16:21,839 --> 00:16:24,480
really engage in in those ideas and

476
00:16:24,480 --> 00:16:25,680
principles

477
00:16:25,680 --> 00:16:26,800
yeah so

478
00:16:26,800 --> 00:16:29,040
for us with suppliers we manage it

479
00:16:29,040 --> 00:16:30,320
through

480
00:16:30,320 --> 00:16:31,600
obviously through procurement so when

481
00:16:31,600 --> 00:16:33,680
you're first boarded as a supplier

482
00:16:33,680 --> 00:16:35,040
there's the usual standard cyber

483
00:16:35,040 --> 00:16:37,759
security contracts we have audits

484
00:16:37,759 --> 00:16:39,759
but actually the the regular engagements

485
00:16:39,759 --> 00:16:41,600
that we have maybe for some of our

486
00:16:41,600 --> 00:16:43,680
larger suppliers who have certs

487
00:16:43,680 --> 00:16:47,279
we do cert to cert engagements with them

488
00:16:47,279 --> 00:16:49,199
we do a lot of information sharing as i

489
00:16:49,199 --> 00:16:51,759
said because that enables

490
00:16:51,759 --> 00:16:53,120
all of us to be more secure and it

491
00:16:53,120 --> 00:16:55,040
builds that trust relationship that we

492
00:16:55,040 --> 00:16:56,720
have very much with

493
00:16:56,720 --> 00:16:58,560
the supply chain

494
00:16:58,560 --> 00:17:00,560
and obviously if there is an incident in

495
00:17:00,560 --> 00:17:02,560
one of the suppliers it enables us to be

496
00:17:02,560 --> 00:17:04,959
very quick to respond depending on how

497
00:17:04,959 --> 00:17:06,400
we use that

498
00:17:06,400 --> 00:17:07,599
supplier

499
00:17:07,599 --> 00:17:09,679
where they are in the infrastructure

500
00:17:09,679 --> 00:17:11,919
but it's that real open communication

501
00:17:11,919 --> 00:17:13,520
and sharing

502
00:17:13,520 --> 00:17:15,199
that is the only way it'll it'll help us

503
00:17:15,199 --> 00:17:16,880
to be more secure

504
00:17:16,880 --> 00:17:19,119
very good um

505
00:17:19,119 --> 00:17:21,359
one question especially now of course in

506
00:17:21,359 --> 00:17:23,119
your industry but i think it could be

507
00:17:23,119 --> 00:17:25,520
also a trigger for other industries

508
00:17:25,520 --> 00:17:28,000
and actually it says also in europe uh

509
00:17:28,000 --> 00:17:31,120
in your short biography um you know the

510
00:17:31,120 --> 00:17:33,679
the connection of cyber security but

511
00:17:33,679 --> 00:17:36,960
also the safety of critical systems so i

512
00:17:36,960 --> 00:17:38,160
think um

513
00:17:38,160 --> 00:17:39,360
maybe you could

514
00:17:39,360 --> 00:17:41,440
um explain a little bit on on on how

515
00:17:41,440 --> 00:17:43,679
these are connected and how do you

516
00:17:43,679 --> 00:17:46,559
actually maybe consciously um

517
00:17:46,559 --> 00:17:49,440
you know put these two concepts together

518
00:17:49,440 --> 00:17:51,039
yeah so there's an open debate in the

519
00:17:51,039 --> 00:17:53,280
industry about security versus safety

520
00:17:53,280 --> 00:17:54,720
and whether one is a

521
00:17:54,720 --> 00:17:56,799
is a subset of the other

522
00:17:56,799 --> 00:17:59,120
um i think from the perspective if we

523
00:17:59,120 --> 00:18:00,400
look at things like industrial control

524
00:18:00,400 --> 00:18:02,160
systems for example

525
00:18:02,160 --> 00:18:04,320
one of the challenges there is how to

526
00:18:04,320 --> 00:18:06,320
encapsulate security around those

527
00:18:06,320 --> 00:18:08,799
environments especially as you integrate

528
00:18:08,799 --> 00:18:11,360
digital transformation into a production

529
00:18:11,360 --> 00:18:13,600
facility

530
00:18:13,600 --> 00:18:16,559
and having good security there enables

531
00:18:16,559 --> 00:18:19,200
you to reduce the number of incidents

532
00:18:19,200 --> 00:18:21,120
that are likely to occur

533
00:18:21,120 --> 00:18:23,120
uh within that environment

534
00:18:23,120 --> 00:18:24,720
and

535
00:18:24,720 --> 00:18:26,480
that that for me is is always slightly

536
00:18:26,480 --> 00:18:29,039
different to the safety question because

537
00:18:29,039 --> 00:18:31,360
you can still build safety critical

538
00:18:31,360 --> 00:18:34,240
systems that are resilient to any kind

539
00:18:34,240 --> 00:18:36,000
of incident within that environment

540
00:18:36,000 --> 00:18:37,520
whether it's

541
00:18:37,520 --> 00:18:40,559
duplicating through

542
00:18:40,559 --> 00:18:42,799
triple redundancy for example in the

543
00:18:42,799 --> 00:18:43,919
systems

544
00:18:43,919 --> 00:18:46,240
uh whether you then have if again i take

545
00:18:46,240 --> 00:18:48,080
the industrial environment

546
00:18:48,080 --> 00:18:49,520
you you not only have the control

547
00:18:49,520 --> 00:18:51,840
devices the plcs the rtus

548
00:18:51,840 --> 00:18:53,919
but you'll have the safety controller

549
00:18:53,919 --> 00:18:56,080
environments as well behind that and

550
00:18:56,080 --> 00:18:57,440
there is cases where those safety

551
00:18:57,440 --> 00:18:58,880
controllers in industrial environments

552
00:18:58,880 --> 00:19:01,039
have been targeted too um but actually

553
00:19:01,039 --> 00:19:04,559
the idea then about having um the

554
00:19:04,559 --> 00:19:06,160
control mechanisms or the outlet

555
00:19:06,160 --> 00:19:08,160
mechanisms there's still engineered

556
00:19:08,160 --> 00:19:09,600
systems and you can still engineer

557
00:19:09,600 --> 00:19:11,039
safety into those industrial

558
00:19:11,039 --> 00:19:13,200
environments

559
00:19:13,200 --> 00:19:14,400
so

560
00:19:14,400 --> 00:19:16,559
it's a it's a mixed question and the

561
00:19:16,559 --> 00:19:18,559
answer is you basically need both you

562
00:19:18,559 --> 00:19:21,360
need to be resilient for cyber

563
00:19:21,360 --> 00:19:23,440
which is obviously part of the equation

564
00:19:23,440 --> 00:19:25,360
and then on top of that you've got to

565
00:19:25,360 --> 00:19:26,640
ensure you have

566
00:19:26,640 --> 00:19:28,559
safety by design as well as security by

567
00:19:28,559 --> 00:19:29,919
design

568
00:19:29,919 --> 00:19:32,880
well since this is a forum also

569
00:19:32,880 --> 00:19:34,559
including you know

570
00:19:34,559 --> 00:19:37,280
experts and perspectives from from

571
00:19:37,280 --> 00:19:39,760
government and policy making or public

572
00:19:39,760 --> 00:19:42,320
agencies is there anything

573
00:19:42,320 --> 00:19:44,559
from your point of view that you wish

574
00:19:44,559 --> 00:19:47,120
could should be addressed more keenly

575
00:19:47,120 --> 00:19:48,559
and um

576
00:19:48,559 --> 00:19:51,440
to help your your daily operational work

577
00:19:51,440 --> 00:19:53,679
to be more successful is there something

578
00:19:53,679 --> 00:19:55,919
that you wish

579
00:19:55,919 --> 00:19:57,360
governments or

580
00:19:57,360 --> 00:19:58,080
the

581
00:19:58,080 --> 00:20:00,160
responsible agencies should

582
00:20:00,160 --> 00:20:01,280
very much

583
00:20:01,280 --> 00:20:04,400
improve or continue or focus on this and

584
00:20:04,400 --> 00:20:05,600
that

585
00:20:05,600 --> 00:20:07,360
there's a few things i think

586
00:20:07,360 --> 00:20:08,799
that are very much on the radar at the

587
00:20:08,799 --> 00:20:09,919
moment

588
00:20:09,919 --> 00:20:11,919
i'm a huge advocate right now for

589
00:20:11,919 --> 00:20:14,559
human-centric cyber security so

590
00:20:14,559 --> 00:20:16,640
considering for example

591
00:20:16,640 --> 00:20:18,640
not just the technical element of our

592
00:20:18,640 --> 00:20:20,080
industry and

593
00:20:20,080 --> 00:20:21,919
we say humans are the weakest link it's

594
00:20:21,919 --> 00:20:24,559
a myth uh it's completely wrong

595
00:20:24,559 --> 00:20:27,919
uh and we've got to start including

596
00:20:27,919 --> 00:20:29,919
i mean airbus is fantastic that we've

597
00:20:29,919 --> 00:20:31,679
got psychologists that work in our

598
00:20:31,679 --> 00:20:33,520
research teams that's right they look

599
00:20:33,520 --> 00:20:35,760
about how people make decisions

600
00:20:35,760 --> 00:20:38,159
uh they look about why people

601
00:20:38,159 --> 00:20:38,960
will

602
00:20:38,960 --> 00:20:41,120
make mistakes and how we learn from

603
00:20:41,120 --> 00:20:42,720
those near misses and incidents that

604
00:20:42,720 --> 00:20:44,720
occurred but more importantly how we

605
00:20:44,720 --> 00:20:47,120
design systems around users

606
00:20:47,120 --> 00:20:49,600
and i don't just mean end users i mean

607
00:20:49,600 --> 00:20:52,320
us as cyber security users

608
00:20:52,320 --> 00:20:53,760
if you've got firewalls that are too

609
00:20:53,760 --> 00:20:56,240
complex to configure if you're working

610
00:20:56,240 --> 00:20:59,039
now with 20 different security tools and

611
00:20:59,039 --> 00:21:00,400
expect them all to be configured

612
00:21:00,400 --> 00:21:03,039
absolutely perfectly otherwise you get

613
00:21:03,039 --> 00:21:04,240
owned

614
00:21:04,240 --> 00:21:06,159
you need to think about systems design

615
00:21:06,159 --> 00:21:07,039
and go back to some of those

616
00:21:07,039 --> 00:21:08,559
fundamentals the first thing i would say

617
00:21:08,559 --> 00:21:10,640
is please consider cyber security as

618
00:21:10,640 --> 00:21:12,640
multidisciplinary it's not just

619
00:21:12,640 --> 00:21:14,880
technical even if it's quite

620
00:21:14,880 --> 00:21:17,360
predominantly technical and certainly

621
00:21:17,360 --> 00:21:20,640
human-centric sits at the heart of that

622
00:21:20,640 --> 00:21:23,039
the second thing i would say is cyber

623
00:21:23,039 --> 00:21:25,679
security is still maturing as a

624
00:21:25,679 --> 00:21:26,880
profession

625
00:21:26,880 --> 00:21:28,080
so

626
00:21:28,080 --> 00:21:30,000
we need to be able to talk amongst

627
00:21:30,000 --> 00:21:33,039
ourselves on a similar plane about

628
00:21:33,039 --> 00:21:36,320
how we are as an industry what is a

629
00:21:36,320 --> 00:21:38,320
junior pen tester a pen tester and a

630
00:21:38,320 --> 00:21:40,080
senior pen tester well how do we

631
00:21:40,080 --> 00:21:42,000
standardize that because depending on

632
00:21:42,000 --> 00:21:43,840
where you talk about could be very

633
00:21:43,840 --> 00:21:45,200
different

634
00:21:45,200 --> 00:21:47,760
and how we all behave

635
00:21:47,760 --> 00:21:49,760
in terms of whether an incident occurs

636
00:21:49,760 --> 00:21:50,559
or

637
00:21:50,559 --> 00:21:52,559
if something happens you get 10

638
00:21:52,559 --> 00:21:54,640
different ideas about how to solve it

639
00:21:54,640 --> 00:21:56,159
and that's confusing for people who are

640
00:21:56,159 --> 00:21:58,559
in the industry and even experts i have

641
00:21:58,559 --> 00:22:00,400
absolutely no idea how businesses would

642
00:22:00,400 --> 00:22:02,240
feel if they get approached by

643
00:22:02,240 --> 00:22:03,760
five different security professionals

644
00:22:03,760 --> 00:22:06,159
with 10 different ideas so that idea of

645
00:22:06,159 --> 00:22:07,600
us being a profession being slightly

646
00:22:07,600 --> 00:22:08,880
more mature would definitely be the

647
00:22:08,880 --> 00:22:10,400
second thing

648
00:22:10,400 --> 00:22:11,760
governments need to do and the uk

649
00:22:11,760 --> 00:22:13,120
government actually

650
00:22:13,120 --> 00:22:14,080
um

651
00:22:14,080 --> 00:22:16,000
is already working on something very

652
00:22:16,000 --> 00:22:18,400
similar to that by establishing a set of

653
00:22:18,400 --> 00:22:21,120
norms and a way of working with

654
00:22:21,120 --> 00:22:23,200
industry skills frameworks to try and

655
00:22:23,200 --> 00:22:25,039
address that so other governments

656
00:22:25,039 --> 00:22:26,320
definitely should look at what the uk

657
00:22:26,320 --> 00:22:28,159
government's doing with the uk national

658
00:22:28,159 --> 00:22:30,400
subsecurity center

659
00:22:30,400 --> 00:22:31,360
um

660
00:22:31,360 --> 00:22:33,039
the obvious one i think for the third

661
00:22:33,039 --> 00:22:35,280
thing will come up is obviously talking

662
00:22:35,280 --> 00:22:39,039
then about certifications

663
00:22:39,039 --> 00:22:41,679
and that that's a double-edged sword um

664
00:22:41,679 --> 00:22:43,440
i know a lot of companies especially for

665
00:22:43,440 --> 00:22:44,720
critical systems and critical

666
00:22:44,720 --> 00:22:47,200
environments are being asked to certify

667
00:22:47,200 --> 00:22:49,039
their cybersecurity products

668
00:22:49,039 --> 00:22:50,880
but equally i go back to our world

669
00:22:50,880 --> 00:22:53,039
changes every six months so can that

670
00:22:53,039 --> 00:22:55,200
certification actually lead to

671
00:22:55,200 --> 00:22:57,600
better technologies um

672
00:22:57,600 --> 00:23:00,000
i'm not i'm not coming down either way

673
00:23:00,000 --> 00:23:02,640
on that argument but what i will say is

674
00:23:02,640 --> 00:23:04,799
we need to do more

675
00:23:04,799 --> 00:23:06,559
on software development especially

676
00:23:06,559 --> 00:23:08,159
critical software development and

677
00:23:08,159 --> 00:23:09,760
whether it's certified or not for me is

678
00:23:09,760 --> 00:23:12,159
still a question mark but what cannot be

679
00:23:12,159 --> 00:23:14,240
allowed to continue to happen

680
00:23:14,240 --> 00:23:16,000
is a vulnerability that's found in a

681
00:23:16,000 --> 00:23:18,480
piece of software sort of over here has

682
00:23:18,480 --> 00:23:22,240
a huge raging absolutely massive scale

683
00:23:22,240 --> 00:23:24,799
consequence for thousands of businesses

684
00:23:24,799 --> 00:23:27,280
if they don't patch within 24 hours that

685
00:23:27,280 --> 00:23:29,280
is a completely wrong and illogical

686
00:23:29,280 --> 00:23:31,600
model and it's not sustainable for us as

687
00:23:31,600 --> 00:23:32,880
an industry

688
00:23:32,880 --> 00:23:34,559
i don't have the answer to that but i

689
00:23:34,559 --> 00:23:36,480
would definitely encourage research

690
00:23:36,480 --> 00:23:38,159
groups governments who are launching

691
00:23:38,159 --> 00:23:39,919
research groups to look at that almost

692
00:23:39,919 --> 00:23:41,120
inequity

693
00:23:41,120 --> 00:23:43,600
between what is a software development

694
00:23:43,600 --> 00:23:46,000
issue and that then turns out to be well

695
00:23:46,000 --> 00:23:47,679
it has to be fixed over here by all the

696
00:23:47,679 --> 00:23:48,799
companies and

697
00:23:48,799 --> 00:23:50,000
i think for me that's something that has

698
00:23:50,000 --> 00:23:51,919
to has to be looked at

699
00:23:51,919 --> 00:23:53,279
and that links back to vulnerability

700
00:23:53,279 --> 00:23:54,880
vulnerability standards come come as

701
00:23:54,880 --> 00:23:56,240
part of that as well

702
00:23:56,240 --> 00:23:58,240
so there's probably quite a lot in there

703
00:23:58,240 --> 00:23:59,679
for governments to look at but that's

704
00:23:59,679 --> 00:24:01,679
certainly where i would uh would put my

705
00:24:01,679 --> 00:24:03,440
uh my thoughts

706
00:24:03,440 --> 00:24:06,400
thank you so much dr kevin jones

707
00:24:06,400 --> 00:24:08,480
the chief information security officer

708
00:24:08,480 --> 00:24:10,799
and chief digital officer from airbus

709
00:24:10,799 --> 00:24:12,640
group thank you for your time thank you

710
00:24:12,640 --> 00:24:14,799
for that short insight i think we had

711
00:24:14,799 --> 00:24:16,840
some very valuable

712
00:24:16,840 --> 00:24:18,640
uh

713
00:24:18,640 --> 00:24:20,960
insights from from from such a complex

714
00:24:20,960 --> 00:24:24,320
and global company like like airbus um i

715
00:24:24,320 --> 00:24:26,320
thank you so much for your time

716
00:24:26,320 --> 00:24:27,679
to speak here at the munich cyber

717
00:24:27,679 --> 00:24:30,400
security conference 2022

718
00:24:30,400 --> 00:24:32,720
at the talking heads series

719
00:24:32,720 --> 00:24:35,200
and uh offering your perspectives on

720
00:24:35,200 --> 00:24:36,720
information on cyber security thank you

721
00:24:36,720 --> 00:24:38,960
so much kevin it was a pleasure talking

722
00:24:38,960 --> 00:24:41,360
to you and i'll see you for the next

723
00:24:41,360 --> 00:24:42,960
edition then hopefully again in person

724
00:24:42,960 --> 00:24:44,799
thank you so much have a nice afternoon

725
00:24:44,799 --> 00:24:46,960
have

