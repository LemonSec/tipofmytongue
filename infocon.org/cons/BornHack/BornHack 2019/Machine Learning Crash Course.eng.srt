1
00:00:27,110 --> 00:00:31,590
so this is the third tour of the day and

2
00:00:30,029 --> 00:00:35,940
I'm not even gonna try pronouncing your

3
00:00:31,590 --> 00:00:58,410
name so will you please give mr. J of

4
00:00:35,940 --> 00:01:05,339
its run of applause oh can you guys give

5
00:00:58,410 --> 00:01:05,820
me now it's it's very loud sorry it's

6
00:01:05,339 --> 00:01:09,720
okay

7
00:01:05,820 --> 00:01:12,538
Oh No well okay this is gonna help a lot

8
00:01:09,720 --> 00:01:15,030
cuz I usually speak very quietly so I

9
00:01:12,539 --> 00:01:21,630
love the fact that this is here maybe

10
00:01:15,030 --> 00:01:25,710
even I made too much okay okay

11
00:01:21,630 --> 00:01:28,170
better okay good thank you very much and

12
00:01:25,710 --> 00:01:31,169
thank you all for having me yes my name

13
00:01:28,170 --> 00:01:33,299
is not easy to pronounce its motto here

14
00:01:31,170 --> 00:01:35,520
average and today I will be talking to

15
00:01:33,299 --> 00:01:37,799
you about machine learning so without

16
00:01:35,520 --> 00:01:40,590
further ado first I would like to

17
00:01:37,799 --> 00:01:42,780
explain why I'm even giving this talk I

18
00:01:40,590 --> 00:01:45,240
think machine learning is a field that

19
00:01:42,780 --> 00:01:47,189
is still in certain ways in its infancy

20
00:01:45,240 --> 00:01:50,429
and I think it needs people who have

21
00:01:47,189 --> 00:01:53,460
expertise and other areas both

22
00:01:50,430 --> 00:01:55,530
engineering and other so I'm doing this

23
00:01:53,460 --> 00:01:57,539
presentation in order to make it much

24
00:01:55,530 --> 00:02:00,030
easier for you guys with your expertise

25
00:01:57,540 --> 00:02:02,189
in your fields to contribute to the

26
00:02:00,030 --> 00:02:04,229
field of machine learning and even

27
00:02:02,189 --> 00:02:05,729
though the presentation is just a small

28
00:02:04,229 --> 00:02:07,470
part of that there's also a larger

29
00:02:05,729 --> 00:02:09,419
project which I will point you to if you

30
00:02:07,470 --> 00:02:11,609
ever want to seriously get into the

31
00:02:09,419 --> 00:02:14,458
field get all the resources tools and

32
00:02:11,610 --> 00:02:16,560
courses and how to do that so what we're

33
00:02:14,459 --> 00:02:18,570
going to be doing today is first I'm

34
00:02:16,560 --> 00:02:21,030
gonna talk about how the machine

35
00:02:18,570 --> 00:02:23,100
learning actually happens I want to give

36
00:02:21,030 --> 00:02:25,230
you the basic idea of how machines can

37
00:02:23,100 --> 00:02:27,370
even learn and there's gonna be a bit of

38
00:02:25,230 --> 00:02:29,738
linear algebra there

39
00:02:27,370 --> 00:02:31,660
I hope that's okay this tuck is meant to

40
00:02:29,739 --> 00:02:33,970
be for anyone even if you don't have

41
00:02:31,660 --> 00:02:37,780
experience in programming or engineering

42
00:02:33,970 --> 00:02:39,400
or mathematics so if you do bear with me

43
00:02:37,780 --> 00:02:41,860
I'll feel free to correct me if I get

44
00:02:39,400 --> 00:02:43,780
something wrong but we have to build

45
00:02:41,860 --> 00:02:45,459
that foundation first then we're going

46
00:02:43,780 --> 00:02:48,730
to jump from the presentation into a

47
00:02:45,459 --> 00:02:52,629
repeater lab where I will show you in

48
00:02:48,730 --> 00:02:55,959
code how we achieve this thing that you

49
00:02:52,629 --> 00:02:59,140
probably you've seen somewhere where we

50
00:02:55,959 --> 00:03:01,720
take a picture and we take the style of

51
00:02:59,140 --> 00:03:03,458
a painter and we change that picture so

52
00:03:01,720 --> 00:03:06,549
that it looks like van Gogh painted it

53
00:03:03,459 --> 00:03:08,680
okay and then if we have time we're

54
00:03:06,549 --> 00:03:10,390
gonna do a brief overview of other

55
00:03:08,680 --> 00:03:11,980
branches of machine learning so that you

56
00:03:10,390 --> 00:03:13,660
know what else is in the field that

57
00:03:11,980 --> 00:03:15,310
might interest you and then I will

58
00:03:13,660 --> 00:03:16,510
provide you the resources for actually

59
00:03:15,310 --> 00:03:18,220
getting into machine learning like

60
00:03:16,510 --> 00:03:19,599
dipping your toe and tracking it is

61
00:03:18,220 --> 00:03:23,489
something you want to do and then I

62
00:03:19,599 --> 00:03:25,720
understand there's gonna be a Q&A okay

63
00:03:23,489 --> 00:03:28,209
so guys like I said this project is a

64
00:03:25,720 --> 00:03:30,340
bit bigger the thing I really want you

65
00:03:28,209 --> 00:03:32,889
to check out is this repository on

66
00:03:30,340 --> 00:03:35,350
github you can see here examples of this

67
00:03:32,889 --> 00:03:37,299
style transfer that I mentioned you're

68
00:03:35,350 --> 00:03:39,130
gonna find both a trip tour notebook and

69
00:03:37,299 --> 00:03:41,170
Python code for running it on your own

70
00:03:39,130 --> 00:03:43,299
images so you can just experiment with

71
00:03:41,170 --> 00:03:45,099
it play with it if that's your way but

72
00:03:43,299 --> 00:03:47,109
you'll also find many other resources

73
00:03:45,099 --> 00:03:51,130
there and don't worry about writing this

74
00:03:47,109 --> 00:03:54,430
down now if you remember my imp renowned

75
00:03:51,130 --> 00:03:56,980
civil name you can just find it on

76
00:03:54,430 --> 00:03:58,780
github this way or you can write it down

77
00:03:56,980 --> 00:04:02,768
when we do the Q&A because this slide

78
00:03:58,780 --> 00:04:05,440
will be open okay so first thing that we

79
00:04:02,769 --> 00:04:06,940
need to figure out is how machines

80
00:04:05,440 --> 00:04:09,579
represent concepts that are actually

81
00:04:06,940 --> 00:04:12,040
useful to us for those of you who are

82
00:04:09,579 --> 00:04:13,599
familiar with this bear with me the

83
00:04:12,040 --> 00:04:15,638
learning curve will be steep at a

84
00:04:13,599 --> 00:04:17,048
certain point so essentially first we

85
00:04:15,639 --> 00:04:20,019
have a scalar which is just a single

86
00:04:17,048 --> 00:04:22,388
numerical value but even this you know

87
00:04:20,019 --> 00:04:24,849
extremely simple thing can represent a

88
00:04:22,389 --> 00:04:27,880
lot of useful things technically if it's

89
00:04:24,849 --> 00:04:30,849
an eight it could it could be obviously

90
00:04:27,880 --> 00:04:34,030
values on a scale of 0 to 9 or it could

91
00:04:30,849 --> 00:04:37,210
be which of the digits am i holding up

92
00:04:34,030 --> 00:04:39,340
on a picture technically that could

93
00:04:37,210 --> 00:04:40,270
represent that then there's a vector

94
00:04:39,340 --> 00:04:44,888
which

95
00:04:40,270 --> 00:04:48,669
to be for example three users rating a

96
00:04:44,889 --> 00:04:50,710
movie or it could be one movie on three

97
00:04:48,669 --> 00:04:53,229
scales for example the first one could

98
00:04:50,710 --> 00:04:54,758
be how much horror is in that movie the

99
00:04:53,229 --> 00:04:56,919
second one could be how much comedy is

100
00:04:54,759 --> 00:04:59,169
in that movie the third one how much

101
00:04:56,919 --> 00:05:00,758
romantic elements are in it I'm just

102
00:04:59,169 --> 00:05:02,229
trying to kinda show you that there's

103
00:05:00,759 --> 00:05:05,050
great flexibility in what we can

104
00:05:02,229 --> 00:05:07,990
represent with with these simple data

105
00:05:05,050 --> 00:05:10,150
structures then there's a matrix which

106
00:05:07,990 --> 00:05:12,069
is Ray just a vector of vectors this

107
00:05:10,150 --> 00:05:15,030
could represent three different users

108
00:05:12,069 --> 00:05:17,259
ratings of three different movies

109
00:05:15,030 --> 00:05:20,198
because this is a bit clunky

110
00:05:17,259 --> 00:05:20,979
we actually usually notation wise show

111
00:05:20,199 --> 00:05:25,409
it like this

112
00:05:20,979 --> 00:05:28,630
and this can also be a grayscale image

113
00:05:25,409 --> 00:05:32,080
technically again this flexibility comes

114
00:05:28,630 --> 00:05:33,789
to mind then there are tensors tensors

115
00:05:32,080 --> 00:05:36,430
have a pretty specific mathematical

116
00:05:33,789 --> 00:05:38,800
definition but that's a bit too nuanced

117
00:05:36,430 --> 00:05:41,440
first right now so think of them just

118
00:05:38,800 --> 00:05:43,389
right now as a vector of matrices

119
00:05:41,440 --> 00:05:46,870
technically scalars vectors and matrices

120
00:05:43,389 --> 00:05:48,430
are all tensors so from now on when we

121
00:05:46,870 --> 00:05:51,099
talk about this we're gonna be talking

122
00:05:48,430 --> 00:05:53,560
about tensors and this is also where the

123
00:05:51,099 --> 00:05:58,270
popular Google library tensor flow takes

124
00:05:53,560 --> 00:06:00,580
its name from you can also imagine that

125
00:05:58,270 --> 00:06:03,219
tensor that we just saw is essentially a

126
00:06:00,580 --> 00:06:06,340
cube and if we can imagine it as a cube

127
00:06:03,219 --> 00:06:08,560
we can imagine it as a 3d shape so it

128
00:06:06,340 --> 00:06:10,679
can be the same image in three different

129
00:06:08,560 --> 00:06:13,599
points in time or it can be the image

130
00:06:10,680 --> 00:06:15,789
and it's mood and its motion there's

131
00:06:13,599 --> 00:06:20,469
just this like great flexibility in what

132
00:06:15,789 --> 00:06:22,870
we can represent with these tensors okay

133
00:06:20,469 --> 00:06:25,680
but that's obviously not enough we need

134
00:06:22,870 --> 00:06:28,000
to transform them in some way

135
00:06:25,680 --> 00:06:29,469
mathematically what we usually do you do

136
00:06:28,000 --> 00:06:31,900
if these tensors is matrix

137
00:06:29,469 --> 00:06:34,000
multiplication also called their dot

138
00:06:31,900 --> 00:06:36,250
product so here we have a very simple

139
00:06:34,000 --> 00:06:39,490
matrix multiplication example two

140
00:06:36,250 --> 00:06:42,009
tensors both of them two by two we could

141
00:06:39,490 --> 00:06:44,199
be tempted to multiply them just element

142
00:06:42,009 --> 00:06:46,180
wise you know that one in the top left

143
00:06:44,199 --> 00:06:48,009
corner multiplied by that one in the top

144
00:06:46,180 --> 00:06:50,529
left corner of the other matrix and

145
00:06:48,009 --> 00:06:52,360
that's the top left corner of the final

146
00:06:50,529 --> 00:06:53,490
one it's actually a little bit more

147
00:06:52,360 --> 00:06:56,370
involved

148
00:06:53,490 --> 00:06:59,640
it's technically multiplying the

149
00:06:56,370 --> 00:07:02,040
internal row and column vectors it only

150
00:06:59,640 --> 00:07:03,719
to if you don't follow it's okay

151
00:07:02,040 --> 00:07:05,880
the reason why I'm showing you this is

152
00:07:03,720 --> 00:07:07,980
just because I had to show you that this

153
00:07:05,880 --> 00:07:08,909
operation which is very key to what

154
00:07:07,980 --> 00:07:11,370
we're going to be doing in machine

155
00:07:08,910 --> 00:07:13,770
learning is actually a more deeply

156
00:07:11,370 --> 00:07:16,580
intertwined way of combining combining

157
00:07:13,770 --> 00:07:22,260
tensors and we do the same thing for

158
00:07:16,580 --> 00:07:24,719
every single cell now you've probably

159
00:07:22,260 --> 00:07:27,719
heard the term hello you've probably

160
00:07:24,720 --> 00:07:29,340
heard the term neural networks and since

161
00:07:27,720 --> 00:07:31,260
I'm trying to demystify a lot of those

162
00:07:29,340 --> 00:07:34,049
terms and neural network is really just

163
00:07:31,260 --> 00:07:37,050
a bunch of operations like the matrix

164
00:07:34,050 --> 00:07:40,110
multiplication stuck together with some

165
00:07:37,050 --> 00:07:42,600
bonus stuff there's changing the way it

166
00:07:40,110 --> 00:07:44,640
behaves so I now have to talk about

167
00:07:42,600 --> 00:07:46,860
neural networks a little bit this is a

168
00:07:44,640 --> 00:07:50,760
very simple diagram of a neural network

169
00:07:46,860 --> 00:07:53,130
okay everyone still with me so far okay

170
00:07:50,760 --> 00:07:57,690
you're nothing that's good so the people

171
00:07:53,130 --> 00:07:59,790
at home they're nodding so right this is

172
00:07:57,690 --> 00:08:02,340
a very simple example of what a neural

173
00:07:59,790 --> 00:08:04,650
network can look like we have input and

174
00:08:02,340 --> 00:08:07,080
this is literally just foreign numbers

175
00:08:04,650 --> 00:08:10,049
here so you could imagine this input as

176
00:08:07,080 --> 00:08:13,050
being in that topmost cell a person's

177
00:08:10,050 --> 00:08:15,780
age the second one could be their salary

178
00:08:13,050 --> 00:08:18,930
and then their marital status and so on

179
00:08:15,780 --> 00:08:21,570
things we can represent with numbers the

180
00:08:18,930 --> 00:08:23,940
first layer of the neural network which

181
00:08:21,570 --> 00:08:27,690
does the matrix multiplication is

182
00:08:23,940 --> 00:08:31,080
actually both those black lines and the

183
00:08:27,690 --> 00:08:32,730
purple dots that come after them the

184
00:08:31,080 --> 00:08:35,370
black lines is the actual matrix

185
00:08:32,730 --> 00:08:37,830
multiplication the dots are the output

186
00:08:35,370 --> 00:08:40,020
of that operation so one important thing

187
00:08:37,830 --> 00:08:42,240
to remember net layers in a neural

188
00:08:40,020 --> 00:08:43,829
network have both an operation and an

189
00:08:42,240 --> 00:08:46,740
output and this is going to be crucial

190
00:08:43,830 --> 00:08:48,240
when we do neural cell transfer so yeah

191
00:08:46,740 --> 00:08:50,490
we do this a couple times

192
00:08:48,240 --> 00:08:52,260
we know that because of how matrix

193
00:08:50,490 --> 00:08:54,300
multiplication works it's no longer

194
00:08:52,260 --> 00:08:56,160
commutative so order matters and there

195
00:08:54,300 --> 00:08:58,020
are certain limitations on the shape but

196
00:08:56,160 --> 00:09:00,540
there's our own nuances and at the end

197
00:08:58,020 --> 00:09:02,760
one more dot product

198
00:09:00,540 --> 00:09:05,730
one more multiplication and we get the

199
00:09:02,760 --> 00:09:06,990
output and the output could be three

200
00:09:05,730 --> 00:09:09,540
zeroes and as

201
00:09:06,990 --> 00:09:12,149
one and depending on where the one is

202
00:09:09,540 --> 00:09:15,510
that encodes something for example

203
00:09:12,149 --> 00:09:21,149
should this person be granted this

204
00:09:15,510 --> 00:09:23,010
insurance rate or not I promise this is

205
00:09:21,149 --> 00:09:24,209
the last deeper details we need to

206
00:09:23,010 --> 00:09:26,130
understand

207
00:09:24,209 --> 00:09:30,000
other than the matrix multiplication

208
00:09:26,130 --> 00:09:34,140
which we do here and those black is in

209
00:09:30,000 --> 00:09:37,080
this black network this is the matrix

210
00:09:34,140 --> 00:09:39,959
that is the input the matrix by which we

211
00:09:37,080 --> 00:09:43,050
multiply it is called the weights or

212
00:09:39,959 --> 00:09:44,069
parameters of that layer and this is

213
00:09:43,050 --> 00:09:46,589
gonna be the thing that we're going to

214
00:09:44,070 --> 00:09:49,020
be changing when we train the network we

215
00:09:46,589 --> 00:09:51,600
also add a bias vector just so that the

216
00:09:49,020 --> 00:09:54,449
function can take any linear shape and

217
00:09:51,600 --> 00:09:57,209
then we add a nonlinear transformation

218
00:09:54,450 --> 00:09:58,950
and we add the nonlinear transformation

219
00:09:57,209 --> 00:10:01,260
for those of you know like a sigmoid

220
00:09:58,950 --> 00:10:03,600
function or a softmax function because

221
00:10:01,260 --> 00:10:06,450
if we didn't if we just did a series of

222
00:10:03,600 --> 00:10:09,660
melting matrix multiplications we could

223
00:10:06,450 --> 00:10:12,470
only have this model resemble linear

224
00:10:09,660 --> 00:10:16,740
functions and this is really why the

225
00:10:12,470 --> 00:10:18,360
metaphor of neural code on because this

226
00:10:16,740 --> 00:10:20,940
is the single behavior that resembles

227
00:10:18,360 --> 00:10:22,320
how neurons actually work unless the

228
00:10:20,940 --> 00:10:24,750
action potential of the neuron is

229
00:10:22,320 --> 00:10:26,490
reached it if it isn't it doesn't fire

230
00:10:24,750 --> 00:10:29,760
if we cross the threshold it does fire

231
00:10:26,490 --> 00:10:32,760
that's what the only our non-linearity

232
00:10:29,760 --> 00:10:35,970
does okay I know it's a lot to throw at

233
00:10:32,760 --> 00:10:39,270
you this is the output of the chaos

234
00:10:35,970 --> 00:10:41,040
libraries plot model function this is an

235
00:10:39,270 --> 00:10:43,110
actual model that you could use for

236
00:10:41,040 --> 00:10:44,430
certain simple tasks I'm throwing this

237
00:10:43,110 --> 00:10:47,520
to you because I want to show you that

238
00:10:44,430 --> 00:10:49,529
there really isn't that much more to

239
00:10:47,520 --> 00:10:52,500
this other than those stacked

240
00:10:49,529 --> 00:10:55,200
mathematical operations okay so here we

241
00:10:52,500 --> 00:10:57,270
have an input layer on top we have a 2d

242
00:10:55,200 --> 00:10:58,860
convolutional layer which is the last

243
00:10:57,270 --> 00:11:00,959
operation I will have to explain and

244
00:10:58,860 --> 00:11:02,790
then there's max pooling which just

245
00:11:00,959 --> 00:11:04,859
reduces the number of parameters we have

246
00:11:02,790 --> 00:11:07,230
to learn and there's a flatten which

247
00:11:04,860 --> 00:11:08,850
turns a matrix to a vector and then

248
00:11:07,230 --> 00:11:12,510
there's a dense layer which does just

249
00:11:08,850 --> 00:11:16,709
what I just described so there's no

250
00:11:12,510 --> 00:11:17,939
magic technically this is convolutional

251
00:11:16,709 --> 00:11:20,699
layer this is going to be important

252
00:11:17,940 --> 00:11:23,850
because convolutional layers are

253
00:11:20,700 --> 00:11:25,800
doing stuff with images and this simple

254
00:11:23,850 --> 00:11:30,660
animation is supposed to show what it

255
00:11:25,800 --> 00:11:33,839
looks like so the blue dancer on the

256
00:11:30,660 --> 00:11:36,900
bottom is the input the green tensor

257
00:11:33,840 --> 00:11:40,710
above is the output and what the

258
00:11:36,900 --> 00:11:46,020
convolution does is it just works over

259
00:11:40,710 --> 00:11:48,030
the outputs in tiny steps combines the

260
00:11:46,020 --> 00:11:51,660
numbers that it grabs from the input

261
00:11:48,030 --> 00:11:53,839
with the values of the gray filter so

262
00:11:51,660 --> 00:11:57,030
again just two matrices two tensors

263
00:11:53,840 --> 00:12:02,420
combines them together and then outputs

264
00:11:57,030 --> 00:12:05,010
them into the input to be more precise

265
00:12:02,420 --> 00:12:08,130
here we have on the left the input on

266
00:12:05,010 --> 00:12:10,860
the right the output so you walk the

267
00:12:08,130 --> 00:12:12,960
input with this little filter and you

268
00:12:10,860 --> 00:12:15,810
can specify the size of the filter

269
00:12:12,960 --> 00:12:19,400
specify the steps and you combine

270
00:12:15,810 --> 00:12:23,400
essentially all the values around the

271
00:12:19,400 --> 00:12:25,740
little cell which ends up with a new

272
00:12:23,400 --> 00:12:28,620
value in the new image which is the

273
00:12:25,740 --> 00:12:31,650
output of that layer okay so in the

274
00:12:28,620 --> 00:12:33,450
dense layer we were learning what the

275
00:12:31,650 --> 00:12:35,880
parameters what the matrix that we

276
00:12:33,450 --> 00:12:38,960
multiply stuff by is here we're going to

277
00:12:35,880 --> 00:12:41,910
be learning what those numbers are

278
00:12:38,960 --> 00:12:45,480
supposed to be for a useful

279
00:12:41,910 --> 00:12:48,209
representation later on again to like

280
00:12:45,480 --> 00:12:50,700
drive this point hope this is an example

281
00:12:48,210 --> 00:12:51,360
specifically if we use a filter like

282
00:12:50,700 --> 00:12:55,140
this

283
00:12:51,360 --> 00:12:59,280
we've just these values this if we and

284
00:12:55,140 --> 00:13:02,310
we convolve with this filter over the

285
00:12:59,280 --> 00:13:04,500
original image we're gonna get this

286
00:13:02,310 --> 00:13:07,020
output image and this is a sharpen

287
00:13:04,500 --> 00:13:09,630
filter and there's a lot of these simple

288
00:13:07,020 --> 00:13:11,189
filters if the values were different in

289
00:13:09,630 --> 00:13:14,700
this filter they could very easily

290
00:13:11,190 --> 00:13:16,920
recognize edges in an image like this

291
00:13:14,700 --> 00:13:19,620
edges like this diagonal and so on so

292
00:13:16,920 --> 00:13:21,229
forth now what do you think will happen

293
00:13:19,620 --> 00:13:23,070
if we stack a couple of those

294
00:13:21,230 --> 00:13:27,380
convolutional layers on top of each

295
00:13:23,070 --> 00:13:27,380
other does anyone have a guess

296
00:13:27,610 --> 00:13:36,890
well if we can learn about edges or a

297
00:13:33,140 --> 00:13:40,580
sharpened image and the first layer then

298
00:13:36,890 --> 00:13:43,640
we when we combine them we start with

299
00:13:40,580 --> 00:13:45,620
edges this is like very early

300
00:13:43,640 --> 00:13:49,280
convolutional layer in the model we

301
00:13:45,620 --> 00:13:53,810
passed the image in it works over the

302
00:13:49,280 --> 00:13:55,400
image it learns and I will explain how

303
00:13:53,810 --> 00:13:57,739
it learns in the moment but essentially

304
00:13:55,400 --> 00:14:00,439
it learns these simple patterns like

305
00:13:57,740 --> 00:14:03,160
edges and the next convolutional layers

306
00:14:00,440 --> 00:14:05,690
it will learn combinations of those

307
00:14:03,160 --> 00:14:07,250
because these are what I'm presenting

308
00:14:05,690 --> 00:14:08,750
here are outputs of those :

309
00:14:07,250 --> 00:14:12,310
convolutional layer that would excite

310
00:14:08,750 --> 00:14:14,990
them the most then we get textures a

311
00:14:12,310 --> 00:14:17,900
couple of layers after that we get

312
00:14:14,990 --> 00:14:20,180
patterns you can see here I think almost

313
00:14:17,900 --> 00:14:22,910
like stubs from from concerts and such

314
00:14:20,180 --> 00:14:25,310
then you get parts you see something

315
00:14:22,910 --> 00:14:27,530
that looks like an interface and top

316
00:14:25,310 --> 00:14:29,750
left of the second panel there something

317
00:14:27,530 --> 00:14:33,380
that looks like dogs ears maybe denim

318
00:14:29,750 --> 00:14:35,050
and then finally we get to a point where

319
00:14:33,380 --> 00:14:39,700
the convolutional layers stuck together

320
00:14:35,050 --> 00:14:42,229
learn actual objects so architectural or

321
00:14:39,700 --> 00:14:45,740
architectural stuff here we see

322
00:14:42,230 --> 00:14:49,430
someone's shorts I think eyes insects

323
00:14:45,740 --> 00:14:52,370
and actually heads of dogs it looks

324
00:14:49,430 --> 00:14:54,290
weird because they don't know where

325
00:14:52,370 --> 00:14:56,360
something might be so they kind of look

326
00:14:54,290 --> 00:14:58,640
for the thing everywhere in the image

327
00:14:56,360 --> 00:15:00,920
but this is one thing that I need you to

328
00:14:58,640 --> 00:15:02,000
remember for the neural style transfer

329
00:15:00,920 --> 00:15:04,069
to be clear to you

330
00:15:02,000 --> 00:15:06,290
essentially early layers of a

331
00:15:04,070 --> 00:15:08,960
convolutional model simple aspects of

332
00:15:06,290 --> 00:15:14,240
the image later layers things that are

333
00:15:08,960 --> 00:15:17,750
actually in the image okay so yeah now

334
00:15:14,240 --> 00:15:19,190
I've told you kind of what working inner

335
00:15:17,750 --> 00:15:21,500
workings actually are but I haven't told

336
00:15:19,190 --> 00:15:22,780
you how learning actually happens so

337
00:15:21,500 --> 00:15:26,360
let's do that

338
00:15:22,780 --> 00:15:29,420
to simplify let's imagine our network or

339
00:15:26,360 --> 00:15:33,110
our model as just some input some

340
00:15:29,420 --> 00:15:34,939
transformations some output in order for

341
00:15:33,110 --> 00:15:36,800
learning to happen we need to know how

342
00:15:34,940 --> 00:15:39,410
well we are doing for the simplest

343
00:15:36,800 --> 00:15:40,260
possible type of learning so usually we

344
00:15:39,410 --> 00:15:41,969
feed

345
00:15:40,260 --> 00:15:43,950
the network a lot of data where we know

346
00:15:41,970 --> 00:15:47,400
what the target is supposed to be you

347
00:15:43,950 --> 00:15:49,650
know remember those four red dots at the

348
00:15:47,400 --> 00:15:51,810
end that's still just numbers that's

349
00:15:49,650 --> 00:15:53,730
still just a vector and we know what the

350
00:15:51,810 --> 00:15:58,290
target vector is supposed to be so for

351
00:15:53,730 --> 00:16:00,000
example a vector with four elements all

352
00:15:58,290 --> 00:16:02,010
of them zeros except for the last one

353
00:16:00,000 --> 00:16:04,800
which is a 1 and we know that that

354
00:16:02,010 --> 00:16:06,960
encodes for example a dog the last index

355
00:16:04,800 --> 00:16:09,199
encodes a dog if the one was in the

356
00:16:06,960 --> 00:16:13,350
third index it would be a cat second one

357
00:16:09,200 --> 00:16:15,780
parrots first one rat for example and

358
00:16:13,350 --> 00:16:17,520
then we know what the target vector

359
00:16:15,780 --> 00:16:19,650
would have been and it was actually a

360
00:16:17,520 --> 00:16:22,890
picture of it say a cat instead of a dog

361
00:16:19,650 --> 00:16:25,140
instead of a dog and then we can just do

362
00:16:22,890 --> 00:16:27,090
a mean squared error on those vectors

363
00:16:25,140 --> 00:16:28,890
this is obviously a very simple example

364
00:16:27,090 --> 00:16:30,540
but we can say that those vectors are

365
00:16:28,890 --> 00:16:33,530
not the same and we can describe it

366
00:16:30,540 --> 00:16:36,329
mathematically so the only catch is that

367
00:16:33,530 --> 00:16:38,670
this loss function which we'll be trying

368
00:16:36,330 --> 00:16:40,730
to minimize during learning has to be

369
00:16:38,670 --> 00:16:43,260
differentiable which just means that

370
00:16:40,730 --> 00:16:46,410
most of you probably know we just need

371
00:16:43,260 --> 00:16:48,240
to be able to tell what will happen if

372
00:16:46,410 --> 00:16:49,800
we change the parameters a little does

373
00:16:48,240 --> 00:16:53,030
the value of the function go up or down

374
00:16:49,800 --> 00:16:56,780
and this is really the trick to learning

375
00:16:53,030 --> 00:16:58,829
we keep we keep the entire model

376
00:16:56,780 --> 00:17:00,780
differentiable so that we can figure out

377
00:16:58,830 --> 00:17:04,500
if we change its parameters a little

378
00:17:00,780 --> 00:17:06,359
will we get a lower or a higher loss

379
00:17:04,500 --> 00:17:09,720
function and we obviously want our loss

380
00:17:06,359 --> 00:17:14,030
function to be as small as possible are

381
00:17:09,720 --> 00:17:16,940
we on the same page so far ok

382
00:17:14,030 --> 00:17:19,770
so final final bit of the new algebra

383
00:17:16,940 --> 00:17:22,230
back propagation so we know that the

384
00:17:19,770 --> 00:17:25,560
model has to be differentiable how do we

385
00:17:22,230 --> 00:17:26,099
use that I'm gonna just stop it for a

386
00:17:25,560 --> 00:17:32,040
moment

387
00:17:26,099 --> 00:17:35,310
or am i yeah okay this gif is just gonna

388
00:17:32,040 --> 00:17:38,310
keep rolling bottom we have the input

389
00:17:35,310 --> 00:17:41,010
top we have the output it goes through

390
00:17:38,310 --> 00:17:43,590
the entire network in one forward pass

391
00:17:41,010 --> 00:17:45,720
gets to the top calculate the loss

392
00:17:43,590 --> 00:17:49,530
function there and then we begin to

393
00:17:45,720 --> 00:17:50,500
track the derivatives so we check how we

394
00:17:49,530 --> 00:17:52,990
can train

395
00:17:50,500 --> 00:17:55,750
the values of those parameters to make

396
00:17:52,990 --> 00:17:58,540
the loss function go up or down and this

397
00:17:55,750 --> 00:18:00,880
is what we used to then update the

398
00:17:58,540 --> 00:18:04,750
parameters of the network and that's how

399
00:18:00,880 --> 00:18:06,100
learning happens as a tiny bonus I just

400
00:18:04,750 --> 00:18:08,170
also want to tell you what's recurrent

401
00:18:06,100 --> 00:18:10,120
neural networks are you may have heard

402
00:18:08,170 --> 00:18:12,550
about them and just went to again

403
00:18:10,120 --> 00:18:16,239
demystified them a little bit same

404
00:18:12,550 --> 00:18:18,970
function graph of a network recurrent

405
00:18:16,240 --> 00:18:21,220
networks are great at figuring out who

406
00:18:18,970 --> 00:18:23,290
what is happening in a video or in a

407
00:18:21,220 --> 00:18:24,880
larger block of text because they have

408
00:18:23,290 --> 00:18:27,340
some representation of what was

409
00:18:24,880 --> 00:18:29,740
important earlier on so you can see here

410
00:18:27,340 --> 00:18:34,300
the second layer called long short-term

411
00:18:29,740 --> 00:18:36,250
memory some of its output is kept

412
00:18:34,300 --> 00:18:38,980
untransformed until a couple of

413
00:18:36,250 --> 00:18:40,930
transformations later and you can this

414
00:18:38,980 --> 00:18:42,820
way have some information about what was

415
00:18:40,930 --> 00:18:48,550
happening earlier in a video or earlier

416
00:18:42,820 --> 00:18:50,950
in a text and use it later okay

417
00:18:48,550 --> 00:18:53,470
lambda you may be wondering why there's

418
00:18:50,950 --> 00:19:06,010
a duck here and this will become clear

419
00:18:53,470 --> 00:19:06,610
in a minute can you see this problem is

420
00:19:06,010 --> 00:19:12,160
this a bit better

421
00:19:06,610 --> 00:19:14,889
can you see bigger can I do it

422
00:19:12,160 --> 00:19:19,900
fullscreen Chrome yeah let's check that

423
00:19:14,890 --> 00:19:22,860
how did it green button thingy but this

424
00:19:19,900 --> 00:19:28,180
is that right this is the same thing

425
00:19:22,860 --> 00:19:30,070
cool okay so case in my personal

426
00:19:28,180 --> 00:19:32,290
experience the presentation would just

427
00:19:30,070 --> 00:19:34,629
show you a line after line of code or

428
00:19:32,290 --> 00:19:36,490
not that useful you either way have to

429
00:19:34,630 --> 00:19:38,440
be able to follow it you know on your

430
00:19:36,490 --> 00:19:40,570
own at your own time so I won't be

431
00:19:38,440 --> 00:19:42,280
explaining everything but we will see

432
00:19:40,570 --> 00:19:43,510
this specifically to the thing it's

433
00:19:42,280 --> 00:19:47,050
supposed to do and we will see the

434
00:19:43,510 --> 00:19:49,300
output of it how many of you are

435
00:19:47,050 --> 00:19:51,340
familiar with Python could you raise

436
00:19:49,300 --> 00:19:53,440
your hand okay so that's majority of

437
00:19:51,340 --> 00:19:54,939
people good even if you're not that's

438
00:19:53,440 --> 00:19:57,550
okay I will be explaining what we're

439
00:19:54,940 --> 00:19:59,200
actually doing so I am just importing a

440
00:19:57,550 --> 00:20:00,790
couple of libraries I am importing

441
00:19:59,200 --> 00:20:02,980
tensorflow which is what it's going to

442
00:20:00,790 --> 00:20:03,800
be doing the heavy lifting I'm importing

443
00:20:02,980 --> 00:20:06,680
Chara's

444
00:20:03,800 --> 00:20:07,520
just a high-level API for tensorflow so

445
00:20:06,680 --> 00:20:08,900
if you're interested you're probably

446
00:20:07,520 --> 00:20:11,060
going to be doing things in curse first

447
00:20:08,900 --> 00:20:15,650
I'm just a library for manipulating

448
00:20:11,060 --> 00:20:18,260
images and a library for operations on

449
00:20:15,650 --> 00:20:22,070
tensors on linear algebra stuff and

450
00:20:18,260 --> 00:20:23,390
numbers I am grabbing some functions

451
00:20:22,070 --> 00:20:26,540
simple functions that I wrote for

452
00:20:23,390 --> 00:20:27,890
loading images this is something that I

453
00:20:26,540 --> 00:20:30,350
would like to see more of and machine

454
00:20:27,890 --> 00:20:31,430
learning papers confirm in the notebook

455
00:20:30,350 --> 00:20:33,379
that you have all the right requirements

456
00:20:31,430 --> 00:20:35,270
and we're going to be using Python 3.7

457
00:20:33,380 --> 00:20:37,130
and these are all the libraries that

458
00:20:35,270 --> 00:20:40,450
we're gonna need underneath the hood and

459
00:20:37,130 --> 00:20:46,190
the virtual environment for this working

460
00:20:40,450 --> 00:20:48,500
okay so I was originally gonna have

461
00:20:46,190 --> 00:20:50,870
asked to which images were gonna mash

462
00:20:48,500 --> 00:20:52,520
together and I'm gonna be here after the

463
00:20:50,870 --> 00:20:54,020
presentation for a couple of hours so if

464
00:20:52,520 --> 00:20:55,580
you're interested we can do that but

465
00:20:54,020 --> 00:21:01,610
just for this example I'm gonna use

466
00:20:55,580 --> 00:21:04,460
these two images okay so this is a

467
00:21:01,610 --> 00:21:06,229
majestic horse duck on the Left that

468
00:21:04,460 --> 00:21:11,090
some person with great photoshop skills

469
00:21:06,230 --> 00:21:16,760
has created and on the right drinking is

470
00:21:11,090 --> 00:21:19,490
trickier this and on the right you can

471
00:21:16,760 --> 00:21:21,440
see an image in this style of Salvador

472
00:21:19,490 --> 00:21:23,780
Dali not actually created by Salvador

473
00:21:21,440 --> 00:21:24,980
Dali and what we're going to be doing is

474
00:21:23,780 --> 00:21:27,649
we're going to be trying to make this

475
00:21:24,980 --> 00:21:31,910
image on the on your own map on your

476
00:21:27,650 --> 00:21:35,750
left take the style of the Salvador Dali

477
00:21:31,910 --> 00:21:38,360
image and you can see there is a style

478
00:21:35,750 --> 00:21:40,400
to Salvador Dali it's very highly

479
00:21:38,360 --> 00:21:43,639
saturated there's great contrast between

480
00:21:40,400 --> 00:21:46,070
colors there's a dress between objects

481
00:21:43,640 --> 00:21:48,980
but not a dress like the gradients are

482
00:21:46,070 --> 00:21:54,040
very smooth in this image we're going to

483
00:21:48,980 --> 00:21:56,870
be loading up the weights of a specific

484
00:21:54,040 --> 00:21:59,510
model that was trained to recognize what

485
00:21:56,870 --> 00:22:01,129
an image is what specific images are

486
00:21:59,510 --> 00:22:03,500
there is a competition in machine

487
00:22:01,130 --> 00:22:06,310
learning called image net and this is a

488
00:22:03,500 --> 00:22:08,840
model that won it a couple of years ago

489
00:22:06,310 --> 00:22:11,419
it's often used because it's very simple

490
00:22:08,840 --> 00:22:11,959
we just need it because when you think

491
00:22:11,420 --> 00:22:13,970
about it

492
00:22:11,960 --> 00:22:16,140
remember those panels I showed you of

493
00:22:13,970 --> 00:22:19,080
edges and patterns and an object

494
00:22:16,140 --> 00:22:21,690
that knowledge is encoded in that model

495
00:22:19,080 --> 00:22:25,830
now and we can actually use it in a

496
00:22:21,690 --> 00:22:28,890
clever way we're going to be generating

497
00:22:25,830 --> 00:22:31,770
an image here are some parameters for

498
00:22:28,890 --> 00:22:33,060
learning often in practice when you do

499
00:22:31,770 --> 00:22:35,340
machine learning you have to fiddle with

500
00:22:33,060 --> 00:22:37,500
certain parameters for learning such as

501
00:22:35,340 --> 00:22:41,340
how many times I wanted to mull over the

502
00:22:37,500 --> 00:22:44,010
data in our context also how much do we

503
00:22:41,340 --> 00:22:46,379
care about the contents of the image and

504
00:22:44,010 --> 00:22:48,930
how much do we care about the style of

505
00:22:46,380 --> 00:22:50,100
the image and these are going to be used

506
00:22:48,930 --> 00:22:52,590
you can probably figure it out

507
00:22:50,100 --> 00:22:54,810
when we were going to multiply them by

508
00:22:52,590 --> 00:22:57,080
different types of losses in a moment

509
00:22:54,810 --> 00:22:59,879
okay and this is really the gist of it

510
00:22:57,080 --> 00:23:03,120
so you remember the image that I showed

511
00:22:59,880 --> 00:23:04,920
you with what the network learns in the

512
00:23:03,120 --> 00:23:07,169
early layers and what it learns and the

513
00:23:04,920 --> 00:23:11,270
later layers right when you think about

514
00:23:07,170 --> 00:23:14,340
it those edges and those simple patterns

515
00:23:11,270 --> 00:23:16,500
they are kind of like the style of an

516
00:23:14,340 --> 00:23:18,810
image a little bit for example when you

517
00:23:16,500 --> 00:23:21,570
think about paintings by Kandinsky

518
00:23:18,810 --> 00:23:25,590
there's like a very specific brushstroke

519
00:23:21,570 --> 00:23:29,340
there so what we're going to be doing is

520
00:23:25,590 --> 00:23:32,760
we are going to be considering the

521
00:23:29,340 --> 00:23:35,760
output of this pre-trained model from

522
00:23:32,760 --> 00:23:38,420
the early convolutional layers to be

523
00:23:35,760 --> 00:23:40,890
essentially the style of an image and

524
00:23:38,420 --> 00:23:42,930
we're going to be considering the output

525
00:23:40,890 --> 00:23:45,270
of this model from one of the later

526
00:23:42,930 --> 00:23:49,080
layers where we solve them learning

527
00:23:45,270 --> 00:23:51,360
things like objects to be content right

528
00:23:49,080 --> 00:23:55,310
this is really the one trick we have to

529
00:23:51,360 --> 00:23:57,389
wrap your mind around you know we I

530
00:23:55,310 --> 00:23:59,310
hesitate to go back to it but I feel

531
00:23:57,390 --> 00:24:05,610
like you're no longer with me a little

532
00:23:59,310 --> 00:24:07,230
bit are you you are okay good sorry so

533
00:24:05,610 --> 00:24:10,679
yeah we're just gonna be grabbing one of

534
00:24:07,230 --> 00:24:13,260
the later layers for content and we're

535
00:24:10,680 --> 00:24:15,240
going to be grabbing the output of two

536
00:24:13,260 --> 00:24:16,890
early convolutional layers and one of

537
00:24:15,240 --> 00:24:18,900
the later ones because that seemed to

538
00:24:16,890 --> 00:24:20,520
work better and yeah and we're just

539
00:24:18,900 --> 00:24:22,770
going to be treating that as as content

540
00:24:20,520 --> 00:24:24,800
runs down there's a couple of functions

541
00:24:22,770 --> 00:24:27,660
we need to go through very quickly

542
00:24:24,800 --> 00:24:29,000
getting feature representations is just

543
00:24:27,660 --> 00:24:33,560
about

544
00:24:29,000 --> 00:24:35,870
figuring out what what the content and

545
00:24:33,560 --> 00:24:37,730
the style of a image that we pass to

546
00:24:35,870 --> 00:24:40,280
this function actually where so we just

547
00:24:37,730 --> 00:24:42,020
load up the content image we load up the

548
00:24:40,280 --> 00:24:44,870
style image we pass them through the

549
00:24:42,020 --> 00:24:49,639
model and then we grab the outputs of

550
00:24:44,870 --> 00:24:51,260
specific layers since this is machine

551
00:24:49,640 --> 00:24:53,450
learning we have to specify a loss

552
00:24:51,260 --> 00:24:55,520
function and we're gonna have two of

553
00:24:53,450 --> 00:24:57,680
them because we want to do two things we

554
00:24:55,520 --> 00:25:00,860
want the model to have same content and

555
00:24:57,680 --> 00:25:05,630
same style so how do we do how do we do

556
00:25:00,860 --> 00:25:08,000
content loss well we have the outputs of

557
00:25:05,630 --> 00:25:10,490
the model for the content convolutional

558
00:25:08,000 --> 00:25:12,230
layers for both the image whose content

559
00:25:10,490 --> 00:25:14,600
while trying to keep and the image that

560
00:25:12,230 --> 00:25:17,000
we will be changing to during learning

561
00:25:14,600 --> 00:25:19,790
the image that were generating so then

562
00:25:17,000 --> 00:25:22,160
we can just do a simple mean squared

563
00:25:19,790 --> 00:25:26,590
error really because that's just how

564
00:25:22,160 --> 00:25:29,030
similar to tensors are no magic there

565
00:25:26,590 --> 00:25:31,459
with the stylus we're doing essentially

566
00:25:29,030 --> 00:25:34,550
the same thing except for one new ones

567
00:25:31,460 --> 00:25:36,500
which is a gram matrix transformation a

568
00:25:34,550 --> 00:25:38,600
gram matrix transformation is

569
00:25:36,500 --> 00:25:39,890
essentially you flatten a tensor and

570
00:25:38,600 --> 00:25:43,820
then you multiply it by its own

571
00:25:39,890 --> 00:25:45,560
transpose really from what I understand

572
00:25:43,820 --> 00:25:47,090
the authors of the original paper that

573
00:25:45,560 --> 00:25:49,850
this is based on what I also linked to

574
00:25:47,090 --> 00:25:52,429
and github they didn't have a clear idea

575
00:25:49,850 --> 00:25:54,500
of why this worked so much better as

576
00:25:52,430 --> 00:25:57,320
opposed to address you know using the

577
00:25:54,500 --> 00:25:59,120
raw stuff I think recently there was a

578
00:25:57,320 --> 00:26:01,760
paper that explains mathematically how

579
00:25:59,120 --> 00:26:04,429
why it actually learns better I haven't

580
00:26:01,760 --> 00:26:05,960
read that one I think this is a bit of a

581
00:26:04,430 --> 00:26:07,910
shameful thing that happens in machine

582
00:26:05,960 --> 00:26:12,020
learning a lot we sometimes don't know

583
00:26:07,910 --> 00:26:14,540
one why things work but they work so if

584
00:26:12,020 --> 00:26:18,320
you're interested I I can look up that

585
00:26:14,540 --> 00:26:19,879
paper for you and yeah this is just the

586
00:26:18,320 --> 00:26:23,139
gram matrix transformation that I just

587
00:26:19,880 --> 00:26:27,260
described and what we do is we just

588
00:26:23,140 --> 00:26:30,380
again get the generated output of those

589
00:26:27,260 --> 00:26:32,390
specific layers for both for the

590
00:26:30,380 --> 00:26:34,580
generator for the image that we will be

591
00:26:32,390 --> 00:26:37,760
training and changing we will be trained

592
00:26:34,580 --> 00:26:39,740
during doing training and we only once

593
00:26:37,760 --> 00:26:40,060
have to pass the style image and the

594
00:26:39,740 --> 00:26:42,040
count

595
00:26:40,060 --> 00:26:44,080
through the network to get the outputs

596
00:26:42,040 --> 00:26:45,550
that we know we actually want and we're

597
00:26:44,080 --> 00:26:47,530
trying to make the outputs from the

598
00:26:45,550 --> 00:26:50,950
generated image be as close as possible

599
00:26:47,530 --> 00:26:52,720
to both of those essentially this is

600
00:26:50,950 --> 00:26:57,100
just for unpacking because we've used

601
00:26:52,720 --> 00:27:00,850
multiple layers and then we multiply we

602
00:26:57,100 --> 00:27:03,669
get an one total loss by multiplying

603
00:27:00,850 --> 00:27:05,110
those individual losses by the amount of

604
00:27:03,670 --> 00:27:07,290
style that we wanted to keep and the

605
00:27:05,110 --> 00:27:10,719
amount of content we wanted to keep them

606
00:27:07,290 --> 00:27:12,250
we load up our model and this is the

607
00:27:10,720 --> 00:27:14,740
important part we don't want it to be

608
00:27:12,250 --> 00:27:16,420
trained the model is trained as it is it

609
00:27:14,740 --> 00:27:18,040
contains some knowledge we don't want to

610
00:27:16,420 --> 00:27:19,990
touch it so we taught specifically that

611
00:27:18,040 --> 00:27:23,170
we don't want to Train it and we also

612
00:27:19,990 --> 00:27:26,590
define which layers outputs we are

613
00:27:23,170 --> 00:27:29,890
interested in then we just start at

614
00:27:26,590 --> 00:27:33,129
tensorflow session get the model get a

615
00:27:29,890 --> 00:27:35,170
lot of warnings and then we compute the

616
00:27:33,130 --> 00:27:37,450
style features and the content features

617
00:27:35,170 --> 00:27:40,210
and we turn the style features into a

618
00:27:37,450 --> 00:27:41,650
gram matrix there's a little bit of

619
00:27:40,210 --> 00:27:44,050
pre-processing that we have to do just

620
00:27:41,650 --> 00:27:46,240
because when you think about it when we

621
00:27:44,050 --> 00:27:48,520
do data transformation we usually want

622
00:27:46,240 --> 00:27:49,630
our input to be in the same range so we

623
00:27:48,520 --> 00:27:51,310
have to normalize it

624
00:27:49,630 --> 00:27:54,220
but then the specific normalization

625
00:27:51,310 --> 00:27:56,050
parameters depend on what corpus of data

626
00:27:54,220 --> 00:27:58,000
you pass to it originally so we are a

627
00:27:56,050 --> 00:27:59,379
little bit tight to the image images

628
00:27:58,000 --> 00:28:02,320
that were originally passed to this

629
00:27:59,380 --> 00:28:04,330
network when it was trained the

630
00:28:02,320 --> 00:28:05,889
generated image starts out as just the

631
00:28:04,330 --> 00:28:11,260
content image because we're just gonna

632
00:28:05,890 --> 00:28:13,750
be making changes to that one we pack

633
00:28:11,260 --> 00:28:17,860
our style and content weight into one

634
00:28:13,750 --> 00:28:19,330
variable we define the loss as we have

635
00:28:17,860 --> 00:28:22,179
already and this is the final bit of

636
00:28:19,330 --> 00:28:22,750
magic we use a solver function from

637
00:28:22,180 --> 00:28:25,750
tensorflow

638
00:28:22,750 --> 00:28:28,270
here the atom optimizer and we tell it

639
00:28:25,750 --> 00:28:30,100
to minimize the loss we're gonna be

640
00:28:28,270 --> 00:28:31,870
outputting both the total loss and the

641
00:28:30,100 --> 00:28:33,610
stylist and the content loss so we're

642
00:28:31,870 --> 00:28:35,919
just trying to make it minimize the

643
00:28:33,610 --> 00:28:38,110
total loss and we the only thing that

644
00:28:35,920 --> 00:28:39,370
can change the only thing that we're

645
00:28:38,110 --> 00:28:41,649
telling this function to be able to

646
00:28:39,370 --> 00:28:44,229
change is the actual image so it's not

647
00:28:41,650 --> 00:28:45,790
making changes to the weights of the

648
00:28:44,230 --> 00:28:48,340
matrix it's just going to be addressing

649
00:28:45,790 --> 00:28:50,230
that very image and we give it a

650
00:28:48,340 --> 00:28:54,000
learning rate hood just means how much

651
00:28:50,230 --> 00:28:54,000
can I change the image by at every step

652
00:28:54,190 --> 00:28:59,149
we have to reload the weights because of

653
00:28:56,840 --> 00:29:00,889
tensorflow and yeah and then we just

654
00:28:59,149 --> 00:29:04,309
we're just gonna run it for a number of

655
00:29:00,889 --> 00:29:06,379
iterations yeah it has to track whether

656
00:29:04,309 --> 00:29:07,580
the values of damage are good but that's

657
00:29:06,379 --> 00:29:09,559
the that's the new ones

658
00:29:07,580 --> 00:29:11,210
and yeah it continues running the

659
00:29:09,559 --> 00:29:13,158
optimization operation and it computes

660
00:29:11,210 --> 00:29:15,049
the loss so I'm just gonna run it and

661
00:29:13,159 --> 00:29:18,259
then it will crash and burn

662
00:29:15,049 --> 00:29:20,299
possibly we're just gonna hold here for

663
00:29:18,259 --> 00:29:22,429
a moment so that we can see that it

664
00:29:20,299 --> 00:29:24,499
actually does something okay it does

665
00:29:22,429 --> 00:29:26,869
something and we're gonna come back to

666
00:29:24,499 --> 00:29:30,590
this at the end of the session to see

667
00:29:26,869 --> 00:29:36,580
what it does how do I get out of Chrome

668
00:29:30,590 --> 00:29:36,580
presentation exit full-screen okay I

669
00:29:37,179 --> 00:29:43,159
realize it may sound like magic I hope

670
00:29:41,149 --> 00:29:44,418
it sounds less like magic but I realize

671
00:29:43,159 --> 00:29:49,549
it can still sound a little bit like

672
00:29:44,419 --> 00:29:50,840
magical if I still have time perfect I

673
00:29:49,549 --> 00:29:52,330
just want to tell you a little bit about

674
00:29:50,840 --> 00:29:55,428
different branches of machine learning

675
00:29:52,330 --> 00:29:57,350
it's gonna get a little esoteric now and

676
00:29:55,429 --> 00:29:59,830
a little bit more general and I actually

677
00:29:57,350 --> 00:30:03,139
hope may be more interesting for you

678
00:29:59,830 --> 00:30:04,699
some of it is gonna be speculative okay

679
00:30:03,139 --> 00:30:05,959
so the first branch of machine learning

680
00:30:04,700 --> 00:30:08,019
that I want to talk to you about is

681
00:30:05,960 --> 00:30:10,100
other than the ones I already have is

682
00:30:08,019 --> 00:30:12,320
reinforcement learning reinforcement

683
00:30:10,100 --> 00:30:14,779
learning is just the model is actually

684
00:30:12,320 --> 00:30:16,100
an agent in a specific environment and

685
00:30:14,779 --> 00:30:18,590
it makes decisions within that

686
00:30:16,100 --> 00:30:22,428
environment yeah and a demonstration

687
00:30:18,590 --> 00:30:22,730
here maybe some of you have already seen

688
00:30:22,429 --> 00:30:25,759
it

689
00:30:22,730 --> 00:30:28,190
this is alphago of a star sorry alpha

690
00:30:25,759 --> 00:30:32,210
star that beat starcraft stack up to the

691
00:30:28,190 --> 00:30:33,350
best players before I played a clip for

692
00:30:32,210 --> 00:30:36,139
those of you who don't know Starcraft

693
00:30:33,350 --> 00:30:39,498
it's a real-time strategy game the a is

694
00:30:36,139 --> 00:30:41,389
controlling the blue guys here and these

695
00:30:39,499 --> 00:30:44,119
are units that have one specific ability

696
00:30:41,389 --> 00:30:47,539
they can teleport at very short range

697
00:30:44,119 --> 00:30:49,730
and they have shield and health and if

698
00:30:47,539 --> 00:30:51,830
they lose shield but then aren't in

699
00:30:49,730 --> 00:30:53,629
combat they regenerate the shield so the

700
00:30:51,830 --> 00:30:56,210
shield is a resource that can be managed

701
00:30:53,629 --> 00:31:01,149
and and regained and this is the human

702
00:30:56,210 --> 00:31:01,149
player and let's just see how he fares

703
00:31:01,840 --> 00:31:07,699
you can see that the a I went to have a

704
00:31:04,970 --> 00:31:10,250
fairly uniform strategy here

705
00:31:07,700 --> 00:31:13,040
it's just spamming those those units

706
00:31:10,250 --> 00:31:15,140
with that one ability what the human

707
00:31:13,040 --> 00:31:18,500
player is doing is usually considered a

708
00:31:15,140 --> 00:31:20,990
hard counter to that build immortals and

709
00:31:18,500 --> 00:31:23,360
zealots specifically so if these were

710
00:31:20,990 --> 00:31:25,490
two humans we could expect them to we

711
00:31:23,360 --> 00:31:27,129
could expect the red one to win but you

712
00:31:25,490 --> 00:31:30,320
can see that it does this thing where it

713
00:31:27,130 --> 00:31:32,000
it does this thing where it keeps the

714
00:31:30,320 --> 00:31:33,379
wound oh it teleports the wounded ones

715
00:31:32,000 --> 00:31:35,390
immediately to the back so that they can

716
00:31:33,380 --> 00:31:36,950
still keep outputting damage even though

717
00:31:35,390 --> 00:31:39,320
they are not technically taking damage

718
00:31:36,950 --> 00:31:41,990
and this is kind of impressive right

719
00:31:39,320 --> 00:31:44,360
it's like maybe it's like a simple

720
00:31:41,990 --> 00:31:48,230
resource management but quite a quite a

721
00:31:44,360 --> 00:31:50,240
elaborate thing to learn I think and

722
00:31:48,230 --> 00:31:52,160
yeah just to explain what is actually

723
00:31:50,240 --> 00:31:55,250
happening they're still the simple model

724
00:31:52,160 --> 00:31:57,560
of input transformation output still

725
00:31:55,250 --> 00:32:00,890
applies here it's just that when we pass

726
00:31:57,560 --> 00:32:02,810
input to the model we pass the current

727
00:32:00,890 --> 00:32:05,120
observation about the environment and

728
00:32:02,810 --> 00:32:07,399
you can actually argue that the guys who

729
00:32:05,120 --> 00:32:10,129
made alpha star were treating a little

730
00:32:07,400 --> 00:32:12,290
bit because the algorithm could always

731
00:32:10,130 --> 00:32:14,780
see the entire board where humans

732
00:32:12,290 --> 00:32:18,050
usually have to zoom zoom in and manage

733
00:32:14,780 --> 00:32:19,760
the low window it sometimes can also get

734
00:32:18,050 --> 00:32:22,899
the possible actions when you think

735
00:32:19,760 --> 00:32:25,580
about the AI playing a game like Mario

736
00:32:22,900 --> 00:32:28,040
the possible actions are always the same

737
00:32:25,580 --> 00:32:30,260
you can jump go left down so on but

738
00:32:28,040 --> 00:32:31,909
sometimes in more complex games certain

739
00:32:30,260 --> 00:32:33,860
actions will not be possible depending

740
00:32:31,910 --> 00:32:35,810
on where you are in the environment what

741
00:32:33,860 --> 00:32:38,149
it learns is considered a decision

742
00:32:35,810 --> 00:32:40,760
policy so this is the state of the

743
00:32:38,150 --> 00:32:43,370
environment why how do I make those

744
00:32:40,760 --> 00:32:45,620
decisions and the output is the chosen

745
00:32:43,370 --> 00:32:48,320
action and then we get the next discrete

746
00:32:45,620 --> 00:32:50,149
step of the of the interaction of the

747
00:32:48,320 --> 00:32:52,639
environment or e and we have a reward

748
00:32:50,150 --> 00:32:55,490
function it's usually it has to want

749
00:32:52,640 --> 00:32:56,990
something usually maximize points and we

750
00:32:55,490 --> 00:33:00,710
can sometimes see interesting things

751
00:32:56,990 --> 00:33:03,410
here such as it learns to play the game

752
00:33:00,710 --> 00:33:05,720
in a way we didn't predict it finds bugs

753
00:33:03,410 --> 00:33:11,300
to maximize points which we didn't see

754
00:33:05,720 --> 00:33:13,250
earlier okay generative learning is a

755
00:33:11,300 --> 00:33:16,639
type of unsupervised learning

756
00:33:13,250 --> 00:33:18,890
this is when we usually feed the

757
00:33:16,640 --> 00:33:22,460
algorithm a lot of data from a specific

758
00:33:18,890 --> 00:33:24,980
sample and we wanted to generate a lot

759
00:33:22,460 --> 00:33:27,530
of data and we wanted to generate new

760
00:33:24,980 --> 00:33:30,230
samples from that set so for example you

761
00:33:27,530 --> 00:33:31,940
could imagine that it wants to we give

762
00:33:30,230 --> 00:33:35,299
it a lot of paintings by Salvador Dali

763
00:33:31,940 --> 00:33:36,220
and we want it to output new paintings

764
00:33:35,299 --> 00:33:38,990
by Salvador Dali

765
00:33:36,220 --> 00:33:41,630
sometimes we give it random input which

766
00:33:38,990 --> 00:33:44,059
is one we want novelty you know so that

767
00:33:41,630 --> 00:33:47,720
doesn't just output it the best most

768
00:33:44,059 --> 00:33:49,639
Salvador Dali picture ever sometimes we

769
00:33:47,720 --> 00:33:52,549
give it more specific things this is for

770
00:33:49,640 --> 00:33:54,320
example from a paper where machine

771
00:33:52,549 --> 00:33:56,389
learning engineers taught the algorithm

772
00:33:54,320 --> 00:33:59,178
to generate pictures that match the

773
00:33:56,390 --> 00:34:02,299
content of the image here red white bird

774
00:33:59,179 --> 00:34:07,549
with a very short beak and a strange

775
00:34:02,299 --> 00:34:08,810
number of legacy but still there's a

776
00:34:07,549 --> 00:34:10,280
specific type of generative learning

777
00:34:08,810 --> 00:34:12,799
that I want to talk about that you may

778
00:34:10,280 --> 00:34:15,139
have heard generative adversarial

779
00:34:12,800 --> 00:34:17,179
Network this is when we technically have

780
00:34:15,139 --> 00:34:18,980
two models one is called the generator

781
00:34:17,179 --> 00:34:21,200
and it does essentially the thing I just

782
00:34:18,980 --> 00:34:25,219
described it tries to generate new

783
00:34:21,199 --> 00:34:26,868
samples from a corpus of data that much

784
00:34:25,219 --> 00:34:29,598
that that corpus that are very similar

785
00:34:26,869 --> 00:34:31,580
as the data that was fed to it and then

786
00:34:29,599 --> 00:34:33,859
there's a discriminator network which

787
00:34:31,580 --> 00:34:36,139
essentially has one job is this a fake

788
00:34:33,859 --> 00:34:38,020
sample or is this from the original set

789
00:34:36,139 --> 00:34:40,369
and through a little bit of clever

790
00:34:38,020 --> 00:34:41,869
gradient juggling between the two you

791
00:34:40,369 --> 00:34:45,320
can actually make them you know

792
00:34:41,869 --> 00:34:46,580
bootstrap each other they get better as

793
00:34:45,320 --> 00:34:48,260
the other one gets better at the other

794
00:34:46,580 --> 00:34:49,790
one gets better and so on better effects

795
00:34:48,260 --> 00:34:52,040
are generated you have to be a better

796
00:34:49,790 --> 00:34:54,099
discriminator to get a higher reward and

797
00:34:52,040 --> 00:34:56,359
and that's how it happens in the loop

798
00:34:54,099 --> 00:34:59,150
one important thing I want to talk about

799
00:34:56,359 --> 00:35:02,779
also is federated machine learning this

800
00:34:59,150 --> 00:35:04,339
is hopefully a way for us in the future

801
00:35:02,780 --> 00:35:06,950
to have machine learning there's more

802
00:35:04,339 --> 00:35:08,330
privacy based this is where the training

803
00:35:06,950 --> 00:35:09,740
doesn't happen in a data center

804
00:35:08,330 --> 00:35:12,880
somewhere it's supposed to happen

805
00:35:09,740 --> 00:35:15,109
on your device this is a picture

806
00:35:12,880 --> 00:35:16,640
outlining the entire protocol that

807
00:35:15,109 --> 00:35:18,109
Google recently came up with I think

808
00:35:16,640 --> 00:35:19,609
it's a step in the right direction you

809
00:35:18,109 --> 00:35:23,029
can see here that the training happens I

810
00:35:19,609 --> 00:35:25,490
can see my cursor anymore the training

811
00:35:23,030 --> 00:35:26,480
happens on the device this is all the

812
00:35:25,490 --> 00:35:27,890
stuff that happens on the

813
00:35:26,480 --> 00:35:30,829
and this is the stuff that happens in

814
00:35:27,890 --> 00:35:33,319
the data center in the cloud it's a very

815
00:35:30,829 --> 00:35:35,420
good protocol I think technically I have

816
00:35:33,320 --> 00:35:36,980
personalized certain qualms about it

817
00:35:35,420 --> 00:35:40,160
still but if you're interested you can

818
00:35:36,980 --> 00:35:42,200
just look up federated learning and

819
00:35:40,160 --> 00:35:44,799
finally the most controversial topic

820
00:35:42,200 --> 00:35:46,970
within machine learning Adria is

821
00:35:44,800 --> 00:35:49,310
artificial general intelligence this is

822
00:35:46,970 --> 00:35:51,529
a stole from one of the movies Blade

823
00:35:49,310 --> 00:35:55,070
Runner 2048 that recently touched on the

824
00:35:51,530 --> 00:35:57,260
subject what is an Adrian it's meant to

825
00:35:55,070 --> 00:35:59,000
be a model that is as flexible at

826
00:35:57,260 --> 00:36:00,770
learning different things as essentially

827
00:35:59,000 --> 00:36:04,760
a human mind so like a human level

828
00:36:00,770 --> 00:36:07,490
intellect we seem to be very intrigued

829
00:36:04,760 --> 00:36:10,790
by this concept and culture we've seen

830
00:36:07,490 --> 00:36:12,680
it in Star Trek Blade Runner we've seen

831
00:36:10,790 --> 00:36:14,900
it everywhere pretty much Terminator

832
00:36:12,680 --> 00:36:16,669
famously obviously most recently the

833
00:36:14,900 --> 00:36:19,579
movie her and the braid Blade Runner

834
00:36:16,670 --> 00:36:21,560
sequel there are two interesting

835
00:36:19,579 --> 00:36:23,869
metaphors that are usually used when

836
00:36:21,560 --> 00:36:26,349
discussing this and again I'm prefacing

837
00:36:23,869 --> 00:36:28,130
this way this is all highly speculative

838
00:36:26,349 --> 00:36:30,740
although I am going to point to specific

839
00:36:28,130 --> 00:36:33,500
research within this subject one is that

840
00:36:30,740 --> 00:36:35,540
of an Oracle which is essentially we

841
00:36:33,500 --> 00:36:37,910
have that model that has learned so much

842
00:36:35,540 --> 00:36:40,460
knowledge but it is locked in a cave or

843
00:36:37,910 --> 00:36:42,500
a cage so the only way we communicate

844
00:36:40,460 --> 00:36:44,300
with it is through some sort of text

845
00:36:42,500 --> 00:36:48,200
communicator it has no agency in the

846
00:36:44,300 --> 00:36:50,510
world or essentially the ominously

847
00:36:48,200 --> 00:36:54,259
sounding deal with the devil metaphor

848
00:36:50,510 --> 00:36:56,869
which is we expressed a wish and then

849
00:36:54,260 --> 00:36:59,720
the AI agent acts in the environment and

850
00:36:56,869 --> 00:37:02,510
tries to make our voice happen and this

851
00:36:59,720 --> 00:37:05,000
is obviously from dr. Faust this is my

852
00:37:02,510 --> 00:37:07,250
Festa Felice and this is a good example

853
00:37:05,000 --> 00:37:09,589
of a perverse instantiation of the wish

854
00:37:07,250 --> 00:37:13,069
you may have heard about the paperclip

855
00:37:09,589 --> 00:37:15,470
maker example we tell the a tree I make

856
00:37:13,069 --> 00:37:17,119
paperclips it proceeds to make paper

857
00:37:15,470 --> 00:37:20,299
clips until there's no more universe

858
00:37:17,119 --> 00:37:22,040
left essentially so you can see kind of

859
00:37:20,300 --> 00:37:24,079
that we have been playing around with

860
00:37:22,040 --> 00:37:27,259
these metaphors and these topics for a

861
00:37:24,079 --> 00:37:29,359
while and culture as well but there are

862
00:37:27,260 --> 00:37:33,140
specific research problems that are

863
00:37:29,359 --> 00:37:36,500
being addressed within this field one of

864
00:37:33,140 --> 00:37:39,259
them is the orthogonality thesis the

865
00:37:36,500 --> 00:37:40,490
orthogonality thesis which I would think

866
00:37:39,260 --> 00:37:43,790
we really need to come up

867
00:37:40,490 --> 00:37:45,500
more human understandable name for it it

868
00:37:43,790 --> 00:37:47,270
just means that any level of

869
00:37:45,500 --> 00:37:50,390
intelligence is compatible with any

870
00:37:47,270 --> 00:37:53,570
goals we may have this intuition that if

871
00:37:50,390 --> 00:37:54,290
a person or if an intellect is very

872
00:37:53,570 --> 00:37:57,619
intelligent

873
00:37:54,290 --> 00:38:00,589
they will also by consequence be good or

874
00:37:57,619 --> 00:38:01,490
virtuous and this thesis states that

875
00:38:00,589 --> 00:38:03,710
that is not true

876
00:38:01,490 --> 00:38:06,560
once again you can have an extremely

877
00:38:03,710 --> 00:38:09,440
intelligent paperclip maker it's

878
00:38:06,560 --> 00:38:11,359
difficult to produce in formal logic but

879
00:38:09,440 --> 00:38:12,880
yeah efforts continue and if it is true

880
00:38:11,359 --> 00:38:16,098
then we should obviously take certain

881
00:38:12,880 --> 00:38:18,530
you know security countermeasures shall

882
00:38:16,099 --> 00:38:21,770
we say the concept of instrumental goals

883
00:38:18,530 --> 00:38:25,250
it's just that no matter what end goal

884
00:38:21,770 --> 00:38:27,400
you give it largely it's probably gonna

885
00:38:25,250 --> 00:38:31,430
converge or getting certain things

886
00:38:27,400 --> 00:38:33,800
regardless of that goal so money is an

887
00:38:31,430 --> 00:38:38,000
instrumental goal power sometimes fame

888
00:38:33,800 --> 00:38:40,040
so you can get a sense that whatever the

889
00:38:38,000 --> 00:38:41,960
goal you give it even if it's virtuous

890
00:38:40,040 --> 00:38:43,580
it will probably want to have as much

891
00:38:41,960 --> 00:38:45,200
power as possible because that increases

892
00:38:43,580 --> 00:38:47,930
the likelihood that it will achieve its

893
00:38:45,200 --> 00:38:50,029
goal and finally there's the catering

894
00:38:47,930 --> 00:38:52,640
problem you can imagine a scenario where

895
00:38:50,030 --> 00:38:56,119
somehow we've built the Oracle and it's

896
00:38:52,640 --> 00:38:59,420
virtuous how do we keep it in a cage

897
00:38:56,119 --> 00:39:01,460
well maybe this will happen at some big

898
00:38:59,420 --> 00:39:03,760
corporations data center and you would

899
00:39:01,460 --> 00:39:06,170
imagine that okay so those servers are

900
00:39:03,760 --> 00:39:09,530
somewhere unconnected to the internet

901
00:39:06,170 --> 00:39:11,780
perhaps so we're safe problem is if we

902
00:39:09,530 --> 00:39:13,790
did that then if it's really intelligent

903
00:39:11,780 --> 00:39:15,800
it could manipulate its internal

904
00:39:13,790 --> 00:39:17,060
processing so that the you know the

905
00:39:15,800 --> 00:39:19,339
electricity that happens within the

906
00:39:17,060 --> 00:39:20,839
server's can technically be used as

907
00:39:19,339 --> 00:39:23,119
radio waves and then it's no longer

908
00:39:20,839 --> 00:39:24,650
contained so I'm just mentioning this

909
00:39:23,119 --> 00:39:27,260
because there's a lot of interesting

910
00:39:24,650 --> 00:39:30,770
cool problems here that's sometimes go

911
00:39:27,260 --> 00:39:34,780
against our intuitions yeah let's check

912
00:39:30,770 --> 00:39:34,780
out how to duck the horse duck worked

913
00:39:35,619 --> 00:39:39,280
yes we need a bigger

914
00:39:47,900 --> 00:39:55,560
yeah okay

915
00:39:53,130 --> 00:39:57,690
so it prints something out every 10th

916
00:39:55,560 --> 00:40:00,779
iteration so you can see the original

917
00:39:57,690 --> 00:40:04,410
image lots of texture here the style

918
00:40:00,780 --> 00:40:05,760
image and even on the 10th iteration I'm

919
00:40:04,410 --> 00:40:11,190
just gonna make it a little bigger if I

920
00:40:05,760 --> 00:40:13,950
can I can't sorry yeah that size is

921
00:40:11,190 --> 00:40:15,420
prefixed but yeah you can see that lines

922
00:40:13,950 --> 00:40:16,770
are getting smoother the colors are

923
00:40:15,420 --> 00:40:19,740
getting more saturated there's almost

924
00:40:16,770 --> 00:40:24,060
like a rainbow and its tail the clouds

925
00:40:19,740 --> 00:40:26,009
look different all of a sudden the tree

926
00:40:24,060 --> 00:40:29,819
has grown a leg and looks vaguely like a

927
00:40:26,010 --> 00:40:33,000
burden and the colors are getting more

928
00:40:29,819 --> 00:40:36,029
and more vivid and we see a much more

929
00:40:33,000 --> 00:40:38,849
vibrant dark here and the grass doesn't

930
00:40:36,030 --> 00:40:41,609
look like grass anymore and yeah we can

931
00:40:38,849 --> 00:40:44,010
see that our little model has learned to

932
00:40:41,609 --> 00:40:49,799
make a better combination of those two

933
00:40:44,010 --> 00:40:53,700
images I'm gonna stop it now I'm just

934
00:40:49,800 --> 00:40:58,890
gonna interrupt the kernel and I am

935
00:40:53,700 --> 00:41:03,509
going to show you the out the final

936
00:40:58,890 --> 00:41:05,490
output after about two hundred

937
00:41:03,510 --> 00:41:15,599
iterations just so you see how it looks

938
00:41:05,490 --> 00:41:18,390
like you can see a certain loss in

939
00:41:15,599 --> 00:41:21,990
fidelity but what do you think did it

940
00:41:18,390 --> 00:41:23,879
capture the style of dying okay great

941
00:41:21,990 --> 00:41:28,459
okay so I'm just gonna hop back over to

942
00:41:23,880 --> 00:41:31,950
the presentation well done well done

943
00:41:28,460 --> 00:41:33,480
thank you okay so thank you so much for

944
00:41:31,950 --> 00:41:35,848
your attention I hope I know that this

945
00:41:33,480 --> 00:41:39,450
was a bit of yeah like the title says a

946
00:41:35,849 --> 00:41:41,490
crash course it's a lot of subjects but

947
00:41:39,450 --> 00:41:43,828
yeah we talked about how learning

948
00:41:41,490 --> 00:41:46,549
happens gave you an overview of the

949
00:41:43,829 --> 00:41:48,660
other branches and I would like to

950
00:41:46,550 --> 00:41:51,869
deeply deeply encourage you to hop over

951
00:41:48,660 --> 00:41:53,520
to this project on github it's not just

952
00:41:51,869 --> 00:41:54,960
my work we did in collaboration of a

953
00:41:53,520 --> 00:41:57,059
couple of people who are passionate

954
00:41:54,960 --> 00:42:00,809
about making it easier for people

955
00:41:57,059 --> 00:42:02,969
new to this this you know topic to just

956
00:42:00,809 --> 00:42:04,499
hop on over so different courses that

957
00:42:02,969 --> 00:42:08,939
we've all done personally different

958
00:42:04,499 --> 00:42:10,288
books tools scientific papers blogs that

959
00:42:08,939 --> 00:42:13,319
you might want to follow YouTube

960
00:42:10,289 --> 00:42:14,999
channels and so on so forth just hop on

961
00:42:13,319 --> 00:42:16,949
over and see what you can do because we

962
00:42:14,999 --> 00:42:18,569
really need people who have your

963
00:42:16,949 --> 00:42:20,130
expertise people from all sorts of

964
00:42:18,569 --> 00:42:22,339
fields thank you very much for your

965
00:42:20,130 --> 00:42:22,339
attention

966
00:42:26,269 --> 00:42:48,269
any questions we're not gonna bite you

967
00:42:32,909 --> 00:42:51,419
if you say yes yeah a question how I was

968
00:42:48,269 --> 00:42:54,238
interested with the ethical themes that

969
00:42:51,419 --> 00:42:56,308
you touched on at the end how do you

970
00:42:54,239 --> 00:42:58,289
feel that they reflect in the lower

971
00:42:56,309 --> 00:43:01,499
level work I mean that the scripting and

972
00:42:58,289 --> 00:43:03,719
the coding so when you're interfacing to

973
00:43:01,499 --> 00:43:05,339
the tends to flow for example do you

974
00:43:03,719 --> 00:43:07,589
ever think about those things when you

975
00:43:05,339 --> 00:43:09,239
actually program in I think we

976
00:43:07,589 --> 00:43:10,439
definitely a great question first of all

977
00:43:09,239 --> 00:43:12,359
this is something that's very close to

978
00:43:10,439 --> 00:43:14,549
my heart one of the resources that I've

979
00:43:12,359 --> 00:43:16,949
included is actually an ethics ethics

980
00:43:14,549 --> 00:43:20,400
guidelines from the European Union about

981
00:43:16,949 --> 00:43:24,269
this to give you the most honest answer

982
00:43:20,400 --> 00:43:26,729
I think I don't think it's as often on

983
00:43:24,269 --> 00:43:28,049
my mind as I wish it was but that is a

984
00:43:26,729 --> 00:43:30,479
little bit because of what I do

985
00:43:28,049 --> 00:43:34,439
specifically at my company in private

986
00:43:30,479 --> 00:43:37,948
projects more so I I think irresponsible

987
00:43:34,439 --> 00:43:40,199
choices creep in very early like it's

988
00:43:37,949 --> 00:43:43,709
sorry I'm exasperated with myself not

989
00:43:40,199 --> 00:43:45,390
with you you can make such an innocent

990
00:43:43,709 --> 00:43:47,569
bad choice that will have such dire

991
00:43:45,390 --> 00:43:51,058
consequences later on in this just

992
00:43:47,569 --> 00:43:53,099
choose the wrong data truth data that

993
00:43:51,059 --> 00:43:56,159
does not include people from you know

994
00:43:53,099 --> 00:43:58,499
the end user group really like you know

995
00:43:56,159 --> 00:44:01,380
was Apple's facial recognition stuff

996
00:43:58,499 --> 00:44:02,879
like little bits like that problems with

997
00:44:01,380 --> 00:44:05,279
data leakage there was like one famous

998
00:44:02,880 --> 00:44:07,529
instance where someone claimed that they

999
00:44:05,279 --> 00:44:08,390
learned how to recognize the flavors of

1000
00:44:07,529 --> 00:44:10,609
a sandwich

1001
00:44:08,390 --> 00:44:12,710
by picture and it turned out when you

1002
00:44:10,609 --> 00:44:14,630
looked at the data that the trace of

1003
00:44:12,710 --> 00:44:15,980
this on which the sandwiches were put

1004
00:44:14,630 --> 00:44:18,140
where of different colors depending on

1005
00:44:15,980 --> 00:44:20,210
the taste you know like you can make

1006
00:44:18,140 --> 00:44:22,009
such little mistakes that have such

1007
00:44:20,210 --> 00:44:24,049
consequences there and I'm not even

1008
00:44:22,010 --> 00:44:26,480
getting into any of the like deeper you

1009
00:44:24,049 --> 00:44:28,339
know more forward problems with it I

1010
00:44:26,480 --> 00:44:30,470
think we definitely need to get much

1011
00:44:28,339 --> 00:44:31,788
better at that and I try to be mindful

1012
00:44:30,470 --> 00:44:35,480
of it in my daily work about here

1013
00:44:31,789 --> 00:44:37,869
thank you great question any more

1014
00:44:35,480 --> 00:44:37,869
questions

1015
00:44:39,400 --> 00:44:48,139
let's have a pick one of applause done

1016
00:44:43,110 --> 00:44:48,139
[Applause]

1017
00:44:53,329 --> 00:44:55,390
you

