1
00:00:12,980 --> 00:00:18,590
[Music]

2
00:00:25,279 --> 00:00:27,119
welcome everybody jb

3
00:00:27,119 --> 00:00:30,160
and j salvatory my name is tanmori

4
00:00:30,160 --> 00:00:32,079
and i'm executive director of equality

5
00:00:32,079 --> 00:00:33,200
labs

6
00:00:33,200 --> 00:00:35,760
and it is my pleasure to be able to host

7
00:00:35,760 --> 00:00:37,280
this wonderful fireside

8
00:00:37,280 --> 00:00:39,760
chat with our colleagues siphia noble

9
00:00:39,760 --> 00:00:40,480
and

10
00:00:40,480 --> 00:00:43,520
sasha castanjo chalk and

11
00:00:43,520 --> 00:00:45,120
you know i think before we begin this

12
00:00:45,120 --> 00:00:46,960
panel i just want everybody to take a

13
00:00:46,960 --> 00:00:48,559
little time to settle

14
00:00:48,559 --> 00:00:51,120
i know that you know the the moment that

15
00:00:51,120 --> 00:00:52,879
we're coming in which is year two of

16
00:00:52,879 --> 00:00:55,120
this pandemic has really

17
00:00:55,120 --> 00:00:58,239
just run havoc for all of us and

18
00:00:58,239 --> 00:01:00,000
even if this is one of the last things

19
00:01:00,000 --> 00:01:01,520
that you do today

20
00:01:01,520 --> 00:01:03,120
i know that there's about a year and a

21
00:01:03,120 --> 00:01:05,760
half of hell that we've survived

22
00:01:05,760 --> 00:01:09,760
many people have lost really deep and

23
00:01:09,760 --> 00:01:13,119
powerful losses from to the pandemic and

24
00:01:13,119 --> 00:01:15,280
many of the activists that are here from

25
00:01:15,280 --> 00:01:16,159
rights con

26
00:01:16,159 --> 00:01:17,439
are also attending while their

27
00:01:17,439 --> 00:01:20,159
democracies are under attack

28
00:01:20,159 --> 00:01:22,880
from digital authoritarianism and so we

29
00:01:22,880 --> 00:01:24,880
know how hard it is to show up

30
00:01:24,880 --> 00:01:27,680
how hard it is to be present when we are

31
00:01:27,680 --> 00:01:30,240
also carrying the losses of so many

32
00:01:30,240 --> 00:01:32,079
and so before we begin i just want you

33
00:01:32,079 --> 00:01:33,280
to settle in

34
00:01:33,280 --> 00:01:35,280
get comfortable into your couch you're

35
00:01:35,280 --> 00:01:37,840
entering a chat with some of your best

36
00:01:37,840 --> 00:01:38,320
friends

37
00:01:38,320 --> 00:01:41,119
um on um you know about some of the

38
00:01:41,119 --> 00:01:43,040
things that we care the most about when

39
00:01:43,040 --> 00:01:44,560
it taught when we're talking about

40
00:01:44,560 --> 00:01:47,439
um digital authoritarianism and you know

41
00:01:47,439 --> 00:01:49,439
bias in these platforms

42
00:01:49,439 --> 00:01:52,000
but i want you to be able to be embodied

43
00:01:52,000 --> 00:01:55,040
so if you can just take a breath

44
00:01:55,040 --> 00:01:58,960
settle and think about

45
00:01:58,960 --> 00:02:00,719
um the fact that we're just gonna spend

46
00:02:00,719 --> 00:02:02,000
an hour together

47
00:02:02,000 --> 00:02:05,360
and think about freedom and as we think

48
00:02:05,360 --> 00:02:06,399
about that

49
00:02:06,399 --> 00:02:08,399
bringing all those that we've lost with

50
00:02:08,399 --> 00:02:10,720
us so that we can hold them

51
00:02:10,720 --> 00:02:12,720
as we work forward into this

52
00:02:12,720 --> 00:02:14,720
conversation with grace

53
00:02:14,720 --> 00:02:17,120
so thank you um and again you know we're

54
00:02:17,120 --> 00:02:19,040
about to go into our panel

55
00:02:19,040 --> 00:02:22,080
and um you know i'd like to welcome you

56
00:02:22,080 --> 00:02:24,160
know professor sophia noble

57
00:02:24,160 --> 00:02:26,080
who is the author of algorithms of

58
00:02:26,080 --> 00:02:29,120
oppression and professor sustanja chuck

59
00:02:29,120 --> 00:02:31,040
who is the author of design justice

60
00:02:31,040 --> 00:02:32,800
community-led practices to build the

61
00:02:32,800 --> 00:02:34,319
world that we need

62
00:02:34,319 --> 00:02:36,160
and you know today's conversation is

63
00:02:36,160 --> 00:02:38,080
really meant to be a thoughtful

64
00:02:38,080 --> 00:02:39,120
reflection

65
00:02:39,120 --> 00:02:42,400
at the face of all of these crisis um

66
00:02:42,400 --> 00:02:44,800
how we can begin to start to put our

67
00:02:44,800 --> 00:02:45,920
attention

68
00:02:45,920 --> 00:02:48,160
from documenting the problem into

69
00:02:48,160 --> 00:02:50,160
imagining the solution

70
00:02:50,160 --> 00:02:51,840
and i think that you know our two

71
00:02:51,840 --> 00:02:53,519
colleagues here are some of the best

72
00:02:53,519 --> 00:02:56,480
people to riff on that idea with me

73
00:02:56,480 --> 00:02:58,959
because they are folks who have really

74
00:02:58,959 --> 00:03:00,239
helped to build this

75
00:03:00,239 --> 00:03:02,879
field and push the field beyond the

76
00:03:02,879 --> 00:03:04,000
constraints that

77
00:03:04,000 --> 00:03:05,840
um you know surveillance capitalism

78
00:03:05,840 --> 00:03:07,680
would not allow us to talk about many of

79
00:03:07,680 --> 00:03:08,879
these issues

80
00:03:08,879 --> 00:03:10,959
and with professor noble's work you know

81
00:03:10,959 --> 00:03:12,000
i really is

82
00:03:12,000 --> 00:03:13,920
it's a it's a really important reminder

83
00:03:13,920 --> 00:03:16,319
how women of color and femmes of color

84
00:03:16,319 --> 00:03:18,159
were the the cassandras

85
00:03:18,159 --> 00:03:20,080
as well as the canaries in the coal mine

86
00:03:20,080 --> 00:03:21,440
of what was happening with these

87
00:03:21,440 --> 00:03:22,959
technical platforms

88
00:03:22,959 --> 00:03:26,159
and people did not listen imagine if we

89
00:03:26,159 --> 00:03:27,440
had the wide scale

90
00:03:27,440 --> 00:03:30,239
societal understanding and the interest

91
00:03:30,239 --> 00:03:32,319
to move on the issues of algorithmic

92
00:03:32,319 --> 00:03:33,040
bias

93
00:03:33,040 --> 00:03:35,760
in 2018 when professor noble's book

94
00:03:35,760 --> 00:03:36,799
first dropped

95
00:03:36,799 --> 00:03:40,000
as opposed to in 2021 after a near

96
00:03:40,000 --> 00:03:43,360
coup took down american democracy right

97
00:03:43,360 --> 00:03:45,440
so i want to first bring in professor

98
00:03:45,440 --> 00:03:47,440
noble and you know um

99
00:03:47,440 --> 00:03:49,440
if you didn't mind doing like a a you

100
00:03:49,440 --> 00:03:51,040
know an intro that you feel like

101
00:03:51,040 --> 00:03:52,239
would be helpful for people to

102
00:03:52,239 --> 00:03:53,360
understand where you're coming from in

103
00:03:53,360 --> 00:03:54,959
this conversation

104
00:03:54,959 --> 00:03:56,959
i'm just wondering for for folks who are

105
00:03:56,959 --> 00:03:58,080
familiar with your work

106
00:03:58,080 --> 00:04:00,959
or for people that are in um democracies

107
00:04:00,959 --> 00:04:02,480
that are facing

108
00:04:02,480 --> 00:04:05,439
um crisis because of the interventions

109
00:04:05,439 --> 00:04:07,599
of these colonial platforms

110
00:04:07,599 --> 00:04:09,280
i'm just wondering what your thoughts

111
00:04:09,280 --> 00:04:11,920
are um you know at this moment in times

112
00:04:11,920 --> 00:04:14,000
of the openings that you see

113
00:04:14,000 --> 00:04:15,599
because i think people definitely see

114
00:04:15,599 --> 00:04:18,000
the problems but i think that

115
00:04:18,000 --> 00:04:20,320
sometimes you know diagnosing and

116
00:04:20,320 --> 00:04:22,400
documenting the problem leads people to

117
00:04:22,400 --> 00:04:23,759
a place of despair

118
00:04:23,759 --> 00:04:25,840
so i'm wondering where is the hope in

119
00:04:25,840 --> 00:04:28,960
what you're seeing thank you so much

120
00:04:28,960 --> 00:04:32,000
for that just incredible framing

121
00:04:32,000 --> 00:04:34,880
and i consider it such an honor to get

122
00:04:34,880 --> 00:04:36,639
to be in conversation with the two of

123
00:04:36,639 --> 00:04:38,160
you tonight so

124
00:04:38,160 --> 00:04:42,400
i just want to say that i'm joining you

125
00:04:42,400 --> 00:04:45,440
tonight from the gabriellino and tonka

126
00:04:45,440 --> 00:04:46,240
people's

127
00:04:46,240 --> 00:04:49,040
land which they have not seated um where

128
00:04:49,040 --> 00:04:50,000
i work and live

129
00:04:50,000 --> 00:04:53,120
in in los angeles and i

130
00:04:53,120 --> 00:04:56,639
am um really

131
00:04:56,639 --> 00:04:59,759
moved by the way that you started us as

132
00:04:59,759 --> 00:05:00,320
well

133
00:05:00,320 --> 00:05:02,639
with a kind of a centering and a

134
00:05:02,639 --> 00:05:03,680
grounding

135
00:05:03,680 --> 00:05:06,639
in these conversations because i think

136
00:05:06,639 --> 00:05:06,960
as

137
00:05:06,960 --> 00:05:09,360
is the practice of many of our

138
00:05:09,360 --> 00:05:10,560
communities

139
00:05:10,560 --> 00:05:13,600
to be present

140
00:05:13,600 --> 00:05:17,280
and to pay attention and to see

141
00:05:17,280 --> 00:05:22,239
and to connect across generations

142
00:05:22,880 --> 00:05:24,960
the conditions that our communities are

143
00:05:24,960 --> 00:05:26,240
facing is

144
00:05:26,240 --> 00:05:28,639
one of the most important entry points

145
00:05:28,639 --> 00:05:30,400
into these conversations that we can

146
00:05:30,400 --> 00:05:31,120
have

147
00:05:31,120 --> 00:05:34,160
um and it is also a practice and a way

148
00:05:34,160 --> 00:05:35,440
of intervening

149
00:05:35,440 --> 00:05:37,360
um into these conversations we're gonna

150
00:05:37,360 --> 00:05:38,880
have tonight so

151
00:05:38,880 --> 00:05:42,479
um i started this work

152
00:05:42,479 --> 00:05:46,000
myself thinking about um where i was

153
00:05:46,000 --> 00:05:49,199
in kind of a very local experience

154
00:05:49,199 --> 00:05:53,280
of um living in the united states

155
00:05:53,280 --> 00:05:57,280
working in corporate america i spent

156
00:05:57,280 --> 00:05:59,120
15 years working in advertising and

157
00:05:59,120 --> 00:06:00,319
marketing and then i went

158
00:06:00,319 --> 00:06:02,319
back to graduate school during the

159
00:06:02,319 --> 00:06:03,440
recession

160
00:06:03,440 --> 00:06:06,720
at a time when not only

161
00:06:06,720 --> 00:06:10,240
were my friends and colleagues all of us

162
00:06:10,240 --> 00:06:12,800
in despair financially because of what

163
00:06:12,800 --> 00:06:14,319
the recession was doing to

164
00:06:14,319 --> 00:06:17,759
our lives and to our networks

165
00:06:17,759 --> 00:06:20,400
um but i you know kind of entered these

166
00:06:20,400 --> 00:06:22,080
conversations at a time

167
00:06:22,080 --> 00:06:25,120
when companies like google and facebook

168
00:06:25,120 --> 00:06:28,240
were emerging powerfully into

169
00:06:28,240 --> 00:06:31,840
the zeitgeist in the united states and

170
00:06:31,840 --> 00:06:34,479
i was interested in things questions

171
00:06:34,479 --> 00:06:35,520
like

172
00:06:35,520 --> 00:06:39,680
how do we disambiguate knowledge and

173
00:06:39,680 --> 00:06:43,440
um wisdom from advertising

174
00:06:43,440 --> 00:06:45,840
or propaganda that really is what like

175
00:06:45,840 --> 00:06:48,319
the kinds of questions that i had when i

176
00:06:48,319 --> 00:06:50,880
entered this conversation and i saw so

177
00:06:50,880 --> 00:06:53,280
many people were turning to

178
00:06:53,280 --> 00:06:56,639
google search to um

179
00:06:56,639 --> 00:07:00,880
help them answer complex questions that

180
00:07:00,880 --> 00:07:03,360
was you know akin to i don't know

181
00:07:03,360 --> 00:07:05,280
opening the pages of vogue magazine or

182
00:07:05,280 --> 00:07:07,039
something or opening the pages of the

183
00:07:07,039 --> 00:07:08,400
inquirer i mean

184
00:07:08,400 --> 00:07:10,400
opening up a media space that was

185
00:07:10,400 --> 00:07:12,720
completely driven by advertising

186
00:07:12,720 --> 00:07:15,680
where there might be some good nuggets

187
00:07:15,680 --> 00:07:17,680
but for the most part

188
00:07:17,680 --> 00:07:20,800
um turning away from

189
00:07:20,800 --> 00:07:24,000
long forms of like oral tradition and

190
00:07:24,000 --> 00:07:25,360
knowledge systems

191
00:07:25,360 --> 00:07:28,479
and libraries and other universities

192
00:07:28,479 --> 00:07:31,280
other kinds of sites of expertise to

193
00:07:31,280 --> 00:07:34,319
um to move our societies forward people

194
00:07:34,319 --> 00:07:35,919
were turning to these advertising

195
00:07:35,919 --> 00:07:37,520
platforms instead

196
00:07:37,520 --> 00:07:38,639
that's what brought me to the

197
00:07:38,639 --> 00:07:41,280
conversation and so even though the book

198
00:07:41,280 --> 00:07:43,599
eventually came out in 2018 it was

199
00:07:43,599 --> 00:07:45,440
really in 2010

200
00:07:45,440 --> 00:07:47,120
that i started documenting

201
00:07:47,120 --> 00:07:49,599
systematically the way in which

202
00:07:49,599 --> 00:07:53,039
uh communities of color women and girls

203
00:07:53,039 --> 00:07:54,560
of color in particular

204
00:07:54,560 --> 00:07:56,639
were so profoundly misrepresented in

205
00:07:56,639 --> 00:07:58,400
something like a large-scale commercial

206
00:07:58,400 --> 00:07:59,840
advertising platform

207
00:07:59,840 --> 00:08:03,680
like google search and

208
00:08:03,680 --> 00:08:05,919
of course one of the things that we know

209
00:08:05,919 --> 00:08:07,599
is that

210
00:08:07,599 --> 00:08:10,560
people who don't have contact or

211
00:08:10,560 --> 00:08:11,680
relationship

212
00:08:11,680 --> 00:08:15,360
with our communities in my case in the

213
00:08:15,360 --> 00:08:16,720
black community

214
00:08:16,720 --> 00:08:19,919
um derive their understandings about the

215
00:08:19,919 --> 00:08:22,319
world from the media that they consume

216
00:08:22,319 --> 00:08:25,199
and the uh you know media serves as a

217
00:08:25,199 --> 00:08:26,639
proxy for

218
00:08:26,639 --> 00:08:28,400
authentic relationship and this is one

219
00:08:28,400 --> 00:08:29,680
of the reasons why

220
00:08:29,680 --> 00:08:32,880
for 50 years more than 50 years going

221
00:08:32,880 --> 00:08:36,399
back all the way to dubois documenting

222
00:08:36,399 --> 00:08:39,440
and taking photographs of african

223
00:08:39,440 --> 00:08:40,559
americans

224
00:08:40,559 --> 00:08:42,799
in the united states and putting those

225
00:08:42,799 --> 00:08:43,760
images out

226
00:08:43,760 --> 00:08:46,240
in direct opposition to the way in which

227
00:08:46,240 --> 00:08:48,080
the scientific community

228
00:08:48,080 --> 00:08:53,120
was portraying black people

229
00:08:53,120 --> 00:08:56,959
as scientific subjects of inferiority

230
00:08:56,959 --> 00:08:59,040
you know there's been a long history of

231
00:08:59,040 --> 00:09:01,519
understanding that the type of media

232
00:09:01,519 --> 00:09:04,160
that people experience is often used in

233
00:09:04,160 --> 00:09:06,640
incredibly dehumanizing ways

234
00:09:06,640 --> 00:09:10,080
for oppressed people part of the project

235
00:09:10,080 --> 00:09:11,120
of oppression

236
00:09:11,120 --> 00:09:14,399
is to misrepresent and dehumanize people

237
00:09:14,399 --> 00:09:17,920
and that of course um allows for people

238
00:09:17,920 --> 00:09:18,959
to

239
00:09:18,959 --> 00:09:22,000
um not only not be held accountable

240
00:09:22,000 --> 00:09:24,080
for acts of dehumanization because they

241
00:09:24,080 --> 00:09:26,080
become so profoundly normalized

242
00:09:26,080 --> 00:09:29,760
but also to legislate

243
00:09:29,760 --> 00:09:32,080
and

244
00:09:32,880 --> 00:09:36,080
organize economies in

245
00:09:36,080 --> 00:09:40,240
direct opposition to oppressed people

246
00:09:40,240 --> 00:09:43,040
so i was thinking about this in the

247
00:09:43,040 --> 00:09:44,480
context of something like

248
00:09:44,480 --> 00:09:46,640
google and eventually of course social

249
00:09:46,640 --> 00:09:49,519
media thinking about facebook and how

250
00:09:49,519 --> 00:09:51,640
that practice and that project of

251
00:09:51,640 --> 00:09:52,800
dehumanization

252
00:09:52,800 --> 00:09:54,720
that we could go all the way back to

253
00:09:54,720 --> 00:09:56,000
early science

254
00:09:56,000 --> 00:09:58,399
we could look in hollywood with the kind

255
00:09:58,399 --> 00:09:59,839
of first blockbuster

256
00:09:59,839 --> 00:10:02,000
film birth of a nation which is one of

257
00:10:02,000 --> 00:10:03,200
like a racist

258
00:10:03,200 --> 00:10:07,279
kkk propaganda film um all the way to

259
00:10:07,279 --> 00:10:10,560
the way in which black girls and women

260
00:10:10,560 --> 00:10:13,440
were represented with pornography as a

261
00:10:13,440 --> 00:10:15,279
primary representation in a

262
00:10:15,279 --> 00:10:17,600
google search when you looked for are

263
00:10:17,600 --> 00:10:19,279
for us

264
00:10:19,279 --> 00:10:21,680
all those practices are actually part of

265
00:10:21,680 --> 00:10:23,600
a systematic

266
00:10:23,600 --> 00:10:26,720
way of disenfranchising

267
00:10:26,720 --> 00:10:29,120
and legitimating the disenfranchisement

268
00:10:29,120 --> 00:10:30,959
and in some cases in the most extreme

269
00:10:30,959 --> 00:10:31,760
cases

270
00:10:31,760 --> 00:10:35,519
the genocide and extermination of people

271
00:10:35,519 --> 00:10:38,000
around the world and so that

272
00:10:38,000 --> 00:10:40,240
documentation is very important but also

273
00:10:40,240 --> 00:10:42,240
making these historical linkages so that

274
00:10:42,240 --> 00:10:44,000
we understand that things like racist

275
00:10:44,000 --> 00:10:45,200
propaganda

276
00:10:45,200 --> 00:10:47,279
are actually not new and they didn't get

277
00:10:47,279 --> 00:10:48,640
invented in social media

278
00:10:48,640 --> 00:10:51,120
like the proliferation of that these we

279
00:10:51,120 --> 00:10:53,120
our communities have been engaged

280
00:10:53,120 --> 00:10:56,480
in resisting that kind of dehumanization

281
00:10:56,480 --> 00:10:58,959
um for as long as we've been in contact

282
00:10:58,959 --> 00:11:00,959
with people who would seek to colonize

283
00:11:00,959 --> 00:11:04,320
our communities so that's how i entered

284
00:11:04,320 --> 00:11:06,480
this conversation is kind of at the just

285
00:11:06,480 --> 00:11:08,959
at the space and place of my own

286
00:11:08,959 --> 00:11:10,240
experience

287
00:11:10,240 --> 00:11:13,920
and um of course here we are it's been

288
00:11:13,920 --> 00:11:15,120
more than a decade

289
00:11:15,120 --> 00:11:16,800
of doing this kind of research and

290
00:11:16,800 --> 00:11:19,040
thinking about this and now of course i

291
00:11:19,040 --> 00:11:19,680
feel

292
00:11:19,680 --> 00:11:23,200
so much more hopeful because when i was

293
00:11:23,200 --> 00:11:26,480
first talking about this in 2010

294
00:11:26,480 --> 00:11:30,160
people would tell me this is not a thing

295
00:11:30,160 --> 00:11:32,399
what you're talking about technology

296
00:11:32,399 --> 00:11:33,680
cannot discriminate

297
00:11:33,680 --> 00:11:36,320
because technology is ultimately just

298
00:11:36,320 --> 00:11:37,440
computer code

299
00:11:37,440 --> 00:11:40,079
and computer code is just math and math

300
00:11:40,079 --> 00:11:41,120
can't be racist

301
00:11:41,120 --> 00:11:43,760
math can't be sexist math can't oppress

302
00:11:43,760 --> 00:11:46,560
and of course this is a ludicrous

303
00:11:46,560 --> 00:11:49,680
for formulation um i thought it was

304
00:11:49,680 --> 00:11:50,720
ludicrous then

305
00:11:50,720 --> 00:11:53,519
but now most of us understand that are

306
00:11:53,519 --> 00:11:54,959
interested in following

307
00:11:54,959 --> 00:11:57,440
what big technology companies are doing

308
00:11:57,440 --> 00:11:58,480
and also

309
00:11:58,480 --> 00:12:00,880
not brand name technology companies like

310
00:12:00,880 --> 00:12:01,600
palantir

311
00:12:01,600 --> 00:12:05,440
and other types of surveillance

312
00:12:05,440 --> 00:12:08,560
technologies so maybe that's just kind

313
00:12:08,560 --> 00:12:10,240
of like a way to enter

314
00:12:10,240 --> 00:12:14,000
and situate how i am interested in this

315
00:12:14,000 --> 00:12:16,560
these conversations ultimately to me i

316
00:12:16,560 --> 00:12:17,440
would say

317
00:12:17,440 --> 00:12:20,320
what i'm most hopeful about is that um

318
00:12:20,320 --> 00:12:21,680
not only is

319
00:12:21,680 --> 00:12:23,839
you know this fantastic conference

320
00:12:23,839 --> 00:12:25,519
rights con giving us

321
00:12:25,519 --> 00:12:28,480
an opportunity to talk openly and

322
00:12:28,480 --> 00:12:29,120
frankly

323
00:12:29,120 --> 00:12:33,120
about the escalating

324
00:12:33,120 --> 00:12:35,760
global inequality um the profound

325
00:12:35,760 --> 00:12:37,279
economic inequality

326
00:12:37,279 --> 00:12:40,480
that is around us and that the tech

327
00:12:40,480 --> 00:12:41,040
industry

328
00:12:41,040 --> 00:12:44,480
is also implicated in exacerbating

329
00:12:44,480 --> 00:12:46,399
but that we are truly on the precipice

330
00:12:46,399 --> 00:12:48,320
of the watching

331
00:12:48,320 --> 00:12:51,760
the real time collapse of modern liberal

332
00:12:51,760 --> 00:12:53,200
democracies

333
00:12:53,200 --> 00:12:56,240
around the world and who's paying the

334
00:12:56,240 --> 00:12:57,680
price

335
00:12:57,680 --> 00:13:00,079
are the most oppressed people in those

336
00:13:00,079 --> 00:13:01,120
countries

337
00:13:01,120 --> 00:13:03,360
and i think that that we have to keep

338
00:13:03,360 --> 00:13:04,639
our eye on the

339
00:13:04,639 --> 00:13:07,519
prize here of thinking about what's

340
00:13:07,519 --> 00:13:08,480
possible

341
00:13:08,480 --> 00:13:11,200
how might we reimagine the future as we

342
00:13:11,200 --> 00:13:12,160
always have

343
00:13:12,160 --> 00:13:14,480
because it has been about reimagining

344
00:13:14,480 --> 00:13:16,480
the end of the transatlantic slave

345
00:13:16,480 --> 00:13:19,600
trade or keeping our eye on imagining

346
00:13:19,600 --> 00:13:22,800
um the end of chattel slavery or the end

347
00:13:22,800 --> 00:13:24,639
of jim crow i mean these are things that

348
00:13:24,639 --> 00:13:25,360
are

349
00:13:25,360 --> 00:13:28,399
specific to you know my family's

350
00:13:28,399 --> 00:13:30,639
history in the united states but i think

351
00:13:30,639 --> 00:13:31,519
these are

352
00:13:31,519 --> 00:13:35,279
um it's in our imagining our way out of

353
00:13:35,279 --> 00:13:38,240
those things that we can remember

354
00:13:38,240 --> 00:13:40,000
there's a lot we can be doing now

355
00:13:40,000 --> 00:13:42,720
to imagine a future that is not

356
00:13:42,720 --> 00:13:43,519
organized

357
00:13:43,519 --> 00:13:48,240
the way we're organized today

358
00:13:48,240 --> 00:13:50,480
uh i think that's so important because

359
00:13:50,480 --> 00:13:52,240
what you're saying because i think that

360
00:13:52,240 --> 00:13:56,000
um you know i i've i felt so often that

361
00:13:56,000 --> 00:13:58,880
in the way that you created space um

362
00:13:58,880 --> 00:13:59,440
through

363
00:13:59,440 --> 00:14:01,440
black feminist scholarship for what it

364
00:14:01,440 --> 00:14:02,720
meant to apply

365
00:14:02,720 --> 00:14:05,199
the politics of intersectionality to

366
00:14:05,199 --> 00:14:07,440
better understand the structural

367
00:14:07,440 --> 00:14:09,519
and implicit bias of these text

368
00:14:09,519 --> 00:14:10,720
structures and

369
00:14:10,720 --> 00:14:14,240
the company cultures of big tech

370
00:14:14,240 --> 00:14:16,079
was so critical i think for other

371
00:14:16,079 --> 00:14:17,920
marginalized communities and

372
00:14:17,920 --> 00:14:19,680
you know in my context like when we're

373
00:14:19,680 --> 00:14:21,600
talking about decolonization

374
00:14:21,600 --> 00:14:23,600
we actually first start with this idea

375
00:14:23,600 --> 00:14:25,120
of deep romanization

376
00:14:25,120 --> 00:14:26,560
which is that we're looking at the

377
00:14:26,560 --> 00:14:29,680
foundations of structural exclusion in

378
00:14:29,680 --> 00:14:31,680
the subcontinent being grounded

379
00:14:31,680 --> 00:14:34,320
in the violent system of caste and you

380
00:14:34,320 --> 00:14:35,680
know it's completely

381
00:14:35,680 --> 00:14:38,240
expected that if you have a system of

382
00:14:38,240 --> 00:14:40,000
oppression that is thousands of years

383
00:14:40,000 --> 00:14:40,560
old

384
00:14:40,560 --> 00:14:43,360
that would find itself to digitize and

385
00:14:43,360 --> 00:14:44,079
make itself

386
00:14:44,079 --> 00:14:47,120
into the culture of the tech that we

387
00:14:47,120 --> 00:14:49,040
start to use because all tech is is a

388
00:14:49,040 --> 00:14:49,680
tool

389
00:14:49,680 --> 00:14:52,240
tech is not a utopian vision tech is not

390
00:14:52,240 --> 00:14:53,600
going to bring forth the

391
00:14:53,600 --> 00:14:56,079
the next era tech is simply a tool by

392
00:14:56,079 --> 00:14:57,680
the people that design it

393
00:14:57,680 --> 00:15:00,240
and and i think what's so profound about

394
00:15:00,240 --> 00:15:01,920
um you know some of the things that you

395
00:15:01,920 --> 00:15:02,320
said

396
00:15:02,320 --> 00:15:05,519
is that i feel that in some ways like

397
00:15:05,519 --> 00:15:06,079
when

398
00:15:06,079 --> 00:15:09,440
when people put um you know

399
00:15:09,440 --> 00:15:12,160
uh theorists of color and queer

400
00:15:12,160 --> 00:15:13,040
theorists

401
00:15:13,040 --> 00:15:15,680
and theorists from the global south into

402
00:15:15,680 --> 00:15:17,199
a cassandra position

403
00:15:17,199 --> 00:15:19,120
where we're seeing the problems from

404
00:15:19,120 --> 00:15:21,040
being the victims of the problems or

405
00:15:21,040 --> 00:15:21,600
from

406
00:15:21,600 --> 00:15:23,199
you know experiencing the structural

407
00:15:23,199 --> 00:15:25,600
exclusion that comes from those problems

408
00:15:25,600 --> 00:15:27,920
as opposed to opening us up to be the

409
00:15:27,920 --> 00:15:29,279
solution makers

410
00:15:29,279 --> 00:15:31,759
the co-designers that can break through

411
00:15:31,759 --> 00:15:33,680
flawed business models that can bake

412
00:15:33,680 --> 00:15:34,320
through

413
00:15:34,320 --> 00:15:37,279
um the questions of bias what happens is

414
00:15:37,279 --> 00:15:37,920
is that

415
00:15:37,920 --> 00:15:41,440
we become the test the testing ground

416
00:15:41,440 --> 00:15:43,120
for violent systems that end up

417
00:15:43,120 --> 00:15:46,160
upending all of society and this is so

418
00:15:46,160 --> 00:15:46,800
poignant

419
00:15:46,800 --> 00:15:49,519
in the subcontinent because you know for

420
00:15:49,519 --> 00:15:51,199
for many people here that are

421
00:15:51,199 --> 00:15:53,839
of indian descent we are in a time of

422
00:15:53,839 --> 00:15:55,839
digital genocide

423
00:15:55,839 --> 00:15:58,720
what we saw in the conditions of india

424
00:15:58,720 --> 00:16:00,800
was because of companies like facebook

425
00:16:00,800 --> 00:16:01,920
who entered the market

426
00:16:01,920 --> 00:16:04,320
you know around 2011 and they had their

427
00:16:04,320 --> 00:16:06,000
first mass atrocity

428
00:16:06,000 --> 00:16:09,040
in india in 2013 instead of them

429
00:16:09,040 --> 00:16:11,360
stopping operations

430
00:16:11,360 --> 00:16:13,120
and doing a human rights audit

431
00:16:13,120 --> 00:16:14,800
assessment or talking about

432
00:16:14,800 --> 00:16:23,839
what happened

433
00:16:28,320 --> 00:16:32,480
um tomorrow you froze for a moment um

434
00:16:32,480 --> 00:16:33,759
at a really crucial moment we were

435
00:16:33,759 --> 00:16:36,720
talking about 2013 um

436
00:16:36,720 --> 00:16:39,839
facebook amplified um

437
00:16:39,839 --> 00:16:42,000
mass murders that were happening and

438
00:16:42,000 --> 00:16:44,000
facebook's inability to

439
00:16:44,000 --> 00:16:46,399
learn from that moment by proactively

440
00:16:46,399 --> 00:16:48,720
doing a human rights

441
00:16:48,720 --> 00:16:51,440
audit or assessment and then shifting

442
00:16:51,440 --> 00:16:52,079
from

443
00:16:52,079 --> 00:16:54,800
shifting practices from that hey guys

444
00:16:54,800 --> 00:16:55,920
i'm back

445
00:16:55,920 --> 00:16:59,199
are you guys able to hear me yes

446
00:16:59,199 --> 00:17:01,120
okay thank you guys uh right live in

447
00:17:01,120 --> 00:17:03,279
process this is uh this is microsoft

448
00:17:03,279 --> 00:17:04,000
teams

449
00:17:04,000 --> 00:17:05,760
so in any case um i think the thing that

450
00:17:05,760 --> 00:17:07,760
was so intense was

451
00:17:07,760 --> 00:17:10,880
in the face of um that massive failure

452
00:17:10,880 --> 00:17:13,280
they leaned into this process and they

453
00:17:13,280 --> 00:17:13,919
basically

454
00:17:13,919 --> 00:17:16,319
polarized the environment so much so

455
00:17:16,319 --> 00:17:18,720
that in the beginning of 2019

456
00:17:18,720 --> 00:17:21,039
we saw the citizenship amendment act

457
00:17:21,039 --> 00:17:22,240
pass in india

458
00:17:22,240 --> 00:17:25,280
which basically opened the stage for

459
00:17:25,280 --> 00:17:27,599
the largest genocidal project in world

460
00:17:27,599 --> 00:17:28,799
history

461
00:17:28,799 --> 00:17:30,400
and that's what we were dealing with

462
00:17:30,400 --> 00:17:32,559
before the pandemic hit

463
00:17:32,559 --> 00:17:35,600
so these questions of how we build hope

464
00:17:35,600 --> 00:17:37,840
in the face of increased polarization

465
00:17:37,840 --> 00:17:39,280
and structural

466
00:17:39,280 --> 00:17:42,160
um bias in the technology that we use

467
00:17:42,160 --> 00:17:44,000
that abets this you know

468
00:17:44,000 --> 00:17:47,600
um you know uh the erosion of democracy

469
00:17:47,600 --> 00:17:48,799
is so critical

470
00:17:48,799 --> 00:17:51,039
and i find that so many of the activists

471
00:17:51,039 --> 00:17:53,520
and the and the community of rightscon

472
00:17:53,520 --> 00:17:55,440
are so effective at documenting the

473
00:17:55,440 --> 00:17:57,440
problem if you talk to any of the folks

474
00:17:57,440 --> 00:17:59,520
here many of them have spent hours and

475
00:17:59,520 --> 00:18:00,960
hours and hours

476
00:18:00,960 --> 00:18:02,640
have come you know spent years

477
00:18:02,640 --> 00:18:04,640
developing data sets to try to move

478
00:18:04,640 --> 00:18:07,039
these companies to do the right thing

479
00:18:07,039 --> 00:18:08,880
and yet what we're doing is often

480
00:18:08,880 --> 00:18:10,880
documenting our own demise

481
00:18:10,880 --> 00:18:12,640
because we're invested to document the

482
00:18:12,640 --> 00:18:14,960
problem but not to build the solutions

483
00:18:14,960 --> 00:18:17,840
and sasha i would love to bring um your

484
00:18:17,840 --> 00:18:19,200
voice into this conversation

485
00:18:19,200 --> 00:18:20,480
particularly with the work

486
00:18:20,480 --> 00:18:22,480
that you've done in terms of thinking

487
00:18:22,480 --> 00:18:24,960
about vision at the point of violence

488
00:18:24,960 --> 00:18:26,640
especially with your work around design

489
00:18:26,640 --> 00:18:28,160
justice and i'm wondering if you could

490
00:18:28,160 --> 00:18:29,200
speak to

491
00:18:29,200 --> 00:18:31,840
how do we start to move beyond um the

492
00:18:31,840 --> 00:18:33,919
paralysis that comes from

493
00:18:33,919 --> 00:18:35,600
the violence that we're experiencing

494
00:18:35,600 --> 00:18:39,678
into creating and designing around hope

495
00:18:40,480 --> 00:18:43,200
thanks tamari and yeah it's such a

496
00:18:43,200 --> 00:18:45,039
pleasure to be in conversation with you

497
00:18:45,039 --> 00:18:46,400
and sophia

498
00:18:46,400 --> 00:18:49,200
um i want to also begin with a land

499
00:18:49,200 --> 00:18:50,400
acknowledgement

500
00:18:50,400 --> 00:18:53,600
um so i'm living and working on the

501
00:18:53,600 --> 00:18:56,640
unseated lands of the massachusetts the

502
00:18:56,640 --> 00:18:59,840
pawtucket and the wampanoag peoples

503
00:18:59,840 --> 00:19:03,039
in the boston area

504
00:19:03,440 --> 00:19:04,960
and i think that that question about how

505
00:19:04,960 --> 00:19:07,440
do we reimagine

506
00:19:07,440 --> 00:19:11,039
our futures

507
00:19:11,039 --> 00:19:13,440
through a lens of hope even as we're

508
00:19:13,440 --> 00:19:14,960
busy

509
00:19:14,960 --> 00:19:19,600
documenting our own erasure

510
00:19:19,679 --> 00:19:22,240
is a really difficult one

511
00:19:22,240 --> 00:19:23,520
[Music]

512
00:19:23,520 --> 00:19:25,840
i would say i would reach back to some

513
00:19:25,840 --> 00:19:27,039
of the work

514
00:19:27,039 --> 00:19:29,360
that actually led me to me and you to

515
00:19:29,360 --> 00:19:30,240
first encounter

516
00:19:30,240 --> 00:19:34,360
each other timuri so um back around

517
00:19:34,360 --> 00:19:38,960
2003 2004 when the indie media network

518
00:19:38,960 --> 00:19:41,120
um was still going really strong so

519
00:19:41,120 --> 00:19:42,320
indie media was

520
00:19:42,320 --> 00:19:44,960
a transnational network of people using

521
00:19:44,960 --> 00:19:47,039
free software to create

522
00:19:47,039 --> 00:19:49,679
kind of diy news network for

523
00:19:49,679 --> 00:19:51,440
self-documenting the social movements of

524
00:19:51,440 --> 00:19:52,960
the time in particular

525
00:19:52,960 --> 00:19:54,799
the global justice movement or the

526
00:19:54,799 --> 00:19:57,280
anti-corporate globalization movement

527
00:19:57,280 --> 00:20:00,080
that was highly inspired by the

528
00:20:00,080 --> 00:20:01,679
zapatista movement

529
00:20:01,679 --> 00:20:04,480
in southern mexico and by subcomandante

530
00:20:04,480 --> 00:20:05,600
marcos's

531
00:20:05,600 --> 00:20:08,640
invitation for us to create a world

532
00:20:08,640 --> 00:20:10,320
where many worlds could fit and to

533
00:20:10,320 --> 00:20:11,039
create

534
00:20:11,039 --> 00:20:12,720
a sort of international communication

535
00:20:12,720 --> 00:20:14,240
network

536
00:20:14,240 --> 00:20:17,200
to tell to tell our own stories so we

537
00:20:17,200 --> 00:20:19,200
met during that time

538
00:20:19,200 --> 00:20:22,720
as kind of activists and hackers many of

539
00:20:22,720 --> 00:20:23,280
whom

540
00:20:23,280 --> 00:20:25,760
came from an anti-authoritarian left

541
00:20:25,760 --> 00:20:27,039
tradition but also

542
00:20:27,039 --> 00:20:29,440
linked to indigenous rights movements

543
00:20:29,440 --> 00:20:30,799
linked to the labor movement

544
00:20:30,799 --> 00:20:32,840
linked to environmental movements and

545
00:20:32,840 --> 00:20:34,159
others

546
00:20:34,159 --> 00:20:36,480
were organizing to figure out how we

547
00:20:36,480 --> 00:20:37,760
could use this

548
00:20:37,760 --> 00:20:40,480
tool that kind of seemed new at the time

549
00:20:40,480 --> 00:20:43,360
that not a lot of people had access to

550
00:20:43,360 --> 00:20:46,480
but the the net became something where

551
00:20:46,480 --> 00:20:48,159
we started to say well we could

552
00:20:48,159 --> 00:20:49,760
we could document our stories we could

553
00:20:49,760 --> 00:20:51,200
document those struggles

554
00:20:51,200 --> 00:20:52,960
we could circulate those struggles more

555
00:20:52,960 --> 00:20:54,799
rapidly and

556
00:20:54,799 --> 00:20:57,919
we thought that we could jump around or

557
00:20:57,919 --> 00:21:01,360
between the cracks of the broadcast

558
00:21:01,360 --> 00:21:04,559
and print media you know of the time

559
00:21:04,559 --> 00:21:07,039
and there were a lot of beautiful things

560
00:21:07,039 --> 00:21:08,799
that happened during that time

561
00:21:08,799 --> 00:21:10,000
there were a lot of connections that

562
00:21:10,000 --> 00:21:11,600
were made there were a lot of networks

563
00:21:11,600 --> 00:21:12,320
of

564
00:21:12,320 --> 00:21:14,320
people more than anything else more than

565
00:21:14,320 --> 00:21:16,080
the tools or the technologies that we

566
00:21:16,080 --> 00:21:17,200
created together

567
00:21:17,200 --> 00:21:19,760
because those didn't necessarily last

568
00:21:19,760 --> 00:21:21,679
you know the open publishing sites that

569
00:21:21,679 --> 00:21:23,520
we innovated at the time

570
00:21:23,520 --> 00:21:25,760
quickly became obsolete or they became

571
00:21:25,760 --> 00:21:27,520
captured or appropriated

572
00:21:27,520 --> 00:21:29,440
by venture capitalists who figured out

573
00:21:29,440 --> 00:21:31,039
how to turn them into

574
00:21:31,039 --> 00:21:33,760
profitable platforms funded by ad

575
00:21:33,760 --> 00:21:35,679
dollars and by packaging consumer

576
00:21:35,679 --> 00:21:37,120
eyeballs and through the model that we

577
00:21:37,120 --> 00:21:38,320
now talk about is

578
00:21:38,320 --> 00:21:40,720
surveillance capitalism but we created a

579
00:21:40,720 --> 00:21:42,640
lot of those things we created a lot of

580
00:21:42,640 --> 00:21:44,400
those tools and then they were

581
00:21:44,400 --> 00:21:46,960
taken from us because that's the cycle

582
00:21:46,960 --> 00:21:47,840
of

583
00:21:47,840 --> 00:21:49,840
capitalist appropriation of

584
00:21:49,840 --> 00:21:51,520
community-led innovation

585
00:21:51,520 --> 00:21:53,360
that operates not only in the media and

586
00:21:53,360 --> 00:21:55,120
information sector but it actually

587
00:21:55,120 --> 00:21:56,960
operates everywhere the history of

588
00:21:56,960 --> 00:21:58,799
capitalism is the history

589
00:21:58,799 --> 00:22:02,320
of people taking and owning

590
00:22:02,320 --> 00:22:04,799
human beings and bodies and chattel

591
00:22:04,799 --> 00:22:05,520
slavery

592
00:22:05,520 --> 00:22:08,240
and taking and owning the earth and the

593
00:22:08,240 --> 00:22:08,720
land

594
00:22:08,720 --> 00:22:10,880
and displacing and committing genocide

595
00:22:10,880 --> 00:22:12,720
upon indigenous peoples to take

596
00:22:12,720 --> 00:22:16,159
control and taking and owning ideas

597
00:22:16,159 --> 00:22:17,919
uh and turning them into something

598
00:22:17,919 --> 00:22:19,840
that's profitable only for

599
00:22:19,840 --> 00:22:21,840
those who already have access to capital

600
00:22:21,840 --> 00:22:23,520
so again just sort of locating that

601
00:22:23,520 --> 00:22:24,400
history

602
00:22:24,400 --> 00:22:26,799
of community-led socio-technical

603
00:22:26,799 --> 00:22:27,840
innovation

604
00:22:27,840 --> 00:22:31,200
that actually generated these ideas that

605
00:22:31,200 --> 00:22:32,400
came to be

606
00:22:32,400 --> 00:22:34,320
known as social media it came to be

607
00:22:34,320 --> 00:22:36,000
known as the platforms that we're

608
00:22:36,000 --> 00:22:38,320
all using now want to locate that within

609
00:22:38,320 --> 00:22:40,240
that much larger history

610
00:22:40,240 --> 00:22:43,600
of a system that uh literally

611
00:22:43,600 --> 00:22:45,760
is about appropriating people's labor

612
00:22:45,760 --> 00:22:48,080
time and bodies as well as

613
00:22:48,080 --> 00:22:51,120
the planet earth

614
00:22:51,120 --> 00:22:53,600
and and destroying all of those things

615
00:22:53,600 --> 00:22:56,480
in the service of an abstracted idea

616
00:22:56,480 --> 00:22:59,440
that then lets people who exist at

617
00:22:59,440 --> 00:23:00,320
intersections

618
00:23:00,320 --> 00:23:03,760
or in bodies that have

619
00:23:03,760 --> 00:23:06,799
structural privilege get more access and

620
00:23:06,799 --> 00:23:08,400
everyone else gets less

621
00:23:08,400 --> 00:23:10,960
so so we were creating all of these

622
00:23:10,960 --> 00:23:13,039
things there's a great story actually in

623
00:23:13,039 --> 00:23:14,159
the

624
00:23:14,159 --> 00:23:16,240
in my my book design justice i talk

625
00:23:16,240 --> 00:23:18,480
about different versions of the origins

626
00:23:18,480 --> 00:23:19,919
of twitter

627
00:23:19,919 --> 00:23:22,480
and the corporate pr version of that

628
00:23:22,480 --> 00:23:24,400
origin story which is that you know jack

629
00:23:24,400 --> 00:23:26,720
dorsey is sitting on a swing

630
00:23:26,720 --> 00:23:28,880
looking into a blue sky and suddenly has

631
00:23:28,880 --> 00:23:31,360
a brilliant flash of brilliance

632
00:23:31,360 --> 00:23:33,919
and then creates this uh this platform

633
00:23:33,919 --> 00:23:35,039
versus other

634
00:23:35,039 --> 00:23:37,280
stories about how twitter came to be

635
00:23:37,280 --> 00:23:39,760
that include the prehistory of the free

636
00:23:39,760 --> 00:23:42,880
open source project text mob

637
00:23:42,880 --> 00:23:45,520
that was created for activists to better

638
00:23:45,520 --> 00:23:46,320
coordinate

639
00:23:46,320 --> 00:23:49,520
using group text messaging to help

640
00:23:49,520 --> 00:23:52,159
do direct action and shut down street

641
00:23:52,159 --> 00:23:53,679
intersections in new york city during

642
00:23:53,679 --> 00:23:55,520
the republican national convention

643
00:23:55,520 --> 00:23:57,520
and how text mob became sort of demo

644
00:23:57,520 --> 00:24:00,320
design um for what would later

645
00:24:00,320 --> 00:24:03,120
um you know become twitter so we see

646
00:24:03,120 --> 00:24:05,039
that over and over and over again if we

647
00:24:05,039 --> 00:24:06,960
look back through the history

648
00:24:06,960 --> 00:24:10,080
of of technology and media technology

649
00:24:10,080 --> 00:24:12,240
and of social media in particular

650
00:24:12,240 --> 00:24:16,080
um now

651
00:24:16,080 --> 00:24:19,039
another great example of that would be a

652
00:24:19,039 --> 00:24:19,600
signal

653
00:24:19,600 --> 00:24:21,679
and the emergence of end-to-end

654
00:24:21,679 --> 00:24:23,279
encrypted messaging is something that

655
00:24:23,279 --> 00:24:24,880
really came out of

656
00:24:24,880 --> 00:24:28,320
anarchist hacker networks and

657
00:24:28,320 --> 00:24:30,880
then the protocol gets adopted by

658
00:24:30,880 --> 00:24:32,000
whatsapp and suddenly

659
00:24:32,000 --> 00:24:34,559
is available to you know over a billion

660
00:24:34,559 --> 00:24:35,919
people at the time

661
00:24:35,919 --> 00:24:38,559
um of course whatsup still shares

662
00:24:38,559 --> 00:24:39,600
metadata

663
00:24:39,600 --> 00:24:41,200
so that's one of the most important

664
00:24:41,200 --> 00:24:43,120
aspects of what uh

665
00:24:43,120 --> 00:24:44,960
the surveillance state likes to do and

666
00:24:44,960 --> 00:24:47,120
the surveillance state linked to

667
00:24:47,120 --> 00:24:50,159
um capitalist companies they work hand

668
00:24:50,159 --> 00:24:51,120
in hand

669
00:24:51,120 --> 00:24:53,520
and the metadata about who's talking to

670
00:24:53,520 --> 00:24:56,159
who and when and for how long

671
00:24:56,159 --> 00:24:57,840
is in a lot of ways what they need to

672
00:24:57,840 --> 00:24:59,279
track

673
00:24:59,279 --> 00:25:01,279
both for targeted ads but also for

674
00:25:01,279 --> 00:25:02,320
targeted drones

675
00:25:02,320 --> 00:25:05,120
right so i also think we want to not

676
00:25:05,120 --> 00:25:07,039
decouple the conversation about

677
00:25:07,039 --> 00:25:10,320
tracking and targeting from the

678
00:25:10,320 --> 00:25:14,720
relevance of the understanding of um

679
00:25:14,720 --> 00:25:16,159
sort of sophisticated surveillance

680
00:25:16,159 --> 00:25:18,559
apparatus of the continued project of

681
00:25:18,559 --> 00:25:21,760
u.s military empire military bases

682
00:25:21,760 --> 00:25:22,880
around the world

683
00:25:22,880 --> 00:25:24,799
targeted assassinations and drone

684
00:25:24,799 --> 00:25:26,320
strikes

685
00:25:26,320 --> 00:25:28,559
systematic death on black and brown

686
00:25:28,559 --> 00:25:30,799
bodies in order to maintain the world

687
00:25:30,799 --> 00:25:32,799
petroleum economy these things are not

688
00:25:32,799 --> 00:25:34,240
separate they're linked

689
00:25:34,240 --> 00:25:37,039
the same firms develop them microsoft

690
00:25:37,039 --> 00:25:37,840
azure

691
00:25:37,840 --> 00:25:39,919
as the cloud contract for the department

692
00:25:39,919 --> 00:25:40,960
of defense

693
00:25:40,960 --> 00:25:44,159
and so on and so on and so forth but

694
00:25:44,159 --> 00:25:46,559
in the midst of all of that even as we

695
00:25:46,559 --> 00:25:48,000
create these new tools

696
00:25:48,000 --> 00:25:50,480
and they emerge from movement spaces and

697
00:25:50,480 --> 00:25:52,640
from community spaces

698
00:25:52,640 --> 00:25:55,120
just as much as they emerge from

699
00:25:55,120 --> 00:25:56,799
academic institutions or

700
00:25:56,799 --> 00:26:00,000
research sites or corporate r

701
00:26:00,000 --> 00:26:03,120
d departments um

702
00:26:03,120 --> 00:26:05,840
there's a cycle where we generate and

703
00:26:05,840 --> 00:26:06,400
create

704
00:26:06,400 --> 00:26:07,840
and then there's appropriation that

705
00:26:07,840 --> 00:26:10,320
happens and then we

706
00:26:10,320 --> 00:26:12,880
come up with new possibilities and we

707
00:26:12,880 --> 00:26:15,279
find new work arounds and we hack

708
00:26:15,279 --> 00:26:17,520
new possible modes of interacting with

709
00:26:17,520 --> 00:26:18,400
one another

710
00:26:18,400 --> 00:26:21,919
and of creating and sharing media so

711
00:26:21,919 --> 00:26:24,480
i don't i see hope in the fact that

712
00:26:24,480 --> 00:26:25,600
there's

713
00:26:25,600 --> 00:26:28,240
constant creation and creativity and

714
00:26:28,240 --> 00:26:30,159
innovation that's happening

715
00:26:30,159 --> 00:26:33,120
um at the sites of the most

716
00:26:33,120 --> 00:26:35,120
marginalization and oppression

717
00:26:35,120 --> 00:26:38,400
there's always resistance and

718
00:26:38,400 --> 00:26:41,200
there's you know where wherever in

719
00:26:41,200 --> 00:26:43,360
allied media projects network and allied

720
00:26:43,360 --> 00:26:44,799
media conference network we always talk

721
00:26:44,799 --> 00:26:45,760
about how

722
00:26:45,760 --> 00:26:47,440
you know wherever people are facing

723
00:26:47,440 --> 00:26:50,000
oppression people are always also

724
00:26:50,000 --> 00:26:52,320
already creating solutions and i think

725
00:26:52,320 --> 00:26:53,039
that

726
00:26:53,039 --> 00:26:56,000
that applies in the tech space as well

727
00:26:56,000 --> 00:26:57,120
um

728
00:26:57,120 --> 00:26:59,120
so that's that's how i think about that

729
00:26:59,120 --> 00:27:00,240
there's always

730
00:27:00,240 --> 00:27:03,520
hope and cracks and new innovations

731
00:27:03,520 --> 00:27:05,360
emerging around the edges

732
00:27:05,360 --> 00:27:07,600
even as those are always being scooped

733
00:27:07,600 --> 00:27:10,000
up and repackaged and resold back to

734
00:27:10,000 --> 00:27:10,799
people

735
00:27:10,799 --> 00:27:13,600
but that process is never done because

736
00:27:13,600 --> 00:27:14,480
they're

737
00:27:14,480 --> 00:27:17,520
you know the power of capital to take

738
00:27:17,520 --> 00:27:22,080
take on and take over um and profit from

739
00:27:22,080 --> 00:27:24,720
the creations of marginalized

740
00:27:24,720 --> 00:27:26,000
communities

741
00:27:26,000 --> 00:27:28,559
is never greater than the power of human

742
00:27:28,559 --> 00:27:29,520
beings

743
00:27:29,520 --> 00:27:32,799
to imagine a new possible world

744
00:27:32,799 --> 00:27:34,960
and i think that's such a powerful and

745
00:27:34,960 --> 00:27:36,240
you know place to

746
00:27:36,240 --> 00:27:38,399
you know really move this conversation

747
00:27:38,399 --> 00:27:39,600
into because

748
00:27:39,600 --> 00:27:41,679
you know i think as you have really kind

749
00:27:41,679 --> 00:27:44,480
of helped remind our audience you know

750
00:27:44,480 --> 00:27:46,640
in many ways the artifacts from

751
00:27:46,640 --> 00:27:48,640
community technology

752
00:27:48,640 --> 00:27:51,039
is both the the innovations in terms of

753
00:27:51,039 --> 00:27:53,039
process and visioning around these

754
00:27:53,039 --> 00:27:54,559
violent frontiers

755
00:27:54,559 --> 00:27:56,320
and the products and sometimes the

756
00:27:56,320 --> 00:27:57,600
products stay

757
00:27:57,600 --> 00:27:59,840
and sometimes they get lost but the

758
00:27:59,840 --> 00:28:02,000
possibilities of the process are

759
00:28:02,000 --> 00:28:04,880
actually the lineages we need to be able

760
00:28:04,880 --> 00:28:06,159
to imagine

761
00:28:06,159 --> 00:28:09,120
ourselves out of this particular moment

762
00:28:09,120 --> 00:28:10,880
and you know i think that you know

763
00:28:10,880 --> 00:28:12,399
sophia and bringing this you know

764
00:28:12,399 --> 00:28:14,080
conversation back to you

765
00:28:14,080 --> 00:28:16,320
i think that when we are looking at so

766
00:28:16,320 --> 00:28:18,159
much of the structural exclusion that's

767
00:28:18,159 --> 00:28:19,200
built into

768
00:28:19,200 --> 00:28:20,880
these algorithms particularly in the

769
00:28:20,880 --> 00:28:22,240
ways that people are starting to bring

770
00:28:22,240 --> 00:28:24,240
this conversation into a.i

771
00:28:24,240 --> 00:28:26,399
and the whole ethical ai model that

772
00:28:26,399 --> 00:28:28,159
people are talking about

773
00:28:28,159 --> 00:28:30,880
you know in many ways i feel that people

774
00:28:30,880 --> 00:28:31,440
are

775
00:28:31,440 --> 00:28:35,440
falling into a trap of wanting to

776
00:28:35,440 --> 00:28:38,559
accept the neoliberal half solution as

777
00:28:38,559 --> 00:28:40,559
opposed to accepting what is the truly

778
00:28:40,559 --> 00:28:42,399
visionary option here

779
00:28:42,399 --> 00:28:43,919
and and i'm wondering if you could speak

780
00:28:43,919 --> 00:28:45,360
to that particularly because i think

781
00:28:45,360 --> 00:28:46,559
there's a lot of people

782
00:28:46,559 --> 00:28:49,919
who are listening who are allies

783
00:28:49,919 --> 00:28:52,640
internal to these institutions you know

784
00:28:52,640 --> 00:28:53,120
because

785
00:28:53,120 --> 00:28:55,679
institutions whether it's big tech or

786
00:28:55,679 --> 00:28:58,720
intergovernmental organizations or

787
00:28:58,720 --> 00:29:01,279
you know venture capital institutions

788
00:29:01,279 --> 00:29:01,760
but

789
00:29:01,760 --> 00:29:03,919
you know are part of this business model

790
00:29:03,919 --> 00:29:05,760
that is is wrong

791
00:29:05,760 --> 00:29:07,520
you know these aren't just like big

792
00:29:07,520 --> 00:29:09,520
buildings there are people

793
00:29:09,520 --> 00:29:11,200
and not all of those people are

794
00:29:11,200 --> 00:29:12,880
ideologically aligned

795
00:29:12,880 --> 00:29:15,600
and sometimes all they need is a spark

796
00:29:15,600 --> 00:29:16,720
to think differently

797
00:29:16,720 --> 00:29:19,039
to open up to a greater liberatory

798
00:29:19,039 --> 00:29:20,080
possibility

799
00:29:20,080 --> 00:29:21,679
and so i'm wondering sophie if you could

800
00:29:21,679 --> 00:29:23,840
like help break down what is wrong about

801
00:29:23,840 --> 00:29:24,720
this model

802
00:29:24,720 --> 00:29:26,559
but also what are the visionary options

803
00:29:26,559 --> 00:29:29,039
that we have out of this

804
00:29:29,039 --> 00:29:32,000
yeah i love this framing because that's

805
00:29:32,000 --> 00:29:32,880
actually

806
00:29:32,880 --> 00:29:35,600
um the historical frame that we need

807
00:29:35,600 --> 00:29:36,960
which is to remember

808
00:29:36,960 --> 00:29:40,480
that for every social movement

809
00:29:40,480 --> 00:29:43,520
for justice around the world there was

810
00:29:43,520 --> 00:29:46,640
the person who made some sandwiches

811
00:29:46,640 --> 00:29:48,720
there was a person who let an activist

812
00:29:48,720 --> 00:29:50,720
sleep on their couch there was a person

813
00:29:50,720 --> 00:29:51,440
who

814
00:29:51,440 --> 00:29:53,840
gave somebody a ride someplace so

815
00:29:53,840 --> 00:29:54,880
everybody

816
00:29:54,880 --> 00:29:58,159
can really play an important

817
00:29:58,159 --> 00:30:00,559
part and it doesn't necessarily mean

818
00:30:00,559 --> 00:30:02,320
that you're going to be writing a book

819
00:30:02,320 --> 00:30:03,760
or that you're going to be on the front

820
00:30:03,760 --> 00:30:05,679
lines as an organizer

821
00:30:05,679 --> 00:30:07,600
always either and this is one of the

822
00:30:07,600 --> 00:30:09,440
reasons why we study the civil rights

823
00:30:09,440 --> 00:30:10,720
movement and other

824
00:30:10,720 --> 00:30:13,440
um power based movements because we have

825
00:30:13,440 --> 00:30:15,760
to understand that

826
00:30:15,760 --> 00:30:18,000
we actually do have agency and we do

827
00:30:18,000 --> 00:30:19,520
have the power to

828
00:30:19,520 --> 00:30:22,880
advance and move forward human rights

829
00:30:22,880 --> 00:30:27,360
and civil rights and anti-racist

830
00:30:29,360 --> 00:30:32,559
agendas efforts

831
00:30:32,559 --> 00:30:35,360
paradigms so i will say that one of the

832
00:30:35,360 --> 00:30:37,039
things that's been so interesting to

833
00:30:37,039 --> 00:30:37,600
watch

834
00:30:37,600 --> 00:30:40,320
is that and i think i look back at even

835
00:30:40,320 --> 00:30:42,159
my own writing and i think

836
00:30:42,159 --> 00:30:45,200
you know when i was saying something 10

837
00:30:45,200 --> 00:30:45,840
years ago

838
00:30:45,840 --> 00:30:48,880
like technology is

839
00:30:48,880 --> 00:30:51,919
a social practice it's not just a tool

840
00:30:51,919 --> 00:30:54,960
it's value-laden social practice that

841
00:30:54,960 --> 00:30:56,159
gets codified

842
00:30:56,159 --> 00:30:58,480
in different ways and that there has to

843
00:30:58,480 --> 00:30:59,440
be an

844
00:30:59,440 --> 00:31:02,640
ethics of justice tied to

845
00:31:02,640 --> 00:31:04,720
the way that we think about these kinds

846
00:31:04,720 --> 00:31:05,679
of projects

847
00:31:05,679 --> 00:31:08,960
because they transform society in so

848
00:31:08,960 --> 00:31:10,240
many different ways

849
00:31:10,240 --> 00:31:11,760
and this is where i think back you know

850
00:31:11,760 --> 00:31:13,760
i remember reading

851
00:31:13,760 --> 00:31:15,840
a million years ago when i was an

852
00:31:15,840 --> 00:31:17,840
undergrad in college i remember reading

853
00:31:17,840 --> 00:31:19,120
angela davis

854
00:31:19,120 --> 00:31:22,159
writing about the dishwasher and how the

855
00:31:22,159 --> 00:31:24,080
dishwasher was supposed to be this new

856
00:31:24,080 --> 00:31:25,440
liberatory tool

857
00:31:25,440 --> 00:31:27,200
for women right she and her feminist

858
00:31:27,200 --> 00:31:28,559
critique is that

859
00:31:28,559 --> 00:31:30,799
it didn't liberate us from washing

860
00:31:30,799 --> 00:31:32,480
dishes as women

861
00:31:32,480 --> 00:31:34,559
right it didn't liberate us in the

862
00:31:34,559 --> 00:31:35,679
domestic sphere

863
00:31:35,679 --> 00:31:38,799
of having to reproduce the labor market

864
00:31:38,799 --> 00:31:41,360
um what it did was raise the bar and

865
00:31:41,360 --> 00:31:42,960
make a higher standard

866
00:31:42,960 --> 00:31:45,200
of cleanliness that we all had to then

867
00:31:45,200 --> 00:31:46,480
adhere to so it made

868
00:31:46,480 --> 00:31:49,519
more work for us but people fancied it a

869
00:31:49,519 --> 00:31:50,159
tool

870
00:31:50,159 --> 00:31:52,480
um but it actually transformed social

871
00:31:52,480 --> 00:31:53,600
practice and

872
00:31:53,600 --> 00:31:56,880
in fact was part of a whole parcel of

873
00:31:56,880 --> 00:32:00,000
um appliances and and projects and

874
00:32:00,000 --> 00:32:03,679
consumerism that ensnared us

875
00:32:03,679 --> 00:32:06,720
even more um so i think that the reason

876
00:32:06,720 --> 00:32:07,279
why we

877
00:32:07,279 --> 00:32:10,640
have to kind of think about um

878
00:32:10,640 --> 00:32:12,320
what these technologies are doing and

879
00:32:12,320 --> 00:32:13,679
how we talk about them

880
00:32:13,679 --> 00:32:16,880
is very very important now

881
00:32:16,880 --> 00:32:20,960
when we talked a decade ago about

882
00:32:20,960 --> 00:32:23,760
that there were values embedded into

883
00:32:23,760 --> 00:32:25,039
these projects

884
00:32:25,039 --> 00:32:28,159
again that was highly illegible except

885
00:32:28,159 --> 00:32:31,360
to a kind of a small community of people

886
00:32:31,360 --> 00:32:33,600
activists and scholars who were thinking

887
00:32:33,600 --> 00:32:34,480
about that

888
00:32:34,480 --> 00:32:37,440
now that's a much more mainstream um

889
00:32:37,440 --> 00:32:38,320
concept

890
00:32:38,320 --> 00:32:42,480
so mainstream that we have ibm and

891
00:32:42,480 --> 00:32:46,159
um google declaring themselves

892
00:32:46,159 --> 00:32:49,919
ethical ai companies and running

893
00:32:49,919 --> 00:32:53,760
like super bowl ads for it so this is

894
00:32:53,760 --> 00:32:55,919
this is exactly the process that sasha

895
00:32:55,919 --> 00:32:57,919
is talking about which is this kind of

896
00:32:57,919 --> 00:32:58,960
capture

897
00:32:58,960 --> 00:33:01,360
um that happens and i think this is part

898
00:33:01,360 --> 00:33:03,200
of what we're dealing with right now

899
00:33:03,200 --> 00:33:06,320
is a moment of full-blown capture

900
00:33:06,320 --> 00:33:08,320
of this conversation and

901
00:33:08,320 --> 00:33:10,399
re-incorporating it back into

902
00:33:10,399 --> 00:33:14,159
the interests of the power

903
00:33:14,159 --> 00:33:17,760
holders in society um so we're gonna

904
00:33:17,760 --> 00:33:18,640
have to be

905
00:33:18,640 --> 00:33:21,760
we need more vocabulary words um the

906
00:33:21,760 --> 00:33:23,519
words we used 10 years ago aren't the

907
00:33:23,519 --> 00:33:24,000
words we

908
00:33:24,000 --> 00:33:26,240
can use today because now they've been

909
00:33:26,240 --> 00:33:28,080
distorted they've been defamed

910
00:33:28,080 --> 00:33:30,880
they've been de-politicized now what

911
00:33:30,880 --> 00:33:33,039
people are interested in doing

912
00:33:33,039 --> 00:33:34,960
is and i see this with computer science

913
00:33:34,960 --> 00:33:36,880
students that come into my classroom

914
00:33:36,880 --> 00:33:38,960
at ucla you know they want to make

915
00:33:38,960 --> 00:33:40,240
better algorithms

916
00:33:40,240 --> 00:33:42,000
they want to make better ai they want to

917
00:33:42,000 --> 00:33:44,559
make ethical algorithms and ethical ai

918
00:33:44,559 --> 00:33:47,440
and and they're interested in the techno

919
00:33:47,440 --> 00:33:48,640
solutionism

920
00:33:48,640 --> 00:33:50,559
rather than thinking about what does it

921
00:33:50,559 --> 00:33:52,080
mean that these

922
00:33:52,080 --> 00:33:54,960
um that this entire sector is so

923
00:33:54,960 --> 00:33:56,559
profoundly implicated

924
00:33:56,559 --> 00:33:59,200
in undermining the project of

925
00:33:59,200 --> 00:34:00,799
multiracial democracy

926
00:34:00,799 --> 00:34:05,200
that is barely underway that um

927
00:34:05,200 --> 00:34:07,679
putting more resources on computer

928
00:34:07,679 --> 00:34:08,719
programming

929
00:34:08,719 --> 00:34:10,480
at the same time that we defund

930
00:34:10,480 --> 00:34:13,199
education we defund the media

931
00:34:13,199 --> 00:34:16,320
we defund every kind of public good

932
00:34:16,320 --> 00:34:19,839
that would help us develop a critical

933
00:34:19,839 --> 00:34:20,719
awareness

934
00:34:20,719 --> 00:34:22,719
and ability to resist these kinds of

935
00:34:22,719 --> 00:34:23,760
technologies

936
00:34:23,760 --> 00:34:27,440
is happening um so we have to

937
00:34:27,440 --> 00:34:29,839
remain creative and agile which i think

938
00:34:29,839 --> 00:34:30,960
people who

939
00:34:30,960 --> 00:34:34,079
are on the front lines of witnessing

940
00:34:34,079 --> 00:34:37,040
and experiencing the most harm are

941
00:34:37,040 --> 00:34:38,480
always thinking about

942
00:34:38,480 --> 00:34:41,599
ways to work our selves out of those

943
00:34:41,599 --> 00:34:43,199
conditions

944
00:34:43,199 --> 00:34:45,679
in fact that is also a feature of

945
00:34:45,679 --> 00:34:46,719
oppression

946
00:34:46,719 --> 00:34:49,839
is the impulse to be liberated

947
00:34:49,839 --> 00:34:52,320
from that oppression and i completely

948
00:34:52,320 --> 00:34:53,119
agree that this

949
00:34:53,119 --> 00:34:56,079
is um this is the energy that is

950
00:34:56,079 --> 00:34:57,359
actually going to take us

951
00:34:57,359 --> 00:34:59,359
forward one of the things that i think

952
00:34:59,359 --> 00:35:00,800
we're way past now

953
00:35:00,800 --> 00:35:03,839
is this desire for ethical ai i mean

954
00:35:03,839 --> 00:35:06,240
many of us who might have said and tried

955
00:35:06,240 --> 00:35:07,520
to make legible

956
00:35:07,520 --> 00:35:10,160
that there are ethical concerns there

957
00:35:10,160 --> 00:35:12,160
are concerns about injustice that are

958
00:35:12,160 --> 00:35:12,960
tied to

959
00:35:12,960 --> 00:35:16,160
the tech industry are now

960
00:35:16,160 --> 00:35:18,720
really far away from that conversation

961
00:35:18,720 --> 00:35:19,520
and saying

962
00:35:19,520 --> 00:35:21,119
some of these technologies should be

963
00:35:21,119 --> 00:35:23,920
abolished we should have an abolitionist

964
00:35:23,920 --> 00:35:24,720
stance

965
00:35:24,720 --> 00:35:26,960
toward many of these projects and

966
00:35:26,960 --> 00:35:28,160
companies

967
00:35:28,160 --> 00:35:31,920
um also there needs to be repair

968
00:35:31,920 --> 00:35:34,400
there needs to be restoration that's

969
00:35:34,400 --> 00:35:35,359
actually what

970
00:35:35,359 --> 00:35:38,079
is required now and i think about this

971
00:35:38,079 --> 00:35:38,640
you know

972
00:35:38,640 --> 00:35:41,920
um if exxon mobil has an oil spill

973
00:35:41,920 --> 00:35:45,040
and they damage the ocean

974
00:35:45,040 --> 00:35:47,280
and all the living creatures of the

975
00:35:47,280 --> 00:35:48,160
ocean and the

976
00:35:48,160 --> 00:35:51,359
people because the damage extends

977
00:35:51,359 --> 00:35:54,000
around the globe they must be

978
00:35:54,000 --> 00:35:55,920
responsible and accountable for cleaning

979
00:35:55,920 --> 00:35:56,560
it up

980
00:35:56,560 --> 00:35:59,680
and for repair and restoration and

981
00:35:59,680 --> 00:36:02,720
you know we need that uh

982
00:36:02,720 --> 00:36:06,160
you know times a thousand or more

983
00:36:06,160 --> 00:36:07,839
when we think about the way in which so

984
00:36:07,839 --> 00:36:09,599
many of these technologies are used and

985
00:36:09,599 --> 00:36:10,400
are implicated

986
00:36:10,400 --> 00:36:14,400
in the whole cell datification and

987
00:36:14,400 --> 00:36:17,280
predictive modeling that is about

988
00:36:17,280 --> 00:36:18,800
classifying every

989
00:36:18,800 --> 00:36:22,400
person and creature on the planet and

990
00:36:22,400 --> 00:36:25,280
creating pathways for opportunity for

991
00:36:25,280 --> 00:36:26,000
some

992
00:36:26,000 --> 00:36:28,640
and for closing opportunity for others

993
00:36:28,640 --> 00:36:30,800
and fully normalizing that through

994
00:36:30,800 --> 00:36:34,800
opaque technologies and automation

995
00:36:34,800 --> 00:36:36,320
and those are the stakes that's what's

996
00:36:36,320 --> 00:36:37,920
happening that is the moment we're

997
00:36:37,920 --> 00:36:38,800
living in

998
00:36:38,800 --> 00:36:41,839
and i think this is the thing that um of

999
00:36:41,839 --> 00:36:43,359
course you know

1000
00:36:43,359 --> 00:36:45,359
i know the three of us it keeps us up at

1001
00:36:45,359 --> 00:36:47,119
night um

1002
00:36:47,119 --> 00:36:49,599
and it is you know so i will just say it

1003
00:36:49,599 --> 00:36:50,160
is like

1004
00:36:50,160 --> 00:36:52,240
about diagnosing like because the

1005
00:36:52,240 --> 00:36:53,280
problem and the

1006
00:36:53,280 --> 00:36:56,640
the ground shifts too so we do have to

1007
00:36:56,640 --> 00:36:57,839
keep diagnosing

1008
00:36:57,839 --> 00:37:00,240
but in that diagnosis and documenting we

1009
00:37:00,240 --> 00:37:01,119
also

1010
00:37:01,119 --> 00:37:05,359
find places of resistance and

1011
00:37:05,359 --> 00:37:08,400
new language to describe the conditions

1012
00:37:08,400 --> 00:37:10,640
and new ways of organizing and

1013
00:37:10,640 --> 00:37:13,520
connecting and linking up and

1014
00:37:13,520 --> 00:37:16,640
you know and uh reimagining

1015
00:37:16,640 --> 00:37:19,200
and you know i have to say one of the

1016
00:37:19,200 --> 00:37:21,200
reasons why i think the tech sector

1017
00:37:21,200 --> 00:37:23,200
has so little imagination or its

1018
00:37:23,200 --> 00:37:25,520
imagination is really about

1019
00:37:25,520 --> 00:37:29,200
um domination um a complete lack of

1020
00:37:29,200 --> 00:37:30,160
regard

1021
00:37:30,160 --> 00:37:32,960
for um oppressed people around the world

1022
00:37:32,960 --> 00:37:33,359
like

1023
00:37:33,359 --> 00:37:36,640
just a inability to cohere

1024
00:37:36,640 --> 00:37:38,800
the work that they're doing um for some

1025
00:37:38,800 --> 00:37:40,400
people in some companies

1026
00:37:40,400 --> 00:37:43,200
is because um they don't have a

1027
00:37:43,200 --> 00:37:45,359
relationship to the lived experience

1028
00:37:45,359 --> 00:37:48,240
of oppression too and this is one of the

1029
00:37:48,240 --> 00:37:49,920
reasons why at a very minimal level

1030
00:37:49,920 --> 00:37:51,680
people want to see more diversity in the

1031
00:37:51,680 --> 00:37:53,920
companies because that would be a site

1032
00:37:53,920 --> 00:37:57,200
of resistance it would be voices in the

1033
00:37:57,200 --> 00:37:58,240
room to say

1034
00:37:58,240 --> 00:38:00,560
you can't do that that's illegal you're

1035
00:38:00,560 --> 00:38:01,599
breaking about

1036
00:38:01,599 --> 00:38:04,640
10 different civil rights laws with your

1037
00:38:04,640 --> 00:38:07,200
project or this is going to create you

1038
00:38:07,200 --> 00:38:08,640
know wide scale

1039
00:38:08,640 --> 00:38:11,760
um uh harm

1040
00:38:11,760 --> 00:38:14,400
um so going back to your original

1041
00:38:14,400 --> 00:38:15,359
question i mean

1042
00:38:15,359 --> 00:38:18,160
yes of course we need people in every

1043
00:38:18,160 --> 00:38:19,119
room

1044
00:38:19,119 --> 00:38:21,599
in the world in every conversation

1045
00:38:21,599 --> 00:38:22,880
foregrounding

1046
00:38:22,880 --> 00:38:26,079
the concerns about justice and fairness

1047
00:38:26,079 --> 00:38:29,520
and equity and repair and restoration

1048
00:38:29,520 --> 00:38:31,440
and i think that it will be people in

1049
00:38:31,440 --> 00:38:32,640
companies

1050
00:38:32,640 --> 00:38:36,000
um who will also create pressure

1051
00:38:36,000 --> 00:38:38,560
um in those conversations too even if

1052
00:38:38,560 --> 00:38:40,720
it's just to be whistleblowers

1053
00:38:40,720 --> 00:38:44,160
or to be people who walk out and say

1054
00:38:44,160 --> 00:38:46,400
we're not gonna put our labor and our

1055
00:38:46,400 --> 00:38:48,079
intellect in service of those kinds of

1056
00:38:48,079 --> 00:38:48,720
projects

1057
00:38:48,720 --> 00:38:51,920
that's important work too

1058
00:38:51,920 --> 00:38:54,960
and i think this is so important to to

1059
00:38:54,960 --> 00:38:56,160
hold because

1060
00:38:56,160 --> 00:38:57,680
you know so much of what you're talking

1061
00:38:57,680 --> 00:39:00,560
about when our ideas and our movements

1062
00:39:00,560 --> 00:39:02,320
become cannibalized by

1063
00:39:02,320 --> 00:39:05,359
surveillance capitalism and the need for

1064
00:39:05,359 --> 00:39:08,480
restoration um and repair after the harm

1065
00:39:08,480 --> 00:39:09,200
that has been

1066
00:39:09,200 --> 00:39:12,079
you know um conducted on our our

1067
00:39:12,079 --> 00:39:13,200
communities

1068
00:39:13,200 --> 00:39:15,200
you know it's it's so much about the

1069
00:39:15,200 --> 00:39:16,560
language of trauma

1070
00:39:16,560 --> 00:39:19,280
and the spirals of trauma where we we

1071
00:39:19,280 --> 00:39:19,680
just

1072
00:39:19,680 --> 00:39:23,119
see ourselves having to to to come from

1073
00:39:23,119 --> 00:39:25,920
one violence to another and and i often

1074
00:39:25,920 --> 00:39:26,480
think that

1075
00:39:26,480 --> 00:39:30,160
some of what we need to do is to stop

1076
00:39:30,160 --> 00:39:32,800
you know i think we need to just pause

1077
00:39:32,800 --> 00:39:33,440
and

1078
00:39:33,440 --> 00:39:36,480
not just look at this moment in time

1079
00:39:36,480 --> 00:39:39,599
but be able to say enough

1080
00:39:39,599 --> 00:39:41,280
we're not going to be able to put a

1081
00:39:41,280 --> 00:39:43,280
band-aid on a cancer

1082
00:39:43,280 --> 00:39:46,560
what we need is time to envision the new

1083
00:39:46,560 --> 00:39:48,880
and i always think about like imagine if

1084
00:39:48,880 --> 00:39:49,760
philanthropy

1085
00:39:49,760 --> 00:39:52,960
funded as much money into a great

1086
00:39:52,960 --> 00:39:54,320
imagining

1087
00:39:54,320 --> 00:39:56,640
by the same people who are researching

1088
00:39:56,640 --> 00:39:57,920
our demise

1089
00:39:57,920 --> 00:40:00,800
to begin thinking about the solutions

1090
00:40:00,800 --> 00:40:02,079
because when you think about something

1091
00:40:02,079 --> 00:40:03,680
like facebook i mean facebook was

1092
00:40:03,680 --> 00:40:04,319
started by

1093
00:40:04,319 --> 00:40:06,160
these dudes in harvard that wanted hot

1094
00:40:06,160 --> 00:40:08,160
chicks and um you know

1095
00:40:08,160 --> 00:40:10,000
certainly not the cultural competencies

1096
00:40:10,000 --> 00:40:11,599
that you need for an intergovernmental

1097
00:40:11,599 --> 00:40:12,640
organization

1098
00:40:12,640 --> 00:40:14,160
handling you know democratic

1099
00:40:14,160 --> 00:40:15,839
conversation around the world

1100
00:40:15,839 --> 00:40:19,119
you know um but the people who saw the

1101
00:40:19,119 --> 00:40:21,440
business potential of that was a cia

1102
00:40:21,440 --> 00:40:24,240
right and um who was one of their first

1103
00:40:24,240 --> 00:40:25,119
funders

1104
00:40:25,119 --> 00:40:28,000
and you know cut to cambridge analytica

1105
00:40:28,000 --> 00:40:28,480
and

1106
00:40:28,480 --> 00:40:31,359
you know facebook disrupting you know so

1107
00:40:31,359 --> 00:40:34,079
many democracies around the world

1108
00:40:34,079 --> 00:40:37,119
and not a single penny was paid

1109
00:40:37,119 --> 00:40:40,160
in terms of reparations and i think this

1110
00:40:40,160 --> 00:40:41,119
is what is so

1111
00:40:41,119 --> 00:40:43,920
critical is that i think that we are so

1112
00:40:43,920 --> 00:40:44,720
breathless

1113
00:40:44,720 --> 00:40:47,839
from the violence we are just so

1114
00:40:47,839 --> 00:40:49,920
tapped in terms of just trying to get

1115
00:40:49,920 --> 00:40:51,359
our communities

1116
00:40:51,359 --> 00:40:54,480
out of the crisis that we're in we need

1117
00:40:54,480 --> 00:40:56,800
time to be able to not only talk about

1118
00:40:56,800 --> 00:40:58,640
the full scope of the harm

1119
00:40:58,640 --> 00:41:00,240
to then be able to demand the

1120
00:41:00,240 --> 00:41:02,079
reparations that are required

1121
00:41:02,079 --> 00:41:04,319
because this isn't just a i need a mea

1122
00:41:04,319 --> 00:41:05,680
culpa in front of a congressional

1123
00:41:05,680 --> 00:41:06,720
hearing thing

1124
00:41:06,720 --> 00:41:08,640
this is more like a billion dollar

1125
00:41:08,640 --> 00:41:10,400
reparations fund to support

1126
00:41:10,400 --> 00:41:12,800
democratic processes around the world

1127
00:41:12,800 --> 00:41:14,960
this is a billion dollar fund

1128
00:41:14,960 --> 00:41:17,359
that is about supporting innovations

1129
00:41:17,359 --> 00:41:19,599
into new business models into new

1130
00:41:19,599 --> 00:41:22,000
developments around technology that can

1131
00:41:22,000 --> 00:41:22,640
actually

1132
00:41:22,640 --> 00:41:24,480
heal that could actually create

1133
00:41:24,480 --> 00:41:26,240
abolitionist futures

1134
00:41:26,240 --> 00:41:29,200
versus digital authoritarianism and

1135
00:41:29,200 --> 00:41:30,560
especially when i think of

1136
00:41:30,560 --> 00:41:32,800
you know you know companies like google

1137
00:41:32,800 --> 00:41:34,400
and their ethical ai

1138
00:41:34,400 --> 00:41:36,640
i was like why would i trust google to

1139
00:41:36,640 --> 00:41:38,480
build ethical ai

1140
00:41:38,480 --> 00:41:41,760
when they couldn't keep google docs

1141
00:41:41,760 --> 00:41:43,520
away out of the hands of the indian

1142
00:41:43,520 --> 00:41:45,920
government and turning over the ip

1143
00:41:45,920 --> 00:41:48,000
of climate change activists who were

1144
00:41:48,000 --> 00:41:50,319
protesting about farmers rights

1145
00:41:50,319 --> 00:41:52,160
that is the most simplest task that they

1146
00:41:52,160 --> 00:41:53,520
could do in order to

1147
00:41:53,520 --> 00:41:56,480
not do evil and yet they failed so

1148
00:41:56,480 --> 00:41:57,359
somehow

1149
00:41:57,359 --> 00:41:58,720
all of a sudden there's going to be a

1150
00:41:58,720 --> 00:42:00,240
moral compass that's going to come out

1151
00:42:00,240 --> 00:42:01,040
of this

1152
00:42:01,040 --> 00:42:03,680
in the face of the profit that is to be

1153
00:42:03,680 --> 00:42:04,240
made

1154
00:42:04,240 --> 00:42:07,599
around genocide yeah and i think that's

1155
00:42:07,599 --> 00:42:09,280
really the the point sasha i want to

1156
00:42:09,280 --> 00:42:09,920
bring you in

1157
00:42:09,920 --> 00:42:12,319
around this is that we are dealing with

1158
00:42:12,319 --> 00:42:14,319
situations like digital war

1159
00:42:14,319 --> 00:42:15,839
digital apartheid when we look at what

1160
00:42:15,839 --> 00:42:17,680
palestinians are dealing with

1161
00:42:17,680 --> 00:42:20,560
and genocide so again i want to bring us

1162
00:42:20,560 --> 00:42:21,359
back to

1163
00:42:21,359 --> 00:42:23,599
you talk a lot also about institutions

1164
00:42:23,599 --> 00:42:24,960
not being monoliths

1165
00:42:24,960 --> 00:42:26,720
where the opportunities and where the

1166
00:42:26,720 --> 00:42:28,880
visioning processes that we could look

1167
00:42:28,880 --> 00:42:30,000
at in both policy

1168
00:42:30,000 --> 00:42:32,720
and processes

1169
00:42:33,760 --> 00:42:35,359
yeah well i definitely agree that it's

1170
00:42:35,359 --> 00:42:38,000
hard to trust um google's ethical ai

1171
00:42:38,000 --> 00:42:40,079
initiatives especially after

1172
00:42:40,079 --> 00:42:42,880
they've just finished um firing dr tim

1173
00:42:42,880 --> 00:42:44,960
nick hebrew and meg mitchell

1174
00:42:44,960 --> 00:42:48,079
and the brilliant uh you know black

1175
00:42:48,079 --> 00:42:48,560
women

1176
00:42:48,560 --> 00:42:52,079
and other women leadership um

1177
00:42:52,079 --> 00:42:55,680
because they dared

1178
00:42:55,680 --> 00:42:59,920
to publish their research findings about

1179
00:42:59,920 --> 00:43:02,079
google's ai systems and their ecological

1180
00:43:02,079 --> 00:43:04,160
impacts and the ways that they

1181
00:43:04,160 --> 00:43:06,640
reproduce existing biases in this

1182
00:43:06,640 --> 00:43:08,400
stochastic pirates paper

1183
00:43:08,400 --> 00:43:12,000
um so it's very yeah it's very

1184
00:43:12,000 --> 00:43:14,880
difficult to look at what these firms

1185
00:43:14,880 --> 00:43:15,520
are doing

1186
00:43:15,520 --> 00:43:18,240
and not be deeply skeptical and

1187
00:43:18,240 --> 00:43:19,760
rightfully so

1188
00:43:19,760 --> 00:43:22,960
not to focus on the ethics watching

1189
00:43:22,960 --> 00:43:24,240
ethics washing

1190
00:43:24,240 --> 00:43:26,800
um as kind of you know that's looks like

1191
00:43:26,800 --> 00:43:28,720
that's what's actually taking place

1192
00:43:28,720 --> 00:43:31,920
um at the same time you know

1193
00:43:31,920 --> 00:43:34,720
as a non-binary person i like to

1194
00:43:34,720 --> 00:43:36,640
complicate binary

1195
00:43:36,640 --> 00:43:39,200
visions of what's happening and so while

1196
00:43:39,200 --> 00:43:41,280
i agree that there's great danger

1197
00:43:41,280 --> 00:43:44,400
the companies will capture

1198
00:43:44,400 --> 00:43:47,839
the ai ethics conversation

1199
00:43:47,839 --> 00:43:51,520
or the broader conversation about ai

1200
00:43:51,520 --> 00:43:55,119
ethics equitable ai transparent ai

1201
00:43:55,119 --> 00:43:58,160
or algorithmic justice

1202
00:43:58,160 --> 00:44:01,760
i actually think that we can also see

1203
00:44:01,760 --> 00:44:03,280
the fact that these companies all feel

1204
00:44:03,280 --> 00:44:05,280
they need to create these teams

1205
00:44:05,280 --> 00:44:07,760
as something very positive i think

1206
00:44:07,760 --> 00:44:08,480
they've been

1207
00:44:08,480 --> 00:44:10,400
forced by a lot of different

1208
00:44:10,400 --> 00:44:12,000
developments including

1209
00:44:12,000 --> 00:44:13,760
the increasing documentation of

1210
00:44:13,760 --> 00:44:16,000
incidents of ai harm

1211
00:44:16,000 --> 00:44:18,000
by the great work of investigative

1212
00:44:18,000 --> 00:44:19,040
journalism

1213
00:44:19,040 --> 00:44:21,359
organizations like propublica by the

1214
00:44:21,359 --> 00:44:22,079
work of

1215
00:44:22,079 --> 00:44:25,119
independent uh researchers coming

1216
00:44:25,119 --> 00:44:27,359
uh from all different spaces whether

1217
00:44:27,359 --> 00:44:29,040
it's you know the work of

1218
00:44:29,040 --> 00:44:32,480
joy bulawini and bharaji

1219
00:44:32,480 --> 00:44:34,800
uh and timothy brew in the gender shades

1220
00:44:34,800 --> 00:44:35,760
work

1221
00:44:35,760 --> 00:44:38,720
in actionable auditing or it's the work

1222
00:44:38,720 --> 00:44:41,040
of researchers outside the academy

1223
00:44:41,040 --> 00:44:43,280
who are independently developing methods

1224
00:44:43,280 --> 00:44:44,400
to

1225
00:44:44,400 --> 00:44:47,680
audit these systems or it's the work of

1226
00:44:47,680 --> 00:44:49,599
researchers inside companies

1227
00:44:49,599 --> 00:44:52,880
that are trying to figure out um

1228
00:44:52,880 --> 00:44:54,480
not only how to audit systems for

1229
00:44:54,480 --> 00:44:56,560
technical bias but also

1230
00:44:56,560 --> 00:45:00,880
how to document harms that systems have

1231
00:45:00,880 --> 00:45:01,599
created

1232
00:45:01,599 --> 00:45:03,920
and also develop tooling that will

1233
00:45:03,920 --> 00:45:06,240
enable

1234
00:45:06,240 --> 00:45:10,000
less yes less biased outcomes but also

1235
00:45:10,000 --> 00:45:12,319
think about how we develop tooling for

1236
00:45:12,319 --> 00:45:13,440
harms reporting

1237
00:45:13,440 --> 00:45:15,440
for incident reporting learning from the

1238
00:45:15,440 --> 00:45:17,440
cyber security industry so that we could

1239
00:45:17,440 --> 00:45:18,560
say

1240
00:45:18,560 --> 00:45:20,960
well in cyber security every time a

1241
00:45:20,960 --> 00:45:23,040
known hack emerges

1242
00:45:23,040 --> 00:45:26,640
and it's been exploited um you know

1243
00:45:26,640 --> 00:45:29,040
that gets documented it gets reported it

1244
00:45:29,040 --> 00:45:30,160
gets shared

1245
00:45:30,160 --> 00:45:32,880
through a database uh that's shared

1246
00:45:32,880 --> 00:45:34,079
across industry

1247
00:45:34,079 --> 00:45:36,240
there's standardization there's incident

1248
00:45:36,240 --> 00:45:38,720
reporting and escalation and there's

1249
00:45:38,720 --> 00:45:41,280
rapid response teams and there's

1250
00:45:41,280 --> 00:45:43,359
coordinated disclosure mechanisms where

1251
00:45:43,359 --> 00:45:44,480
people have to patch those

1252
00:45:44,480 --> 00:45:45,760
vulnerabilities

1253
00:45:45,760 --> 00:45:47,599
quickly before the findings get

1254
00:45:47,599 --> 00:45:48,880
published like

1255
00:45:48,880 --> 00:45:51,520
we can learn a lot from all of those

1256
00:45:51,520 --> 00:45:52,480
sectors

1257
00:45:52,480 --> 00:45:55,119
to actually build better systems and

1258
00:45:55,119 --> 00:45:57,200
while i agree with you sophia that

1259
00:45:57,200 --> 00:46:00,000
um you know we need we need to make more

1260
00:46:00,000 --> 00:46:01,680
careful determinations about which

1261
00:46:01,680 --> 00:46:02,319
systems

1262
00:46:02,319 --> 00:46:04,480
are carceral systems and should never be

1263
00:46:04,480 --> 00:46:05,520
built

1264
00:46:05,520 --> 00:46:08,240
um and which systems are systems worth

1265
00:46:08,240 --> 00:46:09,440
building better

1266
00:46:09,440 --> 00:46:12,640
i completely agree with that um and i

1267
00:46:12,640 --> 00:46:14,319
also completely agree that

1268
00:46:14,319 --> 00:46:15,839
the companies want to capture the whole

1269
00:46:15,839 --> 00:46:17,839
conversation i also think that it

1270
00:46:17,839 --> 00:46:19,680
provides a great opportunity in a lot of

1271
00:46:19,680 --> 00:46:20,400
ways

1272
00:46:20,400 --> 00:46:24,319
because one it means that there's now

1273
00:46:24,319 --> 00:46:27,200
hundreds if not thousands of people you

1274
00:46:27,200 --> 00:46:28,800
know researchers

1275
00:46:28,800 --> 00:46:32,000
students who are just coming up um

1276
00:46:32,000 --> 00:46:33,839
people who have just landed positions

1277
00:46:33,839 --> 00:46:35,440
inside these organizations or have been

1278
00:46:35,440 --> 00:46:37,119
doing this work for a long time

1279
00:46:37,119 --> 00:46:39,520
who are saying finally people are taking

1280
00:46:39,520 --> 00:46:41,599
seriously the work we

1281
00:46:41,599 --> 00:46:44,800
have been trying to do um and so there's

1282
00:46:44,800 --> 00:46:46,400
networks of people that are emerging

1283
00:46:46,400 --> 00:46:47,920
inside these companies that are at least

1284
00:46:47,920 --> 00:46:49,680
having these conversations

1285
00:46:49,680 --> 00:46:51,280
they're in dialogue with one another and

1286
00:46:51,280 --> 00:46:53,040
they're also in dialogue with people

1287
00:46:53,040 --> 00:46:55,359
you know outside the the tech sector

1288
00:46:55,359 --> 00:46:56,560
they're in dialogue with social

1289
00:46:56,560 --> 00:46:57,440
movements

1290
00:46:57,440 --> 00:47:00,319
um i've been in the last few months

1291
00:47:00,319 --> 00:47:02,960
alone i've been contacted by

1292
00:47:02,960 --> 00:47:06,079
many researchers inside

1293
00:47:06,079 --> 00:47:09,280
major multinational corporations that

1294
00:47:09,280 --> 00:47:12,319
only now only in the last year

1295
00:47:12,319 --> 00:47:13,920
specifically because of the black lives

1296
00:47:13,920 --> 00:47:15,920
matter movement have finally gotten

1297
00:47:15,920 --> 00:47:17,680
approval from their higher ups

1298
00:47:17,680 --> 00:47:20,559
to launch whole new initiatives around

1299
00:47:20,559 --> 00:47:22,720
race and technology

1300
00:47:22,720 --> 00:47:25,280
not just in the diversity and inclusion

1301
00:47:25,280 --> 00:47:25,839
in sort of

1302
00:47:25,839 --> 00:47:27,520
employment space which yes it's

1303
00:47:27,520 --> 00:47:29,280
important but we know it's not enough

1304
00:47:29,280 --> 00:47:31,280
but also in the product team you know

1305
00:47:31,280 --> 00:47:33,440
space and i see those things as very

1306
00:47:33,440 --> 00:47:35,119
very positive developments

1307
00:47:35,119 --> 00:47:37,599
because imagining and then building the

1308
00:47:37,599 --> 00:47:38,559
future

1309
00:47:38,559 --> 00:47:41,359
or the many futures that we might want

1310
00:47:41,359 --> 00:47:42,079
is going to take

1311
00:47:42,079 --> 00:47:44,400
all different types of people and all

1312
00:47:44,400 --> 00:47:46,400
different types of skills and the degree

1313
00:47:46,400 --> 00:47:47,359
to which

1314
00:47:47,359 --> 00:47:49,680
um the current moment we're living in in

1315
00:47:49,680 --> 00:47:51,359
terms of the pressure that social

1316
00:47:51,359 --> 00:47:52,720
movements have created

1317
00:47:52,720 --> 00:47:55,359
on these companies and to some degree

1318
00:47:55,359 --> 00:47:57,599
pressure that's starting to be generated

1319
00:47:57,599 --> 00:48:00,319
um in the regulatory space and from some

1320
00:48:00,319 --> 00:48:01,920
of the bills that have been

1321
00:48:01,920 --> 00:48:05,200
um you know introduced or are moving

1322
00:48:05,200 --> 00:48:06,880
through the us congress or through the

1323
00:48:06,880 --> 00:48:08,559
eu space um

1324
00:48:08,559 --> 00:48:10,480
like the algorithmic justice act that's

1325
00:48:10,480 --> 00:48:11,680
just been brought in

1326
00:48:11,680 --> 00:48:15,040
or the facial recognition uh moratorium

1327
00:48:15,040 --> 00:48:16,960
and biometric surveillance moratorium

1328
00:48:16,960 --> 00:48:17,599
act

1329
00:48:17,599 --> 00:48:20,160
um or like the new eu regulations around

1330
00:48:20,160 --> 00:48:22,000
algorithmic accountability that are in

1331
00:48:22,000 --> 00:48:23,359
progress

1332
00:48:23,359 --> 00:48:26,559
like the combination of strong social

1333
00:48:26,559 --> 00:48:27,200
movements

1334
00:48:27,200 --> 00:48:29,119
demanding racial justice everywhere

1335
00:48:29,119 --> 00:48:30,800
including in the tech sector

1336
00:48:30,800 --> 00:48:33,839
as well as some regulatory action that's

1337
00:48:33,839 --> 00:48:34,880
starting to move

1338
00:48:34,880 --> 00:48:37,359
is providing a window of opportunity for

1339
00:48:37,359 --> 00:48:38,800
people who are working inside these

1340
00:48:38,800 --> 00:48:39,680
companies

1341
00:48:39,680 --> 00:48:42,160
to finally get resources and get the

1342
00:48:42,160 --> 00:48:44,079
green light to move forward

1343
00:48:44,079 --> 00:48:47,359
some very interesting projects

1344
00:48:47,359 --> 00:48:50,480
um including around

1345
00:48:50,480 --> 00:48:53,359
better tooling better analysis not only

1346
00:48:53,359 --> 00:48:53,599
of

1347
00:48:53,599 --> 00:48:56,240
technical bias auditing which i think is

1348
00:48:56,240 --> 00:48:57,040
important but

1349
00:48:57,040 --> 00:48:59,520
is very limited but also in terms of

1350
00:48:59,520 --> 00:49:01,599
more radical revisioning

1351
00:49:01,599 --> 00:49:04,720
of what it means to do harm reduction

1352
00:49:04,720 --> 00:49:06,960
in the ai systems that we do need to

1353
00:49:06,960 --> 00:49:07,839
develop

1354
00:49:07,839 --> 00:49:09,680
as well as to think about which are the

1355
00:49:09,680 --> 00:49:11,760
systems we need to not

1356
00:49:11,760 --> 00:49:14,400
say no to

1357
00:49:14,960 --> 00:49:17,440
and i think that that that reminder is

1358
00:49:17,440 --> 00:49:18,640
so important

1359
00:49:18,640 --> 00:49:20,640
because again i want to go back to how

1360
00:49:20,640 --> 00:49:22,640
we started this conversation which is

1361
00:49:22,640 --> 00:49:23,200
that

1362
00:49:23,200 --> 00:49:26,000
i think many many people in this sector

1363
00:49:26,000 --> 00:49:27,520
and especially the human rights

1364
00:49:27,520 --> 00:49:28,400
defenders and

1365
00:49:28,400 --> 00:49:29,920
activists and researchers that are in

1366
00:49:29,920 --> 00:49:31,839
the global south

1367
00:49:31,839 --> 00:49:34,000
they are coming to this conversation not

1368
00:49:34,000 --> 00:49:34,960
with equity

1369
00:49:34,960 --> 00:49:36,400
they are coming with their hearts

1370
00:49:36,400 --> 00:49:38,160
breaking they're coming with

1371
00:49:38,160 --> 00:49:40,559
their dead um you know and i think about

1372
00:49:40,559 --> 00:49:41,520
in india

1373
00:49:41,520 --> 00:49:44,480
you know how devastated you know almost

1374
00:49:44,480 --> 00:49:46,160
all the institutions that work

1375
00:49:46,160 --> 00:49:49,680
in this sector are by the pandemic

1376
00:49:49,680 --> 00:49:52,800
and and to to think about how in the

1377
00:49:52,800 --> 00:49:53,680
face of such

1378
00:49:53,680 --> 00:49:56,960
cataclysm that the burden of hope

1379
00:49:56,960 --> 00:50:00,319
um must feel like and yet i think that

1380
00:50:00,319 --> 00:50:03,280
in many ways you know hope is a muscle

1381
00:50:03,280 --> 00:50:06,079
hope is an exercise hope is a practice

1382
00:50:06,079 --> 00:50:08,559
and i think a lot of what you know both

1383
00:50:08,559 --> 00:50:09,760
you and sophia

1384
00:50:09,760 --> 00:50:12,160
are really speaking to is that there are

1385
00:50:12,160 --> 00:50:13,520
openings

1386
00:50:13,520 --> 00:50:15,599
everywhere you know and i think about

1387
00:50:15,599 --> 00:50:17,680
you know tupac's like you know

1388
00:50:17,680 --> 00:50:19,920
um book the rose that grew from concrete

1389
00:50:19,920 --> 00:50:21,920
you know in many ways life

1390
00:50:21,920 --> 00:50:24,960
always finds a way and that in this time

1391
00:50:24,960 --> 00:50:26,000
of death

1392
00:50:26,000 --> 00:50:28,400
we are choosing to imagine because we

1393
00:50:28,400 --> 00:50:30,800
are choosing life

1394
00:50:30,800 --> 00:50:33,440
and i've never felt such a profound need

1395
00:50:33,440 --> 00:50:34,880
to choose life

1396
00:50:34,880 --> 00:50:36,640
because i've already seen what the

1397
00:50:36,640 --> 00:50:38,800
alternative is i've already seen

1398
00:50:38,800 --> 00:50:41,280
unspeakable things happen to my people

1399
00:50:41,280 --> 00:50:43,760
i've already seen people have to choose

1400
00:50:43,760 --> 00:50:45,119
between

1401
00:50:45,119 --> 00:50:48,480
eating or having the vaccine or paying

1402
00:50:48,480 --> 00:50:50,559
rent or getting room desevere

1403
00:50:50,559 --> 00:50:52,079
because the intellectual property

1404
00:50:52,079 --> 00:50:54,800
patents related to the vaccines that we

1405
00:50:54,800 --> 00:50:55,760
paid for

1406
00:50:55,760 --> 00:50:59,200
as american citizens are being charged

1407
00:50:59,200 --> 00:51:02,400
to countries like india so the ideas

1408
00:51:02,400 --> 00:51:04,000
that we're talking about in terms of

1409
00:51:04,000 --> 00:51:05,440
transformative policy

1410
00:51:05,440 --> 00:51:07,680
transformative business models

1411
00:51:07,680 --> 00:51:09,920
transformative technology

1412
00:51:09,920 --> 00:51:12,559
we need investment in terms of a great

1413
00:51:12,559 --> 00:51:13,440
imagining

1414
00:51:13,440 --> 00:51:14,640
and when i think of that work that

1415
00:51:14,640 --> 00:51:17,280
joanna macy does around

1416
00:51:17,280 --> 00:51:19,520
um the climate crisis and thinking about

1417
00:51:19,520 --> 00:51:21,599
the invitation to use this moment as the

1418
00:51:21,599 --> 00:51:22,640
great turning

1419
00:51:22,640 --> 00:51:24,400
to ask for the world that can come

1420
00:51:24,400 --> 00:51:26,880
afterwards this is what we need in this

1421
00:51:26,880 --> 00:51:28,160
space right now

1422
00:51:28,160 --> 00:51:30,720
we need care we need love we need

1423
00:51:30,720 --> 00:51:33,119
healing we need transformation

1424
00:51:33,119 --> 00:51:36,000
and imagination allows us to do that but

1425
00:51:36,000 --> 00:51:37,200
that doesn't happen

1426
00:51:37,200 --> 00:51:38,960
when people are hungry when people are

1427
00:51:38,960 --> 00:51:41,280
in hiding when people aren't able to

1428
00:51:41,280 --> 00:51:41,839
even

1429
00:51:41,839 --> 00:51:44,079
do their work safely and that's

1430
00:51:44,079 --> 00:51:44,960
unfortunately

1431
00:51:44,960 --> 00:51:46,960
many many many of the activists that are

1432
00:51:46,960 --> 00:51:48,880
part of the rights con space like

1433
00:51:48,880 --> 00:51:50,559
part of the reasons why i can't do a

1434
00:51:50,559 --> 00:51:52,559
land acknowledgement is i don't want to

1435
00:51:52,559 --> 00:51:54,319
reveal where i'm located because of the

1436
00:51:54,319 --> 00:51:56,160
amount of death threats and rape threats

1437
00:51:56,160 --> 00:51:57,359
that i receive

1438
00:51:57,359 --> 00:51:59,839
as adult activists and you know the

1439
00:51:59,839 --> 00:52:02,000
virulence of digital authoritarianism

1440
00:52:02,000 --> 00:52:04,559
and digital brahminism and and i think

1441
00:52:04,559 --> 00:52:05,520
that you know

1442
00:52:05,520 --> 00:52:07,520
sophia i think you know we're coming to

1443
00:52:07,520 --> 00:52:09,839
the closing part of our conversation

1444
00:52:09,839 --> 00:52:12,240
i think people look to your writing um

1445
00:52:12,240 --> 00:52:13,839
as a black feminist scholar

1446
00:52:13,839 --> 00:52:15,839
and as someone who is bringing has

1447
00:52:15,839 --> 00:52:17,680
brought so much internationalism into

1448
00:52:17,680 --> 00:52:19,200
this conversation

1449
00:52:19,200 --> 00:52:21,599
for that engine of hope and i'm

1450
00:52:21,599 --> 00:52:23,280
wondering if you could leave people with

1451
00:52:23,280 --> 00:52:24,960
just a final thought about that

1452
00:52:24,960 --> 00:52:28,079
um before we close you know i

1453
00:52:28,079 --> 00:52:30,240
and did i close my book with thinking

1454
00:52:30,240 --> 00:52:31,280
about like

1455
00:52:31,280 --> 00:52:33,280
well how could we imagine things

1456
00:52:33,280 --> 00:52:34,800
differently because i

1457
00:52:34,800 --> 00:52:38,160
completely agree with you that we

1458
00:52:38,160 --> 00:52:41,920
um we deserve to get to live lives that

1459
00:52:41,920 --> 00:52:44,079
are not completely constructed

1460
00:52:44,079 --> 00:52:46,720
through trauma and oppression where the

1461
00:52:46,720 --> 00:52:47,680
only way we

1462
00:52:47,680 --> 00:52:50,079
can understand ourselves is through

1463
00:52:50,079 --> 00:52:51,359
those lenses

1464
00:52:51,359 --> 00:52:53,520
um or with that our entire life and our

1465
00:52:53,520 --> 00:52:56,319
communities lives are not defined by

1466
00:52:56,319 --> 00:52:58,240
and this is one of the things where you

1467
00:52:58,240 --> 00:53:00,559
know i love being black because even

1468
00:53:00,559 --> 00:53:02,720
in the face of what black people

1469
00:53:02,720 --> 00:53:04,800
experience all around the world

1470
00:53:04,800 --> 00:53:07,839
we have so much love and culture

1471
00:53:07,839 --> 00:53:10,640
and community and connection and flavor

1472
00:53:10,640 --> 00:53:12,720
and all the things that

1473
00:53:12,720 --> 00:53:15,040
make life worth living too and so that's

1474
00:53:15,040 --> 00:53:16,880
a thing that is that we all have that i

1475
00:53:16,880 --> 00:53:18,400
mean this is why

1476
00:53:18,400 --> 00:53:20,800
um you know i roll with the kind of

1477
00:53:20,800 --> 00:53:22,960
communities that i roll with which are

1478
00:53:22,960 --> 00:53:26,160
communities that also are like um

1479
00:53:26,160 --> 00:53:28,079
you know black communities people who

1480
00:53:28,079 --> 00:53:29,760
also have the the texture of

1481
00:53:29,760 --> 00:53:30,800
understanding

1482
00:53:30,800 --> 00:53:33,359
oppression and finding joy and working

1483
00:53:33,359 --> 00:53:34,319
through those things

1484
00:53:34,319 --> 00:53:36,559
um through those conditions so that's

1485
00:53:36,559 --> 00:53:37,839
incredibly um

1486
00:53:37,839 --> 00:53:41,520
important and you know i i think that we

1487
00:53:41,520 --> 00:53:44,160
we don't want to forget that the

1488
00:53:44,160 --> 00:53:45,839
conditions that we're living through

1489
00:53:45,839 --> 00:53:49,359
right now that you are talking about um

1490
00:53:49,359 --> 00:53:52,440
are tied to the

1491
00:53:52,440 --> 00:53:55,599
profoundly immoral and

1492
00:53:55,599 --> 00:53:58,960
gross distribution of resources

1493
00:53:58,960 --> 00:54:02,319
in the world this is fundamental to me i

1494
00:54:02,319 --> 00:54:05,440
really don't care about the technology i

1495
00:54:05,440 --> 00:54:06,720
care about the way in which the

1496
00:54:06,720 --> 00:54:08,400
technology sector

1497
00:54:08,400 --> 00:54:10,240
defunds the possibilities that you're

1498
00:54:10,240 --> 00:54:11,440
talking about

1499
00:54:11,440 --> 00:54:14,880
of having affordable housing of having

1500
00:54:14,880 --> 00:54:17,680
affordable food of having dignity in our

1501
00:54:17,680 --> 00:54:18,480
work

1502
00:54:18,480 --> 00:54:21,440
of um living in worlds where

1503
00:54:21,440 --> 00:54:22,559
discrimination

1504
00:54:22,559 --> 00:54:24,960
and um oppression are not normal and

1505
00:54:24,960 --> 00:54:26,240
expected

1506
00:54:26,240 --> 00:54:29,839
um you should not be experiencing

1507
00:54:29,839 --> 00:54:32,480
death threats um for speaking truth to

1508
00:54:32,480 --> 00:54:33,200
power

1509
00:54:33,200 --> 00:54:34,559
right we should not be living in that

1510
00:54:34,559 --> 00:54:36,720
kind of a world we're just naming the

1511
00:54:36,720 --> 00:54:38,160
most obvious

1512
00:54:38,160 --> 00:54:42,160
of gross injustices um uh

1513
00:54:42,160 --> 00:54:44,240
generates those types of conditions

1514
00:54:44,240 --> 00:54:46,160
right those types of threats

1515
00:54:46,160 --> 00:54:48,480
so this is why you know to me that's

1516
00:54:48,480 --> 00:54:50,319
what i feel the most hopeful about

1517
00:54:50,319 --> 00:54:53,680
is that we are increasingly linking

1518
00:54:53,680 --> 00:54:57,760
the fantasy about what technology can do

1519
00:54:57,760 --> 00:55:00,799
what these systems can do to

1520
00:55:00,799 --> 00:55:02,799
the real world implications of what they

1521
00:55:02,799 --> 00:55:04,160
are not doing

1522
00:55:04,160 --> 00:55:07,760
and in fact the the gross investment of

1523
00:55:07,760 --> 00:55:09,119
resources in one

1524
00:55:09,119 --> 00:55:11,440
sector that will privilege such a small

1525
00:55:11,440 --> 00:55:13,680
minority of people in the world

1526
00:55:13,680 --> 00:55:16,480
and will be used to organize more

1527
00:55:16,480 --> 00:55:17,599
efficiently

1528
00:55:17,599 --> 00:55:19,599
the demise of others those are the

1529
00:55:19,599 --> 00:55:21,440
questions to me that we need to be

1530
00:55:21,440 --> 00:55:22,240
thinking about

1531
00:55:22,240 --> 00:55:25,520
that's actually the point um of studying

1532
00:55:25,520 --> 00:55:26,640
this sector

1533
00:55:26,640 --> 00:55:29,119
and caring about it is not for the tech

1534
00:55:29,119 --> 00:55:30,400
it's for the people

1535
00:55:30,400 --> 00:55:32,240
it's for the planet it's for the quality

1536
00:55:32,240 --> 00:55:34,559
of life that we want to live

1537
00:55:34,559 --> 00:55:37,280
and where we need to put the brakes on

1538
00:55:37,280 --> 00:55:38,960
systems that will

1539
00:55:38,960 --> 00:55:42,400
impede upon people living full powerful

1540
00:55:42,400 --> 00:55:43,280
amazing

1541
00:55:43,280 --> 00:55:44,720
full lives it's not that we don't have

1542
00:55:44,720 --> 00:55:46,559
enough resources in the world

1543
00:55:46,559 --> 00:55:48,559
we have all the resources it's just that

1544
00:55:48,559 --> 00:55:50,559
most of them are concentrated in the

1545
00:55:50,559 --> 00:55:51,359
hands

1546
00:55:51,359 --> 00:55:54,000
of a tiny few that's actually the

1547
00:55:54,000 --> 00:55:54,640
challenge

1548
00:55:54,640 --> 00:55:56,720
and i will say that to your point you

1549
00:55:56,720 --> 00:55:57,920
know you're opening

1550
00:55:57,920 --> 00:56:01,599
salvo here um it is the um

1551
00:56:01,599 --> 00:56:04,640
the cast systems it is the um

1552
00:56:04,640 --> 00:56:07,359
colorism it is the oppression it is the

1553
00:56:07,359 --> 00:56:09,119
anti-blackness it is the

1554
00:56:09,119 --> 00:56:12,319
um um the the homophobic

1555
00:56:12,319 --> 00:56:16,000
transphobic um it is the patriarchal

1556
00:56:16,000 --> 00:56:19,599
i mean um anti-earth sentiments and

1557
00:56:19,599 --> 00:56:21,280
sensibilities that are really about

1558
00:56:21,280 --> 00:56:24,640
the individual and what the individual

1559
00:56:24,640 --> 00:56:27,680
um should have to the detriment of the

1560
00:56:27,680 --> 00:56:30,160
collective that you know those are the

1561
00:56:30,160 --> 00:56:30,799
values

1562
00:56:30,799 --> 00:56:32,240
underneath this that we need to be

1563
00:56:32,240 --> 00:56:33,920
challenging and to me part of the

1564
00:56:33,920 --> 00:56:35,760
problem is that the tech sector really

1565
00:56:35,760 --> 00:56:37,200
socializes us

1566
00:56:37,200 --> 00:56:40,559
to individual hyper-consumptive kinds of

1567
00:56:40,559 --> 00:56:43,200
ways of thinking in the world and that's

1568
00:56:43,200 --> 00:56:44,799
part of what we're resisting and so i

1569
00:56:44,799 --> 00:56:47,119
feel incredibly hopeful because

1570
00:56:47,119 --> 00:56:50,240
you know um nobody wants to live

1571
00:56:50,240 --> 00:56:54,079
um a life of in the united states of

1572
00:56:54,079 --> 00:56:54,400
just

1573
00:56:54,400 --> 00:56:57,839
tapping on glass the rest of their lives

1574
00:56:57,839 --> 00:56:58,240
um

1575
00:56:58,240 --> 00:57:00,720
losing the ability to be creative and do

1576
00:57:00,720 --> 00:57:01,359
work

1577
00:57:01,359 --> 00:57:03,599
but also people don't want to mine the

1578
00:57:03,599 --> 00:57:04,960
minerals that it takes

1579
00:57:04,960 --> 00:57:07,839
to make this stuff or have to cl sift

1580
00:57:07,839 --> 00:57:10,079
through the e-waste and the toxicity

1581
00:57:10,079 --> 00:57:11,680
of it when we're done with it i mean we

1582
00:57:11,680 --> 00:57:13,359
have a responsibility especially in the

1583
00:57:13,359 --> 00:57:14,400
united states

1584
00:57:14,400 --> 00:57:17,040
to understand our role especially as

1585
00:57:17,040 --> 00:57:18,319
consumers

1586
00:57:18,319 --> 00:57:20,240
in relationship to these global problems

1587
00:57:20,240 --> 00:57:21,839
and i think that um

1588
00:57:21,839 --> 00:57:25,200
um you know that we get have space to

1589
00:57:25,200 --> 00:57:26,880
talk about it is incredibly important

1590
00:57:26,880 --> 00:57:27,599
and i agree

1591
00:57:27,599 --> 00:57:29,760
who's going to give us a billion dollars

1592
00:57:29,760 --> 00:57:31,280
to go off into the woods

1593
00:57:31,280 --> 00:57:33,359
and imagine the futures that we want

1594
00:57:33,359 --> 00:57:35,440
like all the tech executives get

1595
00:57:35,440 --> 00:57:37,119
um and the world that they've imagined

1596
00:57:37,119 --> 00:57:38,640
for us is

1597
00:57:38,640 --> 00:57:41,760
not a world we want i i don't think in

1598
00:57:41,760 --> 00:57:44,000
the end if we follow the logics

1599
00:57:44,000 --> 00:57:46,240
um that they've envisioned for us it's

1600
00:57:46,240 --> 00:57:48,000
not the world we want and so we

1601
00:57:48,000 --> 00:57:50,000
absolutely have to invest

1602
00:57:50,000 --> 00:57:53,680
in other kinds of imaginaries

1603
00:58:00,640 --> 00:58:03,200
and i would be more than happy to be

1604
00:58:03,200 --> 00:58:04,400
able to support that

1605
00:58:04,400 --> 00:58:06,559
um support the the hosting of such a

1606
00:58:06,559 --> 00:58:09,680
fund to be able to help make that happen

1607
00:58:09,680 --> 00:58:11,760
particularly because i think this moment

1608
00:58:11,760 --> 00:58:12,720
is about

1609
00:58:12,720 --> 00:58:15,760
um lots of experimentation

1610
00:58:15,760 --> 00:58:17,200
because it may not be that we're

1611
00:58:17,200 --> 00:58:18,799
someone's going to have the big picture

1612
00:58:18,799 --> 00:58:19,520
answer

1613
00:58:19,520 --> 00:58:22,240
but what we actually need is time for

1614
00:58:22,240 --> 00:58:23,960
people to be able to heal through

1615
00:58:23,960 --> 00:58:25,280
experimentation

1616
00:58:25,280 --> 00:58:26,559
and to be able to know that there's

1617
00:58:26,559 --> 00:58:28,799
growth you know how did that rose grow

1618
00:58:28,799 --> 00:58:30,720
from concrete it was first a little

1619
00:58:30,720 --> 00:58:31,440
shoot

1620
00:58:31,440 --> 00:58:33,520
and imagine if there was tons of little

1621
00:58:33,520 --> 00:58:34,880
shoots like that tons of little

1622
00:58:34,880 --> 00:58:36,880
revolutionary possibilities

1623
00:58:36,880 --> 00:58:38,640
that people from people that are coming

1624
00:58:38,640 --> 00:58:40,400
out of digital apartheid that are coming

1625
00:58:40,400 --> 00:58:42,000
from surveillance capitalism

1626
00:58:42,000 --> 00:58:44,240
that are coming from uh you know digital

1627
00:58:44,240 --> 00:58:45,280
brahminism

1628
00:58:45,280 --> 00:58:47,599
imagining this world where we are

1629
00:58:47,599 --> 00:58:48,640
centered

1630
00:58:48,640 --> 00:58:51,520
not capital and sasha i'm just wondering

1631
00:58:51,520 --> 00:58:53,040
if you can kind of bring us home

1632
00:58:53,040 --> 00:58:55,520
um for people that you know may have

1633
00:58:55,520 --> 00:58:57,280
started to feel overwhelmed when we

1634
00:58:57,280 --> 00:58:59,359
started but now see a little opening and

1635
00:58:59,359 --> 00:59:01,040
see a little possibility

1636
00:59:01,040 --> 00:59:03,680
how else might we open people's hearts

1637
00:59:03,680 --> 00:59:06,240
at this time

1638
00:59:06,240 --> 00:59:08,160
well i guess i'll just close by saying

1639
00:59:08,160 --> 00:59:09,280
you know it's

1640
00:59:09,280 --> 00:59:12,880
it's pride month and as a trans person

1641
00:59:12,880 --> 00:59:16,079
who's written about uh sort of my

1642
00:59:16,079 --> 00:59:18,960
interactions in a trans body with

1643
00:59:18,960 --> 00:59:20,880
airport security systems and the way

1644
00:59:20,880 --> 00:59:22,880
that they're designed to

1645
00:59:22,880 --> 00:59:24,640
reproduce cyst normativity or the

1646
00:59:24,640 --> 00:59:27,280
assumption that everybody

1647
00:59:27,280 --> 00:59:29,040
identifies with the same gender they're

1648
00:59:29,040 --> 00:59:30,400
assigned at birth

1649
00:59:30,400 --> 00:59:32,640
and the way that technical systems just

1650
00:59:32,640 --> 00:59:34,240
sort of break

1651
00:59:34,240 --> 00:59:37,119
uh when they attempt to reduce the

1652
00:59:37,119 --> 00:59:37,920
dramatic

1653
00:59:37,920 --> 00:59:41,280
and beautiful diversity of human bodies

1654
00:59:41,280 --> 00:59:42,319
and experiences

1655
00:59:42,319 --> 00:59:45,599
into limited binary categories it

1656
00:59:45,599 --> 00:59:48,079
gives me a lot of hope when i look at

1657
00:59:48,079 --> 00:59:48,880
how

1658
00:59:48,880 --> 00:59:51,119
despite hundreds of years of settler

1659
00:59:51,119 --> 00:59:52,640
colonial violence

1660
00:59:52,640 --> 00:59:54,319
that systematically attempted to

1661
00:59:54,319 --> 00:59:55,920
eliminate destroy

1662
00:59:55,920 --> 00:59:59,119
dismember and kill third gender

1663
00:59:59,119 --> 01:00:01,920
and non-binary peoples in everywhere

1664
01:00:01,920 --> 01:00:02,880
around the world

1665
01:00:02,880 --> 01:00:07,119
that uh colonizers went um

1666
01:00:07,119 --> 01:00:09,760
that did not work because people are not

1667
01:00:09,760 --> 01:00:10,559
like that

1668
01:00:10,559 --> 01:00:13,520
and so there continues to be a beautiful

1669
01:00:13,520 --> 01:00:14,640
diversity

1670
01:00:14,640 --> 01:00:16,480
of human bodies and genders and

1671
01:00:16,480 --> 01:00:17,680
experiences

1672
01:00:17,680 --> 01:00:20,240
of many many different kinds and the

1673
01:00:20,240 --> 01:00:22,960
reductive categorization that so much of

1674
01:00:22,960 --> 01:00:24,079
the tech sector

1675
01:00:24,079 --> 01:00:27,440
is deeply invested in reproducing

1676
01:00:27,440 --> 01:00:30,480
fails against uh

1677
01:00:30,480 --> 01:00:33,920
the brilliance of human

1678
01:00:33,920 --> 01:00:36,480
experience and histories and

1679
01:00:36,480 --> 01:00:38,079
trajectories

1680
01:00:38,079 --> 01:00:41,359
so we cannot be contained we cannot be

1681
01:00:41,359 --> 01:00:45,040
boxed and expect us

1682
01:00:45,040 --> 01:00:47,119
no i'm just saying um there are many

1683
01:00:47,119 --> 01:00:48,880
worlds and they're all sort of

1684
01:00:48,880 --> 01:00:50,960
struggling to be born and the one

1685
01:00:50,960 --> 01:00:53,040
that the masters of tech and the world

1686
01:00:53,040 --> 01:00:54,000
billionaires

1687
01:00:54,000 --> 01:00:56,319
who pay no taxes as propublica just

1688
01:00:56,319 --> 01:00:57,520
demonstrated

1689
01:00:57,520 --> 01:01:00,000
um you know their vision is only one

1690
01:01:00,000 --> 01:01:00,799
vision

1691
01:01:00,799 --> 01:01:04,079
among billions and um i have

1692
01:01:04,079 --> 01:01:07,119
hope and faith that with organizing and

1693
01:01:07,119 --> 01:01:10,319
solidarity and with accomplices

1694
01:01:10,319 --> 01:01:12,799
of many kinds in many directions we'll

1695
01:01:12,799 --> 01:01:16,000
build some of those other worlds

1696
01:01:16,720 --> 01:01:19,680
so i just want to thank you for those

1697
01:01:19,680 --> 01:01:21,440
closing thoughts and for all the people

1698
01:01:21,440 --> 01:01:23,040
that joined us

1699
01:01:23,040 --> 01:01:25,440
we are here even in this conversation

1700
01:01:25,440 --> 01:01:27,520
building that other world

1701
01:01:27,520 --> 01:01:29,920
and so we just want to encourage you all

1702
01:01:29,920 --> 01:01:30,720
to

1703
01:01:30,720 --> 01:01:32,799
know that there's still hope know that

1704
01:01:32,799 --> 01:01:33,880
we're building hope through

1705
01:01:33,880 --> 01:01:36,240
experimentations and relationships and

1706
01:01:36,240 --> 01:01:37,200
dreaming

1707
01:01:37,200 --> 01:01:39,280
and to thank everyone who's showing up

1708
01:01:39,280 --> 01:01:41,119
in these hard times and know

1709
01:01:41,119 --> 01:01:43,760
that we see you we hear you we are part

1710
01:01:43,760 --> 01:01:45,040
of one community

1711
01:01:45,040 --> 01:01:47,359
and we will win so thank you and thank

1712
01:01:47,359 --> 01:01:48,880
you rexcon for hosting this really

1713
01:01:48,880 --> 01:01:50,079
powerful conversation

1714
01:01:50,079 --> 01:02:07,839
jbeam andy jsov3

1715
01:03:58,079 --> 01:04:00,160
you

