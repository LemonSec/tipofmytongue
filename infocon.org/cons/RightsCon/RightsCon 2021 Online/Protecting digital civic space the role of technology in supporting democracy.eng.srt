1
00:00:36,770 --> 00:00:43,320
[Music]

2
00:00:50,000 --> 00:00:51,120
good morning

3
00:00:51,120 --> 00:00:53,600
good afternoon good evening and welcome

4
00:00:53,600 --> 00:00:54,480
everybody

5
00:00:54,480 --> 00:00:57,360
my name is ann marie inc of larsen and

6
00:00:57,360 --> 00:00:59,199
i'm denmark's tech ambassador and i'm

7
00:00:59,199 --> 00:01:01,760
really excited to be here today

8
00:01:01,760 --> 00:01:03,280
thank you all for tuning in to this

9
00:01:03,280 --> 00:01:05,438
special rights clean session focusing on

10
00:01:05,438 --> 00:01:06,240
protecting

11
00:01:06,240 --> 00:01:09,600
digital civic space today i am

12
00:01:09,600 --> 00:01:11,600
thrilled to share this virtual stage

13
00:01:11,600 --> 00:01:13,280
with some of the most prominent

14
00:01:13,280 --> 00:01:16,000
amazing knowledgeable people on the

15
00:01:16,000 --> 00:01:16,560
earth

16
00:01:16,560 --> 00:01:19,680
uh leading in this debate around how do

17
00:01:19,680 --> 00:01:21,200
we make sure that technology

18
00:01:21,200 --> 00:01:24,080
actually works for democracy there is no

19
00:01:24,080 --> 00:01:25,680
doubt that technology has many

20
00:01:25,680 --> 00:01:27,280
empowering qualities

21
00:01:27,280 --> 00:01:29,600
allowing us to work and socialize across

22
00:01:29,600 --> 00:01:30,640
borders and time

23
00:01:30,640 --> 00:01:32,400
allowing it to organize in a different

24
00:01:32,400 --> 00:01:33,920
ways and enhancing

25
00:01:33,920 --> 00:01:36,799
digital civic space at the time where at

26
00:01:36,799 --> 00:01:38,079
the same time we're also

27
00:01:38,079 --> 00:01:40,880
seeing how increasingly it threatens

28
00:01:40,880 --> 00:01:43,200
potentially both core aspects of

29
00:01:43,200 --> 00:01:46,079
democracy and some of our civic freedoms

30
00:01:46,079 --> 00:01:48,479
in today's sessions we are going to gain

31
00:01:48,479 --> 00:01:50,880
new insights on what the challenges

32
00:01:50,880 --> 00:01:52,640
right now but also the opportunities

33
00:01:52,640 --> 00:01:54,000
related to digital civic

34
00:01:54,000 --> 00:01:57,280
space and we'll explore how to protect

35
00:01:57,280 --> 00:01:59,520
and promote digital civic space through

36
00:01:59,520 --> 00:02:01,200
new and enhanced multi-stakeholder

37
00:02:01,200 --> 00:02:03,280
collaboration

38
00:02:03,280 --> 00:02:05,040
the session today is also laying the

39
00:02:05,040 --> 00:02:07,439
groundwork for a new danish initiative

40
00:02:07,439 --> 00:02:10,479
focused on ensuring that technology is

41
00:02:10,479 --> 00:02:12,239
actively supporting

42
00:02:12,239 --> 00:02:15,440
rather than undermining democracy

43
00:02:15,440 --> 00:02:18,800
to start with i'm honored to welcome

44
00:02:18,800 --> 00:02:21,760
danish foreign minister mr yeah because

45
00:02:21,760 --> 00:02:23,599
to give a few brief remarks

46
00:02:23,599 --> 00:02:26,319
on how he sees this mr kofil the floor

47
00:02:26,319 --> 00:02:28,799
is yours

48
00:02:29,040 --> 00:02:31,360
thank you so much marie and good

49
00:02:31,360 --> 00:02:32,160
afternoon

50
00:02:32,160 --> 00:02:34,000
and good morning and good evening to

51
00:02:34,000 --> 00:02:35,360
everyone

52
00:02:35,360 --> 00:02:38,239
i wish to start by thanking accessnow

53
00:02:38,239 --> 00:02:40,080
and the rightscon team for organizing

54
00:02:40,080 --> 00:02:41,519
another incredible

55
00:02:41,519 --> 00:02:44,959
event ricecon has continued to grow

56
00:02:44,959 --> 00:02:46,800
and has become an enormously important

57
00:02:46,800 --> 00:02:48,239
platform for dialogue

58
00:02:48,239 --> 00:02:50,160
and i'm very happy to to be here and be

59
00:02:50,160 --> 00:02:51,440
part of that

60
00:02:51,440 --> 00:02:54,480
last saturday we celebrated

61
00:02:54,480 --> 00:02:58,159
the 172nd

62
00:02:58,159 --> 00:03:00,879
birthday of the danish constitution this

63
00:03:00,879 --> 00:03:02,480
makes denmark one of the oldest

64
00:03:02,480 --> 00:03:04,080
democracies in the world

65
00:03:04,080 --> 00:03:05,920
we celebrated our democracy with

66
00:03:05,920 --> 00:03:07,760
speeches with debates

67
00:03:07,760 --> 00:03:10,879
festivity nevertheless

68
00:03:10,879 --> 00:03:14,720
i am worried for the state of democracy

69
00:03:14,720 --> 00:03:17,760
globally i'm concerned that new

70
00:03:17,760 --> 00:03:18,959
technology and the way

71
00:03:18,959 --> 00:03:21,680
social media platform functions today

72
00:03:21,680 --> 00:03:23,680
are challenging and even undermining uh

73
00:03:23,680 --> 00:03:24,720
democracy

74
00:03:24,720 --> 00:03:26,720
despite all this benefit and they have a

75
00:03:26,720 --> 00:03:28,799
lot of benefit the digital revolution

76
00:03:28,799 --> 00:03:30,720
has dramatically changed the

77
00:03:30,720 --> 00:03:33,519
playing field of democratic governance

78
00:03:33,519 --> 00:03:35,519
digital tools have increasingly become

79
00:03:35,519 --> 00:03:36,159
the weapon

80
00:03:36,159 --> 00:03:40,000
of choice against democracy and private

81
00:03:40,000 --> 00:03:42,239
tech companies have gained unprecedented

82
00:03:42,239 --> 00:03:43,280
influence over

83
00:03:43,280 --> 00:03:45,440
our societies and democratic

84
00:03:45,440 --> 00:03:46,799
institutions

85
00:03:46,799 --> 00:03:50,319
i worry that the rise of disinformation

86
00:03:50,319 --> 00:03:54,480
will solve distrust of objective media

87
00:03:54,480 --> 00:03:57,680
it scares me when democratic governments

88
00:03:57,680 --> 00:03:59,280
use

89
00:03:59,280 --> 00:04:01,920
technology to create a surveillance

90
00:04:01,920 --> 00:04:03,599
state above and beyond

91
00:04:03,599 --> 00:04:06,640
uh not democratic autocratic government

92
00:04:06,640 --> 00:04:09,519
may create a surveillance state above

93
00:04:09,519 --> 00:04:10,480
and beyond

94
00:04:10,480 --> 00:04:14,640
anything oval imagined i'm horrified

95
00:04:14,640 --> 00:04:16,880
when i see human rights and fundamental

96
00:04:16,880 --> 00:04:19,279
freedoms are under attack online

97
00:04:19,279 --> 00:04:21,040
and how the digital space for civil

98
00:04:21,040 --> 00:04:22,720
society is shrinking

99
00:04:22,720 --> 00:04:25,280
in many places and i'm worried when

100
00:04:25,280 --> 00:04:26,880
foreign actors use social media

101
00:04:26,880 --> 00:04:28,400
manipulation to

102
00:04:28,400 --> 00:04:31,120
sway elections and undermine both new

103
00:04:31,120 --> 00:04:32,479
and more mature

104
00:04:32,479 --> 00:04:35,759
democracies fortunately i want to

105
00:04:35,759 --> 00:04:36,639
underline this

106
00:04:36,639 --> 00:04:38,720
not everything is bleak we also have

107
00:04:38,720 --> 00:04:40,000
reason to hope

108
00:04:40,000 --> 00:04:42,080
digital technology holds great potential

109
00:04:42,080 --> 00:04:43,440
for strengthening democracy

110
00:04:43,440 --> 00:04:45,919
and citizens engagement new forms of

111
00:04:45,919 --> 00:04:46,720
mass movement

112
00:04:46,720 --> 00:04:50,240
and digital mobilization are

113
00:04:50,240 --> 00:04:53,840
also a very important part of democratic

114
00:04:53,840 --> 00:04:55,600
values at a global scale

115
00:04:55,600 --> 00:04:57,680
new social movements are flourishing and

116
00:04:57,680 --> 00:04:59,199
especially young people

117
00:04:59,199 --> 00:05:01,600
engage in politics in many different

118
00:05:01,600 --> 00:05:03,600
ways supported by

119
00:05:03,600 --> 00:05:06,080
these digital platforms for better or

120
00:05:06,080 --> 00:05:08,720
worse the kobit-19 pandemic has been a

121
00:05:08,720 --> 00:05:09,440
catalyst

122
00:05:09,440 --> 00:05:12,639
for a massive digital leap we need

123
00:05:12,639 --> 00:05:15,440
to support and strengthen this momentum

124
00:05:15,440 --> 00:05:16,479
and denmark

125
00:05:16,479 --> 00:05:18,800
is a long-term and strong supporter and

126
00:05:18,800 --> 00:05:19,600
promoter

127
00:05:19,600 --> 00:05:21,520
of human rights democracy and good

128
00:05:21,520 --> 00:05:23,360
governance globally

129
00:05:23,360 --> 00:05:25,600
this is the backbone of our foreign

130
00:05:25,600 --> 00:05:26,400
policy

131
00:05:26,400 --> 00:05:28,639
and we are actively engaged in defending

132
00:05:28,639 --> 00:05:30,560
human rights using technology

133
00:05:30,560 --> 00:05:33,840
and in enhancing the digital resilience

134
00:05:33,840 --> 00:05:37,919
of civil society and i'm pleased to see

135
00:05:37,919 --> 00:05:39,520
that many of our partners are here

136
00:05:39,520 --> 00:05:43,919
today and we also pursue this policy

137
00:05:43,919 --> 00:05:46,080
in international fora in the human

138
00:05:46,080 --> 00:05:47,600
rights council denmark is

139
00:05:47,600 --> 00:05:50,800
part of a core group presenting

140
00:05:50,800 --> 00:05:53,759
a resolution on new and emerging digital

141
00:05:53,759 --> 00:05:54,639
technologies

142
00:05:54,639 --> 00:05:56,319
and human rights and the link between

143
00:05:56,319 --> 00:05:58,479
that but

144
00:05:58,479 --> 00:06:01,440
this is uh not enough to stand up

145
00:06:01,440 --> 00:06:01,919
against

146
00:06:01,919 --> 00:06:03,919
the digital threats to a democracy we

147
00:06:03,919 --> 00:06:06,240
need to up our game

148
00:06:06,240 --> 00:06:09,120
all of us here in this virtual room

149
00:06:09,120 --> 00:06:09,680
today

150
00:06:09,680 --> 00:06:12,800
i'm proud to to launch a new danish

151
00:06:12,800 --> 00:06:14,000
initiative

152
00:06:14,000 --> 00:06:16,639
check for the democracy with this

153
00:06:16,639 --> 00:06:19,440
initiative we want to kick-start

154
00:06:19,440 --> 00:06:21,919
a new multi-stakeholder push to make

155
00:06:21,919 --> 00:06:23,919
sure technology supports

156
00:06:23,919 --> 00:06:26,960
democracy instead of undermining it

157
00:06:26,960 --> 00:06:29,600
we will bring together governments civil

158
00:06:29,600 --> 00:06:30,479
society

159
00:06:30,479 --> 00:06:33,360
and tech companies around the same table

160
00:06:33,360 --> 00:06:34,000
to find new

161
00:06:34,000 --> 00:06:35,680
solutions to the dark side of new

162
00:06:35,680 --> 00:06:38,319
technology to force new partnership

163
00:06:38,319 --> 00:06:40,960
between responsible tech companies and

164
00:06:40,960 --> 00:06:42,319
civil society

165
00:06:42,319 --> 00:06:44,720
and to commit as many as possible to the

166
00:06:44,720 --> 00:06:46,800
goal of making sure that new technology

167
00:06:46,800 --> 00:06:47,600
works

168
00:06:47,600 --> 00:06:50,400
for not against democracy and human

169
00:06:50,400 --> 00:06:51,840
rights

170
00:06:51,840 --> 00:06:54,880
because we believe that all

171
00:06:54,880 --> 00:06:58,160
differences aside a critical mass

172
00:06:58,160 --> 00:07:00,560
of governments tech companies and civil

173
00:07:00,560 --> 00:07:02,000
society organization

174
00:07:02,000 --> 00:07:04,400
have a joint interest in shaping a

175
00:07:04,400 --> 00:07:06,080
responsible democratic

176
00:07:06,080 --> 00:07:09,520
and safe technological future together

177
00:07:09,520 --> 00:07:13,199
as part and also equals and also as a

178
00:07:13,199 --> 00:07:16,880
strong signal to the tendency of uh

179
00:07:16,880 --> 00:07:20,000
also autocratic governments and

180
00:07:20,000 --> 00:07:21,520
attacks on our values that we see

181
00:07:21,520 --> 00:07:23,840
globally in in today's world

182
00:07:23,840 --> 00:07:25,520
as part of the initiative the danes

183
00:07:25,520 --> 00:07:27,039
minister for development corporation and

184
00:07:27,039 --> 00:07:27,599
i will

185
00:07:27,599 --> 00:07:30,000
invite high level representatives from

186
00:07:30,000 --> 00:07:31,680
government civil society and the tech

187
00:07:31,680 --> 00:07:32,400
industry

188
00:07:32,400 --> 00:07:35,120
to copenhagen in november to decide how

189
00:07:35,120 --> 00:07:36,400
to pursue

190
00:07:36,400 --> 00:07:39,440
on this important agenda together

191
00:07:39,440 --> 00:07:42,000
the perfect solution must not stand in

192
00:07:42,000 --> 00:07:42,880
the way of

193
00:07:42,880 --> 00:07:46,000
even smaller progress in all the

194
00:07:46,000 --> 00:07:47,120
concrete areas

195
00:07:47,120 --> 00:07:50,080
where we governments civil society and

196
00:07:50,080 --> 00:07:51,199
tech companies

197
00:07:51,199 --> 00:07:53,759
can't agree to act in partnership i

198
00:07:53,759 --> 00:07:55,599
think we should do it

199
00:07:55,599 --> 00:07:58,560
this is what we want to to pave the way

200
00:07:58,560 --> 00:08:00,160
for in copenhagen

201
00:08:00,160 --> 00:08:02,560
in november very important debate full

202
00:08:02,560 --> 00:08:03,440
of dilemmas

203
00:08:03,440 --> 00:08:05,360
full of difficult challenges but

204
00:08:05,360 --> 00:08:06,720
something we need to

205
00:08:06,720 --> 00:08:09,440
to show that we can handle uh together

206
00:08:09,440 --> 00:08:11,199
we who believe in democracy

207
00:08:11,199 --> 00:08:14,160
in the values that that are under

208
00:08:14,160 --> 00:08:15,199
pressure globally

209
00:08:15,199 --> 00:08:17,199
so with this i want to thank you for

210
00:08:17,199 --> 00:08:18,720
your attention

211
00:08:18,720 --> 00:08:20,560
i wish you a continuing successful

212
00:08:20,560 --> 00:08:22,639
rights con and thank you so much for

213
00:08:22,639 --> 00:08:24,720
for all of the engagement that you are

214
00:08:24,720 --> 00:08:26,000
giving to this

215
00:08:26,000 --> 00:08:29,360
very important topic thank you

216
00:08:30,400 --> 00:08:33,200
thank you so much minister kofo for a

217
00:08:33,200 --> 00:08:35,039
thought provoking keynote highlighting

218
00:08:35,039 --> 00:08:36,240
both

219
00:08:36,240 --> 00:08:38,000
the great challenges but also the great

220
00:08:38,000 --> 00:08:39,440
opportunities of this space

221
00:08:39,440 --> 00:08:41,039
and thank you very much for presenting

222
00:08:41,039 --> 00:08:43,039
an active engagement on behalf of the

223
00:08:43,039 --> 00:08:45,360
of the danish government by seeking to

224
00:08:45,360 --> 00:08:46,720
tackle these challenges

225
00:08:46,720 --> 00:08:48,560
at the intersection of tech democracy

226
00:08:48,560 --> 00:08:50,480
and human rights

227
00:08:50,480 --> 00:08:52,320
building on the minister's keynotes it's

228
00:08:52,320 --> 00:08:54,640
evident that there is a lot to be done

229
00:08:54,640 --> 00:08:57,040
if we are to avoid the bleak outlook

230
00:08:57,040 --> 00:08:58,320
that he mentioned

231
00:08:58,320 --> 00:09:00,240
and focusing on how do we harness the

232
00:09:00,240 --> 00:09:02,480
toll uh technologies for all the

233
00:09:02,480 --> 00:09:04,320
positive things it can do to society

234
00:09:04,320 --> 00:09:06,000
space the question is

235
00:09:06,000 --> 00:09:07,760
how do we advance that how do we

236
00:09:07,760 --> 00:09:10,080
cooperate what do we need to do

237
00:09:10,080 --> 00:09:12,320
to answer those questions i luckily have

238
00:09:12,320 --> 00:09:14,800
five amazing people with me here today

239
00:09:14,800 --> 00:09:17,040
to help find some of those answers and

240
00:09:17,040 --> 00:09:18,720
who are really at the front line whether

241
00:09:18,720 --> 00:09:20,080
it's on the developing side of

242
00:09:20,080 --> 00:09:22,080
technologies on the using side

243
00:09:22,080 --> 00:09:24,399
or where activists right now are trying

244
00:09:24,399 --> 00:09:26,640
to do a difference

245
00:09:26,640 --> 00:09:28,560
let me start by introducing them briefly

246
00:09:28,560 --> 00:09:30,320
to you all with we have

247
00:09:30,320 --> 00:09:32,399
dr joan donovan she is the research

248
00:09:32,399 --> 00:09:34,480
director of the schwernstein center on

249
00:09:34,480 --> 00:09:36,480
media politics and public policy at

250
00:09:36,480 --> 00:09:37,920
harvard kennedy school

251
00:09:37,920 --> 00:09:39,360
where she leads the technology and

252
00:09:39,360 --> 00:09:41,760
social change project which explores how

253
00:09:41,760 --> 00:09:42,800
media manipulation

254
00:09:42,800 --> 00:09:45,360
can control public conversation derail

255
00:09:45,360 --> 00:09:47,600
democracy and disrupt society

256
00:09:47,600 --> 00:09:50,080
some grand issues to be tackling with us

257
00:09:50,080 --> 00:09:52,399
today we also have miranda sisson

258
00:09:52,399 --> 00:09:54,080
miranda is a human rights director at

259
00:09:54,080 --> 00:09:56,640
facebook where she joined in 2019

260
00:09:56,640 --> 00:09:59,120
the company's human rights policy work

261
00:09:59,120 --> 00:10:00,640
miranda brings

262
00:10:00,640 --> 00:10:02,720
20 plus years of experience in human

263
00:10:02,720 --> 00:10:04,079
rights research and policy

264
00:10:04,079 --> 00:10:06,720
making we also have with us brett

265
00:10:06,720 --> 00:10:08,720
sullivan who is a well-known face to

266
00:10:08,720 --> 00:10:11,600
many of you as the founder of rightscon

267
00:10:11,600 --> 00:10:13,279
he's also the executive director of

268
00:10:13,279 --> 00:10:15,680
access now and constantly defending and

269
00:10:15,680 --> 00:10:17,680
extending the digital rights of users at

270
00:10:17,680 --> 00:10:18,079
risk

271
00:10:18,079 --> 00:10:21,040
around the world we also have with us

272
00:10:21,040 --> 00:10:22,320
today jessica xu

273
00:10:22,320 --> 00:10:24,800
she is the director of policy for reddit

274
00:10:24,800 --> 00:10:26,320
where she oversees all global

275
00:10:26,320 --> 00:10:28,480
governments relations and public policy

276
00:10:28,480 --> 00:10:29,920
for the company

277
00:10:29,920 --> 00:10:32,079
in addition to advising on matters of

278
00:10:32,079 --> 00:10:35,279
content product and advertising policy

279
00:10:35,279 --> 00:10:37,920
and finally we have today with us nimaya

280
00:10:37,920 --> 00:10:39,760
she is a founder of policy a civic

281
00:10:39,760 --> 00:10:41,040
technology company

282
00:10:41,040 --> 00:10:43,600
based out of kampala uganda working on

283
00:10:43,600 --> 00:10:44,880
the intersection of data

284
00:10:44,880 --> 00:10:46,880
design and technology tackling subjects

285
00:10:46,880 --> 00:10:48,560
such as digital inclusion

286
00:10:48,560 --> 00:10:50,959
detail rights and civic technology thank

287
00:10:50,959 --> 00:10:53,600
you all so much for joining

288
00:10:53,600 --> 00:10:56,320
let's jump right into getting a bit more

289
00:10:56,320 --> 00:10:58,640
perspectives from this panel

290
00:10:58,640 --> 00:11:00,720
joan if you don't mind i'd love to start

291
00:11:00,720 --> 00:11:02,399
with you um

292
00:11:02,399 --> 00:11:03,920
in your work at the technology and

293
00:11:03,920 --> 00:11:05,519
social change project

294
00:11:05,519 --> 00:11:07,680
you explore how media manipulation can

295
00:11:07,680 --> 00:11:09,519
control public conversation that's

296
00:11:09,519 --> 00:11:11,200
really at the heart of our democratic

297
00:11:11,200 --> 00:11:12,079
debate

298
00:11:12,079 --> 00:11:14,320
you know how can this disrupt society

299
00:11:14,320 --> 00:11:16,399
derail democracy some of the really big

300
00:11:16,399 --> 00:11:17,760
issues

301
00:11:17,760 --> 00:11:21,200
could you help us start by defining

302
00:11:21,200 --> 00:11:23,600
what is the tool civic space and how do

303
00:11:23,600 --> 00:11:24,399
you perceive

304
00:11:24,399 --> 00:11:28,399
its current state uh no small questions

305
00:11:28,399 --> 00:11:28,959
uh

306
00:11:28,959 --> 00:11:30,720
thank you so much and i really

307
00:11:30,720 --> 00:11:33,279
appreciate uh the commentary and the

308
00:11:33,279 --> 00:11:34,240
dedication

309
00:11:34,240 --> 00:11:37,279
uh um about

310
00:11:37,279 --> 00:11:40,560
um what denmark is is planning to do and

311
00:11:40,560 --> 00:11:40,800
i

312
00:11:40,800 --> 00:11:43,279
only wish that my my home country here

313
00:11:43,279 --> 00:11:43,920
in the us

314
00:11:43,920 --> 00:11:46,079
would would think through some of these

315
00:11:46,079 --> 00:11:47,279
issues um

316
00:11:47,279 --> 00:11:49,760
more holistically not just in the policy

317
00:11:49,760 --> 00:11:51,760
making space but also

318
00:11:51,760 --> 00:11:53,680
as we think about this grand challenge

319
00:11:53,680 --> 00:11:56,800
around our information crisis and

320
00:11:56,800 --> 00:11:58,959
the question of space is often one that

321
00:11:58,959 --> 00:12:00,959
we talk about

322
00:12:00,959 --> 00:12:04,880
uh related to internet and platforms of

323
00:12:04,880 --> 00:12:07,040
course a decade ago when we were having

324
00:12:07,040 --> 00:12:08,480
a convert having

325
00:12:08,480 --> 00:12:10,480
a very similar conversation about social

326
00:12:10,480 --> 00:12:13,120
media in a very different context uh

327
00:12:13,120 --> 00:12:14,959
there was a lot of talk about how

328
00:12:14,959 --> 00:12:16,240
important it was going to be

329
00:12:16,240 --> 00:12:19,279
that social media remain open

330
00:12:19,279 --> 00:12:22,480
and free and

331
00:12:22,480 --> 00:12:25,920
kind of as a technology be allowed to

332
00:12:25,920 --> 00:12:29,440
explore and do uh whatever they saw fit

333
00:12:29,440 --> 00:12:29,920
these

334
00:12:29,920 --> 00:12:31,440
you know these companies because there

335
00:12:31,440 --> 00:12:35,200
was a lot of energy around this idea

336
00:12:35,200 --> 00:12:37,200
that what happens online

337
00:12:37,200 --> 00:12:40,959
it has these um important effects

338
00:12:40,959 --> 00:12:44,320
in our public sphere and not just in our

339
00:12:44,320 --> 00:12:46,800
public sphere related to

340
00:12:46,800 --> 00:12:48,560
conversations that people are having but

341
00:12:48,560 --> 00:12:50,560
also relationship to

342
00:12:50,560 --> 00:12:52,720
actual physical space if we think back

343
00:12:52,720 --> 00:12:54,800
to um

344
00:12:54,800 --> 00:12:57,120
uh even the documentary the square about

345
00:12:57,120 --> 00:12:58,639
the egyptian revolution

346
00:12:58,639 --> 00:13:00,639
and and things that have happened in

347
00:13:00,639 --> 00:13:02,240
tahrir square and then of course the

348
00:13:02,240 --> 00:13:03,760
occupy movements

349
00:13:03,760 --> 00:13:07,600
there is uh this cl this uh relationship

350
00:13:07,600 --> 00:13:08,240
to in

351
00:13:08,240 --> 00:13:10,800
to spatiality but i think it's also

352
00:13:10,800 --> 00:13:13,600
important for us to realize that

353
00:13:13,600 --> 00:13:16,160
uh there is no public space that doesn't

354
00:13:16,160 --> 00:13:18,000
have some kind of

355
00:13:18,000 --> 00:13:20,959
uh security and safety policies and

356
00:13:20,959 --> 00:13:23,519
apparatus and protocols in place

357
00:13:23,519 --> 00:13:25,760
right i can't just go to the boston

358
00:13:25,760 --> 00:13:27,519
common and set up a tent and

359
00:13:27,519 --> 00:13:30,639
declare myself uh sovereign and and

360
00:13:30,639 --> 00:13:33,680
uh and take up public space and and the

361
00:13:33,680 --> 00:13:34,079
issue

362
00:13:34,079 --> 00:13:36,560
of course with online platforms related

363
00:13:36,560 --> 00:13:37,839
to public space is

364
00:13:37,839 --> 00:13:41,920
very much about uh what happens on those

365
00:13:41,920 --> 00:13:43,839
platforms and how people present

366
00:13:43,839 --> 00:13:44,800
themselves

367
00:13:44,800 --> 00:13:47,519
and what kind of disruptions of course

368
00:13:47,519 --> 00:13:49,760
uh

369
00:13:49,760 --> 00:13:51,920
disinformation agents or media

370
00:13:51,920 --> 00:13:53,920
manipulators might have

371
00:13:53,920 --> 00:13:57,040
on everybody else right and so this is

372
00:13:57,040 --> 00:13:57,279
the

373
00:13:57,279 --> 00:13:59,839
the fundamental question and for us it's

374
00:13:59,839 --> 00:14:00,480
really about

375
00:14:00,480 --> 00:14:02,399
as a research team thinking through

376
00:14:02,399 --> 00:14:04,320
these harms thinking through

377
00:14:04,320 --> 00:14:06,079
hate speech and what it looks like to

378
00:14:06,079 --> 00:14:07,600
have hate speech at scale

379
00:14:07,600 --> 00:14:10,800
right not just a few uh neo-nazi groups

380
00:14:10,800 --> 00:14:12,800
but you have militias getting organized

381
00:14:12,800 --> 00:14:14,480
on facebook and we saw

382
00:14:14,480 --> 00:14:17,040
the effects of that in kenosha over the

383
00:14:17,040 --> 00:14:17,839
summer where

384
00:14:17,839 --> 00:14:20,959
um kyle rittenhouse uh killed several

385
00:14:20,959 --> 00:14:21,600
people

386
00:14:21,600 --> 00:14:25,600
uh after he had uh joined a group that

387
00:14:25,600 --> 00:14:26,079
had been

388
00:14:26,079 --> 00:14:30,160
organizing on facebook um we also worry

389
00:14:30,160 --> 00:14:31,760
a lot about harassments

390
00:14:31,760 --> 00:14:33,519
and network harassment specifically

391
00:14:33,519 --> 00:14:35,760
aimed at silencing journalists and

392
00:14:35,760 --> 00:14:36,800
advocates

393
00:14:36,800 --> 00:14:38,639
right so it's it's not the case that

394
00:14:38,639 --> 00:14:40,639
it's just a few different letters to the

395
00:14:40,639 --> 00:14:41,680
editor that are

396
00:14:41,680 --> 00:14:45,040
uh you know way off base we have at some

397
00:14:45,040 --> 00:14:45,519
point

398
00:14:45,519 --> 00:14:47,839
hundreds of people at a time attacking

399
00:14:47,839 --> 00:14:48,720
journalists

400
00:14:48,720 --> 00:14:50,160
uh trying to get journalists to shut

401
00:14:50,160 --> 00:14:51,839
down their accounts especially

402
00:14:51,839 --> 00:14:52,560
journalists

403
00:14:52,560 --> 00:14:55,120
that are covering very serious issues

404
00:14:55,120 --> 00:14:56,000
like women's

405
00:14:56,000 --> 00:14:59,360
health particularly around abortions and

406
00:14:59,360 --> 00:15:00,800
then the last piece

407
00:15:00,800 --> 00:15:02,720
which i think is also one that uh

408
00:15:02,720 --> 00:15:04,800
resonates across countries is

409
00:15:04,800 --> 00:15:07,440
the degree to which disinformation uh

410
00:15:07,440 --> 00:15:09,519
promotes incitement to violence

411
00:15:09,519 --> 00:15:11,199
and of course in the united states on

412
00:15:11,199 --> 00:15:13,120
january 6th we saw this

413
00:15:13,120 --> 00:15:16,399
uh abhorrent and horrible attempt

414
00:15:16,399 --> 00:15:20,160
to uh take over the u.s government um

415
00:15:20,160 --> 00:15:23,040
several people died there was many many

416
00:15:23,040 --> 00:15:24,639
injuries

417
00:15:24,639 --> 00:15:27,920
but what's different about january 6

418
00:15:27,920 --> 00:15:30,399
that i think the us really wasn't ready

419
00:15:30,399 --> 00:15:31,279
for

420
00:15:31,279 --> 00:15:33,440
was they weren't taking inciting

421
00:15:33,440 --> 00:15:35,360
rhetoric seriously

422
00:15:35,360 --> 00:15:37,920
so anywhere you looked on any platform

423
00:15:37,920 --> 00:15:39,839
that you were looking at related to the

424
00:15:39,839 --> 00:15:41,440
hashtag stop the steal

425
00:15:41,440 --> 00:15:44,320
or uh any of the the ones related to the

426
00:15:44,320 --> 00:15:45,680
election being rigged

427
00:15:45,680 --> 00:15:47,759
you would find violent content very

428
00:15:47,759 --> 00:15:49,199
violent content

429
00:15:49,199 --> 00:15:53,519
uh and there was a lot of confusion

430
00:15:53,519 --> 00:15:56,399
uh in the moment about what do you do

431
00:15:56,399 --> 00:15:58,480
with these kinds of words what do you do

432
00:15:58,480 --> 00:16:00,399
with these calls to action and so i

433
00:16:00,399 --> 00:16:02,000
think there's going to be

434
00:16:02,000 --> 00:16:03,920
at least through the u.s and and it will

435
00:16:03,920 --> 00:16:05,839
reverberate of course throughout the the

436
00:16:05,839 --> 00:16:07,040
rest of the world

437
00:16:07,040 --> 00:16:11,120
a very public reckoning about the

438
00:16:11,120 --> 00:16:14,800
the process by which uh social media

439
00:16:14,800 --> 00:16:18,079
um allows for these kinds of

440
00:16:18,079 --> 00:16:23,839
um serious uh

441
00:16:24,560 --> 00:16:27,279
i don't want to call them debates

442
00:16:27,279 --> 00:16:29,360
because they're not really debates

443
00:16:29,360 --> 00:16:31,360
um once people think the election has

444
00:16:31,360 --> 00:16:32,480
been rigged

445
00:16:32,480 --> 00:16:35,120
and it hasn't that's different than uh

446
00:16:35,120 --> 00:16:36,639
you know just a normal kind of

447
00:16:36,639 --> 00:16:38,720
conversation that one person might have

448
00:16:38,720 --> 00:16:41,279
with another in the us we definitely had

449
00:16:41,279 --> 00:16:43,680
politicians weighing in in ways that

450
00:16:43,680 --> 00:16:44,320
were

451
00:16:44,320 --> 00:16:47,199
obviously beneficial to them uh and

452
00:16:47,199 --> 00:16:49,199
incredibly destructive to our

453
00:16:49,199 --> 00:16:51,680
our democracy and our civic conversation

454
00:16:51,680 --> 00:16:52,560
and so

455
00:16:52,560 --> 00:16:54,079
uh those are the kinds of things that i

456
00:16:54,079 --> 00:16:55,279
think about when i'm thinking about the

457
00:16:55,279 --> 00:16:56,560
relationship between

458
00:16:56,560 --> 00:16:59,680
public space what do we do about it

459
00:16:59,680 --> 00:17:01,600
what do we also do about the digital

460
00:17:01,600 --> 00:17:03,759
space and how do we make it a place that

461
00:17:03,759 --> 00:17:04,559
has

462
00:17:04,559 --> 00:17:07,439
safety and protocols uh in ways that

463
00:17:07,439 --> 00:17:08,959
people understand

464
00:17:08,959 --> 00:17:10,959
what is allowed and what's not allowed

465
00:17:10,959 --> 00:17:12,880
and then what the actual repercussions

466
00:17:12,880 --> 00:17:13,599
are going to be

467
00:17:13,599 --> 00:17:16,240
thank you thank you so much joan and i

468
00:17:16,240 --> 00:17:18,160
think that gives a very

469
00:17:18,160 --> 00:17:20,000
thank you for that overview i think also

470
00:17:20,000 --> 00:17:21,359
for giving us a bit of a temperature

471
00:17:21,359 --> 00:17:23,439
check and how does it currently look

472
00:17:23,439 --> 00:17:26,079
miranda let me go to you um facebook is

473
00:17:26,079 --> 00:17:27,919
a company that has an incredible

474
00:17:27,919 --> 00:17:31,280
global impact not least on politics

475
00:17:31,280 --> 00:17:33,919
society and democratic debate uh it's

476
00:17:33,919 --> 00:17:36,160
very much the center of broad

477
00:17:36,160 --> 00:17:38,080
criticism but equally excitement about

478
00:17:38,080 --> 00:17:39,440
the potential

479
00:17:39,440 --> 00:17:41,760
since you joined facebook in 2019 you've

480
00:17:41,760 --> 00:17:43,600
been heavily involved in developing

481
00:17:43,600 --> 00:17:44,480
facebook human

482
00:17:44,480 --> 00:17:46,880
rights policy a policy that i understand

483
00:17:46,880 --> 00:17:48,559
was first released in here in march

484
00:17:48,559 --> 00:17:51,760
this year um now the huge responsibility

485
00:17:51,760 --> 00:17:53,120
of steering facebook

486
00:17:53,120 --> 00:17:55,039
human rights policy lays on your

487
00:17:55,039 --> 00:17:56,559
shoulders

488
00:17:56,559 --> 00:17:58,400
and given today's topics it would be

489
00:17:58,400 --> 00:18:00,640
great to hear your thoughts on

490
00:18:00,640 --> 00:18:03,280
what action has facebook taken um in

491
00:18:03,280 --> 00:18:04,880
order to contribute to protecting

492
00:18:04,880 --> 00:18:05,760
digital

493
00:18:05,760 --> 00:18:08,160
civic actors at risk and i think some of

494
00:18:08,160 --> 00:18:09,840
the actually some of the examples that

495
00:18:09,840 --> 00:18:11,200
jones just came with

496
00:18:11,200 --> 00:18:12,400
and how do you see i mean obviously

497
00:18:12,400 --> 00:18:13,919
we've been in a bit of a weird space the

498
00:18:13,919 --> 00:18:15,760
last 15 months with the pandemic how has

499
00:18:15,760 --> 00:18:18,480
that influenced that

500
00:18:18,480 --> 00:18:20,960
thank you very much thank you uh for

501
00:18:20,960 --> 00:18:22,559
having me here and joan for your very

502
00:18:22,559 --> 00:18:24,080
insightful comments

503
00:18:24,080 --> 00:18:27,120
um i think the first thing that to say

504
00:18:27,120 --> 00:18:28,160
is of course is

505
00:18:28,160 --> 00:18:32,000
is that i should do is to note that

506
00:18:32,000 --> 00:18:34,000
the human rights principles that we've

507
00:18:34,000 --> 00:18:36,240
developed over the last 60 years

508
00:18:36,240 --> 00:18:38,320
are incredibly important guardrails for

509
00:18:38,320 --> 00:18:39,919
these conversations

510
00:18:39,919 --> 00:18:43,280
when we have a contests over important

511
00:18:43,280 --> 00:18:44,400
public goods

512
00:18:44,400 --> 00:18:46,640
and rights are always confusing they're

513
00:18:46,640 --> 00:18:48,320
always got an element

514
00:18:48,320 --> 00:18:51,440
of of uh integrity or

515
00:18:51,440 --> 00:18:53,280
often an aggregate an element of

516
00:18:53,280 --> 00:18:55,120
malicious or perverse behavior

517
00:18:55,120 --> 00:18:57,840
and so understanding that the rights

518
00:18:57,840 --> 00:18:59,600
framework and other frameworks that we

519
00:18:59,600 --> 00:19:00,799
have

520
00:19:00,799 --> 00:19:03,600
that delineate and define a principled

521
00:19:03,600 --> 00:19:05,280
approach to rights in public space

522
00:19:05,280 --> 00:19:07,120
is really really important because civic

523
00:19:07,120 --> 00:19:08,400
space isn't just what i

524
00:19:08,400 --> 00:19:10,799
or you or joan or some government

525
00:19:10,799 --> 00:19:12,480
defines it is but we'd have

526
00:19:12,480 --> 00:19:15,360
have certain principles defined globally

527
00:19:15,360 --> 00:19:18,240
that we are wise to uphold in common

528
00:19:18,240 --> 00:19:20,320
and the internet is clearly quite apart

529
00:19:20,320 --> 00:19:21,280
from the pandemic

530
00:19:21,280 --> 00:19:23,280
entering a new phase and not all of that

531
00:19:23,280 --> 00:19:26,320
is bad but where adversarial actors have

532
00:19:26,320 --> 00:19:28,880
far greater expertise than in earlier

533
00:19:28,880 --> 00:19:29,840
phases

534
00:19:29,840 --> 00:19:31,760
and simultaneously in the last 15 months

535
00:19:31,760 --> 00:19:34,000
covet has had extraordinary impact on us

536
00:19:34,000 --> 00:19:34,720
all

537
00:19:34,720 --> 00:19:36,960
as humans workers citizens and family

538
00:19:36,960 --> 00:19:38,240
members

539
00:19:38,240 --> 00:19:40,320
so on on a personal level i and my

540
00:19:40,320 --> 00:19:42,559
colleagues actively experiencing the

541
00:19:42,559 --> 00:19:44,240
narrowing of civil space

542
00:19:44,240 --> 00:19:46,240
daily as do billions of users around the

543
00:19:46,240 --> 00:19:48,160
world and one of the most important

544
00:19:48,160 --> 00:19:50,000
things we can do is obviously to keep

545
00:19:50,000 --> 00:19:52,080
services running to keep the

546
00:19:52,080 --> 00:19:54,000
infrastructure functioning

547
00:19:54,000 --> 00:19:57,440
um to to to cope with this huge

548
00:19:57,440 --> 00:20:00,559
wave of increased usage that you know

549
00:20:00,559 --> 00:20:02,640
it's it's not a given that everyone can

550
00:20:02,640 --> 00:20:03,840
cope with

551
00:20:03,840 --> 00:20:06,080
and although our human rights policy

552
00:20:06,080 --> 00:20:08,159
that we put out in march is new

553
00:20:08,159 --> 00:20:09,840
i want to say in the last 15 months i

554
00:20:09,840 --> 00:20:11,440
think we and others who are members of

555
00:20:11,440 --> 00:20:13,120
the global network initiative

556
00:20:13,120 --> 00:20:15,840
have really been leveraging the

557
00:20:15,840 --> 00:20:17,840
fundamental protections

558
00:20:17,840 --> 00:20:19,679
and fundamental commitments that we've

559
00:20:19,679 --> 00:20:21,679
made to protect global freedom of

560
00:20:21,679 --> 00:20:23,120
expression

561
00:20:23,120 --> 00:20:26,480
and um and the right to privacy as

562
00:20:26,480 --> 00:20:27,919
defined by icc par

563
00:20:27,919 --> 00:20:29,840
isis as the international covenant on

564
00:20:29,840 --> 00:20:31,360
civil and political rights

565
00:20:31,360 --> 00:20:32,720
particularly against arbitrary

566
00:20:32,720 --> 00:20:34,559
government requests for data and content

567
00:20:34,559 --> 00:20:35,600
removals

568
00:20:35,600 --> 00:20:38,240
because those as ever are coming in

569
00:20:38,240 --> 00:20:39,360
thick and fast

570
00:20:39,360 --> 00:20:42,159
and in many ways as civic space narrows

571
00:20:42,159 --> 00:20:43,200
we see

572
00:20:43,200 --> 00:20:45,039
attempts to gain data or to suppress

573
00:20:45,039 --> 00:20:46,640
speech to increase and that's reflected

574
00:20:46,640 --> 00:20:48,320
in all indicators

575
00:20:48,320 --> 00:20:51,039
we've also worked very hard to combat

576
00:20:51,039 --> 00:20:52,960
covert related misinformation and

577
00:20:52,960 --> 00:20:54,000
support

578
00:20:54,000 --> 00:20:56,640
the the distribution of accurate health

579
00:20:56,640 --> 00:20:57,760
information

580
00:20:57,760 --> 00:20:59,760
and i do think there is some very

581
00:20:59,760 --> 00:21:02,320
interesting precedent there that helps

582
00:21:02,320 --> 00:21:02,640
us

583
00:21:02,640 --> 00:21:04,880
think about encouraging uh work for the

584
00:21:04,880 --> 00:21:06,240
future

585
00:21:06,240 --> 00:21:09,919
in our human rights policy we explicitly

586
00:21:09,919 --> 00:21:11,919
recognize the risks faced by human

587
00:21:11,919 --> 00:21:13,440
rights defenders

588
00:21:13,440 --> 00:21:16,720
and we explicitly seek to support them

589
00:21:16,720 --> 00:21:18,400
so we've long been doing work in this

590
00:21:18,400 --> 00:21:20,320
space but i guess i'd say that we are

591
00:21:20,320 --> 00:21:21,919
codifying it

592
00:21:21,919 --> 00:21:24,400
by supporting escalations from human

593
00:21:24,400 --> 00:21:25,919
rights defenders through our trusted

594
00:21:25,919 --> 00:21:27,600
partner program

595
00:21:27,600 --> 00:21:29,600
combating malicious actors including

596
00:21:29,600 --> 00:21:32,000
spate state-sponsored actors

597
00:21:32,000 --> 00:21:34,000
and i want to note a very recent

598
00:21:34,000 --> 00:21:36,640
overview report we put out i think about

599
00:21:36,640 --> 00:21:39,520
two weeks ago that has an overview of

600
00:21:39,520 --> 00:21:40,880
three years of work

601
00:21:40,880 --> 00:21:43,280
and i agree with joan this is a field

602
00:21:43,280 --> 00:21:45,679
ripe for further work

603
00:21:45,679 --> 00:21:47,360
we seek to protect activists and

604
00:21:47,360 --> 00:21:48,880
defenders from incorrect content

605
00:21:48,880 --> 00:21:50,480
moderation decisions

606
00:21:50,480 --> 00:21:53,360
as well as expanded access to remedy

607
00:21:53,360 --> 00:21:54,880
through the oversight board

608
00:21:54,880 --> 00:21:57,200
and we are offering advanced security

609
00:21:57,200 --> 00:21:58,240
options

610
00:21:58,240 --> 00:22:00,159
built with nation-state adversaries in

611
00:22:00,159 --> 00:22:01,360
mind

612
00:22:01,360 --> 00:22:03,679
so we're also creating a new fund to

613
00:22:03,679 --> 00:22:05,280
assist human rights defenders in

614
00:22:05,280 --> 00:22:06,799
practical terms that we'll be releasing

615
00:22:06,799 --> 00:22:08,640
in asia pacific

616
00:22:08,640 --> 00:22:10,000
and i can give you a moment of a

617
00:22:10,000 --> 00:22:11,760
snapshot in time but what i want to say

618
00:22:11,760 --> 00:22:12,799
is i think

619
00:22:12,799 --> 00:22:14,799
there's everything we have to learn and

620
00:22:14,799 --> 00:22:16,320
everything we need to do

621
00:22:16,320 --> 00:22:18,640
but actionable practical and principled

622
00:22:18,640 --> 00:22:19,440
steps

623
00:22:19,440 --> 00:22:22,799
can absolutely be taken thank you so

624
00:22:22,799 --> 00:22:23,679
much miranda

625
00:22:23,679 --> 00:22:26,240
and i hope we can dwelve a little bit

626
00:22:26,240 --> 00:22:27,039
more later on

627
00:22:27,039 --> 00:22:28,960
discussion into some of the concrete

628
00:22:28,960 --> 00:22:30,240
initiatives that's been taken by

629
00:22:30,240 --> 00:22:31,679
facebook and and hear the rest of the

630
00:22:31,679 --> 00:22:32,480
panel

631
00:22:32,480 --> 00:22:34,799
um but brad i want to move to you you've

632
00:22:34,799 --> 00:22:35,600
really been

633
00:22:35,600 --> 00:22:38,720
heavily involved in years uh in fighting

634
00:22:38,720 --> 00:22:39,600
for

635
00:22:39,600 --> 00:22:41,280
you know fighting for defending

636
00:22:41,280 --> 00:22:43,440
extending the digital rights of users

637
00:22:43,440 --> 00:22:46,159
at risk around the world and while tech

638
00:22:46,159 --> 00:22:47,840
companies hold a lot of responsibility

639
00:22:47,840 --> 00:22:49,360
and some of it we just heard from

640
00:22:49,360 --> 00:22:52,080
from miranda it said that democracies

641
00:22:52,080 --> 00:22:54,080
haven't figured out

642
00:22:54,080 --> 00:22:56,000
how to adhere to democratic values and

643
00:22:56,000 --> 00:22:57,520
you know international human rights

644
00:22:57,520 --> 00:22:58,720
framework on their own

645
00:22:58,720 --> 00:23:00,880
and use the regulation of tax what is

646
00:23:00,880 --> 00:23:02,080
you know i want to dwelve a little bit

647
00:23:02,080 --> 00:23:02,480
into

648
00:23:02,480 --> 00:23:05,520
what is the role of governments um

649
00:23:05,520 --> 00:23:07,600
particularly also in mature democracies

650
00:23:07,600 --> 00:23:09,200
that are really helping set the frame

651
00:23:09,200 --> 00:23:09,840
for this

652
00:23:09,840 --> 00:23:11,440
you know what is a realistic and

653
00:23:11,440 --> 00:23:13,679
effective approach that you believe

654
00:23:13,679 --> 00:23:14,400
governments

655
00:23:14,400 --> 00:23:17,360
can and should take around harnessing

656
00:23:17,360 --> 00:23:19,360
digital technologies and these platforms

657
00:23:19,360 --> 00:23:20,799
for the purpose of strengthening

658
00:23:20,799 --> 00:23:21,679
promoting

659
00:23:21,679 --> 00:23:25,600
democracy and civic digital space

660
00:23:26,080 --> 00:23:28,960
i have 15 answers to that question and

661
00:23:28,960 --> 00:23:29,679
i'm going to try

662
00:23:29,679 --> 00:23:30,880
to get through them in two minutes

663
00:23:30,880 --> 00:23:32,960
because i think that as you said for us

664
00:23:32,960 --> 00:23:34,720
it's a task

665
00:23:34,720 --> 00:23:36,400
you know it's absolutely essential as

666
00:23:36,400 --> 00:23:37,919
you say that governments whether they be

667
00:23:37,919 --> 00:23:39,760
democracies or or not

668
00:23:39,760 --> 00:23:42,559
that they adhere to and that they um

669
00:23:42,559 --> 00:23:43,919
have in place a range of

670
00:23:43,919 --> 00:23:45,440
not just technologies but actually tech

671
00:23:45,440 --> 00:23:47,520
policy and i want to focus on that

672
00:23:47,520 --> 00:23:50,320
so here's the list number one get the

673
00:23:50,320 --> 00:23:52,159
whole population online

674
00:23:52,159 --> 00:23:53,919
especially the most marginalised like

675
00:23:53,919 --> 00:23:55,360
you can't have a functioning democracy

676
00:23:55,360 --> 00:23:58,400
with half the population or more offline

677
00:23:58,400 --> 00:24:00,320
protect encryption rather than undermine

678
00:24:00,320 --> 00:24:03,360
it legislate enforceable and robust data

679
00:24:03,360 --> 00:24:04,000
protection

680
00:24:04,000 --> 00:24:07,360
laws make multi-stakeholderism real

681
00:24:07,360 --> 00:24:10,240
by consulting with digital civil society

682
00:24:10,240 --> 00:24:12,640
join the freedom online coalition

683
00:24:12,640 --> 00:24:14,640
be consistent with your digital policy

684
00:24:14,640 --> 00:24:16,960
at home and abroad

685
00:24:16,960 --> 00:24:18,960
banned facial recognition in public

686
00:24:18,960 --> 00:24:21,840
publicly accessible spaces

687
00:24:21,840 --> 00:24:22,960
i'm halfway through the list and i've

688
00:24:22,960 --> 00:24:25,520
got a minute to go ensure content

689
00:24:25,520 --> 00:24:27,360
moderation by companies

690
00:24:27,360 --> 00:24:28,559
in their jurisdiction is right

691
00:24:28,559 --> 00:24:30,480
respecting don't

692
00:24:30,480 --> 00:24:33,679
spy on your citizens not apply nor

693
00:24:33,679 --> 00:24:34,240
deploy

694
00:24:34,240 --> 00:24:37,360
surveillance infrastructure against

695
00:24:37,360 --> 00:24:39,760
marginalized populations

696
00:24:39,760 --> 00:24:41,919
resist moves towards um so-called

697
00:24:41,919 --> 00:24:43,679
digital sovereignty

698
00:24:43,679 --> 00:24:46,000
stop unlawfully requesting user data

699
00:24:46,000 --> 00:24:48,159
from tech companies

700
00:24:48,159 --> 00:24:51,039
protect the right to freedom of assembly

701
00:24:51,039 --> 00:24:52,320
and peaceful protest

702
00:24:52,320 --> 00:24:55,520
online and ensure that the kobe tracing

703
00:24:55,520 --> 00:24:57,120
apps the vaccine passports and other

704
00:24:57,120 --> 00:24:58,799
pandemic responses

705
00:24:58,799 --> 00:25:00,960
don't harm privacy and freedom of

706
00:25:00,960 --> 00:25:03,200
movement in the meantime

707
00:25:03,200 --> 00:25:06,159
train your judges your policy makers and

708
00:25:06,159 --> 00:25:06,640
your

709
00:25:06,640 --> 00:25:09,679
legislators in digital rights

710
00:25:09,679 --> 00:25:11,919
and finally keep it on so there's a

711
00:25:11,919 --> 00:25:13,520
15-point agenda for your meeting in

712
00:25:13,520 --> 00:25:14,960
november

713
00:25:14,960 --> 00:25:16,320
these are the things that i think are

714
00:25:16,320 --> 00:25:18,159
absolutely essential for governments to

715
00:25:18,159 --> 00:25:18,559
put

716
00:25:18,559 --> 00:25:21,200
in place if they are to ensure that

717
00:25:21,200 --> 00:25:23,440
technology and technology policy

718
00:25:23,440 --> 00:25:26,080
supports and enables democracy rather

719
00:25:26,080 --> 00:25:27,360
than undermines it

720
00:25:27,360 --> 00:25:29,120
and i just want to just before i hand

721
00:25:29,120 --> 00:25:31,679
over um

722
00:25:31,679 --> 00:25:33,279
i just want to address what miranda said

723
00:25:33,279 --> 00:25:34,960
as well because

724
00:25:34,960 --> 00:25:36,880
i think following on from jones point

725
00:25:36,880 --> 00:25:38,720
around you know civic space and the

726
00:25:38,720 --> 00:25:40,480
protection of civic space that it's not

727
00:25:40,480 --> 00:25:41,919
just about governments obviously it's

728
00:25:41,919 --> 00:25:43,360
about the fact that

729
00:25:43,360 --> 00:25:46,799
much of this space is privatized

730
00:25:46,799 --> 00:25:50,080
and you know it's essentially

731
00:25:50,080 --> 00:25:52,240
the big platforms like facebook and

732
00:25:52,240 --> 00:25:54,400
twitter and others

733
00:25:54,400 --> 00:25:56,000
and we've seen the consequences of just

734
00:25:56,000 --> 00:25:57,679
this global outage that just happened

735
00:25:57,679 --> 00:25:59,200
you know a few hours ago like what

736
00:25:59,200 --> 00:26:01,039
happens when private actors

737
00:26:01,039 --> 00:26:03,039
um what are the consequences of private

738
00:26:03,039 --> 00:26:05,200
actors behaviors

739
00:26:05,200 --> 00:26:09,440
and so the best policies in the world

740
00:26:09,440 --> 00:26:10,960
are different to the implementation of

741
00:26:10,960 --> 00:26:12,799
those policies and when we see

742
00:26:12,799 --> 00:26:15,200
facebook's human rights policy that got

743
00:26:15,200 --> 00:26:16,159
put out

744
00:26:16,159 --> 00:26:18,799
earlier this year which is great it's

745
00:26:18,799 --> 00:26:20,240
about how that policy is actually

746
00:26:20,240 --> 00:26:21,679
implemented in the real world and what

747
00:26:21,679 --> 00:26:23,440
does it look like in palestine

748
00:26:23,440 --> 00:26:24,559
you know what does it look like in

749
00:26:24,559 --> 00:26:26,799
colombia and how does that interface

750
00:26:26,799 --> 00:26:28,559
with the governments that they work with

751
00:26:28,559 --> 00:26:30,480
whether they be those democracies or not

752
00:26:30,480 --> 00:26:32,080
so

753
00:26:32,080 --> 00:26:34,720
thanks excellent brad i want to in the

754
00:26:34,720 --> 00:26:36,559
panel later we'll go back to

755
00:26:36,559 --> 00:26:39,679
policies versus implementation and i

756
00:26:39,679 --> 00:26:41,120
want to also can you just quickly

757
00:26:41,120 --> 00:26:44,320
tell me super quickly on those 15 points

758
00:26:44,320 --> 00:26:46,640
say we had this debate three years ago

759
00:26:46,640 --> 00:26:48,080
and now we're having it again today are

760
00:26:48,080 --> 00:26:49,520
we in a better place today

761
00:26:49,520 --> 00:26:52,559
on you know making those 15

762
00:26:52,559 --> 00:26:56,080
points achievable are we worse

763
00:26:56,320 --> 00:26:58,000
you know it's difficult to say because

764
00:26:58,000 --> 00:26:59,520
there's you know there's sort of 15

765
00:26:59,520 --> 00:27:01,520
gradients that are happening or 15

766
00:27:01,520 --> 00:27:04,000
you know uh line items there and some of

767
00:27:04,000 --> 00:27:05,440
them are going forwards and backwards i

768
00:27:05,440 --> 00:27:07,279
think one thing to say is that

769
00:27:07,279 --> 00:27:10,480
um you know you win up you win once but

770
00:27:10,480 --> 00:27:12,400
you don't necessarily maintain the win

771
00:27:12,400 --> 00:27:14,080
so we've seen like you know victories in

772
00:27:14,080 --> 00:27:15,440
in india for instance that are being

773
00:27:15,440 --> 00:27:17,440
whittled back as we speak on

774
00:27:17,440 --> 00:27:21,440
on um on on content and on censorship

775
00:27:21,440 --> 00:27:23,440
similarly you know the the the crypto

776
00:27:23,440 --> 00:27:25,200
wars we've been sitting there for you

777
00:27:25,200 --> 00:27:26,880
know 20 years now and sometimes we win

778
00:27:26,880 --> 00:27:28,320
and lose on them so

779
00:27:28,320 --> 00:27:30,000
it's difficult to say in a sort of

780
00:27:30,000 --> 00:27:32,240
across the board but i

781
00:27:32,240 --> 00:27:36,159
i i do feel as though um

782
00:27:36,399 --> 00:27:40,000
you know the sort of the conversation

783
00:27:40,000 --> 00:27:41,760
that we're having right now is not

784
00:27:41,760 --> 00:27:43,440
necessarily hasn't necessarily

785
00:27:43,440 --> 00:27:44,799
progressed in the direction that it

786
00:27:44,799 --> 00:27:46,640
needs to and i say that as the convener

787
00:27:46,640 --> 00:27:47,600
of rightscon

788
00:27:47,600 --> 00:27:49,760
i mean there's so much discussion and so

789
00:27:49,760 --> 00:27:51,600
much debate that is happening

790
00:27:51,600 --> 00:27:54,159
but ultimately what does it mean for a

791
00:27:54,159 --> 00:27:54,799
person who's

792
00:27:54,799 --> 00:27:56,799
experiencing a shutdown you know 55

793
00:27:56,799 --> 00:27:59,279
internet shutdowns happened last year

794
00:27:59,279 --> 00:28:01,679
there's already been 55 53 internet

795
00:28:01,679 --> 00:28:02,880
shutdowns this year

796
00:28:02,880 --> 00:28:04,240
so like for the person who's

797
00:28:04,240 --> 00:28:06,320
experiencing a shutdown you know

798
00:28:06,320 --> 00:28:08,240
the conversation hasn't actually evolved

799
00:28:08,240 --> 00:28:10,000
to implementation to stop internet

800
00:28:10,000 --> 00:28:11,440
shutdowns even though we've got the best

801
00:28:11,440 --> 00:28:13,279
resolutions at the un

802
00:28:13,279 --> 00:28:16,559
um so um you know i can't give you

803
00:28:16,559 --> 00:28:18,159
a definitive answer because it is so

804
00:28:18,159 --> 00:28:19,600
nuanced but

805
00:28:19,600 --> 00:28:22,559
i think that there is a maturation of

806
00:28:22,559 --> 00:28:23,279
the space

807
00:28:23,279 --> 00:28:24,720
you know having 500 companies at

808
00:28:24,720 --> 00:28:25,919
wright's economy is a really good

809
00:28:25,919 --> 00:28:27,440
indication that there is

810
00:28:27,440 --> 00:28:29,760
and 55 governments is a sense that we're

811
00:28:29,760 --> 00:28:30,559
actually

812
00:28:30,559 --> 00:28:33,120
progressing things but i want to make

813
00:28:33,120 --> 00:28:34,960
sure that you know the litmus test in a

814
00:28:34,960 --> 00:28:35,520
way

815
00:28:35,520 --> 00:28:37,760
is the marginalized user and what is

816
00:28:37,760 --> 00:28:39,679
their experience of being online

817
00:28:39,679 --> 00:28:41,279
and i don't necessarily think it's

818
00:28:41,279 --> 00:28:43,600
getting better for them

819
00:28:43,600 --> 00:28:46,320
so i hear a little bit of optimism but a

820
00:28:46,320 --> 00:28:48,320
very very cautious one

821
00:28:48,320 --> 00:28:51,279
um jessica i want to move over to you um

822
00:28:51,279 --> 00:28:53,039
there's a lot of concern about social

823
00:28:53,039 --> 00:28:55,120
media platforms being you know potential

824
00:28:55,120 --> 00:28:56,240
bastions of you know

825
00:28:56,240 --> 00:28:59,520
dark anti-democratic conversations hate

826
00:28:59,520 --> 00:29:01,600
speech whatever you want to call it

827
00:29:01,600 --> 00:29:04,240
um and where communities whose purpose

828
00:29:04,240 --> 00:29:05,760
is you know reprehensible

829
00:29:05,760 --> 00:29:07,440
you know threatening the digital civic

830
00:29:07,440 --> 00:29:09,679
space and where they thrive

831
00:29:09,679 --> 00:29:11,840
how have you have read it you know been

832
00:29:11,840 --> 00:29:13,840
supporting digital civic space

833
00:29:13,840 --> 00:29:16,720
and how are you creating an environment

834
00:29:16,720 --> 00:29:18,159
that is enabling democratic

835
00:29:18,159 --> 00:29:20,480
participation

836
00:29:20,480 --> 00:29:22,720
yeah thanks for the question um our

837
00:29:22,720 --> 00:29:24,399
approach to this at reddit

838
00:29:24,399 --> 00:29:26,399
looks a little bit different because

839
00:29:26,399 --> 00:29:28,000
we're a smaller company we're a

840
00:29:28,000 --> 00:29:29,760
differently structured company in terms

841
00:29:29,760 --> 00:29:31,279
of our content moderation

842
00:29:31,279 --> 00:29:33,039
and we're really only just starting to

843
00:29:33,039 --> 00:29:35,360
develop a global footprint

844
00:29:35,360 --> 00:29:38,720
but that said reddit really lends itself

845
00:29:38,720 --> 00:29:40,320
to the organization of civic

846
00:29:40,320 --> 00:29:41,919
participation

847
00:29:41,919 --> 00:29:44,320
no one in the u.s especially in the

848
00:29:44,320 --> 00:29:46,159
congress will ever forget the way that

849
00:29:46,159 --> 00:29:47,919
the reddit community organized a few

850
00:29:47,919 --> 00:29:50,159
years ago against the threat of sopa

851
00:29:50,159 --> 00:29:52,159
pippa for example the historically

852
00:29:52,159 --> 00:29:55,120
bad copyright legislation where reddit

853
00:29:55,120 --> 00:29:56,000
largely

854
00:29:56,000 --> 00:29:58,720
reddit users largely organized a phone

855
00:29:58,720 --> 00:29:59,679
call campaign

856
00:29:59,679 --> 00:30:02,640
to express their displeasure with the

857
00:30:02,640 --> 00:30:04,640
impact that such overbroad legislation

858
00:30:04,640 --> 00:30:06,320
would have on their ability to

859
00:30:06,320 --> 00:30:09,120
speak out and express themselves and

860
00:30:09,120 --> 00:30:10,320
much of the reason

861
00:30:10,320 --> 00:30:12,480
why reddit lends itself to this type of

862
00:30:12,480 --> 00:30:14,159
organization is because

863
00:30:14,159 --> 00:30:17,120
the structure of our platform is itself

864
00:30:17,120 --> 00:30:18,399
democratic

865
00:30:18,399 --> 00:30:21,679
so the unit of engagement on reddit is

866
00:30:21,679 --> 00:30:23,440
fundamentally the community

867
00:30:23,440 --> 00:30:26,720
rather than the individual user and we

868
00:30:26,720 --> 00:30:28,640
actually sort content on reddit

869
00:30:28,640 --> 00:30:29,919
primarily by

870
00:30:29,919 --> 00:30:33,360
the votes of our users and we also put

871
00:30:33,360 --> 00:30:34,960
users at the center of our content

872
00:30:34,960 --> 00:30:37,200
moderation efforts and in fact more than

873
00:30:37,200 --> 00:30:39,840
99 of all content moderation decisions

874
00:30:39,840 --> 00:30:40,720
on reddit

875
00:30:40,720 --> 00:30:42,960
are carried out by the users themselves

876
00:30:42,960 --> 00:30:45,440
rather than our centralized corporate

877
00:30:45,440 --> 00:30:48,399
entity and so this participatory nature

878
00:30:48,399 --> 00:30:49,279
of reddit

879
00:30:49,279 --> 00:30:51,679
helps build a culture of engagement that

880
00:30:51,679 --> 00:30:53,679
carries offline as well

881
00:30:53,679 --> 00:30:55,520
and we've really leaned into that by

882
00:30:55,520 --> 00:30:57,600
running civic engagement campaigns that

883
00:30:57,600 --> 00:30:58,480
connect

884
00:30:58,480 --> 00:31:01,200
voting on reddit to voting in real life

885
00:31:01,200 --> 00:31:02,799
so for example during the u.s

886
00:31:02,799 --> 00:31:04,960
presidential elections last year

887
00:31:04,960 --> 00:31:06,720
we put billboards up around the country

888
00:31:06,720 --> 00:31:08,240
showing reddit posts

889
00:31:08,240 --> 00:31:10,240
that actually got more votes than

890
00:31:10,240 --> 00:31:12,240
political candidates to demonstrate the

891
00:31:12,240 --> 00:31:14,880
power of collective community voices

892
00:31:14,880 --> 00:31:18,080
if they organize but of course as you

893
00:31:18,080 --> 00:31:19,600
mentioned civic participation

894
00:31:19,600 --> 00:31:21,279
certainly goes beyond voting and in

895
00:31:21,279 --> 00:31:23,200
particular when we talk about

896
00:31:23,200 --> 00:31:25,600
the digital civic space preserving

897
00:31:25,600 --> 00:31:26,960
reddit as a place for

898
00:31:26,960 --> 00:31:30,240
safe authentic community-centered

899
00:31:30,240 --> 00:31:31,200
conversation

900
00:31:31,200 --> 00:31:34,399
is what we focus on and so in practice

901
00:31:34,399 --> 00:31:36,640
this often means as was mentioned

902
00:31:36,640 --> 00:31:38,399
earlier defending our communities

903
00:31:38,399 --> 00:31:40,640
against state forces in particular that

904
00:31:40,640 --> 00:31:42,159
seek to constrict them

905
00:31:42,159 --> 00:31:44,480
and this is especially the case

906
00:31:44,480 --> 00:31:46,000
unfortunately in countries around the

907
00:31:46,000 --> 00:31:46,480
world

908
00:31:46,480 --> 00:31:48,480
that we're seeing trend more autocratic

909
00:31:48,480 --> 00:31:50,080
in terms of how they seek to police

910
00:31:50,080 --> 00:31:51,440
dissent on the web

911
00:31:51,440 --> 00:31:53,360
and because of this we've made it a

912
00:31:53,360 --> 00:31:55,279
point to scrutinize every government

913
00:31:55,279 --> 00:31:56,880
takedown request that we get

914
00:31:56,880 --> 00:31:58,640
and in this scrutiny we consider

915
00:31:58,640 --> 00:32:00,399
international human rights principles

916
00:32:00,399 --> 00:32:01,679
and norms

917
00:32:01,679 --> 00:32:03,679
but secondly it's really important that

918
00:32:03,679 --> 00:32:05,600
we're also transparent about doing this

919
00:32:05,600 --> 00:32:07,679
and transparent about sharing our data

920
00:32:07,679 --> 00:32:10,480
so reddit's api is open to researchers

921
00:32:10,480 --> 00:32:10,880
and

922
00:32:10,880 --> 00:32:13,279
in our annual transparency report we

923
00:32:13,279 --> 00:32:15,519
denote for example the number and types

924
00:32:15,519 --> 00:32:16,320
of requests

925
00:32:16,320 --> 00:32:18,720
that we have gotten from every country

926
00:32:18,720 --> 00:32:20,399
and we also know whether we complied or

927
00:32:20,399 --> 00:32:20,799
not

928
00:32:20,799 --> 00:32:23,039
so not only is it important for us to

929
00:32:23,039 --> 00:32:24,960
defend our communities legitimate rights

930
00:32:24,960 --> 00:32:27,120
to digital civic participation

931
00:32:27,120 --> 00:32:29,279
but it's also really important for us to

932
00:32:29,279 --> 00:32:30,720
let them know

933
00:32:30,720 --> 00:32:32,960
who's being the most active in seeking

934
00:32:32,960 --> 00:32:33,919
to control

935
00:32:33,919 --> 00:32:37,440
those spaces their spaces um

936
00:32:37,440 --> 00:32:40,080
and so when we talk about other threats

937
00:32:40,080 --> 00:32:40,559
you know

938
00:32:40,559 --> 00:32:44,960
to um uh online digital civic spaces

939
00:32:44,960 --> 00:32:46,480
there's the there's of course the

940
00:32:46,480 --> 00:32:48,159
obvious threat that you alluded to

941
00:32:48,159 --> 00:32:51,679
um ambassador which is malicious actors

942
00:32:51,679 --> 00:32:53,360
whether they be nefarious government

943
00:32:53,360 --> 00:32:55,840
actors seeking to manipulate or mislead

944
00:32:55,840 --> 00:32:56,960
online dialogue

945
00:32:56,960 --> 00:32:59,519
or you know everyday trolls who might

946
00:32:59,519 --> 00:33:01,600
have a malicious or even a violent

947
00:33:01,600 --> 00:33:03,679
agenda and are seeking to use our tools

948
00:33:03,679 --> 00:33:05,120
to implement that

949
00:33:05,120 --> 00:33:08,399
um so on this you know

950
00:33:08,399 --> 00:33:10,399
the system of self-governance that we've

951
00:33:10,399 --> 00:33:12,000
actually set up has

952
00:33:12,000 --> 00:33:15,440
been highly effective in addressing um

953
00:33:15,440 --> 00:33:17,679
a lot of those concerns with some kind

954
00:33:17,679 --> 00:33:19,679
of guidance and safety guard rails put

955
00:33:19,679 --> 00:33:20,000
on

956
00:33:20,000 --> 00:33:22,799
by our teams that i'll talk about um a

957
00:33:22,799 --> 00:33:24,000
little bit later

958
00:33:24,000 --> 00:33:26,080
but essentially what we try to do on

959
00:33:26,080 --> 00:33:27,039
reddit to

960
00:33:27,039 --> 00:33:30,480
marginalize violent or bad voices is

961
00:33:30,480 --> 00:33:33,360
to essentially try to ensure that the

962
00:33:33,360 --> 00:33:34,320
volume

963
00:33:34,320 --> 00:33:36,000
you know the volume of certain views on

964
00:33:36,000 --> 00:33:38,000
reddit is proportionate to the number

965
00:33:38,000 --> 00:33:40,159
of people who actually hold those views

966
00:33:40,159 --> 00:33:41,919
so loud trolls

967
00:33:41,919 --> 00:33:43,600
or people with an agenda that they're

968
00:33:43,600 --> 00:33:46,320
trying to push should not be able to

969
00:33:46,320 --> 00:33:49,039
hijack an entire community conversation

970
00:33:49,039 --> 00:33:50,799
so we pay a lot of attention

971
00:33:50,799 --> 00:33:52,480
to the fundamental health of the

972
00:33:52,480 --> 00:33:54,720
community conversation

973
00:33:54,720 --> 00:33:56,640
but to ensure this while at the same

974
00:33:56,640 --> 00:33:58,320
time respecting our users rights to

975
00:33:58,320 --> 00:34:00,080
protecting their privacy

976
00:34:00,080 --> 00:34:02,720
protecting their identity we focus on

977
00:34:02,720 --> 00:34:04,000
identifying suspicious

978
00:34:04,000 --> 00:34:06,559
behavioral signals rather than seeking

979
00:34:06,559 --> 00:34:08,000
to collect and verify

980
00:34:08,000 --> 00:34:10,960
individual users personal data which can

981
00:34:10,960 --> 00:34:11,760
be

982
00:34:11,760 --> 00:34:13,440
really dangerous when you're talking

983
00:34:13,440 --> 00:34:15,280
about civic participants especially in

984
00:34:15,280 --> 00:34:15,599
more

985
00:34:15,599 --> 00:34:18,079
autocratic states where if we have the

986
00:34:18,079 --> 00:34:20,239
data we can be compelled to

987
00:34:20,239 --> 00:34:21,520
hand it over and we don't want to do

988
00:34:21,520 --> 00:34:23,918
that now secondly

989
00:34:23,918 --> 00:34:25,679
i will note that there is of course the

990
00:34:25,679 --> 00:34:27,520
less obvious threats

991
00:34:27,520 --> 00:34:30,159
to digital civic space which is what i

992
00:34:30,159 --> 00:34:31,800
will call

993
00:34:31,800 --> 00:34:34,159
well-intentioned but unsophisticated

994
00:34:34,159 --> 00:34:35,440
legislation from

995
00:34:35,440 --> 00:34:37,918
generally liberal rights respecting

996
00:34:37,918 --> 00:34:38,879
countries

997
00:34:38,879 --> 00:34:41,119
and in this i really want to associate

998
00:34:41,119 --> 00:34:43,359
myself with everything that brett just

999
00:34:43,359 --> 00:34:44,560
said

1000
00:34:44,560 --> 00:34:46,719
there are a lot of laws both draft and

1001
00:34:46,719 --> 00:34:48,639
enforce out there right now that

1002
00:34:48,639 --> 00:34:50,719
unintentionally constrain the civic

1003
00:34:50,719 --> 00:34:51,520
space

1004
00:34:51,520 --> 00:34:53,599
in overbroad efforts to address you know

1005
00:34:53,599 --> 00:34:54,879
what are real

1006
00:34:54,879 --> 00:34:56,560
legitimate harms that need to be

1007
00:34:56,560 --> 00:34:57,920
addressed um

1008
00:34:57,920 --> 00:35:00,800
attacks on encryption rigid 24-hour

1009
00:35:00,800 --> 00:35:03,200
takedown laws overbroad copyright

1010
00:35:03,200 --> 00:35:04,640
regulations

1011
00:35:04,640 --> 00:35:06,320
but the unintended consequences of these

1012
00:35:06,320 --> 00:35:07,920
can sometimes be dire

1013
00:35:07,920 --> 00:35:09,599
both within the jurisdic the

1014
00:35:09,599 --> 00:35:11,359
jurisdiction itself and

1015
00:35:11,359 --> 00:35:13,599
through the power of example and by

1016
00:35:13,599 --> 00:35:14,720
power of example

1017
00:35:14,720 --> 00:35:17,280
i mean authoritarian countries are

1018
00:35:17,280 --> 00:35:19,599
modeling their internet restrictions

1019
00:35:19,599 --> 00:35:22,480
on those of liberal states in this sort

1020
00:35:22,480 --> 00:35:23,359
of kind of fun

1021
00:35:23,359 --> 00:35:25,920
house mirror policy jiu jitsu that's

1022
00:35:25,920 --> 00:35:26,560
frankly

1023
00:35:26,560 --> 00:35:29,119
very hard for companies especially

1024
00:35:29,119 --> 00:35:30,079
smaller companies

1025
00:35:30,079 --> 00:35:32,720
to push back against it's hard for us to

1026
00:35:32,720 --> 00:35:34,800
go up against the power of a state

1027
00:35:34,800 --> 00:35:38,000
um so to mitigate this we really need to

1028
00:35:38,000 --> 00:35:40,160
focus on educating lawmakers about the

1029
00:35:40,160 --> 00:35:42,240
nuances of how platform governance

1030
00:35:42,240 --> 00:35:44,400
actually works because it's usually more

1031
00:35:44,400 --> 00:35:46,079
complex and diverse in terms of

1032
00:35:46,079 --> 00:35:47,599
approaches out there in the marketplace

1033
00:35:47,599 --> 00:35:49,040
than it's realized

1034
00:35:49,040 --> 00:35:51,119
and then of course there's you know the

1035
00:35:51,119 --> 00:35:52,880
request scrutinization that i mentioned

1036
00:35:52,880 --> 00:35:54,400
earlier that takes place

1037
00:35:54,400 --> 00:35:57,040
but to wrap up and to be honest there's

1038
00:35:57,040 --> 00:35:59,040
only so much that companies and you know

1039
00:35:59,040 --> 00:36:00,640
particularly smaller ones like reddit

1040
00:36:00,640 --> 00:36:02,320
can do when we're up against the state

1041
00:36:02,320 --> 00:36:03,520
as i mentioned

1042
00:36:03,520 --> 00:36:06,640
so what would be really helpful is to

1043
00:36:06,640 --> 00:36:09,760
have a coalition of democratic countries

1044
00:36:09,760 --> 00:36:12,240
setting and following norms about human

1045
00:36:12,240 --> 00:36:14,000
rights and civic participation in the

1046
00:36:14,000 --> 00:36:15,200
digital space

1047
00:36:15,200 --> 00:36:17,680
in a way that sets an unequivocal

1048
00:36:17,680 --> 00:36:18,480
example

1049
00:36:18,480 --> 00:36:21,359
against authoritarianism thank you so

1050
00:36:21,359 --> 00:36:22,480
much jessica

1051
00:36:22,480 --> 00:36:24,160
lots of food for thought not least on

1052
00:36:24,160 --> 00:36:26,079
the role of various sides of the

1053
00:36:26,079 --> 00:36:27,599
platform i'm interested to hear how

1054
00:36:27,599 --> 00:36:28,480
reddit has been

1055
00:36:28,480 --> 00:36:31,119
been dealing with this um will you go to

1056
00:36:31,119 --> 00:36:32,800
nema now but i just want to advertise

1057
00:36:32,800 --> 00:36:34,560
please ask questions for the panel we'll

1058
00:36:34,560 --> 00:36:36,320
get to them after this round of

1059
00:36:36,320 --> 00:36:37,359
introductions

1060
00:36:37,359 --> 00:36:39,040
um so you can ask your questions and

1061
00:36:39,040 --> 00:36:40,480
we'll get it to the panel

1062
00:36:40,480 --> 00:36:43,440
nima um you're a founder of a civic

1063
00:36:43,440 --> 00:36:44,560
technology company

1064
00:36:44,560 --> 00:36:46,240
a very active figure in the debate on

1065
00:36:46,240 --> 00:36:47,920
the advancement and engagement of civil

1066
00:36:47,920 --> 00:36:48,960
society

1067
00:36:48,960 --> 00:36:50,720
could you give us your view on what is

1068
00:36:50,720 --> 00:36:52,480
the biggest issue neglected in the

1069
00:36:52,480 --> 00:36:54,000
debate on protecting digital

1070
00:36:54,000 --> 00:36:56,800
civic spaces yeah totally thanks so much

1071
00:36:56,800 --> 00:36:57,599
for having me

1072
00:36:57,599 --> 00:36:59,119
um i think that the one i'm going to

1073
00:36:59,119 --> 00:37:01,040
touch upon is one that brett already

1074
00:37:01,040 --> 00:37:03,040
discussed which is on

1075
00:37:03,040 --> 00:37:05,520
access and connectivity and there's

1076
00:37:05,520 --> 00:37:06,960
multiple facets to this

1077
00:37:06,960 --> 00:37:10,000
so when you know you're thinking about

1078
00:37:10,000 --> 00:37:12,400
so i'm coming from the perspective of um

1079
00:37:12,400 --> 00:37:14,160
running a company based in uganda and we

1080
00:37:14,160 --> 00:37:16,160
work across africa so the debate

1081
00:37:16,160 --> 00:37:18,240
that we have is very very different but

1082
00:37:18,240 --> 00:37:19,760
of course you know africa's population

1083
00:37:19,760 --> 00:37:21,280
is growing very quickly

1084
00:37:21,280 --> 00:37:22,800
and even though technology companies

1085
00:37:22,800 --> 00:37:24,960
have for a very long time ignored our

1086
00:37:24,960 --> 00:37:25,520
needs

1087
00:37:25,520 --> 00:37:28,079
um you know finally twitter's

1088
00:37:28,079 --> 00:37:30,000
considering opening an office in ghana

1089
00:37:30,000 --> 00:37:30,960
like very

1090
00:37:30,960 --> 00:37:32,880
you know slow movements are being made

1091
00:37:32,880 --> 00:37:34,240
and considering the needs of african

1092
00:37:34,240 --> 00:37:35,280
users

1093
00:37:35,280 --> 00:37:38,320
but when you think about it if a

1094
00:37:38,320 --> 00:37:40,320
majority of the people are still online

1095
00:37:40,320 --> 00:37:42,640
then basically the marginalized people

1096
00:37:42,640 --> 00:37:44,240
are left behind the privileged people

1097
00:37:44,240 --> 00:37:45,920
continue to have more power

1098
00:37:45,920 --> 00:37:47,920
and many of the harms that are evident

1099
00:37:47,920 --> 00:37:49,359
you know in our physical lives are

1100
00:37:49,359 --> 00:37:50,160
replicated

1101
00:37:50,160 --> 00:37:52,480
online so first of all a large

1102
00:37:52,480 --> 00:37:53,680
proportion of people

1103
00:37:53,680 --> 00:37:56,079
are offline and they don't have access

1104
00:37:56,079 --> 00:37:58,160
to the information and they are more

1105
00:37:58,160 --> 00:37:59,599
susceptible you know to some of this

1106
00:37:59,599 --> 00:38:01,119
misinformation and disinformation that

1107
00:38:01,119 --> 00:38:02,720
spreads because for example

1108
00:38:02,720 --> 00:38:04,480
fact checking is one of the main tools

1109
00:38:04,480 --> 00:38:05,760
and if you're not online you

1110
00:38:05,760 --> 00:38:07,520
don't even have access to fact checking

1111
00:38:07,520 --> 00:38:09,119
for example if that's one of the tools

1112
00:38:09,119 --> 00:38:10,079
you're using

1113
00:38:10,079 --> 00:38:12,400
another big issue is the gender digital

1114
00:38:12,400 --> 00:38:14,480
divide so women are less likely to be

1115
00:38:14,480 --> 00:38:15,520
online

1116
00:38:15,520 --> 00:38:18,240
and as we've seen many technologies new

1117
00:38:18,240 --> 00:38:19,839
technologies for example

1118
00:38:19,839 --> 00:38:21,440
tend to impact vulnerable groups like

1119
00:38:21,440 --> 00:38:24,320
women um disproportionately

1120
00:38:24,320 --> 00:38:26,079
and then you're thinking about other

1121
00:38:26,079 --> 00:38:27,599
issues such as you know the internet

1122
00:38:27,599 --> 00:38:29,440
cost is actually really high and with

1123
00:38:29,440 --> 00:38:31,040
the pandemic many people

1124
00:38:31,040 --> 00:38:32,640
have suffered losses to income so even

1125
00:38:32,640 --> 00:38:35,040
more people are falling offline

1126
00:38:35,040 --> 00:38:37,280
we have many repressive laws that keep

1127
00:38:37,280 --> 00:38:38,800
people offline like for example in

1128
00:38:38,800 --> 00:38:41,680
uganda we have the social media tax

1129
00:38:41,680 --> 00:38:44,400
which everyone has to pay a fee every

1130
00:38:44,400 --> 00:38:45,680
day to access certain

1131
00:38:45,680 --> 00:38:48,000
over-the-top platforms and many people

1132
00:38:48,000 --> 00:38:49,440
can't afford that and that has pushed

1133
00:38:49,440 --> 00:38:50,880
more people offline

1134
00:38:50,880 --> 00:38:52,079
and then the other things that we're

1135
00:38:52,079 --> 00:38:53,440
battling with in terms of access and

1136
00:38:53,440 --> 00:38:56,240
connectivity so earlier this year uganda

1137
00:38:56,240 --> 00:38:59,359
banned facebook last week headlines were

1138
00:38:59,359 --> 00:39:00,960
made when nigeria

1139
00:39:00,960 --> 00:39:03,119
banned twitter and is now going to

1140
00:39:03,119 --> 00:39:04,160
criminalize

1141
00:39:04,160 --> 00:39:07,200
the use of twitter we have many internet

1142
00:39:07,200 --> 00:39:08,160
shutdowns so just

1143
00:39:08,160 --> 00:39:10,560
basically the internet is that threat in

1144
00:39:10,560 --> 00:39:12,640
like how we can be online

1145
00:39:12,640 --> 00:39:14,320
and then the other two issues which are

1146
00:39:14,320 --> 00:39:16,800
related to this are digital literacy or

1147
00:39:16,800 --> 00:39:19,040
media literacy how you want to take it

1148
00:39:19,040 --> 00:39:20,880
and i always want to talk about this

1149
00:39:20,880 --> 00:39:22,079
topic of digital

1150
00:39:22,079 --> 00:39:24,800
empathy so in the african context many

1151
00:39:24,800 --> 00:39:26,800
people are coming online for the first

1152
00:39:26,800 --> 00:39:27,680
time

1153
00:39:27,680 --> 00:39:29,599
and when you enter spaces where you know

1154
00:39:29,599 --> 00:39:31,040
there's a lot of negativity and you have

1155
00:39:31,040 --> 00:39:31,839
more clout

1156
00:39:31,839 --> 00:39:33,920
when you are negative or when you shoot

1157
00:39:33,920 --> 00:39:35,280
other people down

1158
00:39:35,280 --> 00:39:37,119
um then that's kind of the behavior that

1159
00:39:37,119 --> 00:39:38,560
you take on that's what you think

1160
00:39:38,560 --> 00:39:40,160
online spaces are supposed to be like

1161
00:39:40,160 --> 00:39:42,240
and that's very harmful to constructive

1162
00:39:42,240 --> 00:39:45,119
civic discussions so many countries in

1163
00:39:45,119 --> 00:39:46,640
africa at a very pivotal time

1164
00:39:46,640 --> 00:39:48,000
where people are coming online for the

1165
00:39:48,000 --> 00:39:50,079
first time um they're meeting these

1166
00:39:50,079 --> 00:39:52,320
digital spaces and i always remember you

1167
00:39:52,320 --> 00:39:54,320
know like 20 years ago 30 years ago

1168
00:39:54,320 --> 00:39:56,480
maybe not that long but um you know what

1169
00:39:56,480 --> 00:39:57,440
a beautiful space

1170
00:39:57,440 --> 00:39:59,200
it was and now if you come online for

1171
00:39:59,200 --> 00:40:00,800
the first time what a different space it

1172
00:40:00,800 --> 00:40:01,599
is

1173
00:40:01,599 --> 00:40:03,920
and what can we actually do um you know

1174
00:40:03,920 --> 00:40:05,440
even this initiative that's launching

1175
00:40:05,440 --> 00:40:06,079
today

1176
00:40:06,079 --> 00:40:07,520
what can we do when we bring together

1177
00:40:07,520 --> 00:40:09,119
governments educational institutions

1178
00:40:09,119 --> 00:40:10,800
media houses private companies

1179
00:40:10,800 --> 00:40:14,480
to work more on this topic of digital

1180
00:40:14,480 --> 00:40:16,800
empathy when you enter private spaces so

1181
00:40:16,800 --> 00:40:17,520
yes

1182
00:40:17,520 --> 00:40:20,160
content moderation and you know blocking

1183
00:40:20,160 --> 00:40:20,880
and

1184
00:40:20,880 --> 00:40:23,359
d platforming but what about users who

1185
00:40:23,359 --> 00:40:24,000
are coming online

1186
00:40:24,000 --> 00:40:25,119
for the first time as well i think

1187
00:40:25,119 --> 00:40:27,119
that's a topic that i would i would love

1188
00:40:27,119 --> 00:40:27,599
to have

1189
00:40:27,599 --> 00:40:29,680
broader conversations on so that's my

1190
00:40:29,680 --> 00:40:31,520
take on it

1191
00:40:31,520 --> 00:40:33,920
thank you so much nema uh we covered a

1192
00:40:33,920 --> 00:40:34,880
lot of ground

1193
00:40:34,880 --> 00:40:37,359
from you know where is the current you

1194
00:40:37,359 --> 00:40:39,200
know where do we see digital civic space

1195
00:40:39,200 --> 00:40:41,040
all the way down to internet access and

1196
00:40:41,040 --> 00:40:41,839
shutdowns

1197
00:40:41,839 --> 00:40:43,599
we've been getting a few questions

1198
00:40:43,599 --> 00:40:45,680
already so we'll we'll do a few rounds

1199
00:40:45,680 --> 00:40:46,240
here

1200
00:40:46,240 --> 00:40:48,880
um the first one i want to start with is

1201
00:40:48,880 --> 00:40:50,720
actually for you joan

1202
00:40:50,720 --> 00:40:53,040
just very briefly touching on this

1203
00:40:53,040 --> 00:40:54,079
relationship between

1204
00:40:54,079 --> 00:40:56,319
policies and implementation you know

1205
00:40:56,319 --> 00:40:57,920
you're researching this on an everyday

1206
00:40:57,920 --> 00:40:58,480
basis

1207
00:40:58,480 --> 00:41:00,400
very shortly where do you see the status

1208
00:41:00,400 --> 00:41:02,319
of you know good policies coming out

1209
00:41:02,319 --> 00:41:05,599
how is it going with implementation yeah

1210
00:41:05,599 --> 00:41:08,000
so one of the things that uh that the

1211
00:41:08,000 --> 00:41:09,760
field of science studies

1212
00:41:09,760 --> 00:41:12,079
and kind of brings to the fore is uh

1213
00:41:12,079 --> 00:41:14,280
this notion that technology

1214
00:41:14,280 --> 00:41:17,119
is policy made durable

1215
00:41:17,119 --> 00:41:19,359
which is to say that often technology

1216
00:41:19,359 --> 00:41:22,480
arrives in the world

1217
00:41:22,800 --> 00:41:24,960
even years ahead of the policies we're

1218
00:41:24,960 --> 00:41:26,000
going to need

1219
00:41:26,000 --> 00:41:28,960
to uh wrangle them and so of course this

1220
00:41:28,960 --> 00:41:29,440
is

1221
00:41:29,440 --> 00:41:31,440
playing out very clearly in the space of

1222
00:41:31,440 --> 00:41:33,119
ai we have

1223
00:41:33,119 --> 00:41:36,560
uh big debates about facial recognition

1224
00:41:36,560 --> 00:41:37,599
technologies

1225
00:41:37,599 --> 00:41:39,599
and what are the appropriate policies

1226
00:41:39,599 --> 00:41:41,280
even though the technology is already

1227
00:41:41,280 --> 00:41:42,000
here

1228
00:41:42,000 --> 00:41:44,599
right and so there's been calls for

1229
00:41:44,599 --> 00:41:46,839
moratoriums against this kind of

1230
00:41:46,839 --> 00:41:48,160
technology uh

1231
00:41:48,160 --> 00:41:49,440
and so it's really important to

1232
00:41:49,440 --> 00:41:51,359
understand that the technology arrives

1233
00:41:51,359 --> 00:41:52,319
usually much

1234
00:41:52,319 --> 00:41:54,480
earlier than the guard rails or the

1235
00:41:54,480 --> 00:41:55,359
policies

1236
00:41:55,359 --> 00:41:57,119
and right now with social media i feel

1237
00:41:57,119 --> 00:41:58,640
like we're at this point where

1238
00:41:58,640 --> 00:42:02,160
someone has built you know a 737

1239
00:42:02,160 --> 00:42:04,640
and they're in their circle and you know

1240
00:42:04,640 --> 00:42:06,560
trying to land it and we don't have the

1241
00:42:06,560 --> 00:42:07,760
airports we don't have the

1242
00:42:07,760 --> 00:42:10,079
infrastructure in place we don't have

1243
00:42:10,079 --> 00:42:13,200
uh the context in which uh

1244
00:42:13,200 --> 00:42:15,280
we would need to to be able to

1245
00:42:15,280 --> 00:42:16,319
understand well

1246
00:42:16,319 --> 00:42:18,800
this technology is is being used by

1247
00:42:18,800 --> 00:42:20,560
these actors in this way

1248
00:42:20,560 --> 00:42:22,640
which is totally fine right facebook

1249
00:42:22,640 --> 00:42:24,400
events where you're

1250
00:42:24,400 --> 00:42:26,640
organizing your kids birthday party

1251
00:42:26,640 --> 00:42:28,800
totally innocuous use

1252
00:42:28,800 --> 00:42:32,319
same exact technology used to

1253
00:42:32,319 --> 00:42:35,359
uh plan ride shares to take down the

1254
00:42:35,359 --> 00:42:36,319
capital

1255
00:42:36,319 --> 00:42:37,920
right and so it's really important that

1256
00:42:37,920 --> 00:42:39,760
we understand that it isn't just a

1257
00:42:39,760 --> 00:42:40,800
question of

1258
00:42:40,800 --> 00:42:42,800
okay the technology is introduced we

1259
00:42:42,800 --> 00:42:44,000
know what the technologies

1260
00:42:44,000 --> 00:42:46,880
capacities are we know then know what

1261
00:42:46,880 --> 00:42:48,160
policies to make

1262
00:42:48,160 --> 00:42:51,200
scale intervenes in a very strange way

1263
00:42:51,200 --> 00:42:52,640
which is to say that

1264
00:42:52,640 --> 00:42:55,359
when we have millions or hundreds or

1265
00:42:55,359 --> 00:42:57,680
thousands or millions of people

1266
00:42:57,680 --> 00:43:00,800
misusing the technology uh in ways that

1267
00:43:00,800 --> 00:43:01,680
the

1268
00:43:01,680 --> 00:43:04,079
the original designers didn't intend

1269
00:43:04,079 --> 00:43:05,839
that's when we need to

1270
00:43:05,839 --> 00:43:08,480
um have a conversation about what the

1271
00:43:08,480 --> 00:43:11,280
policy is what the implementation is and

1272
00:43:11,280 --> 00:43:13,760
and i've been a strong advocate of

1273
00:43:13,760 --> 00:43:15,359
trying to understand

1274
00:43:15,359 --> 00:43:18,400
disinformation not as a content

1275
00:43:18,400 --> 00:43:20,480
free speech issue but as an issue of

1276
00:43:20,480 --> 00:43:22,240
amplification that is to say

1277
00:43:22,240 --> 00:43:24,720
if misinformation is reaching millions

1278
00:43:24,720 --> 00:43:26,560
it's actually a different problem

1279
00:43:26,560 --> 00:43:29,440
and needs a different policy fix than

1280
00:43:29,440 --> 00:43:31,440
something like hey someone is wrong

1281
00:43:31,440 --> 00:43:33,839
on the internet um and so those are the

1282
00:43:33,839 --> 00:43:35,760
kinds of things that i think policy wise

1283
00:43:35,760 --> 00:43:37,520
we have to think through which is

1284
00:43:37,520 --> 00:43:40,560
really about the process under which we

1285
00:43:40,560 --> 00:43:42,880
decide something is a problem and then

1286
00:43:42,880 --> 00:43:45,200
what policies are going to

1287
00:43:45,200 --> 00:43:47,680
uh be useful in terms of the scale of

1288
00:43:47,680 --> 00:43:50,079
the harm

1289
00:43:50,079 --> 00:43:52,160
thank you joan and picking up on this

1290
00:43:52,160 --> 00:43:53,680
we've been getting quite uh

1291
00:43:53,680 --> 00:43:55,359
quite a number of questions for the

1292
00:43:55,359 --> 00:43:57,040
company representatives

1293
00:43:57,040 --> 00:43:59,359
um and i want to pick up also on what

1294
00:43:59,359 --> 00:44:01,040
you said you know that is very no

1295
00:44:01,040 --> 00:44:03,040
internet shutdown where we're seeing you

1296
00:44:03,040 --> 00:44:04,160
know that the

1297
00:44:04,160 --> 00:44:06,560
access to these platforms are being you

1298
00:44:06,560 --> 00:44:07,440
know banned

1299
00:44:07,440 --> 00:44:09,839
or hindering people from actually using

1300
00:44:09,839 --> 00:44:11,040
them

1301
00:44:11,040 --> 00:44:13,599
miranda let me start by hearing a little

1302
00:44:13,599 --> 00:44:14,240
bit about you

1303
00:44:14,240 --> 00:44:16,000
you know there's been questions around

1304
00:44:16,000 --> 00:44:17,920
you know what kind of structural changes

1305
00:44:17,920 --> 00:44:19,599
or you know what kind of policies are

1306
00:44:19,599 --> 00:44:21,119
you seeing facebook being putting in in

1307
00:44:21,119 --> 00:44:22,319
terms of being you know

1308
00:44:22,319 --> 00:44:24,640
not becoming a you know a weapon for

1309
00:44:24,640 --> 00:44:25,359
malicious

1310
00:44:25,359 --> 00:44:26,720
governments or you know autocratic

1311
00:44:26,720 --> 00:44:28,720
governments um you know

1312
00:44:28,720 --> 00:44:31,520
how are you seeing the opportunity for

1313
00:44:31,520 --> 00:44:33,200
corporate activists and

1314
00:44:33,200 --> 00:44:36,000
uh in terms of defending digital civic

1315
00:44:36,000 --> 00:44:38,400
space

1316
00:44:38,400 --> 00:44:42,000
thanks um so i um i could speak for like

1317
00:44:42,000 --> 00:44:42,880
two hours

1318
00:44:42,880 --> 00:44:44,640
and of course it's not words but action

1319
00:44:44,640 --> 00:44:46,160
that's important

1320
00:44:46,160 --> 00:44:47,839
so i think the key thing to the

1321
00:44:47,839 --> 00:44:49,760
fundamental thing is that the majority

1322
00:44:49,760 --> 00:44:50,800
of facebook

1323
00:44:50,800 --> 00:44:53,440
policies and structures um deeply

1324
00:44:53,440 --> 00:44:54,880
influenced by the membership

1325
00:44:54,880 --> 00:44:56,720
of global network initiative which is a

1326
00:44:56,720 --> 00:44:58,400
multi-stakeholder coalition

1327
00:44:58,400 --> 00:45:02,560
of companies and groups are designed to

1328
00:45:02,560 --> 00:45:05,680
protect freedom of expression um and

1329
00:45:05,680 --> 00:45:07,760
freedom and access to information and

1330
00:45:07,760 --> 00:45:09,280
protection against arbitrary government

1331
00:45:09,280 --> 00:45:10,079
take down

1332
00:45:10,079 --> 00:45:12,480
so we we operate those daily and that's

1333
00:45:12,480 --> 00:45:14,800
a bedrock that's almost impossible to

1334
00:45:14,800 --> 00:45:17,119
explain or overvalue right and not all

1335
00:45:17,119 --> 00:45:19,119
companies have that bedrock

1336
00:45:19,119 --> 00:45:20,640
right not all companies are members of

1337
00:45:20,640 --> 00:45:22,720
the gni so i see there's

1338
00:45:22,720 --> 00:45:24,640
a fundamental opportunity for companies

1339
00:45:24,640 --> 00:45:26,000
to make

1340
00:45:26,000 --> 00:45:28,160
and enact those basic protections where

1341
00:45:28,160 --> 00:45:30,480
they seek to evaluate government

1342
00:45:30,480 --> 00:45:32,000
requests against local law

1343
00:45:32,000 --> 00:45:33,839
and international law and seek to push

1344
00:45:33,839 --> 00:45:36,000
back by all means possible

1345
00:45:36,000 --> 00:45:39,200
um i also think that i'd like to

1346
00:45:39,200 --> 00:45:42,800
revert to um brett's notes the 15 points

1347
00:45:42,800 --> 00:45:44,079
that he made

1348
00:45:44,079 --> 00:45:47,359
right now the space is very fractured

1349
00:45:47,359 --> 00:45:49,599
um we are in the midst of a variety of

1350
00:45:49,599 --> 00:45:50,400
different ways

1351
00:45:50,400 --> 00:45:53,520
of backlash and recognition um of the

1352
00:45:53,520 --> 00:45:54,160
strengths

1353
00:45:54,160 --> 00:45:58,839
and negatives of of all of the tech

1354
00:45:58,839 --> 00:46:01,839
tools

1355
00:46:07,200 --> 00:46:09,520
miranda has oh you're back with us you

1356
00:46:09,520 --> 00:46:10,800
just froze for a second

1357
00:46:10,800 --> 00:46:15,839
please continue miranda

1358
00:46:16,640 --> 00:46:18,079
while we're waiting for miranda's

1359
00:46:18,079 --> 00:46:19,680
internet connection

1360
00:46:19,680 --> 00:46:21,920
speaking of keeping it on jessica let me

1361
00:46:21,920 --> 00:46:23,040
just get a few you know

1362
00:46:23,040 --> 00:46:24,640
a short remark from you when we talk

1363
00:46:24,640 --> 00:46:27,040
corporate activists in this space

1364
00:46:27,040 --> 00:46:29,040
um and especially around some of the

1365
00:46:29,040 --> 00:46:30,319
systemic you know

1366
00:46:30,319 --> 00:46:32,160
changes that corporates need to do in

1367
00:46:32,160 --> 00:46:34,000
this what do you see is reddit's

1368
00:46:34,000 --> 00:46:35,839
you know one or two best examples of

1369
00:46:35,839 --> 00:46:38,000
that

1370
00:46:38,240 --> 00:46:41,040
yeah well how you push back really

1371
00:46:41,040 --> 00:46:42,560
depends on you know the

1372
00:46:42,560 --> 00:46:44,480
nature of the government that you're

1373
00:46:44,480 --> 00:46:45,599
dealing with so

1374
00:46:45,599 --> 00:46:48,160
in established democracies you can use

1375
00:46:48,160 --> 00:46:50,480
the court system and we can and do

1376
00:46:50,480 --> 00:46:53,359
that frequently but to be honest in kind

1377
00:46:53,359 --> 00:46:54,000
of the more

1378
00:46:54,000 --> 00:46:55,839
authoritarian regimes that are passing

1379
00:46:55,839 --> 00:46:57,119
stricter

1380
00:46:57,119 --> 00:47:00,400
internet regulations like turkey

1381
00:47:00,400 --> 00:47:03,680
like russia it's really hard because

1382
00:47:03,680 --> 00:47:05,200
frankly the government

1383
00:47:05,200 --> 00:47:07,680
holds all the cards and if you don't

1384
00:47:07,680 --> 00:47:08,240
comply

1385
00:47:08,240 --> 00:47:11,040
you know at the least they can block you

1386
00:47:11,040 --> 00:47:11,920
which isn't

1387
00:47:11,920 --> 00:47:15,839
good for any of your users they can also

1388
00:47:15,839 --> 00:47:19,280
arrest people and so um what's really

1389
00:47:19,280 --> 00:47:21,760
troubling is when we see kind of more

1390
00:47:21,760 --> 00:47:23,440
established democracies

1391
00:47:23,440 --> 00:47:25,520
copying in a lot of ways that

1392
00:47:25,520 --> 00:47:27,599
authoritarian playbook we're seeing

1393
00:47:27,599 --> 00:47:30,319
you know draft laws in first in

1394
00:47:30,319 --> 00:47:32,319
australia for example right now

1395
00:47:32,319 --> 00:47:35,839
um that would block um

1396
00:47:35,839 --> 00:47:38,960
internet platforms after you know two

1397
00:47:38,960 --> 00:47:40,480
infractions

1398
00:47:40,480 --> 00:47:43,200
we're seeing draft laws in the uk that

1399
00:47:43,200 --> 00:47:43,599
would

1400
00:47:43,599 --> 00:47:46,640
arrest company directors and so i really

1401
00:47:46,640 --> 00:47:47,760
think it's important

1402
00:47:47,760 --> 00:47:51,280
that global democracies set some norms

1403
00:47:51,280 --> 00:47:51,760
for

1404
00:47:51,760 --> 00:47:55,280
what's acceptable behavior for um

1405
00:47:55,280 --> 00:47:57,040
democracies and rights respecting

1406
00:47:57,040 --> 00:47:58,400
societies in

1407
00:47:58,400 --> 00:48:00,800
achieving their you know very legitimate

1408
00:48:00,800 --> 00:48:05,040
goals of online safety and protection

1409
00:48:05,040 --> 00:48:06,960
fred where are we in terms of setting

1410
00:48:06,960 --> 00:48:10,000
those norms globally

1411
00:48:11,119 --> 00:48:14,160
um again it depends uh depends on the

1412
00:48:14,160 --> 00:48:14,640
norm

1413
00:48:14,640 --> 00:48:18,400
um but i i wanna um

1414
00:48:18,400 --> 00:48:20,480
i think there's a few there's a few out

1415
00:48:20,480 --> 00:48:21,520
of the list the

1416
00:48:21,520 --> 00:48:23,440
15. and there's a couple of that i'd

1417
00:48:23,440 --> 00:48:24,640
like to sort of and

1418
00:48:24,640 --> 00:48:25,920
maybe responding to one of the questions

1419
00:48:25,920 --> 00:48:27,839
in the chat about like

1420
00:48:27,839 --> 00:48:30,079
where should focus be i think one of the

1421
00:48:30,079 --> 00:48:30,960
things that would be

1422
00:48:30,960 --> 00:48:33,280
very helpful um across the board that

1423
00:48:33,280 --> 00:48:35,520
would deal with many of the issues that

1424
00:48:35,520 --> 00:48:38,400
um the both the tech reps and also um

1425
00:48:38,400 --> 00:48:40,000
some of the civil society

1426
00:48:40,000 --> 00:48:41,680
and academics on the panel have

1427
00:48:41,680 --> 00:48:43,359
mentioned is we

1428
00:48:43,359 --> 00:48:46,000
really need robust data protection

1429
00:48:46,000 --> 00:48:47,119
frameworks

1430
00:48:47,119 --> 00:48:49,359
nationally within every country because

1431
00:48:49,359 --> 00:48:50,960
if we get the data piece

1432
00:48:50,960 --> 00:48:54,079
right i think we get a lot of the rest

1433
00:48:54,079 --> 00:48:55,839
of the equation right

1434
00:48:55,839 --> 00:48:58,800
and right now we have you know

1435
00:48:58,800 --> 00:49:00,640
extraordinary amounts of information

1436
00:49:00,640 --> 00:49:02,160
that's been collected by

1437
00:49:02,160 --> 00:49:04,480
the tech sector major question marks of

1438
00:49:04,480 --> 00:49:06,000
course over the business model and

1439
00:49:06,000 --> 00:49:07,760
whether it's currently appropriate in

1440
00:49:07,760 --> 00:49:08,800
the context that we're

1441
00:49:08,800 --> 00:49:13,040
we're in now in 2021 and in this decade

1442
00:49:13,040 --> 00:49:15,680
but not just data that's been collected

1443
00:49:15,680 --> 00:49:17,359
by companies but data that's been

1444
00:49:17,359 --> 00:49:18,559
collected by governments as well

1445
00:49:18,559 --> 00:49:20,000
particularly in the context of all of

1446
00:49:20,000 --> 00:49:21,200
this health data

1447
00:49:21,200 --> 00:49:23,200
um that we've got um that's being

1448
00:49:23,200 --> 00:49:24,480
collected including from

1449
00:49:24,480 --> 00:49:27,119
you know vaccination apps and and and

1450
00:49:27,119 --> 00:49:28,960
and contact tracing and

1451
00:49:28,960 --> 00:49:31,200
and immunity passports and so on so i

1452
00:49:31,200 --> 00:49:32,160
think if we can get

1453
00:49:32,160 --> 00:49:35,200
that norm right and that norm legislated

1454
00:49:35,200 --> 00:49:35,760
for

1455
00:49:35,760 --> 00:49:37,760
there's going to be significant benefits

1456
00:49:37,760 --> 00:49:39,359
in terms of holding tech companies

1457
00:49:39,359 --> 00:49:40,720
accountable

1458
00:49:40,720 --> 00:49:42,559
and also holding governments accountable

1459
00:49:42,559 --> 00:49:44,559
and ensuring the citizen actually has

1460
00:49:44,559 --> 00:49:47,119
further and the user has further control

1461
00:49:47,119 --> 00:49:49,119
um i think the other issue that's

1462
00:49:49,119 --> 00:49:51,760
super important and we've seen it play

1463
00:49:51,760 --> 00:49:52,480
out in

1464
00:49:52,480 --> 00:49:54,480
countries all across the world from you

1465
00:49:54,480 --> 00:49:56,079
know hong kong to

1466
00:49:56,079 --> 00:49:58,960
to palestine to myanmar is this issue

1467
00:49:58,960 --> 00:50:01,119
around the right to peaceful protest

1468
00:50:01,119 --> 00:50:04,559
and and that that issue is um

1469
00:50:04,559 --> 00:50:06,319
that right is being undermined

1470
00:50:06,319 --> 00:50:08,480
significantly in the digital environment

1471
00:50:08,480 --> 00:50:10,480
and also how then how it plays in the

1472
00:50:10,480 --> 00:50:12,000
physical environment and the third one

1473
00:50:12,000 --> 00:50:13,599
that i want to mention

1474
00:50:13,599 --> 00:50:16,240
relates to facial recognition um and

1475
00:50:16,240 --> 00:50:18,240
it's also obviously a biometric data

1476
00:50:18,240 --> 00:50:20,640
issue it's it's in the list of 15

1477
00:50:20,640 --> 00:50:24,319
but particularly around the use of

1478
00:50:24,319 --> 00:50:26,160
of facial recognition in publicly

1479
00:50:26,160 --> 00:50:27,599
accessible spaces

1480
00:50:27,599 --> 00:50:28,880
and i think if we get the data

1481
00:50:28,880 --> 00:50:30,720
protection bit right the assembly piece

1482
00:50:30,720 --> 00:50:31,119
right

1483
00:50:31,119 --> 00:50:33,119
uh and the facial recognition piece

1484
00:50:33,119 --> 00:50:35,119
right we're

1485
00:50:35,119 --> 00:50:37,280
in a way being a little prophetic about

1486
00:50:37,280 --> 00:50:39,839
what this next decade looks like

1487
00:50:39,839 --> 00:50:42,480
and how to make sure that the digital

1488
00:50:42,480 --> 00:50:44,079
space is actually one that enables

1489
00:50:44,079 --> 00:50:46,319
democracy which i think is essentially

1490
00:50:46,319 --> 00:50:49,040
the the topic of this panel um just

1491
00:50:49,040 --> 00:50:50,160
before i hand back

1492
00:50:50,160 --> 00:50:53,760
i i also i mean we want to hear from the

1493
00:50:53,760 --> 00:50:55,920
rest of what miranda has to say

1494
00:50:55,920 --> 00:50:59,760
um but again i think that

1495
00:50:59,760 --> 00:51:01,760
it's not just a member of being the gni

1496
00:51:01,760 --> 00:51:03,200
which is the issue like we're seeing

1497
00:51:03,200 --> 00:51:04,960
this play out in real time

1498
00:51:04,960 --> 00:51:07,520
now we've seen it in myanmar we've seen

1499
00:51:07,520 --> 00:51:08,319
it in

1500
00:51:08,319 --> 00:51:09,599
palestine which i've mentioned a few

1501
00:51:09,599 --> 00:51:11,200
times we've seen in colombia we've seen

1502
00:51:11,200 --> 00:51:13,040
it in the u.s

1503
00:51:13,040 --> 00:51:14,880
and there needs to be across the board

1504
00:51:14,880 --> 00:51:17,119
it's not just within facebook but also

1505
00:51:17,119 --> 00:51:18,559
within reddit and all of the tech

1506
00:51:18,559 --> 00:51:20,480
platforms that there needs to be a

1507
00:51:20,480 --> 00:51:23,599
greater allocation of resources

1508
00:51:23,599 --> 00:51:25,040
when they're dealing with these issues

1509
00:51:25,040 --> 00:51:27,280
that are life and death and at scale and

1510
00:51:27,280 --> 00:51:28,800
i think that unless we get

1511
00:51:28,800 --> 00:51:31,359
that commitment from the tech companies

1512
00:51:31,359 --> 00:51:32,720
which is not just about writing great

1513
00:51:32,720 --> 00:51:33,440
documents

1514
00:51:33,440 --> 00:51:35,839
but actually resourcing a commitment to

1515
00:51:35,839 --> 00:51:37,280
human rights protection

1516
00:51:37,280 --> 00:51:38,800
in the real world or in the offline

1517
00:51:38,800 --> 00:51:40,800
world in the world including the digital

1518
00:51:40,800 --> 00:51:42,079
space

1519
00:51:42,079 --> 00:51:45,040
that then democracy has a chance and if

1520
00:51:45,040 --> 00:51:45,680
we don't

1521
00:51:45,680 --> 00:51:47,920
if we don't see that and that commitment

1522
00:51:47,920 --> 00:51:49,920
from the tech sector then

1523
00:51:49,920 --> 00:51:51,599
you know we're all going to we're all

1524
00:51:51,599 --> 00:51:53,760
going to lose out

1525
00:51:53,760 --> 00:51:55,920
miranda where is the what does it look

1526
00:51:55,920 --> 00:51:57,440
like from the tech sector

1527
00:51:57,440 --> 00:51:59,040
what do you see of the commitments going

1528
00:51:59,040 --> 00:52:00,559
forward

1529
00:52:00,559 --> 00:52:02,400
yeah i can't speak on behalf of our

1530
00:52:02,400 --> 00:52:04,079
company but bret i think the fundamental

1531
00:52:04,079 --> 00:52:05,200
thing to understand

1532
00:52:05,200 --> 00:52:06,960
is that the gni commitments have a real

1533
00:52:06,960 --> 00:52:09,599
price tag we have to staff

1534
00:52:09,599 --> 00:52:12,240
the huge teams to assess the government

1535
00:52:12,240 --> 00:52:13,119
requests

1536
00:52:13,119 --> 00:52:15,680
we need outside counsel we fund the

1537
00:52:15,680 --> 00:52:17,760
human rights impact assessment we fund

1538
00:52:17,760 --> 00:52:18,000
the

1539
00:52:18,000 --> 00:52:20,559
operational procedures to handle these

1540
00:52:20,559 --> 00:52:22,319
one by one and to assess them

1541
00:52:22,319 --> 00:52:24,800
and to build infrastructure they are far

1542
00:52:24,800 --> 00:52:27,040
from perfect and covert has taken a huge

1543
00:52:27,040 --> 00:52:27,680
toll

1544
00:52:27,680 --> 00:52:30,000
so we can argue for increased resourcing

1545
00:52:30,000 --> 00:52:31,119
but do not

1546
00:52:31,119 --> 00:52:33,280
for a second i would not want anyone on

1547
00:52:33,280 --> 00:52:34,240
this panel

1548
00:52:34,240 --> 00:52:35,680
to think that these were paper

1549
00:52:35,680 --> 00:52:37,920
commitments that had no resource

1550
00:52:37,920 --> 00:52:40,720
tag already or no meaning okay so there

1551
00:52:40,720 --> 00:52:42,400
is a world more to do

1552
00:52:42,400 --> 00:52:46,079
but there is real you action i i

1553
00:52:46,079 --> 00:52:49,280
agree if i may i think that the gni is a

1554
00:52:49,280 --> 00:52:50,720
global network initiative for people who

1555
00:52:50,720 --> 00:52:53,280
are listening not not aware which is a

1556
00:52:53,280 --> 00:52:54,720
a collection of companies that have

1557
00:52:54,720 --> 00:52:56,480
committed to a set of principles

1558
00:52:56,480 --> 00:52:59,040
absolutely an important and essential

1559
00:52:59,040 --> 00:53:00,480
body it's we watched it since the

1560
00:53:00,480 --> 00:53:01,280
beginning of

1561
00:53:01,280 --> 00:53:04,480
writescon 10 years ago but but

1562
00:53:04,480 --> 00:53:07,280
again like you know sort of um

1563
00:53:07,280 --> 00:53:09,200
assessments that happen

1564
00:53:09,200 --> 00:53:12,800
with um you know lawyers and um

1565
00:53:12,800 --> 00:53:16,960
and assessors uh in menlo park

1566
00:53:16,960 --> 00:53:19,280
is different to what it means for an

1567
00:53:19,280 --> 00:53:21,119
activist or a civil society member on

1568
00:53:21,119 --> 00:53:21,920
the ground

1569
00:53:21,920 --> 00:53:24,800
who can't access their hashtag on right

1570
00:53:24,800 --> 00:53:25,839
on instagram you're like

1571
00:53:25,839 --> 00:53:27,520
that's a there's a gap there and i think

1572
00:53:27,520 --> 00:53:29,440
that we need to close that gap

1573
00:53:29,440 --> 00:53:30,880
it's not to say that we don't need the

1574
00:53:30,880 --> 00:53:32,720
principles or we need that we don't need

1575
00:53:32,720 --> 00:53:34,400
the the bodies that are going to monitor

1576
00:53:34,400 --> 00:53:34,640
it

1577
00:53:34,640 --> 00:53:36,160
but we need to have implementation in

1578
00:53:36,160 --> 00:53:37,440
the ground and i think we're on the

1579
00:53:37,440 --> 00:53:37,839
ground

1580
00:53:37,839 --> 00:53:39,680
and i think we're past the point now in

1581
00:53:39,680 --> 00:53:41,520
terms of what we're seeing and the

1582
00:53:41,520 --> 00:53:44,160
consequences of bad tech from democracy

1583
00:53:44,160 --> 00:53:45,280
and citizens

1584
00:53:45,280 --> 00:53:47,040
that you know it's time to turn this

1585
00:53:47,040 --> 00:53:49,440
around miranda a very

1586
00:53:49,440 --> 00:53:51,440
very quick answer on so where do you see

1587
00:53:51,440 --> 00:53:53,440
the commitments particularly on a global

1588
00:53:53,440 --> 00:53:55,040
scale

1589
00:53:55,040 --> 00:53:56,880
yeah so i think first of all the human

1590
00:53:56,880 --> 00:53:58,559
rights policy which is not just about

1591
00:53:58,559 --> 00:54:00,640
words on paper but is a codification

1592
00:54:00,640 --> 00:54:04,000
and a deep dive into different processes

1593
00:54:04,000 --> 00:54:05,040
that we already have

1594
00:54:05,040 --> 00:54:07,200
and that we are intending to strengthen

1595
00:54:07,200 --> 00:54:08,480
we also commit

1596
00:54:08,480 --> 00:54:10,800
by the way to a global human rights

1597
00:54:10,800 --> 00:54:11,839
report

1598
00:54:11,839 --> 00:54:13,839
annually which i think might be a really

1599
00:54:13,839 --> 00:54:15,119
great way just of

1600
00:54:15,119 --> 00:54:17,599
sharing insights and actions but also

1601
00:54:17,599 --> 00:54:19,760
beginning to drive the accountability

1602
00:54:19,760 --> 00:54:22,160
and drive the conversation much quicker

1603
00:54:22,160 --> 00:54:24,400
and much more publicly to contribute

1604
00:54:24,400 --> 00:54:26,640
towards closing gaps

1605
00:54:26,640 --> 00:54:30,240
but this is not a seamless easy

1606
00:54:30,240 --> 00:54:33,040
experience for anyone right and some of

1607
00:54:33,040 --> 00:54:34,079
these gaps that

1608
00:54:34,079 --> 00:54:35,760
brett you're alluding to are the results

1609
00:54:35,760 --> 00:54:38,000
of enforcement right enforcement

1610
00:54:38,000 --> 00:54:39,680
against good policies enforcement

1611
00:54:39,680 --> 00:54:41,440
against bad policies

1612
00:54:41,440 --> 00:54:43,200
technical failures all kinds of

1613
00:54:43,200 --> 00:54:44,559
different things where

1614
00:54:44,559 --> 00:54:48,799
some of what we need to do is invest in

1615
00:54:48,799 --> 00:54:50,559
much better and more robust

1616
00:54:50,559 --> 00:54:52,640
conversations based on data to narrow

1617
00:54:52,640 --> 00:54:55,119
the problems and drive to change

1618
00:54:55,119 --> 00:54:58,000
which you know is one reason why that um

1619
00:54:58,000 --> 00:54:58,319
we

1620
00:54:58,319 --> 00:54:59,839
here at wright's con is to try and

1621
00:54:59,839 --> 00:55:01,520
contribute the thinking and the

1622
00:55:01,520 --> 00:55:03,280
participation and activism and

1623
00:55:03,280 --> 00:55:06,160
we hope that our policies relate to

1624
00:55:06,160 --> 00:55:06,720
action

1625
00:55:06,720 --> 00:55:10,079
to show not tell change

1626
00:55:10,079 --> 00:55:12,960
and i'll leave it at that excellent i

1627
00:55:12,960 --> 00:55:15,520
want to go over to you nima i mean you

1628
00:55:15,520 --> 00:55:17,280
spoke around some of the challenges that

1629
00:55:17,280 --> 00:55:19,520
you are facing on a daily basis and how

1630
00:55:19,520 --> 00:55:20,480
you're working

1631
00:55:20,480 --> 00:55:22,160
you know against them you know working

1632
00:55:22,160 --> 00:55:24,160
working around or against them

1633
00:55:24,160 --> 00:55:25,920
when we talk about building local

1634
00:55:25,920 --> 00:55:27,520
resilience and when we talk about you

1635
00:55:27,520 --> 00:55:30,559
know using these platform as a way to

1636
00:55:30,559 --> 00:55:32,240
advance digital civics based on

1637
00:55:32,240 --> 00:55:33,599
democracy

1638
00:55:33,599 --> 00:55:34,720
what do you see as the main

1639
00:55:34,720 --> 00:55:36,240
opportunities and i think for the rest

1640
00:55:36,240 --> 00:55:37,119
of the panel

1641
00:55:37,119 --> 00:55:38,960
what do you see as the role between you

1642
00:55:38,960 --> 00:55:41,280
know academia civil society and tech

1643
00:55:41,280 --> 00:55:44,079
companies in this

1644
00:55:44,160 --> 00:55:46,960
yeah so i think one of the main ones of

1645
00:55:46,960 --> 00:55:47,920
course is

1646
00:55:47,920 --> 00:55:49,599
building infrastructure and i obviously

1647
00:55:49,599 --> 00:55:51,200
know that that's very expensive

1648
00:55:51,200 --> 00:55:53,920
and but i think committing to supporting

1649
00:55:53,920 --> 00:55:55,119
countries to build infrastructure

1650
00:55:55,119 --> 00:55:57,599
especially going out into

1651
00:55:57,599 --> 00:55:59,680
rural areas where traditional

1652
00:55:59,680 --> 00:56:01,760
telecommunication networks do not find

1653
00:56:01,760 --> 00:56:02,000
it

1654
00:56:02,000 --> 00:56:03,440
profitable so they do not build their

1655
00:56:03,440 --> 00:56:05,280
towers there i think supporting

1656
00:56:05,280 --> 00:56:06,640
countries to build this kind of

1657
00:56:06,640 --> 00:56:07,920
infrastructure

1658
00:56:07,920 --> 00:56:09,839
um supporting them to lower their prices

1659
00:56:09,839 --> 00:56:11,599
so in east africa for example i know

1660
00:56:11,599 --> 00:56:12,880
that tanzania

1661
00:56:12,880 --> 00:56:14,400
and rwanda have really brought down the

1662
00:56:14,400 --> 00:56:16,160
cost but that's not the case in uganda

1663
00:56:16,160 --> 00:56:19,359
for example um for one you know gb of

1664
00:56:19,359 --> 00:56:20,960
data it can be up to 40

1665
00:56:20,960 --> 00:56:22,240
of your monthly income which is

1666
00:56:22,240 --> 00:56:24,799
completely prohibitive to get online

1667
00:56:24,799 --> 00:56:26,319
uh the other things that can be done are

1668
00:56:26,319 --> 00:56:28,720
local languages so localizing content so

1669
00:56:28,720 --> 00:56:30,000
that people who don't speak english

1670
00:56:30,000 --> 00:56:32,160
basically can get into online spaces

1671
00:56:32,160 --> 00:56:33,680
another big one that came up was on

1672
00:56:33,680 --> 00:56:36,000
research that we did which showed that

1673
00:56:36,000 --> 00:56:38,319
women who experienced violence online um

1674
00:56:38,319 --> 00:56:39,839
disconnected their accounts so either

1675
00:56:39,839 --> 00:56:41,280
they closed down their accounts

1676
00:56:41,280 --> 00:56:42,880
or they stopped using online services

1677
00:56:42,880 --> 00:56:44,640
and we've been talking about

1678
00:56:44,640 --> 00:56:46,240
you know bringing more people online but

1679
00:56:46,240 --> 00:56:47,920
if online spaces are

1680
00:56:47,920 --> 00:56:50,079
toxic then you're actually driving women

1681
00:56:50,079 --> 00:56:51,520
away and you know all these gains that

1682
00:56:51,520 --> 00:56:52,880
you've made through infrastructure are

1683
00:56:52,880 --> 00:56:53,839
lost

1684
00:56:53,839 --> 00:56:56,079
um then there's a lot of um i think

1685
00:56:56,079 --> 00:56:57,440
people need to come together to build

1686
00:56:57,440 --> 00:56:59,200
awareness against patriarchal norms

1687
00:56:59,200 --> 00:57:00,960
which keep women offline

1688
00:57:00,960 --> 00:57:03,119
so even like phone ownership can be a

1689
00:57:03,119 --> 00:57:04,799
big issue so that's you know that's a

1690
00:57:04,799 --> 00:57:06,720
bit of a softer area where

1691
00:57:06,720 --> 00:57:09,359
you don't need that much um investment

1692
00:57:09,359 --> 00:57:10,319
coalitions are

1693
00:57:10,319 --> 00:57:11,680
great to put pressure on governments

1694
00:57:11,680 --> 00:57:13,440
keep it on does such a great job in

1695
00:57:13,440 --> 00:57:14,559
putting pressure on governments when it

1696
00:57:14,559 --> 00:57:16,799
comes to internet shutdowns

1697
00:57:16,799 --> 00:57:18,480
a lot of people have been very quiet

1698
00:57:18,480 --> 00:57:20,319
about the shutdowns of um

1699
00:57:20,319 --> 00:57:21,839
different platforms of course which are

1700
00:57:21,839 --> 00:57:23,599
private companies but it would be

1701
00:57:23,599 --> 00:57:24,960
interesting to see

1702
00:57:24,960 --> 00:57:26,880
other bodies like african union come

1703
00:57:26,880 --> 00:57:28,480
forward and also you know

1704
00:57:28,480 --> 00:57:30,799
voice what's going on across africa and

1705
00:57:30,799 --> 00:57:32,160
then of course there's certain

1706
00:57:32,160 --> 00:57:33,920
policies and laws that are brought about

1707
00:57:33,920 --> 00:57:35,440
by companies one of them

1708
00:57:35,440 --> 00:57:36,720
when we did our research called

1709
00:57:36,720 --> 00:57:38,559
afrofeminist data futures

1710
00:57:38,559 --> 00:57:40,319
um one of the big issues that came up

1711
00:57:40,319 --> 00:57:42,880
when using online platforms are

1712
00:57:42,880 --> 00:57:44,480
some of these colonialist vague

1713
00:57:44,480 --> 00:57:46,240
practices like shadow banning so for

1714
00:57:46,240 --> 00:57:47,280
example

1715
00:57:47,280 --> 00:57:48,559
you know if you want to talk about

1716
00:57:48,559 --> 00:57:50,480
colonial issues patriarchal issues

1717
00:57:50,480 --> 00:57:52,000
violence against black people then you

1718
00:57:52,000 --> 00:57:53,280
might be shadow band or you know your

1719
00:57:53,280 --> 00:57:54,640
content might be removed we've seen it

1720
00:57:54,640 --> 00:57:55,440
with other

1721
00:57:55,440 --> 00:57:57,680
recent happenings where if you want to

1722
00:57:57,680 --> 00:57:59,119
discuss issues related to certain

1723
00:57:59,119 --> 00:58:00,640
contexts you're not allowed to

1724
00:58:00,640 --> 00:58:01,920
or your content gets taken out for

1725
00:58:01,920 --> 00:58:03,760
whatever reason so i think there's a lot

1726
00:58:03,760 --> 00:58:05,440
that can be done in terms of um

1727
00:58:05,440 --> 00:58:07,200
investment of like you know hard cash

1728
00:58:07,200 --> 00:58:08,480
but also in terms of

1729
00:58:08,480 --> 00:58:09,920
bringing together different sectors to

1730
00:58:09,920 --> 00:58:11,680
work on some of these software areas of

1731
00:58:11,680 --> 00:58:13,200
policy advocacy

1732
00:58:13,200 --> 00:58:14,480
awareness building that i think could

1733
00:58:14,480 --> 00:58:16,799
make a big difference

1734
00:58:16,799 --> 00:58:19,920
amazing so i feel like uh

1735
00:58:19,920 --> 00:58:22,000
the list of 15 points from brett just

1736
00:58:22,000 --> 00:58:23,359
got additional

1737
00:58:23,359 --> 00:58:25,280
lists very important points from you

1738
00:58:25,280 --> 00:58:27,280
nema not least in infrastructure

1739
00:58:27,280 --> 00:58:30,400
um one last question and joan i want to

1740
00:58:30,400 --> 00:58:31,920
go back to you you talked about we're

1741
00:58:31,920 --> 00:58:33,599
right now circling in an airplane

1742
00:58:33,599 --> 00:58:34,079
without

1743
00:58:34,079 --> 00:58:36,640
an airport to land in and that speaks to

1744
00:58:36,640 --> 00:58:38,079
the infrastructure but a bit more on the

1745
00:58:38,079 --> 00:58:39,040
policy side

1746
00:58:39,040 --> 00:58:41,920
of brett you still spoke to it too you

1747
00:58:41,920 --> 00:58:42,799
know

1748
00:58:42,799 --> 00:58:44,880
can you can you make it a bit of you

1749
00:58:44,880 --> 00:58:46,079
know can you give give us a bit of

1750
00:58:46,079 --> 00:58:46,799
optimism

1751
00:58:46,799 --> 00:58:48,799
or or how does it look the next 12

1752
00:58:48,799 --> 00:58:50,000
months are we starting

1753
00:58:50,000 --> 00:58:52,960
to build that infrastructure um you know

1754
00:58:52,960 --> 00:58:55,520
what do you see as the outcome here

1755
00:58:55,520 --> 00:58:58,400
yeah i'm i'm certainly not optimism lady

1756
00:58:58,400 --> 00:58:58,880
so

1757
00:58:58,880 --> 00:59:02,319
i apologize for that but um i actually

1758
00:59:02,319 --> 00:59:02,720
do

1759
00:59:02,720 --> 00:59:04,160
you know the reason why i'm in this

1760
00:59:04,160 --> 00:59:06,480
field the reason why uh we do the work

1761
00:59:06,480 --> 00:59:08,559
we do at schwernstein is because we

1762
00:59:08,559 --> 00:59:11,599
we do care deeply about getting a

1763
00:59:11,599 --> 00:59:13,119
communication

1764
00:59:13,119 --> 00:59:15,040
system and infrastructure in place that

1765
00:59:15,040 --> 00:59:16,839
works for the broadest

1766
00:59:16,839 --> 00:59:20,160
possible uh group and so there's just

1767
00:59:20,160 --> 00:59:24,240
some some fundamental uh philosophical

1768
00:59:24,240 --> 00:59:26,079
shifts that need to happen which is to

1769
00:59:26,079 --> 00:59:27,839
say that we need to have

1770
00:59:27,839 --> 00:59:29,680
a broad understanding that the

1771
00:59:29,680 --> 00:59:31,599
technology that uh

1772
00:59:31,599 --> 00:59:34,799
undergirds our policy and our

1773
00:59:34,799 --> 00:59:36,799
our governance structures is is

1774
00:59:36,799 --> 00:59:38,640
incredibly important

1775
00:59:38,640 --> 00:59:41,119
and it's uh at the end of the day a

1776
00:59:41,119 --> 00:59:42,640
struggle over

1777
00:59:42,640 --> 00:59:45,200
power right we these companies are no

1778
00:59:45,200 --> 00:59:46,000
longer

1779
00:59:46,000 --> 00:59:49,440
you know dorm room operations as in the

1780
00:59:49,440 --> 00:59:50,559
case of facebook

1781
00:59:50,559 --> 00:59:54,319
it's no longer uh these ideas that

1782
00:59:54,319 --> 00:59:56,799
we're out here experimenting with even

1783
00:59:56,799 --> 00:59:57,839
something like

1784
00:59:57,839 --> 01:00:00,160
like reddit that seems innocuous right

1785
01:00:00,160 --> 01:00:02,240
it's just a website where people type

1786
01:00:02,240 --> 01:00:02,799
things

1787
01:00:02,799 --> 01:00:06,960
right uh you know um why would it end up

1788
01:00:06,960 --> 01:00:08,880
having such important

1789
01:00:08,880 --> 01:00:12,000
effects on our elections and on

1790
01:00:12,000 --> 01:00:14,079
our our journalism and on our

1791
01:00:14,079 --> 01:00:15,760
educational systems

1792
01:00:15,760 --> 01:00:18,720
and it's because this is where people

1793
01:00:18,720 --> 01:00:18,930
are

1794
01:00:18,930 --> 01:00:20,160
[Music]

1795
01:00:20,160 --> 01:00:23,760
coming up with uh ideas about how they

1796
01:00:23,760 --> 01:00:25,599
think the world should work

1797
01:00:25,599 --> 01:00:28,559
and there's a couple of fundamental um

1798
01:00:28,559 --> 01:00:29,440
problems

1799
01:00:29,440 --> 01:00:31,440
essentially with the openness of some of

1800
01:00:31,440 --> 01:00:32,480
these webs uh

1801
01:00:32,480 --> 01:00:34,960
some of these web platforms and so i

1802
01:00:34,960 --> 01:00:35,680
think

1803
01:00:35,680 --> 01:00:38,079
what we need to understand uh more than

1804
01:00:38,079 --> 01:00:39,920
anything at this point is the scale

1805
01:00:39,920 --> 01:00:41,680
question and how big is a company

1806
01:00:41,680 --> 01:00:42,960
allowed to get

1807
01:00:42,960 --> 01:00:46,640
uh if they cannot protect uh

1808
01:00:46,640 --> 01:00:48,880
the conversation as well as protect the

1809
01:00:48,880 --> 01:00:50,000
civic integrity

1810
01:00:50,000 --> 01:00:51,839
of information that's being circulated

1811
01:00:51,839 --> 01:00:53,040
to millions of people

1812
01:00:53,040 --> 01:00:55,839
at instantaneously and i think that

1813
01:00:55,839 --> 01:00:58,559
that's something that we need to address

1814
01:00:58,559 --> 01:01:01,839
amazing thank you so much uh with the

1815
01:01:01,839 --> 01:01:04,319
great power comes great responsibility i

1816
01:01:04,319 --> 01:01:04,960
want to

1817
01:01:04,960 --> 01:01:07,040
thank you all the participants and i

1818
01:01:07,040 --> 01:01:09,280
want to particularly i think the

1819
01:01:09,280 --> 01:01:11,680
today speakers for showing up and for

1820
01:01:11,680 --> 01:01:13,760
showing how you are taking on that

1821
01:01:13,760 --> 01:01:14,960
responsibility

1822
01:01:14,960 --> 01:01:18,160
and working to defend promote expand

1823
01:01:18,160 --> 01:01:19,680
digital civil rights

1824
01:01:19,680 --> 01:01:21,760
and digital civic space it's been an

1825
01:01:21,760 --> 01:01:23,359
incredibly interesting

1826
01:01:23,359 --> 01:01:25,520
conversation i know the debate could go

1827
01:01:25,520 --> 01:01:27,359
on for a long time we have lots of

1828
01:01:27,359 --> 01:01:29,040
questions still coming in so let's hope

1829
01:01:29,040 --> 01:01:30,240
this is

1830
01:01:30,240 --> 01:01:32,319
not an end but a continuation of a

1831
01:01:32,319 --> 01:01:34,160
discussion

1832
01:01:34,160 --> 01:01:36,400
thank you for your time to all the ones

1833
01:01:36,400 --> 01:01:38,000
who've been viewing this with us thank

1834
01:01:38,000 --> 01:01:39,680
you so much for tuning in

1835
01:01:39,680 --> 01:01:41,760
we look forward to working with you on

1836
01:01:41,760 --> 01:01:43,680
this in the future because there is

1837
01:01:43,680 --> 01:01:44,720
certainly

1838
01:01:44,720 --> 01:01:47,200
lots to do and i hope you all can take a

1839
01:01:47,200 --> 01:01:53,839
note thank you

1840
01:05:46,720 --> 01:05:48,799
you

