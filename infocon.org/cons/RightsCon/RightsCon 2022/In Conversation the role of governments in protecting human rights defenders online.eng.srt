1
00:00:03,040 --> 00:00:06,319
welcome to day two of rights con and in

2
00:00:06,319 --> 00:00:08,400
conversation the next 30 minutes with

3
00:00:08,400 --> 00:00:11,360
u.s secretary of state anthony blinken

4
00:00:11,360 --> 00:00:13,920
and nobel peace prize winner and

5
00:00:13,920 --> 00:00:15,920
journalist from the philippines maria

6
00:00:15,920 --> 00:00:18,960
raisa now we're doing this slightly

7
00:00:18,960 --> 00:00:22,160
differently uh in this segment we are

8
00:00:22,160 --> 00:00:24,160
actually partnering with the atlantic

9
00:00:24,160 --> 00:00:26,480
council's digital forensic lab who are

10
00:00:26,480 --> 00:00:28,400
having their summit

11
00:00:28,400 --> 00:00:31,760
in brussels it's called 360 open summit

12
00:00:31,760 --> 00:00:33,520
and there is rose jackson and graham

13
00:00:33,520 --> 00:00:36,719
brookie right now

14
00:00:36,719 --> 00:00:39,360
hi guys

15
00:00:40,480 --> 00:00:44,120
how are you guys doing

16
00:00:50,320 --> 00:00:52,000
i don't think i can hear you guys on my

17
00:00:52,000 --> 00:00:55,000
end

18
00:01:00,879 --> 00:01:02,960
hello rose and graham i'm so sorry but i

19
00:01:02,960 --> 00:01:06,840
can't hear you guys i hope

20
00:01:20,640 --> 00:01:23,040
so unfortunately for technical reasons i

21
00:01:23,040 --> 00:01:25,920
couldn't quite hear rosengrah at all but

22
00:01:25,920 --> 00:01:28,640
i presume that they've uh introduced me

23
00:01:28,640 --> 00:01:30,799
and said hello and of course just to let

24
00:01:30,799 --> 00:01:32,320
you know a little bit about what's

25
00:01:32,320 --> 00:01:34,799
happened in the next uh in the last day

26
00:01:34,799 --> 00:01:36,159
at wright's con

27
00:01:36,159 --> 00:01:38,400
it's been amazing uh for those of you

28
00:01:38,400 --> 00:01:41,360
who don't know in brussels rightscon is

29
00:01:41,360 --> 00:01:44,079
an incredible summit more than 8

30
00:01:44,079 --> 00:01:47,840
500 participants from over 150 countries

31
00:01:47,840 --> 00:01:48,720
and

32
00:01:48,720 --> 00:01:51,119
hundreds events from workshops to panels

33
00:01:51,119 --> 00:01:53,040
have been taking place in the last 24

34
00:01:53,040 --> 00:01:56,320
hours and for the rest of the week

35
00:01:56,320 --> 00:01:59,119
no surprises a lot of the concerns

36
00:01:59,119 --> 00:02:01,280
in brussels are also being discussed

37
00:02:01,280 --> 00:02:03,520
here including surveillance whether it

38
00:02:03,520 --> 00:02:06,000
is authoritarian surveillance but also

39
00:02:06,000 --> 00:02:08,560
surveillance capitalism for example

40
00:02:08,560 --> 00:02:10,399
people are also very concerned about

41
00:02:10,399 --> 00:02:13,040
facial recognition technology artificial

42
00:02:13,040 --> 00:02:15,040
intelligence in general

43
00:02:15,040 --> 00:02:17,920
and so on so it makes a lot of sense for

44
00:02:17,920 --> 00:02:21,120
the two organizations to host this joint

45
00:02:21,120 --> 00:02:23,840
event

46
00:02:24,319 --> 00:02:25,840
just yet

47
00:02:25,840 --> 00:02:27,840
but just to say that we're super excited

48
00:02:27,840 --> 00:02:29,680
to have this partnership as well and all

49
00:02:29,680 --> 00:02:31,440
of the issues you just talked about are

50
00:02:31,440 --> 00:02:32,800
the same things that we're talking about

51
00:02:32,800 --> 00:02:34,959
here and we're even more excited to be

52
00:02:34,959 --> 00:02:37,040
able to partner together to bring common

53
00:02:37,040 --> 00:02:39,120
programming on many of those topics

54
00:02:39,120 --> 00:02:40,720
themselves i want to make sure that i

55
00:02:40,720 --> 00:02:42,560
don't waste any more of our time and

56
00:02:42,560 --> 00:02:45,200
bring on stage with us we're very lucky

57
00:02:45,200 --> 00:02:47,440
to be joined by the senior director at

58
00:02:47,440 --> 00:02:49,360
the white house for democracy and human

59
00:02:49,360 --> 00:02:51,360
rights and a special assistant to the

60
00:02:51,360 --> 00:02:53,280
president rob berschinsky who's going to

61
00:02:53,280 --> 00:02:55,120
come up and share some remarks before we

62
00:02:55,120 --> 00:02:56,959
get to the main event of the secretary

63
00:02:56,959 --> 00:03:01,480
of state and maria raisa rob welcome rob

64
00:03:06,080 --> 00:03:08,000
hi everybody i feel like that was uh

65
00:03:08,000 --> 00:03:09,680
kind of the equivalent of what we've all

66
00:03:09,680 --> 00:03:11,440
experienced in terms of giving our

67
00:03:11,440 --> 00:03:13,200
speech on zoom with the with the mute

68
00:03:13,200 --> 00:03:16,959
button still on so uh thanks thanks rose

69
00:03:16,959 --> 00:03:18,720
uh thanks melissa if you're still out

70
00:03:18,720 --> 00:03:21,280
there and to uh everybody at rightscon

71
00:03:21,280 --> 00:03:23,840
uh and thanks to dfr lab for putting on

72
00:03:23,840 --> 00:03:25,760
uh this session and for the opportunity

73
00:03:25,760 --> 00:03:29,120
to join you uh to introduce uh

74
00:03:29,120 --> 00:03:31,680
secretary of state anthony blinken and

75
00:03:31,680 --> 00:03:34,799
maria raisa it's been a real pleasure to

76
00:03:34,799 --> 00:03:36,720
have spent the last two days

77
00:03:36,720 --> 00:03:38,319
participating in

78
00:03:38,319 --> 00:03:40,400
discussions at the forefront of

79
00:03:40,400 --> 00:03:42,959
democracy and human rights and i say

80
00:03:42,959 --> 00:03:46,319
that really with everyone here in mind

81
00:03:46,319 --> 00:03:48,400
but particularly with respect to those

82
00:03:48,400 --> 00:03:50,400
truly on the front lines

83
00:03:50,400 --> 00:03:51,920
who have felt the impact for the

84
00:03:51,920 --> 00:03:54,560
struggle for human rights and democracy

85
00:03:54,560 --> 00:03:56,400
in deeply personal ways

86
00:03:56,400 --> 00:03:58,959
these are women like lena hethul and

87
00:03:58,959 --> 00:04:01,200
kareem khanimba someone i had the chance

88
00:04:01,200 --> 00:04:02,799
to speak in depth with a couple of

89
00:04:02,799 --> 00:04:05,040
nights ago and also the woman that we'll

90
00:04:05,040 --> 00:04:07,840
hear from shortly maria raisa

91
00:04:07,840 --> 00:04:09,439
before we turn to that interview i want

92
00:04:09,439 --> 00:04:12,400
to take a few moments to reflect on what

93
00:04:12,400 --> 00:04:14,640
president biden and so many of you both

94
00:04:14,640 --> 00:04:16,320
in the room and at home know is a key

95
00:04:16,320 --> 00:04:18,079
challenge of our time

96
00:04:18,079 --> 00:04:20,238
demonstrating that democracy rather than

97
00:04:20,238 --> 00:04:21,600
autocracy

98
00:04:21,600 --> 00:04:24,240
is best poised to deliver for its

99
00:04:24,240 --> 00:04:26,160
citizens

100
00:04:26,160 --> 00:04:29,120
in december as i hope most in the room

101
00:04:29,120 --> 00:04:32,240
know president biden hosted 100

102
00:04:32,240 --> 00:04:34,240
governmental leaders democratic

103
00:04:34,240 --> 00:04:36,240
opposition figures

104
00:04:36,240 --> 00:04:38,960
activists and business and civil society

105
00:04:38,960 --> 00:04:41,120
leaders from around the world in what we

106
00:04:41,120 --> 00:04:44,240
termed the first summit for democracy

107
00:04:44,240 --> 00:04:46,639
both secretary blinken and maria raisa

108
00:04:46,639 --> 00:04:49,360
spoke at the summit on a panel focused

109
00:04:49,360 --> 00:04:52,880
on media freedom and sustainability

110
00:04:52,880 --> 00:04:54,960
and that issue alone reflects the

111
00:04:54,960 --> 00:04:57,199
ramifications that technology has had on

112
00:04:57,199 --> 00:04:59,199
the world around us

113
00:04:59,199 --> 00:05:01,600
a free media is of course

114
00:05:01,600 --> 00:05:03,280
the bedrock of

115
00:05:03,280 --> 00:05:06,160
pluralistic discourse and a healthy

116
00:05:06,160 --> 00:05:07,440
democratic

117
00:05:07,440 --> 00:05:10,160
society but in the digital age as many

118
00:05:10,160 --> 00:05:12,240
of you also know

119
00:05:12,240 --> 00:05:14,880
has fundamentally altered the business

120
00:05:14,880 --> 00:05:17,520
model that has sustained and enabled

121
00:05:17,520 --> 00:05:19,280
independent journalism

122
00:05:19,280 --> 00:05:21,759
now for decades

123
00:05:21,759 --> 00:05:24,160
one recent study suggests that the move

124
00:05:24,160 --> 00:05:27,039
to digital advertising alone eliminated

125
00:05:27,039 --> 00:05:29,919
nearly 24 billion dollars in annual

126
00:05:29,919 --> 00:05:32,320
advertising revenue for public interest

127
00:05:32,320 --> 00:05:37,199
media between 2017 and last year 2021.

128
00:05:37,199 --> 00:05:39,440
the economic vulnerability of media has

129
00:05:39,440 --> 00:05:42,000
resulted in its capture and closure

130
00:05:42,000 --> 00:05:43,680
around the world

131
00:05:43,680 --> 00:05:45,440
and this trend has of course been

132
00:05:45,440 --> 00:05:47,280
further compounded by governments who

133
00:05:47,280 --> 00:05:48,880
seek to silence

134
00:05:48,880 --> 00:05:50,479
critical voices through internet

135
00:05:50,479 --> 00:05:52,400
shutdown censorship

136
00:05:52,400 --> 00:05:54,720
digital harassment and political and

137
00:05:54,720 --> 00:05:57,759
regulatory pressure that incentivizes

138
00:05:57,759 --> 00:06:01,440
acquiescence or leads to media capture

139
00:06:01,440 --> 00:06:03,039
at the same time

140
00:06:03,039 --> 00:06:04,960
digital technologies have enabled

141
00:06:04,960 --> 00:06:07,280
individuals groups and governments to

142
00:06:07,280 --> 00:06:09,759
create disseminate and amplify

143
00:06:09,759 --> 00:06:12,479
manipulated information for their own

144
00:06:12,479 --> 00:06:14,800
political ideological and commercial

145
00:06:14,800 --> 00:06:16,160
interests

146
00:06:16,160 --> 00:06:18,720
so now we're at a point in time where

147
00:06:18,720 --> 00:06:21,360
the costs of producing high quality

148
00:06:21,360 --> 00:06:23,680
journalism are high while the costs of

149
00:06:23,680 --> 00:06:26,080
disseminating false information and

150
00:06:26,080 --> 00:06:28,479
silencing critical voices like the one

151
00:06:28,479 --> 00:06:30,639
we'll hear from shortly are relatively

152
00:06:30,639 --> 00:06:31,600
low

153
00:06:31,600 --> 00:06:32,960
and communities around the world are

154
00:06:32,960 --> 00:06:34,639
being impacted by this every day not

155
00:06:34,639 --> 00:06:37,280
least in the united states where

156
00:06:37,280 --> 00:06:39,440
an estimated quarter of newspapers have

157
00:06:39,440 --> 00:06:41,840
closed in just the last 15 years and

158
00:06:41,840 --> 00:06:43,840
that means fewer local

159
00:06:43,840 --> 00:06:47,759
trusted voices informing our debate

160
00:06:47,759 --> 00:06:51,280
so all of us joining in the 360 os and

161
00:06:51,280 --> 00:06:52,880
and in reitzcon

162
00:06:52,880 --> 00:06:54,800
are keenly aware of the human rights

163
00:06:54,800 --> 00:06:55,840
impacts

164
00:06:55,840 --> 00:06:57,680
of this and other technology-enabled

165
00:06:57,680 --> 00:06:59,039
challenges

166
00:06:59,039 --> 00:07:00,560
and while this could be a moment of

167
00:07:00,560 --> 00:07:01,680
despair

168
00:07:01,680 --> 00:07:04,080
the breadth of debate discussion and

169
00:07:04,080 --> 00:07:06,800
participation at events like this

170
00:07:06,800 --> 00:07:08,960
reflects another new trend

171
00:07:08,960 --> 00:07:10,960
one where governments and activists and

172
00:07:10,960 --> 00:07:12,560
companies are increasingly working

173
00:07:12,560 --> 00:07:13,919
together

174
00:07:13,919 --> 00:07:15,599
trying to break down their silos to

175
00:07:15,599 --> 00:07:17,680
productively design for and mitigate the

176
00:07:17,680 --> 00:07:20,160
risks from new technologies

177
00:07:20,160 --> 00:07:22,080
and we know authoritarian governments

178
00:07:22,080 --> 00:07:23,840
and other actors will continue to

179
00:07:23,840 --> 00:07:26,639
develop and abuse technologies for their

180
00:07:26,639 --> 00:07:29,680
own political and financial benefit

181
00:07:29,680 --> 00:07:31,759
we know they seek to rewrite the rules

182
00:07:31,759 --> 00:07:33,759
of the international system and the

183
00:07:33,759 --> 00:07:36,479
norms that govern technology

184
00:07:36,479 --> 00:07:38,560
so that's why the biden administration

185
00:07:38,560 --> 00:07:41,039
is driving an agenda in which critical

186
00:07:41,039 --> 00:07:43,440
and emerging technologies work for and

187
00:07:43,440 --> 00:07:44,720
not against

188
00:07:44,720 --> 00:07:46,960
democratic societies

189
00:07:46,960 --> 00:07:48,800
to give one example

190
00:07:48,800 --> 00:07:50,400
two months ago the united states

191
00:07:50,400 --> 00:07:53,039
launched with 60 of our partners around

192
00:07:53,039 --> 00:07:55,360
the world the declaration for the future

193
00:07:55,360 --> 00:07:56,720
of the internet

194
00:07:56,720 --> 00:07:58,400
is a political commitment

195
00:07:58,400 --> 00:08:00,639
among declaration partners to advance a

196
00:08:00,639 --> 00:08:02,800
positive vision for the internet and

197
00:08:02,800 --> 00:08:05,919
digital technologies

198
00:08:06,080 --> 00:08:07,759
we're backing our political commitment

199
00:08:07,759 --> 00:08:10,080
with its expanded investments to support

200
00:08:10,080 --> 00:08:12,160
internet freedom as well as digital

201
00:08:12,160 --> 00:08:14,479
safety and security for targeted groups

202
00:08:14,479 --> 00:08:16,879
while improving cyber security

203
00:08:16,879 --> 00:08:19,360
and in parallel under the auspices of

204
00:08:19,360 --> 00:08:21,759
the summit for democracy we've launched

205
00:08:21,759 --> 00:08:23,919
hundreds of millions of new dollars in

206
00:08:23,919 --> 00:08:26,240
programming to expand our support for

207
00:08:26,240 --> 00:08:28,400
free and independent media to fight

208
00:08:28,400 --> 00:08:29,840
corruption

209
00:08:29,840 --> 00:08:32,159
to bolster democratic reformers and

210
00:08:32,159 --> 00:08:35,440
defend free and fair election processes

211
00:08:35,440 --> 00:08:37,279
and in the wake of russia's

212
00:08:37,279 --> 00:08:39,599
aggression against ukraine we further

213
00:08:39,599 --> 00:08:42,159
expanded our investments in europe and

214
00:08:42,159 --> 00:08:45,600
eurasia in in these thematic areas

215
00:08:45,600 --> 00:08:47,279
we're also working to more effectively

216
00:08:47,279 --> 00:08:48,880
hold to account those who abuse

217
00:08:48,880 --> 00:08:51,440
technology to unlawfully surveil and

218
00:08:51,440 --> 00:08:53,360
harass human rights defenders

219
00:08:53,360 --> 00:08:55,680
journalists and opposition leaders just

220
00:08:55,680 --> 00:08:58,560
as melissa was mentioning in the intro

221
00:08:58,560 --> 00:09:00,000
in terms of the discussion at wright's

222
00:09:00,000 --> 00:09:01,040
con

223
00:09:01,040 --> 00:09:03,839
yesterday panelists stood on this stage

224
00:09:03,839 --> 00:09:06,240
and detailed harrowing accounts of being

225
00:09:06,240 --> 00:09:08,720
targeted via commercial spyware

226
00:09:08,720 --> 00:09:11,839
technology among other forms of what we

227
00:09:11,839 --> 00:09:13,440
in the us government are increasingly

228
00:09:13,440 --> 00:09:16,800
referring to as transnational repression

229
00:09:16,800 --> 00:09:18,959
the united states views the unlawful or

230
00:09:18,959 --> 00:09:20,720
inappropriate use of this technology as

231
00:09:20,720 --> 00:09:22,720
a national security issue

232
00:09:22,720 --> 00:09:24,640
so in october of last year we updated

233
00:09:24,640 --> 00:09:27,279
our export control rules governing items

234
00:09:27,279 --> 00:09:29,040
that can be used for malicious cyber

235
00:09:29,040 --> 00:09:30,480
activities

236
00:09:30,480 --> 00:09:32,480
and then in november we added four

237
00:09:32,480 --> 00:09:34,000
foreign companies

238
00:09:34,000 --> 00:09:36,560
including but not limited to nso group

239
00:09:36,560 --> 00:09:38,560
to the department of commerce's entity

240
00:09:38,560 --> 00:09:39,440
list

241
00:09:39,440 --> 00:09:41,120
based on evidence that these firms

242
00:09:41,120 --> 00:09:43,680
developed and supplied spyware to

243
00:09:43,680 --> 00:09:45,440
foreign governments that then used the

244
00:09:45,440 --> 00:09:47,920
tools provided to maliciously target

245
00:09:47,920 --> 00:09:49,920
government officials journalists

246
00:09:49,920 --> 00:09:52,399
business people activists and embassy

247
00:09:52,399 --> 00:09:53,440
workers

248
00:09:53,440 --> 00:09:55,360
and we intend to do much more in this

249
00:09:55,360 --> 00:09:56,880
space using all the tools at our

250
00:09:56,880 --> 00:09:58,480
disposal

251
00:09:58,480 --> 00:10:00,160
at the same time

252
00:10:00,160 --> 00:10:01,760
we're placing renewed emphasis on

253
00:10:01,760 --> 00:10:04,079
supporting multi-stakeholder initiatives

254
00:10:04,079 --> 00:10:05,920
like the freedom online coalition and

255
00:10:05,920 --> 00:10:09,760
the oscd's work on reinforcing democracy

256
00:10:09,760 --> 00:10:11,279
just over one year ago we joined the

257
00:10:11,279 --> 00:10:13,440
christchurch call to eliminate terrorist

258
00:10:13,440 --> 00:10:16,079
and violent extremist content online

259
00:10:16,079 --> 00:10:17,600
and then in november we announced our

260
00:10:17,600 --> 00:10:19,519
support for the paris call for trust and

261
00:10:19,519 --> 00:10:21,920
security and cyberspace

262
00:10:21,920 --> 00:10:23,680
and we're working also with key allies

263
00:10:23,680 --> 00:10:25,920
and partners on new initiatives like the

264
00:10:25,920 --> 00:10:28,560
global partnership to for action to end

265
00:10:28,560 --> 00:10:30,800
online harassment and abuse

266
00:10:30,800 --> 00:10:32,959
and as those in here in brussels know

267
00:10:32,959 --> 00:10:35,120
well the u.s eu trade and technology

268
00:10:35,120 --> 00:10:37,519
council

269
00:10:38,079 --> 00:10:40,320
yet we know that no single commitment

270
00:10:40,320 --> 00:10:42,480
program or action is going to resolve

271
00:10:42,480 --> 00:10:43,680
all the challenges that we've been

272
00:10:43,680 --> 00:10:45,279
discussing over the course the last few

273
00:10:45,279 --> 00:10:46,800
days and that we'll hear momentarily

274
00:10:46,800 --> 00:10:49,040
from the u.s secretary of state

275
00:10:49,040 --> 00:10:50,720
russia's aggression in ukraine

276
00:10:50,720 --> 00:10:52,560
underscores the importance of taking a

277
00:10:52,560 --> 00:10:55,040
holistic approach to continuing threats

278
00:10:55,040 --> 00:10:58,560
to democracy diplomatically militarily

279
00:10:58,560 --> 00:11:00,480
economically and in the information

280
00:11:00,480 --> 00:11:01,839
realm

281
00:11:01,839 --> 00:11:03,839
but by working together by what doing

282
00:11:03,839 --> 00:11:05,760
exactly what all of you are here doing

283
00:11:05,760 --> 00:11:06,720
today

284
00:11:06,720 --> 00:11:09,600
governments advocates researchers and

285
00:11:09,600 --> 00:11:11,279
the private sector together across

286
00:11:11,279 --> 00:11:13,600
disciplines regions and responsibilities

287
00:11:13,600 --> 00:11:16,000
we can and we are driving change that's

288
00:11:16,000 --> 00:11:18,160
going to prove to be asymmetrically

289
00:11:18,160 --> 00:11:21,440
advantageous for democracies

290
00:11:21,440 --> 00:11:23,040
we're pursuing efforts to close the gap

291
00:11:23,040 --> 00:11:25,120
in digital access and driving innovation

292
00:11:25,120 --> 00:11:26,560
in ways that are going to foster

293
00:11:26,560 --> 00:11:29,120
inclusion equity and accountability and

294
00:11:29,120 --> 00:11:30,800
support human rights rather than

295
00:11:30,800 --> 00:11:32,959
undermining them

296
00:11:32,959 --> 00:11:35,200
so momentarily secretary blinken will

297
00:11:35,200 --> 00:11:37,040
provide more on the breadth of efforts

298
00:11:37,040 --> 00:11:38,880
that the u.s is taking to advance this

299
00:11:38,880 --> 00:11:42,240
agenda in his interview with maria raisa

300
00:11:42,240 --> 00:11:44,720
maria and her team at rappler and so

301
00:11:44,720 --> 00:11:46,399
many other journalists human rights

302
00:11:46,399 --> 00:11:48,800
defenders and activists including many

303
00:11:48,800 --> 00:11:51,839
of you here in brussels and online

304
00:11:51,839 --> 00:11:53,680
have demonstrated courage and commitment

305
00:11:53,680 --> 00:11:55,440
against the global tide of democratic

306
00:11:55,440 --> 00:11:57,040
backsliding

307
00:11:57,040 --> 00:11:58,639
so with that i'm very pleased to

308
00:11:58,639 --> 00:12:01,120
announce a woman who epitomizes

309
00:12:01,120 --> 00:12:03,279
courage and conviction nobel peace

310
00:12:03,279 --> 00:12:05,360
prize-winning journalist maria raisa in

311
00:12:05,360 --> 00:12:06,959
conversation with the u.s secretary of

312
00:12:06,959 --> 00:12:11,160
state tony blinken thank you

313
00:12:14,079 --> 00:12:15,839
hello everybody thank you so much for

314
00:12:15,839 --> 00:12:17,360
joining us i'm maria ressa from the

315
00:12:17,360 --> 00:12:19,440
philippine sport and honor to have u.s

316
00:12:19,440 --> 00:12:21,440
secretary of state anthony blinken with

317
00:12:21,440 --> 00:12:24,320
us today at a crucial moment for all of

318
00:12:24,320 --> 00:12:26,160
us working

319
00:12:26,160 --> 00:12:27,920
for a better digital rights world

320
00:12:27,920 --> 00:12:30,000
secretary blinken thank you for joining

321
00:12:30,000 --> 00:12:32,320
us maria great to be with you and great

322
00:12:32,320 --> 00:12:34,880
to be with everyone um

323
00:12:34,880 --> 00:12:35,920
this is

324
00:12:35,920 --> 00:12:38,000
uh really a pleasure for me i'm i'm

325
00:12:38,000 --> 00:12:39,200
thrilled to be

326
00:12:39,200 --> 00:12:42,399
uh hosted by uh ricecon to be talking to

327
00:12:42,399 --> 00:12:44,959
you i want to say greetings to everyone

328
00:12:44,959 --> 00:12:48,160
uh from the 360 open summit and from

329
00:12:48,160 --> 00:12:49,440
around the world

330
00:12:49,440 --> 00:12:51,839
uh who is in one way or another um

331
00:12:51,839 --> 00:12:54,079
logged on tuned in uh and joining this

332
00:12:54,079 --> 00:12:55,200
conversation

333
00:12:55,200 --> 00:12:56,399
um

334
00:12:56,399 --> 00:12:59,360
you know it's so important from our

335
00:12:59,360 --> 00:13:01,200
perspective that

336
00:13:01,200 --> 00:13:02,959
the united states

337
00:13:02,959 --> 00:13:04,959
like-minded governments

338
00:13:04,959 --> 00:13:08,160
uh but especially with civil society uh

339
00:13:08,160 --> 00:13:10,959
with ngos with think tanks with the

340
00:13:10,959 --> 00:13:12,399
private sector

341
00:13:12,399 --> 00:13:13,200
um

342
00:13:13,200 --> 00:13:16,079
work to protect human rights online

343
00:13:16,079 --> 00:13:18,800
uh work to demonstrate that um our

344
00:13:18,800 --> 00:13:21,120
democracies can deliver for people as we

345
00:13:21,120 --> 00:13:24,079
navigate this extraordinary digital

346
00:13:24,079 --> 00:13:26,160
transformation that is having an impact

347
00:13:26,160 --> 00:13:28,880
on the lives of virtually everyone

348
00:13:28,880 --> 00:13:30,800
on this planet one thing i wanted to say

349
00:13:30,800 --> 00:13:32,399
at the outset before we get into a

350
00:13:32,399 --> 00:13:34,639
conversation is i am very pleased to

351
00:13:34,639 --> 00:13:36,880
announce that for the first time uh the

352
00:13:36,880 --> 00:13:39,040
united states will become chair of the

353
00:13:39,040 --> 00:13:42,000
freedom online coalition um in uh in

354
00:13:42,000 --> 00:13:44,399
2023 uh we want to strengthen the

355
00:13:44,399 --> 00:13:46,959
coalition we want to bring uh more

356
00:13:46,959 --> 00:13:48,399
members on board

357
00:13:48,399 --> 00:13:51,279
we want to make it a center of action uh

358
00:13:51,279 --> 00:13:53,680
for ensuring um a free and open digital

359
00:13:53,680 --> 00:13:54,560
future

360
00:13:54,560 --> 00:13:55,360
um

361
00:13:55,360 --> 00:13:57,279
and this in part is going to be building

362
00:13:57,279 --> 00:14:01,120
on canada's terrific work as the current

363
00:14:01,120 --> 00:14:01,839
and chair

364
00:14:01,839 --> 00:14:03,680
really trying to carry it forward so i'm

365
00:14:03,680 --> 00:14:05,600
really pleased to do that uh to be able

366
00:14:05,600 --> 00:14:07,279
to announce that and maria it's great to

367
00:14:07,279 --> 00:14:10,639
be with you um you have been you are

368
00:14:10,639 --> 00:14:12,720
an extraordinarily uh courageous

369
00:14:12,720 --> 00:14:13,680
champion

370
00:14:13,680 --> 00:14:16,800
of um freedom of speech freedom of the

371
00:14:16,800 --> 00:14:19,760
pre of press and media and

372
00:14:19,760 --> 00:14:23,040
freedom uh for a um a digital future

373
00:14:23,040 --> 00:14:25,600
that we all want uh and uh we hope to

374
00:14:25,600 --> 00:14:27,760
build together so thank you for being uh

375
00:14:27,760 --> 00:14:29,600
willing to have this conversation today

376
00:14:29,600 --> 00:14:31,600
well you know that that's really great

377
00:14:31,600 --> 00:14:34,240
to hear from you mr secretary

378
00:14:34,240 --> 00:14:36,720
exactly at this moment in time when you

379
00:14:36,720 --> 00:14:38,480
know it seems

380
00:14:38,480 --> 00:14:41,120
at times hopeless and you never want to

381
00:14:41,120 --> 00:14:43,120
be hopeless right so let me ask you

382
00:14:43,120 --> 00:14:45,839
you've been very outspoken about

383
00:14:45,839 --> 00:14:48,720
the the way digital authoritarians have

384
00:14:48,720 --> 00:14:51,920
used tech to abuse human rights you know

385
00:14:51,920 --> 00:14:54,240
a growing trend people like us on the

386
00:14:54,240 --> 00:14:56,480
front lines increasingly

387
00:14:56,480 --> 00:14:58,399
defenseless i mean what have you seen

388
00:14:58,399 --> 00:15:00,800
globally and and what can you do about

389
00:15:00,800 --> 00:15:01,760
it

390
00:15:01,760 --> 00:15:03,519
so you're right unfortunately that's

391
00:15:03,519 --> 00:15:06,560
exactly what we're seeing look i think

392
00:15:06,560 --> 00:15:08,480
as in so many ways when

393
00:15:08,480 --> 00:15:10,320
we saw the emergence of a lot of this

394
00:15:10,320 --> 00:15:11,519
technology

395
00:15:11,519 --> 00:15:13,600
starting mostly in the 1990s the early

396
00:15:13,600 --> 00:15:15,760
2000s i think there was great hope

397
00:15:15,760 --> 00:15:17,279
uh that it would be

398
00:15:17,279 --> 00:15:19,600
inexorably a force for openness

399
00:15:19,600 --> 00:15:22,240
transparency freedom and of course

400
00:15:22,240 --> 00:15:24,240
in many ways it is but

401
00:15:24,240 --> 00:15:25,839
we're also seeing of course the abuse of

402
00:15:25,839 --> 00:15:27,680
this technology in in various ways

403
00:15:27,680 --> 00:15:29,519
including by repressive governments

404
00:15:29,519 --> 00:15:31,920
trying to control populations to stifle

405
00:15:31,920 --> 00:15:35,279
dissent uh to surveil and censor uh we

406
00:15:35,279 --> 00:15:38,639
see that of course in um uh in the prc

407
00:15:38,639 --> 00:15:40,720
uh with technology being used for

408
00:15:40,720 --> 00:15:42,480
example for mass surveillance including

409
00:15:42,480 --> 00:15:44,079
uh of the uh the uyghurs and other

410
00:15:44,079 --> 00:15:45,199
minorities

411
00:15:45,199 --> 00:15:48,480
so the question is what is to be done uh

412
00:15:48,480 --> 00:15:49,759
what do we do about it and there are a

413
00:15:49,759 --> 00:15:51,120
number of things that we need to do and

414
00:15:51,120 --> 00:15:52,720
in fact that we are doing

415
00:15:52,720 --> 00:15:55,519
one is to start by calling things out uh

416
00:15:55,519 --> 00:15:56,560
that's the

417
00:15:56,560 --> 00:15:58,720
often the basis for everything we have

418
00:15:58,720 --> 00:16:01,199
to call out the abusive technology uh

419
00:16:01,199 --> 00:16:03,680
including digital authoritarianism

420
00:16:03,680 --> 00:16:05,120
um second

421
00:16:05,120 --> 00:16:07,040
as i mentioned uh we're gonna be taking

422
00:16:07,040 --> 00:16:08,240
on the chairmanship of the freedom

423
00:16:08,240 --> 00:16:09,920
online coalition we're working to

424
00:16:09,920 --> 00:16:11,680
strengthen it and this is an important

425
00:16:11,680 --> 00:16:14,480
vehicle to try to protect and advance

426
00:16:14,480 --> 00:16:16,399
internet freedom and to push back

427
00:16:16,399 --> 00:16:19,759
against digital authoritarianism

428
00:16:19,759 --> 00:16:21,600
very practically speaking

429
00:16:21,600 --> 00:16:23,360
there are a number of things that we

430
00:16:23,360 --> 00:16:26,000
countries ngos and others are doing to

431
00:16:26,000 --> 00:16:27,759
for example get anti-censorship

432
00:16:27,759 --> 00:16:28,959
technology

433
00:16:28,959 --> 00:16:31,519
into the hands of people who need it so

434
00:16:31,519 --> 00:16:33,040
that they have the tools

435
00:16:33,040 --> 00:16:35,360
to push back against the misuse of

436
00:16:35,360 --> 00:16:36,480
technology

437
00:16:36,480 --> 00:16:38,560
in an authoritarian way

438
00:16:38,560 --> 00:16:41,040
we set up a multinational fund

439
00:16:41,040 --> 00:16:42,240
to do that

440
00:16:42,240 --> 00:16:43,680
at the summit for democracy that we

441
00:16:43,680 --> 00:16:45,279
hosted last year

442
00:16:45,279 --> 00:16:47,440
and then for example

443
00:16:47,440 --> 00:16:49,600
putting export controls on surveillance

444
00:16:49,600 --> 00:16:51,600
technology to make sure that technology

445
00:16:51,600 --> 00:16:52,639
that we and other countries are

446
00:16:52,639 --> 00:16:54,560
producing that could have a dual use and

447
00:16:54,560 --> 00:16:56,160
be misused

448
00:16:56,160 --> 00:16:58,320
for the surveillance of populations that

449
00:16:58,320 --> 00:17:00,480
doesn't get into the wrong hands that

450
00:17:00,480 --> 00:17:02,959
takes working together one country alone

451
00:17:02,959 --> 00:17:04,959
can't do it uh and in fact governments

452
00:17:04,959 --> 00:17:07,679
alone can't uh effectively do it we need

453
00:17:07,679 --> 00:17:09,119
to build these coalitions to make sure

454
00:17:09,119 --> 00:17:12,240
that we identify uh where technology

455
00:17:12,240 --> 00:17:14,319
should not go because it's being misused

456
00:17:14,319 --> 00:17:16,000
and then work to uh together to make

457
00:17:16,000 --> 00:17:18,559
sure that it doesn't get there

458
00:17:18,559 --> 00:17:20,880
no that i i agree with working together

459
00:17:20,880 --> 00:17:22,880
mr secretary you know that early on i

460
00:17:22,880 --> 00:17:25,199
said that uh the tech platforms that

461
00:17:25,199 --> 00:17:27,679
took control uh became the gatekeepers

462
00:17:27,679 --> 00:17:29,520
from journalists abdicated

463
00:17:29,520 --> 00:17:31,360
responsibility for protecting the public

464
00:17:31,360 --> 00:17:34,080
sphere and in some ways it's taken so

465
00:17:34,080 --> 00:17:36,080
long to get government regulations that

466
00:17:36,080 --> 00:17:38,720
in a way governments have also abdicated

467
00:17:38,720 --> 00:17:40,559
responsibly we're just starting to see

468
00:17:40,559 --> 00:17:42,799
the beginning of this rollout in the

469
00:17:42,799 --> 00:17:45,679
spring from the eu right and yet we know

470
00:17:45,679 --> 00:17:47,919
the impact of disinformation

471
00:17:47,919 --> 00:17:50,559
um the philippines we have seen

472
00:17:50,559 --> 00:17:53,120
disinformation repeatedly

473
00:17:53,120 --> 00:17:55,120
change our history it's that milan

474
00:17:55,120 --> 00:17:56,880
kundera quote you know the struggle of

475
00:17:56,880 --> 00:17:58,799
man against power well we've forgotten

476
00:17:58,799 --> 00:18:01,360
really quickly and this information is

477
00:18:01,360 --> 00:18:05,360
being used to manipulate our biology uh

478
00:18:05,360 --> 00:18:08,240
where do you see what can you do about

479
00:18:08,240 --> 00:18:10,240
this and how do we

480
00:18:10,240 --> 00:18:12,240
fight back given that there are more

481
00:18:12,240 --> 00:18:14,960
than 30 elections this year and you

482
00:18:14,960 --> 00:18:17,600
can't have integrity of elections if you

483
00:18:17,600 --> 00:18:20,799
don't have integrity of facts

484
00:18:20,799 --> 00:18:23,039
couldn't agree with you more and

485
00:18:23,039 --> 00:18:24,559
you know this has been one of the other

486
00:18:24,559 --> 00:18:26,320
changes that we thought

487
00:18:26,320 --> 00:18:29,039
was going to be totally for the good uh

488
00:18:29,039 --> 00:18:30,960
but of course that hasn't been the case

489
00:18:30,960 --> 00:18:33,360
in the united states

490
00:18:33,360 --> 00:18:34,960
a few decades ago

491
00:18:34,960 --> 00:18:35,919
uh

492
00:18:35,919 --> 00:18:38,720
information that most people used on a

493
00:18:38,720 --> 00:18:40,400
in their daily lives there was a common

494
00:18:40,400 --> 00:18:41,760
foundation

495
00:18:41,760 --> 00:18:43,760
because there were actually a fairly

496
00:18:43,760 --> 00:18:45,919
limited number of sources of the

497
00:18:45,919 --> 00:18:47,840
information that people got we had three

498
00:18:47,840 --> 00:18:50,080
television networks back then uh we

499
00:18:50,080 --> 00:18:51,600
didn't have cable we didn't have an

500
00:18:51,600 --> 00:18:53,600
internet uh we didn't have talk radio et

501
00:18:53,600 --> 00:18:55,840
cetera et cetera

502
00:18:55,840 --> 00:18:57,520
and the hope of course was that the

503
00:18:57,520 --> 00:18:59,280
democratization

504
00:18:59,280 --> 00:19:02,559
of information uh would be uh

505
00:19:02,559 --> 00:19:05,360
a good thing overall and fundamentally i

506
00:19:05,360 --> 00:19:07,280
believe that's still the case but

507
00:19:07,280 --> 00:19:08,960
as a result of this as a result of this

508
00:19:08,960 --> 00:19:10,480
disaggregation

509
00:19:10,480 --> 00:19:12,160
you've lost exactly what you said which

510
00:19:12,160 --> 00:19:13,760
are sort of the trusted

511
00:19:13,760 --> 00:19:15,440
uh mediators

512
00:19:15,440 --> 00:19:17,760
who can make sure that information to

513
00:19:17,760 --> 00:19:20,080
the greatest extent possible is actually

514
00:19:20,080 --> 00:19:22,880
backed up by the by the facts

515
00:19:22,880 --> 00:19:23,679
and

516
00:19:23,679 --> 00:19:25,919
at the same time the technology itself

517
00:19:25,919 --> 00:19:27,840
uh has allowed uh

518
00:19:27,840 --> 00:19:29,679
the abuse uh and the spreading of

519
00:19:29,679 --> 00:19:31,840
misinformation and disinformation in

520
00:19:31,840 --> 00:19:33,360
ways that we probably didn't fully

521
00:19:33,360 --> 00:19:36,880
anticipate uh or imagine so

522
00:19:36,880 --> 00:19:38,480
we see authoritarian governments using

523
00:19:38,480 --> 00:19:40,960
this uh we see it for example right now

524
00:19:40,960 --> 00:19:42,720
in the uh russian aggression against

525
00:19:42,720 --> 00:19:46,320
ukraine we saw it in 2014 uh when russia

526
00:19:46,320 --> 00:19:48,960
initially went at ukraine and was using

527
00:19:48,960 --> 00:19:51,440
information as a weapon of war

528
00:19:51,440 --> 00:19:53,760
so in that particular instance and in

529
00:19:53,760 --> 00:19:55,600
this instance we've actually reversed

530
00:19:55,600 --> 00:19:57,760
this on them precisely by using

531
00:19:57,760 --> 00:20:00,799
information real information uh to call

532
00:20:00,799 --> 00:20:02,960
out what we uh

533
00:20:02,960 --> 00:20:04,960
saw them preparing

534
00:20:04,960 --> 00:20:08,640
and uh and uh and working to do uh and

535
00:20:08,640 --> 00:20:11,120
being able to to do that and to bring to

536
00:20:11,120 --> 00:20:12,159
the world

537
00:20:12,159 --> 00:20:13,840
uh everything that we were seeing about

538
00:20:13,840 --> 00:20:15,840
the the planned russian aggression and

539
00:20:15,840 --> 00:20:17,440
to lay out exactly the steps they were

540
00:20:17,440 --> 00:20:19,039
likely to take

541
00:20:19,039 --> 00:20:21,120
and which unfortunately they did

542
00:20:21,120 --> 00:20:23,280
i think has done um

543
00:20:23,280 --> 00:20:25,520
a profound service to making sure that

544
00:20:25,520 --> 00:20:28,400
um uh credible information is what

545
00:20:28,400 --> 00:20:31,039
carries the day and disinformation

546
00:20:31,039 --> 00:20:33,039
is uh is undermined but there are a

547
00:20:33,039 --> 00:20:34,960
number of things that we can hear again

548
00:20:34,960 --> 00:20:37,679
and we are doing to combat the misuse of

549
00:20:37,679 --> 00:20:40,320
information uh again we start by

550
00:20:40,320 --> 00:20:41,520
exposing it

551
00:20:41,520 --> 00:20:44,000
uh and we sharp we start by sharing the

552
00:20:44,000 --> 00:20:46,159
information that we have

553
00:20:46,159 --> 00:20:47,440
working with others again in a

554
00:20:47,440 --> 00:20:48,960
coordinated way we have at the state

555
00:20:48,960 --> 00:20:50,000
department

556
00:20:50,000 --> 00:20:51,120
uh something called the global

557
00:20:51,120 --> 00:20:53,200
engagement center uh which is focused

558
00:20:53,200 --> 00:20:56,159
intensely on uh finding exposing

559
00:20:56,159 --> 00:20:58,480
disinformation the techniques uh that

560
00:20:58,480 --> 00:21:00,720
are used by those who are propagating it

561
00:21:00,720 --> 00:21:03,360
and in a coordinated way working with

562
00:21:03,360 --> 00:21:05,600
other other countries

563
00:21:05,600 --> 00:21:07,520
pushing back on it and giving people the

564
00:21:07,520 --> 00:21:09,120
tools to do it

565
00:21:09,120 --> 00:21:10,960
it's critical for us that we also build

566
00:21:10,960 --> 00:21:12,480
the capacity of partners around the

567
00:21:12,480 --> 00:21:16,240
world uh both governments but also uh

568
00:21:16,240 --> 00:21:19,760
journalists uh ngos civil society

569
00:21:19,760 --> 00:21:20,720
there are a number of things that we're

570
00:21:20,720 --> 00:21:22,320
doing we have initiatives

571
00:21:22,320 --> 00:21:24,799
to help give people fact checking tools

572
00:21:24,799 --> 00:21:26,400
uh to make sure that the information

573
00:21:26,400 --> 00:21:28,320
that they're they're getting actually is

574
00:21:28,320 --> 00:21:30,240
backed up by the facts and to show when

575
00:21:30,240 --> 00:21:31,200
it's not

576
00:21:31,200 --> 00:21:32,240
um

577
00:21:32,240 --> 00:21:34,000
digital literacy training

578
00:21:34,000 --> 00:21:35,520
which is so critical

579
00:21:35,520 --> 00:21:38,480
um to understanding what people are uh

580
00:21:38,480 --> 00:21:40,799
are consuming and uh being able to

581
00:21:40,799 --> 00:21:43,120
separate the wheat from the chaff the

582
00:21:43,120 --> 00:21:45,280
true from the misinformation and

583
00:21:45,280 --> 00:21:46,799
disinformation

584
00:21:46,799 --> 00:21:48,880
bolstering independent media this is so

585
00:21:48,880 --> 00:21:50,320
critical

586
00:21:50,320 --> 00:21:52,159
the the single best check and balance

587
00:21:52,159 --> 00:21:53,760
against misinformation and

588
00:21:53,760 --> 00:21:55,440
disinformation is

589
00:21:55,440 --> 00:21:57,360
an effective independent media and we

590
00:21:57,360 --> 00:21:59,440
have initiatives to do that including

591
00:21:59,440 --> 00:22:01,520
as appropriate

592
00:22:01,520 --> 00:22:03,919
financing and and other things we see

593
00:22:03,919 --> 00:22:05,360
that there's a

594
00:22:05,360 --> 00:22:08,880
deliberate attack to take down

595
00:22:08,880 --> 00:22:11,039
independent media to take down

596
00:22:11,039 --> 00:22:13,600
ngos that are operating in this space so

597
00:22:13,600 --> 00:22:15,039
we're putting in place protections for

598
00:22:15,039 --> 00:22:17,039
example countries actually try to use

599
00:22:17,039 --> 00:22:19,360
legal means or i should say legal in

600
00:22:19,360 --> 00:22:22,240
quotation marks legal means

601
00:22:22,240 --> 00:22:24,720
through lawsuits as you know very well

602
00:22:24,720 --> 00:22:27,600
and uh through regulatory challenge well

603
00:22:27,600 --> 00:22:30,559
uh we're putting in place uh programs

604
00:22:30,559 --> 00:22:33,600
funding uh to enable people institutions

605
00:22:33,600 --> 00:22:35,600
media organizations to actually push

606
00:22:35,600 --> 00:22:37,520
back on that um

607
00:22:37,520 --> 00:22:40,080
all of these things together are

608
00:22:40,080 --> 00:22:43,120
part of what we need to do and finally

609
00:22:43,120 --> 00:22:44,799
it's so critical

610
00:22:44,799 --> 00:22:46,000
that

611
00:22:46,000 --> 00:22:46,960
we

612
00:22:46,960 --> 00:22:49,120
and you this entire community

613
00:22:49,120 --> 00:22:50,799
work with the platforms

614
00:22:50,799 --> 00:22:53,679
to find ways to more effectively ensure

615
00:22:53,679 --> 00:22:55,520
that they're not being abused

616
00:22:55,520 --> 00:22:57,600
and used as a means of propagating this

617
00:22:57,600 --> 00:22:59,840
information disinformation

618
00:22:59,840 --> 00:23:02,400
of course it's primarily uh on the

619
00:23:02,400 --> 00:23:04,159
platforms themselves to take the steps

620
00:23:04,159 --> 00:23:06,640
necessary to push back against that

621
00:23:06,640 --> 00:23:08,400
i hope very much that we can continue to

622
00:23:08,400 --> 00:23:11,360
do that in a collaborative fashion and

623
00:23:11,360 --> 00:23:13,039
sharing the information what we're

624
00:23:13,039 --> 00:23:14,799
seeing for example with the platforms

625
00:23:14,799 --> 00:23:18,000
we've found that when we've been able to

626
00:23:18,000 --> 00:23:19,280
point them to

627
00:23:19,280 --> 00:23:21,600
malicious actors using the platforms in

628
00:23:21,600 --> 00:23:23,440
abusive ways

629
00:23:23,440 --> 00:23:24,960
they've been responsive in making sure

630
00:23:24,960 --> 00:23:27,039
those actors can't do it but of course

631
00:23:27,039 --> 00:23:28,640
it's a moving target

632
00:23:28,640 --> 00:23:30,480
and for every

633
00:23:30,480 --> 00:23:32,720
every bad actor that you take off

634
00:23:32,720 --> 00:23:35,440
maybe it comes back under another guy's

635
00:23:35,440 --> 00:23:37,039
or something else pops up so we have to

636
00:23:37,039 --> 00:23:40,480
be vigilant we have to be

637
00:23:40,559 --> 00:23:43,039
relentlessly focused on this and i hope

638
00:23:43,039 --> 00:23:44,320
that we can do this in a cooperative

639
00:23:44,320 --> 00:23:45,919
collaborative way

640
00:23:45,919 --> 00:23:47,360
well that's certainly what we're trying

641
00:23:47,360 --> 00:23:49,440
to do but what we've seen in the last

642
00:23:49,440 --> 00:23:52,080
and you mentioned 2014 until now right

643
00:23:52,080 --> 00:23:54,320
uh the disinformation that splintered

644
00:23:54,320 --> 00:23:57,840
reality that allowed russia to invade

645
00:23:57,840 --> 00:24:00,400
to annex crimea and then eight years

646
00:24:00,400 --> 00:24:02,640
later to invade ukraine those

647
00:24:02,640 --> 00:24:04,240
meta-narratives were seated the

648
00:24:04,240 --> 00:24:06,480
platforms were told about it not much

649
00:24:06,480 --> 00:24:08,320
was done and the question of course is

650
00:24:08,320 --> 00:24:10,240
would we be at this place if more was

651
00:24:10,240 --> 00:24:12,320
done right but but i guess this is this

652
00:24:12,320 --> 00:24:14,400
goes to the last the crucial question

653
00:24:14,400 --> 00:24:15,279
which is

654
00:24:15,279 --> 00:24:18,320
we have had impunity in the virtual

655
00:24:18,320 --> 00:24:21,440
world and that impunity

656
00:24:21,440 --> 00:24:24,000
you have a thousand page document from

657
00:24:24,000 --> 00:24:25,919
the senate that that outlines what

658
00:24:25,919 --> 00:24:28,240
russian misinformation did in 2016 in

659
00:24:28,240 --> 00:24:29,919
the united states

660
00:24:29,919 --> 00:24:33,520
that impunity has filtered into the real

661
00:24:33,520 --> 00:24:36,159
world in and really severed the checks

662
00:24:36,159 --> 00:24:38,640
and balances that are there i guess that

663
00:24:38,640 --> 00:24:40,720
and here to quote shoshan azuboff where

664
00:24:40,720 --> 00:24:43,279
she just says we live in one world

665
00:24:43,279 --> 00:24:46,080
and if you don't have rule of law in the

666
00:24:46,080 --> 00:24:48,320
virtual world you know how can you have

667
00:24:48,320 --> 00:24:51,200
rule of law in the real world and this

668
00:24:51,200 --> 00:24:53,840
goes back to what is your democratic

669
00:24:53,840 --> 00:24:55,120
vision i think that's what's been

670
00:24:55,120 --> 00:24:56,880
missing is that we don't have a

671
00:24:56,880 --> 00:24:58,640
democratic vision

672
00:24:58,640 --> 00:25:00,559
uh for the 21st century with this

673
00:25:00,559 --> 00:25:02,720
technology that we have what is it that

674
00:25:02,720 --> 00:25:04,080
that you have

675
00:25:04,080 --> 00:25:05,760
yeah uh maria you're i think you're

676
00:25:05,760 --> 00:25:08,480
exactly right and first let me say look

677
00:25:08,480 --> 00:25:09,440
we've been

678
00:25:09,440 --> 00:25:11,679
awoken to this challenge uh over the

679
00:25:11,679 --> 00:25:13,360
last years and i think for me it

680
00:25:13,360 --> 00:25:16,159
certainly started particularly in 2014

681
00:25:16,159 --> 00:25:17,600
with the initial russian aggression

682
00:25:17,600 --> 00:25:19,520
against ukraine and

683
00:25:19,520 --> 00:25:21,200
the the use of misinformation and

684
00:25:21,200 --> 00:25:22,799
disinformation as

685
00:25:22,799 --> 00:25:24,559
a weapon of war as critical to their

686
00:25:24,559 --> 00:25:26,240
campaign and then of course we saw the

687
00:25:26,240 --> 00:25:28,559
interference in our elections and all of

688
00:25:28,559 --> 00:25:31,760
that has created a i think a an

689
00:25:31,760 --> 00:25:32,960
increasingly

690
00:25:32,960 --> 00:25:34,240
um

691
00:25:34,240 --> 00:25:35,840
greater consciousness

692
00:25:35,840 --> 00:25:37,200
of the challenge and the need to do

693
00:25:37,200 --> 00:25:38,720
something about it but

694
00:25:38,720 --> 00:25:40,320
doing something about it starts with

695
00:25:40,320 --> 00:25:42,880
exactly what you said which is advancing

696
00:25:42,880 --> 00:25:44,400
a positive vision

697
00:25:44,400 --> 00:25:46,559
uh an affirmative vision of what this

698
00:25:46,559 --> 00:25:48,720
future should look like

699
00:25:48,720 --> 00:25:51,440
a vision of an open free

700
00:25:51,440 --> 00:25:52,559
global

701
00:25:52,559 --> 00:25:53,840
interoperable

702
00:25:53,840 --> 00:25:56,880
secure reliable internet one of the ways

703
00:25:56,880 --> 00:25:58,000
we've done that

704
00:25:58,000 --> 00:25:59,760
is with this declaration for the future

705
00:25:59,760 --> 00:26:01,919
of the internet that now some 60

706
00:26:01,919 --> 00:26:04,640
countries have joined onto that actually

707
00:26:04,640 --> 00:26:08,000
lays out what this positive vision is

708
00:26:08,000 --> 00:26:10,159
we're working in concrete ways though

709
00:26:10,159 --> 00:26:12,080
not just to

710
00:26:12,080 --> 00:26:13,520
put out the vision

711
00:26:13,520 --> 00:26:15,760
but to realize it so what are the

712
00:26:15,760 --> 00:26:18,720
concrete steps that that you're taking

713
00:26:18,720 --> 00:26:19,520
so

714
00:26:19,520 --> 00:26:21,039
much of the work that we're doing is to

715
00:26:21,039 --> 00:26:22,400
make sure that

716
00:26:22,400 --> 00:26:25,440
we and other like-minded countries uh

717
00:26:25,440 --> 00:26:26,240
are

718
00:26:26,240 --> 00:26:28,080
at the table when

719
00:26:28,080 --> 00:26:30,240
so many of the rules and norms uh that

720
00:26:30,240 --> 00:26:32,400
are going to uh shape the future of the

721
00:26:32,400 --> 00:26:35,600
internet are being decided um and we're

722
00:26:35,600 --> 00:26:37,440
doing that in a variety of ways we've

723
00:26:37,440 --> 00:26:39,120
come together with the european union

724
00:26:39,120 --> 00:26:40,640
through something we've stood up called

725
00:26:40,640 --> 00:26:42,559
the trade and technology council

726
00:26:42,559 --> 00:26:44,720
to make sure that we're working together

727
00:26:44,720 --> 00:26:46,880
uh to advance

728
00:26:46,880 --> 00:26:48,480
these different norms and standards

729
00:26:48,480 --> 00:26:49,840
there's growing conversions between the

730
00:26:49,840 --> 00:26:51,360
united states and the european union on

731
00:26:51,360 --> 00:26:53,600
this vision for the future now we put

732
00:26:53,600 --> 00:26:54,799
that in practice by bringing our

733
00:26:54,799 --> 00:26:56,640
combined weight together everywhere

734
00:26:56,640 --> 00:26:59,200
these rules and norms are being shaped

735
00:26:59,200 --> 00:27:01,120
we're making sure that we're investing

736
00:27:01,120 --> 00:27:03,120
in our own capacity to do that here at

737
00:27:03,120 --> 00:27:05,200
the state department over just six

738
00:27:05,200 --> 00:27:07,200
months we stood up a new bureau

739
00:27:07,200 --> 00:27:09,919
for cyberspace and digital policy uh we

740
00:27:09,919 --> 00:27:12,640
will soon have an as a senior envoy to

741
00:27:12,640 --> 00:27:14,240
deal with emerging technologies to make

742
00:27:14,240 --> 00:27:15,600
sure that

743
00:27:15,600 --> 00:27:17,200
to the extent values are infused in

744
00:27:17,200 --> 00:27:19,120
technology

745
00:27:19,120 --> 00:27:20,880
there'll be liberal values not illiberal

746
00:27:20,880 --> 00:27:23,039
ones uh and making sure the technology

747
00:27:23,039 --> 00:27:26,080
is used for the good and to advance uh

748
00:27:26,080 --> 00:27:28,640
democracy not to not to undermine it

749
00:27:28,640 --> 00:27:30,799
we've been working to make sure that

750
00:27:30,799 --> 00:27:32,960
after last year's summit for democracy

751
00:27:32,960 --> 00:27:35,039
we make this year a year for action in

752
00:27:35,039 --> 00:27:36,960
terms of implementing many of the

753
00:27:36,960 --> 00:27:39,360
concrete initiatives that were announced

754
00:27:39,360 --> 00:27:40,559
at the summit including some that i

755
00:27:40,559 --> 00:27:42,880
mentioned a short while ago in terms of

756
00:27:42,880 --> 00:27:44,399
supporting independent media giving

757
00:27:44,399 --> 00:27:46,640
people the tools they need to combat

758
00:27:46,640 --> 00:27:48,480
censorship uh making sure that

759
00:27:48,480 --> 00:27:50,880
journalists uh and other organizations

760
00:27:50,880 --> 00:27:53,360
under siege uh can fight back and have

761
00:27:53,360 --> 00:27:56,080
the tools and the means to do so um

762
00:27:56,080 --> 00:27:59,679
we as i mentioned uh have uh initiated a

763
00:27:59,679 --> 00:28:01,120
declaration for the future of the

764
00:28:01,120 --> 00:28:04,000
internet with 60 countries uh so far

765
00:28:04,000 --> 00:28:06,159
making sure that we're all aligned in a

766
00:28:06,159 --> 00:28:08,080
shared vision and trying to advance it

767
00:28:08,080 --> 00:28:09,440
and finally

768
00:28:09,440 --> 00:28:11,440
um

769
00:28:11,440 --> 00:28:13,440
the institutions that are actually doing

770
00:28:13,440 --> 00:28:14,559
this work

771
00:28:14,559 --> 00:28:17,039
that are deciding how all of the the

772
00:28:17,039 --> 00:28:19,120
technology that we share is being used

773
00:28:19,120 --> 00:28:22,080
it's usually important that uh people

774
00:28:22,080 --> 00:28:25,360
who share this vision share these values

775
00:28:25,360 --> 00:28:28,240
are uh running these institutions

776
00:28:28,240 --> 00:28:30,640
there's a usually important election uh

777
00:28:30,640 --> 00:28:32,559
for the uh the head of the um

778
00:28:32,559 --> 00:28:34,799
international telecommunications union

779
00:28:34,799 --> 00:28:37,279
coming up and uh

780
00:28:37,279 --> 00:28:39,120
the candidate we support dorian bogdan

781
00:28:39,120 --> 00:28:41,039
martin is someone

782
00:28:41,039 --> 00:28:42,559
uh a vision

783
00:28:42,559 --> 00:28:46,399
and a value uh who um can help advance

784
00:28:46,399 --> 00:28:48,480
this shared perspective that we have

785
00:28:48,480 --> 00:28:50,159
um so it's one of those one of those

786
00:28:50,159 --> 00:28:52,440
things where probably

787
00:28:52,440 --> 00:28:55,520
99.999 percent of people have no idea uh

788
00:28:55,520 --> 00:28:57,360
what the itu is or how important this

789
00:28:57,360 --> 00:28:59,600
election is but we're very focused on it

790
00:28:59,600 --> 00:29:01,760
and making sure that someone with a

791
00:29:01,760 --> 00:29:04,000
shared vision can drive this forward

792
00:29:04,000 --> 00:29:06,000
last thing i'll say maria is this

793
00:29:06,000 --> 00:29:08,320
i think

794
00:29:08,320 --> 00:29:10,720
everyone present today

795
00:29:10,720 --> 00:29:12,240
um

796
00:29:12,240 --> 00:29:14,080
is at the heart

797
00:29:14,080 --> 00:29:16,320
of this effort

798
00:29:16,320 --> 00:29:18,159
civil society

799
00:29:18,159 --> 00:29:19,760
ngos

800
00:29:19,760 --> 00:29:21,360
the private sector

801
00:29:21,360 --> 00:29:24,080
uh independent media

802
00:29:24,080 --> 00:29:26,559
working together

803
00:29:26,559 --> 00:29:29,440
holding governments to account

804
00:29:29,440 --> 00:29:32,640
uh and then ideally all of us joining

805
00:29:32,640 --> 00:29:33,760
forces

806
00:29:33,760 --> 00:29:35,840
when you put all that together

807
00:29:35,840 --> 00:29:37,919
it's a very powerful force

808
00:29:37,919 --> 00:29:39,600
and it's one that i'm convinced can

809
00:29:39,600 --> 00:29:40,799
carry the day

810
00:29:40,799 --> 00:29:42,159
in making sure that the future of

811
00:29:42,159 --> 00:29:44,240
technology and the future of the

812
00:29:44,240 --> 00:29:45,279
internet

813
00:29:45,279 --> 00:29:47,760
is one that actually advances freedom

814
00:29:47,760 --> 00:29:50,399
uh that advances democratic principles

815
00:29:50,399 --> 00:29:52,799
uh and that makes sure that

816
00:29:52,799 --> 00:29:54,880
together we can build um

817
00:29:54,880 --> 00:29:56,640
a future that reflects the values that

818
00:29:56,640 --> 00:29:58,399
that we share so

819
00:29:58,399 --> 00:30:00,399
the work that every single one of you is

820
00:30:00,399 --> 00:30:03,360
doing in uh ways big and small

821
00:30:03,360 --> 00:30:04,960
that's what really counts

822
00:30:04,960 --> 00:30:06,559
and i'm just pleased for the opportunity

823
00:30:06,559 --> 00:30:08,559
to spend a few minutes talking about how

824
00:30:08,559 --> 00:30:09,840
we see it how we think about it

825
00:30:09,840 --> 00:30:12,240
especially maria uh with you so thank

826
00:30:12,240 --> 00:30:13,279
you

827
00:30:13,279 --> 00:30:15,279
no thank you so much secretary blinken

828
00:30:15,279 --> 00:30:17,760
can i quit to throw one quick question

829
00:30:17,760 --> 00:30:20,640
so you mentioned leading in um cheryl

830
00:30:20,640 --> 00:30:22,080
sandberg just said that she would be

831
00:30:22,080 --> 00:30:25,120
leaving meta this uh at the end of this

832
00:30:25,120 --> 00:30:27,760
year um these are american companies

833
00:30:27,760 --> 00:30:29,120
that did have

834
00:30:29,120 --> 00:30:31,600
values that were infused

835
00:30:31,600 --> 00:30:33,919
into their design and again probably not

836
00:30:33,919 --> 00:30:36,480
by their design that encouraged the

837
00:30:36,480 --> 00:30:38,559
death of democracies in many parts of

838
00:30:38,559 --> 00:30:40,960
the world um

839
00:30:40,960 --> 00:30:44,880
in in norway just last week i i kind of

840
00:30:44,880 --> 00:30:46,720
thought the next two years will be

841
00:30:46,720 --> 00:30:48,000
critical

842
00:30:48,000 --> 00:30:50,559
for the survival of democracy

843
00:30:50,559 --> 00:30:52,559
and there were people from kiev from

844
00:30:52,559 --> 00:30:55,679
ukraine uh who who really said that they

845
00:30:55,679 --> 00:30:58,559
received the most help from

846
00:30:58,559 --> 00:31:01,440
ordinary people you've just asked us all

847
00:31:01,440 --> 00:31:03,840
to work together i guess you know is

848
00:31:03,840 --> 00:31:06,799
there a timetable you know the long term

849
00:31:06,799 --> 00:31:09,679
yes education medium term yes loss in

850
00:31:09,679 --> 00:31:13,039
the short term how how can we stop what

851
00:31:13,039 --> 00:31:16,159
an apple bomb called autocracy inc from

852
00:31:16,159 --> 00:31:20,000
taking over in this period of chaos

853
00:31:20,000 --> 00:31:21,600
maria i think we all have to be seized

854
00:31:21,600 --> 00:31:25,039
with the the the fierce urgency of now

855
00:31:25,039 --> 00:31:27,440
um and yes many of the things that we're

856
00:31:27,440 --> 00:31:30,880
talking about will play out over time

857
00:31:30,880 --> 00:31:32,320
much of this is not flipping a light

858
00:31:32,320 --> 00:31:33,600
switch

859
00:31:33,600 --> 00:31:36,080
or turning on or off a computer uh it

860
00:31:36,080 --> 00:31:38,000
does take time but

861
00:31:38,000 --> 00:31:41,120
if we bring to it together a sense of a

862
00:31:41,120 --> 00:31:43,120
sense of urgency and a sense of

863
00:31:43,120 --> 00:31:44,320
determination

864
00:31:44,320 --> 00:31:46,240
um that's usually important and if this

865
00:31:46,240 --> 00:31:48,480
entire community is galvanized

866
00:31:48,480 --> 00:31:50,080
um i think we can make we can make a

867
00:31:50,080 --> 00:31:52,559
real difference but that requires

868
00:31:52,559 --> 00:31:54,480
day in day out vigilance

869
00:31:54,480 --> 00:31:57,360
uh it requires day in day out action

870
00:31:57,360 --> 00:32:00,000
and i think what we'll see if we if we

871
00:32:00,000 --> 00:32:01,279
if we do it right and do it in a

872
00:32:01,279 --> 00:32:03,120
sustained way is

873
00:32:03,120 --> 00:32:05,200
you you take a step

874
00:32:05,200 --> 00:32:06,399
and you look and it doesn't look like

875
00:32:06,399 --> 00:32:08,000
you've traveled very far

876
00:32:08,000 --> 00:32:08,960
but

877
00:32:08,960 --> 00:32:10,960
my hope and expectation is that over the

878
00:32:10,960 --> 00:32:12,159
next few years

879
00:32:12,159 --> 00:32:13,679
we will take many steps together and

880
00:32:13,679 --> 00:32:15,039
we'll actually recognize that we've

881
00:32:15,039 --> 00:32:16,720
traveled a great distance the hard

882
00:32:16,720 --> 00:32:18,559
reality that we face and it's a it's a

883
00:32:18,559 --> 00:32:20,960
cliche but it's profoundly true

884
00:32:20,960 --> 00:32:22,240
um

885
00:32:22,240 --> 00:32:24,240
technology itself isn't inherently good

886
00:32:24,240 --> 00:32:26,880
or bad how it's used determines

887
00:32:26,880 --> 00:32:29,440
uh whether it's for the good uh or for

888
00:32:29,440 --> 00:32:31,840
the bad and if we marshal all of our

889
00:32:31,840 --> 00:32:33,679
forces together i think we have we carry

890
00:32:33,679 --> 00:32:35,360
a great weight into this fight to make

891
00:32:35,360 --> 00:32:38,159
sure to the best of our ability uh that

892
00:32:38,159 --> 00:32:40,320
technology is used for the good that

893
00:32:40,320 --> 00:32:43,039
it's used to advance a more open more

894
00:32:43,039 --> 00:32:46,080
free more democratic world uh and that

895
00:32:46,080 --> 00:32:49,120
it's not misused and abused to undermine

896
00:32:49,120 --> 00:32:51,120
those basic principles but i think we

897
00:32:51,120 --> 00:32:52,960
have to have exactly what you said a

898
00:32:52,960 --> 00:32:55,120
real sense of urgency about that

899
00:32:55,120 --> 00:32:57,120
a real sense of vigilance

900
00:32:57,120 --> 00:32:59,440
a determination to call out misuse and

901
00:32:59,440 --> 00:33:02,080
abuse the determination on the part of

902
00:33:02,080 --> 00:33:05,039
ngos and civil society to hold

903
00:33:05,039 --> 00:33:07,600
governments and hold the private sector

904
00:33:07,600 --> 00:33:09,360
to account

905
00:33:09,360 --> 00:33:10,480
and

906
00:33:10,480 --> 00:33:12,159
i'm i remain

907
00:33:12,159 --> 00:33:14,240
optimistic that marshaling all of these

908
00:33:14,240 --> 00:33:16,159
forces together with that sense of

909
00:33:16,159 --> 00:33:17,279
urgency

910
00:33:17,279 --> 00:33:18,720
we can make a difference and we can

911
00:33:18,720 --> 00:33:20,810
shape a future that is

912
00:33:20,810 --> 00:33:22,240
[Music]

913
00:33:22,240 --> 00:33:26,399
more more open uh more tolerant and uh

914
00:33:26,399 --> 00:33:28,480
actually supports and defends freedom

915
00:33:28,480 --> 00:33:30,559
and democracy and doesn't undermine it

916
00:33:30,559 --> 00:33:33,200
that's the objective but look

917
00:33:33,200 --> 00:33:35,039
we have to show all of us in different

918
00:33:35,039 --> 00:33:36,559
ways that we can actually deliver on

919
00:33:36,559 --> 00:33:39,120
this so i recognize

920
00:33:39,120 --> 00:33:42,399
declarations are are good uh calling

921
00:33:42,399 --> 00:33:44,799
things out are good but what really

922
00:33:44,799 --> 00:33:47,519
counts is action that makes a change

923
00:33:47,519 --> 00:33:50,000
action that deals with the problem

924
00:33:50,000 --> 00:33:52,080
none of that is easy but we're

925
00:33:52,080 --> 00:33:53,679
determined to do it and we're determined

926
00:33:53,679 --> 00:33:56,320
to do it together

927
00:33:57,039 --> 00:33:58,799
fantastic thank you so much for your

928
00:33:58,799 --> 00:34:01,360
times secretary clinton good luck

929
00:34:01,360 --> 00:34:05,120
great to see you thanks bye-bye

930
00:34:05,120 --> 00:34:06,720
really interesting remarks and what

931
00:34:06,720 --> 00:34:09,679
really struck me were race's comments

932
00:34:09,679 --> 00:34:12,239
about how many democracies really aren't

933
00:34:12,239 --> 00:34:14,480
prepared uh in terms of their

934
00:34:14,480 --> 00:34:17,199
relationship with technology in the 21st

935
00:34:17,199 --> 00:34:19,760
century and frankly the authoritarian

936
00:34:19,760 --> 00:34:21,440
states and corporations many

937
00:34:21,440 --> 00:34:22,960
corporations

938
00:34:22,960 --> 00:34:25,199
have a better vision or stronger vision

939
00:34:25,199 --> 00:34:26,239
rather

940
00:34:26,239 --> 00:34:27,839
when it comes to how they want to

941
00:34:27,839 --> 00:34:30,079
leverage technology and it's really up

942
00:34:30,079 --> 00:34:33,119
to activist people to hold entities to

943
00:34:33,119 --> 00:34:35,280
account people who care about human

944
00:34:35,280 --> 00:34:37,599
rights people participating at rights

945
00:34:37,599 --> 00:34:38,719
con

946
00:34:38,719 --> 00:34:41,040
to really challenge

947
00:34:41,040 --> 00:34:42,239
the vision

948
00:34:42,239 --> 00:34:45,199
pushed by authoritarian states and also

949
00:34:45,199 --> 00:34:47,760
many corporations

950
00:34:47,760 --> 00:34:49,040
otherwise

951
00:34:49,040 --> 00:34:50,320
this century is going to be an

952
00:34:50,320 --> 00:34:52,239
authoritarian century in the 21st

953
00:34:52,239 --> 00:34:54,560
century should be a century for

954
00:34:54,560 --> 00:34:57,200
democracies and on that note thanks so

955
00:34:57,200 --> 00:35:02,200
much for joining and stay engaged

956
00:35:08,320 --> 00:35:10,400
you

