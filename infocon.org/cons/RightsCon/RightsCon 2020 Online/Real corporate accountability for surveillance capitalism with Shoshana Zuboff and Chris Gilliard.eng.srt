1
00:00:02,159 --> 00:00:05,039
hi everyone

2
00:00:03,120 --> 00:00:07,440
my name is natalie marichal i'm a senior

3
00:00:05,040 --> 00:00:09,360
policy analyst at ranking digital rights

4
00:00:07,440 --> 00:00:11,599
and it's my absolute pleasure to welcome

5
00:00:09,360 --> 00:00:14,320
you today for this fireside chat

6
00:00:11,599 --> 00:00:15,360
uh with uh shoshanna zuboff chris

7
00:00:14,320 --> 00:00:17,359
gilliard and

8
00:00:15,360 --> 00:00:18,800
joe westby on real corporate

9
00:00:17,359 --> 00:00:19,920
accountability for surveillance

10
00:00:18,800 --> 00:00:22,800
capitalism

11
00:00:19,920 --> 00:00:24,160
civil society's agenda for a new decade

12
00:00:22,800 --> 00:00:26,000
uh so you're able to

13
00:00:24,160 --> 00:00:28,160
i believe you're able to see our speaker

14
00:00:26,000 --> 00:00:30,800
bios uh through the platform so

15
00:00:28,160 --> 00:00:33,280
i'll i'll let you to read that on your

16
00:00:30,800 --> 00:00:35,760
own uh let's jump right into it

17
00:00:33,280 --> 00:00:36,719
let's go to shashana first so shashana

18
00:00:35,760 --> 00:00:39,599
of course

19
00:00:36,719 --> 00:00:41,920
is professor emerita at the harvard

20
00:00:39,600 --> 00:00:43,600
business school and author of the age of

21
00:00:41,920 --> 00:00:45,840
surveillance capitalism

22
00:00:43,600 --> 00:00:47,520
so shashana for people who may not have

23
00:00:45,840 --> 00:00:48,800
had a chance to read your book yet or

24
00:00:47,520 --> 00:00:50,480
maybe aren't familiar with the

25
00:00:48,800 --> 00:00:52,239
intellectual framework

26
00:00:50,480 --> 00:00:54,078
that you describe in the book could you

27
00:00:52,239 --> 00:00:59,839
give us a brief overview of the age of

28
00:00:54,079 --> 00:00:59,840
surveillance capitalism

29
00:01:01,920 --> 00:01:06,960
we seem to be having an audio issue on

30
00:01:04,080 --> 00:01:06,960
shashana's end

31
00:01:10,840 --> 00:01:13,840
again

32
00:01:23,840 --> 00:01:28,080
so while uh well uh deals with her

33
00:01:26,720 --> 00:01:30,880
technical issue

34
00:01:28,080 --> 00:01:32,640
um let's uh let's take a step back maybe

35
00:01:30,880 --> 00:01:34,240
and talk about uh the context in which

36
00:01:32,640 --> 00:01:35,200
we're having this conversation uh of

37
00:01:34,240 --> 00:01:36,158
course we're all having this

38
00:01:35,200 --> 00:01:39,840
conversation

39
00:01:36,159 --> 00:01:42,960
uh online via a series of um

40
00:01:39,840 --> 00:01:45,439
technical and internet intermediaries

41
00:01:42,960 --> 00:01:47,199
uh many of which are as we speak about

42
00:01:45,439 --> 00:01:50,320
the very problem itself

43
00:01:47,200 --> 00:01:52,880
are in the process of uh recording and

44
00:01:50,320 --> 00:01:55,360
tracking and eventually analyzing

45
00:01:52,880 --> 00:01:56,560
everything that we're doing right now

46
00:01:55,360 --> 00:01:58,799
everything from our ip

47
00:01:56,560 --> 00:01:59,840
addresses to what other browser what

48
00:01:58,799 --> 00:02:01,520
browsers we're using

49
00:01:59,840 --> 00:02:03,600
what other tools we're using at the same

50
00:02:01,520 --> 00:02:05,920
time and all this

51
00:02:03,600 --> 00:02:07,360
uh according to uh the framework of

52
00:02:05,920 --> 00:02:10,318
surveillance capitalism

53
00:02:07,360 --> 00:02:12,959
in order to not only uh target us with

54
00:02:10,318 --> 00:02:13,839
ads and justify charging advertisers and

55
00:02:12,959 --> 00:02:16,239
brands

56
00:02:13,840 --> 00:02:17,040
uh for the privilege of uh reaching our

57
00:02:16,239 --> 00:02:19,840
attention

58
00:02:17,040 --> 00:02:22,079
but also for uh for the purpose of uh

59
00:02:19,840 --> 00:02:25,840
behavior modification of nudging

60
00:02:22,080 --> 00:02:27,920
all of us to take actions that

61
00:02:25,840 --> 00:02:29,599
in this platform's estimation will

62
00:02:27,920 --> 00:02:33,599
benefit their bottom line

63
00:02:29,599 --> 00:02:37,040
in the long short and medium term

64
00:02:33,599 --> 00:02:39,280
so um i i'm told that uh the audio is

65
00:02:37,040 --> 00:02:40,400
back so uh shoshanna uh can we turn to

66
00:02:39,280 --> 00:02:44,239
you for

67
00:02:40,400 --> 00:02:47,440
your book can you hear me now

68
00:02:44,239 --> 00:02:49,120
yes i can thanks so much all right well

69
00:02:47,440 --> 00:02:50,480
thank you so much for stepping into the

70
00:02:49,120 --> 00:02:52,640
fray there natalie it's

71
00:02:50,480 --> 00:02:54,238
it's always something and i bet

72
00:02:52,640 --> 00:02:57,279
everybody who's watching us

73
00:02:54,239 --> 00:03:01,120
understands exactly what that means okay

74
00:02:57,280 --> 00:03:01,519
so um i'll just uh build really quickly

75
00:03:01,120 --> 00:03:03,280
on

76
00:03:01,519 --> 00:03:04,560
on some of the pieces that natalie laid

77
00:03:03,280 --> 00:03:07,760
out

78
00:03:04,560 --> 00:03:11,120
surveillance capitalism begins

79
00:03:07,760 --> 00:03:14,480
with an audacious

80
00:03:11,120 --> 00:03:18,000
unexpected startling and dark

81
00:03:14,480 --> 00:03:20,319
discovery that after all the things that

82
00:03:18,000 --> 00:03:21,519
capitalism has commoditized over the

83
00:03:20,319 --> 00:03:23,200
centuries

84
00:03:21,519 --> 00:03:24,959
turning them into stuff that could be

85
00:03:23,200 --> 00:03:27,760
sold and purchased

86
00:03:24,959 --> 00:03:29,840
in the early 2000s and it happened at

87
00:03:27,760 --> 00:03:31,840
google and it happened under a state of

88
00:03:29,840 --> 00:03:33,200
financial emergency during the dot-com

89
00:03:31,840 --> 00:03:36,000
bust

90
00:03:33,200 --> 00:03:38,159
what they discovered was that private

91
00:03:36,000 --> 00:03:41,519
human experience

92
00:03:38,159 --> 00:03:46,159
what we do in our own lives our behavior

93
00:03:41,519 --> 00:03:48,879
our experience could be taken

94
00:03:46,159 --> 00:03:49,440
without our knowledge which is to say it

95
00:03:48,879 --> 00:03:52,399
could be

96
00:03:49,440 --> 00:03:54,000
stolen it could be translated into

97
00:03:52,400 --> 00:03:57,920
behavioral data

98
00:03:54,000 --> 00:04:01,840
behavioral data claimed as zero cost

99
00:03:57,920 --> 00:04:06,000
proprietary assets those behavioral data

100
00:04:01,840 --> 00:04:08,959
travel through supply chains data flows

101
00:04:06,000 --> 00:04:10,799
into a 21st century factory we call it

102
00:04:08,959 --> 00:04:12,799
artificial intelligence

103
00:04:10,799 --> 00:04:14,720
this computational factory like every

104
00:04:12,799 --> 00:04:17,120
factory makes products

105
00:04:14,720 --> 00:04:18,079
they're prediction products what it

106
00:04:17,120 --> 00:04:21,519
produces

107
00:04:18,079 --> 00:04:22,320
are predictions of our behavior soon and

108
00:04:21,519 --> 00:04:25,680
later

109
00:04:22,320 --> 00:04:28,159
individual group populations

110
00:04:25,680 --> 00:04:29,919
those predictions are sold into a new

111
00:04:28,160 --> 00:04:32,560
kind of marketplace

112
00:04:29,919 --> 00:04:33,919
i call them human futures markets

113
00:04:32,560 --> 00:04:37,280
because they trade

114
00:04:33,919 --> 00:04:40,240
exclusively in bets on what we

115
00:04:37,280 --> 00:04:42,320
will do now the first human futures

116
00:04:40,240 --> 00:04:44,560
markets were as we all know

117
00:04:42,320 --> 00:04:45,680
online advertising where they were

118
00:04:44,560 --> 00:04:48,800
buying a prediction

119
00:04:45,680 --> 00:04:51,759
product called the click through rate

120
00:04:48,800 --> 00:04:52,960
the trillion dollar capitalization of

121
00:04:51,759 --> 00:04:55,600
google

122
00:04:52,960 --> 00:04:57,039
the near trillion dollar capitalization

123
00:04:55,600 --> 00:05:00,240
of facebook

124
00:04:57,040 --> 00:05:03,120
in those two instances that

125
00:05:00,240 --> 00:05:04,479
capital is entirely derived from this

126
00:05:03,120 --> 00:05:07,039
logic

127
00:05:04,479 --> 00:05:08,800
amazon comes on stream later microsoft

128
00:05:07,039 --> 00:05:11,680
comes on stream later

129
00:05:08,800 --> 00:05:12,240
and now we've seen how successful this

130
00:05:11,680 --> 00:05:14,560
logic

131
00:05:12,240 --> 00:05:16,000
and the surveillance dividend has been

132
00:05:14,560 --> 00:05:19,280
for those companies

133
00:05:16,000 --> 00:05:19,840
but let's move on because natalie's

134
00:05:19,280 --> 00:05:22,719
question

135
00:05:19,840 --> 00:05:23,359
really points us into the direction of

136
00:05:22,720 --> 00:05:26,560
not only

137
00:05:23,360 --> 00:05:29,280
understanding this economic logic

138
00:05:26,560 --> 00:05:30,800
very important to understand this is an

139
00:05:29,280 --> 00:05:34,799
economic logic

140
00:05:30,800 --> 00:05:36,880
it's not technology we can deploy

141
00:05:34,800 --> 00:05:38,240
digital technologies in a thousand

142
00:05:36,880 --> 00:05:41,840
different ways

143
00:05:38,240 --> 00:05:43,680
this is only one so let's fast forward

144
00:05:41,840 --> 00:05:45,359
to some of its social consequences

145
00:05:43,680 --> 00:05:46,960
because that brings us

146
00:05:45,360 --> 00:05:49,520
to the question that we're all here to

147
00:05:46,960 --> 00:05:51,919
discuss which is rights

148
00:05:49,520 --> 00:05:53,280
when you are a company and you are

149
00:05:51,919 --> 00:05:56,000
competing

150
00:05:53,280 --> 00:05:58,159
on selling predictions of human behavior

151
00:05:56,000 --> 00:05:58,880
you're selling human futures which is to

152
00:05:58,160 --> 00:06:02,160
say you are

153
00:05:58,880 --> 00:06:03,120
selling certainty there are three things

154
00:06:02,160 --> 00:06:06,080
that you need

155
00:06:03,120 --> 00:06:08,479
to be successful in that competition one

156
00:06:06,080 --> 00:06:11,120
you need a lot of data

157
00:06:08,479 --> 00:06:14,880
everything natalie gave you a sense of

158
00:06:11,120 --> 00:06:14,880
that i call that economies of scale

159
00:06:14,960 --> 00:06:21,520
these data capturing

160
00:06:18,479 --> 00:06:24,159
supply chain interfaces which began

161
00:06:21,520 --> 00:06:26,159
online when you're you know browsing and

162
00:06:24,160 --> 00:06:27,280
searching and so forth posting something

163
00:06:26,160 --> 00:06:29,759
on facebook

164
00:06:27,280 --> 00:06:30,880
they now extend through every domain of

165
00:06:29,759 --> 00:06:32,880
human life

166
00:06:30,880 --> 00:06:34,800
it's your home it's your car it's your

167
00:06:32,880 --> 00:06:38,639
walk in the park it's your bloodstream

168
00:06:34,800 --> 00:06:42,400
it's your thoughts okay they also need

169
00:06:38,639 --> 00:06:46,240
varieties of data so volume

170
00:06:42,400 --> 00:06:47,359
and which is scale and varieties which

171
00:06:46,240 --> 00:06:49,840
is scope

172
00:06:47,360 --> 00:06:51,120
it's not just enough to have what we're

173
00:06:49,840 --> 00:06:53,758
doing online

174
00:06:51,120 --> 00:06:55,520
they want to have our feelings our

175
00:06:53,759 --> 00:06:58,639
emotions

176
00:06:55,520 --> 00:07:01,680
are the state of our health

177
00:06:58,639 --> 00:07:03,199
they take these things from for example

178
00:07:01,680 --> 00:07:04,960
the stoop of our shoulders when they

179
00:07:03,199 --> 00:07:06,560
take us walking down the street

180
00:07:04,960 --> 00:07:08,400
they take them from the hundreds of

181
00:07:06,560 --> 00:07:09,840
facial gestures that they get out of

182
00:07:08,400 --> 00:07:12,159
facial recognition

183
00:07:09,840 --> 00:07:14,159
in a thousand other ways so they need

184
00:07:12,160 --> 00:07:15,520
scale and they need scope

185
00:07:14,160 --> 00:07:18,800
then they made an extraordinary

186
00:07:15,520 --> 00:07:19,758
discovery the most predictive data comes

187
00:07:18,800 --> 00:07:22,880
from

188
00:07:19,759 --> 00:07:24,560
actually interfacing with us touching

189
00:07:22,880 --> 00:07:28,719
our behavior

190
00:07:24,560 --> 00:07:31,520
and learning how to tune us to herd us

191
00:07:28,720 --> 00:07:32,639
to actually modify our behavior in the

192
00:07:31,520 --> 00:07:35,599
direction

193
00:07:32,639 --> 00:07:37,440
that optimizes their revenue flows there

194
00:07:35,599 --> 00:07:39,120
are many examples of this

195
00:07:37,440 --> 00:07:40,880
i won't go into all of them now because

196
00:07:39,120 --> 00:07:44,080
we have a lot of time to talk

197
00:07:40,880 --> 00:07:45,840
but let's just say that when you talk

198
00:07:44,080 --> 00:07:48,159
about facebook's

199
00:07:45,840 --> 00:07:49,758
social contagion experiments when you

200
00:07:48,160 --> 00:07:53,120
talk about google's

201
00:07:49,759 --> 00:07:54,960
uh augmented reality game that we know

202
00:07:53,120 --> 00:07:56,720
as pokemon go

203
00:07:54,960 --> 00:07:59,359
these were early phases of

204
00:07:56,720 --> 00:08:01,919
experimentation and how exactly

205
00:07:59,360 --> 00:08:03,599
do you use subliminal cues social

206
00:08:01,919 --> 00:08:05,599
comparison dynamics

207
00:08:03,599 --> 00:08:07,199
rewards and punishments the structures

208
00:08:05,599 --> 00:08:10,719
of gamification

209
00:08:07,199 --> 00:08:13,520
to learn learn how to tune and herd

210
00:08:10,720 --> 00:08:15,039
individuals groups and populations at

211
00:08:13,520 --> 00:08:18,159
scale

212
00:08:15,039 --> 00:08:22,159
the question we have to ask

213
00:08:18,160 --> 00:08:23,919
what is this power to use digital

214
00:08:22,160 --> 00:08:26,960
instrumentation

215
00:08:23,919 --> 00:08:29,039
to have such control

216
00:08:26,960 --> 00:08:30,239
over human behavior at every level of

217
00:08:29,039 --> 00:08:32,958
the system

218
00:08:30,240 --> 00:08:33,760
this is an extraordinary power now all

219
00:08:32,958 --> 00:08:36,880
of us

220
00:08:33,760 --> 00:08:37,439
have tended to fall back on forms of

221
00:08:36,880 --> 00:08:40,000
power

222
00:08:37,440 --> 00:08:41,200
theories of power examples of power from

223
00:08:40,000 --> 00:08:42,440
the past

224
00:08:41,200 --> 00:08:44,480
so we've called it digital

225
00:08:42,440 --> 00:08:47,120
totalitarianism we've called it digital

226
00:08:44,480 --> 00:08:50,560
fascism whatever whatever

227
00:08:47,120 --> 00:08:52,959
what i want to stress is that taking

228
00:08:50,560 --> 00:08:54,399
old categories and trying to interpret

229
00:08:52,959 --> 00:08:56,000
this new power

230
00:08:54,399 --> 00:08:58,000
through those old categories has

231
00:08:56,000 --> 00:08:59,519
actually set us back from understanding

232
00:08:58,000 --> 00:09:02,320
what's going on

233
00:08:59,519 --> 00:09:03,360
i call this new power instrumentarian

234
00:09:02,320 --> 00:09:06,320
power

235
00:09:03,360 --> 00:09:06,959
because it works exclusively through the

236
00:09:06,320 --> 00:09:10,000
milieu

237
00:09:06,959 --> 00:09:12,479
of digital instrumentation

238
00:09:10,000 --> 00:09:13,440
this is not armies of jack-booted

239
00:09:12,480 --> 00:09:15,519
soldiers

240
00:09:13,440 --> 00:09:18,320
coming to drag us in the middle of the

241
00:09:15,519 --> 00:09:20,640
night to the gulag or the camp

242
00:09:18,320 --> 00:09:22,080
this is not the threat of violence

243
00:09:20,640 --> 00:09:24,560
terror and murder

244
00:09:22,080 --> 00:09:25,920
which was the signature of totalitarian

245
00:09:24,560 --> 00:09:28,640
power

246
00:09:25,920 --> 00:09:30,240
this is a form of power that comes on

247
00:09:28,640 --> 00:09:32,480
slippered feet

248
00:09:30,240 --> 00:09:33,760
it comes more likely offering us a

249
00:09:32,480 --> 00:09:38,399
cappuccino and

250
00:09:33,760 --> 00:09:40,880
just the way we know you like it

251
00:09:38,399 --> 00:09:42,800
but it is a power based on an

252
00:09:40,880 --> 00:09:45,839
increasingly ubiquitous

253
00:09:42,800 --> 00:09:48,160
pervasive digital infrastructure that

254
00:09:45,839 --> 00:09:49,200
has been commandeered by this economic

255
00:09:48,160 --> 00:09:52,399
logic

256
00:09:49,200 --> 00:09:55,120
to shape our behavior in the in

257
00:09:52,399 --> 00:09:56,320
in a way that is aligned with its

258
00:09:55,120 --> 00:09:58,959
interests

259
00:09:56,320 --> 00:10:00,640
and it is radically indifferent to

260
00:09:58,959 --> 00:10:03,680
everything else

261
00:10:00,640 --> 00:10:04,079
which is to say radically indifferent to

262
00:10:03,680 --> 00:10:07,199
our

263
00:10:04,079 --> 00:10:09,880
actual needs our state of well-being

264
00:10:07,200 --> 00:10:12,720
and the needs of our societies and

265
00:10:09,880 --> 00:10:16,160
instrumentarian society

266
00:10:12,720 --> 00:10:19,120
is a vision of the long game

267
00:10:16,160 --> 00:10:20,319
of surveillance capitalism where private

268
00:10:19,120 --> 00:10:24,720
unaccountable

269
00:10:20,320 --> 00:10:28,880
instrumentarian power replaces democracy

270
00:10:24,720 --> 00:10:32,320
as the arbiter of social order

271
00:10:28,880 --> 00:10:33,279
that is the endgame of this work that is

272
00:10:32,320 --> 00:10:37,600
the end game

273
00:10:33,279 --> 00:10:40,240
of this economic logic and that is why

274
00:10:37,600 --> 00:10:41,760
it has mobilized me for so many years to

275
00:10:40,240 --> 00:10:45,279
tell this story

276
00:10:41,760 --> 00:10:48,880
and that is why my greatest wish

277
00:10:45,279 --> 00:10:52,079
is that we all spread this knowledge

278
00:10:48,880 --> 00:10:55,200
and work together now to mobilize

279
00:10:52,079 --> 00:10:55,199
for the third decade

280
00:10:56,240 --> 00:10:59,279
thank you for that shashana so as as i

281
00:10:58,880 --> 00:11:02,320
think

282
00:10:59,279 --> 00:11:04,800
uh has given us a really good sense um

283
00:11:02,320 --> 00:11:06,640
the logic of surveillance capitalism is

284
00:11:04,800 --> 00:11:09,199
a global economic logic

285
00:11:06,640 --> 00:11:10,079
um but like all global uh economic

286
00:11:09,200 --> 00:11:12,480
logics

287
00:11:10,079 --> 00:11:13,599
it uh it affects uh each of us and each

288
00:11:12,480 --> 00:11:15,839
of our communities

289
00:11:13,600 --> 00:11:17,040
in different ways uh depending on where

290
00:11:15,839 --> 00:11:19,760
we are situated

291
00:11:17,040 --> 00:11:21,519
uh so i'd like to turn to uh to a

292
00:11:19,760 --> 00:11:24,720
specific u.s example

293
00:11:21,519 --> 00:11:26,320
um you know as as is always the case and

294
00:11:24,720 --> 00:11:28,079
again especially in the u.s

295
00:11:26,320 --> 00:11:29,360
uh surveillance and control are

296
00:11:28,079 --> 00:11:32,000
experienced differently

297
00:11:29,360 --> 00:11:32,640
uh by uh people who are uh not the

298
00:11:32,000 --> 00:11:35,040
dominant

299
00:11:32,640 --> 00:11:36,880
uh group uh or the most powerful group

300
00:11:35,040 --> 00:11:39,360
in society and so in this case we're

301
00:11:36,880 --> 00:11:41,519
talking specifically uh about black

302
00:11:39,360 --> 00:11:44,640
immigrant

303
00:11:41,519 --> 00:11:46,079
um a range of uh groups in the us that

304
00:11:44,640 --> 00:11:48,720
have been marginalized

305
00:11:46,079 --> 00:11:51,040
over time uh so chris uh let's turn to

306
00:11:48,720 --> 00:11:52,480
you for a sense of that history both

307
00:11:51,040 --> 00:11:54,560
before the rise of surveillance

308
00:11:52,480 --> 00:11:56,000
capitalism since surveillance itself

309
00:11:54,560 --> 00:11:58,560
does predate of course

310
00:11:56,000 --> 00:12:00,720
uh surveillance capitalism uh and since

311
00:11:58,560 --> 00:12:02,479
uh the early 2000's and i'll note for

312
00:12:00,720 --> 00:12:05,680
our audience um

313
00:12:02,480 --> 00:12:07,279
that like many of us uh chris uh has uh

314
00:12:05,680 --> 00:12:09,760
is strongly committed to his personal

315
00:12:07,279 --> 00:12:11,439
privacy and uh one of the choices that

316
00:12:09,760 --> 00:12:12,560
he's making for himself is to keep his

317
00:12:11,440 --> 00:12:14,639
face off the internet

318
00:12:12,560 --> 00:12:16,880
uh as much as possible so uh you'll be

319
00:12:14,639 --> 00:12:19,920
hearing uh chris papia only uh

320
00:12:16,880 --> 00:12:19,920
uh audio only

321
00:12:21,040 --> 00:12:24,240
oh thank you natalie um and so well i

322
00:12:23,519 --> 00:12:26,720
want to

323
00:12:24,240 --> 00:12:27,279
first of all thank you shashana as well

324
00:12:26,720 --> 00:12:30,320
um

325
00:12:27,279 --> 00:12:33,600
but i want to start and and say that

326
00:12:30,320 --> 00:12:35,920
a lot of my work and a lot of um

327
00:12:33,600 --> 00:12:39,200
these understandings is built on the

328
00:12:35,920 --> 00:12:42,079
work of some other amazing scholars

329
00:12:39,200 --> 00:12:44,079
simone brown virginia eubanks sophia

330
00:12:42,079 --> 00:12:45,359
noble ruja benjamin

331
00:12:44,079 --> 00:12:47,120
and i just want to start with something

332
00:12:45,360 --> 00:12:49,519
that simone said

333
00:12:47,120 --> 00:12:51,600
in her book dark matters which is that

334
00:12:49,519 --> 00:12:53,760
the historical formation of surveillance

335
00:12:51,600 --> 00:12:55,360
is not outside the historical formation

336
00:12:53,760 --> 00:12:58,480
of slavery

337
00:12:55,360 --> 00:13:01,279
and how i understand that is that it's

338
00:12:58,480 --> 00:13:04,000
um particularly particularly for uh

339
00:13:01,279 --> 00:13:05,839
enslaved formerly enslaved peoples

340
00:13:04,000 --> 00:13:07,040
but also as we move forward to think

341
00:13:05,839 --> 00:13:10,000
about um

342
00:13:07,040 --> 00:13:11,360
other marginalized groups populations as

343
00:13:10,000 --> 00:13:13,920
you mentioned now

344
00:13:11,360 --> 00:13:15,760
um whether that's who are incarcerated

345
00:13:13,920 --> 00:13:18,560
or formerly incarcerated

346
00:13:15,760 --> 00:13:19,279
um you know people who are experiencing

347
00:13:18,560 --> 00:13:23,199
economic

348
00:13:19,279 --> 00:13:25,760
stress in trans folks

349
00:13:23,200 --> 00:13:27,200
typically experienced are not unfamiliar

350
00:13:25,760 --> 00:13:30,560
with a

351
00:13:27,200 --> 00:13:33,600
wide variety of surveillance practices

352
00:13:30,560 --> 00:13:34,560
both by you know the government by law

353
00:13:33,600 --> 00:13:37,440
enforcement

354
00:13:34,560 --> 00:13:38,959
but by companies as well but the other

355
00:13:37,440 --> 00:13:41,040
part of that i think that's really

356
00:13:38,959 --> 00:13:42,239
important to note and to always pay

357
00:13:41,040 --> 00:13:44,399
attention to

358
00:13:42,240 --> 00:13:45,360
um in these kind of discussions is the

359
00:13:44,399 --> 00:13:47,600
harms that

360
00:13:45,360 --> 00:13:48,720
these groups experience typically come

361
00:13:47,600 --> 00:13:52,880
first

362
00:13:48,720 --> 00:13:56,480
and are often uh much more um

363
00:13:52,880 --> 00:13:59,680
serious and and harmful early on

364
00:13:56,480 --> 00:14:02,639
um and so in a lot of ways these the the

365
00:13:59,680 --> 00:14:02,638
mechanisms or the

366
00:14:07,040 --> 00:14:10,319
don't want to take away from any of

367
00:14:08,320 --> 00:14:13,600
those at all but

368
00:14:10,320 --> 00:14:16,959
uh historically a lot of that falls on

369
00:14:13,600 --> 00:14:18,959
marginalized populations sooner and more

370
00:14:16,959 --> 00:14:31,839
and more harshly and i think that's

371
00:14:18,959 --> 00:14:31,839
something to pay attention to

372
00:15:01,199 --> 00:15:04,479
well that's embarrassing i was on mute

373
00:15:02,800 --> 00:15:08,079
this whole time

374
00:15:04,480 --> 00:15:09,120
i was saying that

375
00:15:08,079 --> 00:15:11,680
well first of all we're all still

376
00:15:09,120 --> 00:15:13,519
getting used to this clearly but also i

377
00:15:11,680 --> 00:15:14,959
wanted to turn uh to joe who's with

378
00:15:13,519 --> 00:15:17,600
amnesty international

379
00:15:14,959 --> 00:15:19,439
uh for for a sense of how uh the

380
00:15:17,600 --> 00:15:21,600
surveillance capitalism framework as

381
00:15:19,440 --> 00:15:24,800
developed by shoshanna as well as other

382
00:15:21,600 --> 00:15:26,800
uh scholarship on uh on surveillance

383
00:15:24,800 --> 00:15:28,800
including work by uh by the scholars

384
00:15:26,800 --> 00:15:29,359
that that chris mentioned as well as

385
00:15:28,800 --> 00:15:32,479
others

386
00:15:29,360 --> 00:15:32,880
uh how this has impacted uh activism for

387
00:15:32,480 --> 00:15:35,360
joe

388
00:15:32,880 --> 00:15:36,639
and for amnesty uh but also uh what what

389
00:15:35,360 --> 00:15:41,839
influence he's seen in the

390
00:15:36,639 --> 00:15:41,839
in the movement more broadly

391
00:15:42,320 --> 00:15:46,000
lee and thanks so much shashana and

392
00:15:44,160 --> 00:15:49,040
chris um

393
00:15:46,000 --> 00:15:51,600
for all of your uh work on this area um

394
00:15:49,040 --> 00:15:54,079
i mean for for amnesty i think uh

395
00:15:51,600 --> 00:15:55,040
shoshanna's book and all the other work

396
00:15:54,079 --> 00:15:58,239
that has been done

397
00:15:55,040 --> 00:16:00,319
on uh uncovering the uh problems of

398
00:15:58,240 --> 00:16:04,240
surveillance capital has really

399
00:16:00,320 --> 00:16:06,160
made us focus on the root causes of so

400
00:16:04,240 --> 00:16:08,240
many of the problems that we're seeing

401
00:16:06,160 --> 00:16:09,839
with technology and human rights and i

402
00:16:08,240 --> 00:16:12,160
think we now

403
00:16:09,839 --> 00:16:13,680
as amnesty sees surveillance capitalism

404
00:16:12,160 --> 00:16:15,519
as one of the biggest human rights

405
00:16:13,680 --> 00:16:18,160
challenges of our time

406
00:16:15,519 --> 00:16:19,519
as shashana has said previously climate

407
00:16:18,160 --> 00:16:20,399
change is to the planet what

408
00:16:19,519 --> 00:16:23,519
surveillance

409
00:16:20,399 --> 00:16:26,480
capitalism is to society and

410
00:16:23,519 --> 00:16:27,199
um i think just like with climate change

411
00:16:26,480 --> 00:16:30,720
as chris

412
00:16:27,199 --> 00:16:32,079
just articulated just now uh

413
00:16:30,720 --> 00:16:33,759
the harms aren't going to be felt

414
00:16:32,079 --> 00:16:35,758
equally systems of surveillance

415
00:16:33,759 --> 00:16:38,079
disproportionately impact people based

416
00:16:35,759 --> 00:16:39,279
on on race class socio-economic

417
00:16:38,079 --> 00:16:41,920
background

418
00:16:39,279 --> 00:16:43,279
and uh other you know marginalized

419
00:16:41,920 --> 00:16:44,240
groups in society and we're already

420
00:16:43,279 --> 00:16:46,560
seeing that

421
00:16:44,240 --> 00:16:48,720
um so really amnesty sees this as a

422
00:16:46,560 --> 00:16:50,719
long-term program of work for the future

423
00:16:48,720 --> 00:16:52,240
and and the report that we published

424
00:16:50,720 --> 00:16:54,560
last year called surveillance giants

425
00:16:52,240 --> 00:16:56,880
really just laid the groundwork for

426
00:16:54,560 --> 00:16:58,160
why we consider this business model

427
00:16:56,880 --> 00:17:00,560
based on surveillance

428
00:16:58,160 --> 00:17:01,759
inherently as a threat to human rights

429
00:17:00,560 --> 00:17:03,680
just

430
00:17:01,759 --> 00:17:06,160
super briefly summarize our our

431
00:17:03,680 --> 00:17:09,280
arguments i mean i think

432
00:17:06,160 --> 00:17:09,839
as shashana's kind of set out you know

433
00:17:09,280 --> 00:17:11,439
this

434
00:17:09,839 --> 00:17:12,958
the the business model is is the

435
00:17:11,439 --> 00:17:15,679
opposite of privacy

436
00:17:12,959 --> 00:17:17,360
undermining the very essence of privacy

437
00:17:15,679 --> 00:17:18,959
but i think it also you know has this

438
00:17:17,359 --> 00:17:20,719
knock-on effect

439
00:17:18,959 --> 00:17:22,400
on a whole range of other human rights

440
00:17:20,720 --> 00:17:24,160
including non-discrimination

441
00:17:22,400 --> 00:17:26,880
freedom of expression even freedom of

442
00:17:24,160 --> 00:17:29,919
thought through the way that it gives

443
00:17:26,880 --> 00:17:31,760
um tech companies another the power to

444
00:17:29,919 --> 00:17:33,440
shape and control our

445
00:17:31,760 --> 00:17:34,960
information environments and influence

446
00:17:33,440 --> 00:17:37,600
our thoughts and behaviors

447
00:17:34,960 --> 00:17:39,200
as well as incentivizing the platform to

448
00:17:37,600 --> 00:17:42,480
amplify racism hate

449
00:17:39,200 --> 00:17:44,080
speech misinformation and this is

450
00:17:42,480 --> 00:17:46,559
you know these are collective harms to

451
00:17:44,080 --> 00:17:47,918
society not just individual harms

452
00:17:46,559 --> 00:17:49,678
and time and again we've seen

453
00:17:47,919 --> 00:17:52,160
governments and other actors

454
00:17:49,679 --> 00:17:53,039
weaponize the same architecture of

455
00:17:52,160 --> 00:17:55,200
surveillance

456
00:17:53,039 --> 00:17:57,200
and control and they seem to now be

457
00:17:55,200 --> 00:17:59,679
almost daily examples of

458
00:17:57,200 --> 00:18:01,200
how this is really impacting on people's

459
00:17:59,679 --> 00:18:04,400
lives

460
00:18:01,200 --> 00:18:06,160
all around the world um but

461
00:18:04,400 --> 00:18:08,400
uh so as shashana said this is an

462
00:18:06,160 --> 00:18:11,679
economic logic that goes far beyond

463
00:18:08,400 --> 00:18:14,880
uh just individual companies but

464
00:18:11,679 --> 00:18:16,160
we have so far focused on in particular

465
00:18:14,880 --> 00:18:18,960
on google and facebook

466
00:18:16,160 --> 00:18:21,840
not just as pioneers of this model but

467
00:18:18,960 --> 00:18:23,919
also because of their dominance over

468
00:18:21,840 --> 00:18:25,199
the kind of global public square through

469
00:18:23,919 --> 00:18:28,080
the the

470
00:18:25,200 --> 00:18:29,760
controlling the channels we rely on to

471
00:18:28,080 --> 00:18:32,000
engage with the digital world

472
00:18:29,760 --> 00:18:33,440
search social media messaging videos

473
00:18:32,000 --> 00:18:36,799
smartphones

474
00:18:33,440 --> 00:18:40,880
and you know it is

475
00:18:36,799 --> 00:18:42,799
um the the power of the platforms

476
00:18:40,880 --> 00:18:43,919
over this you know pervasive digital

477
00:18:42,799 --> 00:18:46,639
infrastructure as

478
00:18:43,919 --> 00:18:48,080
sushana said um that goes hand in hand

479
00:18:46,640 --> 00:18:51,600
with the rights and bats

480
00:18:48,080 --> 00:18:53,520
um so one of our key arguments is that

481
00:18:51,600 --> 00:18:55,199
you know it's well established that

482
00:18:53,520 --> 00:18:57,120
access to the internet is a critical

483
00:18:55,200 --> 00:18:59,280
enabler of human rights

484
00:18:57,120 --> 00:19:00,799
but in practice it's now virtually

485
00:18:59,280 --> 00:19:02,960
impossible to

486
00:19:00,799 --> 00:19:04,720
engage with the digital world without

487
00:19:02,960 --> 00:19:07,120
coming under this

488
00:19:04,720 --> 00:19:09,520
um architecture of surveillance and

489
00:19:07,120 --> 00:19:12,559
control which forces people into this

490
00:19:09,520 --> 00:19:14,480
paradoxical situation where they're only

491
00:19:12,559 --> 00:19:16,240
able to enjoy their human rights online

492
00:19:14,480 --> 00:19:19,600
by submitting to a system

493
00:19:16,240 --> 00:19:22,880
predicated on human rights abuse

494
00:19:19,600 --> 00:19:25,760
and i think you know just finally

495
00:19:22,880 --> 00:19:26,480
um this power has also created this

496
00:19:25,760 --> 00:19:28,240
enormous

497
00:19:26,480 --> 00:19:30,080
accountability gap you know ten years

498
00:19:28,240 --> 00:19:32,160
ago john ruggy said

499
00:19:30,080 --> 00:19:33,280
that the underlying problem of business

500
00:19:32,160 --> 00:19:35,200
human rights was

501
00:19:33,280 --> 00:19:37,600
governance gaps between the scope and

502
00:19:35,200 --> 00:19:39,520
impacts of economic forces and actors

503
00:19:37,600 --> 00:19:41,520
and the capacity of societies to manage

504
00:19:39,520 --> 00:19:43,840
their adverse consequences

505
00:19:41,520 --> 00:19:45,600
i cannot think of a wider governance gap

506
00:19:43,840 --> 00:19:47,520
than that between

507
00:19:45,600 --> 00:19:50,320
um big tech and the surveillance

508
00:19:47,520 --> 00:19:53,120
capitalists and the inability of

509
00:19:50,320 --> 00:19:54,720
societies to hold them to account and so

510
00:19:53,120 --> 00:19:56,479
i think for human rights activism in the

511
00:19:54,720 --> 00:19:59,600
future we need to

512
00:19:56,480 --> 00:20:01,280
you know continue to try to hold them to

513
00:19:59,600 --> 00:20:03,120
account for arms and specific concepts

514
00:20:01,280 --> 00:20:05,520
but also keep in mind the need to

515
00:20:03,120 --> 00:20:07,280
radically overhaul the system itself

516
00:20:05,520 --> 00:20:08,879
um but natalie i know you've done a lot

517
00:20:07,280 --> 00:20:10,559
to analyze this issue as well

518
00:20:08,880 --> 00:20:12,640
using the human rights framework so

519
00:20:10,559 --> 00:20:13,678
maybe you know if you could talk about

520
00:20:12,640 --> 00:20:15,280
your

521
00:20:13,679 --> 00:20:17,679
the main findings and recommendations

522
00:20:15,280 --> 00:20:18,960
from your work

523
00:20:17,679 --> 00:20:21,200
i thought i was asking the questions

524
00:20:18,960 --> 00:20:21,840
here joe um nonetheless thanks for the

525
00:20:21,200 --> 00:20:24,240
question

526
00:20:21,840 --> 00:20:25,039
so uh ranking digital rights as many of

527
00:20:24,240 --> 00:20:27,200
you all know

528
00:20:25,039 --> 00:20:28,960
uh for the past uh couple years has been

529
00:20:27,200 --> 00:20:31,440
working to overhaul

530
00:20:28,960 --> 00:20:32,880
the methodology behind the rdr corporate

531
00:20:31,440 --> 00:20:35,520
accountability index

532
00:20:32,880 --> 00:20:36,799
to account for some of the harms uh that

533
00:20:35,520 --> 00:20:39,280
we see as directly

534
00:20:36,799 --> 00:20:40,799
related to uh to surveillance capitalism

535
00:20:39,280 --> 00:20:43,200
uh the two areas

536
00:20:40,799 --> 00:20:43,840
that we're focusing on is accountability

537
00:20:43,200 --> 00:20:47,039
uh for

538
00:20:43,840 --> 00:20:50,559
targeted advertising uh itself and uh

539
00:20:47,039 --> 00:20:52,799
also for transparency and accountability

540
00:20:50,559 --> 00:20:54,399
uh for the algorithmic content

541
00:20:52,799 --> 00:20:56,960
governance systems uh that

542
00:20:54,400 --> 00:20:58,799
social media platforms in particular use

543
00:20:56,960 --> 00:21:01,919
to determine uh what we see

544
00:20:58,799 --> 00:21:02,639
what we hear what we watch uh and and

545
00:21:01,919 --> 00:21:06,320
therefore

546
00:21:02,640 --> 00:21:09,120
uh nudge our behavior in um

547
00:21:06,320 --> 00:21:10,799
in ways that ultimately benefit them and

548
00:21:09,120 --> 00:21:12,479
one of the most recent outcomes of that

549
00:21:10,799 --> 00:21:14,320
area of work uh was the it's the

550
00:21:12,480 --> 00:21:17,480
business model report series

551
00:21:14,320 --> 00:21:19,360
that you can find on our website

552
00:21:17,480 --> 00:21:21,039
rankingdigitalrights.org

553
00:21:19,360 --> 00:21:22,879
and of course you can stay tuned for uh

554
00:21:21,039 --> 00:21:24,480
for february for the release of the next

555
00:21:22,880 --> 00:21:26,240
corporate accountability index

556
00:21:24,480 --> 00:21:28,799
where we'll have some data on on what

557
00:21:26,240 --> 00:21:33,200
companies do and say they do

558
00:21:28,799 --> 00:21:36,320
in those two areas that i outlined um

559
00:21:33,200 --> 00:21:36,880
so shashana um what should we do about

560
00:21:36,320 --> 00:21:38,320
all this

561
00:21:36,880 --> 00:21:40,480
uh you know we've been talking about the

562
00:21:38,320 --> 00:21:40,879
problems uh but what should we actually

563
00:21:40,480 --> 00:21:42,840
do

564
00:21:40,880 --> 00:21:45,840
about it uh i'm sure you have some

565
00:21:42,840 --> 00:21:45,840
thoughts

566
00:21:50,080 --> 00:21:54,000
let me let me mention a couple of of

567
00:21:52,960 --> 00:21:56,559
principles

568
00:21:54,000 --> 00:21:59,840
for action and then talk about some of

569
00:21:56,559 --> 00:22:04,399
the the specific directions that

570
00:21:59,840 --> 00:22:08,879
we need to move in one principle is that

571
00:22:04,400 --> 00:22:11,120
we're in a a a long game i use the term

572
00:22:08,880 --> 00:22:12,720
long game before

573
00:22:11,120 --> 00:22:14,959
when talking about the surveillance

574
00:22:12,720 --> 00:22:18,640
capitalists and their

575
00:22:14,960 --> 00:22:21,679
v you know their very grand aims

576
00:22:18,640 --> 00:22:24,080
not only for the the growth of their

577
00:22:21,679 --> 00:22:25,679
empires but that their empires will

578
00:22:24,080 --> 00:22:29,199
eventually

579
00:22:25,679 --> 00:22:32,240
displace democratic governance

580
00:22:29,200 --> 00:22:34,960
dis displace the social order as

581
00:22:32,240 --> 00:22:37,200
we know it that may sound a little

582
00:22:34,960 --> 00:22:39,440
fantastical a little science fictiony

583
00:22:37,200 --> 00:22:39,440
but

584
00:22:39,520 --> 00:22:42,879
i've had my head in this for long enough

585
00:22:42,559 --> 00:22:46,080
to

586
00:22:42,880 --> 00:22:47,120
persuade myself that that is not at all

587
00:22:46,080 --> 00:22:50,399
science fiction a

588
00:22:47,120 --> 00:22:54,320
unfortunately um

589
00:22:50,400 --> 00:22:56,799
so so we're talking about

590
00:22:54,320 --> 00:22:59,039
thinking in terms of decades natalie

591
00:22:56,799 --> 00:23:02,000
this is the first thing

592
00:22:59,039 --> 00:23:02,640
uh thinking in terms of decades means

593
00:23:02,000 --> 00:23:05,120
that

594
00:23:02,640 --> 00:23:08,320
you know these the first two decades of

595
00:23:05,120 --> 00:23:08,320
the 21st century

596
00:23:09,200 --> 00:23:15,520
have been essentially gifted

597
00:23:12,320 --> 00:23:19,200
to surveillance capitalists

598
00:23:15,520 --> 00:23:22,240
there has been almost no law

599
00:23:19,200 --> 00:23:26,159
to repel their action

600
00:23:22,240 --> 00:23:29,280
to constrain their stealing

601
00:23:26,159 --> 00:23:34,159
on the contrary there have been

602
00:23:29,280 --> 00:23:38,720
arrangements largely born of 9 11.

603
00:23:34,159 --> 00:23:42,320
what's that largely born of 911

604
00:23:38,720 --> 00:23:44,320
that um that have created this a

605
00:23:42,320 --> 00:23:45,439
convergence of interest between

606
00:23:44,320 --> 00:23:47,520
government

607
00:23:45,440 --> 00:23:49,360
and the and the growth and the power of

608
00:23:47,520 --> 00:23:50,320
the tech companies and and now we're

609
00:23:49,360 --> 00:23:53,360
kind of

610
00:23:50,320 --> 00:23:55,360
you know eating this uh rotten lunch

611
00:23:53,360 --> 00:23:57,120
that that we've set the table for for

612
00:23:55,360 --> 00:23:59,678
for two decades

613
00:23:57,120 --> 00:24:01,678
so my view is that we've got the next

614
00:23:59,679 --> 00:24:03,039
decade to really get serious about

615
00:24:01,679 --> 00:24:04,640
turning this around

616
00:24:03,039 --> 00:24:07,279
it's not going to be one legislative

617
00:24:04,640 --> 00:24:09,520
cycle it's not going to be one big idea

618
00:24:07,279 --> 00:24:12,240
we've got to think about new charters of

619
00:24:09,520 --> 00:24:14,320
rights we've got to think about

620
00:24:12,240 --> 00:24:17,120
new legal frameworks we have to think

621
00:24:14,320 --> 00:24:19,520
about different regulatory paradigms and

622
00:24:17,120 --> 00:24:20,479
we have to think about new institutional

623
00:24:19,520 --> 00:24:22,720
forms

624
00:24:20,480 --> 00:24:23,520
all of those are going to be necessary

625
00:24:22,720 --> 00:24:26,559
in this next

626
00:24:23,520 --> 00:24:28,879
next decade three of the biggest

627
00:24:26,559 --> 00:24:29,600
problems when people try to do something

628
00:24:28,880 --> 00:24:32,960
here

629
00:24:29,600 --> 00:24:36,320
number one they focus on effects

630
00:24:32,960 --> 00:24:39,520
not causes the effects are very

631
00:24:36,320 --> 00:24:41,039
important but unless we get to causes

632
00:24:39,520 --> 00:24:42,559
those effects are going to come back and

633
00:24:41,039 --> 00:24:46,000
back and back

634
00:24:42,559 --> 00:24:49,279
example we're focused on disinformation

635
00:24:46,000 --> 00:24:52,640
rightly so because it is like a a knife

636
00:24:49,279 --> 00:24:53,039
just you know hatching its way through

637
00:24:52,640 --> 00:24:55,120
our

638
00:24:53,039 --> 00:24:56,400
our democracies and through our social

639
00:24:55,120 --> 00:24:58,799
order

640
00:24:56,400 --> 00:24:59,840
but we can't just focus on

641
00:24:58,799 --> 00:25:02,559
disinformation

642
00:24:59,840 --> 00:25:04,399
because it's an effect it's an effect of

643
00:25:02,559 --> 00:25:05,120
the economic logic we've been talking

644
00:25:04,400 --> 00:25:08,360
about

645
00:25:05,120 --> 00:25:11,360
we've got to get to the mechanisms that

646
00:25:08,360 --> 00:25:12,719
incentivize practices that produce

647
00:25:11,360 --> 00:25:14,959
disinformation

648
00:25:12,720 --> 00:25:16,000
if we don't do that we're just chasing

649
00:25:14,960 --> 00:25:19,039
our tail

650
00:25:16,000 --> 00:25:21,120
in a kind of rhetorical arms race with

651
00:25:19,039 --> 00:25:24,320
people like mark zuckerberg

652
00:25:21,120 --> 00:25:26,239
and look where that's getting us so um

653
00:25:24,320 --> 00:25:28,480
we also have to understand that we're

654
00:25:26,240 --> 00:25:30,640
not talking about one company

655
00:25:28,480 --> 00:25:32,000
we're not even only talking about the

656
00:25:30,640 --> 00:25:34,480
tech sector

657
00:25:32,000 --> 00:25:35,600
right now the same economic logic has

658
00:25:34,480 --> 00:25:38,159
spread across

659
00:25:35,600 --> 00:25:39,279
every aspect of the normal economy so

660
00:25:38,159 --> 00:25:42,799
we've got to think

661
00:25:39,279 --> 00:25:46,720
in terms of what are the you know

662
00:25:42,799 --> 00:25:49,840
the sort of dominant uh paradigms

663
00:25:46,720 --> 00:25:51,760
economic paradigms that are producing

664
00:25:49,840 --> 00:25:54,879
wealth in our society

665
00:25:51,760 --> 00:25:55,760
and we have to intervene in those in

666
00:25:54,880 --> 00:25:58,960
order to both

667
00:25:55,760 --> 00:26:02,240
interrupt and criminalize those

668
00:25:58,960 --> 00:26:05,600
key mechanisms and and methods

669
00:26:02,240 --> 00:26:07,600
um and the the the

670
00:26:05,600 --> 00:26:09,840
third thing i would add is that we have

671
00:26:07,600 --> 00:26:12,080
to be mindful that

672
00:26:09,840 --> 00:26:13,678
this trajectory that we're on toward the

673
00:26:12,080 --> 00:26:16,559
digital future right now

674
00:26:13,679 --> 00:26:18,559
is being authored in the west by

675
00:26:16,559 --> 00:26:21,678
surveillance capitalism

676
00:26:18,559 --> 00:26:25,200
in the uh in countries like china

677
00:26:21,679 --> 00:26:28,000
and in other authoritarian countries

678
00:26:25,200 --> 00:26:29,760
what we see is a kind of merging of the

679
00:26:28,000 --> 00:26:31,679
authoritarian state with these

680
00:26:29,760 --> 00:26:34,960
instrumentarian powers

681
00:26:31,679 --> 00:26:38,320
and increasingly we see those

682
00:26:34,960 --> 00:26:39,200
those very same kinds of convergences

683
00:26:38,320 --> 00:26:44,000
occurring

684
00:26:39,200 --> 00:26:47,440
here in the west and in the u.s

685
00:26:44,000 --> 00:26:48,400
this is very dangerous and we we need to

686
00:26:47,440 --> 00:26:51,520
be able to

687
00:26:48,400 --> 00:26:54,159
to constantly tease apart what state

688
00:26:51,520 --> 00:26:55,440
what's market and where are the levers

689
00:26:54,159 --> 00:26:59,919
of change

690
00:26:55,440 --> 00:26:59,919
so what do we do

691
00:27:00,240 --> 00:27:05,520
in the year 2020 we face a very

692
00:27:03,760 --> 00:27:07,520
different reality than we did in the

693
00:27:05,520 --> 00:27:10,559
year 2001

694
00:27:07,520 --> 00:27:12,480
uh when the twin towers were hit which

695
00:27:10,559 --> 00:27:14,000
also coincidentally was the year that

696
00:27:12,480 --> 00:27:17,200
surveillance capitalism

697
00:27:14,000 --> 00:27:18,320
was first discovered at google invented

698
00:27:17,200 --> 00:27:21,520
at google

699
00:27:18,320 --> 00:27:21,918
all right um back then we were talking

700
00:27:21,520 --> 00:27:24,639
about

701
00:27:21,919 --> 00:27:25,520
baby companies um right now we're

702
00:27:24,640 --> 00:27:28,559
talking about

703
00:27:25,520 --> 00:27:32,240
information empires these are two

704
00:27:28,559 --> 00:27:34,720
very distinct time frames very distinct

705
00:27:32,240 --> 00:27:37,440
conditions of existence

706
00:27:34,720 --> 00:27:40,880
we have lawmakers now around the world

707
00:27:37,440 --> 00:27:42,720
who are beginning to mobilize

708
00:27:40,880 --> 00:27:45,360
when those lawmakers go to work every

709
00:27:42,720 --> 00:27:49,440
day in the eu

710
00:27:45,360 --> 00:27:52,719
in the european commission in the uk

711
00:27:49,440 --> 00:27:54,640
houses of parliament and in the united

712
00:27:52,720 --> 00:27:55,440
states congress in the house and in the

713
00:27:54,640 --> 00:27:57,600
senate

714
00:27:55,440 --> 00:27:59,440
when they go to work every day the

715
00:27:57,600 --> 00:28:00,959
people who are ringing their phones and

716
00:27:59,440 --> 00:28:02,640
knocking on their doors

717
00:28:00,960 --> 00:28:05,840
are the lobbyists for surveillance

718
00:28:02,640 --> 00:28:09,520
capitalism we need to change that

719
00:28:05,840 --> 00:28:10,240
that means we need to organize we are no

720
00:28:09,520 --> 00:28:14,000
longer

721
00:28:10,240 --> 00:28:17,440
users that's a name that they gave us

722
00:28:14,000 --> 00:28:18,080
an anonymous global undifferentiated

723
00:28:17,440 --> 00:28:20,159
group

724
00:28:18,080 --> 00:28:21,279
whose only identity derives from our

725
00:28:20,159 --> 00:28:25,360
relationship

726
00:28:21,279 --> 00:28:27,120
to their machines we are no longer users

727
00:28:25,360 --> 00:28:29,039
we need to think of ourselves as

728
00:28:27,120 --> 00:28:32,239
democratic citizens

729
00:28:29,039 --> 00:28:34,640
facing intolerable conditions

730
00:28:32,240 --> 00:28:36,720
that in a democratic society we should

731
00:28:34,640 --> 00:28:39,840
never be asked to face

732
00:28:36,720 --> 00:28:40,240
the fact that chris cannot share his

733
00:28:39,840 --> 00:28:43,360
face

734
00:28:40,240 --> 00:28:45,600
on the internet the fact that our

735
00:28:43,360 --> 00:28:46,479
our families and our friends and our

736
00:28:45,600 --> 00:28:50,080
children

737
00:28:46,480 --> 00:28:52,559
are out protesting wearing masks

738
00:28:50,080 --> 00:28:55,120
not to protect themselves from predators

739
00:28:52,559 --> 00:28:58,559
not to protect themselves from

740
00:28:55,120 --> 00:29:01,439
uh pandemic but to protect themselves

741
00:28:58,559 --> 00:29:02,399
from surveillance systems public and

742
00:29:01,440 --> 00:29:04,399
private

743
00:29:02,399 --> 00:29:05,678
in this new convergence and

744
00:29:04,399 --> 00:29:08,719
collaboration

745
00:29:05,679 --> 00:29:10,840
that is an intolerable situation that is

746
00:29:08,720 --> 00:29:12,320
fundamentally incompatible with

747
00:29:10,840 --> 00:29:15,120
democracy

748
00:29:12,320 --> 00:29:17,439
so we need to organize the way people

749
00:29:15,120 --> 00:29:19,520
have organized throughout the ages

750
00:29:17,440 --> 00:29:21,039
in the civil rights movement in the

751
00:29:19,520 --> 00:29:23,600
union movement

752
00:29:21,039 --> 00:29:25,279
and what we call our organizations and

753
00:29:23,600 --> 00:29:28,399
how we collaborate

754
00:29:25,279 --> 00:29:30,880
and the content of what we want to

755
00:29:28,399 --> 00:29:32,080
achieve those things will be different

756
00:29:30,880 --> 00:29:35,120
and they will be

757
00:29:32,080 --> 00:29:38,799
specific to our material moment

758
00:29:35,120 --> 00:29:40,320
our moment in history but lawmakers need

759
00:29:38,799 --> 00:29:43,760
to feel that

760
00:29:40,320 --> 00:29:48,799
we are pressing them at their backs

761
00:29:43,760 --> 00:29:52,559
that we will not we will not um

762
00:29:48,799 --> 00:29:55,120
we will not in any way

763
00:29:52,559 --> 00:29:56,720
stop mobilizing we will not in any way

764
00:29:55,120 --> 00:29:59,760
let up the pressure we will not

765
00:29:56,720 --> 00:30:02,399
in any way release so this

766
00:29:59,760 --> 00:30:04,000
is the work that the kind of work that

767
00:30:02,399 --> 00:30:08,199
amnesty can do

768
00:30:04,000 --> 00:30:11,919
and it's creating um um

769
00:30:08,200 --> 00:30:14,080
collaborations across the key activist

770
00:30:11,919 --> 00:30:17,360
groups around the world

771
00:30:14,080 --> 00:30:21,199
who who already have hubs available

772
00:30:17,360 --> 00:30:23,520
around which we can mobilize into

773
00:30:21,200 --> 00:30:24,720
new kinds of chapters and networks and

774
00:30:23,520 --> 00:30:28,240
systems

775
00:30:24,720 --> 00:30:30,159
um so so this is one of the key things

776
00:30:28,240 --> 00:30:31,360
at the other end of the spectrum we have

777
00:30:30,159 --> 00:30:33,919
to be thinking about

778
00:30:31,360 --> 00:30:35,600
law in a different way if we're going to

779
00:30:33,919 --> 00:30:38,080
mobilize and put

780
00:30:35,600 --> 00:30:39,520
a fundamentally new level of pressure on

781
00:30:38,080 --> 00:30:41,760
our lawmakers

782
00:30:39,520 --> 00:30:43,279
we have to have things for them to do

783
00:30:41,760 --> 00:30:44,960
that are going to cut to the heart of

784
00:30:43,279 --> 00:30:46,799
this situation

785
00:30:44,960 --> 00:30:50,159
right now they're you know they're in

786
00:30:46,799 --> 00:30:51,679
congress talking about antitrust

787
00:30:50,159 --> 00:30:54,559
there's nothing wrong with talking about

788
00:30:51,679 --> 00:30:59,200
antitrust and in some cases

789
00:30:54,559 --> 00:31:02,399
making some of these empires smaller

790
00:30:59,200 --> 00:31:04,320
will actually be productive in some

791
00:31:02,399 --> 00:31:07,439
cases it won't be

792
00:31:04,320 --> 00:31:10,480
but we have to be working toward

793
00:31:07,440 --> 00:31:11,760
new kinds of laws that interrupt and

794
00:31:10,480 --> 00:31:14,399
criminalize

795
00:31:11,760 --> 00:31:16,720
the new mechanisms the mechanisms that

796
00:31:14,399 --> 00:31:19,120
were invented in the 20th century

797
00:31:16,720 --> 00:31:20,960
the mechanisms that do not pertain to

798
00:31:19,120 --> 00:31:22,959
monopoly as we know it and let me give

799
00:31:20,960 --> 00:31:26,080
you two examples

800
00:31:22,960 --> 00:31:29,840
right now these companies have

801
00:31:26,080 --> 00:31:33,199
fought for the right to take our bodies

802
00:31:29,840 --> 00:31:34,320
our faces our experience wherever they

803
00:31:33,200 --> 00:31:36,159
can get it

804
00:31:34,320 --> 00:31:38,158
they have fought for the right to use

805
00:31:36,159 --> 00:31:40,960
hidden mechanisms

806
00:31:38,159 --> 00:31:42,399
that are engineered with a great deal of

807
00:31:40,960 --> 00:31:45,760
skill and capital

808
00:31:42,399 --> 00:31:49,039
to bypass our awareness to be hidden

809
00:31:45,760 --> 00:31:52,000
ergo the word surveillance capitalism

810
00:31:49,039 --> 00:31:53,919
if these mechanisms were out in the open

811
00:31:52,000 --> 00:31:57,039
they could not

812
00:31:53,919 --> 00:31:58,080
they could not produce these global

813
00:31:57,039 --> 00:31:59,760
supply chains

814
00:31:58,080 --> 00:32:02,480
full of data flows that they have they

815
00:31:59,760 --> 00:32:04,399
could not produce the ai that they have

816
00:32:02,480 --> 00:32:07,679
whereas we know about

817
00:32:04,399 --> 00:32:10,399
facebook's ai hub

818
00:32:07,679 --> 00:32:11,200
trillions of data points crunched every

819
00:32:10,399 --> 00:32:13,120
day

820
00:32:11,200 --> 00:32:15,519
six million predictions of human

821
00:32:13,120 --> 00:32:18,559
behavior produced every second

822
00:32:15,519 --> 00:32:19,200
right so if these systems were out in

823
00:32:18,559 --> 00:32:21,678
the open

824
00:32:19,200 --> 00:32:22,640
that simply would not be possible scale

825
00:32:21,679 --> 00:32:25,840
and scope

826
00:32:22,640 --> 00:32:29,919
let alone action okay so

827
00:32:25,840 --> 00:32:32,720
we have to come backward

828
00:32:29,919 --> 00:32:34,080
from this activity virtually everything

829
00:32:32,720 --> 00:32:37,039
that we've done

830
00:32:34,080 --> 00:32:38,799
is about data protection data privacy

831
00:32:37,039 --> 00:32:42,240
data portability

832
00:32:38,799 --> 00:32:45,600
data rights everything begins with

833
00:32:42,240 --> 00:32:46,880
data if we begin with data we have

834
00:32:45,600 --> 00:32:49,678
already lost

835
00:32:46,880 --> 00:32:51,039
this struggle data means the horse is

836
00:32:49,679 --> 00:32:52,880
out of the barn

837
00:32:51,039 --> 00:32:55,200
data means they've already taken our

838
00:32:52,880 --> 00:32:56,159
faces and translated them into data for

839
00:32:55,200 --> 00:32:59,279
facial recognition

840
00:32:56,159 --> 00:33:00,000
systems and everything else we have to

841
00:32:59,279 --> 00:33:04,000
come

842
00:33:00,000 --> 00:33:06,320
before data and this begins with a new

843
00:33:04,000 --> 00:33:09,440
charter of fundamental rights that

844
00:33:06,320 --> 00:33:10,960
asks who gets to know about my

845
00:33:09,440 --> 00:33:14,080
experience

846
00:33:10,960 --> 00:33:18,000
this is what i call epistemic rights

847
00:33:14,080 --> 00:33:21,039
who knows who decides who knows

848
00:33:18,000 --> 00:33:22,960
knowledge authority who decides who

849
00:33:21,039 --> 00:33:26,158
decides who knows

850
00:33:22,960 --> 00:33:28,640
knowledge authority and power

851
00:33:26,159 --> 00:33:30,519
these fundamental rights which have

852
00:33:28,640 --> 00:33:32,399
always been considered

853
00:33:30,519 --> 00:33:34,880
inalienable they've always been

854
00:33:32,399 --> 00:33:39,199
considered elemental

855
00:33:34,880 --> 00:33:40,880
just like before we had a juridical

856
00:33:39,200 --> 00:33:43,039
right to freedom of speech

857
00:33:40,880 --> 00:33:44,320
a constitutional right to freedom of

858
00:33:43,039 --> 00:33:46,720
speech

859
00:33:44,320 --> 00:33:48,480
no money was going around saying hey i

860
00:33:46,720 --> 00:33:51,440
need a right to speak

861
00:33:48,480 --> 00:33:52,720
if you're healthy and your lungs and

862
00:33:51,440 --> 00:33:54,240
everything work

863
00:33:52,720 --> 00:33:56,080
you can open your mouth and you can

864
00:33:54,240 --> 00:33:58,000
speak you didn't need a right this was

865
00:33:56,080 --> 00:34:00,480
something elemental

866
00:33:58,000 --> 00:34:02,559
it was only when society achieved that

867
00:34:00,480 --> 00:34:04,080
state of complexity and political

868
00:34:02,559 --> 00:34:06,559
density

869
00:34:04,080 --> 00:34:08,560
where some people wanted to stop the

870
00:34:06,559 --> 00:34:10,639
voices of other people

871
00:34:08,560 --> 00:34:12,000
that we had to have a right to free

872
00:34:10,639 --> 00:34:15,040
speech

873
00:34:12,000 --> 00:34:16,560
that is a certain moment in history when

874
00:34:15,040 --> 00:34:19,759
elemental rights

875
00:34:16,560 --> 00:34:22,000
converge with political power

876
00:34:19,760 --> 00:34:24,240
we are at that moment now when it comes

877
00:34:22,000 --> 00:34:27,599
to epistemic rights

878
00:34:24,239 --> 00:34:29,839
they have no right to know my face

879
00:34:27,599 --> 00:34:31,839
to know about my emotions from what they

880
00:34:29,839 --> 00:34:34,399
can read in my face

881
00:34:31,839 --> 00:34:35,279
from what their systems can tell about

882
00:34:34,399 --> 00:34:38,719
my

883
00:34:35,280 --> 00:34:43,280
my my feelings my fears and

884
00:34:38,719 --> 00:34:46,638
my anticipations for my immediate future

885
00:34:43,280 --> 00:34:49,440
so we have to get back to

886
00:34:46,639 --> 00:34:51,520
the elemental rights i am the one who

887
00:34:49,440 --> 00:34:55,119
gets to know my experience

888
00:34:51,520 --> 00:34:57,759
and i am the one who decides who knows

889
00:34:55,119 --> 00:34:59,839
and uh all of that happens under the

890
00:34:57,760 --> 00:35:01,200
rubric of the rule of law and democratic

891
00:34:59,839 --> 00:35:04,560
governance

892
00:35:01,200 --> 00:35:08,799
so coming back to this

893
00:35:04,560 --> 00:35:11,200
deeper level of rights is natalie

894
00:35:08,800 --> 00:35:12,560
one of the key places we have to start

895
00:35:11,200 --> 00:35:14,879
final point

896
00:35:12,560 --> 00:35:17,839
on the other end of the spectrum of this

897
00:35:14,880 --> 00:35:20,160
logic remember the logic begins with

898
00:35:17,839 --> 00:35:21,279
taking our experience translating it

899
00:35:20,160 --> 00:35:24,799
into data

900
00:35:21,280 --> 00:35:27,119
i'm contesting that but it ends with

901
00:35:24,800 --> 00:35:28,880
selling predictions about us into human

902
00:35:27,119 --> 00:35:32,400
futures markets

903
00:35:28,880 --> 00:35:35,599
i want to say that human futures markets

904
00:35:32,400 --> 00:35:36,000
need to be criminalized they need to be

905
00:35:35,599 --> 00:35:39,839
made

906
00:35:36,000 --> 00:35:41,880
illegal they cannot stand human futures

907
00:35:39,839 --> 00:35:44,640
markets have predictably

908
00:35:41,880 --> 00:35:45,599
anti-democratic consequences those

909
00:35:44,640 --> 00:35:48,560
consequences

910
00:35:45,599 --> 00:35:50,960
are already clear the economic

911
00:35:48,560 --> 00:35:53,839
imperatives of surveillance capitalism

912
00:35:50,960 --> 00:35:54,800
are a direct result of the financial

913
00:35:53,839 --> 00:35:57,839
incentives

914
00:35:54,800 --> 00:36:01,119
in those markets

915
00:35:57,839 --> 00:36:01,520
we will have information empires trying

916
00:36:01,119 --> 00:36:04,800
to

917
00:36:01,520 --> 00:36:08,079
know and control human behavior as long

918
00:36:04,800 --> 00:36:10,240
as their revenue flows depend on

919
00:36:08,079 --> 00:36:11,599
their sales of certainty into those

920
00:36:10,240 --> 00:36:14,720
markets

921
00:36:11,599 --> 00:36:17,760
we have outlawed other kinds of markets

922
00:36:14,720 --> 00:36:20,160
uh in our civilization we have outlawed

923
00:36:17,760 --> 00:36:20,800
slave markets we have outlaw markets

924
00:36:20,160 --> 00:36:23,839
that

925
00:36:20,800 --> 00:36:26,320
uh sell babies we have outlawed markets

926
00:36:23,839 --> 00:36:29,359
that sell human organs

927
00:36:26,320 --> 00:36:33,359
these human futures markets are

928
00:36:29,359 --> 00:36:37,520
also pernicious violent

929
00:36:33,359 --> 00:36:42,000
and regularly inevitably

930
00:36:37,520 --> 00:36:45,040
undermine democracy to the point that

931
00:36:42,000 --> 00:36:48,480
they are fundamentally

932
00:36:45,040 --> 00:36:52,640
incompatible with democracy so

933
00:36:48,480 --> 00:36:56,560
here are two ideas for how we begin to

934
00:36:52,640 --> 00:36:59,839
intervene in the foundations with rights

935
00:36:56,560 --> 00:37:03,040
and how we begin to criminalize to

936
00:36:59,839 --> 00:37:04,160
outlaw key mechanisms and financial

937
00:37:03,040 --> 00:37:07,599
incentives

938
00:37:04,160 --> 00:37:10,960
that drive this logic

939
00:37:07,599 --> 00:37:12,079
people will ask wait a minute does that

940
00:37:10,960 --> 00:37:14,960
mean i'm no longer be

941
00:37:12,079 --> 00:37:16,240
going to be able to have you know search

942
00:37:14,960 --> 00:37:17,520
does that mean i'm no longer

943
00:37:16,240 --> 00:37:20,160
no longer going to be able to have a

944
00:37:17,520 --> 00:37:21,759
social network and let me just close on

945
00:37:20,160 --> 00:37:25,200
this one point

946
00:37:21,760 --> 00:37:27,359
we will have all of that because that

947
00:37:25,200 --> 00:37:31,279
belongs to the digital

948
00:37:27,359 --> 00:37:35,598
and once we eliminate the surveillance

949
00:37:31,280 --> 00:37:38,160
dividend from the economic landscape

950
00:37:35,599 --> 00:37:38,960
we will have thousands of tens of

951
00:37:38,160 --> 00:37:42,399
thousands and

952
00:37:38,960 --> 00:37:45,440
hundreds of thousands of entrepreneurs

953
00:37:42,400 --> 00:37:47,680
and technologists and designers and

954
00:37:45,440 --> 00:37:49,119
and all kinds of people who want to come

955
00:37:47,680 --> 00:37:51,440
on stream

956
00:37:49,119 --> 00:37:52,720
and take digital technology and put it

957
00:37:51,440 --> 00:37:57,280
to work for people

958
00:37:52,720 --> 00:38:01,040
and society without the anti-democratic

959
00:37:57,280 --> 00:38:03,520
violent and dangerous in their own way

960
00:38:01,040 --> 00:38:06,240
externalities of instrumentarian power

961
00:38:03,520 --> 00:38:09,280
and anti-democracy

962
00:38:06,240 --> 00:38:12,078
that we buy every time we engage with

963
00:38:09,280 --> 00:38:14,240
a smart product a personalized service a

964
00:38:12,079 --> 00:38:15,680
supply chain interface of surveillance

965
00:38:14,240 --> 00:38:17,680
capitalism

966
00:38:15,680 --> 00:38:18,879
all of that new competition new

967
00:38:17,680 --> 00:38:21,520
capability

968
00:38:18,880 --> 00:38:23,440
is out there but it's out there in a way

969
00:38:21,520 --> 00:38:26,160
that is ready to be designed

970
00:38:23,440 --> 00:38:29,200
on our terms on the terms of a

971
00:38:26,160 --> 00:38:29,200
democratic future

972
00:38:30,160 --> 00:38:32,960
thank you very much shashana it

973
00:38:31,599 --> 00:38:34,880
certainly sounds like we have a lot of

974
00:38:32,960 --> 00:38:38,079
work to do over the next decade and

975
00:38:34,880 --> 00:38:39,920
and possibly beyond um joe what what do

976
00:38:38,079 --> 00:38:40,720
you see as some of the most active

977
00:38:39,920 --> 00:38:42,640
efforts by

978
00:38:40,720 --> 00:38:44,399
activists and advocates to tackle the

979
00:38:42,640 --> 00:38:46,240
system of surveillance capitalism right

980
00:38:44,400 --> 00:38:47,680
now and how well do these efforts align

981
00:38:46,240 --> 00:38:50,319
with what shashana just

982
00:38:47,680 --> 00:38:50,319
just lined up

983
00:38:51,119 --> 00:38:54,880
thanks well i mean i think as shashana

984
00:38:53,760 --> 00:38:57,359
said you know

985
00:38:54,880 --> 00:38:58,640
is creating these these connections and

986
00:38:57,359 --> 00:39:01,359
these collaborations

987
00:38:58,640 --> 00:39:02,879
across all the different movements kind

988
00:39:01,359 --> 00:39:04,960
of working in this space and

989
00:39:02,880 --> 00:39:06,079
you know i don't pretend to speak to all

990
00:39:04,960 --> 00:39:09,280
the

991
00:39:06,079 --> 00:39:11,440
amazing work that's already happening um

992
00:39:09,280 --> 00:39:13,520
but uh i can highlight a few interesting

993
00:39:11,440 --> 00:39:14,320
examples of relevant work that i'm

994
00:39:13,520 --> 00:39:15,759
seeing

995
00:39:14,320 --> 00:39:17,359
i mean i think obviously the digital

996
00:39:15,760 --> 00:39:19,680
rights and privacy movement have

997
00:39:17,359 --> 00:39:20,960
been warning about this for years and in

998
00:39:19,680 --> 00:39:22,399
some cases decades

999
00:39:20,960 --> 00:39:24,720
i think it's interesting how it's

1000
00:39:22,400 --> 00:39:26,960
increasingly involving wider and wider

1001
00:39:24,720 --> 00:39:29,439
and more diverse set of groups at

1002
00:39:26,960 --> 00:39:30,720
national regional local levels i mean i

1003
00:39:29,440 --> 00:39:33,680
think obviously

1004
00:39:30,720 --> 00:39:34,160
you know the very current example is the

1005
00:39:33,680 --> 00:39:36,078
the

1006
00:39:34,160 --> 00:39:37,839
um civil rights and racial justice

1007
00:39:36,079 --> 00:39:38,720
organizations leading the campaign on

1008
00:39:37,839 --> 00:39:41,119
facebook

1009
00:39:38,720 --> 00:39:43,279
to stop pay for profit linking it to the

1010
00:39:41,119 --> 00:39:45,520
fight against structural racism

1011
00:39:43,280 --> 00:39:47,200
um i think it's interesting to see

1012
00:39:45,520 --> 00:39:49,599
consumer rights groups

1013
00:39:47,200 --> 00:39:51,200
um being really active on this area like

1014
00:39:49,599 --> 00:39:54,880
the work of the norwegian

1015
00:39:51,200 --> 00:39:57,359
consumer council on ad tech um

1016
00:39:54,880 --> 00:39:59,920
competition law is obviously one lever

1017
00:39:57,359 --> 00:40:02,078
that as shashana mentioned and there's

1018
00:39:59,920 --> 00:40:03,680
um privacy international and others

1019
00:40:02,079 --> 00:40:05,280
campaigning to challenge the google

1020
00:40:03,680 --> 00:40:08,799
fitbit merger

1021
00:40:05,280 --> 00:40:12,160
um i think strategic litigation will be

1022
00:40:08,800 --> 00:40:14,880
vital um like the work of

1023
00:40:12,160 --> 00:40:15,839
max schrems organization um and others

1024
00:40:14,880 --> 00:40:19,440
in europe

1025
00:40:15,839 --> 00:40:20,240
um i think connecting with with global

1026
00:40:19,440 --> 00:40:22,160
movements

1027
00:40:20,240 --> 00:40:23,520
i think is is also going to be a huge

1028
00:40:22,160 --> 00:40:25,118
priority for the future

1029
00:40:23,520 --> 00:40:27,520
you know this is from a few years ago

1030
00:40:25,119 --> 00:40:29,599
but indian activists succeeded in

1031
00:40:27,520 --> 00:40:30,640
blocking facebook's free basics in the

1032
00:40:29,599 --> 00:40:33,839
country

1033
00:40:30,640 --> 00:40:35,200
um a few years ago

1034
00:40:33,839 --> 00:40:36,880
and then i think at the local level

1035
00:40:35,200 --> 00:40:38,319
that's also where there's that it's

1036
00:40:36,880 --> 00:40:41,440
really interesting to see

1037
00:40:38,319 --> 00:40:44,720
um campaigns and activism like the um

1038
00:40:41,440 --> 00:40:45,760
success of activists stopping alphabet's

1039
00:40:44,720 --> 00:40:49,200
um

1040
00:40:45,760 --> 00:40:51,040
cyborg toronto smart city project which

1041
00:40:49,200 --> 00:40:53,359
shana had previously called the new

1042
00:40:51,040 --> 00:40:55,359
frontier of surveillance capitalism

1043
00:40:53,359 --> 00:40:57,520
and but of course like connected to this

1044
00:40:55,359 --> 00:41:00,078
we'll need lots of advocacy

1045
00:40:57,520 --> 00:41:01,359
um to shape strong future stake

1046
00:41:00,079 --> 00:41:04,960
regulation like the work

1047
00:41:01,359 --> 00:41:07,119
of many of the groups that writes on

1048
00:41:04,960 --> 00:41:08,319
things like the the european digital

1049
00:41:07,119 --> 00:41:11,520
services act

1050
00:41:08,319 --> 00:41:12,800
but i think it is it's it's quite

1051
00:41:11,520 --> 00:41:14,400
exciting to see the

1052
00:41:12,800 --> 00:41:16,079
the opportunity to kind of pull all

1053
00:41:14,400 --> 00:41:18,079
these strands together to create a kind

1054
00:41:16,079 --> 00:41:20,000
of connected and diverse

1055
00:41:18,079 --> 00:41:22,319
global movement working on on these

1056
00:41:20,000 --> 00:41:22,319
issues

1057
00:41:26,000 --> 00:41:30,560
yes right now in many respects but

1058
00:41:28,640 --> 00:41:31,759
specifically with respect to data

1059
00:41:30,560 --> 00:41:33,920
surveillance and servant

1060
00:41:31,760 --> 00:41:35,520
and civil rights including black lives

1061
00:41:33,920 --> 00:41:37,119
matter and the stop paid for profit

1062
00:41:35,520 --> 00:41:38,960
campaign that joe mentioned

1063
00:41:37,119 --> 00:41:40,880
how do you see the connection between

1064
00:41:38,960 --> 00:41:42,240
today's civil rights movement and all of

1065
00:41:40,880 --> 00:41:43,839
its manifestations

1066
00:41:42,240 --> 00:41:46,479
and this fight to roll back surveillance

1067
00:41:43,839 --> 00:41:49,680
capitalism

1068
00:41:46,480 --> 00:41:52,960
well i think um it's really

1069
00:41:49,680 --> 00:41:55,440
impossible to uh

1070
00:41:52,960 --> 00:41:57,040
separate or divorce policing white

1071
00:41:55,440 --> 00:42:00,240
supremacy

1072
00:41:57,040 --> 00:42:02,880
surveillance and tech platforms i think

1073
00:42:00,240 --> 00:42:05,680
we can't really address one of them

1074
00:42:02,880 --> 00:42:06,000
without addressing all of them uh you

1075
00:42:05,680 --> 00:42:07,839
know

1076
00:42:06,000 --> 00:42:09,920
and i think more and more people are

1077
00:42:07,839 --> 00:42:13,279
coming to that realization

1078
00:42:09,920 --> 00:42:14,960
so for instance as people now across

1079
00:42:13,280 --> 00:42:17,920
the united states but also across the

1080
00:42:14,960 --> 00:42:20,560
world are out in the streets

1081
00:42:17,920 --> 00:42:21,760
fighting and advocating for their rights

1082
00:42:20,560 --> 00:42:24,720
governments are

1083
00:42:21,760 --> 00:42:27,040
deploying surveillance planes and

1084
00:42:24,720 --> 00:42:29,839
automated license plate readers

1085
00:42:27,040 --> 00:42:31,119
facial recognition they're buying this

1086
00:42:29,839 --> 00:42:34,560
information

1087
00:42:31,119 --> 00:42:36,079
from uh various companies and

1088
00:42:34,560 --> 00:42:37,759
you know they're monitoring people's

1089
00:42:36,079 --> 00:42:41,839
social media whether they use

1090
00:42:37,760 --> 00:42:44,079
twitter or facebook or or whatsapp

1091
00:42:41,839 --> 00:42:45,200
and so i think as more people come to

1092
00:42:44,079 --> 00:42:47,680
the realization

1093
00:42:45,200 --> 00:42:49,118
that these these uh systems are all

1094
00:42:47,680 --> 00:42:52,399
intertwined

1095
00:42:49,119 --> 00:42:55,680
um what we're seeing is a demand for

1096
00:42:52,400 --> 00:42:56,480
uh for this to be different yeah i'm so

1097
00:42:55,680 --> 00:42:59,200
glad

1098
00:42:56,480 --> 00:42:59,839
that joe pointed out all these systems

1099
00:42:59,200 --> 00:43:02,720
are

1100
00:42:59,839 --> 00:43:04,880
uh collective harm collectively harmful

1101
00:43:02,720 --> 00:43:06,879
and that shashana talks about

1102
00:43:04,880 --> 00:43:09,119
making some of these things illegal i

1103
00:43:06,880 --> 00:43:11,200
think that's a discussion

1104
00:43:09,119 --> 00:43:13,440
that's been a long time coming but one i

1105
00:43:11,200 --> 00:43:15,839
very much welcome and i think is really

1106
00:43:13,440 --> 00:43:18,400
important

1107
00:43:15,839 --> 00:43:20,160
and so where do you see us domestic

1108
00:43:18,400 --> 00:43:23,440
activism going in the next

1109
00:43:20,160 --> 00:43:24,240
two five ten years uh what where do you

1110
00:43:23,440 --> 00:43:26,240
see

1111
00:43:24,240 --> 00:43:27,680
uh the most promising opportunities to

1112
00:43:26,240 --> 00:43:29,279
counter the expansion of these

1113
00:43:27,680 --> 00:43:31,040
architecture of surveillance

1114
00:43:29,280 --> 00:43:32,319
uh including digital redlining which i

1115
00:43:31,040 --> 00:43:34,720
know is something that you've written a

1116
00:43:32,319 --> 00:43:34,720
lot about

1117
00:43:34,960 --> 00:43:38,720
yeah so the thing i would say again just

1118
00:43:36,960 --> 00:43:42,800
to connect back to

1119
00:43:38,720 --> 00:43:44,000
uh what everyone else has said is

1120
00:43:42,800 --> 00:43:46,400
one of the things that people are

1121
00:43:44,000 --> 00:43:49,520
calling for in the u.s is

1122
00:43:46,400 --> 00:43:51,599
abolishing the police and i

1123
00:43:49,520 --> 00:43:52,960
think it's it's kind of widely

1124
00:43:51,599 --> 00:43:56,160
misunderstood but

1125
00:43:52,960 --> 00:43:58,400
uh or maybe willfully so

1126
00:43:56,160 --> 00:43:59,279
but i i think one of the important

1127
00:43:58,400 --> 00:44:03,280
things to to

1128
00:43:59,280 --> 00:44:05,680
take out of that is we've um

1129
00:44:03,280 --> 00:44:07,119
for so long we've been told particularly

1130
00:44:05,680 --> 00:44:09,200
technology

1131
00:44:07,119 --> 00:44:10,800
that once something exists or when

1132
00:44:09,200 --> 00:44:13,520
something's been invented

1133
00:44:10,800 --> 00:44:15,440
uh for instance facial recognition that

1134
00:44:13,520 --> 00:44:18,000
we can't control it or we have to accept

1135
00:44:15,440 --> 00:44:20,400
the way it's been presented to us

1136
00:44:18,000 --> 00:44:21,440
by platforms and technologists and

1137
00:44:20,400 --> 00:44:23,599
things like that

1138
00:44:21,440 --> 00:44:24,720
i think one of the most important things

1139
00:44:23,599 --> 00:44:27,359
that's coming out of

1140
00:44:24,720 --> 00:44:28,879
movement for black lives and the stop

1141
00:44:27,359 --> 00:44:32,000
pay for profit movement

1142
00:44:28,880 --> 00:44:35,119
is a demand that these things stop

1143
00:44:32,000 --> 00:44:36,800
not a request and the admission or the

1144
00:44:35,119 --> 00:44:38,800
acknowledgement

1145
00:44:36,800 --> 00:44:40,319
and the popularization of the notion

1146
00:44:38,800 --> 00:44:42,560
that some technology

1147
00:44:40,319 --> 00:44:43,440
shouldn't exist some technology should

1148
00:44:42,560 --> 00:44:45,920
be illegal

1149
00:44:43,440 --> 00:44:47,040
some technology should not be deployed

1150
00:44:45,920 --> 00:44:50,240
against

1151
00:44:47,040 --> 00:44:53,759
uh individuals or communities

1152
00:44:50,240 --> 00:44:57,200
and for so long so that is the um

1153
00:44:53,760 --> 00:45:00,960
that is the thing that i i've seen um

1154
00:44:57,200 --> 00:45:03,839
become more and more present more potent

1155
00:45:00,960 --> 00:45:05,520
because even two years ago when you

1156
00:45:03,839 --> 00:45:07,279
would say

1157
00:45:05,520 --> 00:45:08,560
well facial recognition should be banned

1158
00:45:07,280 --> 00:45:11,680
or you know

1159
00:45:08,560 --> 00:45:13,599
something like that people would would

1160
00:45:11,680 --> 00:45:15,359
widely ridicule you

1161
00:45:13,599 --> 00:45:16,800
and we're seeing now in lots of

1162
00:45:15,359 --> 00:45:19,279
different cities and

1163
00:45:16,800 --> 00:45:20,000
dates across the country are doing just

1164
00:45:19,280 --> 00:45:23,920
that

1165
00:45:20,000 --> 00:45:27,440
and so that that uh belief in abolition

1166
00:45:23,920 --> 00:45:29,680
and then stopping harmful

1167
00:45:27,440 --> 00:45:31,280
in its tracks rather than negotiating

1168
00:45:29,680 --> 00:45:33,839
with it i think is a really important

1169
00:45:31,280 --> 00:45:33,839
thing

1170
00:45:34,880 --> 00:45:38,960
so joe uh what what do you think um i

1171
00:45:37,359 --> 00:45:40,720
guess same question for you but with

1172
00:45:38,960 --> 00:45:41,599
respect to european and global

1173
00:45:40,720 --> 00:45:43,919
priorities

1174
00:45:41,599 --> 00:45:44,720
uh where do you see activism going in

1175
00:45:43,920 --> 00:45:47,200
the next

1176
00:45:44,720 --> 00:45:49,598
two five ten years and what are what are

1177
00:45:47,200 --> 00:45:52,240
the most promising opportunities to

1178
00:45:49,599 --> 00:45:52,240
to push back

1179
00:45:53,440 --> 00:45:56,880
well i mean i think as an international

1180
00:45:55,520 --> 00:46:00,160
organization one of

1181
00:45:56,880 --> 00:46:03,599
amnesty's priorities is is the need to

1182
00:46:00,160 --> 00:46:05,598
um look beyond europe and the us and

1183
00:46:03,599 --> 00:46:07,440
show how people's lives are impacted

1184
00:46:05,599 --> 00:46:09,359
differently around the world and i think

1185
00:46:07,440 --> 00:46:10,400
to connect with movements in the global

1186
00:46:09,359 --> 00:46:14,319
south

1187
00:46:10,400 --> 00:46:16,400
to expose you know how this is

1188
00:46:14,319 --> 00:46:17,520
part of a you know what what some people

1189
00:46:16,400 --> 00:46:19,680
have called kind of

1190
00:46:17,520 --> 00:46:21,359
digital colonialism especially

1191
00:46:19,680 --> 00:46:23,759
especially in countries where for

1192
00:46:21,359 --> 00:46:25,839
example facebook is the internet

1193
00:46:23,760 --> 00:46:26,800
um and i think the harms are going to be

1194
00:46:25,839 --> 00:46:28,799
completely

1195
00:46:26,800 --> 00:46:29,839
um different and in some cases more

1196
00:46:28,800 --> 00:46:33,760
severe

1197
00:46:29,839 --> 00:46:36,400
um i mean i think another

1198
00:46:33,760 --> 00:46:37,440
thing which i think is pertinent um in

1199
00:46:36,400 --> 00:46:40,079
the context of

1200
00:46:37,440 --> 00:46:42,000
the pandemic is that we need to keep an

1201
00:46:40,079 --> 00:46:44,640
eye on the expansion um

1202
00:46:42,000 --> 00:46:45,680
to health healthcare and biotech in

1203
00:46:44,640 --> 00:46:48,400
particular

1204
00:46:45,680 --> 00:46:48,879
um i think that under the cover of the

1205
00:46:48,400 --> 00:46:52,079
the

1206
00:46:48,880 --> 00:46:53,760
the covert crisis that that's a real um

1207
00:46:52,079 --> 00:46:55,760
danger and something for activists to

1208
00:46:53,760 --> 00:46:56,560
keep an eye on and but i think you know

1209
00:46:55,760 --> 00:46:59,359
going back to

1210
00:46:56,560 --> 00:47:00,400
shashana's point i think we need to

1211
00:46:59,359 --> 00:47:02,480
continue

1212
00:47:00,400 --> 00:47:03,440
calling out the harms in specific

1213
00:47:02,480 --> 00:47:04,720
contexts

1214
00:47:03,440 --> 00:47:06,560
chipping away at the problem and

1215
00:47:04,720 --> 00:47:08,319
campaigning for wins in the

1216
00:47:06,560 --> 00:47:10,000
in the short term but we also need to

1217
00:47:08,319 --> 00:47:11,920
keep this focus on

1218
00:47:10,000 --> 00:47:13,280
overhauling the underlying structures

1219
00:47:11,920 --> 00:47:16,640
you know

1220
00:47:13,280 --> 00:47:18,400
looking for kind of um seemingly radical

1221
00:47:16,640 --> 00:47:22,078
proposals like chris was saying

1222
00:47:18,400 --> 00:47:24,400
um you know blocking particular pieces

1223
00:47:22,079 --> 00:47:27,920
of tech or particular practices where

1224
00:47:24,400 --> 00:47:29,599
where necessary and really trying to um

1225
00:47:27,920 --> 00:47:32,000
get you know cut to the heart of the

1226
00:47:29,599 --> 00:47:33,920
problem because i do think it's you know

1227
00:47:32,000 --> 00:47:36,000
fundamentally a challenge of governance

1228
00:47:33,920 --> 00:47:39,119
and the governance gap as i said

1229
00:47:36,000 --> 00:47:40,559
um you know and shashana has set out how

1230
00:47:39,119 --> 00:47:42,400
she thinks

1231
00:47:40,559 --> 00:47:45,359
you know his work is on defining these

1232
00:47:42,400 --> 00:47:48,880
new epistemic rights i think

1233
00:47:45,359 --> 00:47:51,520
um our institutions of governance

1234
00:47:48,880 --> 00:47:53,200
you know need to be updated to a certain

1235
00:47:51,520 --> 00:47:54,720
extent to keep pace with the

1236
00:47:53,200 --> 00:47:56,399
the kind of networked information

1237
00:47:54,720 --> 00:47:58,480
economy and

1238
00:47:56,400 --> 00:48:00,640
but you know just finally i think

1239
00:47:58,480 --> 00:48:01,200
obviously as a human rights organization

1240
00:48:00,640 --> 00:48:04,558
i

1241
00:48:01,200 --> 00:48:07,040
we think it's it's vital that we we

1242
00:48:04,559 --> 00:48:07,839
take a human rights-based um approach

1243
00:48:07,040 --> 00:48:10,160
this is

1244
00:48:07,839 --> 00:48:11,839
a global problem and human rights is is

1245
00:48:10,160 --> 00:48:13,040
an established international framework

1246
00:48:11,839 --> 00:48:16,000
grounded

1247
00:48:13,040 --> 00:48:17,920
in binding law um but i think you know

1248
00:48:16,000 --> 00:48:19,680
we also need to be frank human rights

1249
00:48:17,920 --> 00:48:20,960
itself has to evolve to keep pace with

1250
00:48:19,680 --> 00:48:23,200
this to capture

1251
00:48:20,960 --> 00:48:24,559
you know these societal impacts and the

1252
00:48:23,200 --> 00:48:28,480
collective harms

1253
00:48:24,559 --> 00:48:28,480
as well as the the individual impacts

1254
00:48:31,760 --> 00:48:37,040
thank you joe um so shashana in in light

1255
00:48:35,359 --> 00:48:38,640
of everything that you've observed over

1256
00:48:37,040 --> 00:48:41,279
the past several years and

1257
00:48:38,640 --> 00:48:42,160
and what uh chris and joe have shared

1258
00:48:41,280 --> 00:48:44,480
with us

1259
00:48:42,160 --> 00:48:46,960
uh do you see do you see room for for

1260
00:48:44,480 --> 00:48:49,680
optimism here or signs that we should be

1261
00:48:46,960 --> 00:48:50,079
uh optimistic that that we can do this

1262
00:48:49,680 --> 00:48:53,118
and

1263
00:48:50,079 --> 00:48:53,520
uh second part of the question uh what

1264
00:48:53,119 --> 00:48:55,119
should

1265
00:48:53,520 --> 00:48:56,559
what should be the priority for

1266
00:48:55,119 --> 00:48:58,400
activists who are

1267
00:48:56,559 --> 00:49:00,880
seeking to overhaul the system of

1268
00:48:58,400 --> 00:49:03,839
surveillance capitalism and reimagine

1269
00:49:00,880 --> 00:49:03,839
uh the digital world

1270
00:49:05,040 --> 00:49:10,720
well i see nothing but calls for

1271
00:49:08,240 --> 00:49:13,680
optimism uh that may seem a little

1272
00:49:10,720 --> 00:49:17,200
strange but um

1273
00:49:13,680 --> 00:49:18,399
gosh natalie you know uh five years ago

1274
00:49:17,200 --> 00:49:19,279
we couldn't have been having this

1275
00:49:18,400 --> 00:49:21,119
conversation

1276
00:49:19,280 --> 00:49:22,400
even though the the phenomena that we're

1277
00:49:21,119 --> 00:49:26,800
talking about

1278
00:49:22,400 --> 00:49:28,960
uh were well entrenched five years ago

1279
00:49:26,800 --> 00:49:30,000
uh even uh three years ago this

1280
00:49:28,960 --> 00:49:33,119
conversation would

1281
00:49:30,000 --> 00:49:35,520
have been um uh some you know something

1282
00:49:33,119 --> 00:49:38,960
more on the on the fringe

1283
00:49:35,520 --> 00:49:40,480
things have changed and part of what has

1284
00:49:38,960 --> 00:49:43,680
changed and i think that

1285
00:49:40,480 --> 00:49:44,160
um both both chris and and joe were

1286
00:49:43,680 --> 00:49:47,440
speaking

1287
00:49:44,160 --> 00:49:49,759
to this is that um

1288
00:49:47,440 --> 00:49:50,720
you know we've got these these big

1289
00:49:49,760 --> 00:49:55,040
companies

1290
00:49:50,720 --> 00:49:58,959
these huge information empires um

1291
00:49:55,040 --> 00:50:02,240
and um

1292
00:49:58,960 --> 00:50:05,200
we we have been kind of mesmerized

1293
00:50:02,240 --> 00:50:06,879
uh by their messaging for many years you

1294
00:50:05,200 --> 00:50:09,160
know we've been told

1295
00:50:06,880 --> 00:50:10,400
uh we're in a we're in a time of the

1296
00:50:09,160 --> 00:50:12,879
democratization

1297
00:50:10,400 --> 00:50:14,400
of knowledge and the empowerment of the

1298
00:50:12,880 --> 00:50:16,640
individual

1299
00:50:14,400 --> 00:50:18,559
and this was supposed to be the three

1300
00:50:16,640 --> 00:50:21,279
century of them all

1301
00:50:18,559 --> 00:50:23,440
and it's turned out to be the most

1302
00:50:21,280 --> 00:50:25,040
threatened century of them all when it

1303
00:50:23,440 --> 00:50:27,200
comes to freedom

1304
00:50:25,040 --> 00:50:28,880
and democracy when it comes comes to

1305
00:50:27,200 --> 00:50:32,319
human autonomy

1306
00:50:28,880 --> 00:50:33,359
agency self-determination but also when

1307
00:50:32,319 --> 00:50:36,240
it comes to

1308
00:50:33,359 --> 00:50:36,720
social equality because now we're seeing

1309
00:50:36,240 --> 00:50:40,959
built

1310
00:50:36,720 --> 00:50:44,640
on top of the extremities of

1311
00:50:40,960 --> 00:50:48,000
of economic inequality which we

1312
00:50:44,640 --> 00:50:50,400
which we have been just torn apart by

1313
00:50:48,000 --> 00:50:54,960
for the last four to five decades

1314
00:50:50,400 --> 00:50:56,800
uh and are only you know hoping

1315
00:50:54,960 --> 00:50:58,319
to be able to get to a point where we

1316
00:50:56,800 --> 00:51:01,280
can now finally

1317
00:50:58,319 --> 00:51:03,759
firmly reverse that course uh we're

1318
00:51:01,280 --> 00:51:06,160
seeing a new axis of social inequality

1319
00:51:03,760 --> 00:51:06,960
imposed on top of that which is

1320
00:51:06,160 --> 00:51:10,879
epistemic

1321
00:51:06,960 --> 00:51:13,280
inequality that the gap between what i

1322
00:51:10,880 --> 00:51:15,280
can know and what can be known about me

1323
00:51:13,280 --> 00:51:17,599
the gap between what i can do and what

1324
00:51:15,280 --> 00:51:21,359
can be done to me

1325
00:51:17,599 --> 00:51:23,280
and so so these things are widening

1326
00:51:21,359 --> 00:51:24,480
we have been the victims of kind of

1327
00:51:23,280 --> 00:51:27,359
universal

1328
00:51:24,480 --> 00:51:29,280
gaslighting these rhetorical strategies

1329
00:51:27,359 --> 00:51:31,359
that have been used to tell us all

1330
00:51:29,280 --> 00:51:34,160
everything is inevitable this is the way

1331
00:51:31,359 --> 00:51:37,598
that digital works

1332
00:51:34,160 --> 00:51:38,960
um and uh just lay back and enjoy this

1333
00:51:37,599 --> 00:51:42,480
is the future and this

1334
00:51:38,960 --> 00:51:44,920
is democratization we have come to

1335
00:51:42,480 --> 00:51:46,240
understand that this is not

1336
00:51:44,920 --> 00:51:49,280
democratization

1337
00:51:46,240 --> 00:51:51,919
and that none of this is inevitable and

1338
00:51:49,280 --> 00:51:54,400
it's no small thing in fact it is the

1339
00:51:51,920 --> 00:51:57,599
essential first step

1340
00:51:54,400 --> 00:51:58,400
this awakening this awareness this sense

1341
00:51:57,599 --> 00:52:01,440
of

1342
00:51:58,400 --> 00:52:04,079
as chris was alluding to people who are

1343
00:52:01,440 --> 00:52:07,040
now willing to stand up and say

1344
00:52:04,079 --> 00:52:07,680
no i'm not negotiating with you about

1345
00:52:07,040 --> 00:52:09,920
how many

1346
00:52:07,680 --> 00:52:11,279
hours a day an eight-year-old works in

1347
00:52:09,920 --> 00:52:15,359
the factory

1348
00:52:11,280 --> 00:52:17,280
i'm saying no child labor period

1349
00:52:15,359 --> 00:52:18,720
and that's the kind of position we need

1350
00:52:17,280 --> 00:52:19,760
to take when it comes to facial

1351
00:52:18,720 --> 00:52:21,919
recognition

1352
00:52:19,760 --> 00:52:23,839
i'm not negotiating with you about what

1353
00:52:21,920 --> 00:52:27,520
facial recognition may or may not

1354
00:52:23,839 --> 00:52:28,640
be allowed to do i'm saying no facial

1355
00:52:27,520 --> 00:52:30,800
recognition

1356
00:52:28,640 --> 00:52:33,440
i'm saying you cannot have my face i'm

1357
00:52:30,800 --> 00:52:36,880
saying you have no right to my face

1358
00:52:33,440 --> 00:52:39,920
so it's it's this new awareness

1359
00:52:36,880 --> 00:52:41,440
that to me is the necessary foundation

1360
00:52:39,920 --> 00:52:45,280
for everything

1361
00:52:41,440 --> 00:52:47,280
uh that we are going to build on um

1362
00:52:45,280 --> 00:52:48,480
i want to pick up on something that joe

1363
00:52:47,280 --> 00:52:51,440
said maybe uh

1364
00:52:48,480 --> 00:52:52,240
to to close out this thought and that is

1365
00:52:51,440 --> 00:52:55,359
um

1366
00:52:52,240 --> 00:52:57,839
i can't stress enough um and

1367
00:52:55,359 --> 00:52:58,558
and joe was um joe was talking about

1368
00:52:57,839 --> 00:53:02,480
this

1369
00:52:58,559 --> 00:53:06,000
the way in which we are in a new

1370
00:53:02,480 --> 00:53:06,880
phase of history our societies have

1371
00:53:06,000 --> 00:53:10,079
undergone

1372
00:53:06,880 --> 00:53:13,599
a massive structural reorganization a

1373
00:53:10,079 --> 00:53:17,760
massive structural transformation

1374
00:53:13,599 --> 00:53:20,160
look in the year 1986 i was i was two

1375
00:53:17,760 --> 00:53:22,480
years away from publishing my first book

1376
00:53:20,160 --> 00:53:24,759
that i had worked on for a decade

1377
00:53:22,480 --> 00:53:28,559
computerization in the workplace

1378
00:53:24,760 --> 00:53:31,680
1986. one percent of the world's

1379
00:53:28,559 --> 00:53:35,040
information was stored in digital format

1380
00:53:31,680 --> 00:53:37,598
even by 2002

1381
00:53:35,040 --> 00:53:39,040
a year after surveillance capitalism was

1382
00:53:37,599 --> 00:53:42,800
invented

1383
00:53:39,040 --> 00:53:44,240
only 25 percent was stored in digital

1384
00:53:42,800 --> 00:53:47,760
format

1385
00:53:44,240 --> 00:53:50,879
um uh we quickly got to the

1386
00:53:47,760 --> 00:53:54,319
the analog the tipping point between uh

1387
00:53:50,880 --> 00:53:57,839
digital and analog but it then

1388
00:53:54,319 --> 00:54:01,200
everything accelerates and by 2007

1389
00:53:57,839 --> 00:54:04,880
97 of information was stored

1390
00:54:01,200 --> 00:54:07,200
in uh digital format so this is

1391
00:54:04,880 --> 00:54:08,079
you know in this is in historical time

1392
00:54:07,200 --> 00:54:10,640
this is like an

1393
00:54:08,079 --> 00:54:11,359
asteroid hitting the surface of the

1394
00:54:10,640 --> 00:54:13,920
earth

1395
00:54:11,359 --> 00:54:15,200
and changing everything in a split

1396
00:54:13,920 --> 00:54:18,319
second

1397
00:54:15,200 --> 00:54:21,439
this is a fundamental societal

1398
00:54:18,319 --> 00:54:25,839
trauma changes everything

1399
00:54:21,440 --> 00:54:28,480
but the human pace is a different pace

1400
00:54:25,839 --> 00:54:29,680
that's not to be mourned that's to be

1401
00:54:28,480 --> 00:54:32,960
celebrated

1402
00:54:29,680 --> 00:54:36,160
democracy is slow because it's human uh

1403
00:54:32,960 --> 00:54:38,319
democracy is slow because it entails our

1404
00:54:36,160 --> 00:54:39,839
participation and our talking and our

1405
00:54:38,319 --> 00:54:43,680
thinking and are discussing

1406
00:54:39,839 --> 00:54:46,000
coming together but ultimately democracy

1407
00:54:43,680 --> 00:54:48,160
is what will turn this around

1408
00:54:46,000 --> 00:54:49,440
and i'm so delighted that joe brought up

1409
00:54:48,160 --> 00:54:51,839
toronto

1410
00:54:49,440 --> 00:54:53,440
because that is if there is ever a

1411
00:54:51,839 --> 00:54:56,078
beacon of optimism

1412
00:54:53,440 --> 00:54:58,000
the folks in toronto have gifted at

1413
00:54:56,079 --> 00:55:00,319
gifted it to us

1414
00:54:58,000 --> 00:55:02,000
because sidewalk labs which is google

1415
00:55:00,319 --> 00:55:05,040
which is alphabet

1416
00:55:02,000 --> 00:55:08,480
they believed they had a slam

1417
00:55:05,040 --> 00:55:08,880
dunk in toronto that all they had to do

1418
00:55:08,480 --> 00:55:11,520
was

1419
00:55:08,880 --> 00:55:12,640
literally dial it in dial in their

1420
00:55:11,520 --> 00:55:15,839
recipe

1421
00:55:12,640 --> 00:55:18,480
for the instrumentarian city

1422
00:55:15,839 --> 00:55:20,078
in toronto that they would take control

1423
00:55:18,480 --> 00:55:21,839
thank you very much

1424
00:55:20,079 --> 00:55:23,839
and everything would be very nice and

1425
00:55:21,839 --> 00:55:26,000
pleasant for the citizens

1426
00:55:23,839 --> 00:55:27,440
and what they didn't reckon was that

1427
00:55:26,000 --> 00:55:30,640
there were citizens

1428
00:55:27,440 --> 00:55:31,920
who care about democracy and who stood

1429
00:55:30,640 --> 00:55:34,960
up and who said

1430
00:55:31,920 --> 00:55:38,799
no not in my city not in

1431
00:55:34,960 --> 00:55:41,599
any city and ultimately it was those

1432
00:55:38,799 --> 00:55:44,160
citizens and their grassroots movement

1433
00:55:41,599 --> 00:55:47,119
and the way in which they could attract

1434
00:55:44,160 --> 00:55:49,040
civil society organizations to them like

1435
00:55:47,119 --> 00:55:52,880
joe's like the

1436
00:55:49,040 --> 00:55:56,480
canadian civil liberties union

1437
00:55:52,880 --> 00:55:59,040
up in canada and and the way they could

1438
00:55:56,480 --> 00:56:02,160
attract elected officials and lawmakers

1439
00:55:59,040 --> 00:56:05,599
to them that sidewalk

1440
00:56:02,160 --> 00:56:08,399
labs ended up uh you know uh

1441
00:56:05,599 --> 00:56:10,240
just like sneaking out of town rolling

1442
00:56:08,400 --> 00:56:11,839
up their tents and sneaking out of town

1443
00:56:10,240 --> 00:56:14,839
in the bed of night

1444
00:56:11,839 --> 00:56:16,078
because democracy won nothing is

1445
00:56:14,839 --> 00:56:18,160
inevitable

1446
00:56:16,079 --> 00:56:20,960
that's the message for all of us in this

1447
00:56:18,160 --> 00:56:22,960
next decade

1448
00:56:20,960 --> 00:56:24,000
what a wonderful message to end on thank

1449
00:56:22,960 --> 00:56:26,480
you so much

1450
00:56:24,000 --> 00:56:28,240
uh shashana zuba chris billiard and joe

1451
00:56:26,480 --> 00:56:29,599
westby thank you to rightscon for

1452
00:56:28,240 --> 00:56:31,359
putting this together

1453
00:56:29,599 --> 00:56:33,440
and thank you to everyone who's tuning

1454
00:56:31,359 --> 00:56:34,240
in today or who may turn in later when

1455
00:56:33,440 --> 00:56:36,960
when this is made

1456
00:56:34,240 --> 00:56:38,959
uh available more broadly we're all on

1457
00:56:36,960 --> 00:56:41,760
twitter we all have books reports

1458
00:56:38,960 --> 00:56:43,520
journal articles out i won't i won't

1459
00:56:41,760 --> 00:56:46,160
spell out our twitter handles

1460
00:56:43,520 --> 00:56:46,559
but check out the live the live tweeting

1461
00:56:46,160 --> 00:56:48,720
at

1462
00:56:46,559 --> 00:56:51,359
the ranking rights handle and you can

1463
00:56:48,720 --> 00:56:53,439
find a way to get in touch with us

1464
00:56:51,359 --> 00:56:58,720
through there thanks again everyone and

1465
00:56:53,440 --> 00:57:02,799
uh keep up the good fight take care

1466
00:56:58,720 --> 00:57:02,799
thank you thanks

1467
00:57:03,200 --> 00:57:14,240
thank you

1468
00:57:12,000 --> 00:57:15,040
i think i might be in a dif okay there

1469
00:57:14,240 --> 00:57:27,839
we are

1470
00:57:15,040 --> 00:57:27,839
thank you

1471
00:59:39,200 --> 00:59:41,279
you

