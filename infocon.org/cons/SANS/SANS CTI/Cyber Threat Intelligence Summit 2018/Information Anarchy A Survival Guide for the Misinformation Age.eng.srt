1
00:00:01,101 --> 00:00:03,269
(humming)

2
00:00:10,043 --> 00:00:12,578
(audience applauding)

3
00:00:12,579 --> 00:00:15,448
- So, my talk is on
information anarchy,

4
00:00:15,448 --> 00:00:19,119
and since basically nothing
Scott said about me was true,

5
00:00:19,119 --> 00:00:22,489
I'll go ahead and tell you a
little bit more about myself.

6
00:00:22,489 --> 00:00:26,693
The most important thing, I
am totally not an anarchist.

7
00:00:26,693 --> 00:00:29,262
Which you might not
believe if you had seen

8
00:00:29,262 --> 00:00:32,265
my browser history lately and
all of the anarchy clip art

9
00:00:32,265 --> 00:00:35,402
I had to look up trying
to make this presentation.

10
00:00:35,402 --> 00:00:37,237
It's actually, anarchy
clip art is a real thing

11
00:00:37,237 --> 00:00:38,538
and I couldn't use any of it

12
00:00:38,538 --> 00:00:40,907
because it was on the
other side of the line

13
00:00:40,907 --> 00:00:43,043
of what I think I could
have gotten approved.

14
00:00:43,043 --> 00:00:45,945
I am a SANS instructor.

15
00:00:45,945 --> 00:00:47,514
I wrote a book with Scott called

16
00:00:47,514 --> 00:00:49,382
Intelligence-Driven
Incident Response,

17
00:00:49,382 --> 00:00:52,285
and I am a player of
random musical instruments.

18
00:00:52,285 --> 00:00:55,087
You all say my ukulele skills.

19
00:00:55,088 --> 00:00:57,390
I also play the steel drums,

20
00:00:57,390 --> 00:00:59,325
and there was a brief
stint in high school

21
00:00:59,325 --> 00:01:01,628
where I was part
of a kazoo band.

22
00:01:01,628 --> 00:01:02,929
It ended poorly.

23
00:01:02,929 --> 00:01:05,265
Creative differences,
and it turns out kazoos

24
00:01:05,265 --> 00:01:06,966
are terrible instruments.

25
00:01:06,966 --> 00:01:10,303
But the most important
thing about my biography

26
00:01:10,303 --> 00:01:14,340
for this talk is that I run
threat intelligence for Rapid7.

27
00:01:14,340 --> 00:01:16,843
And if anyone's
familiar with Rapid7,

28
00:01:16,843 --> 00:01:18,511
we have a lot of
different tools we use.

29
00:01:18,511 --> 00:01:20,012
We have a vulnerability scanner,

30
00:01:20,013 --> 00:01:21,614
incident detection and response,

31
00:01:21,614 --> 00:01:23,516
services and consulting.

32
00:01:23,516 --> 00:01:25,051
We have a medical
framework that we use

33
00:01:25,051 --> 00:01:26,286
for penetration testing.

34
00:01:26,286 --> 00:01:29,722
And so, I kind of
coordinate and liaise

35
00:01:29,722 --> 00:01:31,925
with all of these
different organizations.

36
00:01:31,925 --> 00:01:35,061
The goal of the threat
intelligence I provide to them

37
00:01:35,061 --> 00:01:38,231
is to get the right information
to the right people on time,

38
00:01:38,231 --> 00:01:40,467
and that's really,
really important to me.

39
00:01:40,467 --> 00:01:43,670
It got really, really
difficult in 2017

40
00:01:43,670 --> 00:01:46,306
to achieve that goal,
and that's because

41
00:01:46,306 --> 00:01:49,241
people would come to me
usually maybe once a month

42
00:01:49,242 --> 00:01:51,277
and they would say
hey, I heard this thing

43
00:01:51,277 --> 00:01:54,581
and it sounds really scary
and what do I need to do?

44
00:01:54,581 --> 00:01:56,416
And so I would take
the time to figure out

45
00:01:56,416 --> 00:01:58,184
what is this thing, where
did they hear about it,

46
00:01:58,184 --> 00:01:59,886
and what can they do?

47
00:01:59,886 --> 00:02:01,854
And a lot of times, it
turned out that that

48
00:02:01,855 --> 00:02:04,257
wasn't actually based
on accurate information.

49
00:02:05,358 --> 00:02:07,527
And once a month turned
into once a week,

50
00:02:07,527 --> 00:02:10,763
turned into once a
day, and my entire job

51
00:02:10,763 --> 00:02:12,999
was now being
spent tracking down

52
00:02:12,999 --> 00:02:15,468
misinformation and
bad information

53
00:02:15,468 --> 00:02:16,503
and things that
people didn't know

54
00:02:16,503 --> 00:02:17,670
where they heard it from,

55
00:02:17,670 --> 00:02:18,704
but they're really,
really scared,

56
00:02:18,705 --> 00:02:20,507
they need to know what to do.

57
00:02:20,507 --> 00:02:23,209
And I actually, Chris's
presentation earlier

58
00:02:23,209 --> 00:02:26,346
gave me the words to describe
what I was going through.

59
00:02:26,346 --> 00:02:28,915
I was using all of my
cognitive processing

60
00:02:28,915 --> 00:02:31,417
on tracking down
bad information,

61
00:02:31,417 --> 00:02:33,786
and I was mentally exhausted.

62
00:02:33,786 --> 00:02:36,089
It got to the point where
somebody would send me a link,

63
00:02:36,089 --> 00:02:39,225
any link, in Slack, and I
would be like, ugh, this again,

64
00:02:39,225 --> 00:02:41,161
and I would be angry.

65
00:02:41,161 --> 00:02:43,196
I decided I had to do
something about that.

66
00:02:43,196 --> 00:02:45,865
Plan A was I was
going to just stop

67
00:02:45,865 --> 00:02:48,334
and I was going to go
raise chickens somewhere,

68
00:02:48,334 --> 00:02:50,837
but my HOA doesn't allow
us to have poultry,

69
00:02:50,837 --> 00:02:52,872
so I had to come up
with a better plan.

70
00:02:52,872 --> 00:02:57,810
All this pain led to the
research we started doing

71
00:02:57,810 --> 00:03:01,214
on misinformation,
how do I identify it,

72
00:03:01,214 --> 00:03:04,716
and how do I deal with the
current state that we are in,

73
00:03:04,717 --> 00:03:07,820
which I deemed
information anarchy?

74
00:03:07,820 --> 00:03:09,888
What is information anarchy?

75
00:03:09,889 --> 00:03:11,658
It's a term that I first heard

76
00:03:11,658 --> 00:03:14,059
as part of JDP 2-OO, which
is the British military

77
00:03:14,060 --> 00:03:16,996
intelligence doctrine,
and they said that

78
00:03:16,996 --> 00:03:18,798
information anarchy is a state

79
00:03:18,798 --> 00:03:21,601
where you have
increasing amounts of
information coming in,

80
00:03:21,601 --> 00:03:24,304
and an increasing
lack of control

81
00:03:24,304 --> 00:03:26,606
or information about
where it's coming from

82
00:03:26,606 --> 00:03:28,474
or whether it's valid or not,

83
00:03:28,474 --> 00:03:30,009
and that leads to a state where

84
00:03:30,009 --> 00:03:32,244
it actually makes more
difficult for people

85
00:03:32,245 --> 00:03:34,614
to make decisions based
on this information,

86
00:03:34,614 --> 00:03:36,149
because you don't
know what's important,

87
00:03:36,149 --> 00:03:37,417
you don't know what's relevant,

88
00:03:37,417 --> 00:03:39,118
you don't know what
you need to act on.

89
00:03:41,087 --> 00:03:42,522
How did we get here?

90
00:03:42,522 --> 00:03:44,524
It's not a new term and
it's not a new concept

91
00:03:44,524 --> 00:03:46,859
even in information security.

92
00:03:46,859 --> 00:03:49,429
There was a paper in 1995
written by a gentleman

93
00:03:49,429 --> 00:03:51,831
named Don Parker
called A New Framework

94
00:03:51,831 --> 00:03:55,468
for Information Security to
Combat Information Anarchy.

95
00:03:55,468 --> 00:03:57,170
1995.

96
00:03:57,170 --> 00:03:58,905
I wish I had been paying a
little bit better attention

97
00:03:58,905 --> 00:04:01,774
but I was really caught up with
my kazoo band at that time,

98
00:04:01,774 --> 00:04:05,211
but 2018, we still
have this problem,

99
00:04:05,211 --> 00:04:06,746
we still have this issue.

100
00:04:07,914 --> 00:04:10,315
We came upon it
pretty gradually.

101
00:04:10,316 --> 00:04:12,652
For a brief history,
my brief history

102
00:04:12,652 --> 00:04:15,188
of the state of
information in our world,

103
00:04:15,188 --> 00:04:17,390
we started out with
information monarchy.

104
00:04:17,390 --> 00:04:19,993
One person, one organization,
often one government

105
00:04:19,993 --> 00:04:21,861
controlled all of
the information.

106
00:04:21,861 --> 00:04:23,563
They decided what people heard,

107
00:04:23,563 --> 00:04:24,964
they decided when it went out,

108
00:04:24,964 --> 00:04:26,165
and they weren't
really interested

109
00:04:26,165 --> 00:04:27,800
in any sort of feedback.

110
00:04:27,800 --> 00:04:29,335
Unfortunately, there
are a lot of countries

111
00:04:29,335 --> 00:04:31,236
and a lot of regimes
that still exist

112
00:04:31,237 --> 00:04:34,507
in this type of
information state.

113
00:04:35,942 --> 00:04:38,544
After that, we started to
see information revolutions.

114
00:04:38,544 --> 00:04:40,546
People started
getting more educated.

115
00:04:40,546 --> 00:04:43,216
They realized, wait a minute,
this stuff you're telling me

116
00:04:43,216 --> 00:04:44,784
is not necessarily the truth.

117
00:04:44,784 --> 00:04:46,352
It is not the end-all, be-all.

118
00:04:46,352 --> 00:04:48,688
I need more, I want more.

119
00:04:48,688 --> 00:04:51,357
Luckily, in a lot of cases,
they were successful,

120
00:04:51,357 --> 00:04:53,660
which brought us to
information democracy.

121
00:04:53,660 --> 00:04:56,896
We now have multiple places we
can get our information from.

122
00:04:56,896 --> 00:04:58,464
We can seek it out ourselves,

123
00:04:58,464 --> 00:05:00,933
we can watch the news and
have people tell it to us,

124
00:05:00,933 --> 00:05:02,568
we can read peer
review journals,

125
00:05:03,736 --> 00:05:06,072
and while I flashed
I'm not an anarchist,

126
00:05:06,072 --> 00:05:08,341
I should be saying, yay,
information democracy,

127
00:05:08,341 --> 00:05:09,575
that's the best.

128
00:05:09,575 --> 00:05:11,644
But it had its problems as well,

129
00:05:11,644 --> 00:05:14,914
and one of the problems
is that people started,

130
00:05:14,914 --> 00:05:17,683
the news people who were
creating this information,

131
00:05:17,684 --> 00:05:19,986
started competing for readers.

132
00:05:19,986 --> 00:05:22,255
You want ratings, where
people spend their time

133
00:05:22,255 --> 00:05:25,457
and their money, that
is where they wanted

134
00:05:25,458 --> 00:05:27,393
the readers to be,
so we started seeing

135
00:05:27,393 --> 00:05:30,095
this fight for ratings,
and because of that

136
00:05:30,096 --> 00:05:32,198
we started seeing
people doing things like

137
00:05:32,198 --> 00:05:34,400
posting sensationalized stories,

138
00:05:34,400 --> 00:05:36,803
and the fear, uncertainty,
and doubt, and the FUD

139
00:05:36,803 --> 00:05:38,438
in order to get those ratings

140
00:05:38,438 --> 00:05:40,173
and become the best news source.

141
00:05:41,974 --> 00:05:43,209
So that was bad enough.

142
00:05:44,444 --> 00:05:47,513
But then, we had social media.

143
00:05:47,513 --> 00:05:50,049
And social media
basically allowed anybody

144
00:05:50,049 --> 00:05:51,351
to be their own news source.

145
00:05:51,351 --> 00:05:52,885
You can post anything you want.

146
00:05:52,885 --> 00:05:55,722
It doesn't have to be real,
it doesn't have to be right.

147
00:05:55,722 --> 00:05:57,590
You can literally post anything.

148
00:05:57,590 --> 00:05:59,157
Like I said, try it.

149
00:05:59,158 --> 00:06:02,528
Please, it hurts my
heart, but after that,

150
00:06:02,528 --> 00:06:05,531
it becomes so hard to know
what is a real news source?

151
00:06:05,531 --> 00:06:07,300
What is a new news source?

152
00:06:07,300 --> 00:06:09,168
What is the blog
somebody is running

153
00:06:09,168 --> 00:06:10,670
but it sounds legitimate?

154
00:06:10,670 --> 00:06:13,339
And that brought us to our
state of information anarchy

155
00:06:13,339 --> 00:06:15,141
where we have so
much information.

156
00:06:15,141 --> 00:06:17,510
Some of it's good,
some of it's bad,

157
00:06:17,510 --> 00:06:19,379
and we just really
don't often know

158
00:06:19,379 --> 00:06:22,014
a good way to find out, and
that's where I was spending

159
00:06:22,014 --> 00:06:24,083
all of that cognitive
processing time,

160
00:06:24,083 --> 00:06:26,619
was trying to sort out
what's good from what's bad.

161
00:06:28,087 --> 00:06:30,690
Throughout this research,
we realized it isn't just

162
00:06:30,690 --> 00:06:33,025
good information
and bad information.

163
00:06:33,025 --> 00:06:36,929
There's lots of different types
of misinformation out there.

164
00:06:36,929 --> 00:06:38,231
These are some broad categories

165
00:06:38,231 --> 00:06:39,599
that I identified
through our research.

166
00:06:39,599 --> 00:06:41,667
There's lots of
subcategories throughout it.

167
00:06:41,667 --> 00:06:43,969
But the first one is
innocent mistakes.

168
00:06:43,970 --> 00:06:46,706
Sometimes, some people
just get it wrong,

169
00:06:46,706 --> 00:06:48,274
and it's not intentional.

170
00:06:48,274 --> 00:06:49,742
They're following
their processes.

171
00:06:49,742 --> 00:06:52,211
The same happens to us
in intelligence analysis.

172
00:06:52,211 --> 00:06:54,814
We can do our best job, we
can make our best guesses,

173
00:06:54,814 --> 00:06:56,883
we can use all the tools
and resources we have,

174
00:06:56,883 --> 00:06:58,918
and sometimes it's
still just not right.

175
00:07:00,019 --> 00:07:01,421
When this happens, though,

176
00:07:01,421 --> 00:07:03,823
and this used to happen
a lot more often,

177
00:07:03,823 --> 00:07:05,491
it needs to be corrected
when you identify that.

178
00:07:05,491 --> 00:07:07,659
If new information
comes in or you realize

179
00:07:07,660 --> 00:07:10,530
you made a mistake, that
it needs to be corrected,

180
00:07:10,530 --> 00:07:12,265
and unfortunately
what we've seen

181
00:07:12,265 --> 00:07:14,167
is that even when
it is corrected,

182
00:07:14,167 --> 00:07:17,270
it's really hard to know that
something you read yesterday

183
00:07:17,270 --> 00:07:19,104
is no longer accurate.

184
00:07:19,105 --> 00:07:21,174
There is a really
good resource I found.

185
00:07:21,174 --> 00:07:24,443
It's a website
called newsdiffs.org,

186
00:07:24,444 --> 00:07:28,214
N-E-W-S-D-I-F-F-S dot org,

187
00:07:28,214 --> 00:07:30,683
and they, it's a project
where they catalog

188
00:07:30,683 --> 00:07:35,388
about a handful of the
most common media outlets,

189
00:07:35,388 --> 00:07:37,590
like the New York Times and
the Wall Street Journal,

190
00:07:37,590 --> 00:07:38,957
and they will provide updates

191
00:07:38,958 --> 00:07:40,426
on when articles
have been changed,

192
00:07:40,426 --> 00:07:42,762
so you can see the
changes side by side

193
00:07:42,762 --> 00:07:44,931
so you know when new
information has been introduced.

194
00:07:44,931 --> 00:07:47,099
But it is actually
really, really hard

195
00:07:47,099 --> 00:07:49,335
even to go in and
identify when somebody

196
00:07:49,335 --> 00:07:52,238
did make this kind of innocent
mistake in their reporting.

197
00:07:55,441 --> 00:07:57,243
The next one, I see this a lot,

198
00:07:57,243 --> 00:08:00,613
and I've determined that a
lot of my heartache in 2017

199
00:08:00,613 --> 00:08:02,782
was because of this
type of misinformation.

200
00:08:02,782 --> 00:08:04,650
Hypothesis as a fact.

201
00:08:04,650 --> 00:08:06,751
A lot of these attacks we saw,

202
00:08:06,752 --> 00:08:09,522
WannaCry2 and NotPetya
and things like that,

203
00:08:11,357 --> 00:08:12,725
the commentary and
the information

204
00:08:12,725 --> 00:08:15,294
that was out there about
it was people trying

205
00:08:15,294 --> 00:08:17,462
to do their analysis
in real time,

206
00:08:17,463 --> 00:08:20,466
often over social media
or in the actual press.

207
00:08:22,969 --> 00:08:24,469
They might have been good ideas.

208
00:08:24,470 --> 00:08:25,771
They were definitely
something that somebody

209
00:08:25,771 --> 00:08:27,874
should continue to
research and find out

210
00:08:27,874 --> 00:08:31,844
what the outcome was, but
when they make it to the news

211
00:08:31,844 --> 00:08:34,280
and they make it to
something people are reading,

212
00:08:34,280 --> 00:08:36,482
it is really hard to
know whether or not

213
00:08:36,482 --> 00:08:38,683
you should act on it, because
they don't actually tell you

214
00:08:38,683 --> 00:08:39,885
that this isn't final.

215
00:08:41,053 --> 00:08:44,222
This is a problem
because people rush.

216
00:08:44,222 --> 00:08:46,391
When these new breaking
attacks come out

217
00:08:46,392 --> 00:08:47,827
or these new vulnerabilities
are announced,

218
00:08:47,827 --> 00:08:49,395
we want to get
information out quickly,

219
00:08:49,395 --> 00:08:52,131
but that quick is often
compromising our ability

220
00:08:52,131 --> 00:08:54,766
to provide accurate information.

221
00:08:54,767 --> 00:08:56,269
And it's not always intentional.

222
00:08:56,269 --> 00:08:58,204
I know I've have times
when something happens

223
00:08:58,204 --> 00:09:02,241
and someone calls me and
says hey, what's going on?

224
00:09:02,241 --> 00:09:05,343
And I say, all right, well,
we're still investigating.

225
00:09:05,344 --> 00:09:06,979
I don't have all the details,

226
00:09:06,979 --> 00:09:09,215
but it looks like
it was X, Y, and Z.

227
00:09:09,215 --> 00:09:10,750
I'm pretty sure, then I read it,

228
00:09:10,750 --> 00:09:12,118
and somebody's published that

229
00:09:12,118 --> 00:09:14,086
and they've cut out
all of my qualifiers,

230
00:09:14,086 --> 00:09:16,689
and it just says Rebekah
Brown says X, Y, and Z,

231
00:09:16,689 --> 00:09:19,158
and that's really
unfortunate because

232
00:09:19,158 --> 00:09:21,327
now I'm contributing
to the confusion.

233
00:09:24,463 --> 00:09:28,367
The third category is
something I think we see a lot,

234
00:09:28,367 --> 00:09:30,870
and this is the only time in
my talk I'm gonna say this,

235
00:09:30,870 --> 00:09:32,838
when people talk
about fake news.

236
00:09:32,838 --> 00:09:34,839
It's someone pushing an agenda.

237
00:09:34,840 --> 00:09:36,042
This is essentially everything

238
00:09:36,042 --> 00:09:38,244
that crazy aunt you
have posts to Facebook,

239
00:09:38,244 --> 00:09:39,812
where you're like really?

240
00:09:39,812 --> 00:09:41,414
You know that's not true.

241
00:09:41,414 --> 00:09:44,584
But it's something that confirms
somebody's existing biases.

242
00:09:44,584 --> 00:09:46,685
A lot of the cognitive
biases we talk about

243
00:09:46,686 --> 00:09:49,522
in intelligence analysis
where we will find reports

244
00:09:49,522 --> 00:09:51,223
full of things like that.

245
00:09:54,360 --> 00:09:56,062
And it comes in multiple forms.

246
00:09:56,062 --> 00:10:00,466
It can be either somebody
trying to push an agenda

247
00:10:00,466 --> 00:10:02,802
of I want people to be
scared about their security,

248
00:10:02,802 --> 00:10:04,170
I want them to think
they're vulnerable

249
00:10:04,170 --> 00:10:05,371
because then they'll call us

250
00:10:05,371 --> 00:10:07,573
and they'll need more
security services,

251
00:10:07,573 --> 00:10:09,241
or it can be somebody saying

252
00:10:09,241 --> 00:10:13,312
this is the political
agenda I want to push,

253
00:10:13,312 --> 00:10:15,381
and so I'm going to
pull everything out

254
00:10:15,381 --> 00:10:16,616
and formulate this news in a way

255
00:10:16,616 --> 00:10:17,917
that it is going
to encourage people

256
00:10:17,917 --> 00:10:19,852
to believe my way of thinking.

257
00:10:22,822 --> 00:10:26,292
And the fourth category is
intentional disinformation.

258
00:10:26,292 --> 00:10:30,563
We actually see
this pretty rarely

259
00:10:30,563 --> 00:10:32,365
in information security news.

260
00:10:32,365 --> 00:10:34,467
A lot of times what
we see are the second

261
00:10:34,467 --> 00:10:37,569
and third level effects of
a disinformation campaign,

262
00:10:37,570 --> 00:10:41,140
but it's pretty rare that
there is formal active measures

263
00:10:41,140 --> 00:10:43,442
behind the things we respond to,

264
00:10:43,442 --> 00:10:45,778
and that's because these are,

265
00:10:45,778 --> 00:10:48,381
Thomas talked about some
active measures this morning.

266
00:10:48,381 --> 00:10:51,717
There's a really good
quote I like from a colonel

267
00:10:51,717 --> 00:10:55,588
who's in the East German
foreign intelligence service,

268
00:10:55,588 --> 00:10:57,456
he's in charge of
their disinformation,

269
00:10:57,456 --> 00:11:00,693
and he says, our friends
in Russia call it

270
00:11:00,693 --> 00:11:02,328
(speaks in foreign language),

271
00:11:02,328 --> 00:11:04,863
our enemies in America
call it active measures,

272
00:11:04,864 --> 00:11:07,333
and as for me, I call
it my favorite pastime.

273
00:11:08,267 --> 00:11:11,504
Disinformation is an operation.

274
00:11:11,504 --> 00:11:15,041
This image comes from
Operation Infection,

275
00:11:15,041 --> 00:11:17,677
which was a Russian
disinformation campaign

276
00:11:17,677 --> 00:11:20,880
that they ran in the
80s, and they convinced,

277
00:11:20,880 --> 00:11:24,150
they started
inserting information

278
00:11:24,150 --> 00:11:27,153
and started conjecture and
getting people to think

279
00:11:27,153 --> 00:11:28,854
that the AIDS epidemic
that was being experienced

280
00:11:28,854 --> 00:11:32,758
in the U.S. was actually
U.S. biological weapons.

281
00:11:32,758 --> 00:11:34,694
We say that now and it
doesn't make a lot of sense,

282
00:11:34,694 --> 00:11:37,762
but if you look at what
was going on at the time,

283
00:11:37,763 --> 00:11:39,031
we had just come out of Vietnam

284
00:11:39,031 --> 00:11:41,266
where biological
weapons were used.

285
00:11:41,267 --> 00:11:44,236
There were prisoners of war who
had been captured in Vietnam

286
00:11:44,236 --> 00:11:47,406
who gave coerced
confessions saying that yes,

287
00:11:47,406 --> 00:11:49,040
the U.S. is employing
nuclear weapons,

288
00:11:49,041 --> 00:11:51,677
and during the Cold
War, when we're trying

289
00:11:51,677 --> 00:11:53,012
to increase military spending,

290
00:11:53,012 --> 00:11:55,547
it was probably in
Russia's best interest

291
00:11:55,548 --> 00:11:58,584
for the U.S. public to
not trust their government

292
00:11:58,584 --> 00:12:00,986
and not trust their military.

293
00:12:00,986 --> 00:12:03,089
This campaign was very involved.

294
00:12:03,089 --> 00:12:06,525
It involved thinking research
and scientific journals

295
00:12:06,525 --> 00:12:08,327
and all these sorts
of activities,

296
00:12:08,327 --> 00:12:10,696
so misinformation
is not trivial,

297
00:12:10,696 --> 00:12:13,132
or disinformation is not
trivial, and we do see it.

298
00:12:13,132 --> 00:12:15,401
Like I said, we'll see second
and third level effects,

299
00:12:15,401 --> 00:12:18,002
but in most cases, if
somebody's just publishing

300
00:12:18,003 --> 00:12:20,706
a dumb article that
I have to respond to,

301
00:12:20,706 --> 00:12:23,576
it's not disinformation,
it's misinformation.

302
00:12:26,045 --> 00:12:29,247
All right, so how
can we identify it?

303
00:12:29,248 --> 00:12:32,818
It's good to have a better
idea of what misinformation is

304
00:12:32,818 --> 00:12:34,954
and what kind of
categories things go into,

305
00:12:34,954 --> 00:12:36,655
but I still need
to free up my time.

306
00:12:36,655 --> 00:12:38,790
I still need to be
able to have shortcuts,

307
00:12:38,791 --> 00:12:40,459
they're gonna help
me get through

308
00:12:41,761 --> 00:12:42,962
all of this bad
information so I can focus

309
00:12:42,962 --> 00:12:45,631
on what's really
important to my job.

310
00:12:45,631 --> 00:12:47,333
There's a couple
different techniques

311
00:12:47,333 --> 00:12:48,601
that I've come up with.

312
00:12:48,601 --> 00:12:50,536
Are there any
Zombieland fans in here?

313
00:12:50,536 --> 00:12:51,936
What's rule number one?

314
00:12:53,472 --> 00:12:55,040
Cardio.

315
00:12:55,040 --> 00:12:56,709
Well, since Alex Pinto
has already claimed

316
00:12:56,709 --> 00:12:58,911
cardio is rule number one
from machine learning,

317
00:12:58,911 --> 00:13:01,146
I'm going to go ahead
and say rule number one

318
00:13:01,147 --> 00:13:03,482
for misinformation is sourcing.

319
00:13:03,482 --> 00:13:05,651
Where does the
information come from?

320
00:13:05,651 --> 00:13:08,186
Identifying the source
and being able to know

321
00:13:08,187 --> 00:13:09,722
whether or not
it's a valid source

322
00:13:09,722 --> 00:13:11,189
is going to cut all
that information

323
00:13:11,190 --> 00:13:13,092
you have to respond
to by about half.

324
00:13:13,092 --> 00:13:15,561
When we were
responding to WannaCry,

325
00:13:15,561 --> 00:13:18,097
and trying to identify
what was going on,

326
00:13:18,097 --> 00:13:19,932
as we kind of worked
through this little war room

327
00:13:19,932 --> 00:13:22,902
across all of Rapid7,
I had one person

328
00:13:22,902 --> 00:13:25,371
who kept saying, I
have IOCs, I have IOCs,

329
00:13:25,371 --> 00:13:27,305
and they would send
me this list in Excel

330
00:13:27,306 --> 00:13:30,209
of some IPs and
domains, and he's like,

331
00:13:30,209 --> 00:13:31,443
we need to push those
in for detection,

332
00:13:31,443 --> 00:13:34,079
and I'm like where,
what's going on?

333
00:13:34,079 --> 00:13:35,948
One of the guys I
work with jokes that

334
00:13:35,948 --> 00:13:37,949
I am the great intel firewall,

335
00:13:37,950 --> 00:13:39,752
'cause nothing goes into
our detection systems

336
00:13:39,752 --> 00:13:42,320
unless I approve it,
and that often involves

337
00:13:42,321 --> 00:13:43,923
knowing the source and
me being comfortable

338
00:13:43,923 --> 00:13:45,191
with the sourcing.

339
00:13:45,191 --> 00:13:47,126
When I finally got this
person to explain to me

340
00:13:47,126 --> 00:13:49,194
where he got those IPs from,

341
00:13:49,195 --> 00:13:54,200
his response was, literally,
Twitter, word of mouth,

342
00:13:55,100 --> 00:13:57,469
and probably some other places.

343
00:13:57,469 --> 00:13:59,071
(audience laughing)

344
00:13:59,071 --> 00:14:02,474
I don't have, that
made it pretty easy

345
00:14:02,474 --> 00:14:04,143
for me to be like, no.

346
00:14:04,143 --> 00:14:06,378
And turns out, it was
a separate campaign,

347
00:14:06,378 --> 00:14:07,813
it was the (mumbles) campaign

348
00:14:07,813 --> 00:14:09,481
that had been running
at the same time,

349
00:14:09,481 --> 00:14:11,383
but the unfortunate thing is,

350
00:14:11,383 --> 00:14:13,452
if you look through a lot of
threat intelligence tools,

351
00:14:13,452 --> 00:14:16,989
especially aggregators,
you will see those IPs

352
00:14:16,989 --> 00:14:19,325
and those domains listed
as tied to WannaCry,

353
00:14:19,325 --> 00:14:20,826
because once something's
on the internet,

354
00:14:20,826 --> 00:14:23,829
once something's on Twitter,
if you're mining Twitter,

355
00:14:23,829 --> 00:14:26,464
you're gonna get the bad
information with the good.

356
00:14:26,465 --> 00:14:28,100
Even though we are
able to identify

357
00:14:28,100 --> 00:14:31,403
that that was not linked,
if you go look it up today,

358
00:14:31,403 --> 00:14:33,873
you will have a really hard
time figuring that out.

359
00:14:33,873 --> 00:14:36,909
You would have to go back to
the actual source of the source

360
00:14:36,909 --> 00:14:40,779
who later corrected it,
and said just kidding,

361
00:14:40,779 --> 00:14:42,181
totally different thing.

362
00:14:42,181 --> 00:14:44,116
It's not that easy to do.

363
00:14:44,116 --> 00:14:45,451
When we're looking at sourcing,

364
00:14:45,451 --> 00:14:46,585
the things you want to know are

365
00:14:46,585 --> 00:14:48,854
where did the
information come from?

366
00:14:48,854 --> 00:14:50,890
A lot of times, like
I said that itself

367
00:14:50,890 --> 00:14:53,592
will be like nope,
not acting on this.

368
00:14:53,592 --> 00:14:56,528
The next thing is can you
access the source material?

369
00:14:56,528 --> 00:14:59,131
If they say, oh it came from
a report from CrowdStrike.

370
00:14:59,131 --> 00:15:01,500
Okay, cool, can I
actually see that report?

371
00:15:01,500 --> 00:15:04,103
Can I get that report
to validate, to verify,

372
00:15:04,103 --> 00:15:06,472
to answer any follow up
questions that I have?

373
00:15:06,472 --> 00:15:08,207
A lot of times,
the answer is no,

374
00:15:08,207 --> 00:15:10,809
and that makes it really,
really difficult to do your job,

375
00:15:10,809 --> 00:15:13,746
but if you are able to
see the original source,

376
00:15:13,746 --> 00:15:17,316
who is being cited, what
report, what analysis,

377
00:15:17,316 --> 00:15:19,652
what Twitter post in some cases,

378
00:15:19,652 --> 00:15:21,086
that will give you
a lot better idea

379
00:15:21,086 --> 00:15:23,856
of whether or not it's something
that you can follow up on.

380
00:15:23,856 --> 00:15:27,126
And then finally, was a
structured analytic method used

381
00:15:27,126 --> 00:15:30,562
when you read through this,
whoever they're talking about,

382
00:15:30,562 --> 00:15:32,264
where this
information came from?

383
00:15:32,264 --> 00:15:34,633
Did they go through
some sort of process

384
00:15:34,633 --> 00:15:36,635
to get from point A to point B?

385
00:15:36,635 --> 00:15:38,670
Carmen spoke about how
structured analytic techniques

386
00:15:38,671 --> 00:15:41,106
are not always necessary
and that's absolutely true,

387
00:15:41,106 --> 00:15:43,809
but I want to know that
there was some sort

388
00:15:43,809 --> 00:15:45,276
of analytic process
that happened

389
00:15:45,277 --> 00:15:48,113
to get to the information I'm
being asked to respond to.

390
00:15:51,083 --> 00:15:53,385
The next thing we
looked at after sourcing

391
00:15:53,385 --> 00:15:54,954
was linguistic methods.

392
00:15:57,256 --> 00:15:59,525
One of the things I
wrote up in my bio

393
00:15:59,525 --> 00:16:01,760
is that I'm writing
my Master's thesis,

394
00:16:01,760 --> 00:16:04,863
and my degree is in
homeland security

395
00:16:04,863 --> 00:16:06,398
with a cyber security focus,

396
00:16:06,398 --> 00:16:09,034
and a graduate certificate
in intelligence analysis,

397
00:16:09,034 --> 00:16:11,136
so I take a lot
of weird classes,

398
00:16:11,136 --> 00:16:13,271
and one of my favorites
was actually called

399
00:16:13,272 --> 00:16:15,874
intelligence
profiling of leaders,

400
00:16:15,874 --> 00:16:18,444
which, I read intelligence
profiling, and I was like whoa,

401
00:16:18,444 --> 00:16:20,411
pretty sure we're not
supposed to do that,

402
00:16:20,412 --> 00:16:21,680
but when you're
talking about leaders

403
00:16:21,680 --> 00:16:23,882
it was actually really
helpful to understand

404
00:16:23,882 --> 00:16:26,084
how these people who are
making decisions operate

405
00:16:26,085 --> 00:16:27,953
and how they think and
what motivates them.

406
00:16:27,953 --> 00:16:30,589
And they used things like
leadership trade analysis

407
00:16:30,589 --> 00:16:33,559
and sentiment analysis and
motive imagery analysis

408
00:16:33,559 --> 00:16:37,262
to look over texts
that people speak about

409
00:16:37,262 --> 00:16:40,064
to understand more about
what they're saying.

410
00:16:40,065 --> 00:16:42,401
I decided to try and apply
some of those methods

411
00:16:42,401 --> 00:16:44,870
and we had to tweak obviously
some of the word lists

412
00:16:44,870 --> 00:16:46,405
and things to make
it more applicable

413
00:16:46,405 --> 00:16:48,173
to information
security research.

414
00:16:48,173 --> 00:16:51,710
But I ended up after looking
through about 100 articles,

415
00:16:51,710 --> 00:16:55,414
some good, some really,
really bad, like I feel,

416
00:16:55,414 --> 00:16:56,982
I don't know, man,
I wish I hadn't read

417
00:16:56,982 --> 00:16:58,717
some of those blog posts,

418
00:16:58,717 --> 00:17:01,754
but I did it for science,
and I came up with four lists

419
00:17:01,754 --> 00:17:04,890
of things to look at,
look for in an article.

420
00:17:04,890 --> 00:17:06,592
The first is words of sourcing.

421
00:17:06,592 --> 00:17:09,361
Things like
according to, as per,

422
00:17:09,361 --> 00:17:12,398
they're going to tell me that
this text that I'm reading

423
00:17:12,397 --> 00:17:13,898
was based on something.

424
00:17:15,334 --> 00:17:17,569
The next thing I looked for
was words of uncertainty.

425
00:17:17,569 --> 00:17:19,271
If you've done a lot
of intelligence work

426
00:17:19,271 --> 00:17:20,938
and you've written
intelligence reporting

427
00:17:20,939 --> 00:17:22,775
you know those words
of uncertainty are
really important.

428
00:17:22,775 --> 00:17:26,078
Those are things like possibly,
and could be, and might,

429
00:17:26,078 --> 00:17:28,079
that show kind of
how confident we are

430
00:17:28,079 --> 00:17:31,116
and when something's a fact
and when it's an assessment.

431
00:17:31,116 --> 00:17:34,153
The next thing I looked for
were explanatory phrases.

432
00:17:34,153 --> 00:17:36,555
Things like because
and therefore

433
00:17:36,555 --> 00:17:38,690
that show that they're
doing some of that

434
00:17:38,690 --> 00:17:42,061
analytic explaining and
talking through their process

435
00:17:42,061 --> 00:17:44,696
and not just stating facts
with nothing to back it up.

436
00:17:44,696 --> 00:17:46,965
And then the fourth
thing was retractors.

437
00:17:46,965 --> 00:17:50,101
Those are words like
but, however, although.

438
00:17:50,102 --> 00:17:51,937
And retractors
serve two purposes.

439
00:17:53,338 --> 00:17:56,408
Sometimes, retractors
actually show complexity,

440
00:17:56,408 --> 00:17:57,842
which we're going
to talk about next,

441
00:17:57,843 --> 00:17:59,445
meaning that
somebody can identify

442
00:17:59,445 --> 00:18:01,280
that there's more than
one side to a story,

443
00:18:01,280 --> 00:18:04,183
or there might be concerns,
and they can address them

444
00:18:04,183 --> 00:18:07,419
as part of their own
analysis, and those are good,

445
00:18:07,419 --> 00:18:09,421
and then there's
retractors where people

446
00:18:09,421 --> 00:18:11,223
kind of want to give
themselves a way out.

447
00:18:11,223 --> 00:18:14,960
They could be like, that was
totally China who hacked those

448
00:18:14,960 --> 00:18:17,463
but who do I know,
it could be anybody.

449
00:18:17,463 --> 00:18:19,598
You've made this very
blatant statement

450
00:18:19,598 --> 00:18:21,667
and then you've kind of
tried to walk yourself back.

451
00:18:21,667 --> 00:18:23,534
People are gonna remember
that blatant statement

452
00:18:23,535 --> 00:18:25,237
and then it turns
out you're wrong,

453
00:18:25,237 --> 00:18:26,171
you can go back and be like,

454
00:18:26,171 --> 00:18:28,607
hey, I said, what do I know?

455
00:18:28,607 --> 00:18:30,075
Retractors are
often used as a way

456
00:18:30,075 --> 00:18:34,947
of letting yourself state
something sensational

457
00:18:34,947 --> 00:18:37,748
without having to be
accountable for it later.

458
00:18:39,151 --> 00:18:43,322
So like I said, we did this
across 100 different documents,

459
00:18:43,322 --> 00:18:45,991
refined our word
list, had some issues.

460
00:18:45,991 --> 00:18:48,694
May was one of our
words of uncertainty.

461
00:18:48,694 --> 00:18:51,730
We found huge spikes in
reports that came out

462
00:18:51,730 --> 00:18:54,566
in the month of May, so we
had to do some tweaking.

463
00:18:54,566 --> 00:18:56,101
I have a great
data science team,

464
00:18:56,101 --> 00:18:58,036
so I'm very, very thankful
they helped me with those,

465
00:18:58,036 --> 00:19:01,740
but for our case study, we
took seven different articles

466
00:19:01,740 --> 00:19:03,342
about the DNC hack.

467
00:19:03,342 --> 00:19:06,512
Five had some pretty
blatant misinformation,

468
00:19:06,512 --> 00:19:07,980
and bad information.

469
00:19:07,980 --> 00:19:10,716
Two were pretty, we view
them as these are objective,

470
00:19:10,716 --> 00:19:12,684
they're conveying the facts,
and we kind of ran them through

471
00:19:12,684 --> 00:19:14,286
just to see what it looked like.

472
00:19:16,054 --> 00:19:18,490
What we found was a couple
different interesting things.

473
00:19:18,490 --> 00:19:20,659
Our explanatory
and our retractors

474
00:19:20,659 --> 00:19:22,427
were kind of
basically consistent.

475
00:19:22,427 --> 00:19:25,496
And this was, for anybody
who does data science,

476
00:19:25,497 --> 00:19:28,800
this was normalized by
words in the articles

477
00:19:28,800 --> 00:19:30,869
so we did a percentage
of words in the article

478
00:19:30,869 --> 00:19:32,937
rather than just a raw count,

479
00:19:32,938 --> 00:19:34,973
but what was interesting
was that the sourcing

480
00:19:34,973 --> 00:19:37,408
and the uncertainty
was all over the place.

481
00:19:37,409 --> 00:19:40,979
Some articles use a lot,
some articles use none.

482
00:19:40,979 --> 00:19:42,581
The first thing that jumped out

483
00:19:42,581 --> 00:19:44,315
when we used this first
analysis right here

484
00:19:44,316 --> 00:19:48,287
was our words of uncertainty
in this article, zero.

485
00:19:48,287 --> 00:19:50,255
And it was not a short article.

486
00:19:50,255 --> 00:19:52,891
You're telling me there's
not a single possibly,

487
00:19:52,891 --> 00:19:55,727
or might, or any room
for chance in that,

488
00:19:55,727 --> 00:19:57,429
so that jumped out
to me right away

489
00:19:57,429 --> 00:19:59,498
as something to look into.

490
00:19:59,498 --> 00:20:00,732
In addition to just
kind of looking

491
00:20:00,732 --> 00:20:02,601
at what they look
like in general,

492
00:20:02,601 --> 00:20:05,504
we took a look at each
article's profile,

493
00:20:05,504 --> 00:20:07,639
so each of those
categories of their words

494
00:20:07,639 --> 00:20:09,174
across the whole
article, and again,

495
00:20:09,174 --> 00:20:11,376
a couple of things jumped out.

496
00:20:11,376 --> 00:20:14,713
The ones here that are
kind of more balanced,

497
00:20:14,713 --> 00:20:17,316
and they definitely have
some but no huge spikes,

498
00:20:17,316 --> 00:20:20,452
these were our good reports.

499
00:20:20,452 --> 00:20:22,854
Right off the bat, that told
me that okay, you know what,

500
00:20:22,854 --> 00:20:24,690
that balance and
that middle line,

501
00:20:24,690 --> 00:20:27,025
there's something to that.

502
00:20:27,025 --> 00:20:29,094
Again, we have our one to
zero words of uncertainty,

503
00:20:29,094 --> 00:20:32,130
tons of sourcing, our
IVN, which stands for

504
00:20:32,130 --> 00:20:33,966
Independer Voting
Network and that hey,

505
00:20:33,966 --> 00:20:35,199
they're saying they're independ,

506
00:20:35,200 --> 00:20:37,369
and so I'm trusting
that they're objective,

507
00:20:37,369 --> 00:20:38,971
but they had basically none.

508
00:20:38,971 --> 00:20:43,308
They had very, very small
counts of any of those words.

509
00:20:44,776 --> 00:20:47,980
We generated a heat map
because we love heat maps,

510
00:20:47,980 --> 00:20:50,582
and what we saw were
right around here,
this is the midline.

511
00:20:50,582 --> 00:20:53,018
Kind of that orange to
pinkish purple color,

512
00:20:53,018 --> 00:20:55,420
and so our two control documents

513
00:20:55,420 --> 00:20:58,190
were kind of more consistent
and more in the midline.

514
00:20:58,190 --> 00:21:01,059
Here's our IVN report there
with basically nothing,

515
00:21:01,059 --> 00:21:03,262
and then we had a couple
of different reports

516
00:21:03,262 --> 00:21:06,697
with things like high
sourcing but not much else,

517
00:21:08,133 --> 00:21:10,068
and we could kind of start
to see the fingerprint.

518
00:21:10,068 --> 00:21:13,504
What does a good piece
of information look like

519
00:21:13,505 --> 00:21:15,474
versus something I know is bad?

520
00:21:15,474 --> 00:21:17,075
Again, I'm not looking
for perfection,

521
00:21:17,075 --> 00:21:18,577
I'm looking for shortcuts.

522
00:21:18,577 --> 00:21:20,078
I'm looking for something
that's going to help me

523
00:21:20,078 --> 00:21:22,547
quickly identify whether or
not this is worth my time.

524
00:21:23,749 --> 00:21:25,250
We found a couple
of trends by then

525
00:21:25,250 --> 00:21:27,619
going back in and reading
more about the document

526
00:21:27,619 --> 00:21:30,389
or more about the articles
and looking for where it fit

527
00:21:30,389 --> 00:21:31,622
in those different categories,

528
00:21:31,623 --> 00:21:33,492
so we found a couple of trends.

529
00:21:33,492 --> 00:21:37,162
The first one, in documents
where they had high sourcing

530
00:21:37,162 --> 00:21:39,097
and high words of uncertainty,

531
00:21:39,097 --> 00:21:42,334
those tended to be more of
those hypothesis as facts.

532
00:21:42,334 --> 00:21:44,069
There was a source,
somebody was willing

533
00:21:44,069 --> 00:21:46,805
to talk to somebody, they
could say who was being cited,

534
00:21:46,805 --> 00:21:48,674
but there were lots of
high words of uncertainty.

535
00:21:48,674 --> 00:21:51,677
It could be, might be,
we'll see, we'll find out.

536
00:21:53,011 --> 00:21:54,546
Looking for that
particular pattern

537
00:21:54,546 --> 00:21:58,216
is a good way to identify
that type of misinformation.

538
00:22:00,252 --> 00:22:02,587
We also saw high
words of sourcing

539
00:22:02,587 --> 00:22:05,891
and then low uncertainty
and low explanatory

540
00:22:05,891 --> 00:22:07,893
fit the pattern of
pushing an agenda,

541
00:22:07,893 --> 00:22:12,264
and what we found when we went
back to look in more detail

542
00:22:12,264 --> 00:22:13,931
was that they had high sourcing

543
00:22:15,200 --> 00:22:16,835
but the sources were things like

544
00:22:16,835 --> 00:22:18,737
according to an
anonymous source,

545
00:22:18,737 --> 00:22:21,306
or according to somebody
close to the information

546
00:22:21,306 --> 00:22:22,607
and I'm like, wait a minute,

547
00:22:22,607 --> 00:22:25,476
you're saying the right
words to make me think

548
00:22:25,477 --> 00:22:27,813
that you've talked to
somebody about this,

549
00:22:27,813 --> 00:22:29,915
but you're not giving
me any information.

550
00:22:29,915 --> 00:22:31,082
The next stage of our research,

551
00:22:31,083 --> 00:22:32,684
we're going to
start applying tags,

552
00:22:32,684 --> 00:22:34,019
so when we look for
words of sourcing

553
00:22:34,019 --> 00:22:35,187
we're going to try and identify

554
00:22:35,187 --> 00:22:37,322
whether it's a
person's name versus

555
00:22:37,322 --> 00:22:39,323
somebody close to the President,

556
00:22:39,324 --> 00:22:42,027
'cause let's face it,
we're all here in Bethesda.

557
00:22:42,027 --> 00:22:43,228
Compared to most of the world,

558
00:22:43,228 --> 00:22:44,930
we are relatively
close to the President.

559
00:22:44,930 --> 00:22:47,532
I feel like we can go ahead
and start citing things.

560
00:22:48,767 --> 00:22:51,636
The next one we found
is low everything,

561
00:22:51,636 --> 00:22:53,071
and this was our IVN report

562
00:22:53,071 --> 00:22:55,374
and a couple of
other opinion pieces.

563
00:22:55,374 --> 00:22:58,710
This is the profile of an
opinion piece pushing an agenda.

564
00:22:58,710 --> 00:22:59,845
There's not a lot of sourcing

565
00:22:59,845 --> 00:23:01,113
'cause it's somebody's
own opinion.

566
00:23:01,113 --> 00:23:02,481
There's not a lot of
words of uncertainty

567
00:23:02,481 --> 00:23:04,683
because they are certain
of their position.

568
00:23:04,683 --> 00:23:07,285
Not a lot of explanations,
not a lot of retractors.

569
00:23:07,285 --> 00:23:09,221
When you see that low pattern,

570
00:23:09,221 --> 00:23:11,556
I would not even really
waste my time on that

571
00:23:11,556 --> 00:23:14,259
because that's likely
to be opinion, not fact.

572
00:23:15,927 --> 00:23:17,963
And then none of the
information in our sample

573
00:23:17,963 --> 00:23:20,298
fit this profile, but we
started looking out for

574
00:23:20,298 --> 00:23:24,669
okay, what does disinformation
actually look like?

575
00:23:24,669 --> 00:23:27,038
We had to go back and
pull different documents

576
00:23:27,038 --> 00:23:29,341
from the CIA archives
that had been published

577
00:23:29,341 --> 00:23:31,642
and we found in a lot of cases

578
00:23:31,643 --> 00:23:33,378
that information that
was being sent out

579
00:23:33,378 --> 00:23:36,814
as kind of propaganda
and disinformation

580
00:23:36,815 --> 00:23:39,451
had high words of uncertainty
and high retractors

581
00:23:39,451 --> 00:23:42,854
and again, they want to be
able to back themselves out.

582
00:23:42,854 --> 00:23:45,957
All they want to do is sew those
seeds of doubt in your mind

583
00:23:45,957 --> 00:23:49,494
and there was low sourcing
and low explantation.

584
00:23:49,494 --> 00:23:51,562
Again, that's just
something to look for.

585
00:23:51,563 --> 00:23:52,898
Like I said, we're
still kind of still

586
00:23:52,898 --> 00:23:54,331
tweaking our algorithms.

587
00:23:54,332 --> 00:23:56,368
We've already got more
things we want to look for,

588
00:23:56,368 --> 00:23:58,970
but we want to make this
mechanism that we use

589
00:23:58,970 --> 00:24:00,605
to do this quick
fingerprint available

590
00:24:00,605 --> 00:24:02,441
just in case it does
help other people

591
00:24:02,441 --> 00:24:03,642
kind of understand how to handle

592
00:24:03,642 --> 00:24:06,278
a lot of the information
that's out there.

593
00:24:06,278 --> 00:24:09,381
The problem we found with
information security, though,

594
00:24:09,381 --> 00:24:11,716
is that that model really
only works with text,

595
00:24:11,716 --> 00:24:14,285
like with news articles
and media reporting

596
00:24:14,286 --> 00:24:16,488
and even long form
intelligence reports,

597
00:24:16,488 --> 00:24:18,290
we saw the same profiles.

598
00:24:19,958 --> 00:24:20,992
But it doesn't work really well

599
00:24:20,992 --> 00:24:23,161
for things like malware analysis

600
00:24:23,161 --> 00:24:25,997
or technical blogs or
vulnerability disclosure,

601
00:24:25,997 --> 00:24:27,966
so what we started
looking for there

602
00:24:27,966 --> 00:24:30,101
is something called
integrative complexity,

603
00:24:30,101 --> 00:24:32,437
which is a score
from one to seven

604
00:24:32,437 --> 00:24:37,375
that looks at how
complex, not the content,

605
00:24:37,375 --> 00:24:39,945
but the way that
words are put together

606
00:24:39,945 --> 00:24:42,880
and the way that
they are structured.

607
00:24:44,282 --> 00:24:45,550
It looks for two things.

608
00:24:45,550 --> 00:24:47,953
Differentiation, how
well can I identify

609
00:24:47,953 --> 00:24:50,455
that there's more than
one possible answer

610
00:24:50,455 --> 00:24:53,692
or outcome or consideration,
and then integration,

611
00:24:53,692 --> 00:24:56,127
which is how well
can I piece together

612
00:24:56,127 --> 00:24:58,562
different information and
then draw those connections

613
00:24:58,563 --> 00:25:00,031
between different things.

614
00:25:01,199 --> 00:25:03,802
It is really hard,
really, really hard,

615
00:25:03,802 --> 00:25:06,237
to automate
integrative complexity.

616
00:25:06,238 --> 00:25:07,873
A lot of people have tried.

617
00:25:07,873 --> 00:25:10,709
There's some documentation
out there about how to do it,

618
00:25:10,709 --> 00:25:14,246
but the recommended
way to handle it

619
00:25:14,246 --> 00:25:15,814
is still like hand coding,

620
00:25:15,814 --> 00:25:20,151
which is not going to save me
any processing power there.

621
00:25:20,151 --> 00:25:21,553
What I started doing with this

622
00:25:21,553 --> 00:25:23,455
is coming up with
some rules of thumb

623
00:25:23,455 --> 00:25:28,260
for the very simple versus
the very complex documents

624
00:25:28,260 --> 00:25:30,862
with the idea that the
more complex it is,

625
00:25:30,862 --> 00:25:34,299
the more likely it has been
well researched and thorough.

626
00:25:34,299 --> 00:25:37,369
Some tips for that are
when you start to see

627
00:25:37,369 --> 00:25:40,071
words like just, or
always, or never,

628
00:25:40,071 --> 00:25:43,375
that's the indication of a
more simplistic viewpoint.

629
00:25:44,576 --> 00:25:47,112
Look for synthesis and
multiple data sources.

630
00:25:47,112 --> 00:25:48,813
That's when we talk
about that integration.

631
00:25:48,813 --> 00:25:51,416
If somebody's taken more
things into account,

632
00:25:51,416 --> 00:25:54,019
they've probably done some
more thorough research.

633
00:25:54,019 --> 00:25:55,554
Look for counterpoints
or arguments

634
00:25:55,554 --> 00:25:56,955
to be preemptively addressed,

635
00:25:56,955 --> 00:25:59,124
especially with a lot
of things that we do.

636
00:26:00,325 --> 00:26:01,793
There are going to
be counterpoints,

637
00:26:01,793 --> 00:26:03,828
and if there's an analyst
who can identify those

638
00:26:03,828 --> 00:26:06,264
and say well yes, we
know that sometimes

639
00:26:06,264 --> 00:26:07,933
people run this against
this type of system

640
00:26:07,933 --> 00:26:09,701
and so we would expect
to see this sort of thing

641
00:26:09,701 --> 00:26:11,570
but in this case, we saw,

642
00:26:11,570 --> 00:26:13,104
when they're doing
that type of analysis

643
00:26:13,104 --> 00:26:16,107
I have a little more faith
that it's worth my time.

644
00:26:16,107 --> 00:26:18,643
And then look for complexity
across the entire text,

645
00:26:18,643 --> 00:26:20,378
not just their
area of expertise.

646
00:26:20,378 --> 00:26:22,847
This is a big problem I found

647
00:26:22,847 --> 00:26:25,617
as kind of a result of
doing this analysis,

648
00:26:25,617 --> 00:26:29,486
which is that any time we
talk about vulnerabilities,

649
00:26:29,487 --> 00:26:33,058
we find big problems or attacks
or people aren't patching,

650
00:26:33,058 --> 00:26:34,893
our analysis of
information security,

651
00:26:34,893 --> 00:26:38,163
our domain where we're
experts, super complex.

652
00:26:38,163 --> 00:26:39,698
We can see all the
different components,

653
00:26:39,698 --> 00:26:40,999
we can articulate
all the components,

654
00:26:40,999 --> 00:26:42,801
we know how they're all related,

655
00:26:42,801 --> 00:26:45,704
and then when we say,
what needs to be done?

656
00:26:45,704 --> 00:26:47,305
Well, just patch.

657
00:26:47,305 --> 00:26:49,407
Jeez, you're dumb, why
didn't you already fix that?

658
00:26:49,407 --> 00:26:51,842
We cannot reach that
same level of complexity

659
00:26:51,843 --> 00:26:53,612
outside of information security

660
00:26:53,612 --> 00:26:56,348
to tell people how to
address the problems.

661
00:26:56,348 --> 00:26:57,514
That's a whole another
line of research,

662
00:26:57,515 --> 00:26:59,351
but it's just something
to be aware of,

663
00:26:59,351 --> 00:27:01,987
that you want that complexity
across the whole spectrum,

664
00:27:01,987 --> 00:27:03,822
not just one particular area.

665
00:27:06,424 --> 00:27:08,059
All right, so how do we survive,

666
00:27:08,059 --> 00:27:11,363
how did I find out
how to survive in the
misinformation age?

667
00:27:11,363 --> 00:27:14,432
Sourcing, look for where
the information came from.

668
00:27:14,432 --> 00:27:17,569
That's going to be
your number one way

669
00:27:17,569 --> 00:27:19,838
of weeding out bad
information right there.

670
00:27:19,838 --> 00:27:22,706
Number two, content,
what are they saying?

671
00:27:22,707 --> 00:27:25,710
Look for some of those tips like

672
00:27:25,710 --> 00:27:28,647
according to an anonymous
source close to the President.

673
00:27:28,647 --> 00:27:31,515
Look for high words
of uncertainty.

674
00:27:31,516 --> 00:27:33,451
Like I said, you want
some, but you don't want

675
00:27:33,451 --> 00:27:35,353
the whole thing to be a
high word of uncertainty

676
00:27:35,353 --> 00:27:36,855
or that could give
you an indication

677
00:27:36,855 --> 00:27:39,791
that it's not actually final
research or final information.

678
00:27:39,791 --> 00:27:41,525
And then look at the structure.

679
00:27:41,526 --> 00:27:43,094
Like I said, any
time somebody says

680
00:27:43,094 --> 00:27:46,297
always or never or just,
I'm immediately suspicious.

681
00:27:46,297 --> 00:27:48,867
Sometimes, they are
good cases for that,

682
00:27:48,867 --> 00:27:51,403
but it is kind of a
good flag to look for.

683
00:27:52,704 --> 00:27:56,408
And then finally,
let's not just survive.

684
00:27:56,408 --> 00:27:57,908
Let's change things.

685
00:27:57,909 --> 00:28:00,111
Let's not make it
more and more piled on

686
00:28:00,111 --> 00:28:01,546
of bad information.

687
00:28:01,546 --> 00:28:03,782
A lot of us in this
room, we have the ability

688
00:28:03,782 --> 00:28:05,550
to create content.

689
00:28:05,550 --> 00:28:08,520
We provide input to media,
to information report,

690
00:28:08,520 --> 00:28:10,655
to infosec reporting, to blogs.

691
00:28:10,655 --> 00:28:12,424
Make sure that you
are taking the time

692
00:28:12,424 --> 00:28:15,460
to do good analysis, to
identify your sources

693
00:28:15,460 --> 00:28:18,296
and validate them before you
start putting information out.

694
00:28:18,296 --> 00:28:20,865
It's great if you go back
and fix it after you need it,

695
00:28:20,865 --> 00:28:22,333
but the best way to make sure

696
00:28:22,333 --> 00:28:24,035
people are getting
the right information

697
00:28:24,035 --> 00:28:26,304
is to put it out there
and take the extra time

698
00:28:26,304 --> 00:28:27,472
to be thorough.

699
00:28:29,274 --> 00:28:31,176
Let's raise the bar.

700
00:28:31,176 --> 00:28:33,110
And if that requires
raising a little hell

701
00:28:33,111 --> 00:28:35,380
and turning the current
way that we're doing things

702
00:28:35,380 --> 00:28:37,682
on its head, I'm
okay with that, too.

703
00:28:37,682 --> 00:28:39,684
Like I said, totally
not an anarchist.

704
00:28:42,087 --> 00:28:43,688
If you want to learn
more, we started putting

705
00:28:43,688 --> 00:28:46,257
our basic research
that we've been doing

706
00:28:46,257 --> 00:28:49,594
on the thematic content analysis
into my github repo there.

707
00:28:49,594 --> 00:28:51,096
These are some additional
documentations,

708
00:28:51,096 --> 00:28:54,165
they're not necessarily
CTI documentations

709
00:28:54,165 --> 00:28:55,600
except for the very bottom one.

710
00:28:55,600 --> 00:28:57,702
That's actually a really
good current report

711
00:28:57,702 --> 00:29:00,371
on countering Russian
disinformation.

712
00:29:00,371 --> 00:29:03,141
But it's some different
good things you can look at

713
00:29:03,141 --> 00:29:05,110
to better understand how
we can solve problems

714
00:29:05,110 --> 00:29:08,178
by looking outside of our
own domain of expertise.

715
00:29:08,179 --> 00:29:10,115
All right, I am out of time,

716
00:29:10,115 --> 00:29:12,083
but thank you so
much for being here.

717
00:29:12,083 --> 00:29:15,019
Thank you for staying, I
really, really appreciate it,

718
00:29:15,019 --> 00:29:16,855
and I hope to see you
all back next year.

719
00:29:16,855 --> 00:29:20,458
(audience applauding)

720
00:29:20,458 --> 00:29:22,961
(tense music)

